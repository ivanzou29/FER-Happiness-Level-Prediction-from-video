Epoch: 1| Step: 0
Training loss: 6.4583639164682465
Validation loss: 5.787557328452598

Epoch: 6| Step: 1
Training loss: 5.970748167457678
Validation loss: 5.770483302290703

Epoch: 6| Step: 2
Training loss: 5.254468560173666
Validation loss: 5.753421526973316

Epoch: 6| Step: 3
Training loss: 5.9561308233420815
Validation loss: 5.7353064691507125

Epoch: 6| Step: 4
Training loss: 6.34091198207358
Validation loss: 5.715713493671167

Epoch: 6| Step: 5
Training loss: 5.413376537645435
Validation loss: 5.692809459046758

Epoch: 6| Step: 6
Training loss: 4.958369321719229
Validation loss: 5.667642610078708

Epoch: 6| Step: 7
Training loss: 4.88537413274256
Validation loss: 5.638495630450034

Epoch: 6| Step: 8
Training loss: 4.076955108627476
Validation loss: 5.605730627716501

Epoch: 6| Step: 9
Training loss: 6.181342249414324
Validation loss: 5.569060809598365

Epoch: 6| Step: 10
Training loss: 5.420989478186378
Validation loss: 5.529338224718908

Epoch: 6| Step: 11
Training loss: 5.832312830714953
Validation loss: 5.482566836226511

Epoch: 6| Step: 12
Training loss: 5.877067689042048
Validation loss: 5.431363118489759

Epoch: 6| Step: 13
Training loss: 6.616376915007587
Validation loss: 5.376471891955525

Epoch: 2| Step: 0
Training loss: 4.414237716032912
Validation loss: 5.313430683377808

Epoch: 6| Step: 1
Training loss: 5.661116893009573
Validation loss: 5.250422789332594

Epoch: 6| Step: 2
Training loss: 5.520514290665976
Validation loss: 5.181331164555833

Epoch: 6| Step: 3
Training loss: 4.357933106776051
Validation loss: 5.10980583051108

Epoch: 6| Step: 4
Training loss: 4.501154433626063
Validation loss: 5.035948414105851

Epoch: 6| Step: 5
Training loss: 5.587270041561799
Validation loss: 4.964042790212668

Epoch: 6| Step: 6
Training loss: 4.378806937433129
Validation loss: 4.895669826621465

Epoch: 6| Step: 7
Training loss: 5.718843052841817
Validation loss: 4.833310399126599

Epoch: 6| Step: 8
Training loss: 5.231310320179412
Validation loss: 4.77331711454988

Epoch: 6| Step: 9
Training loss: 5.249770749854263
Validation loss: 4.717325029234238

Epoch: 6| Step: 10
Training loss: 3.2886246414680262
Validation loss: 4.664814425800725

Epoch: 6| Step: 11
Training loss: 5.5202634505277395
Validation loss: 4.61821654890832

Epoch: 6| Step: 12
Training loss: 4.538240499472751
Validation loss: 4.577159060260554

Epoch: 6| Step: 13
Training loss: 4.877815802755905
Validation loss: 4.5378901252305335

Epoch: 3| Step: 0
Training loss: 4.773303440540276
Validation loss: 4.505230867992318

Epoch: 6| Step: 1
Training loss: 4.388457173764693
Validation loss: 4.477768762530689

Epoch: 6| Step: 2
Training loss: 5.904328856285367
Validation loss: 4.453928033269473

Epoch: 6| Step: 3
Training loss: 4.761933044167954
Validation loss: 4.429387109479352

Epoch: 6| Step: 4
Training loss: 4.970102761816167
Validation loss: 4.4047578373650005

Epoch: 6| Step: 5
Training loss: 5.178940294780806
Validation loss: 4.375223067964935

Epoch: 6| Step: 6
Training loss: 4.8293921526889
Validation loss: 4.345877309960581

Epoch: 6| Step: 7
Training loss: 3.4805697202753683
Validation loss: 4.321100398680209

Epoch: 6| Step: 8
Training loss: 4.108171758253603
Validation loss: 4.2968491802017805

Epoch: 6| Step: 9
Training loss: 3.9275013965043293
Validation loss: 4.278395562659754

Epoch: 6| Step: 10
Training loss: 4.1428546012908205
Validation loss: 4.263084357275331

Epoch: 6| Step: 11
Training loss: 3.9727513124688105
Validation loss: 4.246585939268236

Epoch: 6| Step: 12
Training loss: 3.668253699661206
Validation loss: 4.232880643977454

Epoch: 6| Step: 13
Training loss: 3.5928765603829773
Validation loss: 4.215481911903768

Epoch: 4| Step: 0
Training loss: 4.530888615370881
Validation loss: 4.202791739275294

Epoch: 6| Step: 1
Training loss: 5.1764684832665555
Validation loss: 4.183399063892813

Epoch: 6| Step: 2
Training loss: 5.072012359206969
Validation loss: 4.169415765995787

Epoch: 6| Step: 3
Training loss: 4.831219221759779
Validation loss: 4.153348403492745

Epoch: 6| Step: 4
Training loss: 3.618024230808411
Validation loss: 4.134100633952474

Epoch: 6| Step: 5
Training loss: 4.325148237036376
Validation loss: 4.118903105796205

Epoch: 6| Step: 6
Training loss: 4.290393060137221
Validation loss: 4.102238747535054

Epoch: 6| Step: 7
Training loss: 4.164730741262488
Validation loss: 4.089771973465616

Epoch: 6| Step: 8
Training loss: 3.1645543599178385
Validation loss: 4.075985857413186

Epoch: 6| Step: 9
Training loss: 3.7164502125020906
Validation loss: 4.067847779128399

Epoch: 6| Step: 10
Training loss: 3.930641013131177
Validation loss: 4.0544832755006945

Epoch: 6| Step: 11
Training loss: 3.853058004299581
Validation loss: 4.041912812650601

Epoch: 6| Step: 12
Training loss: 4.154130897380732
Validation loss: 4.02795619765085

Epoch: 6| Step: 13
Training loss: 4.348137923957992
Validation loss: 4.0163554325330075

Epoch: 5| Step: 0
Training loss: 3.803542949997166
Validation loss: 4.0060816390318585

Epoch: 6| Step: 1
Training loss: 4.818592129309408
Validation loss: 3.995674828981431

Epoch: 6| Step: 2
Training loss: 4.7586979785878425
Validation loss: 3.9827756492781665

Epoch: 6| Step: 3
Training loss: 2.8443470422472577
Validation loss: 3.97260792415748

Epoch: 6| Step: 4
Training loss: 3.30553062992333
Validation loss: 3.9697441268693976

Epoch: 6| Step: 5
Training loss: 4.471366063233422
Validation loss: 3.959959341034989

Epoch: 6| Step: 6
Training loss: 2.78107649015481
Validation loss: 3.947937449769261

Epoch: 6| Step: 7
Training loss: 5.323676884281888
Validation loss: 3.938420188354724

Epoch: 6| Step: 8
Training loss: 3.3845293652667614
Validation loss: 3.929938140752195

Epoch: 6| Step: 9
Training loss: 3.897443442041351
Validation loss: 3.9337138254897948

Epoch: 6| Step: 10
Training loss: 4.736436854422081
Validation loss: 3.9028636615554078

Epoch: 6| Step: 11
Training loss: 4.699214285248295
Validation loss: 3.8931818338973176

Epoch: 6| Step: 12
Training loss: 3.899116533422788
Validation loss: 3.8855712185999636

Epoch: 6| Step: 13
Training loss: 3.477942443608325
Validation loss: 3.871429292062076

Epoch: 6| Step: 0
Training loss: 4.1917306964652985
Validation loss: 3.8600009694375292

Epoch: 6| Step: 1
Training loss: 3.5409865380768952
Validation loss: 3.849452699493983

Epoch: 6| Step: 2
Training loss: 5.086856975736743
Validation loss: 3.836916316843158

Epoch: 6| Step: 3
Training loss: 3.4696391572687832
Validation loss: 3.8231652636038294

Epoch: 6| Step: 4
Training loss: 3.8648942409322546
Validation loss: 3.8131768916626814

Epoch: 6| Step: 5
Training loss: 4.1151917341763316
Validation loss: 3.8050650715243877

Epoch: 6| Step: 6
Training loss: 3.65438299521049
Validation loss: 3.795068389783486

Epoch: 6| Step: 7
Training loss: 2.662680348480379
Validation loss: 3.786397848365408

Epoch: 6| Step: 8
Training loss: 4.175702685767017
Validation loss: 3.777814817478239

Epoch: 6| Step: 9
Training loss: 4.1217245333309345
Validation loss: 3.7724194999841414

Epoch: 6| Step: 10
Training loss: 4.566318533962921
Validation loss: 3.7654095721151113

Epoch: 6| Step: 11
Training loss: 3.662600618093473
Validation loss: 3.755703469820796

Epoch: 6| Step: 12
Training loss: 4.072801645253197
Validation loss: 3.749065166429706

Epoch: 6| Step: 13
Training loss: 3.8446827818897327
Validation loss: 3.738882686038535

Epoch: 7| Step: 0
Training loss: 4.203980766448387
Validation loss: 3.728801200439575

Epoch: 6| Step: 1
Training loss: 4.390356958427425
Validation loss: 3.719568672764467

Epoch: 6| Step: 2
Training loss: 3.7558322058462195
Validation loss: 3.7117937089236968

Epoch: 6| Step: 3
Training loss: 2.777303059597759
Validation loss: 3.710010813283899

Epoch: 6| Step: 4
Training loss: 3.8126677179185573
Validation loss: 3.71463084028867

Epoch: 6| Step: 5
Training loss: 3.17782995904378
Validation loss: 3.6864021395295987

Epoch: 6| Step: 6
Training loss: 4.362659597893221
Validation loss: 3.6830836178070756

Epoch: 6| Step: 7
Training loss: 4.2027692112426
Validation loss: 3.6828929318972

Epoch: 6| Step: 8
Training loss: 3.4190209039058557
Validation loss: 3.6779270277302785

Epoch: 6| Step: 9
Training loss: 2.7621078972427457
Validation loss: 3.6697375581497274

Epoch: 6| Step: 10
Training loss: 3.7402288929871705
Validation loss: 3.6618297062229783

Epoch: 6| Step: 11
Training loss: 4.303260746783719
Validation loss: 3.651424862105059

Epoch: 6| Step: 12
Training loss: 3.9337964275615604
Validation loss: 3.6371969686206675

Epoch: 6| Step: 13
Training loss: 5.324461273020998
Validation loss: 3.625567718847627

Epoch: 8| Step: 0
Training loss: 4.418574634832919
Validation loss: 3.6174525982353045

Epoch: 6| Step: 1
Training loss: 4.130151941492523
Validation loss: 3.607904009535906

Epoch: 6| Step: 2
Training loss: 3.7791348681361585
Validation loss: 3.598421771299416

Epoch: 6| Step: 3
Training loss: 4.227929646898242
Validation loss: 3.5930829299796887

Epoch: 6| Step: 4
Training loss: 3.4116023297774563
Validation loss: 3.5860474551063675

Epoch: 6| Step: 5
Training loss: 3.589466760077895
Validation loss: 3.578512063813539

Epoch: 6| Step: 6
Training loss: 4.106401535327
Validation loss: 3.571061005143187

Epoch: 6| Step: 7
Training loss: 3.1065097815339504
Validation loss: 3.562345212471253

Epoch: 6| Step: 8
Training loss: 4.22742299682582
Validation loss: 3.5547230636366436

Epoch: 6| Step: 9
Training loss: 3.2041594532925517
Validation loss: 3.544436156714453

Epoch: 6| Step: 10
Training loss: 3.7385477032864696
Validation loss: 3.539284405217317

Epoch: 6| Step: 11
Training loss: 3.5289438194587337
Validation loss: 3.5312961201837187

Epoch: 6| Step: 12
Training loss: 3.2959931988692253
Validation loss: 3.5249809731823993

Epoch: 6| Step: 13
Training loss: 3.814695757812202
Validation loss: 3.520458920681933

Epoch: 9| Step: 0
Training loss: 3.44743285381386
Validation loss: 3.5137746417474753

Epoch: 6| Step: 1
Training loss: 3.6348326613830966
Validation loss: 3.5053310636402584

Epoch: 6| Step: 2
Training loss: 3.4701419821062887
Validation loss: 3.5001974914429703

Epoch: 6| Step: 3
Training loss: 3.773718276545999
Validation loss: 3.492666237340117

Epoch: 6| Step: 4
Training loss: 3.5758177135526137
Validation loss: 3.4867286129240225

Epoch: 6| Step: 5
Training loss: 3.9794415017861104
Validation loss: 3.4814725419763204

Epoch: 6| Step: 6
Training loss: 4.051479945167414
Validation loss: 3.476192834568486

Epoch: 6| Step: 7
Training loss: 3.3798976259697766
Validation loss: 3.4709179256431844

Epoch: 6| Step: 8
Training loss: 4.059816853568826
Validation loss: 3.464796227326015

Epoch: 6| Step: 9
Training loss: 3.5532321507813407
Validation loss: 3.4584400166971547

Epoch: 6| Step: 10
Training loss: 3.304276388943396
Validation loss: 3.454552661152556

Epoch: 6| Step: 11
Training loss: 4.0855649701709895
Validation loss: 3.4491528020571876

Epoch: 6| Step: 12
Training loss: 3.2523063399110312
Validation loss: 3.4442674234317243

Epoch: 6| Step: 13
Training loss: 4.166703694496931
Validation loss: 3.4405781676138525

Epoch: 10| Step: 0
Training loss: 3.4029844537021723
Validation loss: 3.4316582570592526

Epoch: 6| Step: 1
Training loss: 3.32965625764393
Validation loss: 3.424899012597232

Epoch: 6| Step: 2
Training loss: 3.5921876911496797
Validation loss: 3.4216498799427706

Epoch: 6| Step: 3
Training loss: 3.722345233105579
Validation loss: 3.416490895942091

Epoch: 6| Step: 4
Training loss: 4.219638307085923
Validation loss: 3.4102508569762806

Epoch: 6| Step: 5
Training loss: 3.310324044169209
Validation loss: 3.403794194271941

Epoch: 6| Step: 6
Training loss: 3.342567733957131
Validation loss: 3.4087377056864567

Epoch: 6| Step: 7
Training loss: 3.966498990615491
Validation loss: 3.410404889151581

Epoch: 6| Step: 8
Training loss: 3.66025916802677
Validation loss: 3.389067742343904

Epoch: 6| Step: 9
Training loss: 3.4424307399145864
Validation loss: 3.3823294376269724

Epoch: 6| Step: 10
Training loss: 3.529895083675691
Validation loss: 3.3787542356957325

Epoch: 6| Step: 11
Training loss: 3.826524298630261
Validation loss: 3.376959498883695

Epoch: 6| Step: 12
Training loss: 3.624390386426078
Validation loss: 3.369521010916205

Epoch: 6| Step: 13
Training loss: 3.7695913359443693
Validation loss: 3.3641980922552817

Epoch: 11| Step: 0
Training loss: 3.7478799549204003
Validation loss: 3.36423530227577

Epoch: 6| Step: 1
Training loss: 2.7698728192049384
Validation loss: 3.360904935310409

Epoch: 6| Step: 2
Training loss: 4.228286927273913
Validation loss: 3.3539532961907956

Epoch: 6| Step: 3
Training loss: 3.1103604542651553
Validation loss: 3.343508239660664

Epoch: 6| Step: 4
Training loss: 4.296083467578393
Validation loss: 3.339547924984304

Epoch: 6| Step: 5
Training loss: 3.440308134783258
Validation loss: 3.3360340442286147

Epoch: 6| Step: 6
Training loss: 3.7066723536257946
Validation loss: 3.333824718055178

Epoch: 6| Step: 7
Training loss: 3.228378856090491
Validation loss: 3.3265167961768176

Epoch: 6| Step: 8
Training loss: 3.923220096035403
Validation loss: 3.320076881266734

Epoch: 6| Step: 9
Training loss: 3.120691610122391
Validation loss: 3.316501825300672

Epoch: 6| Step: 10
Training loss: 3.991248093057112
Validation loss: 3.318878706624424

Epoch: 6| Step: 11
Training loss: 2.8223212107955993
Validation loss: 3.3074014966015906

Epoch: 6| Step: 12
Training loss: 2.913229488323181
Validation loss: 3.3101191261862715

Epoch: 6| Step: 13
Training loss: 4.54907236389445
Validation loss: 3.3128654261389854

Epoch: 12| Step: 0
Training loss: 3.7537257441887584
Validation loss: 3.3009426426263153

Epoch: 6| Step: 1
Training loss: 3.7754430397211927
Validation loss: 3.3064102456891353

Epoch: 6| Step: 2
Training loss: 3.6631620882763776
Validation loss: 3.2914481230015973

Epoch: 6| Step: 3
Training loss: 3.699455922307191
Validation loss: 3.283545244181922

Epoch: 6| Step: 4
Training loss: 3.9121124221858454
Validation loss: 3.286636946512857

Epoch: 6| Step: 5
Training loss: 3.711868972323807
Validation loss: 3.28209644344102

Epoch: 6| Step: 6
Training loss: 3.358085207296034
Validation loss: 3.27487924790461

Epoch: 6| Step: 7
Training loss: 2.9690633508046456
Validation loss: 3.268423718248011

Epoch: 6| Step: 8
Training loss: 2.88730195262165
Validation loss: 3.2696801206100212

Epoch: 6| Step: 9
Training loss: 3.6999022548239657
Validation loss: 3.2683463584454326

Epoch: 6| Step: 10
Training loss: 3.445260875773594
Validation loss: 3.2700193176145493

Epoch: 6| Step: 11
Training loss: 3.37565945434503
Validation loss: 3.261951512355617

Epoch: 6| Step: 12
Training loss: 3.0626558536653645
Validation loss: 3.2535830877459757

Epoch: 6| Step: 13
Training loss: 4.078258760677524
Validation loss: 3.2464014518610056

Epoch: 13| Step: 0
Training loss: 2.936954041736766
Validation loss: 3.2418745269130076

Epoch: 6| Step: 1
Training loss: 2.8344980164805422
Validation loss: 3.2448961713210633

Epoch: 6| Step: 2
Training loss: 3.567634897334809
Validation loss: 3.237432614200592

Epoch: 6| Step: 3
Training loss: 3.689211044326095
Validation loss: 3.227931908289397

Epoch: 6| Step: 4
Training loss: 3.338242174701465
Validation loss: 3.223367902201735

Epoch: 6| Step: 5
Training loss: 4.076077118792617
Validation loss: 3.2182888756420165

Epoch: 6| Step: 6
Training loss: 3.491152206673833
Validation loss: 3.214249766015788

Epoch: 6| Step: 7
Training loss: 3.3155290681441754
Validation loss: 3.220015055300798

Epoch: 6| Step: 8
Training loss: 3.298036199071463
Validation loss: 3.2081956044106352

Epoch: 6| Step: 9
Training loss: 3.2617032536121404
Validation loss: 3.2562638414964344

Epoch: 6| Step: 10
Training loss: 3.796374001435693
Validation loss: 3.213245491014016

Epoch: 6| Step: 11
Training loss: 3.721243270955074
Validation loss: 3.226841404101482

Epoch: 6| Step: 12
Training loss: 3.624982636508792
Validation loss: 3.2370072862544887

Epoch: 6| Step: 13
Training loss: 3.722089406074761
Validation loss: 3.2362188182557365

Epoch: 14| Step: 0
Training loss: 3.7924801858523938
Validation loss: 3.2215648655864344

Epoch: 6| Step: 1
Training loss: 3.2632339704256186
Validation loss: 3.20529650402336

Epoch: 6| Step: 2
Training loss: 4.236124163053379
Validation loss: 3.1903015731932283

Epoch: 6| Step: 3
Training loss: 3.1379969594635586
Validation loss: 3.1886349080593175

Epoch: 6| Step: 4
Training loss: 3.3226122263259614
Validation loss: 3.186640731999295

Epoch: 6| Step: 5
Training loss: 3.4020782962784364
Validation loss: 3.1846015020158975

Epoch: 6| Step: 6
Training loss: 3.5593874535079
Validation loss: 3.1816770016597617

Epoch: 6| Step: 7
Training loss: 2.932459788587412
Validation loss: 3.1747891367127448

Epoch: 6| Step: 8
Training loss: 3.26206535279503
Validation loss: 3.1726063644341194

Epoch: 6| Step: 9
Training loss: 3.8999980486351413
Validation loss: 3.16927097677924

Epoch: 6| Step: 10
Training loss: 3.5808971610686355
Validation loss: 3.165063640651443

Epoch: 6| Step: 11
Training loss: 2.957178472484784
Validation loss: 3.162082821614055

Epoch: 6| Step: 12
Training loss: 3.4775413935245627
Validation loss: 3.15766364342521

Epoch: 6| Step: 13
Training loss: 2.94332745996093
Validation loss: 3.14897503868851

Epoch: 15| Step: 0
Training loss: 3.4152757247940007
Validation loss: 3.1455140049889514

Epoch: 6| Step: 1
Training loss: 4.100763966165472
Validation loss: 3.140212289288179

Epoch: 6| Step: 2
Training loss: 2.9886402587654266
Validation loss: 3.133492570556069

Epoch: 6| Step: 3
Training loss: 3.080383866156687
Validation loss: 3.132086682986729

Epoch: 6| Step: 4
Training loss: 3.261207037891667
Validation loss: 3.141390611702704

Epoch: 6| Step: 5
Training loss: 3.167564432140678
Validation loss: 3.134799411793372

Epoch: 6| Step: 6
Training loss: 3.7822442126976497
Validation loss: 3.1188087052274516

Epoch: 6| Step: 7
Training loss: 2.98198152600098
Validation loss: 3.1118907269047233

Epoch: 6| Step: 8
Training loss: 3.5223495258493265
Validation loss: 3.1088366191567807

Epoch: 6| Step: 9
Training loss: 4.116035198835967
Validation loss: 3.1063315179239788

Epoch: 6| Step: 10
Training loss: 2.1446763286608115
Validation loss: 3.1058767700653296

Epoch: 6| Step: 11
Training loss: 3.544661314244654
Validation loss: 3.106458222919057

Epoch: 6| Step: 12
Training loss: 3.298589613102689
Validation loss: 3.0994453315689063

Epoch: 6| Step: 13
Training loss: 3.838480741447822
Validation loss: 3.0903778359237517

Epoch: 16| Step: 0
Training loss: 3.151318010975539
Validation loss: 3.09472108352348

Epoch: 6| Step: 1
Training loss: 2.469351972754034
Validation loss: 3.105250904596814

Epoch: 6| Step: 2
Training loss: 3.6273383129636994
Validation loss: 3.1175104595323027

Epoch: 6| Step: 3
Training loss: 3.1278889844272553
Validation loss: 3.118571241978944

Epoch: 6| Step: 4
Training loss: 3.6107760265764366
Validation loss: 3.1116943053254724

Epoch: 6| Step: 5
Training loss: 2.8913784385483585
Validation loss: 3.1068018642926014

Epoch: 6| Step: 6
Training loss: 3.9227341398594735
Validation loss: 3.088616623600343

Epoch: 6| Step: 7
Training loss: 3.6956270821931763
Validation loss: 3.0787695203738212

Epoch: 6| Step: 8
Training loss: 3.2116034715100388
Validation loss: 3.0747361447548585

Epoch: 6| Step: 9
Training loss: 3.736623685545925
Validation loss: 3.086557212527821

Epoch: 6| Step: 10
Training loss: 2.980184599003999
Validation loss: 3.0910996658594834

Epoch: 6| Step: 11
Training loss: 3.718157296270502
Validation loss: 3.0706950334541165

Epoch: 6| Step: 12
Training loss: 3.370115914091689
Validation loss: 3.055098210473381

Epoch: 6| Step: 13
Training loss: 3.382752873906164
Validation loss: 3.056604310239701

Epoch: 17| Step: 0
Training loss: 3.799806569848223
Validation loss: 3.0611014103515375

Epoch: 6| Step: 1
Training loss: 3.9780245568240056
Validation loss: 3.0598217099789426

Epoch: 6| Step: 2
Training loss: 3.791923528222092
Validation loss: 3.0559976478567177

Epoch: 6| Step: 3
Training loss: 2.6850335979668287
Validation loss: 3.037748440790879

Epoch: 6| Step: 4
Training loss: 3.235948557629888
Validation loss: 3.02769540385743

Epoch: 6| Step: 5
Training loss: 2.7068992241264573
Validation loss: 3.025250399816142

Epoch: 6| Step: 6
Training loss: 3.618150751704598
Validation loss: 3.033780365310815

Epoch: 6| Step: 7
Training loss: 3.7158494424367388
Validation loss: 3.0303485376939356

Epoch: 6| Step: 8
Training loss: 3.454122407918793
Validation loss: 3.0163500058459323

Epoch: 6| Step: 9
Training loss: 3.007494783341473
Validation loss: 3.013252302942568

Epoch: 6| Step: 10
Training loss: 3.0198165936388106
Validation loss: 3.0108386581114646

Epoch: 6| Step: 11
Training loss: 2.770168559320154
Validation loss: 3.0100563453353013

Epoch: 6| Step: 12
Training loss: 2.954465531555316
Validation loss: 3.007048857603009

Epoch: 6| Step: 13
Training loss: 3.521637924324979
Validation loss: 3.010013976771404

Epoch: 18| Step: 0
Training loss: 3.6436523162677394
Validation loss: 3.0094947954744717

Epoch: 6| Step: 1
Training loss: 3.827322365832854
Validation loss: 3.015366923379848

Epoch: 6| Step: 2
Training loss: 2.992960299701755
Validation loss: 2.993882114419575

Epoch: 6| Step: 3
Training loss: 3.1651312636022726
Validation loss: 2.9878774530042835

Epoch: 6| Step: 4
Training loss: 3.062660368788204
Validation loss: 2.9828305514477145

Epoch: 6| Step: 5
Training loss: 3.563285071888024
Validation loss: 2.9885504428493888

Epoch: 6| Step: 6
Training loss: 2.9637502229289048
Validation loss: 2.983545471642349

Epoch: 6| Step: 7
Training loss: 3.4966621831883966
Validation loss: 2.9828058743656154

Epoch: 6| Step: 8
Training loss: 2.776314631933103
Validation loss: 2.9744924639564108

Epoch: 6| Step: 9
Training loss: 3.562653789212411
Validation loss: 2.9731929406095627

Epoch: 6| Step: 10
Training loss: 4.024116769874837
Validation loss: 2.9748319302454513

Epoch: 6| Step: 11
Training loss: 2.342412541567471
Validation loss: 2.9767986420655634

Epoch: 6| Step: 12
Training loss: 2.792101574703308
Validation loss: 2.973344076555575

Epoch: 6| Step: 13
Training loss: 3.3901470919855163
Validation loss: 2.9760117614928054

Epoch: 19| Step: 0
Training loss: 3.1116140920252997
Validation loss: 2.9691462400774475

Epoch: 6| Step: 1
Training loss: 3.188788209788666
Validation loss: 2.971699274829362

Epoch: 6| Step: 2
Training loss: 3.3772298722632756
Validation loss: 2.968540238211245

Epoch: 6| Step: 3
Training loss: 3.672725108332301
Validation loss: 2.966013303179219

Epoch: 6| Step: 4
Training loss: 3.246562166536178
Validation loss: 2.95997504633701

Epoch: 6| Step: 5
Training loss: 3.2863482876513594
Validation loss: 2.958954260790748

Epoch: 6| Step: 6
Training loss: 3.3679911988566973
Validation loss: 2.9662347921210097

Epoch: 6| Step: 7
Training loss: 2.7616653976790513
Validation loss: 2.9631035414911144

Epoch: 6| Step: 8
Training loss: 2.9576110674526426
Validation loss: 2.9616380478011752

Epoch: 6| Step: 9
Training loss: 2.8460365576577566
Validation loss: 2.9519128872259883

Epoch: 6| Step: 10
Training loss: 3.103653594419853
Validation loss: 2.947443964020384

Epoch: 6| Step: 11
Training loss: 3.4665081580921786
Validation loss: 2.94858290401168

Epoch: 6| Step: 12
Training loss: 3.5518481641913873
Validation loss: 2.946272185501468

Epoch: 6| Step: 13
Training loss: 3.730050108422182
Validation loss: 2.942512903122742

Epoch: 20| Step: 0
Training loss: 2.872492484538553
Validation loss: 2.9438753207492323

Epoch: 6| Step: 1
Training loss: 3.1585388948752007
Validation loss: 2.941653141396286

Epoch: 6| Step: 2
Training loss: 3.0924877327480647
Validation loss: 2.939656537957439

Epoch: 6| Step: 3
Training loss: 3.595524756023688
Validation loss: 2.9395327894841867

Epoch: 6| Step: 4
Training loss: 3.3606669935596956
Validation loss: 2.9341501437178104

Epoch: 6| Step: 5
Training loss: 3.262113152146508
Validation loss: 2.9308004350994548

Epoch: 6| Step: 6
Training loss: 3.0794053876030563
Validation loss: 2.9286992515837404

Epoch: 6| Step: 7
Training loss: 3.507667589486632
Validation loss: 2.931487129979011

Epoch: 6| Step: 8
Training loss: 3.8599336659952836
Validation loss: 2.9257249275121584

Epoch: 6| Step: 9
Training loss: 3.1235848846699015
Validation loss: 2.9236305485657352

Epoch: 6| Step: 10
Training loss: 3.1300851265540843
Validation loss: 2.934584411496589

Epoch: 6| Step: 11
Training loss: 2.517864012781296
Validation loss: 2.9385525282443408

Epoch: 6| Step: 12
Training loss: 3.6089600163478077
Validation loss: 2.9475535861223063

Epoch: 6| Step: 13
Training loss: 2.7698484596913495
Validation loss: 2.919821753414249

Epoch: 21| Step: 0
Training loss: 2.700553067394161
Validation loss: 2.9188387721212736

Epoch: 6| Step: 1
Training loss: 3.0958867256280422
Validation loss: 2.9196033501183467

Epoch: 6| Step: 2
Training loss: 3.5609596000678567
Validation loss: 2.9218759230201576

Epoch: 6| Step: 3
Training loss: 3.5778664574647236
Validation loss: 2.925583337532727

Epoch: 6| Step: 4
Training loss: 3.2472954280517654
Validation loss: 2.9195439264360346

Epoch: 6| Step: 5
Training loss: 3.241650346128147
Validation loss: 2.914827934181749

Epoch: 6| Step: 6
Training loss: 3.2840511899203975
Validation loss: 2.9098105195023667

Epoch: 6| Step: 7
Training loss: 2.501123938636568
Validation loss: 2.9058134589348183

Epoch: 6| Step: 8
Training loss: 3.767202339791839
Validation loss: 2.9039282158707658

Epoch: 6| Step: 9
Training loss: 3.667052003090709
Validation loss: 2.900998909870217

Epoch: 6| Step: 10
Training loss: 3.1632904994732334
Validation loss: 2.899781018579547

Epoch: 6| Step: 11
Training loss: 3.0411998617019433
Validation loss: 2.8993201597187874

Epoch: 6| Step: 12
Training loss: 2.5057700327811085
Validation loss: 2.8984611290692524

Epoch: 6| Step: 13
Training loss: 3.5448449328771114
Validation loss: 2.898227532023347

Epoch: 22| Step: 0
Training loss: 3.295448898741091
Validation loss: 2.9087956394611973

Epoch: 6| Step: 1
Training loss: 3.567496827624701
Validation loss: 2.922009652574102

Epoch: 6| Step: 2
Training loss: 3.30066842332132
Validation loss: 2.8912976955271628

Epoch: 6| Step: 3
Training loss: 2.70181083707139
Validation loss: 2.8876541706661847

Epoch: 6| Step: 4
Training loss: 3.3464111006627193
Validation loss: 2.887872973292203

Epoch: 6| Step: 5
Training loss: 3.523977842999536
Validation loss: 2.8925338353645653

Epoch: 6| Step: 6
Training loss: 2.9494654672259513
Validation loss: 2.8942289820798384

Epoch: 6| Step: 7
Training loss: 3.183086556128141
Validation loss: 2.898762714244352

Epoch: 6| Step: 8
Training loss: 2.698429152272029
Validation loss: 2.8959610182654565

Epoch: 6| Step: 9
Training loss: 2.896506764073955
Validation loss: 2.8876840793868968

Epoch: 6| Step: 10
Training loss: 3.6085243708995476
Validation loss: 2.882860935365762

Epoch: 6| Step: 11
Training loss: 3.3004804666025227
Validation loss: 2.8788734841904216

Epoch: 6| Step: 12
Training loss: 3.0009638509533905
Validation loss: 2.8767887879968512

Epoch: 6| Step: 13
Training loss: 3.3749992935745063
Validation loss: 2.8836599561052214

Epoch: 23| Step: 0
Training loss: 3.6081749708797934
Validation loss: 2.882697269539908

Epoch: 6| Step: 1
Training loss: 3.2437190471488027
Validation loss: 2.8684578106404963

Epoch: 6| Step: 2
Training loss: 3.4420227814828697
Validation loss: 2.8677287512247926

Epoch: 6| Step: 3
Training loss: 3.1822721207055387
Validation loss: 2.8788706612998554

Epoch: 6| Step: 4
Training loss: 3.4273373278767902
Validation loss: 2.8640087553032427

Epoch: 6| Step: 5
Training loss: 3.064922542371155
Validation loss: 2.8611841851198307

Epoch: 6| Step: 6
Training loss: 3.206718104287655
Validation loss: 2.8633951488680656

Epoch: 6| Step: 7
Training loss: 3.600133119876953
Validation loss: 2.864059135973398

Epoch: 6| Step: 8
Training loss: 2.80090502009254
Validation loss: 2.8603176367748953

Epoch: 6| Step: 9
Training loss: 2.9852185080854006
Validation loss: 2.860201526941861

Epoch: 6| Step: 10
Training loss: 3.7594129045181663
Validation loss: 2.8668934491157847

Epoch: 6| Step: 11
Training loss: 2.2067609503312173
Validation loss: 2.8733815956540245

Epoch: 6| Step: 12
Training loss: 2.8498677273221684
Validation loss: 2.881518465944867

Epoch: 6| Step: 13
Training loss: 2.6026630994714983
Validation loss: 2.8799837145706673

Epoch: 24| Step: 0
Training loss: 3.5221377933891396
Validation loss: 2.8751378001841266

Epoch: 6| Step: 1
Training loss: 3.0720432053050994
Validation loss: 2.8664482035125283

Epoch: 6| Step: 2
Training loss: 2.8688048912232165
Validation loss: 2.859251779418064

Epoch: 6| Step: 3
Training loss: 3.4178136125506784
Validation loss: 2.8531047880755667

Epoch: 6| Step: 4
Training loss: 3.1819063360214392
Validation loss: 2.851423533524999

Epoch: 6| Step: 5
Training loss: 3.6123648806319046
Validation loss: 2.850277706865387

Epoch: 6| Step: 6
Training loss: 2.6637503253680586
Validation loss: 2.8511755041962554

Epoch: 6| Step: 7
Training loss: 2.514484692029159
Validation loss: 2.8598648818087065

Epoch: 6| Step: 8
Training loss: 3.799553322890891
Validation loss: 2.887816309169962

Epoch: 6| Step: 9
Training loss: 3.112770105614566
Validation loss: 2.8699902619736233

Epoch: 6| Step: 10
Training loss: 2.6018092866067817
Validation loss: 2.8561068477099956

Epoch: 6| Step: 11
Training loss: 3.627039237122272
Validation loss: 2.8478768942054047

Epoch: 6| Step: 12
Training loss: 3.2672404258961953
Validation loss: 2.8469078599402997

Epoch: 6| Step: 13
Training loss: 2.638314404334359
Validation loss: 2.8423966941626118

Epoch: 25| Step: 0
Training loss: 3.2446415082171565
Validation loss: 2.8415379233049385

Epoch: 6| Step: 1
Training loss: 2.990313946881753
Validation loss: 2.844884535912238

Epoch: 6| Step: 2
Training loss: 2.7377627068145376
Validation loss: 2.845353648994778

Epoch: 6| Step: 3
Training loss: 3.0247370960336486
Validation loss: 2.8522909567068493

Epoch: 6| Step: 4
Training loss: 3.229921379904057
Validation loss: 2.8547082136786917

Epoch: 6| Step: 5
Training loss: 2.8004540075343907
Validation loss: 2.8564939903288433

Epoch: 6| Step: 6
Training loss: 3.2579843306565657
Validation loss: 2.8572589215276785

Epoch: 6| Step: 7
Training loss: 2.652658255671208
Validation loss: 2.8564775269441847

Epoch: 6| Step: 8
Training loss: 2.91181331283426
Validation loss: 2.8489975228148534

Epoch: 6| Step: 9
Training loss: 3.1479888672104694
Validation loss: 2.845492267729408

Epoch: 6| Step: 10
Training loss: 3.568766386458795
Validation loss: 2.8411735664978863

Epoch: 6| Step: 11
Training loss: 3.4011491852960005
Validation loss: 2.8368035041737167

Epoch: 6| Step: 12
Training loss: 3.590923225893003
Validation loss: 2.8334141839765334

Epoch: 6| Step: 13
Training loss: 4.0301781937270915
Validation loss: 2.8303271897638185

Epoch: 26| Step: 0
Training loss: 3.3366501201126635
Validation loss: 2.8283706628141556

Epoch: 6| Step: 1
Training loss: 3.7082097036491604
Validation loss: 2.8252682899577715

Epoch: 6| Step: 2
Training loss: 3.5988735661918674
Validation loss: 2.8239749801030767

Epoch: 6| Step: 3
Training loss: 3.484159454384466
Validation loss: 2.833583658465619

Epoch: 6| Step: 4
Training loss: 2.8306607001528192
Validation loss: 2.832019994343479

Epoch: 6| Step: 5
Training loss: 3.8653663739935693
Validation loss: 2.832033615365913

Epoch: 6| Step: 6
Training loss: 3.248791983649822
Validation loss: 2.833393134898141

Epoch: 6| Step: 7
Training loss: 2.4086035575753635
Validation loss: 2.8215384397136107

Epoch: 6| Step: 8
Training loss: 3.0740001944924704
Validation loss: 2.8212017754492145

Epoch: 6| Step: 9
Training loss: 2.5225667957123687
Validation loss: 2.8240186183272358

Epoch: 6| Step: 10
Training loss: 2.89414590388952
Validation loss: 2.819787077492009

Epoch: 6| Step: 11
Training loss: 2.5060354811644676
Validation loss: 2.817319178072759

Epoch: 6| Step: 12
Training loss: 2.822842379973216
Validation loss: 2.8165582316579507

Epoch: 6| Step: 13
Training loss: 3.3816506590886566
Validation loss: 2.8155956118045853

Epoch: 27| Step: 0
Training loss: 3.169839139882258
Validation loss: 2.8159474044361734

Epoch: 6| Step: 1
Training loss: 3.241997770709919
Validation loss: 2.815363566727064

Epoch: 6| Step: 2
Training loss: 2.883645038257143
Validation loss: 2.8142277067686585

Epoch: 6| Step: 3
Training loss: 2.668128348138656
Validation loss: 2.8128467596717504

Epoch: 6| Step: 4
Training loss: 3.3425807156229004
Validation loss: 2.812816336831653

Epoch: 6| Step: 5
Training loss: 3.5820339123831437
Validation loss: 2.8103353832158575

Epoch: 6| Step: 6
Training loss: 2.9375240243781544
Validation loss: 2.8067598054626317

Epoch: 6| Step: 7
Training loss: 3.0448318282167213
Validation loss: 2.8145250729946074

Epoch: 6| Step: 8
Training loss: 2.813395548338977
Validation loss: 2.8299613886721575

Epoch: 6| Step: 9
Training loss: 3.761190502118325
Validation loss: 2.840808954497032

Epoch: 6| Step: 10
Training loss: 3.2922883875107427
Validation loss: 2.850975369277532

Epoch: 6| Step: 11
Training loss: 2.830385263861145
Validation loss: 2.843110672678109

Epoch: 6| Step: 12
Training loss: 2.7098434835188687
Validation loss: 2.8293642048472485

Epoch: 6| Step: 13
Training loss: 3.574569734944057
Validation loss: 2.801901757497407

Epoch: 28| Step: 0
Training loss: 3.077351894208092
Validation loss: 2.805911340053976

Epoch: 6| Step: 1
Training loss: 3.50619721126427
Validation loss: 2.8073170823421885

Epoch: 6| Step: 2
Training loss: 3.1241708799998382
Validation loss: 2.8119019468412363

Epoch: 6| Step: 3
Training loss: 2.507310478373378
Validation loss: 2.8161943088622308

Epoch: 6| Step: 4
Training loss: 2.6391250593902447
Validation loss: 2.82253164099419

Epoch: 6| Step: 5
Training loss: 3.5284220757103806
Validation loss: 2.827758381858285

Epoch: 6| Step: 6
Training loss: 3.1991671789761296
Validation loss: 2.816581158675904

Epoch: 6| Step: 7
Training loss: 2.9870639690321887
Validation loss: 2.8130523139328303

Epoch: 6| Step: 8
Training loss: 2.8195487808523905
Validation loss: 2.8105339461546324

Epoch: 6| Step: 9
Training loss: 2.94259607331618
Validation loss: 2.8068521595337126

Epoch: 6| Step: 10
Training loss: 3.7421877548440676
Validation loss: 2.8065889615103425

Epoch: 6| Step: 11
Training loss: 3.282566060943482
Validation loss: 2.8060629290207846

Epoch: 6| Step: 12
Training loss: 3.397721559375333
Validation loss: 2.8093680650874426

Epoch: 6| Step: 13
Training loss: 3.033236766857061
Validation loss: 2.802186578788959

Epoch: 29| Step: 0
Training loss: 3.3103071908071864
Validation loss: 2.799498442659553

Epoch: 6| Step: 1
Training loss: 3.4542822646311224
Validation loss: 2.795370069532414

Epoch: 6| Step: 2
Training loss: 2.6115176603569896
Validation loss: 2.7940585548697126

Epoch: 6| Step: 3
Training loss: 2.9055096083104552
Validation loss: 2.794257136797607

Epoch: 6| Step: 4
Training loss: 3.1383604169322847
Validation loss: 2.7966774207135296

Epoch: 6| Step: 5
Training loss: 3.553677794869841
Validation loss: 2.7973721281759274

Epoch: 6| Step: 6
Training loss: 3.271841310985302
Validation loss: 2.79463914423054

Epoch: 6| Step: 7
Training loss: 3.0440689076508054
Validation loss: 2.797305254308362

Epoch: 6| Step: 8
Training loss: 3.3105941183944685
Validation loss: 2.8155927272931662

Epoch: 6| Step: 9
Training loss: 2.9685460070745346
Validation loss: 2.800974075133442

Epoch: 6| Step: 10
Training loss: 3.507437297236113
Validation loss: 2.8053156436990734

Epoch: 6| Step: 11
Training loss: 3.2832510523160088
Validation loss: 2.7961295885214628

Epoch: 6| Step: 12
Training loss: 2.4090791394451663
Validation loss: 2.7846910832975285

Epoch: 6| Step: 13
Training loss: 2.292004046025458
Validation loss: 2.7856448087217323

Epoch: 30| Step: 0
Training loss: 3.118597873195925
Validation loss: 2.7822323140906584

Epoch: 6| Step: 1
Training loss: 3.379518098505318
Validation loss: 2.780027872478345

Epoch: 6| Step: 2
Training loss: 2.805886694960881
Validation loss: 2.779030948254826

Epoch: 6| Step: 3
Training loss: 2.865947902378965
Validation loss: 2.780048538088815

Epoch: 6| Step: 4
Training loss: 2.742893399839093
Validation loss: 2.77886517474721

Epoch: 6| Step: 5
Training loss: 3.0849122481022393
Validation loss: 2.7795584736868344

Epoch: 6| Step: 6
Training loss: 3.55131541851498
Validation loss: 2.7799399852051163

Epoch: 6| Step: 7
Training loss: 2.7392502402134644
Validation loss: 2.807475144512011

Epoch: 6| Step: 8
Training loss: 3.2762328528254243
Validation loss: 2.800005269887978

Epoch: 6| Step: 9
Training loss: 3.552739475240292
Validation loss: 2.7758601024103102

Epoch: 6| Step: 10
Training loss: 3.1834155073760853
Validation loss: 2.7729787028494988

Epoch: 6| Step: 11
Training loss: 3.5379359323793715
Validation loss: 2.7746632186581355

Epoch: 6| Step: 12
Training loss: 2.6530250269877294
Validation loss: 2.777246234003883

Epoch: 6| Step: 13
Training loss: 2.599730800484033
Validation loss: 2.778740791074267

Epoch: 31| Step: 0
Training loss: 2.7290879934682444
Validation loss: 2.78013534304086

Epoch: 6| Step: 1
Training loss: 3.947934569198291
Validation loss: 2.780249774926003

Epoch: 6| Step: 2
Training loss: 3.3215754721130994
Validation loss: 2.7791601406000557

Epoch: 6| Step: 3
Training loss: 3.4582134057511253
Validation loss: 2.7765172095362862

Epoch: 6| Step: 4
Training loss: 2.4712535863145075
Validation loss: 2.7730874542758155

Epoch: 6| Step: 5
Training loss: 2.1159190076460215
Validation loss: 2.7712333899885464

Epoch: 6| Step: 6
Training loss: 2.3150744155556957
Validation loss: 2.7728620459925724

Epoch: 6| Step: 7
Training loss: 3.036823457954498
Validation loss: 2.7692218275993357

Epoch: 6| Step: 8
Training loss: 3.5932527944519053
Validation loss: 2.76961029827168

Epoch: 6| Step: 9
Training loss: 2.5639947392949782
Validation loss: 2.766593315401476

Epoch: 6| Step: 10
Training loss: 2.825525849274902
Validation loss: 2.780601317049786

Epoch: 6| Step: 11
Training loss: 3.1894751020656638
Validation loss: 2.7777370413661053

Epoch: 6| Step: 12
Training loss: 3.556131928801847
Validation loss: 2.768793898957381

Epoch: 6| Step: 13
Training loss: 3.970889618599105
Validation loss: 2.763974156305195

Epoch: 32| Step: 0
Training loss: 3.1094041372496304
Validation loss: 2.7643697661828033

Epoch: 6| Step: 1
Training loss: 2.813759246363587
Validation loss: 2.7637643405901438

Epoch: 6| Step: 2
Training loss: 2.9928103762281837
Validation loss: 2.761661586096474

Epoch: 6| Step: 3
Training loss: 2.850074191549909
Validation loss: 2.7611527622192527

Epoch: 6| Step: 4
Training loss: 3.6175096669097577
Validation loss: 2.7649509727191557

Epoch: 6| Step: 5
Training loss: 2.6167177604335845
Validation loss: 2.761441304632409

Epoch: 6| Step: 6
Training loss: 3.6094429042753444
Validation loss: 2.7607548471510204

Epoch: 6| Step: 7
Training loss: 1.8916200903761562
Validation loss: 2.7620872384818353

Epoch: 6| Step: 8
Training loss: 3.3650368462595726
Validation loss: 2.7587255940354236

Epoch: 6| Step: 9
Training loss: 3.3787250448159876
Validation loss: 2.7599437702485523

Epoch: 6| Step: 10
Training loss: 2.4178139385896062
Validation loss: 2.7573010737547285

Epoch: 6| Step: 11
Training loss: 3.1459819598593146
Validation loss: 2.757818893726858

Epoch: 6| Step: 12
Training loss: 3.7433936100695675
Validation loss: 2.7540579935631437

Epoch: 6| Step: 13
Training loss: 3.1725013753348423
Validation loss: 2.754220034653598

Epoch: 33| Step: 0
Training loss: 2.6190054429774405
Validation loss: 2.7532827057290965

Epoch: 6| Step: 1
Training loss: 2.8645249979263783
Validation loss: 2.753325155229596

Epoch: 6| Step: 2
Training loss: 2.796521553424377
Validation loss: 2.751768567078131

Epoch: 6| Step: 3
Training loss: 2.831461082151971
Validation loss: 2.7578297587524014

Epoch: 6| Step: 4
Training loss: 3.549800926321941
Validation loss: 2.778412362560621

Epoch: 6| Step: 5
Training loss: 3.1645245250053526
Validation loss: 2.796012778054492

Epoch: 6| Step: 6
Training loss: 2.984749176375466
Validation loss: 2.8301581163078917

Epoch: 6| Step: 7
Training loss: 2.986840472982674
Validation loss: 2.7932225646770426

Epoch: 6| Step: 8
Training loss: 3.0547596174151623
Validation loss: 2.764004410906537

Epoch: 6| Step: 9
Training loss: 3.5963214464883655
Validation loss: 2.7524353982085827

Epoch: 6| Step: 10
Training loss: 3.0418384102885283
Validation loss: 2.755023370329561

Epoch: 6| Step: 11
Training loss: 3.299982856937154
Validation loss: 2.766685318269312

Epoch: 6| Step: 12
Training loss: 2.87940492283662
Validation loss: 2.786323069495218

Epoch: 6| Step: 13
Training loss: 3.6319726116643394
Validation loss: 2.7944906831171212

Epoch: 34| Step: 0
Training loss: 2.9386672277894266
Validation loss: 2.7951804998699994

Epoch: 6| Step: 1
Training loss: 3.236551483126707
Validation loss: 2.78479546024838

Epoch: 6| Step: 2
Training loss: 3.0834389917639324
Validation loss: 2.7708410749775236

Epoch: 6| Step: 3
Training loss: 3.446370557046861
Validation loss: 2.762838312251425

Epoch: 6| Step: 4
Training loss: 3.00149276469698
Validation loss: 2.7604036445024165

Epoch: 6| Step: 5
Training loss: 3.2619201963428797
Validation loss: 2.7545447536843204

Epoch: 6| Step: 6
Training loss: 2.836696890891492
Validation loss: 2.750477788480516

Epoch: 6| Step: 7
Training loss: 3.135874025227992
Validation loss: 2.7496732012344576

Epoch: 6| Step: 8
Training loss: 2.691584654543803
Validation loss: 2.7441320618941174

Epoch: 6| Step: 9
Training loss: 2.7507389116265695
Validation loss: 2.7442466012665068

Epoch: 6| Step: 10
Training loss: 2.4237536619492204
Validation loss: 2.7500765632270654

Epoch: 6| Step: 11
Training loss: 3.7885949544416597
Validation loss: 2.768290930278631

Epoch: 6| Step: 12
Training loss: 3.179707145161595
Validation loss: 2.7636856584891163

Epoch: 6| Step: 13
Training loss: 3.5908767492420384
Validation loss: 2.7460548557879814

Epoch: 35| Step: 0
Training loss: 3.201339298359775
Validation loss: 2.745366458812065

Epoch: 6| Step: 1
Training loss: 3.4741722548169856
Validation loss: 2.741201480519339

Epoch: 6| Step: 2
Training loss: 3.3092693193111944
Validation loss: 2.738078276919829

Epoch: 6| Step: 3
Training loss: 3.069287777024324
Validation loss: 2.736204643754488

Epoch: 6| Step: 4
Training loss: 2.85216308957794
Validation loss: 2.736703783054146

Epoch: 6| Step: 5
Training loss: 3.177944145945768
Validation loss: 2.7333341346647506

Epoch: 6| Step: 6
Training loss: 2.5179678864555997
Validation loss: 2.73615866244046

Epoch: 6| Step: 7
Training loss: 2.750994849152702
Validation loss: 2.7326554636863403

Epoch: 6| Step: 8
Training loss: 3.339912565537393
Validation loss: 2.7329103546502194

Epoch: 6| Step: 9
Training loss: 3.3614665772618992
Validation loss: 2.732789664620237

Epoch: 6| Step: 10
Training loss: 2.8370693669839326
Validation loss: 2.731475830728881

Epoch: 6| Step: 11
Training loss: 3.2605627512679547
Validation loss: 2.731557701542448

Epoch: 6| Step: 12
Training loss: 2.6252135235365017
Validation loss: 2.7334064471112773

Epoch: 6| Step: 13
Training loss: 3.008594599515428
Validation loss: 2.7380459830839112

Epoch: 36| Step: 0
Training loss: 3.7779339839080803
Validation loss: 2.7476178208114925

Epoch: 6| Step: 1
Training loss: 3.1146612423409734
Validation loss: 2.7439110542640326

Epoch: 6| Step: 2
Training loss: 2.966429918107861
Validation loss: 2.7317618132136285

Epoch: 6| Step: 3
Training loss: 2.974171877452347
Validation loss: 2.7374493545040584

Epoch: 6| Step: 4
Training loss: 3.468761547172503
Validation loss: 2.7376301159374066

Epoch: 6| Step: 5
Training loss: 2.843358777980687
Validation loss: 2.741454760528513

Epoch: 6| Step: 6
Training loss: 3.046876252002948
Validation loss: 2.7287797065651

Epoch: 6| Step: 7
Training loss: 3.2683946463750555
Validation loss: 2.7304784544665024

Epoch: 6| Step: 8
Training loss: 2.863560016379476
Validation loss: 2.726411985899562

Epoch: 6| Step: 9
Training loss: 2.838165164907761
Validation loss: 2.722496998960033

Epoch: 6| Step: 10
Training loss: 2.717691675917105
Validation loss: 2.7195184272570594

Epoch: 6| Step: 11
Training loss: 2.8729240552010986
Validation loss: 2.718913891729482

Epoch: 6| Step: 12
Training loss: 2.932671006884192
Validation loss: 2.718481565204891

Epoch: 6| Step: 13
Training loss: 3.021133530707269
Validation loss: 2.718511975290523

Epoch: 37| Step: 0
Training loss: 2.861600083065485
Validation loss: 2.7164545945642247

Epoch: 6| Step: 1
Training loss: 2.421514668885154
Validation loss: 2.7170441409860886

Epoch: 6| Step: 2
Training loss: 3.8331549782655987
Validation loss: 2.7165090330094475

Epoch: 6| Step: 3
Training loss: 2.926950055727488
Validation loss: 2.714722022574154

Epoch: 6| Step: 4
Training loss: 2.5642654106195506
Validation loss: 2.718751309754845

Epoch: 6| Step: 5
Training loss: 3.757661241433439
Validation loss: 2.7378521661870736

Epoch: 6| Step: 6
Training loss: 2.60150091424853
Validation loss: 2.746883584196386

Epoch: 6| Step: 7
Training loss: 3.607720991042204
Validation loss: 2.7675946457239693

Epoch: 6| Step: 8
Training loss: 3.0073882361087914
Validation loss: 2.716002883447407

Epoch: 6| Step: 9
Training loss: 2.711720554150086
Validation loss: 2.714029936424177

Epoch: 6| Step: 10
Training loss: 3.2542567619586973
Validation loss: 2.7175313471750173

Epoch: 6| Step: 11
Training loss: 2.875213780955052
Validation loss: 2.716629573892913

Epoch: 6| Step: 12
Training loss: 2.7380090597266147
Validation loss: 2.7232350182570784

Epoch: 6| Step: 13
Training loss: 3.4093528404180033
Validation loss: 2.7268493089667665

Epoch: 38| Step: 0
Training loss: 3.155793714117647
Validation loss: 2.7322794873561875

Epoch: 6| Step: 1
Training loss: 3.1967546337807398
Validation loss: 2.7365279902356647

Epoch: 6| Step: 2
Training loss: 3.361919911771258
Validation loss: 2.7334981976913166

Epoch: 6| Step: 3
Training loss: 3.0477343790052807
Validation loss: 2.728905582096451

Epoch: 6| Step: 4
Training loss: 2.5487551623895963
Validation loss: 2.724391446289186

Epoch: 6| Step: 5
Training loss: 2.727597802468995
Validation loss: 2.7235559210060134

Epoch: 6| Step: 6
Training loss: 3.473929859294422
Validation loss: 2.720539193112654

Epoch: 6| Step: 7
Training loss: 3.3938573381229156
Validation loss: 2.7197827565392645

Epoch: 6| Step: 8
Training loss: 2.446749816264653
Validation loss: 2.7160622013788314

Epoch: 6| Step: 9
Training loss: 3.2303760519877343
Validation loss: 2.71163978805465

Epoch: 6| Step: 10
Training loss: 3.4648079682129276
Validation loss: 2.709604394471237

Epoch: 6| Step: 11
Training loss: 3.2655906857964676
Validation loss: 2.708162695823459

Epoch: 6| Step: 12
Training loss: 2.5482335124186473
Validation loss: 2.7071997100855523

Epoch: 6| Step: 13
Training loss: 2.472742256970827
Validation loss: 2.7079212440001004

Epoch: 39| Step: 0
Training loss: 2.9243481618877114
Validation loss: 2.706611760727898

Epoch: 6| Step: 1
Training loss: 2.741121177168635
Validation loss: 2.7181577111591704

Epoch: 6| Step: 2
Training loss: 2.567604098935116
Validation loss: 2.7402087668622426

Epoch: 6| Step: 3
Training loss: 2.889875490086998
Validation loss: 2.763354441490657

Epoch: 6| Step: 4
Training loss: 2.987750955040956
Validation loss: 2.7581839660029965

Epoch: 6| Step: 5
Training loss: 2.9953946686858153
Validation loss: 2.7208745272418375

Epoch: 6| Step: 6
Training loss: 3.283595817904714
Validation loss: 2.712224567973492

Epoch: 6| Step: 7
Training loss: 3.3995154764838937
Validation loss: 2.7029193641337037

Epoch: 6| Step: 8
Training loss: 3.347598988990298
Validation loss: 2.694035330905769

Epoch: 6| Step: 9
Training loss: 2.997694082968353
Validation loss: 2.6886964954772297

Epoch: 6| Step: 10
Training loss: 3.057399784669702
Validation loss: 2.6869753072369393

Epoch: 6| Step: 11
Training loss: 2.9902257638878296
Validation loss: 2.68422340884628

Epoch: 6| Step: 12
Training loss: 3.0986915965114257
Validation loss: 2.6852867550283466

Epoch: 6| Step: 13
Training loss: 3.4324650737544213
Validation loss: 2.6861487833921336

Epoch: 40| Step: 0
Training loss: 2.97675857498883
Validation loss: 2.6852308033546204

Epoch: 6| Step: 1
Training loss: 3.357872205427991
Validation loss: 2.6857574548579795

Epoch: 6| Step: 2
Training loss: 2.31735194748725
Validation loss: 2.71194449707323

Epoch: 6| Step: 3
Training loss: 3.562306449049334
Validation loss: 2.70320321237308

Epoch: 6| Step: 4
Training loss: 2.856836077705182
Validation loss: 2.6783632940790074

Epoch: 6| Step: 5
Training loss: 2.924674095842908
Validation loss: 2.68155287641539

Epoch: 6| Step: 6
Training loss: 3.1709474607389967
Validation loss: 2.6796593242603692

Epoch: 6| Step: 7
Training loss: 3.3338868317416464
Validation loss: 2.6851694371405177

Epoch: 6| Step: 8
Training loss: 2.952171373546363
Validation loss: 2.683498627051698

Epoch: 6| Step: 9
Training loss: 3.104337512612299
Validation loss: 2.685652868601129

Epoch: 6| Step: 10
Training loss: 2.8481125119412454
Validation loss: 2.6935205272251603

Epoch: 6| Step: 11
Training loss: 2.5332218543002205
Validation loss: 2.703657578760093

Epoch: 6| Step: 12
Training loss: 3.087542384547845
Validation loss: 2.701952636704284

Epoch: 6| Step: 13
Training loss: 3.347219645673746
Validation loss: 2.6962304172632603

Epoch: 41| Step: 0
Training loss: 2.2456090254816634
Validation loss: 2.686000513448631

Epoch: 6| Step: 1
Training loss: 3.866073910452192
Validation loss: 2.679742522727001

Epoch: 6| Step: 2
Training loss: 2.5903695379736305
Validation loss: 2.6769841439403406

Epoch: 6| Step: 3
Training loss: 3.0108986614990707
Validation loss: 2.67686702626401

Epoch: 6| Step: 4
Training loss: 3.4706316818758274
Validation loss: 2.6755948814912944

Epoch: 6| Step: 5
Training loss: 3.149217684042241
Validation loss: 2.672096513355841

Epoch: 6| Step: 6
Training loss: 2.660358886170954
Validation loss: 2.676933172959241

Epoch: 6| Step: 7
Training loss: 3.25145072836561
Validation loss: 2.6806142364437267

Epoch: 6| Step: 8
Training loss: 2.2867215525691744
Validation loss: 2.6883373210509105

Epoch: 6| Step: 9
Training loss: 2.819106924799872
Validation loss: 2.7174992318016495

Epoch: 6| Step: 10
Training loss: 2.828433699646916
Validation loss: 2.7610634533418668

Epoch: 6| Step: 11
Training loss: 3.109054625602134
Validation loss: 2.7653943500913933

Epoch: 6| Step: 12
Training loss: 3.175225653852157
Validation loss: 2.6996564299383063

Epoch: 6| Step: 13
Training loss: 3.862133445753476
Validation loss: 2.677871998433441

Epoch: 42| Step: 0
Training loss: 3.135116681082844
Validation loss: 2.6677023446044275

Epoch: 6| Step: 1
Training loss: 2.600085964982518
Validation loss: 2.666866267781439

Epoch: 6| Step: 2
Training loss: 3.0489820188578283
Validation loss: 2.6704757750438826

Epoch: 6| Step: 3
Training loss: 2.874578030344465
Validation loss: 2.6963594989927153

Epoch: 6| Step: 4
Training loss: 3.4292439584530747
Validation loss: 2.731191894599503

Epoch: 6| Step: 5
Training loss: 3.10942223287775
Validation loss: 2.727249305821229

Epoch: 6| Step: 6
Training loss: 3.495355112483669
Validation loss: 2.7050914251867484

Epoch: 6| Step: 7
Training loss: 2.4415225558234113
Validation loss: 2.673578248720742

Epoch: 6| Step: 8
Training loss: 3.3899583292962814
Validation loss: 2.66507077788084

Epoch: 6| Step: 9
Training loss: 2.76233006986058
Validation loss: 2.665043541346459

Epoch: 6| Step: 10
Training loss: 2.888087793278551
Validation loss: 2.671714169077126

Epoch: 6| Step: 11
Training loss: 3.1751839051338266
Validation loss: 2.6718250656906966

Epoch: 6| Step: 12
Training loss: 2.792471632032158
Validation loss: 2.676546710881962

Epoch: 6| Step: 13
Training loss: 3.039029864059983
Validation loss: 2.690371463406837

Epoch: 43| Step: 0
Training loss: 2.918333794205079
Validation loss: 2.706400873953391

Epoch: 6| Step: 1
Training loss: 2.945724660837435
Validation loss: 2.7103233974052494

Epoch: 6| Step: 2
Training loss: 2.2025393526023462
Validation loss: 2.7296353667008666

Epoch: 6| Step: 3
Training loss: 3.582090354440134
Validation loss: 2.7382810262428032

Epoch: 6| Step: 4
Training loss: 3.209128954109511
Validation loss: 2.6623752278786

Epoch: 6| Step: 5
Training loss: 3.680611852699153
Validation loss: 2.663357155431881

Epoch: 6| Step: 6
Training loss: 3.1379796364429247
Validation loss: 2.670188138640509

Epoch: 6| Step: 7
Training loss: 2.6525289164700845
Validation loss: 2.67750651661471

Epoch: 6| Step: 8
Training loss: 3.0920464034848685
Validation loss: 2.6890263154535345

Epoch: 6| Step: 9
Training loss: 3.2580481428004813
Validation loss: 2.699731876933616

Epoch: 6| Step: 10
Training loss: 2.683691653224603
Validation loss: 2.698317552427261

Epoch: 6| Step: 11
Training loss: 3.0119964432005126
Validation loss: 2.698954286508682

Epoch: 6| Step: 12
Training loss: 3.032288992664482
Validation loss: 2.6989184421870824

Epoch: 6| Step: 13
Training loss: 2.9294042831855256
Validation loss: 2.6857203586362406

Epoch: 44| Step: 0
Training loss: 3.2078828041187752
Validation loss: 2.6784724643940168

Epoch: 6| Step: 1
Training loss: 2.7870191253400085
Validation loss: 2.6752646791689876

Epoch: 6| Step: 2
Training loss: 3.034500267201021
Validation loss: 2.6713831751786934

Epoch: 6| Step: 3
Training loss: 3.1380616920101057
Validation loss: 2.667571381242772

Epoch: 6| Step: 4
Training loss: 2.7696643361557634
Validation loss: 2.6632127511777517

Epoch: 6| Step: 5
Training loss: 2.5419104933388668
Validation loss: 2.6623393648364906

Epoch: 6| Step: 6
Training loss: 2.842128752635534
Validation loss: 2.6605593735608912

Epoch: 6| Step: 7
Training loss: 3.0956787878578056
Validation loss: 2.658049237671764

Epoch: 6| Step: 8
Training loss: 2.9544685980664016
Validation loss: 2.662249876524533

Epoch: 6| Step: 9
Training loss: 3.0225677422062165
Validation loss: 2.6744469142254808

Epoch: 6| Step: 10
Training loss: 2.822372487298898
Validation loss: 2.7125438930853463

Epoch: 6| Step: 11
Training loss: 3.434898362967384
Validation loss: 2.7320140869249365

Epoch: 6| Step: 12
Training loss: 3.287185387007354
Validation loss: 2.73399581084782

Epoch: 6| Step: 13
Training loss: 3.3925747517254385
Validation loss: 2.672877126353998

Epoch: 45| Step: 0
Training loss: 2.8835140708181823
Validation loss: 2.6539550335116813

Epoch: 6| Step: 1
Training loss: 3.2958655959011915
Validation loss: 2.652662539905611

Epoch: 6| Step: 2
Training loss: 3.290642365702338
Validation loss: 2.6584125100682705

Epoch: 6| Step: 3
Training loss: 2.9189023486613093
Validation loss: 2.662569868222592

Epoch: 6| Step: 4
Training loss: 2.379326042631563
Validation loss: 2.668208213767232

Epoch: 6| Step: 5
Training loss: 2.7473624325329484
Validation loss: 2.6822515436682632

Epoch: 6| Step: 6
Training loss: 2.7656837069212625
Validation loss: 2.7030410388428514

Epoch: 6| Step: 7
Training loss: 3.4913568042080074
Validation loss: 2.674403300919091

Epoch: 6| Step: 8
Training loss: 2.510953463282282
Validation loss: 2.667305889604694

Epoch: 6| Step: 9
Training loss: 2.9430274092719686
Validation loss: 2.661783895902247

Epoch: 6| Step: 10
Training loss: 3.361145546546713
Validation loss: 2.6601070922147083

Epoch: 6| Step: 11
Training loss: 2.8396380532343315
Validation loss: 2.662534192670813

Epoch: 6| Step: 12
Training loss: 3.58845514747767
Validation loss: 2.6605900323195613

Epoch: 6| Step: 13
Training loss: 2.9174369521466916
Validation loss: 2.6633291678949425

Epoch: 46| Step: 0
Training loss: 2.98252883449535
Validation loss: 2.658403035310672

Epoch: 6| Step: 1
Training loss: 2.715314426375338
Validation loss: 2.657856654503893

Epoch: 6| Step: 2
Training loss: 3.7082638394705683
Validation loss: 2.653534709628427

Epoch: 6| Step: 3
Training loss: 3.032098710317876
Validation loss: 2.648578755826734

Epoch: 6| Step: 4
Training loss: 3.0401138801325853
Validation loss: 2.6448230095032956

Epoch: 6| Step: 5
Training loss: 3.089477363015776
Validation loss: 2.6450306158617947

Epoch: 6| Step: 6
Training loss: 3.0268325866336454
Validation loss: 2.643613584869002

Epoch: 6| Step: 7
Training loss: 2.966896201122868
Validation loss: 2.6434876929841113

Epoch: 6| Step: 8
Training loss: 3.4352476196769417
Validation loss: 2.6453169968950245

Epoch: 6| Step: 9
Training loss: 2.8807362261814227
Validation loss: 2.643355529923278

Epoch: 6| Step: 10
Training loss: 2.5659288865282712
Validation loss: 2.6406889012917705

Epoch: 6| Step: 11
Training loss: 3.186463430566235
Validation loss: 2.6420922263399627

Epoch: 6| Step: 12
Training loss: 1.9492465152941725
Validation loss: 2.643787532654303

Epoch: 6| Step: 13
Training loss: 3.1797980212000008
Validation loss: 2.64238400095631

Epoch: 47| Step: 0
Training loss: 2.7402173216459738
Validation loss: 2.6441266765911964

Epoch: 6| Step: 1
Training loss: 2.563030560159834
Validation loss: 2.646226220242124

Epoch: 6| Step: 2
Training loss: 2.8273746064002543
Validation loss: 2.6459592544270465

Epoch: 6| Step: 3
Training loss: 2.6308401626757663
Validation loss: 2.6527884660527805

Epoch: 6| Step: 4
Training loss: 3.048937290346239
Validation loss: 2.6582228435841553

Epoch: 6| Step: 5
Training loss: 3.2426435402633182
Validation loss: 2.659134445145095

Epoch: 6| Step: 6
Training loss: 2.817508899637432
Validation loss: 2.6492175507910862

Epoch: 6| Step: 7
Training loss: 3.152434204770224
Validation loss: 2.6382297346948875

Epoch: 6| Step: 8
Training loss: 2.9930912575260558
Validation loss: 2.6380291882477107

Epoch: 6| Step: 9
Training loss: 3.102079026573852
Validation loss: 2.63457368884262

Epoch: 6| Step: 10
Training loss: 3.3108347899783164
Validation loss: 2.633961761161415

Epoch: 6| Step: 11
Training loss: 3.6620817707292956
Validation loss: 2.6330522459902848

Epoch: 6| Step: 12
Training loss: 2.4494155731695364
Validation loss: 2.6322892781210956

Epoch: 6| Step: 13
Training loss: 3.2093604454297378
Validation loss: 2.6314723650943215

Epoch: 48| Step: 0
Training loss: 2.700611952909291
Validation loss: 2.633112074413337

Epoch: 6| Step: 1
Training loss: 2.8622720352752036
Validation loss: 2.6340085824183195

Epoch: 6| Step: 2
Training loss: 3.3787205286748225
Validation loss: 2.633781499435584

Epoch: 6| Step: 3
Training loss: 3.473978312300043
Validation loss: 2.6332059809444717

Epoch: 6| Step: 4
Training loss: 2.8179825645216035
Validation loss: 2.6302766976030396

Epoch: 6| Step: 5
Training loss: 2.734580070435147
Validation loss: 2.630306384779877

Epoch: 6| Step: 6
Training loss: 3.1947313447093113
Validation loss: 2.6346013415735157

Epoch: 6| Step: 7
Training loss: 2.1413827933105685
Validation loss: 2.6305511871703686

Epoch: 6| Step: 8
Training loss: 3.0666404294536345
Validation loss: 2.6287554906258466

Epoch: 6| Step: 9
Training loss: 2.7379456666803756
Validation loss: 2.6300307837842065

Epoch: 6| Step: 10
Training loss: 3.293819801705673
Validation loss: 2.6344360562861806

Epoch: 6| Step: 11
Training loss: 2.869400376207882
Validation loss: 2.6305838226817633

Epoch: 6| Step: 12
Training loss: 3.322133433354421
Validation loss: 2.628995627064959

Epoch: 6| Step: 13
Training loss: 2.7899507876468816
Validation loss: 2.633507228772732

Epoch: 49| Step: 0
Training loss: 3.0487421037071982
Validation loss: 2.6356130249019385

Epoch: 6| Step: 1
Training loss: 2.956395835585946
Validation loss: 2.6382255684095335

Epoch: 6| Step: 2
Training loss: 3.407889155488152
Validation loss: 2.642790051767688

Epoch: 6| Step: 3
Training loss: 2.912095293078796
Validation loss: 2.644347863829124

Epoch: 6| Step: 4
Training loss: 2.867465554041283
Validation loss: 2.6565582029028274

Epoch: 6| Step: 5
Training loss: 3.32064164269339
Validation loss: 2.6375912377457684

Epoch: 6| Step: 6
Training loss: 2.6934854258030936
Validation loss: 2.6279218051553928

Epoch: 6| Step: 7
Training loss: 2.889672529681588
Validation loss: 2.6233546876977014

Epoch: 6| Step: 8
Training loss: 2.450527297905649
Validation loss: 2.624545138513309

Epoch: 6| Step: 9
Training loss: 2.730136572806708
Validation loss: 2.6231241110752404

Epoch: 6| Step: 10
Training loss: 3.438123889140005
Validation loss: 2.620470030156896

Epoch: 6| Step: 11
Training loss: 2.8880884536976765
Validation loss: 2.620787335663896

Epoch: 6| Step: 12
Training loss: 2.7162611520242477
Validation loss: 2.619418330931937

Epoch: 6| Step: 13
Training loss: 3.4010602980722124
Validation loss: 2.620915512246088

Epoch: 50| Step: 0
Training loss: 2.4287291964407136
Validation loss: 2.6199138117646723

Epoch: 6| Step: 1
Training loss: 3.6748491943973023
Validation loss: 2.6212090259867153

Epoch: 6| Step: 2
Training loss: 2.9995876664673835
Validation loss: 2.6170952746555836

Epoch: 6| Step: 3
Training loss: 2.9646299986250493
Validation loss: 2.6199879180246373

Epoch: 6| Step: 4
Training loss: 2.713887041972623
Validation loss: 2.6248945370303836

Epoch: 6| Step: 5
Training loss: 3.049236614811233
Validation loss: 2.6305173266988677

Epoch: 6| Step: 6
Training loss: 2.8406365086959178
Validation loss: 2.6293748738599563

Epoch: 6| Step: 7
Training loss: 3.3108126103248483
Validation loss: 2.631643592837073

Epoch: 6| Step: 8
Training loss: 3.297583336691699
Validation loss: 2.634401940181848

Epoch: 6| Step: 9
Training loss: 2.525349840157903
Validation loss: 2.624403482916788

Epoch: 6| Step: 10
Training loss: 2.1856779957455825
Validation loss: 2.626042566731554

Epoch: 6| Step: 11
Training loss: 3.0200758587233945
Validation loss: 2.6224203291387003

Epoch: 6| Step: 12
Training loss: 3.2324528534202877
Validation loss: 2.624089616887223

Epoch: 6| Step: 13
Training loss: 3.159037199742654
Validation loss: 2.6198066243407037

Epoch: 51| Step: 0
Training loss: 2.470027062117246
Validation loss: 2.6150355810570796

Epoch: 6| Step: 1
Training loss: 3.2394899475440972
Validation loss: 2.615003510789674

Epoch: 6| Step: 2
Training loss: 3.1058063827367506
Validation loss: 2.617625137689626

Epoch: 6| Step: 3
Training loss: 3.1717099301836518
Validation loss: 2.615742556388553

Epoch: 6| Step: 4
Training loss: 3.0244932081184426
Validation loss: 2.618289300875186

Epoch: 6| Step: 5
Training loss: 2.511078890966047
Validation loss: 2.614572046916823

Epoch: 6| Step: 6
Training loss: 2.7957192702318228
Validation loss: 2.614269403615838

Epoch: 6| Step: 7
Training loss: 2.853130087372672
Validation loss: 2.6150486108082025

Epoch: 6| Step: 8
Training loss: 3.13006075205969
Validation loss: 2.6150665941305484

Epoch: 6| Step: 9
Training loss: 3.3188451778463786
Validation loss: 2.615667237028389

Epoch: 6| Step: 10
Training loss: 3.133817211962619
Validation loss: 2.6137366357703176

Epoch: 6| Step: 11
Training loss: 2.9751453780869186
Validation loss: 2.6132667104920317

Epoch: 6| Step: 12
Training loss: 2.7749311696357117
Validation loss: 2.6116535882452023

Epoch: 6| Step: 13
Training loss: 3.051743437466144
Validation loss: 2.6119396164313775

Epoch: 52| Step: 0
Training loss: 2.7474523360723215
Validation loss: 2.6163190404495795

Epoch: 6| Step: 1
Training loss: 3.0106523854897103
Validation loss: 2.6191567459485743

Epoch: 6| Step: 2
Training loss: 3.0388486340739296
Validation loss: 2.6160298602944594

Epoch: 6| Step: 3
Training loss: 2.903632349002929
Validation loss: 2.6152090662189487

Epoch: 6| Step: 4
Training loss: 2.5757986959619226
Validation loss: 2.6213239859017703

Epoch: 6| Step: 5
Training loss: 3.263054086688765
Validation loss: 2.623910460029508

Epoch: 6| Step: 6
Training loss: 3.249338082619088
Validation loss: 2.636817620724136

Epoch: 6| Step: 7
Training loss: 3.261138169932564
Validation loss: 2.639235449657162

Epoch: 6| Step: 8
Training loss: 3.351241516535094
Validation loss: 2.6151267516800676

Epoch: 6| Step: 9
Training loss: 2.3841707954606544
Validation loss: 2.6092334630576204

Epoch: 6| Step: 10
Training loss: 3.0461789632160388
Validation loss: 2.6087556442529167

Epoch: 6| Step: 11
Training loss: 2.44346651350087
Validation loss: 2.6067632669508667

Epoch: 6| Step: 12
Training loss: 3.2497438183099225
Validation loss: 2.605766117926946

Epoch: 6| Step: 13
Training loss: 2.7071262799822
Validation loss: 2.6072757404851394

Epoch: 53| Step: 0
Training loss: 2.744537563734776
Validation loss: 2.607964909670959

Epoch: 6| Step: 1
Training loss: 3.2761234016512075
Validation loss: 2.6083876842156832

Epoch: 6| Step: 2
Training loss: 2.4529589943084638
Validation loss: 2.6046756829376596

Epoch: 6| Step: 3
Training loss: 3.3817176368548334
Validation loss: 2.6062427516224727

Epoch: 6| Step: 4
Training loss: 3.5644955316398654
Validation loss: 2.606614195132395

Epoch: 6| Step: 5
Training loss: 2.449246395752067
Validation loss: 2.6067748613961466

Epoch: 6| Step: 6
Training loss: 2.849475504480564
Validation loss: 2.6069854214956316

Epoch: 6| Step: 7
Training loss: 2.7649616372618597
Validation loss: 2.6090531475211334

Epoch: 6| Step: 8
Training loss: 2.7484259869202616
Validation loss: 2.602768493056304

Epoch: 6| Step: 9
Training loss: 3.2480938530126426
Validation loss: 2.5992913744320134

Epoch: 6| Step: 10
Training loss: 2.857313069314285
Validation loss: 2.598819201623115

Epoch: 6| Step: 11
Training loss: 2.9658982885596488
Validation loss: 2.6011213614516406

Epoch: 6| Step: 12
Training loss: 3.0464394282510265
Validation loss: 2.6020694214032303

Epoch: 6| Step: 13
Training loss: 2.8398835443072397
Validation loss: 2.601627948537236

Epoch: 54| Step: 0
Training loss: 3.0700341794972332
Validation loss: 2.6035429724899646

Epoch: 6| Step: 1
Training loss: 2.9464161067550365
Validation loss: 2.6026375689571766

Epoch: 6| Step: 2
Training loss: 3.277173225413212
Validation loss: 2.600523692769597

Epoch: 6| Step: 3
Training loss: 2.3048112221822987
Validation loss: 2.600141852857908

Epoch: 6| Step: 4
Training loss: 2.6363924856012555
Validation loss: 2.6039233586670156

Epoch: 6| Step: 5
Training loss: 3.547976285053117
Validation loss: 2.6076887504738147

Epoch: 6| Step: 6
Training loss: 2.8789617359709836
Validation loss: 2.6097068759784894

Epoch: 6| Step: 7
Training loss: 3.3826224822137236
Validation loss: 2.6185106929408843

Epoch: 6| Step: 8
Training loss: 2.7452458989635824
Validation loss: 2.6049460293688487

Epoch: 6| Step: 9
Training loss: 2.5798049539575403
Validation loss: 2.597250767075104

Epoch: 6| Step: 10
Training loss: 2.7120664153335956
Validation loss: 2.595801262749678

Epoch: 6| Step: 11
Training loss: 3.226808404673068
Validation loss: 2.5944657952224284

Epoch: 6| Step: 12
Training loss: 3.1063245062076517
Validation loss: 2.593593998455479

Epoch: 6| Step: 13
Training loss: 2.651342368668369
Validation loss: 2.5967646096547656

Epoch: 55| Step: 0
Training loss: 2.8919813118696194
Validation loss: 2.5974562716095546

Epoch: 6| Step: 1
Training loss: 3.140291718216715
Validation loss: 2.597837388172476

Epoch: 6| Step: 2
Training loss: 2.881722758600154
Validation loss: 2.600456322144489

Epoch: 6| Step: 3
Training loss: 2.4722326316566723
Validation loss: 2.6020154429677675

Epoch: 6| Step: 4
Training loss: 2.7455033906281083
Validation loss: 2.597140862601345

Epoch: 6| Step: 5
Training loss: 3.066166765130657
Validation loss: 2.5949873697640284

Epoch: 6| Step: 6
Training loss: 3.570799412486491
Validation loss: 2.593817544812044

Epoch: 6| Step: 7
Training loss: 2.9852415095126204
Validation loss: 2.5964793396645818

Epoch: 6| Step: 8
Training loss: 3.314222355880599
Validation loss: 2.5976104354796736

Epoch: 6| Step: 9
Training loss: 2.7569672150930007
Validation loss: 2.598015123179824

Epoch: 6| Step: 10
Training loss: 3.059031488072578
Validation loss: 2.594042491074729

Epoch: 6| Step: 11
Training loss: 2.832349120092002
Validation loss: 2.593975158676002

Epoch: 6| Step: 12
Training loss: 2.725337674278689
Validation loss: 2.59225759554794

Epoch: 6| Step: 13
Training loss: 2.8970465188549643
Validation loss: 2.591915916810438

Epoch: 56| Step: 0
Training loss: 2.611312603672552
Validation loss: 2.58843489981938

Epoch: 6| Step: 1
Training loss: 3.4791116005809406
Validation loss: 2.587082034105268

Epoch: 6| Step: 2
Training loss: 3.0595640784527935
Validation loss: 2.588434743332835

Epoch: 6| Step: 3
Training loss: 2.1662903483353784
Validation loss: 2.587893226391597

Epoch: 6| Step: 4
Training loss: 3.142231544553941
Validation loss: 2.589029001126472

Epoch: 6| Step: 5
Training loss: 2.7327738406378796
Validation loss: 2.5952459262445955

Epoch: 6| Step: 6
Training loss: 2.960372508554337
Validation loss: 2.610588132156975

Epoch: 6| Step: 7
Training loss: 3.24160445152798
Validation loss: 2.630033536008854

Epoch: 6| Step: 8
Training loss: 3.1659556812068943
Validation loss: 2.6346492111139

Epoch: 6| Step: 9
Training loss: 2.90063853633248
Validation loss: 2.6153521382873883

Epoch: 6| Step: 10
Training loss: 3.2424569259288405
Validation loss: 2.5968422409306755

Epoch: 6| Step: 11
Training loss: 2.747757604322444
Validation loss: 2.587062356953549

Epoch: 6| Step: 12
Training loss: 2.5237305651101103
Validation loss: 2.5794857666335838

Epoch: 6| Step: 13
Training loss: 3.3433660839399915
Validation loss: 2.58226955838711

Epoch: 57| Step: 0
Training loss: 3.100055011138112
Validation loss: 2.5825807928815

Epoch: 6| Step: 1
Training loss: 3.257178668014116
Validation loss: 2.584053198924742

Epoch: 6| Step: 2
Training loss: 3.2742563466248464
Validation loss: 2.586745348579307

Epoch: 6| Step: 3
Training loss: 2.8025637265666745
Validation loss: 2.587680635730329

Epoch: 6| Step: 4
Training loss: 3.445728233668862
Validation loss: 2.587260218630589

Epoch: 6| Step: 5
Training loss: 2.738643605939627
Validation loss: 2.5921124338241177

Epoch: 6| Step: 6
Training loss: 3.0385336918421624
Validation loss: 2.587544519517911

Epoch: 6| Step: 7
Training loss: 2.6532772707966874
Validation loss: 2.588628694211077

Epoch: 6| Step: 8
Training loss: 2.7339929804289755
Validation loss: 2.5916515173296335

Epoch: 6| Step: 9
Training loss: 3.0868218422340736
Validation loss: 2.591933396956256

Epoch: 6| Step: 10
Training loss: 2.8619873120808412
Validation loss: 2.590025050506589

Epoch: 6| Step: 11
Training loss: 2.863940986515463
Validation loss: 2.587397651734757

Epoch: 6| Step: 12
Training loss: 2.405034935076917
Validation loss: 2.585280805390447

Epoch: 6| Step: 13
Training loss: 3.097988269613775
Validation loss: 2.582304868559428

Epoch: 58| Step: 0
Training loss: 2.6753109261038364
Validation loss: 2.5807853925966686

Epoch: 6| Step: 1
Training loss: 3.21984015216109
Validation loss: 2.581409333961193

Epoch: 6| Step: 2
Training loss: 3.2757088512860166
Validation loss: 2.5842799910980996

Epoch: 6| Step: 3
Training loss: 2.869054867038643
Validation loss: 2.5821452079746186

Epoch: 6| Step: 4
Training loss: 2.863710212580984
Validation loss: 2.5857893482459544

Epoch: 6| Step: 5
Training loss: 2.956773713964811
Validation loss: 2.6181998413077916

Epoch: 6| Step: 6
Training loss: 3.2426528045249245
Validation loss: 2.628131509417534

Epoch: 6| Step: 7
Training loss: 2.9192857336412126
Validation loss: 2.6432687391617207

Epoch: 6| Step: 8
Training loss: 3.153989378877994
Validation loss: 2.6356179068403383

Epoch: 6| Step: 9
Training loss: 1.913214920158996
Validation loss: 2.631819205531815

Epoch: 6| Step: 10
Training loss: 3.2884728272347674
Validation loss: 2.628072527486872

Epoch: 6| Step: 11
Training loss: 3.167045938633823
Validation loss: 2.6089356767159413

Epoch: 6| Step: 12
Training loss: 2.2218378635312903
Validation loss: 2.5851774636346465

Epoch: 6| Step: 13
Training loss: 3.232236145768771
Validation loss: 2.5778334959017943

Epoch: 59| Step: 0
Training loss: 3.1668741425926563
Validation loss: 2.570611285001958

Epoch: 6| Step: 1
Training loss: 3.4415594926331012
Validation loss: 2.571492395806915

Epoch: 6| Step: 2
Training loss: 2.937228575807979
Validation loss: 2.5757486468312756

Epoch: 6| Step: 3
Training loss: 2.6028996144479075
Validation loss: 2.572560125281909

Epoch: 6| Step: 4
Training loss: 2.58541200951447
Validation loss: 2.5723014133456057

Epoch: 6| Step: 5
Training loss: 3.2552444984970204
Validation loss: 2.571144316253153

Epoch: 6| Step: 6
Training loss: 2.829976524282617
Validation loss: 2.582105684950453

Epoch: 6| Step: 7
Training loss: 2.9349237061028575
Validation loss: 2.6029470633871097

Epoch: 6| Step: 8
Training loss: 3.1434532070933625
Validation loss: 2.6198000219812

Epoch: 6| Step: 9
Training loss: 3.3028287958671987
Validation loss: 2.5984669786699723

Epoch: 6| Step: 10
Training loss: 2.085250226929884
Validation loss: 2.5846211517817324

Epoch: 6| Step: 11
Training loss: 2.932451333034817
Validation loss: 2.583387865198203

Epoch: 6| Step: 12
Training loss: 2.942294975663711
Validation loss: 2.581523539851639

Epoch: 6| Step: 13
Training loss: 2.956517445763595
Validation loss: 2.5768547242475885

Epoch: 60| Step: 0
Training loss: 2.6068703514611906
Validation loss: 2.5765366848297173

Epoch: 6| Step: 1
Training loss: 3.308451643845363
Validation loss: 2.5747229549630997

Epoch: 6| Step: 2
Training loss: 3.431510840335328
Validation loss: 2.5764390132926622

Epoch: 6| Step: 3
Training loss: 2.827603286758954
Validation loss: 2.5761612489189423

Epoch: 6| Step: 4
Training loss: 3.14815942184657
Validation loss: 2.5786517338834747

Epoch: 6| Step: 5
Training loss: 2.462945028455934
Validation loss: 2.5758415035894364

Epoch: 6| Step: 6
Training loss: 2.855842785010287
Validation loss: 2.5756335607965712

Epoch: 6| Step: 7
Training loss: 3.2529673601372275
Validation loss: 2.580005670537915

Epoch: 6| Step: 8
Training loss: 2.7974505125412295
Validation loss: 2.579861492843959

Epoch: 6| Step: 9
Training loss: 2.656218405142979
Validation loss: 2.584596568847546

Epoch: 6| Step: 10
Training loss: 3.187584071827098
Validation loss: 2.5797155421594042

Epoch: 6| Step: 11
Training loss: 3.02394986801373
Validation loss: 2.576704381768

Epoch: 6| Step: 12
Training loss: 2.487139237663307
Validation loss: 2.58013166614706

Epoch: 6| Step: 13
Training loss: 3.0949268607277935
Validation loss: 2.575316911552678

Epoch: 61| Step: 0
Training loss: 2.8846380144845516
Validation loss: 2.5751906345797546

Epoch: 6| Step: 1
Training loss: 3.0502244585335885
Validation loss: 2.5736545997284033

Epoch: 6| Step: 2
Training loss: 3.0333139530722555
Validation loss: 2.5723761348242005

Epoch: 6| Step: 3
Training loss: 2.4131495653792654
Validation loss: 2.570531288268405

Epoch: 6| Step: 4
Training loss: 2.8182683495132546
Validation loss: 2.57434688508578

Epoch: 6| Step: 5
Training loss: 2.8825511452073713
Validation loss: 2.5691550878907723

Epoch: 6| Step: 6
Training loss: 3.0963233494916085
Validation loss: 2.576326822922069

Epoch: 6| Step: 7
Training loss: 3.3877768090244187
Validation loss: 2.5757020733735168

Epoch: 6| Step: 8
Training loss: 3.1042554872508403
Validation loss: 2.5710494740982637

Epoch: 6| Step: 9
Training loss: 3.0088022164289714
Validation loss: 2.567868003347845

Epoch: 6| Step: 10
Training loss: 3.1309772547794545
Validation loss: 2.5663845533142253

Epoch: 6| Step: 11
Training loss: 2.6392288580182544
Validation loss: 2.568089775060474

Epoch: 6| Step: 12
Training loss: 2.9384601728211086
Validation loss: 2.566971732599922

Epoch: 6| Step: 13
Training loss: 2.4218916369451247
Validation loss: 2.5653750490475216

Epoch: 62| Step: 0
Training loss: 2.776959399362329
Validation loss: 2.5652388715606778

Epoch: 6| Step: 1
Training loss: 3.0057670474977334
Validation loss: 2.568585506799528

Epoch: 6| Step: 2
Training loss: 2.7444391380118045
Validation loss: 2.5673286509880793

Epoch: 6| Step: 3
Training loss: 2.3226620886736025
Validation loss: 2.57084775711789

Epoch: 6| Step: 4
Training loss: 3.1623023894921705
Validation loss: 2.5665782127219483

Epoch: 6| Step: 5
Training loss: 2.918018427455308
Validation loss: 2.5688559987918556

Epoch: 6| Step: 6
Training loss: 3.286306789831791
Validation loss: 2.5729657927761087

Epoch: 6| Step: 7
Training loss: 3.718266303397124
Validation loss: 2.5764109621778424

Epoch: 6| Step: 8
Training loss: 2.927795287370853
Validation loss: 2.580112929604415

Epoch: 6| Step: 9
Training loss: 2.7334410025937355
Validation loss: 2.5849583291904605

Epoch: 6| Step: 10
Training loss: 2.995084868742734
Validation loss: 2.590314627391545

Epoch: 6| Step: 11
Training loss: 2.657786743828667
Validation loss: 2.5774323508417183

Epoch: 6| Step: 12
Training loss: 2.4540289895817784
Validation loss: 2.5741289011605177

Epoch: 6| Step: 13
Training loss: 3.144836335161366
Validation loss: 2.570450509117085

Epoch: 63| Step: 0
Training loss: 3.2140418126651014
Validation loss: 2.56660550530315

Epoch: 6| Step: 1
Training loss: 2.783018000285102
Validation loss: 2.5659069789888695

Epoch: 6| Step: 2
Training loss: 2.5949242013728187
Validation loss: 2.5627609668288374

Epoch: 6| Step: 3
Training loss: 3.056677128875477
Validation loss: 2.5646452669044435

Epoch: 6| Step: 4
Training loss: 2.6011464012446526
Validation loss: 2.5640792382309674

Epoch: 6| Step: 5
Training loss: 2.5017186932763016
Validation loss: 2.564912000501595

Epoch: 6| Step: 6
Training loss: 2.451383130214172
Validation loss: 2.561050545844561

Epoch: 6| Step: 7
Training loss: 3.4318596081240047
Validation loss: 2.561288873052617

Epoch: 6| Step: 8
Training loss: 2.8912626645692754
Validation loss: 2.5657641222986456

Epoch: 6| Step: 9
Training loss: 2.926504944552584
Validation loss: 2.5630987624828774

Epoch: 6| Step: 10
Training loss: 3.381765860025092
Validation loss: 2.561767253262627

Epoch: 6| Step: 11
Training loss: 2.482761074755541
Validation loss: 2.562203997211551

Epoch: 6| Step: 12
Training loss: 3.2711120940232297
Validation loss: 2.56169784760488

Epoch: 6| Step: 13
Training loss: 3.1649009064744402
Validation loss: 2.5623875414974706

Epoch: 64| Step: 0
Training loss: 3.259607054074564
Validation loss: 2.5682951653826844

Epoch: 6| Step: 1
Training loss: 2.8570452094421586
Validation loss: 2.5612017586578935

Epoch: 6| Step: 2
Training loss: 2.5447117330078206
Validation loss: 2.5572503774128497

Epoch: 6| Step: 3
Training loss: 2.8389745166437024
Validation loss: 2.559771177546808

Epoch: 6| Step: 4
Training loss: 2.8265654758418726
Validation loss: 2.560258811185033

Epoch: 6| Step: 5
Training loss: 2.5714299981552284
Validation loss: 2.565659087148511

Epoch: 6| Step: 6
Training loss: 3.2409386125334065
Validation loss: 2.565551065921942

Epoch: 6| Step: 7
Training loss: 3.0971944111106176
Validation loss: 2.566967541042845

Epoch: 6| Step: 8
Training loss: 2.614613648095755
Validation loss: 2.5699221581462406

Epoch: 6| Step: 9
Training loss: 2.8242580891213334
Validation loss: 2.5705697356397677

Epoch: 6| Step: 10
Training loss: 3.0858299526354385
Validation loss: 2.572249762318568

Epoch: 6| Step: 11
Training loss: 3.0754131628834074
Validation loss: 2.574552770999803

Epoch: 6| Step: 12
Training loss: 3.406630748502195
Validation loss: 2.5672254533695713

Epoch: 6| Step: 13
Training loss: 2.835549067858878
Validation loss: 2.5693665887229886

Epoch: 65| Step: 0
Training loss: 3.3760049524677704
Validation loss: 2.5651964016856503

Epoch: 6| Step: 1
Training loss: 2.562932326900999
Validation loss: 2.5718715873989377

Epoch: 6| Step: 2
Training loss: 2.8037898505308743
Validation loss: 2.5746601656251578

Epoch: 6| Step: 3
Training loss: 3.634407202068753
Validation loss: 2.5822492637793544

Epoch: 6| Step: 4
Training loss: 3.1344685351334602
Validation loss: 2.5769795547790357

Epoch: 6| Step: 5
Training loss: 2.1713253945024076
Validation loss: 2.589107442106052

Epoch: 6| Step: 6
Training loss: 2.952556091085875
Validation loss: 2.5963148138624095

Epoch: 6| Step: 7
Training loss: 2.5013746297080277
Validation loss: 2.6201908438064185

Epoch: 6| Step: 8
Training loss: 3.1350966044117587
Validation loss: 2.646250766390533

Epoch: 6| Step: 9
Training loss: 3.004689524982661
Validation loss: 2.6443645872949473

Epoch: 6| Step: 10
Training loss: 2.6076059340759254
Validation loss: 2.634632208988087

Epoch: 6| Step: 11
Training loss: 3.2663515003782795
Validation loss: 2.609587950205691

Epoch: 6| Step: 12
Training loss: 2.467141508672723
Validation loss: 2.5902887905863663

Epoch: 6| Step: 13
Training loss: 3.0277329323934605
Validation loss: 2.573734797210633

Epoch: 66| Step: 0
Training loss: 3.002689745241216
Validation loss: 2.556972857632183

Epoch: 6| Step: 1
Training loss: 2.4142420433460816
Validation loss: 2.554667464450517

Epoch: 6| Step: 2
Training loss: 2.6004080745598066
Validation loss: 2.5465511506427716

Epoch: 6| Step: 3
Training loss: 3.320756806210176
Validation loss: 2.5486169149447413

Epoch: 6| Step: 4
Training loss: 3.1252194136839404
Validation loss: 2.548549829928229

Epoch: 6| Step: 5
Training loss: 3.3310456691005887
Validation loss: 2.547987678202411

Epoch: 6| Step: 6
Training loss: 2.881421422927217
Validation loss: 2.5468856506306143

Epoch: 6| Step: 7
Training loss: 2.3655916884381107
Validation loss: 2.5467701793535293

Epoch: 6| Step: 8
Training loss: 3.2732650237974354
Validation loss: 2.5441670020580838

Epoch: 6| Step: 9
Training loss: 2.764669479564925
Validation loss: 2.5433555054244152

Epoch: 6| Step: 10
Training loss: 3.5751418292315473
Validation loss: 2.542493484649569

Epoch: 6| Step: 11
Training loss: 2.9210995547820264
Validation loss: 2.539835135986311

Epoch: 6| Step: 12
Training loss: 2.2886253173801236
Validation loss: 2.5396523733713945

Epoch: 6| Step: 13
Training loss: 2.4315204146365774
Validation loss: 2.5414864277658036

Epoch: 67| Step: 0
Training loss: 2.7220669386380845
Validation loss: 2.539928856545234

Epoch: 6| Step: 1
Training loss: 3.4188033300281577
Validation loss: 2.539819759153732

Epoch: 6| Step: 2
Training loss: 2.6763816438357018
Validation loss: 2.5382568211952803

Epoch: 6| Step: 3
Training loss: 2.9210004670724885
Validation loss: 2.539541792267142

Epoch: 6| Step: 4
Training loss: 2.4259005653904326
Validation loss: 2.5393096435014484

Epoch: 6| Step: 5
Training loss: 3.0606898972445293
Validation loss: 2.538963490867755

Epoch: 6| Step: 6
Training loss: 3.0634060511988097
Validation loss: 2.539413359248531

Epoch: 6| Step: 7
Training loss: 2.6061237661404606
Validation loss: 2.537407158483202

Epoch: 6| Step: 8
Training loss: 3.2149569189053655
Validation loss: 2.5355988535218126

Epoch: 6| Step: 9
Training loss: 2.751697016671279
Validation loss: 2.537849375505283

Epoch: 6| Step: 10
Training loss: 3.210581961668752
Validation loss: 2.5369972390462716

Epoch: 6| Step: 11
Training loss: 2.7920111448398903
Validation loss: 2.537207006535166

Epoch: 6| Step: 12
Training loss: 2.836578044590305
Validation loss: 2.541229738685609

Epoch: 6| Step: 13
Training loss: 2.8956751242765484
Validation loss: 2.53972030410661

Epoch: 68| Step: 0
Training loss: 3.060442174740709
Validation loss: 2.5538673164299204

Epoch: 6| Step: 1
Training loss: 3.01493709011459
Validation loss: 2.554179865903982

Epoch: 6| Step: 2
Training loss: 2.8094717040937636
Validation loss: 2.5685263142894854

Epoch: 6| Step: 3
Training loss: 2.5245271107726537
Validation loss: 2.583166039283427

Epoch: 6| Step: 4
Training loss: 3.016706045606795
Validation loss: 2.580988014522812

Epoch: 6| Step: 5
Training loss: 2.8776171837881956
Validation loss: 2.554781458414049

Epoch: 6| Step: 6
Training loss: 2.7756552841846758
Validation loss: 2.5456772109110064

Epoch: 6| Step: 7
Training loss: 3.269413698696991
Validation loss: 2.5396868578141163

Epoch: 6| Step: 8
Training loss: 2.5321853228299216
Validation loss: 2.5417555543502033

Epoch: 6| Step: 9
Training loss: 2.8171536410259908
Validation loss: 2.5411088873761614

Epoch: 6| Step: 10
Training loss: 2.8940287577288384
Validation loss: 2.544988998230391

Epoch: 6| Step: 11
Training loss: 3.4905257741131974
Validation loss: 2.5403808079231798

Epoch: 6| Step: 12
Training loss: 2.728552324489231
Validation loss: 2.535982383991108

Epoch: 6| Step: 13
Training loss: 2.691336975534901
Validation loss: 2.535147935100398

Epoch: 69| Step: 0
Training loss: 2.566070766962749
Validation loss: 2.5354348999109857

Epoch: 6| Step: 1
Training loss: 2.9741596926493994
Validation loss: 2.5339137779191163

Epoch: 6| Step: 2
Training loss: 2.443081944462694
Validation loss: 2.5348008080755196

Epoch: 6| Step: 3
Training loss: 3.4316885634902174
Validation loss: 2.5339696279230206

Epoch: 6| Step: 4
Training loss: 2.944152765602041
Validation loss: 2.540565805727282

Epoch: 6| Step: 5
Training loss: 3.0774431586884745
Validation loss: 2.543579139200785

Epoch: 6| Step: 6
Training loss: 2.895810975644826
Validation loss: 2.5418741041354393

Epoch: 6| Step: 7
Training loss: 2.922967879774988
Validation loss: 2.5380300225225736

Epoch: 6| Step: 8
Training loss: 3.190593340470987
Validation loss: 2.5351139840382046

Epoch: 6| Step: 9
Training loss: 2.7931276076162326
Validation loss: 2.532033187650266

Epoch: 6| Step: 10
Training loss: 2.862269869553244
Validation loss: 2.531776990157603

Epoch: 6| Step: 11
Training loss: 2.7157938001560096
Validation loss: 2.53165422637978

Epoch: 6| Step: 12
Training loss: 3.148374495337336
Validation loss: 2.5345421077580568

Epoch: 6| Step: 13
Training loss: 2.2632211494827597
Validation loss: 2.532442205858626

Epoch: 70| Step: 0
Training loss: 2.872135891857979
Validation loss: 2.530829421651693

Epoch: 6| Step: 1
Training loss: 2.720629689032705
Validation loss: 2.534041190169772

Epoch: 6| Step: 2
Training loss: 3.366281338789122
Validation loss: 2.5350461007753253

Epoch: 6| Step: 3
Training loss: 3.307896996717636
Validation loss: 2.548535016687667

Epoch: 6| Step: 4
Training loss: 2.696647158796985
Validation loss: 2.551626130755279

Epoch: 6| Step: 5
Training loss: 3.179240277305999
Validation loss: 2.546014556495416

Epoch: 6| Step: 6
Training loss: 3.241658583551706
Validation loss: 2.5410463408943245

Epoch: 6| Step: 7
Training loss: 3.2799073878448697
Validation loss: 2.5336177775397015

Epoch: 6| Step: 8
Training loss: 2.3737266540182813
Validation loss: 2.5295144241624516

Epoch: 6| Step: 9
Training loss: 2.3855898820602386
Validation loss: 2.5292741261444793

Epoch: 6| Step: 10
Training loss: 2.4387502153905856
Validation loss: 2.536932923824481

Epoch: 6| Step: 11
Training loss: 3.2697883605130142
Validation loss: 2.538565442423001

Epoch: 6| Step: 12
Training loss: 2.7625530013441546
Validation loss: 2.532807414278446

Epoch: 6| Step: 13
Training loss: 1.9628037163013006
Validation loss: 2.5345940437297005

Epoch: 71| Step: 0
Training loss: 2.7445941156646843
Validation loss: 2.5321262716041355

Epoch: 6| Step: 1
Training loss: 2.6195225561619453
Validation loss: 2.5325339932292135

Epoch: 6| Step: 2
Training loss: 2.961828253836574
Validation loss: 2.5366864007223158

Epoch: 6| Step: 3
Training loss: 3.0213794258498434
Validation loss: 2.5398928442047928

Epoch: 6| Step: 4
Training loss: 3.025390152164666
Validation loss: 2.5510076496381986

Epoch: 6| Step: 5
Training loss: 3.0564493625264717
Validation loss: 2.533273888178173

Epoch: 6| Step: 6
Training loss: 3.210745627060707
Validation loss: 2.5334723776346055

Epoch: 6| Step: 7
Training loss: 2.9719271072649134
Validation loss: 2.5425322713024032

Epoch: 6| Step: 8
Training loss: 2.4567923376616645
Validation loss: 2.5339417480965

Epoch: 6| Step: 9
Training loss: 3.0860286650893136
Validation loss: 2.5276422529263174

Epoch: 6| Step: 10
Training loss: 3.181528818918721
Validation loss: 2.5252612880046374

Epoch: 6| Step: 11
Training loss: 3.076270149719887
Validation loss: 2.524683677737536

Epoch: 6| Step: 12
Training loss: 2.9664882677708784
Validation loss: 2.5233450515520923

Epoch: 6| Step: 13
Training loss: 1.1142567426457397
Validation loss: 2.5257709127606605

Epoch: 72| Step: 0
Training loss: 3.164379866895977
Validation loss: 2.5292775814619026

Epoch: 6| Step: 1
Training loss: 3.1196725830039416
Validation loss: 2.536633532316343

Epoch: 6| Step: 2
Training loss: 2.6698924065102903
Validation loss: 2.539994439298308

Epoch: 6| Step: 3
Training loss: 2.8054919775965574
Validation loss: 2.5430425651448516

Epoch: 6| Step: 4
Training loss: 3.0068827195228023
Validation loss: 2.5423462977984137

Epoch: 6| Step: 5
Training loss: 3.0986595886016124
Validation loss: 2.5346544403244815

Epoch: 6| Step: 6
Training loss: 2.533977216743107
Validation loss: 2.527920500957025

Epoch: 6| Step: 7
Training loss: 2.8148270199141145
Validation loss: 2.527830889806205

Epoch: 6| Step: 8
Training loss: 2.4221770067495827
Validation loss: 2.5259812339672365

Epoch: 6| Step: 9
Training loss: 3.032026682975335
Validation loss: 2.5223479439979717

Epoch: 6| Step: 10
Training loss: 3.1815240228595205
Validation loss: 2.5191547788859374

Epoch: 6| Step: 11
Training loss: 3.0161654131427333
Validation loss: 2.5190063667521567

Epoch: 6| Step: 12
Training loss: 2.5053220367535625
Validation loss: 2.5217292815212726

Epoch: 6| Step: 13
Training loss: 3.2151267389497673
Validation loss: 2.5309925229444707

Epoch: 73| Step: 0
Training loss: 2.672645948401889
Validation loss: 2.5292747342969055

Epoch: 6| Step: 1
Training loss: 2.3620527621197622
Validation loss: 2.533019613644162

Epoch: 6| Step: 2
Training loss: 2.755156797180658
Validation loss: 2.537251516085547

Epoch: 6| Step: 3
Training loss: 3.226590726788987
Validation loss: 2.5561183045970153

Epoch: 6| Step: 4
Training loss: 3.5817365119505986
Validation loss: 2.5820748349669875

Epoch: 6| Step: 5
Training loss: 3.0112131686430432
Validation loss: 2.605984807120786

Epoch: 6| Step: 6
Training loss: 3.1871699742025066
Validation loss: 2.5677279854096295

Epoch: 6| Step: 7
Training loss: 2.2656896121578827
Validation loss: 2.5347595587064404

Epoch: 6| Step: 8
Training loss: 2.43861393050829
Validation loss: 2.5238086099025674

Epoch: 6| Step: 9
Training loss: 3.1577652419459854
Validation loss: 2.519771510607923

Epoch: 6| Step: 10
Training loss: 3.210528642375455
Validation loss: 2.5205185562390926

Epoch: 6| Step: 11
Training loss: 2.4612068150007334
Validation loss: 2.525307399914856

Epoch: 6| Step: 12
Training loss: 2.7284010669904704
Validation loss: 2.5277737535724643

Epoch: 6| Step: 13
Training loss: 3.5343495497052855
Validation loss: 2.5300187458966907

Epoch: 74| Step: 0
Training loss: 3.2241243105035635
Validation loss: 2.531670469999101

Epoch: 6| Step: 1
Training loss: 2.7596149551935203
Validation loss: 2.525520611122515

Epoch: 6| Step: 2
Training loss: 2.910393499137912
Validation loss: 2.522973073778235

Epoch: 6| Step: 3
Training loss: 2.975136242479648
Validation loss: 2.5186999765359674

Epoch: 6| Step: 4
Training loss: 2.4417257603426115
Validation loss: 2.5137079478540403

Epoch: 6| Step: 5
Training loss: 3.1865556103283126
Validation loss: 2.521081195450501

Epoch: 6| Step: 6
Training loss: 2.4739637729518047
Validation loss: 2.543417443771176

Epoch: 6| Step: 7
Training loss: 2.5556465238698918
Validation loss: 2.5426744278417863

Epoch: 6| Step: 8
Training loss: 2.9708552876464243
Validation loss: 2.545061815978057

Epoch: 6| Step: 9
Training loss: 2.835601870850473
Validation loss: 2.5271812683816726

Epoch: 6| Step: 10
Training loss: 3.349979480282013
Validation loss: 2.5166656842386366

Epoch: 6| Step: 11
Training loss: 2.9759177964045027
Validation loss: 2.5127576413573194

Epoch: 6| Step: 12
Training loss: 2.9343546808776333
Validation loss: 2.516948735104454

Epoch: 6| Step: 13
Training loss: 2.911831817601522
Validation loss: 2.5159605955619697

Epoch: 75| Step: 0
Training loss: 3.0005060404910764
Validation loss: 2.51393241503202

Epoch: 6| Step: 1
Training loss: 2.444502626314272
Validation loss: 2.5191838450957715

Epoch: 6| Step: 2
Training loss: 2.7859491661456524
Validation loss: 2.517216492825687

Epoch: 6| Step: 3
Training loss: 3.1254967866843533
Validation loss: 2.522070581501946

Epoch: 6| Step: 4
Training loss: 3.1801583506186866
Validation loss: 2.524376961545379

Epoch: 6| Step: 5
Training loss: 2.739021059844552
Validation loss: 2.5254277039570137

Epoch: 6| Step: 6
Training loss: 2.7707889429040575
Validation loss: 2.527495230232705

Epoch: 6| Step: 7
Training loss: 3.277961318127047
Validation loss: 2.523300623847609

Epoch: 6| Step: 8
Training loss: 2.8076662699514077
Validation loss: 2.5271366646521107

Epoch: 6| Step: 9
Training loss: 2.2853693936053907
Validation loss: 2.529479031788292

Epoch: 6| Step: 10
Training loss: 3.1355045006363396
Validation loss: 2.5349687862527484

Epoch: 6| Step: 11
Training loss: 2.6843595564268083
Validation loss: 2.5249627736735625

Epoch: 6| Step: 12
Training loss: 3.0535841410156372
Validation loss: 2.5256272627593375

Epoch: 6| Step: 13
Training loss: 2.961697684665672
Validation loss: 2.5178985339625233

Epoch: 76| Step: 0
Training loss: 2.8741611417911024
Validation loss: 2.5136251447392586

Epoch: 6| Step: 1
Training loss: 2.495191718554169
Validation loss: 2.516040039881456

Epoch: 6| Step: 2
Training loss: 3.2773405491082404
Validation loss: 2.51569168918583

Epoch: 6| Step: 3
Training loss: 3.119527679296103
Validation loss: 2.5133924483758214

Epoch: 6| Step: 4
Training loss: 2.8644420981991496
Validation loss: 2.515296842785867

Epoch: 6| Step: 5
Training loss: 2.6241077541579974
Validation loss: 2.5137542003077336

Epoch: 6| Step: 6
Training loss: 2.6755420884222594
Validation loss: 2.5106160231052863

Epoch: 6| Step: 7
Training loss: 2.4738621957403333
Validation loss: 2.510417683102104

Epoch: 6| Step: 8
Training loss: 3.151581739481355
Validation loss: 2.5131431958282104

Epoch: 6| Step: 9
Training loss: 2.8851261107386144
Validation loss: 2.514761887056139

Epoch: 6| Step: 10
Training loss: 3.0015524979702235
Validation loss: 2.522462340028396

Epoch: 6| Step: 11
Training loss: 3.148781580143838
Validation loss: 2.5274787964764256

Epoch: 6| Step: 12
Training loss: 2.774447662783822
Validation loss: 2.539974856598999

Epoch: 6| Step: 13
Training loss: 2.732069514952665
Validation loss: 2.549105027968833

Epoch: 77| Step: 0
Training loss: 3.1443736919475422
Validation loss: 2.541159024539676

Epoch: 6| Step: 1
Training loss: 2.9994169304395517
Validation loss: 2.5433183662872905

Epoch: 6| Step: 2
Training loss: 2.7517438041400304
Validation loss: 2.533888933716203

Epoch: 6| Step: 3
Training loss: 2.929381982767757
Validation loss: 2.547083289706502

Epoch: 6| Step: 4
Training loss: 2.689204008467508
Validation loss: 2.566064885531141

Epoch: 6| Step: 5
Training loss: 2.697764202115534
Validation loss: 2.5681865932065895

Epoch: 6| Step: 6
Training loss: 2.954276047274692
Validation loss: 2.5616785699233136

Epoch: 6| Step: 7
Training loss: 2.9269446796054592
Validation loss: 2.544809279395722

Epoch: 6| Step: 8
Training loss: 3.123864081880482
Validation loss: 2.5316818883677077

Epoch: 6| Step: 9
Training loss: 2.965511442850252
Validation loss: 2.5345702308137197

Epoch: 6| Step: 10
Training loss: 2.5515290780807307
Validation loss: 2.5232993056041297

Epoch: 6| Step: 11
Training loss: 2.842068017563105
Validation loss: 2.5063957480687336

Epoch: 6| Step: 12
Training loss: 3.0653197094699025
Validation loss: 2.506046752405124

Epoch: 6| Step: 13
Training loss: 2.4314680536153364
Validation loss: 2.5068459544338886

Epoch: 78| Step: 0
Training loss: 2.940119123575681
Validation loss: 2.5116150608680234

Epoch: 6| Step: 1
Training loss: 2.510468689523265
Validation loss: 2.5144666673558

Epoch: 6| Step: 2
Training loss: 3.364503007211417
Validation loss: 2.5185566520491602

Epoch: 6| Step: 3
Training loss: 2.8771130633262567
Validation loss: 2.5195244062387516

Epoch: 6| Step: 4
Training loss: 3.009806024378037
Validation loss: 2.5161817512006115

Epoch: 6| Step: 5
Training loss: 2.9591424578750067
Validation loss: 2.515009723359853

Epoch: 6| Step: 6
Training loss: 2.6128284193160103
Validation loss: 2.5098354269402954

Epoch: 6| Step: 7
Training loss: 2.1114530147064574
Validation loss: 2.5056475909029445

Epoch: 6| Step: 8
Training loss: 2.348189663071555
Validation loss: 2.503328477441246

Epoch: 6| Step: 9
Training loss: 2.8464161876867884
Validation loss: 2.510264207243119

Epoch: 6| Step: 10
Training loss: 2.849286066948806
Validation loss: 2.5474939007664794

Epoch: 6| Step: 11
Training loss: 3.522505203362352
Validation loss: 2.5674114535323524

Epoch: 6| Step: 12
Training loss: 3.2585372301649547
Validation loss: 2.5701792932094265

Epoch: 6| Step: 13
Training loss: 3.5190143438482133
Validation loss: 2.533225559258587

Epoch: 79| Step: 0
Training loss: 2.8459028541782523
Validation loss: 2.5098724231427005

Epoch: 6| Step: 1
Training loss: 1.8451995324062083
Validation loss: 2.5049585738054185

Epoch: 6| Step: 2
Training loss: 2.7877814933387537
Validation loss: 2.500394724376325

Epoch: 6| Step: 3
Training loss: 3.180685350711688
Validation loss: 2.5004529922017875

Epoch: 6| Step: 4
Training loss: 3.1948114949048363
Validation loss: 2.506496793371392

Epoch: 6| Step: 5
Training loss: 2.891195374998226
Validation loss: 2.511726264174956

Epoch: 6| Step: 6
Training loss: 3.587857931005777
Validation loss: 2.5156352295741127

Epoch: 6| Step: 7
Training loss: 2.3712212467008777
Validation loss: 2.519361719493365

Epoch: 6| Step: 8
Training loss: 2.853942713803463
Validation loss: 2.505668098736049

Epoch: 6| Step: 9
Training loss: 2.591320508631572
Validation loss: 2.50095510388895

Epoch: 6| Step: 10
Training loss: 2.920784486660577
Validation loss: 2.4967991940016527

Epoch: 6| Step: 11
Training loss: 2.87017417246296
Validation loss: 2.4991487253498517

Epoch: 6| Step: 12
Training loss: 2.7461483598599643
Validation loss: 2.499089487454627

Epoch: 6| Step: 13
Training loss: 3.532227642469423
Validation loss: 2.496312706728505

Epoch: 80| Step: 0
Training loss: 2.692476854145161
Validation loss: 2.4991402450009725

Epoch: 6| Step: 1
Training loss: 2.318726071134006
Validation loss: 2.5018960858632866

Epoch: 6| Step: 2
Training loss: 3.644575210747732
Validation loss: 2.5032427952519445

Epoch: 6| Step: 3
Training loss: 2.5654378657796935
Validation loss: 2.521164444124425

Epoch: 6| Step: 4
Training loss: 1.8589514241882317
Validation loss: 2.5419758020823537

Epoch: 6| Step: 5
Training loss: 3.3422251994827663
Validation loss: 2.601036125198656

Epoch: 6| Step: 6
Training loss: 2.679745509462307
Validation loss: 2.595435870520906

Epoch: 6| Step: 7
Training loss: 2.781161789084592
Validation loss: 2.566857448548946

Epoch: 6| Step: 8
Training loss: 2.6372454985998655
Validation loss: 2.5615287398735136

Epoch: 6| Step: 9
Training loss: 3.543001185292889
Validation loss: 2.5296359489742994

Epoch: 6| Step: 10
Training loss: 3.2338408245577983
Validation loss: 2.501907320419741

Epoch: 6| Step: 11
Training loss: 3.3551359178098195
Validation loss: 2.5057900863847378

Epoch: 6| Step: 12
Training loss: 2.7215955903988056
Validation loss: 2.527122648536733

Epoch: 6| Step: 13
Training loss: 2.0624061331918937
Validation loss: 2.574499263197344

Epoch: 81| Step: 0
Training loss: 3.3289700720218978
Validation loss: 2.6144810236447387

Epoch: 6| Step: 1
Training loss: 3.41750833952639
Validation loss: 2.6302763418500135

Epoch: 6| Step: 2
Training loss: 3.3477419972426996
Validation loss: 2.5700998555872037

Epoch: 6| Step: 3
Training loss: 2.77532258779202
Validation loss: 2.5172409536624056

Epoch: 6| Step: 4
Training loss: 2.8074123566586766
Validation loss: 2.5088509177057863

Epoch: 6| Step: 5
Training loss: 2.592899964544574
Validation loss: 2.500694375358517

Epoch: 6| Step: 6
Training loss: 2.396021418168465
Validation loss: 2.500444223048009

Epoch: 6| Step: 7
Training loss: 3.1884797030516694
Validation loss: 2.5264396317626825

Epoch: 6| Step: 8
Training loss: 3.0305618606192546
Validation loss: 2.5387824326400943

Epoch: 6| Step: 9
Training loss: 2.804229613944295
Validation loss: 2.5249365798513477

Epoch: 6| Step: 10
Training loss: 2.3384573623199083
Validation loss: 2.507457322737845

Epoch: 6| Step: 11
Training loss: 2.741716306366497
Validation loss: 2.5290250166404684

Epoch: 6| Step: 12
Training loss: 3.1904142932269406
Validation loss: 2.541900607524854

Epoch: 6| Step: 13
Training loss: 2.464424690134541
Validation loss: 2.543550162281228

Epoch: 82| Step: 0
Training loss: 2.992691196844474
Validation loss: 2.5390992076608856

Epoch: 6| Step: 1
Training loss: 2.481577707937478
Validation loss: 2.5183277707432

Epoch: 6| Step: 2
Training loss: 2.6695712681852886
Validation loss: 2.5157988318859617

Epoch: 6| Step: 3
Training loss: 2.5150285096571823
Validation loss: 2.5127735572047527

Epoch: 6| Step: 4
Training loss: 3.2577292159524576
Validation loss: 2.5145778077645593

Epoch: 6| Step: 5
Training loss: 2.872235171175933
Validation loss: 2.512835577035611

Epoch: 6| Step: 6
Training loss: 2.919052801006847
Validation loss: 2.5203822925755306

Epoch: 6| Step: 7
Training loss: 3.197935189225589
Validation loss: 2.5298044312231434

Epoch: 6| Step: 8
Training loss: 3.1095225236870987
Validation loss: 2.542014287022307

Epoch: 6| Step: 9
Training loss: 3.044174954242705
Validation loss: 2.5288429802265155

Epoch: 6| Step: 10
Training loss: 2.784046438849294
Validation loss: 2.5189337356799117

Epoch: 6| Step: 11
Training loss: 2.7455550597392087
Validation loss: 2.506292936268096

Epoch: 6| Step: 12
Training loss: 2.962353692284795
Validation loss: 2.5015915562680813

Epoch: 6| Step: 13
Training loss: 1.906247436021425
Validation loss: 2.5046796193249428

Epoch: 83| Step: 0
Training loss: 2.8430206705013505
Validation loss: 2.5017880700580326

Epoch: 6| Step: 1
Training loss: 3.180006756325508
Validation loss: 2.5019763815032854

Epoch: 6| Step: 2
Training loss: 2.5794677936564243
Validation loss: 2.5016072572384567

Epoch: 6| Step: 3
Training loss: 2.410540038578055
Validation loss: 2.5057868871904283

Epoch: 6| Step: 4
Training loss: 3.1727302788742304
Validation loss: 2.506182307148331

Epoch: 6| Step: 5
Training loss: 3.1538536114631355
Validation loss: 2.515782956577107

Epoch: 6| Step: 6
Training loss: 2.554864253191133
Validation loss: 2.5124840474825034

Epoch: 6| Step: 7
Training loss: 3.1387921958891463
Validation loss: 2.524558972692712

Epoch: 6| Step: 8
Training loss: 2.3833370444351147
Validation loss: 2.5140571821936573

Epoch: 6| Step: 9
Training loss: 2.651396142509942
Validation loss: 2.5131162407372494

Epoch: 6| Step: 10
Training loss: 2.9331607016425396
Validation loss: 2.506259732292329

Epoch: 6| Step: 11
Training loss: 3.094795743891854
Validation loss: 2.51346844378406

Epoch: 6| Step: 12
Training loss: 2.9294057481705313
Validation loss: 2.515866404003681

Epoch: 6| Step: 13
Training loss: 2.874672580816712
Validation loss: 2.5204486890765727

Epoch: 84| Step: 0
Training loss: 2.901028279810666
Validation loss: 2.512992425590436

Epoch: 6| Step: 1
Training loss: 2.8340886922995745
Validation loss: 2.50668891150794

Epoch: 6| Step: 2
Training loss: 2.9310335449464855
Validation loss: 2.5052571089304134

Epoch: 6| Step: 3
Training loss: 2.8345493250424543
Validation loss: 2.5056033169842693

Epoch: 6| Step: 4
Training loss: 2.533028248770594
Validation loss: 2.5077211848123624

Epoch: 6| Step: 5
Training loss: 3.0064846526185134
Validation loss: 2.5149125919888613

Epoch: 6| Step: 6
Training loss: 2.791650335539311
Validation loss: 2.5126281111773303

Epoch: 6| Step: 7
Training loss: 3.0978917613222325
Validation loss: 2.50717519424362

Epoch: 6| Step: 8
Training loss: 3.314003944868872
Validation loss: 2.506919426065479

Epoch: 6| Step: 9
Training loss: 3.352415745392575
Validation loss: 2.5073178053566574

Epoch: 6| Step: 10
Training loss: 2.6857832814980735
Validation loss: 2.5077364078192357

Epoch: 6| Step: 11
Training loss: 1.8929129384086896
Validation loss: 2.5086422061601716

Epoch: 6| Step: 12
Training loss: 1.7026939196505322
Validation loss: 2.5175559881581515

Epoch: 6| Step: 13
Training loss: 3.948795043070138
Validation loss: 2.5331470627731973

Epoch: 85| Step: 0
Training loss: 3.27073364753837
Validation loss: 2.516916460072181

Epoch: 6| Step: 1
Training loss: 3.144554905772822
Validation loss: 2.5037930130083867

Epoch: 6| Step: 2
Training loss: 2.689953859210034
Validation loss: 2.4987259222918

Epoch: 6| Step: 3
Training loss: 2.4630897435431205
Validation loss: 2.5000772105363667

Epoch: 6| Step: 4
Training loss: 2.8285963814255424
Validation loss: 2.502591850746688

Epoch: 6| Step: 5
Training loss: 3.1728129386018606
Validation loss: 2.5072939368579297

Epoch: 6| Step: 6
Training loss: 2.5826976568279285
Validation loss: 2.5003267577140367

Epoch: 6| Step: 7
Training loss: 2.9982304122362575
Validation loss: 2.5003431079617

Epoch: 6| Step: 8
Training loss: 1.8172703810181439
Validation loss: 2.505260875711097

Epoch: 6| Step: 9
Training loss: 2.752876164841978
Validation loss: 2.510848884885457

Epoch: 6| Step: 10
Training loss: 3.30464204797533
Validation loss: 2.5187788632067707

Epoch: 6| Step: 11
Training loss: 2.972819219826448
Validation loss: 2.535713094575383

Epoch: 6| Step: 12
Training loss: 3.0972461404908
Validation loss: 2.5502532531620448

Epoch: 6| Step: 13
Training loss: 2.2868133014488947
Validation loss: 2.528742682875357

Epoch: 86| Step: 0
Training loss: 2.4152194216859297
Validation loss: 2.5170257954558815

Epoch: 6| Step: 1
Training loss: 3.1549364132526474
Validation loss: 2.5030856327807336

Epoch: 6| Step: 2
Training loss: 3.29441387283124
Validation loss: 2.5006984463112802

Epoch: 6| Step: 3
Training loss: 3.2435588096766574
Validation loss: 2.496221627121157

Epoch: 6| Step: 4
Training loss: 2.382036326582201
Validation loss: 2.5001500151345284

Epoch: 6| Step: 5
Training loss: 2.8988290198422013
Validation loss: 2.5020961526068266

Epoch: 6| Step: 6
Training loss: 2.8633605196649916
Validation loss: 2.5156039272315662

Epoch: 6| Step: 7
Training loss: 2.022828470724262
Validation loss: 2.524751003939145

Epoch: 6| Step: 8
Training loss: 2.2847560956067836
Validation loss: 2.512577063906556

Epoch: 6| Step: 9
Training loss: 2.4254660286396934
Validation loss: 2.516015921956575

Epoch: 6| Step: 10
Training loss: 2.859048126381374
Validation loss: 2.5134304744165235

Epoch: 6| Step: 11
Training loss: 3.5108015413532785
Validation loss: 2.493353768658078

Epoch: 6| Step: 12
Training loss: 3.158102870239295
Validation loss: 2.4974304725134986

Epoch: 6| Step: 13
Training loss: 3.1596395591197877
Validation loss: 2.495035338453518

Epoch: 87| Step: 0
Training loss: 2.375644897441841
Validation loss: 2.4960470881268164

Epoch: 6| Step: 1
Training loss: 2.4265546318363866
Validation loss: 2.4937749361340757

Epoch: 6| Step: 2
Training loss: 3.028630648853989
Validation loss: 2.5045910579781943

Epoch: 6| Step: 3
Training loss: 3.814248981472444
Validation loss: 2.5082749132210433

Epoch: 6| Step: 4
Training loss: 2.84733707434104
Validation loss: 2.5163912672633466

Epoch: 6| Step: 5
Training loss: 2.405217729574634
Validation loss: 2.5260355908839123

Epoch: 6| Step: 6
Training loss: 2.087079253596043
Validation loss: 2.538282292269862

Epoch: 6| Step: 7
Training loss: 2.516818977530072
Validation loss: 2.553824502855033

Epoch: 6| Step: 8
Training loss: 3.612722058714585
Validation loss: 2.5624205043976462

Epoch: 6| Step: 9
Training loss: 3.2232344415032204
Validation loss: 2.5220343517720973

Epoch: 6| Step: 10
Training loss: 2.8972346439584973
Validation loss: 2.497750987289733

Epoch: 6| Step: 11
Training loss: 2.9401426400076764
Validation loss: 2.4900282954167374

Epoch: 6| Step: 12
Training loss: 2.699981449204754
Validation loss: 2.4900716875094324

Epoch: 6| Step: 13
Training loss: 2.665444113708487
Validation loss: 2.490339680101374

Epoch: 88| Step: 0
Training loss: 2.637197222212016
Validation loss: 2.4865508666118443

Epoch: 6| Step: 1
Training loss: 2.838911026654541
Validation loss: 2.4902372379757023

Epoch: 6| Step: 2
Training loss: 2.935517798893345
Validation loss: 2.4887409745940436

Epoch: 6| Step: 3
Training loss: 2.5020918677377955
Validation loss: 2.4861770665322163

Epoch: 6| Step: 4
Training loss: 3.1281923391618704
Validation loss: 2.492478628735192

Epoch: 6| Step: 5
Training loss: 2.2801159692015256
Validation loss: 2.4999627900174435

Epoch: 6| Step: 6
Training loss: 3.166492423902177
Validation loss: 2.517589231533877

Epoch: 6| Step: 7
Training loss: 2.8767900284726937
Validation loss: 2.5516600012657182

Epoch: 6| Step: 8
Training loss: 2.908579395308974
Validation loss: 2.6060579125807495

Epoch: 6| Step: 9
Training loss: 2.7328731226971996
Validation loss: 2.5486666137130385

Epoch: 6| Step: 10
Training loss: 2.7163898264553303
Validation loss: 2.5121585485976783

Epoch: 6| Step: 11
Training loss: 3.064597520896976
Validation loss: 2.4912286560347194

Epoch: 6| Step: 12
Training loss: 3.0888969813118123
Validation loss: 2.485329013803325

Epoch: 6| Step: 13
Training loss: 3.087394428378771
Validation loss: 2.4788943732580826

Epoch: 89| Step: 0
Training loss: 3.037956605351455
Validation loss: 2.4802298792152353

Epoch: 6| Step: 1
Training loss: 3.2436681836344574
Validation loss: 2.4828216583748626

Epoch: 6| Step: 2
Training loss: 2.8938336683663937
Validation loss: 2.4877559734428676

Epoch: 6| Step: 3
Training loss: 2.7008659316413106
Validation loss: 2.497013100224494

Epoch: 6| Step: 4
Training loss: 3.191626775772831
Validation loss: 2.522370902183853

Epoch: 6| Step: 5
Training loss: 2.3563191411324027
Validation loss: 2.534680605026166

Epoch: 6| Step: 6
Training loss: 2.3857332932895505
Validation loss: 2.5453565600582277

Epoch: 6| Step: 7
Training loss: 2.9504868768330033
Validation loss: 2.539611958890175

Epoch: 6| Step: 8
Training loss: 2.5874645875728155
Validation loss: 2.502197457601129

Epoch: 6| Step: 9
Training loss: 2.822802260967407
Validation loss: 2.4923353084173736

Epoch: 6| Step: 10
Training loss: 2.3343625069606926
Validation loss: 2.4800053904058337

Epoch: 6| Step: 11
Training loss: 2.981893256504746
Validation loss: 2.480718929330818

Epoch: 6| Step: 12
Training loss: 2.9485787410898876
Validation loss: 2.4807019077048387

Epoch: 6| Step: 13
Training loss: 3.320113160376477
Validation loss: 2.476970979100319

Epoch: 90| Step: 0
Training loss: 2.453218591933534
Validation loss: 2.4814645491937797

Epoch: 6| Step: 1
Training loss: 3.033629437201561
Validation loss: 2.479336307175047

Epoch: 6| Step: 2
Training loss: 2.4604683565098395
Validation loss: 2.4821183304266854

Epoch: 6| Step: 3
Training loss: 3.1379223482287104
Validation loss: 2.482628644325519

Epoch: 6| Step: 4
Training loss: 2.93372475729031
Validation loss: 2.4825020879742836

Epoch: 6| Step: 5
Training loss: 3.022875356534334
Validation loss: 2.4857778955102323

Epoch: 6| Step: 6
Training loss: 2.847304083001438
Validation loss: 2.496861549016863

Epoch: 6| Step: 7
Training loss: 3.0612821687727028
Validation loss: 2.502030160506676

Epoch: 6| Step: 8
Training loss: 2.9318502759084133
Validation loss: 2.5208199033800636

Epoch: 6| Step: 9
Training loss: 2.294603327293514
Validation loss: 2.538120109907176

Epoch: 6| Step: 10
Training loss: 2.406626684256511
Validation loss: 2.5611103670850266

Epoch: 6| Step: 11
Training loss: 2.7589293209644556
Validation loss: 2.636576454275907

Epoch: 6| Step: 12
Training loss: 3.1171951485064375
Validation loss: 2.6874020571269313

Epoch: 6| Step: 13
Training loss: 3.3178699080778786
Validation loss: 2.687364817618011

Epoch: 91| Step: 0
Training loss: 3.6882553620047034
Validation loss: 2.637227179495483

Epoch: 6| Step: 1
Training loss: 3.470397970150978
Validation loss: 2.5611482662106626

Epoch: 6| Step: 2
Training loss: 2.899213250087413
Validation loss: 2.522332331478782

Epoch: 6| Step: 3
Training loss: 2.2925309603232247
Validation loss: 2.494286719441189

Epoch: 6| Step: 4
Training loss: 2.6465003206680597
Validation loss: 2.487794938526905

Epoch: 6| Step: 5
Training loss: 3.0297070538508044
Validation loss: 2.4836603288474257

Epoch: 6| Step: 6
Training loss: 2.652483255259794
Validation loss: 2.479816599408084

Epoch: 6| Step: 7
Training loss: 2.4582612517398186
Validation loss: 2.477238505474316

Epoch: 6| Step: 8
Training loss: 2.9074711028850015
Validation loss: 2.4739084864173044

Epoch: 6| Step: 9
Training loss: 3.0684423599336768
Validation loss: 2.4768092710962906

Epoch: 6| Step: 10
Training loss: 2.4565979495157904
Validation loss: 2.474223494425042

Epoch: 6| Step: 11
Training loss: 2.8694693401085924
Validation loss: 2.476431320938174

Epoch: 6| Step: 12
Training loss: 2.0101288373659183
Validation loss: 2.4768382070017716

Epoch: 6| Step: 13
Training loss: 3.103270706489975
Validation loss: 2.484623041744902

Epoch: 92| Step: 0
Training loss: 2.950440493525494
Validation loss: 2.494203241768886

Epoch: 6| Step: 1
Training loss: 3.1058513669560956
Validation loss: 2.5005684647242004

Epoch: 6| Step: 2
Training loss: 2.745867832490016
Validation loss: 2.505946993310083

Epoch: 6| Step: 3
Training loss: 2.615162535771147
Validation loss: 2.5204381118507704

Epoch: 6| Step: 4
Training loss: 2.544139680374652
Validation loss: 2.5202700186296383

Epoch: 6| Step: 5
Training loss: 2.9527736232756654
Validation loss: 2.5356497527659765

Epoch: 6| Step: 6
Training loss: 3.102703048123359
Validation loss: 2.52355781292997

Epoch: 6| Step: 7
Training loss: 2.5194199648388347
Validation loss: 2.5129470497269235

Epoch: 6| Step: 8
Training loss: 2.915223736560215
Validation loss: 2.514557241077828

Epoch: 6| Step: 9
Training loss: 3.220635907898488
Validation loss: 2.5085638530334133

Epoch: 6| Step: 10
Training loss: 2.453343084080987
Validation loss: 2.5084496009161024

Epoch: 6| Step: 11
Training loss: 2.557979970213828
Validation loss: 2.501430243355633

Epoch: 6| Step: 12
Training loss: 2.8805796341935532
Validation loss: 2.503313582991452

Epoch: 6| Step: 13
Training loss: 3.233121619880011
Validation loss: 2.497265044736376

Epoch: 93| Step: 0
Training loss: 2.9184019285542826
Validation loss: 2.4901253818158393

Epoch: 6| Step: 1
Training loss: 2.7450153083582864
Validation loss: 2.487005446727418

Epoch: 6| Step: 2
Training loss: 2.962341136938263
Validation loss: 2.482911188247987

Epoch: 6| Step: 3
Training loss: 2.6393009455248913
Validation loss: 2.4832273848284223

Epoch: 6| Step: 4
Training loss: 2.6732261765932086
Validation loss: 2.484836299493606

Epoch: 6| Step: 5
Training loss: 2.8819320698872026
Validation loss: 2.4821462356447768

Epoch: 6| Step: 6
Training loss: 2.68346403605267
Validation loss: 2.489553638689111

Epoch: 6| Step: 7
Training loss: 3.2668536489521345
Validation loss: 2.4926949451599287

Epoch: 6| Step: 8
Training loss: 2.6540995251493853
Validation loss: 2.493860721569129

Epoch: 6| Step: 9
Training loss: 3.104847127250189
Validation loss: 2.493179741480009

Epoch: 6| Step: 10
Training loss: 2.100134836136969
Validation loss: 2.4874508814590404

Epoch: 6| Step: 11
Training loss: 2.6389352482075377
Validation loss: 2.4841446721063645

Epoch: 6| Step: 12
Training loss: 3.265691291099734
Validation loss: 2.4775893613260376

Epoch: 6| Step: 13
Training loss: 2.883215237736631
Validation loss: 2.4781782710548144

Epoch: 94| Step: 0
Training loss: 2.1438345133412846
Validation loss: 2.4792921869178404

Epoch: 6| Step: 1
Training loss: 3.11412383467492
Validation loss: 2.484515159792759

Epoch: 6| Step: 2
Training loss: 2.3071353649876527
Validation loss: 2.4906583261943536

Epoch: 6| Step: 3
Training loss: 2.804783641474361
Validation loss: 2.4812904392843365

Epoch: 6| Step: 4
Training loss: 3.003059257875381
Validation loss: 2.4756150337178084

Epoch: 6| Step: 5
Training loss: 2.7472966518247426
Validation loss: 2.4752507486829023

Epoch: 6| Step: 6
Training loss: 2.8608929716569054
Validation loss: 2.475884171760071

Epoch: 6| Step: 7
Training loss: 2.971071319535531
Validation loss: 2.483102043196078

Epoch: 6| Step: 8
Training loss: 3.5773491830445066
Validation loss: 2.4919730993136486

Epoch: 6| Step: 9
Training loss: 2.525957201826948
Validation loss: 2.5031065180197594

Epoch: 6| Step: 10
Training loss: 2.3636378500006745
Validation loss: 2.551078740972979

Epoch: 6| Step: 11
Training loss: 3.067695725592637
Validation loss: 2.5956230907094833

Epoch: 6| Step: 12
Training loss: 3.345676473231923
Validation loss: 2.5496901849737093

Epoch: 6| Step: 13
Training loss: 2.5853288285680316
Validation loss: 2.51351468126608

Epoch: 95| Step: 0
Training loss: 2.8673710985154264
Validation loss: 2.4879105472209333

Epoch: 6| Step: 1
Training loss: 2.2504312313940824
Validation loss: 2.475947109936008

Epoch: 6| Step: 2
Training loss: 2.914562192726131
Validation loss: 2.478198607930917

Epoch: 6| Step: 3
Training loss: 3.182760267620321
Validation loss: 2.4732605226021716

Epoch: 6| Step: 4
Training loss: 2.360570743534176
Validation loss: 2.475217192504401

Epoch: 6| Step: 5
Training loss: 2.652563251744319
Validation loss: 2.4792968968798466

Epoch: 6| Step: 6
Training loss: 3.0971819405057905
Validation loss: 2.488928004048781

Epoch: 6| Step: 7
Training loss: 2.7754143345442235
Validation loss: 2.485116463201272

Epoch: 6| Step: 8
Training loss: 2.051301552300802
Validation loss: 2.4782512933086243

Epoch: 6| Step: 9
Training loss: 3.290922603933889
Validation loss: 2.473531615540581

Epoch: 6| Step: 10
Training loss: 2.835166469039433
Validation loss: 2.483068404181843

Epoch: 6| Step: 11
Training loss: 2.8769494786339758
Validation loss: 2.500865816090028

Epoch: 6| Step: 12
Training loss: 3.1404824295706377
Validation loss: 2.5218013009095057

Epoch: 6| Step: 13
Training loss: 3.7206996647375643
Validation loss: 2.5882329411091805

Epoch: 96| Step: 0
Training loss: 2.8923753542407553
Validation loss: 2.598604123921591

Epoch: 6| Step: 1
Training loss: 2.91788949309824
Validation loss: 2.5918661353837167

Epoch: 6| Step: 2
Training loss: 2.8327767068460603
Validation loss: 2.5553050744011565

Epoch: 6| Step: 3
Training loss: 2.2632641297530016
Validation loss: 2.502136804193886

Epoch: 6| Step: 4
Training loss: 2.2616247180636413
Validation loss: 2.48044479264238

Epoch: 6| Step: 5
Training loss: 2.823538755069495
Validation loss: 2.468169300200076

Epoch: 6| Step: 6
Training loss: 3.181758721526778
Validation loss: 2.469620780184712

Epoch: 6| Step: 7
Training loss: 2.7845900121830693
Validation loss: 2.4735741046311475

Epoch: 6| Step: 8
Training loss: 2.8734113201465075
Validation loss: 2.4885337756699837

Epoch: 6| Step: 9
Training loss: 3.0241988453152118
Validation loss: 2.4953848981492643

Epoch: 6| Step: 10
Training loss: 2.929030362498982
Validation loss: 2.495630395651285

Epoch: 6| Step: 11
Training loss: 3.160344555576328
Validation loss: 2.4987436696156795

Epoch: 6| Step: 12
Training loss: 3.096399887085353
Validation loss: 2.4866767478230907

Epoch: 6| Step: 13
Training loss: 3.0529386777844882
Validation loss: 2.482509593511565

Epoch: 97| Step: 0
Training loss: 2.870883814603636
Validation loss: 2.476206245495262

Epoch: 6| Step: 1
Training loss: 2.787330752310949
Validation loss: 2.4699909470911927

Epoch: 6| Step: 2
Training loss: 2.759594392965039
Validation loss: 2.4713572240588153

Epoch: 6| Step: 3
Training loss: 2.4683221373818207
Validation loss: 2.480020983046854

Epoch: 6| Step: 4
Training loss: 2.8932796351405683
Validation loss: 2.491557795706337

Epoch: 6| Step: 5
Training loss: 3.059208249154401
Validation loss: 2.4935790039999692

Epoch: 6| Step: 6
Training loss: 2.7069858035281475
Validation loss: 2.5338315035816117

Epoch: 6| Step: 7
Training loss: 2.7133188479581265
Validation loss: 2.5706836851205805

Epoch: 6| Step: 8
Training loss: 2.8803972086908405
Validation loss: 2.5671032093925743

Epoch: 6| Step: 9
Training loss: 3.153846203050738
Validation loss: 2.5428793586353136

Epoch: 6| Step: 10
Training loss: 3.247126556138832
Validation loss: 2.4904750490677703

Epoch: 6| Step: 11
Training loss: 2.5280817242703693
Validation loss: 2.469545593665411

Epoch: 6| Step: 12
Training loss: 2.4275460081916487
Validation loss: 2.464626606590183

Epoch: 6| Step: 13
Training loss: 3.3603678810723356
Validation loss: 2.470339928619296

Epoch: 98| Step: 0
Training loss: 2.925908369860266
Validation loss: 2.4738747394905283

Epoch: 6| Step: 1
Training loss: 2.1431708129008906
Validation loss: 2.485766323004666

Epoch: 6| Step: 2
Training loss: 2.7345316814764264
Validation loss: 2.4931521191394523

Epoch: 6| Step: 3
Training loss: 2.8046942155592913
Validation loss: 2.5104341483797796

Epoch: 6| Step: 4
Training loss: 2.8452521747727944
Validation loss: 2.5147994173393124

Epoch: 6| Step: 5
Training loss: 2.4839791996280023
Validation loss: 2.5129505856439227

Epoch: 6| Step: 6
Training loss: 3.324525991511768
Validation loss: 2.4979031311137523

Epoch: 6| Step: 7
Training loss: 2.8576905338713514
Validation loss: 2.487680067475882

Epoch: 6| Step: 8
Training loss: 2.7805154237530343
Validation loss: 2.495233913815662

Epoch: 6| Step: 9
Training loss: 3.208173541428803
Validation loss: 2.493477132946028

Epoch: 6| Step: 10
Training loss: 2.8143566361246886
Validation loss: 2.4879352869134674

Epoch: 6| Step: 11
Training loss: 2.6614918765786677
Validation loss: 2.489308826128804

Epoch: 6| Step: 12
Training loss: 2.9217095149703307
Validation loss: 2.4848548021853087

Epoch: 6| Step: 13
Training loss: 3.0004127536390235
Validation loss: 2.490923984244167

Epoch: 99| Step: 0
Training loss: 3.2509617482859374
Validation loss: 2.4882799023859152

Epoch: 6| Step: 1
Training loss: 3.072368059918191
Validation loss: 2.4820920981201393

Epoch: 6| Step: 2
Training loss: 2.379815790596842
Validation loss: 2.4761204064704856

Epoch: 6| Step: 3
Training loss: 3.2085590695981563
Validation loss: 2.4757150002361747

Epoch: 6| Step: 4
Training loss: 2.946110220220469
Validation loss: 2.47495615259374

Epoch: 6| Step: 5
Training loss: 2.66967808043622
Validation loss: 2.4750047979290746

Epoch: 6| Step: 6
Training loss: 2.6056157060669243
Validation loss: 2.47648241658861

Epoch: 6| Step: 7
Training loss: 2.564229707072107
Validation loss: 2.4742394897765023

Epoch: 6| Step: 8
Training loss: 2.84754707116665
Validation loss: 2.4937082257389127

Epoch: 6| Step: 9
Training loss: 2.6601144840585977
Validation loss: 2.5064370141896455

Epoch: 6| Step: 10
Training loss: 2.8174192852654354
Validation loss: 2.491148158043935

Epoch: 6| Step: 11
Training loss: 2.716904112223523
Validation loss: 2.492782251779629

Epoch: 6| Step: 12
Training loss: 2.5684845056257686
Validation loss: 2.4703234674826025

Epoch: 6| Step: 13
Training loss: 2.755830392881135
Validation loss: 2.469636816246717

Epoch: 100| Step: 0
Training loss: 2.745050310740423
Validation loss: 2.4679234924031985

Epoch: 6| Step: 1
Training loss: 2.691156871298795
Validation loss: 2.4671194211722347

Epoch: 6| Step: 2
Training loss: 2.9463293612072485
Validation loss: 2.4646976307311994

Epoch: 6| Step: 3
Training loss: 3.1399061604466993
Validation loss: 2.470115364017399

Epoch: 6| Step: 4
Training loss: 2.967187731412906
Validation loss: 2.4700391027636743

Epoch: 6| Step: 5
Training loss: 2.758397804805254
Validation loss: 2.4653262521300476

Epoch: 6| Step: 6
Training loss: 3.1970607013780485
Validation loss: 2.4693088047040592

Epoch: 6| Step: 7
Training loss: 2.912722527512333
Validation loss: 2.473819334381518

Epoch: 6| Step: 8
Training loss: 3.318918020589327
Validation loss: 2.4755857510975305

Epoch: 6| Step: 9
Training loss: 2.2461651865338252
Validation loss: 2.480967840346696

Epoch: 6| Step: 10
Training loss: 2.795436553164123
Validation loss: 2.4833600052797427

Epoch: 6| Step: 11
Training loss: 2.5003227979164047
Validation loss: 2.500252028036356

Epoch: 6| Step: 12
Training loss: 2.388095889199842
Validation loss: 2.492407305952173

Epoch: 6| Step: 13
Training loss: 2.603031419626686
Validation loss: 2.4851891557391204

Epoch: 101| Step: 0
Training loss: 3.218883326463506
Validation loss: 2.4827070022679383

Epoch: 6| Step: 1
Training loss: 2.9880292798692514
Validation loss: 2.472597237965771

Epoch: 6| Step: 2
Training loss: 2.4129802166617482
Validation loss: 2.474512185932269

Epoch: 6| Step: 3
Training loss: 2.8028391748699293
Validation loss: 2.472944576584429

Epoch: 6| Step: 4
Training loss: 2.6199990728245615
Validation loss: 2.4757774524086646

Epoch: 6| Step: 5
Training loss: 2.4018986979776393
Validation loss: 2.4720748147513354

Epoch: 6| Step: 6
Training loss: 2.9526420077186177
Validation loss: 2.4777814725414244

Epoch: 6| Step: 7
Training loss: 2.556043445850719
Validation loss: 2.4780696838566945

Epoch: 6| Step: 8
Training loss: 3.028913560985905
Validation loss: 2.4894642117687367

Epoch: 6| Step: 9
Training loss: 2.7072376871592545
Validation loss: 2.5051462621450065

Epoch: 6| Step: 10
Training loss: 2.593008096137245
Validation loss: 2.4967433955697556

Epoch: 6| Step: 11
Training loss: 2.9262209308521507
Validation loss: 2.494584358153858

Epoch: 6| Step: 12
Training loss: 2.9048064553792377
Validation loss: 2.51420861763863

Epoch: 6| Step: 13
Training loss: 2.975627762413225
Validation loss: 2.5232084213426345

Epoch: 102| Step: 0
Training loss: 3.040437598103909
Validation loss: 2.5264735101482767

Epoch: 6| Step: 1
Training loss: 3.174085025660477
Validation loss: 2.5364906107006573

Epoch: 6| Step: 2
Training loss: 2.3384721458200275
Validation loss: 2.49895304322846

Epoch: 6| Step: 3
Training loss: 2.6958377050003697
Validation loss: 2.486630266985408

Epoch: 6| Step: 4
Training loss: 2.8559526484862294
Validation loss: 2.4761191392070145

Epoch: 6| Step: 5
Training loss: 2.8746875095543674
Validation loss: 2.4728776505111787

Epoch: 6| Step: 6
Training loss: 2.9413342714051693
Validation loss: 2.4772414310738418

Epoch: 6| Step: 7
Training loss: 2.4076930091315014
Validation loss: 2.4817123999314394

Epoch: 6| Step: 8
Training loss: 2.8091481899067636
Validation loss: 2.4759258801484605

Epoch: 6| Step: 9
Training loss: 2.8310605825762183
Validation loss: 2.4792716697846706

Epoch: 6| Step: 10
Training loss: 2.9430841166600756
Validation loss: 2.4765256925108

Epoch: 6| Step: 11
Training loss: 2.915379612645262
Validation loss: 2.4725033758934165

Epoch: 6| Step: 12
Training loss: 3.0860932516074735
Validation loss: 2.470422665392439

Epoch: 6| Step: 13
Training loss: 2.5992393774894413
Validation loss: 2.4679731458021084

Epoch: 103| Step: 0
Training loss: 2.9875554418806267
Validation loss: 2.4829665334806665

Epoch: 6| Step: 1
Training loss: 2.057171150894715
Validation loss: 2.515182592773145

Epoch: 6| Step: 2
Training loss: 3.0509417658936906
Validation loss: 2.567303762171947

Epoch: 6| Step: 3
Training loss: 2.965522859219306
Validation loss: 2.5923049979741712

Epoch: 6| Step: 4
Training loss: 2.827892989447377
Validation loss: 2.591381402432182

Epoch: 6| Step: 5
Training loss: 2.6862907350486114
Validation loss: 2.550135187904249

Epoch: 6| Step: 6
Training loss: 3.237698970851752
Validation loss: 2.5204354510088276

Epoch: 6| Step: 7
Training loss: 3.053305701196009
Validation loss: 2.474095687982349

Epoch: 6| Step: 8
Training loss: 2.5772888677280323
Validation loss: 2.470137741274015

Epoch: 6| Step: 9
Training loss: 2.7919868930847844
Validation loss: 2.4715086499674634

Epoch: 6| Step: 10
Training loss: 2.6812382873421603
Validation loss: 2.478072087071724

Epoch: 6| Step: 11
Training loss: 3.036362888064056
Validation loss: 2.4718705114896338

Epoch: 6| Step: 12
Training loss: 2.5048342694492236
Validation loss: 2.468548202730386

Epoch: 6| Step: 13
Training loss: 2.8754519231787214
Validation loss: 2.4719658298081466

Epoch: 104| Step: 0
Training loss: 2.3522623737896424
Validation loss: 2.4753698254790377

Epoch: 6| Step: 1
Training loss: 2.7093793365197416
Validation loss: 2.492030958125544

Epoch: 6| Step: 2
Training loss: 2.745625658145915
Validation loss: 2.4970041495869846

Epoch: 6| Step: 3
Training loss: 2.54141886602742
Validation loss: 2.4988107416244083

Epoch: 6| Step: 4
Training loss: 2.628576748336124
Validation loss: 2.5170815730567493

Epoch: 6| Step: 5
Training loss: 2.350593646123629
Validation loss: 2.5130364418129516

Epoch: 6| Step: 6
Training loss: 3.0928657886531536
Validation loss: 2.5173600753953664

Epoch: 6| Step: 7
Training loss: 2.6193637283508653
Validation loss: 2.4886425305498103

Epoch: 6| Step: 8
Training loss: 3.242662362862333
Validation loss: 2.4763382367319746

Epoch: 6| Step: 9
Training loss: 3.264994145106255
Validation loss: 2.4678853074288845

Epoch: 6| Step: 10
Training loss: 2.43084159500066
Validation loss: 2.4678410655553384

Epoch: 6| Step: 11
Training loss: 2.6762938962042013
Validation loss: 2.471901326378775

Epoch: 6| Step: 12
Training loss: 3.3471474188487513
Validation loss: 2.4753462755023388

Epoch: 6| Step: 13
Training loss: 3.316833540458041
Validation loss: 2.476209244785986

Epoch: 105| Step: 0
Training loss: 2.855916250416761
Validation loss: 2.483169329149104

Epoch: 6| Step: 1
Training loss: 2.0073328298700908
Validation loss: 2.4733376163519325

Epoch: 6| Step: 2
Training loss: 2.697805650309759
Validation loss: 2.467017283654311

Epoch: 6| Step: 3
Training loss: 3.0579108283325076
Validation loss: 2.455711916844224

Epoch: 6| Step: 4
Training loss: 1.7098993086588323
Validation loss: 2.4768293749414116

Epoch: 6| Step: 5
Training loss: 2.9197366815226182
Validation loss: 2.5150960301004615

Epoch: 6| Step: 6
Training loss: 3.162127922998026
Validation loss: 2.5418452404061282

Epoch: 6| Step: 7
Training loss: 2.7299281991871664
Validation loss: 2.550746398948004

Epoch: 6| Step: 8
Training loss: 3.573855855894434
Validation loss: 2.57347385337906

Epoch: 6| Step: 9
Training loss: 2.2945434777801315
Validation loss: 2.496651225776733

Epoch: 6| Step: 10
Training loss: 3.0155155774756075
Validation loss: 2.475289594733089

Epoch: 6| Step: 11
Training loss: 3.0465732522857496
Validation loss: 2.4646140766217437

Epoch: 6| Step: 12
Training loss: 2.9332793736552154
Validation loss: 2.460991313272387

Epoch: 6| Step: 13
Training loss: 3.2524363848881257
Validation loss: 2.4637725859909563

Epoch: 106| Step: 0
Training loss: 3.262792791915925
Validation loss: 2.4717403778181053

Epoch: 6| Step: 1
Training loss: 2.465753305865565
Validation loss: 2.4787911395842515

Epoch: 6| Step: 2
Training loss: 3.1609453081457874
Validation loss: 2.47328239977987

Epoch: 6| Step: 3
Training loss: 2.9628194902263347
Validation loss: 2.4658282410144814

Epoch: 6| Step: 4
Training loss: 3.001230305484339
Validation loss: 2.465104630466642

Epoch: 6| Step: 5
Training loss: 3.2161353889738473
Validation loss: 2.465525366331291

Epoch: 6| Step: 6
Training loss: 2.7494379683019816
Validation loss: 2.4778996652205483

Epoch: 6| Step: 7
Training loss: 2.4041294811244502
Validation loss: 2.483485234794294

Epoch: 6| Step: 8
Training loss: 2.7134640927248928
Validation loss: 2.5115531956517527

Epoch: 6| Step: 9
Training loss: 2.71864090623885
Validation loss: 2.521994501720976

Epoch: 6| Step: 10
Training loss: 3.4339797982280955
Validation loss: 2.5443406955647103

Epoch: 6| Step: 11
Training loss: 2.5078950196947183
Validation loss: 2.527136119895197

Epoch: 6| Step: 12
Training loss: 2.022203341536826
Validation loss: 2.504747100430688

Epoch: 6| Step: 13
Training loss: 2.7095199528586176
Validation loss: 2.49694036278879

Epoch: 107| Step: 0
Training loss: 2.2885783337685695
Validation loss: 2.4788334826751046

Epoch: 6| Step: 1
Training loss: 2.5447905265773283
Validation loss: 2.471698226447868

Epoch: 6| Step: 2
Training loss: 2.4268772763603357
Validation loss: 2.4652949994129036

Epoch: 6| Step: 3
Training loss: 2.9266866141344066
Validation loss: 2.465734425903642

Epoch: 6| Step: 4
Training loss: 1.9643169326283125
Validation loss: 2.459692510628831

Epoch: 6| Step: 5
Training loss: 2.483395173329058
Validation loss: 2.461427199288174

Epoch: 6| Step: 6
Training loss: 3.549118340843885
Validation loss: 2.4620145478404276

Epoch: 6| Step: 7
Training loss: 2.666243301004041
Validation loss: 2.463876033769663

Epoch: 6| Step: 8
Training loss: 2.649872427694707
Validation loss: 2.464571679587495

Epoch: 6| Step: 9
Training loss: 2.210393077018574
Validation loss: 2.4630060099852833

Epoch: 6| Step: 10
Training loss: 3.744551706208468
Validation loss: 2.4625862646996945

Epoch: 6| Step: 11
Training loss: 3.2166121707180557
Validation loss: 2.4643749610785384

Epoch: 6| Step: 12
Training loss: 2.9109514826849825
Validation loss: 2.4812631836231978

Epoch: 6| Step: 13
Training loss: 2.915500316836399
Validation loss: 2.489277788001937

Epoch: 108| Step: 0
Training loss: 2.444903842306732
Validation loss: 2.4953094574662282

Epoch: 6| Step: 1
Training loss: 2.6501528605872453
Validation loss: 2.5046754852420876

Epoch: 6| Step: 2
Training loss: 2.3163208197911085
Validation loss: 2.5413028578376746

Epoch: 6| Step: 3
Training loss: 2.73845851612831
Validation loss: 2.5581586956197935

Epoch: 6| Step: 4
Training loss: 3.2440860934327875
Validation loss: 2.611791942357183

Epoch: 6| Step: 5
Training loss: 2.6626059390201036
Validation loss: 2.5926092065339703

Epoch: 6| Step: 6
Training loss: 2.9266248640349515
Validation loss: 2.5486022258198804

Epoch: 6| Step: 7
Training loss: 3.4465915096458404
Validation loss: 2.5189386056010252

Epoch: 6| Step: 8
Training loss: 2.9133502815969883
Validation loss: 2.492780318339089

Epoch: 6| Step: 9
Training loss: 2.6098948434860696
Validation loss: 2.4731641761360668

Epoch: 6| Step: 10
Training loss: 2.5883917557246847
Validation loss: 2.4551509018488007

Epoch: 6| Step: 11
Training loss: 2.9434429680813685
Validation loss: 2.4548822309904414

Epoch: 6| Step: 12
Training loss: 2.9836004560284843
Validation loss: 2.4577332340016977

Epoch: 6| Step: 13
Training loss: 2.0901070402195185
Validation loss: 2.455406218795939

Epoch: 109| Step: 0
Training loss: 3.3755441862708295
Validation loss: 2.4573323422873186

Epoch: 6| Step: 1
Training loss: 3.154675232484119
Validation loss: 2.4560961282718035

Epoch: 6| Step: 2
Training loss: 2.7976400511783197
Validation loss: 2.4573221824625726

Epoch: 6| Step: 3
Training loss: 2.6064444892456082
Validation loss: 2.46478442922582

Epoch: 6| Step: 4
Training loss: 2.363643397807612
Validation loss: 2.4788000866934925

Epoch: 6| Step: 5
Training loss: 2.990725486286926
Validation loss: 2.507070815117306

Epoch: 6| Step: 6
Training loss: 3.1238688138215402
Validation loss: 2.541201429051444

Epoch: 6| Step: 7
Training loss: 3.130389639395325
Validation loss: 2.5348649827086325

Epoch: 6| Step: 8
Training loss: 2.179669451895206
Validation loss: 2.5081923222120843

Epoch: 6| Step: 9
Training loss: 1.5257169445294296
Validation loss: 2.5181503028192833

Epoch: 6| Step: 10
Training loss: 2.822481879690575
Validation loss: 2.5035108852749453

Epoch: 6| Step: 11
Training loss: 2.799254188664607
Validation loss: 2.476804329725655

Epoch: 6| Step: 12
Training loss: 2.7282895627372232
Validation loss: 2.47167632902517

Epoch: 6| Step: 13
Training loss: 3.010062508171647
Validation loss: 2.458693305041203

Epoch: 110| Step: 0
Training loss: 2.7713499137407513
Validation loss: 2.4608211252172447

Epoch: 6| Step: 1
Training loss: 2.04948189398759
Validation loss: 2.4585873910707448

Epoch: 6| Step: 2
Training loss: 2.766933498001143
Validation loss: 2.458861756370996

Epoch: 6| Step: 3
Training loss: 2.8073236089716307
Validation loss: 2.465588088039824

Epoch: 6| Step: 4
Training loss: 2.839241394218025
Validation loss: 2.4599707899369485

Epoch: 6| Step: 5
Training loss: 3.5613870053300016
Validation loss: 2.4573569860908413

Epoch: 6| Step: 6
Training loss: 2.9847643533341257
Validation loss: 2.4647590463130293

Epoch: 6| Step: 7
Training loss: 2.505885444440096
Validation loss: 2.463568860662524

Epoch: 6| Step: 8
Training loss: 2.8042972048737878
Validation loss: 2.468889357388948

Epoch: 6| Step: 9
Training loss: 2.5995017014351345
Validation loss: 2.4698123196135437

Epoch: 6| Step: 10
Training loss: 2.9467323179684586
Validation loss: 2.464350466517707

Epoch: 6| Step: 11
Training loss: 2.8441185345634703
Validation loss: 2.4657634304312284

Epoch: 6| Step: 12
Training loss: 2.676151712208292
Validation loss: 2.4625653762263635

Epoch: 6| Step: 13
Training loss: 1.9451847264254425
Validation loss: 2.4664736380652434

Epoch: 111| Step: 0
Training loss: 2.500706286797954
Validation loss: 2.474883431405128

Epoch: 6| Step: 1
Training loss: 2.693457100293793
Validation loss: 2.480226361768993

Epoch: 6| Step: 2
Training loss: 3.075675648220111
Validation loss: 2.4923009772987337

Epoch: 6| Step: 3
Training loss: 2.773539022817254
Validation loss: 2.513640450298231

Epoch: 6| Step: 4
Training loss: 2.8167893655751204
Validation loss: 2.527072588463195

Epoch: 6| Step: 5
Training loss: 2.7362341963380024
Validation loss: 2.512571584765072

Epoch: 6| Step: 6
Training loss: 2.491124036851634
Validation loss: 2.4867475658973452

Epoch: 6| Step: 7
Training loss: 2.726784246221078
Validation loss: 2.4806305460233493

Epoch: 6| Step: 8
Training loss: 2.7267770764755377
Validation loss: 2.4589996901699704

Epoch: 6| Step: 9
Training loss: 2.450504725879968
Validation loss: 2.459465998206178

Epoch: 6| Step: 10
Training loss: 2.8661029645868066
Validation loss: 2.4518113447440175

Epoch: 6| Step: 11
Training loss: 3.078665284119179
Validation loss: 2.4530247921969823

Epoch: 6| Step: 12
Training loss: 3.40427096209838
Validation loss: 2.457562592912426

Epoch: 6| Step: 13
Training loss: 2.1930852159885177
Validation loss: 2.4588735868694918

Epoch: 112| Step: 0
Training loss: 2.375856345538128
Validation loss: 2.4615200204258056

Epoch: 6| Step: 1
Training loss: 2.9450939309857507
Validation loss: 2.459480670374029

Epoch: 6| Step: 2
Training loss: 2.41291243432298
Validation loss: 2.4604957237426963

Epoch: 6| Step: 3
Training loss: 3.4248719351556485
Validation loss: 2.4780410447614045

Epoch: 6| Step: 4
Training loss: 3.0626139716914387
Validation loss: 2.4791597717994476

Epoch: 6| Step: 5
Training loss: 2.1757263505402746
Validation loss: 2.482484478581174

Epoch: 6| Step: 6
Training loss: 2.715931011908088
Validation loss: 2.482649642799042

Epoch: 6| Step: 7
Training loss: 3.01488948410707
Validation loss: 2.477953176859007

Epoch: 6| Step: 8
Training loss: 2.390992778337997
Validation loss: 2.5266910051188836

Epoch: 6| Step: 9
Training loss: 3.3566413580184378
Validation loss: 2.5223118920539607

Epoch: 6| Step: 10
Training loss: 2.856765974255686
Validation loss: 2.505297046136409

Epoch: 6| Step: 11
Training loss: 2.4704120690718026
Validation loss: 2.493299536203142

Epoch: 6| Step: 12
Training loss: 2.171438269306698
Validation loss: 2.4648382417173855

Epoch: 6| Step: 13
Training loss: 2.7722820615287898
Validation loss: 2.4567519542289733

Epoch: 113| Step: 0
Training loss: 3.007240617559056
Validation loss: 2.454569890929824

Epoch: 6| Step: 1
Training loss: 3.0464885760064475
Validation loss: 2.457879942528067

Epoch: 6| Step: 2
Training loss: 2.185943812919483
Validation loss: 2.4579523256050795

Epoch: 6| Step: 3
Training loss: 2.667865890821252
Validation loss: 2.469827925225784

Epoch: 6| Step: 4
Training loss: 2.616744183244597
Validation loss: 2.4626011608369107

Epoch: 6| Step: 5
Training loss: 2.7818234313285197
Validation loss: 2.4607054648364644

Epoch: 6| Step: 6
Training loss: 2.714393896800858
Validation loss: 2.468071960365091

Epoch: 6| Step: 7
Training loss: 3.2536185733896277
Validation loss: 2.4665602243943607

Epoch: 6| Step: 8
Training loss: 1.9937111208003844
Validation loss: 2.4524033300526216

Epoch: 6| Step: 9
Training loss: 2.6857657048628116
Validation loss: 2.4503816107348193

Epoch: 6| Step: 10
Training loss: 2.8476321372435907
Validation loss: 2.448709495059643

Epoch: 6| Step: 11
Training loss: 2.961680457477165
Validation loss: 2.4493661621456124

Epoch: 6| Step: 12
Training loss: 3.1593739374689114
Validation loss: 2.453240811903718

Epoch: 6| Step: 13
Training loss: 2.4686827831533744
Validation loss: 2.459300838552675

Epoch: 114| Step: 0
Training loss: 2.803108812368341
Validation loss: 2.4670571769168808

Epoch: 6| Step: 1
Training loss: 3.2042228492074036
Validation loss: 2.4676303196200418

Epoch: 6| Step: 2
Training loss: 3.143847885276391
Validation loss: 2.4777198251612025

Epoch: 6| Step: 3
Training loss: 3.100417841161885
Validation loss: 2.496460558438812

Epoch: 6| Step: 4
Training loss: 2.6569886022171816
Validation loss: 2.513879860476316

Epoch: 6| Step: 5
Training loss: 2.617214282453915
Validation loss: 2.5188576130601295

Epoch: 6| Step: 6
Training loss: 2.962643738168922
Validation loss: 2.5087109316236917

Epoch: 6| Step: 7
Training loss: 2.5571111445732435
Validation loss: 2.487868886213937

Epoch: 6| Step: 8
Training loss: 3.212996887490468
Validation loss: 2.452399451769567

Epoch: 6| Step: 9
Training loss: 2.4547110126032163
Validation loss: 2.453003603876798

Epoch: 6| Step: 10
Training loss: 2.491713715005965
Validation loss: 2.44429142146098

Epoch: 6| Step: 11
Training loss: 2.538915354059553
Validation loss: 2.448081011329216

Epoch: 6| Step: 12
Training loss: 2.244343747606831
Validation loss: 2.444560282054793

Epoch: 6| Step: 13
Training loss: 2.509369838989575
Validation loss: 2.4381521607800893

Epoch: 115| Step: 0
Training loss: 3.08800798322209
Validation loss: 2.447107868897495

Epoch: 6| Step: 1
Training loss: 2.6790146942305255
Validation loss: 2.4440516749525774

Epoch: 6| Step: 2
Training loss: 2.63745902513251
Validation loss: 2.446074367258051

Epoch: 6| Step: 3
Training loss: 2.2537442947459354
Validation loss: 2.442765657108399

Epoch: 6| Step: 4
Training loss: 3.610329770060345
Validation loss: 2.4492037169941474

Epoch: 6| Step: 5
Training loss: 2.507268543609593
Validation loss: 2.4504982275962663

Epoch: 6| Step: 6
Training loss: 2.9578245200000084
Validation loss: 2.458106786746477

Epoch: 6| Step: 7
Training loss: 2.8601688471216886
Validation loss: 2.4703004765019965

Epoch: 6| Step: 8
Training loss: 2.6342881592253646
Validation loss: 2.4863159188667736

Epoch: 6| Step: 9
Training loss: 1.757993086969456
Validation loss: 2.511335060350292

Epoch: 6| Step: 10
Training loss: 3.4452457897275983
Validation loss: 2.5400571580284934

Epoch: 6| Step: 11
Training loss: 3.1558979706801
Validation loss: 2.5078523290435446

Epoch: 6| Step: 12
Training loss: 1.833566636355176
Validation loss: 2.474448524878834

Epoch: 6| Step: 13
Training loss: 2.4875684642475364
Validation loss: 2.4395035943312946

Epoch: 116| Step: 0
Training loss: 2.8383660965031132
Validation loss: 2.4453923566424316

Epoch: 6| Step: 1
Training loss: 3.0066021750639242
Validation loss: 2.456222095491207

Epoch: 6| Step: 2
Training loss: 2.87915501755503
Validation loss: 2.4624191082251126

Epoch: 6| Step: 3
Training loss: 2.473983818056787
Validation loss: 2.4678667907394645

Epoch: 6| Step: 4
Training loss: 2.869226380398148
Validation loss: 2.4645928516709845

Epoch: 6| Step: 5
Training loss: 2.2609404441956684
Validation loss: 2.464102362404348

Epoch: 6| Step: 6
Training loss: 2.0375947895116724
Validation loss: 2.4565449907181685

Epoch: 6| Step: 7
Training loss: 3.4271428219966675
Validation loss: 2.4629220237661666

Epoch: 6| Step: 8
Training loss: 2.0674961727526666
Validation loss: 2.455346277428909

Epoch: 6| Step: 9
Training loss: 2.452581065915599
Validation loss: 2.4744835667891323

Epoch: 6| Step: 10
Training loss: 3.0336916813158776
Validation loss: 2.480818559977246

Epoch: 6| Step: 11
Training loss: 2.95801764581355
Validation loss: 2.473649399816676

Epoch: 6| Step: 12
Training loss: 3.3933738429781073
Validation loss: 2.4789927266389022

Epoch: 6| Step: 13
Training loss: 2.8227005672908754
Validation loss: 2.4972428469132217

Epoch: 117| Step: 0
Training loss: 2.7077012327020444
Validation loss: 2.48762884319063

Epoch: 6| Step: 1
Training loss: 2.3631000543915675
Validation loss: 2.490535062121088

Epoch: 6| Step: 2
Training loss: 2.6968763154734985
Validation loss: 2.4798419682751205

Epoch: 6| Step: 3
Training loss: 2.761601252666512
Validation loss: 2.480536563157229

Epoch: 6| Step: 4
Training loss: 2.8861815245622737
Validation loss: 2.4621445208466697

Epoch: 6| Step: 5
Training loss: 2.865731932663573
Validation loss: 2.4553538544910767

Epoch: 6| Step: 6
Training loss: 3.1213962374930144
Validation loss: 2.4643223374193792

Epoch: 6| Step: 7
Training loss: 2.586700142597913
Validation loss: 2.470307875897548

Epoch: 6| Step: 8
Training loss: 2.9287306380110163
Validation loss: 2.473955431139312

Epoch: 6| Step: 9
Training loss: 2.7940195521091757
Validation loss: 2.4648568092401844

Epoch: 6| Step: 10
Training loss: 2.622138780094214
Validation loss: 2.449217780739211

Epoch: 6| Step: 11
Training loss: 2.72020489580112
Validation loss: 2.4552693047624543

Epoch: 6| Step: 12
Training loss: 3.0035298561833645
Validation loss: 2.4508257289552504

Epoch: 6| Step: 13
Training loss: 2.0240609523054043
Validation loss: 2.4560567782392795

Epoch: 118| Step: 0
Training loss: 2.4256654671819855
Validation loss: 2.4439231539716983

Epoch: 6| Step: 1
Training loss: 2.3599513278403412
Validation loss: 2.451724203552525

Epoch: 6| Step: 2
Training loss: 2.3638286870793177
Validation loss: 2.4441347740192056

Epoch: 6| Step: 3
Training loss: 2.860667952585328
Validation loss: 2.434450625905493

Epoch: 6| Step: 4
Training loss: 2.349791610893192
Validation loss: 2.4380024806703893

Epoch: 6| Step: 5
Training loss: 2.870060201405605
Validation loss: 2.437405018813562

Epoch: 6| Step: 6
Training loss: 3.041763321547073
Validation loss: 2.4389843056536535

Epoch: 6| Step: 7
Training loss: 2.7010208495887866
Validation loss: 2.4440268214641314

Epoch: 6| Step: 8
Training loss: 2.568862645261939
Validation loss: 2.459607322066561

Epoch: 6| Step: 9
Training loss: 2.5023784767239916
Validation loss: 2.4587864003792594

Epoch: 6| Step: 10
Training loss: 3.1377007834336057
Validation loss: 2.474603363212916

Epoch: 6| Step: 11
Training loss: 3.0894795238077473
Validation loss: 2.486277845203427

Epoch: 6| Step: 12
Training loss: 2.812231517268799
Validation loss: 2.52204911228347

Epoch: 6| Step: 13
Training loss: 3.4154972928560965
Validation loss: 2.538103844941122

Epoch: 119| Step: 0
Training loss: 3.196563699580165
Validation loss: 2.5091918008423426

Epoch: 6| Step: 1
Training loss: 2.8582292773228684
Validation loss: 2.5045113630884432

Epoch: 6| Step: 2
Training loss: 2.8048302234261655
Validation loss: 2.4788469382606433

Epoch: 6| Step: 3
Training loss: 2.173036004285624
Validation loss: 2.459666621781105

Epoch: 6| Step: 4
Training loss: 2.106042334396443
Validation loss: 2.446310851821435

Epoch: 6| Step: 5
Training loss: 2.233943337311864
Validation loss: 2.443032710705476

Epoch: 6| Step: 6
Training loss: 2.542230783198391
Validation loss: 2.4399289780415154

Epoch: 6| Step: 7
Training loss: 2.9663394175996234
Validation loss: 2.4351466481995687

Epoch: 6| Step: 8
Training loss: 2.645251492981453
Validation loss: 2.436853256226837

Epoch: 6| Step: 9
Training loss: 2.5185134132911116
Validation loss: 2.435476790215969

Epoch: 6| Step: 10
Training loss: 2.7680174398809974
Validation loss: 2.435681018022797

Epoch: 6| Step: 11
Training loss: 3.6736048742640786
Validation loss: 2.4287969606317183

Epoch: 6| Step: 12
Training loss: 2.6347080730602817
Validation loss: 2.439782833489344

Epoch: 6| Step: 13
Training loss: 3.3065830863367314
Validation loss: 2.4324664440698114

Epoch: 120| Step: 0
Training loss: 3.0267152195311673
Validation loss: 2.4599972591773382

Epoch: 6| Step: 1
Training loss: 2.888817959509743
Validation loss: 2.469316589128247

Epoch: 6| Step: 2
Training loss: 2.5895409500528723
Validation loss: 2.4890642943585424

Epoch: 6| Step: 3
Training loss: 2.746124744918654
Validation loss: 2.49193697982535

Epoch: 6| Step: 4
Training loss: 2.771082950524752
Validation loss: 2.487497796308993

Epoch: 6| Step: 5
Training loss: 2.357334290199316
Validation loss: 2.4977467042040296

Epoch: 6| Step: 6
Training loss: 2.9323721423491915
Validation loss: 2.48692703763686

Epoch: 6| Step: 7
Training loss: 2.8882297799165286
Validation loss: 2.4786948901855084

Epoch: 6| Step: 8
Training loss: 2.8840808920977037
Validation loss: 2.4592883888201627

Epoch: 6| Step: 9
Training loss: 2.4533421122697963
Validation loss: 2.437197996519319

Epoch: 6| Step: 10
Training loss: 2.716033279754392
Validation loss: 2.431107710211623

Epoch: 6| Step: 11
Training loss: 2.790289771779635
Validation loss: 2.4360203076146285

Epoch: 6| Step: 12
Training loss: 2.5214872116439313
Validation loss: 2.4293184037305924

Epoch: 6| Step: 13
Training loss: 2.9846012369254677
Validation loss: 2.433156997465506

Epoch: 121| Step: 0
Training loss: 2.579641555016542
Validation loss: 2.4329808741272636

Epoch: 6| Step: 1
Training loss: 2.5060411894230143
Validation loss: 2.432285984885797

Epoch: 6| Step: 2
Training loss: 3.0831242739624183
Validation loss: 2.4257567715586745

Epoch: 6| Step: 3
Training loss: 3.1414670811673493
Validation loss: 2.4377070366097002

Epoch: 6| Step: 4
Training loss: 2.9074794670816617
Validation loss: 2.4609383813062458

Epoch: 6| Step: 5
Training loss: 2.358431494818786
Validation loss: 2.4960688354290212

Epoch: 6| Step: 6
Training loss: 2.956987065699454
Validation loss: 2.5109167392785547

Epoch: 6| Step: 7
Training loss: 2.4819823445469105
Validation loss: 2.524145323405289

Epoch: 6| Step: 8
Training loss: 3.069946577868546
Validation loss: 2.5173748271617034

Epoch: 6| Step: 9
Training loss: 2.7545570416211085
Validation loss: 2.5283341267878607

Epoch: 6| Step: 10
Training loss: 2.9796783079056564
Validation loss: 2.5145548390882753

Epoch: 6| Step: 11
Training loss: 1.86824765295052
Validation loss: 2.4892875171956304

Epoch: 6| Step: 12
Training loss: 2.632979299994905
Validation loss: 2.474233404561215

Epoch: 6| Step: 13
Training loss: 3.4546052685720126
Validation loss: 2.446152823490221

Epoch: 122| Step: 0
Training loss: 3.004852185668181
Validation loss: 2.4375182835535028

Epoch: 6| Step: 1
Training loss: 2.649836168083205
Validation loss: 2.439870642314987

Epoch: 6| Step: 2
Training loss: 2.9253581292426696
Validation loss: 2.4375997774807456

Epoch: 6| Step: 3
Training loss: 2.82343067026922
Validation loss: 2.4633993158710776

Epoch: 6| Step: 4
Training loss: 2.440515462490711
Validation loss: 2.4614306290311836

Epoch: 6| Step: 5
Training loss: 2.745038064300163
Validation loss: 2.490008017579002

Epoch: 6| Step: 6
Training loss: 2.8380366351482933
Validation loss: 2.5533898597696996

Epoch: 6| Step: 7
Training loss: 3.0023903860241647
Validation loss: 2.579640361465791

Epoch: 6| Step: 8
Training loss: 3.304875650302874
Validation loss: 2.6376969783780266

Epoch: 6| Step: 9
Training loss: 2.6248459543713585
Validation loss: 2.5524307402937274

Epoch: 6| Step: 10
Training loss: 2.925730237528834
Validation loss: 2.534111715475267

Epoch: 6| Step: 11
Training loss: 1.761337611210316
Validation loss: 2.4956404883791006

Epoch: 6| Step: 12
Training loss: 2.534428331822924
Validation loss: 2.4843147751916344

Epoch: 6| Step: 13
Training loss: 3.662984530846093
Validation loss: 2.480888413234923

Epoch: 123| Step: 0
Training loss: 2.553017259843505
Validation loss: 2.474953461498795

Epoch: 6| Step: 1
Training loss: 2.311659789163397
Validation loss: 2.4505125658535

Epoch: 6| Step: 2
Training loss: 1.9697421767864634
Validation loss: 2.445412567805451

Epoch: 6| Step: 3
Training loss: 2.8744950887731324
Validation loss: 2.4336247135122253

Epoch: 6| Step: 4
Training loss: 2.746333799546496
Validation loss: 2.4897643081997596

Epoch: 6| Step: 5
Training loss: 2.8857456575169493
Validation loss: 2.497645712395718

Epoch: 6| Step: 6
Training loss: 2.739047521451219
Validation loss: 2.5373856250432394

Epoch: 6| Step: 7
Training loss: 2.973295566621196
Validation loss: 2.5526869010965756

Epoch: 6| Step: 8
Training loss: 2.493386485439328
Validation loss: 2.5522548149982534

Epoch: 6| Step: 9
Training loss: 3.487157283884165
Validation loss: 2.5910713685152498

Epoch: 6| Step: 10
Training loss: 2.193459050808668
Validation loss: 2.5414046901106477

Epoch: 6| Step: 11
Training loss: 2.841104135927024
Validation loss: 2.5182845423074265

Epoch: 6| Step: 12
Training loss: 2.926744941527838
Validation loss: 2.4529623512370162

Epoch: 6| Step: 13
Training loss: 3.428423185776733
Validation loss: 2.4406778835164666

Epoch: 124| Step: 0
Training loss: 2.919637547559397
Validation loss: 2.451337737648304

Epoch: 6| Step: 1
Training loss: 2.648726095944133
Validation loss: 2.449532786001615

Epoch: 6| Step: 2
Training loss: 2.6247093403067985
Validation loss: 2.439069267492117

Epoch: 6| Step: 3
Training loss: 2.670858803407941
Validation loss: 2.4448294087860605

Epoch: 6| Step: 4
Training loss: 2.585480710162911
Validation loss: 2.4529518947865885

Epoch: 6| Step: 5
Training loss: 3.3035583731492753
Validation loss: 2.472646658579633

Epoch: 6| Step: 6
Training loss: 2.818027490014737
Validation loss: 2.484495454523837

Epoch: 6| Step: 7
Training loss: 2.884461796902168
Validation loss: 2.482890798077211

Epoch: 6| Step: 8
Training loss: 2.1332336680655404
Validation loss: 2.493783063615647

Epoch: 6| Step: 9
Training loss: 2.735084659584192
Validation loss: 2.4986623548945746

Epoch: 6| Step: 10
Training loss: 2.4224682481257602
Validation loss: 2.5237048435547953

Epoch: 6| Step: 11
Training loss: 2.591349766563923
Validation loss: 2.5417693319285033

Epoch: 6| Step: 12
Training loss: 3.1166592487376126
Validation loss: 2.5341647255156086

Epoch: 6| Step: 13
Training loss: 2.774284813625273
Validation loss: 2.497597850865973

Epoch: 125| Step: 0
Training loss: 2.100970897576494
Validation loss: 2.466714089363735

Epoch: 6| Step: 1
Training loss: 2.5501657768666632
Validation loss: 2.445404627613292

Epoch: 6| Step: 2
Training loss: 2.519688422453526
Validation loss: 2.4345640807454187

Epoch: 6| Step: 3
Training loss: 2.8798131044992665
Validation loss: 2.4344148234561414

Epoch: 6| Step: 4
Training loss: 3.005732146328683
Validation loss: 2.4391716020481633

Epoch: 6| Step: 5
Training loss: 2.428341998955584
Validation loss: 2.432802182621039

Epoch: 6| Step: 6
Training loss: 2.5579534064218308
Validation loss: 2.4281599433278584

Epoch: 6| Step: 7
Training loss: 3.108829622986094
Validation loss: 2.4247315940240854

Epoch: 6| Step: 8
Training loss: 2.960148285940395
Validation loss: 2.4203791883901142

Epoch: 6| Step: 9
Training loss: 2.7790901284113647
Validation loss: 2.4405786420674045

Epoch: 6| Step: 10
Training loss: 2.9973477719605146
Validation loss: 2.453400292255504

Epoch: 6| Step: 11
Training loss: 3.0665804090669853
Validation loss: 2.4849969177431657

Epoch: 6| Step: 12
Training loss: 2.4579643576065457
Validation loss: 2.499092632647019

Epoch: 6| Step: 13
Training loss: 2.6739386904185345
Validation loss: 2.5226505583626686

Testing loss: 2.7500458376368444
