Epoch: 1| Step: 0
Training loss: 5.902143392942887
Validation loss: 5.8067099367922355

Epoch: 6| Step: 1
Training loss: 5.326451550573371
Validation loss: 5.783968789987507

Epoch: 6| Step: 2
Training loss: 6.553252471135188
Validation loss: 5.761888166063919

Epoch: 6| Step: 3
Training loss: 5.948105184993625
Validation loss: 5.737617308565528

Epoch: 6| Step: 4
Training loss: 5.087442248717247
Validation loss: 5.7102206764100165

Epoch: 6| Step: 5
Training loss: 5.863144295431653
Validation loss: 5.679640914812382

Epoch: 6| Step: 6
Training loss: 6.753992665908984
Validation loss: 5.644729814579104

Epoch: 6| Step: 7
Training loss: 6.765139520507585
Validation loss: 5.60656706026074

Epoch: 6| Step: 8
Training loss: 4.571175883325736
Validation loss: 5.56383056876006

Epoch: 6| Step: 9
Training loss: 4.419753141802453
Validation loss: 5.517285183785525

Epoch: 6| Step: 10
Training loss: 5.68200485200282
Validation loss: 5.468059147151396

Epoch: 6| Step: 11
Training loss: 5.15758353819802
Validation loss: 5.414833702767076

Epoch: 6| Step: 12
Training loss: 4.815673772427519
Validation loss: 5.359890545189835

Epoch: 6| Step: 13
Training loss: 5.709773789182266
Validation loss: 5.30199762335483

Epoch: 2| Step: 0
Training loss: 5.544228365621858
Validation loss: 5.2452340592056395

Epoch: 6| Step: 1
Training loss: 4.023030973470249
Validation loss: 5.187163595951665

Epoch: 6| Step: 2
Training loss: 4.599201730210992
Validation loss: 5.12954348844206

Epoch: 6| Step: 3
Training loss: 4.2892990741905095
Validation loss: 5.07203274288991

Epoch: 6| Step: 4
Training loss: 4.913405915806412
Validation loss: 5.0103988287274355

Epoch: 6| Step: 5
Training loss: 5.721324570419676
Validation loss: 4.9480185898374165

Epoch: 6| Step: 6
Training loss: 4.57196275961887
Validation loss: 4.887880413499069

Epoch: 6| Step: 7
Training loss: 5.672176300537123
Validation loss: 4.826136329393057

Epoch: 6| Step: 8
Training loss: 4.982174570009056
Validation loss: 4.767968496559228

Epoch: 6| Step: 9
Training loss: 5.838658037026988
Validation loss: 4.7071879426901315

Epoch: 6| Step: 10
Training loss: 4.098396518050082
Validation loss: 4.648039653101816

Epoch: 6| Step: 11
Training loss: 4.17762685586573
Validation loss: 4.596466087445807

Epoch: 6| Step: 12
Training loss: 4.902129562987838
Validation loss: 4.546368154198332

Epoch: 6| Step: 13
Training loss: 5.560267482608135
Validation loss: 4.497497888431971

Epoch: 3| Step: 0
Training loss: 4.347442594284105
Validation loss: 4.453761834039791

Epoch: 6| Step: 1
Training loss: 3.3165704441649355
Validation loss: 4.424827604213001

Epoch: 6| Step: 2
Training loss: 4.845338819248395
Validation loss: 4.390096861038205

Epoch: 6| Step: 3
Training loss: 3.9747895670917135
Validation loss: 4.338743695901379

Epoch: 6| Step: 4
Training loss: 3.731672641964607
Validation loss: 4.303913017676858

Epoch: 6| Step: 5
Training loss: 3.882834236805668
Validation loss: 4.289890708362071

Epoch: 6| Step: 6
Training loss: 4.042006226003949
Validation loss: 4.2663493189989365

Epoch: 6| Step: 7
Training loss: 5.078341717130432
Validation loss: 4.235318754128399

Epoch: 6| Step: 8
Training loss: 4.165748698522066
Validation loss: 4.203904522101474

Epoch: 6| Step: 9
Training loss: 4.446810129835829
Validation loss: 4.193246379986127

Epoch: 6| Step: 10
Training loss: 4.407909757074624
Validation loss: 4.1870722704528

Epoch: 6| Step: 11
Training loss: 4.788264695093955
Validation loss: 4.162122454007498

Epoch: 6| Step: 12
Training loss: 5.49986735097274
Validation loss: 4.133983305485131

Epoch: 6| Step: 13
Training loss: 4.285909748161383
Validation loss: 4.117020834572715

Epoch: 4| Step: 0
Training loss: 3.76193727866681
Validation loss: 4.109623931752668

Epoch: 6| Step: 1
Training loss: 4.896395170831835
Validation loss: 4.102145805856655

Epoch: 6| Step: 2
Training loss: 4.517588469035391
Validation loss: 4.090311121045482

Epoch: 6| Step: 3
Training loss: 5.19400480634594
Validation loss: 4.071926197405098

Epoch: 6| Step: 4
Training loss: 3.96061389210609
Validation loss: 4.052747881625051

Epoch: 6| Step: 5
Training loss: 4.005301300411753
Validation loss: 4.04207093923614

Epoch: 6| Step: 6
Training loss: 4.9396905989029944
Validation loss: 4.0334794878803875

Epoch: 6| Step: 7
Training loss: 3.548540572933316
Validation loss: 4.0274819037808225

Epoch: 6| Step: 8
Training loss: 4.17717780230742
Validation loss: 4.0136660600250895

Epoch: 6| Step: 9
Training loss: 2.9694460404235845
Validation loss: 3.9950946306272486

Epoch: 6| Step: 10
Training loss: 4.594336647410192
Validation loss: 3.9840264473744083

Epoch: 6| Step: 11
Training loss: 4.118131062567865
Validation loss: 3.9755051748786356

Epoch: 6| Step: 12
Training loss: 3.4487379004614285
Validation loss: 3.965763215169566

Epoch: 6| Step: 13
Training loss: 3.5851882451006136
Validation loss: 3.9594691298018714

Epoch: 5| Step: 0
Training loss: 3.8600134688226397
Validation loss: 3.948645177947796

Epoch: 6| Step: 1
Training loss: 4.3742332876583525
Validation loss: 3.9386249347479656

Epoch: 6| Step: 2
Training loss: 4.219089070575451
Validation loss: 3.928358580170696

Epoch: 6| Step: 3
Training loss: 5.093109652282757
Validation loss: 3.9181107237374935

Epoch: 6| Step: 4
Training loss: 4.278238169898785
Validation loss: 3.9105103025228165

Epoch: 6| Step: 5
Training loss: 3.855676770999711
Validation loss: 3.8983842452885993

Epoch: 6| Step: 6
Training loss: 3.540798005930136
Validation loss: 3.8868177030633895

Epoch: 6| Step: 7
Training loss: 4.478849296267598
Validation loss: 3.8773099595025897

Epoch: 6| Step: 8
Training loss: 3.7060157019935644
Validation loss: 3.8689290884532404

Epoch: 6| Step: 9
Training loss: 4.157099357381139
Validation loss: 3.8627719159137004

Epoch: 6| Step: 10
Training loss: 4.188288827870406
Validation loss: 3.8511288742469727

Epoch: 6| Step: 11
Training loss: 2.7588993340793526
Validation loss: 3.8395791704171325

Epoch: 6| Step: 12
Training loss: 4.366674075714892
Validation loss: 3.8310148781560365

Epoch: 6| Step: 13
Training loss: 2.7486225493106726
Validation loss: 3.821149720093583

Epoch: 6| Step: 0
Training loss: 3.5747985036125693
Validation loss: 3.8123116388696943

Epoch: 6| Step: 1
Training loss: 4.8791200882631856
Validation loss: 3.804163171460878

Epoch: 6| Step: 2
Training loss: 4.03951203373664
Validation loss: 3.794346172384808

Epoch: 6| Step: 3
Training loss: 3.7616809751964975
Validation loss: 3.7850116611660383

Epoch: 6| Step: 4
Training loss: 3.6763457656314866
Validation loss: 3.771705260581756

Epoch: 6| Step: 5
Training loss: 4.17476893716418
Validation loss: 3.7611430526725114

Epoch: 6| Step: 6
Training loss: 3.7719204145350713
Validation loss: 3.752054126330635

Epoch: 6| Step: 7
Training loss: 3.592716499659252
Validation loss: 3.744318763129751

Epoch: 6| Step: 8
Training loss: 4.287079121476396
Validation loss: 3.7316241507908963

Epoch: 6| Step: 9
Training loss: 3.517016732990373
Validation loss: 3.7240878275907936

Epoch: 6| Step: 10
Training loss: 4.327319789860775
Validation loss: 3.714788855702655

Epoch: 6| Step: 11
Training loss: 3.697943688235707
Validation loss: 3.7043106993641848

Epoch: 6| Step: 12
Training loss: 3.8893638926253495
Validation loss: 3.692509096127081

Epoch: 6| Step: 13
Training loss: 3.346542618290213
Validation loss: 3.6838661199023854

Epoch: 7| Step: 0
Training loss: 3.7050679578224366
Validation loss: 3.6767061357219815

Epoch: 6| Step: 1
Training loss: 3.764407139032445
Validation loss: 3.667988160535966

Epoch: 6| Step: 2
Training loss: 3.384245747275765
Validation loss: 3.6581320289288115

Epoch: 6| Step: 3
Training loss: 3.770041254359203
Validation loss: 3.648293722842341

Epoch: 6| Step: 4
Training loss: 3.659255528637587
Validation loss: 3.6392653907504235

Epoch: 6| Step: 5
Training loss: 4.10549941264715
Validation loss: 3.6320396304255826

Epoch: 6| Step: 6
Training loss: 4.388188565120765
Validation loss: 3.635271715388474

Epoch: 6| Step: 7
Training loss: 4.120919029545629
Validation loss: 3.6139639150843714

Epoch: 6| Step: 8
Training loss: 3.846416509902609
Validation loss: 3.606738048437188

Epoch: 6| Step: 9
Training loss: 4.008798221480097
Validation loss: 3.600935312113281

Epoch: 6| Step: 10
Training loss: 2.7707294836636556
Validation loss: 3.590690116941948

Epoch: 6| Step: 11
Training loss: 4.543413765284659
Validation loss: 3.5863201907561693

Epoch: 6| Step: 12
Training loss: 3.659678490072017
Validation loss: 3.5762876887701016

Epoch: 6| Step: 13
Training loss: 2.9995573035081042
Validation loss: 3.569919386733964

Epoch: 8| Step: 0
Training loss: 3.036743220492479
Validation loss: 3.5604310589983097

Epoch: 6| Step: 1
Training loss: 3.37009865228712
Validation loss: 3.5506563776013556

Epoch: 6| Step: 2
Training loss: 4.672322025409942
Validation loss: 3.5481569460699776

Epoch: 6| Step: 3
Training loss: 3.791773756142821
Validation loss: 3.53987362018393

Epoch: 6| Step: 4
Training loss: 3.018227990550398
Validation loss: 3.532254095810898

Epoch: 6| Step: 5
Training loss: 3.4450862057645124
Validation loss: 3.5398112774903283

Epoch: 6| Step: 6
Training loss: 3.3050969729141397
Validation loss: 3.5153193675718954

Epoch: 6| Step: 7
Training loss: 3.572344512652389
Validation loss: 3.5127476403132922

Epoch: 6| Step: 8
Training loss: 4.055583053797567
Validation loss: 3.5074963167123983

Epoch: 6| Step: 9
Training loss: 3.6861816894576522
Validation loss: 3.4964484347372187

Epoch: 6| Step: 10
Training loss: 3.869333246049238
Validation loss: 3.4909937988789785

Epoch: 6| Step: 11
Training loss: 4.073029239331365
Validation loss: 3.48731912111581

Epoch: 6| Step: 12
Training loss: 4.517821520207737
Validation loss: 3.472148353583933

Epoch: 6| Step: 13
Training loss: 2.947321927270374
Validation loss: 3.4652847775337294

Epoch: 9| Step: 0
Training loss: 4.303920449042878
Validation loss: 3.458072288279002

Epoch: 6| Step: 1
Training loss: 4.040595289506127
Validation loss: 3.4475257604106937

Epoch: 6| Step: 2
Training loss: 2.6173906389797916
Validation loss: 3.456956577253504

Epoch: 6| Step: 3
Training loss: 4.04330251301977
Validation loss: 3.4335169323643617

Epoch: 6| Step: 4
Training loss: 3.427982958178185
Validation loss: 3.4260069366712043

Epoch: 6| Step: 5
Training loss: 3.4985003664638867
Validation loss: 3.428229582035208

Epoch: 6| Step: 6
Training loss: 2.652688365004192
Validation loss: 3.420702328905792

Epoch: 6| Step: 7
Training loss: 4.298143678119519
Validation loss: 3.415436477951857

Epoch: 6| Step: 8
Training loss: 3.184124973652786
Validation loss: 3.4076684469091036

Epoch: 6| Step: 9
Training loss: 3.1738079927246097
Validation loss: 3.410250735193512

Epoch: 6| Step: 10
Training loss: 4.051982705142439
Validation loss: 3.398729471015539

Epoch: 6| Step: 11
Training loss: 3.603069925011376
Validation loss: 3.3934187396016102

Epoch: 6| Step: 12
Training loss: 3.8995786537076844
Validation loss: 3.394547958594399

Epoch: 6| Step: 13
Training loss: 3.739074176494318
Validation loss: 3.3891709485061474

Epoch: 10| Step: 0
Training loss: 3.951734577262043
Validation loss: 3.381898216251726

Epoch: 6| Step: 1
Training loss: 3.7377680602635928
Validation loss: 3.372321916306143

Epoch: 6| Step: 2
Training loss: 3.0377976008806145
Validation loss: 3.377939417076591

Epoch: 6| Step: 3
Training loss: 2.8863870432729946
Validation loss: 3.435718949782197

Epoch: 6| Step: 4
Training loss: 3.7688622706251027
Validation loss: 3.364363591772477

Epoch: 6| Step: 5
Training loss: 3.9976620994466927
Validation loss: 3.395954717000089

Epoch: 6| Step: 6
Training loss: 3.099944108028464
Validation loss: 3.39384301312962

Epoch: 6| Step: 7
Training loss: 3.9915814023610747
Validation loss: 3.3897312438625558

Epoch: 6| Step: 8
Training loss: 3.974542910608288
Validation loss: 3.3814388186714712

Epoch: 6| Step: 9
Training loss: 3.6908413247867236
Validation loss: 3.3782489289701356

Epoch: 6| Step: 10
Training loss: 2.9870751433957063
Validation loss: 3.3734092974431804

Epoch: 6| Step: 11
Training loss: 3.5537065095551554
Validation loss: 3.3774765936411013

Epoch: 6| Step: 12
Training loss: 4.410399518935442
Validation loss: 3.37818559791446

Epoch: 6| Step: 13
Training loss: 2.57673940704765
Validation loss: 3.3704529655899913

Epoch: 11| Step: 0
Training loss: 3.6144339377597827
Validation loss: 3.3602153546404963

Epoch: 6| Step: 1
Training loss: 3.258325915966388
Validation loss: 3.3470611585142205

Epoch: 6| Step: 2
Training loss: 3.392260600830625
Validation loss: 3.3440418516638934

Epoch: 6| Step: 3
Training loss: 3.3620618853844415
Validation loss: 3.3444583001944097

Epoch: 6| Step: 4
Training loss: 3.0433910307023115
Validation loss: 3.343993779058254

Epoch: 6| Step: 5
Training loss: 3.7540991948902582
Validation loss: 3.3364236171088906

Epoch: 6| Step: 6
Training loss: 3.8166285189480975
Validation loss: 3.3302528811593697

Epoch: 6| Step: 7
Training loss: 4.040795668252524
Validation loss: 3.325518381359724

Epoch: 6| Step: 8
Training loss: 2.967345859345454
Validation loss: 3.326316098881183

Epoch: 6| Step: 9
Training loss: 3.7563411504822284
Validation loss: 3.3374652116108563

Epoch: 6| Step: 10
Training loss: 3.207633516025845
Validation loss: 3.328275843603757

Epoch: 6| Step: 11
Training loss: 3.28265321790893
Validation loss: 3.3181542949878216

Epoch: 6| Step: 12
Training loss: 4.278426304218059
Validation loss: 3.3124245781882458

Epoch: 6| Step: 13
Training loss: 4.249541762836529
Validation loss: 3.310568926337849

Epoch: 12| Step: 0
Training loss: 4.35017501654365
Validation loss: 3.3075259851001646

Epoch: 6| Step: 1
Training loss: 4.403218410088621
Validation loss: 3.305323785986789

Epoch: 6| Step: 2
Training loss: 3.348002928829393
Validation loss: 3.3010374067510186

Epoch: 6| Step: 3
Training loss: 3.7439795167395262
Validation loss: 3.2991066250740486

Epoch: 6| Step: 4
Training loss: 3.48236929468157
Validation loss: 3.298406600844338

Epoch: 6| Step: 5
Training loss: 3.2841066550291034
Validation loss: 3.300230349024024

Epoch: 6| Step: 6
Training loss: 3.90051043177915
Validation loss: 3.3000959836090145

Epoch: 6| Step: 7
Training loss: 3.407581174223637
Validation loss: 3.297256855851116

Epoch: 6| Step: 8
Training loss: 3.3102814064376958
Validation loss: 3.292561755297341

Epoch: 6| Step: 9
Training loss: 2.6071715959879804
Validation loss: 3.291176571127904

Epoch: 6| Step: 10
Training loss: 2.4902668311304055
Validation loss: 3.2890723568363773

Epoch: 6| Step: 11
Training loss: 3.8693866064223847
Validation loss: 3.2906013146916395

Epoch: 6| Step: 12
Training loss: 2.837816188857327
Validation loss: 3.2894628885779613

Epoch: 6| Step: 13
Training loss: 4.225704084789543
Validation loss: 3.286554876525221

Epoch: 13| Step: 0
Training loss: 3.2205660243143246
Validation loss: 3.2885706838336697

Epoch: 6| Step: 1
Training loss: 4.186761136133176
Validation loss: 3.2878279779202244

Epoch: 6| Step: 2
Training loss: 4.036782896057496
Validation loss: 3.2859085320233636

Epoch: 6| Step: 3
Training loss: 3.8653381241208042
Validation loss: 3.2809234675430803

Epoch: 6| Step: 4
Training loss: 3.054588530905537
Validation loss: 3.2793781916589024

Epoch: 6| Step: 5
Training loss: 4.1019510139653885
Validation loss: 3.280770557728405

Epoch: 6| Step: 6
Training loss: 2.1453173365750287
Validation loss: 3.2812525095346508

Epoch: 6| Step: 7
Training loss: 3.031923042377544
Validation loss: 3.282976403227305

Epoch: 6| Step: 8
Training loss: 3.469103820901074
Validation loss: 3.2930398296272045

Epoch: 6| Step: 9
Training loss: 3.8970723485341496
Validation loss: 3.2811832169213107

Epoch: 6| Step: 10
Training loss: 3.3640106154647422
Validation loss: 3.2762619474799073

Epoch: 6| Step: 11
Training loss: 3.0460933367329486
Validation loss: 3.272153841888716

Epoch: 6| Step: 12
Training loss: 3.740802166024944
Validation loss: 3.273774910679783

Epoch: 6| Step: 13
Training loss: 3.778970204510693
Validation loss: 3.2730436337508553

Epoch: 14| Step: 0
Training loss: 3.5638797162926457
Validation loss: 3.2719562631100816

Epoch: 6| Step: 1
Training loss: 3.994657286265844
Validation loss: 3.268829580522671

Epoch: 6| Step: 2
Training loss: 3.3452712546901266
Validation loss: 3.267488246672853

Epoch: 6| Step: 3
Training loss: 3.4340217332279983
Validation loss: 3.26572181733597

Epoch: 6| Step: 4
Training loss: 4.008389734411994
Validation loss: 3.2635154153208807

Epoch: 6| Step: 5
Training loss: 3.712128843513151
Validation loss: 3.2619976330974247

Epoch: 6| Step: 6
Training loss: 3.173422450035091
Validation loss: 3.2613972060880934

Epoch: 6| Step: 7
Training loss: 3.3730579015996667
Validation loss: 3.2613879211821537

Epoch: 6| Step: 8
Training loss: 3.7622886218136062
Validation loss: 3.258060712140995

Epoch: 6| Step: 9
Training loss: 3.0081056130008608
Validation loss: 3.2588748619621364

Epoch: 6| Step: 10
Training loss: 3.6351098456701263
Validation loss: 3.258262589218037

Epoch: 6| Step: 11
Training loss: 3.004929307559933
Validation loss: 3.258974955595341

Epoch: 6| Step: 12
Training loss: 3.5066553598905776
Validation loss: 3.2615871305376842

Epoch: 6| Step: 13
Training loss: 3.5144073412114505
Validation loss: 3.256609907020169

Epoch: 15| Step: 0
Training loss: 3.620500863764101
Validation loss: 3.256143224075353

Epoch: 6| Step: 1
Training loss: 3.1041839052954816
Validation loss: 3.254727863251727

Epoch: 6| Step: 2
Training loss: 3.285470192295229
Validation loss: 3.2538926041400704

Epoch: 6| Step: 3
Training loss: 3.7021242229984948
Validation loss: 3.252523206339371

Epoch: 6| Step: 4
Training loss: 3.3653845684344947
Validation loss: 3.251254201787609

Epoch: 6| Step: 5
Training loss: 3.3698603737541757
Validation loss: 3.2545181339440252

Epoch: 6| Step: 6
Training loss: 2.605008978361447
Validation loss: 3.2518763241328603

Epoch: 6| Step: 7
Training loss: 3.972180543397813
Validation loss: 3.2479025964765595

Epoch: 6| Step: 8
Training loss: 4.121387171130063
Validation loss: 3.247198775022714

Epoch: 6| Step: 9
Training loss: 3.04786908487834
Validation loss: 3.24678009727348

Epoch: 6| Step: 10
Training loss: 3.800882869353889
Validation loss: 3.247049669534289

Epoch: 6| Step: 11
Training loss: 3.954682416547133
Validation loss: 3.2450185924969253

Epoch: 6| Step: 12
Training loss: 3.5264137030475458
Validation loss: 3.2444102664372605

Epoch: 6| Step: 13
Training loss: 2.982604615134592
Validation loss: 3.2454571648933586

Epoch: 16| Step: 0
Training loss: 3.004523046538771
Validation loss: 3.2443030431294035

Epoch: 6| Step: 1
Training loss: 3.348182378707717
Validation loss: 3.244150155246751

Epoch: 6| Step: 2
Training loss: 3.616854230057437
Validation loss: 3.2443589522920786

Epoch: 6| Step: 3
Training loss: 3.295867332029145
Validation loss: 3.2408164090296028

Epoch: 6| Step: 4
Training loss: 3.2470484315522157
Validation loss: 3.236789674888164

Epoch: 6| Step: 5
Training loss: 3.2897633872705914
Validation loss: 3.2391777015436296

Epoch: 6| Step: 6
Training loss: 3.2193416310978438
Validation loss: 3.2434823064142453

Epoch: 6| Step: 7
Training loss: 4.536921667649088
Validation loss: 3.256828569703786

Epoch: 6| Step: 8
Training loss: 3.52306923982361
Validation loss: 3.238956164513591

Epoch: 6| Step: 9
Training loss: 3.3991333698482067
Validation loss: 3.234494555487357

Epoch: 6| Step: 10
Training loss: 4.115762713770614
Validation loss: 3.2359564799977862

Epoch: 6| Step: 11
Training loss: 3.3911208392306884
Validation loss: 3.239134416964625

Epoch: 6| Step: 12
Training loss: 3.4585893988124172
Validation loss: 3.2512290104296775

Epoch: 6| Step: 13
Training loss: 2.936693770781136
Validation loss: 3.2550555381436683

Epoch: 17| Step: 0
Training loss: 3.4760782997610016
Validation loss: 3.3279930202966166

Epoch: 6| Step: 1
Training loss: 4.007346559324911
Validation loss: 3.2973708613021553

Epoch: 6| Step: 2
Training loss: 2.6460244317516257
Validation loss: 3.232666650356105

Epoch: 6| Step: 3
Training loss: 3.420158338841075
Validation loss: 3.226514188283673

Epoch: 6| Step: 4
Training loss: 3.7431147627118055
Validation loss: 3.2249348237584665

Epoch: 6| Step: 5
Training loss: 3.5459983515340263
Validation loss: 3.2266275151585275

Epoch: 6| Step: 6
Training loss: 3.688625875030872
Validation loss: 3.2285066902052844

Epoch: 6| Step: 7
Training loss: 3.1877725522070253
Validation loss: 3.231526192684163

Epoch: 6| Step: 8
Training loss: 3.338809061674145
Validation loss: 3.233113363877449

Epoch: 6| Step: 9
Training loss: 3.540363939834018
Validation loss: 3.2238391643008475

Epoch: 6| Step: 10
Training loss: 3.0579491882493794
Validation loss: 3.22018245430798

Epoch: 6| Step: 11
Training loss: 4.658761595191375
Validation loss: 3.2182783750414505

Epoch: 6| Step: 12
Training loss: 2.881054680879686
Validation loss: 3.2187829020437686

Epoch: 6| Step: 13
Training loss: 3.0003386942090824
Validation loss: 3.220986894911927

Epoch: 18| Step: 0
Training loss: 2.938471532014222
Validation loss: 3.251243927509381

Epoch: 6| Step: 1
Training loss: 3.417882950932049
Validation loss: 3.2596793173302183

Epoch: 6| Step: 2
Training loss: 3.572088488509036
Validation loss: 3.2233407829312175

Epoch: 6| Step: 3
Training loss: 4.119185540147488
Validation loss: 3.226417931364992

Epoch: 6| Step: 4
Training loss: 3.4627023851209566
Validation loss: 3.2264921663422865

Epoch: 6| Step: 5
Training loss: 2.8797885986729783
Validation loss: 3.226946932317736

Epoch: 6| Step: 6
Training loss: 2.8519306938021787
Validation loss: 3.2314805969771863

Epoch: 6| Step: 7
Training loss: 3.2724105207247307
Validation loss: 3.2292978906448586

Epoch: 6| Step: 8
Training loss: 3.731903024139238
Validation loss: 3.2234558883396285

Epoch: 6| Step: 9
Training loss: 3.292916619916553
Validation loss: 3.2158771967489637

Epoch: 6| Step: 10
Training loss: 3.9716567561038887
Validation loss: 3.21066494042316

Epoch: 6| Step: 11
Training loss: 3.3291501181282293
Validation loss: 3.2116886477195505

Epoch: 6| Step: 12
Training loss: 4.092206591211672
Validation loss: 3.2183576743596984

Epoch: 6| Step: 13
Training loss: 3.491037610426463
Validation loss: 3.2519725669519373

Epoch: 19| Step: 0
Training loss: 3.4089719763152546
Validation loss: 3.2159266711012258

Epoch: 6| Step: 1
Training loss: 2.5452872165573983
Validation loss: 3.206142723375567

Epoch: 6| Step: 2
Training loss: 2.9143035216281636
Validation loss: 3.201423621756498

Epoch: 6| Step: 3
Training loss: 3.3502928990097676
Validation loss: 3.2026151357858312

Epoch: 6| Step: 4
Training loss: 3.7687471354965534
Validation loss: 3.199282748648133

Epoch: 6| Step: 5
Training loss: 2.5115514910168195
Validation loss: 3.2001175578760868

Epoch: 6| Step: 6
Training loss: 3.5546825366981145
Validation loss: 3.1990112636468533

Epoch: 6| Step: 7
Training loss: 4.073585995102727
Validation loss: 3.1969772508400163

Epoch: 6| Step: 8
Training loss: 3.9028940662391998
Validation loss: 3.1964738038611435

Epoch: 6| Step: 9
Training loss: 3.2083926174747086
Validation loss: 3.1949052103553424

Epoch: 6| Step: 10
Training loss: 4.597023141679484
Validation loss: 3.1914152645635894

Epoch: 6| Step: 11
Training loss: 3.5457737763390424
Validation loss: 3.189980131763706

Epoch: 6| Step: 12
Training loss: 2.9182367367736752
Validation loss: 3.186745610845293

Epoch: 6| Step: 13
Training loss: 3.567853686116782
Validation loss: 3.185664649673866

Epoch: 20| Step: 0
Training loss: 3.393981116418227
Validation loss: 3.184065866760091

Epoch: 6| Step: 1
Training loss: 3.482935586759203
Validation loss: 3.182044665721071

Epoch: 6| Step: 2
Training loss: 3.932588208198106
Validation loss: 3.1809131688574204

Epoch: 6| Step: 3
Training loss: 3.9210961772989474
Validation loss: 3.1822487291977573

Epoch: 6| Step: 4
Training loss: 3.1854001776844596
Validation loss: 3.1808165926300145

Epoch: 6| Step: 5
Training loss: 3.5213373188408865
Validation loss: 3.180878129405466

Epoch: 6| Step: 6
Training loss: 3.1804139903036583
Validation loss: 3.1774461452649185

Epoch: 6| Step: 7
Training loss: 3.3991337906941195
Validation loss: 3.177766740074965

Epoch: 6| Step: 8
Training loss: 2.870624031516887
Validation loss: 3.1762532664664134

Epoch: 6| Step: 9
Training loss: 3.7115197939534426
Validation loss: 3.174135705474368

Epoch: 6| Step: 10
Training loss: 3.598604323793272
Validation loss: 3.1730767695214186

Epoch: 6| Step: 11
Training loss: 2.9326843396303475
Validation loss: 3.1733449910786398

Epoch: 6| Step: 12
Training loss: 3.2484087349635065
Validation loss: 3.1743326163485053

Epoch: 6| Step: 13
Training loss: 3.810965932917521
Validation loss: 3.1784007896176623

Epoch: 21| Step: 0
Training loss: 2.2284987212466927
Validation loss: 3.1914695329514884

Epoch: 6| Step: 1
Training loss: 3.1193751257145648
Validation loss: 3.1728300245757146

Epoch: 6| Step: 2
Training loss: 3.484781284337714
Validation loss: 3.1680594545683114

Epoch: 6| Step: 3
Training loss: 3.948825110976691
Validation loss: 3.172317439270895

Epoch: 6| Step: 4
Training loss: 3.2879097338720875
Validation loss: 3.168476907459738

Epoch: 6| Step: 5
Training loss: 4.196283494476466
Validation loss: 3.1690430643209666

Epoch: 6| Step: 6
Training loss: 3.409670171364121
Validation loss: 3.1695852387700842

Epoch: 6| Step: 7
Training loss: 3.1068052474890013
Validation loss: 3.166116314220024

Epoch: 6| Step: 8
Training loss: 3.8570773431976564
Validation loss: 3.1658682267253235

Epoch: 6| Step: 9
Training loss: 3.689384366914884
Validation loss: 3.1697816041392937

Epoch: 6| Step: 10
Training loss: 3.3134708061584246
Validation loss: 3.1679522172249057

Epoch: 6| Step: 11
Training loss: 3.757862748981866
Validation loss: 3.171058921997723

Epoch: 6| Step: 12
Training loss: 3.414899012132207
Validation loss: 3.171882717079334

Epoch: 6| Step: 13
Training loss: 2.1804676915613475
Validation loss: 3.1723934186174554

Epoch: 22| Step: 0
Training loss: 3.6482722961794276
Validation loss: 3.1811523949236507

Epoch: 6| Step: 1
Training loss: 2.4892863544729904
Validation loss: 3.1781692389356544

Epoch: 6| Step: 2
Training loss: 3.2490699611092735
Validation loss: 3.193452577540708

Epoch: 6| Step: 3
Training loss: 3.606446238026215
Validation loss: 3.205098740741226

Epoch: 6| Step: 4
Training loss: 3.2276472064900443
Validation loss: 3.2074757806824303

Epoch: 6| Step: 5
Training loss: 4.141116476580612
Validation loss: 3.165502248858438

Epoch: 6| Step: 6
Training loss: 3.203884871996847
Validation loss: 3.177028307075942

Epoch: 6| Step: 7
Training loss: 3.5374350605857527
Validation loss: 3.1998746478232167

Epoch: 6| Step: 8
Training loss: 3.770080083709821
Validation loss: 3.205351341193374

Epoch: 6| Step: 9
Training loss: 3.423248712025576
Validation loss: 3.2091672176161716

Epoch: 6| Step: 10
Training loss: 3.245117628319636
Validation loss: 3.1772212221323364

Epoch: 6| Step: 11
Training loss: 3.84764162632056
Validation loss: 3.156648227160345

Epoch: 6| Step: 12
Training loss: 3.1807514631931664
Validation loss: 3.1611651448024465

Epoch: 6| Step: 13
Training loss: 3.349992006206939
Validation loss: 3.169929323480891

Epoch: 23| Step: 0
Training loss: 2.9386143295533773
Validation loss: 3.179718079512757

Epoch: 6| Step: 1
Training loss: 2.904383890866092
Validation loss: 3.1918571694731477

Epoch: 6| Step: 2
Training loss: 4.511788715298958
Validation loss: 3.197062693233052

Epoch: 6| Step: 3
Training loss: 2.834969179231475
Validation loss: 3.1819903429421252

Epoch: 6| Step: 4
Training loss: 3.1322246199700126
Validation loss: 3.1738364382903947

Epoch: 6| Step: 5
Training loss: 3.4370326331339984
Validation loss: 3.160435527629209

Epoch: 6| Step: 6
Training loss: 3.749350173595841
Validation loss: 3.1555887831505536

Epoch: 6| Step: 7
Training loss: 4.244283758875517
Validation loss: 3.1535850929506406

Epoch: 6| Step: 8
Training loss: 3.199044060973955
Validation loss: 3.148454135248379

Epoch: 6| Step: 9
Training loss: 3.527871465231594
Validation loss: 3.143502791275927

Epoch: 6| Step: 10
Training loss: 2.6466443678575535
Validation loss: 3.143021724243347

Epoch: 6| Step: 11
Training loss: 4.011623660022016
Validation loss: 3.1434710887734747

Epoch: 6| Step: 12
Training loss: 2.6593532610676
Validation loss: 3.136139412149413

Epoch: 6| Step: 13
Training loss: 3.5216988547413206
Validation loss: 3.1343697590165016

Epoch: 24| Step: 0
Training loss: 3.8953000823984785
Validation loss: 3.1351182870801417

Epoch: 6| Step: 1
Training loss: 3.653916094956135
Validation loss: 3.13068155043638

Epoch: 6| Step: 2
Training loss: 4.049294002833916
Validation loss: 3.1310624283545074

Epoch: 6| Step: 3
Training loss: 3.54920647577258
Validation loss: 3.126865709454691

Epoch: 6| Step: 4
Training loss: 2.3940343543498135
Validation loss: 3.1268562341390016

Epoch: 6| Step: 5
Training loss: 2.6432747271640458
Validation loss: 3.126125051138449

Epoch: 6| Step: 6
Training loss: 2.8962612979357387
Validation loss: 3.1262850213347515

Epoch: 6| Step: 7
Training loss: 3.5885300915240266
Validation loss: 3.1281626622798293

Epoch: 6| Step: 8
Training loss: 3.9618583376272754
Validation loss: 3.127332126445335

Epoch: 6| Step: 9
Training loss: 2.796052268296918
Validation loss: 3.1272204707821394

Epoch: 6| Step: 10
Training loss: 2.9497590435350802
Validation loss: 3.12645005741419

Epoch: 6| Step: 11
Training loss: 3.6873922817208413
Validation loss: 3.1228193340905914

Epoch: 6| Step: 12
Training loss: 3.469762980696508
Validation loss: 3.1218732273541407

Epoch: 6| Step: 13
Training loss: 3.6557376861291835
Validation loss: 3.120415831054089

Epoch: 25| Step: 0
Training loss: 3.7321959965665132
Validation loss: 3.1208818188065783

Epoch: 6| Step: 1
Training loss: 2.846480180348048
Validation loss: 3.118308268285225

Epoch: 6| Step: 2
Training loss: 3.407848018301979
Validation loss: 3.118417704418327

Epoch: 6| Step: 3
Training loss: 3.7064153161578655
Validation loss: 3.11669149952089

Epoch: 6| Step: 4
Training loss: 2.753915946348178
Validation loss: 3.1168371980304697

Epoch: 6| Step: 5
Training loss: 4.1872185000415065
Validation loss: 3.1174311212039387

Epoch: 6| Step: 6
Training loss: 3.57625400984325
Validation loss: 3.114278645842676

Epoch: 6| Step: 7
Training loss: 3.041303499741363
Validation loss: 3.1123570586257747

Epoch: 6| Step: 8
Training loss: 3.5930628907506823
Validation loss: 3.1165423491894266

Epoch: 6| Step: 9
Training loss: 3.475792137260989
Validation loss: 3.1139834246678277

Epoch: 6| Step: 10
Training loss: 3.3921879273304083
Validation loss: 3.1115280054306997

Epoch: 6| Step: 11
Training loss: 3.0647686710151447
Validation loss: 3.1117994363235244

Epoch: 6| Step: 12
Training loss: 3.1578325892908423
Validation loss: 3.1098629271882245

Epoch: 6| Step: 13
Training loss: 3.021004419853263
Validation loss: 3.1081125210384775

Epoch: 26| Step: 0
Training loss: 3.219079750725092
Validation loss: 3.107838177970197

Epoch: 6| Step: 1
Training loss: 3.987915141818432
Validation loss: 3.104894856708501

Epoch: 6| Step: 2
Training loss: 3.23284522105012
Validation loss: 3.10492751949779

Epoch: 6| Step: 3
Training loss: 3.707626889836117
Validation loss: 3.1069800860641426

Epoch: 6| Step: 4
Training loss: 2.757939754500291
Validation loss: 3.107498591329352

Epoch: 6| Step: 5
Training loss: 3.0577954338115987
Validation loss: 3.115062886734454

Epoch: 6| Step: 6
Training loss: 3.1601885403750476
Validation loss: 3.119992402840245

Epoch: 6| Step: 7
Training loss: 3.5769851401524013
Validation loss: 3.112826585131706

Epoch: 6| Step: 8
Training loss: 2.721143874419456
Validation loss: 3.0962743005852116

Epoch: 6| Step: 9
Training loss: 3.608982345559014
Validation loss: 3.0934975443290584

Epoch: 6| Step: 10
Training loss: 3.077819344308358
Validation loss: 3.0944743621327047

Epoch: 6| Step: 11
Training loss: 4.495790207838385
Validation loss: 3.0957341183899523

Epoch: 6| Step: 12
Training loss: 3.0824604001560627
Validation loss: 3.0923364085725185

Epoch: 6| Step: 13
Training loss: 2.9169619456186773
Validation loss: 3.0973707291299815

Epoch: 27| Step: 0
Training loss: 2.611205777916406
Validation loss: 3.094818487576567

Epoch: 6| Step: 1
Training loss: 3.4089406436979597
Validation loss: 3.093048932758124

Epoch: 6| Step: 2
Training loss: 3.423943717297881
Validation loss: 3.0883110333935706

Epoch: 6| Step: 3
Training loss: 3.19461372774657
Validation loss: 3.086804285173793

Epoch: 6| Step: 4
Training loss: 2.739607768560204
Validation loss: 3.0855188827520585

Epoch: 6| Step: 5
Training loss: 3.7082102180074767
Validation loss: 3.087578622714438

Epoch: 6| Step: 6
Training loss: 3.792354702966909
Validation loss: 3.09512548777083

Epoch: 6| Step: 7
Training loss: 3.369132982328288
Validation loss: 3.0829652507239618

Epoch: 6| Step: 8
Training loss: 3.5115483362520403
Validation loss: 3.0816291787936576

Epoch: 6| Step: 9
Training loss: 3.1000843897992443
Validation loss: 3.081314703788167

Epoch: 6| Step: 10
Training loss: 3.646810229983955
Validation loss: 3.0825992845107395

Epoch: 6| Step: 11
Training loss: 3.8800597843008213
Validation loss: 3.0829440161827337

Epoch: 6| Step: 12
Training loss: 3.2325478520579902
Validation loss: 3.0854621418280654

Epoch: 6| Step: 13
Training loss: 3.1759253887954157
Validation loss: 3.0994901467399623

Epoch: 28| Step: 0
Training loss: 3.4249008944018526
Validation loss: 3.164676796121799

Epoch: 6| Step: 1
Training loss: 3.4922776178598802
Validation loss: 3.1643888126234416

Epoch: 6| Step: 2
Training loss: 3.428249466061403
Validation loss: 3.162664759242201

Epoch: 6| Step: 3
Training loss: 3.474663170606602
Validation loss: 3.162682203201182

Epoch: 6| Step: 4
Training loss: 3.6637604351018735
Validation loss: 3.1646019260441127

Epoch: 6| Step: 5
Training loss: 2.856174366156187
Validation loss: 3.15361742622116

Epoch: 6| Step: 6
Training loss: 2.862422132474094
Validation loss: 3.148136057003747

Epoch: 6| Step: 7
Training loss: 3.7105865633816095
Validation loss: 3.193192159461773

Epoch: 6| Step: 8
Training loss: 3.8041207206656127
Validation loss: 3.1381288266388325

Epoch: 6| Step: 9
Training loss: 3.2183002046539086
Validation loss: 3.127826880526622

Epoch: 6| Step: 10
Training loss: 3.7401647655891956
Validation loss: 3.127342489748593

Epoch: 6| Step: 11
Training loss: 3.4406607228433317
Validation loss: 3.132658444348483

Epoch: 6| Step: 12
Training loss: 3.2452387045127478
Validation loss: 3.1353578642051434

Epoch: 6| Step: 13
Training loss: 3.294258706694989
Validation loss: 3.1296699512334487

Epoch: 29| Step: 0
Training loss: 3.5307997695039437
Validation loss: 3.1270386524928053

Epoch: 6| Step: 1
Training loss: 3.264769519656708
Validation loss: 3.1245994097820153

Epoch: 6| Step: 2
Training loss: 2.9703074335318935
Validation loss: 3.121867347652148

Epoch: 6| Step: 3
Training loss: 3.727442863328349
Validation loss: 3.1186903934519052

Epoch: 6| Step: 4
Training loss: 4.428739039154228
Validation loss: 3.111415560158329

Epoch: 6| Step: 5
Training loss: 3.248504294497267
Validation loss: 3.108895907030614

Epoch: 6| Step: 6
Training loss: 3.7919274264927707
Validation loss: 3.1030910663124684

Epoch: 6| Step: 7
Training loss: 2.533293099669481
Validation loss: 3.1059284935080216

Epoch: 6| Step: 8
Training loss: 3.4365865707560435
Validation loss: 3.10335721544483

Epoch: 6| Step: 9
Training loss: 2.9679458332105844
Validation loss: 3.102510222701524

Epoch: 6| Step: 10
Training loss: 2.2900353144958667
Validation loss: 3.103000365332546

Epoch: 6| Step: 11
Training loss: 4.09489343413702
Validation loss: 3.1013667303480936

Epoch: 6| Step: 12
Training loss: 3.397771239467418
Validation loss: 3.0996326573572666

Epoch: 6| Step: 13
Training loss: 2.8548556607665887
Validation loss: 3.101660423172238

Epoch: 30| Step: 0
Training loss: 2.648485571500953
Validation loss: 3.098175206051885

Epoch: 6| Step: 1
Training loss: 3.3573556907925424
Validation loss: 3.0986271071185727

Epoch: 6| Step: 2
Training loss: 3.0416280317247906
Validation loss: 3.0964187011904234

Epoch: 6| Step: 3
Training loss: 3.5691583884107048
Validation loss: 3.0954781043137842

Epoch: 6| Step: 4
Training loss: 3.526904512856856
Validation loss: 3.094197426207617

Epoch: 6| Step: 5
Training loss: 3.5761530743890706
Validation loss: 3.0947237045530707

Epoch: 6| Step: 6
Training loss: 3.6206876162819217
Validation loss: 3.0938774820949875

Epoch: 6| Step: 7
Training loss: 3.716041155354194
Validation loss: 3.0941413042758192

Epoch: 6| Step: 8
Training loss: 2.8919595472954596
Validation loss: 3.0925267712870137

Epoch: 6| Step: 9
Training loss: 3.6295038065939647
Validation loss: 3.0920711315342695

Epoch: 6| Step: 10
Training loss: 3.6246177208688537
Validation loss: 3.0925692437490873

Epoch: 6| Step: 11
Training loss: 3.686713312577112
Validation loss: 3.092883923020833

Epoch: 6| Step: 12
Training loss: 2.3239304820577167
Validation loss: 3.093354830628287

Epoch: 6| Step: 13
Training loss: 3.8287014274243596
Validation loss: 3.096423072696446

Epoch: 31| Step: 0
Training loss: 2.7004269933382936
Validation loss: 3.098903728254615

Epoch: 6| Step: 1
Training loss: 2.977187844415851
Validation loss: 3.100208254106393

Epoch: 6| Step: 2
Training loss: 3.5813062094226757
Validation loss: 3.103952061123315

Epoch: 6| Step: 3
Training loss: 3.1606327258802587
Validation loss: 3.0927431281414064

Epoch: 6| Step: 4
Training loss: 3.4996036577609146
Validation loss: 3.0863141421027844

Epoch: 6| Step: 5
Training loss: 4.1757346597611384
Validation loss: 3.0851090818384663

Epoch: 6| Step: 6
Training loss: 2.901256907141343
Validation loss: 3.0840394997104603

Epoch: 6| Step: 7
Training loss: 2.4201092589753914
Validation loss: 3.083891924141452

Epoch: 6| Step: 8
Training loss: 3.6946849330430824
Validation loss: 3.0835593328376976

Epoch: 6| Step: 9
Training loss: 3.372418864796274
Validation loss: 3.0819304272595556

Epoch: 6| Step: 10
Training loss: 3.0517235935581537
Validation loss: 3.083187670760493

Epoch: 6| Step: 11
Training loss: 3.8601252641266104
Validation loss: 3.082227779482469

Epoch: 6| Step: 12
Training loss: 3.9046065878909197
Validation loss: 3.0762441337759427

Epoch: 6| Step: 13
Training loss: 3.2237995131182164
Validation loss: 3.0785696956579574

Epoch: 32| Step: 0
Training loss: 3.5351659616579307
Validation loss: 3.078097565539457

Epoch: 6| Step: 1
Training loss: 2.9891613032138062
Validation loss: 3.0769845613346534

Epoch: 6| Step: 2
Training loss: 3.267232544860752
Validation loss: 3.0755298752566853

Epoch: 6| Step: 3
Training loss: 3.1796931986089905
Validation loss: 3.074805127256881

Epoch: 6| Step: 4
Training loss: 2.4467550781795993
Validation loss: 3.0735404545089335

Epoch: 6| Step: 5
Training loss: 2.8457689768568906
Validation loss: 3.073265117385313

Epoch: 6| Step: 6
Training loss: 3.7267161723507
Validation loss: 3.073231159605698

Epoch: 6| Step: 7
Training loss: 3.459667515297713
Validation loss: 3.072447276917014

Epoch: 6| Step: 8
Training loss: 4.088703102115752
Validation loss: 3.0702183749283525

Epoch: 6| Step: 9
Training loss: 2.88674352735899
Validation loss: 3.071293429708034

Epoch: 6| Step: 10
Training loss: 3.6844518962468267
Validation loss: 3.0696229076521355

Epoch: 6| Step: 11
Training loss: 3.240400074406232
Validation loss: 3.07027138211223

Epoch: 6| Step: 12
Training loss: 3.969804758800872
Validation loss: 3.0693538734507326

Epoch: 6| Step: 13
Training loss: 3.0457177727760345
Validation loss: 3.0705010704479783

Epoch: 33| Step: 0
Training loss: 3.8242401964094754
Validation loss: 3.0693638478453407

Epoch: 6| Step: 1
Training loss: 3.508063700290086
Validation loss: 3.0698858872396455

Epoch: 6| Step: 2
Training loss: 4.025476387217166
Validation loss: 3.0696429156271843

Epoch: 6| Step: 3
Training loss: 3.3286100938470327
Validation loss: 3.065748986305323

Epoch: 6| Step: 4
Training loss: 2.4598752590279913
Validation loss: 3.0668927118964353

Epoch: 6| Step: 5
Training loss: 3.1477601337877195
Validation loss: 3.0891879675362954

Epoch: 6| Step: 6
Training loss: 3.3458007513211996
Validation loss: 3.106966674486446

Epoch: 6| Step: 7
Training loss: 2.6780522197506578
Validation loss: 3.149578241519101

Epoch: 6| Step: 8
Training loss: 3.274003228075863
Validation loss: 3.115570664736093

Epoch: 6| Step: 9
Training loss: 3.2242383367980145
Validation loss: 3.0756445860649038

Epoch: 6| Step: 10
Training loss: 3.0490899276008046
Validation loss: 3.0596145478951247

Epoch: 6| Step: 11
Training loss: 4.220405536347823
Validation loss: 3.0633439790227692

Epoch: 6| Step: 12
Training loss: 3.137340289302604
Validation loss: 3.0592795569283187

Epoch: 6| Step: 13
Training loss: 2.977051221720178
Validation loss: 3.0581805078985624

Epoch: 34| Step: 0
Training loss: 3.3966027228788285
Validation loss: 3.0580303514720075

Epoch: 6| Step: 1
Training loss: 2.8346112305300477
Validation loss: 3.0576636478416788

Epoch: 6| Step: 2
Training loss: 3.445548328450989
Validation loss: 3.0583248160327106

Epoch: 6| Step: 3
Training loss: 3.109930094334982
Validation loss: 3.063400228324468

Epoch: 6| Step: 4
Training loss: 3.5763670755027697
Validation loss: 3.0694795031860687

Epoch: 6| Step: 5
Training loss: 4.510140331986244
Validation loss: 3.068301594023445

Epoch: 6| Step: 6
Training loss: 3.0732147244661867
Validation loss: 3.0622035861053862

Epoch: 6| Step: 7
Training loss: 3.4128763682978094
Validation loss: 3.0552018100344753

Epoch: 6| Step: 8
Training loss: 3.5842708130172536
Validation loss: 3.0554206999860267

Epoch: 6| Step: 9
Training loss: 3.3784179334644637
Validation loss: 3.0529862648466217

Epoch: 6| Step: 10
Training loss: 3.206413553390487
Validation loss: 3.0535847320597185

Epoch: 6| Step: 11
Training loss: 3.003687658405143
Validation loss: 3.0532055017175472

Epoch: 6| Step: 12
Training loss: 2.796200463133732
Validation loss: 3.05292292107199

Epoch: 6| Step: 13
Training loss: 2.718173437259288
Validation loss: 3.0573409798487976

Epoch: 35| Step: 0
Training loss: 3.1228819726633197
Validation loss: 3.061726815531726

Epoch: 6| Step: 1
Training loss: 3.8160046587741654
Validation loss: 3.0730672897763025

Epoch: 6| Step: 2
Training loss: 2.7516934642568986
Validation loss: 3.054297953269356

Epoch: 6| Step: 3
Training loss: 2.7591527000387903
Validation loss: 3.0482442593080625

Epoch: 6| Step: 4
Training loss: 3.1645264838718705
Validation loss: 3.047741495233849

Epoch: 6| Step: 5
Training loss: 2.940645684423882
Validation loss: 3.0443148450011193

Epoch: 6| Step: 6
Training loss: 4.251506089772431
Validation loss: 3.045685214884205

Epoch: 6| Step: 7
Training loss: 3.463320219757347
Validation loss: 3.04571011480062

Epoch: 6| Step: 8
Training loss: 3.0236437823282207
Validation loss: 3.0460692731556134

Epoch: 6| Step: 9
Training loss: 3.686248566946409
Validation loss: 3.0454321504233284

Epoch: 6| Step: 10
Training loss: 3.324958835433037
Validation loss: 3.0445496845920594

Epoch: 6| Step: 11
Training loss: 3.3865730227892743
Validation loss: 3.043387819612064

Epoch: 6| Step: 12
Training loss: 3.029461047644742
Validation loss: 3.0434598577371395

Epoch: 6| Step: 13
Training loss: 3.680863307986
Validation loss: 3.040203230154806

Epoch: 36| Step: 0
Training loss: 3.165352565418791
Validation loss: 3.040978128871987

Epoch: 6| Step: 1
Training loss: 3.3784365641764036
Validation loss: 3.040022110596857

Epoch: 6| Step: 2
Training loss: 3.109050637967449
Validation loss: 3.042536993809338

Epoch: 6| Step: 3
Training loss: 2.9961720522280983
Validation loss: 3.0469068602859535

Epoch: 6| Step: 4
Training loss: 2.8440960684001273
Validation loss: 3.0483668240334643

Epoch: 6| Step: 5
Training loss: 2.9563429319844037
Validation loss: 3.05730239092876

Epoch: 6| Step: 6
Training loss: 3.5571391946595377
Validation loss: 3.0555183416457723

Epoch: 6| Step: 7
Training loss: 3.8632854465504254
Validation loss: 3.0495005243849054

Epoch: 6| Step: 8
Training loss: 3.816739586101629
Validation loss: 3.040322968795289

Epoch: 6| Step: 9
Training loss: 2.775747964768418
Validation loss: 3.034327663268982

Epoch: 6| Step: 10
Training loss: 3.7065430652355573
Validation loss: 3.033955374782144

Epoch: 6| Step: 11
Training loss: 3.290296309557469
Validation loss: 3.033646507643488

Epoch: 6| Step: 12
Training loss: 3.3832897527985395
Validation loss: 3.033739742674075

Epoch: 6| Step: 13
Training loss: 3.490426184747627
Validation loss: 3.0325166225053013

Epoch: 37| Step: 0
Training loss: 3.9129181367269315
Validation loss: 3.031342983986903

Epoch: 6| Step: 1
Training loss: 3.0559419753672556
Validation loss: 3.031484549349091

Epoch: 6| Step: 2
Training loss: 3.4815911774754937
Validation loss: 3.03031209820335

Epoch: 6| Step: 3
Training loss: 3.446742169889323
Validation loss: 3.02968834079151

Epoch: 6| Step: 4
Training loss: 3.648140284584838
Validation loss: 3.02856604907013

Epoch: 6| Step: 5
Training loss: 3.4978714328648572
Validation loss: 3.026589121688675

Epoch: 6| Step: 6
Training loss: 2.7021323790519403
Validation loss: 3.02758304747087

Epoch: 6| Step: 7
Training loss: 2.487826079652695
Validation loss: 3.025995629296302

Epoch: 6| Step: 8
Training loss: 3.446335690345872
Validation loss: 3.026403283980207

Epoch: 6| Step: 9
Training loss: 3.067623290527683
Validation loss: 3.022838025511058

Epoch: 6| Step: 10
Training loss: 3.7997789619808295
Validation loss: 3.026051163117973

Epoch: 6| Step: 11
Training loss: 3.4701730369496087
Validation loss: 3.0252998070596164

Epoch: 6| Step: 12
Training loss: 3.0358791595052272
Validation loss: 3.026802778175392

Epoch: 6| Step: 13
Training loss: 2.6437668928323608
Validation loss: 3.028328723861861

Epoch: 38| Step: 0
Training loss: 2.96661332186054
Validation loss: 3.0270808407099867

Epoch: 6| Step: 1
Training loss: 3.004583036974385
Validation loss: 3.026003489660241

Epoch: 6| Step: 2
Training loss: 3.0386382054391876
Validation loss: 3.026831986977834

Epoch: 6| Step: 3
Training loss: 3.7097947459239258
Validation loss: 3.034982497420289

Epoch: 6| Step: 4
Training loss: 3.660644238164004
Validation loss: 3.0575817580071383

Epoch: 6| Step: 5
Training loss: 3.4590792177144234
Validation loss: 3.0498636359479985

Epoch: 6| Step: 6
Training loss: 2.636789459410682
Validation loss: 3.043236097632478

Epoch: 6| Step: 7
Training loss: 3.3704164251116078
Validation loss: 3.0262003496198764

Epoch: 6| Step: 8
Training loss: 2.5862424734014375
Validation loss: 3.023963569783895

Epoch: 6| Step: 9
Training loss: 3.164344906860691
Validation loss: 3.0236975050979034

Epoch: 6| Step: 10
Training loss: 2.9543157528237924
Validation loss: 3.023220625023343

Epoch: 6| Step: 11
Training loss: 3.607752712013738
Validation loss: 3.017586992787519

Epoch: 6| Step: 12
Training loss: 4.0217068107193885
Validation loss: 3.0184447494746993

Epoch: 6| Step: 13
Training loss: 4.107104468314321
Validation loss: 3.018322381341917

Epoch: 39| Step: 0
Training loss: 3.287918435507457
Validation loss: 3.021255204583886

Epoch: 6| Step: 1
Training loss: 4.0421421256392245
Validation loss: 3.044957606711571

Epoch: 6| Step: 2
Training loss: 3.6716427993402716
Validation loss: 3.0589508475555918

Epoch: 6| Step: 3
Training loss: 3.816112995106206
Validation loss: 3.022890817844308

Epoch: 6| Step: 4
Training loss: 2.9885646311712084
Validation loss: 3.012125652495641

Epoch: 6| Step: 5
Training loss: 3.163240905338624
Validation loss: 3.0107849477176467

Epoch: 6| Step: 6
Training loss: 3.4395508630437974
Validation loss: 3.009279155341139

Epoch: 6| Step: 7
Training loss: 3.12254389564807
Validation loss: 3.00808508577643

Epoch: 6| Step: 8
Training loss: 3.116475341826625
Validation loss: 3.006644509850512

Epoch: 6| Step: 9
Training loss: 3.5987555101199433
Validation loss: 3.0089156115115103

Epoch: 6| Step: 10
Training loss: 1.803389441603887
Validation loss: 3.005622736384025

Epoch: 6| Step: 11
Training loss: 3.00188926971367
Validation loss: 3.0071094336347306

Epoch: 6| Step: 12
Training loss: 3.225270601497006
Validation loss: 3.0063581922923976

Epoch: 6| Step: 13
Training loss: 3.564570043031109
Validation loss: 3.004995391450687

Epoch: 40| Step: 0
Training loss: 3.0492778986384628
Validation loss: 2.9981599688672667

Epoch: 6| Step: 1
Training loss: 3.6150552549663693
Validation loss: 2.992884236487264

Epoch: 6| Step: 2
Training loss: 2.6153464147315306
Validation loss: 2.987612368121083

Epoch: 6| Step: 3
Training loss: 3.9484616241503088
Validation loss: 2.978796669974293

Epoch: 6| Step: 4
Training loss: 3.121200082278174
Validation loss: 2.9752113669798734

Epoch: 6| Step: 5
Training loss: 3.203874007320693
Validation loss: 3.0007510065588616

Epoch: 6| Step: 6
Training loss: 3.8371053188286615
Validation loss: 3.004044322471181

Epoch: 6| Step: 7
Training loss: 3.129416434880534
Validation loss: 3.0036784167173702

Epoch: 6| Step: 8
Training loss: 3.1246413978817547
Validation loss: 3.0143685681627783

Epoch: 6| Step: 9
Training loss: 3.764881234695823
Validation loss: 2.982099224914453

Epoch: 6| Step: 10
Training loss: 2.555930112489228
Validation loss: 2.9999545326342356

Epoch: 6| Step: 11
Training loss: 3.5396942181177007
Validation loss: 2.9946195608427586

Epoch: 6| Step: 12
Training loss: 3.2494327343542246
Validation loss: 2.9859733233690253

Epoch: 6| Step: 13
Training loss: 2.1865867888391106
Validation loss: 2.9780487965336624

Epoch: 41| Step: 0
Training loss: 3.008006855023466
Validation loss: 2.978573500354887

Epoch: 6| Step: 1
Training loss: 3.530525605836445
Validation loss: 2.9870903016705554

Epoch: 6| Step: 2
Training loss: 2.368310240333858
Validation loss: 2.9931512098553843

Epoch: 6| Step: 3
Training loss: 3.3081485309120695
Validation loss: 3.0021071827123555

Epoch: 6| Step: 4
Training loss: 3.133558379539299
Validation loss: 2.990366078887723

Epoch: 6| Step: 5
Training loss: 3.294354238949505
Validation loss: 2.9898997871055615

Epoch: 6| Step: 6
Training loss: 3.218551333324
Validation loss: 2.975670359534506

Epoch: 6| Step: 7
Training loss: 3.8601418169682487
Validation loss: 2.9622046897407963

Epoch: 6| Step: 8
Training loss: 2.6742133008726983
Validation loss: 2.9577832771454506

Epoch: 6| Step: 9
Training loss: 3.692900243308943
Validation loss: 2.961401385915512

Epoch: 6| Step: 10
Training loss: 3.8445463518614686
Validation loss: 2.9785008370906367

Epoch: 6| Step: 11
Training loss: 2.666431257665472
Validation loss: 3.001132192570896

Epoch: 6| Step: 12
Training loss: 3.568328105620383
Validation loss: 3.0298532308936306

Epoch: 6| Step: 13
Training loss: 3.2841160927161224
Validation loss: 3.0594835583910163

Epoch: 42| Step: 0
Training loss: 3.1286977634191864
Validation loss: 3.0700797279493344

Epoch: 6| Step: 1
Training loss: 3.037786456128796
Validation loss: 3.0838282076316395

Epoch: 6| Step: 2
Training loss: 2.460796824476279
Validation loss: 3.0727678371711806

Epoch: 6| Step: 3
Training loss: 3.4674043536866783
Validation loss: 3.0664171569684586

Epoch: 6| Step: 4
Training loss: 3.239479349477085
Validation loss: 3.056243022896729

Epoch: 6| Step: 5
Training loss: 2.8665341664528277
Validation loss: 3.051089755507216

Epoch: 6| Step: 6
Training loss: 2.7991640750486506
Validation loss: 3.0432543339849705

Epoch: 6| Step: 7
Training loss: 4.381669111245103
Validation loss: 3.0330511234564694

Epoch: 6| Step: 8
Training loss: 3.133565531574827
Validation loss: 3.012215939956603

Epoch: 6| Step: 9
Training loss: 3.2724651631481967
Validation loss: 2.994025803806131

Epoch: 6| Step: 10
Training loss: 4.155956745557786
Validation loss: 2.971655666641138

Epoch: 6| Step: 11
Training loss: 3.4393067206915613
Validation loss: 2.946526174283102

Epoch: 6| Step: 12
Training loss: 3.005541134570725
Validation loss: 2.9434837821661763

Epoch: 6| Step: 13
Training loss: 2.9718526588667182
Validation loss: 2.952973448217738

Epoch: 43| Step: 0
Training loss: 3.083631208997838
Validation loss: 2.9464340844538044

Epoch: 6| Step: 1
Training loss: 3.062846261515535
Validation loss: 2.94516126520171

Epoch: 6| Step: 2
Training loss: 3.339041844519641
Validation loss: 2.94040965646696

Epoch: 6| Step: 3
Training loss: 2.9663802476556578
Validation loss: 2.9498202154939093

Epoch: 6| Step: 4
Training loss: 3.325984069217188
Validation loss: 2.949728066849202

Epoch: 6| Step: 5
Training loss: 2.410011621027743
Validation loss: 2.956212387638305

Epoch: 6| Step: 6
Training loss: 3.114216930734724
Validation loss: 2.9779885410261455

Epoch: 6| Step: 7
Training loss: 3.6530028702134354
Validation loss: 3.0205790943490225

Epoch: 6| Step: 8
Training loss: 3.48778063010776
Validation loss: 2.997638707983532

Epoch: 6| Step: 9
Training loss: 3.0340795779771574
Validation loss: 2.9671772917214887

Epoch: 6| Step: 10
Training loss: 3.2943723318675016
Validation loss: 2.9501250508359482

Epoch: 6| Step: 11
Training loss: 3.7876352670013675
Validation loss: 2.9454546447175005

Epoch: 6| Step: 12
Training loss: 3.478916699839038
Validation loss: 2.9434590251785684

Epoch: 6| Step: 13
Training loss: 3.05827382486294
Validation loss: 2.9408905545109247

Epoch: 44| Step: 0
Training loss: 3.748515025804437
Validation loss: 2.938774488698476

Epoch: 6| Step: 1
Training loss: 3.4169596724749787
Validation loss: 2.939710313058232

Epoch: 6| Step: 2
Training loss: 3.0276007955390085
Validation loss: 2.939825247355802

Epoch: 6| Step: 3
Training loss: 3.4764882969170303
Validation loss: 2.93905462364804

Epoch: 6| Step: 4
Training loss: 3.41897041684228
Validation loss: 2.939356982972405

Epoch: 6| Step: 5
Training loss: 2.631190221836876
Validation loss: 2.937418320182852

Epoch: 6| Step: 6
Training loss: 2.963919474157824
Validation loss: 2.9375212438858544

Epoch: 6| Step: 7
Training loss: 3.1681537315464072
Validation loss: 2.9382181505021725

Epoch: 6| Step: 8
Training loss: 3.400962996144983
Validation loss: 2.937232356815755

Epoch: 6| Step: 9
Training loss: 2.723927883661196
Validation loss: 2.9444157354312606

Epoch: 6| Step: 10
Training loss: 3.208374039693106
Validation loss: 2.9455784194300465

Epoch: 6| Step: 11
Training loss: 3.6526889250327135
Validation loss: 2.95120578134321

Epoch: 6| Step: 12
Training loss: 2.879639572266312
Validation loss: 2.9363619481236087

Epoch: 6| Step: 13
Training loss: 3.191538776461554
Validation loss: 2.9330812740145222

Epoch: 45| Step: 0
Training loss: 3.608207480781175
Validation loss: 2.9321721042626776

Epoch: 6| Step: 1
Training loss: 3.072536294100438
Validation loss: 2.930126776683292

Epoch: 6| Step: 2
Training loss: 2.9456602341559845
Validation loss: 2.9290034501168476

Epoch: 6| Step: 3
Training loss: 3.670424154441928
Validation loss: 2.9299673557951382

Epoch: 6| Step: 4
Training loss: 3.6161229851493695
Validation loss: 2.931133649153104

Epoch: 6| Step: 5
Training loss: 3.4256204808787727
Validation loss: 2.9311741754632332

Epoch: 6| Step: 6
Training loss: 3.1309294332850968
Validation loss: 2.9314247586339874

Epoch: 6| Step: 7
Training loss: 2.377930589867642
Validation loss: 2.932215130712978

Epoch: 6| Step: 8
Training loss: 2.784627342563217
Validation loss: 2.93570628456688

Epoch: 6| Step: 9
Training loss: 3.2691937526488695
Validation loss: 2.9314904741370316

Epoch: 6| Step: 10
Training loss: 2.667331692105969
Validation loss: 2.928207494847726

Epoch: 6| Step: 11
Training loss: 2.9013670231508706
Validation loss: 2.9276193863550595

Epoch: 6| Step: 12
Training loss: 3.594788111144505
Validation loss: 2.926094101427928

Epoch: 6| Step: 13
Training loss: 3.9380089567130057
Validation loss: 2.9243599756491063

Epoch: 46| Step: 0
Training loss: 2.482411598406394
Validation loss: 2.926695016265868

Epoch: 6| Step: 1
Training loss: 2.9737692715508244
Validation loss: 2.922827725386084

Epoch: 6| Step: 2
Training loss: 3.361491259750631
Validation loss: 2.9224422014633875

Epoch: 6| Step: 3
Training loss: 4.027177986707453
Validation loss: 2.9211972297063564

Epoch: 6| Step: 4
Training loss: 2.5199562837956555
Validation loss: 2.924015451128658

Epoch: 6| Step: 5
Training loss: 3.093342455598381
Validation loss: 2.921435086291384

Epoch: 6| Step: 6
Training loss: 3.6142929063076017
Validation loss: 2.9196958682610545

Epoch: 6| Step: 7
Training loss: 3.0567518512610716
Validation loss: 2.921584934368308

Epoch: 6| Step: 8
Training loss: 2.7457502646801677
Validation loss: 2.916692829161235

Epoch: 6| Step: 9
Training loss: 3.4841036156313674
Validation loss: 2.915864841860308

Epoch: 6| Step: 10
Training loss: 3.871756765363015
Validation loss: 2.9231219975516507

Epoch: 6| Step: 11
Training loss: 2.9524901984404974
Validation loss: 2.919049839566545

Epoch: 6| Step: 12
Training loss: 3.3296939214307066
Validation loss: 2.9193177499309138

Epoch: 6| Step: 13
Training loss: 2.8133667352088647
Validation loss: 2.9142258311945537

Epoch: 47| Step: 0
Training loss: 3.4571610420991816
Validation loss: 2.911890176665822

Epoch: 6| Step: 1
Training loss: 3.1231537514936325
Validation loss: 2.912886176750269

Epoch: 6| Step: 2
Training loss: 3.5568410533088795
Validation loss: 2.9116484621975456

Epoch: 6| Step: 3
Training loss: 3.2271529943550257
Validation loss: 2.912298444343428

Epoch: 6| Step: 4
Training loss: 2.9879084734808123
Validation loss: 2.9130830439174633

Epoch: 6| Step: 5
Training loss: 2.9896160660036153
Validation loss: 2.914384346827312

Epoch: 6| Step: 6
Training loss: 3.065848252375156
Validation loss: 2.917414772906262

Epoch: 6| Step: 7
Training loss: 2.618481671918732
Validation loss: 2.9156449806465967

Epoch: 6| Step: 8
Training loss: 3.417007816929817
Validation loss: 2.9144834712353274

Epoch: 6| Step: 9
Training loss: 3.469993299758115
Validation loss: 2.9108713266251223

Epoch: 6| Step: 10
Training loss: 2.93854260711132
Validation loss: 2.9097874557151973

Epoch: 6| Step: 11
Training loss: 3.1209149936098655
Validation loss: 2.907725911754669

Epoch: 6| Step: 12
Training loss: 3.5532754965173177
Validation loss: 2.905926312696115

Epoch: 6| Step: 13
Training loss: 3.330924991978213
Validation loss: 2.9059483652449107

Epoch: 48| Step: 0
Training loss: 3.217996453529239
Validation loss: 2.9029748276044685

Epoch: 6| Step: 1
Training loss: 4.012918354221945
Validation loss: 2.905643180578343

Epoch: 6| Step: 2
Training loss: 3.7547551841524798
Validation loss: 2.9114827340268574

Epoch: 6| Step: 3
Training loss: 2.2950373973583607
Validation loss: 2.901929315734511

Epoch: 6| Step: 4
Training loss: 3.18314333110679
Validation loss: 2.8990056154142896

Epoch: 6| Step: 5
Training loss: 2.493714346188625
Validation loss: 2.9020996909767134

Epoch: 6| Step: 6
Training loss: 3.6031190235257107
Validation loss: 2.9030454409538446

Epoch: 6| Step: 7
Training loss: 2.903902808252265
Validation loss: 2.90031439159402

Epoch: 6| Step: 8
Training loss: 3.575786242690965
Validation loss: 2.9017879419995483

Epoch: 6| Step: 9
Training loss: 3.4890349151709885
Validation loss: 2.9008233353164123

Epoch: 6| Step: 10
Training loss: 2.713577699818614
Validation loss: 2.8987698070542063

Epoch: 6| Step: 11
Training loss: 2.759631802283338
Validation loss: 2.901580897994147

Epoch: 6| Step: 12
Training loss: 2.9310159748413844
Validation loss: 2.9017625845521775

Epoch: 6| Step: 13
Training loss: 3.338918028916074
Validation loss: 2.905229330812977

Epoch: 49| Step: 0
Training loss: 2.168812520557877
Validation loss: 2.9058063427344916

Epoch: 6| Step: 1
Training loss: 3.311984471925095
Validation loss: 2.903897969479428

Epoch: 6| Step: 2
Training loss: 3.0280386047321204
Validation loss: 2.90139983889268

Epoch: 6| Step: 3
Training loss: 3.524393226940352
Validation loss: 2.8987988502491886

Epoch: 6| Step: 4
Training loss: 3.5627631374687336
Validation loss: 2.899418769937906

Epoch: 6| Step: 5
Training loss: 3.651786884143787
Validation loss: 2.8975771636641503

Epoch: 6| Step: 6
Training loss: 3.275844808626483
Validation loss: 2.896203808307768

Epoch: 6| Step: 7
Training loss: 3.051749531238764
Validation loss: 2.8969138528631886

Epoch: 6| Step: 8
Training loss: 3.139479698760714
Validation loss: 2.8921694083378213

Epoch: 6| Step: 9
Training loss: 3.186449663230039
Validation loss: 2.8936901582370234

Epoch: 6| Step: 10
Training loss: 2.6388323415308115
Validation loss: 2.8916044385691633

Epoch: 6| Step: 11
Training loss: 2.7708097662437368
Validation loss: 2.891164107797922

Epoch: 6| Step: 12
Training loss: 3.5068001762570233
Validation loss: 2.891190920183243

Epoch: 6| Step: 13
Training loss: 3.633919627164235
Validation loss: 2.8891055897741786

Epoch: 50| Step: 0
Training loss: 3.558033602834083
Validation loss: 2.8863378765820507

Epoch: 6| Step: 1
Training loss: 3.43776909901957
Validation loss: 2.8872688319182926

Epoch: 6| Step: 2
Training loss: 3.241671233839987
Validation loss: 2.8841190235971625

Epoch: 6| Step: 3
Training loss: 2.4525205997453505
Validation loss: 2.88331464059226

Epoch: 6| Step: 4
Training loss: 3.1327738390889124
Validation loss: 2.8834247678700518

Epoch: 6| Step: 5
Training loss: 2.984395451500605
Validation loss: 2.8792149222212737

Epoch: 6| Step: 6
Training loss: 3.268976417416766
Validation loss: 2.8813862007188398

Epoch: 6| Step: 7
Training loss: 2.6227483629238484
Validation loss: 2.885594448501688

Epoch: 6| Step: 8
Training loss: 2.397143782325305
Validation loss: 2.880835412010781

Epoch: 6| Step: 9
Training loss: 3.376400692234481
Validation loss: 2.877386697727501

Epoch: 6| Step: 10
Training loss: 3.8326897011705743
Validation loss: 2.88002187450253

Epoch: 6| Step: 11
Training loss: 3.4330618210872967
Validation loss: 2.8765985771540095

Epoch: 6| Step: 12
Training loss: 3.239170223934522
Validation loss: 2.876083294769841

Epoch: 6| Step: 13
Training loss: 3.0520126456102443
Validation loss: 2.8769141464266723

Testing loss: 3.0650786669677044
