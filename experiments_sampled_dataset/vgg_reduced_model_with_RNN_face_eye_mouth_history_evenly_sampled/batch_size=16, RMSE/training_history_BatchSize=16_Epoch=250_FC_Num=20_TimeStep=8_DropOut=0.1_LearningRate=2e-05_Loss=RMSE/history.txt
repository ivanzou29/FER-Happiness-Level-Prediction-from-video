Epoch: 1| Step: 0
Training loss: 6.3806247206815
Validation loss: 5.793987972539914

Epoch: 6| Step: 1
Training loss: 6.1758501216708455
Validation loss: 5.782051887096676

Epoch: 6| Step: 2
Training loss: 5.621234905281184
Validation loss: 5.771231301478496

Epoch: 6| Step: 3
Training loss: 6.273754905186491
Validation loss: 5.759167618249158

Epoch: 6| Step: 4
Training loss: 6.122037521471642
Validation loss: 5.744604528171868

Epoch: 6| Step: 5
Training loss: 7.109593918332731
Validation loss: 5.727975597205181

Epoch: 6| Step: 6
Training loss: 5.886050605953014
Validation loss: 5.709930883804301

Epoch: 6| Step: 7
Training loss: 4.645871263471786
Validation loss: 5.689373437570612

Epoch: 6| Step: 8
Training loss: 5.195886474109211
Validation loss: 5.666138260011748

Epoch: 6| Step: 9
Training loss: 5.5597997390578495
Validation loss: 5.638843680399463

Epoch: 6| Step: 10
Training loss: 5.251501322840815
Validation loss: 5.607300801419728

Epoch: 6| Step: 11
Training loss: 5.433862631512185
Validation loss: 5.571915105738478

Epoch: 6| Step: 12
Training loss: 4.1208745961426425
Validation loss: 5.532934159668161

Epoch: 6| Step: 13
Training loss: 5.775024361166826
Validation loss: 5.487933668617389

Epoch: 2| Step: 0
Training loss: 5.411011467829325
Validation loss: 5.440975190892183

Epoch: 6| Step: 1
Training loss: 5.609284211595547
Validation loss: 5.3889707076955755

Epoch: 6| Step: 2
Training loss: 6.2484699665284
Validation loss: 5.332875752559678

Epoch: 6| Step: 3
Training loss: 6.006205846205422
Validation loss: 5.273983428905027

Epoch: 6| Step: 4
Training loss: 4.873722202391012
Validation loss: 5.21099616450004

Epoch: 6| Step: 5
Training loss: 4.529701968193304
Validation loss: 5.149144739007728

Epoch: 6| Step: 6
Training loss: 5.951704201146863
Validation loss: 5.085000761046991

Epoch: 6| Step: 7
Training loss: 4.851552474891514
Validation loss: 5.021008134073878

Epoch: 6| Step: 8
Training loss: 5.915568433391394
Validation loss: 4.955005892515236

Epoch: 6| Step: 9
Training loss: 3.583805289718494
Validation loss: 4.890956181408641

Epoch: 6| Step: 10
Training loss: 3.7653794584510987
Validation loss: 4.831153844283937

Epoch: 6| Step: 11
Training loss: 4.443121344929328
Validation loss: 4.775625344683414

Epoch: 6| Step: 12
Training loss: 4.874986306195711
Validation loss: 4.725083784914573

Epoch: 6| Step: 13
Training loss: 5.100864052973188
Validation loss: 4.6757693610660995

Epoch: 3| Step: 0
Training loss: 4.744774604484736
Validation loss: 4.632859004640036

Epoch: 6| Step: 1
Training loss: 5.290123702046955
Validation loss: 4.588385160330685

Epoch: 6| Step: 2
Training loss: 3.7915192180651056
Validation loss: 4.543332534513223

Epoch: 6| Step: 3
Training loss: 5.477863500069222
Validation loss: 4.506753891578135

Epoch: 6| Step: 4
Training loss: 4.718494534682447
Validation loss: 4.473486058559375

Epoch: 6| Step: 5
Training loss: 3.8735106282411524
Validation loss: 4.443325431159488

Epoch: 6| Step: 6
Training loss: 4.773540789146922
Validation loss: 4.4161931668496806

Epoch: 6| Step: 7
Training loss: 5.340974142538022
Validation loss: 4.382718201172417

Epoch: 6| Step: 8
Training loss: 4.451252861675488
Validation loss: 4.3488888098401315

Epoch: 6| Step: 9
Training loss: 4.307050274592937
Validation loss: 4.3159910900040686

Epoch: 6| Step: 10
Training loss: 3.9809776033309525
Validation loss: 4.2874737065274156

Epoch: 6| Step: 11
Training loss: 5.053790099772506
Validation loss: 4.263394634775889

Epoch: 6| Step: 12
Training loss: 3.0598565974324003
Validation loss: 4.237992017991756

Epoch: 6| Step: 13
Training loss: 3.3606142109376167
Validation loss: 4.215116022707341

Epoch: 4| Step: 0
Training loss: 4.45886695496678
Validation loss: 4.18913188268448

Epoch: 6| Step: 1
Training loss: 4.065409396155522
Validation loss: 4.16246644535944

Epoch: 6| Step: 2
Training loss: 4.276859900573183
Validation loss: 4.151927685712811

Epoch: 6| Step: 3
Training loss: 4.058074888633502
Validation loss: 4.128971861293745

Epoch: 6| Step: 4
Training loss: 4.429248498762961
Validation loss: 4.109632225974246

Epoch: 6| Step: 5
Training loss: 4.275309652970669
Validation loss: 4.093389743714719

Epoch: 6| Step: 6
Training loss: 4.493443693245219
Validation loss: 4.079255506184587

Epoch: 6| Step: 7
Training loss: 4.974987026178514
Validation loss: 4.065832644377328

Epoch: 6| Step: 8
Training loss: 4.260427585329771
Validation loss: 4.051648810565356

Epoch: 6| Step: 9
Training loss: 4.459489096215796
Validation loss: 4.035848191822646

Epoch: 6| Step: 10
Training loss: 3.516817831493708
Validation loss: 4.014789257956801

Epoch: 6| Step: 11
Training loss: 3.937744254150616
Validation loss: 4.001718298177102

Epoch: 6| Step: 12
Training loss: 4.182155557827002
Validation loss: 3.985218130200187

Epoch: 6| Step: 13
Training loss: 2.9652022194051675
Validation loss: 3.97049323255689

Epoch: 5| Step: 0
Training loss: 2.5757846266470135
Validation loss: 3.95966018864483

Epoch: 6| Step: 1
Training loss: 4.203760262169677
Validation loss: 3.9412853317097944

Epoch: 6| Step: 2
Training loss: 3.5788799971921046
Validation loss: 3.927084112353604

Epoch: 6| Step: 3
Training loss: 3.552752360025258
Validation loss: 3.9203272181771904

Epoch: 6| Step: 4
Training loss: 4.19272321931396
Validation loss: 3.899763405235932

Epoch: 6| Step: 5
Training loss: 4.120078184997013
Validation loss: 3.880924060344651

Epoch: 6| Step: 6
Training loss: 3.3164985563015392
Validation loss: 3.8694156575625356

Epoch: 6| Step: 7
Training loss: 3.3850885007211913
Validation loss: 3.8605713730549596

Epoch: 6| Step: 8
Training loss: 4.824836277531132
Validation loss: 3.8504619500770008

Epoch: 6| Step: 9
Training loss: 4.323757350327574
Validation loss: 3.8355544603083906

Epoch: 6| Step: 10
Training loss: 3.5503377941766034
Validation loss: 3.826494782500577

Epoch: 6| Step: 11
Training loss: 5.282676368726293
Validation loss: 3.854206547728949

Epoch: 6| Step: 12
Training loss: 4.311909731951612
Validation loss: 3.819035538269395

Epoch: 6| Step: 13
Training loss: 4.829151229680128
Validation loss: 3.8470551741657286

Epoch: 6| Step: 0
Training loss: 4.312422599650748
Validation loss: 3.863697955031213

Epoch: 6| Step: 1
Training loss: 4.277310974831622
Validation loss: 3.8504920361658788

Epoch: 6| Step: 2
Training loss: 3.9237582483900666
Validation loss: 3.8156135187427056

Epoch: 6| Step: 3
Training loss: 3.7605691105736097
Validation loss: 3.7886140379309166

Epoch: 6| Step: 4
Training loss: 3.1605099172462214
Validation loss: 3.7690133177364875

Epoch: 6| Step: 5
Training loss: 3.4069367162740622
Validation loss: 3.7625655153595376

Epoch: 6| Step: 6
Training loss: 3.908442743934877
Validation loss: 3.7597130067188003

Epoch: 6| Step: 7
Training loss: 4.895929451939055
Validation loss: 3.747859204304439

Epoch: 6| Step: 8
Training loss: 4.336753424779184
Validation loss: 3.73268911467969

Epoch: 6| Step: 9
Training loss: 3.488960704010353
Validation loss: 3.7181504054785828

Epoch: 6| Step: 10
Training loss: 3.326687784554746
Validation loss: 3.707548977752929

Epoch: 6| Step: 11
Training loss: 3.9109239615351967
Validation loss: 3.6938291627365807

Epoch: 6| Step: 12
Training loss: 3.9072733034648026
Validation loss: 3.6814867186971996

Epoch: 6| Step: 13
Training loss: 4.318520586514825
Validation loss: 3.6736103161271947

Epoch: 7| Step: 0
Training loss: 4.179213566515344
Validation loss: 3.6691265249727754

Epoch: 6| Step: 1
Training loss: 3.3726473484977793
Validation loss: 3.66344094995015

Epoch: 6| Step: 2
Training loss: 3.1621193275978334
Validation loss: 3.6580906685303427

Epoch: 6| Step: 3
Training loss: 3.91687885007278
Validation loss: 3.647613969987592

Epoch: 6| Step: 4
Training loss: 3.736776944137396
Validation loss: 3.6396537019195123

Epoch: 6| Step: 5
Training loss: 3.944375468861385
Validation loss: 3.6366782500020514

Epoch: 6| Step: 6
Training loss: 3.996543344393162
Validation loss: 3.6358411358787452

Epoch: 6| Step: 7
Training loss: 4.260676045749229
Validation loss: 3.633959427042305

Epoch: 6| Step: 8
Training loss: 3.570137403606119
Validation loss: 3.6274357053657895

Epoch: 6| Step: 9
Training loss: 3.905201275238201
Validation loss: 3.6200470869747616

Epoch: 6| Step: 10
Training loss: 4.243585570440679
Validation loss: 3.6111168474562536

Epoch: 6| Step: 11
Training loss: 3.416714892783613
Validation loss: 3.6016317587829434

Epoch: 6| Step: 12
Training loss: 4.045886769647368
Validation loss: 3.5883215339572234

Epoch: 6| Step: 13
Training loss: 3.423766009936412
Validation loss: 3.579008158304784

Epoch: 8| Step: 0
Training loss: 4.469643243467755
Validation loss: 3.569612242437732

Epoch: 6| Step: 1
Training loss: 3.6232950871006917
Validation loss: 3.564963751929366

Epoch: 6| Step: 2
Training loss: 4.278223457624571
Validation loss: 3.5604460443682666

Epoch: 6| Step: 3
Training loss: 3.3496876699122136
Validation loss: 3.554360253417005

Epoch: 6| Step: 4
Training loss: 4.103497962241854
Validation loss: 3.5465610602469106

Epoch: 6| Step: 5
Training loss: 2.8117422990589196
Validation loss: 3.5351144124063336

Epoch: 6| Step: 6
Training loss: 2.904804157214813
Validation loss: 3.5356329048653357

Epoch: 6| Step: 7
Training loss: 4.188924290996227
Validation loss: 3.5366367378030494

Epoch: 6| Step: 8
Training loss: 4.350879334768751
Validation loss: 3.5239617670017553

Epoch: 6| Step: 9
Training loss: 3.4802372060151066
Validation loss: 3.5107351612435673

Epoch: 6| Step: 10
Training loss: 3.330256106634865
Validation loss: 3.503616512538597

Epoch: 6| Step: 11
Training loss: 3.744510065277871
Validation loss: 3.4968184954999466

Epoch: 6| Step: 12
Training loss: 3.6294670205515693
Validation loss: 3.489237607537975

Epoch: 6| Step: 13
Training loss: 3.5804799422027367
Validation loss: 3.482279372428767

Epoch: 9| Step: 0
Training loss: 4.262292027923336
Validation loss: 3.477808998322742

Epoch: 6| Step: 1
Training loss: 3.48806471542378
Validation loss: 3.4697030326987224

Epoch: 6| Step: 2
Training loss: 3.4561516801256214
Validation loss: 3.461412242111144

Epoch: 6| Step: 3
Training loss: 3.2727692497817342
Validation loss: 3.4573619341624733

Epoch: 6| Step: 4
Training loss: 3.4734128936568682
Validation loss: 3.4522488251385455

Epoch: 6| Step: 5
Training loss: 3.686934864252053
Validation loss: 3.4541902203442545

Epoch: 6| Step: 6
Training loss: 3.3597511258370725
Validation loss: 3.451333857584435

Epoch: 6| Step: 7
Training loss: 4.158122623178596
Validation loss: 3.443751890442044

Epoch: 6| Step: 8
Training loss: 2.9273328753947165
Validation loss: 3.435375600531177

Epoch: 6| Step: 9
Training loss: 4.176413820919145
Validation loss: 3.434614890056586

Epoch: 6| Step: 10
Training loss: 4.3642961624587695
Validation loss: 3.429924573181098

Epoch: 6| Step: 11
Training loss: 3.254116239332036
Validation loss: 3.422812170522584

Epoch: 6| Step: 12
Training loss: 3.1304219321664406
Validation loss: 3.4180214059644087

Epoch: 6| Step: 13
Training loss: 4.147734214235343
Validation loss: 3.4161953849913367

Epoch: 10| Step: 0
Training loss: 3.2324004849651033
Validation loss: 3.4174580836713933

Epoch: 6| Step: 1
Training loss: 3.8426356987703576
Validation loss: 3.4401843511015415

Epoch: 6| Step: 2
Training loss: 4.100537446315155
Validation loss: 3.3983499480103485

Epoch: 6| Step: 3
Training loss: 3.240186105728475
Validation loss: 3.39310224457184

Epoch: 6| Step: 4
Training loss: 2.9736485272573265
Validation loss: 3.4015494218870574

Epoch: 6| Step: 5
Training loss: 2.8886672529966404
Validation loss: 3.4059565616145835

Epoch: 6| Step: 6
Training loss: 4.317263860645031
Validation loss: 3.3883945218364393

Epoch: 6| Step: 7
Training loss: 3.9574178071924115
Validation loss: 3.3786502985643234

Epoch: 6| Step: 8
Training loss: 4.172049415171378
Validation loss: 3.3698932504140306

Epoch: 6| Step: 9
Training loss: 3.30554303577378
Validation loss: 3.372571371418476

Epoch: 6| Step: 10
Training loss: 4.064088950828235
Validation loss: 3.3717226897983648

Epoch: 6| Step: 11
Training loss: 3.8242157574681857
Validation loss: 3.358988040158725

Epoch: 6| Step: 12
Training loss: 3.529784582119282
Validation loss: 3.3460671438194973

Epoch: 6| Step: 13
Training loss: 1.4681236067660148
Validation loss: 3.3415609122418877

Epoch: 11| Step: 0
Training loss: 3.4189845030869375
Validation loss: 3.3413953290499894

Epoch: 6| Step: 1
Training loss: 3.6309798017027766
Validation loss: 3.33913778920314

Epoch: 6| Step: 2
Training loss: 3.2701066945252872
Validation loss: 3.32639044889507

Epoch: 6| Step: 3
Training loss: 4.296910289272702
Validation loss: 3.3213140929697067

Epoch: 6| Step: 4
Training loss: 2.9632514225982027
Validation loss: 3.3146788353552283

Epoch: 6| Step: 5
Training loss: 3.7322335587468443
Validation loss: 3.3149907984046205

Epoch: 6| Step: 6
Training loss: 3.5093525859494035
Validation loss: 3.3112483261155514

Epoch: 6| Step: 7
Training loss: 3.5044886552624592
Validation loss: 3.305790527259014

Epoch: 6| Step: 8
Training loss: 3.6831789723728194
Validation loss: 3.2973665766058575

Epoch: 6| Step: 9
Training loss: 3.009322305219954
Validation loss: 3.293648368720021

Epoch: 6| Step: 10
Training loss: 3.8316733594661456
Validation loss: 3.2902700629417345

Epoch: 6| Step: 11
Training loss: 3.2631771276519244
Validation loss: 3.2899126951291824

Epoch: 6| Step: 12
Training loss: 3.569673510242437
Validation loss: 3.295877068952036

Epoch: 6| Step: 13
Training loss: 4.018984328300862
Validation loss: 3.285570160791324

Epoch: 12| Step: 0
Training loss: 3.15910285962416
Validation loss: 3.2746956691449007

Epoch: 6| Step: 1
Training loss: 4.549532503697195
Validation loss: 3.274552469268124

Epoch: 6| Step: 2
Training loss: 3.6910162502727935
Validation loss: 3.2704784722553306

Epoch: 6| Step: 3
Training loss: 3.500639448335291
Validation loss: 3.2706910705875307

Epoch: 6| Step: 4
Training loss: 3.0274445547733095
Validation loss: 3.268608429667113

Epoch: 6| Step: 5
Training loss: 3.7336637066938176
Validation loss: 3.2717495171955204

Epoch: 6| Step: 6
Training loss: 2.8121135870076284
Validation loss: 3.260598343360407

Epoch: 6| Step: 7
Training loss: 4.297343724434607
Validation loss: 3.2536285360271764

Epoch: 6| Step: 8
Training loss: 3.4449897320819973
Validation loss: 3.25341364547404

Epoch: 6| Step: 9
Training loss: 3.1411700179106665
Validation loss: 3.2490675797908146

Epoch: 6| Step: 10
Training loss: 3.7347320002931497
Validation loss: 3.2469117405849484

Epoch: 6| Step: 11
Training loss: 2.9611310669125355
Validation loss: 3.2411108252232226

Epoch: 6| Step: 12
Training loss: 3.3688061711258666
Validation loss: 3.240073351200014

Epoch: 6| Step: 13
Training loss: 3.1253707665793615
Validation loss: 3.2340328508578975

Epoch: 13| Step: 0
Training loss: 3.8479112879466473
Validation loss: 3.235984532946576

Epoch: 6| Step: 1
Training loss: 3.1688366699404495
Validation loss: 3.2355839952268823

Epoch: 6| Step: 2
Training loss: 3.7028561265126605
Validation loss: 3.232846772154345

Epoch: 6| Step: 3
Training loss: 3.267070249682033
Validation loss: 3.229704021370701

Epoch: 6| Step: 4
Training loss: 2.9946928765408796
Validation loss: 3.2230882409682167

Epoch: 6| Step: 5
Training loss: 3.6955718580528543
Validation loss: 3.22111769974596

Epoch: 6| Step: 6
Training loss: 3.9679832618960242
Validation loss: 3.2179631913182494

Epoch: 6| Step: 7
Training loss: 4.006922453862757
Validation loss: 3.2147174587564824

Epoch: 6| Step: 8
Training loss: 3.7718449424677485
Validation loss: 3.2105646757553132

Epoch: 6| Step: 9
Training loss: 3.2066775090859747
Validation loss: 3.2078508411936024

Epoch: 6| Step: 10
Training loss: 2.3567217124470665
Validation loss: 3.2052343370868073

Epoch: 6| Step: 11
Training loss: 3.4909071655430686
Validation loss: 3.205102351321819

Epoch: 6| Step: 12
Training loss: 3.3438904634723996
Validation loss: 3.2019095439039944

Epoch: 6| Step: 13
Training loss: 3.4904965396695102
Validation loss: 3.201927571511977

Epoch: 14| Step: 0
Training loss: 3.7984889489490534
Validation loss: 3.199129720627526

Epoch: 6| Step: 1
Training loss: 3.107112809209745
Validation loss: 3.198173417779277

Epoch: 6| Step: 2
Training loss: 3.9165843522099806
Validation loss: 3.1941056784515567

Epoch: 6| Step: 3
Training loss: 3.6405773241580555
Validation loss: 3.201382121789885

Epoch: 6| Step: 4
Training loss: 3.510973213669465
Validation loss: 3.220001604980036

Epoch: 6| Step: 5
Training loss: 3.445830637059354
Validation loss: 3.1873247201763384

Epoch: 6| Step: 6
Training loss: 3.054995470059247
Validation loss: 3.1857133249739644

Epoch: 6| Step: 7
Training loss: 3.1975043877041367
Validation loss: 3.182936890968592

Epoch: 6| Step: 8
Training loss: 2.882136568051454
Validation loss: 3.1811523449588264

Epoch: 6| Step: 9
Training loss: 3.794100780075579
Validation loss: 3.1804127505656625

Epoch: 6| Step: 10
Training loss: 3.1493101969307022
Validation loss: 3.1781586493390024

Epoch: 6| Step: 11
Training loss: 2.9411170280283976
Validation loss: 3.181547197299072

Epoch: 6| Step: 12
Training loss: 3.604346798197255
Validation loss: 3.1823521190715307

Epoch: 6| Step: 13
Training loss: 4.336497887492009
Validation loss: 3.1857067454907084

Epoch: 15| Step: 0
Training loss: 3.761618607912238
Validation loss: 3.1862512402809315

Epoch: 6| Step: 1
Training loss: 3.308540424876503
Validation loss: 3.17249527835177

Epoch: 6| Step: 2
Training loss: 3.0086640180624995
Validation loss: 3.1692736396949357

Epoch: 6| Step: 3
Training loss: 4.520735544767318
Validation loss: 3.166132263876016

Epoch: 6| Step: 4
Training loss: 3.4491417466896492
Validation loss: 3.166197538572666

Epoch: 6| Step: 5
Training loss: 2.8739520941280947
Validation loss: 3.1622307271027297

Epoch: 6| Step: 6
Training loss: 3.4996697406265396
Validation loss: 3.1622341588209877

Epoch: 6| Step: 7
Training loss: 3.5119628821390556
Validation loss: 3.1618025397508625

Epoch: 6| Step: 8
Training loss: 2.7828129866362397
Validation loss: 3.159564147755003

Epoch: 6| Step: 9
Training loss: 3.1679219384738886
Validation loss: 3.1608357433852787

Epoch: 6| Step: 10
Training loss: 3.678460501745646
Validation loss: 3.158703206701073

Epoch: 6| Step: 11
Training loss: 3.0953731710003924
Validation loss: 3.155821067785595

Epoch: 6| Step: 12
Training loss: 3.5033193923958343
Validation loss: 3.154929865470071

Epoch: 6| Step: 13
Training loss: 3.5648561683520414
Validation loss: 3.154880560832153

Epoch: 16| Step: 0
Training loss: 2.381407977293094
Validation loss: 3.1593058715721463

Epoch: 6| Step: 1
Training loss: 3.613015984773052
Validation loss: 3.158173728501302

Epoch: 6| Step: 2
Training loss: 3.6076235794821154
Validation loss: 3.156570073950179

Epoch: 6| Step: 3
Training loss: 3.6812600827038544
Validation loss: 3.153688040593213

Epoch: 6| Step: 4
Training loss: 3.6736726297004147
Validation loss: 3.14947155111973

Epoch: 6| Step: 5
Training loss: 2.3704102990752283
Validation loss: 3.145283919510827

Epoch: 6| Step: 6
Training loss: 3.2775215400785256
Validation loss: 3.144936879147678

Epoch: 6| Step: 7
Training loss: 3.9436821014314627
Validation loss: 3.1501350928586653

Epoch: 6| Step: 8
Training loss: 2.615315055030015
Validation loss: 3.1559356026026473

Epoch: 6| Step: 9
Training loss: 3.953312925915423
Validation loss: 3.1647539585190385

Epoch: 6| Step: 10
Training loss: 3.9751301342277348
Validation loss: 3.144452234711213

Epoch: 6| Step: 11
Training loss: 3.1093845079746276
Validation loss: 3.144599029150914

Epoch: 6| Step: 12
Training loss: 3.0841811964683474
Validation loss: 3.143247708084467

Epoch: 6| Step: 13
Training loss: 4.292182274125413
Validation loss: 3.1546754031402022

Epoch: 17| Step: 0
Training loss: 2.4638156106806854
Validation loss: 3.143667846596568

Epoch: 6| Step: 1
Training loss: 3.080938147805871
Validation loss: 3.143784302617082

Epoch: 6| Step: 2
Training loss: 4.006014117409812
Validation loss: 3.179199052232658

Epoch: 6| Step: 3
Training loss: 2.857677518682129
Validation loss: 3.1802180557266544

Epoch: 6| Step: 4
Training loss: 3.922594832665291
Validation loss: 3.1567215674330553

Epoch: 6| Step: 5
Training loss: 3.5163980269913298
Validation loss: 3.1505619625993315

Epoch: 6| Step: 6
Training loss: 2.3915031665204407
Validation loss: 3.1572841776320093

Epoch: 6| Step: 7
Training loss: 3.834196919454044
Validation loss: 3.1631543402583064

Epoch: 6| Step: 8
Training loss: 3.2737605770795213
Validation loss: 3.154707856883524

Epoch: 6| Step: 9
Training loss: 2.8234619983988782
Validation loss: 3.149085172418842

Epoch: 6| Step: 10
Training loss: 3.139206447310442
Validation loss: 3.14980972087758

Epoch: 6| Step: 11
Training loss: 4.22231859521022
Validation loss: 3.1441914223897247

Epoch: 6| Step: 12
Training loss: 3.719705923618576
Validation loss: 3.138122343452761

Epoch: 6| Step: 13
Training loss: 4.308633812781216
Validation loss: 3.1315737355155537

Epoch: 18| Step: 0
Training loss: 3.111788325929028
Validation loss: 3.131060911161108

Epoch: 6| Step: 1
Training loss: 3.398665356944707
Validation loss: 3.13204326733997

Epoch: 6| Step: 2
Training loss: 3.3111223918998562
Validation loss: 3.1367532938169944

Epoch: 6| Step: 3
Training loss: 3.1576773560308595
Validation loss: 3.136279653378117

Epoch: 6| Step: 4
Training loss: 3.626864644308128
Validation loss: 3.131846212228662

Epoch: 6| Step: 5
Training loss: 3.211697453692925
Validation loss: 3.128256814028818

Epoch: 6| Step: 6
Training loss: 3.1058159016361477
Validation loss: 3.1407617898243085

Epoch: 6| Step: 7
Training loss: 3.5910334395463974
Validation loss: 3.1492316239122298

Epoch: 6| Step: 8
Training loss: 3.5032987035993126
Validation loss: 3.128555196838471

Epoch: 6| Step: 9
Training loss: 3.369212804933336
Validation loss: 3.1162580453766613

Epoch: 6| Step: 10
Training loss: 3.544992627995712
Validation loss: 3.114612055853317

Epoch: 6| Step: 11
Training loss: 4.1699022064817175
Validation loss: 3.111041886123005

Epoch: 6| Step: 12
Training loss: 2.8672914408207624
Validation loss: 3.1127422204413975

Epoch: 6| Step: 13
Training loss: 3.314941370288794
Validation loss: 3.1132369141539247

Epoch: 19| Step: 0
Training loss: 2.600032963910579
Validation loss: 3.1110811104502374

Epoch: 6| Step: 1
Training loss: 3.5956246172173554
Validation loss: 3.1076687712355606

Epoch: 6| Step: 2
Training loss: 3.480552458264907
Validation loss: 3.1085147221027936

Epoch: 6| Step: 3
Training loss: 3.3123278303207817
Validation loss: 3.106023976233442

Epoch: 6| Step: 4
Training loss: 3.787085200090452
Validation loss: 3.1080433993331513

Epoch: 6| Step: 5
Training loss: 3.5797144928359477
Validation loss: 3.1088640239722034

Epoch: 6| Step: 6
Training loss: 2.742934166090768
Validation loss: 3.1212800607282523

Epoch: 6| Step: 7
Training loss: 4.065894718591579
Validation loss: 3.1213523766524394

Epoch: 6| Step: 8
Training loss: 2.960078857247808
Validation loss: 3.1004301887780255

Epoch: 6| Step: 9
Training loss: 3.517595883101691
Validation loss: 3.104509334036032

Epoch: 6| Step: 10
Training loss: 3.8000103599005572
Validation loss: 3.111388890536699

Epoch: 6| Step: 11
Training loss: 3.068134340888651
Validation loss: 3.11700909202938

Epoch: 6| Step: 12
Training loss: 3.276342882501131
Validation loss: 3.1178600247748434

Epoch: 6| Step: 13
Training loss: 3.2331767788244865
Validation loss: 3.1058372654003965

Epoch: 20| Step: 0
Training loss: 3.4204667211262314
Validation loss: 3.0990330697520916

Epoch: 6| Step: 1
Training loss: 2.6559675178667255
Validation loss: 3.0947109622196014

Epoch: 6| Step: 2
Training loss: 2.989784012460116
Validation loss: 3.09206740140463

Epoch: 6| Step: 3
Training loss: 2.672044179813828
Validation loss: 3.0886215290664367

Epoch: 6| Step: 4
Training loss: 4.222058616502339
Validation loss: 3.086555156835265

Epoch: 6| Step: 5
Training loss: 3.253433761088885
Validation loss: 3.093978551876973

Epoch: 6| Step: 6
Training loss: 3.6248495136463297
Validation loss: 3.0930570951571728

Epoch: 6| Step: 7
Training loss: 3.3322141357891346
Validation loss: 3.091402150900596

Epoch: 6| Step: 8
Training loss: 3.3869735815495017
Validation loss: 3.093008892928136

Epoch: 6| Step: 9
Training loss: 3.355370978639601
Validation loss: 3.0870958622809908

Epoch: 6| Step: 10
Training loss: 3.681391165703122
Validation loss: 3.086318900881445

Epoch: 6| Step: 11
Training loss: 3.5402832620514313
Validation loss: 3.0829526177861366

Epoch: 6| Step: 12
Training loss: 3.134948458939949
Validation loss: 3.0822504936389676

Epoch: 6| Step: 13
Training loss: 3.6375031408971488
Validation loss: 3.081320329738068

Epoch: 21| Step: 0
Training loss: 3.4066998945831624
Validation loss: 3.0774721934113254

Epoch: 6| Step: 1
Training loss: 3.0635908091543587
Validation loss: 3.0750513167042333

Epoch: 6| Step: 2
Training loss: 2.867618538785167
Validation loss: 3.074738967084697

Epoch: 6| Step: 3
Training loss: 3.5424973953442094
Validation loss: 3.0722234584709907

Epoch: 6| Step: 4
Training loss: 3.502699492148849
Validation loss: 3.073422981765637

Epoch: 6| Step: 5
Training loss: 3.0015310513200717
Validation loss: 3.0716143858058484

Epoch: 6| Step: 6
Training loss: 3.7833759227041606
Validation loss: 3.07815706486104

Epoch: 6| Step: 7
Training loss: 2.899817783287345
Validation loss: 3.0762766649218327

Epoch: 6| Step: 8
Training loss: 3.3647171482052927
Validation loss: 3.0708755335541587

Epoch: 6| Step: 9
Training loss: 3.9193775994680475
Validation loss: 3.074122514571091

Epoch: 6| Step: 10
Training loss: 3.149417242004209
Validation loss: 3.0699764784766654

Epoch: 6| Step: 11
Training loss: 3.513782883269374
Validation loss: 3.0719490014064745

Epoch: 6| Step: 12
Training loss: 3.1122578047927925
Validation loss: 3.0716966835588515

Epoch: 6| Step: 13
Training loss: 3.6662124150115556
Validation loss: 3.0631444209913683

Epoch: 22| Step: 0
Training loss: 3.3396098807920347
Validation loss: 3.0645824130520842

Epoch: 6| Step: 1
Training loss: 3.5927308337461072
Validation loss: 3.063047842648815

Epoch: 6| Step: 2
Training loss: 2.483379620455647
Validation loss: 3.0645748356785782

Epoch: 6| Step: 3
Training loss: 3.04460333233969
Validation loss: 3.095170487245055

Epoch: 6| Step: 4
Training loss: 3.323186084185186
Validation loss: 3.1009953523431135

Epoch: 6| Step: 5
Training loss: 3.9776631389084294
Validation loss: 3.061949802923199

Epoch: 6| Step: 6
Training loss: 2.6737206759991556
Validation loss: 3.058688978750201

Epoch: 6| Step: 7
Training loss: 3.6841410192945694
Validation loss: 3.0565156845782973

Epoch: 6| Step: 8
Training loss: 3.8606751757698
Validation loss: 3.062367946011933

Epoch: 6| Step: 9
Training loss: 3.4747029678408023
Validation loss: 3.062236074694597

Epoch: 6| Step: 10
Training loss: 2.8776117154996195
Validation loss: 3.0694398766907773

Epoch: 6| Step: 11
Training loss: 3.15676679251674
Validation loss: 3.0642815866347233

Epoch: 6| Step: 12
Training loss: 3.3431341727190307
Validation loss: 3.067670566226007

Epoch: 6| Step: 13
Training loss: 3.7682250610975965
Validation loss: 3.0614899122043258

Epoch: 23| Step: 0
Training loss: 3.52434154339703
Validation loss: 3.0640791855679606

Epoch: 6| Step: 1
Training loss: 3.0787504693486687
Validation loss: 3.0556744624767602

Epoch: 6| Step: 2
Training loss: 3.3010323152482886
Validation loss: 3.05377302582811

Epoch: 6| Step: 3
Training loss: 3.1802851984502025
Validation loss: 3.0551380607470446

Epoch: 6| Step: 4
Training loss: 3.2221133242946576
Validation loss: 3.0566132946143014

Epoch: 6| Step: 5
Training loss: 3.0035714507325713
Validation loss: 3.058757127141809

Epoch: 6| Step: 6
Training loss: 2.6673655686830497
Validation loss: 3.059422568867799

Epoch: 6| Step: 7
Training loss: 3.3707788702703034
Validation loss: 3.075549517216764

Epoch: 6| Step: 8
Training loss: 3.2310629578397903
Validation loss: 3.0527598842035593

Epoch: 6| Step: 9
Training loss: 2.8521420242664837
Validation loss: 3.0512434294318425

Epoch: 6| Step: 10
Training loss: 3.2651647215997675
Validation loss: 3.047161109686341

Epoch: 6| Step: 11
Training loss: 3.921902599465574
Validation loss: 3.0512372405463895

Epoch: 6| Step: 12
Training loss: 4.239148141830359
Validation loss: 3.0530888142493713

Epoch: 6| Step: 13
Training loss: 3.496179266368567
Validation loss: 3.0441266854034255

Epoch: 24| Step: 0
Training loss: 3.1437368586058896
Validation loss: 3.047449310757937

Epoch: 6| Step: 1
Training loss: 3.591695447011346
Validation loss: 3.0467183962895885

Epoch: 6| Step: 2
Training loss: 2.7090189628345747
Validation loss: 3.0424616324476546

Epoch: 6| Step: 3
Training loss: 3.691795821043919
Validation loss: 3.04257801381205

Epoch: 6| Step: 4
Training loss: 3.005993260704095
Validation loss: 3.0385689232714923

Epoch: 6| Step: 5
Training loss: 3.6338768497105547
Validation loss: 3.038201555766247

Epoch: 6| Step: 6
Training loss: 3.5696021777841858
Validation loss: 3.037776124031353

Epoch: 6| Step: 7
Training loss: 3.9894594550094205
Validation loss: 3.0325633498932767

Epoch: 6| Step: 8
Training loss: 2.5413509443792996
Validation loss: 3.029271203760847

Epoch: 6| Step: 9
Training loss: 3.6320697640428143
Validation loss: 3.029276660631103

Epoch: 6| Step: 10
Training loss: 2.9464908741891067
Validation loss: 3.0212439190479663

Epoch: 6| Step: 11
Training loss: 3.0630360348307017
Validation loss: 3.014374046908191

Epoch: 6| Step: 12
Training loss: 3.284212065193135
Validation loss: 3.0170944402334237

Epoch: 6| Step: 13
Training loss: 3.193407605474846
Validation loss: 3.023681232701207

Epoch: 25| Step: 0
Training loss: 3.2040052739551204
Validation loss: 3.0128703384719535

Epoch: 6| Step: 1
Training loss: 3.0053769245602453
Validation loss: 3.0125099452583073

Epoch: 6| Step: 2
Training loss: 3.3634054446799504
Validation loss: 3.020437320017559

Epoch: 6| Step: 3
Training loss: 4.029800035991628
Validation loss: 3.008510321671935

Epoch: 6| Step: 4
Training loss: 3.312780404368566
Validation loss: 3.0062246562769626

Epoch: 6| Step: 5
Training loss: 2.436296312529046
Validation loss: 3.010148941558815

Epoch: 6| Step: 6
Training loss: 3.5166434614190294
Validation loss: 3.0175053559945524

Epoch: 6| Step: 7
Training loss: 3.914757337589015
Validation loss: 3.033468606950989

Epoch: 6| Step: 8
Training loss: 2.6336688451660994
Validation loss: 3.017506391643882

Epoch: 6| Step: 9
Training loss: 3.523743339172325
Validation loss: 3.0124882081320594

Epoch: 6| Step: 10
Training loss: 3.330939021097214
Validation loss: 3.0097650696431857

Epoch: 6| Step: 11
Training loss: 3.2590814035788993
Validation loss: 3.0068691530669005

Epoch: 6| Step: 12
Training loss: 3.259237366620464
Validation loss: 3.000994606311268

Epoch: 6| Step: 13
Training loss: 2.7021032618422804
Validation loss: 3.0002409947582103

Epoch: 26| Step: 0
Training loss: 3.366560946274472
Validation loss: 3.0113655301256976

Epoch: 6| Step: 1
Training loss: 3.264476519413301
Validation loss: 3.019791006503397

Epoch: 6| Step: 2
Training loss: 3.551561125164714
Validation loss: 3.0133409189267972

Epoch: 6| Step: 3
Training loss: 3.0235012156157763
Validation loss: 3.011591816536158

Epoch: 6| Step: 4
Training loss: 2.559625362312197
Validation loss: 3.003237377283374

Epoch: 6| Step: 5
Training loss: 3.2771579476067387
Validation loss: 3.0013424969817883

Epoch: 6| Step: 6
Training loss: 3.536066197418659
Validation loss: 2.9996249911365434

Epoch: 6| Step: 7
Training loss: 3.2794575472941245
Validation loss: 2.9997591807330792

Epoch: 6| Step: 8
Training loss: 3.4697500625875306
Validation loss: 3.0003288731399653

Epoch: 6| Step: 9
Training loss: 3.21656147153996
Validation loss: 3.001106032685908

Epoch: 6| Step: 10
Training loss: 2.806369967540694
Validation loss: 3.0023473798749265

Epoch: 6| Step: 11
Training loss: 3.4516208876873105
Validation loss: 2.9935027833660848

Epoch: 6| Step: 12
Training loss: 3.5807926278704043
Validation loss: 2.992963364460582

Epoch: 6| Step: 13
Training loss: 3.6389821811458853
Validation loss: 2.990774061526754

Epoch: 27| Step: 0
Training loss: 3.493666504218769
Validation loss: 2.988378242378642

Epoch: 6| Step: 1
Training loss: 2.924943750606816
Validation loss: 2.9872603862813336

Epoch: 6| Step: 2
Training loss: 2.6962612969980215
Validation loss: 2.98597515897216

Epoch: 6| Step: 3
Training loss: 3.2183962136804136
Validation loss: 2.9835624608784137

Epoch: 6| Step: 4
Training loss: 3.3374475996497255
Validation loss: 2.983949024063041

Epoch: 6| Step: 5
Training loss: 3.6050013345618033
Validation loss: 2.982385974279022

Epoch: 6| Step: 6
Training loss: 3.4362543796970715
Validation loss: 2.9825437752025103

Epoch: 6| Step: 7
Training loss: 3.133665506192342
Validation loss: 2.9802932026321924

Epoch: 6| Step: 8
Training loss: 3.26340843794851
Validation loss: 2.979554449192172

Epoch: 6| Step: 9
Training loss: 2.92075689617565
Validation loss: 2.9792017597243032

Epoch: 6| Step: 10
Training loss: 3.8129312240116486
Validation loss: 2.978150637148222

Epoch: 6| Step: 11
Training loss: 3.0289442593775173
Validation loss: 2.9762941661064155

Epoch: 6| Step: 12
Training loss: 3.3649081771134965
Validation loss: 2.9763194880613684

Epoch: 6| Step: 13
Training loss: 3.453289045346898
Validation loss: 2.9764093629826576

Epoch: 28| Step: 0
Training loss: 3.4244607709770087
Validation loss: 2.9770534279451923

Epoch: 6| Step: 1
Training loss: 3.0105708169684258
Validation loss: 2.979785519022679

Epoch: 6| Step: 2
Training loss: 2.4461416965343457
Validation loss: 2.9840917115123435

Epoch: 6| Step: 3
Training loss: 3.8770266739717534
Validation loss: 2.9858944102555403

Epoch: 6| Step: 4
Training loss: 2.627079820945705
Validation loss: 2.9883530277513977

Epoch: 6| Step: 5
Training loss: 3.308417629702214
Validation loss: 2.978160093200351

Epoch: 6| Step: 6
Training loss: 3.3658045077114713
Validation loss: 2.9691849532954984

Epoch: 6| Step: 7
Training loss: 3.7459514380065473
Validation loss: 2.967038315824349

Epoch: 6| Step: 8
Training loss: 3.131709106655811
Validation loss: 2.965876694729628

Epoch: 6| Step: 9
Training loss: 3.726195247315707
Validation loss: 2.9673592920210745

Epoch: 6| Step: 10
Training loss: 3.2452898372764314
Validation loss: 2.968569669659951

Epoch: 6| Step: 11
Training loss: 3.0935846149666726
Validation loss: 2.972075863904847

Epoch: 6| Step: 12
Training loss: 3.184041259766664
Validation loss: 2.969504401613378

Epoch: 6| Step: 13
Training loss: 3.1964909029132595
Validation loss: 2.965415839624282

Epoch: 29| Step: 0
Training loss: 2.5447676663874668
Validation loss: 2.9631797548924275

Epoch: 6| Step: 1
Training loss: 3.2759549968921426
Validation loss: 2.9587042485159634

Epoch: 6| Step: 2
Training loss: 2.791633937890563
Validation loss: 2.9612296428907112

Epoch: 6| Step: 3
Training loss: 3.1403714357567005
Validation loss: 2.965844365061364

Epoch: 6| Step: 4
Training loss: 3.3473504192729417
Validation loss: 2.9867283289981668

Epoch: 6| Step: 5
Training loss: 3.4803914790454407
Validation loss: 2.994612376591944

Epoch: 6| Step: 6
Training loss: 3.0543412502571585
Validation loss: 2.957680632083871

Epoch: 6| Step: 7
Training loss: 4.340036684927176
Validation loss: 2.9442015432446853

Epoch: 6| Step: 8
Training loss: 3.28882907936196
Validation loss: 2.9430168586155463

Epoch: 6| Step: 9
Training loss: 3.2933747571844547
Validation loss: 2.9420861317756013

Epoch: 6| Step: 10
Training loss: 3.4204781524848213
Validation loss: 2.9424780767627787

Epoch: 6| Step: 11
Training loss: 3.226471167650303
Validation loss: 2.94512151718734

Epoch: 6| Step: 12
Training loss: 2.8991458161004418
Validation loss: 2.9430490453164864

Epoch: 6| Step: 13
Training loss: 2.95344339904745
Validation loss: 2.941444317304534

Epoch: 30| Step: 0
Training loss: 3.957153197929639
Validation loss: 2.936384102114457

Epoch: 6| Step: 1
Training loss: 2.9816888834035167
Validation loss: 2.9350628697442223

Epoch: 6| Step: 2
Training loss: 3.3996694852960236
Validation loss: 2.9357609153270277

Epoch: 6| Step: 3
Training loss: 3.425538214280366
Validation loss: 2.931007046304764

Epoch: 6| Step: 4
Training loss: 3.2681188962452263
Validation loss: 2.9269102574757486

Epoch: 6| Step: 5
Training loss: 2.1890803486806365
Validation loss: 2.928408563635188

Epoch: 6| Step: 6
Training loss: 3.0320776369929794
Validation loss: 2.9238266519594625

Epoch: 6| Step: 7
Training loss: 3.512366111077003
Validation loss: 2.925290249809076

Epoch: 6| Step: 8
Training loss: 3.2793277014259865
Validation loss: 2.92340947104079

Epoch: 6| Step: 9
Training loss: 3.613742976199977
Validation loss: 2.9227964378374645

Epoch: 6| Step: 10
Training loss: 3.2257915619537285
Validation loss: 2.9214971110561008

Epoch: 6| Step: 11
Training loss: 3.2608499614845017
Validation loss: 2.923281633895542

Epoch: 6| Step: 12
Training loss: 3.032366674751997
Validation loss: 2.9251064339018957

Epoch: 6| Step: 13
Training loss: 2.3901250977277497
Validation loss: 2.923274786478142

Epoch: 31| Step: 0
Training loss: 3.694000721021085
Validation loss: 2.92527852919484

Epoch: 6| Step: 1
Training loss: 3.0827759591212174
Validation loss: 2.92507356947841

Epoch: 6| Step: 2
Training loss: 3.1831114233938207
Validation loss: 2.923757982896064

Epoch: 6| Step: 3
Training loss: 3.220619325490313
Validation loss: 2.925424020458856

Epoch: 6| Step: 4
Training loss: 3.4054228452042006
Validation loss: 2.9232674163659786

Epoch: 6| Step: 5
Training loss: 3.828786364665064
Validation loss: 2.92111697214813

Epoch: 6| Step: 6
Training loss: 3.9705670620056623
Validation loss: 2.9193737112928804

Epoch: 6| Step: 7
Training loss: 3.109519916780403
Validation loss: 2.9173333409589786

Epoch: 6| Step: 8
Training loss: 3.1410166937412685
Validation loss: 2.916765070425713

Epoch: 6| Step: 9
Training loss: 2.959567354389979
Validation loss: 2.9202442339834045

Epoch: 6| Step: 10
Training loss: 2.799599370223987
Validation loss: 2.9285212732552015

Epoch: 6| Step: 11
Training loss: 2.5638151748087914
Validation loss: 2.9522294162660825

Epoch: 6| Step: 12
Training loss: 2.7974268193086314
Validation loss: 2.9817181575535985

Epoch: 6| Step: 13
Training loss: 3.102148197709413
Validation loss: 2.97884619277265

Epoch: 32| Step: 0
Training loss: 3.431278633039898
Validation loss: 2.9293938497406575

Epoch: 6| Step: 1
Training loss: 3.8120487133648235
Validation loss: 2.924865276977234

Epoch: 6| Step: 2
Training loss: 3.1393528729463442
Validation loss: 2.926752565663003

Epoch: 6| Step: 3
Training loss: 2.7882083044239434
Validation loss: 2.934184584011781

Epoch: 6| Step: 4
Training loss: 2.950376331441694
Validation loss: 2.9471504084905287

Epoch: 6| Step: 5
Training loss: 3.0054330901530992
Validation loss: 2.9594292304290155

Epoch: 6| Step: 6
Training loss: 2.825311262149242
Validation loss: 2.975942101599225

Epoch: 6| Step: 7
Training loss: 3.5270733734969633
Validation loss: 2.9598990223818347

Epoch: 6| Step: 8
Training loss: 2.2390369783851654
Validation loss: 2.937720075613679

Epoch: 6| Step: 9
Training loss: 3.4820170956213325
Validation loss: 2.9237200000989088

Epoch: 6| Step: 10
Training loss: 3.7311876812559763
Validation loss: 2.92690068927802

Epoch: 6| Step: 11
Training loss: 3.7115896836445064
Validation loss: 2.9286655888814965

Epoch: 6| Step: 12
Training loss: 3.230771623687417
Validation loss: 2.9371258775159874

Epoch: 6| Step: 13
Training loss: 2.880073714372555
Validation loss: 2.979473839661579

Epoch: 33| Step: 0
Training loss: 2.2187268967836005
Validation loss: 2.9929517049980188

Epoch: 6| Step: 1
Training loss: 3.6324166030919374
Validation loss: 2.9985546309920124

Epoch: 6| Step: 2
Training loss: 2.918849745685897
Validation loss: 2.9446243104916348

Epoch: 6| Step: 3
Training loss: 2.456774578424548
Validation loss: 2.909596249544808

Epoch: 6| Step: 4
Training loss: 3.874809014320698
Validation loss: 2.9021910746218316

Epoch: 6| Step: 5
Training loss: 3.976557583609129
Validation loss: 2.9058538213827756

Epoch: 6| Step: 6
Training loss: 3.260034329520301
Validation loss: 2.9083568554652275

Epoch: 6| Step: 7
Training loss: 3.220746208351543
Validation loss: 2.9013570879636195

Epoch: 6| Step: 8
Training loss: 3.1122450881197308
Validation loss: 2.9003444552635433

Epoch: 6| Step: 9
Training loss: 2.526450233583848
Validation loss: 2.901472761336395

Epoch: 6| Step: 10
Training loss: 3.5685484553678273
Validation loss: 2.899456964978888

Epoch: 6| Step: 11
Training loss: 3.243167444150977
Validation loss: 2.8978695111836172

Epoch: 6| Step: 12
Training loss: 2.9716424604347496
Validation loss: 2.8968735056786543

Epoch: 6| Step: 13
Training loss: 3.5445680888369697
Validation loss: 2.8944899449362764

Epoch: 34| Step: 0
Training loss: 2.419467147455904
Validation loss: 2.9090226922244673

Epoch: 6| Step: 1
Training loss: 2.9999818801332667
Validation loss: 2.9052021679469973

Epoch: 6| Step: 2
Training loss: 2.8827321111123867
Validation loss: 2.8897029666666834

Epoch: 6| Step: 3
Training loss: 3.09708078818899
Validation loss: 2.8897225853462576

Epoch: 6| Step: 4
Training loss: 2.952455475008756
Validation loss: 2.891211177831523

Epoch: 6| Step: 5
Training loss: 3.038546560076693
Validation loss: 2.8880298906221977

Epoch: 6| Step: 6
Training loss: 3.438157452220559
Validation loss: 2.889233487437844

Epoch: 6| Step: 7
Training loss: 3.0106112055415952
Validation loss: 2.885205202286128

Epoch: 6| Step: 8
Training loss: 3.504532195692391
Validation loss: 2.8887785153790144

Epoch: 6| Step: 9
Training loss: 2.7281586530254947
Validation loss: 2.889315775230758

Epoch: 6| Step: 10
Training loss: 3.379521061524198
Validation loss: 2.887422746472686

Epoch: 6| Step: 11
Training loss: 3.757375203977095
Validation loss: 2.8836947380395888

Epoch: 6| Step: 12
Training loss: 3.8116889466130917
Validation loss: 2.8810760580074946

Epoch: 6| Step: 13
Training loss: 3.4965896340010385
Validation loss: 2.879152365900193

Epoch: 35| Step: 0
Training loss: 3.357348447377325
Validation loss: 2.8777116825121043

Epoch: 6| Step: 1
Training loss: 2.967623527031918
Validation loss: 2.8750982147390363

Epoch: 6| Step: 2
Training loss: 2.997263932274219
Validation loss: 2.873099516185586

Epoch: 6| Step: 3
Training loss: 2.7098917854352655
Validation loss: 2.8714733831280204

Epoch: 6| Step: 4
Training loss: 3.2690970475479344
Validation loss: 2.872687365104754

Epoch: 6| Step: 5
Training loss: 3.31987747035216
Validation loss: 2.8695190120309966

Epoch: 6| Step: 6
Training loss: 3.2551491368315424
Validation loss: 2.8678769511037707

Epoch: 6| Step: 7
Training loss: 3.1188926526548135
Validation loss: 2.8691143651580213

Epoch: 6| Step: 8
Training loss: 2.7346044825578324
Validation loss: 2.875970262089873

Epoch: 6| Step: 9
Training loss: 3.3314759483791723
Validation loss: 2.873311308800232

Epoch: 6| Step: 10
Training loss: 2.60517133533716
Validation loss: 2.8781469268745647

Epoch: 6| Step: 11
Training loss: 3.1402024321693722
Validation loss: 2.874983441063061

Epoch: 6| Step: 12
Training loss: 4.015234546010065
Validation loss: 2.870006460261369

Epoch: 6| Step: 13
Training loss: 3.5729129594759526
Validation loss: 2.8670467281685643

Epoch: 36| Step: 0
Training loss: 2.8868518845102855
Validation loss: 2.865448714545777

Epoch: 6| Step: 1
Training loss: 3.2493235544342713
Validation loss: 2.863790937591157

Epoch: 6| Step: 2
Training loss: 3.3113300488632786
Validation loss: 2.859653932014005

Epoch: 6| Step: 3
Training loss: 3.3860517326769752
Validation loss: 2.862376828106622

Epoch: 6| Step: 4
Training loss: 2.9159737626767392
Validation loss: 2.8595844445149443

Epoch: 6| Step: 5
Training loss: 3.6127731378379404
Validation loss: 2.8579329313867268

Epoch: 6| Step: 6
Training loss: 2.6871673023198124
Validation loss: 2.858550540728094

Epoch: 6| Step: 7
Training loss: 3.1392834583251426
Validation loss: 2.858036893035056

Epoch: 6| Step: 8
Training loss: 3.5900779207746853
Validation loss: 2.8572187949781713

Epoch: 6| Step: 9
Training loss: 2.8743577322676583
Validation loss: 2.8545332576572053

Epoch: 6| Step: 10
Training loss: 3.266781396862247
Validation loss: 2.8565317676222923

Epoch: 6| Step: 11
Training loss: 3.356139998524684
Validation loss: 2.855702409122562

Epoch: 6| Step: 12
Training loss: 2.8840683266724176
Validation loss: 2.8560168753874215

Epoch: 6| Step: 13
Training loss: 2.8862940330004636
Validation loss: 2.85597437238669

Epoch: 37| Step: 0
Training loss: 3.6608113585039135
Validation loss: 2.8657557016869157

Epoch: 6| Step: 1
Training loss: 3.1572856148301316
Validation loss: 2.877743789848383

Epoch: 6| Step: 2
Training loss: 2.8426145864991845
Validation loss: 2.8801443578005803

Epoch: 6| Step: 3
Training loss: 3.345878992841972
Validation loss: 2.8757683474949305

Epoch: 6| Step: 4
Training loss: 2.8539747930107273
Validation loss: 2.8683484279248286

Epoch: 6| Step: 5
Training loss: 3.386437427491815
Validation loss: 2.863490118727368

Epoch: 6| Step: 6
Training loss: 2.843690305649221
Validation loss: 2.853304415139771

Epoch: 6| Step: 7
Training loss: 3.385573038255604
Validation loss: 2.8532411640512403

Epoch: 6| Step: 8
Training loss: 3.0391757816491456
Validation loss: 2.8489222970354033

Epoch: 6| Step: 9
Training loss: 2.854846641309818
Validation loss: 2.8464299262539203

Epoch: 6| Step: 10
Training loss: 3.392224334558981
Validation loss: 2.8478980630801014

Epoch: 6| Step: 11
Training loss: 3.5402204964281645
Validation loss: 2.8478625738891554

Epoch: 6| Step: 12
Training loss: 2.816986066627372
Validation loss: 2.850092266037843

Epoch: 6| Step: 13
Training loss: 2.9828212348246583
Validation loss: 2.8471365201350443

Epoch: 38| Step: 0
Training loss: 2.665135321411111
Validation loss: 2.8501430995833306

Epoch: 6| Step: 1
Training loss: 3.14264443222659
Validation loss: 2.8448056066255054

Epoch: 6| Step: 2
Training loss: 3.0873017591084992
Validation loss: 2.8499687466565584

Epoch: 6| Step: 3
Training loss: 2.6744186161743255
Validation loss: 2.853448634813399

Epoch: 6| Step: 4
Training loss: 3.1888049577248596
Validation loss: 2.8546829948230568

Epoch: 6| Step: 5
Training loss: 3.599146233091639
Validation loss: 2.8696480810348732

Epoch: 6| Step: 6
Training loss: 2.7488975048863873
Validation loss: 2.889760798539167

Epoch: 6| Step: 7
Training loss: 3.56640625
Validation loss: 2.8840700795774197

Epoch: 6| Step: 8
Training loss: 2.747540154063878
Validation loss: 2.870870610977139

Epoch: 6| Step: 9
Training loss: 3.3607353827134427
Validation loss: 2.8571081753243113

Epoch: 6| Step: 10
Training loss: 4.08310275821651
Validation loss: 2.8430641525523335

Epoch: 6| Step: 11
Training loss: 2.7585089563276557
Validation loss: 2.8374053971833226

Epoch: 6| Step: 12
Training loss: 2.831961206030361
Validation loss: 2.8357407050092514

Epoch: 6| Step: 13
Training loss: 3.4272516242141764
Validation loss: 2.8359144121680733

Epoch: 39| Step: 0
Training loss: 3.6357625161011726
Validation loss: 2.8366087946119256

Epoch: 6| Step: 1
Training loss: 3.5697691522754114
Validation loss: 2.837656377354109

Epoch: 6| Step: 2
Training loss: 2.7734341473626305
Validation loss: 2.8374052724981382

Epoch: 6| Step: 3
Training loss: 2.875473315212475
Validation loss: 2.84243561394589

Epoch: 6| Step: 4
Training loss: 3.769216257483605
Validation loss: 2.83857470866933

Epoch: 6| Step: 5
Training loss: 3.5639690917073774
Validation loss: 2.84413873989727

Epoch: 6| Step: 6
Training loss: 2.7687422431509923
Validation loss: 2.850697496413791

Epoch: 6| Step: 7
Training loss: 3.109080238364534
Validation loss: 2.8496579410939877

Epoch: 6| Step: 8
Training loss: 3.2770443075919644
Validation loss: 2.848443624929432

Epoch: 6| Step: 9
Training loss: 3.1694807966775587
Validation loss: 2.836681642924326

Epoch: 6| Step: 10
Training loss: 2.54326668911566
Validation loss: 2.8306859663838635

Epoch: 6| Step: 11
Training loss: 2.929193480483315
Validation loss: 2.826231607372742

Epoch: 6| Step: 12
Training loss: 2.7837443792511647
Validation loss: 2.826709783688234

Epoch: 6| Step: 13
Training loss: 2.9871040369133026
Validation loss: 2.8287171617677744

Epoch: 40| Step: 0
Training loss: 3.2229626689078077
Validation loss: 2.8268157297915373

Epoch: 6| Step: 1
Training loss: 2.9875209663964206
Validation loss: 2.825280568830478

Epoch: 6| Step: 2
Training loss: 3.2031660868172804
Validation loss: 2.825004277655764

Epoch: 6| Step: 3
Training loss: 3.5483803936399982
Validation loss: 2.826645234608716

Epoch: 6| Step: 4
Training loss: 3.186736969218879
Validation loss: 2.8240239171437005

Epoch: 6| Step: 5
Training loss: 2.796327164343684
Validation loss: 2.82391653269451

Epoch: 6| Step: 6
Training loss: 2.9809122018153507
Validation loss: 2.8204518095353315

Epoch: 6| Step: 7
Training loss: 3.2004961344441267
Validation loss: 2.824591181594071

Epoch: 6| Step: 8
Training loss: 2.604617687587265
Validation loss: 2.8369796918448045

Epoch: 6| Step: 9
Training loss: 3.6803571411648948
Validation loss: 2.86341511432302

Epoch: 6| Step: 10
Training loss: 3.1687537560073893
Validation loss: 2.8837106957696066

Epoch: 6| Step: 11
Training loss: 2.9747632613674724
Validation loss: 2.9105502196474466

Epoch: 6| Step: 12
Training loss: 3.5181897112000855
Validation loss: 2.920996624681427

Epoch: 6| Step: 13
Training loss: 2.612528830921301
Validation loss: 2.8594882188878596

Epoch: 41| Step: 0
Training loss: 3.3313826257238315
Validation loss: 2.8208020940609084

Epoch: 6| Step: 1
Training loss: 1.884238055616098
Validation loss: 2.820822699977201

Epoch: 6| Step: 2
Training loss: 2.837989254082302
Validation loss: 2.820029936685165

Epoch: 6| Step: 3
Training loss: 2.951145699648148
Validation loss: 2.8226093975190696

Epoch: 6| Step: 4
Training loss: 3.009698133064652
Validation loss: 2.8342489256731174

Epoch: 6| Step: 5
Training loss: 3.186974426023288
Validation loss: 2.859072047811071

Epoch: 6| Step: 6
Training loss: 3.5876588367562317
Validation loss: 2.8725674214941708

Epoch: 6| Step: 7
Training loss: 3.093820282108882
Validation loss: 2.850604972827371

Epoch: 6| Step: 8
Training loss: 3.692600666551582
Validation loss: 2.8244862121818612

Epoch: 6| Step: 9
Training loss: 3.368385332005982
Validation loss: 2.818406311085038

Epoch: 6| Step: 10
Training loss: 3.5017445167579733
Validation loss: 2.8136339324106134

Epoch: 6| Step: 11
Training loss: 2.876072559147025
Validation loss: 2.8112061307919967

Epoch: 6| Step: 12
Training loss: 3.043636694332522
Validation loss: 2.8147698420801692

Epoch: 6| Step: 13
Training loss: 3.322874844247039
Validation loss: 2.82165608145876

Epoch: 42| Step: 0
Training loss: 2.826652522891425
Validation loss: 2.8173233747934914

Epoch: 6| Step: 1
Training loss: 3.105231356394141
Validation loss: 2.814136472027931

Epoch: 6| Step: 2
Training loss: 2.8435395550674007
Validation loss: 2.8160381016505163

Epoch: 6| Step: 3
Training loss: 4.03413016169521
Validation loss: 2.8182662154711897

Epoch: 6| Step: 4
Training loss: 3.099024120669002
Validation loss: 2.8246654389344488

Epoch: 6| Step: 5
Training loss: 3.604892077054046
Validation loss: 2.826662299826521

Epoch: 6| Step: 6
Training loss: 2.6812990197455737
Validation loss: 2.8557076105470056

Epoch: 6| Step: 7
Training loss: 2.933115832617053
Validation loss: 2.861870766553702

Epoch: 6| Step: 8
Training loss: 2.705813003039155
Validation loss: 2.8706211415719896

Epoch: 6| Step: 9
Training loss: 3.118355362564749
Validation loss: 2.827567580018512

Epoch: 6| Step: 10
Training loss: 2.7394820123267496
Validation loss: 2.813985481968099

Epoch: 6| Step: 11
Training loss: 2.733086680316602
Validation loss: 2.8069794202076945

Epoch: 6| Step: 12
Training loss: 3.7819565042045133
Validation loss: 2.802057717090287

Epoch: 6| Step: 13
Training loss: 3.2557524610333037
Validation loss: 2.7981525362556345

Epoch: 43| Step: 0
Training loss: 3.343124188479933
Validation loss: 2.801573837906394

Epoch: 6| Step: 1
Training loss: 3.33293699451391
Validation loss: 2.8044199257618114

Epoch: 6| Step: 2
Training loss: 3.109739042661321
Validation loss: 2.801875372541942

Epoch: 6| Step: 3
Training loss: 3.281617352948371
Validation loss: 2.8022869676700495

Epoch: 6| Step: 4
Training loss: 3.4790529396215653
Validation loss: 2.798421901606893

Epoch: 6| Step: 5
Training loss: 2.9225047039845826
Validation loss: 2.8005847884601196

Epoch: 6| Step: 6
Training loss: 2.8892439558813097
Validation loss: 2.7998516288097504

Epoch: 6| Step: 7
Training loss: 3.4135881526522405
Validation loss: 2.7997754414922595

Epoch: 6| Step: 8
Training loss: 2.586046752465763
Validation loss: 2.801006758231145

Epoch: 6| Step: 9
Training loss: 2.8461293756777297
Validation loss: 2.803499263794722

Epoch: 6| Step: 10
Training loss: 3.696437672458394
Validation loss: 2.8044541391803883

Epoch: 6| Step: 11
Training loss: 2.8941243203540927
Validation loss: 2.8028424365401916

Epoch: 6| Step: 12
Training loss: 2.6909471626892367
Validation loss: 2.8021993640889886

Epoch: 6| Step: 13
Training loss: 2.9328786331386425
Validation loss: 2.8018575652786044

Epoch: 44| Step: 0
Training loss: 3.219633703307207
Validation loss: 2.8034471345651255

Epoch: 6| Step: 1
Training loss: 2.7577405709458285
Validation loss: 2.798539662242786

Epoch: 6| Step: 2
Training loss: 3.6539231419657114
Validation loss: 2.798751569070922

Epoch: 6| Step: 3
Training loss: 3.4084639047796217
Validation loss: 2.7929897668691566

Epoch: 6| Step: 4
Training loss: 3.305163626494215
Validation loss: 2.797699225305034

Epoch: 6| Step: 5
Training loss: 2.625734317340814
Validation loss: 2.793624986019562

Epoch: 6| Step: 6
Training loss: 3.5536383453443814
Validation loss: 2.79098191830055

Epoch: 6| Step: 7
Training loss: 3.4030709086341258
Validation loss: 2.7852879839272577

Epoch: 6| Step: 8
Training loss: 2.98406565396079
Validation loss: 2.7854893447564066

Epoch: 6| Step: 9
Training loss: 2.7788689525847827
Validation loss: 2.782900361261743

Epoch: 6| Step: 10
Training loss: 2.6089023915897607
Validation loss: 2.7833643903860765

Epoch: 6| Step: 11
Training loss: 2.8331670338314603
Validation loss: 2.7854301266088037

Epoch: 6| Step: 12
Training loss: 3.028443285706571
Validation loss: 2.7875324925554494

Epoch: 6| Step: 13
Training loss: 3.2478924299946277
Validation loss: 2.8042329827875663

Epoch: 45| Step: 0
Training loss: 2.9004731548653795
Validation loss: 2.793748092201075

Epoch: 6| Step: 1
Training loss: 3.201520117669538
Validation loss: 2.799148968823504

Epoch: 6| Step: 2
Training loss: 3.6992587094429674
Validation loss: 2.7907097623892696

Epoch: 6| Step: 3
Training loss: 2.9722109246757236
Validation loss: 2.787811356231631

Epoch: 6| Step: 4
Training loss: 3.1128748840324656
Validation loss: 2.775555633426573

Epoch: 6| Step: 5
Training loss: 2.7104606099027655
Validation loss: 2.7792853338298142

Epoch: 6| Step: 6
Training loss: 3.2555772902884663
Validation loss: 2.7787021222578234

Epoch: 6| Step: 7
Training loss: 3.3026126633860518
Validation loss: 2.7768680073956276

Epoch: 6| Step: 8
Training loss: 3.0358976933828816
Validation loss: 2.779873052568202

Epoch: 6| Step: 9
Training loss: 2.904308696176346
Validation loss: 2.775839781504612

Epoch: 6| Step: 10
Training loss: 3.131843702486866
Validation loss: 2.7751934939299225

Epoch: 6| Step: 11
Training loss: 3.0328509635392598
Validation loss: 2.776150562521063

Epoch: 6| Step: 12
Training loss: 2.871160182054569
Validation loss: 2.7764316524936454

Epoch: 6| Step: 13
Training loss: 3.3512489154362872
Validation loss: 2.7776730949064508

Epoch: 46| Step: 0
Training loss: 3.2871946707962
Validation loss: 2.7824412439403465

Epoch: 6| Step: 1
Training loss: 2.861363121053052
Validation loss: 2.7909193665673375

Epoch: 6| Step: 2
Training loss: 2.6348616325922114
Validation loss: 2.794473924167863

Epoch: 6| Step: 3
Training loss: 2.7519723581544904
Validation loss: 2.8049247861382045

Epoch: 6| Step: 4
Training loss: 2.9744429764070888
Validation loss: 2.831301964086447

Epoch: 6| Step: 5
Training loss: 2.4725299338909563
Validation loss: 2.8286200428735233

Epoch: 6| Step: 6
Training loss: 2.5512336925562944
Validation loss: 2.8164233954626003

Epoch: 6| Step: 7
Training loss: 3.208624459141301
Validation loss: 2.805941368145413

Epoch: 6| Step: 8
Training loss: 3.117178321767503
Validation loss: 2.7955825375790786

Epoch: 6| Step: 9
Training loss: 3.4448201699236485
Validation loss: 2.7866020845616233

Epoch: 6| Step: 10
Training loss: 3.14032223888538
Validation loss: 2.7810901735569424

Epoch: 6| Step: 11
Training loss: 3.671158870907705
Validation loss: 2.7745302826571305

Epoch: 6| Step: 12
Training loss: 3.605660248503278
Validation loss: 2.7777203013171845

Epoch: 6| Step: 13
Training loss: 3.484887876526717
Validation loss: 2.773803000057901

Epoch: 47| Step: 0
Training loss: 3.0014180964336856
Validation loss: 2.776482862384561

Epoch: 6| Step: 1
Training loss: 2.245442330808415
Validation loss: 2.784754623723621

Epoch: 6| Step: 2
Training loss: 2.3897353368126324
Validation loss: 2.7882772123577486

Epoch: 6| Step: 3
Training loss: 2.8582497972861862
Validation loss: 2.8164548880084155

Epoch: 6| Step: 4
Training loss: 3.6759795926910894
Validation loss: 2.863449553062684

Epoch: 6| Step: 5
Training loss: 2.920437219363925
Validation loss: 2.8834039665114295

Epoch: 6| Step: 6
Training loss: 3.254678000419331
Validation loss: 2.88005514797668

Epoch: 6| Step: 7
Training loss: 2.9604327493794944
Validation loss: 2.855245702561335

Epoch: 6| Step: 8
Training loss: 3.863724824841273
Validation loss: 2.8488435165132056

Epoch: 6| Step: 9
Training loss: 3.7750485852885474
Validation loss: 2.840466823230866

Epoch: 6| Step: 10
Training loss: 2.929116318018112
Validation loss: 2.838994451564441

Epoch: 6| Step: 11
Training loss: 3.6798266730747073
Validation loss: 2.838665763954868

Epoch: 6| Step: 12
Training loss: 2.7057195130299294
Validation loss: 2.833529866066026

Epoch: 6| Step: 13
Training loss: 3.4073830216298413
Validation loss: 2.830958866793248

Epoch: 48| Step: 0
Training loss: 3.446608941746461
Validation loss: 2.8299880417140995

Epoch: 6| Step: 1
Training loss: 2.914540596776581
Validation loss: 2.8239918109022444

Epoch: 6| Step: 2
Training loss: 3.0015969794227675
Validation loss: 2.799179985312343

Epoch: 6| Step: 3
Training loss: 2.9594242788721474
Validation loss: 2.7878807126098613

Epoch: 6| Step: 4
Training loss: 2.9498227340973653
Validation loss: 2.7862128417091516

Epoch: 6| Step: 5
Training loss: 3.0891800853711193
Validation loss: 2.7829874696857195

Epoch: 6| Step: 6
Training loss: 2.6940179784467997
Validation loss: 2.782095426324152

Epoch: 6| Step: 7
Training loss: 3.487887130634729
Validation loss: 2.786428988032613

Epoch: 6| Step: 8
Training loss: 3.237974660829637
Validation loss: 2.7821922521994775

Epoch: 6| Step: 9
Training loss: 2.8633080620440587
Validation loss: 2.774932499990018

Epoch: 6| Step: 10
Training loss: 3.509885587430597
Validation loss: 2.7748949098444244

Epoch: 6| Step: 11
Training loss: 2.530397059528332
Validation loss: 2.7705623723369084

Epoch: 6| Step: 12
Training loss: 3.212624062840317
Validation loss: 2.77202698425629

Epoch: 6| Step: 13
Training loss: 3.6194971344408584
Validation loss: 2.7856001018252337

Epoch: 49| Step: 0
Training loss: 2.9634924662729025
Validation loss: 2.847857455357844

Epoch: 6| Step: 1
Training loss: 3.2657137772023708
Validation loss: 2.869478615577645

Epoch: 6| Step: 2
Training loss: 3.257531169938381
Validation loss: 2.813009612880642

Epoch: 6| Step: 3
Training loss: 3.2105584953479327
Validation loss: 2.7678721041194927

Epoch: 6| Step: 4
Training loss: 2.4295062521889195
Validation loss: 2.7720204226131533

Epoch: 6| Step: 5
Training loss: 2.5880444750848253
Validation loss: 2.794095769756108

Epoch: 6| Step: 6
Training loss: 3.3307490503564203
Validation loss: 2.822288555613165

Epoch: 6| Step: 7
Training loss: 3.1902235774313725
Validation loss: 2.817503658630457

Epoch: 6| Step: 8
Training loss: 3.4529766896706935
Validation loss: 2.8066774812399937

Epoch: 6| Step: 9
Training loss: 2.7262359685943403
Validation loss: 2.8014022869276616

Epoch: 6| Step: 10
Training loss: 3.3853803583790163
Validation loss: 2.784213811712653

Epoch: 6| Step: 11
Training loss: 3.0801315351365557
Validation loss: 2.7746217627125787

Epoch: 6| Step: 12
Training loss: 2.840662695169825
Validation loss: 2.773532495253977

Epoch: 6| Step: 13
Training loss: 3.956108686144059
Validation loss: 2.787896382891984

Epoch: 50| Step: 0
Training loss: 2.969114742961706
Validation loss: 2.802875490235185

Epoch: 6| Step: 1
Training loss: 3.128044324019368
Validation loss: 2.8057248299583715

Epoch: 6| Step: 2
Training loss: 3.0004790241542514
Validation loss: 2.8285850287181526

Epoch: 6| Step: 3
Training loss: 2.889016853661
Validation loss: 2.8414963973591596

Epoch: 6| Step: 4
Training loss: 3.6800323130391406
Validation loss: 2.8521067281057286

Epoch: 6| Step: 5
Training loss: 2.479127151644505
Validation loss: 2.8542228934511207

Epoch: 6| Step: 6
Training loss: 3.467148969796332
Validation loss: 2.8549068638729893

Epoch: 6| Step: 7
Training loss: 3.1654893460068094
Validation loss: 2.8318947868581

Epoch: 6| Step: 8
Training loss: 3.2825067928851137
Validation loss: 2.7759431567820982

Epoch: 6| Step: 9
Training loss: 3.1282932476333603
Validation loss: 2.7459378374806085

Epoch: 6| Step: 10
Training loss: 3.205966340543328
Validation loss: 2.738281229403104

Epoch: 6| Step: 11
Training loss: 3.352323147904461
Validation loss: 2.74411885003247

Epoch: 6| Step: 12
Training loss: 2.9121660294832723
Validation loss: 2.7549757563967736

Epoch: 6| Step: 13
Training loss: 1.900454983694707
Validation loss: 2.7749879553342325

Epoch: 51| Step: 0
Training loss: 3.499429383765715
Validation loss: 2.790880542232223

Epoch: 6| Step: 1
Training loss: 2.877130631139319
Validation loss: 2.7752518912868216

Epoch: 6| Step: 2
Training loss: 3.3944638226905126
Validation loss: 2.7586181796785705

Epoch: 6| Step: 3
Training loss: 3.68457587732319
Validation loss: 2.741769037979535

Epoch: 6| Step: 4
Training loss: 3.0593692580764396
Validation loss: 2.7396764503530098

Epoch: 6| Step: 5
Training loss: 2.1793630488390456
Validation loss: 2.7346051106702487

Epoch: 6| Step: 6
Training loss: 3.104570673994106
Validation loss: 2.7345273201937146

Epoch: 6| Step: 7
Training loss: 2.9658474837720616
Validation loss: 2.7421104238718077

Epoch: 6| Step: 8
Training loss: 3.0820925166201385
Validation loss: 2.7559695414806447

Epoch: 6| Step: 9
Training loss: 3.0455842242847124
Validation loss: 2.795540713238295

Epoch: 6| Step: 10
Training loss: 2.8489824720588635
Validation loss: 2.809364628486643

Epoch: 6| Step: 11
Training loss: 3.226652351957153
Validation loss: 2.844720742605611

Epoch: 6| Step: 12
Training loss: 2.430081154680839
Validation loss: 2.778544227540058

Epoch: 6| Step: 13
Training loss: 3.850081400815795
Validation loss: 2.7689151148853113

Epoch: 52| Step: 0
Training loss: 2.9193616859166736
Validation loss: 2.738677313709173

Epoch: 6| Step: 1
Training loss: 2.862765277414363
Validation loss: 2.737698867009265

Epoch: 6| Step: 2
Training loss: 2.822602164190859
Validation loss: 2.7317372658870407

Epoch: 6| Step: 3
Training loss: 3.03515907788237
Validation loss: 2.7331903350704865

Epoch: 6| Step: 4
Training loss: 3.4645581735204733
Validation loss: 2.7450351345976323

Epoch: 6| Step: 5
Training loss: 3.4830660563844043
Validation loss: 2.7532525926305764

Epoch: 6| Step: 6
Training loss: 3.0422288732159535
Validation loss: 2.761203235108829

Epoch: 6| Step: 7
Training loss: 2.861662736407517
Validation loss: 2.7652658366382226

Epoch: 6| Step: 8
Training loss: 3.0761839657500483
Validation loss: 2.7500491655267245

Epoch: 6| Step: 9
Training loss: 2.810585642024374
Validation loss: 2.739754337916088

Epoch: 6| Step: 10
Training loss: 3.1038505512715826
Validation loss: 2.7360618851590415

Epoch: 6| Step: 11
Training loss: 3.162567463633959
Validation loss: 2.7307023884071833

Epoch: 6| Step: 12
Training loss: 3.342529929917975
Validation loss: 2.7283423396172295

Epoch: 6| Step: 13
Training loss: 2.9656492403123034
Validation loss: 2.727948888768705

Epoch: 53| Step: 0
Training loss: 3.205084819891317
Validation loss: 2.734328048467029

Epoch: 6| Step: 1
Training loss: 3.3473374561050675
Validation loss: 2.7360557516682382

Epoch: 6| Step: 2
Training loss: 2.8030921415276455
Validation loss: 2.747947430269164

Epoch: 6| Step: 3
Training loss: 2.413277112488613
Validation loss: 2.7412931142208983

Epoch: 6| Step: 4
Training loss: 3.220720447241546
Validation loss: 2.7464267956616135

Epoch: 6| Step: 5
Training loss: 2.867568653352427
Validation loss: 2.725748473914443

Epoch: 6| Step: 6
Training loss: 3.4310593348825758
Validation loss: 2.7209373974957347

Epoch: 6| Step: 7
Training loss: 2.3635425265565475
Validation loss: 2.7220405982688662

Epoch: 6| Step: 8
Training loss: 3.1373243305527283
Validation loss: 2.7207830962795985

Epoch: 6| Step: 9
Training loss: 3.2953612120036437
Validation loss: 2.718113972995319

Epoch: 6| Step: 10
Training loss: 2.938969346090691
Validation loss: 2.7188283295852247

Epoch: 6| Step: 11
Training loss: 3.7198310370682077
Validation loss: 2.7187627222284236

Epoch: 6| Step: 12
Training loss: 2.525737080776322
Validation loss: 2.7170740019853152

Epoch: 6| Step: 13
Training loss: 3.4410790970970178
Validation loss: 2.734074023861674

Epoch: 54| Step: 0
Training loss: 3.3592448364590597
Validation loss: 2.7536137162735512

Epoch: 6| Step: 1
Training loss: 3.28535567867846
Validation loss: 2.8010267345560216

Epoch: 6| Step: 2
Training loss: 3.6828511562592583
Validation loss: 2.8643493867060363

Epoch: 6| Step: 3
Training loss: 2.869349690838576
Validation loss: 2.8645396144062722

Epoch: 6| Step: 4
Training loss: 2.7955423088986304
Validation loss: 2.851928127401346

Epoch: 6| Step: 5
Training loss: 3.2479075518356426
Validation loss: 2.8234044256675377

Epoch: 6| Step: 6
Training loss: 2.764202032023045
Validation loss: 2.7901776811589523

Epoch: 6| Step: 7
Training loss: 3.5578794798914446
Validation loss: 2.7626230892773176

Epoch: 6| Step: 8
Training loss: 2.9801109969185844
Validation loss: 2.7150858609050488

Epoch: 6| Step: 9
Training loss: 2.8871343207723537
Validation loss: 2.7216925910132153

Epoch: 6| Step: 10
Training loss: 2.8653565259195726
Validation loss: 2.7467401560852056

Epoch: 6| Step: 11
Training loss: 3.0461124346214583
Validation loss: 2.8535229524616037

Epoch: 6| Step: 12
Training loss: 2.8217860886939463
Validation loss: 2.742030493069222

Epoch: 6| Step: 13
Training loss: 3.413567897838251
Validation loss: 2.724421390489784

Epoch: 55| Step: 0
Training loss: 3.144146970405294
Validation loss: 2.7164045699523545

Epoch: 6| Step: 1
Training loss: 3.1427611113404885
Validation loss: 2.7162533759437286

Epoch: 6| Step: 2
Training loss: 2.8704629010379756
Validation loss: 2.7119749388673458

Epoch: 6| Step: 3
Training loss: 2.9703825627812495
Validation loss: 2.7092772480467606

Epoch: 6| Step: 4
Training loss: 2.7321120134851236
Validation loss: 2.70483588032901

Epoch: 6| Step: 5
Training loss: 2.811565922226985
Validation loss: 2.7046729923818265

Epoch: 6| Step: 6
Training loss: 3.0310395157873886
Validation loss: 2.724125113609073

Epoch: 6| Step: 7
Training loss: 3.1018990206782786
Validation loss: 2.756416589184209

Epoch: 6| Step: 8
Training loss: 3.4532172419453078
Validation loss: 2.8069340274511396

Epoch: 6| Step: 9
Training loss: 2.7837195415911733
Validation loss: 2.778585110590089

Epoch: 6| Step: 10
Training loss: 2.406755072360401
Validation loss: 2.7381807100240323

Epoch: 6| Step: 11
Training loss: 3.211694929720791
Validation loss: 2.7321654653053757

Epoch: 6| Step: 12
Training loss: 3.824324235250359
Validation loss: 2.7057275382534884

Epoch: 6| Step: 13
Training loss: 3.117750379943947
Validation loss: 2.700285259796562

Epoch: 56| Step: 0
Training loss: 2.6547897813120693
Validation loss: 2.7009233875270473

Epoch: 6| Step: 1
Training loss: 3.011759281504178
Validation loss: 2.7016430638992412

Epoch: 6| Step: 2
Training loss: 3.164739842381755
Validation loss: 2.703947831742345

Epoch: 6| Step: 3
Training loss: 3.5133222710316447
Validation loss: 2.706391728230599

Epoch: 6| Step: 4
Training loss: 3.386356321167507
Validation loss: 2.703681492561678

Epoch: 6| Step: 5
Training loss: 3.0884968248857083
Validation loss: 2.702769586928091

Epoch: 6| Step: 6
Training loss: 3.137406707227741
Validation loss: 2.7020617040483104

Epoch: 6| Step: 7
Training loss: 2.78684238152109
Validation loss: 2.700601064629938

Epoch: 6| Step: 8
Training loss: 3.305979230498182
Validation loss: 2.6986230997598724

Epoch: 6| Step: 9
Training loss: 2.659648650778361
Validation loss: 2.6964298613882

Epoch: 6| Step: 10
Training loss: 2.8738941885544143
Validation loss: 2.69932486491728

Epoch: 6| Step: 11
Training loss: 2.5143964148587803
Validation loss: 2.69898074960156

Epoch: 6| Step: 12
Training loss: 3.0583795348236817
Validation loss: 2.7027317159110367

Epoch: 6| Step: 13
Training loss: 3.466250644687905
Validation loss: 2.704124108133879

Epoch: 57| Step: 0
Training loss: 3.2490429569503076
Validation loss: 2.7059195623424586

Epoch: 6| Step: 1
Training loss: 3.3260442829131747
Validation loss: 2.705439536263105

Epoch: 6| Step: 2
Training loss: 2.598539595166663
Validation loss: 2.710128368854486

Epoch: 6| Step: 3
Training loss: 3.267854942184053
Validation loss: 2.7082625762430292

Epoch: 6| Step: 4
Training loss: 2.8859915223819943
Validation loss: 2.709800410580213

Epoch: 6| Step: 5
Training loss: 3.714689458135867
Validation loss: 2.6996614671789394

Epoch: 6| Step: 6
Training loss: 3.210984426930507
Validation loss: 2.6976585874476715

Epoch: 6| Step: 7
Training loss: 3.11045105683686
Validation loss: 2.6942678963584146

Epoch: 6| Step: 8
Training loss: 2.711466888715153
Validation loss: 2.6964467353118597

Epoch: 6| Step: 9
Training loss: 2.9350908830079034
Validation loss: 2.697320715897713

Epoch: 6| Step: 10
Training loss: 2.7607783722369987
Validation loss: 2.6932802304471157

Epoch: 6| Step: 11
Training loss: 2.4761036348485606
Validation loss: 2.6946938309826645

Epoch: 6| Step: 12
Training loss: 3.084084256120857
Validation loss: 2.6932727982707405

Epoch: 6| Step: 13
Training loss: 2.9537031627013657
Validation loss: 2.701857541462008

Epoch: 58| Step: 0
Training loss: 2.9253672573008487
Validation loss: 2.7117745572757506

Epoch: 6| Step: 1
Training loss: 3.207570930820567
Validation loss: 2.725758144398168

Epoch: 6| Step: 2
Training loss: 2.8668375659242593
Validation loss: 2.7322560771932927

Epoch: 6| Step: 3
Training loss: 3.01629188555942
Validation loss: 2.7592260983779333

Epoch: 6| Step: 4
Training loss: 2.8301841026245156
Validation loss: 2.7650271377176705

Epoch: 6| Step: 5
Training loss: 2.627063938909259
Validation loss: 2.7776665779812606

Epoch: 6| Step: 6
Training loss: 3.780696607716574
Validation loss: 2.762391646738074

Epoch: 6| Step: 7
Training loss: 2.9778780695725624
Validation loss: 2.698781607982235

Epoch: 6| Step: 8
Training loss: 3.0852320383808824
Validation loss: 2.6926195985267083

Epoch: 6| Step: 9
Training loss: 3.1534666876254422
Validation loss: 2.6904852375779513

Epoch: 6| Step: 10
Training loss: 3.559689400228429
Validation loss: 2.692409107852109

Epoch: 6| Step: 11
Training loss: 2.7513968648018774
Validation loss: 2.6936622383967355

Epoch: 6| Step: 12
Training loss: 2.895368653116762
Validation loss: 2.6971024709110756

Epoch: 6| Step: 13
Training loss: 2.5134901382680814
Validation loss: 2.704575938712582

Epoch: 59| Step: 0
Training loss: 2.830316358481312
Validation loss: 2.7035004165825

Epoch: 6| Step: 1
Training loss: 3.1126296295993154
Validation loss: 2.7073542163672117

Epoch: 6| Step: 2
Training loss: 3.1721040990615683
Validation loss: 2.70224726705403

Epoch: 6| Step: 3
Training loss: 2.8846004906294302
Validation loss: 2.702778859678525

Epoch: 6| Step: 4
Training loss: 3.0069188759773655
Validation loss: 2.695114029991193

Epoch: 6| Step: 5
Training loss: 3.0537521608386395
Validation loss: 2.692315720863186

Epoch: 6| Step: 6
Training loss: 2.8053083237426444
Validation loss: 2.696886165534327

Epoch: 6| Step: 7
Training loss: 2.31084062993571
Validation loss: 2.6893489017134278

Epoch: 6| Step: 8
Training loss: 2.6870061731185957
Validation loss: 2.6880291825347205

Epoch: 6| Step: 9
Training loss: 3.6912831442352845
Validation loss: 2.6879671105337795

Epoch: 6| Step: 10
Training loss: 3.1034532448301326
Validation loss: 2.6863591414272054

Epoch: 6| Step: 11
Training loss: 3.028330547336381
Validation loss: 2.6836609068420723

Epoch: 6| Step: 12
Training loss: 3.4407415191849653
Validation loss: 2.6888691990792855

Epoch: 6| Step: 13
Training loss: 3.3077208393210733
Validation loss: 2.685559477686094

Epoch: 60| Step: 0
Training loss: 3.2539965192310776
Validation loss: 2.686848182932251

Epoch: 6| Step: 1
Training loss: 3.198420051113402
Validation loss: 2.6855300471430255

Epoch: 6| Step: 2
Training loss: 2.6920965939858283
Validation loss: 2.689634305057417

Epoch: 6| Step: 3
Training loss: 3.1782976341809825
Validation loss: 2.688594660045376

Epoch: 6| Step: 4
Training loss: 2.85769871004965
Validation loss: 2.6837568780261347

Epoch: 6| Step: 5
Training loss: 2.854776656037977
Validation loss: 2.6809508293132835

Epoch: 6| Step: 6
Training loss: 2.8595560985811446
Validation loss: 2.6792181546270775

Epoch: 6| Step: 7
Training loss: 2.6174458390455597
Validation loss: 2.6789275840560265

Epoch: 6| Step: 8
Training loss: 3.5252618570666026
Validation loss: 2.6771629455406614

Epoch: 6| Step: 9
Training loss: 3.0551585739112075
Validation loss: 2.6773204654551592

Epoch: 6| Step: 10
Training loss: 3.5778833832434165
Validation loss: 2.6775902310146122

Epoch: 6| Step: 11
Training loss: 2.7069142854420916
Validation loss: 2.6782239729018547

Epoch: 6| Step: 12
Training loss: 2.1142230799687525
Validation loss: 2.680266514684085

Epoch: 6| Step: 13
Training loss: 3.846870458307382
Validation loss: 2.6809910380763577

Epoch: 61| Step: 0
Training loss: 2.763339116313238
Validation loss: 2.6827600417653925

Epoch: 6| Step: 1
Training loss: 3.2984214879907277
Validation loss: 2.678772348309338

Epoch: 6| Step: 2
Training loss: 3.0198090143002623
Validation loss: 2.6766253249122425

Epoch: 6| Step: 3
Training loss: 2.8177684182878378
Validation loss: 2.6766868276287203

Epoch: 6| Step: 4
Training loss: 3.269697652248841
Validation loss: 2.6751958961431885

Epoch: 6| Step: 5
Training loss: 2.5353610715723764
Validation loss: 2.6755827856868213

Epoch: 6| Step: 6
Training loss: 3.098846091580574
Validation loss: 2.6758148960111643

Epoch: 6| Step: 7
Training loss: 2.5577329629079535
Validation loss: 2.6718311528098995

Epoch: 6| Step: 8
Training loss: 2.9943363451707046
Validation loss: 2.671792494953594

Epoch: 6| Step: 9
Training loss: 3.072629874257107
Validation loss: 2.6702325869388583

Epoch: 6| Step: 10
Training loss: 2.945168731985195
Validation loss: 2.6756022535430253

Epoch: 6| Step: 11
Training loss: 2.851187903477689
Validation loss: 2.678395662395773

Epoch: 6| Step: 12
Training loss: 3.6359782545742507
Validation loss: 2.6849778892679277

Epoch: 6| Step: 13
Training loss: 3.3146592785862135
Validation loss: 2.698654659843672

Epoch: 62| Step: 0
Training loss: 2.9006888393617563
Validation loss: 2.716704104583481

Epoch: 6| Step: 1
Training loss: 3.0097947759782326
Validation loss: 2.737695157372175

Epoch: 6| Step: 2
Training loss: 2.898659916078813
Validation loss: 2.7173563914791514

Epoch: 6| Step: 3
Training loss: 2.9563264800616773
Validation loss: 2.6923944710011

Epoch: 6| Step: 4
Training loss: 2.534091343745534
Validation loss: 2.671646781020721

Epoch: 6| Step: 5
Training loss: 2.766624485598203
Validation loss: 2.668955894797343

Epoch: 6| Step: 6
Training loss: 2.9146670616908152
Validation loss: 2.669966089607035

Epoch: 6| Step: 7
Training loss: 3.211474742635073
Validation loss: 2.6691540940411205

Epoch: 6| Step: 8
Training loss: 3.0551950954944274
Validation loss: 2.6760550687978952

Epoch: 6| Step: 9
Training loss: 3.0269332508985904
Validation loss: 2.6762660717351676

Epoch: 6| Step: 10
Training loss: 2.5733397492475363
Validation loss: 2.676519729533725

Epoch: 6| Step: 11
Training loss: 3.6650459580187595
Validation loss: 2.6764352891202647

Epoch: 6| Step: 12
Training loss: 3.4026750475542102
Validation loss: 2.6744627094710034

Epoch: 6| Step: 13
Training loss: 3.1578825703604045
Validation loss: 2.667122115252347

Epoch: 63| Step: 0
Training loss: 3.4841771090981406
Validation loss: 2.6676021074107488

Epoch: 6| Step: 1
Training loss: 2.53900615923068
Validation loss: 2.665100120765123

Epoch: 6| Step: 2
Training loss: 2.5287419833529046
Validation loss: 2.660729383671331

Epoch: 6| Step: 3
Training loss: 2.8901614255601533
Validation loss: 2.6599518375445226

Epoch: 6| Step: 4
Training loss: 2.844860153649603
Validation loss: 2.6644556437899785

Epoch: 6| Step: 5
Training loss: 3.6316493643677785
Validation loss: 2.6627161443484675

Epoch: 6| Step: 6
Training loss: 2.457965230591878
Validation loss: 2.662138604149684

Epoch: 6| Step: 7
Training loss: 3.0311137689869034
Validation loss: 2.6598226862642873

Epoch: 6| Step: 8
Training loss: 2.7176435126317187
Validation loss: 2.6670047106082198

Epoch: 6| Step: 9
Training loss: 3.16031498268684
Validation loss: 2.6688522840687883

Epoch: 6| Step: 10
Training loss: 3.2760456774534936
Validation loss: 2.677689450932942

Epoch: 6| Step: 11
Training loss: 3.2562787953456285
Validation loss: 2.66802037171913

Epoch: 6| Step: 12
Training loss: 3.1725610451502866
Validation loss: 2.6621428798681848

Epoch: 6| Step: 13
Training loss: 2.685435544567376
Validation loss: 2.661162946368057

Epoch: 64| Step: 0
Training loss: 3.104434434918149
Validation loss: 2.6560844760693487

Epoch: 6| Step: 1
Training loss: 3.691984133420763
Validation loss: 2.657980553127937

Epoch: 6| Step: 2
Training loss: 2.924286036286718
Validation loss: 2.659275502960075

Epoch: 6| Step: 3
Training loss: 2.8728540123702078
Validation loss: 2.657925502360905

Epoch: 6| Step: 4
Training loss: 3.4880619813154192
Validation loss: 2.6585006723947093

Epoch: 6| Step: 5
Training loss: 2.846496262047191
Validation loss: 2.658122603840246

Epoch: 6| Step: 6
Training loss: 3.1215719112170737
Validation loss: 2.6578091450763774

Epoch: 6| Step: 7
Training loss: 2.669588058353976
Validation loss: 2.6583361044682934

Epoch: 6| Step: 8
Training loss: 3.387533580430594
Validation loss: 2.653671555475601

Epoch: 6| Step: 9
Training loss: 2.7568986367349817
Validation loss: 2.6548222738479486

Epoch: 6| Step: 10
Training loss: 2.442462759680888
Validation loss: 2.6546923225636814

Epoch: 6| Step: 11
Training loss: 2.8199653728875234
Validation loss: 2.655545754545527

Epoch: 6| Step: 12
Training loss: 3.0099422692627233
Validation loss: 2.6545829526726132

Epoch: 6| Step: 13
Training loss: 2.2781792444539652
Validation loss: 2.6604228598434836

Epoch: 65| Step: 0
Training loss: 3.0331672818632383
Validation loss: 2.665857035133634

Epoch: 6| Step: 1
Training loss: 3.253566399053401
Validation loss: 2.6621523365004776

Epoch: 6| Step: 2
Training loss: 2.9708645969224294
Validation loss: 2.655366709944616

Epoch: 6| Step: 3
Training loss: 2.853508940786148
Validation loss: 2.6605762870872303

Epoch: 6| Step: 4
Training loss: 2.1727858355578737
Validation loss: 2.659448538160229

Epoch: 6| Step: 5
Training loss: 2.9784437427289228
Validation loss: 2.6572174761807803

Epoch: 6| Step: 6
Training loss: 3.094334710863782
Validation loss: 2.657710712832953

Epoch: 6| Step: 7
Training loss: 3.5405060306234275
Validation loss: 2.6606482288368016

Epoch: 6| Step: 8
Training loss: 3.542778169832897
Validation loss: 2.660848284951969

Epoch: 6| Step: 9
Training loss: 2.8307920915101565
Validation loss: 2.6601925607214585

Epoch: 6| Step: 10
Training loss: 2.6165306064033733
Validation loss: 2.6727151116654912

Epoch: 6| Step: 11
Training loss: 2.9895758722901147
Validation loss: 2.647873665791824

Epoch: 6| Step: 12
Training loss: 2.0580221175107254
Validation loss: 2.647433047242784

Epoch: 6| Step: 13
Training loss: 3.836779344717555
Validation loss: 2.6515729849498073

Epoch: 66| Step: 0
Training loss: 2.921529004831925
Validation loss: 2.6616472302008534

Epoch: 6| Step: 1
Training loss: 2.9075857394853375
Validation loss: 2.666145280145401

Epoch: 6| Step: 2
Training loss: 3.07002315177016
Validation loss: 2.6725068040081217

Epoch: 6| Step: 3
Training loss: 2.6824408529823236
Validation loss: 2.6784243606297418

Epoch: 6| Step: 4
Training loss: 3.152093548872674
Validation loss: 2.672691682396747

Epoch: 6| Step: 5
Training loss: 3.2253664030366984
Validation loss: 2.671971329264228

Epoch: 6| Step: 6
Training loss: 3.2868839397406773
Validation loss: 2.6632378174770777

Epoch: 6| Step: 7
Training loss: 3.268409089788249
Validation loss: 2.6617472081485065

Epoch: 6| Step: 8
Training loss: 2.630976367776159
Validation loss: 2.6565342296851675

Epoch: 6| Step: 9
Training loss: 2.839779607790928
Validation loss: 2.656433830680135

Epoch: 6| Step: 10
Training loss: 2.8535804610618407
Validation loss: 2.654258600199415

Epoch: 6| Step: 11
Training loss: 2.9933799180425185
Validation loss: 2.6510262012101093

Epoch: 6| Step: 12
Training loss: 3.3054759570741714
Validation loss: 2.6504418849238793

Epoch: 6| Step: 13
Training loss: 2.8801086482111207
Validation loss: 2.651966613356573

Epoch: 67| Step: 0
Training loss: 3.2552781893546197
Validation loss: 2.657990011065963

Epoch: 6| Step: 1
Training loss: 3.2416360776842366
Validation loss: 2.6697080275856644

Epoch: 6| Step: 2
Training loss: 3.5643807516197104
Validation loss: 2.6605150084069145

Epoch: 6| Step: 3
Training loss: 3.1236783093686076
Validation loss: 2.651027700117159

Epoch: 6| Step: 4
Training loss: 2.3973353335542296
Validation loss: 2.6492526421653806

Epoch: 6| Step: 5
Training loss: 2.7891821742094463
Validation loss: 2.6468823408909397

Epoch: 6| Step: 6
Training loss: 2.8658091378824424
Validation loss: 2.643825008767579

Epoch: 6| Step: 7
Training loss: 2.761461820615804
Validation loss: 2.6461051030715965

Epoch: 6| Step: 8
Training loss: 2.7213560746230354
Validation loss: 2.645453457687745

Epoch: 6| Step: 9
Training loss: 2.8153840430797494
Validation loss: 2.6429961863164535

Epoch: 6| Step: 10
Training loss: 3.3809877191662974
Validation loss: 2.64373610879854

Epoch: 6| Step: 11
Training loss: 3.2008706696496256
Validation loss: 2.6502783468749764

Epoch: 6| Step: 12
Training loss: 2.9479424752946732
Validation loss: 2.663340742773491

Epoch: 6| Step: 13
Training loss: 2.375069065093654
Validation loss: 2.6634673017643538

Epoch: 68| Step: 0
Training loss: 2.932208875952038
Validation loss: 2.671202596047197

Epoch: 6| Step: 1
Training loss: 2.393250164705018
Validation loss: 2.6708468541301946

Epoch: 6| Step: 2
Training loss: 3.1007377238929847
Validation loss: 2.674167878584019

Epoch: 6| Step: 3
Training loss: 3.2478933108805013
Validation loss: 2.693814135067928

Epoch: 6| Step: 4
Training loss: 2.1900041688156513
Validation loss: 2.6838398730523805

Epoch: 6| Step: 5
Training loss: 3.5406012484636786
Validation loss: 2.6918912689541648

Epoch: 6| Step: 6
Training loss: 2.921367417580503
Validation loss: 2.664622717194631

Epoch: 6| Step: 7
Training loss: 2.9323607595286494
Validation loss: 2.648394836804269

Epoch: 6| Step: 8
Training loss: 3.056245450443556
Validation loss: 2.640177178653807

Epoch: 6| Step: 9
Training loss: 3.0562891358910282
Validation loss: 2.639707053946953

Epoch: 6| Step: 10
Training loss: 3.1002234347638535
Validation loss: 2.646686821957395

Epoch: 6| Step: 11
Training loss: 2.8277688829656413
Validation loss: 2.652798984271522

Epoch: 6| Step: 12
Training loss: 2.8883311475014346
Validation loss: 2.666850663061888

Epoch: 6| Step: 13
Training loss: 3.879340048636064
Validation loss: 2.6640222907448847

Epoch: 69| Step: 0
Training loss: 3.165922997806414
Validation loss: 2.661821582382455

Epoch: 6| Step: 1
Training loss: 3.3877872246738114
Validation loss: 2.653959814092331

Epoch: 6| Step: 2
Training loss: 2.9756928222208683
Validation loss: 2.652596457743677

Epoch: 6| Step: 3
Training loss: 2.667840957373646
Validation loss: 2.6545655557501746

Epoch: 6| Step: 4
Training loss: 3.173812650202659
Validation loss: 2.650697690931465

Epoch: 6| Step: 5
Training loss: 2.8191970775143114
Validation loss: 2.648940193262198

Epoch: 6| Step: 6
Training loss: 2.336957319778291
Validation loss: 2.6482485547299985

Epoch: 6| Step: 7
Training loss: 3.2855995051552416
Validation loss: 2.648945820037337

Epoch: 6| Step: 8
Training loss: 2.940228595020973
Validation loss: 2.6482289651700675

Epoch: 6| Step: 9
Training loss: 2.771830090284749
Validation loss: 2.642266772500344

Epoch: 6| Step: 10
Training loss: 2.8283580030700275
Validation loss: 2.641590698843387

Epoch: 6| Step: 11
Training loss: 3.3215964314458124
Validation loss: 2.6391734501061803

Epoch: 6| Step: 12
Training loss: 2.7119495800248883
Validation loss: 2.6406421975128387

Epoch: 6| Step: 13
Training loss: 3.747403453883662
Validation loss: 2.6375375780481547

Epoch: 70| Step: 0
Training loss: 3.160865355199612
Validation loss: 2.6416335359794316

Epoch: 6| Step: 1
Training loss: 2.8558563094656813
Validation loss: 2.652490610359265

Epoch: 6| Step: 2
Training loss: 2.852763719863534
Validation loss: 2.663187453613427

Epoch: 6| Step: 3
Training loss: 2.9067797434390648
Validation loss: 2.6542735497292043

Epoch: 6| Step: 4
Training loss: 3.292435101656615
Validation loss: 2.641491134270623

Epoch: 6| Step: 5
Training loss: 2.8367194156546143
Validation loss: 2.635965754016801

Epoch: 6| Step: 6
Training loss: 3.056958225312965
Validation loss: 2.6285228870575046

Epoch: 6| Step: 7
Training loss: 2.9701669624228146
Validation loss: 2.628829715291645

Epoch: 6| Step: 8
Training loss: 2.771036145429161
Validation loss: 2.6322254154277474

Epoch: 6| Step: 9
Training loss: 3.4877342829065436
Validation loss: 2.625152142047132

Epoch: 6| Step: 10
Training loss: 3.2539201715544777
Validation loss: 2.6232113464907476

Epoch: 6| Step: 11
Training loss: 2.760955834665176
Validation loss: 2.6213632022128546

Epoch: 6| Step: 12
Training loss: 2.4628416415008982
Validation loss: 2.6199894283286174

Epoch: 6| Step: 13
Training loss: 2.9213011479011395
Validation loss: 2.6194070728517542

Epoch: 71| Step: 0
Training loss: 2.531828072554898
Validation loss: 2.620176042264321

Epoch: 6| Step: 1
Training loss: 3.5426979508210903
Validation loss: 2.633705300106566

Epoch: 6| Step: 2
Training loss: 3.0420666436012422
Validation loss: 2.652608687358825

Epoch: 6| Step: 3
Training loss: 2.951261871197684
Validation loss: 2.669039559458427

Epoch: 6| Step: 4
Training loss: 2.493241233841638
Validation loss: 2.6979197732826203

Epoch: 6| Step: 5
Training loss: 2.966630038203169
Validation loss: 2.7267157586802604

Epoch: 6| Step: 6
Training loss: 3.574651239629588
Validation loss: 2.736600706358672

Epoch: 6| Step: 7
Training loss: 2.7308331902598706
Validation loss: 2.6373465726629957

Epoch: 6| Step: 8
Training loss: 3.049794837430059
Validation loss: 2.619845034536181

Epoch: 6| Step: 9
Training loss: 2.75711664601029
Validation loss: 2.6126350157945746

Epoch: 6| Step: 10
Training loss: 3.3275661805275965
Validation loss: 2.6112995307359355

Epoch: 6| Step: 11
Training loss: 3.2328944848986767
Validation loss: 2.617973128174931

Epoch: 6| Step: 12
Training loss: 1.942037621727896
Validation loss: 2.629547761035103

Epoch: 6| Step: 13
Training loss: 3.317869764360017
Validation loss: 2.6337654903909136

Epoch: 72| Step: 0
Training loss: 3.5412888418882367
Validation loss: 2.636406001020547

Epoch: 6| Step: 1
Training loss: 2.795683111332627
Validation loss: 2.6455617252848302

Epoch: 6| Step: 2
Training loss: 3.295397097287153
Validation loss: 2.660903647140991

Epoch: 6| Step: 3
Training loss: 2.801399705351428
Validation loss: 2.6819398162789914

Epoch: 6| Step: 4
Training loss: 3.785630644211034
Validation loss: 2.6922060396710235

Epoch: 6| Step: 5
Training loss: 2.3363653193097687
Validation loss: 2.642056273309319

Epoch: 6| Step: 6
Training loss: 3.1841743922661916
Validation loss: 2.6308030550911736

Epoch: 6| Step: 7
Training loss: 2.8224454723460037
Validation loss: 2.625163773927613

Epoch: 6| Step: 8
Training loss: 2.905554903645034
Validation loss: 2.6162609690590433

Epoch: 6| Step: 9
Training loss: 3.276973880816226
Validation loss: 2.614178834642505

Epoch: 6| Step: 10
Training loss: 2.3907578375317997
Validation loss: 2.612262792426714

Epoch: 6| Step: 11
Training loss: 2.557592018239558
Validation loss: 2.629277183865116

Epoch: 6| Step: 12
Training loss: 2.9026041440326593
Validation loss: 2.642161197773642

Epoch: 6| Step: 13
Training loss: 2.9119757577494876
Validation loss: 2.663696834614006

Epoch: 73| Step: 0
Training loss: 2.9047294658812026
Validation loss: 2.6618759684566013

Epoch: 6| Step: 1
Training loss: 2.573689477254315
Validation loss: 2.6576900759967352

Epoch: 6| Step: 2
Training loss: 2.4211198183116798
Validation loss: 2.64242286299685

Epoch: 6| Step: 3
Training loss: 2.6105524935527034
Validation loss: 2.646432741994422

Epoch: 6| Step: 4
Training loss: 2.4696396781870193
Validation loss: 2.6476235258856105

Epoch: 6| Step: 5
Training loss: 3.055502546216665
Validation loss: 2.6649855206553403

Epoch: 6| Step: 6
Training loss: 3.3798454258351907
Validation loss: 2.6482002456219695

Epoch: 6| Step: 7
Training loss: 2.853780808551925
Validation loss: 2.638593694939405

Epoch: 6| Step: 8
Training loss: 2.878795274849719
Validation loss: 2.649958450740822

Epoch: 6| Step: 9
Training loss: 3.10916980468897
Validation loss: 2.6421270271423603

Epoch: 6| Step: 10
Training loss: 3.179355313431547
Validation loss: 2.623279193058329

Epoch: 6| Step: 11
Training loss: 3.045987200383866
Validation loss: 2.615630331720205

Epoch: 6| Step: 12
Training loss: 3.5356674246276674
Validation loss: 2.6095085313739657

Epoch: 6| Step: 13
Training loss: 3.606849744830953
Validation loss: 2.6090409161591683

Epoch: 74| Step: 0
Training loss: 2.9117494459200004
Validation loss: 2.608675336257079

Epoch: 6| Step: 1
Training loss: 2.4075175328076774
Validation loss: 2.6106164307732436

Epoch: 6| Step: 2
Training loss: 2.667509025408305
Validation loss: 2.608051543347123

Epoch: 6| Step: 3
Training loss: 3.0094330620636014
Validation loss: 2.609380340718077

Epoch: 6| Step: 4
Training loss: 3.0264302112064674
Validation loss: 2.6070507491353965

Epoch: 6| Step: 5
Training loss: 3.608338178201173
Validation loss: 2.6091094525122176

Epoch: 6| Step: 6
Training loss: 2.7420513412710754
Validation loss: 2.6053867309036747

Epoch: 6| Step: 7
Training loss: 3.2418415666352454
Validation loss: 2.6067478187561894

Epoch: 6| Step: 8
Training loss: 2.397138610428826
Validation loss: 2.610390351450769

Epoch: 6| Step: 9
Training loss: 3.0718850338404287
Validation loss: 2.6063851876888204

Epoch: 6| Step: 10
Training loss: 3.6052484083368554
Validation loss: 2.6113882655910587

Epoch: 6| Step: 11
Training loss: 2.873772566459098
Validation loss: 2.61139772342216

Epoch: 6| Step: 12
Training loss: 2.655165327423999
Validation loss: 2.6070695831499426

Epoch: 6| Step: 13
Training loss: 3.058177934348688
Validation loss: 2.607047074357754

Epoch: 75| Step: 0
Training loss: 2.877008980120134
Validation loss: 2.6113382388475967

Epoch: 6| Step: 1
Training loss: 3.059477423881204
Validation loss: 2.6073276917095725

Epoch: 6| Step: 2
Training loss: 3.34341628646503
Validation loss: 2.6068800853045415

Epoch: 6| Step: 3
Training loss: 3.0224404280402695
Validation loss: 2.6067776578433373

Epoch: 6| Step: 4
Training loss: 3.017731716358176
Validation loss: 2.601470559355025

Epoch: 6| Step: 5
Training loss: 3.4504968644755167
Validation loss: 2.601691631608252

Epoch: 6| Step: 6
Training loss: 2.7044850714975532
Validation loss: 2.6028453331244368

Epoch: 6| Step: 7
Training loss: 2.486133648742396
Validation loss: 2.601425542247021

Epoch: 6| Step: 8
Training loss: 2.8789393760814663
Validation loss: 2.599817021244103

Epoch: 6| Step: 9
Training loss: 3.205100143701027
Validation loss: 2.599132751876514

Epoch: 6| Step: 10
Training loss: 2.5773232802925006
Validation loss: 2.5953806981951493

Epoch: 6| Step: 11
Training loss: 2.709521184759252
Validation loss: 2.600834771412547

Epoch: 6| Step: 12
Training loss: 2.953841511022758
Validation loss: 2.595227408470106

Epoch: 6| Step: 13
Training loss: 2.9749599357920555
Validation loss: 2.5939791326504884

Epoch: 76| Step: 0
Training loss: 3.127867489332429
Validation loss: 2.5977795589126327

Epoch: 6| Step: 1
Training loss: 2.53823895523372
Validation loss: 2.6007224653260304

Epoch: 6| Step: 2
Training loss: 3.1244080555085407
Validation loss: 2.6044128032569245

Epoch: 6| Step: 3
Training loss: 3.1588362871226443
Validation loss: 2.638978360625131

Epoch: 6| Step: 4
Training loss: 2.7163428688938334
Validation loss: 2.6428978969063723

Epoch: 6| Step: 5
Training loss: 3.0183842344606857
Validation loss: 2.6840157622513363

Epoch: 6| Step: 6
Training loss: 2.9899929355295476
Validation loss: 2.6667951590078314

Epoch: 6| Step: 7
Training loss: 3.170667897811578
Validation loss: 2.6787648270729587

Epoch: 6| Step: 8
Training loss: 3.126977676209443
Validation loss: 2.612228218916777

Epoch: 6| Step: 9
Training loss: 2.7680139945453712
Validation loss: 2.595857778146475

Epoch: 6| Step: 10
Training loss: 3.0805849421522904
Validation loss: 2.5946547245782847

Epoch: 6| Step: 11
Training loss: 2.5071295167679066
Validation loss: 2.599856781860488

Epoch: 6| Step: 12
Training loss: 3.069824801239109
Validation loss: 2.6005130390227476

Epoch: 6| Step: 13
Training loss: 3.187644207254162
Validation loss: 2.600018475540248

Epoch: 77| Step: 0
Training loss: 3.5318125048906754
Validation loss: 2.599509709404464

Epoch: 6| Step: 1
Training loss: 2.852152389756643
Validation loss: 2.596268227196688

Epoch: 6| Step: 2
Training loss: 2.7359450709980555
Validation loss: 2.5928644407385564

Epoch: 6| Step: 3
Training loss: 2.7333398221877077
Validation loss: 2.5919927556764186

Epoch: 6| Step: 4
Training loss: 3.0059175938055107
Validation loss: 2.5889469810791756

Epoch: 6| Step: 5
Training loss: 3.006922047575446
Validation loss: 2.5921286120971354

Epoch: 6| Step: 6
Training loss: 2.6493211920462736
Validation loss: 2.5974800478790256

Epoch: 6| Step: 7
Training loss: 2.4779368537203266
Validation loss: 2.6053224547648135

Epoch: 6| Step: 8
Training loss: 2.8057531176042203
Validation loss: 2.6334383022913457

Epoch: 6| Step: 9
Training loss: 2.987147296850876
Validation loss: 2.6232476037333865

Epoch: 6| Step: 10
Training loss: 3.297744997769309
Validation loss: 2.6185099380968353

Epoch: 6| Step: 11
Training loss: 3.014890907553413
Validation loss: 2.6068794775550304

Epoch: 6| Step: 12
Training loss: 3.261199434706453
Validation loss: 2.601222014910377

Epoch: 6| Step: 13
Training loss: 2.720567819006264
Validation loss: 2.589520475821106

Epoch: 78| Step: 0
Training loss: 3.24320214262686
Validation loss: 2.5873148952951626

Epoch: 6| Step: 1
Training loss: 2.3138940063375197
Validation loss: 2.5872366209345703

Epoch: 6| Step: 2
Training loss: 2.435520248451085
Validation loss: 2.5892903387154798

Epoch: 6| Step: 3
Training loss: 2.81687493729914
Validation loss: 2.5872687797402465

Epoch: 6| Step: 4
Training loss: 2.7559261624835893
Validation loss: 2.5880001110119926

Epoch: 6| Step: 5
Training loss: 2.8598795794764587
Validation loss: 2.5837582811947923

Epoch: 6| Step: 6
Training loss: 3.471081062137443
Validation loss: 2.583200915419792

Epoch: 6| Step: 7
Training loss: 2.8758721065495907
Validation loss: 2.5842776360569806

Epoch: 6| Step: 8
Training loss: 3.2281750212613174
Validation loss: 2.587004341334595

Epoch: 6| Step: 9
Training loss: 3.239668637508993
Validation loss: 2.584984424068342

Epoch: 6| Step: 10
Training loss: 2.5806121850983206
Validation loss: 2.585028138745705

Epoch: 6| Step: 11
Training loss: 3.2166619796587015
Validation loss: 2.583022745643181

Epoch: 6| Step: 12
Training loss: 2.6310890057891005
Validation loss: 2.5804824973634233

Epoch: 6| Step: 13
Training loss: 3.746770867180477
Validation loss: 2.580325147247639

Epoch: 79| Step: 0
Training loss: 3.2471453527513257
Validation loss: 2.5797716576816643

Epoch: 6| Step: 1
Training loss: 2.9388536621399073
Validation loss: 2.586578968672828

Epoch: 6| Step: 2
Training loss: 2.918815765620162
Validation loss: 2.5902570384422554

Epoch: 6| Step: 3
Training loss: 2.584587920526811
Validation loss: 2.5966120186922

Epoch: 6| Step: 4
Training loss: 2.302797738870581
Validation loss: 2.614736712250402

Epoch: 6| Step: 5
Training loss: 3.326442239360509
Validation loss: 2.652439997970365

Epoch: 6| Step: 6
Training loss: 3.346219300794374
Validation loss: 2.6492319607321906

Epoch: 6| Step: 7
Training loss: 3.0725890593816856
Validation loss: 2.608672603265264

Epoch: 6| Step: 8
Training loss: 2.9376350534113747
Validation loss: 2.5917670395069825

Epoch: 6| Step: 9
Training loss: 2.687670147854724
Validation loss: 2.5787681973001346

Epoch: 6| Step: 10
Training loss: 2.985047908634919
Validation loss: 2.5771419626079775

Epoch: 6| Step: 11
Training loss: 3.510507071186524
Validation loss: 2.5793015704802444

Epoch: 6| Step: 12
Training loss: 2.7063482394458878
Validation loss: 2.5845857829915353

Epoch: 6| Step: 13
Training loss: 2.2862665071303425
Validation loss: 2.594752752790716

Epoch: 80| Step: 0
Training loss: 3.077794246040413
Validation loss: 2.603456469426133

Epoch: 6| Step: 1
Training loss: 3.1876530330049544
Validation loss: 2.600222621597058

Epoch: 6| Step: 2
Training loss: 2.7555376996552217
Validation loss: 2.596721927778228

Epoch: 6| Step: 3
Training loss: 3.407896851165122
Validation loss: 2.5852288077846324

Epoch: 6| Step: 4
Training loss: 2.692957637222774
Validation loss: 2.584039520798068

Epoch: 6| Step: 5
Training loss: 2.8870256438905155
Validation loss: 2.5832826554497554

Epoch: 6| Step: 6
Training loss: 3.1502710498269715
Validation loss: 2.5797106905759075

Epoch: 6| Step: 7
Training loss: 3.091179752993964
Validation loss: 2.5874518964799247

Epoch: 6| Step: 8
Training loss: 2.9066547399095364
Validation loss: 2.590697225511422

Epoch: 6| Step: 9
Training loss: 3.1481051967740936
Validation loss: 2.5909098516437834

Epoch: 6| Step: 10
Training loss: 2.603534764235962
Validation loss: 2.5937553511464415

Epoch: 6| Step: 11
Training loss: 2.7769247991856085
Validation loss: 2.590944023928496

Epoch: 6| Step: 12
Training loss: 2.830366900488669
Validation loss: 2.595705481526723

Epoch: 6| Step: 13
Training loss: 2.4027165813652327
Validation loss: 2.6009028074211087

Epoch: 81| Step: 0
Training loss: 2.772212399975184
Validation loss: 2.6142674099867986

Epoch: 6| Step: 1
Training loss: 3.1426761438838895
Validation loss: 2.632355156204856

Epoch: 6| Step: 2
Training loss: 3.42144326748125
Validation loss: 2.6605032526059684

Epoch: 6| Step: 3
Training loss: 3.1411020096977347
Validation loss: 2.6317714160213375

Epoch: 6| Step: 4
Training loss: 2.433935248598976
Validation loss: 2.5863253652614153

Epoch: 6| Step: 5
Training loss: 2.474959856728879
Validation loss: 2.5790800103869254

Epoch: 6| Step: 6
Training loss: 3.014562231770767
Validation loss: 2.5855063525826933

Epoch: 6| Step: 7
Training loss: 2.751043381859561
Validation loss: 2.5817207138641978

Epoch: 6| Step: 8
Training loss: 2.89826870244248
Validation loss: 2.5896293682442066

Epoch: 6| Step: 9
Training loss: 2.6317444397940157
Validation loss: 2.5899559052020926

Epoch: 6| Step: 10
Training loss: 3.1258211201492156
Validation loss: 2.5915547824503924

Epoch: 6| Step: 11
Training loss: 2.549912589575874
Validation loss: 2.590299499251145

Epoch: 6| Step: 12
Training loss: 3.4366723191233
Validation loss: 2.5897922716462887

Epoch: 6| Step: 13
Training loss: 3.7336252649018458
Validation loss: 2.590356930391178

Epoch: 82| Step: 0
Training loss: 2.9552609424302965
Validation loss: 2.5903878955094766

Epoch: 6| Step: 1
Training loss: 2.8793787574950556
Validation loss: 2.588659778045427

Epoch: 6| Step: 2
Training loss: 2.7659278315895675
Validation loss: 2.5835014368619023

Epoch: 6| Step: 3
Training loss: 3.0076037049587407
Validation loss: 2.5867031882014238

Epoch: 6| Step: 4
Training loss: 3.0728702520108717
Validation loss: 2.5836567023019583

Epoch: 6| Step: 5
Training loss: 2.3516524288179954
Validation loss: 2.58605199067864

Epoch: 6| Step: 6
Training loss: 3.0831261298863666
Validation loss: 2.5800585881911995

Epoch: 6| Step: 7
Training loss: 3.0496444244735574
Validation loss: 2.580950083907186

Epoch: 6| Step: 8
Training loss: 2.8564912189153033
Validation loss: 2.5806373464045587

Epoch: 6| Step: 9
Training loss: 2.852205386916032
Validation loss: 2.580263789835523

Epoch: 6| Step: 10
Training loss: 3.251675980588973
Validation loss: 2.583295808639325

Epoch: 6| Step: 11
Training loss: 2.723736891975391
Validation loss: 2.588940301011115

Epoch: 6| Step: 12
Training loss: 2.925145241807481
Validation loss: 2.586469636596987

Epoch: 6| Step: 13
Training loss: 3.5577398253378396
Validation loss: 2.5887521251461525

Epoch: 83| Step: 0
Training loss: 3.2260363429198753
Validation loss: 2.5914519154517484

Epoch: 6| Step: 1
Training loss: 2.9838521609258257
Validation loss: 2.591949415127035

Epoch: 6| Step: 2
Training loss: 2.9431714439008405
Validation loss: 2.5963521655348143

Epoch: 6| Step: 3
Training loss: 3.540114627426262
Validation loss: 2.5978734410053055

Epoch: 6| Step: 4
Training loss: 2.71772132793423
Validation loss: 2.596045831986081

Epoch: 6| Step: 5
Training loss: 3.182318870981732
Validation loss: 2.5890683442004145

Epoch: 6| Step: 6
Training loss: 2.7309606542892335
Validation loss: 2.58411813406706

Epoch: 6| Step: 7
Training loss: 2.9033533242636342
Validation loss: 2.5919285088970248

Epoch: 6| Step: 8
Training loss: 2.3154678888600553
Validation loss: 2.5751658979068237

Epoch: 6| Step: 9
Training loss: 2.8246595532013585
Validation loss: 2.586241920277884

Epoch: 6| Step: 10
Training loss: 3.3263008957287346
Validation loss: 2.5829151716867282

Epoch: 6| Step: 11
Training loss: 2.8016124646422056
Validation loss: 2.5732169907450793

Epoch: 6| Step: 12
Training loss: 2.5057175106289433
Validation loss: 2.564101155387564

Epoch: 6| Step: 13
Training loss: 2.87071323078955
Validation loss: 2.5667776524338954

Epoch: 84| Step: 0
Training loss: 3.1756699883934894
Validation loss: 2.566672993364382

Epoch: 6| Step: 1
Training loss: 2.8880200995171146
Validation loss: 2.5663142206279823

Epoch: 6| Step: 2
Training loss: 3.049424889545965
Validation loss: 2.5660615386938193

Epoch: 6| Step: 3
Training loss: 2.636378106612671
Validation loss: 2.565993791773609

Epoch: 6| Step: 4
Training loss: 2.6147091190633867
Validation loss: 2.564330630895347

Epoch: 6| Step: 5
Training loss: 3.075117316760585
Validation loss: 2.5638696315228535

Epoch: 6| Step: 6
Training loss: 3.1978117255637986
Validation loss: 2.5650413061151602

Epoch: 6| Step: 7
Training loss: 2.897447278100176
Validation loss: 2.567110402666907

Epoch: 6| Step: 8
Training loss: 2.801331448747575
Validation loss: 2.566476966736573

Epoch: 6| Step: 9
Training loss: 2.389633371970542
Validation loss: 2.5633449066934353

Epoch: 6| Step: 10
Training loss: 3.1488863717320887
Validation loss: 2.5614658302774878

Epoch: 6| Step: 11
Training loss: 2.771970118940952
Validation loss: 2.5625719500029125

Epoch: 6| Step: 12
Training loss: 3.285993362800828
Validation loss: 2.5624195499432085

Epoch: 6| Step: 13
Training loss: 3.0557445833710104
Validation loss: 2.5626211120253317

Epoch: 85| Step: 0
Training loss: 3.2437901959289968
Validation loss: 2.56750408660627

Epoch: 6| Step: 1
Training loss: 2.9222898137825593
Validation loss: 2.567737663960327

Epoch: 6| Step: 2
Training loss: 2.5751507798280233
Validation loss: 2.579172212447405

Epoch: 6| Step: 3
Training loss: 2.9590059688774772
Validation loss: 2.592521563384014

Epoch: 6| Step: 4
Training loss: 2.550154931840731
Validation loss: 2.5778872572040723

Epoch: 6| Step: 5
Training loss: 2.938123758523107
Validation loss: 2.590172174121702

Epoch: 6| Step: 6
Training loss: 3.398793028727113
Validation loss: 2.5893527831863863

Epoch: 6| Step: 7
Training loss: 3.211460191641802
Validation loss: 2.587023539302282

Epoch: 6| Step: 8
Training loss: 2.9811700518302686
Validation loss: 2.5904069872483384

Epoch: 6| Step: 9
Training loss: 3.0749749655596155
Validation loss: 2.5869103056033764

Epoch: 6| Step: 10
Training loss: 2.4305587138806364
Validation loss: 2.5679891107846684

Epoch: 6| Step: 11
Training loss: 2.849765326224386
Validation loss: 2.569061644187422

Epoch: 6| Step: 12
Training loss: 2.6118697615454787
Validation loss: 2.565033447396804

Epoch: 6| Step: 13
Training loss: 3.078634152201756
Validation loss: 2.5613992038907583

Epoch: 86| Step: 0
Training loss: 3.009944328731106
Validation loss: 2.568683464981634

Epoch: 6| Step: 1
Training loss: 2.0883974578868254
Validation loss: 2.5686300395159316

Epoch: 6| Step: 2
Training loss: 3.8384444674327947
Validation loss: 2.58087336376603

Epoch: 6| Step: 3
Training loss: 2.751928433591102
Validation loss: 2.587808041840487

Epoch: 6| Step: 4
Training loss: 3.089459150566257
Validation loss: 2.5910613961987776

Epoch: 6| Step: 5
Training loss: 2.5696877876957953
Validation loss: 2.5879678513374573

Epoch: 6| Step: 6
Training loss: 2.6256451495150435
Validation loss: 2.593132911294599

Epoch: 6| Step: 7
Training loss: 3.2311990228464946
Validation loss: 2.595346793737129

Epoch: 6| Step: 8
Training loss: 2.3899768623923947
Validation loss: 2.5892603664186975

Epoch: 6| Step: 9
Training loss: 2.713861125707291
Validation loss: 2.5724399545667

Epoch: 6| Step: 10
Training loss: 3.3066802813905976
Validation loss: 2.565120396683233

Epoch: 6| Step: 11
Training loss: 3.038158448990018
Validation loss: 2.5588716820824833

Epoch: 6| Step: 12
Training loss: 2.9048993653612127
Validation loss: 2.5569658814784

Epoch: 6| Step: 13
Training loss: 3.0662558743482413
Validation loss: 2.554270270937515

Epoch: 87| Step: 0
Training loss: 3.1502498588165406
Validation loss: 2.5558533845706197

Epoch: 6| Step: 1
Training loss: 2.5625832706970892
Validation loss: 2.553991342251121

Epoch: 6| Step: 2
Training loss: 2.9263216342167118
Validation loss: 2.549179907434997

Epoch: 6| Step: 3
Training loss: 2.8748809126363515
Validation loss: 2.551468614717112

Epoch: 6| Step: 4
Training loss: 2.720950409111716
Validation loss: 2.552792681384439

Epoch: 6| Step: 5
Training loss: 2.7406175254450167
Validation loss: 2.5574498408457162

Epoch: 6| Step: 6
Training loss: 2.867205461243129
Validation loss: 2.569180079012461

Epoch: 6| Step: 7
Training loss: 2.7557174894818113
Validation loss: 2.5869826608279376

Epoch: 6| Step: 8
Training loss: 2.724858754548347
Validation loss: 2.5995519520205868

Epoch: 6| Step: 9
Training loss: 3.0860088871292044
Validation loss: 2.635697231479166

Epoch: 6| Step: 10
Training loss: 3.1284179306447046
Validation loss: 2.6157267054839894

Epoch: 6| Step: 11
Training loss: 3.118062979149613
Validation loss: 2.579584527319659

Epoch: 6| Step: 12
Training loss: 3.4959415338720916
Validation loss: 2.550149405765563

Epoch: 6| Step: 13
Training loss: 2.520182018367063
Validation loss: 2.5490214708459065

Epoch: 88| Step: 0
Training loss: 2.907240832021161
Validation loss: 2.5482908584187336

Epoch: 6| Step: 1
Training loss: 2.974180214394022
Validation loss: 2.5496204053071003

Epoch: 6| Step: 2
Training loss: 2.735706027188156
Validation loss: 2.551747527808426

Epoch: 6| Step: 3
Training loss: 2.9393879119634874
Validation loss: 2.555839071052275

Epoch: 6| Step: 4
Training loss: 2.941547284031711
Validation loss: 2.5551905193712616

Epoch: 6| Step: 5
Training loss: 2.8079900397806044
Validation loss: 2.5569668068876497

Epoch: 6| Step: 6
Training loss: 2.8570966137822222
Validation loss: 2.5583177658312337

Epoch: 6| Step: 7
Training loss: 3.6026101398772377
Validation loss: 2.5594995992524816

Epoch: 6| Step: 8
Training loss: 3.100833374723294
Validation loss: 2.5636342187423056

Epoch: 6| Step: 9
Training loss: 2.415087534737728
Validation loss: 2.558871159109582

Epoch: 6| Step: 10
Training loss: 3.18229444704491
Validation loss: 2.553455007436363

Epoch: 6| Step: 11
Training loss: 2.997097041364194
Validation loss: 2.554833879028109

Epoch: 6| Step: 12
Training loss: 2.8334352998524084
Validation loss: 2.5537930321611633

Epoch: 6| Step: 13
Training loss: 2.3705607636908583
Validation loss: 2.5460101048849064

Epoch: 89| Step: 0
Training loss: 2.8013911946436982
Validation loss: 2.549900702896305

Epoch: 6| Step: 1
Training loss: 2.988474322296314
Validation loss: 2.558771652052402

Epoch: 6| Step: 2
Training loss: 2.4113584515598627
Validation loss: 2.591649606210218

Epoch: 6| Step: 3
Training loss: 3.1780128661772107
Validation loss: 2.647198613959051

Epoch: 6| Step: 4
Training loss: 3.1053437597684748
Validation loss: 2.715681644206112

Epoch: 6| Step: 5
Training loss: 3.0900738385708237
Validation loss: 2.716008067352409

Epoch: 6| Step: 6
Training loss: 2.883488604236493
Validation loss: 2.7307417735400352

Epoch: 6| Step: 7
Training loss: 3.2355049849960933
Validation loss: 2.71774218338867

Epoch: 6| Step: 8
Training loss: 2.9955825071068842
Validation loss: 2.6581561936798512

Epoch: 6| Step: 9
Training loss: 2.9721114552932812
Validation loss: 2.6127619900139223

Epoch: 6| Step: 10
Training loss: 2.960046961386059
Validation loss: 2.5854364230693867

Epoch: 6| Step: 11
Training loss: 2.8497542827489353
Validation loss: 2.5735199142919174

Epoch: 6| Step: 12
Training loss: 3.133174884793955
Validation loss: 2.5666045364234837

Epoch: 6| Step: 13
Training loss: 2.675409310657572
Validation loss: 2.5585329866587503

Epoch: 90| Step: 0
Training loss: 2.8737554759022768
Validation loss: 2.557302383518355

Epoch: 6| Step: 1
Training loss: 2.577821470946306
Validation loss: 2.5472267965328177

Epoch: 6| Step: 2
Training loss: 2.9954694870954897
Validation loss: 2.5482002603627736

Epoch: 6| Step: 3
Training loss: 2.987365662176015
Validation loss: 2.5516435865022293

Epoch: 6| Step: 4
Training loss: 2.988083058685047
Validation loss: 2.546207896496601

Epoch: 6| Step: 5
Training loss: 2.832675371254379
Validation loss: 2.546002459293659

Epoch: 6| Step: 6
Training loss: 2.9119549613760376
Validation loss: 2.5498680526983737

Epoch: 6| Step: 7
Training loss: 2.996980737246856
Validation loss: 2.553799549186451

Epoch: 6| Step: 8
Training loss: 2.9552233471834715
Validation loss: 2.5500481106962645

Epoch: 6| Step: 9
Training loss: 2.8890323684796346
Validation loss: 2.552778491300331

Epoch: 6| Step: 10
Training loss: 3.0985814140473993
Validation loss: 2.5495631756866746

Epoch: 6| Step: 11
Training loss: 3.099802743111828
Validation loss: 2.5474651535449166

Epoch: 6| Step: 12
Training loss: 3.040183206358238
Validation loss: 2.550768106035337

Epoch: 6| Step: 13
Training loss: 2.7883988988099024
Validation loss: 2.5476748228953485

Epoch: 91| Step: 0
Training loss: 2.6129916590876108
Validation loss: 2.5450283885097527

Epoch: 6| Step: 1
Training loss: 3.127619751513696
Validation loss: 2.541427171001916

Epoch: 6| Step: 2
Training loss: 2.9831562849250934
Validation loss: 2.53747695172035

Epoch: 6| Step: 3
Training loss: 3.4011343241868746
Validation loss: 2.5387141082256344

Epoch: 6| Step: 4
Training loss: 3.1794832431131486
Validation loss: 2.540823120857136

Epoch: 6| Step: 5
Training loss: 2.646969188469067
Validation loss: 2.533884667198631

Epoch: 6| Step: 6
Training loss: 2.995339429213927
Validation loss: 2.535633516439674

Epoch: 6| Step: 7
Training loss: 3.1174178647843727
Validation loss: 2.5405178718355397

Epoch: 6| Step: 8
Training loss: 2.5764038814395214
Validation loss: 2.559420896916923

Epoch: 6| Step: 9
Training loss: 2.5803033122596375
Validation loss: 2.557753490128853

Epoch: 6| Step: 10
Training loss: 2.7046188901135917
Validation loss: 2.5642521208239097

Epoch: 6| Step: 11
Training loss: 2.8977059729026178
Validation loss: 2.559438235397336

Epoch: 6| Step: 12
Training loss: 2.595455298494261
Validation loss: 2.5767696901391095

Epoch: 6| Step: 13
Training loss: 3.3795020135003515
Validation loss: 2.5759684960620284

Epoch: 92| Step: 0
Training loss: 3.325273752057573
Validation loss: 2.5824975743487015

Epoch: 6| Step: 1
Training loss: 2.9211898245141015
Validation loss: 2.59639101749732

Epoch: 6| Step: 2
Training loss: 2.5925693812416117
Validation loss: 2.588190896090798

Epoch: 6| Step: 3
Training loss: 3.0507793743992315
Validation loss: 2.6007891498984477

Epoch: 6| Step: 4
Training loss: 3.00830724040909
Validation loss: 2.6212008847901997

Epoch: 6| Step: 5
Training loss: 2.9061535234742766
Validation loss: 2.635063153188992

Epoch: 6| Step: 6
Training loss: 2.858712541729272
Validation loss: 2.6315244562771336

Epoch: 6| Step: 7
Training loss: 3.2007279521740246
Validation loss: 2.62191749247037

Epoch: 6| Step: 8
Training loss: 2.958179165400462
Validation loss: 2.6104912072925965

Epoch: 6| Step: 9
Training loss: 3.066942068532335
Validation loss: 2.6014803833698106

Epoch: 6| Step: 10
Training loss: 2.455326137594671
Validation loss: 2.5588088905069206

Epoch: 6| Step: 11
Training loss: 2.916538853342544
Validation loss: 2.5447819837488117

Epoch: 6| Step: 12
Training loss: 2.8106381505548685
Validation loss: 2.5400854138036872

Epoch: 6| Step: 13
Training loss: 2.820402698712376
Validation loss: 2.5447782089780664

Epoch: 93| Step: 0
Training loss: 3.182890906887398
Validation loss: 2.554468021107416

Epoch: 6| Step: 1
Training loss: 2.258683297418456
Validation loss: 2.549275533046947

Epoch: 6| Step: 2
Training loss: 3.1787274385132385
Validation loss: 2.5473033666332756

Epoch: 6| Step: 3
Training loss: 3.1036440688886437
Validation loss: 2.542077862544114

Epoch: 6| Step: 4
Training loss: 3.15158370639246
Validation loss: 2.5387228148663645

Epoch: 6| Step: 5
Training loss: 2.934517015426996
Validation loss: 2.537836438319325

Epoch: 6| Step: 6
Training loss: 2.093145254680129
Validation loss: 2.5401355933720864

Epoch: 6| Step: 7
Training loss: 2.6804549561259314
Validation loss: 2.547556932991313

Epoch: 6| Step: 8
Training loss: 2.7031736865647993
Validation loss: 2.5462302403371955

Epoch: 6| Step: 9
Training loss: 2.8735244945240823
Validation loss: 2.5507392972188963

Epoch: 6| Step: 10
Training loss: 2.9904201457337485
Validation loss: 2.551165641313686

Epoch: 6| Step: 11
Training loss: 3.8227017348292813
Validation loss: 2.549909840855269

Epoch: 6| Step: 12
Training loss: 2.9559845174092314
Validation loss: 2.5425264836417463

Epoch: 6| Step: 13
Training loss: 2.1244557749651354
Validation loss: 2.5501347013409514

Epoch: 94| Step: 0
Training loss: 3.034603819779046
Validation loss: 2.540972165082906

Epoch: 6| Step: 1
Training loss: 2.837747295879426
Validation loss: 2.540488817616292

Epoch: 6| Step: 2
Training loss: 3.1749325001667725
Validation loss: 2.536811986056224

Epoch: 6| Step: 3
Training loss: 2.9303091788316333
Validation loss: 2.5461237479057104

Epoch: 6| Step: 4
Training loss: 2.9155165084818964
Validation loss: 2.5451348935328473

Epoch: 6| Step: 5
Training loss: 3.008299315058582
Validation loss: 2.5462905814201067

Epoch: 6| Step: 6
Training loss: 2.9414795236972293
Validation loss: 2.5448266801548525

Epoch: 6| Step: 7
Training loss: 3.143930697698916
Validation loss: 2.5549610487342025

Epoch: 6| Step: 8
Training loss: 2.754342119069564
Validation loss: 2.5591424144107644

Epoch: 6| Step: 9
Training loss: 2.1517095998927243
Validation loss: 2.5480677166479904

Epoch: 6| Step: 10
Training loss: 3.118365760633259
Validation loss: 2.554245108844048

Epoch: 6| Step: 11
Training loss: 2.8508631018368873
Validation loss: 2.550440850937499

Epoch: 6| Step: 12
Training loss: 2.9126206991046786
Validation loss: 2.547372818285877

Epoch: 6| Step: 13
Training loss: 2.5293102602807016
Validation loss: 2.5429338574065374

Epoch: 95| Step: 0
Training loss: 2.923787353068262
Validation loss: 2.5419822193050354

Epoch: 6| Step: 1
Training loss: 2.7153375190304865
Validation loss: 2.538528455382712

Epoch: 6| Step: 2
Training loss: 2.8270290211178724
Validation loss: 2.5316483277764306

Epoch: 6| Step: 3
Training loss: 3.2260428465086703
Validation loss: 2.5333299486103127

Epoch: 6| Step: 4
Training loss: 2.926618998522392
Validation loss: 2.532663662831818

Epoch: 6| Step: 5
Training loss: 2.1041883209423613
Validation loss: 2.528416308782648

Epoch: 6| Step: 6
Training loss: 2.8798063157439477
Validation loss: 2.5361240504685694

Epoch: 6| Step: 7
Training loss: 3.4875558609402533
Validation loss: 2.532942860731531

Epoch: 6| Step: 8
Training loss: 3.1759417541409354
Validation loss: 2.5331272495252573

Epoch: 6| Step: 9
Training loss: 2.8563049177570528
Validation loss: 2.5328033210453604

Epoch: 6| Step: 10
Training loss: 2.7257500342486547
Validation loss: 2.5349976357441735

Epoch: 6| Step: 11
Training loss: 2.342765703144799
Validation loss: 2.5330498283612752

Epoch: 6| Step: 12
Training loss: 3.281225440523788
Validation loss: 2.544687000271834

Epoch: 6| Step: 13
Training loss: 2.641965446864193
Validation loss: 2.5329908924269966

Epoch: 96| Step: 0
Training loss: 3.1697192453432397
Validation loss: 2.5448669070550003

Epoch: 6| Step: 1
Training loss: 2.861021474608995
Validation loss: 2.5501520808418303

Epoch: 6| Step: 2
Training loss: 3.1434882477834454
Validation loss: 2.548865408147941

Epoch: 6| Step: 3
Training loss: 2.821801297227563
Validation loss: 2.543787460936177

Epoch: 6| Step: 4
Training loss: 3.0110651041655405
Validation loss: 2.5438406523054082

Epoch: 6| Step: 5
Training loss: 3.0371244473098673
Validation loss: 2.5418789638924877

Epoch: 6| Step: 6
Training loss: 2.683702847013681
Validation loss: 2.545663747537826

Epoch: 6| Step: 7
Training loss: 2.3350357815861926
Validation loss: 2.5391662929829764

Epoch: 6| Step: 8
Training loss: 3.053403462544399
Validation loss: 2.538692587891002

Epoch: 6| Step: 9
Training loss: 2.3983239758989154
Validation loss: 2.5355561824188335

Epoch: 6| Step: 10
Training loss: 2.2038874828536184
Validation loss: 2.53256384628571

Epoch: 6| Step: 11
Training loss: 3.5332800507276687
Validation loss: 2.5304177983718907

Epoch: 6| Step: 12
Training loss: 2.710045923498475
Validation loss: 2.533621823923811

Epoch: 6| Step: 13
Training loss: 3.4263836147304008
Validation loss: 2.532510382634816

Epoch: 97| Step: 0
Training loss: 2.6167079201461267
Validation loss: 2.5275865663766153

Epoch: 6| Step: 1
Training loss: 2.3096590892028637
Validation loss: 2.530275959321661

Epoch: 6| Step: 2
Training loss: 2.9829839690107285
Validation loss: 2.530825060328811

Epoch: 6| Step: 3
Training loss: 3.2193229683826163
Validation loss: 2.5297521982948648

Epoch: 6| Step: 4
Training loss: 3.1315857728177665
Validation loss: 2.5314014905502047

Epoch: 6| Step: 5
Training loss: 2.416862764842984
Validation loss: 2.5300053420718323

Epoch: 6| Step: 6
Training loss: 2.7377272629137246
Validation loss: 2.5316401679347553

Epoch: 6| Step: 7
Training loss: 3.143420138031913
Validation loss: 2.531217931627602

Epoch: 6| Step: 8
Training loss: 2.9530479784412704
Validation loss: 2.528395631088511

Epoch: 6| Step: 9
Training loss: 2.7732564517821054
Validation loss: 2.529138079785089

Epoch: 6| Step: 10
Training loss: 3.412435951609983
Validation loss: 2.528399210293018

Epoch: 6| Step: 11
Training loss: 2.791061240825185
Validation loss: 2.5276688664931926

Epoch: 6| Step: 12
Training loss: 3.2253386090558624
Validation loss: 2.520730816810787

Epoch: 6| Step: 13
Training loss: 2.7867035279581454
Validation loss: 2.5177866553114794

Epoch: 98| Step: 0
Training loss: 3.120053458122628
Validation loss: 2.5221004008565817

Epoch: 6| Step: 1
Training loss: 2.8198275585072214
Validation loss: 2.531572408233474

Epoch: 6| Step: 2
Training loss: 2.5323627051355277
Validation loss: 2.539215011622954

Epoch: 6| Step: 3
Training loss: 3.007523322137856
Validation loss: 2.5566704713215236

Epoch: 6| Step: 4
Training loss: 2.952720170302931
Validation loss: 2.5654408536832944

Epoch: 6| Step: 5
Training loss: 2.729838242541916
Validation loss: 2.582400741774969

Epoch: 6| Step: 6
Training loss: 2.769864728082843
Validation loss: 2.594109619133609

Epoch: 6| Step: 7
Training loss: 2.6781822848341674
Validation loss: 2.6687344819535346

Epoch: 6| Step: 8
Training loss: 2.9956854948688254
Validation loss: 2.757308218985601

Epoch: 6| Step: 9
Training loss: 3.4050876138985315
Validation loss: 2.7699907509666497

Epoch: 6| Step: 10
Training loss: 2.700157432911293
Validation loss: 2.7030759004715277

Epoch: 6| Step: 11
Training loss: 3.1993051966724084
Validation loss: 2.643792196834169

Epoch: 6| Step: 12
Training loss: 2.611986418257916
Validation loss: 2.587383544427033

Epoch: 6| Step: 13
Training loss: 3.5379213762879074
Validation loss: 2.549469180819049

Epoch: 99| Step: 0
Training loss: 2.926870879113968
Validation loss: 2.521779943765969

Epoch: 6| Step: 1
Training loss: 2.6176048743107003
Validation loss: 2.5154009233702577

Epoch: 6| Step: 2
Training loss: 2.7550697411988736
Validation loss: 2.519905725790385

Epoch: 6| Step: 3
Training loss: 3.393813361319347
Validation loss: 2.522038622581098

Epoch: 6| Step: 4
Training loss: 2.334150466435996
Validation loss: 2.526779131769398

Epoch: 6| Step: 5
Training loss: 3.1724525264136947
Validation loss: 2.5325872792359223

Epoch: 6| Step: 6
Training loss: 3.0971269768713485
Validation loss: 2.5502026293034183

Epoch: 6| Step: 7
Training loss: 3.180694495603945
Validation loss: 2.5534965150145448

Epoch: 6| Step: 8
Training loss: 3.0106235595851727
Validation loss: 2.5542444805412945

Epoch: 6| Step: 9
Training loss: 2.726165217883269
Validation loss: 2.5468258339938754

Epoch: 6| Step: 10
Training loss: 2.819104472199816
Validation loss: 2.541528292203802

Epoch: 6| Step: 11
Training loss: 2.8948625176814278
Validation loss: 2.542339786202956

Epoch: 6| Step: 12
Training loss: 2.9749661868441817
Validation loss: 2.532893343317466

Epoch: 6| Step: 13
Training loss: 2.435372622450344
Validation loss: 2.5205414380232583

Epoch: 100| Step: 0
Training loss: 2.714917254653533
Validation loss: 2.5170096009388017

Epoch: 6| Step: 1
Training loss: 3.0580957623613525
Validation loss: 2.5125048556174017

Epoch: 6| Step: 2
Training loss: 3.1391254849758403
Validation loss: 2.5155054949480906

Epoch: 6| Step: 3
Training loss: 3.221634988512284
Validation loss: 2.522779355465526

Epoch: 6| Step: 4
Training loss: 2.777417145737083
Validation loss: 2.526455975880164

Epoch: 6| Step: 5
Training loss: 3.1828227414250576
Validation loss: 2.5311838189733726

Epoch: 6| Step: 6
Training loss: 2.3664883125511444
Validation loss: 2.550705412974932

Epoch: 6| Step: 7
Training loss: 2.8279241838341704
Validation loss: 2.565386441314849

Epoch: 6| Step: 8
Training loss: 2.417858410907581
Validation loss: 2.5578933114015445

Epoch: 6| Step: 9
Training loss: 2.6264106048469813
Validation loss: 2.58111244849595

Epoch: 6| Step: 10
Training loss: 2.9532709640679826
Validation loss: 2.5889210786378736

Epoch: 6| Step: 11
Training loss: 2.741699349190224
Validation loss: 2.581345219539161

Epoch: 6| Step: 12
Training loss: 3.3603758274788693
Validation loss: 2.5661110384721906

Epoch: 6| Step: 13
Training loss: 3.1433593082534634
Validation loss: 2.5638795836145705

Epoch: 101| Step: 0
Training loss: 3.3455792708668266
Validation loss: 2.5685650701372706

Epoch: 6| Step: 1
Training loss: 2.9177378367782603
Validation loss: 2.5561767524305807

Epoch: 6| Step: 2
Training loss: 2.6358254961188137
Validation loss: 2.544121180584758

Epoch: 6| Step: 3
Training loss: 3.010883774646765
Validation loss: 2.5515271379139532

Epoch: 6| Step: 4
Training loss: 2.9014925831725087
Validation loss: 2.5515674601239406

Epoch: 6| Step: 5
Training loss: 2.740795075414479
Validation loss: 2.550887632413741

Epoch: 6| Step: 6
Training loss: 2.9477973797031347
Validation loss: 2.5534007071201295

Epoch: 6| Step: 7
Training loss: 2.6141893209007403
Validation loss: 2.5480548625330233

Epoch: 6| Step: 8
Training loss: 2.7477499686910916
Validation loss: 2.552463403912111

Epoch: 6| Step: 9
Training loss: 3.303505399773181
Validation loss: 2.548578795268336

Epoch: 6| Step: 10
Training loss: 2.9880726859917615
Validation loss: 2.5527492944269325

Epoch: 6| Step: 11
Training loss: 2.8982851548785287
Validation loss: 2.548290138608776

Epoch: 6| Step: 12
Training loss: 2.14081143869044
Validation loss: 2.546906712194509

Epoch: 6| Step: 13
Training loss: 3.183212088893993
Validation loss: 2.5412967879416457

Epoch: 102| Step: 0
Training loss: 3.2148407835268817
Validation loss: 2.535037874001697

Epoch: 6| Step: 1
Training loss: 2.900517871261749
Validation loss: 2.525857551105587

Epoch: 6| Step: 2
Training loss: 3.218589112047759
Validation loss: 2.5197745068784783

Epoch: 6| Step: 3
Training loss: 3.5009784693160775
Validation loss: 2.519829908245596

Epoch: 6| Step: 4
Training loss: 3.3001134795126563
Validation loss: 2.5190292078249326

Epoch: 6| Step: 5
Training loss: 2.953276130805441
Validation loss: 2.515147856960025

Epoch: 6| Step: 6
Training loss: 2.924098183920811
Validation loss: 2.51617924123413

Epoch: 6| Step: 7
Training loss: 2.6736244586649933
Validation loss: 2.5220628440252093

Epoch: 6| Step: 8
Training loss: 2.673631592599163
Validation loss: 2.5131519216914886

Epoch: 6| Step: 9
Training loss: 2.6541730053245596
Validation loss: 2.5128197697248162

Epoch: 6| Step: 10
Training loss: 2.453975942958566
Validation loss: 2.5118072570211787

Epoch: 6| Step: 11
Training loss: 2.464862128187725
Validation loss: 2.5144229698074647

Epoch: 6| Step: 12
Training loss: 2.1780965050649104
Validation loss: 2.5119053872038855

Epoch: 6| Step: 13
Training loss: 3.115356213330588
Validation loss: 2.51339661198044

Epoch: 103| Step: 0
Training loss: 3.031600774545617
Validation loss: 2.5136443340422234

Epoch: 6| Step: 1
Training loss: 2.8636594264985704
Validation loss: 2.518471213102821

Epoch: 6| Step: 2
Training loss: 2.950128558962185
Validation loss: 2.516367033506765

Epoch: 6| Step: 3
Training loss: 2.3241785382550857
Validation loss: 2.5146631649042845

Epoch: 6| Step: 4
Training loss: 2.522766590983599
Validation loss: 2.526700681566805

Epoch: 6| Step: 5
Training loss: 3.040098665794601
Validation loss: 2.5310554981640685

Epoch: 6| Step: 6
Training loss: 2.9118244484605085
Validation loss: 2.5403771184460195

Epoch: 6| Step: 7
Training loss: 3.3834342120936705
Validation loss: 2.547165677486468

Epoch: 6| Step: 8
Training loss: 3.44590508518141
Validation loss: 2.548825684900137

Epoch: 6| Step: 9
Training loss: 2.7294186385998627
Validation loss: 2.551772589952914

Epoch: 6| Step: 10
Training loss: 2.633543643118287
Validation loss: 2.5477091091939035

Epoch: 6| Step: 11
Training loss: 2.856116767964597
Validation loss: 2.5569344865455923

Epoch: 6| Step: 12
Training loss: 2.7238330897367096
Validation loss: 2.5325361453415605

Epoch: 6| Step: 13
Training loss: 2.500797621325718
Validation loss: 2.5251330926323283

Epoch: 104| Step: 0
Training loss: 3.4463480044194488
Validation loss: 2.5304361430392235

Epoch: 6| Step: 1
Training loss: 3.0865400667641163
Validation loss: 2.521794341317565

Epoch: 6| Step: 2
Training loss: 3.209413189832573
Validation loss: 2.518523877468449

Epoch: 6| Step: 3
Training loss: 3.008471924468051
Validation loss: 2.528223932826222

Epoch: 6| Step: 4
Training loss: 2.192844510474726
Validation loss: 2.5318308510318888

Epoch: 6| Step: 5
Training loss: 2.6964968525623956
Validation loss: 2.545446990922925

Epoch: 6| Step: 6
Training loss: 2.4434858330584652
Validation loss: 2.5317121362642965

Epoch: 6| Step: 7
Training loss: 3.0277000168391472
Validation loss: 2.5204221650656287

Epoch: 6| Step: 8
Training loss: 2.836850358310134
Validation loss: 2.515001895864439

Epoch: 6| Step: 9
Training loss: 2.661184596686521
Validation loss: 2.51154969349334

Epoch: 6| Step: 10
Training loss: 2.4996440634069454
Validation loss: 2.513232142313029

Epoch: 6| Step: 11
Training loss: 3.1787694407058726
Validation loss: 2.507966942628989

Epoch: 6| Step: 12
Training loss: 2.7543461008722003
Validation loss: 2.504979795484529

Epoch: 6| Step: 13
Training loss: 3.0425272904161837
Validation loss: 2.503382259144379

Epoch: 105| Step: 0
Training loss: 2.3098207366215995
Validation loss: 2.5016998705651523

Epoch: 6| Step: 1
Training loss: 3.179145935577621
Validation loss: 2.5040036905727967

Epoch: 6| Step: 2
Training loss: 3.0950952552841127
Validation loss: 2.502322822168179

Epoch: 6| Step: 3
Training loss: 2.767889270508115
Validation loss: 2.4997765359167765

Epoch: 6| Step: 4
Training loss: 3.1342657433405243
Validation loss: 2.502122724368724

Epoch: 6| Step: 5
Training loss: 2.760441637226141
Validation loss: 2.501308963969853

Epoch: 6| Step: 6
Training loss: 3.1105369045543774
Validation loss: 2.5016164742493734

Epoch: 6| Step: 7
Training loss: 3.0043546542864927
Validation loss: 2.5074204606233668

Epoch: 6| Step: 8
Training loss: 2.8777359922199204
Validation loss: 2.5059794720239905

Epoch: 6| Step: 9
Training loss: 2.667586247516555
Validation loss: 2.5021101106551327

Epoch: 6| Step: 10
Training loss: 3.043209276989055
Validation loss: 2.502109347334383

Epoch: 6| Step: 11
Training loss: 2.9634104042057494
Validation loss: 2.502012188533775

Epoch: 6| Step: 12
Training loss: 2.33374870100021
Validation loss: 2.5034054624326947

Epoch: 6| Step: 13
Training loss: 2.6878444539603294
Validation loss: 2.505160221619151

Epoch: 106| Step: 0
Training loss: 3.2865578001097004
Validation loss: 2.513736374366938

Epoch: 6| Step: 1
Training loss: 2.951995310596163
Validation loss: 2.5329073765885624

Epoch: 6| Step: 2
Training loss: 3.17530449435908
Validation loss: 2.545324755025079

Epoch: 6| Step: 3
Training loss: 3.0540661582351083
Validation loss: 2.5357472069586176

Epoch: 6| Step: 4
Training loss: 2.1561089068704606
Validation loss: 2.530040426139222

Epoch: 6| Step: 5
Training loss: 3.0006932411308163
Validation loss: 2.5295100489171123

Epoch: 6| Step: 6
Training loss: 3.04134206912358
Validation loss: 2.5400881247105866

Epoch: 6| Step: 7
Training loss: 3.0273261088195675
Validation loss: 2.544486027552874

Epoch: 6| Step: 8
Training loss: 2.927676881679901
Validation loss: 2.5464888284392027

Epoch: 6| Step: 9
Training loss: 2.841717339415338
Validation loss: 2.529491097541196

Epoch: 6| Step: 10
Training loss: 3.0675713724975027
Validation loss: 2.5169195269666815

Epoch: 6| Step: 11
Training loss: 2.535570578081609
Validation loss: 2.5095538273142246

Epoch: 6| Step: 12
Training loss: 2.64328861764782
Validation loss: 2.5129851845230684

Epoch: 6| Step: 13
Training loss: 1.749280849920213
Validation loss: 2.5009570330598527

Epoch: 107| Step: 0
Training loss: 2.3640822385176987
Validation loss: 2.5031574562968064

Epoch: 6| Step: 1
Training loss: 2.9619625199526904
Validation loss: 2.502033694433024

Epoch: 6| Step: 2
Training loss: 3.2409336101319943
Validation loss: 2.4979360397539887

Epoch: 6| Step: 3
Training loss: 2.487440221633712
Validation loss: 2.4971469688986088

Epoch: 6| Step: 4
Training loss: 2.507743668131516
Validation loss: 2.4962005353600767

Epoch: 6| Step: 5
Training loss: 2.648959938215839
Validation loss: 2.4946281277943028

Epoch: 6| Step: 6
Training loss: 3.233040797053164
Validation loss: 2.495528675112176

Epoch: 6| Step: 7
Training loss: 3.137270830151383
Validation loss: 2.4914677976167727

Epoch: 6| Step: 8
Training loss: 3.063768085378109
Validation loss: 2.4920773665222464

Epoch: 6| Step: 9
Training loss: 2.8357115095906704
Validation loss: 2.495409358271944

Epoch: 6| Step: 10
Training loss: 2.904586808304675
Validation loss: 2.494090721639789

Epoch: 6| Step: 11
Training loss: 2.870775186939966
Validation loss: 2.494173577116408

Epoch: 6| Step: 12
Training loss: 2.783540960855744
Validation loss: 2.4959262656459473

Epoch: 6| Step: 13
Training loss: 3.0776675121540746
Validation loss: 2.4998484304073205

Epoch: 108| Step: 0
Training loss: 2.9209687974746172
Validation loss: 2.4981603642437498

Epoch: 6| Step: 1
Training loss: 3.463211173827187
Validation loss: 2.50625611430998

Epoch: 6| Step: 2
Training loss: 2.5081822012893125
Validation loss: 2.5255080482888257

Epoch: 6| Step: 3
Training loss: 3.0364944865897328
Validation loss: 2.532664517660741

Epoch: 6| Step: 4
Training loss: 2.6458276363121236
Validation loss: 2.552387144293126

Epoch: 6| Step: 5
Training loss: 2.250154701848514
Validation loss: 2.558463357989069

Epoch: 6| Step: 6
Training loss: 2.403299578810148
Validation loss: 2.5786065848507973

Epoch: 6| Step: 7
Training loss: 3.123810961534145
Validation loss: 2.59959254704661

Epoch: 6| Step: 8
Training loss: 3.2930295673876744
Validation loss: 2.6479220757387596

Epoch: 6| Step: 9
Training loss: 2.7656335345637646
Validation loss: 2.6116115924169705

Epoch: 6| Step: 10
Training loss: 3.1163757338025526
Validation loss: 2.571811103876848

Epoch: 6| Step: 11
Training loss: 2.9387558220887207
Validation loss: 2.5098110798321454

Epoch: 6| Step: 12
Training loss: 2.975780634680955
Validation loss: 2.5026370732454843

Epoch: 6| Step: 13
Training loss: 2.6534642590117055
Validation loss: 2.496103416679763

Epoch: 109| Step: 0
Training loss: 2.7673954873135003
Validation loss: 2.492910457137835

Epoch: 6| Step: 1
Training loss: 2.9352638986406463
Validation loss: 2.4973274610052107

Epoch: 6| Step: 2
Training loss: 3.0234704619589685
Validation loss: 2.512926594155604

Epoch: 6| Step: 3
Training loss: 2.6540345770416804
Validation loss: 2.516967342434504

Epoch: 6| Step: 4
Training loss: 3.3728492382928903
Validation loss: 2.5341060036784064

Epoch: 6| Step: 5
Training loss: 2.8215445154934873
Validation loss: 2.531164073409823

Epoch: 6| Step: 6
Training loss: 3.2791258703179835
Validation loss: 2.5303733134956983

Epoch: 6| Step: 7
Training loss: 3.057061173146102
Validation loss: 2.5298422977244064

Epoch: 6| Step: 8
Training loss: 2.926218323599277
Validation loss: 2.522330198102501

Epoch: 6| Step: 9
Training loss: 2.691837802166733
Validation loss: 2.5182197379658224

Epoch: 6| Step: 10
Training loss: 2.821475647711219
Validation loss: 2.512954597975334

Epoch: 6| Step: 11
Training loss: 2.7170711025163015
Validation loss: 2.5121770847671945

Epoch: 6| Step: 12
Training loss: 2.690393620022535
Validation loss: 2.498932357180008

Epoch: 6| Step: 13
Training loss: 2.9337764434207836
Validation loss: 2.5062356880063095

Epoch: 110| Step: 0
Training loss: 2.4987155475693497
Validation loss: 2.5073901323504395

Epoch: 6| Step: 1
Training loss: 3.2934071892656456
Validation loss: 2.503087583866004

Epoch: 6| Step: 2
Training loss: 2.5165751303726864
Validation loss: 2.5007873382336894

Epoch: 6| Step: 3
Training loss: 3.2088475166247354
Validation loss: 2.506572387253121

Epoch: 6| Step: 4
Training loss: 3.0810390562697783
Validation loss: 2.501909970226598

Epoch: 6| Step: 5
Training loss: 2.873945457445323
Validation loss: 2.5060445192344956

Epoch: 6| Step: 6
Training loss: 3.1284891105268464
Validation loss: 2.509121307677878

Epoch: 6| Step: 7
Training loss: 2.789862339082829
Validation loss: 2.5082796341728373

Epoch: 6| Step: 8
Training loss: 2.445556823419711
Validation loss: 2.5061921558666267

Epoch: 6| Step: 9
Training loss: 3.2869025089950106
Validation loss: 2.505562502679323

Epoch: 6| Step: 10
Training loss: 1.9956246438819096
Validation loss: 2.5049344505065276

Epoch: 6| Step: 11
Training loss: 2.9026066082179156
Validation loss: 2.507015718757677

Epoch: 6| Step: 12
Training loss: 3.039320907786042
Validation loss: 2.513378239844632

Epoch: 6| Step: 13
Training loss: 2.641738927516727
Validation loss: 2.513240491467647

Epoch: 111| Step: 0
Training loss: 2.7559076490168657
Validation loss: 2.5237680920447088

Epoch: 6| Step: 1
Training loss: 2.66728467535201
Validation loss: 2.5198695096993577

Epoch: 6| Step: 2
Training loss: 3.114996041774531
Validation loss: 2.529832940342158

Epoch: 6| Step: 3
Training loss: 2.6760154900038375
Validation loss: 2.5271299449608553

Epoch: 6| Step: 4
Training loss: 2.3381343450005168
Validation loss: 2.5390410886355537

Epoch: 6| Step: 5
Training loss: 3.118994932169954
Validation loss: 2.5511185899239965

Epoch: 6| Step: 6
Training loss: 3.0940610170567915
Validation loss: 2.548508013435463

Epoch: 6| Step: 7
Training loss: 2.986782041972189
Validation loss: 2.564551272015721

Epoch: 6| Step: 8
Training loss: 2.588604338492974
Validation loss: 2.556783339709568

Epoch: 6| Step: 9
Training loss: 2.8585273862163754
Validation loss: 2.5470656195222183

Epoch: 6| Step: 10
Training loss: 2.8430885971063393
Validation loss: 2.5316711140304853

Epoch: 6| Step: 11
Training loss: 3.154723147473805
Validation loss: 2.519734682132999

Epoch: 6| Step: 12
Training loss: 2.9467907340338892
Validation loss: 2.4948465647516604

Epoch: 6| Step: 13
Training loss: 2.632476422964156
Validation loss: 2.4972893293785408

Epoch: 112| Step: 0
Training loss: 3.115467486135191
Validation loss: 2.4898694890338775

Epoch: 6| Step: 1
Training loss: 2.722398086195639
Validation loss: 2.4820546423925527

Epoch: 6| Step: 2
Training loss: 2.176782346906374
Validation loss: 2.482623772365142

Epoch: 6| Step: 3
Training loss: 2.8385628142429455
Validation loss: 2.482726421247785

Epoch: 6| Step: 4
Training loss: 2.909455367308939
Validation loss: 2.4824319666953807

Epoch: 6| Step: 5
Training loss: 2.898971796272937
Validation loss: 2.4854968223653042

Epoch: 6| Step: 6
Training loss: 2.5331948426522275
Validation loss: 2.4748703251114668

Epoch: 6| Step: 7
Training loss: 2.718915210834287
Validation loss: 2.477867057446038

Epoch: 6| Step: 8
Training loss: 3.206530737530445
Validation loss: 2.478551153467186

Epoch: 6| Step: 9
Training loss: 3.2056127796174447
Validation loss: 2.4770337701235774

Epoch: 6| Step: 10
Training loss: 2.875610120967385
Validation loss: 2.4750751783086793

Epoch: 6| Step: 11
Training loss: 3.0059897708680707
Validation loss: 2.4792516581263855

Epoch: 6| Step: 12
Training loss: 2.7968969930284913
Validation loss: 2.4749293875666125

Epoch: 6| Step: 13
Training loss: 2.563140230912611
Validation loss: 2.4734825463451937

Epoch: 113| Step: 0
Training loss: 2.879342655557479
Validation loss: 2.4762186360521548

Epoch: 6| Step: 1
Training loss: 2.670557957902909
Validation loss: 2.470311001694451

Epoch: 6| Step: 2
Training loss: 3.0987659212959846
Validation loss: 2.471522381929223

Epoch: 6| Step: 3
Training loss: 3.005862389080279
Validation loss: 2.476702360778925

Epoch: 6| Step: 4
Training loss: 2.211565878707722
Validation loss: 2.4747072279122766

Epoch: 6| Step: 5
Training loss: 2.827558260451508
Validation loss: 2.486759446204184

Epoch: 6| Step: 6
Training loss: 3.108265434389431
Validation loss: 2.4985839114596504

Epoch: 6| Step: 7
Training loss: 2.66352521115261
Validation loss: 2.5226503490154046

Epoch: 6| Step: 8
Training loss: 2.7613575225659646
Validation loss: 2.5363944858967256

Epoch: 6| Step: 9
Training loss: 2.962851678118282
Validation loss: 2.5354987933342126

Epoch: 6| Step: 10
Training loss: 3.0408903376668044
Validation loss: 2.53369825778253

Epoch: 6| Step: 11
Training loss: 2.3691840989416026
Validation loss: 2.5047750237503514

Epoch: 6| Step: 12
Training loss: 3.2996915384104053
Validation loss: 2.4966753659600007

Epoch: 6| Step: 13
Training loss: 2.804691240313488
Validation loss: 2.4788625387057057

Epoch: 114| Step: 0
Training loss: 2.8526167919378005
Validation loss: 2.4677570880615303

Epoch: 6| Step: 1
Training loss: 2.720747466044362
Validation loss: 2.465167316602444

Epoch: 6| Step: 2
Training loss: 3.356657410513861
Validation loss: 2.465394660651167

Epoch: 6| Step: 3
Training loss: 2.587325815428568
Validation loss: 2.4680881134780073

Epoch: 6| Step: 4
Training loss: 2.2505691656143045
Validation loss: 2.467182287315252

Epoch: 6| Step: 5
Training loss: 2.9197396211933704
Validation loss: 2.4695224874792534

Epoch: 6| Step: 6
Training loss: 3.1595963971210304
Validation loss: 2.467584446215284

Epoch: 6| Step: 7
Training loss: 1.7706187697926097
Validation loss: 2.4664244856201805

Epoch: 6| Step: 8
Training loss: 3.0876957387306776
Validation loss: 2.465072156076392

Epoch: 6| Step: 9
Training loss: 3.4808098725403567
Validation loss: 2.4608905652986413

Epoch: 6| Step: 10
Training loss: 2.9326680801757035
Validation loss: 2.461305398131087

Epoch: 6| Step: 11
Training loss: 2.5682678438419155
Validation loss: 2.464203200660181

Epoch: 6| Step: 12
Training loss: 2.9071771926967798
Validation loss: 2.469018945651409

Epoch: 6| Step: 13
Training loss: 2.7572965058179895
Validation loss: 2.457565916430437

Epoch: 115| Step: 0
Training loss: 3.114663998038747
Validation loss: 2.4554177871755862

Epoch: 6| Step: 1
Training loss: 2.241960573841709
Validation loss: 2.4582081843355548

Epoch: 6| Step: 2
Training loss: 2.546506515713304
Validation loss: 2.4656595430096715

Epoch: 6| Step: 3
Training loss: 3.045615694034543
Validation loss: 2.4619818889927116

Epoch: 6| Step: 4
Training loss: 2.388226171974639
Validation loss: 2.4640092046843014

Epoch: 6| Step: 5
Training loss: 3.5890025750398364
Validation loss: 2.459550314029295

Epoch: 6| Step: 6
Training loss: 2.4829110684763567
Validation loss: 2.461296650946634

Epoch: 6| Step: 7
Training loss: 3.041569085493712
Validation loss: 2.4713151833749625

Epoch: 6| Step: 8
Training loss: 2.8427454253493623
Validation loss: 2.4733708259283285

Epoch: 6| Step: 9
Training loss: 2.762888788680819
Validation loss: 2.487616925813405

Epoch: 6| Step: 10
Training loss: 2.6930270470621895
Validation loss: 2.500140933709659

Epoch: 6| Step: 11
Training loss: 2.8651796217395415
Validation loss: 2.505562331808311

Epoch: 6| Step: 12
Training loss: 3.332591037751609
Validation loss: 2.5373153796770525

Epoch: 6| Step: 13
Training loss: 2.070235916736555
Validation loss: 2.5317109029032796

Epoch: 116| Step: 0
Training loss: 2.3754450732356394
Validation loss: 2.51231499757467

Epoch: 6| Step: 1
Training loss: 2.415402531218634
Validation loss: 2.48433897694399

Epoch: 6| Step: 2
Training loss: 2.54535091176798
Validation loss: 2.4700799814672716

Epoch: 6| Step: 3
Training loss: 3.368366645699853
Validation loss: 2.4558943539141698

Epoch: 6| Step: 4
Training loss: 2.516071256304753
Validation loss: 2.4544148400623333

Epoch: 6| Step: 5
Training loss: 2.770870944654614
Validation loss: 2.4561678395509103

Epoch: 6| Step: 6
Training loss: 3.2329688217401276
Validation loss: 2.4598763720793824

Epoch: 6| Step: 7
Training loss: 3.1918820945073794
Validation loss: 2.4608740576219756

Epoch: 6| Step: 8
Training loss: 2.7849084174064083
Validation loss: 2.4576178528568056

Epoch: 6| Step: 9
Training loss: 2.7823285358308834
Validation loss: 2.4586853983542825

Epoch: 6| Step: 10
Training loss: 3.3455665858923878
Validation loss: 2.4567562096514384

Epoch: 6| Step: 11
Training loss: 2.9425067843842707
Validation loss: 2.462136752272244

Epoch: 6| Step: 12
Training loss: 2.6297507212173947
Validation loss: 2.4612549862992648

Epoch: 6| Step: 13
Training loss: 2.660060079799573
Validation loss: 2.455673166155715

Epoch: 117| Step: 0
Training loss: 3.2363206107052926
Validation loss: 2.4689140166688746

Epoch: 6| Step: 1
Training loss: 3.0306781347348424
Validation loss: 2.4721249572041994

Epoch: 6| Step: 2
Training loss: 3.0368722902840544
Validation loss: 2.472741464885945

Epoch: 6| Step: 3
Training loss: 2.891156616813897
Validation loss: 2.4694920467369417

Epoch: 6| Step: 4
Training loss: 2.2879987204288024
Validation loss: 2.470612790591005

Epoch: 6| Step: 5
Training loss: 2.6825215559037328
Validation loss: 2.4812914786717046

Epoch: 6| Step: 6
Training loss: 2.4539727368072297
Validation loss: 2.4822759787044957

Epoch: 6| Step: 7
Training loss: 2.566259092527578
Validation loss: 2.4853978269163988

Epoch: 6| Step: 8
Training loss: 3.0472812479570033
Validation loss: 2.474994523684651

Epoch: 6| Step: 9
Training loss: 2.98061721451987
Validation loss: 2.4728936524945317

Epoch: 6| Step: 10
Training loss: 2.980388755274781
Validation loss: 2.48607150313021

Epoch: 6| Step: 11
Training loss: 2.64331784154418
Validation loss: 2.4795680918459904

Epoch: 6| Step: 12
Training loss: 2.546154364923366
Validation loss: 2.4776528692491473

Epoch: 6| Step: 13
Training loss: 2.995961809299438
Validation loss: 2.4623252184063458

Epoch: 118| Step: 0
Training loss: 2.300357280845163
Validation loss: 2.4610360178749704

Epoch: 6| Step: 1
Training loss: 2.9733699788913035
Validation loss: 2.476716158655901

Epoch: 6| Step: 2
Training loss: 2.1013964052045586
Validation loss: 2.4765688134382056

Epoch: 6| Step: 3
Training loss: 3.5546185497262033
Validation loss: 2.470269503616247

Epoch: 6| Step: 4
Training loss: 2.3114081202091823
Validation loss: 2.4676328815655957

Epoch: 6| Step: 5
Training loss: 3.0867047478762077
Validation loss: 2.481171860511526

Epoch: 6| Step: 6
Training loss: 3.3016419862854645
Validation loss: 2.4669783364420406

Epoch: 6| Step: 7
Training loss: 2.469956308511264
Validation loss: 2.4688442820226064

Epoch: 6| Step: 8
Training loss: 3.0205280193512585
Validation loss: 2.463853015922064

Epoch: 6| Step: 9
Training loss: 2.471226765625189
Validation loss: 2.46685573584399

Epoch: 6| Step: 10
Training loss: 2.8805854279176897
Validation loss: 2.466347579083859

Epoch: 6| Step: 11
Training loss: 2.7858892602429326
Validation loss: 2.4688479382159354

Epoch: 6| Step: 12
Training loss: 2.9267424976659706
Validation loss: 2.469114993907649

Epoch: 6| Step: 13
Training loss: 2.895061820099824
Validation loss: 2.4749893870643542

Epoch: 119| Step: 0
Training loss: 2.9270753328659755
Validation loss: 2.4744227344700738

Epoch: 6| Step: 1
Training loss: 3.0001339882493134
Validation loss: 2.468012556177901

Epoch: 6| Step: 2
Training loss: 2.7542984054230075
Validation loss: 2.4656532858567064

Epoch: 6| Step: 3
Training loss: 2.8850388445957984
Validation loss: 2.464723057962078

Epoch: 6| Step: 4
Training loss: 2.552303403331722
Validation loss: 2.4763831477412626

Epoch: 6| Step: 5
Training loss: 2.885430364656584
Validation loss: 2.4670487660284466

Epoch: 6| Step: 6
Training loss: 2.448069520330926
Validation loss: 2.4692094841777763

Epoch: 6| Step: 7
Training loss: 2.995129127839339
Validation loss: 2.4708304351052006

Epoch: 6| Step: 8
Training loss: 2.7747307139839235
Validation loss: 2.483106794455878

Epoch: 6| Step: 9
Training loss: 2.5182460612085706
Validation loss: 2.5069830284966828

Epoch: 6| Step: 10
Training loss: 3.09413684006286
Validation loss: 2.4946840002569326

Epoch: 6| Step: 11
Training loss: 3.3055464978632707
Validation loss: 2.511513349762815

Epoch: 6| Step: 12
Training loss: 2.139337305510865
Validation loss: 2.479561000273743

Epoch: 6| Step: 13
Training loss: 3.082829631868024
Validation loss: 2.4678098644239865

Epoch: 120| Step: 0
Training loss: 3.0204939202113437
Validation loss: 2.4603593732220683

Epoch: 6| Step: 1
Training loss: 2.7617401597030806
Validation loss: 2.4604314572544586

Epoch: 6| Step: 2
Training loss: 2.6422232582023235
Validation loss: 2.4524731036030105

Epoch: 6| Step: 3
Training loss: 2.73566471746459
Validation loss: 2.45392065950574

Epoch: 6| Step: 4
Training loss: 2.7110272923090935
Validation loss: 2.453873315830246

Epoch: 6| Step: 5
Training loss: 2.572904537857029
Validation loss: 2.461621250862244

Epoch: 6| Step: 6
Training loss: 2.643897923148196
Validation loss: 2.4613310551790426

Epoch: 6| Step: 7
Training loss: 3.1129061330532735
Validation loss: 2.4600547685319847

Epoch: 6| Step: 8
Training loss: 2.9806167345818277
Validation loss: 2.4574311257057744

Epoch: 6| Step: 9
Training loss: 2.6382347891311317
Validation loss: 2.457408271784879

Epoch: 6| Step: 10
Training loss: 2.694941132987159
Validation loss: 2.4575701913066945

Epoch: 6| Step: 11
Training loss: 2.546037032931588
Validation loss: 2.4473157983497384

Epoch: 6| Step: 12
Training loss: 3.058316857677295
Validation loss: 2.456577708279885

Epoch: 6| Step: 13
Training loss: 3.223282224952816
Validation loss: 2.454622749778062

Epoch: 121| Step: 0
Training loss: 3.0829887884965
Validation loss: 2.4635597104681324

Epoch: 6| Step: 1
Training loss: 2.794969474339173
Validation loss: 2.4713837259093547

Epoch: 6| Step: 2
Training loss: 2.4496042048661755
Validation loss: 2.462611092239013

Epoch: 6| Step: 3
Training loss: 3.011299786945888
Validation loss: 2.460212260268875

Epoch: 6| Step: 4
Training loss: 2.993621562201579
Validation loss: 2.451235623918339

Epoch: 6| Step: 5
Training loss: 2.8091082996908625
Validation loss: 2.458030847537351

Epoch: 6| Step: 6
Training loss: 2.7607830356292244
Validation loss: 2.4650984207839675

Epoch: 6| Step: 7
Training loss: 2.230239455534364
Validation loss: 2.491700483748334

Epoch: 6| Step: 8
Training loss: 2.749580351281682
Validation loss: 2.517341695014514

Epoch: 6| Step: 9
Training loss: 2.7807992291285912
Validation loss: 2.545043152656186

Epoch: 6| Step: 10
Training loss: 2.781813318018251
Validation loss: 2.5113461368178696

Epoch: 6| Step: 11
Training loss: 3.1500945546324477
Validation loss: 2.508427770857316

Epoch: 6| Step: 12
Training loss: 2.9370998353494997
Validation loss: 2.4894309429523442

Epoch: 6| Step: 13
Training loss: 3.2769715526325056
Validation loss: 2.456303488113432

Epoch: 122| Step: 0
Training loss: 2.5818735325554485
Validation loss: 2.4515035441078403

Epoch: 6| Step: 1
Training loss: 2.8893642666118335
Validation loss: 2.452786177350286

Epoch: 6| Step: 2
Training loss: 2.794849024262386
Validation loss: 2.4596850907643026

Epoch: 6| Step: 3
Training loss: 2.7873954171717226
Validation loss: 2.4707406957453686

Epoch: 6| Step: 4
Training loss: 3.006855760479883
Validation loss: 2.4986677332081837

Epoch: 6| Step: 5
Training loss: 2.851501965860047
Validation loss: 2.4850322338780204

Epoch: 6| Step: 6
Training loss: 3.285576864887353
Validation loss: 2.4732848822769116

Epoch: 6| Step: 7
Training loss: 2.4673931400925713
Validation loss: 2.471284253290432

Epoch: 6| Step: 8
Training loss: 2.8413531923833735
Validation loss: 2.469404698419874

Epoch: 6| Step: 9
Training loss: 2.4177413611653638
Validation loss: 2.471810757802643

Epoch: 6| Step: 10
Training loss: 2.7621688368100226
Validation loss: 2.47672627567004

Epoch: 6| Step: 11
Training loss: 3.028329445124894
Validation loss: 2.484897850794214

Epoch: 6| Step: 12
Training loss: 2.9373340965659036
Validation loss: 2.5026668567921058

Epoch: 6| Step: 13
Training loss: 3.0856479170892626
Validation loss: 2.5498712458508788

Epoch: 123| Step: 0
Training loss: 3.522176783442768
Validation loss: 2.596525588823326

Epoch: 6| Step: 1
Training loss: 2.713184491823201
Validation loss: 2.600777965935614

Epoch: 6| Step: 2
Training loss: 3.6173472688460167
Validation loss: 2.6300758074197166

Epoch: 6| Step: 3
Training loss: 2.3062066712483196
Validation loss: 2.626734389627272

Epoch: 6| Step: 4
Training loss: 2.8071396502854706
Validation loss: 2.6007035636598674

Epoch: 6| Step: 5
Training loss: 2.6631525448903517
Validation loss: 2.5510772315764587

Epoch: 6| Step: 6
Training loss: 3.1548446699255135
Validation loss: 2.511547163076222

Epoch: 6| Step: 7
Training loss: 2.5005948312737254
Validation loss: 2.508336780594649

Epoch: 6| Step: 8
Training loss: 2.9393097193008706
Validation loss: 2.480607453178374

Epoch: 6| Step: 9
Training loss: 2.5936768303167743
Validation loss: 2.4774259324562222

Epoch: 6| Step: 10
Training loss: 2.6682000122820613
Validation loss: 2.4778649395864023

Epoch: 6| Step: 11
Training loss: 2.531249434859601
Validation loss: 2.473293900094886

Epoch: 6| Step: 12
Training loss: 3.0017016670972474
Validation loss: 2.4710806077747582

Epoch: 6| Step: 13
Training loss: 2.8028468305509997
Validation loss: 2.4646648638947624

Epoch: 124| Step: 0
Training loss: 3.084581758164749
Validation loss: 2.463267319252202

Epoch: 6| Step: 1
Training loss: 2.502960073916944
Validation loss: 2.462852356789632

Epoch: 6| Step: 2
Training loss: 2.6881279322686487
Validation loss: 2.4599379564905557

Epoch: 6| Step: 3
Training loss: 2.571023396329539
Validation loss: 2.464211639987432

Epoch: 6| Step: 4
Training loss: 3.024282726654733
Validation loss: 2.4673792433245603

Epoch: 6| Step: 5
Training loss: 2.693482681782411
Validation loss: 2.4732060071005977

Epoch: 6| Step: 6
Training loss: 3.0393434997721025
Validation loss: 2.488739579844478

Epoch: 6| Step: 7
Training loss: 2.3823895188420647
Validation loss: 2.5201273556465247

Epoch: 6| Step: 8
Training loss: 2.81620087317884
Validation loss: 2.537546624834762

Epoch: 6| Step: 9
Training loss: 2.3434089921193233
Validation loss: 2.5302704648070367

Epoch: 6| Step: 10
Training loss: 2.9776061623814445
Validation loss: 2.5078241097990994

Epoch: 6| Step: 11
Training loss: 3.384863956033461
Validation loss: 2.4763454358822368

Epoch: 6| Step: 12
Training loss: 3.1796269141571347
Validation loss: 2.4650471786050723

Epoch: 6| Step: 13
Training loss: 2.190151133961651
Validation loss: 2.4600027762153167

Epoch: 125| Step: 0
Training loss: 2.9348073752520767
Validation loss: 2.4600757814905836

Epoch: 6| Step: 1
Training loss: 2.1744260008626504
Validation loss: 2.460020165121082

Epoch: 6| Step: 2
Training loss: 2.756146497794242
Validation loss: 2.456927818707487

Epoch: 6| Step: 3
Training loss: 3.302257320661919
Validation loss: 2.4658086369726515

Epoch: 6| Step: 4
Training loss: 3.0482636246202697
Validation loss: 2.453569234976012

Epoch: 6| Step: 5
Training loss: 2.5745903059574884
Validation loss: 2.45173283954457

Epoch: 6| Step: 6
Training loss: 3.1573446660557978
Validation loss: 2.4517562242236943

Epoch: 6| Step: 7
Training loss: 3.140443559406361
Validation loss: 2.445527975493515

Epoch: 6| Step: 8
Training loss: 1.9963839743605176
Validation loss: 2.453132964320435

Epoch: 6| Step: 9
Training loss: 2.8526624256532505
Validation loss: 2.4461636165995415

Epoch: 6| Step: 10
Training loss: 2.6909382140495675
Validation loss: 2.44251412824996

Epoch: 6| Step: 11
Training loss: 2.74802457777357
Validation loss: 2.450965754038791

Epoch: 6| Step: 12
Training loss: 2.700442532195407
Validation loss: 2.4399230510188357

Epoch: 6| Step: 13
Training loss: 2.782826523314435
Validation loss: 2.4456410390933208

Epoch: 126| Step: 0
Training loss: 3.0456579663210612
Validation loss: 2.458112069196343

Epoch: 6| Step: 1
Training loss: 3.03432756695274
Validation loss: 2.4330561453312045

Epoch: 6| Step: 2
Training loss: 2.3189310913112533
Validation loss: 2.442493394543051

Epoch: 6| Step: 3
Training loss: 2.274615949136129
Validation loss: 2.4403197115971604

Epoch: 6| Step: 4
Training loss: 2.5567146681051454
Validation loss: 2.436741784877706

Epoch: 6| Step: 5
Training loss: 3.3051748795634204
Validation loss: 2.4398676025567108

Epoch: 6| Step: 6
Training loss: 2.7228879460573965
Validation loss: 2.43668143592633

Epoch: 6| Step: 7
Training loss: 2.6938436292763766
Validation loss: 2.4531758526976675

Epoch: 6| Step: 8
Training loss: 2.7147378365693564
Validation loss: 2.451605936859803

Epoch: 6| Step: 9
Training loss: 2.953579983655197
Validation loss: 2.4480371634508695

Epoch: 6| Step: 10
Training loss: 2.86303077008084
Validation loss: 2.459364526866586

Epoch: 6| Step: 11
Training loss: 2.7511859417346796
Validation loss: 2.460998255221758

Epoch: 6| Step: 12
Training loss: 2.714608732520897
Validation loss: 2.459842746866453

Epoch: 6| Step: 13
Training loss: 3.1775555035705487
Validation loss: 2.4416640929871027

Epoch: 127| Step: 0
Training loss: 2.9572166878570854
Validation loss: 2.4523246054547654

Epoch: 6| Step: 1
Training loss: 3.1069657849999177
Validation loss: 2.460779386885103

Epoch: 6| Step: 2
Training loss: 2.3733786017497613
Validation loss: 2.4565653741515434

Epoch: 6| Step: 3
Training loss: 3.1085148680774544
Validation loss: 2.455556633756836

Epoch: 6| Step: 4
Training loss: 2.9898254792687107
Validation loss: 2.4479457423242583

Epoch: 6| Step: 5
Training loss: 2.7518545313136067
Validation loss: 2.4514902474600913

Epoch: 6| Step: 6
Training loss: 2.6956993820502744
Validation loss: 2.4503680506272554

Epoch: 6| Step: 7
Training loss: 3.367546327947698
Validation loss: 2.4647671074755895

Epoch: 6| Step: 8
Training loss: 2.6660106169824758
Validation loss: 2.4644872224468464

Epoch: 6| Step: 9
Training loss: 3.0792342767446423
Validation loss: 2.4867219205708295

Epoch: 6| Step: 10
Training loss: 2.6019994237079613
Validation loss: 2.5151993932820176

Epoch: 6| Step: 11
Training loss: 2.464578218258612
Validation loss: 2.555830341471917

Epoch: 6| Step: 12
Training loss: 2.090655074879728
Validation loss: 2.611459464527094

Epoch: 6| Step: 13
Training loss: 2.1575911400773964
Validation loss: 2.6380200324042993

Epoch: 128| Step: 0
Training loss: 3.5159369436258006
Validation loss: 2.685453806885643

Epoch: 6| Step: 1
Training loss: 2.943696324857324
Validation loss: 2.61039524127683

Epoch: 6| Step: 2
Training loss: 2.928475172341738
Validation loss: 2.547649456795139

Epoch: 6| Step: 3
Training loss: 2.6731498309327373
Validation loss: 2.4848556131064172

Epoch: 6| Step: 4
Training loss: 2.996706903574351
Validation loss: 2.4502900170846833

Epoch: 6| Step: 5
Training loss: 2.8477617409087084
Validation loss: 2.4534463833254265

Epoch: 6| Step: 6
Training loss: 2.332765192164111
Validation loss: 2.4622742558529516

Epoch: 6| Step: 7
Training loss: 3.1209091876750987
Validation loss: 2.465166306294798

Epoch: 6| Step: 8
Training loss: 2.5720661523359363
Validation loss: 2.471462607377781

Epoch: 6| Step: 9
Training loss: 2.8127861725069137
Validation loss: 2.465580613133308

Epoch: 6| Step: 10
Training loss: 2.6877980621414923
Validation loss: 2.4603628836438522

Epoch: 6| Step: 11
Training loss: 2.58050501235212
Validation loss: 2.4575924084428107

Epoch: 6| Step: 12
Training loss: 2.8846552058674675
Validation loss: 2.458404077673362

Epoch: 6| Step: 13
Training loss: 2.447274100737268
Validation loss: 2.460091398325199

Epoch: 129| Step: 0
Training loss: 2.4715226453962633
Validation loss: 2.460081348373069

Epoch: 6| Step: 1
Training loss: 3.054327980211943
Validation loss: 2.4737865691906142

Epoch: 6| Step: 2
Training loss: 2.907891578972399
Validation loss: 2.478554326790611

Epoch: 6| Step: 3
Training loss: 2.6414514636480355
Validation loss: 2.477994437115155

Epoch: 6| Step: 4
Training loss: 2.8291553285471753
Validation loss: 2.4723855567221062

Epoch: 6| Step: 5
Training loss: 2.3532337827221967
Validation loss: 2.474828909699586

Epoch: 6| Step: 6
Training loss: 3.0635585901613767
Validation loss: 2.48501725865191

Epoch: 6| Step: 7
Training loss: 3.283704584371791
Validation loss: 2.4637281693304214

Epoch: 6| Step: 8
Training loss: 2.4292490278341985
Validation loss: 2.473215812993137

Epoch: 6| Step: 9
Training loss: 2.510196111548382
Validation loss: 2.4816695574224448

Epoch: 6| Step: 10
Training loss: 2.81975027804843
Validation loss: 2.4828121650804147

Epoch: 6| Step: 11
Training loss: 3.0291715752213353
Validation loss: 2.474784890368153

Epoch: 6| Step: 12
Training loss: 2.3763753020968754
Validation loss: 2.4817788961395095

Epoch: 6| Step: 13
Training loss: 3.1416898981208488
Validation loss: 2.477578773927077

Epoch: 130| Step: 0
Training loss: 2.6955093090793163
Validation loss: 2.474883359412635

Epoch: 6| Step: 1
Training loss: 2.6945751121359796
Validation loss: 2.4677293775001545

Epoch: 6| Step: 2
Training loss: 3.20945820760906
Validation loss: 2.461568529279008

Epoch: 6| Step: 3
Training loss: 3.155143921678361
Validation loss: 2.4720269248141364

Epoch: 6| Step: 4
Training loss: 2.720124259101932
Validation loss: 2.469869540228686

Epoch: 6| Step: 5
Training loss: 2.669445159926127
Validation loss: 2.470316233140512

Epoch: 6| Step: 6
Training loss: 3.0182594295604974
Validation loss: 2.481463363176372

Epoch: 6| Step: 7
Training loss: 2.462188402784085
Validation loss: 2.4781245672031114

Epoch: 6| Step: 8
Training loss: 2.931311398902202
Validation loss: 2.4846084257014915

Epoch: 6| Step: 9
Training loss: 2.8637608312554335
Validation loss: 2.493382374787502

Epoch: 6| Step: 10
Training loss: 1.9721130227436503
Validation loss: 2.4939684670363653

Epoch: 6| Step: 11
Training loss: 2.138958470202205
Validation loss: 2.492311745940272

Epoch: 6| Step: 12
Training loss: 3.390015156129698
Validation loss: 2.489307982672976

Epoch: 6| Step: 13
Training loss: 2.5813814808608675
Validation loss: 2.499770551837481

Epoch: 131| Step: 0
Training loss: 2.5201840050442756
Validation loss: 2.4948023581063254

Epoch: 6| Step: 1
Training loss: 2.696756611830164
Validation loss: 2.502159189129021

Epoch: 6| Step: 2
Training loss: 2.498968102161882
Validation loss: 2.4917604312778985

Epoch: 6| Step: 3
Training loss: 2.6649895003292667
Validation loss: 2.499961276421026

Epoch: 6| Step: 4
Training loss: 2.764532013344685
Validation loss: 2.490808824188268

Epoch: 6| Step: 5
Training loss: 2.764188404137702
Validation loss: 2.5109594523610337

Epoch: 6| Step: 6
Training loss: 3.276692449624137
Validation loss: 2.5186867750802597

Epoch: 6| Step: 7
Training loss: 3.116512521886005
Validation loss: 2.5505569963209327

Epoch: 6| Step: 8
Training loss: 2.719195274633537
Validation loss: 2.5359912536677043

Epoch: 6| Step: 9
Training loss: 3.0143777906834806
Validation loss: 2.513249372040762

Epoch: 6| Step: 10
Training loss: 2.580950581547122
Validation loss: 2.498010836663475

Epoch: 6| Step: 11
Training loss: 2.7947062176582316
Validation loss: 2.485084455610715

Epoch: 6| Step: 12
Training loss: 2.816621854150998
Validation loss: 2.479038778804829

Epoch: 6| Step: 13
Training loss: 2.718340261868789
Validation loss: 2.467417681333969

Epoch: 132| Step: 0
Training loss: 3.2800790786514633
Validation loss: 2.477858793437821

Epoch: 6| Step: 1
Training loss: 2.431570813505901
Validation loss: 2.48758236468436

Epoch: 6| Step: 2
Training loss: 2.8574205399860175
Validation loss: 2.4813941454746757

Epoch: 6| Step: 3
Training loss: 2.6387596991074784
Validation loss: 2.5067387144042184

Epoch: 6| Step: 4
Training loss: 2.607200218808872
Validation loss: 2.5245541425546643

Epoch: 6| Step: 5
Training loss: 2.7782979149745275
Validation loss: 2.522737890225235

Epoch: 6| Step: 6
Training loss: 2.4870263113509776
Validation loss: 2.5191756189304

Epoch: 6| Step: 7
Training loss: 2.8478143174579955
Validation loss: 2.4903446975582173

Epoch: 6| Step: 8
Training loss: 3.0086049014558167
Validation loss: 2.458656714895366

Epoch: 6| Step: 9
Training loss: 2.785630879882742
Validation loss: 2.446260782832041

Epoch: 6| Step: 10
Training loss: 3.1941790447464684
Validation loss: 2.452784396336813

Epoch: 6| Step: 11
Training loss: 2.8146963232831115
Validation loss: 2.45031460564264

Epoch: 6| Step: 12
Training loss: 2.415161277803769
Validation loss: 2.45520885989832

Epoch: 6| Step: 13
Training loss: 2.7662940643841485
Validation loss: 2.4561131398496077

Epoch: 133| Step: 0
Training loss: 3.0291482777061405
Validation loss: 2.4600712566958762

Epoch: 6| Step: 1
Training loss: 3.2762807365643614
Validation loss: 2.445877053533762

Epoch: 6| Step: 2
Training loss: 2.6910096251373363
Validation loss: 2.452801315912595

Epoch: 6| Step: 3
Training loss: 2.7146666105372805
Validation loss: 2.452491488776093

Epoch: 6| Step: 4
Training loss: 2.4224541740689065
Validation loss: 2.449434212596371

Epoch: 6| Step: 5
Training loss: 2.768816125222209
Validation loss: 2.455994594946811

Epoch: 6| Step: 6
Training loss: 3.015644923327159
Validation loss: 2.45682280323532

Epoch: 6| Step: 7
Training loss: 2.7079592128482486
Validation loss: 2.470843641163514

Epoch: 6| Step: 8
Training loss: 2.7805823049699345
Validation loss: 2.45876200810658

Epoch: 6| Step: 9
Training loss: 2.4077576707146027
Validation loss: 2.4601043619108203

Epoch: 6| Step: 10
Training loss: 2.738790902720703
Validation loss: 2.455005180480068

Epoch: 6| Step: 11
Training loss: 2.42768428931893
Validation loss: 2.4669123360414607

Epoch: 6| Step: 12
Training loss: 2.796647302320305
Validation loss: 2.4753219464705927

Epoch: 6| Step: 13
Training loss: 3.400282926568448
Validation loss: 2.464320264615819

Epoch: 134| Step: 0
Training loss: 2.973974509565427
Validation loss: 2.4600411919227203

Epoch: 6| Step: 1
Training loss: 2.706708528292048
Validation loss: 2.454347422814434

Epoch: 6| Step: 2
Training loss: 2.259880412490839
Validation loss: 2.448247637832783

Epoch: 6| Step: 3
Training loss: 1.986662379885322
Validation loss: 2.4456761101067617

Epoch: 6| Step: 4
Training loss: 2.6662577871932327
Validation loss: 2.432068344277158

Epoch: 6| Step: 5
Training loss: 2.5161564425544376
Validation loss: 2.4345759324380274

Epoch: 6| Step: 6
Training loss: 2.816703283384176
Validation loss: 2.4371219591115723

Epoch: 6| Step: 7
Training loss: 2.9784778429980756
Validation loss: 2.434537552962781

Epoch: 6| Step: 8
Training loss: 2.3799882003748127
Validation loss: 2.4325857864518694

Epoch: 6| Step: 9
Training loss: 3.1376621827538247
Validation loss: 2.431120312693074

Epoch: 6| Step: 10
Training loss: 3.3353591167402157
Validation loss: 2.4264301060213738

Epoch: 6| Step: 11
Training loss: 3.091834814497955
Validation loss: 2.4314939232342776

Epoch: 6| Step: 12
Training loss: 2.8022373729090866
Validation loss: 2.4247184836122364

Epoch: 6| Step: 13
Training loss: 3.125151973843695
Validation loss: 2.4361767391436366

Epoch: 135| Step: 0
Training loss: 2.3712148117004372
Validation loss: 2.4425493344242475

Epoch: 6| Step: 1
Training loss: 3.506634554794512
Validation loss: 2.440822841709531

Epoch: 6| Step: 2
Training loss: 2.556306378551951
Validation loss: 2.4545329860360767

Epoch: 6| Step: 3
Training loss: 2.0242560067791437
Validation loss: 2.46990865878194

Epoch: 6| Step: 4
Training loss: 3.463281117823706
Validation loss: 2.478888712111317

Epoch: 6| Step: 5
Training loss: 2.5260485671955255
Validation loss: 2.5204915549173537

Epoch: 6| Step: 6
Training loss: 2.9507887545513687
Validation loss: 2.5523936829873817

Epoch: 6| Step: 7
Training loss: 2.6486707376499545
Validation loss: 2.548089757440759

Epoch: 6| Step: 8
Training loss: 2.3539135101945785
Validation loss: 2.5220670461732975

Epoch: 6| Step: 9
Training loss: 2.676660368244113
Validation loss: 2.501159622573311

Epoch: 6| Step: 10
Training loss: 3.0484583726380503
Validation loss: 2.5102566968617883

Epoch: 6| Step: 11
Training loss: 3.1633250189438447
Validation loss: 2.5049390508480944

Epoch: 6| Step: 12
Training loss: 2.7389722270636883
Validation loss: 2.48016678148751

Epoch: 6| Step: 13
Training loss: 2.712725574589104
Validation loss: 2.466290427478883

Epoch: 136| Step: 0
Training loss: 2.6957105259779217
Validation loss: 2.4497171462625666

Epoch: 6| Step: 1
Training loss: 2.696148198256934
Validation loss: 2.4535389693239997

Epoch: 6| Step: 2
Training loss: 2.4987163109008717
Validation loss: 2.4490054426702934

Epoch: 6| Step: 3
Training loss: 2.435939778540367
Validation loss: 2.453101206164357

Epoch: 6| Step: 4
Training loss: 3.024701625516289
Validation loss: 2.456707915704201

Epoch: 6| Step: 5
Training loss: 2.7358219351072566
Validation loss: 2.4653718670338196

Epoch: 6| Step: 6
Training loss: 3.2818668330651604
Validation loss: 2.4625285083933464

Epoch: 6| Step: 7
Training loss: 2.706230188169488
Validation loss: 2.46068840686906

Epoch: 6| Step: 8
Training loss: 3.2488615536297205
Validation loss: 2.466493515377209

Epoch: 6| Step: 9
Training loss: 2.2991299102968035
Validation loss: 2.470270189600599

Epoch: 6| Step: 10
Training loss: 2.481342312034885
Validation loss: 2.4653642739672326

Epoch: 6| Step: 11
Training loss: 2.7820769377215906
Validation loss: 2.474261732338867

Epoch: 6| Step: 12
Training loss: 2.9835649759164182
Validation loss: 2.4796340841618165

Epoch: 6| Step: 13
Training loss: 3.4433672683634002
Validation loss: 2.491422227294226

Epoch: 137| Step: 0
Training loss: 2.5821731689971377
Validation loss: 2.48874494251837

Epoch: 6| Step: 1
Training loss: 3.050521780939505
Validation loss: 2.4758828836667846

Epoch: 6| Step: 2
Training loss: 2.4798284229792533
Validation loss: 2.4830150249801495

Epoch: 6| Step: 3
Training loss: 2.386607665428409
Validation loss: 2.4811351183021513

Epoch: 6| Step: 4
Training loss: 3.433308490799096
Validation loss: 2.4740186572316807

Epoch: 6| Step: 5
Training loss: 3.406191204158555
Validation loss: 2.479522991416785

Epoch: 6| Step: 6
Training loss: 2.3444092904097342
Validation loss: 2.475294441772584

Epoch: 6| Step: 7
Training loss: 2.808591033552233
Validation loss: 2.486936987349715

Epoch: 6| Step: 8
Training loss: 2.721127051895253
Validation loss: 2.4877874880938884

Epoch: 6| Step: 9
Training loss: 2.651621117559299
Validation loss: 2.4934080122714484

Epoch: 6| Step: 10
Training loss: 3.236952781825459
Validation loss: 2.503092800067081

Epoch: 6| Step: 11
Training loss: 2.862425963931088
Validation loss: 2.498807350876198

Epoch: 6| Step: 12
Training loss: 2.4554250831617273
Validation loss: 2.4924996491371867

Epoch: 6| Step: 13
Training loss: 2.1192558292418098
Validation loss: 2.488636151938594

Epoch: 138| Step: 0
Training loss: 2.8992596306022076
Validation loss: 2.482959267830766

Epoch: 6| Step: 1
Training loss: 2.581666121297064
Validation loss: 2.4810572273585665

Epoch: 6| Step: 2
Training loss: 2.4780086302403004
Validation loss: 2.4821646117278178

Epoch: 6| Step: 3
Training loss: 3.0051225796546137
Validation loss: 2.470947586605654

Epoch: 6| Step: 4
Training loss: 3.213194116792501
Validation loss: 2.4777518078670084

Epoch: 6| Step: 5
Training loss: 2.7834147911563027
Validation loss: 2.4806886053122237

Epoch: 6| Step: 6
Training loss: 2.5531776002580533
Validation loss: 2.4698616952691124

Epoch: 6| Step: 7
Training loss: 2.726389444974831
Validation loss: 2.4689306315349673

Epoch: 6| Step: 8
Training loss: 2.0494214008984812
Validation loss: 2.4783728481567784

Epoch: 6| Step: 9
Training loss: 2.9337821320902098
Validation loss: 2.469647322468324

Epoch: 6| Step: 10
Training loss: 3.0099859930580677
Validation loss: 2.4811149387863933

Epoch: 6| Step: 11
Training loss: 3.1239803939673005
Validation loss: 2.4783556149138013

Epoch: 6| Step: 12
Training loss: 2.2720618001968114
Validation loss: 2.4814899110279316

Epoch: 6| Step: 13
Training loss: 3.305513175101416
Validation loss: 2.474937609046397

Epoch: 139| Step: 0
Training loss: 2.491725962602043
Validation loss: 2.4769488001964914

Epoch: 6| Step: 1
Training loss: 2.3525433189952154
Validation loss: 2.4779203561450966

Epoch: 6| Step: 2
Training loss: 2.25673948351733
Validation loss: 2.488933174733751

Epoch: 6| Step: 3
Training loss: 3.011180705931548
Validation loss: 2.485348842432482

Epoch: 6| Step: 4
Training loss: 2.504203409781205
Validation loss: 2.4926929005777456

Epoch: 6| Step: 5
Training loss: 3.1625193659374164
Validation loss: 2.5042956240831757

Epoch: 6| Step: 6
Training loss: 3.0933278113622817
Validation loss: 2.4877545575309883

Epoch: 6| Step: 7
Training loss: 3.5810279231427566
Validation loss: 2.473530916987136

Epoch: 6| Step: 8
Training loss: 2.8334065222169587
Validation loss: 2.466425933525996

Epoch: 6| Step: 9
Training loss: 3.089870910910964
Validation loss: 2.464658271365159

Epoch: 6| Step: 10
Training loss: 2.872936835343842
Validation loss: 2.4732856969914727

Epoch: 6| Step: 11
Training loss: 2.3260281740222353
Validation loss: 2.482901744856716

Epoch: 6| Step: 12
Training loss: 2.4823922936622624
Validation loss: 2.4851862095802826

Epoch: 6| Step: 13
Training loss: 2.890438754293503
Validation loss: 2.489031415707294

Epoch: 140| Step: 0
Training loss: 2.903326389320499
Validation loss: 2.50902318100181

Epoch: 6| Step: 1
Training loss: 2.8471118212956488
Validation loss: 2.504451129109934

Epoch: 6| Step: 2
Training loss: 2.9160643546037233
Validation loss: 2.4818468119149593

Epoch: 6| Step: 3
Training loss: 3.163116841225616
Validation loss: 2.4734393788683495

Epoch: 6| Step: 4
Training loss: 2.309732069355286
Validation loss: 2.4728442202294474

Epoch: 6| Step: 5
Training loss: 2.6657278275865006
Validation loss: 2.4817019014003088

Epoch: 6| Step: 6
Training loss: 2.0849121088032287
Validation loss: 2.4996813540274685

Epoch: 6| Step: 7
Training loss: 2.3142186557130238
Validation loss: 2.520961300245942

Epoch: 6| Step: 8
Training loss: 3.268475470310954
Validation loss: 2.531097690097161

Epoch: 6| Step: 9
Training loss: 2.652150929426852
Validation loss: 2.543376946993874

Epoch: 6| Step: 10
Training loss: 3.458152459864797
Validation loss: 2.509105745683531

Epoch: 6| Step: 11
Training loss: 2.9773359920707936
Validation loss: 2.4857871784338252

Epoch: 6| Step: 12
Training loss: 2.8495123195003695
Validation loss: 2.475923197355515

Epoch: 6| Step: 13
Training loss: 2.4055709871654156
Validation loss: 2.464379596563036

Epoch: 141| Step: 0
Training loss: 3.144300596888171
Validation loss: 2.458366265205844

Epoch: 6| Step: 1
Training loss: 2.558243915432453
Validation loss: 2.456894385307575

Epoch: 6| Step: 2
Training loss: 3.098690827094395
Validation loss: 2.4650556140029

Epoch: 6| Step: 3
Training loss: 2.5269303374325176
Validation loss: 2.459401739730099

Epoch: 6| Step: 4
Training loss: 2.8604039076381405
Validation loss: 2.4550636510298096

Epoch: 6| Step: 5
Training loss: 2.573093660472775
Validation loss: 2.465793741497888

Epoch: 6| Step: 6
Training loss: 2.5087512389495026
Validation loss: 2.460034422348074

Epoch: 6| Step: 7
Training loss: 2.5875933091298116
Validation loss: 2.4595654620319247

Epoch: 6| Step: 8
Training loss: 3.0539122082995407
Validation loss: 2.460121387455109

Epoch: 6| Step: 9
Training loss: 2.8584793439075082
Validation loss: 2.4709177299091065

Epoch: 6| Step: 10
Training loss: 2.767561584724745
Validation loss: 2.4777191577942084

Epoch: 6| Step: 11
Training loss: 2.5568908149343903
Validation loss: 2.4909257493089223

Epoch: 6| Step: 12
Training loss: 3.0246623709921896
Validation loss: 2.4946721176107682

Epoch: 6| Step: 13
Training loss: 2.5091976725439356
Validation loss: 2.470351690657975

Epoch: 142| Step: 0
Training loss: 2.5499842100963535
Validation loss: 2.482796228572164

Epoch: 6| Step: 1
Training loss: 2.3944394465859227
Validation loss: 2.4824675516769865

Epoch: 6| Step: 2
Training loss: 2.9321903371609155
Validation loss: 2.482344399320442

Epoch: 6| Step: 3
Training loss: 2.870959884740649
Validation loss: 2.497067345452656

Epoch: 6| Step: 4
Training loss: 3.1346941312914294
Validation loss: 2.500991208454983

Epoch: 6| Step: 5
Training loss: 2.1304766820935486
Validation loss: 2.492717377859942

Epoch: 6| Step: 6
Training loss: 3.158869043846141
Validation loss: 2.4873932376747088

Epoch: 6| Step: 7
Training loss: 2.6720263343472705
Validation loss: 2.4773187269145382

Epoch: 6| Step: 8
Training loss: 2.869640330197292
Validation loss: 2.4738777224366744

Epoch: 6| Step: 9
Training loss: 2.50070828894758
Validation loss: 2.4605756867066293

Epoch: 6| Step: 10
Training loss: 3.305294621388491
Validation loss: 2.456988713771593

Epoch: 6| Step: 11
Training loss: 2.419463698491439
Validation loss: 2.4512539294757723

Epoch: 6| Step: 12
Training loss: 3.0658390759802003
Validation loss: 2.4536740125195746

Epoch: 6| Step: 13
Training loss: 2.5378198957576212
Validation loss: 2.452428163463114

Epoch: 143| Step: 0
Training loss: 2.3834327765928514
Validation loss: 2.4579661854518235

Epoch: 6| Step: 1
Training loss: 2.8336851986079137
Validation loss: 2.4564574064023863

Epoch: 6| Step: 2
Training loss: 3.290296164635212
Validation loss: 2.4526568142948255

Epoch: 6| Step: 3
Training loss: 3.0193426904862544
Validation loss: 2.4519500248992037

Epoch: 6| Step: 4
Training loss: 2.9111904687556147
Validation loss: 2.45313900782307

Epoch: 6| Step: 5
Training loss: 2.704292177678103
Validation loss: 2.454996086606865

Epoch: 6| Step: 6
Training loss: 3.0087622790210853
Validation loss: 2.4599283420558344

Epoch: 6| Step: 7
Training loss: 2.4697770505354946
Validation loss: 2.4568468260692353

Epoch: 6| Step: 8
Training loss: 3.1514242313070047
Validation loss: 2.470202787873893

Epoch: 6| Step: 9
Training loss: 2.292352908874566
Validation loss: 2.492410577863425

Epoch: 6| Step: 10
Training loss: 2.5713484974912553
Validation loss: 2.4946523969998315

Epoch: 6| Step: 11
Training loss: 2.415834042287062
Validation loss: 2.5065588462869615

Epoch: 6| Step: 12
Training loss: 2.367045886144123
Validation loss: 2.5283297170531154

Epoch: 6| Step: 13
Training loss: 2.909411116067539
Validation loss: 2.5233627750710372

Epoch: 144| Step: 0
Training loss: 2.1883871187029347
Validation loss: 2.5290239411179747

Epoch: 6| Step: 1
Training loss: 3.0098983864092137
Validation loss: 2.5317740131545223

Epoch: 6| Step: 2
Training loss: 3.050488954967692
Validation loss: 2.543149614014865

Epoch: 6| Step: 3
Training loss: 2.4344974511509854
Validation loss: 2.5218875063572237

Epoch: 6| Step: 4
Training loss: 3.004793470143626
Validation loss: 2.493675606218024

Epoch: 6| Step: 5
Training loss: 2.620922645862423
Validation loss: 2.4715638351144835

Epoch: 6| Step: 6
Training loss: 3.058460140111344
Validation loss: 2.4562757657552896

Epoch: 6| Step: 7
Training loss: 2.2945989633192596
Validation loss: 2.4593859678908

Epoch: 6| Step: 8
Training loss: 3.2041228438126694
Validation loss: 2.445415689780466

Epoch: 6| Step: 9
Training loss: 2.702449295175242
Validation loss: 2.441762298676146

Epoch: 6| Step: 10
Training loss: 2.2559720362154394
Validation loss: 2.4525086162994008

Epoch: 6| Step: 11
Training loss: 3.2871018317278273
Validation loss: 2.445725226709954

Epoch: 6| Step: 12
Training loss: 2.263868190096081
Validation loss: 2.4502146166685934

Epoch: 6| Step: 13
Training loss: 3.3149298626828947
Validation loss: 2.4602641293684533

Epoch: 145| Step: 0
Training loss: 2.4106383498407937
Validation loss: 2.45092487608078

Epoch: 6| Step: 1
Training loss: 2.5286173375282464
Validation loss: 2.4646688882624024

Epoch: 6| Step: 2
Training loss: 2.6375069351466696
Validation loss: 2.4859783642982465

Epoch: 6| Step: 3
Training loss: 3.383299900384591
Validation loss: 2.5075713982140764

Epoch: 6| Step: 4
Training loss: 3.036192178375862
Validation loss: 2.53178034788885

Epoch: 6| Step: 5
Training loss: 2.255800611382892
Validation loss: 2.5346454537000866

Epoch: 6| Step: 6
Training loss: 2.747457195639291
Validation loss: 2.5327313948564085

Epoch: 6| Step: 7
Training loss: 3.0212174971524473
Validation loss: 2.5144701012194806

Epoch: 6| Step: 8
Training loss: 2.781000447596597
Validation loss: 2.4810267483468467

Epoch: 6| Step: 9
Training loss: 3.2428336729013005
Validation loss: 2.471425025823387

Epoch: 6| Step: 10
Training loss: 2.353005508286708
Validation loss: 2.4584763660676674

Epoch: 6| Step: 11
Training loss: 2.687193121133979
Validation loss: 2.4615888429951105

Epoch: 6| Step: 12
Training loss: 2.918707778265866
Validation loss: 2.454016208060047

Epoch: 6| Step: 13
Training loss: 2.4252846619579156
Validation loss: 2.4503545113693015

Epoch: 146| Step: 0
Training loss: 2.476221680881219
Validation loss: 2.4525069385704827

Epoch: 6| Step: 1
Training loss: 2.642585703633811
Validation loss: 2.4576915996950865

Epoch: 6| Step: 2
Training loss: 2.480312841126288
Validation loss: 2.460299270147983

Epoch: 6| Step: 3
Training loss: 2.8263310596528752
Validation loss: 2.4563959398092567

Epoch: 6| Step: 4
Training loss: 3.084643283295601
Validation loss: 2.453559931509384

Epoch: 6| Step: 5
Training loss: 2.449105438093553
Validation loss: 2.4765019951421885

Epoch: 6| Step: 6
Training loss: 3.0944327169485653
Validation loss: 2.488232949736736

Epoch: 6| Step: 7
Training loss: 2.520028755689981
Validation loss: 2.4890549515593623

Epoch: 6| Step: 8
Training loss: 3.0054402297719123
Validation loss: 2.486502001759153

Epoch: 6| Step: 9
Training loss: 2.4622103835455156
Validation loss: 2.4782783824462724

Epoch: 6| Step: 10
Training loss: 2.8670446375873637
Validation loss: 2.461782078926793

Epoch: 6| Step: 11
Training loss: 2.6541323130094585
Validation loss: 2.442140247946319

Epoch: 6| Step: 12
Training loss: 3.016829492238781
Validation loss: 2.448739481199545

Epoch: 6| Step: 13
Training loss: 3.082202360288907
Validation loss: 2.43725973059409

Epoch: 147| Step: 0
Training loss: 2.6608944847406746
Validation loss: 2.432906429884748

Epoch: 6| Step: 1
Training loss: 3.0827898800963096
Validation loss: 2.4502767897058875

Epoch: 6| Step: 2
Training loss: 2.7292490842376873
Validation loss: 2.492528878073062

Epoch: 6| Step: 3
Training loss: 3.0679966392250004
Validation loss: 2.539883987143814

Epoch: 6| Step: 4
Training loss: 2.9866921581588253
Validation loss: 2.5604473219279886

Epoch: 6| Step: 5
Training loss: 2.9595117684394734
Validation loss: 2.6289237484613714

Epoch: 6| Step: 6
Training loss: 2.2849298348703755
Validation loss: 2.6682983073823854

Epoch: 6| Step: 7
Training loss: 3.433007651378573
Validation loss: 2.6472042570256433

Epoch: 6| Step: 8
Training loss: 2.9395308272018212
Validation loss: 2.506781966041807

Epoch: 6| Step: 9
Training loss: 2.9039051071300213
Validation loss: 2.451366780223482

Epoch: 6| Step: 10
Training loss: 2.2168671046488266
Validation loss: 2.463430496895647

Epoch: 6| Step: 11
Training loss: 2.2526762199270784
Validation loss: 2.5255826792930853

Epoch: 6| Step: 12
Training loss: 2.9590527013563475
Validation loss: 2.5967429454790585

Epoch: 6| Step: 13
Training loss: 3.1512851757611795
Validation loss: 2.644048048917896

Epoch: 148| Step: 0
Training loss: 2.9154831437807904
Validation loss: 2.730895612517208

Epoch: 6| Step: 1
Training loss: 2.457899852832486
Validation loss: 2.761643007108909

Epoch: 6| Step: 2
Training loss: 3.169640416349703
Validation loss: 2.7858990063124787

Epoch: 6| Step: 3
Training loss: 2.4453600796589146
Validation loss: 2.813245890893399

Epoch: 6| Step: 4
Training loss: 3.154517576450751
Validation loss: 2.8040057674096626

Epoch: 6| Step: 5
Training loss: 3.1962035785715885
Validation loss: 2.743976143485337

Epoch: 6| Step: 6
Training loss: 2.2141644009526034
Validation loss: 2.6343285089697943

Epoch: 6| Step: 7
Training loss: 3.1993762898577596
Validation loss: 2.5538044901486363

Epoch: 6| Step: 8
Training loss: 3.2105047300928
Validation loss: 2.5047249873397432

Epoch: 6| Step: 9
Training loss: 3.1188827150044633
Validation loss: 2.4491667589796395

Epoch: 6| Step: 10
Training loss: 2.608884662539546
Validation loss: 2.436392769020401

Epoch: 6| Step: 11
Training loss: 3.0073002366640984
Validation loss: 2.424493387929858

Epoch: 6| Step: 12
Training loss: 2.584606185222505
Validation loss: 2.4133039212447263

Epoch: 6| Step: 13
Training loss: 2.902121780553428
Validation loss: 2.425458327820885

Epoch: 149| Step: 0
Training loss: 2.4852753932949923
Validation loss: 2.4210042657801334

Epoch: 6| Step: 1
Training loss: 2.7179853745292277
Validation loss: 2.459342706218647

Epoch: 6| Step: 2
Training loss: 2.609751234513068
Validation loss: 2.4692862797769184

Epoch: 6| Step: 3
Training loss: 3.1512152673909775
Validation loss: 2.512006576240325

Epoch: 6| Step: 4
Training loss: 2.262300564738214
Validation loss: 2.4980650140446166

Epoch: 6| Step: 5
Training loss: 3.0900681290013847
Validation loss: 2.4962707802873285

Epoch: 6| Step: 6
Training loss: 2.8713707615090094
Validation loss: 2.502976046943665

Epoch: 6| Step: 7
Training loss: 3.261958788416724
Validation loss: 2.523908942841075

Epoch: 6| Step: 8
Training loss: 3.088771937997517
Validation loss: 2.559463661951248

Epoch: 6| Step: 9
Training loss: 2.84423438337984
Validation loss: 2.5822709750921056

Epoch: 6| Step: 10
Training loss: 2.419765612072914
Validation loss: 2.5888465326630334

Epoch: 6| Step: 11
Training loss: 3.1275952053444596
Validation loss: 2.6005246164800235

Epoch: 6| Step: 12
Training loss: 2.744085280108039
Validation loss: 2.565419718437587

Epoch: 6| Step: 13
Training loss: 3.22151065694043
Validation loss: 2.5561523512719715

Epoch: 150| Step: 0
Training loss: 2.5587245762115898
Validation loss: 2.538013976170278

Epoch: 6| Step: 1
Training loss: 3.2346663044391795
Validation loss: 2.510205839326075

Epoch: 6| Step: 2
Training loss: 2.5586726751603184
Validation loss: 2.497137710751453

Epoch: 6| Step: 3
Training loss: 2.6999010915653634
Validation loss: 2.481215797528098

Epoch: 6| Step: 4
Training loss: 3.1312670617771348
Validation loss: 2.4763187738683667

Epoch: 6| Step: 5
Training loss: 2.9939042786284675
Validation loss: 2.463741326052031

Epoch: 6| Step: 6
Training loss: 2.915652089539966
Validation loss: 2.4613946888782445

Epoch: 6| Step: 7
Training loss: 2.4707506981894714
Validation loss: 2.4508968957134014

Epoch: 6| Step: 8
Training loss: 2.9819388307556967
Validation loss: 2.4570585960435283

Epoch: 6| Step: 9
Training loss: 2.435375363598206
Validation loss: 2.4424427508265385

Epoch: 6| Step: 10
Training loss: 2.9371741905523705
Validation loss: 2.4603169049532885

Epoch: 6| Step: 11
Training loss: 3.07562107544067
Validation loss: 2.451815053000225

Epoch: 6| Step: 12
Training loss: 2.4175139509427717
Validation loss: 2.4391523481678217

Epoch: 6| Step: 13
Training loss: 2.550839386959509
Validation loss: 2.45631077050997

Epoch: 151| Step: 0
Training loss: 2.8177432882475926
Validation loss: 2.4450608892337278

Epoch: 6| Step: 1
Training loss: 2.7350124814936003
Validation loss: 2.4446185509664016

Epoch: 6| Step: 2
Training loss: 3.068803799967556
Validation loss: 2.4478733859210227

Epoch: 6| Step: 3
Training loss: 2.447783273078998
Validation loss: 2.4506381809040105

Epoch: 6| Step: 4
Training loss: 2.9666890268518973
Validation loss: 2.444995217797487

Epoch: 6| Step: 5
Training loss: 3.1055748495534927
Validation loss: 2.434598133014467

Epoch: 6| Step: 6
Training loss: 2.3875885672394133
Validation loss: 2.4433880848522223

Epoch: 6| Step: 7
Training loss: 2.688944228927811
Validation loss: 2.456100521566374

Epoch: 6| Step: 8
Training loss: 3.046533966541248
Validation loss: 2.466937186031888

Epoch: 6| Step: 9
Training loss: 2.915667626170519
Validation loss: 2.451945745452163

Epoch: 6| Step: 10
Training loss: 2.5240468331781525
Validation loss: 2.442449996353605

Epoch: 6| Step: 11
Training loss: 2.4642714426958188
Validation loss: 2.4323756400273844

Epoch: 6| Step: 12
Training loss: 2.4731473751371853
Validation loss: 2.4160019303701015

Epoch: 6| Step: 13
Training loss: 2.979387999806933
Validation loss: 2.4148265323695326

Epoch: 152| Step: 0
Training loss: 2.7333713978543783
Validation loss: 2.423841128114003

Epoch: 6| Step: 1
Training loss: 2.716926928107972
Validation loss: 2.424897766580082

Epoch: 6| Step: 2
Training loss: 2.5112638402683722
Validation loss: 2.4251275637834455

Epoch: 6| Step: 3
Training loss: 2.941543069319589
Validation loss: 2.41978300725536

Epoch: 6| Step: 4
Training loss: 2.9071693196938395
Validation loss: 2.4225165600717933

Epoch: 6| Step: 5
Training loss: 2.963179330961345
Validation loss: 2.4166128761138186

Epoch: 6| Step: 6
Training loss: 3.0739404729317594
Validation loss: 2.4190852774914537

Epoch: 6| Step: 7
Training loss: 2.8858930467652755
Validation loss: 2.41925024411518

Epoch: 6| Step: 8
Training loss: 2.941060606974376
Validation loss: 2.41560050241835

Epoch: 6| Step: 9
Training loss: 2.755986892702246
Validation loss: 2.415744592502989

Epoch: 6| Step: 10
Training loss: 1.6325143058114986
Validation loss: 2.422557357580958

Epoch: 6| Step: 11
Training loss: 2.7508294848584938
Validation loss: 2.4158244353834366

Epoch: 6| Step: 12
Training loss: 2.8678940570262808
Validation loss: 2.419465931577287

Epoch: 6| Step: 13
Training loss: 2.3950103230741693
Validation loss: 2.4232679750734896

Epoch: 153| Step: 0
Training loss: 2.8157744949062504
Validation loss: 2.425972328073462

Epoch: 6| Step: 1
Training loss: 2.5430687856848
Validation loss: 2.4217830030505003

Epoch: 6| Step: 2
Training loss: 2.318178473519481
Validation loss: 2.428545528338212

Epoch: 6| Step: 3
Training loss: 2.2543589436525346
Validation loss: 2.430297612470324

Epoch: 6| Step: 4
Training loss: 3.0865915112446607
Validation loss: 2.419593955737392

Epoch: 6| Step: 5
Training loss: 2.566765189653771
Validation loss: 2.422479367408896

Epoch: 6| Step: 6
Training loss: 3.1168572195894906
Validation loss: 2.435486974329154

Epoch: 6| Step: 7
Training loss: 2.7003083300263087
Validation loss: 2.4412197813954584

Epoch: 6| Step: 8
Training loss: 3.072680465327365
Validation loss: 2.4332366777789534

Epoch: 6| Step: 9
Training loss: 2.700941758687066
Validation loss: 2.439240115578968

Epoch: 6| Step: 10
Training loss: 3.0344073968605585
Validation loss: 2.464315081819062

Epoch: 6| Step: 11
Training loss: 2.708283282086468
Validation loss: 2.4811596403775864

Epoch: 6| Step: 12
Training loss: 2.2495129375980256
Validation loss: 2.520144002645941

Epoch: 6| Step: 13
Training loss: 2.645181280172375
Validation loss: 2.5025301179405974

Epoch: 154| Step: 0
Training loss: 2.5869474254053797
Validation loss: 2.4618009871171878

Epoch: 6| Step: 1
Training loss: 3.243108485296152
Validation loss: 2.419632311602367

Epoch: 6| Step: 2
Training loss: 1.8887861783332618
Validation loss: 2.396536207600921

Epoch: 6| Step: 3
Training loss: 2.6344232810450485
Validation loss: 2.392627131563129

Epoch: 6| Step: 4
Training loss: 2.4415124000360984
Validation loss: 2.3968341964301336

Epoch: 6| Step: 5
Training loss: 2.978536436914995
Validation loss: 2.3981308060408684

Epoch: 6| Step: 6
Training loss: 2.976459491379112
Validation loss: 2.3986878890511125

Epoch: 6| Step: 7
Training loss: 2.8413343964313227
Validation loss: 2.401321067798047

Epoch: 6| Step: 8
Training loss: 2.4080367947425523
Validation loss: 2.4026565344133863

Epoch: 6| Step: 9
Training loss: 1.8863736107469564
Validation loss: 2.402200772265702

Epoch: 6| Step: 10
Training loss: 2.8168363414724493
Validation loss: 2.4123768552243865

Epoch: 6| Step: 11
Training loss: 3.109735515914958
Validation loss: 2.4188357036881762

Epoch: 6| Step: 12
Training loss: 2.825466191807965
Validation loss: 2.4235726494775496

Epoch: 6| Step: 13
Training loss: 3.137371902586488
Validation loss: 2.4284876961257957

Epoch: 155| Step: 0
Training loss: 2.3339729340723774
Validation loss: 2.4338370546738233

Epoch: 6| Step: 1
Training loss: 2.7744987928697578
Validation loss: 2.449160368624046

Epoch: 6| Step: 2
Training loss: 2.6755072460358034
Validation loss: 2.4531336812229614

Epoch: 6| Step: 3
Training loss: 2.575046435187448
Validation loss: 2.461429309419118

Epoch: 6| Step: 4
Training loss: 2.3273182949839484
Validation loss: 2.4616948767263205

Epoch: 6| Step: 5
Training loss: 3.090523164033753
Validation loss: 2.4665672379763692

Epoch: 6| Step: 6
Training loss: 2.927191319402567
Validation loss: 2.467903786063437

Epoch: 6| Step: 7
Training loss: 3.1842110813467266
Validation loss: 2.4467268761950045

Epoch: 6| Step: 8
Training loss: 2.6642091772247434
Validation loss: 2.4338916957044914

Epoch: 6| Step: 9
Training loss: 2.3494361566254227
Validation loss: 2.4039458008551677

Epoch: 6| Step: 10
Training loss: 2.489427622843006
Validation loss: 2.406100401258588

Epoch: 6| Step: 11
Training loss: 2.8064616338029738
Validation loss: 2.4163710321766323

Epoch: 6| Step: 12
Training loss: 2.65046726641675
Validation loss: 2.4348170005079472

Epoch: 6| Step: 13
Training loss: 3.192307231821729
Validation loss: 2.4566640965780873

Epoch: 156| Step: 0
Training loss: 2.4580328375141476
Validation loss: 2.4456337369802785

Epoch: 6| Step: 1
Training loss: 2.139230315575818
Validation loss: 2.4281674373536126

Epoch: 6| Step: 2
Training loss: 2.607050791419401
Validation loss: 2.4237961531619683

Epoch: 6| Step: 3
Training loss: 3.2626232606250274
Validation loss: 2.4341775259850316

Epoch: 6| Step: 4
Training loss: 2.806457471081168
Validation loss: 2.4428820860588

Epoch: 6| Step: 5
Training loss: 3.182679813935839
Validation loss: 2.4352702566851403

Epoch: 6| Step: 6
Training loss: 2.6107411719975393
Validation loss: 2.455779552394107

Epoch: 6| Step: 7
Training loss: 2.646378068090888
Validation loss: 2.4605300162291392

Epoch: 6| Step: 8
Training loss: 2.5594188495461445
Validation loss: 2.465732148944889

Epoch: 6| Step: 9
Training loss: 2.960271352753594
Validation loss: 2.43643396339746

Epoch: 6| Step: 10
Training loss: 2.854536621917242
Validation loss: 2.4373508141622207

Epoch: 6| Step: 11
Training loss: 3.1368367136131097
Validation loss: 2.4240838993296068

Epoch: 6| Step: 12
Training loss: 1.860720620381205
Validation loss: 2.415746996168993

Epoch: 6| Step: 13
Training loss: 2.117087161230801
Validation loss: 2.434337310054842

Epoch: 157| Step: 0
Training loss: 3.13226876808138
Validation loss: 2.417869142118795

Epoch: 6| Step: 1
Training loss: 2.4054817855992194
Validation loss: 2.413642397271919

Epoch: 6| Step: 2
Training loss: 2.463437121849897
Validation loss: 2.4059461911367985

Epoch: 6| Step: 3
Training loss: 2.870555593696786
Validation loss: 2.4133171303154786

Epoch: 6| Step: 4
Training loss: 2.6041407367686933
Validation loss: 2.4190539540744798

Epoch: 6| Step: 5
Training loss: 2.747254041053132
Validation loss: 2.40351340019788

Epoch: 6| Step: 6
Training loss: 3.0844279399684327
Validation loss: 2.41186508915237

Epoch: 6| Step: 7
Training loss: 2.650700415411131
Validation loss: 2.402064040206268

Epoch: 6| Step: 8
Training loss: 2.0299137121568713
Validation loss: 2.4129639591885677

Epoch: 6| Step: 9
Training loss: 2.02448566639528
Validation loss: 2.409192068428789

Epoch: 6| Step: 10
Training loss: 3.1362815162653335
Validation loss: 2.424135343263486

Epoch: 6| Step: 11
Training loss: 3.2112929989678185
Validation loss: 2.434648909372293

Epoch: 6| Step: 12
Training loss: 2.5299917790878683
Validation loss: 2.439032975762486

Epoch: 6| Step: 13
Training loss: 2.356469696083179
Validation loss: 2.4598489771119962

Epoch: 158| Step: 0
Training loss: 2.7346099752554034
Validation loss: 2.485360891370307

Epoch: 6| Step: 1
Training loss: 2.5891708949897287
Validation loss: 2.504470088782001

Epoch: 6| Step: 2
Training loss: 2.8000400472229403
Validation loss: 2.5362474894166134

Epoch: 6| Step: 3
Training loss: 2.892879782021289
Validation loss: 2.618161295350161

Epoch: 6| Step: 4
Training loss: 2.534726522317197
Validation loss: 2.653133366318411

Epoch: 6| Step: 5
Training loss: 2.936571014901823
Validation loss: 2.636840251643515

Epoch: 6| Step: 6
Training loss: 3.114180488858586
Validation loss: 2.6085063256443686

Epoch: 6| Step: 7
Training loss: 2.766017907460487
Validation loss: 2.5108107401055815

Epoch: 6| Step: 8
Training loss: 2.528816843323216
Validation loss: 2.4243433419632314

Epoch: 6| Step: 9
Training loss: 2.4945151242799133
Validation loss: 2.4003970522741813

Epoch: 6| Step: 10
Training loss: 2.4212276454951143
Validation loss: 2.3965780779732744

Epoch: 6| Step: 11
Training loss: 2.7092432889856117
Validation loss: 2.426597572658862

Epoch: 6| Step: 12
Training loss: 2.8009361745636925
Validation loss: 2.468307449220503

Epoch: 6| Step: 13
Training loss: 3.2909050716316206
Validation loss: 2.5353824265505653

Epoch: 159| Step: 0
Training loss: 2.2397827651067828
Validation loss: 2.512834867983849

Epoch: 6| Step: 1
Training loss: 2.7019830838569696
Validation loss: 2.517116288295787

Epoch: 6| Step: 2
Training loss: 2.9190947825250952
Validation loss: 2.5474619191351264

Epoch: 6| Step: 3
Training loss: 2.4490322303629335
Validation loss: 2.496795093075502

Epoch: 6| Step: 4
Training loss: 2.656121643555462
Validation loss: 2.431696503536639

Epoch: 6| Step: 5
Training loss: 2.813587910793387
Validation loss: 2.447210755649833

Epoch: 6| Step: 6
Training loss: 2.5926174770654566
Validation loss: 2.431340578250256

Epoch: 6| Step: 7
Training loss: 2.453093704704339
Validation loss: 2.41070357048647

Epoch: 6| Step: 8
Training loss: 1.9733857571666353
Validation loss: 2.4116829366852537

Epoch: 6| Step: 9
Training loss: 3.258646979362508
Validation loss: 2.412843556770205

Epoch: 6| Step: 10
Training loss: 2.71649848401796
Validation loss: 2.399190289881303

Epoch: 6| Step: 11
Training loss: 2.8174791131180448
Validation loss: 2.3941625771547685

Epoch: 6| Step: 12
Training loss: 3.075800758863867
Validation loss: 2.40181547076156

Epoch: 6| Step: 13
Training loss: 3.269584482140208
Validation loss: 2.4238846447794447

Epoch: 160| Step: 0
Training loss: 3.093091798374071
Validation loss: 2.4157400058983542

Epoch: 6| Step: 1
Training loss: 3.0203193139533684
Validation loss: 2.427426637440947

Epoch: 6| Step: 2
Training loss: 2.600084406142882
Validation loss: 2.4441393235968416

Epoch: 6| Step: 3
Training loss: 2.5761169011263916
Validation loss: 2.4193179749855864

Epoch: 6| Step: 4
Training loss: 2.397092162319956
Validation loss: 2.4422699213686423

Epoch: 6| Step: 5
Training loss: 2.3541286319147017
Validation loss: 2.4189062451908945

Epoch: 6| Step: 6
Training loss: 3.212702134003564
Validation loss: 2.392940508964969

Epoch: 6| Step: 7
Training loss: 2.741166579564063
Validation loss: 2.399156467016409

Epoch: 6| Step: 8
Training loss: 2.2216518928549815
Validation loss: 2.4049204154938106

Epoch: 6| Step: 9
Training loss: 3.2076488276597415
Validation loss: 2.4088235343087363

Epoch: 6| Step: 10
Training loss: 2.8590593007393257
Validation loss: 2.4062940372165773

Epoch: 6| Step: 11
Training loss: 2.6400951327898516
Validation loss: 2.422261272195739

Epoch: 6| Step: 12
Training loss: 2.8554585635398846
Validation loss: 2.4287928852705583

Epoch: 6| Step: 13
Training loss: 1.7637477110720137
Validation loss: 2.45151594030418

Epoch: 161| Step: 0
Training loss: 3.0032793241577735
Validation loss: 2.466275839481183

Epoch: 6| Step: 1
Training loss: 2.622792360139151
Validation loss: 2.4535251675361245

Epoch: 6| Step: 2
Training loss: 3.173835637010341
Validation loss: 2.4901759288089114

Epoch: 6| Step: 3
Training loss: 2.056992894621702
Validation loss: 2.4941982721599087

Epoch: 6| Step: 4
Training loss: 2.429481816555262
Validation loss: 2.503849335219228

Epoch: 6| Step: 5
Training loss: 2.7391072332164352
Validation loss: 2.490457089442173

Epoch: 6| Step: 6
Training loss: 2.5317434136128063
Validation loss: 2.475209203956087

Epoch: 6| Step: 7
Training loss: 2.7740709897661606
Validation loss: 2.464500893149409

Epoch: 6| Step: 8
Training loss: 1.8079662181812455
Validation loss: 2.450675619900342

Epoch: 6| Step: 9
Training loss: 2.9811524573149364
Validation loss: 2.4151801221497204

Epoch: 6| Step: 10
Training loss: 2.799599796032343
Validation loss: 2.427324539642385

Epoch: 6| Step: 11
Training loss: 2.7282286529251176
Validation loss: 2.429894309700062

Epoch: 6| Step: 12
Training loss: 2.936213434802858
Validation loss: 2.4312357334522194

Epoch: 6| Step: 13
Training loss: 3.4996656530628094
Validation loss: 2.4366471192306007

Epoch: 162| Step: 0
Training loss: 2.794032863830531
Validation loss: 2.4216692310133894

Epoch: 6| Step: 1
Training loss: 2.602957045321966
Validation loss: 2.419440690434951

Epoch: 6| Step: 2
Training loss: 2.369340679027796
Validation loss: 2.4221237684681673

Epoch: 6| Step: 3
Training loss: 2.91874372003766
Validation loss: 2.4319844829369783

Epoch: 6| Step: 4
Training loss: 3.122458988894666
Validation loss: 2.4248510498709543

Epoch: 6| Step: 5
Training loss: 3.5990367978380524
Validation loss: 2.432775473342042

Epoch: 6| Step: 6
Training loss: 2.3466258398030244
Validation loss: 2.4408811221199276

Epoch: 6| Step: 7
Training loss: 2.1586067478204174
Validation loss: 2.4471160350865153

Epoch: 6| Step: 8
Training loss: 2.4560590558174376
Validation loss: 2.4559189442960854

Epoch: 6| Step: 9
Training loss: 2.3351353317349917
Validation loss: 2.483185086722464

Epoch: 6| Step: 10
Training loss: 2.5912565632583817
Validation loss: 2.5018010850353627

Epoch: 6| Step: 11
Training loss: 2.623218658571235
Validation loss: 2.5113396331442424

Epoch: 6| Step: 12
Training loss: 2.5013641450335795
Validation loss: 2.527699903805916

Epoch: 6| Step: 13
Training loss: 3.0420631951483794
Validation loss: 2.530547224367524

Epoch: 163| Step: 0
Training loss: 3.044790640713474
Validation loss: 2.5362713634050307

Epoch: 6| Step: 1
Training loss: 3.0255961437618346
Validation loss: 2.5291490169588506

Epoch: 6| Step: 2
Training loss: 2.8269112021308107
Validation loss: 2.4954483415142668

Epoch: 6| Step: 3
Training loss: 2.8214017080369844
Validation loss: 2.4776845900074647

Epoch: 6| Step: 4
Training loss: 1.956747129606591
Validation loss: 2.4628885015483544

Epoch: 6| Step: 5
Training loss: 2.156731814305026
Validation loss: 2.4448620597795316

Epoch: 6| Step: 6
Training loss: 2.9628273762922035
Validation loss: 2.4183092578141747

Epoch: 6| Step: 7
Training loss: 2.6536150260736773
Validation loss: 2.4061374347653453

Epoch: 6| Step: 8
Training loss: 2.486769188343331
Validation loss: 2.4193491498135096

Epoch: 6| Step: 9
Training loss: 2.287785821787002
Validation loss: 2.4134097357211224

Epoch: 6| Step: 10
Training loss: 2.586387479879115
Validation loss: 2.411478514582338

Epoch: 6| Step: 11
Training loss: 2.5536664969842526
Validation loss: 2.4207189049321833

Epoch: 6| Step: 12
Training loss: 3.2345607538371683
Validation loss: 2.4246015387741227

Epoch: 6| Step: 13
Training loss: 2.8309755238586947
Validation loss: 2.416183801797999

Epoch: 164| Step: 0
Training loss: 2.4408672256521737
Validation loss: 2.4198962948378484

Epoch: 6| Step: 1
Training loss: 2.3469751166514636
Validation loss: 2.421559977345705

Epoch: 6| Step: 2
Training loss: 2.796302012137587
Validation loss: 2.421732961543047

Epoch: 6| Step: 3
Training loss: 2.2347978311880827
Validation loss: 2.4338966778521427

Epoch: 6| Step: 4
Training loss: 2.822150479512035
Validation loss: 2.438911988217982

Epoch: 6| Step: 5
Training loss: 2.9827958167974873
Validation loss: 2.464105453416989

Epoch: 6| Step: 6
Training loss: 2.7975174150103834
Validation loss: 2.4796309794224127

Epoch: 6| Step: 7
Training loss: 2.473595222461622
Validation loss: 2.4895596287908726

Epoch: 6| Step: 8
Training loss: 2.1053025103956724
Validation loss: 2.526639642314704

Epoch: 6| Step: 9
Training loss: 2.4985450325465592
Validation loss: 2.5796025104154303

Epoch: 6| Step: 10
Training loss: 2.8839826819208088
Validation loss: 2.6147683759634788

Epoch: 6| Step: 11
Training loss: 3.156130948984638
Validation loss: 2.568311093414369

Epoch: 6| Step: 12
Training loss: 2.9236183881228612
Validation loss: 2.5301852380178462

Epoch: 6| Step: 13
Training loss: 2.681017398303962
Validation loss: 2.481865446386362

Epoch: 165| Step: 0
Training loss: 3.06606723344895
Validation loss: 2.4472067046679062

Epoch: 6| Step: 1
Training loss: 2.6482265692241254
Validation loss: 2.4258494643064235

Epoch: 6| Step: 2
Training loss: 2.3932992774786004
Validation loss: 2.413832709339195

Epoch: 6| Step: 3
Training loss: 2.375683234468747
Validation loss: 2.4357333421559906

Epoch: 6| Step: 4
Training loss: 3.082642623930805
Validation loss: 2.4435547963591744

Epoch: 6| Step: 5
Training loss: 2.191258716206861
Validation loss: 2.4363949829070592

Epoch: 6| Step: 6
Training loss: 2.8851252843670654
Validation loss: 2.426545876654041

Epoch: 6| Step: 7
Training loss: 2.9650045760892967
Validation loss: 2.4221893498198175

Epoch: 6| Step: 8
Training loss: 3.082427450225046
Validation loss: 2.4171816429579858

Epoch: 6| Step: 9
Training loss: 2.6403226961527517
Validation loss: 2.413607535263896

Epoch: 6| Step: 10
Training loss: 2.5079047165312534
Validation loss: 2.4103145611525223

Epoch: 6| Step: 11
Training loss: 2.3742465781727145
Validation loss: 2.4050295168603917

Epoch: 6| Step: 12
Training loss: 2.771261043569596
Validation loss: 2.4013219976739353

Epoch: 6| Step: 13
Training loss: 1.8842627294190646
Validation loss: 2.420296780971669

Epoch: 166| Step: 0
Training loss: 2.666418471309754
Validation loss: 2.430936188277873

Epoch: 6| Step: 1
Training loss: 2.714701125974854
Validation loss: 2.446571947033955

Epoch: 6| Step: 2
Training loss: 2.6262031704242137
Validation loss: 2.4653716465835718

Epoch: 6| Step: 3
Training loss: 2.962403752175885
Validation loss: 2.494343202859265

Epoch: 6| Step: 4
Training loss: 2.8275471302425137
Validation loss: 2.4892855058601984

Epoch: 6| Step: 5
Training loss: 3.039242462086098
Validation loss: 2.4857863626600163

Epoch: 6| Step: 6
Training loss: 2.381034412787419
Validation loss: 2.506030207663162

Epoch: 6| Step: 7
Training loss: 2.825127377634435
Validation loss: 2.5025082362445548

Epoch: 6| Step: 8
Training loss: 2.105105225386306
Validation loss: 2.482008437540462

Epoch: 6| Step: 9
Training loss: 1.8908111228439788
Validation loss: 2.4584294406909644

Epoch: 6| Step: 10
Training loss: 2.3278220574844277
Validation loss: 2.447395152557731

Epoch: 6| Step: 11
Training loss: 2.996018947179799
Validation loss: 2.4432338064830317

Epoch: 6| Step: 12
Training loss: 2.7059805015656555
Validation loss: 2.4460054157775235

Epoch: 6| Step: 13
Training loss: 3.064288492928743
Validation loss: 2.4262899096320556

Epoch: 167| Step: 0
Training loss: 2.469553563162898
Validation loss: 2.4111067797091694

Epoch: 6| Step: 1
Training loss: 2.7826819858863527
Validation loss: 2.4329581129699562

Epoch: 6| Step: 2
Training loss: 2.6956036838862376
Validation loss: 2.4356662256445536

Epoch: 6| Step: 3
Training loss: 2.470477501741088
Validation loss: 2.449443023598423

Epoch: 6| Step: 4
Training loss: 2.918848765497234
Validation loss: 2.4699034233587494

Epoch: 6| Step: 5
Training loss: 2.1223300541394625
Validation loss: 2.4780113521577003

Epoch: 6| Step: 6
Training loss: 2.3210555919282787
Validation loss: 2.489644250696399

Epoch: 6| Step: 7
Training loss: 2.533519433949242
Validation loss: 2.4945507074918236

Epoch: 6| Step: 8
Training loss: 3.046412819262789
Validation loss: 2.4835631166850995

Epoch: 6| Step: 9
Training loss: 3.084510028824663
Validation loss: 2.478528131235752

Epoch: 6| Step: 10
Training loss: 2.665023138292934
Validation loss: 2.48695089543943

Epoch: 6| Step: 11
Training loss: 2.8311897658789107
Validation loss: 2.477490392421088

Epoch: 6| Step: 12
Training loss: 2.3355307336515208
Validation loss: 2.4818615118801888

Epoch: 6| Step: 13
Training loss: 2.7397125465080996
Validation loss: 2.496950168903503

Epoch: 168| Step: 0
Training loss: 2.236178757122823
Validation loss: 2.4906389402371834

Epoch: 6| Step: 1
Training loss: 2.77769122518693
Validation loss: 2.476637570800093

Epoch: 6| Step: 2
Training loss: 1.9773407259721665
Validation loss: 2.4494414918668386

Epoch: 6| Step: 3
Training loss: 3.0222536277853354
Validation loss: 2.4353097709993894

Epoch: 6| Step: 4
Training loss: 2.708015208022718
Validation loss: 2.4370598554717833

Epoch: 6| Step: 5
Training loss: 2.614618845745324
Validation loss: 2.4177154472482414

Epoch: 6| Step: 6
Training loss: 2.909073801152903
Validation loss: 2.418918107890959

Epoch: 6| Step: 7
Training loss: 2.6644651047219603
Validation loss: 2.405560225603532

Epoch: 6| Step: 8
Training loss: 2.1461644580748036
Validation loss: 2.408292684571453

Epoch: 6| Step: 9
Training loss: 3.045684268781007
Validation loss: 2.4133052623917632

Epoch: 6| Step: 10
Training loss: 2.021350388071653
Validation loss: 2.4287819743308345

Epoch: 6| Step: 11
Training loss: 2.961901827270311
Validation loss: 2.434272625730754

Epoch: 6| Step: 12
Training loss: 2.763663506916439
Validation loss: 2.453462090423384

Epoch: 6| Step: 13
Training loss: 2.3168570223024103
Validation loss: 2.4791355122481855

Epoch: 169| Step: 0
Training loss: 2.908751528894853
Validation loss: 2.4936629333273173

Epoch: 6| Step: 1
Training loss: 1.6187552256849622
Validation loss: 2.5223215812360618

Epoch: 6| Step: 2
Training loss: 2.2908491121287353
Validation loss: 2.5751429957648213

Epoch: 6| Step: 3
Training loss: 2.6418452406092205
Validation loss: 2.579581822142374

Epoch: 6| Step: 4
Training loss: 2.9239559820908863
Validation loss: 2.5718939704371313

Epoch: 6| Step: 5
Training loss: 2.399000468334742
Validation loss: 2.5521478055068454

Epoch: 6| Step: 6
Training loss: 2.9938418443962287
Validation loss: 2.5375614304913525

Epoch: 6| Step: 7
Training loss: 2.4042962800187118
Validation loss: 2.51977585697953

Epoch: 6| Step: 8
Training loss: 2.5867312961874367
Validation loss: 2.5061918039812223

Epoch: 6| Step: 9
Training loss: 2.7798821160824763
Validation loss: 2.5004647889360845

Epoch: 6| Step: 10
Training loss: 2.235962097331237
Validation loss: 2.502877172322046

Epoch: 6| Step: 11
Training loss: 2.9078487797789645
Validation loss: 2.490990791330225

Epoch: 6| Step: 12
Training loss: 2.8242521798462352
Validation loss: 2.5001101131185086

Epoch: 6| Step: 13
Training loss: 2.672031241862455
Validation loss: 2.5008692573525044

Epoch: 170| Step: 0
Training loss: 2.4913698008931244
Validation loss: 2.4970069647599833

Epoch: 6| Step: 1
Training loss: 2.6769399542702317
Validation loss: 2.4947734425083965

Epoch: 6| Step: 2
Training loss: 2.5753915803810035
Validation loss: 2.4800432947010496

Epoch: 6| Step: 3
Training loss: 2.1397932901104855
Validation loss: 2.4829819433612417

Epoch: 6| Step: 4
Training loss: 2.9603238639987928
Validation loss: 2.4745342095175316

Epoch: 6| Step: 5
Training loss: 2.3570961968233504
Validation loss: 2.487889015069548

Epoch: 6| Step: 6
Training loss: 1.9702028030727181
Validation loss: 2.5014922046868233

Epoch: 6| Step: 7
Training loss: 2.411773287567677
Validation loss: 2.5113225010745093

Epoch: 6| Step: 8
Training loss: 2.9919262963769113
Validation loss: 2.524812512263434

Epoch: 6| Step: 9
Training loss: 2.6517770243213796
Validation loss: 2.5455233421352412

Epoch: 6| Step: 10
Training loss: 2.611688741636514
Validation loss: 2.55317453976538

Epoch: 6| Step: 11
Training loss: 3.2196345919246143
Validation loss: 2.5051127840597514

Epoch: 6| Step: 12
Training loss: 2.583971365206053
Validation loss: 2.4794454613437935

Epoch: 6| Step: 13
Training loss: 2.3929085390472236
Validation loss: 2.460535518527818

Epoch: 171| Step: 0
Training loss: 2.9061031509543525
Validation loss: 2.447868926543413

Epoch: 6| Step: 1
Training loss: 2.4579043148713566
Validation loss: 2.464584816203309

Epoch: 6| Step: 2
Training loss: 2.796851131401295
Validation loss: 2.461159773979856

Epoch: 6| Step: 3
Training loss: 2.4196254989009436
Validation loss: 2.4676050220829837

Epoch: 6| Step: 4
Training loss: 2.4670082418538364
Validation loss: 2.4787322446463262

Epoch: 6| Step: 5
Training loss: 2.8876401594749983
Validation loss: 2.4861578338199104

Epoch: 6| Step: 6
Training loss: 2.830555919596863
Validation loss: 2.503318190408071

Epoch: 6| Step: 7
Training loss: 2.1930499924416096
Validation loss: 2.5152464500100082

Epoch: 6| Step: 8
Training loss: 2.3780877971370895
Validation loss: 2.5167589912547186

Epoch: 6| Step: 9
Training loss: 2.4189246141751712
Validation loss: 2.5068877331557866

Epoch: 6| Step: 10
Training loss: 2.6700925179500508
Validation loss: 2.5032135685210433

Epoch: 6| Step: 11
Training loss: 2.8126298662508664
Validation loss: 2.4967123862044676

Epoch: 6| Step: 12
Training loss: 2.0095243170093404
Validation loss: 2.5005755633590967

Epoch: 6| Step: 13
Training loss: 2.176186323554451
Validation loss: 2.490935058332375

Epoch: 172| Step: 0
Training loss: 2.682045035767121
Validation loss: 2.482073754551839

Epoch: 6| Step: 1
Training loss: 2.7334878408755725
Validation loss: 2.5009947869014106

Epoch: 6| Step: 2
Training loss: 2.568379611671701
Validation loss: 2.516577216673938

Epoch: 6| Step: 3
Training loss: 2.736757036529887
Validation loss: 2.522137908338842

Epoch: 6| Step: 4
Training loss: 2.8070754402604203
Validation loss: 2.519213144008778

Epoch: 6| Step: 5
Training loss: 2.6079248293299773
Validation loss: 2.51541348674292

Epoch: 6| Step: 6
Training loss: 2.569968991964577
Validation loss: 2.505586748850846

Epoch: 6| Step: 7
Training loss: 1.9980635208823654
Validation loss: 2.4961254058745523

Epoch: 6| Step: 8
Training loss: 2.578747113624248
Validation loss: 2.479050608153976

Epoch: 6| Step: 9
Training loss: 2.2239087804296007
Validation loss: 2.4912904466119064

Epoch: 6| Step: 10
Training loss: 2.708718570796229
Validation loss: 2.502991519019714

Epoch: 6| Step: 11
Training loss: 2.68925525211631
Validation loss: 2.4962355132634144

Epoch: 6| Step: 12
Training loss: 2.462488273166676
Validation loss: 2.480171288225968

Epoch: 6| Step: 13
Training loss: 1.6455540319454727
Validation loss: 2.4837870465468534

Epoch: 173| Step: 0
Training loss: 2.69140500980786
Validation loss: 2.4828064607226064

Epoch: 6| Step: 1
Training loss: 1.8397624327878015
Validation loss: 2.4982623716787487

Epoch: 6| Step: 2
Training loss: 2.7391834813332934
Validation loss: 2.4964837541770577

Epoch: 6| Step: 3
Training loss: 2.0714782887397627
Validation loss: 2.5016890798246525

Epoch: 6| Step: 4
Training loss: 2.5148314177965334
Validation loss: 2.5146153953381334

Epoch: 6| Step: 5
Training loss: 2.3663864542957094
Validation loss: 2.5131242689451168

Epoch: 6| Step: 6
Training loss: 2.38604217279708
Validation loss: 2.5162981218477407

Epoch: 6| Step: 7
Training loss: 2.618757545624198
Validation loss: 2.5186919376007073

Epoch: 6| Step: 8
Training loss: 3.0888921957966446
Validation loss: 2.538368082430865

Epoch: 6| Step: 9
Training loss: 2.6332272166185775
Validation loss: 2.5497463288747295

Epoch: 6| Step: 10
Training loss: 2.1107815044599745
Validation loss: 2.55081667947168

Epoch: 6| Step: 11
Training loss: 2.847204101835653
Validation loss: 2.555589068063601

Epoch: 6| Step: 12
Training loss: 2.3298367345690374
Validation loss: 2.5544558425038812

Epoch: 6| Step: 13
Training loss: 3.0858314978827335
Validation loss: 2.531101206735076

Epoch: 174| Step: 0
Training loss: 2.419356186876639
Validation loss: 2.5133145748466683

Epoch: 6| Step: 1
Training loss: 2.5417396868446525
Validation loss: 2.4929896909537788

Epoch: 6| Step: 2
Training loss: 2.838141139525773
Validation loss: 2.4804772724796176

Epoch: 6| Step: 3
Training loss: 1.7824182527477301
Validation loss: 2.4810773928778325

Epoch: 6| Step: 4
Training loss: 2.3511894665256605
Validation loss: 2.4654830307195583

Epoch: 6| Step: 5
Training loss: 2.9223686250081675
Validation loss: 2.471018727858828

Epoch: 6| Step: 6
Training loss: 2.373994112324022
Validation loss: 2.4707674521926264

Epoch: 6| Step: 7
Training loss: 2.6473514276733274
Validation loss: 2.479949196542562

Epoch: 6| Step: 8
Training loss: 2.206535999466893
Validation loss: 2.512066624973276

Epoch: 6| Step: 9
Training loss: 2.6709668138528273
Validation loss: 2.5182827597700417

Epoch: 6| Step: 10
Training loss: 2.232342842952544
Validation loss: 2.5166173755985657

Epoch: 6| Step: 11
Training loss: 3.0386830855502485
Validation loss: 2.5134699064081922

Epoch: 6| Step: 12
Training loss: 2.3185692606196353
Validation loss: 2.5365350762234913

Epoch: 6| Step: 13
Training loss: 1.8988034244979795
Validation loss: 2.534440144904009

Epoch: 175| Step: 0
Training loss: 2.6350901003060514
Validation loss: 2.510985021666472

Epoch: 6| Step: 1
Training loss: 2.718909774119444
Validation loss: 2.5136467817769512

Epoch: 6| Step: 2
Training loss: 2.7108503432101285
Validation loss: 2.4797624523764417

Epoch: 6| Step: 3
Training loss: 2.082820778420345
Validation loss: 2.4647818227151843

Epoch: 6| Step: 4
Training loss: 2.0006461291879227
Validation loss: 2.4661908933969543

Epoch: 6| Step: 5
Training loss: 2.086688531551837
Validation loss: 2.4453584557342025

Epoch: 6| Step: 6
Training loss: 1.6436624655968048
Validation loss: 2.442634223688192

Epoch: 6| Step: 7
Training loss: 1.8356155437866244
Validation loss: 2.4394682548745585

Epoch: 6| Step: 8
Training loss: 2.998666784953376
Validation loss: 2.4465976087480845

Epoch: 6| Step: 9
Training loss: 3.095507498255
Validation loss: 2.475262166317742

Epoch: 6| Step: 10
Training loss: 2.16313597748271
Validation loss: 2.4960582011102446

Epoch: 6| Step: 11
Training loss: 2.8041222302872884
Validation loss: 2.5052324614992676

Epoch: 6| Step: 12
Training loss: 2.576244061133264
Validation loss: 2.540632074341664

Epoch: 6| Step: 13
Training loss: 2.7819257622473095
Validation loss: 2.556946918034602

Epoch: 176| Step: 0
Training loss: 2.769747231997262
Validation loss: 2.563318868557575

Epoch: 6| Step: 1
Training loss: 2.980219799358805
Validation loss: 2.5458011594215915

Epoch: 6| Step: 2
Training loss: 2.2696097224156713
Validation loss: 2.533168209215218

Epoch: 6| Step: 3
Training loss: 2.1326016611819187
Validation loss: 2.5237836194976184

Epoch: 6| Step: 4
Training loss: 2.80647293258818
Validation loss: 2.5159657565436335

Epoch: 6| Step: 5
Training loss: 2.716812056959063
Validation loss: 2.5236106027616745

Epoch: 6| Step: 6
Training loss: 2.194446542258675
Validation loss: 2.508013245759841

Epoch: 6| Step: 7
Training loss: 2.801159182790936
Validation loss: 2.510791836481887

Epoch: 6| Step: 8
Training loss: 2.2229041311619064
Validation loss: 2.5033748745590563

Epoch: 6| Step: 9
Training loss: 2.5922279028247313
Validation loss: 2.498252759787144

Epoch: 6| Step: 10
Training loss: 1.6813848391778106
Validation loss: 2.4860961476924412

Epoch: 6| Step: 11
Training loss: 2.3088060723534856
Validation loss: 2.487831323730467

Epoch: 6| Step: 12
Training loss: 2.2352029826863187
Validation loss: 2.471700261429648

Epoch: 6| Step: 13
Training loss: 2.248870036052861
Validation loss: 2.4844367123517985

Epoch: 177| Step: 0
Training loss: 2.079870308537456
Validation loss: 2.4943440148067832

Epoch: 6| Step: 1
Training loss: 2.3828040951439884
Validation loss: 2.501304903235018

Epoch: 6| Step: 2
Training loss: 2.296525370658067
Validation loss: 2.516421879277571

Epoch: 6| Step: 3
Training loss: 2.8860719857018173
Validation loss: 2.5476471071376428

Epoch: 6| Step: 4
Training loss: 1.7044541658173717
Validation loss: 2.5584222225860156

Epoch: 6| Step: 5
Training loss: 2.8441579337497798
Validation loss: 2.592957635683968

Epoch: 6| Step: 6
Training loss: 3.5698320662378693
Validation loss: 2.5709680062432816

Epoch: 6| Step: 7
Training loss: 2.554498321341506
Validation loss: 2.551010254472855

Epoch: 6| Step: 8
Training loss: 2.7344820710063678
Validation loss: 2.5147478718009166

Epoch: 6| Step: 9
Training loss: 2.472939521750353
Validation loss: 2.503672357492842

Epoch: 6| Step: 10
Training loss: 2.2137401058034074
Validation loss: 2.493786424186866

Epoch: 6| Step: 11
Training loss: 2.1489850820287195
Validation loss: 2.496519743702557

Epoch: 6| Step: 12
Training loss: 2.044958134341561
Validation loss: 2.5032206442928993

Epoch: 6| Step: 13
Training loss: 1.9553586470865036
Validation loss: 2.5074277371867573

Epoch: 178| Step: 0
Training loss: 2.961345875944358
Validation loss: 2.49961628378939

Epoch: 6| Step: 1
Training loss: 2.4499633241360605
Validation loss: 2.5106478348812122

Epoch: 6| Step: 2
Training loss: 2.669402467536772
Validation loss: 2.515894321095263

Epoch: 6| Step: 3
Training loss: 2.0363386530396363
Validation loss: 2.520580923538432

Epoch: 6| Step: 4
Training loss: 2.213613447633627
Validation loss: 2.505760990651735

Epoch: 6| Step: 5
Training loss: 2.236718289518159
Validation loss: 2.492630425853357

Epoch: 6| Step: 6
Training loss: 2.432227276120609
Validation loss: 2.506280705644361

Epoch: 6| Step: 7
Training loss: 2.840708856635348
Validation loss: 2.525807914071566

Epoch: 6| Step: 8
Training loss: 2.2108317103873043
Validation loss: 2.5520764908103466

Epoch: 6| Step: 9
Training loss: 2.569960828104098
Validation loss: 2.5697964420976964

Epoch: 6| Step: 10
Training loss: 2.6015645161755514
Validation loss: 2.5764397973781783

Epoch: 6| Step: 11
Training loss: 1.5332415339038536
Validation loss: 2.554770390141509

Epoch: 6| Step: 12
Training loss: 2.2859595818538403
Validation loss: 2.5441997606861255

Epoch: 6| Step: 13
Training loss: 2.763018656929638
Validation loss: 2.500778899321273

Epoch: 179| Step: 0
Training loss: 1.763540472160546
Validation loss: 2.509965647681477

Epoch: 6| Step: 1
Training loss: 1.6509233867584294
Validation loss: 2.48824815803296

Epoch: 6| Step: 2
Training loss: 2.317923089411142
Validation loss: 2.4955296135447034

Epoch: 6| Step: 3
Training loss: 2.517517136455804
Validation loss: 2.492172541023596

Epoch: 6| Step: 4
Training loss: 3.255243619600416
Validation loss: 2.4847542552025392

Epoch: 6| Step: 5
Training loss: 3.055783126525412
Validation loss: 2.473895705012716

Epoch: 6| Step: 6
Training loss: 2.177658285000585
Validation loss: 2.4760981422962844

Epoch: 6| Step: 7
Training loss: 2.3251446586644495
Validation loss: 2.46557486111025

Epoch: 6| Step: 8
Training loss: 2.712516830321805
Validation loss: 2.4615206286540277

Epoch: 6| Step: 9
Training loss: 2.5337921375446246
Validation loss: 2.4563843530756198

Epoch: 6| Step: 10
Training loss: 2.040592014577754
Validation loss: 2.486702510111675

Epoch: 6| Step: 11
Training loss: 2.014683111560859
Validation loss: 2.516940796505489

Epoch: 6| Step: 12
Training loss: 2.67670534980853
Validation loss: 2.548864183087161

Epoch: 6| Step: 13
Training loss: 2.6596877347892054
Validation loss: 2.5316019759210926

Epoch: 180| Step: 0
Training loss: 2.1805757196335045
Validation loss: 2.517260539066495

Epoch: 6| Step: 1
Training loss: 2.101361233174248
Validation loss: 2.525932250947887

Epoch: 6| Step: 2
Training loss: 2.3685986432759067
Validation loss: 2.521286006370648

Epoch: 6| Step: 3
Training loss: 2.261019636559028
Validation loss: 2.508035216397579

Epoch: 6| Step: 4
Training loss: 2.7568306620510543
Validation loss: 2.5239887453910668

Epoch: 6| Step: 5
Training loss: 2.7230121046141167
Validation loss: 2.523802204369953

Epoch: 6| Step: 6
Training loss: 2.775606322849503
Validation loss: 2.517559850587236

Epoch: 6| Step: 7
Training loss: 2.1480016647772846
Validation loss: 2.515624219379267

Epoch: 6| Step: 8
Training loss: 1.8359221112844093
Validation loss: 2.5308729828068457

Epoch: 6| Step: 9
Training loss: 2.831425379695911
Validation loss: 2.5504785758998594

Epoch: 6| Step: 10
Training loss: 2.6462229244124607
Validation loss: 2.535556306781209

Epoch: 6| Step: 11
Training loss: 2.608673732430514
Validation loss: 2.5466261021815697

Epoch: 6| Step: 12
Training loss: 1.8820882330185973
Validation loss: 2.5462417373910995

Epoch: 6| Step: 13
Training loss: 1.757520456425654
Validation loss: 2.5432283219140186

Epoch: 181| Step: 0
Training loss: 1.8578446445619818
Validation loss: 2.5527409218432737

Epoch: 6| Step: 1
Training loss: 1.6092221085598266
Validation loss: 2.542955962859153

Epoch: 6| Step: 2
Training loss: 2.277974743067559
Validation loss: 2.5477298741518695

Epoch: 6| Step: 3
Training loss: 2.1593090969247575
Validation loss: 2.5240231563959457

Epoch: 6| Step: 4
Training loss: 2.5808859173504137
Validation loss: 2.5375771170180452

Epoch: 6| Step: 5
Training loss: 2.90880185555209
Validation loss: 2.519900608485655

Epoch: 6| Step: 6
Training loss: 2.5003891641987708
Validation loss: 2.515524999085281

Epoch: 6| Step: 7
Training loss: 2.0895402634486953
Validation loss: 2.5062986981528663

Epoch: 6| Step: 8
Training loss: 2.6768414478394753
Validation loss: 2.4935255794046935

Epoch: 6| Step: 9
Training loss: 2.410166834679705
Validation loss: 2.4925456584829284

Epoch: 6| Step: 10
Training loss: 2.3359605666842933
Validation loss: 2.5017504890718745

Epoch: 6| Step: 11
Training loss: 2.243717110480462
Validation loss: 2.4887172421129136

Epoch: 6| Step: 12
Training loss: 2.657708878153901
Validation loss: 2.4899451872015472

Epoch: 6| Step: 13
Training loss: 2.6430640158086596
Validation loss: 2.5039225272173873

Epoch: 182| Step: 0
Training loss: 2.885599582717988
Validation loss: 2.5067190140647577

Epoch: 6| Step: 1
Training loss: 2.521654378890888
Validation loss: 2.5272268106665576

Epoch: 6| Step: 2
Training loss: 1.964336109753445
Validation loss: 2.549441570041764

Epoch: 6| Step: 3
Training loss: 2.2468626613569964
Validation loss: 2.5700435757692466

Epoch: 6| Step: 4
Training loss: 2.3921326514496113
Validation loss: 2.5883228698698155

Epoch: 6| Step: 5
Training loss: 2.8258765962064416
Validation loss: 2.5898911411741214

Epoch: 6| Step: 6
Training loss: 2.6578251375843176
Validation loss: 2.6123965422311826

Epoch: 6| Step: 7
Training loss: 1.5306852428065596
Validation loss: 2.6346582302820982

Epoch: 6| Step: 8
Training loss: 2.889200880451219
Validation loss: 2.594683866858832

Epoch: 6| Step: 9
Training loss: 2.2724221180746422
Validation loss: 2.5816282989547465

Epoch: 6| Step: 10
Training loss: 2.3246703662797294
Validation loss: 2.5732718382780653

Epoch: 6| Step: 11
Training loss: 1.7807927130263022
Validation loss: 2.5400738242908245

Epoch: 6| Step: 12
Training loss: 2.1256417819995166
Validation loss: 2.5365368469448457

Epoch: 6| Step: 13
Training loss: 2.3395149114516327
Validation loss: 2.4967439828957394

Epoch: 183| Step: 0
Training loss: 2.0558616851265996
Validation loss: 2.464624246434137

Epoch: 6| Step: 1
Training loss: 2.9803898752157534
Validation loss: 2.426560666523143

Epoch: 6| Step: 2
Training loss: 1.975668361903588
Validation loss: 2.4068821371163773

Epoch: 6| Step: 3
Training loss: 1.3578384748110002
Validation loss: 2.389995120125878

Epoch: 6| Step: 4
Training loss: 2.7078561998331097
Validation loss: 2.406139246044858

Epoch: 6| Step: 5
Training loss: 2.328491796490957
Validation loss: 2.3984239700853394

Epoch: 6| Step: 6
Training loss: 2.673800215425696
Validation loss: 2.395955547481033

Epoch: 6| Step: 7
Training loss: 1.9876935948546917
Validation loss: 2.4124222449770167

Epoch: 6| Step: 8
Training loss: 2.8760874806178953
Validation loss: 2.39472071550439

Epoch: 6| Step: 9
Training loss: 1.8534484143628005
Validation loss: 2.417697373401704

Epoch: 6| Step: 10
Training loss: 2.781555501896706
Validation loss: 2.449001116205386

Epoch: 6| Step: 11
Training loss: 2.4161888066657347
Validation loss: 2.4922044647819273

Epoch: 6| Step: 12
Training loss: 2.5405794747228065
Validation loss: 2.5404459864573306

Epoch: 6| Step: 13
Training loss: 2.488462911588902
Validation loss: 2.6034038146650746

Epoch: 184| Step: 0
Training loss: 2.699122999952405
Validation loss: 2.6599965763987523

Epoch: 6| Step: 1
Training loss: 2.304421309276625
Validation loss: 2.7006792997861826

Epoch: 6| Step: 2
Training loss: 2.131210228333544
Validation loss: 2.717427717766529

Epoch: 6| Step: 3
Training loss: 3.153175594048688
Validation loss: 2.716323844975374

Epoch: 6| Step: 4
Training loss: 2.3663684195878925
Validation loss: 2.7006697986490953

Epoch: 6| Step: 5
Training loss: 1.6752416635660827
Validation loss: 2.624519177146973

Epoch: 6| Step: 6
Training loss: 2.6820485026434975
Validation loss: 2.5718017147832293

Epoch: 6| Step: 7
Training loss: 2.5097984935226134
Validation loss: 2.567166096682709

Epoch: 6| Step: 8
Training loss: 2.096083977072586
Validation loss: 2.517772742424002

Epoch: 6| Step: 9
Training loss: 2.4703798346417876
Validation loss: 2.489778752396907

Epoch: 6| Step: 10
Training loss: 2.3122819333745617
Validation loss: 2.47741447615768

Epoch: 6| Step: 11
Training loss: 2.1713197945295777
Validation loss: 2.4499371933059666

Epoch: 6| Step: 12
Training loss: 2.552449123611573
Validation loss: 2.4475054568105308

Epoch: 6| Step: 13
Training loss: 1.7314783599849555
Validation loss: 2.424403905512719

Epoch: 185| Step: 0
Training loss: 2.655887893229646
Validation loss: 2.4236480457463427

Epoch: 6| Step: 1
Training loss: 2.434578734504586
Validation loss: 2.452156047443568

Epoch: 6| Step: 2
Training loss: 2.3277229115472258
Validation loss: 2.428129779059603

Epoch: 6| Step: 3
Training loss: 2.124434676424995
Validation loss: 2.415308227005426

Epoch: 6| Step: 4
Training loss: 2.134646231758209
Validation loss: 2.402942501819235

Epoch: 6| Step: 5
Training loss: 2.098394906754299
Validation loss: 2.398814724935455

Epoch: 6| Step: 6
Training loss: 2.6635387274932656
Validation loss: 2.406608909557222

Epoch: 6| Step: 7
Training loss: 2.2686049233702734
Validation loss: 2.410004585400294

Epoch: 6| Step: 8
Training loss: 2.339825001229142
Validation loss: 2.425242245449464

Epoch: 6| Step: 9
Training loss: 2.3050283406267544
Validation loss: 2.44177725360661

Epoch: 6| Step: 10
Training loss: 2.5510666878842496
Validation loss: 2.426927901580324

Epoch: 6| Step: 11
Training loss: 2.534587778738366
Validation loss: 2.455233796495666

Epoch: 6| Step: 12
Training loss: 1.9134924214823303
Validation loss: 2.4536462557507477

Epoch: 6| Step: 13
Training loss: 2.0599888629056737
Validation loss: 2.4909222449079955

Epoch: 186| Step: 0
Training loss: 2.2779125726817826
Validation loss: 2.5023530776479594

Epoch: 6| Step: 1
Training loss: 2.554744988124197
Validation loss: 2.4958640752337073

Epoch: 6| Step: 2
Training loss: 2.2381684439628367
Validation loss: 2.5019720421227913

Epoch: 6| Step: 3
Training loss: 2.3442683346106525
Validation loss: 2.516334401565207

Epoch: 6| Step: 4
Training loss: 2.047425290748727
Validation loss: 2.5318511548827085

Epoch: 6| Step: 5
Training loss: 2.3576977559679047
Validation loss: 2.5303934405979103

Epoch: 6| Step: 6
Training loss: 1.8153939656585059
Validation loss: 2.4965304695015353

Epoch: 6| Step: 7
Training loss: 2.2984968415048375
Validation loss: 2.478620455733495

Epoch: 6| Step: 8
Training loss: 2.440406924382384
Validation loss: 2.464382495816973

Epoch: 6| Step: 9
Training loss: 2.3756399798203227
Validation loss: 2.4927834447528316

Epoch: 6| Step: 10
Training loss: 2.451805975003426
Validation loss: 2.4918169688743

Epoch: 6| Step: 11
Training loss: 2.337209501931825
Validation loss: 2.503325723654229

Epoch: 6| Step: 12
Training loss: 2.197091464451975
Validation loss: 2.5157379581580996

Epoch: 6| Step: 13
Training loss: 2.3550225336572055
Validation loss: 2.506159205266718

Epoch: 187| Step: 0
Training loss: 2.7073977003557945
Validation loss: 2.505939014743418

Epoch: 6| Step: 1
Training loss: 2.472236392758032
Validation loss: 2.5349492547371724

Epoch: 6| Step: 2
Training loss: 1.958485867937964
Validation loss: 2.5033067870620624

Epoch: 6| Step: 3
Training loss: 2.5773053340124457
Validation loss: 2.488760102362064

Epoch: 6| Step: 4
Training loss: 2.2592414109452066
Validation loss: 2.482906097948604

Epoch: 6| Step: 5
Training loss: 2.008762951033502
Validation loss: 2.4809844571549955

Epoch: 6| Step: 6
Training loss: 2.439597279036156
Validation loss: 2.478174359660301

Epoch: 6| Step: 7
Training loss: 2.0789736972262407
Validation loss: 2.4622664043941596

Epoch: 6| Step: 8
Training loss: 1.99962016313448
Validation loss: 2.4822064769193215

Epoch: 6| Step: 9
Training loss: 2.5482825385903296
Validation loss: 2.4909703561453846

Epoch: 6| Step: 10
Training loss: 2.2562104451524334
Validation loss: 2.4989928780595863

Epoch: 6| Step: 11
Training loss: 2.1582877440283417
Validation loss: 2.5019061276983376

Epoch: 6| Step: 12
Training loss: 2.2193233125383447
Validation loss: 2.5054118861036763

Epoch: 6| Step: 13
Training loss: 1.6909855766561064
Validation loss: 2.536942281292422

Epoch: 188| Step: 0
Training loss: 2.2532782514412126
Validation loss: 2.5416483216923975

Epoch: 6| Step: 1
Training loss: 2.3516263731332656
Validation loss: 2.5594382504219646

Epoch: 6| Step: 2
Training loss: 2.6002448700255596
Validation loss: 2.5526920947825125

Epoch: 6| Step: 3
Training loss: 2.398779630333888
Validation loss: 2.5448535653177626

Epoch: 6| Step: 4
Training loss: 1.9898922132889039
Validation loss: 2.564918142448313

Epoch: 6| Step: 5
Training loss: 1.9020438143861151
Validation loss: 2.553908735998365

Epoch: 6| Step: 6
Training loss: 1.1076354774467738
Validation loss: 2.555012737212159

Epoch: 6| Step: 7
Training loss: 2.100878749640473
Validation loss: 2.546867810975309

Epoch: 6| Step: 8
Training loss: 2.6855015976296834
Validation loss: 2.5413738867501383

Epoch: 6| Step: 9
Training loss: 2.2853123277361314
Validation loss: 2.5670009255015627

Epoch: 6| Step: 10
Training loss: 1.8368461795089195
Validation loss: 2.5470246311877127

Epoch: 6| Step: 11
Training loss: 2.7154684322336577
Validation loss: 2.5309828517631727

Epoch: 6| Step: 12
Training loss: 2.285081650258027
Validation loss: 2.5295132870250576

Epoch: 6| Step: 13
Training loss: 2.182470916694098
Validation loss: 2.511064138456226

Epoch: 189| Step: 0
Training loss: 1.6052424139043489
Validation loss: 2.5083806107409687

Epoch: 6| Step: 1
Training loss: 2.273632342716428
Validation loss: 2.4944588174141007

Epoch: 6| Step: 2
Training loss: 2.3474008227635905
Validation loss: 2.4939410518254475

Epoch: 6| Step: 3
Training loss: 2.144634862734915
Validation loss: 2.47941337123861

Epoch: 6| Step: 4
Training loss: 2.302966390088699
Validation loss: 2.470747681896536

Epoch: 6| Step: 5
Training loss: 2.5201746392665614
Validation loss: 2.4761829581620405

Epoch: 6| Step: 6
Training loss: 1.5337353991223108
Validation loss: 2.470826390683846

Epoch: 6| Step: 7
Training loss: 2.465725941882267
Validation loss: 2.4889654923014475

Epoch: 6| Step: 8
Training loss: 2.537429425239987
Validation loss: 2.4928297820641547

Epoch: 6| Step: 9
Training loss: 1.7661563445123165
Validation loss: 2.463140005417307

Epoch: 6| Step: 10
Training loss: 2.2579670889443584
Validation loss: 2.454418904215341

Epoch: 6| Step: 11
Training loss: 2.351033908581613
Validation loss: 2.462217019071003

Epoch: 6| Step: 12
Training loss: 2.4618127628777486
Validation loss: 2.4558241013324307

Epoch: 6| Step: 13
Training loss: 1.9609792028605284
Validation loss: 2.4688871362971967

Epoch: 190| Step: 0
Training loss: 1.8279173643436786
Validation loss: 2.5081977189306186

Epoch: 6| Step: 1
Training loss: 2.0392880369835997
Validation loss: 2.551355540352741

Epoch: 6| Step: 2
Training loss: 2.3898915680425197
Validation loss: 2.5781983465486342

Epoch: 6| Step: 3
Training loss: 2.4193699833180577
Validation loss: 2.5891227084075368

Epoch: 6| Step: 4
Training loss: 1.7081039864021854
Validation loss: 2.58301209613544

Epoch: 6| Step: 5
Training loss: 2.465675274199807
Validation loss: 2.603617843057595

Epoch: 6| Step: 6
Training loss: 2.0936507016448678
Validation loss: 2.6050535802523362

Epoch: 6| Step: 7
Training loss: 2.6617405412709574
Validation loss: 2.61777495058976

Epoch: 6| Step: 8
Training loss: 1.9812695090118577
Validation loss: 2.608838259064349

Epoch: 6| Step: 9
Training loss: 2.571484979510363
Validation loss: 2.5910486574213913

Epoch: 6| Step: 10
Training loss: 2.218858420718327
Validation loss: 2.553268875155167

Epoch: 6| Step: 11
Training loss: 2.103302416183788
Validation loss: 2.522850970927658

Epoch: 6| Step: 12
Training loss: 1.8881056843249144
Validation loss: 2.4764660263020364

Epoch: 6| Step: 13
Training loss: 1.7560474944198068
Validation loss: 2.44718331841823

Epoch: 191| Step: 0
Training loss: 2.3209207167916817
Validation loss: 2.4444257254068686

Epoch: 6| Step: 1
Training loss: 2.2439047587373624
Validation loss: 2.455330581340251

Epoch: 6| Step: 2
Training loss: 1.6762033922285595
Validation loss: 2.4703851022633123

Epoch: 6| Step: 3
Training loss: 2.487765990944869
Validation loss: 2.457691035372963

Epoch: 6| Step: 4
Training loss: 2.165262598758412
Validation loss: 2.4506280869539414

Epoch: 6| Step: 5
Training loss: 1.8063204424892583
Validation loss: 2.4602583107305005

Epoch: 6| Step: 6
Training loss: 2.2786104791714172
Validation loss: 2.4607954451421064

Epoch: 6| Step: 7
Training loss: 1.9004095690136849
Validation loss: 2.4681580159435503

Epoch: 6| Step: 8
Training loss: 2.127712313931781
Validation loss: 2.4817516788986995

Epoch: 6| Step: 9
Training loss: 1.9689424208809116
Validation loss: 2.488877073257842

Epoch: 6| Step: 10
Training loss: 2.1272437647572238
Validation loss: 2.513882942293142

Epoch: 6| Step: 11
Training loss: 2.030380062736461
Validation loss: 2.5410211406717673

Epoch: 6| Step: 12
Training loss: 2.639241776099712
Validation loss: 2.5522021726589212

Epoch: 6| Step: 13
Training loss: 2.094013140639907
Validation loss: 2.536365300551286

Epoch: 192| Step: 0
Training loss: 1.981280218910785
Validation loss: 2.5808001597961274

Epoch: 6| Step: 1
Training loss: 2.221486512892962
Validation loss: 2.585392119351847

Epoch: 6| Step: 2
Training loss: 1.8693574562384627
Validation loss: 2.5898000898807467

Epoch: 6| Step: 3
Training loss: 2.1807572122402332
Validation loss: 2.5956478734154027

Epoch: 6| Step: 4
Training loss: 2.3123081230771527
Validation loss: 2.6040964057221996

Epoch: 6| Step: 5
Training loss: 1.8215562230746603
Validation loss: 2.562021474430119

Epoch: 6| Step: 6
Training loss: 2.1647204559139266
Validation loss: 2.5277859633657767

Epoch: 6| Step: 7
Training loss: 2.5455088315475978
Validation loss: 2.4926168497739702

Epoch: 6| Step: 8
Training loss: 1.9369301727108077
Validation loss: 2.4699746642271188

Epoch: 6| Step: 9
Training loss: 2.319074615212467
Validation loss: 2.469144749886793

Epoch: 6| Step: 10
Training loss: 2.070380098210982
Validation loss: 2.4950141498398626

Epoch: 6| Step: 11
Training loss: 2.4179896537111363
Validation loss: 2.5185990126493834

Epoch: 6| Step: 12
Training loss: 2.2835895612680215
Validation loss: 2.5462933551907656

Epoch: 6| Step: 13
Training loss: 2.0348492938199554
Validation loss: 2.541273909438056

Epoch: 193| Step: 0
Training loss: 2.771579431647045
Validation loss: 2.478164499939411

Epoch: 6| Step: 1
Training loss: 2.415202738779745
Validation loss: 2.4318080986262007

Epoch: 6| Step: 2
Training loss: 1.8776869912117786
Validation loss: 2.4192234498583263

Epoch: 6| Step: 3
Training loss: 1.333991836817413
Validation loss: 2.411951033910303

Epoch: 6| Step: 4
Training loss: 2.2643412142704014
Validation loss: 2.4380655981357973

Epoch: 6| Step: 5
Training loss: 2.3019578188918395
Validation loss: 2.4260134183023627

Epoch: 6| Step: 6
Training loss: 2.1360535082955
Validation loss: 2.4459577753039983

Epoch: 6| Step: 7
Training loss: 1.6877034382579816
Validation loss: 2.4541236449420656

Epoch: 6| Step: 8
Training loss: 2.286563381368507
Validation loss: 2.478635875050974

Epoch: 6| Step: 9
Training loss: 1.547711695179061
Validation loss: 2.4624214340560227

Epoch: 6| Step: 10
Training loss: 2.6308779528216095
Validation loss: 2.4960355046890226

Epoch: 6| Step: 11
Training loss: 2.6346774867694056
Validation loss: 2.5149884935537123

Epoch: 6| Step: 12
Training loss: 1.8763123687808136
Validation loss: 2.519951781065325

Epoch: 6| Step: 13
Training loss: 1.9706423913615956
Validation loss: 2.5424344258002374

Epoch: 194| Step: 0
Training loss: 1.854167409603813
Validation loss: 2.561346762504057

Epoch: 6| Step: 1
Training loss: 2.0337022504025106
Validation loss: 2.553273839233609

Epoch: 6| Step: 2
Training loss: 2.649642085250693
Validation loss: 2.567386749749726

Epoch: 6| Step: 3
Training loss: 1.9476866424796626
Validation loss: 2.570975866764372

Epoch: 6| Step: 4
Training loss: 2.6699149097499673
Validation loss: 2.5844942253894723

Epoch: 6| Step: 5
Training loss: 1.628389564735412
Validation loss: 2.5920681334414994

Epoch: 6| Step: 6
Training loss: 1.971603868225538
Validation loss: 2.5794591609377386

Epoch: 6| Step: 7
Training loss: 2.1950679113357694
Validation loss: 2.570102753284673

Epoch: 6| Step: 8
Training loss: 2.540521384515762
Validation loss: 2.567466756591466

Epoch: 6| Step: 9
Training loss: 1.6812970633460538
Validation loss: 2.5631490356161075

Epoch: 6| Step: 10
Training loss: 1.6450071393817547
Validation loss: 2.575256518903769

Epoch: 6| Step: 11
Training loss: 1.974464539480673
Validation loss: 2.5755271245049536

Epoch: 6| Step: 12
Training loss: 2.1833677226068864
Validation loss: 2.5739323527372333

Epoch: 6| Step: 13
Training loss: 2.3080331086109522
Validation loss: 2.5664123574041553

Epoch: 195| Step: 0
Training loss: 1.6412332043220543
Validation loss: 2.5625675761758973

Epoch: 6| Step: 1
Training loss: 1.9134747283917413
Validation loss: 2.5428866839478435

Epoch: 6| Step: 2
Training loss: 1.9188163422786215
Validation loss: 2.5227975808916274

Epoch: 6| Step: 3
Training loss: 2.051877497178556
Validation loss: 2.5092846695876116

Epoch: 6| Step: 4
Training loss: 2.537334617148693
Validation loss: 2.525895883768006

Epoch: 6| Step: 5
Training loss: 2.3480649773219286
Validation loss: 2.5210646283639098

Epoch: 6| Step: 6
Training loss: 1.8200539335706394
Validation loss: 2.553509298566161

Epoch: 6| Step: 7
Training loss: 1.5791198314206822
Validation loss: 2.57522720655078

Epoch: 6| Step: 8
Training loss: 2.3055878513122003
Validation loss: 2.5399051309916327

Epoch: 6| Step: 9
Training loss: 2.5948917679459225
Validation loss: 2.5666242355730287

Epoch: 6| Step: 10
Training loss: 2.0808246258039267
Validation loss: 2.5368498990374513

Epoch: 6| Step: 11
Training loss: 2.3499330470510342
Validation loss: 2.52124768191506

Epoch: 6| Step: 12
Training loss: 1.952441164466142
Validation loss: 2.4939118517759273

Epoch: 6| Step: 13
Training loss: 1.836746297392015
Validation loss: 2.481966885078001

Epoch: 196| Step: 0
Training loss: 2.2839617354065433
Validation loss: 2.493461062056353

Epoch: 6| Step: 1
Training loss: 2.4876921958092177
Validation loss: 2.4865516357397333

Epoch: 6| Step: 2
Training loss: 2.058858257289316
Validation loss: 2.5041458373351535

Epoch: 6| Step: 3
Training loss: 2.0417065778710883
Validation loss: 2.508930813480536

Epoch: 6| Step: 4
Training loss: 1.8574128897817634
Validation loss: 2.5215885600926464

Epoch: 6| Step: 5
Training loss: 2.0524723310382855
Validation loss: 2.5145176222303047

Epoch: 6| Step: 6
Training loss: 1.6949485001293758
Validation loss: 2.5158913375262917

Epoch: 6| Step: 7
Training loss: 1.7389962429644388
Validation loss: 2.5036087242032172

Epoch: 6| Step: 8
Training loss: 2.2108856302923394
Validation loss: 2.4681124161778625

Epoch: 6| Step: 9
Training loss: 1.6332452374010353
Validation loss: 2.4597709394899367

Epoch: 6| Step: 10
Training loss: 2.401526434583517
Validation loss: 2.445698763384912

Epoch: 6| Step: 11
Training loss: 2.5544145070776016
Validation loss: 2.435166515926527

Epoch: 6| Step: 12
Training loss: 1.8510024756935912
Validation loss: 2.4398451178945586

Epoch: 6| Step: 13
Training loss: 1.7833901648809471
Validation loss: 2.466383604017652

Epoch: 197| Step: 0
Training loss: 1.8431854676902277
Validation loss: 2.466902397014414

Epoch: 6| Step: 1
Training loss: 1.8451938471491631
Validation loss: 2.501200257607746

Epoch: 6| Step: 2
Training loss: 2.2603440397581225
Validation loss: 2.530842208271651

Epoch: 6| Step: 3
Training loss: 2.1470826471960462
Validation loss: 2.554124675637686

Epoch: 6| Step: 4
Training loss: 2.2633169058801443
Validation loss: 2.5753892052667013

Epoch: 6| Step: 5
Training loss: 2.174028824335254
Validation loss: 2.5777802058728745

Epoch: 6| Step: 6
Training loss: 2.1318591995123435
Validation loss: 2.5641814187129963

Epoch: 6| Step: 7
Training loss: 1.8564751074344967
Validation loss: 2.586942088915382

Epoch: 6| Step: 8
Training loss: 2.4866274813035276
Validation loss: 2.5665673101915556

Epoch: 6| Step: 9
Training loss: 1.8339219087762773
Validation loss: 2.5404659661465736

Epoch: 6| Step: 10
Training loss: 2.171168809425798
Validation loss: 2.537444240673337

Epoch: 6| Step: 11
Training loss: 1.7052015192186611
Validation loss: 2.501456109914028

Epoch: 6| Step: 12
Training loss: 2.029528078744443
Validation loss: 2.4943939747652144

Epoch: 6| Step: 13
Training loss: 1.2481637819365237
Validation loss: 2.484550737638148

Epoch: 198| Step: 0
Training loss: 2.0423266712916637
Validation loss: 2.450837259332101

Epoch: 6| Step: 1
Training loss: 2.0426963493258894
Validation loss: 2.451058719279811

Epoch: 6| Step: 2
Training loss: 1.6804821884632362
Validation loss: 2.4535150812838014

Epoch: 6| Step: 3
Training loss: 1.7396087035501073
Validation loss: 2.4560330107188233

Epoch: 6| Step: 4
Training loss: 2.0634469834900813
Validation loss: 2.4853396053209105

Epoch: 6| Step: 5
Training loss: 1.945936110707221
Validation loss: 2.4926238363216346

Epoch: 6| Step: 6
Training loss: 2.0362236752807696
Validation loss: 2.5208136153426683

Epoch: 6| Step: 7
Training loss: 2.1339459324487926
Validation loss: 2.533107337953137

Epoch: 6| Step: 8
Training loss: 1.9018215582864204
Validation loss: 2.5382882421160744

Epoch: 6| Step: 9
Training loss: 1.6856778514979551
Validation loss: 2.553391682055503

Epoch: 6| Step: 10
Training loss: 2.0570013557692954
Validation loss: 2.553755355157233

Epoch: 6| Step: 11
Training loss: 2.3464758725343295
Validation loss: 2.5888891700942116

Epoch: 6| Step: 12
Training loss: 2.319559302566714
Validation loss: 2.593460970293964

Epoch: 6| Step: 13
Training loss: 1.8757020271854477
Validation loss: 2.56135750909728

Epoch: 199| Step: 0
Training loss: 1.5791530470986301
Validation loss: 2.543632354075807

Epoch: 6| Step: 1
Training loss: 2.3342667029817767
Validation loss: 2.504377683336942

Epoch: 6| Step: 2
Training loss: 1.8249703600841156
Validation loss: 2.5173080858174752

Epoch: 6| Step: 3
Training loss: 2.1408321530982426
Validation loss: 2.5006278090610596

Epoch: 6| Step: 4
Training loss: 1.7004949578443485
Validation loss: 2.4933838183488453

Epoch: 6| Step: 5
Training loss: 1.6552096284253492
Validation loss: 2.4987343896831726

Epoch: 6| Step: 6
Training loss: 1.6134158764102595
Validation loss: 2.469056834827108

Epoch: 6| Step: 7
Training loss: 2.2951339039353256
Validation loss: 2.45605599068942

Epoch: 6| Step: 8
Training loss: 2.1839359131377623
Validation loss: 2.462685989752699

Epoch: 6| Step: 9
Training loss: 1.5654200924241968
Validation loss: 2.4709693971110176

Epoch: 6| Step: 10
Training loss: 2.1384794523167523
Validation loss: 2.4585989350975894

Epoch: 6| Step: 11
Training loss: 2.0179262257938424
Validation loss: 2.466498640587862

Epoch: 6| Step: 12
Training loss: 1.6578275976473302
Validation loss: 2.4903525747597697

Epoch: 6| Step: 13
Training loss: 3.020399514102808
Validation loss: 2.499816931923085

Epoch: 200| Step: 0
Training loss: 1.711038107505053
Validation loss: 2.498554349094097

Epoch: 6| Step: 1
Training loss: 2.0287088785099545
Validation loss: 2.517359903797562

Epoch: 6| Step: 2
Training loss: 1.7673100220749576
Validation loss: 2.5427138398619378

Epoch: 6| Step: 3
Training loss: 1.8363973488060874
Validation loss: 2.5254206640118357

Epoch: 6| Step: 4
Training loss: 1.8067629551067415
Validation loss: 2.522556521074784

Epoch: 6| Step: 5
Training loss: 1.9313337585655923
Validation loss: 2.516397354446397

Epoch: 6| Step: 6
Training loss: 1.7638632162567063
Validation loss: 2.5091023545434665

Epoch: 6| Step: 7
Training loss: 1.952584397840072
Validation loss: 2.529165443917064

Epoch: 6| Step: 8
Training loss: 2.218173314759034
Validation loss: 2.4887667773200177

Epoch: 6| Step: 9
Training loss: 2.19718011986409
Validation loss: 2.5084363168982766

Epoch: 6| Step: 10
Training loss: 1.7984286018900477
Validation loss: 2.516482418614601

Epoch: 6| Step: 11
Training loss: 1.8440703420855313
Validation loss: 2.5145526165322316

Epoch: 6| Step: 12
Training loss: 2.283644895342996
Validation loss: 2.537743315302915

Epoch: 6| Step: 13
Training loss: 2.0646372039059164
Validation loss: 2.565044088093689

Epoch: 201| Step: 0
Training loss: 2.159072355710856
Validation loss: 2.5905794102234307

Epoch: 6| Step: 1
Training loss: 1.978553523070679
Validation loss: 2.591255758922682

Epoch: 6| Step: 2
Training loss: 1.77890422353516
Validation loss: 2.6130427274933994

Epoch: 6| Step: 3
Training loss: 2.054712099573512
Validation loss: 2.598082290686712

Epoch: 6| Step: 4
Training loss: 2.354524793363509
Validation loss: 2.602875017994119

Epoch: 6| Step: 5
Training loss: 1.7409571250311995
Validation loss: 2.5538048204157797

Epoch: 6| Step: 6
Training loss: 2.0949682989885767
Validation loss: 2.527410043752064

Epoch: 6| Step: 7
Training loss: 2.0419683687635226
Validation loss: 2.523429368468029

Epoch: 6| Step: 8
Training loss: 1.7672685383666058
Validation loss: 2.503090095181918

Epoch: 6| Step: 9
Training loss: 2.003151556306147
Validation loss: 2.504634606686829

Epoch: 6| Step: 10
Training loss: 1.3193398227817976
Validation loss: 2.505305155681417

Epoch: 6| Step: 11
Training loss: 1.319018073654419
Validation loss: 2.4801383412981672

Epoch: 6| Step: 12
Training loss: 2.23619645576493
Validation loss: 2.489468270706913

Epoch: 6| Step: 13
Training loss: 1.4454245858934491
Validation loss: 2.498421314120402

Epoch: 202| Step: 0
Training loss: 2.1304406472322563
Validation loss: 2.5230858330216357

Epoch: 6| Step: 1
Training loss: 2.0511301089066314
Validation loss: 2.4914764645991574

Epoch: 6| Step: 2
Training loss: 1.8784920916051966
Validation loss: 2.508040530658502

Epoch: 6| Step: 3
Training loss: 1.360997733218669
Validation loss: 2.4944234466631223

Epoch: 6| Step: 4
Training loss: 2.122467776212296
Validation loss: 2.499236289655087

Epoch: 6| Step: 5
Training loss: 1.9782389892711358
Validation loss: 2.446696770039599

Epoch: 6| Step: 6
Training loss: 1.4900122160698803
Validation loss: 2.4540425733361126

Epoch: 6| Step: 7
Training loss: 1.2056920792194739
Validation loss: 2.439142773197219

Epoch: 6| Step: 8
Training loss: 2.34327367392827
Validation loss: 2.4422459892353796

Epoch: 6| Step: 9
Training loss: 2.3431294954978736
Validation loss: 2.463790376987404

Epoch: 6| Step: 10
Training loss: 1.624237028150295
Validation loss: 2.462914842628332

Epoch: 6| Step: 11
Training loss: 1.9595721837653342
Validation loss: 2.5249701601025976

Epoch: 6| Step: 12
Training loss: 1.7315715091886086
Validation loss: 2.5487182015142498

Epoch: 6| Step: 13
Training loss: 2.0939714684715036
Validation loss: 2.560915092915761

Epoch: 203| Step: 0
Training loss: 1.922262819439663
Validation loss: 2.577688849116535

Epoch: 6| Step: 1
Training loss: 1.965164431421247
Validation loss: 2.596596431119029

Epoch: 6| Step: 2
Training loss: 1.9912447026164921
Validation loss: 2.616940302310084

Epoch: 6| Step: 3
Training loss: 1.950786930636628
Validation loss: 2.608784191715055

Epoch: 6| Step: 4
Training loss: 1.809352509617415
Validation loss: 2.6242315053235243

Epoch: 6| Step: 5
Training loss: 2.117064975698225
Validation loss: 2.5994692393205665

Epoch: 6| Step: 6
Training loss: 1.882441187290694
Validation loss: 2.602335145447918

Epoch: 6| Step: 7
Training loss: 1.7496534413100528
Validation loss: 2.5688486497319425

Epoch: 6| Step: 8
Training loss: 1.6028904317532295
Validation loss: 2.536764052985724

Epoch: 6| Step: 9
Training loss: 2.0981701553480967
Validation loss: 2.501252496410867

Epoch: 6| Step: 10
Training loss: 1.9090556775182075
Validation loss: 2.470134564402984

Epoch: 6| Step: 11
Training loss: 1.6210736009195845
Validation loss: 2.4412421861876807

Epoch: 6| Step: 12
Training loss: 1.9241624570690095
Validation loss: 2.4429729568553995

Epoch: 6| Step: 13
Training loss: 1.37388704513616
Validation loss: 2.4480769377016185

Epoch: 204| Step: 0
Training loss: 2.1515331922874554
Validation loss: 2.4673856924736612

Epoch: 6| Step: 1
Training loss: 1.1561873650984065
Validation loss: 2.4420700500478514

Epoch: 6| Step: 2
Training loss: 1.7462368422212549
Validation loss: 2.4855052022847812

Epoch: 6| Step: 3
Training loss: 1.8265277373021953
Validation loss: 2.477877572225037

Epoch: 6| Step: 4
Training loss: 1.9559170107447126
Validation loss: 2.5066298794201542

Epoch: 6| Step: 5
Training loss: 2.147424854566968
Validation loss: 2.504073141234993

Epoch: 6| Step: 6
Training loss: 1.9868011061519204
Validation loss: 2.5382156502113684

Epoch: 6| Step: 7
Training loss: 1.9241623331612874
Validation loss: 2.5539403056463046

Epoch: 6| Step: 8
Training loss: 1.5697463044428197
Validation loss: 2.5843208408991036

Epoch: 6| Step: 9
Training loss: 2.396342602106114
Validation loss: 2.5954629376809226

Epoch: 6| Step: 10
Training loss: 1.817588109920121
Validation loss: 2.568448677071657

Epoch: 6| Step: 11
Training loss: 1.6696717905986562
Validation loss: 2.5450472287220527

Epoch: 6| Step: 12
Training loss: 1.6241476317703254
Validation loss: 2.53370410608184

Epoch: 6| Step: 13
Training loss: 1.4706697295552715
Validation loss: 2.5134231020137943

Epoch: 205| Step: 0
Training loss: 1.5246464554003474
Validation loss: 2.4948561977299284

Epoch: 6| Step: 1
Training loss: 2.027525788882835
Validation loss: 2.4929829954240486

Epoch: 6| Step: 2
Training loss: 1.784632766731314
Validation loss: 2.482305832013006

Epoch: 6| Step: 3
Training loss: 1.977637861633046
Validation loss: 2.47623254015439

Epoch: 6| Step: 4
Training loss: 1.8577945307318995
Validation loss: 2.4785999102851095

Epoch: 6| Step: 5
Training loss: 1.383510262691483
Validation loss: 2.482121714020809

Epoch: 6| Step: 6
Training loss: 1.6648758883800037
Validation loss: 2.469635822819438

Epoch: 6| Step: 7
Training loss: 1.991344138756064
Validation loss: 2.4767430793036525

Epoch: 6| Step: 8
Training loss: 2.1872162771150907
Validation loss: 2.4691141819700473

Epoch: 6| Step: 9
Training loss: 1.703000405330016
Validation loss: 2.4793578877531592

Epoch: 6| Step: 10
Training loss: 1.7646160787751544
Validation loss: 2.5002866385835074

Epoch: 6| Step: 11
Training loss: 1.8710975089463482
Validation loss: 2.469878342164779

Epoch: 6| Step: 12
Training loss: 2.2127939794029587
Validation loss: 2.50353963134798

Epoch: 6| Step: 13
Training loss: 2.1658271728208827
Validation loss: 2.4823713828600695

Epoch: 206| Step: 0
Training loss: 1.8052515246695617
Validation loss: 2.5030007043033478

Epoch: 6| Step: 1
Training loss: 1.4505100306913954
Validation loss: 2.5319945044281056

Epoch: 6| Step: 2
Training loss: 1.8958937946222252
Validation loss: 2.5093664717038635

Epoch: 6| Step: 3
Training loss: 1.665784419519844
Validation loss: 2.56113490418529

Epoch: 6| Step: 4
Training loss: 1.7291420011791105
Validation loss: 2.5500743979374922

Epoch: 6| Step: 5
Training loss: 1.7782965820338001
Validation loss: 2.5576133705289257

Epoch: 6| Step: 6
Training loss: 1.8223093238162067
Validation loss: 2.5682809621306752

Epoch: 6| Step: 7
Training loss: 1.8445143973951181
Validation loss: 2.5461739232536726

Epoch: 6| Step: 8
Training loss: 2.1050223193944824
Validation loss: 2.535559893065954

Epoch: 6| Step: 9
Training loss: 1.757524661763397
Validation loss: 2.5611343106050493

Epoch: 6| Step: 10
Training loss: 2.077205827545213
Validation loss: 2.577177603657838

Epoch: 6| Step: 11
Training loss: 1.9865435668177505
Validation loss: 2.5881242286531267

Epoch: 6| Step: 12
Training loss: 1.6485032344204404
Validation loss: 2.5909684437353833

Epoch: 6| Step: 13
Training loss: 1.4772300220532413
Validation loss: 2.561730678274524

Epoch: 207| Step: 0
Training loss: 1.5020682063864352
Validation loss: 2.54376051008352

Epoch: 6| Step: 1
Training loss: 2.089050028156722
Validation loss: 2.55203195553249

Epoch: 6| Step: 2
Training loss: 1.9973987113471021
Validation loss: 2.5099198519463504

Epoch: 6| Step: 3
Training loss: 1.8827175892061392
Validation loss: 2.5070000076881978

Epoch: 6| Step: 4
Training loss: 1.306843512368758
Validation loss: 2.493140332019907

Epoch: 6| Step: 5
Training loss: 1.4127241091889728
Validation loss: 2.485134805973768

Epoch: 6| Step: 6
Training loss: 1.5228931726121169
Validation loss: 2.500636273088049

Epoch: 6| Step: 7
Training loss: 2.003798929950898
Validation loss: 2.513506165241126

Epoch: 6| Step: 8
Training loss: 1.9775257402136128
Validation loss: 2.5367652424555596

Epoch: 6| Step: 9
Training loss: 1.4665444229218139
Validation loss: 2.5368474873333584

Epoch: 6| Step: 10
Training loss: 2.3527196527432452
Validation loss: 2.548955176947694

Epoch: 6| Step: 11
Training loss: 1.5798788616967152
Validation loss: 2.5236867089947363

Epoch: 6| Step: 12
Training loss: 1.6468493870402876
Validation loss: 2.5294256833424407

Epoch: 6| Step: 13
Training loss: 1.9851104094501946
Validation loss: 2.550304373604325

Epoch: 208| Step: 0
Training loss: 1.8805877077380255
Validation loss: 2.5410315000536574

Epoch: 6| Step: 1
Training loss: 1.425866027819855
Validation loss: 2.551374327311959

Epoch: 6| Step: 2
Training loss: 1.9281599044731788
Validation loss: 2.5456196519493237

Epoch: 6| Step: 3
Training loss: 2.0039119608836753
Validation loss: 2.5674900497216715

Epoch: 6| Step: 4
Training loss: 2.0010158819800816
Validation loss: 2.550408638880284

Epoch: 6| Step: 5
Training loss: 1.7605623564918658
Validation loss: 2.5908479354926564

Epoch: 6| Step: 6
Training loss: 1.49360629232396
Validation loss: 2.5945613959389515

Epoch: 6| Step: 7
Training loss: 1.573368799098121
Validation loss: 2.5741678106801493

Epoch: 6| Step: 8
Training loss: 1.5382197052445996
Validation loss: 2.5566183074649182

Epoch: 6| Step: 9
Training loss: 1.9621705817477288
Validation loss: 2.581427898720863

Epoch: 6| Step: 10
Training loss: 1.651855107915457
Validation loss: 2.5504911494231055

Epoch: 6| Step: 11
Training loss: 1.4914807947951176
Validation loss: 2.5276148885322183

Epoch: 6| Step: 12
Training loss: 1.850429139754133
Validation loss: 2.5288821688550494

Epoch: 6| Step: 13
Training loss: 1.9651988866972532
Validation loss: 2.51999763813875

Epoch: 209| Step: 0
Training loss: 1.8244601300337489
Validation loss: 2.4998380495754673

Epoch: 6| Step: 1
Training loss: 1.6397734839154603
Validation loss: 2.490429017938981

Epoch: 6| Step: 2
Training loss: 1.7080207941991654
Validation loss: 2.49336253601614

Epoch: 6| Step: 3
Training loss: 1.8359825615729977
Validation loss: 2.487682678849445

Epoch: 6| Step: 4
Training loss: 1.7160868038817358
Validation loss: 2.4756223758065037

Epoch: 6| Step: 5
Training loss: 1.5454255065637719
Validation loss: 2.505795982426741

Epoch: 6| Step: 6
Training loss: 1.8276016920943932
Validation loss: 2.5123163016833843

Epoch: 6| Step: 7
Training loss: 1.3479138998782472
Validation loss: 2.5151351118469942

Epoch: 6| Step: 8
Training loss: 2.105442931630894
Validation loss: 2.531772727675409

Epoch: 6| Step: 9
Training loss: 1.7088184908330777
Validation loss: 2.551745875643255

Epoch: 6| Step: 10
Training loss: 1.7816374507943522
Validation loss: 2.54879816974593

Epoch: 6| Step: 11
Training loss: 1.6242270465325173
Validation loss: 2.5346608255116254

Epoch: 6| Step: 12
Training loss: 1.6499888275230616
Validation loss: 2.503134660890502

Epoch: 6| Step: 13
Training loss: 1.7868161153681037
Validation loss: 2.4996946271388447

Epoch: 210| Step: 0
Training loss: 1.9250123382767448
Validation loss: 2.5179671798672194

Epoch: 6| Step: 1
Training loss: 1.6421806589377903
Validation loss: 2.5171666813212763

Epoch: 6| Step: 2
Training loss: 2.156652219548053
Validation loss: 2.5237413063036307

Epoch: 6| Step: 3
Training loss: 1.7165320911557849
Validation loss: 2.5196529286866474

Epoch: 6| Step: 4
Training loss: 1.341670667551524
Validation loss: 2.5157114843473893

Epoch: 6| Step: 5
Training loss: 1.5208477995023364
Validation loss: 2.5258835359398923

Epoch: 6| Step: 6
Training loss: 1.5223600832534647
Validation loss: 2.4977371937363295

Epoch: 6| Step: 7
Training loss: 1.951878630640548
Validation loss: 2.526137333284597

Epoch: 6| Step: 8
Training loss: 2.109927182862001
Validation loss: 2.532605564661914

Epoch: 6| Step: 9
Training loss: 1.7051130817758295
Validation loss: 2.5547631571048606

Epoch: 6| Step: 10
Training loss: 1.525563014176533
Validation loss: 2.529215986097315

Epoch: 6| Step: 11
Training loss: 1.3017318047617643
Validation loss: 2.557210419500371

Epoch: 6| Step: 12
Training loss: 1.4081741732135669
Validation loss: 2.5368027978850085

Epoch: 6| Step: 13
Training loss: 1.7111461634093854
Validation loss: 2.5493172856635335

Epoch: 211| Step: 0
Training loss: 1.5312732772614923
Validation loss: 2.537236667193829

Epoch: 6| Step: 1
Training loss: 1.8732491265690345
Validation loss: 2.555368182818549

Epoch: 6| Step: 2
Training loss: 2.006533916978567
Validation loss: 2.5388927741863307

Epoch: 6| Step: 3
Training loss: 2.1117891413521757
Validation loss: 2.518458371816846

Epoch: 6| Step: 4
Training loss: 1.9362247946608873
Validation loss: 2.4631275188860533

Epoch: 6| Step: 5
Training loss: 1.6110224023418074
Validation loss: 2.4628668703417578

Epoch: 6| Step: 6
Training loss: 1.215918749152679
Validation loss: 2.474230970678137

Epoch: 6| Step: 7
Training loss: 1.39132364275241
Validation loss: 2.4608490760857253

Epoch: 6| Step: 8
Training loss: 1.4063866866757526
Validation loss: 2.4945671033053722

Epoch: 6| Step: 9
Training loss: 1.827446053435382
Validation loss: 2.509129524404654

Epoch: 6| Step: 10
Training loss: 1.3718903664529933
Validation loss: 2.493720238912779

Epoch: 6| Step: 11
Training loss: 1.6543275724443036
Validation loss: 2.517045302580956

Epoch: 6| Step: 12
Training loss: 2.137805278906959
Validation loss: 2.531461579496464

Epoch: 6| Step: 13
Training loss: 1.2211380572831942
Validation loss: 2.5598507744515557

Epoch: 212| Step: 0
Training loss: 1.0879919802776854
Validation loss: 2.5676009767601884

Epoch: 6| Step: 1
Training loss: 1.6889293409962933
Validation loss: 2.5834950136154404

Epoch: 6| Step: 2
Training loss: 1.8832603333540519
Validation loss: 2.5799817193189645

Epoch: 6| Step: 3
Training loss: 2.0084892349619423
Validation loss: 2.5718682132299917

Epoch: 6| Step: 4
Training loss: 1.5479046255938034
Validation loss: 2.5572345198364226

Epoch: 6| Step: 5
Training loss: 1.4565995218498538
Validation loss: 2.5624286432583108

Epoch: 6| Step: 6
Training loss: 1.6782546208223
Validation loss: 2.533346833186079

Epoch: 6| Step: 7
Training loss: 1.9305980557246878
Validation loss: 2.5153034722930707

Epoch: 6| Step: 8
Training loss: 1.171959276347854
Validation loss: 2.4707003773917955

Epoch: 6| Step: 9
Training loss: 1.3325499925664717
Validation loss: 2.472930810534404

Epoch: 6| Step: 10
Training loss: 1.955628522441224
Validation loss: 2.4794655562217107

Epoch: 6| Step: 11
Training loss: 2.1602990653371994
Validation loss: 2.4830657260085864

Epoch: 6| Step: 12
Training loss: 1.5593115508906772
Validation loss: 2.4914517857942813

Epoch: 6| Step: 13
Training loss: 1.3990639929542985
Validation loss: 2.490478448072151

Epoch: 213| Step: 0
Training loss: 1.7489893583537797
Validation loss: 2.463646738440616

Epoch: 6| Step: 1
Training loss: 1.5689447624008979
Validation loss: 2.480465222557169

Epoch: 6| Step: 2
Training loss: 1.6617086893556372
Validation loss: 2.48798432660647

Epoch: 6| Step: 3
Training loss: 1.465856583443236
Validation loss: 2.4803642723140493

Epoch: 6| Step: 4
Training loss: 1.4890271818089464
Validation loss: 2.49525566717765

Epoch: 6| Step: 5
Training loss: 1.9691066116213485
Validation loss: 2.4816244703915697

Epoch: 6| Step: 6
Training loss: 1.4997985227696344
Validation loss: 2.499348966881028

Epoch: 6| Step: 7
Training loss: 2.1537692408662568
Validation loss: 2.482301015188515

Epoch: 6| Step: 8
Training loss: 1.6292476890820347
Validation loss: 2.476002498493978

Epoch: 6| Step: 9
Training loss: 1.1150137821765542
Validation loss: 2.5173915957277733

Epoch: 6| Step: 10
Training loss: 1.5128184022809972
Validation loss: 2.5404565641375254

Epoch: 6| Step: 11
Training loss: 1.5603275455274335
Validation loss: 2.5439084732152963

Epoch: 6| Step: 12
Training loss: 1.2956175625519069
Validation loss: 2.5288357794768044

Epoch: 6| Step: 13
Training loss: 2.3177068703178905
Validation loss: 2.5861081164128996

Epoch: 214| Step: 0
Training loss: 1.577650697646789
Validation loss: 2.5768680674364224

Epoch: 6| Step: 1
Training loss: 1.5890452186147404
Validation loss: 2.572979403232399

Epoch: 6| Step: 2
Training loss: 1.2538280522096128
Validation loss: 2.597871088418784

Epoch: 6| Step: 3
Training loss: 2.0704877671242192
Validation loss: 2.5774664163518635

Epoch: 6| Step: 4
Training loss: 1.6751174145439909
Validation loss: 2.591244793022141

Epoch: 6| Step: 5
Training loss: 1.6678786242254906
Validation loss: 2.5774922349813103

Epoch: 6| Step: 6
Training loss: 1.8040178385865469
Validation loss: 2.588676630027773

Epoch: 6| Step: 7
Training loss: 1.798620421173993
Validation loss: 2.587418432081025

Epoch: 6| Step: 8
Training loss: 1.7118602337292634
Validation loss: 2.5780620329853114

Epoch: 6| Step: 9
Training loss: 2.109084497863568
Validation loss: 2.5781175142827744

Epoch: 6| Step: 10
Training loss: 1.817355197243678
Validation loss: 2.541225750821297

Epoch: 6| Step: 11
Training loss: 1.0350288744598268
Validation loss: 2.50710007255089

Epoch: 6| Step: 12
Training loss: 1.0824897978832697
Validation loss: 2.5043846759742143

Epoch: 6| Step: 13
Training loss: 0.9027393679313628
Validation loss: 2.478959135278017

Epoch: 215| Step: 0
Training loss: 1.9525078981168968
Validation loss: 2.496447475569481

Epoch: 6| Step: 1
Training loss: 1.4891012340843595
Validation loss: 2.477123424322512

Epoch: 6| Step: 2
Training loss: 1.386640089785985
Validation loss: 2.5040382571993423

Epoch: 6| Step: 3
Training loss: 1.2933874460743933
Validation loss: 2.494705844735188

Epoch: 6| Step: 4
Training loss: 1.7923778482738135
Validation loss: 2.490211563729724

Epoch: 6| Step: 5
Training loss: 1.480618351043419
Validation loss: 2.4864166377795023

Epoch: 6| Step: 6
Training loss: 1.4656280452477026
Validation loss: 2.529217771065302

Epoch: 6| Step: 7
Training loss: 1.6791395136276157
Validation loss: 2.5372496417916093

Epoch: 6| Step: 8
Training loss: 1.8013734981389515
Validation loss: 2.515014436766358

Epoch: 6| Step: 9
Training loss: 1.781465283150073
Validation loss: 2.510140799862339

Epoch: 6| Step: 10
Training loss: 1.3521227254355583
Validation loss: 2.502593797094956

Epoch: 6| Step: 11
Training loss: 1.5762311695011717
Validation loss: 2.52266628069906

Epoch: 6| Step: 12
Training loss: 1.7804507419935907
Validation loss: 2.4858327530533195

Epoch: 6| Step: 13
Training loss: 1.695022487885053
Validation loss: 2.4580391891588693

Epoch: 216| Step: 0
Training loss: 1.5084735429344713
Validation loss: 2.4663494230643366

Epoch: 6| Step: 1
Training loss: 1.5048912092664024
Validation loss: 2.490636903231012

Epoch: 6| Step: 2
Training loss: 1.6478656662846862
Validation loss: 2.50995067515777

Epoch: 6| Step: 3
Training loss: 1.5579749387113742
Validation loss: 2.523055198219841

Epoch: 6| Step: 4
Training loss: 1.1974926681931217
Validation loss: 2.53173473309372

Epoch: 6| Step: 5
Training loss: 1.4699146441895878
Validation loss: 2.5247848156290003

Epoch: 6| Step: 6
Training loss: 1.2314447316736339
Validation loss: 2.542313138654565

Epoch: 6| Step: 7
Training loss: 2.1002051071638177
Validation loss: 2.524202690558764

Epoch: 6| Step: 8
Training loss: 1.4498439375980756
Validation loss: 2.5479414948019694

Epoch: 6| Step: 9
Training loss: 1.575895793422679
Validation loss: 2.5221386508593846

Epoch: 6| Step: 10
Training loss: 1.3686765137197572
Validation loss: 2.516778537627373

Epoch: 6| Step: 11
Training loss: 1.804187655895796
Validation loss: 2.5218668742461365

Epoch: 6| Step: 12
Training loss: 1.8545403978972421
Validation loss: 2.545156679704624

Epoch: 6| Step: 13
Training loss: 1.9093671233518872
Validation loss: 2.5407410652130835

Epoch: 217| Step: 0
Training loss: 1.578895154307175
Validation loss: 2.5239404123674336

Epoch: 6| Step: 1
Training loss: 1.5974501497851457
Validation loss: 2.5299141125049878

Epoch: 6| Step: 2
Training loss: 1.767039719666801
Validation loss: 2.5025760002446735

Epoch: 6| Step: 3
Training loss: 1.6542973073623255
Validation loss: 2.5054803031683335

Epoch: 6| Step: 4
Training loss: 2.1338870517045585
Validation loss: 2.494101882399699

Epoch: 6| Step: 5
Training loss: 1.5543032990941477
Validation loss: 2.4473515427476302

Epoch: 6| Step: 6
Training loss: 1.742651633803175
Validation loss: 2.441664733460372

Epoch: 6| Step: 7
Training loss: 1.5232578269448127
Validation loss: 2.44235905676575

Epoch: 6| Step: 8
Training loss: 1.1910382312144379
Validation loss: 2.450318086512532

Epoch: 6| Step: 9
Training loss: 1.1438639391236254
Validation loss: 2.456620817236489

Epoch: 6| Step: 10
Training loss: 1.1948372887324072
Validation loss: 2.4545072234604133

Epoch: 6| Step: 11
Training loss: 1.3083104979998577
Validation loss: 2.4809197717710227

Epoch: 6| Step: 12
Training loss: 1.7059215019832992
Validation loss: 2.523089460401398

Epoch: 6| Step: 13
Training loss: 1.444320173093693
Validation loss: 2.545337237173155

Epoch: 218| Step: 0
Training loss: 1.4460655106600826
Validation loss: 2.5582498809835945

Epoch: 6| Step: 1
Training loss: 1.385087980512565
Validation loss: 2.585675460654318

Epoch: 6| Step: 2
Training loss: 1.3541640452824186
Validation loss: 2.570024954210758

Epoch: 6| Step: 3
Training loss: 1.2453164094602707
Validation loss: 2.535769073785119

Epoch: 6| Step: 4
Training loss: 1.6879870100515897
Validation loss: 2.5464618940959114

Epoch: 6| Step: 5
Training loss: 1.3730055909984136
Validation loss: 2.497967456760818

Epoch: 6| Step: 6
Training loss: 1.7983006005170399
Validation loss: 2.472250521465121

Epoch: 6| Step: 7
Training loss: 0.9122919394129795
Validation loss: 2.487451526633119

Epoch: 6| Step: 8
Training loss: 1.5288868789342365
Validation loss: 2.4574829361458916

Epoch: 6| Step: 9
Training loss: 2.027960123140335
Validation loss: 2.469643197216795

Epoch: 6| Step: 10
Training loss: 1.4470318439409515
Validation loss: 2.487901088801236

Epoch: 6| Step: 11
Training loss: 1.938066707301553
Validation loss: 2.5008805990312393

Epoch: 6| Step: 12
Training loss: 1.6883537110997149
Validation loss: 2.521199659353102

Epoch: 6| Step: 13
Training loss: 1.2468663992142959
Validation loss: 2.5165459377636163

Epoch: 219| Step: 0
Training loss: 1.7809008875261436
Validation loss: 2.5499360536161455

Epoch: 6| Step: 1
Training loss: 1.5732644646060119
Validation loss: 2.5591140414699614

Epoch: 6| Step: 2
Training loss: 1.1783333389267838
Validation loss: 2.5431260293959754

Epoch: 6| Step: 3
Training loss: 1.64747048891348
Validation loss: 2.5339072411128303

Epoch: 6| Step: 4
Training loss: 1.289953397899727
Validation loss: 2.541563881931253

Epoch: 6| Step: 5
Training loss: 1.9573833582827735
Validation loss: 2.5288857199998795

Epoch: 6| Step: 6
Training loss: 1.1426596587996285
Validation loss: 2.5031268510541125

Epoch: 6| Step: 7
Training loss: 1.500849086135864
Validation loss: 2.494040021681343

Epoch: 6| Step: 8
Training loss: 1.5910977004076248
Validation loss: 2.4996810981435056

Epoch: 6| Step: 9
Training loss: 2.020236867859386
Validation loss: 2.507095577407493

Epoch: 6| Step: 10
Training loss: 1.5324282881120985
Validation loss: 2.5018279827138796

Epoch: 6| Step: 11
Training loss: 0.837838907135129
Validation loss: 2.5023577862086257

Epoch: 6| Step: 12
Training loss: 0.6836269261620234
Validation loss: 2.505378751288408

Epoch: 6| Step: 13
Training loss: 1.7272722675468892
Validation loss: 2.5029542459645326

Epoch: 220| Step: 0
Training loss: 1.2206764645526147
Validation loss: 2.54448900278099

Epoch: 6| Step: 1
Training loss: 1.6968416972958211
Validation loss: 2.5406109143442985

Epoch: 6| Step: 2
Training loss: 1.5410522920720875
Validation loss: 2.5362130683881734

Epoch: 6| Step: 3
Training loss: 1.338320697797618
Validation loss: 2.5590975983838398

Epoch: 6| Step: 4
Training loss: 1.7512800439821015
Validation loss: 2.5682893519309595

Epoch: 6| Step: 5
Training loss: 1.1160588465390113
Validation loss: 2.5676566251898856

Epoch: 6| Step: 6
Training loss: 1.6522294674574611
Validation loss: 2.5576482853779647

Epoch: 6| Step: 7
Training loss: 1.193047065887226
Validation loss: 2.5556027429756116

Epoch: 6| Step: 8
Training loss: 1.5106056708984112
Validation loss: 2.531560727089036

Epoch: 6| Step: 9
Training loss: 1.602356058163662
Validation loss: 2.5570717559493925

Epoch: 6| Step: 10
Training loss: 1.6567385690668037
Validation loss: 2.542992781666417

Epoch: 6| Step: 11
Training loss: 1.5017098377357456
Validation loss: 2.52096971430895

Epoch: 6| Step: 12
Training loss: 1.2235483930469888
Validation loss: 2.5252720389303605

Epoch: 6| Step: 13
Training loss: 1.868417247120776
Validation loss: 2.4980877525749277

Epoch: 221| Step: 0
Training loss: 1.8929939246304368
Validation loss: 2.4765665723195833

Epoch: 6| Step: 1
Training loss: 1.319562936225096
Validation loss: 2.474790057454064

Epoch: 6| Step: 2
Training loss: 1.31420918846802
Validation loss: 2.479246249067265

Epoch: 6| Step: 3
Training loss: 1.241427783047101
Validation loss: 2.474172304978898

Epoch: 6| Step: 4
Training loss: 1.618564259245447
Validation loss: 2.4818088711202893

Epoch: 6| Step: 5
Training loss: 1.6243361070592162
Validation loss: 2.506449078354176

Epoch: 6| Step: 6
Training loss: 1.350507379482746
Validation loss: 2.5349046450933184

Epoch: 6| Step: 7
Training loss: 1.743795157774161
Validation loss: 2.58288753531968

Epoch: 6| Step: 8
Training loss: 1.5988811097358266
Validation loss: 2.6175877996723353

Epoch: 6| Step: 9
Training loss: 1.7135538798382988
Validation loss: 2.6558186749698156

Epoch: 6| Step: 10
Training loss: 0.9664805501686882
Validation loss: 2.62968236309648

Epoch: 6| Step: 11
Training loss: 0.5961193694162531
Validation loss: 2.638246170930096

Epoch: 6| Step: 12
Training loss: 1.7150488798110073
Validation loss: 2.630098149345094

Epoch: 6| Step: 13
Training loss: 1.8219187448265206
Validation loss: 2.5890580562220444

Epoch: 222| Step: 0
Training loss: 1.7084372729183903
Validation loss: 2.4979972282487624

Epoch: 6| Step: 1
Training loss: 1.2570498031849724
Validation loss: 2.44550463713698

Epoch: 6| Step: 2
Training loss: 1.0996716551141912
Validation loss: 2.4488158216035147

Epoch: 6| Step: 3
Training loss: 1.3316475323928454
Validation loss: 2.3974075256964915

Epoch: 6| Step: 4
Training loss: 1.568532057741285
Validation loss: 2.4144782400526266

Epoch: 6| Step: 5
Training loss: 1.4300296561627255
Validation loss: 2.4397983280342896

Epoch: 6| Step: 6
Training loss: 1.6916695405281097
Validation loss: 2.46173989242585

Epoch: 6| Step: 7
Training loss: 1.5192331055917576
Validation loss: 2.5186925808793275

Epoch: 6| Step: 8
Training loss: 1.1853842207362846
Validation loss: 2.523740056857519

Epoch: 6| Step: 9
Training loss: 1.5484069020532594
Validation loss: 2.5254466888706886

Epoch: 6| Step: 10
Training loss: 1.5077246605779413
Validation loss: 2.5730346095338117

Epoch: 6| Step: 11
Training loss: 1.892683059727988
Validation loss: 2.5344008181611994

Epoch: 6| Step: 12
Training loss: 1.4298485837147492
Validation loss: 2.4784233294388573

Epoch: 6| Step: 13
Training loss: 1.6988436580885498
Validation loss: 2.4511449809997803

Epoch: 223| Step: 0
Training loss: 1.0654406525128932
Validation loss: 2.458425868068926

Epoch: 6| Step: 1
Training loss: 1.680083968811586
Validation loss: 2.4542431691489006

Epoch: 6| Step: 2
Training loss: 1.566755450891606
Validation loss: 2.4808219236430724

Epoch: 6| Step: 3
Training loss: 1.1886658216128623
Validation loss: 2.4772134747438543

Epoch: 6| Step: 4
Training loss: 1.4315052254675047
Validation loss: 2.543441878406518

Epoch: 6| Step: 5
Training loss: 1.421126619349978
Validation loss: 2.545084478111397

Epoch: 6| Step: 6
Training loss: 1.5058664205463015
Validation loss: 2.5735390604385833

Epoch: 6| Step: 7
Training loss: 1.370649521204353
Validation loss: 2.5841234039674523

Epoch: 6| Step: 8
Training loss: 1.8376246066239958
Validation loss: 2.553401601693159

Epoch: 6| Step: 9
Training loss: 1.1332042148378398
Validation loss: 2.550112635999964

Epoch: 6| Step: 10
Training loss: 1.4412413298585127
Validation loss: 2.5567454490786643

Epoch: 6| Step: 11
Training loss: 1.5284368403559485
Validation loss: 2.5173067924420387

Epoch: 6| Step: 12
Training loss: 1.6815026699638211
Validation loss: 2.510998408590774

Epoch: 6| Step: 13
Training loss: 1.5717520876203617
Validation loss: 2.4978977121537174

Epoch: 224| Step: 0
Training loss: 1.4593501315560904
Validation loss: 2.4753906545781907

Epoch: 6| Step: 1
Training loss: 1.7184961304874935
Validation loss: 2.453446361382231

Epoch: 6| Step: 2
Training loss: 0.9885564729943719
Validation loss: 2.4503433428114354

Epoch: 6| Step: 3
Training loss: 1.1851282024648075
Validation loss: 2.4226338605827005

Epoch: 6| Step: 4
Training loss: 1.6379598859921773
Validation loss: 2.4414630096728653

Epoch: 6| Step: 5
Training loss: 1.1911493743634796
Validation loss: 2.4166018916166525

Epoch: 6| Step: 6
Training loss: 2.1098022028339547
Validation loss: 2.466295218402158

Epoch: 6| Step: 7
Training loss: 1.3972172874597797
Validation loss: 2.4324857843330587

Epoch: 6| Step: 8
Training loss: 1.360068396503321
Validation loss: 2.4430222789147527

Epoch: 6| Step: 9
Training loss: 1.4298627568789675
Validation loss: 2.4576996775191953

Epoch: 6| Step: 10
Training loss: 1.05669139239467
Validation loss: 2.47190539341348

Epoch: 6| Step: 11
Training loss: 1.5457425065961012
Validation loss: 2.4840874985740786

Epoch: 6| Step: 12
Training loss: 1.338864427336916
Validation loss: 2.5066770724744076

Epoch: 6| Step: 13
Training loss: 1.1306324996404287
Validation loss: 2.544014401348267

Epoch: 225| Step: 0
Training loss: 1.4987831743273776
Validation loss: 2.607067413896912

Epoch: 6| Step: 1
Training loss: 1.2622582666855864
Validation loss: 2.595440274892451

Epoch: 6| Step: 2
Training loss: 1.6502024526370487
Validation loss: 2.605292751532792

Epoch: 6| Step: 3
Training loss: 0.9240797800945291
Validation loss: 2.6132421674699433

Epoch: 6| Step: 4
Training loss: 1.0412903042213566
Validation loss: 2.595666332881185

Epoch: 6| Step: 5
Training loss: 1.5933862906930034
Validation loss: 2.5851628265571405

Epoch: 6| Step: 6
Training loss: 1.747556410876326
Validation loss: 2.584771228182363

Epoch: 6| Step: 7
Training loss: 1.6477044088995623
Validation loss: 2.5525821689655546

Epoch: 6| Step: 8
Training loss: 1.3870694428918462
Validation loss: 2.493552929272183

Epoch: 6| Step: 9
Training loss: 1.1489790593223583
Validation loss: 2.467875144822097

Epoch: 6| Step: 10
Training loss: 1.6022000416219608
Validation loss: 2.432009734616432

Epoch: 6| Step: 11
Training loss: 1.3735364147062534
Validation loss: 2.434071877595038

Epoch: 6| Step: 12
Training loss: 1.4262223071018425
Validation loss: 2.415688824657812

Epoch: 6| Step: 13
Training loss: 1.323537870922357
Validation loss: 2.4274490459764286

Epoch: 226| Step: 0
Training loss: 1.4304293182788428
Validation loss: 2.434488738223163

Epoch: 6| Step: 1
Training loss: 1.6764304586357293
Validation loss: 2.4103378754252143

Epoch: 6| Step: 2
Training loss: 1.2158741399040958
Validation loss: 2.449518127509031

Epoch: 6| Step: 3
Training loss: 1.1454419883814515
Validation loss: 2.4519502371461996

Epoch: 6| Step: 4
Training loss: 1.420052838484158
Validation loss: 2.4903760147429854

Epoch: 6| Step: 5
Training loss: 1.499755998475138
Validation loss: 2.5013556670711377

Epoch: 6| Step: 6
Training loss: 1.0866817421442752
Validation loss: 2.5264336306738246

Epoch: 6| Step: 7
Training loss: 1.6421732545301932
Validation loss: 2.4749130491460423

Epoch: 6| Step: 8
Training loss: 1.4038279974881813
Validation loss: 2.495004776403792

Epoch: 6| Step: 9
Training loss: 0.8988132520337888
Validation loss: 2.5012428998534015

Epoch: 6| Step: 10
Training loss: 1.6277036916185759
Validation loss: 2.5110331691339387

Epoch: 6| Step: 11
Training loss: 1.251795956748726
Validation loss: 2.5178695017876644

Epoch: 6| Step: 12
Training loss: 1.596793615727094
Validation loss: 2.5057330691114723

Epoch: 6| Step: 13
Training loss: 1.4687931784918127
Validation loss: 2.5140360208236032

Epoch: 227| Step: 0
Training loss: 1.5557950929104603
Validation loss: 2.5351919049106315

Epoch: 6| Step: 1
Training loss: 1.29544549312197
Validation loss: 2.5608325528342664

Epoch: 6| Step: 2
Training loss: 1.9596513884813367
Validation loss: 2.586632180752209

Epoch: 6| Step: 3
Training loss: 0.9887686571658945
Validation loss: 2.54732653517435

Epoch: 6| Step: 4
Training loss: 0.7243133516055651
Validation loss: 2.5361064636417674

Epoch: 6| Step: 5
Training loss: 1.4459152202155225
Validation loss: 2.5381277731820786

Epoch: 6| Step: 6
Training loss: 1.5378810007318868
Validation loss: 2.514993016382863

Epoch: 6| Step: 7
Training loss: 1.0801279011685099
Validation loss: 2.4551138829947092

Epoch: 6| Step: 8
Training loss: 1.5335431736259517
Validation loss: 2.442695996691742

Epoch: 6| Step: 9
Training loss: 1.8412189891764983
Validation loss: 2.436603907303299

Epoch: 6| Step: 10
Training loss: 1.1252346323960263
Validation loss: 2.4371732530126873

Epoch: 6| Step: 11
Training loss: 1.1078455953671695
Validation loss: 2.449995140755618

Epoch: 6| Step: 12
Training loss: 1.1717287099445213
Validation loss: 2.475603181738842

Epoch: 6| Step: 13
Training loss: 1.6395188735382806
Validation loss: 2.5099437531824833

Epoch: 228| Step: 0
Training loss: 1.3447706648853437
Validation loss: 2.5363774022765764

Epoch: 6| Step: 1
Training loss: 1.4744649854288217
Validation loss: 2.5233468721680876

Epoch: 6| Step: 2
Training loss: 0.9260985719913422
Validation loss: 2.5558970062034834

Epoch: 6| Step: 3
Training loss: 1.384795281397991
Validation loss: 2.5581687801641615

Epoch: 6| Step: 4
Training loss: 1.6050661050843589
Validation loss: 2.5349335772320116

Epoch: 6| Step: 5
Training loss: 1.2341927019541745
Validation loss: 2.53112699999044

Epoch: 6| Step: 6
Training loss: 1.5208984343647667
Validation loss: 2.523170255123646

Epoch: 6| Step: 7
Training loss: 1.332934657733953
Validation loss: 2.523502773795819

Epoch: 6| Step: 8
Training loss: 1.107229495284361
Validation loss: 2.4917908818811414

Epoch: 6| Step: 9
Training loss: 1.2102864145569967
Validation loss: 2.4362051400772358

Epoch: 6| Step: 10
Training loss: 1.276240487731097
Validation loss: 2.4513230988384853

Epoch: 6| Step: 11
Training loss: 1.3711376563538429
Validation loss: 2.460772460987146

Epoch: 6| Step: 12
Training loss: 1.523093629810616
Validation loss: 2.4521266728683067

Epoch: 6| Step: 13
Training loss: 1.2494652080935535
Validation loss: 2.4638847031247377

Epoch: 229| Step: 0
Training loss: 1.5216670777458536
Validation loss: 2.4962280756987125

Epoch: 6| Step: 1
Training loss: 1.199527564033787
Validation loss: 2.5033551928072098

Epoch: 6| Step: 2
Training loss: 1.3399925927768779
Validation loss: 2.5202885632935548

Epoch: 6| Step: 3
Training loss: 1.231848436724332
Validation loss: 2.5261852690855933

Epoch: 6| Step: 4
Training loss: 1.1213619961297672
Validation loss: 2.594342150936971

Epoch: 6| Step: 5
Training loss: 1.7650059652903092
Validation loss: 2.578594544610699

Epoch: 6| Step: 6
Training loss: 1.3502969273995906
Validation loss: 2.5860780229720706

Epoch: 6| Step: 7
Training loss: 1.2295680064365666
Validation loss: 2.6064472845718885

Epoch: 6| Step: 8
Training loss: 1.2774638548214843
Validation loss: 2.5723759424795998

Epoch: 6| Step: 9
Training loss: 1.5139591461273247
Validation loss: 2.539563122689543

Epoch: 6| Step: 10
Training loss: 1.271957192354416
Validation loss: 2.52445292078072

Epoch: 6| Step: 11
Training loss: 0.979517319300746
Validation loss: 2.508590428334537

Epoch: 6| Step: 12
Training loss: 1.2552900432831482
Validation loss: 2.4909640226037233

Epoch: 6| Step: 13
Training loss: 1.3065502095551096
Validation loss: 2.456384032670661

Epoch: 230| Step: 0
Training loss: 1.3662494165920118
Validation loss: 2.476200834960246

Epoch: 6| Step: 1
Training loss: 1.835718409675177
Validation loss: 2.449308101427271

Epoch: 6| Step: 2
Training loss: 1.2017765167085188
Validation loss: 2.4443734499505645

Epoch: 6| Step: 3
Training loss: 1.2749676550708045
Validation loss: 2.4636914479285297

Epoch: 6| Step: 4
Training loss: 1.0668735248933148
Validation loss: 2.48124204013232

Epoch: 6| Step: 5
Training loss: 1.408054296324437
Validation loss: 2.4841989104087854

Epoch: 6| Step: 6
Training loss: 1.6382593447230844
Validation loss: 2.490226441832583

Epoch: 6| Step: 7
Training loss: 0.9906629127925057
Validation loss: 2.5171097822167394

Epoch: 6| Step: 8
Training loss: 1.2275380428191618
Validation loss: 2.56457435171364

Epoch: 6| Step: 9
Training loss: 1.5823709758933686
Validation loss: 2.543531752946766

Epoch: 6| Step: 10
Training loss: 1.2552175350036598
Validation loss: 2.5437890482278838

Epoch: 6| Step: 11
Training loss: 1.2198610865349382
Validation loss: 2.5210991108037697

Epoch: 6| Step: 12
Training loss: 0.8607239972523747
Validation loss: 2.4839443964326557

Epoch: 6| Step: 13
Training loss: 0.6112713284662158
Validation loss: 2.5096109273553537

Epoch: 231| Step: 0
Training loss: 0.9548926924289767
Validation loss: 2.4812931152409923

Epoch: 6| Step: 1
Training loss: 1.2729450982264534
Validation loss: 2.4604127599548273

Epoch: 6| Step: 2
Training loss: 1.5091946448701494
Validation loss: 2.438952105739344

Epoch: 6| Step: 3
Training loss: 1.219344409850256
Validation loss: 2.4399432328871336

Epoch: 6| Step: 4
Training loss: 1.1187957711686431
Validation loss: 2.4406293591279242

Epoch: 6| Step: 5
Training loss: 1.3846036872817977
Validation loss: 2.461820287755026

Epoch: 6| Step: 6
Training loss: 0.9837599149638147
Validation loss: 2.465686620765259

Epoch: 6| Step: 7
Training loss: 0.7586862305390859
Validation loss: 2.4807396990493027

Epoch: 6| Step: 8
Training loss: 1.3914309534260623
Validation loss: 2.4887240387379097

Epoch: 6| Step: 9
Training loss: 1.9285875034671522
Validation loss: 2.48620906675888

Epoch: 6| Step: 10
Training loss: 1.3126762362642004
Validation loss: 2.500845108959363

Epoch: 6| Step: 11
Training loss: 1.5522732799797643
Validation loss: 2.5140518143687696

Epoch: 6| Step: 12
Training loss: 1.2664091718523511
Validation loss: 2.5159868201679063

Epoch: 6| Step: 13
Training loss: 0.968903898504806
Validation loss: 2.51195725437862

Epoch: 232| Step: 0
Training loss: 1.2524428339721394
Validation loss: 2.524007315548877

Epoch: 6| Step: 1
Training loss: 1.1694375693108312
Validation loss: 2.498795771000347

Epoch: 6| Step: 2
Training loss: 1.2291384332722546
Validation loss: 2.4927169993895086

Epoch: 6| Step: 3
Training loss: 1.2599695321592521
Validation loss: 2.5008700446290453

Epoch: 6| Step: 4
Training loss: 1.0143580236794807
Validation loss: 2.497756858174091

Epoch: 6| Step: 5
Training loss: 1.403940253676505
Validation loss: 2.4780884160440264

Epoch: 6| Step: 6
Training loss: 1.181162234482152
Validation loss: 2.464963437698046

Epoch: 6| Step: 7
Training loss: 1.6788462816749772
Validation loss: 2.47052396375759

Epoch: 6| Step: 8
Training loss: 1.4752389940511645
Validation loss: 2.4618386781000665

Epoch: 6| Step: 9
Training loss: 1.5394529825175176
Validation loss: 2.4756217477429274

Epoch: 6| Step: 10
Training loss: 1.3000821821205513
Validation loss: 2.4547642187931493

Epoch: 6| Step: 11
Training loss: 1.052422528621031
Validation loss: 2.511648289992224

Epoch: 6| Step: 12
Training loss: 0.8340393334176783
Validation loss: 2.521608438587791

Epoch: 6| Step: 13
Training loss: 1.3607569718218218
Validation loss: 2.5243476210098086

Epoch: 233| Step: 0
Training loss: 0.9368944119509399
Validation loss: 2.508669777506969

Epoch: 6| Step: 1
Training loss: 1.1006107412147894
Validation loss: 2.4914550625617795

Epoch: 6| Step: 2
Training loss: 1.2680482624387857
Validation loss: 2.4924569529635128

Epoch: 6| Step: 3
Training loss: 0.8518780814749721
Validation loss: 2.478136473331474

Epoch: 6| Step: 4
Training loss: 1.6014809192255632
Validation loss: 2.4749077694089374

Epoch: 6| Step: 5
Training loss: 1.113497957252578
Validation loss: 2.4264634240436793

Epoch: 6| Step: 6
Training loss: 0.6762007585391506
Validation loss: 2.472087112978918

Epoch: 6| Step: 7
Training loss: 1.3120765911343772
Validation loss: 2.433920363453504

Epoch: 6| Step: 8
Training loss: 1.5725488632688538
Validation loss: 2.436744502391769

Epoch: 6| Step: 9
Training loss: 1.2964682803027054
Validation loss: 2.4305461274729363

Epoch: 6| Step: 10
Training loss: 1.1871168622768984
Validation loss: 2.415179433255756

Epoch: 6| Step: 11
Training loss: 1.1729724069001979
Validation loss: 2.457517515299568

Epoch: 6| Step: 12
Training loss: 1.6020643983010516
Validation loss: 2.4649658994523507

Epoch: 6| Step: 13
Training loss: 1.574363455735754
Validation loss: 2.5201488330984385

Epoch: 234| Step: 0
Training loss: 1.187343787911032
Validation loss: 2.513518611101748

Epoch: 6| Step: 1
Training loss: 1.0872217721298691
Validation loss: 2.535814306146329

Epoch: 6| Step: 2
Training loss: 0.8653365305232666
Validation loss: 2.5099781095658753

Epoch: 6| Step: 3
Training loss: 1.4596028478858618
Validation loss: 2.5040359968983457

Epoch: 6| Step: 4
Training loss: 1.1999320726242604
Validation loss: 2.4837037516826865

Epoch: 6| Step: 5
Training loss: 1.3507451579367047
Validation loss: 2.4374530347028482

Epoch: 6| Step: 6
Training loss: 1.6934256183202512
Validation loss: 2.435294632132453

Epoch: 6| Step: 7
Training loss: 1.705953506587499
Validation loss: 2.433498384584367

Epoch: 6| Step: 8
Training loss: 1.0780095024716287
Validation loss: 2.454980551183971

Epoch: 6| Step: 9
Training loss: 1.3442608062043042
Validation loss: 2.4503488444441706

Epoch: 6| Step: 10
Training loss: 0.9187583287179456
Validation loss: 2.4821871674814506

Epoch: 6| Step: 11
Training loss: 0.9610369250957009
Validation loss: 2.4975720808670845

Epoch: 6| Step: 12
Training loss: 1.1517817791843046
Validation loss: 2.524641910707554

Epoch: 6| Step: 13
Training loss: 1.2358185741051688
Validation loss: 2.5290897671176222

Epoch: 235| Step: 0
Training loss: 1.347300208785135
Validation loss: 2.5534307931158313

Epoch: 6| Step: 1
Training loss: 0.8263516061495442
Validation loss: 2.5996752883659844

Epoch: 6| Step: 2
Training loss: 1.058607375842023
Validation loss: 2.604431498853785

Epoch: 6| Step: 3
Training loss: 1.2356785518636173
Validation loss: 2.573785620095191

Epoch: 6| Step: 4
Training loss: 1.1667650328902572
Validation loss: 2.603323894023175

Epoch: 6| Step: 5
Training loss: 1.2669076895201397
Validation loss: 2.578354338994885

Epoch: 6| Step: 6
Training loss: 1.2180861107620866
Validation loss: 2.5583724227323437

Epoch: 6| Step: 7
Training loss: 1.208469361288929
Validation loss: 2.5479741666687135

Epoch: 6| Step: 8
Training loss: 1.2693219291077205
Validation loss: 2.516625935594945

Epoch: 6| Step: 9
Training loss: 1.0740123203643586
Validation loss: 2.502197625628256

Epoch: 6| Step: 10
Training loss: 1.3054736846702721
Validation loss: 2.4690711364354576

Epoch: 6| Step: 11
Training loss: 0.8692866170618551
Validation loss: 2.452654076782373

Epoch: 6| Step: 12
Training loss: 1.3966552203050016
Validation loss: 2.4634156026513234

Epoch: 6| Step: 13
Training loss: 2.1037451318694718
Validation loss: 2.4678616662925403

Epoch: 236| Step: 0
Training loss: 1.1930373736056832
Validation loss: 2.460728024553848

Epoch: 6| Step: 1
Training loss: 1.0977379167795684
Validation loss: 2.4825604122590015

Epoch: 6| Step: 2
Training loss: 1.2994314069004638
Validation loss: 2.490188210735262

Epoch: 6| Step: 3
Training loss: 1.2529141312880003
Validation loss: 2.515997729939195

Epoch: 6| Step: 4
Training loss: 0.708971638210425
Validation loss: 2.505734235456635

Epoch: 6| Step: 5
Training loss: 1.1928383146975017
Validation loss: 2.512360012403597

Epoch: 6| Step: 6
Training loss: 1.0722702943460491
Validation loss: 2.5172917749806447

Epoch: 6| Step: 7
Training loss: 1.2724436058333766
Validation loss: 2.47022324126368

Epoch: 6| Step: 8
Training loss: 1.308555579696338
Validation loss: 2.4737169138670256

Epoch: 6| Step: 9
Training loss: 0.8177284230155667
Validation loss: 2.4702163615626254

Epoch: 6| Step: 10
Training loss: 0.8643299826968864
Validation loss: 2.4834332034415754

Epoch: 6| Step: 11
Training loss: 1.2716616552378317
Validation loss: 2.520787919958437

Epoch: 6| Step: 12
Training loss: 1.656848439478943
Validation loss: 2.508123858514478

Epoch: 6| Step: 13
Training loss: 1.636994623136924
Validation loss: 2.5470822338872456

Epoch: 237| Step: 0
Training loss: 1.1675612845662873
Validation loss: 2.554346743812987

Epoch: 6| Step: 1
Training loss: 1.4174144491654954
Validation loss: 2.5649726537048583

Epoch: 6| Step: 2
Training loss: 1.3225498091290393
Validation loss: 2.5213797707639003

Epoch: 6| Step: 3
Training loss: 0.9684176951793197
Validation loss: 2.505130484089893

Epoch: 6| Step: 4
Training loss: 1.3015365011817326
Validation loss: 2.546199375539993

Epoch: 6| Step: 5
Training loss: 0.9341436386729759
Validation loss: 2.492766844890793

Epoch: 6| Step: 6
Training loss: 1.1425859499932371
Validation loss: 2.4576964271995667

Epoch: 6| Step: 7
Training loss: 0.899853660024186
Validation loss: 2.4786494294495873

Epoch: 6| Step: 8
Training loss: 1.3803826659843896
Validation loss: 2.438344990933563

Epoch: 6| Step: 9
Training loss: 0.8500495910202863
Validation loss: 2.4449336685566694

Epoch: 6| Step: 10
Training loss: 1.5275408917586701
Validation loss: 2.445050875012013

Epoch: 6| Step: 11
Training loss: 1.131334274272119
Validation loss: 2.4337143277637305

Epoch: 6| Step: 12
Training loss: 1.0416836482889071
Validation loss: 2.45302340640241

Epoch: 6| Step: 13
Training loss: 1.3331163299321538
Validation loss: 2.473909642895928

Epoch: 238| Step: 0
Training loss: 1.3114645370243752
Validation loss: 2.4661768729083335

Epoch: 6| Step: 1
Training loss: 1.0762612639755975
Validation loss: 2.475656792204218

Epoch: 6| Step: 2
Training loss: 1.4532925088788993
Validation loss: 2.4701083708885334

Epoch: 6| Step: 3
Training loss: 1.005675423106593
Validation loss: 2.485365180328342

Epoch: 6| Step: 4
Training loss: 1.3222110799022537
Validation loss: 2.4927284408955535

Epoch: 6| Step: 5
Training loss: 0.7598584272883858
Validation loss: 2.4923085222444565

Epoch: 6| Step: 6
Training loss: 0.8340170360307189
Validation loss: 2.4574933926161537

Epoch: 6| Step: 7
Training loss: 0.9197543046274572
Validation loss: 2.497130746072553

Epoch: 6| Step: 8
Training loss: 1.005684905985445
Validation loss: 2.485492226264786

Epoch: 6| Step: 9
Training loss: 1.5503723220340724
Validation loss: 2.502371348371061

Epoch: 6| Step: 10
Training loss: 1.2961364849419432
Validation loss: 2.511085176836114

Epoch: 6| Step: 11
Training loss: 1.162707673258145
Validation loss: 2.530927468648833

Epoch: 6| Step: 12
Training loss: 1.0878195063084013
Validation loss: 2.5251581904956386

Epoch: 6| Step: 13
Training loss: 1.325386545190173
Validation loss: 2.5425993255329327

Epoch: 239| Step: 0
Training loss: 1.2397965266579523
Validation loss: 2.518305283172225

Epoch: 6| Step: 1
Training loss: 1.2582221459955734
Validation loss: 2.5048988582123783

Epoch: 6| Step: 2
Training loss: 1.058298386474896
Validation loss: 2.520479730877621

Epoch: 6| Step: 3
Training loss: 1.244512625134049
Validation loss: 2.518305527492771

Epoch: 6| Step: 4
Training loss: 1.1716759576243714
Validation loss: 2.489956184305138

Epoch: 6| Step: 5
Training loss: 0.6688650486818397
Validation loss: 2.484432930508601

Epoch: 6| Step: 6
Training loss: 1.7597343281154958
Validation loss: 2.454378679144807

Epoch: 6| Step: 7
Training loss: 1.1918361200993457
Validation loss: 2.4602908903409606

Epoch: 6| Step: 8
Training loss: 0.761943373205557
Validation loss: 2.4642255036420204

Epoch: 6| Step: 9
Training loss: 1.063572958928932
Validation loss: 2.457373985810417

Epoch: 6| Step: 10
Training loss: 1.219313906767404
Validation loss: 2.455477452211901

Epoch: 6| Step: 11
Training loss: 1.0139398532988966
Validation loss: 2.4324797200811323

Epoch: 6| Step: 12
Training loss: 1.2176599763264733
Validation loss: 2.4627644731821956

Epoch: 6| Step: 13
Training loss: 0.5000114439608326
Validation loss: 2.441310638458788

Epoch: 240| Step: 0
Training loss: 1.2584804869917197
Validation loss: 2.5067596939756527

Epoch: 6| Step: 1
Training loss: 1.4220894452707051
Validation loss: 2.4939494768694725

Epoch: 6| Step: 2
Training loss: 1.0520990326468607
Validation loss: 2.5340991830922115

Epoch: 6| Step: 3
Training loss: 1.2339568576721267
Validation loss: 2.5585017792930613

Epoch: 6| Step: 4
Training loss: 0.9666844774666212
Validation loss: 2.5787790900012104

Epoch: 6| Step: 5
Training loss: 1.0473010206946225
Validation loss: 2.552331250328736

Epoch: 6| Step: 6
Training loss: 0.8288573859190898
Validation loss: 2.524543510937898

Epoch: 6| Step: 7
Training loss: 1.6228338622816172
Validation loss: 2.5057749405627185

Epoch: 6| Step: 8
Training loss: 1.2151247539757428
Validation loss: 2.4521599637482265

Epoch: 6| Step: 9
Training loss: 0.9551678636825517
Validation loss: 2.4637955005374765

Epoch: 6| Step: 10
Training loss: 0.7798061762146177
Validation loss: 2.495408059710409

Epoch: 6| Step: 11
Training loss: 0.7314673141613379
Validation loss: 2.454761476320362

Epoch: 6| Step: 12
Training loss: 1.3478508407973362
Validation loss: 2.459338857642112

Epoch: 6| Step: 13
Training loss: 1.263709420025228
Validation loss: 2.449388777109577

Epoch: 241| Step: 0
Training loss: 1.4576825279200438
Validation loss: 2.4726263595029194

Epoch: 6| Step: 1
Training loss: 0.9074306361169188
Validation loss: 2.443480337481381

Epoch: 6| Step: 2
Training loss: 1.3125785622471986
Validation loss: 2.472298187238495

Epoch: 6| Step: 3
Training loss: 0.6092611597782065
Validation loss: 2.4840612849983676

Epoch: 6| Step: 4
Training loss: 1.196623986518229
Validation loss: 2.4849834072519497

Epoch: 6| Step: 5
Training loss: 0.8375217719593081
Validation loss: 2.5034390237684936

Epoch: 6| Step: 6
Training loss: 1.258835086617414
Validation loss: 2.5271388649819126

Epoch: 6| Step: 7
Training loss: 0.7206517229642275
Validation loss: 2.4644914749151816

Epoch: 6| Step: 8
Training loss: 1.0877808219244496
Validation loss: 2.4945695039870914

Epoch: 6| Step: 9
Training loss: 0.7001414258324435
Validation loss: 2.474455252947527

Epoch: 6| Step: 10
Training loss: 0.9361175198403221
Validation loss: 2.489873755810806

Epoch: 6| Step: 11
Training loss: 1.7105815639145066
Validation loss: 2.480569469657229

Epoch: 6| Step: 12
Training loss: 1.5103690655102457
Validation loss: 2.4922381399228164

Epoch: 6| Step: 13
Training loss: 0.872846507862109
Validation loss: 2.4726843262820433

Epoch: 242| Step: 0
Training loss: 1.613642617456526
Validation loss: 2.5066444514341173

Epoch: 6| Step: 1
Training loss: 1.220673290651045
Validation loss: 2.5059328356590758

Epoch: 6| Step: 2
Training loss: 1.1212632851892725
Validation loss: 2.523001549333716

Epoch: 6| Step: 3
Training loss: 0.9130397519757268
Validation loss: 2.5156969679108094

Epoch: 6| Step: 4
Training loss: 0.8312572407227854
Validation loss: 2.516050074174327

Epoch: 6| Step: 5
Training loss: 0.8834466934940183
Validation loss: 2.5295197895792287

Epoch: 6| Step: 6
Training loss: 0.9698756354037728
Validation loss: 2.5075460824085494

Epoch: 6| Step: 7
Training loss: 1.4214667268576338
Validation loss: 2.517367530468507

Epoch: 6| Step: 8
Training loss: 1.1962963368720156
Validation loss: 2.4876318956953978

Epoch: 6| Step: 9
Training loss: 1.193077541104829
Validation loss: 2.502563862091205

Epoch: 6| Step: 10
Training loss: 0.7306504049199913
Validation loss: 2.4818083339744637

Epoch: 6| Step: 11
Training loss: 1.2094518592718935
Validation loss: 2.487385282562671

Epoch: 6| Step: 12
Training loss: 1.0307122186568851
Validation loss: 2.473639912776443

Epoch: 6| Step: 13
Training loss: 0.7417466711619541
Validation loss: 2.441895345414148

Epoch: 243| Step: 0
Training loss: 1.117721963297469
Validation loss: 2.4555152433901144

Epoch: 6| Step: 1
Training loss: 1.0286237046320175
Validation loss: 2.4378839279310407

Epoch: 6| Step: 2
Training loss: 1.1530141658293225
Validation loss: 2.448371722030578

Epoch: 6| Step: 3
Training loss: 0.6726913815139774
Validation loss: 2.465633660148714

Epoch: 6| Step: 4
Training loss: 1.0081319967879667
Validation loss: 2.5095148302714283

Epoch: 6| Step: 5
Training loss: 1.1947004958036394
Validation loss: 2.5150608670179526

Epoch: 6| Step: 6
Training loss: 1.1078759932515168
Validation loss: 2.5262613951746156

Epoch: 6| Step: 7
Training loss: 1.2519784529053632
Validation loss: 2.5417233351010466

Epoch: 6| Step: 8
Training loss: 1.4873389918277973
Validation loss: 2.5502679086514113

Epoch: 6| Step: 9
Training loss: 0.8520226591437201
Validation loss: 2.5196331105648304

Epoch: 6| Step: 10
Training loss: 1.6361818001845043
Validation loss: 2.5071510227404668

Epoch: 6| Step: 11
Training loss: 1.0202573331958664
Validation loss: 2.501279485058002

Epoch: 6| Step: 12
Training loss: 0.8646297365781043
Validation loss: 2.4525378229717427

Epoch: 6| Step: 13
Training loss: 0.45817694560757855
Validation loss: 2.468078362519816

Epoch: 244| Step: 0
Training loss: 1.0578507071374998
Validation loss: 2.4607936032505546

Epoch: 6| Step: 1
Training loss: 1.7739309557065668
Validation loss: 2.448890734854491

Epoch: 6| Step: 2
Training loss: 0.705098519069938
Validation loss: 2.4220455960392

Epoch: 6| Step: 3
Training loss: 1.5367027045276718
Validation loss: 2.419786362533184

Epoch: 6| Step: 4
Training loss: 0.9697561576453048
Validation loss: 2.4127740631099224

Epoch: 6| Step: 5
Training loss: 1.3185948140465178
Validation loss: 2.4421743688339985

Epoch: 6| Step: 6
Training loss: 0.9800356634131928
Validation loss: 2.4308947994921937

Epoch: 6| Step: 7
Training loss: 0.8758420298683288
Validation loss: 2.440644725927667

Epoch: 6| Step: 8
Training loss: 1.1953603697522428
Validation loss: 2.4795520062823346

Epoch: 6| Step: 9
Training loss: 0.7107562158871642
Validation loss: 2.5066804658727695

Epoch: 6| Step: 10
Training loss: 1.02298365423469
Validation loss: 2.506624915015928

Epoch: 6| Step: 11
Training loss: 0.8251776157264766
Validation loss: 2.4601304472725465

Epoch: 6| Step: 12
Training loss: 0.7975197969568442
Validation loss: 2.4764633099325626

Epoch: 6| Step: 13
Training loss: 0.9231244687832367
Validation loss: 2.4636126069257314

Epoch: 245| Step: 0
Training loss: 1.2065058184916977
Validation loss: 2.4653258699745395

Epoch: 6| Step: 1
Training loss: 1.1560580119984087
Validation loss: 2.474852996003794

Epoch: 6| Step: 2
Training loss: 0.9307803294516829
Validation loss: 2.4901751618299417

Epoch: 6| Step: 3
Training loss: 1.0153390335086643
Validation loss: 2.439164358343997

Epoch: 6| Step: 4
Training loss: 1.1696689440564734
Validation loss: 2.469337548189445

Epoch: 6| Step: 5
Training loss: 0.960774260511176
Validation loss: 2.4560200684400137

Epoch: 6| Step: 6
Training loss: 0.6348589784493691
Validation loss: 2.4689544057279864

Epoch: 6| Step: 7
Training loss: 1.6862618177719502
Validation loss: 2.475738256763923

Epoch: 6| Step: 8
Training loss: 1.2064145188479918
Validation loss: 2.4614849678961277

Epoch: 6| Step: 9
Training loss: 0.760460935026966
Validation loss: 2.4638893520174148

Epoch: 6| Step: 10
Training loss: 1.0160459379714273
Validation loss: 2.4658405100960707

Epoch: 6| Step: 11
Training loss: 1.1083750987011465
Validation loss: 2.4920146073503653

Epoch: 6| Step: 12
Training loss: 1.0985582114428565
Validation loss: 2.490131225379894

Epoch: 6| Step: 13
Training loss: 0.8264616329613499
Validation loss: 2.495053108946069

Epoch: 246| Step: 0
Training loss: 1.082834985012419
Validation loss: 2.488962746313315

Epoch: 6| Step: 1
Training loss: 0.6481241595153362
Validation loss: 2.484630740528438

Epoch: 6| Step: 2
Training loss: 0.7878218235431076
Validation loss: 2.476460170161848

Epoch: 6| Step: 3
Training loss: 0.9221491002070626
Validation loss: 2.4630715155411984

Epoch: 6| Step: 4
Training loss: 0.8605420597753813
Validation loss: 2.495035885081715

Epoch: 6| Step: 5
Training loss: 1.7520279714189146
Validation loss: 2.4693710503415387

Epoch: 6| Step: 6
Training loss: 1.2958462323020048
Validation loss: 2.4715707297353284

Epoch: 6| Step: 7
Training loss: 1.1775687181867311
Validation loss: 2.46391798080394

Epoch: 6| Step: 8
Training loss: 1.0559232465962343
Validation loss: 2.488457600848076

Epoch: 6| Step: 9
Training loss: 0.9050334130752598
Validation loss: 2.4691224113917416

Epoch: 6| Step: 10
Training loss: 1.0000970316541233
Validation loss: 2.4674433132674913

Epoch: 6| Step: 11
Training loss: 1.3077234818984642
Validation loss: 2.4858486164674543

Epoch: 6| Step: 12
Training loss: 0.8787429318747458
Validation loss: 2.4993845315342678

Epoch: 6| Step: 13
Training loss: 0.6090544566704271
Validation loss: 2.53756365411065

Epoch: 247| Step: 0
Training loss: 1.1087847469179326
Validation loss: 2.54537655458269

Epoch: 6| Step: 1
Training loss: 0.5600025577997649
Validation loss: 2.513298932733311

Epoch: 6| Step: 2
Training loss: 1.2594882393560862
Validation loss: 2.553611281567717

Epoch: 6| Step: 3
Training loss: 0.9278993479964338
Validation loss: 2.5459241120574485

Epoch: 6| Step: 4
Training loss: 1.035705766032088
Validation loss: 2.488271757959571

Epoch: 6| Step: 5
Training loss: 1.1208602715319358
Validation loss: 2.47695185603047

Epoch: 6| Step: 6
Training loss: 1.1779959468836592
Validation loss: 2.4943713043119162

Epoch: 6| Step: 7
Training loss: 1.0385794413031302
Validation loss: 2.4922548430847153

Epoch: 6| Step: 8
Training loss: 1.5970051005120183
Validation loss: 2.43625434660223

Epoch: 6| Step: 9
Training loss: 0.9089934817039523
Validation loss: 2.4794941276834757

Epoch: 6| Step: 10
Training loss: 1.1833473175637363
Validation loss: 2.465034415734001

Epoch: 6| Step: 11
Training loss: 0.8043426219052371
Validation loss: 2.4561291325876033

Epoch: 6| Step: 12
Training loss: 0.8293292089152224
Validation loss: 2.5031995408389416

Epoch: 6| Step: 13
Training loss: 0.6547801496184896
Validation loss: 2.4491529869836937

Epoch: 248| Step: 0
Training loss: 0.6939067989863437
Validation loss: 2.4402533116455176

Epoch: 6| Step: 1
Training loss: 1.0791968946506962
Validation loss: 2.4487503110661413

Epoch: 6| Step: 2
Training loss: 1.0608485233710674
Validation loss: 2.4606832028787946

Epoch: 6| Step: 3
Training loss: 0.727581990658856
Validation loss: 2.4493327992761156

Epoch: 6| Step: 4
Training loss: 1.332535008011761
Validation loss: 2.4677419482685625

Epoch: 6| Step: 5
Training loss: 0.8895448525985331
Validation loss: 2.481107391832648

Epoch: 6| Step: 6
Training loss: 1.791141684452394
Validation loss: 2.4906479914619926

Epoch: 6| Step: 7
Training loss: 0.8389663016016099
Validation loss: 2.526349881829883

Epoch: 6| Step: 8
Training loss: 0.6002557855015064
Validation loss: 2.4714267508738517

Epoch: 6| Step: 9
Training loss: 1.1277250029885022
Validation loss: 2.4898731493605735

Epoch: 6| Step: 10
Training loss: 1.0250794147337685
Validation loss: 2.484962123643185

Epoch: 6| Step: 11
Training loss: 1.0222005576335034
Validation loss: 2.476134342184501

Epoch: 6| Step: 12
Training loss: 1.0406594302235168
Validation loss: 2.4567948884740325

Epoch: 6| Step: 13
Training loss: 0.753558577781152
Validation loss: 2.4596905126144155

Epoch: 249| Step: 0
Training loss: 0.7481334427028126
Validation loss: 2.489050570082427

Epoch: 6| Step: 1
Training loss: 1.6667434515749326
Validation loss: 2.4805714415529763

Epoch: 6| Step: 2
Training loss: 0.644959486679655
Validation loss: 2.4837564885279377

Epoch: 6| Step: 3
Training loss: 1.013258539208554
Validation loss: 2.50771118159757

Epoch: 6| Step: 4
Training loss: 0.9713632959886246
Validation loss: 2.518911607698246

Epoch: 6| Step: 5
Training loss: 1.1212523876492224
Validation loss: 2.5307499310445403

Epoch: 6| Step: 6
Training loss: 1.3037239674120633
Validation loss: 2.506892629034208

Epoch: 6| Step: 7
Training loss: 0.7073553617521606
Validation loss: 2.504931741469399

Epoch: 6| Step: 8
Training loss: 0.897565036584954
Validation loss: 2.5296358628316837

Epoch: 6| Step: 9
Training loss: 0.6484548497464204
Validation loss: 2.4628344455556515

Epoch: 6| Step: 10
Training loss: 1.3289239612006851
Validation loss: 2.4887952929920316

Epoch: 6| Step: 11
Training loss: 0.9608969330947434
Validation loss: 2.4348312610651384

Epoch: 6| Step: 12
Training loss: 1.1440061334532263
Validation loss: 2.4422069986388886

Epoch: 6| Step: 13
Training loss: 0.9021500548839421
Validation loss: 2.471555234185454

Epoch: 250| Step: 0
Training loss: 1.1338496228981123
Validation loss: 2.4683621404191474

Epoch: 6| Step: 1
Training loss: 0.6226634696436595
Validation loss: 2.4639446661959283

Epoch: 6| Step: 2
Training loss: 1.0012588326282454
Validation loss: 2.4481101066768853

Epoch: 6| Step: 3
Training loss: 1.1957586116684047
Validation loss: 2.50660190926156

Epoch: 6| Step: 4
Training loss: 0.9688030351457373
Validation loss: 2.503912653190229

Epoch: 6| Step: 5
Training loss: 0.958826677521308
Validation loss: 2.51661100677123

Epoch: 6| Step: 6
Training loss: 0.9998138671739744
Validation loss: 2.5379981135553638

Epoch: 6| Step: 7
Training loss: 0.6104833353847099
Validation loss: 2.52039796599771

Epoch: 6| Step: 8
Training loss: 0.9377321591613671
Validation loss: 2.5278972721970536

Epoch: 6| Step: 9
Training loss: 0.7902795451553626
Validation loss: 2.5323538677995763

Epoch: 6| Step: 10
Training loss: 1.0795456744837195
Validation loss: 2.536049747872182

Epoch: 6| Step: 11
Training loss: 1.151771532649436
Validation loss: 2.5141431412901087

Epoch: 6| Step: 12
Training loss: 1.6851642125648545
Validation loss: 2.497013092011031

Epoch: 6| Step: 13
Training loss: 0.8498390676513552
Validation loss: 2.497232446524091

Testing loss: 2.4882361434076636
