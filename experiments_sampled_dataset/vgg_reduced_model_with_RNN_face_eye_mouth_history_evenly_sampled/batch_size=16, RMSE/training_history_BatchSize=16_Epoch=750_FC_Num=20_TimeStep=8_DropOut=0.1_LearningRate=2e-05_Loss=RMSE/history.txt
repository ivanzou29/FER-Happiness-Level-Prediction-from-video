Epoch: 1| Step: 0
Training loss: 5.242119278442541
Validation loss: 5.705524930691294

Epoch: 6| Step: 1
Training loss: 6.368243058593187
Validation loss: 5.689102352809243

Epoch: 6| Step: 2
Training loss: 6.69219007650108
Validation loss: 5.672768115979358

Epoch: 6| Step: 3
Training loss: 6.644780983512373
Validation loss: 5.652920733205637

Epoch: 6| Step: 4
Training loss: 6.098572060471025
Validation loss: 5.62966940984564

Epoch: 6| Step: 5
Training loss: 5.110878819333149
Validation loss: 5.60310440007988

Epoch: 6| Step: 6
Training loss: 5.238352070328962
Validation loss: 5.571597642108828

Epoch: 6| Step: 7
Training loss: 5.538497056602639
Validation loss: 5.537271305218121

Epoch: 6| Step: 8
Training loss: 4.511382225003566
Validation loss: 5.49773656112575

Epoch: 6| Step: 9
Training loss: 4.43222011175196
Validation loss: 5.453447083183123

Epoch: 6| Step: 10
Training loss: 5.164354647915203
Validation loss: 5.4047268826133505

Epoch: 6| Step: 11
Training loss: 5.123343037033736
Validation loss: 5.3517015956894705

Epoch: 6| Step: 12
Training loss: 5.386818423604218
Validation loss: 5.293627023707408

Epoch: 6| Step: 13
Training loss: 6.240470334936358
Validation loss: 5.232490099526318

Epoch: 2| Step: 0
Training loss: 5.02723353457032
Validation loss: 5.170159455675927

Epoch: 6| Step: 1
Training loss: 4.438680787208887
Validation loss: 5.104713637992511

Epoch: 6| Step: 2
Training loss: 4.792047612623989
Validation loss: 5.037294104451443

Epoch: 6| Step: 3
Training loss: 4.272920845782343
Validation loss: 4.971051611315955

Epoch: 6| Step: 4
Training loss: 4.92954124560185
Validation loss: 4.904979661793138

Epoch: 6| Step: 5
Training loss: 4.843387122558935
Validation loss: 4.843341316080102

Epoch: 6| Step: 6
Training loss: 4.607604640490685
Validation loss: 4.782064910102282

Epoch: 6| Step: 7
Training loss: 5.687917170054293
Validation loss: 4.726955579784185

Epoch: 6| Step: 8
Training loss: 4.543477575223905
Validation loss: 4.668559349079117

Epoch: 6| Step: 9
Training loss: 5.2880479749618425
Validation loss: 4.614953928990473

Epoch: 6| Step: 10
Training loss: 5.136262010350022
Validation loss: 4.563221655106001

Epoch: 6| Step: 11
Training loss: 5.092104406109015
Validation loss: 4.516331998231228

Epoch: 6| Step: 12
Training loss: 4.5553476368873875
Validation loss: 4.471076839720992

Epoch: 6| Step: 13
Training loss: 4.118791937144237
Validation loss: 4.433297301954105

Epoch: 3| Step: 0
Training loss: 4.254469372736709
Validation loss: 4.3996111339065

Epoch: 6| Step: 1
Training loss: 5.065138517784652
Validation loss: 4.366284017667118

Epoch: 6| Step: 2
Training loss: 4.69571281668838
Validation loss: 4.3336381442174225

Epoch: 6| Step: 3
Training loss: 4.048044632194448
Validation loss: 4.299929314099367

Epoch: 6| Step: 4
Training loss: 4.842739073563549
Validation loss: 4.271748271255151

Epoch: 6| Step: 5
Training loss: 4.507689370204202
Validation loss: 4.241418311636173

Epoch: 6| Step: 6
Training loss: 4.462172996870908
Validation loss: 4.215954762498191

Epoch: 6| Step: 7
Training loss: 3.552424186096225
Validation loss: 4.1902437693564405

Epoch: 6| Step: 8
Training loss: 4.829985325003182
Validation loss: 4.1648779103818585

Epoch: 6| Step: 9
Training loss: 3.94248961123765
Validation loss: 4.140419005867177

Epoch: 6| Step: 10
Training loss: 4.440394357574702
Validation loss: 4.117624709228186

Epoch: 6| Step: 11
Training loss: 3.895160528555003
Validation loss: 4.095597162985159

Epoch: 6| Step: 12
Training loss: 3.3943052227593595
Validation loss: 4.070859932905724

Epoch: 6| Step: 13
Training loss: 4.857199816810588
Validation loss: 4.049294881587796

Epoch: 4| Step: 0
Training loss: 3.6924760509584695
Validation loss: 4.026516614918924

Epoch: 6| Step: 1
Training loss: 4.771851521192546
Validation loss: 4.008731459313086

Epoch: 6| Step: 2
Training loss: 4.261304966378198
Validation loss: 3.9816114434708565

Epoch: 6| Step: 3
Training loss: 4.2257234935794665
Validation loss: 3.9602368793321197

Epoch: 6| Step: 4
Training loss: 3.73737116052558
Validation loss: 3.9361924348986856

Epoch: 6| Step: 5
Training loss: 4.581800632250536
Validation loss: 3.9153756641107953

Epoch: 6| Step: 6
Training loss: 3.34919566277105
Validation loss: 3.9022988446529907

Epoch: 6| Step: 7
Training loss: 2.895080596645243
Validation loss: 3.892434116130281

Epoch: 6| Step: 8
Training loss: 4.08842669606795
Validation loss: 3.880985781320881

Epoch: 6| Step: 9
Training loss: 4.298966997842058
Validation loss: 3.8730170223692464

Epoch: 6| Step: 10
Training loss: 4.7552669837680055
Validation loss: 3.862178121131427

Epoch: 6| Step: 11
Training loss: 4.1169289900461035
Validation loss: 3.8545650224208856

Epoch: 6| Step: 12
Training loss: 4.04485915949087
Validation loss: 3.8387217139733294

Epoch: 6| Step: 13
Training loss: 3.6261360755968766
Validation loss: 3.8300600218735816

Epoch: 5| Step: 0
Training loss: 3.9830901823223503
Validation loss: 3.8170543266539907

Epoch: 6| Step: 1
Training loss: 4.464015773786342
Validation loss: 3.7999811573025553

Epoch: 6| Step: 2
Training loss: 4.424387295648351
Validation loss: 3.7865819489244226

Epoch: 6| Step: 3
Training loss: 3.659476136618795
Validation loss: 3.7731291008128576

Epoch: 6| Step: 4
Training loss: 3.8334194394820695
Validation loss: 3.7640040115324256

Epoch: 6| Step: 5
Training loss: 3.491917951793207
Validation loss: 3.7539146609086886

Epoch: 6| Step: 6
Training loss: 3.6424686855208517
Validation loss: 3.7464456360129597

Epoch: 6| Step: 7
Training loss: 4.305385526082216
Validation loss: 3.738231497660346

Epoch: 6| Step: 8
Training loss: 3.8343131982972802
Validation loss: 3.7266411193753317

Epoch: 6| Step: 9
Training loss: 4.481546074571348
Validation loss: 3.7184746739339136

Epoch: 6| Step: 10
Training loss: 3.3057452734208272
Validation loss: 3.7091404385769597

Epoch: 6| Step: 11
Training loss: 3.9060873989595453
Validation loss: 3.699583358720207

Epoch: 6| Step: 12
Training loss: 3.5326951032296594
Validation loss: 3.6937926869396382

Epoch: 6| Step: 13
Training loss: 3.923710123948988
Validation loss: 3.6922229522071897

Epoch: 6| Step: 0
Training loss: 3.0570624209773594
Validation loss: 3.6900366416143693

Epoch: 6| Step: 1
Training loss: 4.823093595067612
Validation loss: 3.68480335019385

Epoch: 6| Step: 2
Training loss: 3.9496841835571246
Validation loss: 3.6755695817141474

Epoch: 6| Step: 3
Training loss: 3.5418874484789704
Validation loss: 3.6577945122283073

Epoch: 6| Step: 4
Training loss: 2.9034684519051512
Validation loss: 3.6391292215444495

Epoch: 6| Step: 5
Training loss: 3.3295956796331208
Validation loss: 3.626806649824769

Epoch: 6| Step: 6
Training loss: 3.306217065081043
Validation loss: 3.6188206789547084

Epoch: 6| Step: 7
Training loss: 4.206597804389032
Validation loss: 3.6134986655496095

Epoch: 6| Step: 8
Training loss: 3.6718260416865767
Validation loss: 3.6069828255312957

Epoch: 6| Step: 9
Training loss: 4.89428573930346
Validation loss: 3.601121192043165

Epoch: 6| Step: 10
Training loss: 4.147335272444289
Validation loss: 3.5913616188969795

Epoch: 6| Step: 11
Training loss: 3.308690885989249
Validation loss: 3.581697496011906

Epoch: 6| Step: 12
Training loss: 4.355314818257997
Validation loss: 3.57479992212054

Epoch: 6| Step: 13
Training loss: 2.792773003821256
Validation loss: 3.570867944068343

Epoch: 7| Step: 0
Training loss: 3.676531756621489
Validation loss: 3.56161866353071

Epoch: 6| Step: 1
Training loss: 4.404711732124502
Validation loss: 3.5539686462160343

Epoch: 6| Step: 2
Training loss: 2.7025207549788233
Validation loss: 3.5545247546090213

Epoch: 6| Step: 3
Training loss: 4.004827923643917
Validation loss: 3.5532365143828124

Epoch: 6| Step: 4
Training loss: 3.044555720347676
Validation loss: 3.5443483125554067

Epoch: 6| Step: 5
Training loss: 3.931349901346097
Validation loss: 3.543175439049095

Epoch: 6| Step: 6
Training loss: 3.1761599006469337
Validation loss: 3.533676008156912

Epoch: 6| Step: 7
Training loss: 3.701662185118904
Validation loss: 3.530600256152648

Epoch: 6| Step: 8
Training loss: 4.117117083126478
Validation loss: 3.529029333072131

Epoch: 6| Step: 9
Training loss: 3.8489618710031457
Validation loss: 3.5253743387400074

Epoch: 6| Step: 10
Training loss: 3.895068591668351
Validation loss: 3.5218944495412243

Epoch: 6| Step: 11
Training loss: 4.20999095236198
Validation loss: 3.518150621579133

Epoch: 6| Step: 12
Training loss: 2.9004619756585694
Validation loss: 3.514607035606719

Epoch: 6| Step: 13
Training loss: 4.684515447973227
Validation loss: 3.513546601617157

Epoch: 8| Step: 0
Training loss: 3.8893609502171715
Validation loss: 3.5090146472677235

Epoch: 6| Step: 1
Training loss: 4.377323078826349
Validation loss: 3.50352775173907

Epoch: 6| Step: 2
Training loss: 3.7733268010742296
Validation loss: 3.500149777865591

Epoch: 6| Step: 3
Training loss: 3.294078924849064
Validation loss: 3.4982044797358145

Epoch: 6| Step: 4
Training loss: 4.155832829010997
Validation loss: 3.495567075227813

Epoch: 6| Step: 5
Training loss: 3.2103312493178455
Validation loss: 3.493397981576526

Epoch: 6| Step: 6
Training loss: 3.6680662489537816
Validation loss: 3.48931380094056

Epoch: 6| Step: 7
Training loss: 4.293944313061346
Validation loss: 3.486520887890484

Epoch: 6| Step: 8
Training loss: 3.2546207151918423
Validation loss: 3.4850019673265282

Epoch: 6| Step: 9
Training loss: 3.0448808453176976
Validation loss: 3.483340506691741

Epoch: 6| Step: 10
Training loss: 3.412290623987246
Validation loss: 3.480431153325106

Epoch: 6| Step: 11
Training loss: 3.9006916019796902
Validation loss: 3.47824730066537

Epoch: 6| Step: 12
Training loss: 3.7826174950866682
Validation loss: 3.475955368035171

Epoch: 6| Step: 13
Training loss: 3.384829723633909
Validation loss: 3.4737052197390264

Epoch: 9| Step: 0
Training loss: 3.4252127476907708
Validation loss: 3.4719442116520782

Epoch: 6| Step: 1
Training loss: 3.9814604028411598
Validation loss: 3.469875003598577

Epoch: 6| Step: 2
Training loss: 2.920912966728742
Validation loss: 3.4688744996105507

Epoch: 6| Step: 3
Training loss: 3.8783661772732456
Validation loss: 3.467338785640604

Epoch: 6| Step: 4
Training loss: 2.735413359625261
Validation loss: 3.4660206139103127

Epoch: 6| Step: 5
Training loss: 4.041590240909516
Validation loss: 3.4631812750173716

Epoch: 6| Step: 6
Training loss: 3.8204944777881265
Validation loss: 3.462651095675831

Epoch: 6| Step: 7
Training loss: 2.3896423514366205
Validation loss: 3.4606120616430194

Epoch: 6| Step: 8
Training loss: 4.127658334210162
Validation loss: 3.4591276593647513

Epoch: 6| Step: 9
Training loss: 3.4540811311065225
Validation loss: 3.458059127815204

Epoch: 6| Step: 10
Training loss: 4.575409692649481
Validation loss: 3.456134012802432

Epoch: 6| Step: 11
Training loss: 3.727646644005233
Validation loss: 3.45575613388174

Epoch: 6| Step: 12
Training loss: 3.937141523240362
Validation loss: 3.4541307101288186

Epoch: 6| Step: 13
Training loss: 4.061765164159456
Validation loss: 3.453260380586505

Epoch: 10| Step: 0
Training loss: 3.821019643541892
Validation loss: 3.4511698723245585

Epoch: 6| Step: 1
Training loss: 3.782884480966593
Validation loss: 3.4494931761685663

Epoch: 6| Step: 2
Training loss: 4.087976009171593
Validation loss: 3.448228431919311

Epoch: 6| Step: 3
Training loss: 3.799338965893776
Validation loss: 3.446788749954113

Epoch: 6| Step: 4
Training loss: 3.73689574393311
Validation loss: 3.4455710738105316

Epoch: 6| Step: 5
Training loss: 3.4450473121085023
Validation loss: 3.444039218956692

Epoch: 6| Step: 6
Training loss: 3.6349198986604554
Validation loss: 3.443028788981059

Epoch: 6| Step: 7
Training loss: 3.214908863395503
Validation loss: 3.4422230138832743

Epoch: 6| Step: 8
Training loss: 3.7675350932288523
Validation loss: 3.4414069472636237

Epoch: 6| Step: 9
Training loss: 3.3881368341117866
Validation loss: 3.4404057427249746

Epoch: 6| Step: 10
Training loss: 4.380428107603615
Validation loss: 3.439141007281833

Epoch: 6| Step: 11
Training loss: 3.657414959892133
Validation loss: 3.438230382862801

Epoch: 6| Step: 12
Training loss: 2.7576811761900504
Validation loss: 3.436938624628074

Epoch: 6| Step: 13
Training loss: 3.5465318959188186
Validation loss: 3.4359690891974477

Epoch: 11| Step: 0
Training loss: 3.1349985006471788
Validation loss: 3.4338522147921777

Epoch: 6| Step: 1
Training loss: 3.7617783269393046
Validation loss: 3.432181367006407

Epoch: 6| Step: 2
Training loss: 4.062026245663485
Validation loss: 3.431677810445342

Epoch: 6| Step: 3
Training loss: 4.2441383779618995
Validation loss: 3.4308154580462458

Epoch: 6| Step: 4
Training loss: 3.42931445619461
Validation loss: 3.428418833805824

Epoch: 6| Step: 5
Training loss: 3.0270290284997077
Validation loss: 3.427511138700454

Epoch: 6| Step: 6
Training loss: 4.00660494036951
Validation loss: 3.427703907957451

Epoch: 6| Step: 7
Training loss: 3.536362449608354
Validation loss: 3.4253753845620407

Epoch: 6| Step: 8
Training loss: 3.0893145275583556
Validation loss: 3.424469618228567

Epoch: 6| Step: 9
Training loss: 3.511260854637069
Validation loss: 3.425593427101086

Epoch: 6| Step: 10
Training loss: 4.5366870750923045
Validation loss: 3.420519837795961

Epoch: 6| Step: 11
Training loss: 3.094636115897851
Validation loss: 3.4184470821449877

Epoch: 6| Step: 12
Training loss: 3.886019267106602
Validation loss: 3.4170973651620486

Epoch: 6| Step: 13
Training loss: 3.2110004650912782
Validation loss: 3.4142106595856667

Epoch: 12| Step: 0
Training loss: 3.8266800625219926
Validation loss: 3.4112885303347635

Epoch: 6| Step: 1
Training loss: 3.199593732793531
Validation loss: 3.408562347147944

Epoch: 6| Step: 2
Training loss: 3.4335090357688087
Validation loss: 3.407684444101133

Epoch: 6| Step: 3
Training loss: 3.3933065331930226
Validation loss: 3.4054449988616633

Epoch: 6| Step: 4
Training loss: 2.9992533390388747
Validation loss: 3.4058341157860226

Epoch: 6| Step: 5
Training loss: 4.137475770262796
Validation loss: 3.4048850802058994

Epoch: 6| Step: 6
Training loss: 3.393530097707673
Validation loss: 3.4029056809371623

Epoch: 6| Step: 7
Training loss: 3.4947838742907877
Validation loss: 3.401395326350736

Epoch: 6| Step: 8
Training loss: 4.648323429535257
Validation loss: 3.4000201666232086

Epoch: 6| Step: 9
Training loss: 3.7936948165776494
Validation loss: 3.3983037194085006

Epoch: 6| Step: 10
Training loss: 2.825787837806808
Validation loss: 3.396606151024785

Epoch: 6| Step: 11
Training loss: 4.220633983266391
Validation loss: 3.3948213383059653

Epoch: 6| Step: 12
Training loss: 3.2362223339113827
Validation loss: 3.392730710781657

Epoch: 6| Step: 13
Training loss: 3.8859564412218686
Validation loss: 3.3900476558344965

Epoch: 13| Step: 0
Training loss: 4.202399322374929
Validation loss: 3.386390206550453

Epoch: 6| Step: 1
Training loss: 3.0051144872300397
Validation loss: 3.3841428939196425

Epoch: 6| Step: 2
Training loss: 2.837689323663152
Validation loss: 3.3846606530072894

Epoch: 6| Step: 3
Training loss: 4.14503974923101
Validation loss: 3.412966316374763

Epoch: 6| Step: 4
Training loss: 2.784997451342747
Validation loss: 3.3855605319039577

Epoch: 6| Step: 5
Training loss: 3.9501004314933916
Validation loss: 3.565422633836987

Epoch: 6| Step: 6
Training loss: 4.764227189983013
Validation loss: 3.4501865520216133

Epoch: 6| Step: 7
Training loss: 3.266250769421282
Validation loss: 3.3859296179450733

Epoch: 6| Step: 8
Training loss: 3.6775642635246384
Validation loss: 3.528954023317494

Epoch: 6| Step: 9
Training loss: 3.249390178101272
Validation loss: 3.52018851496495

Epoch: 6| Step: 10
Training loss: 2.7979379690518713
Validation loss: 3.523640308764704

Epoch: 6| Step: 11
Training loss: 4.33858704590926
Validation loss: 3.441449525518272

Epoch: 6| Step: 12
Training loss: 3.6970764208472175
Validation loss: 3.420313783681732

Epoch: 6| Step: 13
Training loss: 4.168430921247808
Validation loss: 3.4334662851249322

Epoch: 14| Step: 0
Training loss: 4.456085612941942
Validation loss: 3.4586078511617355

Epoch: 6| Step: 1
Training loss: 2.865203420397719
Validation loss: 3.461382821029146

Epoch: 6| Step: 2
Training loss: 4.35547707047972
Validation loss: 3.4626389017716677

Epoch: 6| Step: 3
Training loss: 3.343114204211017
Validation loss: 3.445639228633614

Epoch: 6| Step: 4
Training loss: 2.89819532344052
Validation loss: 3.4277940248798044

Epoch: 6| Step: 5
Training loss: 3.3671873583871057
Validation loss: 3.4069071016707495

Epoch: 6| Step: 6
Training loss: 3.8475868489933887
Validation loss: 3.3937503071156363

Epoch: 6| Step: 7
Training loss: 3.723266167326584
Validation loss: 3.388033933168786

Epoch: 6| Step: 8
Training loss: 3.8772241915629055
Validation loss: 3.388929983490917

Epoch: 6| Step: 9
Training loss: 3.631725649122015
Validation loss: 3.388419914565668

Epoch: 6| Step: 10
Training loss: 4.0944127136086745
Validation loss: 3.3862993049901497

Epoch: 6| Step: 11
Training loss: 3.0567641748193437
Validation loss: 3.379978729514119

Epoch: 6| Step: 12
Training loss: 3.53360244577853
Validation loss: 3.3728376804723235

Epoch: 6| Step: 13
Training loss: 3.321935064251852
Validation loss: 3.371355115952917

Epoch: 15| Step: 0
Training loss: 3.3332543045848158
Validation loss: 3.384419339597162

Epoch: 6| Step: 1
Training loss: 4.182246770495065
Validation loss: 3.361254244241851

Epoch: 6| Step: 2
Training loss: 3.803213848496108
Validation loss: 3.3582961574426493

Epoch: 6| Step: 3
Training loss: 3.214715595866093
Validation loss: 3.356199724661786

Epoch: 6| Step: 4
Training loss: 3.426908788130067
Validation loss: 3.3555008019564596

Epoch: 6| Step: 5
Training loss: 4.258631076344742
Validation loss: 3.35668171288963

Epoch: 6| Step: 6
Training loss: 3.59757645939952
Validation loss: 3.352593250790851

Epoch: 6| Step: 7
Training loss: 2.699875305969823
Validation loss: 3.350063359006229

Epoch: 6| Step: 8
Training loss: 3.8429969111878575
Validation loss: 3.34857487456375

Epoch: 6| Step: 9
Training loss: 3.7184802045645315
Validation loss: 3.346512432464806

Epoch: 6| Step: 10
Training loss: 3.4819836814186846
Validation loss: 3.346491131238583

Epoch: 6| Step: 11
Training loss: 3.6149827075085628
Validation loss: 3.3436093197764585

Epoch: 6| Step: 12
Training loss: 3.3642640488875433
Validation loss: 3.339357392234883

Epoch: 6| Step: 13
Training loss: 3.335619015644517
Validation loss: 3.338213569558243

Epoch: 16| Step: 0
Training loss: 3.846391468043711
Validation loss: 3.3367165552088465

Epoch: 6| Step: 1
Training loss: 3.6890596873665684
Validation loss: 3.3346552693765856

Epoch: 6| Step: 2
Training loss: 3.955089337368366
Validation loss: 3.334097916581212

Epoch: 6| Step: 3
Training loss: 3.1509981178658206
Validation loss: 3.3319522001139537

Epoch: 6| Step: 4
Training loss: 3.162122494326938
Validation loss: 3.3312669860989192

Epoch: 6| Step: 5
Training loss: 3.3840501736828505
Validation loss: 3.3292910350971896

Epoch: 6| Step: 6
Training loss: 3.71117238154692
Validation loss: 3.3285463851970243

Epoch: 6| Step: 7
Training loss: 3.436666214132295
Validation loss: 3.325437841424478

Epoch: 6| Step: 8
Training loss: 3.129066263172017
Validation loss: 3.3228548573750825

Epoch: 6| Step: 9
Training loss: 4.161403128870906
Validation loss: 3.3192398730333603

Epoch: 6| Step: 10
Training loss: 4.005236535868007
Validation loss: 3.3139892979101275

Epoch: 6| Step: 11
Training loss: 3.761009078063801
Validation loss: 3.309683078935018

Epoch: 6| Step: 12
Training loss: 3.198025099979689
Validation loss: 3.3018661887755467

Epoch: 6| Step: 13
Training loss: 2.604422065926595
Validation loss: 3.2981985079718807

Epoch: 17| Step: 0
Training loss: 3.3380831891133877
Validation loss: 3.2960019647221257

Epoch: 6| Step: 1
Training loss: 3.4020348462311056
Validation loss: 3.2934193675604275

Epoch: 6| Step: 2
Training loss: 3.641856496884039
Validation loss: 3.292393121481419

Epoch: 6| Step: 3
Training loss: 3.144459371752255
Validation loss: 3.2908744027316454

Epoch: 6| Step: 4
Training loss: 3.753742639189524
Validation loss: 3.2897187405654447

Epoch: 6| Step: 5
Training loss: 3.097154689750128
Validation loss: 3.289115026324118

Epoch: 6| Step: 6
Training loss: 3.4625700464978753
Validation loss: 3.2880110909016658

Epoch: 6| Step: 7
Training loss: 3.681874785325331
Validation loss: 3.2867539723026136

Epoch: 6| Step: 8
Training loss: 4.1272874905219465
Validation loss: 3.285503090988258

Epoch: 6| Step: 9
Training loss: 4.4107283972034015
Validation loss: 3.28411830186475

Epoch: 6| Step: 10
Training loss: 3.455119941937094
Validation loss: 3.2829012589667004

Epoch: 6| Step: 11
Training loss: 3.373085609306405
Validation loss: 3.28186748767144

Epoch: 6| Step: 12
Training loss: 2.963972886037428
Validation loss: 3.280150420398651

Epoch: 6| Step: 13
Training loss: 3.199770031056599
Validation loss: 3.2802706302336917

Epoch: 18| Step: 0
Training loss: 3.2698369219417884
Validation loss: 3.278653468257579

Epoch: 6| Step: 1
Training loss: 3.0403827064948787
Validation loss: 3.2783761107258433

Epoch: 6| Step: 2
Training loss: 3.7881230713651046
Validation loss: 3.2772583370589023

Epoch: 6| Step: 3
Training loss: 4.263905608358058
Validation loss: 3.2764144918253524

Epoch: 6| Step: 4
Training loss: 2.8570311899161704
Validation loss: 3.2752501653246653

Epoch: 6| Step: 5
Training loss: 2.935667399700627
Validation loss: 3.274643021132364

Epoch: 6| Step: 6
Training loss: 4.1236588580930995
Validation loss: 3.2729478241169585

Epoch: 6| Step: 7
Training loss: 3.8529375883067725
Validation loss: 3.2720239192956764

Epoch: 6| Step: 8
Training loss: 3.33309236291271
Validation loss: 3.2707799344510824

Epoch: 6| Step: 9
Training loss: 3.3030405833158847
Validation loss: 3.2702843308726877

Epoch: 6| Step: 10
Training loss: 3.1591514621517325
Validation loss: 3.2695543244240195

Epoch: 6| Step: 11
Training loss: 3.8946689898927893
Validation loss: 3.2684790642173613

Epoch: 6| Step: 12
Training loss: 3.119212628072735
Validation loss: 3.2680374092521105

Epoch: 6| Step: 13
Training loss: 4.270362096080452
Validation loss: 3.266231621240482

Epoch: 19| Step: 0
Training loss: 3.4766811393468258
Validation loss: 3.265640582972693

Epoch: 6| Step: 1
Training loss: 2.9367109821741506
Validation loss: 3.2645734053625306

Epoch: 6| Step: 2
Training loss: 4.002777327508759
Validation loss: 3.2635842095496184

Epoch: 6| Step: 3
Training loss: 3.5909507132292013
Validation loss: 3.2628570906555696

Epoch: 6| Step: 4
Training loss: 3.971043922521473
Validation loss: 3.2619163012719365

Epoch: 6| Step: 5
Training loss: 2.852294493484759
Validation loss: 3.2608772200758653

Epoch: 6| Step: 6
Training loss: 3.4576673364312867
Validation loss: 3.2597243487297227

Epoch: 6| Step: 7
Training loss: 2.9817213473593305
Validation loss: 3.2587884221383066

Epoch: 6| Step: 8
Training loss: 3.819998074875591
Validation loss: 3.257767945809715

Epoch: 6| Step: 9
Training loss: 3.8001438715954188
Validation loss: 3.256784364150809

Epoch: 6| Step: 10
Training loss: 3.0542547597492864
Validation loss: 3.2559762220133006

Epoch: 6| Step: 11
Training loss: 3.6254614174615005
Validation loss: 3.2550767257501807

Epoch: 6| Step: 12
Training loss: 3.59180829210733
Validation loss: 3.25446415909867

Epoch: 6| Step: 13
Training loss: 3.880075514736928
Validation loss: 3.253514510698094

Epoch: 20| Step: 0
Training loss: 3.8533927484131367
Validation loss: 3.252358261729911

Epoch: 6| Step: 1
Training loss: 3.038739733974827
Validation loss: 3.2516314290413044

Epoch: 6| Step: 2
Training loss: 2.9615320097007936
Validation loss: 3.25064908843172

Epoch: 6| Step: 3
Training loss: 3.9465251607485525
Validation loss: 3.2499183205941518

Epoch: 6| Step: 4
Training loss: 3.150346730843469
Validation loss: 3.2494346893722548

Epoch: 6| Step: 5
Training loss: 3.5323927389114114
Validation loss: 3.248372141182293

Epoch: 6| Step: 6
Training loss: 3.6408234243388344
Validation loss: 3.2473809864690844

Epoch: 6| Step: 7
Training loss: 4.141290344907635
Validation loss: 3.24630031903539

Epoch: 6| Step: 8
Training loss: 2.812508816175418
Validation loss: 3.2455862836795384

Epoch: 6| Step: 9
Training loss: 3.979831393710452
Validation loss: 3.2447215948875945

Epoch: 6| Step: 10
Training loss: 3.0848600027508972
Validation loss: 3.2438713167855253

Epoch: 6| Step: 11
Training loss: 4.141813287627813
Validation loss: 3.243270904524816

Epoch: 6| Step: 12
Training loss: 3.38119038019837
Validation loss: 3.2423550161828865

Epoch: 6| Step: 13
Training loss: 2.375069065093654
Validation loss: 3.2414923284261623

Epoch: 21| Step: 0
Training loss: 3.2448664983669393
Validation loss: 3.2402504392794342

Epoch: 6| Step: 1
Training loss: 4.132208565499106
Validation loss: 3.239783116913978

Epoch: 6| Step: 2
Training loss: 2.8870976551691836
Validation loss: 3.238628931513425

Epoch: 6| Step: 3
Training loss: 3.373533566102263
Validation loss: 3.2381122183352375

Epoch: 6| Step: 4
Training loss: 2.4560407088319893
Validation loss: 3.237167450468748

Epoch: 6| Step: 5
Training loss: 3.60009709333247
Validation loss: 3.236262336702088

Epoch: 6| Step: 6
Training loss: 4.059303317123538
Validation loss: 3.2352897955818607

Epoch: 6| Step: 7
Training loss: 3.683755816457329
Validation loss: 3.234742581896257

Epoch: 6| Step: 8
Training loss: 3.9777490910206645
Validation loss: 3.233695558615734

Epoch: 6| Step: 9
Training loss: 3.5432221680575373
Validation loss: 3.232951417632875

Epoch: 6| Step: 10
Training loss: 3.451240405021353
Validation loss: 3.231857687468117

Epoch: 6| Step: 11
Training loss: 3.095130381264474
Validation loss: 3.231136003876554

Epoch: 6| Step: 12
Training loss: 3.433799832943762
Validation loss: 3.23028358305448

Epoch: 6| Step: 13
Training loss: 3.604726464929467
Validation loss: 3.229299595875784

Epoch: 22| Step: 0
Training loss: 3.138652124918415
Validation loss: 3.2283509244598427

Epoch: 6| Step: 1
Training loss: 2.485188572903353
Validation loss: 3.227539698735815

Epoch: 6| Step: 2
Training loss: 3.70856960844062
Validation loss: 3.2266851615040952

Epoch: 6| Step: 3
Training loss: 3.520110121868429
Validation loss: 3.225970022094764

Epoch: 6| Step: 4
Training loss: 3.9805950111077686
Validation loss: 3.2249880272911025

Epoch: 6| Step: 5
Training loss: 2.6176281003019657
Validation loss: 3.2238495736296104

Epoch: 6| Step: 6
Training loss: 3.339730244096448
Validation loss: 3.222847261109787

Epoch: 6| Step: 7
Training loss: 3.3792141636255404
Validation loss: 3.2216799851092124

Epoch: 6| Step: 8
Training loss: 4.077113234316586
Validation loss: 3.220869475801861

Epoch: 6| Step: 9
Training loss: 3.9186694658634362
Validation loss: 3.2194501045946438

Epoch: 6| Step: 10
Training loss: 3.3613634478914656
Validation loss: 3.21859923647922

Epoch: 6| Step: 11
Training loss: 3.5851738808573073
Validation loss: 3.217483272842861

Epoch: 6| Step: 12
Training loss: 3.8905390841025103
Validation loss: 3.2164744907640177

Epoch: 6| Step: 13
Training loss: 3.1534381087184156
Validation loss: 3.2158348963793477

Epoch: 23| Step: 0
Training loss: 3.7516507647965494
Validation loss: 3.2150226503816755

Epoch: 6| Step: 1
Training loss: 3.4208316693009584
Validation loss: 3.2139563366820294

Epoch: 6| Step: 2
Training loss: 3.810522723646875
Validation loss: 3.213850559797556

Epoch: 6| Step: 3
Training loss: 3.6487109063443453
Validation loss: 3.2131385254514164

Epoch: 6| Step: 4
Training loss: 2.2537454584110854
Validation loss: 3.2110962149489133

Epoch: 6| Step: 5
Training loss: 3.100589628442685
Validation loss: 3.2103914505597504

Epoch: 6| Step: 6
Training loss: 2.488959634670438
Validation loss: 3.2093940396327305

Epoch: 6| Step: 7
Training loss: 3.6686782232018533
Validation loss: 3.2086626152096738

Epoch: 6| Step: 8
Training loss: 3.2424236900979486
Validation loss: 3.2081906324618013

Epoch: 6| Step: 9
Training loss: 3.418416823308834
Validation loss: 3.207418264664605

Epoch: 6| Step: 10
Training loss: 3.053579300158815
Validation loss: 3.206665147665846

Epoch: 6| Step: 11
Training loss: 4.622502245327377
Validation loss: 3.2058053188259525

Epoch: 6| Step: 12
Training loss: 3.638019202233588
Validation loss: 3.2051965161309726

Epoch: 6| Step: 13
Training loss: 4.044274632471989
Validation loss: 3.2039884486467267

Epoch: 24| Step: 0
Training loss: 3.6637524959642906
Validation loss: 3.203343097616014

Epoch: 6| Step: 1
Training loss: 3.2521284909547603
Validation loss: 3.202051014984338

Epoch: 6| Step: 2
Training loss: 3.3163047388579474
Validation loss: 3.2013606637001972

Epoch: 6| Step: 3
Training loss: 3.2353195801411228
Validation loss: 3.200493462261949

Epoch: 6| Step: 4
Training loss: 4.227758213777149
Validation loss: 3.1990302163533086

Epoch: 6| Step: 5
Training loss: 3.314204371327936
Validation loss: 3.1985666882953665

Epoch: 6| Step: 6
Training loss: 3.0754773521525918
Validation loss: 3.197716504702635

Epoch: 6| Step: 7
Training loss: 3.6625817403687817
Validation loss: 3.196888693121596

Epoch: 6| Step: 8
Training loss: 3.416954927767347
Validation loss: 3.1960818255162273

Epoch: 6| Step: 9
Training loss: 3.937161627868478
Validation loss: 3.195026719389549

Epoch: 6| Step: 10
Training loss: 3.7851198428896042
Validation loss: 3.194181304860687

Epoch: 6| Step: 11
Training loss: 2.8036423970092224
Validation loss: 3.1935559113472802

Epoch: 6| Step: 12
Training loss: 3.427759971414402
Validation loss: 3.192833907199555

Epoch: 6| Step: 13
Training loss: 2.7049839926085615
Validation loss: 3.191915952982797

Epoch: 25| Step: 0
Training loss: 3.124381957926808
Validation loss: 3.1910398276461374

Epoch: 6| Step: 1
Training loss: 3.7351778196930012
Validation loss: 3.19026700811117

Epoch: 6| Step: 2
Training loss: 3.5269625131395705
Validation loss: 3.1893637362139615

Epoch: 6| Step: 3
Training loss: 3.4926612754508817
Validation loss: 3.1886274630740234

Epoch: 6| Step: 4
Training loss: 2.9682796708028647
Validation loss: 3.187742391752349

Epoch: 6| Step: 5
Training loss: 4.043383413970662
Validation loss: 3.1868576489951534

Epoch: 6| Step: 6
Training loss: 3.704806046859759
Validation loss: 3.186568646707703

Epoch: 6| Step: 7
Training loss: 3.9509067267296847
Validation loss: 3.1853304868494208

Epoch: 6| Step: 8
Training loss: 3.273956621836936
Validation loss: 3.1846915525422568

Epoch: 6| Step: 9
Training loss: 3.03150860184763
Validation loss: 3.1838909534621216

Epoch: 6| Step: 10
Training loss: 2.8444709283205105
Validation loss: 3.1828515784209266

Epoch: 6| Step: 11
Training loss: 2.8135146959733492
Validation loss: 3.1819105425434095

Epoch: 6| Step: 12
Training loss: 4.305868606398296
Validation loss: 3.1815505171284673

Epoch: 6| Step: 13
Training loss: 2.742546731834108
Validation loss: 3.1805385879558616

Epoch: 26| Step: 0
Training loss: 3.9013493428878507
Validation loss: 3.179786317979954

Epoch: 6| Step: 1
Training loss: 3.926611847573104
Validation loss: 3.1790824895657974

Epoch: 6| Step: 2
Training loss: 3.493158738769706
Validation loss: 3.178224723231361

Epoch: 6| Step: 3
Training loss: 3.1978460215035516
Validation loss: 3.1774818099243607

Epoch: 6| Step: 4
Training loss: 4.373660509230226
Validation loss: 3.1765176033698594

Epoch: 6| Step: 5
Training loss: 2.685917588049738
Validation loss: 3.1757511201612454

Epoch: 6| Step: 6
Training loss: 3.5037271545296833
Validation loss: 3.174886169214649

Epoch: 6| Step: 7
Training loss: 3.472573037968866
Validation loss: 3.1742810302885975

Epoch: 6| Step: 8
Training loss: 3.373065818110531
Validation loss: 3.173410750769486

Epoch: 6| Step: 9
Training loss: 3.6246809983476775
Validation loss: 3.172433241993972

Epoch: 6| Step: 10
Training loss: 2.9652133153439677
Validation loss: 3.1714315160466144

Epoch: 6| Step: 11
Training loss: 3.0736607744407074
Validation loss: 3.1710517995506415

Epoch: 6| Step: 12
Training loss: 2.5173662686934564
Validation loss: 3.1698735476015263

Epoch: 6| Step: 13
Training loss: 3.730357926405218
Validation loss: 3.169445896142657

Epoch: 27| Step: 0
Training loss: 3.927092224164995
Validation loss: 3.1684800387069103

Epoch: 6| Step: 1
Training loss: 3.351452663373598
Validation loss: 3.167742071094714

Epoch: 6| Step: 2
Training loss: 3.2336457393252056
Validation loss: 3.16706680841796

Epoch: 6| Step: 3
Training loss: 3.9789439566769444
Validation loss: 3.166250480564795

Epoch: 6| Step: 4
Training loss: 3.537653964840424
Validation loss: 3.165473687906207

Epoch: 6| Step: 5
Training loss: 3.082909597887216
Validation loss: 3.164947978146237

Epoch: 6| Step: 6
Training loss: 3.612039218541817
Validation loss: 3.163698933854605

Epoch: 6| Step: 7
Training loss: 3.37919948826916
Validation loss: 3.163023458046373

Epoch: 6| Step: 8
Training loss: 3.9526824100296882
Validation loss: 3.162629588945367

Epoch: 6| Step: 9
Training loss: 3.466455198831771
Validation loss: 3.161862860655478

Epoch: 6| Step: 10
Training loss: 3.0027278578007524
Validation loss: 3.161005411834864

Epoch: 6| Step: 11
Training loss: 3.0237390333326086
Validation loss: 3.1601701432412006

Epoch: 6| Step: 12
Training loss: 2.7953771064503705
Validation loss: 3.1591788808794945

Epoch: 6| Step: 13
Training loss: 3.466873211087387
Validation loss: 3.1583352767969095

Epoch: 28| Step: 0
Training loss: 3.4450462048093757
Validation loss: 3.1578173381120935

Epoch: 6| Step: 1
Training loss: 3.362951743259221
Validation loss: 3.1569578793719466

Epoch: 6| Step: 2
Training loss: 3.0199789132398878
Validation loss: 3.156264392905658

Epoch: 6| Step: 3
Training loss: 3.7446250542444166
Validation loss: 3.155395793469237

Epoch: 6| Step: 4
Training loss: 4.542373158978165
Validation loss: 3.1545593223651776

Epoch: 6| Step: 5
Training loss: 3.827904768856403
Validation loss: 3.154065936286613

Epoch: 6| Step: 6
Training loss: 3.12735171520735
Validation loss: 3.1532422605492836

Epoch: 6| Step: 7
Training loss: 2.9972181137696317
Validation loss: 3.1521412168238943

Epoch: 6| Step: 8
Training loss: 3.229799877143927
Validation loss: 3.15139162660492

Epoch: 6| Step: 9
Training loss: 3.80853490539477
Validation loss: 3.1507033926279555

Epoch: 6| Step: 10
Training loss: 3.2245454926288764
Validation loss: 3.1497856552918453

Epoch: 6| Step: 11
Training loss: 4.0095127953200205
Validation loss: 3.1488837046017806

Epoch: 6| Step: 12
Training loss: 1.481790883264391
Validation loss: 3.1482423912074284

Epoch: 6| Step: 13
Training loss: 2.9884156041079657
Validation loss: 3.147364294320817

Epoch: 29| Step: 0
Training loss: 2.9175327286768167
Validation loss: 3.146711956288839

Epoch: 6| Step: 1
Training loss: 3.47949986185303
Validation loss: 3.1461795914317214

Epoch: 6| Step: 2
Training loss: 4.110882036740427
Validation loss: 3.145499610163674

Epoch: 6| Step: 3
Training loss: 2.870023649962274
Validation loss: 3.1445341115948837

Epoch: 6| Step: 4
Training loss: 3.9530919492041043
Validation loss: 3.1440987001774525

Epoch: 6| Step: 5
Training loss: 3.5169115213301496
Validation loss: 3.143392121051885

Epoch: 6| Step: 6
Training loss: 2.88894588055596
Validation loss: 3.1423779956581033

Epoch: 6| Step: 7
Training loss: 3.006567442187823
Validation loss: 3.141584420930315

Epoch: 6| Step: 8
Training loss: 4.140966322164288
Validation loss: 3.141154566673196

Epoch: 6| Step: 9
Training loss: 3.228942141366878
Validation loss: 3.1404883511549975

Epoch: 6| Step: 10
Training loss: 3.1780731827104116
Validation loss: 3.1396785177802733

Epoch: 6| Step: 11
Training loss: 4.236327674763692
Validation loss: 3.1389731692204568

Epoch: 6| Step: 12
Training loss: 2.8608578031763683
Validation loss: 3.1381108883752766

Epoch: 6| Step: 13
Training loss: 2.3947981768089988
Validation loss: 3.137387611053871

Epoch: 30| Step: 0
Training loss: 3.3440574433352923
Validation loss: 3.136816541705103

Epoch: 6| Step: 1
Training loss: 3.298453870449887
Validation loss: 3.1360235256869555

Epoch: 6| Step: 2
Training loss: 3.5101415298054772
Validation loss: 3.135581056417657

Epoch: 6| Step: 3
Training loss: 2.8596613172587886
Validation loss: 3.1348322086944562

Epoch: 6| Step: 4
Training loss: 3.2261619781109547
Validation loss: 3.134056059099561

Epoch: 6| Step: 5
Training loss: 4.095499844070113
Validation loss: 3.1332696157647537

Epoch: 6| Step: 6
Training loss: 2.571379466193463
Validation loss: 3.1325416540945907

Epoch: 6| Step: 7
Training loss: 3.2723002131058183
Validation loss: 3.131988563521223

Epoch: 6| Step: 8
Training loss: 3.1304498072623006
Validation loss: 3.1315086740130718

Epoch: 6| Step: 9
Training loss: 3.6827196073085293
Validation loss: 3.1307407538075314

Epoch: 6| Step: 10
Training loss: 3.1834781181071117
Validation loss: 3.129782898894662

Epoch: 6| Step: 11
Training loss: 4.103425451174861
Validation loss: 3.129562897517612

Epoch: 6| Step: 12
Training loss: 3.826850523259063
Validation loss: 3.128878903561044

Epoch: 6| Step: 13
Training loss: 3.082554452481683
Validation loss: 3.127993782578278

Epoch: 31| Step: 0
Training loss: 3.1442986254211283
Validation loss: 3.1269993266318448

Epoch: 6| Step: 1
Training loss: 3.0711605075440365
Validation loss: 3.1265702877919437

Epoch: 6| Step: 2
Training loss: 2.9090759320307047
Validation loss: 3.1256371338772673

Epoch: 6| Step: 3
Training loss: 3.7685987198613136
Validation loss: 3.1249452910197646

Epoch: 6| Step: 4
Training loss: 3.4637580211247796
Validation loss: 3.124113993405512

Epoch: 6| Step: 5
Training loss: 3.6708482970770953
Validation loss: 3.1236158870227646

Epoch: 6| Step: 6
Training loss: 3.474302916282539
Validation loss: 3.122736963382667

Epoch: 6| Step: 7
Training loss: 3.77305850698493
Validation loss: 3.1220786494706685

Epoch: 6| Step: 8
Training loss: 3.2000200807418193
Validation loss: 3.1210610682942193

Epoch: 6| Step: 9
Training loss: 3.7560221318902025
Validation loss: 3.120550368488533

Epoch: 6| Step: 10
Training loss: 3.103038369436057
Validation loss: 3.1197973180040353

Epoch: 6| Step: 11
Training loss: 3.8389001038003068
Validation loss: 3.119021349353336

Epoch: 6| Step: 12
Training loss: 3.246433355054219
Validation loss: 3.118099903490143

Epoch: 6| Step: 13
Training loss: 2.544764199865335
Validation loss: 3.117374856689655

Epoch: 32| Step: 0
Training loss: 2.5626629103071696
Validation loss: 3.1164712435859387

Epoch: 6| Step: 1
Training loss: 3.3148917434530176
Validation loss: 3.1159521959249408

Epoch: 6| Step: 2
Training loss: 4.08688011018603
Validation loss: 3.115315629062291

Epoch: 6| Step: 3
Training loss: 2.8672107830713367
Validation loss: 3.114768159651392

Epoch: 6| Step: 4
Training loss: 2.888371099220376
Validation loss: 3.1140332006557316

Epoch: 6| Step: 5
Training loss: 3.655280090537961
Validation loss: 3.1133500157965703

Epoch: 6| Step: 6
Training loss: 3.857946710735644
Validation loss: 3.112609419415122

Epoch: 6| Step: 7
Training loss: 2.7223719882206647
Validation loss: 3.1119990063930456

Epoch: 6| Step: 8
Training loss: 3.210980714381873
Validation loss: 3.1112820795749183

Epoch: 6| Step: 9
Training loss: 3.595574222804922
Validation loss: 3.110315845173862

Epoch: 6| Step: 10
Training loss: 3.6173251230906214
Validation loss: 3.109714067638059

Epoch: 6| Step: 11
Training loss: 3.824344932960384
Validation loss: 3.1093664550004245

Epoch: 6| Step: 12
Training loss: 3.00165258031149
Validation loss: 3.1083900927040258

Epoch: 6| Step: 13
Training loss: 4.098932378445197
Validation loss: 3.1078562299232004

Epoch: 33| Step: 0
Training loss: 3.9050987072923378
Validation loss: 3.1070669455450335

Epoch: 6| Step: 1
Training loss: 3.6278405734344674
Validation loss: 3.106394355268478

Epoch: 6| Step: 2
Training loss: 3.14039147870554
Validation loss: 3.105398640712226

Epoch: 6| Step: 3
Training loss: 2.262812690834951
Validation loss: 3.104521382137767

Epoch: 6| Step: 4
Training loss: 2.8193432101244094
Validation loss: 3.1039529217400768

Epoch: 6| Step: 5
Training loss: 4.291127192592619
Validation loss: 3.1032733830827905

Epoch: 6| Step: 6
Training loss: 3.71512587445722
Validation loss: 3.1023811054994095

Epoch: 6| Step: 7
Training loss: 3.452399682556357
Validation loss: 3.101705793171963

Epoch: 6| Step: 8
Training loss: 2.6016490108551524
Validation loss: 3.100964125491526

Epoch: 6| Step: 9
Training loss: 3.6326195450268575
Validation loss: 3.100148374626875

Epoch: 6| Step: 10
Training loss: 3.8413872628928765
Validation loss: 3.099713748070161

Epoch: 6| Step: 11
Training loss: 3.078769674420268
Validation loss: 3.098998723430841

Epoch: 6| Step: 12
Training loss: 2.9154972093385947
Validation loss: 3.09831128099275

Epoch: 6| Step: 13
Training loss: 3.5245938655558966
Validation loss: 3.0972993472830193

Epoch: 34| Step: 0
Training loss: 2.9437251581978296
Validation loss: 3.0966219167075346

Epoch: 6| Step: 1
Training loss: 2.8196740101361897
Validation loss: 3.0959012699839388

Epoch: 6| Step: 2
Training loss: 3.151822903891124
Validation loss: 3.095391462946678

Epoch: 6| Step: 3
Training loss: 3.0513679438467185
Validation loss: 3.0946717573869997

Epoch: 6| Step: 4
Training loss: 3.3175331600460862
Validation loss: 3.0942238231147945

Epoch: 6| Step: 5
Training loss: 3.298505623898664
Validation loss: 3.0933462562925818

Epoch: 6| Step: 6
Training loss: 4.146762200713658
Validation loss: 3.0928174922634146

Epoch: 6| Step: 7
Training loss: 3.9007005258004592
Validation loss: 3.0920436657687995

Epoch: 6| Step: 8
Training loss: 3.5638019792665694
Validation loss: 3.091134875393775

Epoch: 6| Step: 9
Training loss: 3.8596308696731967
Validation loss: 3.090620922692

Epoch: 6| Step: 10
Training loss: 3.4628170928635447
Validation loss: 3.089749717108662

Epoch: 6| Step: 11
Training loss: 3.1737696809522795
Validation loss: 3.08897266383766

Epoch: 6| Step: 12
Training loss: 2.9758780586117037
Validation loss: 3.0881743393278

Epoch: 6| Step: 13
Training loss: 3.1929921723606447
Validation loss: 3.087433946492544

Epoch: 35| Step: 0
Training loss: 4.057539508319329
Validation loss: 3.0867905284745705

Epoch: 6| Step: 1
Training loss: 3.2649266714650644
Validation loss: 3.0860908159722875

Epoch: 6| Step: 2
Training loss: 3.788674120317795
Validation loss: 3.085313593997959

Epoch: 6| Step: 3
Training loss: 3.1067754719335308
Validation loss: 3.084721517706762

Epoch: 6| Step: 4
Training loss: 4.098171961708583
Validation loss: 3.0839924632999525

Epoch: 6| Step: 5
Training loss: 2.9868345660745352
Validation loss: 3.08285778428128

Epoch: 6| Step: 6
Training loss: 3.0415052780464276
Validation loss: 3.0822035638397582

Epoch: 6| Step: 7
Training loss: 3.5433239070112625
Validation loss: 3.08159431155041

Epoch: 6| Step: 8
Training loss: 3.3171614471145574
Validation loss: 3.0807282665534546

Epoch: 6| Step: 9
Training loss: 3.2617819043287137
Validation loss: 3.080177333778348

Epoch: 6| Step: 10
Training loss: 3.2139700053345908
Validation loss: 3.079224412583565

Epoch: 6| Step: 11
Training loss: 2.7198156263469038
Validation loss: 3.0784516211996373

Epoch: 6| Step: 12
Training loss: 3.1588358342623355
Validation loss: 3.0776294629819807

Epoch: 6| Step: 13
Training loss: 3.189210320672254
Validation loss: 3.0774771932805782

Epoch: 36| Step: 0
Training loss: 3.67449442181934
Validation loss: 3.0767298884379892

Epoch: 6| Step: 1
Training loss: 3.739238429125133
Validation loss: 3.075733197314467

Epoch: 6| Step: 2
Training loss: 2.5622184412651623
Validation loss: 3.0752432670847045

Epoch: 6| Step: 3
Training loss: 2.8330779989043675
Validation loss: 3.074511380595855

Epoch: 6| Step: 4
Training loss: 3.5597269073493862
Validation loss: 3.0741299399838855

Epoch: 6| Step: 5
Training loss: 3.2476331455343956
Validation loss: 3.0732064142682898

Epoch: 6| Step: 6
Training loss: 3.6063015886183574
Validation loss: 3.07270198271625

Epoch: 6| Step: 7
Training loss: 3.550335376639944
Validation loss: 3.072237051757458

Epoch: 6| Step: 8
Training loss: 3.178525670244204
Validation loss: 3.071425742649979

Epoch: 6| Step: 9
Training loss: 3.2403778541074706
Validation loss: 3.0706662443905737

Epoch: 6| Step: 10
Training loss: 2.848491530499716
Validation loss: 3.070183566808446

Epoch: 6| Step: 11
Training loss: 3.6408562975580034
Validation loss: 3.069404863464794

Epoch: 6| Step: 12
Training loss: 3.6782044744858773
Validation loss: 3.0689922659763846

Epoch: 6| Step: 13
Training loss: 3.4146630219491345
Validation loss: 3.0682155079084943

Epoch: 37| Step: 0
Training loss: 3.05508818279055
Validation loss: 3.0676783966894083

Epoch: 6| Step: 1
Training loss: 3.2511233809123636
Validation loss: 3.066975443954514

Epoch: 6| Step: 2
Training loss: 3.307345428430327
Validation loss: 3.0659524185037266

Epoch: 6| Step: 3
Training loss: 2.9333949523291434
Validation loss: 3.0651431151470567

Epoch: 6| Step: 4
Training loss: 3.926989499428982
Validation loss: 3.064771491649644

Epoch: 6| Step: 5
Training loss: 2.7391214210975354
Validation loss: 3.0638921376565396

Epoch: 6| Step: 6
Training loss: 3.7595703074266846
Validation loss: 3.062846793018432

Epoch: 6| Step: 7
Training loss: 3.5679306666390476
Validation loss: 3.0624105604922476

Epoch: 6| Step: 8
Training loss: 3.1773027854963174
Validation loss: 3.0624253425262675

Epoch: 6| Step: 9
Training loss: 3.1316816995560046
Validation loss: 3.0608661622045945

Epoch: 6| Step: 10
Training loss: 3.6189987228909906
Validation loss: 3.0608981968015754

Epoch: 6| Step: 11
Training loss: 3.763309510805761
Validation loss: 3.0608473707858233

Epoch: 6| Step: 12
Training loss: 2.980653209652773
Validation loss: 3.059082471641282

Epoch: 6| Step: 13
Training loss: 3.5285635662928945
Validation loss: 3.058493678500598

Epoch: 38| Step: 0
Training loss: 3.386099190013396
Validation loss: 3.0575154003869995

Epoch: 6| Step: 1
Training loss: 3.6150695004779827
Validation loss: 3.057468036421515

Epoch: 6| Step: 2
Training loss: 4.121060426405555
Validation loss: 3.0614133124427787

Epoch: 6| Step: 3
Training loss: 4.140482428633321
Validation loss: 3.057831504708601

Epoch: 6| Step: 4
Training loss: 3.312309259645114
Validation loss: 3.0548207302458628

Epoch: 6| Step: 5
Training loss: 2.388425226335984
Validation loss: 3.0547013836495243

Epoch: 6| Step: 6
Training loss: 3.2220397729484835
Validation loss: 3.05375045664273

Epoch: 6| Step: 7
Training loss: 3.7353024149136003
Validation loss: 3.0530782123360845

Epoch: 6| Step: 8
Training loss: 3.379410863692743
Validation loss: 3.0526380568555957

Epoch: 6| Step: 9
Training loss: 3.5006893024147425
Validation loss: 3.0518647259498097

Epoch: 6| Step: 10
Training loss: 2.487231166248753
Validation loss: 3.0511971225522316

Epoch: 6| Step: 11
Training loss: 2.5768387793845746
Validation loss: 3.050427068730156

Epoch: 6| Step: 12
Training loss: 2.9838550374305073
Validation loss: 3.0494383019874034

Epoch: 6| Step: 13
Training loss: 3.4280854743619287
Validation loss: 3.049358990003098

Epoch: 39| Step: 0
Training loss: 3.627977398113266
Validation loss: 3.048684284766804

Epoch: 6| Step: 1
Training loss: 3.5427803233383797
Validation loss: 3.0480711333668133

Epoch: 6| Step: 2
Training loss: 2.3846170565028992
Validation loss: 3.047486895511062

Epoch: 6| Step: 3
Training loss: 3.3368056014254264
Validation loss: 3.04689321793841

Epoch: 6| Step: 4
Training loss: 3.4632615666913305
Validation loss: 3.045974446065161

Epoch: 6| Step: 5
Training loss: 3.386619064817528
Validation loss: 3.0454111651527866

Epoch: 6| Step: 6
Training loss: 3.248236544559842
Validation loss: 3.045022118059369

Epoch: 6| Step: 7
Training loss: 3.34863637243723
Validation loss: 3.0442626406198325

Epoch: 6| Step: 8
Training loss: 3.821446162795766
Validation loss: 3.0432382188102842

Epoch: 6| Step: 9
Training loss: 3.224656102970032
Validation loss: 3.042410759650411

Epoch: 6| Step: 10
Training loss: 3.344887370678118
Validation loss: 3.042088918557425

Epoch: 6| Step: 11
Training loss: 3.165347744849718
Validation loss: 3.0414780535664736

Epoch: 6| Step: 12
Training loss: 3.183156962942987
Validation loss: 3.040971942699867

Epoch: 6| Step: 13
Training loss: 3.4916444223889553
Validation loss: 3.0402197240109765

Epoch: 40| Step: 0
Training loss: 3.014289204331368
Validation loss: 3.039561745365665

Epoch: 6| Step: 1
Training loss: 3.5129619091041815
Validation loss: 3.0387592678440245

Epoch: 6| Step: 2
Training loss: 3.6404397941926745
Validation loss: 3.038056884151627

Epoch: 6| Step: 3
Training loss: 3.33087531696959
Validation loss: 3.0373002372874844

Epoch: 6| Step: 4
Training loss: 3.544663601128606
Validation loss: 3.036445549402382

Epoch: 6| Step: 5
Training loss: 3.1330573920902482
Validation loss: 3.036370960529844

Epoch: 6| Step: 6
Training loss: 3.579555175679976
Validation loss: 3.035619133688337

Epoch: 6| Step: 7
Training loss: 2.865450881443841
Validation loss: 3.0350181434247023

Epoch: 6| Step: 8
Training loss: 3.083774552264931
Validation loss: 3.0342760888634994

Epoch: 6| Step: 9
Training loss: 2.6345793005663922
Validation loss: 3.033699662018223

Epoch: 6| Step: 10
Training loss: 3.494875562469078
Validation loss: 3.0333100298293236

Epoch: 6| Step: 11
Training loss: 3.4455953814919975
Validation loss: 3.032509759671286

Epoch: 6| Step: 12
Training loss: 3.578864008785999
Validation loss: 3.032189373659993

Epoch: 6| Step: 13
Training loss: 3.714970439110432
Validation loss: 3.0314406755847827

Epoch: 41| Step: 0
Training loss: 3.5187754438710135
Validation loss: 3.0305589573890024

Epoch: 6| Step: 1
Training loss: 2.875814571254932
Validation loss: 3.029711095145653

Epoch: 6| Step: 2
Training loss: 3.312100224392876
Validation loss: 3.0291505500850056

Epoch: 6| Step: 3
Training loss: 4.422020576156577
Validation loss: 3.028642140489409

Epoch: 6| Step: 4
Training loss: 3.2247973178781395
Validation loss: 3.02807300666533

Epoch: 6| Step: 5
Training loss: 2.992218415820214
Validation loss: 3.027328854251963

Epoch: 6| Step: 6
Training loss: 2.7605174688012104
Validation loss: 3.0269186360108686

Epoch: 6| Step: 7
Training loss: 3.355831814931282
Validation loss: 3.0261087308331414

Epoch: 6| Step: 8
Training loss: 3.228827395100437
Validation loss: 3.0256995960736996

Epoch: 6| Step: 9
Training loss: 3.7176613376191256
Validation loss: 3.0251580946460574

Epoch: 6| Step: 10
Training loss: 3.119387966183324
Validation loss: 3.0238352834492805

Epoch: 6| Step: 11
Training loss: 3.1127540208960442
Validation loss: 3.0237211438994174

Epoch: 6| Step: 12
Training loss: 3.0994179948400444
Validation loss: 3.0230417944696466

Epoch: 6| Step: 13
Training loss: 3.517603880996073
Validation loss: 3.022948573800724

Epoch: 42| Step: 0
Training loss: 2.2082790392073286
Validation loss: 3.021930812334662

Epoch: 6| Step: 1
Training loss: 3.542649495504466
Validation loss: 3.0211295551583044

Epoch: 6| Step: 2
Training loss: 3.578886659006901
Validation loss: 3.0205153815976353

Epoch: 6| Step: 3
Training loss: 3.1888191634946477
Validation loss: 3.0206734099752404

Epoch: 6| Step: 4
Training loss: 2.4887496531326767
Validation loss: 3.0196311312363453

Epoch: 6| Step: 5
Training loss: 3.6675255520898467
Validation loss: 3.017570149236293

Epoch: 6| Step: 6
Training loss: 3.978327091714485
Validation loss: 3.016759795047278

Epoch: 6| Step: 7
Training loss: 3.4027644531265917
Validation loss: 3.0168884162415273

Epoch: 6| Step: 8
Training loss: 2.8138765992773553
Validation loss: 3.015877396621522

Epoch: 6| Step: 9
Training loss: 3.0846633791779934
Validation loss: 3.015230603924579

Epoch: 6| Step: 10
Training loss: 3.620767160973538
Validation loss: 3.015002082248916

Epoch: 6| Step: 11
Training loss: 3.655039399400427
Validation loss: 3.0129542952535995

Epoch: 6| Step: 12
Training loss: 2.8943244973498516
Validation loss: 3.012824017015643

Epoch: 6| Step: 13
Training loss: 4.058208135178951
Validation loss: 3.012661875247405

Epoch: 43| Step: 0
Training loss: 3.2492710176278146
Validation loss: 3.0126876965248317

Epoch: 6| Step: 1
Training loss: 4.253160087222096
Validation loss: 3.0119690907347665

Epoch: 6| Step: 2
Training loss: 3.129513647056721
Validation loss: 3.0105484161064107

Epoch: 6| Step: 3
Training loss: 2.1259989914698822
Validation loss: 3.008589193751951

Epoch: 6| Step: 4
Training loss: 3.251850188404618
Validation loss: 3.007605171063072

Epoch: 6| Step: 5
Training loss: 3.668213662450522
Validation loss: 3.006938452868886

Epoch: 6| Step: 6
Training loss: 3.1021952332006086
Validation loss: 3.006554868538774

Epoch: 6| Step: 7
Training loss: 3.557031550282768
Validation loss: 3.0043023033687764

Epoch: 6| Step: 8
Training loss: 3.2440430260755324
Validation loss: 3.005690784677572

Epoch: 6| Step: 9
Training loss: 3.560851401626832
Validation loss: 3.004251672721059

Epoch: 6| Step: 10
Training loss: 3.8750252261417426
Validation loss: 3.003999954064257

Epoch: 6| Step: 11
Training loss: 2.605365894123269
Validation loss: 3.0012759704856142

Epoch: 6| Step: 12
Training loss: 3.1130135108759944
Validation loss: 3.0017968961103874

Epoch: 6| Step: 13
Training loss: 2.812293066253378
Validation loss: 2.999896107518852

Epoch: 44| Step: 0
Training loss: 3.3003349769967567
Validation loss: 3.000879992692957

Epoch: 6| Step: 1
Training loss: 2.8672330681196714
Validation loss: 3.000871774351422

Epoch: 6| Step: 2
Training loss: 2.8457329512206666
Validation loss: 2.9983409307025712

Epoch: 6| Step: 3
Training loss: 2.7884257468600366
Validation loss: 2.9959926245626662

Epoch: 6| Step: 4
Training loss: 2.746498392823751
Validation loss: 2.996680821405374

Epoch: 6| Step: 5
Training loss: 2.6419470372518905
Validation loss: 2.996065876712603

Epoch: 6| Step: 6
Training loss: 3.52014940529977
Validation loss: 2.9984840302289633

Epoch: 6| Step: 7
Training loss: 3.6737712752280087
Validation loss: 2.9946612123786283

Epoch: 6| Step: 8
Training loss: 3.285112995311999
Validation loss: 2.99396506752197

Epoch: 6| Step: 9
Training loss: 3.7625907608187257
Validation loss: 2.9907014435314476

Epoch: 6| Step: 10
Training loss: 3.6328526648485306
Validation loss: 2.992533428139658

Epoch: 6| Step: 11
Training loss: 3.410543273427545
Validation loss: 2.9909055453632303

Epoch: 6| Step: 12
Training loss: 3.7328350131927572
Validation loss: 2.990459390242957

Epoch: 6| Step: 13
Training loss: 3.8892843242203914
Validation loss: 2.9891784938100727

Epoch: 45| Step: 0
Training loss: 3.579439013551341
Validation loss: 2.9863957605117903

Epoch: 6| Step: 1
Training loss: 2.942351210988197
Validation loss: 2.9862277677248388

Epoch: 6| Step: 2
Training loss: 3.781369546308844
Validation loss: 2.9872179776029757

Epoch: 6| Step: 3
Training loss: 3.295866753319929
Validation loss: 2.988308528459559

Epoch: 6| Step: 4
Training loss: 3.5511387140439665
Validation loss: 2.9857725369462673

Epoch: 6| Step: 5
Training loss: 3.905245232104634
Validation loss: 2.9862345789606812

Epoch: 6| Step: 6
Training loss: 2.9166307356301484
Validation loss: 2.9861337652457607

Epoch: 6| Step: 7
Training loss: 3.3430771195225506
Validation loss: 2.9856039561103023

Epoch: 6| Step: 8
Training loss: 2.5694088724325974
Validation loss: 2.9888978143375184

Epoch: 6| Step: 9
Training loss: 2.9681656111707975
Validation loss: 2.9953928593957087

Epoch: 6| Step: 10
Training loss: 4.065004017207377
Validation loss: 2.9878369544698007

Epoch: 6| Step: 11
Training loss: 2.2998117369849496
Validation loss: 2.9834399380670806

Epoch: 6| Step: 12
Training loss: 3.0208694631235593
Validation loss: 2.984811768163843

Epoch: 6| Step: 13
Training loss: 3.251822767422908
Validation loss: 2.9825562283132734

Epoch: 46| Step: 0
Training loss: 3.506039177579406
Validation loss: 2.9865728427842155

Epoch: 6| Step: 1
Training loss: 3.442073484550682
Validation loss: 2.987934584177183

Epoch: 6| Step: 2
Training loss: 3.1624423176326104
Validation loss: 2.9780621697422873

Epoch: 6| Step: 3
Training loss: 4.088655752870192
Validation loss: 2.9824618608372315

Epoch: 6| Step: 4
Training loss: 3.3344820586359787
Validation loss: 2.986482801593632

Epoch: 6| Step: 5
Training loss: 2.4665449894286318
Validation loss: 2.9807340190779916

Epoch: 6| Step: 6
Training loss: 2.9735872713056195
Validation loss: 2.9779499207324913

Epoch: 6| Step: 7
Training loss: 2.580315231759768
Validation loss: 2.9809070932991

Epoch: 6| Step: 8
Training loss: 3.5141294562040453
Validation loss: 2.9767023161961936

Epoch: 6| Step: 9
Training loss: 3.263736452551564
Validation loss: 2.9761748904099914

Epoch: 6| Step: 10
Training loss: 3.2429727729362545
Validation loss: 2.9871217388394546

Epoch: 6| Step: 11
Training loss: 3.599333828642429
Validation loss: 2.9962876835720467

Epoch: 6| Step: 12
Training loss: 3.5440708452467384
Validation loss: 2.9744293792100915

Epoch: 6| Step: 13
Training loss: 2.6488383392105543
Validation loss: 2.974832237899692

Epoch: 47| Step: 0
Training loss: 3.672885577149061
Validation loss: 2.976181094118205

Epoch: 6| Step: 1
Training loss: 2.828899298624865
Validation loss: 2.978151409730758

Epoch: 6| Step: 2
Training loss: 3.495626032566714
Validation loss: 2.9786822883809645

Epoch: 6| Step: 3
Training loss: 3.732228192744228
Validation loss: 2.9767901057668515

Epoch: 6| Step: 4
Training loss: 3.0134699735916204
Validation loss: 2.970955270230177

Epoch: 6| Step: 5
Training loss: 3.2246498923294893
Validation loss: 2.973592866571725

Epoch: 6| Step: 6
Training loss: 2.7848560230288824
Validation loss: 2.9686807120267984

Epoch: 6| Step: 7
Training loss: 2.6427997008454995
Validation loss: 2.9716118904471447

Epoch: 6| Step: 8
Training loss: 4.023064872004362
Validation loss: 2.9735362650985517

Epoch: 6| Step: 9
Training loss: 3.5134673554725384
Validation loss: 2.9709019631722398

Epoch: 6| Step: 10
Training loss: 3.378295843301857
Validation loss: 2.9667169359153003

Epoch: 6| Step: 11
Training loss: 2.9616403676505634
Validation loss: 2.966167543900384

Epoch: 6| Step: 12
Training loss: 3.2406603790088275
Validation loss: 2.9666115485953433

Epoch: 6| Step: 13
Training loss: 2.8687191232253784
Validation loss: 2.966577056129608

Epoch: 48| Step: 0
Training loss: 3.079749903247459
Validation loss: 2.9637701645460894

Epoch: 6| Step: 1
Training loss: 3.1939113688153817
Validation loss: 2.9621857908445333

Epoch: 6| Step: 2
Training loss: 3.474391439378044
Validation loss: 2.962793211841292

Epoch: 6| Step: 3
Training loss: 3.3838588162453305
Validation loss: 2.9624045483364574

Epoch: 6| Step: 4
Training loss: 3.5960974945837827
Validation loss: 2.9654577146108134

Epoch: 6| Step: 5
Training loss: 3.6635183487447356
Validation loss: 2.968526241762352

Epoch: 6| Step: 6
Training loss: 3.2601007343010933
Validation loss: 2.9700780379717813

Epoch: 6| Step: 7
Training loss: 3.505624883348746
Validation loss: 2.9841676036617226

Epoch: 6| Step: 8
Training loss: 3.1809901163186893
Validation loss: 2.9686198941678517

Epoch: 6| Step: 9
Training loss: 3.2471664988103233
Validation loss: 2.958010524334579

Epoch: 6| Step: 10
Training loss: 2.8435192643343608
Validation loss: 2.9579519181669105

Epoch: 6| Step: 11
Training loss: 3.6875920688320827
Validation loss: 2.9634024643249823

Epoch: 6| Step: 12
Training loss: 2.278365310113399
Validation loss: 2.9687730806637633

Epoch: 6| Step: 13
Training loss: 2.8551972099643286
Validation loss: 2.973322510934355

Epoch: 49| Step: 0
Training loss: 3.125571541972645
Validation loss: 2.9582777669478277

Epoch: 6| Step: 1
Training loss: 3.1867315824698723
Validation loss: 2.9543410601035553

Epoch: 6| Step: 2
Training loss: 3.454745227567779
Validation loss: 2.9544778513788055

Epoch: 6| Step: 3
Training loss: 3.118164368344802
Validation loss: 2.954057509682752

Epoch: 6| Step: 4
Training loss: 3.7823000624232646
Validation loss: 2.957075684189288

Epoch: 6| Step: 5
Training loss: 3.2306637318821245
Validation loss: 2.9584046949843747

Epoch: 6| Step: 6
Training loss: 3.0319030687444015
Validation loss: 2.961575139371694

Epoch: 6| Step: 7
Training loss: 3.4546963667874397
Validation loss: 2.9909650812261788

Epoch: 6| Step: 8
Training loss: 3.032402055609987
Validation loss: 2.972444688771281

Epoch: 6| Step: 9
Training loss: 3.22847811013065
Validation loss: 2.955432641957028

Epoch: 6| Step: 10
Training loss: 2.945212607877915
Validation loss: 2.957887567134271

Epoch: 6| Step: 11
Training loss: 3.2236004180343705
Validation loss: 2.9545112043662005

Epoch: 6| Step: 12
Training loss: 3.621684827576167
Validation loss: 2.9542299048269673

Epoch: 6| Step: 13
Training loss: 2.9536079132994906
Validation loss: 2.95372597471155

Epoch: 50| Step: 0
Training loss: 3.4218382114888874
Validation loss: 2.9519142090333457

Epoch: 6| Step: 1
Training loss: 3.0725381564199084
Validation loss: 2.9539560569184506

Epoch: 6| Step: 2
Training loss: 3.4339281424911863
Validation loss: 2.95020170465987

Epoch: 6| Step: 3
Training loss: 3.231898442325177
Validation loss: 2.951342386984869

Epoch: 6| Step: 4
Training loss: 3.139724222695375
Validation loss: 2.9516439418302753

Epoch: 6| Step: 5
Training loss: 3.194577008873788
Validation loss: 2.9522315055743027

Epoch: 6| Step: 6
Training loss: 3.901129945266309
Validation loss: 2.9525518339138825

Epoch: 6| Step: 7
Training loss: 2.8405507295171564
Validation loss: 2.9541898588149578

Epoch: 6| Step: 8
Training loss: 3.4568571747310095
Validation loss: 2.951752918111372

Epoch: 6| Step: 9
Training loss: 2.133381191352635
Validation loss: 2.949890518312107

Epoch: 6| Step: 10
Training loss: 3.032847976280546
Validation loss: 2.952366756913368

Epoch: 6| Step: 11
Training loss: 3.8037015354103954
Validation loss: 2.948884074244873

Epoch: 6| Step: 12
Training loss: 3.129917243375361
Validation loss: 2.9469470282457695

Epoch: 6| Step: 13
Training loss: 3.2733729681605306
Validation loss: 2.94528905879276

Epoch: 51| Step: 0
Training loss: 3.6818439619743732
Validation loss: 2.947695429693793

Epoch: 6| Step: 1
Training loss: 3.493020591956904
Validation loss: 2.9456749232291712

Epoch: 6| Step: 2
Training loss: 3.055032774004911
Validation loss: 2.944585313546823

Epoch: 6| Step: 3
Training loss: 3.2587163389491844
Validation loss: 2.945762008311989

Epoch: 6| Step: 4
Training loss: 3.1827867854282323
Validation loss: 2.9447078084642753

Epoch: 6| Step: 5
Training loss: 3.4618451928093275
Validation loss: 2.943116884495699

Epoch: 6| Step: 6
Training loss: 3.251470233244238
Validation loss: 2.9398315696277257

Epoch: 6| Step: 7
Training loss: 3.066262405812064
Validation loss: 2.9431738654104844

Epoch: 6| Step: 8
Training loss: 2.7347931460415325
Validation loss: 2.9411603882082695

Epoch: 6| Step: 9
Training loss: 3.022662080594984
Validation loss: 2.9457901112912115

Epoch: 6| Step: 10
Training loss: 3.0656696965714625
Validation loss: 2.9727344537957436

Epoch: 6| Step: 11
Training loss: 2.9692994261839654
Validation loss: 2.9746866294335987

Epoch: 6| Step: 12
Training loss: 3.4987368347857934
Validation loss: 2.958165906830313

Epoch: 6| Step: 13
Training loss: 3.596938468578622
Validation loss: 2.942371672287014

Epoch: 52| Step: 0
Training loss: 3.1091437325662286
Validation loss: 2.938218090298608

Epoch: 6| Step: 1
Training loss: 3.2074332688035967
Validation loss: 2.939027983617989

Epoch: 6| Step: 2
Training loss: 2.881536268465051
Validation loss: 2.941049369355492

Epoch: 6| Step: 3
Training loss: 3.4421079788338513
Validation loss: 2.9385344936026825

Epoch: 6| Step: 4
Training loss: 3.237238109703773
Validation loss: 2.9433012914959202

Epoch: 6| Step: 5
Training loss: 3.492473547909722
Validation loss: 2.932140516857686

Epoch: 6| Step: 6
Training loss: 3.3107686826505307
Validation loss: 2.9329085378286237

Epoch: 6| Step: 7
Training loss: 3.0617098664828704
Validation loss: 2.92686545905152

Epoch: 6| Step: 8
Training loss: 3.4635691400265336
Validation loss: 2.9247297487305914

Epoch: 6| Step: 9
Training loss: 3.4191964870872176
Validation loss: 2.9256416781590997

Epoch: 6| Step: 10
Training loss: 2.945613289204157
Validation loss: 2.9372853305620303

Epoch: 6| Step: 11
Training loss: 2.6521208139924015
Validation loss: 2.932595526942827

Epoch: 6| Step: 12
Training loss: 3.4662967288873743
Validation loss: 2.954030026890345

Epoch: 6| Step: 13
Training loss: 3.565397322504433
Validation loss: 2.9340162597657997

Epoch: 53| Step: 0
Training loss: 3.314577279044392
Validation loss: 2.914336213695234

Epoch: 6| Step: 1
Training loss: 3.694256815213047
Validation loss: 2.918372644735573

Epoch: 6| Step: 2
Training loss: 3.7991247223144287
Validation loss: 2.9097442932202915

Epoch: 6| Step: 3
Training loss: 3.5239235823937474
Validation loss: 2.911458687601848

Epoch: 6| Step: 4
Training loss: 2.687065710419192
Validation loss: 2.9121623330134447

Epoch: 6| Step: 5
Training loss: 3.0504236146010317
Validation loss: 2.909745176035848

Epoch: 6| Step: 6
Training loss: 3.263851578591648
Validation loss: 2.911694364643912

Epoch: 6| Step: 7
Training loss: 3.012011482865329
Validation loss: 2.910944009155283

Epoch: 6| Step: 8
Training loss: 3.047580422145306
Validation loss: 2.911051116759239

Epoch: 6| Step: 9
Training loss: 2.6360146267590765
Validation loss: 2.9079076877958108

Epoch: 6| Step: 10
Training loss: 2.913338824455388
Validation loss: 2.909807208576475

Epoch: 6| Step: 11
Training loss: 3.3209087240419555
Validation loss: 2.9160267305121117

Epoch: 6| Step: 12
Training loss: 2.942819202776394
Validation loss: 2.921071181787863

Epoch: 6| Step: 13
Training loss: 3.6961010984655336
Validation loss: 2.9166327273830386

Epoch: 54| Step: 0
Training loss: 2.797690586964871
Validation loss: 2.9118346455154396

Epoch: 6| Step: 1
Training loss: 2.4783050471703105
Validation loss: 2.9131914245740265

Epoch: 6| Step: 2
Training loss: 3.075011872059304
Validation loss: 2.9110900010756198

Epoch: 6| Step: 3
Training loss: 3.6995386712406297
Validation loss: 2.906211805142262

Epoch: 6| Step: 4
Training loss: 2.8288826112094028
Validation loss: 2.9035454130344167

Epoch: 6| Step: 5
Training loss: 2.3354538636955953
Validation loss: 2.905647136795975

Epoch: 6| Step: 6
Training loss: 3.6536552155370376
Validation loss: 2.911180427955726

Epoch: 6| Step: 7
Training loss: 2.9174531330440083
Validation loss: 2.9209715349196057

Epoch: 6| Step: 8
Training loss: 3.3484254752266733
Validation loss: 2.9243839799852216

Epoch: 6| Step: 9
Training loss: 4.188846428608456
Validation loss: 2.9226946867401

Epoch: 6| Step: 10
Training loss: 2.7105118035272504
Validation loss: 2.9046273307801904

Epoch: 6| Step: 11
Training loss: 3.8460090015720634
Validation loss: 2.89400992652345

Epoch: 6| Step: 12
Training loss: 2.9643412730908043
Validation loss: 2.8961605159562582

Epoch: 6| Step: 13
Training loss: 3.5195794816686843
Validation loss: 2.8931667302351567

Epoch: 55| Step: 0
Training loss: 3.100947936545142
Validation loss: 2.9051528775770095

Epoch: 6| Step: 1
Training loss: 2.3775065396095614
Validation loss: 2.9131070267720394

Epoch: 6| Step: 2
Training loss: 3.5747432803298858
Validation loss: 2.8937461492076557

Epoch: 6| Step: 3
Training loss: 3.1744332355851337
Validation loss: 2.8890518053665994

Epoch: 6| Step: 4
Training loss: 2.7509206617889355
Validation loss: 2.8903623329113786

Epoch: 6| Step: 5
Training loss: 3.4672702691752826
Validation loss: 2.8913428517457507

Epoch: 6| Step: 6
Training loss: 3.456145333607457
Validation loss: 2.8883175061687902

Epoch: 6| Step: 7
Training loss: 2.739963770995819
Validation loss: 2.8991831101364225

Epoch: 6| Step: 8
Training loss: 3.348799271116073
Validation loss: 2.9208851755880336

Epoch: 6| Step: 9
Training loss: 3.0710370710912303
Validation loss: 2.909415021341568

Epoch: 6| Step: 10
Training loss: 2.6095276747941107
Validation loss: 2.901622032318933

Epoch: 6| Step: 11
Training loss: 3.4846070900842787
Validation loss: 2.925674925258713

Epoch: 6| Step: 12
Training loss: 3.2824739625686914
Validation loss: 2.9163000392042617

Epoch: 6| Step: 13
Training loss: 4.233184309211206
Validation loss: 2.8925600616251566

Epoch: 56| Step: 0
Training loss: 3.2369514560306167
Validation loss: 2.8869412359602182

Epoch: 6| Step: 1
Training loss: 3.0120991863622097
Validation loss: 2.886863492948941

Epoch: 6| Step: 2
Training loss: 3.3614871460150946
Validation loss: 2.8924621154180032

Epoch: 6| Step: 3
Training loss: 2.7884060811161575
Validation loss: 2.902173525121751

Epoch: 6| Step: 4
Training loss: 2.9973051365117738
Validation loss: 2.9060318788131645

Epoch: 6| Step: 5
Training loss: 2.6475994393294644
Validation loss: 2.8925408362067424

Epoch: 6| Step: 6
Training loss: 2.8294381312461674
Validation loss: 2.8898090713154057

Epoch: 6| Step: 7
Training loss: 3.130693665686431
Validation loss: 2.8882638872697903

Epoch: 6| Step: 8
Training loss: 3.2126164931019217
Validation loss: 2.88820879747201

Epoch: 6| Step: 9
Training loss: 3.708626181937003
Validation loss: 2.893296013163215

Epoch: 6| Step: 10
Training loss: 3.2566461830965676
Validation loss: 2.9018880638509157

Epoch: 6| Step: 11
Training loss: 3.550060169623436
Validation loss: 2.901581485543111

Epoch: 6| Step: 12
Training loss: 3.2661020030943155
Validation loss: 2.8990367334865264

Epoch: 6| Step: 13
Training loss: 3.8280160070979514
Validation loss: 2.897820762252286

Epoch: 57| Step: 0
Training loss: 3.5652908636695995
Validation loss: 2.896611187487829

Epoch: 6| Step: 1
Training loss: 3.0206882485813042
Validation loss: 2.89113354077237

Epoch: 6| Step: 2
Training loss: 3.205520850364125
Validation loss: 2.8818725544024635

Epoch: 6| Step: 3
Training loss: 3.3168634429782053
Validation loss: 2.8827604568194194

Epoch: 6| Step: 4
Training loss: 3.2524101417320517
Validation loss: 2.8788281386156234

Epoch: 6| Step: 5
Training loss: 3.2775651859228723
Validation loss: 2.8811855759270557

Epoch: 6| Step: 6
Training loss: 3.0159630462446776
Validation loss: 2.878704135245099

Epoch: 6| Step: 7
Training loss: 2.9388079065015322
Validation loss: 2.880945295912651

Epoch: 6| Step: 8
Training loss: 3.1689641214291577
Validation loss: 2.878693831520283

Epoch: 6| Step: 9
Training loss: 2.892030281562608
Validation loss: 2.8778567377261854

Epoch: 6| Step: 10
Training loss: 3.3076249723114763
Validation loss: 2.874732175803101

Epoch: 6| Step: 11
Training loss: 3.7795489559825715
Validation loss: 2.872662454014236

Epoch: 6| Step: 12
Training loss: 2.4366684497804116
Validation loss: 2.8742074984322463

Epoch: 6| Step: 13
Training loss: 3.057947161111344
Validation loss: 2.8736694568854517

Epoch: 58| Step: 0
Training loss: 3.0835192512615177
Validation loss: 2.8727554487243117

Epoch: 6| Step: 1
Training loss: 3.138672482692847
Validation loss: 2.8688631247094305

Epoch: 6| Step: 2
Training loss: 3.020922815159528
Validation loss: 2.8751421229405723

Epoch: 6| Step: 3
Training loss: 4.218309619665593
Validation loss: 2.881232005513288

Epoch: 6| Step: 4
Training loss: 2.853224345856043
Validation loss: 2.881972931363083

Epoch: 6| Step: 5
Training loss: 3.643279716280985
Validation loss: 2.87794368004797

Epoch: 6| Step: 6
Training loss: 2.688928180290159
Validation loss: 2.877579969286667

Epoch: 6| Step: 7
Training loss: 3.2819736227757383
Validation loss: 2.8687034610129065

Epoch: 6| Step: 8
Training loss: 2.9646494604488813
Validation loss: 2.8681727701431527

Epoch: 6| Step: 9
Training loss: 3.4963558844638793
Validation loss: 2.865769377955445

Epoch: 6| Step: 10
Training loss: 2.4072013064407853
Validation loss: 2.858155279378772

Epoch: 6| Step: 11
Training loss: 2.827682207545628
Validation loss: 2.8544205930704636

Epoch: 6| Step: 12
Training loss: 2.7132024180753995
Validation loss: 2.850915876573399

Epoch: 6| Step: 13
Training loss: 3.807321001279917
Validation loss: 2.8501857830864132

Epoch: 59| Step: 0
Training loss: 3.1664285737593585
Validation loss: 2.8495586524881062

Epoch: 6| Step: 1
Training loss: 3.274808974191296
Validation loss: 2.8489508333576317

Epoch: 6| Step: 2
Training loss: 3.1711238479031745
Validation loss: 2.8479672218023997

Epoch: 6| Step: 3
Training loss: 3.1946276091617096
Validation loss: 2.848063013958641

Epoch: 6| Step: 4
Training loss: 2.541491382579014
Validation loss: 2.852922464046423

Epoch: 6| Step: 5
Training loss: 3.9812770393447465
Validation loss: 2.85964582866266

Epoch: 6| Step: 6
Training loss: 3.342817515183761
Validation loss: 2.8635333857488967

Epoch: 6| Step: 7
Training loss: 2.50825615401888
Validation loss: 2.8442066632352665

Epoch: 6| Step: 8
Training loss: 3.081666255171731
Validation loss: 2.8427517263487796

Epoch: 6| Step: 9
Training loss: 3.2612108394776267
Validation loss: 2.8431744836603254

Epoch: 6| Step: 10
Training loss: 3.0447821838948155
Validation loss: 2.8430142925489346

Epoch: 6| Step: 11
Training loss: 2.855569276723126
Validation loss: 2.8406469982956954

Epoch: 6| Step: 12
Training loss: 3.1059474744021536
Validation loss: 2.8402101431264333

Epoch: 6| Step: 13
Training loss: 3.459409906199161
Validation loss: 2.8398920931226748

Epoch: 60| Step: 0
Training loss: 3.4361089492773234
Validation loss: 2.84114328456114

Epoch: 6| Step: 1
Training loss: 2.7346534805178333
Validation loss: 2.838015905803426

Epoch: 6| Step: 2
Training loss: 3.0440967902737075
Validation loss: 2.8386192378162023

Epoch: 6| Step: 3
Training loss: 3.4061177079295124
Validation loss: 2.8376227648224766

Epoch: 6| Step: 4
Training loss: 3.3857035979917955
Validation loss: 2.840011615866628

Epoch: 6| Step: 5
Training loss: 3.057656954637994
Validation loss: 2.8383241393789818

Epoch: 6| Step: 6
Training loss: 2.6162277055966934
Validation loss: 2.8395274971412308

Epoch: 6| Step: 7
Training loss: 3.5985807376235583
Validation loss: 2.8407999662470185

Epoch: 6| Step: 8
Training loss: 2.8913048846770253
Validation loss: 2.8399866320976996

Epoch: 6| Step: 9
Training loss: 2.614919197628434
Validation loss: 2.847462960493833

Epoch: 6| Step: 10
Training loss: 3.17929817084382
Validation loss: 2.845722681263337

Epoch: 6| Step: 11
Training loss: 3.129990521986386
Validation loss: 2.838124134295652

Epoch: 6| Step: 12
Training loss: 3.625422222935649
Validation loss: 2.843225832210832

Epoch: 6| Step: 13
Training loss: 3.1511439955728715
Validation loss: 2.8527172645903076

Epoch: 61| Step: 0
Training loss: 3.2037436283329512
Validation loss: 2.8542517270703107

Epoch: 6| Step: 1
Training loss: 3.175880796554452
Validation loss: 2.838072985208357

Epoch: 6| Step: 2
Training loss: 3.0927318092004255
Validation loss: 2.829349357721665

Epoch: 6| Step: 3
Training loss: 3.290519047523022
Validation loss: 2.8287194365570305

Epoch: 6| Step: 4
Training loss: 3.221401862878676
Validation loss: 2.8358803857489385

Epoch: 6| Step: 5
Training loss: 3.394666381534266
Validation loss: 2.8499089405845677

Epoch: 6| Step: 6
Training loss: 3.5217688557183746
Validation loss: 2.8559194371065586

Epoch: 6| Step: 7
Training loss: 3.2503524002341666
Validation loss: 2.850126241519294

Epoch: 6| Step: 8
Training loss: 3.0493304408829345
Validation loss: 2.839415244753877

Epoch: 6| Step: 9
Training loss: 3.3255430423450028
Validation loss: 2.836545056452544

Epoch: 6| Step: 10
Training loss: 2.773165149479753
Validation loss: 2.8333942468912787

Epoch: 6| Step: 11
Training loss: 2.7234966015599316
Validation loss: 2.829871401321529

Epoch: 6| Step: 12
Training loss: 3.0091898353154494
Validation loss: 2.821616370797188

Epoch: 6| Step: 13
Training loss: 2.5913891446431987
Validation loss: 2.8207415332622934

Epoch: 62| Step: 0
Training loss: 2.6596286603398
Validation loss: 2.8231742047277475

Epoch: 6| Step: 1
Training loss: 3.2159709599735296
Validation loss: 2.825261092473733

Epoch: 6| Step: 2
Training loss: 3.5852877292061636
Validation loss: 2.8239555637361486

Epoch: 6| Step: 3
Training loss: 3.446148760072654
Validation loss: 2.8239069786586963

Epoch: 6| Step: 4
Training loss: 4.03995183897111
Validation loss: 2.8238254012733925

Epoch: 6| Step: 5
Training loss: 2.9634055769545604
Validation loss: 2.823953909689369

Epoch: 6| Step: 6
Training loss: 3.1313725917673354
Validation loss: 2.8204442334536117

Epoch: 6| Step: 7
Training loss: 3.374516770418824
Validation loss: 2.8215216224463835

Epoch: 6| Step: 8
Training loss: 2.834461679363435
Validation loss: 2.8207913470792865

Epoch: 6| Step: 9
Training loss: 2.4782245245595522
Validation loss: 2.8220025527371733

Epoch: 6| Step: 10
Training loss: 3.0906877871963716
Validation loss: 2.819419388782898

Epoch: 6| Step: 11
Training loss: 3.596021117032756
Validation loss: 2.817634600812938

Epoch: 6| Step: 12
Training loss: 2.133074286746892
Validation loss: 2.8186089122785587

Epoch: 6| Step: 13
Training loss: 2.517632199010779
Validation loss: 2.8222860794356586

Epoch: 63| Step: 0
Training loss: 2.7910641451783227
Validation loss: 2.819588918874152

Epoch: 6| Step: 1
Training loss: 3.4567247502723597
Validation loss: 2.8209537516450895

Epoch: 6| Step: 2
Training loss: 3.178752489887782
Validation loss: 2.822945221884148

Epoch: 6| Step: 3
Training loss: 3.342685708341569
Validation loss: 2.8242047871942737

Epoch: 6| Step: 4
Training loss: 3.115592682421171
Validation loss: 2.8263788982901885

Epoch: 6| Step: 5
Training loss: 2.963211836782588
Validation loss: 2.8296479506470598

Epoch: 6| Step: 6
Training loss: 3.3588422485903573
Validation loss: 2.843124885280906

Epoch: 6| Step: 7
Training loss: 2.7616274979122983
Validation loss: 2.8245849980079716

Epoch: 6| Step: 8
Training loss: 2.430630418139241
Validation loss: 2.8160416903324097

Epoch: 6| Step: 9
Training loss: 3.2088384519659803
Validation loss: 2.8148591833298977

Epoch: 6| Step: 10
Training loss: 3.247409962264188
Validation loss: 2.8123087591237037

Epoch: 6| Step: 11
Training loss: 3.380443844969068
Validation loss: 2.822343205369509

Epoch: 6| Step: 12
Training loss: 2.5076705559700327
Validation loss: 2.8096586525314566

Epoch: 6| Step: 13
Training loss: 4.064074401955371
Validation loss: 2.8126924811233525

Epoch: 64| Step: 0
Training loss: 3.3805848995855237
Validation loss: 2.809889380497512

Epoch: 6| Step: 1
Training loss: 2.873214830874202
Validation loss: 2.809351324622509

Epoch: 6| Step: 2
Training loss: 3.1956355670744543
Validation loss: 2.8085830375415406

Epoch: 6| Step: 3
Training loss: 3.154024907247809
Validation loss: 2.8104904324088666

Epoch: 6| Step: 4
Training loss: 2.642244102192083
Validation loss: 2.809407956177586

Epoch: 6| Step: 5
Training loss: 2.939860268211135
Validation loss: 2.8075254320414644

Epoch: 6| Step: 6
Training loss: 3.264187583151883
Validation loss: 2.8101813435602625

Epoch: 6| Step: 7
Training loss: 3.012238335226482
Validation loss: 2.8096177038195074

Epoch: 6| Step: 8
Training loss: 3.3113916810175605
Validation loss: 2.811375337285455

Epoch: 6| Step: 9
Training loss: 2.7388032641469793
Validation loss: 2.8132697543504848

Epoch: 6| Step: 10
Training loss: 2.9740328715392663
Validation loss: 2.8165988127803416

Epoch: 6| Step: 11
Training loss: 3.5460213461554537
Validation loss: 2.8266636783897887

Epoch: 6| Step: 12
Training loss: 3.1234900832222587
Validation loss: 2.8069521532237025

Epoch: 6| Step: 13
Training loss: 3.6177380927557317
Validation loss: 2.8025194542247753

Epoch: 65| Step: 0
Training loss: 3.4150271940475063
Validation loss: 2.803798384131078

Epoch: 6| Step: 1
Training loss: 3.2974193539421024
Validation loss: 2.804546509760743

Epoch: 6| Step: 2
Training loss: 3.212185582311514
Validation loss: 2.801779911770738

Epoch: 6| Step: 3
Training loss: 3.2100258528479406
Validation loss: 2.8012899271342198

Epoch: 6| Step: 4
Training loss: 2.737492293952303
Validation loss: 2.8049021458881747

Epoch: 6| Step: 5
Training loss: 2.6102559321533114
Validation loss: 2.8015338874259283

Epoch: 6| Step: 6
Training loss: 2.7198758479843317
Validation loss: 2.8000022063415084

Epoch: 6| Step: 7
Training loss: 3.020027070587295
Validation loss: 2.8021603886401696

Epoch: 6| Step: 8
Training loss: 3.431880171811346
Validation loss: 2.8045508087775812

Epoch: 6| Step: 9
Training loss: 3.5327783838554088
Validation loss: 2.8033000553406255

Epoch: 6| Step: 10
Training loss: 3.4412647785461106
Validation loss: 2.8025970524815995

Epoch: 6| Step: 11
Training loss: 2.8277265573628814
Validation loss: 2.8016125799396345

Epoch: 6| Step: 12
Training loss: 2.9598045093831193
Validation loss: 2.8001814785976187

Epoch: 6| Step: 13
Training loss: 2.967012880961425
Validation loss: 2.799324814742549

Epoch: 66| Step: 0
Training loss: 2.8994413627040774
Validation loss: 2.797140588580147

Epoch: 6| Step: 1
Training loss: 3.1840283805119065
Validation loss: 2.7945950013715484

Epoch: 6| Step: 2
Training loss: 2.925399857276125
Validation loss: 2.7937243868392017

Epoch: 6| Step: 3
Training loss: 3.0228764607345093
Validation loss: 2.795886678776506

Epoch: 6| Step: 4
Training loss: 3.5214644699676625
Validation loss: 2.7946613603374963

Epoch: 6| Step: 5
Training loss: 2.896865624142055
Validation loss: 2.7927427671296576

Epoch: 6| Step: 6
Training loss: 2.615892687810068
Validation loss: 2.79366666927355

Epoch: 6| Step: 7
Training loss: 2.855809724960797
Validation loss: 2.7918731341892746

Epoch: 6| Step: 8
Training loss: 3.303934647317885
Validation loss: 2.796366754658765

Epoch: 6| Step: 9
Training loss: 3.4539396265846625
Validation loss: 2.7926622163588006

Epoch: 6| Step: 10
Training loss: 2.905504028401547
Validation loss: 2.7921879819907947

Epoch: 6| Step: 11
Training loss: 3.777828844199008
Validation loss: 2.7886679450041507

Epoch: 6| Step: 12
Training loss: 2.8907012104607386
Validation loss: 2.7906079161818242

Epoch: 6| Step: 13
Training loss: 3.0183213587129667
Validation loss: 2.789300157658793

Epoch: 67| Step: 0
Training loss: 2.986494180716761
Validation loss: 2.787951873245036

Epoch: 6| Step: 1
Training loss: 3.354351315046022
Validation loss: 2.7975597651280006

Epoch: 6| Step: 2
Training loss: 2.882144840325558
Validation loss: 2.8033134876035652

Epoch: 6| Step: 3
Training loss: 2.0210439303539176
Validation loss: 2.824275881320286

Epoch: 6| Step: 4
Training loss: 3.5145799227918273
Validation loss: 2.857773780160136

Epoch: 6| Step: 5
Training loss: 2.9746396720079713
Validation loss: 2.8598415729958044

Epoch: 6| Step: 6
Training loss: 2.4487125049970455
Validation loss: 2.867373153095691

Epoch: 6| Step: 7
Training loss: 3.5114259863017745
Validation loss: 2.823902027324113

Epoch: 6| Step: 8
Training loss: 2.8044276210064014
Validation loss: 2.784024014644256

Epoch: 6| Step: 9
Training loss: 3.6535091723521016
Validation loss: 2.810581086805876

Epoch: 6| Step: 10
Training loss: 3.2621163679798713
Validation loss: 2.8001612105963414

Epoch: 6| Step: 11
Training loss: 2.939689631785231
Validation loss: 2.8030552573518177

Epoch: 6| Step: 12
Training loss: 3.564839180720417
Validation loss: 2.796346543352217

Epoch: 6| Step: 13
Training loss: 3.36294678056153
Validation loss: 2.80603888915899

Epoch: 68| Step: 0
Training loss: 2.4722927121555887
Validation loss: 2.9540604637986863

Epoch: 6| Step: 1
Training loss: 3.18660199848568
Validation loss: 2.9564522726815943

Epoch: 6| Step: 2
Training loss: 2.3253505483538373
Validation loss: 2.87999008898528

Epoch: 6| Step: 3
Training loss: 3.7662041563022366
Validation loss: 2.8623485313213086

Epoch: 6| Step: 4
Training loss: 3.6164436646605025
Validation loss: 2.8578297930445955

Epoch: 6| Step: 5
Training loss: 3.5500957637281596
Validation loss: 2.8525790769336594

Epoch: 6| Step: 6
Training loss: 3.09132382598966
Validation loss: 2.866271763830978

Epoch: 6| Step: 7
Training loss: 3.059623145540086
Validation loss: 2.867819705055906

Epoch: 6| Step: 8
Training loss: 3.101866738413889
Validation loss: 2.855202925898728

Epoch: 6| Step: 9
Training loss: 3.027234120998877
Validation loss: 2.850042516394482

Epoch: 6| Step: 10
Training loss: 2.7673883366305847
Validation loss: 2.830211074226737

Epoch: 6| Step: 11
Training loss: 3.2526105519769857
Validation loss: 2.803957076200576

Epoch: 6| Step: 12
Training loss: 3.2948399631378806
Validation loss: 2.7828034748095645

Epoch: 6| Step: 13
Training loss: 3.3741845452672
Validation loss: 2.776387976388962

Epoch: 69| Step: 0
Training loss: 3.6923683487054717
Validation loss: 2.7802323215508795

Epoch: 6| Step: 1
Training loss: 3.500943193050524
Validation loss: 2.7740076075604976

Epoch: 6| Step: 2
Training loss: 2.9420293424116846
Validation loss: 2.776672662502665

Epoch: 6| Step: 3
Training loss: 2.7935357645318426
Validation loss: 2.775287460076239

Epoch: 6| Step: 4
Training loss: 3.2860229655210325
Validation loss: 2.778655331098694

Epoch: 6| Step: 5
Training loss: 3.6363429480744447
Validation loss: 2.7839955494930795

Epoch: 6| Step: 6
Training loss: 2.528375665523611
Validation loss: 2.7822659139416936

Epoch: 6| Step: 7
Training loss: 2.964435212506826
Validation loss: 2.7802902838906745

Epoch: 6| Step: 8
Training loss: 2.5611298782679754
Validation loss: 2.780166379851742

Epoch: 6| Step: 9
Training loss: 2.9917595858652644
Validation loss: 2.784716808967224

Epoch: 6| Step: 10
Training loss: 3.1716377658165364
Validation loss: 2.778048687067419

Epoch: 6| Step: 11
Training loss: 2.6464597806456367
Validation loss: 2.778580349750854

Epoch: 6| Step: 12
Training loss: 3.548128015954686
Validation loss: 2.773819602007975

Epoch: 6| Step: 13
Training loss: 2.5354018834439818
Validation loss: 2.7830813771770337

Epoch: 70| Step: 0
Training loss: 2.78549607438821
Validation loss: 2.790986071954951

Epoch: 6| Step: 1
Training loss: 3.018306824434153
Validation loss: 2.8006583074251474

Epoch: 6| Step: 2
Training loss: 3.320356445021689
Validation loss: 2.7999550075256203

Epoch: 6| Step: 3
Training loss: 2.2731761454423207
Validation loss: 2.790689759982714

Epoch: 6| Step: 4
Training loss: 2.40801283431831
Validation loss: 2.7773580628517185

Epoch: 6| Step: 5
Training loss: 2.829224936363235
Validation loss: 2.7709015301153177

Epoch: 6| Step: 6
Training loss: 2.9366867887721906
Validation loss: 2.7696437022871825

Epoch: 6| Step: 7
Training loss: 3.6745212839994466
Validation loss: 2.7662702340401184

Epoch: 6| Step: 8
Training loss: 3.6301841497869973
Validation loss: 2.762546207470458

Epoch: 6| Step: 9
Training loss: 3.4591172643515797
Validation loss: 2.7645915400375087

Epoch: 6| Step: 10
Training loss: 3.441452112660845
Validation loss: 2.763320912278146

Epoch: 6| Step: 11
Training loss: 3.6064975382506783
Validation loss: 2.765885797032995

Epoch: 6| Step: 12
Training loss: 2.4210038125639577
Validation loss: 2.7647769295798375

Epoch: 6| Step: 13
Training loss: 2.896793526467731
Validation loss: 2.7656584762513288

Epoch: 71| Step: 0
Training loss: 3.592033971664086
Validation loss: 2.780477859295947

Epoch: 6| Step: 1
Training loss: 3.790487811820861
Validation loss: 2.7904781761937736

Epoch: 6| Step: 2
Training loss: 3.0013303985694333
Validation loss: 2.771350257859786

Epoch: 6| Step: 3
Training loss: 3.2894098456361984
Validation loss: 2.7678508798547194

Epoch: 6| Step: 4
Training loss: 3.3269688563676447
Validation loss: 2.7609960120275936

Epoch: 6| Step: 5
Training loss: 2.6276124942119545
Validation loss: 2.7633627965942633

Epoch: 6| Step: 6
Training loss: 3.2634413139498504
Validation loss: 2.762676034290135

Epoch: 6| Step: 7
Training loss: 3.064020052104703
Validation loss: 2.767979941061938

Epoch: 6| Step: 8
Training loss: 2.2759464223619497
Validation loss: 2.766659119150082

Epoch: 6| Step: 9
Training loss: 2.9776817480263564
Validation loss: 2.772344131244855

Epoch: 6| Step: 10
Training loss: 3.0371489396538696
Validation loss: 2.7687133005153894

Epoch: 6| Step: 11
Training loss: 3.1219044421452478
Validation loss: 2.767078284555683

Epoch: 6| Step: 12
Training loss: 2.688498378101191
Validation loss: 2.762552198626715

Epoch: 6| Step: 13
Training loss: 2.6222639811507955
Validation loss: 2.7623123111496346

Epoch: 72| Step: 0
Training loss: 3.0809658515322926
Validation loss: 2.759993444137432

Epoch: 6| Step: 1
Training loss: 3.161396325564848
Validation loss: 2.763382541294013

Epoch: 6| Step: 2
Training loss: 3.8366766875860048
Validation loss: 2.7629108778019065

Epoch: 6| Step: 3
Training loss: 2.6916879359803483
Validation loss: 2.768913641371322

Epoch: 6| Step: 4
Training loss: 2.8158086177045676
Validation loss: 2.7724494871574126

Epoch: 6| Step: 5
Training loss: 3.3608273227851355
Validation loss: 2.77855713592951

Epoch: 6| Step: 6
Training loss: 3.192822220447652
Validation loss: 2.765830356154712

Epoch: 6| Step: 7
Training loss: 2.8152409231237585
Validation loss: 2.7600684279278385

Epoch: 6| Step: 8
Training loss: 2.8773147552545697
Validation loss: 2.7517710508127484

Epoch: 6| Step: 9
Training loss: 2.3343824230724617
Validation loss: 2.7518129572078895

Epoch: 6| Step: 10
Training loss: 3.1059482420215407
Validation loss: 2.7501504070135274

Epoch: 6| Step: 11
Training loss: 2.5380036479060992
Validation loss: 2.7502351485068424

Epoch: 6| Step: 12
Training loss: 3.5204506540089455
Validation loss: 2.7502470996177104

Epoch: 6| Step: 13
Training loss: 3.9067259231560727
Validation loss: 2.7517040432272077

Epoch: 73| Step: 0
Training loss: 2.511111932189867
Validation loss: 2.765320676969453

Epoch: 6| Step: 1
Training loss: 3.231478808803803
Validation loss: 2.7715286399002057

Epoch: 6| Step: 2
Training loss: 3.318496171400475
Validation loss: 2.7478012531547473

Epoch: 6| Step: 3
Training loss: 3.3929623752422557
Validation loss: 2.7469426673891477

Epoch: 6| Step: 4
Training loss: 3.2399554923026415
Validation loss: 2.7472065229598526

Epoch: 6| Step: 5
Training loss: 3.449074833979133
Validation loss: 2.7501411597527974

Epoch: 6| Step: 6
Training loss: 2.9739647290127067
Validation loss: 2.7466181696584595

Epoch: 6| Step: 7
Training loss: 2.7662219249267683
Validation loss: 2.750417662718105

Epoch: 6| Step: 8
Training loss: 3.476702809449196
Validation loss: 2.7471058159647805

Epoch: 6| Step: 9
Training loss: 2.358537841215104
Validation loss: 2.7508795479245256

Epoch: 6| Step: 10
Training loss: 3.5366749910142197
Validation loss: 2.7502037403558504

Epoch: 6| Step: 11
Training loss: 2.7138429402479236
Validation loss: 2.7545166884379344

Epoch: 6| Step: 12
Training loss: 3.048851272133464
Validation loss: 2.7547504342221476

Epoch: 6| Step: 13
Training loss: 2.4063911891981404
Validation loss: 2.7572132681872086

Epoch: 74| Step: 0
Training loss: 2.85781834655464
Validation loss: 2.7603494801222577

Epoch: 6| Step: 1
Training loss: 3.2277067432331115
Validation loss: 2.7581218369488356

Epoch: 6| Step: 2
Training loss: 3.7678016291759957
Validation loss: 2.7550777548040153

Epoch: 6| Step: 3
Training loss: 3.5432712884197626
Validation loss: 2.752458097461884

Epoch: 6| Step: 4
Training loss: 2.098909653571635
Validation loss: 2.746743176369639

Epoch: 6| Step: 5
Training loss: 3.227722550570968
Validation loss: 2.745204310690234

Epoch: 6| Step: 6
Training loss: 2.7496198044568416
Validation loss: 2.7462516476359626

Epoch: 6| Step: 7
Training loss: 2.772841182591775
Validation loss: 2.7421770385733355

Epoch: 6| Step: 8
Training loss: 3.908198488643552
Validation loss: 2.747594500980498

Epoch: 6| Step: 9
Training loss: 2.484054832701008
Validation loss: 2.7457985642393075

Epoch: 6| Step: 10
Training loss: 2.7164870743004297
Validation loss: 2.743997704702727

Epoch: 6| Step: 11
Training loss: 3.2135627205940596
Validation loss: 2.7430170669094998

Epoch: 6| Step: 12
Training loss: 2.9610502276941766
Validation loss: 2.746695418899791

Epoch: 6| Step: 13
Training loss: 2.8570684082685815
Validation loss: 2.74680052941004

Epoch: 75| Step: 0
Training loss: 2.8259730292165086
Validation loss: 2.741850855762137

Epoch: 6| Step: 1
Training loss: 2.5628751154556624
Validation loss: 2.7414844491534582

Epoch: 6| Step: 2
Training loss: 3.2346502362038665
Validation loss: 2.7439996601336403

Epoch: 6| Step: 3
Training loss: 2.445830561448389
Validation loss: 2.743440946276177

Epoch: 6| Step: 4
Training loss: 3.4005649265619358
Validation loss: 2.73981779297628

Epoch: 6| Step: 5
Training loss: 3.417180712727599
Validation loss: 2.7370176740636487

Epoch: 6| Step: 6
Training loss: 3.2197475924396612
Validation loss: 2.7374802562529625

Epoch: 6| Step: 7
Training loss: 2.2611123228994128
Validation loss: 2.7362566692797734

Epoch: 6| Step: 8
Training loss: 3.2554961461305254
Validation loss: 2.7384468103344006

Epoch: 6| Step: 9
Training loss: 3.251666888679042
Validation loss: 2.7382050029745493

Epoch: 6| Step: 10
Training loss: 3.0131118659552376
Validation loss: 2.7403323651751674

Epoch: 6| Step: 11
Training loss: 3.239451087795543
Validation loss: 2.7424944610663906

Epoch: 6| Step: 12
Training loss: 3.2814357160054755
Validation loss: 2.748200007399837

Epoch: 6| Step: 13
Training loss: 3.128238068479753
Validation loss: 2.746761859872395

Epoch: 76| Step: 0
Training loss: 2.6828682486552213
Validation loss: 2.7431813928530855

Epoch: 6| Step: 1
Training loss: 2.7379834588653944
Validation loss: 2.733993686510214

Epoch: 6| Step: 2
Training loss: 2.9666105893725
Validation loss: 2.73175480199337

Epoch: 6| Step: 3
Training loss: 2.3443369829740752
Validation loss: 2.7307237530721737

Epoch: 6| Step: 4
Training loss: 3.0752453961962405
Validation loss: 2.7297648250542927

Epoch: 6| Step: 5
Training loss: 3.235591346428653
Validation loss: 2.730711469607221

Epoch: 6| Step: 6
Training loss: 3.3967974333693682
Validation loss: 2.7279396282734645

Epoch: 6| Step: 7
Training loss: 3.145958466388457
Validation loss: 2.7253510656095203

Epoch: 6| Step: 8
Training loss: 2.930832783953243
Validation loss: 2.7248031478500994

Epoch: 6| Step: 9
Training loss: 3.489703701087919
Validation loss: 2.7279224773848636

Epoch: 6| Step: 10
Training loss: 2.8517920832772288
Validation loss: 2.7256812310319276

Epoch: 6| Step: 11
Training loss: 3.0546003948778138
Validation loss: 2.7263588011670117

Epoch: 6| Step: 12
Training loss: 3.3015641406985394
Validation loss: 2.724206512714567

Epoch: 6| Step: 13
Training loss: 3.4071444115830833
Validation loss: 2.727864347757387

Epoch: 77| Step: 0
Training loss: 2.903667984722587
Validation loss: 2.7233237207255896

Epoch: 6| Step: 1
Training loss: 3.459670823154978
Validation loss: 2.7247750199480567

Epoch: 6| Step: 2
Training loss: 2.879659111723373
Validation loss: 2.7227186619949975

Epoch: 6| Step: 3
Training loss: 2.891911071064312
Validation loss: 2.721914280940372

Epoch: 6| Step: 4
Training loss: 2.7655187898920692
Validation loss: 2.7237943463738943

Epoch: 6| Step: 5
Training loss: 2.2699944816219793
Validation loss: 2.7267978532669574

Epoch: 6| Step: 6
Training loss: 3.389368061591068
Validation loss: 2.726986892325927

Epoch: 6| Step: 7
Training loss: 3.6611707130356863
Validation loss: 2.723151916260772

Epoch: 6| Step: 8
Training loss: 3.3549939353649285
Validation loss: 2.725352321866493

Epoch: 6| Step: 9
Training loss: 2.8085617466828854
Validation loss: 2.720546281295683

Epoch: 6| Step: 10
Training loss: 2.539804485185332
Validation loss: 2.723109290600905

Epoch: 6| Step: 11
Training loss: 3.230124809286684
Validation loss: 2.7206128369446363

Epoch: 6| Step: 12
Training loss: 2.8743285348698726
Validation loss: 2.719720477947589

Epoch: 6| Step: 13
Training loss: 3.4185060961541898
Validation loss: 2.7195978847485973

Epoch: 78| Step: 0
Training loss: 3.417773710953115
Validation loss: 2.72000842401357

Epoch: 6| Step: 1
Training loss: 3.2601741582770334
Validation loss: 2.7192989535844143

Epoch: 6| Step: 2
Training loss: 2.7986160059513505
Validation loss: 2.7179294112067027

Epoch: 6| Step: 3
Training loss: 3.2935994586164887
Validation loss: 2.7215124402261823

Epoch: 6| Step: 4
Training loss: 3.10448650444785
Validation loss: 2.7240914356364914

Epoch: 6| Step: 5
Training loss: 3.0293107269186845
Validation loss: 2.73080204149483

Epoch: 6| Step: 6
Training loss: 2.579128463125282
Validation loss: 2.7262227978938256

Epoch: 6| Step: 7
Training loss: 3.800655162950669
Validation loss: 2.743030951383407

Epoch: 6| Step: 8
Training loss: 3.28689496524809
Validation loss: 2.725339493531907

Epoch: 6| Step: 9
Training loss: 3.0748419124005193
Validation loss: 2.717338421872812

Epoch: 6| Step: 10
Training loss: 2.3749540224142325
Validation loss: 2.7174450226280866

Epoch: 6| Step: 11
Training loss: 3.2975442939195414
Validation loss: 2.7175464938997735

Epoch: 6| Step: 12
Training loss: 2.146808464429647
Validation loss: 2.7153595795601024

Epoch: 6| Step: 13
Training loss: 2.4904257547477475
Validation loss: 2.717138312224081

Epoch: 79| Step: 0
Training loss: 3.0297788215712385
Validation loss: 2.7151441300358816

Epoch: 6| Step: 1
Training loss: 2.916728009986657
Validation loss: 2.7177895987899032

Epoch: 6| Step: 2
Training loss: 3.1607436116407532
Validation loss: 2.715419627175921

Epoch: 6| Step: 3
Training loss: 2.831742307458362
Validation loss: 2.712972927210146

Epoch: 6| Step: 4
Training loss: 3.5878399890530708
Validation loss: 2.716387987995475

Epoch: 6| Step: 5
Training loss: 3.3325169199280062
Validation loss: 2.7153318400626087

Epoch: 6| Step: 6
Training loss: 2.7625258155410535
Validation loss: 2.728783841224216

Epoch: 6| Step: 7
Training loss: 2.7783378184861487
Validation loss: 2.7290696502052034

Epoch: 6| Step: 8
Training loss: 2.763344724452979
Validation loss: 2.75185628738792

Epoch: 6| Step: 9
Training loss: 2.821335878970771
Validation loss: 2.7622402811671023

Epoch: 6| Step: 10
Training loss: 2.774368430772443
Validation loss: 2.762063599241973

Epoch: 6| Step: 11
Training loss: 2.9911473311368972
Validation loss: 2.7704217052810107

Epoch: 6| Step: 12
Training loss: 3.3578368458102688
Validation loss: 2.7581259806023954

Epoch: 6| Step: 13
Training loss: 3.5443208211176103
Validation loss: 2.7372060962895426

Epoch: 80| Step: 0
Training loss: 3.5306433772714434
Validation loss: 2.724070641026241

Epoch: 6| Step: 1
Training loss: 3.4261415959730472
Validation loss: 2.715813874647769

Epoch: 6| Step: 2
Training loss: 2.784220619931046
Validation loss: 2.7149368370506295

Epoch: 6| Step: 3
Training loss: 2.641842533198155
Validation loss: 2.7151996947266737

Epoch: 6| Step: 4
Training loss: 2.7052459334231953
Validation loss: 2.7191860107251924

Epoch: 6| Step: 5
Training loss: 2.875967443480874
Validation loss: 2.7223327645108037

Epoch: 6| Step: 6
Training loss: 3.3651679193507187
Validation loss: 2.7248018297139978

Epoch: 6| Step: 7
Training loss: 2.7705692557405044
Validation loss: 2.7167093352769296

Epoch: 6| Step: 8
Training loss: 3.4723310801078306
Validation loss: 2.71572947223828

Epoch: 6| Step: 9
Training loss: 3.930279605615905
Validation loss: 2.7140762888601997

Epoch: 6| Step: 10
Training loss: 2.9163375850496362
Validation loss: 2.7156307255186256

Epoch: 6| Step: 11
Training loss: 2.818245169691029
Validation loss: 2.712571796241871

Epoch: 6| Step: 12
Training loss: 2.3696262399692656
Validation loss: 2.710251711051327

Epoch: 6| Step: 13
Training loss: 2.4177246956611933
Validation loss: 2.7038752728400293

Epoch: 81| Step: 0
Training loss: 3.050140352615646
Validation loss: 2.7067669967059094

Epoch: 6| Step: 1
Training loss: 3.2544399158149186
Validation loss: 2.7073176262872676

Epoch: 6| Step: 2
Training loss: 3.0172111806626694
Validation loss: 2.704846277663622

Epoch: 6| Step: 3
Training loss: 3.195331004492568
Validation loss: 2.735447727621174

Epoch: 6| Step: 4
Training loss: 2.7205222481152833
Validation loss: 2.745116022003603

Epoch: 6| Step: 5
Training loss: 2.858833636956503
Validation loss: 2.753369963463676

Epoch: 6| Step: 6
Training loss: 2.6507266793675535
Validation loss: 2.768012171849951

Epoch: 6| Step: 7
Training loss: 3.5699691106491063
Validation loss: 2.8077033720409315

Epoch: 6| Step: 8
Training loss: 3.099567530829717
Validation loss: 2.7506652038679524

Epoch: 6| Step: 9
Training loss: 3.4137993543109912
Validation loss: 2.7196203264268823

Epoch: 6| Step: 10
Training loss: 2.8170126422223296
Validation loss: 2.6982001293773674

Epoch: 6| Step: 11
Training loss: 2.716293013996193
Validation loss: 2.699606834766052

Epoch: 6| Step: 12
Training loss: 3.0794451830643204
Validation loss: 2.706570920038256

Epoch: 6| Step: 13
Training loss: 3.21884584747122
Validation loss: 2.7308487701417805

Epoch: 82| Step: 0
Training loss: 3.386196214960583
Validation loss: 2.701700314427158

Epoch: 6| Step: 1
Training loss: 3.166582474509561
Validation loss: 2.7001854991958893

Epoch: 6| Step: 2
Training loss: 2.615915017587908
Validation loss: 2.6965135112031864

Epoch: 6| Step: 3
Training loss: 3.3080149102572642
Validation loss: 2.6986955766360294

Epoch: 6| Step: 4
Training loss: 3.4616648854701224
Validation loss: 2.7071686776556882

Epoch: 6| Step: 5
Training loss: 3.271273897147142
Validation loss: 2.727258765121822

Epoch: 6| Step: 6
Training loss: 2.8497614777453752
Validation loss: 2.7406827181410964

Epoch: 6| Step: 7
Training loss: 2.8606372819486414
Validation loss: 2.7259793551040357

Epoch: 6| Step: 8
Training loss: 2.562873627010771
Validation loss: 2.6984628731099813

Epoch: 6| Step: 9
Training loss: 3.152317429897092
Validation loss: 2.6941383937394856

Epoch: 6| Step: 10
Training loss: 3.2748816315903286
Validation loss: 2.6968455825201456

Epoch: 6| Step: 11
Training loss: 2.8455454429868148
Validation loss: 2.6950528716953457

Epoch: 6| Step: 12
Training loss: 2.591742784500565
Validation loss: 2.7024812820425494

Epoch: 6| Step: 13
Training loss: 2.958356472157712
Validation loss: 2.702859319561565

Epoch: 83| Step: 0
Training loss: 3.269746944190105
Validation loss: 2.703515564159521

Epoch: 6| Step: 1
Training loss: 2.9354900220085103
Validation loss: 2.7039569117788957

Epoch: 6| Step: 2
Training loss: 3.247014949011101
Validation loss: 2.699343837686974

Epoch: 6| Step: 3
Training loss: 2.776580748661762
Validation loss: 2.7035455006199727

Epoch: 6| Step: 4
Training loss: 2.9866228675469055
Validation loss: 2.699655153652261

Epoch: 6| Step: 5
Training loss: 2.7737203964159574
Validation loss: 2.694666605598529

Epoch: 6| Step: 6
Training loss: 2.516449597662485
Validation loss: 2.6977183030351175

Epoch: 6| Step: 7
Training loss: 3.643843378404897
Validation loss: 2.6964752328739836

Epoch: 6| Step: 8
Training loss: 3.4461226083969345
Validation loss: 2.691758925264104

Epoch: 6| Step: 9
Training loss: 2.938917751286709
Validation loss: 2.693674738396736

Epoch: 6| Step: 10
Training loss: 3.0303686374729217
Validation loss: 2.69836708103938

Epoch: 6| Step: 11
Training loss: 2.56769166106614
Validation loss: 2.7010394497756596

Epoch: 6| Step: 12
Training loss: 3.4342191818752856
Validation loss: 2.7183836512261457

Epoch: 6| Step: 13
Training loss: 2.240186057197441
Validation loss: 2.7258972857122292

Epoch: 84| Step: 0
Training loss: 2.8973972479413193
Validation loss: 2.729917623166606

Epoch: 6| Step: 1
Training loss: 2.850050099250416
Validation loss: 2.71158492851285

Epoch: 6| Step: 2
Training loss: 3.20310966674112
Validation loss: 2.691877535935789

Epoch: 6| Step: 3
Training loss: 3.1331957347227704
Validation loss: 2.690985015687006

Epoch: 6| Step: 4
Training loss: 2.4911760053350074
Validation loss: 2.6897394198884963

Epoch: 6| Step: 5
Training loss: 2.7674077209691363
Validation loss: 2.690182689302223

Epoch: 6| Step: 6
Training loss: 3.351183463051127
Validation loss: 2.6896745660586117

Epoch: 6| Step: 7
Training loss: 3.1744595225318073
Validation loss: 2.684879524013768

Epoch: 6| Step: 8
Training loss: 2.91367368175135
Validation loss: 2.686224644128899

Epoch: 6| Step: 9
Training loss: 3.4755595957311685
Validation loss: 2.6863118927320753

Epoch: 6| Step: 10
Training loss: 2.4864064673991395
Validation loss: 2.6843861032305734

Epoch: 6| Step: 11
Training loss: 2.7047313702053932
Validation loss: 2.6834460821472006

Epoch: 6| Step: 12
Training loss: 3.435153090662281
Validation loss: 2.683351854894673

Epoch: 6| Step: 13
Training loss: 3.3593703159033477
Validation loss: 2.6826438910692127

Epoch: 85| Step: 0
Training loss: 2.3331895057310112
Validation loss: 2.6851988974136916

Epoch: 6| Step: 1
Training loss: 3.2709593212055457
Validation loss: 2.6952976506391733

Epoch: 6| Step: 2
Training loss: 2.762964466801176
Validation loss: 2.697465824174261

Epoch: 6| Step: 3
Training loss: 3.278941768574749
Validation loss: 2.6972508206085624

Epoch: 6| Step: 4
Training loss: 3.1654650934922146
Validation loss: 2.701786160901649

Epoch: 6| Step: 5
Training loss: 2.720139071892202
Validation loss: 2.690229109564205

Epoch: 6| Step: 6
Training loss: 2.4814848012833455
Validation loss: 2.677605083790222

Epoch: 6| Step: 7
Training loss: 3.3751650169438476
Validation loss: 2.679008884677033

Epoch: 6| Step: 8
Training loss: 3.1153311113507036
Validation loss: 2.673015659717165

Epoch: 6| Step: 9
Training loss: 2.929957181598143
Validation loss: 2.671398047110474

Epoch: 6| Step: 10
Training loss: 2.692943294660479
Validation loss: 2.6725011241975745

Epoch: 6| Step: 11
Training loss: 3.633498654118702
Validation loss: 2.6735421322626647

Epoch: 6| Step: 12
Training loss: 2.820488667996017
Validation loss: 2.672673449898127

Epoch: 6| Step: 13
Training loss: 3.4535576044505616
Validation loss: 2.6705432972859633

Epoch: 86| Step: 0
Training loss: 2.7068586198112534
Validation loss: 2.6712698763051828

Epoch: 6| Step: 1
Training loss: 2.8245885667547497
Validation loss: 2.671695446291609

Epoch: 6| Step: 2
Training loss: 3.380130259469875
Validation loss: 2.675857639382533

Epoch: 6| Step: 3
Training loss: 2.879650169954392
Validation loss: 2.6761291502890656

Epoch: 6| Step: 4
Training loss: 2.8469565621677684
Validation loss: 2.6869484587550385

Epoch: 6| Step: 5
Training loss: 2.499943160364593
Validation loss: 2.690381505945051

Epoch: 6| Step: 6
Training loss: 3.057724947448355
Validation loss: 2.702198444258342

Epoch: 6| Step: 7
Training loss: 3.3222811259559015
Validation loss: 2.7006570006813617

Epoch: 6| Step: 8
Training loss: 2.991169649313071
Validation loss: 2.679805084665164

Epoch: 6| Step: 9
Training loss: 3.1117590577668044
Validation loss: 2.672258261433877

Epoch: 6| Step: 10
Training loss: 3.1730606043113663
Validation loss: 2.6642966185166927

Epoch: 6| Step: 11
Training loss: 3.17005183998825
Validation loss: 2.6638858245686334

Epoch: 6| Step: 12
Training loss: 3.03172864772638
Validation loss: 2.659869620950422

Epoch: 6| Step: 13
Training loss: 2.8807843938865085
Validation loss: 2.6607213508723655

Epoch: 87| Step: 0
Training loss: 3.0332447842539207
Validation loss: 2.6616484678845755

Epoch: 6| Step: 1
Training loss: 3.1723674523430523
Validation loss: 2.663544779650058

Epoch: 6| Step: 2
Training loss: 2.793558125232757
Validation loss: 2.6657896740417426

Epoch: 6| Step: 3
Training loss: 3.0904981689348956
Validation loss: 2.6646549512875772

Epoch: 6| Step: 4
Training loss: 3.6177419151082426
Validation loss: 2.662018996808657

Epoch: 6| Step: 5
Training loss: 3.35545709716763
Validation loss: 2.658325594656977

Epoch: 6| Step: 6
Training loss: 2.669506428563819
Validation loss: 2.661509566320358

Epoch: 6| Step: 7
Training loss: 2.7634459278496264
Validation loss: 2.6574837846776127

Epoch: 6| Step: 8
Training loss: 3.1004421411045415
Validation loss: 2.658728855972577

Epoch: 6| Step: 9
Training loss: 2.260067035220997
Validation loss: 2.663619816397139

Epoch: 6| Step: 10
Training loss: 2.5411935167842086
Validation loss: 2.670402871146828

Epoch: 6| Step: 11
Training loss: 3.1930096449355374
Validation loss: 2.687703961709788

Epoch: 6| Step: 12
Training loss: 3.1452184080328216
Validation loss: 2.7122221434909304

Epoch: 6| Step: 13
Training loss: 2.9578399963229343
Validation loss: 2.753743619763362

Epoch: 88| Step: 0
Training loss: 2.8433931566975903
Validation loss: 2.7639942453825883

Epoch: 6| Step: 1
Training loss: 2.6855459872157623
Validation loss: 2.703746126090314

Epoch: 6| Step: 2
Training loss: 3.057075523174809
Validation loss: 2.666123245100269

Epoch: 6| Step: 3
Training loss: 3.2984048629439924
Validation loss: 2.653506867752777

Epoch: 6| Step: 4
Training loss: 2.7927739428893172
Validation loss: 2.6545500564197533

Epoch: 6| Step: 5
Training loss: 2.9884459207079677
Validation loss: 2.6686753743292186

Epoch: 6| Step: 6
Training loss: 3.064269508321503
Validation loss: 2.6580651313230663

Epoch: 6| Step: 7
Training loss: 3.183924146486699
Validation loss: 2.6590780598380293

Epoch: 6| Step: 8
Training loss: 2.237144621006396
Validation loss: 2.656420780991707

Epoch: 6| Step: 9
Training loss: 3.3304807537022714
Validation loss: 2.655593498505995

Epoch: 6| Step: 10
Training loss: 3.0816493891686756
Validation loss: 2.652843822494726

Epoch: 6| Step: 11
Training loss: 3.2455963231051563
Validation loss: 2.660307393320186

Epoch: 6| Step: 12
Training loss: 3.119925689790456
Validation loss: 2.668578197896203

Epoch: 6| Step: 13
Training loss: 3.2499044844456613
Validation loss: 2.676854606756968

Epoch: 89| Step: 0
Training loss: 3.290582953290397
Validation loss: 2.698668440071526

Epoch: 6| Step: 1
Training loss: 2.9445650887714674
Validation loss: 2.7220631318828032

Epoch: 6| Step: 2
Training loss: 2.7649480993494158
Validation loss: 2.6975366880153486

Epoch: 6| Step: 3
Training loss: 3.1671275422528353
Validation loss: 2.6961447342971856

Epoch: 6| Step: 4
Training loss: 3.6791932245824595
Validation loss: 2.6736536290481805

Epoch: 6| Step: 5
Training loss: 3.1611821380245755
Validation loss: 2.6491673819856283

Epoch: 6| Step: 6
Training loss: 2.7924204041314096
Validation loss: 2.650063388342627

Epoch: 6| Step: 7
Training loss: 3.205444389397593
Validation loss: 2.652071642597165

Epoch: 6| Step: 8
Training loss: 2.4665660614254743
Validation loss: 2.6522955473791145

Epoch: 6| Step: 9
Training loss: 2.9479330936329156
Validation loss: 2.6565637566062694

Epoch: 6| Step: 10
Training loss: 2.913202644693268
Validation loss: 2.654219519308411

Epoch: 6| Step: 11
Training loss: 3.2198288970410682
Validation loss: 2.655439747643469

Epoch: 6| Step: 12
Training loss: 2.6670813138771687
Validation loss: 2.6530958564553235

Epoch: 6| Step: 13
Training loss: 2.495157224330202
Validation loss: 2.653274841726956

Epoch: 90| Step: 0
Training loss: 3.6243067111314597
Validation loss: 2.6533665129291193

Epoch: 6| Step: 1
Training loss: 2.865762715166109
Validation loss: 2.6527014601137906

Epoch: 6| Step: 2
Training loss: 3.1645502915372443
Validation loss: 2.652387262092834

Epoch: 6| Step: 3
Training loss: 3.160303364690257
Validation loss: 2.650952773067751

Epoch: 6| Step: 4
Training loss: 2.8810045315654884
Validation loss: 2.653168006837417

Epoch: 6| Step: 5
Training loss: 3.3487531362805805
Validation loss: 2.6573053414568357

Epoch: 6| Step: 6
Training loss: 3.252453684729957
Validation loss: 2.6652330177458547

Epoch: 6| Step: 7
Training loss: 2.6503296341199953
Validation loss: 2.664470526485697

Epoch: 6| Step: 8
Training loss: 3.2701343996385255
Validation loss: 2.6682479064469984

Epoch: 6| Step: 9
Training loss: 2.4278372929210965
Validation loss: 2.660765816643532

Epoch: 6| Step: 10
Training loss: 2.897877765086346
Validation loss: 2.653856200394684

Epoch: 6| Step: 11
Training loss: 2.9695330741493344
Validation loss: 2.647027129983799

Epoch: 6| Step: 12
Training loss: 2.644894911583966
Validation loss: 2.6472284561252146

Epoch: 6| Step: 13
Training loss: 2.1941730623867977
Validation loss: 2.644259511761443

Epoch: 91| Step: 0
Training loss: 2.6401482326622663
Validation loss: 2.6415756755962567

Epoch: 6| Step: 1
Training loss: 3.1976569419205823
Validation loss: 2.645690565946275

Epoch: 6| Step: 2
Training loss: 3.347521784784884
Validation loss: 2.646460326995587

Epoch: 6| Step: 3
Training loss: 2.1174140611884473
Validation loss: 2.6448985909638307

Epoch: 6| Step: 4
Training loss: 3.4154212046254093
Validation loss: 2.645795423801157

Epoch: 6| Step: 5
Training loss: 3.5285778907156304
Validation loss: 2.6468739997162682

Epoch: 6| Step: 6
Training loss: 2.890950117643443
Validation loss: 2.6499334339349563

Epoch: 6| Step: 7
Training loss: 2.7553632628947953
Validation loss: 2.6551675259339182

Epoch: 6| Step: 8
Training loss: 2.632608920866259
Validation loss: 2.6583224276254893

Epoch: 6| Step: 9
Training loss: 2.989529138443794
Validation loss: 2.667011302807206

Epoch: 6| Step: 10
Training loss: 3.208773512596232
Validation loss: 2.6813251407863423

Epoch: 6| Step: 11
Training loss: 3.176965246455343
Validation loss: 2.67501993494864

Epoch: 6| Step: 12
Training loss: 2.7459334737744503
Validation loss: 2.6622559662777827

Epoch: 6| Step: 13
Training loss: 2.6300643025358967
Validation loss: 2.65578910984055

Epoch: 92| Step: 0
Training loss: 2.744829779594978
Validation loss: 2.6902825930760415

Epoch: 6| Step: 1
Training loss: 2.8807736348469817
Validation loss: 2.693463197537117

Epoch: 6| Step: 2
Training loss: 2.5590237554630417
Validation loss: 2.706900511203111

Epoch: 6| Step: 3
Training loss: 3.5472229102152375
Validation loss: 2.728530784034728

Epoch: 6| Step: 4
Training loss: 2.830698602131785
Validation loss: 2.6880371165612966

Epoch: 6| Step: 5
Training loss: 2.896777394778954
Validation loss: 2.664485552458969

Epoch: 6| Step: 6
Training loss: 3.2032887486726898
Validation loss: 2.6796900744619983

Epoch: 6| Step: 7
Training loss: 3.0340765919281
Validation loss: 2.659123199994383

Epoch: 6| Step: 8
Training loss: 2.5595646304722797
Validation loss: 2.6339278092438234

Epoch: 6| Step: 9
Training loss: 2.931275611228732
Validation loss: 2.632997765492968

Epoch: 6| Step: 10
Training loss: 3.267447661117106
Validation loss: 2.634149027570364

Epoch: 6| Step: 11
Training loss: 2.9081331120371123
Validation loss: 2.634003515492542

Epoch: 6| Step: 12
Training loss: 2.9242640229618067
Validation loss: 2.6386355032505637

Epoch: 6| Step: 13
Training loss: 3.6248472773509577
Validation loss: 2.640610060577063

Epoch: 93| Step: 0
Training loss: 3.0010747573830705
Validation loss: 2.637484445056071

Epoch: 6| Step: 1
Training loss: 2.5915964217238843
Validation loss: 2.6363345101912596

Epoch: 6| Step: 2
Training loss: 2.3297820882444853
Validation loss: 2.6350214214862606

Epoch: 6| Step: 3
Training loss: 3.563068411470902
Validation loss: 2.6450577541372917

Epoch: 6| Step: 4
Training loss: 3.2517454888667463
Validation loss: 2.646769275639343

Epoch: 6| Step: 5
Training loss: 2.95365230958933
Validation loss: 2.6502166888537366

Epoch: 6| Step: 6
Training loss: 2.9075777035905666
Validation loss: 2.645635194523888

Epoch: 6| Step: 7
Training loss: 3.2704429312484162
Validation loss: 2.6600207969410135

Epoch: 6| Step: 8
Training loss: 2.8276252094206495
Validation loss: 2.6508313070634957

Epoch: 6| Step: 9
Training loss: 2.7764707499700862
Validation loss: 2.6501390099512747

Epoch: 6| Step: 10
Training loss: 3.5670607969997072
Validation loss: 2.647994883112655

Epoch: 6| Step: 11
Training loss: 2.9668108580048194
Validation loss: 2.6366330553452944

Epoch: 6| Step: 12
Training loss: 2.6144971086081563
Validation loss: 2.6344852230648215

Epoch: 6| Step: 13
Training loss: 2.5520095087908636
Validation loss: 2.6307818349304632

Epoch: 94| Step: 0
Training loss: 3.202218276295057
Validation loss: 2.6275372916769353

Epoch: 6| Step: 1
Training loss: 3.4105315291431184
Validation loss: 2.6271894878122506

Epoch: 6| Step: 2
Training loss: 2.877012792151118
Validation loss: 2.6271638824044925

Epoch: 6| Step: 3
Training loss: 2.125590522843189
Validation loss: 2.6258272722051768

Epoch: 6| Step: 4
Training loss: 2.6035492330386614
Validation loss: 2.6273848154874804

Epoch: 6| Step: 5
Training loss: 2.856678175604422
Validation loss: 2.624181534872974

Epoch: 6| Step: 6
Training loss: 3.2264312643559108
Validation loss: 2.625603256404452

Epoch: 6| Step: 7
Training loss: 3.277691028186965
Validation loss: 2.6303492146599012

Epoch: 6| Step: 8
Training loss: 3.247519353349325
Validation loss: 2.6308982143371282

Epoch: 6| Step: 9
Training loss: 3.0657840170336725
Validation loss: 2.641061936852044

Epoch: 6| Step: 10
Training loss: 2.7720244770538187
Validation loss: 2.6504761476088237

Epoch: 6| Step: 11
Training loss: 2.8008610968068295
Validation loss: 2.6554207537098677

Epoch: 6| Step: 12
Training loss: 2.9374224064095307
Validation loss: 2.6623585058468504

Epoch: 6| Step: 13
Training loss: 2.990688017975432
Validation loss: 2.6824787772737233

Epoch: 95| Step: 0
Training loss: 2.739853259424437
Validation loss: 2.6521180146074115

Epoch: 6| Step: 1
Training loss: 3.0938526483326134
Validation loss: 2.6527732443266547

Epoch: 6| Step: 2
Training loss: 3.0559518056234882
Validation loss: 2.6275845103549678

Epoch: 6| Step: 3
Training loss: 3.41778138437344
Validation loss: 2.624232584809962

Epoch: 6| Step: 4
Training loss: 2.284942043078614
Validation loss: 2.6231208126066132

Epoch: 6| Step: 5
Training loss: 2.757485864763872
Validation loss: 2.622969648379035

Epoch: 6| Step: 6
Training loss: 2.265525868318871
Validation loss: 2.6212990449654865

Epoch: 6| Step: 7
Training loss: 3.3340209887415435
Validation loss: 2.6208892566929065

Epoch: 6| Step: 8
Training loss: 2.9664840884943304
Validation loss: 2.6216468460376503

Epoch: 6| Step: 9
Training loss: 3.6510046477715306
Validation loss: 2.623588796976661

Epoch: 6| Step: 10
Training loss: 2.6494748944822444
Validation loss: 2.6190517348329196

Epoch: 6| Step: 11
Training loss: 2.7930364427166032
Validation loss: 2.619706466706021

Epoch: 6| Step: 12
Training loss: 2.91829376249066
Validation loss: 2.6190083071213155

Epoch: 6| Step: 13
Training loss: 3.4373395015354418
Validation loss: 2.618211226973631

Epoch: 96| Step: 0
Training loss: 3.4067740780892155
Validation loss: 2.620585901955146

Epoch: 6| Step: 1
Training loss: 2.6336067427974146
Validation loss: 2.6249600205743877

Epoch: 6| Step: 2
Training loss: 3.364231591198613
Validation loss: 2.6206493625415432

Epoch: 6| Step: 3
Training loss: 2.806447021772698
Validation loss: 2.6258982338941435

Epoch: 6| Step: 4
Training loss: 2.86373385694159
Validation loss: 2.627795295167269

Epoch: 6| Step: 5
Training loss: 2.8433091377340887
Validation loss: 2.628047303320876

Epoch: 6| Step: 6
Training loss: 2.8102699763702224
Validation loss: 2.6290391043286943

Epoch: 6| Step: 7
Training loss: 2.8570931089702336
Validation loss: 2.629628377252767

Epoch: 6| Step: 8
Training loss: 3.2878267771252543
Validation loss: 2.6339249389372315

Epoch: 6| Step: 9
Training loss: 2.5602899650923883
Validation loss: 2.6271057550557755

Epoch: 6| Step: 10
Training loss: 3.3486020544847244
Validation loss: 2.620886675335853

Epoch: 6| Step: 11
Training loss: 3.2470372707435398
Validation loss: 2.6212255919329785

Epoch: 6| Step: 12
Training loss: 2.7413671413011724
Validation loss: 2.6160285162600934

Epoch: 6| Step: 13
Training loss: 2.5291823431175438
Validation loss: 2.616165927093312

Epoch: 97| Step: 0
Training loss: 2.538501102299251
Validation loss: 2.615255705628438

Epoch: 6| Step: 1
Training loss: 3.184636943252268
Validation loss: 2.637037991939872

Epoch: 6| Step: 2
Training loss: 3.0673531206279425
Validation loss: 2.668645918012651

Epoch: 6| Step: 3
Training loss: 3.2602869237530787
Validation loss: 2.7769977028679738

Epoch: 6| Step: 4
Training loss: 2.8682762802038577
Validation loss: 2.7426093782304193

Epoch: 6| Step: 5
Training loss: 2.8512061327511886
Validation loss: 2.737630787368547

Epoch: 6| Step: 6
Training loss: 2.732810308456633
Validation loss: 2.6968786539393723

Epoch: 6| Step: 7
Training loss: 3.249849756142582
Validation loss: 2.662760610505471

Epoch: 6| Step: 8
Training loss: 2.503739326138153
Validation loss: 2.630363282560001

Epoch: 6| Step: 9
Training loss: 2.51045700821707
Validation loss: 2.617275537642593

Epoch: 6| Step: 10
Training loss: 3.4024749275085364
Validation loss: 2.6162570063922055

Epoch: 6| Step: 11
Training loss: 3.2412534540277886
Validation loss: 2.617773887047497

Epoch: 6| Step: 12
Training loss: 3.0393607574260972
Validation loss: 2.6204012078486976

Epoch: 6| Step: 13
Training loss: 3.0889616622249942
Validation loss: 2.6254486251439886

Epoch: 98| Step: 0
Training loss: 3.0701174297923597
Validation loss: 2.6293989494259877

Epoch: 6| Step: 1
Training loss: 2.869556082709729
Validation loss: 2.6299599530955393

Epoch: 6| Step: 2
Training loss: 2.3476842792887904
Validation loss: 2.625709133199663

Epoch: 6| Step: 3
Training loss: 3.0309580239536063
Validation loss: 2.6283839935016577

Epoch: 6| Step: 4
Training loss: 3.1314603022995406
Validation loss: 2.6271722676175244

Epoch: 6| Step: 5
Training loss: 2.521921653268759
Validation loss: 2.624061156799633

Epoch: 6| Step: 6
Training loss: 3.1012805262842575
Validation loss: 2.6232662667337805

Epoch: 6| Step: 7
Training loss: 2.381934432542209
Validation loss: 2.616607634102708

Epoch: 6| Step: 8
Training loss: 2.8495303921542137
Validation loss: 2.61647378994311

Epoch: 6| Step: 9
Training loss: 3.7772859334219255
Validation loss: 2.614396317088487

Epoch: 6| Step: 10
Training loss: 2.846429254368018
Validation loss: 2.6149437053028395

Epoch: 6| Step: 11
Training loss: 3.356723608489246
Validation loss: 2.6149962247559584

Epoch: 6| Step: 12
Training loss: 3.438445360063269
Validation loss: 2.6106263431215853

Epoch: 6| Step: 13
Training loss: 2.4364837092828235
Validation loss: 2.608675013919466

Epoch: 99| Step: 0
Training loss: 3.176348908801093
Validation loss: 2.6094790948740685

Epoch: 6| Step: 1
Training loss: 2.976888964113893
Validation loss: 2.6077091970815225

Epoch: 6| Step: 2
Training loss: 2.91818183417092
Validation loss: 2.6209334152094126

Epoch: 6| Step: 3
Training loss: 3.188041491421558
Validation loss: 2.641678742282521

Epoch: 6| Step: 4
Training loss: 2.2337340389251428
Validation loss: 2.656645921110029

Epoch: 6| Step: 5
Training loss: 3.2904228242530964
Validation loss: 2.6938507201338515

Epoch: 6| Step: 6
Training loss: 3.225163708457308
Validation loss: 2.6223247444428575

Epoch: 6| Step: 7
Training loss: 2.8972807269855494
Validation loss: 2.604449180455484

Epoch: 6| Step: 8
Training loss: 3.4331000171629484
Validation loss: 2.6042787497406157

Epoch: 6| Step: 9
Training loss: 2.394460057854056
Validation loss: 2.6063832657335886

Epoch: 6| Step: 10
Training loss: 2.408567031380551
Validation loss: 2.608480013983718

Epoch: 6| Step: 11
Training loss: 3.234240100645821
Validation loss: 2.610356657658379

Epoch: 6| Step: 12
Training loss: 3.015968737999263
Validation loss: 2.609835137037909

Epoch: 6| Step: 13
Training loss: 2.718132211934809
Validation loss: 2.6091395298825226

Epoch: 100| Step: 0
Training loss: 2.3373570036370506
Validation loss: 2.610816239715406

Epoch: 6| Step: 1
Training loss: 2.633533050914917
Validation loss: 2.6090576497641282

Epoch: 6| Step: 2
Training loss: 3.4289007653144505
Validation loss: 2.6103939802741594

Epoch: 6| Step: 3
Training loss: 3.09977320795165
Validation loss: 2.60955532276922

Epoch: 6| Step: 4
Training loss: 2.77142312410294
Validation loss: 2.60878076996688

Epoch: 6| Step: 5
Training loss: 2.616782085845561
Validation loss: 2.609284483187202

Epoch: 6| Step: 6
Training loss: 2.839737629121059
Validation loss: 2.6045037728613667

Epoch: 6| Step: 7
Training loss: 2.831503857143334
Validation loss: 2.603602460879899

Epoch: 6| Step: 8
Training loss: 2.9882718354120485
Validation loss: 2.6018786598082815

Epoch: 6| Step: 9
Training loss: 3.6785280381181926
Validation loss: 2.602289518712584

Epoch: 6| Step: 10
Training loss: 3.2816158998927207
Validation loss: 2.6108173492968687

Epoch: 6| Step: 11
Training loss: 2.7281601386849657
Validation loss: 2.611439803188816

Epoch: 6| Step: 12
Training loss: 3.4679682770084437
Validation loss: 2.6239846400241684

Epoch: 6| Step: 13
Training loss: 2.0086418843446077
Validation loss: 2.64326159214216

Epoch: 101| Step: 0
Training loss: 3.020218113481695
Validation loss: 2.6859239629793192

Epoch: 6| Step: 1
Training loss: 3.6972173898233662
Validation loss: 2.692108329908825

Epoch: 6| Step: 2
Training loss: 2.992804162447109
Validation loss: 2.6392053063251146

Epoch: 6| Step: 3
Training loss: 3.1852741323499574
Validation loss: 2.6045601781687306

Epoch: 6| Step: 4
Training loss: 2.894878495323344
Validation loss: 2.597334118950896

Epoch: 6| Step: 5
Training loss: 2.9970750855289463
Validation loss: 2.6039460598605455

Epoch: 6| Step: 6
Training loss: 2.7439718934446393
Validation loss: 2.6085339107355683

Epoch: 6| Step: 7
Training loss: 2.613813269135384
Validation loss: 2.6115809741642284

Epoch: 6| Step: 8
Training loss: 2.9547292398765483
Validation loss: 2.6144444879358755

Epoch: 6| Step: 9
Training loss: 2.705810976428533
Validation loss: 2.607225160889207

Epoch: 6| Step: 10
Training loss: 2.874894513392581
Validation loss: 2.6047654721495666

Epoch: 6| Step: 11
Training loss: 3.163621810552753
Validation loss: 2.6022821389575284

Epoch: 6| Step: 12
Training loss: 2.9737625369384544
Validation loss: 2.5964185634511376

Epoch: 6| Step: 13
Training loss: 2.7414524582158926
Validation loss: 2.596953452719127

Epoch: 102| Step: 0
Training loss: 2.458776100070586
Validation loss: 2.6008031381629033

Epoch: 6| Step: 1
Training loss: 3.2930925556408357
Validation loss: 2.5991750953066135

Epoch: 6| Step: 2
Training loss: 3.2491119345195094
Validation loss: 2.6057982094022254

Epoch: 6| Step: 3
Training loss: 2.8828803160426166
Validation loss: 2.596373685355977

Epoch: 6| Step: 4
Training loss: 2.8408758709439117
Validation loss: 2.6017888635925837

Epoch: 6| Step: 5
Training loss: 2.781224197096556
Validation loss: 2.6015589396627203

Epoch: 6| Step: 6
Training loss: 2.6619871227603533
Validation loss: 2.609964841597126

Epoch: 6| Step: 7
Training loss: 2.854842131570747
Validation loss: 2.606157498918951

Epoch: 6| Step: 8
Training loss: 2.6996608874385553
Validation loss: 2.6117436205018705

Epoch: 6| Step: 9
Training loss: 3.3015228341315455
Validation loss: 2.621359752875325

Epoch: 6| Step: 10
Training loss: 3.3462492257175396
Validation loss: 2.6346875275267436

Epoch: 6| Step: 11
Training loss: 2.7241499318608224
Validation loss: 2.6182356460636584

Epoch: 6| Step: 12
Training loss: 3.10755997787867
Validation loss: 2.5951538596150154

Epoch: 6| Step: 13
Training loss: 2.728383502751389
Validation loss: 2.59587589639138

Epoch: 103| Step: 0
Training loss: 2.52560709462926
Validation loss: 2.5920116699278997

Epoch: 6| Step: 1
Training loss: 3.154440030371857
Validation loss: 2.5879552498857405

Epoch: 6| Step: 2
Training loss: 3.4346851267861536
Validation loss: 2.5929850490466757

Epoch: 6| Step: 3
Training loss: 2.7576653546637937
Validation loss: 2.5883575041834157

Epoch: 6| Step: 4
Training loss: 2.7908451143025417
Validation loss: 2.5901765805154215

Epoch: 6| Step: 5
Training loss: 2.98173462069759
Validation loss: 2.589018917962701

Epoch: 6| Step: 6
Training loss: 3.6290804818070126
Validation loss: 2.5882931003124887

Epoch: 6| Step: 7
Training loss: 2.444578700520965
Validation loss: 2.5866125400708553

Epoch: 6| Step: 8
Training loss: 2.787007063315714
Validation loss: 2.5858695084443304

Epoch: 6| Step: 9
Training loss: 2.4688179875923164
Validation loss: 2.586434237577835

Epoch: 6| Step: 10
Training loss: 3.1439397978321053
Validation loss: 2.5880635930258014

Epoch: 6| Step: 11
Training loss: 3.081892003151927
Validation loss: 2.589191186831185

Epoch: 6| Step: 12
Training loss: 2.6999810959895947
Validation loss: 2.5905801524242658

Epoch: 6| Step: 13
Training loss: 2.937403738189623
Validation loss: 2.6007455818523644

Epoch: 104| Step: 0
Training loss: 3.048060416436343
Validation loss: 2.6122371839899086

Epoch: 6| Step: 1
Training loss: 3.1240209953296176
Validation loss: 2.6068036877202463

Epoch: 6| Step: 2
Training loss: 2.817168705306829
Validation loss: 2.6028986856708096

Epoch: 6| Step: 3
Training loss: 2.2597601386871604
Validation loss: 2.5926987511359747

Epoch: 6| Step: 4
Training loss: 3.0250328251342413
Validation loss: 2.5833199494405843

Epoch: 6| Step: 5
Training loss: 3.1230111468992914
Validation loss: 2.584501887055234

Epoch: 6| Step: 6
Training loss: 3.43232698475443
Validation loss: 2.5825017962905994

Epoch: 6| Step: 7
Training loss: 2.7643000128155504
Validation loss: 2.5829649926276894

Epoch: 6| Step: 8
Training loss: 2.5794717681162056
Validation loss: 2.57989856004166

Epoch: 6| Step: 9
Training loss: 3.1702227117722073
Validation loss: 2.581250140395634

Epoch: 6| Step: 10
Training loss: 2.9454675932101795
Validation loss: 2.5801206499866147

Epoch: 6| Step: 11
Training loss: 2.534763864207086
Validation loss: 2.5809650239896915

Epoch: 6| Step: 12
Training loss: 3.3887458903119962
Validation loss: 2.5829711293625137

Epoch: 6| Step: 13
Training loss: 2.606259707791844
Validation loss: 2.5830384855947686

Epoch: 105| Step: 0
Training loss: 3.00444496195536
Validation loss: 2.5797720879741277

Epoch: 6| Step: 1
Training loss: 3.0016640180808722
Validation loss: 2.579559975893267

Epoch: 6| Step: 2
Training loss: 3.084047922031722
Validation loss: 2.5800424624124734

Epoch: 6| Step: 3
Training loss: 2.888319591116053
Validation loss: 2.5795526980757195

Epoch: 6| Step: 4
Training loss: 2.847958981679358
Validation loss: 2.5795505002164996

Epoch: 6| Step: 5
Training loss: 2.787528420205062
Validation loss: 2.5817823246139873

Epoch: 6| Step: 6
Training loss: 3.448109293893788
Validation loss: 2.589850922677626

Epoch: 6| Step: 7
Training loss: 3.182477397254096
Validation loss: 2.592249214093277

Epoch: 6| Step: 8
Training loss: 2.7846499460363865
Validation loss: 2.597950961684141

Epoch: 6| Step: 9
Training loss: 3.195212066489689
Validation loss: 2.5890825760014655

Epoch: 6| Step: 10
Training loss: 2.5799788774320627
Validation loss: 2.5894908833846655

Epoch: 6| Step: 11
Training loss: 2.6260415690168712
Validation loss: 2.5764458362217013

Epoch: 6| Step: 12
Training loss: 2.80378245252858
Validation loss: 2.576620025242342

Epoch: 6| Step: 13
Training loss: 2.7263010331405484
Validation loss: 2.576219012157208

Epoch: 106| Step: 0
Training loss: 3.335161820221836
Validation loss: 2.579695025722411

Epoch: 6| Step: 1
Training loss: 3.3454454348368476
Validation loss: 2.5802785351813706

Epoch: 6| Step: 2
Training loss: 2.4785142782822387
Validation loss: 2.5785948383970045

Epoch: 6| Step: 3
Training loss: 2.8123972556102843
Validation loss: 2.5798373763223714

Epoch: 6| Step: 4
Training loss: 3.0462179404705645
Validation loss: 2.5782074916018614

Epoch: 6| Step: 5
Training loss: 2.572051228340858
Validation loss: 2.580995852473792

Epoch: 6| Step: 6
Training loss: 2.7283387614922265
Validation loss: 2.575803566857085

Epoch: 6| Step: 7
Training loss: 3.002839651851468
Validation loss: 2.5838553049844557

Epoch: 6| Step: 8
Training loss: 3.266899480762643
Validation loss: 2.5886690416233606

Epoch: 6| Step: 9
Training loss: 2.787193035107833
Validation loss: 2.598537823286735

Epoch: 6| Step: 10
Training loss: 2.8153339095798957
Validation loss: 2.60373494234626

Epoch: 6| Step: 11
Training loss: 2.5155455772230457
Validation loss: 2.6186122238462954

Epoch: 6| Step: 12
Training loss: 3.2586706847037576
Validation loss: 2.632208474588088

Epoch: 6| Step: 13
Training loss: 2.97015973801473
Validation loss: 2.6433812500423164

Epoch: 107| Step: 0
Training loss: 2.5054528849961533
Validation loss: 2.6212281172085414

Epoch: 6| Step: 1
Training loss: 3.138513263143823
Validation loss: 2.6171145535966285

Epoch: 6| Step: 2
Training loss: 2.46360822806789
Validation loss: 2.6002314091870833

Epoch: 6| Step: 3
Training loss: 3.096324273497986
Validation loss: 2.5974108957372635

Epoch: 6| Step: 4
Training loss: 2.6873374712391764
Validation loss: 2.5819810913291588

Epoch: 6| Step: 5
Training loss: 2.915971636839602
Validation loss: 2.5763703591133575

Epoch: 6| Step: 6
Training loss: 2.158424386812669
Validation loss: 2.571758696366887

Epoch: 6| Step: 7
Training loss: 2.986206770752077
Validation loss: 2.571595664442178

Epoch: 6| Step: 8
Training loss: 2.6668872344668615
Validation loss: 2.5730632334869754

Epoch: 6| Step: 9
Training loss: 3.42414439297083
Validation loss: 2.5772936999975884

Epoch: 6| Step: 10
Training loss: 3.0500987677919764
Validation loss: 2.5758694743186674

Epoch: 6| Step: 11
Training loss: 3.4406413203518467
Validation loss: 2.5792462279628685

Epoch: 6| Step: 12
Training loss: 3.141541152861842
Validation loss: 2.577281321889235

Epoch: 6| Step: 13
Training loss: 3.0148493110109214
Validation loss: 2.576593143201788

Epoch: 108| Step: 0
Training loss: 3.3450500242772145
Validation loss: 2.5751657764528373

Epoch: 6| Step: 1
Training loss: 2.7184940963100073
Validation loss: 2.583396749746842

Epoch: 6| Step: 2
Training loss: 2.559334823796099
Validation loss: 2.5957310219515324

Epoch: 6| Step: 3
Training loss: 2.748996725003431
Validation loss: 2.599676613736176

Epoch: 6| Step: 4
Training loss: 2.8302115651770823
Validation loss: 2.600828642327982

Epoch: 6| Step: 5
Training loss: 3.068394340835542
Validation loss: 2.5876313722152386

Epoch: 6| Step: 6
Training loss: 3.2706571073904303
Validation loss: 2.578167228067011

Epoch: 6| Step: 7
Training loss: 2.989651314807608
Validation loss: 2.5755417974309736

Epoch: 6| Step: 8
Training loss: 3.0502033541067077
Validation loss: 2.5735073307531224

Epoch: 6| Step: 9
Training loss: 2.355080542513324
Validation loss: 2.571038683260725

Epoch: 6| Step: 10
Training loss: 3.1970935139037624
Validation loss: 2.5710547498460943

Epoch: 6| Step: 11
Training loss: 2.8527401517297393
Validation loss: 2.5687941249188073

Epoch: 6| Step: 12
Training loss: 2.7924079385333953
Validation loss: 2.5694494158885086

Epoch: 6| Step: 13
Training loss: 2.8895873810717547
Validation loss: 2.567691085974826

Epoch: 109| Step: 0
Training loss: 2.708521225109317
Validation loss: 2.568498892402309

Epoch: 6| Step: 1
Training loss: 3.2264294908647058
Validation loss: 2.5690827374972742

Epoch: 6| Step: 2
Training loss: 2.8708708592265944
Validation loss: 2.5727628758490346

Epoch: 6| Step: 3
Training loss: 2.4877816122318075
Validation loss: 2.5701051412642286

Epoch: 6| Step: 4
Training loss: 2.246297969656173
Validation loss: 2.5683587780986112

Epoch: 6| Step: 5
Training loss: 3.0048109262302307
Validation loss: 2.569148460138658

Epoch: 6| Step: 6
Training loss: 2.975958334815708
Validation loss: 2.5675817044598173

Epoch: 6| Step: 7
Training loss: 3.1845902270057334
Validation loss: 2.567135611424097

Epoch: 6| Step: 8
Training loss: 2.989952427922597
Validation loss: 2.5698982665748833

Epoch: 6| Step: 9
Training loss: 2.823937366444814
Validation loss: 2.5728346594155167

Epoch: 6| Step: 10
Training loss: 2.6839271571512144
Validation loss: 2.5747486044550247

Epoch: 6| Step: 11
Training loss: 3.3001143464593814
Validation loss: 2.582501525284426

Epoch: 6| Step: 12
Training loss: 3.4943105230931204
Validation loss: 2.578926679229437

Epoch: 6| Step: 13
Training loss: 2.5107408580680066
Validation loss: 2.575646625644828

Epoch: 110| Step: 0
Training loss: 2.541387813675971
Validation loss: 2.5676954980002047

Epoch: 6| Step: 1
Training loss: 3.070586447105893
Validation loss: 2.5635854111555316

Epoch: 6| Step: 2
Training loss: 2.538996581175562
Validation loss: 2.562643690905202

Epoch: 6| Step: 3
Training loss: 2.65902564940145
Validation loss: 2.565848969614773

Epoch: 6| Step: 4
Training loss: 3.040735563834027
Validation loss: 2.563519564891493

Epoch: 6| Step: 5
Training loss: 3.1980514912136893
Validation loss: 2.5651559039421645

Epoch: 6| Step: 6
Training loss: 3.0352410853250062
Validation loss: 2.565222157925883

Epoch: 6| Step: 7
Training loss: 3.0672194259155745
Validation loss: 2.5637106867932626

Epoch: 6| Step: 8
Training loss: 3.0923619094399477
Validation loss: 2.562827791887747

Epoch: 6| Step: 9
Training loss: 2.657854111943919
Validation loss: 2.565835036578904

Epoch: 6| Step: 10
Training loss: 2.962500489311339
Validation loss: 2.5640497910998348

Epoch: 6| Step: 11
Training loss: 3.149076259742347
Validation loss: 2.5734827980548465

Epoch: 6| Step: 12
Training loss: 2.658489225912799
Validation loss: 2.586231434698247

Epoch: 6| Step: 13
Training loss: 3.2541023186163667
Validation loss: 2.601682094150818

Epoch: 111| Step: 0
Training loss: 3.2876129943226977
Validation loss: 2.609352281194107

Epoch: 6| Step: 1
Training loss: 2.907810735522621
Validation loss: 2.6414306454315786

Epoch: 6| Step: 2
Training loss: 2.631435226481125
Validation loss: 2.655721458628827

Epoch: 6| Step: 3
Training loss: 2.869312964159104
Validation loss: 2.6725474477316875

Epoch: 6| Step: 4
Training loss: 3.0119758624848583
Validation loss: 2.625561841069311

Epoch: 6| Step: 5
Training loss: 2.543406552835266
Validation loss: 2.6137637468504207

Epoch: 6| Step: 6
Training loss: 3.1060715192333825
Validation loss: 2.6118866016809386

Epoch: 6| Step: 7
Training loss: 3.170881444605299
Validation loss: 2.606290912835762

Epoch: 6| Step: 8
Training loss: 2.906215544465612
Validation loss: 2.6072055482492207

Epoch: 6| Step: 9
Training loss: 3.0686421983356498
Validation loss: 2.607781118750971

Epoch: 6| Step: 10
Training loss: 2.9480320848351997
Validation loss: 2.619586073824936

Epoch: 6| Step: 11
Training loss: 3.037602640309466
Validation loss: 2.630138037022517

Epoch: 6| Step: 12
Training loss: 3.163356221809294
Validation loss: 2.6286894404088312

Epoch: 6| Step: 13
Training loss: 2.5909869632547564
Validation loss: 2.6314162297721486

Epoch: 112| Step: 0
Training loss: 3.6261509350746657
Validation loss: 2.6176405118973127

Epoch: 6| Step: 1
Training loss: 2.45206656978282
Validation loss: 2.6061049036490775

Epoch: 6| Step: 2
Training loss: 3.3295173418951385
Validation loss: 2.5997478385703396

Epoch: 6| Step: 3
Training loss: 3.0572906095556007
Validation loss: 2.602011749255807

Epoch: 6| Step: 4
Training loss: 2.7452168916436324
Validation loss: 2.6035490036102

Epoch: 6| Step: 5
Training loss: 3.1079628963145884
Validation loss: 2.6114262901051117

Epoch: 6| Step: 6
Training loss: 2.6705517978040865
Validation loss: 2.6287731744079443

Epoch: 6| Step: 7
Training loss: 2.7854043173296286
Validation loss: 2.6304371236693798

Epoch: 6| Step: 8
Training loss: 2.4595958140415934
Validation loss: 2.660484094393482

Epoch: 6| Step: 9
Training loss: 3.381540953692056
Validation loss: 2.6555446346914406

Epoch: 6| Step: 10
Training loss: 3.1440900978884394
Validation loss: 2.6171744524906475

Epoch: 6| Step: 11
Training loss: 2.8101814037699997
Validation loss: 2.5972914464332333

Epoch: 6| Step: 12
Training loss: 2.562508187629831
Validation loss: 2.597375548119774

Epoch: 6| Step: 13
Training loss: 2.8262812890501903
Validation loss: 2.5972021193997925

Epoch: 113| Step: 0
Training loss: 2.7224783928244043
Validation loss: 2.6004365135335767

Epoch: 6| Step: 1
Training loss: 2.461249825171004
Validation loss: 2.596341443325588

Epoch: 6| Step: 2
Training loss: 2.8089748755336696
Validation loss: 2.5968164582119657

Epoch: 6| Step: 3
Training loss: 2.7159263592878777
Validation loss: 2.59325526085831

Epoch: 6| Step: 4
Training loss: 2.717531830180996
Validation loss: 2.5985292381364777

Epoch: 6| Step: 5
Training loss: 2.697165827800551
Validation loss: 2.592654935400074

Epoch: 6| Step: 6
Training loss: 3.290065875104086
Validation loss: 2.6009900045397956

Epoch: 6| Step: 7
Training loss: 2.756303066166675
Validation loss: 2.6031634170649354

Epoch: 6| Step: 8
Training loss: 3.137904113033924
Validation loss: 2.60597918399296

Epoch: 6| Step: 9
Training loss: 3.1116337072353053
Validation loss: 2.6082298158669968

Epoch: 6| Step: 10
Training loss: 3.189886658188633
Validation loss: 2.6097834587140163

Epoch: 6| Step: 11
Training loss: 3.1769059595509086
Validation loss: 2.6110661899953054

Epoch: 6| Step: 12
Training loss: 3.2087424541722
Validation loss: 2.611686860885126

Epoch: 6| Step: 13
Training loss: 3.04584881056277
Validation loss: 2.596542577841378

Epoch: 114| Step: 0
Training loss: 3.0969987245975243
Validation loss: 2.6002428045165273

Epoch: 6| Step: 1
Training loss: 3.2310856849314815
Validation loss: 2.6077912207951783

Epoch: 6| Step: 2
Training loss: 2.9529465717322707
Validation loss: 2.600595113249432

Epoch: 6| Step: 3
Training loss: 3.3578050360368126
Validation loss: 2.593013457712789

Epoch: 6| Step: 4
Training loss: 2.1764203268200197
Validation loss: 2.5868610957989535

Epoch: 6| Step: 5
Training loss: 3.1407980800022313
Validation loss: 2.5842780358387536

Epoch: 6| Step: 6
Training loss: 2.864153595103659
Validation loss: 2.5847610341852607

Epoch: 6| Step: 7
Training loss: 2.7360796165482504
Validation loss: 2.5883806261529374

Epoch: 6| Step: 8
Training loss: 3.229710260393162
Validation loss: 2.5819276679668097

Epoch: 6| Step: 9
Training loss: 2.9582213976104414
Validation loss: 2.578483699283514

Epoch: 6| Step: 10
Training loss: 1.9588544503938414
Validation loss: 2.5784733322857893

Epoch: 6| Step: 11
Training loss: 2.698323654839176
Validation loss: 2.5780054431985646

Epoch: 6| Step: 12
Training loss: 3.41865115955583
Validation loss: 2.5713635791024037

Epoch: 6| Step: 13
Training loss: 3.1316411975138245
Validation loss: 2.5807246640095336

Epoch: 115| Step: 0
Training loss: 3.5266601981648744
Validation loss: 2.57533126016081

Epoch: 6| Step: 1
Training loss: 2.5318924830239657
Validation loss: 2.577355159946419

Epoch: 6| Step: 2
Training loss: 3.0211445790570695
Validation loss: 2.5740823053679365

Epoch: 6| Step: 3
Training loss: 2.841201478650389
Validation loss: 2.5711970663129917

Epoch: 6| Step: 4
Training loss: 3.1333065261776265
Validation loss: 2.5680211831824957

Epoch: 6| Step: 5
Training loss: 2.575830721879037
Validation loss: 2.5642643648741923

Epoch: 6| Step: 6
Training loss: 2.874947754758394
Validation loss: 2.5694233777543296

Epoch: 6| Step: 7
Training loss: 2.5847085758235946
Validation loss: 2.57355589936681

Epoch: 6| Step: 8
Training loss: 3.293979620846752
Validation loss: 2.5960606842064804

Epoch: 6| Step: 9
Training loss: 2.9929516964324256
Validation loss: 2.5902914430139297

Epoch: 6| Step: 10
Training loss: 2.9079332296899394
Validation loss: 2.5894176478032347

Epoch: 6| Step: 11
Training loss: 2.2645235738674843
Validation loss: 2.6044913941420176

Epoch: 6| Step: 12
Training loss: 3.195595875604909
Validation loss: 2.5873673642273225

Epoch: 6| Step: 13
Training loss: 2.859213735900315
Validation loss: 2.5808143368638543

Epoch: 116| Step: 0
Training loss: 2.2492871744786003
Validation loss: 2.565670650018548

Epoch: 6| Step: 1
Training loss: 2.721840077996275
Validation loss: 2.5593798610436704

Epoch: 6| Step: 2
Training loss: 2.46030449370636
Validation loss: 2.5577838316255272

Epoch: 6| Step: 3
Training loss: 3.4339278647700704
Validation loss: 2.566114735906563

Epoch: 6| Step: 4
Training loss: 3.1690044473970165
Validation loss: 2.568315064177331

Epoch: 6| Step: 5
Training loss: 3.214741405095555
Validation loss: 2.5588663000650604

Epoch: 6| Step: 6
Training loss: 3.1768076459163894
Validation loss: 2.556885982205723

Epoch: 6| Step: 7
Training loss: 2.732725070712982
Validation loss: 2.560386678672475

Epoch: 6| Step: 8
Training loss: 3.274973361074418
Validation loss: 2.5591621679947405

Epoch: 6| Step: 9
Training loss: 2.8380663739239522
Validation loss: 2.573726563616631

Epoch: 6| Step: 10
Training loss: 2.8997968997209695
Validation loss: 2.5968652888346067

Epoch: 6| Step: 11
Training loss: 2.897367295261742
Validation loss: 2.602578446617538

Epoch: 6| Step: 12
Training loss: 2.876418883112383
Validation loss: 2.6224357769025675

Epoch: 6| Step: 13
Training loss: 2.4871857296040725
Validation loss: 2.635702690048601

Epoch: 117| Step: 0
Training loss: 2.3450333197205033
Validation loss: 2.612449926402912

Epoch: 6| Step: 1
Training loss: 2.5096896267676363
Validation loss: 2.6120126043011602

Epoch: 6| Step: 2
Training loss: 2.694447077152325
Validation loss: 2.594040051998235

Epoch: 6| Step: 3
Training loss: 3.181155454058821
Validation loss: 2.596152637704496

Epoch: 6| Step: 4
Training loss: 2.421402128262497
Validation loss: 2.5744634526274788

Epoch: 6| Step: 5
Training loss: 2.451270890990644
Validation loss: 2.571297846279214

Epoch: 6| Step: 6
Training loss: 3.057573365074418
Validation loss: 2.5654442243141826

Epoch: 6| Step: 7
Training loss: 2.94647647108636
Validation loss: 2.5591531261835017

Epoch: 6| Step: 8
Training loss: 3.3852161211133196
Validation loss: 2.5601226289232755

Epoch: 6| Step: 9
Training loss: 3.1712579737748343
Validation loss: 2.555683727611075

Epoch: 6| Step: 10
Training loss: 3.5319267232169227
Validation loss: 2.558692449403645

Epoch: 6| Step: 11
Training loss: 3.0376896049442457
Validation loss: 2.553339544087529

Epoch: 6| Step: 12
Training loss: 2.5895738187713846
Validation loss: 2.549446088061437

Epoch: 6| Step: 13
Training loss: 2.8767156043223765
Validation loss: 2.5509111281873804

Epoch: 118| Step: 0
Training loss: 3.0971874830030237
Validation loss: 2.5516750405043176

Epoch: 6| Step: 1
Training loss: 2.319868565486591
Validation loss: 2.5511560275137133

Epoch: 6| Step: 2
Training loss: 2.941295039087036
Validation loss: 2.548289403708254

Epoch: 6| Step: 3
Training loss: 2.5160603590792063
Validation loss: 2.551138778454934

Epoch: 6| Step: 4
Training loss: 2.389672582057734
Validation loss: 2.5478116393082715

Epoch: 6| Step: 5
Training loss: 2.617023246507377
Validation loss: 2.547015536223393

Epoch: 6| Step: 6
Training loss: 3.0237104898862173
Validation loss: 2.5504407494147725

Epoch: 6| Step: 7
Training loss: 2.312278324534022
Validation loss: 2.562051996525771

Epoch: 6| Step: 8
Training loss: 3.8549621311014928
Validation loss: 2.5704402473551653

Epoch: 6| Step: 9
Training loss: 2.4729200466511054
Validation loss: 2.5797677164776056

Epoch: 6| Step: 10
Training loss: 3.4256440051434978
Validation loss: 2.5975321950195074

Epoch: 6| Step: 11
Training loss: 3.391456466897063
Validation loss: 2.6201744709164316

Epoch: 6| Step: 12
Training loss: 3.0260714312264287
Validation loss: 2.579047752455471

Epoch: 6| Step: 13
Training loss: 2.872023658931266
Validation loss: 2.5594421778569076

Epoch: 119| Step: 0
Training loss: 3.104680029558199
Validation loss: 2.5499210971188213

Epoch: 6| Step: 1
Training loss: 2.9569120798827853
Validation loss: 2.5469270649645117

Epoch: 6| Step: 2
Training loss: 2.882855836289277
Validation loss: 2.5459406734546217

Epoch: 6| Step: 3
Training loss: 3.5113140887193035
Validation loss: 2.5464778197630085

Epoch: 6| Step: 4
Training loss: 3.7509202463798332
Validation loss: 2.54490048472686

Epoch: 6| Step: 5
Training loss: 3.0446056815963365
Validation loss: 2.5477723941920183

Epoch: 6| Step: 6
Training loss: 2.272878361794988
Validation loss: 2.552947114209954

Epoch: 6| Step: 7
Training loss: 2.748459471180479
Validation loss: 2.5535521134100496

Epoch: 6| Step: 8
Training loss: 2.5080851469051
Validation loss: 2.5585502509970848

Epoch: 6| Step: 9
Training loss: 2.2089757404782615
Validation loss: 2.5696727511201876

Epoch: 6| Step: 10
Training loss: 2.5669574581079133
Validation loss: 2.5601319206572026

Epoch: 6| Step: 11
Training loss: 2.9119721552387383
Validation loss: 2.5596280615384086

Epoch: 6| Step: 12
Training loss: 3.002660842894377
Validation loss: 2.5571591814712638

Epoch: 6| Step: 13
Training loss: 2.6166878750016527
Validation loss: 2.5516802246958905

Epoch: 120| Step: 0
Training loss: 2.6765556161661697
Validation loss: 2.545985993957158

Epoch: 6| Step: 1
Training loss: 2.3292645219458867
Validation loss: 2.538485810297451

Epoch: 6| Step: 2
Training loss: 3.355535255634582
Validation loss: 2.5402743972542354

Epoch: 6| Step: 3
Training loss: 2.928475497997312
Validation loss: 2.541146161707987

Epoch: 6| Step: 4
Training loss: 2.7094287906573715
Validation loss: 2.539009888058938

Epoch: 6| Step: 5
Training loss: 3.1162481207139967
Validation loss: 2.540058570017291

Epoch: 6| Step: 6
Training loss: 2.8859864004109466
Validation loss: 2.5434356321853397

Epoch: 6| Step: 7
Training loss: 2.3835580128579164
Validation loss: 2.5447378799329754

Epoch: 6| Step: 8
Training loss: 3.0456975764867056
Validation loss: 2.547445288125603

Epoch: 6| Step: 9
Training loss: 2.719704822063018
Validation loss: 2.5549891707913672

Epoch: 6| Step: 10
Training loss: 3.1707706126068147
Validation loss: 2.5560872482822967

Epoch: 6| Step: 11
Training loss: 2.202315594404207
Validation loss: 2.5596666376269206

Epoch: 6| Step: 12
Training loss: 3.500560579366112
Validation loss: 2.5661603005284563

Epoch: 6| Step: 13
Training loss: 3.3834466141651713
Validation loss: 2.5637868415812224

Epoch: 121| Step: 0
Training loss: 3.1794934412718674
Validation loss: 2.5615668279670785

Epoch: 6| Step: 1
Training loss: 2.5031638153152724
Validation loss: 2.547777336277425

Epoch: 6| Step: 2
Training loss: 2.819732014523371
Validation loss: 2.554189981213209

Epoch: 6| Step: 3
Training loss: 2.8237797355014975
Validation loss: 2.541455358082718

Epoch: 6| Step: 4
Training loss: 2.7777461579960323
Validation loss: 2.5481606132684376

Epoch: 6| Step: 5
Training loss: 2.6550898991826433
Validation loss: 2.545070866552

Epoch: 6| Step: 6
Training loss: 3.128766498468832
Validation loss: 2.5420974189584586

Epoch: 6| Step: 7
Training loss: 2.6184693798396723
Validation loss: 2.548997236535168

Epoch: 6| Step: 8
Training loss: 2.43119328685209
Validation loss: 2.5500071079702797

Epoch: 6| Step: 9
Training loss: 2.8979988691644984
Validation loss: 2.549750719667997

Epoch: 6| Step: 10
Training loss: 3.178029070731428
Validation loss: 2.5512317551794728

Epoch: 6| Step: 11
Training loss: 3.2733661215927574
Validation loss: 2.5515151884233833

Epoch: 6| Step: 12
Training loss: 3.0653803767637138
Validation loss: 2.5433276488544445

Epoch: 6| Step: 13
Training loss: 3.039712007834981
Validation loss: 2.5412665149131572

Epoch: 122| Step: 0
Training loss: 2.6712772526151896
Validation loss: 2.5395191705174045

Epoch: 6| Step: 1
Training loss: 3.1149390962626047
Validation loss: 2.5362393463934265

Epoch: 6| Step: 2
Training loss: 2.5875452120604168
Validation loss: 2.5395301578746334

Epoch: 6| Step: 3
Training loss: 3.3215312561007018
Validation loss: 2.549736673526918

Epoch: 6| Step: 4
Training loss: 2.5755754290825097
Validation loss: 2.549558400460512

Epoch: 6| Step: 5
Training loss: 2.8456163255679545
Validation loss: 2.5434352491665986

Epoch: 6| Step: 6
Training loss: 2.924585074966665
Validation loss: 2.5402877519404035

Epoch: 6| Step: 7
Training loss: 2.779878085090918
Validation loss: 2.542044678216067

Epoch: 6| Step: 8
Training loss: 2.8865685946548973
Validation loss: 2.537438813207385

Epoch: 6| Step: 9
Training loss: 3.0450399497031375
Validation loss: 2.5421688209816216

Epoch: 6| Step: 10
Training loss: 2.7820572270993917
Validation loss: 2.542693494705304

Epoch: 6| Step: 11
Training loss: 3.0850284831062984
Validation loss: 2.544152586515863

Epoch: 6| Step: 12
Training loss: 2.740927208274523
Validation loss: 2.536639886244999

Epoch: 6| Step: 13
Training loss: 2.9004133127269216
Validation loss: 2.540592233461955

Epoch: 123| Step: 0
Training loss: 3.0340028827329153
Validation loss: 2.5372823169526626

Epoch: 6| Step: 1
Training loss: 2.9094240637226396
Validation loss: 2.5349091232857144

Epoch: 6| Step: 2
Training loss: 3.126624333705777
Validation loss: 2.535051370548314

Epoch: 6| Step: 3
Training loss: 2.2773977701837014
Validation loss: 2.5345136971265934

Epoch: 6| Step: 4
Training loss: 3.1282298372518684
Validation loss: 2.5367037632135476

Epoch: 6| Step: 5
Training loss: 2.556003616509543
Validation loss: 2.5385945802571155

Epoch: 6| Step: 6
Training loss: 2.543388460977567
Validation loss: 2.549331388418428

Epoch: 6| Step: 7
Training loss: 2.6441033381987418
Validation loss: 2.5670755426113434

Epoch: 6| Step: 8
Training loss: 3.064715148732602
Validation loss: 2.565675973797395

Epoch: 6| Step: 9
Training loss: 3.055522209524976
Validation loss: 2.568714635477968

Epoch: 6| Step: 10
Training loss: 3.042484974632055
Validation loss: 2.5767646300481264

Epoch: 6| Step: 11
Training loss: 2.0143449844174057
Validation loss: 2.5891240253173793

Epoch: 6| Step: 12
Training loss: 3.6857418459540936
Validation loss: 2.62715078783523

Epoch: 6| Step: 13
Training loss: 2.79804405628719
Validation loss: 2.6000170921697827

Epoch: 124| Step: 0
Training loss: 2.9971404752601076
Validation loss: 2.5932212673189916

Epoch: 6| Step: 1
Training loss: 3.1024119561526176
Validation loss: 2.5793418431436486

Epoch: 6| Step: 2
Training loss: 2.924402133451343
Validation loss: 2.5448576774493064

Epoch: 6| Step: 3
Training loss: 3.056107369119566
Validation loss: 2.5413142541115317

Epoch: 6| Step: 4
Training loss: 3.0609062874776507
Validation loss: 2.537315580741717

Epoch: 6| Step: 5
Training loss: 2.9567927436941868
Validation loss: 2.533155588165461

Epoch: 6| Step: 6
Training loss: 2.700738106610044
Validation loss: 2.529586830992173

Epoch: 6| Step: 7
Training loss: 2.084398709323903
Validation loss: 2.5322817106758166

Epoch: 6| Step: 8
Training loss: 3.0056913749043357
Validation loss: 2.5309699463305697

Epoch: 6| Step: 9
Training loss: 2.8592771086065216
Validation loss: 2.530866811925139

Epoch: 6| Step: 10
Training loss: 3.3015098354546084
Validation loss: 2.535318980924184

Epoch: 6| Step: 11
Training loss: 2.6256203599583254
Validation loss: 2.538171286852535

Epoch: 6| Step: 12
Training loss: 2.6391439403843866
Validation loss: 2.545082181486929

Epoch: 6| Step: 13
Training loss: 2.7641406197557483
Validation loss: 2.5466133011911825

Epoch: 125| Step: 0
Training loss: 2.8420153347087567
Validation loss: 2.5645960017369607

Epoch: 6| Step: 1
Training loss: 2.767845167846089
Validation loss: 2.589147082022832

Epoch: 6| Step: 2
Training loss: 2.48539549783121
Validation loss: 2.593267078318316

Epoch: 6| Step: 3
Training loss: 3.1846267615646315
Validation loss: 2.5822400794290954

Epoch: 6| Step: 4
Training loss: 2.8300146039174834
Validation loss: 2.5553084995355375

Epoch: 6| Step: 5
Training loss: 2.9604541716234545
Validation loss: 2.540583913649207

Epoch: 6| Step: 6
Training loss: 3.2259070074651857
Validation loss: 2.5331221078216695

Epoch: 6| Step: 7
Training loss: 3.285439278366145
Validation loss: 2.5262184212315475

Epoch: 6| Step: 8
Training loss: 2.9969925110563964
Validation loss: 2.5236648004601387

Epoch: 6| Step: 9
Training loss: 3.09189804596001
Validation loss: 2.5248928101736814

Epoch: 6| Step: 10
Training loss: 2.711088852408847
Validation loss: 2.5267116526272915

Epoch: 6| Step: 11
Training loss: 2.631025211400473
Validation loss: 2.5242493357032534

Epoch: 6| Step: 12
Training loss: 2.292223105644877
Validation loss: 2.5271444342728513

Epoch: 6| Step: 13
Training loss: 3.1535543884745185
Validation loss: 2.53389697300155

Epoch: 126| Step: 0
Training loss: 2.2488159667046372
Validation loss: 2.53895797880369

Epoch: 6| Step: 1
Training loss: 3.6304471098400803
Validation loss: 2.555718574530481

Epoch: 6| Step: 2
Training loss: 2.8751122825921436
Validation loss: 2.590818952913949

Epoch: 6| Step: 3
Training loss: 2.6970440154085407
Validation loss: 2.6408961919484937

Epoch: 6| Step: 4
Training loss: 3.0950330135328765
Validation loss: 2.6310306835604407

Epoch: 6| Step: 5
Training loss: 3.245043863667181
Validation loss: 2.605184261895726

Epoch: 6| Step: 6
Training loss: 3.441548824063178
Validation loss: 2.5661608310070227

Epoch: 6| Step: 7
Training loss: 3.1093165713240665
Validation loss: 2.5424815763921864

Epoch: 6| Step: 8
Training loss: 3.197992893432966
Validation loss: 2.5303933960197877

Epoch: 6| Step: 9
Training loss: 2.3907390891383327
Validation loss: 2.5243094374851616

Epoch: 6| Step: 10
Training loss: 2.3628044214855985
Validation loss: 2.5256558900822

Epoch: 6| Step: 11
Training loss: 2.40050961329119
Validation loss: 2.522499616508195

Epoch: 6| Step: 12
Training loss: 2.405354518971887
Validation loss: 2.523566252367679

Epoch: 6| Step: 13
Training loss: 2.836184320139073
Validation loss: 2.5228337874668507

Epoch: 127| Step: 0
Training loss: 3.0463600701696483
Validation loss: 2.526128384355785

Epoch: 6| Step: 1
Training loss: 2.68271094937049
Validation loss: 2.5260586622042984

Epoch: 6| Step: 2
Training loss: 2.8909581997573297
Validation loss: 2.5227825656295844

Epoch: 6| Step: 3
Training loss: 2.924538933043332
Validation loss: 2.5214903532996145

Epoch: 6| Step: 4
Training loss: 2.8811046638159996
Validation loss: 2.522508948245897

Epoch: 6| Step: 5
Training loss: 2.254475381222282
Validation loss: 2.5234649869035866

Epoch: 6| Step: 6
Training loss: 2.912012437605234
Validation loss: 2.524146273035059

Epoch: 6| Step: 7
Training loss: 3.5152721990946914
Validation loss: 2.5306326344830965

Epoch: 6| Step: 8
Training loss: 3.614549239086698
Validation loss: 2.535266357024945

Epoch: 6| Step: 9
Training loss: 2.4814991170131044
Validation loss: 2.5377814694435283

Epoch: 6| Step: 10
Training loss: 2.480614653373779
Validation loss: 2.5283374049324356

Epoch: 6| Step: 11
Training loss: 2.2973574177163485
Validation loss: 2.52667434595705

Epoch: 6| Step: 12
Training loss: 2.885595451535838
Validation loss: 2.5287123142985615

Epoch: 6| Step: 13
Training loss: 3.115136564148265
Validation loss: 2.5266081587190397

Epoch: 128| Step: 0
Training loss: 2.523469812522899
Validation loss: 2.524616528460994

Epoch: 6| Step: 1
Training loss: 3.3435283837007135
Validation loss: 2.5298992458808263

Epoch: 6| Step: 2
Training loss: 2.961658883099765
Validation loss: 2.5262632370291707

Epoch: 6| Step: 3
Training loss: 2.6032912550426515
Validation loss: 2.5236807724680506

Epoch: 6| Step: 4
Training loss: 2.8630724072242373
Validation loss: 2.521839216420912

Epoch: 6| Step: 5
Training loss: 2.8906104834939548
Validation loss: 2.5188007043166367

Epoch: 6| Step: 6
Training loss: 1.9389103094312534
Validation loss: 2.518032662663053

Epoch: 6| Step: 7
Training loss: 2.957406628667278
Validation loss: 2.5196919814684144

Epoch: 6| Step: 8
Training loss: 2.970278055552194
Validation loss: 2.518853499193646

Epoch: 6| Step: 9
Training loss: 2.488584874191738
Validation loss: 2.524295728120375

Epoch: 6| Step: 10
Training loss: 3.5655456373658536
Validation loss: 2.5255837512057013

Epoch: 6| Step: 11
Training loss: 3.0998742724118253
Validation loss: 2.524644333563483

Epoch: 6| Step: 12
Training loss: 2.531505618904956
Validation loss: 2.5219779802782454

Epoch: 6| Step: 13
Training loss: 3.0995255322525495
Validation loss: 2.525190980491911

Epoch: 129| Step: 0
Training loss: 2.5842678061675692
Validation loss: 2.522186279969867

Epoch: 6| Step: 1
Training loss: 2.298560944541494
Validation loss: 2.523845771016198

Epoch: 6| Step: 2
Training loss: 3.3401739659945724
Validation loss: 2.5252140128289904

Epoch: 6| Step: 3
Training loss: 2.9679032573819217
Validation loss: 2.524704593486919

Epoch: 6| Step: 4
Training loss: 2.9571215516264715
Validation loss: 2.522510738976193

Epoch: 6| Step: 5
Training loss: 2.147527106472621
Validation loss: 2.5352369969000597

Epoch: 6| Step: 6
Training loss: 3.1917957455767643
Validation loss: 2.544534769270236

Epoch: 6| Step: 7
Training loss: 2.5309149437956764
Validation loss: 2.5648464451737403

Epoch: 6| Step: 8
Training loss: 2.7404236949033796
Validation loss: 2.6047225030810526

Epoch: 6| Step: 9
Training loss: 2.9670017917526077
Validation loss: 2.708909296425738

Epoch: 6| Step: 10
Training loss: 3.3318744009829935
Validation loss: 2.718521078351994

Epoch: 6| Step: 11
Training loss: 3.28329462199619
Validation loss: 2.6170878847326997

Epoch: 6| Step: 12
Training loss: 2.7612630638134728
Validation loss: 2.518302044904744

Epoch: 6| Step: 13
Training loss: 3.100099155932166
Validation loss: 2.521699011476578

Epoch: 130| Step: 0
Training loss: 2.932504992858851
Validation loss: 2.591993543463904

Epoch: 6| Step: 1
Training loss: 3.20341378747717
Validation loss: 2.691212812172995

Epoch: 6| Step: 2
Training loss: 2.709959441863326
Validation loss: 2.844059505971376

Epoch: 6| Step: 3
Training loss: 2.5712093191679424
Validation loss: 2.8586284394225423

Epoch: 6| Step: 4
Training loss: 3.2289303272677796
Validation loss: 2.9534742707974684

Epoch: 6| Step: 5
Training loss: 3.5791768356255758
Validation loss: 2.843532530050825

Epoch: 6| Step: 6
Training loss: 3.6320319536962913
Validation loss: 2.7382280795331164

Epoch: 6| Step: 7
Training loss: 2.4973924389532023
Validation loss: 2.618268726375527

Epoch: 6| Step: 8
Training loss: 3.1595017706758464
Validation loss: 2.5343795474682933

Epoch: 6| Step: 9
Training loss: 2.420372182899494
Validation loss: 2.5274042417488225

Epoch: 6| Step: 10
Training loss: 3.058230479604478
Validation loss: 2.5307007678244577

Epoch: 6| Step: 11
Training loss: 2.6081769557141086
Validation loss: 2.571643755762761

Epoch: 6| Step: 12
Training loss: 3.2737486334088164
Validation loss: 2.6328196091712797

Epoch: 6| Step: 13
Training loss: 3.2022834975043466
Validation loss: 2.6814239423731867

Epoch: 131| Step: 0
Training loss: 3.056890995387016
Validation loss: 2.637844511322498

Epoch: 6| Step: 1
Training loss: 3.2523693837849263
Validation loss: 2.5517854404102507

Epoch: 6| Step: 2
Training loss: 3.0717827380461498
Validation loss: 2.5223050975093266

Epoch: 6| Step: 3
Training loss: 2.857459255138276
Validation loss: 2.514419460430828

Epoch: 6| Step: 4
Training loss: 3.035738109847757
Validation loss: 2.521245826228324

Epoch: 6| Step: 5
Training loss: 2.750426519436278
Validation loss: 2.5223861877060894

Epoch: 6| Step: 6
Training loss: 3.2073373776224483
Validation loss: 2.530084365653401

Epoch: 6| Step: 7
Training loss: 2.271148263167461
Validation loss: 2.5291231335893207

Epoch: 6| Step: 8
Training loss: 3.3371756978294678
Validation loss: 2.5304509776352577

Epoch: 6| Step: 9
Training loss: 2.7318988160347826
Validation loss: 2.5310983859299934

Epoch: 6| Step: 10
Training loss: 2.8608174672303974
Validation loss: 2.527931328802455

Epoch: 6| Step: 11
Training loss: 2.824131121403776
Validation loss: 2.531381443367838

Epoch: 6| Step: 12
Training loss: 2.7415976908934248
Validation loss: 2.529221524460655

Epoch: 6| Step: 13
Training loss: 2.352432343567141
Validation loss: 2.52806657814164

Epoch: 132| Step: 0
Training loss: 2.090957601459454
Validation loss: 2.523171098436287

Epoch: 6| Step: 1
Training loss: 2.5790350030459135
Validation loss: 2.5232341794548465

Epoch: 6| Step: 2
Training loss: 3.427070470783866
Validation loss: 2.5257292022802584

Epoch: 6| Step: 3
Training loss: 2.807562074866687
Validation loss: 2.524971274918464

Epoch: 6| Step: 4
Training loss: 2.8165615001961535
Validation loss: 2.5359389363813785

Epoch: 6| Step: 5
Training loss: 2.756033693852303
Validation loss: 2.5562740308049907

Epoch: 6| Step: 6
Training loss: 3.388073501744414
Validation loss: 2.580704175462756

Epoch: 6| Step: 7
Training loss: 3.1517658672996935
Validation loss: 2.5987161545753157

Epoch: 6| Step: 8
Training loss: 2.673439326416676
Validation loss: 2.607298422322748

Epoch: 6| Step: 9
Training loss: 3.1267704335490016
Validation loss: 2.6020696480064545

Epoch: 6| Step: 10
Training loss: 3.12334245591543
Validation loss: 2.5858132863199006

Epoch: 6| Step: 11
Training loss: 2.5322574447355186
Validation loss: 2.56146711636819

Epoch: 6| Step: 12
Training loss: 3.5655592782786467
Validation loss: 2.5585849832263894

Epoch: 6| Step: 13
Training loss: 1.5258235146196015
Validation loss: 2.5495672902774076

Epoch: 133| Step: 0
Training loss: 2.565714239132013
Validation loss: 2.552898449757698

Epoch: 6| Step: 1
Training loss: 2.9355754635168134
Validation loss: 2.5533463835604304

Epoch: 6| Step: 2
Training loss: 2.6169747792808105
Validation loss: 2.5530692437305644

Epoch: 6| Step: 3
Training loss: 2.7314054222317354
Validation loss: 2.550522022592597

Epoch: 6| Step: 4
Training loss: 3.2934202199226137
Validation loss: 2.5464251204148045

Epoch: 6| Step: 5
Training loss: 2.864565281666607
Validation loss: 2.5455437578320383

Epoch: 6| Step: 6
Training loss: 2.7693316948668043
Validation loss: 2.54443706525651

Epoch: 6| Step: 7
Training loss: 2.7248176303698592
Validation loss: 2.5482858323200825

Epoch: 6| Step: 8
Training loss: 3.446543778442925
Validation loss: 2.5505593714413513

Epoch: 6| Step: 9
Training loss: 2.6917020195055588
Validation loss: 2.5577939036158592

Epoch: 6| Step: 10
Training loss: 2.8443572685009215
Validation loss: 2.561898891077386

Epoch: 6| Step: 11
Training loss: 3.0701843700900464
Validation loss: 2.5627547456866124

Epoch: 6| Step: 12
Training loss: 2.9983108851589257
Validation loss: 2.565406671458565

Epoch: 6| Step: 13
Training loss: 2.9384419980207914
Validation loss: 2.5448256203771744

Epoch: 134| Step: 0
Training loss: 3.008201356002353
Validation loss: 2.5384835430498764

Epoch: 6| Step: 1
Training loss: 3.242796470717903
Validation loss: 2.5358288075063227

Epoch: 6| Step: 2
Training loss: 3.1117492505723368
Validation loss: 2.5343108130200815

Epoch: 6| Step: 3
Training loss: 2.903946815024715
Validation loss: 2.5345107031081464

Epoch: 6| Step: 4
Training loss: 2.5281006801270083
Validation loss: 2.5372247615451085

Epoch: 6| Step: 5
Training loss: 2.940341954488656
Validation loss: 2.534454514031599

Epoch: 6| Step: 6
Training loss: 2.1355386714662603
Validation loss: 2.5351565078651035

Epoch: 6| Step: 7
Training loss: 2.9715161737691553
Validation loss: 2.535856156052997

Epoch: 6| Step: 8
Training loss: 3.324160798371182
Validation loss: 2.531182560540754

Epoch: 6| Step: 9
Training loss: 3.8809729042591563
Validation loss: 2.5304272609826817

Epoch: 6| Step: 10
Training loss: 2.6727420225544436
Validation loss: 2.5340548043207547

Epoch: 6| Step: 11
Training loss: 2.2891266589238137
Validation loss: 2.541802371588347

Epoch: 6| Step: 12
Training loss: 2.4118678910308087
Validation loss: 2.529498357235266

Epoch: 6| Step: 13
Training loss: 2.3011679462016623
Validation loss: 2.5379844276269

Epoch: 135| Step: 0
Training loss: 3.088655843870437
Validation loss: 2.536996826761446

Epoch: 6| Step: 1
Training loss: 2.715521638612992
Validation loss: 2.553124683742745

Epoch: 6| Step: 2
Training loss: 3.4245508609514275
Validation loss: 2.5519966624754997

Epoch: 6| Step: 3
Training loss: 2.5789434809916667
Validation loss: 2.5512844225662867

Epoch: 6| Step: 4
Training loss: 2.4200367503883036
Validation loss: 2.5458460836398538

Epoch: 6| Step: 5
Training loss: 2.48430014443537
Validation loss: 2.538634810984454

Epoch: 6| Step: 6
Training loss: 3.531656967613028
Validation loss: 2.5572367564243117

Epoch: 6| Step: 7
Training loss: 2.542720659521206
Validation loss: 2.569903978625884

Epoch: 6| Step: 8
Training loss: 2.354863179113851
Validation loss: 2.5517625795916863

Epoch: 6| Step: 9
Training loss: 2.8073103602724125
Validation loss: 2.548478857166449

Epoch: 6| Step: 10
Training loss: 2.598981430368988
Validation loss: 2.557882877990063

Epoch: 6| Step: 11
Training loss: 3.040306013415821
Validation loss: 2.5542932759198225

Epoch: 6| Step: 12
Training loss: 3.2557363504051753
Validation loss: 2.5588455012465023

Epoch: 6| Step: 13
Training loss: 3.3528237981692124
Validation loss: 2.563505174171486

Epoch: 136| Step: 0
Training loss: 3.3854634599630695
Validation loss: 2.5383687762706937

Epoch: 6| Step: 1
Training loss: 2.4002246473396056
Validation loss: 2.5276322311824146

Epoch: 6| Step: 2
Training loss: 2.8059577296927967
Validation loss: 2.5222958768205292

Epoch: 6| Step: 3
Training loss: 2.373630530397776
Validation loss: 2.5257103352021595

Epoch: 6| Step: 4
Training loss: 2.441173719395115
Validation loss: 2.523284534626154

Epoch: 6| Step: 5
Training loss: 3.031918481480781
Validation loss: 2.519836432736022

Epoch: 6| Step: 6
Training loss: 2.4423863267167842
Validation loss: 2.5243988212464443

Epoch: 6| Step: 7
Training loss: 2.6065457475849008
Validation loss: 2.5297819727060915

Epoch: 6| Step: 8
Training loss: 2.7858571672651466
Validation loss: 2.536067268374707

Epoch: 6| Step: 9
Training loss: 3.252811976020559
Validation loss: 2.5338569199888656

Epoch: 6| Step: 10
Training loss: 3.1404081810651894
Validation loss: 2.5325458652542214

Epoch: 6| Step: 11
Training loss: 3.1692272842578944
Validation loss: 2.5329690714522966

Epoch: 6| Step: 12
Training loss: 3.2629702057479215
Validation loss: 2.5326217667509128

Epoch: 6| Step: 13
Training loss: 2.888621197630606
Validation loss: 2.531660949251886

Epoch: 137| Step: 0
Training loss: 2.5173085899281933
Validation loss: 2.5333116137664273

Epoch: 6| Step: 1
Training loss: 2.26801442393673
Validation loss: 2.5342175867520007

Epoch: 6| Step: 2
Training loss: 2.865051471720519
Validation loss: 2.546773242509296

Epoch: 6| Step: 3
Training loss: 2.991374968721108
Validation loss: 2.5490077053109648

Epoch: 6| Step: 4
Training loss: 2.8491759464112425
Validation loss: 2.5517802564324343

Epoch: 6| Step: 5
Training loss: 2.7674016903005816
Validation loss: 2.552473426590452

Epoch: 6| Step: 6
Training loss: 3.3325266497749064
Validation loss: 2.549531457318601

Epoch: 6| Step: 7
Training loss: 3.0983585749667233
Validation loss: 2.5407020151028425

Epoch: 6| Step: 8
Training loss: 2.8882769971820865
Validation loss: 2.548814170333071

Epoch: 6| Step: 9
Training loss: 3.1709055053143436
Validation loss: 2.540412206610158

Epoch: 6| Step: 10
Training loss: 2.54948572320975
Validation loss: 2.530721831380677

Epoch: 6| Step: 11
Training loss: 2.7718274238227845
Validation loss: 2.5366567952783807

Epoch: 6| Step: 12
Training loss: 2.652840973621156
Validation loss: 2.5352368755556314

Epoch: 6| Step: 13
Training loss: 3.434628483700227
Validation loss: 2.5324943094074506

Epoch: 138| Step: 0
Training loss: 3.101238704662364
Validation loss: 2.5250616779427437

Epoch: 6| Step: 1
Training loss: 2.593824914057218
Validation loss: 2.528058127868493

Epoch: 6| Step: 2
Training loss: 3.2071552508190875
Validation loss: 2.525944727433149

Epoch: 6| Step: 3
Training loss: 2.4234694615905945
Validation loss: 2.5330272144192145

Epoch: 6| Step: 4
Training loss: 2.5883817156388025
Validation loss: 2.525974382308495

Epoch: 6| Step: 5
Training loss: 2.4672652016713603
Validation loss: 2.527170464712197

Epoch: 6| Step: 6
Training loss: 2.70913979676493
Validation loss: 2.516057386915155

Epoch: 6| Step: 7
Training loss: 2.7959885710945174
Validation loss: 2.519574419398849

Epoch: 6| Step: 8
Training loss: 3.12385614441487
Validation loss: 2.522182416494121

Epoch: 6| Step: 9
Training loss: 3.0347364373435504
Validation loss: 2.5216304752961616

Epoch: 6| Step: 10
Training loss: 3.286682137407126
Validation loss: 2.5243672528323073

Epoch: 6| Step: 11
Training loss: 2.5642814956490683
Validation loss: 2.5138979301485698

Epoch: 6| Step: 12
Training loss: 3.0294534924354903
Validation loss: 2.510734626473788

Epoch: 6| Step: 13
Training loss: 2.9114151862171163
Validation loss: 2.511309877423121

Epoch: 139| Step: 0
Training loss: 2.980128917593753
Validation loss: 2.512096092618936

Epoch: 6| Step: 1
Training loss: 2.9535675524569047
Validation loss: 2.5105542261948943

Epoch: 6| Step: 2
Training loss: 2.406410707333768
Validation loss: 2.513648995954937

Epoch: 6| Step: 3
Training loss: 2.507961375728501
Validation loss: 2.5055346976172834

Epoch: 6| Step: 4
Training loss: 2.6502773679571185
Validation loss: 2.5042891061940695

Epoch: 6| Step: 5
Training loss: 3.1093728530339635
Validation loss: 2.4976257986865793

Epoch: 6| Step: 6
Training loss: 2.422264313939685
Validation loss: 2.4968916427376144

Epoch: 6| Step: 7
Training loss: 3.3510704835350924
Validation loss: 2.498235965119584

Epoch: 6| Step: 8
Training loss: 2.4556329626748963
Validation loss: 2.505943955953874

Epoch: 6| Step: 9
Training loss: 3.2651936369370707
Validation loss: 2.5075134409795945

Epoch: 6| Step: 10
Training loss: 3.0248364112694435
Validation loss: 2.5110270025851884

Epoch: 6| Step: 11
Training loss: 2.707710390097254
Validation loss: 2.517531545657098

Epoch: 6| Step: 12
Training loss: 2.959498073189919
Validation loss: 2.527785709312617

Epoch: 6| Step: 13
Training loss: 3.031344068188435
Validation loss: 2.5275624957433602

Epoch: 140| Step: 0
Training loss: 2.7813285216487666
Validation loss: 2.523364303077389

Epoch: 6| Step: 1
Training loss: 2.658316223743191
Validation loss: 2.5270246999286883

Epoch: 6| Step: 2
Training loss: 2.8886096424056213
Validation loss: 2.5200471958216086

Epoch: 6| Step: 3
Training loss: 2.767343795213779
Validation loss: 2.524945455331788

Epoch: 6| Step: 4
Training loss: 2.8253019796014622
Validation loss: 2.5129590204079495

Epoch: 6| Step: 5
Training loss: 2.610679437472962
Validation loss: 2.516724911812824

Epoch: 6| Step: 6
Training loss: 3.4120682886943907
Validation loss: 2.510870594855937

Epoch: 6| Step: 7
Training loss: 2.619230196315143
Validation loss: 2.5037731348808383

Epoch: 6| Step: 8
Training loss: 2.7446095782014917
Validation loss: 2.500772977098604

Epoch: 6| Step: 9
Training loss: 3.1334924887419073
Validation loss: 2.4964753130399524

Epoch: 6| Step: 10
Training loss: 3.0063571331896473
Validation loss: 2.496611382334981

Epoch: 6| Step: 11
Training loss: 2.882537911423025
Validation loss: 2.49590511181486

Epoch: 6| Step: 12
Training loss: 2.3025961487417717
Validation loss: 2.497517969778647

Epoch: 6| Step: 13
Training loss: 3.275239216461727
Validation loss: 2.4985913635584507

Epoch: 141| Step: 0
Training loss: 2.370309313455752
Validation loss: 2.4963216629261065

Epoch: 6| Step: 1
Training loss: 2.4519281079455006
Validation loss: 2.5063818588923454

Epoch: 6| Step: 2
Training loss: 3.0619330367945614
Validation loss: 2.501966574595118

Epoch: 6| Step: 3
Training loss: 3.029232966464003
Validation loss: 2.5037531060793667

Epoch: 6| Step: 4
Training loss: 3.161441876254959
Validation loss: 2.5032504920728886

Epoch: 6| Step: 5
Training loss: 2.7048769879531482
Validation loss: 2.5048642970652994

Epoch: 6| Step: 6
Training loss: 3.149332454126781
Validation loss: 2.5022819646008383

Epoch: 6| Step: 7
Training loss: 2.0998464619048267
Validation loss: 2.5060502949891705

Epoch: 6| Step: 8
Training loss: 2.2535230816661387
Validation loss: 2.528787760099707

Epoch: 6| Step: 9
Training loss: 2.946039651410949
Validation loss: 2.5357405434483185

Epoch: 6| Step: 10
Training loss: 3.5326886242656066
Validation loss: 2.535226828216831

Epoch: 6| Step: 11
Training loss: 3.002284610591675
Validation loss: 2.554049389076551

Epoch: 6| Step: 12
Training loss: 2.915046587092466
Validation loss: 2.5369367860578724

Epoch: 6| Step: 13
Training loss: 2.6879290748333053
Validation loss: 2.555917915776824

Epoch: 142| Step: 0
Training loss: 2.559674449724851
Validation loss: 2.563948524261885

Epoch: 6| Step: 1
Training loss: 2.7623930759364144
Validation loss: 2.577832804230938

Epoch: 6| Step: 2
Training loss: 2.298068923494273
Validation loss: 2.5855654458850292

Epoch: 6| Step: 3
Training loss: 2.7088950430532677
Validation loss: 2.59674627745368

Epoch: 6| Step: 4
Training loss: 2.7298827845523
Validation loss: 2.596163912196979

Epoch: 6| Step: 5
Training loss: 2.693896023715573
Validation loss: 2.584926369746763

Epoch: 6| Step: 6
Training loss: 2.6526225734221613
Validation loss: 2.5664362914157848

Epoch: 6| Step: 7
Training loss: 3.0566003766319794
Validation loss: 2.57010513727429

Epoch: 6| Step: 8
Training loss: 2.917044006643427
Validation loss: 2.577316472617338

Epoch: 6| Step: 9
Training loss: 3.2922986707488358
Validation loss: 2.5577708840131685

Epoch: 6| Step: 10
Training loss: 2.817452372678987
Validation loss: 2.545647049391878

Epoch: 6| Step: 11
Training loss: 3.0308618985300906
Validation loss: 2.524545928810834

Epoch: 6| Step: 12
Training loss: 3.480345307461241
Validation loss: 2.5053550188292566

Epoch: 6| Step: 13
Training loss: 3.181681239909199
Validation loss: 2.4993800604657372

Epoch: 143| Step: 0
Training loss: 3.1801764934673122
Validation loss: 2.496279653449607

Epoch: 6| Step: 1
Training loss: 2.4972463701622583
Validation loss: 2.498890863511839

Epoch: 6| Step: 2
Training loss: 2.5295520315012343
Validation loss: 2.497365307698622

Epoch: 6| Step: 3
Training loss: 3.2093886749362537
Validation loss: 2.5023575054983387

Epoch: 6| Step: 4
Training loss: 3.2653250670613336
Validation loss: 2.505477154739195

Epoch: 6| Step: 5
Training loss: 2.228228029755458
Validation loss: 2.503264758601236

Epoch: 6| Step: 6
Training loss: 2.727353656174943
Validation loss: 2.5242548260587454

Epoch: 6| Step: 7
Training loss: 2.555014213179081
Validation loss: 2.5320696651261394

Epoch: 6| Step: 8
Training loss: 2.818510795644319
Validation loss: 2.5416010900786508

Epoch: 6| Step: 9
Training loss: 2.230876397662575
Validation loss: 2.550578797491351

Epoch: 6| Step: 10
Training loss: 3.5618162335516126
Validation loss: 2.5552134388144823

Epoch: 6| Step: 11
Training loss: 2.769803613524814
Validation loss: 2.551833650397245

Epoch: 6| Step: 12
Training loss: 2.6134011279609264
Validation loss: 2.5246585650026456

Epoch: 6| Step: 13
Training loss: 3.36523224957311
Validation loss: 2.5126187509051543

Epoch: 144| Step: 0
Training loss: 2.5273976150739315
Validation loss: 2.5119921322852132

Epoch: 6| Step: 1
Training loss: 3.082657164243332
Validation loss: 2.502394667578376

Epoch: 6| Step: 2
Training loss: 2.765948432932649
Validation loss: 2.489096785315019

Epoch: 6| Step: 3
Training loss: 2.6535120597466113
Validation loss: 2.487853853869273

Epoch: 6| Step: 4
Training loss: 3.3436456111406887
Validation loss: 2.5003440004987154

Epoch: 6| Step: 5
Training loss: 2.854828435282488
Validation loss: 2.4916042792809217

Epoch: 6| Step: 6
Training loss: 2.779689479610602
Validation loss: 2.5012655336487892

Epoch: 6| Step: 7
Training loss: 2.419110301385316
Validation loss: 2.500596682806495

Epoch: 6| Step: 8
Training loss: 2.9161224039077567
Validation loss: 2.5001930049514396

Epoch: 6| Step: 9
Training loss: 2.9467611216025107
Validation loss: 2.493146200393901

Epoch: 6| Step: 10
Training loss: 3.1066793901021943
Validation loss: 2.4884987399919574

Epoch: 6| Step: 11
Training loss: 2.762178676784047
Validation loss: 2.489597578124229

Epoch: 6| Step: 12
Training loss: 2.7158503361002246
Validation loss: 2.493897820087881

Epoch: 6| Step: 13
Training loss: 2.737446656425901
Validation loss: 2.494806815799379

Epoch: 145| Step: 0
Training loss: 2.6237110424738876
Validation loss: 2.488808776610033

Epoch: 6| Step: 1
Training loss: 2.9283789395330952
Validation loss: 2.4958006280561316

Epoch: 6| Step: 2
Training loss: 3.268955120703978
Validation loss: 2.500980884131695

Epoch: 6| Step: 3
Training loss: 2.6650608910337263
Validation loss: 2.5087276201450504

Epoch: 6| Step: 4
Training loss: 3.2524616015760373
Validation loss: 2.5096094737189985

Epoch: 6| Step: 5
Training loss: 2.824046867068155
Validation loss: 2.5069882938581234

Epoch: 6| Step: 6
Training loss: 2.403329836048786
Validation loss: 2.51625592424117

Epoch: 6| Step: 7
Training loss: 3.000136054450672
Validation loss: 2.50649370758705

Epoch: 6| Step: 8
Training loss: 3.085425689361245
Validation loss: 2.5148656921170596

Epoch: 6| Step: 9
Training loss: 2.5720966489261707
Validation loss: 2.513167717732365

Epoch: 6| Step: 10
Training loss: 2.794288163547629
Validation loss: 2.5138052675271285

Epoch: 6| Step: 11
Training loss: 2.203353437119421
Validation loss: 2.5100225831072254

Epoch: 6| Step: 12
Training loss: 3.0196702142990715
Validation loss: 2.502609217241701

Epoch: 6| Step: 13
Training loss: 2.6870358088399717
Validation loss: 2.504186068674284

Epoch: 146| Step: 0
Training loss: 2.7866360236343306
Validation loss: 2.5058858485439517

Epoch: 6| Step: 1
Training loss: 3.197985438167587
Validation loss: 2.497744547775881

Epoch: 6| Step: 2
Training loss: 2.7724310969741848
Validation loss: 2.5010901924839923

Epoch: 6| Step: 3
Training loss: 2.8848826514431494
Validation loss: 2.5018400762766113

Epoch: 6| Step: 4
Training loss: 2.5691691815362634
Validation loss: 2.515232213730334

Epoch: 6| Step: 5
Training loss: 2.7488846684557706
Validation loss: 2.516354714310864

Epoch: 6| Step: 6
Training loss: 2.6403913225239113
Validation loss: 2.517491824941118

Epoch: 6| Step: 7
Training loss: 3.1577886475762167
Validation loss: 2.510350269666206

Epoch: 6| Step: 8
Training loss: 2.8636814061595413
Validation loss: 2.50668799105986

Epoch: 6| Step: 9
Training loss: 3.1289943344537945
Validation loss: 2.5031926053157636

Epoch: 6| Step: 10
Training loss: 2.49550529790953
Validation loss: 2.5212259880891574

Epoch: 6| Step: 11
Training loss: 3.0187282901085934
Validation loss: 2.521940915659729

Epoch: 6| Step: 12
Training loss: 2.589141059931393
Validation loss: 2.5239653941099016

Epoch: 6| Step: 13
Training loss: 2.026740482370557
Validation loss: 2.518007805322643

Epoch: 147| Step: 0
Training loss: 3.1283594003633595
Validation loss: 2.517564768989542

Epoch: 6| Step: 1
Training loss: 3.2815051751596567
Validation loss: 2.5075541754787682

Epoch: 6| Step: 2
Training loss: 2.8440035193484565
Validation loss: 2.506031916053743

Epoch: 6| Step: 3
Training loss: 2.871642432690823
Validation loss: 2.494139361239277

Epoch: 6| Step: 4
Training loss: 2.718896182284775
Validation loss: 2.498393904674322

Epoch: 6| Step: 5
Training loss: 2.617592304864779
Validation loss: 2.4978606945948556

Epoch: 6| Step: 6
Training loss: 3.209573349213938
Validation loss: 2.495747354765066

Epoch: 6| Step: 7
Training loss: 2.729233447318301
Validation loss: 2.492340757986375

Epoch: 6| Step: 8
Training loss: 2.5690900220233166
Validation loss: 2.4999150425821557

Epoch: 6| Step: 9
Training loss: 2.1936080669341003
Validation loss: 2.498164789263371

Epoch: 6| Step: 10
Training loss: 2.9761358641200606
Validation loss: 2.4992396182752565

Epoch: 6| Step: 11
Training loss: 2.166541047000357
Validation loss: 2.5008970681560947

Epoch: 6| Step: 12
Training loss: 2.886903418801416
Validation loss: 2.5269265552706983

Epoch: 6| Step: 13
Training loss: 3.381786587316793
Validation loss: 2.564942884999268

Epoch: 148| Step: 0
Training loss: 3.2412552194078867
Validation loss: 2.586278069329752

Epoch: 6| Step: 1
Training loss: 2.9254128971645157
Validation loss: 2.619158229814749

Epoch: 6| Step: 2
Training loss: 2.5525064753376485
Validation loss: 2.580260905536269

Epoch: 6| Step: 3
Training loss: 2.562043777419373
Validation loss: 2.563564542621058

Epoch: 6| Step: 4
Training loss: 2.5346786448827605
Validation loss: 2.553610141105802

Epoch: 6| Step: 5
Training loss: 2.6976562040424534
Validation loss: 2.533049187716662

Epoch: 6| Step: 6
Training loss: 2.7919879178110936
Validation loss: 2.5130076799149954

Epoch: 6| Step: 7
Training loss: 3.129927450685977
Validation loss: 2.5192506507198518

Epoch: 6| Step: 8
Training loss: 2.4866054287376476
Validation loss: 2.5186276262127874

Epoch: 6| Step: 9
Training loss: 2.521511417542341
Validation loss: 2.5246877394559935

Epoch: 6| Step: 10
Training loss: 3.0828631961944395
Validation loss: 2.5335076737471223

Epoch: 6| Step: 11
Training loss: 3.4390097337181817
Validation loss: 2.5214899577968977

Epoch: 6| Step: 12
Training loss: 2.7608803605544754
Validation loss: 2.4879929572945687

Epoch: 6| Step: 13
Training loss: 2.278804356465018
Validation loss: 2.4787659342321

Epoch: 149| Step: 0
Training loss: 2.6678774191107206
Validation loss: 2.481540603442639

Epoch: 6| Step: 1
Training loss: 2.117066439725306
Validation loss: 2.4859737474319266

Epoch: 6| Step: 2
Training loss: 3.267065579197837
Validation loss: 2.489089156477363

Epoch: 6| Step: 3
Training loss: 2.6261430703881046
Validation loss: 2.4878937953139277

Epoch: 6| Step: 4
Training loss: 2.656767491812974
Validation loss: 2.4839313668470764

Epoch: 6| Step: 5
Training loss: 2.8680528379544943
Validation loss: 2.4870022099685904

Epoch: 6| Step: 6
Training loss: 3.1193075595200463
Validation loss: 2.485409045278435

Epoch: 6| Step: 7
Training loss: 3.1510071975882457
Validation loss: 2.4766358317819055

Epoch: 6| Step: 8
Training loss: 2.806569522602099
Validation loss: 2.481642935047602

Epoch: 6| Step: 9
Training loss: 2.5505904729516398
Validation loss: 2.482493106187371

Epoch: 6| Step: 10
Training loss: 3.2543221124374004
Validation loss: 2.4840624099173367

Epoch: 6| Step: 11
Training loss: 2.61927680131636
Validation loss: 2.4923567147249317

Epoch: 6| Step: 12
Training loss: 3.1180167947430633
Validation loss: 2.492394186378061

Epoch: 6| Step: 13
Training loss: 2.500606558649987
Validation loss: 2.5256975256466014

Epoch: 150| Step: 0
Training loss: 2.417601722383927
Validation loss: 2.5741598822248073

Epoch: 6| Step: 1
Training loss: 2.6677160185246787
Validation loss: 2.649355436324539

Epoch: 6| Step: 2
Training loss: 2.148959120804061
Validation loss: 2.674333708720962

Epoch: 6| Step: 3
Training loss: 2.81623143514651
Validation loss: 2.715492926481322

Epoch: 6| Step: 4
Training loss: 3.1128071767445356
Validation loss: 2.679609509179843

Epoch: 6| Step: 5
Training loss: 2.489912471535046
Validation loss: 2.607900476877303

Epoch: 6| Step: 6
Training loss: 2.938994494173098
Validation loss: 2.618236842582446

Epoch: 6| Step: 7
Training loss: 2.9313286418979914
Validation loss: 2.542751055379137

Epoch: 6| Step: 8
Training loss: 3.3743161109043407
Validation loss: 2.490476785628129

Epoch: 6| Step: 9
Training loss: 3.370906749502687
Validation loss: 2.485972979156489

Epoch: 6| Step: 10
Training loss: 2.532767888593472
Validation loss: 2.499718748700002

Epoch: 6| Step: 11
Training loss: 3.0077104030967616
Validation loss: 2.520475899368287

Epoch: 6| Step: 12
Training loss: 2.954136912236844
Validation loss: 2.5276664566787055

Epoch: 6| Step: 13
Training loss: 2.934971146969749
Validation loss: 2.5286017627047466

Epoch: 151| Step: 0
Training loss: 2.8237965375046743
Validation loss: 2.516602974406031

Epoch: 6| Step: 1
Training loss: 2.962002766403771
Validation loss: 2.514201460627431

Epoch: 6| Step: 2
Training loss: 3.493995556877119
Validation loss: 2.4913183962445173

Epoch: 6| Step: 3
Training loss: 3.2988177175679523
Validation loss: 2.4834167103777047

Epoch: 6| Step: 4
Training loss: 2.135342170222244
Validation loss: 2.4823415220778835

Epoch: 6| Step: 5
Training loss: 2.5429189650764643
Validation loss: 2.4946345239696215

Epoch: 6| Step: 6
Training loss: 2.8295550866744743
Validation loss: 2.503924739755877

Epoch: 6| Step: 7
Training loss: 2.2882673425274604
Validation loss: 2.530099949588893

Epoch: 6| Step: 8
Training loss: 2.9332572652606013
Validation loss: 2.535278292094061

Epoch: 6| Step: 9
Training loss: 2.3483497750451465
Validation loss: 2.5707256105965572

Epoch: 6| Step: 10
Training loss: 2.6974885421665147
Validation loss: 2.581996016509975

Epoch: 6| Step: 11
Training loss: 2.9578269381808036
Validation loss: 2.6159838658013688

Epoch: 6| Step: 12
Training loss: 3.1149034282477475
Validation loss: 2.636438873762826

Epoch: 6| Step: 13
Training loss: 3.254936723694694
Validation loss: 2.6962461276827185

Epoch: 152| Step: 0
Training loss: 2.7141612999589437
Validation loss: 2.682583327683913

Epoch: 6| Step: 1
Training loss: 2.548570501527734
Validation loss: 2.6088880045562868

Epoch: 6| Step: 2
Training loss: 2.8315648188095777
Validation loss: 2.560581516570844

Epoch: 6| Step: 3
Training loss: 3.1407942844904366
Validation loss: 2.542645966922025

Epoch: 6| Step: 4
Training loss: 2.6662236282754157
Validation loss: 2.498579737535866

Epoch: 6| Step: 5
Training loss: 2.95735600047573
Validation loss: 2.4874902171899347

Epoch: 6| Step: 6
Training loss: 3.0476148440695336
Validation loss: 2.4988819914142635

Epoch: 6| Step: 7
Training loss: 2.4486817375042667
Validation loss: 2.4906746272033904

Epoch: 6| Step: 8
Training loss: 2.994347651640791
Validation loss: 2.498459725010234

Epoch: 6| Step: 9
Training loss: 3.445922520754489
Validation loss: 2.4901927652246583

Epoch: 6| Step: 10
Training loss: 2.6529628385090067
Validation loss: 2.483224691340872

Epoch: 6| Step: 11
Training loss: 2.8604012403931165
Validation loss: 2.4861945319622687

Epoch: 6| Step: 12
Training loss: 3.085119829617343
Validation loss: 2.4706004030494415

Epoch: 6| Step: 13
Training loss: 2.063283135826003
Validation loss: 2.499903254534129

Epoch: 153| Step: 0
Training loss: 2.9004675652673604
Validation loss: 2.5059869297516504

Epoch: 6| Step: 1
Training loss: 2.349612114731102
Validation loss: 2.501940978701352

Epoch: 6| Step: 2
Training loss: 2.787199792818791
Validation loss: 2.4962654584288027

Epoch: 6| Step: 3
Training loss: 2.9314519426290038
Validation loss: 2.496954761367606

Epoch: 6| Step: 4
Training loss: 3.048543463448595
Validation loss: 2.5002107592927674

Epoch: 6| Step: 5
Training loss: 3.0415620306820665
Validation loss: 2.4810003577687905

Epoch: 6| Step: 6
Training loss: 2.8085480793726765
Validation loss: 2.471167626086688

Epoch: 6| Step: 7
Training loss: 2.979261081150936
Validation loss: 2.4680099239916022

Epoch: 6| Step: 8
Training loss: 3.3195448044024136
Validation loss: 2.4713401607747296

Epoch: 6| Step: 9
Training loss: 2.9110666374355523
Validation loss: 2.478629045074683

Epoch: 6| Step: 10
Training loss: 2.5881526252987515
Validation loss: 2.4801610074753078

Epoch: 6| Step: 11
Training loss: 2.237430004538135
Validation loss: 2.48737437355151

Epoch: 6| Step: 12
Training loss: 2.7266961095039512
Validation loss: 2.4965554277285427

Epoch: 6| Step: 13
Training loss: 2.9628457233846337
Validation loss: 2.487142690702862

Epoch: 154| Step: 0
Training loss: 2.4521986068643224
Validation loss: 2.49824688775926

Epoch: 6| Step: 1
Training loss: 3.1126343786194
Validation loss: 2.4903460800850703

Epoch: 6| Step: 2
Training loss: 2.426279112116951
Validation loss: 2.4837176138824884

Epoch: 6| Step: 3
Training loss: 3.277486622984566
Validation loss: 2.5126422198800955

Epoch: 6| Step: 4
Training loss: 2.380764941376029
Validation loss: 2.5299767426846866

Epoch: 6| Step: 5
Training loss: 2.9035098376165753
Validation loss: 2.5350320884452113

Epoch: 6| Step: 6
Training loss: 2.645741398533235
Validation loss: 2.5438077126884533

Epoch: 6| Step: 7
Training loss: 3.2607712882892064
Validation loss: 2.549222642132426

Epoch: 6| Step: 8
Training loss: 3.2172052324574296
Validation loss: 2.5019123413197586

Epoch: 6| Step: 9
Training loss: 2.447630931870633
Validation loss: 2.476101975177593

Epoch: 6| Step: 10
Training loss: 3.0548930769719185
Validation loss: 2.4574992178006223

Epoch: 6| Step: 11
Training loss: 2.5527163492513436
Validation loss: 2.4605918421459476

Epoch: 6| Step: 12
Training loss: 2.5275203401405535
Validation loss: 2.462306313200399

Epoch: 6| Step: 13
Training loss: 2.873488982809256
Validation loss: 2.465310942466097

Epoch: 155| Step: 0
Training loss: 2.7917482924033834
Validation loss: 2.468744486933334

Epoch: 6| Step: 1
Training loss: 2.841895368514382
Validation loss: 2.4748301030399777

Epoch: 6| Step: 2
Training loss: 2.8233561906786324
Validation loss: 2.473783979419378

Epoch: 6| Step: 3
Training loss: 2.5249537586472517
Validation loss: 2.4753081035373143

Epoch: 6| Step: 4
Training loss: 3.19042639940908
Validation loss: 2.470719609547453

Epoch: 6| Step: 5
Training loss: 2.75015275704328
Validation loss: 2.465011418063276

Epoch: 6| Step: 6
Training loss: 2.5917562152401294
Validation loss: 2.469229764104294

Epoch: 6| Step: 7
Training loss: 2.5676941681033325
Validation loss: 2.465713024487781

Epoch: 6| Step: 8
Training loss: 2.610140933620132
Validation loss: 2.480828194206698

Epoch: 6| Step: 9
Training loss: 2.965501152001046
Validation loss: 2.490524862237753

Epoch: 6| Step: 10
Training loss: 3.374488509237305
Validation loss: 2.506225428249684

Epoch: 6| Step: 11
Training loss: 3.158832060423902
Validation loss: 2.5389229987783892

Epoch: 6| Step: 12
Training loss: 2.8731413098964174
Validation loss: 2.5092192956536743

Epoch: 6| Step: 13
Training loss: 2.845298429367409
Validation loss: 2.505092850908924

Epoch: 156| Step: 0
Training loss: 2.6335218249434753
Validation loss: 2.4943541589895704

Epoch: 6| Step: 1
Training loss: 2.3984419732564657
Validation loss: 2.486564134550081

Epoch: 6| Step: 2
Training loss: 2.948526020672037
Validation loss: 2.479124285145324

Epoch: 6| Step: 3
Training loss: 2.1855152390332093
Validation loss: 2.4822165044238362

Epoch: 6| Step: 4
Training loss: 2.63755321720184
Validation loss: 2.4880537793034616

Epoch: 6| Step: 5
Training loss: 3.18420808633559
Validation loss: 2.480397844645541

Epoch: 6| Step: 6
Training loss: 2.7144924457955764
Validation loss: 2.478714028250211

Epoch: 6| Step: 7
Training loss: 2.5805094471747254
Validation loss: 2.4684458241863454

Epoch: 6| Step: 8
Training loss: 2.893402909293452
Validation loss: 2.4699051349406287

Epoch: 6| Step: 9
Training loss: 2.7738114225816495
Validation loss: 2.475306773716814

Epoch: 6| Step: 10
Training loss: 3.005937581473271
Validation loss: 2.468644067836598

Epoch: 6| Step: 11
Training loss: 2.6436444236651107
Validation loss: 2.4668921176031935

Epoch: 6| Step: 12
Training loss: 2.918206017587515
Validation loss: 2.4657795342064923

Epoch: 6| Step: 13
Training loss: 3.608739623585692
Validation loss: 2.472818175677721

Epoch: 157| Step: 0
Training loss: 2.753283188049975
Validation loss: 2.4673798272501446

Epoch: 6| Step: 1
Training loss: 3.25501949322045
Validation loss: 2.4610823352160174

Epoch: 6| Step: 2
Training loss: 2.7027629984754
Validation loss: 2.4599570482047395

Epoch: 6| Step: 3
Training loss: 2.8469917348802687
Validation loss: 2.4710959050354178

Epoch: 6| Step: 4
Training loss: 2.3216626898116943
Validation loss: 2.4669592341159623

Epoch: 6| Step: 5
Training loss: 2.752999144155284
Validation loss: 2.454649040653154

Epoch: 6| Step: 6
Training loss: 2.716532712883019
Validation loss: 2.453448693629338

Epoch: 6| Step: 7
Training loss: 2.770203502079248
Validation loss: 2.4586199453793123

Epoch: 6| Step: 8
Training loss: 3.0156887225598252
Validation loss: 2.4550628563738996

Epoch: 6| Step: 9
Training loss: 2.3276805069335436
Validation loss: 2.449451995747963

Epoch: 6| Step: 10
Training loss: 2.4549934415088694
Validation loss: 2.46081969276575

Epoch: 6| Step: 11
Training loss: 2.510837145107282
Validation loss: 2.4842800112676517

Epoch: 6| Step: 12
Training loss: 3.1855780098877
Validation loss: 2.51873251676007

Epoch: 6| Step: 13
Training loss: 3.3758884249595513
Validation loss: 2.620800763309999

Epoch: 158| Step: 0
Training loss: 2.7887639759488083
Validation loss: 2.720946875912951

Epoch: 6| Step: 1
Training loss: 3.4493386063104747
Validation loss: 2.7376934938162596

Epoch: 6| Step: 2
Training loss: 3.082181320114616
Validation loss: 2.7171367526055783

Epoch: 6| Step: 3
Training loss: 2.915742200844771
Validation loss: 2.6558458217392085

Epoch: 6| Step: 4
Training loss: 2.5877102310357567
Validation loss: 2.627405005391868

Epoch: 6| Step: 5
Training loss: 3.2322407190551217
Validation loss: 2.582458170879334

Epoch: 6| Step: 6
Training loss: 2.671713930149417
Validation loss: 2.52697343724208

Epoch: 6| Step: 7
Training loss: 2.793679228362026
Validation loss: 2.4953300687558873

Epoch: 6| Step: 8
Training loss: 2.838460845263287
Validation loss: 2.4900810506880275

Epoch: 6| Step: 9
Training loss: 2.8093360906671005
Validation loss: 2.476993457950004

Epoch: 6| Step: 10
Training loss: 2.8234929884169446
Validation loss: 2.4740550782091657

Epoch: 6| Step: 11
Training loss: 2.627393630294704
Validation loss: 2.470411446428886

Epoch: 6| Step: 12
Training loss: 1.9637410461493612
Validation loss: 2.462380174697187

Epoch: 6| Step: 13
Training loss: 2.6193652757169694
Validation loss: 2.4538016022699805

Epoch: 159| Step: 0
Training loss: 3.243244191977216
Validation loss: 2.4622022861602804

Epoch: 6| Step: 1
Training loss: 3.045689435308948
Validation loss: 2.4499216299893294

Epoch: 6| Step: 2
Training loss: 2.546787751932531
Validation loss: 2.451443813724668

Epoch: 6| Step: 3
Training loss: 2.472630987294427
Validation loss: 2.46467753090515

Epoch: 6| Step: 4
Training loss: 2.422431930987146
Validation loss: 2.450943520765063

Epoch: 6| Step: 5
Training loss: 2.2779307843846497
Validation loss: 2.4448725508292926

Epoch: 6| Step: 6
Training loss: 2.8979134715702775
Validation loss: 2.444581351644454

Epoch: 6| Step: 7
Training loss: 3.1618759323574186
Validation loss: 2.4402916663605683

Epoch: 6| Step: 8
Training loss: 2.085396914494962
Validation loss: 2.4472733428351243

Epoch: 6| Step: 9
Training loss: 3.0619563963194225
Validation loss: 2.485267601091451

Epoch: 6| Step: 10
Training loss: 3.029761509338119
Validation loss: 2.525812630672082

Epoch: 6| Step: 11
Training loss: 2.8151932430848587
Validation loss: 2.589120369653218

Epoch: 6| Step: 12
Training loss: 2.8807607239465085
Validation loss: 2.5989879051040417

Epoch: 6| Step: 13
Training loss: 2.6277027748037223
Validation loss: 2.615030772453721

Epoch: 160| Step: 0
Training loss: 2.3112198662946857
Validation loss: 2.6526713557616297

Epoch: 6| Step: 1
Training loss: 2.263355460117295
Validation loss: 2.66593572638162

Epoch: 6| Step: 2
Training loss: 2.698751892258801
Validation loss: 2.7097724117149533

Epoch: 6| Step: 3
Training loss: 2.550671702160462
Validation loss: 2.7517935366142305

Epoch: 6| Step: 4
Training loss: 3.0401860295646963
Validation loss: 2.7790357037096642

Epoch: 6| Step: 5
Training loss: 3.1718746993341913
Validation loss: 2.6368766170445097

Epoch: 6| Step: 6
Training loss: 3.2387630164099446
Validation loss: 2.4997935353413547

Epoch: 6| Step: 7
Training loss: 2.9074942273700115
Validation loss: 2.4664726173790354

Epoch: 6| Step: 8
Training loss: 2.640068130914496
Validation loss: 2.444590482687407

Epoch: 6| Step: 9
Training loss: 2.6330659557561527
Validation loss: 2.470291229820862

Epoch: 6| Step: 10
Training loss: 2.6705322460919643
Validation loss: 2.4939272515911837

Epoch: 6| Step: 11
Training loss: 3.4960966142184495
Validation loss: 2.5183486456259705

Epoch: 6| Step: 12
Training loss: 3.0419199241517143
Validation loss: 2.5206769404708584

Epoch: 6| Step: 13
Training loss: 3.22698469378586
Validation loss: 2.5304689122595305

Epoch: 161| Step: 0
Training loss: 2.596278601145891
Validation loss: 2.5101138452122522

Epoch: 6| Step: 1
Training loss: 2.8662989432294057
Validation loss: 2.5019011344521305

Epoch: 6| Step: 2
Training loss: 2.5523630936061554
Validation loss: 2.481128071505774

Epoch: 6| Step: 3
Training loss: 2.9274053611410737
Validation loss: 2.478706435718554

Epoch: 6| Step: 4
Training loss: 2.9388997415663916
Validation loss: 2.476351663948178

Epoch: 6| Step: 5
Training loss: 2.7940031683650584
Validation loss: 2.479168131259049

Epoch: 6| Step: 6
Training loss: 3.2337874463968905
Validation loss: 2.497817469116565

Epoch: 6| Step: 7
Training loss: 2.5684072743869932
Validation loss: 2.518812913840985

Epoch: 6| Step: 8
Training loss: 2.8458901201859277
Validation loss: 2.5437643559036087

Epoch: 6| Step: 9
Training loss: 2.9654522699796306
Validation loss: 2.547103478013767

Epoch: 6| Step: 10
Training loss: 3.138874534041477
Validation loss: 2.5554024581904895

Epoch: 6| Step: 11
Training loss: 2.4009677326682692
Validation loss: 2.54391053508453

Epoch: 6| Step: 12
Training loss: 2.81053482911986
Validation loss: 2.502860184622969

Epoch: 6| Step: 13
Training loss: 2.5353747069481796
Validation loss: 2.492944813798964

Epoch: 162| Step: 0
Training loss: 2.6955435391240625
Validation loss: 2.4915989335647817

Epoch: 6| Step: 1
Training loss: 3.099861043461389
Validation loss: 2.4805831509435463

Epoch: 6| Step: 2
Training loss: 2.421116273226853
Validation loss: 2.471319616005282

Epoch: 6| Step: 3
Training loss: 3.029828239583385
Validation loss: 2.457829562656675

Epoch: 6| Step: 4
Training loss: 3.248564770046235
Validation loss: 2.4725236837561972

Epoch: 6| Step: 5
Training loss: 2.5172513834106267
Validation loss: 2.466985640844793

Epoch: 6| Step: 6
Training loss: 2.628375108863007
Validation loss: 2.471981643241693

Epoch: 6| Step: 7
Training loss: 2.25100102938845
Validation loss: 2.482529125564273

Epoch: 6| Step: 8
Training loss: 3.107937120918473
Validation loss: 2.474774920803821

Epoch: 6| Step: 9
Training loss: 2.837471539190794
Validation loss: 2.4765850053305987

Epoch: 6| Step: 10
Training loss: 3.3737513740256904
Validation loss: 2.4808873199441583

Epoch: 6| Step: 11
Training loss: 1.9348429026151692
Validation loss: 2.4856729819346683

Epoch: 6| Step: 12
Training loss: 2.9817621267044463
Validation loss: 2.4852139668794018

Epoch: 6| Step: 13
Training loss: 2.480009646243132
Validation loss: 2.489737420229209

Epoch: 163| Step: 0
Training loss: 2.4820555409895904
Validation loss: 2.511449215907393

Epoch: 6| Step: 1
Training loss: 3.367923240203716
Validation loss: 2.537345297721896

Epoch: 6| Step: 2
Training loss: 3.1100055304475043
Validation loss: 2.5192102345873075

Epoch: 6| Step: 3
Training loss: 2.694695089639856
Validation loss: 2.493922565147892

Epoch: 6| Step: 4
Training loss: 3.011394478327534
Validation loss: 2.4782033923846147

Epoch: 6| Step: 5
Training loss: 2.534818135947887
Validation loss: 2.480796504343597

Epoch: 6| Step: 6
Training loss: 2.9112409170425915
Validation loss: 2.4690522683457767

Epoch: 6| Step: 7
Training loss: 2.919154078349084
Validation loss: 2.4739256718826774

Epoch: 6| Step: 8
Training loss: 2.5408814473245127
Validation loss: 2.4772363870773133

Epoch: 6| Step: 9
Training loss: 2.7054877566651165
Validation loss: 2.482232745197774

Epoch: 6| Step: 10
Training loss: 2.1748652010833456
Validation loss: 2.4846560215499838

Epoch: 6| Step: 11
Training loss: 2.96308857024593
Validation loss: 2.4804383195685595

Epoch: 6| Step: 12
Training loss: 2.613785813322045
Validation loss: 2.4701016398016744

Epoch: 6| Step: 13
Training loss: 2.6748184142469067
Validation loss: 2.476483737496264

Epoch: 164| Step: 0
Training loss: 3.356513787670733
Validation loss: 2.4851553180280446

Epoch: 6| Step: 1
Training loss: 2.8727112657695852
Validation loss: 2.4954970332414153

Epoch: 6| Step: 2
Training loss: 2.870094094146206
Validation loss: 2.5052058623449693

Epoch: 6| Step: 3
Training loss: 2.7722265044310714
Validation loss: 2.5141303513157616

Epoch: 6| Step: 4
Training loss: 3.133575574831204
Validation loss: 2.5252960664240187

Epoch: 6| Step: 5
Training loss: 2.55945946410821
Validation loss: 2.5288157748085833

Epoch: 6| Step: 6
Training loss: 2.500174325587157
Validation loss: 2.521326414648734

Epoch: 6| Step: 7
Training loss: 2.4661485510183074
Validation loss: 2.517686870592642

Epoch: 6| Step: 8
Training loss: 2.1872267416169695
Validation loss: 2.4941346068413286

Epoch: 6| Step: 9
Training loss: 2.6790434394210885
Validation loss: 2.4768606114987866

Epoch: 6| Step: 10
Training loss: 2.1353851564144937
Validation loss: 2.474209147478189

Epoch: 6| Step: 11
Training loss: 3.3712360444874467
Validation loss: 2.459409526846266

Epoch: 6| Step: 12
Training loss: 2.7188867118049695
Validation loss: 2.4704165583225843

Epoch: 6| Step: 13
Training loss: 2.686884343800311
Validation loss: 2.469155744110706

Epoch: 165| Step: 0
Training loss: 2.8617005610324053
Validation loss: 2.469290151263394

Epoch: 6| Step: 1
Training loss: 3.110805163401983
Validation loss: 2.4787126625063807

Epoch: 6| Step: 2
Training loss: 3.3676927368923057
Validation loss: 2.4904959103582867

Epoch: 6| Step: 3
Training loss: 3.153618952885716
Validation loss: 2.515778826473595

Epoch: 6| Step: 4
Training loss: 2.3239537705109203
Validation loss: 2.5151610820870096

Epoch: 6| Step: 5
Training loss: 2.7284911583996094
Validation loss: 2.513746631003845

Epoch: 6| Step: 6
Training loss: 2.3525547709560133
Validation loss: 2.519538822275573

Epoch: 6| Step: 7
Training loss: 2.883336626907261
Validation loss: 2.4841257771219327

Epoch: 6| Step: 8
Training loss: 3.1309894384829215
Validation loss: 2.4745842897038677

Epoch: 6| Step: 9
Training loss: 3.1893987049475476
Validation loss: 2.472254072035404

Epoch: 6| Step: 10
Training loss: 2.30374995413256
Validation loss: 2.454666223096517

Epoch: 6| Step: 11
Training loss: 2.393641743814118
Validation loss: 2.4533814180680174

Epoch: 6| Step: 12
Training loss: 2.1414608402523903
Validation loss: 2.4492040749737747

Epoch: 6| Step: 13
Training loss: 2.402804397210152
Validation loss: 2.4487044362626027

Epoch: 166| Step: 0
Training loss: 2.190306253139945
Validation loss: 2.4523268870218433

Epoch: 6| Step: 1
Training loss: 2.649628048110708
Validation loss: 2.4595812447067735

Epoch: 6| Step: 2
Training loss: 1.9752612146431692
Validation loss: 2.4632589547459993

Epoch: 6| Step: 3
Training loss: 2.3612794579222856
Validation loss: 2.4565530629203103

Epoch: 6| Step: 4
Training loss: 2.7196281155039204
Validation loss: 2.466948994950575

Epoch: 6| Step: 5
Training loss: 2.6754177765506553
Validation loss: 2.4550800421863905

Epoch: 6| Step: 6
Training loss: 3.0180425095240846
Validation loss: 2.4536222036704847

Epoch: 6| Step: 7
Training loss: 2.818328582320522
Validation loss: 2.461537280926202

Epoch: 6| Step: 8
Training loss: 2.8718692484767963
Validation loss: 2.454893954306816

Epoch: 6| Step: 9
Training loss: 3.0631803418608405
Validation loss: 2.449232393927316

Epoch: 6| Step: 10
Training loss: 2.9133731957450193
Validation loss: 2.4510230339136316

Epoch: 6| Step: 11
Training loss: 2.8579910347693147
Validation loss: 2.4469135982775843

Epoch: 6| Step: 12
Training loss: 3.0172756599019777
Validation loss: 2.4563155725485295

Epoch: 6| Step: 13
Training loss: 3.452367639124464
Validation loss: 2.4574157569446538

Epoch: 167| Step: 0
Training loss: 3.1373015321978
Validation loss: 2.455039558535531

Epoch: 6| Step: 1
Training loss: 2.4646523185183704
Validation loss: 2.457329008020769

Epoch: 6| Step: 2
Training loss: 2.653724277423783
Validation loss: 2.4532955275786414

Epoch: 6| Step: 3
Training loss: 2.743266966408267
Validation loss: 2.4552158892001175

Epoch: 6| Step: 4
Training loss: 3.093709155497031
Validation loss: 2.4776808889111104

Epoch: 6| Step: 5
Training loss: 2.497851211245968
Validation loss: 2.4946491115863934

Epoch: 6| Step: 6
Training loss: 3.018218669373912
Validation loss: 2.5159572697036157

Epoch: 6| Step: 7
Training loss: 2.5200342430331317
Validation loss: 2.5294483902942098

Epoch: 6| Step: 8
Training loss: 2.5613478885113294
Validation loss: 2.5322414782294227

Epoch: 6| Step: 9
Training loss: 3.2092405415480507
Validation loss: 2.534839738732662

Epoch: 6| Step: 10
Training loss: 2.6151529631360697
Validation loss: 2.535025995444077

Epoch: 6| Step: 11
Training loss: 2.6595563170036858
Validation loss: 2.524074353057512

Epoch: 6| Step: 12
Training loss: 2.440658479233803
Validation loss: 2.517246697616582

Epoch: 6| Step: 13
Training loss: 3.1783780487654427
Validation loss: 2.529155970503488

Epoch: 168| Step: 0
Training loss: 2.665493488533512
Validation loss: 2.5164047639800535

Epoch: 6| Step: 1
Training loss: 2.759746273375182
Validation loss: 2.52369043912551

Epoch: 6| Step: 2
Training loss: 2.899031503685807
Validation loss: 2.501575316148898

Epoch: 6| Step: 3
Training loss: 2.8850902459956194
Validation loss: 2.5107231771682

Epoch: 6| Step: 4
Training loss: 2.4615991096636303
Validation loss: 2.5005330717207293

Epoch: 6| Step: 5
Training loss: 2.4334009378874906
Validation loss: 2.4930811446805445

Epoch: 6| Step: 6
Training loss: 2.7578029902567094
Validation loss: 2.5062064746964965

Epoch: 6| Step: 7
Training loss: 2.724805992989661
Validation loss: 2.503036929922195

Epoch: 6| Step: 8
Training loss: 3.3510240953763626
Validation loss: 2.505753654000722

Epoch: 6| Step: 9
Training loss: 2.4508284977987667
Validation loss: 2.50012164999206

Epoch: 6| Step: 10
Training loss: 3.018120558295632
Validation loss: 2.5004724691892086

Epoch: 6| Step: 11
Training loss: 2.894563867794458
Validation loss: 2.4973704506492025

Epoch: 6| Step: 12
Training loss: 2.716529728845277
Validation loss: 2.499529759471268

Epoch: 6| Step: 13
Training loss: 2.8050195183984354
Validation loss: 2.5129542511175447

Epoch: 169| Step: 0
Training loss: 2.894377381305872
Validation loss: 2.5125665076206953

Epoch: 6| Step: 1
Training loss: 2.9489999854190345
Validation loss: 2.516290076257956

Epoch: 6| Step: 2
Training loss: 2.652063548775169
Validation loss: 2.518882799913602

Epoch: 6| Step: 3
Training loss: 2.9654940770215017
Validation loss: 2.516084672207093

Epoch: 6| Step: 4
Training loss: 3.0147109153410003
Validation loss: 2.5002097462271884

Epoch: 6| Step: 5
Training loss: 2.816706161297372
Validation loss: 2.4896285576886896

Epoch: 6| Step: 6
Training loss: 2.7079646715482673
Validation loss: 2.4931164337030696

Epoch: 6| Step: 7
Training loss: 2.789441678641093
Validation loss: 2.4939811147321214

Epoch: 6| Step: 8
Training loss: 2.9224105588933678
Validation loss: 2.4976147378412463

Epoch: 6| Step: 9
Training loss: 2.4680603609292926
Validation loss: 2.4951159298849492

Epoch: 6| Step: 10
Training loss: 2.004688132710405
Validation loss: 2.5014735032536946

Epoch: 6| Step: 11
Training loss: 2.661926218450535
Validation loss: 2.4938424573695417

Epoch: 6| Step: 12
Training loss: 3.180954739221939
Validation loss: 2.483353403537095

Epoch: 6| Step: 13
Training loss: 2.3702981484468397
Validation loss: 2.4821764561319015

Epoch: 170| Step: 0
Training loss: 2.5950306867427826
Validation loss: 2.475893649165393

Epoch: 6| Step: 1
Training loss: 1.9807297273190876
Validation loss: 2.4809156063626148

Epoch: 6| Step: 2
Training loss: 3.0727462635099814
Validation loss: 2.4815174482996665

Epoch: 6| Step: 3
Training loss: 2.688161546768698
Validation loss: 2.4815686396425205

Epoch: 6| Step: 4
Training loss: 3.4253639306285364
Validation loss: 2.4771044468028838

Epoch: 6| Step: 5
Training loss: 2.661858236847201
Validation loss: 2.48745228517623

Epoch: 6| Step: 6
Training loss: 2.969763171325654
Validation loss: 2.4849912251062336

Epoch: 6| Step: 7
Training loss: 2.468445674633027
Validation loss: 2.494596953398515

Epoch: 6| Step: 8
Training loss: 2.6098766644155225
Validation loss: 2.4906259955955927

Epoch: 6| Step: 9
Training loss: 2.42847385330686
Validation loss: 2.499930410544595

Epoch: 6| Step: 10
Training loss: 2.6495458033731674
Validation loss: 2.4963154990609606

Epoch: 6| Step: 11
Training loss: 2.968189547992186
Validation loss: 2.5138429711823704

Epoch: 6| Step: 12
Training loss: 2.454549096647444
Validation loss: 2.510715356730493

Epoch: 6| Step: 13
Training loss: 3.279332209039464
Validation loss: 2.5122687038278433

Epoch: 171| Step: 0
Training loss: 2.5233157101934998
Validation loss: 2.5145013483478387

Epoch: 6| Step: 1
Training loss: 2.606998297757733
Validation loss: 2.538452376017275

Epoch: 6| Step: 2
Training loss: 2.598886390765655
Validation loss: 2.524968487877875

Epoch: 6| Step: 3
Training loss: 2.2834805596586785
Validation loss: 2.5353712882523913

Epoch: 6| Step: 4
Training loss: 3.2741112937397143
Validation loss: 2.5473044465147905

Epoch: 6| Step: 5
Training loss: 2.3768350639268303
Validation loss: 2.5440940327384243

Epoch: 6| Step: 6
Training loss: 2.669821144999991
Validation loss: 2.538294813089421

Epoch: 6| Step: 7
Training loss: 2.319787373829298
Validation loss: 2.5262756601254788

Epoch: 6| Step: 8
Training loss: 2.643030278783319
Validation loss: 2.5097452303239436

Epoch: 6| Step: 9
Training loss: 2.6529937531950933
Validation loss: 2.4907393361236525

Epoch: 6| Step: 10
Training loss: 2.9808712508772732
Validation loss: 2.491791503297153

Epoch: 6| Step: 11
Training loss: 3.266582147971081
Validation loss: 2.4814010355109453

Epoch: 6| Step: 12
Training loss: 3.083337388594426
Validation loss: 2.4692696631509876

Epoch: 6| Step: 13
Training loss: 2.6018828690222255
Validation loss: 2.476219834934634

Epoch: 172| Step: 0
Training loss: 2.6548161844247327
Validation loss: 2.479257052697203

Epoch: 6| Step: 1
Training loss: 2.525087460806635
Validation loss: 2.4840580898129025

Epoch: 6| Step: 2
Training loss: 2.910434786376763
Validation loss: 2.4826921493202594

Epoch: 6| Step: 3
Training loss: 2.4084628940390362
Validation loss: 2.488433648287415

Epoch: 6| Step: 4
Training loss: 2.8805745025995866
Validation loss: 2.4911533230916136

Epoch: 6| Step: 5
Training loss: 3.141354907796679
Validation loss: 2.4819069891848753

Epoch: 6| Step: 6
Training loss: 2.937258122002313
Validation loss: 2.487889329356214

Epoch: 6| Step: 7
Training loss: 2.437715765377702
Validation loss: 2.4923123188813068

Epoch: 6| Step: 8
Training loss: 2.4119683228305746
Validation loss: 2.4915399395766955

Epoch: 6| Step: 9
Training loss: 3.312505182226194
Validation loss: 2.5293712178546333

Epoch: 6| Step: 10
Training loss: 2.5794477364054913
Validation loss: 2.5381403230452033

Epoch: 6| Step: 11
Training loss: 2.4558139326582498
Validation loss: 2.5775181120344777

Epoch: 6| Step: 12
Training loss: 2.7833908071313647
Validation loss: 2.55126600573485

Epoch: 6| Step: 13
Training loss: 2.8708100678304445
Validation loss: 2.524177046940109

Epoch: 173| Step: 0
Training loss: 2.9525796699595586
Validation loss: 2.502827237274191

Epoch: 6| Step: 1
Training loss: 3.292300843259816
Validation loss: 2.478117898753111

Epoch: 6| Step: 2
Training loss: 2.994006368534753
Validation loss: 2.4746439588087337

Epoch: 6| Step: 3
Training loss: 2.727782405565337
Validation loss: 2.4902879669708975

Epoch: 6| Step: 4
Training loss: 2.5233722123242006
Validation loss: 2.5208049261705665

Epoch: 6| Step: 5
Training loss: 2.2688518827066746
Validation loss: 2.517661206428978

Epoch: 6| Step: 6
Training loss: 3.206430357978162
Validation loss: 2.514744215058327

Epoch: 6| Step: 7
Training loss: 1.932986015604727
Validation loss: 2.507439071693203

Epoch: 6| Step: 8
Training loss: 2.5120887305874047
Validation loss: 2.4777726924721493

Epoch: 6| Step: 9
Training loss: 3.3283682720838237
Validation loss: 2.469767701207828

Epoch: 6| Step: 10
Training loss: 2.8342744348890467
Validation loss: 2.462005959367682

Epoch: 6| Step: 11
Training loss: 2.6931664810651172
Validation loss: 2.4637162102215795

Epoch: 6| Step: 12
Training loss: 2.5964300258705113
Validation loss: 2.4576912012273526

Epoch: 6| Step: 13
Training loss: 2.662987903431411
Validation loss: 2.4765996609619

Epoch: 174| Step: 0
Training loss: 2.5958395205240823
Validation loss: 2.5017267672823946

Epoch: 6| Step: 1
Training loss: 2.73701898538
Validation loss: 2.5252383789388437

Epoch: 6| Step: 2
Training loss: 3.2204144072568943
Validation loss: 2.5353860024642496

Epoch: 6| Step: 3
Training loss: 2.44602122410996
Validation loss: 2.5201170593646163

Epoch: 6| Step: 4
Training loss: 2.333561738506323
Validation loss: 2.5202481994081802

Epoch: 6| Step: 5
Training loss: 2.936333932143885
Validation loss: 2.5101508720356707

Epoch: 6| Step: 6
Training loss: 2.629122630222587
Validation loss: 2.5075538892159925

Epoch: 6| Step: 7
Training loss: 2.529802827049966
Validation loss: 2.4859759419140164

Epoch: 6| Step: 8
Training loss: 2.5174402357506267
Validation loss: 2.4760281150694445

Epoch: 6| Step: 9
Training loss: 2.9903788466283507
Validation loss: 2.4820212742588814

Epoch: 6| Step: 10
Training loss: 3.068818405849563
Validation loss: 2.480347706130693

Epoch: 6| Step: 11
Training loss: 2.5957725636169218
Validation loss: 2.4712391946347974

Epoch: 6| Step: 12
Training loss: 2.742102814586674
Validation loss: 2.467354800408117

Epoch: 6| Step: 13
Training loss: 2.9234308190730713
Validation loss: 2.4704725051596035

Epoch: 175| Step: 0
Training loss: 2.9880709306093354
Validation loss: 2.4812894835848316

Epoch: 6| Step: 1
Training loss: 2.0109254921152266
Validation loss: 2.479539001175679

Epoch: 6| Step: 2
Training loss: 2.5192568134209288
Validation loss: 2.4915871416697732

Epoch: 6| Step: 3
Training loss: 3.337786052889442
Validation loss: 2.501634243083074

Epoch: 6| Step: 4
Training loss: 2.349177269272854
Validation loss: 2.486427688638338

Epoch: 6| Step: 5
Training loss: 2.613052609053845
Validation loss: 2.4937459788101255

Epoch: 6| Step: 6
Training loss: 3.1547160434045662
Validation loss: 2.4917724008569735

Epoch: 6| Step: 7
Training loss: 2.6535612971972964
Validation loss: 2.489097139617159

Epoch: 6| Step: 8
Training loss: 3.031381505886139
Validation loss: 2.484294593641351

Epoch: 6| Step: 9
Training loss: 2.3094429222927606
Validation loss: 2.4768538144060974

Epoch: 6| Step: 10
Training loss: 3.3193054826309565
Validation loss: 2.4838169405254877

Epoch: 6| Step: 11
Training loss: 2.637397283208178
Validation loss: 2.484995763329445

Epoch: 6| Step: 12
Training loss: 2.2517059005191733
Validation loss: 2.4854214796946583

Epoch: 6| Step: 13
Training loss: 2.1894051021648546
Validation loss: 2.4963679622890096

Epoch: 176| Step: 0
Training loss: 2.7283315958317758
Validation loss: 2.5034344892817706

Epoch: 6| Step: 1
Training loss: 2.620122829207959
Validation loss: 2.502459149249484

Epoch: 6| Step: 2
Training loss: 3.1925466640709432
Validation loss: 2.5061257775390553

Epoch: 6| Step: 3
Training loss: 2.4056780246788745
Validation loss: 2.4930699649547896

Epoch: 6| Step: 4
Training loss: 2.081811259887806
Validation loss: 2.497048959947116

Epoch: 6| Step: 5
Training loss: 2.769151153092423
Validation loss: 2.4838603332716978

Epoch: 6| Step: 6
Training loss: 3.384711527625972
Validation loss: 2.477317197413313

Epoch: 6| Step: 7
Training loss: 2.5757574134119428
Validation loss: 2.479957369334769

Epoch: 6| Step: 8
Training loss: 2.4559343130292697
Validation loss: 2.4766637470168145

Epoch: 6| Step: 9
Training loss: 2.412615197154029
Validation loss: 2.4747896845292194

Epoch: 6| Step: 10
Training loss: 2.4471703440026236
Validation loss: 2.465525501504621

Epoch: 6| Step: 11
Training loss: 3.1517011136318063
Validation loss: 2.4649861518903355

Epoch: 6| Step: 12
Training loss: 2.905687995633101
Validation loss: 2.4661514575484067

Epoch: 6| Step: 13
Training loss: 2.0949498624424074
Validation loss: 2.474122290022246

Epoch: 177| Step: 0
Training loss: 3.344232542211549
Validation loss: 2.468111043009509

Epoch: 6| Step: 1
Training loss: 2.5647713433978465
Validation loss: 2.477636820917468

Epoch: 6| Step: 2
Training loss: 3.2425867777016073
Validation loss: 2.473764389717442

Epoch: 6| Step: 3
Training loss: 2.457982884228728
Validation loss: 2.473451717988483

Epoch: 6| Step: 4
Training loss: 2.2417617021384775
Validation loss: 2.4732338636116395

Epoch: 6| Step: 5
Training loss: 2.092763184252181
Validation loss: 2.4755715275121557

Epoch: 6| Step: 6
Training loss: 2.7412674710838525
Validation loss: 2.4739604414114313

Epoch: 6| Step: 7
Training loss: 2.902991981045866
Validation loss: 2.497941127135526

Epoch: 6| Step: 8
Training loss: 1.8549668446377148
Validation loss: 2.505032042459569

Epoch: 6| Step: 9
Training loss: 2.8373508767085176
Validation loss: 2.5127090576094866

Epoch: 6| Step: 10
Training loss: 2.646247611065031
Validation loss: 2.5085331236651642

Epoch: 6| Step: 11
Training loss: 2.5170470773373452
Validation loss: 2.511628897628787

Epoch: 6| Step: 12
Training loss: 3.014816887452398
Validation loss: 2.4891660473346806

Epoch: 6| Step: 13
Training loss: 2.78920850184644
Validation loss: 2.494112072793892

Epoch: 178| Step: 0
Training loss: 3.1233882562401285
Validation loss: 2.489186012244002

Epoch: 6| Step: 1
Training loss: 2.8080884455040653
Validation loss: 2.481740305581895

Epoch: 6| Step: 2
Training loss: 2.6414952396001166
Validation loss: 2.4617805439381737

Epoch: 6| Step: 3
Training loss: 2.7207309039601686
Validation loss: 2.471640000573875

Epoch: 6| Step: 4
Training loss: 3.1225212947953125
Validation loss: 2.4551586507603314

Epoch: 6| Step: 5
Training loss: 2.043599777066959
Validation loss: 2.468329785743477

Epoch: 6| Step: 6
Training loss: 2.790858868307181
Validation loss: 2.4569055783448577

Epoch: 6| Step: 7
Training loss: 2.829360270629321
Validation loss: 2.455566980978503

Epoch: 6| Step: 8
Training loss: 2.6024028348785917
Validation loss: 2.4795694762459037

Epoch: 6| Step: 9
Training loss: 2.5067615624314548
Validation loss: 2.4919767565504682

Epoch: 6| Step: 10
Training loss: 2.2528765622122817
Validation loss: 2.4963405724027727

Epoch: 6| Step: 11
Training loss: 2.5410874962813312
Validation loss: 2.5063046564167246

Epoch: 6| Step: 12
Training loss: 2.714568155694681
Validation loss: 2.5092729439461667

Epoch: 6| Step: 13
Training loss: 2.691854542020562
Validation loss: 2.496348673046069

Epoch: 179| Step: 0
Training loss: 2.3786124813803466
Validation loss: 2.4878470486841993

Epoch: 6| Step: 1
Training loss: 2.5833568777016387
Validation loss: 2.46692570544536

Epoch: 6| Step: 2
Training loss: 3.1760412956647115
Validation loss: 2.472704292596185

Epoch: 6| Step: 3
Training loss: 2.1069964526580653
Validation loss: 2.4606532075728205

Epoch: 6| Step: 4
Training loss: 2.330494129683396
Validation loss: 2.4702848640160004

Epoch: 6| Step: 5
Training loss: 2.7691572660488837
Validation loss: 2.4621964210837266

Epoch: 6| Step: 6
Training loss: 2.8144305914586316
Validation loss: 2.4551382566920315

Epoch: 6| Step: 7
Training loss: 2.5888751075534264
Validation loss: 2.4673965553087363

Epoch: 6| Step: 8
Training loss: 2.925843017903982
Validation loss: 2.452724570673999

Epoch: 6| Step: 9
Training loss: 2.476752240827707
Validation loss: 2.453600913412364

Epoch: 6| Step: 10
Training loss: 2.632167205062029
Validation loss: 2.4684994353512613

Epoch: 6| Step: 11
Training loss: 2.830115866294239
Validation loss: 2.4769143510353793

Epoch: 6| Step: 12
Training loss: 2.918222030820649
Validation loss: 2.480592508081414

Epoch: 6| Step: 13
Training loss: 2.8429435173271385
Validation loss: 2.4702117131612185

Epoch: 180| Step: 0
Training loss: 2.197550545763187
Validation loss: 2.4709961531568365

Epoch: 6| Step: 1
Training loss: 2.4361890544285014
Validation loss: 2.4677059790058524

Epoch: 6| Step: 2
Training loss: 2.604980514512066
Validation loss: 2.4567443355643093

Epoch: 6| Step: 3
Training loss: 2.768081694604654
Validation loss: 2.46671485532314

Epoch: 6| Step: 4
Training loss: 2.840568859187649
Validation loss: 2.4591296645826284

Epoch: 6| Step: 5
Training loss: 2.373114088072064
Validation loss: 2.454641818601944

Epoch: 6| Step: 6
Training loss: 2.8813845191385594
Validation loss: 2.472492047131633

Epoch: 6| Step: 7
Training loss: 2.4742401497929936
Validation loss: 2.452613325219098

Epoch: 6| Step: 8
Training loss: 2.63712851272033
Validation loss: 2.4597399934797393

Epoch: 6| Step: 9
Training loss: 2.3927481205551935
Validation loss: 2.4621287743862252

Epoch: 6| Step: 10
Training loss: 3.1982933261655835
Validation loss: 2.4686907003977434

Epoch: 6| Step: 11
Training loss: 2.9721881432723585
Validation loss: 2.474271717440536

Epoch: 6| Step: 12
Training loss: 2.709845859043084
Validation loss: 2.486605494720371

Epoch: 6| Step: 13
Training loss: 2.454085435370309
Validation loss: 2.5061172839732264

Epoch: 181| Step: 0
Training loss: 2.2458415279581
Validation loss: 2.5413121608810307

Epoch: 6| Step: 1
Training loss: 2.9859008084153285
Validation loss: 2.5707250012804144

Epoch: 6| Step: 2
Training loss: 2.877548083741289
Validation loss: 2.5871484836432797

Epoch: 6| Step: 3
Training loss: 2.7311279199757372
Validation loss: 2.5745183343481104

Epoch: 6| Step: 4
Training loss: 2.763748394341522
Validation loss: 2.552346577899805

Epoch: 6| Step: 5
Training loss: 3.0583667500374077
Validation loss: 2.5332259195328617

Epoch: 6| Step: 6
Training loss: 2.162628469895768
Validation loss: 2.497517593062165

Epoch: 6| Step: 7
Training loss: 1.9031119861377064
Validation loss: 2.473070357350166

Epoch: 6| Step: 8
Training loss: 2.7313032935069343
Validation loss: 2.4513739596334885

Epoch: 6| Step: 9
Training loss: 2.8221681360216784
Validation loss: 2.4478035524756847

Epoch: 6| Step: 10
Training loss: 2.243730711787634
Validation loss: 2.460186566543885

Epoch: 6| Step: 11
Training loss: 2.8461940449276883
Validation loss: 2.458678841926274

Epoch: 6| Step: 12
Training loss: 2.8152250863265142
Validation loss: 2.4530306541202656

Epoch: 6| Step: 13
Training loss: 2.8509606131164813
Validation loss: 2.4486394153424906

Epoch: 182| Step: 0
Training loss: 2.374418488636678
Validation loss: 2.4627434894102382

Epoch: 6| Step: 1
Training loss: 2.4152167563772915
Validation loss: 2.466231778713708

Epoch: 6| Step: 2
Training loss: 2.7757221107184695
Validation loss: 2.4875365943585277

Epoch: 6| Step: 3
Training loss: 2.416572031820953
Validation loss: 2.519217263393766

Epoch: 6| Step: 4
Training loss: 2.5718040892233507
Validation loss: 2.5661949382508973

Epoch: 6| Step: 5
Training loss: 2.8140881610825073
Validation loss: 2.5540275432525625

Epoch: 6| Step: 6
Training loss: 2.1004626718104147
Validation loss: 2.5538687860320355

Epoch: 6| Step: 7
Training loss: 2.6385141095392672
Validation loss: 2.5155338848420237

Epoch: 6| Step: 8
Training loss: 2.9211779084163343
Validation loss: 2.4974015103553566

Epoch: 6| Step: 9
Training loss: 2.6749556778417785
Validation loss: 2.467481914436156

Epoch: 6| Step: 10
Training loss: 2.9528149638840393
Validation loss: 2.4521327251238807

Epoch: 6| Step: 11
Training loss: 3.2149103466009947
Validation loss: 2.4600364503045022

Epoch: 6| Step: 12
Training loss: 2.7953754006436564
Validation loss: 2.453012069193883

Epoch: 6| Step: 13
Training loss: 2.2004061757450226
Validation loss: 2.4600960033237667

Epoch: 183| Step: 0
Training loss: 2.9729241189059064
Validation loss: 2.4441754812934446

Epoch: 6| Step: 1
Training loss: 2.3402378470023066
Validation loss: 2.443461528832975

Epoch: 6| Step: 2
Training loss: 2.293665193658256
Validation loss: 2.4408698398452184

Epoch: 6| Step: 3
Training loss: 2.08787166918722
Validation loss: 2.444983262476766

Epoch: 6| Step: 4
Training loss: 2.684869321488109
Validation loss: 2.4457361427743205

Epoch: 6| Step: 5
Training loss: 2.8062295313982863
Validation loss: 2.455936248336676

Epoch: 6| Step: 6
Training loss: 2.5293620097489176
Validation loss: 2.4507400721322687

Epoch: 6| Step: 7
Training loss: 2.8418790929902005
Validation loss: 2.479747982918296

Epoch: 6| Step: 8
Training loss: 2.8682335548697497
Validation loss: 2.5139995141863243

Epoch: 6| Step: 9
Training loss: 2.73223584014214
Validation loss: 2.5607652652477926

Epoch: 6| Step: 10
Training loss: 3.2375830621263573
Validation loss: 2.617177704578644

Epoch: 6| Step: 11
Training loss: 2.5068659912495317
Validation loss: 2.6397199580341

Epoch: 6| Step: 12
Training loss: 2.8308350450542203
Validation loss: 2.6356149372144113

Epoch: 6| Step: 13
Training loss: 2.386948894386736
Validation loss: 2.6045229136946926

Epoch: 184| Step: 0
Training loss: 2.4633847617466333
Validation loss: 2.5776395647110215

Epoch: 6| Step: 1
Training loss: 2.49161209591036
Validation loss: 2.522156997298562

Epoch: 6| Step: 2
Training loss: 2.8228541199533925
Validation loss: 2.483183715694697

Epoch: 6| Step: 3
Training loss: 2.443198853608757
Validation loss: 2.4552248010979305

Epoch: 6| Step: 4
Training loss: 2.5765648022347016
Validation loss: 2.437032988777232

Epoch: 6| Step: 5
Training loss: 2.3696639700778683
Validation loss: 2.448473964099526

Epoch: 6| Step: 6
Training loss: 2.792120702080075
Validation loss: 2.44947531219358

Epoch: 6| Step: 7
Training loss: 2.577829054983815
Validation loss: 2.4520899272329637

Epoch: 6| Step: 8
Training loss: 2.707040057367527
Validation loss: 2.4591930690860395

Epoch: 6| Step: 9
Training loss: 2.2642194926483326
Validation loss: 2.4705116753894734

Epoch: 6| Step: 10
Training loss: 2.4674790406423965
Validation loss: 2.462077479772593

Epoch: 6| Step: 11
Training loss: 3.3829841834501138
Validation loss: 2.460996465567416

Epoch: 6| Step: 12
Training loss: 2.886532417447041
Validation loss: 2.4588965950294717

Epoch: 6| Step: 13
Training loss: 3.294151880983971
Validation loss: 2.481402405457397

Epoch: 185| Step: 0
Training loss: 2.731309229298027
Validation loss: 2.486412504263142

Epoch: 6| Step: 1
Training loss: 3.046367270396427
Validation loss: 2.507766773817892

Epoch: 6| Step: 2
Training loss: 1.876046587993882
Validation loss: 2.5230303161873415

Epoch: 6| Step: 3
Training loss: 2.6646836974505055
Validation loss: 2.5533022138171293

Epoch: 6| Step: 4
Training loss: 2.5130522467407306
Validation loss: 2.597436250617756

Epoch: 6| Step: 5
Training loss: 3.550177158717064
Validation loss: 2.613825956795656

Epoch: 6| Step: 6
Training loss: 2.444387047508005
Validation loss: 2.5593003236185226

Epoch: 6| Step: 7
Training loss: 2.713043362387311
Validation loss: 2.525227112142219

Epoch: 6| Step: 8
Training loss: 2.762576562157108
Validation loss: 2.490162824245841

Epoch: 6| Step: 9
Training loss: 2.476391133537804
Validation loss: 2.470857697943132

Epoch: 6| Step: 10
Training loss: 1.864946241243176
Validation loss: 2.4535253284477183

Epoch: 6| Step: 11
Training loss: 2.877060359243438
Validation loss: 2.4476237467185156

Epoch: 6| Step: 12
Training loss: 2.761178618061469
Validation loss: 2.4550868810265745

Epoch: 6| Step: 13
Training loss: 2.361017627984709
Validation loss: 2.4454165945025013

Epoch: 186| Step: 0
Training loss: 2.959745383523814
Validation loss: 2.4482077469801826

Epoch: 6| Step: 1
Training loss: 2.593817836379948
Validation loss: 2.4586750903236303

Epoch: 6| Step: 2
Training loss: 2.5884565087375395
Validation loss: 2.471307049430964

Epoch: 6| Step: 3
Training loss: 2.4888225547526304
Validation loss: 2.467029417966575

Epoch: 6| Step: 4
Training loss: 2.5384494452199555
Validation loss: 2.481328078054282

Epoch: 6| Step: 5
Training loss: 3.087854335699554
Validation loss: 2.478313500542734

Epoch: 6| Step: 6
Training loss: 2.4913359236458343
Validation loss: 2.483126882933749

Epoch: 6| Step: 7
Training loss: 2.811439738165602
Validation loss: 2.4938470925640583

Epoch: 6| Step: 8
Training loss: 3.1096252647400098
Validation loss: 2.4956628791940108

Epoch: 6| Step: 9
Training loss: 2.223400561199442
Validation loss: 2.5120326594471987

Epoch: 6| Step: 10
Training loss: 1.9824396142024985
Validation loss: 2.5168746772092683

Epoch: 6| Step: 11
Training loss: 2.5033135389552
Validation loss: 2.53401511699992

Epoch: 6| Step: 12
Training loss: 2.6505737691190547
Validation loss: 2.5551119933358737

Epoch: 6| Step: 13
Training loss: 2.6550241671107053
Validation loss: 2.564096054798735

Epoch: 187| Step: 0
Training loss: 2.8602133600638764
Validation loss: 2.5665186722556665

Epoch: 6| Step: 1
Training loss: 2.578083569742867
Validation loss: 2.563866167829907

Epoch: 6| Step: 2
Training loss: 2.3017774928226324
Validation loss: 2.541949232913746

Epoch: 6| Step: 3
Training loss: 2.6958035671314393
Validation loss: 2.544218389889413

Epoch: 6| Step: 4
Training loss: 2.647637440515309
Validation loss: 2.5471590669963486

Epoch: 6| Step: 5
Training loss: 2.508132676455749
Validation loss: 2.5509290470993653

Epoch: 6| Step: 6
Training loss: 2.247475161134056
Validation loss: 2.537997449917314

Epoch: 6| Step: 7
Training loss: 2.4279485532849914
Validation loss: 2.5293863723877763

Epoch: 6| Step: 8
Training loss: 2.804212949766683
Validation loss: 2.5119908912830056

Epoch: 6| Step: 9
Training loss: 2.4880803145358494
Validation loss: 2.5003511623149253

Epoch: 6| Step: 10
Training loss: 2.899462577745416
Validation loss: 2.5174473652238194

Epoch: 6| Step: 11
Training loss: 2.6527533460715857
Validation loss: 2.5100665748077624

Epoch: 6| Step: 12
Training loss: 2.633410286885564
Validation loss: 2.5174266376578602

Epoch: 6| Step: 13
Training loss: 2.4784014399734264
Validation loss: 2.5092896011449346

Epoch: 188| Step: 0
Training loss: 2.3025913857415437
Validation loss: 2.492594879509753

Epoch: 6| Step: 1
Training loss: 2.349721194022012
Validation loss: 2.4655386475954337

Epoch: 6| Step: 2
Training loss: 2.3484029740709937
Validation loss: 2.44914567859352

Epoch: 6| Step: 3
Training loss: 3.002178037280484
Validation loss: 2.4372564235638525

Epoch: 6| Step: 4
Training loss: 2.01097931836921
Validation loss: 2.4380725706621966

Epoch: 6| Step: 5
Training loss: 2.1783830574662835
Validation loss: 2.43492512448701

Epoch: 6| Step: 6
Training loss: 2.7875296176311997
Validation loss: 2.423989108452427

Epoch: 6| Step: 7
Training loss: 3.0136164958659344
Validation loss: 2.429927616093777

Epoch: 6| Step: 8
Training loss: 2.890598606298421
Validation loss: 2.4346282287247747

Epoch: 6| Step: 9
Training loss: 2.2862956018837797
Validation loss: 2.4579078110681962

Epoch: 6| Step: 10
Training loss: 2.515883817449457
Validation loss: 2.510207462150621

Epoch: 6| Step: 11
Training loss: 2.5812739705965533
Validation loss: 2.5186879679979906

Epoch: 6| Step: 12
Training loss: 3.2184565141817902
Validation loss: 2.5157058856698735

Epoch: 6| Step: 13
Training loss: 2.6637950774182197
Validation loss: 2.535081686446578

Epoch: 189| Step: 0
Training loss: 2.626161409215629
Validation loss: 2.5365192518625306

Epoch: 6| Step: 1
Training loss: 2.538891595810723
Validation loss: 2.5402205832025997

Epoch: 6| Step: 2
Training loss: 2.3515225530634227
Validation loss: 2.5305793523991236

Epoch: 6| Step: 3
Training loss: 1.9600082566612875
Validation loss: 2.555386763708733

Epoch: 6| Step: 4
Training loss: 1.7801064283721317
Validation loss: 2.5600071708837695

Epoch: 6| Step: 5
Training loss: 2.8808479541616836
Validation loss: 2.5759701859353235

Epoch: 6| Step: 6
Training loss: 2.7999230510492383
Validation loss: 2.59468145605028

Epoch: 6| Step: 7
Training loss: 2.9776676559329878
Validation loss: 2.5930923940868116

Epoch: 6| Step: 8
Training loss: 2.560646596402694
Validation loss: 2.609599133742332

Epoch: 6| Step: 9
Training loss: 2.756579590897856
Validation loss: 2.604381772581317

Epoch: 6| Step: 10
Training loss: 2.9155714612749217
Validation loss: 2.59885752347985

Epoch: 6| Step: 11
Training loss: 2.5089339841426455
Validation loss: 2.5790066491509984

Epoch: 6| Step: 12
Training loss: 2.2203266827897434
Validation loss: 2.5114024800171215

Epoch: 6| Step: 13
Training loss: 3.090383219735737
Validation loss: 2.4882459753426804

Epoch: 190| Step: 0
Training loss: 2.6393125082499864
Validation loss: 2.458250345407865

Epoch: 6| Step: 1
Training loss: 2.6015383974167365
Validation loss: 2.46412582216738

Epoch: 6| Step: 2
Training loss: 2.924701486336629
Validation loss: 2.460147673755401

Epoch: 6| Step: 3
Training loss: 3.0121845127648523
Validation loss: 2.453317854483801

Epoch: 6| Step: 4
Training loss: 2.7011083235474116
Validation loss: 2.446502574183042

Epoch: 6| Step: 5
Training loss: 2.5436846638004798
Validation loss: 2.4347728411057186

Epoch: 6| Step: 6
Training loss: 2.7194467287591944
Validation loss: 2.4543393141111003

Epoch: 6| Step: 7
Training loss: 2.714994884647728
Validation loss: 2.492916423748117

Epoch: 6| Step: 8
Training loss: 2.955346296386835
Validation loss: 2.524867968588293

Epoch: 6| Step: 9
Training loss: 2.833274915504348
Validation loss: 2.5287073263352036

Epoch: 6| Step: 10
Training loss: 2.241692890548
Validation loss: 2.556862396955062

Epoch: 6| Step: 11
Training loss: 2.746190293244258
Validation loss: 2.5622587963347456

Epoch: 6| Step: 12
Training loss: 1.658322962372266
Validation loss: 2.5590792738453665

Epoch: 6| Step: 13
Training loss: 1.7591086123290094
Validation loss: 2.526279931375241

Epoch: 191| Step: 0
Training loss: 2.1821380294093524
Validation loss: 2.5201441318379048

Epoch: 6| Step: 1
Training loss: 2.864844921768236
Validation loss: 2.5198644859193453

Epoch: 6| Step: 2
Training loss: 2.4899155356547387
Validation loss: 2.4901762932525267

Epoch: 6| Step: 3
Training loss: 2.5930875368830084
Validation loss: 2.4644013414045607

Epoch: 6| Step: 4
Training loss: 2.885913700486852
Validation loss: 2.4515328602685407

Epoch: 6| Step: 5
Training loss: 2.7558285760814423
Validation loss: 2.4545826732239195

Epoch: 6| Step: 6
Training loss: 2.0583867759819467
Validation loss: 2.46321585008127

Epoch: 6| Step: 7
Training loss: 2.758214818553937
Validation loss: 2.47709425578276

Epoch: 6| Step: 8
Training loss: 2.493313334770714
Validation loss: 2.4671645820853825

Epoch: 6| Step: 9
Training loss: 1.7279080632442265
Validation loss: 2.490807082713198

Epoch: 6| Step: 10
Training loss: 2.6506543629141355
Validation loss: 2.487447885416839

Epoch: 6| Step: 11
Training loss: 2.378322786585362
Validation loss: 2.5257743312558905

Epoch: 6| Step: 12
Training loss: 2.6166888772625234
Validation loss: 2.5381217280145982

Epoch: 6| Step: 13
Training loss: 3.2058668357527114
Validation loss: 2.5810287157866045

Epoch: 192| Step: 0
Training loss: 1.949548483195552
Validation loss: 2.6970428928238874

Epoch: 6| Step: 1
Training loss: 2.9219905402038893
Validation loss: 2.7935259386513556

Epoch: 6| Step: 2
Training loss: 3.081273361643657
Validation loss: 2.787148472620466

Epoch: 6| Step: 3
Training loss: 2.8940114572610627
Validation loss: 2.669985414063969

Epoch: 6| Step: 4
Training loss: 2.403331026489731
Validation loss: 2.509449731012861

Epoch: 6| Step: 5
Training loss: 2.725797529491772
Validation loss: 2.463504589531716

Epoch: 6| Step: 6
Training loss: 2.3701149744401495
Validation loss: 2.4557598670908507

Epoch: 6| Step: 7
Training loss: 3.1094832665078584
Validation loss: 2.4593359868419333

Epoch: 6| Step: 8
Training loss: 2.435082630737213
Validation loss: 2.5031198589997325

Epoch: 6| Step: 9
Training loss: 2.850599988724362
Validation loss: 2.5192147091316346

Epoch: 6| Step: 10
Training loss: 2.673809399758665
Validation loss: 2.4858018458155984

Epoch: 6| Step: 11
Training loss: 2.851851608043328
Validation loss: 2.4667357221691217

Epoch: 6| Step: 12
Training loss: 3.1584537479793813
Validation loss: 2.4522757888192346

Epoch: 6| Step: 13
Training loss: 1.064862317870058
Validation loss: 2.465250098545693

Epoch: 193| Step: 0
Training loss: 2.6522761520288745
Validation loss: 2.4843496562676086

Epoch: 6| Step: 1
Training loss: 2.675264316940819
Validation loss: 2.530277836754957

Epoch: 6| Step: 2
Training loss: 3.217128308100448
Validation loss: 2.570324263358917

Epoch: 6| Step: 3
Training loss: 2.93536396687736
Validation loss: 2.5922293585910055

Epoch: 6| Step: 4
Training loss: 2.6470842983540916
Validation loss: 2.55666447150187

Epoch: 6| Step: 5
Training loss: 2.2952741376918318
Validation loss: 2.5261374165019763

Epoch: 6| Step: 6
Training loss: 2.6775892400606875
Validation loss: 2.490924498840435

Epoch: 6| Step: 7
Training loss: 2.447027512982229
Validation loss: 2.4726864516892326

Epoch: 6| Step: 8
Training loss: 2.316833765420868
Validation loss: 2.4433898296969647

Epoch: 6| Step: 9
Training loss: 2.3157428994583147
Validation loss: 2.4482176634701864

Epoch: 6| Step: 10
Training loss: 2.1954745304139354
Validation loss: 2.451567553150412

Epoch: 6| Step: 11
Training loss: 3.0704743243176527
Validation loss: 2.4555076814424686

Epoch: 6| Step: 12
Training loss: 2.446405623470552
Validation loss: 2.4668809953390465

Epoch: 6| Step: 13
Training loss: 2.5089894797878847
Validation loss: 2.4687061163129096

Epoch: 194| Step: 0
Training loss: 2.9479502394059627
Validation loss: 2.4637113362411407

Epoch: 6| Step: 1
Training loss: 2.7338507449438207
Validation loss: 2.453645304956221

Epoch: 6| Step: 2
Training loss: 2.4949735656132974
Validation loss: 2.4565062041213754

Epoch: 6| Step: 3
Training loss: 2.287035568701301
Validation loss: 2.456731021366723

Epoch: 6| Step: 4
Training loss: 2.3136757619562043
Validation loss: 2.461015583967009

Epoch: 6| Step: 5
Training loss: 2.6712256640841696
Validation loss: 2.4514426665172877

Epoch: 6| Step: 6
Training loss: 2.127721950550057
Validation loss: 2.4561147952833955

Epoch: 6| Step: 7
Training loss: 3.111069873884685
Validation loss: 2.4470250845167087

Epoch: 6| Step: 8
Training loss: 2.703721350007942
Validation loss: 2.463682771649982

Epoch: 6| Step: 9
Training loss: 2.4012260007676693
Validation loss: 2.471439386339071

Epoch: 6| Step: 10
Training loss: 2.364563951678954
Validation loss: 2.4672276528150228

Epoch: 6| Step: 11
Training loss: 2.540291450630082
Validation loss: 2.4803110416355576

Epoch: 6| Step: 12
Training loss: 2.1643563081450283
Validation loss: 2.4854496727366184

Epoch: 6| Step: 13
Training loss: 2.794631399098964
Validation loss: 2.4957181481145754

Epoch: 195| Step: 0
Training loss: 2.7078216851943178
Validation loss: 2.5038207073777135

Epoch: 6| Step: 1
Training loss: 2.6501921746010977
Validation loss: 2.5035359152259526

Epoch: 6| Step: 2
Training loss: 2.5339083428911433
Validation loss: 2.527239404518068

Epoch: 6| Step: 3
Training loss: 3.0796495718824413
Validation loss: 2.5008149956674104

Epoch: 6| Step: 4
Training loss: 2.3135292237239318
Validation loss: 2.5012355868480656

Epoch: 6| Step: 5
Training loss: 2.6784853004050784
Validation loss: 2.5135550747472353

Epoch: 6| Step: 6
Training loss: 2.676402221797807
Validation loss: 2.522142982478974

Epoch: 6| Step: 7
Training loss: 2.1513423632532835
Validation loss: 2.521950767387237

Epoch: 6| Step: 8
Training loss: 2.6017632850856884
Validation loss: 2.524600778666981

Epoch: 6| Step: 9
Training loss: 2.546966176653528
Validation loss: 2.537780400662628

Epoch: 6| Step: 10
Training loss: 2.2820107223700155
Validation loss: 2.552044285334662

Epoch: 6| Step: 11
Training loss: 1.848805237641915
Validation loss: 2.549734462534599

Epoch: 6| Step: 12
Training loss: 2.2295065172146806
Validation loss: 2.549621918582568

Epoch: 6| Step: 13
Training loss: 1.7907841157370212
Validation loss: 2.554006807413838

Epoch: 196| Step: 0
Training loss: 2.6672680494573937
Validation loss: 2.53625502795673

Epoch: 6| Step: 1
Training loss: 2.5008685510586264
Validation loss: 2.5314568562049176

Epoch: 6| Step: 2
Training loss: 2.3329789937132785
Validation loss: 2.5165779124468717

Epoch: 6| Step: 3
Training loss: 2.1133138544807495
Validation loss: 2.5314118214458987

Epoch: 6| Step: 4
Training loss: 2.365246672720404
Validation loss: 2.5143401953380704

Epoch: 6| Step: 5
Training loss: 2.6265798083659244
Validation loss: 2.492674293568644

Epoch: 6| Step: 6
Training loss: 2.700668630108496
Validation loss: 2.518213239827855

Epoch: 6| Step: 7
Training loss: 2.3681189589777007
Validation loss: 2.5466474840006206

Epoch: 6| Step: 8
Training loss: 2.647008639838541
Validation loss: 2.559954345469715

Epoch: 6| Step: 9
Training loss: 2.5527859298064866
Validation loss: 2.5909119908879417

Epoch: 6| Step: 10
Training loss: 2.6999819790274073
Validation loss: 2.5990674520826107

Epoch: 6| Step: 11
Training loss: 2.040627299332309
Validation loss: 2.578455605786379

Epoch: 6| Step: 12
Training loss: 2.4300721284184976
Validation loss: 2.6077553866739103

Epoch: 6| Step: 13
Training loss: 2.232997336188306
Validation loss: 2.577296787552478

Epoch: 197| Step: 0
Training loss: 2.2077364444793837
Validation loss: 2.554887079232317

Epoch: 6| Step: 1
Training loss: 1.9778903526718519
Validation loss: 2.5314618822972292

Epoch: 6| Step: 2
Training loss: 2.2573640899470604
Validation loss: 2.5236276763000247

Epoch: 6| Step: 3
Training loss: 2.3563064932691096
Validation loss: 2.517834285801022

Epoch: 6| Step: 4
Training loss: 2.5387197409873363
Validation loss: 2.523869894364456

Epoch: 6| Step: 5
Training loss: 2.3440557661876475
Validation loss: 2.520138256140009

Epoch: 6| Step: 6
Training loss: 2.0519143307669756
Validation loss: 2.526949731068189

Epoch: 6| Step: 7
Training loss: 2.6129112723024197
Validation loss: 2.5398771578492685

Epoch: 6| Step: 8
Training loss: 2.94272959653661
Validation loss: 2.528715592966678

Epoch: 6| Step: 9
Training loss: 2.6537368554154965
Validation loss: 2.5355505426292413

Epoch: 6| Step: 10
Training loss: 2.5337888441980367
Validation loss: 2.5235635557126193

Epoch: 6| Step: 11
Training loss: 2.4720292343460315
Validation loss: 2.5312605806608373

Epoch: 6| Step: 12
Training loss: 2.376561304176125
Validation loss: 2.5463141568641894

Epoch: 6| Step: 13
Training loss: 2.39460871261583
Validation loss: 2.523151265273997

Epoch: 198| Step: 0
Training loss: 2.0155605335424136
Validation loss: 2.4884549768949342

Epoch: 6| Step: 1
Training loss: 1.723627694530291
Validation loss: 2.506018528173725

Epoch: 6| Step: 2
Training loss: 1.7583438324577163
Validation loss: 2.508811851491238

Epoch: 6| Step: 3
Training loss: 2.9313471861387543
Validation loss: 2.5252201518397834

Epoch: 6| Step: 4
Training loss: 2.3865826906671574
Validation loss: 2.542879017875698

Epoch: 6| Step: 5
Training loss: 2.1962206716647263
Validation loss: 2.5645815460832484

Epoch: 6| Step: 6
Training loss: 2.550719559815847
Validation loss: 2.5736339781962574

Epoch: 6| Step: 7
Training loss: 1.9365506461228374
Validation loss: 2.595431950633823

Epoch: 6| Step: 8
Training loss: 2.3983248705932243
Validation loss: 2.6281817705569863

Epoch: 6| Step: 9
Training loss: 2.231419242189065
Validation loss: 2.60644890550567

Epoch: 6| Step: 10
Training loss: 3.020267056410909
Validation loss: 2.6096513432485877

Epoch: 6| Step: 11
Training loss: 2.628318142682745
Validation loss: 2.547876746480611

Epoch: 6| Step: 12
Training loss: 2.445686579844661
Validation loss: 2.5033692267856456

Epoch: 6| Step: 13
Training loss: 2.708150260802197
Validation loss: 2.4706965050022345

Epoch: 199| Step: 0
Training loss: 2.6291173705624784
Validation loss: 2.455807263129242

Epoch: 6| Step: 1
Training loss: 2.997359385242577
Validation loss: 2.4434983496665157

Epoch: 6| Step: 2
Training loss: 3.0924430167176093
Validation loss: 2.444320101487138

Epoch: 6| Step: 3
Training loss: 2.334095921105407
Validation loss: 2.449244773357396

Epoch: 6| Step: 4
Training loss: 1.9788778261597402
Validation loss: 2.4538328801793767

Epoch: 6| Step: 5
Training loss: 2.0874127946558554
Validation loss: 2.4646620731495297

Epoch: 6| Step: 6
Training loss: 2.539178370252762
Validation loss: 2.482651266081559

Epoch: 6| Step: 7
Training loss: 1.9939268410442053
Validation loss: 2.4960986778339915

Epoch: 6| Step: 8
Training loss: 2.6758979716216404
Validation loss: 2.5047508669548386

Epoch: 6| Step: 9
Training loss: 2.140559954246694
Validation loss: 2.4952692309547517

Epoch: 6| Step: 10
Training loss: 2.113163237881561
Validation loss: 2.5287662211861757

Epoch: 6| Step: 11
Training loss: 2.4370819124489516
Validation loss: 2.5602992161668223

Epoch: 6| Step: 12
Training loss: 2.091887371481404
Validation loss: 2.6023616088834043

Epoch: 6| Step: 13
Training loss: 1.5716128303204115
Validation loss: 2.6905755723735143

Epoch: 200| Step: 0
Training loss: 2.247519715491056
Validation loss: 2.70716576852471

Epoch: 6| Step: 1
Training loss: 1.9794229308077564
Validation loss: 2.672439931890897

Epoch: 6| Step: 2
Training loss: 2.8057919508629108
Validation loss: 2.6427984145625065

Epoch: 6| Step: 3
Training loss: 2.4233740320509236
Validation loss: 2.5890908221522104

Epoch: 6| Step: 4
Training loss: 2.466724095664053
Validation loss: 2.565850715110599

Epoch: 6| Step: 5
Training loss: 2.300808606851367
Validation loss: 2.527369046024818

Epoch: 6| Step: 6
Training loss: 2.5297579665380434
Validation loss: 2.5185464353588873

Epoch: 6| Step: 7
Training loss: 2.261961296398015
Validation loss: 2.49559506513253

Epoch: 6| Step: 8
Training loss: 1.972621320660745
Validation loss: 2.493149330461923

Epoch: 6| Step: 9
Training loss: 2.038559541021262
Validation loss: 2.5001399175395895

Epoch: 6| Step: 10
Training loss: 2.8507588965599875
Validation loss: 2.490239917701506

Epoch: 6| Step: 11
Training loss: 2.1920040083730203
Validation loss: 2.502375729062907

Epoch: 6| Step: 12
Training loss: 2.4555014015524654
Validation loss: 2.505373876498174

Epoch: 6| Step: 13
Training loss: 2.5469739461763683
Validation loss: 2.493736127198556

Epoch: 201| Step: 0
Training loss: 2.9848466270827103
Validation loss: 2.5265612293826467

Epoch: 6| Step: 1
Training loss: 1.7085138861293108
Validation loss: 2.576895051068909

Epoch: 6| Step: 2
Training loss: 2.277419336023185
Validation loss: 2.619404176846428

Epoch: 6| Step: 3
Training loss: 2.262430925526687
Validation loss: 2.643795148547903

Epoch: 6| Step: 4
Training loss: 2.18840062811007
Validation loss: 2.6369404779239263

Epoch: 6| Step: 5
Training loss: 2.2437274177286195
Validation loss: 2.6758115762672143

Epoch: 6| Step: 6
Training loss: 2.4552172831546337
Validation loss: 2.6969094093298875

Epoch: 6| Step: 7
Training loss: 2.090593150171371
Validation loss: 2.678374883430507

Epoch: 6| Step: 8
Training loss: 2.4218867147839154
Validation loss: 2.6179911095243185

Epoch: 6| Step: 9
Training loss: 1.7730916900248987
Validation loss: 2.5573003545010833

Epoch: 6| Step: 10
Training loss: 2.4740132108257
Validation loss: 2.5313903028343137

Epoch: 6| Step: 11
Training loss: 2.421120113735181
Validation loss: 2.4894047094366756

Epoch: 6| Step: 12
Training loss: 2.537692219636815
Validation loss: 2.4448167490424337

Epoch: 6| Step: 13
Training loss: 2.26472613163136
Validation loss: 2.4505576017995043

Epoch: 202| Step: 0
Training loss: 2.3398500674867764
Validation loss: 2.421462139144685

Epoch: 6| Step: 1
Training loss: 2.4653196041755767
Validation loss: 2.4313923273062676

Epoch: 6| Step: 2
Training loss: 2.0644506997605787
Validation loss: 2.427922965827302

Epoch: 6| Step: 3
Training loss: 2.0274533515954216
Validation loss: 2.4434580953760636

Epoch: 6| Step: 4
Training loss: 2.452882208016481
Validation loss: 2.4456983986028624

Epoch: 6| Step: 5
Training loss: 2.0541278961835348
Validation loss: 2.4647632837507567

Epoch: 6| Step: 6
Training loss: 2.853008582924903
Validation loss: 2.512833049953813

Epoch: 6| Step: 7
Training loss: 1.8521545365001937
Validation loss: 2.5442991363562992

Epoch: 6| Step: 8
Training loss: 2.4236161402881207
Validation loss: 2.5806353496421393

Epoch: 6| Step: 9
Training loss: 2.651532370688934
Validation loss: 2.676088041737972

Epoch: 6| Step: 10
Training loss: 1.7041856455348465
Validation loss: 2.7631826525118304

Epoch: 6| Step: 11
Training loss: 2.385781361605313
Validation loss: 2.782060556444304

Epoch: 6| Step: 12
Training loss: 2.3439821255493865
Validation loss: 2.8244281565727216

Epoch: 6| Step: 13
Training loss: 2.3554846413552353
Validation loss: 2.767574940337751

Epoch: 203| Step: 0
Training loss: 2.3934835659185683
Validation loss: 2.640852379855741

Epoch: 6| Step: 1
Training loss: 2.2575030791302844
Validation loss: 2.593631103652929

Epoch: 6| Step: 2
Training loss: 2.1600782163021814
Validation loss: 2.567873668999092

Epoch: 6| Step: 3
Training loss: 1.9414357234935777
Validation loss: 2.5452793623158847

Epoch: 6| Step: 4
Training loss: 2.811749167355963
Validation loss: 2.5011383900055466

Epoch: 6| Step: 5
Training loss: 2.3749318364049063
Validation loss: 2.4980571909242992

Epoch: 6| Step: 6
Training loss: 2.458444258778903
Validation loss: 2.508764696040209

Epoch: 6| Step: 7
Training loss: 2.5565321675632013
Validation loss: 2.516189209255512

Epoch: 6| Step: 8
Training loss: 2.1888461739212284
Validation loss: 2.5023780966412996

Epoch: 6| Step: 9
Training loss: 2.6640784299491655
Validation loss: 2.514662913093514

Epoch: 6| Step: 10
Training loss: 1.5374564684155936
Validation loss: 2.547058072717843

Epoch: 6| Step: 11
Training loss: 2.1424941096007877
Validation loss: 2.5869462025226646

Epoch: 6| Step: 12
Training loss: 2.207527685456213
Validation loss: 2.6326336864899935

Epoch: 6| Step: 13
Training loss: 2.5896929528708466
Validation loss: 2.6672944693760057

Epoch: 204| Step: 0
Training loss: 2.2624959450363997
Validation loss: 2.654753836077506

Epoch: 6| Step: 1
Training loss: 1.8162588408347529
Validation loss: 2.632676203902931

Epoch: 6| Step: 2
Training loss: 2.054675896325362
Validation loss: 2.6199868906064663

Epoch: 6| Step: 3
Training loss: 2.6946165209047215
Validation loss: 2.614889188698693

Epoch: 6| Step: 4
Training loss: 2.0452083179351734
Validation loss: 2.569336544152209

Epoch: 6| Step: 5
Training loss: 2.3783830339798597
Validation loss: 2.5213274344813996

Epoch: 6| Step: 6
Training loss: 2.0665158565419612
Validation loss: 2.5011628071866845

Epoch: 6| Step: 7
Training loss: 2.403435286988492
Validation loss: 2.4808334303425266

Epoch: 6| Step: 8
Training loss: 1.4651664683573602
Validation loss: 2.494495106444716

Epoch: 6| Step: 9
Training loss: 2.344614098523698
Validation loss: 2.492631767001429

Epoch: 6| Step: 10
Training loss: 2.6760823101334403
Validation loss: 2.487700213317187

Epoch: 6| Step: 11
Training loss: 2.4222385256721197
Validation loss: 2.5080247278799566

Epoch: 6| Step: 12
Training loss: 2.0250122540892006
Validation loss: 2.5294661014534623

Epoch: 6| Step: 13
Training loss: 2.431997397113963
Validation loss: 2.554995611518665

Epoch: 205| Step: 0
Training loss: 2.4780984922821716
Validation loss: 2.567118787304982

Epoch: 6| Step: 1
Training loss: 2.8560114187017676
Validation loss: 2.604095133793671

Epoch: 6| Step: 2
Training loss: 1.8983097111898728
Validation loss: 2.632788959070636

Epoch: 6| Step: 3
Training loss: 2.2850366805657107
Validation loss: 2.6465745397513074

Epoch: 6| Step: 4
Training loss: 1.7972233973556102
Validation loss: 2.6652245714434337

Epoch: 6| Step: 5
Training loss: 1.9110474798910542
Validation loss: 2.6506760139546053

Epoch: 6| Step: 6
Training loss: 2.182882503623978
Validation loss: 2.6739871586629884

Epoch: 6| Step: 7
Training loss: 1.993882718347583
Validation loss: 2.6621148631940836

Epoch: 6| Step: 8
Training loss: 2.242955093049898
Validation loss: 2.6337142193274694

Epoch: 6| Step: 9
Training loss: 2.364464833879556
Validation loss: 2.646362123623678

Epoch: 6| Step: 10
Training loss: 2.5066552269789555
Validation loss: 2.631468189571665

Epoch: 6| Step: 11
Training loss: 2.301618802481957
Validation loss: 2.622493729156827

Epoch: 6| Step: 12
Training loss: 1.4994007344042997
Validation loss: 2.6196962716477388

Epoch: 6| Step: 13
Training loss: 2.3928295268110227
Validation loss: 2.601514948943365

Epoch: 206| Step: 0
Training loss: 1.684895023618933
Validation loss: 2.5815412323748115

Epoch: 6| Step: 1
Training loss: 2.169330231279634
Validation loss: 2.5267953448389964

Epoch: 6| Step: 2
Training loss: 1.8307458723960144
Validation loss: 2.508775723054956

Epoch: 6| Step: 3
Training loss: 2.15143988543195
Validation loss: 2.4817556208099627

Epoch: 6| Step: 4
Training loss: 2.3035528978550834
Validation loss: 2.4780003651523814

Epoch: 6| Step: 5
Training loss: 2.5676386412989
Validation loss: 2.478508521107275

Epoch: 6| Step: 6
Training loss: 2.0383819964576477
Validation loss: 2.4980361926574477

Epoch: 6| Step: 7
Training loss: 1.7764349657647343
Validation loss: 2.4954842319407247

Epoch: 6| Step: 8
Training loss: 2.2925056886758393
Validation loss: 2.5112846064504653

Epoch: 6| Step: 9
Training loss: 1.9848370952685332
Validation loss: 2.541332653281257

Epoch: 6| Step: 10
Training loss: 3.027860338988883
Validation loss: 2.5746889806051656

Epoch: 6| Step: 11
Training loss: 2.058430558455435
Validation loss: 2.612210665538349

Epoch: 6| Step: 12
Training loss: 2.122467214558043
Validation loss: 2.641719729296021

Epoch: 6| Step: 13
Training loss: 1.8280010996508473
Validation loss: 2.7097048395501044

Epoch: 207| Step: 0
Training loss: 2.258458873267071
Validation loss: 2.7692968512700276

Epoch: 6| Step: 1
Training loss: 2.289814587878851
Validation loss: 2.84571962549344

Epoch: 6| Step: 2
Training loss: 2.3273988141642894
Validation loss: 2.8181209803781844

Epoch: 6| Step: 3
Training loss: 2.1744435442597383
Validation loss: 2.7795506044467837

Epoch: 6| Step: 4
Training loss: 2.336507976365714
Validation loss: 2.751239830863351

Epoch: 6| Step: 5
Training loss: 1.9598770617835441
Validation loss: 2.7119131710582134

Epoch: 6| Step: 6
Training loss: 2.0680281794489344
Validation loss: 2.6699534997335546

Epoch: 6| Step: 7
Training loss: 2.3453512189847103
Validation loss: 2.670356485449097

Epoch: 6| Step: 8
Training loss: 1.637810536415977
Validation loss: 2.6569762924154134

Epoch: 6| Step: 9
Training loss: 2.4161379882614966
Validation loss: 2.623517779661596

Epoch: 6| Step: 10
Training loss: 2.1398705036876624
Validation loss: 2.594391716868681

Epoch: 6| Step: 11
Training loss: 2.236640688446373
Validation loss: 2.5859337585380513

Epoch: 6| Step: 12
Training loss: 1.7543243385667586
Validation loss: 2.5639493611612383

Epoch: 6| Step: 13
Training loss: 2.4546346696380623
Validation loss: 2.5619133718747813

Epoch: 208| Step: 0
Training loss: 1.6728192808974789
Validation loss: 2.575715880377031

Epoch: 6| Step: 1
Training loss: 2.257001896314454
Validation loss: 2.5992881162393267

Epoch: 6| Step: 2
Training loss: 2.1675329921723825
Validation loss: 2.5807552976845667

Epoch: 6| Step: 3
Training loss: 2.3487218383919806
Validation loss: 2.637078621391564

Epoch: 6| Step: 4
Training loss: 2.265952461518407
Validation loss: 2.641653686855926

Epoch: 6| Step: 5
Training loss: 2.0816951287153547
Validation loss: 2.653787613092477

Epoch: 6| Step: 6
Training loss: 2.1102396005483386
Validation loss: 2.6362953473817687

Epoch: 6| Step: 7
Training loss: 2.21104490201258
Validation loss: 2.630429945684066

Epoch: 6| Step: 8
Training loss: 1.9814732278405696
Validation loss: 2.6264452991330662

Epoch: 6| Step: 9
Training loss: 2.280489232963532
Validation loss: 2.6210400420724578

Epoch: 6| Step: 10
Training loss: 2.1488738015789353
Validation loss: 2.6235534170564287

Epoch: 6| Step: 11
Training loss: 1.6014023119204066
Validation loss: 2.6021740459539435

Epoch: 6| Step: 12
Training loss: 1.900855012552919
Validation loss: 2.619263157380935

Epoch: 6| Step: 13
Training loss: 2.2647796105957667
Validation loss: 2.649919786282109

Epoch: 209| Step: 0
Training loss: 1.746625985564831
Validation loss: 2.682493724354823

Epoch: 6| Step: 1
Training loss: 2.178388748728835
Validation loss: 2.7100982572689976

Epoch: 6| Step: 2
Training loss: 2.0410871137300735
Validation loss: 2.762838126671204

Epoch: 6| Step: 3
Training loss: 2.1220822217653623
Validation loss: 2.797859086138937

Epoch: 6| Step: 4
Training loss: 2.63510701970139
Validation loss: 2.7893084809992885

Epoch: 6| Step: 5
Training loss: 1.8895968959984735
Validation loss: 2.712959077896473

Epoch: 6| Step: 6
Training loss: 2.0082146505319307
Validation loss: 2.6624376760257085

Epoch: 6| Step: 7
Training loss: 1.97749999961419
Validation loss: 2.5990502783480327

Epoch: 6| Step: 8
Training loss: 1.8242325384039593
Validation loss: 2.580770603458738

Epoch: 6| Step: 9
Training loss: 2.0671888286560356
Validation loss: 2.53400273994032

Epoch: 6| Step: 10
Training loss: 2.2907920786877014
Validation loss: 2.50453564297873

Epoch: 6| Step: 11
Training loss: 1.9092907651310786
Validation loss: 2.527957562075136

Epoch: 6| Step: 12
Training loss: 2.2793087995751695
Validation loss: 2.548595688463172

Epoch: 6| Step: 13
Training loss: 2.454744035542056
Validation loss: 2.632834191627176

Epoch: 210| Step: 0
Training loss: 2.2599137504121165
Validation loss: 2.6728793189276976

Epoch: 6| Step: 1
Training loss: 1.7828677677878952
Validation loss: 2.733327929398632

Epoch: 6| Step: 2
Training loss: 1.733605635173777
Validation loss: 2.746323808519318

Epoch: 6| Step: 3
Training loss: 2.180697736808962
Validation loss: 2.7931915554605227

Epoch: 6| Step: 4
Training loss: 2.5795757488997144
Validation loss: 2.8469177402095696

Epoch: 6| Step: 5
Training loss: 2.4591267054469523
Validation loss: 2.8396644673925637

Epoch: 6| Step: 6
Training loss: 1.9582573558056082
Validation loss: 2.841140478322413

Epoch: 6| Step: 7
Training loss: 2.154506697340883
Validation loss: 2.82920948411602

Epoch: 6| Step: 8
Training loss: 2.077985027446539
Validation loss: 2.799764038762822

Epoch: 6| Step: 9
Training loss: 2.0850962110317677
Validation loss: 2.704847878489439

Epoch: 6| Step: 10
Training loss: 2.2713794109991703
Validation loss: 2.626684081272463

Epoch: 6| Step: 11
Training loss: 1.0497752766592408
Validation loss: 2.539150674833403

Epoch: 6| Step: 12
Training loss: 2.0709057227926415
Validation loss: 2.468329693306874

Epoch: 6| Step: 13
Training loss: 3.0803060017954818
Validation loss: 2.4347198529776133

Epoch: 211| Step: 0
Training loss: 2.303913361443649
Validation loss: 2.4160214589354476

Epoch: 6| Step: 1
Training loss: 1.8386682857610495
Validation loss: 2.435495903682451

Epoch: 6| Step: 2
Training loss: 2.452908937694654
Validation loss: 2.444640944534254

Epoch: 6| Step: 3
Training loss: 2.2253923520253416
Validation loss: 2.4562513730777127

Epoch: 6| Step: 4
Training loss: 2.264063435114002
Validation loss: 2.483051079632966

Epoch: 6| Step: 5
Training loss: 1.9798199495660167
Validation loss: 2.500255282504302

Epoch: 6| Step: 6
Training loss: 2.596260785891775
Validation loss: 2.5381233774326506

Epoch: 6| Step: 7
Training loss: 1.664819178227611
Validation loss: 2.5626575252477517

Epoch: 6| Step: 8
Training loss: 2.287442933084701
Validation loss: 2.5978410631488305

Epoch: 6| Step: 9
Training loss: 1.87640347406476
Validation loss: 2.654940494344579

Epoch: 6| Step: 10
Training loss: 1.9419969853496626
Validation loss: 2.6487013588324233

Epoch: 6| Step: 11
Training loss: 1.8879347647856972
Validation loss: 2.6895506090475134

Epoch: 6| Step: 12
Training loss: 1.6443162356192154
Validation loss: 2.692700235350638

Epoch: 6| Step: 13
Training loss: 1.6090557189075436
Validation loss: 2.7249723409901208

Epoch: 212| Step: 0
Training loss: 1.7502238266721568
Validation loss: 2.741346273868276

Epoch: 6| Step: 1
Training loss: 2.096641024911348
Validation loss: 2.7336906858924745

Epoch: 6| Step: 2
Training loss: 2.144398725128791
Validation loss: 2.7154521466701627

Epoch: 6| Step: 3
Training loss: 1.9796591764981628
Validation loss: 2.6497602862819947

Epoch: 6| Step: 4
Training loss: 1.7769730065978402
Validation loss: 2.5870413339361025

Epoch: 6| Step: 5
Training loss: 1.527133858934723
Validation loss: 2.533459688278146

Epoch: 6| Step: 6
Training loss: 1.5258674218317816
Validation loss: 2.460521407987889

Epoch: 6| Step: 7
Training loss: 2.1742099861848394
Validation loss: 2.415157870456889

Epoch: 6| Step: 8
Training loss: 2.2554917601576734
Validation loss: 2.401534543335147

Epoch: 6| Step: 9
Training loss: 2.134244333403349
Validation loss: 2.4129244093625593

Epoch: 6| Step: 10
Training loss: 2.2712411660089256
Validation loss: 2.423278695553099

Epoch: 6| Step: 11
Training loss: 2.2680991508165094
Validation loss: 2.4683159555273786

Epoch: 6| Step: 12
Training loss: 2.177938983696587
Validation loss: 2.5217236443566025

Epoch: 6| Step: 13
Training loss: 2.007103939677866
Validation loss: 2.589173174290086

Epoch: 213| Step: 0
Training loss: 2.2194642542577103
Validation loss: 2.643230797373977

Epoch: 6| Step: 1
Training loss: 1.7720691258357029
Validation loss: 2.706316858126171

Epoch: 6| Step: 2
Training loss: 1.8867240573974264
Validation loss: 2.725633681090522

Epoch: 6| Step: 3
Training loss: 2.2411845552641116
Validation loss: 2.751896643250579

Epoch: 6| Step: 4
Training loss: 1.8823029394468416
Validation loss: 2.715781046083901

Epoch: 6| Step: 5
Training loss: 2.1774716069048874
Validation loss: 2.6846052043753894

Epoch: 6| Step: 6
Training loss: 1.7313863762530048
Validation loss: 2.65981507770894

Epoch: 6| Step: 7
Training loss: 2.040369543001776
Validation loss: 2.6221352828923354

Epoch: 6| Step: 8
Training loss: 1.9623229463247398
Validation loss: 2.610994167352016

Epoch: 6| Step: 9
Training loss: 1.7058237374760594
Validation loss: 2.6076123362730925

Epoch: 6| Step: 10
Training loss: 2.388879575144431
Validation loss: 2.6089602651632147

Epoch: 6| Step: 11
Training loss: 1.669623382839463
Validation loss: 2.5890672985713703

Epoch: 6| Step: 12
Training loss: 1.5064459423972412
Validation loss: 2.5882828468908725

Epoch: 6| Step: 13
Training loss: 1.8756874095953207
Validation loss: 2.565253469418456

Epoch: 214| Step: 0
Training loss: 2.0489089993496457
Validation loss: 2.5600633338687393

Epoch: 6| Step: 1
Training loss: 1.8953850464172521
Validation loss: 2.6013742792874024

Epoch: 6| Step: 2
Training loss: 1.658751631781229
Validation loss: 2.58527464042268

Epoch: 6| Step: 3
Training loss: 1.5919203634279901
Validation loss: 2.6273249147032796

Epoch: 6| Step: 4
Training loss: 2.027083834118469
Validation loss: 2.617741996247998

Epoch: 6| Step: 5
Training loss: 1.5559022078195826
Validation loss: 2.5931369389569654

Epoch: 6| Step: 6
Training loss: 2.163549699861774
Validation loss: 2.6296872852915083

Epoch: 6| Step: 7
Training loss: 1.7341799239691105
Validation loss: 2.6170002345807446

Epoch: 6| Step: 8
Training loss: 2.162443030163711
Validation loss: 2.588603713578068

Epoch: 6| Step: 9
Training loss: 2.2463187726955525
Validation loss: 2.569139736865235

Epoch: 6| Step: 10
Training loss: 1.680130372324845
Validation loss: 2.594093245680544

Epoch: 6| Step: 11
Training loss: 1.4606533488181987
Validation loss: 2.57687078839584

Epoch: 6| Step: 12
Training loss: 1.924683604310025
Validation loss: 2.5655842999404643

Epoch: 6| Step: 13
Training loss: 2.401474213823293
Validation loss: 2.604748829076666

Epoch: 215| Step: 0
Training loss: 2.3372055235411455
Validation loss: 2.592586085690121

Epoch: 6| Step: 1
Training loss: 1.6744282558012702
Validation loss: 2.6041145503253853

Epoch: 6| Step: 2
Training loss: 1.8828385853840046
Validation loss: 2.5682392612723

Epoch: 6| Step: 3
Training loss: 2.008145553336463
Validation loss: 2.6061220830313925

Epoch: 6| Step: 4
Training loss: 1.9749086117424515
Validation loss: 2.611282145867231

Epoch: 6| Step: 5
Training loss: 1.5878163750850283
Validation loss: 2.6183668975857377

Epoch: 6| Step: 6
Training loss: 1.5695279567108618
Validation loss: 2.645331588957386

Epoch: 6| Step: 7
Training loss: 1.6295112199985229
Validation loss: 2.638417497365884

Epoch: 6| Step: 8
Training loss: 1.6699874061977626
Validation loss: 2.6512908699151634

Epoch: 6| Step: 9
Training loss: 2.121168159879785
Validation loss: 2.649954238561497

Epoch: 6| Step: 10
Training loss: 1.9358058413610049
Validation loss: 2.6472546770544727

Epoch: 6| Step: 11
Training loss: 1.8054436754955727
Validation loss: 2.665799369697081

Epoch: 6| Step: 12
Training loss: 1.9130186387473658
Validation loss: 2.6260719112838045

Epoch: 6| Step: 13
Training loss: 1.5999643679465898
Validation loss: 2.6170335998981296

Epoch: 216| Step: 0
Training loss: 2.057503051199337
Validation loss: 2.601099798612193

Epoch: 6| Step: 1
Training loss: 1.7710692603829028
Validation loss: 2.5594446959795842

Epoch: 6| Step: 2
Training loss: 1.3554235005590005
Validation loss: 2.5409582419324743

Epoch: 6| Step: 3
Training loss: 1.7964290563100058
Validation loss: 2.5672451167981816

Epoch: 6| Step: 4
Training loss: 2.218917947779564
Validation loss: 2.558844545959518

Epoch: 6| Step: 5
Training loss: 1.4137355363208828
Validation loss: 2.5587630527057073

Epoch: 6| Step: 6
Training loss: 2.065223283126423
Validation loss: 2.589701551475391

Epoch: 6| Step: 7
Training loss: 2.021916351603013
Validation loss: 2.601386725070539

Epoch: 6| Step: 8
Training loss: 1.3649848851914614
Validation loss: 2.584667723223828

Epoch: 6| Step: 9
Training loss: 1.6981138649225462
Validation loss: 2.5706829660958452

Epoch: 6| Step: 10
Training loss: 2.3857026130057863
Validation loss: 2.594570550506896

Epoch: 6| Step: 11
Training loss: 1.9953770853342487
Validation loss: 2.5669590340684607

Epoch: 6| Step: 12
Training loss: 1.6148351247379036
Validation loss: 2.543046420115466

Epoch: 6| Step: 13
Training loss: 1.4129490552088781
Validation loss: 2.588194849231186

Epoch: 217| Step: 0
Training loss: 1.9668278469158622
Validation loss: 2.6040108848656045

Epoch: 6| Step: 1
Training loss: 1.4192069036335206
Validation loss: 2.6343945725322513

Epoch: 6| Step: 2
Training loss: 1.677125333966946
Validation loss: 2.665328487669996

Epoch: 6| Step: 3
Training loss: 2.160039253584612
Validation loss: 2.6367346283295174

Epoch: 6| Step: 4
Training loss: 1.7546018312895795
Validation loss: 2.6269830946839186

Epoch: 6| Step: 5
Training loss: 1.2744671923791069
Validation loss: 2.645934970083421

Epoch: 6| Step: 6
Training loss: 2.0954103860882975
Validation loss: 2.630608344731306

Epoch: 6| Step: 7
Training loss: 1.9667911775690194
Validation loss: 2.6096496530821396

Epoch: 6| Step: 8
Training loss: 1.6700202422143025
Validation loss: 2.5699168152320695

Epoch: 6| Step: 9
Training loss: 1.7529891235136008
Validation loss: 2.5912448513936215

Epoch: 6| Step: 10
Training loss: 2.112060419880104
Validation loss: 2.5813053386476694

Epoch: 6| Step: 11
Training loss: 1.5617823669391742
Validation loss: 2.562117669380809

Epoch: 6| Step: 12
Training loss: 1.8008412249791008
Validation loss: 2.5417702961544664

Epoch: 6| Step: 13
Training loss: 2.0178762476001006
Validation loss: 2.5218663578312577

Epoch: 218| Step: 0
Training loss: 1.6980687952831606
Validation loss: 2.5365896799713865

Epoch: 6| Step: 1
Training loss: 1.8806450108648547
Validation loss: 2.564175590935704

Epoch: 6| Step: 2
Training loss: 1.5987321360218614
Validation loss: 2.536196153363963

Epoch: 6| Step: 3
Training loss: 2.205701471280217
Validation loss: 2.5523212331186946

Epoch: 6| Step: 4
Training loss: 1.6542076618229762
Validation loss: 2.5896072058184956

Epoch: 6| Step: 5
Training loss: 1.4848334156709604
Validation loss: 2.597130426947415

Epoch: 6| Step: 6
Training loss: 1.8888699290626754
Validation loss: 2.616155333126492

Epoch: 6| Step: 7
Training loss: 2.3437375894853716
Validation loss: 2.6704078862875207

Epoch: 6| Step: 8
Training loss: 1.8649107647326317
Validation loss: 2.717585239546924

Epoch: 6| Step: 9
Training loss: 1.580305349565004
Validation loss: 2.6876056952748764

Epoch: 6| Step: 10
Training loss: 1.7490935021386458
Validation loss: 2.724683463008584

Epoch: 6| Step: 11
Training loss: 1.6252229244204899
Validation loss: 2.6968465150655776

Epoch: 6| Step: 12
Training loss: 1.6759829099735222
Validation loss: 2.687147527094587

Epoch: 6| Step: 13
Training loss: 1.6953351419228944
Validation loss: 2.672858516260804

Epoch: 219| Step: 0
Training loss: 2.0282035871189072
Validation loss: 2.6232304680952354

Epoch: 6| Step: 1
Training loss: 2.063335249575874
Validation loss: 2.578078354121119

Epoch: 6| Step: 2
Training loss: 1.9177122857507038
Validation loss: 2.5717594559614314

Epoch: 6| Step: 3
Training loss: 1.4691976311518897
Validation loss: 2.547226389929487

Epoch: 6| Step: 4
Training loss: 1.7343305289950706
Validation loss: 2.5437102095270476

Epoch: 6| Step: 5
Training loss: 1.753260912191238
Validation loss: 2.551717346615755

Epoch: 6| Step: 6
Training loss: 1.556502160168554
Validation loss: 2.526318193698018

Epoch: 6| Step: 7
Training loss: 1.8607953841284184
Validation loss: 2.5362463280063894

Epoch: 6| Step: 8
Training loss: 1.6409100966016983
Validation loss: 2.532874072113837

Epoch: 6| Step: 9
Training loss: 1.4519036195046868
Validation loss: 2.511326801839841

Epoch: 6| Step: 10
Training loss: 1.8649229738421524
Validation loss: 2.529380550592847

Epoch: 6| Step: 11
Training loss: 1.4295027149624309
Validation loss: 2.5549109787257858

Epoch: 6| Step: 12
Training loss: 1.890586159047049
Validation loss: 2.5827350605118844

Epoch: 6| Step: 13
Training loss: 1.836967147068221
Validation loss: 2.5994945184037266

Epoch: 220| Step: 0
Training loss: 1.8098378197316685
Validation loss: 2.6461368787484654

Epoch: 6| Step: 1
Training loss: 1.4008310814422777
Validation loss: 2.6500711400147035

Epoch: 6| Step: 2
Training loss: 2.0587790476377466
Validation loss: 2.651304953366778

Epoch: 6| Step: 3
Training loss: 1.8778501465011082
Validation loss: 2.657303898187456

Epoch: 6| Step: 4
Training loss: 1.3196266695420158
Validation loss: 2.6594055137013033

Epoch: 6| Step: 5
Training loss: 1.7769344990496876
Validation loss: 2.6694527698443773

Epoch: 6| Step: 6
Training loss: 1.748912882332626
Validation loss: 2.633174759947759

Epoch: 6| Step: 7
Training loss: 1.6762903680570296
Validation loss: 2.6183764839273374

Epoch: 6| Step: 8
Training loss: 1.5382169153061396
Validation loss: 2.6266637404017277

Epoch: 6| Step: 9
Training loss: 2.0157966244989978
Validation loss: 2.613165155350108

Epoch: 6| Step: 10
Training loss: 1.8748585329729546
Validation loss: 2.589043692591176

Epoch: 6| Step: 11
Training loss: 1.6801080221688145
Validation loss: 2.573345763984709

Epoch: 6| Step: 12
Training loss: 1.7497085601089695
Validation loss: 2.5444500736661446

Epoch: 6| Step: 13
Training loss: 1.8656143520441137
Validation loss: 2.569568786635257

Epoch: 221| Step: 0
Training loss: 1.7862586826463143
Validation loss: 2.5436493174123482

Epoch: 6| Step: 1
Training loss: 2.11821201212152
Validation loss: 2.5822762775528885

Epoch: 6| Step: 2
Training loss: 1.8848554362507393
Validation loss: 2.5840411736458275

Epoch: 6| Step: 3
Training loss: 1.5118412884868193
Validation loss: 2.626960898999045

Epoch: 6| Step: 4
Training loss: 1.359825454267986
Validation loss: 2.6271387988162282

Epoch: 6| Step: 5
Training loss: 1.5739955696567098
Validation loss: 2.6518171408267146

Epoch: 6| Step: 6
Training loss: 1.4574916408816025
Validation loss: 2.669997825196128

Epoch: 6| Step: 7
Training loss: 1.9544011943880633
Validation loss: 2.64607227387607

Epoch: 6| Step: 8
Training loss: 1.6742990336569552
Validation loss: 2.65123542786552

Epoch: 6| Step: 9
Training loss: 1.8973714716105907
Validation loss: 2.623402757571019

Epoch: 6| Step: 10
Training loss: 1.6505277858823233
Validation loss: 2.589015478013528

Epoch: 6| Step: 11
Training loss: 1.982164127525389
Validation loss: 2.5939294659325625

Epoch: 6| Step: 12
Training loss: 1.3774339634458614
Validation loss: 2.5485433729110296

Epoch: 6| Step: 13
Training loss: 1.5850599896122404
Validation loss: 2.5254464300141475

Epoch: 222| Step: 0
Training loss: 1.7294285663984577
Validation loss: 2.524725812671679

Epoch: 6| Step: 1
Training loss: 1.939068374809323
Validation loss: 2.5791316349611773

Epoch: 6| Step: 2
Training loss: 1.3598919904818443
Validation loss: 2.6116585905549368

Epoch: 6| Step: 3
Training loss: 1.7763080639513158
Validation loss: 2.6134181328383477

Epoch: 6| Step: 4
Training loss: 1.9738082090543576
Validation loss: 2.6503054865514994

Epoch: 6| Step: 5
Training loss: 1.3244197546619034
Validation loss: 2.672382120709257

Epoch: 6| Step: 6
Training loss: 1.7368337712399762
Validation loss: 2.6684005840165987

Epoch: 6| Step: 7
Training loss: 1.51033212710161
Validation loss: 2.673145261133496

Epoch: 6| Step: 8
Training loss: 1.5376013001356077
Validation loss: 2.6673712084901773

Epoch: 6| Step: 9
Training loss: 1.8532760995951376
Validation loss: 2.6852714005600973

Epoch: 6| Step: 10
Training loss: 1.8462908419648214
Validation loss: 2.6437750799325284

Epoch: 6| Step: 11
Training loss: 2.073109475630561
Validation loss: 2.622826869657403

Epoch: 6| Step: 12
Training loss: 1.6206733618132056
Validation loss: 2.61296431090431

Epoch: 6| Step: 13
Training loss: 1.2653491814615405
Validation loss: 2.5958665340959466

Epoch: 223| Step: 0
Training loss: 1.756866607483123
Validation loss: 2.5877843441289716

Epoch: 6| Step: 1
Training loss: 1.7963955446873086
Validation loss: 2.5952709012242914

Epoch: 6| Step: 2
Training loss: 1.8081371810402564
Validation loss: 2.593610769449727

Epoch: 6| Step: 3
Training loss: 1.6383551017476667
Validation loss: 2.5950883964764526

Epoch: 6| Step: 4
Training loss: 1.7144946044854776
Validation loss: 2.621843927205578

Epoch: 6| Step: 5
Training loss: 1.726967190225959
Validation loss: 2.6366160378148837

Epoch: 6| Step: 6
Training loss: 1.5804039391708233
Validation loss: 2.6358469976076093

Epoch: 6| Step: 7
Training loss: 1.590251448560012
Validation loss: 2.6378334893274316

Epoch: 6| Step: 8
Training loss: 1.6589300676245515
Validation loss: 2.662727299228138

Epoch: 6| Step: 9
Training loss: 1.6643960108130957
Validation loss: 2.679594125050322

Epoch: 6| Step: 10
Training loss: 1.8026222202381963
Validation loss: 2.704041345082899

Epoch: 6| Step: 11
Training loss: 2.0098066705751525
Validation loss: 2.716764073412615

Epoch: 6| Step: 12
Training loss: 1.278893466855283
Validation loss: 2.690457588460417

Epoch: 6| Step: 13
Training loss: 1.6595630259049168
Validation loss: 2.701177354059854

Epoch: 224| Step: 0
Training loss: 2.039490402748999
Validation loss: 2.657918050415658

Epoch: 6| Step: 1
Training loss: 1.7694334293636782
Validation loss: 2.6393951165413583

Epoch: 6| Step: 2
Training loss: 1.4428972012760706
Validation loss: 2.5836840893267485

Epoch: 6| Step: 3
Training loss: 1.5073247723567578
Validation loss: 2.5486547151870793

Epoch: 6| Step: 4
Training loss: 1.864484738206381
Validation loss: 2.525880093233672

Epoch: 6| Step: 5
Training loss: 1.6892518733997806
Validation loss: 2.5534761714359173

Epoch: 6| Step: 6
Training loss: 1.4346569806348661
Validation loss: 2.6061404378131887

Epoch: 6| Step: 7
Training loss: 1.6974228060759258
Validation loss: 2.607843539241886

Epoch: 6| Step: 8
Training loss: 1.7268108344677706
Validation loss: 2.6347317982573206

Epoch: 6| Step: 9
Training loss: 1.5381713455949646
Validation loss: 2.6645449800890137

Epoch: 6| Step: 10
Training loss: 1.7700725342279684
Validation loss: 2.6377910142232013

Epoch: 6| Step: 11
Training loss: 1.6058802761758184
Validation loss: 2.6380645402046086

Epoch: 6| Step: 12
Training loss: 1.6282218391774699
Validation loss: 2.609826877847792

Epoch: 6| Step: 13
Training loss: 1.7146493023788612
Validation loss: 2.62676961934666

Epoch: 225| Step: 0
Training loss: 1.61637452556735
Validation loss: 2.607430109853915

Epoch: 6| Step: 1
Training loss: 2.0892084314680495
Validation loss: 2.5952081373384654

Epoch: 6| Step: 2
Training loss: 1.2641883042473878
Validation loss: 2.578349499764492

Epoch: 6| Step: 3
Training loss: 1.6325271576145743
Validation loss: 2.5893228819082066

Epoch: 6| Step: 4
Training loss: 1.8311648404366994
Validation loss: 2.597089677942969

Epoch: 6| Step: 5
Training loss: 1.0173456728258976
Validation loss: 2.6071681396743185

Epoch: 6| Step: 6
Training loss: 1.526524160444457
Validation loss: 2.6301441972276525

Epoch: 6| Step: 7
Training loss: 1.5880599828965352
Validation loss: 2.661884024737855

Epoch: 6| Step: 8
Training loss: 1.9862521446797416
Validation loss: 2.669362410748468

Epoch: 6| Step: 9
Training loss: 2.1889066260835346
Validation loss: 2.680141846589728

Epoch: 6| Step: 10
Training loss: 1.573283104391101
Validation loss: 2.673595615898382

Epoch: 6| Step: 11
Training loss: 1.957301930117602
Validation loss: 2.663031305142852

Epoch: 6| Step: 12
Training loss: 1.0912149751860596
Validation loss: 2.660253256091758

Epoch: 6| Step: 13
Training loss: 0.7031737204732337
Validation loss: 2.6641568523333743

Epoch: 226| Step: 0
Training loss: 0.9912276543771991
Validation loss: 2.659937407609678

Epoch: 6| Step: 1
Training loss: 1.2545344125126041
Validation loss: 2.6344227526345176

Epoch: 6| Step: 2
Training loss: 1.9688380993704364
Validation loss: 2.625427064860115

Epoch: 6| Step: 3
Training loss: 1.30071219412759
Validation loss: 2.597246911618449

Epoch: 6| Step: 4
Training loss: 1.1692272537821458
Validation loss: 2.62140773415131

Epoch: 6| Step: 5
Training loss: 1.6723597884315715
Validation loss: 2.6324740467658665

Epoch: 6| Step: 6
Training loss: 1.8197403037107296
Validation loss: 2.6186871305439317

Epoch: 6| Step: 7
Training loss: 1.4004275690842496
Validation loss: 2.59859171611197

Epoch: 6| Step: 8
Training loss: 1.639029389984298
Validation loss: 2.617714192841756

Epoch: 6| Step: 9
Training loss: 2.1725368451855918
Validation loss: 2.6125474390008234

Epoch: 6| Step: 10
Training loss: 2.036752144642557
Validation loss: 2.6392456226626186

Epoch: 6| Step: 11
Training loss: 1.5004149498788888
Validation loss: 2.638201711379803

Epoch: 6| Step: 12
Training loss: 1.7935818556819803
Validation loss: 2.6561809735917428

Epoch: 6| Step: 13
Training loss: 1.6403369469037272
Validation loss: 2.6502455558318654

Epoch: 227| Step: 0
Training loss: 1.3582668830360136
Validation loss: 2.646602813924459

Epoch: 6| Step: 1
Training loss: 1.6481307047056981
Validation loss: 2.617470331877643

Epoch: 6| Step: 2
Training loss: 1.7071855767714232
Validation loss: 2.640902102331715

Epoch: 6| Step: 3
Training loss: 2.0957418048911833
Validation loss: 2.6281999771313025

Epoch: 6| Step: 4
Training loss: 1.1722772543666224
Validation loss: 2.6069143531003434

Epoch: 6| Step: 5
Training loss: 1.7258846281353193
Validation loss: 2.596434248854367

Epoch: 6| Step: 6
Training loss: 1.1419886967889612
Validation loss: 2.5804489445692593

Epoch: 6| Step: 7
Training loss: 1.4131621977521764
Validation loss: 2.6046243372902547

Epoch: 6| Step: 8
Training loss: 1.672962013602311
Validation loss: 2.5964937450991035

Epoch: 6| Step: 9
Training loss: 1.4707950396141085
Validation loss: 2.584880971285138

Epoch: 6| Step: 10
Training loss: 1.8335248312494903
Validation loss: 2.5705815875785247

Epoch: 6| Step: 11
Training loss: 1.260963048286137
Validation loss: 2.5867077461936003

Epoch: 6| Step: 12
Training loss: 1.944160702605351
Validation loss: 2.5691908557038343

Epoch: 6| Step: 13
Training loss: 1.7790206208987938
Validation loss: 2.614191609768871

Epoch: 228| Step: 0
Training loss: 1.2775130320143715
Validation loss: 2.6184505064172776

Epoch: 6| Step: 1
Training loss: 1.198307648031103
Validation loss: 2.638216627514661

Epoch: 6| Step: 2
Training loss: 1.6474984192442654
Validation loss: 2.633147804912719

Epoch: 6| Step: 3
Training loss: 1.7989580768113063
Validation loss: 2.6322055137770466

Epoch: 6| Step: 4
Training loss: 2.2978882922452293
Validation loss: 2.625270616652395

Epoch: 6| Step: 5
Training loss: 1.4081372630554254
Validation loss: 2.616636166441514

Epoch: 6| Step: 6
Training loss: 1.7679784163456471
Validation loss: 2.621589561545114

Epoch: 6| Step: 7
Training loss: 1.7922944440254431
Validation loss: 2.640132389428316

Epoch: 6| Step: 8
Training loss: 1.482370730034227
Validation loss: 2.628540563626682

Epoch: 6| Step: 9
Training loss: 1.3974676765156782
Validation loss: 2.668098104612315

Epoch: 6| Step: 10
Training loss: 1.417393507279093
Validation loss: 2.6393335869752605

Epoch: 6| Step: 11
Training loss: 1.2742895540531476
Validation loss: 2.6800370933213755

Epoch: 6| Step: 12
Training loss: 1.5703580479634927
Validation loss: 2.701827068224358

Epoch: 6| Step: 13
Training loss: 1.7569081332442138
Validation loss: 2.6921569385971837

Epoch: 229| Step: 0
Training loss: 1.6398952496035353
Validation loss: 2.6936704308808253

Epoch: 6| Step: 1
Training loss: 1.2921167430394291
Validation loss: 2.6734009363454723

Epoch: 6| Step: 2
Training loss: 1.3344392908407772
Validation loss: 2.671588980504116

Epoch: 6| Step: 3
Training loss: 1.6102564351593338
Validation loss: 2.6739068079321315

Epoch: 6| Step: 4
Training loss: 1.2811919873757915
Validation loss: 2.6793736496731233

Epoch: 6| Step: 5
Training loss: 1.6316204921876696
Validation loss: 2.6598800456278417

Epoch: 6| Step: 6
Training loss: 1.8700368679716564
Validation loss: 2.6289588445004486

Epoch: 6| Step: 7
Training loss: 1.7310119878440866
Validation loss: 2.602114235255177

Epoch: 6| Step: 8
Training loss: 1.531622938556509
Validation loss: 2.5670936452924584

Epoch: 6| Step: 9
Training loss: 1.7692798831750545
Validation loss: 2.533845147188476

Epoch: 6| Step: 10
Training loss: 1.908274841522723
Validation loss: 2.55359454855099

Epoch: 6| Step: 11
Training loss: 1.4638746794546442
Validation loss: 2.539525858435749

Epoch: 6| Step: 12
Training loss: 1.4029543086773455
Validation loss: 2.522583797045987

Epoch: 6| Step: 13
Training loss: 1.5250936260562185
Validation loss: 2.5496099792671902

Epoch: 230| Step: 0
Training loss: 1.0830018135365582
Validation loss: 2.562208271603313

Epoch: 6| Step: 1
Training loss: 1.7407245052803995
Validation loss: 2.5925961975001623

Epoch: 6| Step: 2
Training loss: 1.6164497498696826
Validation loss: 2.6606844181844767

Epoch: 6| Step: 3
Training loss: 1.6108377716245388
Validation loss: 2.674701318673578

Epoch: 6| Step: 4
Training loss: 2.040110702315896
Validation loss: 2.7000637451783778

Epoch: 6| Step: 5
Training loss: 1.200516089087302
Validation loss: 2.7403637405252965

Epoch: 6| Step: 6
Training loss: 1.5604484823096156
Validation loss: 2.7440075509792514

Epoch: 6| Step: 7
Training loss: 1.830759741870132
Validation loss: 2.690344655487443

Epoch: 6| Step: 8
Training loss: 1.313872301123773
Validation loss: 2.6502633235414437

Epoch: 6| Step: 9
Training loss: 1.7699659205243203
Validation loss: 2.640451288550014

Epoch: 6| Step: 10
Training loss: 1.5900979178645624
Validation loss: 2.6011389009619488

Epoch: 6| Step: 11
Training loss: 0.7181388495747352
Validation loss: 2.6061793100972745

Epoch: 6| Step: 12
Training loss: 2.1194099501234134
Validation loss: 2.5783849531061267

Epoch: 6| Step: 13
Training loss: 1.3318203398337591
Validation loss: 2.5632849140710317

Epoch: 231| Step: 0
Training loss: 1.4837568903492289
Validation loss: 2.5793640311555035

Epoch: 6| Step: 1
Training loss: 1.454304534293556
Validation loss: 2.5952029269910137

Epoch: 6| Step: 2
Training loss: 1.843488642385212
Validation loss: 2.6100390338913773

Epoch: 6| Step: 3
Training loss: 2.018529647280585
Validation loss: 2.6288012080251026

Epoch: 6| Step: 4
Training loss: 1.709158961506399
Validation loss: 2.632713086924933

Epoch: 6| Step: 5
Training loss: 0.902882072749526
Validation loss: 2.619138888590755

Epoch: 6| Step: 6
Training loss: 1.1924268009904067
Validation loss: 2.6621966459607065

Epoch: 6| Step: 7
Training loss: 1.4722072412620328
Validation loss: 2.6210689027256904

Epoch: 6| Step: 8
Training loss: 1.1129240835026704
Validation loss: 2.633234390873039

Epoch: 6| Step: 9
Training loss: 1.598660999531971
Validation loss: 2.6195430846033343

Epoch: 6| Step: 10
Training loss: 1.718911388796284
Validation loss: 2.67056086563357

Epoch: 6| Step: 11
Training loss: 1.9099019823338585
Validation loss: 2.6672229063340684

Epoch: 6| Step: 12
Training loss: 1.3644606945265807
Validation loss: 2.66961439289281

Epoch: 6| Step: 13
Training loss: 1.2165246845818714
Validation loss: 2.677152845756175

Epoch: 232| Step: 0
Training loss: 1.321344232077035
Validation loss: 2.6815851479149853

Epoch: 6| Step: 1
Training loss: 1.8771190113511393
Validation loss: 2.6788205664072176

Epoch: 6| Step: 2
Training loss: 1.5886962648634153
Validation loss: 2.659347013317548

Epoch: 6| Step: 3
Training loss: 1.2458171477696396
Validation loss: 2.6351069214405953

Epoch: 6| Step: 4
Training loss: 1.7180176301657748
Validation loss: 2.604551617790885

Epoch: 6| Step: 5
Training loss: 1.7039966277684615
Validation loss: 2.558796166494142

Epoch: 6| Step: 6
Training loss: 1.5162742246750958
Validation loss: 2.5472650723096835

Epoch: 6| Step: 7
Training loss: 1.6939187363473227
Validation loss: 2.5515128453400524

Epoch: 6| Step: 8
Training loss: 1.4694446787666722
Validation loss: 2.540835630164886

Epoch: 6| Step: 9
Training loss: 1.4551664389621508
Validation loss: 2.559553094104324

Epoch: 6| Step: 10
Training loss: 1.2757377210620817
Validation loss: 2.5878413724169143

Epoch: 6| Step: 11
Training loss: 1.203822936703463
Validation loss: 2.613458504632561

Epoch: 6| Step: 12
Training loss: 1.773105943245953
Validation loss: 2.637928088346104

Epoch: 6| Step: 13
Training loss: 1.4737175878530997
Validation loss: 2.622803568500438

Epoch: 233| Step: 0
Training loss: 1.201044984643637
Validation loss: 2.692380307305858

Epoch: 6| Step: 1
Training loss: 1.4374328265873602
Validation loss: 2.683574152877291

Epoch: 6| Step: 2
Training loss: 0.9967719069600125
Validation loss: 2.7044395661237672

Epoch: 6| Step: 3
Training loss: 1.549051083539427
Validation loss: 2.6834414840250203

Epoch: 6| Step: 4
Training loss: 1.5952439131830616
Validation loss: 2.653361162195971

Epoch: 6| Step: 5
Training loss: 1.4373810760398817
Validation loss: 2.63515218036381

Epoch: 6| Step: 6
Training loss: 1.8051846962900295
Validation loss: 2.6078991596187078

Epoch: 6| Step: 7
Training loss: 1.4573744300679539
Validation loss: 2.5907782619741324

Epoch: 6| Step: 8
Training loss: 1.815477687617689
Validation loss: 2.6028570243093156

Epoch: 6| Step: 9
Training loss: 1.5817325262916622
Validation loss: 2.6054231761731015

Epoch: 6| Step: 10
Training loss: 1.354616452370274
Validation loss: 2.6103782176893766

Epoch: 6| Step: 11
Training loss: 1.8822669034116046
Validation loss: 2.5889991317562076

Epoch: 6| Step: 12
Training loss: 1.5419814415642428
Validation loss: 2.598289917877018

Epoch: 6| Step: 13
Training loss: 1.0021475144186696
Validation loss: 2.5769586265854287

Epoch: 234| Step: 0
Training loss: 1.4017586084995823
Validation loss: 2.6299501633301885

Epoch: 6| Step: 1
Training loss: 1.4049968646140087
Validation loss: 2.6391873029217847

Epoch: 6| Step: 2
Training loss: 1.2777441487977894
Validation loss: 2.645202455567977

Epoch: 6| Step: 3
Training loss: 1.5091177869295924
Validation loss: 2.6292518776518103

Epoch: 6| Step: 4
Training loss: 1.9186463567221255
Validation loss: 2.6206964881567925

Epoch: 6| Step: 5
Training loss: 1.448798681696898
Validation loss: 2.6305149399596885

Epoch: 6| Step: 6
Training loss: 1.2664884282911397
Validation loss: 2.6234020930615958

Epoch: 6| Step: 7
Training loss: 1.546466195389167
Validation loss: 2.614632535487103

Epoch: 6| Step: 8
Training loss: 1.4692923984975608
Validation loss: 2.6417732196188792

Epoch: 6| Step: 9
Training loss: 1.593539803799304
Validation loss: 2.647835663155224

Epoch: 6| Step: 10
Training loss: 1.4818242694178656
Validation loss: 2.6525382179461454

Epoch: 6| Step: 11
Training loss: 1.8060920171055292
Validation loss: 2.669128860471694

Epoch: 6| Step: 12
Training loss: 1.2015054875255273
Validation loss: 2.6818263726256535

Epoch: 6| Step: 13
Training loss: 1.8096487704549349
Validation loss: 2.6897518856976097

Epoch: 235| Step: 0
Training loss: 1.4850671860880351
Validation loss: 2.659008638275562

Epoch: 6| Step: 1
Training loss: 1.5430975365309625
Validation loss: 2.6632126934210296

Epoch: 6| Step: 2
Training loss: 1.4622141925603536
Validation loss: 2.647841914830232

Epoch: 6| Step: 3
Training loss: 1.119604736812557
Validation loss: 2.6559175306187415

Epoch: 6| Step: 4
Training loss: 1.5247348054528134
Validation loss: 2.653946090547429

Epoch: 6| Step: 5
Training loss: 1.2570924771264735
Validation loss: 2.67044510402047

Epoch: 6| Step: 6
Training loss: 1.5158589762566395
Validation loss: 2.6857973864403664

Epoch: 6| Step: 7
Training loss: 1.063921930604011
Validation loss: 2.6391616482969655

Epoch: 6| Step: 8
Training loss: 2.131761005253757
Validation loss: 2.6717207074359512

Epoch: 6| Step: 9
Training loss: 1.46644199919172
Validation loss: 2.6677391916665565

Epoch: 6| Step: 10
Training loss: 1.2928988619353037
Validation loss: 2.6570754060242323

Epoch: 6| Step: 11
Training loss: 1.5789125951066607
Validation loss: 2.661422279090743

Epoch: 6| Step: 12
Training loss: 1.6724898018975098
Validation loss: 2.6465863971368635

Epoch: 6| Step: 13
Training loss: 1.3158389264149544
Validation loss: 2.6217091319684944

Epoch: 236| Step: 0
Training loss: 1.3885112943234585
Validation loss: 2.6349136343927073

Epoch: 6| Step: 1
Training loss: 1.5408164936395032
Validation loss: 2.627778317962639

Epoch: 6| Step: 2
Training loss: 0.9486129146041842
Validation loss: 2.622507849949136

Epoch: 6| Step: 3
Training loss: 1.4710743956019456
Validation loss: 2.6286508083522975

Epoch: 6| Step: 4
Training loss: 1.7792590207408177
Validation loss: 2.6365382236556143

Epoch: 6| Step: 5
Training loss: 1.1206010008080864
Validation loss: 2.653211425214648

Epoch: 6| Step: 6
Training loss: 1.3933469728474541
Validation loss: 2.6771184466404487

Epoch: 6| Step: 7
Training loss: 1.8449695239354194
Validation loss: 2.6587833298967127

Epoch: 6| Step: 8
Training loss: 1.328067912950498
Validation loss: 2.6606829439881263

Epoch: 6| Step: 9
Training loss: 1.420678610035604
Validation loss: 2.6547945478359223

Epoch: 6| Step: 10
Training loss: 1.5777637332565786
Validation loss: 2.7079752594636552

Epoch: 6| Step: 11
Training loss: 1.1444757337418305
Validation loss: 2.711016340895122

Epoch: 6| Step: 12
Training loss: 1.8583911248131875
Validation loss: 2.713529879208406

Epoch: 6| Step: 13
Training loss: 1.4740301952659538
Validation loss: 2.7402073438690504

Epoch: 237| Step: 0
Training loss: 1.9102149127463166
Validation loss: 2.743321127440934

Epoch: 6| Step: 1
Training loss: 1.5550139578042586
Validation loss: 2.7146197081620183

Epoch: 6| Step: 2
Training loss: 1.5996014754364618
Validation loss: 2.7170445825629117

Epoch: 6| Step: 3
Training loss: 1.2553657760121715
Validation loss: 2.681221027993645

Epoch: 6| Step: 4
Training loss: 1.8366177211869856
Validation loss: 2.646193792664894

Epoch: 6| Step: 5
Training loss: 1.2718210551001206
Validation loss: 2.6245736558669015

Epoch: 6| Step: 6
Training loss: 1.5896076898804468
Validation loss: 2.64419223648612

Epoch: 6| Step: 7
Training loss: 0.8324205804006534
Validation loss: 2.6801477660796134

Epoch: 6| Step: 8
Training loss: 1.4561133062689042
Validation loss: 2.687750644161481

Epoch: 6| Step: 9
Training loss: 1.4537616278592533
Validation loss: 2.683238923813138

Epoch: 6| Step: 10
Training loss: 1.0583131988492445
Validation loss: 2.6900170137430246

Epoch: 6| Step: 11
Training loss: 1.4854257980144483
Validation loss: 2.7271524774694527

Epoch: 6| Step: 12
Training loss: 1.4508312539237844
Validation loss: 2.689122476488249

Epoch: 6| Step: 13
Training loss: 1.674877785736234
Validation loss: 2.6919264744933895

Epoch: 238| Step: 0
Training loss: 1.6710705113946371
Validation loss: 2.6630660566154654

Epoch: 6| Step: 1
Training loss: 1.4590680406064485
Validation loss: 2.629877774668112

Epoch: 6| Step: 2
Training loss: 0.6987595568772792
Validation loss: 2.5905980235665673

Epoch: 6| Step: 3
Training loss: 1.3754517506713886
Validation loss: 2.615059122008468

Epoch: 6| Step: 4
Training loss: 1.5603995128277819
Validation loss: 2.595646837350538

Epoch: 6| Step: 5
Training loss: 1.61509104303783
Validation loss: 2.57502048152556

Epoch: 6| Step: 6
Training loss: 1.5049451534124634
Validation loss: 2.611686733276684

Epoch: 6| Step: 7
Training loss: 1.4471965160677986
Validation loss: 2.612226789016663

Epoch: 6| Step: 8
Training loss: 1.2257471958776427
Validation loss: 2.6679411274586826

Epoch: 6| Step: 9
Training loss: 1.3539236975600573
Validation loss: 2.70250100293056

Epoch: 6| Step: 10
Training loss: 1.2471225043527348
Validation loss: 2.7008415448874947

Epoch: 6| Step: 11
Training loss: 1.8651252754619767
Validation loss: 2.721794834992997

Epoch: 6| Step: 12
Training loss: 1.7891538505053717
Validation loss: 2.72322547155065

Epoch: 6| Step: 13
Training loss: 1.4633791506349896
Validation loss: 2.7037760125894383

Epoch: 239| Step: 0
Training loss: 1.5776392878538352
Validation loss: 2.692648420315725

Epoch: 6| Step: 1
Training loss: 1.539864732820952
Validation loss: 2.6802386511103946

Epoch: 6| Step: 2
Training loss: 1.1855034859524385
Validation loss: 2.656913551871831

Epoch: 6| Step: 3
Training loss: 1.40684445850059
Validation loss: 2.653371765100892

Epoch: 6| Step: 4
Training loss: 1.3236755337180797
Validation loss: 2.6316434778862483

Epoch: 6| Step: 5
Training loss: 1.4185490537329613
Validation loss: 2.6182262667865603

Epoch: 6| Step: 6
Training loss: 1.580385760524655
Validation loss: 2.6398379109175627

Epoch: 6| Step: 7
Training loss: 1.228851903064119
Validation loss: 2.6123392511656744

Epoch: 6| Step: 8
Training loss: 1.6316394881705025
Validation loss: 2.614138699529837

Epoch: 6| Step: 9
Training loss: 1.963528323613035
Validation loss: 2.608509206230273

Epoch: 6| Step: 10
Training loss: 1.1898420227398925
Validation loss: 2.631016968061086

Epoch: 6| Step: 11
Training loss: 1.4149201042345774
Validation loss: 2.611450891424305

Epoch: 6| Step: 12
Training loss: 0.9046522723308182
Validation loss: 2.609604324187735

Epoch: 6| Step: 13
Training loss: 1.9517032789362783
Validation loss: 2.6090428764431617

Epoch: 240| Step: 0
Training loss: 1.5014702426224074
Validation loss: 2.611994015967138

Epoch: 6| Step: 1
Training loss: 1.0889520312727112
Validation loss: 2.6201472094460243

Epoch: 6| Step: 2
Training loss: 1.5130336671198479
Validation loss: 2.628614353533922

Epoch: 6| Step: 3
Training loss: 1.7743067018721284
Validation loss: 2.6414634265265335

Epoch: 6| Step: 4
Training loss: 1.7611585178807045
Validation loss: 2.660298796465883

Epoch: 6| Step: 5
Training loss: 1.3449100986910225
Validation loss: 2.6510419909445226

Epoch: 6| Step: 6
Training loss: 1.6636641477793663
Validation loss: 2.7011638571213776

Epoch: 6| Step: 7
Training loss: 1.1449215584750927
Validation loss: 2.7165940991535136

Epoch: 6| Step: 8
Training loss: 1.05605843065183
Validation loss: 2.691116586747652

Epoch: 6| Step: 9
Training loss: 1.4121634023205374
Validation loss: 2.6708545512411694

Epoch: 6| Step: 10
Training loss: 1.362866051524242
Validation loss: 2.6879006020696607

Epoch: 6| Step: 11
Training loss: 1.3147099373011073
Validation loss: 2.669141122871346

Epoch: 6| Step: 12
Training loss: 1.6109842199290318
Validation loss: 2.6977027617906257

Epoch: 6| Step: 13
Training loss: 1.017468642424102
Validation loss: 2.6967317182957493

Epoch: 241| Step: 0
Training loss: 1.5751615592807278
Validation loss: 2.6779612002058917

Epoch: 6| Step: 1
Training loss: 1.2653747122731382
Validation loss: 2.688361640048109

Epoch: 6| Step: 2
Training loss: 1.1054880524692348
Validation loss: 2.680207039649613

Epoch: 6| Step: 3
Training loss: 1.7691369701641702
Validation loss: 2.6381144799400706

Epoch: 6| Step: 4
Training loss: 1.2575500877977017
Validation loss: 2.6565235245632266

Epoch: 6| Step: 5
Training loss: 1.8212789826715037
Validation loss: 2.638796724920339

Epoch: 6| Step: 6
Training loss: 1.4993348236234887
Validation loss: 2.635535896078618

Epoch: 6| Step: 7
Training loss: 1.4814654294221645
Validation loss: 2.643219570884258

Epoch: 6| Step: 8
Training loss: 0.7404183835932958
Validation loss: 2.6376941150887734

Epoch: 6| Step: 9
Training loss: 1.0829326304283702
Validation loss: 2.669071797839581

Epoch: 6| Step: 10
Training loss: 1.380600145495298
Validation loss: 2.680777606979794

Epoch: 6| Step: 11
Training loss: 1.3227459754860995
Validation loss: 2.6945036185759332

Epoch: 6| Step: 12
Training loss: 1.5691685851428594
Validation loss: 2.696000461127616

Epoch: 6| Step: 13
Training loss: 1.684667824396949
Validation loss: 2.695347226659136

Epoch: 242| Step: 0
Training loss: 1.3970509906820852
Validation loss: 2.6984038190894357

Epoch: 6| Step: 1
Training loss: 1.8493499412785583
Validation loss: 2.7115430366918756

Epoch: 6| Step: 2
Training loss: 1.1586989166620796
Validation loss: 2.718085309940542

Epoch: 6| Step: 3
Training loss: 1.2243658429008333
Validation loss: 2.7128153530747006

Epoch: 6| Step: 4
Training loss: 1.2405854456671248
Validation loss: 2.7148687758568197

Epoch: 6| Step: 5
Training loss: 1.4501941616683145
Validation loss: 2.702986344325902

Epoch: 6| Step: 6
Training loss: 1.4136857010227717
Validation loss: 2.72371112967071

Epoch: 6| Step: 7
Training loss: 1.3871781139051937
Validation loss: 2.7175531012263536

Epoch: 6| Step: 8
Training loss: 1.4742518515779803
Validation loss: 2.7279094247815485

Epoch: 6| Step: 9
Training loss: 1.300502758743311
Validation loss: 2.732362095949147

Epoch: 6| Step: 10
Training loss: 1.2520024948978854
Validation loss: 2.712440092505421

Epoch: 6| Step: 11
Training loss: 1.2323627729798903
Validation loss: 2.714516723133899

Epoch: 6| Step: 12
Training loss: 1.0958421044427742
Validation loss: 2.6829528635609314

Epoch: 6| Step: 13
Training loss: 2.138179189290251
Validation loss: 2.7000548049153075

Epoch: 243| Step: 0
Training loss: 1.714521025788215
Validation loss: 2.6578546559516445

Epoch: 6| Step: 1
Training loss: 1.6832051901938552
Validation loss: 2.6489123069662814

Epoch: 6| Step: 2
Training loss: 1.255127784181122
Validation loss: 2.650634819182586

Epoch: 6| Step: 3
Training loss: 0.9111552833656407
Validation loss: 2.6365804029331925

Epoch: 6| Step: 4
Training loss: 1.5523808682692715
Validation loss: 2.6473465257321735

Epoch: 6| Step: 5
Training loss: 1.8200118835815808
Validation loss: 2.649342223072858

Epoch: 6| Step: 6
Training loss: 1.2075993950730155
Validation loss: 2.637487135556738

Epoch: 6| Step: 7
Training loss: 1.3418872697302116
Validation loss: 2.6235755643736414

Epoch: 6| Step: 8
Training loss: 1.156900686744488
Validation loss: 2.656643072453701

Epoch: 6| Step: 9
Training loss: 1.5346210507762084
Validation loss: 2.6381059749948985

Epoch: 6| Step: 10
Training loss: 1.258531495253004
Validation loss: 2.6508725461696416

Epoch: 6| Step: 11
Training loss: 1.3618350514981665
Validation loss: 2.6800079675475494

Epoch: 6| Step: 12
Training loss: 1.2221301229532842
Validation loss: 2.693001845838842

Epoch: 6| Step: 13
Training loss: 0.8234124601491094
Validation loss: 2.6984812733714927

Epoch: 244| Step: 0
Training loss: 1.4846619178143319
Validation loss: 2.6910665055261336

Epoch: 6| Step: 1
Training loss: 1.824980027599002
Validation loss: 2.7118248904008393

Epoch: 6| Step: 2
Training loss: 1.3094528794173186
Validation loss: 2.68153989160658

Epoch: 6| Step: 3
Training loss: 1.4672190214920873
Validation loss: 2.698806276476788

Epoch: 6| Step: 4
Training loss: 1.262151212952192
Validation loss: 2.6585596436570627

Epoch: 6| Step: 5
Training loss: 1.0409461135988864
Validation loss: 2.6798977271474587

Epoch: 6| Step: 6
Training loss: 0.889862034905369
Validation loss: 2.6658938528872884

Epoch: 6| Step: 7
Training loss: 1.4523131040527621
Validation loss: 2.6988626857292135

Epoch: 6| Step: 8
Training loss: 1.5011663670554203
Validation loss: 2.679540318171294

Epoch: 6| Step: 9
Training loss: 0.9988836971931159
Validation loss: 2.692686658790149

Epoch: 6| Step: 10
Training loss: 1.3622576961821486
Validation loss: 2.652928342195272

Epoch: 6| Step: 11
Training loss: 1.726539715232507
Validation loss: 2.6975057107364555

Epoch: 6| Step: 12
Training loss: 1.4404871214714987
Validation loss: 2.6608756684821104

Epoch: 6| Step: 13
Training loss: 1.093914836996414
Validation loss: 2.6858390956681677

Epoch: 245| Step: 0
Training loss: 1.9439249873739637
Validation loss: 2.6748224856773533

Epoch: 6| Step: 1
Training loss: 1.3355628040275351
Validation loss: 2.7012040222023637

Epoch: 6| Step: 2
Training loss: 1.035720268476523
Validation loss: 2.704864367224555

Epoch: 6| Step: 3
Training loss: 1.2209316192399406
Validation loss: 2.694131355975223

Epoch: 6| Step: 4
Training loss: 1.1051520982554033
Validation loss: 2.7269967031928664

Epoch: 6| Step: 5
Training loss: 1.4966648694957203
Validation loss: 2.750789860776182

Epoch: 6| Step: 6
Training loss: 1.452653623851213
Validation loss: 2.7269863846718287

Epoch: 6| Step: 7
Training loss: 1.6487695440908303
Validation loss: 2.6890986667849415

Epoch: 6| Step: 8
Training loss: 1.3544990522874887
Validation loss: 2.714707801609677

Epoch: 6| Step: 9
Training loss: 0.7023820130445648
Validation loss: 2.6982111641635322

Epoch: 6| Step: 10
Training loss: 1.6025527497892023
Validation loss: 2.694058869549453

Epoch: 6| Step: 11
Training loss: 1.2033006118823582
Validation loss: 2.676526577024239

Epoch: 6| Step: 12
Training loss: 1.3189521417676835
Validation loss: 2.703269920943157

Epoch: 6| Step: 13
Training loss: 0.7671060056580354
Validation loss: 2.687410513858746

Epoch: 246| Step: 0
Training loss: 2.0804192061905042
Validation loss: 2.707643952833134

Epoch: 6| Step: 1
Training loss: 1.195680947956448
Validation loss: 2.6954112615766643

Epoch: 6| Step: 2
Training loss: 1.2780269930321595
Validation loss: 2.6943586209874706

Epoch: 6| Step: 3
Training loss: 1.2385068862347826
Validation loss: 2.7005752316080973

Epoch: 6| Step: 4
Training loss: 1.4632978496434825
Validation loss: 2.686403015834733

Epoch: 6| Step: 5
Training loss: 1.2329060952903417
Validation loss: 2.689220491118363

Epoch: 6| Step: 6
Training loss: 1.0774652425023552
Validation loss: 2.7051065449006386

Epoch: 6| Step: 7
Training loss: 1.2373065180716036
Validation loss: 2.70021174514726

Epoch: 6| Step: 8
Training loss: 1.4536391138376845
Validation loss: 2.6933055252031406

Epoch: 6| Step: 9
Training loss: 1.4714282351955077
Validation loss: 2.7053563206934776

Epoch: 6| Step: 10
Training loss: 0.69684601026374
Validation loss: 2.717215871215522

Epoch: 6| Step: 11
Training loss: 1.3041677753252836
Validation loss: 2.7112963109994257

Epoch: 6| Step: 12
Training loss: 1.3513482425628163
Validation loss: 2.715107449484364

Epoch: 6| Step: 13
Training loss: 1.0132430093647877
Validation loss: 2.7182509082423087

Epoch: 247| Step: 0
Training loss: 1.5757140826622997
Validation loss: 2.716628285291717

Epoch: 6| Step: 1
Training loss: 1.3667492409315525
Validation loss: 2.7249156443241804

Epoch: 6| Step: 2
Training loss: 1.3221322785478575
Validation loss: 2.7003129127188514

Epoch: 6| Step: 3
Training loss: 1.4683316223330853
Validation loss: 2.7144260611924413

Epoch: 6| Step: 4
Training loss: 0.9999237925578676
Validation loss: 2.706334953961174

Epoch: 6| Step: 5
Training loss: 1.0561876154427239
Validation loss: 2.7193564564959876

Epoch: 6| Step: 6
Training loss: 1.6492697255665272
Validation loss: 2.692824135915539

Epoch: 6| Step: 7
Training loss: 1.268564413619253
Validation loss: 2.6833339967333854

Epoch: 6| Step: 8
Training loss: 1.2790508470486768
Validation loss: 2.677042628555343

Epoch: 6| Step: 9
Training loss: 1.0740021088364566
Validation loss: 2.6793893527262687

Epoch: 6| Step: 10
Training loss: 1.5992809140078519
Validation loss: 2.6886670611324677

Epoch: 6| Step: 11
Training loss: 0.9257034075882489
Validation loss: 2.7259126883123597

Epoch: 6| Step: 12
Training loss: 1.424798998125207
Validation loss: 2.703727608052475

Epoch: 6| Step: 13
Training loss: 1.125762680927704
Validation loss: 2.684867217958344

Epoch: 248| Step: 0
Training loss: 1.1467469416748675
Validation loss: 2.7107060460023

Epoch: 6| Step: 1
Training loss: 1.3516622517549322
Validation loss: 2.7010008863024013

Epoch: 6| Step: 2
Training loss: 1.146327617267919
Validation loss: 2.7023347440042302

Epoch: 6| Step: 3
Training loss: 1.6186059453191608
Validation loss: 2.7019236807547697

Epoch: 6| Step: 4
Training loss: 1.3891834116298183
Validation loss: 2.7187363064705967

Epoch: 6| Step: 5
Training loss: 0.6415201306741279
Validation loss: 2.700692941534215

Epoch: 6| Step: 6
Training loss: 1.2227033904619133
Validation loss: 2.678535378062628

Epoch: 6| Step: 7
Training loss: 1.0171808503339372
Validation loss: 2.6579226994442666

Epoch: 6| Step: 8
Training loss: 1.821917697936155
Validation loss: 2.6944761629235394

Epoch: 6| Step: 9
Training loss: 1.5400002812719706
Validation loss: 2.6922790101941914

Epoch: 6| Step: 10
Training loss: 1.018512201931822
Validation loss: 2.697181554632713

Epoch: 6| Step: 11
Training loss: 1.3453084646556557
Validation loss: 2.708973649076014

Epoch: 6| Step: 12
Training loss: 1.2542708867937962
Validation loss: 2.679537922716347

Epoch: 6| Step: 13
Training loss: 1.1486991013467693
Validation loss: 2.673544378947844

Epoch: 249| Step: 0
Training loss: 1.0154495674618866
Validation loss: 2.7074571490592207

Epoch: 6| Step: 1
Training loss: 1.5785041580217931
Validation loss: 2.693006694186801

Epoch: 6| Step: 2
Training loss: 1.5815376170940252
Validation loss: 2.6637513609293726

Epoch: 6| Step: 3
Training loss: 1.0867070826131067
Validation loss: 2.680836399957456

Epoch: 6| Step: 4
Training loss: 1.7207706018179212
Validation loss: 2.6624477478597153

Epoch: 6| Step: 5
Training loss: 1.11529711865833
Validation loss: 2.680745545711569

Epoch: 6| Step: 6
Training loss: 1.0055695644009355
Validation loss: 2.6556099928331167

Epoch: 6| Step: 7
Training loss: 1.2130250718056497
Validation loss: 2.674673256226473

Epoch: 6| Step: 8
Training loss: 1.3650137923665204
Validation loss: 2.6569104449104977

Epoch: 6| Step: 9
Training loss: 1.5230660792722797
Validation loss: 2.6328088446262785

Epoch: 6| Step: 10
Training loss: 1.151314485879031
Validation loss: 2.680098292956235

Epoch: 6| Step: 11
Training loss: 1.1145287735084048
Validation loss: 2.6536950831149326

Epoch: 6| Step: 12
Training loss: 1.2444745967444006
Validation loss: 2.6382533917829876

Epoch: 6| Step: 13
Training loss: 0.8040255814819188
Validation loss: 2.663156885402587

Epoch: 250| Step: 0
Training loss: 1.1350629354664823
Validation loss: 2.6635574248403984

Epoch: 6| Step: 1
Training loss: 1.3920517792142248
Validation loss: 2.6475047583668316

Epoch: 6| Step: 2
Training loss: 1.0726747270897288
Validation loss: 2.647162875549213

Epoch: 6| Step: 3
Training loss: 0.9922515367883847
Validation loss: 2.6666226870489007

Epoch: 6| Step: 4
Training loss: 1.6007214826873284
Validation loss: 2.685950148805484

Epoch: 6| Step: 5
Training loss: 1.2099576862282286
Validation loss: 2.6652695921099094

Epoch: 6| Step: 6
Training loss: 1.7097339316052438
Validation loss: 2.6948666924825977

Epoch: 6| Step: 7
Training loss: 1.0048855409872457
Validation loss: 2.691236023998417

Epoch: 6| Step: 8
Training loss: 1.4221206285198762
Validation loss: 2.7040669297800513

Epoch: 6| Step: 9
Training loss: 1.5267840284244214
Validation loss: 2.7024267706686644

Epoch: 6| Step: 10
Training loss: 1.275993543482981
Validation loss: 2.7340038707506604

Epoch: 6| Step: 11
Training loss: 1.3100954463636472
Validation loss: 2.721848358031068

Epoch: 6| Step: 12
Training loss: 1.2107014579832858
Validation loss: 2.767333565066042

Epoch: 6| Step: 13
Training loss: 0.5368844966026313
Validation loss: 2.779792922918371

Epoch: 251| Step: 0
Training loss: 0.9232565016632509
Validation loss: 2.804847859178283

Epoch: 6| Step: 1
Training loss: 1.4272684780039924
Validation loss: 2.7705993865072807

Epoch: 6| Step: 2
Training loss: 0.7942006731574675
Validation loss: 2.7851551914643107

Epoch: 6| Step: 3
Training loss: 0.9347032793218718
Validation loss: 2.772010996755549

Epoch: 6| Step: 4
Training loss: 1.3471766406254055
Validation loss: 2.748161587037057

Epoch: 6| Step: 5
Training loss: 2.124375083139973
Validation loss: 2.731493952291092

Epoch: 6| Step: 6
Training loss: 0.5394357688150304
Validation loss: 2.6696292160998962

Epoch: 6| Step: 7
Training loss: 1.5894359468631971
Validation loss: 2.6953356375228017

Epoch: 6| Step: 8
Training loss: 1.2555419140940198
Validation loss: 2.630553072951142

Epoch: 6| Step: 9
Training loss: 1.031451003397184
Validation loss: 2.6568019865253554

Epoch: 6| Step: 10
Training loss: 1.3388601980437318
Validation loss: 2.6677311540283033

Epoch: 6| Step: 11
Training loss: 0.9386506331029001
Validation loss: 2.6773240916555476

Epoch: 6| Step: 12
Training loss: 1.3752469794665467
Validation loss: 2.6796257992311614

Epoch: 6| Step: 13
Training loss: 1.4462347439000007
Validation loss: 2.6845014833221343

Epoch: 252| Step: 0
Training loss: 0.9709469893783395
Validation loss: 2.688349399520041

Epoch: 6| Step: 1
Training loss: 1.1668143292485824
Validation loss: 2.7196759061830442

Epoch: 6| Step: 2
Training loss: 1.7481717368770153
Validation loss: 2.7069237239374915

Epoch: 6| Step: 3
Training loss: 0.8761537982846369
Validation loss: 2.7061583403353224

Epoch: 6| Step: 4
Training loss: 1.4002208739842303
Validation loss: 2.7250371534756184

Epoch: 6| Step: 5
Training loss: 0.9679101564470585
Validation loss: 2.6544318851741284

Epoch: 6| Step: 6
Training loss: 1.3267734606968598
Validation loss: 2.6972332227044866

Epoch: 6| Step: 7
Training loss: 1.2124849829776152
Validation loss: 2.688996089598532

Epoch: 6| Step: 8
Training loss: 1.3842570631368212
Validation loss: 2.6780821058049558

Epoch: 6| Step: 9
Training loss: 1.4847051955934774
Validation loss: 2.6645464848610674

Epoch: 6| Step: 10
Training loss: 0.8865519631438346
Validation loss: 2.662943714479223

Epoch: 6| Step: 11
Training loss: 1.370833412951126
Validation loss: 2.705176672201607

Epoch: 6| Step: 12
Training loss: 1.2147577874781332
Validation loss: 2.7292887993746056

Epoch: 6| Step: 13
Training loss: 1.2347315985418135
Validation loss: 2.75274593636912

Epoch: 253| Step: 0
Training loss: 1.0951098027328146
Validation loss: 2.7323918083106062

Epoch: 6| Step: 1
Training loss: 0.9498053414030528
Validation loss: 2.737203560001878

Epoch: 6| Step: 2
Training loss: 1.108056587908784
Validation loss: 2.7637844451063724

Epoch: 6| Step: 3
Training loss: 1.4650530449439405
Validation loss: 2.776572908838131

Epoch: 6| Step: 4
Training loss: 1.0497207111216427
Validation loss: 2.730648747406007

Epoch: 6| Step: 5
Training loss: 1.240502275983759
Validation loss: 2.696118726406743

Epoch: 6| Step: 6
Training loss: 1.0377102420536346
Validation loss: 2.6689075724413134

Epoch: 6| Step: 7
Training loss: 0.9788802147254977
Validation loss: 2.6784426630949754

Epoch: 6| Step: 8
Training loss: 1.954106198848198
Validation loss: 2.6541264460937986

Epoch: 6| Step: 9
Training loss: 1.1706499944932018
Validation loss: 2.636043985758736

Epoch: 6| Step: 10
Training loss: 1.0294115845896459
Validation loss: 2.6403478991714873

Epoch: 6| Step: 11
Training loss: 1.3352656320193608
Validation loss: 2.648417602080994

Epoch: 6| Step: 12
Training loss: 1.1030115647388434
Validation loss: 2.660773020702966

Epoch: 6| Step: 13
Training loss: 1.5302882385511873
Validation loss: 2.6668753942842716

Epoch: 254| Step: 0
Training loss: 1.383380536151141
Validation loss: 2.6926619780273326

Epoch: 6| Step: 1
Training loss: 1.226865548764484
Validation loss: 2.706880997577905

Epoch: 6| Step: 2
Training loss: 1.6451709074153096
Validation loss: 2.742765402376675

Epoch: 6| Step: 3
Training loss: 0.9440720040412129
Validation loss: 2.714003763648305

Epoch: 6| Step: 4
Training loss: 1.367633812126609
Validation loss: 2.726960377613956

Epoch: 6| Step: 5
Training loss: 1.2562358760514232
Validation loss: 2.722256673497622

Epoch: 6| Step: 6
Training loss: 1.2365384518066254
Validation loss: 2.727936297720301

Epoch: 6| Step: 7
Training loss: 1.0931594344179658
Validation loss: 2.6938625683240587

Epoch: 6| Step: 8
Training loss: 1.2220069209151003
Validation loss: 2.7122109776101273

Epoch: 6| Step: 9
Training loss: 0.9794038255413889
Validation loss: 2.6832412990052026

Epoch: 6| Step: 10
Training loss: 0.9981669672848087
Validation loss: 2.690935448377524

Epoch: 6| Step: 11
Training loss: 1.126227874369172
Validation loss: 2.703974563578505

Epoch: 6| Step: 12
Training loss: 1.301243971811599
Validation loss: 2.688166654663428

Epoch: 6| Step: 13
Training loss: 0.9816639215488188
Validation loss: 2.714320392141935

Epoch: 255| Step: 0
Training loss: 1.2838721077408894
Validation loss: 2.7222050528214714

Epoch: 6| Step: 1
Training loss: 1.1450824126523589
Validation loss: 2.7063662431865523

Epoch: 6| Step: 2
Training loss: 1.6486046150434475
Validation loss: 2.7082722173441645

Epoch: 6| Step: 3
Training loss: 0.8820006764792099
Validation loss: 2.72147738097371

Epoch: 6| Step: 4
Training loss: 1.3520798327023997
Validation loss: 2.7260493724066337

Epoch: 6| Step: 5
Training loss: 1.341804026844227
Validation loss: 2.7346630426393057

Epoch: 6| Step: 6
Training loss: 1.2792258672445185
Validation loss: 2.73724722259655

Epoch: 6| Step: 7
Training loss: 1.075433384231954
Validation loss: 2.716490700123222

Epoch: 6| Step: 8
Training loss: 1.4849370595007423
Validation loss: 2.706599458763972

Epoch: 6| Step: 9
Training loss: 0.8576783511357612
Validation loss: 2.7016189536558164

Epoch: 6| Step: 10
Training loss: 1.2284794303280522
Validation loss: 2.7227275617362827

Epoch: 6| Step: 11
Training loss: 0.9486598500480241
Validation loss: 2.6955508927587073

Epoch: 6| Step: 12
Training loss: 1.231343615308447
Validation loss: 2.695287110891395

Epoch: 6| Step: 13
Training loss: 0.878597256068168
Validation loss: 2.68572472090283

Epoch: 256| Step: 0
Training loss: 1.3533462044067803
Validation loss: 2.717640247757011

Epoch: 6| Step: 1
Training loss: 1.7101616341343622
Validation loss: 2.6868000316132568

Epoch: 6| Step: 2
Training loss: 1.0281091891757186
Validation loss: 2.7122859090242755

Epoch: 6| Step: 3
Training loss: 1.1515341808299704
Validation loss: 2.6942382954658144

Epoch: 6| Step: 4
Training loss: 1.0666114693506221
Validation loss: 2.7081353795963428

Epoch: 6| Step: 5
Training loss: 0.9823391160936066
Validation loss: 2.7154683076140644

Epoch: 6| Step: 6
Training loss: 1.4331183619788415
Validation loss: 2.7394547061270442

Epoch: 6| Step: 7
Training loss: 1.09111867186518
Validation loss: 2.73138887596684

Epoch: 6| Step: 8
Training loss: 1.1836058361078465
Validation loss: 2.7430439245551064

Epoch: 6| Step: 9
Training loss: 1.0894327243168245
Validation loss: 2.7410450816248813

Epoch: 6| Step: 10
Training loss: 1.0276188935224975
Validation loss: 2.7265442365923285

Epoch: 6| Step: 11
Training loss: 1.1826826057012283
Validation loss: 2.730566952614622

Epoch: 6| Step: 12
Training loss: 1.3053735539662936
Validation loss: 2.7206178532880703

Epoch: 6| Step: 13
Training loss: 1.2185422769224208
Validation loss: 2.6999140915673077

Epoch: 257| Step: 0
Training loss: 1.1455671290189078
Validation loss: 2.6860404418948427

Epoch: 6| Step: 1
Training loss: 1.1132527665627072
Validation loss: 2.6080337397044793

Epoch: 6| Step: 2
Training loss: 1.5655462705876668
Validation loss: 2.5222807386368777

Epoch: 6| Step: 3
Training loss: 1.090337935216886
Validation loss: 2.514228032929995

Epoch: 6| Step: 4
Training loss: 1.3604132534917024
Validation loss: 2.5194890566847277

Epoch: 6| Step: 5
Training loss: 1.7725347834565144
Validation loss: 2.5411173769769095

Epoch: 6| Step: 6
Training loss: 0.7440598010927844
Validation loss: 2.589306004924268

Epoch: 6| Step: 7
Training loss: 0.9603700280329549
Validation loss: 2.667878599131205

Epoch: 6| Step: 8
Training loss: 1.4103122952421154
Validation loss: 2.7057484113031802

Epoch: 6| Step: 9
Training loss: 1.8240134146096694
Validation loss: 2.761778423657131

Epoch: 6| Step: 10
Training loss: 0.9711615172821879
Validation loss: 2.787735167242531

Epoch: 6| Step: 11
Training loss: 0.8527322486924325
Validation loss: 2.8145348282971576

Epoch: 6| Step: 12
Training loss: 1.1201875326987425
Validation loss: 2.7975170200426214

Epoch: 6| Step: 13
Training loss: 0.917091827341688
Validation loss: 2.7976011267567222

Epoch: 258| Step: 0
Training loss: 1.0389981357458606
Validation loss: 2.8054920004413977

Epoch: 6| Step: 1
Training loss: 1.0490093962518556
Validation loss: 2.7792958658874474

Epoch: 6| Step: 2
Training loss: 0.5813190788320857
Validation loss: 2.757533254995861

Epoch: 6| Step: 3
Training loss: 1.7849293904804342
Validation loss: 2.701127010449167

Epoch: 6| Step: 4
Training loss: 1.1495442150650519
Validation loss: 2.6886802260572393

Epoch: 6| Step: 5
Training loss: 1.296629089572613
Validation loss: 2.6605531585139444

Epoch: 6| Step: 6
Training loss: 1.2838154671531974
Validation loss: 2.660130618830846

Epoch: 6| Step: 7
Training loss: 1.4098178108684536
Validation loss: 2.690406397251635

Epoch: 6| Step: 8
Training loss: 1.0879657931700584
Validation loss: 2.691321582237249

Epoch: 6| Step: 9
Training loss: 1.126147003375523
Validation loss: 2.6813704599971158

Epoch: 6| Step: 10
Training loss: 0.9823532535559872
Validation loss: 2.7168821991695062

Epoch: 6| Step: 11
Training loss: 0.6892284859449823
Validation loss: 2.7418743672638253

Epoch: 6| Step: 12
Training loss: 1.305060784396826
Validation loss: 2.7726686212893124

Epoch: 6| Step: 13
Training loss: 1.8019637654352343
Validation loss: 2.7480325676105175

Epoch: 259| Step: 0
Training loss: 1.0007094608380003
Validation loss: 2.769251593468407

Epoch: 6| Step: 1
Training loss: 1.0296286350494976
Validation loss: 2.7578697065027686

Epoch: 6| Step: 2
Training loss: 0.9668479212376234
Validation loss: 2.7418328344420173

Epoch: 6| Step: 3
Training loss: 1.1272599514953237
Validation loss: 2.7271927617752585

Epoch: 6| Step: 4
Training loss: 1.1104819456931798
Validation loss: 2.7217189338084737

Epoch: 6| Step: 5
Training loss: 1.384379947903232
Validation loss: 2.7325257116508865

Epoch: 6| Step: 6
Training loss: 1.0305208460528468
Validation loss: 2.7408311587082212

Epoch: 6| Step: 7
Training loss: 1.7048559229768159
Validation loss: 2.7431891991395436

Epoch: 6| Step: 8
Training loss: 1.09554878548621
Validation loss: 2.744734949126544

Epoch: 6| Step: 9
Training loss: 0.8718349912480968
Validation loss: 2.755873416171159

Epoch: 6| Step: 10
Training loss: 1.3111385823234667
Validation loss: 2.757673948258035

Epoch: 6| Step: 11
Training loss: 1.280479059649166
Validation loss: 2.7380742958035844

Epoch: 6| Step: 12
Training loss: 1.3531606409607697
Validation loss: 2.7523164194286682

Epoch: 6| Step: 13
Training loss: 0.8561124078507133
Validation loss: 2.7454077925052367

Epoch: 260| Step: 0
Training loss: 0.9265199764072393
Validation loss: 2.777318262492365

Epoch: 6| Step: 1
Training loss: 1.0313593488575308
Validation loss: 2.729374539868183

Epoch: 6| Step: 2
Training loss: 1.315029884985102
Validation loss: 2.735330542330642

Epoch: 6| Step: 3
Training loss: 1.1208341078536939
Validation loss: 2.7289997554846837

Epoch: 6| Step: 4
Training loss: 0.5821409698091315
Validation loss: 2.7381305552177944

Epoch: 6| Step: 5
Training loss: 1.5576776474845173
Validation loss: 2.7276365951938817

Epoch: 6| Step: 6
Training loss: 0.8165575827192478
Validation loss: 2.731159668585018

Epoch: 6| Step: 7
Training loss: 0.9588110431102826
Validation loss: 2.7367245331948022

Epoch: 6| Step: 8
Training loss: 1.9495161360967836
Validation loss: 2.740648242740893

Epoch: 6| Step: 9
Training loss: 0.9205228943927779
Validation loss: 2.745390747941618

Epoch: 6| Step: 10
Training loss: 0.5808026191776504
Validation loss: 2.769241599955842

Epoch: 6| Step: 11
Training loss: 1.3765540444225888
Validation loss: 2.779080481153067

Epoch: 6| Step: 12
Training loss: 1.0580444036659256
Validation loss: 2.7852267190375883

Epoch: 6| Step: 13
Training loss: 1.110662599613014
Validation loss: 2.8061055411865294

Epoch: 261| Step: 0
Training loss: 1.0565608588552606
Validation loss: 2.7822217986775235

Epoch: 6| Step: 1
Training loss: 0.8442663802528176
Validation loss: 2.7779287168724287

Epoch: 6| Step: 2
Training loss: 1.3253936506709587
Validation loss: 2.762335224366539

Epoch: 6| Step: 3
Training loss: 1.0736032283066423
Validation loss: 2.7293709311608803

Epoch: 6| Step: 4
Training loss: 1.0133461254236846
Validation loss: 2.7438440098268906

Epoch: 6| Step: 5
Training loss: 0.9497178260954625
Validation loss: 2.7258894609417172

Epoch: 6| Step: 6
Training loss: 0.9001793603193389
Validation loss: 2.722675987651499

Epoch: 6| Step: 7
Training loss: 1.649201419509769
Validation loss: 2.722386227534336

Epoch: 6| Step: 8
Training loss: 1.2953004585691152
Validation loss: 2.6843599814145827

Epoch: 6| Step: 9
Training loss: 1.1169273767213739
Validation loss: 2.7030512486542912

Epoch: 6| Step: 10
Training loss: 0.9023024644530753
Validation loss: 2.7105102315835436

Epoch: 6| Step: 11
Training loss: 1.1627670350550317
Validation loss: 2.678693889644886

Epoch: 6| Step: 12
Training loss: 1.1079360871455821
Validation loss: 2.6819076565861004

Epoch: 6| Step: 13
Training loss: 1.2565514065343641
Validation loss: 2.728611207064891

Epoch: 262| Step: 0
Training loss: 1.1382987979957973
Validation loss: 2.656672344374879

Epoch: 6| Step: 1
Training loss: 1.1003980501606236
Validation loss: 2.7256135867466607

Epoch: 6| Step: 2
Training loss: 0.832001806463518
Validation loss: 2.7173054381327306

Epoch: 6| Step: 3
Training loss: 0.9376778116084828
Validation loss: 2.7448815099525103

Epoch: 6| Step: 4
Training loss: 1.5063280299065842
Validation loss: 2.7385394863858794

Epoch: 6| Step: 5
Training loss: 1.1696644087358627
Validation loss: 2.728669894828745

Epoch: 6| Step: 6
Training loss: 1.2129055151278787
Validation loss: 2.7286693884272806

Epoch: 6| Step: 7
Training loss: 1.297608776935146
Validation loss: 2.712965000433335

Epoch: 6| Step: 8
Training loss: 0.87862707154587
Validation loss: 2.6887415264453

Epoch: 6| Step: 9
Training loss: 0.9722004630666264
Validation loss: 2.7083195921846683

Epoch: 6| Step: 10
Training loss: 1.1354955010066734
Validation loss: 2.669981199873296

Epoch: 6| Step: 11
Training loss: 1.149044162084155
Validation loss: 2.7095405592088424

Epoch: 6| Step: 12
Training loss: 1.0958058246210582
Validation loss: 2.6769613007788964

Epoch: 6| Step: 13
Training loss: 1.0973910082527087
Validation loss: 2.703554710495396

Epoch: 263| Step: 0
Training loss: 0.782036842836851
Validation loss: 2.702314718324285

Epoch: 6| Step: 1
Training loss: 0.6251494705759342
Validation loss: 2.7513635513967105

Epoch: 6| Step: 2
Training loss: 1.013854376032762
Validation loss: 2.705345326423014

Epoch: 6| Step: 3
Training loss: 1.1270980345119206
Validation loss: 2.734228933625674

Epoch: 6| Step: 4
Training loss: 0.7941432204159545
Validation loss: 2.7257489667506616

Epoch: 6| Step: 5
Training loss: 1.3751119654758697
Validation loss: 2.6768762379038797

Epoch: 6| Step: 6
Training loss: 1.5818804633725585
Validation loss: 2.6925607743468607

Epoch: 6| Step: 7
Training loss: 0.9620203879212348
Validation loss: 2.6836106993800373

Epoch: 6| Step: 8
Training loss: 0.9857051883992469
Validation loss: 2.71331509223344

Epoch: 6| Step: 9
Training loss: 1.020734405914189
Validation loss: 2.682861642385471

Epoch: 6| Step: 10
Training loss: 1.3828013791429143
Validation loss: 2.7171064016663133

Epoch: 6| Step: 11
Training loss: 1.0323673321926121
Validation loss: 2.712296106720148

Epoch: 6| Step: 12
Training loss: 1.3997558687430778
Validation loss: 2.7196710770993264

Epoch: 6| Step: 13
Training loss: 1.4730965439285963
Validation loss: 2.7035559493812635

Epoch: 264| Step: 0
Training loss: 0.9090842290112681
Validation loss: 2.7237792118039876

Epoch: 6| Step: 1
Training loss: 1.235064543300043
Validation loss: 2.747009963769367

Epoch: 6| Step: 2
Training loss: 1.1217924592407889
Validation loss: 2.7756484854363093

Epoch: 6| Step: 3
Training loss: 1.3511716244364558
Validation loss: 2.762317143646329

Epoch: 6| Step: 4
Training loss: 0.9031852332491864
Validation loss: 2.7487043720106468

Epoch: 6| Step: 5
Training loss: 1.1109237605665754
Validation loss: 2.7333525984370555

Epoch: 6| Step: 6
Training loss: 0.9945223811638906
Validation loss: 2.7426483979516627

Epoch: 6| Step: 7
Training loss: 0.9376814666596662
Validation loss: 2.7458674123538533

Epoch: 6| Step: 8
Training loss: 1.0938329392730393
Validation loss: 2.677754896612213

Epoch: 6| Step: 9
Training loss: 1.347506219003796
Validation loss: 2.686406703256374

Epoch: 6| Step: 10
Training loss: 0.6654667536357842
Validation loss: 2.6637827904086984

Epoch: 6| Step: 11
Training loss: 0.7646024843636079
Validation loss: 2.6625911142635847

Epoch: 6| Step: 12
Training loss: 1.6322055400367803
Validation loss: 2.6823755617737843

Epoch: 6| Step: 13
Training loss: 1.5043822488899377
Validation loss: 2.6716339380622203

Epoch: 265| Step: 0
Training loss: 1.7184559657271374
Validation loss: 2.684600775353552

Epoch: 6| Step: 1
Training loss: 0.825767616585291
Validation loss: 2.7026030571041955

Epoch: 6| Step: 2
Training loss: 0.9668931084720557
Validation loss: 2.6832837224858284

Epoch: 6| Step: 3
Training loss: 0.6050019956981436
Validation loss: 2.7125038850492884

Epoch: 6| Step: 4
Training loss: 0.7765958245416898
Validation loss: 2.733469611546566

Epoch: 6| Step: 5
Training loss: 1.0959608349519874
Validation loss: 2.737209344382721

Epoch: 6| Step: 6
Training loss: 1.2678748020193402
Validation loss: 2.73464883537715

Epoch: 6| Step: 7
Training loss: 1.4257493106974821
Validation loss: 2.700258898732271

Epoch: 6| Step: 8
Training loss: 1.3029615212773016
Validation loss: 2.706564469657295

Epoch: 6| Step: 9
Training loss: 1.0680544904602411
Validation loss: 2.673579545126149

Epoch: 6| Step: 10
Training loss: 0.8667761024437499
Validation loss: 2.684856739433728

Epoch: 6| Step: 11
Training loss: 1.3172038121418217
Validation loss: 2.6738619250229925

Epoch: 6| Step: 12
Training loss: 0.44031002000661257
Validation loss: 2.6900147417418347

Epoch: 6| Step: 13
Training loss: 0.9832628113033013
Validation loss: 2.6883666517253335

Epoch: 266| Step: 0
Training loss: 1.3213115726873865
Validation loss: 2.693575021349158

Epoch: 6| Step: 1
Training loss: 0.8570047463115362
Validation loss: 2.7114364733637824

Epoch: 6| Step: 2
Training loss: 1.1687135904934125
Validation loss: 2.733146085210499

Epoch: 6| Step: 3
Training loss: 1.6422568788400347
Validation loss: 2.7259653687320298

Epoch: 6| Step: 4
Training loss: 0.5561667047778193
Validation loss: 2.701253914525372

Epoch: 6| Step: 5
Training loss: 1.356831945213286
Validation loss: 2.6905408836981293

Epoch: 6| Step: 6
Training loss: 0.9267763351020438
Validation loss: 2.729627019185632

Epoch: 6| Step: 7
Training loss: 0.7925907981915956
Validation loss: 2.700147373088624

Epoch: 6| Step: 8
Training loss: 0.9522833938812347
Validation loss: 2.7247229040942953

Epoch: 6| Step: 9
Training loss: 0.9863947477596103
Validation loss: 2.761562025436304

Epoch: 6| Step: 10
Training loss: 1.2129198153756429
Validation loss: 2.7400251656348105

Epoch: 6| Step: 11
Training loss: 1.1007837559473173
Validation loss: 2.736376514981749

Epoch: 6| Step: 12
Training loss: 0.733762363804072
Validation loss: 2.7189154465570224

Epoch: 6| Step: 13
Training loss: 1.2737278987475749
Validation loss: 2.7016220965020104

Epoch: 267| Step: 0
Training loss: 1.1367856035531676
Validation loss: 2.667341020293668

Epoch: 6| Step: 1
Training loss: 1.0316689536131458
Validation loss: 2.6652076181591244

Epoch: 6| Step: 2
Training loss: 1.0573260610213295
Validation loss: 2.6516129247129823

Epoch: 6| Step: 3
Training loss: 1.4445657811594466
Validation loss: 2.640006081972484

Epoch: 6| Step: 4
Training loss: 0.869830220142774
Validation loss: 2.6380408780216587

Epoch: 6| Step: 5
Training loss: 1.2493830111820678
Validation loss: 2.65525824643283

Epoch: 6| Step: 6
Training loss: 1.5408986558507147
Validation loss: 2.629088170189128

Epoch: 6| Step: 7
Training loss: 1.0527973333156866
Validation loss: 2.6412734164973513

Epoch: 6| Step: 8
Training loss: 1.1659283118089157
Validation loss: 2.6330264833935972

Epoch: 6| Step: 9
Training loss: 0.8205450545778106
Validation loss: 2.644106359374027

Epoch: 6| Step: 10
Training loss: 0.9411962757761593
Validation loss: 2.642846342246771

Epoch: 6| Step: 11
Training loss: 0.809126305390355
Validation loss: 2.6622335957068914

Epoch: 6| Step: 12
Training loss: 0.9271727136680693
Validation loss: 2.6822963311146553

Epoch: 6| Step: 13
Training loss: 1.013042041128356
Validation loss: 2.6903094664121956

Epoch: 268| Step: 0
Training loss: 0.9123958815654369
Validation loss: 2.704206552013366

Epoch: 6| Step: 1
Training loss: 1.2628223328749195
Validation loss: 2.7025082029302947

Epoch: 6| Step: 2
Training loss: 1.1534435132122365
Validation loss: 2.7521209871711196

Epoch: 6| Step: 3
Training loss: 0.8524376108603143
Validation loss: 2.7171711158981426

Epoch: 6| Step: 4
Training loss: 0.9493677155828619
Validation loss: 2.7016198750643032

Epoch: 6| Step: 5
Training loss: 1.1510489738312966
Validation loss: 2.7172058042581844

Epoch: 6| Step: 6
Training loss: 1.2247392260078926
Validation loss: 2.682684965098823

Epoch: 6| Step: 7
Training loss: 0.513183651823409
Validation loss: 2.681024994499485

Epoch: 6| Step: 8
Training loss: 1.0323154263243308
Validation loss: 2.680795705944346

Epoch: 6| Step: 9
Training loss: 1.0641416321400945
Validation loss: 2.643057346422241

Epoch: 6| Step: 10
Training loss: 1.1766412067810812
Validation loss: 2.632379981675361

Epoch: 6| Step: 11
Training loss: 0.7219256445223599
Validation loss: 2.5690443521943087

Epoch: 6| Step: 12
Training loss: 1.167969974785102
Validation loss: 2.583328880864599

Epoch: 6| Step: 13
Training loss: 2.112763346673122
Validation loss: 2.611008899194799

Epoch: 269| Step: 0
Training loss: 0.7701881045167546
Validation loss: 2.6204031136523307

Epoch: 6| Step: 1
Training loss: 1.245085592430017
Validation loss: 2.6406549771320837

Epoch: 6| Step: 2
Training loss: 1.1738225394066877
Validation loss: 2.6528795906731446

Epoch: 6| Step: 3
Training loss: 0.8936578076170253
Validation loss: 2.7045580775612965

Epoch: 6| Step: 4
Training loss: 0.8825379679025607
Validation loss: 2.70856706322224

Epoch: 6| Step: 5
Training loss: 1.7977865146222431
Validation loss: 2.7107317786954734

Epoch: 6| Step: 6
Training loss: 0.5530508368822137
Validation loss: 2.706917360580621

Epoch: 6| Step: 7
Training loss: 1.1104463588807603
Validation loss: 2.7618550140228253

Epoch: 6| Step: 8
Training loss: 0.9283944121036888
Validation loss: 2.7601895802930776

Epoch: 6| Step: 9
Training loss: 1.1877875732760996
Validation loss: 2.7473511118015077

Epoch: 6| Step: 10
Training loss: 1.024290646518173
Validation loss: 2.7647963285183206

Epoch: 6| Step: 11
Training loss: 1.1898814465267686
Validation loss: 2.7321657205279193

Epoch: 6| Step: 12
Training loss: 0.8915606486197315
Validation loss: 2.7464306913950156

Epoch: 6| Step: 13
Training loss: 0.7275614280591202
Validation loss: 2.7246082044947286

Epoch: 270| Step: 0
Training loss: 0.8620893094934405
Validation loss: 2.709168382239864

Epoch: 6| Step: 1
Training loss: 1.2675280450882118
Validation loss: 2.7107339075497

Epoch: 6| Step: 2
Training loss: 0.9066438148110423
Validation loss: 2.735093097296466

Epoch: 6| Step: 3
Training loss: 0.914225278526914
Validation loss: 2.7274188059121034

Epoch: 6| Step: 4
Training loss: 1.2318440819454877
Validation loss: 2.7301934080079837

Epoch: 6| Step: 5
Training loss: 1.5830770920990578
Validation loss: 2.707135095563503

Epoch: 6| Step: 6
Training loss: 1.0507717203041382
Validation loss: 2.710424959365008

Epoch: 6| Step: 7
Training loss: 1.066622366332975
Validation loss: 2.693017963492002

Epoch: 6| Step: 8
Training loss: 0.8972442332114593
Validation loss: 2.715277123094255

Epoch: 6| Step: 9
Training loss: 1.1586285432207215
Validation loss: 2.716200640713415

Epoch: 6| Step: 10
Training loss: 1.3306733758606908
Validation loss: 2.7318522522126303

Epoch: 6| Step: 11
Training loss: 0.5556068323896212
Validation loss: 2.719586956535361

Epoch: 6| Step: 12
Training loss: 0.5171327221952913
Validation loss: 2.7219046269394

Epoch: 6| Step: 13
Training loss: 0.9887046359394414
Validation loss: 2.739785120096464

Epoch: 271| Step: 0
Training loss: 0.7458648330458405
Validation loss: 2.7236540453107425

Epoch: 6| Step: 1
Training loss: 1.2924403467929615
Validation loss: 2.7318723987326323

Epoch: 6| Step: 2
Training loss: 0.7987494394960064
Validation loss: 2.7109585201759065

Epoch: 6| Step: 3
Training loss: 0.951712828539306
Validation loss: 2.7176507027002414

Epoch: 6| Step: 4
Training loss: 1.003879413171814
Validation loss: 2.7316849440685114

Epoch: 6| Step: 5
Training loss: 0.5403398500473515
Validation loss: 2.729314772973865

Epoch: 6| Step: 6
Training loss: 1.110553223239226
Validation loss: 2.6875094189184288

Epoch: 6| Step: 7
Training loss: 1.5421224470244965
Validation loss: 2.723614130351066

Epoch: 6| Step: 8
Training loss: 1.0437319816815813
Validation loss: 2.6851343349133048

Epoch: 6| Step: 9
Training loss: 1.081474188346261
Validation loss: 2.745574279821483

Epoch: 6| Step: 10
Training loss: 1.1799357071026426
Validation loss: 2.7083703482648676

Epoch: 6| Step: 11
Training loss: 1.0746441917644776
Validation loss: 2.746728560252809

Epoch: 6| Step: 12
Training loss: 0.8675130284674992
Validation loss: 2.7592304224795994

Epoch: 6| Step: 13
Training loss: 0.8110590775629175
Validation loss: 2.72672138761338

Epoch: 272| Step: 0
Training loss: 0.7564488362359025
Validation loss: 2.7360809114486244

Epoch: 6| Step: 1
Training loss: 0.702056751446047
Validation loss: 2.7454738267006147

Epoch: 6| Step: 2
Training loss: 1.69534737687339
Validation loss: 2.7157296204458143

Epoch: 6| Step: 3
Training loss: 1.0824902934460745
Validation loss: 2.746458602644035

Epoch: 6| Step: 4
Training loss: 1.3632931421848788
Validation loss: 2.736241556794856

Epoch: 6| Step: 5
Training loss: 1.0579221502409613
Validation loss: 2.727013282688087

Epoch: 6| Step: 6
Training loss: 0.8492263456705036
Validation loss: 2.7470071192290098

Epoch: 6| Step: 7
Training loss: 0.9961008707427773
Validation loss: 2.7324453250241993

Epoch: 6| Step: 8
Training loss: 1.0187306384721635
Validation loss: 2.7493333675076923

Epoch: 6| Step: 9
Training loss: 0.5986638768958755
Validation loss: 2.712200219075549

Epoch: 6| Step: 10
Training loss: 0.8834239901200216
Validation loss: 2.7538727574932533

Epoch: 6| Step: 11
Training loss: 0.9765203237962692
Validation loss: 2.7274700872886926

Epoch: 6| Step: 12
Training loss: 1.0338604572146404
Validation loss: 2.7230608818602735

Epoch: 6| Step: 13
Training loss: 0.8995609722624076
Validation loss: 2.7294080014310675

Epoch: 273| Step: 0
Training loss: 1.3322002046441466
Validation loss: 2.73381649284552

Epoch: 6| Step: 1
Training loss: 0.5567518156661809
Validation loss: 2.7489318814924344

Epoch: 6| Step: 2
Training loss: 1.0349425473138785
Validation loss: 2.7290462914166675

Epoch: 6| Step: 3
Training loss: 1.175457830716831
Validation loss: 2.7091671927615697

Epoch: 6| Step: 4
Training loss: 0.8785536673430813
Validation loss: 2.725878987752188

Epoch: 6| Step: 5
Training loss: 0.8956611526976372
Validation loss: 2.733936528034357

Epoch: 6| Step: 6
Training loss: 0.8601108521721441
Validation loss: 2.694414272744829

Epoch: 6| Step: 7
Training loss: 1.0067657831061732
Validation loss: 2.7385354394744836

Epoch: 6| Step: 8
Training loss: 0.9573271936099761
Validation loss: 2.7482030400725264

Epoch: 6| Step: 9
Training loss: 1.1205667991864223
Validation loss: 2.743931851740026

Epoch: 6| Step: 10
Training loss: 1.5712062133417593
Validation loss: 2.7463362424558615

Epoch: 6| Step: 11
Training loss: 0.8451961557139301
Validation loss: 2.7599065648695

Epoch: 6| Step: 12
Training loss: 0.7494346951847434
Validation loss: 2.73514825953478

Epoch: 6| Step: 13
Training loss: 0.9000544054753311
Validation loss: 2.7427857823233874

Epoch: 274| Step: 0
Training loss: 1.0850624016427255
Validation loss: 2.7684504297904997

Epoch: 6| Step: 1
Training loss: 0.8409882310232073
Validation loss: 2.7673186241466285

Epoch: 6| Step: 2
Training loss: 0.6829441580864593
Validation loss: 2.7797112480035944

Epoch: 6| Step: 3
Training loss: 1.0265879588693472
Validation loss: 2.752580043949238

Epoch: 6| Step: 4
Training loss: 0.7993969372803037
Validation loss: 2.7274342624261774

Epoch: 6| Step: 5
Training loss: 0.6783117423928969
Validation loss: 2.7843190481138844

Epoch: 6| Step: 6
Training loss: 1.1961676337447413
Validation loss: 2.764642346565675

Epoch: 6| Step: 7
Training loss: 0.8292286554165065
Validation loss: 2.7513278074990417

Epoch: 6| Step: 8
Training loss: 1.2866664929134535
Validation loss: 2.7332352632906667

Epoch: 6| Step: 9
Training loss: 1.2328447925123935
Validation loss: 2.744048063378064

Epoch: 6| Step: 10
Training loss: 1.5472411675989268
Validation loss: 2.6874536423001

Epoch: 6| Step: 11
Training loss: 0.8748544503818191
Validation loss: 2.69538968073677

Epoch: 6| Step: 12
Training loss: 1.0257563638101563
Validation loss: 2.6909318090803214

Epoch: 6| Step: 13
Training loss: 0.5192522145730529
Validation loss: 2.7010867787341186

Epoch: 275| Step: 0
Training loss: 1.1483035885336286
Validation loss: 2.664716531136795

Epoch: 6| Step: 1
Training loss: 1.2308365045212633
Validation loss: 2.6807050176771474

Epoch: 6| Step: 2
Training loss: 1.075072569948144
Validation loss: 2.693922314765266

Epoch: 6| Step: 3
Training loss: 0.8588026047854106
Validation loss: 2.7036198187970353

Epoch: 6| Step: 4
Training loss: 0.9155834618217629
Validation loss: 2.689220817624452

Epoch: 6| Step: 5
Training loss: 0.752255227970556
Validation loss: 2.7046177450803475

Epoch: 6| Step: 6
Training loss: 1.0379859108161615
Validation loss: 2.721593646187777

Epoch: 6| Step: 7
Training loss: 0.9239134476921778
Validation loss: 2.6950872321480435

Epoch: 6| Step: 8
Training loss: 0.9389122815826374
Validation loss: 2.7374339020940237

Epoch: 6| Step: 9
Training loss: 0.965809697631886
Validation loss: 2.778979630337058

Epoch: 6| Step: 10
Training loss: 0.8082854931887932
Validation loss: 2.7947197453473724

Epoch: 6| Step: 11
Training loss: 0.5878327806980501
Validation loss: 2.7735343189431965

Epoch: 6| Step: 12
Training loss: 1.0907534285952016
Validation loss: 2.7849096859206504

Epoch: 6| Step: 13
Training loss: 1.913110862363155
Validation loss: 2.784323755865856

Epoch: 276| Step: 0
Training loss: 1.4722760668490817
Validation loss: 2.7884460569504497

Epoch: 6| Step: 1
Training loss: 0.9606881787403994
Validation loss: 2.802312124707216

Epoch: 6| Step: 2
Training loss: 0.9548526177847388
Validation loss: 2.796525121314986

Epoch: 6| Step: 3
Training loss: 0.6151710114320037
Validation loss: 2.7789076476783605

Epoch: 6| Step: 4
Training loss: 1.2068436856506515
Validation loss: 2.745123513671332

Epoch: 6| Step: 5
Training loss: 0.9286065749968171
Validation loss: 2.7045165991962774

Epoch: 6| Step: 6
Training loss: 0.9088553107107809
Validation loss: 2.7040852307581074

Epoch: 6| Step: 7
Training loss: 1.0340141473684041
Validation loss: 2.66933774866747

Epoch: 6| Step: 8
Training loss: 0.9223375614714091
Validation loss: 2.6835950740472945

Epoch: 6| Step: 9
Training loss: 0.8562354566912229
Validation loss: 2.67926181777412

Epoch: 6| Step: 10
Training loss: 1.022448928602173
Validation loss: 2.652169945811196

Epoch: 6| Step: 11
Training loss: 0.7923150586240915
Validation loss: 2.707468399879848

Epoch: 6| Step: 12
Training loss: 1.2127754783336746
Validation loss: 2.6452960055822454

Epoch: 6| Step: 13
Training loss: 1.3142115015200329
Validation loss: 2.682055674389255

Epoch: 277| Step: 0
Training loss: 0.793414587206126
Validation loss: 2.7052860255787126

Epoch: 6| Step: 1
Training loss: 0.9011256265202848
Validation loss: 2.7255560653510447

Epoch: 6| Step: 2
Training loss: 1.4490320954332174
Validation loss: 2.7317490482934854

Epoch: 6| Step: 3
Training loss: 1.2624811756505798
Validation loss: 2.7293150115556144

Epoch: 6| Step: 4
Training loss: 0.8741129056862202
Validation loss: 2.6714078011027245

Epoch: 6| Step: 5
Training loss: 1.1256529714443888
Validation loss: 2.745522145129186

Epoch: 6| Step: 6
Training loss: 1.0805211184837245
Validation loss: 2.6769695529928152

Epoch: 6| Step: 7
Training loss: 0.906002208113348
Validation loss: 2.6903080122610223

Epoch: 6| Step: 8
Training loss: 0.8543431092054088
Validation loss: 2.6947578495566753

Epoch: 6| Step: 9
Training loss: 0.5394419564673087
Validation loss: 2.67628698681215

Epoch: 6| Step: 10
Training loss: 0.7760279652113509
Validation loss: 2.679341119987155

Epoch: 6| Step: 11
Training loss: 0.9716365938838389
Validation loss: 2.689639962031357

Epoch: 6| Step: 12
Training loss: 0.9857131400457086
Validation loss: 2.689405862028319

Epoch: 6| Step: 13
Training loss: 1.4763922214719654
Validation loss: 2.6802734109479838

Epoch: 278| Step: 0
Training loss: 1.0222643469225627
Validation loss: 2.694736794337849

Epoch: 6| Step: 1
Training loss: 0.7786110367330545
Validation loss: 2.7169478179674855

Epoch: 6| Step: 2
Training loss: 0.7112664520157632
Validation loss: 2.7236342930981206

Epoch: 6| Step: 3
Training loss: 0.8390778353690903
Validation loss: 2.712257008097842

Epoch: 6| Step: 4
Training loss: 0.8469192887440505
Validation loss: 2.68810342327849

Epoch: 6| Step: 5
Training loss: 1.3059482536229172
Validation loss: 2.725240912526706

Epoch: 6| Step: 6
Training loss: 0.7357503308766302
Validation loss: 2.7293361776188334

Epoch: 6| Step: 7
Training loss: 0.9893785197809281
Validation loss: 2.7191465727658706

Epoch: 6| Step: 8
Training loss: 1.7473973948381234
Validation loss: 2.71538494148907

Epoch: 6| Step: 9
Training loss: 0.7606959592119904
Validation loss: 2.756939263776032

Epoch: 6| Step: 10
Training loss: 1.010933530820339
Validation loss: 2.7652841650776536

Epoch: 6| Step: 11
Training loss: 0.9369439701398679
Validation loss: 2.78819944175349

Epoch: 6| Step: 12
Training loss: 0.7205598683629721
Validation loss: 2.783110266192275

Epoch: 6| Step: 13
Training loss: 1.0224285248115825
Validation loss: 2.7873824342862425

Epoch: 279| Step: 0
Training loss: 0.7488969002165322
Validation loss: 2.7844854056453046

Epoch: 6| Step: 1
Training loss: 0.7973314361847387
Validation loss: 2.7667312648134206

Epoch: 6| Step: 2
Training loss: 1.0041921483100429
Validation loss: 2.750639941688311

Epoch: 6| Step: 3
Training loss: 1.167125997493269
Validation loss: 2.7430630893343344

Epoch: 6| Step: 4
Training loss: 0.8060599909007823
Validation loss: 2.7182585475150134

Epoch: 6| Step: 5
Training loss: 1.005253937367031
Validation loss: 2.7049110473245235

Epoch: 6| Step: 6
Training loss: 0.47817231922735454
Validation loss: 2.6590339100358866

Epoch: 6| Step: 7
Training loss: 0.758540089336775
Validation loss: 2.6790888977042093

Epoch: 6| Step: 8
Training loss: 1.0713752983109759
Validation loss: 2.6487178786570413

Epoch: 6| Step: 9
Training loss: 0.8247859503758402
Validation loss: 2.6939269406768456

Epoch: 6| Step: 10
Training loss: 1.0186592553099638
Validation loss: 2.706483852806497

Epoch: 6| Step: 11
Training loss: 0.8791428311146632
Validation loss: 2.712033594343442

Epoch: 6| Step: 12
Training loss: 1.7121808833707877
Validation loss: 2.752612222220104

Epoch: 6| Step: 13
Training loss: 1.0350533488248976
Validation loss: 2.7512256281351894

Epoch: 280| Step: 0
Training loss: 0.5419856440518576
Validation loss: 2.7620395105658235

Epoch: 6| Step: 1
Training loss: 0.591152583236361
Validation loss: 2.805321923676433

Epoch: 6| Step: 2
Training loss: 0.7347914144156658
Validation loss: 2.809934264775975

Epoch: 6| Step: 3
Training loss: 0.9191937004487695
Validation loss: 2.763430347133746

Epoch: 6| Step: 4
Training loss: 0.9650473437777143
Validation loss: 2.757725635689621

Epoch: 6| Step: 5
Training loss: 1.1208618136809023
Validation loss: 2.7489788437869977

Epoch: 6| Step: 6
Training loss: 1.3228206850010882
Validation loss: 2.725187387916588

Epoch: 6| Step: 7
Training loss: 0.8661460809177788
Validation loss: 2.707011966500208

Epoch: 6| Step: 8
Training loss: 1.6839713892284482
Validation loss: 2.674308572913569

Epoch: 6| Step: 9
Training loss: 0.7461480725070306
Validation loss: 2.6768110183133054

Epoch: 6| Step: 10
Training loss: 0.4185684572091831
Validation loss: 2.637007351982632

Epoch: 6| Step: 11
Training loss: 0.8114853539006014
Validation loss: 2.6663060777681

Epoch: 6| Step: 12
Training loss: 1.2050895999504316
Validation loss: 2.6678722493079836

Epoch: 6| Step: 13
Training loss: 0.9810882070512078
Validation loss: 2.7297258559596487

Epoch: 281| Step: 0
Training loss: 0.7954778952701347
Validation loss: 2.7458830152341607

Epoch: 6| Step: 1
Training loss: 0.933921341502076
Validation loss: 2.747949607725256

Epoch: 6| Step: 2
Training loss: 1.5280926129550199
Validation loss: 2.7300741040840273

Epoch: 6| Step: 3
Training loss: 1.3029334789753335
Validation loss: 2.7750141326358175

Epoch: 6| Step: 4
Training loss: 0.7085853063044544
Validation loss: 2.7534723779501857

Epoch: 6| Step: 5
Training loss: 0.8784718436004533
Validation loss: 2.757162711099176

Epoch: 6| Step: 6
Training loss: 0.8029209486314838
Validation loss: 2.7726217495743817

Epoch: 6| Step: 7
Training loss: 0.91882741822497
Validation loss: 2.7666464216522235

Epoch: 6| Step: 8
Training loss: 0.5170156049162624
Validation loss: 2.746354992202973

Epoch: 6| Step: 9
Training loss: 1.201314182690543
Validation loss: 2.702267945939269

Epoch: 6| Step: 10
Training loss: 1.1012237244328067
Validation loss: 2.715339188257689

Epoch: 6| Step: 11
Training loss: 0.7590286878057037
Validation loss: 2.7384439400481204

Epoch: 6| Step: 12
Training loss: 0.9681568791144332
Validation loss: 2.7368553675875367

Epoch: 6| Step: 13
Training loss: 0.33376294877082247
Validation loss: 2.7692807295127655

Epoch: 282| Step: 0
Training loss: 0.9206556888186408
Validation loss: 2.774557006192228

Epoch: 6| Step: 1
Training loss: 0.5495636650549449
Validation loss: 2.774236313249884

Epoch: 6| Step: 2
Training loss: 1.1820211002899914
Validation loss: 2.7533790937362963

Epoch: 6| Step: 3
Training loss: 0.9066761264646455
Validation loss: 2.7713189437777093

Epoch: 6| Step: 4
Training loss: 0.8293730130779093
Validation loss: 2.775553282737543

Epoch: 6| Step: 5
Training loss: 0.7085126247882993
Validation loss: 2.7643809819786527

Epoch: 6| Step: 6
Training loss: 0.7333035871223702
Validation loss: 2.7471856046973224

Epoch: 6| Step: 7
Training loss: 0.9093992498776036
Validation loss: 2.7637160665209017

Epoch: 6| Step: 8
Training loss: 0.8528491458029528
Validation loss: 2.7409143419994733

Epoch: 6| Step: 9
Training loss: 0.9272511719639444
Validation loss: 2.754284652211471

Epoch: 6| Step: 10
Training loss: 1.041272559316553
Validation loss: 2.7383042032718867

Epoch: 6| Step: 11
Training loss: 1.5768679153821494
Validation loss: 2.7217253765314804

Epoch: 6| Step: 12
Training loss: 0.9127577247888303
Validation loss: 2.7722067283952936

Epoch: 6| Step: 13
Training loss: 0.8989580387956322
Validation loss: 2.75190338795718

Epoch: 283| Step: 0
Training loss: 0.9068862063072402
Validation loss: 2.739666677406811

Epoch: 6| Step: 1
Training loss: 0.5709950269125114
Validation loss: 2.7723713169396835

Epoch: 6| Step: 2
Training loss: 0.8163571867733415
Validation loss: 2.79760110659656

Epoch: 6| Step: 3
Training loss: 0.8610583378060668
Validation loss: 2.7812157454022524

Epoch: 6| Step: 4
Training loss: 0.7878246228663462
Validation loss: 2.802739947302308

Epoch: 6| Step: 5
Training loss: 1.0080848739783377
Validation loss: 2.799257351939235

Epoch: 6| Step: 6
Training loss: 0.7674945271324833
Validation loss: 2.77189290909284

Epoch: 6| Step: 7
Training loss: 1.1308495713831854
Validation loss: 2.7816111436282265

Epoch: 6| Step: 8
Training loss: 0.8431954150703178
Validation loss: 2.7566630066891005

Epoch: 6| Step: 9
Training loss: 1.017170712849608
Validation loss: 2.74235948424657

Epoch: 6| Step: 10
Training loss: 1.4062165150364487
Validation loss: 2.7255549281731257

Epoch: 6| Step: 11
Training loss: 1.0530014124043006
Validation loss: 2.769662484926747

Epoch: 6| Step: 12
Training loss: 0.929439800186497
Validation loss: 2.7279529729998675

Epoch: 6| Step: 13
Training loss: 0.6878955310167852
Validation loss: 2.726555355998325

Epoch: 284| Step: 0
Training loss: 0.7404098101548707
Validation loss: 2.7679885535727546

Epoch: 6| Step: 1
Training loss: 0.8293032990474991
Validation loss: 2.7879281471047905

Epoch: 6| Step: 2
Training loss: 1.021184523501717
Validation loss: 2.777891233718195

Epoch: 6| Step: 3
Training loss: 1.0826347128055058
Validation loss: 2.782983017604912

Epoch: 6| Step: 4
Training loss: 0.9097402383186782
Validation loss: 2.7595860487478383

Epoch: 6| Step: 5
Training loss: 0.7463857668469168
Validation loss: 2.786157451060466

Epoch: 6| Step: 6
Training loss: 0.607714910444366
Validation loss: 2.7619425207265924

Epoch: 6| Step: 7
Training loss: 0.7607011698289975
Validation loss: 2.7617500225545943

Epoch: 6| Step: 8
Training loss: 0.8175989227638688
Validation loss: 2.7364238848064617

Epoch: 6| Step: 9
Training loss: 0.8952703962029306
Validation loss: 2.720840457584754

Epoch: 6| Step: 10
Training loss: 1.1184890741148008
Validation loss: 2.7134997184502327

Epoch: 6| Step: 11
Training loss: 0.9079904614926421
Validation loss: 2.6911971219058377

Epoch: 6| Step: 12
Training loss: 1.6014346187988298
Validation loss: 2.727290805991031

Epoch: 6| Step: 13
Training loss: 0.40413553824284726
Validation loss: 2.7213516385282133

Epoch: 285| Step: 0
Training loss: 0.8998212689841983
Validation loss: 2.698228438349413

Epoch: 6| Step: 1
Training loss: 0.6946999069389521
Validation loss: 2.7024187678969858

Epoch: 6| Step: 2
Training loss: 0.7122579196798927
Validation loss: 2.7115503355909905

Epoch: 6| Step: 3
Training loss: 1.5768455379846915
Validation loss: 2.745716631603718

Epoch: 6| Step: 4
Training loss: 0.9873791524121489
Validation loss: 2.7462517652576355

Epoch: 6| Step: 5
Training loss: 0.7837013315303152
Validation loss: 2.7609076591290584

Epoch: 6| Step: 6
Training loss: 0.9880862741041845
Validation loss: 2.781822253563824

Epoch: 6| Step: 7
Training loss: 0.779703211196054
Validation loss: 2.783294277630669

Epoch: 6| Step: 8
Training loss: 1.078024596915662
Validation loss: 2.747286004559434

Epoch: 6| Step: 9
Training loss: 0.927937214410758
Validation loss: 2.7614230890148153

Epoch: 6| Step: 10
Training loss: 0.839944877745958
Validation loss: 2.7501523245111796

Epoch: 6| Step: 11
Training loss: 0.8199540581277621
Validation loss: 2.7432271424405843

Epoch: 6| Step: 12
Training loss: 0.8717261785562305
Validation loss: 2.7405745648051094

Epoch: 6| Step: 13
Training loss: 0.6624973252080507
Validation loss: 2.7005005287089556

Epoch: 286| Step: 0
Training loss: 0.9415592370038446
Validation loss: 2.723968419882761

Epoch: 6| Step: 1
Training loss: 0.7856795052472192
Validation loss: 2.724883488029553

Epoch: 6| Step: 2
Training loss: 0.9739294948830294
Validation loss: 2.7178448150978642

Epoch: 6| Step: 3
Training loss: 0.9263022200346853
Validation loss: 2.7008378757497673

Epoch: 6| Step: 4
Training loss: 0.763532308718039
Validation loss: 2.6976802974353364

Epoch: 6| Step: 5
Training loss: 1.7463148007012348
Validation loss: 2.7263883955930175

Epoch: 6| Step: 6
Training loss: 0.8093568821944894
Validation loss: 2.7191888202590446

Epoch: 6| Step: 7
Training loss: 0.9683201974666115
Validation loss: 2.714103551906684

Epoch: 6| Step: 8
Training loss: 0.764775953707291
Validation loss: 2.7157213245874394

Epoch: 6| Step: 9
Training loss: 0.8268320318405447
Validation loss: 2.747634519165892

Epoch: 6| Step: 10
Training loss: 0.7709767663525089
Validation loss: 2.748355724426806

Epoch: 6| Step: 11
Training loss: 0.662045456043095
Validation loss: 2.718493370171387

Epoch: 6| Step: 12
Training loss: 0.4576274536908953
Validation loss: 2.7678984686625063

Epoch: 6| Step: 13
Training loss: 1.238568678749289
Validation loss: 2.743325076178689

Epoch: 287| Step: 0
Training loss: 0.6536672722896174
Validation loss: 2.773510459299595

Epoch: 6| Step: 1
Training loss: 0.680971095537438
Validation loss: 2.7334116524081313

Epoch: 6| Step: 2
Training loss: 0.9817730256856358
Validation loss: 2.776110174148776

Epoch: 6| Step: 3
Training loss: 0.9065608445171822
Validation loss: 2.7767401519154844

Epoch: 6| Step: 4
Training loss: 1.1167015139043697
Validation loss: 2.810507551933756

Epoch: 6| Step: 5
Training loss: 1.496049447063526
Validation loss: 2.7890671758468057

Epoch: 6| Step: 6
Training loss: 0.7702606926571743
Validation loss: 2.7319385705385124

Epoch: 6| Step: 7
Training loss: 1.0411774758203813
Validation loss: 2.742315903983132

Epoch: 6| Step: 8
Training loss: 0.8210586061224894
Validation loss: 2.6878256947423624

Epoch: 6| Step: 9
Training loss: 0.9070679492081014
Validation loss: 2.6506585933243123

Epoch: 6| Step: 10
Training loss: 0.696052907137256
Validation loss: 2.672260249693514

Epoch: 6| Step: 11
Training loss: 1.0884677308205317
Validation loss: 2.693026711973999

Epoch: 6| Step: 12
Training loss: 0.5640330351850364
Validation loss: 2.7448699865900483

Epoch: 6| Step: 13
Training loss: 0.728393462628435
Validation loss: 2.735178830175839

Epoch: 288| Step: 0
Training loss: 0.7622606746117566
Validation loss: 2.7222976009331483

Epoch: 6| Step: 1
Training loss: 0.8117573718813279
Validation loss: 2.7499391916362903

Epoch: 6| Step: 2
Training loss: 0.9209174015685553
Validation loss: 2.715025569846957

Epoch: 6| Step: 3
Training loss: 0.7256463951091215
Validation loss: 2.729742264858168

Epoch: 6| Step: 4
Training loss: 1.2264806149113638
Validation loss: 2.728558794296802

Epoch: 6| Step: 5
Training loss: 0.7897340919145883
Validation loss: 2.712318008621202

Epoch: 6| Step: 6
Training loss: 1.5370325168652097
Validation loss: 2.7319366538637047

Epoch: 6| Step: 7
Training loss: 0.9871989117114036
Validation loss: 2.689279698178691

Epoch: 6| Step: 8
Training loss: 0.6667007546849297
Validation loss: 2.715047517714682

Epoch: 6| Step: 9
Training loss: 0.9052410428568777
Validation loss: 2.705151014603553

Epoch: 6| Step: 10
Training loss: 1.0327026077880321
Validation loss: 2.733544863367557

Epoch: 6| Step: 11
Training loss: 0.6113705605108023
Validation loss: 2.73521506347882

Epoch: 6| Step: 12
Training loss: 0.7644708848702084
Validation loss: 2.7240379373784336

Epoch: 6| Step: 13
Training loss: 0.5043405834495448
Validation loss: 2.7412816655531027

Epoch: 289| Step: 0
Training loss: 1.0426009883496143
Validation loss: 2.7955202245118382

Epoch: 6| Step: 1
Training loss: 0.9267601278455008
Validation loss: 2.810857758697476

Epoch: 6| Step: 2
Training loss: 0.7437650278320275
Validation loss: 2.792491650134779

Epoch: 6| Step: 3
Training loss: 0.7989360857621813
Validation loss: 2.7963246395069663

Epoch: 6| Step: 4
Training loss: 0.7861597281640358
Validation loss: 2.7620226906923016

Epoch: 6| Step: 5
Training loss: 0.5527025355142681
Validation loss: 2.7583714507598

Epoch: 6| Step: 6
Training loss: 0.9172115368268484
Validation loss: 2.7471747423675468

Epoch: 6| Step: 7
Training loss: 0.862825471862747
Validation loss: 2.735653712865839

Epoch: 6| Step: 8
Training loss: 0.7963909848377843
Validation loss: 2.6968238810226905

Epoch: 6| Step: 9
Training loss: 1.580899283374559
Validation loss: 2.6710832342964257

Epoch: 6| Step: 10
Training loss: 1.085435820036512
Validation loss: 2.6893491381211505

Epoch: 6| Step: 11
Training loss: 1.0514834301994824
Validation loss: 2.6858150926818247

Epoch: 6| Step: 12
Training loss: 0.8407583180610737
Validation loss: 2.6922996332856384

Epoch: 6| Step: 13
Training loss: 0.7405952640793059
Validation loss: 2.702734976978769

Epoch: 290| Step: 0
Training loss: 0.5333731802817021
Validation loss: 2.734250419814066

Epoch: 6| Step: 1
Training loss: 0.8995944990484328
Validation loss: 2.7298788515868346

Epoch: 6| Step: 2
Training loss: 0.9710263610192312
Validation loss: 2.7173178699392198

Epoch: 6| Step: 3
Training loss: 0.5766285525067192
Validation loss: 2.745427603771027

Epoch: 6| Step: 4
Training loss: 0.7087759336809795
Validation loss: 2.745097930130082

Epoch: 6| Step: 5
Training loss: 0.8115693778244903
Validation loss: 2.775168511380215

Epoch: 6| Step: 6
Training loss: 0.8604698835884637
Validation loss: 2.7451382560033992

Epoch: 6| Step: 7
Training loss: 0.9024360576496319
Validation loss: 2.7353085566427033

Epoch: 6| Step: 8
Training loss: 0.662415560253488
Validation loss: 2.7175905657095165

Epoch: 6| Step: 9
Training loss: 0.8644682374814875
Validation loss: 2.7320322508967307

Epoch: 6| Step: 10
Training loss: 1.1774798825240198
Validation loss: 2.6928734295059096

Epoch: 6| Step: 11
Training loss: 1.6155194511836464
Validation loss: 2.684297061480976

Epoch: 6| Step: 12
Training loss: 0.9495010270228162
Validation loss: 2.6492060574254817

Epoch: 6| Step: 13
Training loss: 0.6847397054585714
Validation loss: 2.6426207346451553

Epoch: 291| Step: 0
Training loss: 1.5404761933118747
Validation loss: 2.6779682641914704

Epoch: 6| Step: 1
Training loss: 0.6163926861603869
Validation loss: 2.6840553099917015

Epoch: 6| Step: 2
Training loss: 0.9051132307294979
Validation loss: 2.7187775594096895

Epoch: 6| Step: 3
Training loss: 0.8573758888512539
Validation loss: 2.752663149735173

Epoch: 6| Step: 4
Training loss: 0.8286916845181337
Validation loss: 2.7677401488875137

Epoch: 6| Step: 5
Training loss: 0.9397609150976466
Validation loss: 2.751820296490867

Epoch: 6| Step: 6
Training loss: 0.9442449484445847
Validation loss: 2.7797648986220183

Epoch: 6| Step: 7
Training loss: 0.8446372982776599
Validation loss: 2.7618706342571966

Epoch: 6| Step: 8
Training loss: 0.6748644392441743
Validation loss: 2.745133969472592

Epoch: 6| Step: 9
Training loss: 0.9094087207742666
Validation loss: 2.7055007743585926

Epoch: 6| Step: 10
Training loss: 0.3201556868615697
Validation loss: 2.66413395788554

Epoch: 6| Step: 11
Training loss: 1.0484342776844517
Validation loss: 2.642550175447024

Epoch: 6| Step: 12
Training loss: 0.7916873293405386
Validation loss: 2.652105160211189

Epoch: 6| Step: 13
Training loss: 0.9792682851993512
Validation loss: 2.672538112296217

Epoch: 292| Step: 0
Training loss: 1.443980495004137
Validation loss: 2.634435780891249

Epoch: 6| Step: 1
Training loss: 0.8814753981395792
Validation loss: 2.6779520425570618

Epoch: 6| Step: 2
Training loss: 0.7914363166241722
Validation loss: 2.6769324365045772

Epoch: 6| Step: 3
Training loss: 0.8445375087622573
Validation loss: 2.7128936224903994

Epoch: 6| Step: 4
Training loss: 0.7956487907694378
Validation loss: 2.68382063402414

Epoch: 6| Step: 5
Training loss: 0.43477867360511147
Validation loss: 2.72187726307623

Epoch: 6| Step: 6
Training loss: 0.9912222124031622
Validation loss: 2.718068806146543

Epoch: 6| Step: 7
Training loss: 0.9981200607550227
Validation loss: 2.7298208368706653

Epoch: 6| Step: 8
Training loss: 0.7581773646448209
Validation loss: 2.6937687977514515

Epoch: 6| Step: 9
Training loss: 0.7524492484939719
Validation loss: 2.6869702485989206

Epoch: 6| Step: 10
Training loss: 0.8382697681447696
Validation loss: 2.6846446508046777

Epoch: 6| Step: 11
Training loss: 0.776980866502228
Validation loss: 2.697720400345529

Epoch: 6| Step: 12
Training loss: 0.9081356228589773
Validation loss: 2.6631641070597403

Epoch: 6| Step: 13
Training loss: 0.9540946280814085
Validation loss: 2.6494038733837786

Epoch: 293| Step: 0
Training loss: 1.4058128101197764
Validation loss: 2.667027224755751

Epoch: 6| Step: 1
Training loss: 0.6895422513158947
Validation loss: 2.6327969767982924

Epoch: 6| Step: 2
Training loss: 0.8943680860144202
Validation loss: 2.6393133717612773

Epoch: 6| Step: 3
Training loss: 0.9753598857247825
Validation loss: 2.6648630386426824

Epoch: 6| Step: 4
Training loss: 0.9789382113439712
Validation loss: 2.7134440310824206

Epoch: 6| Step: 5
Training loss: 0.5223638711763033
Validation loss: 2.7040175880536803

Epoch: 6| Step: 6
Training loss: 0.8149292649541199
Validation loss: 2.7361042767055848

Epoch: 6| Step: 7
Training loss: 0.7274673733818047
Validation loss: 2.73348507698811

Epoch: 6| Step: 8
Training loss: 0.5804454783399312
Validation loss: 2.740750433875788

Epoch: 6| Step: 9
Training loss: 0.7648399376311475
Validation loss: 2.704225653591495

Epoch: 6| Step: 10
Training loss: 1.1182503079798356
Validation loss: 2.755287605815586

Epoch: 6| Step: 11
Training loss: 0.7968290727133491
Validation loss: 2.738734743925711

Epoch: 6| Step: 12
Training loss: 0.9059647078177042
Validation loss: 2.6874511210639116

Epoch: 6| Step: 13
Training loss: 0.3291101992235076
Validation loss: 2.6971101463215947

Epoch: 294| Step: 0
Training loss: 0.7413581229568822
Validation loss: 2.6853192489676174

Epoch: 6| Step: 1
Training loss: 1.0109681397501327
Validation loss: 2.6604228333438926

Epoch: 6| Step: 2
Training loss: 0.8398407692080097
Validation loss: 2.6571925277168327

Epoch: 6| Step: 3
Training loss: 0.8128945786372198
Validation loss: 2.64286401904709

Epoch: 6| Step: 4
Training loss: 0.38184783995046007
Validation loss: 2.6586177573346355

Epoch: 6| Step: 5
Training loss: 1.0338181394101842
Validation loss: 2.660950214962403

Epoch: 6| Step: 6
Training loss: 0.5049529921493169
Validation loss: 2.6327966496240687

Epoch: 6| Step: 7
Training loss: 0.6797955744969375
Validation loss: 2.6618733440202043

Epoch: 6| Step: 8
Training loss: 1.039018787812623
Validation loss: 2.6993575859048984

Epoch: 6| Step: 9
Training loss: 0.8184136711808709
Validation loss: 2.7354104364840888

Epoch: 6| Step: 10
Training loss: 0.7152642436017624
Validation loss: 2.779374059033249

Epoch: 6| Step: 11
Training loss: 1.495343530665773
Validation loss: 2.7694305716809304

Epoch: 6| Step: 12
Training loss: 0.6042841490161956
Validation loss: 2.7596241855720938

Epoch: 6| Step: 13
Training loss: 0.9185342223904802
Validation loss: 2.718567316492157

Epoch: 295| Step: 0
Training loss: 0.8484789464111052
Validation loss: 2.704955437786571

Epoch: 6| Step: 1
Training loss: 1.1833404672882237
Validation loss: 2.727553239592296

Epoch: 6| Step: 2
Training loss: 0.7754305197496211
Validation loss: 2.6901522686919805

Epoch: 6| Step: 3
Training loss: 0.9229668439280685
Validation loss: 2.6850152115314465

Epoch: 6| Step: 4
Training loss: 0.6835974774940227
Validation loss: 2.684772927907258

Epoch: 6| Step: 5
Training loss: 0.8201008841630877
Validation loss: 2.6581980704376837

Epoch: 6| Step: 6
Training loss: 1.1671515320083479
Validation loss: 2.7121163630498564

Epoch: 6| Step: 7
Training loss: 0.8717524343226329
Validation loss: 2.6520318914763448

Epoch: 6| Step: 8
Training loss: 0.7805969178865355
Validation loss: 2.6571635635096182

Epoch: 6| Step: 9
Training loss: 0.7854116603243174
Validation loss: 2.6596482440116893

Epoch: 6| Step: 10
Training loss: 0.8500755697204424
Validation loss: 2.661054952249547

Epoch: 6| Step: 11
Training loss: 0.4751966947573852
Validation loss: 2.653649080656447

Epoch: 6| Step: 12
Training loss: 0.7817169319968897
Validation loss: 2.6890471922982098

Epoch: 6| Step: 13
Training loss: 0.6437905419184943
Validation loss: 2.6669356001583866

Epoch: 296| Step: 0
Training loss: 0.5772097792195525
Validation loss: 2.6930157121098275

Epoch: 6| Step: 1
Training loss: 0.6328132064250253
Validation loss: 2.67536448074393

Epoch: 6| Step: 2
Training loss: 1.01402579360148
Validation loss: 2.7290986713379817

Epoch: 6| Step: 3
Training loss: 0.9705339741073973
Validation loss: 2.708821205342276

Epoch: 6| Step: 4
Training loss: 0.7185594471978342
Validation loss: 2.67433410654371

Epoch: 6| Step: 5
Training loss: 0.6974352461997846
Validation loss: 2.6866045941400367

Epoch: 6| Step: 6
Training loss: 0.8659911279994753
Validation loss: 2.704287242440174

Epoch: 6| Step: 7
Training loss: 1.3476528886393768
Validation loss: 2.6752568126737275

Epoch: 6| Step: 8
Training loss: 1.0441349096459331
Validation loss: 2.66578427900302

Epoch: 6| Step: 9
Training loss: 1.0552179203683725
Validation loss: 2.6975013380598463

Epoch: 6| Step: 10
Training loss: 0.3721802116148045
Validation loss: 2.72782056411084

Epoch: 6| Step: 11
Training loss: 0.7193937321402316
Validation loss: 2.6875251641017113

Epoch: 6| Step: 12
Training loss: 0.7204323029756344
Validation loss: 2.707778763767855

Epoch: 6| Step: 13
Training loss: 0.5944404352232157
Validation loss: 2.720994530369338

Epoch: 297| Step: 0
Training loss: 0.9769010033444475
Validation loss: 2.6767138192645628

Epoch: 6| Step: 1
Training loss: 0.7878024549800936
Validation loss: 2.6839712031270095

Epoch: 6| Step: 2
Training loss: 0.6613892997301792
Validation loss: 2.6773265908296136

Epoch: 6| Step: 3
Training loss: 0.49749707561381024
Validation loss: 2.6531464089858785

Epoch: 6| Step: 4
Training loss: 0.9062135952181658
Validation loss: 2.680437808417528

Epoch: 6| Step: 5
Training loss: 1.4927051704765437
Validation loss: 2.652278273674066

Epoch: 6| Step: 6
Training loss: 0.7353985329428432
Validation loss: 2.6527170659208643

Epoch: 6| Step: 7
Training loss: 0.7095042862900452
Validation loss: 2.6269389236809846

Epoch: 6| Step: 8
Training loss: 0.8742628398341824
Validation loss: 2.6150663666928784

Epoch: 6| Step: 9
Training loss: 0.8474164702738194
Validation loss: 2.658279753340576

Epoch: 6| Step: 10
Training loss: 0.5113666283876374
Validation loss: 2.639102942023661

Epoch: 6| Step: 11
Training loss: 0.7791711997513985
Validation loss: 2.6709857049136563

Epoch: 6| Step: 12
Training loss: 0.7432805896088106
Validation loss: 2.7068652792713457

Epoch: 6| Step: 13
Training loss: 1.12940492802513
Validation loss: 2.7403011840565563

Epoch: 298| Step: 0
Training loss: 0.9293485071527472
Validation loss: 2.743602053965411

Epoch: 6| Step: 1
Training loss: 0.7595500493111694
Validation loss: 2.7296724117788616

Epoch: 6| Step: 2
Training loss: 0.8192323021256174
Validation loss: 2.6726650213541214

Epoch: 6| Step: 3
Training loss: 0.8411681622040345
Validation loss: 2.712750004769684

Epoch: 6| Step: 4
Training loss: 0.9944735346226721
Validation loss: 2.668249116088284

Epoch: 6| Step: 5
Training loss: 0.6832979488709363
Validation loss: 2.6346852321384557

Epoch: 6| Step: 6
Training loss: 1.3768182350263325
Validation loss: 2.646941965189759

Epoch: 6| Step: 7
Training loss: 0.44022220706455584
Validation loss: 2.618138272863446

Epoch: 6| Step: 8
Training loss: 0.6844387825981818
Validation loss: 2.6222209781494072

Epoch: 6| Step: 9
Training loss: 0.6209371117339627
Validation loss: 2.632739213364277

Epoch: 6| Step: 10
Training loss: 1.0883858065688057
Validation loss: 2.672533836421826

Epoch: 6| Step: 11
Training loss: 0.7777868570259533
Validation loss: 2.6776684941526687

Epoch: 6| Step: 12
Training loss: 0.6602762553372625
Validation loss: 2.6834181875795298

Epoch: 6| Step: 13
Training loss: 0.9508481894682929
Validation loss: 2.6855189569090467

Epoch: 299| Step: 0
Training loss: 0.7195320021700992
Validation loss: 2.686998790374675

Epoch: 6| Step: 1
Training loss: 0.8955242858503051
Validation loss: 2.683955695946491

Epoch: 6| Step: 2
Training loss: 0.7033240566349981
Validation loss: 2.725952867269795

Epoch: 6| Step: 3
Training loss: 0.744140865295852
Validation loss: 2.6748396885527006

Epoch: 6| Step: 4
Training loss: 0.36915315879251526
Validation loss: 2.6916227605005822

Epoch: 6| Step: 5
Training loss: 0.6708331791263505
Validation loss: 2.694148230021443

Epoch: 6| Step: 6
Training loss: 1.1113220107408144
Validation loss: 2.728397352698443

Epoch: 6| Step: 7
Training loss: 0.8634800746719457
Validation loss: 2.6852472301980033

Epoch: 6| Step: 8
Training loss: 0.5144165501087937
Validation loss: 2.6602198103019625

Epoch: 6| Step: 9
Training loss: 0.47278454513253754
Validation loss: 2.6979531660108136

Epoch: 6| Step: 10
Training loss: 0.6013773596096271
Validation loss: 2.6807887708594027

Epoch: 6| Step: 11
Training loss: 1.0759752928261874
Validation loss: 2.703889394336054

Epoch: 6| Step: 12
Training loss: 0.8517608061704836
Validation loss: 2.6361746248688647

Epoch: 6| Step: 13
Training loss: 1.6016524871108537
Validation loss: 2.6447667029355006

Epoch: 300| Step: 0
Training loss: 0.755860400137588
Validation loss: 2.6950566814066863

Epoch: 6| Step: 1
Training loss: 0.6971068642295418
Validation loss: 2.658305417785853

Epoch: 6| Step: 2
Training loss: 0.29405247201958845
Validation loss: 2.6947353482838894

Epoch: 6| Step: 3
Training loss: 0.5130622640491398
Validation loss: 2.687185535696482

Epoch: 6| Step: 4
Training loss: 0.9805145252986283
Validation loss: 2.661375488342978

Epoch: 6| Step: 5
Training loss: 0.4579431939648991
Validation loss: 2.70840614037981

Epoch: 6| Step: 6
Training loss: 0.8937493450989358
Validation loss: 2.700451483516237

Epoch: 6| Step: 7
Training loss: 0.8056547407131175
Validation loss: 2.7225170616914682

Epoch: 6| Step: 8
Training loss: 0.7560153376421156
Validation loss: 2.702351167436566

Epoch: 6| Step: 9
Training loss: 1.2294873880621426
Validation loss: 2.7028456569729866

Epoch: 6| Step: 10
Training loss: 0.739495988622158
Validation loss: 2.7049824255083386

Epoch: 6| Step: 11
Training loss: 1.0413938482966965
Validation loss: 2.654385845262683

Epoch: 6| Step: 12
Training loss: 0.9159134927842206
Validation loss: 2.6742628934117834

Epoch: 6| Step: 13
Training loss: 0.5593506280288724
Validation loss: 2.668113462305534

Epoch: 301| Step: 0
Training loss: 1.2528341112677848
Validation loss: 2.6475197140784896

Epoch: 6| Step: 1
Training loss: 0.8106925373869343
Validation loss: 2.6499334310326486

Epoch: 6| Step: 2
Training loss: 0.7485001189410792
Validation loss: 2.6409958469000543

Epoch: 6| Step: 3
Training loss: 0.5261650475821578
Validation loss: 2.6766764837319017

Epoch: 6| Step: 4
Training loss: 0.9281132295934647
Validation loss: 2.684473464112888

Epoch: 6| Step: 5
Training loss: 0.6151414831364276
Validation loss: 2.6519914683969725

Epoch: 6| Step: 6
Training loss: 0.7558589018591058
Validation loss: 2.6603014841301897

Epoch: 6| Step: 7
Training loss: 0.7407737115855797
Validation loss: 2.697853514926428

Epoch: 6| Step: 8
Training loss: 0.9071718657299814
Validation loss: 2.7079689525397854

Epoch: 6| Step: 9
Training loss: 0.5262121421625171
Validation loss: 2.688391642265968

Epoch: 6| Step: 10
Training loss: 0.8850686604864786
Validation loss: 2.6722991574063917

Epoch: 6| Step: 11
Training loss: 0.8273373582861429
Validation loss: 2.6443789267343774

Epoch: 6| Step: 12
Training loss: 0.36767302533620205
Validation loss: 2.6649941668428996

Epoch: 6| Step: 13
Training loss: 0.9177427297692317
Validation loss: 2.6603394118047334

Epoch: 302| Step: 0
Training loss: 0.32689100926510983
Validation loss: 2.664353481288374

Epoch: 6| Step: 1
Training loss: 0.8308889938835755
Validation loss: 2.634301621211357

Epoch: 6| Step: 2
Training loss: 1.2434298462690903
Validation loss: 2.6652839441210703

Epoch: 6| Step: 3
Training loss: 0.8512360883407842
Validation loss: 2.659674683715985

Epoch: 6| Step: 4
Training loss: 0.7874887465626601
Validation loss: 2.6504289479199112

Epoch: 6| Step: 5
Training loss: 0.9381916355913308
Validation loss: 2.6707592586959628

Epoch: 6| Step: 6
Training loss: 0.7861650353693042
Validation loss: 2.6537476171828938

Epoch: 6| Step: 7
Training loss: 0.7040170520957908
Validation loss: 2.68656389398309

Epoch: 6| Step: 8
Training loss: 0.7069525912035486
Validation loss: 2.6905808071746082

Epoch: 6| Step: 9
Training loss: 0.8195164769153022
Validation loss: 2.6859722683995932

Epoch: 6| Step: 10
Training loss: 0.7196074636978778
Validation loss: 2.682421682288883

Epoch: 6| Step: 11
Training loss: 0.7225473270293169
Validation loss: 2.706064588941093

Epoch: 6| Step: 12
Training loss: 0.7805619834221939
Validation loss: 2.745411366126013

Epoch: 6| Step: 13
Training loss: 0.5425153252419048
Validation loss: 2.7142634616395767

Epoch: 303| Step: 0
Training loss: 0.9543857053744612
Validation loss: 2.7474828351247043

Epoch: 6| Step: 1
Training loss: 1.3035993778345496
Validation loss: 2.7325820787341826

Epoch: 6| Step: 2
Training loss: 0.7595026890027158
Validation loss: 2.751335039989624

Epoch: 6| Step: 3
Training loss: 0.6415130228993793
Validation loss: 2.7229816431054905

Epoch: 6| Step: 4
Training loss: 0.7689486781854007
Validation loss: 2.6964810038455895

Epoch: 6| Step: 5
Training loss: 0.562198054546965
Validation loss: 2.703066608349063

Epoch: 6| Step: 6
Training loss: 0.4134459673878741
Validation loss: 2.691820430779781

Epoch: 6| Step: 7
Training loss: 0.7382382173460217
Validation loss: 2.675582491531199

Epoch: 6| Step: 8
Training loss: 0.9084999501821938
Validation loss: 2.677178391999026

Epoch: 6| Step: 9
Training loss: 0.5928091575757576
Validation loss: 2.6651907407568887

Epoch: 6| Step: 10
Training loss: 0.8413089834113832
Validation loss: 2.650214438837474

Epoch: 6| Step: 11
Training loss: 0.749908600642116
Validation loss: 2.6431933041066404

Epoch: 6| Step: 12
Training loss: 0.5464274346093143
Validation loss: 2.632062637050934

Epoch: 6| Step: 13
Training loss: 0.9930758366740499
Validation loss: 2.695473895443086

Epoch: 304| Step: 0
Training loss: 0.5291068098301596
Validation loss: 2.7008620038814986

Epoch: 6| Step: 1
Training loss: 0.8469577143628974
Validation loss: 2.7000570855587207

Epoch: 6| Step: 2
Training loss: 0.815019369538779
Validation loss: 2.70194548266475

Epoch: 6| Step: 3
Training loss: 0.5146922720784589
Validation loss: 2.704955184735422

Epoch: 6| Step: 4
Training loss: 0.679535092333967
Validation loss: 2.7175101778442605

Epoch: 6| Step: 5
Training loss: 1.1680223331471837
Validation loss: 2.7050538586720547

Epoch: 6| Step: 6
Training loss: 0.46514040032274706
Validation loss: 2.6729930358411504

Epoch: 6| Step: 7
Training loss: 1.0477991722071627
Validation loss: 2.717055874827884

Epoch: 6| Step: 8
Training loss: 0.5495261914950769
Validation loss: 2.696723405823243

Epoch: 6| Step: 9
Training loss: 0.5948163545721519
Validation loss: 2.7067397260628314

Epoch: 6| Step: 10
Training loss: 0.4127776165416112
Validation loss: 2.660226111896363

Epoch: 6| Step: 11
Training loss: 0.7276042320198643
Validation loss: 2.6610700370080416

Epoch: 6| Step: 12
Training loss: 1.0163565715169545
Validation loss: 2.6720504439281028

Epoch: 6| Step: 13
Training loss: 1.0200810612462947
Validation loss: 2.6753535807443813

Epoch: 305| Step: 0
Training loss: 0.6856911010313831
Validation loss: 2.6608361394539366

Epoch: 6| Step: 1
Training loss: 0.6634877129561899
Validation loss: 2.6855280042714322

Epoch: 6| Step: 2
Training loss: 0.9513344439747544
Validation loss: 2.6280984498499538

Epoch: 6| Step: 3
Training loss: 0.4624159910611054
Validation loss: 2.692728517410327

Epoch: 6| Step: 4
Training loss: 0.6926858558927839
Validation loss: 2.679026329567526

Epoch: 6| Step: 5
Training loss: 0.976848895992677
Validation loss: 2.6509915152972248

Epoch: 6| Step: 6
Training loss: 0.6213063769789483
Validation loss: 2.6595777172486814

Epoch: 6| Step: 7
Training loss: 1.2183056534850853
Validation loss: 2.686682048885279

Epoch: 6| Step: 8
Training loss: 0.8440619704334189
Validation loss: 2.679716212142949

Epoch: 6| Step: 9
Training loss: 0.586155355007926
Validation loss: 2.6609675701431006

Epoch: 6| Step: 10
Training loss: 0.5972428481534847
Validation loss: 2.6691141305342025

Epoch: 6| Step: 11
Training loss: 0.7091819971163076
Validation loss: 2.64893613237612

Epoch: 6| Step: 12
Training loss: 0.7712812711660749
Validation loss: 2.6723060914992387

Epoch: 6| Step: 13
Training loss: 0.3746173217376063
Validation loss: 2.639407381099587

Epoch: 306| Step: 0
Training loss: 1.0961710700716656
Validation loss: 2.667062767154279

Epoch: 6| Step: 1
Training loss: 0.9588703779224304
Validation loss: 2.695534774082739

Epoch: 6| Step: 2
Training loss: 0.7465298960653213
Validation loss: 2.6704379097333555

Epoch: 6| Step: 3
Training loss: 0.6660372822839664
Validation loss: 2.6797854894925814

Epoch: 6| Step: 4
Training loss: 0.46942070026121835
Validation loss: 2.680178430329691

Epoch: 6| Step: 5
Training loss: 0.50264552708822
Validation loss: 2.7164857417479946

Epoch: 6| Step: 6
Training loss: 0.9112348264312633
Validation loss: 2.661825932288379

Epoch: 6| Step: 7
Training loss: 0.6893711851884251
Validation loss: 2.664551473501471

Epoch: 6| Step: 8
Training loss: 0.6171312668690585
Validation loss: 2.6818904536423096

Epoch: 6| Step: 9
Training loss: 0.6481670597006889
Validation loss: 2.660299537525262

Epoch: 6| Step: 10
Training loss: 0.7818682703693687
Validation loss: 2.6571747088959685

Epoch: 6| Step: 11
Training loss: 0.9722284502253793
Validation loss: 2.6417142540462075

Epoch: 6| Step: 12
Training loss: 0.7788681342346232
Validation loss: 2.62220612647386

Epoch: 6| Step: 13
Training loss: 0.49002756262642855
Validation loss: 2.628831652042587

Epoch: 307| Step: 0
Training loss: 0.6454368471504516
Validation loss: 2.613020459507184

Epoch: 6| Step: 1
Training loss: 0.566871294306006
Validation loss: 2.610200302084704

Epoch: 6| Step: 2
Training loss: 0.7048624612349518
Validation loss: 2.6642856438889857

Epoch: 6| Step: 3
Training loss: 0.722627958826495
Validation loss: 2.6268711735884223

Epoch: 6| Step: 4
Training loss: 0.8497787482147992
Validation loss: 2.6378149809023395

Epoch: 6| Step: 5
Training loss: 0.5852542453906832
Validation loss: 2.641904663216578

Epoch: 6| Step: 6
Training loss: 0.3552647099358786
Validation loss: 2.6895264409206363

Epoch: 6| Step: 7
Training loss: 0.7884818858604087
Validation loss: 2.679930295994332

Epoch: 6| Step: 8
Training loss: 0.6293007933993683
Validation loss: 2.647169913254337

Epoch: 6| Step: 9
Training loss: 0.5250434721250754
Validation loss: 2.675997702635247

Epoch: 6| Step: 10
Training loss: 0.8567464683956383
Validation loss: 2.6599756325018813

Epoch: 6| Step: 11
Training loss: 0.9184630666044725
Validation loss: 2.6864132946053774

Epoch: 6| Step: 12
Training loss: 1.1497114731782132
Validation loss: 2.6299560598087743

Epoch: 6| Step: 13
Training loss: 1.1023909247109256
Validation loss: 2.6513200549209643

Epoch: 308| Step: 0
Training loss: 0.5656431648330357
Validation loss: 2.628912108837977

Epoch: 6| Step: 1
Training loss: 1.0137664221622322
Validation loss: 2.6153157157127755

Epoch: 6| Step: 2
Training loss: 0.7580577807333415
Validation loss: 2.600108477835556

Epoch: 6| Step: 3
Training loss: 0.8526144966582518
Validation loss: 2.6280516149945283

Epoch: 6| Step: 4
Training loss: 0.7864920796276248
Validation loss: 2.615075536728777

Epoch: 6| Step: 5
Training loss: 0.26148560800936954
Validation loss: 2.6054432824004103

Epoch: 6| Step: 6
Training loss: 0.6955657454939469
Validation loss: 2.6430949900188425

Epoch: 6| Step: 7
Training loss: 0.6844838042840597
Validation loss: 2.6145259091135244

Epoch: 6| Step: 8
Training loss: 0.7228064303673111
Validation loss: 2.6573151973449622

Epoch: 6| Step: 9
Training loss: 0.41659607487966166
Validation loss: 2.6793173448789154

Epoch: 6| Step: 10
Training loss: 0.675749496860578
Validation loss: 2.7098458931007636

Epoch: 6| Step: 11
Training loss: 1.0661043850746925
Validation loss: 2.7377535291440545

Epoch: 6| Step: 12
Training loss: 0.832952750243209
Validation loss: 2.6928070888704285

Epoch: 6| Step: 13
Training loss: 0.5412232038635253
Validation loss: 2.688319144120891

Epoch: 309| Step: 0
Training loss: 0.8158713600822084
Validation loss: 2.6980731405769736

Epoch: 6| Step: 1
Training loss: 1.0931254647430078
Validation loss: 2.6610139884811193

Epoch: 6| Step: 2
Training loss: 0.5384712016959899
Validation loss: 2.6538509936180024

Epoch: 6| Step: 3
Training loss: 0.6021789265899786
Validation loss: 2.6476153734404644

Epoch: 6| Step: 4
Training loss: 0.6896751845884566
Validation loss: 2.5761442608311023

Epoch: 6| Step: 5
Training loss: 0.8323669830797782
Validation loss: 2.585730724062481

Epoch: 6| Step: 6
Training loss: 0.698334886493033
Validation loss: 2.6054071581862446

Epoch: 6| Step: 7
Training loss: 0.7406909510868704
Validation loss: 2.5835944376875553

Epoch: 6| Step: 8
Training loss: 0.37242550053721307
Validation loss: 2.6023180730742754

Epoch: 6| Step: 9
Training loss: 0.6688790615716279
Validation loss: 2.6505357858514564

Epoch: 6| Step: 10
Training loss: 0.789657444021533
Validation loss: 2.65710456849912

Epoch: 6| Step: 11
Training loss: 0.8244979168673006
Validation loss: 2.671399580170942

Epoch: 6| Step: 12
Training loss: 0.5905620420294487
Validation loss: 2.660383199778278

Epoch: 6| Step: 13
Training loss: 0.6686783529387453
Validation loss: 2.6701716556378177

Epoch: 310| Step: 0
Training loss: 0.6589918306897881
Validation loss: 2.6766080090000983

Epoch: 6| Step: 1
Training loss: 0.8673272235101968
Validation loss: 2.6933547433544147

Epoch: 6| Step: 2
Training loss: 0.48396357629404435
Validation loss: 2.645041530328138

Epoch: 6| Step: 3
Training loss: 0.5503060204786782
Validation loss: 2.6488684551866744

Epoch: 6| Step: 4
Training loss: 0.5857120843257805
Validation loss: 2.660192655164538

Epoch: 6| Step: 5
Training loss: 0.5577450954626854
Validation loss: 2.6622614377994194

Epoch: 6| Step: 6
Training loss: 1.1627466329830536
Validation loss: 2.6225021229481422

Epoch: 6| Step: 7
Training loss: 1.0382974432492642
Validation loss: 2.626073872033726

Epoch: 6| Step: 8
Training loss: 0.44733948076977753
Validation loss: 2.6473968849497096

Epoch: 6| Step: 9
Training loss: 0.4945325842382864
Validation loss: 2.608616959086543

Epoch: 6| Step: 10
Training loss: 0.5838960306458971
Validation loss: 2.6182515287779133

Epoch: 6| Step: 11
Training loss: 0.7877067022164632
Validation loss: 2.615364208783546

Epoch: 6| Step: 12
Training loss: 0.9412978493735931
Validation loss: 2.6630316363039324

Epoch: 6| Step: 13
Training loss: 0.3559448281957998
Validation loss: 2.6824870703336408

Epoch: 311| Step: 0
Training loss: 0.8575882109488275
Validation loss: 2.7005449166742292

Epoch: 6| Step: 1
Training loss: 0.6093212984337875
Validation loss: 2.7147854630900192

Epoch: 6| Step: 2
Training loss: 0.4077832558622248
Validation loss: 2.7494488962839485

Epoch: 6| Step: 3
Training loss: 0.6299488121763321
Validation loss: 2.7482617646799454

Epoch: 6| Step: 4
Training loss: 0.6494382466567168
Validation loss: 2.7005182111702086

Epoch: 6| Step: 5
Training loss: 1.0583997034803394
Validation loss: 2.68024697357919

Epoch: 6| Step: 6
Training loss: 1.0780155292163882
Validation loss: 2.7126994194700838

Epoch: 6| Step: 7
Training loss: 0.5853045796328425
Validation loss: 2.648411140742683

Epoch: 6| Step: 8
Training loss: 0.7146362670629445
Validation loss: 2.6209582314898503

Epoch: 6| Step: 9
Training loss: 0.7511825775002974
Validation loss: 2.6147886848544637

Epoch: 6| Step: 10
Training loss: 0.549885528746352
Validation loss: 2.5906056938994277

Epoch: 6| Step: 11
Training loss: 0.5517957016080273
Validation loss: 2.581961725798313

Epoch: 6| Step: 12
Training loss: 0.8699639353457045
Validation loss: 2.59593235189727

Epoch: 6| Step: 13
Training loss: 0.6601667911207119
Validation loss: 2.6485423846137803

Epoch: 312| Step: 0
Training loss: 0.4907057270527057
Validation loss: 2.630549559647891

Epoch: 6| Step: 1
Training loss: 0.7834041270941289
Validation loss: 2.6599120972069428

Epoch: 6| Step: 2
Training loss: 1.0703632314868774
Validation loss: 2.663226828860193

Epoch: 6| Step: 3
Training loss: 0.5044906244021136
Validation loss: 2.6791443106956887

Epoch: 6| Step: 4
Training loss: 0.6793050457296844
Validation loss: 2.6408911731845146

Epoch: 6| Step: 5
Training loss: 0.7148683470783134
Validation loss: 2.659627570158228

Epoch: 6| Step: 6
Training loss: 1.0671322764997249
Validation loss: 2.6251460043075427

Epoch: 6| Step: 7
Training loss: 0.885237713101259
Validation loss: 2.6034974250187783

Epoch: 6| Step: 8
Training loss: 0.5000041425056515
Validation loss: 2.570276748793089

Epoch: 6| Step: 9
Training loss: 0.7136797991700538
Validation loss: 2.597480720993989

Epoch: 6| Step: 10
Training loss: 0.566009066525959
Validation loss: 2.588224978480144

Epoch: 6| Step: 11
Training loss: 0.811244214218033
Validation loss: 2.591625835802814

Epoch: 6| Step: 12
Training loss: 0.577385842281997
Validation loss: 2.605953817790531

Epoch: 6| Step: 13
Training loss: 0.512184717148674
Validation loss: 2.6326684954696074

Epoch: 313| Step: 0
Training loss: 0.3739585322146653
Validation loss: 2.624779287142957

Epoch: 6| Step: 1
Training loss: 0.8369444370878196
Validation loss: 2.6881087840133184

Epoch: 6| Step: 2
Training loss: 0.8816011946501313
Validation loss: 2.6907886569453265

Epoch: 6| Step: 3
Training loss: 0.9158478280211368
Validation loss: 2.6978024174932416

Epoch: 6| Step: 4
Training loss: 0.8768159211010641
Validation loss: 2.711563738285145

Epoch: 6| Step: 5
Training loss: 0.6876167501673461
Validation loss: 2.716473574155053

Epoch: 6| Step: 6
Training loss: 0.5572179109722044
Validation loss: 2.7078622267846604

Epoch: 6| Step: 7
Training loss: 0.6447767772609095
Validation loss: 2.648549416717401

Epoch: 6| Step: 8
Training loss: 0.6626401815915092
Validation loss: 2.6596112424428333

Epoch: 6| Step: 9
Training loss: 0.44033572258230086
Validation loss: 2.6652343624570602

Epoch: 6| Step: 10
Training loss: 0.7630652630643696
Validation loss: 2.655864154315034

Epoch: 6| Step: 11
Training loss: 0.7006988417398498
Validation loss: 2.6487579108325674

Epoch: 6| Step: 12
Training loss: 0.715649926696829
Validation loss: 2.659014745093308

Epoch: 6| Step: 13
Training loss: 0.6342156477854876
Validation loss: 2.679830016811095

Epoch: 314| Step: 0
Training loss: 0.6650649190349122
Validation loss: 2.678865315516724

Epoch: 6| Step: 1
Training loss: 0.9566507011060499
Validation loss: 2.7300416348081025

Epoch: 6| Step: 2
Training loss: 0.5013098249622061
Validation loss: 2.6779864941470337

Epoch: 6| Step: 3
Training loss: 0.8402028934924729
Validation loss: 2.648818569154408

Epoch: 6| Step: 4
Training loss: 0.8174469442970412
Validation loss: 2.651220970795717

Epoch: 6| Step: 5
Training loss: 0.6501489138584676
Validation loss: 2.6734920612819235

Epoch: 6| Step: 6
Training loss: 0.4560864292509944
Validation loss: 2.6430498848079997

Epoch: 6| Step: 7
Training loss: 0.6567212411024109
Validation loss: 2.6506336817788165

Epoch: 6| Step: 8
Training loss: 0.43895642502702903
Validation loss: 2.6428364032991585

Epoch: 6| Step: 9
Training loss: 0.28244205682382956
Validation loss: 2.6871179460320427

Epoch: 6| Step: 10
Training loss: 0.7026131780417417
Validation loss: 2.6546779630248363

Epoch: 6| Step: 11
Training loss: 0.7233095257733462
Validation loss: 2.6593995870834526

Epoch: 6| Step: 12
Training loss: 0.6540006963597828
Validation loss: 2.658022869567675

Epoch: 6| Step: 13
Training loss: 1.310636468999959
Validation loss: 2.6384908837641055

Epoch: 315| Step: 0
Training loss: 0.6324090966953577
Validation loss: 2.6364718885482454

Epoch: 6| Step: 1
Training loss: 0.6254340571917432
Validation loss: 2.6671554370017465

Epoch: 6| Step: 2
Training loss: 0.7976740776259208
Validation loss: 2.6793446731268116

Epoch: 6| Step: 3
Training loss: 0.5265134420662376
Validation loss: 2.692361520655967

Epoch: 6| Step: 4
Training loss: 0.41722222087262983
Validation loss: 2.6733621333712905

Epoch: 6| Step: 5
Training loss: 0.7721443540282099
Validation loss: 2.650686486394775

Epoch: 6| Step: 6
Training loss: 0.6736617394283967
Validation loss: 2.6321427272416575

Epoch: 6| Step: 7
Training loss: 0.7418372281364449
Validation loss: 2.641871083144883

Epoch: 6| Step: 8
Training loss: 0.9101014345877654
Validation loss: 2.6360308973726876

Epoch: 6| Step: 9
Training loss: 0.7080589118144002
Validation loss: 2.655898877944089

Epoch: 6| Step: 10
Training loss: 0.5688484421098381
Validation loss: 2.660155438549265

Epoch: 6| Step: 11
Training loss: 0.6035828043759676
Validation loss: 2.647588734876179

Epoch: 6| Step: 12
Training loss: 1.000615109568126
Validation loss: 2.671300091599415

Epoch: 6| Step: 13
Training loss: 0.5606977412600644
Validation loss: 2.677357048009471

Epoch: 316| Step: 0
Training loss: 1.1030068093761485
Validation loss: 2.6486287760760683

Epoch: 6| Step: 1
Training loss: 0.5960876224547854
Validation loss: 2.664979769020376

Epoch: 6| Step: 2
Training loss: 0.6887541732038567
Validation loss: 2.675365921936151

Epoch: 6| Step: 3
Training loss: 0.42698785443419823
Validation loss: 2.659153028847887

Epoch: 6| Step: 4
Training loss: 0.7672959602588676
Validation loss: 2.6519105406357673

Epoch: 6| Step: 5
Training loss: 0.5575589552100543
Validation loss: 2.615151407395753

Epoch: 6| Step: 6
Training loss: 0.36943653901126344
Validation loss: 2.623660067398745

Epoch: 6| Step: 7
Training loss: 0.3618811010264782
Validation loss: 2.6218502496568075

Epoch: 6| Step: 8
Training loss: 0.4490134060117861
Validation loss: 2.6754577675917623

Epoch: 6| Step: 9
Training loss: 0.7535998655763535
Validation loss: 2.661648173152162

Epoch: 6| Step: 10
Training loss: 0.42823330421215056
Validation loss: 2.6419297618702084

Epoch: 6| Step: 11
Training loss: 0.8026587086306286
Validation loss: 2.6081102083992014

Epoch: 6| Step: 12
Training loss: 1.1045828460803564
Validation loss: 2.6271583368101705

Epoch: 6| Step: 13
Training loss: 0.7631458705138304
Validation loss: 2.6555501335566265

Epoch: 317| Step: 0
Training loss: 0.7657044817092501
Validation loss: 2.6324606007542353

Epoch: 6| Step: 1
Training loss: 0.6190727028157618
Validation loss: 2.646035344056362

Epoch: 6| Step: 2
Training loss: 1.1285426732430215
Validation loss: 2.6031211670706735

Epoch: 6| Step: 3
Training loss: 0.6631952119881636
Validation loss: 2.6147269708875864

Epoch: 6| Step: 4
Training loss: 0.7100999530765898
Validation loss: 2.6123853745955197

Epoch: 6| Step: 5
Training loss: 0.5946103939357914
Validation loss: 2.612299843447172

Epoch: 6| Step: 6
Training loss: 0.6421163923337505
Validation loss: 2.6566753406418826

Epoch: 6| Step: 7
Training loss: 0.5911545745830707
Validation loss: 2.6263031935305765

Epoch: 6| Step: 8
Training loss: 0.8022433447485996
Validation loss: 2.6303770433768787

Epoch: 6| Step: 9
Training loss: 0.5293817205801898
Validation loss: 2.6457843448159357

Epoch: 6| Step: 10
Training loss: 0.6662737438487069
Validation loss: 2.639849525674068

Epoch: 6| Step: 11
Training loss: 0.6609114441120785
Validation loss: 2.65637521466742

Epoch: 6| Step: 12
Training loss: 0.42462399904112347
Validation loss: 2.6520168510094924

Epoch: 6| Step: 13
Training loss: 0.6549269190633503
Validation loss: 2.669400669704881

Epoch: 318| Step: 0
Training loss: 0.7570431136549041
Validation loss: 2.674659732893452

Epoch: 6| Step: 1
Training loss: 1.0439383468181431
Validation loss: 2.6486746034280144

Epoch: 6| Step: 2
Training loss: 0.22596086168929236
Validation loss: 2.6609403426716045

Epoch: 6| Step: 3
Training loss: 0.6036636022981114
Validation loss: 2.6313764325910554

Epoch: 6| Step: 4
Training loss: 0.2409436370325295
Validation loss: 2.6681594406937235

Epoch: 6| Step: 5
Training loss: 0.9960526401787915
Validation loss: 2.6184624236036935

Epoch: 6| Step: 6
Training loss: 0.4578908840166344
Validation loss: 2.617547114495206

Epoch: 6| Step: 7
Training loss: 0.3632021171767541
Validation loss: 2.6779522967238827

Epoch: 6| Step: 8
Training loss: 0.4159919660404556
Validation loss: 2.6501829316378047

Epoch: 6| Step: 9
Training loss: 0.4760134457654606
Validation loss: 2.6325959108353163

Epoch: 6| Step: 10
Training loss: 0.8025889763868553
Validation loss: 2.637593542268624

Epoch: 6| Step: 11
Training loss: 0.8407683849360665
Validation loss: 2.6347294377153587

Epoch: 6| Step: 12
Training loss: 0.8655721035436348
Validation loss: 2.616536779539178

Epoch: 6| Step: 13
Training loss: 0.6782793168306428
Validation loss: 2.6385784253308686

Epoch: 319| Step: 0
Training loss: 0.8336259844624433
Validation loss: 2.6395877869726894

Epoch: 6| Step: 1
Training loss: 0.5437159713971419
Validation loss: 2.6410060199195033

Epoch: 6| Step: 2
Training loss: 0.9365262378575181
Validation loss: 2.5927168014771

Epoch: 6| Step: 3
Training loss: 0.3813183293318277
Validation loss: 2.5836145044218997

Epoch: 6| Step: 4
Training loss: 0.5611908566295615
Validation loss: 2.6182019846915647

Epoch: 6| Step: 5
Training loss: 0.7803062460713284
Validation loss: 2.578684882570895

Epoch: 6| Step: 6
Training loss: 0.7431126500315426
Validation loss: 2.5764216653395744

Epoch: 6| Step: 7
Training loss: 0.6335035248096079
Validation loss: 2.593372076764638

Epoch: 6| Step: 8
Training loss: 0.46768694179470505
Validation loss: 2.6189046482750427

Epoch: 6| Step: 9
Training loss: 0.808826726254352
Validation loss: 2.6354324821540094

Epoch: 6| Step: 10
Training loss: 0.7580061989432629
Validation loss: 2.6185707508081655

Epoch: 6| Step: 11
Training loss: 0.5291832101543722
Validation loss: 2.624493985252823

Epoch: 6| Step: 12
Training loss: 0.48040882760385395
Validation loss: 2.6552020752251164

Epoch: 6| Step: 13
Training loss: 0.6142159403734521
Validation loss: 2.658219020624462

Epoch: 320| Step: 0
Training loss: 0.5231573294490649
Validation loss: 2.6424688047668177

Epoch: 6| Step: 1
Training loss: 0.5218504859968837
Validation loss: 2.635880764326834

Epoch: 6| Step: 2
Training loss: 0.46832672718022633
Validation loss: 2.5799751909237596

Epoch: 6| Step: 3
Training loss: 0.5825005501838673
Validation loss: 2.6167640427946646

Epoch: 6| Step: 4
Training loss: 0.4082787548621076
Validation loss: 2.5726603904757495

Epoch: 6| Step: 5
Training loss: 0.6665998117383113
Validation loss: 2.5486569663453764

Epoch: 6| Step: 6
Training loss: 0.9282988106171487
Validation loss: 2.5530123424618325

Epoch: 6| Step: 7
Training loss: 0.6176715835609587
Validation loss: 2.5556955081478874

Epoch: 6| Step: 8
Training loss: 0.7168640188425403
Validation loss: 2.565581552022369

Epoch: 6| Step: 9
Training loss: 0.6480555960888702
Validation loss: 2.595178778185575

Epoch: 6| Step: 10
Training loss: 0.7249800564226169
Validation loss: 2.6058205932157574

Epoch: 6| Step: 11
Training loss: 0.4512289927604222
Validation loss: 2.639674171402226

Epoch: 6| Step: 12
Training loss: 1.102410605476202
Validation loss: 2.648963594529208

Epoch: 6| Step: 13
Training loss: 0.46859786425823036
Validation loss: 2.657207445303656

Epoch: 321| Step: 0
Training loss: 0.5561206195681933
Validation loss: 2.662949806496601

Epoch: 6| Step: 1
Training loss: 0.6777500293693691
Validation loss: 2.662060933179479

Epoch: 6| Step: 2
Training loss: 0.6775904345947416
Validation loss: 2.649427004943407

Epoch: 6| Step: 3
Training loss: 0.3800886523209068
Validation loss: 2.647048971461898

Epoch: 6| Step: 4
Training loss: 0.6624137831314153
Validation loss: 2.613455584378644

Epoch: 6| Step: 5
Training loss: 0.7880065197263444
Validation loss: 2.605578712504024

Epoch: 6| Step: 6
Training loss: 0.6058123690228098
Validation loss: 2.607282745249181

Epoch: 6| Step: 7
Training loss: 0.4907067443393503
Validation loss: 2.6294670516740206

Epoch: 6| Step: 8
Training loss: 0.9972003250468887
Validation loss: 2.662080301538877

Epoch: 6| Step: 9
Training loss: 0.4951392174509084
Validation loss: 2.6275598708109653

Epoch: 6| Step: 10
Training loss: 0.6626388548241097
Validation loss: 2.6382449854295493

Epoch: 6| Step: 11
Training loss: 0.7818676986170464
Validation loss: 2.6655366695961575

Epoch: 6| Step: 12
Training loss: 0.5202410731963536
Validation loss: 2.6644353093595434

Epoch: 6| Step: 13
Training loss: 0.5914187088615279
Validation loss: 2.6625319395836446

Epoch: 322| Step: 0
Training loss: 0.47944954801023565
Validation loss: 2.6300127575432066

Epoch: 6| Step: 1
Training loss: 0.555686561383742
Validation loss: 2.6401069988842867

Epoch: 6| Step: 2
Training loss: 0.9009390462014608
Validation loss: 2.657625857119131

Epoch: 6| Step: 3
Training loss: 0.6286362726031818
Validation loss: 2.6274359261267857

Epoch: 6| Step: 4
Training loss: 0.7327452899230946
Validation loss: 2.628809802561623

Epoch: 6| Step: 5
Training loss: 0.45172220989473794
Validation loss: 2.6443142634005063

Epoch: 6| Step: 6
Training loss: 0.6366125380972064
Validation loss: 2.576615454379968

Epoch: 6| Step: 7
Training loss: 0.6094623649766171
Validation loss: 2.5591227989179397

Epoch: 6| Step: 8
Training loss: 0.7399091584920642
Validation loss: 2.5524189672874957

Epoch: 6| Step: 9
Training loss: 0.7105406187850565
Validation loss: 2.5438075897372716

Epoch: 6| Step: 10
Training loss: 0.48693821644770097
Validation loss: 2.5513434172294587

Epoch: 6| Step: 11
Training loss: 0.5773074581317996
Validation loss: 2.548827089013946

Epoch: 6| Step: 12
Training loss: 0.6588657111763535
Validation loss: 2.5664583312865163

Epoch: 6| Step: 13
Training loss: 0.6913665070399199
Validation loss: 2.587586551261198

Epoch: 323| Step: 0
Training loss: 0.1637025130736447
Validation loss: 2.595368934808939

Epoch: 6| Step: 1
Training loss: 0.5141959762050804
Validation loss: 2.626767125261642

Epoch: 6| Step: 2
Training loss: 0.5547571004264448
Validation loss: 2.586806533423114

Epoch: 6| Step: 3
Training loss: 0.6566822354251001
Validation loss: 2.648583324455602

Epoch: 6| Step: 4
Training loss: 1.1337101503916305
Validation loss: 2.6480789621888823

Epoch: 6| Step: 5
Training loss: 0.5454767061919197
Validation loss: 2.6692998124697254

Epoch: 6| Step: 6
Training loss: 0.4605571664787887
Validation loss: 2.6795528792657417

Epoch: 6| Step: 7
Training loss: 1.0199776326326289
Validation loss: 2.6793041530856696

Epoch: 6| Step: 8
Training loss: 0.2539000583774068
Validation loss: 2.705129831312357

Epoch: 6| Step: 9
Training loss: 0.7579137203612967
Validation loss: 2.6697733117064133

Epoch: 6| Step: 10
Training loss: 0.5564523478873643
Validation loss: 2.6500422488865474

Epoch: 6| Step: 11
Training loss: 0.3151263026929695
Validation loss: 2.6710745444735955

Epoch: 6| Step: 12
Training loss: 0.49530062014415605
Validation loss: 2.6079338829227052

Epoch: 6| Step: 13
Training loss: 0.8148412717231084
Validation loss: 2.568469908165377

Epoch: 324| Step: 0
Training loss: 0.3834440315952515
Validation loss: 2.604087407700529

Epoch: 6| Step: 1
Training loss: 0.8378904827268965
Validation loss: 2.6162791184668093

Epoch: 6| Step: 2
Training loss: 0.506836731309214
Validation loss: 2.624292447255088

Epoch: 6| Step: 3
Training loss: 0.5540705997931401
Validation loss: 2.5999547667705976

Epoch: 6| Step: 4
Training loss: 0.645584540488813
Validation loss: 2.6081713864588028

Epoch: 6| Step: 5
Training loss: 0.44569634742498304
Validation loss: 2.622880286868921

Epoch: 6| Step: 6
Training loss: 0.5944158183862382
Validation loss: 2.584992964946374

Epoch: 6| Step: 7
Training loss: 0.4219754770507322
Validation loss: 2.634272527936923

Epoch: 6| Step: 8
Training loss: 0.8514867626422363
Validation loss: 2.6713728500919904

Epoch: 6| Step: 9
Training loss: 0.6163144757663032
Validation loss: 2.6216769947016783

Epoch: 6| Step: 10
Training loss: 0.5317119104941485
Validation loss: 2.638020679140341

Epoch: 6| Step: 11
Training loss: 0.7473318801438118
Validation loss: 2.645082068826421

Epoch: 6| Step: 12
Training loss: 0.8118532247464372
Validation loss: 2.6413363839291746

Epoch: 6| Step: 13
Training loss: 0.7358439748505056
Validation loss: 2.6393185945901414

Epoch: 325| Step: 0
Training loss: 0.36622110988476053
Validation loss: 2.5964649213144826

Epoch: 6| Step: 1
Training loss: 0.552738715380554
Validation loss: 2.645915741267331

Epoch: 6| Step: 2
Training loss: 0.4868798707172396
Validation loss: 2.631510404326688

Epoch: 6| Step: 3
Training loss: 0.6892103680966006
Validation loss: 2.6056885424653364

Epoch: 6| Step: 4
Training loss: 0.9718658115651767
Validation loss: 2.610777674102062

Epoch: 6| Step: 5
Training loss: 0.6841882790633973
Validation loss: 2.6505176572598677

Epoch: 6| Step: 6
Training loss: 0.6783676926145652
Validation loss: 2.638363961357543

Epoch: 6| Step: 7
Training loss: 0.5766267177308946
Validation loss: 2.6162842216789683

Epoch: 6| Step: 8
Training loss: 0.584769037576935
Validation loss: 2.5829747743756086

Epoch: 6| Step: 9
Training loss: 0.22648870976521457
Validation loss: 2.5665853625193003

Epoch: 6| Step: 10
Training loss: 0.8805072359679152
Validation loss: 2.579928100533551

Epoch: 6| Step: 11
Training loss: 0.6186494051916941
Validation loss: 2.6091732433225974

Epoch: 6| Step: 12
Training loss: 0.6089722941083046
Validation loss: 2.5969591121720272

Epoch: 6| Step: 13
Training loss: 0.4602739115672684
Validation loss: 2.5917415673425346

Epoch: 326| Step: 0
Training loss: 0.5040083789091105
Validation loss: 2.6302553518489566

Epoch: 6| Step: 1
Training loss: 0.6113612010648826
Validation loss: 2.6630373228338478

Epoch: 6| Step: 2
Training loss: 0.9966121745655677
Validation loss: 2.6165670052083176

Epoch: 6| Step: 3
Training loss: 0.5684474077247327
Validation loss: 2.589495842871315

Epoch: 6| Step: 4
Training loss: 0.7172915962818239
Validation loss: 2.6324329498823364

Epoch: 6| Step: 5
Training loss: 0.3732240066611689
Validation loss: 2.6159450108297846

Epoch: 6| Step: 6
Training loss: 0.322618591752641
Validation loss: 2.5992734131440347

Epoch: 6| Step: 7
Training loss: 0.5201811203607224
Validation loss: 2.5897181061340904

Epoch: 6| Step: 8
Training loss: 0.6571052518666947
Validation loss: 2.5563418437682115

Epoch: 6| Step: 9
Training loss: 0.7713382630873437
Validation loss: 2.5528105770468366

Epoch: 6| Step: 10
Training loss: 0.8055179347830445
Validation loss: 2.566161944911753

Epoch: 6| Step: 11
Training loss: 0.6051195183442447
Validation loss: 2.5287679608510683

Epoch: 6| Step: 12
Training loss: 0.60928774477969
Validation loss: 2.5435869835740896

Epoch: 6| Step: 13
Training loss: 0.5756170931675857
Validation loss: 2.5434383637120606

Epoch: 327| Step: 0
Training loss: 0.7898472198198814
Validation loss: 2.5697748727990977

Epoch: 6| Step: 1
Training loss: 0.7186314858293031
Validation loss: 2.5499019219294716

Epoch: 6| Step: 2
Training loss: 0.6910577531547873
Validation loss: 2.573533756910451

Epoch: 6| Step: 3
Training loss: 0.672953804121171
Validation loss: 2.6083934895057137

Epoch: 6| Step: 4
Training loss: 0.5429700124163326
Validation loss: 2.6307647142599895

Epoch: 6| Step: 5
Training loss: 0.2397449050532005
Validation loss: 2.6537815068046116

Epoch: 6| Step: 6
Training loss: 0.6887903458881812
Validation loss: 2.6533672037506872

Epoch: 6| Step: 7
Training loss: 0.4346306576781601
Validation loss: 2.657161143781405

Epoch: 6| Step: 8
Training loss: 0.6306072947924991
Validation loss: 2.6183640023881405

Epoch: 6| Step: 9
Training loss: 0.4876981075941598
Validation loss: 2.6644684539973653

Epoch: 6| Step: 10
Training loss: 0.5784867933096188
Validation loss: 2.5860926241387747

Epoch: 6| Step: 11
Training loss: 0.5474566227786765
Validation loss: 2.632419135537005

Epoch: 6| Step: 12
Training loss: 0.6424812777273938
Validation loss: 2.6688343980475677

Epoch: 6| Step: 13
Training loss: 0.8823780239738097
Validation loss: 2.6163137001774235

Epoch: 328| Step: 0
Training loss: 0.5587301554558812
Validation loss: 2.6280235977688564

Epoch: 6| Step: 1
Training loss: 0.5070899517951212
Validation loss: 2.6723826205092807

Epoch: 6| Step: 2
Training loss: 0.8149291918132351
Validation loss: 2.602431622449419

Epoch: 6| Step: 3
Training loss: 0.6921149463388416
Validation loss: 2.624152011894179

Epoch: 6| Step: 4
Training loss: 0.4183833837521105
Validation loss: 2.6188385918914703

Epoch: 6| Step: 5
Training loss: 0.5392263964959514
Validation loss: 2.545817442679359

Epoch: 6| Step: 6
Training loss: 0.515797615057441
Validation loss: 2.579713461206847

Epoch: 6| Step: 7
Training loss: 0.4505099109656022
Validation loss: 2.587467557967174

Epoch: 6| Step: 8
Training loss: 0.7130940186359493
Validation loss: 2.578425528423397

Epoch: 6| Step: 9
Training loss: 0.49982817498876164
Validation loss: 2.508027187232241

Epoch: 6| Step: 10
Training loss: 0.4708648498783972
Validation loss: 2.5520408367329668

Epoch: 6| Step: 11
Training loss: 0.7645510712624386
Validation loss: 2.5230899176337713

Epoch: 6| Step: 12
Training loss: 0.7381103560039164
Validation loss: 2.572159001501709

Epoch: 6| Step: 13
Training loss: 0.7136973793554651
Validation loss: 2.573546570928968

Epoch: 329| Step: 0
Training loss: 0.31141739717659334
Validation loss: 2.5827221426934153

Epoch: 6| Step: 1
Training loss: 0.6646012308786057
Validation loss: 2.5607302557422074

Epoch: 6| Step: 2
Training loss: 0.7811313539058259
Validation loss: 2.6274000555036063

Epoch: 6| Step: 3
Training loss: 0.4635862121894936
Validation loss: 2.6045165787106117

Epoch: 6| Step: 4
Training loss: 0.6737848240304768
Validation loss: 2.6214282346274422

Epoch: 6| Step: 5
Training loss: 0.4319882093791921
Validation loss: 2.663452394212362

Epoch: 6| Step: 6
Training loss: 0.6685457470290769
Validation loss: 2.634417221347386

Epoch: 6| Step: 7
Training loss: 0.7361201389726814
Validation loss: 2.648017543396613

Epoch: 6| Step: 8
Training loss: 0.6367094589210801
Validation loss: 2.61497654001088

Epoch: 6| Step: 9
Training loss: 0.6891829525946388
Validation loss: 2.6530471708209125

Epoch: 6| Step: 10
Training loss: 0.5786034176786524
Validation loss: 2.6617343482449254

Epoch: 6| Step: 11
Training loss: 0.8405333061268281
Validation loss: 2.6188073209969414

Epoch: 6| Step: 12
Training loss: 0.6778752513099302
Validation loss: 2.6397566139604316

Epoch: 6| Step: 13
Training loss: 0.30598056725820644
Validation loss: 2.6241530415893672

Epoch: 330| Step: 0
Training loss: 0.5559709234627774
Validation loss: 2.6457304540089948

Epoch: 6| Step: 1
Training loss: 0.5206871654127999
Validation loss: 2.65849066564571

Epoch: 6| Step: 2
Training loss: 0.6767871404460974
Validation loss: 2.670471747866151

Epoch: 6| Step: 3
Training loss: 1.008744215730063
Validation loss: 2.6280779121486963

Epoch: 6| Step: 4
Training loss: 0.39252175453058635
Validation loss: 2.639685960722483

Epoch: 6| Step: 5
Training loss: 0.6182454855569344
Validation loss: 2.5912845258881707

Epoch: 6| Step: 6
Training loss: 0.6140338871625646
Validation loss: 2.6568534981041854

Epoch: 6| Step: 7
Training loss: 0.482533430413873
Validation loss: 2.6036407738737237

Epoch: 6| Step: 8
Training loss: 0.6484755079781188
Validation loss: 2.6489231976962957

Epoch: 6| Step: 9
Training loss: 0.7360606226210854
Validation loss: 2.589962624223844

Epoch: 6| Step: 10
Training loss: 0.929357678547633
Validation loss: 2.5860807570416044

Epoch: 6| Step: 11
Training loss: 0.3226382211261896
Validation loss: 2.602265932189326

Epoch: 6| Step: 12
Training loss: 0.5259459159753436
Validation loss: 2.5912988939165973

Epoch: 6| Step: 13
Training loss: 0.6212582640222963
Validation loss: 2.586009402629765

Epoch: 331| Step: 0
Training loss: 0.6093959804737874
Validation loss: 2.6020400165117694

Epoch: 6| Step: 1
Training loss: 0.5682822106274343
Validation loss: 2.6138940577601413

Epoch: 6| Step: 2
Training loss: 0.4757809092453111
Validation loss: 2.665167718599772

Epoch: 6| Step: 3
Training loss: 0.8086795853468445
Validation loss: 2.660939663450485

Epoch: 6| Step: 4
Training loss: 0.4079562083799927
Validation loss: 2.6850012762539066

Epoch: 6| Step: 5
Training loss: 0.6934329356541437
Validation loss: 2.6647802943698364

Epoch: 6| Step: 6
Training loss: 0.6226215405524107
Validation loss: 2.6495894407544887

Epoch: 6| Step: 7
Training loss: 0.7807391976358281
Validation loss: 2.6967952293410744

Epoch: 6| Step: 8
Training loss: 0.5033570483075628
Validation loss: 2.638517372246827

Epoch: 6| Step: 9
Training loss: 0.6386954393618505
Validation loss: 2.654817843422166

Epoch: 6| Step: 10
Training loss: 0.6586361601038405
Validation loss: 2.6315708026317384

Epoch: 6| Step: 11
Training loss: 0.6796119691821388
Validation loss: 2.5963400955173537

Epoch: 6| Step: 12
Training loss: 0.2954432445312225
Validation loss: 2.6025853950716473

Epoch: 6| Step: 13
Training loss: 0.9360299983352608
Validation loss: 2.6207829729113006

Epoch: 332| Step: 0
Training loss: 0.6026071420352668
Validation loss: 2.647922869638635

Epoch: 6| Step: 1
Training loss: 0.3187864516489863
Validation loss: 2.6807740456981555

Epoch: 6| Step: 2
Training loss: 0.835437161455038
Validation loss: 2.6996212098247825

Epoch: 6| Step: 3
Training loss: 0.7202817517252805
Validation loss: 2.6849432533537

Epoch: 6| Step: 4
Training loss: 0.5213974155115413
Validation loss: 2.6878819634194966

Epoch: 6| Step: 5
Training loss: 0.48122739986511126
Validation loss: 2.674477478966836

Epoch: 6| Step: 6
Training loss: 0.6486617929841395
Validation loss: 2.648255269125773

Epoch: 6| Step: 7
Training loss: 0.40408577683058045
Validation loss: 2.6136182033185626

Epoch: 6| Step: 8
Training loss: 0.5941457433436206
Validation loss: 2.581055494021412

Epoch: 6| Step: 9
Training loss: 0.5608744976397672
Validation loss: 2.586926297399063

Epoch: 6| Step: 10
Training loss: 0.6089657118153773
Validation loss: 2.643039192724979

Epoch: 6| Step: 11
Training loss: 0.8409247250474361
Validation loss: 2.638587963502783

Epoch: 6| Step: 12
Training loss: 0.6431632580883881
Validation loss: 2.6161818424610264

Epoch: 6| Step: 13
Training loss: 0.6304010669251432
Validation loss: 2.60656828726159

Epoch: 333| Step: 0
Training loss: 0.8524897015975947
Validation loss: 2.610607778305265

Epoch: 6| Step: 1
Training loss: 0.7325562620851785
Validation loss: 2.6034367181072504

Epoch: 6| Step: 2
Training loss: 0.7136542006435336
Validation loss: 2.5814076397036025

Epoch: 6| Step: 3
Training loss: 0.670171707768404
Validation loss: 2.594741378799245

Epoch: 6| Step: 4
Training loss: 0.4015914030842844
Validation loss: 2.624013665643158

Epoch: 6| Step: 5
Training loss: 0.6987427524470576
Validation loss: 2.6568013487033904

Epoch: 6| Step: 6
Training loss: 0.5457057988313609
Validation loss: 2.6996615008902927

Epoch: 6| Step: 7
Training loss: 0.4573863190759156
Validation loss: 2.7036650971228084

Epoch: 6| Step: 8
Training loss: 0.42051061123467187
Validation loss: 2.7207148053707138

Epoch: 6| Step: 9
Training loss: 0.4976040535806175
Validation loss: 2.689673927453685

Epoch: 6| Step: 10
Training loss: 0.28175290497853667
Validation loss: 2.6893035224848822

Epoch: 6| Step: 11
Training loss: 0.43495301957582577
Validation loss: 2.670516577355791

Epoch: 6| Step: 12
Training loss: 0.7510686254931671
Validation loss: 2.642182033763094

Epoch: 6| Step: 13
Training loss: 0.6499559479237693
Validation loss: 2.59336419614682

Epoch: 334| Step: 0
Training loss: 0.5741011830079662
Validation loss: 2.641350836866139

Epoch: 6| Step: 1
Training loss: 0.6521541525518081
Validation loss: 2.6311073150152278

Epoch: 6| Step: 2
Training loss: 0.1646714659364627
Validation loss: 2.638283486716824

Epoch: 6| Step: 3
Training loss: 0.6181939285078286
Validation loss: 2.6353935831805044

Epoch: 6| Step: 4
Training loss: 0.31804892257972106
Validation loss: 2.6706351014498506

Epoch: 6| Step: 5
Training loss: 0.6070495396513592
Validation loss: 2.7051542992900637

Epoch: 6| Step: 6
Training loss: 0.5327621145280717
Validation loss: 2.694939512007427

Epoch: 6| Step: 7
Training loss: 0.8426307743125351
Validation loss: 2.71470709051228

Epoch: 6| Step: 8
Training loss: 0.7689206561960098
Validation loss: 2.690561573470607

Epoch: 6| Step: 9
Training loss: 0.5508928388819478
Validation loss: 2.6845677474928538

Epoch: 6| Step: 10
Training loss: 0.64124691246732
Validation loss: 2.733474826101825

Epoch: 6| Step: 11
Training loss: 0.5332853652075524
Validation loss: 2.687477586771517

Epoch: 6| Step: 12
Training loss: 0.7485235702304787
Validation loss: 2.674418626718691

Epoch: 6| Step: 13
Training loss: 0.5588892975140631
Validation loss: 2.685480025935159

Epoch: 335| Step: 0
Training loss: 0.5475275233940792
Validation loss: 2.7035035477588165

Epoch: 6| Step: 1
Training loss: 0.5701116443350182
Validation loss: 2.7127884872209553

Epoch: 6| Step: 2
Training loss: 0.8445379322221691
Validation loss: 2.7099838988722587

Epoch: 6| Step: 3
Training loss: 0.27095205963067864
Validation loss: 2.682521550169634

Epoch: 6| Step: 4
Training loss: 0.7868913296436008
Validation loss: 2.6720605198244067

Epoch: 6| Step: 5
Training loss: 0.44407767031673756
Validation loss: 2.657392351014969

Epoch: 6| Step: 6
Training loss: 0.8703399955200375
Validation loss: 2.6720161767696124

Epoch: 6| Step: 7
Training loss: 0.5280232325810629
Validation loss: 2.6246147419959853

Epoch: 6| Step: 8
Training loss: 0.46269331320141077
Validation loss: 2.6373953284464657

Epoch: 6| Step: 9
Training loss: 0.7540060580108892
Validation loss: 2.5753229619884164

Epoch: 6| Step: 10
Training loss: 0.34499733208578426
Validation loss: 2.574959010654075

Epoch: 6| Step: 11
Training loss: 0.3153561840099112
Validation loss: 2.569838390029253

Epoch: 6| Step: 12
Training loss: 0.4646561668878756
Validation loss: 2.6112618411208253

Epoch: 6| Step: 13
Training loss: 0.7135031381122359
Validation loss: 2.5906657227966168

Epoch: 336| Step: 0
Training loss: 0.46615946517135265
Validation loss: 2.6307566922876053

Epoch: 6| Step: 1
Training loss: 0.8068976927860078
Validation loss: 2.6332436446491214

Epoch: 6| Step: 2
Training loss: 0.5805504927447394
Validation loss: 2.635379136483937

Epoch: 6| Step: 3
Training loss: 0.4671797359421044
Validation loss: 2.6528328773145047

Epoch: 6| Step: 4
Training loss: 0.4302691770698504
Validation loss: 2.678882367065826

Epoch: 6| Step: 5
Training loss: 0.4613748027756651
Validation loss: 2.6853668091667418

Epoch: 6| Step: 6
Training loss: 0.4671947268179047
Validation loss: 2.641565052517357

Epoch: 6| Step: 7
Training loss: 0.5803132271133
Validation loss: 2.631449833170655

Epoch: 6| Step: 8
Training loss: 0.4792371642732505
Validation loss: 2.6074758988248603

Epoch: 6| Step: 9
Training loss: 0.39971535657930896
Validation loss: 2.5926892033396696

Epoch: 6| Step: 10
Training loss: 0.6150548763913248
Validation loss: 2.5637898754064063

Epoch: 6| Step: 11
Training loss: 0.7599366297151765
Validation loss: 2.5519135531484802

Epoch: 6| Step: 12
Training loss: 0.7505542773265607
Validation loss: 2.5913694873359443

Epoch: 6| Step: 13
Training loss: 0.48622744640323506
Validation loss: 2.5525136444638914

Epoch: 337| Step: 0
Training loss: 0.6116023560695661
Validation loss: 2.5562715617088703

Epoch: 6| Step: 1
Training loss: 0.6298399681483114
Validation loss: 2.5990981240448767

Epoch: 6| Step: 2
Training loss: 0.4687833933061924
Validation loss: 2.6109135599996995

Epoch: 6| Step: 3
Training loss: 0.41292419152792426
Validation loss: 2.6000584347116247

Epoch: 6| Step: 4
Training loss: 0.7233355654258685
Validation loss: 2.616015619276922

Epoch: 6| Step: 5
Training loss: 0.670422603216573
Validation loss: 2.6578128683105833

Epoch: 6| Step: 6
Training loss: 0.5877657532748984
Validation loss: 2.6122800711590464

Epoch: 6| Step: 7
Training loss: 0.7124375667322674
Validation loss: 2.5943905133052416

Epoch: 6| Step: 8
Training loss: 0.15802925468914125
Validation loss: 2.5488113600788096

Epoch: 6| Step: 9
Training loss: 0.4710242414674998
Validation loss: 2.5220051659381366

Epoch: 6| Step: 10
Training loss: 0.40717569669302156
Validation loss: 2.504711199951347

Epoch: 6| Step: 11
Training loss: 0.6780342515969628
Validation loss: 2.466212178919124

Epoch: 6| Step: 12
Training loss: 0.6256834346603732
Validation loss: 2.4850643803781964

Epoch: 6| Step: 13
Training loss: 0.42118006442653655
Validation loss: 2.4552921942548362

Epoch: 338| Step: 0
Training loss: 0.5155269356155298
Validation loss: 2.4574162493473963

Epoch: 6| Step: 1
Training loss: 0.5823163096127346
Validation loss: 2.4504942165726593

Epoch: 6| Step: 2
Training loss: 0.4419106833525084
Validation loss: 2.4884011167350653

Epoch: 6| Step: 3
Training loss: 0.6521953939445424
Validation loss: 2.493456808615015

Epoch: 6| Step: 4
Training loss: 0.6001022748404702
Validation loss: 2.5427570149330645

Epoch: 6| Step: 5
Training loss: 0.8163070618457295
Validation loss: 2.567984010430871

Epoch: 6| Step: 6
Training loss: 0.42850581586489755
Validation loss: 2.556544907857859

Epoch: 6| Step: 7
Training loss: 0.617900750123924
Validation loss: 2.62172132476302

Epoch: 6| Step: 8
Training loss: 0.36078642371008907
Validation loss: 2.623444031094048

Epoch: 6| Step: 9
Training loss: 0.6636136726063652
Validation loss: 2.6412383831463218

Epoch: 6| Step: 10
Training loss: 0.7697811592289999
Validation loss: 2.6431379647521203

Epoch: 6| Step: 11
Training loss: 0.5935274008039274
Validation loss: 2.6064635986146003

Epoch: 6| Step: 12
Training loss: 0.30499792180369534
Validation loss: 2.5959576698661393

Epoch: 6| Step: 13
Training loss: 0.40623226493857617
Validation loss: 2.591988620900887

Epoch: 339| Step: 0
Training loss: 0.5067362016512782
Validation loss: 2.5551530686549437

Epoch: 6| Step: 1
Training loss: 0.6153802607914103
Validation loss: 2.5218670673934067

Epoch: 6| Step: 2
Training loss: 0.7170372749519384
Validation loss: 2.54856558864307

Epoch: 6| Step: 3
Training loss: 0.6349643102888952
Validation loss: 2.5153842536438598

Epoch: 6| Step: 4
Training loss: 0.5360267409159069
Validation loss: 2.5549383778784054

Epoch: 6| Step: 5
Training loss: 0.4513010277784374
Validation loss: 2.552502752164815

Epoch: 6| Step: 6
Training loss: 0.6975788513514757
Validation loss: 2.5787588444723535

Epoch: 6| Step: 7
Training loss: 0.5680084718354501
Validation loss: 2.6009871816643706

Epoch: 6| Step: 8
Training loss: 0.5093669867324064
Validation loss: 2.6042476702161523

Epoch: 6| Step: 9
Training loss: 0.8366006377813912
Validation loss: 2.6562957904495317

Epoch: 6| Step: 10
Training loss: 0.5640125072864514
Validation loss: 2.62194015764388

Epoch: 6| Step: 11
Training loss: 0.2777738325845513
Validation loss: 2.615458400654165

Epoch: 6| Step: 12
Training loss: 0.4858520046226537
Validation loss: 2.553606648438019

Epoch: 6| Step: 13
Training loss: 0.5204809013695803
Validation loss: 2.5437628603075986

Epoch: 340| Step: 0
Training loss: 0.6101792725580113
Validation loss: 2.5366859520044365

Epoch: 6| Step: 1
Training loss: 0.5130001651324922
Validation loss: 2.4946978045260804

Epoch: 6| Step: 2
Training loss: 0.6147387248863357
Validation loss: 2.459745053552152

Epoch: 6| Step: 3
Training loss: 0.7551064696618667
Validation loss: 2.5363497389394403

Epoch: 6| Step: 4
Training loss: 0.6064203720984307
Validation loss: 2.5441990996733774

Epoch: 6| Step: 5
Training loss: 0.5946167842978248
Validation loss: 2.505457994973816

Epoch: 6| Step: 6
Training loss: 0.5328313628406778
Validation loss: 2.531817691716657

Epoch: 6| Step: 7
Training loss: 0.566479119184526
Validation loss: 2.54287067933253

Epoch: 6| Step: 8
Training loss: 0.3634736566770769
Validation loss: 2.5563782070380636

Epoch: 6| Step: 9
Training loss: 0.6311561901902584
Validation loss: 2.581544588935461

Epoch: 6| Step: 10
Training loss: 0.30420570917691
Validation loss: 2.5941496436282607

Epoch: 6| Step: 11
Training loss: 0.6051162678152154
Validation loss: 2.6109785183599943

Epoch: 6| Step: 12
Training loss: 0.5405651654775274
Validation loss: 2.5800783664518536

Epoch: 6| Step: 13
Training loss: 0.8360135409271526
Validation loss: 2.633205341301347

Epoch: 341| Step: 0
Training loss: 0.8801637596867794
Validation loss: 2.6040825434397625

Epoch: 6| Step: 1
Training loss: 0.7108339506760034
Validation loss: 2.609156278575919

Epoch: 6| Step: 2
Training loss: 0.5531579002466526
Validation loss: 2.5512504882855445

Epoch: 6| Step: 3
Training loss: 0.4484796829852693
Validation loss: 2.551645381903526

Epoch: 6| Step: 4
Training loss: 0.5994843591840245
Validation loss: 2.548048781556229

Epoch: 6| Step: 5
Training loss: 0.44755731258254744
Validation loss: 2.513587309307586

Epoch: 6| Step: 6
Training loss: 0.43207745434333744
Validation loss: 2.522168627466134

Epoch: 6| Step: 7
Training loss: 0.6430552140567533
Validation loss: 2.539274853076534

Epoch: 6| Step: 8
Training loss: 0.5830565772437104
Validation loss: 2.5250851896509743

Epoch: 6| Step: 9
Training loss: 0.49037320424377556
Validation loss: 2.5393704357475038

Epoch: 6| Step: 10
Training loss: 0.6646007824543317
Validation loss: 2.538644790303597

Epoch: 6| Step: 11
Training loss: 0.39896851104157877
Validation loss: 2.563817299663245

Epoch: 6| Step: 12
Training loss: 0.41198243993076916
Validation loss: 2.6104845047724923

Epoch: 6| Step: 13
Training loss: 0.5678392632600928
Validation loss: 2.5886153289487708

Epoch: 342| Step: 0
Training loss: 0.5852632075957778
Validation loss: 2.589339587499157

Epoch: 6| Step: 1
Training loss: 0.514214928472849
Validation loss: 2.5928091128428843

Epoch: 6| Step: 2
Training loss: 0.6190665889722414
Validation loss: 2.593725800107899

Epoch: 6| Step: 3
Training loss: 0.6394476888585172
Validation loss: 2.594388245505618

Epoch: 6| Step: 4
Training loss: 0.4480483855776611
Validation loss: 2.616881599113569

Epoch: 6| Step: 5
Training loss: 0.43024190336075585
Validation loss: 2.6016940014328864

Epoch: 6| Step: 6
Training loss: 0.694537470202918
Validation loss: 2.6527083893817935

Epoch: 6| Step: 7
Training loss: 0.7467938079755042
Validation loss: 2.6661294115850382

Epoch: 6| Step: 8
Training loss: 0.40689717608840925
Validation loss: 2.6554036229459

Epoch: 6| Step: 9
Training loss: 0.7687117187148658
Validation loss: 2.65097218100142

Epoch: 6| Step: 10
Training loss: 0.5505200300929605
Validation loss: 2.6153601447750625

Epoch: 6| Step: 11
Training loss: 0.19855986824608973
Validation loss: 2.629003089806142

Epoch: 6| Step: 12
Training loss: 0.38801348335763586
Validation loss: 2.5757141515197017

Epoch: 6| Step: 13
Training loss: 0.1524422400559881
Validation loss: 2.5860800551850165

Epoch: 343| Step: 0
Training loss: 0.5526353727177017
Validation loss: 2.607320989906387

Epoch: 6| Step: 1
Training loss: 0.39970713638017225
Validation loss: 2.557789751643358

Epoch: 6| Step: 2
Training loss: 0.5217432815254456
Validation loss: 2.5833898925808634

Epoch: 6| Step: 3
Training loss: 0.5513399415373555
Validation loss: 2.594496985007396

Epoch: 6| Step: 4
Training loss: 0.5725198382892566
Validation loss: 2.5683474668908852

Epoch: 6| Step: 5
Training loss: 0.7571181429507907
Validation loss: 2.6116870650586197

Epoch: 6| Step: 6
Training loss: 0.3505953944213831
Validation loss: 2.6176551348416166

Epoch: 6| Step: 7
Training loss: 0.22731052431176746
Validation loss: 2.5991297987590105

Epoch: 6| Step: 8
Training loss: 0.8228597420105491
Validation loss: 2.6173896575564

Epoch: 6| Step: 9
Training loss: 0.5389439825716342
Validation loss: 2.6001524322068876

Epoch: 6| Step: 10
Training loss: 0.6361841403022884
Validation loss: 2.6489875878717086

Epoch: 6| Step: 11
Training loss: 0.48262623462356063
Validation loss: 2.6347180339131917

Epoch: 6| Step: 12
Training loss: 0.2746502141850288
Validation loss: 2.645793676785666

Epoch: 6| Step: 13
Training loss: 0.5304580282889058
Validation loss: 2.6299904724039602

Epoch: 344| Step: 0
Training loss: 0.18232859282924344
Validation loss: 2.6297705702812495

Epoch: 6| Step: 1
Training loss: 0.5439284371681001
Validation loss: 2.658077461158587

Epoch: 6| Step: 2
Training loss: 0.4699057001515433
Validation loss: 2.6146869240976254

Epoch: 6| Step: 3
Training loss: 0.6321642345573104
Validation loss: 2.6007523597433515

Epoch: 6| Step: 4
Training loss: 0.5925189859430691
Validation loss: 2.5985545199514273

Epoch: 6| Step: 5
Training loss: 0.7192543996544419
Validation loss: 2.56141443916593

Epoch: 6| Step: 6
Training loss: 0.7567436703460394
Validation loss: 2.5681907947527844

Epoch: 6| Step: 7
Training loss: 0.2927819482992694
Validation loss: 2.554306824283077

Epoch: 6| Step: 8
Training loss: 0.40977994822878133
Validation loss: 2.5196784870980515

Epoch: 6| Step: 9
Training loss: 0.4727177540510203
Validation loss: 2.5587359509987446

Epoch: 6| Step: 10
Training loss: 0.6908601015478169
Validation loss: 2.5641457909808683

Epoch: 6| Step: 11
Training loss: 0.3265249659674428
Validation loss: 2.5842889767407486

Epoch: 6| Step: 12
Training loss: 0.5738827507344825
Validation loss: 2.614050163956492

Epoch: 6| Step: 13
Training loss: 0.47656775299679177
Validation loss: 2.5949485906397256

Epoch: 345| Step: 0
Training loss: 0.5554361529651052
Validation loss: 2.6137828071219857

Epoch: 6| Step: 1
Training loss: 0.813755422653202
Validation loss: 2.6098851798234404

Epoch: 6| Step: 2
Training loss: 0.2518691876784405
Validation loss: 2.6030996592054843

Epoch: 6| Step: 3
Training loss: 0.25564438035243414
Validation loss: 2.566455588299864

Epoch: 6| Step: 4
Training loss: 0.45954860339300635
Validation loss: 2.5682759205013364

Epoch: 6| Step: 5
Training loss: 0.8504984095635364
Validation loss: 2.595457241135437

Epoch: 6| Step: 6
Training loss: 0.13094738946818207
Validation loss: 2.534327297561643

Epoch: 6| Step: 7
Training loss: 0.3517016241512808
Validation loss: 2.5638254235905418

Epoch: 6| Step: 8
Training loss: 0.7013282070306469
Validation loss: 2.5860391270998173

Epoch: 6| Step: 9
Training loss: 0.682397482337254
Validation loss: 2.5368958715504166

Epoch: 6| Step: 10
Training loss: 0.22548819567124043
Validation loss: 2.5621402807136677

Epoch: 6| Step: 11
Training loss: 0.518240652164742
Validation loss: 2.5543006698684363

Epoch: 6| Step: 12
Training loss: 0.29546339327728843
Validation loss: 2.5742279490263993

Epoch: 6| Step: 13
Training loss: 0.4174097369323199
Validation loss: 2.6154625380239507

Epoch: 346| Step: 0
Training loss: 0.48667046933561
Validation loss: 2.6306288158994153

Epoch: 6| Step: 1
Training loss: 0.5368992619922018
Validation loss: 2.612385809329506

Epoch: 6| Step: 2
Training loss: 0.5902098978194447
Validation loss: 2.6110544285468764

Epoch: 6| Step: 3
Training loss: 0.7808372933346034
Validation loss: 2.638218423275567

Epoch: 6| Step: 4
Training loss: 0.46211481873118515
Validation loss: 2.6195782064987876

Epoch: 6| Step: 5
Training loss: 0.29152948979711096
Validation loss: 2.6321324060106703

Epoch: 6| Step: 6
Training loss: 0.34894434582969136
Validation loss: 2.6197472191420674

Epoch: 6| Step: 7
Training loss: 0.4108357205556929
Validation loss: 2.57966658268461

Epoch: 6| Step: 8
Training loss: 0.6245167771552861
Validation loss: 2.596629474135587

Epoch: 6| Step: 9
Training loss: 0.28894382050961764
Validation loss: 2.6067705710787736

Epoch: 6| Step: 10
Training loss: 0.20774982016230856
Validation loss: 2.583552210014016

Epoch: 6| Step: 11
Training loss: 0.5694019940171534
Validation loss: 2.573344140131587

Epoch: 6| Step: 12
Training loss: 0.4773239244005694
Validation loss: 2.5621968792128147

Epoch: 6| Step: 13
Training loss: 0.919615352288086
Validation loss: 2.5619717745585944

Epoch: 347| Step: 0
Training loss: 0.30695589223047853
Validation loss: 2.5806971199146322

Epoch: 6| Step: 1
Training loss: 0.47763428781998696
Validation loss: 2.5848300080206217

Epoch: 6| Step: 2
Training loss: 0.40577604082632246
Validation loss: 2.5687757976951047

Epoch: 6| Step: 3
Training loss: 0.7431417253824226
Validation loss: 2.5765995697244457

Epoch: 6| Step: 4
Training loss: 0.44276167791270926
Validation loss: 2.6022991475325266

Epoch: 6| Step: 5
Training loss: 0.5767835053929276
Validation loss: 2.6347696435083825

Epoch: 6| Step: 6
Training loss: 0.15664382417603487
Validation loss: 2.63914397341168

Epoch: 6| Step: 7
Training loss: 0.4767859200986905
Validation loss: 2.6047734019311073

Epoch: 6| Step: 8
Training loss: 0.516371504499156
Validation loss: 2.58361403507861

Epoch: 6| Step: 9
Training loss: 0.539880463694619
Validation loss: 2.633375790475577

Epoch: 6| Step: 10
Training loss: 0.5962191488573668
Validation loss: 2.600849051196999

Epoch: 6| Step: 11
Training loss: 0.5286939501983916
Validation loss: 2.609814923193537

Epoch: 6| Step: 12
Training loss: 0.6112953152855678
Validation loss: 2.5898123279737235

Epoch: 6| Step: 13
Training loss: 0.5650599296822753
Validation loss: 2.5620883658051388

Epoch: 348| Step: 0
Training loss: 0.5297175351069822
Validation loss: 2.5437523538216227

Epoch: 6| Step: 1
Training loss: 0.3686400152507049
Validation loss: 2.5713446370950463

Epoch: 6| Step: 2
Training loss: 0.7917147713819641
Validation loss: 2.5563452454506863

Epoch: 6| Step: 3
Training loss: 0.5229066747746777
Validation loss: 2.5849345666751185

Epoch: 6| Step: 4
Training loss: 0.11096181334437467
Validation loss: 2.5949013609874765

Epoch: 6| Step: 5
Training loss: 0.27894551510997806
Validation loss: 2.625161350094457

Epoch: 6| Step: 6
Training loss: 0.5406711735053475
Validation loss: 2.6191418015291723

Epoch: 6| Step: 7
Training loss: 0.4362834979315606
Validation loss: 2.647500395582454

Epoch: 6| Step: 8
Training loss: 0.6246179605148026
Validation loss: 2.600423307544831

Epoch: 6| Step: 9
Training loss: 0.5154168836037568
Validation loss: 2.620693326519583

Epoch: 6| Step: 10
Training loss: 0.3104749392318267
Validation loss: 2.612156164029601

Epoch: 6| Step: 11
Training loss: 0.5184580682373023
Validation loss: 2.6150219689123246

Epoch: 6| Step: 12
Training loss: 0.5126872325442178
Validation loss: 2.6065374917414754

Epoch: 6| Step: 13
Training loss: 0.6377142863934063
Validation loss: 2.5909213117183802

Epoch: 349| Step: 0
Training loss: 0.6839466165156196
Validation loss: 2.591618992496544

Epoch: 6| Step: 1
Training loss: 0.20955928265075466
Validation loss: 2.580891453106118

Epoch: 6| Step: 2
Training loss: 0.5262576751874166
Validation loss: 2.584506940925124

Epoch: 6| Step: 3
Training loss: 0.330343568598483
Validation loss: 2.575841496622593

Epoch: 6| Step: 4
Training loss: 0.5057843126847122
Validation loss: 2.556939355276934

Epoch: 6| Step: 5
Training loss: 0.48376469464124966
Validation loss: 2.5712292801590295

Epoch: 6| Step: 6
Training loss: 0.726210313983145
Validation loss: 2.5751905658892262

Epoch: 6| Step: 7
Training loss: 0.4885740089149185
Validation loss: 2.6089532742381394

Epoch: 6| Step: 8
Training loss: 0.22780902548548762
Validation loss: 2.6214798071019763

Epoch: 6| Step: 9
Training loss: 0.5072320995829128
Validation loss: 2.623065542360606

Epoch: 6| Step: 10
Training loss: 0.47010290094846635
Validation loss: 2.6011664380304937

Epoch: 6| Step: 11
Training loss: 0.45728819707482576
Validation loss: 2.6146361348909073

Epoch: 6| Step: 12
Training loss: 0.5780032261623118
Validation loss: 2.6164938641621047

Epoch: 6| Step: 13
Training loss: 0.5491098515735058
Validation loss: 2.6217721106771537

Epoch: 350| Step: 0
Training loss: 0.6412714046304165
Validation loss: 2.6051387844513236

Epoch: 6| Step: 1
Training loss: 0.3742713604541227
Validation loss: 2.6364058055681823

Epoch: 6| Step: 2
Training loss: 0.467748270970487
Validation loss: 2.616343470830865

Epoch: 6| Step: 3
Training loss: 0.7168552884199677
Validation loss: 2.579583552382838

Epoch: 6| Step: 4
Training loss: 0.42679641164984594
Validation loss: 2.570839088473255

Epoch: 6| Step: 5
Training loss: 0.5431424418854383
Validation loss: 2.559457044160252

Epoch: 6| Step: 6
Training loss: 0.6549723085344721
Validation loss: 2.533977182850947

Epoch: 6| Step: 7
Training loss: 0.2635713597609378
Validation loss: 2.5712546429570313

Epoch: 6| Step: 8
Training loss: 0.3969380080902014
Validation loss: 2.567118796292788

Epoch: 6| Step: 9
Training loss: 0.474305766133376
Validation loss: 2.59890871968328

Epoch: 6| Step: 10
Training loss: 0.6672001035692514
Validation loss: 2.610706278835366

Epoch: 6| Step: 11
Training loss: 0.3237920043826393
Validation loss: 2.649635815569567

Epoch: 6| Step: 12
Training loss: 0.48868318418106305
Validation loss: 2.679754684898987

Epoch: 6| Step: 13
Training loss: 0.5165347541054633
Validation loss: 2.626326816021887

Epoch: 351| Step: 0
Training loss: 0.546395718497848
Validation loss: 2.6060048155592748

Epoch: 6| Step: 1
Training loss: 0.4993257148303242
Validation loss: 2.5688680562343444

Epoch: 6| Step: 2
Training loss: 0.6107233242809715
Validation loss: 2.5257550290800594

Epoch: 6| Step: 3
Training loss: 0.40554761689216895
Validation loss: 2.470847006995499

Epoch: 6| Step: 4
Training loss: 0.49429156143036007
Validation loss: 2.49279933078208

Epoch: 6| Step: 5
Training loss: 0.5573193076816213
Validation loss: 2.5270684839121498

Epoch: 6| Step: 6
Training loss: 0.8166952397414803
Validation loss: 2.5492274471514977

Epoch: 6| Step: 7
Training loss: 0.37524056665608513
Validation loss: 2.5490203162616276

Epoch: 6| Step: 8
Training loss: 0.30918754717053637
Validation loss: 2.5816425231121567

Epoch: 6| Step: 9
Training loss: 0.3654933969733583
Validation loss: 2.6186900733542164

Epoch: 6| Step: 10
Training loss: 0.5072682912507657
Validation loss: 2.6277612230886747

Epoch: 6| Step: 11
Training loss: 0.6164456991860787
Validation loss: 2.617359340991089

Epoch: 6| Step: 12
Training loss: 0.4917219473047254
Validation loss: 2.600888298268631

Epoch: 6| Step: 13
Training loss: 0.6086153038821048
Validation loss: 2.5858853877088674

Epoch: 352| Step: 0
Training loss: 0.6486638604750642
Validation loss: 2.5948682762058373

Epoch: 6| Step: 1
Training loss: 0.3763815544011266
Validation loss: 2.593852302440375

Epoch: 6| Step: 2
Training loss: 0.5171583668781135
Validation loss: 2.5662835833960576

Epoch: 6| Step: 3
Training loss: 0.4429200806699983
Validation loss: 2.527525534825563

Epoch: 6| Step: 4
Training loss: 0.40953150807779704
Validation loss: 2.559471004904703

Epoch: 6| Step: 5
Training loss: 0.5436356928587969
Validation loss: 2.567674442217275

Epoch: 6| Step: 6
Training loss: 0.5448212616165519
Validation loss: 2.5504778853544177

Epoch: 6| Step: 7
Training loss: 0.5905944140149108
Validation loss: 2.563762470855263

Epoch: 6| Step: 8
Training loss: 0.7716287212297546
Validation loss: 2.553269433413661

Epoch: 6| Step: 9
Training loss: 0.462320274151516
Validation loss: 2.5515795470173037

Epoch: 6| Step: 10
Training loss: 0.5679379765754246
Validation loss: 2.57617535996291

Epoch: 6| Step: 11
Training loss: 0.4602484644667887
Validation loss: 2.617287383777719

Epoch: 6| Step: 12
Training loss: 0.4078074641300457
Validation loss: 2.566685594428463

Epoch: 6| Step: 13
Training loss: 0.20401237218226528
Validation loss: 2.5388805728730772

Epoch: 353| Step: 0
Training loss: 0.40869211723238447
Validation loss: 2.584586473351149

Epoch: 6| Step: 1
Training loss: 0.4624868635941091
Validation loss: 2.573252777565367

Epoch: 6| Step: 2
Training loss: 0.593862246895726
Validation loss: 2.5676657608624107

Epoch: 6| Step: 3
Training loss: 0.31866605298371925
Validation loss: 2.5746454946447908

Epoch: 6| Step: 4
Training loss: 0.45930953175624706
Validation loss: 2.629592086124331

Epoch: 6| Step: 5
Training loss: 0.5636853867442675
Validation loss: 2.6330926419354137

Epoch: 6| Step: 6
Training loss: 0.5093320559320026
Validation loss: 2.6190376306451753

Epoch: 6| Step: 7
Training loss: 0.4959887896662987
Validation loss: 2.603704947281516

Epoch: 6| Step: 8
Training loss: 0.34783509829677645
Validation loss: 2.6388612514387804

Epoch: 6| Step: 9
Training loss: 0.47579722636040966
Validation loss: 2.6144907428809914

Epoch: 6| Step: 10
Training loss: 0.6014313492922775
Validation loss: 2.63176507746564

Epoch: 6| Step: 11
Training loss: 0.5852341053892958
Validation loss: 2.597227072607496

Epoch: 6| Step: 12
Training loss: 0.5778641498891252
Validation loss: 2.639046536241319

Epoch: 6| Step: 13
Training loss: 0.336643608010993
Validation loss: 2.5880539835540546

Epoch: 354| Step: 0
Training loss: 0.8167716125930853
Validation loss: 2.573075536238994

Epoch: 6| Step: 1
Training loss: 0.28599909759925984
Validation loss: 2.609774516646196

Epoch: 6| Step: 2
Training loss: 0.4786939950261542
Validation loss: 2.597922793516326

Epoch: 6| Step: 3
Training loss: 0.48658601595010686
Validation loss: 2.578555719287738

Epoch: 6| Step: 4
Training loss: 0.23095675704326846
Validation loss: 2.5934878475165193

Epoch: 6| Step: 5
Training loss: 0.5071201299462195
Validation loss: 2.614567054103336

Epoch: 6| Step: 6
Training loss: 0.21678431362842948
Validation loss: 2.618297417834576

Epoch: 6| Step: 7
Training loss: 0.40336918938810457
Validation loss: 2.6363057981802074

Epoch: 6| Step: 8
Training loss: 0.5446645751348389
Validation loss: 2.619685074456997

Epoch: 6| Step: 9
Training loss: 0.18774127337941307
Validation loss: 2.610678335688745

Epoch: 6| Step: 10
Training loss: 0.5585924428644425
Validation loss: 2.6047213554710344

Epoch: 6| Step: 11
Training loss: 0.5780483143439626
Validation loss: 2.585879656432838

Epoch: 6| Step: 12
Training loss: 0.32917317366908583
Validation loss: 2.6093583853452222

Epoch: 6| Step: 13
Training loss: 0.8112795172848031
Validation loss: 2.5818866998742

Epoch: 355| Step: 0
Training loss: 0.23379907578621353
Validation loss: 2.6008902775110463

Epoch: 6| Step: 1
Training loss: 0.593278697834448
Validation loss: 2.665979607066951

Epoch: 6| Step: 2
Training loss: 0.3316337000614748
Validation loss: 2.616933232290396

Epoch: 6| Step: 3
Training loss: 0.45995622377349293
Validation loss: 2.6571642465903897

Epoch: 6| Step: 4
Training loss: 0.13590834074677433
Validation loss: 2.630010297726177

Epoch: 6| Step: 5
Training loss: 0.4377556122246343
Validation loss: 2.646897258471971

Epoch: 6| Step: 6
Training loss: 0.7681720173586569
Validation loss: 2.6286076153009708

Epoch: 6| Step: 7
Training loss: 0.36622064196126136
Validation loss: 2.6699147023477026

Epoch: 6| Step: 8
Training loss: 0.49501063537731965
Validation loss: 2.595351954900575

Epoch: 6| Step: 9
Training loss: 0.6257479960050967
Validation loss: 2.6045113156224673

Epoch: 6| Step: 10
Training loss: 0.45458064904835055
Validation loss: 2.6163233038406815

Epoch: 6| Step: 11
Training loss: 0.479100519949723
Validation loss: 2.541722418262567

Epoch: 6| Step: 12
Training loss: 0.3589897578752183
Validation loss: 2.5924272046543977

Epoch: 6| Step: 13
Training loss: 0.6961861811278728
Validation loss: 2.6232485194421638

Epoch: 356| Step: 0
Training loss: 0.4366444669545272
Validation loss: 2.5634638936578913

Epoch: 6| Step: 1
Training loss: 0.4357765344943872
Validation loss: 2.5772476468471113

Epoch: 6| Step: 2
Training loss: 0.43323765127806235
Validation loss: 2.593649528050928

Epoch: 6| Step: 3
Training loss: 0.6640071621445374
Validation loss: 2.550084368681144

Epoch: 6| Step: 4
Training loss: 0.685279772421024
Validation loss: 2.5837324706081635

Epoch: 6| Step: 5
Training loss: 0.34294398051083463
Validation loss: 2.544437501272556

Epoch: 6| Step: 6
Training loss: 0.4548784071503015
Validation loss: 2.5748091260075014

Epoch: 6| Step: 7
Training loss: 0.3229791314201054
Validation loss: 2.5944831929732146

Epoch: 6| Step: 8
Training loss: 0.34288335054111957
Validation loss: 2.5810242977484648

Epoch: 6| Step: 9
Training loss: 0.2725803291404434
Validation loss: 2.613071967856443

Epoch: 6| Step: 10
Training loss: 0.43498212182915863
Validation loss: 2.5810783218499136

Epoch: 6| Step: 11
Training loss: 0.5930478813435219
Validation loss: 2.593129680954589

Epoch: 6| Step: 12
Training loss: 0.5377483104854842
Validation loss: 2.6068481723631103

Epoch: 6| Step: 13
Training loss: 0.3593849512463941
Validation loss: 2.584154876319021

Epoch: 357| Step: 0
Training loss: 0.3411021774935439
Validation loss: 2.5798324564010593

Epoch: 6| Step: 1
Training loss: 0.6441927165290904
Validation loss: 2.5941965603590282

Epoch: 6| Step: 2
Training loss: 0.20707828059514802
Validation loss: 2.5872178872922986

Epoch: 6| Step: 3
Training loss: 0.4844992693569788
Validation loss: 2.6011679774958005

Epoch: 6| Step: 4
Training loss: 0.4738517019470924
Validation loss: 2.6421588040876256

Epoch: 6| Step: 5
Training loss: 0.3832461372835276
Validation loss: 2.6265155989479987

Epoch: 6| Step: 6
Training loss: 0.29883739980628216
Validation loss: 2.662876621461337

Epoch: 6| Step: 7
Training loss: 0.23891050081731385
Validation loss: 2.6474575122393755

Epoch: 6| Step: 8
Training loss: 0.6150306970021943
Validation loss: 2.6432524937032222

Epoch: 6| Step: 9
Training loss: 0.4197135408493048
Validation loss: 2.632543379260054

Epoch: 6| Step: 10
Training loss: 0.5519801409265784
Validation loss: 2.5877194157852186

Epoch: 6| Step: 11
Training loss: 0.5538169853477399
Validation loss: 2.5947228337114447

Epoch: 6| Step: 12
Training loss: 0.5266516771275881
Validation loss: 2.589224853075155

Epoch: 6| Step: 13
Training loss: 0.663360314211856
Validation loss: 2.5964086146343726

Epoch: 358| Step: 0
Training loss: 0.4116192474866846
Validation loss: 2.599682456598944

Epoch: 6| Step: 1
Training loss: 0.23852168912953675
Validation loss: 2.5772735283454806

Epoch: 6| Step: 2
Training loss: 0.8188820128265036
Validation loss: 2.6274074996031715

Epoch: 6| Step: 3
Training loss: 0.2190426333693149
Validation loss: 2.6085327363014406

Epoch: 6| Step: 4
Training loss: 0.6601150319250294
Validation loss: 2.6341117262068865

Epoch: 6| Step: 5
Training loss: 0.47322327516608126
Validation loss: 2.61027057485963

Epoch: 6| Step: 6
Training loss: 0.5872800831387072
Validation loss: 2.616688993850029

Epoch: 6| Step: 7
Training loss: 0.32344090556687616
Validation loss: 2.6325423674540747

Epoch: 6| Step: 8
Training loss: 0.5001580167463299
Validation loss: 2.606211861758542

Epoch: 6| Step: 9
Training loss: 0.3355239385153048
Validation loss: 2.603101836689183

Epoch: 6| Step: 10
Training loss: 0.44270717022312933
Validation loss: 2.603668197342373

Epoch: 6| Step: 11
Training loss: 0.3532417247920627
Validation loss: 2.6199374781662472

Epoch: 6| Step: 12
Training loss: 0.2866405629916682
Validation loss: 2.630322589339984

Epoch: 6| Step: 13
Training loss: 0.49164687846929
Validation loss: 2.618459915242147

Epoch: 359| Step: 0
Training loss: 0.4996308066369727
Validation loss: 2.611535453991916

Epoch: 6| Step: 1
Training loss: 0.6656424632042702
Validation loss: 2.6069459515307143

Epoch: 6| Step: 2
Training loss: 0.21831307884323042
Validation loss: 2.59397141002948

Epoch: 6| Step: 3
Training loss: 0.369678892033792
Validation loss: 2.6156251145178553

Epoch: 6| Step: 4
Training loss: 0.28635793429260126
Validation loss: 2.583059178934586

Epoch: 6| Step: 5
Training loss: 0.5549407166100909
Validation loss: 2.577880272509786

Epoch: 6| Step: 6
Training loss: 0.45040996010428147
Validation loss: 2.568054366766232

Epoch: 6| Step: 7
Training loss: 0.5302811651913757
Validation loss: 2.5872819849981723

Epoch: 6| Step: 8
Training loss: 0.23504441348871888
Validation loss: 2.602041371712594

Epoch: 6| Step: 9
Training loss: 0.33151786608041195
Validation loss: 2.5758165661503076

Epoch: 6| Step: 10
Training loss: 0.5664113011628219
Validation loss: 2.5962819011313223

Epoch: 6| Step: 11
Training loss: 0.42914165158498835
Validation loss: 2.615587522517776

Epoch: 6| Step: 12
Training loss: 0.7008638263136237
Validation loss: 2.584407020264639

Epoch: 6| Step: 13
Training loss: 0.27019463323265375
Validation loss: 2.599779301246047

Epoch: 360| Step: 0
Training loss: 0.5053582378724129
Validation loss: 2.623338901355266

Epoch: 6| Step: 1
Training loss: 0.3710281514864367
Validation loss: 2.6336794592116775

Epoch: 6| Step: 2
Training loss: 0.4718755153627929
Validation loss: 2.6553408066245647

Epoch: 6| Step: 3
Training loss: 0.6558054826325203
Validation loss: 2.6554278839330037

Epoch: 6| Step: 4
Training loss: 0.5017044401311082
Validation loss: 2.648703931471833

Epoch: 6| Step: 5
Training loss: 0.16085106463686216
Validation loss: 2.6126133340678166

Epoch: 6| Step: 6
Training loss: 0.17178546133807338
Validation loss: 2.60699458062124

Epoch: 6| Step: 7
Training loss: 0.31511517839132935
Validation loss: 2.5921388295373826

Epoch: 6| Step: 8
Training loss: 0.6491881931426466
Validation loss: 2.597325229764517

Epoch: 6| Step: 9
Training loss: 0.42931797437388836
Validation loss: 2.5748864868182033

Epoch: 6| Step: 10
Training loss: 0.5597288962198474
Validation loss: 2.6036788549175105

Epoch: 6| Step: 11
Training loss: 0.49995919895592605
Validation loss: 2.567287499857212

Epoch: 6| Step: 12
Training loss: 0.455265448658492
Validation loss: 2.61082885454872

Epoch: 6| Step: 13
Training loss: 0.41750183050816525
Validation loss: 2.6561539923963084

Epoch: 361| Step: 0
Training loss: 0.4676664703965313
Validation loss: 2.642778658496343

Epoch: 6| Step: 1
Training loss: 0.15431685861517117
Validation loss: 2.6248135458985566

Epoch: 6| Step: 2
Training loss: 0.5783930492169462
Validation loss: 2.6073738447983303

Epoch: 6| Step: 3
Training loss: 0.19457948462037974
Validation loss: 2.635193482915913

Epoch: 6| Step: 4
Training loss: 0.5441323032550663
Validation loss: 2.636975996137928

Epoch: 6| Step: 5
Training loss: 0.6283523300024492
Validation loss: 2.6169370940105976

Epoch: 6| Step: 6
Training loss: 0.35536259334133197
Validation loss: 2.5788864393491937

Epoch: 6| Step: 7
Training loss: 0.651662505088585
Validation loss: 2.603925376952711

Epoch: 6| Step: 8
Training loss: 0.2625774133156754
Validation loss: 2.604257707214494

Epoch: 6| Step: 9
Training loss: 0.3319393030648093
Validation loss: 2.585565066132725

Epoch: 6| Step: 10
Training loss: 0.3208996810471069
Validation loss: 2.568870994241883

Epoch: 6| Step: 11
Training loss: 0.34252005229500726
Validation loss: 2.6051821884942212

Epoch: 6| Step: 12
Training loss: 0.6710121025182196
Validation loss: 2.5949088368172077

Epoch: 6| Step: 13
Training loss: 0.47660020772871003
Validation loss: 2.6164271742063665

Epoch: 362| Step: 0
Training loss: 0.3310611577934897
Validation loss: 2.584765906044116

Epoch: 6| Step: 1
Training loss: 0.4231380875055231
Validation loss: 2.6061555748284326

Epoch: 6| Step: 2
Training loss: 0.6067122702654115
Validation loss: 2.596076658148688

Epoch: 6| Step: 3
Training loss: 0.2001571153626507
Validation loss: 2.605858735373466

Epoch: 6| Step: 4
Training loss: 0.22412371997499642
Validation loss: 2.5757866968396543

Epoch: 6| Step: 5
Training loss: 0.37944472286542436
Validation loss: 2.56889928636397

Epoch: 6| Step: 6
Training loss: 0.3901299582266837
Validation loss: 2.581504606850568

Epoch: 6| Step: 7
Training loss: 0.5305324083652536
Validation loss: 2.553115067278355

Epoch: 6| Step: 8
Training loss: 0.5023145747277773
Validation loss: 2.5866118963390345

Epoch: 6| Step: 9
Training loss: 0.5988365934187477
Validation loss: 2.561792941905917

Epoch: 6| Step: 10
Training loss: 0.5669426318518715
Validation loss: 2.554365385325744

Epoch: 6| Step: 11
Training loss: 0.43264267547131435
Validation loss: 2.569666982686528

Epoch: 6| Step: 12
Training loss: 0.3935629794096817
Validation loss: 2.5833148088958726

Epoch: 6| Step: 13
Training loss: 0.3563995122878915
Validation loss: 2.5738584413883667

Epoch: 363| Step: 0
Training loss: 0.3187356375282125
Validation loss: 2.5668252617343637

Epoch: 6| Step: 1
Training loss: 0.4649239158425324
Validation loss: 2.567971753168086

Epoch: 6| Step: 2
Training loss: 0.44533814808116334
Validation loss: 2.6073052598728537

Epoch: 6| Step: 3
Training loss: 0.5758305977490925
Validation loss: 2.5747762898478146

Epoch: 6| Step: 4
Training loss: 0.42638798451957655
Validation loss: 2.5535173001755007

Epoch: 6| Step: 5
Training loss: 0.3292394513328169
Validation loss: 2.5680448047110587

Epoch: 6| Step: 6
Training loss: 0.6949442627738387
Validation loss: 2.586973942196514

Epoch: 6| Step: 7
Training loss: 0.33649037575668533
Validation loss: 2.5479463958099204

Epoch: 6| Step: 8
Training loss: 0.25828084886800146
Validation loss: 2.5822463985753314

Epoch: 6| Step: 9
Training loss: 0.518695589452245
Validation loss: 2.5758486933618188

Epoch: 6| Step: 10
Training loss: 0.5136603002368227
Validation loss: 2.591507141742575

Epoch: 6| Step: 11
Training loss: 0.37526117607567544
Validation loss: 2.6048829612470503

Epoch: 6| Step: 12
Training loss: 0.36974652332685776
Validation loss: 2.598913539374112

Epoch: 6| Step: 13
Training loss: 0.2997556515829805
Validation loss: 2.5923308438580683

Epoch: 364| Step: 0
Training loss: 0.4551507785414564
Validation loss: 2.6035007926600207

Epoch: 6| Step: 1
Training loss: 0.6361969992440649
Validation loss: 2.5642571526187767

Epoch: 6| Step: 2
Training loss: 0.4164084786933388
Validation loss: 2.578586846005683

Epoch: 6| Step: 3
Training loss: 0.4897146775884081
Validation loss: 2.5665791906012476

Epoch: 6| Step: 4
Training loss: 0.12644081918524225
Validation loss: 2.5689146767483493

Epoch: 6| Step: 5
Training loss: 0.4356121647228674
Validation loss: 2.518844422608451

Epoch: 6| Step: 6
Training loss: 0.3970370269799475
Validation loss: 2.547018680109431

Epoch: 6| Step: 7
Training loss: 0.399680908900385
Validation loss: 2.6122070755507525

Epoch: 6| Step: 8
Training loss: 0.46976643668668766
Validation loss: 2.555741859378654

Epoch: 6| Step: 9
Training loss: 0.47078431881456084
Validation loss: 2.5755524579197338

Epoch: 6| Step: 10
Training loss: 0.5517865738925949
Validation loss: 2.574094241723551

Epoch: 6| Step: 11
Training loss: 0.3530924988871424
Validation loss: 2.5935923175939735

Epoch: 6| Step: 12
Training loss: 0.37924523281931016
Validation loss: 2.5911504095643823

Epoch: 6| Step: 13
Training loss: 0.422944514605817
Validation loss: 2.600590614592913

Epoch: 365| Step: 0
Training loss: 0.3935392390927345
Validation loss: 2.570610890075749

Epoch: 6| Step: 1
Training loss: 0.40931784907929164
Validation loss: 2.574136722151657

Epoch: 6| Step: 2
Training loss: 0.5352422269268333
Validation loss: 2.5590829944625804

Epoch: 6| Step: 3
Training loss: 0.5220526980915392
Validation loss: 2.5834506428652926

Epoch: 6| Step: 4
Training loss: 0.3784847077615199
Validation loss: 2.5768458002302186

Epoch: 6| Step: 5
Training loss: 0.45439369895165255
Validation loss: 2.5612604948627444

Epoch: 6| Step: 6
Training loss: 0.5438926575410754
Validation loss: 2.548329392853736

Epoch: 6| Step: 7
Training loss: 0.5082527599681966
Validation loss: 2.6103280645379616

Epoch: 6| Step: 8
Training loss: 0.4204096245845397
Validation loss: 2.570276936307691

Epoch: 6| Step: 9
Training loss: 0.30929191899502384
Validation loss: 2.591515179361892

Epoch: 6| Step: 10
Training loss: 0.3176854612632895
Validation loss: 2.6160308089088935

Epoch: 6| Step: 11
Training loss: 0.5888878358475649
Validation loss: 2.604082759038641

Epoch: 6| Step: 12
Training loss: 0.2760887090916872
Validation loss: 2.6189469779315857

Epoch: 6| Step: 13
Training loss: 0.08344839083034047
Validation loss: 2.592290670135356

Epoch: 366| Step: 0
Training loss: 0.5421738053936677
Validation loss: 2.609586082676148

Epoch: 6| Step: 1
Training loss: 0.49542121656791993
Validation loss: 2.6216831024261578

Epoch: 6| Step: 2
Training loss: 0.5112523873047248
Validation loss: 2.6390249957346748

Epoch: 6| Step: 3
Training loss: 0.1360777474005131
Validation loss: 2.6023552656826308

Epoch: 6| Step: 4
Training loss: 0.39550988467580234
Validation loss: 2.6365031186329695

Epoch: 6| Step: 5
Training loss: 0.42675138769834814
Validation loss: 2.6175177527262266

Epoch: 6| Step: 6
Training loss: 0.44346871057187226
Validation loss: 2.6091271996863092

Epoch: 6| Step: 7
Training loss: 0.5061374032820068
Validation loss: 2.6563014807830596

Epoch: 6| Step: 8
Training loss: 0.2239944249650393
Validation loss: 2.621231708533502

Epoch: 6| Step: 9
Training loss: 0.5374620146968995
Validation loss: 2.6489757954303936

Epoch: 6| Step: 10
Training loss: 0.2903816434812118
Validation loss: 2.6374090311886245

Epoch: 6| Step: 11
Training loss: 0.579165193043579
Validation loss: 2.591168676481671

Epoch: 6| Step: 12
Training loss: 0.2750040682578439
Validation loss: 2.600643812297742

Epoch: 6| Step: 13
Training loss: 0.47036332017446436
Validation loss: 2.613401658659956

Epoch: 367| Step: 0
Training loss: 0.5065659996726066
Validation loss: 2.5773681842382152

Epoch: 6| Step: 1
Training loss: 0.3785201396220181
Validation loss: 2.5933689406335345

Epoch: 6| Step: 2
Training loss: 0.3476468202833692
Validation loss: 2.6163339564088823

Epoch: 6| Step: 3
Training loss: 0.6292075625974579
Validation loss: 2.6277422851847736

Epoch: 6| Step: 4
Training loss: 0.38073051424566423
Validation loss: 2.6345963857444

Epoch: 6| Step: 5
Training loss: 0.2768018828780709
Validation loss: 2.6047474629817486

Epoch: 6| Step: 6
Training loss: 0.4130658805432934
Validation loss: 2.5816346593196564

Epoch: 6| Step: 7
Training loss: 0.5009422364846879
Validation loss: 2.573961818278692

Epoch: 6| Step: 8
Training loss: 0.2431974120040413
Validation loss: 2.5552624775455253

Epoch: 6| Step: 9
Training loss: 0.4758005460888333
Validation loss: 2.5609349639647174

Epoch: 6| Step: 10
Training loss: 0.36028386335560847
Validation loss: 2.570538873868313

Epoch: 6| Step: 11
Training loss: 0.39118233022398813
Validation loss: 2.550501527634265

Epoch: 6| Step: 12
Training loss: 0.2031594944055109
Validation loss: 2.571523133481193

Epoch: 6| Step: 13
Training loss: 0.7138624282448656
Validation loss: 2.511833277998415

Epoch: 368| Step: 0
Training loss: 0.33438988099898437
Validation loss: 2.484287242096588

Epoch: 6| Step: 1
Training loss: 0.5368979297932674
Validation loss: 2.473362689416052

Epoch: 6| Step: 2
Training loss: 0.6610223404561589
Validation loss: 2.50207368616383

Epoch: 6| Step: 3
Training loss: 0.497099150475018
Validation loss: 2.502015786012573

Epoch: 6| Step: 4
Training loss: 0.5654409667687066
Validation loss: 2.497743535762791

Epoch: 6| Step: 5
Training loss: 0.5387017245248596
Validation loss: 2.502701065178125

Epoch: 6| Step: 6
Training loss: 0.4610293830198212
Validation loss: 2.553002165249135

Epoch: 6| Step: 7
Training loss: 0.2683761002882713
Validation loss: 2.541066356218501

Epoch: 6| Step: 8
Training loss: 0.2228422224810646
Validation loss: 2.5637280462601426

Epoch: 6| Step: 9
Training loss: 0.2912081139451295
Validation loss: 2.577756157397667

Epoch: 6| Step: 10
Training loss: 0.2772526792984983
Validation loss: 2.6063781962501937

Epoch: 6| Step: 11
Training loss: 0.2676441779367674
Validation loss: 2.5874098823654794

Epoch: 6| Step: 12
Training loss: 0.435212901073034
Validation loss: 2.5781849833968686

Epoch: 6| Step: 13
Training loss: 0.32472756686560655
Validation loss: 2.5707237387689283

Epoch: 369| Step: 0
Training loss: 0.32288926787683064
Validation loss: 2.515496154555039

Epoch: 6| Step: 1
Training loss: 0.35938350004012354
Validation loss: 2.5586676033268305

Epoch: 6| Step: 2
Training loss: 0.5219531577512391
Validation loss: 2.560485834610748

Epoch: 6| Step: 3
Training loss: 0.4502670661195522
Validation loss: 2.5709402833307227

Epoch: 6| Step: 4
Training loss: 0.4609015984212232
Validation loss: 2.5489428724334684

Epoch: 6| Step: 5
Training loss: 0.4693663359857028
Validation loss: 2.547328857954648

Epoch: 6| Step: 6
Training loss: 0.6121835786578006
Validation loss: 2.515116088340972

Epoch: 6| Step: 7
Training loss: 0.5379264581361894
Validation loss: 2.5665811473575824

Epoch: 6| Step: 8
Training loss: 0.1999151828595388
Validation loss: 2.5563503650143926

Epoch: 6| Step: 9
Training loss: 0.354602975058514
Validation loss: 2.5627343535588203

Epoch: 6| Step: 10
Training loss: 0.492129912867597
Validation loss: 2.5623772129281144

Epoch: 6| Step: 11
Training loss: 0.17382353873042594
Validation loss: 2.5631265982153573

Epoch: 6| Step: 12
Training loss: 0.3424875964055827
Validation loss: 2.562107317210058

Epoch: 6| Step: 13
Training loss: 0.43062620796731793
Validation loss: 2.5679900731521097

Epoch: 370| Step: 0
Training loss: 0.5631311901908139
Validation loss: 2.5840702868083527

Epoch: 6| Step: 1
Training loss: 0.49228580946255607
Validation loss: 2.576894662080012

Epoch: 6| Step: 2
Training loss: 0.542056188155392
Validation loss: 2.550058368060699

Epoch: 6| Step: 3
Training loss: 0.5704171594190827
Validation loss: 2.572414491837319

Epoch: 6| Step: 4
Training loss: 0.2187000796713856
Validation loss: 2.577747016710411

Epoch: 6| Step: 5
Training loss: 0.5543587476031734
Validation loss: 2.5113030367781453

Epoch: 6| Step: 6
Training loss: 0.2854971741972403
Validation loss: 2.5525049949075576

Epoch: 6| Step: 7
Training loss: 0.31862680635056223
Validation loss: 2.5612437842938203

Epoch: 6| Step: 8
Training loss: 0.24813852344192538
Validation loss: 2.53148557963611

Epoch: 6| Step: 9
Training loss: 0.3827338624488652
Validation loss: 2.6055037182233405

Epoch: 6| Step: 10
Training loss: 0.23649783385698164
Validation loss: 2.5905223145498377

Epoch: 6| Step: 11
Training loss: 0.4295886706357679
Validation loss: 2.6475055882197993

Epoch: 6| Step: 12
Training loss: 0.3546927439096132
Validation loss: 2.5918501374696894

Epoch: 6| Step: 13
Training loss: 0.6189161068064722
Validation loss: 2.6698838030710474

Epoch: 371| Step: 0
Training loss: 0.46282583499528784
Validation loss: 2.6439808884940934

Epoch: 6| Step: 1
Training loss: 0.3280543296641042
Validation loss: 2.668962030723975

Epoch: 6| Step: 2
Training loss: 0.2912468343775541
Validation loss: 2.6608307767643877

Epoch: 6| Step: 3
Training loss: 0.4884133427284505
Validation loss: 2.6669574054792333

Epoch: 6| Step: 4
Training loss: 0.660383557794371
Validation loss: 2.6479591389910606

Epoch: 6| Step: 5
Training loss: 0.3005395760578289
Validation loss: 2.6341037952073085

Epoch: 6| Step: 6
Training loss: 0.44922450518031265
Validation loss: 2.5890109567607733

Epoch: 6| Step: 7
Training loss: 0.3673769685238863
Validation loss: 2.542774502831227

Epoch: 6| Step: 8
Training loss: 0.44422314228753784
Validation loss: 2.5189164715556087

Epoch: 6| Step: 9
Training loss: 0.5148815228002042
Validation loss: 2.5282705301448294

Epoch: 6| Step: 10
Training loss: 0.32307056123370037
Validation loss: 2.552553914431689

Epoch: 6| Step: 11
Training loss: 0.4487330091070384
Validation loss: 2.5407060946016213

Epoch: 6| Step: 12
Training loss: 0.2803809195789441
Validation loss: 2.5688771456842843

Epoch: 6| Step: 13
Training loss: 0.41174379739449696
Validation loss: 2.563772032383027

Epoch: 372| Step: 0
Training loss: 0.5039954882715009
Validation loss: 2.585580160995979

Epoch: 6| Step: 1
Training loss: 0.3085514474194715
Validation loss: 2.5914271539536515

Epoch: 6| Step: 2
Training loss: 0.26273514399556336
Validation loss: 2.635751823473302

Epoch: 6| Step: 3
Training loss: 0.6323980222071509
Validation loss: 2.643932482985601

Epoch: 6| Step: 4
Training loss: 0.4231826507984624
Validation loss: 2.6038353480749

Epoch: 6| Step: 5
Training loss: 0.41698362891104407
Validation loss: 2.6228975000552452

Epoch: 6| Step: 6
Training loss: 0.562356798169538
Validation loss: 2.596689900854518

Epoch: 6| Step: 7
Training loss: 0.3071055683918037
Validation loss: 2.571865918593219

Epoch: 6| Step: 8
Training loss: 0.2501760399428659
Validation loss: 2.52053718552799

Epoch: 6| Step: 9
Training loss: 0.313854370140333
Validation loss: 2.535493480761019

Epoch: 6| Step: 10
Training loss: 0.4912011845191146
Validation loss: 2.5001117906904886

Epoch: 6| Step: 11
Training loss: 0.39662239416007594
Validation loss: 2.5505554996823427

Epoch: 6| Step: 12
Training loss: 0.5419682677893216
Validation loss: 2.5637330410849715

Epoch: 6| Step: 13
Training loss: 0.323140903520554
Validation loss: 2.6122498302356125

Epoch: 373| Step: 0
Training loss: 0.517785142487816
Validation loss: 2.6373029368430534

Epoch: 6| Step: 1
Training loss: 0.4935091227854465
Validation loss: 2.6593691440334304

Epoch: 6| Step: 2
Training loss: 0.4275829099265092
Validation loss: 2.627254732658944

Epoch: 6| Step: 3
Training loss: 0.45286259781451743
Validation loss: 2.6105078805346245

Epoch: 6| Step: 4
Training loss: 0.34381576472529984
Validation loss: 2.544194489709269

Epoch: 6| Step: 5
Training loss: 0.5427767736683129
Validation loss: 2.5357742470226534

Epoch: 6| Step: 6
Training loss: 0.4528217287353908
Validation loss: 2.563174193316871

Epoch: 6| Step: 7
Training loss: 0.4685755087013579
Validation loss: 2.5466436405211463

Epoch: 6| Step: 8
Training loss: 0.4939550119023156
Validation loss: 2.557168714555297

Epoch: 6| Step: 9
Training loss: 0.519019398194454
Validation loss: 2.584098657564821

Epoch: 6| Step: 10
Training loss: 0.2805840767840272
Validation loss: 2.5541327546132497

Epoch: 6| Step: 11
Training loss: 0.38725953870542235
Validation loss: 2.5639179357530253

Epoch: 6| Step: 12
Training loss: 0.5188222363744823
Validation loss: 2.586378262150233

Epoch: 6| Step: 13
Training loss: 0.16862521966767194
Validation loss: 2.59867601248184

Epoch: 374| Step: 0
Training loss: 0.6336925650609685
Validation loss: 2.597321939987961

Epoch: 6| Step: 1
Training loss: 0.4693276978085758
Validation loss: 2.6664982112493343

Epoch: 6| Step: 2
Training loss: 0.26857122196969313
Validation loss: 2.638618891154837

Epoch: 6| Step: 3
Training loss: 0.35137970728725276
Validation loss: 2.657444727099254

Epoch: 6| Step: 4
Training loss: 0.30211244503145274
Validation loss: 2.6429775782475744

Epoch: 6| Step: 5
Training loss: 0.45257027970712815
Validation loss: 2.5839215031478795

Epoch: 6| Step: 6
Training loss: 0.2412532892768842
Validation loss: 2.574617579324022

Epoch: 6| Step: 7
Training loss: 0.5210834919664752
Validation loss: 2.5640076824745237

Epoch: 6| Step: 8
Training loss: 0.46997263722207544
Validation loss: 2.579906585136093

Epoch: 6| Step: 9
Training loss: 0.2743679021382136
Validation loss: 2.5614516752303027

Epoch: 6| Step: 10
Training loss: 0.5090579678665658
Validation loss: 2.5870229001320584

Epoch: 6| Step: 11
Training loss: 0.38797678686782916
Validation loss: 2.566201075129027

Epoch: 6| Step: 12
Training loss: 0.5389430425111849
Validation loss: 2.560706841053693

Epoch: 6| Step: 13
Training loss: 0.5312508975750689
Validation loss: 2.624080347438057

Epoch: 375| Step: 0
Training loss: 0.5283317353147212
Validation loss: 2.6308585506152617

Epoch: 6| Step: 1
Training loss: 0.3915849334915198
Validation loss: 2.6826049150264986

Epoch: 6| Step: 2
Training loss: 0.5409066541527983
Validation loss: 2.6360790550773388

Epoch: 6| Step: 3
Training loss: 0.2898753824992286
Validation loss: 2.675460274258413

Epoch: 6| Step: 4
Training loss: 0.48900861351836516
Validation loss: 2.6608731572289357

Epoch: 6| Step: 5
Training loss: 0.47932838392333077
Validation loss: 2.6711587392591785

Epoch: 6| Step: 6
Training loss: 0.16532579602889622
Validation loss: 2.608299302352842

Epoch: 6| Step: 7
Training loss: 0.30388853271539246
Validation loss: 2.6034544000644977

Epoch: 6| Step: 8
Training loss: 0.3072718543869546
Validation loss: 2.599221012934082

Epoch: 6| Step: 9
Training loss: 0.49939031980884807
Validation loss: 2.58894174179215

Epoch: 6| Step: 10
Training loss: 0.30779452586099365
Validation loss: 2.594488011004091

Epoch: 6| Step: 11
Training loss: 0.3582114581654059
Validation loss: 2.5969738022101643

Epoch: 6| Step: 12
Training loss: 0.7036735514149348
Validation loss: 2.5512150583066364

Epoch: 6| Step: 13
Training loss: 0.33004931036324203
Validation loss: 2.6088237684957334

Epoch: 376| Step: 0
Training loss: 0.3298146025457081
Validation loss: 2.611020927912545

Epoch: 6| Step: 1
Training loss: 0.4118443219766828
Validation loss: 2.647357237943461

Epoch: 6| Step: 2
Training loss: 0.39905742961676516
Validation loss: 2.653457957783407

Epoch: 6| Step: 3
Training loss: 0.5481692122545961
Validation loss: 2.623228619073638

Epoch: 6| Step: 4
Training loss: 0.4880943093072271
Validation loss: 2.6308568726114854

Epoch: 6| Step: 5
Training loss: 0.18698301169675532
Validation loss: 2.6117846257697654

Epoch: 6| Step: 6
Training loss: 0.5509682736860182
Validation loss: 2.606873235821673

Epoch: 6| Step: 7
Training loss: 0.441534411973935
Validation loss: 2.5942601634870353

Epoch: 6| Step: 8
Training loss: 0.47456365922444393
Validation loss: 2.6215459617116834

Epoch: 6| Step: 9
Training loss: 0.5106614233167766
Validation loss: 2.5898847892074808

Epoch: 6| Step: 10
Training loss: 0.295546583719536
Validation loss: 2.648137456888578

Epoch: 6| Step: 11
Training loss: 0.42374841318424156
Validation loss: 2.6205057422615963

Epoch: 6| Step: 12
Training loss: 0.31426977652849475
Validation loss: 2.6227029270972353

Epoch: 6| Step: 13
Training loss: 0.27422084318486967
Validation loss: 2.6119588627583963

Epoch: 377| Step: 0
Training loss: 0.25620924346405666
Validation loss: 2.6340809743503146

Epoch: 6| Step: 1
Training loss: 0.3402794752219198
Validation loss: 2.5832580945123085

Epoch: 6| Step: 2
Training loss: 0.3571939001903354
Validation loss: 2.6056405245875145

Epoch: 6| Step: 3
Training loss: 0.4832619522538797
Validation loss: 2.590747228790591

Epoch: 6| Step: 4
Training loss: 0.37946439710984076
Validation loss: 2.6029306923401343

Epoch: 6| Step: 5
Training loss: 0.37551766666271136
Validation loss: 2.579164695974235

Epoch: 6| Step: 6
Training loss: 0.4227143520956393
Validation loss: 2.5810398631545297

Epoch: 6| Step: 7
Training loss: 0.23692113389345398
Validation loss: 2.5889764638774797

Epoch: 6| Step: 8
Training loss: 0.3907780156846332
Validation loss: 2.597988815786625

Epoch: 6| Step: 9
Training loss: 0.5284771078415538
Validation loss: 2.5899101781732887

Epoch: 6| Step: 10
Training loss: 0.5905261103278265
Validation loss: 2.5922167818115085

Epoch: 6| Step: 11
Training loss: 0.4296659637602765
Validation loss: 2.570605544603921

Epoch: 6| Step: 12
Training loss: 0.519520092607739
Validation loss: 2.56302358749105

Epoch: 6| Step: 13
Training loss: 0.3006487467818514
Validation loss: 2.5495070991459508

Epoch: 378| Step: 0
Training loss: 0.3737594828471148
Validation loss: 2.4951505680089694

Epoch: 6| Step: 1
Training loss: 0.5194802223328957
Validation loss: 2.543885116332607

Epoch: 6| Step: 2
Training loss: 0.38583195281691507
Validation loss: 2.5130790903049585

Epoch: 6| Step: 3
Training loss: 0.6207753450932331
Validation loss: 2.5128276121793567

Epoch: 6| Step: 4
Training loss: 0.41928222198498766
Validation loss: 2.498385033890336

Epoch: 6| Step: 5
Training loss: 0.2380007202504183
Validation loss: 2.5463629884294177

Epoch: 6| Step: 6
Training loss: 0.21472029173176344
Validation loss: 2.5145394330642294

Epoch: 6| Step: 7
Training loss: 0.46130007691679387
Validation loss: 2.5020472706475805

Epoch: 6| Step: 8
Training loss: 0.36564081190430586
Validation loss: 2.5440901511400504

Epoch: 6| Step: 9
Training loss: 0.33211593669905193
Validation loss: 2.5370023653174414

Epoch: 6| Step: 10
Training loss: 0.5098737404712589
Validation loss: 2.566728456161223

Epoch: 6| Step: 11
Training loss: 0.43421350468408054
Validation loss: 2.5656694239890845

Epoch: 6| Step: 12
Training loss: 0.31340203037934056
Validation loss: 2.576555166792071

Epoch: 6| Step: 13
Training loss: 0.2686699221208107
Validation loss: 2.565174564844513

Epoch: 379| Step: 0
Training loss: 0.24169091104428939
Validation loss: 2.5592837074330292

Epoch: 6| Step: 1
Training loss: 0.4418461051245201
Validation loss: 2.5398906841950484

Epoch: 6| Step: 2
Training loss: 0.5074107414827281
Validation loss: 2.5284959868176795

Epoch: 6| Step: 3
Training loss: 0.5841334226112469
Validation loss: 2.5517389500003564

Epoch: 6| Step: 4
Training loss: 0.23276761729643886
Validation loss: 2.5059566137969984

Epoch: 6| Step: 5
Training loss: 0.3821343234131781
Validation loss: 2.5157405373500628

Epoch: 6| Step: 6
Training loss: 0.31372217556500276
Validation loss: 2.520797079041371

Epoch: 6| Step: 7
Training loss: 0.40280683958872265
Validation loss: 2.501113879823577

Epoch: 6| Step: 8
Training loss: 0.29326065779731286
Validation loss: 2.506482029745987

Epoch: 6| Step: 9
Training loss: 0.25142408614726985
Validation loss: 2.5594525142639366

Epoch: 6| Step: 10
Training loss: 0.433174016058806
Validation loss: 2.5263684315878194

Epoch: 6| Step: 11
Training loss: 0.2314844943331753
Validation loss: 2.5909468686301618

Epoch: 6| Step: 12
Training loss: 0.6164797334178435
Validation loss: 2.572683295784798

Epoch: 6| Step: 13
Training loss: 0.28490745455642164
Validation loss: 2.588248058051901

Epoch: 380| Step: 0
Training loss: 0.42857920158523877
Validation loss: 2.5841367989106256

Epoch: 6| Step: 1
Training loss: 0.3144476990794371
Validation loss: 2.581652740346366

Epoch: 6| Step: 2
Training loss: 0.29550774593818957
Validation loss: 2.537514453173715

Epoch: 6| Step: 3
Training loss: 0.3549701421565796
Validation loss: 2.5881392630259437

Epoch: 6| Step: 4
Training loss: 0.20164556196480707
Validation loss: 2.503172778748881

Epoch: 6| Step: 5
Training loss: 0.5180358014787873
Validation loss: 2.5395180368504056

Epoch: 6| Step: 6
Training loss: 0.2689560820861807
Validation loss: 2.523049032095446

Epoch: 6| Step: 7
Training loss: 0.3306188048808109
Validation loss: 2.5530229303349734

Epoch: 6| Step: 8
Training loss: 0.5477162022229124
Validation loss: 2.560998343071717

Epoch: 6| Step: 9
Training loss: 0.5739312263037044
Validation loss: 2.547196533594199

Epoch: 6| Step: 10
Training loss: 0.3072899909970561
Validation loss: 2.5554350547312006

Epoch: 6| Step: 11
Training loss: 0.4616056384393864
Validation loss: 2.5684711099013184

Epoch: 6| Step: 12
Training loss: 0.45659163108596673
Validation loss: 2.5390935646346544

Epoch: 6| Step: 13
Training loss: 0.15908041590835875
Validation loss: 2.5508825104289654

Epoch: 381| Step: 0
Training loss: 0.3971297925540439
Validation loss: 2.5716801628493577

Epoch: 6| Step: 1
Training loss: 0.14934107924023118
Validation loss: 2.533411279924553

Epoch: 6| Step: 2
Training loss: 0.3994098653782669
Validation loss: 2.5501830053641985

Epoch: 6| Step: 3
Training loss: 0.2646955610036366
Validation loss: 2.557225502287193

Epoch: 6| Step: 4
Training loss: 0.4732546683069626
Validation loss: 2.568650760105407

Epoch: 6| Step: 5
Training loss: 0.42093408703570895
Validation loss: 2.539087673217075

Epoch: 6| Step: 6
Training loss: 0.4019687905331211
Validation loss: 2.5537486251979864

Epoch: 6| Step: 7
Training loss: 0.31401476900635383
Validation loss: 2.588900199445682

Epoch: 6| Step: 8
Training loss: 0.3218429567997862
Validation loss: 2.603079377300126

Epoch: 6| Step: 9
Training loss: 0.33009172445418095
Validation loss: 2.5478260341476546

Epoch: 6| Step: 10
Training loss: 0.34932321952934475
Validation loss: 2.5715829767808525

Epoch: 6| Step: 11
Training loss: 0.41823562230709327
Validation loss: 2.5828177870162614

Epoch: 6| Step: 12
Training loss: 0.48464856574907816
Validation loss: 2.5924208757129077

Epoch: 6| Step: 13
Training loss: 0.5430498405664237
Validation loss: 2.556562559654303

Epoch: 382| Step: 0
Training loss: 0.38145445281922574
Validation loss: 2.5667080906099664

Epoch: 6| Step: 1
Training loss: 0.4325646913249986
Validation loss: 2.576231204308028

Epoch: 6| Step: 2
Training loss: 0.2394893304607437
Validation loss: 2.572816156705301

Epoch: 6| Step: 3
Training loss: 0.32566335864023616
Validation loss: 2.519672202316864

Epoch: 6| Step: 4
Training loss: 0.30336855021514003
Validation loss: 2.5291949003707828

Epoch: 6| Step: 5
Training loss: 0.35394410779289304
Validation loss: 2.4761910170763333

Epoch: 6| Step: 6
Training loss: 0.3461906207120132
Validation loss: 2.466550310971904

Epoch: 6| Step: 7
Training loss: 0.49327409479886525
Validation loss: 2.4996423424457372

Epoch: 6| Step: 8
Training loss: 0.3939538072493836
Validation loss: 2.467074848106304

Epoch: 6| Step: 9
Training loss: 0.42322963877313663
Validation loss: 2.485067466981537

Epoch: 6| Step: 10
Training loss: 0.5406518256968467
Validation loss: 2.5123840414450203

Epoch: 6| Step: 11
Training loss: 0.3446594691702532
Validation loss: 2.5294972449213526

Epoch: 6| Step: 12
Training loss: 0.39235432256979325
Validation loss: 2.560013491834702

Epoch: 6| Step: 13
Training loss: 0.4754653871876779
Validation loss: 2.5858855998679506

Epoch: 383| Step: 0
Training loss: 0.5353243208881108
Validation loss: 2.5990857560753438

Epoch: 6| Step: 1
Training loss: 0.5048300680504315
Validation loss: 2.5890508422355425

Epoch: 6| Step: 2
Training loss: 0.34968980471385896
Validation loss: 2.594569543654215

Epoch: 6| Step: 3
Training loss: 0.34418148356787215
Validation loss: 2.5565815289573623

Epoch: 6| Step: 4
Training loss: 0.419664508107421
Validation loss: 2.5891919017062754

Epoch: 6| Step: 5
Training loss: 0.29053230601969493
Validation loss: 2.5909518953340522

Epoch: 6| Step: 6
Training loss: 0.4254145837067147
Validation loss: 2.5451493730126584

Epoch: 6| Step: 7
Training loss: 0.38118000716916695
Validation loss: 2.5011909416910942

Epoch: 6| Step: 8
Training loss: 0.47496005630693783
Validation loss: 2.524524304455065

Epoch: 6| Step: 9
Training loss: 0.3381749538956001
Validation loss: 2.5131082298455643

Epoch: 6| Step: 10
Training loss: 0.20058966153113475
Validation loss: 2.5409022983484935

Epoch: 6| Step: 11
Training loss: 0.3047009734084678
Validation loss: 2.5299280452625004

Epoch: 6| Step: 12
Training loss: 0.26483257686486145
Validation loss: 2.5177397580655128

Epoch: 6| Step: 13
Training loss: 0.37233718552527634
Validation loss: 2.549668274651644

Epoch: 384| Step: 0
Training loss: 0.5021023064770627
Validation loss: 2.5671011421838106

Epoch: 6| Step: 1
Training loss: 0.1772423525749067
Validation loss: 2.5310445175718073

Epoch: 6| Step: 2
Training loss: 0.3860047424672385
Validation loss: 2.589078331124722

Epoch: 6| Step: 3
Training loss: 0.22408952677700653
Validation loss: 2.5503401162914527

Epoch: 6| Step: 4
Training loss: 0.46888069873866445
Validation loss: 2.5754078149154576

Epoch: 6| Step: 5
Training loss: 0.23805203904502725
Validation loss: 2.5845264659303995

Epoch: 6| Step: 6
Training loss: 0.5892955430354733
Validation loss: 2.5551463172940023

Epoch: 6| Step: 7
Training loss: 0.30967727401741046
Validation loss: 2.5165043794912716

Epoch: 6| Step: 8
Training loss: 0.5221059859076063
Validation loss: 2.4982091950095895

Epoch: 6| Step: 9
Training loss: 0.17967859536373168
Validation loss: 2.5055268855415678

Epoch: 6| Step: 10
Training loss: 0.27106119009822455
Validation loss: 2.5148860610687978

Epoch: 6| Step: 11
Training loss: 0.3767385316684074
Validation loss: 2.4888289066196108

Epoch: 6| Step: 12
Training loss: 0.4583291754389502
Validation loss: 2.5007420489675276

Epoch: 6| Step: 13
Training loss: 0.3638609086547931
Validation loss: 2.5365406339800316

Epoch: 385| Step: 0
Training loss: 0.30335857889334733
Validation loss: 2.5014993693647636

Epoch: 6| Step: 1
Training loss: 0.2014651336889728
Validation loss: 2.5452604120202875

Epoch: 6| Step: 2
Training loss: 0.3945598403089321
Validation loss: 2.533255393033409

Epoch: 6| Step: 3
Training loss: 0.4219972645232504
Validation loss: 2.5988200662583467

Epoch: 6| Step: 4
Training loss: 0.5757517171710732
Validation loss: 2.550426450752757

Epoch: 6| Step: 5
Training loss: 0.3215769489626962
Validation loss: 2.5981754001020034

Epoch: 6| Step: 6
Training loss: 0.27404143531951564
Validation loss: 2.595912786271979

Epoch: 6| Step: 7
Training loss: 0.2627267074260138
Validation loss: 2.5740087120560866

Epoch: 6| Step: 8
Training loss: 0.4545677663193039
Validation loss: 2.538776479912886

Epoch: 6| Step: 9
Training loss: 0.4381979586085358
Validation loss: 2.5400329280169407

Epoch: 6| Step: 10
Training loss: 0.35239042704569085
Validation loss: 2.560064489481019

Epoch: 6| Step: 11
Training loss: 0.4189541689063342
Validation loss: 2.576214100252521

Epoch: 6| Step: 12
Training loss: 0.3933209276398165
Validation loss: 2.5275890391515916

Epoch: 6| Step: 13
Training loss: 0.23618015669758138
Validation loss: 2.513016075721882

Epoch: 386| Step: 0
Training loss: 0.44603090728808603
Validation loss: 2.5430212366884897

Epoch: 6| Step: 1
Training loss: 0.41397365480599846
Validation loss: 2.5274929155970374

Epoch: 6| Step: 2
Training loss: 0.3420026105493886
Validation loss: 2.5548776881492437

Epoch: 6| Step: 3
Training loss: 0.29783407691534713
Validation loss: 2.553713530542267

Epoch: 6| Step: 4
Training loss: 0.21393369920716046
Validation loss: 2.529955192614017

Epoch: 6| Step: 5
Training loss: 0.18067980517282406
Validation loss: 2.570848581799343

Epoch: 6| Step: 6
Training loss: 0.3218392875451656
Validation loss: 2.5642724778874726

Epoch: 6| Step: 7
Training loss: 0.2807391082947243
Validation loss: 2.537858445739456

Epoch: 6| Step: 8
Training loss: 0.43644474694251134
Validation loss: 2.588199965225756

Epoch: 6| Step: 9
Training loss: 0.38456019615402043
Validation loss: 2.5543373361905464

Epoch: 6| Step: 10
Training loss: 0.4068923420293957
Validation loss: 2.6077124452440836

Epoch: 6| Step: 11
Training loss: 0.3999460124299048
Validation loss: 2.594516340469191

Epoch: 6| Step: 12
Training loss: 0.5435569650737323
Validation loss: 2.6098746183167125

Epoch: 6| Step: 13
Training loss: 0.32093259057335893
Validation loss: 2.593630237782078

Epoch: 387| Step: 0
Training loss: 0.3728278750553111
Validation loss: 2.5852696326770634

Epoch: 6| Step: 1
Training loss: 0.1973090737715682
Validation loss: 2.601531890104707

Epoch: 6| Step: 2
Training loss: 0.28538130671098605
Validation loss: 2.5980280784369674

Epoch: 6| Step: 3
Training loss: 0.20903734623189868
Validation loss: 2.572534064819736

Epoch: 6| Step: 4
Training loss: 0.41859891215491524
Validation loss: 2.5424186734497853

Epoch: 6| Step: 5
Training loss: 0.22635567202172088
Validation loss: 2.589371648902433

Epoch: 6| Step: 6
Training loss: 0.2791236527005115
Validation loss: 2.5423568317750163

Epoch: 6| Step: 7
Training loss: 0.4686617132332546
Validation loss: 2.553155978923314

Epoch: 6| Step: 8
Training loss: 0.37396990838727723
Validation loss: 2.5482663505609935

Epoch: 6| Step: 9
Training loss: 0.4952950844576051
Validation loss: 2.552461569915402

Epoch: 6| Step: 10
Training loss: 0.20259981853523112
Validation loss: 2.543948956492602

Epoch: 6| Step: 11
Training loss: 0.49595922613599036
Validation loss: 2.5284143118440077

Epoch: 6| Step: 12
Training loss: 0.23010260382127737
Validation loss: 2.5400937110267368

Epoch: 6| Step: 13
Training loss: 0.6633780598617494
Validation loss: 2.5687373574056585

Epoch: 388| Step: 0
Training loss: 0.37996951096969367
Validation loss: 2.5187173408742725

Epoch: 6| Step: 1
Training loss: 0.4350247182619467
Validation loss: 2.5274078669880735

Epoch: 6| Step: 2
Training loss: 0.25182670556222414
Validation loss: 2.5069464350029014

Epoch: 6| Step: 3
Training loss: 0.33552690297775145
Validation loss: 2.542601174709548

Epoch: 6| Step: 4
Training loss: 0.21583871202014243
Validation loss: 2.5031242271156784

Epoch: 6| Step: 5
Training loss: 0.3053926231570684
Validation loss: 2.491026815705477

Epoch: 6| Step: 6
Training loss: 0.3480127521232409
Validation loss: 2.5288972036564767

Epoch: 6| Step: 7
Training loss: 0.24601303775186448
Validation loss: 2.567315681612825

Epoch: 6| Step: 8
Training loss: 0.44365727503540514
Validation loss: 2.5373745657579367

Epoch: 6| Step: 9
Training loss: 0.2784889647148362
Validation loss: 2.561747569803361

Epoch: 6| Step: 10
Training loss: 0.6179937094797264
Validation loss: 2.58874860957958

Epoch: 6| Step: 11
Training loss: 0.2539480908471748
Validation loss: 2.545227436890423

Epoch: 6| Step: 12
Training loss: 0.5021444468152333
Validation loss: 2.5781242810618425

Epoch: 6| Step: 13
Training loss: 0.059156804019713585
Validation loss: 2.54530138998755

Epoch: 389| Step: 0
Training loss: 0.31648987971754017
Validation loss: 2.5082195274834373

Epoch: 6| Step: 1
Training loss: 0.3662641359472025
Validation loss: 2.569667512940007

Epoch: 6| Step: 2
Training loss: 0.3820170877714111
Validation loss: 2.5332126217349407

Epoch: 6| Step: 3
Training loss: 0.30174844227288417
Validation loss: 2.5318011381811254

Epoch: 6| Step: 4
Training loss: 0.4805336574968708
Validation loss: 2.5224925175754858

Epoch: 6| Step: 5
Training loss: 0.471184069324355
Validation loss: 2.5675666046282264

Epoch: 6| Step: 6
Training loss: 0.15815341427478152
Validation loss: 2.5334110643829693

Epoch: 6| Step: 7
Training loss: 0.2656133593084214
Validation loss: 2.5416674355906332

Epoch: 6| Step: 8
Training loss: 0.29220206076504346
Validation loss: 2.5299433580846555

Epoch: 6| Step: 9
Training loss: 0.20145006296630733
Validation loss: 2.549273813410561

Epoch: 6| Step: 10
Training loss: 0.5292163520175249
Validation loss: 2.5790447723636687

Epoch: 6| Step: 11
Training loss: 0.2809652370385584
Validation loss: 2.543129519320457

Epoch: 6| Step: 12
Training loss: 0.43447115334756536
Validation loss: 2.563387009204448

Epoch: 6| Step: 13
Training loss: 0.2647519911978446
Validation loss: 2.5426565919122606

Epoch: 390| Step: 0
Training loss: 0.10621542560905815
Validation loss: 2.561784061490151

Epoch: 6| Step: 1
Training loss: 0.4972886091435822
Validation loss: 2.5753344416507162

Epoch: 6| Step: 2
Training loss: 0.20593223730028498
Validation loss: 2.5686107300236967

Epoch: 6| Step: 3
Training loss: 0.4120192587434482
Validation loss: 2.542020602288826

Epoch: 6| Step: 4
Training loss: 0.4029914309392843
Validation loss: 2.5448107109105895

Epoch: 6| Step: 5
Training loss: 0.4018970342857469
Validation loss: 2.5071286067069924

Epoch: 6| Step: 6
Training loss: 0.16075418666212343
Validation loss: 2.4913435517776956

Epoch: 6| Step: 7
Training loss: 0.3097812283062896
Validation loss: 2.4634149865654935

Epoch: 6| Step: 8
Training loss: 0.5648540933804271
Validation loss: 2.4928142438323193

Epoch: 6| Step: 9
Training loss: 0.2980115117083353
Validation loss: 2.4570614157706823

Epoch: 6| Step: 10
Training loss: 0.3918959350712888
Validation loss: 2.4392314742441084

Epoch: 6| Step: 11
Training loss: 0.4419268011460521
Validation loss: 2.50236148973739

Epoch: 6| Step: 12
Training loss: 0.3406840929341433
Validation loss: 2.509517261602649

Epoch: 6| Step: 13
Training loss: 0.210148262028107
Validation loss: 2.5336368042918536

Epoch: 391| Step: 0
Training loss: 0.2909588342336638
Validation loss: 2.5543249451944137

Epoch: 6| Step: 1
Training loss: 0.47289378920296404
Validation loss: 2.610550776963853

Epoch: 6| Step: 2
Training loss: 0.37177368915786707
Validation loss: 2.5880948550125695

Epoch: 6| Step: 3
Training loss: 0.3059793497633363
Validation loss: 2.5450571229632715

Epoch: 6| Step: 4
Training loss: 0.17717317915201883
Validation loss: 2.5646438674524745

Epoch: 6| Step: 5
Training loss: 0.2549380246283503
Validation loss: 2.546563249264848

Epoch: 6| Step: 6
Training loss: 0.42566994428356064
Validation loss: 2.5334296029159633

Epoch: 6| Step: 7
Training loss: 0.3698786870444555
Validation loss: 2.5076220914210974

Epoch: 6| Step: 8
Training loss: 0.3594092891754672
Validation loss: 2.519760205123069

Epoch: 6| Step: 9
Training loss: 0.22714735868924327
Validation loss: 2.5068078264665457

Epoch: 6| Step: 10
Training loss: 0.5863764580940459
Validation loss: 2.531477127610693

Epoch: 6| Step: 11
Training loss: 0.30333949493256496
Validation loss: 2.561105962734226

Epoch: 6| Step: 12
Training loss: 0.4591039623547339
Validation loss: 2.556093035326433

Epoch: 6| Step: 13
Training loss: 0.44676667080831084
Validation loss: 2.571453652175756

Epoch: 392| Step: 0
Training loss: 0.40124015932701934
Validation loss: 2.603041984277225

Epoch: 6| Step: 1
Training loss: 0.1502180843675792
Validation loss: 2.632679964628632

Epoch: 6| Step: 2
Training loss: 0.4588636198885032
Validation loss: 2.6113626947192556

Epoch: 6| Step: 3
Training loss: 0.29045665746575755
Validation loss: 2.6231985937905073

Epoch: 6| Step: 4
Training loss: 0.3161468502177057
Validation loss: 2.636718577905647

Epoch: 6| Step: 5
Training loss: 0.32299549796669424
Validation loss: 2.6579131361328

Epoch: 6| Step: 6
Training loss: 0.3330509348046276
Validation loss: 2.6320102409357804

Epoch: 6| Step: 7
Training loss: 0.4460672708058194
Validation loss: 2.650135959860866

Epoch: 6| Step: 8
Training loss: 0.5074287138045631
Validation loss: 2.6349540095847535

Epoch: 6| Step: 9
Training loss: 0.21569482253364175
Validation loss: 2.574101813836012

Epoch: 6| Step: 10
Training loss: 0.3279918900205352
Validation loss: 2.532351318182687

Epoch: 6| Step: 11
Training loss: 0.31996983132606704
Validation loss: 2.539933980936944

Epoch: 6| Step: 12
Training loss: 0.4356767606154495
Validation loss: 2.501443113126657

Epoch: 6| Step: 13
Training loss: 0.28558852469934615
Validation loss: 2.559866264303596

Epoch: 393| Step: 0
Training loss: 0.3402846753573964
Validation loss: 2.5684512442556846

Epoch: 6| Step: 1
Training loss: 0.27458192571463486
Validation loss: 2.578884442722227

Epoch: 6| Step: 2
Training loss: 0.3340995545350901
Validation loss: 2.555102628162994

Epoch: 6| Step: 3
Training loss: 0.2304058474029248
Validation loss: 2.6067013113485262

Epoch: 6| Step: 4
Training loss: 0.45776609699878446
Validation loss: 2.610302837827016

Epoch: 6| Step: 5
Training loss: 0.49865745068175044
Validation loss: 2.6130128235760735

Epoch: 6| Step: 6
Training loss: 0.5296081809910945
Validation loss: 2.607725477177651

Epoch: 6| Step: 7
Training loss: 0.3771102459227512
Validation loss: 2.624319469800622

Epoch: 6| Step: 8
Training loss: 0.3971549315947338
Validation loss: 2.5996487739172056

Epoch: 6| Step: 9
Training loss: 0.2135616192373903
Validation loss: 2.565259967322269

Epoch: 6| Step: 10
Training loss: 0.272786332390634
Validation loss: 2.5774731480388615

Epoch: 6| Step: 11
Training loss: 0.31719613087003296
Validation loss: 2.5473109952365953

Epoch: 6| Step: 12
Training loss: 0.31555480365279287
Validation loss: 2.5658312727978276

Epoch: 6| Step: 13
Training loss: 0.3426697294277555
Validation loss: 2.514752274768839

Epoch: 394| Step: 0
Training loss: 0.44062372910877673
Validation loss: 2.5487476960261763

Epoch: 6| Step: 1
Training loss: 0.2131681820256602
Validation loss: 2.5261384790455907

Epoch: 6| Step: 2
Training loss: 0.4033073441681165
Validation loss: 2.535324413939311

Epoch: 6| Step: 3
Training loss: 0.28550975260804107
Validation loss: 2.5186227994589565

Epoch: 6| Step: 4
Training loss: 0.2852990433067182
Validation loss: 2.5674410957607026

Epoch: 6| Step: 5
Training loss: 0.44973907190885404
Validation loss: 2.5675540677965247

Epoch: 6| Step: 6
Training loss: 0.36013996559118117
Validation loss: 2.5808341669464214

Epoch: 6| Step: 7
Training loss: 0.43304176249093623
Validation loss: 2.5973230158529397

Epoch: 6| Step: 8
Training loss: 0.48864893992855585
Validation loss: 2.600945078172923

Epoch: 6| Step: 9
Training loss: 0.5281992718990931
Validation loss: 2.562968759708144

Epoch: 6| Step: 10
Training loss: 0.16046371835585
Validation loss: 2.5325138021557305

Epoch: 6| Step: 11
Training loss: 0.23989197125116443
Validation loss: 2.5486069294069793

Epoch: 6| Step: 12
Training loss: 0.2443366827522701
Validation loss: 2.4889475269333134

Epoch: 6| Step: 13
Training loss: 0.27982688179913606
Validation loss: 2.4998926462688797

Epoch: 395| Step: 0
Training loss: 0.318922270709323
Validation loss: 2.4401619918208293

Epoch: 6| Step: 1
Training loss: 0.37314664295500516
Validation loss: 2.474362388649797

Epoch: 6| Step: 2
Training loss: 0.3481970235192868
Validation loss: 2.4952905134635217

Epoch: 6| Step: 3
Training loss: 0.3090872500492773
Validation loss: 2.5019032114716175

Epoch: 6| Step: 4
Training loss: 0.24076049847702477
Validation loss: 2.5047788659714985

Epoch: 6| Step: 5
Training loss: 0.2539305748658326
Validation loss: 2.530598687171766

Epoch: 6| Step: 6
Training loss: 0.5220359143000526
Validation loss: 2.5410390112853447

Epoch: 6| Step: 7
Training loss: 0.3854355957778451
Validation loss: 2.5044496847623328

Epoch: 6| Step: 8
Training loss: 0.42587566203924415
Validation loss: 2.5778952199413134

Epoch: 6| Step: 9
Training loss: 0.4261967093192546
Validation loss: 2.5713366740125543

Epoch: 6| Step: 10
Training loss: 0.28022678000178924
Validation loss: 2.556168960733691

Epoch: 6| Step: 11
Training loss: 0.22970334342238802
Validation loss: 2.5658085601052676

Epoch: 6| Step: 12
Training loss: 0.3801805560098532
Validation loss: 2.5796789642544766

Epoch: 6| Step: 13
Training loss: 0.5986830922056203
Validation loss: 2.5423183570623493

Epoch: 396| Step: 0
Training loss: 0.2374030957039427
Validation loss: 2.618398067998696

Epoch: 6| Step: 1
Training loss: 0.4295299241096512
Validation loss: 2.557045660952731

Epoch: 6| Step: 2
Training loss: 0.23778608339590887
Validation loss: 2.5703360525962715

Epoch: 6| Step: 3
Training loss: 0.0747989668538673
Validation loss: 2.582083884876435

Epoch: 6| Step: 4
Training loss: 0.5635403707727938
Validation loss: 2.584748578768205

Epoch: 6| Step: 5
Training loss: 0.4056788427592524
Validation loss: 2.5454525810891213

Epoch: 6| Step: 6
Training loss: 0.4593972641875879
Validation loss: 2.5853001019321087

Epoch: 6| Step: 7
Training loss: 0.3508358333065155
Validation loss: 2.585507346108553

Epoch: 6| Step: 8
Training loss: 0.1711051508183797
Validation loss: 2.5684986708222075

Epoch: 6| Step: 9
Training loss: 0.2444510127165578
Validation loss: 2.61514178668492

Epoch: 6| Step: 10
Training loss: 0.2929222960200229
Validation loss: 2.6002109718077837

Epoch: 6| Step: 11
Training loss: 0.3351756817179738
Validation loss: 2.5992685443126966

Epoch: 6| Step: 12
Training loss: 0.4633562667348801
Validation loss: 2.580442995566527

Epoch: 6| Step: 13
Training loss: 0.26055374193650477
Validation loss: 2.5884635525442756

Epoch: 397| Step: 0
Training loss: 0.4862936536223041
Validation loss: 2.569188699371335

Epoch: 6| Step: 1
Training loss: 0.31780313682454475
Validation loss: 2.5870709930387163

Epoch: 6| Step: 2
Training loss: 0.438532122721837
Validation loss: 2.580361568951658

Epoch: 6| Step: 3
Training loss: 0.5317641743222181
Validation loss: 2.5593597795896135

Epoch: 6| Step: 4
Training loss: 0.17690138491982813
Validation loss: 2.547835452480219

Epoch: 6| Step: 5
Training loss: 0.20608551011810708
Validation loss: 2.54506175654736

Epoch: 6| Step: 6
Training loss: 0.26348056210478915
Validation loss: 2.5484304423765227

Epoch: 6| Step: 7
Training loss: 0.1345924840858292
Validation loss: 2.512448416225113

Epoch: 6| Step: 8
Training loss: 0.4534948911042632
Validation loss: 2.549094584735385

Epoch: 6| Step: 9
Training loss: 0.16065271698755343
Validation loss: 2.528023045192179

Epoch: 6| Step: 10
Training loss: 0.3814202116302204
Validation loss: 2.477849808269851

Epoch: 6| Step: 11
Training loss: 0.29004449550279593
Validation loss: 2.521553514999175

Epoch: 6| Step: 12
Training loss: 0.28998364776515206
Validation loss: 2.4924083417321508

Epoch: 6| Step: 13
Training loss: 0.4226555314824736
Validation loss: 2.5206549783161045

Epoch: 398| Step: 0
Training loss: 0.2653532320888494
Validation loss: 2.524588406226037

Epoch: 6| Step: 1
Training loss: 0.38574321118955346
Validation loss: 2.5509836572976203

Epoch: 6| Step: 2
Training loss: 0.3309058696050436
Validation loss: 2.5171805680232993

Epoch: 6| Step: 3
Training loss: 0.3100015182227212
Validation loss: 2.553562375774299

Epoch: 6| Step: 4
Training loss: 0.2325895009511836
Validation loss: 2.524624100715764

Epoch: 6| Step: 5
Training loss: 0.16544989515375025
Validation loss: 2.5306171946418536

Epoch: 6| Step: 6
Training loss: 0.5154135299295233
Validation loss: 2.5566533958389153

Epoch: 6| Step: 7
Training loss: 0.17155272440341102
Validation loss: 2.5426585438889377

Epoch: 6| Step: 8
Training loss: 0.5774869748913203
Validation loss: 2.5446439234320932

Epoch: 6| Step: 9
Training loss: 0.36866539938336956
Validation loss: 2.529278713637339

Epoch: 6| Step: 10
Training loss: 0.18456588215026803
Validation loss: 2.530201558953385

Epoch: 6| Step: 11
Training loss: 0.32965799262895
Validation loss: 2.543182880697568

Epoch: 6| Step: 12
Training loss: 0.3476696011840642
Validation loss: 2.542486754121449

Epoch: 6| Step: 13
Training loss: 0.23826906298130104
Validation loss: 2.536180832301975

Epoch: 399| Step: 0
Training loss: 0.29468062935887007
Validation loss: 2.5381606476315453

Epoch: 6| Step: 1
Training loss: 0.33630340077685333
Validation loss: 2.526645395341614

Epoch: 6| Step: 2
Training loss: 0.1032998066475906
Validation loss: 2.5402024666352996

Epoch: 6| Step: 3
Training loss: 0.29071101946057015
Validation loss: 2.524635038151346

Epoch: 6| Step: 4
Training loss: 0.34331446930108517
Validation loss: 2.5178111157000123

Epoch: 6| Step: 5
Training loss: 0.2473934457897959
Validation loss: 2.5518226843691583

Epoch: 6| Step: 6
Training loss: 0.39983968278754956
Validation loss: 2.5636518887256377

Epoch: 6| Step: 7
Training loss: 0.3565258196486495
Validation loss: 2.5270139828363294

Epoch: 6| Step: 8
Training loss: 0.41201401461449616
Validation loss: 2.538372598951066

Epoch: 6| Step: 9
Training loss: 0.3645158319200832
Validation loss: 2.53692150382683

Epoch: 6| Step: 10
Training loss: 0.18263745322970643
Validation loss: 2.5401720917519834

Epoch: 6| Step: 11
Training loss: 0.4569095058169922
Validation loss: 2.5464081806035903

Epoch: 6| Step: 12
Training loss: 0.3026210449729234
Validation loss: 2.526327937533918

Epoch: 6| Step: 13
Training loss: 0.45294152853400566
Validation loss: 2.516393068459798

Epoch: 400| Step: 0
Training loss: 0.20994599754940863
Validation loss: 2.532439531309086

Epoch: 6| Step: 1
Training loss: 0.2514503252597358
Validation loss: 2.5385338310343517

Epoch: 6| Step: 2
Training loss: 0.21726846523684887
Validation loss: 2.50138751257628

Epoch: 6| Step: 3
Training loss: 0.423202950102749
Validation loss: 2.5049774436695738

Epoch: 6| Step: 4
Training loss: 0.3216814700032676
Validation loss: 2.537615155457586

Epoch: 6| Step: 5
Training loss: 0.2385219858760167
Validation loss: 2.520310098368865

Epoch: 6| Step: 6
Training loss: 0.47685493814508
Validation loss: 2.542587678915825

Epoch: 6| Step: 7
Training loss: 0.5189004381193766
Validation loss: 2.545744660643838

Epoch: 6| Step: 8
Training loss: 0.22736058582483953
Validation loss: 2.578856504693871

Epoch: 6| Step: 9
Training loss: 0.22525659274933066
Validation loss: 2.5633553038717185

Epoch: 6| Step: 10
Training loss: 0.43957929707281646
Validation loss: 2.5756154584171043

Epoch: 6| Step: 11
Training loss: 0.3470826721566731
Validation loss: 2.5521217314841107

Epoch: 6| Step: 12
Training loss: 0.2834259209165596
Validation loss: 2.564150521044464

Epoch: 6| Step: 13
Training loss: 0.09734395637918948
Validation loss: 2.509452242091466

Epoch: 401| Step: 0
Training loss: 0.35277984511945293
Validation loss: 2.549301252031682

Epoch: 6| Step: 1
Training loss: 0.3792766255278073
Validation loss: 2.545675164571493

Epoch: 6| Step: 2
Training loss: 0.2931600073547274
Validation loss: 2.5457097839432423

Epoch: 6| Step: 3
Training loss: 0.35946490365694633
Validation loss: 2.5321771925603915

Epoch: 6| Step: 4
Training loss: 0.4511782162703714
Validation loss: 2.5170976988718974

Epoch: 6| Step: 5
Training loss: 0.43097433387846046
Validation loss: 2.5345912662588628

Epoch: 6| Step: 6
Training loss: 0.3424825276143516
Validation loss: 2.496335609487745

Epoch: 6| Step: 7
Training loss: 0.2717864462355849
Validation loss: 2.560855803196108

Epoch: 6| Step: 8
Training loss: 0.20764571897269396
Validation loss: 2.523818402026933

Epoch: 6| Step: 9
Training loss: 0.35536536086055776
Validation loss: 2.594609910828741

Epoch: 6| Step: 10
Training loss: 0.21273381468845845
Validation loss: 2.54983521507532

Epoch: 6| Step: 11
Training loss: 0.3403499822931242
Validation loss: 2.546583583639212

Epoch: 6| Step: 12
Training loss: 0.11419969694645182
Validation loss: 2.5244941141297566

Epoch: 6| Step: 13
Training loss: 0.29818505549983004
Validation loss: 2.5181434364706705

Epoch: 402| Step: 0
Training loss: 0.24852007687132927
Validation loss: 2.558242233892091

Epoch: 6| Step: 1
Training loss: 0.16955305499822015
Validation loss: 2.511937754177466

Epoch: 6| Step: 2
Training loss: 0.3720595991539648
Validation loss: 2.4789191987956145

Epoch: 6| Step: 3
Training loss: 0.43547558735659436
Validation loss: 2.52480699062848

Epoch: 6| Step: 4
Training loss: 0.3053438746048296
Validation loss: 2.526028805340441

Epoch: 6| Step: 5
Training loss: 0.4268974931077229
Validation loss: 2.48437522598733

Epoch: 6| Step: 6
Training loss: 0.3892323464094247
Validation loss: 2.5035957124790236

Epoch: 6| Step: 7
Training loss: 0.30542684984773383
Validation loss: 2.5388308870174368

Epoch: 6| Step: 8
Training loss: 0.4938990337854756
Validation loss: 2.5182888230388247

Epoch: 6| Step: 9
Training loss: 0.2923783138237393
Validation loss: 2.539726298026533

Epoch: 6| Step: 10
Training loss: 0.12222768938490547
Validation loss: 2.5813765777863193

Epoch: 6| Step: 11
Training loss: 0.17741631775068115
Validation loss: 2.53687035320745

Epoch: 6| Step: 12
Training loss: 0.2913814779598241
Validation loss: 2.539866401117975

Epoch: 6| Step: 13
Training loss: 0.17874113984590634
Validation loss: 2.539073535778462

Epoch: 403| Step: 0
Training loss: 0.4574819934146785
Validation loss: 2.547637060440633

Epoch: 6| Step: 1
Training loss: 0.2363702641899812
Validation loss: 2.5451619028584602

Epoch: 6| Step: 2
Training loss: 0.21485681494088635
Validation loss: 2.5180370965392704

Epoch: 6| Step: 3
Training loss: 0.39827315363057003
Validation loss: 2.5677855869253268

Epoch: 6| Step: 4
Training loss: 0.3452403424678052
Validation loss: 2.5373901261363283

Epoch: 6| Step: 5
Training loss: 0.21305639480008026
Validation loss: 2.5738243301174353

Epoch: 6| Step: 6
Training loss: 0.4022540390589503
Validation loss: 2.5171231044853304

Epoch: 6| Step: 7
Training loss: 0.3211279235994828
Validation loss: 2.5363665862296783

Epoch: 6| Step: 8
Training loss: 0.32077617347665566
Validation loss: 2.5326274576012597

Epoch: 6| Step: 9
Training loss: 0.4430875238838978
Validation loss: 2.529962314179284

Epoch: 6| Step: 10
Training loss: 0.31392326494949413
Validation loss: 2.549712763740161

Epoch: 6| Step: 11
Training loss: 0.28671219010085836
Validation loss: 2.582074098264241

Epoch: 6| Step: 12
Training loss: 0.44026549803853876
Validation loss: 2.560043341894006

Epoch: 6| Step: 13
Training loss: 0.20596396451289214
Validation loss: 2.5386665386355443

Epoch: 404| Step: 0
Training loss: 0.2787366730878445
Validation loss: 2.5486039720628106

Epoch: 6| Step: 1
Training loss: 0.17674913437758152
Validation loss: 2.581575046048156

Epoch: 6| Step: 2
Training loss: 0.5543778858303233
Validation loss: 2.534043899449313

Epoch: 6| Step: 3
Training loss: 0.33609803378373615
Validation loss: 2.547316571751296

Epoch: 6| Step: 4
Training loss: 0.2521746201517348
Validation loss: 2.5529206165453

Epoch: 6| Step: 5
Training loss: 0.15669607622194712
Validation loss: 2.570874394095401

Epoch: 6| Step: 6
Training loss: 0.24437585561022038
Validation loss: 2.584003718923547

Epoch: 6| Step: 7
Training loss: 0.3223728810625672
Validation loss: 2.5831531762198447

Epoch: 6| Step: 8
Training loss: 0.4135078998523708
Validation loss: 2.579421846906315

Epoch: 6| Step: 9
Training loss: 0.42417973994110625
Validation loss: 2.5096440032286793

Epoch: 6| Step: 10
Training loss: 0.3608556390384356
Validation loss: 2.5221738133529668

Epoch: 6| Step: 11
Training loss: 0.2903033507006889
Validation loss: 2.5112344205358736

Epoch: 6| Step: 12
Training loss: 0.16401659232398813
Validation loss: 2.5339792877049936

Epoch: 6| Step: 13
Training loss: 0.32348643176958836
Validation loss: 2.531388330015701

Epoch: 405| Step: 0
Training loss: 0.21502266283411672
Validation loss: 2.4928943044381655

Epoch: 6| Step: 1
Training loss: 0.4901439385757384
Validation loss: 2.541977945192469

Epoch: 6| Step: 2
Training loss: 0.11153424155551238
Validation loss: 2.507849215281967

Epoch: 6| Step: 3
Training loss: 0.1503636905776678
Validation loss: 2.51068509889162

Epoch: 6| Step: 4
Training loss: 0.2637816589120914
Validation loss: 2.5459728594722133

Epoch: 6| Step: 5
Training loss: 0.41506887889797506
Validation loss: 2.530001544240992

Epoch: 6| Step: 6
Training loss: 0.1848557097370128
Validation loss: 2.5485369168833967

Epoch: 6| Step: 7
Training loss: 0.3184571847268969
Validation loss: 2.5598448156356404

Epoch: 6| Step: 8
Training loss: 0.3016841514580173
Validation loss: 2.5724338016782005

Epoch: 6| Step: 9
Training loss: 0.34150301698913077
Validation loss: 2.5820834629120806

Epoch: 6| Step: 10
Training loss: 0.25224228463599485
Validation loss: 2.5863516426079975

Epoch: 6| Step: 11
Training loss: 0.4590457631715772
Validation loss: 2.621056769983269

Epoch: 6| Step: 12
Training loss: 0.23638473967563933
Validation loss: 2.5869546259332106

Epoch: 6| Step: 13
Training loss: 0.5584624876506166
Validation loss: 2.5647853421853837

Epoch: 406| Step: 0
Training loss: 0.21676482573736994
Validation loss: 2.5542184259145015

Epoch: 6| Step: 1
Training loss: 0.34790694381163606
Validation loss: 2.5457564972441236

Epoch: 6| Step: 2
Training loss: 0.36361168630676066
Validation loss: 2.5364909058261427

Epoch: 6| Step: 3
Training loss: 0.21276296935462538
Validation loss: 2.565866177733851

Epoch: 6| Step: 4
Training loss: 0.42909918303908645
Validation loss: 2.534718451274952

Epoch: 6| Step: 5
Training loss: 0.24026989092788525
Validation loss: 2.566128220857135

Epoch: 6| Step: 6
Training loss: 0.16334672737509728
Validation loss: 2.5771061519534704

Epoch: 6| Step: 7
Training loss: 0.30125257793684745
Validation loss: 2.5885401328972764

Epoch: 6| Step: 8
Training loss: 0.264686961730806
Validation loss: 2.5529343258348707

Epoch: 6| Step: 9
Training loss: 0.3485361601050049
Validation loss: 2.5770881683492335

Epoch: 6| Step: 10
Training loss: 0.4424262962275329
Validation loss: 2.5820187982937193

Epoch: 6| Step: 11
Training loss: 0.4074196483518298
Validation loss: 2.564219382423707

Epoch: 6| Step: 12
Training loss: 0.32166778134777124
Validation loss: 2.5542495676814334

Epoch: 6| Step: 13
Training loss: 0.309005257712234
Validation loss: 2.5624679435367606

Epoch: 407| Step: 0
Training loss: 0.384967692803152
Validation loss: 2.5774104863735943

Epoch: 6| Step: 1
Training loss: 0.2239567106025517
Validation loss: 2.551185396368123

Epoch: 6| Step: 2
Training loss: 0.18690444817923826
Validation loss: 2.579626971994748

Epoch: 6| Step: 3
Training loss: 0.22272308082807046
Validation loss: 2.5703264257205456

Epoch: 6| Step: 4
Training loss: 0.22487775276433064
Validation loss: 2.554732334686457

Epoch: 6| Step: 5
Training loss: 0.395748187829096
Validation loss: 2.548189485444616

Epoch: 6| Step: 6
Training loss: 0.2576394945599091
Validation loss: 2.5525937689768763

Epoch: 6| Step: 7
Training loss: 0.19395651271169095
Validation loss: 2.5297313759625597

Epoch: 6| Step: 8
Training loss: 0.27098304785866645
Validation loss: 2.574255260091788

Epoch: 6| Step: 9
Training loss: 0.3392557121040537
Validation loss: 2.557441501945002

Epoch: 6| Step: 10
Training loss: 0.4234009097009796
Validation loss: 2.538463095314005

Epoch: 6| Step: 11
Training loss: 0.49566063785264275
Validation loss: 2.5168674967125186

Epoch: 6| Step: 12
Training loss: 0.34643328869589735
Validation loss: 2.476072240425496

Epoch: 6| Step: 13
Training loss: 0.18182873983099754
Validation loss: 2.517497414555228

Epoch: 408| Step: 0
Training loss: 0.190211381247154
Validation loss: 2.5056467396462163

Epoch: 6| Step: 1
Training loss: 0.2904255151609291
Validation loss: 2.4770193281946287

Epoch: 6| Step: 2
Training loss: 0.2017332318704733
Validation loss: 2.5257845912812655

Epoch: 6| Step: 3
Training loss: 0.3609733695830292
Validation loss: 2.4989306182884468

Epoch: 6| Step: 4
Training loss: 0.2490772264020598
Validation loss: 2.5403207220619906

Epoch: 6| Step: 5
Training loss: 0.18550037002012462
Validation loss: 2.57996810680134

Epoch: 6| Step: 6
Training loss: 0.20323424885950392
Validation loss: 2.5540529634467077

Epoch: 6| Step: 7
Training loss: 0.32800377014075194
Validation loss: 2.5474989264149026

Epoch: 6| Step: 8
Training loss: 0.3869071848150689
Validation loss: 2.530938227919213

Epoch: 6| Step: 9
Training loss: 0.549897695910255
Validation loss: 2.5490945072959943

Epoch: 6| Step: 10
Training loss: 0.2745649527030544
Validation loss: 2.539293977773344

Epoch: 6| Step: 11
Training loss: 0.3636282422434907
Validation loss: 2.5045205873249086

Epoch: 6| Step: 12
Training loss: 0.36850352536123593
Validation loss: 2.507502100674986

Epoch: 6| Step: 13
Training loss: 0.19105975259584373
Validation loss: 2.5338055810320586

Epoch: 409| Step: 0
Training loss: 0.2857596532212385
Validation loss: 2.498137602771287

Epoch: 6| Step: 1
Training loss: 0.2588247886325235
Validation loss: 2.535008899062034

Epoch: 6| Step: 2
Training loss: 0.3074110884755374
Validation loss: 2.5169866839912975

Epoch: 6| Step: 3
Training loss: 0.4119489818692373
Validation loss: 2.510465168491855

Epoch: 6| Step: 4
Training loss: 0.4501447338894061
Validation loss: 2.4897784249630837

Epoch: 6| Step: 5
Training loss: 0.22349512450876366
Validation loss: 2.555414391510057

Epoch: 6| Step: 6
Training loss: 0.3664555660806212
Validation loss: 2.5314602092972294

Epoch: 6| Step: 7
Training loss: 0.36747758647792983
Validation loss: 2.570479261081171

Epoch: 6| Step: 8
Training loss: 0.39345801138643355
Validation loss: 2.605902820007537

Epoch: 6| Step: 9
Training loss: 0.31536985130960704
Validation loss: 2.6409005214741663

Epoch: 6| Step: 10
Training loss: 0.2301990175232234
Validation loss: 2.5930774783986568

Epoch: 6| Step: 11
Training loss: 0.3139467960942968
Validation loss: 2.635159775490098

Epoch: 6| Step: 12
Training loss: 0.21944558722430524
Validation loss: 2.599189698846285

Epoch: 6| Step: 13
Training loss: 0.29021877282821223
Validation loss: 2.5743786123902117

Epoch: 410| Step: 0
Training loss: 0.236723899470555
Validation loss: 2.565631552679579

Epoch: 6| Step: 1
Training loss: 0.39117423545775853
Validation loss: 2.5567238629295224

Epoch: 6| Step: 2
Training loss: 0.317317909060125
Validation loss: 2.5543700135665386

Epoch: 6| Step: 3
Training loss: 0.21278245610200489
Validation loss: 2.531946373841995

Epoch: 6| Step: 4
Training loss: 0.49538286593764375
Validation loss: 2.5353214011604455

Epoch: 6| Step: 5
Training loss: 0.38264599896583135
Validation loss: 2.548590470837776

Epoch: 6| Step: 6
Training loss: 0.1458299642128277
Validation loss: 2.5109772735124083

Epoch: 6| Step: 7
Training loss: 0.20856940881102043
Validation loss: 2.572328401030735

Epoch: 6| Step: 8
Training loss: 0.23607322250185034
Validation loss: 2.5119744642749553

Epoch: 6| Step: 9
Training loss: 0.3384487195678128
Validation loss: 2.5359610760180433

Epoch: 6| Step: 10
Training loss: 0.5328910109772044
Validation loss: 2.575172321022618

Epoch: 6| Step: 11
Training loss: 0.22445510044151398
Validation loss: 2.5284477987603666

Epoch: 6| Step: 12
Training loss: 0.20456339407951848
Validation loss: 2.5711090372706797

Epoch: 6| Step: 13
Training loss: 0.28580922652554897
Validation loss: 2.517677907919284

Epoch: 411| Step: 0
Training loss: 0.24992594516178965
Validation loss: 2.552830801404535

Epoch: 6| Step: 1
Training loss: 0.3463207589675637
Validation loss: 2.579394060800926

Epoch: 6| Step: 2
Training loss: 0.32673733060480614
Validation loss: 2.532530456310594

Epoch: 6| Step: 3
Training loss: 0.14833462437883124
Validation loss: 2.539767570697005

Epoch: 6| Step: 4
Training loss: 0.3267209120559852
Validation loss: 2.5194741326157124

Epoch: 6| Step: 5
Training loss: 0.4984268235166311
Validation loss: 2.503613115017684

Epoch: 6| Step: 6
Training loss: 0.35573048440103644
Validation loss: 2.5131068736122333

Epoch: 6| Step: 7
Training loss: 0.4972317626403094
Validation loss: 2.509784287117214

Epoch: 6| Step: 8
Training loss: 0.299527739303782
Validation loss: 2.486348761250797

Epoch: 6| Step: 9
Training loss: 0.2926568341796715
Validation loss: 2.5417259534850265

Epoch: 6| Step: 10
Training loss: 0.19769866548569215
Validation loss: 2.536967777691106

Epoch: 6| Step: 11
Training loss: 0.22197346819331798
Validation loss: 2.5364137758359484

Epoch: 6| Step: 12
Training loss: 0.225745281073527
Validation loss: 2.5718295191202802

Epoch: 6| Step: 13
Training loss: 0.10779300648224992
Validation loss: 2.5388015125766668

Epoch: 412| Step: 0
Training loss: 0.5115098891006119
Validation loss: 2.558838393441932

Epoch: 6| Step: 1
Training loss: 0.31863836923598676
Validation loss: 2.5478659017733025

Epoch: 6| Step: 2
Training loss: 0.43833717220617335
Validation loss: 2.55439014328046

Epoch: 6| Step: 3
Training loss: 0.12194635582611435
Validation loss: 2.5708198783414584

Epoch: 6| Step: 4
Training loss: 0.32842507719071096
Validation loss: 2.544526009975485

Epoch: 6| Step: 5
Training loss: 0.24207592516762402
Validation loss: 2.5218395285096533

Epoch: 6| Step: 6
Training loss: 0.21706694028691506
Validation loss: 2.5032727165041413

Epoch: 6| Step: 7
Training loss: 0.168903069920559
Validation loss: 2.5133828981709225

Epoch: 6| Step: 8
Training loss: 0.23281564934411753
Validation loss: 2.490040688233958

Epoch: 6| Step: 9
Training loss: 0.46393504399344976
Validation loss: 2.4701714064114095

Epoch: 6| Step: 10
Training loss: 0.33722560686682823
Validation loss: 2.4695645275382767

Epoch: 6| Step: 11
Training loss: 0.21709731479956104
Validation loss: 2.5283032797766385

Epoch: 6| Step: 12
Training loss: 0.1357186592074518
Validation loss: 2.568388277637724

Epoch: 6| Step: 13
Training loss: 0.258904024896171
Validation loss: 2.5258605300070793

Epoch: 413| Step: 0
Training loss: 0.23015464779567418
Validation loss: 2.549557328572341

Epoch: 6| Step: 1
Training loss: 0.2542396703739142
Validation loss: 2.583196073359576

Epoch: 6| Step: 2
Training loss: 0.466018762442043
Validation loss: 2.567420151723566

Epoch: 6| Step: 3
Training loss: 0.49037630374763336
Validation loss: 2.567512129472914

Epoch: 6| Step: 4
Training loss: 0.2430760021162381
Validation loss: 2.5419686652605122

Epoch: 6| Step: 5
Training loss: 0.1743493142574249
Validation loss: 2.5504157395197518

Epoch: 6| Step: 6
Training loss: 0.35753285920579786
Validation loss: 2.5203521914791263

Epoch: 6| Step: 7
Training loss: 0.2673339007651838
Validation loss: 2.5358640222944624

Epoch: 6| Step: 8
Training loss: 0.281795951983466
Validation loss: 2.532260060758622

Epoch: 6| Step: 9
Training loss: 0.2532756163048807
Validation loss: 2.5495820663494557

Epoch: 6| Step: 10
Training loss: 0.23644876159642933
Validation loss: 2.5529264348683687

Epoch: 6| Step: 11
Training loss: 0.4085817907855233
Validation loss: 2.534519530394943

Epoch: 6| Step: 12
Training loss: 0.3245428602467922
Validation loss: 2.4804210386628416

Epoch: 6| Step: 13
Training loss: 0.17302754705399695
Validation loss: 2.496390675712937

Epoch: 414| Step: 0
Training loss: 0.268146940547398
Validation loss: 2.4680744065541815

Epoch: 6| Step: 1
Training loss: 0.27174563838069493
Validation loss: 2.4860846034794086

Epoch: 6| Step: 2
Training loss: 0.5314822530753166
Validation loss: 2.4516379622126996

Epoch: 6| Step: 3
Training loss: 0.22861675730738668
Validation loss: 2.502901040817505

Epoch: 6| Step: 4
Training loss: 0.24724459626509512
Validation loss: 2.5035869727648175

Epoch: 6| Step: 5
Training loss: 0.2957905739565549
Validation loss: 2.5579393672385993

Epoch: 6| Step: 6
Training loss: 0.22472574287900315
Validation loss: 2.55280123958387

Epoch: 6| Step: 7
Training loss: 0.2300403460329004
Validation loss: 2.5647267416816946

Epoch: 6| Step: 8
Training loss: 0.3736638265162078
Validation loss: 2.564510451190783

Epoch: 6| Step: 9
Training loss: 0.39300900626600793
Validation loss: 2.562993802148925

Epoch: 6| Step: 10
Training loss: 0.19995704055389954
Validation loss: 2.5914174679193236

Epoch: 6| Step: 11
Training loss: 0.27593893562712424
Validation loss: 2.5570902773403033

Epoch: 6| Step: 12
Training loss: 0.3830254021106604
Validation loss: 2.5526851179771746

Epoch: 6| Step: 13
Training loss: 0.3647078528522918
Validation loss: 2.5426616210722677

Epoch: 415| Step: 0
Training loss: 0.1938503466979147
Validation loss: 2.508996471833314

Epoch: 6| Step: 1
Training loss: 0.22888277994596992
Validation loss: 2.5051185159113722

Epoch: 6| Step: 2
Training loss: 0.24362909515710668
Validation loss: 2.506764404486078

Epoch: 6| Step: 3
Training loss: 0.12618855079782074
Validation loss: 2.4825573225385997

Epoch: 6| Step: 4
Training loss: 0.3695432495685162
Validation loss: 2.4832609483908867

Epoch: 6| Step: 5
Training loss: 0.417758960303613
Validation loss: 2.5199399900998385

Epoch: 6| Step: 6
Training loss: 0.34697810479311514
Validation loss: 2.508439428398067

Epoch: 6| Step: 7
Training loss: 0.2355887535532857
Validation loss: 2.5067690592511997

Epoch: 6| Step: 8
Training loss: 0.27402546202821904
Validation loss: 2.5172039730790563

Epoch: 6| Step: 9
Training loss: 0.28379066293557875
Validation loss: 2.5360441031149166

Epoch: 6| Step: 10
Training loss: 0.32603000365086404
Validation loss: 2.5272382856306996

Epoch: 6| Step: 11
Training loss: 0.2993817530330289
Validation loss: 2.5398762898028293

Epoch: 6| Step: 12
Training loss: 0.49871256601780795
Validation loss: 2.5670492357237875

Epoch: 6| Step: 13
Training loss: 0.1152070142300827
Validation loss: 2.601673139018965

Epoch: 416| Step: 0
Training loss: 0.3498387037443996
Validation loss: 2.553943527836436

Epoch: 6| Step: 1
Training loss: 0.34970472942788905
Validation loss: 2.5602395321806606

Epoch: 6| Step: 2
Training loss: 0.15766033021771683
Validation loss: 2.5851600171411175

Epoch: 6| Step: 3
Training loss: 0.3726699282776984
Validation loss: 2.583257599301705

Epoch: 6| Step: 4
Training loss: 0.26195331993289184
Validation loss: 2.5785363837078865

Epoch: 6| Step: 5
Training loss: 0.2813669332502859
Validation loss: 2.5460259336930626

Epoch: 6| Step: 6
Training loss: 0.3638807907469298
Validation loss: 2.561466814111912

Epoch: 6| Step: 7
Training loss: 0.37303844662077634
Validation loss: 2.5695963796807266

Epoch: 6| Step: 8
Training loss: 0.34344105492193366
Validation loss: 2.5565983351790065

Epoch: 6| Step: 9
Training loss: 0.23449427430741354
Validation loss: 2.58794174790845

Epoch: 6| Step: 10
Training loss: 0.205050239483643
Validation loss: 2.5279403616057143

Epoch: 6| Step: 11
Training loss: 0.16361714269628977
Validation loss: 2.5781011570996055

Epoch: 6| Step: 12
Training loss: 0.3118990842582564
Validation loss: 2.560457423490762

Epoch: 6| Step: 13
Training loss: 0.08326202622494891
Validation loss: 2.5400990460228865

Epoch: 417| Step: 0
Training loss: 0.422089239752598
Validation loss: 2.5695673260123786

Epoch: 6| Step: 1
Training loss: 0.11710520079682696
Validation loss: 2.5521844354576406

Epoch: 6| Step: 2
Training loss: 0.2516666676482354
Validation loss: 2.5473827784697907

Epoch: 6| Step: 3
Training loss: 0.2480421291107561
Validation loss: 2.555802625884803

Epoch: 6| Step: 4
Training loss: 0.26418553933760053
Validation loss: 2.5305258382096296

Epoch: 6| Step: 5
Training loss: 0.3536092307578575
Validation loss: 2.583640006602151

Epoch: 6| Step: 6
Training loss: 0.21791959570660072
Validation loss: 2.5181852619099363

Epoch: 6| Step: 7
Training loss: 0.3510995253566238
Validation loss: 2.5613676240855288

Epoch: 6| Step: 8
Training loss: 0.3491957791345347
Validation loss: 2.545912253076288

Epoch: 6| Step: 9
Training loss: 0.2814561829860117
Validation loss: 2.5534128275038253

Epoch: 6| Step: 10
Training loss: 0.18042864539668668
Validation loss: 2.5665143041557337

Epoch: 6| Step: 11
Training loss: 0.40095262860174924
Validation loss: 2.542765339734039

Epoch: 6| Step: 12
Training loss: 0.2869821513113646
Validation loss: 2.534279118213644

Epoch: 6| Step: 13
Training loss: 0.12023657393969871
Validation loss: 2.507799285188362

Epoch: 418| Step: 0
Training loss: 0.1763270434869093
Validation loss: 2.565247072434936

Epoch: 6| Step: 1
Training loss: 0.44133130002681864
Validation loss: 2.520474924961746

Epoch: 6| Step: 2
Training loss: 0.16667376940215584
Validation loss: 2.5297879526781495

Epoch: 6| Step: 3
Training loss: 0.1825125389331342
Validation loss: 2.5341800810222646

Epoch: 6| Step: 4
Training loss: 0.397080222708389
Validation loss: 2.557185048738972

Epoch: 6| Step: 5
Training loss: 0.19607510459069777
Validation loss: 2.550291546846425

Epoch: 6| Step: 6
Training loss: 0.3613952780516425
Validation loss: 2.564168989304768

Epoch: 6| Step: 7
Training loss: 0.22842620665139782
Validation loss: 2.549949155120032

Epoch: 6| Step: 8
Training loss: 0.2683610113724261
Validation loss: 2.586942824727331

Epoch: 6| Step: 9
Training loss: 0.1979968427252225
Validation loss: 2.55176791430333

Epoch: 6| Step: 10
Training loss: 0.16350095446151988
Validation loss: 2.5582669838900762

Epoch: 6| Step: 11
Training loss: 0.4612305727798438
Validation loss: 2.5621248946629063

Epoch: 6| Step: 12
Training loss: 0.3185416910688359
Validation loss: 2.5462116772025882

Epoch: 6| Step: 13
Training loss: 0.27112669675849216
Validation loss: 2.5420716180137846

Epoch: 419| Step: 0
Training loss: 0.24916236592385202
Validation loss: 2.548076994992809

Epoch: 6| Step: 1
Training loss: 0.3105003034111052
Validation loss: 2.5332948655730596

Epoch: 6| Step: 2
Training loss: 0.30182765411705165
Validation loss: 2.556639907039511

Epoch: 6| Step: 3
Training loss: 0.15529128637831074
Validation loss: 2.551543926185502

Epoch: 6| Step: 4
Training loss: 0.25845573118821624
Validation loss: 2.520142487945968

Epoch: 6| Step: 5
Training loss: 0.31872747940091295
Validation loss: 2.516449130054804

Epoch: 6| Step: 6
Training loss: 0.16235644115594314
Validation loss: 2.5105878543265243

Epoch: 6| Step: 7
Training loss: 0.19664490173381327
Validation loss: 2.5084863692143995

Epoch: 6| Step: 8
Training loss: 0.4797725440568288
Validation loss: 2.5569547615020554

Epoch: 6| Step: 9
Training loss: 0.30475030154009103
Validation loss: 2.559788559723852

Epoch: 6| Step: 10
Training loss: 0.3092532173481247
Validation loss: 2.527749218697329

Epoch: 6| Step: 11
Training loss: 0.3221034479995335
Validation loss: 2.539815266403993

Epoch: 6| Step: 12
Training loss: 0.3119628103784233
Validation loss: 2.5797086155820645

Epoch: 6| Step: 13
Training loss: 0.27303786365226523
Validation loss: 2.548124078399736

Epoch: 420| Step: 0
Training loss: 0.24904758859842457
Validation loss: 2.5561176697340984

Epoch: 6| Step: 1
Training loss: 0.377960164420873
Validation loss: 2.5139054123152587

Epoch: 6| Step: 2
Training loss: 0.3852432500915051
Validation loss: 2.503018625137147

Epoch: 6| Step: 3
Training loss: 0.3024054432304637
Validation loss: 2.517162103836043

Epoch: 6| Step: 4
Training loss: 0.20594098357349733
Validation loss: 2.4895810517564816

Epoch: 6| Step: 5
Training loss: 0.4108674740324011
Validation loss: 2.5201213664840556

Epoch: 6| Step: 6
Training loss: 0.33000263502051524
Validation loss: 2.5642648202633564

Epoch: 6| Step: 7
Training loss: 0.1322320427033634
Validation loss: 2.539762840645585

Epoch: 6| Step: 8
Training loss: 0.26176124910923104
Validation loss: 2.551874467557942

Epoch: 6| Step: 9
Training loss: 0.2605758021823511
Validation loss: 2.57484809394766

Epoch: 6| Step: 10
Training loss: 0.41901782993217745
Validation loss: 2.568756849579561

Epoch: 6| Step: 11
Training loss: 0.15197281427967194
Validation loss: 2.5639614536764808

Epoch: 6| Step: 12
Training loss: 0.12516186337259097
Validation loss: 2.5631948889988156

Epoch: 6| Step: 13
Training loss: 0.2341891426042054
Validation loss: 2.5959896297829483

Epoch: 421| Step: 0
Training loss: 0.3062689040635978
Validation loss: 2.5447174884976067

Epoch: 6| Step: 1
Training loss: 0.21846437539931987
Validation loss: 2.5658668011925396

Epoch: 6| Step: 2
Training loss: 0.25218753112736053
Validation loss: 2.5668577351892585

Epoch: 6| Step: 3
Training loss: 0.22572161570037932
Validation loss: 2.5584351949590793

Epoch: 6| Step: 4
Training loss: 0.312414038279166
Validation loss: 2.521577734494642

Epoch: 6| Step: 5
Training loss: 0.42269769560562775
Validation loss: 2.545666487751423

Epoch: 6| Step: 6
Training loss: 0.34628534589344706
Validation loss: 2.538088910129831

Epoch: 6| Step: 7
Training loss: 0.2468910924278051
Validation loss: 2.532454379983708

Epoch: 6| Step: 8
Training loss: 0.4084861175975044
Validation loss: 2.5371341947407413

Epoch: 6| Step: 9
Training loss: 0.21381399285665906
Validation loss: 2.5039341545409024

Epoch: 6| Step: 10
Training loss: 0.38379725479040716
Validation loss: 2.5094230207655404

Epoch: 6| Step: 11
Training loss: 0.2443737595373022
Validation loss: 2.569866626610128

Epoch: 6| Step: 12
Training loss: 0.14697216198606805
Validation loss: 2.55699007936638

Epoch: 6| Step: 13
Training loss: 0.21613064199323337
Validation loss: 2.590676771797738

Epoch: 422| Step: 0
Training loss: 0.19650203860538232
Validation loss: 2.591200822104599

Epoch: 6| Step: 1
Training loss: 0.25193817626608744
Validation loss: 2.5410262797597793

Epoch: 6| Step: 2
Training loss: 0.20925085956643047
Validation loss: 2.6112479648436757

Epoch: 6| Step: 3
Training loss: 0.3873614548071884
Validation loss: 2.5582125472072925

Epoch: 6| Step: 4
Training loss: 0.25648852156448626
Validation loss: 2.555477400921163

Epoch: 6| Step: 5
Training loss: 0.34013385010308317
Validation loss: 2.522942366478074

Epoch: 6| Step: 6
Training loss: 0.2670220493006118
Validation loss: 2.503315533899057

Epoch: 6| Step: 7
Training loss: 0.30360543236904597
Validation loss: 2.521370377908219

Epoch: 6| Step: 8
Training loss: 0.2970958941980044
Validation loss: 2.4955060170216825

Epoch: 6| Step: 9
Training loss: 0.39755922644013614
Validation loss: 2.4724295482628587

Epoch: 6| Step: 10
Training loss: 0.17521628612570544
Validation loss: 2.5182625603062205

Epoch: 6| Step: 11
Training loss: 0.28283478032650317
Validation loss: 2.535549876328423

Epoch: 6| Step: 12
Training loss: 0.3361988160199882
Validation loss: 2.5345227570453295

Epoch: 6| Step: 13
Training loss: 0.31614877090890886
Validation loss: 2.509418342318289

Epoch: 423| Step: 0
Training loss: 0.15189027540678587
Validation loss: 2.5519451911778215

Epoch: 6| Step: 1
Training loss: 0.2386787491602931
Validation loss: 2.562096730856482

Epoch: 6| Step: 2
Training loss: 0.2945845740335786
Validation loss: 2.5328788929649253

Epoch: 6| Step: 3
Training loss: 0.2137144231189531
Validation loss: 2.6172114947092573

Epoch: 6| Step: 4
Training loss: 0.2063368903265885
Validation loss: 2.5925012096006226

Epoch: 6| Step: 5
Training loss: 0.35820384550698137
Validation loss: 2.5565229349463574

Epoch: 6| Step: 6
Training loss: 0.1836434357959586
Validation loss: 2.572579753914282

Epoch: 6| Step: 7
Training loss: 0.3320983706679
Validation loss: 2.5776160669146044

Epoch: 6| Step: 8
Training loss: 0.33521449109868884
Validation loss: 2.5650803794692782

Epoch: 6| Step: 9
Training loss: 0.3215603016851407
Validation loss: 2.5502061115541994

Epoch: 6| Step: 10
Training loss: 0.2187438861809987
Validation loss: 2.5269539423365335

Epoch: 6| Step: 11
Training loss: 0.37035191322183714
Validation loss: 2.525376746644709

Epoch: 6| Step: 12
Training loss: 0.32739148577138794
Validation loss: 2.523848794954383

Epoch: 6| Step: 13
Training loss: 0.5092343305818509
Validation loss: 2.5241312515768235

Epoch: 424| Step: 0
Training loss: 0.30427486648594254
Validation loss: 2.5494707972539703

Epoch: 6| Step: 1
Training loss: 0.34683655964009036
Validation loss: 2.5542083518693293

Epoch: 6| Step: 2
Training loss: 0.27038087862002097
Validation loss: 2.5743744562949207

Epoch: 6| Step: 3
Training loss: 0.5018440454611505
Validation loss: 2.5505486009611427

Epoch: 6| Step: 4
Training loss: 0.28458590494244135
Validation loss: 2.618199241081688

Epoch: 6| Step: 5
Training loss: 0.16475905416598607
Validation loss: 2.592094693783665

Epoch: 6| Step: 6
Training loss: 0.3100806160863038
Validation loss: 2.57394577581524

Epoch: 6| Step: 7
Training loss: 0.22311003771069776
Validation loss: 2.534027267381348

Epoch: 6| Step: 8
Training loss: 0.19268512693497336
Validation loss: 2.5225705917789365

Epoch: 6| Step: 9
Training loss: 0.10837485941929483
Validation loss: 2.5134810810732615

Epoch: 6| Step: 10
Training loss: 0.30375244249531375
Validation loss: 2.5029417368180424

Epoch: 6| Step: 11
Training loss: 0.330196111234274
Validation loss: 2.476591745192719

Epoch: 6| Step: 12
Training loss: 0.2316946224041971
Validation loss: 2.4981949873501197

Epoch: 6| Step: 13
Training loss: 0.2163756376435588
Validation loss: 2.484074294809928

Epoch: 425| Step: 0
Training loss: 0.4012539557680882
Validation loss: 2.5021055665879093

Epoch: 6| Step: 1
Training loss: 0.22124808050659217
Validation loss: 2.519284761630618

Epoch: 6| Step: 2
Training loss: 0.19653904118367008
Validation loss: 2.541589963398755

Epoch: 6| Step: 3
Training loss: 0.48115450295516826
Validation loss: 2.53178666539344

Epoch: 6| Step: 4
Training loss: 0.20588609388127319
Validation loss: 2.5398212792779957

Epoch: 6| Step: 5
Training loss: 0.24414095306374442
Validation loss: 2.522088150324459

Epoch: 6| Step: 6
Training loss: 0.11638534505398009
Validation loss: 2.5262479003778022

Epoch: 6| Step: 7
Training loss: 0.2563122824830977
Validation loss: 2.546165930786576

Epoch: 6| Step: 8
Training loss: 0.3769980290207073
Validation loss: 2.5358152928561077

Epoch: 6| Step: 9
Training loss: 0.2750440811460014
Validation loss: 2.5118558306547984

Epoch: 6| Step: 10
Training loss: 0.19457645963322048
Validation loss: 2.4826181424405642

Epoch: 6| Step: 11
Training loss: 0.23409125318253624
Validation loss: 2.458226239301686

Epoch: 6| Step: 12
Training loss: 0.3412151072203142
Validation loss: 2.4793749020624376

Epoch: 6| Step: 13
Training loss: 0.19641802712260525
Validation loss: 2.483859396107033

Epoch: 426| Step: 0
Training loss: 0.29447848102789775
Validation loss: 2.5032844123890072

Epoch: 6| Step: 1
Training loss: 0.17151451780044033
Validation loss: 2.52162437405844

Epoch: 6| Step: 2
Training loss: 0.1999655358601227
Validation loss: 2.5343987101168572

Epoch: 6| Step: 3
Training loss: 0.32596391912754763
Validation loss: 2.582876249028288

Epoch: 6| Step: 4
Training loss: 0.29369592067371514
Validation loss: 2.580134272380718

Epoch: 6| Step: 5
Training loss: 0.3041578727043164
Validation loss: 2.556860149511861

Epoch: 6| Step: 6
Training loss: 0.36769957041182333
Validation loss: 2.561324263774106

Epoch: 6| Step: 7
Training loss: 0.2224574623807739
Validation loss: 2.525083398715879

Epoch: 6| Step: 8
Training loss: 0.3349619050748769
Validation loss: 2.5418708268072656

Epoch: 6| Step: 9
Training loss: 0.3220356438497593
Validation loss: 2.539688737375402

Epoch: 6| Step: 10
Training loss: 0.1380869186884486
Validation loss: 2.5463895774884016

Epoch: 6| Step: 11
Training loss: 0.31779150838178194
Validation loss: 2.5419373074828955

Epoch: 6| Step: 12
Training loss: 0.47959578690432186
Validation loss: 2.5440750620251067

Epoch: 6| Step: 13
Training loss: 0.2756809300703764
Validation loss: 2.5495423366708034

Epoch: 427| Step: 0
Training loss: 0.42899582419108184
Validation loss: 2.488159829668608

Epoch: 6| Step: 1
Training loss: 0.15981312957224925
Validation loss: 2.553131551906479

Epoch: 6| Step: 2
Training loss: 0.3480851817002437
Validation loss: 2.5480808141758944

Epoch: 6| Step: 3
Training loss: 0.39209162995536084
Validation loss: 2.5768568801343297

Epoch: 6| Step: 4
Training loss: 0.2927220768377533
Validation loss: 2.512613444286703

Epoch: 6| Step: 5
Training loss: 0.364718516582682
Validation loss: 2.576702107854353

Epoch: 6| Step: 6
Training loss: 0.3700971170182225
Validation loss: 2.552321672056727

Epoch: 6| Step: 7
Training loss: 0.2773980369628366
Validation loss: 2.601388559066805

Epoch: 6| Step: 8
Training loss: 0.30324108417924023
Validation loss: 2.611418133136106

Epoch: 6| Step: 9
Training loss: 0.21743554900550396
Validation loss: 2.5816473303512115

Epoch: 6| Step: 10
Training loss: 0.21799565426077794
Validation loss: 2.570510185901315

Epoch: 6| Step: 11
Training loss: 0.40832348012065023
Validation loss: 2.5713676787489783

Epoch: 6| Step: 12
Training loss: 0.24007027922005686
Validation loss: 2.5767810892360967

Epoch: 6| Step: 13
Training loss: 0.31726104748055484
Validation loss: 2.533718127779771

Epoch: 428| Step: 0
Training loss: 0.19346969039299025
Validation loss: 2.5049649507669516

Epoch: 6| Step: 1
Training loss: 0.347266010331411
Validation loss: 2.519045616306112

Epoch: 6| Step: 2
Training loss: 0.2476493924752895
Validation loss: 2.4685838694586395

Epoch: 6| Step: 3
Training loss: 0.30323930286164175
Validation loss: 2.489917781231998

Epoch: 6| Step: 4
Training loss: 0.2625991191376398
Validation loss: 2.464412604372677

Epoch: 6| Step: 5
Training loss: 0.2655730898005496
Validation loss: 2.456386118954966

Epoch: 6| Step: 6
Training loss: 0.20359595428585095
Validation loss: 2.48448136862263

Epoch: 6| Step: 7
Training loss: 0.2975096569377251
Validation loss: 2.4579372563162822

Epoch: 6| Step: 8
Training loss: 0.1936591262129803
Validation loss: 2.4592047989562955

Epoch: 6| Step: 9
Training loss: 0.4848581795937862
Validation loss: 2.4912984762078407

Epoch: 6| Step: 10
Training loss: 0.46420585717138685
Validation loss: 2.460909434502117

Epoch: 6| Step: 11
Training loss: 0.35122501281020335
Validation loss: 2.4850900882007765

Epoch: 6| Step: 12
Training loss: 0.2831118337883522
Validation loss: 2.481083428242462

Epoch: 6| Step: 13
Training loss: 0.22013417900190121
Validation loss: 2.512593382902601

Epoch: 429| Step: 0
Training loss: 0.26746251748310446
Validation loss: 2.5388672506704393

Epoch: 6| Step: 1
Training loss: 0.14094569144370614
Validation loss: 2.556704937799149

Epoch: 6| Step: 2
Training loss: 0.18015888827560012
Validation loss: 2.545386796528671

Epoch: 6| Step: 3
Training loss: 0.2592629322709225
Validation loss: 2.5335519032378064

Epoch: 6| Step: 4
Training loss: 0.442761930325424
Validation loss: 2.5193495207693366

Epoch: 6| Step: 5
Training loss: 0.3197703425331797
Validation loss: 2.533237376936481

Epoch: 6| Step: 6
Training loss: 0.34797395697998584
Validation loss: 2.5656960098120076

Epoch: 6| Step: 7
Training loss: 0.17828148693901452
Validation loss: 2.572931950154139

Epoch: 6| Step: 8
Training loss: 0.30285289044275404
Validation loss: 2.530509665250923

Epoch: 6| Step: 9
Training loss: 0.33272594257605015
Validation loss: 2.58989332555612

Epoch: 6| Step: 10
Training loss: 0.2167840558635259
Validation loss: 2.5397873871546963

Epoch: 6| Step: 11
Training loss: 0.3361959572086611
Validation loss: 2.5646917682599

Epoch: 6| Step: 12
Training loss: 0.35929282949035984
Validation loss: 2.5693844013761153

Epoch: 6| Step: 13
Training loss: 0.14034390833957652
Validation loss: 2.566808554434199

Epoch: 430| Step: 0
Training loss: 0.24634558795135403
Validation loss: 2.537628522117949

Epoch: 6| Step: 1
Training loss: 0.3066349271985999
Validation loss: 2.555743561622835

Epoch: 6| Step: 2
Training loss: 0.32226868830294203
Validation loss: 2.5601169656454754

Epoch: 6| Step: 3
Training loss: 0.2663814208690258
Validation loss: 2.549729563958156

Epoch: 6| Step: 4
Training loss: 0.17625685564363652
Validation loss: 2.5896993340162093

Epoch: 6| Step: 5
Training loss: 0.27540101376681436
Validation loss: 2.583963662281853

Epoch: 6| Step: 6
Training loss: 0.2466694818410698
Validation loss: 2.6319165537624962

Epoch: 6| Step: 7
Training loss: 0.27623883289533613
Validation loss: 2.6352400643744622

Epoch: 6| Step: 8
Training loss: 0.19069815076367472
Validation loss: 2.5867862317949024

Epoch: 6| Step: 9
Training loss: 0.3946896603269192
Validation loss: 2.5982147477484863

Epoch: 6| Step: 10
Training loss: 0.2864829905330597
Validation loss: 2.590565323211265

Epoch: 6| Step: 11
Training loss: 0.30511823187842113
Validation loss: 2.54682734691662

Epoch: 6| Step: 12
Training loss: 0.5115650907251638
Validation loss: 2.565023035032639

Epoch: 6| Step: 13
Training loss: 0.3018802530214698
Validation loss: 2.527789520614425

Epoch: 431| Step: 0
Training loss: 0.1859337437675036
Validation loss: 2.556960673914577

Epoch: 6| Step: 1
Training loss: 0.37495922820652144
Validation loss: 2.5918650176892095

Epoch: 6| Step: 2
Training loss: 0.2585002078833934
Validation loss: 2.601037234024125

Epoch: 6| Step: 3
Training loss: 0.15401740054345223
Validation loss: 2.567490408183401

Epoch: 6| Step: 4
Training loss: 0.31725266355684495
Validation loss: 2.6241858060057397

Epoch: 6| Step: 5
Training loss: 0.37747541622298336
Validation loss: 2.6189991283415845

Epoch: 6| Step: 6
Training loss: 0.28838404086690017
Validation loss: 2.6038258096085043

Epoch: 6| Step: 7
Training loss: 0.27175853799885136
Validation loss: 2.624690173802114

Epoch: 6| Step: 8
Training loss: 0.39939906458222213
Validation loss: 2.582949916227114

Epoch: 6| Step: 9
Training loss: 0.3197108409933554
Validation loss: 2.631997881518672

Epoch: 6| Step: 10
Training loss: 0.1450405940420102
Validation loss: 2.5620854430337516

Epoch: 6| Step: 11
Training loss: 0.2750507042480715
Validation loss: 2.536316240113264

Epoch: 6| Step: 12
Training loss: 0.3513284752020979
Validation loss: 2.564289915530435

Epoch: 6| Step: 13
Training loss: 0.2966794951327154
Validation loss: 2.5357709784921343

Epoch: 432| Step: 0
Training loss: 0.2911139712474264
Validation loss: 2.522238276736077

Epoch: 6| Step: 1
Training loss: 0.20175824308395598
Validation loss: 2.5223203026279886

Epoch: 6| Step: 2
Training loss: 0.23539765092687234
Validation loss: 2.5376986881005403

Epoch: 6| Step: 3
Training loss: 0.31799096163464746
Validation loss: 2.5496059974719643

Epoch: 6| Step: 4
Training loss: 0.2122874859225694
Validation loss: 2.5663198157867635

Epoch: 6| Step: 5
Training loss: 0.362592639266817
Validation loss: 2.5848539911793744

Epoch: 6| Step: 6
Training loss: 0.3739892729850269
Validation loss: 2.542542570079223

Epoch: 6| Step: 7
Training loss: 0.33218131320679095
Validation loss: 2.516709152359629

Epoch: 6| Step: 8
Training loss: 0.25797395274636126
Validation loss: 2.5059849287503577

Epoch: 6| Step: 9
Training loss: 0.25879846231915427
Validation loss: 2.4911144131109624

Epoch: 6| Step: 10
Training loss: 0.24128127520437198
Validation loss: 2.5169353064923294

Epoch: 6| Step: 11
Training loss: 0.36386230105089595
Validation loss: 2.5178067282632206

Epoch: 6| Step: 12
Training loss: 0.20475036223639187
Validation loss: 2.5150533373227586

Epoch: 6| Step: 13
Training loss: 0.42013750084822
Validation loss: 2.475116539883069

Epoch: 433| Step: 0
Training loss: 0.15190421177694008
Validation loss: 2.495563020382749

Epoch: 6| Step: 1
Training loss: 0.27025165203764645
Validation loss: 2.488109401680539

Epoch: 6| Step: 2
Training loss: 0.2886840817731623
Validation loss: 2.497054113815909

Epoch: 6| Step: 3
Training loss: 0.1831836991086625
Validation loss: 2.509527676203711

Epoch: 6| Step: 4
Training loss: 0.23607161291266524
Validation loss: 2.510155050208874

Epoch: 6| Step: 5
Training loss: 0.28789088224609144
Validation loss: 2.53359507861151

Epoch: 6| Step: 6
Training loss: 0.4294586959624648
Validation loss: 2.5223774226425313

Epoch: 6| Step: 7
Training loss: 0.373770964745779
Validation loss: 2.5083850994934127

Epoch: 6| Step: 8
Training loss: 0.1745609683585247
Validation loss: 2.5701268823494696

Epoch: 6| Step: 9
Training loss: 0.33174830329765853
Validation loss: 2.545295982297424

Epoch: 6| Step: 10
Training loss: 0.3044367027013837
Validation loss: 2.564465525040091

Epoch: 6| Step: 11
Training loss: 0.3921796759930631
Validation loss: 2.587033989960779

Epoch: 6| Step: 12
Training loss: 0.163136794104206
Validation loss: 2.5289813810788977

Epoch: 6| Step: 13
Training loss: 0.17311715879482678
Validation loss: 2.5172787015893827

Epoch: 434| Step: 0
Training loss: 0.18222872578439758
Validation loss: 2.5081628782062926

Epoch: 6| Step: 1
Training loss: 0.24176937587818653
Validation loss: 2.536790499103964

Epoch: 6| Step: 2
Training loss: 0.3063101962348688
Validation loss: 2.492797190128315

Epoch: 6| Step: 3
Training loss: 0.1923384445847023
Validation loss: 2.5410826738523973

Epoch: 6| Step: 4
Training loss: 0.4446286756756623
Validation loss: 2.543974385691686

Epoch: 6| Step: 5
Training loss: 0.22017155832981627
Validation loss: 2.521910726429357

Epoch: 6| Step: 6
Training loss: 0.19656413527931968
Validation loss: 2.5500005541082427

Epoch: 6| Step: 7
Training loss: 0.1842205427048599
Validation loss: 2.5645757472050015

Epoch: 6| Step: 8
Training loss: 0.35356531795021373
Validation loss: 2.5704024219015666

Epoch: 6| Step: 9
Training loss: 0.33660812862030737
Validation loss: 2.607986177864567

Epoch: 6| Step: 10
Training loss: 0.35254513848899144
Validation loss: 2.609348334071245

Epoch: 6| Step: 11
Training loss: 0.20613114805057398
Validation loss: 2.5708012180300535

Epoch: 6| Step: 12
Training loss: 0.30126906136796067
Validation loss: 2.58091533628422

Epoch: 6| Step: 13
Training loss: 0.3401465656301996
Validation loss: 2.5637598079804316

Epoch: 435| Step: 0
Training loss: 0.3258221172982055
Validation loss: 2.560994772389

Epoch: 6| Step: 1
Training loss: 0.13081311361849687
Validation loss: 2.5164535025397936

Epoch: 6| Step: 2
Training loss: 0.3765803851237114
Validation loss: 2.5207969214069808

Epoch: 6| Step: 3
Training loss: 0.2962067763267553
Validation loss: 2.4742537427779414

Epoch: 6| Step: 4
Training loss: 0.20971843110448096
Validation loss: 2.479311990412411

Epoch: 6| Step: 5
Training loss: 0.27671367640612493
Validation loss: 2.450496484151366

Epoch: 6| Step: 6
Training loss: 0.3297491070284838
Validation loss: 2.484773636516172

Epoch: 6| Step: 7
Training loss: 0.2247491650327166
Validation loss: 2.4594360083813656

Epoch: 6| Step: 8
Training loss: 0.3068774942463745
Validation loss: 2.493907525090208

Epoch: 6| Step: 9
Training loss: 0.261789668139667
Validation loss: 2.5307806378189146

Epoch: 6| Step: 10
Training loss: 0.4080846514188172
Validation loss: 2.532102780727475

Epoch: 6| Step: 11
Training loss: 0.28418650405940826
Validation loss: 2.5534583055379647

Epoch: 6| Step: 12
Training loss: 0.31562866218255214
Validation loss: 2.605463990648701

Epoch: 6| Step: 13
Training loss: 0.33464895460993416
Validation loss: 2.587195192907229

Epoch: 436| Step: 0
Training loss: 0.2697629623657297
Validation loss: 2.5825768827664186

Epoch: 6| Step: 1
Training loss: 0.23429019506331397
Validation loss: 2.5809585467529192

Epoch: 6| Step: 2
Training loss: 0.38910658406599086
Validation loss: 2.535205484568181

Epoch: 6| Step: 3
Training loss: 0.38674102102557284
Validation loss: 2.5512534953168475

Epoch: 6| Step: 4
Training loss: 0.3459621148970758
Validation loss: 2.491578123180931

Epoch: 6| Step: 5
Training loss: 0.2801789845668751
Validation loss: 2.5042716929973614

Epoch: 6| Step: 6
Training loss: 0.11846333822645339
Validation loss: 2.495395605197064

Epoch: 6| Step: 7
Training loss: 0.21020867569488783
Validation loss: 2.49291860492008

Epoch: 6| Step: 8
Training loss: 0.1820616610750303
Validation loss: 2.521894102782435

Epoch: 6| Step: 9
Training loss: 0.27283844039044663
Validation loss: 2.5258777720431915

Epoch: 6| Step: 10
Training loss: 0.34535363414062364
Validation loss: 2.5292565362858594

Epoch: 6| Step: 11
Training loss: 0.12788912443097455
Validation loss: 2.502345311986773

Epoch: 6| Step: 12
Training loss: 0.3072996650344533
Validation loss: 2.5116130939513903

Epoch: 6| Step: 13
Training loss: 0.21928561576856137
Validation loss: 2.5512678094406587

Epoch: 437| Step: 0
Training loss: 0.36481439443765923
Validation loss: 2.5346052944278075

Epoch: 6| Step: 1
Training loss: 0.1660895968175425
Validation loss: 2.581207786969108

Epoch: 6| Step: 2
Training loss: 0.3395971192543557
Validation loss: 2.587612362043336

Epoch: 6| Step: 3
Training loss: 0.26665458571119066
Validation loss: 2.638075610795337

Epoch: 6| Step: 4
Training loss: 0.35070237800176973
Validation loss: 2.5834522782278424

Epoch: 6| Step: 5
Training loss: 0.25593017006369817
Validation loss: 2.6123293629813893

Epoch: 6| Step: 6
Training loss: 0.17533833546250777
Validation loss: 2.584733939261969

Epoch: 6| Step: 7
Training loss: 0.3254456687614128
Validation loss: 2.5750669398787753

Epoch: 6| Step: 8
Training loss: 0.25489254636922537
Validation loss: 2.5809449187764355

Epoch: 6| Step: 9
Training loss: 0.23708564161898832
Validation loss: 2.540183125989857

Epoch: 6| Step: 10
Training loss: 0.1917352767822407
Validation loss: 2.5331655496006285

Epoch: 6| Step: 11
Training loss: 0.16183391975841024
Validation loss: 2.5088225579487307

Epoch: 6| Step: 12
Training loss: 0.30644247614153913
Validation loss: 2.5107412185054754

Epoch: 6| Step: 13
Training loss: 0.17875297760650843
Validation loss: 2.54915404743607

Epoch: 438| Step: 0
Training loss: 0.2629007578423156
Validation loss: 2.515886985462885

Epoch: 6| Step: 1
Training loss: 0.23010886105218206
Validation loss: 2.4817735876233735

Epoch: 6| Step: 2
Training loss: 0.18038225619603585
Validation loss: 2.526724196286744

Epoch: 6| Step: 3
Training loss: 0.36816964790296525
Validation loss: 2.538916964591984

Epoch: 6| Step: 4
Training loss: 0.2013980371947801
Validation loss: 2.5782596308115844

Epoch: 6| Step: 5
Training loss: 0.23336332847175983
Validation loss: 2.5763115584131175

Epoch: 6| Step: 6
Training loss: 0.4422237455522449
Validation loss: 2.6118100138672773

Epoch: 6| Step: 7
Training loss: 0.2503100796795629
Validation loss: 2.5841318355873133

Epoch: 6| Step: 8
Training loss: 0.29472691995385436
Validation loss: 2.5937679590126588

Epoch: 6| Step: 9
Training loss: 0.2644617048305777
Validation loss: 2.5661166560527624

Epoch: 6| Step: 10
Training loss: 0.21647183219837765
Validation loss: 2.6262947040238442

Epoch: 6| Step: 11
Training loss: 0.15128502615565734
Validation loss: 2.5596765760135316

Epoch: 6| Step: 12
Training loss: 0.1992359340960638
Validation loss: 2.5695470897153037

Epoch: 6| Step: 13
Training loss: 0.22535827840953368
Validation loss: 2.5802477716505687

Epoch: 439| Step: 0
Training loss: 0.3377535326904956
Validation loss: 2.5143158008504933

Epoch: 6| Step: 1
Training loss: 0.23854653646392998
Validation loss: 2.5631878497652227

Epoch: 6| Step: 2
Training loss: 0.2747853167226541
Validation loss: 2.5168807336843946

Epoch: 6| Step: 3
Training loss: 0.33689575145552875
Validation loss: 2.5776465266852475

Epoch: 6| Step: 4
Training loss: 0.3100738281352111
Validation loss: 2.551456713181669

Epoch: 6| Step: 5
Training loss: 0.24876051842193697
Validation loss: 2.5916513689508474

Epoch: 6| Step: 6
Training loss: 0.18883326481242452
Validation loss: 2.575067337606049

Epoch: 6| Step: 7
Training loss: 0.2702009202287817
Validation loss: 2.554451686611135

Epoch: 6| Step: 8
Training loss: 0.2344043395434093
Validation loss: 2.581989130305185

Epoch: 6| Step: 9
Training loss: 0.22321899306919452
Validation loss: 2.575914324983889

Epoch: 6| Step: 10
Training loss: 0.3880740029007475
Validation loss: 2.5417279717367847

Epoch: 6| Step: 11
Training loss: 0.3219741196464625
Validation loss: 2.5738543098519466

Epoch: 6| Step: 12
Training loss: 0.19790803530761356
Validation loss: 2.559180232488267

Epoch: 6| Step: 13
Training loss: 0.1541369007238776
Validation loss: 2.621784518299813

Epoch: 440| Step: 0
Training loss: 0.28250032235017464
Validation loss: 2.572716667855187

Epoch: 6| Step: 1
Training loss: 0.3063455242925509
Validation loss: 2.5580151195846894

Epoch: 6| Step: 2
Training loss: 0.3319086858388658
Validation loss: 2.553029559281186

Epoch: 6| Step: 3
Training loss: 0.2533437072492248
Validation loss: 2.5937509765306874

Epoch: 6| Step: 4
Training loss: 0.16535512016032372
Validation loss: 2.5754538920062937

Epoch: 6| Step: 5
Training loss: 0.14199443117491548
Validation loss: 2.5742591649210658

Epoch: 6| Step: 6
Training loss: 0.31217796899186057
Validation loss: 2.6233216720088683

Epoch: 6| Step: 7
Training loss: 0.2543991879203569
Validation loss: 2.5972915263837866

Epoch: 6| Step: 8
Training loss: 0.16360037295644658
Validation loss: 2.584819377860516

Epoch: 6| Step: 9
Training loss: 0.27209144066614516
Validation loss: 2.6278610898231882

Epoch: 6| Step: 10
Training loss: 0.3264382696447588
Validation loss: 2.5811641188297805

Epoch: 6| Step: 11
Training loss: 0.5152996076887737
Validation loss: 2.5778379895202277

Epoch: 6| Step: 12
Training loss: 0.27098295162741903
Validation loss: 2.55642341671199

Epoch: 6| Step: 13
Training loss: 0.24556147065630196
Validation loss: 2.5235558675123997

Epoch: 441| Step: 0
Training loss: 0.28023665715169155
Validation loss: 2.5243420882022933

Epoch: 6| Step: 1
Training loss: 0.1808325729119739
Validation loss: 2.484419837960321

Epoch: 6| Step: 2
Training loss: 0.2225548697440843
Validation loss: 2.4637321213489294

Epoch: 6| Step: 3
Training loss: 0.29379959550135704
Validation loss: 2.4474225978893926

Epoch: 6| Step: 4
Training loss: 0.21942995184680322
Validation loss: 2.4566899314969026

Epoch: 6| Step: 5
Training loss: 0.13247385748915685
Validation loss: 2.4592968179099546

Epoch: 6| Step: 6
Training loss: 0.21135202931927274
Validation loss: 2.4869601760463045

Epoch: 6| Step: 7
Training loss: 0.23149204184806402
Validation loss: 2.4807091417293003

Epoch: 6| Step: 8
Training loss: 0.30547901194864957
Validation loss: 2.5027838476398476

Epoch: 6| Step: 9
Training loss: 0.2103443105540261
Validation loss: 2.491851939379141

Epoch: 6| Step: 10
Training loss: 0.47546283295779684
Validation loss: 2.5101758480323486

Epoch: 6| Step: 11
Training loss: 0.4734030884175028
Validation loss: 2.489128062584005

Epoch: 6| Step: 12
Training loss: 0.21441290744074937
Validation loss: 2.506012034202648

Epoch: 6| Step: 13
Training loss: 0.2473166749031611
Validation loss: 2.5012487410177777

Epoch: 442| Step: 0
Training loss: 0.43324258691660794
Validation loss: 2.497586578448765

Epoch: 6| Step: 1
Training loss: 0.2960599074738411
Validation loss: 2.491516473501465

Epoch: 6| Step: 2
Training loss: 0.2737446694530069
Validation loss: 2.528238564926979

Epoch: 6| Step: 3
Training loss: 0.2084708544711122
Validation loss: 2.548877447507036

Epoch: 6| Step: 4
Training loss: 0.3393726811057546
Validation loss: 2.589698361897345

Epoch: 6| Step: 5
Training loss: 0.36987073035191453
Validation loss: 2.61140769170738

Epoch: 6| Step: 6
Training loss: 0.2185938482168439
Validation loss: 2.642378842398523

Epoch: 6| Step: 7
Training loss: 0.2729150549401796
Validation loss: 2.6391493354844107

Epoch: 6| Step: 8
Training loss: 0.36655605076338554
Validation loss: 2.6114007873436984

Epoch: 6| Step: 9
Training loss: 0.2881789235195853
Validation loss: 2.581685981578404

Epoch: 6| Step: 10
Training loss: 0.3040693566155948
Validation loss: 2.58410546126184

Epoch: 6| Step: 11
Training loss: 0.2577456763392353
Validation loss: 2.585567974260567

Epoch: 6| Step: 12
Training loss: 0.15156392263944263
Validation loss: 2.539118673935317

Epoch: 6| Step: 13
Training loss: 0.2673700456378717
Validation loss: 2.540735912178726

Epoch: 443| Step: 0
Training loss: 0.19447526777337046
Validation loss: 2.4801446259940874

Epoch: 6| Step: 1
Training loss: 0.2475773881327677
Validation loss: 2.492091006748844

Epoch: 6| Step: 2
Training loss: 0.25412665850881067
Validation loss: 2.4794058346151453

Epoch: 6| Step: 3
Training loss: 0.22569478699258747
Validation loss: 2.489816643818952

Epoch: 6| Step: 4
Training loss: 0.36743005897967307
Validation loss: 2.508187030759171

Epoch: 6| Step: 5
Training loss: 0.2533017224481048
Validation loss: 2.5260050233179734

Epoch: 6| Step: 6
Training loss: 0.2449882669826413
Validation loss: 2.5646165320039462

Epoch: 6| Step: 7
Training loss: 0.17422749685559763
Validation loss: 2.5589512022747916

Epoch: 6| Step: 8
Training loss: 0.1337229920574912
Validation loss: 2.5371268518089027

Epoch: 6| Step: 9
Training loss: 0.4143911353086873
Validation loss: 2.544427999329964

Epoch: 6| Step: 10
Training loss: 0.35639735905228587
Validation loss: 2.5433787381510244

Epoch: 6| Step: 11
Training loss: 0.3424750656950453
Validation loss: 2.543922166071684

Epoch: 6| Step: 12
Training loss: 0.2665734747877995
Validation loss: 2.5612998370870574

Epoch: 6| Step: 13
Training loss: 0.09684912447527491
Validation loss: 2.5584837991886196

Epoch: 444| Step: 0
Training loss: 0.13395883411276294
Validation loss: 2.5556298297588698

Epoch: 6| Step: 1
Training loss: 0.24172501859815754
Validation loss: 2.614424980443057

Epoch: 6| Step: 2
Training loss: 0.2555605038233505
Validation loss: 2.567852028639896

Epoch: 6| Step: 3
Training loss: 0.3301676566685047
Validation loss: 2.5837628339638257

Epoch: 6| Step: 4
Training loss: 0.3249032367112708
Validation loss: 2.590528889349739

Epoch: 6| Step: 5
Training loss: 0.2846023457758878
Validation loss: 2.53919625585483

Epoch: 6| Step: 6
Training loss: 0.20435315008050275
Validation loss: 2.550450192016234

Epoch: 6| Step: 7
Training loss: 0.237001728024903
Validation loss: 2.5375989468604603

Epoch: 6| Step: 8
Training loss: 0.22907787828228549
Validation loss: 2.543166813431042

Epoch: 6| Step: 9
Training loss: 0.2553692556865765
Validation loss: 2.4943070524268003

Epoch: 6| Step: 10
Training loss: 0.16310841296990564
Validation loss: 2.507971574207179

Epoch: 6| Step: 11
Training loss: 0.35881155874862763
Validation loss: 2.5294201494802384

Epoch: 6| Step: 12
Training loss: 0.264316618269622
Validation loss: 2.5156053947286545

Epoch: 6| Step: 13
Training loss: 0.20157543924480859
Validation loss: 2.542923225509612

Epoch: 445| Step: 0
Training loss: 0.15505796152474408
Validation loss: 2.5337944130372017

Epoch: 6| Step: 1
Training loss: 0.3581416277994762
Validation loss: 2.5790042783600087

Epoch: 6| Step: 2
Training loss: 0.26158904662146026
Validation loss: 2.6001403818024325

Epoch: 6| Step: 3
Training loss: 0.16160252052375396
Validation loss: 2.5889746943645293

Epoch: 6| Step: 4
Training loss: 0.24513381354493546
Validation loss: 2.586740833764923

Epoch: 6| Step: 5
Training loss: 0.15646298912281525
Validation loss: 2.5977889014845115

Epoch: 6| Step: 6
Training loss: 0.3138592009842759
Validation loss: 2.6039652914306686

Epoch: 6| Step: 7
Training loss: 0.26030878057490187
Validation loss: 2.5891024110785588

Epoch: 6| Step: 8
Training loss: 0.31189607438188205
Validation loss: 2.5470106062479743

Epoch: 6| Step: 9
Training loss: 0.33908463243245174
Validation loss: 2.5515892998827856

Epoch: 6| Step: 10
Training loss: 0.267246737243462
Validation loss: 2.566528148599662

Epoch: 6| Step: 11
Training loss: 0.287757712419096
Validation loss: 2.527121834440139

Epoch: 6| Step: 12
Training loss: 0.22294322142385828
Validation loss: 2.517851736546226

Epoch: 6| Step: 13
Training loss: 0.11169248068680988
Validation loss: 2.5276008025492174

Epoch: 446| Step: 0
Training loss: 0.2897878001622681
Validation loss: 2.5397942227469623

Epoch: 6| Step: 1
Training loss: 0.18628686612050868
Validation loss: 2.5046098661263962

Epoch: 6| Step: 2
Training loss: 0.2427211542522455
Validation loss: 2.5684506543625365

Epoch: 6| Step: 3
Training loss: 0.2135775970066216
Validation loss: 2.5790964205054308

Epoch: 6| Step: 4
Training loss: 0.18959543448033592
Validation loss: 2.557440614549038

Epoch: 6| Step: 5
Training loss: 0.3526598440789126
Validation loss: 2.5401236296534027

Epoch: 6| Step: 6
Training loss: 0.15591427976078287
Validation loss: 2.5495545472919257

Epoch: 6| Step: 7
Training loss: 0.2668213968471352
Validation loss: 2.536902499688824

Epoch: 6| Step: 8
Training loss: 0.21775231879091322
Validation loss: 2.557879841167774

Epoch: 6| Step: 9
Training loss: 0.20116274544453142
Validation loss: 2.5368342782483997

Epoch: 6| Step: 10
Training loss: 0.19676616438164155
Validation loss: 2.525669074396592

Epoch: 6| Step: 11
Training loss: 0.28647945355093585
Validation loss: 2.5515832268269603

Epoch: 6| Step: 12
Training loss: 0.24601599055166454
Validation loss: 2.534142824106748

Epoch: 6| Step: 13
Training loss: 0.40027233330239365
Validation loss: 2.53058120073501

Epoch: 447| Step: 0
Training loss: 0.2691248442033245
Validation loss: 2.5308932477468757

Epoch: 6| Step: 1
Training loss: 0.3201286090444814
Validation loss: 2.5613833900156626

Epoch: 6| Step: 2
Training loss: 0.22448376999727912
Validation loss: 2.5658604372108744

Epoch: 6| Step: 3
Training loss: 0.12664657408186047
Validation loss: 2.5506707593910107

Epoch: 6| Step: 4
Training loss: 0.2657168173577816
Validation loss: 2.543283623643003

Epoch: 6| Step: 5
Training loss: 0.24510375210237495
Validation loss: 2.5649236946755285

Epoch: 6| Step: 6
Training loss: 0.18744682511667843
Validation loss: 2.5940605992682424

Epoch: 6| Step: 7
Training loss: 0.2418538379283043
Validation loss: 2.6119977750632573

Epoch: 6| Step: 8
Training loss: 0.40357436706218275
Validation loss: 2.6137509294188495

Epoch: 6| Step: 9
Training loss: 0.21017990227374125
Validation loss: 2.585855008132949

Epoch: 6| Step: 10
Training loss: 0.19752268519071758
Validation loss: 2.5824897697438365

Epoch: 6| Step: 11
Training loss: 0.13083360190450027
Validation loss: 2.547671009141257

Epoch: 6| Step: 12
Training loss: 0.16615464616639633
Validation loss: 2.620316866823244

Epoch: 6| Step: 13
Training loss: 0.23850914734866677
Validation loss: 2.566588307135275

Epoch: 448| Step: 0
Training loss: 0.150182177015137
Validation loss: 2.5549670289742195

Epoch: 6| Step: 1
Training loss: 0.32106674758347004
Validation loss: 2.5820597861334607

Epoch: 6| Step: 2
Training loss: 0.15157925301802447
Validation loss: 2.560103404470058

Epoch: 6| Step: 3
Training loss: 0.2545221488220045
Validation loss: 2.5544319126583876

Epoch: 6| Step: 4
Training loss: 0.28637959380692546
Validation loss: 2.565381850437066

Epoch: 6| Step: 5
Training loss: 0.22777731541325646
Validation loss: 2.52118374992372

Epoch: 6| Step: 6
Training loss: 0.31320225963629983
Validation loss: 2.5696916665433798

Epoch: 6| Step: 7
Training loss: 0.1393042972339518
Validation loss: 2.52438608424875

Epoch: 6| Step: 8
Training loss: 0.23674824313757614
Validation loss: 2.5591014592227395

Epoch: 6| Step: 9
Training loss: 0.2031710920857846
Validation loss: 2.557270519540993

Epoch: 6| Step: 10
Training loss: 0.24169065672226298
Validation loss: 2.5803322778309448

Epoch: 6| Step: 11
Training loss: 0.11539575623484842
Validation loss: 2.558124632555021

Epoch: 6| Step: 12
Training loss: 0.24589634349800996
Validation loss: 2.5875894828765054

Epoch: 6| Step: 13
Training loss: 0.17181109193937472
Validation loss: 2.566115309353081

Epoch: 449| Step: 0
Training loss: 0.35990127093802726
Validation loss: 2.581858490492145

Epoch: 6| Step: 1
Training loss: 0.1899855692302229
Validation loss: 2.5941841453034913

Epoch: 6| Step: 2
Training loss: 0.2689420784372815
Validation loss: 2.6028453173654325

Epoch: 6| Step: 3
Training loss: 0.34139413266534213
Validation loss: 2.561212107482187

Epoch: 6| Step: 4
Training loss: 0.10539622373958538
Validation loss: 2.5483342076051274

Epoch: 6| Step: 5
Training loss: 0.3296523423454631
Validation loss: 2.5536401433168257

Epoch: 6| Step: 6
Training loss: 0.2256424738069448
Validation loss: 2.5723575580564617

Epoch: 6| Step: 7
Training loss: 0.14850291266458776
Validation loss: 2.573249551907654

Epoch: 6| Step: 8
Training loss: 0.23974919365706504
Validation loss: 2.6051250202186806

Epoch: 6| Step: 9
Training loss: 0.23038549859263852
Validation loss: 2.5882754836571302

Epoch: 6| Step: 10
Training loss: 0.14337964966974495
Validation loss: 2.571764082306038

Epoch: 6| Step: 11
Training loss: 0.31050072333041234
Validation loss: 2.5791816681435162

Epoch: 6| Step: 12
Training loss: 0.2837292486744764
Validation loss: 2.5542294554278087

Epoch: 6| Step: 13
Training loss: 0.21036673963051902
Validation loss: 2.5915048081078784

Epoch: 450| Step: 0
Training loss: 0.18660030478759745
Validation loss: 2.5991336149279225

Epoch: 6| Step: 1
Training loss: 0.2769680567968044
Validation loss: 2.5623929876537384

Epoch: 6| Step: 2
Training loss: 0.1042850526974286
Validation loss: 2.5935582249307574

Epoch: 6| Step: 3
Training loss: 0.23920268766669836
Validation loss: 2.620990128149408

Epoch: 6| Step: 4
Training loss: 0.15844430318217217
Validation loss: 2.6031395105127073

Epoch: 6| Step: 5
Training loss: 0.22289881961598962
Validation loss: 2.586155068499721

Epoch: 6| Step: 6
Training loss: 0.24171650371974976
Validation loss: 2.562124474414402

Epoch: 6| Step: 7
Training loss: 0.196983636295667
Validation loss: 2.571295274958076

Epoch: 6| Step: 8
Training loss: 0.33572821418839355
Validation loss: 2.525255915570213

Epoch: 6| Step: 9
Training loss: 0.34779410897136215
Validation loss: 2.5031589505498193

Epoch: 6| Step: 10
Training loss: 0.18884868156398588
Validation loss: 2.557139807416134

Epoch: 6| Step: 11
Training loss: 0.299463108572079
Validation loss: 2.53756761237044

Epoch: 6| Step: 12
Training loss: 0.35217048207879226
Validation loss: 2.4810954637965086

Epoch: 6| Step: 13
Training loss: 0.10693148171067934
Validation loss: 2.504069517021999

Epoch: 451| Step: 0
Training loss: 0.1430605018100373
Validation loss: 2.542789959087089

Epoch: 6| Step: 1
Training loss: 0.2119554312271539
Validation loss: 2.5929998861723127

Epoch: 6| Step: 2
Training loss: 0.20388739816622062
Validation loss: 2.597346019516212

Epoch: 6| Step: 3
Training loss: 0.33356845902782273
Validation loss: 2.6188385194511867

Epoch: 6| Step: 4
Training loss: 0.28652942237766227
Validation loss: 2.6081893601898916

Epoch: 6| Step: 5
Training loss: 0.21504223931206812
Validation loss: 2.5867157689935443

Epoch: 6| Step: 6
Training loss: 0.23091379934472023
Validation loss: 2.5616152036432243

Epoch: 6| Step: 7
Training loss: 0.22580143927359575
Validation loss: 2.5296186540118204

Epoch: 6| Step: 8
Training loss: 0.2059359276035696
Validation loss: 2.58589588163145

Epoch: 6| Step: 9
Training loss: 0.4090428635712256
Validation loss: 2.5278083133517177

Epoch: 6| Step: 10
Training loss: 0.12752200826096255
Validation loss: 2.519108422054795

Epoch: 6| Step: 11
Training loss: 0.31439426416183247
Validation loss: 2.5341760491865015

Epoch: 6| Step: 12
Training loss: 0.3516163572808071
Validation loss: 2.530757678429348

Epoch: 6| Step: 13
Training loss: 0.27868267362444393
Validation loss: 2.5480448838477194

Epoch: 452| Step: 0
Training loss: 0.20176909969991855
Validation loss: 2.5550850987226146

Epoch: 6| Step: 1
Training loss: 0.27042019798890415
Validation loss: 2.539655591481579

Epoch: 6| Step: 2
Training loss: 0.11656409385245983
Validation loss: 2.5125979294290763

Epoch: 6| Step: 3
Training loss: 0.1479125276398373
Validation loss: 2.5341893292837043

Epoch: 6| Step: 4
Training loss: 0.1925603753938134
Validation loss: 2.560315510853342

Epoch: 6| Step: 5
Training loss: 0.21718156038025166
Validation loss: 2.5113453283256906

Epoch: 6| Step: 6
Training loss: 0.21489694977040544
Validation loss: 2.5127422814487095

Epoch: 6| Step: 7
Training loss: 0.328396525889605
Validation loss: 2.525281543157269

Epoch: 6| Step: 8
Training loss: 0.2715714129882737
Validation loss: 2.5229831394320223

Epoch: 6| Step: 9
Training loss: 0.16219213969699964
Validation loss: 2.5135162101595343

Epoch: 6| Step: 10
Training loss: 0.26136429825706503
Validation loss: 2.549628742890745

Epoch: 6| Step: 11
Training loss: 0.3843848576095795
Validation loss: 2.532121728249485

Epoch: 6| Step: 12
Training loss: 0.25125086300260446
Validation loss: 2.530076168343216

Epoch: 6| Step: 13
Training loss: 0.2158415943544563
Validation loss: 2.5286293384513363

Epoch: 453| Step: 0
Training loss: 0.2616682857996865
Validation loss: 2.5203534339587588

Epoch: 6| Step: 1
Training loss: 0.20048014219684213
Validation loss: 2.507800218006893

Epoch: 6| Step: 2
Training loss: 0.3352793523041602
Validation loss: 2.4966912308194584

Epoch: 6| Step: 3
Training loss: 0.29623206689936327
Validation loss: 2.497133211020829

Epoch: 6| Step: 4
Training loss: 0.21515840550093002
Validation loss: 2.5038954370283837

Epoch: 6| Step: 5
Training loss: 0.27442360586493564
Validation loss: 2.5349937184743765

Epoch: 6| Step: 6
Training loss: 0.2172850533817348
Validation loss: 2.5589254234904106

Epoch: 6| Step: 7
Training loss: 0.1874652770792684
Validation loss: 2.546560705317383

Epoch: 6| Step: 8
Training loss: 0.26781309906704465
Validation loss: 2.548889445069092

Epoch: 6| Step: 9
Training loss: 0.25005626045419055
Validation loss: 2.5672593846977962

Epoch: 6| Step: 10
Training loss: 0.1930621010160908
Validation loss: 2.5662134647249624

Epoch: 6| Step: 11
Training loss: 0.17567194613257053
Validation loss: 2.5368327507761403

Epoch: 6| Step: 12
Training loss: 0.12164315828050971
Validation loss: 2.528759649783864

Epoch: 6| Step: 13
Training loss: 0.24077827631248486
Validation loss: 2.528443701511372

Epoch: 454| Step: 0
Training loss: 0.20551706297255445
Validation loss: 2.5066362147997725

Epoch: 6| Step: 1
Training loss: 0.19159517890025266
Validation loss: 2.5236457305243643

Epoch: 6| Step: 2
Training loss: 0.20728293001910877
Validation loss: 2.48017543937965

Epoch: 6| Step: 3
Training loss: 0.22278775129866435
Validation loss: 2.510667061235474

Epoch: 6| Step: 4
Training loss: 0.18759272190100137
Validation loss: 2.501757345589365

Epoch: 6| Step: 5
Training loss: 0.11749957968504786
Validation loss: 2.515159153363284

Epoch: 6| Step: 6
Training loss: 0.31090282936986646
Validation loss: 2.499772620371738

Epoch: 6| Step: 7
Training loss: 0.17738996399334864
Validation loss: 2.5125575817801074

Epoch: 6| Step: 8
Training loss: 0.14402402332953426
Validation loss: 2.53667880484769

Epoch: 6| Step: 9
Training loss: 0.4748642633393672
Validation loss: 2.529312988817796

Epoch: 6| Step: 10
Training loss: 0.21205668769783834
Validation loss: 2.5437242990238356

Epoch: 6| Step: 11
Training loss: 0.32736843170853774
Validation loss: 2.542330839349477

Epoch: 6| Step: 12
Training loss: 0.23993714871819297
Validation loss: 2.524705749036912

Epoch: 6| Step: 13
Training loss: 0.34748106196482964
Validation loss: 2.5881401881847865

Epoch: 455| Step: 0
Training loss: 0.37701785070494404
Validation loss: 2.56463907682272

Epoch: 6| Step: 1
Training loss: 0.4185835158637351
Validation loss: 2.5485498198690157

Epoch: 6| Step: 2
Training loss: 0.2335105530949627
Validation loss: 2.5393839193625536

Epoch: 6| Step: 3
Training loss: 0.1951742541282917
Validation loss: 2.5708166623455457

Epoch: 6| Step: 4
Training loss: 0.19493921848724782
Validation loss: 2.589343759672242

Epoch: 6| Step: 5
Training loss: 0.25069901969118485
Validation loss: 2.570945660015643

Epoch: 6| Step: 6
Training loss: 0.3182196164089869
Validation loss: 2.567067712091147

Epoch: 6| Step: 7
Training loss: 0.24890460002421738
Validation loss: 2.6050710716375525

Epoch: 6| Step: 8
Training loss: 0.15456769812327312
Validation loss: 2.562401656357883

Epoch: 6| Step: 9
Training loss: 0.29615279240616055
Validation loss: 2.564376637100124

Epoch: 6| Step: 10
Training loss: 0.2563388350649309
Validation loss: 2.5577446207458556

Epoch: 6| Step: 11
Training loss: 0.18220847593052283
Validation loss: 2.571135666555903

Epoch: 6| Step: 12
Training loss: 0.26381240208218876
Validation loss: 2.546179391504374

Epoch: 6| Step: 13
Training loss: 0.44533607353589955
Validation loss: 2.499133090998544

Epoch: 456| Step: 0
Training loss: 0.29022986304574033
Validation loss: 2.512231281154349

Epoch: 6| Step: 1
Training loss: 0.36265830496715723
Validation loss: 2.4632906995459716

Epoch: 6| Step: 2
Training loss: 0.285457530310125
Validation loss: 2.4760823691300313

Epoch: 6| Step: 3
Training loss: 0.3019789345433235
Validation loss: 2.4997631555572095

Epoch: 6| Step: 4
Training loss: 0.2241601515169435
Validation loss: 2.4598611686709564

Epoch: 6| Step: 5
Training loss: 0.2504999109732494
Validation loss: 2.524919514656152

Epoch: 6| Step: 6
Training loss: 0.23320989295429329
Validation loss: 2.538212316143479

Epoch: 6| Step: 7
Training loss: 0.23493986407848955
Validation loss: 2.542793941473658

Epoch: 6| Step: 8
Training loss: 0.2575984991437123
Validation loss: 2.557275568581842

Epoch: 6| Step: 9
Training loss: 0.24765562755374124
Validation loss: 2.5619654144104196

Epoch: 6| Step: 10
Training loss: 0.2347590002816783
Validation loss: 2.558065188965319

Epoch: 6| Step: 11
Training loss: 0.32234811594045476
Validation loss: 2.5409101277800676

Epoch: 6| Step: 12
Training loss: 0.21070198757499703
Validation loss: 2.5653227798770226

Epoch: 6| Step: 13
Training loss: 0.11919314368198138
Validation loss: 2.5274666318576076

Epoch: 457| Step: 0
Training loss: 0.20926152328382674
Validation loss: 2.534323873406672

Epoch: 6| Step: 1
Training loss: 0.3298613722560362
Validation loss: 2.5165448859411685

Epoch: 6| Step: 2
Training loss: 0.2320989721863032
Validation loss: 2.540790068463414

Epoch: 6| Step: 3
Training loss: 0.35136456745691225
Validation loss: 2.5555841887345605

Epoch: 6| Step: 4
Training loss: 0.34750814176187816
Validation loss: 2.5686438955116966

Epoch: 6| Step: 5
Training loss: 0.18763563098435326
Validation loss: 2.5057876995222133

Epoch: 6| Step: 6
Training loss: 0.34338700028215424
Validation loss: 2.5402151828622856

Epoch: 6| Step: 7
Training loss: 0.19664892734586153
Validation loss: 2.547543239041993

Epoch: 6| Step: 8
Training loss: 0.2712261975739712
Validation loss: 2.482253623085878

Epoch: 6| Step: 9
Training loss: 0.20890728250503746
Validation loss: 2.4627867340227323

Epoch: 6| Step: 10
Training loss: 0.2561343222709305
Validation loss: 2.5109941338081057

Epoch: 6| Step: 11
Training loss: 0.3110609058878105
Validation loss: 2.538832526886823

Epoch: 6| Step: 12
Training loss: 0.17687032080078538
Validation loss: 2.5041372551527767

Epoch: 6| Step: 13
Training loss: 0.15431961061071525
Validation loss: 2.5413828031791392

Epoch: 458| Step: 0
Training loss: 0.23732197074588327
Validation loss: 2.5217946635777975

Epoch: 6| Step: 1
Training loss: 0.15311255015150438
Validation loss: 2.5222429461419322

Epoch: 6| Step: 2
Training loss: 0.23096119270043503
Validation loss: 2.54421910279028

Epoch: 6| Step: 3
Training loss: 0.168192337618645
Validation loss: 2.5455298098344263

Epoch: 6| Step: 4
Training loss: 0.19980591841660664
Validation loss: 2.5790312784092233

Epoch: 6| Step: 5
Training loss: 0.30927121367430604
Validation loss: 2.6083935213252474

Epoch: 6| Step: 6
Training loss: 0.3230142394697528
Validation loss: 2.566213941246689

Epoch: 6| Step: 7
Training loss: 0.33948419997159446
Validation loss: 2.614421044410723

Epoch: 6| Step: 8
Training loss: 0.2942331495321806
Validation loss: 2.624061146052914

Epoch: 6| Step: 9
Training loss: 0.2570084112392128
Validation loss: 2.654409382023704

Epoch: 6| Step: 10
Training loss: 0.32048652155128793
Validation loss: 2.646312123499755

Epoch: 6| Step: 11
Training loss: 0.12567972356592172
Validation loss: 2.612529299976455

Epoch: 6| Step: 12
Training loss: 0.17486283597843671
Validation loss: 2.5745186589706943

Epoch: 6| Step: 13
Training loss: 0.1786457318026715
Validation loss: 2.5674682064272396

Epoch: 459| Step: 0
Training loss: 0.23816793905678654
Validation loss: 2.494169749393614

Epoch: 6| Step: 1
Training loss: 0.22842814735543895
Validation loss: 2.488882470656737

Epoch: 6| Step: 2
Training loss: 0.24320343954995435
Validation loss: 2.4909769099134977

Epoch: 6| Step: 3
Training loss: 0.33417080812234423
Validation loss: 2.515166241651412

Epoch: 6| Step: 4
Training loss: 0.3089889820203923
Validation loss: 2.515071171257677

Epoch: 6| Step: 5
Training loss: 0.25395985550981015
Validation loss: 2.530236487306551

Epoch: 6| Step: 6
Training loss: 0.13182786987486175
Validation loss: 2.5387948651612176

Epoch: 6| Step: 7
Training loss: 0.20757712967317776
Validation loss: 2.55659442343048

Epoch: 6| Step: 8
Training loss: 0.3151661625344857
Validation loss: 2.5480797195318017

Epoch: 6| Step: 9
Training loss: 0.28547921899099415
Validation loss: 2.5617929859376516

Epoch: 6| Step: 10
Training loss: 0.25510785337073644
Validation loss: 2.5196676970439666

Epoch: 6| Step: 11
Training loss: 0.2235511730717046
Validation loss: 2.568880243355089

Epoch: 6| Step: 12
Training loss: 0.17043831054360475
Validation loss: 2.51876712985514

Epoch: 6| Step: 13
Training loss: 0.24314611437638606
Validation loss: 2.4744951371515564

Epoch: 460| Step: 0
Training loss: 0.2463373537691011
Validation loss: 2.508149435262739

Epoch: 6| Step: 1
Training loss: 0.21545235522375655
Validation loss: 2.477311333971584

Epoch: 6| Step: 2
Training loss: 0.26465599640471393
Validation loss: 2.48943143005238

Epoch: 6| Step: 3
Training loss: 0.32327526188389105
Validation loss: 2.452095218985493

Epoch: 6| Step: 4
Training loss: 0.19241073328333563
Validation loss: 2.488670747364203

Epoch: 6| Step: 5
Training loss: 0.23795383659615593
Validation loss: 2.480521798497171

Epoch: 6| Step: 6
Training loss: 0.12645593265672175
Validation loss: 2.5053391653435293

Epoch: 6| Step: 7
Training loss: 0.1376201816961831
Validation loss: 2.531752848991921

Epoch: 6| Step: 8
Training loss: 0.1298610339154588
Validation loss: 2.552754590923034

Epoch: 6| Step: 9
Training loss: 0.2245368508720136
Validation loss: 2.560386846885978

Epoch: 6| Step: 10
Training loss: 0.3288526867452693
Validation loss: 2.546269967829806

Epoch: 6| Step: 11
Training loss: 0.3029281734229495
Validation loss: 2.55183410197698

Epoch: 6| Step: 12
Training loss: 0.17913052024241463
Validation loss: 2.568048770894344

Epoch: 6| Step: 13
Training loss: 0.21633823958006163
Validation loss: 2.5367546695953784

Epoch: 461| Step: 0
Training loss: 0.13611699235410943
Validation loss: 2.5268957073092495

Epoch: 6| Step: 1
Training loss: 0.3473151816332709
Validation loss: 2.4989102495714977

Epoch: 6| Step: 2
Training loss: 0.24250609454135755
Validation loss: 2.4829285127404446

Epoch: 6| Step: 3
Training loss: 0.1548119049545945
Validation loss: 2.5207227090922326

Epoch: 6| Step: 4
Training loss: 0.2994784465725852
Validation loss: 2.488236168409717

Epoch: 6| Step: 5
Training loss: 0.22234939880326274
Validation loss: 2.5330591030149003

Epoch: 6| Step: 6
Training loss: 0.18079975290656083
Validation loss: 2.5528996357268805

Epoch: 6| Step: 7
Training loss: 0.19685076534126336
Validation loss: 2.4942772271290354

Epoch: 6| Step: 8
Training loss: 0.31070561220719284
Validation loss: 2.5132215092138948

Epoch: 6| Step: 9
Training loss: 0.2251601225594722
Validation loss: 2.4838127887488786

Epoch: 6| Step: 10
Training loss: 0.32193887502694724
Validation loss: 2.520868452846691

Epoch: 6| Step: 11
Training loss: 0.2108713328817692
Validation loss: 2.5570047513863177

Epoch: 6| Step: 12
Training loss: 0.25478106693189656
Validation loss: 2.571597475820793

Epoch: 6| Step: 13
Training loss: 0.2769647614653381
Validation loss: 2.584976869949613

Epoch: 462| Step: 0
Training loss: 0.3107649319499227
Validation loss: 2.549599039370429

Epoch: 6| Step: 1
Training loss: 0.25944430333101226
Validation loss: 2.6298894256145164

Epoch: 6| Step: 2
Training loss: 0.26309121798488466
Validation loss: 2.623183597634186

Epoch: 6| Step: 3
Training loss: 0.24374523188744712
Validation loss: 2.6250551045108432

Epoch: 6| Step: 4
Training loss: 0.3230620743890233
Validation loss: 2.6236367926956947

Epoch: 6| Step: 5
Training loss: 0.40645667467637564
Validation loss: 2.6351733507387856

Epoch: 6| Step: 6
Training loss: 0.24420996634904898
Validation loss: 2.601116244260467

Epoch: 6| Step: 7
Training loss: 0.20166870911867013
Validation loss: 2.6159008572869995

Epoch: 6| Step: 8
Training loss: 0.34516530848333676
Validation loss: 2.554140910849649

Epoch: 6| Step: 9
Training loss: 0.3433163899149754
Validation loss: 2.5770261568793393

Epoch: 6| Step: 10
Training loss: 0.2383021830134625
Validation loss: 2.537477338669397

Epoch: 6| Step: 11
Training loss: 0.1866170837833878
Validation loss: 2.526133312461126

Epoch: 6| Step: 12
Training loss: 0.3438903023758442
Validation loss: 2.5242230004164288

Epoch: 6| Step: 13
Training loss: 0.40931688434922214
Validation loss: 2.52993020516491

Epoch: 463| Step: 0
Training loss: 0.22370333163569006
Validation loss: 2.444491266367431

Epoch: 6| Step: 1
Training loss: 0.23582080898513838
Validation loss: 2.487176949749309

Epoch: 6| Step: 2
Training loss: 0.29939225497523025
Validation loss: 2.507490050778349

Epoch: 6| Step: 3
Training loss: 0.36958389310496936
Validation loss: 2.5114926834653977

Epoch: 6| Step: 4
Training loss: 0.2875916847943243
Validation loss: 2.551099019256808

Epoch: 6| Step: 5
Training loss: 0.256264765825745
Validation loss: 2.5397747919322256

Epoch: 6| Step: 6
Training loss: 0.30459084567204564
Validation loss: 2.598682559993489

Epoch: 6| Step: 7
Training loss: 0.2514107062571337
Validation loss: 2.599269063102817

Epoch: 6| Step: 8
Training loss: 0.16761520237881747
Validation loss: 2.591142409399628

Epoch: 6| Step: 9
Training loss: 0.3229073118064831
Validation loss: 2.598157597854009

Epoch: 6| Step: 10
Training loss: 0.26618228682612305
Validation loss: 2.6074715000352557

Epoch: 6| Step: 11
Training loss: 0.3174984999869049
Validation loss: 2.6155273922288145

Epoch: 6| Step: 12
Training loss: 0.24867835725226756
Validation loss: 2.5877248982854315

Epoch: 6| Step: 13
Training loss: 0.1433560300847376
Validation loss: 2.5197763168479974

Epoch: 464| Step: 0
Training loss: 0.2306547303536682
Validation loss: 2.528076583459734

Epoch: 6| Step: 1
Training loss: 0.20999647327708754
Validation loss: 2.5074066067735155

Epoch: 6| Step: 2
Training loss: 0.24582646250552093
Validation loss: 2.5129876012749786

Epoch: 6| Step: 3
Training loss: 0.20972153077650155
Validation loss: 2.501009973459463

Epoch: 6| Step: 4
Training loss: 0.3103409090128145
Validation loss: 2.5137658719012155

Epoch: 6| Step: 5
Training loss: 0.3306254189133469
Validation loss: 2.526630571377939

Epoch: 6| Step: 6
Training loss: 0.2209567326156175
Validation loss: 2.4563547858882933

Epoch: 6| Step: 7
Training loss: 0.27793094101259236
Validation loss: 2.483300825372726

Epoch: 6| Step: 8
Training loss: 0.15411764914284493
Validation loss: 2.508965572015507

Epoch: 6| Step: 9
Training loss: 0.21153387781867442
Validation loss: 2.4652119938332318

Epoch: 6| Step: 10
Training loss: 0.3985001009961315
Validation loss: 2.50876077715155

Epoch: 6| Step: 11
Training loss: 0.14560518271138617
Validation loss: 2.5170461031311953

Epoch: 6| Step: 12
Training loss: 0.21441936192398092
Validation loss: 2.54023609032045

Epoch: 6| Step: 13
Training loss: 0.450437484778262
Validation loss: 2.610401013007915

Epoch: 465| Step: 0
Training loss: 0.29304363565223246
Validation loss: 2.5963589252730253

Epoch: 6| Step: 1
Training loss: 0.18252065218381758
Validation loss: 2.5582344675262556

Epoch: 6| Step: 2
Training loss: 0.2839141863908768
Validation loss: 2.564103220015853

Epoch: 6| Step: 3
Training loss: 0.3540665985368505
Validation loss: 2.5612640701796545

Epoch: 6| Step: 4
Training loss: 0.30862453162311104
Validation loss: 2.5040776433397336

Epoch: 6| Step: 5
Training loss: 0.2268430682638592
Validation loss: 2.4990084989260137

Epoch: 6| Step: 6
Training loss: 0.259393123774835
Validation loss: 2.459927510932538

Epoch: 6| Step: 7
Training loss: 0.19874980373192938
Validation loss: 2.4296676761021723

Epoch: 6| Step: 8
Training loss: 0.20365744278801248
Validation loss: 2.46157049140071

Epoch: 6| Step: 9
Training loss: 0.24056032599727728
Validation loss: 2.4513049276634336

Epoch: 6| Step: 10
Training loss: 0.3443497930325877
Validation loss: 2.4526398017395206

Epoch: 6| Step: 11
Training loss: 0.2660562856690883
Validation loss: 2.4294057244205804

Epoch: 6| Step: 12
Training loss: 0.2225563845957926
Validation loss: 2.4560721158398637

Epoch: 6| Step: 13
Training loss: 0.1910272368507686
Validation loss: 2.4953519065510497

Epoch: 466| Step: 0
Training loss: 0.14016925287903634
Validation loss: 2.4946439753574032

Epoch: 6| Step: 1
Training loss: 0.20497577474670794
Validation loss: 2.5357696005115655

Epoch: 6| Step: 2
Training loss: 0.22397557273576066
Validation loss: 2.5431783192936805

Epoch: 6| Step: 3
Training loss: 0.21861412733206181
Validation loss: 2.5403238162057074

Epoch: 6| Step: 4
Training loss: 0.1978153274659483
Validation loss: 2.504733539873329

Epoch: 6| Step: 5
Training loss: 0.30805048625782594
Validation loss: 2.518027310948788

Epoch: 6| Step: 6
Training loss: 0.3134883272334193
Validation loss: 2.5085534065825055

Epoch: 6| Step: 7
Training loss: 0.1588667209281664
Validation loss: 2.4890114500729115

Epoch: 6| Step: 8
Training loss: 0.27075401697498735
Validation loss: 2.436547804619021

Epoch: 6| Step: 9
Training loss: 0.26534257628455654
Validation loss: 2.4388276468766072

Epoch: 6| Step: 10
Training loss: 0.18682381774270995
Validation loss: 2.46907131190843

Epoch: 6| Step: 11
Training loss: 0.22675340107677167
Validation loss: 2.469164467087701

Epoch: 6| Step: 12
Training loss: 0.2998772697935272
Validation loss: 2.470134744989686

Epoch: 6| Step: 13
Training loss: 0.3363010524083894
Validation loss: 2.4781414854954336

Epoch: 467| Step: 0
Training loss: 0.17192162076512987
Validation loss: 2.457508101597627

Epoch: 6| Step: 1
Training loss: 0.35101779489634
Validation loss: 2.471614330739383

Epoch: 6| Step: 2
Training loss: 0.25540793975454074
Validation loss: 2.489148479935883

Epoch: 6| Step: 3
Training loss: 0.22293719753451266
Validation loss: 2.4686872734718963

Epoch: 6| Step: 4
Training loss: 0.14921966073122764
Validation loss: 2.5247703610067656

Epoch: 6| Step: 5
Training loss: 0.20675781474860294
Validation loss: 2.515110026087573

Epoch: 6| Step: 6
Training loss: 0.20739479355109952
Validation loss: 2.5543529598402337

Epoch: 6| Step: 7
Training loss: 0.2148089814229509
Validation loss: 2.5330791642457613

Epoch: 6| Step: 8
Training loss: 0.22746318157647571
Validation loss: 2.568097671344493

Epoch: 6| Step: 9
Training loss: 0.1840134956007977
Validation loss: 2.4943717339198463

Epoch: 6| Step: 10
Training loss: 0.19632309765646397
Validation loss: 2.50816169254811

Epoch: 6| Step: 11
Training loss: 0.3043822936216178
Validation loss: 2.5068268450141753

Epoch: 6| Step: 12
Training loss: 0.22470929784182872
Validation loss: 2.510200177304463

Epoch: 6| Step: 13
Training loss: 0.1774849976156675
Validation loss: 2.515303015174102

Epoch: 468| Step: 0
Training loss: 0.27904998430847716
Validation loss: 2.5264213899913353

Epoch: 6| Step: 1
Training loss: 0.23634756812199684
Validation loss: 2.505234138711127

Epoch: 6| Step: 2
Training loss: 0.18102151717078285
Validation loss: 2.4941350272392206

Epoch: 6| Step: 3
Training loss: 0.17671778526009088
Validation loss: 2.526847388292395

Epoch: 6| Step: 4
Training loss: 0.22392302426996274
Validation loss: 2.5123569848413405

Epoch: 6| Step: 5
Training loss: 0.1856595349858341
Validation loss: 2.507123992999838

Epoch: 6| Step: 6
Training loss: 0.12311741154421155
Validation loss: 2.5112459670448373

Epoch: 6| Step: 7
Training loss: 0.24198007160734078
Validation loss: 2.483163762405975

Epoch: 6| Step: 8
Training loss: 0.12592014261756446
Validation loss: 2.5323510428218845

Epoch: 6| Step: 9
Training loss: 0.1283798451275418
Validation loss: 2.4985408052029587

Epoch: 6| Step: 10
Training loss: 0.3295635975877848
Validation loss: 2.522842148540933

Epoch: 6| Step: 11
Training loss: 0.21740424503807265
Validation loss: 2.465468885066629

Epoch: 6| Step: 12
Training loss: 0.3054396808188126
Validation loss: 2.513230608146476

Epoch: 6| Step: 13
Training loss: 0.09165213211835697
Validation loss: 2.4966018860257617

Epoch: 469| Step: 0
Training loss: 0.127754411671602
Validation loss: 2.519047147948873

Epoch: 6| Step: 1
Training loss: 0.19563645199841162
Validation loss: 2.472359882703934

Epoch: 6| Step: 2
Training loss: 0.3109948388143647
Validation loss: 2.4783056957597442

Epoch: 6| Step: 3
Training loss: 0.16657118123389184
Validation loss: 2.4454073092918476

Epoch: 6| Step: 4
Training loss: 0.3212989643275538
Validation loss: 2.469392512451309

Epoch: 6| Step: 5
Training loss: 0.2170895499683474
Validation loss: 2.478196028977233

Epoch: 6| Step: 6
Training loss: 0.20064069006224922
Validation loss: 2.4835852396184843

Epoch: 6| Step: 7
Training loss: 0.18568974064348528
Validation loss: 2.532211627446896

Epoch: 6| Step: 8
Training loss: 0.2792221582948643
Validation loss: 2.5590592611596508

Epoch: 6| Step: 9
Training loss: 0.1461300888868199
Validation loss: 2.5663131047914303

Epoch: 6| Step: 10
Training loss: 0.2022477887136478
Validation loss: 2.56736040286367

Epoch: 6| Step: 11
Training loss: 0.191453246750229
Validation loss: 2.5696797446552173

Epoch: 6| Step: 12
Training loss: 0.14974572887801604
Validation loss: 2.5258579834778785

Epoch: 6| Step: 13
Training loss: 0.20924344449103152
Validation loss: 2.522247886412704

Epoch: 470| Step: 0
Training loss: 0.3456473332444724
Validation loss: 2.47781008152844

Epoch: 6| Step: 1
Training loss: 0.1136257835225829
Validation loss: 2.444616891942396

Epoch: 6| Step: 2
Training loss: 0.21272034791111158
Validation loss: 2.4780275801444285

Epoch: 6| Step: 3
Training loss: 0.2609419611018414
Validation loss: 2.438808665165871

Epoch: 6| Step: 4
Training loss: 0.3062353797264323
Validation loss: 2.424364367833062

Epoch: 6| Step: 5
Training loss: 0.18016621840822927
Validation loss: 2.4187111313025893

Epoch: 6| Step: 6
Training loss: 0.2124570754118021
Validation loss: 2.4230845643197654

Epoch: 6| Step: 7
Training loss: 0.11305318269089934
Validation loss: 2.460179347201814

Epoch: 6| Step: 8
Training loss: 0.1675960320017365
Validation loss: 2.499968456766626

Epoch: 6| Step: 9
Training loss: 0.26596119585717465
Validation loss: 2.4519507489436827

Epoch: 6| Step: 10
Training loss: 0.23766920562282354
Validation loss: 2.5007928831741215

Epoch: 6| Step: 11
Training loss: 0.21773261812429975
Validation loss: 2.5034932905329192

Epoch: 6| Step: 12
Training loss: 0.2758819039781131
Validation loss: 2.529872676043885

Epoch: 6| Step: 13
Training loss: 0.21597070761582562
Validation loss: 2.5013639820749494

Epoch: 471| Step: 0
Training loss: 0.18810723244607935
Validation loss: 2.510638769219653

Epoch: 6| Step: 1
Training loss: 0.2066711677232884
Validation loss: 2.4896170174984467

Epoch: 6| Step: 2
Training loss: 0.1912555101012285
Validation loss: 2.5113017382682945

Epoch: 6| Step: 3
Training loss: 0.21826519205969508
Validation loss: 2.4749768000207606

Epoch: 6| Step: 4
Training loss: 0.2649526501585128
Validation loss: 2.423305344998931

Epoch: 6| Step: 5
Training loss: 0.2643888967437375
Validation loss: 2.4722242352650023

Epoch: 6| Step: 6
Training loss: 0.2301822109562496
Validation loss: 2.430662411881546

Epoch: 6| Step: 7
Training loss: 0.3489636366237174
Validation loss: 2.458294092459225

Epoch: 6| Step: 8
Training loss: 0.21817544857902216
Validation loss: 2.4466720523921923

Epoch: 6| Step: 9
Training loss: 0.1491108229422039
Validation loss: 2.413941317631333

Epoch: 6| Step: 10
Training loss: 0.13266992629896376
Validation loss: 2.4478898042781534

Epoch: 6| Step: 11
Training loss: 0.16515818929481021
Validation loss: 2.4358444186716626

Epoch: 6| Step: 12
Training loss: 0.19019884643280077
Validation loss: 2.4354873764297

Epoch: 6| Step: 13
Training loss: 0.14880826722477383
Validation loss: 2.4892714038093993

Epoch: 472| Step: 0
Training loss: 0.11423530519952284
Validation loss: 2.453680817404095

Epoch: 6| Step: 1
Training loss: 0.18117024418079197
Validation loss: 2.4465641793089046

Epoch: 6| Step: 2
Training loss: 0.17830563011600545
Validation loss: 2.4634584285643726

Epoch: 6| Step: 3
Training loss: 0.2063063490360074
Validation loss: 2.4809947716926604

Epoch: 6| Step: 4
Training loss: 0.14522381404012238
Validation loss: 2.4779577915985076

Epoch: 6| Step: 5
Training loss: 0.16515386978498584
Validation loss: 2.4827631564288066

Epoch: 6| Step: 6
Training loss: 0.1842949442905849
Validation loss: 2.4720642675128173

Epoch: 6| Step: 7
Training loss: 0.08073038118228196
Validation loss: 2.4571378935710046

Epoch: 6| Step: 8
Training loss: 0.20723052600805802
Validation loss: 2.533605092958885

Epoch: 6| Step: 9
Training loss: 0.1298786535529361
Validation loss: 2.487252703064425

Epoch: 6| Step: 10
Training loss: 0.2945048687197261
Validation loss: 2.499147348718423

Epoch: 6| Step: 11
Training loss: 0.3784008982099817
Validation loss: 2.4831249094538372

Epoch: 6| Step: 12
Training loss: 0.20489407409322574
Validation loss: 2.491978109366666

Epoch: 6| Step: 13
Training loss: 0.16536482425481913
Validation loss: 2.48899743968341

Epoch: 473| Step: 0
Training loss: 0.09492212931281037
Validation loss: 2.5088016170867964

Epoch: 6| Step: 1
Training loss: 0.3158164944768877
Validation loss: 2.522551541265052

Epoch: 6| Step: 2
Training loss: 0.16756861733094874
Validation loss: 2.511918406913544

Epoch: 6| Step: 3
Training loss: 0.2325211801674737
Validation loss: 2.5097132686955406

Epoch: 6| Step: 4
Training loss: 0.2769656895422479
Validation loss: 2.5022159190019506

Epoch: 6| Step: 5
Training loss: 0.23547164734220374
Validation loss: 2.515106266922514

Epoch: 6| Step: 6
Training loss: 0.1544484408106788
Validation loss: 2.451934668832589

Epoch: 6| Step: 7
Training loss: 0.22133372530330378
Validation loss: 2.4711325387108256

Epoch: 6| Step: 8
Training loss: 0.12781439383393142
Validation loss: 2.464263251171312

Epoch: 6| Step: 9
Training loss: 0.11339868016599734
Validation loss: 2.4387398167908962

Epoch: 6| Step: 10
Training loss: 0.10899287980232815
Validation loss: 2.4616443932008867

Epoch: 6| Step: 11
Training loss: 0.14285905152348596
Validation loss: 2.3998830338657857

Epoch: 6| Step: 12
Training loss: 0.22273739791633146
Validation loss: 2.427396936677296

Epoch: 6| Step: 13
Training loss: 0.13056088323902337
Validation loss: 2.434745282663734

Epoch: 474| Step: 0
Training loss: 0.18487219368337415
Validation loss: 2.426127876345611

Epoch: 6| Step: 1
Training loss: 0.12766167908123227
Validation loss: 2.4651402419823185

Epoch: 6| Step: 2
Training loss: 0.17959252210801008
Validation loss: 2.479479467964867

Epoch: 6| Step: 3
Training loss: 0.2504386332129022
Validation loss: 2.4852242071277253

Epoch: 6| Step: 4
Training loss: 0.19762019593783506
Validation loss: 2.47903471675112

Epoch: 6| Step: 5
Training loss: 0.2501484757835025
Validation loss: 2.49136692789981

Epoch: 6| Step: 6
Training loss: 0.11897549755144096
Validation loss: 2.485324772232398

Epoch: 6| Step: 7
Training loss: 0.28715077575304476
Validation loss: 2.5069459160258147

Epoch: 6| Step: 8
Training loss: 0.1312877490049723
Validation loss: 2.5210921258852297

Epoch: 6| Step: 9
Training loss: 0.1973573263818698
Validation loss: 2.494167035859397

Epoch: 6| Step: 10
Training loss: 0.2633597610638283
Validation loss: 2.502684208425651

Epoch: 6| Step: 11
Training loss: 0.20236836324215546
Validation loss: 2.4868668478288893

Epoch: 6| Step: 12
Training loss: 0.11144900869717597
Validation loss: 2.4884958760463367

Epoch: 6| Step: 13
Training loss: 0.19556424129731276
Validation loss: 2.495229766138048

Epoch: 475| Step: 0
Training loss: 0.1469502289348252
Validation loss: 2.5145884616356806

Epoch: 6| Step: 1
Training loss: 0.14288620780845754
Validation loss: 2.492312620266753

Epoch: 6| Step: 2
Training loss: 0.1254166127544849
Validation loss: 2.4980622257202714

Epoch: 6| Step: 3
Training loss: 0.1476922652306786
Validation loss: 2.453154045974416

Epoch: 6| Step: 4
Training loss: 0.16783799582472284
Validation loss: 2.460886787898618

Epoch: 6| Step: 5
Training loss: 0.19859509930576216
Validation loss: 2.4841989578798103

Epoch: 6| Step: 6
Training loss: 0.33362673969322604
Validation loss: 2.471082290529939

Epoch: 6| Step: 7
Training loss: 0.2046993117527976
Validation loss: 2.475210522436018

Epoch: 6| Step: 8
Training loss: 0.11541274780705234
Validation loss: 2.4892307305880634

Epoch: 6| Step: 9
Training loss: 0.17376602863916277
Validation loss: 2.49248658456215

Epoch: 6| Step: 10
Training loss: 0.3101291005625736
Validation loss: 2.5121123443241085

Epoch: 6| Step: 11
Training loss: 0.2809187474850343
Validation loss: 2.5078578348515004

Epoch: 6| Step: 12
Training loss: 0.23065754867516813
Validation loss: 2.51163012758207

Epoch: 6| Step: 13
Training loss: 0.07085308905061227
Validation loss: 2.5162795090595416

Epoch: 476| Step: 0
Training loss: 0.17668255631797425
Validation loss: 2.4384313696614677

Epoch: 6| Step: 1
Training loss: 0.2213946959846622
Validation loss: 2.4776559268015177

Epoch: 6| Step: 2
Training loss: 0.4031030656332715
Validation loss: 2.483493695308802

Epoch: 6| Step: 3
Training loss: 0.24908507837073726
Validation loss: 2.487661304459815

Epoch: 6| Step: 4
Training loss: 0.13896559784095525
Validation loss: 2.4650897296978926

Epoch: 6| Step: 5
Training loss: 0.1394145714602769
Validation loss: 2.4980931470061027

Epoch: 6| Step: 6
Training loss: 0.14330872724635366
Validation loss: 2.4643132352760335

Epoch: 6| Step: 7
Training loss: 0.18267399113549962
Validation loss: 2.4828385188471636

Epoch: 6| Step: 8
Training loss: 0.12818107947772936
Validation loss: 2.5126380295179396

Epoch: 6| Step: 9
Training loss: 0.1466114256153457
Validation loss: 2.505661356257056

Epoch: 6| Step: 10
Training loss: 0.20411597205589443
Validation loss: 2.5189729726261847

Epoch: 6| Step: 11
Training loss: 0.1974316266772119
Validation loss: 2.5297410569952428

Epoch: 6| Step: 12
Training loss: 0.16248743944041508
Validation loss: 2.531348642412031

Epoch: 6| Step: 13
Training loss: 0.06794369197297674
Validation loss: 2.526888872333722

Epoch: 477| Step: 0
Training loss: 0.2786653889125029
Validation loss: 2.517466991792402

Epoch: 6| Step: 1
Training loss: 0.25951683348887017
Validation loss: 2.457659114974746

Epoch: 6| Step: 2
Training loss: 0.16676610287583823
Validation loss: 2.4659936298778806

Epoch: 6| Step: 3
Training loss: 0.10702689555283253
Validation loss: 2.438065399401153

Epoch: 6| Step: 4
Training loss: 0.24464613650130818
Validation loss: 2.4112605524072226

Epoch: 6| Step: 5
Training loss: 0.1341329457079448
Validation loss: 2.4660197610603842

Epoch: 6| Step: 6
Training loss: 0.1607314631151149
Validation loss: 2.461695397432682

Epoch: 6| Step: 7
Training loss: 0.22947743145192417
Validation loss: 2.4875856006883104

Epoch: 6| Step: 8
Training loss: 0.1718055953431638
Validation loss: 2.473760428854235

Epoch: 6| Step: 9
Training loss: 0.15582038707258
Validation loss: 2.487172339230869

Epoch: 6| Step: 10
Training loss: 0.1559785989217139
Validation loss: 2.481541677333536

Epoch: 6| Step: 11
Training loss: 0.1999271737067699
Validation loss: 2.4555388561865032

Epoch: 6| Step: 12
Training loss: 0.28274337018501294
Validation loss: 2.5180216924765144

Epoch: 6| Step: 13
Training loss: 0.34974774227817895
Validation loss: 2.4499608630029717

Epoch: 478| Step: 0
Training loss: 0.20465955252261017
Validation loss: 2.4730550712659944

Epoch: 6| Step: 1
Training loss: 0.24845715630942514
Validation loss: 2.481429719510911

Epoch: 6| Step: 2
Training loss: 0.12272039880220485
Validation loss: 2.4686121914481047

Epoch: 6| Step: 3
Training loss: 0.2184746490863977
Validation loss: 2.4977675293948156

Epoch: 6| Step: 4
Training loss: 0.18892258164113787
Validation loss: 2.475307142421012

Epoch: 6| Step: 5
Training loss: 0.15038409156974744
Validation loss: 2.4882294796646587

Epoch: 6| Step: 6
Training loss: 0.162469045505963
Validation loss: 2.45305741875869

Epoch: 6| Step: 7
Training loss: 0.19459178511223468
Validation loss: 2.477532826036652

Epoch: 6| Step: 8
Training loss: 0.32845059770697255
Validation loss: 2.470255672844202

Epoch: 6| Step: 9
Training loss: 0.12630754062490204
Validation loss: 2.4635792221005723

Epoch: 6| Step: 10
Training loss: 0.24411368412144935
Validation loss: 2.505281842075796

Epoch: 6| Step: 11
Training loss: 0.33301173904207143
Validation loss: 2.546412420097404

Epoch: 6| Step: 12
Training loss: 0.10695306609370168
Validation loss: 2.522046403333065

Epoch: 6| Step: 13
Training loss: 0.2156971972990175
Validation loss: 2.5382998776560255

Epoch: 479| Step: 0
Training loss: 0.17759963577024812
Validation loss: 2.5157974480611123

Epoch: 6| Step: 1
Training loss: 0.1533512278689259
Validation loss: 2.5465312146700687

Epoch: 6| Step: 2
Training loss: 0.22304508489100863
Validation loss: 2.5119206777268874

Epoch: 6| Step: 3
Training loss: 0.1878729330128095
Validation loss: 2.507555449347725

Epoch: 6| Step: 4
Training loss: 0.3019088441227744
Validation loss: 2.4768143853113616

Epoch: 6| Step: 5
Training loss: 0.16249170373866348
Validation loss: 2.472293472238846

Epoch: 6| Step: 6
Training loss: 0.285433125311411
Validation loss: 2.4814696093906035

Epoch: 6| Step: 7
Training loss: 0.20768644912688047
Validation loss: 2.4428738039209485

Epoch: 6| Step: 8
Training loss: 0.2738397500567573
Validation loss: 2.4537797896152678

Epoch: 6| Step: 9
Training loss: 0.16624499351986938
Validation loss: 2.448871329695966

Epoch: 6| Step: 10
Training loss: 0.23488233810166273
Validation loss: 2.4608757744421763

Epoch: 6| Step: 11
Training loss: 0.14935090718637165
Validation loss: 2.460655159484943

Epoch: 6| Step: 12
Training loss: 0.22797337614284924
Validation loss: 2.439133913951095

Epoch: 6| Step: 13
Training loss: 0.3234264620680447
Validation loss: 2.458695730323431

Epoch: 480| Step: 0
Training loss: 0.16815728318996367
Validation loss: 2.4538241753112353

Epoch: 6| Step: 1
Training loss: 0.29890854694542773
Validation loss: 2.4931381788054487

Epoch: 6| Step: 2
Training loss: 0.1303114736868788
Validation loss: 2.4575686964569603

Epoch: 6| Step: 3
Training loss: 0.1518301252700715
Validation loss: 2.479339882754084

Epoch: 6| Step: 4
Training loss: 0.29528761915317464
Validation loss: 2.4745302198422188

Epoch: 6| Step: 5
Training loss: 0.14873983938512725
Validation loss: 2.5053209050079657

Epoch: 6| Step: 6
Training loss: 0.09238230420833707
Validation loss: 2.5218342407859122

Epoch: 6| Step: 7
Training loss: 0.18053953673348194
Validation loss: 2.514791672272415

Epoch: 6| Step: 8
Training loss: 0.14280052997792295
Validation loss: 2.5072161888419697

Epoch: 6| Step: 9
Training loss: 0.18087925853145043
Validation loss: 2.4784395415397915

Epoch: 6| Step: 10
Training loss: 0.2254832475776922
Validation loss: 2.5073026125272793

Epoch: 6| Step: 11
Training loss: 0.22470777263626812
Validation loss: 2.4995452508284006

Epoch: 6| Step: 12
Training loss: 0.1901697781530028
Validation loss: 2.5059704930541224

Epoch: 6| Step: 13
Training loss: 0.2341241129518763
Validation loss: 2.48030224984875

Epoch: 481| Step: 0
Training loss: 0.21237673550278913
Validation loss: 2.4886678769207107

Epoch: 6| Step: 1
Training loss: 0.13013536952070887
Validation loss: 2.4560440584170187

Epoch: 6| Step: 2
Training loss: 0.23696229511330005
Validation loss: 2.463523102066225

Epoch: 6| Step: 3
Training loss: 0.16698691153417977
Validation loss: 2.479005368008475

Epoch: 6| Step: 4
Training loss: 0.11531233574951176
Validation loss: 2.476881685783175

Epoch: 6| Step: 5
Training loss: 0.27756973247472305
Validation loss: 2.475420764910224

Epoch: 6| Step: 6
Training loss: 0.19132145151545946
Validation loss: 2.47767147628527

Epoch: 6| Step: 7
Training loss: 0.11535567833378046
Validation loss: 2.4790547105123353

Epoch: 6| Step: 8
Training loss: 0.19905296608268003
Validation loss: 2.474564976732626

Epoch: 6| Step: 9
Training loss: 0.2913013182398757
Validation loss: 2.4760106356500025

Epoch: 6| Step: 10
Training loss: 0.14525822220525356
Validation loss: 2.493253353116942

Epoch: 6| Step: 11
Training loss: 0.31350035294903805
Validation loss: 2.516734939300541

Epoch: 6| Step: 12
Training loss: 0.23549962431782523
Validation loss: 2.4999081369155274

Epoch: 6| Step: 13
Training loss: 0.17240444912850636
Validation loss: 2.516112504346869

Epoch: 482| Step: 0
Training loss: 0.190502563617007
Validation loss: 2.55717581246417

Epoch: 6| Step: 1
Training loss: 0.26861837845598674
Validation loss: 2.5275555205722195

Epoch: 6| Step: 2
Training loss: 0.2823750722259389
Validation loss: 2.479402408023654

Epoch: 6| Step: 3
Training loss: 0.1394707943704304
Validation loss: 2.477090884985217

Epoch: 6| Step: 4
Training loss: 0.17146316953337698
Validation loss: 2.4617099584207685

Epoch: 6| Step: 5
Training loss: 0.17868705756728753
Validation loss: 2.4506591459336957

Epoch: 6| Step: 6
Training loss: 0.2637550364144535
Validation loss: 2.4294871485819636

Epoch: 6| Step: 7
Training loss: 0.20065841145547653
Validation loss: 2.4041725804247354

Epoch: 6| Step: 8
Training loss: 0.164038866475277
Validation loss: 2.422270180451755

Epoch: 6| Step: 9
Training loss: 0.2987743404081423
Validation loss: 2.398304026373892

Epoch: 6| Step: 10
Training loss: 0.13134662103067737
Validation loss: 2.440530200266426

Epoch: 6| Step: 11
Training loss: 0.1880396785080147
Validation loss: 2.4052614829902237

Epoch: 6| Step: 12
Training loss: 0.23726557970596096
Validation loss: 2.433679907078919

Epoch: 6| Step: 13
Training loss: 0.4209986166987946
Validation loss: 2.443048855705293

Epoch: 483| Step: 0
Training loss: 0.267525744358015
Validation loss: 2.47145033819895

Epoch: 6| Step: 1
Training loss: 0.29859755852474695
Validation loss: 2.435392127797693

Epoch: 6| Step: 2
Training loss: 0.2251731266100503
Validation loss: 2.472857903306221

Epoch: 6| Step: 3
Training loss: 0.1863327849503172
Validation loss: 2.4660354753985203

Epoch: 6| Step: 4
Training loss: 0.23682316249372953
Validation loss: 2.5011164459086683

Epoch: 6| Step: 5
Training loss: 0.15435988310687704
Validation loss: 2.457222005499572

Epoch: 6| Step: 6
Training loss: 0.11326860899934084
Validation loss: 2.459134354260675

Epoch: 6| Step: 7
Training loss: 0.1610608604926499
Validation loss: 2.509081592778549

Epoch: 6| Step: 8
Training loss: 0.13051022024711018
Validation loss: 2.499085027142387

Epoch: 6| Step: 9
Training loss: 0.28154453114404543
Validation loss: 2.4747359423637856

Epoch: 6| Step: 10
Training loss: 0.1354010982611867
Validation loss: 2.4930273104265335

Epoch: 6| Step: 11
Training loss: 0.19276578901552463
Validation loss: 2.5250689138216886

Epoch: 6| Step: 12
Training loss: 0.20223842221330443
Validation loss: 2.5705437786658027

Epoch: 6| Step: 13
Training loss: 0.22643573272851442
Validation loss: 2.5256233669903567

Epoch: 484| Step: 0
Training loss: 0.221166883039716
Validation loss: 2.554954604909577

Epoch: 6| Step: 1
Training loss: 0.1551700823861538
Validation loss: 2.512833371322855

Epoch: 6| Step: 2
Training loss: 0.19382849533740654
Validation loss: 2.4751229429778943

Epoch: 6| Step: 3
Training loss: 0.3645231288065773
Validation loss: 2.4492344392014687

Epoch: 6| Step: 4
Training loss: 0.28456066589133044
Validation loss: 2.472004141534515

Epoch: 6| Step: 5
Training loss: 0.13170820335393638
Validation loss: 2.4606439657922667

Epoch: 6| Step: 6
Training loss: 0.32689771011702284
Validation loss: 2.4565103055151636

Epoch: 6| Step: 7
Training loss: 0.21044429764448216
Validation loss: 2.455018822009895

Epoch: 6| Step: 8
Training loss: 0.19730361723699247
Validation loss: 2.490724549602174

Epoch: 6| Step: 9
Training loss: 0.24212741875658922
Validation loss: 2.451009187625725

Epoch: 6| Step: 10
Training loss: 0.24583232709037536
Validation loss: 2.495699612967312

Epoch: 6| Step: 11
Training loss: 0.14078425952476237
Validation loss: 2.4792015543387604

Epoch: 6| Step: 12
Training loss: 0.1793104964423906
Validation loss: 2.465721500235905

Epoch: 6| Step: 13
Training loss: 0.1450850791373745
Validation loss: 2.438393112900012

Epoch: 485| Step: 0
Training loss: 0.20916058785285985
Validation loss: 2.4322382063876593

Epoch: 6| Step: 1
Training loss: 0.2978781391231318
Validation loss: 2.4275805718195893

Epoch: 6| Step: 2
Training loss: 0.2421748942509335
Validation loss: 2.4215485055358026

Epoch: 6| Step: 3
Training loss: 0.20806386129816856
Validation loss: 2.443743675879833

Epoch: 6| Step: 4
Training loss: 0.2442648990956815
Validation loss: 2.415626368449095

Epoch: 6| Step: 5
Training loss: 0.12153339945377663
Validation loss: 2.441704344305628

Epoch: 6| Step: 6
Training loss: 0.10693121606979086
Validation loss: 2.4059179380815894

Epoch: 6| Step: 7
Training loss: 0.17662814953770556
Validation loss: 2.4466432888671883

Epoch: 6| Step: 8
Training loss: 0.311468388587556
Validation loss: 2.4383784137247364

Epoch: 6| Step: 9
Training loss: 0.18081577220333286
Validation loss: 2.4127518216345334

Epoch: 6| Step: 10
Training loss: 0.3558847487413743
Validation loss: 2.486790604936112

Epoch: 6| Step: 11
Training loss: 0.14417803622581493
Validation loss: 2.4976584081877076

Epoch: 6| Step: 12
Training loss: 0.14237703879414626
Validation loss: 2.4770835265503277

Epoch: 6| Step: 13
Training loss: 0.24835724824016997
Validation loss: 2.5350677895980613

Epoch: 486| Step: 0
Training loss: 0.3243934666149146
Validation loss: 2.477087018446065

Epoch: 6| Step: 1
Training loss: 0.19000850953320542
Validation loss: 2.432845595901946

Epoch: 6| Step: 2
Training loss: 0.17995379245584922
Validation loss: 2.4755343759708266

Epoch: 6| Step: 3
Training loss: 0.188251430081132
Validation loss: 2.460548650644831

Epoch: 6| Step: 4
Training loss: 0.15915467937585073
Validation loss: 2.517662469074477

Epoch: 6| Step: 5
Training loss: 0.19539129575105563
Validation loss: 2.474422718929233

Epoch: 6| Step: 6
Training loss: 0.26604455182824416
Validation loss: 2.5416647677227036

Epoch: 6| Step: 7
Training loss: 0.12183181352108806
Validation loss: 2.5328432429438457

Epoch: 6| Step: 8
Training loss: 0.3051982169487315
Validation loss: 2.5305616444725842

Epoch: 6| Step: 9
Training loss: 0.28102531995426777
Validation loss: 2.5413456553884703

Epoch: 6| Step: 10
Training loss: 0.23185600187510114
Validation loss: 2.4983182757411613

Epoch: 6| Step: 11
Training loss: 0.20496777790069956
Validation loss: 2.4695430970284344

Epoch: 6| Step: 12
Training loss: 0.1755609085014946
Validation loss: 2.443829866410341

Epoch: 6| Step: 13
Training loss: 0.3018701708350114
Validation loss: 2.4389409751011155

Epoch: 487| Step: 0
Training loss: 0.2833752865211442
Validation loss: 2.453785001977681

Epoch: 6| Step: 1
Training loss: 0.14883607758027917
Validation loss: 2.4943502308215555

Epoch: 6| Step: 2
Training loss: 0.14845113315215644
Validation loss: 2.4712401531836474

Epoch: 6| Step: 3
Training loss: 0.25199777370180937
Validation loss: 2.509812100258143

Epoch: 6| Step: 4
Training loss: 0.1992668766905804
Validation loss: 2.5109580740369815

Epoch: 6| Step: 5
Training loss: 0.17843645414523593
Validation loss: 2.5427789404462806

Epoch: 6| Step: 6
Training loss: 0.3121597464237046
Validation loss: 2.5137765776557037

Epoch: 6| Step: 7
Training loss: 0.19474153030706381
Validation loss: 2.5465810840068173

Epoch: 6| Step: 8
Training loss: 0.15262206648523227
Validation loss: 2.5021041111526827

Epoch: 6| Step: 9
Training loss: 0.13900275447143698
Validation loss: 2.4995006759940623

Epoch: 6| Step: 10
Training loss: 0.1968823287750244
Validation loss: 2.4695908503528554

Epoch: 6| Step: 11
Training loss: 0.29580868407882577
Validation loss: 2.5120723348349943

Epoch: 6| Step: 12
Training loss: 0.3231289483720098
Validation loss: 2.487641083073201

Epoch: 6| Step: 13
Training loss: 0.25791749839052885
Validation loss: 2.493551065312467

Epoch: 488| Step: 0
Training loss: 0.24769135776858545
Validation loss: 2.5095238609183754

Epoch: 6| Step: 1
Training loss: 0.18426464140131443
Validation loss: 2.525923270844539

Epoch: 6| Step: 2
Training loss: 0.13161172521295925
Validation loss: 2.543771489199165

Epoch: 6| Step: 3
Training loss: 0.1594319363411756
Validation loss: 2.563200435957278

Epoch: 6| Step: 4
Training loss: 0.2648276535138916
Validation loss: 2.574574274380487

Epoch: 6| Step: 5
Training loss: 0.2199228384969146
Validation loss: 2.5315494621007724

Epoch: 6| Step: 6
Training loss: 0.14277498815818995
Validation loss: 2.535903592728036

Epoch: 6| Step: 7
Training loss: 0.23381650663214662
Validation loss: 2.5553415642866706

Epoch: 6| Step: 8
Training loss: 0.26895743947332423
Validation loss: 2.5118308080839338

Epoch: 6| Step: 9
Training loss: 0.2174769380280288
Validation loss: 2.4999063638358825

Epoch: 6| Step: 10
Training loss: 0.10764264914992881
Validation loss: 2.470915633068787

Epoch: 6| Step: 11
Training loss: 0.26573790226455546
Validation loss: 2.485260775930431

Epoch: 6| Step: 12
Training loss: 0.15037268989925814
Validation loss: 2.454915201500226

Epoch: 6| Step: 13
Training loss: 0.17002262767796433
Validation loss: 2.46288534134928

Epoch: 489| Step: 0
Training loss: 0.19958743405924256
Validation loss: 2.439677326955086

Epoch: 6| Step: 1
Training loss: 0.14684551227077963
Validation loss: 2.462595852621396

Epoch: 6| Step: 2
Training loss: 0.18446597424951505
Validation loss: 2.476577809982204

Epoch: 6| Step: 3
Training loss: 0.252086781380982
Validation loss: 2.4694778638368646

Epoch: 6| Step: 4
Training loss: 0.16042238314050156
Validation loss: 2.5018665708323264

Epoch: 6| Step: 5
Training loss: 0.14223076036518742
Validation loss: 2.4996915770575194

Epoch: 6| Step: 6
Training loss: 0.09468853078885402
Validation loss: 2.5828226833846117

Epoch: 6| Step: 7
Training loss: 0.1898052247128732
Validation loss: 2.5631789301743435

Epoch: 6| Step: 8
Training loss: 0.2073688633305674
Validation loss: 2.5612255531839945

Epoch: 6| Step: 9
Training loss: 0.20031725263387948
Validation loss: 2.571629821225441

Epoch: 6| Step: 10
Training loss: 0.3143643793014639
Validation loss: 2.5818088418268976

Epoch: 6| Step: 11
Training loss: 0.10795746711206523
Validation loss: 2.549376919148979

Epoch: 6| Step: 12
Training loss: 0.28936082034870364
Validation loss: 2.551471762661441

Epoch: 6| Step: 13
Training loss: 0.07842590676649283
Validation loss: 2.5279254945294167

Epoch: 490| Step: 0
Training loss: 0.18505394358567356
Validation loss: 2.5233821991733287

Epoch: 6| Step: 1
Training loss: 0.16319133299596217
Validation loss: 2.549100601869434

Epoch: 6| Step: 2
Training loss: 0.1898624874020303
Validation loss: 2.4922470634451486

Epoch: 6| Step: 3
Training loss: 0.2216668062206656
Validation loss: 2.534135545851212

Epoch: 6| Step: 4
Training loss: 0.29215057568125335
Validation loss: 2.5347304177490053

Epoch: 6| Step: 5
Training loss: 0.19078252334232274
Validation loss: 2.596276931403011

Epoch: 6| Step: 6
Training loss: 0.22231396080815502
Validation loss: 2.542222330593823

Epoch: 6| Step: 7
Training loss: 0.2016336086431442
Validation loss: 2.5692135404914507

Epoch: 6| Step: 8
Training loss: 0.19878948937983226
Validation loss: 2.5286858769668252

Epoch: 6| Step: 9
Training loss: 0.27494093520751545
Validation loss: 2.529751695650423

Epoch: 6| Step: 10
Training loss: 0.08683305887452265
Validation loss: 2.5637532552766635

Epoch: 6| Step: 11
Training loss: 0.14512682968698093
Validation loss: 2.536847562114915

Epoch: 6| Step: 12
Training loss: 0.19418735670876963
Validation loss: 2.5450366696179207

Epoch: 6| Step: 13
Training loss: 0.3679839080474562
Validation loss: 2.5066051168761274

Epoch: 491| Step: 0
Training loss: 0.13010348310537892
Validation loss: 2.5306208213566794

Epoch: 6| Step: 1
Training loss: 0.32372517531081846
Validation loss: 2.503475381289218

Epoch: 6| Step: 2
Training loss: 0.1869918374432247
Validation loss: 2.514859134852416

Epoch: 6| Step: 3
Training loss: 0.20462324466138854
Validation loss: 2.5424182494397716

Epoch: 6| Step: 4
Training loss: 0.2438077259178152
Validation loss: 2.509806865335593

Epoch: 6| Step: 5
Training loss: 0.11545222106034546
Validation loss: 2.5302003881820565

Epoch: 6| Step: 6
Training loss: 0.16998456478169666
Validation loss: 2.4907514907309043

Epoch: 6| Step: 7
Training loss: 0.24656995989268246
Validation loss: 2.5080574076298263

Epoch: 6| Step: 8
Training loss: 0.17272809570610675
Validation loss: 2.507219203184364

Epoch: 6| Step: 9
Training loss: 0.16579245545631124
Validation loss: 2.4833508247749974

Epoch: 6| Step: 10
Training loss: 0.09192571830366422
Validation loss: 2.515492387813887

Epoch: 6| Step: 11
Training loss: 0.15340123197585853
Validation loss: 2.5100832972121507

Epoch: 6| Step: 12
Training loss: 0.1871599949194381
Validation loss: 2.473428086524288

Epoch: 6| Step: 13
Training loss: 0.22491788822839717
Validation loss: 2.5042667587244267

Epoch: 492| Step: 0
Training loss: 0.16458333879080494
Validation loss: 2.4650859920118693

Epoch: 6| Step: 1
Training loss: 0.10222790145434446
Validation loss: 2.487119891276301

Epoch: 6| Step: 2
Training loss: 0.14515521705103876
Validation loss: 2.509083750702273

Epoch: 6| Step: 3
Training loss: 0.162188924092268
Validation loss: 2.4527906586211303

Epoch: 6| Step: 4
Training loss: 0.14373704136613472
Validation loss: 2.4450740426015676

Epoch: 6| Step: 5
Training loss: 0.24378828946177297
Validation loss: 2.4667888991945888

Epoch: 6| Step: 6
Training loss: 0.29338574297332815
Validation loss: 2.4382135857551916

Epoch: 6| Step: 7
Training loss: 0.1910217763928304
Validation loss: 2.4702576519351873

Epoch: 6| Step: 8
Training loss: 0.16340052934147062
Validation loss: 2.447814751473488

Epoch: 6| Step: 9
Training loss: 0.10192504693487067
Validation loss: 2.4789949417788373

Epoch: 6| Step: 10
Training loss: 0.1651139287038171
Validation loss: 2.470557541136794

Epoch: 6| Step: 11
Training loss: 0.13842091215569358
Validation loss: 2.4266591569977463

Epoch: 6| Step: 12
Training loss: 0.27567476805053376
Validation loss: 2.470097084073778

Epoch: 6| Step: 13
Training loss: 0.1900159596340714
Validation loss: 2.41629077447714

Epoch: 493| Step: 0
Training loss: 0.2023335038172094
Validation loss: 2.476645231781749

Epoch: 6| Step: 1
Training loss: 0.12041564242076969
Validation loss: 2.454833723685751

Epoch: 6| Step: 2
Training loss: 0.14551466727271853
Validation loss: 2.4915738130211125

Epoch: 6| Step: 3
Training loss: 0.16077748626033134
Validation loss: 2.485362226126198

Epoch: 6| Step: 4
Training loss: 0.15925966488638324
Validation loss: 2.448553227637616

Epoch: 6| Step: 5
Training loss: 0.10118113037251696
Validation loss: 2.4612196393847223

Epoch: 6| Step: 6
Training loss: 0.213670535667448
Validation loss: 2.466499611372862

Epoch: 6| Step: 7
Training loss: 0.20804420117082836
Validation loss: 2.4841226831564494

Epoch: 6| Step: 8
Training loss: 0.24393256668010702
Validation loss: 2.435925663393464

Epoch: 6| Step: 9
Training loss: 0.16706925560164512
Validation loss: 2.434098784872402

Epoch: 6| Step: 10
Training loss: 0.2770816746760083
Validation loss: 2.4345784228130127

Epoch: 6| Step: 11
Training loss: 0.2681803087840784
Validation loss: 2.443915583954094

Epoch: 6| Step: 12
Training loss: 0.24594409873185227
Validation loss: 2.383309476397267

Epoch: 6| Step: 13
Training loss: 0.1737878517045251
Validation loss: 2.413766342279993

Epoch: 494| Step: 0
Training loss: 0.20446915811098307
Validation loss: 2.37406012153681

Epoch: 6| Step: 1
Training loss: 0.2603511092002454
Validation loss: 2.4642162893036703

Epoch: 6| Step: 2
Training loss: 0.166259244674337
Validation loss: 2.4411816397434927

Epoch: 6| Step: 3
Training loss: 0.17723768650429575
Validation loss: 2.4491871336875777

Epoch: 6| Step: 4
Training loss: 0.2391345193003085
Validation loss: 2.480269770820383

Epoch: 6| Step: 5
Training loss: 0.19596908831852317
Validation loss: 2.5154155485283507

Epoch: 6| Step: 6
Training loss: 0.12234985387490965
Validation loss: 2.4779407499709625

Epoch: 6| Step: 7
Training loss: 0.19872477005419648
Validation loss: 2.5409344291327183

Epoch: 6| Step: 8
Training loss: 0.1828979129634644
Validation loss: 2.5422807984048466

Epoch: 6| Step: 9
Training loss: 0.09477898042101558
Validation loss: 2.5507784328675354

Epoch: 6| Step: 10
Training loss: 0.23786012770375742
Validation loss: 2.5118038470743556

Epoch: 6| Step: 11
Training loss: 0.1212331676843398
Validation loss: 2.50050203963516

Epoch: 6| Step: 12
Training loss: 0.16550702558289418
Validation loss: 2.485047390580151

Epoch: 6| Step: 13
Training loss: 0.178445420765822
Validation loss: 2.4758428778892583

Epoch: 495| Step: 0
Training loss: 0.12317430996813822
Validation loss: 2.4855207292225794

Epoch: 6| Step: 1
Training loss: 0.178461828828017
Validation loss: 2.457061546714455

Epoch: 6| Step: 2
Training loss: 0.11700439453125
Validation loss: 2.4922024465426396

Epoch: 6| Step: 3
Training loss: 0.1330168638356523
Validation loss: 2.5153886055578973

Epoch: 6| Step: 4
Training loss: 0.19761470086576127
Validation loss: 2.489158388841543

Epoch: 6| Step: 5
Training loss: 0.1596209430563641
Validation loss: 2.531774156941826

Epoch: 6| Step: 6
Training loss: 0.10883375342246868
Validation loss: 2.4887516896233524

Epoch: 6| Step: 7
Training loss: 0.2638966344162344
Validation loss: 2.510910123203659

Epoch: 6| Step: 8
Training loss: 0.09471557494473726
Validation loss: 2.494659619344847

Epoch: 6| Step: 9
Training loss: 0.17119710165277965
Validation loss: 2.5024105643055803

Epoch: 6| Step: 10
Training loss: 0.24829017541493775
Validation loss: 2.48529816631852

Epoch: 6| Step: 11
Training loss: 0.2522889789392983
Validation loss: 2.47319986259035

Epoch: 6| Step: 12
Training loss: 0.2221779370429608
Validation loss: 2.5249254827916743

Epoch: 6| Step: 13
Training loss: 0.09916550717090017
Validation loss: 2.4801093405279304

Epoch: 496| Step: 0
Training loss: 0.26076681756549136
Validation loss: 2.4829124577236614

Epoch: 6| Step: 1
Training loss: 0.1237927942986469
Validation loss: 2.456635764155794

Epoch: 6| Step: 2
Training loss: 0.1293509571913518
Validation loss: 2.446017837741704

Epoch: 6| Step: 3
Training loss: 0.1773362679100513
Validation loss: 2.493125526833455

Epoch: 6| Step: 4
Training loss: 0.19352847709991472
Validation loss: 2.4810857479429886

Epoch: 6| Step: 5
Training loss: 0.16829615665070338
Validation loss: 2.47603880021236

Epoch: 6| Step: 6
Training loss: 0.09909353201886385
Validation loss: 2.482668056976904

Epoch: 6| Step: 7
Training loss: 0.2534178364483262
Validation loss: 2.4873537138589055

Epoch: 6| Step: 8
Training loss: 0.17409853315724197
Validation loss: 2.4977835038098846

Epoch: 6| Step: 9
Training loss: 0.14683952511856885
Validation loss: 2.470561792495636

Epoch: 6| Step: 10
Training loss: 0.19680727217567293
Validation loss: 2.488325616798359

Epoch: 6| Step: 11
Training loss: 0.22420426198958304
Validation loss: 2.5024476677160714

Epoch: 6| Step: 12
Training loss: 0.10865551303627864
Validation loss: 2.502091723269343

Epoch: 6| Step: 13
Training loss: 0.22622225139441324
Validation loss: 2.5008749958547356

Epoch: 497| Step: 0
Training loss: 0.11001804048085888
Validation loss: 2.500460971869188

Epoch: 6| Step: 1
Training loss: 0.09152258821712886
Validation loss: 2.4974822481809604

Epoch: 6| Step: 2
Training loss: 0.15794467419006034
Validation loss: 2.4717857784167108

Epoch: 6| Step: 3
Training loss: 0.12344066489061536
Validation loss: 2.4703157173646324

Epoch: 6| Step: 4
Training loss: 0.19351232625207984
Validation loss: 2.468990262833729

Epoch: 6| Step: 5
Training loss: 0.10707906730373057
Validation loss: 2.4329796460354416

Epoch: 6| Step: 6
Training loss: 0.23968791838538547
Validation loss: 2.480264710242899

Epoch: 6| Step: 7
Training loss: 0.07656910828856944
Validation loss: 2.4690595884174984

Epoch: 6| Step: 8
Training loss: 0.1609003586641674
Validation loss: 2.4866901326174045

Epoch: 6| Step: 9
Training loss: 0.32392168798611926
Validation loss: 2.478329720344472

Epoch: 6| Step: 10
Training loss: 0.17736916170935768
Validation loss: 2.472830939325505

Epoch: 6| Step: 11
Training loss: 0.1110711771530301
Validation loss: 2.488673310827627

Epoch: 6| Step: 12
Training loss: 0.14681141268220746
Validation loss: 2.4968525508623154

Epoch: 6| Step: 13
Training loss: 0.24838789828588514
Validation loss: 2.470121003238018

Epoch: 498| Step: 0
Training loss: 0.1839387573901747
Validation loss: 2.4947123866346756

Epoch: 6| Step: 1
Training loss: 0.16267911915143296
Validation loss: 2.4794876991720565

Epoch: 6| Step: 2
Training loss: 0.2731567030954089
Validation loss: 2.5139213351729435

Epoch: 6| Step: 3
Training loss: 0.12196000264902822
Validation loss: 2.4501143651692514

Epoch: 6| Step: 4
Training loss: 0.1318515485774957
Validation loss: 2.4870194781313044

Epoch: 6| Step: 5
Training loss: 0.07528586941707209
Validation loss: 2.4521998530353515

Epoch: 6| Step: 6
Training loss: 0.21060617351440594
Validation loss: 2.444281230505047

Epoch: 6| Step: 7
Training loss: 0.22722232040162466
Validation loss: 2.4411271996942148

Epoch: 6| Step: 8
Training loss: 0.16885645960930232
Validation loss: 2.4392572352530433

Epoch: 6| Step: 9
Training loss: 0.20230566351213738
Validation loss: 2.48671752776667

Epoch: 6| Step: 10
Training loss: 0.16648321498608135
Validation loss: 2.4756994573623725

Epoch: 6| Step: 11
Training loss: 0.3097415534692823
Validation loss: 2.5083614966601018

Epoch: 6| Step: 12
Training loss: 0.11711948725842235
Validation loss: 2.5724772801803035

Epoch: 6| Step: 13
Training loss: 0.24438014678706066
Validation loss: 2.5558054003659296

Epoch: 499| Step: 0
Training loss: 0.13522762773188887
Validation loss: 2.5288578642115387

Epoch: 6| Step: 1
Training loss: 0.17946962955756834
Validation loss: 2.528244080081443

Epoch: 6| Step: 2
Training loss: 0.2717080327048762
Validation loss: 2.5159428178605743

Epoch: 6| Step: 3
Training loss: 0.16745923077243252
Validation loss: 2.4849271340691863

Epoch: 6| Step: 4
Training loss: 0.15478370015996776
Validation loss: 2.4896743729621864

Epoch: 6| Step: 5
Training loss: 0.23106102890380073
Validation loss: 2.4860993742878206

Epoch: 6| Step: 6
Training loss: 0.28349673080241355
Validation loss: 2.4860096828635214

Epoch: 6| Step: 7
Training loss: 0.13429915511108026
Validation loss: 2.4903366741519313

Epoch: 6| Step: 8
Training loss: 0.15984861554807206
Validation loss: 2.5073794898135393

Epoch: 6| Step: 9
Training loss: 0.15436835383769001
Validation loss: 2.5067699147288987

Epoch: 6| Step: 10
Training loss: 0.1718493897691369
Validation loss: 2.5016351971589876

Epoch: 6| Step: 11
Training loss: 0.2700877043217253
Validation loss: 2.5313610618186138

Epoch: 6| Step: 12
Training loss: 0.2687178237638227
Validation loss: 2.485854145228165

Epoch: 6| Step: 13
Training loss: 0.10901215517116161
Validation loss: 2.4934307706512304

Epoch: 500| Step: 0
Training loss: 0.13601926613567641
Validation loss: 2.483158043885898

Epoch: 6| Step: 1
Training loss: 0.1775393831189306
Validation loss: 2.4758353635318286

Epoch: 6| Step: 2
Training loss: 0.18963975660608198
Validation loss: 2.483391517906728

Epoch: 6| Step: 3
Training loss: 0.18817167377975894
Validation loss: 2.47552594210495

Epoch: 6| Step: 4
Training loss: 0.14345447130301736
Validation loss: 2.4513587400959556

Epoch: 6| Step: 5
Training loss: 0.21125659825104534
Validation loss: 2.4560485280026416

Epoch: 6| Step: 6
Training loss: 0.278825615732366
Validation loss: 2.4346446110973874

Epoch: 6| Step: 7
Training loss: 0.20055596964431746
Validation loss: 2.426006405833381

Epoch: 6| Step: 8
Training loss: 0.1281602834175193
Validation loss: 2.46425576288315

Epoch: 6| Step: 9
Training loss: 0.18223176153520498
Validation loss: 2.43493251662133

Epoch: 6| Step: 10
Training loss: 0.2950622401407039
Validation loss: 2.47533622430945

Epoch: 6| Step: 11
Training loss: 0.1082286019749576
Validation loss: 2.4717609906551177

Epoch: 6| Step: 12
Training loss: 0.24711355200393126
Validation loss: 2.479356979906454

Epoch: 6| Step: 13
Training loss: 0.15994317138905292
Validation loss: 2.4953509973316446

Epoch: 501| Step: 0
Training loss: 0.23705999686651727
Validation loss: 2.5181616990128726

Epoch: 6| Step: 1
Training loss: 0.29733011846923035
Validation loss: 2.5352074291360203

Epoch: 6| Step: 2
Training loss: 0.15257654376756127
Validation loss: 2.5185056114449984

Epoch: 6| Step: 3
Training loss: 0.1539267736876573
Validation loss: 2.4717038936916373

Epoch: 6| Step: 4
Training loss: 0.2726967997306177
Validation loss: 2.413413969308416

Epoch: 6| Step: 5
Training loss: 0.25300178825741565
Validation loss: 2.434964194837116

Epoch: 6| Step: 6
Training loss: 0.12526137621929073
Validation loss: 2.3977503536261993

Epoch: 6| Step: 7
Training loss: 0.16107071922795982
Validation loss: 2.3901107275683398

Epoch: 6| Step: 8
Training loss: 0.18657618670522555
Validation loss: 2.4231545372529935

Epoch: 6| Step: 9
Training loss: 0.2735767010181067
Validation loss: 2.4888836716794023

Epoch: 6| Step: 10
Training loss: 0.14631738044855835
Validation loss: 2.4969296485043606

Epoch: 6| Step: 11
Training loss: 0.17003625549761725
Validation loss: 2.536787309697927

Epoch: 6| Step: 12
Training loss: 0.25769216445635285
Validation loss: 2.559137422647245

Epoch: 6| Step: 13
Training loss: 0.29780782159530994
Validation loss: 2.6328545783026254

Epoch: 502| Step: 0
Training loss: 0.27508820506345405
Validation loss: 2.588611595813826

Epoch: 6| Step: 1
Training loss: 0.16290474722955942
Validation loss: 2.5942660709231844

Epoch: 6| Step: 2
Training loss: 0.2557633780432525
Validation loss: 2.5583735229931137

Epoch: 6| Step: 3
Training loss: 0.2670774857976436
Validation loss: 2.523133931450189

Epoch: 6| Step: 4
Training loss: 0.12691778277917473
Validation loss: 2.5149764647457307

Epoch: 6| Step: 5
Training loss: 0.23192680750505715
Validation loss: 2.4803479242163062

Epoch: 6| Step: 6
Training loss: 0.13434777926702604
Validation loss: 2.518944161472361

Epoch: 6| Step: 7
Training loss: 0.15696426690041218
Validation loss: 2.453369266410488

Epoch: 6| Step: 8
Training loss: 0.14304681064389677
Validation loss: 2.4406821286258635

Epoch: 6| Step: 9
Training loss: 0.21650179981106882
Validation loss: 2.4464842273107172

Epoch: 6| Step: 10
Training loss: 0.14588113551978044
Validation loss: 2.4348932288704686

Epoch: 6| Step: 11
Training loss: 0.1442222772292985
Validation loss: 2.453008651194989

Epoch: 6| Step: 12
Training loss: 0.17965739454089627
Validation loss: 2.433513576764661

Epoch: 6| Step: 13
Training loss: 0.22505909223235646
Validation loss: 2.4592909521588364

Epoch: 503| Step: 0
Training loss: 0.1693472683557428
Validation loss: 2.4414661629493337

Epoch: 6| Step: 1
Training loss: 0.10095539572127665
Validation loss: 2.5162698465342213

Epoch: 6| Step: 2
Training loss: 0.1627103054470095
Validation loss: 2.4425979282501453

Epoch: 6| Step: 3
Training loss: 0.12372325252935708
Validation loss: 2.5034560945831936

Epoch: 6| Step: 4
Training loss: 0.15611669098800357
Validation loss: 2.543655977337923

Epoch: 6| Step: 5
Training loss: 0.28619756389083617
Validation loss: 2.491021869862206

Epoch: 6| Step: 6
Training loss: 0.3033002916791842
Validation loss: 2.527103854251116

Epoch: 6| Step: 7
Training loss: 0.16532433137578206
Validation loss: 2.528868983044698

Epoch: 6| Step: 8
Training loss: 0.1501083883942223
Validation loss: 2.5325695362539395

Epoch: 6| Step: 9
Training loss: 0.1653364763377735
Validation loss: 2.503281912533264

Epoch: 6| Step: 10
Training loss: 0.18047008926753383
Validation loss: 2.5055729176036223

Epoch: 6| Step: 11
Training loss: 0.11448427726779961
Validation loss: 2.481649761377765

Epoch: 6| Step: 12
Training loss: 0.11841723220850324
Validation loss: 2.4436875230981077

Epoch: 6| Step: 13
Training loss: 0.31365088491173604
Validation loss: 2.44906338704334

Epoch: 504| Step: 0
Training loss: 0.1575775375506563
Validation loss: 2.424572706915622

Epoch: 6| Step: 1
Training loss: 0.34143801787950046
Validation loss: 2.419983320949092

Epoch: 6| Step: 2
Training loss: 0.14762900418997052
Validation loss: 2.4713929249352313

Epoch: 6| Step: 3
Training loss: 0.16227734148301767
Validation loss: 2.502650419801056

Epoch: 6| Step: 4
Training loss: 0.1326076105224472
Validation loss: 2.5001474931749317

Epoch: 6| Step: 5
Training loss: 0.13013797448525838
Validation loss: 2.4699876065595303

Epoch: 6| Step: 6
Training loss: 0.18474375936152676
Validation loss: 2.4806706172057793

Epoch: 6| Step: 7
Training loss: 0.2242740366890485
Validation loss: 2.5160705002762294

Epoch: 6| Step: 8
Training loss: 0.2220856901965826
Validation loss: 2.475765386859944

Epoch: 6| Step: 9
Training loss: 0.15191835530288214
Validation loss: 2.4997985327974055

Epoch: 6| Step: 10
Training loss: 0.15049786892994832
Validation loss: 2.4899355347089274

Epoch: 6| Step: 11
Training loss: 0.086691440006446
Validation loss: 2.5005758073614976

Epoch: 6| Step: 12
Training loss: 0.16008859461462782
Validation loss: 2.52326728807789

Epoch: 6| Step: 13
Training loss: 0.08506572224892528
Validation loss: 2.451557781971231

Epoch: 505| Step: 0
Training loss: 0.15139218400862536
Validation loss: 2.447244663373159

Epoch: 6| Step: 1
Training loss: 0.16170965459373604
Validation loss: 2.471151079169917

Epoch: 6| Step: 2
Training loss: 0.11586780539288657
Validation loss: 2.476057026971826

Epoch: 6| Step: 3
Training loss: 0.11089224563947345
Validation loss: 2.49389001833238

Epoch: 6| Step: 4
Training loss: 0.2259469302176135
Validation loss: 2.492654816328412

Epoch: 6| Step: 5
Training loss: 0.27015237144655735
Validation loss: 2.485892009844192

Epoch: 6| Step: 6
Training loss: 0.1868584904028162
Validation loss: 2.486545898720414

Epoch: 6| Step: 7
Training loss: 0.22315464789832176
Validation loss: 2.4865346952820464

Epoch: 6| Step: 8
Training loss: 0.12243607464876388
Validation loss: 2.4660297358718344

Epoch: 6| Step: 9
Training loss: 0.14517706845956235
Validation loss: 2.4429850447924917

Epoch: 6| Step: 10
Training loss: 0.25542220411992944
Validation loss: 2.4630078741620745

Epoch: 6| Step: 11
Training loss: 0.19359616509779215
Validation loss: 2.436545594027705

Epoch: 6| Step: 12
Training loss: 0.09142569820022967
Validation loss: 2.448147363380434

Epoch: 6| Step: 13
Training loss: 0.049611136262522004
Validation loss: 2.4431818643858847

Epoch: 506| Step: 0
Training loss: 0.20826314200679047
Validation loss: 2.462440547638739

Epoch: 6| Step: 1
Training loss: 0.12994448552797072
Validation loss: 2.4408455064205796

Epoch: 6| Step: 2
Training loss: 0.11977507944607035
Validation loss: 2.4359526401758522

Epoch: 6| Step: 3
Training loss: 0.12075151257525213
Validation loss: 2.4205418246774824

Epoch: 6| Step: 4
Training loss: 0.23793419593969933
Validation loss: 2.453112424347043

Epoch: 6| Step: 5
Training loss: 0.10662819961149919
Validation loss: 2.44530479904074

Epoch: 6| Step: 6
Training loss: 0.1343369438375509
Validation loss: 2.444090394870725

Epoch: 6| Step: 7
Training loss: 0.13491997656179622
Validation loss: 2.4102442276878393

Epoch: 6| Step: 8
Training loss: 0.24100177978614254
Validation loss: 2.436040548125493

Epoch: 6| Step: 9
Training loss: 0.12483215984833601
Validation loss: 2.436531067836114

Epoch: 6| Step: 10
Training loss: 0.2483559282609072
Validation loss: 2.381088172487334

Epoch: 6| Step: 11
Training loss: 0.11317265995063627
Validation loss: 2.3916361857392725

Epoch: 6| Step: 12
Training loss: 0.1438486696144143
Validation loss: 2.438051443772275

Epoch: 6| Step: 13
Training loss: 0.11048176350890454
Validation loss: 2.409310301763567

Epoch: 507| Step: 0
Training loss: 0.12422860814209474
Validation loss: 2.445054721962679

Epoch: 6| Step: 1
Training loss: 0.09529265134539229
Validation loss: 2.3942688194568613

Epoch: 6| Step: 2
Training loss: 0.27808921991000646
Validation loss: 2.430833375193603

Epoch: 6| Step: 3
Training loss: 0.1025079498319169
Validation loss: 2.463274555562698

Epoch: 6| Step: 4
Training loss: 0.1407846895151257
Validation loss: 2.4552158482167985

Epoch: 6| Step: 5
Training loss: 0.17723318846408898
Validation loss: 2.4425044520521606

Epoch: 6| Step: 6
Training loss: 0.16249416826861127
Validation loss: 2.4427188360818124

Epoch: 6| Step: 7
Training loss: 0.15058050925122857
Validation loss: 2.475245066774241

Epoch: 6| Step: 8
Training loss: 0.23365482310193206
Validation loss: 2.4331950668292586

Epoch: 6| Step: 9
Training loss: 0.0997528697502738
Validation loss: 2.42555594432085

Epoch: 6| Step: 10
Training loss: 0.187626319296085
Validation loss: 2.4916777671818844

Epoch: 6| Step: 11
Training loss: 0.10736642620219526
Validation loss: 2.487240348922471

Epoch: 6| Step: 12
Training loss: 0.2676893128541441
Validation loss: 2.4842501672355075

Epoch: 6| Step: 13
Training loss: 0.14195581387422737
Validation loss: 2.504916438987806

Epoch: 508| Step: 0
Training loss: 0.1791790111488233
Validation loss: 2.493908756587644

Epoch: 6| Step: 1
Training loss: 0.2875382859196623
Validation loss: 2.4826220034632156

Epoch: 6| Step: 2
Training loss: 0.23905003926582627
Validation loss: 2.4417536526183286

Epoch: 6| Step: 3
Training loss: 0.22278711589015382
Validation loss: 2.4575528998141376

Epoch: 6| Step: 4
Training loss: 0.14677611862554565
Validation loss: 2.4399420540049985

Epoch: 6| Step: 5
Training loss: 0.15634081108934506
Validation loss: 2.4534041491027447

Epoch: 6| Step: 6
Training loss: 0.11168672295979436
Validation loss: 2.449256415847083

Epoch: 6| Step: 7
Training loss: 0.13007514738277626
Validation loss: 2.411333828833109

Epoch: 6| Step: 8
Training loss: 0.11138527223255469
Validation loss: 2.415365508156496

Epoch: 6| Step: 9
Training loss: 0.1392105011471018
Validation loss: 2.433448301654075

Epoch: 6| Step: 10
Training loss: 0.14734158517373816
Validation loss: 2.4657653840163887

Epoch: 6| Step: 11
Training loss: 0.1511248093904377
Validation loss: 2.4497891060119543

Epoch: 6| Step: 12
Training loss: 0.12538980263888966
Validation loss: 2.4515472745638602

Epoch: 6| Step: 13
Training loss: 0.11674062640684384
Validation loss: 2.454298171664691

Epoch: 509| Step: 0
Training loss: 0.09880970681493487
Validation loss: 2.4322321267620586

Epoch: 6| Step: 1
Training loss: 0.10090302975638381
Validation loss: 2.443773822612183

Epoch: 6| Step: 2
Training loss: 0.2672028799259433
Validation loss: 2.448119620395184

Epoch: 6| Step: 3
Training loss: 0.11768935746511389
Validation loss: 2.4844557721347686

Epoch: 6| Step: 4
Training loss: 0.21425229937433457
Validation loss: 2.444249616927624

Epoch: 6| Step: 5
Training loss: 0.17608060777596013
Validation loss: 2.4600891187487197

Epoch: 6| Step: 6
Training loss: 0.16653990705934235
Validation loss: 2.45068833097329

Epoch: 6| Step: 7
Training loss: 0.24141725218802507
Validation loss: 2.443026635905894

Epoch: 6| Step: 8
Training loss: 0.14653228612026217
Validation loss: 2.4408096948413083

Epoch: 6| Step: 9
Training loss: 0.0949609550435259
Validation loss: 2.4064308027195005

Epoch: 6| Step: 10
Training loss: 0.15619602463193122
Validation loss: 2.4569360378189136

Epoch: 6| Step: 11
Training loss: 0.14753607547191552
Validation loss: 2.421186230513915

Epoch: 6| Step: 12
Training loss: 0.11684404747408075
Validation loss: 2.465012449754634

Epoch: 6| Step: 13
Training loss: 0.09298138151989668
Validation loss: 2.4575677075398183

Epoch: 510| Step: 0
Training loss: 0.10737240258995448
Validation loss: 2.438008941282025

Epoch: 6| Step: 1
Training loss: 0.11015974100140905
Validation loss: 2.4689267750601704

Epoch: 6| Step: 2
Training loss: 0.27411394915156156
Validation loss: 2.4749998892092897

Epoch: 6| Step: 3
Training loss: 0.21463068887850448
Validation loss: 2.5039181901857828

Epoch: 6| Step: 4
Training loss: 0.10662602038163567
Validation loss: 2.4817335704051375

Epoch: 6| Step: 5
Training loss: 0.1045979650712055
Validation loss: 2.503756905840276

Epoch: 6| Step: 6
Training loss: 0.28245806851233696
Validation loss: 2.461430868581838

Epoch: 6| Step: 7
Training loss: 0.09549038460830425
Validation loss: 2.480834258078795

Epoch: 6| Step: 8
Training loss: 0.13890524153670528
Validation loss: 2.4983798309479552

Epoch: 6| Step: 9
Training loss: 0.04556261638769085
Validation loss: 2.4566732134959777

Epoch: 6| Step: 10
Training loss: 0.13998263723983279
Validation loss: 2.513668862276243

Epoch: 6| Step: 11
Training loss: 0.16920952175616674
Validation loss: 2.496391871582972

Epoch: 6| Step: 12
Training loss: 0.08883610905083972
Validation loss: 2.4974832613264177

Epoch: 6| Step: 13
Training loss: 0.18573034150448603
Validation loss: 2.467346589507995

Epoch: 511| Step: 0
Training loss: 0.150211524832475
Validation loss: 2.4608889682904587

Epoch: 6| Step: 1
Training loss: 0.12055305546697913
Validation loss: 2.4786298215736546

Epoch: 6| Step: 2
Training loss: 0.15908754057035082
Validation loss: 2.4644591791692605

Epoch: 6| Step: 3
Training loss: 0.15080837341809464
Validation loss: 2.4690948075230117

Epoch: 6| Step: 4
Training loss: 0.1637200630555467
Validation loss: 2.449126893565057

Epoch: 6| Step: 5
Training loss: 0.22180179140366765
Validation loss: 2.4671093499711647

Epoch: 6| Step: 6
Training loss: 0.18820525689538722
Validation loss: 2.4535935435641214

Epoch: 6| Step: 7
Training loss: 0.10261531446945296
Validation loss: 2.4849098864435732

Epoch: 6| Step: 8
Training loss: 0.21653566863068346
Validation loss: 2.50697783624023

Epoch: 6| Step: 9
Training loss: 0.22493282745926657
Validation loss: 2.51484044770121

Epoch: 6| Step: 10
Training loss: 0.12832340776725382
Validation loss: 2.5188777660234765

Epoch: 6| Step: 11
Training loss: 0.20655232942620927
Validation loss: 2.515063648728533

Epoch: 6| Step: 12
Training loss: 0.18669941973682883
Validation loss: 2.4945465843706947

Epoch: 6| Step: 13
Training loss: 0.12472448309035052
Validation loss: 2.4568206954087812

Epoch: 512| Step: 0
Training loss: 0.15390380455630326
Validation loss: 2.4585911250808423

Epoch: 6| Step: 1
Training loss: 0.24689585289828855
Validation loss: 2.4608215273452965

Epoch: 6| Step: 2
Training loss: 0.19603367223327087
Validation loss: 2.45110951130109

Epoch: 6| Step: 3
Training loss: 0.2673533811456359
Validation loss: 2.443464304972148

Epoch: 6| Step: 4
Training loss: 0.12645910684541728
Validation loss: 2.484657942740272

Epoch: 6| Step: 5
Training loss: 0.15378784160793116
Validation loss: 2.4538228683246466

Epoch: 6| Step: 6
Training loss: 0.09393330376339531
Validation loss: 2.502469590407277

Epoch: 6| Step: 7
Training loss: 0.210949438251761
Validation loss: 2.4946453298101723

Epoch: 6| Step: 8
Training loss: 0.2279864239786564
Validation loss: 2.4773791838852373

Epoch: 6| Step: 9
Training loss: 0.07466102879168598
Validation loss: 2.522333437296745

Epoch: 6| Step: 10
Training loss: 0.0983042390193621
Validation loss: 2.5056984186929503

Epoch: 6| Step: 11
Training loss: 0.1663089628993903
Validation loss: 2.4988164253493625

Epoch: 6| Step: 12
Training loss: 0.12936943818544241
Validation loss: 2.4959073273519694

Epoch: 6| Step: 13
Training loss: 0.0746609071699692
Validation loss: 2.5047509595826027

Epoch: 513| Step: 0
Training loss: 0.15197261817656127
Validation loss: 2.4869075535262555

Epoch: 6| Step: 1
Training loss: 0.1928333293786484
Validation loss: 2.4762625895204153

Epoch: 6| Step: 2
Training loss: 0.14183507935336087
Validation loss: 2.475986050154191

Epoch: 6| Step: 3
Training loss: 0.14491845792664534
Validation loss: 2.467657481717619

Epoch: 6| Step: 4
Training loss: 0.24101034310116037
Validation loss: 2.4733826663197473

Epoch: 6| Step: 5
Training loss: 0.09807124651869253
Validation loss: 2.4318921979673878

Epoch: 6| Step: 6
Training loss: 0.15276052855942646
Validation loss: 2.438606817607958

Epoch: 6| Step: 7
Training loss: 0.20633542791439927
Validation loss: 2.46791941101558

Epoch: 6| Step: 8
Training loss: 0.24505167537794434
Validation loss: 2.455920338895416

Epoch: 6| Step: 9
Training loss: 0.09827809237000161
Validation loss: 2.4359389050285802

Epoch: 6| Step: 10
Training loss: 0.12303665285187007
Validation loss: 2.478077724220864

Epoch: 6| Step: 11
Training loss: 0.25050117504106967
Validation loss: 2.4455958801119007

Epoch: 6| Step: 12
Training loss: 0.10245819990548988
Validation loss: 2.4715529791853608

Epoch: 6| Step: 13
Training loss: 0.11126749161037243
Validation loss: 2.481277899444371

Epoch: 514| Step: 0
Training loss: 0.16039400363788053
Validation loss: 2.491219906893646

Epoch: 6| Step: 1
Training loss: 0.20008049440302902
Validation loss: 2.4627012694110357

Epoch: 6| Step: 2
Training loss: 0.1428805110223969
Validation loss: 2.499691661155306

Epoch: 6| Step: 3
Training loss: 0.13275333797843367
Validation loss: 2.466270205501442

Epoch: 6| Step: 4
Training loss: 0.17806906156410568
Validation loss: 2.495856134281522

Epoch: 6| Step: 5
Training loss: 0.2645589811026618
Validation loss: 2.475832814215914

Epoch: 6| Step: 6
Training loss: 0.1253168961831177
Validation loss: 2.5070565881424836

Epoch: 6| Step: 7
Training loss: 0.15174816547695782
Validation loss: 2.504639801242034

Epoch: 6| Step: 8
Training loss: 0.08107511998215336
Validation loss: 2.4557543238179433

Epoch: 6| Step: 9
Training loss: 0.19030528773655506
Validation loss: 2.539502698477973

Epoch: 6| Step: 10
Training loss: 0.16542610515872727
Validation loss: 2.491387247670702

Epoch: 6| Step: 11
Training loss: 0.23113327882483398
Validation loss: 2.503105371958053

Epoch: 6| Step: 12
Training loss: 0.21775389271430814
Validation loss: 2.481952096906352

Epoch: 6| Step: 13
Training loss: 0.1450617308179193
Validation loss: 2.492492969776329

Epoch: 515| Step: 0
Training loss: 0.10503800611862052
Validation loss: 2.4593612193303835

Epoch: 6| Step: 1
Training loss: 0.11564241516568771
Validation loss: 2.451146706726162

Epoch: 6| Step: 2
Training loss: 0.24791798284058383
Validation loss: 2.420822312784599

Epoch: 6| Step: 3
Training loss: 0.20631011390288498
Validation loss: 2.451035699778307

Epoch: 6| Step: 4
Training loss: 0.1521868264342017
Validation loss: 2.442875595308188

Epoch: 6| Step: 5
Training loss: 0.2540199612035437
Validation loss: 2.460303589249011

Epoch: 6| Step: 6
Training loss: 0.16467373948815758
Validation loss: 2.4957138122337263

Epoch: 6| Step: 7
Training loss: 0.16551915151303
Validation loss: 2.4764035210991637

Epoch: 6| Step: 8
Training loss: 0.07901807782886652
Validation loss: 2.5079241387139

Epoch: 6| Step: 9
Training loss: 0.1846587156078553
Validation loss: 2.4962276161135883

Epoch: 6| Step: 10
Training loss: 0.22466459839342376
Validation loss: 2.485601356602631

Epoch: 6| Step: 11
Training loss: 0.13268375467673676
Validation loss: 2.5245676682380305

Epoch: 6| Step: 12
Training loss: 0.12238791538221022
Validation loss: 2.4976081943058435

Epoch: 6| Step: 13
Training loss: 0.17522373798142846
Validation loss: 2.4939584189391155

Epoch: 516| Step: 0
Training loss: 0.16724266541439864
Validation loss: 2.4649214762133917

Epoch: 6| Step: 1
Training loss: 0.22453408845396167
Validation loss: 2.466853326898137

Epoch: 6| Step: 2
Training loss: 0.13901995908282314
Validation loss: 2.4762131561786487

Epoch: 6| Step: 3
Training loss: 0.15996469695874982
Validation loss: 2.484958771255724

Epoch: 6| Step: 4
Training loss: 0.13027056557894057
Validation loss: 2.4768237339160284

Epoch: 6| Step: 5
Training loss: 0.15943069793714457
Validation loss: 2.430036777344799

Epoch: 6| Step: 6
Training loss: 0.1532318443135266
Validation loss: 2.46729737496632

Epoch: 6| Step: 7
Training loss: 0.20091759249374863
Validation loss: 2.45289222162036

Epoch: 6| Step: 8
Training loss: 0.11491846165103496
Validation loss: 2.4648991332462478

Epoch: 6| Step: 9
Training loss: 0.2510653832155859
Validation loss: 2.4394943433626315

Epoch: 6| Step: 10
Training loss: 0.1537458261450564
Validation loss: 2.462718490923482

Epoch: 6| Step: 11
Training loss: 0.2156744502902584
Validation loss: 2.5094802499484254

Epoch: 6| Step: 12
Training loss: 0.10917197696707781
Validation loss: 2.5170714512108248

Epoch: 6| Step: 13
Training loss: 0.058108403828965906
Validation loss: 2.5243403972812777

Epoch: 517| Step: 0
Training loss: 0.10428738354417283
Validation loss: 2.545731119078635

Epoch: 6| Step: 1
Training loss: 0.17969722306855485
Validation loss: 2.539982857444857

Epoch: 6| Step: 2
Training loss: 0.20722708346978228
Validation loss: 2.5652062077160265

Epoch: 6| Step: 3
Training loss: 0.17180986687497474
Validation loss: 2.5421132872565018

Epoch: 6| Step: 4
Training loss: 0.18138205674966937
Validation loss: 2.536519533845684

Epoch: 6| Step: 5
Training loss: 0.21084037063341976
Validation loss: 2.522616873554618

Epoch: 6| Step: 6
Training loss: 0.09122530050140663
Validation loss: 2.4848478629182837

Epoch: 6| Step: 7
Training loss: 0.0956147428072727
Validation loss: 2.4792050179169016

Epoch: 6| Step: 8
Training loss: 0.1871200725706811
Validation loss: 2.4666221719887127

Epoch: 6| Step: 9
Training loss: 0.2430471959076703
Validation loss: 2.452175009994547

Epoch: 6| Step: 10
Training loss: 0.18826742873371363
Validation loss: 2.4650988773329336

Epoch: 6| Step: 11
Training loss: 0.09598287741722171
Validation loss: 2.4855640548355202

Epoch: 6| Step: 12
Training loss: 0.1139008087983105
Validation loss: 2.4704278799983355

Epoch: 6| Step: 13
Training loss: 0.06601799334278707
Validation loss: 2.458259014788127

Epoch: 518| Step: 0
Training loss: 0.1686585533973637
Validation loss: 2.504132373338786

Epoch: 6| Step: 1
Training loss: 0.16119366277115724
Validation loss: 2.526778086743195

Epoch: 6| Step: 2
Training loss: 0.10687284616620095
Validation loss: 2.5208932006230254

Epoch: 6| Step: 3
Training loss: 0.22518854519815626
Validation loss: 2.516432373546175

Epoch: 6| Step: 4
Training loss: 0.13159152793502926
Validation loss: 2.52147079465006

Epoch: 6| Step: 5
Training loss: 0.21065641147747113
Validation loss: 2.4818441737417927

Epoch: 6| Step: 6
Training loss: 0.14864744848707342
Validation loss: 2.535277449775089

Epoch: 6| Step: 7
Training loss: 0.081079324172351
Validation loss: 2.5644394532964907

Epoch: 6| Step: 8
Training loss: 0.1912879578315258
Validation loss: 2.506801811106233

Epoch: 6| Step: 9
Training loss: 0.149428983953051
Validation loss: 2.491476066389895

Epoch: 6| Step: 10
Training loss: 0.11717239918370904
Validation loss: 2.4844164038378747

Epoch: 6| Step: 11
Training loss: 0.08883302681783849
Validation loss: 2.4770795327014805

Epoch: 6| Step: 12
Training loss: 0.1247472256175651
Validation loss: 2.4767716350754347

Epoch: 6| Step: 13
Training loss: 0.2407763500569086
Validation loss: 2.5038623661029185

Epoch: 519| Step: 0
Training loss: 0.09802279822646623
Validation loss: 2.4803674459017446

Epoch: 6| Step: 1
Training loss: 0.08518209393329736
Validation loss: 2.472901028062051

Epoch: 6| Step: 2
Training loss: 0.17211154893947167
Validation loss: 2.4854228360788944

Epoch: 6| Step: 3
Training loss: 0.1890020506352738
Validation loss: 2.486842188224881

Epoch: 6| Step: 4
Training loss: 0.12196896733003919
Validation loss: 2.4605057553316496

Epoch: 6| Step: 5
Training loss: 0.11318836843904163
Validation loss: 2.472537533983768

Epoch: 6| Step: 6
Training loss: 0.18136622098147176
Validation loss: 2.479036145916397

Epoch: 6| Step: 7
Training loss: 0.11594948087208398
Validation loss: 2.4947168681239367

Epoch: 6| Step: 8
Training loss: 0.21887395956880343
Validation loss: 2.468274877791525

Epoch: 6| Step: 9
Training loss: 0.21798032504285608
Validation loss: 2.5085153761057066

Epoch: 6| Step: 10
Training loss: 0.13781801803077565
Validation loss: 2.491081316071368

Epoch: 6| Step: 11
Training loss: 0.18443454815303434
Validation loss: 2.4715342856325027

Epoch: 6| Step: 12
Training loss: 0.15398162312905833
Validation loss: 2.4958475169177463

Epoch: 6| Step: 13
Training loss: 0.18491702338922494
Validation loss: 2.5101965956402577

Epoch: 520| Step: 0
Training loss: 0.1780093654274354
Validation loss: 2.504830482580912

Epoch: 6| Step: 1
Training loss: 0.09706526269192657
Validation loss: 2.4719102683496152

Epoch: 6| Step: 2
Training loss: 0.0639686146563732
Validation loss: 2.4868861631967736

Epoch: 6| Step: 3
Training loss: 0.06084933030945002
Validation loss: 2.446579417145844

Epoch: 6| Step: 4
Training loss: 0.08069189298152128
Validation loss: 2.4518029782742286

Epoch: 6| Step: 5
Training loss: 0.2058475592333008
Validation loss: 2.461005757588602

Epoch: 6| Step: 6
Training loss: 0.23388092893948112
Validation loss: 2.4559512484831396

Epoch: 6| Step: 7
Training loss: 0.14127344723852117
Validation loss: 2.419298660590013

Epoch: 6| Step: 8
Training loss: 0.2509487299941906
Validation loss: 2.452817884190603

Epoch: 6| Step: 9
Training loss: 0.14508473892213927
Validation loss: 2.429760008633049

Epoch: 6| Step: 10
Training loss: 0.16922544946908116
Validation loss: 2.4608127086412077

Epoch: 6| Step: 11
Training loss: 0.08839359477521161
Validation loss: 2.455207033132771

Epoch: 6| Step: 12
Training loss: 0.1541652117694903
Validation loss: 2.4764300279534006

Epoch: 6| Step: 13
Training loss: 0.13496130406375464
Validation loss: 2.476944998123109

Epoch: 521| Step: 0
Training loss: 0.1074030599589313
Validation loss: 2.473736683232338

Epoch: 6| Step: 1
Training loss: 0.20808135331054228
Validation loss: 2.5076655251304785

Epoch: 6| Step: 2
Training loss: 0.17735115069437357
Validation loss: 2.5034056631487003

Epoch: 6| Step: 3
Training loss: 0.10933604568525157
Validation loss: 2.501212414678172

Epoch: 6| Step: 4
Training loss: 0.12417807662893422
Validation loss: 2.505797669492254

Epoch: 6| Step: 5
Training loss: 0.1295689972105479
Validation loss: 2.4814641586759154

Epoch: 6| Step: 6
Training loss: 0.1836037734521744
Validation loss: 2.489850586012134

Epoch: 6| Step: 7
Training loss: 0.22600846127267255
Validation loss: 2.4909809741055704

Epoch: 6| Step: 8
Training loss: 0.17500465825386485
Validation loss: 2.487288495303813

Epoch: 6| Step: 9
Training loss: 0.1261278397450258
Validation loss: 2.4751343109680217

Epoch: 6| Step: 10
Training loss: 0.14006265151625494
Validation loss: 2.4869568794401644

Epoch: 6| Step: 11
Training loss: 0.1257001965159714
Validation loss: 2.499296099513876

Epoch: 6| Step: 12
Training loss: 0.2218677378527131
Validation loss: 2.4746427550189387

Epoch: 6| Step: 13
Training loss: 0.10586598875352232
Validation loss: 2.4860116122887366

Epoch: 522| Step: 0
Training loss: 0.158859785689319
Validation loss: 2.524536616788535

Epoch: 6| Step: 1
Training loss: 0.09667830996061794
Validation loss: 2.502019564845455

Epoch: 6| Step: 2
Training loss: 0.13388730361332157
Validation loss: 2.5109104044892967

Epoch: 6| Step: 3
Training loss: 0.09791835895895358
Validation loss: 2.5438583086110502

Epoch: 6| Step: 4
Training loss: 0.11901969713494157
Validation loss: 2.54669246048375

Epoch: 6| Step: 5
Training loss: 0.11336201633160274
Validation loss: 2.519504190274039

Epoch: 6| Step: 6
Training loss: 0.18926300262168766
Validation loss: 2.5463389684342164

Epoch: 6| Step: 7
Training loss: 0.17579456914668232
Validation loss: 2.5114453624546687

Epoch: 6| Step: 8
Training loss: 0.14570778667979917
Validation loss: 2.472583623432298

Epoch: 6| Step: 9
Training loss: 0.10841609192469112
Validation loss: 2.503800385097575

Epoch: 6| Step: 10
Training loss: 0.19860789199886453
Validation loss: 2.4552321467327918

Epoch: 6| Step: 11
Training loss: 0.212895235834149
Validation loss: 2.447678337634974

Epoch: 6| Step: 12
Training loss: 0.23229977261437312
Validation loss: 2.456539943882513

Epoch: 6| Step: 13
Training loss: 0.15535199079677522
Validation loss: 2.431405316326705

Epoch: 523| Step: 0
Training loss: 0.18830531746036022
Validation loss: 2.4405274995730606

Epoch: 6| Step: 1
Training loss: 0.07239781674005434
Validation loss: 2.479487719850849

Epoch: 6| Step: 2
Training loss: 0.207418170184654
Validation loss: 2.4551824967048126

Epoch: 6| Step: 3
Training loss: 0.13666150393222906
Validation loss: 2.434754815963598

Epoch: 6| Step: 4
Training loss: 0.08757671352511547
Validation loss: 2.4959943208083266

Epoch: 6| Step: 5
Training loss: 0.21298467675910324
Validation loss: 2.470588561775885

Epoch: 6| Step: 6
Training loss: 0.08645850171030646
Validation loss: 2.4704465300370444

Epoch: 6| Step: 7
Training loss: 0.11798121358070958
Validation loss: 2.495280974627524

Epoch: 6| Step: 8
Training loss: 0.17741460645023568
Validation loss: 2.500362296155683

Epoch: 6| Step: 9
Training loss: 0.19291230739202495
Validation loss: 2.461471481454421

Epoch: 6| Step: 10
Training loss: 0.12428941516081664
Validation loss: 2.5198868334228752

Epoch: 6| Step: 11
Training loss: 0.10936420676927781
Validation loss: 2.4779187690779483

Epoch: 6| Step: 12
Training loss: 0.22288391119214734
Validation loss: 2.4907732811819727

Epoch: 6| Step: 13
Training loss: 0.09825181079699118
Validation loss: 2.4696322923604317

Epoch: 524| Step: 0
Training loss: 0.14741157185423967
Validation loss: 2.4885197991628076

Epoch: 6| Step: 1
Training loss: 0.08722646695314155
Validation loss: 2.4545301305040406

Epoch: 6| Step: 2
Training loss: 0.17919942663528898
Validation loss: 2.420080498597497

Epoch: 6| Step: 3
Training loss: 0.1290022247112453
Validation loss: 2.434760958783607

Epoch: 6| Step: 4
Training loss: 0.12336474565190216
Validation loss: 2.4612863559352522

Epoch: 6| Step: 5
Training loss: 0.13814855609878568
Validation loss: 2.4604236176282765

Epoch: 6| Step: 6
Training loss: 0.1250327931542238
Validation loss: 2.43827844100132

Epoch: 6| Step: 7
Training loss: 0.10665412859255746
Validation loss: 2.4386832376240926

Epoch: 6| Step: 8
Training loss: 0.22691175244574444
Validation loss: 2.4429045915666645

Epoch: 6| Step: 9
Training loss: 0.16293421557693438
Validation loss: 2.4305465525408145

Epoch: 6| Step: 10
Training loss: 0.16822529208639375
Validation loss: 2.4415935419906134

Epoch: 6| Step: 11
Training loss: 0.13422982502142894
Validation loss: 2.4397392294666225

Epoch: 6| Step: 12
Training loss: 0.22499332782336245
Validation loss: 2.500843070527849

Epoch: 6| Step: 13
Training loss: 0.1688176096916489
Validation loss: 2.4834870412755317

Epoch: 525| Step: 0
Training loss: 0.08437494734921402
Validation loss: 2.5204019176498678

Epoch: 6| Step: 1
Training loss: 0.10714481343458847
Validation loss: 2.483567212621935

Epoch: 6| Step: 2
Training loss: 0.12223967057330487
Validation loss: 2.5511199535844025

Epoch: 6| Step: 3
Training loss: 0.17559086768301196
Validation loss: 2.543411976134077

Epoch: 6| Step: 4
Training loss: 0.11105638936792032
Validation loss: 2.522366765081036

Epoch: 6| Step: 5
Training loss: 0.21766418658900927
Validation loss: 2.5270616737513314

Epoch: 6| Step: 6
Training loss: 0.1345242951751986
Validation loss: 2.506559685472043

Epoch: 6| Step: 7
Training loss: 0.14576146719342326
Validation loss: 2.4616659737055837

Epoch: 6| Step: 8
Training loss: 0.08961647249198786
Validation loss: 2.4562560197182965

Epoch: 6| Step: 9
Training loss: 0.2667862947301374
Validation loss: 2.462252664020735

Epoch: 6| Step: 10
Training loss: 0.1761970106662194
Validation loss: 2.4587643957854954

Epoch: 6| Step: 11
Training loss: 0.15702889141759727
Validation loss: 2.473225224954906

Epoch: 6| Step: 12
Training loss: 0.2164392528776899
Validation loss: 2.4486972505961506

Epoch: 6| Step: 13
Training loss: 0.245350722657825
Validation loss: 2.482590499656094

Epoch: 526| Step: 0
Training loss: 0.1317862593689481
Validation loss: 2.471792429204818

Epoch: 6| Step: 1
Training loss: 0.1774198452872478
Validation loss: 2.4804150321762974

Epoch: 6| Step: 2
Training loss: 0.12896438934786866
Validation loss: 2.5219674857056535

Epoch: 6| Step: 3
Training loss: 0.13792246486061874
Validation loss: 2.5027780643470696

Epoch: 6| Step: 4
Training loss: 0.2095880168536212
Validation loss: 2.5019357437042755

Epoch: 6| Step: 5
Training loss: 0.21814038277082437
Validation loss: 2.5214296403646084

Epoch: 6| Step: 6
Training loss: 0.17957756577174586
Validation loss: 2.521645340853684

Epoch: 6| Step: 7
Training loss: 0.20953786052997578
Validation loss: 2.506671424982079

Epoch: 6| Step: 8
Training loss: 0.12068754561658972
Validation loss: 2.5363562360958243

Epoch: 6| Step: 9
Training loss: 0.15183784775137088
Validation loss: 2.493153074404747

Epoch: 6| Step: 10
Training loss: 0.0798282854571758
Validation loss: 2.4843420716720237

Epoch: 6| Step: 11
Training loss: 0.22111753362780784
Validation loss: 2.493315606077535

Epoch: 6| Step: 12
Training loss: 0.19950577684573836
Validation loss: 2.460621738701676

Epoch: 6| Step: 13
Training loss: 0.2816693570405431
Validation loss: 2.4537349799760193

Epoch: 527| Step: 0
Training loss: 0.14182839476780473
Validation loss: 2.4303434966398645

Epoch: 6| Step: 1
Training loss: 0.1910411115622351
Validation loss: 2.4460866866864253

Epoch: 6| Step: 2
Training loss: 0.09797299515806367
Validation loss: 2.468416306963232

Epoch: 6| Step: 3
Training loss: 0.14260833237343049
Validation loss: 2.477758590080349

Epoch: 6| Step: 4
Training loss: 0.1152841694786095
Validation loss: 2.454622901217985

Epoch: 6| Step: 5
Training loss: 0.1643977996385249
Validation loss: 2.465778870885655

Epoch: 6| Step: 6
Training loss: 0.2354488488300824
Validation loss: 2.454711640272957

Epoch: 6| Step: 7
Training loss: 0.16159671127012423
Validation loss: 2.5037866279424867

Epoch: 6| Step: 8
Training loss: 0.1874443110576502
Validation loss: 2.4902029994119643

Epoch: 6| Step: 9
Training loss: 0.12749817559395532
Validation loss: 2.473885227714308

Epoch: 6| Step: 10
Training loss: 0.14711002254495506
Validation loss: 2.4894457464256714

Epoch: 6| Step: 11
Training loss: 0.11089074230738834
Validation loss: 2.4941956573296173

Epoch: 6| Step: 12
Training loss: 0.23850895991979185
Validation loss: 2.474676528248579

Epoch: 6| Step: 13
Training loss: 0.0656405758254828
Validation loss: 2.492871871273491

Epoch: 528| Step: 0
Training loss: 0.09705012570177228
Validation loss: 2.517316837979932

Epoch: 6| Step: 1
Training loss: 0.1298358158184684
Validation loss: 2.5648023415385386

Epoch: 6| Step: 2
Training loss: 0.14746258589473757
Validation loss: 2.5022688302060465

Epoch: 6| Step: 3
Training loss: 0.10540680037269118
Validation loss: 2.5508847762037403

Epoch: 6| Step: 4
Training loss: 0.1665820165082451
Validation loss: 2.5281587799106022

Epoch: 6| Step: 5
Training loss: 0.11521061959536123
Validation loss: 2.489530882967445

Epoch: 6| Step: 6
Training loss: 0.15803505953767813
Validation loss: 2.4971728695584323

Epoch: 6| Step: 7
Training loss: 0.1109418567621326
Validation loss: 2.508390066546181

Epoch: 6| Step: 8
Training loss: 0.20676959795706912
Validation loss: 2.5242374398920537

Epoch: 6| Step: 9
Training loss: 0.13190229653166044
Validation loss: 2.477946462943426

Epoch: 6| Step: 10
Training loss: 0.0791579887089617
Validation loss: 2.504460247622546

Epoch: 6| Step: 11
Training loss: 0.21672014648548635
Validation loss: 2.487641201586546

Epoch: 6| Step: 12
Training loss: 0.21531447081639704
Validation loss: 2.465798243835391

Epoch: 6| Step: 13
Training loss: 0.07989687294555117
Validation loss: 2.4663434618259674

Epoch: 529| Step: 0
Training loss: 0.09990354184861387
Validation loss: 2.4262238040799473

Epoch: 6| Step: 1
Training loss: 0.11096179655801156
Validation loss: 2.3980491147090004

Epoch: 6| Step: 2
Training loss: 0.10056069900015452
Validation loss: 2.414160124116355

Epoch: 6| Step: 3
Training loss: 0.1579127826366101
Validation loss: 2.387299595489061

Epoch: 6| Step: 4
Training loss: 0.15787029577164718
Validation loss: 2.4252613042709594

Epoch: 6| Step: 5
Training loss: 0.17465674144036197
Validation loss: 2.407953382830071

Epoch: 6| Step: 6
Training loss: 0.1512818064920725
Validation loss: 2.4030503327804995

Epoch: 6| Step: 7
Training loss: 0.11239971618497727
Validation loss: 2.434434065310946

Epoch: 6| Step: 8
Training loss: 0.26457183686508196
Validation loss: 2.4249605464231347

Epoch: 6| Step: 9
Training loss: 0.12103621592726452
Validation loss: 2.4494570257890764

Epoch: 6| Step: 10
Training loss: 0.160957946682162
Validation loss: 2.4480584261727714

Epoch: 6| Step: 11
Training loss: 0.2416402648543231
Validation loss: 2.409352654004905

Epoch: 6| Step: 12
Training loss: 0.1233384371667487
Validation loss: 2.4589868896552836

Epoch: 6| Step: 13
Training loss: 0.14936171967435619
Validation loss: 2.4365187374451645

Epoch: 530| Step: 0
Training loss: 0.14761674619973633
Validation loss: 2.4560552730741865

Epoch: 6| Step: 1
Training loss: 0.09597371248912882
Validation loss: 2.4780718729239446

Epoch: 6| Step: 2
Training loss: 0.2314307051286215
Validation loss: 2.426081168529718

Epoch: 6| Step: 3
Training loss: 0.1342371238815121
Validation loss: 2.459844316414576

Epoch: 6| Step: 4
Training loss: 0.1294618395517889
Validation loss: 2.467363724568353

Epoch: 6| Step: 5
Training loss: 0.2449995343656397
Validation loss: 2.441362909141507

Epoch: 6| Step: 6
Training loss: 0.12257063377178277
Validation loss: 2.457204085567218

Epoch: 6| Step: 7
Training loss: 0.08891698469108392
Validation loss: 2.433696506513892

Epoch: 6| Step: 8
Training loss: 0.18450331102542974
Validation loss: 2.480470980358276

Epoch: 6| Step: 9
Training loss: 0.10993639314640803
Validation loss: 2.44364507142685

Epoch: 6| Step: 10
Training loss: 0.10016587421667221
Validation loss: 2.4332119508839765

Epoch: 6| Step: 11
Training loss: 0.141839202889497
Validation loss: 2.455919922394651

Epoch: 6| Step: 12
Training loss: 0.15993818696527798
Validation loss: 2.4779770139833355

Epoch: 6| Step: 13
Training loss: 0.13472750719004126
Validation loss: 2.516904380892068

Epoch: 531| Step: 0
Training loss: 0.13827830866471041
Validation loss: 2.4737967800549487

Epoch: 6| Step: 1
Training loss: 0.10342348694600527
Validation loss: 2.466627842060753

Epoch: 6| Step: 2
Training loss: 0.20977590525066642
Validation loss: 2.4616838658438125

Epoch: 6| Step: 3
Training loss: 0.08131572902837422
Validation loss: 2.5009437328210824

Epoch: 6| Step: 4
Training loss: 0.23643703945981256
Validation loss: 2.484769352727525

Epoch: 6| Step: 5
Training loss: 0.15052955576319593
Validation loss: 2.45905752623069

Epoch: 6| Step: 6
Training loss: 0.13278350794132185
Validation loss: 2.485146403083393

Epoch: 6| Step: 7
Training loss: 0.1281748017773659
Validation loss: 2.497775150201178

Epoch: 6| Step: 8
Training loss: 0.15339361248777236
Validation loss: 2.505309324540143

Epoch: 6| Step: 9
Training loss: 0.11018332595027196
Validation loss: 2.501294858473796

Epoch: 6| Step: 10
Training loss: 0.0876050282569017
Validation loss: 2.5165412613525504

Epoch: 6| Step: 11
Training loss: 0.22956149901055778
Validation loss: 2.4743145606019246

Epoch: 6| Step: 12
Training loss: 0.11530706973716238
Validation loss: 2.5330947752994972

Epoch: 6| Step: 13
Training loss: 0.08885969926913455
Validation loss: 2.5015330772029767

Epoch: 532| Step: 0
Training loss: 0.15095494647319482
Validation loss: 2.530640060080171

Epoch: 6| Step: 1
Training loss: 0.11384714941571959
Validation loss: 2.5226888462623864

Epoch: 6| Step: 2
Training loss: 0.30519394477196965
Validation loss: 2.533393767364103

Epoch: 6| Step: 3
Training loss: 0.10969230911656547
Validation loss: 2.5207764878385417

Epoch: 6| Step: 4
Training loss: 0.1075931051347405
Validation loss: 2.4942251911850226

Epoch: 6| Step: 5
Training loss: 0.10499961146214669
Validation loss: 2.4994364759637677

Epoch: 6| Step: 6
Training loss: 0.20576030258176578
Validation loss: 2.5080303508593356

Epoch: 6| Step: 7
Training loss: 0.15807052046977496
Validation loss: 2.491155700306612

Epoch: 6| Step: 8
Training loss: 0.12833742872377182
Validation loss: 2.484476387306316

Epoch: 6| Step: 9
Training loss: 0.13520595237529187
Validation loss: 2.456890625241145

Epoch: 6| Step: 10
Training loss: 0.17296580402584377
Validation loss: 2.4300973957498346

Epoch: 6| Step: 11
Training loss: 0.13729416466405173
Validation loss: 2.4724322815067583

Epoch: 6| Step: 12
Training loss: 0.14506520409428378
Validation loss: 2.4480278588575106

Epoch: 6| Step: 13
Training loss: 0.18567935831638885
Validation loss: 2.4350460648178633

Epoch: 533| Step: 0
Training loss: 0.2031748783787593
Validation loss: 2.4229129531966342

Epoch: 6| Step: 1
Training loss: 0.07006769479044311
Validation loss: 2.442981744463142

Epoch: 6| Step: 2
Training loss: 0.12432171404970321
Validation loss: 2.4388029824497073

Epoch: 6| Step: 3
Training loss: 0.2428895327475091
Validation loss: 2.4279290604667874

Epoch: 6| Step: 4
Training loss: 0.12417663664068539
Validation loss: 2.4434387908124635

Epoch: 6| Step: 5
Training loss: 0.18343612316206256
Validation loss: 2.4362608497319234

Epoch: 6| Step: 6
Training loss: 0.09514129438930669
Validation loss: 2.449061444211263

Epoch: 6| Step: 7
Training loss: 0.18884955938336817
Validation loss: 2.4166770863405636

Epoch: 6| Step: 8
Training loss: 0.10850000348673433
Validation loss: 2.4396676825894157

Epoch: 6| Step: 9
Training loss: 0.10810497011588314
Validation loss: 2.439329577135088

Epoch: 6| Step: 10
Training loss: 0.2041600339811246
Validation loss: 2.4324743840749705

Epoch: 6| Step: 11
Training loss: 0.10897757498743711
Validation loss: 2.446639881355685

Epoch: 6| Step: 12
Training loss: 0.15996245545352888
Validation loss: 2.4529171786334607

Epoch: 6| Step: 13
Training loss: 0.3090569846082524
Validation loss: 2.458885415225862

Epoch: 534| Step: 0
Training loss: 0.20694344835998169
Validation loss: 2.515356570402215

Epoch: 6| Step: 1
Training loss: 0.26623048213824096
Validation loss: 2.485113027978278

Epoch: 6| Step: 2
Training loss: 0.10722275398870042
Validation loss: 2.4989464601101132

Epoch: 6| Step: 3
Training loss: 0.0978432105453713
Validation loss: 2.4596165901515024

Epoch: 6| Step: 4
Training loss: 0.12670317767000203
Validation loss: 2.4414900103239185

Epoch: 6| Step: 5
Training loss: 0.12150840368318981
Validation loss: 2.433234658567521

Epoch: 6| Step: 6
Training loss: 0.13720530715890902
Validation loss: 2.488258548580922

Epoch: 6| Step: 7
Training loss: 0.1598396894399721
Validation loss: 2.4570015559984633

Epoch: 6| Step: 8
Training loss: 0.13406835765534916
Validation loss: 2.4763777800375157

Epoch: 6| Step: 9
Training loss: 0.15132312133228853
Validation loss: 2.4209740208267294

Epoch: 6| Step: 10
Training loss: 0.18063924464317135
Validation loss: 2.494040453402151

Epoch: 6| Step: 11
Training loss: 0.14912164034740147
Validation loss: 2.480178733629383

Epoch: 6| Step: 12
Training loss: 0.2115077593233417
Validation loss: 2.4879519061318645

Epoch: 6| Step: 13
Training loss: 0.1482058210333819
Validation loss: 2.4698445323869676

Epoch: 535| Step: 0
Training loss: 0.22836261908791025
Validation loss: 2.484735417473192

Epoch: 6| Step: 1
Training loss: 0.20176669947798143
Validation loss: 2.4536458806571266

Epoch: 6| Step: 2
Training loss: 0.11313168336689287
Validation loss: 2.4678623373640383

Epoch: 6| Step: 3
Training loss: 0.15613073327095175
Validation loss: 2.486870304339271

Epoch: 6| Step: 4
Training loss: 0.17510138006128062
Validation loss: 2.4806473583473765

Epoch: 6| Step: 5
Training loss: 0.2192888095461083
Validation loss: 2.476403698640647

Epoch: 6| Step: 6
Training loss: 0.15632828896898537
Validation loss: 2.435272506594941

Epoch: 6| Step: 7
Training loss: 0.16791920707530533
Validation loss: 2.4462860212855078

Epoch: 6| Step: 8
Training loss: 0.06818222183840465
Validation loss: 2.4574602324070867

Epoch: 6| Step: 9
Training loss: 0.11911058047076309
Validation loss: 2.4467459143514803

Epoch: 6| Step: 10
Training loss: 0.09014071231480081
Validation loss: 2.4807168242401816

Epoch: 6| Step: 11
Training loss: 0.12243684291322508
Validation loss: 2.464521490600291

Epoch: 6| Step: 12
Training loss: 0.11539473125354817
Validation loss: 2.4775666659309503

Epoch: 6| Step: 13
Training loss: 0.14149784367370738
Validation loss: 2.4642193593664876

Epoch: 536| Step: 0
Training loss: 0.16192939832923545
Validation loss: 2.4977092923236213

Epoch: 6| Step: 1
Training loss: 0.10732471233389791
Validation loss: 2.482383571210576

Epoch: 6| Step: 2
Training loss: 0.0616128684023825
Validation loss: 2.4541395190228945

Epoch: 6| Step: 3
Training loss: 0.18392676729211593
Validation loss: 2.3940706096874256

Epoch: 6| Step: 4
Training loss: 0.12412747952701648
Validation loss: 2.4197538817227615

Epoch: 6| Step: 5
Training loss: 0.10722793932588401
Validation loss: 2.4118732173544797

Epoch: 6| Step: 6
Training loss: 0.2288205891361718
Validation loss: 2.4070054716663933

Epoch: 6| Step: 7
Training loss: 0.1573046437072314
Validation loss: 2.399052700197367

Epoch: 6| Step: 8
Training loss: 0.20738123156098895
Validation loss: 2.383016045112495

Epoch: 6| Step: 9
Training loss: 0.24907283666979374
Validation loss: 2.3924735135180306

Epoch: 6| Step: 10
Training loss: 0.13545429795030497
Validation loss: 2.4180092176440837

Epoch: 6| Step: 11
Training loss: 0.16993488612730437
Validation loss: 2.4315626826180297

Epoch: 6| Step: 12
Training loss: 0.13223898701071957
Validation loss: 2.4410124041784447

Epoch: 6| Step: 13
Training loss: 0.09379561625774638
Validation loss: 2.4559973219509565

Epoch: 537| Step: 0
Training loss: 0.14340296012586135
Validation loss: 2.4788444101405593

Epoch: 6| Step: 1
Training loss: 0.19085509882167934
Validation loss: 2.4789629616674462

Epoch: 6| Step: 2
Training loss: 0.07244334405738084
Validation loss: 2.4277523002061425

Epoch: 6| Step: 3
Training loss: 0.10794031144745415
Validation loss: 2.421651978533271

Epoch: 6| Step: 4
Training loss: 0.11968247129169876
Validation loss: 2.428839638044781

Epoch: 6| Step: 5
Training loss: 0.19788414704705912
Validation loss: 2.449989481893551

Epoch: 6| Step: 6
Training loss: 0.17642693611171612
Validation loss: 2.457578148523615

Epoch: 6| Step: 7
Training loss: 0.11285053369562166
Validation loss: 2.446579969361093

Epoch: 6| Step: 8
Training loss: 0.0851828865948696
Validation loss: 2.4535935540126355

Epoch: 6| Step: 9
Training loss: 0.12562426016480577
Validation loss: 2.4541536620780393

Epoch: 6| Step: 10
Training loss: 0.17138139874061742
Validation loss: 2.4714882274424634

Epoch: 6| Step: 11
Training loss: 0.12719476151884468
Validation loss: 2.459497910267879

Epoch: 6| Step: 12
Training loss: 0.23608272201058572
Validation loss: 2.458252657454165

Epoch: 6| Step: 13
Training loss: 0.0503219849482237
Validation loss: 2.500002572868418

Epoch: 538| Step: 0
Training loss: 0.15028997248487977
Validation loss: 2.5107578710685363

Epoch: 6| Step: 1
Training loss: 0.12410003444438114
Validation loss: 2.543204940640159

Epoch: 6| Step: 2
Training loss: 0.1553451924100714
Validation loss: 2.4954768065192994

Epoch: 6| Step: 3
Training loss: 0.15773765942204018
Validation loss: 2.5090097682119925

Epoch: 6| Step: 4
Training loss: 0.19481744969590517
Validation loss: 2.504023120489535

Epoch: 6| Step: 5
Training loss: 0.15554770353049657
Validation loss: 2.4819206414068304

Epoch: 6| Step: 6
Training loss: 0.22376767718690818
Validation loss: 2.4802085057167873

Epoch: 6| Step: 7
Training loss: 0.10582661843336336
Validation loss: 2.4519086729788566

Epoch: 6| Step: 8
Training loss: 0.08300385185217296
Validation loss: 2.4448808880622215

Epoch: 6| Step: 9
Training loss: 0.15130576456442657
Validation loss: 2.487051190750365

Epoch: 6| Step: 10
Training loss: 0.10093735444645972
Validation loss: 2.455817977793408

Epoch: 6| Step: 11
Training loss: 0.21275213093928758
Validation loss: 2.4749471946959143

Epoch: 6| Step: 12
Training loss: 0.1466116733555854
Validation loss: 2.4283912465736677

Epoch: 6| Step: 13
Training loss: 0.11655367869652611
Validation loss: 2.455762440376187

Epoch: 539| Step: 0
Training loss: 0.14464972769223403
Validation loss: 2.446567012702904

Epoch: 6| Step: 1
Training loss: 0.12833391637122663
Validation loss: 2.4871456376364103

Epoch: 6| Step: 2
Training loss: 0.20939571683790162
Validation loss: 2.482347780540923

Epoch: 6| Step: 3
Training loss: 0.13087330929029348
Validation loss: 2.5117040196205958

Epoch: 6| Step: 4
Training loss: 0.2153759866084141
Validation loss: 2.4980694741255967

Epoch: 6| Step: 5
Training loss: 0.13463097908729812
Validation loss: 2.543669430488094

Epoch: 6| Step: 6
Training loss: 0.14807542762098858
Validation loss: 2.5380385072706466

Epoch: 6| Step: 7
Training loss: 0.10829974742426923
Validation loss: 2.5435918274600047

Epoch: 6| Step: 8
Training loss: 0.14165790357788025
Validation loss: 2.4939359295574626

Epoch: 6| Step: 9
Training loss: 0.20936810389591878
Validation loss: 2.513306784912981

Epoch: 6| Step: 10
Training loss: 0.21362500871029966
Validation loss: 2.5120901246194283

Epoch: 6| Step: 11
Training loss: 0.21439410754260363
Validation loss: 2.498671425790317

Epoch: 6| Step: 12
Training loss: 0.20640095547304302
Validation loss: 2.5064594558417004

Epoch: 6| Step: 13
Training loss: 0.17287175550884742
Validation loss: 2.4973797079335576

Epoch: 540| Step: 0
Training loss: 0.11866371665420479
Validation loss: 2.525181582523319

Epoch: 6| Step: 1
Training loss: 0.15859736663941496
Validation loss: 2.509350982233555

Epoch: 6| Step: 2
Training loss: 0.1352268357161483
Validation loss: 2.510219813557441

Epoch: 6| Step: 3
Training loss: 0.09875917366429059
Validation loss: 2.5103674247104992

Epoch: 6| Step: 4
Training loss: 0.21293819840867834
Validation loss: 2.519365562872908

Epoch: 6| Step: 5
Training loss: 0.12408227726260307
Validation loss: 2.521956080279876

Epoch: 6| Step: 6
Training loss: 0.13208468247601063
Validation loss: 2.4964840658413667

Epoch: 6| Step: 7
Training loss: 0.1521859084913628
Validation loss: 2.51250482041524

Epoch: 6| Step: 8
Training loss: 0.18376293908838648
Validation loss: 2.469540752990256

Epoch: 6| Step: 9
Training loss: 0.1408793612628434
Validation loss: 2.4537577066906513

Epoch: 6| Step: 10
Training loss: 0.11833167601807754
Validation loss: 2.449157566492346

Epoch: 6| Step: 11
Training loss: 0.21877447059544625
Validation loss: 2.431854336967534

Epoch: 6| Step: 12
Training loss: 0.23506459671044902
Validation loss: 2.39442244973115

Epoch: 6| Step: 13
Training loss: 0.16133874391794595
Validation loss: 2.4083783885075176

Epoch: 541| Step: 0
Training loss: 0.22288254063676696
Validation loss: 2.44254391965677

Epoch: 6| Step: 1
Training loss: 0.09560396935570122
Validation loss: 2.4553911391015433

Epoch: 6| Step: 2
Training loss: 0.22356317926943003
Validation loss: 2.4730363828475515

Epoch: 6| Step: 3
Training loss: 0.13720060991893332
Validation loss: 2.4661523525843463

Epoch: 6| Step: 4
Training loss: 0.17293793734649238
Validation loss: 2.4803407676907256

Epoch: 6| Step: 5
Training loss: 0.1417941132583905
Validation loss: 2.4878109512146938

Epoch: 6| Step: 6
Training loss: 0.10319855100875647
Validation loss: 2.4769722862925696

Epoch: 6| Step: 7
Training loss: 0.1018855386092426
Validation loss: 2.499470909080105

Epoch: 6| Step: 8
Training loss: 0.15538346093312116
Validation loss: 2.469757411405047

Epoch: 6| Step: 9
Training loss: 0.14448999125308687
Validation loss: 2.475542050722381

Epoch: 6| Step: 10
Training loss: 0.1316976033405436
Validation loss: 2.4633742579550613

Epoch: 6| Step: 11
Training loss: 0.20941860328537343
Validation loss: 2.4982411216704774

Epoch: 6| Step: 12
Training loss: 0.09376154272228783
Validation loss: 2.456949469855883

Epoch: 6| Step: 13
Training loss: 0.15427886278307965
Validation loss: 2.479624675848634

Epoch: 542| Step: 0
Training loss: 0.06707602612659226
Validation loss: 2.455919895254248

Epoch: 6| Step: 1
Training loss: 0.19144767196250534
Validation loss: 2.4252233376397863

Epoch: 6| Step: 2
Training loss: 0.16184831763887736
Validation loss: 2.4755076016613824

Epoch: 6| Step: 3
Training loss: 0.16704910825179076
Validation loss: 2.4407231424201856

Epoch: 6| Step: 4
Training loss: 0.09942353433929613
Validation loss: 2.4298673785478537

Epoch: 6| Step: 5
Training loss: 0.13443522794684323
Validation loss: 2.4686534982670305

Epoch: 6| Step: 6
Training loss: 0.14561982931526837
Validation loss: 2.4172435287001

Epoch: 6| Step: 7
Training loss: 0.23411094572885519
Validation loss: 2.415982126286959

Epoch: 6| Step: 8
Training loss: 0.1150148086044696
Validation loss: 2.4262790740788445

Epoch: 6| Step: 9
Training loss: 0.12256146613778716
Validation loss: 2.4737435365616163

Epoch: 6| Step: 10
Training loss: 0.22050820241645283
Validation loss: 2.5097192377504225

Epoch: 6| Step: 11
Training loss: 0.17560578171527455
Validation loss: 2.476491748848201

Epoch: 6| Step: 12
Training loss: 0.1415504231680403
Validation loss: 2.4573976913292026

Epoch: 6| Step: 13
Training loss: 0.10687613576569975
Validation loss: 2.5181178385539624

Epoch: 543| Step: 0
Training loss: 0.19251179123349163
Validation loss: 2.4945182490332547

Epoch: 6| Step: 1
Training loss: 0.09189970263403455
Validation loss: 2.502481922637026

Epoch: 6| Step: 2
Training loss: 0.11318100818514672
Validation loss: 2.484845538476156

Epoch: 6| Step: 3
Training loss: 0.19714146663162305
Validation loss: 2.4809449490411013

Epoch: 6| Step: 4
Training loss: 0.19621425360813222
Validation loss: 2.465919208133393

Epoch: 6| Step: 5
Training loss: 0.21921335261274214
Validation loss: 2.4918849711428

Epoch: 6| Step: 6
Training loss: 0.118613483988455
Validation loss: 2.4975011550293136

Epoch: 6| Step: 7
Training loss: 0.1800058074848779
Validation loss: 2.4811417827759117

Epoch: 6| Step: 8
Training loss: 0.11846778000057404
Validation loss: 2.465793234133165

Epoch: 6| Step: 9
Training loss: 0.11434886434428553
Validation loss: 2.508288514934673

Epoch: 6| Step: 10
Training loss: 0.13529563425378247
Validation loss: 2.5129559553110163

Epoch: 6| Step: 11
Training loss: 0.10861839282405511
Validation loss: 2.491135669369259

Epoch: 6| Step: 12
Training loss: 0.10589209997391877
Validation loss: 2.501988580911409

Epoch: 6| Step: 13
Training loss: 0.07178282554609573
Validation loss: 2.4773006770841404

Epoch: 544| Step: 0
Training loss: 0.07494691594370098
Validation loss: 2.4891926901794803

Epoch: 6| Step: 1
Training loss: 0.15018045924919662
Validation loss: 2.4998436540506734

Epoch: 6| Step: 2
Training loss: 0.19004445357482724
Validation loss: 2.4814805546912067

Epoch: 6| Step: 3
Training loss: 0.08805925299179368
Validation loss: 2.4801621651730676

Epoch: 6| Step: 4
Training loss: 0.12297836167386382
Validation loss: 2.4855342324095484

Epoch: 6| Step: 5
Training loss: 0.19359670388936973
Validation loss: 2.48775835184325

Epoch: 6| Step: 6
Training loss: 0.15287587569821093
Validation loss: 2.507729966344629

Epoch: 6| Step: 7
Training loss: 0.15042553533639821
Validation loss: 2.507577216457952

Epoch: 6| Step: 8
Training loss: 0.1300229915131517
Validation loss: 2.523010976760895

Epoch: 6| Step: 9
Training loss: 0.1930509959560264
Validation loss: 2.521818428377374

Epoch: 6| Step: 10
Training loss: 0.14106937900286534
Validation loss: 2.4937181180682684

Epoch: 6| Step: 11
Training loss: 0.22060150575223356
Validation loss: 2.461112398728894

Epoch: 6| Step: 12
Training loss: 0.1622245046538816
Validation loss: 2.4922479470521344

Epoch: 6| Step: 13
Training loss: 0.14899329234312614
Validation loss: 2.4844497325799306

Epoch: 545| Step: 0
Training loss: 0.1468823050650538
Validation loss: 2.4645146480340667

Epoch: 6| Step: 1
Training loss: 0.24113296298676304
Validation loss: 2.4857506003582017

Epoch: 6| Step: 2
Training loss: 0.07700580981555796
Validation loss: 2.527763611153835

Epoch: 6| Step: 3
Training loss: 0.21099978869493127
Validation loss: 2.482319579120863

Epoch: 6| Step: 4
Training loss: 0.0683232859307438
Validation loss: 2.52439226589487

Epoch: 6| Step: 5
Training loss: 0.22445200507219534
Validation loss: 2.4986051729169825

Epoch: 6| Step: 6
Training loss: 0.10246570324476388
Validation loss: 2.5168393770198234

Epoch: 6| Step: 7
Training loss: 0.29031438635961626
Validation loss: 2.5052721381571303

Epoch: 6| Step: 8
Training loss: 0.1955659366450781
Validation loss: 2.4830496992390985

Epoch: 6| Step: 9
Training loss: 0.1477062382928352
Validation loss: 2.4594818268615146

Epoch: 6| Step: 10
Training loss: 0.15471175706809387
Validation loss: 2.425702702940519

Epoch: 6| Step: 11
Training loss: 0.17703160530856
Validation loss: 2.4404406028275334

Epoch: 6| Step: 12
Training loss: 0.15560740417372348
Validation loss: 2.4434068248182883

Epoch: 6| Step: 13
Training loss: 0.09886846152682571
Validation loss: 2.4479965821789964

Epoch: 546| Step: 0
Training loss: 0.11606766981546905
Validation loss: 2.447149902218186

Epoch: 6| Step: 1
Training loss: 0.1845275486244617
Validation loss: 2.469042919388576

Epoch: 6| Step: 2
Training loss: 0.08690817148624816
Validation loss: 2.4470161542802393

Epoch: 6| Step: 3
Training loss: 0.2347838888188866
Validation loss: 2.4507841352562765

Epoch: 6| Step: 4
Training loss: 0.1813406569568644
Validation loss: 2.4415052231282535

Epoch: 6| Step: 5
Training loss: 0.13773471187435676
Validation loss: 2.4403637543434575

Epoch: 6| Step: 6
Training loss: 0.12704678528444394
Validation loss: 2.4505667168512377

Epoch: 6| Step: 7
Training loss: 0.13640509457442954
Validation loss: 2.4497256124713838

Epoch: 6| Step: 8
Training loss: 0.1990784824458848
Validation loss: 2.424910398163548

Epoch: 6| Step: 9
Training loss: 0.1652296196363749
Validation loss: 2.456605881705514

Epoch: 6| Step: 10
Training loss: 0.1995166066561071
Validation loss: 2.4352590979018713

Epoch: 6| Step: 11
Training loss: 0.12970163141954721
Validation loss: 2.4427505733697332

Epoch: 6| Step: 12
Training loss: 0.14496986746105506
Validation loss: 2.4671723982134406

Epoch: 6| Step: 13
Training loss: 0.12030605261730645
Validation loss: 2.4746514514028743

Epoch: 547| Step: 0
Training loss: 0.15076306287747246
Validation loss: 2.4855265926373327

Epoch: 6| Step: 1
Training loss: 0.10187133727627283
Validation loss: 2.5062083586527524

Epoch: 6| Step: 2
Training loss: 0.22645571263810982
Validation loss: 2.4821254033312456

Epoch: 6| Step: 3
Training loss: 0.09604083053958608
Validation loss: 2.4924653722242565

Epoch: 6| Step: 4
Training loss: 0.24796148767875711
Validation loss: 2.489686516293303

Epoch: 6| Step: 5
Training loss: 0.11811949149412282
Validation loss: 2.4882535057963557

Epoch: 6| Step: 6
Training loss: 0.20063076576967576
Validation loss: 2.4691087169585395

Epoch: 6| Step: 7
Training loss: 0.12202822913510483
Validation loss: 2.418882789876703

Epoch: 6| Step: 8
Training loss: 0.20353327581263425
Validation loss: 2.448574125712504

Epoch: 6| Step: 9
Training loss: 0.16750721398162985
Validation loss: 2.3989658755072547

Epoch: 6| Step: 10
Training loss: 0.2182061041312074
Validation loss: 2.4125262687945113

Epoch: 6| Step: 11
Training loss: 0.11646827287118189
Validation loss: 2.436047791647065

Epoch: 6| Step: 12
Training loss: 0.16695283124841634
Validation loss: 2.4523367429490732

Epoch: 6| Step: 13
Training loss: 0.3153351089832975
Validation loss: 2.448686058251796

Epoch: 548| Step: 0
Training loss: 0.11693981539586504
Validation loss: 2.4975821195583476

Epoch: 6| Step: 1
Training loss: 0.2005506571764891
Validation loss: 2.5501792290378886

Epoch: 6| Step: 2
Training loss: 0.1838854845910129
Validation loss: 2.5412555552394047

Epoch: 6| Step: 3
Training loss: 0.2580592390811998
Validation loss: 2.4865763033801382

Epoch: 6| Step: 4
Training loss: 0.17654988404159172
Validation loss: 2.476011343857762

Epoch: 6| Step: 5
Training loss: 0.1963736982690948
Validation loss: 2.4880584716491585

Epoch: 6| Step: 6
Training loss: 0.2907901889220343
Validation loss: 2.487017219629016

Epoch: 6| Step: 7
Training loss: 0.11893050237823896
Validation loss: 2.4758476575761508

Epoch: 6| Step: 8
Training loss: 0.1651141938063812
Validation loss: 2.4231459909034907

Epoch: 6| Step: 9
Training loss: 0.10961431904747361
Validation loss: 2.4253872007789967

Epoch: 6| Step: 10
Training loss: 0.12312876156444187
Validation loss: 2.465352310316511

Epoch: 6| Step: 11
Training loss: 0.11986196354052678
Validation loss: 2.451764796319477

Epoch: 6| Step: 12
Training loss: 0.13898536680702878
Validation loss: 2.466478527374989

Epoch: 6| Step: 13
Training loss: 0.20438648031228962
Validation loss: 2.471851861304914

Epoch: 549| Step: 0
Training loss: 0.15640271591553448
Validation loss: 2.4885582062964984

Epoch: 6| Step: 1
Training loss: 0.15940945079987348
Validation loss: 2.4795687142573986

Epoch: 6| Step: 2
Training loss: 0.1395373936632314
Validation loss: 2.5352058920882414

Epoch: 6| Step: 3
Training loss: 0.14002368102999355
Validation loss: 2.4904414746432364

Epoch: 6| Step: 4
Training loss: 0.14693330637213978
Validation loss: 2.4879656101928824

Epoch: 6| Step: 5
Training loss: 0.20326374890510487
Validation loss: 2.493481598148922

Epoch: 6| Step: 6
Training loss: 0.11409131985889287
Validation loss: 2.489860028789069

Epoch: 6| Step: 7
Training loss: 0.1627270810639444
Validation loss: 2.4788345520506248

Epoch: 6| Step: 8
Training loss: 0.21979635189962535
Validation loss: 2.478917977949644

Epoch: 6| Step: 9
Training loss: 0.16313170744453742
Validation loss: 2.457706073835256

Epoch: 6| Step: 10
Training loss: 0.2073815189766004
Validation loss: 2.4484022400289747

Epoch: 6| Step: 11
Training loss: 0.24769796026234742
Validation loss: 2.4727037451783596

Epoch: 6| Step: 12
Training loss: 0.17491334063763395
Validation loss: 2.464615693059903

Epoch: 6| Step: 13
Training loss: 0.14007936028203402
Validation loss: 2.49536582321712

Epoch: 550| Step: 0
Training loss: 0.15247434740372515
Validation loss: 2.5158496833547184

Epoch: 6| Step: 1
Training loss: 0.10682214738598897
Validation loss: 2.514948364174131

Epoch: 6| Step: 2
Training loss: 0.16412812010580458
Validation loss: 2.5742597136481944

Epoch: 6| Step: 3
Training loss: 0.156029593463694
Validation loss: 2.5835364464001733

Epoch: 6| Step: 4
Training loss: 0.2306380781352636
Validation loss: 2.5233301309855767

Epoch: 6| Step: 5
Training loss: 0.1852737424181609
Validation loss: 2.5043961931563565

Epoch: 6| Step: 6
Training loss: 0.10709546087833582
Validation loss: 2.4702783612059

Epoch: 6| Step: 7
Training loss: 0.18109280000952568
Validation loss: 2.437870287792013

Epoch: 6| Step: 8
Training loss: 0.3035446644052229
Validation loss: 2.4170690787738143

Epoch: 6| Step: 9
Training loss: 0.3006116215352118
Validation loss: 2.418298970618044

Epoch: 6| Step: 10
Training loss: 0.18735864397138094
Validation loss: 2.4378220298376148

Epoch: 6| Step: 11
Training loss: 0.22141306972297917
Validation loss: 2.454834010874707

Epoch: 6| Step: 12
Training loss: 0.163903659040048
Validation loss: 2.4866993379078286

Epoch: 6| Step: 13
Training loss: 0.44425750710944695
Validation loss: 2.4826612577131715

Epoch: 551| Step: 0
Training loss: 0.27243441107360294
Validation loss: 2.4479803645622416

Epoch: 6| Step: 1
Training loss: 0.11001451044394404
Validation loss: 2.4903956528937248

Epoch: 6| Step: 2
Training loss: 0.21379251787824977
Validation loss: 2.488521059081135

Epoch: 6| Step: 3
Training loss: 0.22077785340846307
Validation loss: 2.4368907712972

Epoch: 6| Step: 4
Training loss: 0.21420353955804677
Validation loss: 2.4511793896626473

Epoch: 6| Step: 5
Training loss: 0.1992221065313276
Validation loss: 2.4884083221958426

Epoch: 6| Step: 6
Training loss: 0.37913307793976286
Validation loss: 2.4847935985437166

Epoch: 6| Step: 7
Training loss: 0.23077001116846863
Validation loss: 2.554966236793901

Epoch: 6| Step: 8
Training loss: 0.22641045302549975
Validation loss: 2.561197948029884

Epoch: 6| Step: 9
Training loss: 0.32663917188998637
Validation loss: 2.5571332577993813

Epoch: 6| Step: 10
Training loss: 0.2613378286342021
Validation loss: 2.5574726924268956

Epoch: 6| Step: 11
Training loss: 0.1863313954544152
Validation loss: 2.5116116833231525

Epoch: 6| Step: 12
Training loss: 0.39305939283096686
Validation loss: 2.5298637747821053

Epoch: 6| Step: 13
Training loss: 0.3275864359308349
Validation loss: 2.5297281806968073

Epoch: 552| Step: 0
Training loss: 0.36022171534355785
Validation loss: 2.5249438023818946

Epoch: 6| Step: 1
Training loss: 0.18807744475429677
Validation loss: 2.5050254584305334

Epoch: 6| Step: 2
Training loss: 0.15951066040270884
Validation loss: 2.463447745050688

Epoch: 6| Step: 3
Training loss: 0.3105855473844688
Validation loss: 2.5206379802458505

Epoch: 6| Step: 4
Training loss: 0.24644854870127222
Validation loss: 2.4646147007292667

Epoch: 6| Step: 5
Training loss: 0.24869246834717115
Validation loss: 2.4858025223570657

Epoch: 6| Step: 6
Training loss: 0.26304394869058967
Validation loss: 2.51271332539355

Epoch: 6| Step: 7
Training loss: 0.2608751250999235
Validation loss: 2.514869810468079

Epoch: 6| Step: 8
Training loss: 0.2565533784366945
Validation loss: 2.5673608644438892

Epoch: 6| Step: 9
Training loss: 0.2716274433377194
Validation loss: 2.6015240011926766

Epoch: 6| Step: 10
Training loss: 0.28912678854241103
Validation loss: 2.608128648466707

Epoch: 6| Step: 11
Training loss: 0.2767934847545238
Validation loss: 2.565256070780571

Epoch: 6| Step: 12
Training loss: 0.3269807756005002
Validation loss: 2.5365931874794176

Epoch: 6| Step: 13
Training loss: 0.16199568128164216
Validation loss: 2.511760909517811

Epoch: 553| Step: 0
Training loss: 0.22194903978551275
Validation loss: 2.4682575657359065

Epoch: 6| Step: 1
Training loss: 0.23594011027426914
Validation loss: 2.497088384719504

Epoch: 6| Step: 2
Training loss: 0.1963592897112793
Validation loss: 2.4902673139490843

Epoch: 6| Step: 3
Training loss: 0.245000287026607
Validation loss: 2.5156934226062

Epoch: 6| Step: 4
Training loss: 0.22028968706450672
Validation loss: 2.538448295926355

Epoch: 6| Step: 5
Training loss: 0.2709450613548492
Validation loss: 2.55531580526963

Epoch: 6| Step: 6
Training loss: 0.26270363663315177
Validation loss: 2.524099334489996

Epoch: 6| Step: 7
Training loss: 0.3475365807812427
Validation loss: 2.509749389764468

Epoch: 6| Step: 8
Training loss: 0.3152563250532617
Validation loss: 2.482825593424602

Epoch: 6| Step: 9
Training loss: 0.19462724638066975
Validation loss: 2.4619840580018

Epoch: 6| Step: 10
Training loss: 0.2077166350538082
Validation loss: 2.489007216579778

Epoch: 6| Step: 11
Training loss: 0.28833124094315954
Validation loss: 2.4849454483208326

Epoch: 6| Step: 12
Training loss: 0.18809646862173915
Validation loss: 2.4864061972607323

Epoch: 6| Step: 13
Training loss: 0.2716372628891208
Validation loss: 2.5135671006681015

Epoch: 554| Step: 0
Training loss: 0.13590470883163772
Validation loss: 2.5137122358692285

Epoch: 6| Step: 1
Training loss: 0.13029222567390283
Validation loss: 2.5103305445648876

Epoch: 6| Step: 2
Training loss: 0.22121718132291654
Validation loss: 2.5215216456032996

Epoch: 6| Step: 3
Training loss: 0.2716349314635212
Validation loss: 2.5353733247076398

Epoch: 6| Step: 4
Training loss: 0.09876163492590358
Validation loss: 2.5204311718890016

Epoch: 6| Step: 5
Training loss: 0.09580543460102034
Validation loss: 2.4911552228055998

Epoch: 6| Step: 6
Training loss: 0.19497328865673694
Validation loss: 2.504097690532876

Epoch: 6| Step: 7
Training loss: 0.33598788571090243
Validation loss: 2.514634915044809

Epoch: 6| Step: 8
Training loss: 0.18530639323164338
Validation loss: 2.471746698387287

Epoch: 6| Step: 9
Training loss: 0.19288722103633438
Validation loss: 2.4606061669079398

Epoch: 6| Step: 10
Training loss: 0.24742298813748057
Validation loss: 2.472151702817431

Epoch: 6| Step: 11
Training loss: 0.24627987317360034
Validation loss: 2.513138809423022

Epoch: 6| Step: 12
Training loss: 0.26742641296904973
Validation loss: 2.5121732058982893

Epoch: 6| Step: 13
Training loss: 0.3245537876683881
Validation loss: 2.514126926165289

Epoch: 555| Step: 0
Training loss: 0.2088702505217773
Validation loss: 2.511374594658007

Epoch: 6| Step: 1
Training loss: 0.3069244334850224
Validation loss: 2.5134282947252733

Epoch: 6| Step: 2
Training loss: 0.21504371180692428
Validation loss: 2.5302195292880736

Epoch: 6| Step: 3
Training loss: 0.2513611811325604
Validation loss: 2.516060045254714

Epoch: 6| Step: 4
Training loss: 0.2139684881390072
Validation loss: 2.49199875849735

Epoch: 6| Step: 5
Training loss: 0.1851644087655783
Validation loss: 2.48725243507935

Epoch: 6| Step: 6
Training loss: 0.3531190534107854
Validation loss: 2.539317465728683

Epoch: 6| Step: 7
Training loss: 0.18484673161492143
Validation loss: 2.4842711323959685

Epoch: 6| Step: 8
Training loss: 0.32623292728491826
Validation loss: 2.545181193331697

Epoch: 6| Step: 9
Training loss: 0.3058057462756136
Validation loss: 2.5427399246573534

Epoch: 6| Step: 10
Training loss: 0.13762667142232482
Validation loss: 2.5255508099862998

Epoch: 6| Step: 11
Training loss: 0.16856068725339637
Validation loss: 2.4793145216747514

Epoch: 6| Step: 12
Training loss: 0.11560745782779594
Validation loss: 2.508836979788968

Epoch: 6| Step: 13
Training loss: 0.15068261176510622
Validation loss: 2.4854305741594453

Epoch: 556| Step: 0
Training loss: 0.2763569833334202
Validation loss: 2.5331519387667294

Epoch: 6| Step: 1
Training loss: 0.2640061696480376
Validation loss: 2.5449715794417016

Epoch: 6| Step: 2
Training loss: 0.2981584187736514
Validation loss: 2.532854760277399

Epoch: 6| Step: 3
Training loss: 0.23936747159399122
Validation loss: 2.5161319971560134

Epoch: 6| Step: 4
Training loss: 0.18919015113868384
Validation loss: 2.5331032624096377

Epoch: 6| Step: 5
Training loss: 0.4181885898742932
Validation loss: 2.5398621093138125

Epoch: 6| Step: 6
Training loss: 0.2600919065436489
Validation loss: 2.512145189286096

Epoch: 6| Step: 7
Training loss: 0.16417161401161717
Validation loss: 2.5221705404111265

Epoch: 6| Step: 8
Training loss: 0.2590826708185071
Validation loss: 2.501495051703344

Epoch: 6| Step: 9
Training loss: 0.31263684614327514
Validation loss: 2.508325859987802

Epoch: 6| Step: 10
Training loss: 0.16719743039595567
Validation loss: 2.520966612681547

Epoch: 6| Step: 11
Training loss: 0.12467611343335233
Validation loss: 2.539840974696864

Epoch: 6| Step: 12
Training loss: 0.23311286278493473
Validation loss: 2.54877113608921

Epoch: 6| Step: 13
Training loss: 0.13558971294266975
Validation loss: 2.5227501975585183

Epoch: 557| Step: 0
Training loss: 0.12096669853725672
Validation loss: 2.5231431338356054

Epoch: 6| Step: 1
Training loss: 0.2546584358481972
Validation loss: 2.5426472252264696

Epoch: 6| Step: 2
Training loss: 0.2312839766621144
Validation loss: 2.5658136218198675

Epoch: 6| Step: 3
Training loss: 0.15444469614140877
Validation loss: 2.57989260778239

Epoch: 6| Step: 4
Training loss: 0.10601818060553093
Validation loss: 2.581807345431233

Epoch: 6| Step: 5
Training loss: 0.18405070152097203
Validation loss: 2.580553840680113

Epoch: 6| Step: 6
Training loss: 0.21386926031632314
Validation loss: 2.5685491616461427

Epoch: 6| Step: 7
Training loss: 0.23561719885289498
Validation loss: 2.514240542004218

Epoch: 6| Step: 8
Training loss: 0.16215803381254276
Validation loss: 2.499782807134462

Epoch: 6| Step: 9
Training loss: 0.15284585128553352
Validation loss: 2.4808646206183176

Epoch: 6| Step: 10
Training loss: 0.23509531594043548
Validation loss: 2.5056519566585687

Epoch: 6| Step: 11
Training loss: 0.13751847836568565
Validation loss: 2.4938334388126977

Epoch: 6| Step: 12
Training loss: 0.1843220691350628
Validation loss: 2.51377608405488

Epoch: 6| Step: 13
Training loss: 0.1615529737947511
Validation loss: 2.5166595549205537

Epoch: 558| Step: 0
Training loss: 0.18541782308246446
Validation loss: 2.5149262780889776

Epoch: 6| Step: 1
Training loss: 0.15398158683942847
Validation loss: 2.5293452992572543

Epoch: 6| Step: 2
Training loss: 0.19662501873760777
Validation loss: 2.5104082742505742

Epoch: 6| Step: 3
Training loss: 0.21214796596889812
Validation loss: 2.5428865780908763

Epoch: 6| Step: 4
Training loss: 0.10083651579840816
Validation loss: 2.570851020940281

Epoch: 6| Step: 5
Training loss: 0.19571871476505795
Validation loss: 2.5309410752387147

Epoch: 6| Step: 6
Training loss: 0.21983701684776896
Validation loss: 2.5278399148550648

Epoch: 6| Step: 7
Training loss: 0.18709507570996498
Validation loss: 2.5370479303697366

Epoch: 6| Step: 8
Training loss: 0.17491913890019148
Validation loss: 2.49474433030056

Epoch: 6| Step: 9
Training loss: 0.11526120002938325
Validation loss: 2.50545484242375

Epoch: 6| Step: 10
Training loss: 0.20583474592800086
Validation loss: 2.5252690715170028

Epoch: 6| Step: 11
Training loss: 0.1420824763429737
Validation loss: 2.501364449427973

Epoch: 6| Step: 12
Training loss: 0.18272602693392076
Validation loss: 2.487702766960186

Epoch: 6| Step: 13
Training loss: 0.19441409432363221
Validation loss: 2.5309167143973608

Epoch: 559| Step: 0
Training loss: 0.13560327791040053
Validation loss: 2.4852059857076756

Epoch: 6| Step: 1
Training loss: 0.09063964223961854
Validation loss: 2.5304574661290262

Epoch: 6| Step: 2
Training loss: 0.16059587199688502
Validation loss: 2.5174855459027055

Epoch: 6| Step: 3
Training loss: 0.16122194772496762
Validation loss: 2.51781454092964

Epoch: 6| Step: 4
Training loss: 0.17847187958666727
Validation loss: 2.522032804663018

Epoch: 6| Step: 5
Training loss: 0.21336569843399084
Validation loss: 2.5260956339287852

Epoch: 6| Step: 6
Training loss: 0.17263456506180913
Validation loss: 2.50917161401748

Epoch: 6| Step: 7
Training loss: 0.13767378212630993
Validation loss: 2.4950413349171914

Epoch: 6| Step: 8
Training loss: 0.13870703560388348
Validation loss: 2.5098859375498934

Epoch: 6| Step: 9
Training loss: 0.2092233610464139
Validation loss: 2.478903081098348

Epoch: 6| Step: 10
Training loss: 0.22755229076522437
Validation loss: 2.4573211303286064

Epoch: 6| Step: 11
Training loss: 0.17958495074810196
Validation loss: 2.510567229425404

Epoch: 6| Step: 12
Training loss: 0.15851474024721732
Validation loss: 2.5209314074176534

Epoch: 6| Step: 13
Training loss: 0.3762236736757118
Validation loss: 2.5237703968911664

Epoch: 560| Step: 0
Training loss: 0.16695753373754352
Validation loss: 2.578610409520395

Epoch: 6| Step: 1
Training loss: 0.22788340172944355
Validation loss: 2.582183251093932

Epoch: 6| Step: 2
Training loss: 0.24914190428995409
Validation loss: 2.6185190011062773

Epoch: 6| Step: 3
Training loss: 0.20134578520797008
Validation loss: 2.626258536680142

Epoch: 6| Step: 4
Training loss: 0.22296800872583278
Validation loss: 2.5913498516443294

Epoch: 6| Step: 5
Training loss: 0.19146281982896252
Validation loss: 2.57259206894362

Epoch: 6| Step: 6
Training loss: 0.12247193452900262
Validation loss: 2.5410976576539293

Epoch: 6| Step: 7
Training loss: 0.09911514602631036
Validation loss: 2.507626925036691

Epoch: 6| Step: 8
Training loss: 0.1091198200897779
Validation loss: 2.489484971342563

Epoch: 6| Step: 9
Training loss: 0.1936090860611723
Validation loss: 2.4708531057385676

Epoch: 6| Step: 10
Training loss: 0.18372179192757887
Validation loss: 2.476224150596162

Epoch: 6| Step: 11
Training loss: 0.12697441216043764
Validation loss: 2.5129438229177725

Epoch: 6| Step: 12
Training loss: 0.1179309429128414
Validation loss: 2.4585051433939524

Epoch: 6| Step: 13
Training loss: 0.30706945429139604
Validation loss: 2.4984889273165067

Epoch: 561| Step: 0
Training loss: 0.23406759606684766
Validation loss: 2.4809851680762187

Epoch: 6| Step: 1
Training loss: 0.22970972505074402
Validation loss: 2.5190451624104706

Epoch: 6| Step: 2
Training loss: 0.14418589080223443
Validation loss: 2.479921120842367

Epoch: 6| Step: 3
Training loss: 0.20588427543243423
Validation loss: 2.519641317430982

Epoch: 6| Step: 4
Training loss: 0.2353786041426477
Validation loss: 2.5194074285679275

Epoch: 6| Step: 5
Training loss: 0.22514188087934336
Validation loss: 2.4638003993239668

Epoch: 6| Step: 6
Training loss: 0.15562284491092418
Validation loss: 2.4877119210995664

Epoch: 6| Step: 7
Training loss: 0.15106834937778718
Validation loss: 2.450259585898084

Epoch: 6| Step: 8
Training loss: 0.1711362927380524
Validation loss: 2.464536631973009

Epoch: 6| Step: 9
Training loss: 0.1942297103624905
Validation loss: 2.4451064240148623

Epoch: 6| Step: 10
Training loss: 0.33035387563194446
Validation loss: 2.4928247973762017

Epoch: 6| Step: 11
Training loss: 0.2821600548545437
Validation loss: 2.472797784184298

Epoch: 6| Step: 12
Training loss: 0.1345163749375266
Validation loss: 2.4791102814425865

Epoch: 6| Step: 13
Training loss: 0.23930683023117952
Validation loss: 2.5188618989242753

Epoch: 562| Step: 0
Training loss: 0.23278466128634237
Validation loss: 2.553616426691063

Epoch: 6| Step: 1
Training loss: 0.4778570041176706
Validation loss: 2.584794942608514

Epoch: 6| Step: 2
Training loss: 0.18238248379355604
Validation loss: 2.5430715407915834

Epoch: 6| Step: 3
Training loss: 0.17463550158812516
Validation loss: 2.5311614395422635

Epoch: 6| Step: 4
Training loss: 0.17749516665231396
Validation loss: 2.511674009471438

Epoch: 6| Step: 5
Training loss: 0.21812388529123797
Validation loss: 2.543090189348445

Epoch: 6| Step: 6
Training loss: 0.25402722044545806
Validation loss: 2.5392117490358954

Epoch: 6| Step: 7
Training loss: 0.3709748730234905
Validation loss: 2.5233637524262704

Epoch: 6| Step: 8
Training loss: 0.28481062754588327
Validation loss: 2.4987886078040664

Epoch: 6| Step: 9
Training loss: 0.1225697333756026
Validation loss: 2.4691374819812317

Epoch: 6| Step: 10
Training loss: 0.2735978337652493
Validation loss: 2.4748981028098713

Epoch: 6| Step: 11
Training loss: 0.1350865344137552
Validation loss: 2.4674906812526936

Epoch: 6| Step: 12
Training loss: 0.2140413559265386
Validation loss: 2.454525749021031

Epoch: 6| Step: 13
Training loss: 0.32803054994252406
Validation loss: 2.4956621827263077

Epoch: 563| Step: 0
Training loss: 0.22870160547205023
Validation loss: 2.5066803349641775

Epoch: 6| Step: 1
Training loss: 0.22308181782937886
Validation loss: 2.4780674978911073

Epoch: 6| Step: 2
Training loss: 0.15679098888956622
Validation loss: 2.4891152192587938

Epoch: 6| Step: 3
Training loss: 0.15485932050535992
Validation loss: 2.5093829423466136

Epoch: 6| Step: 4
Training loss: 0.2019667984190731
Validation loss: 2.5345076504194806

Epoch: 6| Step: 5
Training loss: 0.26799160273228223
Validation loss: 2.5667385559764337

Epoch: 6| Step: 6
Training loss: 0.1906055127798648
Validation loss: 2.4811166813813634

Epoch: 6| Step: 7
Training loss: 0.10930069033962278
Validation loss: 2.542580925446545

Epoch: 6| Step: 8
Training loss: 0.2740334691816868
Validation loss: 2.5661630213528603

Epoch: 6| Step: 9
Training loss: 0.19109594727482634
Validation loss: 2.5505737356963323

Epoch: 6| Step: 10
Training loss: 0.21309068886051435
Validation loss: 2.534814791342981

Epoch: 6| Step: 11
Training loss: 0.17581745410656002
Validation loss: 2.509467109300742

Epoch: 6| Step: 12
Training loss: 0.2709808895210483
Validation loss: 2.5170350150803182

Epoch: 6| Step: 13
Training loss: 0.1868882929816947
Validation loss: 2.4679031498027775

Epoch: 564| Step: 0
Training loss: 0.23390283708242124
Validation loss: 2.526113270153973

Epoch: 6| Step: 1
Training loss: 0.21419646985462448
Validation loss: 2.54451747834908

Epoch: 6| Step: 2
Training loss: 0.2170978810636792
Validation loss: 2.5524714610277144

Epoch: 6| Step: 3
Training loss: 0.22498640675014467
Validation loss: 2.5567155625213567

Epoch: 6| Step: 4
Training loss: 0.15627382812008742
Validation loss: 2.5792130318220705

Epoch: 6| Step: 5
Training loss: 0.2955863742313458
Validation loss: 2.5802049685694683

Epoch: 6| Step: 6
Training loss: 0.26116269382197016
Validation loss: 2.6022452083430503

Epoch: 6| Step: 7
Training loss: 0.29227900372729676
Validation loss: 2.5957648878117463

Epoch: 6| Step: 8
Training loss: 0.23547739804086962
Validation loss: 2.542050893566276

Epoch: 6| Step: 9
Training loss: 0.1690522500437172
Validation loss: 2.54311974913275

Epoch: 6| Step: 10
Training loss: 0.2508962183495914
Validation loss: 2.5043648434896872

Epoch: 6| Step: 11
Training loss: 0.16555186177295322
Validation loss: 2.486576227086718

Epoch: 6| Step: 12
Training loss: 0.24943763842539435
Validation loss: 2.45027200512803

Epoch: 6| Step: 13
Training loss: 0.20244835981028225
Validation loss: 2.4580745838939237

Epoch: 565| Step: 0
Training loss: 0.22111481273057743
Validation loss: 2.485600488166594

Epoch: 6| Step: 1
Training loss: 0.17675828670206267
Validation loss: 2.4754188935110477

Epoch: 6| Step: 2
Training loss: 0.2093883068923383
Validation loss: 2.460480432471708

Epoch: 6| Step: 3
Training loss: 0.23359355990296862
Validation loss: 2.4970545368022776

Epoch: 6| Step: 4
Training loss: 0.24619860156271803
Validation loss: 2.4914757618163597

Epoch: 6| Step: 5
Training loss: 0.3528078697583281
Validation loss: 2.5455728198174357

Epoch: 6| Step: 6
Training loss: 0.21737960305805135
Validation loss: 2.560359774382443

Epoch: 6| Step: 7
Training loss: 0.3806070910470265
Validation loss: 2.5311728176684145

Epoch: 6| Step: 8
Training loss: 0.2254440637637133
Validation loss: 2.566641857004404

Epoch: 6| Step: 9
Training loss: 0.3137331711484636
Validation loss: 2.553296637322674

Epoch: 6| Step: 10
Training loss: 0.3770801152395831
Validation loss: 2.5582480751857752

Epoch: 6| Step: 11
Training loss: 0.23966084225112655
Validation loss: 2.5113846072698656

Epoch: 6| Step: 12
Training loss: 0.3033401581019167
Validation loss: 2.4807637217638545

Epoch: 6| Step: 13
Training loss: 0.17816562523937454
Validation loss: 2.4333173932379246

Epoch: 566| Step: 0
Training loss: 0.45123465625533976
Validation loss: 2.4397945852270078

Epoch: 6| Step: 1
Training loss: 0.28469594618393707
Validation loss: 2.4566485946615457

Epoch: 6| Step: 2
Training loss: 0.2509027513551585
Validation loss: 2.480542501655245

Epoch: 6| Step: 3
Training loss: 0.19918763160761066
Validation loss: 2.486374802235004

Epoch: 6| Step: 4
Training loss: 0.25910538828012447
Validation loss: 2.5373743616668905

Epoch: 6| Step: 5
Training loss: 0.27567287617470093
Validation loss: 2.5786946383026397

Epoch: 6| Step: 6
Training loss: 0.3156657088814706
Validation loss: 2.6219811344661506

Epoch: 6| Step: 7
Training loss: 0.38951416379054743
Validation loss: 2.6687112040998446

Epoch: 6| Step: 8
Training loss: 0.2976912019889067
Validation loss: 2.6416750982068535

Epoch: 6| Step: 9
Training loss: 0.24330596153965156
Validation loss: 2.599155852951459

Epoch: 6| Step: 10
Training loss: 0.18735230112166826
Validation loss: 2.5635414148302655

Epoch: 6| Step: 11
Training loss: 0.2679156798591258
Validation loss: 2.519259977701564

Epoch: 6| Step: 12
Training loss: 0.2676386242712174
Validation loss: 2.480916609223304

Epoch: 6| Step: 13
Training loss: 0.26451817083049073
Validation loss: 2.486300955496845

Epoch: 567| Step: 0
Training loss: 0.24906490205111415
Validation loss: 2.4736244581711135

Epoch: 6| Step: 1
Training loss: 0.20752371391120294
Validation loss: 2.5134014395907807

Epoch: 6| Step: 2
Training loss: 0.21238403241380924
Validation loss: 2.508846498760996

Epoch: 6| Step: 3
Training loss: 0.2699073710319485
Validation loss: 2.495674521886391

Epoch: 6| Step: 4
Training loss: 0.29062723958782993
Validation loss: 2.500709059872149

Epoch: 6| Step: 5
Training loss: 0.23135880571827191
Validation loss: 2.475322717016153

Epoch: 6| Step: 6
Training loss: 0.22902911114614605
Validation loss: 2.4547496176489547

Epoch: 6| Step: 7
Training loss: 0.2010214066961952
Validation loss: 2.4447740548241805

Epoch: 6| Step: 8
Training loss: 0.2693057983221484
Validation loss: 2.455251026009922

Epoch: 6| Step: 9
Training loss: 0.24061049504344226
Validation loss: 2.473707976354145

Epoch: 6| Step: 10
Training loss: 0.30150346622878504
Validation loss: 2.429972845759918

Epoch: 6| Step: 11
Training loss: 0.4726860415314999
Validation loss: 2.4594778143323026

Epoch: 6| Step: 12
Training loss: 0.2000884538492057
Validation loss: 2.4728178470348214

Epoch: 6| Step: 13
Training loss: 0.20617706497557972
Validation loss: 2.4596419698499723

Epoch: 568| Step: 0
Training loss: 0.26019369434402734
Validation loss: 2.5127236882327875

Epoch: 6| Step: 1
Training loss: 0.4155653545059569
Validation loss: 2.4556485660047866

Epoch: 6| Step: 2
Training loss: 0.28343380707981547
Validation loss: 2.465560526744218

Epoch: 6| Step: 3
Training loss: 0.4217613914954772
Validation loss: 2.469892194770954

Epoch: 6| Step: 4
Training loss: 0.4360495604456543
Validation loss: 2.460971508191556

Epoch: 6| Step: 5
Training loss: 0.47231485316917116
Validation loss: 2.440074400455886

Epoch: 6| Step: 6
Training loss: 0.20714260201720325
Validation loss: 2.433926265068562

Epoch: 6| Step: 7
Training loss: 0.41073409656168824
Validation loss: 2.4887332766791967

Epoch: 6| Step: 8
Training loss: 0.815789605846621
Validation loss: 2.5356032263492305

Epoch: 6| Step: 9
Training loss: 0.27492272418347113
Validation loss: 2.556445330309987

Epoch: 6| Step: 10
Training loss: 0.3599259672600903
Validation loss: 2.5999657048092564

Epoch: 6| Step: 11
Training loss: 0.26425310287169634
Validation loss: 2.598210377680949

Epoch: 6| Step: 12
Training loss: 0.5395294875694232
Validation loss: 2.532488996858429

Epoch: 6| Step: 13
Training loss: 0.29676883455600694
Validation loss: 2.50009396796877

Epoch: 569| Step: 0
Training loss: 0.470916224950258
Validation loss: 2.3890152364643202

Epoch: 6| Step: 1
Training loss: 0.38486483306688063
Validation loss: 2.3375766112283696

Epoch: 6| Step: 2
Training loss: 0.41952243703326725
Validation loss: 2.307717995971298

Epoch: 6| Step: 3
Training loss: 0.47280476341296745
Validation loss: 2.308962151386919

Epoch: 6| Step: 4
Training loss: 0.5232651839661795
Validation loss: 2.265920568980647

Epoch: 6| Step: 5
Training loss: 0.6511530717264229
Validation loss: 2.2861081575426687

Epoch: 6| Step: 6
Training loss: 0.2735682311212676
Validation loss: 2.3660582047813152

Epoch: 6| Step: 7
Training loss: 0.33529577396623933
Validation loss: 2.411741320684152

Epoch: 6| Step: 8
Training loss: 0.32393673040764853
Validation loss: 2.5027149624894816

Epoch: 6| Step: 9
Training loss: 0.6633443202573701
Validation loss: 2.5578641523652306

Epoch: 6| Step: 10
Training loss: 0.37424321104630837
Validation loss: 2.560726647643565

Epoch: 6| Step: 11
Training loss: 0.491932848493869
Validation loss: 2.5544590740796584

Epoch: 6| Step: 12
Training loss: 0.3571456926097028
Validation loss: 2.5001894540680447

Epoch: 6| Step: 13
Training loss: 0.5740509826136077
Validation loss: 2.5301920215334515

Epoch: 570| Step: 0
Training loss: 0.46236183448274776
Validation loss: 2.492841916194795

Epoch: 6| Step: 1
Training loss: 0.508465244682739
Validation loss: 2.433267471994344

Epoch: 6| Step: 2
Training loss: 0.3071094743315566
Validation loss: 2.478011249736689

Epoch: 6| Step: 3
Training loss: 0.32763186364478
Validation loss: 2.4833471930310407

Epoch: 6| Step: 4
Training loss: 0.5592715013111275
Validation loss: 2.4974481294721897

Epoch: 6| Step: 5
Training loss: 0.455315671162241
Validation loss: 2.4647591118404724

Epoch: 6| Step: 6
Training loss: 0.37152211411735475
Validation loss: 2.48366987205818

Epoch: 6| Step: 7
Training loss: 0.3786372380109693
Validation loss: 2.413866760939367

Epoch: 6| Step: 8
Training loss: 0.37912124747768966
Validation loss: 2.3864272107237565

Epoch: 6| Step: 9
Training loss: 0.3056144430330377
Validation loss: 2.36607507059122

Epoch: 6| Step: 10
Training loss: 0.42578595710042344
Validation loss: 2.3949686634634806

Epoch: 6| Step: 11
Training loss: 0.40424414765410027
Validation loss: 2.418345046399594

Epoch: 6| Step: 12
Training loss: 0.38496223499809085
Validation loss: 2.4883745365019965

Epoch: 6| Step: 13
Training loss: 0.5620488635928323
Validation loss: 2.5372015967493033

Epoch: 571| Step: 0
Training loss: 0.2811281019534114
Validation loss: 2.520431151546128

Epoch: 6| Step: 1
Training loss: 0.35368416915028894
Validation loss: 2.543483452630007

Epoch: 6| Step: 2
Training loss: 0.36077758499735674
Validation loss: 2.545081554447651

Epoch: 6| Step: 3
Training loss: 0.3274533800620238
Validation loss: 2.5054392730043964

Epoch: 6| Step: 4
Training loss: 0.3442772592973056
Validation loss: 2.506663204288688

Epoch: 6| Step: 5
Training loss: 0.4980672345955418
Validation loss: 2.4621219746288516

Epoch: 6| Step: 6
Training loss: 0.3128435035112443
Validation loss: 2.480159397034133

Epoch: 6| Step: 7
Training loss: 0.49486208632102424
Validation loss: 2.4555562391187222

Epoch: 6| Step: 8
Training loss: 0.39202270313006304
Validation loss: 2.4716212381847495

Epoch: 6| Step: 9
Training loss: 0.34879245896105693
Validation loss: 2.47007920980517

Epoch: 6| Step: 10
Training loss: 0.4921943875996487
Validation loss: 2.442771646499615

Epoch: 6| Step: 11
Training loss: 0.41262436278096676
Validation loss: 2.446694493176458

Epoch: 6| Step: 12
Training loss: 0.47963738816532314
Validation loss: 2.373109884677631

Epoch: 6| Step: 13
Training loss: 0.32932365688683407
Validation loss: 2.3280933755402033

Epoch: 572| Step: 0
Training loss: 0.37852248194480353
Validation loss: 2.350784301090598

Epoch: 6| Step: 1
Training loss: 0.40706911405147717
Validation loss: 2.3526577184094193

Epoch: 6| Step: 2
Training loss: 0.4018726553781794
Validation loss: 2.387946132250567

Epoch: 6| Step: 3
Training loss: 0.5559826894387825
Validation loss: 2.434225292747706

Epoch: 6| Step: 4
Training loss: 0.3731231212089432
Validation loss: 2.4382774999854075

Epoch: 6| Step: 5
Training loss: 0.2932216061734839
Validation loss: 2.4339336212647615

Epoch: 6| Step: 6
Training loss: 0.38363663847351337
Validation loss: 2.46979135108735

Epoch: 6| Step: 7
Training loss: 0.3568198757388203
Validation loss: 2.444421086692273

Epoch: 6| Step: 8
Training loss: 0.35429816282599763
Validation loss: 2.501086679774753

Epoch: 6| Step: 9
Training loss: 0.3873254467454812
Validation loss: 2.463178777062087

Epoch: 6| Step: 10
Training loss: 0.21323592504336428
Validation loss: 2.4906392346199486

Epoch: 6| Step: 11
Training loss: 0.39715245528227583
Validation loss: 2.4785248885779225

Epoch: 6| Step: 12
Training loss: 0.3156227725488605
Validation loss: 2.482434881010747

Epoch: 6| Step: 13
Training loss: 0.3612019086459944
Validation loss: 2.414592423116182

Epoch: 573| Step: 0
Training loss: 0.26570612005325206
Validation loss: 2.453493438489309

Epoch: 6| Step: 1
Training loss: 0.22625553777672225
Validation loss: 2.390565081505054

Epoch: 6| Step: 2
Training loss: 0.2655468433062497
Validation loss: 2.3895951273278313

Epoch: 6| Step: 3
Training loss: 0.3260449602287755
Validation loss: 2.3643651226173152

Epoch: 6| Step: 4
Training loss: 0.24040080717464218
Validation loss: 2.3688646936016307

Epoch: 6| Step: 5
Training loss: 0.32315006845064187
Validation loss: 2.3207832229906367

Epoch: 6| Step: 6
Training loss: 0.268099187017451
Validation loss: 2.3683084997106967

Epoch: 6| Step: 7
Training loss: 0.2879327140279526
Validation loss: 2.326606662258683

Epoch: 6| Step: 8
Training loss: 0.3886005968841233
Validation loss: 2.322192038542239

Epoch: 6| Step: 9
Training loss: 0.26801840208166355
Validation loss: 2.337779481473167

Epoch: 6| Step: 10
Training loss: 0.34158302156482684
Validation loss: 2.3243403671018292

Epoch: 6| Step: 11
Training loss: 0.3264014983390563
Validation loss: 2.3024576914979313

Epoch: 6| Step: 12
Training loss: 0.31506273165366827
Validation loss: 2.351734092294482

Epoch: 6| Step: 13
Training loss: 0.3152066673571794
Validation loss: 2.299812583612816

Epoch: 574| Step: 0
Training loss: 0.27223120681188184
Validation loss: 2.348732205479568

Epoch: 6| Step: 1
Training loss: 0.210402472453199
Validation loss: 2.356442702561523

Epoch: 6| Step: 2
Training loss: 0.14963354557893263
Validation loss: 2.3688393607824816

Epoch: 6| Step: 3
Training loss: 0.3056401861938553
Validation loss: 2.4223045410145114

Epoch: 6| Step: 4
Training loss: 0.15880289123115288
Validation loss: 2.431995195036067

Epoch: 6| Step: 5
Training loss: 0.2907996176074372
Validation loss: 2.4442962460638

Epoch: 6| Step: 6
Training loss: 0.22775270803738437
Validation loss: 2.46376481942842

Epoch: 6| Step: 7
Training loss: 0.30342930434028537
Validation loss: 2.4576388026790883

Epoch: 6| Step: 8
Training loss: 0.23038366331161783
Validation loss: 2.4382404772923807

Epoch: 6| Step: 9
Training loss: 0.21530723861555512
Validation loss: 2.4220731432544174

Epoch: 6| Step: 10
Training loss: 0.27434430304755175
Validation loss: 2.381389610662107

Epoch: 6| Step: 11
Training loss: 0.3505496906892628
Validation loss: 2.379448294061922

Epoch: 6| Step: 12
Training loss: 0.30835566208940307
Validation loss: 2.3825966820499067

Epoch: 6| Step: 13
Training loss: 0.3384532874238921
Validation loss: 2.3690566679125045

Epoch: 575| Step: 0
Training loss: 0.20195683783949522
Validation loss: 2.369959320625106

Epoch: 6| Step: 1
Training loss: 0.20708787791416308
Validation loss: 2.368563404028874

Epoch: 6| Step: 2
Training loss: 0.18750729149310186
Validation loss: 2.4180967161326303

Epoch: 6| Step: 3
Training loss: 0.25751090471084553
Validation loss: 2.4100971989515907

Epoch: 6| Step: 4
Training loss: 0.2135782249294725
Validation loss: 2.4087453410613278

Epoch: 6| Step: 5
Training loss: 0.1419563518466029
Validation loss: 2.4906213039698555

Epoch: 6| Step: 6
Training loss: 0.272579932804077
Validation loss: 2.446257800269533

Epoch: 6| Step: 7
Training loss: 0.29459442503351946
Validation loss: 2.528608629548986

Epoch: 6| Step: 8
Training loss: 0.2222381983832246
Validation loss: 2.4536965653160507

Epoch: 6| Step: 9
Training loss: 0.2349924220222813
Validation loss: 2.4783598673776317

Epoch: 6| Step: 10
Training loss: 0.1968931042203529
Validation loss: 2.4732455175616286

Epoch: 6| Step: 11
Training loss: 0.20266016629154823
Validation loss: 2.4667065404417383

Epoch: 6| Step: 12
Training loss: 0.13238656239898383
Validation loss: 2.4520435979040824

Epoch: 6| Step: 13
Training loss: 0.2801882916885413
Validation loss: 2.4687318148293027

Epoch: 576| Step: 0
Training loss: 0.15143594103281133
Validation loss: 2.452864523940265

Epoch: 6| Step: 1
Training loss: 0.2871703906976448
Validation loss: 2.473695895529672

Epoch: 6| Step: 2
Training loss: 0.2167986019168842
Validation loss: 2.491396124848821

Epoch: 6| Step: 3
Training loss: 0.1996529652875674
Validation loss: 2.5005469298195635

Epoch: 6| Step: 4
Training loss: 0.290115834360497
Validation loss: 2.4702956741475117

Epoch: 6| Step: 5
Training loss: 0.2888795428312958
Validation loss: 2.484977563962377

Epoch: 6| Step: 6
Training loss: 0.22557488946984894
Validation loss: 2.474482234971468

Epoch: 6| Step: 7
Training loss: 0.17992967374184682
Validation loss: 2.4904708275843386

Epoch: 6| Step: 8
Training loss: 0.2573610746276476
Validation loss: 2.4860874892798934

Epoch: 6| Step: 9
Training loss: 0.21528580011439677
Validation loss: 2.464024155685335

Epoch: 6| Step: 10
Training loss: 0.21464407919016054
Validation loss: 2.44859496497791

Epoch: 6| Step: 11
Training loss: 0.146524843348016
Validation loss: 2.4172324479056195

Epoch: 6| Step: 12
Training loss: 0.1945307823543213
Validation loss: 2.4450342834606995

Epoch: 6| Step: 13
Training loss: 0.1557085729833553
Validation loss: 2.4225414109501124

Epoch: 577| Step: 0
Training loss: 0.11915382327783318
Validation loss: 2.4709529847807223

Epoch: 6| Step: 1
Training loss: 0.16238329621427175
Validation loss: 2.4539795335505783

Epoch: 6| Step: 2
Training loss: 0.21923344698123567
Validation loss: 2.46585796907795

Epoch: 6| Step: 3
Training loss: 0.2803804678364633
Validation loss: 2.4852091577545674

Epoch: 6| Step: 4
Training loss: 0.21470441634984458
Validation loss: 2.5022366278514285

Epoch: 6| Step: 5
Training loss: 0.20922789245299006
Validation loss: 2.4942935204183283

Epoch: 6| Step: 6
Training loss: 0.16349409617802205
Validation loss: 2.5120874294221167

Epoch: 6| Step: 7
Training loss: 0.2643696065672707
Validation loss: 2.521849971769591

Epoch: 6| Step: 8
Training loss: 0.19366802280991333
Validation loss: 2.541855124418334

Epoch: 6| Step: 9
Training loss: 0.22439593249360024
Validation loss: 2.5478601030859447

Epoch: 6| Step: 10
Training loss: 0.27337268333604664
Validation loss: 2.5485667846758555

Epoch: 6| Step: 11
Training loss: 0.09327226848749988
Validation loss: 2.5099897021984594

Epoch: 6| Step: 12
Training loss: 0.14524173731249618
Validation loss: 2.463918547861771

Epoch: 6| Step: 13
Training loss: 0.2148129180979607
Validation loss: 2.476815245442428

Epoch: 578| Step: 0
Training loss: 0.2904738176549121
Validation loss: 2.457238743241033

Epoch: 6| Step: 1
Training loss: 0.18185346705330938
Validation loss: 2.4781995058572015

Epoch: 6| Step: 2
Training loss: 0.30930887729437195
Validation loss: 2.4729403179185057

Epoch: 6| Step: 3
Training loss: 0.32726107124517084
Validation loss: 2.4510274572202735

Epoch: 6| Step: 4
Training loss: 0.17559942272199738
Validation loss: 2.466429940468385

Epoch: 6| Step: 5
Training loss: 0.17118368593815875
Validation loss: 2.4793562240566085

Epoch: 6| Step: 6
Training loss: 0.18534050557768916
Validation loss: 2.457906267401947

Epoch: 6| Step: 7
Training loss: 0.20680360154070018
Validation loss: 2.5152075636521327

Epoch: 6| Step: 8
Training loss: 0.21123757035181856
Validation loss: 2.5474869142533767

Epoch: 6| Step: 9
Training loss: 0.10933813257116191
Validation loss: 2.475681875952786

Epoch: 6| Step: 10
Training loss: 0.22621321061602348
Validation loss: 2.4947390560528904

Epoch: 6| Step: 11
Training loss: 0.30759205791221517
Validation loss: 2.4821346451744137

Epoch: 6| Step: 12
Training loss: 0.1997641968927817
Validation loss: 2.499620564697191

Epoch: 6| Step: 13
Training loss: 0.277216358209328
Validation loss: 2.437922793127989

Epoch: 579| Step: 0
Training loss: 0.13860821941927368
Validation loss: 2.454612647147464

Epoch: 6| Step: 1
Training loss: 0.21423520687894113
Validation loss: 2.4799486951751004

Epoch: 6| Step: 2
Training loss: 0.19940845956132672
Validation loss: 2.4678675947769984

Epoch: 6| Step: 3
Training loss: 0.2252004558310037
Validation loss: 2.4752473815891327

Epoch: 6| Step: 4
Training loss: 0.18384677617255413
Validation loss: 2.450050220849558

Epoch: 6| Step: 5
Training loss: 0.14465935931899015
Validation loss: 2.4331395862120924

Epoch: 6| Step: 6
Training loss: 0.235958709142463
Validation loss: 2.420925531697892

Epoch: 6| Step: 7
Training loss: 0.22549890102459128
Validation loss: 2.45138511408371

Epoch: 6| Step: 8
Training loss: 0.1738870392305501
Validation loss: 2.4417284969830977

Epoch: 6| Step: 9
Training loss: 0.2607854742915982
Validation loss: 2.3947097446010845

Epoch: 6| Step: 10
Training loss: 0.21869427959043
Validation loss: 2.442837268569692

Epoch: 6| Step: 11
Training loss: 0.2400637695410027
Validation loss: 2.410253300549922

Epoch: 6| Step: 12
Training loss: 0.20722724526137357
Validation loss: 2.452533302301377

Epoch: 6| Step: 13
Training loss: 0.1769916399878034
Validation loss: 2.5037973067410277

Epoch: 580| Step: 0
Training loss: 0.22617869918621547
Validation loss: 2.5048382241618037

Epoch: 6| Step: 1
Training loss: 0.25581375472476153
Validation loss: 2.5055128779734956

Epoch: 6| Step: 2
Training loss: 0.21802126890947915
Validation loss: 2.51725567812009

Epoch: 6| Step: 3
Training loss: 0.1795225422858162
Validation loss: 2.5062928472774053

Epoch: 6| Step: 4
Training loss: 0.18179214474663774
Validation loss: 2.4769082428936673

Epoch: 6| Step: 5
Training loss: 0.13546473463062822
Validation loss: 2.5598426043605924

Epoch: 6| Step: 6
Training loss: 0.1934091234269526
Validation loss: 2.5220758173979205

Epoch: 6| Step: 7
Training loss: 0.17718542652834365
Validation loss: 2.513644618591508

Epoch: 6| Step: 8
Training loss: 0.20130266178799747
Validation loss: 2.5005329169098403

Epoch: 6| Step: 9
Training loss: 0.17548382285880978
Validation loss: 2.502283730874567

Epoch: 6| Step: 10
Training loss: 0.19666628862973695
Validation loss: 2.516393362376631

Epoch: 6| Step: 11
Training loss: 0.17777465531550865
Validation loss: 2.467347588013095

Epoch: 6| Step: 12
Training loss: 0.16727427031309844
Validation loss: 2.494953018167988

Epoch: 6| Step: 13
Training loss: 0.19313201638472713
Validation loss: 2.4641049789972596

Epoch: 581| Step: 0
Training loss: 0.19708421126957118
Validation loss: 2.4556588663823047

Epoch: 6| Step: 1
Training loss: 0.18855939043279815
Validation loss: 2.4584922683532415

Epoch: 6| Step: 2
Training loss: 0.23250015126756648
Validation loss: 2.4886284094034012

Epoch: 6| Step: 3
Training loss: 0.16383978508861669
Validation loss: 2.492503971067027

Epoch: 6| Step: 4
Training loss: 0.1410195722582274
Validation loss: 2.4886501082197943

Epoch: 6| Step: 5
Training loss: 0.07969596726648076
Validation loss: 2.4752210790538163

Epoch: 6| Step: 6
Training loss: 0.1478917857072666
Validation loss: 2.514316645348626

Epoch: 6| Step: 7
Training loss: 0.21326399792772932
Validation loss: 2.5394105340478665

Epoch: 6| Step: 8
Training loss: 0.1505380007469669
Validation loss: 2.5512064324840718

Epoch: 6| Step: 9
Training loss: 0.2061673800841066
Validation loss: 2.563661557664962

Epoch: 6| Step: 10
Training loss: 0.23225253211007457
Validation loss: 2.5666809509395523

Epoch: 6| Step: 11
Training loss: 0.22387039690807325
Validation loss: 2.5216624541311483

Epoch: 6| Step: 12
Training loss: 0.211795650747399
Validation loss: 2.503197129999189

Epoch: 6| Step: 13
Training loss: 0.21552730537832496
Validation loss: 2.4697826339574425

Epoch: 582| Step: 0
Training loss: 0.17949313556806795
Validation loss: 2.4370498404568606

Epoch: 6| Step: 1
Training loss: 0.1900127835741594
Validation loss: 2.473616338039021

Epoch: 6| Step: 2
Training loss: 0.17912546661832612
Validation loss: 2.454349680043714

Epoch: 6| Step: 3
Training loss: 0.11113329620792398
Validation loss: 2.4300358152026846

Epoch: 6| Step: 4
Training loss: 0.166209786138794
Validation loss: 2.4404439467742995

Epoch: 6| Step: 5
Training loss: 0.1441965997244432
Validation loss: 2.426579878744393

Epoch: 6| Step: 6
Training loss: 0.2128463226558296
Validation loss: 2.439615137044885

Epoch: 6| Step: 7
Training loss: 0.20036241953783504
Validation loss: 2.4395837094261723

Epoch: 6| Step: 8
Training loss: 0.2912648816870457
Validation loss: 2.460008837491597

Epoch: 6| Step: 9
Training loss: 0.26664305982307934
Validation loss: 2.459220664215259

Epoch: 6| Step: 10
Training loss: 0.17623687082284265
Validation loss: 2.514773167098261

Epoch: 6| Step: 11
Training loss: 0.25848338950153255
Validation loss: 2.5144400812620216

Epoch: 6| Step: 12
Training loss: 0.15698293208251435
Validation loss: 2.5496548987151857

Epoch: 6| Step: 13
Training loss: 0.13954208565829707
Validation loss: 2.576187534407986

Epoch: 583| Step: 0
Training loss: 0.24494937456397253
Validation loss: 2.576605966382033

Epoch: 6| Step: 1
Training loss: 0.13637704381451457
Validation loss: 2.5339736636281995

Epoch: 6| Step: 2
Training loss: 0.1917292633065378
Validation loss: 2.5086328662721846

Epoch: 6| Step: 3
Training loss: 0.20058576143697202
Validation loss: 2.4985529444318297

Epoch: 6| Step: 4
Training loss: 0.18744799767022813
Validation loss: 2.478626138178935

Epoch: 6| Step: 5
Training loss: 0.1913263387662873
Validation loss: 2.4502077299631346

Epoch: 6| Step: 6
Training loss: 0.17062148950794154
Validation loss: 2.4398072342533474

Epoch: 6| Step: 7
Training loss: 0.1911327490542377
Validation loss: 2.4110854048382713

Epoch: 6| Step: 8
Training loss: 0.08801486453109243
Validation loss: 2.4349288610921085

Epoch: 6| Step: 9
Training loss: 0.21849530583474278
Validation loss: 2.4178275614584166

Epoch: 6| Step: 10
Training loss: 0.23495128830576612
Validation loss: 2.4328780283775946

Epoch: 6| Step: 11
Training loss: 0.12272686823659244
Validation loss: 2.439312141101692

Epoch: 6| Step: 12
Training loss: 0.2255662934308534
Validation loss: 2.4491755447754615

Epoch: 6| Step: 13
Training loss: 0.19521222401435973
Validation loss: 2.4882710851803393

Epoch: 584| Step: 0
Training loss: 0.19795896471343472
Validation loss: 2.4863578672745237

Epoch: 6| Step: 1
Training loss: 0.1603092881302944
Validation loss: 2.5172281061004353

Epoch: 6| Step: 2
Training loss: 0.2387864900584905
Validation loss: 2.5248177790268245

Epoch: 6| Step: 3
Training loss: 0.1553600357695363
Validation loss: 2.522596402898378

Epoch: 6| Step: 4
Training loss: 0.20863915388608115
Validation loss: 2.5173505193656998

Epoch: 6| Step: 5
Training loss: 0.2068919486913952
Validation loss: 2.5045169683656314

Epoch: 6| Step: 6
Training loss: 0.15610827933003227
Validation loss: 2.48513895915232

Epoch: 6| Step: 7
Training loss: 0.18285788518824678
Validation loss: 2.4707972982541895

Epoch: 6| Step: 8
Training loss: 0.15820538554519226
Validation loss: 2.428585506752402

Epoch: 6| Step: 9
Training loss: 0.1366683322041291
Validation loss: 2.431337331706001

Epoch: 6| Step: 10
Training loss: 0.18323404502627502
Validation loss: 2.4376278647306777

Epoch: 6| Step: 11
Training loss: 0.11139833177405943
Validation loss: 2.4523774494533095

Epoch: 6| Step: 12
Training loss: 0.19497714816589107
Validation loss: 2.475473373742889

Epoch: 6| Step: 13
Training loss: 0.22446768064534947
Validation loss: 2.443674977035335

Epoch: 585| Step: 0
Training loss: 0.10514307957058905
Validation loss: 2.455021190878078

Epoch: 6| Step: 1
Training loss: 0.21539483916844063
Validation loss: 2.464048622277409

Epoch: 6| Step: 2
Training loss: 0.11576051535382345
Validation loss: 2.4681089479395277

Epoch: 6| Step: 3
Training loss: 0.10416837680922833
Validation loss: 2.4953600083491083

Epoch: 6| Step: 4
Training loss: 0.21970364769022308
Validation loss: 2.488846800225351

Epoch: 6| Step: 5
Training loss: 0.11294426617095166
Validation loss: 2.4878194784260925

Epoch: 6| Step: 6
Training loss: 0.09917818971293986
Validation loss: 2.495763179813358

Epoch: 6| Step: 7
Training loss: 0.1302538712662069
Validation loss: 2.532933391324624

Epoch: 6| Step: 8
Training loss: 0.19742358842112986
Validation loss: 2.4603940036421754

Epoch: 6| Step: 9
Training loss: 0.10140969169930249
Validation loss: 2.473726379884997

Epoch: 6| Step: 10
Training loss: 0.195464990215292
Validation loss: 2.4990421203374753

Epoch: 6| Step: 11
Training loss: 0.18373967519609657
Validation loss: 2.472532666505461

Epoch: 6| Step: 12
Training loss: 0.10848978850054863
Validation loss: 2.489074303505217

Epoch: 6| Step: 13
Training loss: 0.1501505595328741
Validation loss: 2.4788502958111067

Epoch: 586| Step: 0
Training loss: 0.11898279288574469
Validation loss: 2.4411227636992843

Epoch: 6| Step: 1
Training loss: 0.1739718721502592
Validation loss: 2.4506328007469707

Epoch: 6| Step: 2
Training loss: 0.16909425157025998
Validation loss: 2.4380007519491382

Epoch: 6| Step: 3
Training loss: 0.14267956378160443
Validation loss: 2.410659869052385

Epoch: 6| Step: 4
Training loss: 0.18902232160906962
Validation loss: 2.426553805657865

Epoch: 6| Step: 5
Training loss: 0.14477084250808528
Validation loss: 2.4341389914632328

Epoch: 6| Step: 6
Training loss: 0.15755980580427484
Validation loss: 2.409822044429992

Epoch: 6| Step: 7
Training loss: 0.18790287207899978
Validation loss: 2.4133281504780992

Epoch: 6| Step: 8
Training loss: 0.16321268124904476
Validation loss: 2.403827355922657

Epoch: 6| Step: 9
Training loss: 0.1519907260060786
Validation loss: 2.4105624349939947

Epoch: 6| Step: 10
Training loss: 0.19546552385554058
Validation loss: 2.4044907372280435

Epoch: 6| Step: 11
Training loss: 0.14279072731209255
Validation loss: 2.460666884469187

Epoch: 6| Step: 12
Training loss: 0.1873892616051249
Validation loss: 2.4751769636406853

Epoch: 6| Step: 13
Training loss: 0.10704186588740021
Validation loss: 2.445112840692659

Epoch: 587| Step: 0
Training loss: 0.15134806973721698
Validation loss: 2.440523634981751

Epoch: 6| Step: 1
Training loss: 0.17554143865814842
Validation loss: 2.457389187914779

Epoch: 6| Step: 2
Training loss: 0.130928384320181
Validation loss: 2.444920602512494

Epoch: 6| Step: 3
Training loss: 0.17528369209586475
Validation loss: 2.4490057336831437

Epoch: 6| Step: 4
Training loss: 0.18204437012111854
Validation loss: 2.457293100729653

Epoch: 6| Step: 5
Training loss: 0.10805417285140483
Validation loss: 2.4842264052680667

Epoch: 6| Step: 6
Training loss: 0.20852886005017038
Validation loss: 2.4457245506125656

Epoch: 6| Step: 7
Training loss: 0.19055197286257683
Validation loss: 2.4944002862370125

Epoch: 6| Step: 8
Training loss: 0.11853875896908019
Validation loss: 2.4896862671048767

Epoch: 6| Step: 9
Training loss: 0.11473710045167797
Validation loss: 2.4744191497135564

Epoch: 6| Step: 10
Training loss: 0.1556051118716618
Validation loss: 2.482620207711518

Epoch: 6| Step: 11
Training loss: 0.18014356537072826
Validation loss: 2.475181886509637

Epoch: 6| Step: 12
Training loss: 0.20105333446746315
Validation loss: 2.502564240096872

Epoch: 6| Step: 13
Training loss: 0.1537608057291583
Validation loss: 2.473589930584047

Epoch: 588| Step: 0
Training loss: 0.2025835817825361
Validation loss: 2.43383761504686

Epoch: 6| Step: 1
Training loss: 0.19052466933711398
Validation loss: 2.4624871441180884

Epoch: 6| Step: 2
Training loss: 0.2448065259495265
Validation loss: 2.449098440975323

Epoch: 6| Step: 3
Training loss: 0.17316455305749828
Validation loss: 2.410551956275121

Epoch: 6| Step: 4
Training loss: 0.12377271691162953
Validation loss: 2.428800889269181

Epoch: 6| Step: 5
Training loss: 0.21644117197517931
Validation loss: 2.4357735862310173

Epoch: 6| Step: 6
Training loss: 0.19645665733543474
Validation loss: 2.461604144043969

Epoch: 6| Step: 7
Training loss: 0.20966017717045746
Validation loss: 2.443610362585485

Epoch: 6| Step: 8
Training loss: 0.23544914153836288
Validation loss: 2.4589206330511186

Epoch: 6| Step: 9
Training loss: 0.13165186995294914
Validation loss: 2.4736230434978164

Epoch: 6| Step: 10
Training loss: 0.13545625059196187
Validation loss: 2.4577121916268725

Epoch: 6| Step: 11
Training loss: 0.20002372645666516
Validation loss: 2.451092317521691

Epoch: 6| Step: 12
Training loss: 0.13841578517788541
Validation loss: 2.459548021964623

Epoch: 6| Step: 13
Training loss: 0.14120516705891092
Validation loss: 2.450454038496229

Epoch: 589| Step: 0
Training loss: 0.11318977543140879
Validation loss: 2.455490023582835

Epoch: 6| Step: 1
Training loss: 0.1266209732189249
Validation loss: 2.4550072058032733

Epoch: 6| Step: 2
Training loss: 0.17458922677422378
Validation loss: 2.465654992070979

Epoch: 6| Step: 3
Training loss: 0.16393120371180034
Validation loss: 2.4776551776756683

Epoch: 6| Step: 4
Training loss: 0.14306462257497188
Validation loss: 2.4661411765664107

Epoch: 6| Step: 5
Training loss: 0.1528998398184639
Validation loss: 2.4658375085900976

Epoch: 6| Step: 6
Training loss: 0.13085262793612193
Validation loss: 2.4559525720824786

Epoch: 6| Step: 7
Training loss: 0.21103857409221918
Validation loss: 2.447439905830342

Epoch: 6| Step: 8
Training loss: 0.07457626342008536
Validation loss: 2.4501902546780543

Epoch: 6| Step: 9
Training loss: 0.11298663781898835
Validation loss: 2.404359289638561

Epoch: 6| Step: 10
Training loss: 0.21008528642233287
Validation loss: 2.4226747185495197

Epoch: 6| Step: 11
Training loss: 0.13167188822174822
Validation loss: 2.4060546184132656

Epoch: 6| Step: 12
Training loss: 0.19771397505375943
Validation loss: 2.430058682327027

Epoch: 6| Step: 13
Training loss: 0.23577878489384346
Validation loss: 2.4198665678622615

Epoch: 590| Step: 0
Training loss: 0.16191698630791077
Validation loss: 2.388905406944718

Epoch: 6| Step: 1
Training loss: 0.17001666242445818
Validation loss: 2.4323845607772028

Epoch: 6| Step: 2
Training loss: 0.10998166805284781
Validation loss: 2.4312311834534097

Epoch: 6| Step: 3
Training loss: 0.12492828248931044
Validation loss: 2.4523571979486793

Epoch: 6| Step: 4
Training loss: 0.08202231165462705
Validation loss: 2.4590087045989732

Epoch: 6| Step: 5
Training loss: 0.1767816369455549
Validation loss: 2.467604860011684

Epoch: 6| Step: 6
Training loss: 0.14882731700287402
Validation loss: 2.4773240915446606

Epoch: 6| Step: 7
Training loss: 0.13099995932869607
Validation loss: 2.458440419223803

Epoch: 6| Step: 8
Training loss: 0.11494399515897132
Validation loss: 2.4975673745751306

Epoch: 6| Step: 9
Training loss: 0.1363012956927637
Validation loss: 2.5076119283254346

Epoch: 6| Step: 10
Training loss: 0.2088962440405524
Validation loss: 2.4985329989632596

Epoch: 6| Step: 11
Training loss: 0.20240183626174066
Validation loss: 2.4887822007307787

Epoch: 6| Step: 12
Training loss: 0.16715271801871098
Validation loss: 2.4810842641615207

Epoch: 6| Step: 13
Training loss: 0.13088881460374294
Validation loss: 2.4676545582612337

Epoch: 591| Step: 0
Training loss: 0.10922942521420402
Validation loss: 2.4558214080628016

Epoch: 6| Step: 1
Training loss: 0.14296042126227212
Validation loss: 2.4440635425247845

Epoch: 6| Step: 2
Training loss: 0.14438722496789208
Validation loss: 2.457752254701523

Epoch: 6| Step: 3
Training loss: 0.14666770271478102
Validation loss: 2.449855192047415

Epoch: 6| Step: 4
Training loss: 0.17398996534303504
Validation loss: 2.448379007601164

Epoch: 6| Step: 5
Training loss: 0.17869233206532997
Validation loss: 2.4724102277921762

Epoch: 6| Step: 6
Training loss: 0.20453229654742336
Validation loss: 2.4866869975118338

Epoch: 6| Step: 7
Training loss: 0.08187809338622719
Validation loss: 2.468765900491746

Epoch: 6| Step: 8
Training loss: 0.10012820173203284
Validation loss: 2.505421214976222

Epoch: 6| Step: 9
Training loss: 0.19195600306426389
Validation loss: 2.4738783949850913

Epoch: 6| Step: 10
Training loss: 0.13926941447461338
Validation loss: 2.455820696642443

Epoch: 6| Step: 11
Training loss: 0.13131475213728172
Validation loss: 2.4786299940427576

Epoch: 6| Step: 12
Training loss: 0.15346090588867659
Validation loss: 2.496759740019945

Epoch: 6| Step: 13
Training loss: 0.1042297802897262
Validation loss: 2.4985854412810022

Epoch: 592| Step: 0
Training loss: 0.08633082502121461
Validation loss: 2.474835714425406

Epoch: 6| Step: 1
Training loss: 0.18122231091090715
Validation loss: 2.4786242847143622

Epoch: 6| Step: 2
Training loss: 0.1128690388775141
Validation loss: 2.4416506797583257

Epoch: 6| Step: 3
Training loss: 0.20808027912493512
Validation loss: 2.411743991959588

Epoch: 6| Step: 4
Training loss: 0.15369330429861683
Validation loss: 2.442809148339546

Epoch: 6| Step: 5
Training loss: 0.19066649165185764
Validation loss: 2.4237124265786787

Epoch: 6| Step: 6
Training loss: 0.11214666859458454
Validation loss: 2.4524387454970955

Epoch: 6| Step: 7
Training loss: 0.16253902764424283
Validation loss: 2.4624895656638013

Epoch: 6| Step: 8
Training loss: 0.12534325379259395
Validation loss: 2.4616139492876634

Epoch: 6| Step: 9
Training loss: 0.12249074630916208
Validation loss: 2.4697976506944674

Epoch: 6| Step: 10
Training loss: 0.1339862789986344
Validation loss: 2.501666508273363

Epoch: 6| Step: 11
Training loss: 0.11374992398112764
Validation loss: 2.4715089284764917

Epoch: 6| Step: 12
Training loss: 0.14127916268154908
Validation loss: 2.494663171933464

Epoch: 6| Step: 13
Training loss: 0.20468969343917526
Validation loss: 2.4958722824498425

Epoch: 593| Step: 0
Training loss: 0.11831087654751114
Validation loss: 2.532785848817287

Epoch: 6| Step: 1
Training loss: 0.13834437125785795
Validation loss: 2.521414550867797

Epoch: 6| Step: 2
Training loss: 0.09447890282516623
Validation loss: 2.4738563645251257

Epoch: 6| Step: 3
Training loss: 0.17726745686902196
Validation loss: 2.474190673971383

Epoch: 6| Step: 4
Training loss: 0.11386074453613591
Validation loss: 2.498914907681751

Epoch: 6| Step: 5
Training loss: 0.09934885888284262
Validation loss: 2.464835494852063

Epoch: 6| Step: 6
Training loss: 0.12541525382004423
Validation loss: 2.49085765807053

Epoch: 6| Step: 7
Training loss: 0.1785041780370185
Validation loss: 2.487523416116361

Epoch: 6| Step: 8
Training loss: 0.15680668131636594
Validation loss: 2.4713609439615114

Epoch: 6| Step: 9
Training loss: 0.14383371962856048
Validation loss: 2.4492199202301177

Epoch: 6| Step: 10
Training loss: 0.12973085276313204
Validation loss: 2.457178029652261

Epoch: 6| Step: 11
Training loss: 0.09245194898685515
Validation loss: 2.458667121016417

Epoch: 6| Step: 12
Training loss: 0.13700076716749465
Validation loss: 2.413232039453382

Epoch: 6| Step: 13
Training loss: 0.06279587746345411
Validation loss: 2.4522046160791864

Epoch: 594| Step: 0
Training loss: 0.15443994432087343
Validation loss: 2.458148154335028

Epoch: 6| Step: 1
Training loss: 0.112115144415015
Validation loss: 2.40140386911201

Epoch: 6| Step: 2
Training loss: 0.10121568280001406
Validation loss: 2.435688474698834

Epoch: 6| Step: 3
Training loss: 0.09700290519318563
Validation loss: 2.49176236345211

Epoch: 6| Step: 4
Training loss: 0.16823792513515803
Validation loss: 2.4298850400830685

Epoch: 6| Step: 5
Training loss: 0.09457674665595246
Validation loss: 2.4602099167188376

Epoch: 6| Step: 6
Training loss: 0.12520406130068454
Validation loss: 2.3949562207803625

Epoch: 6| Step: 7
Training loss: 0.14044654967788106
Validation loss: 2.4323022966064114

Epoch: 6| Step: 8
Training loss: 0.07941519115357112
Validation loss: 2.467115029834355

Epoch: 6| Step: 9
Training loss: 0.1265089849077193
Validation loss: 2.427851448756937

Epoch: 6| Step: 10
Training loss: 0.1947297175389993
Validation loss: 2.4141761484091986

Epoch: 6| Step: 11
Training loss: 0.15918184056610407
Validation loss: 2.423316896827203

Epoch: 6| Step: 12
Training loss: 0.1194568876443559
Validation loss: 2.4250788122846347

Epoch: 6| Step: 13
Training loss: 0.10361903351717872
Validation loss: 2.4420122557278257

Epoch: 595| Step: 0
Training loss: 0.10842455300205331
Validation loss: 2.4395721763017413

Epoch: 6| Step: 1
Training loss: 0.11214464642937592
Validation loss: 2.4552232171109583

Epoch: 6| Step: 2
Training loss: 0.10799422808131308
Validation loss: 2.4646674351637565

Epoch: 6| Step: 3
Training loss: 0.12975550270447841
Validation loss: 2.437077772047244

Epoch: 6| Step: 4
Training loss: 0.14791352247424577
Validation loss: 2.4389339569680755

Epoch: 6| Step: 5
Training loss: 0.1017116771530166
Validation loss: 2.433283321992157

Epoch: 6| Step: 6
Training loss: 0.06717404907339294
Validation loss: 2.4462241020908664

Epoch: 6| Step: 7
Training loss: 0.06612688090924966
Validation loss: 2.4465626751148624

Epoch: 6| Step: 8
Training loss: 0.20937807664461153
Validation loss: 2.4510661443395056

Epoch: 6| Step: 9
Training loss: 0.1839640312529232
Validation loss: 2.453513815927972

Epoch: 6| Step: 10
Training loss: 0.1496096558730076
Validation loss: 2.48897404027737

Epoch: 6| Step: 11
Training loss: 0.0663488434445878
Validation loss: 2.4481321939450247

Epoch: 6| Step: 12
Training loss: 0.12110047936968737
Validation loss: 2.4329290366278538

Epoch: 6| Step: 13
Training loss: 0.08646081763838548
Validation loss: 2.4306555325347365

Epoch: 596| Step: 0
Training loss: 0.18464891082205895
Validation loss: 2.4272855417145434

Epoch: 6| Step: 1
Training loss: 0.09820077717295325
Validation loss: 2.448120320963622

Epoch: 6| Step: 2
Training loss: 0.13860049223815873
Validation loss: 2.4382702420594144

Epoch: 6| Step: 3
Training loss: 0.14813257570249305
Validation loss: 2.450246650789895

Epoch: 6| Step: 4
Training loss: 0.10987248700037998
Validation loss: 2.4832808807676887

Epoch: 6| Step: 5
Training loss: 0.14233402363431463
Validation loss: 2.46398773626153

Epoch: 6| Step: 6
Training loss: 0.12736307857540005
Validation loss: 2.4506541602041554

Epoch: 6| Step: 7
Training loss: 0.17139544559877098
Validation loss: 2.5009856772799357

Epoch: 6| Step: 8
Training loss: 0.17147046404225713
Validation loss: 2.4660365440863106

Epoch: 6| Step: 9
Training loss: 0.16106465371971196
Validation loss: 2.4845211310867845

Epoch: 6| Step: 10
Training loss: 0.09918898338694136
Validation loss: 2.502381228479981

Epoch: 6| Step: 11
Training loss: 0.15492862827126871
Validation loss: 2.503518027791493

Epoch: 6| Step: 12
Training loss: 0.12187912273769824
Validation loss: 2.467969535576624

Epoch: 6| Step: 13
Training loss: 0.22270577699718455
Validation loss: 2.4335457791115878

Epoch: 597| Step: 0
Training loss: 0.07012951405168912
Validation loss: 2.4737949540615998

Epoch: 6| Step: 1
Training loss: 0.08328353025685668
Validation loss: 2.4782595725592427

Epoch: 6| Step: 2
Training loss: 0.13900643943889315
Validation loss: 2.4624340782505336

Epoch: 6| Step: 3
Training loss: 0.15964896996066066
Validation loss: 2.466805702449401

Epoch: 6| Step: 4
Training loss: 0.1896123708418359
Validation loss: 2.4808269107472065

Epoch: 6| Step: 5
Training loss: 0.11615196302373032
Validation loss: 2.4669375814473806

Epoch: 6| Step: 6
Training loss: 0.11305489616435417
Validation loss: 2.466572220642402

Epoch: 6| Step: 7
Training loss: 0.08893599832926417
Validation loss: 2.454771187751531

Epoch: 6| Step: 8
Training loss: 0.11008048732542965
Validation loss: 2.474550536453387

Epoch: 6| Step: 9
Training loss: 0.0967669045431308
Validation loss: 2.5033924783258854

Epoch: 6| Step: 10
Training loss: 0.08987638668547723
Validation loss: 2.5204130036031205

Epoch: 6| Step: 11
Training loss: 0.24557182430430258
Validation loss: 2.4950246380796934

Epoch: 6| Step: 12
Training loss: 0.16246241309047768
Validation loss: 2.4914945454963395

Epoch: 6| Step: 13
Training loss: 0.0931652378911821
Validation loss: 2.498218232660353

Epoch: 598| Step: 0
Training loss: 0.11874093959149348
Validation loss: 2.4881115953093658

Epoch: 6| Step: 1
Training loss: 0.1439688540376122
Validation loss: 2.4622124586458676

Epoch: 6| Step: 2
Training loss: 0.18455667798580044
Validation loss: 2.4598349710226364

Epoch: 6| Step: 3
Training loss: 0.11850669146961987
Validation loss: 2.4718269538973

Epoch: 6| Step: 4
Training loss: 0.11025896660516908
Validation loss: 2.4666705061936143

Epoch: 6| Step: 5
Training loss: 0.11015724695714983
Validation loss: 2.459740147731328

Epoch: 6| Step: 6
Training loss: 0.1909473816051842
Validation loss: 2.4877329570461297

Epoch: 6| Step: 7
Training loss: 0.1592639688270794
Validation loss: 2.4982580104545895

Epoch: 6| Step: 8
Training loss: 0.09749621152394984
Validation loss: 2.4920222462640003

Epoch: 6| Step: 9
Training loss: 0.07806216335529462
Validation loss: 2.4880639295552758

Epoch: 6| Step: 10
Training loss: 0.1810363850812684
Validation loss: 2.492950935608753

Epoch: 6| Step: 11
Training loss: 0.15233750208244845
Validation loss: 2.5058913530458016

Epoch: 6| Step: 12
Training loss: 0.16750644671431883
Validation loss: 2.4990449229562195

Epoch: 6| Step: 13
Training loss: 0.10643900843860128
Validation loss: 2.499461239013301

Epoch: 599| Step: 0
Training loss: 0.16152230784748828
Validation loss: 2.48219231192863

Epoch: 6| Step: 1
Training loss: 0.08161990025860204
Validation loss: 2.452458658162518

Epoch: 6| Step: 2
Training loss: 0.1053907759617996
Validation loss: 2.449590130780967

Epoch: 6| Step: 3
Training loss: 0.12668977713126287
Validation loss: 2.4741548932696427

Epoch: 6| Step: 4
Training loss: 0.12553206099423192
Validation loss: 2.456707438812391

Epoch: 6| Step: 5
Training loss: 0.13385181625939754
Validation loss: 2.493079989896992

Epoch: 6| Step: 6
Training loss: 0.10022004251743931
Validation loss: 2.4475143779295574

Epoch: 6| Step: 7
Training loss: 0.10260484946535256
Validation loss: 2.475588512959348

Epoch: 6| Step: 8
Training loss: 0.13904596294700228
Validation loss: 2.4649265204488695

Epoch: 6| Step: 9
Training loss: 0.10256945749926429
Validation loss: 2.456121020111524

Epoch: 6| Step: 10
Training loss: 0.18021563991074338
Validation loss: 2.467161687659437

Epoch: 6| Step: 11
Training loss: 0.20190601278957407
Validation loss: 2.471728052972868

Epoch: 6| Step: 12
Training loss: 0.09330562237211563
Validation loss: 2.4764305880053348

Epoch: 6| Step: 13
Training loss: 0.08439558846452216
Validation loss: 2.488736606985705

Epoch: 600| Step: 0
Training loss: 0.17272864028127485
Validation loss: 2.4799952381834585

Epoch: 6| Step: 1
Training loss: 0.12690075014037708
Validation loss: 2.4832052679984264

Epoch: 6| Step: 2
Training loss: 0.09988688165628191
Validation loss: 2.470572776262926

Epoch: 6| Step: 3
Training loss: 0.12134784910910283
Validation loss: 2.487907860864403

Epoch: 6| Step: 4
Training loss: 0.13936428023498126
Validation loss: 2.498007478696538

Epoch: 6| Step: 5
Training loss: 0.12770138819148347
Validation loss: 2.519540662939497

Epoch: 6| Step: 6
Training loss: 0.12487508075108175
Validation loss: 2.489688487661193

Epoch: 6| Step: 7
Training loss: 0.10661313188114911
Validation loss: 2.4698274275126453

Epoch: 6| Step: 8
Training loss: 0.21864932161655998
Validation loss: 2.485336011554323

Epoch: 6| Step: 9
Training loss: 0.1722356956242351
Validation loss: 2.447383061262656

Epoch: 6| Step: 10
Training loss: 0.13651000845027095
Validation loss: 2.482269475291351

Epoch: 6| Step: 11
Training loss: 0.1000845737746999
Validation loss: 2.4513334168684877

Epoch: 6| Step: 12
Training loss: 0.15832514825377578
Validation loss: 2.4662157423407245

Epoch: 6| Step: 13
Training loss: 0.06183598993097952
Validation loss: 2.45124842621395

Epoch: 601| Step: 0
Training loss: 0.09579380760514693
Validation loss: 2.44119703299623

Epoch: 6| Step: 1
Training loss: 0.09944071702800347
Validation loss: 2.416395435947138

Epoch: 6| Step: 2
Training loss: 0.1716283469742016
Validation loss: 2.4409478998929757

Epoch: 6| Step: 3
Training loss: 0.19334938524430617
Validation loss: 2.4295494120275873

Epoch: 6| Step: 4
Training loss: 0.100381346841581
Validation loss: 2.4185421857913805

Epoch: 6| Step: 5
Training loss: 0.18382472868836705
Validation loss: 2.40924104988778

Epoch: 6| Step: 6
Training loss: 0.11871255516413676
Validation loss: 2.4211939303615444

Epoch: 6| Step: 7
Training loss: 0.11173160118935094
Validation loss: 2.4413065808368324

Epoch: 6| Step: 8
Training loss: 0.1594788075351056
Validation loss: 2.4432824926709844

Epoch: 6| Step: 9
Training loss: 0.10919689254452744
Validation loss: 2.4435870468301712

Epoch: 6| Step: 10
Training loss: 0.17849597614091195
Validation loss: 2.4680720341143516

Epoch: 6| Step: 11
Training loss: 0.09139819517265715
Validation loss: 2.47153359481267

Epoch: 6| Step: 12
Training loss: 0.10340245376355676
Validation loss: 2.497805266784593

Epoch: 6| Step: 13
Training loss: 0.12595461868670593
Validation loss: 2.4758366133376564

Epoch: 602| Step: 0
Training loss: 0.1492695077977908
Validation loss: 2.506079388386301

Epoch: 6| Step: 1
Training loss: 0.16363907851886478
Validation loss: 2.478422779405276

Epoch: 6| Step: 2
Training loss: 0.08833320500378389
Validation loss: 2.492963645540269

Epoch: 6| Step: 3
Training loss: 0.10162647689823004
Validation loss: 2.4893832777447047

Epoch: 6| Step: 4
Training loss: 0.16352523525773985
Validation loss: 2.4439452376450523

Epoch: 6| Step: 5
Training loss: 0.11461858360699254
Validation loss: 2.4413210292585923

Epoch: 6| Step: 6
Training loss: 0.13690495753249612
Validation loss: 2.458002562158371

Epoch: 6| Step: 7
Training loss: 0.12563013156449768
Validation loss: 2.4211857498020435

Epoch: 6| Step: 8
Training loss: 0.19023697712272014
Validation loss: 2.431677128267056

Epoch: 6| Step: 9
Training loss: 0.16269851969915666
Validation loss: 2.427164847638678

Epoch: 6| Step: 10
Training loss: 0.08909017756039073
Validation loss: 2.4163505420280345

Epoch: 6| Step: 11
Training loss: 0.16392499406512623
Validation loss: 2.4424186723886536

Epoch: 6| Step: 12
Training loss: 0.18538444838299842
Validation loss: 2.4781704306732975

Epoch: 6| Step: 13
Training loss: 0.1320040372873203
Validation loss: 2.4698801046241567

Epoch: 603| Step: 0
Training loss: 0.10936646768804628
Validation loss: 2.494222641136338

Epoch: 6| Step: 1
Training loss: 0.1058259231949993
Validation loss: 2.465192280897262

Epoch: 6| Step: 2
Training loss: 0.19261488495941445
Validation loss: 2.4905171111631432

Epoch: 6| Step: 3
Training loss: 0.17658999153070437
Validation loss: 2.485287173360393

Epoch: 6| Step: 4
Training loss: 0.09874687115172985
Validation loss: 2.511775934020726

Epoch: 6| Step: 5
Training loss: 0.16744319623361703
Validation loss: 2.496223572274351

Epoch: 6| Step: 6
Training loss: 0.12991722626205682
Validation loss: 2.5124381134732623

Epoch: 6| Step: 7
Training loss: 0.147217960890791
Validation loss: 2.5226231144141926

Epoch: 6| Step: 8
Training loss: 0.0859214702741654
Validation loss: 2.520978461894596

Epoch: 6| Step: 9
Training loss: 0.1721084374961999
Validation loss: 2.4725913716258354

Epoch: 6| Step: 10
Training loss: 0.12609328547584783
Validation loss: 2.4887083100544762

Epoch: 6| Step: 11
Training loss: 0.1684981475630621
Validation loss: 2.4792737776533955

Epoch: 6| Step: 12
Training loss: 0.1227413160412013
Validation loss: 2.487842623861265

Epoch: 6| Step: 13
Training loss: 0.1222564232200225
Validation loss: 2.4908423329368885

Epoch: 604| Step: 0
Training loss: 0.19792049596662487
Validation loss: 2.4835388041467823

Epoch: 6| Step: 1
Training loss: 0.17672886268896568
Validation loss: 2.4761176327777803

Epoch: 6| Step: 2
Training loss: 0.07261342047595348
Validation loss: 2.514679264429614

Epoch: 6| Step: 3
Training loss: 0.10987032549845119
Validation loss: 2.4966448008824864

Epoch: 6| Step: 4
Training loss: 0.07787311599168482
Validation loss: 2.4755713141836426

Epoch: 6| Step: 5
Training loss: 0.16761934733727268
Validation loss: 2.460784681308392

Epoch: 6| Step: 6
Training loss: 0.0993129583339786
Validation loss: 2.5333645626284826

Epoch: 6| Step: 7
Training loss: 0.14365679165445727
Validation loss: 2.454045494204328

Epoch: 6| Step: 8
Training loss: 0.1466827257656963
Validation loss: 2.465585945076175

Epoch: 6| Step: 9
Training loss: 0.12530212101322796
Validation loss: 2.4591518744059115

Epoch: 6| Step: 10
Training loss: 0.12216413325716143
Validation loss: 2.4338180229806308

Epoch: 6| Step: 11
Training loss: 0.09974560584551576
Validation loss: 2.480674713784752

Epoch: 6| Step: 12
Training loss: 0.14274924604288605
Validation loss: 2.4757013417523606

Epoch: 6| Step: 13
Training loss: 0.07199976965499827
Validation loss: 2.4604506774656683

Epoch: 605| Step: 0
Training loss: 0.19922877267795044
Validation loss: 2.4505793186447247

Epoch: 6| Step: 1
Training loss: 0.11567315519691883
Validation loss: 2.4477596902010115

Epoch: 6| Step: 2
Training loss: 0.12938723993451232
Validation loss: 2.478518099152383

Epoch: 6| Step: 3
Training loss: 0.1355758581039028
Validation loss: 2.431412671714926

Epoch: 6| Step: 4
Training loss: 0.1054708339343997
Validation loss: 2.4348151226440935

Epoch: 6| Step: 5
Training loss: 0.09265449830244044
Validation loss: 2.4451789839163895

Epoch: 6| Step: 6
Training loss: 0.09293938902427529
Validation loss: 2.5230708804398057

Epoch: 6| Step: 7
Training loss: 0.11630914449361195
Validation loss: 2.4759030789043543

Epoch: 6| Step: 8
Training loss: 0.12484583810556774
Validation loss: 2.52639777300833

Epoch: 6| Step: 9
Training loss: 0.09041934561862527
Validation loss: 2.488691166407687

Epoch: 6| Step: 10
Training loss: 0.1592334352333981
Validation loss: 2.477810342257626

Epoch: 6| Step: 11
Training loss: 0.14207188994250647
Validation loss: 2.521577583009141

Epoch: 6| Step: 12
Training loss: 0.17981806448188298
Validation loss: 2.5282624435629066

Epoch: 6| Step: 13
Training loss: 0.09381218675590333
Validation loss: 2.5209399131048924

Epoch: 606| Step: 0
Training loss: 0.17925999413777677
Validation loss: 2.545862473350504

Epoch: 6| Step: 1
Training loss: 0.16498749960162296
Validation loss: 2.4974975633652954

Epoch: 6| Step: 2
Training loss: 0.13885952784878725
Validation loss: 2.5402840986590904

Epoch: 6| Step: 3
Training loss: 0.11554060672009472
Validation loss: 2.498959109284291

Epoch: 6| Step: 4
Training loss: 0.12068869155708452
Validation loss: 2.482128400633728

Epoch: 6| Step: 5
Training loss: 0.08713302996757169
Validation loss: 2.4816188547287537

Epoch: 6| Step: 6
Training loss: 0.1785079136357782
Validation loss: 2.4743524453574453

Epoch: 6| Step: 7
Training loss: 0.07351788131725531
Validation loss: 2.47681423833346

Epoch: 6| Step: 8
Training loss: 0.08288494722100273
Validation loss: 2.461555594233742

Epoch: 6| Step: 9
Training loss: 0.07721437581894565
Validation loss: 2.4609058811066125

Epoch: 6| Step: 10
Training loss: 0.099940665344629
Validation loss: 2.4513332160720482

Epoch: 6| Step: 11
Training loss: 0.07967581523047888
Validation loss: 2.4492193516009286

Epoch: 6| Step: 12
Training loss: 0.16617267697225507
Validation loss: 2.4709529474303302

Epoch: 6| Step: 13
Training loss: 0.14795117014992348
Validation loss: 2.4293107729010885

Epoch: 607| Step: 0
Training loss: 0.09797122704265886
Validation loss: 2.487012114025001

Epoch: 6| Step: 1
Training loss: 0.1083082175905065
Validation loss: 2.4948613011536067

Epoch: 6| Step: 2
Training loss: 0.10617157096061373
Validation loss: 2.4876401102330075

Epoch: 6| Step: 3
Training loss: 0.11818945036614796
Validation loss: 2.47471435385325

Epoch: 6| Step: 4
Training loss: 0.0836123276504426
Validation loss: 2.493430455006724

Epoch: 6| Step: 5
Training loss: 0.09751692369803755
Validation loss: 2.4902040309613542

Epoch: 6| Step: 6
Training loss: 0.07318196045697412
Validation loss: 2.4881133160032403

Epoch: 6| Step: 7
Training loss: 0.07584266558124564
Validation loss: 2.4994537802769035

Epoch: 6| Step: 8
Training loss: 0.21036214421114288
Validation loss: 2.4790095490362707

Epoch: 6| Step: 9
Training loss: 0.08989891141828057
Validation loss: 2.515208733757856

Epoch: 6| Step: 10
Training loss: 0.10354933999384033
Validation loss: 2.48924572063163

Epoch: 6| Step: 11
Training loss: 0.16287378686100337
Validation loss: 2.4540284975440456

Epoch: 6| Step: 12
Training loss: 0.1665781923742456
Validation loss: 2.4566274062896927

Epoch: 6| Step: 13
Training loss: 0.12074572404034345
Validation loss: 2.456388400924239

Epoch: 608| Step: 0
Training loss: 0.16108604677284397
Validation loss: 2.4373744093999985

Epoch: 6| Step: 1
Training loss: 0.08530152499603173
Validation loss: 2.4311234382586497

Epoch: 6| Step: 2
Training loss: 0.1614643327818672
Validation loss: 2.4438415651183116

Epoch: 6| Step: 3
Training loss: 0.15064824320689574
Validation loss: 2.4563374639224693

Epoch: 6| Step: 4
Training loss: 0.17341547645748226
Validation loss: 2.452503069859114

Epoch: 6| Step: 5
Training loss: 0.1306277830566638
Validation loss: 2.4961729536364503

Epoch: 6| Step: 6
Training loss: 0.11360176552692139
Validation loss: 2.4980028830364276

Epoch: 6| Step: 7
Training loss: 0.08144207668966195
Validation loss: 2.522318771956422

Epoch: 6| Step: 8
Training loss: 0.19211706212050414
Validation loss: 2.4794016470177795

Epoch: 6| Step: 9
Training loss: 0.10278455321088985
Validation loss: 2.4985339824399904

Epoch: 6| Step: 10
Training loss: 0.13975770050407707
Validation loss: 2.5076624668535428

Epoch: 6| Step: 11
Training loss: 0.09960214738242479
Validation loss: 2.4978350689433277

Epoch: 6| Step: 12
Training loss: 0.13746314394698486
Validation loss: 2.487923981020942

Epoch: 6| Step: 13
Training loss: 0.11273824098928055
Validation loss: 2.4912997043643115

Epoch: 609| Step: 0
Training loss: 0.15036421085593857
Validation loss: 2.487777782918219

Epoch: 6| Step: 1
Training loss: 0.09701276969455616
Validation loss: 2.43802069631257

Epoch: 6| Step: 2
Training loss: 0.12600886500012032
Validation loss: 2.475966164663342

Epoch: 6| Step: 3
Training loss: 0.08750744845414467
Validation loss: 2.462843105045124

Epoch: 6| Step: 4
Training loss: 0.10645009388815357
Validation loss: 2.4809325190553135

Epoch: 6| Step: 5
Training loss: 0.1439340470562835
Validation loss: 2.459456628965961

Epoch: 6| Step: 6
Training loss: 0.1011249396544419
Validation loss: 2.443641825493352

Epoch: 6| Step: 7
Training loss: 0.16771123796715887
Validation loss: 2.464590631908164

Epoch: 6| Step: 8
Training loss: 0.13961614221994115
Validation loss: 2.4696517279885186

Epoch: 6| Step: 9
Training loss: 0.1645763501866826
Validation loss: 2.4735214885691814

Epoch: 6| Step: 10
Training loss: 0.19977570264786043
Validation loss: 2.4666654930663485

Epoch: 6| Step: 11
Training loss: 0.10670592401318763
Validation loss: 2.4867216999514206

Epoch: 6| Step: 12
Training loss: 0.08982847954717749
Validation loss: 2.513679745392317

Epoch: 6| Step: 13
Training loss: 0.11908495493523982
Validation loss: 2.514442845307184

Epoch: 610| Step: 0
Training loss: 0.18382228668578202
Validation loss: 2.4998796208430036

Epoch: 6| Step: 1
Training loss: 0.08665555109508447
Validation loss: 2.5044290952971027

Epoch: 6| Step: 2
Training loss: 0.10069968449269467
Validation loss: 2.5083311777211557

Epoch: 6| Step: 3
Training loss: 0.131411370348876
Validation loss: 2.5008026352275516

Epoch: 6| Step: 4
Training loss: 0.07740550730437129
Validation loss: 2.514239964373493

Epoch: 6| Step: 5
Training loss: 0.13557850966003865
Validation loss: 2.531198587912083

Epoch: 6| Step: 6
Training loss: 0.0897594502153783
Validation loss: 2.5064688104767585

Epoch: 6| Step: 7
Training loss: 0.09779603490485399
Validation loss: 2.500499076916155

Epoch: 6| Step: 8
Training loss: 0.15527152414162682
Validation loss: 2.4879022181666723

Epoch: 6| Step: 9
Training loss: 0.09568272587323606
Validation loss: 2.508079948241968

Epoch: 6| Step: 10
Training loss: 0.09961083822484619
Validation loss: 2.49182225187898

Epoch: 6| Step: 11
Training loss: 0.14255166788102214
Validation loss: 2.469686120152945

Epoch: 6| Step: 12
Training loss: 0.11921705077274015
Validation loss: 2.484639954738405

Epoch: 6| Step: 13
Training loss: 0.09739046166986326
Validation loss: 2.4863252833004035

Epoch: 611| Step: 0
Training loss: 0.09637722714580667
Validation loss: 2.4826584520885535

Epoch: 6| Step: 1
Training loss: 0.10091159933346978
Validation loss: 2.4894810426999503

Epoch: 6| Step: 2
Training loss: 0.13191909286807615
Validation loss: 2.487234143999057

Epoch: 6| Step: 3
Training loss: 0.08408098430624175
Validation loss: 2.4726656132888696

Epoch: 6| Step: 4
Training loss: 0.0857341240108717
Validation loss: 2.5367972164488726

Epoch: 6| Step: 5
Training loss: 0.11872176113788421
Validation loss: 2.508361878902265

Epoch: 6| Step: 6
Training loss: 0.09015682859912766
Validation loss: 2.5346280649718427

Epoch: 6| Step: 7
Training loss: 0.12131041708911632
Validation loss: 2.505638462387228

Epoch: 6| Step: 8
Training loss: 0.17599238854816446
Validation loss: 2.4805700442769063

Epoch: 6| Step: 9
Training loss: 0.15498427090130323
Validation loss: 2.5211316800570707

Epoch: 6| Step: 10
Training loss: 0.07808080853882694
Validation loss: 2.5283322235760846

Epoch: 6| Step: 11
Training loss: 0.20219709207047856
Validation loss: 2.503909112701077

Epoch: 6| Step: 12
Training loss: 0.10635719676874408
Validation loss: 2.5016440933101176

Epoch: 6| Step: 13
Training loss: 0.07217149145177626
Validation loss: 2.4938944483591357

Epoch: 612| Step: 0
Training loss: 0.16853849127654147
Validation loss: 2.4781845865835717

Epoch: 6| Step: 1
Training loss: 0.0735651778176953
Validation loss: 2.471143492449338

Epoch: 6| Step: 2
Training loss: 0.09015214897494059
Validation loss: 2.4926267160941573

Epoch: 6| Step: 3
Training loss: 0.08071235961185527
Validation loss: 2.4732941975786664

Epoch: 6| Step: 4
Training loss: 0.09516752974830876
Validation loss: 2.471548471253523

Epoch: 6| Step: 5
Training loss: 0.16071987414388764
Validation loss: 2.4485791554630167

Epoch: 6| Step: 6
Training loss: 0.10089499021305616
Validation loss: 2.472670072528474

Epoch: 6| Step: 7
Training loss: 0.112111634720149
Validation loss: 2.473351284779334

Epoch: 6| Step: 8
Training loss: 0.07955253054060359
Validation loss: 2.4724257719019382

Epoch: 6| Step: 9
Training loss: 0.11812712352095352
Validation loss: 2.482062420410501

Epoch: 6| Step: 10
Training loss: 0.16065980670503885
Validation loss: 2.484702355148598

Epoch: 6| Step: 11
Training loss: 0.07907433099959689
Validation loss: 2.5092188369154713

Epoch: 6| Step: 12
Training loss: 0.11199159932056925
Validation loss: 2.4900885277186076

Epoch: 6| Step: 13
Training loss: 0.10501961976058774
Validation loss: 2.533205120693631

Epoch: 613| Step: 0
Training loss: 0.09006399132283399
Validation loss: 2.536408397712547

Epoch: 6| Step: 1
Training loss: 0.09829778709528128
Validation loss: 2.4899068632390002

Epoch: 6| Step: 2
Training loss: 0.08561104845283243
Validation loss: 2.5272518826653894

Epoch: 6| Step: 3
Training loss: 0.07806788383232735
Validation loss: 2.547921281943428

Epoch: 6| Step: 4
Training loss: 0.07565075254084128
Validation loss: 2.477889631627353

Epoch: 6| Step: 5
Training loss: 0.10141776849722306
Validation loss: 2.4878052619254305

Epoch: 6| Step: 6
Training loss: 0.07154055222396072
Validation loss: 2.4757879957365168

Epoch: 6| Step: 7
Training loss: 0.19205796947467402
Validation loss: 2.510245493545186

Epoch: 6| Step: 8
Training loss: 0.06898470690594467
Validation loss: 2.4679519164993913

Epoch: 6| Step: 9
Training loss: 0.12447255584554724
Validation loss: 2.4733812354425244

Epoch: 6| Step: 10
Training loss: 0.1103170940277368
Validation loss: 2.4659643088977017

Epoch: 6| Step: 11
Training loss: 0.1225830600831863
Validation loss: 2.4520225872079515

Epoch: 6| Step: 12
Training loss: 0.16825705558881857
Validation loss: 2.484171453428829

Epoch: 6| Step: 13
Training loss: 0.14552388966472146
Validation loss: 2.458120855350647

Epoch: 614| Step: 0
Training loss: 0.1572258279913574
Validation loss: 2.4834111576090785

Epoch: 6| Step: 1
Training loss: 0.18841081174059793
Validation loss: 2.5145936437846177

Epoch: 6| Step: 2
Training loss: 0.16059428301676554
Validation loss: 2.5068404433355513

Epoch: 6| Step: 3
Training loss: 0.11153705133029158
Validation loss: 2.476558174058873

Epoch: 6| Step: 4
Training loss: 0.10024698330527226
Validation loss: 2.494877182686465

Epoch: 6| Step: 5
Training loss: 0.16766733471541892
Validation loss: 2.517737392713822

Epoch: 6| Step: 6
Training loss: 0.1463223642252954
Validation loss: 2.4990162308443273

Epoch: 6| Step: 7
Training loss: 0.11811322308673367
Validation loss: 2.5031202717434877

Epoch: 6| Step: 8
Training loss: 0.0494967693881547
Validation loss: 2.48709663242987

Epoch: 6| Step: 9
Training loss: 0.14228631557811786
Validation loss: 2.472436835524025

Epoch: 6| Step: 10
Training loss: 0.11438681989577461
Validation loss: 2.454717976490787

Epoch: 6| Step: 11
Training loss: 0.06742351104545963
Validation loss: 2.459860654871649

Epoch: 6| Step: 12
Training loss: 0.13475978534596114
Validation loss: 2.4510619668963765

Epoch: 6| Step: 13
Training loss: 0.07580946945000722
Validation loss: 2.4798896519867353

Epoch: 615| Step: 0
Training loss: 0.05990980294660609
Validation loss: 2.4813372143843804

Epoch: 6| Step: 1
Training loss: 0.10900912226063211
Validation loss: 2.458999908063804

Epoch: 6| Step: 2
Training loss: 0.1408996615080392
Validation loss: 2.4722281405187694

Epoch: 6| Step: 3
Training loss: 0.05888957804290464
Validation loss: 2.460556093952645

Epoch: 6| Step: 4
Training loss: 0.07865757612429794
Validation loss: 2.4764087024065917

Epoch: 6| Step: 5
Training loss: 0.07360897411924747
Validation loss: 2.476115678042122

Epoch: 6| Step: 6
Training loss: 0.16739641310142983
Validation loss: 2.4817180267456953

Epoch: 6| Step: 7
Training loss: 0.09292951805929905
Validation loss: 2.493651880605963

Epoch: 6| Step: 8
Training loss: 0.14401199525056466
Validation loss: 2.487665992908383

Epoch: 6| Step: 9
Training loss: 0.09224451774884028
Validation loss: 2.481517290236289

Epoch: 6| Step: 10
Training loss: 0.10250591468900398
Validation loss: 2.5055603734415075

Epoch: 6| Step: 11
Training loss: 0.14098039065369403
Validation loss: 2.497527679703358

Epoch: 6| Step: 12
Training loss: 0.15587354848946056
Validation loss: 2.4669535429825458

Epoch: 6| Step: 13
Training loss: 0.08952833869954116
Validation loss: 2.532506566290155

Epoch: 616| Step: 0
Training loss: 0.1896790209702361
Validation loss: 2.508675832330354

Epoch: 6| Step: 1
Training loss: 0.11750857555262632
Validation loss: 2.477312538534343

Epoch: 6| Step: 2
Training loss: 0.0773758403837589
Validation loss: 2.409815302398856

Epoch: 6| Step: 3
Training loss: 0.10252012350384075
Validation loss: 2.4505747805000953

Epoch: 6| Step: 4
Training loss: 0.12566852612641724
Validation loss: 2.4552227211359217

Epoch: 6| Step: 5
Training loss: 0.15359397931823998
Validation loss: 2.455072942532781

Epoch: 6| Step: 6
Training loss: 0.08470549769175485
Validation loss: 2.479068331906626

Epoch: 6| Step: 7
Training loss: 0.18165188416071643
Validation loss: 2.4645906631138406

Epoch: 6| Step: 8
Training loss: 0.11633915599735883
Validation loss: 2.459397821927307

Epoch: 6| Step: 9
Training loss: 0.09729197271667854
Validation loss: 2.482372370157932

Epoch: 6| Step: 10
Training loss: 0.1074328026848701
Validation loss: 2.4571646802446727

Epoch: 6| Step: 11
Training loss: 0.15893581642327254
Validation loss: 2.472254587406893

Epoch: 6| Step: 12
Training loss: 0.1433770449504172
Validation loss: 2.467559334697269

Epoch: 6| Step: 13
Training loss: 0.09851158359172983
Validation loss: 2.4789875155712773

Epoch: 617| Step: 0
Training loss: 0.11640991278780652
Validation loss: 2.473992518829438

Epoch: 6| Step: 1
Training loss: 0.09010218685194799
Validation loss: 2.455839176280498

Epoch: 6| Step: 2
Training loss: 0.11520503769832069
Validation loss: 2.465312368668388

Epoch: 6| Step: 3
Training loss: 0.13829610173702364
Validation loss: 2.4734075518423277

Epoch: 6| Step: 4
Training loss: 0.08417412480607996
Validation loss: 2.5003149264927007

Epoch: 6| Step: 5
Training loss: 0.08621566900345988
Validation loss: 2.4593993802931404

Epoch: 6| Step: 6
Training loss: 0.11367949823989408
Validation loss: 2.4793569116628382

Epoch: 6| Step: 7
Training loss: 0.12649325195320757
Validation loss: 2.469547005483957

Epoch: 6| Step: 8
Training loss: 0.1551037346859722
Validation loss: 2.45563265365572

Epoch: 6| Step: 9
Training loss: 0.09926938019189624
Validation loss: 2.470330198483918

Epoch: 6| Step: 10
Training loss: 0.10662963639400054
Validation loss: 2.468652579214443

Epoch: 6| Step: 11
Training loss: 0.14705589699988764
Validation loss: 2.466065865247196

Epoch: 6| Step: 12
Training loss: 0.06730302288323808
Validation loss: 2.4739035257810915

Epoch: 6| Step: 13
Training loss: 0.07746889461136063
Validation loss: 2.470030068911185

Epoch: 618| Step: 0
Training loss: 0.09791916740889993
Validation loss: 2.4717889557584156

Epoch: 6| Step: 1
Training loss: 0.09006250742357
Validation loss: 2.442293495324585

Epoch: 6| Step: 2
Training loss: 0.12168297158550283
Validation loss: 2.4901646886827398

Epoch: 6| Step: 3
Training loss: 0.18581029363362228
Validation loss: 2.4482970442056273

Epoch: 6| Step: 4
Training loss: 0.09218960311074761
Validation loss: 2.501869141781203

Epoch: 6| Step: 5
Training loss: 0.10351110394519583
Validation loss: 2.5019691090661875

Epoch: 6| Step: 6
Training loss: 0.15034202310533343
Validation loss: 2.481492689046806

Epoch: 6| Step: 7
Training loss: 0.09996811462729886
Validation loss: 2.45392191002582

Epoch: 6| Step: 8
Training loss: 0.09016916180912776
Validation loss: 2.5010306520617505

Epoch: 6| Step: 9
Training loss: 0.097799825029909
Validation loss: 2.4773661244269576

Epoch: 6| Step: 10
Training loss: 0.07573008493719831
Validation loss: 2.471985824741312

Epoch: 6| Step: 11
Training loss: 0.15299411259493717
Validation loss: 2.4420469053993483

Epoch: 6| Step: 12
Training loss: 0.08971529568128042
Validation loss: 2.445722201565768

Epoch: 6| Step: 13
Training loss: 0.16195178127513452
Validation loss: 2.4671940031011843

Epoch: 619| Step: 0
Training loss: 0.08476701616648671
Validation loss: 2.4989029087086094

Epoch: 6| Step: 1
Training loss: 0.0654267908280682
Validation loss: 2.477277216868376

Epoch: 6| Step: 2
Training loss: 0.09155464170376501
Validation loss: 2.472364498032753

Epoch: 6| Step: 3
Training loss: 0.15734508146387485
Validation loss: 2.4564188334144816

Epoch: 6| Step: 4
Training loss: 0.10603176065834088
Validation loss: 2.494462718690071

Epoch: 6| Step: 5
Training loss: 0.1400250378639471
Validation loss: 2.488644071633014

Epoch: 6| Step: 6
Training loss: 0.12804764849212125
Validation loss: 2.489983091534587

Epoch: 6| Step: 7
Training loss: 0.09538258180442756
Validation loss: 2.4905500381381027

Epoch: 6| Step: 8
Training loss: 0.07382573043128932
Validation loss: 2.4833282775260344

Epoch: 6| Step: 9
Training loss: 0.11462806962644388
Validation loss: 2.4730529057470405

Epoch: 6| Step: 10
Training loss: 0.09716077039882869
Validation loss: 2.4779692019330852

Epoch: 6| Step: 11
Training loss: 0.10765277149632178
Validation loss: 2.486913307751197

Epoch: 6| Step: 12
Training loss: 0.14093876643573983
Validation loss: 2.485029507271168

Epoch: 6| Step: 13
Training loss: 0.08611352730584157
Validation loss: 2.4934194249025903

Epoch: 620| Step: 0
Training loss: 0.07291352600191298
Validation loss: 2.472021577726174

Epoch: 6| Step: 1
Training loss: 0.0668472101781475
Validation loss: 2.4587403828243235

Epoch: 6| Step: 2
Training loss: 0.11272182945981736
Validation loss: 2.4780834710168897

Epoch: 6| Step: 3
Training loss: 0.1258573707525171
Validation loss: 2.4704097393487525

Epoch: 6| Step: 4
Training loss: 0.11159031093920382
Validation loss: 2.4404337119139083

Epoch: 6| Step: 5
Training loss: 0.12528861522172505
Validation loss: 2.4705396951040037

Epoch: 6| Step: 6
Training loss: 0.07971912544192734
Validation loss: 2.450797851014212

Epoch: 6| Step: 7
Training loss: 0.14382221957820812
Validation loss: 2.4442226058557486

Epoch: 6| Step: 8
Training loss: 0.13261300418868302
Validation loss: 2.455030979077741

Epoch: 6| Step: 9
Training loss: 0.13400336317300665
Validation loss: 2.45666345062337

Epoch: 6| Step: 10
Training loss: 0.1611668868594291
Validation loss: 2.442724858122342

Epoch: 6| Step: 11
Training loss: 0.12138666212797188
Validation loss: 2.4654818890049186

Epoch: 6| Step: 12
Training loss: 0.18793103225724828
Validation loss: 2.4203905248706112

Epoch: 6| Step: 13
Training loss: 0.07506852484047515
Validation loss: 2.4241670250936704

Epoch: 621| Step: 0
Training loss: 0.07082666384395102
Validation loss: 2.437409228077466

Epoch: 6| Step: 1
Training loss: 0.11600814082348229
Validation loss: 2.4619606725884604

Epoch: 6| Step: 2
Training loss: 0.16188632603277758
Validation loss: 2.469729942310674

Epoch: 6| Step: 3
Training loss: 0.08732211037268146
Validation loss: 2.4604299818562243

Epoch: 6| Step: 4
Training loss: 0.18677657361277186
Validation loss: 2.4416393285918527

Epoch: 6| Step: 5
Training loss: 0.09372155433483673
Validation loss: 2.469854933927783

Epoch: 6| Step: 6
Training loss: 0.17663006354894187
Validation loss: 2.472359561258559

Epoch: 6| Step: 7
Training loss: 0.12784724454642427
Validation loss: 2.461896937931146

Epoch: 6| Step: 8
Training loss: 0.10570057363313876
Validation loss: 2.4508609297506796

Epoch: 6| Step: 9
Training loss: 0.1461403685663054
Validation loss: 2.454582287829091

Epoch: 6| Step: 10
Training loss: 0.12889509441771663
Validation loss: 2.4613928318120055

Epoch: 6| Step: 11
Training loss: 0.07962915701659415
Validation loss: 2.433634710493077

Epoch: 6| Step: 12
Training loss: 0.16377654586627843
Validation loss: 2.4712277023935534

Epoch: 6| Step: 13
Training loss: 0.09867271711423556
Validation loss: 2.4572043244865984

Epoch: 622| Step: 0
Training loss: 0.130990389814479
Validation loss: 2.4742624796428023

Epoch: 6| Step: 1
Training loss: 0.07774720936643546
Validation loss: 2.466422841263801

Epoch: 6| Step: 2
Training loss: 0.21716162781335765
Validation loss: 2.5087295923896424

Epoch: 6| Step: 3
Training loss: 0.11118106582218265
Validation loss: 2.5019500940664794

Epoch: 6| Step: 4
Training loss: 0.1510886737144323
Validation loss: 2.4832347839031805

Epoch: 6| Step: 5
Training loss: 0.08237106465575994
Validation loss: 2.491471259062718

Epoch: 6| Step: 6
Training loss: 0.07322668547290832
Validation loss: 2.514449306289133

Epoch: 6| Step: 7
Training loss: 0.09520367287860533
Validation loss: 2.495924550851897

Epoch: 6| Step: 8
Training loss: 0.11681029488261466
Validation loss: 2.47654875923626

Epoch: 6| Step: 9
Training loss: 0.0878509219881135
Validation loss: 2.508494177183465

Epoch: 6| Step: 10
Training loss: 0.07868877482233742
Validation loss: 2.4722677754882523

Epoch: 6| Step: 11
Training loss: 0.07998886599957802
Validation loss: 2.480279600466504

Epoch: 6| Step: 12
Training loss: 0.10158055860188706
Validation loss: 2.4816131801691474

Epoch: 6| Step: 13
Training loss: 0.10512127858751986
Validation loss: 2.4958156371894367

Epoch: 623| Step: 0
Training loss: 0.12274465078393089
Validation loss: 2.4766083344296423

Epoch: 6| Step: 1
Training loss: 0.13668921015279675
Validation loss: 2.471388676043457

Epoch: 6| Step: 2
Training loss: 0.14492167758157037
Validation loss: 2.462914886346005

Epoch: 6| Step: 3
Training loss: 0.12169429085234032
Validation loss: 2.479011735205306

Epoch: 6| Step: 4
Training loss: 0.09367120431559703
Validation loss: 2.47775251454243

Epoch: 6| Step: 5
Training loss: 0.10871821138950843
Validation loss: 2.5017883682525075

Epoch: 6| Step: 6
Training loss: 0.07610882081119993
Validation loss: 2.4652552814565483

Epoch: 6| Step: 7
Training loss: 0.09434923252066223
Validation loss: 2.4774611350711724

Epoch: 6| Step: 8
Training loss: 0.12824922796206634
Validation loss: 2.4760795016943837

Epoch: 6| Step: 9
Training loss: 0.17328011464227716
Validation loss: 2.4995075540679963

Epoch: 6| Step: 10
Training loss: 0.08751601813360343
Validation loss: 2.484501489840117

Epoch: 6| Step: 11
Training loss: 0.08056740037709342
Validation loss: 2.4910919294421086

Epoch: 6| Step: 12
Training loss: 0.07509714381882708
Validation loss: 2.4948522441492895

Epoch: 6| Step: 13
Training loss: 0.10743317544626356
Validation loss: 2.4661054370862296

Epoch: 624| Step: 0
Training loss: 0.08457531782055173
Validation loss: 2.4344412462159295

Epoch: 6| Step: 1
Training loss: 0.15473662256301307
Validation loss: 2.468174480096946

Epoch: 6| Step: 2
Training loss: 0.16128860225043637
Validation loss: 2.469947626215333

Epoch: 6| Step: 3
Training loss: 0.12199491461161743
Validation loss: 2.486023710606622

Epoch: 6| Step: 4
Training loss: 0.08957732128699003
Validation loss: 2.4980559778920366

Epoch: 6| Step: 5
Training loss: 0.09852624556115407
Validation loss: 2.507329187393158

Epoch: 6| Step: 6
Training loss: 0.09429352875265938
Validation loss: 2.4484131431110185

Epoch: 6| Step: 7
Training loss: 0.16696344652522352
Validation loss: 2.493833539555904

Epoch: 6| Step: 8
Training loss: 0.06337886040308253
Validation loss: 2.4302710233484746

Epoch: 6| Step: 9
Training loss: 0.13189745280237108
Validation loss: 2.454809319812052

Epoch: 6| Step: 10
Training loss: 0.07032012566964503
Validation loss: 2.448761816143835

Epoch: 6| Step: 11
Training loss: 0.09407785824134564
Validation loss: 2.4679453992319855

Epoch: 6| Step: 12
Training loss: 0.0920460342941265
Validation loss: 2.5011174237570573

Epoch: 6| Step: 13
Training loss: 0.12417427787385507
Validation loss: 2.473257167310527

Epoch: 625| Step: 0
Training loss: 0.11563349963212685
Validation loss: 2.4677160675105343

Epoch: 6| Step: 1
Training loss: 0.11865666856458339
Validation loss: 2.488753962002989

Epoch: 6| Step: 2
Training loss: 0.13659127286926545
Validation loss: 2.507883116843058

Epoch: 6| Step: 3
Training loss: 0.11609953260716822
Validation loss: 2.4581539216505814

Epoch: 6| Step: 4
Training loss: 0.09059973561888345
Validation loss: 2.508307397564076

Epoch: 6| Step: 5
Training loss: 0.0599968484271873
Validation loss: 2.447262949547979

Epoch: 6| Step: 6
Training loss: 0.12812563762273532
Validation loss: 2.451161249844772

Epoch: 6| Step: 7
Training loss: 0.07500043610604969
Validation loss: 2.4616533187964333

Epoch: 6| Step: 8
Training loss: 0.0709242040928679
Validation loss: 2.460635725726651

Epoch: 6| Step: 9
Training loss: 0.08207271867444879
Validation loss: 2.4190435640677896

Epoch: 6| Step: 10
Training loss: 0.1566687931980051
Validation loss: 2.4455872612347513

Epoch: 6| Step: 11
Training loss: 0.08157904620619483
Validation loss: 2.4705691226221838

Epoch: 6| Step: 12
Training loss: 0.08052947324906644
Validation loss: 2.45297275538708

Epoch: 6| Step: 13
Training loss: 0.0815928729047426
Validation loss: 2.453921194398283

Epoch: 626| Step: 0
Training loss: 0.1419059441657048
Validation loss: 2.4279126966630495

Epoch: 6| Step: 1
Training loss: 0.06377673699880122
Validation loss: 2.46052356786534

Epoch: 6| Step: 2
Training loss: 0.14834412976038144
Validation loss: 2.4464728456524085

Epoch: 6| Step: 3
Training loss: 0.15834412943168005
Validation loss: 2.4622670738670895

Epoch: 6| Step: 4
Training loss: 0.0834144952042366
Validation loss: 2.44080180689645

Epoch: 6| Step: 5
Training loss: 0.10572908643036728
Validation loss: 2.491976454095644

Epoch: 6| Step: 6
Training loss: 0.10059402951773198
Validation loss: 2.47285539549943

Epoch: 6| Step: 7
Training loss: 0.12295414064113667
Validation loss: 2.4489313431829713

Epoch: 6| Step: 8
Training loss: 0.09905912783144928
Validation loss: 2.4608296803211034

Epoch: 6| Step: 9
Training loss: 0.07036554799076317
Validation loss: 2.435545623466092

Epoch: 6| Step: 10
Training loss: 0.1392683712673426
Validation loss: 2.467701780904171

Epoch: 6| Step: 11
Training loss: 0.07865650457758544
Validation loss: 2.450017178592222

Epoch: 6| Step: 12
Training loss: 0.10512126972801371
Validation loss: 2.43735662963699

Epoch: 6| Step: 13
Training loss: 0.09415142226922601
Validation loss: 2.4533217229552804

Epoch: 627| Step: 0
Training loss: 0.1361963509663532
Validation loss: 2.4628933506140496

Epoch: 6| Step: 1
Training loss: 0.1170965159394685
Validation loss: 2.464894545021506

Epoch: 6| Step: 2
Training loss: 0.10347447387096584
Validation loss: 2.485226935841959

Epoch: 6| Step: 3
Training loss: 0.08044978862800474
Validation loss: 2.445141676741232

Epoch: 6| Step: 4
Training loss: 0.12213018474949813
Validation loss: 2.4668787880274023

Epoch: 6| Step: 5
Training loss: 0.11259954141592042
Validation loss: 2.4751221009024746

Epoch: 6| Step: 6
Training loss: 0.15761217371684247
Validation loss: 2.461483432722229

Epoch: 6| Step: 7
Training loss: 0.09660054830658142
Validation loss: 2.455885230451372

Epoch: 6| Step: 8
Training loss: 0.09230194241884977
Validation loss: 2.435538145827054

Epoch: 6| Step: 9
Training loss: 0.07018822376267847
Validation loss: 2.41654776244245

Epoch: 6| Step: 10
Training loss: 0.12555890749068593
Validation loss: 2.4448557221360554

Epoch: 6| Step: 11
Training loss: 0.07939141057392907
Validation loss: 2.447129800736661

Epoch: 6| Step: 12
Training loss: 0.10974924739142948
Validation loss: 2.4099976274062285

Epoch: 6| Step: 13
Training loss: 0.07469271853103995
Validation loss: 2.4494537394129896

Epoch: 628| Step: 0
Training loss: 0.06458009870694113
Validation loss: 2.4349473324082247

Epoch: 6| Step: 1
Training loss: 0.07668558233614088
Validation loss: 2.432381907953672

Epoch: 6| Step: 2
Training loss: 0.08162509186375869
Validation loss: 2.4617578022510935

Epoch: 6| Step: 3
Training loss: 0.13438095950063358
Validation loss: 2.4379193681698896

Epoch: 6| Step: 4
Training loss: 0.08579179484448268
Validation loss: 2.4447190938992334

Epoch: 6| Step: 5
Training loss: 0.10952653775438469
Validation loss: 2.477718838078794

Epoch: 6| Step: 6
Training loss: 0.08401166672061361
Validation loss: 2.4450314063501044

Epoch: 6| Step: 7
Training loss: 0.11783844638701182
Validation loss: 2.4808560333337177

Epoch: 6| Step: 8
Training loss: 0.10961281942990289
Validation loss: 2.4684052806252397

Epoch: 6| Step: 9
Training loss: 0.0577065574842421
Validation loss: 2.4799600911807866

Epoch: 6| Step: 10
Training loss: 0.16455392806216546
Validation loss: 2.4666506230326717

Epoch: 6| Step: 11
Training loss: 0.17999805689464923
Validation loss: 2.4562449552301606

Epoch: 6| Step: 12
Training loss: 0.10781743307852318
Validation loss: 2.4992859876985873

Epoch: 6| Step: 13
Training loss: 0.15319953097223094
Validation loss: 2.4584618255533766

Epoch: 629| Step: 0
Training loss: 0.06575532557536837
Validation loss: 2.4625811584134563

Epoch: 6| Step: 1
Training loss: 0.14458120616819337
Validation loss: 2.461867677499812

Epoch: 6| Step: 2
Training loss: 0.10502640362402968
Validation loss: 2.470479793004981

Epoch: 6| Step: 3
Training loss: 0.14997070692057032
Validation loss: 2.460672046820135

Epoch: 6| Step: 4
Training loss: 0.11293406970515033
Validation loss: 2.4476748613900847

Epoch: 6| Step: 5
Training loss: 0.11447296507669578
Validation loss: 2.421184768789525

Epoch: 6| Step: 6
Training loss: 0.10445463539663533
Validation loss: 2.4698027062499026

Epoch: 6| Step: 7
Training loss: 0.18926046347951267
Validation loss: 2.4267968226056587

Epoch: 6| Step: 8
Training loss: 0.1097046278761096
Validation loss: 2.404760536045746

Epoch: 6| Step: 9
Training loss: 0.14867340340683136
Validation loss: 2.41379898650258

Epoch: 6| Step: 10
Training loss: 0.11972242320187809
Validation loss: 2.4195276312154816

Epoch: 6| Step: 11
Training loss: 0.11446386488691965
Validation loss: 2.419308853464389

Epoch: 6| Step: 12
Training loss: 0.07715154895061162
Validation loss: 2.440701614124212

Epoch: 6| Step: 13
Training loss: 0.09122278393878722
Validation loss: 2.486827068233879

Epoch: 630| Step: 0
Training loss: 0.13683309541756897
Validation loss: 2.4363444723297727

Epoch: 6| Step: 1
Training loss: 0.1063490878902925
Validation loss: 2.465484896142886

Epoch: 6| Step: 2
Training loss: 0.11120664929294846
Validation loss: 2.502145398360554

Epoch: 6| Step: 3
Training loss: 0.13252680568083802
Validation loss: 2.5083486567645052

Epoch: 6| Step: 4
Training loss: 0.15862787588930394
Validation loss: 2.4744345403005594

Epoch: 6| Step: 5
Training loss: 0.1537576257938988
Validation loss: 2.483804397442711

Epoch: 6| Step: 6
Training loss: 0.08758038230355372
Validation loss: 2.4751319717070426

Epoch: 6| Step: 7
Training loss: 0.08978167753054742
Validation loss: 2.4657402149838252

Epoch: 6| Step: 8
Training loss: 0.07817536161349463
Validation loss: 2.4598502881921034

Epoch: 6| Step: 9
Training loss: 0.06296646124653514
Validation loss: 2.4826792308802417

Epoch: 6| Step: 10
Training loss: 0.08091168255135947
Validation loss: 2.4368294413268248

Epoch: 6| Step: 11
Training loss: 0.10626803956740262
Validation loss: 2.415643707475912

Epoch: 6| Step: 12
Training loss: 0.1012602490076857
Validation loss: 2.425077845004051

Epoch: 6| Step: 13
Training loss: 0.12985572675928278
Validation loss: 2.477419446320622

Epoch: 631| Step: 0
Training loss: 0.12302603999354107
Validation loss: 2.4416076414332006

Epoch: 6| Step: 1
Training loss: 0.11792601891466238
Validation loss: 2.443252939011485

Epoch: 6| Step: 2
Training loss: 0.066455738476367
Validation loss: 2.4442147121432316

Epoch: 6| Step: 3
Training loss: 0.06637336112861943
Validation loss: 2.4533455308490697

Epoch: 6| Step: 4
Training loss: 0.09091134277685349
Validation loss: 2.4273756466379117

Epoch: 6| Step: 5
Training loss: 0.06638254064962422
Validation loss: 2.442297888255423

Epoch: 6| Step: 6
Training loss: 0.061118206741258375
Validation loss: 2.4474264473970067

Epoch: 6| Step: 7
Training loss: 0.15331866633995422
Validation loss: 2.459274437914651

Epoch: 6| Step: 8
Training loss: 0.11125779021505118
Validation loss: 2.422754389126799

Epoch: 6| Step: 9
Training loss: 0.0713560201440136
Validation loss: 2.496621784284488

Epoch: 6| Step: 10
Training loss: 0.1445964009128743
Validation loss: 2.464264612959531

Epoch: 6| Step: 11
Training loss: 0.09404606561523211
Validation loss: 2.48756421515871

Epoch: 6| Step: 12
Training loss: 0.06895341933572491
Validation loss: 2.4598263301251406

Epoch: 6| Step: 13
Training loss: 0.07027002879766124
Validation loss: 2.458038011654872

Epoch: 632| Step: 0
Training loss: 0.08270189348288035
Validation loss: 2.464687137735442

Epoch: 6| Step: 1
Training loss: 0.0929186738211546
Validation loss: 2.459217077105737

Epoch: 6| Step: 2
Training loss: 0.13863503947421532
Validation loss: 2.4645073643937483

Epoch: 6| Step: 3
Training loss: 0.11020511006907083
Validation loss: 2.4278018501728216

Epoch: 6| Step: 4
Training loss: 0.11277263012112435
Validation loss: 2.444261546469202

Epoch: 6| Step: 5
Training loss: 0.15916291247949318
Validation loss: 2.4536841075219016

Epoch: 6| Step: 6
Training loss: 0.08691465184729853
Validation loss: 2.4383479016926595

Epoch: 6| Step: 7
Training loss: 0.10356740286374942
Validation loss: 2.4512280404013476

Epoch: 6| Step: 8
Training loss: 0.08629083065191777
Validation loss: 2.460177950848564

Epoch: 6| Step: 9
Training loss: 0.1156267178897569
Validation loss: 2.4776021278147717

Epoch: 6| Step: 10
Training loss: 0.0686923297215858
Validation loss: 2.4624735408377756

Epoch: 6| Step: 11
Training loss: 0.08730440139723629
Validation loss: 2.424039652273703

Epoch: 6| Step: 12
Training loss: 0.10034297561881306
Validation loss: 2.4653415549397555

Epoch: 6| Step: 13
Training loss: 0.0518308317886713
Validation loss: 2.454795006129638

Epoch: 633| Step: 0
Training loss: 0.12594610038147896
Validation loss: 2.4431011453380957

Epoch: 6| Step: 1
Training loss: 0.09314783742759848
Validation loss: 2.4655643214185723

Epoch: 6| Step: 2
Training loss: 0.13857090995123392
Validation loss: 2.4667221334845557

Epoch: 6| Step: 3
Training loss: 0.13157372005488074
Validation loss: 2.4741495694316753

Epoch: 6| Step: 4
Training loss: 0.0789259090578309
Validation loss: 2.454910118941007

Epoch: 6| Step: 5
Training loss: 0.07277180624304297
Validation loss: 2.4332425283727175

Epoch: 6| Step: 6
Training loss: 0.06832819636350124
Validation loss: 2.4277882700725346

Epoch: 6| Step: 7
Training loss: 0.06753162523449609
Validation loss: 2.4740843893080675

Epoch: 6| Step: 8
Training loss: 0.09763886296939069
Validation loss: 2.463806460362165

Epoch: 6| Step: 9
Training loss: 0.07192183891285536
Validation loss: 2.4379724287168485

Epoch: 6| Step: 10
Training loss: 0.07682888026716742
Validation loss: 2.4669875446207024

Epoch: 6| Step: 11
Training loss: 0.06158444052053621
Validation loss: 2.449786604937788

Epoch: 6| Step: 12
Training loss: 0.1620120652685432
Validation loss: 2.4560592196944278

Epoch: 6| Step: 13
Training loss: 0.08669584182209158
Validation loss: 2.4576915308498806

Epoch: 634| Step: 0
Training loss: 0.08547240351446975
Validation loss: 2.4569892605171018

Epoch: 6| Step: 1
Training loss: 0.09495942507268706
Validation loss: 2.482413882786019

Epoch: 6| Step: 2
Training loss: 0.06238442030729565
Validation loss: 2.452591750772404

Epoch: 6| Step: 3
Training loss: 0.10421859718322989
Validation loss: 2.4588777677229783

Epoch: 6| Step: 4
Training loss: 0.07925197053363799
Validation loss: 2.494297178364058

Epoch: 6| Step: 5
Training loss: 0.0878492204838219
Validation loss: 2.456642212289021

Epoch: 6| Step: 6
Training loss: 0.06402379151642672
Validation loss: 2.440864065300154

Epoch: 6| Step: 7
Training loss: 0.10468064008128881
Validation loss: 2.446384168235152

Epoch: 6| Step: 8
Training loss: 0.10665160496396506
Validation loss: 2.4593714077368176

Epoch: 6| Step: 9
Training loss: 0.12990060125159314
Validation loss: 2.47040892576121

Epoch: 6| Step: 10
Training loss: 0.08548867268480327
Validation loss: 2.4368534403319293

Epoch: 6| Step: 11
Training loss: 0.14847863405383788
Validation loss: 2.464080621687044

Epoch: 6| Step: 12
Training loss: 0.15517205701407663
Validation loss: 2.4417284019645553

Epoch: 6| Step: 13
Training loss: 0.07571466484928413
Validation loss: 2.4857230243803383

Epoch: 635| Step: 0
Training loss: 0.08363006952554622
Validation loss: 2.451594450880641

Epoch: 6| Step: 1
Training loss: 0.13840980346374623
Validation loss: 2.460658326715624

Epoch: 6| Step: 2
Training loss: 0.11150312890165874
Validation loss: 2.4641275970643073

Epoch: 6| Step: 3
Training loss: 0.08037825491092984
Validation loss: 2.4420267073230137

Epoch: 6| Step: 4
Training loss: 0.07581391343397538
Validation loss: 2.4415690795414817

Epoch: 6| Step: 5
Training loss: 0.06567829854278608
Validation loss: 2.4432521273982752

Epoch: 6| Step: 6
Training loss: 0.06552819409223745
Validation loss: 2.4742218070713293

Epoch: 6| Step: 7
Training loss: 0.04847780442779509
Validation loss: 2.4463580012701045

Epoch: 6| Step: 8
Training loss: 0.09515678396216098
Validation loss: 2.418825075333082

Epoch: 6| Step: 9
Training loss: 0.06989114395041042
Validation loss: 2.4672104466714146

Epoch: 6| Step: 10
Training loss: 0.08506458909533599
Validation loss: 2.468929524642171

Epoch: 6| Step: 11
Training loss: 0.08199531755929143
Validation loss: 2.4993515004164584

Epoch: 6| Step: 12
Training loss: 0.13000466789980036
Validation loss: 2.4714417622889266

Epoch: 6| Step: 13
Training loss: 0.06062988774023952
Validation loss: 2.465321375093403

Epoch: 636| Step: 0
Training loss: 0.05995091034489947
Validation loss: 2.491621411629673

Epoch: 6| Step: 1
Training loss: 0.09404476833503284
Validation loss: 2.4621100155275832

Epoch: 6| Step: 2
Training loss: 0.07266068406572411
Validation loss: 2.455039499014079

Epoch: 6| Step: 3
Training loss: 0.09974248724595323
Validation loss: 2.497010132082484

Epoch: 6| Step: 4
Training loss: 0.12008430061765887
Validation loss: 2.4961331826699835

Epoch: 6| Step: 5
Training loss: 0.15401334908998057
Validation loss: 2.502199494929284

Epoch: 6| Step: 6
Training loss: 0.16755636180596628
Validation loss: 2.467788311675822

Epoch: 6| Step: 7
Training loss: 0.0668300540682217
Validation loss: 2.4988101137464183

Epoch: 6| Step: 8
Training loss: 0.07342098029988452
Validation loss: 2.4806750289854267

Epoch: 6| Step: 9
Training loss: 0.10721787242035492
Validation loss: 2.452985180737608

Epoch: 6| Step: 10
Training loss: 0.08759046267738342
Validation loss: 2.481642866866849

Epoch: 6| Step: 11
Training loss: 0.11131798129130883
Validation loss: 2.466526548945131

Epoch: 6| Step: 12
Training loss: 0.10176091802621079
Validation loss: 2.4558276688662386

Epoch: 6| Step: 13
Training loss: 0.05442810914146756
Validation loss: 2.4647651486786994

Epoch: 637| Step: 0
Training loss: 0.11670025621535607
Validation loss: 2.4538008197425176

Epoch: 6| Step: 1
Training loss: 0.09059962254399814
Validation loss: 2.467645343221463

Epoch: 6| Step: 2
Training loss: 0.06885155876408112
Validation loss: 2.458450713639388

Epoch: 6| Step: 3
Training loss: 0.06600275944162029
Validation loss: 2.451949499248006

Epoch: 6| Step: 4
Training loss: 0.08126382102698657
Validation loss: 2.458839173274968

Epoch: 6| Step: 5
Training loss: 0.10463134020790134
Validation loss: 2.439807760681748

Epoch: 6| Step: 6
Training loss: 0.11562237639930253
Validation loss: 2.440121970886197

Epoch: 6| Step: 7
Training loss: 0.153936175762727
Validation loss: 2.467714555951601

Epoch: 6| Step: 8
Training loss: 0.15406220130427192
Validation loss: 2.4293238490319715

Epoch: 6| Step: 9
Training loss: 0.08241753792764285
Validation loss: 2.44771587741364

Epoch: 6| Step: 10
Training loss: 0.1429279295173868
Validation loss: 2.479817029469893

Epoch: 6| Step: 11
Training loss: 0.07397448032984794
Validation loss: 2.451255241492564

Epoch: 6| Step: 12
Training loss: 0.08662682657290847
Validation loss: 2.465278599221058

Epoch: 6| Step: 13
Training loss: 0.0913364347555779
Validation loss: 2.4587377683423894

Epoch: 638| Step: 0
Training loss: 0.09474533917455484
Validation loss: 2.4678001575557404

Epoch: 6| Step: 1
Training loss: 0.07079742029039422
Validation loss: 2.473407544586959

Epoch: 6| Step: 2
Training loss: 0.2003270901798388
Validation loss: 2.501281324809727

Epoch: 6| Step: 3
Training loss: 0.1287439147775013
Validation loss: 2.4938653752333164

Epoch: 6| Step: 4
Training loss: 0.1440805353865527
Validation loss: 2.4962261983314598

Epoch: 6| Step: 5
Training loss: 0.08095309198456521
Validation loss: 2.5095723694426155

Epoch: 6| Step: 6
Training loss: 0.07557669442608989
Validation loss: 2.5165126047106803

Epoch: 6| Step: 7
Training loss: 0.06794816039627116
Validation loss: 2.5132328145306584

Epoch: 6| Step: 8
Training loss: 0.06763258542179933
Validation loss: 2.4910025628921297

Epoch: 6| Step: 9
Training loss: 0.09872517651750796
Validation loss: 2.495887625745036

Epoch: 6| Step: 10
Training loss: 0.07079662442336636
Validation loss: 2.516657235412376

Epoch: 6| Step: 11
Training loss: 0.14222946386146515
Validation loss: 2.5131198437429867

Epoch: 6| Step: 12
Training loss: 0.11109987082433101
Validation loss: 2.5041493723708266

Epoch: 6| Step: 13
Training loss: 0.13601002238488347
Validation loss: 2.4564525994229167

Epoch: 639| Step: 0
Training loss: 0.11498660995052054
Validation loss: 2.48129877710116

Epoch: 6| Step: 1
Training loss: 0.07885260021007269
Validation loss: 2.4649338413322655

Epoch: 6| Step: 2
Training loss: 0.08882824075770154
Validation loss: 2.4578264115987487

Epoch: 6| Step: 3
Training loss: 0.1003191938721867
Validation loss: 2.4716722465740193

Epoch: 6| Step: 4
Training loss: 0.11921913265026873
Validation loss: 2.4487885719537927

Epoch: 6| Step: 5
Training loss: 0.09633620251483087
Validation loss: 2.461939644478361

Epoch: 6| Step: 6
Training loss: 0.06915312158401082
Validation loss: 2.431662376897248

Epoch: 6| Step: 7
Training loss: 0.14099510815010804
Validation loss: 2.4152614495310525

Epoch: 6| Step: 8
Training loss: 0.137569708385286
Validation loss: 2.4165263391586747

Epoch: 6| Step: 9
Training loss: 0.14226445222190015
Validation loss: 2.4007691853877575

Epoch: 6| Step: 10
Training loss: 0.14180326237229576
Validation loss: 2.4650391830983978

Epoch: 6| Step: 11
Training loss: 0.14179990623323732
Validation loss: 2.441129489101324

Epoch: 6| Step: 12
Training loss: 0.10878897244023374
Validation loss: 2.43770818291957

Epoch: 6| Step: 13
Training loss: 0.08819790213962368
Validation loss: 2.4452805322898503

Epoch: 640| Step: 0
Training loss: 0.06776456225104778
Validation loss: 2.4507682519946754

Epoch: 6| Step: 1
Training loss: 0.09227622458211998
Validation loss: 2.4922203884474277

Epoch: 6| Step: 2
Training loss: 0.048767256945346435
Validation loss: 2.463027071666112

Epoch: 6| Step: 3
Training loss: 0.1618665231966978
Validation loss: 2.446414492012696

Epoch: 6| Step: 4
Training loss: 0.10583709045872465
Validation loss: 2.468423003699252

Epoch: 6| Step: 5
Training loss: 0.06544012726580395
Validation loss: 2.4600185644214805

Epoch: 6| Step: 6
Training loss: 0.08900901983160985
Validation loss: 2.4435124189708612

Epoch: 6| Step: 7
Training loss: 0.08665857643766313
Validation loss: 2.4661108957587894

Epoch: 6| Step: 8
Training loss: 0.11869527487502202
Validation loss: 2.4785930290112286

Epoch: 6| Step: 9
Training loss: 0.09505647056940761
Validation loss: 2.4482232300904783

Epoch: 6| Step: 10
Training loss: 0.10632127131530737
Validation loss: 2.4908023471711087

Epoch: 6| Step: 11
Training loss: 0.10970902952330569
Validation loss: 2.4643246292046737

Epoch: 6| Step: 12
Training loss: 0.15424921410273845
Validation loss: 2.474106096519149

Epoch: 6| Step: 13
Training loss: 0.15839213395187848
Validation loss: 2.47630192283891

Epoch: 641| Step: 0
Training loss: 0.06506642161390498
Validation loss: 2.455482259012274

Epoch: 6| Step: 1
Training loss: 0.15068235217588508
Validation loss: 2.4606961247987216

Epoch: 6| Step: 2
Training loss: 0.1463576595278759
Validation loss: 2.478220214450484

Epoch: 6| Step: 3
Training loss: 0.0936038198849186
Validation loss: 2.438130979902986

Epoch: 6| Step: 4
Training loss: 0.07908799502496068
Validation loss: 2.466513654452318

Epoch: 6| Step: 5
Training loss: 0.10416383938131382
Validation loss: 2.4809256297845588

Epoch: 6| Step: 6
Training loss: 0.0634954241092776
Validation loss: 2.496596441650531

Epoch: 6| Step: 7
Training loss: 0.05708675785970948
Validation loss: 2.48289168604641

Epoch: 6| Step: 8
Training loss: 0.13818713881187908
Validation loss: 2.4710908204833957

Epoch: 6| Step: 9
Training loss: 0.08074324879827731
Validation loss: 2.4692031290812877

Epoch: 6| Step: 10
Training loss: 0.12517594828946424
Validation loss: 2.4686724701360423

Epoch: 6| Step: 11
Training loss: 0.18695870387564384
Validation loss: 2.5119943509833567

Epoch: 6| Step: 12
Training loss: 0.10409981599097749
Validation loss: 2.456132712725494

Epoch: 6| Step: 13
Training loss: 0.08312247435149565
Validation loss: 2.4668650930902074

Epoch: 642| Step: 0
Training loss: 0.09493333331363812
Validation loss: 2.44156427789968

Epoch: 6| Step: 1
Training loss: 0.09271042340133596
Validation loss: 2.4332012752230607

Epoch: 6| Step: 2
Training loss: 0.10174666726256856
Validation loss: 2.434131307550871

Epoch: 6| Step: 3
Training loss: 0.11141820659517777
Validation loss: 2.4355938791585725

Epoch: 6| Step: 4
Training loss: 0.1154218135284636
Validation loss: 2.447177638649722

Epoch: 6| Step: 5
Training loss: 0.09020403996136865
Validation loss: 2.447393832710355

Epoch: 6| Step: 6
Training loss: 0.0736404273347976
Validation loss: 2.4631841537538612

Epoch: 6| Step: 7
Training loss: 0.09264798968646222
Validation loss: 2.4675032755748165

Epoch: 6| Step: 8
Training loss: 0.11278883195697485
Validation loss: 2.4931960326871896

Epoch: 6| Step: 9
Training loss: 0.13700603546732068
Validation loss: 2.492868219463437

Epoch: 6| Step: 10
Training loss: 0.10870036613502271
Validation loss: 2.5348037279208295

Epoch: 6| Step: 11
Training loss: 0.07959790569265773
Validation loss: 2.4893970588865364

Epoch: 6| Step: 12
Training loss: 0.1547731822102587
Validation loss: 2.531278460682036

Epoch: 6| Step: 13
Training loss: 0.08505199748410815
Validation loss: 2.5025728850401703

Epoch: 643| Step: 0
Training loss: 0.14618402843422437
Validation loss: 2.4862161991746836

Epoch: 6| Step: 1
Training loss: 0.06310661422908302
Validation loss: 2.488299921798021

Epoch: 6| Step: 2
Training loss: 0.13406106350091337
Validation loss: 2.46351990729941

Epoch: 6| Step: 3
Training loss: 0.07915334713666085
Validation loss: 2.48469950281959

Epoch: 6| Step: 4
Training loss: 0.08467394764787303
Validation loss: 2.415702813964987

Epoch: 6| Step: 5
Training loss: 0.10681998955008147
Validation loss: 2.407143778293646

Epoch: 6| Step: 6
Training loss: 0.11983351045753712
Validation loss: 2.431915107196638

Epoch: 6| Step: 7
Training loss: 0.1377270574026874
Validation loss: 2.3868099298815935

Epoch: 6| Step: 8
Training loss: 0.057591404237597996
Validation loss: 2.4161725622936223

Epoch: 6| Step: 9
Training loss: 0.1014471132208959
Validation loss: 2.3850924242005984

Epoch: 6| Step: 10
Training loss: 0.08119071897757707
Validation loss: 2.406162223605301

Epoch: 6| Step: 11
Training loss: 0.11578349835867868
Validation loss: 2.4236399729001428

Epoch: 6| Step: 12
Training loss: 0.16960745254685186
Validation loss: 2.427432234841706

Epoch: 6| Step: 13
Training loss: 0.0725664501634625
Validation loss: 2.41191975017308

Epoch: 644| Step: 0
Training loss: 0.0760206408477762
Validation loss: 2.409043631426316

Epoch: 6| Step: 1
Training loss: 0.07682951364102075
Validation loss: 2.419742443729037

Epoch: 6| Step: 2
Training loss: 0.0941166166502128
Validation loss: 2.44309969620089

Epoch: 6| Step: 3
Training loss: 0.1582387366068071
Validation loss: 2.453225274770354

Epoch: 6| Step: 4
Training loss: 0.10744064773904839
Validation loss: 2.4545803023658848

Epoch: 6| Step: 5
Training loss: 0.08525718363681421
Validation loss: 2.4567484783009363

Epoch: 6| Step: 6
Training loss: 0.08647559503029104
Validation loss: 2.4531112491809326

Epoch: 6| Step: 7
Training loss: 0.09429444235640246
Validation loss: 2.4212929874798075

Epoch: 6| Step: 8
Training loss: 0.14043679491289662
Validation loss: 2.4668158559517366

Epoch: 6| Step: 9
Training loss: 0.05548481985478889
Validation loss: 2.450018774316011

Epoch: 6| Step: 10
Training loss: 0.0968033933561488
Validation loss: 2.464068323554634

Epoch: 6| Step: 11
Training loss: 0.06950460657497899
Validation loss: 2.468532454538572

Epoch: 6| Step: 12
Training loss: 0.07930469333459635
Validation loss: 2.450390106034402

Epoch: 6| Step: 13
Training loss: 0.15582981235581653
Validation loss: 2.461688563673632

Epoch: 645| Step: 0
Training loss: 0.15786714551963518
Validation loss: 2.4495705610957663

Epoch: 6| Step: 1
Training loss: 0.09039688874997351
Validation loss: 2.470955669857452

Epoch: 6| Step: 2
Training loss: 0.08056620973505271
Validation loss: 2.474851246408739

Epoch: 6| Step: 3
Training loss: 0.10339033894227631
Validation loss: 2.4728982149924046

Epoch: 6| Step: 4
Training loss: 0.05677990191142117
Validation loss: 2.468307361976178

Epoch: 6| Step: 5
Training loss: 0.07941745155071873
Validation loss: 2.494419408121052

Epoch: 6| Step: 6
Training loss: 0.07450128097220973
Validation loss: 2.456554490554593

Epoch: 6| Step: 7
Training loss: 0.07635645632457187
Validation loss: 2.4871977964424103

Epoch: 6| Step: 8
Training loss: 0.0865561746272758
Validation loss: 2.4502614775590765

Epoch: 6| Step: 9
Training loss: 0.08888931837243062
Validation loss: 2.4501533481655873

Epoch: 6| Step: 10
Training loss: 0.1384355788388215
Validation loss: 2.4600622612709007

Epoch: 6| Step: 11
Training loss: 0.05404777245632499
Validation loss: 2.482254301627205

Epoch: 6| Step: 12
Training loss: 0.11964148630442722
Validation loss: 2.4330695848673445

Epoch: 6| Step: 13
Training loss: 0.0807894048088708
Validation loss: 2.476958924540379

Epoch: 646| Step: 0
Training loss: 0.1420307167492247
Validation loss: 2.4465355025363746

Epoch: 6| Step: 1
Training loss: 0.06386517264894762
Validation loss: 2.462446810873181

Epoch: 6| Step: 2
Training loss: 0.05496151853334256
Validation loss: 2.4694504954471426

Epoch: 6| Step: 3
Training loss: 0.09468999137055836
Validation loss: 2.4541512615563637

Epoch: 6| Step: 4
Training loss: 0.05762323250821641
Validation loss: 2.457968174959475

Epoch: 6| Step: 5
Training loss: 0.08427029554791171
Validation loss: 2.4796191331981916

Epoch: 6| Step: 6
Training loss: 0.14716049560122157
Validation loss: 2.485920960685258

Epoch: 6| Step: 7
Training loss: 0.09236373280934919
Validation loss: 2.475200967842462

Epoch: 6| Step: 8
Training loss: 0.14652319711590714
Validation loss: 2.4640287002722636

Epoch: 6| Step: 9
Training loss: 0.09243788015482163
Validation loss: 2.4893526566024464

Epoch: 6| Step: 10
Training loss: 0.0858564075507333
Validation loss: 2.487385200625452

Epoch: 6| Step: 11
Training loss: 0.13116986888330676
Validation loss: 2.493665059359069

Epoch: 6| Step: 12
Training loss: 0.10732717674837218
Validation loss: 2.4632677750998013

Epoch: 6| Step: 13
Training loss: 0.05844854203681205
Validation loss: 2.496988427885984

Epoch: 647| Step: 0
Training loss: 0.08175195251493278
Validation loss: 2.4853655681702618

Epoch: 6| Step: 1
Training loss: 0.13041788325971213
Validation loss: 2.4571352893824345

Epoch: 6| Step: 2
Training loss: 0.0682166448719178
Validation loss: 2.525837345230601

Epoch: 6| Step: 3
Training loss: 0.12320132628574974
Validation loss: 2.488816341413079

Epoch: 6| Step: 4
Training loss: 0.09569642958283739
Validation loss: 2.4672333718907185

Epoch: 6| Step: 5
Training loss: 0.10129161159928281
Validation loss: 2.4776393073292393

Epoch: 6| Step: 6
Training loss: 0.11401623676037122
Validation loss: 2.4760349693040204

Epoch: 6| Step: 7
Training loss: 0.061641978172248896
Validation loss: 2.4846537485178803

Epoch: 6| Step: 8
Training loss: 0.1187526765320956
Validation loss: 2.458652775572718

Epoch: 6| Step: 9
Training loss: 0.1415748768357966
Validation loss: 2.487440883300696

Epoch: 6| Step: 10
Training loss: 0.07695529397337957
Validation loss: 2.462149293806658

Epoch: 6| Step: 11
Training loss: 0.07696392230467904
Validation loss: 2.4759505563230015

Epoch: 6| Step: 12
Training loss: 0.05828206090835989
Validation loss: 2.479663692200628

Epoch: 6| Step: 13
Training loss: 0.09415809896548379
Validation loss: 2.477473922916261

Epoch: 648| Step: 0
Training loss: 0.08270474251744238
Validation loss: 2.4684399313633447

Epoch: 6| Step: 1
Training loss: 0.06659698792238083
Validation loss: 2.515338498978095

Epoch: 6| Step: 2
Training loss: 0.07848201478328946
Validation loss: 2.481407981317618

Epoch: 6| Step: 3
Training loss: 0.08880801903509557
Validation loss: 2.5200346458854397

Epoch: 6| Step: 4
Training loss: 0.09612822999537704
Validation loss: 2.4853011793935136

Epoch: 6| Step: 5
Training loss: 0.08877009547928205
Validation loss: 2.482300910878962

Epoch: 6| Step: 6
Training loss: 0.16385733173544534
Validation loss: 2.4943096424732185

Epoch: 6| Step: 7
Training loss: 0.08642704203057809
Validation loss: 2.5041465611323224

Epoch: 6| Step: 8
Training loss: 0.07084863295299637
Validation loss: 2.479844919232453

Epoch: 6| Step: 9
Training loss: 0.1849243965831162
Validation loss: 2.4793829805872454

Epoch: 6| Step: 10
Training loss: 0.0870915620278863
Validation loss: 2.4801915767168556

Epoch: 6| Step: 11
Training loss: 0.08006779673890814
Validation loss: 2.476001571815269

Epoch: 6| Step: 12
Training loss: 0.07139041958881832
Validation loss: 2.436330261667796

Epoch: 6| Step: 13
Training loss: 0.13921135746844196
Validation loss: 2.4459392781322706

Epoch: 649| Step: 0
Training loss: 0.08024001620778132
Validation loss: 2.456812138866638

Epoch: 6| Step: 1
Training loss: 0.07547831845883957
Validation loss: 2.469134061905127

Epoch: 6| Step: 2
Training loss: 0.11133715526029134
Validation loss: 2.4960657069679155

Epoch: 6| Step: 3
Training loss: 0.09238791925457492
Validation loss: 2.535308296870527

Epoch: 6| Step: 4
Training loss: 0.05569469295124478
Validation loss: 2.5195352426942295

Epoch: 6| Step: 5
Training loss: 0.16039371331424113
Validation loss: 2.5202705862320394

Epoch: 6| Step: 6
Training loss: 0.12233720213808114
Validation loss: 2.4928651456039668

Epoch: 6| Step: 7
Training loss: 0.10306661770271035
Validation loss: 2.471398697648801

Epoch: 6| Step: 8
Training loss: 0.14304240940109325
Validation loss: 2.458608722087557

Epoch: 6| Step: 9
Training loss: 0.0921334781203789
Validation loss: 2.444358249753044

Epoch: 6| Step: 10
Training loss: 0.08650860885409288
Validation loss: 2.470879882756944

Epoch: 6| Step: 11
Training loss: 0.09249908638515865
Validation loss: 2.418794943035386

Epoch: 6| Step: 12
Training loss: 0.0995422585955319
Validation loss: 2.4112058147760567

Epoch: 6| Step: 13
Training loss: 0.0562503353579114
Validation loss: 2.437117979720879

Epoch: 650| Step: 0
Training loss: 0.1637129807122862
Validation loss: 2.431637834834889

Epoch: 6| Step: 1
Training loss: 0.09382394516915044
Validation loss: 2.4374880668152406

Epoch: 6| Step: 2
Training loss: 0.09187388233718172
Validation loss: 2.4410442954555545

Epoch: 6| Step: 3
Training loss: 0.1132407157002258
Validation loss: 2.4446157583103

Epoch: 6| Step: 4
Training loss: 0.12225280852982456
Validation loss: 2.462078107646865

Epoch: 6| Step: 5
Training loss: 0.0756451570675564
Validation loss: 2.470972064532364

Epoch: 6| Step: 6
Training loss: 0.09915007557476528
Validation loss: 2.4484834408049467

Epoch: 6| Step: 7
Training loss: 0.13026967193331457
Validation loss: 2.4644876499825217

Epoch: 6| Step: 8
Training loss: 0.11343295938820262
Validation loss: 2.467068366450718

Epoch: 6| Step: 9
Training loss: 0.050125444896012616
Validation loss: 2.46599070652818

Epoch: 6| Step: 10
Training loss: 0.14451952835183227
Validation loss: 2.4487528702557126

Epoch: 6| Step: 11
Training loss: 0.05324093478541979
Validation loss: 2.499187253283564

Epoch: 6| Step: 12
Training loss: 0.15742002159523188
Validation loss: 2.4574475813986996

Epoch: 6| Step: 13
Training loss: 0.0672527800068706
Validation loss: 2.5102376154492205

Epoch: 651| Step: 0
Training loss: 0.10587219058653279
Validation loss: 2.4876106053756284

Epoch: 6| Step: 1
Training loss: 0.10036179651839813
Validation loss: 2.468224102999603

Epoch: 6| Step: 2
Training loss: 0.09555333443186521
Validation loss: 2.4372900900579935

Epoch: 6| Step: 3
Training loss: 0.11311427092518557
Validation loss: 2.466745641082126

Epoch: 6| Step: 4
Training loss: 0.07759819634511485
Validation loss: 2.4530520240510856

Epoch: 6| Step: 5
Training loss: 0.06450125674406779
Validation loss: 2.4626094661568407

Epoch: 6| Step: 6
Training loss: 0.16788580975876358
Validation loss: 2.4041010776894938

Epoch: 6| Step: 7
Training loss: 0.12599627761933843
Validation loss: 2.4672466127885313

Epoch: 6| Step: 8
Training loss: 0.10417918537334989
Validation loss: 2.4455962134611973

Epoch: 6| Step: 9
Training loss: 0.12777732920164805
Validation loss: 2.465163648190564

Epoch: 6| Step: 10
Training loss: 0.0708578077393209
Validation loss: 2.486201102186531

Epoch: 6| Step: 11
Training loss: 0.07298151039442315
Validation loss: 2.4817824093193677

Epoch: 6| Step: 12
Training loss: 0.07284525122930516
Validation loss: 2.467575381558687

Epoch: 6| Step: 13
Training loss: 0.06890321072862846
Validation loss: 2.484875383095463

Epoch: 652| Step: 0
Training loss: 0.07688372503366474
Validation loss: 2.4953944175820526

Epoch: 6| Step: 1
Training loss: 0.0902746740163238
Validation loss: 2.5013942276297505

Epoch: 6| Step: 2
Training loss: 0.12022301423780267
Validation loss: 2.4909310547875805

Epoch: 6| Step: 3
Training loss: 0.06872326862229546
Validation loss: 2.50246775665136

Epoch: 6| Step: 4
Training loss: 0.20320523951338493
Validation loss: 2.5141688617590656

Epoch: 6| Step: 5
Training loss: 0.13626671038968377
Validation loss: 2.4879492316698584

Epoch: 6| Step: 6
Training loss: 0.08060049434034319
Validation loss: 2.512282824243206

Epoch: 6| Step: 7
Training loss: 0.13336112504513659
Validation loss: 2.471208704495718

Epoch: 6| Step: 8
Training loss: 0.09528838032259904
Validation loss: 2.4811197940776055

Epoch: 6| Step: 9
Training loss: 0.08816352438435006
Validation loss: 2.4611122153968488

Epoch: 6| Step: 10
Training loss: 0.10027437195530095
Validation loss: 2.4544204103839316

Epoch: 6| Step: 11
Training loss: 0.13035371928935652
Validation loss: 2.4105342137103904

Epoch: 6| Step: 12
Training loss: 0.12723872997087818
Validation loss: 2.431129730503476

Epoch: 6| Step: 13
Training loss: 0.10068283228766638
Validation loss: 2.4493284435593288

Epoch: 653| Step: 0
Training loss: 0.0979320969454476
Validation loss: 2.430004730000567

Epoch: 6| Step: 1
Training loss: 0.08640408647736199
Validation loss: 2.4694294304150235

Epoch: 6| Step: 2
Training loss: 0.07077085257051195
Validation loss: 2.449255964718647

Epoch: 6| Step: 3
Training loss: 0.08067117006240289
Validation loss: 2.499165584407219

Epoch: 6| Step: 4
Training loss: 0.09294226493562233
Validation loss: 2.463664006933936

Epoch: 6| Step: 5
Training loss: 0.08254354454830062
Validation loss: 2.4845268248008128

Epoch: 6| Step: 6
Training loss: 0.17924360718160937
Validation loss: 2.4846357416553464

Epoch: 6| Step: 7
Training loss: 0.0722006847521908
Validation loss: 2.493324372541588

Epoch: 6| Step: 8
Training loss: 0.14522784777086972
Validation loss: 2.491962876510981

Epoch: 6| Step: 9
Training loss: 0.05341829425356928
Validation loss: 2.5070411973954916

Epoch: 6| Step: 10
Training loss: 0.07906162171950301
Validation loss: 2.4497226576736453

Epoch: 6| Step: 11
Training loss: 0.13196105671200226
Validation loss: 2.492209905893413

Epoch: 6| Step: 12
Training loss: 0.11018555738291326
Validation loss: 2.48190640867714

Epoch: 6| Step: 13
Training loss: 0.06899135554281483
Validation loss: 2.452675722802555

Epoch: 654| Step: 0
Training loss: 0.06605643810927957
Validation loss: 2.4515375503615995

Epoch: 6| Step: 1
Training loss: 0.10029141815829237
Validation loss: 2.4810935057497536

Epoch: 6| Step: 2
Training loss: 0.08511440896238642
Validation loss: 2.4548032188057203

Epoch: 6| Step: 3
Training loss: 0.08230738484688488
Validation loss: 2.412318462164211

Epoch: 6| Step: 4
Training loss: 0.11476236999003886
Validation loss: 2.4559285290189186

Epoch: 6| Step: 5
Training loss: 0.0880212978015962
Validation loss: 2.458119900550783

Epoch: 6| Step: 6
Training loss: 0.0502651980494307
Validation loss: 2.5032597813786586

Epoch: 6| Step: 7
Training loss: 0.11653258585400758
Validation loss: 2.467851952356346

Epoch: 6| Step: 8
Training loss: 0.0765311924021774
Validation loss: 2.498723081353988

Epoch: 6| Step: 9
Training loss: 0.09349305486033677
Validation loss: 2.488361843825425

Epoch: 6| Step: 10
Training loss: 0.09080434474242025
Validation loss: 2.4774963030384964

Epoch: 6| Step: 11
Training loss: 0.17349551021156145
Validation loss: 2.465055309284926

Epoch: 6| Step: 12
Training loss: 0.1349092077991819
Validation loss: 2.5241396662451367

Epoch: 6| Step: 13
Training loss: 0.10012573220607948
Validation loss: 2.448656376122506

Epoch: 655| Step: 0
Training loss: 0.06281059545742068
Validation loss: 2.490617193900819

Epoch: 6| Step: 1
Training loss: 0.08720083823432744
Validation loss: 2.441019325753126

Epoch: 6| Step: 2
Training loss: 0.05127340483791573
Validation loss: 2.4639971096014275

Epoch: 6| Step: 3
Training loss: 0.1055280686388354
Validation loss: 2.4688324525749983

Epoch: 6| Step: 4
Training loss: 0.06125631509370598
Validation loss: 2.4688305502217425

Epoch: 6| Step: 5
Training loss: 0.0818777862740848
Validation loss: 2.4549552830686427

Epoch: 6| Step: 6
Training loss: 0.14760586898345235
Validation loss: 2.4145445238393957

Epoch: 6| Step: 7
Training loss: 0.10221965633819705
Validation loss: 2.4366017735689365

Epoch: 6| Step: 8
Training loss: 0.09656308589066222
Validation loss: 2.42453063534484

Epoch: 6| Step: 9
Training loss: 0.08835462373595658
Validation loss: 2.422898440500163

Epoch: 6| Step: 10
Training loss: 0.09415885562785772
Validation loss: 2.464312901337682

Epoch: 6| Step: 11
Training loss: 0.17535208658882354
Validation loss: 2.472234309479822

Epoch: 6| Step: 12
Training loss: 0.07969138332329403
Validation loss: 2.434517781194638

Epoch: 6| Step: 13
Training loss: 0.09702744218477365
Validation loss: 2.4378995544247033

Epoch: 656| Step: 0
Training loss: 0.08175003862762852
Validation loss: 2.422907201455938

Epoch: 6| Step: 1
Training loss: 0.0911965217879434
Validation loss: 2.427445263534072

Epoch: 6| Step: 2
Training loss: 0.10001826510664338
Validation loss: 2.4526519956855237

Epoch: 6| Step: 3
Training loss: 0.13266689369043058
Validation loss: 2.4594088044764444

Epoch: 6| Step: 4
Training loss: 0.13853571479842883
Validation loss: 2.4507455446306223

Epoch: 6| Step: 5
Training loss: 0.08688931702231484
Validation loss: 2.4719418066361754

Epoch: 6| Step: 6
Training loss: 0.10819024635957832
Validation loss: 2.4474392413360904

Epoch: 6| Step: 7
Training loss: 0.10520747724584503
Validation loss: 2.472826491261602

Epoch: 6| Step: 8
Training loss: 0.15372152134521436
Validation loss: 2.4484567183071526

Epoch: 6| Step: 9
Training loss: 0.16783387846248132
Validation loss: 2.4768446025406443

Epoch: 6| Step: 10
Training loss: 0.14409047006263123
Validation loss: 2.4423792709872894

Epoch: 6| Step: 11
Training loss: 0.0879800526987194
Validation loss: 2.443108959751067

Epoch: 6| Step: 12
Training loss: 0.09779429215986539
Validation loss: 2.4943860281051564

Epoch: 6| Step: 13
Training loss: 0.08293940025012596
Validation loss: 2.484846853906389

Epoch: 657| Step: 0
Training loss: 0.137492375270807
Validation loss: 2.448642395004079

Epoch: 6| Step: 1
Training loss: 0.06758628062830387
Validation loss: 2.497748750294414

Epoch: 6| Step: 2
Training loss: 0.11046244527746997
Validation loss: 2.4832931446617827

Epoch: 6| Step: 3
Training loss: 0.11812696978147794
Validation loss: 2.4778927354448075

Epoch: 6| Step: 4
Training loss: 0.11317403422182261
Validation loss: 2.4494423113721377

Epoch: 6| Step: 5
Training loss: 0.07950167657888185
Validation loss: 2.4701706062372817

Epoch: 6| Step: 6
Training loss: 0.08929797965340183
Validation loss: 2.476949080681325

Epoch: 6| Step: 7
Training loss: 0.05600981660945597
Validation loss: 2.471184225800767

Epoch: 6| Step: 8
Training loss: 0.09000943290100154
Validation loss: 2.502121464127272

Epoch: 6| Step: 9
Training loss: 0.14126555598733753
Validation loss: 2.5013207781904243

Epoch: 6| Step: 10
Training loss: 0.07331540898168108
Validation loss: 2.4850240457953996

Epoch: 6| Step: 11
Training loss: 0.09479900421661289
Validation loss: 2.4901114749842166

Epoch: 6| Step: 12
Training loss: 0.09153754553368527
Validation loss: 2.487221856762016

Epoch: 6| Step: 13
Training loss: 0.15155010860952717
Validation loss: 2.505621081077504

Epoch: 658| Step: 0
Training loss: 0.13138038199205015
Validation loss: 2.484336318715032

Epoch: 6| Step: 1
Training loss: 0.07697538087906414
Validation loss: 2.516480579788705

Epoch: 6| Step: 2
Training loss: 0.11657945321086585
Validation loss: 2.447660808680026

Epoch: 6| Step: 3
Training loss: 0.16292081685727314
Validation loss: 2.4950465812973373

Epoch: 6| Step: 4
Training loss: 0.09737593473896629
Validation loss: 2.4457664420923417

Epoch: 6| Step: 5
Training loss: 0.136820537278777
Validation loss: 2.458728208646694

Epoch: 6| Step: 6
Training loss: 0.11161222514433657
Validation loss: 2.460947754801609

Epoch: 6| Step: 7
Training loss: 0.08146543300015885
Validation loss: 2.4619978696403835

Epoch: 6| Step: 8
Training loss: 0.08188198906064356
Validation loss: 2.4431308792192064

Epoch: 6| Step: 9
Training loss: 0.10058361347069139
Validation loss: 2.4362582768938528

Epoch: 6| Step: 10
Training loss: 0.10459346408793518
Validation loss: 2.4646018061156525

Epoch: 6| Step: 11
Training loss: 0.08405533276992856
Validation loss: 2.454740412648671

Epoch: 6| Step: 12
Training loss: 0.08340345229140711
Validation loss: 2.466267425928098

Epoch: 6| Step: 13
Training loss: 0.07377405015427857
Validation loss: 2.4874717691424917

Epoch: 659| Step: 0
Training loss: 0.060715776248813004
Validation loss: 2.4976069759233193

Epoch: 6| Step: 1
Training loss: 0.14578209697890296
Validation loss: 2.494247387085132

Epoch: 6| Step: 2
Training loss: 0.07545996205084203
Validation loss: 2.4920999693745314

Epoch: 6| Step: 3
Training loss: 0.09739705975758238
Validation loss: 2.4666529583847994

Epoch: 6| Step: 4
Training loss: 0.11846412439329476
Validation loss: 2.462240685251177

Epoch: 6| Step: 5
Training loss: 0.0740660017881792
Validation loss: 2.4569314508965925

Epoch: 6| Step: 6
Training loss: 0.06355379980882324
Validation loss: 2.4596928035040477

Epoch: 6| Step: 7
Training loss: 0.07884165957677501
Validation loss: 2.447802597317043

Epoch: 6| Step: 8
Training loss: 0.09873077513272735
Validation loss: 2.4587473655367225

Epoch: 6| Step: 9
Training loss: 0.1727925269827419
Validation loss: 2.4544420857396827

Epoch: 6| Step: 10
Training loss: 0.1009979420944455
Validation loss: 2.4666693608713555

Epoch: 6| Step: 11
Training loss: 0.10715785526492769
Validation loss: 2.4562806826702035

Epoch: 6| Step: 12
Training loss: 0.11775292444065
Validation loss: 2.4613290157904633

Epoch: 6| Step: 13
Training loss: 0.0521178096667771
Validation loss: 2.436104266803445

Epoch: 660| Step: 0
Training loss: 0.07145691406719183
Validation loss: 2.4752353403851926

Epoch: 6| Step: 1
Training loss: 0.0957961117289855
Validation loss: 2.4896204053174937

Epoch: 6| Step: 2
Training loss: 0.09897225108486993
Validation loss: 2.512076063842236

Epoch: 6| Step: 3
Training loss: 0.09222784735411929
Validation loss: 2.5002728180050595

Epoch: 6| Step: 4
Training loss: 0.1119996530807393
Validation loss: 2.5197344094631298

Epoch: 6| Step: 5
Training loss: 0.07409339281613071
Validation loss: 2.496058058346723

Epoch: 6| Step: 6
Training loss: 0.09449938441951516
Validation loss: 2.5080982539074728

Epoch: 6| Step: 7
Training loss: 0.11815715012942733
Validation loss: 2.5307306951823003

Epoch: 6| Step: 8
Training loss: 0.0545129160611165
Validation loss: 2.522963896175598

Epoch: 6| Step: 9
Training loss: 0.10003656057992516
Validation loss: 2.515052117198104

Epoch: 6| Step: 10
Training loss: 0.05539908836766749
Validation loss: 2.496443520914715

Epoch: 6| Step: 11
Training loss: 0.18158989885060906
Validation loss: 2.460865027628047

Epoch: 6| Step: 12
Training loss: 0.0874613610598559
Validation loss: 2.475621417918875

Epoch: 6| Step: 13
Training loss: 0.08625677254078155
Validation loss: 2.485031050594975

Epoch: 661| Step: 0
Training loss: 0.13612974538317058
Validation loss: 2.457605512995668

Epoch: 6| Step: 1
Training loss: 0.09681236911257521
Validation loss: 2.4547143452039473

Epoch: 6| Step: 2
Training loss: 0.07282012767500229
Validation loss: 2.4587819910308237

Epoch: 6| Step: 3
Training loss: 0.08412062881089702
Validation loss: 2.4849255102100307

Epoch: 6| Step: 4
Training loss: 0.0836246877756762
Validation loss: 2.4766088406138964

Epoch: 6| Step: 5
Training loss: 0.12993657283030147
Validation loss: 2.4643381244790743

Epoch: 6| Step: 6
Training loss: 0.0804187693510405
Validation loss: 2.497436375973087

Epoch: 6| Step: 7
Training loss: 0.08800171348426884
Validation loss: 2.5027475302653794

Epoch: 6| Step: 8
Training loss: 0.08796445341865117
Validation loss: 2.460044748651442

Epoch: 6| Step: 9
Training loss: 0.09346198006086479
Validation loss: 2.4857033286866925

Epoch: 6| Step: 10
Training loss: 0.13155326208269733
Validation loss: 2.4794805758346286

Epoch: 6| Step: 11
Training loss: 0.1286226968642473
Validation loss: 2.4898529253447914

Epoch: 6| Step: 12
Training loss: 0.09810621548003358
Validation loss: 2.4646131258976465

Epoch: 6| Step: 13
Training loss: 0.11813084474363605
Validation loss: 2.4841160483522313

Epoch: 662| Step: 0
Training loss: 0.07103305075133845
Validation loss: 2.4670552170806013

Epoch: 6| Step: 1
Training loss: 0.07895197676475377
Validation loss: 2.484793852349733

Epoch: 6| Step: 2
Training loss: 0.06721411887424421
Validation loss: 2.4740954465493683

Epoch: 6| Step: 3
Training loss: 0.15797505599131242
Validation loss: 2.4675188952709313

Epoch: 6| Step: 4
Training loss: 0.13840340429099257
Validation loss: 2.4881066078662957

Epoch: 6| Step: 5
Training loss: 0.05450750429652155
Validation loss: 2.460542514900056

Epoch: 6| Step: 6
Training loss: 0.07508173948750957
Validation loss: 2.4689686134402895

Epoch: 6| Step: 7
Training loss: 0.08542401078196782
Validation loss: 2.461689081257083

Epoch: 6| Step: 8
Training loss: 0.07389889988027146
Validation loss: 2.477065375909546

Epoch: 6| Step: 9
Training loss: 0.08086950047531191
Validation loss: 2.4509100836586915

Epoch: 6| Step: 10
Training loss: 0.07101266659658505
Validation loss: 2.4549481830542326

Epoch: 6| Step: 11
Training loss: 0.10746960879873174
Validation loss: 2.482053146795842

Epoch: 6| Step: 12
Training loss: 0.07300481477831694
Validation loss: 2.450090932382849

Epoch: 6| Step: 13
Training loss: 0.060582967352726405
Validation loss: 2.4770690869813694

Epoch: 663| Step: 0
Training loss: 0.14586177758565838
Validation loss: 2.4717593042133013

Epoch: 6| Step: 1
Training loss: 0.10731715386474316
Validation loss: 2.4787169712420263

Epoch: 6| Step: 2
Training loss: 0.11442033506308116
Validation loss: 2.473945064455123

Epoch: 6| Step: 3
Training loss: 0.08072497917153906
Validation loss: 2.4934216282541

Epoch: 6| Step: 4
Training loss: 0.14125296335361098
Validation loss: 2.4847464696187123

Epoch: 6| Step: 5
Training loss: 0.08724033802569563
Validation loss: 2.4801857428107574

Epoch: 6| Step: 6
Training loss: 0.0910759425138191
Validation loss: 2.506560495507833

Epoch: 6| Step: 7
Training loss: 0.06632829044936969
Validation loss: 2.477109540744825

Epoch: 6| Step: 8
Training loss: 0.04652049450490062
Validation loss: 2.4878021130254946

Epoch: 6| Step: 9
Training loss: 0.1065329881813314
Validation loss: 2.4957708478277354

Epoch: 6| Step: 10
Training loss: 0.07590139490276288
Validation loss: 2.467637543136104

Epoch: 6| Step: 11
Training loss: 0.0788677639866959
Validation loss: 2.4832118267745606

Epoch: 6| Step: 12
Training loss: 0.06712882229775048
Validation loss: 2.4953709456320263

Epoch: 6| Step: 13
Training loss: 0.08190205595644819
Validation loss: 2.46951081284544

Epoch: 664| Step: 0
Training loss: 0.08722776153755087
Validation loss: 2.4749723685023044

Epoch: 6| Step: 1
Training loss: 0.08672370316561803
Validation loss: 2.4748441423564294

Epoch: 6| Step: 2
Training loss: 0.10909155323403281
Validation loss: 2.5054668458315725

Epoch: 6| Step: 3
Training loss: 0.11758175334211335
Validation loss: 2.479933246805117

Epoch: 6| Step: 4
Training loss: 0.14498276677983327
Validation loss: 2.47989078189934

Epoch: 6| Step: 5
Training loss: 0.09636112673425834
Validation loss: 2.4871562152334197

Epoch: 6| Step: 6
Training loss: 0.11837781535862106
Validation loss: 2.5023676448568875

Epoch: 6| Step: 7
Training loss: 0.0855320882864177
Validation loss: 2.4796762629486584

Epoch: 6| Step: 8
Training loss: 0.03928916258238832
Validation loss: 2.482216400110732

Epoch: 6| Step: 9
Training loss: 0.062034728444554786
Validation loss: 2.4633097668360446

Epoch: 6| Step: 10
Training loss: 0.10423657535088432
Validation loss: 2.454611250760743

Epoch: 6| Step: 11
Training loss: 0.14910139142317197
Validation loss: 2.475890195968813

Epoch: 6| Step: 12
Training loss: 0.04659910019255392
Validation loss: 2.456021185326187

Epoch: 6| Step: 13
Training loss: 0.10402120079274478
Validation loss: 2.453214510116819

Epoch: 665| Step: 0
Training loss: 0.11934928913002636
Validation loss: 2.500570373688945

Epoch: 6| Step: 1
Training loss: 0.14314369483523298
Validation loss: 2.472110650966718

Epoch: 6| Step: 2
Training loss: 0.07456214106166392
Validation loss: 2.455449020484334

Epoch: 6| Step: 3
Training loss: 0.14477956550329604
Validation loss: 2.4462899868104784

Epoch: 6| Step: 4
Training loss: 0.12595309549039574
Validation loss: 2.484422176215256

Epoch: 6| Step: 5
Training loss: 0.047708760512791076
Validation loss: 2.4661780111826714

Epoch: 6| Step: 6
Training loss: 0.10028401216891428
Validation loss: 2.487287854210235

Epoch: 6| Step: 7
Training loss: 0.056776196914706485
Validation loss: 2.4640079530410604

Epoch: 6| Step: 8
Training loss: 0.10177624658122422
Validation loss: 2.4429640149546006

Epoch: 6| Step: 9
Training loss: 0.07646454924311138
Validation loss: 2.4609596414216193

Epoch: 6| Step: 10
Training loss: 0.093315233984203
Validation loss: 2.4652659290596497

Epoch: 6| Step: 11
Training loss: 0.03298038035433665
Validation loss: 2.471764449620434

Epoch: 6| Step: 12
Training loss: 0.09995868619207508
Validation loss: 2.473135979873516

Epoch: 6| Step: 13
Training loss: 0.0666083458273526
Validation loss: 2.4426624613800842

Epoch: 666| Step: 0
Training loss: 0.09670194697128662
Validation loss: 2.473268197153899

Epoch: 6| Step: 1
Training loss: 0.0869564692307429
Validation loss: 2.469563572491419

Epoch: 6| Step: 2
Training loss: 0.0630352155901801
Validation loss: 2.4614533091671285

Epoch: 6| Step: 3
Training loss: 0.0694173046647209
Validation loss: 2.4852675123794357

Epoch: 6| Step: 4
Training loss: 0.15785457928216656
Validation loss: 2.465764045930286

Epoch: 6| Step: 5
Training loss: 0.14943414440958508
Validation loss: 2.4790384535719046

Epoch: 6| Step: 6
Training loss: 0.08085478122304059
Validation loss: 2.476188324217474

Epoch: 6| Step: 7
Training loss: 0.07301161394381653
Validation loss: 2.4620208371491867

Epoch: 6| Step: 8
Training loss: 0.12020414197871626
Validation loss: 2.4508966112011095

Epoch: 6| Step: 9
Training loss: 0.08633764266284949
Validation loss: 2.4333226726105726

Epoch: 6| Step: 10
Training loss: 0.08840303460480317
Validation loss: 2.4829266924302447

Epoch: 6| Step: 11
Training loss: 0.07402597035526011
Validation loss: 2.466192798306125

Epoch: 6| Step: 12
Training loss: 0.07254297927898273
Validation loss: 2.4561713163006567

Epoch: 6| Step: 13
Training loss: 0.0738634243343968
Validation loss: 2.4611573230014665

Epoch: 667| Step: 0
Training loss: 0.07352121608565498
Validation loss: 2.469670699455534

Epoch: 6| Step: 1
Training loss: 0.0894970735925277
Validation loss: 2.4543385704028453

Epoch: 6| Step: 2
Training loss: 0.16364693804484787
Validation loss: 2.439673547183718

Epoch: 6| Step: 3
Training loss: 0.10686949110612438
Validation loss: 2.4445405934492532

Epoch: 6| Step: 4
Training loss: 0.09857370947488404
Validation loss: 2.495594151892648

Epoch: 6| Step: 5
Training loss: 0.0806839172644906
Validation loss: 2.462068100165727

Epoch: 6| Step: 6
Training loss: 0.11385024976958434
Validation loss: 2.469979038544818

Epoch: 6| Step: 7
Training loss: 0.07784502406783256
Validation loss: 2.465011270381615

Epoch: 6| Step: 8
Training loss: 0.08978203540495644
Validation loss: 2.437784779385663

Epoch: 6| Step: 9
Training loss: 0.106070361199824
Validation loss: 2.43491345242863

Epoch: 6| Step: 10
Training loss: 0.08130097601175383
Validation loss: 2.4495721414119953

Epoch: 6| Step: 11
Training loss: 0.09080852411529776
Validation loss: 2.4172610114984736

Epoch: 6| Step: 12
Training loss: 0.09101194243287151
Validation loss: 2.4493621759578974

Epoch: 6| Step: 13
Training loss: 0.08537952305553989
Validation loss: 2.4827467652697557

Epoch: 668| Step: 0
Training loss: 0.06209632028578921
Validation loss: 2.437483537953343

Epoch: 6| Step: 1
Training loss: 0.08463977258428013
Validation loss: 2.437900355726726

Epoch: 6| Step: 2
Training loss: 0.08453012727460742
Validation loss: 2.4598486717490413

Epoch: 6| Step: 3
Training loss: 0.10052374426262096
Validation loss: 2.499351042431398

Epoch: 6| Step: 4
Training loss: 0.07187320833979248
Validation loss: 2.4797083145009187

Epoch: 6| Step: 5
Training loss: 0.12740451088664098
Validation loss: 2.4639966845817365

Epoch: 6| Step: 6
Training loss: 0.1512195359241348
Validation loss: 2.48933225122372

Epoch: 6| Step: 7
Training loss: 0.052211357762301944
Validation loss: 2.505398200215403

Epoch: 6| Step: 8
Training loss: 0.1284169171656497
Validation loss: 2.518950964064944

Epoch: 6| Step: 9
Training loss: 0.10209528395303441
Validation loss: 2.4939574845411094

Epoch: 6| Step: 10
Training loss: 0.12611204447146476
Validation loss: 2.4822939613742068

Epoch: 6| Step: 11
Training loss: 0.10803839886807921
Validation loss: 2.4745217597615747

Epoch: 6| Step: 12
Training loss: 0.08498609378691127
Validation loss: 2.4305060473515945

Epoch: 6| Step: 13
Training loss: 0.10026389483409126
Validation loss: 2.4157459328256516

Epoch: 669| Step: 0
Training loss: 0.16728694734432906
Validation loss: 2.4614115044815548

Epoch: 6| Step: 1
Training loss: 0.05488107685317675
Validation loss: 2.4319527316481127

Epoch: 6| Step: 2
Training loss: 0.09182034861968749
Validation loss: 2.4065295087580756

Epoch: 6| Step: 3
Training loss: 0.11242710159033818
Validation loss: 2.4382978552876793

Epoch: 6| Step: 4
Training loss: 0.07227717771203376
Validation loss: 2.4399456274240485

Epoch: 6| Step: 5
Training loss: 0.09720235244990945
Validation loss: 2.4435469634381817

Epoch: 6| Step: 6
Training loss: 0.050291783587370666
Validation loss: 2.4716879374215766

Epoch: 6| Step: 7
Training loss: 0.11945760880058069
Validation loss: 2.4595036530503926

Epoch: 6| Step: 8
Training loss: 0.11772496632000143
Validation loss: 2.4779732150394485

Epoch: 6| Step: 9
Training loss: 0.07521081739816084
Validation loss: 2.477230074305596

Epoch: 6| Step: 10
Training loss: 0.09800969535962104
Validation loss: 2.5517525732098236

Epoch: 6| Step: 11
Training loss: 0.15780367873814774
Validation loss: 2.539765280368043

Epoch: 6| Step: 12
Training loss: 0.1226350728055291
Validation loss: 2.5242460745929973

Epoch: 6| Step: 13
Training loss: 0.08343992240028913
Validation loss: 2.502822421020921

Epoch: 670| Step: 0
Training loss: 0.11482187163278185
Validation loss: 2.5512553743955952

Epoch: 6| Step: 1
Training loss: 0.09725423558512619
Validation loss: 2.50527448304401

Epoch: 6| Step: 2
Training loss: 0.09478916970132721
Validation loss: 2.5141446534863943

Epoch: 6| Step: 3
Training loss: 0.15286302099994611
Validation loss: 2.519804454127123

Epoch: 6| Step: 4
Training loss: 0.08169450214148602
Validation loss: 2.473057571613908

Epoch: 6| Step: 5
Training loss: 0.07046802195788268
Validation loss: 2.455254364142542

Epoch: 6| Step: 6
Training loss: 0.14239823737925442
Validation loss: 2.457038332517796

Epoch: 6| Step: 7
Training loss: 0.09815215560373411
Validation loss: 2.4482563164548306

Epoch: 6| Step: 8
Training loss: 0.08555957752138191
Validation loss: 2.458201422227752

Epoch: 6| Step: 9
Training loss: 0.08299203610561279
Validation loss: 2.445992860117746

Epoch: 6| Step: 10
Training loss: 0.07860760342488399
Validation loss: 2.448400350072718

Epoch: 6| Step: 11
Training loss: 0.07420167601097007
Validation loss: 2.4724131943595262

Epoch: 6| Step: 12
Training loss: 0.1302416083415844
Validation loss: 2.5001261422932783

Epoch: 6| Step: 13
Training loss: 0.06383648945386897
Validation loss: 2.4744207281467263

Epoch: 671| Step: 0
Training loss: 0.04660525292958937
Validation loss: 2.475863366486421

Epoch: 6| Step: 1
Training loss: 0.06087930235551824
Validation loss: 2.4716930010384566

Epoch: 6| Step: 2
Training loss: 0.10585493451479201
Validation loss: 2.4831926650441405

Epoch: 6| Step: 3
Training loss: 0.09636899849002191
Validation loss: 2.499195670899971

Epoch: 6| Step: 4
Training loss: 0.09355091772269017
Validation loss: 2.4903734772236117

Epoch: 6| Step: 5
Training loss: 0.12397357734409875
Validation loss: 2.52649486871128

Epoch: 6| Step: 6
Training loss: 0.11682706079206231
Validation loss: 2.5142033653590006

Epoch: 6| Step: 7
Training loss: 0.08927106779743564
Validation loss: 2.520691730288686

Epoch: 6| Step: 8
Training loss: 0.12244196201769714
Validation loss: 2.492508328988219

Epoch: 6| Step: 9
Training loss: 0.1284519484205875
Validation loss: 2.487763022590416

Epoch: 6| Step: 10
Training loss: 0.08200761477255862
Validation loss: 2.511298593947389

Epoch: 6| Step: 11
Training loss: 0.07368762938048869
Validation loss: 2.4771486795047535

Epoch: 6| Step: 12
Training loss: 0.06632661602631255
Validation loss: 2.4665473612585163

Epoch: 6| Step: 13
Training loss: 0.07801572787222487
Validation loss: 2.479585996967602

Epoch: 672| Step: 0
Training loss: 0.09493633030685042
Validation loss: 2.4789271536705204

Epoch: 6| Step: 1
Training loss: 0.1151490299544262
Validation loss: 2.4405907597203425

Epoch: 6| Step: 2
Training loss: 0.11397618855917009
Validation loss: 2.500438363087172

Epoch: 6| Step: 3
Training loss: 0.07545483379913452
Validation loss: 2.4931243011188426

Epoch: 6| Step: 4
Training loss: 0.06319943602350302
Validation loss: 2.5002553112141452

Epoch: 6| Step: 5
Training loss: 0.12310600373849244
Validation loss: 2.497064518027789

Epoch: 6| Step: 6
Training loss: 0.1601428282161211
Validation loss: 2.512232001601564

Epoch: 6| Step: 7
Training loss: 0.10083550907315017
Validation loss: 2.4959692670982583

Epoch: 6| Step: 8
Training loss: 0.09377895841782731
Validation loss: 2.493563612315028

Epoch: 6| Step: 9
Training loss: 0.07322599549920027
Validation loss: 2.5151424384601695

Epoch: 6| Step: 10
Training loss: 0.0639318679664748
Validation loss: 2.5163746040974826

Epoch: 6| Step: 11
Training loss: 0.12825640243774772
Validation loss: 2.4845990764651043

Epoch: 6| Step: 12
Training loss: 0.11537510554447285
Validation loss: 2.5012480040827185

Epoch: 6| Step: 13
Training loss: 0.07173208509565504
Validation loss: 2.486601583179018

Epoch: 673| Step: 0
Training loss: 0.06492091694617277
Validation loss: 2.4929347749444597

Epoch: 6| Step: 1
Training loss: 0.060860255462119615
Validation loss: 2.5105105003725874

Epoch: 6| Step: 2
Training loss: 0.12135904615099082
Validation loss: 2.5200136588221764

Epoch: 6| Step: 3
Training loss: 0.09113337284018881
Validation loss: 2.520705031083612

Epoch: 6| Step: 4
Training loss: 0.13674070999348958
Validation loss: 2.4919932773179228

Epoch: 6| Step: 5
Training loss: 0.04603052156817908
Validation loss: 2.470097080960167

Epoch: 6| Step: 6
Training loss: 0.05969486933484907
Validation loss: 2.470614782885409

Epoch: 6| Step: 7
Training loss: 0.14303855494705484
Validation loss: 2.4569472870114013

Epoch: 6| Step: 8
Training loss: 0.09964111233909557
Validation loss: 2.483365027547579

Epoch: 6| Step: 9
Training loss: 0.05498720961150662
Validation loss: 2.467311703397935

Epoch: 6| Step: 10
Training loss: 0.11465855363734254
Validation loss: 2.4357264892352006

Epoch: 6| Step: 11
Training loss: 0.12478188767617736
Validation loss: 2.461158169854879

Epoch: 6| Step: 12
Training loss: 0.11461643441684603
Validation loss: 2.4926900455648084

Epoch: 6| Step: 13
Training loss: 0.05458466832872231
Validation loss: 2.4711450039857077

Epoch: 674| Step: 0
Training loss: 0.05921917556305313
Validation loss: 2.4878756068420755

Epoch: 6| Step: 1
Training loss: 0.08461022888643871
Validation loss: 2.4801822346047713

Epoch: 6| Step: 2
Training loss: 0.0963013838415426
Validation loss: 2.5051984805767695

Epoch: 6| Step: 3
Training loss: 0.0795827698635622
Validation loss: 2.4585782911569845

Epoch: 6| Step: 4
Training loss: 0.059717317455702
Validation loss: 2.476469050122935

Epoch: 6| Step: 5
Training loss: 0.07041539504710687
Validation loss: 2.4776776099648243

Epoch: 6| Step: 6
Training loss: 0.08036616902425901
Validation loss: 2.461572737840674

Epoch: 6| Step: 7
Training loss: 0.15024645818758314
Validation loss: 2.4711783944908774

Epoch: 6| Step: 8
Training loss: 0.11460708964330937
Validation loss: 2.473043518008668

Epoch: 6| Step: 9
Training loss: 0.07799999846441621
Validation loss: 2.5084737629722107

Epoch: 6| Step: 10
Training loss: 0.1081479202009573
Validation loss: 2.4702002389719646

Epoch: 6| Step: 11
Training loss: 0.11919182709013991
Validation loss: 2.4809261237212117

Epoch: 6| Step: 12
Training loss: 0.05635221816559003
Validation loss: 2.45449285474839

Epoch: 6| Step: 13
Training loss: 0.1074954301256437
Validation loss: 2.476312956720024

Epoch: 675| Step: 0
Training loss: 0.08312564228462237
Validation loss: 2.4454986995165946

Epoch: 6| Step: 1
Training loss: 0.0850313733251407
Validation loss: 2.4574048343414963

Epoch: 6| Step: 2
Training loss: 0.07979100204772811
Validation loss: 2.4694758560913908

Epoch: 6| Step: 3
Training loss: 0.17608643635926635
Validation loss: 2.488187468535768

Epoch: 6| Step: 4
Training loss: 0.12064916382896858
Validation loss: 2.4922778629813296

Epoch: 6| Step: 5
Training loss: 0.0981644235445693
Validation loss: 2.480690889211615

Epoch: 6| Step: 6
Training loss: 0.08350461503655233
Validation loss: 2.4084601329055197

Epoch: 6| Step: 7
Training loss: 0.06277316346194753
Validation loss: 2.47932042173944

Epoch: 6| Step: 8
Training loss: 0.060117485279265345
Validation loss: 2.474889036972409

Epoch: 6| Step: 9
Training loss: 0.09457878501847075
Validation loss: 2.498971311111509

Epoch: 6| Step: 10
Training loss: 0.08713275741004896
Validation loss: 2.4793266774884515

Epoch: 6| Step: 11
Training loss: 0.07403634897323047
Validation loss: 2.457293463790484

Epoch: 6| Step: 12
Training loss: 0.05252037292024514
Validation loss: 2.464796264580023

Epoch: 6| Step: 13
Training loss: 0.1518436623549694
Validation loss: 2.4935241369535386

Epoch: 676| Step: 0
Training loss: 0.07427546567746814
Validation loss: 2.4789628365342637

Epoch: 6| Step: 1
Training loss: 0.10233493650502927
Validation loss: 2.485687750032273

Epoch: 6| Step: 2
Training loss: 0.05848211342693585
Validation loss: 2.478030928976861

Epoch: 6| Step: 3
Training loss: 0.04429906612187833
Validation loss: 2.5081378300359107

Epoch: 6| Step: 4
Training loss: 0.08165694739791754
Validation loss: 2.4856509714379413

Epoch: 6| Step: 5
Training loss: 0.08138078562213863
Validation loss: 2.509527636618144

Epoch: 6| Step: 6
Training loss: 0.12059747229256175
Validation loss: 2.4840597224953944

Epoch: 6| Step: 7
Training loss: 0.06479076970127068
Validation loss: 2.518495845997581

Epoch: 6| Step: 8
Training loss: 0.0715970675404542
Validation loss: 2.500501545464434

Epoch: 6| Step: 9
Training loss: 0.08230642588010256
Validation loss: 2.5034728355426497

Epoch: 6| Step: 10
Training loss: 0.1561665968029252
Validation loss: 2.5083566552616725

Epoch: 6| Step: 11
Training loss: 0.09042412985908257
Validation loss: 2.5092194734274766

Epoch: 6| Step: 12
Training loss: 0.0782287028591428
Validation loss: 2.5006886200390217

Epoch: 6| Step: 13
Training loss: 0.048552064138084855
Validation loss: 2.488369259570785

Epoch: 677| Step: 0
Training loss: 0.07600048848064979
Validation loss: 2.5032321699030597

Epoch: 6| Step: 1
Training loss: 0.11529883101453638
Validation loss: 2.4891073793391714

Epoch: 6| Step: 2
Training loss: 0.15197171119638284
Validation loss: 2.479469382863564

Epoch: 6| Step: 3
Training loss: 0.06471261616101964
Validation loss: 2.49869222583219

Epoch: 6| Step: 4
Training loss: 0.12016124615122718
Validation loss: 2.5085111895805903

Epoch: 6| Step: 5
Training loss: 0.056177007400243395
Validation loss: 2.4999519097409686

Epoch: 6| Step: 6
Training loss: 0.1106461921291152
Validation loss: 2.5030803735485603

Epoch: 6| Step: 7
Training loss: 0.06673065355187444
Validation loss: 2.495254083944507

Epoch: 6| Step: 8
Training loss: 0.07568703920458789
Validation loss: 2.497028083589692

Epoch: 6| Step: 9
Training loss: 0.07576533794486369
Validation loss: 2.502258274487628

Epoch: 6| Step: 10
Training loss: 0.09488153071222831
Validation loss: 2.5258082246549565

Epoch: 6| Step: 11
Training loss: 0.06903020182280468
Validation loss: 2.5187301533585145

Epoch: 6| Step: 12
Training loss: 0.061977440829384396
Validation loss: 2.4894336256056935

Epoch: 6| Step: 13
Training loss: 0.0550920137520205
Validation loss: 2.4898601132189273

Epoch: 678| Step: 0
Training loss: 0.13504168665959437
Validation loss: 2.523845513011227

Epoch: 6| Step: 1
Training loss: 0.08197533313851345
Validation loss: 2.5582384539296257

Epoch: 6| Step: 2
Training loss: 0.10618061875274634
Validation loss: 2.494256277723683

Epoch: 6| Step: 3
Training loss: 0.08423550894633307
Validation loss: 2.499324766872492

Epoch: 6| Step: 4
Training loss: 0.07402991125640261
Validation loss: 2.5151945232558686

Epoch: 6| Step: 5
Training loss: 0.08216307186843644
Validation loss: 2.493952162885944

Epoch: 6| Step: 6
Training loss: 0.11478094423935169
Validation loss: 2.4934191452423433

Epoch: 6| Step: 7
Training loss: 0.0990940395322123
Validation loss: 2.498189076447406

Epoch: 6| Step: 8
Training loss: 0.07679298458936498
Validation loss: 2.473627165739545

Epoch: 6| Step: 9
Training loss: 0.1022512711504826
Validation loss: 2.514618403359633

Epoch: 6| Step: 10
Training loss: 0.12759236277915303
Validation loss: 2.5077865129510246

Epoch: 6| Step: 11
Training loss: 0.11816586343322891
Validation loss: 2.504117283523487

Epoch: 6| Step: 12
Training loss: 0.15589013381747568
Validation loss: 2.484942025241468

Epoch: 6| Step: 13
Training loss: 0.045076849273136495
Validation loss: 2.4731091495370356

Epoch: 679| Step: 0
Training loss: 0.05145571372536805
Validation loss: 2.4882543346703203

Epoch: 6| Step: 1
Training loss: 0.05702240504628775
Validation loss: 2.519605117888967

Epoch: 6| Step: 2
Training loss: 0.07693167910453483
Validation loss: 2.504024473452356

Epoch: 6| Step: 3
Training loss: 0.11178057317152933
Validation loss: 2.463467725348169

Epoch: 6| Step: 4
Training loss: 0.08727096027757902
Validation loss: 2.5065907652939616

Epoch: 6| Step: 5
Training loss: 0.13484859676645838
Validation loss: 2.487526695482124

Epoch: 6| Step: 6
Training loss: 0.0749446729395942
Validation loss: 2.506823420111346

Epoch: 6| Step: 7
Training loss: 0.13497989317161746
Validation loss: 2.497042775290523

Epoch: 6| Step: 8
Training loss: 0.08706206140147556
Validation loss: 2.4849674238003154

Epoch: 6| Step: 9
Training loss: 0.09580397158257807
Validation loss: 2.4772777813856606

Epoch: 6| Step: 10
Training loss: 0.1046866363518234
Validation loss: 2.4542364587910335

Epoch: 6| Step: 11
Training loss: 0.050105718517922566
Validation loss: 2.4240571310042967

Epoch: 6| Step: 12
Training loss: 0.08599331517076683
Validation loss: 2.4368116176097634

Epoch: 6| Step: 13
Training loss: 0.12938773659194427
Validation loss: 2.4224178969346264

Epoch: 680| Step: 0
Training loss: 0.08655968223385592
Validation loss: 2.4579991495345963

Epoch: 6| Step: 1
Training loss: 0.09855114983776218
Validation loss: 2.4356494796461505

Epoch: 6| Step: 2
Training loss: 0.06271259464803658
Validation loss: 2.451378384398505

Epoch: 6| Step: 3
Training loss: 0.09897808507340936
Validation loss: 2.435973069630233

Epoch: 6| Step: 4
Training loss: 0.10268226342568076
Validation loss: 2.4270195630240323

Epoch: 6| Step: 5
Training loss: 0.09682158932059029
Validation loss: 2.4479650600435026

Epoch: 6| Step: 6
Training loss: 0.1263241887821103
Validation loss: 2.4733466484887345

Epoch: 6| Step: 7
Training loss: 0.11519313332872429
Validation loss: 2.4778815709952635

Epoch: 6| Step: 8
Training loss: 0.1721376125082139
Validation loss: 2.488443059353262

Epoch: 6| Step: 9
Training loss: 0.15160308422336316
Validation loss: 2.482841097108816

Epoch: 6| Step: 10
Training loss: 0.05378463847085445
Validation loss: 2.4890878278398194

Epoch: 6| Step: 11
Training loss: 0.07283302459898691
Validation loss: 2.489155587450324

Epoch: 6| Step: 12
Training loss: 0.07574840969636862
Validation loss: 2.467474079548041

Epoch: 6| Step: 13
Training loss: 0.11095892185587392
Validation loss: 2.4607758504915376

Epoch: 681| Step: 0
Training loss: 0.07458750818775785
Validation loss: 2.4985118497591285

Epoch: 6| Step: 1
Training loss: 0.09554514691559443
Validation loss: 2.485016100121081

Epoch: 6| Step: 2
Training loss: 0.06755065745630945
Validation loss: 2.4563129768813843

Epoch: 6| Step: 3
Training loss: 0.15454090112377583
Validation loss: 2.4519050417137045

Epoch: 6| Step: 4
Training loss: 0.0811559435324892
Validation loss: 2.4334570288421262

Epoch: 6| Step: 5
Training loss: 0.2671218099765116
Validation loss: 2.428697768346443

Epoch: 6| Step: 6
Training loss: 0.10468535972656348
Validation loss: 2.456964802927258

Epoch: 6| Step: 7
Training loss: 0.07667743281655892
Validation loss: 2.4591514667923837

Epoch: 6| Step: 8
Training loss: 0.10130138025146064
Validation loss: 2.4127481340933845

Epoch: 6| Step: 9
Training loss: 0.13481403946251772
Validation loss: 2.4713750828601584

Epoch: 6| Step: 10
Training loss: 0.10781246181846717
Validation loss: 2.4780555531534674

Epoch: 6| Step: 11
Training loss: 0.0769199173821751
Validation loss: 2.481091290416892

Epoch: 6| Step: 12
Training loss: 0.17218738041854556
Validation loss: 2.4922200325319848

Epoch: 6| Step: 13
Training loss: 0.15128402271145025
Validation loss: 2.454904459921351

Epoch: 682| Step: 0
Training loss: 0.07370239632856679
Validation loss: 2.4638360942020756

Epoch: 6| Step: 1
Training loss: 0.12987529761580438
Validation loss: 2.4979878470201573

Epoch: 6| Step: 2
Training loss: 0.10398698946777857
Validation loss: 2.4636709840160678

Epoch: 6| Step: 3
Training loss: 0.08747773674874079
Validation loss: 2.494059460864562

Epoch: 6| Step: 4
Training loss: 0.094606982782866
Validation loss: 2.496018258845148

Epoch: 6| Step: 5
Training loss: 0.14780524144284865
Validation loss: 2.4593220247398353

Epoch: 6| Step: 6
Training loss: 0.15963653815053408
Validation loss: 2.501556033240324

Epoch: 6| Step: 7
Training loss: 0.12911163931343786
Validation loss: 2.473669749053248

Epoch: 6| Step: 8
Training loss: 0.08498532942607517
Validation loss: 2.48257061285273

Epoch: 6| Step: 9
Training loss: 0.06988142910947945
Validation loss: 2.4421075395668934

Epoch: 6| Step: 10
Training loss: 0.11540606203691436
Validation loss: 2.4535669958362676

Epoch: 6| Step: 11
Training loss: 0.14956573816070673
Validation loss: 2.4713507121409366

Epoch: 6| Step: 12
Training loss: 0.1384286359054569
Validation loss: 2.4536138564359984

Epoch: 6| Step: 13
Training loss: 0.10498133814252109
Validation loss: 2.4894772365962403

Epoch: 683| Step: 0
Training loss: 0.051037581598205886
Validation loss: 2.476668373992499

Epoch: 6| Step: 1
Training loss: 0.10156675476551982
Validation loss: 2.4652373991201473

Epoch: 6| Step: 2
Training loss: 0.12771926201357695
Validation loss: 2.4989788779789692

Epoch: 6| Step: 3
Training loss: 0.15247272265091277
Validation loss: 2.4783684053844137

Epoch: 6| Step: 4
Training loss: 0.13877828303315665
Validation loss: 2.4691323466739186

Epoch: 6| Step: 5
Training loss: 0.15121277347081777
Validation loss: 2.50496368069775

Epoch: 6| Step: 6
Training loss: 0.12997463393782574
Validation loss: 2.4675763737376224

Epoch: 6| Step: 7
Training loss: 0.15185253716978486
Validation loss: 2.464703925675098

Epoch: 6| Step: 8
Training loss: 0.14567700732350428
Validation loss: 2.4587483863018877

Epoch: 6| Step: 9
Training loss: 0.13609569131011875
Validation loss: 2.4201142292425253

Epoch: 6| Step: 10
Training loss: 0.17184872318021854
Validation loss: 2.422280970965585

Epoch: 6| Step: 11
Training loss: 0.10201710049366572
Validation loss: 2.40958336823353

Epoch: 6| Step: 12
Training loss: 0.09372038174703591
Validation loss: 2.403208325834443

Epoch: 6| Step: 13
Training loss: 0.17103927258857723
Validation loss: 2.4143601302530344

Epoch: 684| Step: 0
Training loss: 0.09169364766025559
Validation loss: 2.4472249573422133

Epoch: 6| Step: 1
Training loss: 0.1259914359841837
Validation loss: 2.4546267498777246

Epoch: 6| Step: 2
Training loss: 0.1698264259515212
Validation loss: 2.4524087742735805

Epoch: 6| Step: 3
Training loss: 0.16245805630028817
Validation loss: 2.4770139572121135

Epoch: 6| Step: 4
Training loss: 0.13214811874743612
Validation loss: 2.4859798585647366

Epoch: 6| Step: 5
Training loss: 0.14073505333768419
Validation loss: 2.486763238942046

Epoch: 6| Step: 6
Training loss: 0.11745413011691998
Validation loss: 2.4929912071118787

Epoch: 6| Step: 7
Training loss: 0.10023906767393835
Validation loss: 2.5375453326822646

Epoch: 6| Step: 8
Training loss: 0.13411457947542746
Validation loss: 2.5206825942149305

Epoch: 6| Step: 9
Training loss: 0.10539196451154523
Validation loss: 2.551877600937085

Epoch: 6| Step: 10
Training loss: 0.12238432360025778
Validation loss: 2.5778471666809994

Epoch: 6| Step: 11
Training loss: 0.12423563248692766
Validation loss: 2.5456298531377715

Epoch: 6| Step: 12
Training loss: 0.12891191412301461
Validation loss: 2.5651932136183726

Epoch: 6| Step: 13
Training loss: 0.12736568905526247
Validation loss: 2.53550864824555

Epoch: 685| Step: 0
Training loss: 0.11507008042092935
Validation loss: 2.560283557709952

Epoch: 6| Step: 1
Training loss: 0.076272283912249
Validation loss: 2.563093131286435

Epoch: 6| Step: 2
Training loss: 0.13148748478014036
Validation loss: 2.5401423553612656

Epoch: 6| Step: 3
Training loss: 0.11281953639121507
Validation loss: 2.5743609279018553

Epoch: 6| Step: 4
Training loss: 0.1574422352216159
Validation loss: 2.5525565674033586

Epoch: 6| Step: 5
Training loss: 0.14582104219570347
Validation loss: 2.5518854408980536

Epoch: 6| Step: 6
Training loss: 0.10222022121820301
Validation loss: 2.5435411859205

Epoch: 6| Step: 7
Training loss: 0.12091435711247951
Validation loss: 2.502279728070308

Epoch: 6| Step: 8
Training loss: 0.10736334246418044
Validation loss: 2.5130021277514727

Epoch: 6| Step: 9
Training loss: 0.12385575906728719
Validation loss: 2.5216425999532097

Epoch: 6| Step: 10
Training loss: 0.11230161082158302
Validation loss: 2.532172199779359

Epoch: 6| Step: 11
Training loss: 0.10448637616406198
Validation loss: 2.5297360913283384

Epoch: 6| Step: 12
Training loss: 0.12791521412752663
Validation loss: 2.5292534073175545

Epoch: 6| Step: 13
Training loss: 0.07617552149431853
Validation loss: 2.514227821861776

Epoch: 686| Step: 0
Training loss: 0.1446460062101308
Validation loss: 2.5137393788509703

Epoch: 6| Step: 1
Training loss: 0.10102259658334867
Validation loss: 2.5276653349376765

Epoch: 6| Step: 2
Training loss: 0.08930548849139572
Validation loss: 2.590440968235859

Epoch: 6| Step: 3
Training loss: 0.09362332408573917
Validation loss: 2.5232909841445226

Epoch: 6| Step: 4
Training loss: 0.08549865927223647
Validation loss: 2.518680463396069

Epoch: 6| Step: 5
Training loss: 0.09939490397873095
Validation loss: 2.5140347612004863

Epoch: 6| Step: 6
Training loss: 0.13283150901517896
Validation loss: 2.470140401290621

Epoch: 6| Step: 7
Training loss: 0.1397456051160159
Validation loss: 2.4656720905394214

Epoch: 6| Step: 8
Training loss: 0.10102515941978758
Validation loss: 2.471850324790999

Epoch: 6| Step: 9
Training loss: 0.10367984161871403
Validation loss: 2.4582147759127104

Epoch: 6| Step: 10
Training loss: 0.10036759613350626
Validation loss: 2.5059472408815617

Epoch: 6| Step: 11
Training loss: 0.13374789502590873
Validation loss: 2.484778055455152

Epoch: 6| Step: 12
Training loss: 0.09226437491103838
Validation loss: 2.505670237090544

Epoch: 6| Step: 13
Training loss: 0.18015019304890895
Validation loss: 2.5303118268714284

Epoch: 687| Step: 0
Training loss: 0.07641345010661625
Validation loss: 2.4753211158553516

Epoch: 6| Step: 1
Training loss: 0.13537517165554433
Validation loss: 2.5026769600691283

Epoch: 6| Step: 2
Training loss: 0.10565528445351273
Validation loss: 2.514047229682511

Epoch: 6| Step: 3
Training loss: 0.08052530107074747
Validation loss: 2.4905507391234276

Epoch: 6| Step: 4
Training loss: 0.08650450973059073
Validation loss: 2.4808608829314296

Epoch: 6| Step: 5
Training loss: 0.13210409936686118
Validation loss: 2.498013330505192

Epoch: 6| Step: 6
Training loss: 0.10804458806064896
Validation loss: 2.472585006040271

Epoch: 6| Step: 7
Training loss: 0.08435813494631303
Validation loss: 2.4793089772969252

Epoch: 6| Step: 8
Training loss: 0.15237097007931671
Validation loss: 2.4949920167605577

Epoch: 6| Step: 9
Training loss: 0.10012493692204397
Validation loss: 2.4857987240281196

Epoch: 6| Step: 10
Training loss: 0.11084549423132756
Validation loss: 2.4790165346358624

Epoch: 6| Step: 11
Training loss: 0.13026722688754977
Validation loss: 2.492161455975321

Epoch: 6| Step: 12
Training loss: 0.04635244910579943
Validation loss: 2.4921625391768107

Epoch: 6| Step: 13
Training loss: 0.10228390509157237
Validation loss: 2.5122016242654817

Epoch: 688| Step: 0
Training loss: 0.09904329413088048
Validation loss: 2.4923438376356146

Epoch: 6| Step: 1
Training loss: 0.08632285244405616
Validation loss: 2.4991086734769743

Epoch: 6| Step: 2
Training loss: 0.08486890741273691
Validation loss: 2.4811985871305957

Epoch: 6| Step: 3
Training loss: 0.18157732280950867
Validation loss: 2.490716269070632

Epoch: 6| Step: 4
Training loss: 0.07955835164025284
Validation loss: 2.475232068038596

Epoch: 6| Step: 5
Training loss: 0.1359723356160373
Validation loss: 2.514189049246989

Epoch: 6| Step: 6
Training loss: 0.12253704489523523
Validation loss: 2.501823019028269

Epoch: 6| Step: 7
Training loss: 0.12296573294703414
Validation loss: 2.5176189980657226

Epoch: 6| Step: 8
Training loss: 0.07726676534113996
Validation loss: 2.485506489001406

Epoch: 6| Step: 9
Training loss: 0.09100318770504225
Validation loss: 2.499337504396127

Epoch: 6| Step: 10
Training loss: 0.08876567324405561
Validation loss: 2.4727018022588134

Epoch: 6| Step: 11
Training loss: 0.10386454957249826
Validation loss: 2.4969624811647124

Epoch: 6| Step: 12
Training loss: 0.10569938855358633
Validation loss: 2.5030292247629324

Epoch: 6| Step: 13
Training loss: 0.07194143469545264
Validation loss: 2.4922900666599346

Epoch: 689| Step: 0
Training loss: 0.16725456528177757
Validation loss: 2.474151614313184

Epoch: 6| Step: 1
Training loss: 0.09658931592848827
Validation loss: 2.4898480211866993

Epoch: 6| Step: 2
Training loss: 0.1392028609219897
Validation loss: 2.4628281104416523

Epoch: 6| Step: 3
Training loss: 0.059045417727283986
Validation loss: 2.465074764360006

Epoch: 6| Step: 4
Training loss: 0.10152148830895465
Validation loss: 2.4683547507699033

Epoch: 6| Step: 5
Training loss: 0.14286248056623724
Validation loss: 2.4845416698760467

Epoch: 6| Step: 6
Training loss: 0.1647737842708276
Validation loss: 2.4553258765661328

Epoch: 6| Step: 7
Training loss: 0.1346262196978799
Validation loss: 2.4686974586969566

Epoch: 6| Step: 8
Training loss: 0.15154159096889092
Validation loss: 2.466440826222197

Epoch: 6| Step: 9
Training loss: 0.10056218542745642
Validation loss: 2.4717241531521004

Epoch: 6| Step: 10
Training loss: 0.12272990742498012
Validation loss: 2.5025433575031077

Epoch: 6| Step: 11
Training loss: 0.1573195212270843
Validation loss: 2.5308735551219343

Epoch: 6| Step: 12
Training loss: 0.12506036492945863
Validation loss: 2.521912301060078

Epoch: 6| Step: 13
Training loss: 0.18075643703796201
Validation loss: 2.477998560878678

Epoch: 690| Step: 0
Training loss: 0.08730031030251281
Validation loss: 2.4897943744410984

Epoch: 6| Step: 1
Training loss: 0.13226502139544669
Validation loss: 2.471919343037589

Epoch: 6| Step: 2
Training loss: 0.10190094895248557
Validation loss: 2.4448143236239503

Epoch: 6| Step: 3
Training loss: 0.13163293114203503
Validation loss: 2.4582135536486507

Epoch: 6| Step: 4
Training loss: 0.14699834301316342
Validation loss: 2.436161880321785

Epoch: 6| Step: 5
Training loss: 0.17930334947984447
Validation loss: 2.449900541448595

Epoch: 6| Step: 6
Training loss: 0.09975451759335979
Validation loss: 2.45024445255757

Epoch: 6| Step: 7
Training loss: 0.19594098063697796
Validation loss: 2.420511352587206

Epoch: 6| Step: 8
Training loss: 0.11159331542597843
Validation loss: 2.462671036873592

Epoch: 6| Step: 9
Training loss: 0.16132483167265632
Validation loss: 2.438249162093627

Epoch: 6| Step: 10
Training loss: 0.09335383015690239
Validation loss: 2.4608457820043474

Epoch: 6| Step: 11
Training loss: 0.14468330684130717
Validation loss: 2.451176331506265

Epoch: 6| Step: 12
Training loss: 0.1332722168664208
Validation loss: 2.4875543905944673

Epoch: 6| Step: 13
Training loss: 0.09989167396045964
Validation loss: 2.5143357865504896

Epoch: 691| Step: 0
Training loss: 0.20333680700698892
Validation loss: 2.511916291228074

Epoch: 6| Step: 1
Training loss: 0.1308747609900521
Validation loss: 2.5292236124934657

Epoch: 6| Step: 2
Training loss: 0.15620149813323128
Validation loss: 2.5299537770130684

Epoch: 6| Step: 3
Training loss: 0.16930360232349523
Validation loss: 2.4745376987946406

Epoch: 6| Step: 4
Training loss: 0.19638567771996115
Validation loss: 2.4994393530154206

Epoch: 6| Step: 5
Training loss: 0.12196661931927431
Validation loss: 2.447887069812972

Epoch: 6| Step: 6
Training loss: 0.1647889425817748
Validation loss: 2.443524161164938

Epoch: 6| Step: 7
Training loss: 0.18451718166126577
Validation loss: 2.402242885939607

Epoch: 6| Step: 8
Training loss: 0.0882741797620507
Validation loss: 2.4002378920740197

Epoch: 6| Step: 9
Training loss: 0.09534274582848241
Validation loss: 2.3624305120656395

Epoch: 6| Step: 10
Training loss: 0.11641401290610895
Validation loss: 2.4034313115552433

Epoch: 6| Step: 11
Training loss: 0.15234057105244453
Validation loss: 2.396155539983377

Epoch: 6| Step: 12
Training loss: 0.11020587486482752
Validation loss: 2.483997872801949

Epoch: 6| Step: 13
Training loss: 0.08859627689814824
Validation loss: 2.4463059054361365

Epoch: 692| Step: 0
Training loss: 0.16111458762013026
Validation loss: 2.441808924915596

Epoch: 6| Step: 1
Training loss: 0.11020087613134595
Validation loss: 2.4675714034885625

Epoch: 6| Step: 2
Training loss: 0.13626713413154767
Validation loss: 2.4629623939867384

Epoch: 6| Step: 3
Training loss: 0.11213610891927867
Validation loss: 2.4443054400522874

Epoch: 6| Step: 4
Training loss: 0.11592285930083512
Validation loss: 2.462101155623973

Epoch: 6| Step: 5
Training loss: 0.1316836784774192
Validation loss: 2.454971430590778

Epoch: 6| Step: 6
Training loss: 0.14244456763808436
Validation loss: 2.4638181276886555

Epoch: 6| Step: 7
Training loss: 0.07650088511956911
Validation loss: 2.50471568657985

Epoch: 6| Step: 8
Training loss: 0.1483295700804928
Validation loss: 2.490770155332842

Epoch: 6| Step: 9
Training loss: 0.07768354862887218
Validation loss: 2.4759436324816284

Epoch: 6| Step: 10
Training loss: 0.129532578441954
Validation loss: 2.473261253364808

Epoch: 6| Step: 11
Training loss: 0.14874174910590493
Validation loss: 2.485744899649587

Epoch: 6| Step: 12
Training loss: 0.11150271127915438
Validation loss: 2.4403903359247545

Epoch: 6| Step: 13
Training loss: 0.11575586510447987
Validation loss: 2.4666535383250383

Epoch: 693| Step: 0
Training loss: 0.11512200890066303
Validation loss: 2.442099663162437

Epoch: 6| Step: 1
Training loss: 0.12290668827573303
Validation loss: 2.4308176969472126

Epoch: 6| Step: 2
Training loss: 0.1349453901949789
Validation loss: 2.471793636457068

Epoch: 6| Step: 3
Training loss: 0.11452443241785645
Validation loss: 2.4592025805848388

Epoch: 6| Step: 4
Training loss: 0.10259296726046731
Validation loss: 2.434795514752913

Epoch: 6| Step: 5
Training loss: 0.13619769122492242
Validation loss: 2.4359084413721646

Epoch: 6| Step: 6
Training loss: 0.0912823715908304
Validation loss: 2.44353226903728

Epoch: 6| Step: 7
Training loss: 0.2165742882772035
Validation loss: 2.4454940198564707

Epoch: 6| Step: 8
Training loss: 0.15598365016685928
Validation loss: 2.4457945597668513

Epoch: 6| Step: 9
Training loss: 0.17482687100778888
Validation loss: 2.471537960666295

Epoch: 6| Step: 10
Training loss: 0.07424897908422426
Validation loss: 2.465839516179014

Epoch: 6| Step: 11
Training loss: 0.1321629741813533
Validation loss: 2.505235232633327

Epoch: 6| Step: 12
Training loss: 0.10622900236435881
Validation loss: 2.540370893954901

Epoch: 6| Step: 13
Training loss: 0.08048967117261004
Validation loss: 2.537299099953773

Epoch: 694| Step: 0
Training loss: 0.12645085084303853
Validation loss: 2.5525074827125853

Epoch: 6| Step: 1
Training loss: 0.15800962859667297
Validation loss: 2.589672689709761

Epoch: 6| Step: 2
Training loss: 0.0998932356052464
Validation loss: 2.531420964369885

Epoch: 6| Step: 3
Training loss: 0.06697664302953242
Validation loss: 2.562226597777058

Epoch: 6| Step: 4
Training loss: 0.09271128228762258
Validation loss: 2.523420078739768

Epoch: 6| Step: 5
Training loss: 0.12737103415661621
Validation loss: 2.5140952348896217

Epoch: 6| Step: 6
Training loss: 0.07976788517143843
Validation loss: 2.5244140391426053

Epoch: 6| Step: 7
Training loss: 0.07610569732350528
Validation loss: 2.5266763194124326

Epoch: 6| Step: 8
Training loss: 0.12824732535159147
Validation loss: 2.502272029800147

Epoch: 6| Step: 9
Training loss: 0.1308419657271917
Validation loss: 2.500993019717393

Epoch: 6| Step: 10
Training loss: 0.09220423506117183
Validation loss: 2.5071589933600293

Epoch: 6| Step: 11
Training loss: 0.11391671937152022
Validation loss: 2.516395633736229

Epoch: 6| Step: 12
Training loss: 0.1891559157243312
Validation loss: 2.5124042937836735

Epoch: 6| Step: 13
Training loss: 0.14788293140387854
Validation loss: 2.5139554566994704

Epoch: 695| Step: 0
Training loss: 0.06452181796817215
Validation loss: 2.532123345634053

Epoch: 6| Step: 1
Training loss: 0.09273208901368432
Validation loss: 2.507459216233946

Epoch: 6| Step: 2
Training loss: 0.08661995642946493
Validation loss: 2.503636037647462

Epoch: 6| Step: 3
Training loss: 0.13203739033477527
Validation loss: 2.4910302986044575

Epoch: 6| Step: 4
Training loss: 0.12044098096760139
Validation loss: 2.5093211681948597

Epoch: 6| Step: 5
Training loss: 0.14621098756088635
Validation loss: 2.4946385225985277

Epoch: 6| Step: 6
Training loss: 0.07135713606187635
Validation loss: 2.4756148980598294

Epoch: 6| Step: 7
Training loss: 0.08702902744817989
Validation loss: 2.46596243552015

Epoch: 6| Step: 8
Training loss: 0.14361774590684634
Validation loss: 2.4837271909349052

Epoch: 6| Step: 9
Training loss: 0.08385184276906804
Validation loss: 2.4547716984386967

Epoch: 6| Step: 10
Training loss: 0.11977215967435391
Validation loss: 2.4564130975093534

Epoch: 6| Step: 11
Training loss: 0.06555373616847239
Validation loss: 2.4877837917227814

Epoch: 6| Step: 12
Training loss: 0.08787295905696392
Validation loss: 2.4519069571989007

Epoch: 6| Step: 13
Training loss: 0.18294991561611948
Validation loss: 2.4607839348599896

Epoch: 696| Step: 0
Training loss: 0.07260839901582804
Validation loss: 2.4732493299866074

Epoch: 6| Step: 1
Training loss: 0.08015686327716387
Validation loss: 2.502334871334919

Epoch: 6| Step: 2
Training loss: 0.1282228357992201
Validation loss: 2.482126046791043

Epoch: 6| Step: 3
Training loss: 0.08624989181750188
Validation loss: 2.4981340315205367

Epoch: 6| Step: 4
Training loss: 0.16310346817545618
Validation loss: 2.5020223298040225

Epoch: 6| Step: 5
Training loss: 0.10153242729692653
Validation loss: 2.5166734790553607

Epoch: 6| Step: 6
Training loss: 0.10804825141289308
Validation loss: 2.5523367104098234

Epoch: 6| Step: 7
Training loss: 0.11551282667333246
Validation loss: 2.541996604797694

Epoch: 6| Step: 8
Training loss: 0.08716830026818685
Validation loss: 2.533767236500543

Epoch: 6| Step: 9
Training loss: 0.08371983493758359
Validation loss: 2.5342764769618813

Epoch: 6| Step: 10
Training loss: 0.12352149118829052
Validation loss: 2.514169777429014

Epoch: 6| Step: 11
Training loss: 0.1225467919370425
Validation loss: 2.5639420140354856

Epoch: 6| Step: 12
Training loss: 0.0916294945951949
Validation loss: 2.5527045614937873

Epoch: 6| Step: 13
Training loss: 0.10281518814520726
Validation loss: 2.523231705460138

Epoch: 697| Step: 0
Training loss: 0.0914029893130517
Validation loss: 2.513651862858681

Epoch: 6| Step: 1
Training loss: 0.09874128759707355
Validation loss: 2.4979477339424627

Epoch: 6| Step: 2
Training loss: 0.11393422987969569
Validation loss: 2.4876190384622685

Epoch: 6| Step: 3
Training loss: 0.10784197072805554
Validation loss: 2.4907557323238945

Epoch: 6| Step: 4
Training loss: 0.11745202488350402
Validation loss: 2.461128841786954

Epoch: 6| Step: 5
Training loss: 0.1319752769215658
Validation loss: 2.4795969169811856

Epoch: 6| Step: 6
Training loss: 0.05392457781771441
Validation loss: 2.4708482852634117

Epoch: 6| Step: 7
Training loss: 0.08057763281544841
Validation loss: 2.431312464235266

Epoch: 6| Step: 8
Training loss: 0.11885827643181529
Validation loss: 2.4452297706871633

Epoch: 6| Step: 9
Training loss: 0.12061825580223896
Validation loss: 2.432582484396699

Epoch: 6| Step: 10
Training loss: 0.18348156768488572
Validation loss: 2.4609029350451186

Epoch: 6| Step: 11
Training loss: 0.16321749149635612
Validation loss: 2.4930527507835407

Epoch: 6| Step: 12
Training loss: 0.08137463995638536
Validation loss: 2.4761826931202204

Epoch: 6| Step: 13
Training loss: 0.07431945117823058
Validation loss: 2.513151418787168

Epoch: 698| Step: 0
Training loss: 0.0794705596997911
Validation loss: 2.51389969539939

Epoch: 6| Step: 1
Training loss: 0.08478699340095329
Validation loss: 2.503912150541924

Epoch: 6| Step: 2
Training loss: 0.09523464877219902
Validation loss: 2.510557761397416

Epoch: 6| Step: 3
Training loss: 0.20966009721340617
Validation loss: 2.533001561965028

Epoch: 6| Step: 4
Training loss: 0.1052280080295101
Validation loss: 2.546108419121101

Epoch: 6| Step: 5
Training loss: 0.1523824239206139
Validation loss: 2.4976475106879072

Epoch: 6| Step: 6
Training loss: 0.1296896537923637
Validation loss: 2.5248449036488996

Epoch: 6| Step: 7
Training loss: 0.08975906631141199
Validation loss: 2.518099674956995

Epoch: 6| Step: 8
Training loss: 0.08025841073424354
Validation loss: 2.5065640598667533

Epoch: 6| Step: 9
Training loss: 0.1340741023909578
Validation loss: 2.495613131599036

Epoch: 6| Step: 10
Training loss: 0.06782203726458845
Validation loss: 2.48922056964564

Epoch: 6| Step: 11
Training loss: 0.09645734613032182
Validation loss: 2.4904435128386457

Epoch: 6| Step: 12
Training loss: 0.12802408099290669
Validation loss: 2.4707194725830752

Epoch: 6| Step: 13
Training loss: 0.05464380511186524
Validation loss: 2.4875320185163408

Epoch: 699| Step: 0
Training loss: 0.15077617691083872
Validation loss: 2.469761668293249

Epoch: 6| Step: 1
Training loss: 0.11660402796964636
Validation loss: 2.4591647553755918

Epoch: 6| Step: 2
Training loss: 0.04597545057279378
Validation loss: 2.4714689016876843

Epoch: 6| Step: 3
Training loss: 0.09417620279422773
Validation loss: 2.4417495316874662

Epoch: 6| Step: 4
Training loss: 0.12151423636181721
Validation loss: 2.451181656607503

Epoch: 6| Step: 5
Training loss: 0.09247688278448289
Validation loss: 2.4505056904470535

Epoch: 6| Step: 6
Training loss: 0.07440996634355822
Validation loss: 2.4614997696729577

Epoch: 6| Step: 7
Training loss: 0.10597384886285167
Validation loss: 2.4605666785393017

Epoch: 6| Step: 8
Training loss: 0.04434572429022234
Validation loss: 2.4502364296729326

Epoch: 6| Step: 9
Training loss: 0.11354616856909722
Validation loss: 2.459156351895334

Epoch: 6| Step: 10
Training loss: 0.11443018341582055
Validation loss: 2.4617132877949466

Epoch: 6| Step: 11
Training loss: 0.10864667563265827
Validation loss: 2.483609748856954

Epoch: 6| Step: 12
Training loss: 0.061743726007537206
Validation loss: 2.487863818423767

Epoch: 6| Step: 13
Training loss: 0.10202551259679955
Validation loss: 2.5144191576168677

Epoch: 700| Step: 0
Training loss: 0.09407274501713632
Validation loss: 2.4828695424778657

Epoch: 6| Step: 1
Training loss: 0.08958057544403444
Validation loss: 2.5291046881691903

Epoch: 6| Step: 2
Training loss: 0.06755280819790496
Validation loss: 2.48657567859882

Epoch: 6| Step: 3
Training loss: 0.04422540940562362
Validation loss: 2.493663253054645

Epoch: 6| Step: 4
Training loss: 0.09012586935426926
Validation loss: 2.5080220870889804

Epoch: 6| Step: 5
Training loss: 0.06419316521198934
Validation loss: 2.497539861322522

Epoch: 6| Step: 6
Training loss: 0.07504867523912433
Validation loss: 2.481199497403154

Epoch: 6| Step: 7
Training loss: 0.060165066661264005
Validation loss: 2.4882243291538613

Epoch: 6| Step: 8
Training loss: 0.1274801392724122
Validation loss: 2.5392400384491314

Epoch: 6| Step: 9
Training loss: 0.1199857876974289
Validation loss: 2.507760858896949

Epoch: 6| Step: 10
Training loss: 0.11981914730267813
Validation loss: 2.499052102857176

Epoch: 6| Step: 11
Training loss: 0.0857949402008638
Validation loss: 2.4509086119427432

Epoch: 6| Step: 12
Training loss: 0.119075319496125
Validation loss: 2.435299707205696

Epoch: 6| Step: 13
Training loss: 0.17341343566696002
Validation loss: 2.4880493692735275

Epoch: 701| Step: 0
Training loss: 0.10160083689095041
Validation loss: 2.4921257881143584

Epoch: 6| Step: 1
Training loss: 0.07838752863606213
Validation loss: 2.4774555420497197

Epoch: 6| Step: 2
Training loss: 0.1250204874177044
Validation loss: 2.516049431239012

Epoch: 6| Step: 3
Training loss: 0.06780011080919025
Validation loss: 2.5380180236262544

Epoch: 6| Step: 4
Training loss: 0.08726668618888028
Validation loss: 2.5192448014315025

Epoch: 6| Step: 5
Training loss: 0.10637740935383014
Validation loss: 2.534421306763795

Epoch: 6| Step: 6
Training loss: 0.09908173160067771
Validation loss: 2.5360364547722587

Epoch: 6| Step: 7
Training loss: 0.11896998270196268
Validation loss: 2.519034679535568

Epoch: 6| Step: 8
Training loss: 0.08131598672420964
Validation loss: 2.529809323793046

Epoch: 6| Step: 9
Training loss: 0.09318435415974324
Validation loss: 2.5347254532595693

Epoch: 6| Step: 10
Training loss: 0.12769841262447654
Validation loss: 2.5183039455168137

Epoch: 6| Step: 11
Training loss: 0.0927804542698823
Validation loss: 2.4723781863567726

Epoch: 6| Step: 12
Training loss: 0.06300205996718032
Validation loss: 2.48036500201736

Epoch: 6| Step: 13
Training loss: 0.08390174171654098
Validation loss: 2.44547458302713

Epoch: 702| Step: 0
Training loss: 0.08757075010294653
Validation loss: 2.440451038562991

Epoch: 6| Step: 1
Training loss: 0.12785510444338635
Validation loss: 2.39465971062827

Epoch: 6| Step: 2
Training loss: 0.06330610275852126
Validation loss: 2.392504533444153

Epoch: 6| Step: 3
Training loss: 0.1024972376218591
Validation loss: 2.4303035091694336

Epoch: 6| Step: 4
Training loss: 0.07671691227088943
Validation loss: 2.4126229158552164

Epoch: 6| Step: 5
Training loss: 0.06362063856390075
Validation loss: 2.4546724487260163

Epoch: 6| Step: 6
Training loss: 0.07825208698443588
Validation loss: 2.4429037546515575

Epoch: 6| Step: 7
Training loss: 0.17872734202986035
Validation loss: 2.4339277997178574

Epoch: 6| Step: 8
Training loss: 0.08115214498153564
Validation loss: 2.4540336435643715

Epoch: 6| Step: 9
Training loss: 0.07779678901373407
Validation loss: 2.4350025507425554

Epoch: 6| Step: 10
Training loss: 0.08841012434966632
Validation loss: 2.4514209416337023

Epoch: 6| Step: 11
Training loss: 0.07665788440618165
Validation loss: 2.445025515287836

Epoch: 6| Step: 12
Training loss: 0.09824623228509799
Validation loss: 2.48131395144261

Epoch: 6| Step: 13
Training loss: 0.0767288568350017
Validation loss: 2.451234233451768

Epoch: 703| Step: 0
Training loss: 0.08358970491925527
Validation loss: 2.495505804369967

Epoch: 6| Step: 1
Training loss: 0.12870961421581534
Validation loss: 2.4782545156353546

Epoch: 6| Step: 2
Training loss: 0.07870173956655283
Validation loss: 2.451754087207469

Epoch: 6| Step: 3
Training loss: 0.13582105883792897
Validation loss: 2.4516517693963675

Epoch: 6| Step: 4
Training loss: 0.10406772016915275
Validation loss: 2.5171950025755954

Epoch: 6| Step: 5
Training loss: 0.09752051934555908
Validation loss: 2.4535781643482473

Epoch: 6| Step: 6
Training loss: 0.12455176663079988
Validation loss: 2.468767815355969

Epoch: 6| Step: 7
Training loss: 0.06456180282199732
Validation loss: 2.4613186745645006

Epoch: 6| Step: 8
Training loss: 0.11949965442748162
Validation loss: 2.448598828347156

Epoch: 6| Step: 9
Training loss: 0.10566298824476392
Validation loss: 2.437042590972084

Epoch: 6| Step: 10
Training loss: 0.10808974636743902
Validation loss: 2.449969938418986

Epoch: 6| Step: 11
Training loss: 0.11250091078839904
Validation loss: 2.434918903116293

Epoch: 6| Step: 12
Training loss: 0.06968399786916175
Validation loss: 2.4171322040724004

Epoch: 6| Step: 13
Training loss: 0.07565595983723773
Validation loss: 2.4690626846455594

Epoch: 704| Step: 0
Training loss: 0.08192777919938575
Validation loss: 2.448832458721841

Epoch: 6| Step: 1
Training loss: 0.07918989582904751
Validation loss: 2.4781543381064917

Epoch: 6| Step: 2
Training loss: 0.08794683407442096
Validation loss: 2.4743037861606156

Epoch: 6| Step: 3
Training loss: 0.08245176433245102
Validation loss: 2.478008603341824

Epoch: 6| Step: 4
Training loss: 0.14225069753269676
Validation loss: 2.45111937107747

Epoch: 6| Step: 5
Training loss: 0.11527418806606658
Validation loss: 2.4637831754888775

Epoch: 6| Step: 6
Training loss: 0.1215143015084206
Validation loss: 2.492954532794861

Epoch: 6| Step: 7
Training loss: 0.08062496369198417
Validation loss: 2.4771092064616744

Epoch: 6| Step: 8
Training loss: 0.09289874097533764
Validation loss: 2.4575755197657623

Epoch: 6| Step: 9
Training loss: 0.08385293400146725
Validation loss: 2.457444979624738

Epoch: 6| Step: 10
Training loss: 0.07538902115474706
Validation loss: 2.4729713848631585

Epoch: 6| Step: 11
Training loss: 0.09364729958197178
Validation loss: 2.4814598185512793

Epoch: 6| Step: 12
Training loss: 0.06340628181154027
Validation loss: 2.470414925963038

Epoch: 6| Step: 13
Training loss: 0.049439510287556714
Validation loss: 2.449417458155922

Epoch: 705| Step: 0
Training loss: 0.1352632154435401
Validation loss: 2.4739647750036617

Epoch: 6| Step: 1
Training loss: 0.07537163460669169
Validation loss: 2.4808203839010634

Epoch: 6| Step: 2
Training loss: 0.06102285642668355
Validation loss: 2.459507256419379

Epoch: 6| Step: 3
Training loss: 0.12903996959057282
Validation loss: 2.4911441147066498

Epoch: 6| Step: 4
Training loss: 0.09019204711620288
Validation loss: 2.463592670988613

Epoch: 6| Step: 5
Training loss: 0.046806449237116236
Validation loss: 2.48214042698951

Epoch: 6| Step: 6
Training loss: 0.060084645505904234
Validation loss: 2.5138108663583494

Epoch: 6| Step: 7
Training loss: 0.05195321005979186
Validation loss: 2.477851348823159

Epoch: 6| Step: 8
Training loss: 0.058681569250948674
Validation loss: 2.5014138356466957

Epoch: 6| Step: 9
Training loss: 0.14548710541308255
Validation loss: 2.472056575223321

Epoch: 6| Step: 10
Training loss: 0.12544451592349198
Validation loss: 2.4825524659282032

Epoch: 6| Step: 11
Training loss: 0.05277858311621852
Validation loss: 2.496854976619609

Epoch: 6| Step: 12
Training loss: 0.08136800165817516
Validation loss: 2.4950896790809827

Epoch: 6| Step: 13
Training loss: 0.08271858089791463
Validation loss: 2.488709229941574

Epoch: 706| Step: 0
Training loss: 0.06699781032798846
Validation loss: 2.481055920251974

Epoch: 6| Step: 1
Training loss: 0.06584211506259872
Validation loss: 2.4993557386975174

Epoch: 6| Step: 2
Training loss: 0.11597840903518766
Validation loss: 2.514815973199953

Epoch: 6| Step: 3
Training loss: 0.11977310831637933
Validation loss: 2.533397671422793

Epoch: 6| Step: 4
Training loss: 0.07178742149865343
Validation loss: 2.5098939117412096

Epoch: 6| Step: 5
Training loss: 0.16525651499361002
Validation loss: 2.5112851127911737

Epoch: 6| Step: 6
Training loss: 0.10592008201352215
Validation loss: 2.52748343287164

Epoch: 6| Step: 7
Training loss: 0.04969591061316577
Validation loss: 2.5268167382208198

Epoch: 6| Step: 8
Training loss: 0.11680985636957261
Validation loss: 2.538363893129004

Epoch: 6| Step: 9
Training loss: 0.09533737319269146
Validation loss: 2.4871186636327276

Epoch: 6| Step: 10
Training loss: 0.09700070174414416
Validation loss: 2.4978038196204

Epoch: 6| Step: 11
Training loss: 0.08567438703524477
Validation loss: 2.4790525791896187

Epoch: 6| Step: 12
Training loss: 0.12519926341662044
Validation loss: 2.478338553264562

Epoch: 6| Step: 13
Training loss: 0.05561510869749637
Validation loss: 2.437909262570053

Epoch: 707| Step: 0
Training loss: 0.08760881278482018
Validation loss: 2.437158125721121

Epoch: 6| Step: 1
Training loss: 0.08760628801257778
Validation loss: 2.4576901372556

Epoch: 6| Step: 2
Training loss: 0.08498804986182949
Validation loss: 2.455111831132273

Epoch: 6| Step: 3
Training loss: 0.16167384551600375
Validation loss: 2.4591720913266313

Epoch: 6| Step: 4
Training loss: 0.14202426432645815
Validation loss: 2.465619176919639

Epoch: 6| Step: 5
Training loss: 0.14490647838270967
Validation loss: 2.4387882552601776

Epoch: 6| Step: 6
Training loss: 0.0730085461060725
Validation loss: 2.4653735006527304

Epoch: 6| Step: 7
Training loss: 0.12337661642003186
Validation loss: 2.459014540268202

Epoch: 6| Step: 8
Training loss: 0.061922140075892064
Validation loss: 2.477614053009252

Epoch: 6| Step: 9
Training loss: 0.06429131020281086
Validation loss: 2.4823277420433314

Epoch: 6| Step: 10
Training loss: 0.1000683206509943
Validation loss: 2.4476912842209697

Epoch: 6| Step: 11
Training loss: 0.07400836426251284
Validation loss: 2.4636237351002506

Epoch: 6| Step: 12
Training loss: 0.05403250752602318
Validation loss: 2.4730910534338704

Epoch: 6| Step: 13
Training loss: 0.07489131811526784
Validation loss: 2.455235245780112

Epoch: 708| Step: 0
Training loss: 0.06627925833457454
Validation loss: 2.470327416214398

Epoch: 6| Step: 1
Training loss: 0.08978747077134454
Validation loss: 2.517062495003394

Epoch: 6| Step: 2
Training loss: 0.04542980999327371
Validation loss: 2.4720621011259216

Epoch: 6| Step: 3
Training loss: 0.10238973552667373
Validation loss: 2.496475926101601

Epoch: 6| Step: 4
Training loss: 0.0880435910539092
Validation loss: 2.4524106370975622

Epoch: 6| Step: 5
Training loss: 0.09295476960602748
Validation loss: 2.4782680431551807

Epoch: 6| Step: 6
Training loss: 0.06799942001518802
Validation loss: 2.498989460885864

Epoch: 6| Step: 7
Training loss: 0.12386859779914441
Validation loss: 2.4650983511056443

Epoch: 6| Step: 8
Training loss: 0.12462701134555619
Validation loss: 2.4755274851400246

Epoch: 6| Step: 9
Training loss: 0.08835720354290721
Validation loss: 2.4552854904184414

Epoch: 6| Step: 10
Training loss: 0.06846025720524072
Validation loss: 2.4462632613114716

Epoch: 6| Step: 11
Training loss: 0.07793002833624092
Validation loss: 2.4277402641971997

Epoch: 6| Step: 12
Training loss: 0.0797214239502711
Validation loss: 2.4651896550590657

Epoch: 6| Step: 13
Training loss: 0.06751331876776695
Validation loss: 2.432646446723736

Epoch: 709| Step: 0
Training loss: 0.07810762927536317
Validation loss: 2.456337601688782

Epoch: 6| Step: 1
Training loss: 0.07123168177574644
Validation loss: 2.450972418960931

Epoch: 6| Step: 2
Training loss: 0.0526123356653109
Validation loss: 2.4925860976237324

Epoch: 6| Step: 3
Training loss: 0.08203749122037612
Validation loss: 2.465155554526306

Epoch: 6| Step: 4
Training loss: 0.06829419775462839
Validation loss: 2.463872849865398

Epoch: 6| Step: 5
Training loss: 0.07649150142550963
Validation loss: 2.476300717784551

Epoch: 6| Step: 6
Training loss: 0.10770686665633318
Validation loss: 2.5022681724599707

Epoch: 6| Step: 7
Training loss: 0.08732624577179177
Validation loss: 2.4802116314396367

Epoch: 6| Step: 8
Training loss: 0.050517140465313005
Validation loss: 2.5268510965098727

Epoch: 6| Step: 9
Training loss: 0.0866782224736778
Validation loss: 2.5056962379028156

Epoch: 6| Step: 10
Training loss: 0.15750904060143453
Validation loss: 2.4790389292702857

Epoch: 6| Step: 11
Training loss: 0.09417230638861251
Validation loss: 2.5079702698836632

Epoch: 6| Step: 12
Training loss: 0.07203529031618086
Validation loss: 2.453004503710039

Epoch: 6| Step: 13
Training loss: 0.1129672079455915
Validation loss: 2.4642763041249074

Epoch: 710| Step: 0
Training loss: 0.06543004690612467
Validation loss: 2.5008995529692015

Epoch: 6| Step: 1
Training loss: 0.08115546441992427
Validation loss: 2.4981190629984855

Epoch: 6| Step: 2
Training loss: 0.06990468117492998
Validation loss: 2.5090482111377885

Epoch: 6| Step: 3
Training loss: 0.06125612314670577
Validation loss: 2.473471144334019

Epoch: 6| Step: 4
Training loss: 0.07613249518855336
Validation loss: 2.5177700706194805

Epoch: 6| Step: 5
Training loss: 0.1336316902539483
Validation loss: 2.5186160931872523

Epoch: 6| Step: 6
Training loss: 0.09042481992239314
Validation loss: 2.5100483006047614

Epoch: 6| Step: 7
Training loss: 0.06687755438904018
Validation loss: 2.459361461428008

Epoch: 6| Step: 8
Training loss: 0.11606878514083142
Validation loss: 2.463774563005913

Epoch: 6| Step: 9
Training loss: 0.09113918745698128
Validation loss: 2.4377694634398828

Epoch: 6| Step: 10
Training loss: 0.11973322776673934
Validation loss: 2.424704750379805

Epoch: 6| Step: 11
Training loss: 0.0816145228908285
Validation loss: 2.4238814019982904

Epoch: 6| Step: 12
Training loss: 0.11127582375570336
Validation loss: 2.4368519632826806

Epoch: 6| Step: 13
Training loss: 0.1526953966985135
Validation loss: 2.4338250961560655

Epoch: 711| Step: 0
Training loss: 0.11317291505612984
Validation loss: 2.4487149192259023

Epoch: 6| Step: 1
Training loss: 0.06393930420352922
Validation loss: 2.4479114233068593

Epoch: 6| Step: 2
Training loss: 0.12123806106887107
Validation loss: 2.4725558301004735

Epoch: 6| Step: 3
Training loss: 0.0977999583482166
Validation loss: 2.4924245952956436

Epoch: 6| Step: 4
Training loss: 0.10879420297418478
Validation loss: 2.4854649805796716

Epoch: 6| Step: 5
Training loss: 0.1260749078165928
Validation loss: 2.524626635288658

Epoch: 6| Step: 6
Training loss: 0.17015533194806576
Validation loss: 2.4978300521637307

Epoch: 6| Step: 7
Training loss: 0.08692609778667038
Validation loss: 2.4744241854661415

Epoch: 6| Step: 8
Training loss: 0.13801336418190868
Validation loss: 2.484401651916547

Epoch: 6| Step: 9
Training loss: 0.12820095683419944
Validation loss: 2.477138592676081

Epoch: 6| Step: 10
Training loss: 0.1100750556285041
Validation loss: 2.411033378356994

Epoch: 6| Step: 11
Training loss: 0.140713121036868
Validation loss: 2.3884828919178758

Epoch: 6| Step: 12
Training loss: 0.17288799763961538
Validation loss: 2.4366747182373536

Epoch: 6| Step: 13
Training loss: 0.16000545776453873
Validation loss: 2.4390954805943514

Epoch: 712| Step: 0
Training loss: 0.1198015329886589
Validation loss: 2.4620887377526555

Epoch: 6| Step: 1
Training loss: 0.1009057709926791
Validation loss: 2.4362280771488964

Epoch: 6| Step: 2
Training loss: 0.09936467201017536
Validation loss: 2.4388582007346704

Epoch: 6| Step: 3
Training loss: 0.06622197022693349
Validation loss: 2.4858629215046566

Epoch: 6| Step: 4
Training loss: 0.09360825233633126
Validation loss: 2.4551602248692053

Epoch: 6| Step: 5
Training loss: 0.07354588170755519
Validation loss: 2.4721540091217356

Epoch: 6| Step: 6
Training loss: 0.12003439864716807
Validation loss: 2.4430362838013018

Epoch: 6| Step: 7
Training loss: 0.1393594485959653
Validation loss: 2.4858418491073513

Epoch: 6| Step: 8
Training loss: 0.09558484495011704
Validation loss: 2.4704576300224597

Epoch: 6| Step: 9
Training loss: 0.14458165063231548
Validation loss: 2.4655767093078422

Epoch: 6| Step: 10
Training loss: 0.10747867729694625
Validation loss: 2.4424559938661954

Epoch: 6| Step: 11
Training loss: 0.06121819896447568
Validation loss: 2.4191963098400655

Epoch: 6| Step: 12
Training loss: 0.08904016867299697
Validation loss: 2.4179904799002068

Epoch: 6| Step: 13
Training loss: 0.10111724011645967
Validation loss: 2.3959060130034264

Epoch: 713| Step: 0
Training loss: 0.09978912067882013
Validation loss: 2.4080455948633883

Epoch: 6| Step: 1
Training loss: 0.12626803486491286
Validation loss: 2.390828608067992

Epoch: 6| Step: 2
Training loss: 0.10189337660471819
Validation loss: 2.3798718459080797

Epoch: 6| Step: 3
Training loss: 0.10593890549281582
Validation loss: 2.3932106982956447

Epoch: 6| Step: 4
Training loss: 0.1828855287150628
Validation loss: 2.3865278075768135

Epoch: 6| Step: 5
Training loss: 0.10340233667542312
Validation loss: 2.4371940498611213

Epoch: 6| Step: 6
Training loss: 0.08421783379532337
Validation loss: 2.4286707257576334

Epoch: 6| Step: 7
Training loss: 0.12928859764871664
Validation loss: 2.4162755164491028

Epoch: 6| Step: 8
Training loss: 0.07967231725060156
Validation loss: 2.463764842320254

Epoch: 6| Step: 9
Training loss: 0.07231223368925382
Validation loss: 2.448623178949931

Epoch: 6| Step: 10
Training loss: 0.09475958140537913
Validation loss: 2.439524903057486

Epoch: 6| Step: 11
Training loss: 0.12081778521504569
Validation loss: 2.458401111407461

Epoch: 6| Step: 12
Training loss: 0.06682941999155123
Validation loss: 2.4614295458453257

Epoch: 6| Step: 13
Training loss: 0.15737895214755518
Validation loss: 2.4461447489326194

Epoch: 714| Step: 0
Training loss: 0.07005761891631468
Validation loss: 2.4754054135956065

Epoch: 6| Step: 1
Training loss: 0.12941943234933295
Validation loss: 2.4575102276119227

Epoch: 6| Step: 2
Training loss: 0.10813083781761394
Validation loss: 2.443994829594486

Epoch: 6| Step: 3
Training loss: 0.06634369877378882
Validation loss: 2.4573634302450817

Epoch: 6| Step: 4
Training loss: 0.12933520990580083
Validation loss: 2.439102394996084

Epoch: 6| Step: 5
Training loss: 0.12298633584805184
Validation loss: 2.4742969778996873

Epoch: 6| Step: 6
Training loss: 0.08078681966259645
Validation loss: 2.451482365645937

Epoch: 6| Step: 7
Training loss: 0.10968949029480721
Validation loss: 2.458318632765654

Epoch: 6| Step: 8
Training loss: 0.10810232959107657
Validation loss: 2.4396764148506604

Epoch: 6| Step: 9
Training loss: 0.07314316095105042
Validation loss: 2.477019396502646

Epoch: 6| Step: 10
Training loss: 0.07885069567454203
Validation loss: 2.50129602893833

Epoch: 6| Step: 11
Training loss: 0.13134238789142783
Validation loss: 2.484244278878934

Epoch: 6| Step: 12
Training loss: 0.17458483653703583
Validation loss: 2.4850566138193755

Epoch: 6| Step: 13
Training loss: 0.18815701331107484
Validation loss: 2.4766934112671337

Epoch: 715| Step: 0
Training loss: 0.0747703209361938
Validation loss: 2.4560553179577633

Epoch: 6| Step: 1
Training loss: 0.10796715452282343
Validation loss: 2.4277279651887125

Epoch: 6| Step: 2
Training loss: 0.08403329755034121
Validation loss: 2.418160453882542

Epoch: 6| Step: 3
Training loss: 0.13267585091748396
Validation loss: 2.4005863703931776

Epoch: 6| Step: 4
Training loss: 0.13587596530974988
Validation loss: 2.3939652774009614

Epoch: 6| Step: 5
Training loss: 0.0798935828141671
Validation loss: 2.40615629118374

Epoch: 6| Step: 6
Training loss: 0.0755584543618628
Validation loss: 2.4102270753115302

Epoch: 6| Step: 7
Training loss: 0.06458357412283115
Validation loss: 2.4156498405245808

Epoch: 6| Step: 8
Training loss: 0.07373350655063894
Validation loss: 2.4379999748654027

Epoch: 6| Step: 9
Training loss: 0.10035086449261191
Validation loss: 2.4661773937078904

Epoch: 6| Step: 10
Training loss: 0.08817729557818837
Validation loss: 2.4127939301815995

Epoch: 6| Step: 11
Training loss: 0.10203291540407797
Validation loss: 2.432228592603784

Epoch: 6| Step: 12
Training loss: 0.12430750611982631
Validation loss: 2.4510168094740474

Epoch: 6| Step: 13
Training loss: 0.12669927453265808
Validation loss: 2.4669891844439706

Epoch: 716| Step: 0
Training loss: 0.14776814903297128
Validation loss: 2.478088825715288

Epoch: 6| Step: 1
Training loss: 0.1317238295696783
Validation loss: 2.455094877357481

Epoch: 6| Step: 2
Training loss: 0.10513019087253236
Validation loss: 2.4827268384144614

Epoch: 6| Step: 3
Training loss: 0.14675414358248445
Validation loss: 2.509157994613281

Epoch: 6| Step: 4
Training loss: 0.09533646469889497
Validation loss: 2.4812226828935335

Epoch: 6| Step: 5
Training loss: 0.10299088976671172
Validation loss: 2.5039321431964576

Epoch: 6| Step: 6
Training loss: 0.13323535641102646
Validation loss: 2.48670806687109

Epoch: 6| Step: 7
Training loss: 0.09275087784984078
Validation loss: 2.4900849233036397

Epoch: 6| Step: 8
Training loss: 0.0664419120510508
Validation loss: 2.479685757910106

Epoch: 6| Step: 9
Training loss: 0.0804401738156638
Validation loss: 2.4948773404172053

Epoch: 6| Step: 10
Training loss: 0.07372213468123072
Validation loss: 2.467874421813825

Epoch: 6| Step: 11
Training loss: 0.128342102035557
Validation loss: 2.4325975582038755

Epoch: 6| Step: 12
Training loss: 0.16367548754217282
Validation loss: 2.4488642774716216

Epoch: 6| Step: 13
Training loss: 0.07939278306244615
Validation loss: 2.427403992126744

Epoch: 717| Step: 0
Training loss: 0.1274581182052906
Validation loss: 2.438757193318085

Epoch: 6| Step: 1
Training loss: 0.10974193229056318
Validation loss: 2.4430636007594484

Epoch: 6| Step: 2
Training loss: 0.12864112320924767
Validation loss: 2.44287192175608

Epoch: 6| Step: 3
Training loss: 0.0782515157070619
Validation loss: 2.4599257898029636

Epoch: 6| Step: 4
Training loss: 0.08961851455853885
Validation loss: 2.4589395330099912

Epoch: 6| Step: 5
Training loss: 0.1165397224466401
Validation loss: 2.428859025922157

Epoch: 6| Step: 6
Training loss: 0.10581737314974046
Validation loss: 2.472388590199655

Epoch: 6| Step: 7
Training loss: 0.11409237287552772
Validation loss: 2.491066330898732

Epoch: 6| Step: 8
Training loss: 0.11745827703885077
Validation loss: 2.482762983988677

Epoch: 6| Step: 9
Training loss: 0.042414240896623066
Validation loss: 2.476909573406883

Epoch: 6| Step: 10
Training loss: 0.09377331245170581
Validation loss: 2.502996024606297

Epoch: 6| Step: 11
Training loss: 0.09737583909695428
Validation loss: 2.4791815772728008

Epoch: 6| Step: 12
Training loss: 0.06516519150112077
Validation loss: 2.4639574945379628

Epoch: 6| Step: 13
Training loss: 0.04380063640089484
Validation loss: 2.4858382436912767

Epoch: 718| Step: 0
Training loss: 0.058126217479414516
Validation loss: 2.484772798227188

Epoch: 6| Step: 1
Training loss: 0.13518721523466554
Validation loss: 2.480796603549435

Epoch: 6| Step: 2
Training loss: 0.11475529735259726
Validation loss: 2.467614152082325

Epoch: 6| Step: 3
Training loss: 0.08797574954279322
Validation loss: 2.462507733947692

Epoch: 6| Step: 4
Training loss: 0.08517978970622019
Validation loss: 2.484704516189322

Epoch: 6| Step: 5
Training loss: 0.05431525807708586
Validation loss: 2.4703008438778387

Epoch: 6| Step: 6
Training loss: 0.10443773365964838
Validation loss: 2.4490382138497124

Epoch: 6| Step: 7
Training loss: 0.08834046639613718
Validation loss: 2.4912112451931345

Epoch: 6| Step: 8
Training loss: 0.07230555874399054
Validation loss: 2.432766115119427

Epoch: 6| Step: 9
Training loss: 0.13335751454553435
Validation loss: 2.4886535867190167

Epoch: 6| Step: 10
Training loss: 0.06210059082844188
Validation loss: 2.4818446427046514

Epoch: 6| Step: 11
Training loss: 0.05158010149851976
Validation loss: 2.455567413199305

Epoch: 6| Step: 12
Training loss: 0.08468231466824712
Validation loss: 2.4510550857095095

Epoch: 6| Step: 13
Training loss: 0.09504885265224998
Validation loss: 2.4415738727738794

Epoch: 719| Step: 0
Training loss: 0.07677802967433749
Validation loss: 2.432080606579079

Epoch: 6| Step: 1
Training loss: 0.061607286671691276
Validation loss: 2.4625300043965246

Epoch: 6| Step: 2
Training loss: 0.08091579740033969
Validation loss: 2.491442274449297

Epoch: 6| Step: 3
Training loss: 0.07395836365334243
Validation loss: 2.4436703972185483

Epoch: 6| Step: 4
Training loss: 0.09366921580169482
Validation loss: 2.48513953787337

Epoch: 6| Step: 5
Training loss: 0.08474661937039825
Validation loss: 2.4994979272207787

Epoch: 6| Step: 6
Training loss: 0.14400423466644854
Validation loss: 2.519041849783972

Epoch: 6| Step: 7
Training loss: 0.09563520512635208
Validation loss: 2.485138883330568

Epoch: 6| Step: 8
Training loss: 0.07024266165453551
Validation loss: 2.513000933154833

Epoch: 6| Step: 9
Training loss: 0.08341351267872898
Validation loss: 2.492978411582659

Epoch: 6| Step: 10
Training loss: 0.1101588786602891
Validation loss: 2.48530139807598

Epoch: 6| Step: 11
Training loss: 0.10332364597964372
Validation loss: 2.5095090931376633

Epoch: 6| Step: 12
Training loss: 0.08173905854214485
Validation loss: 2.488924578206568

Epoch: 6| Step: 13
Training loss: 0.05654113763272045
Validation loss: 2.4662194211419286

Epoch: 720| Step: 0
Training loss: 0.04876397687503614
Validation loss: 2.439544977878407

Epoch: 6| Step: 1
Training loss: 0.11604782486086802
Validation loss: 2.4830865679846053

Epoch: 6| Step: 2
Training loss: 0.07912149884514087
Validation loss: 2.4933360467176207

Epoch: 6| Step: 3
Training loss: 0.05343059289502312
Validation loss: 2.488954172548426

Epoch: 6| Step: 4
Training loss: 0.09226875563114208
Validation loss: 2.495581666462594

Epoch: 6| Step: 5
Training loss: 0.10153220715281476
Validation loss: 2.5054365931635845

Epoch: 6| Step: 6
Training loss: 0.10481687707354191
Validation loss: 2.4779374936121483

Epoch: 6| Step: 7
Training loss: 0.08938444949593995
Validation loss: 2.483452567193134

Epoch: 6| Step: 8
Training loss: 0.105732297107161
Validation loss: 2.485937800137041

Epoch: 6| Step: 9
Training loss: 0.07873292667883545
Validation loss: 2.4540989895623957

Epoch: 6| Step: 10
Training loss: 0.1074120343642706
Validation loss: 2.4503126083513718

Epoch: 6| Step: 11
Training loss: 0.08475227602431529
Validation loss: 2.5085875490037566

Epoch: 6| Step: 12
Training loss: 0.07015049337290398
Validation loss: 2.4495307598150897

Epoch: 6| Step: 13
Training loss: 0.1247133118997803
Validation loss: 2.4927616245656274

Epoch: 721| Step: 0
Training loss: 0.07669729195883117
Validation loss: 2.501501147464321

Epoch: 6| Step: 1
Training loss: 0.06254107645379159
Validation loss: 2.485304618482521

Epoch: 6| Step: 2
Training loss: 0.07402512742179408
Validation loss: 2.4685830147675616

Epoch: 6| Step: 3
Training loss: 0.08670210979373974
Validation loss: 2.5042602284756503

Epoch: 6| Step: 4
Training loss: 0.05121719777464905
Validation loss: 2.4809830911110273

Epoch: 6| Step: 5
Training loss: 0.053711791465212794
Validation loss: 2.5134703347916685

Epoch: 6| Step: 6
Training loss: 0.1495245045403061
Validation loss: 2.4826309212770163

Epoch: 6| Step: 7
Training loss: 0.07465743930842574
Validation loss: 2.511420666531052

Epoch: 6| Step: 8
Training loss: 0.12465672744254072
Validation loss: 2.5404413939018737

Epoch: 6| Step: 9
Training loss: 0.07127751949345291
Validation loss: 2.491083068675122

Epoch: 6| Step: 10
Training loss: 0.08186019933853081
Validation loss: 2.5157410346416107

Epoch: 6| Step: 11
Training loss: 0.0983777619932062
Validation loss: 2.47762103116151

Epoch: 6| Step: 12
Training loss: 0.12906337323251285
Validation loss: 2.4796443381486504

Epoch: 6| Step: 13
Training loss: 0.11911318807016878
Validation loss: 2.476858149146212

Epoch: 722| Step: 0
Training loss: 0.11508943850447836
Validation loss: 2.471026237151459

Epoch: 6| Step: 1
Training loss: 0.10403836713654332
Validation loss: 2.4729396627384816

Epoch: 6| Step: 2
Training loss: 0.057074214970287855
Validation loss: 2.4891859051332315

Epoch: 6| Step: 3
Training loss: 0.10885541833799807
Validation loss: 2.4821676323505826

Epoch: 6| Step: 4
Training loss: 0.06815570053139708
Validation loss: 2.4946310905491442

Epoch: 6| Step: 5
Training loss: 0.10935983382389176
Validation loss: 2.453672606195317

Epoch: 6| Step: 6
Training loss: 0.1109585147752447
Validation loss: 2.480783168356035

Epoch: 6| Step: 7
Training loss: 0.06082254381196733
Validation loss: 2.46679959577833

Epoch: 6| Step: 8
Training loss: 0.11232223373672921
Validation loss: 2.4869789582681765

Epoch: 6| Step: 9
Training loss: 0.11621425928449255
Validation loss: 2.4720825469099945

Epoch: 6| Step: 10
Training loss: 0.055625318545731314
Validation loss: 2.4575156500875535

Epoch: 6| Step: 11
Training loss: 0.08172085199059662
Validation loss: 2.482317215131851

Epoch: 6| Step: 12
Training loss: 0.07186217063969999
Validation loss: 2.4589598559336445

Epoch: 6| Step: 13
Training loss: 0.0760490301101941
Validation loss: 2.489055314107179

Epoch: 723| Step: 0
Training loss: 0.10047078717155321
Validation loss: 2.5293868710506464

Epoch: 6| Step: 1
Training loss: 0.11402712871200223
Validation loss: 2.4817284064129095

Epoch: 6| Step: 2
Training loss: 0.05609131482013257
Validation loss: 2.4960326031722007

Epoch: 6| Step: 3
Training loss: 0.09004974074356836
Validation loss: 2.5028436485210346

Epoch: 6| Step: 4
Training loss: 0.1084872002651985
Validation loss: 2.4850046406436808

Epoch: 6| Step: 5
Training loss: 0.07190370789742204
Validation loss: 2.504723165470271

Epoch: 6| Step: 6
Training loss: 0.08032569761973579
Validation loss: 2.4995042822159204

Epoch: 6| Step: 7
Training loss: 0.07077003008502478
Validation loss: 2.519922380358017

Epoch: 6| Step: 8
Training loss: 0.1328447807575332
Validation loss: 2.4955308550282425

Epoch: 6| Step: 9
Training loss: 0.10559147740859715
Validation loss: 2.4921652044882543

Epoch: 6| Step: 10
Training loss: 0.052589721435300364
Validation loss: 2.4724818422845707

Epoch: 6| Step: 11
Training loss: 0.0586850508011495
Validation loss: 2.4555537376544945

Epoch: 6| Step: 12
Training loss: 0.049593017539664976
Validation loss: 2.48401011303104

Epoch: 6| Step: 13
Training loss: 0.17369785142027064
Validation loss: 2.4637340016251255

Epoch: 724| Step: 0
Training loss: 0.11057394120970601
Validation loss: 2.48104714763734

Epoch: 6| Step: 1
Training loss: 0.10658425703305853
Validation loss: 2.459693089083406

Epoch: 6| Step: 2
Training loss: 0.1615188597984134
Validation loss: 2.469868670413015

Epoch: 6| Step: 3
Training loss: 0.09990158416369785
Validation loss: 2.4690316048602643

Epoch: 6| Step: 4
Training loss: 0.10451869984770246
Validation loss: 2.481969377481016

Epoch: 6| Step: 5
Training loss: 0.1138221471705271
Validation loss: 2.4831381007150863

Epoch: 6| Step: 6
Training loss: 0.13434139458037164
Validation loss: 2.471689665400154

Epoch: 6| Step: 7
Training loss: 0.0948127030472288
Validation loss: 2.4939133556803723

Epoch: 6| Step: 8
Training loss: 0.1914024741909746
Validation loss: 2.47641760946799

Epoch: 6| Step: 9
Training loss: 0.10932692680421949
Validation loss: 2.4646058841556715

Epoch: 6| Step: 10
Training loss: 0.12711668482360988
Validation loss: 2.486537754285044

Epoch: 6| Step: 11
Training loss: 0.13748574372642175
Validation loss: 2.463813611847803

Epoch: 6| Step: 12
Training loss: 0.09933483399180634
Validation loss: 2.4414160670585554

Epoch: 6| Step: 13
Training loss: 0.0680109134429427
Validation loss: 2.4487210730907734

Epoch: 725| Step: 0
Training loss: 0.06512823693043579
Validation loss: 2.4586857069897756

Epoch: 6| Step: 1
Training loss: 0.11167488971130035
Validation loss: 2.4459652284256213

Epoch: 6| Step: 2
Training loss: 0.12978515682407032
Validation loss: 2.4567767489005097

Epoch: 6| Step: 3
Training loss: 0.1087004218256832
Validation loss: 2.473969781629998

Epoch: 6| Step: 4
Training loss: 0.17079153259432928
Validation loss: 2.448418234968772

Epoch: 6| Step: 5
Training loss: 0.10777244584006515
Validation loss: 2.4449700268346946

Epoch: 6| Step: 6
Training loss: 0.08161271418989455
Validation loss: 2.4754967847748084

Epoch: 6| Step: 7
Training loss: 0.08740400866835417
Validation loss: 2.4871097083101428

Epoch: 6| Step: 8
Training loss: 0.16058528816502007
Validation loss: 2.468733497108597

Epoch: 6| Step: 9
Training loss: 0.08697261605988917
Validation loss: 2.4874204395647426

Epoch: 6| Step: 10
Training loss: 0.13660281579192934
Validation loss: 2.458657751338656

Epoch: 6| Step: 11
Training loss: 0.1116978462376376
Validation loss: 2.4702801628160302

Epoch: 6| Step: 12
Training loss: 0.08236513704719917
Validation loss: 2.4781483090567393

Epoch: 6| Step: 13
Training loss: 0.12863069038482536
Validation loss: 2.505111011593785

Epoch: 726| Step: 0
Training loss: 0.12844327670005462
Validation loss: 2.4785159208226974

Epoch: 6| Step: 1
Training loss: 0.17060121029810785
Validation loss: 2.497063562205514

Epoch: 6| Step: 2
Training loss: 0.17183988385829696
Validation loss: 2.472205771813624

Epoch: 6| Step: 3
Training loss: 0.09081084704552048
Validation loss: 2.4570425978781207

Epoch: 6| Step: 4
Training loss: 0.09014826459906908
Validation loss: 2.4256494596039775

Epoch: 6| Step: 5
Training loss: 0.11290099185479621
Validation loss: 2.441909373561522

Epoch: 6| Step: 6
Training loss: 0.11037355389517138
Validation loss: 2.427132691341792

Epoch: 6| Step: 7
Training loss: 0.14540984548890346
Validation loss: 2.4274692829726163

Epoch: 6| Step: 8
Training loss: 0.04869780315209145
Validation loss: 2.3999761245250943

Epoch: 6| Step: 9
Training loss: 0.13609740208566232
Validation loss: 2.458689748442861

Epoch: 6| Step: 10
Training loss: 0.09265859422403973
Validation loss: 2.4714471308587638

Epoch: 6| Step: 11
Training loss: 0.09262734002337696
Validation loss: 2.4857239154631703

Epoch: 6| Step: 12
Training loss: 0.15129086200600284
Validation loss: 2.4652492426988113

Epoch: 6| Step: 13
Training loss: 0.09656384781943084
Validation loss: 2.438502008729478

Epoch: 727| Step: 0
Training loss: 0.09127658140029266
Validation loss: 2.474653837736252

Epoch: 6| Step: 1
Training loss: 0.06321385011456022
Validation loss: 2.430421949094555

Epoch: 6| Step: 2
Training loss: 0.13075244862158214
Validation loss: 2.4517800750282266

Epoch: 6| Step: 3
Training loss: 0.11293512938881961
Validation loss: 2.475408019276441

Epoch: 6| Step: 4
Training loss: 0.11330721820603011
Validation loss: 2.4415301579359787

Epoch: 6| Step: 5
Training loss: 0.09519622816381922
Validation loss: 2.4315847472878724

Epoch: 6| Step: 6
Training loss: 0.11535194024871247
Validation loss: 2.4613702531907165

Epoch: 6| Step: 7
Training loss: 0.0964034691105031
Validation loss: 2.485033227340159

Epoch: 6| Step: 8
Training loss: 0.08961685700680277
Validation loss: 2.5077615806284577

Epoch: 6| Step: 9
Training loss: 0.09087374356278852
Validation loss: 2.4676547972076923

Epoch: 6| Step: 10
Training loss: 0.11497466271452174
Validation loss: 2.514902684657492

Epoch: 6| Step: 11
Training loss: 0.13906100572361868
Validation loss: 2.483789654788367

Epoch: 6| Step: 12
Training loss: 0.09112752208241442
Validation loss: 2.48274286158889

Epoch: 6| Step: 13
Training loss: 0.1685831344309941
Validation loss: 2.4695521907958793

Epoch: 728| Step: 0
Training loss: 0.05055516837137033
Validation loss: 2.457833931991815

Epoch: 6| Step: 1
Training loss: 0.13651124329470105
Validation loss: 2.4915340128855803

Epoch: 6| Step: 2
Training loss: 0.12126992853326611
Validation loss: 2.4736611782467395

Epoch: 6| Step: 3
Training loss: 0.06681307824797234
Validation loss: 2.4897069239169887

Epoch: 6| Step: 4
Training loss: 0.13037563701814153
Validation loss: 2.492650204628802

Epoch: 6| Step: 5
Training loss: 0.08473205154229334
Validation loss: 2.4759739535243623

Epoch: 6| Step: 6
Training loss: 0.09828987556777981
Validation loss: 2.483261173447232

Epoch: 6| Step: 7
Training loss: 0.0861932460330096
Validation loss: 2.475695114121461

Epoch: 6| Step: 8
Training loss: 0.050890765482884605
Validation loss: 2.4568486239636553

Epoch: 6| Step: 9
Training loss: 0.09553586200803278
Validation loss: 2.4239759993128316

Epoch: 6| Step: 10
Training loss: 0.13260499086321145
Validation loss: 2.4724216046260126

Epoch: 6| Step: 11
Training loss: 0.08287713760410463
Validation loss: 2.471770229763667

Epoch: 6| Step: 12
Training loss: 0.09806147424892002
Validation loss: 2.507025991641435

Epoch: 6| Step: 13
Training loss: 0.04689783791669216
Validation loss: 2.46788892245218

Epoch: 729| Step: 0
Training loss: 0.06454573826561125
Validation loss: 2.4538762212289646

Epoch: 6| Step: 1
Training loss: 0.13403708030220884
Validation loss: 2.459139234185144

Epoch: 6| Step: 2
Training loss: 0.11564795581944348
Validation loss: 2.4751685927730844

Epoch: 6| Step: 3
Training loss: 0.11833970359646623
Validation loss: 2.4864623740761944

Epoch: 6| Step: 4
Training loss: 0.07455470881061556
Validation loss: 2.489413199264497

Epoch: 6| Step: 5
Training loss: 0.14096075612554249
Validation loss: 2.4739066791593056

Epoch: 6| Step: 6
Training loss: 0.059201148047956356
Validation loss: 2.4867646482019627

Epoch: 6| Step: 7
Training loss: 0.07636101788040847
Validation loss: 2.457508024401784

Epoch: 6| Step: 8
Training loss: 0.0750441704262122
Validation loss: 2.457339383250221

Epoch: 6| Step: 9
Training loss: 0.08357284877302358
Validation loss: 2.4877034239199767

Epoch: 6| Step: 10
Training loss: 0.08161504495320178
Validation loss: 2.488294240838713

Epoch: 6| Step: 11
Training loss: 0.05746263043822611
Validation loss: 2.4728465093004113

Epoch: 6| Step: 12
Training loss: 0.10074486260414173
Validation loss: 2.5088748005141017

Epoch: 6| Step: 13
Training loss: 0.15761426547153326
Validation loss: 2.4755492055867263

Epoch: 730| Step: 0
Training loss: 0.08900925002255214
Validation loss: 2.4933960412905964

Epoch: 6| Step: 1
Training loss: 0.10698687301701168
Validation loss: 2.498057887750519

Epoch: 6| Step: 2
Training loss: 0.06272132250818223
Validation loss: 2.450262451638365

Epoch: 6| Step: 3
Training loss: 0.14165342630777905
Validation loss: 2.4900587275643584

Epoch: 6| Step: 4
Training loss: 0.09750109267692351
Validation loss: 2.4602783560053334

Epoch: 6| Step: 5
Training loss: 0.06558296412713835
Validation loss: 2.479665382571392

Epoch: 6| Step: 6
Training loss: 0.11104146122540667
Validation loss: 2.4549874882005076

Epoch: 6| Step: 7
Training loss: 0.1335312384755607
Validation loss: 2.4653220520557824

Epoch: 6| Step: 8
Training loss: 0.13828967709914153
Validation loss: 2.441714424224262

Epoch: 6| Step: 9
Training loss: 0.10322427234088305
Validation loss: 2.511416499650571

Epoch: 6| Step: 10
Training loss: 0.0894764513727669
Validation loss: 2.494126524703772

Epoch: 6| Step: 11
Training loss: 0.06598649877842584
Validation loss: 2.455645376652965

Epoch: 6| Step: 12
Training loss: 0.09303561859201771
Validation loss: 2.4845280619797903

Epoch: 6| Step: 13
Training loss: 0.12934230974238362
Validation loss: 2.471730748616659

Epoch: 731| Step: 0
Training loss: 0.1565610174386799
Validation loss: 2.4656314304055376

Epoch: 6| Step: 1
Training loss: 0.12279873380723674
Validation loss: 2.4484595851105144

Epoch: 6| Step: 2
Training loss: 0.0788592671984485
Validation loss: 2.430670773597225

Epoch: 6| Step: 3
Training loss: 0.11085503427880136
Validation loss: 2.468624350113912

Epoch: 6| Step: 4
Training loss: 0.09863349234469446
Validation loss: 2.4424827368831923

Epoch: 6| Step: 5
Training loss: 0.06609190844727607
Validation loss: 2.456101422352577

Epoch: 6| Step: 6
Training loss: 0.12440093853058298
Validation loss: 2.4631938673641236

Epoch: 6| Step: 7
Training loss: 0.1266267542741067
Validation loss: 2.418454230115138

Epoch: 6| Step: 8
Training loss: 0.07182570210296092
Validation loss: 2.4401217429016744

Epoch: 6| Step: 9
Training loss: 0.08453335262740244
Validation loss: 2.402828903558461

Epoch: 6| Step: 10
Training loss: 0.04959371706397219
Validation loss: 2.454034212906193

Epoch: 6| Step: 11
Training loss: 0.08528716660950456
Validation loss: 2.42694461374504

Epoch: 6| Step: 12
Training loss: 0.08465262079222162
Validation loss: 2.4361288843632067

Epoch: 6| Step: 13
Training loss: 0.07548630441640947
Validation loss: 2.415098314352205

Epoch: 732| Step: 0
Training loss: 0.0600529450962393
Validation loss: 2.411011991139002

Epoch: 6| Step: 1
Training loss: 0.07016942912527666
Validation loss: 2.412468875065981

Epoch: 6| Step: 2
Training loss: 0.08185624573943422
Validation loss: 2.3946633366316727

Epoch: 6| Step: 3
Training loss: 0.0885409718607774
Validation loss: 2.3948221634683327

Epoch: 6| Step: 4
Training loss: 0.11629048998504035
Validation loss: 2.391079985825215

Epoch: 6| Step: 5
Training loss: 0.05378124880153449
Validation loss: 2.4114224312003216

Epoch: 6| Step: 6
Training loss: 0.11685097376042665
Validation loss: 2.4170097702280113

Epoch: 6| Step: 7
Training loss: 0.15588515720946997
Validation loss: 2.427647425048388

Epoch: 6| Step: 8
Training loss: 0.15015985692958642
Validation loss: 2.4434817517700593

Epoch: 6| Step: 9
Training loss: 0.11188475006921152
Validation loss: 2.421402760331513

Epoch: 6| Step: 10
Training loss: 0.061603412796925945
Validation loss: 2.413097565340814

Epoch: 6| Step: 11
Training loss: 0.06112010765901486
Validation loss: 2.447159947659038

Epoch: 6| Step: 12
Training loss: 0.10294643045151163
Validation loss: 2.4120587650559693

Epoch: 6| Step: 13
Training loss: 0.14233013690963342
Validation loss: 2.450677963153048

Epoch: 733| Step: 0
Training loss: 0.04964736794010739
Validation loss: 2.4161953372757368

Epoch: 6| Step: 1
Training loss: 0.07471668579946888
Validation loss: 2.4492427165780906

Epoch: 6| Step: 2
Training loss: 0.11079612575563333
Validation loss: 2.4765606491316414

Epoch: 6| Step: 3
Training loss: 0.07396133857764169
Validation loss: 2.4647986578546006

Epoch: 6| Step: 4
Training loss: 0.11627057092177122
Validation loss: 2.487741079534697

Epoch: 6| Step: 5
Training loss: 0.107024611315927
Validation loss: 2.436857712618199

Epoch: 6| Step: 6
Training loss: 0.09280332284728948
Validation loss: 2.492611209508338

Epoch: 6| Step: 7
Training loss: 0.1161115285293566
Validation loss: 2.4597108647698303

Epoch: 6| Step: 8
Training loss: 0.06328253803590655
Validation loss: 2.4693379655416408

Epoch: 6| Step: 9
Training loss: 0.06773102323583553
Validation loss: 2.4436697273717587

Epoch: 6| Step: 10
Training loss: 0.08689377044221201
Validation loss: 2.456658184886011

Epoch: 6| Step: 11
Training loss: 0.1349792238977606
Validation loss: 2.479986660293285

Epoch: 6| Step: 12
Training loss: 0.09395943037927111
Validation loss: 2.4679075096133496

Epoch: 6| Step: 13
Training loss: 0.14396476562398514
Validation loss: 2.4590723968301242

Epoch: 734| Step: 0
Training loss: 0.07575503638217294
Validation loss: 2.477864559882016

Epoch: 6| Step: 1
Training loss: 0.11859369201935166
Validation loss: 2.440222121271599

Epoch: 6| Step: 2
Training loss: 0.12449219494506315
Validation loss: 2.4476509307821024

Epoch: 6| Step: 3
Training loss: 0.0514277650354155
Validation loss: 2.4584472109150988

Epoch: 6| Step: 4
Training loss: 0.09764437126393478
Validation loss: 2.4741613993612495

Epoch: 6| Step: 5
Training loss: 0.1106317431945932
Validation loss: 2.4575350042012976

Epoch: 6| Step: 6
Training loss: 0.09024688212921306
Validation loss: 2.463432601147891

Epoch: 6| Step: 7
Training loss: 0.11673809744616356
Validation loss: 2.4370440878927853

Epoch: 6| Step: 8
Training loss: 0.10572752289676556
Validation loss: 2.4604781641959015

Epoch: 6| Step: 9
Training loss: 0.07325039499708506
Validation loss: 2.458276317999655

Epoch: 6| Step: 10
Training loss: 0.05862871557277528
Validation loss: 2.471174599100594

Epoch: 6| Step: 11
Training loss: 0.08270977313230198
Validation loss: 2.4713676923652295

Epoch: 6| Step: 12
Training loss: 0.10791986948201371
Validation loss: 2.4680353441043543

Epoch: 6| Step: 13
Training loss: 0.06605799249381399
Validation loss: 2.479232799268074

Epoch: 735| Step: 0
Training loss: 0.12772279856075067
Validation loss: 2.4617483329080443

Epoch: 6| Step: 1
Training loss: 0.12305063287355421
Validation loss: 2.486074877219192

Epoch: 6| Step: 2
Training loss: 0.07906020225231723
Validation loss: 2.4901439481592065

Epoch: 6| Step: 3
Training loss: 0.060188360669938316
Validation loss: 2.4684460111279796

Epoch: 6| Step: 4
Training loss: 0.08857945087124898
Validation loss: 2.486514377096857

Epoch: 6| Step: 5
Training loss: 0.07791905378390468
Validation loss: 2.46531307371012

Epoch: 6| Step: 6
Training loss: 0.05857567905871098
Validation loss: 2.48103122304095

Epoch: 6| Step: 7
Training loss: 0.07679836303767244
Validation loss: 2.436948772288629

Epoch: 6| Step: 8
Training loss: 0.05971669363167323
Validation loss: 2.4506978828027615

Epoch: 6| Step: 9
Training loss: 0.08160983559107642
Validation loss: 2.4755136806376874

Epoch: 6| Step: 10
Training loss: 0.044479199993141906
Validation loss: 2.4425630439446793

Epoch: 6| Step: 11
Training loss: 0.05777591525587868
Validation loss: 2.431531955376122

Epoch: 6| Step: 12
Training loss: 0.06432884690262106
Validation loss: 2.4238852545191216

Epoch: 6| Step: 13
Training loss: 0.03905041776006947
Validation loss: 2.4613827892567848

Epoch: 736| Step: 0
Training loss: 0.08441018126081028
Validation loss: 2.4500457832222433

Epoch: 6| Step: 1
Training loss: 0.07161493807040123
Validation loss: 2.42852490550223

Epoch: 6| Step: 2
Training loss: 0.054806214295679175
Validation loss: 2.4337012188661715

Epoch: 6| Step: 3
Training loss: 0.07543183569118543
Validation loss: 2.460362090699506

Epoch: 6| Step: 4
Training loss: 0.0670990844537253
Validation loss: 2.4083458081289337

Epoch: 6| Step: 5
Training loss: 0.09480727581613681
Validation loss: 2.4578407764682493

Epoch: 6| Step: 6
Training loss: 0.1357344412480181
Validation loss: 2.505422111332005

Epoch: 6| Step: 7
Training loss: 0.08062243391913994
Validation loss: 2.4995322107715943

Epoch: 6| Step: 8
Training loss: 0.09469846918443325
Validation loss: 2.4565876911664057

Epoch: 6| Step: 9
Training loss: 0.07249121637410247
Validation loss: 2.4622293602887204

Epoch: 6| Step: 10
Training loss: 0.10827611774815811
Validation loss: 2.4977967736636093

Epoch: 6| Step: 11
Training loss: 0.10191245034998116
Validation loss: 2.424906393447022

Epoch: 6| Step: 12
Training loss: 0.0485915772337139
Validation loss: 2.4474689958370384

Epoch: 6| Step: 13
Training loss: 0.07224295234708454
Validation loss: 2.4821684910139283

Epoch: 737| Step: 0
Training loss: 0.10358359246779078
Validation loss: 2.4306609985715637

Epoch: 6| Step: 1
Training loss: 0.06245201474143669
Validation loss: 2.4408055557740873

Epoch: 6| Step: 2
Training loss: 0.1115255153549287
Validation loss: 2.427385397928972

Epoch: 6| Step: 3
Training loss: 0.06644238863056207
Validation loss: 2.4562166409352604

Epoch: 6| Step: 4
Training loss: 0.0590947527627627
Validation loss: 2.422844795355518

Epoch: 6| Step: 5
Training loss: 0.090277103529556
Validation loss: 2.410795418122324

Epoch: 6| Step: 6
Training loss: 0.10693820089927632
Validation loss: 2.416575141194797

Epoch: 6| Step: 7
Training loss: 0.08588058852195778
Validation loss: 2.4123196641103397

Epoch: 6| Step: 8
Training loss: 0.07275241811881714
Validation loss: 2.4141167804729613

Epoch: 6| Step: 9
Training loss: 0.06379078340048679
Validation loss: 2.4406146944291227

Epoch: 6| Step: 10
Training loss: 0.04381778810612031
Validation loss: 2.3794496063465553

Epoch: 6| Step: 11
Training loss: 0.03613564763673915
Validation loss: 2.413135324362208

Epoch: 6| Step: 12
Training loss: 0.1074639021417037
Validation loss: 2.4027112624845905

Epoch: 6| Step: 13
Training loss: 0.07414494157210033
Validation loss: 2.3954711818690684

Epoch: 738| Step: 0
Training loss: 0.0962385168749698
Validation loss: 2.4052002365125316

Epoch: 6| Step: 1
Training loss: 0.056177857034697395
Validation loss: 2.420234629044458

Epoch: 6| Step: 2
Training loss: 0.08635786049289389
Validation loss: 2.4155836518066196

Epoch: 6| Step: 3
Training loss: 0.05727922600720211
Validation loss: 2.4092729914215956

Epoch: 6| Step: 4
Training loss: 0.15628979891312986
Validation loss: 2.400048089827427

Epoch: 6| Step: 5
Training loss: 0.0519869832085997
Validation loss: 2.368423513398484

Epoch: 6| Step: 6
Training loss: 0.04369652979186933
Validation loss: 2.4034051249443893

Epoch: 6| Step: 7
Training loss: 0.06625894730132183
Validation loss: 2.405571259987115

Epoch: 6| Step: 8
Training loss: 0.08366454293122626
Validation loss: 2.405712232465361

Epoch: 6| Step: 9
Training loss: 0.09770409365743761
Validation loss: 2.385515896526745

Epoch: 6| Step: 10
Training loss: 0.11378119576706153
Validation loss: 2.4570629244929294

Epoch: 6| Step: 11
Training loss: 0.04566129844954158
Validation loss: 2.474703422394998

Epoch: 6| Step: 12
Training loss: 0.10658167058328985
Validation loss: 2.45327795307033

Epoch: 6| Step: 13
Training loss: 0.14150429377427096
Validation loss: 2.4287629779691042

Epoch: 739| Step: 0
Training loss: 0.08382092139195098
Validation loss: 2.4543626227745787

Epoch: 6| Step: 1
Training loss: 0.10052849694260019
Validation loss: 2.449817167051887

Epoch: 6| Step: 2
Training loss: 0.06423113988242565
Validation loss: 2.4455354278284265

Epoch: 6| Step: 3
Training loss: 0.04609242241370017
Validation loss: 2.440264599922347

Epoch: 6| Step: 4
Training loss: 0.06654777592346743
Validation loss: 2.4398542771700016

Epoch: 6| Step: 5
Training loss: 0.09822604367158509
Validation loss: 2.4549372620036025

Epoch: 6| Step: 6
Training loss: 0.07943070773417521
Validation loss: 2.443406772357916

Epoch: 6| Step: 7
Training loss: 0.0824645383980158
Validation loss: 2.4609799085987665

Epoch: 6| Step: 8
Training loss: 0.09389631456824951
Validation loss: 2.476352225053084

Epoch: 6| Step: 9
Training loss: 0.1017681845066801
Validation loss: 2.448228042756511

Epoch: 6| Step: 10
Training loss: 0.0819161777377858
Validation loss: 2.450596538515185

Epoch: 6| Step: 11
Training loss: 0.08358325647286094
Validation loss: 2.4339407509818143

Epoch: 6| Step: 12
Training loss: 0.07216101885253015
Validation loss: 2.4382220771875422

Epoch: 6| Step: 13
Training loss: 0.09927826902178613
Validation loss: 2.4457222560729037

Epoch: 740| Step: 0
Training loss: 0.03525262114383134
Validation loss: 2.4455108577852473

Epoch: 6| Step: 1
Training loss: 0.057501924115879136
Validation loss: 2.455968571085262

Epoch: 6| Step: 2
Training loss: 0.04104392460499396
Validation loss: 2.4593564169842113

Epoch: 6| Step: 3
Training loss: 0.12244756768600253
Validation loss: 2.421063291167377

Epoch: 6| Step: 4
Training loss: 0.07653076647936354
Validation loss: 2.4377181752483263

Epoch: 6| Step: 5
Training loss: 0.058009204141383386
Validation loss: 2.4272097599064795

Epoch: 6| Step: 6
Training loss: 0.09052004450369093
Validation loss: 2.455728668009967

Epoch: 6| Step: 7
Training loss: 0.0680400816639272
Validation loss: 2.413390222139087

Epoch: 6| Step: 8
Training loss: 0.13429446024607258
Validation loss: 2.4057288322617847

Epoch: 6| Step: 9
Training loss: 0.11850651071665744
Validation loss: 2.388054867413564

Epoch: 6| Step: 10
Training loss: 0.08934388841309422
Validation loss: 2.4468612067651403

Epoch: 6| Step: 11
Training loss: 0.07159611796247382
Validation loss: 2.4536779943144196

Epoch: 6| Step: 12
Training loss: 0.05746781658744226
Validation loss: 2.4204769294985975

Epoch: 6| Step: 13
Training loss: 0.08673152614677919
Validation loss: 2.425082217320648

Epoch: 741| Step: 0
Training loss: 0.1128150167012774
Validation loss: 2.410618074707338

Epoch: 6| Step: 1
Training loss: 0.06551260462630473
Validation loss: 2.450166675087347

Epoch: 6| Step: 2
Training loss: 0.05718873021686471
Validation loss: 2.428557067380361

Epoch: 6| Step: 3
Training loss: 0.13643193814714297
Validation loss: 2.4673349258786956

Epoch: 6| Step: 4
Training loss: 0.03576801414434373
Validation loss: 2.4481861567471817

Epoch: 6| Step: 5
Training loss: 0.11959461577066953
Validation loss: 2.457270086945266

Epoch: 6| Step: 6
Training loss: 0.12059802831641131
Validation loss: 2.4769072083945662

Epoch: 6| Step: 7
Training loss: 0.07047682673040345
Validation loss: 2.4702164362856847

Epoch: 6| Step: 8
Training loss: 0.12235286817517128
Validation loss: 2.440556377193888

Epoch: 6| Step: 9
Training loss: 0.05834640709617023
Validation loss: 2.5042677251056173

Epoch: 6| Step: 10
Training loss: 0.09115528046377135
Validation loss: 2.4689937152973864

Epoch: 6| Step: 11
Training loss: 0.07172966366051052
Validation loss: 2.4574682452698617

Epoch: 6| Step: 12
Training loss: 0.10563023002643976
Validation loss: 2.4220504395515756

Epoch: 6| Step: 13
Training loss: 0.06104824307331593
Validation loss: 2.4415371284433913

Epoch: 742| Step: 0
Training loss: 0.08989329630467988
Validation loss: 2.4527495743370373

Epoch: 6| Step: 1
Training loss: 0.08199452247856925
Validation loss: 2.4595472600272354

Epoch: 6| Step: 2
Training loss: 0.06241736686407277
Validation loss: 2.465033910292995

Epoch: 6| Step: 3
Training loss: 0.09874776713194842
Validation loss: 2.4746703270453523

Epoch: 6| Step: 4
Training loss: 0.07366050154069011
Validation loss: 2.4767403518520847

Epoch: 6| Step: 5
Training loss: 0.11506514326475292
Validation loss: 2.4413277604150534

Epoch: 6| Step: 6
Training loss: 0.07690897427821428
Validation loss: 2.4962675041928204

Epoch: 6| Step: 7
Training loss: 0.06974163707230924
Validation loss: 2.4837459883152833

Epoch: 6| Step: 8
Training loss: 0.08206034609810799
Validation loss: 2.5177480433974107

Epoch: 6| Step: 9
Training loss: 0.14026766650174013
Validation loss: 2.5172726929190703

Epoch: 6| Step: 10
Training loss: 0.11380368649148614
Validation loss: 2.4929076383671345

Epoch: 6| Step: 11
Training loss: 0.09471976855582095
Validation loss: 2.522985144225826

Epoch: 6| Step: 12
Training loss: 0.07188202237985504
Validation loss: 2.4935278885585475

Epoch: 6| Step: 13
Training loss: 0.09961543812717936
Validation loss: 2.4470633854745145

Epoch: 743| Step: 0
Training loss: 0.06831910786621803
Validation loss: 2.4558838180861953

Epoch: 6| Step: 1
Training loss: 0.06370237240266055
Validation loss: 2.4603702358199957

Epoch: 6| Step: 2
Training loss: 0.127851229188498
Validation loss: 2.4809292361398674

Epoch: 6| Step: 3
Training loss: 0.08814052710893723
Validation loss: 2.471178230579104

Epoch: 6| Step: 4
Training loss: 0.09798550413840995
Validation loss: 2.45422365641355

Epoch: 6| Step: 5
Training loss: 0.06814075661786267
Validation loss: 2.4554292354326543

Epoch: 6| Step: 6
Training loss: 0.10127523952423789
Validation loss: 2.463476218707657

Epoch: 6| Step: 7
Training loss: 0.09154927565081314
Validation loss: 2.439901423200409

Epoch: 6| Step: 8
Training loss: 0.07366923448335025
Validation loss: 2.455893165986951

Epoch: 6| Step: 9
Training loss: 0.09232548937357962
Validation loss: 2.440920830228717

Epoch: 6| Step: 10
Training loss: 0.07192673997753339
Validation loss: 2.4780929467354365

Epoch: 6| Step: 11
Training loss: 0.06329255944905836
Validation loss: 2.4755487002213896

Epoch: 6| Step: 12
Training loss: 0.08483137468144622
Validation loss: 2.477507201219759

Epoch: 6| Step: 13
Training loss: 0.12409431955095868
Validation loss: 2.484944934549728

Epoch: 744| Step: 0
Training loss: 0.058226253487332444
Validation loss: 2.489923612413191

Epoch: 6| Step: 1
Training loss: 0.06878421782633821
Validation loss: 2.486129267272935

Epoch: 6| Step: 2
Training loss: 0.09910308975047329
Validation loss: 2.5037834190209236

Epoch: 6| Step: 3
Training loss: 0.07906331797881543
Validation loss: 2.481069157645093

Epoch: 6| Step: 4
Training loss: 0.10711805554696854
Validation loss: 2.478091965491522

Epoch: 6| Step: 5
Training loss: 0.052063753003924955
Validation loss: 2.4725956630342356

Epoch: 6| Step: 6
Training loss: 0.09844555878576249
Validation loss: 2.4614736602868295

Epoch: 6| Step: 7
Training loss: 0.06839120328260857
Validation loss: 2.4685245388637274

Epoch: 6| Step: 8
Training loss: 0.1194855979930673
Validation loss: 2.4593845471121014

Epoch: 6| Step: 9
Training loss: 0.09611702478192415
Validation loss: 2.4705815009815866

Epoch: 6| Step: 10
Training loss: 0.10713407804789972
Validation loss: 2.4559778591647223

Epoch: 6| Step: 11
Training loss: 0.0928931317420286
Validation loss: 2.448941308037898

Epoch: 6| Step: 12
Training loss: 0.11695479494379311
Validation loss: 2.4358792065964647

Epoch: 6| Step: 13
Training loss: 0.05934602107103632
Validation loss: 2.4764760232199774

Epoch: 745| Step: 0
Training loss: 0.09015486587242048
Validation loss: 2.45171951277088

Epoch: 6| Step: 1
Training loss: 0.11890692929363333
Validation loss: 2.439260441828522

Epoch: 6| Step: 2
Training loss: 0.06490843158011711
Validation loss: 2.4243301274065474

Epoch: 6| Step: 3
Training loss: 0.08855429785987268
Validation loss: 2.452788235339009

Epoch: 6| Step: 4
Training loss: 0.06992337715410744
Validation loss: 2.414594081534911

Epoch: 6| Step: 5
Training loss: 0.1382055905361
Validation loss: 2.425509620790374

Epoch: 6| Step: 6
Training loss: 0.11770302310783728
Validation loss: 2.409472536083631

Epoch: 6| Step: 7
Training loss: 0.09347590472144968
Validation loss: 2.440119716254908

Epoch: 6| Step: 8
Training loss: 0.048604802602660535
Validation loss: 2.4348454836345286

Epoch: 6| Step: 9
Training loss: 0.06568790837913191
Validation loss: 2.4672844190416163

Epoch: 6| Step: 10
Training loss: 0.1110385382614477
Validation loss: 2.480986118726373

Epoch: 6| Step: 11
Training loss: 0.07616496360430446
Validation loss: 2.4469079783880345

Epoch: 6| Step: 12
Training loss: 0.07665170635134697
Validation loss: 2.4351633787061497

Epoch: 6| Step: 13
Training loss: 0.08191310230760185
Validation loss: 2.4270115320249017

Epoch: 746| Step: 0
Training loss: 0.10581695069006784
Validation loss: 2.419066617232209

Epoch: 6| Step: 1
Training loss: 0.0648833854599469
Validation loss: 2.394148025101182

Epoch: 6| Step: 2
Training loss: 0.11063479054898798
Validation loss: 2.4241690322936122

Epoch: 6| Step: 3
Training loss: 0.10454015433015902
Validation loss: 2.3856821345484094

Epoch: 6| Step: 4
Training loss: 0.0582527449970509
Validation loss: 2.4134638906615646

Epoch: 6| Step: 5
Training loss: 0.09767708556111597
Validation loss: 2.389402104227023

Epoch: 6| Step: 6
Training loss: 0.07496090058548949
Validation loss: 2.3964946306772075

Epoch: 6| Step: 7
Training loss: 0.06334996436960352
Validation loss: 2.417289401885221

Epoch: 6| Step: 8
Training loss: 0.07062727616448466
Validation loss: 2.40350198198062

Epoch: 6| Step: 9
Training loss: 0.09336162129496964
Validation loss: 2.414964261568564

Epoch: 6| Step: 10
Training loss: 0.10181501980702354
Validation loss: 2.409846736858244

Epoch: 6| Step: 11
Training loss: 0.13245299010310987
Validation loss: 2.4112253486941073

Epoch: 6| Step: 12
Training loss: 0.07836586360081234
Validation loss: 2.417965395380716

Epoch: 6| Step: 13
Training loss: 0.13925101008125926
Validation loss: 2.404355082224618

Epoch: 747| Step: 0
Training loss: 0.06221751359806072
Validation loss: 2.427105980935169

Epoch: 6| Step: 1
Training loss: 0.06037059432927389
Validation loss: 2.391735528071281

Epoch: 6| Step: 2
Training loss: 0.07018296575252031
Validation loss: 2.376595430269446

Epoch: 6| Step: 3
Training loss: 0.06886601372409294
Validation loss: 2.376460658688046

Epoch: 6| Step: 4
Training loss: 0.07504416422104924
Validation loss: 2.4158920383941727

Epoch: 6| Step: 5
Training loss: 0.1199839403413097
Validation loss: 2.4011462201768805

Epoch: 6| Step: 6
Training loss: 0.06792795763121921
Validation loss: 2.4081578132796335

Epoch: 6| Step: 7
Training loss: 0.1034905025298649
Validation loss: 2.4014819416450592

Epoch: 6| Step: 8
Training loss: 0.0957958297927574
Validation loss: 2.4143008167481805

Epoch: 6| Step: 9
Training loss: 0.1292642621402282
Validation loss: 2.437072709092201

Epoch: 6| Step: 10
Training loss: 0.06213355111187112
Validation loss: 2.4248614509397055

Epoch: 6| Step: 11
Training loss: 0.03835227347985662
Validation loss: 2.4344748189561476

Epoch: 6| Step: 12
Training loss: 0.0954146221134795
Validation loss: 2.4455969933725816

Epoch: 6| Step: 13
Training loss: 0.07572905805386272
Validation loss: 2.4619835415216524

Epoch: 748| Step: 0
Training loss: 0.10905622110354961
Validation loss: 2.466923321508768

Epoch: 6| Step: 1
Training loss: 0.06016729759667185
Validation loss: 2.4644260903231237

Epoch: 6| Step: 2
Training loss: 0.12557701209641797
Validation loss: 2.439773270450032

Epoch: 6| Step: 3
Training loss: 0.049621706372395
Validation loss: 2.455658623006174

Epoch: 6| Step: 4
Training loss: 0.09035879718035734
Validation loss: 2.474955817501823

Epoch: 6| Step: 5
Training loss: 0.07550691470872001
Validation loss: 2.4105315081252963

Epoch: 6| Step: 6
Training loss: 0.09363499680646106
Validation loss: 2.3903395399029748

Epoch: 6| Step: 7
Training loss: 0.09251420293003995
Validation loss: 2.4009326663340618

Epoch: 6| Step: 8
Training loss: 0.14221633445844262
Validation loss: 2.344397193944331

Epoch: 6| Step: 9
Training loss: 0.08718752167557887
Validation loss: 2.3811345408820497

Epoch: 6| Step: 10
Training loss: 0.10393459177335541
Validation loss: 2.371205637037554

Epoch: 6| Step: 11
Training loss: 0.15952794178998872
Validation loss: 2.407277352841575

Epoch: 6| Step: 12
Training loss: 0.06122238814651141
Validation loss: 2.3928700987293716

Epoch: 6| Step: 13
Training loss: 0.17996171055622132
Validation loss: 2.4248448058251237

Epoch: 749| Step: 0
Training loss: 0.08774360440047375
Validation loss: 2.4376286550792186

Epoch: 6| Step: 1
Training loss: 0.059335743167350526
Validation loss: 2.432959440648514

Epoch: 6| Step: 2
Training loss: 0.10198718923289242
Validation loss: 2.4397471166437743

Epoch: 6| Step: 3
Training loss: 0.12999354926482226
Validation loss: 2.4562615743835776

Epoch: 6| Step: 4
Training loss: 0.1616676125322607
Validation loss: 2.445577380202972

Epoch: 6| Step: 5
Training loss: 0.1145260669555502
Validation loss: 2.4246454678943907

Epoch: 6| Step: 6
Training loss: 0.11022784040698361
Validation loss: 2.4409045382925925

Epoch: 6| Step: 7
Training loss: 0.12116771408010511
Validation loss: 2.438832147488722

Epoch: 6| Step: 8
Training loss: 0.07538556207941356
Validation loss: 2.4274782217528266

Epoch: 6| Step: 9
Training loss: 0.12983449596520868
Validation loss: 2.4060963950679866

Epoch: 6| Step: 10
Training loss: 0.14844063705341815
Validation loss: 2.4381453062461254

Epoch: 6| Step: 11
Training loss: 0.12165853092946993
Validation loss: 2.470822340549259

Epoch: 6| Step: 12
Training loss: 0.14208974543302616
Validation loss: 2.431207238614834

Epoch: 6| Step: 13
Training loss: 0.1133111881289575
Validation loss: 2.4323119849324977

Epoch: 750| Step: 0
Training loss: 0.07593480840767543
Validation loss: 2.392839907433612

Epoch: 6| Step: 1
Training loss: 0.10604887818220209
Validation loss: 2.4250151707426615

Epoch: 6| Step: 2
Training loss: 0.10352202161782646
Validation loss: 2.4065061123147955

Epoch: 6| Step: 3
Training loss: 0.14439035971792302
Validation loss: 2.4160608169401434

Epoch: 6| Step: 4
Training loss: 0.0962904937746094
Validation loss: 2.429283260664945

Epoch: 6| Step: 5
Training loss: 0.13244299818600253
Validation loss: 2.402955404577658

Epoch: 6| Step: 6
Training loss: 0.11702742770259576
Validation loss: 2.414695299192714

Epoch: 6| Step: 7
Training loss: 0.13232792782248007
Validation loss: 2.4230914260149965

Epoch: 6| Step: 8
Training loss: 0.08289004554869585
Validation loss: 2.4414020297762584

Epoch: 6| Step: 9
Training loss: 0.07875865029705915
Validation loss: 2.4652188552623566

Epoch: 6| Step: 10
Training loss: 0.12408871697383105
Validation loss: 2.4740886915973146

Epoch: 6| Step: 11
Training loss: 0.11174154482554463
Validation loss: 2.4762760916870095

Epoch: 6| Step: 12
Training loss: 0.13521457609827622
Validation loss: 2.5013806724681764

Epoch: 6| Step: 13
Training loss: 0.14594065529028272
Validation loss: 2.5132431793081005

Testing loss: 2.453054404677166
