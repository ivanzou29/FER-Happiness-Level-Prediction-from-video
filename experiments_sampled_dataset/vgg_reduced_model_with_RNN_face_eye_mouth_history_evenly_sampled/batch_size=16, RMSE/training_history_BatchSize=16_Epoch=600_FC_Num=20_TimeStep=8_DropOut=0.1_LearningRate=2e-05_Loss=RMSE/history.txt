Epoch: 1| Step: 0
Training loss: 6.5908167674136635
Validation loss: 5.7951545892152385

Epoch: 6| Step: 1
Training loss: 6.1145640626914535
Validation loss: 5.778502546952911

Epoch: 6| Step: 2
Training loss: 5.16681176668915
Validation loss: 5.763018054545467

Epoch: 6| Step: 3
Training loss: 5.025311300020067
Validation loss: 5.745795376115001

Epoch: 6| Step: 4
Training loss: 5.400914552738401
Validation loss: 5.726023677718791

Epoch: 6| Step: 5
Training loss: 6.2893127012536425
Validation loss: 5.704286419692093

Epoch: 6| Step: 6
Training loss: 5.370694765010494
Validation loss: 5.679561230542759

Epoch: 6| Step: 7
Training loss: 6.1635677008513925
Validation loss: 5.653079652616562

Epoch: 6| Step: 8
Training loss: 5.32845146543827
Validation loss: 5.623820381031666

Epoch: 6| Step: 9
Training loss: 5.456551161382272
Validation loss: 5.59197136938655

Epoch: 6| Step: 10
Training loss: 5.257590846112595
Validation loss: 5.557027099036879

Epoch: 6| Step: 11
Training loss: 5.404212876560799
Validation loss: 5.520869191525965

Epoch: 6| Step: 12
Training loss: 5.606071498244793
Validation loss: 5.482437596058422

Epoch: 6| Step: 13
Training loss: 6.630534900934446
Validation loss: 5.4434204439587655

Epoch: 2| Step: 0
Training loss: 5.320611124718524
Validation loss: 5.40099505770873

Epoch: 6| Step: 1
Training loss: 5.99152920724008
Validation loss: 5.35861001889813

Epoch: 6| Step: 2
Training loss: 4.481178340578331
Validation loss: 5.312591530712893

Epoch: 6| Step: 3
Training loss: 5.454129801432043
Validation loss: 5.267021291301374

Epoch: 6| Step: 4
Training loss: 5.582994061690473
Validation loss: 5.215498905553349

Epoch: 6| Step: 5
Training loss: 4.88948489419055
Validation loss: 5.16616806313094

Epoch: 6| Step: 6
Training loss: 5.755221111116565
Validation loss: 5.114852006341202

Epoch: 6| Step: 7
Training loss: 5.3739179364814555
Validation loss: 5.05666693947777

Epoch: 6| Step: 8
Training loss: 5.9175191274123495
Validation loss: 4.99777808708869

Epoch: 6| Step: 9
Training loss: 5.538469506119434
Validation loss: 4.932300754951138

Epoch: 6| Step: 10
Training loss: 4.670512431291625
Validation loss: 4.856762593254743

Epoch: 6| Step: 11
Training loss: 4.049440491257568
Validation loss: 4.780432383283517

Epoch: 6| Step: 12
Training loss: 4.20145834172679
Validation loss: 4.721428241289711

Epoch: 6| Step: 13
Training loss: 3.5324924950003624
Validation loss: 4.665272905968015

Epoch: 3| Step: 0
Training loss: 4.061046633807951
Validation loss: 4.613800281647149

Epoch: 6| Step: 1
Training loss: 4.8240969746776186
Validation loss: 4.577325485891436

Epoch: 6| Step: 2
Training loss: 4.923296623187818
Validation loss: 4.540979315111655

Epoch: 6| Step: 3
Training loss: 4.933402377152362
Validation loss: 4.510444056543736

Epoch: 6| Step: 4
Training loss: 3.6360743819414285
Validation loss: 4.476312091826729

Epoch: 6| Step: 5
Training loss: 5.025525170966568
Validation loss: 4.445882018861892

Epoch: 6| Step: 6
Training loss: 5.04048247919253
Validation loss: 4.418461488144221

Epoch: 6| Step: 7
Training loss: 4.7446905879767085
Validation loss: 4.393137066964634

Epoch: 6| Step: 8
Training loss: 4.922163116257119
Validation loss: 4.36814681605702

Epoch: 6| Step: 9
Training loss: 4.199750148062661
Validation loss: 4.343979882618191

Epoch: 6| Step: 10
Training loss: 4.580151835094502
Validation loss: 4.323583394879514

Epoch: 6| Step: 11
Training loss: 3.9079963137512626
Validation loss: 4.301488365875262

Epoch: 6| Step: 12
Training loss: 4.010822675225682
Validation loss: 4.279160759491383

Epoch: 6| Step: 13
Training loss: 4.176679837469193
Validation loss: 4.262457661112768

Epoch: 4| Step: 0
Training loss: 4.130284709953821
Validation loss: 4.253295060230305

Epoch: 6| Step: 1
Training loss: 4.906541949290404
Validation loss: 4.238478902396124

Epoch: 6| Step: 2
Training loss: 5.02393638779526
Validation loss: 4.225455190340412

Epoch: 6| Step: 3
Training loss: 4.168173301418056
Validation loss: 4.205952294339536

Epoch: 6| Step: 4
Training loss: 3.8376042305276314
Validation loss: 4.192088190175748

Epoch: 6| Step: 5
Training loss: 3.7480275370788263
Validation loss: 4.182132917406717

Epoch: 6| Step: 6
Training loss: 5.184406139241172
Validation loss: 4.171537648583917

Epoch: 6| Step: 7
Training loss: 3.862432589143307
Validation loss: 4.151540215257478

Epoch: 6| Step: 8
Training loss: 4.018021517827475
Validation loss: 4.136688103095053

Epoch: 6| Step: 9
Training loss: 3.9374600363020305
Validation loss: 4.12169721203596

Epoch: 6| Step: 10
Training loss: 4.2321415602835515
Validation loss: 4.101869811905939

Epoch: 6| Step: 11
Training loss: 3.796416580720577
Validation loss: 4.0871276822379

Epoch: 6| Step: 12
Training loss: 4.43784062327423
Validation loss: 4.074338891823841

Epoch: 6| Step: 13
Training loss: 4.703187859707623
Validation loss: 4.069635941502685

Epoch: 5| Step: 0
Training loss: 3.3441437106212404
Validation loss: 4.055373789314377

Epoch: 6| Step: 1
Training loss: 3.961695130250902
Validation loss: 4.052992956553462

Epoch: 6| Step: 2
Training loss: 4.348280266383989
Validation loss: 4.028938542084177

Epoch: 6| Step: 3
Training loss: 4.6528779178806285
Validation loss: 4.015223788911124

Epoch: 6| Step: 4
Training loss: 4.249685836848891
Validation loss: 4.0064274922368535

Epoch: 6| Step: 5
Training loss: 4.672845337802803
Validation loss: 3.9989180806514546

Epoch: 6| Step: 6
Training loss: 4.096863472672808
Validation loss: 3.986693483796732

Epoch: 6| Step: 7
Training loss: 3.850270516936293
Validation loss: 3.9764730266660098

Epoch: 6| Step: 8
Training loss: 4.419679777533379
Validation loss: 3.9590990156057426

Epoch: 6| Step: 9
Training loss: 3.2148734145806337
Validation loss: 3.9431393072270833

Epoch: 6| Step: 10
Training loss: 3.7841470512705566
Validation loss: 3.9353715124755517

Epoch: 6| Step: 11
Training loss: 3.753962394302441
Validation loss: 3.9363125783059587

Epoch: 6| Step: 12
Training loss: 4.491051571733585
Validation loss: 3.9158714881851355

Epoch: 6| Step: 13
Training loss: 5.034431730929873
Validation loss: 3.9017424114313775

Epoch: 6| Step: 0
Training loss: 3.7804543154543997
Validation loss: 3.8900837533924157

Epoch: 6| Step: 1
Training loss: 4.5412359237557745
Validation loss: 3.887570063393526

Epoch: 6| Step: 2
Training loss: 4.0066344554281255
Validation loss: 3.8740403333012328

Epoch: 6| Step: 3
Training loss: 4.291002512283674
Validation loss: 3.860138598587089

Epoch: 6| Step: 4
Training loss: 4.429234718716253
Validation loss: 3.84419673548268

Epoch: 6| Step: 5
Training loss: 3.9148637937429664
Validation loss: 3.831936662503876

Epoch: 6| Step: 6
Training loss: 3.9771749628114743
Validation loss: 3.819952904848435

Epoch: 6| Step: 7
Training loss: 3.540831403784893
Validation loss: 3.8121645016770356

Epoch: 6| Step: 8
Training loss: 4.259547112976451
Validation loss: 3.7999672960084108

Epoch: 6| Step: 9
Training loss: 3.1800533899587724
Validation loss: 3.7847654103046557

Epoch: 6| Step: 10
Training loss: 3.279764765701187
Validation loss: 3.783073722468651

Epoch: 6| Step: 11
Training loss: 4.124733193756626
Validation loss: 3.781836777152364

Epoch: 6| Step: 12
Training loss: 4.401029700388996
Validation loss: 3.7719132060058413

Epoch: 6| Step: 13
Training loss: 3.9298985085231504
Validation loss: 3.754876060111191

Epoch: 7| Step: 0
Training loss: 3.451078611192078
Validation loss: 3.732984213410753

Epoch: 6| Step: 1
Training loss: 4.478882300051525
Validation loss: 3.72412496902878

Epoch: 6| Step: 2
Training loss: 3.950073391196346
Validation loss: 3.719124676980531

Epoch: 6| Step: 3
Training loss: 4.4915915450476955
Validation loss: 3.7080042712524435

Epoch: 6| Step: 4
Training loss: 3.7150158767052885
Validation loss: 3.69933016272573

Epoch: 6| Step: 5
Training loss: 3.291806632498592
Validation loss: 3.7054932228722337

Epoch: 6| Step: 6
Training loss: 4.564504104871489
Validation loss: 3.703245519003765

Epoch: 6| Step: 7
Training loss: 3.193515860080232
Validation loss: 3.6818646682649248

Epoch: 6| Step: 8
Training loss: 4.334788787166649
Validation loss: 3.6572913071920974

Epoch: 6| Step: 9
Training loss: 3.5189185418914963
Validation loss: 3.6488589120963604

Epoch: 6| Step: 10
Training loss: 3.782368770322306
Validation loss: 3.665357978908253

Epoch: 6| Step: 11
Training loss: 3.267737184655981
Validation loss: 3.6363861589955495

Epoch: 6| Step: 12
Training loss: 3.2687482728096535
Validation loss: 3.629677889646107

Epoch: 6| Step: 13
Training loss: 4.848406122753367
Validation loss: 3.632519801734677

Epoch: 8| Step: 0
Training loss: 3.5819971713209884
Validation loss: 3.625980164061865

Epoch: 6| Step: 1
Training loss: 3.25164195911817
Validation loss: 3.6111216494204275

Epoch: 6| Step: 2
Training loss: 4.312475895468753
Validation loss: 3.596522326511824

Epoch: 6| Step: 3
Training loss: 3.838752785634776
Validation loss: 3.5856610660167334

Epoch: 6| Step: 4
Training loss: 3.5743333475054277
Validation loss: 3.586431159176949

Epoch: 6| Step: 5
Training loss: 4.1830475323279375
Validation loss: 3.573924274351454

Epoch: 6| Step: 6
Training loss: 3.207858723466743
Validation loss: 3.565924640042282

Epoch: 6| Step: 7
Training loss: 4.315552888636535
Validation loss: 3.5736954138513073

Epoch: 6| Step: 8
Training loss: 3.11709632835812
Validation loss: 3.5782989059898154

Epoch: 6| Step: 9
Training loss: 3.247852789883029
Validation loss: 3.5795342671760917

Epoch: 6| Step: 10
Training loss: 3.6508848816007844
Validation loss: 3.566905908397366

Epoch: 6| Step: 11
Training loss: 4.197543270394712
Validation loss: 3.5476218134789717

Epoch: 6| Step: 12
Training loss: 4.188741926813272
Validation loss: 3.5337751882719317

Epoch: 6| Step: 13
Training loss: 4.008747787356026
Validation loss: 3.5289386586748495

Epoch: 9| Step: 0
Training loss: 4.533110979648368
Validation loss: 3.5219846530981576

Epoch: 6| Step: 1
Training loss: 4.108225150292769
Validation loss: 3.5106867700945106

Epoch: 6| Step: 2
Training loss: 2.853714807387784
Validation loss: 3.5092085338677865

Epoch: 6| Step: 3
Training loss: 2.981747734058089
Validation loss: 3.5047099070189116

Epoch: 6| Step: 4
Training loss: 2.9758588304569478
Validation loss: 3.4964806754204143

Epoch: 6| Step: 5
Training loss: 4.238721805299872
Validation loss: 3.49112061439715

Epoch: 6| Step: 6
Training loss: 3.396571978096825
Validation loss: 3.4790571029847492

Epoch: 6| Step: 7
Training loss: 3.4247702974018304
Validation loss: 3.46923536936291

Epoch: 6| Step: 8
Training loss: 4.2197253194788145
Validation loss: 3.4641905439627902

Epoch: 6| Step: 9
Training loss: 3.2739979849071044
Validation loss: 3.4586627169293735

Epoch: 6| Step: 10
Training loss: 3.4017128781050756
Validation loss: 3.450944281622688

Epoch: 6| Step: 11
Training loss: 4.947434294092277
Validation loss: 3.446654727740012

Epoch: 6| Step: 12
Training loss: 2.8446380570037384
Validation loss: 3.4414360623634326

Epoch: 6| Step: 13
Training loss: 3.8178424612148136
Validation loss: 3.431442401907798

Epoch: 10| Step: 0
Training loss: 3.680915255134043
Validation loss: 3.42460286324764

Epoch: 6| Step: 1
Training loss: 4.414435608885366
Validation loss: 3.4219405386696287

Epoch: 6| Step: 2
Training loss: 3.4903959931715414
Validation loss: 3.4154434533086673

Epoch: 6| Step: 3
Training loss: 3.329113164351667
Validation loss: 3.4121478146363

Epoch: 6| Step: 4
Training loss: 3.8227659744927815
Validation loss: 3.398750064683019

Epoch: 6| Step: 5
Training loss: 4.059300028025682
Validation loss: 3.390655531050408

Epoch: 6| Step: 6
Training loss: 3.4500609738034234
Validation loss: 3.3829280251237632

Epoch: 6| Step: 7
Training loss: 3.7284780253637164
Validation loss: 3.3811502632527213

Epoch: 6| Step: 8
Training loss: 3.171860568009039
Validation loss: 3.3820465129313013

Epoch: 6| Step: 9
Training loss: 3.374813639829118
Validation loss: 3.375787586120464

Epoch: 6| Step: 10
Training loss: 3.2607582733954827
Validation loss: 3.368269729753744

Epoch: 6| Step: 11
Training loss: 3.101762049330823
Validation loss: 3.3587285298575353

Epoch: 6| Step: 12
Training loss: 3.5309013262076636
Validation loss: 3.3513874107945867

Epoch: 6| Step: 13
Training loss: 4.31733498916767
Validation loss: 3.3463451368937

Epoch: 11| Step: 0
Training loss: 3.144669542766477
Validation loss: 3.3504730051690133

Epoch: 6| Step: 1
Training loss: 3.325658896419913
Validation loss: 3.358080842038521

Epoch: 6| Step: 2
Training loss: 4.296496565366491
Validation loss: 3.3342842389012333

Epoch: 6| Step: 3
Training loss: 3.6665431493126444
Validation loss: 3.331908454195624

Epoch: 6| Step: 4
Training loss: 3.9636173249424553
Validation loss: 3.332399100981938

Epoch: 6| Step: 5
Training loss: 3.157077038873509
Validation loss: 3.332862804386983

Epoch: 6| Step: 6
Training loss: 3.3198006269040583
Validation loss: 3.3316295181415594

Epoch: 6| Step: 7
Training loss: 3.3176780391889005
Validation loss: 3.328619679537308

Epoch: 6| Step: 8
Training loss: 3.623051349811927
Validation loss: 3.323660066682922

Epoch: 6| Step: 9
Training loss: 3.6212362284031423
Validation loss: 3.3142037880853255

Epoch: 6| Step: 10
Training loss: 3.9944949414971704
Validation loss: 3.302074994584275

Epoch: 6| Step: 11
Training loss: 3.364119333370943
Validation loss: 3.302086408794898

Epoch: 6| Step: 12
Training loss: 3.523659709681653
Validation loss: 3.301904609004562

Epoch: 6| Step: 13
Training loss: 3.161653783916422
Validation loss: 3.286864677772258

Epoch: 12| Step: 0
Training loss: 4.216052061581061
Validation loss: 3.2963671946126882

Epoch: 6| Step: 1
Training loss: 3.492180809338879
Validation loss: 3.2877887912314923

Epoch: 6| Step: 2
Training loss: 3.3031352841479715
Validation loss: 3.284718601282884

Epoch: 6| Step: 3
Training loss: 3.366029473867588
Validation loss: 3.2859354313844324

Epoch: 6| Step: 4
Training loss: 3.545247246388452
Validation loss: 3.2861435066291342

Epoch: 6| Step: 5
Training loss: 3.9841346817844467
Validation loss: 3.281318197405973

Epoch: 6| Step: 6
Training loss: 2.9621347709250245
Validation loss: 3.2701715808800214

Epoch: 6| Step: 7
Training loss: 2.9349076215252854
Validation loss: 3.2648963953443757

Epoch: 6| Step: 8
Training loss: 3.0155604854659948
Validation loss: 3.265680701131129

Epoch: 6| Step: 9
Training loss: 3.3897699781040553
Validation loss: 3.266208465260473

Epoch: 6| Step: 10
Training loss: 4.045653405528102
Validation loss: 3.2788730737319414

Epoch: 6| Step: 11
Training loss: 4.507094618625741
Validation loss: 3.264794242184801

Epoch: 6| Step: 12
Training loss: 3.025653510003691
Validation loss: 3.2463167742118326

Epoch: 6| Step: 13
Training loss: 2.653582860756635
Validation loss: 3.239347394625021

Epoch: 13| Step: 0
Training loss: 3.4255654974998118
Validation loss: 3.241269684098926

Epoch: 6| Step: 1
Training loss: 3.2915555878902283
Validation loss: 3.243328048750145

Epoch: 6| Step: 2
Training loss: 3.9333069288585203
Validation loss: 3.2362835047576692

Epoch: 6| Step: 3
Training loss: 3.4827102310684515
Validation loss: 3.2256992747334836

Epoch: 6| Step: 4
Training loss: 3.518219799798242
Validation loss: 3.2164708323742985

Epoch: 6| Step: 5
Training loss: 3.372725674124771
Validation loss: 3.213637542903192

Epoch: 6| Step: 6
Training loss: 3.48670970206996
Validation loss: 3.208071311369314

Epoch: 6| Step: 7
Training loss: 3.24829643790944
Validation loss: 3.206625901320144

Epoch: 6| Step: 8
Training loss: 4.029425866285376
Validation loss: 3.201568439805458

Epoch: 6| Step: 9
Training loss: 2.774785791325907
Validation loss: 3.197394040765142

Epoch: 6| Step: 10
Training loss: 3.0980139738670305
Validation loss: 3.1879666071555506

Epoch: 6| Step: 11
Training loss: 3.937200504599115
Validation loss: 3.187098735828484

Epoch: 6| Step: 12
Training loss: 3.479611686219806
Validation loss: 3.182125040398734

Epoch: 6| Step: 13
Training loss: 3.1565362781583217
Validation loss: 3.1736638078458004

Epoch: 14| Step: 0
Training loss: 2.8028828970338493
Validation loss: 3.1697016233543156

Epoch: 6| Step: 1
Training loss: 3.2604542365463867
Validation loss: 3.1668360416039336

Epoch: 6| Step: 2
Training loss: 3.618168411561151
Validation loss: 3.1640065623607456

Epoch: 6| Step: 3
Training loss: 3.5527398778905295
Validation loss: 3.1566936303387574

Epoch: 6| Step: 4
Training loss: 3.231665614421241
Validation loss: 3.1556751300732406

Epoch: 6| Step: 5
Training loss: 3.585033161430266
Validation loss: 3.1546755526674297

Epoch: 6| Step: 6
Training loss: 3.006974378460802
Validation loss: 3.1516241782850307

Epoch: 6| Step: 7
Training loss: 3.3797071621235153
Validation loss: 3.146669197043265

Epoch: 6| Step: 8
Training loss: 4.092724154700599
Validation loss: 3.145512598273

Epoch: 6| Step: 9
Training loss: 3.321059342706161
Validation loss: 3.141058865571386

Epoch: 6| Step: 10
Training loss: 3.95810154018681
Validation loss: 3.1373454781259618

Epoch: 6| Step: 11
Training loss: 3.1661337019159825
Validation loss: 3.133474191769195

Epoch: 6| Step: 12
Training loss: 3.62438170323062
Validation loss: 3.1318782444120834

Epoch: 6| Step: 13
Training loss: 2.6276124034761312
Validation loss: 3.1292947671312694

Epoch: 15| Step: 0
Training loss: 3.466452585236931
Validation loss: 3.1295935588598094

Epoch: 6| Step: 1
Training loss: 2.94951881751631
Validation loss: 3.1249384687375126

Epoch: 6| Step: 2
Training loss: 3.1327001689454326
Validation loss: 3.125408869421482

Epoch: 6| Step: 3
Training loss: 3.4947471710571305
Validation loss: 3.121831119903206

Epoch: 6| Step: 4
Training loss: 3.3876138140150025
Validation loss: 3.1189888727894375

Epoch: 6| Step: 5
Training loss: 3.8993049833697953
Validation loss: 3.119167565321057

Epoch: 6| Step: 6
Training loss: 3.3105321833191703
Validation loss: 3.117587550098733

Epoch: 6| Step: 7
Training loss: 3.0186147150089324
Validation loss: 3.115951791133341

Epoch: 6| Step: 8
Training loss: 3.2267717566072567
Validation loss: 3.1145684962149542

Epoch: 6| Step: 9
Training loss: 4.102798362915034
Validation loss: 3.113888229641502

Epoch: 6| Step: 10
Training loss: 3.705224323354384
Validation loss: 3.111298642394339

Epoch: 6| Step: 11
Training loss: 2.936266538687907
Validation loss: 3.1116679997762087

Epoch: 6| Step: 12
Training loss: 2.9530308622665182
Validation loss: 3.117923190537379

Epoch: 6| Step: 13
Training loss: 3.846740551728756
Validation loss: 3.1146451130646056

Epoch: 16| Step: 0
Training loss: 3.8461965822633224
Validation loss: 3.115746699832837

Epoch: 6| Step: 1
Training loss: 3.016558408814433
Validation loss: 3.107342207307168

Epoch: 6| Step: 2
Training loss: 3.632766296749197
Validation loss: 3.1015342198023297

Epoch: 6| Step: 3
Training loss: 2.9624335301664235
Validation loss: 3.1014658483380453

Epoch: 6| Step: 4
Training loss: 2.9718823421800735
Validation loss: 3.099607211344703

Epoch: 6| Step: 5
Training loss: 3.3903319060749215
Validation loss: 3.096982014939537

Epoch: 6| Step: 6
Training loss: 3.806931352938843
Validation loss: 3.0955647300052447

Epoch: 6| Step: 7
Training loss: 3.8698851761060196
Validation loss: 3.096885260058796

Epoch: 6| Step: 8
Training loss: 3.229914884124875
Validation loss: 3.0942250029336367

Epoch: 6| Step: 9
Training loss: 3.1831672991315196
Validation loss: 3.093019699456462

Epoch: 6| Step: 10
Training loss: 4.0911745312819585
Validation loss: 3.09198114535801

Epoch: 6| Step: 11
Training loss: 2.767647041749558
Validation loss: 3.088125368530319

Epoch: 6| Step: 12
Training loss: 2.3525050102610243
Validation loss: 3.0883346184142573

Epoch: 6| Step: 13
Training loss: 3.9036486699673163
Validation loss: 3.086644084428506

Epoch: 17| Step: 0
Training loss: 3.3149839480832792
Validation loss: 3.084566507175913

Epoch: 6| Step: 1
Training loss: 2.910499337473317
Validation loss: 3.0838499082696726

Epoch: 6| Step: 2
Training loss: 3.5348940251502547
Validation loss: 3.082451286522158

Epoch: 6| Step: 3
Training loss: 3.088185401855418
Validation loss: 3.0836770504374726

Epoch: 6| Step: 4
Training loss: 3.544927120993019
Validation loss: 3.08106924196288

Epoch: 6| Step: 5
Training loss: 3.0903762763585894
Validation loss: 3.079799041348874

Epoch: 6| Step: 6
Training loss: 3.4256774121057463
Validation loss: 3.0804764722319447

Epoch: 6| Step: 7
Training loss: 3.7393288415083963
Validation loss: 3.0771520499156817

Epoch: 6| Step: 8
Training loss: 3.242752209856814
Validation loss: 3.0779676074926607

Epoch: 6| Step: 9
Training loss: 3.577160967764022
Validation loss: 3.07551977081807

Epoch: 6| Step: 10
Training loss: 3.4157466269962744
Validation loss: 3.0740059180605215

Epoch: 6| Step: 11
Training loss: 3.077323228235474
Validation loss: 3.074329552108655

Epoch: 6| Step: 12
Training loss: 3.6320135735245542
Validation loss: 3.075555823889784

Epoch: 6| Step: 13
Training loss: 3.3648330706021032
Validation loss: 3.0733892976603037

Epoch: 18| Step: 0
Training loss: 3.1810188973952886
Validation loss: 3.0734408846898456

Epoch: 6| Step: 1
Training loss: 2.8624431221321074
Validation loss: 3.0715307103515825

Epoch: 6| Step: 2
Training loss: 3.6206338831171774
Validation loss: 3.067988602342687

Epoch: 6| Step: 3
Training loss: 2.965239688133331
Validation loss: 3.0683307169213028

Epoch: 6| Step: 4
Training loss: 3.5033542364085477
Validation loss: 3.065688224285112

Epoch: 6| Step: 5
Training loss: 3.665408670037188
Validation loss: 3.0642741047289173

Epoch: 6| Step: 6
Training loss: 3.9985611234980025
Validation loss: 3.0637076422116576

Epoch: 6| Step: 7
Training loss: 3.2097391458686304
Validation loss: 3.0640731614969097

Epoch: 6| Step: 8
Training loss: 3.449403716816417
Validation loss: 3.060440517828975

Epoch: 6| Step: 9
Training loss: 3.699218363293604
Validation loss: 3.05909409191431

Epoch: 6| Step: 10
Training loss: 3.483036622425779
Validation loss: 3.060239715766995

Epoch: 6| Step: 11
Training loss: 2.7956173589283466
Validation loss: 3.059288998528516

Epoch: 6| Step: 12
Training loss: 2.8463300801078497
Validation loss: 3.0572920283539755

Epoch: 6| Step: 13
Training loss: 3.3964790401230385
Validation loss: 3.056360078116828

Epoch: 19| Step: 0
Training loss: 3.342292824646517
Validation loss: 3.0557065464672823

Epoch: 6| Step: 1
Training loss: 3.3253240843274368
Validation loss: 3.0545073895333186

Epoch: 6| Step: 2
Training loss: 3.8825602459086648
Validation loss: 3.052751385638219

Epoch: 6| Step: 3
Training loss: 3.046070168641891
Validation loss: 3.0510714130631125

Epoch: 6| Step: 4
Training loss: 3.8334775289421987
Validation loss: 3.0517006421056254

Epoch: 6| Step: 5
Training loss: 3.1750265165408154
Validation loss: 3.0506083503925274

Epoch: 6| Step: 6
Training loss: 3.6646457362468725
Validation loss: 3.05058224669878

Epoch: 6| Step: 7
Training loss: 3.312448177292151
Validation loss: 3.0501350507418583

Epoch: 6| Step: 8
Training loss: 2.399003747953832
Validation loss: 3.0490169605540305

Epoch: 6| Step: 9
Training loss: 3.427143795944882
Validation loss: 3.0489743623545125

Epoch: 6| Step: 10
Training loss: 3.6120488554986734
Validation loss: 3.047957659161074

Epoch: 6| Step: 11
Training loss: 2.394685774479836
Validation loss: 3.0467915908759835

Epoch: 6| Step: 12
Training loss: 3.344065428499851
Validation loss: 3.046227022804473

Epoch: 6| Step: 13
Training loss: 3.7940050117970343
Validation loss: 3.0462366184729075

Epoch: 20| Step: 0
Training loss: 3.6254398473721863
Validation loss: 3.0431174609545586

Epoch: 6| Step: 1
Training loss: 2.946429215468299
Validation loss: 3.0423156735886905

Epoch: 6| Step: 2
Training loss: 2.96925654858147
Validation loss: 3.0421540688342765

Epoch: 6| Step: 3
Training loss: 3.403408860487242
Validation loss: 3.040592358437184

Epoch: 6| Step: 4
Training loss: 3.2972718492640576
Validation loss: 3.040638948230301

Epoch: 6| Step: 5
Training loss: 2.707445253362896
Validation loss: 3.0379551758352297

Epoch: 6| Step: 6
Training loss: 3.9708353406187884
Validation loss: 3.0379733223714314

Epoch: 6| Step: 7
Training loss: 3.955110435824809
Validation loss: 3.0370409615914107

Epoch: 6| Step: 8
Training loss: 3.702239240470118
Validation loss: 3.036225225620199

Epoch: 6| Step: 9
Training loss: 3.6194880442816433
Validation loss: 3.0331275114430483

Epoch: 6| Step: 10
Training loss: 3.182735547430916
Validation loss: 3.03501195693017

Epoch: 6| Step: 11
Training loss: 3.8080810201745154
Validation loss: 3.033086053432437

Epoch: 6| Step: 12
Training loss: 2.130325824012627
Validation loss: 3.0301372920272263

Epoch: 6| Step: 13
Training loss: 2.136171930001508
Validation loss: 3.0308233548012113

Epoch: 21| Step: 0
Training loss: 2.963235813620236
Validation loss: 3.031816844589388

Epoch: 6| Step: 1
Training loss: 3.058630386464409
Validation loss: 3.030235861747467

Epoch: 6| Step: 2
Training loss: 3.6597801186222374
Validation loss: 3.0300331189234613

Epoch: 6| Step: 3
Training loss: 4.096496592489171
Validation loss: 3.030903008030075

Epoch: 6| Step: 4
Training loss: 3.40673684656923
Validation loss: 3.0260284380049747

Epoch: 6| Step: 5
Training loss: 2.4027529980429723
Validation loss: 3.0241243621404768

Epoch: 6| Step: 6
Training loss: 3.744473008280499
Validation loss: 3.0263450272397248

Epoch: 6| Step: 7
Training loss: 2.8159653401842752
Validation loss: 3.0244460780217852

Epoch: 6| Step: 8
Training loss: 3.2725260701609105
Validation loss: 3.0226850108212138

Epoch: 6| Step: 9
Training loss: 3.518823143857762
Validation loss: 3.02179847436549

Epoch: 6| Step: 10
Training loss: 3.8705642907820494
Validation loss: 3.023861828293314

Epoch: 6| Step: 11
Training loss: 3.1855690287013236
Validation loss: 3.0275780346388883

Epoch: 6| Step: 12
Training loss: 2.358345362853877
Validation loss: 3.017414204717358

Epoch: 6| Step: 13
Training loss: 3.7936420255626695
Validation loss: 3.021777140866408

Epoch: 22| Step: 0
Training loss: 3.6951579087807866
Validation loss: 3.0165550195863085

Epoch: 6| Step: 1
Training loss: 2.8377998899379837
Validation loss: 3.019830151167149

Epoch: 6| Step: 2
Training loss: 3.812560284247386
Validation loss: 3.019029242524939

Epoch: 6| Step: 3
Training loss: 3.342253305465932
Validation loss: 3.0154039320076134

Epoch: 6| Step: 4
Training loss: 3.025040391384359
Validation loss: 3.016289566946167

Epoch: 6| Step: 5
Training loss: 2.8518056269427454
Validation loss: 3.0158608350903076

Epoch: 6| Step: 6
Training loss: 3.051335439521119
Validation loss: 3.0209986136896014

Epoch: 6| Step: 7
Training loss: 3.2115722919792553
Validation loss: 3.0182183618952103

Epoch: 6| Step: 8
Training loss: 3.829274281403305
Validation loss: 3.014366074573397

Epoch: 6| Step: 9
Training loss: 3.7363558188417594
Validation loss: 3.0152057498879357

Epoch: 6| Step: 10
Training loss: 2.757884945876971
Validation loss: 3.0185040784906296

Epoch: 6| Step: 11
Training loss: 3.564229445036505
Validation loss: 3.021628694704029

Epoch: 6| Step: 12
Training loss: 3.43858985963408
Validation loss: 3.0223010075246135

Epoch: 6| Step: 13
Training loss: 2.511300486716498
Validation loss: 3.0193590690490075

Epoch: 23| Step: 0
Training loss: 2.9749487159219608
Validation loss: 3.0136503478648895

Epoch: 6| Step: 1
Training loss: 2.09765602268097
Validation loss: 3.0116595009754965

Epoch: 6| Step: 2
Training loss: 3.006399640266921
Validation loss: 3.019501644548094

Epoch: 6| Step: 3
Training loss: 3.7780025187817685
Validation loss: 3.015294994583973

Epoch: 6| Step: 4
Training loss: 2.0571800748924893
Validation loss: 3.036026648815771

Epoch: 6| Step: 5
Training loss: 3.772633216078213
Validation loss: 3.0674929004260125

Epoch: 6| Step: 6
Training loss: 3.1373281302624427
Validation loss: 3.053938115639471

Epoch: 6| Step: 7
Training loss: 3.617064504818658
Validation loss: 3.034167196169533

Epoch: 6| Step: 8
Training loss: 3.4728432638233198
Validation loss: 3.018512326112482

Epoch: 6| Step: 9
Training loss: 2.0772449666466253
Validation loss: 3.011661988293482

Epoch: 6| Step: 10
Training loss: 4.238628657996667
Validation loss: 3.0076557103110138

Epoch: 6| Step: 11
Training loss: 3.684028672627588
Validation loss: 3.0052554642838847

Epoch: 6| Step: 12
Training loss: 4.049472520174744
Validation loss: 3.0096307111680147

Epoch: 6| Step: 13
Training loss: 3.1421958828382244
Validation loss: 3.0066086417091733

Epoch: 24| Step: 0
Training loss: 2.9538093863775714
Validation loss: 3.0080643854039764

Epoch: 6| Step: 1
Training loss: 3.7729287130302898
Validation loss: 3.00216031055928

Epoch: 6| Step: 2
Training loss: 3.149279914778681
Validation loss: 3.006027964395527

Epoch: 6| Step: 3
Training loss: 3.4219200096479754
Validation loss: 3.002997019103198

Epoch: 6| Step: 4
Training loss: 4.279141763220323
Validation loss: 2.995315839452865

Epoch: 6| Step: 5
Training loss: 3.6568944640188454
Validation loss: 3.001239640129949

Epoch: 6| Step: 6
Training loss: 3.5985412503192213
Validation loss: 2.999908686858163

Epoch: 6| Step: 7
Training loss: 2.9668987726288147
Validation loss: 3.0008727636290686

Epoch: 6| Step: 8
Training loss: 2.6551947797746367
Validation loss: 3.000787059195247

Epoch: 6| Step: 9
Training loss: 2.162174654615243
Validation loss: 3.010624293605191

Epoch: 6| Step: 10
Training loss: 2.8856511393737367
Validation loss: 3.0249522664483735

Epoch: 6| Step: 11
Training loss: 2.9289238913700006
Validation loss: 3.0243451817826075

Epoch: 6| Step: 12
Training loss: 3.703237926193845
Validation loss: 3.018555276910036

Epoch: 6| Step: 13
Training loss: 3.50736075638119
Validation loss: 3.0066663054250093

Epoch: 25| Step: 0
Training loss: 3.3685232110907632
Validation loss: 2.999505162873968

Epoch: 6| Step: 1
Training loss: 3.1513516024076194
Validation loss: 2.9929503961751127

Epoch: 6| Step: 2
Training loss: 2.467159869744151
Validation loss: 2.990109002166446

Epoch: 6| Step: 3
Training loss: 2.982249836434577
Validation loss: 2.987820636494126

Epoch: 6| Step: 4
Training loss: 3.470619866140489
Validation loss: 2.9881101630747318

Epoch: 6| Step: 5
Training loss: 3.813360648646481
Validation loss: 2.990212928620744

Epoch: 6| Step: 6
Training loss: 3.22035666060211
Validation loss: 2.991236511995124

Epoch: 6| Step: 7
Training loss: 3.3680464142525666
Validation loss: 2.987736233435505

Epoch: 6| Step: 8
Training loss: 3.366273689625785
Validation loss: 2.9872217159346626

Epoch: 6| Step: 9
Training loss: 3.5205391002857254
Validation loss: 2.9849319458027734

Epoch: 6| Step: 10
Training loss: 3.67026487719876
Validation loss: 2.985464964684489

Epoch: 6| Step: 11
Training loss: 2.91075851045757
Validation loss: 2.9843062259906312

Epoch: 6| Step: 12
Training loss: 3.462755677185847
Validation loss: 2.9828402272972023

Epoch: 6| Step: 13
Training loss: 2.4816334310457666
Validation loss: 2.9815567730037977

Epoch: 26| Step: 0
Training loss: 3.9882898582791526
Validation loss: 2.986133039800496

Epoch: 6| Step: 1
Training loss: 3.925199399123053
Validation loss: 2.9861780265171785

Epoch: 6| Step: 2
Training loss: 3.427660088671524
Validation loss: 2.98579595654266

Epoch: 6| Step: 3
Training loss: 2.7734390473697266
Validation loss: 2.9852963441521485

Epoch: 6| Step: 4
Training loss: 2.5886520474781074
Validation loss: 2.99103891762702

Epoch: 6| Step: 5
Training loss: 3.886188720141456
Validation loss: 2.9902516057232753

Epoch: 6| Step: 6
Training loss: 2.7746140254573954
Validation loss: 2.9870206795652257

Epoch: 6| Step: 7
Training loss: 2.4473924657248216
Validation loss: 2.9818888219837576

Epoch: 6| Step: 8
Training loss: 3.1854238293411097
Validation loss: 2.9785300298215045

Epoch: 6| Step: 9
Training loss: 3.4642771157563907
Validation loss: 2.976655836695292

Epoch: 6| Step: 10
Training loss: 3.142467205207275
Validation loss: 2.9739923732576554

Epoch: 6| Step: 11
Training loss: 3.5620965561885534
Validation loss: 2.9729801913630554

Epoch: 6| Step: 12
Training loss: 2.74655759537741
Validation loss: 2.9752375408531897

Epoch: 6| Step: 13
Training loss: 3.2459095375866975
Validation loss: 2.974099604015133

Epoch: 27| Step: 0
Training loss: 2.9599578766789683
Validation loss: 2.9728849447361534

Epoch: 6| Step: 1
Training loss: 3.1654435522830653
Validation loss: 2.9688999278492694

Epoch: 6| Step: 2
Training loss: 2.9296053048365516
Validation loss: 2.9704176911466837

Epoch: 6| Step: 3
Training loss: 3.1210693052860004
Validation loss: 2.971917766812264

Epoch: 6| Step: 4
Training loss: 3.79258014169306
Validation loss: 2.9686287527578163

Epoch: 6| Step: 5
Training loss: 3.2538139266051656
Validation loss: 2.966957106158593

Epoch: 6| Step: 6
Training loss: 3.3391726527879557
Validation loss: 2.9681376233110566

Epoch: 6| Step: 7
Training loss: 3.1267234627364724
Validation loss: 2.966003048644944

Epoch: 6| Step: 8
Training loss: 3.8826893224692722
Validation loss: 2.9677710118748646

Epoch: 6| Step: 9
Training loss: 3.095934164288604
Validation loss: 2.9681712529330544

Epoch: 6| Step: 10
Training loss: 3.6015797116081414
Validation loss: 2.970256534992173

Epoch: 6| Step: 11
Training loss: 3.356069242415552
Validation loss: 2.967752914644703

Epoch: 6| Step: 12
Training loss: 2.623696321371775
Validation loss: 2.9637124775972437

Epoch: 6| Step: 13
Training loss: 2.8277810240574732
Validation loss: 2.9661911805168986

Epoch: 28| Step: 0
Training loss: 3.057269397938269
Validation loss: 3.013710136198075

Epoch: 6| Step: 1
Training loss: 3.6578140174051077
Validation loss: 3.0011123633921555

Epoch: 6| Step: 2
Training loss: 2.9770124600950254
Validation loss: 2.9762658300338547

Epoch: 6| Step: 3
Training loss: 2.859081482544372
Validation loss: 2.9634445788430415

Epoch: 6| Step: 4
Training loss: 2.8778075731748736
Validation loss: 2.9669588671203724

Epoch: 6| Step: 5
Training loss: 3.728568187121322
Validation loss: 2.9718098163772426

Epoch: 6| Step: 6
Training loss: 3.1567974560023098
Validation loss: 2.964039659912418

Epoch: 6| Step: 7
Training loss: 3.630287260769198
Validation loss: 2.957713151531563

Epoch: 6| Step: 8
Training loss: 3.3670373869888732
Validation loss: 2.962113945897609

Epoch: 6| Step: 9
Training loss: 3.2642688034110874
Validation loss: 2.96926028017141

Epoch: 6| Step: 10
Training loss: 3.003965776545684
Validation loss: 2.9999389932780405

Epoch: 6| Step: 11
Training loss: 3.18721246357438
Validation loss: 3.0264865214391743

Epoch: 6| Step: 12
Training loss: 3.4859793352312316
Validation loss: 3.028965022723134

Epoch: 6| Step: 13
Training loss: 3.2950932176107157
Validation loss: 3.004140293898251

Epoch: 29| Step: 0
Training loss: 3.3540159550960063
Validation loss: 3.000339082129545

Epoch: 6| Step: 1
Training loss: 2.999222177760398
Validation loss: 2.981397582728515

Epoch: 6| Step: 2
Training loss: 3.1634122957504722
Validation loss: 2.97477366840408

Epoch: 6| Step: 3
Training loss: 3.0563913261954485
Validation loss: 2.962605359161526

Epoch: 6| Step: 4
Training loss: 2.9174166850375935
Validation loss: 2.952209311592047

Epoch: 6| Step: 5
Training loss: 2.819732437291492
Validation loss: 2.9519485688692426

Epoch: 6| Step: 6
Training loss: 2.63158861459663
Validation loss: 2.949652234215497

Epoch: 6| Step: 7
Training loss: 3.2381225105280493
Validation loss: 2.9507692951399824

Epoch: 6| Step: 8
Training loss: 3.5794544665289574
Validation loss: 2.9904212250546536

Epoch: 6| Step: 9
Training loss: 3.194417590337099
Validation loss: 2.944939397865992

Epoch: 6| Step: 10
Training loss: 2.8543944627579836
Validation loss: 2.9451935781846124

Epoch: 6| Step: 11
Training loss: 3.219768177951788
Validation loss: 2.9455735081243173

Epoch: 6| Step: 12
Training loss: 3.948257767058985
Validation loss: 2.946555828227759

Epoch: 6| Step: 13
Training loss: 4.674441650013388
Validation loss: 2.951893134733309

Epoch: 30| Step: 0
Training loss: 3.7440443429521757
Validation loss: 2.9443004213311794

Epoch: 6| Step: 1
Training loss: 3.202085745088111
Validation loss: 2.949940050140631

Epoch: 6| Step: 2
Training loss: 3.088982501848872
Validation loss: 2.953858174666078

Epoch: 6| Step: 3
Training loss: 3.788964464944712
Validation loss: 2.9673128113179152

Epoch: 6| Step: 4
Training loss: 3.5523000224106562
Validation loss: 2.98088860624524

Epoch: 6| Step: 5
Training loss: 3.2435817432314566
Validation loss: 2.968541410984061

Epoch: 6| Step: 6
Training loss: 3.3679543880898843
Validation loss: 2.959577678865072

Epoch: 6| Step: 7
Training loss: 3.3780722586637215
Validation loss: 2.9561007468283327

Epoch: 6| Step: 8
Training loss: 2.6746613546618536
Validation loss: 2.966965672476089

Epoch: 6| Step: 9
Training loss: 2.8173371150973363
Validation loss: 2.9885416741926365

Epoch: 6| Step: 10
Training loss: 2.3662480167596227
Validation loss: 2.9452165901534038

Epoch: 6| Step: 11
Training loss: 2.9393188040323697
Validation loss: 2.9615268660231853

Epoch: 6| Step: 12
Training loss: 3.671668773297851
Validation loss: 2.936624924200326

Epoch: 6| Step: 13
Training loss: 3.140714425858767
Validation loss: 2.933097790768121

Epoch: 31| Step: 0
Training loss: 3.301450618612035
Validation loss: 2.9314299638760697

Epoch: 6| Step: 1
Training loss: 3.423203580552324
Validation loss: 2.930735696082519

Epoch: 6| Step: 2
Training loss: 3.3882436520225623
Validation loss: 2.92965772169286

Epoch: 6| Step: 3
Training loss: 3.5315195166437277
Validation loss: 2.936106978798257

Epoch: 6| Step: 4
Training loss: 2.7720289495093167
Validation loss: 2.93737576443857

Epoch: 6| Step: 5
Training loss: 2.556064432958804
Validation loss: 2.9367923953402224

Epoch: 6| Step: 6
Training loss: 3.5464044334392515
Validation loss: 2.938709155917959

Epoch: 6| Step: 7
Training loss: 3.0243867867372742
Validation loss: 2.9359608180425902

Epoch: 6| Step: 8
Training loss: 2.8405696985214433
Validation loss: 2.9344408770689583

Epoch: 6| Step: 9
Training loss: 3.606210617828859
Validation loss: 2.9330913018985068

Epoch: 6| Step: 10
Training loss: 3.4122317924877352
Validation loss: 2.9285277206020823

Epoch: 6| Step: 11
Training loss: 2.9447765722833616
Validation loss: 2.9324714568952333

Epoch: 6| Step: 12
Training loss: 3.65501278542345
Validation loss: 2.9259888079079737

Epoch: 6| Step: 13
Training loss: 2.5455733641537064
Validation loss: 2.9282145487289

Epoch: 32| Step: 0
Training loss: 2.5981167722071166
Validation loss: 2.9264551010464803

Epoch: 6| Step: 1
Training loss: 2.454311594113709
Validation loss: 2.9326063397577107

Epoch: 6| Step: 2
Training loss: 3.6507911033832094
Validation loss: 2.934020812077773

Epoch: 6| Step: 3
Training loss: 4.183847229132387
Validation loss: 2.9352661694630675

Epoch: 6| Step: 4
Training loss: 3.7142585108882185
Validation loss: 2.9297533664750826

Epoch: 6| Step: 5
Training loss: 3.280292189539658
Validation loss: 2.92701989449164

Epoch: 6| Step: 6
Training loss: 3.4348258974688735
Validation loss: 2.927170710828146

Epoch: 6| Step: 7
Training loss: 3.4110543902469006
Validation loss: 2.924759700802447

Epoch: 6| Step: 8
Training loss: 2.9798594560699816
Validation loss: 2.926610491055566

Epoch: 6| Step: 9
Training loss: 3.172106804857128
Validation loss: 2.9207763053901203

Epoch: 6| Step: 10
Training loss: 3.1151860056981597
Validation loss: 2.9225644025523527

Epoch: 6| Step: 11
Training loss: 2.804441053353523
Validation loss: 2.91766881704711

Epoch: 6| Step: 12
Training loss: 2.2693687288853748
Validation loss: 2.9173487333072847

Epoch: 6| Step: 13
Training loss: 3.426753916266665
Validation loss: 2.914092667282273

Epoch: 33| Step: 0
Training loss: 2.554604811890497
Validation loss: 2.9183074016218558

Epoch: 6| Step: 1
Training loss: 2.8298727294017687
Validation loss: 2.914164415263307

Epoch: 6| Step: 2
Training loss: 3.55786902609356
Validation loss: 2.9184745957100975

Epoch: 6| Step: 3
Training loss: 3.1067460030615734
Validation loss: 2.9150929214796015

Epoch: 6| Step: 4
Training loss: 4.025909671700594
Validation loss: 2.9088878676827066

Epoch: 6| Step: 5
Training loss: 3.2696750477077288
Validation loss: 2.905186896554894

Epoch: 6| Step: 6
Training loss: 3.4729819386433007
Validation loss: 2.905534633064246

Epoch: 6| Step: 7
Training loss: 3.0929854247782393
Validation loss: 2.907377997329319

Epoch: 6| Step: 8
Training loss: 3.231371678435388
Validation loss: 2.9060224853547494

Epoch: 6| Step: 9
Training loss: 3.244117107455396
Validation loss: 2.907509062530558

Epoch: 6| Step: 10
Training loss: 2.6096354828525454
Validation loss: 2.904073744801928

Epoch: 6| Step: 11
Training loss: 3.147150803784702
Validation loss: 2.9031267411866675

Epoch: 6| Step: 12
Training loss: 3.1233372651695928
Validation loss: 2.9026636972403654

Epoch: 6| Step: 13
Training loss: 3.4083125318220446
Validation loss: 2.9034985667967543

Epoch: 34| Step: 0
Training loss: 3.32225313806626
Validation loss: 2.900951886416677

Epoch: 6| Step: 1
Training loss: 2.4118498010003546
Validation loss: 2.900129245484769

Epoch: 6| Step: 2
Training loss: 3.1680914200105454
Validation loss: 2.901892716036137

Epoch: 6| Step: 3
Training loss: 2.354633948837912
Validation loss: 2.9032115103598652

Epoch: 6| Step: 4
Training loss: 3.7803304515688945
Validation loss: 2.9008342515377357

Epoch: 6| Step: 5
Training loss: 2.715711540010939
Validation loss: 2.8982747049388404

Epoch: 6| Step: 6
Training loss: 3.3710957302825877
Validation loss: 2.8982068758295876

Epoch: 6| Step: 7
Training loss: 2.9491933657330587
Validation loss: 2.9015109311060594

Epoch: 6| Step: 8
Training loss: 3.547945104825878
Validation loss: 2.9019319448099448

Epoch: 6| Step: 9
Training loss: 3.539591701258931
Validation loss: 2.912299907369882

Epoch: 6| Step: 10
Training loss: 3.5650700450719803
Validation loss: 2.8924839932036415

Epoch: 6| Step: 11
Training loss: 3.3042245815696636
Validation loss: 2.8941257553639055

Epoch: 6| Step: 12
Training loss: 3.4793339001938413
Validation loss: 2.8921295409996244

Epoch: 6| Step: 13
Training loss: 2.36701043099352
Validation loss: 2.8919056475337364

Epoch: 35| Step: 0
Training loss: 2.80580146790339
Validation loss: 2.8926897093275765

Epoch: 6| Step: 1
Training loss: 3.313344020199443
Validation loss: 2.8980716356883764

Epoch: 6| Step: 2
Training loss: 3.183598992279043
Validation loss: 2.891630935684606

Epoch: 6| Step: 3
Training loss: 3.3758899786861183
Validation loss: 2.892226173316627

Epoch: 6| Step: 4
Training loss: 3.205289825570499
Validation loss: 2.89074214574875

Epoch: 6| Step: 5
Training loss: 3.1315140542414337
Validation loss: 2.891783414165264

Epoch: 6| Step: 6
Training loss: 3.2534169061536797
Validation loss: 2.8914134911562046

Epoch: 6| Step: 7
Training loss: 3.307467686732449
Validation loss: 2.8890292147649546

Epoch: 6| Step: 8
Training loss: 2.249888099430933
Validation loss: 2.894801670414622

Epoch: 6| Step: 9
Training loss: 2.869895716244606
Validation loss: 2.8998372654628226

Epoch: 6| Step: 10
Training loss: 3.293688350440749
Validation loss: 2.922697767288064

Epoch: 6| Step: 11
Training loss: 3.5620858470375247
Validation loss: 2.917022378094185

Epoch: 6| Step: 12
Training loss: 3.2308908761008137
Validation loss: 2.8927901646868563

Epoch: 6| Step: 13
Training loss: 3.8824885212077023
Validation loss: 2.889006790813703

Epoch: 36| Step: 0
Training loss: 3.2077027894372896
Validation loss: 2.8879297818868808

Epoch: 6| Step: 1
Training loss: 3.106196019645795
Validation loss: 2.886632246931348

Epoch: 6| Step: 2
Training loss: 3.130398321918415
Validation loss: 2.886261131668658

Epoch: 6| Step: 3
Training loss: 3.202720356015025
Validation loss: 2.8850237063953093

Epoch: 6| Step: 4
Training loss: 2.796868862379788
Validation loss: 2.886195231061458

Epoch: 6| Step: 5
Training loss: 2.956466479772857
Validation loss: 2.8872225153932773

Epoch: 6| Step: 6
Training loss: 3.5563664422305163
Validation loss: 2.8841021410175247

Epoch: 6| Step: 7
Training loss: 3.0755232451082484
Validation loss: 2.8841310848078

Epoch: 6| Step: 8
Training loss: 3.5744899626012123
Validation loss: 2.880222720096322

Epoch: 6| Step: 9
Training loss: 3.1162400108327257
Validation loss: 2.8787603517894205

Epoch: 6| Step: 10
Training loss: 3.0325910610228997
Validation loss: 2.878834227953118

Epoch: 6| Step: 11
Training loss: 3.0096952812594093
Validation loss: 2.8755200117735495

Epoch: 6| Step: 12
Training loss: 2.9067958196183445
Validation loss: 2.87712575001395

Epoch: 6| Step: 13
Training loss: 3.9781614435269166
Validation loss: 2.876981575763683

Epoch: 37| Step: 0
Training loss: 3.7036767218631272
Validation loss: 2.872237353482951

Epoch: 6| Step: 1
Training loss: 2.625235138307155
Validation loss: 2.8775494013990732

Epoch: 6| Step: 2
Training loss: 2.9714600089789087
Validation loss: 2.8740161997697724

Epoch: 6| Step: 3
Training loss: 3.0973816181064278
Validation loss: 2.8754572261783355

Epoch: 6| Step: 4
Training loss: 3.383754819226083
Validation loss: 2.8787789755151345

Epoch: 6| Step: 5
Training loss: 3.2427416224516667
Validation loss: 2.8744100194494497

Epoch: 6| Step: 6
Training loss: 3.310905504634664
Validation loss: 2.8704069203242395

Epoch: 6| Step: 7
Training loss: 3.271489330686545
Validation loss: 2.8690043140678996

Epoch: 6| Step: 8
Training loss: 2.764593503157637
Validation loss: 2.870740729812143

Epoch: 6| Step: 9
Training loss: 2.57268667287067
Validation loss: 2.868487798862013

Epoch: 6| Step: 10
Training loss: 3.0087865267962375
Validation loss: 2.865699649594924

Epoch: 6| Step: 11
Training loss: 3.1462737189919343
Validation loss: 2.867144470526793

Epoch: 6| Step: 12
Training loss: 3.467733285725731
Validation loss: 2.8656660045733084

Epoch: 6| Step: 13
Training loss: 3.905667681205192
Validation loss: 2.86954187415606

Epoch: 38| Step: 0
Training loss: 3.1948691062799752
Validation loss: 2.863950673751397

Epoch: 6| Step: 1
Training loss: 3.2741657621428213
Validation loss: 2.86607979953157

Epoch: 6| Step: 2
Training loss: 2.578719931652307
Validation loss: 2.8635873074606075

Epoch: 6| Step: 3
Training loss: 2.393053105754586
Validation loss: 2.861631009455473

Epoch: 6| Step: 4
Training loss: 3.07137895461653
Validation loss: 2.8624727730307664

Epoch: 6| Step: 5
Training loss: 3.3759682290810513
Validation loss: 2.8635295951656654

Epoch: 6| Step: 6
Training loss: 3.6045535693940445
Validation loss: 2.8645774189430253

Epoch: 6| Step: 7
Training loss: 2.9936043594389776
Validation loss: 2.8688492397860794

Epoch: 6| Step: 8
Training loss: 3.145773998652501
Validation loss: 2.8583045362001744

Epoch: 6| Step: 9
Training loss: 3.4811956158264667
Validation loss: 2.8592160742956434

Epoch: 6| Step: 10
Training loss: 2.9242808183283904
Validation loss: 2.857929097494299

Epoch: 6| Step: 11
Training loss: 3.643008781931426
Validation loss: 2.8591401579600704

Epoch: 6| Step: 12
Training loss: 3.4587544257628893
Validation loss: 2.8570061136006357

Epoch: 6| Step: 13
Training loss: 2.5563662551522146
Validation loss: 2.858120398325914

Epoch: 39| Step: 0
Training loss: 2.529002098079609
Validation loss: 2.85647130378879

Epoch: 6| Step: 1
Training loss: 2.8802384460604213
Validation loss: 2.854407823430216

Epoch: 6| Step: 2
Training loss: 2.7950733711562
Validation loss: 2.85525664758068

Epoch: 6| Step: 3
Training loss: 3.304128180171868
Validation loss: 2.855592840360222

Epoch: 6| Step: 4
Training loss: 3.135585556466509
Validation loss: 2.853517109180844

Epoch: 6| Step: 5
Training loss: 3.161941533290698
Validation loss: 2.8564957745146353

Epoch: 6| Step: 6
Training loss: 3.398343911471764
Validation loss: 2.8525808977190366

Epoch: 6| Step: 7
Training loss: 3.658336337587228
Validation loss: 2.855949833460217

Epoch: 6| Step: 8
Training loss: 3.726336010462048
Validation loss: 2.8534543919847106

Epoch: 6| Step: 9
Training loss: 2.062279198127119
Validation loss: 2.8591474369345304

Epoch: 6| Step: 10
Training loss: 3.1749548781184873
Validation loss: 2.8586192919670843

Epoch: 6| Step: 11
Training loss: 3.535985691283261
Validation loss: 2.8606450132671193

Epoch: 6| Step: 12
Training loss: 3.066967566558422
Validation loss: 2.8609338262678476

Epoch: 6| Step: 13
Training loss: 3.288231969071202
Validation loss: 2.8644440993910965

Epoch: 40| Step: 0
Training loss: 2.6400057275305375
Validation loss: 2.8791073871223625

Epoch: 6| Step: 1
Training loss: 3.0446998069880142
Validation loss: 2.882163985656838

Epoch: 6| Step: 2
Training loss: 2.8084288908173964
Validation loss: 2.882100934736967

Epoch: 6| Step: 3
Training loss: 2.761640447777203
Validation loss: 2.898930224620915

Epoch: 6| Step: 4
Training loss: 3.369401314642738
Validation loss: 2.8508211406919886

Epoch: 6| Step: 5
Training loss: 2.911671493633995
Validation loss: 2.845143583084182

Epoch: 6| Step: 6
Training loss: 3.804851677268214
Validation loss: 2.8458751791118164

Epoch: 6| Step: 7
Training loss: 2.5087486730095927
Validation loss: 2.845703861920781

Epoch: 6| Step: 8
Training loss: 2.9847974228609853
Validation loss: 2.8473537319321225

Epoch: 6| Step: 9
Training loss: 3.46858063705346
Validation loss: 2.8463966965325485

Epoch: 6| Step: 10
Training loss: 2.994356410144611
Validation loss: 2.8425178369101403

Epoch: 6| Step: 11
Training loss: 3.692581813063455
Validation loss: 2.8454731486471627

Epoch: 6| Step: 12
Training loss: 3.3537289035629803
Validation loss: 2.8445331018567925

Epoch: 6| Step: 13
Training loss: 3.6390242434137248
Validation loss: 2.841373319938403

Epoch: 41| Step: 0
Training loss: 3.379235612108684
Validation loss: 2.842153135780149

Epoch: 6| Step: 1
Training loss: 3.0289642525216767
Validation loss: 2.842490920754198

Epoch: 6| Step: 2
Training loss: 2.862652343960547
Validation loss: 2.842563287332747

Epoch: 6| Step: 3
Training loss: 2.6918115850436113
Validation loss: 2.8415320129747856

Epoch: 6| Step: 4
Training loss: 2.5868927726863187
Validation loss: 2.841351487110594

Epoch: 6| Step: 5
Training loss: 3.942359831645926
Validation loss: 2.8405729656033136

Epoch: 6| Step: 6
Training loss: 2.0603648607036598
Validation loss: 2.8385411341067304

Epoch: 6| Step: 7
Training loss: 3.3918068228091047
Validation loss: 2.83786886203887

Epoch: 6| Step: 8
Training loss: 3.296998948212474
Validation loss: 2.8412479219009974

Epoch: 6| Step: 9
Training loss: 3.3861735431971645
Validation loss: 2.8401783642804137

Epoch: 6| Step: 10
Training loss: 3.2826227132342525
Validation loss: 2.836454088545316

Epoch: 6| Step: 11
Training loss: 3.2712913888973905
Validation loss: 2.8390465583804967

Epoch: 6| Step: 12
Training loss: 3.3331610317203255
Validation loss: 2.8385129672937772

Epoch: 6| Step: 13
Training loss: 2.926081602521826
Validation loss: 2.8448841781594427

Epoch: 42| Step: 0
Training loss: 3.1948574646868875
Validation loss: 2.854193836786733

Epoch: 6| Step: 1
Training loss: 2.800350140068635
Validation loss: 2.8691122126427078

Epoch: 6| Step: 2
Training loss: 2.966431204063216
Validation loss: 2.867156832938027

Epoch: 6| Step: 3
Training loss: 2.8395525797472767
Validation loss: 2.872847580180369

Epoch: 6| Step: 4
Training loss: 3.2347927837247465
Validation loss: 2.8595244083228684

Epoch: 6| Step: 5
Training loss: 3.2846060892068754
Validation loss: 2.8462091752808028

Epoch: 6| Step: 6
Training loss: 2.752461112403401
Validation loss: 2.8367277860293516

Epoch: 6| Step: 7
Training loss: 3.2622122568272207
Validation loss: 2.830969313467042

Epoch: 6| Step: 8
Training loss: 3.0414458590970117
Validation loss: 2.829182215718307

Epoch: 6| Step: 9
Training loss: 3.5606537435106995
Validation loss: 2.829424131678898

Epoch: 6| Step: 10
Training loss: 3.3381176152064596
Validation loss: 2.8275302843394376

Epoch: 6| Step: 11
Training loss: 3.16661725925919
Validation loss: 2.8275389321573314

Epoch: 6| Step: 12
Training loss: 3.093896419258503
Validation loss: 2.830447810204331

Epoch: 6| Step: 13
Training loss: 3.3412384868727445
Validation loss: 2.8305074224530675

Epoch: 43| Step: 0
Training loss: 3.1639449486265487
Validation loss: 2.8227896616201558

Epoch: 6| Step: 1
Training loss: 3.1851024212381076
Validation loss: 2.8237319036720083

Epoch: 6| Step: 2
Training loss: 3.4555183505406033
Validation loss: 2.8255238958260604

Epoch: 6| Step: 3
Training loss: 3.654296092079686
Validation loss: 2.823277936232305

Epoch: 6| Step: 4
Training loss: 2.0528073139099035
Validation loss: 2.8316642983467535

Epoch: 6| Step: 5
Training loss: 2.572790001185047
Validation loss: 2.8383052068512145

Epoch: 6| Step: 6
Training loss: 2.9386341259372606
Validation loss: 2.8509300592575886

Epoch: 6| Step: 7
Training loss: 3.1759399524556513
Validation loss: 2.850556180044529

Epoch: 6| Step: 8
Training loss: 3.2036887068286193
Validation loss: 2.852702175944602

Epoch: 6| Step: 9
Training loss: 2.8114320210802313
Validation loss: 2.848746468218121

Epoch: 6| Step: 10
Training loss: 3.303381840041463
Validation loss: 2.8341964701452427

Epoch: 6| Step: 11
Training loss: 2.796278735487671
Validation loss: 2.8256801983129227

Epoch: 6| Step: 12
Training loss: 3.597768643059803
Validation loss: 2.819499969811266

Epoch: 6| Step: 13
Training loss: 3.7899067046426116
Validation loss: 2.821236786733416

Epoch: 44| Step: 0
Training loss: 3.302327497021307
Validation loss: 2.8164150739732423

Epoch: 6| Step: 1
Training loss: 3.9722631329354092
Validation loss: 2.814104046183838

Epoch: 6| Step: 2
Training loss: 2.3971434839469654
Validation loss: 2.812293496520871

Epoch: 6| Step: 3
Training loss: 3.341541166794862
Validation loss: 2.815692890403979

Epoch: 6| Step: 4
Training loss: 2.590310263295082
Validation loss: 2.8138872706286975

Epoch: 6| Step: 5
Training loss: 2.905374046314695
Validation loss: 2.8122922285077947

Epoch: 6| Step: 6
Training loss: 2.765361622483882
Validation loss: 2.813717644831078

Epoch: 6| Step: 7
Training loss: 2.4624989233643944
Validation loss: 2.814549391051909

Epoch: 6| Step: 8
Training loss: 3.717542564492172
Validation loss: 2.8143548370663147

Epoch: 6| Step: 9
Training loss: 3.3009479548324743
Validation loss: 2.821442355789264

Epoch: 6| Step: 10
Training loss: 2.7916735653768296
Validation loss: 2.8552624729356406

Epoch: 6| Step: 11
Training loss: 3.538253186384761
Validation loss: 2.8716700986842234

Epoch: 6| Step: 12
Training loss: 2.8627849320440877
Validation loss: 2.892455610724414

Epoch: 6| Step: 13
Training loss: 3.5849682530656084
Validation loss: 2.881283298654409

Epoch: 45| Step: 0
Training loss: 2.8414820755623618
Validation loss: 2.824732969242982

Epoch: 6| Step: 1
Training loss: 3.217440737020689
Validation loss: 2.8078116422550736

Epoch: 6| Step: 2
Training loss: 2.6970200589133837
Validation loss: 2.802095859577509

Epoch: 6| Step: 3
Training loss: 3.0635713532812496
Validation loss: 2.8061089205679752

Epoch: 6| Step: 4
Training loss: 3.277209600856243
Validation loss: 2.8142270308384285

Epoch: 6| Step: 5
Training loss: 3.307507477374862
Validation loss: 2.832021633721681

Epoch: 6| Step: 6
Training loss: 3.5332927365639915
Validation loss: 2.8508736626175293

Epoch: 6| Step: 7
Training loss: 3.661558291869168
Validation loss: 2.820091122746526

Epoch: 6| Step: 8
Training loss: 2.2807746287400894
Validation loss: 2.8060703447645037

Epoch: 6| Step: 9
Training loss: 3.64577476817731
Validation loss: 2.8345644741405907

Epoch: 6| Step: 10
Training loss: 3.651729560657482
Validation loss: 2.817077983520458

Epoch: 6| Step: 11
Training loss: 2.4960944186166456
Validation loss: 2.806651812998014

Epoch: 6| Step: 12
Training loss: 3.0739398524419217
Validation loss: 2.799399400716025

Epoch: 6| Step: 13
Training loss: 2.2867949519674364
Validation loss: 2.798279123426942

Epoch: 46| Step: 0
Training loss: 2.9496096724564476
Validation loss: 2.796944644913541

Epoch: 6| Step: 1
Training loss: 2.035451446621298
Validation loss: 2.798560366122191

Epoch: 6| Step: 2
Training loss: 3.3150017845643824
Validation loss: 2.8010804647264003

Epoch: 6| Step: 3
Training loss: 3.099364917059481
Validation loss: 2.799385048537832

Epoch: 6| Step: 4
Training loss: 3.1964536088966042
Validation loss: 2.7972006045405395

Epoch: 6| Step: 5
Training loss: 3.585568344628771
Validation loss: 2.8090856457020137

Epoch: 6| Step: 6
Training loss: 3.572964741167477
Validation loss: 2.799315548594246

Epoch: 6| Step: 7
Training loss: 3.1239832940821084
Validation loss: 2.7988061196670557

Epoch: 6| Step: 8
Training loss: 2.766616643507034
Validation loss: 2.791131194297076

Epoch: 6| Step: 9
Training loss: 3.3936831135771084
Validation loss: 2.793103083776125

Epoch: 6| Step: 10
Training loss: 3.069441111137533
Validation loss: 2.7916887717427143

Epoch: 6| Step: 11
Training loss: 2.924238422071821
Validation loss: 2.7929161929076116

Epoch: 6| Step: 12
Training loss: 3.4967625495072894
Validation loss: 2.7908957639418155

Epoch: 6| Step: 13
Training loss: 2.296102173209924
Validation loss: 2.7900949779264406

Epoch: 47| Step: 0
Training loss: 3.288586072326911
Validation loss: 2.791309204014474

Epoch: 6| Step: 1
Training loss: 3.1818543345391515
Validation loss: 2.7903229594712005

Epoch: 6| Step: 2
Training loss: 1.9450774759390423
Validation loss: 2.7879220210528346

Epoch: 6| Step: 3
Training loss: 3.017795710450296
Validation loss: 2.784555640318709

Epoch: 6| Step: 4
Training loss: 3.1819947515764477
Validation loss: 2.785862903078102

Epoch: 6| Step: 5
Training loss: 3.445352636263523
Validation loss: 2.7863793649525004

Epoch: 6| Step: 6
Training loss: 3.5567454658319058
Validation loss: 2.7862032393559595

Epoch: 6| Step: 7
Training loss: 3.4105951435333486
Validation loss: 2.7863183365987445

Epoch: 6| Step: 8
Training loss: 2.737550210710015
Validation loss: 2.7855770348548927

Epoch: 6| Step: 9
Training loss: 3.252020867819185
Validation loss: 2.783163997747157

Epoch: 6| Step: 10
Training loss: 3.5530602388007546
Validation loss: 2.798514558320184

Epoch: 6| Step: 11
Training loss: 2.5693287923634496
Validation loss: 2.799321713819085

Epoch: 6| Step: 12
Training loss: 2.9810414495238566
Validation loss: 2.8073612936360206

Epoch: 6| Step: 13
Training loss: 2.6013759053531937
Validation loss: 2.8308697379648784

Epoch: 48| Step: 0
Training loss: 2.914243145372665
Validation loss: 2.8396280772168776

Epoch: 6| Step: 1
Training loss: 2.9997335951456927
Validation loss: 2.8448199765740987

Epoch: 6| Step: 2
Training loss: 2.4136574414610825
Validation loss: 2.822176287937768

Epoch: 6| Step: 3
Training loss: 3.546888309403374
Validation loss: 2.818124013311596

Epoch: 6| Step: 4
Training loss: 3.0510000621754387
Validation loss: 2.78291073777205

Epoch: 6| Step: 5
Training loss: 3.2599000531654982
Validation loss: 2.776113418279493

Epoch: 6| Step: 6
Training loss: 2.4655349656988723
Validation loss: 2.7762273593864095

Epoch: 6| Step: 7
Training loss: 3.107753618467942
Validation loss: 2.777069192223274

Epoch: 6| Step: 8
Training loss: 3.1544822047915693
Validation loss: 2.7788117466252724

Epoch: 6| Step: 9
Training loss: 3.5594718511330847
Validation loss: 2.7756641139430513

Epoch: 6| Step: 10
Training loss: 3.106326962290878
Validation loss: 2.777665200020188

Epoch: 6| Step: 11
Training loss: 3.780658391905005
Validation loss: 2.7775653001744134

Epoch: 6| Step: 12
Training loss: 2.9108728537801207
Validation loss: 2.780813857923859

Epoch: 6| Step: 13
Training loss: 2.5650437917559006
Validation loss: 2.7826079016828027

Epoch: 49| Step: 0
Training loss: 3.171571012315068
Validation loss: 2.7784279312313607

Epoch: 6| Step: 1
Training loss: 3.0192022896992987
Validation loss: 2.7764898446808943

Epoch: 6| Step: 2
Training loss: 3.1730297974330384
Validation loss: 2.7778082311321355

Epoch: 6| Step: 3
Training loss: 3.1802481642043743
Validation loss: 2.7700993092022808

Epoch: 6| Step: 4
Training loss: 3.043236697425558
Validation loss: 2.7751184319793083

Epoch: 6| Step: 5
Training loss: 3.337984194261581
Validation loss: 2.774090463256948

Epoch: 6| Step: 6
Training loss: 3.276083957579069
Validation loss: 2.7722765935346643

Epoch: 6| Step: 7
Training loss: 2.716209276774453
Validation loss: 2.7715169535320374

Epoch: 6| Step: 8
Training loss: 3.2528106566896766
Validation loss: 2.773228123855628

Epoch: 6| Step: 9
Training loss: 2.7446250406511874
Validation loss: 2.768910793871598

Epoch: 6| Step: 10
Training loss: 3.402690742746317
Validation loss: 2.7747756763869735

Epoch: 6| Step: 11
Training loss: 3.024312210708305
Validation loss: 2.7702426115713985

Epoch: 6| Step: 12
Training loss: 2.787234350983251
Validation loss: 2.76883058863327

Epoch: 6| Step: 13
Training loss: 3.058744970020544
Validation loss: 2.7644327415357455

Epoch: 50| Step: 0
Training loss: 3.1568069721958913
Validation loss: 2.7669777041394537

Epoch: 6| Step: 1
Training loss: 2.8129067020939496
Validation loss: 2.7672169055424254

Epoch: 6| Step: 2
Training loss: 2.906258203638455
Validation loss: 2.760261128819371

Epoch: 6| Step: 3
Training loss: 3.5170239187234777
Validation loss: 2.76134063679943

Epoch: 6| Step: 4
Training loss: 3.174395682426562
Validation loss: 2.7596723863006765

Epoch: 6| Step: 5
Training loss: 2.8438942002845518
Validation loss: 2.759716500665144

Epoch: 6| Step: 6
Training loss: 2.978930555114917
Validation loss: 2.765078202797479

Epoch: 6| Step: 7
Training loss: 2.911016349932648
Validation loss: 2.7644414689623797

Epoch: 6| Step: 8
Training loss: 3.470325284107334
Validation loss: 2.7574708890803987

Epoch: 6| Step: 9
Training loss: 3.288922304622334
Validation loss: 2.759722737633243

Epoch: 6| Step: 10
Training loss: 2.9145939319373353
Validation loss: 2.7570462962853255

Epoch: 6| Step: 11
Training loss: 3.4648926053048723
Validation loss: 2.7582858188205983

Epoch: 6| Step: 12
Training loss: 2.3648315389045074
Validation loss: 2.753693767034135

Epoch: 6| Step: 13
Training loss: 3.1451720159456613
Validation loss: 2.7510034514696833

Epoch: 51| Step: 0
Training loss: 2.5866884368622696
Validation loss: 2.74941660266637

Epoch: 6| Step: 1
Training loss: 3.3962959645305535
Validation loss: 2.750657545551558

Epoch: 6| Step: 2
Training loss: 3.3663459310308803
Validation loss: 2.7496829553975144

Epoch: 6| Step: 3
Training loss: 3.04617066678825
Validation loss: 2.7547193865236705

Epoch: 6| Step: 4
Training loss: 3.3287526286591462
Validation loss: 2.7529642735686295

Epoch: 6| Step: 5
Training loss: 3.0432160146049196
Validation loss: 2.7534795228748523

Epoch: 6| Step: 6
Training loss: 2.71010935334015
Validation loss: 2.752048115689199

Epoch: 6| Step: 7
Training loss: 3.3233363126730566
Validation loss: 2.751459599465269

Epoch: 6| Step: 8
Training loss: 3.0993752249894366
Validation loss: 2.7498676234627446

Epoch: 6| Step: 9
Training loss: 2.868610579815666
Validation loss: 2.750133995900908

Epoch: 6| Step: 10
Training loss: 2.905453480503201
Validation loss: 2.748341159794364

Epoch: 6| Step: 11
Training loss: 3.8288483850963186
Validation loss: 2.7485353805715067

Epoch: 6| Step: 12
Training loss: 2.4527574008639084
Validation loss: 2.749757759783415

Epoch: 6| Step: 13
Training loss: 2.6030214360072943
Validation loss: 2.7507541988936803

Epoch: 52| Step: 0
Training loss: 3.2888219749958085
Validation loss: 2.7580723663752793

Epoch: 6| Step: 1
Training loss: 3.1430360260129744
Validation loss: 2.751223211930928

Epoch: 6| Step: 2
Training loss: 2.366462117968515
Validation loss: 2.7646154850003906

Epoch: 6| Step: 3
Training loss: 2.8238285370231577
Validation loss: 2.778019349521908

Epoch: 6| Step: 4
Training loss: 3.2125949711992345
Validation loss: 2.8083684949796703

Epoch: 6| Step: 5
Training loss: 3.5266948115686607
Validation loss: 2.8115164856744848

Epoch: 6| Step: 6
Training loss: 3.1266077102221517
Validation loss: 2.7711009037401197

Epoch: 6| Step: 7
Training loss: 3.109210292728554
Validation loss: 2.750361097238054

Epoch: 6| Step: 8
Training loss: 3.4961293479769373
Validation loss: 2.7415331062703974

Epoch: 6| Step: 9
Training loss: 3.1167701690405556
Validation loss: 2.7404414233285954

Epoch: 6| Step: 10
Training loss: 2.7105190162969746
Validation loss: 2.7441579818833546

Epoch: 6| Step: 11
Training loss: 3.0055876194467177
Validation loss: 2.748142733007925

Epoch: 6| Step: 12
Training loss: 3.010456458932015
Validation loss: 2.74794075421908

Epoch: 6| Step: 13
Training loss: 2.9372607194557343
Validation loss: 2.749526504219651

Epoch: 53| Step: 0
Training loss: 2.6796627655222345
Validation loss: 2.747012466738465

Epoch: 6| Step: 1
Training loss: 2.9240898672610673
Validation loss: 2.7495142488121984

Epoch: 6| Step: 2
Training loss: 3.306938541013136
Validation loss: 2.7486456465998845

Epoch: 6| Step: 3
Training loss: 2.365908538475835
Validation loss: 2.744433934013901

Epoch: 6| Step: 4
Training loss: 2.864014410685934
Validation loss: 2.747947160652587

Epoch: 6| Step: 5
Training loss: 2.4263675491024443
Validation loss: 2.7442280160120673

Epoch: 6| Step: 6
Training loss: 3.427137256572988
Validation loss: 2.743233221581315

Epoch: 6| Step: 7
Training loss: 3.577169099082085
Validation loss: 2.741983974614331

Epoch: 6| Step: 8
Training loss: 3.268342999708739
Validation loss: 2.7383589600495153

Epoch: 6| Step: 9
Training loss: 3.358669189116997
Validation loss: 2.738867324383891

Epoch: 6| Step: 10
Training loss: 2.7104889336426767
Validation loss: 2.7349407533086274

Epoch: 6| Step: 11
Training loss: 3.5183508583932257
Validation loss: 2.7340034272245437

Epoch: 6| Step: 12
Training loss: 2.9725643349271285
Validation loss: 2.734218846797724

Epoch: 6| Step: 13
Training loss: 3.497691483071998
Validation loss: 2.7347677081849517

Epoch: 54| Step: 0
Training loss: 4.193798736880322
Validation loss: 2.7320066081041174

Epoch: 6| Step: 1
Training loss: 3.363062905768237
Validation loss: 2.7345942789920477

Epoch: 6| Step: 2
Training loss: 2.99629618571321
Validation loss: 2.7333536582759352

Epoch: 6| Step: 3
Training loss: 2.499471990139555
Validation loss: 2.7461131670257544

Epoch: 6| Step: 4
Training loss: 3.3696672199427553
Validation loss: 2.7395322256765398

Epoch: 6| Step: 5
Training loss: 2.8757263592883553
Validation loss: 2.7417262945477407

Epoch: 6| Step: 6
Training loss: 3.0079976606968652
Validation loss: 2.73426886614779

Epoch: 6| Step: 7
Training loss: 3.0405241679990844
Validation loss: 2.737792619008493

Epoch: 6| Step: 8
Training loss: 2.7272607297344456
Validation loss: 2.74057075288808

Epoch: 6| Step: 9
Training loss: 2.6095188124081443
Validation loss: 2.7464815435806633

Epoch: 6| Step: 10
Training loss: 2.892729122282683
Validation loss: 2.738625909873208

Epoch: 6| Step: 11
Training loss: 2.9993908581609587
Validation loss: 2.7320668509723847

Epoch: 6| Step: 12
Training loss: 2.670688745053478
Validation loss: 2.733075626879272

Epoch: 6| Step: 13
Training loss: 3.2117338283651615
Validation loss: 2.735248447031047

Epoch: 55| Step: 0
Training loss: 2.4046355937786474
Validation loss: 2.7372924832043855

Epoch: 6| Step: 1
Training loss: 3.1102511451117487
Validation loss: 2.735262654927775

Epoch: 6| Step: 2
Training loss: 2.598184311047306
Validation loss: 2.7284410162165016

Epoch: 6| Step: 3
Training loss: 3.3751046906234565
Validation loss: 2.729748296080304

Epoch: 6| Step: 4
Training loss: 2.784271827438877
Validation loss: 2.7457330863918195

Epoch: 6| Step: 5
Training loss: 2.5811743995365277
Validation loss: 2.7313947308538116

Epoch: 6| Step: 6
Training loss: 2.973533871763266
Validation loss: 2.7230909306003017

Epoch: 6| Step: 7
Training loss: 3.4814701031287765
Validation loss: 2.7221630522649862

Epoch: 6| Step: 8
Training loss: 3.1661612626030444
Validation loss: 2.723926991445314

Epoch: 6| Step: 9
Training loss: 3.0289061618398554
Validation loss: 2.7242527202301607

Epoch: 6| Step: 10
Training loss: 3.412771439149423
Validation loss: 2.723383352698137

Epoch: 6| Step: 11
Training loss: 3.114094741585476
Validation loss: 2.7209496252130796

Epoch: 6| Step: 12
Training loss: 3.2284335052698885
Validation loss: 2.723642286243304

Epoch: 6| Step: 13
Training loss: 3.398584963350599
Validation loss: 2.728607029864797

Epoch: 56| Step: 0
Training loss: 2.587420911087017
Validation loss: 2.730397550308969

Epoch: 6| Step: 1
Training loss: 2.4064556876120595
Validation loss: 2.73237606646628

Epoch: 6| Step: 2
Training loss: 3.1097871900159824
Validation loss: 2.7335422261469136

Epoch: 6| Step: 3
Training loss: 3.057523615723281
Validation loss: 2.734894593264876

Epoch: 6| Step: 4
Training loss: 3.0606878719217048
Validation loss: 2.735942049100539

Epoch: 6| Step: 5
Training loss: 3.1299137393655343
Validation loss: 2.733574161479813

Epoch: 6| Step: 6
Training loss: 3.2598940559443714
Validation loss: 2.730624436990331

Epoch: 6| Step: 7
Training loss: 3.31062811017588
Validation loss: 2.7283396503861135

Epoch: 6| Step: 8
Training loss: 3.1197412112088
Validation loss: 2.7281228606977272

Epoch: 6| Step: 9
Training loss: 3.5613582186794086
Validation loss: 2.7264788017398245

Epoch: 6| Step: 10
Training loss: 3.039573959813733
Validation loss: 2.7242505802961334

Epoch: 6| Step: 11
Training loss: 2.932184808025082
Validation loss: 2.723994513856279

Epoch: 6| Step: 12
Training loss: 2.98373901620864
Validation loss: 2.724194490651911

Epoch: 6| Step: 13
Training loss: 3.152303815964529
Validation loss: 2.726676457365424

Epoch: 57| Step: 0
Training loss: 3.115592682421171
Validation loss: 2.735355882167907

Epoch: 6| Step: 1
Training loss: 2.464534588995749
Validation loss: 2.7408084295716413

Epoch: 6| Step: 2
Training loss: 3.127242847485375
Validation loss: 2.7441391050179584

Epoch: 6| Step: 3
Training loss: 3.0724278120433173
Validation loss: 2.7413297193366617

Epoch: 6| Step: 4
Training loss: 2.643069608535955
Validation loss: 2.747145977516357

Epoch: 6| Step: 5
Training loss: 3.2625947609655395
Validation loss: 2.754530153835408

Epoch: 6| Step: 6
Training loss: 3.5256995406552387
Validation loss: 2.75928097977486

Epoch: 6| Step: 7
Training loss: 2.831456535166074
Validation loss: 2.7391439232313695

Epoch: 6| Step: 8
Training loss: 2.9747437054164916
Validation loss: 2.731081025263304

Epoch: 6| Step: 9
Training loss: 3.3193281801542187
Validation loss: 2.7226376327118476

Epoch: 6| Step: 10
Training loss: 2.875833141850484
Validation loss: 2.717525674678453

Epoch: 6| Step: 11
Training loss: 2.9557330205726986
Validation loss: 2.719037035277371

Epoch: 6| Step: 12
Training loss: 3.1842631940895525
Validation loss: 2.7146776095534677

Epoch: 6| Step: 13
Training loss: 3.2400137726761824
Validation loss: 2.715560793605274

Epoch: 58| Step: 0
Training loss: 3.338118329436996
Validation loss: 2.716093063294139

Epoch: 6| Step: 1
Training loss: 2.703830781206934
Validation loss: 2.7126954426904875

Epoch: 6| Step: 2
Training loss: 2.680946521434819
Validation loss: 2.711899452460067

Epoch: 6| Step: 3
Training loss: 3.324247725435557
Validation loss: 2.7107632309043064

Epoch: 6| Step: 4
Training loss: 2.992170607715862
Validation loss: 2.7120757943068607

Epoch: 6| Step: 5
Training loss: 2.7249179022784733
Validation loss: 2.708151707266192

Epoch: 6| Step: 6
Training loss: 2.856731923388068
Validation loss: 2.710177588922219

Epoch: 6| Step: 7
Training loss: 2.7980952664368224
Validation loss: 2.709608068295305

Epoch: 6| Step: 8
Training loss: 3.4136241919551376
Validation loss: 2.707649490754295

Epoch: 6| Step: 9
Training loss: 2.612583221132163
Validation loss: 2.706319728383947

Epoch: 6| Step: 10
Training loss: 3.370456604403618
Validation loss: 2.7108943167770834

Epoch: 6| Step: 11
Training loss: 3.2208479183075704
Validation loss: 2.707482631409747

Epoch: 6| Step: 12
Training loss: 3.191700579775989
Validation loss: 2.713769790979986

Epoch: 6| Step: 13
Training loss: 3.1878184739127837
Validation loss: 2.715784200860329

Epoch: 59| Step: 0
Training loss: 2.7465924044943
Validation loss: 2.705541737328088

Epoch: 6| Step: 1
Training loss: 3.0318708275628854
Validation loss: 2.702483114784948

Epoch: 6| Step: 2
Training loss: 2.9661738411393515
Validation loss: 2.7064026576262283

Epoch: 6| Step: 3
Training loss: 3.2165152189611343
Validation loss: 2.702924497253888

Epoch: 6| Step: 4
Training loss: 2.5548810506405895
Validation loss: 2.7061641778121333

Epoch: 6| Step: 5
Training loss: 3.224743346418216
Validation loss: 2.7075252479082987

Epoch: 6| Step: 6
Training loss: 2.2288570961544676
Validation loss: 2.707002515053918

Epoch: 6| Step: 7
Training loss: 2.986407162285919
Validation loss: 2.7094296734546357

Epoch: 6| Step: 8
Training loss: 3.4901463903641456
Validation loss: 2.7017050930781257

Epoch: 6| Step: 9
Training loss: 2.6222459787524692
Validation loss: 2.695032562656376

Epoch: 6| Step: 10
Training loss: 3.2753804342603843
Validation loss: 2.700838784610502

Epoch: 6| Step: 11
Training loss: 3.6794544964213585
Validation loss: 2.6982480972094263

Epoch: 6| Step: 12
Training loss: 2.859020440470533
Validation loss: 2.7007064265873972

Epoch: 6| Step: 13
Training loss: 3.4112025662510934
Validation loss: 2.6978374651228

Epoch: 60| Step: 0
Training loss: 2.5651969673423145
Validation loss: 2.699628750349343

Epoch: 6| Step: 1
Training loss: 2.5455821681850477
Validation loss: 2.698566975249525

Epoch: 6| Step: 2
Training loss: 3.1068629560004997
Validation loss: 2.6964132925527715

Epoch: 6| Step: 3
Training loss: 3.3555311345972436
Validation loss: 2.6989214532955894

Epoch: 6| Step: 4
Training loss: 3.3905012398208267
Validation loss: 2.698851382885256

Epoch: 6| Step: 5
Training loss: 3.2693468996713433
Validation loss: 2.6955519959923864

Epoch: 6| Step: 6
Training loss: 2.632022365556206
Validation loss: 2.6996143416188225

Epoch: 6| Step: 7
Training loss: 3.0140604496736807
Validation loss: 2.6993619451276545

Epoch: 6| Step: 8
Training loss: 2.694725702513317
Validation loss: 2.7021595017019027

Epoch: 6| Step: 9
Training loss: 3.12198019986469
Validation loss: 2.7063412476420625

Epoch: 6| Step: 10
Training loss: 3.00991090180088
Validation loss: 2.7150968771071686

Epoch: 6| Step: 11
Training loss: 3.3139345913258365
Validation loss: 2.7322436354779978

Epoch: 6| Step: 12
Training loss: 3.24428172668761
Validation loss: 2.7163794931245127

Epoch: 6| Step: 13
Training loss: 2.988803952446883
Validation loss: 2.7082885157913292

Epoch: 61| Step: 0
Training loss: 3.2411030989611707
Validation loss: 2.6989696885162306

Epoch: 6| Step: 1
Training loss: 3.3176146553424153
Validation loss: 2.7010975872284533

Epoch: 6| Step: 2
Training loss: 3.1816568110776124
Validation loss: 2.690582158273783

Epoch: 6| Step: 3
Training loss: 2.1986709915374605
Validation loss: 2.6919277449202874

Epoch: 6| Step: 4
Training loss: 3.146600911724977
Validation loss: 2.6930544175340385

Epoch: 6| Step: 5
Training loss: 3.2122523824650426
Validation loss: 2.6953173926999967

Epoch: 6| Step: 6
Training loss: 3.0501406652813454
Validation loss: 2.6972349031358243

Epoch: 6| Step: 7
Training loss: 2.4305319345931053
Validation loss: 2.693954720721819

Epoch: 6| Step: 8
Training loss: 3.1468910982085756
Validation loss: 2.695019036846642

Epoch: 6| Step: 9
Training loss: 3.340895816113693
Validation loss: 2.701762101276825

Epoch: 6| Step: 10
Training loss: 3.183149772531169
Validation loss: 2.700460017100122

Epoch: 6| Step: 11
Training loss: 3.0126981614654276
Validation loss: 2.693603795796773

Epoch: 6| Step: 12
Training loss: 2.5812608547767564
Validation loss: 2.698079303402555

Epoch: 6| Step: 13
Training loss: 3.110314308793776
Validation loss: 2.695139733677991

Epoch: 62| Step: 0
Training loss: 4.046204971755869
Validation loss: 2.694931742896782

Epoch: 6| Step: 1
Training loss: 2.732041589479023
Validation loss: 2.695314763730885

Epoch: 6| Step: 2
Training loss: 2.317281470833783
Validation loss: 2.695014604962719

Epoch: 6| Step: 3
Training loss: 3.4810494603142037
Validation loss: 2.6987388866584663

Epoch: 6| Step: 4
Training loss: 2.728806323851966
Validation loss: 2.693213605698454

Epoch: 6| Step: 5
Training loss: 3.089837885681066
Validation loss: 2.6953437849728585

Epoch: 6| Step: 6
Training loss: 3.478339883176385
Validation loss: 2.6990862650426037

Epoch: 6| Step: 7
Training loss: 3.111550954728537
Validation loss: 2.703920172380762

Epoch: 6| Step: 8
Training loss: 3.1913720342699947
Validation loss: 2.6912109993807287

Epoch: 6| Step: 9
Training loss: 2.904110356737727
Validation loss: 2.684295970812494

Epoch: 6| Step: 10
Training loss: 2.826389939674809
Validation loss: 2.684334642475378

Epoch: 6| Step: 11
Training loss: 2.4738053338106143
Validation loss: 2.686640406180264

Epoch: 6| Step: 12
Training loss: 2.0685852907193527
Validation loss: 2.6877793426599097

Epoch: 6| Step: 13
Training loss: 3.4185331565249943
Validation loss: 2.6903126548693566

Epoch: 63| Step: 0
Training loss: 3.239196132731655
Validation loss: 2.6863677140512934

Epoch: 6| Step: 1
Training loss: 3.0383500781690325
Validation loss: 2.687173612272766

Epoch: 6| Step: 2
Training loss: 2.7593488439268548
Validation loss: 2.686446325542193

Epoch: 6| Step: 3
Training loss: 2.9517565589225154
Validation loss: 2.6857061482889177

Epoch: 6| Step: 4
Training loss: 2.696703388858417
Validation loss: 2.680374413834186

Epoch: 6| Step: 5
Training loss: 2.7281433594250863
Validation loss: 2.6815223540798225

Epoch: 6| Step: 6
Training loss: 3.137379349900274
Validation loss: 2.680433446154611

Epoch: 6| Step: 7
Training loss: 3.29805904297175
Validation loss: 2.677783384389444

Epoch: 6| Step: 8
Training loss: 3.1125824453932327
Validation loss: 2.69335638622838

Epoch: 6| Step: 9
Training loss: 3.0876401429282008
Validation loss: 2.701430068718982

Epoch: 6| Step: 10
Training loss: 3.6592438007293624
Validation loss: 2.7045667934538686

Epoch: 6| Step: 11
Training loss: 2.8445037848852586
Validation loss: 2.713081150887153

Epoch: 6| Step: 12
Training loss: 2.998940916674435
Validation loss: 2.7144494740155727

Epoch: 6| Step: 13
Training loss: 2.50119743280491
Validation loss: 2.6940691866731292

Epoch: 64| Step: 0
Training loss: 3.409412281031847
Validation loss: 2.6828220784825003

Epoch: 6| Step: 1
Training loss: 3.256008755758824
Validation loss: 2.6760220312652505

Epoch: 6| Step: 2
Training loss: 3.022374639064837
Validation loss: 2.672037614422974

Epoch: 6| Step: 3
Training loss: 3.0675147901705446
Validation loss: 2.670935675272643

Epoch: 6| Step: 4
Training loss: 2.966546134071771
Validation loss: 2.675345487406097

Epoch: 6| Step: 5
Training loss: 2.8371344108164953
Validation loss: 2.671698044767223

Epoch: 6| Step: 6
Training loss: 3.0420642923838055
Validation loss: 2.6703464328842923

Epoch: 6| Step: 7
Training loss: 3.0173880211659685
Validation loss: 2.6685580697241265

Epoch: 6| Step: 8
Training loss: 2.5149667008851786
Validation loss: 2.6719105057371277

Epoch: 6| Step: 9
Training loss: 3.6233229868675916
Validation loss: 2.6724611445511735

Epoch: 6| Step: 10
Training loss: 1.8990610613494994
Validation loss: 2.6803301490226414

Epoch: 6| Step: 11
Training loss: 3.406305715122753
Validation loss: 2.698242177998849

Epoch: 6| Step: 12
Training loss: 2.9694805651772387
Validation loss: 2.7031598117039497

Epoch: 6| Step: 13
Training loss: 2.488453043182897
Validation loss: 2.7342313020277347

Epoch: 65| Step: 0
Training loss: 2.3402337718817035
Validation loss: 2.734732777617669

Epoch: 6| Step: 1
Training loss: 3.3247693835140275
Validation loss: 2.7751303646141516

Epoch: 6| Step: 2
Training loss: 3.334074764445469
Validation loss: 2.691958478783208

Epoch: 6| Step: 3
Training loss: 2.77377841627187
Validation loss: 2.667423363646611

Epoch: 6| Step: 4
Training loss: 2.8167379874354768
Validation loss: 2.6660540021799384

Epoch: 6| Step: 5
Training loss: 3.581870172138252
Validation loss: 2.665753047188185

Epoch: 6| Step: 6
Training loss: 2.90536895851374
Validation loss: 2.6681843759692825

Epoch: 6| Step: 7
Training loss: 2.838304944914684
Validation loss: 2.6706564484367807

Epoch: 6| Step: 8
Training loss: 2.8839744149182946
Validation loss: 2.6671788072502376

Epoch: 6| Step: 9
Training loss: 2.6097369828099155
Validation loss: 2.6654258008558074

Epoch: 6| Step: 10
Training loss: 3.0786222259609355
Validation loss: 2.665343692518389

Epoch: 6| Step: 11
Training loss: 2.9653107648489234
Validation loss: 2.665044130541229

Epoch: 6| Step: 12
Training loss: 2.8519500887062663
Validation loss: 2.6649883411548543

Epoch: 6| Step: 13
Training loss: 4.025339688011663
Validation loss: 2.6639208487889205

Epoch: 66| Step: 0
Training loss: 3.140584916955036
Validation loss: 2.66260013314036

Epoch: 6| Step: 1
Training loss: 2.8929958209348126
Validation loss: 2.667755205368145

Epoch: 6| Step: 2
Training loss: 2.9536343897126573
Validation loss: 2.6689434615301826

Epoch: 6| Step: 3
Training loss: 2.6291249879978413
Validation loss: 2.669020726661776

Epoch: 6| Step: 4
Training loss: 2.942649548148779
Validation loss: 2.665682405928098

Epoch: 6| Step: 5
Training loss: 3.431272935356379
Validation loss: 2.6678094997882895

Epoch: 6| Step: 6
Training loss: 3.258019017688003
Validation loss: 2.663438876471054

Epoch: 6| Step: 7
Training loss: 2.830854247604281
Validation loss: 2.6698698742745877

Epoch: 6| Step: 8
Training loss: 3.7016867890913856
Validation loss: 2.6662727232891648

Epoch: 6| Step: 9
Training loss: 2.731363960175717
Validation loss: 2.671489426533978

Epoch: 6| Step: 10
Training loss: 2.480472979204072
Validation loss: 2.6667596178492983

Epoch: 6| Step: 11
Training loss: 2.3141780641536345
Validation loss: 2.666734989377995

Epoch: 6| Step: 12
Training loss: 3.1324024265007604
Validation loss: 2.6725576311082855

Epoch: 6| Step: 13
Training loss: 3.371203936812714
Validation loss: 2.6757342073421935

Epoch: 67| Step: 0
Training loss: 2.6893725414295915
Validation loss: 2.6954706398570427

Epoch: 6| Step: 1
Training loss: 3.0632499243747855
Validation loss: 2.740179240303776

Epoch: 6| Step: 2
Training loss: 3.1299675178670516
Validation loss: 2.7507547315186898

Epoch: 6| Step: 3
Training loss: 3.1354089950180404
Validation loss: 2.7181612706190883

Epoch: 6| Step: 4
Training loss: 2.835250224755321
Validation loss: 2.6850676254775987

Epoch: 6| Step: 5
Training loss: 3.1214215962237577
Validation loss: 2.6641264097569737

Epoch: 6| Step: 6
Training loss: 3.0767630260362577
Validation loss: 2.6613650781927927

Epoch: 6| Step: 7
Training loss: 2.912643782705266
Validation loss: 2.6646000990269245

Epoch: 6| Step: 8
Training loss: 3.006129837013841
Validation loss: 2.6701275145234487

Epoch: 6| Step: 9
Training loss: 2.9829420873868977
Validation loss: 2.6756087766516625

Epoch: 6| Step: 10
Training loss: 3.4636224187553397
Validation loss: 2.691104923663091

Epoch: 6| Step: 11
Training loss: 2.3584073337047533
Validation loss: 2.661834351813758

Epoch: 6| Step: 12
Training loss: 3.5629446187218656
Validation loss: 2.6620750376580093

Epoch: 6| Step: 13
Training loss: 2.7288549890735494
Validation loss: 2.6630397189319486

Epoch: 68| Step: 0
Training loss: 3.5518825321362653
Validation loss: 2.67921619497406

Epoch: 6| Step: 1
Training loss: 3.398244146349441
Validation loss: 2.666360195940663

Epoch: 6| Step: 2
Training loss: 2.9478790676203888
Validation loss: 2.664970113672155

Epoch: 6| Step: 3
Training loss: 2.7865842606560167
Validation loss: 2.6701280675520382

Epoch: 6| Step: 4
Training loss: 2.082905483817401
Validation loss: 2.692451860103363

Epoch: 6| Step: 5
Training loss: 3.2677476910762526
Validation loss: 2.7291316083622537

Epoch: 6| Step: 6
Training loss: 2.8792422964170714
Validation loss: 2.737394430623761

Epoch: 6| Step: 7
Training loss: 3.208286351111755
Validation loss: 2.708744099958756

Epoch: 6| Step: 8
Training loss: 2.583341557479401
Validation loss: 2.6642401326920653

Epoch: 6| Step: 9
Training loss: 3.679057526976739
Validation loss: 2.6557537254657837

Epoch: 6| Step: 10
Training loss: 2.971033121875166
Validation loss: 2.6512841477359808

Epoch: 6| Step: 11
Training loss: 3.167609291991199
Validation loss: 2.6569302975589424

Epoch: 6| Step: 12
Training loss: 2.1828772609663813
Validation loss: 2.6545041788757118

Epoch: 6| Step: 13
Training loss: 2.885613793939417
Validation loss: 2.657809339919333

Epoch: 69| Step: 0
Training loss: 3.1795528298992166
Validation loss: 2.656855717410219

Epoch: 6| Step: 1
Training loss: 3.2883012846673765
Validation loss: 2.6554235959539763

Epoch: 6| Step: 2
Training loss: 2.9112245378244785
Validation loss: 2.6525106893870327

Epoch: 6| Step: 3
Training loss: 3.1237279210220525
Validation loss: 2.6542226545323544

Epoch: 6| Step: 4
Training loss: 3.0961719627233086
Validation loss: 2.6540701446803876

Epoch: 6| Step: 5
Training loss: 3.462135124950077
Validation loss: 2.650806499655544

Epoch: 6| Step: 6
Training loss: 3.268133049066976
Validation loss: 2.652297762766419

Epoch: 6| Step: 7
Training loss: 3.0628629196931985
Validation loss: 2.661761597451687

Epoch: 6| Step: 8
Training loss: 2.455789661707376
Validation loss: 2.6573591480252268

Epoch: 6| Step: 9
Training loss: 2.7812505143411568
Validation loss: 2.669655149312081

Epoch: 6| Step: 10
Training loss: 2.1417580828718434
Validation loss: 2.669050289300131

Epoch: 6| Step: 11
Training loss: 3.2104533403609476
Validation loss: 2.6761903157167337

Epoch: 6| Step: 12
Training loss: 2.4422149051390423
Validation loss: 2.66454158665173

Epoch: 6| Step: 13
Training loss: 3.3183547767037003
Validation loss: 2.672707384422612

Epoch: 70| Step: 0
Training loss: 3.0734552116252174
Validation loss: 2.6583579398234165

Epoch: 6| Step: 1
Training loss: 2.777225282613159
Validation loss: 2.6580020094622667

Epoch: 6| Step: 2
Training loss: 3.2133303448622277
Validation loss: 2.649188341655164

Epoch: 6| Step: 3
Training loss: 2.847079999726265
Validation loss: 2.656264613073352

Epoch: 6| Step: 4
Training loss: 2.942969080532816
Validation loss: 2.6506279609012666

Epoch: 6| Step: 5
Training loss: 3.2477127242804475
Validation loss: 2.651401104647142

Epoch: 6| Step: 6
Training loss: 3.149071414257658
Validation loss: 2.655404270758022

Epoch: 6| Step: 7
Training loss: 2.8680791066218556
Validation loss: 2.656004307656292

Epoch: 6| Step: 8
Training loss: 3.1711686574016404
Validation loss: 2.6482914284099732

Epoch: 6| Step: 9
Training loss: 2.9829529574831746
Validation loss: 2.6417982816751175

Epoch: 6| Step: 10
Training loss: 2.8320723326761565
Validation loss: 2.6426095628006387

Epoch: 6| Step: 11
Training loss: 2.924329899380813
Validation loss: 2.6412016351911634

Epoch: 6| Step: 12
Training loss: 3.168022334048989
Validation loss: 2.6419427346706224

Epoch: 6| Step: 13
Training loss: 2.1899408074657765
Validation loss: 2.642285083346453

Epoch: 71| Step: 0
Training loss: 3.460138301841574
Validation loss: 2.637614491853892

Epoch: 6| Step: 1
Training loss: 3.0489127363039095
Validation loss: 2.642043628065896

Epoch: 6| Step: 2
Training loss: 3.4806427403725877
Validation loss: 2.6413509814824616

Epoch: 6| Step: 3
Training loss: 3.012149052735199
Validation loss: 2.6419674826652244

Epoch: 6| Step: 4
Training loss: 3.23391115852393
Validation loss: 2.6386955907894794

Epoch: 6| Step: 5
Training loss: 2.904318875484089
Validation loss: 2.6350263074394564

Epoch: 6| Step: 6
Training loss: 3.2453447894058995
Validation loss: 2.638817094676461

Epoch: 6| Step: 7
Training loss: 2.729371643134224
Validation loss: 2.6595904227493636

Epoch: 6| Step: 8
Training loss: 2.809939087448498
Validation loss: 2.6718260559039706

Epoch: 6| Step: 9
Training loss: 2.823763355562965
Validation loss: 2.719160749302845

Epoch: 6| Step: 10
Training loss: 2.767270218459899
Validation loss: 2.7341846780712893

Epoch: 6| Step: 11
Training loss: 2.884332189107909
Validation loss: 2.7880057091883934

Epoch: 6| Step: 12
Training loss: 2.5600374996895834
Validation loss: 2.671977903453042

Epoch: 6| Step: 13
Training loss: 2.201611912364392
Validation loss: 2.6330222772314253

Epoch: 72| Step: 0
Training loss: 3.193714740356978
Validation loss: 2.6350304160306814

Epoch: 6| Step: 1
Training loss: 2.9210125471379116
Validation loss: 2.6341520504301803

Epoch: 6| Step: 2
Training loss: 2.80526191970935
Validation loss: 2.643319864665363

Epoch: 6| Step: 3
Training loss: 2.691359299470291
Validation loss: 2.6613680248656966

Epoch: 6| Step: 4
Training loss: 3.3564373567879238
Validation loss: 2.6716977895256386

Epoch: 6| Step: 5
Training loss: 2.797114356683551
Validation loss: 2.660544333122334

Epoch: 6| Step: 6
Training loss: 2.9353329395909347
Validation loss: 2.6527005149486347

Epoch: 6| Step: 7
Training loss: 2.3891529213339515
Validation loss: 2.6475199735876647

Epoch: 6| Step: 8
Training loss: 3.1548857809390634
Validation loss: 2.6441603598760497

Epoch: 6| Step: 9
Training loss: 3.108450594029125
Validation loss: 2.6426222654829705

Epoch: 6| Step: 10
Training loss: 3.269309999187684
Validation loss: 2.640572133984972

Epoch: 6| Step: 11
Training loss: 3.060742866750212
Validation loss: 2.634282116734187

Epoch: 6| Step: 12
Training loss: 3.1104594884140417
Validation loss: 2.637169709466617

Epoch: 6| Step: 13
Training loss: 3.3151564113258933
Validation loss: 2.641849098907794

Epoch: 73| Step: 0
Training loss: 3.6510611990253357
Validation loss: 2.6435716584245386

Epoch: 6| Step: 1
Training loss: 2.6782280420268316
Validation loss: 2.6516368370409644

Epoch: 6| Step: 2
Training loss: 2.705759341402414
Validation loss: 2.6550259804710237

Epoch: 6| Step: 3
Training loss: 1.95624110551951
Validation loss: 2.656459148166747

Epoch: 6| Step: 4
Training loss: 3.4720300511057287
Validation loss: 2.673447134011697

Epoch: 6| Step: 5
Training loss: 2.6639023002717397
Validation loss: 2.662852020617561

Epoch: 6| Step: 6
Training loss: 2.859142189762394
Validation loss: 2.6664560648859044

Epoch: 6| Step: 7
Training loss: 3.006702882276538
Validation loss: 2.6732238462069833

Epoch: 6| Step: 8
Training loss: 3.2094767791150494
Validation loss: 2.642493021037819

Epoch: 6| Step: 9
Training loss: 2.0076448244370484
Validation loss: 2.6314701565300833

Epoch: 6| Step: 10
Training loss: 2.8449199910637555
Validation loss: 2.6303301311612337

Epoch: 6| Step: 11
Training loss: 3.610542009617178
Validation loss: 2.6280449953044265

Epoch: 6| Step: 12
Training loss: 3.1088731830458634
Validation loss: 2.638255941572101

Epoch: 6| Step: 13
Training loss: 3.725994842607632
Validation loss: 2.6371061030066043

Epoch: 74| Step: 0
Training loss: 2.8324811065124513
Validation loss: 2.6362490977010333

Epoch: 6| Step: 1
Training loss: 3.361982602157827
Validation loss: 2.6371307000195117

Epoch: 6| Step: 2
Training loss: 2.726814498842228
Validation loss: 2.635185707909517

Epoch: 6| Step: 3
Training loss: 3.0906114167164698
Validation loss: 2.63886962182683

Epoch: 6| Step: 4
Training loss: 3.1239684882046124
Validation loss: 2.638022414782789

Epoch: 6| Step: 5
Training loss: 2.717698694175235
Validation loss: 2.6357470507189493

Epoch: 6| Step: 6
Training loss: 3.089777389951905
Validation loss: 2.6339576285172597

Epoch: 6| Step: 7
Training loss: 2.911595504522908
Validation loss: 2.631771930352527

Epoch: 6| Step: 8
Training loss: 2.6117985600524856
Validation loss: 2.6331876201069013

Epoch: 6| Step: 9
Training loss: 2.672465833511557
Validation loss: 2.634857575305275

Epoch: 6| Step: 10
Training loss: 3.4238440017636735
Validation loss: 2.629799187920317

Epoch: 6| Step: 11
Training loss: 3.3593010472873894
Validation loss: 2.629567927507828

Epoch: 6| Step: 12
Training loss: 3.1678921352769436
Validation loss: 2.6265377554495606

Epoch: 6| Step: 13
Training loss: 2.2947947105725763
Validation loss: 2.624234226019261

Epoch: 75| Step: 0
Training loss: 3.2842620104256297
Validation loss: 2.6283562061066976

Epoch: 6| Step: 1
Training loss: 3.0930551076050423
Validation loss: 2.6270384898803454

Epoch: 6| Step: 2
Training loss: 2.5435510955951566
Validation loss: 2.6447976872536296

Epoch: 6| Step: 3
Training loss: 3.5856888296301688
Validation loss: 2.6853981183599074

Epoch: 6| Step: 4
Training loss: 2.5346321775098954
Validation loss: 2.6470954435655774

Epoch: 6| Step: 5
Training loss: 3.214247433873458
Validation loss: 2.6411670454443246

Epoch: 6| Step: 6
Training loss: 3.310798927996984
Validation loss: 2.6222046853944208

Epoch: 6| Step: 7
Training loss: 2.3130581156500396
Validation loss: 2.621465241676144

Epoch: 6| Step: 8
Training loss: 2.7341913652065073
Validation loss: 2.6191892880371097

Epoch: 6| Step: 9
Training loss: 2.4798256348255987
Validation loss: 2.6204198089416355

Epoch: 6| Step: 10
Training loss: 2.6328018142981406
Validation loss: 2.6213737291678254

Epoch: 6| Step: 11
Training loss: 3.4087862144479737
Validation loss: 2.6187969912605302

Epoch: 6| Step: 12
Training loss: 2.7717461385093607
Validation loss: 2.616853337879119

Epoch: 6| Step: 13
Training loss: 3.577222552040705
Validation loss: 2.620435444597518

Epoch: 76| Step: 0
Training loss: 3.1013440264186487
Validation loss: 2.6179860434232105

Epoch: 6| Step: 1
Training loss: 3.216831561459164
Validation loss: 2.6159047391516332

Epoch: 6| Step: 2
Training loss: 2.553147344596511
Validation loss: 2.61564959989622

Epoch: 6| Step: 3
Training loss: 3.1689942154836057
Validation loss: 2.6205100555825243

Epoch: 6| Step: 4
Training loss: 3.083696154992959
Validation loss: 2.6209665671094307

Epoch: 6| Step: 5
Training loss: 3.3669655852863185
Validation loss: 2.6218711744562633

Epoch: 6| Step: 6
Training loss: 2.769777617909665
Validation loss: 2.6188372938396025

Epoch: 6| Step: 7
Training loss: 2.7731464931780527
Validation loss: 2.6442441517423627

Epoch: 6| Step: 8
Training loss: 3.175797766235496
Validation loss: 2.685863997573347

Epoch: 6| Step: 9
Training loss: 3.189352506976506
Validation loss: 2.6790269104239663

Epoch: 6| Step: 10
Training loss: 2.9707546493004657
Validation loss: 2.6670457486563173

Epoch: 6| Step: 11
Training loss: 2.4969071330078494
Validation loss: 2.6397223490757584

Epoch: 6| Step: 12
Training loss: 2.7296994589514707
Validation loss: 2.6238027646288824

Epoch: 6| Step: 13
Training loss: 2.78100662023805
Validation loss: 2.612302246828638

Epoch: 77| Step: 0
Training loss: 2.8709681892187278
Validation loss: 2.612124396515989

Epoch: 6| Step: 1
Training loss: 2.964392747112106
Validation loss: 2.6105745518153944

Epoch: 6| Step: 2
Training loss: 2.9403773074772475
Validation loss: 2.6122508214411706

Epoch: 6| Step: 3
Training loss: 3.1514451118057902
Validation loss: 2.6065012125370246

Epoch: 6| Step: 4
Training loss: 2.466525270516241
Validation loss: 2.6131646295082884

Epoch: 6| Step: 5
Training loss: 3.175352698733251
Validation loss: 2.6151093138286767

Epoch: 6| Step: 6
Training loss: 3.1868806125002673
Validation loss: 2.6135411767756374

Epoch: 6| Step: 7
Training loss: 3.7876180196069367
Validation loss: 2.6093792108761287

Epoch: 6| Step: 8
Training loss: 2.861132639173317
Validation loss: 2.60960143646037

Epoch: 6| Step: 9
Training loss: 2.7271302951842293
Validation loss: 2.6144956691628893

Epoch: 6| Step: 10
Training loss: 2.748057025817473
Validation loss: 2.6111999284394543

Epoch: 6| Step: 11
Training loss: 2.7897693582453353
Validation loss: 2.618039696495612

Epoch: 6| Step: 12
Training loss: 2.7168295204949127
Validation loss: 2.61707313617099

Epoch: 6| Step: 13
Training loss: 2.7530813293803837
Validation loss: 2.6306167530738467

Epoch: 78| Step: 0
Training loss: 2.8492539349520682
Validation loss: 2.630177011773459

Epoch: 6| Step: 1
Training loss: 2.7228542348937372
Validation loss: 2.6287818724094394

Epoch: 6| Step: 2
Training loss: 2.800162743198548
Validation loss: 2.648776434740077

Epoch: 6| Step: 3
Training loss: 2.784701060032099
Validation loss: 2.6497442799288935

Epoch: 6| Step: 4
Training loss: 2.939972993116833
Validation loss: 2.6430375971413307

Epoch: 6| Step: 5
Training loss: 3.1809859190565946
Validation loss: 2.6227873780868434

Epoch: 6| Step: 6
Training loss: 2.7464468282694776
Validation loss: 2.6139628523013196

Epoch: 6| Step: 7
Training loss: 2.54312513020033
Validation loss: 2.604942702961782

Epoch: 6| Step: 8
Training loss: 3.040197322364312
Validation loss: 2.60503110718287

Epoch: 6| Step: 9
Training loss: 3.0588397515414814
Validation loss: 2.607109632389329

Epoch: 6| Step: 10
Training loss: 3.368602198824578
Validation loss: 2.6092140001205277

Epoch: 6| Step: 11
Training loss: 3.10361933309849
Validation loss: 2.6140086263840088

Epoch: 6| Step: 12
Training loss: 2.65521112209656
Validation loss: 2.6100146471422794

Epoch: 6| Step: 13
Training loss: 3.690582021903915
Validation loss: 2.6131986167234866

Epoch: 79| Step: 0
Training loss: 2.9472884372563968
Validation loss: 2.6177932853636814

Epoch: 6| Step: 1
Training loss: 2.8297185465364403
Validation loss: 2.6146776281777777

Epoch: 6| Step: 2
Training loss: 2.8329436838333875
Validation loss: 2.6098533674769526

Epoch: 6| Step: 3
Training loss: 2.4290409515810985
Validation loss: 2.603385956589382

Epoch: 6| Step: 4
Training loss: 3.4108943249726122
Validation loss: 2.5985639179441753

Epoch: 6| Step: 5
Training loss: 3.1360041848368847
Validation loss: 2.600152909410431

Epoch: 6| Step: 6
Training loss: 2.614920474095904
Validation loss: 2.597640270474217

Epoch: 6| Step: 7
Training loss: 3.2168204440450316
Validation loss: 2.5994275910449534

Epoch: 6| Step: 8
Training loss: 3.1090337671487256
Validation loss: 2.6024408035123794

Epoch: 6| Step: 9
Training loss: 2.9954938424724773
Validation loss: 2.6136178904184573

Epoch: 6| Step: 10
Training loss: 2.0189020294483084
Validation loss: 2.626186400616155

Epoch: 6| Step: 11
Training loss: 3.0760069400227885
Validation loss: 2.6367718809206644

Epoch: 6| Step: 12
Training loss: 3.2183665815704
Validation loss: 2.623493469345226

Epoch: 6| Step: 13
Training loss: 3.4516264136334325
Validation loss: 2.6115165903397703

Epoch: 80| Step: 0
Training loss: 2.131075308791485
Validation loss: 2.6078273522900703

Epoch: 6| Step: 1
Training loss: 2.799284680138657
Validation loss: 2.5946963309009274

Epoch: 6| Step: 2
Training loss: 3.4108688815908454
Validation loss: 2.586596394693207

Epoch: 6| Step: 3
Training loss: 3.127969780271073
Validation loss: 2.591386993921426

Epoch: 6| Step: 4
Training loss: 2.626873256220796
Validation loss: 2.585629553818526

Epoch: 6| Step: 5
Training loss: 2.6747275846579455
Validation loss: 2.583829098492411

Epoch: 6| Step: 6
Training loss: 3.010399911871267
Validation loss: 2.5852414859913186

Epoch: 6| Step: 7
Training loss: 3.383205752167465
Validation loss: 2.5837731425304242

Epoch: 6| Step: 8
Training loss: 2.9439537091243952
Validation loss: 2.586062779341412

Epoch: 6| Step: 9
Training loss: 2.7150492418857266
Validation loss: 2.5827380671164266

Epoch: 6| Step: 10
Training loss: 3.3423145100633014
Validation loss: 2.5855495299521314

Epoch: 6| Step: 11
Training loss: 2.2566071034867448
Validation loss: 2.5855407574073634

Epoch: 6| Step: 12
Training loss: 3.2338849124848683
Validation loss: 2.584671123333729

Epoch: 6| Step: 13
Training loss: 3.3627506772446822
Validation loss: 2.585798803538999

Epoch: 81| Step: 0
Training loss: 3.204175823249846
Validation loss: 2.583541708556418

Epoch: 6| Step: 1
Training loss: 2.973295085501321
Validation loss: 2.5910968823920157

Epoch: 6| Step: 2
Training loss: 3.271348527963086
Validation loss: 2.589539464065289

Epoch: 6| Step: 3
Training loss: 3.02190618646855
Validation loss: 2.5856687295006235

Epoch: 6| Step: 4
Training loss: 3.455609424684983
Validation loss: 2.5839220647053573

Epoch: 6| Step: 5
Training loss: 2.975669106002542
Validation loss: 2.5893422775317902

Epoch: 6| Step: 6
Training loss: 2.4619496035403152
Validation loss: 2.580776708657196

Epoch: 6| Step: 7
Training loss: 2.9765107558351023
Validation loss: 2.5804462552004845

Epoch: 6| Step: 8
Training loss: 2.755221005694855
Validation loss: 2.581579676649765

Epoch: 6| Step: 9
Training loss: 2.5392382751656855
Validation loss: 2.587148159119053

Epoch: 6| Step: 10
Training loss: 2.9987932003164475
Validation loss: 2.5861195551395655

Epoch: 6| Step: 11
Training loss: 2.9697909487738268
Validation loss: 2.587561926155938

Epoch: 6| Step: 12
Training loss: 2.4049572134672994
Validation loss: 2.588026040501261

Epoch: 6| Step: 13
Training loss: 2.851363167262475
Validation loss: 2.596829788669165

Epoch: 82| Step: 0
Training loss: 3.398339421402618
Validation loss: 2.6064042645422334

Epoch: 6| Step: 1
Training loss: 3.027650091607264
Validation loss: 2.5947336920394584

Epoch: 6| Step: 2
Training loss: 2.9546046511181796
Validation loss: 2.583778214693243

Epoch: 6| Step: 3
Training loss: 3.3707360070083907
Validation loss: 2.5813099826441195

Epoch: 6| Step: 4
Training loss: 2.739273740344735
Validation loss: 2.5791034262592736

Epoch: 6| Step: 5
Training loss: 2.7855034353645545
Validation loss: 2.5784354531667297

Epoch: 6| Step: 6
Training loss: 3.311547196307796
Validation loss: 2.580594540844275

Epoch: 6| Step: 7
Training loss: 2.6444827459893645
Validation loss: 2.580148917119365

Epoch: 6| Step: 8
Training loss: 3.1305086030986575
Validation loss: 2.5826234354836317

Epoch: 6| Step: 9
Training loss: 2.1447958305309824
Validation loss: 2.578340192149947

Epoch: 6| Step: 10
Training loss: 2.618465282467163
Validation loss: 2.5780252377078794

Epoch: 6| Step: 11
Training loss: 2.913721141304059
Validation loss: 2.5812211871106414

Epoch: 6| Step: 12
Training loss: 2.8952464508411713
Validation loss: 2.5798828367066364

Epoch: 6| Step: 13
Training loss: 3.092629894590847
Validation loss: 2.5757514754701236

Epoch: 83| Step: 0
Training loss: 2.364075683234268
Validation loss: 2.5796332130690938

Epoch: 6| Step: 1
Training loss: 2.546930792261794
Validation loss: 2.5809647111040683

Epoch: 6| Step: 2
Training loss: 3.486527808532146
Validation loss: 2.5891869401522385

Epoch: 6| Step: 3
Training loss: 2.7283891827415716
Validation loss: 2.584411988515259

Epoch: 6| Step: 4
Training loss: 3.073865703004512
Validation loss: 2.595537498083314

Epoch: 6| Step: 5
Training loss: 3.065184525976159
Validation loss: 2.607788202769332

Epoch: 6| Step: 6
Training loss: 2.6239500216516105
Validation loss: 2.624324336603597

Epoch: 6| Step: 7
Training loss: 2.8792194418663866
Validation loss: 2.6488767087838796

Epoch: 6| Step: 8
Training loss: 2.9003758285607426
Validation loss: 2.6150229943597627

Epoch: 6| Step: 9
Training loss: 3.530753041635116
Validation loss: 2.5949272353480635

Epoch: 6| Step: 10
Training loss: 3.15472662392739
Validation loss: 2.5913346182498462

Epoch: 6| Step: 11
Training loss: 2.6918849214894
Validation loss: 2.578805713648702

Epoch: 6| Step: 12
Training loss: 3.0767393139837798
Validation loss: 2.577081027794944

Epoch: 6| Step: 13
Training loss: 2.429759229968866
Validation loss: 2.5775253568069036

Epoch: 84| Step: 0
Training loss: 2.7428314235452134
Validation loss: 2.577709547609571

Epoch: 6| Step: 1
Training loss: 3.309188915348566
Validation loss: 2.579627194606577

Epoch: 6| Step: 2
Training loss: 2.617122364657055
Validation loss: 2.582997810044636

Epoch: 6| Step: 3
Training loss: 2.597568596529835
Validation loss: 2.581689231698898

Epoch: 6| Step: 4
Training loss: 3.4706099738660123
Validation loss: 2.5754363607304724

Epoch: 6| Step: 5
Training loss: 3.0240914674983603
Validation loss: 2.580905131030451

Epoch: 6| Step: 6
Training loss: 3.6512422093899577
Validation loss: 2.5775500141437693

Epoch: 6| Step: 7
Training loss: 2.4509967878204675
Validation loss: 2.579562914642942

Epoch: 6| Step: 8
Training loss: 3.338476853874746
Validation loss: 2.584565178251097

Epoch: 6| Step: 9
Training loss: 2.4465658370124492
Validation loss: 2.6050724351025303

Epoch: 6| Step: 10
Training loss: 3.1597326723328845
Validation loss: 2.619752246119179

Epoch: 6| Step: 11
Training loss: 2.310931008557429
Validation loss: 2.636682409646027

Epoch: 6| Step: 12
Training loss: 2.7257083112251905
Validation loss: 2.6501352188615246

Epoch: 6| Step: 13
Training loss: 2.6163520960017377
Validation loss: 2.6893279261648497

Epoch: 85| Step: 0
Training loss: 3.212324821950413
Validation loss: 2.7020459932861787

Epoch: 6| Step: 1
Training loss: 2.711345279157348
Validation loss: 2.655233168526978

Epoch: 6| Step: 2
Training loss: 2.704003692872725
Validation loss: 2.6234026676668125

Epoch: 6| Step: 3
Training loss: 2.0672819016541943
Validation loss: 2.6185131767776797

Epoch: 6| Step: 4
Training loss: 3.4698072317265405
Validation loss: 2.602924834115901

Epoch: 6| Step: 5
Training loss: 2.8201464659619258
Validation loss: 2.5873193749235606

Epoch: 6| Step: 6
Training loss: 2.2610996696980417
Validation loss: 2.586770768358495

Epoch: 6| Step: 7
Training loss: 3.650002774799285
Validation loss: 2.578829291069321

Epoch: 6| Step: 8
Training loss: 3.302877593361358
Validation loss: 2.5765075631569703

Epoch: 6| Step: 9
Training loss: 3.107304636184032
Validation loss: 2.5699711037507553

Epoch: 6| Step: 10
Training loss: 3.1344270041992237
Validation loss: 2.5720582632516176

Epoch: 6| Step: 11
Training loss: 2.4102516093625104
Validation loss: 2.5662869479252373

Epoch: 6| Step: 12
Training loss: 2.9529076551756774
Validation loss: 2.569426823978449

Epoch: 6| Step: 13
Training loss: 2.490592900814806
Validation loss: 2.573972429535952

Epoch: 86| Step: 0
Training loss: 3.237628277332439
Validation loss: 2.5761834702952324

Epoch: 6| Step: 1
Training loss: 2.7310737954571844
Validation loss: 2.588160201845176

Epoch: 6| Step: 2
Training loss: 2.807183390400654
Validation loss: 2.6034426037362928

Epoch: 6| Step: 3
Training loss: 2.9658355863226227
Validation loss: 2.6815760265425306

Epoch: 6| Step: 4
Training loss: 2.4001019694600796
Validation loss: 2.8067524335561718

Epoch: 6| Step: 5
Training loss: 2.8882073266802797
Validation loss: 2.9930973131118694

Epoch: 6| Step: 6
Training loss: 3.250723978247225
Validation loss: 2.955067534085094

Epoch: 6| Step: 7
Training loss: 3.008633905190837
Validation loss: 2.7655656104978834

Epoch: 6| Step: 8
Training loss: 2.8653808223480657
Validation loss: 2.5994537280540335

Epoch: 6| Step: 9
Training loss: 3.0370010405718615
Validation loss: 2.5703041517127914

Epoch: 6| Step: 10
Training loss: 3.469468738222105
Validation loss: 2.5725314987204104

Epoch: 6| Step: 11
Training loss: 3.1404611725091582
Validation loss: 2.5768243327182487

Epoch: 6| Step: 12
Training loss: 3.0722695051727724
Validation loss: 2.59792873604329

Epoch: 6| Step: 13
Training loss: 2.3662603092120165
Validation loss: 2.6014318729326913

Epoch: 87| Step: 0
Training loss: 2.880202520455444
Validation loss: 2.5812696771244887

Epoch: 6| Step: 1
Training loss: 2.797892635769633
Validation loss: 2.5853240460235116

Epoch: 6| Step: 2
Training loss: 3.1479353965809658
Validation loss: 2.5850341932282523

Epoch: 6| Step: 3
Training loss: 3.4363366672747495
Validation loss: 2.5812984600353515

Epoch: 6| Step: 4
Training loss: 2.189143843844659
Validation loss: 2.579015112906755

Epoch: 6| Step: 5
Training loss: 2.760923883634452
Validation loss: 2.577942948114561

Epoch: 6| Step: 6
Training loss: 3.1294958199715235
Validation loss: 2.5910226948571182

Epoch: 6| Step: 7
Training loss: 3.281962290154935
Validation loss: 2.5750632582852213

Epoch: 6| Step: 8
Training loss: 2.090950303934302
Validation loss: 2.5776461726195836

Epoch: 6| Step: 9
Training loss: 2.7977571428221575
Validation loss: 2.5924534972852737

Epoch: 6| Step: 10
Training loss: 2.554380252572323
Validation loss: 2.601235327718315

Epoch: 6| Step: 11
Training loss: 3.268024931626953
Validation loss: 2.6315680827017456

Epoch: 6| Step: 12
Training loss: 3.05900623565567
Validation loss: 2.6595538367965967

Epoch: 6| Step: 13
Training loss: 3.4184006423560356
Validation loss: 2.720794804574184

Epoch: 88| Step: 0
Training loss: 3.24610697058454
Validation loss: 2.7106569764490596

Epoch: 6| Step: 1
Training loss: 2.7505863604944465
Validation loss: 2.6501678748734707

Epoch: 6| Step: 2
Training loss: 3.359065551699644
Validation loss: 2.5752813622180697

Epoch: 6| Step: 3
Training loss: 2.9992067559875117
Validation loss: 2.5603958923505803

Epoch: 6| Step: 4
Training loss: 2.7626890989458226
Validation loss: 2.567221802472134

Epoch: 6| Step: 5
Training loss: 2.712492483102254
Validation loss: 2.5662726806129386

Epoch: 6| Step: 6
Training loss: 2.9811275049151327
Validation loss: 2.574175394527092

Epoch: 6| Step: 7
Training loss: 3.1958468487058793
Validation loss: 2.574952437665143

Epoch: 6| Step: 8
Training loss: 3.272681392482944
Validation loss: 2.5786608365676105

Epoch: 6| Step: 9
Training loss: 2.934507915829986
Validation loss: 2.58472006537696

Epoch: 6| Step: 10
Training loss: 3.4078310875470987
Validation loss: 2.589358006790693

Epoch: 6| Step: 11
Training loss: 2.399096867388595
Validation loss: 2.5858034959768257

Epoch: 6| Step: 12
Training loss: 2.7314060332468024
Validation loss: 2.5831984512201647

Epoch: 6| Step: 13
Training loss: 2.07707049927976
Validation loss: 2.5845819046747573

Epoch: 89| Step: 0
Training loss: 2.886824795603761
Validation loss: 2.582173418195672

Epoch: 6| Step: 1
Training loss: 2.5120135619289443
Validation loss: 2.578487448572994

Epoch: 6| Step: 2
Training loss: 3.118567751526623
Validation loss: 2.5808381184419384

Epoch: 6| Step: 3
Training loss: 3.134647279210769
Validation loss: 2.570884502552699

Epoch: 6| Step: 4
Training loss: 3.312952982321622
Validation loss: 2.572614312180678

Epoch: 6| Step: 5
Training loss: 3.112659349154185
Validation loss: 2.56691460818877

Epoch: 6| Step: 6
Training loss: 3.133566140257948
Validation loss: 2.5650711586311306

Epoch: 6| Step: 7
Training loss: 2.4601097046806104
Validation loss: 2.5578100052873505

Epoch: 6| Step: 8
Training loss: 2.762522018137738
Validation loss: 2.5603872874451006

Epoch: 6| Step: 9
Training loss: 3.2132129635036835
Validation loss: 2.5597829062227793

Epoch: 6| Step: 10
Training loss: 3.1530682228806355
Validation loss: 2.565518811754914

Epoch: 6| Step: 11
Training loss: 2.754473255846804
Validation loss: 2.5648605894819387

Epoch: 6| Step: 12
Training loss: 2.5460360965012847
Validation loss: 2.5747134958363507

Epoch: 6| Step: 13
Training loss: 3.120690693330946
Validation loss: 2.5898591416350323

Epoch: 90| Step: 0
Training loss: 1.9479124779749695
Validation loss: 2.603068175601253

Epoch: 6| Step: 1
Training loss: 3.0345805639690555
Validation loss: 2.602723257076505

Epoch: 6| Step: 2
Training loss: 2.949380428101463
Validation loss: 2.603683050390361

Epoch: 6| Step: 3
Training loss: 2.5073085765852143
Validation loss: 2.5848557223538418

Epoch: 6| Step: 4
Training loss: 3.336418742503643
Validation loss: 2.576551307231988

Epoch: 6| Step: 5
Training loss: 2.997783795969604
Validation loss: 2.5721656474103267

Epoch: 6| Step: 6
Training loss: 2.6642754880722777
Validation loss: 2.5734204795465763

Epoch: 6| Step: 7
Training loss: 2.9687705591393385
Validation loss: 2.5676021559383098

Epoch: 6| Step: 8
Training loss: 2.6866533587041754
Validation loss: 2.5562837717771045

Epoch: 6| Step: 9
Training loss: 2.8589070255069795
Validation loss: 2.5671073717672956

Epoch: 6| Step: 10
Training loss: 3.2614061765461053
Validation loss: 2.5556572111734632

Epoch: 6| Step: 11
Training loss: 2.866011126180536
Validation loss: 2.558085792691837

Epoch: 6| Step: 12
Training loss: 2.766291134024688
Validation loss: 2.559712749692298

Epoch: 6| Step: 13
Training loss: 3.932039016118709
Validation loss: 2.566470321080504

Epoch: 91| Step: 0
Training loss: 2.82783801904184
Validation loss: 2.566982743269432

Epoch: 6| Step: 1
Training loss: 2.769364581991378
Validation loss: 2.5610887186269733

Epoch: 6| Step: 2
Training loss: 2.238184955116656
Validation loss: 2.5961183552442533

Epoch: 6| Step: 3
Training loss: 2.7516093313465695
Validation loss: 2.6166407555710083

Epoch: 6| Step: 4
Training loss: 2.8892340535404353
Validation loss: 2.627391480749023

Epoch: 6| Step: 5
Training loss: 2.712906180351597
Validation loss: 2.678743378178539

Epoch: 6| Step: 6
Training loss: 2.608506840631642
Validation loss: 2.704961110106677

Epoch: 6| Step: 7
Training loss: 2.939082591887066
Validation loss: 2.6595170840592166

Epoch: 6| Step: 8
Training loss: 3.3155772472685627
Validation loss: 2.622313521814649

Epoch: 6| Step: 9
Training loss: 2.99990399524933
Validation loss: 2.5780197922565544

Epoch: 6| Step: 10
Training loss: 3.010326731745302
Validation loss: 2.5567568567354

Epoch: 6| Step: 11
Training loss: 2.877826296603117
Validation loss: 2.5482055582656753

Epoch: 6| Step: 12
Training loss: 3.627873564295032
Validation loss: 2.555890632443237

Epoch: 6| Step: 13
Training loss: 3.0616849476436876
Validation loss: 2.562154024720421

Epoch: 92| Step: 0
Training loss: 2.739991702742439
Validation loss: 2.5722070812931803

Epoch: 6| Step: 1
Training loss: 3.218560074323045
Validation loss: 2.5985610056158137

Epoch: 6| Step: 2
Training loss: 2.7747829558576145
Validation loss: 2.6238654156042047

Epoch: 6| Step: 3
Training loss: 2.942338408227836
Validation loss: 2.6241877373917184

Epoch: 6| Step: 4
Training loss: 3.0922690806294013
Validation loss: 2.6175382440025032

Epoch: 6| Step: 5
Training loss: 2.8465620955557918
Validation loss: 2.6154037815644866

Epoch: 6| Step: 6
Training loss: 2.8334489312619233
Validation loss: 2.613435115043348

Epoch: 6| Step: 7
Training loss: 3.3030532872437255
Validation loss: 2.6057646038063744

Epoch: 6| Step: 8
Training loss: 3.3616521170482065
Validation loss: 2.5831550985874805

Epoch: 6| Step: 9
Training loss: 2.9427942494141117
Validation loss: 2.5702584331386586

Epoch: 6| Step: 10
Training loss: 2.610131433911887
Validation loss: 2.5614097350767104

Epoch: 6| Step: 11
Training loss: 2.791172543726697
Validation loss: 2.5618775024566753

Epoch: 6| Step: 12
Training loss: 3.0291404068834873
Validation loss: 2.5571502609025605

Epoch: 6| Step: 13
Training loss: 2.9559172493446337
Validation loss: 2.552410381189714

Epoch: 93| Step: 0
Training loss: 2.9069201609405306
Validation loss: 2.5548161049078777

Epoch: 6| Step: 1
Training loss: 2.6555451299373147
Validation loss: 2.564901451711266

Epoch: 6| Step: 2
Training loss: 3.4257932203860135
Validation loss: 2.567702425034485

Epoch: 6| Step: 3
Training loss: 2.6795344628767404
Validation loss: 2.5736692833300054

Epoch: 6| Step: 4
Training loss: 2.8739610536255267
Validation loss: 2.569678474646633

Epoch: 6| Step: 5
Training loss: 3.1902029507451966
Validation loss: 2.563149967794691

Epoch: 6| Step: 6
Training loss: 3.109325466048995
Validation loss: 2.574699293141199

Epoch: 6| Step: 7
Training loss: 2.7582951196364935
Validation loss: 2.56482432648186

Epoch: 6| Step: 8
Training loss: 2.5246169224584496
Validation loss: 2.5615754138981237

Epoch: 6| Step: 9
Training loss: 2.3266674830190253
Validation loss: 2.557438547549282

Epoch: 6| Step: 10
Training loss: 3.1496422216289233
Validation loss: 2.5606486898467424

Epoch: 6| Step: 11
Training loss: 2.762442271462269
Validation loss: 2.5601139099436567

Epoch: 6| Step: 12
Training loss: 3.2674812261484263
Validation loss: 2.5685598411761212

Epoch: 6| Step: 13
Training loss: 2.8344877546567084
Validation loss: 2.568126638819225

Epoch: 94| Step: 0
Training loss: 2.373966393673983
Validation loss: 2.5601193153740507

Epoch: 6| Step: 1
Training loss: 2.611193634199115
Validation loss: 2.5733005970743923

Epoch: 6| Step: 2
Training loss: 3.407125657944455
Validation loss: 2.5740204445796473

Epoch: 6| Step: 3
Training loss: 2.6799781574953365
Validation loss: 2.5635670476941885

Epoch: 6| Step: 4
Training loss: 2.753440525363693
Validation loss: 2.558549376260051

Epoch: 6| Step: 5
Training loss: 3.204704676693211
Validation loss: 2.5539906897952576

Epoch: 6| Step: 6
Training loss: 2.976697222847219
Validation loss: 2.5419661716795856

Epoch: 6| Step: 7
Training loss: 2.721919875535996
Validation loss: 2.542536109905611

Epoch: 6| Step: 8
Training loss: 3.2560193000240196
Validation loss: 2.54345236904007

Epoch: 6| Step: 9
Training loss: 2.896552694059
Validation loss: 2.5436945628377643

Epoch: 6| Step: 10
Training loss: 3.067167811979126
Validation loss: 2.5463136242645357

Epoch: 6| Step: 11
Training loss: 2.8277590182901444
Validation loss: 2.542352525015913

Epoch: 6| Step: 12
Training loss: 2.7323824352720116
Validation loss: 2.5449038120473326

Epoch: 6| Step: 13
Training loss: 3.0274458148117356
Validation loss: 2.547838667046429

Epoch: 95| Step: 0
Training loss: 2.111825042883351
Validation loss: 2.5464400284830218

Epoch: 6| Step: 1
Training loss: 2.56878885949807
Validation loss: 2.544994868935687

Epoch: 6| Step: 2
Training loss: 3.255928354613845
Validation loss: 2.5548452611031593

Epoch: 6| Step: 3
Training loss: 2.397411014946115
Validation loss: 2.561997953466693

Epoch: 6| Step: 4
Training loss: 3.306550350860897
Validation loss: 2.550946099595968

Epoch: 6| Step: 5
Training loss: 3.119002576244155
Validation loss: 2.547966155700983

Epoch: 6| Step: 6
Training loss: 2.9256005021251053
Validation loss: 2.544633001476562

Epoch: 6| Step: 7
Training loss: 3.085269285842341
Validation loss: 2.546328676957764

Epoch: 6| Step: 8
Training loss: 3.194712239710435
Validation loss: 2.5438670329172934

Epoch: 6| Step: 9
Training loss: 3.1609259989402423
Validation loss: 2.5433703085129835

Epoch: 6| Step: 10
Training loss: 2.9779787874305335
Validation loss: 2.5490554629606366

Epoch: 6| Step: 11
Training loss: 2.5436661052694074
Validation loss: 2.5609369901023067

Epoch: 6| Step: 12
Training loss: 3.005902365017057
Validation loss: 2.5848526785407286

Epoch: 6| Step: 13
Training loss: 2.189374610929158
Validation loss: 2.6082852176695916

Epoch: 96| Step: 0
Training loss: 3.0538752029491953
Validation loss: 2.658355110360343

Epoch: 6| Step: 1
Training loss: 3.1572528416784458
Validation loss: 2.693438724721769

Epoch: 6| Step: 2
Training loss: 3.063728553201977
Validation loss: 2.6672340524577915

Epoch: 6| Step: 3
Training loss: 3.403312606474418
Validation loss: 2.587558746820298

Epoch: 6| Step: 4
Training loss: 2.40293160046
Validation loss: 2.5498231068428763

Epoch: 6| Step: 5
Training loss: 2.8833465495017983
Validation loss: 2.5404848316162814

Epoch: 6| Step: 6
Training loss: 2.704365175677643
Validation loss: 2.5378393324484034

Epoch: 6| Step: 7
Training loss: 2.9915710292253452
Validation loss: 2.5458387759055356

Epoch: 6| Step: 8
Training loss: 3.197776534565017
Validation loss: 2.5465488613813037

Epoch: 6| Step: 9
Training loss: 2.885376490417685
Validation loss: 2.5415571025416757

Epoch: 6| Step: 10
Training loss: 2.7296110669829594
Validation loss: 2.546751562776507

Epoch: 6| Step: 11
Training loss: 2.8275307721285694
Validation loss: 2.5368580486905716

Epoch: 6| Step: 12
Training loss: 2.9592950538221383
Validation loss: 2.5410913360581593

Epoch: 6| Step: 13
Training loss: 2.5245004783020955
Validation loss: 2.5404376046084898

Epoch: 97| Step: 0
Training loss: 3.2009624345190537
Validation loss: 2.537744398747398

Epoch: 6| Step: 1
Training loss: 2.8470794972775804
Validation loss: 2.5441007302955256

Epoch: 6| Step: 2
Training loss: 2.876834284237172
Validation loss: 2.549623944660941

Epoch: 6| Step: 3
Training loss: 3.572996770704098
Validation loss: 2.557817783967032

Epoch: 6| Step: 4
Training loss: 2.4927025146246424
Validation loss: 2.566849968923343

Epoch: 6| Step: 5
Training loss: 2.915266263915934
Validation loss: 2.590396381953718

Epoch: 6| Step: 6
Training loss: 2.398996791180734
Validation loss: 2.599009309887265

Epoch: 6| Step: 7
Training loss: 3.0723407442739457
Validation loss: 2.6470151365609245

Epoch: 6| Step: 8
Training loss: 2.823606643719091
Validation loss: 2.697611481542909

Epoch: 6| Step: 9
Training loss: 2.8116926941932308
Validation loss: 2.6955445396456303

Epoch: 6| Step: 10
Training loss: 3.0162058848930515
Validation loss: 2.649358894692384

Epoch: 6| Step: 11
Training loss: 2.9332065453727227
Validation loss: 2.580666155242638

Epoch: 6| Step: 12
Training loss: 2.599929067671152
Validation loss: 2.558503111964074

Epoch: 6| Step: 13
Training loss: 2.240983912453194
Validation loss: 2.5456224012740902

Epoch: 98| Step: 0
Training loss: 2.6914198920758214
Validation loss: 2.5382992994404865

Epoch: 6| Step: 1
Training loss: 2.6074372366120517
Validation loss: 2.544331050938613

Epoch: 6| Step: 2
Training loss: 2.8768394225027945
Validation loss: 2.5470044150791287

Epoch: 6| Step: 3
Training loss: 3.4614604615120665
Validation loss: 2.5460824564361184

Epoch: 6| Step: 4
Training loss: 2.8372123942211087
Validation loss: 2.5565252864740686

Epoch: 6| Step: 5
Training loss: 2.5652840539946924
Validation loss: 2.549530513121974

Epoch: 6| Step: 6
Training loss: 2.843933434910555
Validation loss: 2.545981097230927

Epoch: 6| Step: 7
Training loss: 2.3499065664669025
Validation loss: 2.5474159949034827

Epoch: 6| Step: 8
Training loss: 3.1918971829215885
Validation loss: 2.5493355883574176

Epoch: 6| Step: 9
Training loss: 3.01085859352691
Validation loss: 2.5472103994975313

Epoch: 6| Step: 10
Training loss: 2.894089061407981
Validation loss: 2.5398737371389646

Epoch: 6| Step: 11
Training loss: 3.223328676296001
Validation loss: 2.5410544503530996

Epoch: 6| Step: 12
Training loss: 2.946019581073811
Validation loss: 2.5425726403732116

Epoch: 6| Step: 13
Training loss: 3.3115787304621516
Validation loss: 2.5462356178517496

Epoch: 99| Step: 0
Training loss: 2.984310129469211
Validation loss: 2.5534758069909196

Epoch: 6| Step: 1
Training loss: 3.0882785078172117
Validation loss: 2.5781458262487673

Epoch: 6| Step: 2
Training loss: 2.68546111368745
Validation loss: 2.5784817257094286

Epoch: 6| Step: 3
Training loss: 2.4366414440987434
Validation loss: 2.5999374993071536

Epoch: 6| Step: 4
Training loss: 3.0295611523885784
Validation loss: 2.61819257102313

Epoch: 6| Step: 5
Training loss: 3.142166897911544
Validation loss: 2.6504519065850065

Epoch: 6| Step: 6
Training loss: 2.6900993019692723
Validation loss: 2.617644509685793

Epoch: 6| Step: 7
Training loss: 3.253538259738245
Validation loss: 2.571806765699196

Epoch: 6| Step: 8
Training loss: 3.36101445846376
Validation loss: 2.583612219225333

Epoch: 6| Step: 9
Training loss: 2.7376549803179664
Validation loss: 2.555303657794734

Epoch: 6| Step: 10
Training loss: 2.477123112809621
Validation loss: 2.5413270464865887

Epoch: 6| Step: 11
Training loss: 2.5827569215936754
Validation loss: 2.53817563504745

Epoch: 6| Step: 12
Training loss: 3.0689498556595436
Validation loss: 2.546953028098839

Epoch: 6| Step: 13
Training loss: 2.7160926196748783
Validation loss: 2.540979742069672

Epoch: 100| Step: 0
Training loss: 3.170041461035653
Validation loss: 2.542960965215665

Epoch: 6| Step: 1
Training loss: 2.8970639657914368
Validation loss: 2.5385222758434955

Epoch: 6| Step: 2
Training loss: 2.662476366681441
Validation loss: 2.541530536561228

Epoch: 6| Step: 3
Training loss: 2.4284496036395304
Validation loss: 2.5482215947675235

Epoch: 6| Step: 4
Training loss: 3.194158443603228
Validation loss: 2.558637166103044

Epoch: 6| Step: 5
Training loss: 3.175015252745028
Validation loss: 2.5906507218875587

Epoch: 6| Step: 6
Training loss: 3.0261992229123598
Validation loss: 2.6032177902355245

Epoch: 6| Step: 7
Training loss: 3.081903143131299
Validation loss: 2.6393405707653637

Epoch: 6| Step: 8
Training loss: 2.731953709641647
Validation loss: 2.6072839969407178

Epoch: 6| Step: 9
Training loss: 3.0225901438962106
Validation loss: 2.5619898942900163

Epoch: 6| Step: 10
Training loss: 2.6292894829439435
Validation loss: 2.550646104539542

Epoch: 6| Step: 11
Training loss: 2.792964993987859
Validation loss: 2.5400921834959798

Epoch: 6| Step: 12
Training loss: 2.8953243512705202
Validation loss: 2.531563973207014

Epoch: 6| Step: 13
Training loss: 2.1874134591559016
Validation loss: 2.5319008794921656

Epoch: 101| Step: 0
Training loss: 2.8460466102970625
Validation loss: 2.5306587951801007

Epoch: 6| Step: 1
Training loss: 3.2081096290444586
Validation loss: 2.5295457205774214

Epoch: 6| Step: 2
Training loss: 2.7697927677017975
Validation loss: 2.5289319229504374

Epoch: 6| Step: 3
Training loss: 2.797537613275802
Validation loss: 2.529114235771423

Epoch: 6| Step: 4
Training loss: 2.771537452280909
Validation loss: 2.5325967377898535

Epoch: 6| Step: 5
Training loss: 2.878847615901379
Validation loss: 2.529216906455753

Epoch: 6| Step: 6
Training loss: 3.0100574389075136
Validation loss: 2.5270561276109738

Epoch: 6| Step: 7
Training loss: 2.987088073678463
Validation loss: 2.528532548780621

Epoch: 6| Step: 8
Training loss: 2.906442451257748
Validation loss: 2.528587256396964

Epoch: 6| Step: 9
Training loss: 3.1397542932679823
Validation loss: 2.5345946192504076

Epoch: 6| Step: 10
Training loss: 2.779457800703863
Validation loss: 2.539988897173542

Epoch: 6| Step: 11
Training loss: 2.6391066299642554
Validation loss: 2.5609136493806557

Epoch: 6| Step: 12
Training loss: 3.057220891407329
Validation loss: 2.546127194453021

Epoch: 6| Step: 13
Training loss: 2.2100817638479047
Validation loss: 2.539448655063013

Epoch: 102| Step: 0
Training loss: 2.583951896526801
Validation loss: 2.5305781189925396

Epoch: 6| Step: 1
Training loss: 2.8644401005857585
Validation loss: 2.525712507339053

Epoch: 6| Step: 2
Training loss: 2.5203121897158636
Validation loss: 2.5315701702377162

Epoch: 6| Step: 3
Training loss: 3.096480272621699
Validation loss: 2.5306281912709343

Epoch: 6| Step: 4
Training loss: 3.2713610634409434
Validation loss: 2.5258717381559026

Epoch: 6| Step: 5
Training loss: 2.6062402226472776
Validation loss: 2.5271229300467093

Epoch: 6| Step: 6
Training loss: 2.7336784129456912
Validation loss: 2.528548600553311

Epoch: 6| Step: 7
Training loss: 3.134466861736493
Validation loss: 2.5362660708970735

Epoch: 6| Step: 8
Training loss: 3.373475613539977
Validation loss: 2.535397822711399

Epoch: 6| Step: 9
Training loss: 2.753762532264982
Validation loss: 2.5453218271049387

Epoch: 6| Step: 10
Training loss: 2.674097753936348
Validation loss: 2.538219596344226

Epoch: 6| Step: 11
Training loss: 3.068460386326676
Validation loss: 2.5480923763254064

Epoch: 6| Step: 12
Training loss: 2.9764365822898955
Validation loss: 2.5480946309988144

Epoch: 6| Step: 13
Training loss: 1.7519561189181498
Validation loss: 2.554138613335041

Epoch: 103| Step: 0
Training loss: 2.9082277193175963
Validation loss: 2.548368599715368

Epoch: 6| Step: 1
Training loss: 2.7513394128325412
Validation loss: 2.5515468278756783

Epoch: 6| Step: 2
Training loss: 2.4626762907951645
Validation loss: 2.557646415005403

Epoch: 6| Step: 3
Training loss: 2.5028039466806065
Validation loss: 2.5796939912007293

Epoch: 6| Step: 4
Training loss: 3.2949160862426923
Validation loss: 2.5758420022163246

Epoch: 6| Step: 5
Training loss: 2.9960023948140373
Validation loss: 2.5638347344025076

Epoch: 6| Step: 6
Training loss: 2.5094823298891504
Validation loss: 2.5496968753718248

Epoch: 6| Step: 7
Training loss: 3.1441263447580723
Validation loss: 2.544802073453974

Epoch: 6| Step: 8
Training loss: 2.8954417743839462
Validation loss: 2.538094121061729

Epoch: 6| Step: 9
Training loss: 3.09323192844031
Validation loss: 2.535236685449349

Epoch: 6| Step: 10
Training loss: 3.000967982211945
Validation loss: 2.531935620880699

Epoch: 6| Step: 11
Training loss: 2.7560760823781134
Validation loss: 2.532410233569933

Epoch: 6| Step: 12
Training loss: 2.5397292919529453
Validation loss: 2.534843296701747

Epoch: 6| Step: 13
Training loss: 3.242864845943725
Validation loss: 2.529930134232184

Epoch: 104| Step: 0
Training loss: 2.943615492807209
Validation loss: 2.529107161487168

Epoch: 6| Step: 1
Training loss: 2.417008858054883
Validation loss: 2.535727795682736

Epoch: 6| Step: 2
Training loss: 3.0516310911190065
Validation loss: 2.537698829531704

Epoch: 6| Step: 3
Training loss: 2.9945221799040826
Validation loss: 2.5500049525065447

Epoch: 6| Step: 4
Training loss: 3.1732484446586153
Validation loss: 2.550382311860599

Epoch: 6| Step: 5
Training loss: 2.5707188432900123
Validation loss: 2.579660160821212

Epoch: 6| Step: 6
Training loss: 2.596025502871661
Validation loss: 2.5936698520660446

Epoch: 6| Step: 7
Training loss: 2.5725382991271624
Validation loss: 2.602704388655558

Epoch: 6| Step: 8
Training loss: 3.066198801203369
Validation loss: 2.6180646665235843

Epoch: 6| Step: 9
Training loss: 3.0137008299706722
Validation loss: 2.580947709934913

Epoch: 6| Step: 10
Training loss: 3.323327847255922
Validation loss: 2.5490378582426856

Epoch: 6| Step: 11
Training loss: 2.7272623033035357
Validation loss: 2.53994430538906

Epoch: 6| Step: 12
Training loss: 2.813735859927317
Validation loss: 2.533020618648084

Epoch: 6| Step: 13
Training loss: 2.5788104446583042
Validation loss: 2.524984552154835

Epoch: 105| Step: 0
Training loss: 2.5258793310065126
Validation loss: 2.5343434866204624

Epoch: 6| Step: 1
Training loss: 2.590685401276788
Validation loss: 2.528966639740328

Epoch: 6| Step: 2
Training loss: 2.866876320232572
Validation loss: 2.547842660659462

Epoch: 6| Step: 3
Training loss: 3.5069973344664915
Validation loss: 2.5585351659998166

Epoch: 6| Step: 4
Training loss: 3.1199146855745385
Validation loss: 2.5787228057453233

Epoch: 6| Step: 5
Training loss: 3.2732431722785527
Validation loss: 2.586108443545919

Epoch: 6| Step: 6
Training loss: 2.6830712133135175
Validation loss: 2.637667699009161

Epoch: 6| Step: 7
Training loss: 2.9853563542650456
Validation loss: 2.6123817946614345

Epoch: 6| Step: 8
Training loss: 2.96408533742067
Validation loss: 2.5926128434352127

Epoch: 6| Step: 9
Training loss: 3.045051381095758
Validation loss: 2.559169800316412

Epoch: 6| Step: 10
Training loss: 2.480953523617994
Validation loss: 2.5405284794893563

Epoch: 6| Step: 11
Training loss: 2.5693262869212528
Validation loss: 2.5251904972440817

Epoch: 6| Step: 12
Training loss: 2.5941748213729188
Validation loss: 2.5216076796444145

Epoch: 6| Step: 13
Training loss: 2.6483703424721834
Validation loss: 2.516349917836207

Epoch: 106| Step: 0
Training loss: 2.8801341446788924
Validation loss: 2.5204012564987153

Epoch: 6| Step: 1
Training loss: 2.6755190978447767
Validation loss: 2.525916439327267

Epoch: 6| Step: 2
Training loss: 3.531662773381011
Validation loss: 2.531559462261406

Epoch: 6| Step: 3
Training loss: 2.794343196693889
Validation loss: 2.544662852628552

Epoch: 6| Step: 4
Training loss: 2.877340939365312
Validation loss: 2.569546950037109

Epoch: 6| Step: 5
Training loss: 3.3840405919772025
Validation loss: 2.586361548830733

Epoch: 6| Step: 6
Training loss: 2.631424353977668
Validation loss: 2.5887799563812988

Epoch: 6| Step: 7
Training loss: 2.8167629571591095
Validation loss: 2.578482758729

Epoch: 6| Step: 8
Training loss: 2.1206384665468887
Validation loss: 2.5429178278843936

Epoch: 6| Step: 9
Training loss: 2.192041097743
Validation loss: 2.5291210140504403

Epoch: 6| Step: 10
Training loss: 2.821450297184053
Validation loss: 2.526416064672175

Epoch: 6| Step: 11
Training loss: 2.9034648388388544
Validation loss: 2.5292269350974625

Epoch: 6| Step: 12
Training loss: 3.079711505209906
Validation loss: 2.5306962781330964

Epoch: 6| Step: 13
Training loss: 3.037639372967943
Validation loss: 2.5221249159727646

Epoch: 107| Step: 0
Training loss: 2.0938250400134333
Validation loss: 2.5213762883550452

Epoch: 6| Step: 1
Training loss: 2.9718181616705883
Validation loss: 2.5166759279185684

Epoch: 6| Step: 2
Training loss: 3.1098627829255565
Validation loss: 2.5184240283079493

Epoch: 6| Step: 3
Training loss: 2.820659584392954
Validation loss: 2.5221178718908868

Epoch: 6| Step: 4
Training loss: 3.119769487424205
Validation loss: 2.5381293316915943

Epoch: 6| Step: 5
Training loss: 3.0229698430613072
Validation loss: 2.5591641344291842

Epoch: 6| Step: 6
Training loss: 2.8836083282871128
Validation loss: 2.5968712732696457

Epoch: 6| Step: 7
Training loss: 3.243639076409059
Validation loss: 2.6754978145684474

Epoch: 6| Step: 8
Training loss: 2.2947301906317072
Validation loss: 2.686319960665455

Epoch: 6| Step: 9
Training loss: 3.1059508519260377
Validation loss: 2.645163217616886

Epoch: 6| Step: 10
Training loss: 3.062668776240582
Validation loss: 2.5783905180940607

Epoch: 6| Step: 11
Training loss: 2.2674012686065117
Validation loss: 2.5227042299565228

Epoch: 6| Step: 12
Training loss: 3.0008804300926237
Validation loss: 2.5131593693560665

Epoch: 6| Step: 13
Training loss: 3.034955463616838
Validation loss: 2.5113562751039487

Epoch: 108| Step: 0
Training loss: 2.6627216264779774
Validation loss: 2.518805382130725

Epoch: 6| Step: 1
Training loss: 3.292053167773607
Validation loss: 2.5254271765962635

Epoch: 6| Step: 2
Training loss: 3.05149326978401
Validation loss: 2.528766447261576

Epoch: 6| Step: 3
Training loss: 2.4089577042606516
Validation loss: 2.5374153250377267

Epoch: 6| Step: 4
Training loss: 2.7477557821850715
Validation loss: 2.532621763208046

Epoch: 6| Step: 5
Training loss: 2.874331852770921
Validation loss: 2.5308835863156496

Epoch: 6| Step: 6
Training loss: 2.7003461192064218
Validation loss: 2.5296862223179213

Epoch: 6| Step: 7
Training loss: 2.7451063309939627
Validation loss: 2.5163939395130495

Epoch: 6| Step: 8
Training loss: 3.1204547633795063
Validation loss: 2.513621704621786

Epoch: 6| Step: 9
Training loss: 2.612942934589071
Validation loss: 2.524644829101207

Epoch: 6| Step: 10
Training loss: 3.2134192313061067
Validation loss: 2.536848054258348

Epoch: 6| Step: 11
Training loss: 3.001032333774392
Validation loss: 2.5513507112066813

Epoch: 6| Step: 12
Training loss: 2.6736484464430315
Validation loss: 2.5992902525332218

Epoch: 6| Step: 13
Training loss: 3.0596717698327263
Validation loss: 2.5749727768399313

Epoch: 109| Step: 0
Training loss: 2.869114698444806
Validation loss: 2.6015992087345348

Epoch: 6| Step: 1
Training loss: 3.084924613736375
Validation loss: 2.613206158913597

Epoch: 6| Step: 2
Training loss: 3.0842033052437015
Validation loss: 2.606774314104478

Epoch: 6| Step: 3
Training loss: 3.2410368934421774
Validation loss: 2.6338808201112758

Epoch: 6| Step: 4
Training loss: 2.5308489069639006
Validation loss: 2.5748407799119697

Epoch: 6| Step: 5
Training loss: 2.885257831337764
Validation loss: 2.5253099865912323

Epoch: 6| Step: 6
Training loss: 2.4177468834372644
Validation loss: 2.5103090454065864

Epoch: 6| Step: 7
Training loss: 2.5401181887365487
Validation loss: 2.5031409119169954

Epoch: 6| Step: 8
Training loss: 2.8920828777166867
Validation loss: 2.5000964812663184

Epoch: 6| Step: 9
Training loss: 3.312329557820202
Validation loss: 2.5157551340389444

Epoch: 6| Step: 10
Training loss: 2.86378897085527
Validation loss: 2.5219330934125224

Epoch: 6| Step: 11
Training loss: 2.6735248491207195
Validation loss: 2.5229541932022266

Epoch: 6| Step: 12
Training loss: 2.8112103366386036
Validation loss: 2.508309979286284

Epoch: 6| Step: 13
Training loss: 2.8174485646844265
Validation loss: 2.504876289998045

Epoch: 110| Step: 0
Training loss: 3.2933087337465774
Validation loss: 2.5036397935555317

Epoch: 6| Step: 1
Training loss: 2.4837962502107604
Validation loss: 2.5073950522974697

Epoch: 6| Step: 2
Training loss: 3.292077211941537
Validation loss: 2.5100249935194006

Epoch: 6| Step: 3
Training loss: 2.975867483141963
Validation loss: 2.5459623147799437

Epoch: 6| Step: 4
Training loss: 2.5102620268450884
Validation loss: 2.574708954447466

Epoch: 6| Step: 5
Training loss: 2.4312545776324095
Validation loss: 2.59891356304838

Epoch: 6| Step: 6
Training loss: 2.57197011815773
Validation loss: 2.607122633903167

Epoch: 6| Step: 7
Training loss: 2.5338128384823064
Validation loss: 2.5835858048655975

Epoch: 6| Step: 8
Training loss: 2.8056334703996977
Validation loss: 2.5738093844434156

Epoch: 6| Step: 9
Training loss: 3.403931414826577
Validation loss: 2.5537503448327565

Epoch: 6| Step: 10
Training loss: 3.5255177651935483
Validation loss: 2.5272059857864075

Epoch: 6| Step: 11
Training loss: 2.658478643418029
Validation loss: 2.5154643347909635

Epoch: 6| Step: 12
Training loss: 2.7150877040234906
Validation loss: 2.504724916716738

Epoch: 6| Step: 13
Training loss: 2.3230795240120456
Validation loss: 2.5016622098587473

Epoch: 111| Step: 0
Training loss: 2.8644783879332243
Validation loss: 2.507877500689208

Epoch: 6| Step: 1
Training loss: 2.872420107109772
Validation loss: 2.5028006873322965

Epoch: 6| Step: 2
Training loss: 2.7261570844947327
Validation loss: 2.5032823907934456

Epoch: 6| Step: 3
Training loss: 2.531779857798077
Validation loss: 2.5016581937626987

Epoch: 6| Step: 4
Training loss: 3.4842143342477567
Validation loss: 2.4999633765870826

Epoch: 6| Step: 5
Training loss: 3.0084608295788646
Validation loss: 2.5038715563828737

Epoch: 6| Step: 6
Training loss: 2.9352755951041236
Validation loss: 2.4996532958615654

Epoch: 6| Step: 7
Training loss: 2.966174805689185
Validation loss: 2.509555656913835

Epoch: 6| Step: 8
Training loss: 2.575923187538193
Validation loss: 2.5246037742833383

Epoch: 6| Step: 9
Training loss: 2.9685463283342566
Validation loss: 2.5522812572992866

Epoch: 6| Step: 10
Training loss: 2.403173287927161
Validation loss: 2.5833031235462385

Epoch: 6| Step: 11
Training loss: 2.552667875233674
Validation loss: 2.576553490237293

Epoch: 6| Step: 12
Training loss: 3.121901540099274
Validation loss: 2.588112851285404

Epoch: 6| Step: 13
Training loss: 2.4134370555331475
Validation loss: 2.5936900108566983

Epoch: 112| Step: 0
Training loss: 3.392798786091694
Validation loss: 2.5704928463059833

Epoch: 6| Step: 1
Training loss: 2.9367546596904175
Validation loss: 2.541667338760693

Epoch: 6| Step: 2
Training loss: 2.9891067461726166
Validation loss: 2.519821981775821

Epoch: 6| Step: 3
Training loss: 2.7155976710025356
Validation loss: 2.523732496171631

Epoch: 6| Step: 4
Training loss: 2.3068277023125803
Validation loss: 2.5093153999688362

Epoch: 6| Step: 5
Training loss: 2.437336647233164
Validation loss: 2.505939181496642

Epoch: 6| Step: 6
Training loss: 2.975436260388757
Validation loss: 2.502471951750208

Epoch: 6| Step: 7
Training loss: 3.09112560819433
Validation loss: 2.508411843788192

Epoch: 6| Step: 8
Training loss: 2.646035874992175
Validation loss: 2.5056368887840943

Epoch: 6| Step: 9
Training loss: 2.768804500551487
Validation loss: 2.5048313382089553

Epoch: 6| Step: 10
Training loss: 3.258588007919824
Validation loss: 2.5128714802986605

Epoch: 6| Step: 11
Training loss: 2.7126809266394414
Validation loss: 2.508964044436189

Epoch: 6| Step: 12
Training loss: 2.6382605445959797
Validation loss: 2.5061924034138876

Epoch: 6| Step: 13
Training loss: 2.363492694569872
Validation loss: 2.5113375726062426

Epoch: 113| Step: 0
Training loss: 2.9961717339305003
Validation loss: 2.511998246457371

Epoch: 6| Step: 1
Training loss: 2.880538912260834
Validation loss: 2.5108897919372457

Epoch: 6| Step: 2
Training loss: 2.698596048915693
Validation loss: 2.5224710397523324

Epoch: 6| Step: 3
Training loss: 2.8246146487837125
Validation loss: 2.5369564487969867

Epoch: 6| Step: 4
Training loss: 2.1803772631388902
Validation loss: 2.525263173734532

Epoch: 6| Step: 5
Training loss: 3.3911742719159808
Validation loss: 2.5262436199406526

Epoch: 6| Step: 6
Training loss: 2.1927847105181413
Validation loss: 2.5221600293601774

Epoch: 6| Step: 7
Training loss: 2.648317137377193
Validation loss: 2.516924330504328

Epoch: 6| Step: 8
Training loss: 2.67957717179037
Validation loss: 2.5173416125247607

Epoch: 6| Step: 9
Training loss: 2.390907420511516
Validation loss: 2.514064184618205

Epoch: 6| Step: 10
Training loss: 3.2744225087499177
Validation loss: 2.5221459566196667

Epoch: 6| Step: 11
Training loss: 3.1088911283859297
Validation loss: 2.531856894042621

Epoch: 6| Step: 12
Training loss: 2.9558917612847653
Validation loss: 2.5408362577475048

Epoch: 6| Step: 13
Training loss: 3.294459176490728
Validation loss: 2.5543092350591987

Epoch: 114| Step: 0
Training loss: 3.2309555185149286
Validation loss: 2.564922847099586

Epoch: 6| Step: 1
Training loss: 3.2298874245503595
Validation loss: 2.5397979756529088

Epoch: 6| Step: 2
Training loss: 2.962533002581041
Validation loss: 2.530316300021054

Epoch: 6| Step: 3
Training loss: 2.734065708651651
Validation loss: 2.527465535385712

Epoch: 6| Step: 4
Training loss: 2.6427942879761885
Validation loss: 2.5277888725515374

Epoch: 6| Step: 5
Training loss: 3.331218589076377
Validation loss: 2.5186449696747326

Epoch: 6| Step: 6
Training loss: 2.7153221532171745
Validation loss: 2.527893599995028

Epoch: 6| Step: 7
Training loss: 2.1023457141925164
Validation loss: 2.527739805899231

Epoch: 6| Step: 8
Training loss: 2.799488828184031
Validation loss: 2.5360913209606846

Epoch: 6| Step: 9
Training loss: 2.843357436363795
Validation loss: 2.520047681581672

Epoch: 6| Step: 10
Training loss: 2.5704757499448787
Validation loss: 2.5314381401767876

Epoch: 6| Step: 11
Training loss: 2.508751809158015
Validation loss: 2.5170275279574823

Epoch: 6| Step: 12
Training loss: 2.667459866651747
Validation loss: 2.518474198705153

Epoch: 6| Step: 13
Training loss: 2.8560109178243582
Validation loss: 2.520097868484354

Epoch: 115| Step: 0
Training loss: 2.4524165788903027
Validation loss: 2.5162406284783385

Epoch: 6| Step: 1
Training loss: 3.1859665716396757
Validation loss: 2.522191282862315

Epoch: 6| Step: 2
Training loss: 2.5574139619526846
Validation loss: 2.5218179526159483

Epoch: 6| Step: 3
Training loss: 2.4395909266648235
Validation loss: 2.528121071736423

Epoch: 6| Step: 4
Training loss: 2.5046462752292538
Validation loss: 2.541215078486805

Epoch: 6| Step: 5
Training loss: 3.0182856548158896
Validation loss: 2.564311980847108

Epoch: 6| Step: 6
Training loss: 3.253306833951412
Validation loss: 2.5831651411239034

Epoch: 6| Step: 7
Training loss: 2.1446195212508385
Validation loss: 2.6033920914701136

Epoch: 6| Step: 8
Training loss: 2.8743116135149496
Validation loss: 2.6131921379569527

Epoch: 6| Step: 9
Training loss: 3.076191716205854
Validation loss: 2.6240693907271546

Epoch: 6| Step: 10
Training loss: 3.247783932390913
Validation loss: 2.5713411804801964

Epoch: 6| Step: 11
Training loss: 2.49715118217577
Validation loss: 2.5276039325490554

Epoch: 6| Step: 12
Training loss: 3.004861706996485
Validation loss: 2.5062826982264217

Epoch: 6| Step: 13
Training loss: 3.3160092461046404
Validation loss: 2.499427158601569

Epoch: 116| Step: 0
Training loss: 2.597726370646633
Validation loss: 2.498135298904649

Epoch: 6| Step: 1
Training loss: 3.337466601944025
Validation loss: 2.4968078527452326

Epoch: 6| Step: 2
Training loss: 2.5549702619102255
Validation loss: 2.500190989571951

Epoch: 6| Step: 3
Training loss: 2.8055772140556603
Validation loss: 2.494742194912394

Epoch: 6| Step: 4
Training loss: 2.7638092114727955
Validation loss: 2.493171891719683

Epoch: 6| Step: 5
Training loss: 3.36534319506297
Validation loss: 2.4911620415937055

Epoch: 6| Step: 6
Training loss: 2.9599221131671056
Validation loss: 2.4976027161987857

Epoch: 6| Step: 7
Training loss: 2.797535653112974
Validation loss: 2.5027974525631835

Epoch: 6| Step: 8
Training loss: 2.2619651963231977
Validation loss: 2.5063270296989173

Epoch: 6| Step: 9
Training loss: 2.818045341565522
Validation loss: 2.515590198958661

Epoch: 6| Step: 10
Training loss: 2.9473413415969856
Validation loss: 2.519727388203822

Epoch: 6| Step: 11
Training loss: 2.839257684862331
Validation loss: 2.518352831575978

Epoch: 6| Step: 12
Training loss: 2.939244016388979
Validation loss: 2.5360107215589234

Epoch: 6| Step: 13
Training loss: 1.9436285244679572
Validation loss: 2.5433104374220177

Epoch: 117| Step: 0
Training loss: 2.7237912498176153
Validation loss: 2.587154780891588

Epoch: 6| Step: 1
Training loss: 2.775419488766166
Validation loss: 2.617305272378419

Epoch: 6| Step: 2
Training loss: 3.23091729404733
Validation loss: 2.648386941801644

Epoch: 6| Step: 3
Training loss: 3.166724923919729
Validation loss: 2.6911856220659995

Epoch: 6| Step: 4
Training loss: 2.826484921193656
Validation loss: 2.6013900481407375

Epoch: 6| Step: 5
Training loss: 2.316876780177653
Validation loss: 2.5412704754758266

Epoch: 6| Step: 6
Training loss: 3.0840097321234303
Validation loss: 2.511862944339314

Epoch: 6| Step: 7
Training loss: 3.040832161192713
Validation loss: 2.504611835472086

Epoch: 6| Step: 8
Training loss: 2.481113139877405
Validation loss: 2.5038149203365028

Epoch: 6| Step: 9
Training loss: 3.089510546440154
Validation loss: 2.502124708991578

Epoch: 6| Step: 10
Training loss: 2.828391889761366
Validation loss: 2.508705246812088

Epoch: 6| Step: 11
Training loss: 2.3204828578691443
Validation loss: 2.505718308659595

Epoch: 6| Step: 12
Training loss: 2.9671880528196892
Validation loss: 2.50227945964553

Epoch: 6| Step: 13
Training loss: 3.185143141711361
Validation loss: 2.507994379315152

Epoch: 118| Step: 0
Training loss: 1.7783784306941475
Validation loss: 2.50686502382466

Epoch: 6| Step: 1
Training loss: 2.467625615440583
Validation loss: 2.5104683239407675

Epoch: 6| Step: 2
Training loss: 3.1176160933621735
Validation loss: 2.506353860394501

Epoch: 6| Step: 3
Training loss: 2.572721239665574
Validation loss: 2.5121150272485595

Epoch: 6| Step: 4
Training loss: 3.0551311043985456
Validation loss: 2.5184764401949287

Epoch: 6| Step: 5
Training loss: 3.078768280507813
Validation loss: 2.522248512521836

Epoch: 6| Step: 6
Training loss: 2.9486806214350447
Validation loss: 2.528715107350982

Epoch: 6| Step: 7
Training loss: 3.124699387396599
Validation loss: 2.533636881191859

Epoch: 6| Step: 8
Training loss: 2.703761031454141
Validation loss: 2.542874318816105

Epoch: 6| Step: 9
Training loss: 2.9953177788836665
Validation loss: 2.5548732871019593

Epoch: 6| Step: 10
Training loss: 2.8477337778262486
Validation loss: 2.5624534798798164

Epoch: 6| Step: 11
Training loss: 3.0495482626149837
Validation loss: 2.5281296860746916

Epoch: 6| Step: 12
Training loss: 2.3977988321587684
Validation loss: 2.5200599359291735

Epoch: 6| Step: 13
Training loss: 3.0701298550159333
Validation loss: 2.517808607866922

Epoch: 119| Step: 0
Training loss: 2.5695703240796166
Validation loss: 2.506418419204264

Epoch: 6| Step: 1
Training loss: 3.1149415455533602
Validation loss: 2.498960121830989

Epoch: 6| Step: 2
Training loss: 3.371619191334412
Validation loss: 2.50012272769391

Epoch: 6| Step: 3
Training loss: 2.5321671507986476
Validation loss: 2.5020366668618457

Epoch: 6| Step: 4
Training loss: 3.0965749770415605
Validation loss: 2.4934790493960506

Epoch: 6| Step: 5
Training loss: 2.5147771887549064
Validation loss: 2.5020183260692526

Epoch: 6| Step: 6
Training loss: 2.7919440250305536
Validation loss: 2.497021042630729

Epoch: 6| Step: 7
Training loss: 2.5538571376051706
Validation loss: 2.5046962988828274

Epoch: 6| Step: 8
Training loss: 3.0909111793021427
Validation loss: 2.5067637121254607

Epoch: 6| Step: 9
Training loss: 2.5305822928177335
Validation loss: 2.5188600068754363

Epoch: 6| Step: 10
Training loss: 3.124098685939243
Validation loss: 2.5392325627852554

Epoch: 6| Step: 11
Training loss: 2.276394418809665
Validation loss: 2.531083776438932

Epoch: 6| Step: 12
Training loss: 2.6133226696432623
Validation loss: 2.517489374834901

Epoch: 6| Step: 13
Training loss: 2.971872715192011
Validation loss: 2.5227965565723145

Epoch: 120| Step: 0
Training loss: 2.515902296622407
Validation loss: 2.508932928618128

Epoch: 6| Step: 1
Training loss: 3.0088537222239173
Validation loss: 2.4995133798002755

Epoch: 6| Step: 2
Training loss: 2.911842789399143
Validation loss: 2.4925919734735986

Epoch: 6| Step: 3
Training loss: 2.561630101370047
Validation loss: 2.5012358881832557

Epoch: 6| Step: 4
Training loss: 3.1203202875505287
Validation loss: 2.4989827763019616

Epoch: 6| Step: 5
Training loss: 1.846244805185994
Validation loss: 2.4993661056339906

Epoch: 6| Step: 6
Training loss: 2.9395157411312494
Validation loss: 2.509939927038918

Epoch: 6| Step: 7
Training loss: 3.417186294367071
Validation loss: 2.5134940375435937

Epoch: 6| Step: 8
Training loss: 2.8930980104418276
Validation loss: 2.496020488661101

Epoch: 6| Step: 9
Training loss: 2.961773998295613
Validation loss: 2.525245774206166

Epoch: 6| Step: 10
Training loss: 3.3773889916712307
Validation loss: 2.527294612828511

Epoch: 6| Step: 11
Training loss: 2.3462704140085506
Validation loss: 2.5378155045257995

Epoch: 6| Step: 12
Training loss: 2.56680996069608
Validation loss: 2.5476487473698706

Epoch: 6| Step: 13
Training loss: 2.441455858870979
Validation loss: 2.5641308088892534

Epoch: 121| Step: 0
Training loss: 2.734312133066365
Validation loss: 2.5561099295088363

Epoch: 6| Step: 1
Training loss: 2.0798190676416968
Validation loss: 2.554674620989612

Epoch: 6| Step: 2
Training loss: 2.2605386399322955
Validation loss: 2.5361931926671755

Epoch: 6| Step: 3
Training loss: 1.8652329689539857
Validation loss: 2.5196113448414326

Epoch: 6| Step: 4
Training loss: 2.640859559605927
Validation loss: 2.501464887306369

Epoch: 6| Step: 5
Training loss: 3.5366162062151267
Validation loss: 2.4968170104659086

Epoch: 6| Step: 6
Training loss: 2.8219440844624333
Validation loss: 2.5015224722624425

Epoch: 6| Step: 7
Training loss: 3.3780091610790497
Validation loss: 2.499937996044148

Epoch: 6| Step: 8
Training loss: 3.1454376241295963
Validation loss: 2.4975571346385954

Epoch: 6| Step: 9
Training loss: 2.644440732502759
Validation loss: 2.5099497783764497

Epoch: 6| Step: 10
Training loss: 2.9402561649646777
Validation loss: 2.5041562417713745

Epoch: 6| Step: 11
Training loss: 3.154068750216347
Validation loss: 2.5131576994734615

Epoch: 6| Step: 12
Training loss: 2.6303123126234413
Validation loss: 2.536466715529456

Epoch: 6| Step: 13
Training loss: 2.8353835896943482
Validation loss: 2.55533922320701

Epoch: 122| Step: 0
Training loss: 2.1504868599322364
Validation loss: 2.569330404286439

Epoch: 6| Step: 1
Training loss: 3.1295377210789854
Validation loss: 2.527713633247841

Epoch: 6| Step: 2
Training loss: 2.313262195244576
Validation loss: 2.5125124898832825

Epoch: 6| Step: 3
Training loss: 3.03896992598801
Validation loss: 2.5091205873592144

Epoch: 6| Step: 4
Training loss: 2.8693425449604
Validation loss: 2.498892711177596

Epoch: 6| Step: 5
Training loss: 3.284474124011524
Validation loss: 2.509188492576371

Epoch: 6| Step: 6
Training loss: 1.9986851065325606
Validation loss: 2.4984264169314407

Epoch: 6| Step: 7
Training loss: 3.0547667978438198
Validation loss: 2.5039489997384634

Epoch: 6| Step: 8
Training loss: 2.949734472189132
Validation loss: 2.4959150986640846

Epoch: 6| Step: 9
Training loss: 3.048763843863111
Validation loss: 2.503866304944726

Epoch: 6| Step: 10
Training loss: 2.7993788779577438
Validation loss: 2.501085433361418

Epoch: 6| Step: 11
Training loss: 2.8703585766877016
Validation loss: 2.5076189129661723

Epoch: 6| Step: 12
Training loss: 2.5990457360829056
Validation loss: 2.5250282618629343

Epoch: 6| Step: 13
Training loss: 2.9333279790251443
Validation loss: 2.53436425689795

Epoch: 123| Step: 0
Training loss: 2.5947705754347234
Validation loss: 2.5321385808903814

Epoch: 6| Step: 1
Training loss: 2.835761955439829
Validation loss: 2.5624125816146592

Epoch: 6| Step: 2
Training loss: 2.5709985437793383
Validation loss: 2.556568158105216

Epoch: 6| Step: 3
Training loss: 3.3175695241558123
Validation loss: 2.5556394126854696

Epoch: 6| Step: 4
Training loss: 2.8694108455332548
Validation loss: 2.5212080909235746

Epoch: 6| Step: 5
Training loss: 2.642945663707643
Validation loss: 2.5066155783501953

Epoch: 6| Step: 6
Training loss: 2.6839006850888976
Validation loss: 2.492267049961954

Epoch: 6| Step: 7
Training loss: 2.9938311731089002
Validation loss: 2.489687347264445

Epoch: 6| Step: 8
Training loss: 2.9898859240864515
Validation loss: 2.488620940862728

Epoch: 6| Step: 9
Training loss: 2.7321105299745923
Validation loss: 2.4887069843039398

Epoch: 6| Step: 10
Training loss: 2.7312989289464302
Validation loss: 2.486938297550337

Epoch: 6| Step: 11
Training loss: 3.2331027417363414
Validation loss: 2.4861472622868743

Epoch: 6| Step: 12
Training loss: 2.4934429008290575
Validation loss: 2.489328167862227

Epoch: 6| Step: 13
Training loss: 2.329561340886861
Validation loss: 2.4856797621308866

Epoch: 124| Step: 0
Training loss: 2.7775445320961283
Validation loss: 2.5111411609165097

Epoch: 6| Step: 1
Training loss: 2.8604567519174005
Validation loss: 2.5212301052022235

Epoch: 6| Step: 2
Training loss: 2.6130212218236353
Validation loss: 2.5403074169992252

Epoch: 6| Step: 3
Training loss: 3.152236047958779
Validation loss: 2.5789397124838174

Epoch: 6| Step: 4
Training loss: 2.413086036302355
Validation loss: 2.5866547891432714

Epoch: 6| Step: 5
Training loss: 2.3497103370544004
Validation loss: 2.586158672843083

Epoch: 6| Step: 6
Training loss: 3.2050630986374604
Validation loss: 2.5607052612452956

Epoch: 6| Step: 7
Training loss: 2.986808064667218
Validation loss: 2.540939777497694

Epoch: 6| Step: 8
Training loss: 2.599504819812331
Validation loss: 2.5168887458102267

Epoch: 6| Step: 9
Training loss: 3.0583436749220234
Validation loss: 2.5052143579775192

Epoch: 6| Step: 10
Training loss: 2.631587346214143
Validation loss: 2.4830412413415943

Epoch: 6| Step: 11
Training loss: 2.6186231632516663
Validation loss: 2.4848380951913405

Epoch: 6| Step: 12
Training loss: 2.9032547805734947
Validation loss: 2.483467308235548

Epoch: 6| Step: 13
Training loss: 2.9333361069348256
Validation loss: 2.4806620705876066

Epoch: 125| Step: 0
Training loss: 1.8723707201833852
Validation loss: 2.4935637171815483

Epoch: 6| Step: 1
Training loss: 3.061840375590423
Validation loss: 2.497867163572904

Epoch: 6| Step: 2
Training loss: 2.718420863781998
Validation loss: 2.5152583027279425

Epoch: 6| Step: 3
Training loss: 2.333198498054386
Validation loss: 2.518772002134005

Epoch: 6| Step: 4
Training loss: 2.7923583317324105
Validation loss: 2.5066866134552686

Epoch: 6| Step: 5
Training loss: 3.1706101474756228
Validation loss: 2.514773431640892

Epoch: 6| Step: 6
Training loss: 2.9114463046149006
Validation loss: 2.487571012872885

Epoch: 6| Step: 7
Training loss: 2.7192768156527363
Validation loss: 2.495198909542669

Epoch: 6| Step: 8
Training loss: 3.1013970703284346
Validation loss: 2.4891614446202075

Epoch: 6| Step: 9
Training loss: 2.76108087190085
Validation loss: 2.4930105198903516

Epoch: 6| Step: 10
Training loss: 2.7757495967435575
Validation loss: 2.4892534246858897

Epoch: 6| Step: 11
Training loss: 2.5765649873017105
Validation loss: 2.4996749502542013

Epoch: 6| Step: 12
Training loss: 2.9204679150810025
Validation loss: 2.5147148141245492

Epoch: 6| Step: 13
Training loss: 3.3627447216504973
Validation loss: 2.5350438228667995

Epoch: 126| Step: 0
Training loss: 2.7020762619675045
Validation loss: 2.537759834119055

Epoch: 6| Step: 1
Training loss: 2.8829195162957575
Validation loss: 2.5135046190024686

Epoch: 6| Step: 2
Training loss: 2.3937056893413313
Validation loss: 2.549327355907345

Epoch: 6| Step: 3
Training loss: 3.0467652912440104
Validation loss: 2.543965628498378

Epoch: 6| Step: 4
Training loss: 2.5137715590361998
Validation loss: 2.5577612449252416

Epoch: 6| Step: 5
Training loss: 3.3182797660955443
Validation loss: 2.5567558530401233

Epoch: 6| Step: 6
Training loss: 2.9968244912323443
Validation loss: 2.5840986357389926

Epoch: 6| Step: 7
Training loss: 3.0054675188252937
Validation loss: 2.613333517396446

Epoch: 6| Step: 8
Training loss: 2.7363884188798
Validation loss: 2.6114044363605906

Epoch: 6| Step: 9
Training loss: 2.4164241362143155
Validation loss: 2.586031898248

Epoch: 6| Step: 10
Training loss: 2.9955086466244683
Validation loss: 2.561857821845876

Epoch: 6| Step: 11
Training loss: 2.7495937047274204
Validation loss: 2.529744628215782

Epoch: 6| Step: 12
Training loss: 2.952960943277024
Validation loss: 2.511597568831429

Epoch: 6| Step: 13
Training loss: 1.7120222720096774
Validation loss: 2.5036810375199754

Epoch: 127| Step: 0
Training loss: 2.573268686118306
Validation loss: 2.4991889837902512

Epoch: 6| Step: 1
Training loss: 3.0139762838401336
Validation loss: 2.492509325641771

Epoch: 6| Step: 2
Training loss: 3.0008731207257555
Validation loss: 2.4855418556555424

Epoch: 6| Step: 3
Training loss: 3.270307624182641
Validation loss: 2.4881647822312263

Epoch: 6| Step: 4
Training loss: 3.089735103968512
Validation loss: 2.491445588272483

Epoch: 6| Step: 5
Training loss: 2.9397955508086273
Validation loss: 2.4961320395688458

Epoch: 6| Step: 6
Training loss: 2.9924201576079192
Validation loss: 2.5040420148076596

Epoch: 6| Step: 7
Training loss: 2.9685072950235294
Validation loss: 2.499598565737603

Epoch: 6| Step: 8
Training loss: 2.6354648349466236
Validation loss: 2.508009830654594

Epoch: 6| Step: 9
Training loss: 2.297852911342836
Validation loss: 2.5120866650509783

Epoch: 6| Step: 10
Training loss: 2.504676260063286
Validation loss: 2.532522705238406

Epoch: 6| Step: 11
Training loss: 2.3123698842326994
Validation loss: 2.533496163935272

Epoch: 6| Step: 12
Training loss: 2.1726406586549523
Validation loss: 2.5565878543668754

Epoch: 6| Step: 13
Training loss: 2.9436355795359357
Validation loss: 2.551324350700627

Epoch: 128| Step: 0
Training loss: 2.969311149166002
Validation loss: 2.560172153405869

Epoch: 6| Step: 1
Training loss: 2.5949737235853916
Validation loss: 2.5517270567584687

Epoch: 6| Step: 2
Training loss: 2.1956233011614326
Validation loss: 2.5244193879802816

Epoch: 6| Step: 3
Training loss: 3.124764395415352
Validation loss: 2.5106823531735523

Epoch: 6| Step: 4
Training loss: 3.0611011658045606
Validation loss: 2.5052069480929178

Epoch: 6| Step: 5
Training loss: 2.7549369019692245
Validation loss: 2.4886783852103678

Epoch: 6| Step: 6
Training loss: 2.995218599267416
Validation loss: 2.4756528457596705

Epoch: 6| Step: 7
Training loss: 2.7322264159004357
Validation loss: 2.473778010188435

Epoch: 6| Step: 8
Training loss: 3.0961319202242725
Validation loss: 2.4873126263788117

Epoch: 6| Step: 9
Training loss: 2.573501510148303
Validation loss: 2.4916598944208945

Epoch: 6| Step: 10
Training loss: 2.410521147322851
Validation loss: 2.4905911746287104

Epoch: 6| Step: 11
Training loss: 2.836600570297157
Validation loss: 2.5081884893083455

Epoch: 6| Step: 12
Training loss: 2.9246886063149855
Validation loss: 2.5307316220809057

Epoch: 6| Step: 13
Training loss: 2.3312739639482336
Validation loss: 2.544215133214644

Epoch: 129| Step: 0
Training loss: 3.5078774766914953
Validation loss: 2.548841890498995

Epoch: 6| Step: 1
Training loss: 2.9924195202145265
Validation loss: 2.514868561711366

Epoch: 6| Step: 2
Training loss: 2.593492610064087
Validation loss: 2.51517027287226

Epoch: 6| Step: 3
Training loss: 2.937166397955653
Validation loss: 2.5220792358191892

Epoch: 6| Step: 4
Training loss: 2.248009436964271
Validation loss: 2.508595665284569

Epoch: 6| Step: 5
Training loss: 2.445078098165359
Validation loss: 2.504161388178782

Epoch: 6| Step: 6
Training loss: 2.8189081727031855
Validation loss: 2.510953385687578

Epoch: 6| Step: 7
Training loss: 2.3506526771139225
Validation loss: 2.5068482502951803

Epoch: 6| Step: 8
Training loss: 3.1030211585918885
Validation loss: 2.5133901074926848

Epoch: 6| Step: 9
Training loss: 2.4642316780721147
Validation loss: 2.528396695724942

Epoch: 6| Step: 10
Training loss: 3.090836357087108
Validation loss: 2.517569307556396

Epoch: 6| Step: 11
Training loss: 2.7148910847660783
Validation loss: 2.4976468784118055

Epoch: 6| Step: 12
Training loss: 2.7924544707900876
Validation loss: 2.506278408240286

Epoch: 6| Step: 13
Training loss: 2.351484937434264
Validation loss: 2.5035176888424227

Epoch: 130| Step: 0
Training loss: 3.257233565962819
Validation loss: 2.5031815895516187

Epoch: 6| Step: 1
Training loss: 2.658778882930175
Validation loss: 2.501438598593774

Epoch: 6| Step: 2
Training loss: 2.6589414536772433
Validation loss: 2.5023469737173545

Epoch: 6| Step: 3
Training loss: 2.4370612703306125
Validation loss: 2.5058666520042663

Epoch: 6| Step: 4
Training loss: 2.618828011673184
Validation loss: 2.5271184715336714

Epoch: 6| Step: 5
Training loss: 3.3469922754878434
Validation loss: 2.51688658286471

Epoch: 6| Step: 6
Training loss: 2.6876955183012603
Validation loss: 2.5121190225453502

Epoch: 6| Step: 7
Training loss: 2.874899323400724
Validation loss: 2.5058059104175348

Epoch: 6| Step: 8
Training loss: 2.1248970006776258
Validation loss: 2.503273597755458

Epoch: 6| Step: 9
Training loss: 3.0967502110780605
Validation loss: 2.4976717875057406

Epoch: 6| Step: 10
Training loss: 2.8347688479100976
Validation loss: 2.4929588549644426

Epoch: 6| Step: 11
Training loss: 2.4938144455615783
Validation loss: 2.4864723864794978

Epoch: 6| Step: 12
Training loss: 2.887757234551257
Validation loss: 2.484135454253275

Epoch: 6| Step: 13
Training loss: 2.3066505477136277
Validation loss: 2.4943671788386945

Epoch: 131| Step: 0
Training loss: 2.7775665923478337
Validation loss: 2.504865935632035

Epoch: 6| Step: 1
Training loss: 2.8605967762017115
Validation loss: 2.517131901594719

Epoch: 6| Step: 2
Training loss: 2.920227728807831
Validation loss: 2.5330724441255854

Epoch: 6| Step: 3
Training loss: 3.012657800870601
Validation loss: 2.571849560026481

Epoch: 6| Step: 4
Training loss: 2.9241065005569
Validation loss: 2.5767820736898925

Epoch: 6| Step: 5
Training loss: 2.978505699266248
Validation loss: 2.5648965890981215

Epoch: 6| Step: 6
Training loss: 2.2305369458570947
Validation loss: 2.526844677384137

Epoch: 6| Step: 7
Training loss: 3.324973319957647
Validation loss: 2.5300583530343688

Epoch: 6| Step: 8
Training loss: 2.206670302861532
Validation loss: 2.520242979042436

Epoch: 6| Step: 9
Training loss: 2.9437582028025644
Validation loss: 2.508777247683336

Epoch: 6| Step: 10
Training loss: 3.0280088420118996
Validation loss: 2.497704297872168

Epoch: 6| Step: 11
Training loss: 1.9830159016104836
Validation loss: 2.4967924799380246

Epoch: 6| Step: 12
Training loss: 2.1760595612789184
Validation loss: 2.486011511228554

Epoch: 6| Step: 13
Training loss: 2.946762739775846
Validation loss: 2.482888704120681

Epoch: 132| Step: 0
Training loss: 3.037828994327906
Validation loss: 2.4979985736994017

Epoch: 6| Step: 1
Training loss: 3.1412595800518583
Validation loss: 2.487982224571883

Epoch: 6| Step: 2
Training loss: 2.8559254334596926
Validation loss: 2.4831076090451396

Epoch: 6| Step: 3
Training loss: 3.0186101340042706
Validation loss: 2.497223736896314

Epoch: 6| Step: 4
Training loss: 3.085977983812773
Validation loss: 2.504564648540791

Epoch: 6| Step: 5
Training loss: 2.6448157649064803
Validation loss: 2.518913952609936

Epoch: 6| Step: 6
Training loss: 2.772579264492373
Validation loss: 2.5206990997391694

Epoch: 6| Step: 7
Training loss: 2.392160757601788
Validation loss: 2.5252386002540423

Epoch: 6| Step: 8
Training loss: 2.6380550360965027
Validation loss: 2.548491016047169

Epoch: 6| Step: 9
Training loss: 2.25484115277941
Validation loss: 2.5604836028634015

Epoch: 6| Step: 10
Training loss: 2.952532189021734
Validation loss: 2.5418928885553016

Epoch: 6| Step: 11
Training loss: 2.4515550777403177
Validation loss: 2.510470902419539

Epoch: 6| Step: 12
Training loss: 2.527285261229127
Validation loss: 2.495857189173405

Epoch: 6| Step: 13
Training loss: 2.5813935801034233
Validation loss: 2.487232231498363

Epoch: 133| Step: 0
Training loss: 2.737603597553237
Validation loss: 2.4852434434547397

Epoch: 6| Step: 1
Training loss: 2.3699232351369304
Validation loss: 2.478452029540769

Epoch: 6| Step: 2
Training loss: 2.572115651177969
Validation loss: 2.492844718585416

Epoch: 6| Step: 3
Training loss: 2.6576478758011732
Validation loss: 2.48828301075767

Epoch: 6| Step: 4
Training loss: 2.2163595297524523
Validation loss: 2.4801643162154163

Epoch: 6| Step: 5
Training loss: 2.685539861496524
Validation loss: 2.508915447514394

Epoch: 6| Step: 6
Training loss: 2.5709433665497863
Validation loss: 2.5600166973680176

Epoch: 6| Step: 7
Training loss: 2.184905557228126
Validation loss: 2.578735507985228

Epoch: 6| Step: 8
Training loss: 3.23269122980842
Validation loss: 2.6308200439594365

Epoch: 6| Step: 9
Training loss: 2.9247653964910962
Validation loss: 2.608689051292507

Epoch: 6| Step: 10
Training loss: 2.9330662482941507
Validation loss: 2.5532788484850215

Epoch: 6| Step: 11
Training loss: 3.4634199001543484
Validation loss: 2.517031774160067

Epoch: 6| Step: 12
Training loss: 2.6977710070866365
Validation loss: 2.4935448061810646

Epoch: 6| Step: 13
Training loss: 3.5350368753584513
Validation loss: 2.4753237837656585

Epoch: 134| Step: 0
Training loss: 3.062253669641273
Validation loss: 2.488906560011739

Epoch: 6| Step: 1
Training loss: 2.7551649314956905
Validation loss: 2.4769131535240763

Epoch: 6| Step: 2
Training loss: 2.594758906107223
Validation loss: 2.4735273267924285

Epoch: 6| Step: 3
Training loss: 2.5307202196849548
Validation loss: 2.4775437250920085

Epoch: 6| Step: 4
Training loss: 2.701199325234481
Validation loss: 2.488486004680454

Epoch: 6| Step: 5
Training loss: 2.482999408809424
Validation loss: 2.504046235935488

Epoch: 6| Step: 6
Training loss: 3.0543559252988515
Validation loss: 2.5044512488750765

Epoch: 6| Step: 7
Training loss: 2.975362380580955
Validation loss: 2.524982436249089

Epoch: 6| Step: 8
Training loss: 2.1338832528910747
Validation loss: 2.540804260926189

Epoch: 6| Step: 9
Training loss: 2.6352774742872134
Validation loss: 2.5628664028392123

Epoch: 6| Step: 10
Training loss: 3.4155859439777303
Validation loss: 2.595163499104701

Epoch: 6| Step: 11
Training loss: 3.1576376404592126
Validation loss: 2.6055777546728116

Epoch: 6| Step: 12
Training loss: 2.5721682078945323
Validation loss: 2.591078682248504

Epoch: 6| Step: 13
Training loss: 2.5003738123848915
Validation loss: 2.5516951442582134

Epoch: 135| Step: 0
Training loss: 2.378479767452502
Validation loss: 2.522923768158856

Epoch: 6| Step: 1
Training loss: 2.7071255754162933
Validation loss: 2.5008751229668187

Epoch: 6| Step: 2
Training loss: 2.7386186204160667
Validation loss: 2.492054688882344

Epoch: 6| Step: 3
Training loss: 2.501414852324127
Validation loss: 2.4927259757053863

Epoch: 6| Step: 4
Training loss: 2.5391008110090465
Validation loss: 2.4983380905521235

Epoch: 6| Step: 5
Training loss: 3.0283390500972227
Validation loss: 2.4919250028065716

Epoch: 6| Step: 6
Training loss: 2.7711532427217405
Validation loss: 2.4949177160760647

Epoch: 6| Step: 7
Training loss: 3.0539212643929328
Validation loss: 2.4881188830064667

Epoch: 6| Step: 8
Training loss: 3.124719683472545
Validation loss: 2.4828301965265633

Epoch: 6| Step: 9
Training loss: 2.57557098576412
Validation loss: 2.494678911371377

Epoch: 6| Step: 10
Training loss: 2.9278216714803915
Validation loss: 2.5066810416659475

Epoch: 6| Step: 11
Training loss: 3.0503385762383
Validation loss: 2.5262904506542685

Epoch: 6| Step: 12
Training loss: 2.6057224865027857
Validation loss: 2.5554397236710726

Epoch: 6| Step: 13
Training loss: 2.921783935433359
Validation loss: 2.591424185130105

Epoch: 136| Step: 0
Training loss: 2.841756268502842
Validation loss: 2.5791127331074275

Epoch: 6| Step: 1
Training loss: 2.826464676732603
Validation loss: 2.5364091436360003

Epoch: 6| Step: 2
Training loss: 2.6314084981629327
Validation loss: 2.5165282258299313

Epoch: 6| Step: 3
Training loss: 3.166608676044792
Validation loss: 2.4994308992948593

Epoch: 6| Step: 4
Training loss: 3.110782323978213
Validation loss: 2.5041158236267655

Epoch: 6| Step: 5
Training loss: 1.9111810911042377
Validation loss: 2.4930039663266528

Epoch: 6| Step: 6
Training loss: 2.9910194766610307
Validation loss: 2.4964424020882423

Epoch: 6| Step: 7
Training loss: 2.375585985673764
Validation loss: 2.485256660606646

Epoch: 6| Step: 8
Training loss: 2.178497536542934
Validation loss: 2.4979959330850674

Epoch: 6| Step: 9
Training loss: 2.9741407740406363
Validation loss: 2.4919534828530803

Epoch: 6| Step: 10
Training loss: 2.7773035746698675
Validation loss: 2.5068824118492006

Epoch: 6| Step: 11
Training loss: 3.234371166871974
Validation loss: 2.496010595699225

Epoch: 6| Step: 12
Training loss: 2.2830610010767236
Validation loss: 2.512096093639455

Epoch: 6| Step: 13
Training loss: 3.2306317031150233
Validation loss: 2.513899802476956

Epoch: 137| Step: 0
Training loss: 3.1047193474712813
Validation loss: 2.5580805413078695

Epoch: 6| Step: 1
Training loss: 2.5954723844019916
Validation loss: 2.552582484325867

Epoch: 6| Step: 2
Training loss: 2.3267109307976277
Validation loss: 2.5659240972985624

Epoch: 6| Step: 3
Training loss: 2.312621036145726
Validation loss: 2.575668519020727

Epoch: 6| Step: 4
Training loss: 2.9393179928967705
Validation loss: 2.6322199457515247

Epoch: 6| Step: 5
Training loss: 3.2265593965159862
Validation loss: 2.6020506979973446

Epoch: 6| Step: 6
Training loss: 3.382583716146686
Validation loss: 2.581311595527159

Epoch: 6| Step: 7
Training loss: 2.6450814107325837
Validation loss: 2.5456252573460514

Epoch: 6| Step: 8
Training loss: 3.1548901640669933
Validation loss: 2.4755568440469564

Epoch: 6| Step: 9
Training loss: 2.3696116508328826
Validation loss: 2.4837417244297626

Epoch: 6| Step: 10
Training loss: 2.330829253081195
Validation loss: 2.4870880445010566

Epoch: 6| Step: 11
Training loss: 2.543734433738075
Validation loss: 2.4926743048818136

Epoch: 6| Step: 12
Training loss: 2.5928589542747393
Validation loss: 2.495707154828924

Epoch: 6| Step: 13
Training loss: 3.2470835291084406
Validation loss: 2.4823411141412137

Epoch: 138| Step: 0
Training loss: 2.2234629690570666
Validation loss: 2.4877693009058026

Epoch: 6| Step: 1
Training loss: 2.761221791058977
Validation loss: 2.521110462144883

Epoch: 6| Step: 2
Training loss: 3.2640644341915492
Validation loss: 2.5225841009124057

Epoch: 6| Step: 3
Training loss: 2.517620266842066
Validation loss: 2.527255935184332

Epoch: 6| Step: 4
Training loss: 2.7086302863452385
Validation loss: 2.50618419035556

Epoch: 6| Step: 5
Training loss: 2.662775439132186
Validation loss: 2.5173458429216997

Epoch: 6| Step: 6
Training loss: 2.9346432694238005
Validation loss: 2.5347606237041096

Epoch: 6| Step: 7
Training loss: 2.7503460753031694
Validation loss: 2.5425114356623792

Epoch: 6| Step: 8
Training loss: 2.612580665912706
Validation loss: 2.545016923245329

Epoch: 6| Step: 9
Training loss: 2.4625076371282666
Validation loss: 2.5605123731315316

Epoch: 6| Step: 10
Training loss: 2.7660895350784576
Validation loss: 2.560351682013329

Epoch: 6| Step: 11
Training loss: 2.8035022494499446
Validation loss: 2.5830150696650396

Epoch: 6| Step: 12
Training loss: 2.8936222517845946
Validation loss: 2.6088061214569427

Epoch: 6| Step: 13
Training loss: 3.062435538722898
Validation loss: 2.6320119883339106

Epoch: 139| Step: 0
Training loss: 2.721829303835255
Validation loss: 2.6070339298805787

Epoch: 6| Step: 1
Training loss: 2.8890683493340936
Validation loss: 2.566724315145595

Epoch: 6| Step: 2
Training loss: 3.5310112526454223
Validation loss: 2.555976315033781

Epoch: 6| Step: 3
Training loss: 1.8822628501061291
Validation loss: 2.5309752721971606

Epoch: 6| Step: 4
Training loss: 2.7922155685166743
Validation loss: 2.5001062391124105

Epoch: 6| Step: 5
Training loss: 2.566338803872592
Validation loss: 2.5128451935941363

Epoch: 6| Step: 6
Training loss: 2.604607526973665
Validation loss: 2.5127124489833093

Epoch: 6| Step: 7
Training loss: 3.096222939155486
Validation loss: 2.5088915778657834

Epoch: 6| Step: 8
Training loss: 2.799124468430156
Validation loss: 2.502591327281185

Epoch: 6| Step: 9
Training loss: 2.478643656039873
Validation loss: 2.512229158589116

Epoch: 6| Step: 10
Training loss: 2.799428956520415
Validation loss: 2.527829718443978

Epoch: 6| Step: 11
Training loss: 2.454258942178113
Validation loss: 2.52761520802185

Epoch: 6| Step: 12
Training loss: 2.329373018772111
Validation loss: 2.5202404258198667

Epoch: 6| Step: 13
Training loss: 3.120741880440992
Validation loss: 2.5116247259902185

Epoch: 140| Step: 0
Training loss: 2.934079715386942
Validation loss: 2.490496544449844

Epoch: 6| Step: 1
Training loss: 2.7560272922631706
Validation loss: 2.495482562558337

Epoch: 6| Step: 2
Training loss: 3.056469955798395
Validation loss: 2.5062284386691673

Epoch: 6| Step: 3
Training loss: 2.7112001846964016
Validation loss: 2.495044446167853

Epoch: 6| Step: 4
Training loss: 3.0242007374011495
Validation loss: 2.5054674249733138

Epoch: 6| Step: 5
Training loss: 2.98362554756475
Validation loss: 2.5410947621914928

Epoch: 6| Step: 6
Training loss: 1.662547680163898
Validation loss: 2.5097349746994846

Epoch: 6| Step: 7
Training loss: 2.7365634552902884
Validation loss: 2.4986735860355456

Epoch: 6| Step: 8
Training loss: 2.8502038514699404
Validation loss: 2.4923212585958985

Epoch: 6| Step: 9
Training loss: 3.0690963705027423
Validation loss: 2.4831569268165277

Epoch: 6| Step: 10
Training loss: 2.2403352643204135
Validation loss: 2.48771793109373

Epoch: 6| Step: 11
Training loss: 2.451488556485248
Validation loss: 2.4874984528076123

Epoch: 6| Step: 12
Training loss: 2.3581695508754814
Validation loss: 2.489199167265422

Epoch: 6| Step: 13
Training loss: 3.137820381737437
Validation loss: 2.483957185475438

Epoch: 141| Step: 0
Training loss: 2.729227507012594
Validation loss: 2.5031494913703924

Epoch: 6| Step: 1
Training loss: 2.4728710689909694
Validation loss: 2.497968783754271

Epoch: 6| Step: 2
Training loss: 2.271215972393558
Validation loss: 2.501107017954585

Epoch: 6| Step: 3
Training loss: 2.64494106436188
Validation loss: 2.505252200646026

Epoch: 6| Step: 4
Training loss: 2.190230926461972
Validation loss: 2.5135444481138616

Epoch: 6| Step: 5
Training loss: 2.5890535786117606
Validation loss: 2.52104944617877

Epoch: 6| Step: 6
Training loss: 3.066921701054324
Validation loss: 2.5217074332443876

Epoch: 6| Step: 7
Training loss: 1.5935270864137445
Validation loss: 2.5226301306625705

Epoch: 6| Step: 8
Training loss: 3.1287538488945814
Validation loss: 2.512471568436968

Epoch: 6| Step: 9
Training loss: 2.8685103438923796
Validation loss: 2.4941386566371477

Epoch: 6| Step: 10
Training loss: 3.1381464805088184
Validation loss: 2.5090117954105433

Epoch: 6| Step: 11
Training loss: 2.6079560036370895
Validation loss: 2.5166519169360604

Epoch: 6| Step: 12
Training loss: 3.1065041021727957
Validation loss: 2.511589112142871

Epoch: 6| Step: 13
Training loss: 3.061289956956303
Validation loss: 2.520674648051498

Epoch: 142| Step: 0
Training loss: 2.8790341145706018
Validation loss: 2.5524141537128093

Epoch: 6| Step: 1
Training loss: 2.7126828602272877
Validation loss: 2.5943422695168854

Epoch: 6| Step: 2
Training loss: 2.4900149259924205
Validation loss: 2.666836261804033

Epoch: 6| Step: 3
Training loss: 2.832575883783193
Validation loss: 2.691052500603188

Epoch: 6| Step: 4
Training loss: 2.631028020560938
Validation loss: 2.6797135506477665

Epoch: 6| Step: 5
Training loss: 3.2154988285442787
Validation loss: 2.653844924184349

Epoch: 6| Step: 6
Training loss: 2.8163195635064326
Validation loss: 2.554011243078652

Epoch: 6| Step: 7
Training loss: 2.384616656575207
Validation loss: 2.507082208500725

Epoch: 6| Step: 8
Training loss: 2.4721265469538674
Validation loss: 2.4929681965016504

Epoch: 6| Step: 9
Training loss: 2.6512770832410446
Validation loss: 2.5006781509415257

Epoch: 6| Step: 10
Training loss: 2.9739996823154837
Validation loss: 2.514027663603748

Epoch: 6| Step: 11
Training loss: 2.629831771836906
Validation loss: 2.5969540331764027

Epoch: 6| Step: 12
Training loss: 2.911702936824011
Validation loss: 2.561700068286804

Epoch: 6| Step: 13
Training loss: 3.320248879215846
Validation loss: 2.4952890648408763

Epoch: 143| Step: 0
Training loss: 3.104468687243942
Validation loss: 2.478925614819956

Epoch: 6| Step: 1
Training loss: 2.7770734996197057
Validation loss: 2.4818777260546754

Epoch: 6| Step: 2
Training loss: 2.6586153157873116
Validation loss: 2.510120161074688

Epoch: 6| Step: 3
Training loss: 2.346990760762282
Validation loss: 2.5364657321052277

Epoch: 6| Step: 4
Training loss: 3.0733351255509564
Validation loss: 2.5727225569991425

Epoch: 6| Step: 5
Training loss: 3.2532675529562836
Validation loss: 2.625934356410192

Epoch: 6| Step: 6
Training loss: 2.8956018442256877
Validation loss: 2.6067390983731227

Epoch: 6| Step: 7
Training loss: 2.606993907995975
Validation loss: 2.576189567457087

Epoch: 6| Step: 8
Training loss: 2.46730849275588
Validation loss: 2.5763513364993202

Epoch: 6| Step: 9
Training loss: 3.0262844668934457
Validation loss: 2.6183362095032567

Epoch: 6| Step: 10
Training loss: 3.305485333748431
Validation loss: 2.637497977235733

Epoch: 6| Step: 11
Training loss: 2.2022009460549734
Validation loss: 2.5803829643145675

Epoch: 6| Step: 12
Training loss: 2.2529065114827116
Validation loss: 2.5467951757243705

Epoch: 6| Step: 13
Training loss: 2.202937557822961
Validation loss: 2.537752344497908

Epoch: 144| Step: 0
Training loss: 2.649088101665504
Validation loss: 2.560702858493013

Epoch: 6| Step: 1
Training loss: 2.6631213900280444
Validation loss: 2.5504443650285955

Epoch: 6| Step: 2
Training loss: 2.536322326982534
Validation loss: 2.560821659879531

Epoch: 6| Step: 3
Training loss: 2.3182479973048733
Validation loss: 2.5547277221543894

Epoch: 6| Step: 4
Training loss: 3.0952151133484067
Validation loss: 2.550890033356267

Epoch: 6| Step: 5
Training loss: 2.7820935630943535
Validation loss: 2.55885157059166

Epoch: 6| Step: 6
Training loss: 2.9342475904077974
Validation loss: 2.5722938528760824

Epoch: 6| Step: 7
Training loss: 2.6644163372171747
Validation loss: 2.537948019000884

Epoch: 6| Step: 8
Training loss: 2.272349618399098
Validation loss: 2.530078398541114

Epoch: 6| Step: 9
Training loss: 3.2753160862866184
Validation loss: 2.536038171254022

Epoch: 6| Step: 10
Training loss: 3.0886766855577026
Validation loss: 2.49616002742293

Epoch: 6| Step: 11
Training loss: 2.4759168294640554
Validation loss: 2.5059273962107955

Epoch: 6| Step: 12
Training loss: 3.0124821072755394
Validation loss: 2.517715499613645

Epoch: 6| Step: 13
Training loss: 1.8735854853197336
Validation loss: 2.519561124845349

Epoch: 145| Step: 0
Training loss: 2.9539041450047048
Validation loss: 2.5300750507103635

Epoch: 6| Step: 1
Training loss: 2.830596349852939
Validation loss: 2.5180951139300576

Epoch: 6| Step: 2
Training loss: 2.692205169318649
Validation loss: 2.514543771147519

Epoch: 6| Step: 3
Training loss: 1.8889172620449957
Validation loss: 2.5362774645330437

Epoch: 6| Step: 4
Training loss: 2.8269337205272262
Validation loss: 2.5345571828228133

Epoch: 6| Step: 5
Training loss: 2.514908398273978
Validation loss: 2.519734779805781

Epoch: 6| Step: 6
Training loss: 3.104566834192221
Validation loss: 2.535513365000292

Epoch: 6| Step: 7
Training loss: 2.701268435039748
Validation loss: 2.528509272920882

Epoch: 6| Step: 8
Training loss: 2.815964662850348
Validation loss: 2.545794083170677

Epoch: 6| Step: 9
Training loss: 2.6543651400805803
Validation loss: 2.550833318650917

Epoch: 6| Step: 10
Training loss: 3.0219931294371327
Validation loss: 2.5355533008498847

Epoch: 6| Step: 11
Training loss: 2.949987935187028
Validation loss: 2.5246879912823226

Epoch: 6| Step: 12
Training loss: 2.344050273733696
Validation loss: 2.5134083571434607

Epoch: 6| Step: 13
Training loss: 3.0813522848055155
Validation loss: 2.5116820769925274

Epoch: 146| Step: 0
Training loss: 2.3180080491486583
Validation loss: 2.5129265064200133

Epoch: 6| Step: 1
Training loss: 2.5216193957120203
Validation loss: 2.514805057792237

Epoch: 6| Step: 2
Training loss: 2.8698827564070384
Validation loss: 2.532037124181229

Epoch: 6| Step: 3
Training loss: 2.813906678117072
Validation loss: 2.538255122373886

Epoch: 6| Step: 4
Training loss: 2.7147324793125787
Validation loss: 2.559274541839644

Epoch: 6| Step: 5
Training loss: 3.386971892121702
Validation loss: 2.5428451070247364

Epoch: 6| Step: 6
Training loss: 2.297327113905665
Validation loss: 2.5547568342018594

Epoch: 6| Step: 7
Training loss: 2.765727585436292
Validation loss: 2.5648246183470826

Epoch: 6| Step: 8
Training loss: 2.8688642292093935
Validation loss: 2.5423999362739114

Epoch: 6| Step: 9
Training loss: 2.723478305355567
Validation loss: 2.5744620983444424

Epoch: 6| Step: 10
Training loss: 2.3961184345835806
Validation loss: 2.573852475160793

Epoch: 6| Step: 11
Training loss: 2.6973310348015707
Validation loss: 2.5747346025853273

Epoch: 6| Step: 12
Training loss: 2.906124973684184
Validation loss: 2.53656373002206

Epoch: 6| Step: 13
Training loss: 2.9554495568576167
Validation loss: 2.5002300371962765

Epoch: 147| Step: 0
Training loss: 1.8893637745858485
Validation loss: 2.480392042231468

Epoch: 6| Step: 1
Training loss: 2.5483358675152203
Validation loss: 2.4693026092275536

Epoch: 6| Step: 2
Training loss: 2.8104447378722446
Validation loss: 2.4785770291740126

Epoch: 6| Step: 3
Training loss: 2.8351076030998867
Validation loss: 2.4940077894003174

Epoch: 6| Step: 4
Training loss: 2.844435389159942
Validation loss: 2.491265522593633

Epoch: 6| Step: 5
Training loss: 2.776121232620356
Validation loss: 2.5001799785269143

Epoch: 6| Step: 6
Training loss: 2.3582158557042074
Validation loss: 2.4959852345343823

Epoch: 6| Step: 7
Training loss: 2.62820248302496
Validation loss: 2.5033809032742926

Epoch: 6| Step: 8
Training loss: 2.739255810633181
Validation loss: 2.5225891335040873

Epoch: 6| Step: 9
Training loss: 3.1546909523085835
Validation loss: 2.5295414756184456

Epoch: 6| Step: 10
Training loss: 2.9756801629116327
Validation loss: 2.551291066078019

Epoch: 6| Step: 11
Training loss: 2.898097427036268
Validation loss: 2.5630531454350165

Epoch: 6| Step: 12
Training loss: 2.971057196088079
Validation loss: 2.5756102089321913

Epoch: 6| Step: 13
Training loss: 3.2648732173308264
Validation loss: 2.5722520526263155

Epoch: 148| Step: 0
Training loss: 3.0275497661755986
Validation loss: 2.5343260492882544

Epoch: 6| Step: 1
Training loss: 2.9997701556850114
Validation loss: 2.527165420955103

Epoch: 6| Step: 2
Training loss: 2.716117636856407
Validation loss: 2.512214084242512

Epoch: 6| Step: 3
Training loss: 2.932576700363628
Validation loss: 2.5045624253081287

Epoch: 6| Step: 4
Training loss: 3.026480786781702
Validation loss: 2.5057503637037355

Epoch: 6| Step: 5
Training loss: 2.720979499882669
Validation loss: 2.5073729625594137

Epoch: 6| Step: 6
Training loss: 2.7656078445850776
Validation loss: 2.496179077286062

Epoch: 6| Step: 7
Training loss: 1.730311126074608
Validation loss: 2.487859418361708

Epoch: 6| Step: 8
Training loss: 2.996206109875695
Validation loss: 2.485635126358697

Epoch: 6| Step: 9
Training loss: 2.506836698358864
Validation loss: 2.4861630876035035

Epoch: 6| Step: 10
Training loss: 2.6425472689093774
Validation loss: 2.4827667895433683

Epoch: 6| Step: 11
Training loss: 2.5172115085624234
Validation loss: 2.4762107553007193

Epoch: 6| Step: 12
Training loss: 2.842826106305294
Validation loss: 2.479892876319696

Epoch: 6| Step: 13
Training loss: 2.7554811127495915
Validation loss: 2.513854753522401

Epoch: 149| Step: 0
Training loss: 2.2219159815961675
Validation loss: 2.5982839554561084

Epoch: 6| Step: 1
Training loss: 2.9142140203360567
Validation loss: 2.7306322444371403

Epoch: 6| Step: 2
Training loss: 2.7143086955883056
Validation loss: 2.860916081932474

Epoch: 6| Step: 3
Training loss: 3.9968953004609316
Validation loss: 2.954914612242331

Epoch: 6| Step: 4
Training loss: 3.1832459429450886
Validation loss: 2.9083017592992344

Epoch: 6| Step: 5
Training loss: 2.828702751705687
Validation loss: 2.7957904046602198

Epoch: 6| Step: 6
Training loss: 3.0301983769002883
Validation loss: 2.6706424991917523

Epoch: 6| Step: 7
Training loss: 2.7800218249225845
Validation loss: 2.5564985431087384

Epoch: 6| Step: 8
Training loss: 2.3940357485900967
Validation loss: 2.5260816998233095

Epoch: 6| Step: 9
Training loss: 2.475482019052866
Validation loss: 2.5302325459477535

Epoch: 6| Step: 10
Training loss: 2.5284544024045723
Validation loss: 2.5137850851158268

Epoch: 6| Step: 11
Training loss: 2.6340318340906457
Validation loss: 2.5035473257203367

Epoch: 6| Step: 12
Training loss: 2.956278252819457
Validation loss: 2.486727925741149

Epoch: 6| Step: 13
Training loss: 2.693887084871524
Validation loss: 2.4884948180339377

Epoch: 150| Step: 0
Training loss: 2.719919238293997
Validation loss: 2.48386166470547

Epoch: 6| Step: 1
Training loss: 2.9274835460014756
Validation loss: 2.4804078205490874

Epoch: 6| Step: 2
Training loss: 2.402536871366166
Validation loss: 2.4751307650473158

Epoch: 6| Step: 3
Training loss: 2.3923324770260392
Validation loss: 2.4868554659484903

Epoch: 6| Step: 4
Training loss: 2.174979097989375
Validation loss: 2.5051327467292728

Epoch: 6| Step: 5
Training loss: 3.029890247031667
Validation loss: 2.5120480492082415

Epoch: 6| Step: 6
Training loss: 3.146804120838594
Validation loss: 2.519532330592182

Epoch: 6| Step: 7
Training loss: 2.548993966856828
Validation loss: 2.5592065391234367

Epoch: 6| Step: 8
Training loss: 2.5417890258686633
Validation loss: 2.593476042924424

Epoch: 6| Step: 9
Training loss: 2.3482643901197626
Validation loss: 2.6146237247218225

Epoch: 6| Step: 10
Training loss: 2.994787615344859
Validation loss: 2.612682338953026

Epoch: 6| Step: 11
Training loss: 2.726934631660899
Validation loss: 2.6329697249527273

Epoch: 6| Step: 12
Training loss: 2.971986953439738
Validation loss: 2.6369928626013364

Epoch: 6| Step: 13
Training loss: 3.15626646736306
Validation loss: 2.6654831867983817

Epoch: 151| Step: 0
Training loss: 2.5717568093416734
Validation loss: 2.6291468455853924

Epoch: 6| Step: 1
Training loss: 2.863402651597959
Validation loss: 2.597910096278075

Epoch: 6| Step: 2
Training loss: 2.9725628912122137
Validation loss: 2.5720443399305646

Epoch: 6| Step: 3
Training loss: 1.9465094258324918
Validation loss: 2.5385449387932137

Epoch: 6| Step: 4
Training loss: 2.5536614553642933
Validation loss: 2.534520307218985

Epoch: 6| Step: 5
Training loss: 3.164394634381055
Validation loss: 2.515663001465736

Epoch: 6| Step: 6
Training loss: 2.4702778205150455
Validation loss: 2.521044412547306

Epoch: 6| Step: 7
Training loss: 3.0125705884838854
Validation loss: 2.518220427176715

Epoch: 6| Step: 8
Training loss: 2.7948932126412913
Validation loss: 2.5046644637172384

Epoch: 6| Step: 9
Training loss: 2.510308090542302
Validation loss: 2.5155437601329695

Epoch: 6| Step: 10
Training loss: 2.8345543717360804
Validation loss: 2.5189383867855453

Epoch: 6| Step: 11
Training loss: 1.9422214569535967
Validation loss: 2.5165910455069174

Epoch: 6| Step: 12
Training loss: 2.85625400000361
Validation loss: 2.496182045902745

Epoch: 6| Step: 13
Training loss: 2.756530290741318
Validation loss: 2.543514386668994

Epoch: 152| Step: 0
Training loss: 2.052305980809681
Validation loss: 2.5418313845700284

Epoch: 6| Step: 1
Training loss: 2.6123824462726093
Validation loss: 2.5507773092298156

Epoch: 6| Step: 2
Training loss: 2.8843421082775547
Validation loss: 2.583033827833602

Epoch: 6| Step: 3
Training loss: 2.086599637784134
Validation loss: 2.5577016435440676

Epoch: 6| Step: 4
Training loss: 2.5568066128555738
Validation loss: 2.5477199445061305

Epoch: 6| Step: 5
Training loss: 2.466747195845259
Validation loss: 2.528780777156592

Epoch: 6| Step: 6
Training loss: 2.409330699627184
Validation loss: 2.5077416276403546

Epoch: 6| Step: 7
Training loss: 3.1733749676492273
Validation loss: 2.514950270888423

Epoch: 6| Step: 8
Training loss: 2.9088262808797
Validation loss: 2.5237419950224425

Epoch: 6| Step: 9
Training loss: 2.411144085066298
Validation loss: 2.5074068828288354

Epoch: 6| Step: 10
Training loss: 2.996520886070093
Validation loss: 2.5104849201071056

Epoch: 6| Step: 11
Training loss: 2.703073137259881
Validation loss: 2.5076508649958615

Epoch: 6| Step: 12
Training loss: 2.6439720475397213
Validation loss: 2.520124152272904

Epoch: 6| Step: 13
Training loss: 2.8705494475020283
Validation loss: 2.529574134305864

Epoch: 153| Step: 0
Training loss: 2.673552048156014
Validation loss: 2.5285950641425754

Epoch: 6| Step: 1
Training loss: 2.9422726108843573
Validation loss: 2.576671387686234

Epoch: 6| Step: 2
Training loss: 2.5710351733869703
Validation loss: 2.612264228195439

Epoch: 6| Step: 3
Training loss: 2.5032042949180053
Validation loss: 2.627583990325797

Epoch: 6| Step: 4
Training loss: 2.8655457330720857
Validation loss: 2.616370326104608

Epoch: 6| Step: 5
Training loss: 2.480599467520244
Validation loss: 2.5863372475914326

Epoch: 6| Step: 6
Training loss: 2.7989241270117184
Validation loss: 2.5650221425137594

Epoch: 6| Step: 7
Training loss: 3.294509111112477
Validation loss: 2.5376638089144197

Epoch: 6| Step: 8
Training loss: 2.5911959287059676
Validation loss: 2.5161674045713647

Epoch: 6| Step: 9
Training loss: 2.540620953508559
Validation loss: 2.5148517059835513

Epoch: 6| Step: 10
Training loss: 2.0226732379292764
Validation loss: 2.5135217678170987

Epoch: 6| Step: 11
Training loss: 2.496127276128281
Validation loss: 2.503187317632126

Epoch: 6| Step: 12
Training loss: 2.282558013914114
Validation loss: 2.5090579862796427

Epoch: 6| Step: 13
Training loss: 2.6427956411945557
Validation loss: 2.52853003130349

Epoch: 154| Step: 0
Training loss: 2.8007231936429684
Validation loss: 2.5375519146719

Epoch: 6| Step: 1
Training loss: 2.995194082451542
Validation loss: 2.5807474282084883

Epoch: 6| Step: 2
Training loss: 2.8887583711272584
Validation loss: 2.6376624738833

Epoch: 6| Step: 3
Training loss: 2.786150269398518
Validation loss: 2.677949738301584

Epoch: 6| Step: 4
Training loss: 1.7511379084631762
Validation loss: 2.6431863906303086

Epoch: 6| Step: 5
Training loss: 2.700023304874014
Validation loss: 2.602342031503454

Epoch: 6| Step: 6
Training loss: 1.7524724932592028
Validation loss: 2.5510791077702675

Epoch: 6| Step: 7
Training loss: 2.497870778311076
Validation loss: 2.519050737383111

Epoch: 6| Step: 8
Training loss: 2.531303876138638
Validation loss: 2.5053406347600955

Epoch: 6| Step: 9
Training loss: 2.9772480653248343
Validation loss: 2.505618709401335

Epoch: 6| Step: 10
Training loss: 2.7797426575307194
Validation loss: 2.503338783889831

Epoch: 6| Step: 11
Training loss: 2.7010833438865482
Validation loss: 2.5296696072034144

Epoch: 6| Step: 12
Training loss: 2.9651698962163593
Validation loss: 2.533792630281519

Epoch: 6| Step: 13
Training loss: 2.8683786854177717
Validation loss: 2.543559415781399

Epoch: 155| Step: 0
Training loss: 2.7911540932072505
Validation loss: 2.5153207678403775

Epoch: 6| Step: 1
Training loss: 2.7261653927945844
Validation loss: 2.5009862010815067

Epoch: 6| Step: 2
Training loss: 2.398669899482238
Validation loss: 2.4837413569776543

Epoch: 6| Step: 3
Training loss: 2.8944945133570394
Validation loss: 2.48191862616717

Epoch: 6| Step: 4
Training loss: 3.0233345112768513
Validation loss: 2.5034005807277495

Epoch: 6| Step: 5
Training loss: 1.9171085953894509
Validation loss: 2.520404722963135

Epoch: 6| Step: 6
Training loss: 2.014651041033824
Validation loss: 2.5295680610958553

Epoch: 6| Step: 7
Training loss: 2.7624206945851077
Validation loss: 2.539209962511514

Epoch: 6| Step: 8
Training loss: 2.5907490846668555
Validation loss: 2.546765866971568

Epoch: 6| Step: 9
Training loss: 2.561523251346257
Validation loss: 2.551408321740468

Epoch: 6| Step: 10
Training loss: 2.492258483449828
Validation loss: 2.571550374577497

Epoch: 6| Step: 11
Training loss: 2.8842558103590332
Validation loss: 2.591016827024299

Epoch: 6| Step: 12
Training loss: 2.4388277399058103
Validation loss: 2.6366492851948355

Epoch: 6| Step: 13
Training loss: 2.4504414841834574
Validation loss: 2.689154293930847

Epoch: 156| Step: 0
Training loss: 2.5144747361123683
Validation loss: 2.824486614270112

Epoch: 6| Step: 1
Training loss: 3.0243959312400497
Validation loss: 2.893743516238818

Epoch: 6| Step: 2
Training loss: 3.2989752710114573
Validation loss: 2.9964206597051692

Epoch: 6| Step: 3
Training loss: 2.6146194840524535
Validation loss: 2.6888227944307777

Epoch: 6| Step: 4
Training loss: 2.817001978160203
Validation loss: 2.5112596190221748

Epoch: 6| Step: 5
Training loss: 2.1264387757622907
Validation loss: 2.4722385154394

Epoch: 6| Step: 6
Training loss: 2.1103859068526507
Validation loss: 2.4704376055980735

Epoch: 6| Step: 7
Training loss: 2.660190845326164
Validation loss: 2.489403096736852

Epoch: 6| Step: 8
Training loss: 2.7992294886236944
Validation loss: 2.5600123882731003

Epoch: 6| Step: 9
Training loss: 2.7041973125992027
Validation loss: 2.60527008077015

Epoch: 6| Step: 10
Training loss: 3.033707399324595
Validation loss: 2.620554934634539

Epoch: 6| Step: 11
Training loss: 2.1237964587774014
Validation loss: 2.5186579138310465

Epoch: 6| Step: 12
Training loss: 3.1302411188237715
Validation loss: 2.497606426778516

Epoch: 6| Step: 13
Training loss: 2.9672793309372842
Validation loss: 2.4736499345886713

Epoch: 157| Step: 0
Training loss: 2.741872220512948
Validation loss: 2.4518232411530256

Epoch: 6| Step: 1
Training loss: 2.7612571924132325
Validation loss: 2.461124070493751

Epoch: 6| Step: 2
Training loss: 2.4277941818420246
Validation loss: 2.482348604673989

Epoch: 6| Step: 3
Training loss: 2.541349068064912
Validation loss: 2.4985371714260385

Epoch: 6| Step: 4
Training loss: 2.7977706071948427
Validation loss: 2.5475360649852217

Epoch: 6| Step: 5
Training loss: 1.867927436579161
Validation loss: 2.5766608601750005

Epoch: 6| Step: 6
Training loss: 2.8147417247449655
Validation loss: 2.649378678134033

Epoch: 6| Step: 7
Training loss: 2.2896404903683627
Validation loss: 2.660678474181258

Epoch: 6| Step: 8
Training loss: 2.6186479280012414
Validation loss: 2.661630867678996

Epoch: 6| Step: 9
Training loss: 2.1905740119779393
Validation loss: 2.618629373062035

Epoch: 6| Step: 10
Training loss: 2.7697882055572043
Validation loss: 2.599168699944346

Epoch: 6| Step: 11
Training loss: 2.5331689601409018
Validation loss: 2.610570319298806

Epoch: 6| Step: 12
Training loss: 2.765209619395386
Validation loss: 2.587673506572592

Epoch: 6| Step: 13
Training loss: 2.4955282272121266
Validation loss: 2.581666052778829

Epoch: 158| Step: 0
Training loss: 2.572104620619628
Validation loss: 2.564315479928409

Epoch: 6| Step: 1
Training loss: 2.7892546600907364
Validation loss: 2.5425476034979493

Epoch: 6| Step: 2
Training loss: 2.5307476345806
Validation loss: 2.5072486020352156

Epoch: 6| Step: 3
Training loss: 2.64090686625502
Validation loss: 2.500447563388711

Epoch: 6| Step: 4
Training loss: 2.4190125315524136
Validation loss: 2.497941700324828

Epoch: 6| Step: 5
Training loss: 2.22840371548821
Validation loss: 2.533445168297795

Epoch: 6| Step: 6
Training loss: 2.536746333154096
Validation loss: 2.5588613889141905

Epoch: 6| Step: 7
Training loss: 2.2980065704862653
Validation loss: 2.582789874660917

Epoch: 6| Step: 8
Training loss: 2.531790028174757
Validation loss: 2.6154487261818566

Epoch: 6| Step: 9
Training loss: 2.918751071709185
Validation loss: 2.6244100639266894

Epoch: 6| Step: 10
Training loss: 2.559575715072036
Validation loss: 2.6345106035651122

Epoch: 6| Step: 11
Training loss: 2.683230357435234
Validation loss: 2.59099248732362

Epoch: 6| Step: 12
Training loss: 2.2199960352888017
Validation loss: 2.5659651998585815

Epoch: 6| Step: 13
Training loss: 2.4719366439675494
Validation loss: 2.547613732710704

Epoch: 159| Step: 0
Training loss: 2.6313622892436186
Validation loss: 2.554962585938174

Epoch: 6| Step: 1
Training loss: 2.517099836683001
Validation loss: 2.579991711606939

Epoch: 6| Step: 2
Training loss: 2.5545917458043923
Validation loss: 2.5904374905888674

Epoch: 6| Step: 3
Training loss: 2.395152672538447
Validation loss: 2.6162336104653723

Epoch: 6| Step: 4
Training loss: 2.9775483508792484
Validation loss: 2.6740846504789277

Epoch: 6| Step: 5
Training loss: 2.290704652408387
Validation loss: 2.7209442057538276

Epoch: 6| Step: 6
Training loss: 1.9906160028035733
Validation loss: 2.6984320679716514

Epoch: 6| Step: 7
Training loss: 2.9909059653643983
Validation loss: 2.6828807349240673

Epoch: 6| Step: 8
Training loss: 2.4822633994335654
Validation loss: 2.618472028197704

Epoch: 6| Step: 9
Training loss: 2.732879927486585
Validation loss: 2.5660157814950164

Epoch: 6| Step: 10
Training loss: 2.396426274000256
Validation loss: 2.5021077397493854

Epoch: 6| Step: 11
Training loss: 2.8994908642257378
Validation loss: 2.499973622049614

Epoch: 6| Step: 12
Training loss: 1.91296249232834
Validation loss: 2.491073989700926

Epoch: 6| Step: 13
Training loss: 2.2919646213923355
Validation loss: 2.473801750232061

Epoch: 160| Step: 0
Training loss: 3.191252649876189
Validation loss: 2.4808362586986483

Epoch: 6| Step: 1
Training loss: 2.6244966841865884
Validation loss: 2.4735118932488462

Epoch: 6| Step: 2
Training loss: 3.0517976559899034
Validation loss: 2.5095604929345234

Epoch: 6| Step: 3
Training loss: 2.439576267283235
Validation loss: 2.5499828609089232

Epoch: 6| Step: 4
Training loss: 2.6022158423820723
Validation loss: 2.6061577477914963

Epoch: 6| Step: 5
Training loss: 1.8355392998187752
Validation loss: 2.727232379485138

Epoch: 6| Step: 6
Training loss: 2.552556540286115
Validation loss: 2.802278442275006

Epoch: 6| Step: 7
Training loss: 3.0197068492763344
Validation loss: 2.767665319221079

Epoch: 6| Step: 8
Training loss: 2.494675497537244
Validation loss: 2.7571019137969084

Epoch: 6| Step: 9
Training loss: 2.4532892451609456
Validation loss: 2.6793029771404044

Epoch: 6| Step: 10
Training loss: 2.505011113916896
Validation loss: 2.5867342892274374

Epoch: 6| Step: 11
Training loss: 2.0473046470668725
Validation loss: 2.5378723172053985

Epoch: 6| Step: 12
Training loss: 2.2947463987101733
Validation loss: 2.5071154649815495

Epoch: 6| Step: 13
Training loss: 2.6973139753710873
Validation loss: 2.481698138115963

Epoch: 161| Step: 0
Training loss: 2.587541618565316
Validation loss: 2.4823030048149444

Epoch: 6| Step: 1
Training loss: 2.305249265320879
Validation loss: 2.4693391449245796

Epoch: 6| Step: 2
Training loss: 2.7945350789850933
Validation loss: 2.4600707200142384

Epoch: 6| Step: 3
Training loss: 2.6901858016728086
Validation loss: 2.463717082209377

Epoch: 6| Step: 4
Training loss: 2.7690911420850393
Validation loss: 2.472568183998206

Epoch: 6| Step: 5
Training loss: 2.910688395138468
Validation loss: 2.4918110346114797

Epoch: 6| Step: 6
Training loss: 2.2037316968204284
Validation loss: 2.473570217048575

Epoch: 6| Step: 7
Training loss: 2.515241510766493
Validation loss: 2.493380356473482

Epoch: 6| Step: 8
Training loss: 1.8856508380054042
Validation loss: 2.5059443395878187

Epoch: 6| Step: 9
Training loss: 2.7092410009350334
Validation loss: 2.512566298453555

Epoch: 6| Step: 10
Training loss: 2.5240776265777236
Validation loss: 2.519537798666419

Epoch: 6| Step: 11
Training loss: 2.4141225467855683
Validation loss: 2.555151816007438

Epoch: 6| Step: 12
Training loss: 2.646266531336291
Validation loss: 2.5669086657708227

Epoch: 6| Step: 13
Training loss: 2.8151258290763335
Validation loss: 2.5915205915097284

Epoch: 162| Step: 0
Training loss: 2.223523874005837
Validation loss: 2.669127229578861

Epoch: 6| Step: 1
Training loss: 2.0034105308667987
Validation loss: 2.709812466228231

Epoch: 6| Step: 2
Training loss: 2.363330481150439
Validation loss: 2.753094789692798

Epoch: 6| Step: 3
Training loss: 2.3304785794425835
Validation loss: 2.7979976646329563

Epoch: 6| Step: 4
Training loss: 2.8254599475306845
Validation loss: 2.7591676034128363

Epoch: 6| Step: 5
Training loss: 2.6711305172251074
Validation loss: 2.6683282258220187

Epoch: 6| Step: 6
Training loss: 2.748070039631178
Validation loss: 2.590750581835062

Epoch: 6| Step: 7
Training loss: 1.9667128665260547
Validation loss: 2.5304687461096615

Epoch: 6| Step: 8
Training loss: 2.7829097981393645
Validation loss: 2.493522971065823

Epoch: 6| Step: 9
Training loss: 2.24551262013489
Validation loss: 2.4922777858338114

Epoch: 6| Step: 10
Training loss: 3.189170848271207
Validation loss: 2.4616258623718728

Epoch: 6| Step: 11
Training loss: 2.6648170096320345
Validation loss: 2.4822082853640093

Epoch: 6| Step: 12
Training loss: 2.3591173043898395
Validation loss: 2.481348932559267

Epoch: 6| Step: 13
Training loss: 2.096248104342546
Validation loss: 2.483202022156639

Epoch: 163| Step: 0
Training loss: 2.6534765686817763
Validation loss: 2.5092996787782367

Epoch: 6| Step: 1
Training loss: 2.6365467608837627
Validation loss: 2.5359660178703276

Epoch: 6| Step: 2
Training loss: 2.680113822455748
Validation loss: 2.567802255920332

Epoch: 6| Step: 3
Training loss: 1.7755063798725876
Validation loss: 2.605781147911705

Epoch: 6| Step: 4
Training loss: 2.330268947976513
Validation loss: 2.6280418756745747

Epoch: 6| Step: 5
Training loss: 2.536066347469701
Validation loss: 2.6983851323302854

Epoch: 6| Step: 6
Training loss: 2.929311824871839
Validation loss: 2.698819347296294

Epoch: 6| Step: 7
Training loss: 2.4540376362669836
Validation loss: 2.7200881310872767

Epoch: 6| Step: 8
Training loss: 2.109277341489334
Validation loss: 2.675128228755312

Epoch: 6| Step: 9
Training loss: 2.328461488306572
Validation loss: 2.6608303008083074

Epoch: 6| Step: 10
Training loss: 2.8283595203932475
Validation loss: 2.6361985829037784

Epoch: 6| Step: 11
Training loss: 2.396205795747972
Validation loss: 2.6023694780167195

Epoch: 6| Step: 12
Training loss: 2.202111951436933
Validation loss: 2.574631800393097

Epoch: 6| Step: 13
Training loss: 1.835036815720946
Validation loss: 2.565683236021448

Epoch: 164| Step: 0
Training loss: 2.4643291050978604
Validation loss: 2.5602101124816428

Epoch: 6| Step: 1
Training loss: 1.9717661445182115
Validation loss: 2.5710249029902217

Epoch: 6| Step: 2
Training loss: 2.5881656140749816
Validation loss: 2.5817475514516084

Epoch: 6| Step: 3
Training loss: 2.2256732436459963
Validation loss: 2.5856123820471346

Epoch: 6| Step: 4
Training loss: 2.182422521730037
Validation loss: 2.5745590154128557

Epoch: 6| Step: 5
Training loss: 2.917086343998457
Validation loss: 2.598774153384338

Epoch: 6| Step: 6
Training loss: 2.1909271641320016
Validation loss: 2.5929507049325258

Epoch: 6| Step: 7
Training loss: 2.5323266459384217
Validation loss: 2.625143123422437

Epoch: 6| Step: 8
Training loss: 2.140652844324495
Validation loss: 2.630792560020224

Epoch: 6| Step: 9
Training loss: 2.142012765826769
Validation loss: 2.635145871343197

Epoch: 6| Step: 10
Training loss: 2.27135348414395
Validation loss: 2.62845492127785

Epoch: 6| Step: 11
Training loss: 2.6823543701743815
Validation loss: 2.6124424840867637

Epoch: 6| Step: 12
Training loss: 2.3937899513994325
Validation loss: 2.5938371203118424

Epoch: 6| Step: 13
Training loss: 2.6327018374948814
Validation loss: 2.56877763551316

Epoch: 165| Step: 0
Training loss: 1.6507059552216585
Validation loss: 2.581451467585082

Epoch: 6| Step: 1
Training loss: 2.735604407634104
Validation loss: 2.556709576344116

Epoch: 6| Step: 2
Training loss: 2.429429019045739
Validation loss: 2.5482643636445834

Epoch: 6| Step: 3
Training loss: 2.3951508807795845
Validation loss: 2.538141362383198

Epoch: 6| Step: 4
Training loss: 2.1608468412523125
Validation loss: 2.53046653246555

Epoch: 6| Step: 5
Training loss: 2.0641747813038984
Validation loss: 2.547511431119035

Epoch: 6| Step: 6
Training loss: 1.919318631188194
Validation loss: 2.5513553765678703

Epoch: 6| Step: 7
Training loss: 1.7565108841955996
Validation loss: 2.5589111271558145

Epoch: 6| Step: 8
Training loss: 2.618424854714681
Validation loss: 2.5820009511735846

Epoch: 6| Step: 9
Training loss: 2.38809519034587
Validation loss: 2.5703612197441226

Epoch: 6| Step: 10
Training loss: 2.9971944087822604
Validation loss: 2.5903171258940803

Epoch: 6| Step: 11
Training loss: 3.150086380515924
Validation loss: 2.611509365257897

Epoch: 6| Step: 12
Training loss: 1.7384410998965274
Validation loss: 2.5999507437537286

Epoch: 6| Step: 13
Training loss: 2.5184137276070544
Validation loss: 2.6112353412355724

Epoch: 166| Step: 0
Training loss: 1.9692522649554645
Validation loss: 2.623262946943922

Epoch: 6| Step: 1
Training loss: 2.908723168538286
Validation loss: 2.6399222488147

Epoch: 6| Step: 2
Training loss: 1.982083416689452
Validation loss: 2.615875675498092

Epoch: 6| Step: 3
Training loss: 2.5957204848283775
Validation loss: 2.5952445284762997

Epoch: 6| Step: 4
Training loss: 2.9022514154011954
Validation loss: 2.6175084345390265

Epoch: 6| Step: 5
Training loss: 2.421679778075599
Validation loss: 2.5802424496208873

Epoch: 6| Step: 6
Training loss: 1.7689168844584853
Validation loss: 2.5543165165527806

Epoch: 6| Step: 7
Training loss: 2.089246661015684
Validation loss: 2.541438114804551

Epoch: 6| Step: 8
Training loss: 2.549000420721116
Validation loss: 2.547506921744233

Epoch: 6| Step: 9
Training loss: 2.1112337188363957
Validation loss: 2.543167628943784

Epoch: 6| Step: 10
Training loss: 1.7485556773047066
Validation loss: 2.549582074393568

Epoch: 6| Step: 11
Training loss: 2.03646650255781
Validation loss: 2.550517147641958

Epoch: 6| Step: 12
Training loss: 2.5398767662190513
Validation loss: 2.561028703183498

Epoch: 6| Step: 13
Training loss: 2.522083497912128
Validation loss: 2.5906655100394267

Epoch: 167| Step: 0
Training loss: 2.678834829549285
Validation loss: 2.614606309008735

Epoch: 6| Step: 1
Training loss: 2.417939366175963
Validation loss: 2.6646488689411227

Epoch: 6| Step: 2
Training loss: 2.323365126857015
Validation loss: 2.6726104965595976

Epoch: 6| Step: 3
Training loss: 1.9121340632184278
Validation loss: 2.6918083621712707

Epoch: 6| Step: 4
Training loss: 1.7941780084776249
Validation loss: 2.6583999378049854

Epoch: 6| Step: 5
Training loss: 2.184799161885847
Validation loss: 2.6374503693554523

Epoch: 6| Step: 6
Training loss: 2.4846402392560325
Validation loss: 2.5885739007032553

Epoch: 6| Step: 7
Training loss: 2.064620459640101
Validation loss: 2.5496630893856502

Epoch: 6| Step: 8
Training loss: 2.978030826324513
Validation loss: 2.519448383886269

Epoch: 6| Step: 9
Training loss: 2.5335022125505504
Validation loss: 2.5208969664129364

Epoch: 6| Step: 10
Training loss: 2.575464158676916
Validation loss: 2.523149463821768

Epoch: 6| Step: 11
Training loss: 1.5225000871930778
Validation loss: 2.522222744343535

Epoch: 6| Step: 12
Training loss: 2.771599388827624
Validation loss: 2.603194596197186

Epoch: 6| Step: 13
Training loss: 1.60985365480895
Validation loss: 2.633017607604626

Epoch: 168| Step: 0
Training loss: 1.8042961455907542
Validation loss: 2.6419318083727625

Epoch: 6| Step: 1
Training loss: 2.2189148317816714
Validation loss: 2.6457005232413326

Epoch: 6| Step: 2
Training loss: 1.5076123831186
Validation loss: 2.6380376652582886

Epoch: 6| Step: 3
Training loss: 2.168775913402519
Validation loss: 2.611923306655617

Epoch: 6| Step: 4
Training loss: 2.6173099318378164
Validation loss: 2.591893369394551

Epoch: 6| Step: 5
Training loss: 2.3893928094909125
Validation loss: 2.5789997375684983

Epoch: 6| Step: 6
Training loss: 2.2653339067443037
Validation loss: 2.587573642801329

Epoch: 6| Step: 7
Training loss: 2.2470936548113993
Validation loss: 2.575486498547985

Epoch: 6| Step: 8
Training loss: 2.6957913622961924
Validation loss: 2.5872359689355466

Epoch: 6| Step: 9
Training loss: 2.4106914599917384
Validation loss: 2.576989288116874

Epoch: 6| Step: 10
Training loss: 2.4865645830338177
Validation loss: 2.5852622400368444

Epoch: 6| Step: 11
Training loss: 2.110252367448332
Validation loss: 2.6269194621280465

Epoch: 6| Step: 12
Training loss: 2.1094975188666356
Validation loss: 2.621724505695276

Epoch: 6| Step: 13
Training loss: 2.696134314816358
Validation loss: 2.6167650783361087

Epoch: 169| Step: 0
Training loss: 2.3132788918691545
Validation loss: 2.664503027972065

Epoch: 6| Step: 1
Training loss: 2.386646625534107
Validation loss: 2.7019258288835766

Epoch: 6| Step: 2
Training loss: 2.329683844437472
Validation loss: 2.7304930392683744

Epoch: 6| Step: 3
Training loss: 2.2720573929267127
Validation loss: 2.770217257696757

Epoch: 6| Step: 4
Training loss: 2.455656652637353
Validation loss: 2.8203692677779246

Epoch: 6| Step: 5
Training loss: 2.7859204970529325
Validation loss: 2.768738167237313

Epoch: 6| Step: 6
Training loss: 2.1995702974116593
Validation loss: 2.724305165027212

Epoch: 6| Step: 7
Training loss: 2.2521907948967006
Validation loss: 2.639575721384054

Epoch: 6| Step: 8
Training loss: 2.4541728703453356
Validation loss: 2.5773381200469174

Epoch: 6| Step: 9
Training loss: 2.245084054643512
Validation loss: 2.5214769976774005

Epoch: 6| Step: 10
Training loss: 2.1837947527749293
Validation loss: 2.5317036809447733

Epoch: 6| Step: 11
Training loss: 2.233192290886513
Validation loss: 2.5217392697938226

Epoch: 6| Step: 12
Training loss: 2.1943739653052248
Validation loss: 2.5564445481144995

Epoch: 6| Step: 13
Training loss: 2.166437381447794
Validation loss: 2.562759432301832

Epoch: 170| Step: 0
Training loss: 2.3790233063359936
Validation loss: 2.544717936806697

Epoch: 6| Step: 1
Training loss: 2.480670398115089
Validation loss: 2.5663393672795585

Epoch: 6| Step: 2
Training loss: 2.3626451881643695
Validation loss: 2.556578853589213

Epoch: 6| Step: 3
Training loss: 1.903283233829445
Validation loss: 2.6104792979090994

Epoch: 6| Step: 4
Training loss: 2.516243047197707
Validation loss: 2.683946114594178

Epoch: 6| Step: 5
Training loss: 2.1802254836684787
Validation loss: 2.70755800140544

Epoch: 6| Step: 6
Training loss: 2.2253545328634794
Validation loss: 2.708291416143583

Epoch: 6| Step: 7
Training loss: 2.4576731511971306
Validation loss: 2.640622510749278

Epoch: 6| Step: 8
Training loss: 2.4035121650491105
Validation loss: 2.578477979394364

Epoch: 6| Step: 9
Training loss: 2.4875094236262494
Validation loss: 2.518741097049403

Epoch: 6| Step: 10
Training loss: 2.7486428466561676
Validation loss: 2.5045322722643553

Epoch: 6| Step: 11
Training loss: 2.0652777721909836
Validation loss: 2.46195604087992

Epoch: 6| Step: 12
Training loss: 2.542509304093373
Validation loss: 2.4837415768296247

Epoch: 6| Step: 13
Training loss: 1.8601555348042056
Validation loss: 2.496998921693477

Epoch: 171| Step: 0
Training loss: 1.8937926435547865
Validation loss: 2.524161814411823

Epoch: 6| Step: 1
Training loss: 1.8081969120349894
Validation loss: 2.544630874707146

Epoch: 6| Step: 2
Training loss: 1.9000660382890957
Validation loss: 2.5468037772296848

Epoch: 6| Step: 3
Training loss: 2.182437597477262
Validation loss: 2.5840177231492634

Epoch: 6| Step: 4
Training loss: 1.7709997959061456
Validation loss: 2.6104414678000625

Epoch: 6| Step: 5
Training loss: 2.6580666108291906
Validation loss: 2.6075143009064545

Epoch: 6| Step: 6
Training loss: 2.7315896807240083
Validation loss: 2.6522578536144166

Epoch: 6| Step: 7
Training loss: 2.1334956266341836
Validation loss: 2.6524374318541906

Epoch: 6| Step: 8
Training loss: 2.374650427539838
Validation loss: 2.642691209501972

Epoch: 6| Step: 9
Training loss: 2.1994152895984387
Validation loss: 2.6633081366209725

Epoch: 6| Step: 10
Training loss: 2.883853052593887
Validation loss: 2.7000199693194284

Epoch: 6| Step: 11
Training loss: 2.106576150607451
Validation loss: 2.690684858881628

Epoch: 6| Step: 12
Training loss: 2.4605503322675744
Validation loss: 2.6668293086824053

Epoch: 6| Step: 13
Training loss: 2.0147377841236898
Validation loss: 2.6659734585063686

Epoch: 172| Step: 0
Training loss: 1.726768377811318
Validation loss: 2.654148399148628

Epoch: 6| Step: 1
Training loss: 1.9634891641277512
Validation loss: 2.6560316484669495

Epoch: 6| Step: 2
Training loss: 1.9361211731167465
Validation loss: 2.657518702266709

Epoch: 6| Step: 3
Training loss: 2.0124801824316623
Validation loss: 2.663750209877924

Epoch: 6| Step: 4
Training loss: 2.4793596806977263
Validation loss: 2.687912001511991

Epoch: 6| Step: 5
Training loss: 2.780980557880937
Validation loss: 2.6892960840847997

Epoch: 6| Step: 6
Training loss: 2.0828797291624896
Validation loss: 2.669034871202351

Epoch: 6| Step: 7
Training loss: 2.3014865176419024
Validation loss: 2.6253465344623703

Epoch: 6| Step: 8
Training loss: 2.161856949293307
Validation loss: 2.608286691994501

Epoch: 6| Step: 9
Training loss: 2.5546232909553233
Validation loss: 2.581836364628443

Epoch: 6| Step: 10
Training loss: 2.37555025653032
Validation loss: 2.5775183905269294

Epoch: 6| Step: 11
Training loss: 2.0510382790938713
Validation loss: 2.5419139466074205

Epoch: 6| Step: 12
Training loss: 2.2449298529933714
Validation loss: 2.5441664911773394

Epoch: 6| Step: 13
Training loss: 2.1583979868195846
Validation loss: 2.54982325162321

Epoch: 173| Step: 0
Training loss: 2.1849800854436636
Validation loss: 2.540336763935175

Epoch: 6| Step: 1
Training loss: 1.6018525395956422
Validation loss: 2.545962760352478

Epoch: 6| Step: 2
Training loss: 2.1050655849505877
Validation loss: 2.571502810887094

Epoch: 6| Step: 3
Training loss: 2.274457669853534
Validation loss: 2.5946851325324256

Epoch: 6| Step: 4
Training loss: 2.0299184102541705
Validation loss: 2.6332467990061823

Epoch: 6| Step: 5
Training loss: 2.4236131890939903
Validation loss: 2.644988183640801

Epoch: 6| Step: 6
Training loss: 2.571213028214971
Validation loss: 2.6610345590769566

Epoch: 6| Step: 7
Training loss: 1.9412941238291592
Validation loss: 2.6272245006566304

Epoch: 6| Step: 8
Training loss: 1.6238231799261664
Validation loss: 2.5967253308624727

Epoch: 6| Step: 9
Training loss: 2.0576409409595353
Validation loss: 2.552554364879657

Epoch: 6| Step: 10
Training loss: 2.7623455194286026
Validation loss: 2.5202882591503677

Epoch: 6| Step: 11
Training loss: 2.296185967513521
Validation loss: 2.493947242118011

Epoch: 6| Step: 12
Training loss: 2.5967762768797638
Validation loss: 2.487241731113435

Epoch: 6| Step: 13
Training loss: 1.9124992370603946
Validation loss: 2.5284534746711675

Epoch: 174| Step: 0
Training loss: 2.058720912299375
Validation loss: 2.5650980294962418

Epoch: 6| Step: 1
Training loss: 2.563175391534601
Validation loss: 2.6104135208366923

Epoch: 6| Step: 2
Training loss: 1.4889913151669005
Validation loss: 2.6704328149682683

Epoch: 6| Step: 3
Training loss: 2.1922004334985212
Validation loss: 2.7111338310597017

Epoch: 6| Step: 4
Training loss: 2.3487132100324546
Validation loss: 2.7362229494917067

Epoch: 6| Step: 5
Training loss: 1.9089149232973184
Validation loss: 2.700392987536253

Epoch: 6| Step: 6
Training loss: 2.2137924471145363
Validation loss: 2.670341784364307

Epoch: 6| Step: 7
Training loss: 1.6086000965765783
Validation loss: 2.624892458688052

Epoch: 6| Step: 8
Training loss: 2.3431534071426685
Validation loss: 2.6055934838205

Epoch: 6| Step: 9
Training loss: 2.9889315826253426
Validation loss: 2.6001295835198714

Epoch: 6| Step: 10
Training loss: 2.5771983012831905
Validation loss: 2.5843709809424213

Epoch: 6| Step: 11
Training loss: 2.273846042276084
Validation loss: 2.5815852317718537

Epoch: 6| Step: 12
Training loss: 1.6887736282559234
Validation loss: 2.590445099048957

Epoch: 6| Step: 13
Training loss: 1.9791054030188855
Validation loss: 2.5961573380900593

Epoch: 175| Step: 0
Training loss: 2.7179860762800185
Validation loss: 2.5324417695488823

Epoch: 6| Step: 1
Training loss: 2.418333947330382
Validation loss: 2.560414678058406

Epoch: 6| Step: 2
Training loss: 2.3074755340634736
Validation loss: 2.5422466304956877

Epoch: 6| Step: 3
Training loss: 1.5019875709740729
Validation loss: 2.5622393948036266

Epoch: 6| Step: 4
Training loss: 1.9815940895083284
Validation loss: 2.5765732347099157

Epoch: 6| Step: 5
Training loss: 2.0779994840648843
Validation loss: 2.5915258265723335

Epoch: 6| Step: 6
Training loss: 2.4050133239630798
Validation loss: 2.6328715607491646

Epoch: 6| Step: 7
Training loss: 2.1967126040172933
Validation loss: 2.6212454038378588

Epoch: 6| Step: 8
Training loss: 2.441764036283342
Validation loss: 2.614615442418506

Epoch: 6| Step: 9
Training loss: 1.9318422958582553
Validation loss: 2.6043628019899896

Epoch: 6| Step: 10
Training loss: 2.125306612221721
Validation loss: 2.5911327678128195

Epoch: 6| Step: 11
Training loss: 1.7329970375911796
Validation loss: 2.591783174435485

Epoch: 6| Step: 12
Training loss: 2.249547912955647
Validation loss: 2.6030698459121435

Epoch: 6| Step: 13
Training loss: 2.0749030125023924
Validation loss: 2.5591343412326744

Epoch: 176| Step: 0
Training loss: 2.0764495290734977
Validation loss: 2.6118692531104877

Epoch: 6| Step: 1
Training loss: 2.537154199499383
Validation loss: 2.635325718719731

Epoch: 6| Step: 2
Training loss: 2.0337421094932426
Validation loss: 2.661647060681482

Epoch: 6| Step: 3
Training loss: 2.12812799349895
Validation loss: 2.6658335215495232

Epoch: 6| Step: 4
Training loss: 2.2582416060659205
Validation loss: 2.635692563673563

Epoch: 6| Step: 5
Training loss: 2.1636433660278778
Validation loss: 2.61263787122219

Epoch: 6| Step: 6
Training loss: 1.8274660797728468
Validation loss: 2.576796556409342

Epoch: 6| Step: 7
Training loss: 2.17600883238767
Validation loss: 2.565330768622724

Epoch: 6| Step: 8
Training loss: 2.419093645311983
Validation loss: 2.533023125589664

Epoch: 6| Step: 9
Training loss: 1.9861207026655356
Validation loss: 2.553402742248217

Epoch: 6| Step: 10
Training loss: 1.931137281665345
Validation loss: 2.516766702255235

Epoch: 6| Step: 11
Training loss: 2.416782464070297
Validation loss: 2.529012743898095

Epoch: 6| Step: 12
Training loss: 1.5945789201069167
Validation loss: 2.5366883936755427

Epoch: 6| Step: 13
Training loss: 2.3263633258484235
Validation loss: 2.538840697944354

Epoch: 177| Step: 0
Training loss: 2.2657770566228717
Validation loss: 2.5741695495392163

Epoch: 6| Step: 1
Training loss: 1.6555724287488893
Validation loss: 2.5407462010838042

Epoch: 6| Step: 2
Training loss: 2.098676891405402
Validation loss: 2.5695873685990636

Epoch: 6| Step: 3
Training loss: 1.472740272128514
Validation loss: 2.572788416838923

Epoch: 6| Step: 4
Training loss: 2.1465636803621964
Validation loss: 2.645330698337038

Epoch: 6| Step: 5
Training loss: 1.7796200438886811
Validation loss: 2.673611511101169

Epoch: 6| Step: 6
Training loss: 2.4413404288002183
Validation loss: 2.693681877284981

Epoch: 6| Step: 7
Training loss: 2.1561325704691696
Validation loss: 2.706893699823612

Epoch: 6| Step: 8
Training loss: 2.247898603996652
Validation loss: 2.726385955496648

Epoch: 6| Step: 9
Training loss: 2.1549787229120416
Validation loss: 2.705825753881265

Epoch: 6| Step: 10
Training loss: 2.111718578388011
Validation loss: 2.648150150480204

Epoch: 6| Step: 11
Training loss: 2.4902071842878275
Validation loss: 2.588728633148405

Epoch: 6| Step: 12
Training loss: 2.53872988356223
Validation loss: 2.589564967295543

Epoch: 6| Step: 13
Training loss: 1.7023797460761991
Validation loss: 2.5983056511828067

Epoch: 178| Step: 0
Training loss: 1.7280120288421374
Validation loss: 2.575100348755662

Epoch: 6| Step: 1
Training loss: 2.362338598480249
Validation loss: 2.5755624644055906

Epoch: 6| Step: 2
Training loss: 1.9947609828518016
Validation loss: 2.6096772442616634

Epoch: 6| Step: 3
Training loss: 2.501152249875422
Validation loss: 2.6036233934984545

Epoch: 6| Step: 4
Training loss: 1.560754793183279
Validation loss: 2.6240599736833397

Epoch: 6| Step: 5
Training loss: 1.950614108685
Validation loss: 2.60402741550053

Epoch: 6| Step: 6
Training loss: 2.070978942705099
Validation loss: 2.627829851176277

Epoch: 6| Step: 7
Training loss: 2.17384446678634
Validation loss: 2.6083703674132135

Epoch: 6| Step: 8
Training loss: 2.5810519163222923
Validation loss: 2.617104592354695

Epoch: 6| Step: 9
Training loss: 2.421030598764966
Validation loss: 2.5859528345839857

Epoch: 6| Step: 10
Training loss: 2.133566922075359
Validation loss: 2.5614815305483734

Epoch: 6| Step: 11
Training loss: 2.0924209247993306
Validation loss: 2.580913923801629

Epoch: 6| Step: 12
Training loss: 1.55894148922217
Validation loss: 2.5673862474836118

Epoch: 6| Step: 13
Training loss: 2.173311485734587
Validation loss: 2.5509762497148603

Epoch: 179| Step: 0
Training loss: 2.07699669058127
Validation loss: 2.5226319629733522

Epoch: 6| Step: 1
Training loss: 1.929935516604465
Validation loss: 2.5179182430487743

Epoch: 6| Step: 2
Training loss: 2.353457273654233
Validation loss: 2.535560180211173

Epoch: 6| Step: 3
Training loss: 1.7018338830346944
Validation loss: 2.539671637556071

Epoch: 6| Step: 4
Training loss: 2.342400531102209
Validation loss: 2.556796323405834

Epoch: 6| Step: 5
Training loss: 1.8678121758815414
Validation loss: 2.5819875689794336

Epoch: 6| Step: 6
Training loss: 2.228559060638818
Validation loss: 2.605954313606975

Epoch: 6| Step: 7
Training loss: 1.8887938151399268
Validation loss: 2.6723037986841427

Epoch: 6| Step: 8
Training loss: 1.701466794295573
Validation loss: 2.703728761996378

Epoch: 6| Step: 9
Training loss: 2.197558031758888
Validation loss: 2.722205885329652

Epoch: 6| Step: 10
Training loss: 2.1296782887316272
Validation loss: 2.738170748232292

Epoch: 6| Step: 11
Training loss: 2.503624196465289
Validation loss: 2.7172662148773994

Epoch: 6| Step: 12
Training loss: 1.9323790771236058
Validation loss: 2.6962993672868643

Epoch: 6| Step: 13
Training loss: 2.672456198494848
Validation loss: 2.5911825128709762

Epoch: 180| Step: 0
Training loss: 2.21129742715455
Validation loss: 2.54534569454153

Epoch: 6| Step: 1
Training loss: 1.8933242571080398
Validation loss: 2.480458778475639

Epoch: 6| Step: 2
Training loss: 2.3952004522803523
Validation loss: 2.4624528190240955

Epoch: 6| Step: 3
Training loss: 2.026891404331671
Validation loss: 2.459569073648862

Epoch: 6| Step: 4
Training loss: 2.1918408511993026
Validation loss: 2.471392857509027

Epoch: 6| Step: 5
Training loss: 1.8549652380141044
Validation loss: 2.473105344152217

Epoch: 6| Step: 6
Training loss: 2.3306904425503103
Validation loss: 2.5197197778325564

Epoch: 6| Step: 7
Training loss: 2.20055396301491
Validation loss: 2.535024538178067

Epoch: 6| Step: 8
Training loss: 2.4356697253436908
Validation loss: 2.5727081300672188

Epoch: 6| Step: 9
Training loss: 1.4623132439728963
Validation loss: 2.6023034732983343

Epoch: 6| Step: 10
Training loss: 1.9594043954594158
Validation loss: 2.6138753307847695

Epoch: 6| Step: 11
Training loss: 2.328666163280195
Validation loss: 2.6243199914535604

Epoch: 6| Step: 12
Training loss: 1.80768676162281
Validation loss: 2.614860572590357

Epoch: 6| Step: 13
Training loss: 2.0655840155478704
Validation loss: 2.5863255714370332

Epoch: 181| Step: 0
Training loss: 2.347874991434346
Validation loss: 2.588603091634082

Epoch: 6| Step: 1
Training loss: 1.7647938079995118
Validation loss: 2.585434138491595

Epoch: 6| Step: 2
Training loss: 1.290238785858884
Validation loss: 2.568315474429263

Epoch: 6| Step: 3
Training loss: 1.8561734758523745
Validation loss: 2.548208210231164

Epoch: 6| Step: 4
Training loss: 2.521666291970752
Validation loss: 2.5396688383834163

Epoch: 6| Step: 5
Training loss: 1.9941662703610814
Validation loss: 2.5886885025555824

Epoch: 6| Step: 6
Training loss: 1.651139490095605
Validation loss: 2.5931425741147254

Epoch: 6| Step: 7
Training loss: 2.0737046576308975
Validation loss: 2.627398042565894

Epoch: 6| Step: 8
Training loss: 2.5514132080506546
Validation loss: 2.6198966778062527

Epoch: 6| Step: 9
Training loss: 1.826492101978568
Validation loss: 2.662842694515272

Epoch: 6| Step: 10
Training loss: 1.992177925834837
Validation loss: 2.67870849416898

Epoch: 6| Step: 11
Training loss: 2.1902167752074
Validation loss: 2.7096737251156453

Epoch: 6| Step: 12
Training loss: 1.8250812721445753
Validation loss: 2.704965874467273

Epoch: 6| Step: 13
Training loss: 2.17613494025491
Validation loss: 2.6962048523367215

Epoch: 182| Step: 0
Training loss: 1.8593325570014727
Validation loss: 2.671026265245689

Epoch: 6| Step: 1
Training loss: 2.066910738017461
Validation loss: 2.6469564804973715

Epoch: 6| Step: 2
Training loss: 1.6762317683219083
Validation loss: 2.627600111182232

Epoch: 6| Step: 3
Training loss: 2.2335374235967977
Validation loss: 2.5763878163701426

Epoch: 6| Step: 4
Training loss: 2.005738133050779
Validation loss: 2.542491146360246

Epoch: 6| Step: 5
Training loss: 2.054534790398073
Validation loss: 2.51863653563098

Epoch: 6| Step: 6
Training loss: 1.9620170509266301
Validation loss: 2.5653571006275726

Epoch: 6| Step: 7
Training loss: 1.8424040844199938
Validation loss: 2.556781543905473

Epoch: 6| Step: 8
Training loss: 2.29934912054995
Validation loss: 2.564617013820489

Epoch: 6| Step: 9
Training loss: 2.2757485300600138
Validation loss: 2.598720907541223

Epoch: 6| Step: 10
Training loss: 1.875850675252195
Validation loss: 2.6248064287169695

Epoch: 6| Step: 11
Training loss: 2.076989803166124
Validation loss: 2.643531783367502

Epoch: 6| Step: 12
Training loss: 1.8706535825065604
Validation loss: 2.608454902080682

Epoch: 6| Step: 13
Training loss: 2.2500156825896602
Validation loss: 2.612541153894656

Epoch: 183| Step: 0
Training loss: 1.6485106827097908
Validation loss: 2.6130038827485085

Epoch: 6| Step: 1
Training loss: 1.9738894394365818
Validation loss: 2.604200586569772

Epoch: 6| Step: 2
Training loss: 2.3443187786409663
Validation loss: 2.588304172813266

Epoch: 6| Step: 3
Training loss: 2.031082146384968
Validation loss: 2.587219212107912

Epoch: 6| Step: 4
Training loss: 1.8816557057041439
Validation loss: 2.576381826148302

Epoch: 6| Step: 5
Training loss: 2.0251190386033895
Validation loss: 2.569055909307837

Epoch: 6| Step: 6
Training loss: 1.7837799576594116
Validation loss: 2.574857072679647

Epoch: 6| Step: 7
Training loss: 2.2944347887346592
Validation loss: 2.5900434847195233

Epoch: 6| Step: 8
Training loss: 2.220254200137074
Validation loss: 2.6187194425371425

Epoch: 6| Step: 9
Training loss: 1.9311390718372956
Validation loss: 2.617577823581647

Epoch: 6| Step: 10
Training loss: 1.7569255710571512
Validation loss: 2.6432831097625895

Epoch: 6| Step: 11
Training loss: 2.0222734910569926
Validation loss: 2.657576036114939

Epoch: 6| Step: 12
Training loss: 2.2633396592798536
Validation loss: 2.6726481670640103

Epoch: 6| Step: 13
Training loss: 1.613984552737296
Validation loss: 2.700278663383525

Epoch: 184| Step: 0
Training loss: 2.264756661116117
Validation loss: 2.6620370095171597

Epoch: 6| Step: 1
Training loss: 1.8337093386728338
Validation loss: 2.634228496681592

Epoch: 6| Step: 2
Training loss: 2.4088279489001168
Validation loss: 2.616940493338479

Epoch: 6| Step: 3
Training loss: 2.17709645049845
Validation loss: 2.597903243868488

Epoch: 6| Step: 4
Training loss: 1.081784988087869
Validation loss: 2.5876418758994753

Epoch: 6| Step: 5
Training loss: 1.7231605120442364
Validation loss: 2.592836564359257

Epoch: 6| Step: 6
Training loss: 1.3662023428155097
Validation loss: 2.5641612938792075

Epoch: 6| Step: 7
Training loss: 1.9747058456203788
Validation loss: 2.542055773659416

Epoch: 6| Step: 8
Training loss: 2.4773078061723006
Validation loss: 2.5630011139833506

Epoch: 6| Step: 9
Training loss: 1.8167385658711692
Validation loss: 2.5746493849420826

Epoch: 6| Step: 10
Training loss: 1.6234893379343003
Validation loss: 2.5725126141437276

Epoch: 6| Step: 11
Training loss: 2.4098969602915417
Validation loss: 2.58079206695216

Epoch: 6| Step: 12
Training loss: 2.00748592348021
Validation loss: 2.597193002732942

Epoch: 6| Step: 13
Training loss: 2.111883861368492
Validation loss: 2.6279724985589983

Epoch: 185| Step: 0
Training loss: 1.8188562421148022
Validation loss: 2.66878664985266

Epoch: 6| Step: 1
Training loss: 1.357657696115885
Validation loss: 2.6859061877786092

Epoch: 6| Step: 2
Training loss: 1.7927666178273438
Validation loss: 2.6544004579747416

Epoch: 6| Step: 3
Training loss: 2.3548582180941255
Validation loss: 2.6562534127162216

Epoch: 6| Step: 4
Training loss: 1.8203465536313086
Validation loss: 2.6361501920391115

Epoch: 6| Step: 5
Training loss: 2.148368473678072
Validation loss: 2.629738548103628

Epoch: 6| Step: 6
Training loss: 1.548573957756885
Validation loss: 2.582540835772925

Epoch: 6| Step: 7
Training loss: 2.027462641587017
Validation loss: 2.5497009274078337

Epoch: 6| Step: 8
Training loss: 2.6790747650979925
Validation loss: 2.564139041301981

Epoch: 6| Step: 9
Training loss: 2.11036240814543
Validation loss: 2.555893472025853

Epoch: 6| Step: 10
Training loss: 2.045837838452177
Validation loss: 2.560200996266616

Epoch: 6| Step: 11
Training loss: 1.7155459971208304
Validation loss: 2.574619596685332

Epoch: 6| Step: 12
Training loss: 1.8808927127026671
Validation loss: 2.5620779354684116

Epoch: 6| Step: 13
Training loss: 1.8646677165055185
Validation loss: 2.5816349721240837

Epoch: 186| Step: 0
Training loss: 1.5233299021748328
Validation loss: 2.59501101157643

Epoch: 6| Step: 1
Training loss: 1.9653954158062983
Validation loss: 2.599325972566737

Epoch: 6| Step: 2
Training loss: 1.6096283055927936
Validation loss: 2.655374618951207

Epoch: 6| Step: 3
Training loss: 1.9497067866813647
Validation loss: 2.6973379758270624

Epoch: 6| Step: 4
Training loss: 2.5687039336368915
Validation loss: 2.6961701676262715

Epoch: 6| Step: 5
Training loss: 1.8220445635817628
Validation loss: 2.628866663494584

Epoch: 6| Step: 6
Training loss: 1.229242979794981
Validation loss: 2.6140840533564647

Epoch: 6| Step: 7
Training loss: 1.4962143812027147
Validation loss: 2.488204823261976

Epoch: 6| Step: 8
Training loss: 1.96102661902974
Validation loss: 2.4950541528750865

Epoch: 6| Step: 9
Training loss: 2.1896849483160996
Validation loss: 2.4515322140075226

Epoch: 6| Step: 10
Training loss: 1.8236968705071126
Validation loss: 2.4882237995748313

Epoch: 6| Step: 11
Training loss: 2.3878481825743614
Validation loss: 2.5016930702520614

Epoch: 6| Step: 12
Training loss: 2.1570887385592847
Validation loss: 2.498660007393513

Epoch: 6| Step: 13
Training loss: 2.7003337583178557
Validation loss: 2.494885910267848

Epoch: 187| Step: 0
Training loss: 1.6879312176227488
Validation loss: 2.559135020426452

Epoch: 6| Step: 1
Training loss: 2.250405592919108
Validation loss: 2.628882616555456

Epoch: 6| Step: 2
Training loss: 1.7150285834107528
Validation loss: 2.6558924975487

Epoch: 6| Step: 3
Training loss: 1.8124599452361223
Validation loss: 2.694855467058131

Epoch: 6| Step: 4
Training loss: 2.170908651186331
Validation loss: 2.7140628825158184

Epoch: 6| Step: 5
Training loss: 1.8265458810277029
Validation loss: 2.647212372483881

Epoch: 6| Step: 6
Training loss: 1.9509550934535533
Validation loss: 2.5672545814733674

Epoch: 6| Step: 7
Training loss: 2.046391786802511
Validation loss: 2.5128140207524146

Epoch: 6| Step: 8
Training loss: 1.8706664551163596
Validation loss: 2.514154711658906

Epoch: 6| Step: 9
Training loss: 1.7203235705553903
Validation loss: 2.5070578489708684

Epoch: 6| Step: 10
Training loss: 1.5912042368790733
Validation loss: 2.531995764988423

Epoch: 6| Step: 11
Training loss: 2.3558276458157015
Validation loss: 2.5522010205180354

Epoch: 6| Step: 12
Training loss: 2.1747812270709246
Validation loss: 2.6279112439472034

Epoch: 6| Step: 13
Training loss: 2.0310370700445177
Validation loss: 2.6527486957147897

Epoch: 188| Step: 0
Training loss: 1.858627361364094
Validation loss: 2.6802914779274785

Epoch: 6| Step: 1
Training loss: 1.6457332467981254
Validation loss: 2.6423292452184652

Epoch: 6| Step: 2
Training loss: 1.5927310004740962
Validation loss: 2.6132973374430866

Epoch: 6| Step: 3
Training loss: 2.062206594231645
Validation loss: 2.5903622182794126

Epoch: 6| Step: 4
Training loss: 2.36372267958952
Validation loss: 2.5534222681505057

Epoch: 6| Step: 5
Training loss: 1.8085423373665774
Validation loss: 2.5197435825497094

Epoch: 6| Step: 6
Training loss: 1.660285639489062
Validation loss: 2.515726141328556

Epoch: 6| Step: 7
Training loss: 1.9268028536296522
Validation loss: 2.516306749152867

Epoch: 6| Step: 8
Training loss: 1.3222049490729133
Validation loss: 2.4781247565181377

Epoch: 6| Step: 9
Training loss: 1.7214817186460176
Validation loss: 2.515246610030736

Epoch: 6| Step: 10
Training loss: 1.972575029268532
Validation loss: 2.468556246067094

Epoch: 6| Step: 11
Training loss: 2.4573132181832866
Validation loss: 2.52476897346834

Epoch: 6| Step: 12
Training loss: 2.0182780467031076
Validation loss: 2.531368112587276

Epoch: 6| Step: 13
Training loss: 2.0275361368554896
Validation loss: 2.538246865600917

Epoch: 189| Step: 0
Training loss: 2.4450754654048326
Validation loss: 2.5474377857194987

Epoch: 6| Step: 1
Training loss: 1.4089839215088853
Validation loss: 2.5891376547998304

Epoch: 6| Step: 2
Training loss: 1.7943001252446942
Validation loss: 2.575387607587994

Epoch: 6| Step: 3
Training loss: 2.0345026822900985
Validation loss: 2.613871846065685

Epoch: 6| Step: 4
Training loss: 2.3931458589805925
Validation loss: 2.6551283010379008

Epoch: 6| Step: 5
Training loss: 1.8097497528914932
Validation loss: 2.6661888631513873

Epoch: 6| Step: 6
Training loss: 2.2152411425626215
Validation loss: 2.6557117203883713

Epoch: 6| Step: 7
Training loss: 2.0396051963540955
Validation loss: 2.618833904805223

Epoch: 6| Step: 8
Training loss: 1.6662456537005437
Validation loss: 2.597775270022391

Epoch: 6| Step: 9
Training loss: 1.4848440934872964
Validation loss: 2.559589608063182

Epoch: 6| Step: 10
Training loss: 1.9333679683915301
Validation loss: 2.558156431777926

Epoch: 6| Step: 11
Training loss: 1.7858162959798134
Validation loss: 2.5571011500982306

Epoch: 6| Step: 12
Training loss: 1.2710843489755876
Validation loss: 2.5283150104459553

Epoch: 6| Step: 13
Training loss: 1.543928789295282
Validation loss: 2.5513028191680616

Epoch: 190| Step: 0
Training loss: 1.5281955070845925
Validation loss: 2.5363814675053407

Epoch: 6| Step: 1
Training loss: 1.9380986304089989
Validation loss: 2.515656045273606

Epoch: 6| Step: 2
Training loss: 2.171968197366691
Validation loss: 2.581700643333075

Epoch: 6| Step: 3
Training loss: 1.70650964794455
Validation loss: 2.5875476562683213

Epoch: 6| Step: 4
Training loss: 1.8322544246645662
Validation loss: 2.5862659859993777

Epoch: 6| Step: 5
Training loss: 1.2714009763025313
Validation loss: 2.6079920320921692

Epoch: 6| Step: 6
Training loss: 1.508628268763103
Validation loss: 2.6076070774670206

Epoch: 6| Step: 7
Training loss: 2.2162853037200225
Validation loss: 2.6164437077204012

Epoch: 6| Step: 8
Training loss: 1.8963513627241555
Validation loss: 2.6651507870777933

Epoch: 6| Step: 9
Training loss: 2.098193108819923
Validation loss: 2.653983918751927

Epoch: 6| Step: 10
Training loss: 1.991644332739238
Validation loss: 2.581260299592546

Epoch: 6| Step: 11
Training loss: 1.721658638378134
Validation loss: 2.5770521122274457

Epoch: 6| Step: 12
Training loss: 1.9583361267178139
Validation loss: 2.5589987673399586

Epoch: 6| Step: 13
Training loss: 1.9714842685784844
Validation loss: 2.5322111637623026

Epoch: 191| Step: 0
Training loss: 2.2374937259863157
Validation loss: 2.5280745517744156

Epoch: 6| Step: 1
Training loss: 2.010325243622047
Validation loss: 2.540176443586643

Epoch: 6| Step: 2
Training loss: 1.2823857181784224
Validation loss: 2.521853883533425

Epoch: 6| Step: 3
Training loss: 2.334496911885729
Validation loss: 2.536379556181539

Epoch: 6| Step: 4
Training loss: 2.076051179207233
Validation loss: 2.605177603781381

Epoch: 6| Step: 5
Training loss: 1.6801792578202552
Validation loss: 2.6225444424384228

Epoch: 6| Step: 6
Training loss: 1.9159160125378667
Validation loss: 2.630609962471991

Epoch: 6| Step: 7
Training loss: 1.9928142683629395
Validation loss: 2.6212521854467634

Epoch: 6| Step: 8
Training loss: 1.5500006644955102
Validation loss: 2.6020114221516937

Epoch: 6| Step: 9
Training loss: 1.828370428320459
Validation loss: 2.5981974736544795

Epoch: 6| Step: 10
Training loss: 0.8975062644229829
Validation loss: 2.5905296377501754

Epoch: 6| Step: 11
Training loss: 1.836204736617851
Validation loss: 2.6058084883503168

Epoch: 6| Step: 12
Training loss: 1.6826723059838333
Validation loss: 2.611773800048958

Epoch: 6| Step: 13
Training loss: 1.8688500316983714
Validation loss: 2.6155179424696224

Epoch: 192| Step: 0
Training loss: 1.8774662328698235
Validation loss: 2.642405372432798

Epoch: 6| Step: 1
Training loss: 2.34265375567059
Validation loss: 2.6429791515578844

Epoch: 6| Step: 2
Training loss: 1.8006625519067234
Validation loss: 2.6526206076517433

Epoch: 6| Step: 3
Training loss: 1.9689409678043897
Validation loss: 2.6682653083187153

Epoch: 6| Step: 4
Training loss: 1.4094071868807436
Validation loss: 2.6747793749716267

Epoch: 6| Step: 5
Training loss: 1.3863953119175578
Validation loss: 2.675271039236014

Epoch: 6| Step: 6
Training loss: 1.2448290682271979
Validation loss: 2.7040274234777186

Epoch: 6| Step: 7
Training loss: 2.102485539117857
Validation loss: 2.6958206408747847

Epoch: 6| Step: 8
Training loss: 1.8165543034419631
Validation loss: 2.7285377833387234

Epoch: 6| Step: 9
Training loss: 1.8556704120469136
Validation loss: 2.6943377843464527

Epoch: 6| Step: 10
Training loss: 2.0312786393714184
Validation loss: 2.652207999436175

Epoch: 6| Step: 11
Training loss: 2.059845806017497
Validation loss: 2.6117904611768665

Epoch: 6| Step: 12
Training loss: 1.77985173272255
Validation loss: 2.5929831339667

Epoch: 6| Step: 13
Training loss: 1.4733715799094067
Validation loss: 2.5828922806887493

Epoch: 193| Step: 0
Training loss: 2.4626832613066627
Validation loss: 2.5946235752237867

Epoch: 6| Step: 1
Training loss: 2.2001586856832622
Validation loss: 2.6276345556075467

Epoch: 6| Step: 2
Training loss: 1.357672491197075
Validation loss: 2.6036311495231

Epoch: 6| Step: 3
Training loss: 1.2174533891469863
Validation loss: 2.6250125681570893

Epoch: 6| Step: 4
Training loss: 1.6597092688714292
Validation loss: 2.6462367180425814

Epoch: 6| Step: 5
Training loss: 1.6077331760660984
Validation loss: 2.6480121450657785

Epoch: 6| Step: 6
Training loss: 1.5974392545370968
Validation loss: 2.6655742255972026

Epoch: 6| Step: 7
Training loss: 2.0498849417799363
Validation loss: 2.6493100871633772

Epoch: 6| Step: 8
Training loss: 1.8345993034828068
Validation loss: 2.649298970621923

Epoch: 6| Step: 9
Training loss: 1.7216190320958946
Validation loss: 2.6200921098339145

Epoch: 6| Step: 10
Training loss: 1.7962231988042259
Validation loss: 2.626431515764185

Epoch: 6| Step: 11
Training loss: 2.0016253542653506
Validation loss: 2.635759512190231

Epoch: 6| Step: 12
Training loss: 1.783338159334777
Validation loss: 2.6099102897519604

Epoch: 6| Step: 13
Training loss: 1.4405191477781045
Validation loss: 2.5951173866942714

Epoch: 194| Step: 0
Training loss: 1.8261268324575475
Validation loss: 2.608115919329567

Epoch: 6| Step: 1
Training loss: 2.3342417810464307
Validation loss: 2.5985224948964083

Epoch: 6| Step: 2
Training loss: 1.4467067282853203
Validation loss: 2.5690369273338947

Epoch: 6| Step: 3
Training loss: 1.8668572680484004
Validation loss: 2.591417222577569

Epoch: 6| Step: 4
Training loss: 1.9229583788060738
Validation loss: 2.603730499821705

Epoch: 6| Step: 5
Training loss: 1.8460755633452397
Validation loss: 2.585359704176942

Epoch: 6| Step: 6
Training loss: 1.6714463442019372
Validation loss: 2.5686562194304314

Epoch: 6| Step: 7
Training loss: 0.846100535413985
Validation loss: 2.5691930110366847

Epoch: 6| Step: 8
Training loss: 1.7615882842142925
Validation loss: 2.610761265746015

Epoch: 6| Step: 9
Training loss: 1.1957454022146268
Validation loss: 2.62688620676087

Epoch: 6| Step: 10
Training loss: 1.8391155899668943
Validation loss: 2.691547535767717

Epoch: 6| Step: 11
Training loss: 2.201825130438223
Validation loss: 2.719435674558032

Epoch: 6| Step: 12
Training loss: 2.2087699050740417
Validation loss: 2.7533047341126706

Epoch: 6| Step: 13
Training loss: 1.1419211039138306
Validation loss: 2.665605995200782

Epoch: 195| Step: 0
Training loss: 2.025951576354649
Validation loss: 2.6584346929233673

Epoch: 6| Step: 1
Training loss: 1.6522633057259257
Validation loss: 2.6190859539841913

Epoch: 6| Step: 2
Training loss: 0.6974979088522899
Validation loss: 2.583829843624448

Epoch: 6| Step: 3
Training loss: 1.79946420960529
Validation loss: 2.53729323619667

Epoch: 6| Step: 4
Training loss: 1.8065168348637097
Validation loss: 2.548613326915277

Epoch: 6| Step: 5
Training loss: 1.9252650437638485
Validation loss: 2.532154090424859

Epoch: 6| Step: 6
Training loss: 1.8157360522241208
Validation loss: 2.53630281397651

Epoch: 6| Step: 7
Training loss: 1.3444876752992856
Validation loss: 2.5018465390640445

Epoch: 6| Step: 8
Training loss: 1.3945400975050877
Validation loss: 2.5389078718860847

Epoch: 6| Step: 9
Training loss: 2.0271720446013175
Validation loss: 2.5360553734102167

Epoch: 6| Step: 10
Training loss: 1.9967485462439907
Validation loss: 2.590802422111192

Epoch: 6| Step: 11
Training loss: 1.8319283722905224
Validation loss: 2.6525837438710926

Epoch: 6| Step: 12
Training loss: 2.4773138693478436
Validation loss: 2.6905651656272926

Epoch: 6| Step: 13
Training loss: 1.1302623589373033
Validation loss: 2.703203059685279

Epoch: 196| Step: 0
Training loss: 1.7736597132000151
Validation loss: 2.758225713621274

Epoch: 6| Step: 1
Training loss: 1.882988252786468
Validation loss: 2.7256931242660825

Epoch: 6| Step: 2
Training loss: 1.3807362200732993
Validation loss: 2.7304218035929413

Epoch: 6| Step: 3
Training loss: 2.0532775218405224
Validation loss: 2.6600872189429996

Epoch: 6| Step: 4
Training loss: 1.4107635965403582
Validation loss: 2.620929656213488

Epoch: 6| Step: 5
Training loss: 1.7717078424419577
Validation loss: 2.5615159703223114

Epoch: 6| Step: 6
Training loss: 1.6669647268168755
Validation loss: 2.5358829189670744

Epoch: 6| Step: 7
Training loss: 2.025773162178345
Validation loss: 2.5435107148401164

Epoch: 6| Step: 8
Training loss: 2.139597402474992
Validation loss: 2.5309710068454083

Epoch: 6| Step: 9
Training loss: 1.4045151075376996
Validation loss: 2.5322336214889867

Epoch: 6| Step: 10
Training loss: 1.9410155611274265
Validation loss: 2.5480486487484995

Epoch: 6| Step: 11
Training loss: 1.8245481402004204
Validation loss: 2.574355050970491

Epoch: 6| Step: 12
Training loss: 1.6998604100081818
Validation loss: 2.6103162457471867

Epoch: 6| Step: 13
Training loss: 1.6576434337758041
Validation loss: 2.676539660864238

Epoch: 197| Step: 0
Training loss: 1.1970597007606005
Validation loss: 2.7467379608702083

Epoch: 6| Step: 1
Training loss: 1.5635775093309403
Validation loss: 2.785722363518232

Epoch: 6| Step: 2
Training loss: 1.9764090014777904
Validation loss: 2.7693958468925906

Epoch: 6| Step: 3
Training loss: 2.2593584410929877
Validation loss: 2.7435895169996565

Epoch: 6| Step: 4
Training loss: 1.950494933285326
Validation loss: 2.698339189657355

Epoch: 6| Step: 5
Training loss: 1.5907934852806254
Validation loss: 2.654688748499637

Epoch: 6| Step: 6
Training loss: 1.3806938277185001
Validation loss: 2.610292220064634

Epoch: 6| Step: 7
Training loss: 2.0557658915545094
Validation loss: 2.5769890961165953

Epoch: 6| Step: 8
Training loss: 1.724056721287485
Validation loss: 2.5743977212801563

Epoch: 6| Step: 9
Training loss: 1.6980353783919675
Validation loss: 2.5556301081286983

Epoch: 6| Step: 10
Training loss: 1.2040552283512256
Validation loss: 2.6189256264655363

Epoch: 6| Step: 11
Training loss: 1.8847032605857736
Validation loss: 2.5944370506849794

Epoch: 6| Step: 12
Training loss: 2.142138760357958
Validation loss: 2.6479045082226813

Epoch: 6| Step: 13
Training loss: 1.6263032968688136
Validation loss: 2.6548665863898764

Epoch: 198| Step: 0
Training loss: 2.253638610287552
Validation loss: 2.6606430478779024

Epoch: 6| Step: 1
Training loss: 1.3097903118770715
Validation loss: 2.72039874678621

Epoch: 6| Step: 2
Training loss: 1.491085664274919
Validation loss: 2.73298271114093

Epoch: 6| Step: 3
Training loss: 1.9006697478165144
Validation loss: 2.7360423733770753

Epoch: 6| Step: 4
Training loss: 1.8830084481113114
Validation loss: 2.6983798722915897

Epoch: 6| Step: 5
Training loss: 1.6066058881562704
Validation loss: 2.6006830117001796

Epoch: 6| Step: 6
Training loss: 1.4552391833578524
Validation loss: 2.498065934591205

Epoch: 6| Step: 7
Training loss: 2.0361192295710016
Validation loss: 2.473540937168121

Epoch: 6| Step: 8
Training loss: 2.0053898188383443
Validation loss: 2.4215185913395514

Epoch: 6| Step: 9
Training loss: 1.3811107012902495
Validation loss: 2.4566274438578892

Epoch: 6| Step: 10
Training loss: 1.910780229436415
Validation loss: 2.4834423826095

Epoch: 6| Step: 11
Training loss: 1.897073577592134
Validation loss: 2.4764560148508648

Epoch: 6| Step: 12
Training loss: 1.499647178481448
Validation loss: 2.498659177354367

Epoch: 6| Step: 13
Training loss: 2.3934554753000215
Validation loss: 2.560720666838446

Epoch: 199| Step: 0
Training loss: 1.7400121407797806
Validation loss: 2.57569756358723

Epoch: 6| Step: 1
Training loss: 1.5678147525934647
Validation loss: 2.587429580653644

Epoch: 6| Step: 2
Training loss: 1.9765631031141002
Validation loss: 2.5857278706478732

Epoch: 6| Step: 3
Training loss: 1.6573055430594021
Validation loss: 2.5952361013498653

Epoch: 6| Step: 4
Training loss: 1.8434052225802742
Validation loss: 2.575480658526432

Epoch: 6| Step: 5
Training loss: 1.2614222789413667
Validation loss: 2.556022480635882

Epoch: 6| Step: 6
Training loss: 1.7084234570557044
Validation loss: 2.52182855556831

Epoch: 6| Step: 7
Training loss: 1.7895902829669958
Validation loss: 2.551889618048355

Epoch: 6| Step: 8
Training loss: 1.35380865891052
Validation loss: 2.5588083344588655

Epoch: 6| Step: 9
Training loss: 1.581580279087729
Validation loss: 2.5955228117686366

Epoch: 6| Step: 10
Training loss: 2.296393934462005
Validation loss: 2.566402230333201

Epoch: 6| Step: 11
Training loss: 1.6071486397291028
Validation loss: 2.5733637224368184

Epoch: 6| Step: 12
Training loss: 2.0244072317329285
Validation loss: 2.583474236442197

Epoch: 6| Step: 13
Training loss: 1.2611390662957649
Validation loss: 2.5900524127544435

Epoch: 200| Step: 0
Training loss: 1.4591531719728963
Validation loss: 2.641975882996358

Epoch: 6| Step: 1
Training loss: 1.8840348956891533
Validation loss: 2.6228864494586888

Epoch: 6| Step: 2
Training loss: 1.5677850225031742
Validation loss: 2.636448291320524

Epoch: 6| Step: 3
Training loss: 0.6932997127169767
Validation loss: 2.6425876011992435

Epoch: 6| Step: 4
Training loss: 2.1114889219527764
Validation loss: 2.6550209700704075

Epoch: 6| Step: 5
Training loss: 1.8439641278598629
Validation loss: 2.6643980173004156

Epoch: 6| Step: 6
Training loss: 1.1437721208611566
Validation loss: 2.658179949738321

Epoch: 6| Step: 7
Training loss: 1.6973940117041884
Validation loss: 2.6792286331966

Epoch: 6| Step: 8
Training loss: 1.6201173346613105
Validation loss: 2.681255494948319

Epoch: 6| Step: 9
Training loss: 1.7905943862934415
Validation loss: 2.691048076476607

Epoch: 6| Step: 10
Training loss: 1.6927249692441728
Validation loss: 2.688205060838126

Epoch: 6| Step: 11
Training loss: 1.4184796382395983
Validation loss: 2.689987349871761

Epoch: 6| Step: 12
Training loss: 2.049154861041803
Validation loss: 2.718741885446469

Epoch: 6| Step: 13
Training loss: 2.469312676155219
Validation loss: 2.767430975511645

Epoch: 201| Step: 0
Training loss: 1.739278854251402
Validation loss: 2.7632659125784724

Epoch: 6| Step: 1
Training loss: 1.7708553387639707
Validation loss: 2.76277897698014

Epoch: 6| Step: 2
Training loss: 2.243499478351353
Validation loss: 2.7826631593823286

Epoch: 6| Step: 3
Training loss: 1.9498215471433138
Validation loss: 2.760817986676752

Epoch: 6| Step: 4
Training loss: 1.501667843873596
Validation loss: 2.73407019913075

Epoch: 6| Step: 5
Training loss: 1.6278318525640687
Validation loss: 2.6856389519054535

Epoch: 6| Step: 6
Training loss: 1.8880226573716046
Validation loss: 2.6791986116170343

Epoch: 6| Step: 7
Training loss: 1.5811374729812637
Validation loss: 2.6301499197723754

Epoch: 6| Step: 8
Training loss: 1.5558304922155923
Validation loss: 2.6148398622856432

Epoch: 6| Step: 9
Training loss: 1.083806808637121
Validation loss: 2.5630648535913503

Epoch: 6| Step: 10
Training loss: 1.7372473224262985
Validation loss: 2.5938162925522326

Epoch: 6| Step: 11
Training loss: 1.6419055119508432
Validation loss: 2.6096107033081117

Epoch: 6| Step: 12
Training loss: 1.2488916728747401
Validation loss: 2.5921335947237876

Epoch: 6| Step: 13
Training loss: 1.6155761209616402
Validation loss: 2.6346288986547166

Epoch: 202| Step: 0
Training loss: 1.6422640651054699
Validation loss: 2.6464172163442377

Epoch: 6| Step: 1
Training loss: 1.6278986387261059
Validation loss: 2.6695550348996

Epoch: 6| Step: 2
Training loss: 1.6540158155762203
Validation loss: 2.6921079509014003

Epoch: 6| Step: 3
Training loss: 1.5257185071944959
Validation loss: 2.6851038800225835

Epoch: 6| Step: 4
Training loss: 1.3620188204631525
Validation loss: 2.6517910065817354

Epoch: 6| Step: 5
Training loss: 1.100605271447999
Validation loss: 2.7060423668981595

Epoch: 6| Step: 6
Training loss: 1.933541468674511
Validation loss: 2.7203396647742313

Epoch: 6| Step: 7
Training loss: 1.6033058168636811
Validation loss: 2.645129337756838

Epoch: 6| Step: 8
Training loss: 1.9835553015655742
Validation loss: 2.660217347096301

Epoch: 6| Step: 9
Training loss: 1.553388810347255
Validation loss: 2.641328048534769

Epoch: 6| Step: 10
Training loss: 1.6229030577546475
Validation loss: 2.641296765335892

Epoch: 6| Step: 11
Training loss: 1.8309679666964027
Validation loss: 2.654691845507046

Epoch: 6| Step: 12
Training loss: 1.6748546537280486
Validation loss: 2.6224287246313263

Epoch: 6| Step: 13
Training loss: 2.1954985298806857
Validation loss: 2.6261437439659576

Epoch: 203| Step: 0
Training loss: 1.8947039024099828
Validation loss: 2.6463722314524847

Epoch: 6| Step: 1
Training loss: 1.2141947592001223
Validation loss: 2.679539757517827

Epoch: 6| Step: 2
Training loss: 1.4163280905248492
Validation loss: 2.7147011849970193

Epoch: 6| Step: 3
Training loss: 1.4948993426982984
Validation loss: 2.7167490478301133

Epoch: 6| Step: 4
Training loss: 1.9149559582658235
Validation loss: 2.696602281712202

Epoch: 6| Step: 5
Training loss: 2.029319667596374
Validation loss: 2.622085541363387

Epoch: 6| Step: 6
Training loss: 1.5616336709644931
Validation loss: 2.6000714719775817

Epoch: 6| Step: 7
Training loss: 1.5146139646403451
Validation loss: 2.5632260302242766

Epoch: 6| Step: 8
Training loss: 1.8787203437053357
Validation loss: 2.590588525919353

Epoch: 6| Step: 9
Training loss: 1.3783275048910313
Validation loss: 2.5911964095377025

Epoch: 6| Step: 10
Training loss: 1.4748254478750458
Validation loss: 2.5653276686645614

Epoch: 6| Step: 11
Training loss: 1.438821434017452
Validation loss: 2.622634468365844

Epoch: 6| Step: 12
Training loss: 1.952358797464927
Validation loss: 2.6597500060333954

Epoch: 6| Step: 13
Training loss: 1.6115085570143413
Validation loss: 2.682896895224928

Epoch: 204| Step: 0
Training loss: 1.616270238243663
Validation loss: 2.710324786902581

Epoch: 6| Step: 1
Training loss: 1.697012405030965
Validation loss: 2.753290584867687

Epoch: 6| Step: 2
Training loss: 1.864506796290726
Validation loss: 2.7906240350742064

Epoch: 6| Step: 3
Training loss: 1.6538016018129804
Validation loss: 2.7784509302234475

Epoch: 6| Step: 4
Training loss: 1.4062709382935559
Validation loss: 2.8078100407847724

Epoch: 6| Step: 5
Training loss: 1.9143074968762035
Validation loss: 2.8155423352760134

Epoch: 6| Step: 6
Training loss: 1.9128262011020654
Validation loss: 2.779401633463677

Epoch: 6| Step: 7
Training loss: 1.8921732592499636
Validation loss: 2.7269351271030984

Epoch: 6| Step: 8
Training loss: 1.8990357009882488
Validation loss: 2.63999674508176

Epoch: 6| Step: 9
Training loss: 1.493578996007802
Validation loss: 2.5943182885953178

Epoch: 6| Step: 10
Training loss: 1.4668514886637032
Validation loss: 2.593976250753656

Epoch: 6| Step: 11
Training loss: 1.417645798573901
Validation loss: 2.568334702294842

Epoch: 6| Step: 12
Training loss: 1.4261872849981025
Validation loss: 2.54164341358325

Epoch: 6| Step: 13
Training loss: 1.5462418618755152
Validation loss: 2.557304477695066

Epoch: 205| Step: 0
Training loss: 1.3821019647856858
Validation loss: 2.5555597177156235

Epoch: 6| Step: 1
Training loss: 1.6501791192135118
Validation loss: 2.584923544205483

Epoch: 6| Step: 2
Training loss: 0.9959196050668295
Validation loss: 2.585747654125527

Epoch: 6| Step: 3
Training loss: 2.019753656001795
Validation loss: 2.62123323621436

Epoch: 6| Step: 4
Training loss: 1.404318351740544
Validation loss: 2.657329415769123

Epoch: 6| Step: 5
Training loss: 1.1460949627974528
Validation loss: 2.6701443924051436

Epoch: 6| Step: 6
Training loss: 1.4611795806232868
Validation loss: 2.6668810053280723

Epoch: 6| Step: 7
Training loss: 1.7202591252860375
Validation loss: 2.7131421456371356

Epoch: 6| Step: 8
Training loss: 1.96045450896313
Validation loss: 2.7278407850477286

Epoch: 6| Step: 9
Training loss: 1.5076811738216944
Validation loss: 2.6960883005077942

Epoch: 6| Step: 10
Training loss: 1.9094128244402684
Validation loss: 2.70216965507387

Epoch: 6| Step: 11
Training loss: 1.7327979538687956
Validation loss: 2.680515117135857

Epoch: 6| Step: 12
Training loss: 1.824615827388539
Validation loss: 2.612170332362327

Epoch: 6| Step: 13
Training loss: 1.6517671341016753
Validation loss: 2.6121188415656027

Epoch: 206| Step: 0
Training loss: 1.2751363176513502
Validation loss: 2.5612564090661443

Epoch: 6| Step: 1
Training loss: 1.1933093271202821
Validation loss: 2.5737327283557745

Epoch: 6| Step: 2
Training loss: 1.6337218604258426
Validation loss: 2.5283702216326667

Epoch: 6| Step: 3
Training loss: 1.7053775415220547
Validation loss: 2.5195029412704963

Epoch: 6| Step: 4
Training loss: 1.6456039445908615
Validation loss: 2.5471620672833475

Epoch: 6| Step: 5
Training loss: 1.940092505776268
Validation loss: 2.535680093863005

Epoch: 6| Step: 6
Training loss: 1.6822879976246352
Validation loss: 2.5610362228337684

Epoch: 6| Step: 7
Training loss: 1.789460183799826
Validation loss: 2.5900166954810255

Epoch: 6| Step: 8
Training loss: 1.4011063921228195
Validation loss: 2.6177257862810714

Epoch: 6| Step: 9
Training loss: 1.7211018510611376
Validation loss: 2.6350838971815627

Epoch: 6| Step: 10
Training loss: 1.1640560994836358
Validation loss: 2.634620680700087

Epoch: 6| Step: 11
Training loss: 1.6420349601945443
Validation loss: 2.606915257828561

Epoch: 6| Step: 12
Training loss: 1.3639394925336343
Validation loss: 2.6124860327185804

Epoch: 6| Step: 13
Training loss: 1.5937013057674907
Validation loss: 2.620374720165378

Epoch: 207| Step: 0
Training loss: 1.6709017906846468
Validation loss: 2.599442414081003

Epoch: 6| Step: 1
Training loss: 1.6831780648463004
Validation loss: 2.6342063114390846

Epoch: 6| Step: 2
Training loss: 1.1256368741728207
Validation loss: 2.6218266631008706

Epoch: 6| Step: 3
Training loss: 1.892338063355372
Validation loss: 2.6006644941951356

Epoch: 6| Step: 4
Training loss: 1.2985444870629546
Validation loss: 2.574983882724186

Epoch: 6| Step: 5
Training loss: 1.4642873292176384
Validation loss: 2.6318011535504726

Epoch: 6| Step: 6
Training loss: 1.3916182239271218
Validation loss: 2.59351543616693

Epoch: 6| Step: 7
Training loss: 1.3427873756378876
Validation loss: 2.61391362708047

Epoch: 6| Step: 8
Training loss: 1.3296833544799875
Validation loss: 2.6569277888484937

Epoch: 6| Step: 9
Training loss: 1.9694420945273534
Validation loss: 2.6533488085119195

Epoch: 6| Step: 10
Training loss: 1.3017725103053648
Validation loss: 2.618489671774472

Epoch: 6| Step: 11
Training loss: 1.594586171723408
Validation loss: 2.656217121497454

Epoch: 6| Step: 12
Training loss: 1.3923574221914399
Validation loss: 2.6264377822718576

Epoch: 6| Step: 13
Training loss: 2.017756436676698
Validation loss: 2.642020748676761

Epoch: 208| Step: 0
Training loss: 1.8056325048367936
Validation loss: 2.6229345601672964

Epoch: 6| Step: 1
Training loss: 0.826564253749321
Validation loss: 2.6253981398207373

Epoch: 6| Step: 2
Training loss: 1.280205417109314
Validation loss: 2.6081911726931404

Epoch: 6| Step: 3
Training loss: 1.6975183858423528
Validation loss: 2.59688942146337

Epoch: 6| Step: 4
Training loss: 1.309915768703594
Validation loss: 2.6087077319667458

Epoch: 6| Step: 5
Training loss: 1.268671818847204
Validation loss: 2.6133065254584107

Epoch: 6| Step: 6
Training loss: 1.3504424553354446
Validation loss: 2.5664400043641176

Epoch: 6| Step: 7
Training loss: 1.590627491167737
Validation loss: 2.64455928137219

Epoch: 6| Step: 8
Training loss: 2.1223337612943527
Validation loss: 2.665938100642127

Epoch: 6| Step: 9
Training loss: 1.7444010814547057
Validation loss: 2.7091388126197975

Epoch: 6| Step: 10
Training loss: 1.920592585748505
Validation loss: 2.6962505917717707

Epoch: 6| Step: 11
Training loss: 1.4393958154085094
Validation loss: 2.690607047724095

Epoch: 6| Step: 12
Training loss: 1.1533787621295875
Validation loss: 2.6741277465001527

Epoch: 6| Step: 13
Training loss: 1.5664684254775736
Validation loss: 2.627657217810617

Epoch: 209| Step: 0
Training loss: 1.502932701578768
Validation loss: 2.599657296201554

Epoch: 6| Step: 1
Training loss: 1.751274802599341
Validation loss: 2.596323485327959

Epoch: 6| Step: 2
Training loss: 1.4506338772878078
Validation loss: 2.587440568668349

Epoch: 6| Step: 3
Training loss: 1.116431560723295
Validation loss: 2.5923478613554156

Epoch: 6| Step: 4
Training loss: 1.7489703419015419
Validation loss: 2.603285080533435

Epoch: 6| Step: 5
Training loss: 1.7441533377633698
Validation loss: 2.6234104424148237

Epoch: 6| Step: 6
Training loss: 1.429843581387953
Validation loss: 2.667259964264113

Epoch: 6| Step: 7
Training loss: 1.6539636341603765
Validation loss: 2.680831352686383

Epoch: 6| Step: 8
Training loss: 1.248140764361345
Validation loss: 2.7019173378821395

Epoch: 6| Step: 9
Training loss: 1.3618417042009785
Validation loss: 2.692433818545692

Epoch: 6| Step: 10
Training loss: 1.8052137524112017
Validation loss: 2.706747349520018

Epoch: 6| Step: 11
Training loss: 1.341681951629259
Validation loss: 2.6860960631795936

Epoch: 6| Step: 12
Training loss: 1.3108415570802425
Validation loss: 2.659804365550927

Epoch: 6| Step: 13
Training loss: 1.395362969283501
Validation loss: 2.6351164157513147

Epoch: 210| Step: 0
Training loss: 1.9825524799188354
Validation loss: 2.6388670405714154

Epoch: 6| Step: 1
Training loss: 1.284709771700261
Validation loss: 2.6265824446421417

Epoch: 6| Step: 2
Training loss: 1.221243532723958
Validation loss: 2.6496087532109067

Epoch: 6| Step: 3
Training loss: 1.1345768310233535
Validation loss: 2.64464851136748

Epoch: 6| Step: 4
Training loss: 1.7443788030481107
Validation loss: 2.626254027807122

Epoch: 6| Step: 5
Training loss: 1.6127999906418815
Validation loss: 2.6357642236459164

Epoch: 6| Step: 6
Training loss: 1.491615705134603
Validation loss: 2.6025958118078347

Epoch: 6| Step: 7
Training loss: 1.5237825443087631
Validation loss: 2.6553292741109926

Epoch: 6| Step: 8
Training loss: 1.4989450241604334
Validation loss: 2.6266721564914786

Epoch: 6| Step: 9
Training loss: 1.1782984861340704
Validation loss: 2.6851793091415455

Epoch: 6| Step: 10
Training loss: 1.2956338941578887
Validation loss: 2.6300869457524705

Epoch: 6| Step: 11
Training loss: 1.6460449790881027
Validation loss: 2.6601828995621806

Epoch: 6| Step: 12
Training loss: 1.6558577594897683
Validation loss: 2.6730316753759458

Epoch: 6| Step: 13
Training loss: 1.1994496474261915
Validation loss: 2.656896212665401

Epoch: 211| Step: 0
Training loss: 1.2535782144290648
Validation loss: 2.674349177751306

Epoch: 6| Step: 1
Training loss: 1.4540665560185562
Validation loss: 2.6694055532358005

Epoch: 6| Step: 2
Training loss: 1.1290955698263063
Validation loss: 2.676370146430347

Epoch: 6| Step: 3
Training loss: 2.0079092752014933
Validation loss: 2.6882202698062936

Epoch: 6| Step: 4
Training loss: 1.5724430339544064
Validation loss: 2.6643943379069857

Epoch: 6| Step: 5
Training loss: 1.3100823433308966
Validation loss: 2.693168590011461

Epoch: 6| Step: 6
Training loss: 1.6697543946990956
Validation loss: 2.6644740932016284

Epoch: 6| Step: 7
Training loss: 1.4466178154644596
Validation loss: 2.671243421807019

Epoch: 6| Step: 8
Training loss: 1.2768957536516694
Validation loss: 2.66648504400742

Epoch: 6| Step: 9
Training loss: 1.799524890927838
Validation loss: 2.6386442999045894

Epoch: 6| Step: 10
Training loss: 1.5104689841143497
Validation loss: 2.6428746485450088

Epoch: 6| Step: 11
Training loss: 1.4511065667347212
Validation loss: 2.6581328309053798

Epoch: 6| Step: 12
Training loss: 0.9057857376574441
Validation loss: 2.6136509664006717

Epoch: 6| Step: 13
Training loss: 1.64706957136382
Validation loss: 2.5929634838000535

Epoch: 212| Step: 0
Training loss: 1.6443610386417067
Validation loss: 2.6208384145440315

Epoch: 6| Step: 1
Training loss: 1.0850458669855962
Validation loss: 2.5758862990078994

Epoch: 6| Step: 2
Training loss: 0.9036012944541937
Validation loss: 2.6297793332233623

Epoch: 6| Step: 3
Training loss: 1.6037588550682926
Validation loss: 2.6081168423169667

Epoch: 6| Step: 4
Training loss: 1.6237742863131703
Validation loss: 2.616034203534587

Epoch: 6| Step: 5
Training loss: 1.1057378758096332
Validation loss: 2.6326340623741205

Epoch: 6| Step: 6
Training loss: 1.3797088967000173
Validation loss: 2.6426632407729653

Epoch: 6| Step: 7
Training loss: 1.8458475369265026
Validation loss: 2.6558478391781914

Epoch: 6| Step: 8
Training loss: 1.6187689231444018
Validation loss: 2.6526510025132737

Epoch: 6| Step: 9
Training loss: 1.8362579715314227
Validation loss: 2.6867991528305475

Epoch: 6| Step: 10
Training loss: 1.365303136051728
Validation loss: 2.616443661668919

Epoch: 6| Step: 11
Training loss: 1.7402228666496575
Validation loss: 2.595579059636826

Epoch: 6| Step: 12
Training loss: 1.2395973311630328
Validation loss: 2.561344020048719

Epoch: 6| Step: 13
Training loss: 0.9010356322216908
Validation loss: 2.5809796332228276

Epoch: 213| Step: 0
Training loss: 1.6646819058842204
Validation loss: 2.6187731187627024

Epoch: 6| Step: 1
Training loss: 1.3873819833688519
Validation loss: 2.6119283403479527

Epoch: 6| Step: 2
Training loss: 1.9077770182991232
Validation loss: 2.683733279593199

Epoch: 6| Step: 3
Training loss: 1.2453868618807729
Validation loss: 2.70564884076546

Epoch: 6| Step: 4
Training loss: 1.3485940075483929
Validation loss: 2.7138866848994625

Epoch: 6| Step: 5
Training loss: 1.5323204658476444
Validation loss: 2.7394926178656624

Epoch: 6| Step: 6
Training loss: 1.4066007388666915
Validation loss: 2.8133779215179513

Epoch: 6| Step: 7
Training loss: 1.5458623480665805
Validation loss: 2.8007004663374824

Epoch: 6| Step: 8
Training loss: 1.8073798899229245
Validation loss: 2.7347452905027296

Epoch: 6| Step: 9
Training loss: 1.2923480615646543
Validation loss: 2.689549352748734

Epoch: 6| Step: 10
Training loss: 1.5143849127016418
Validation loss: 2.6587418268363145

Epoch: 6| Step: 11
Training loss: 1.0492553409152359
Validation loss: 2.6172502799441

Epoch: 6| Step: 12
Training loss: 1.1908038007590338
Validation loss: 2.5665819464409045

Epoch: 6| Step: 13
Training loss: 1.045670228881735
Validation loss: 2.589726718514098

Epoch: 214| Step: 0
Training loss: 1.232398224859126
Validation loss: 2.6028063933190673

Epoch: 6| Step: 1
Training loss: 1.8920461814518645
Validation loss: 2.618191277546801

Epoch: 6| Step: 2
Training loss: 1.1939185497867015
Validation loss: 2.6125384298533127

Epoch: 6| Step: 3
Training loss: 1.4057088446470287
Validation loss: 2.592325581742047

Epoch: 6| Step: 4
Training loss: 0.8382271044363546
Validation loss: 2.5893578662010257

Epoch: 6| Step: 5
Training loss: 1.2849428411306238
Validation loss: 2.6242812012926717

Epoch: 6| Step: 6
Training loss: 1.274972423554439
Validation loss: 2.644333355530923

Epoch: 6| Step: 7
Training loss: 1.670764732696589
Validation loss: 2.631575044236152

Epoch: 6| Step: 8
Training loss: 1.561869532227152
Validation loss: 2.6785030099985776

Epoch: 6| Step: 9
Training loss: 1.14544089561713
Validation loss: 2.676154254627312

Epoch: 6| Step: 10
Training loss: 1.531225866010785
Validation loss: 2.70296726149488

Epoch: 6| Step: 11
Training loss: 1.833659475389526
Validation loss: 2.666350115809978

Epoch: 6| Step: 12
Training loss: 1.7404011005377966
Validation loss: 2.659464466827542

Epoch: 6| Step: 13
Training loss: 0.8564343511560699
Validation loss: 2.6581926247894314

Epoch: 215| Step: 0
Training loss: 1.6383622323660172
Validation loss: 2.6327946252326555

Epoch: 6| Step: 1
Training loss: 1.8107059413000708
Validation loss: 2.6632091173148558

Epoch: 6| Step: 2
Training loss: 1.5360301396323606
Validation loss: 2.6514622816598132

Epoch: 6| Step: 3
Training loss: 1.4857497424568826
Validation loss: 2.646714023645711

Epoch: 6| Step: 4
Training loss: 1.0313157725311433
Validation loss: 2.596168405686994

Epoch: 6| Step: 5
Training loss: 0.7775998101151788
Validation loss: 2.681531421140794

Epoch: 6| Step: 6
Training loss: 1.5523830184231828
Validation loss: 2.6411425927941345

Epoch: 6| Step: 7
Training loss: 1.7423225658388852
Validation loss: 2.6740930524983737

Epoch: 6| Step: 8
Training loss: 1.1915304150527286
Validation loss: 2.6278436447709415

Epoch: 6| Step: 9
Training loss: 1.3025261799822623
Validation loss: 2.6595565203940597

Epoch: 6| Step: 10
Training loss: 1.4736682440136608
Validation loss: 2.664628025109784

Epoch: 6| Step: 11
Training loss: 1.728083290300364
Validation loss: 2.650620610305056

Epoch: 6| Step: 12
Training loss: 1.2999703110459215
Validation loss: 2.657547124320737

Epoch: 6| Step: 13
Training loss: 0.4446370205137757
Validation loss: 2.6490537068323263

Epoch: 216| Step: 0
Training loss: 1.364611089098972
Validation loss: 2.6318571608506485

Epoch: 6| Step: 1
Training loss: 1.310930312526855
Validation loss: 2.638082906942269

Epoch: 6| Step: 2
Training loss: 1.359491672112961
Validation loss: 2.6907793095289483

Epoch: 6| Step: 3
Training loss: 1.1275060080898942
Validation loss: 2.6942092661219768

Epoch: 6| Step: 4
Training loss: 1.5032478774001987
Validation loss: 2.695755028952468

Epoch: 6| Step: 5
Training loss: 1.5544082160716863
Validation loss: 2.6613033032714446

Epoch: 6| Step: 6
Training loss: 0.9253543561636971
Validation loss: 2.6584035975287827

Epoch: 6| Step: 7
Training loss: 1.4632859555325102
Validation loss: 2.6754592384381133

Epoch: 6| Step: 8
Training loss: 1.3823318076994968
Validation loss: 2.6870834998929927

Epoch: 6| Step: 9
Training loss: 1.6373185035352904
Validation loss: 2.67937381902777

Epoch: 6| Step: 10
Training loss: 1.5018370822877625
Validation loss: 2.6592330117148926

Epoch: 6| Step: 11
Training loss: 1.7238163577468442
Validation loss: 2.6505247489266375

Epoch: 6| Step: 12
Training loss: 1.5148898042442875
Validation loss: 2.6188875473598445

Epoch: 6| Step: 13
Training loss: 1.1188261911884134
Validation loss: 2.643780874305108

Epoch: 217| Step: 0
Training loss: 1.7836853244447026
Validation loss: 2.6702892628225614

Epoch: 6| Step: 1
Training loss: 1.4468924469853697
Validation loss: 2.6989586986252854

Epoch: 6| Step: 2
Training loss: 1.201579798461052
Validation loss: 2.7192971755423887

Epoch: 6| Step: 3
Training loss: 1.6708720398539423
Validation loss: 2.7102259605572754

Epoch: 6| Step: 4
Training loss: 1.4477863481820443
Validation loss: 2.7627256089441254

Epoch: 6| Step: 5
Training loss: 1.5044339926056243
Validation loss: 2.7787274715992454

Epoch: 6| Step: 6
Training loss: 1.5029896506678442
Validation loss: 2.812520113454929

Epoch: 6| Step: 7
Training loss: 1.4744388709114276
Validation loss: 2.7851639027408335

Epoch: 6| Step: 8
Training loss: 1.4702746817157037
Validation loss: 2.8394287436248518

Epoch: 6| Step: 9
Training loss: 1.1096574665496817
Validation loss: 2.8593941848212596

Epoch: 6| Step: 10
Training loss: 1.3709432839975282
Validation loss: 2.8014638166884023

Epoch: 6| Step: 11
Training loss: 1.4290746824211153
Validation loss: 2.7486720547228627

Epoch: 6| Step: 12
Training loss: 1.127118870332991
Validation loss: 2.722545930446418

Epoch: 6| Step: 13
Training loss: 1.3038072643340397
Validation loss: 2.6566256079620625

Epoch: 218| Step: 0
Training loss: 1.6185302320077983
Validation loss: 2.5998040492632213

Epoch: 6| Step: 1
Training loss: 1.1997302825127814
Validation loss: 2.6242800729815863

Epoch: 6| Step: 2
Training loss: 1.5240244981643993
Validation loss: 2.5936870169476594

Epoch: 6| Step: 3
Training loss: 1.9096732747904743
Validation loss: 2.6138113516612704

Epoch: 6| Step: 4
Training loss: 1.5038971343321543
Validation loss: 2.6196303051975

Epoch: 6| Step: 5
Training loss: 1.4920666231258137
Validation loss: 2.636035172646967

Epoch: 6| Step: 6
Training loss: 1.35332704581756
Validation loss: 2.6555394901143163

Epoch: 6| Step: 7
Training loss: 1.331153916307715
Validation loss: 2.6989319783757613

Epoch: 6| Step: 8
Training loss: 1.3617977169774618
Validation loss: 2.681664692118757

Epoch: 6| Step: 9
Training loss: 1.180501088899258
Validation loss: 2.686860813863607

Epoch: 6| Step: 10
Training loss: 1.0020049975912066
Validation loss: 2.738563208861414

Epoch: 6| Step: 11
Training loss: 1.5335961099413118
Validation loss: 2.74864612786907

Epoch: 6| Step: 12
Training loss: 1.474666366991584
Validation loss: 2.7462002968929786

Epoch: 6| Step: 13
Training loss: 1.2506927954557991
Validation loss: 2.746324895090792

Epoch: 219| Step: 0
Training loss: 1.308326170024983
Validation loss: 2.720592676305137

Epoch: 6| Step: 1
Training loss: 1.1501765675376787
Validation loss: 2.7555260757192976

Epoch: 6| Step: 2
Training loss: 0.8459170733812161
Validation loss: 2.703765453742208

Epoch: 6| Step: 3
Training loss: 1.5026445124436376
Validation loss: 2.709374895008417

Epoch: 6| Step: 4
Training loss: 1.8216804308893357
Validation loss: 2.6633916918549936

Epoch: 6| Step: 5
Training loss: 1.2732648205841144
Validation loss: 2.6610050576792994

Epoch: 6| Step: 6
Training loss: 1.1838615290822208
Validation loss: 2.6359415225183764

Epoch: 6| Step: 7
Training loss: 1.139452606085972
Validation loss: 2.648346591349585

Epoch: 6| Step: 8
Training loss: 1.3743340873787127
Validation loss: 2.6521754922712213

Epoch: 6| Step: 9
Training loss: 1.4921331745264768
Validation loss: 2.6276022229944145

Epoch: 6| Step: 10
Training loss: 1.6473016667555995
Validation loss: 2.6323802280687594

Epoch: 6| Step: 11
Training loss: 1.6465417166393899
Validation loss: 2.6807725060448546

Epoch: 6| Step: 12
Training loss: 1.3919094882729666
Validation loss: 2.6628471780187146

Epoch: 6| Step: 13
Training loss: 1.6956338182410564
Validation loss: 2.640023616593158

Epoch: 220| Step: 0
Training loss: 1.708109081095031
Validation loss: 2.662671116131973

Epoch: 6| Step: 1
Training loss: 1.3410312294989688
Validation loss: 2.6639689257440713

Epoch: 6| Step: 2
Training loss: 1.0831005445428086
Validation loss: 2.653927872231499

Epoch: 6| Step: 3
Training loss: 1.0088914521981145
Validation loss: 2.6792946565235227

Epoch: 6| Step: 4
Training loss: 1.4615071048152783
Validation loss: 2.6782351986368376

Epoch: 6| Step: 5
Training loss: 1.3479190735989541
Validation loss: 2.6680579215851132

Epoch: 6| Step: 6
Training loss: 1.2214546026755968
Validation loss: 2.700140796751842

Epoch: 6| Step: 7
Training loss: 1.3072896351994794
Validation loss: 2.6882307752735635

Epoch: 6| Step: 8
Training loss: 1.4776234523880294
Validation loss: 2.685352543486671

Epoch: 6| Step: 9
Training loss: 1.2669482436835577
Validation loss: 2.675430974091501

Epoch: 6| Step: 10
Training loss: 1.5022250996997244
Validation loss: 2.6714598457842604

Epoch: 6| Step: 11
Training loss: 1.7298482983839227
Validation loss: 2.7149567006976913

Epoch: 6| Step: 12
Training loss: 1.0450522653386427
Validation loss: 2.718432947214293

Epoch: 6| Step: 13
Training loss: 1.3529662411348533
Validation loss: 2.705458533430229

Epoch: 221| Step: 0
Training loss: 1.445926927437599
Validation loss: 2.6862323019482783

Epoch: 6| Step: 1
Training loss: 1.6985753035945157
Validation loss: 2.6726789029706466

Epoch: 6| Step: 2
Training loss: 1.1983804164456489
Validation loss: 2.7107791417603275

Epoch: 6| Step: 3
Training loss: 1.142682766809474
Validation loss: 2.692818087682745

Epoch: 6| Step: 4
Training loss: 1.3062879602492565
Validation loss: 2.728998472254839

Epoch: 6| Step: 5
Training loss: 1.440897037531174
Validation loss: 2.678877645315368

Epoch: 6| Step: 6
Training loss: 1.1641836423371217
Validation loss: 2.6720944669299196

Epoch: 6| Step: 7
Training loss: 1.0704207539631958
Validation loss: 2.6596964213321317

Epoch: 6| Step: 8
Training loss: 1.1208990373225982
Validation loss: 2.678951477458118

Epoch: 6| Step: 9
Training loss: 1.2145494797679617
Validation loss: 2.652432930754777

Epoch: 6| Step: 10
Training loss: 0.9199574457568562
Validation loss: 2.6219459156941087

Epoch: 6| Step: 11
Training loss: 1.8129844018230443
Validation loss: 2.6389136980492074

Epoch: 6| Step: 12
Training loss: 1.7346981537961974
Validation loss: 2.6078600278876944

Epoch: 6| Step: 13
Training loss: 1.4677917113851215
Validation loss: 2.6460563508187023

Epoch: 222| Step: 0
Training loss: 1.0522929948944266
Validation loss: 2.6374787150969836

Epoch: 6| Step: 1
Training loss: 1.5011936842291804
Validation loss: 2.658675761745426

Epoch: 6| Step: 2
Training loss: 1.6174879301820673
Validation loss: 2.626663350975143

Epoch: 6| Step: 3
Training loss: 1.442849282036914
Validation loss: 2.641962592082412

Epoch: 6| Step: 4
Training loss: 1.1313233156841573
Validation loss: 2.6462937170007477

Epoch: 6| Step: 5
Training loss: 1.0057991083849287
Validation loss: 2.6555603521864968

Epoch: 6| Step: 6
Training loss: 0.9748544327568939
Validation loss: 2.6409600420251826

Epoch: 6| Step: 7
Training loss: 1.4058334581382228
Validation loss: 2.6703303934400457

Epoch: 6| Step: 8
Training loss: 1.474841532842451
Validation loss: 2.6890914242079487

Epoch: 6| Step: 9
Training loss: 1.5745272275012656
Validation loss: 2.6922021392713162

Epoch: 6| Step: 10
Training loss: 1.3982111571857576
Validation loss: 2.693255000180989

Epoch: 6| Step: 11
Training loss: 1.316208051935065
Validation loss: 2.6105635806468666

Epoch: 6| Step: 12
Training loss: 1.4153973933268271
Validation loss: 2.5931570050058785

Epoch: 6| Step: 13
Training loss: 1.7446105938987853
Validation loss: 2.5986890167294416

Epoch: 223| Step: 0
Training loss: 1.4188215565386317
Validation loss: 2.613484790694693

Epoch: 6| Step: 1
Training loss: 1.566150596855826
Validation loss: 2.634764141166663

Epoch: 6| Step: 2
Training loss: 1.0000347489041608
Validation loss: 2.622090912410664

Epoch: 6| Step: 3
Training loss: 1.4573433467634986
Validation loss: 2.651549887097368

Epoch: 6| Step: 4
Training loss: 1.142014271428177
Validation loss: 2.6323329094003705

Epoch: 6| Step: 5
Training loss: 1.5282126684335977
Validation loss: 2.655441260954232

Epoch: 6| Step: 6
Training loss: 1.6763562903105051
Validation loss: 2.665536614775108

Epoch: 6| Step: 7
Training loss: 1.371418189111647
Validation loss: 2.6607679401906967

Epoch: 6| Step: 8
Training loss: 1.499668005124832
Validation loss: 2.672132457473106

Epoch: 6| Step: 9
Training loss: 1.1739107886736557
Validation loss: 2.6260549639394277

Epoch: 6| Step: 10
Training loss: 1.2376700737191657
Validation loss: 2.6085825288960813

Epoch: 6| Step: 11
Training loss: 0.9060529626203706
Validation loss: 2.6278642106432173

Epoch: 6| Step: 12
Training loss: 1.0428645621276578
Validation loss: 2.662235186526371

Epoch: 6| Step: 13
Training loss: 1.561543820589879
Validation loss: 2.6581916367307428

Epoch: 224| Step: 0
Training loss: 1.5560396534885477
Validation loss: 2.662038174791902

Epoch: 6| Step: 1
Training loss: 1.0536876318814006
Validation loss: 2.6625128729978593

Epoch: 6| Step: 2
Training loss: 1.6005281411163539
Validation loss: 2.684472088929445

Epoch: 6| Step: 3
Training loss: 1.6606122994933272
Validation loss: 2.6882502545289837

Epoch: 6| Step: 4
Training loss: 0.7755291716513996
Validation loss: 2.6367764952856376

Epoch: 6| Step: 5
Training loss: 1.4644988200663838
Validation loss: 2.6848618822612895

Epoch: 6| Step: 6
Training loss: 0.8471683557163201
Validation loss: 2.715390081256253

Epoch: 6| Step: 7
Training loss: 1.5159747319946546
Validation loss: 2.694709762513988

Epoch: 6| Step: 8
Training loss: 1.473296737015009
Validation loss: 2.6861767345440293

Epoch: 6| Step: 9
Training loss: 0.6404996609772523
Validation loss: 2.6826170498865296

Epoch: 6| Step: 10
Training loss: 0.6597795032150524
Validation loss: 2.7110253320082975

Epoch: 6| Step: 11
Training loss: 1.2614726957495284
Validation loss: 2.7162957519621256

Epoch: 6| Step: 12
Training loss: 1.7417973650332554
Validation loss: 2.685893752799433

Epoch: 6| Step: 13
Training loss: 1.2802009940292678
Validation loss: 2.666868863272046

Epoch: 225| Step: 0
Training loss: 1.390691262713132
Validation loss: 2.6503762939040523

Epoch: 6| Step: 1
Training loss: 1.2054397806974848
Validation loss: 2.630592058120259

Epoch: 6| Step: 2
Training loss: 1.2591928052093206
Validation loss: 2.632624727577822

Epoch: 6| Step: 3
Training loss: 1.2741732198040645
Validation loss: 2.6262807031595883

Epoch: 6| Step: 4
Training loss: 1.7292159046684992
Validation loss: 2.5906519855732673

Epoch: 6| Step: 5
Training loss: 0.9340790002258226
Validation loss: 2.6131694631286377

Epoch: 6| Step: 6
Training loss: 1.2505376613151455
Validation loss: 2.616759505805513

Epoch: 6| Step: 7
Training loss: 1.1614543703750035
Validation loss: 2.6027550344347232

Epoch: 6| Step: 8
Training loss: 1.1623444647978463
Validation loss: 2.633373060727664

Epoch: 6| Step: 9
Training loss: 1.441895771381324
Validation loss: 2.611375328510647

Epoch: 6| Step: 10
Training loss: 1.0134527009899672
Validation loss: 2.6068523106137937

Epoch: 6| Step: 11
Training loss: 1.5913317416188069
Validation loss: 2.6509422223799843

Epoch: 6| Step: 12
Training loss: 1.2461449304671113
Validation loss: 2.642586010193554

Epoch: 6| Step: 13
Training loss: 1.062137261347635
Validation loss: 2.619209438343537

Epoch: 226| Step: 0
Training loss: 1.120446420323904
Validation loss: 2.6593111364301056

Epoch: 6| Step: 1
Training loss: 1.0644657239255826
Validation loss: 2.6589218513013373

Epoch: 6| Step: 2
Training loss: 1.0700073921090876
Validation loss: 2.657764198186626

Epoch: 6| Step: 3
Training loss: 1.3783085638093933
Validation loss: 2.676646032216932

Epoch: 6| Step: 4
Training loss: 1.3778819313127608
Validation loss: 2.6556448085981197

Epoch: 6| Step: 5
Training loss: 1.696829473120089
Validation loss: 2.5843545854685743

Epoch: 6| Step: 6
Training loss: 1.3807148945503789
Validation loss: 2.606527927755784

Epoch: 6| Step: 7
Training loss: 1.0074470507998945
Validation loss: 2.6064784086849273

Epoch: 6| Step: 8
Training loss: 1.3596448959237388
Validation loss: 2.58833260215083

Epoch: 6| Step: 9
Training loss: 1.1178593249454207
Validation loss: 2.6081079888982774

Epoch: 6| Step: 10
Training loss: 1.4258075868447255
Validation loss: 2.6115407628053364

Epoch: 6| Step: 11
Training loss: 1.004047369037101
Validation loss: 2.6172858293061227

Epoch: 6| Step: 12
Training loss: 1.6810537060583721
Validation loss: 2.640845865060118

Epoch: 6| Step: 13
Training loss: 1.1636423978628765
Validation loss: 2.6772933173913267

Epoch: 227| Step: 0
Training loss: 1.3967479537094036
Validation loss: 2.695325772284142

Epoch: 6| Step: 1
Training loss: 0.9610913161319979
Validation loss: 2.7091528896463544

Epoch: 6| Step: 2
Training loss: 1.2826985799965804
Validation loss: 2.702128526186654

Epoch: 6| Step: 3
Training loss: 1.1780708300534666
Validation loss: 2.6974810132413167

Epoch: 6| Step: 4
Training loss: 0.7968849480699898
Validation loss: 2.695006942609188

Epoch: 6| Step: 5
Training loss: 1.5530395207973844
Validation loss: 2.631942237611154

Epoch: 6| Step: 6
Training loss: 1.5660800356332474
Validation loss: 2.6194125134965627

Epoch: 6| Step: 7
Training loss: 1.091682387134453
Validation loss: 2.6400336360466645

Epoch: 6| Step: 8
Training loss: 1.037743670792326
Validation loss: 2.634595789253835

Epoch: 6| Step: 9
Training loss: 1.7309504886820994
Validation loss: 2.6274011971108333

Epoch: 6| Step: 10
Training loss: 1.3108721129122904
Validation loss: 2.6277411529939894

Epoch: 6| Step: 11
Training loss: 1.3022027482269913
Validation loss: 2.6168484983276366

Epoch: 6| Step: 12
Training loss: 1.021506781542016
Validation loss: 2.6120236842162052

Epoch: 6| Step: 13
Training loss: 1.5426696487442995
Validation loss: 2.616889344253005

Epoch: 228| Step: 0
Training loss: 1.2610567795163887
Validation loss: 2.6487163252094437

Epoch: 6| Step: 1
Training loss: 0.555959693289876
Validation loss: 2.6867439244341282

Epoch: 6| Step: 2
Training loss: 1.1523481983163613
Validation loss: 2.698008091788155

Epoch: 6| Step: 3
Training loss: 1.6271921923272843
Validation loss: 2.7148169646554092

Epoch: 6| Step: 4
Training loss: 1.4668289770278302
Validation loss: 2.7158211979394795

Epoch: 6| Step: 5
Training loss: 0.8319304140981503
Validation loss: 2.6696917336738957

Epoch: 6| Step: 6
Training loss: 1.1114021370483305
Validation loss: 2.63075675562932

Epoch: 6| Step: 7
Training loss: 1.4424371935098106
Validation loss: 2.6408416674690867

Epoch: 6| Step: 8
Training loss: 1.5277680493054688
Validation loss: 2.6280592555164928

Epoch: 6| Step: 9
Training loss: 1.5281586875400732
Validation loss: 2.6540191963196373

Epoch: 6| Step: 10
Training loss: 1.0781314130951698
Validation loss: 2.7008404741889134

Epoch: 6| Step: 11
Training loss: 1.472950225548494
Validation loss: 2.701074408896477

Epoch: 6| Step: 12
Training loss: 1.2252951714035354
Validation loss: 2.7299475461931553

Epoch: 6| Step: 13
Training loss: 1.3264429099159512
Validation loss: 2.6973266532878535

Epoch: 229| Step: 0
Training loss: 1.168590622505117
Validation loss: 2.7003903786982426

Epoch: 6| Step: 1
Training loss: 1.6227354262700606
Validation loss: 2.730423170656384

Epoch: 6| Step: 2
Training loss: 1.2793944809347797
Validation loss: 2.738368306077981

Epoch: 6| Step: 3
Training loss: 1.2606708911264837
Validation loss: 2.782894326396734

Epoch: 6| Step: 4
Training loss: 1.335380393421851
Validation loss: 2.7595560680701032

Epoch: 6| Step: 5
Training loss: 1.1981213049316737
Validation loss: 2.7324382996079613

Epoch: 6| Step: 6
Training loss: 1.2453787255955577
Validation loss: 2.7517519224581353

Epoch: 6| Step: 7
Training loss: 1.3044627561417572
Validation loss: 2.716063811640049

Epoch: 6| Step: 8
Training loss: 1.2876770897710972
Validation loss: 2.695801324732473

Epoch: 6| Step: 9
Training loss: 1.1738241135311291
Validation loss: 2.7019347895225976

Epoch: 6| Step: 10
Training loss: 0.9952197859623324
Validation loss: 2.6658777385712895

Epoch: 6| Step: 11
Training loss: 1.5074354105408678
Validation loss: 2.592720225638834

Epoch: 6| Step: 12
Training loss: 0.983706837910546
Validation loss: 2.572331287248184

Epoch: 6| Step: 13
Training loss: 1.1070916223317389
Validation loss: 2.5730189458824344

Epoch: 230| Step: 0
Training loss: 1.2509243408547812
Validation loss: 2.5585858313988954

Epoch: 6| Step: 1
Training loss: 1.3268979855890037
Validation loss: 2.614633023774807

Epoch: 6| Step: 2
Training loss: 1.4326877485605467
Validation loss: 2.5769928565339546

Epoch: 6| Step: 3
Training loss: 0.6726258761718011
Validation loss: 2.6276069563940254

Epoch: 6| Step: 4
Training loss: 0.9155734363397251
Validation loss: 2.667267254827768

Epoch: 6| Step: 5
Training loss: 1.0026429536260926
Validation loss: 2.6839090516031474

Epoch: 6| Step: 6
Training loss: 1.2710656855227633
Validation loss: 2.6881731325014018

Epoch: 6| Step: 7
Training loss: 1.416818367558669
Validation loss: 2.7063303170511555

Epoch: 6| Step: 8
Training loss: 1.5702305103362437
Validation loss: 2.7015106067320835

Epoch: 6| Step: 9
Training loss: 1.1601742829741981
Validation loss: 2.682277828427364

Epoch: 6| Step: 10
Training loss: 1.438640390922172
Validation loss: 2.6568360214868485

Epoch: 6| Step: 11
Training loss: 1.3124690733399458
Validation loss: 2.628297839818695

Epoch: 6| Step: 12
Training loss: 1.578911764596768
Validation loss: 2.662164651258041

Epoch: 6| Step: 13
Training loss: 1.2921624103956428
Validation loss: 2.663654120350949

Epoch: 231| Step: 0
Training loss: 1.267641979895635
Validation loss: 2.6446276746958746

Epoch: 6| Step: 1
Training loss: 0.7570689771638576
Validation loss: 2.6265204031180835

Epoch: 6| Step: 2
Training loss: 1.1956570197372849
Validation loss: 2.6265137014838458

Epoch: 6| Step: 3
Training loss: 1.4044010298811815
Validation loss: 2.6391939403189926

Epoch: 6| Step: 4
Training loss: 1.1339363048534343
Validation loss: 2.614298265957409

Epoch: 6| Step: 5
Training loss: 1.225709849624914
Validation loss: 2.604644342400039

Epoch: 6| Step: 6
Training loss: 1.6818253507625367
Validation loss: 2.6353913791183725

Epoch: 6| Step: 7
Training loss: 1.4647008393829644
Validation loss: 2.650978995841827

Epoch: 6| Step: 8
Training loss: 1.1039385769937122
Validation loss: 2.6347996721777305

Epoch: 6| Step: 9
Training loss: 0.6266032873942896
Validation loss: 2.648389840962405

Epoch: 6| Step: 10
Training loss: 1.1339913384108453
Validation loss: 2.6472720397066656

Epoch: 6| Step: 11
Training loss: 1.342490515293594
Validation loss: 2.6521202127435264

Epoch: 6| Step: 12
Training loss: 1.4757620443181874
Validation loss: 2.6482165759280374

Epoch: 6| Step: 13
Training loss: 0.8744077721889909
Validation loss: 2.6277959302737615

Epoch: 232| Step: 0
Training loss: 0.8263983810549275
Validation loss: 2.650864643072779

Epoch: 6| Step: 1
Training loss: 1.3987460515270804
Validation loss: 2.6524263378433353

Epoch: 6| Step: 2
Training loss: 0.9363860824147088
Validation loss: 2.6714046668544738

Epoch: 6| Step: 3
Training loss: 1.3470232817769594
Validation loss: 2.667396704729146

Epoch: 6| Step: 4
Training loss: 1.407339818183876
Validation loss: 2.6519152833333504

Epoch: 6| Step: 5
Training loss: 1.2870181431947554
Validation loss: 2.6396578994509827

Epoch: 6| Step: 6
Training loss: 1.5874225447374657
Validation loss: 2.6576335992735487

Epoch: 6| Step: 7
Training loss: 1.0144540345338806
Validation loss: 2.704277901866285

Epoch: 6| Step: 8
Training loss: 1.2303399881475594
Validation loss: 2.6684034518255895

Epoch: 6| Step: 9
Training loss: 1.463486513159735
Validation loss: 2.6796843008137508

Epoch: 6| Step: 10
Training loss: 0.8922600377619913
Validation loss: 2.6856658430699283

Epoch: 6| Step: 11
Training loss: 1.0206889744627017
Validation loss: 2.6840760020007077

Epoch: 6| Step: 12
Training loss: 1.2460321393223055
Validation loss: 2.6880124350715264

Epoch: 6| Step: 13
Training loss: 1.2386348953429263
Validation loss: 2.6976498682417085

Epoch: 233| Step: 0
Training loss: 1.338571684187818
Validation loss: 2.690857555863058

Epoch: 6| Step: 1
Training loss: 1.2869753963220198
Validation loss: 2.697156831357383

Epoch: 6| Step: 2
Training loss: 1.1762435865886134
Validation loss: 2.668421327285114

Epoch: 6| Step: 3
Training loss: 1.0121871865328862
Validation loss: 2.6665371900576353

Epoch: 6| Step: 4
Training loss: 1.1396790331187894
Validation loss: 2.630299814623941

Epoch: 6| Step: 5
Training loss: 1.138796765134536
Validation loss: 2.5909097586331273

Epoch: 6| Step: 6
Training loss: 1.1758144538728117
Validation loss: 2.608548273186811

Epoch: 6| Step: 7
Training loss: 0.9281181103999733
Validation loss: 2.679007088507146

Epoch: 6| Step: 8
Training loss: 1.0818387628102777
Validation loss: 2.5944415921256923

Epoch: 6| Step: 9
Training loss: 1.2710727195195737
Validation loss: 2.648402049346787

Epoch: 6| Step: 10
Training loss: 1.3140513017066136
Validation loss: 2.604752592723509

Epoch: 6| Step: 11
Training loss: 1.1235470396074083
Validation loss: 2.640054365260508

Epoch: 6| Step: 12
Training loss: 1.1804954338971008
Validation loss: 2.642971640011196

Epoch: 6| Step: 13
Training loss: 1.8433421055525823
Validation loss: 2.642886091843358

Epoch: 234| Step: 0
Training loss: 1.3867067148465417
Validation loss: 2.701444516163364

Epoch: 6| Step: 1
Training loss: 0.7785577543490236
Validation loss: 2.7140711088220706

Epoch: 6| Step: 2
Training loss: 1.3163494244996943
Validation loss: 2.676818425324524

Epoch: 6| Step: 3
Training loss: 1.271370972060365
Validation loss: 2.6828462678266263

Epoch: 6| Step: 4
Training loss: 1.121981385693693
Validation loss: 2.6436101558356446

Epoch: 6| Step: 5
Training loss: 1.3509406274304445
Validation loss: 2.5985827049487233

Epoch: 6| Step: 6
Training loss: 1.0022808527966054
Validation loss: 2.5883073185477574

Epoch: 6| Step: 7
Training loss: 1.2408791615614359
Validation loss: 2.5590617786573286

Epoch: 6| Step: 8
Training loss: 1.2750206216378646
Validation loss: 2.5575297275149453

Epoch: 6| Step: 9
Training loss: 0.955787379737993
Validation loss: 2.5240491001897043

Epoch: 6| Step: 10
Training loss: 1.3185963961559675
Validation loss: 2.557106202982445

Epoch: 6| Step: 11
Training loss: 1.125311278618232
Validation loss: 2.5543916617592015

Epoch: 6| Step: 12
Training loss: 1.4478136021366779
Validation loss: 2.558349274057927

Epoch: 6| Step: 13
Training loss: 0.9591449673007412
Validation loss: 2.5948661856697512

Epoch: 235| Step: 0
Training loss: 1.2714528257144553
Validation loss: 2.6000085572605967

Epoch: 6| Step: 1
Training loss: 1.0403351984501328
Validation loss: 2.6079735286381336

Epoch: 6| Step: 2
Training loss: 1.139661931053633
Validation loss: 2.645699162787893

Epoch: 6| Step: 3
Training loss: 1.2356009853501124
Validation loss: 2.6456232398500004

Epoch: 6| Step: 4
Training loss: 0.9895871547156719
Validation loss: 2.6552716609973315

Epoch: 6| Step: 5
Training loss: 0.873888126746695
Validation loss: 2.6492601649337595

Epoch: 6| Step: 6
Training loss: 1.1617919488355695
Validation loss: 2.602627638988111

Epoch: 6| Step: 7
Training loss: 1.7450044720436657
Validation loss: 2.6217778730077548

Epoch: 6| Step: 8
Training loss: 1.3016279975741567
Validation loss: 2.642150994756818

Epoch: 6| Step: 9
Training loss: 0.7732911019536874
Validation loss: 2.666428731934827

Epoch: 6| Step: 10
Training loss: 1.0967974034872003
Validation loss: 2.6762865892796923

Epoch: 6| Step: 11
Training loss: 1.315034054942521
Validation loss: 2.672541041853769

Epoch: 6| Step: 12
Training loss: 1.319540305865998
Validation loss: 2.695434078680463

Epoch: 6| Step: 13
Training loss: 1.2940705091260374
Validation loss: 2.7268462027175664

Epoch: 236| Step: 0
Training loss: 0.8920216568233715
Validation loss: 2.7217920860756735

Epoch: 6| Step: 1
Training loss: 1.3661885563051277
Validation loss: 2.726283729011578

Epoch: 6| Step: 2
Training loss: 0.983118739123334
Validation loss: 2.737321700933422

Epoch: 6| Step: 3
Training loss: 0.9636768899144632
Validation loss: 2.7132447396992414

Epoch: 6| Step: 4
Training loss: 0.9467293391223403
Validation loss: 2.7322842350441183

Epoch: 6| Step: 5
Training loss: 1.3512876374457696
Validation loss: 2.7285343731827205

Epoch: 6| Step: 6
Training loss: 1.501424113395723
Validation loss: 2.7385172390648247

Epoch: 6| Step: 7
Training loss: 1.3278158389018313
Validation loss: 2.733368540996557

Epoch: 6| Step: 8
Training loss: 1.1199710554401858
Validation loss: 2.697232212354146

Epoch: 6| Step: 9
Training loss: 1.0997882379091932
Validation loss: 2.693241812880004

Epoch: 6| Step: 10
Training loss: 1.3454267996017277
Validation loss: 2.688027488718584

Epoch: 6| Step: 11
Training loss: 1.1129453989021654
Validation loss: 2.7042805581456295

Epoch: 6| Step: 12
Training loss: 0.9811317664185385
Validation loss: 2.684140076110069

Epoch: 6| Step: 13
Training loss: 1.2184675329498296
Validation loss: 2.7138897001824542

Epoch: 237| Step: 0
Training loss: 1.2057711248601741
Validation loss: 2.7363421342922125

Epoch: 6| Step: 1
Training loss: 1.4976574566935263
Validation loss: 2.7124620121465393

Epoch: 6| Step: 2
Training loss: 1.4056189922714926
Validation loss: 2.6357355657266517

Epoch: 6| Step: 3
Training loss: 1.1933040325112323
Validation loss: 2.6421172455880213

Epoch: 6| Step: 4
Training loss: 0.9972428220240501
Validation loss: 2.589900179608758

Epoch: 6| Step: 5
Training loss: 0.9682715680443335
Validation loss: 2.5645848638634057

Epoch: 6| Step: 6
Training loss: 1.1649142739676874
Validation loss: 2.576535933608524

Epoch: 6| Step: 7
Training loss: 1.242191962468031
Validation loss: 2.5875964587007245

Epoch: 6| Step: 8
Training loss: 1.49910391426891
Validation loss: 2.619890916230696

Epoch: 6| Step: 9
Training loss: 1.0709088745387807
Validation loss: 2.624865308236854

Epoch: 6| Step: 10
Training loss: 1.2967972329963848
Validation loss: 2.656295371588

Epoch: 6| Step: 11
Training loss: 1.003020196116127
Validation loss: 2.6304611417577877

Epoch: 6| Step: 12
Training loss: 0.5369917584733394
Validation loss: 2.638725211423734

Epoch: 6| Step: 13
Training loss: 1.3871665553922072
Validation loss: 2.6264327436885173

Epoch: 238| Step: 0
Training loss: 0.9062528281332151
Validation loss: 2.6504472696006767

Epoch: 6| Step: 1
Training loss: 1.1185804632862868
Validation loss: 2.634139385490548

Epoch: 6| Step: 2
Training loss: 0.9589946303431092
Validation loss: 2.6452914235228477

Epoch: 6| Step: 3
Training loss: 1.2081152730156492
Validation loss: 2.6715327189181313

Epoch: 6| Step: 4
Training loss: 1.439851413319355
Validation loss: 2.6597767994249852

Epoch: 6| Step: 5
Training loss: 1.2826191169790477
Validation loss: 2.6507960973222224

Epoch: 6| Step: 6
Training loss: 1.0033340901681405
Validation loss: 2.667285630727474

Epoch: 6| Step: 7
Training loss: 1.0767966116936927
Validation loss: 2.6254259985588715

Epoch: 6| Step: 8
Training loss: 1.1237891356513823
Validation loss: 2.6749581677279948

Epoch: 6| Step: 9
Training loss: 1.308782353260882
Validation loss: 2.646721945432263

Epoch: 6| Step: 10
Training loss: 1.1914199578168898
Validation loss: 2.622573222996803

Epoch: 6| Step: 11
Training loss: 1.1715923731453086
Validation loss: 2.674847934852515

Epoch: 6| Step: 12
Training loss: 1.1069415630227024
Validation loss: 2.6480988060182344

Epoch: 6| Step: 13
Training loss: 0.7660015114627398
Validation loss: 2.649859616583122

Epoch: 239| Step: 0
Training loss: 1.3435350734134657
Validation loss: 2.616648662101023

Epoch: 6| Step: 1
Training loss: 1.119153993004121
Validation loss: 2.6340235028327386

Epoch: 6| Step: 2
Training loss: 0.678650053298567
Validation loss: 2.6556993501265

Epoch: 6| Step: 3
Training loss: 0.8913369930019112
Validation loss: 2.6605931889433316

Epoch: 6| Step: 4
Training loss: 1.2518375718325145
Validation loss: 2.6971652632069016

Epoch: 6| Step: 5
Training loss: 1.1477046366879202
Validation loss: 2.682825131546375

Epoch: 6| Step: 6
Training loss: 1.05869244893106
Validation loss: 2.7068543853654043

Epoch: 6| Step: 7
Training loss: 0.9208740036960192
Validation loss: 2.6923236679672344

Epoch: 6| Step: 8
Training loss: 1.1295435601388282
Validation loss: 2.649121696705356

Epoch: 6| Step: 9
Training loss: 1.3159830109157644
Validation loss: 2.6525907270855047

Epoch: 6| Step: 10
Training loss: 1.3389568451870715
Validation loss: 2.63951165328193

Epoch: 6| Step: 11
Training loss: 1.053882828799328
Validation loss: 2.619035280429258

Epoch: 6| Step: 12
Training loss: 0.936611931113381
Validation loss: 2.6459377256273986

Epoch: 6| Step: 13
Training loss: 1.4948773331855603
Validation loss: 2.5964049494790875

Epoch: 240| Step: 0
Training loss: 0.849179248891298
Validation loss: 2.5965651688078064

Epoch: 6| Step: 1
Training loss: 1.204307569468054
Validation loss: 2.612449202191117

Epoch: 6| Step: 2
Training loss: 0.9417451747024337
Validation loss: 2.615116742673444

Epoch: 6| Step: 3
Training loss: 1.4862504054037684
Validation loss: 2.5985409290086627

Epoch: 6| Step: 4
Training loss: 0.9827519311723388
Validation loss: 2.583159284719178

Epoch: 6| Step: 5
Training loss: 1.2840647598881725
Validation loss: 2.626608767241686

Epoch: 6| Step: 6
Training loss: 1.0227425814937443
Validation loss: 2.60404048359659

Epoch: 6| Step: 7
Training loss: 1.1679144499031084
Validation loss: 2.6271136544864335

Epoch: 6| Step: 8
Training loss: 0.9537584357432302
Validation loss: 2.63912696430091

Epoch: 6| Step: 9
Training loss: 1.1216487241918756
Validation loss: 2.6287094818079484

Epoch: 6| Step: 10
Training loss: 0.7615827390089164
Validation loss: 2.6223319627001005

Epoch: 6| Step: 11
Training loss: 1.3738893878673801
Validation loss: 2.615484277486293

Epoch: 6| Step: 12
Training loss: 1.2976751501830213
Validation loss: 2.627209524064941

Epoch: 6| Step: 13
Training loss: 0.36020922240233405
Validation loss: 2.6466423404971833

Epoch: 241| Step: 0
Training loss: 0.793369060628154
Validation loss: 2.5952131402302556

Epoch: 6| Step: 1
Training loss: 1.3908356924857916
Validation loss: 2.6197847514535355

Epoch: 6| Step: 2
Training loss: 0.7515968568685404
Validation loss: 2.668257973643468

Epoch: 6| Step: 3
Training loss: 1.1158075947222896
Validation loss: 2.6238895827580215

Epoch: 6| Step: 4
Training loss: 1.221025348097164
Validation loss: 2.616350881963501

Epoch: 6| Step: 5
Training loss: 1.0286686118134927
Validation loss: 2.6438130701503617

Epoch: 6| Step: 6
Training loss: 1.1066617425747751
Validation loss: 2.696653101472838

Epoch: 6| Step: 7
Training loss: 1.187382140083021
Validation loss: 2.736341432564509

Epoch: 6| Step: 8
Training loss: 0.8803493604976523
Validation loss: 2.7171574238467215

Epoch: 6| Step: 9
Training loss: 0.9649087984343181
Validation loss: 2.7180053762421843

Epoch: 6| Step: 10
Training loss: 1.2461903693071756
Validation loss: 2.647511250966828

Epoch: 6| Step: 11
Training loss: 1.2609314721021307
Validation loss: 2.650334146529784

Epoch: 6| Step: 12
Training loss: 1.2999136382540746
Validation loss: 2.60167997263084

Epoch: 6| Step: 13
Training loss: 1.079754303164253
Validation loss: 2.632066455145481

Epoch: 242| Step: 0
Training loss: 1.300116200022206
Validation loss: 2.571641201734601

Epoch: 6| Step: 1
Training loss: 0.8478321648808321
Validation loss: 2.614842233919935

Epoch: 6| Step: 2
Training loss: 0.9106834096509749
Validation loss: 2.585048532526834

Epoch: 6| Step: 3
Training loss: 1.088340406049225
Validation loss: 2.6514812498052174

Epoch: 6| Step: 4
Training loss: 1.0278848593720415
Validation loss: 2.598628700621411

Epoch: 6| Step: 5
Training loss: 1.1314460668786865
Validation loss: 2.6142850025093067

Epoch: 6| Step: 6
Training loss: 1.033253659489001
Validation loss: 2.6170797880216283

Epoch: 6| Step: 7
Training loss: 1.212756605622202
Validation loss: 2.578262322461213

Epoch: 6| Step: 8
Training loss: 1.1796233304994101
Validation loss: 2.5653076487607196

Epoch: 6| Step: 9
Training loss: 1.2220715474443626
Validation loss: 2.5783267183713012

Epoch: 6| Step: 10
Training loss: 1.0248740793431754
Validation loss: 2.6059324867726796

Epoch: 6| Step: 11
Training loss: 1.2154474261112918
Validation loss: 2.628377338559974

Epoch: 6| Step: 12
Training loss: 1.361981403453539
Validation loss: 2.609047106524656

Epoch: 6| Step: 13
Training loss: 0.5455990483862305
Validation loss: 2.6073650183536747

Epoch: 243| Step: 0
Training loss: 1.3282804959093895
Validation loss: 2.6059741383173733

Epoch: 6| Step: 1
Training loss: 1.0619427958956926
Validation loss: 2.596960091444677

Epoch: 6| Step: 2
Training loss: 1.0152238493752055
Validation loss: 2.560224153231753

Epoch: 6| Step: 3
Training loss: 1.3862767334433632
Validation loss: 2.63728360231821

Epoch: 6| Step: 4
Training loss: 0.7855454803864151
Validation loss: 2.6202940530813916

Epoch: 6| Step: 5
Training loss: 1.1197202023908253
Validation loss: 2.6446629510506705

Epoch: 6| Step: 6
Training loss: 1.0359315667766436
Validation loss: 2.6084069960644083

Epoch: 6| Step: 7
Training loss: 0.870057828614578
Validation loss: 2.5899789040205565

Epoch: 6| Step: 8
Training loss: 1.021098601979853
Validation loss: 2.6090518765351542

Epoch: 6| Step: 9
Training loss: 1.1628254711695805
Validation loss: 2.6186792869496003

Epoch: 6| Step: 10
Training loss: 1.270509970543661
Validation loss: 2.631603342206584

Epoch: 6| Step: 11
Training loss: 1.0393961320610958
Validation loss: 2.6258870856043197

Epoch: 6| Step: 12
Training loss: 1.137898936897718
Validation loss: 2.62872943820844

Epoch: 6| Step: 13
Training loss: 0.9535541506325043
Validation loss: 2.631695820906832

Epoch: 244| Step: 0
Training loss: 1.2033803099200788
Validation loss: 2.6639840844615796

Epoch: 6| Step: 1
Training loss: 0.6332071039450166
Validation loss: 2.6285840045290483

Epoch: 6| Step: 2
Training loss: 1.3266143285468963
Validation loss: 2.6521153602154617

Epoch: 6| Step: 3
Training loss: 0.7502402477119958
Validation loss: 2.6938352184350562

Epoch: 6| Step: 4
Training loss: 1.4715235879856527
Validation loss: 2.690004896063496

Epoch: 6| Step: 5
Training loss: 0.9292521378987997
Validation loss: 2.69448429204075

Epoch: 6| Step: 6
Training loss: 1.0608081811848344
Validation loss: 2.688369535902958

Epoch: 6| Step: 7
Training loss: 1.0952847203801028
Validation loss: 2.7167984659532602

Epoch: 6| Step: 8
Training loss: 0.9521565128864284
Validation loss: 2.7130040094769554

Epoch: 6| Step: 9
Training loss: 0.7471020261727604
Validation loss: 2.6471318671026953

Epoch: 6| Step: 10
Training loss: 1.3155211237766808
Validation loss: 2.659201381923347

Epoch: 6| Step: 11
Training loss: 1.0973952991186773
Validation loss: 2.639857182062534

Epoch: 6| Step: 12
Training loss: 1.058283348605211
Validation loss: 2.630914007940421

Epoch: 6| Step: 13
Training loss: 1.1513157801520555
Validation loss: 2.6180053745587095

Epoch: 245| Step: 0
Training loss: 0.9604530664084724
Validation loss: 2.62621340172142

Epoch: 6| Step: 1
Training loss: 0.8474296583393396
Validation loss: 2.6314618532082483

Epoch: 6| Step: 2
Training loss: 1.40208636713857
Validation loss: 2.656703161857001

Epoch: 6| Step: 3
Training loss: 1.0476664497851849
Validation loss: 2.696646095939805

Epoch: 6| Step: 4
Training loss: 1.3289457141504135
Validation loss: 2.6744676738634703

Epoch: 6| Step: 5
Training loss: 0.7901919750957981
Validation loss: 2.681759845703

Epoch: 6| Step: 6
Training loss: 1.1897517989678679
Validation loss: 2.6878457864053953

Epoch: 6| Step: 7
Training loss: 0.9477684967160016
Validation loss: 2.6907534803459474

Epoch: 6| Step: 8
Training loss: 1.331477567537482
Validation loss: 2.6364795790547526

Epoch: 6| Step: 9
Training loss: 0.937720018636232
Validation loss: 2.6458526086109173

Epoch: 6| Step: 10
Training loss: 1.0018967878479603
Validation loss: 2.604333381156591

Epoch: 6| Step: 11
Training loss: 0.928331781080125
Validation loss: 2.615897853517557

Epoch: 6| Step: 12
Training loss: 1.1725136606034736
Validation loss: 2.595016790356995

Epoch: 6| Step: 13
Training loss: 1.339381413446648
Validation loss: 2.5834689285015746

Epoch: 246| Step: 0
Training loss: 0.6559141753012931
Validation loss: 2.5753628100937678

Epoch: 6| Step: 1
Training loss: 1.4024634350040779
Validation loss: 2.579961837968998

Epoch: 6| Step: 2
Training loss: 0.9137851587777268
Validation loss: 2.5831398039647078

Epoch: 6| Step: 3
Training loss: 1.0809956907526983
Validation loss: 2.6385647208888394

Epoch: 6| Step: 4
Training loss: 0.8130151875943611
Validation loss: 2.6681148483225483

Epoch: 6| Step: 5
Training loss: 0.8824625587625788
Validation loss: 2.6944178516777137

Epoch: 6| Step: 6
Training loss: 1.0729140247695148
Validation loss: 2.772067397901661

Epoch: 6| Step: 7
Training loss: 1.2790151970283352
Validation loss: 2.798575977520959

Epoch: 6| Step: 8
Training loss: 1.181046366421768
Validation loss: 2.76353911715783

Epoch: 6| Step: 9
Training loss: 1.0107604683959726
Validation loss: 2.702303848290058

Epoch: 6| Step: 10
Training loss: 1.2908738328225304
Validation loss: 2.6766498671691923

Epoch: 6| Step: 11
Training loss: 1.3589210190660714
Validation loss: 2.674067591345453

Epoch: 6| Step: 12
Training loss: 1.179076687150899
Validation loss: 2.648219137421649

Epoch: 6| Step: 13
Training loss: 1.1519388813057914
Validation loss: 2.6640033820616535

Epoch: 247| Step: 0
Training loss: 1.225814105068271
Validation loss: 2.6913970590386844

Epoch: 6| Step: 1
Training loss: 1.1616994952393582
Validation loss: 2.6904581558909704

Epoch: 6| Step: 2
Training loss: 1.243778529391087
Validation loss: 2.677801648154133

Epoch: 6| Step: 3
Training loss: 1.0086122636698867
Validation loss: 2.673029043190456

Epoch: 6| Step: 4
Training loss: 1.0763602810137818
Validation loss: 2.675018813184292

Epoch: 6| Step: 5
Training loss: 0.8672708007394146
Validation loss: 2.6298953066323687

Epoch: 6| Step: 6
Training loss: 1.3760408016936563
Validation loss: 2.61992918379494

Epoch: 6| Step: 7
Training loss: 0.9893325822596857
Validation loss: 2.6329611177059196

Epoch: 6| Step: 8
Training loss: 1.1086700241162664
Validation loss: 2.619993223409962

Epoch: 6| Step: 9
Training loss: 0.8682511825531503
Validation loss: 2.610979384368906

Epoch: 6| Step: 10
Training loss: 0.9663808833179887
Validation loss: 2.616367995049356

Epoch: 6| Step: 11
Training loss: 1.0463352804851451
Validation loss: 2.6371880250817665

Epoch: 6| Step: 12
Training loss: 1.207289239169498
Validation loss: 2.631831203426528

Epoch: 6| Step: 13
Training loss: 1.1664062050310293
Validation loss: 2.6517480686364987

Epoch: 248| Step: 0
Training loss: 0.901442172319451
Validation loss: 2.65383439465487

Epoch: 6| Step: 1
Training loss: 1.1662896886943277
Validation loss: 2.6939948733814103

Epoch: 6| Step: 2
Training loss: 0.6307333711147481
Validation loss: 2.6931657661838106

Epoch: 6| Step: 3
Training loss: 1.4156988802529868
Validation loss: 2.7500551111958065

Epoch: 6| Step: 4
Training loss: 1.0718945137227307
Validation loss: 2.706651617646138

Epoch: 6| Step: 5
Training loss: 0.9919578106161054
Validation loss: 2.7032231252541816

Epoch: 6| Step: 6
Training loss: 1.2717493955934325
Validation loss: 2.7041890780608573

Epoch: 6| Step: 7
Training loss: 1.173593913497172
Validation loss: 2.6968660532916635

Epoch: 6| Step: 8
Training loss: 0.7162960288019056
Validation loss: 2.6721120317948874

Epoch: 6| Step: 9
Training loss: 0.9836423963374739
Validation loss: 2.594840617961009

Epoch: 6| Step: 10
Training loss: 1.1412901833052145
Validation loss: 2.603998424058567

Epoch: 6| Step: 11
Training loss: 1.0284857259157638
Validation loss: 2.5846767342987773

Epoch: 6| Step: 12
Training loss: 1.109321270568382
Validation loss: 2.5921196793451076

Epoch: 6| Step: 13
Training loss: 1.1559383900338094
Validation loss: 2.5398643904712084

Epoch: 249| Step: 0
Training loss: 1.3421197805318272
Validation loss: 2.5438083284520707

Epoch: 6| Step: 1
Training loss: 0.9621324320363989
Validation loss: 2.550299883241167

Epoch: 6| Step: 2
Training loss: 1.076341785234299
Validation loss: 2.529476460523808

Epoch: 6| Step: 3
Training loss: 1.030356511387132
Validation loss: 2.5414433340003093

Epoch: 6| Step: 4
Training loss: 0.7262126121154916
Validation loss: 2.51361909316866

Epoch: 6| Step: 5
Training loss: 1.0841210631373066
Validation loss: 2.516939818693261

Epoch: 6| Step: 6
Training loss: 0.8571538136837825
Validation loss: 2.544554175826676

Epoch: 6| Step: 7
Training loss: 1.2454406557466695
Validation loss: 2.542982949457834

Epoch: 6| Step: 8
Training loss: 1.078180062919637
Validation loss: 2.566620949395421

Epoch: 6| Step: 9
Training loss: 0.870841977808147
Validation loss: 2.561802088481815

Epoch: 6| Step: 10
Training loss: 1.1893284423824495
Validation loss: 2.5441851014789405

Epoch: 6| Step: 11
Training loss: 0.7037193541350355
Validation loss: 2.549380011854468

Epoch: 6| Step: 12
Training loss: 1.411720866131529
Validation loss: 2.539176214683408

Epoch: 6| Step: 13
Training loss: 0.47503762096195407
Validation loss: 2.5397964797400143

Epoch: 250| Step: 0
Training loss: 0.9642162985516314
Validation loss: 2.5931659727405547

Epoch: 6| Step: 1
Training loss: 1.1242131554502148
Validation loss: 2.646572383505075

Epoch: 6| Step: 2
Training loss: 0.8045430099982108
Validation loss: 2.6395132063192754

Epoch: 6| Step: 3
Training loss: 1.2649452361967226
Validation loss: 2.6467806168635915

Epoch: 6| Step: 4
Training loss: 0.923600344168895
Validation loss: 2.673996758442674

Epoch: 6| Step: 5
Training loss: 0.8663768931885392
Validation loss: 2.623904775659709

Epoch: 6| Step: 6
Training loss: 0.9948528863467262
Validation loss: 2.645316388284977

Epoch: 6| Step: 7
Training loss: 1.0691485236381024
Validation loss: 2.604229546228745

Epoch: 6| Step: 8
Training loss: 0.7566747087591824
Validation loss: 2.6252310055970787

Epoch: 6| Step: 9
Training loss: 1.185869402431829
Validation loss: 2.6179423091523373

Epoch: 6| Step: 10
Training loss: 1.0109179062986007
Validation loss: 2.60178093555343

Epoch: 6| Step: 11
Training loss: 1.3897391079926842
Validation loss: 2.5954476513831546

Epoch: 6| Step: 12
Training loss: 0.9073540769383166
Validation loss: 2.6370070112342074

Epoch: 6| Step: 13
Training loss: 0.6206065252191539
Validation loss: 2.63093348087063

Epoch: 251| Step: 0
Training loss: 1.1779463594623352
Validation loss: 2.6628491468298447

Epoch: 6| Step: 1
Training loss: 0.7456518332424635
Validation loss: 2.6893980130650617

Epoch: 6| Step: 2
Training loss: 0.9611908803451631
Validation loss: 2.6623430273299276

Epoch: 6| Step: 3
Training loss: 0.8091536348068081
Validation loss: 2.6811536379273977

Epoch: 6| Step: 4
Training loss: 0.7755193723549968
Validation loss: 2.663572061347075

Epoch: 6| Step: 5
Training loss: 0.8360469782077771
Validation loss: 2.647881473251777

Epoch: 6| Step: 6
Training loss: 0.9875957539163919
Validation loss: 2.645163425021507

Epoch: 6| Step: 7
Training loss: 1.3467283731115207
Validation loss: 2.645973159884456

Epoch: 6| Step: 8
Training loss: 1.2159292394415802
Validation loss: 2.6136835250545687

Epoch: 6| Step: 9
Training loss: 1.3509971450532667
Validation loss: 2.6187618980457543

Epoch: 6| Step: 10
Training loss: 0.9237279857856602
Validation loss: 2.612719953128788

Epoch: 6| Step: 11
Training loss: 0.8312287378101544
Validation loss: 2.6049267041638338

Epoch: 6| Step: 12
Training loss: 1.0928532875484562
Validation loss: 2.652462652174153

Epoch: 6| Step: 13
Training loss: 0.2642110327840571
Validation loss: 2.672515711722494

Epoch: 252| Step: 0
Training loss: 0.8830277509659493
Validation loss: 2.666066685471245

Epoch: 6| Step: 1
Training loss: 0.9338432202155922
Validation loss: 2.7141969628149267

Epoch: 6| Step: 2
Training loss: 0.9024896545028537
Validation loss: 2.6741866990987115

Epoch: 6| Step: 3
Training loss: 0.8946506470536069
Validation loss: 2.691103053640012

Epoch: 6| Step: 4
Training loss: 1.1827483226544104
Validation loss: 2.661475848309334

Epoch: 6| Step: 5
Training loss: 0.9029214504228469
Validation loss: 2.6821735041048864

Epoch: 6| Step: 6
Training loss: 1.2771825192855815
Validation loss: 2.6173796905051807

Epoch: 6| Step: 7
Training loss: 1.1323824888487681
Validation loss: 2.5939234579089536

Epoch: 6| Step: 8
Training loss: 0.9027336566283382
Validation loss: 2.5928110962751094

Epoch: 6| Step: 9
Training loss: 0.6565266661781065
Validation loss: 2.6188716890599797

Epoch: 6| Step: 10
Training loss: 1.4441633450219897
Validation loss: 2.6294599500130227

Epoch: 6| Step: 11
Training loss: 0.9993544521450003
Validation loss: 2.650560042550667

Epoch: 6| Step: 12
Training loss: 0.835290105528784
Validation loss: 2.597539309949619

Epoch: 6| Step: 13
Training loss: 0.7711069849921082
Validation loss: 2.637433652592973

Epoch: 253| Step: 0
Training loss: 1.2530663074627924
Validation loss: 2.6617750832594615

Epoch: 6| Step: 1
Training loss: 0.7734176556131821
Validation loss: 2.6800164791782715

Epoch: 6| Step: 2
Training loss: 1.1078970291752068
Validation loss: 2.67788586646078

Epoch: 6| Step: 3
Training loss: 1.0233162961053122
Validation loss: 2.6467572146991545

Epoch: 6| Step: 4
Training loss: 0.766614119311472
Validation loss: 2.6334055264370684

Epoch: 6| Step: 5
Training loss: 1.0925385987296057
Validation loss: 2.6176834770306026

Epoch: 6| Step: 6
Training loss: 0.9046195259977569
Validation loss: 2.601693985174222

Epoch: 6| Step: 7
Training loss: 0.731814038142703
Validation loss: 2.5770680378643105

Epoch: 6| Step: 8
Training loss: 1.2819894657148543
Validation loss: 2.584946029438296

Epoch: 6| Step: 9
Training loss: 1.0668960955366107
Validation loss: 2.6029352032032054

Epoch: 6| Step: 10
Training loss: 1.0417880686905172
Validation loss: 2.5968815401666534

Epoch: 6| Step: 11
Training loss: 0.9156116497641885
Validation loss: 2.6413400925306427

Epoch: 6| Step: 12
Training loss: 1.0704759904502161
Validation loss: 2.643179429610407

Epoch: 6| Step: 13
Training loss: 0.7107383113628547
Validation loss: 2.6358778659964552

Epoch: 254| Step: 0
Training loss: 0.9398758347663972
Validation loss: 2.627545030774545

Epoch: 6| Step: 1
Training loss: 0.9808936547199253
Validation loss: 2.5789995899528786

Epoch: 6| Step: 2
Training loss: 0.9806047322480591
Validation loss: 2.593225353171029

Epoch: 6| Step: 3
Training loss: 1.2220144324004505
Validation loss: 2.576334507383957

Epoch: 6| Step: 4
Training loss: 0.9018367317207115
Validation loss: 2.5320355123102374

Epoch: 6| Step: 5
Training loss: 0.7616294221585326
Validation loss: 2.6023299183383752

Epoch: 6| Step: 6
Training loss: 1.0230521138957596
Validation loss: 2.5615685163322928

Epoch: 6| Step: 7
Training loss: 1.4051028340945346
Validation loss: 2.6120991027488034

Epoch: 6| Step: 8
Training loss: 1.0508416027335634
Validation loss: 2.611408456458043

Epoch: 6| Step: 9
Training loss: 0.9780426709806698
Validation loss: 2.664883348645134

Epoch: 6| Step: 10
Training loss: 0.9495643018149166
Validation loss: 2.6354397612994673

Epoch: 6| Step: 11
Training loss: 0.5503407333210766
Validation loss: 2.6612722365783084

Epoch: 6| Step: 12
Training loss: 1.045547383694588
Validation loss: 2.6303377616533856

Epoch: 6| Step: 13
Training loss: 0.6958472949091176
Validation loss: 2.586739913060945

Epoch: 255| Step: 0
Training loss: 0.8806938134212734
Validation loss: 2.650047918789243

Epoch: 6| Step: 1
Training loss: 0.5119265360151234
Validation loss: 2.627324080915552

Epoch: 6| Step: 2
Training loss: 0.7549006569790151
Validation loss: 2.6073033936580523

Epoch: 6| Step: 3
Training loss: 1.174450549039932
Validation loss: 2.5585974232286333

Epoch: 6| Step: 4
Training loss: 1.054623750243487
Validation loss: 2.569625022977786

Epoch: 6| Step: 5
Training loss: 0.938705622796213
Validation loss: 2.597822088215043

Epoch: 6| Step: 6
Training loss: 1.211710922835727
Validation loss: 2.585972497376892

Epoch: 6| Step: 7
Training loss: 1.125346925013468
Validation loss: 2.586229109189573

Epoch: 6| Step: 8
Training loss: 1.165320005221352
Validation loss: 2.573687874536076

Epoch: 6| Step: 9
Training loss: 1.1981780665370878
Validation loss: 2.5687699074868617

Epoch: 6| Step: 10
Training loss: 0.6935930315062533
Validation loss: 2.6020661524032174

Epoch: 6| Step: 11
Training loss: 0.8791492719571645
Validation loss: 2.586354521106087

Epoch: 6| Step: 12
Training loss: 0.8513345675816721
Validation loss: 2.6129246148373766

Epoch: 6| Step: 13
Training loss: 1.0533516795536435
Validation loss: 2.60854145412811

Epoch: 256| Step: 0
Training loss: 0.6373491033846883
Validation loss: 2.61693603600563

Epoch: 6| Step: 1
Training loss: 1.251540093572596
Validation loss: 2.603483126280651

Epoch: 6| Step: 2
Training loss: 1.2127324736804552
Validation loss: 2.5856976528137636

Epoch: 6| Step: 3
Training loss: 1.022251869257792
Validation loss: 2.5944662349352927

Epoch: 6| Step: 4
Training loss: 0.6249790903408418
Validation loss: 2.6350416380073853

Epoch: 6| Step: 5
Training loss: 0.47764940293745056
Validation loss: 2.691173922128815

Epoch: 6| Step: 6
Training loss: 0.8376630282790435
Validation loss: 2.6577945945113313

Epoch: 6| Step: 7
Training loss: 1.2319128856513606
Validation loss: 2.6497756994649877

Epoch: 6| Step: 8
Training loss: 0.6447653836474376
Validation loss: 2.6885919434529613

Epoch: 6| Step: 9
Training loss: 0.8824484758222014
Validation loss: 2.722376940583493

Epoch: 6| Step: 10
Training loss: 1.1662264686001333
Validation loss: 2.6681573691490956

Epoch: 6| Step: 11
Training loss: 0.9504155279205961
Validation loss: 2.638071800426085

Epoch: 6| Step: 12
Training loss: 1.2691277904571872
Validation loss: 2.615003953911629

Epoch: 6| Step: 13
Training loss: 1.0506820348250645
Validation loss: 2.63561152403721

Epoch: 257| Step: 0
Training loss: 0.6754178078665516
Validation loss: 2.581175319246101

Epoch: 6| Step: 1
Training loss: 1.0181118376403848
Validation loss: 2.567347367993746

Epoch: 6| Step: 2
Training loss: 1.0597310730939637
Validation loss: 2.566717267613045

Epoch: 6| Step: 3
Training loss: 1.216323295023559
Validation loss: 2.58146545139476

Epoch: 6| Step: 4
Training loss: 0.8370198880639136
Validation loss: 2.584352470555976

Epoch: 6| Step: 5
Training loss: 1.0955929624287595
Validation loss: 2.5770880937405907

Epoch: 6| Step: 6
Training loss: 1.1898783908542807
Validation loss: 2.589590202980241

Epoch: 6| Step: 7
Training loss: 0.8503899857707462
Validation loss: 2.5757975374558733

Epoch: 6| Step: 8
Training loss: 1.3139746873615163
Validation loss: 2.54723757351031

Epoch: 6| Step: 9
Training loss: 0.8434285151881835
Validation loss: 2.5297665033516674

Epoch: 6| Step: 10
Training loss: 0.3357593818242829
Validation loss: 2.538545037762026

Epoch: 6| Step: 11
Training loss: 0.6647920079610441
Validation loss: 2.532164636935036

Epoch: 6| Step: 12
Training loss: 0.6908276825809104
Validation loss: 2.521509315497835

Epoch: 6| Step: 13
Training loss: 1.212435478774706
Validation loss: 2.516238128249555

Epoch: 258| Step: 0
Training loss: 0.6113206905607623
Validation loss: 2.51265269728535

Epoch: 6| Step: 1
Training loss: 0.7710439849532811
Validation loss: 2.5058298063899107

Epoch: 6| Step: 2
Training loss: 0.996096861591341
Validation loss: 2.553064649782912

Epoch: 6| Step: 3
Training loss: 1.0012056711887463
Validation loss: 2.587112267974753

Epoch: 6| Step: 4
Training loss: 1.163009269487172
Validation loss: 2.604117841365416

Epoch: 6| Step: 5
Training loss: 0.8486091074908616
Validation loss: 2.589663122837097

Epoch: 6| Step: 6
Training loss: 1.022759948555268
Validation loss: 2.607092888247701

Epoch: 6| Step: 7
Training loss: 0.9504125803439138
Validation loss: 2.6359625747090734

Epoch: 6| Step: 8
Training loss: 1.1075945791844073
Validation loss: 2.607102451144201

Epoch: 6| Step: 9
Training loss: 0.6274055441021956
Validation loss: 2.58583047460268

Epoch: 6| Step: 10
Training loss: 0.8958682267837956
Validation loss: 2.619515173086673

Epoch: 6| Step: 11
Training loss: 1.1068211024218948
Validation loss: 2.6324761804751664

Epoch: 6| Step: 12
Training loss: 0.9128321004119435
Validation loss: 2.6338722041618183

Epoch: 6| Step: 13
Training loss: 1.1212878441351322
Validation loss: 2.6112868312912

Epoch: 259| Step: 0
Training loss: 1.1624507114257105
Validation loss: 2.6400202838880418

Epoch: 6| Step: 1
Training loss: 1.002677432599335
Validation loss: 2.661374476902394

Epoch: 6| Step: 2
Training loss: 0.7341796939948291
Validation loss: 2.7112441393514684

Epoch: 6| Step: 3
Training loss: 1.0194131483170452
Validation loss: 2.7000815230731843

Epoch: 6| Step: 4
Training loss: 0.6169571023971999
Validation loss: 2.7048897887010743

Epoch: 6| Step: 5
Training loss: 0.9660480720571465
Validation loss: 2.710156846470798

Epoch: 6| Step: 6
Training loss: 1.1484592461635597
Validation loss: 2.6884572441310177

Epoch: 6| Step: 7
Training loss: 0.803962751503105
Validation loss: 2.668306906326009

Epoch: 6| Step: 8
Training loss: 1.216521793824072
Validation loss: 2.6110326188187276

Epoch: 6| Step: 9
Training loss: 0.7207124704308125
Validation loss: 2.606566443140369

Epoch: 6| Step: 10
Training loss: 1.2238395254491146
Validation loss: 2.563948298289014

Epoch: 6| Step: 11
Training loss: 1.1558897127254915
Validation loss: 2.613637612860655

Epoch: 6| Step: 12
Training loss: 1.0314625607684302
Validation loss: 2.533871649065162

Epoch: 6| Step: 13
Training loss: 0.5083382745669405
Validation loss: 2.556594732279338

Epoch: 260| Step: 0
Training loss: 0.9036115187286928
Validation loss: 2.5920877270980163

Epoch: 6| Step: 1
Training loss: 0.8095248109480062
Validation loss: 2.6015443671603187

Epoch: 6| Step: 2
Training loss: 1.0645119747027665
Validation loss: 2.603656821927874

Epoch: 6| Step: 3
Training loss: 0.8232845055687175
Validation loss: 2.62814555797394

Epoch: 6| Step: 4
Training loss: 1.0602561594382316
Validation loss: 2.6664630795514452

Epoch: 6| Step: 5
Training loss: 0.8541209782422395
Validation loss: 2.6312532961115

Epoch: 6| Step: 6
Training loss: 0.9789225632510056
Validation loss: 2.60356024065769

Epoch: 6| Step: 7
Training loss: 1.3346749748012043
Validation loss: 2.630823782002452

Epoch: 6| Step: 8
Training loss: 0.6998484243043938
Validation loss: 2.6594438705914936

Epoch: 6| Step: 9
Training loss: 1.212459370827069
Validation loss: 2.6366378702499733

Epoch: 6| Step: 10
Training loss: 0.9365374073820398
Validation loss: 2.6035390475771116

Epoch: 6| Step: 11
Training loss: 0.8787459163652281
Validation loss: 2.5812368307840656

Epoch: 6| Step: 12
Training loss: 0.6163174738128631
Validation loss: 2.5640131546852043

Epoch: 6| Step: 13
Training loss: 0.7297925215953974
Validation loss: 2.5609247631784924

Epoch: 261| Step: 0
Training loss: 0.5526234006515585
Validation loss: 2.575066361954554

Epoch: 6| Step: 1
Training loss: 1.003346565471939
Validation loss: 2.5719168018325136

Epoch: 6| Step: 2
Training loss: 0.9347210386859819
Validation loss: 2.5616338743262097

Epoch: 6| Step: 3
Training loss: 0.6800085822082743
Validation loss: 2.556217800611226

Epoch: 6| Step: 4
Training loss: 0.7757301644122948
Validation loss: 2.507768948207203

Epoch: 6| Step: 5
Training loss: 1.0029363436974839
Validation loss: 2.5788397292058383

Epoch: 6| Step: 6
Training loss: 0.905696370936988
Validation loss: 2.5717384374390484

Epoch: 6| Step: 7
Training loss: 1.093971665944732
Validation loss: 2.5897456349617825

Epoch: 6| Step: 8
Training loss: 1.167271077177993
Validation loss: 2.6066253948699987

Epoch: 6| Step: 9
Training loss: 0.956290787718305
Validation loss: 2.608237943491049

Epoch: 6| Step: 10
Training loss: 0.8087158110996462
Validation loss: 2.6130503378287537

Epoch: 6| Step: 11
Training loss: 0.9763148794949237
Validation loss: 2.609845747819202

Epoch: 6| Step: 12
Training loss: 1.1343964125448731
Validation loss: 2.5972974673939433

Epoch: 6| Step: 13
Training loss: 0.5435559233344035
Validation loss: 2.5645109510211466

Epoch: 262| Step: 0
Training loss: 1.0119562054494955
Validation loss: 2.5806260274234156

Epoch: 6| Step: 1
Training loss: 0.8840235277945927
Validation loss: 2.5558199146848435

Epoch: 6| Step: 2
Training loss: 0.8775554873646327
Validation loss: 2.5896303512785743

Epoch: 6| Step: 3
Training loss: 1.2167517590922519
Validation loss: 2.556145333764529

Epoch: 6| Step: 4
Training loss: 0.7059627066777374
Validation loss: 2.546065800305443

Epoch: 6| Step: 5
Training loss: 0.9229773380208701
Validation loss: 2.587115334398017

Epoch: 6| Step: 6
Training loss: 0.5504461581260769
Validation loss: 2.623002152936758

Epoch: 6| Step: 7
Training loss: 0.5793079439470302
Validation loss: 2.6453291632518607

Epoch: 6| Step: 8
Training loss: 0.814238156277913
Validation loss: 2.664204994311973

Epoch: 6| Step: 9
Training loss: 0.9041506358599197
Validation loss: 2.664365344224449

Epoch: 6| Step: 10
Training loss: 0.9973364763384609
Validation loss: 2.6453047374458833

Epoch: 6| Step: 11
Training loss: 1.0399170996563691
Validation loss: 2.677245674814711

Epoch: 6| Step: 12
Training loss: 0.6761092784518575
Validation loss: 2.672704215728609

Epoch: 6| Step: 13
Training loss: 1.1297178947612427
Validation loss: 2.6959130011617027

Epoch: 263| Step: 0
Training loss: 0.8193478680038718
Validation loss: 2.6416808083887022

Epoch: 6| Step: 1
Training loss: 0.9819301944713663
Validation loss: 2.6320408932865047

Epoch: 6| Step: 2
Training loss: 1.143550309222511
Validation loss: 2.6412142941720598

Epoch: 6| Step: 3
Training loss: 0.6430649464097539
Validation loss: 2.6058637389692394

Epoch: 6| Step: 4
Training loss: 0.8577930802612052
Validation loss: 2.6451630131197907

Epoch: 6| Step: 5
Training loss: 0.7413375806612473
Validation loss: 2.669879622327281

Epoch: 6| Step: 6
Training loss: 0.4517151505265179
Validation loss: 2.602709700214597

Epoch: 6| Step: 7
Training loss: 1.0996928479779247
Validation loss: 2.5984680836587697

Epoch: 6| Step: 8
Training loss: 0.784826104894005
Validation loss: 2.577842933137876

Epoch: 6| Step: 9
Training loss: 1.132073259857554
Validation loss: 2.5757469229724386

Epoch: 6| Step: 10
Training loss: 0.8468144891383161
Validation loss: 2.5609514072662773

Epoch: 6| Step: 11
Training loss: 1.0573783738736022
Validation loss: 2.5894823697173543

Epoch: 6| Step: 12
Training loss: 0.49751783209620526
Validation loss: 2.5822484060055104

Epoch: 6| Step: 13
Training loss: 0.8489399344355939
Validation loss: 2.6055406892369595

Epoch: 264| Step: 0
Training loss: 1.0547662776207267
Validation loss: 2.602263967785422

Epoch: 6| Step: 1
Training loss: 0.665668094833891
Validation loss: 2.5999561087608694

Epoch: 6| Step: 2
Training loss: 0.9236447432536561
Validation loss: 2.6384014144263297

Epoch: 6| Step: 3
Training loss: 1.1264475939768872
Validation loss: 2.609138032949306

Epoch: 6| Step: 4
Training loss: 0.8617468268211824
Validation loss: 2.5949249591260046

Epoch: 6| Step: 5
Training loss: 0.6522387117349935
Validation loss: 2.6023750478671057

Epoch: 6| Step: 6
Training loss: 0.6537199750901828
Validation loss: 2.6195047541462664

Epoch: 6| Step: 7
Training loss: 0.8567575648864046
Validation loss: 2.612154517685259

Epoch: 6| Step: 8
Training loss: 0.9969692197656943
Validation loss: 2.5617136175071846

Epoch: 6| Step: 9
Training loss: 0.816152870977197
Validation loss: 2.6257779013269893

Epoch: 6| Step: 10
Training loss: 0.8360844420583451
Validation loss: 2.6117811549478525

Epoch: 6| Step: 11
Training loss: 0.91358364636579
Validation loss: 2.580202136864271

Epoch: 6| Step: 12
Training loss: 0.9025681121780597
Validation loss: 2.5402817638866377

Epoch: 6| Step: 13
Training loss: 0.8243478249097347
Validation loss: 2.5903449442732787

Epoch: 265| Step: 0
Training loss: 0.7392507172298209
Validation loss: 2.5230155675129606

Epoch: 6| Step: 1
Training loss: 0.8712338732591052
Validation loss: 2.5768048239690966

Epoch: 6| Step: 2
Training loss: 0.9971033701708009
Validation loss: 2.5648398147837734

Epoch: 6| Step: 3
Training loss: 0.8630113481834136
Validation loss: 2.5678386895178926

Epoch: 6| Step: 4
Training loss: 0.978546994861902
Validation loss: 2.53967733077907

Epoch: 6| Step: 5
Training loss: 0.6857770658318898
Validation loss: 2.614334797335786

Epoch: 6| Step: 6
Training loss: 1.047135847247014
Validation loss: 2.5935462943820493

Epoch: 6| Step: 7
Training loss: 1.2239939528889345
Validation loss: 2.561973779863209

Epoch: 6| Step: 8
Training loss: 0.4910790662666968
Validation loss: 2.57705796659412

Epoch: 6| Step: 9
Training loss: 0.9294564096162385
Validation loss: 2.568838486358603

Epoch: 6| Step: 10
Training loss: 0.8136007482067632
Validation loss: 2.609408458396716

Epoch: 6| Step: 11
Training loss: 0.6125647860927015
Validation loss: 2.6243166925342614

Epoch: 6| Step: 12
Training loss: 0.4523056449059674
Validation loss: 2.6179697223539034

Epoch: 6| Step: 13
Training loss: 0.956028814228713
Validation loss: 2.624008582348311

Epoch: 266| Step: 0
Training loss: 1.0471540619996553
Validation loss: 2.623442189063405

Epoch: 6| Step: 1
Training loss: 0.8124640530190367
Validation loss: 2.644754019276819

Epoch: 6| Step: 2
Training loss: 0.7199275280983539
Validation loss: 2.6621176559187876

Epoch: 6| Step: 3
Training loss: 0.5184211056021588
Validation loss: 2.6499324307037773

Epoch: 6| Step: 4
Training loss: 0.9052679397103318
Validation loss: 2.657824047627544

Epoch: 6| Step: 5
Training loss: 0.6418259691271428
Validation loss: 2.6824791041225513

Epoch: 6| Step: 6
Training loss: 0.6281387194753109
Validation loss: 2.678812024180431

Epoch: 6| Step: 7
Training loss: 0.8189948989699993
Validation loss: 2.6752942648036138

Epoch: 6| Step: 8
Training loss: 0.71630859375
Validation loss: 2.6734601178517265

Epoch: 6| Step: 9
Training loss: 0.9820551102318397
Validation loss: 2.665534054534663

Epoch: 6| Step: 10
Training loss: 1.0441435865594983
Validation loss: 2.669065974328148

Epoch: 6| Step: 11
Training loss: 0.9987507706258424
Validation loss: 2.613052128319541

Epoch: 6| Step: 12
Training loss: 0.8911313407844661
Validation loss: 2.644776073391539

Epoch: 6| Step: 13
Training loss: 0.7226781893312424
Validation loss: 2.6349014034031195

Epoch: 267| Step: 0
Training loss: 1.1757941261169442
Validation loss: 2.610592412763414

Epoch: 6| Step: 1
Training loss: 1.0647155438249176
Validation loss: 2.5693452507929693

Epoch: 6| Step: 2
Training loss: 0.8197512205067699
Validation loss: 2.57257935929026

Epoch: 6| Step: 3
Training loss: 0.7774080796197037
Validation loss: 2.5729820635401146

Epoch: 6| Step: 4
Training loss: 0.8937348064384952
Validation loss: 2.53661877480842

Epoch: 6| Step: 5
Training loss: 0.7396406948428753
Validation loss: 2.570475638242694

Epoch: 6| Step: 6
Training loss: 0.6042581083442624
Validation loss: 2.5855777684699963

Epoch: 6| Step: 7
Training loss: 0.935072426158295
Validation loss: 2.5326343003712974

Epoch: 6| Step: 8
Training loss: 0.9282769152712331
Validation loss: 2.607990609207902

Epoch: 6| Step: 9
Training loss: 0.7866705719667687
Validation loss: 2.5875381508923048

Epoch: 6| Step: 10
Training loss: 0.6557899406535294
Validation loss: 2.544259758969461

Epoch: 6| Step: 11
Training loss: 0.5932247448612115
Validation loss: 2.5997001409169007

Epoch: 6| Step: 12
Training loss: 0.6290621830749471
Validation loss: 2.5740031415785967

Epoch: 6| Step: 13
Training loss: 0.7076609215526393
Validation loss: 2.5851124172560342

Epoch: 268| Step: 0
Training loss: 0.831284667131129
Validation loss: 2.5353577711633837

Epoch: 6| Step: 1
Training loss: 0.6437847553981932
Validation loss: 2.573442030741922

Epoch: 6| Step: 2
Training loss: 1.2320592379974078
Validation loss: 2.575737933905774

Epoch: 6| Step: 3
Training loss: 0.47456968793043725
Validation loss: 2.5918918684355083

Epoch: 6| Step: 4
Training loss: 0.7282555655447807
Validation loss: 2.5720731931862058

Epoch: 6| Step: 5
Training loss: 0.9011971260571021
Validation loss: 2.5772837758310625

Epoch: 6| Step: 6
Training loss: 0.9297596238313399
Validation loss: 2.5691388437807774

Epoch: 6| Step: 7
Training loss: 0.4409773439158311
Validation loss: 2.589611862398756

Epoch: 6| Step: 8
Training loss: 0.8850012459180435
Validation loss: 2.6253505410227853

Epoch: 6| Step: 9
Training loss: 0.6333931743016156
Validation loss: 2.6220779474747298

Epoch: 6| Step: 10
Training loss: 0.7732534478570418
Validation loss: 2.605536506594511

Epoch: 6| Step: 11
Training loss: 0.6662451161318302
Validation loss: 2.6026414912894444

Epoch: 6| Step: 12
Training loss: 1.138766616884295
Validation loss: 2.5909816707048674

Epoch: 6| Step: 13
Training loss: 0.6810134363221321
Validation loss: 2.5789566702287416

Epoch: 269| Step: 0
Training loss: 0.5956925438113152
Validation loss: 2.5984362992576617

Epoch: 6| Step: 1
Training loss: 1.0905945082285047
Validation loss: 2.6077828175015076

Epoch: 6| Step: 2
Training loss: 0.9979928854954386
Validation loss: 2.6568881045936488

Epoch: 6| Step: 3
Training loss: 0.7161085269343066
Validation loss: 2.6400682144248755

Epoch: 6| Step: 4
Training loss: 0.8204623130962834
Validation loss: 2.6482675991360787

Epoch: 6| Step: 5
Training loss: 0.5594189557328375
Validation loss: 2.6490787329137193

Epoch: 6| Step: 6
Training loss: 1.004510007756206
Validation loss: 2.618024908251463

Epoch: 6| Step: 7
Training loss: 0.9045292533078859
Validation loss: 2.6125331073666413

Epoch: 6| Step: 8
Training loss: 0.6996846059012691
Validation loss: 2.644980102066597

Epoch: 6| Step: 9
Training loss: 0.7849153367327701
Validation loss: 2.6102828731373346

Epoch: 6| Step: 10
Training loss: 0.7772980106258124
Validation loss: 2.671644677635451

Epoch: 6| Step: 11
Training loss: 0.8545380847048654
Validation loss: 2.6090175105492865

Epoch: 6| Step: 12
Training loss: 0.5752582094683482
Validation loss: 2.6007117611346677

Epoch: 6| Step: 13
Training loss: 1.040684287641934
Validation loss: 2.5802516902629984

Epoch: 270| Step: 0
Training loss: 0.836784290414616
Validation loss: 2.5758058500238166

Epoch: 6| Step: 1
Training loss: 0.968013976043503
Validation loss: 2.589735920859981

Epoch: 6| Step: 2
Training loss: 0.5214597717653442
Validation loss: 2.5543838696353265

Epoch: 6| Step: 3
Training loss: 1.245361926391434
Validation loss: 2.5565125801764275

Epoch: 6| Step: 4
Training loss: 0.9200735432835541
Validation loss: 2.5339071915378537

Epoch: 6| Step: 5
Training loss: 0.36811544972646326
Validation loss: 2.60314863195928

Epoch: 6| Step: 6
Training loss: 0.845514536350838
Validation loss: 2.622712908130332

Epoch: 6| Step: 7
Training loss: 0.6114222786155239
Validation loss: 2.6739613609418744

Epoch: 6| Step: 8
Training loss: 0.4950561184813147
Validation loss: 2.632750554653994

Epoch: 6| Step: 9
Training loss: 0.908872886545082
Validation loss: 2.6550527346336414

Epoch: 6| Step: 10
Training loss: 0.828174193738496
Validation loss: 2.6466246114406378

Epoch: 6| Step: 11
Training loss: 0.9863621469805259
Validation loss: 2.6425419758205915

Epoch: 6| Step: 12
Training loss: 0.7015274124037145
Validation loss: 2.6247603184453103

Epoch: 6| Step: 13
Training loss: 0.6741607950526219
Validation loss: 2.6301093957780144

Epoch: 271| Step: 0
Training loss: 0.8350442409787547
Validation loss: 2.5970044752078443

Epoch: 6| Step: 1
Training loss: 0.8613724816074737
Validation loss: 2.624441150843139

Epoch: 6| Step: 2
Training loss: 0.8025517685256417
Validation loss: 2.5784278430734244

Epoch: 6| Step: 3
Training loss: 0.6209633168429218
Validation loss: 2.586725307123819

Epoch: 6| Step: 4
Training loss: 0.60894133958347
Validation loss: 2.565282928715804

Epoch: 6| Step: 5
Training loss: 0.8935436810925623
Validation loss: 2.5573965796749802

Epoch: 6| Step: 6
Training loss: 0.8011358824949215
Validation loss: 2.590122256244041

Epoch: 6| Step: 7
Training loss: 1.0659524140535024
Validation loss: 2.589365795644337

Epoch: 6| Step: 8
Training loss: 1.0991438698495333
Validation loss: 2.595029962609208

Epoch: 6| Step: 9
Training loss: 0.774135351837736
Validation loss: 2.560897240373614

Epoch: 6| Step: 10
Training loss: 0.20484317763457363
Validation loss: 2.6198155409735193

Epoch: 6| Step: 11
Training loss: 0.7656290482394569
Validation loss: 2.5645834183953866

Epoch: 6| Step: 12
Training loss: 0.794824167756134
Validation loss: 2.5785790206163264

Epoch: 6| Step: 13
Training loss: 0.8115652649677755
Validation loss: 2.5705106905490074

Epoch: 272| Step: 0
Training loss: 0.6419584074495932
Validation loss: 2.5881655288899004

Epoch: 6| Step: 1
Training loss: 0.6589087713680463
Validation loss: 2.548071598223811

Epoch: 6| Step: 2
Training loss: 0.8676853640944339
Validation loss: 2.598612061159527

Epoch: 6| Step: 3
Training loss: 0.629869895625189
Validation loss: 2.5910550035665523

Epoch: 6| Step: 4
Training loss: 0.884920153060077
Validation loss: 2.6264669945420964

Epoch: 6| Step: 5
Training loss: 1.3496043402526838
Validation loss: 2.672852721141677

Epoch: 6| Step: 6
Training loss: 0.7770352158636054
Validation loss: 2.6588815006702613

Epoch: 6| Step: 7
Training loss: 0.6567407544171021
Validation loss: 2.6519569869986643

Epoch: 6| Step: 8
Training loss: 0.5771574739371631
Validation loss: 2.678150021149734

Epoch: 6| Step: 9
Training loss: 0.8253971733270397
Validation loss: 2.643194973308864

Epoch: 6| Step: 10
Training loss: 0.56381326595314
Validation loss: 2.6607885319585187

Epoch: 6| Step: 11
Training loss: 0.6693907653775679
Validation loss: 2.6348590337887563

Epoch: 6| Step: 12
Training loss: 0.7883045975674567
Validation loss: 2.673592978994288

Epoch: 6| Step: 13
Training loss: 0.9835344692118513
Validation loss: 2.642718108910097

Epoch: 273| Step: 0
Training loss: 0.7911059292709588
Validation loss: 2.589972692825457

Epoch: 6| Step: 1
Training loss: 1.0162736435282937
Validation loss: 2.5595049699220724

Epoch: 6| Step: 2
Training loss: 1.0660273399282438
Validation loss: 2.5179401420222534

Epoch: 6| Step: 3
Training loss: 0.6550627140786937
Validation loss: 2.521668579422043

Epoch: 6| Step: 4
Training loss: 0.5635034829093846
Validation loss: 2.526844891456714

Epoch: 6| Step: 5
Training loss: 0.9138144784244165
Validation loss: 2.499153637927807

Epoch: 6| Step: 6
Training loss: 0.9098125021467335
Validation loss: 2.5869863849172865

Epoch: 6| Step: 7
Training loss: 0.7436443285845143
Validation loss: 2.574231991329325

Epoch: 6| Step: 8
Training loss: 0.43842573657198275
Validation loss: 2.5382227576901566

Epoch: 6| Step: 9
Training loss: 0.7232996370521119
Validation loss: 2.5695192656690278

Epoch: 6| Step: 10
Training loss: 0.8134637032507968
Validation loss: 2.5396382814732523

Epoch: 6| Step: 11
Training loss: 0.7801922695066381
Validation loss: 2.5959146024090636

Epoch: 6| Step: 12
Training loss: 0.8820325393599757
Validation loss: 2.5957954131259755

Epoch: 6| Step: 13
Training loss: 0.6115605214222912
Validation loss: 2.6250295857111445

Epoch: 274| Step: 0
Training loss: 0.8275697033962394
Validation loss: 2.6300138346567357

Epoch: 6| Step: 1
Training loss: 0.8026359107893792
Validation loss: 2.6141100085189

Epoch: 6| Step: 2
Training loss: 0.7783037708013206
Validation loss: 2.596070103077223

Epoch: 6| Step: 3
Training loss: 0.9001055946922975
Validation loss: 2.598308408892151

Epoch: 6| Step: 4
Training loss: 0.8391676199363691
Validation loss: 2.642499637519719

Epoch: 6| Step: 5
Training loss: 0.4977671117978622
Validation loss: 2.652104812219449

Epoch: 6| Step: 6
Training loss: 0.7767300507531631
Validation loss: 2.669334872738404

Epoch: 6| Step: 7
Training loss: 0.7463063042133284
Validation loss: 2.683333608843479

Epoch: 6| Step: 8
Training loss: 0.6056284047947338
Validation loss: 2.706810066770871

Epoch: 6| Step: 9
Training loss: 1.0230515312796744
Validation loss: 2.7001652800311704

Epoch: 6| Step: 10
Training loss: 0.7062367142634536
Validation loss: 2.693887201924608

Epoch: 6| Step: 11
Training loss: 0.8139073580995964
Validation loss: 2.7139663507250535

Epoch: 6| Step: 12
Training loss: 0.9097800398225538
Validation loss: 2.7245003681280586

Epoch: 6| Step: 13
Training loss: 0.5254852039620656
Validation loss: 2.650055532653315

Epoch: 275| Step: 0
Training loss: 1.0793553947077472
Validation loss: 2.6284911335001264

Epoch: 6| Step: 1
Training loss: 0.4996749298060536
Validation loss: 2.598683784258941

Epoch: 6| Step: 2
Training loss: 0.7054611391520866
Validation loss: 2.6303554289501148

Epoch: 6| Step: 3
Training loss: 0.8309203419199666
Validation loss: 2.579594314432591

Epoch: 6| Step: 4
Training loss: 0.7904085066445696
Validation loss: 2.6180309109059947

Epoch: 6| Step: 5
Training loss: 0.6290404845856197
Validation loss: 2.5717790448503335

Epoch: 6| Step: 6
Training loss: 0.5833757220489173
Validation loss: 2.5944303847525996

Epoch: 6| Step: 7
Training loss: 0.6899149701344544
Validation loss: 2.5973155449978482

Epoch: 6| Step: 8
Training loss: 0.6629334219591972
Validation loss: 2.5755210665857384

Epoch: 6| Step: 9
Training loss: 0.9835441049616823
Validation loss: 2.5799009238002446

Epoch: 6| Step: 10
Training loss: 0.7443908911353206
Validation loss: 2.6153232057262863

Epoch: 6| Step: 11
Training loss: 0.8327984205705541
Validation loss: 2.609458700449747

Epoch: 6| Step: 12
Training loss: 0.876360516727871
Validation loss: 2.6138839793019573

Epoch: 6| Step: 13
Training loss: 0.8943242995568568
Validation loss: 2.6033414196790954

Epoch: 276| Step: 0
Training loss: 0.6946109489995439
Validation loss: 2.5687840381755676

Epoch: 6| Step: 1
Training loss: 0.8631017852246744
Validation loss: 2.578250780265972

Epoch: 6| Step: 2
Training loss: 0.7114179057023763
Validation loss: 2.5747256562841803

Epoch: 6| Step: 3
Training loss: 0.7404614102896746
Validation loss: 2.572056667490748

Epoch: 6| Step: 4
Training loss: 0.6188248993594844
Validation loss: 2.579592360590713

Epoch: 6| Step: 5
Training loss: 0.4329544027560815
Validation loss: 2.5853154546752024

Epoch: 6| Step: 6
Training loss: 1.0334329331501566
Validation loss: 2.6008012524968023

Epoch: 6| Step: 7
Training loss: 0.8062116392014184
Validation loss: 2.5890922410657504

Epoch: 6| Step: 8
Training loss: 0.6406480738508534
Validation loss: 2.585664251969917

Epoch: 6| Step: 9
Training loss: 1.0707638199702811
Validation loss: 2.6497462081655034

Epoch: 6| Step: 10
Training loss: 0.8775741994629567
Validation loss: 2.6448620256875013

Epoch: 6| Step: 11
Training loss: 0.3165900556013471
Validation loss: 2.6114422063801057

Epoch: 6| Step: 12
Training loss: 0.8509709814841662
Validation loss: 2.6515191876226636

Epoch: 6| Step: 13
Training loss: 0.8102787171724082
Validation loss: 2.6111474563369037

Epoch: 277| Step: 0
Training loss: 0.8664076451667856
Validation loss: 2.6197870158616565

Epoch: 6| Step: 1
Training loss: 0.8097860787325385
Validation loss: 2.5920165113448337

Epoch: 6| Step: 2
Training loss: 0.6677496924562079
Validation loss: 2.584614255213116

Epoch: 6| Step: 3
Training loss: 0.8155383009157939
Validation loss: 2.584603914789189

Epoch: 6| Step: 4
Training loss: 0.9458616253882867
Validation loss: 2.560371743672397

Epoch: 6| Step: 5
Training loss: 0.6475109696655723
Validation loss: 2.5499087620771337

Epoch: 6| Step: 6
Training loss: 0.761470265084093
Validation loss: 2.5395037322108682

Epoch: 6| Step: 7
Training loss: 0.9663373375193743
Validation loss: 2.550223992193697

Epoch: 6| Step: 8
Training loss: 0.7971417223782624
Validation loss: 2.501129308838169

Epoch: 6| Step: 9
Training loss: 0.6919929472089792
Validation loss: 2.5517153478187304

Epoch: 6| Step: 10
Training loss: 0.4989144043774232
Validation loss: 2.589828923499617

Epoch: 6| Step: 11
Training loss: 0.7923504904383387
Validation loss: 2.5817524970164634

Epoch: 6| Step: 12
Training loss: 0.538424072363873
Validation loss: 2.595236135923761

Epoch: 6| Step: 13
Training loss: 0.5246844171975356
Validation loss: 2.595786238187352

Epoch: 278| Step: 0
Training loss: 0.7044380643109764
Validation loss: 2.5860565081826246

Epoch: 6| Step: 1
Training loss: 0.8929743982705464
Validation loss: 2.5851397948090518

Epoch: 6| Step: 2
Training loss: 0.6241294997557498
Validation loss: 2.5911213749628725

Epoch: 6| Step: 3
Training loss: 0.5528055960664553
Validation loss: 2.569522604011771

Epoch: 6| Step: 4
Training loss: 0.5503378361551066
Validation loss: 2.5532573545200705

Epoch: 6| Step: 5
Training loss: 0.7993533545956928
Validation loss: 2.5877050457146304

Epoch: 6| Step: 6
Training loss: 0.7538596420507416
Validation loss: 2.5770876401199962

Epoch: 6| Step: 7
Training loss: 0.832393907482631
Validation loss: 2.6063458886356177

Epoch: 6| Step: 8
Training loss: 0.8476703132833971
Validation loss: 2.5976214189188855

Epoch: 6| Step: 9
Training loss: 0.785876726413467
Validation loss: 2.5958197280378976

Epoch: 6| Step: 10
Training loss: 0.7195965715511132
Validation loss: 2.6087087648098435

Epoch: 6| Step: 11
Training loss: 0.5584040499735706
Validation loss: 2.5951806165689546

Epoch: 6| Step: 12
Training loss: 0.7372382734083376
Validation loss: 2.611586979850259

Epoch: 6| Step: 13
Training loss: 1.039629444534325
Validation loss: 2.655454657699272

Epoch: 279| Step: 0
Training loss: 0.7537228455088445
Validation loss: 2.62866547440083

Epoch: 6| Step: 1
Training loss: 0.668236372134062
Validation loss: 2.6230856853687676

Epoch: 6| Step: 2
Training loss: 0.8745341423222659
Validation loss: 2.575198045181974

Epoch: 6| Step: 3
Training loss: 1.0227149567681315
Validation loss: 2.577491917695616

Epoch: 6| Step: 4
Training loss: 0.6847273446506827
Validation loss: 2.5933639500006946

Epoch: 6| Step: 5
Training loss: 0.7881965039674923
Validation loss: 2.512064440016503

Epoch: 6| Step: 6
Training loss: 0.6180673436196775
Validation loss: 2.548420445042405

Epoch: 6| Step: 7
Training loss: 0.47384209482555123
Validation loss: 2.4887952574545156

Epoch: 6| Step: 8
Training loss: 0.8181149793787837
Validation loss: 2.5162580464661555

Epoch: 6| Step: 9
Training loss: 0.4637305449957392
Validation loss: 2.5359639879565115

Epoch: 6| Step: 10
Training loss: 0.3764151850899171
Validation loss: 2.528759598587281

Epoch: 6| Step: 11
Training loss: 0.7846302908852256
Validation loss: 2.576754223302052

Epoch: 6| Step: 12
Training loss: 0.7543670748062831
Validation loss: 2.5839188699774427

Epoch: 6| Step: 13
Training loss: 1.2966367203916325
Validation loss: 2.6216839551204703

Epoch: 280| Step: 0
Training loss: 0.8599811496997465
Validation loss: 2.594329270161539

Epoch: 6| Step: 1
Training loss: 0.5668958980993966
Validation loss: 2.594994286184655

Epoch: 6| Step: 2
Training loss: 0.9427505013042969
Validation loss: 2.5878788929489724

Epoch: 6| Step: 3
Training loss: 0.8689680635402436
Validation loss: 2.574212599371395

Epoch: 6| Step: 4
Training loss: 1.0155914301092626
Validation loss: 2.5700377602873785

Epoch: 6| Step: 5
Training loss: 0.4166076638248441
Validation loss: 2.569260931034701

Epoch: 6| Step: 6
Training loss: 0.5769558761210829
Validation loss: 2.5199219525627057

Epoch: 6| Step: 7
Training loss: 0.6960027890012481
Validation loss: 2.5524696390893133

Epoch: 6| Step: 8
Training loss: 0.6312054136789861
Validation loss: 2.5297088124153593

Epoch: 6| Step: 9
Training loss: 0.5550716574263236
Validation loss: 2.55099606351849

Epoch: 6| Step: 10
Training loss: 0.8817938269681376
Validation loss: 2.582504689999435

Epoch: 6| Step: 11
Training loss: 0.8403289812598994
Validation loss: 2.584844849309302

Epoch: 6| Step: 12
Training loss: 0.6703446725091468
Validation loss: 2.5782145420309406

Epoch: 6| Step: 13
Training loss: 0.323041190728176
Validation loss: 2.580829916449643

Epoch: 281| Step: 0
Training loss: 0.43879163335323645
Validation loss: 2.598709735393987

Epoch: 6| Step: 1
Training loss: 0.8886716067135584
Validation loss: 2.6420624804405017

Epoch: 6| Step: 2
Training loss: 0.6468205341500317
Validation loss: 2.5972940176812767

Epoch: 6| Step: 3
Training loss: 0.8401617823073299
Validation loss: 2.5933917169156735

Epoch: 6| Step: 4
Training loss: 0.8636112876838195
Validation loss: 2.6061002182539093

Epoch: 6| Step: 5
Training loss: 0.6981946808986375
Validation loss: 2.587021279909156

Epoch: 6| Step: 6
Training loss: 0.7091952764236543
Validation loss: 2.605979288270808

Epoch: 6| Step: 7
Training loss: 0.7481572241603321
Validation loss: 2.5894468381327758

Epoch: 6| Step: 8
Training loss: 0.885078694783392
Validation loss: 2.5493959067227077

Epoch: 6| Step: 9
Training loss: 0.6343665643892213
Validation loss: 2.5810885825369763

Epoch: 6| Step: 10
Training loss: 0.4387243373679991
Validation loss: 2.568881531721582

Epoch: 6| Step: 11
Training loss: 0.7433788174739181
Validation loss: 2.5953413391911315

Epoch: 6| Step: 12
Training loss: 0.736404617343374
Validation loss: 2.6044131024977775

Epoch: 6| Step: 13
Training loss: 0.7608764294942579
Validation loss: 2.643326004818974

Epoch: 282| Step: 0
Training loss: 0.8182841336933551
Validation loss: 2.668008354958565

Epoch: 6| Step: 1
Training loss: 1.0471906043917074
Validation loss: 2.674240528375694

Epoch: 6| Step: 2
Training loss: 0.8519461931019218
Validation loss: 2.7040631128536394

Epoch: 6| Step: 3
Training loss: 0.731603220865909
Validation loss: 2.6964309728190328

Epoch: 6| Step: 4
Training loss: 0.42561764154781273
Validation loss: 2.6566297786837842

Epoch: 6| Step: 5
Training loss: 0.5367174417849038
Validation loss: 2.665225971948226

Epoch: 6| Step: 6
Training loss: 0.6929366421491643
Validation loss: 2.660006187154819

Epoch: 6| Step: 7
Training loss: 0.5941862962814309
Validation loss: 2.6520057061802356

Epoch: 6| Step: 8
Training loss: 0.5947422971350919
Validation loss: 2.6112162142618396

Epoch: 6| Step: 9
Training loss: 0.8773281935062507
Validation loss: 2.605989617659628

Epoch: 6| Step: 10
Training loss: 0.6980469330636605
Validation loss: 2.6289577952341654

Epoch: 6| Step: 11
Training loss: 0.515228581486334
Validation loss: 2.5825791927031063

Epoch: 6| Step: 12
Training loss: 0.6022472695193343
Validation loss: 2.5892497866259765

Epoch: 6| Step: 13
Training loss: 0.8713806774593057
Validation loss: 2.6145877528417794

Epoch: 283| Step: 0
Training loss: 1.002280614920558
Validation loss: 2.617387505671687

Epoch: 6| Step: 1
Training loss: 0.8355447078068589
Validation loss: 2.5871545440638015

Epoch: 6| Step: 2
Training loss: 0.3042415387396227
Validation loss: 2.611736830644666

Epoch: 6| Step: 3
Training loss: 0.6293688429272747
Validation loss: 2.6054506118757295

Epoch: 6| Step: 4
Training loss: 0.8355512350502768
Validation loss: 2.604100498138181

Epoch: 6| Step: 5
Training loss: 0.4435233598511386
Validation loss: 2.566711017106675

Epoch: 6| Step: 6
Training loss: 0.5221685143791275
Validation loss: 2.594287668822152

Epoch: 6| Step: 7
Training loss: 0.47472799255261167
Validation loss: 2.589034602647111

Epoch: 6| Step: 8
Training loss: 0.79348362335247
Validation loss: 2.5771000420385035

Epoch: 6| Step: 9
Training loss: 0.5653245001215659
Validation loss: 2.5550193735380358

Epoch: 6| Step: 10
Training loss: 0.5568439848340757
Validation loss: 2.5550193936055203

Epoch: 6| Step: 11
Training loss: 0.7353507114116713
Validation loss: 2.5718166222834333

Epoch: 6| Step: 12
Training loss: 0.746327947638319
Validation loss: 2.568196118298592

Epoch: 6| Step: 13
Training loss: 1.064261995007352
Validation loss: 2.5528640920615993

Epoch: 284| Step: 0
Training loss: 0.6998253434135366
Validation loss: 2.570460574360725

Epoch: 6| Step: 1
Training loss: 0.715856075044041
Validation loss: 2.562127084956972

Epoch: 6| Step: 2
Training loss: 0.602221437694575
Validation loss: 2.5068751449520086

Epoch: 6| Step: 3
Training loss: 0.3447175605614387
Validation loss: 2.4934987741461225

Epoch: 6| Step: 4
Training loss: 0.6168023126711577
Validation loss: 2.5507065763446195

Epoch: 6| Step: 5
Training loss: 0.6807714128604352
Validation loss: 2.567640380585886

Epoch: 6| Step: 6
Training loss: 1.1341777072979204
Validation loss: 2.553124568269074

Epoch: 6| Step: 7
Training loss: 0.7631609834627554
Validation loss: 2.565400505698608

Epoch: 6| Step: 8
Training loss: 0.8098051423120346
Validation loss: 2.550859192781125

Epoch: 6| Step: 9
Training loss: 0.637300541472912
Validation loss: 2.5616266276434247

Epoch: 6| Step: 10
Training loss: 0.5088502696996624
Validation loss: 2.581616493261652

Epoch: 6| Step: 11
Training loss: 0.8349736441375973
Validation loss: 2.585065323259422

Epoch: 6| Step: 12
Training loss: 0.3735925966864844
Validation loss: 2.584514859957313

Epoch: 6| Step: 13
Training loss: 0.48618130593375986
Validation loss: 2.6019839964931415

Epoch: 285| Step: 0
Training loss: 0.5564034743160783
Validation loss: 2.6085953068601806

Epoch: 6| Step: 1
Training loss: 0.6146045670370376
Validation loss: 2.6003962234989655

Epoch: 6| Step: 2
Training loss: 0.8308828963020292
Validation loss: 2.6102179613052114

Epoch: 6| Step: 3
Training loss: 0.47435920307057416
Validation loss: 2.6305423751474115

Epoch: 6| Step: 4
Training loss: 0.49990867734437666
Validation loss: 2.5892118012940433

Epoch: 6| Step: 5
Training loss: 0.7971895008667674
Validation loss: 2.6531037519395415

Epoch: 6| Step: 6
Training loss: 0.4773171968457516
Validation loss: 2.5873993460332922

Epoch: 6| Step: 7
Training loss: 0.6399931699418159
Validation loss: 2.573144059140156

Epoch: 6| Step: 8
Training loss: 0.8849842736091543
Validation loss: 2.6044556750647665

Epoch: 6| Step: 9
Training loss: 0.7035621979255228
Validation loss: 2.569222481040675

Epoch: 6| Step: 10
Training loss: 0.7049438475505596
Validation loss: 2.5981691414051746

Epoch: 6| Step: 11
Training loss: 0.6572453806480105
Validation loss: 2.5960885111531837

Epoch: 6| Step: 12
Training loss: 0.764505190238524
Validation loss: 2.5965402971114107

Epoch: 6| Step: 13
Training loss: 0.8885563701979797
Validation loss: 2.5665975385044346

Epoch: 286| Step: 0
Training loss: 0.6188136540047585
Validation loss: 2.6205357211137708

Epoch: 6| Step: 1
Training loss: 0.7577092601807863
Validation loss: 2.604102070325146

Epoch: 6| Step: 2
Training loss: 0.4865231410224345
Validation loss: 2.6068655415641784

Epoch: 6| Step: 3
Training loss: 0.5179551388892617
Validation loss: 2.642140463742828

Epoch: 6| Step: 4
Training loss: 1.1101741330278896
Validation loss: 2.5895600183361833

Epoch: 6| Step: 5
Training loss: 0.8043781908234306
Validation loss: 2.618182904695545

Epoch: 6| Step: 6
Training loss: 0.6687887412284853
Validation loss: 2.6023171401490726

Epoch: 6| Step: 7
Training loss: 0.7981492867952967
Validation loss: 2.5787762239239695

Epoch: 6| Step: 8
Training loss: 0.8332271667245361
Validation loss: 2.581304461690174

Epoch: 6| Step: 9
Training loss: 0.6499436592480042
Validation loss: 2.643435709531777

Epoch: 6| Step: 10
Training loss: 0.5260124355793402
Validation loss: 2.5800952213251866

Epoch: 6| Step: 11
Training loss: 0.3781397430446206
Validation loss: 2.6377551765368747

Epoch: 6| Step: 12
Training loss: 0.29056234709862233
Validation loss: 2.6303623693280884

Epoch: 6| Step: 13
Training loss: 0.5512675039492312
Validation loss: 2.6325249427112603

Epoch: 287| Step: 0
Training loss: 0.4966209943971322
Validation loss: 2.6313359888648784

Epoch: 6| Step: 1
Training loss: 0.8304463366465178
Validation loss: 2.6267390596881603

Epoch: 6| Step: 2
Training loss: 0.6273061168589521
Validation loss: 2.5977349979252695

Epoch: 6| Step: 3
Training loss: 0.5111941495015858
Validation loss: 2.6273085701713197

Epoch: 6| Step: 4
Training loss: 0.5811423868625387
Validation loss: 2.5815433893131026

Epoch: 6| Step: 5
Training loss: 0.8270039798197992
Validation loss: 2.620711926517366

Epoch: 6| Step: 6
Training loss: 0.8268540904658851
Validation loss: 2.608620082291364

Epoch: 6| Step: 7
Training loss: 0.5262356453974274
Validation loss: 2.5873360250824247

Epoch: 6| Step: 8
Training loss: 0.7065132308849543
Validation loss: 2.563650339731969

Epoch: 6| Step: 9
Training loss: 0.7005784863048359
Validation loss: 2.560317275641722

Epoch: 6| Step: 10
Training loss: 0.607728445326004
Validation loss: 2.5636469627425282

Epoch: 6| Step: 11
Training loss: 0.5601361727341934
Validation loss: 2.580491930375803

Epoch: 6| Step: 12
Training loss: 0.7809068307582474
Validation loss: 2.594761259539448

Epoch: 6| Step: 13
Training loss: 0.6376302548647965
Validation loss: 2.602997277006624

Epoch: 288| Step: 0
Training loss: 0.8442771112834974
Validation loss: 2.5784418015223913

Epoch: 6| Step: 1
Training loss: 0.6389932086565776
Validation loss: 2.654619520218552

Epoch: 6| Step: 2
Training loss: 0.5842553980214368
Validation loss: 2.5976096311375705

Epoch: 6| Step: 3
Training loss: 0.7355901120970728
Validation loss: 2.6026229975690836

Epoch: 6| Step: 4
Training loss: 0.8442695572169028
Validation loss: 2.6355959618774443

Epoch: 6| Step: 5
Training loss: 0.5382757388692356
Validation loss: 2.612329339919383

Epoch: 6| Step: 6
Training loss: 0.412258645454561
Validation loss: 2.577131335552979

Epoch: 6| Step: 7
Training loss: 0.5411648596122622
Validation loss: 2.5753933423042805

Epoch: 6| Step: 8
Training loss: 0.764728878072489
Validation loss: 2.6115634134904564

Epoch: 6| Step: 9
Training loss: 0.9152857103005638
Validation loss: 2.567329726940005

Epoch: 6| Step: 10
Training loss: 0.28190517936412746
Validation loss: 2.6058521606379488

Epoch: 6| Step: 11
Training loss: 0.6868767514262896
Validation loss: 2.5835257082142147

Epoch: 6| Step: 12
Training loss: 0.618055963932812
Validation loss: 2.575367846559722

Epoch: 6| Step: 13
Training loss: 0.5567092050167196
Validation loss: 2.608459932146608

Epoch: 289| Step: 0
Training loss: 0.9565777385286743
Validation loss: 2.660545987584373

Epoch: 6| Step: 1
Training loss: 0.546526361778953
Validation loss: 2.573790279651894

Epoch: 6| Step: 2
Training loss: 0.8455060416467653
Validation loss: 2.5988242611901717

Epoch: 6| Step: 3
Training loss: 0.6006431986486026
Validation loss: 2.611194082876553

Epoch: 6| Step: 4
Training loss: 0.6915059206399505
Validation loss: 2.5872030705161855

Epoch: 6| Step: 5
Training loss: 0.6725021806135596
Validation loss: 2.599029727124279

Epoch: 6| Step: 6
Training loss: 0.6007904944930161
Validation loss: 2.6294678608955695

Epoch: 6| Step: 7
Training loss: 0.6060225384489873
Validation loss: 2.6288177690370214

Epoch: 6| Step: 8
Training loss: 0.49338659421327297
Validation loss: 2.5858053945627093

Epoch: 6| Step: 9
Training loss: 0.5462504499071307
Validation loss: 2.625909723592919

Epoch: 6| Step: 10
Training loss: 0.6125177380854364
Validation loss: 2.589917154675801

Epoch: 6| Step: 11
Training loss: 0.598286838341011
Validation loss: 2.5720855455260185

Epoch: 6| Step: 12
Training loss: 0.6603211868371874
Validation loss: 2.6080985702511086

Epoch: 6| Step: 13
Training loss: 0.5432224367138743
Validation loss: 2.581962754446857

Epoch: 290| Step: 0
Training loss: 0.5800167526505863
Validation loss: 2.5836962254137803

Epoch: 6| Step: 1
Training loss: 0.7187914629047673
Validation loss: 2.578666416866932

Epoch: 6| Step: 2
Training loss: 0.5496970252534106
Validation loss: 2.5752089410381003

Epoch: 6| Step: 3
Training loss: 0.8541707682317247
Validation loss: 2.6003322489210343

Epoch: 6| Step: 4
Training loss: 0.6342206522895909
Validation loss: 2.6247195500786127

Epoch: 6| Step: 5
Training loss: 0.6708120320968112
Validation loss: 2.581532680076887

Epoch: 6| Step: 6
Training loss: 0.6511643306887831
Validation loss: 2.613014855444285

Epoch: 6| Step: 7
Training loss: 0.3053940381639832
Validation loss: 2.608453225389885

Epoch: 6| Step: 8
Training loss: 0.7800875216678861
Validation loss: 2.604405298600082

Epoch: 6| Step: 9
Training loss: 0.7552716634220016
Validation loss: 2.6053906796004083

Epoch: 6| Step: 10
Training loss: 0.5570203857646454
Validation loss: 2.605113135507453

Epoch: 6| Step: 11
Training loss: 0.5082626108574303
Validation loss: 2.6267463775641553

Epoch: 6| Step: 12
Training loss: 0.5003776911925942
Validation loss: 2.5737417304022845

Epoch: 6| Step: 13
Training loss: 0.9376912557700501
Validation loss: 2.6022727790218334

Epoch: 291| Step: 0
Training loss: 0.5744914750146446
Validation loss: 2.6352147239763544

Epoch: 6| Step: 1
Training loss: 0.37532013897264405
Validation loss: 2.6120520114458747

Epoch: 6| Step: 2
Training loss: 0.5079150463148291
Validation loss: 2.61048042727492

Epoch: 6| Step: 3
Training loss: 0.5540165940581342
Validation loss: 2.607762760279387

Epoch: 6| Step: 4
Training loss: 0.8572398624705174
Validation loss: 2.6210940747226994

Epoch: 6| Step: 5
Training loss: 0.31505868783213586
Validation loss: 2.629166846444906

Epoch: 6| Step: 6
Training loss: 0.6495196722676724
Validation loss: 2.632254766046053

Epoch: 6| Step: 7
Training loss: 0.31489714082241815
Validation loss: 2.6346178155271187

Epoch: 6| Step: 8
Training loss: 0.7855192645288744
Validation loss: 2.5933236874953187

Epoch: 6| Step: 9
Training loss: 0.8799313141286816
Validation loss: 2.5859814682162554

Epoch: 6| Step: 10
Training loss: 0.8723435267619469
Validation loss: 2.590941623492591

Epoch: 6| Step: 11
Training loss: 0.4600048813612719
Validation loss: 2.629000721195039

Epoch: 6| Step: 12
Training loss: 0.9040970056187818
Validation loss: 2.5777150553777695

Epoch: 6| Step: 13
Training loss: 0.6216973065256423
Validation loss: 2.576020708454936

Epoch: 292| Step: 0
Training loss: 0.6679478692254416
Validation loss: 2.6245560434218116

Epoch: 6| Step: 1
Training loss: 0.5434267047601753
Validation loss: 2.6277873187629863

Epoch: 6| Step: 2
Training loss: 0.9666238649253835
Validation loss: 2.6744736811590437

Epoch: 6| Step: 3
Training loss: 0.3599903394806928
Validation loss: 2.653483891077533

Epoch: 6| Step: 4
Training loss: 0.3347504735876356
Validation loss: 2.673426192881891

Epoch: 6| Step: 5
Training loss: 0.5130930493126565
Validation loss: 2.6803058671483946

Epoch: 6| Step: 6
Training loss: 0.7439424345962811
Validation loss: 2.7208036597276286

Epoch: 6| Step: 7
Training loss: 0.5514526063193907
Validation loss: 2.6313654741095722

Epoch: 6| Step: 8
Training loss: 0.41447829117082907
Validation loss: 2.682592152244346

Epoch: 6| Step: 9
Training loss: 0.782848972529268
Validation loss: 2.626643555535701

Epoch: 6| Step: 10
Training loss: 0.7525998987695046
Validation loss: 2.618843051859651

Epoch: 6| Step: 11
Training loss: 0.45964194735317276
Validation loss: 2.5883214168587125

Epoch: 6| Step: 12
Training loss: 0.818316765816272
Validation loss: 2.6465662286038754

Epoch: 6| Step: 13
Training loss: 0.8900369409331199
Validation loss: 2.61013279424237

Epoch: 293| Step: 0
Training loss: 0.5053153629257263
Validation loss: 2.5919855463960153

Epoch: 6| Step: 1
Training loss: 0.7798249408316255
Validation loss: 2.5668440303507594

Epoch: 6| Step: 2
Training loss: 0.5818553889295894
Validation loss: 2.5952223250976094

Epoch: 6| Step: 3
Training loss: 0.7063052839398831
Validation loss: 2.596410853022731

Epoch: 6| Step: 4
Training loss: 0.7496088915530619
Validation loss: 2.5696753300507984

Epoch: 6| Step: 5
Training loss: 0.6276667921127272
Validation loss: 2.5974275098297332

Epoch: 6| Step: 6
Training loss: 0.48293126198032843
Validation loss: 2.588762688652252

Epoch: 6| Step: 7
Training loss: 0.6456762143231511
Validation loss: 2.5545833371104107

Epoch: 6| Step: 8
Training loss: 0.6548999341574715
Validation loss: 2.515008984340947

Epoch: 6| Step: 9
Training loss: 0.805414963562716
Validation loss: 2.4944678563200076

Epoch: 6| Step: 10
Training loss: 0.287760405159284
Validation loss: 2.538320918047139

Epoch: 6| Step: 11
Training loss: 0.7869829024186871
Validation loss: 2.5519995013680865

Epoch: 6| Step: 12
Training loss: 0.5027428140947127
Validation loss: 2.5952070126866684

Epoch: 6| Step: 13
Training loss: 0.7050379268779334
Validation loss: 2.5778268074219177

Epoch: 294| Step: 0
Training loss: 0.7468232188769667
Validation loss: 2.5798717012323618

Epoch: 6| Step: 1
Training loss: 0.6532466145503266
Validation loss: 2.5999357057009895

Epoch: 6| Step: 2
Training loss: 0.767189917783948
Validation loss: 2.5583937685084748

Epoch: 6| Step: 3
Training loss: 0.6702515705578284
Validation loss: 2.5371629711088852

Epoch: 6| Step: 4
Training loss: 0.42256856350722893
Validation loss: 2.578711616548141

Epoch: 6| Step: 5
Training loss: 0.5087029792463688
Validation loss: 2.5729882021647623

Epoch: 6| Step: 6
Training loss: 0.4388063885244591
Validation loss: 2.5788420564074674

Epoch: 6| Step: 7
Training loss: 0.5950822940784043
Validation loss: 2.573507978260974

Epoch: 6| Step: 8
Training loss: 0.8174632772311118
Validation loss: 2.539826013258089

Epoch: 6| Step: 9
Training loss: 0.5548367903844164
Validation loss: 2.5439446332817752

Epoch: 6| Step: 10
Training loss: 0.9764402999715699
Validation loss: 2.556500490533364

Epoch: 6| Step: 11
Training loss: 0.6079608696922192
Validation loss: 2.5832402619087147

Epoch: 6| Step: 12
Training loss: 0.5795865528813482
Validation loss: 2.5811522161615277

Epoch: 6| Step: 13
Training loss: 0.3637222361701964
Validation loss: 2.636834079859013

Epoch: 295| Step: 0
Training loss: 0.3719462590904941
Validation loss: 2.595030344928051

Epoch: 6| Step: 1
Training loss: 0.9229227028528075
Validation loss: 2.6229114407865213

Epoch: 6| Step: 2
Training loss: 0.38075329207952696
Validation loss: 2.618550281318124

Epoch: 6| Step: 3
Training loss: 0.36619606496492585
Validation loss: 2.639303211644276

Epoch: 6| Step: 4
Training loss: 0.5893312463468103
Validation loss: 2.5932439445568156

Epoch: 6| Step: 5
Training loss: 0.7286366216492184
Validation loss: 2.616440745726606

Epoch: 6| Step: 6
Training loss: 0.8243919299095768
Validation loss: 2.608815897211856

Epoch: 6| Step: 7
Training loss: 0.5432462189126301
Validation loss: 2.5999474829362232

Epoch: 6| Step: 8
Training loss: 0.45867679110546544
Validation loss: 2.609559873265991

Epoch: 6| Step: 9
Training loss: 0.5815316943045434
Validation loss: 2.621233973647695

Epoch: 6| Step: 10
Training loss: 0.8050160524296034
Validation loss: 2.5713843315019984

Epoch: 6| Step: 11
Training loss: 0.5561654187307435
Validation loss: 2.5872344796423277

Epoch: 6| Step: 12
Training loss: 0.9258695793667844
Validation loss: 2.5947438547609805

Epoch: 6| Step: 13
Training loss: 0.6225659657958126
Validation loss: 2.620494803867031

Epoch: 296| Step: 0
Training loss: 0.6431008853228263
Validation loss: 2.572316692681709

Epoch: 6| Step: 1
Training loss: 0.20334278865591066
Validation loss: 2.636656912956255

Epoch: 6| Step: 2
Training loss: 0.4612759301410113
Validation loss: 2.6430321314113185

Epoch: 6| Step: 3
Training loss: 0.6777000088732098
Validation loss: 2.610328406313731

Epoch: 6| Step: 4
Training loss: 0.8087047555994251
Validation loss: 2.602915471566745

Epoch: 6| Step: 5
Training loss: 0.5248083979791694
Validation loss: 2.617494656019382

Epoch: 6| Step: 6
Training loss: 0.7153793579694034
Validation loss: 2.5426749017172354

Epoch: 6| Step: 7
Training loss: 0.8673306252529882
Validation loss: 2.5423312603489236

Epoch: 6| Step: 8
Training loss: 0.8663167620056523
Validation loss: 2.5312424111059446

Epoch: 6| Step: 9
Training loss: 0.7526800431982331
Validation loss: 2.4961765749361327

Epoch: 6| Step: 10
Training loss: 0.5324129950495841
Validation loss: 2.512484100541273

Epoch: 6| Step: 11
Training loss: 0.7724925732795719
Validation loss: 2.496355408842404

Epoch: 6| Step: 12
Training loss: 0.40816793335707285
Validation loss: 2.5207148835732185

Epoch: 6| Step: 13
Training loss: 0.5456828338192853
Validation loss: 2.5007840270506034

Epoch: 297| Step: 0
Training loss: 0.7862046866406065
Validation loss: 2.5248936315887245

Epoch: 6| Step: 1
Training loss: 0.5085865869911289
Validation loss: 2.5125553350100254

Epoch: 6| Step: 2
Training loss: 0.5962451907429785
Validation loss: 2.4966443644778504

Epoch: 6| Step: 3
Training loss: 0.6563647941823146
Validation loss: 2.5221779279023973

Epoch: 6| Step: 4
Training loss: 0.5946087399485476
Validation loss: 2.5111336592834594

Epoch: 6| Step: 5
Training loss: 0.5762230284661474
Validation loss: 2.4774447724728486

Epoch: 6| Step: 6
Training loss: 0.5671430333889814
Validation loss: 2.5242235701768

Epoch: 6| Step: 7
Training loss: 0.86243248550878
Validation loss: 2.539564384540438

Epoch: 6| Step: 8
Training loss: 0.6469179756521164
Validation loss: 2.6045139732519975

Epoch: 6| Step: 9
Training loss: 0.8230261106184698
Validation loss: 2.6411276504749703

Epoch: 6| Step: 10
Training loss: 0.5231344000223608
Validation loss: 2.634319386489874

Epoch: 6| Step: 11
Training loss: 0.6568504946681045
Validation loss: 2.676181057171309

Epoch: 6| Step: 12
Training loss: 0.5900745066780944
Validation loss: 2.6887954705079133

Epoch: 6| Step: 13
Training loss: 0.6638347459561451
Validation loss: 2.6437507551623627

Epoch: 298| Step: 0
Training loss: 0.6786625028384444
Validation loss: 2.6804668721357894

Epoch: 6| Step: 1
Training loss: 0.5911366270135452
Validation loss: 2.6632201112991707

Epoch: 6| Step: 2
Training loss: 0.6444094918581421
Validation loss: 2.6822205886638515

Epoch: 6| Step: 3
Training loss: 0.44570440481070706
Validation loss: 2.658793651323663

Epoch: 6| Step: 4
Training loss: 0.729644963660406
Validation loss: 2.6988216574810653

Epoch: 6| Step: 5
Training loss: 0.7183237055541175
Validation loss: 2.6788944919929016

Epoch: 6| Step: 6
Training loss: 0.5017917833896953
Validation loss: 2.6905218169324026

Epoch: 6| Step: 7
Training loss: 0.5968074131192664
Validation loss: 2.6454197792384546

Epoch: 6| Step: 8
Training loss: 0.5865828711051798
Validation loss: 2.6322125943952788

Epoch: 6| Step: 9
Training loss: 0.7312757552738312
Validation loss: 2.581132264369533

Epoch: 6| Step: 10
Training loss: 0.8143288496968583
Validation loss: 2.591527585440201

Epoch: 6| Step: 11
Training loss: 0.5222330041825212
Validation loss: 2.6309943065397974

Epoch: 6| Step: 12
Training loss: 0.5900364744097442
Validation loss: 2.5797817292889884

Epoch: 6| Step: 13
Training loss: 0.5397328617578421
Validation loss: 2.609226152068794

Epoch: 299| Step: 0
Training loss: 0.6435142122313142
Validation loss: 2.613901394923872

Epoch: 6| Step: 1
Training loss: 0.5043167689482304
Validation loss: 2.609725751238124

Epoch: 6| Step: 2
Training loss: 0.8047131284317627
Validation loss: 2.622477340339926

Epoch: 6| Step: 3
Training loss: 0.4463086280457147
Validation loss: 2.6489256665652383

Epoch: 6| Step: 4
Training loss: 0.5592357174392886
Validation loss: 2.619376450785451

Epoch: 6| Step: 5
Training loss: 0.4184305545438433
Validation loss: 2.6131419044073803

Epoch: 6| Step: 6
Training loss: 0.662068233505857
Validation loss: 2.6628316970472232

Epoch: 6| Step: 7
Training loss: 0.7936224286747787
Validation loss: 2.6608594197216586

Epoch: 6| Step: 8
Training loss: 0.7005068246984114
Validation loss: 2.6618518996293776

Epoch: 6| Step: 9
Training loss: 0.5709126854709803
Validation loss: 2.611451008245659

Epoch: 6| Step: 10
Training loss: 0.5454531851574523
Validation loss: 2.639661887688367

Epoch: 6| Step: 11
Training loss: 0.5845128350720912
Validation loss: 2.630277639129995

Epoch: 6| Step: 12
Training loss: 0.6558741446871712
Validation loss: 2.599317570014719

Epoch: 6| Step: 13
Training loss: 0.589708198988663
Validation loss: 2.651043702589406

Epoch: 300| Step: 0
Training loss: 0.5363031057813781
Validation loss: 2.6221669618764953

Epoch: 6| Step: 1
Training loss: 0.6558308398075356
Validation loss: 2.6333408243714787

Epoch: 6| Step: 2
Training loss: 0.8795881550661387
Validation loss: 2.615264164311549

Epoch: 6| Step: 3
Training loss: 0.6793471613341686
Validation loss: 2.631636822419763

Epoch: 6| Step: 4
Training loss: 0.6219045277395275
Validation loss: 2.6369032014647735

Epoch: 6| Step: 5
Training loss: 0.5321979760008568
Validation loss: 2.632525883434127

Epoch: 6| Step: 6
Training loss: 0.48689870798664636
Validation loss: 2.60799974219456

Epoch: 6| Step: 7
Training loss: 0.46833207255269554
Validation loss: 2.637550944719014

Epoch: 6| Step: 8
Training loss: 0.671596069987978
Validation loss: 2.666666754471357

Epoch: 6| Step: 9
Training loss: 0.5444909035664598
Validation loss: 2.6347252897339852

Epoch: 6| Step: 10
Training loss: 0.29968506604221584
Validation loss: 2.6003923145397585

Epoch: 6| Step: 11
Training loss: 0.4495118719014088
Validation loss: 2.592701873740268

Epoch: 6| Step: 12
Training loss: 0.7120191289871644
Validation loss: 2.5776053274373

Epoch: 6| Step: 13
Training loss: 0.8473531998732218
Validation loss: 2.566201179025258

Epoch: 301| Step: 0
Training loss: 0.6552831248265162
Validation loss: 2.547514187962296

Epoch: 6| Step: 1
Training loss: 0.7382588862508578
Validation loss: 2.56624587299569

Epoch: 6| Step: 2
Training loss: 0.5176165296593424
Validation loss: 2.566317003224541

Epoch: 6| Step: 3
Training loss: 0.7470762963148837
Validation loss: 2.5851183495631105

Epoch: 6| Step: 4
Training loss: 0.34018547591406745
Validation loss: 2.550745586863367

Epoch: 6| Step: 5
Training loss: 0.43363952395103805
Validation loss: 2.5779098202179713

Epoch: 6| Step: 6
Training loss: 0.3654804522731233
Validation loss: 2.534270696748306

Epoch: 6| Step: 7
Training loss: 0.827526956217132
Validation loss: 2.544544428236748

Epoch: 6| Step: 8
Training loss: 0.7121387017384769
Validation loss: 2.5220401762938245

Epoch: 6| Step: 9
Training loss: 0.39518607911290826
Validation loss: 2.521311884784601

Epoch: 6| Step: 10
Training loss: 0.6624979774876079
Validation loss: 2.542734423804395

Epoch: 6| Step: 11
Training loss: 0.5385308062296404
Validation loss: 2.561260907746041

Epoch: 6| Step: 12
Training loss: 0.5928670944307695
Validation loss: 2.539731786215983

Epoch: 6| Step: 13
Training loss: 0.7334112783392347
Validation loss: 2.534449657739874

Epoch: 302| Step: 0
Training loss: 0.7574287701470456
Validation loss: 2.4931590753955795

Epoch: 6| Step: 1
Training loss: 0.38299293547531726
Validation loss: 2.549064425434656

Epoch: 6| Step: 2
Training loss: 0.7519125791245019
Validation loss: 2.553884741801115

Epoch: 6| Step: 3
Training loss: 0.797206360980016
Validation loss: 2.5671578250443363

Epoch: 6| Step: 4
Training loss: 0.7478297144960474
Validation loss: 2.588554794454192

Epoch: 6| Step: 5
Training loss: 0.4273458309924909
Validation loss: 2.570343720558516

Epoch: 6| Step: 6
Training loss: 0.4602001240511698
Validation loss: 2.587491726229217

Epoch: 6| Step: 7
Training loss: 0.3002585042389145
Validation loss: 2.614168817103184

Epoch: 6| Step: 8
Training loss: 0.4861601573936398
Validation loss: 2.6096436237814022

Epoch: 6| Step: 9
Training loss: 0.6985295271356682
Validation loss: 2.5881153553803813

Epoch: 6| Step: 10
Training loss: 0.4944253184322773
Validation loss: 2.6244328321204096

Epoch: 6| Step: 11
Training loss: 0.49060606828840725
Validation loss: 2.6204419993748207

Epoch: 6| Step: 12
Training loss: 0.7112783097195946
Validation loss: 2.610402791566683

Epoch: 6| Step: 13
Training loss: 0.3649808646437912
Validation loss: 2.6328538811251385

Epoch: 303| Step: 0
Training loss: 0.41715887521558853
Validation loss: 2.629208304450245

Epoch: 6| Step: 1
Training loss: 0.5964230299146438
Validation loss: 2.5599316647565127

Epoch: 6| Step: 2
Training loss: 0.73258482074149
Validation loss: 2.6119832765039805

Epoch: 6| Step: 3
Training loss: 0.5497694529326531
Validation loss: 2.5796838596240024

Epoch: 6| Step: 4
Training loss: 0.5397416963738061
Validation loss: 2.605001637802316

Epoch: 6| Step: 5
Training loss: 0.8120159761520231
Validation loss: 2.570581687308508

Epoch: 6| Step: 6
Training loss: 0.2641061667729464
Validation loss: 2.5862900386107848

Epoch: 6| Step: 7
Training loss: 0.6703564982879673
Validation loss: 2.5441935848453885

Epoch: 6| Step: 8
Training loss: 0.47629683547121004
Validation loss: 2.5297819139298174

Epoch: 6| Step: 9
Training loss: 0.5058902451216597
Validation loss: 2.536927894423833

Epoch: 6| Step: 10
Training loss: 0.6914868496398123
Validation loss: 2.537666789110381

Epoch: 6| Step: 11
Training loss: 0.5058695670614479
Validation loss: 2.5217982430017694

Epoch: 6| Step: 12
Training loss: 0.39476429316788436
Validation loss: 2.52956241150259

Epoch: 6| Step: 13
Training loss: 0.8846216147739245
Validation loss: 2.518293423417202

Epoch: 304| Step: 0
Training loss: 0.6495901227656999
Validation loss: 2.5057415527254796

Epoch: 6| Step: 1
Training loss: 0.32088523925832485
Validation loss: 2.512632010770295

Epoch: 6| Step: 2
Training loss: 0.7716332786853802
Validation loss: 2.5005216464463214

Epoch: 6| Step: 3
Training loss: 0.5004897996832911
Validation loss: 2.5233631098304867

Epoch: 6| Step: 4
Training loss: 0.6829754676392477
Validation loss: 2.521417711932183

Epoch: 6| Step: 5
Training loss: 0.2940943394043885
Validation loss: 2.5361670273969774

Epoch: 6| Step: 6
Training loss: 0.7883056183177937
Validation loss: 2.5472883750528537

Epoch: 6| Step: 7
Training loss: 0.6002066554379626
Validation loss: 2.5309734661846983

Epoch: 6| Step: 8
Training loss: 0.5788172623867113
Validation loss: 2.557045416323409

Epoch: 6| Step: 9
Training loss: 0.44106032733725364
Validation loss: 2.55835834751952

Epoch: 6| Step: 10
Training loss: 0.678946386979163
Validation loss: 2.554856030026716

Epoch: 6| Step: 11
Training loss: 0.40747116024844227
Validation loss: 2.5389997980975343

Epoch: 6| Step: 12
Training loss: 0.7256528020061993
Validation loss: 2.5708939757675178

Epoch: 6| Step: 13
Training loss: 0.16147569529696268
Validation loss: 2.5248155944433432

Epoch: 305| Step: 0
Training loss: 0.6504128025615439
Validation loss: 2.5714457502457018

Epoch: 6| Step: 1
Training loss: 0.5907365723842316
Validation loss: 2.5303068501665607

Epoch: 6| Step: 2
Training loss: 0.48329409619539143
Validation loss: 2.574214623025434

Epoch: 6| Step: 3
Training loss: 0.4840784087746812
Validation loss: 2.600631995334653

Epoch: 6| Step: 4
Training loss: 0.6198654504876211
Validation loss: 2.6419368959964733

Epoch: 6| Step: 5
Training loss: 0.3525761930825683
Validation loss: 2.644593401188676

Epoch: 6| Step: 6
Training loss: 0.7760121811421951
Validation loss: 2.603250030314602

Epoch: 6| Step: 7
Training loss: 0.4927855899505256
Validation loss: 2.6172771518702143

Epoch: 6| Step: 8
Training loss: 0.2686531302614947
Validation loss: 2.6018442375036397

Epoch: 6| Step: 9
Training loss: 0.7805652287661776
Validation loss: 2.6038107456917707

Epoch: 6| Step: 10
Training loss: 0.5615674076279826
Validation loss: 2.5939060806180696

Epoch: 6| Step: 11
Training loss: 0.62573689888176
Validation loss: 2.5737095186187506

Epoch: 6| Step: 12
Training loss: 0.7701922448558557
Validation loss: 2.5636917522407243

Epoch: 6| Step: 13
Training loss: 0.23375428976110785
Validation loss: 2.577563059332147

Epoch: 306| Step: 0
Training loss: 0.5501888416953835
Validation loss: 2.5282769263846623

Epoch: 6| Step: 1
Training loss: 0.24333018254881317
Validation loss: 2.587595307458199

Epoch: 6| Step: 2
Training loss: 0.5379671772300383
Validation loss: 2.5866579547234694

Epoch: 6| Step: 3
Training loss: 0.8341159761393186
Validation loss: 2.5706086850699665

Epoch: 6| Step: 4
Training loss: 0.7472104009790675
Validation loss: 2.5981203737703464

Epoch: 6| Step: 5
Training loss: 0.5465754097078594
Validation loss: 2.573680369438538

Epoch: 6| Step: 6
Training loss: 0.5483940281172065
Validation loss: 2.559126157835071

Epoch: 6| Step: 7
Training loss: 0.2700495780796738
Validation loss: 2.571382995537047

Epoch: 6| Step: 8
Training loss: 0.5609129132591206
Validation loss: 2.5558443872247176

Epoch: 6| Step: 9
Training loss: 0.4398811121193742
Validation loss: 2.578979273092139

Epoch: 6| Step: 10
Training loss: 0.5874064025992356
Validation loss: 2.5796905129787757

Epoch: 6| Step: 11
Training loss: 0.4556273392040345
Validation loss: 2.5413396299807753

Epoch: 6| Step: 12
Training loss: 0.8092322661867016
Validation loss: 2.5700533378688726

Epoch: 6| Step: 13
Training loss: 0.6912191320980742
Validation loss: 2.5514560887137554

Epoch: 307| Step: 0
Training loss: 0.642557717784803
Validation loss: 2.5962121423776994

Epoch: 6| Step: 1
Training loss: 0.7506791854218813
Validation loss: 2.5799354220078965

Epoch: 6| Step: 2
Training loss: 0.741227703884913
Validation loss: 2.5818737907193454

Epoch: 6| Step: 3
Training loss: 0.5445634763970055
Validation loss: 2.567902185754178

Epoch: 6| Step: 4
Training loss: 0.3019097201992213
Validation loss: 2.5766720811612696

Epoch: 6| Step: 5
Training loss: 0.6153900433952021
Validation loss: 2.554718178958154

Epoch: 6| Step: 6
Training loss: 0.4378899981777527
Validation loss: 2.596200863651102

Epoch: 6| Step: 7
Training loss: 0.3711277193282691
Validation loss: 2.588132339182135

Epoch: 6| Step: 8
Training loss: 0.39705166376531753
Validation loss: 2.587912214687915

Epoch: 6| Step: 9
Training loss: 0.6222873710285686
Validation loss: 2.6004338862416936

Epoch: 6| Step: 10
Training loss: 0.3974414792558267
Validation loss: 2.5787791327487835

Epoch: 6| Step: 11
Training loss: 0.742493897486825
Validation loss: 2.5719496386156737

Epoch: 6| Step: 12
Training loss: 0.6193114806091868
Validation loss: 2.5897289260505687

Epoch: 6| Step: 13
Training loss: 0.5029831348648134
Validation loss: 2.557872153882036

Epoch: 308| Step: 0
Training loss: 0.6490469217428277
Validation loss: 2.6084530828809456

Epoch: 6| Step: 1
Training loss: 0.32110437343129333
Validation loss: 2.5796288979839517

Epoch: 6| Step: 2
Training loss: 0.5756371295740305
Validation loss: 2.6095917442042555

Epoch: 6| Step: 3
Training loss: 0.5715266328781895
Validation loss: 2.6332057102888

Epoch: 6| Step: 4
Training loss: 0.6415510230285084
Validation loss: 2.6314307596023014

Epoch: 6| Step: 5
Training loss: 0.5940596877126333
Validation loss: 2.6576847812343427

Epoch: 6| Step: 6
Training loss: 0.6897579308220142
Validation loss: 2.643305116988106

Epoch: 6| Step: 7
Training loss: 0.17707871449748633
Validation loss: 2.6139198333676683

Epoch: 6| Step: 8
Training loss: 0.473658232645807
Validation loss: 2.638409605544213

Epoch: 6| Step: 9
Training loss: 0.5274733772610493
Validation loss: 2.61964260455127

Epoch: 6| Step: 10
Training loss: 0.7921635340088196
Validation loss: 2.5588933342690288

Epoch: 6| Step: 11
Training loss: 0.5495632312222729
Validation loss: 2.5913180432493546

Epoch: 6| Step: 12
Training loss: 0.7276746789893339
Validation loss: 2.6005875946182955

Epoch: 6| Step: 13
Training loss: 0.3766006046817542
Validation loss: 2.618556965150933

Epoch: 309| Step: 0
Training loss: 0.4885770893336649
Validation loss: 2.6362603227559345

Epoch: 6| Step: 1
Training loss: 0.6811114555310134
Validation loss: 2.613359435869116

Epoch: 6| Step: 2
Training loss: 0.40612086664587344
Validation loss: 2.6073875411159215

Epoch: 6| Step: 3
Training loss: 0.8221181343073813
Validation loss: 2.6391767683386007

Epoch: 6| Step: 4
Training loss: 0.4649373769635616
Validation loss: 2.5894686227511845

Epoch: 6| Step: 5
Training loss: 0.38454242952007767
Validation loss: 2.603462593308959

Epoch: 6| Step: 6
Training loss: 0.428335942558525
Validation loss: 2.5904996768232906

Epoch: 6| Step: 7
Training loss: 0.561873351827714
Validation loss: 2.5527339270944776

Epoch: 6| Step: 8
Training loss: 0.48602365055151
Validation loss: 2.5591779595326107

Epoch: 6| Step: 9
Training loss: 0.6167275851892337
Validation loss: 2.5289771965019066

Epoch: 6| Step: 10
Training loss: 0.46220388856710426
Validation loss: 2.5335551301086547

Epoch: 6| Step: 11
Training loss: 0.5949907890376218
Validation loss: 2.496316638997181

Epoch: 6| Step: 12
Training loss: 0.8170466489466012
Validation loss: 2.553756730459968

Epoch: 6| Step: 13
Training loss: 0.6277056304674252
Validation loss: 2.558088706253225

Epoch: 310| Step: 0
Training loss: 0.49080749082079717
Validation loss: 2.557811846474203

Epoch: 6| Step: 1
Training loss: 0.5273959946360585
Validation loss: 2.5697162084988605

Epoch: 6| Step: 2
Training loss: 0.6890937581833222
Validation loss: 2.597996681389605

Epoch: 6| Step: 3
Training loss: 0.5542619711684749
Validation loss: 2.563885426563311

Epoch: 6| Step: 4
Training loss: 0.4095987254607685
Validation loss: 2.5300555756506653

Epoch: 6| Step: 5
Training loss: 0.6460930830042209
Validation loss: 2.541123980484535

Epoch: 6| Step: 6
Training loss: 0.7151074366113889
Validation loss: 2.5461815205043474

Epoch: 6| Step: 7
Training loss: 0.6387376430607692
Validation loss: 2.5559403963989595

Epoch: 6| Step: 8
Training loss: 0.5817947419210574
Validation loss: 2.544243864761507

Epoch: 6| Step: 9
Training loss: 0.6333687303924279
Validation loss: 2.5294752767480304

Epoch: 6| Step: 10
Training loss: 0.45675655815352245
Validation loss: 2.560225084472619

Epoch: 6| Step: 11
Training loss: 0.5717183904446005
Validation loss: 2.545596521752417

Epoch: 6| Step: 12
Training loss: 0.5562206089098659
Validation loss: 2.543607615883872

Epoch: 6| Step: 13
Training loss: 0.9139286823620822
Validation loss: 2.555587382770084

Epoch: 311| Step: 0
Training loss: 0.5622476435536031
Validation loss: 2.561918512833369

Epoch: 6| Step: 1
Training loss: 0.3033255189152807
Validation loss: 2.61063872024712

Epoch: 6| Step: 2
Training loss: 0.4380421514989511
Validation loss: 2.570090080198146

Epoch: 6| Step: 3
Training loss: 0.42474670014382193
Validation loss: 2.5835755506232756

Epoch: 6| Step: 4
Training loss: 0.8025871940136791
Validation loss: 2.5997509162217827

Epoch: 6| Step: 5
Training loss: 0.5224926520018
Validation loss: 2.5880981238296834

Epoch: 6| Step: 6
Training loss: 0.5570321028222702
Validation loss: 2.5541751695684884

Epoch: 6| Step: 7
Training loss: 0.5738742339823535
Validation loss: 2.544691258752306

Epoch: 6| Step: 8
Training loss: 0.8109946978615608
Validation loss: 2.5526952522652304

Epoch: 6| Step: 9
Training loss: 0.6004156600110706
Validation loss: 2.550595620148176

Epoch: 6| Step: 10
Training loss: 0.28445269393154843
Validation loss: 2.556976902148383

Epoch: 6| Step: 11
Training loss: 0.5219576969982812
Validation loss: 2.563927635685466

Epoch: 6| Step: 12
Training loss: 0.8027806697963495
Validation loss: 2.5681233146339175

Epoch: 6| Step: 13
Training loss: 0.7753673713329711
Validation loss: 2.565491457649164

Epoch: 312| Step: 0
Training loss: 0.38562212657012485
Validation loss: 2.582942444493149

Epoch: 6| Step: 1
Training loss: 0.40925162327164266
Validation loss: 2.5986489768157

Epoch: 6| Step: 2
Training loss: 0.4424581568810676
Validation loss: 2.6200154057143514

Epoch: 6| Step: 3
Training loss: 0.3988595111389561
Validation loss: 2.6204632435888713

Epoch: 6| Step: 4
Training loss: 0.6429948933548396
Validation loss: 2.6219350830399706

Epoch: 6| Step: 5
Training loss: 0.6417367174462887
Validation loss: 2.615163201393932

Epoch: 6| Step: 6
Training loss: 0.6923278872894525
Validation loss: 2.626922079521102

Epoch: 6| Step: 7
Training loss: 0.48641349625328956
Validation loss: 2.5842645575540053

Epoch: 6| Step: 8
Training loss: 0.5488612480621388
Validation loss: 2.597407954480094

Epoch: 6| Step: 9
Training loss: 0.7295668230597796
Validation loss: 2.5743493039828658

Epoch: 6| Step: 10
Training loss: 0.7679030334979057
Validation loss: 2.5528063265873153

Epoch: 6| Step: 11
Training loss: 0.5610943821919682
Validation loss: 2.595257527198489

Epoch: 6| Step: 12
Training loss: 0.2556102646542244
Validation loss: 2.559182313608302

Epoch: 6| Step: 13
Training loss: 0.4014478913265469
Validation loss: 2.560177568726817

Epoch: 313| Step: 0
Training loss: 0.5448881022607915
Validation loss: 2.6179847224260655

Epoch: 6| Step: 1
Training loss: 0.6301361520798539
Validation loss: 2.576815441426904

Epoch: 6| Step: 2
Training loss: 0.5058148044112767
Validation loss: 2.5737940641659276

Epoch: 6| Step: 3
Training loss: 0.4172760937235817
Validation loss: 2.5849320952023005

Epoch: 6| Step: 4
Training loss: 0.8075060693022632
Validation loss: 2.5824243032494865

Epoch: 6| Step: 5
Training loss: 0.6840816609438126
Validation loss: 2.5340961723974784

Epoch: 6| Step: 6
Training loss: 0.27068931467297525
Validation loss: 2.514733447668865

Epoch: 6| Step: 7
Training loss: 0.3522949430237022
Validation loss: 2.5735038561235903

Epoch: 6| Step: 8
Training loss: 0.5878601826741653
Validation loss: 2.5469745440632687

Epoch: 6| Step: 9
Training loss: 0.4414914816880292
Validation loss: 2.5552892087656693

Epoch: 6| Step: 10
Training loss: 0.5428689000373074
Validation loss: 2.6095042661819643

Epoch: 6| Step: 11
Training loss: 0.5705438170911968
Validation loss: 2.5615539004770413

Epoch: 6| Step: 12
Training loss: 0.3830484324950131
Validation loss: 2.5498521351354304

Epoch: 6| Step: 13
Training loss: 0.35778015190393814
Validation loss: 2.5735342868652937

Epoch: 314| Step: 0
Training loss: 0.6083486178407121
Validation loss: 2.555974920865363

Epoch: 6| Step: 1
Training loss: 0.500259749176941
Validation loss: 2.5676180882690276

Epoch: 6| Step: 2
Training loss: 0.5189161459723787
Validation loss: 2.563421354372225

Epoch: 6| Step: 3
Training loss: 0.5655272141121986
Validation loss: 2.5616038436429647

Epoch: 6| Step: 4
Training loss: 0.5352936171604546
Validation loss: 2.559996167765365

Epoch: 6| Step: 5
Training loss: 0.5309748217401853
Validation loss: 2.5575451652671797

Epoch: 6| Step: 6
Training loss: 0.640498218551767
Validation loss: 2.5854170893694506

Epoch: 6| Step: 7
Training loss: 0.5428475992629452
Validation loss: 2.557193450882915

Epoch: 6| Step: 8
Training loss: 0.39961472672713116
Validation loss: 2.558731896238085

Epoch: 6| Step: 9
Training loss: 0.6044771503802924
Validation loss: 2.5801725756636076

Epoch: 6| Step: 10
Training loss: 0.47173629642186365
Validation loss: 2.5789673543758593

Epoch: 6| Step: 11
Training loss: 0.3157184094356666
Validation loss: 2.6315741918242384

Epoch: 6| Step: 12
Training loss: 0.46642817217299226
Validation loss: 2.5921645663105473

Epoch: 6| Step: 13
Training loss: 0.8202407805562116
Validation loss: 2.5694124623527

Epoch: 315| Step: 0
Training loss: 0.5097021304521049
Validation loss: 2.6094181007370896

Epoch: 6| Step: 1
Training loss: 0.6504511074777213
Validation loss: 2.615242808265117

Epoch: 6| Step: 2
Training loss: 0.5586137567952058
Validation loss: 2.646226959429695

Epoch: 6| Step: 3
Training loss: 0.6111262173904837
Validation loss: 2.61638740280921

Epoch: 6| Step: 4
Training loss: 0.5383360016858055
Validation loss: 2.6264975866481564

Epoch: 6| Step: 5
Training loss: 0.7091637586749918
Validation loss: 2.555909816365335

Epoch: 6| Step: 6
Training loss: 0.44703941788423196
Validation loss: 2.566507247056554

Epoch: 6| Step: 7
Training loss: 0.39593166669178037
Validation loss: 2.571069970283019

Epoch: 6| Step: 8
Training loss: 0.5683849630462096
Validation loss: 2.591429102829639

Epoch: 6| Step: 9
Training loss: 0.31608042011448856
Validation loss: 2.609257988765149

Epoch: 6| Step: 10
Training loss: 0.35113385878388054
Validation loss: 2.579596202184311

Epoch: 6| Step: 11
Training loss: 0.37525531898581654
Validation loss: 2.5420478126181694

Epoch: 6| Step: 12
Training loss: 0.5102131658470339
Validation loss: 2.58383099158377

Epoch: 6| Step: 13
Training loss: 0.6002884538988673
Validation loss: 2.6138155328319126

Epoch: 316| Step: 0
Training loss: 0.6908818427572305
Validation loss: 2.554315018102386

Epoch: 6| Step: 1
Training loss: 0.6563006790211094
Validation loss: 2.5568597459444478

Epoch: 6| Step: 2
Training loss: 0.427621190672731
Validation loss: 2.5732706636905402

Epoch: 6| Step: 3
Training loss: 0.448434543267581
Validation loss: 2.5697774705818492

Epoch: 6| Step: 4
Training loss: 0.4851607440734197
Validation loss: 2.530057959884289

Epoch: 6| Step: 5
Training loss: 0.5561976225978077
Validation loss: 2.5739748428090223

Epoch: 6| Step: 6
Training loss: 0.6351746635067067
Validation loss: 2.5275697122917595

Epoch: 6| Step: 7
Training loss: 0.6804630853042708
Validation loss: 2.503035397700469

Epoch: 6| Step: 8
Training loss: 0.2950460917624007
Validation loss: 2.5177972752404476

Epoch: 6| Step: 9
Training loss: 0.4113265462267248
Validation loss: 2.542588210783538

Epoch: 6| Step: 10
Training loss: 0.41310184529293364
Validation loss: 2.5069609243907425

Epoch: 6| Step: 11
Training loss: 0.5445350176162308
Validation loss: 2.5660167096349507

Epoch: 6| Step: 12
Training loss: 0.4649982035509909
Validation loss: 2.554724932454025

Epoch: 6| Step: 13
Training loss: 0.4354062559017881
Validation loss: 2.573341764621906

Epoch: 317| Step: 0
Training loss: 0.5983008604703719
Validation loss: 2.5762221278682316

Epoch: 6| Step: 1
Training loss: 0.6384057006534807
Validation loss: 2.6070088178153052

Epoch: 6| Step: 2
Training loss: 0.4738148447614508
Validation loss: 2.602425870477269

Epoch: 6| Step: 3
Training loss: 0.48821653318680164
Validation loss: 2.6208956968693324

Epoch: 6| Step: 4
Training loss: 0.4524679352796254
Validation loss: 2.6142804494503156

Epoch: 6| Step: 5
Training loss: 0.4966743405947218
Validation loss: 2.595978404898246

Epoch: 6| Step: 6
Training loss: 0.5009261434960939
Validation loss: 2.6207525048489506

Epoch: 6| Step: 7
Training loss: 0.4207602714467998
Validation loss: 2.595538058115324

Epoch: 6| Step: 8
Training loss: 0.7487661623603483
Validation loss: 2.5423825461312446

Epoch: 6| Step: 9
Training loss: 0.4249810740520354
Validation loss: 2.5362886317021665

Epoch: 6| Step: 10
Training loss: 0.6484595375452656
Validation loss: 2.559840388076211

Epoch: 6| Step: 11
Training loss: 0.36499401077817467
Validation loss: 2.533534793366947

Epoch: 6| Step: 12
Training loss: 0.4563865352814231
Validation loss: 2.5565127887563635

Epoch: 6| Step: 13
Training loss: 0.3923193235097159
Validation loss: 2.5309886870917944

Epoch: 318| Step: 0
Training loss: 0.6196247698899073
Validation loss: 2.5487306665403437

Epoch: 6| Step: 1
Training loss: 0.43044612845851987
Validation loss: 2.582594513477128

Epoch: 6| Step: 2
Training loss: 0.45163890891746333
Validation loss: 2.5725196727064765

Epoch: 6| Step: 3
Training loss: 0.6375284020323955
Validation loss: 2.5712215290912837

Epoch: 6| Step: 4
Training loss: 0.2739264612308433
Validation loss: 2.495497465737467

Epoch: 6| Step: 5
Training loss: 0.419904806100677
Validation loss: 2.50572990360704

Epoch: 6| Step: 6
Training loss: 0.6524310481884107
Validation loss: 2.530474026428208

Epoch: 6| Step: 7
Training loss: 0.38403265990008467
Validation loss: 2.4992960533553474

Epoch: 6| Step: 8
Training loss: 0.7691250808718257
Validation loss: 2.5265505509115496

Epoch: 6| Step: 9
Training loss: 0.23088543610874274
Validation loss: 2.5109509679987503

Epoch: 6| Step: 10
Training loss: 0.3744575829402719
Validation loss: 2.5268407814629836

Epoch: 6| Step: 11
Training loss: 0.8399090408850528
Validation loss: 2.4744078395654916

Epoch: 6| Step: 12
Training loss: 0.6397927390830433
Validation loss: 2.455577369916861

Epoch: 6| Step: 13
Training loss: 0.34819258348899823
Validation loss: 2.514026157965371

Epoch: 319| Step: 0
Training loss: 0.49928015807328996
Validation loss: 2.5760862103032665

Epoch: 6| Step: 1
Training loss: 0.382113519247165
Validation loss: 2.520662826904727

Epoch: 6| Step: 2
Training loss: 0.7580672160469051
Validation loss: 2.583310634924823

Epoch: 6| Step: 3
Training loss: 0.721738655458357
Validation loss: 2.591334198781164

Epoch: 6| Step: 4
Training loss: 0.4865915282207731
Validation loss: 2.6226213423839297

Epoch: 6| Step: 5
Training loss: 0.6867523462889383
Validation loss: 2.640434953909171

Epoch: 6| Step: 6
Training loss: 0.4960910466638635
Validation loss: 2.6234828609944403

Epoch: 6| Step: 7
Training loss: 0.41063159464123195
Validation loss: 2.619315538351996

Epoch: 6| Step: 8
Training loss: 0.4606054694229059
Validation loss: 2.5963310108766424

Epoch: 6| Step: 9
Training loss: 0.4580088210755653
Validation loss: 2.578040486103695

Epoch: 6| Step: 10
Training loss: 0.466340676047865
Validation loss: 2.5911275606484514

Epoch: 6| Step: 11
Training loss: 0.6631264091354484
Validation loss: 2.525297509000337

Epoch: 6| Step: 12
Training loss: 0.4305135416311299
Validation loss: 2.5498544334960966

Epoch: 6| Step: 13
Training loss: 0.42655629303716547
Validation loss: 2.5369150586448574

Epoch: 320| Step: 0
Training loss: 0.540673295658731
Validation loss: 2.581371795864457

Epoch: 6| Step: 1
Training loss: 0.6005373555204695
Validation loss: 2.5493378967370757

Epoch: 6| Step: 2
Training loss: 0.2511721490885187
Validation loss: 2.5735330655782174

Epoch: 6| Step: 3
Training loss: 0.4468993640473459
Validation loss: 2.599390353834653

Epoch: 6| Step: 4
Training loss: 0.3029345558114729
Validation loss: 2.5794502976121185

Epoch: 6| Step: 5
Training loss: 0.5498358817593128
Validation loss: 2.6063118022221787

Epoch: 6| Step: 6
Training loss: 0.4300903512601042
Validation loss: 2.599848487026873

Epoch: 6| Step: 7
Training loss: 0.6534828702262035
Validation loss: 2.5820931740319044

Epoch: 6| Step: 8
Training loss: 0.4499075708567954
Validation loss: 2.5644773292147462

Epoch: 6| Step: 9
Training loss: 0.5800214026875936
Validation loss: 2.5693265932418754

Epoch: 6| Step: 10
Training loss: 0.47633705122037096
Validation loss: 2.5323151059555222

Epoch: 6| Step: 11
Training loss: 0.4529037264168821
Validation loss: 2.557014368261187

Epoch: 6| Step: 12
Training loss: 0.733164540466026
Validation loss: 2.5772581053154644

Epoch: 6| Step: 13
Training loss: 0.41386477229811963
Validation loss: 2.5685558498317493

Epoch: 321| Step: 0
Training loss: 0.42031497741876683
Validation loss: 2.5939438875044107

Epoch: 6| Step: 1
Training loss: 0.5958024989554944
Validation loss: 2.5765272890765716

Epoch: 6| Step: 2
Training loss: 0.6106181302655428
Validation loss: 2.620417696721928

Epoch: 6| Step: 3
Training loss: 0.43475277959692926
Validation loss: 2.5560777613127934

Epoch: 6| Step: 4
Training loss: 0.5873285692774444
Validation loss: 2.5920915200077013

Epoch: 6| Step: 5
Training loss: 0.6668329677188287
Validation loss: 2.5982703167245

Epoch: 6| Step: 6
Training loss: 0.43858641881628735
Validation loss: 2.584773999339833

Epoch: 6| Step: 7
Training loss: 0.5213099841724987
Validation loss: 2.5805915883679345

Epoch: 6| Step: 8
Training loss: 0.591432213559793
Validation loss: 2.594247494767969

Epoch: 6| Step: 9
Training loss: 0.2729172662311015
Validation loss: 2.60196477195489

Epoch: 6| Step: 10
Training loss: 0.5474427954083066
Validation loss: 2.6471056502835233

Epoch: 6| Step: 11
Training loss: 0.4510705346904519
Validation loss: 2.625183136192145

Epoch: 6| Step: 12
Training loss: 0.4275422731769541
Validation loss: 2.624776253488869

Epoch: 6| Step: 13
Training loss: 0.41907353428615784
Validation loss: 2.649987063199284

Epoch: 322| Step: 0
Training loss: 0.559074994838363
Validation loss: 2.6475349756923627

Epoch: 6| Step: 1
Training loss: 0.40069375077570846
Validation loss: 2.659849375794021

Epoch: 6| Step: 2
Training loss: 0.2549468212214553
Validation loss: 2.6566394286395285

Epoch: 6| Step: 3
Training loss: 0.35349237776555215
Validation loss: 2.6614178635049437

Epoch: 6| Step: 4
Training loss: 0.2753104911713592
Validation loss: 2.617254852324558

Epoch: 6| Step: 5
Training loss: 0.3952228225796185
Validation loss: 2.6729289755406214

Epoch: 6| Step: 6
Training loss: 0.6544061370262215
Validation loss: 2.6621986051416564

Epoch: 6| Step: 7
Training loss: 0.5618071527645678
Validation loss: 2.6363192459736884

Epoch: 6| Step: 8
Training loss: 0.373489496768971
Validation loss: 2.6318428691033264

Epoch: 6| Step: 9
Training loss: 0.6243805676766665
Validation loss: 2.6100485658580626

Epoch: 6| Step: 10
Training loss: 0.5764128100424418
Validation loss: 2.601453058543024

Epoch: 6| Step: 11
Training loss: 0.49254965703683357
Validation loss: 2.610924243967606

Epoch: 6| Step: 12
Training loss: 0.5497296622600999
Validation loss: 2.5969705593723895

Epoch: 6| Step: 13
Training loss: 0.7015471237978438
Validation loss: 2.627407120775925

Epoch: 323| Step: 0
Training loss: 0.5017723321948381
Validation loss: 2.6277185027343686

Epoch: 6| Step: 1
Training loss: 0.4534032887882617
Validation loss: 2.5810307321099506

Epoch: 6| Step: 2
Training loss: 0.6423825833165661
Validation loss: 2.5635386292209406

Epoch: 6| Step: 3
Training loss: 0.28953037543867244
Validation loss: 2.598226812017348

Epoch: 6| Step: 4
Training loss: 0.5480343654779155
Validation loss: 2.5970929522198256

Epoch: 6| Step: 5
Training loss: 0.33112666380072925
Validation loss: 2.6256479175651632

Epoch: 6| Step: 6
Training loss: 0.5508302977887576
Validation loss: 2.586903296216642

Epoch: 6| Step: 7
Training loss: 0.6170905314696872
Validation loss: 2.5730085877536166

Epoch: 6| Step: 8
Training loss: 0.3334119475565517
Validation loss: 2.619804260136219

Epoch: 6| Step: 9
Training loss: 0.29985878422165935
Validation loss: 2.569883263153071

Epoch: 6| Step: 10
Training loss: 0.37440061351041165
Validation loss: 2.572846806822305

Epoch: 6| Step: 11
Training loss: 0.8270690231302382
Validation loss: 2.626461138058465

Epoch: 6| Step: 12
Training loss: 0.2404295895759885
Validation loss: 2.6010100070476545

Epoch: 6| Step: 13
Training loss: 0.41664298308138126
Validation loss: 2.583169879035923

Epoch: 324| Step: 0
Training loss: 0.3718711540279741
Validation loss: 2.562452712524359

Epoch: 6| Step: 1
Training loss: 0.3353483334331982
Validation loss: 2.5428822631555095

Epoch: 6| Step: 2
Training loss: 0.35586467115060216
Validation loss: 2.5705559708068995

Epoch: 6| Step: 3
Training loss: 0.49376884617631017
Validation loss: 2.5645887234389595

Epoch: 6| Step: 4
Training loss: 0.5516541510235023
Validation loss: 2.5914363314649798

Epoch: 6| Step: 5
Training loss: 0.35767139001134934
Validation loss: 2.5931682544610637

Epoch: 6| Step: 6
Training loss: 0.5693534207154277
Validation loss: 2.586282932383451

Epoch: 6| Step: 7
Training loss: 0.5429087543960062
Validation loss: 2.5908211367610647

Epoch: 6| Step: 8
Training loss: 0.597309111464699
Validation loss: 2.596801249975161

Epoch: 6| Step: 9
Training loss: 0.5998113832438515
Validation loss: 2.610868032118746

Epoch: 6| Step: 10
Training loss: 0.2762991481101371
Validation loss: 2.6103713400657056

Epoch: 6| Step: 11
Training loss: 0.6248723853480653
Validation loss: 2.6276800417726442

Epoch: 6| Step: 12
Training loss: 0.4319429331456956
Validation loss: 2.5957108829623436

Epoch: 6| Step: 13
Training loss: 0.45179431469300846
Validation loss: 2.6419229304798857

Epoch: 325| Step: 0
Training loss: 0.44832344399090024
Validation loss: 2.57796321894534

Epoch: 6| Step: 1
Training loss: 0.5082938040805063
Validation loss: 2.6111336177425253

Epoch: 6| Step: 2
Training loss: 0.5662748250087902
Validation loss: 2.6047124157094728

Epoch: 6| Step: 3
Training loss: 0.45055752165657154
Validation loss: 2.5978685641226553

Epoch: 6| Step: 4
Training loss: 0.4760283932271764
Validation loss: 2.5965919744065333

Epoch: 6| Step: 5
Training loss: 0.5190222692085301
Validation loss: 2.611614622712162

Epoch: 6| Step: 6
Training loss: 0.44059789114272946
Validation loss: 2.592906828199162

Epoch: 6| Step: 7
Training loss: 0.28561170340458697
Validation loss: 2.6621681440241556

Epoch: 6| Step: 8
Training loss: 0.6881710159063926
Validation loss: 2.6027027855820637

Epoch: 6| Step: 9
Training loss: 0.19765959951706416
Validation loss: 2.6147230465851803

Epoch: 6| Step: 10
Training loss: 0.49511684139322376
Validation loss: 2.6193394685453204

Epoch: 6| Step: 11
Training loss: 0.3805170330140135
Validation loss: 2.610919958995746

Epoch: 6| Step: 12
Training loss: 0.3881391391850867
Validation loss: 2.5831147365063916

Epoch: 6| Step: 13
Training loss: 0.7288730348008717
Validation loss: 2.579493974887568

Epoch: 326| Step: 0
Training loss: 0.40883818876628514
Validation loss: 2.563395259007344

Epoch: 6| Step: 1
Training loss: 0.4634083295350128
Validation loss: 2.642197712132216

Epoch: 6| Step: 2
Training loss: 0.43231286912267836
Validation loss: 2.5637578790693722

Epoch: 6| Step: 3
Training loss: 0.3414360430569597
Validation loss: 2.5658953922057863

Epoch: 6| Step: 4
Training loss: 0.32250459076327115
Validation loss: 2.54359914467342

Epoch: 6| Step: 5
Training loss: 0.2994636559270574
Validation loss: 2.560832712008613

Epoch: 6| Step: 6
Training loss: 0.46659706340295737
Validation loss: 2.5653697646172207

Epoch: 6| Step: 7
Training loss: 0.4213468283009121
Validation loss: 2.553698004373758

Epoch: 6| Step: 8
Training loss: 0.5261551920193732
Validation loss: 2.5606972600714477

Epoch: 6| Step: 9
Training loss: 0.49998056850822037
Validation loss: 2.5729876551592

Epoch: 6| Step: 10
Training loss: 0.5081765263932222
Validation loss: 2.5651999695179994

Epoch: 6| Step: 11
Training loss: 0.6429375799695775
Validation loss: 2.559635593315976

Epoch: 6| Step: 12
Training loss: 0.6641448026031432
Validation loss: 2.5871683077849474

Epoch: 6| Step: 13
Training loss: 0.6685908582767036
Validation loss: 2.551828782473137

Epoch: 327| Step: 0
Training loss: 0.5786285269615948
Validation loss: 2.561130919287309

Epoch: 6| Step: 1
Training loss: 0.39821431510040545
Validation loss: 2.5699711935290614

Epoch: 6| Step: 2
Training loss: 0.4097544018542148
Validation loss: 2.566665577125824

Epoch: 6| Step: 3
Training loss: 0.6163316901576886
Validation loss: 2.5562262834085137

Epoch: 6| Step: 4
Training loss: 0.5285931233654091
Validation loss: 2.558968758829274

Epoch: 6| Step: 5
Training loss: 0.477696211531184
Validation loss: 2.57739071748024

Epoch: 6| Step: 6
Training loss: 0.30908162145602525
Validation loss: 2.552200164699011

Epoch: 6| Step: 7
Training loss: 0.5654570419731159
Validation loss: 2.5826847785274265

Epoch: 6| Step: 8
Training loss: 0.6461114182184039
Validation loss: 2.569059273199955

Epoch: 6| Step: 9
Training loss: 0.4581599684324282
Validation loss: 2.5975604217047987

Epoch: 6| Step: 10
Training loss: 0.31139099510561746
Validation loss: 2.6137151593502357

Epoch: 6| Step: 11
Training loss: 0.42728163217150683
Validation loss: 2.5917789468407078

Epoch: 6| Step: 12
Training loss: 0.4638980895340022
Validation loss: 2.58146797683431

Epoch: 6| Step: 13
Training loss: 0.547203619178716
Validation loss: 2.601730004765088

Epoch: 328| Step: 0
Training loss: 0.5699479492581637
Validation loss: 2.620833219447366

Epoch: 6| Step: 1
Training loss: 0.3438474126986654
Validation loss: 2.5932739726355947

Epoch: 6| Step: 2
Training loss: 0.4576613329614563
Validation loss: 2.5963287205804315

Epoch: 6| Step: 3
Training loss: 0.22668286119021147
Validation loss: 2.6053433666761325

Epoch: 6| Step: 4
Training loss: 0.7024203690436462
Validation loss: 2.612503843309084

Epoch: 6| Step: 5
Training loss: 0.39103560801537535
Validation loss: 2.6330673461041054

Epoch: 6| Step: 6
Training loss: 0.7066616968289042
Validation loss: 2.602673197740772

Epoch: 6| Step: 7
Training loss: 0.3286790937751249
Validation loss: 2.539836697485634

Epoch: 6| Step: 8
Training loss: 0.6491257565363738
Validation loss: 2.5598394677117313

Epoch: 6| Step: 9
Training loss: 0.48506066798240316
Validation loss: 2.543173957979086

Epoch: 6| Step: 10
Training loss: 0.5533775927420644
Validation loss: 2.539743969812857

Epoch: 6| Step: 11
Training loss: 0.30049633800081066
Validation loss: 2.5225892635870997

Epoch: 6| Step: 12
Training loss: 0.4782685245190604
Validation loss: 2.518037182060572

Epoch: 6| Step: 13
Training loss: 0.25973922193762283
Validation loss: 2.559157261669102

Epoch: 329| Step: 0
Training loss: 0.4965832915613616
Validation loss: 2.5494722578264786

Epoch: 6| Step: 1
Training loss: 0.6790845981307904
Validation loss: 2.548050308844618

Epoch: 6| Step: 2
Training loss: 0.31433212131948884
Validation loss: 2.580955694022106

Epoch: 6| Step: 3
Training loss: 0.5125686925116982
Validation loss: 2.616233177350665

Epoch: 6| Step: 4
Training loss: 0.4857573932864494
Validation loss: 2.6334928656684684

Epoch: 6| Step: 5
Training loss: 0.44449092970412907
Validation loss: 2.6763438812400673

Epoch: 6| Step: 6
Training loss: 0.4587192175305555
Validation loss: 2.655105188733702

Epoch: 6| Step: 7
Training loss: 0.5935422634319476
Validation loss: 2.6523393823682935

Epoch: 6| Step: 8
Training loss: 0.4425231845622578
Validation loss: 2.65396684439917

Epoch: 6| Step: 9
Training loss: 0.3638150385099789
Validation loss: 2.6585516091237382

Epoch: 6| Step: 10
Training loss: 0.7050756945792707
Validation loss: 2.652441399426361

Epoch: 6| Step: 11
Training loss: 0.3547881601145028
Validation loss: 2.567313085333345

Epoch: 6| Step: 12
Training loss: 0.22547642415205255
Validation loss: 2.5706837489452354

Epoch: 6| Step: 13
Training loss: 0.5834543636195785
Validation loss: 2.585812520443766

Epoch: 330| Step: 0
Training loss: 0.433671239853471
Validation loss: 2.529516693368254

Epoch: 6| Step: 1
Training loss: 0.5124447746295551
Validation loss: 2.5774318346188108

Epoch: 6| Step: 2
Training loss: 0.5178904904353712
Validation loss: 2.587412416865165

Epoch: 6| Step: 3
Training loss: 0.6263864398277809
Validation loss: 2.578317165577678

Epoch: 6| Step: 4
Training loss: 0.6320071099083587
Validation loss: 2.5439288096628467

Epoch: 6| Step: 5
Training loss: 0.4886146932760619
Validation loss: 2.5454973744899205

Epoch: 6| Step: 6
Training loss: 0.3575444245913163
Validation loss: 2.5193829562035006

Epoch: 6| Step: 7
Training loss: 0.4557124452702189
Validation loss: 2.5916582042581124

Epoch: 6| Step: 8
Training loss: 0.5036363100442147
Validation loss: 2.537332734833194

Epoch: 6| Step: 9
Training loss: 0.5101033111725044
Validation loss: 2.5245065378079046

Epoch: 6| Step: 10
Training loss: 0.4821463195610861
Validation loss: 2.511214900939902

Epoch: 6| Step: 11
Training loss: 0.41161092109825675
Validation loss: 2.565723538593267

Epoch: 6| Step: 12
Training loss: 0.43072201431898427
Validation loss: 2.547644246288352

Epoch: 6| Step: 13
Training loss: 0.3996015449122233
Validation loss: 2.601302256364724

Epoch: 331| Step: 0
Training loss: 0.42335152967398987
Validation loss: 2.5129226888986813

Epoch: 6| Step: 1
Training loss: 0.3784037138192114
Validation loss: 2.5324298059266743

Epoch: 6| Step: 2
Training loss: 0.49202545465452524
Validation loss: 2.564825914498145

Epoch: 6| Step: 3
Training loss: 0.3899123748740941
Validation loss: 2.580876678482446

Epoch: 6| Step: 4
Training loss: 0.37179777722009766
Validation loss: 2.6031303535802968

Epoch: 6| Step: 5
Training loss: 0.2591144171990608
Validation loss: 2.577843091261881

Epoch: 6| Step: 6
Training loss: 0.6539798253094461
Validation loss: 2.580048186782336

Epoch: 6| Step: 7
Training loss: 0.4827429749142138
Validation loss: 2.6003519015709355

Epoch: 6| Step: 8
Training loss: 0.4912695878130108
Validation loss: 2.5682854919274987

Epoch: 6| Step: 9
Training loss: 0.16484114387223858
Validation loss: 2.5716246907087617

Epoch: 6| Step: 10
Training loss: 0.5140657836438155
Validation loss: 2.5813099727125706

Epoch: 6| Step: 11
Training loss: 0.42169676653794025
Validation loss: 2.5575507094433605

Epoch: 6| Step: 12
Training loss: 0.5107937671881545
Validation loss: 2.577966134156938

Epoch: 6| Step: 13
Training loss: 0.5484167709128287
Validation loss: 2.579020490153089

Epoch: 332| Step: 0
Training loss: 0.23555407378676713
Validation loss: 2.595337185055736

Epoch: 6| Step: 1
Training loss: 0.43224378879865594
Validation loss: 2.5988907764658875

Epoch: 6| Step: 2
Training loss: 0.5001149045520709
Validation loss: 2.5856690923825334

Epoch: 6| Step: 3
Training loss: 0.5870764788499795
Validation loss: 2.5465207930965925

Epoch: 6| Step: 4
Training loss: 0.36847576434460366
Validation loss: 2.5432182940501806

Epoch: 6| Step: 5
Training loss: 0.4415679567921816
Validation loss: 2.5516963066743217

Epoch: 6| Step: 6
Training loss: 0.35801736805385426
Validation loss: 2.5703841126282096

Epoch: 6| Step: 7
Training loss: 0.25186939474641584
Validation loss: 2.525756899343217

Epoch: 6| Step: 8
Training loss: 0.16326307624538205
Validation loss: 2.5803712478046266

Epoch: 6| Step: 9
Training loss: 0.4976246259333861
Validation loss: 2.559856999646779

Epoch: 6| Step: 10
Training loss: 0.6943543937365539
Validation loss: 2.5587177671454233

Epoch: 6| Step: 11
Training loss: 0.4143350172243915
Validation loss: 2.56151804804342

Epoch: 6| Step: 12
Training loss: 0.4897374982450387
Validation loss: 2.57643055450722

Epoch: 6| Step: 13
Training loss: 0.5892147980372603
Validation loss: 2.575995745880134

Epoch: 333| Step: 0
Training loss: 0.46193561140770356
Validation loss: 2.570638732224845

Epoch: 6| Step: 1
Training loss: 0.3487297799459602
Validation loss: 2.594173872672222

Epoch: 6| Step: 2
Training loss: 0.6659870309368863
Validation loss: 2.5726779914890097

Epoch: 6| Step: 3
Training loss: 0.36641697491726904
Validation loss: 2.596852866299932

Epoch: 6| Step: 4
Training loss: 0.3513652460066892
Validation loss: 2.5893317609437108

Epoch: 6| Step: 5
Training loss: 0.5195581529578399
Validation loss: 2.6001014833231024

Epoch: 6| Step: 6
Training loss: 0.44396017765477763
Validation loss: 2.6318521657613063

Epoch: 6| Step: 7
Training loss: 0.5424570100864221
Validation loss: 2.6493425540097353

Epoch: 6| Step: 8
Training loss: 0.23587238095218796
Validation loss: 2.623275037721511

Epoch: 6| Step: 9
Training loss: 0.3470000600045232
Validation loss: 2.615352449999781

Epoch: 6| Step: 10
Training loss: 0.2393193846903046
Validation loss: 2.5894446204554717

Epoch: 6| Step: 11
Training loss: 0.7567561938205949
Validation loss: 2.592739495981302

Epoch: 6| Step: 12
Training loss: 0.3840539615014079
Validation loss: 2.5412265720010523

Epoch: 6| Step: 13
Training loss: 0.47319057307506984
Validation loss: 2.5298759167277263

Epoch: 334| Step: 0
Training loss: 0.45711809947037024
Validation loss: 2.5739456702396235

Epoch: 6| Step: 1
Training loss: 0.5025489921789716
Validation loss: 2.5563977465662986

Epoch: 6| Step: 2
Training loss: 0.20868082372228905
Validation loss: 2.597585915270123

Epoch: 6| Step: 3
Training loss: 0.4235253900902088
Validation loss: 2.558547254044561

Epoch: 6| Step: 4
Training loss: 0.3228886102465395
Validation loss: 2.5773981088261144

Epoch: 6| Step: 5
Training loss: 0.3970315474291772
Validation loss: 2.580370030746995

Epoch: 6| Step: 6
Training loss: 0.47580633989899057
Validation loss: 2.558258235537713

Epoch: 6| Step: 7
Training loss: 0.6476307181742967
Validation loss: 2.560555854320375

Epoch: 6| Step: 8
Training loss: 0.4675607854931281
Validation loss: 2.5688946558580823

Epoch: 6| Step: 9
Training loss: 0.5294377044598082
Validation loss: 2.5803369911386733

Epoch: 6| Step: 10
Training loss: 0.32170842869762173
Validation loss: 2.5300745349575933

Epoch: 6| Step: 11
Training loss: 0.5700435265435753
Validation loss: 2.5273603083857137

Epoch: 6| Step: 12
Training loss: 0.4828599955829414
Validation loss: 2.569441941812618

Epoch: 6| Step: 13
Training loss: 0.28841895559424563
Validation loss: 2.5027322943271084

Epoch: 335| Step: 0
Training loss: 0.5434718648389033
Validation loss: 2.517736705407167

Epoch: 6| Step: 1
Training loss: 0.5000567404023529
Validation loss: 2.5186472183920445

Epoch: 6| Step: 2
Training loss: 0.3097453780610682
Validation loss: 2.5337125688910582

Epoch: 6| Step: 3
Training loss: 0.35430682671984887
Validation loss: 2.577260119615176

Epoch: 6| Step: 4
Training loss: 0.48489806942640995
Validation loss: 2.5516871590379964

Epoch: 6| Step: 5
Training loss: 0.5431029887946512
Validation loss: 2.5560941636480705

Epoch: 6| Step: 6
Training loss: 0.589128199184383
Validation loss: 2.5936264016544297

Epoch: 6| Step: 7
Training loss: 0.6478857427578919
Validation loss: 2.595229685414721

Epoch: 6| Step: 8
Training loss: 0.43170124163419243
Validation loss: 2.598539415610957

Epoch: 6| Step: 9
Training loss: 0.6035654485685202
Validation loss: 2.5710071520582534

Epoch: 6| Step: 10
Training loss: 0.22271022644314847
Validation loss: 2.5696276268980505

Epoch: 6| Step: 11
Training loss: 0.29726562399745143
Validation loss: 2.580932405211041

Epoch: 6| Step: 12
Training loss: 0.6603838736959472
Validation loss: 2.5912798522797105

Epoch: 6| Step: 13
Training loss: 0.6198218415766019
Validation loss: 2.6147550232278087

Epoch: 336| Step: 0
Training loss: 0.4340436337011929
Validation loss: 2.5399669273896937

Epoch: 6| Step: 1
Training loss: 0.6061729519836085
Validation loss: 2.5386504868392663

Epoch: 6| Step: 2
Training loss: 0.630378232600819
Validation loss: 2.5706092295898877

Epoch: 6| Step: 3
Training loss: 0.5480433925482673
Validation loss: 2.600924719833494

Epoch: 6| Step: 4
Training loss: 0.4786713016058923
Validation loss: 2.62502820477859

Epoch: 6| Step: 5
Training loss: 0.26269477362027965
Validation loss: 2.631922871498209

Epoch: 6| Step: 6
Training loss: 0.694443663490704
Validation loss: 2.6297175416240717

Epoch: 6| Step: 7
Training loss: 0.34928129562004934
Validation loss: 2.6268116373206434

Epoch: 6| Step: 8
Training loss: 0.32038220368233306
Validation loss: 2.5973774096235944

Epoch: 6| Step: 9
Training loss: 0.7913931616767511
Validation loss: 2.610006512772984

Epoch: 6| Step: 10
Training loss: 0.4269954273037104
Validation loss: 2.577165220018114

Epoch: 6| Step: 11
Training loss: 0.5322237907127508
Validation loss: 2.575683895830927

Epoch: 6| Step: 12
Training loss: 0.4129778312466895
Validation loss: 2.573241089611664

Epoch: 6| Step: 13
Training loss: 0.43705945313672356
Validation loss: 2.569402622487466

Epoch: 337| Step: 0
Training loss: 0.44287166574392844
Validation loss: 2.5621785538270765

Epoch: 6| Step: 1
Training loss: 0.4526191387034043
Validation loss: 2.5379744356100815

Epoch: 6| Step: 2
Training loss: 0.5244151706790403
Validation loss: 2.574085458523243

Epoch: 6| Step: 3
Training loss: 0.30295961676096517
Validation loss: 2.561199148173123

Epoch: 6| Step: 4
Training loss: 0.5374401946396744
Validation loss: 2.5486707096337144

Epoch: 6| Step: 5
Training loss: 0.55398324127361
Validation loss: 2.5444031358757515

Epoch: 6| Step: 6
Training loss: 0.66629966429064
Validation loss: 2.573614392468682

Epoch: 6| Step: 7
Training loss: 0.5328529521542856
Validation loss: 2.537960250555438

Epoch: 6| Step: 8
Training loss: 0.20734509485609204
Validation loss: 2.558281818942933

Epoch: 6| Step: 9
Training loss: 0.4617670159842212
Validation loss: 2.6240388152534107

Epoch: 6| Step: 10
Training loss: 0.6095002608060083
Validation loss: 2.5423719799934847

Epoch: 6| Step: 11
Training loss: 0.6488889478530305
Validation loss: 2.5939810025214807

Epoch: 6| Step: 12
Training loss: 0.3420525820489818
Validation loss: 2.556491060251191

Epoch: 6| Step: 13
Training loss: 0.5034873759155984
Validation loss: 2.5985642504150577

Epoch: 338| Step: 0
Training loss: 0.4421677392918306
Validation loss: 2.614865691316303

Epoch: 6| Step: 1
Training loss: 0.4400333896885923
Validation loss: 2.630397607959471

Epoch: 6| Step: 2
Training loss: 0.47971685238974104
Validation loss: 2.6331865092424267

Epoch: 6| Step: 3
Training loss: 0.5789510135615736
Validation loss: 2.6060433130981133

Epoch: 6| Step: 4
Training loss: 0.6328845512909573
Validation loss: 2.598520086662613

Epoch: 6| Step: 5
Training loss: 0.3670640291441626
Validation loss: 2.608063237734199

Epoch: 6| Step: 6
Training loss: 0.49507694720404605
Validation loss: 2.562788916266845

Epoch: 6| Step: 7
Training loss: 0.3604573660492757
Validation loss: 2.605817746058869

Epoch: 6| Step: 8
Training loss: 0.5198397186737556
Validation loss: 2.6067357290146402

Epoch: 6| Step: 9
Training loss: 0.3223417712329774
Validation loss: 2.6125884566748225

Epoch: 6| Step: 10
Training loss: 0.5732471784280178
Validation loss: 2.6183762753799873

Epoch: 6| Step: 11
Training loss: 0.3768448352919882
Validation loss: 2.6235747621290586

Epoch: 6| Step: 12
Training loss: 0.47244838210632367
Validation loss: 2.596904769858517

Epoch: 6| Step: 13
Training loss: 0.4647978912300344
Validation loss: 2.6099077407560336

Epoch: 339| Step: 0
Training loss: 0.47627795432743675
Validation loss: 2.592330825068348

Epoch: 6| Step: 1
Training loss: 0.4621207357575661
Validation loss: 2.599094188474386

Epoch: 6| Step: 2
Training loss: 0.42260684008368204
Validation loss: 2.627890222860786

Epoch: 6| Step: 3
Training loss: 0.3859963654015941
Validation loss: 2.5982716724115087

Epoch: 6| Step: 4
Training loss: 0.2409060941877021
Validation loss: 2.580299335106516

Epoch: 6| Step: 5
Training loss: 0.7099801628941375
Validation loss: 2.5350979495660964

Epoch: 6| Step: 6
Training loss: 0.23183116056282005
Validation loss: 2.581191103238807

Epoch: 6| Step: 7
Training loss: 0.6225707288569132
Validation loss: 2.580751181162835

Epoch: 6| Step: 8
Training loss: 0.45461437843402686
Validation loss: 2.5635037555961366

Epoch: 6| Step: 9
Training loss: 0.26175326504078233
Validation loss: 2.605778826076427

Epoch: 6| Step: 10
Training loss: 0.4095074926978734
Validation loss: 2.611782249395871

Epoch: 6| Step: 11
Training loss: 0.4197441967170515
Validation loss: 2.6286307840608063

Epoch: 6| Step: 12
Training loss: 0.3616205836124309
Validation loss: 2.6373415804371003

Epoch: 6| Step: 13
Training loss: 0.5169914519416814
Validation loss: 2.6238217353637663

Epoch: 340| Step: 0
Training loss: 0.29554552491878233
Validation loss: 2.640630129946115

Epoch: 6| Step: 1
Training loss: 0.4105959034543973
Validation loss: 2.683577719279595

Epoch: 6| Step: 2
Training loss: 0.5555940392861047
Validation loss: 2.700351606587359

Epoch: 6| Step: 3
Training loss: 0.4351628582108506
Validation loss: 2.675591293189985

Epoch: 6| Step: 4
Training loss: 0.45011507258422806
Validation loss: 2.657399834340644

Epoch: 6| Step: 5
Training loss: 0.46289289449787296
Validation loss: 2.6417111165929104

Epoch: 6| Step: 6
Training loss: 0.4615331938523984
Validation loss: 2.6594933558500786

Epoch: 6| Step: 7
Training loss: 0.2142884881898745
Validation loss: 2.648514457347065

Epoch: 6| Step: 8
Training loss: 0.5469703591177103
Validation loss: 2.6204456025387035

Epoch: 6| Step: 9
Training loss: 0.4048438495560777
Validation loss: 2.6084594142016195

Epoch: 6| Step: 10
Training loss: 0.46249499898217167
Validation loss: 2.6342337091548744

Epoch: 6| Step: 11
Training loss: 0.3850620309287869
Validation loss: 2.6366405518913765

Epoch: 6| Step: 12
Training loss: 0.43332799723286336
Validation loss: 2.6334728397422396

Epoch: 6| Step: 13
Training loss: 0.6040002303138824
Validation loss: 2.6236927832530816

Epoch: 341| Step: 0
Training loss: 0.35175844665842965
Validation loss: 2.627726327152115

Epoch: 6| Step: 1
Training loss: 0.5834967321927077
Validation loss: 2.606805782451194

Epoch: 6| Step: 2
Training loss: 0.5187608269630181
Validation loss: 2.6682465161755182

Epoch: 6| Step: 3
Training loss: 0.38398097241466755
Validation loss: 2.606585722256782

Epoch: 6| Step: 4
Training loss: 0.37807684505047506
Validation loss: 2.637896382403506

Epoch: 6| Step: 5
Training loss: 0.6455138836689132
Validation loss: 2.605981467283381

Epoch: 6| Step: 6
Training loss: 0.5554846824367662
Validation loss: 2.6021007673383174

Epoch: 6| Step: 7
Training loss: 0.19106916991606293
Validation loss: 2.5783862029177556

Epoch: 6| Step: 8
Training loss: 0.27005102653382473
Validation loss: 2.570019100781064

Epoch: 6| Step: 9
Training loss: 0.29541857999030485
Validation loss: 2.5302528676900464

Epoch: 6| Step: 10
Training loss: 0.40413834048174313
Validation loss: 2.605652326215365

Epoch: 6| Step: 11
Training loss: 0.5306858545461359
Validation loss: 2.583501834779163

Epoch: 6| Step: 12
Training loss: 0.311444670187186
Validation loss: 2.583286103032855

Epoch: 6| Step: 13
Training loss: 0.23426555621382067
Validation loss: 2.529565772173456

Epoch: 342| Step: 0
Training loss: 0.3778318332682446
Validation loss: 2.5371527899359907

Epoch: 6| Step: 1
Training loss: 0.4496748060511801
Validation loss: 2.5440312104773053

Epoch: 6| Step: 2
Training loss: 0.369457189868709
Validation loss: 2.5813240913639492

Epoch: 6| Step: 3
Training loss: 0.44596309986695915
Validation loss: 2.557865678303072

Epoch: 6| Step: 4
Training loss: 0.3932654214613177
Validation loss: 2.5578918912172965

Epoch: 6| Step: 5
Training loss: 0.30038117144606985
Validation loss: 2.5824711585150966

Epoch: 6| Step: 6
Training loss: 0.27214296990579273
Validation loss: 2.5620377646670573

Epoch: 6| Step: 7
Training loss: 0.38845761781800026
Validation loss: 2.5619402228251067

Epoch: 6| Step: 8
Training loss: 0.41560522620409474
Validation loss: 2.5448519776826406

Epoch: 6| Step: 9
Training loss: 0.35137902876540206
Validation loss: 2.5502185456839634

Epoch: 6| Step: 10
Training loss: 0.5713536935095507
Validation loss: 2.551884927544094

Epoch: 6| Step: 11
Training loss: 0.5816206539868086
Validation loss: 2.597453371857026

Epoch: 6| Step: 12
Training loss: 0.5857528395541206
Validation loss: 2.5627959530950353

Epoch: 6| Step: 13
Training loss: 0.3955100730548824
Validation loss: 2.5591672919407285

Epoch: 343| Step: 0
Training loss: 0.6919178336236758
Validation loss: 2.531519676578147

Epoch: 6| Step: 1
Training loss: 0.37249341322048474
Validation loss: 2.5460145121908035

Epoch: 6| Step: 2
Training loss: 0.4814038984271606
Validation loss: 2.5681369138188592

Epoch: 6| Step: 3
Training loss: 0.43782319324730296
Validation loss: 2.5628088588147984

Epoch: 6| Step: 4
Training loss: 0.52604911975176
Validation loss: 2.575432864813369

Epoch: 6| Step: 5
Training loss: 0.3562080115955194
Validation loss: 2.5095356701768883

Epoch: 6| Step: 6
Training loss: 0.5156628854878449
Validation loss: 2.623890596923588

Epoch: 6| Step: 7
Training loss: 0.3209104655281742
Validation loss: 2.539754614009348

Epoch: 6| Step: 8
Training loss: 0.42614139409419477
Validation loss: 2.5831347811634444

Epoch: 6| Step: 9
Training loss: 0.2679303489284246
Validation loss: 2.5819318868689485

Epoch: 6| Step: 10
Training loss: 0.3293671823655997
Validation loss: 2.575928564769922

Epoch: 6| Step: 11
Training loss: 0.2037957743555256
Validation loss: 2.6058560692774178

Epoch: 6| Step: 12
Training loss: 0.3940838458143325
Validation loss: 2.5623411383959205

Epoch: 6| Step: 13
Training loss: 0.26459718045972824
Validation loss: 2.5819670378303057

Epoch: 344| Step: 0
Training loss: 0.13875971953397773
Validation loss: 2.5991723947376064

Epoch: 6| Step: 1
Training loss: 0.4917301899343181
Validation loss: 2.6205152082748113

Epoch: 6| Step: 2
Training loss: 0.22436101699866906
Validation loss: 2.5806018077761963

Epoch: 6| Step: 3
Training loss: 0.352659315908049
Validation loss: 2.547127328755692

Epoch: 6| Step: 4
Training loss: 0.3951107528094678
Validation loss: 2.551686022739531

Epoch: 6| Step: 5
Training loss: 0.447491051781553
Validation loss: 2.5658331222168274

Epoch: 6| Step: 6
Training loss: 0.22716475056712204
Validation loss: 2.540205252099989

Epoch: 6| Step: 7
Training loss: 0.4064951670407462
Validation loss: 2.561946921259296

Epoch: 6| Step: 8
Training loss: 0.42440289317222607
Validation loss: 2.567334844071321

Epoch: 6| Step: 9
Training loss: 0.30418704576460354
Validation loss: 2.622561558120692

Epoch: 6| Step: 10
Training loss: 0.6769443711707029
Validation loss: 2.581376913463991

Epoch: 6| Step: 11
Training loss: 0.35894866201191505
Validation loss: 2.5850790425686103

Epoch: 6| Step: 12
Training loss: 0.37223017504761824
Validation loss: 2.5622637960247756

Epoch: 6| Step: 13
Training loss: 0.7096242827962342
Validation loss: 2.575155692765381

Epoch: 345| Step: 0
Training loss: 0.41141860705752514
Validation loss: 2.57971776223779

Epoch: 6| Step: 1
Training loss: 0.48736960183202
Validation loss: 2.611451856427433

Epoch: 6| Step: 2
Training loss: 0.20794529042385546
Validation loss: 2.580781921805789

Epoch: 6| Step: 3
Training loss: 0.521112430815301
Validation loss: 2.5915459763206257

Epoch: 6| Step: 4
Training loss: 0.1806105766510527
Validation loss: 2.5614191207269967

Epoch: 6| Step: 5
Training loss: 0.6248556447214547
Validation loss: 2.5882922762368277

Epoch: 6| Step: 6
Training loss: 0.38494808692327936
Validation loss: 2.567313440824075

Epoch: 6| Step: 7
Training loss: 0.3972548716842356
Validation loss: 2.5564548404843124

Epoch: 6| Step: 8
Training loss: 0.2500423753111013
Validation loss: 2.527565224138642

Epoch: 6| Step: 9
Training loss: 0.22369055856157563
Validation loss: 2.572091940452462

Epoch: 6| Step: 10
Training loss: 0.3607379939935858
Validation loss: 2.5595563823450793

Epoch: 6| Step: 11
Training loss: 0.5161486192224524
Validation loss: 2.540252310853147

Epoch: 6| Step: 12
Training loss: 0.41071004265613376
Validation loss: 2.5367087986169614

Epoch: 6| Step: 13
Training loss: 0.38091598481277417
Validation loss: 2.5601376334696515

Epoch: 346| Step: 0
Training loss: 0.34158839816011205
Validation loss: 2.588856565004706

Epoch: 6| Step: 1
Training loss: 0.4719827124836328
Validation loss: 2.5327596685905736

Epoch: 6| Step: 2
Training loss: 0.3690206948488634
Validation loss: 2.551611701090027

Epoch: 6| Step: 3
Training loss: 0.3395674009427584
Validation loss: 2.5337974058784845

Epoch: 6| Step: 4
Training loss: 0.31685356028104994
Validation loss: 2.5905237000217594

Epoch: 6| Step: 5
Training loss: 0.4634227993177564
Validation loss: 2.538209886038526

Epoch: 6| Step: 6
Training loss: 0.4976817269743141
Validation loss: 2.566613955516488

Epoch: 6| Step: 7
Training loss: 0.24645147360953
Validation loss: 2.587736888613595

Epoch: 6| Step: 8
Training loss: 0.45798817736866765
Validation loss: 2.571187907293199

Epoch: 6| Step: 9
Training loss: 0.4813900000811357
Validation loss: 2.591955822367629

Epoch: 6| Step: 10
Training loss: 0.4852736965173532
Validation loss: 2.5689001605706103

Epoch: 6| Step: 11
Training loss: 0.28363637997866464
Validation loss: 2.557066887470145

Epoch: 6| Step: 12
Training loss: 0.5532370933271787
Validation loss: 2.5622491921399564

Epoch: 6| Step: 13
Training loss: 0.2516613683053354
Validation loss: 2.550681078576686

Epoch: 347| Step: 0
Training loss: 0.3486468314977254
Validation loss: 2.576254976945472

Epoch: 6| Step: 1
Training loss: 0.3522223849311654
Validation loss: 2.5821712756831867

Epoch: 6| Step: 2
Training loss: 0.2690244969501796
Validation loss: 2.572817840677646

Epoch: 6| Step: 3
Training loss: 0.439369414091891
Validation loss: 2.5742182211819586

Epoch: 6| Step: 4
Training loss: 0.3565636216395905
Validation loss: 2.55934895248728

Epoch: 6| Step: 5
Training loss: 0.4173089282877217
Validation loss: 2.562586302945937

Epoch: 6| Step: 6
Training loss: 0.29748511363298985
Validation loss: 2.588850309525867

Epoch: 6| Step: 7
Training loss: 0.48259423146133995
Validation loss: 2.512210375849583

Epoch: 6| Step: 8
Training loss: 0.38286294410149496
Validation loss: 2.582512411173043

Epoch: 6| Step: 9
Training loss: 0.39940827978746735
Validation loss: 2.5257267500146803

Epoch: 6| Step: 10
Training loss: 0.2731869094264503
Validation loss: 2.532470957593939

Epoch: 6| Step: 11
Training loss: 0.5890149489417941
Validation loss: 2.543833642153724

Epoch: 6| Step: 12
Training loss: 0.268613926682799
Validation loss: 2.5941435783024485

Epoch: 6| Step: 13
Training loss: 0.6162723565060286
Validation loss: 2.561374498171112

Epoch: 348| Step: 0
Training loss: 0.19002692839569085
Validation loss: 2.5584514849840176

Epoch: 6| Step: 1
Training loss: 0.41343843467185776
Validation loss: 2.561459128583501

Epoch: 6| Step: 2
Training loss: 0.34099028100988776
Validation loss: 2.5525763558837764

Epoch: 6| Step: 3
Training loss: 0.4129979826806333
Validation loss: 2.5397374702194453

Epoch: 6| Step: 4
Training loss: 0.27517988379649905
Validation loss: 2.557343345463935

Epoch: 6| Step: 5
Training loss: 0.46662773675266755
Validation loss: 2.5622621091182434

Epoch: 6| Step: 6
Training loss: 0.3161226461518225
Validation loss: 2.5375619588663096

Epoch: 6| Step: 7
Training loss: 0.37928974761709294
Validation loss: 2.5525220660021324

Epoch: 6| Step: 8
Training loss: 0.43801810036561495
Validation loss: 2.5483511622783377

Epoch: 6| Step: 9
Training loss: 0.5003297433734947
Validation loss: 2.578303630528455

Epoch: 6| Step: 10
Training loss: 0.434089823632515
Validation loss: 2.588358914584902

Epoch: 6| Step: 11
Training loss: 0.4566271372843508
Validation loss: 2.5608640946895855

Epoch: 6| Step: 12
Training loss: 0.2884690662771166
Validation loss: 2.579645911819926

Epoch: 6| Step: 13
Training loss: 0.5431564336005736
Validation loss: 2.5523570741191612

Epoch: 349| Step: 0
Training loss: 0.3104561727248355
Validation loss: 2.5915909721442385

Epoch: 6| Step: 1
Training loss: 0.21378544329537358
Validation loss: 2.580482224158233

Epoch: 6| Step: 2
Training loss: 0.5691140529317879
Validation loss: 2.6012657316769885

Epoch: 6| Step: 3
Training loss: 0.20201701808168523
Validation loss: 2.5983117921387224

Epoch: 6| Step: 4
Training loss: 0.34303637687241534
Validation loss: 2.5818381112311384

Epoch: 6| Step: 5
Training loss: 0.3856616358611611
Validation loss: 2.609518835986198

Epoch: 6| Step: 6
Training loss: 0.4292499742235766
Validation loss: 2.5797395405688155

Epoch: 6| Step: 7
Training loss: 0.42092159057095535
Validation loss: 2.6153924194546723

Epoch: 6| Step: 8
Training loss: 0.3779999817918844
Validation loss: 2.588691807265026

Epoch: 6| Step: 9
Training loss: 0.31391805534513023
Validation loss: 2.570876569954911

Epoch: 6| Step: 10
Training loss: 0.4721946827097931
Validation loss: 2.5786996448984247

Epoch: 6| Step: 11
Training loss: 0.4670380484072464
Validation loss: 2.5985455737726495

Epoch: 6| Step: 12
Training loss: 0.3902919302987975
Validation loss: 2.578882201547621

Epoch: 6| Step: 13
Training loss: 0.21530273134359
Validation loss: 2.627648530720917

Epoch: 350| Step: 0
Training loss: 0.27546723294503034
Validation loss: 2.574462719721453

Epoch: 6| Step: 1
Training loss: 0.3429126293868644
Validation loss: 2.6041126621348214

Epoch: 6| Step: 2
Training loss: 0.37403096721828755
Validation loss: 2.562430080937588

Epoch: 6| Step: 3
Training loss: 0.4811263507676384
Validation loss: 2.5438213955054074

Epoch: 6| Step: 4
Training loss: 0.5774800337192674
Validation loss: 2.584779402790806

Epoch: 6| Step: 5
Training loss: 0.4703340468429427
Validation loss: 2.605513859599237

Epoch: 6| Step: 6
Training loss: 0.39352447166594007
Validation loss: 2.6078336394179

Epoch: 6| Step: 7
Training loss: 0.29304250424572414
Validation loss: 2.559443626228487

Epoch: 6| Step: 8
Training loss: 0.4813023600642701
Validation loss: 2.5989934057556017

Epoch: 6| Step: 9
Training loss: 0.22867566397824826
Validation loss: 2.570409289279167

Epoch: 6| Step: 10
Training loss: 0.3829531119432727
Validation loss: 2.594731790106305

Epoch: 6| Step: 11
Training loss: 0.2652515141788161
Validation loss: 2.610845185890247

Epoch: 6| Step: 12
Training loss: 0.37409864819855254
Validation loss: 2.6190631334356427

Epoch: 6| Step: 13
Training loss: 0.28605601350924176
Validation loss: 2.598991408793067

Epoch: 351| Step: 0
Training loss: 0.47821421570015804
Validation loss: 2.6102895084082847

Epoch: 6| Step: 1
Training loss: 0.39487440463507567
Validation loss: 2.57154713756279

Epoch: 6| Step: 2
Training loss: 0.16490507612231667
Validation loss: 2.6046642715689305

Epoch: 6| Step: 3
Training loss: 0.1882830599939238
Validation loss: 2.6194243783497986

Epoch: 6| Step: 4
Training loss: 0.4249607018926742
Validation loss: 2.60083219282228

Epoch: 6| Step: 5
Training loss: 0.5492992076300687
Validation loss: 2.583454721346422

Epoch: 6| Step: 6
Training loss: 0.3915210365207329
Validation loss: 2.576019040509068

Epoch: 6| Step: 7
Training loss: 0.473168780922855
Validation loss: 2.5619844893040207

Epoch: 6| Step: 8
Training loss: 0.34109586490494437
Validation loss: 2.568880213416278

Epoch: 6| Step: 9
Training loss: 0.37719912235333874
Validation loss: 2.571748945226442

Epoch: 6| Step: 10
Training loss: 0.5461262618225147
Validation loss: 2.531910757267254

Epoch: 6| Step: 11
Training loss: 0.3460711228528051
Validation loss: 2.5144099141267153

Epoch: 6| Step: 12
Training loss: 0.2871450544751418
Validation loss: 2.5543684218099436

Epoch: 6| Step: 13
Training loss: 0.4104533981048745
Validation loss: 2.5411666231638512

Epoch: 352| Step: 0
Training loss: 0.3358370386768009
Validation loss: 2.5482373756331174

Epoch: 6| Step: 1
Training loss: 0.24282663365571253
Validation loss: 2.5506481800590537

Epoch: 6| Step: 2
Training loss: 0.23334928817072376
Validation loss: 2.5846626131319224

Epoch: 6| Step: 3
Training loss: 0.5030004951482198
Validation loss: 2.549724846354705

Epoch: 6| Step: 4
Training loss: 0.512596338800564
Validation loss: 2.578374060728536

Epoch: 6| Step: 5
Training loss: 0.27855153434144586
Validation loss: 2.5949241845777653

Epoch: 6| Step: 6
Training loss: 0.3585302541860767
Validation loss: 2.569785328758926

Epoch: 6| Step: 7
Training loss: 0.40822247180995697
Validation loss: 2.592617681751877

Epoch: 6| Step: 8
Training loss: 0.5405954319800791
Validation loss: 2.607153245515774

Epoch: 6| Step: 9
Training loss: 0.2296386332656857
Validation loss: 2.5570314949715556

Epoch: 6| Step: 10
Training loss: 0.4741296109378356
Validation loss: 2.5862665153277478

Epoch: 6| Step: 11
Training loss: 0.6245315942293297
Validation loss: 2.566072675153223

Epoch: 6| Step: 12
Training loss: 0.33414129842672924
Validation loss: 2.6025356906591286

Epoch: 6| Step: 13
Training loss: 0.39900358041433215
Validation loss: 2.564565253011377

Epoch: 353| Step: 0
Training loss: 0.4565692261677569
Validation loss: 2.5556215518789753

Epoch: 6| Step: 1
Training loss: 0.4208664848785022
Validation loss: 2.5328624637744612

Epoch: 6| Step: 2
Training loss: 0.2572872851972967
Validation loss: 2.538906762179937

Epoch: 6| Step: 3
Training loss: 0.1853750939500793
Validation loss: 2.5687637617756898

Epoch: 6| Step: 4
Training loss: 0.48301404061256725
Validation loss: 2.5309178681239937

Epoch: 6| Step: 5
Training loss: 0.21411861811790567
Validation loss: 2.543301140680083

Epoch: 6| Step: 6
Training loss: 0.3639177059009954
Validation loss: 2.5734352501567113

Epoch: 6| Step: 7
Training loss: 0.4757988235911273
Validation loss: 2.5720348569984117

Epoch: 6| Step: 8
Training loss: 0.5881616721643373
Validation loss: 2.5838325577487127

Epoch: 6| Step: 9
Training loss: 0.300640568716705
Validation loss: 2.592306866085917

Epoch: 6| Step: 10
Training loss: 0.414732983990291
Validation loss: 2.585576220713716

Epoch: 6| Step: 11
Training loss: 0.44727805174509877
Validation loss: 2.589200920303949

Epoch: 6| Step: 12
Training loss: 0.4142539283609918
Validation loss: 2.5803176112816244

Epoch: 6| Step: 13
Training loss: 0.38551348896275156
Validation loss: 2.606969725822375

Epoch: 354| Step: 0
Training loss: 0.4511175411915257
Validation loss: 2.5651375926998337

Epoch: 6| Step: 1
Training loss: 0.3189664914258717
Validation loss: 2.541911884127204

Epoch: 6| Step: 2
Training loss: 0.3760085847767384
Validation loss: 2.5297137001031356

Epoch: 6| Step: 3
Training loss: 0.32167869062796167
Validation loss: 2.526880183507988

Epoch: 6| Step: 4
Training loss: 0.2411107770404269
Validation loss: 2.5270611533256546

Epoch: 6| Step: 5
Training loss: 0.5026588970158504
Validation loss: 2.5602996577423287

Epoch: 6| Step: 6
Training loss: 0.49545669201747
Validation loss: 2.5374196533110713

Epoch: 6| Step: 7
Training loss: 0.21517999519403982
Validation loss: 2.5031593335864315

Epoch: 6| Step: 8
Training loss: 0.376603196347003
Validation loss: 2.522660251325225

Epoch: 6| Step: 9
Training loss: 0.3119708946396574
Validation loss: 2.5310254531004266

Epoch: 6| Step: 10
Training loss: 0.6154325135897654
Validation loss: 2.56976978446932

Epoch: 6| Step: 11
Training loss: 0.27267338390128487
Validation loss: 2.5272185675687515

Epoch: 6| Step: 12
Training loss: 0.35716008672706984
Validation loss: 2.549781218731824

Epoch: 6| Step: 13
Training loss: 0.44317073421911796
Validation loss: 2.5574087472817784

Epoch: 355| Step: 0
Training loss: 0.26673086754525904
Validation loss: 2.543522309858952

Epoch: 6| Step: 1
Training loss: 0.3925665478873453
Validation loss: 2.554654333957971

Epoch: 6| Step: 2
Training loss: 0.4460677384844881
Validation loss: 2.5745063979671854

Epoch: 6| Step: 3
Training loss: 0.40528698634284605
Validation loss: 2.604707585095609

Epoch: 6| Step: 4
Training loss: 0.6135586153894225
Validation loss: 2.5704626388677774

Epoch: 6| Step: 5
Training loss: 0.3803191045408616
Validation loss: 2.601199756113877

Epoch: 6| Step: 6
Training loss: 0.3123974393392258
Validation loss: 2.6248786925585517

Epoch: 6| Step: 7
Training loss: 0.3251592713508485
Validation loss: 2.5968010071165186

Epoch: 6| Step: 8
Training loss: 0.34324435411270643
Validation loss: 2.5948617753839396

Epoch: 6| Step: 9
Training loss: 0.4383363733288949
Validation loss: 2.6256974246495206

Epoch: 6| Step: 10
Training loss: 0.1922746150748864
Validation loss: 2.584655937860779

Epoch: 6| Step: 11
Training loss: 0.36444551269824066
Validation loss: 2.628278406860821

Epoch: 6| Step: 12
Training loss: 0.3394669932702995
Validation loss: 2.575388937493828

Epoch: 6| Step: 13
Training loss: 0.41443609981101864
Validation loss: 2.5868321825211393

Epoch: 356| Step: 0
Training loss: 0.24643221543586458
Validation loss: 2.5579714734383807

Epoch: 6| Step: 1
Training loss: 0.27772047756529544
Validation loss: 2.5170850328894963

Epoch: 6| Step: 2
Training loss: 0.4365010266450342
Validation loss: 2.516103817279914

Epoch: 6| Step: 3
Training loss: 0.41624029119584405
Validation loss: 2.5402771286480004

Epoch: 6| Step: 4
Training loss: 0.20794847922696585
Validation loss: 2.480665285648998

Epoch: 6| Step: 5
Training loss: 0.487423792408961
Validation loss: 2.48977542142503

Epoch: 6| Step: 6
Training loss: 0.47824819448721506
Validation loss: 2.4842418186851627

Epoch: 6| Step: 7
Training loss: 0.5110564860348952
Validation loss: 2.4987638288550054

Epoch: 6| Step: 8
Training loss: 0.5444271891264261
Validation loss: 2.5418058239952037

Epoch: 6| Step: 9
Training loss: 0.4880302547032609
Validation loss: 2.5154417411076824

Epoch: 6| Step: 10
Training loss: 0.35697899150074175
Validation loss: 2.545257357116091

Epoch: 6| Step: 11
Training loss: 0.4514898855569789
Validation loss: 2.5249142978565207

Epoch: 6| Step: 12
Training loss: 0.3044384403030199
Validation loss: 2.6033251023193604

Epoch: 6| Step: 13
Training loss: 0.3736809738873005
Validation loss: 2.547579439090709

Epoch: 357| Step: 0
Training loss: 0.26238064550220785
Validation loss: 2.5559071061912024

Epoch: 6| Step: 1
Training loss: 0.406148494363765
Validation loss: 2.533390373317524

Epoch: 6| Step: 2
Training loss: 0.595500223593746
Validation loss: 2.531817664377288

Epoch: 6| Step: 3
Training loss: 0.35178990956322886
Validation loss: 2.5075983577017302

Epoch: 6| Step: 4
Training loss: 0.4791966166327481
Validation loss: 2.5357356158161797

Epoch: 6| Step: 5
Training loss: 0.3123443692818056
Validation loss: 2.5395318154633557

Epoch: 6| Step: 6
Training loss: 0.6216519804115509
Validation loss: 2.5499282008753297

Epoch: 6| Step: 7
Training loss: 0.4559132685507079
Validation loss: 2.5677341935042146

Epoch: 6| Step: 8
Training loss: 0.2868154539378861
Validation loss: 2.5429526380306986

Epoch: 6| Step: 9
Training loss: 0.4769058241575127
Validation loss: 2.578255656471919

Epoch: 6| Step: 10
Training loss: 0.2879180936506565
Validation loss: 2.5970589743633585

Epoch: 6| Step: 11
Training loss: 0.22903295792244593
Validation loss: 2.59829049408907

Epoch: 6| Step: 12
Training loss: 0.49965075872492115
Validation loss: 2.5914425050221443

Epoch: 6| Step: 13
Training loss: 0.49690928970634524
Validation loss: 2.56489622477658

Epoch: 358| Step: 0
Training loss: 0.42999932505310673
Validation loss: 2.557649401987727

Epoch: 6| Step: 1
Training loss: 0.28922925469411975
Validation loss: 2.5536473243191025

Epoch: 6| Step: 2
Training loss: 0.5029019542565855
Validation loss: 2.552740745091781

Epoch: 6| Step: 3
Training loss: 0.4112594300786096
Validation loss: 2.5553861788255823

Epoch: 6| Step: 4
Training loss: 0.2810383901317881
Validation loss: 2.5774898259961594

Epoch: 6| Step: 5
Training loss: 0.17748185968383998
Validation loss: 2.545468977362003

Epoch: 6| Step: 6
Training loss: 0.35091134273642743
Validation loss: 2.565984327443413

Epoch: 6| Step: 7
Training loss: 0.465965935999005
Validation loss: 2.5798827442921364

Epoch: 6| Step: 8
Training loss: 0.28858706321466804
Validation loss: 2.5480560537749577

Epoch: 6| Step: 9
Training loss: 0.3300317923627438
Validation loss: 2.529947674821532

Epoch: 6| Step: 10
Training loss: 0.3949734315507968
Validation loss: 2.5540559285340216

Epoch: 6| Step: 11
Training loss: 0.4172722905320662
Validation loss: 2.578411403843021

Epoch: 6| Step: 12
Training loss: 0.5247065689138836
Validation loss: 2.5652965764366136

Epoch: 6| Step: 13
Training loss: 0.48358046062001214
Validation loss: 2.6119371970120873

Epoch: 359| Step: 0
Training loss: 0.29590606679617626
Validation loss: 2.6186011434175724

Epoch: 6| Step: 1
Training loss: 0.3562248488800223
Validation loss: 2.578167065488241

Epoch: 6| Step: 2
Training loss: 0.4703106965698948
Validation loss: 2.619921577295676

Epoch: 6| Step: 3
Training loss: 0.26383471229108113
Validation loss: 2.6316429284602028

Epoch: 6| Step: 4
Training loss: 0.28258006518401607
Validation loss: 2.6050710804944184

Epoch: 6| Step: 5
Training loss: 0.3384702374835326
Validation loss: 2.611887207283834

Epoch: 6| Step: 6
Training loss: 0.2536040929070677
Validation loss: 2.601091148983433

Epoch: 6| Step: 7
Training loss: 0.24489950871897292
Validation loss: 2.566704071415874

Epoch: 6| Step: 8
Training loss: 0.4868927095201545
Validation loss: 2.5659437479701888

Epoch: 6| Step: 9
Training loss: 0.30144381930208947
Validation loss: 2.573241089611664

Epoch: 6| Step: 10
Training loss: 0.41449015503179143
Validation loss: 2.580740215328815

Epoch: 6| Step: 11
Training loss: 0.42252060270017094
Validation loss: 2.5603089448285874

Epoch: 6| Step: 12
Training loss: 0.39711061827566113
Validation loss: 2.5653869449718156

Epoch: 6| Step: 13
Training loss: 0.7070246111310485
Validation loss: 2.5368649457353483

Epoch: 360| Step: 0
Training loss: 0.22363431172097425
Validation loss: 2.553302458805083

Epoch: 6| Step: 1
Training loss: 0.3523683213761081
Validation loss: 2.5568131999065367

Epoch: 6| Step: 2
Training loss: 0.2982041570152392
Validation loss: 2.5621426130776084

Epoch: 6| Step: 3
Training loss: 0.28639654302302153
Validation loss: 2.575835420532678

Epoch: 6| Step: 4
Training loss: 0.3478633178232523
Validation loss: 2.5509688818068037

Epoch: 6| Step: 5
Training loss: 0.48052685083932184
Validation loss: 2.566238581395232

Epoch: 6| Step: 6
Training loss: 0.44479055099287823
Validation loss: 2.5588363671454486

Epoch: 6| Step: 7
Training loss: 0.3399162653585317
Validation loss: 2.5504306634635476

Epoch: 6| Step: 8
Training loss: 0.3087492683726303
Validation loss: 2.5700431857433443

Epoch: 6| Step: 9
Training loss: 0.56427828182858
Validation loss: 2.5301207947257516

Epoch: 6| Step: 10
Training loss: 0.289424798071004
Validation loss: 2.530791317688116

Epoch: 6| Step: 11
Training loss: 0.4494144842551191
Validation loss: 2.5480137603207136

Epoch: 6| Step: 12
Training loss: 0.31146608021945754
Validation loss: 2.5238081802265304

Epoch: 6| Step: 13
Training loss: 0.20280376121608948
Validation loss: 2.525873786329856

Epoch: 361| Step: 0
Training loss: 0.2503054213505219
Validation loss: 2.54015287173255

Epoch: 6| Step: 1
Training loss: 0.27787100681124727
Validation loss: 2.5374291827608166

Epoch: 6| Step: 2
Training loss: 0.3739136616936299
Validation loss: 2.519406947263426

Epoch: 6| Step: 3
Training loss: 0.35998239189372305
Validation loss: 2.544620235796028

Epoch: 6| Step: 4
Training loss: 0.4120499626831771
Validation loss: 2.539760111222234

Epoch: 6| Step: 5
Training loss: 0.40018733376424026
Validation loss: 2.5186747929435183

Epoch: 6| Step: 6
Training loss: 0.46598051823057757
Validation loss: 2.5254830726701063

Epoch: 6| Step: 7
Training loss: 0.15813650683048247
Validation loss: 2.510842947615392

Epoch: 6| Step: 8
Training loss: 0.2893820105129849
Validation loss: 2.5091240244523676

Epoch: 6| Step: 9
Training loss: 0.3870281369049822
Validation loss: 2.5059205777019646

Epoch: 6| Step: 10
Training loss: 0.47985333673160313
Validation loss: 2.5397578461216344

Epoch: 6| Step: 11
Training loss: 0.4772172088967867
Validation loss: 2.533025454401561

Epoch: 6| Step: 12
Training loss: 0.2873928461245655
Validation loss: 2.541556140252209

Epoch: 6| Step: 13
Training loss: 0.31211901328777497
Validation loss: 2.5331257248778947

Epoch: 362| Step: 0
Training loss: 0.3925638148797918
Validation loss: 2.565428222521925

Epoch: 6| Step: 1
Training loss: 0.5721376555903548
Validation loss: 2.548611874400651

Epoch: 6| Step: 2
Training loss: 0.31750252446725424
Validation loss: 2.5368345440274687

Epoch: 6| Step: 3
Training loss: 0.4052767098535998
Validation loss: 2.5887129268038684

Epoch: 6| Step: 4
Training loss: 0.08575628964105093
Validation loss: 2.556804124220289

Epoch: 6| Step: 5
Training loss: 0.4968571983603308
Validation loss: 2.569957624998774

Epoch: 6| Step: 6
Training loss: 0.43123051419671027
Validation loss: 2.5282490167378153

Epoch: 6| Step: 7
Training loss: 0.41181883129394586
Validation loss: 2.560065791296654

Epoch: 6| Step: 8
Training loss: 0.43994826503068635
Validation loss: 2.548377310592721

Epoch: 6| Step: 9
Training loss: 0.3024821676759664
Validation loss: 2.5657958278406

Epoch: 6| Step: 10
Training loss: 0.3466167554015848
Validation loss: 2.586886167585856

Epoch: 6| Step: 11
Training loss: 0.19782353811819417
Validation loss: 2.5228824434892227

Epoch: 6| Step: 12
Training loss: 0.14919909427666095
Validation loss: 2.5688439427897345

Epoch: 6| Step: 13
Training loss: 0.4347992026360332
Validation loss: 2.616074266448826

Epoch: 363| Step: 0
Training loss: 0.426361685772854
Validation loss: 2.5910712398915092

Epoch: 6| Step: 1
Training loss: 0.26341288527389617
Validation loss: 2.6212943603227172

Epoch: 6| Step: 2
Training loss: 0.4115005443344595
Validation loss: 2.6494698068192393

Epoch: 6| Step: 3
Training loss: 0.22986745791174135
Validation loss: 2.6190696603246817

Epoch: 6| Step: 4
Training loss: 0.383405304282245
Validation loss: 2.664485831483092

Epoch: 6| Step: 5
Training loss: 0.27758301904273663
Validation loss: 2.646663644654659

Epoch: 6| Step: 6
Training loss: 0.4364449005821508
Validation loss: 2.6660687797951197

Epoch: 6| Step: 7
Training loss: 0.4768693280163945
Validation loss: 2.64223163249363

Epoch: 6| Step: 8
Training loss: 0.28730936934794626
Validation loss: 2.606150561956074

Epoch: 6| Step: 9
Training loss: 0.4976332648701765
Validation loss: 2.610854080104829

Epoch: 6| Step: 10
Training loss: 0.44075490781547483
Validation loss: 2.541848147116564

Epoch: 6| Step: 11
Training loss: 0.30653549627582455
Validation loss: 2.54868755393771

Epoch: 6| Step: 12
Training loss: 0.48893471288441326
Validation loss: 2.5323750487046475

Epoch: 6| Step: 13
Training loss: 0.23241659366794132
Validation loss: 2.554760904302777

Epoch: 364| Step: 0
Training loss: 0.22914151935162244
Validation loss: 2.5003608853319337

Epoch: 6| Step: 1
Training loss: 0.28942988221290705
Validation loss: 2.513678608230767

Epoch: 6| Step: 2
Training loss: 0.3761621784929229
Validation loss: 2.5207940016094894

Epoch: 6| Step: 3
Training loss: 0.2987273301816727
Validation loss: 2.495292707971119

Epoch: 6| Step: 4
Training loss: 0.6047798667761409
Validation loss: 2.513800382052284

Epoch: 6| Step: 5
Training loss: 0.28435106124307613
Validation loss: 2.5638321685954866

Epoch: 6| Step: 6
Training loss: 0.2947328100433405
Validation loss: 2.5434061186583956

Epoch: 6| Step: 7
Training loss: 0.4617340188640323
Validation loss: 2.5355139352568625

Epoch: 6| Step: 8
Training loss: 0.3149983908975465
Validation loss: 2.5515743435313274

Epoch: 6| Step: 9
Training loss: 0.29313493465758406
Validation loss: 2.558489978611257

Epoch: 6| Step: 10
Training loss: 0.22403014587894374
Validation loss: 2.5421842022616445

Epoch: 6| Step: 11
Training loss: 0.43233859906645444
Validation loss: 2.5801202127969916

Epoch: 6| Step: 12
Training loss: 0.48048977689555616
Validation loss: 2.546939194010736

Epoch: 6| Step: 13
Training loss: 0.15281464474778006
Validation loss: 2.5632242639380154

Epoch: 365| Step: 0
Training loss: 0.28708427994234753
Validation loss: 2.5930398709480094

Epoch: 6| Step: 1
Training loss: 0.332599176623701
Validation loss: 2.5971576886724077

Epoch: 6| Step: 2
Training loss: 0.5229463123059114
Validation loss: 2.60185325412134

Epoch: 6| Step: 3
Training loss: 0.3680727412851939
Validation loss: 2.5790573974721442

Epoch: 6| Step: 4
Training loss: 0.36368452269362556
Validation loss: 2.5989941065909417

Epoch: 6| Step: 5
Training loss: 0.5680613572130891
Validation loss: 2.5792396480084343

Epoch: 6| Step: 6
Training loss: 0.30661275457570464
Validation loss: 2.5546669501503287

Epoch: 6| Step: 7
Training loss: 0.2425504241705311
Validation loss: 2.580061493582973

Epoch: 6| Step: 8
Training loss: 0.4397894017739331
Validation loss: 2.5745305455062666

Epoch: 6| Step: 9
Training loss: 0.2692035119896778
Validation loss: 2.594555053429817

Epoch: 6| Step: 10
Training loss: 0.2680507439934784
Validation loss: 2.5453920751082006

Epoch: 6| Step: 11
Training loss: 0.24783376114258296
Validation loss: 2.5384402321729196

Epoch: 6| Step: 12
Training loss: 0.35859109549277485
Validation loss: 2.521663123084803

Epoch: 6| Step: 13
Training loss: 0.3246483886079794
Validation loss: 2.5835874580036213

Epoch: 366| Step: 0
Training loss: 0.3201878118898837
Validation loss: 2.567257029021907

Epoch: 6| Step: 1
Training loss: 0.2844174363887493
Validation loss: 2.5671361626725284

Epoch: 6| Step: 2
Training loss: 0.32862609112784413
Validation loss: 2.535905469027779

Epoch: 6| Step: 3
Training loss: 0.24282654160754757
Validation loss: 2.557988855818353

Epoch: 6| Step: 4
Training loss: 0.30569846596446804
Validation loss: 2.5721779026281

Epoch: 6| Step: 5
Training loss: 0.3574581023653968
Validation loss: 2.592582170393801

Epoch: 6| Step: 6
Training loss: 0.4691663482500061
Validation loss: 2.598351067668242

Epoch: 6| Step: 7
Training loss: 0.3453631911894269
Validation loss: 2.5876148804929384

Epoch: 6| Step: 8
Training loss: 0.3468960369020086
Validation loss: 2.5884595760443756

Epoch: 6| Step: 9
Training loss: 0.38637550611163546
Validation loss: 2.609933515459506

Epoch: 6| Step: 10
Training loss: 0.47252197565211135
Validation loss: 2.5959789287898225

Epoch: 6| Step: 11
Training loss: 0.3034679998986236
Validation loss: 2.584763001973005

Epoch: 6| Step: 12
Training loss: 0.36740298745602523
Validation loss: 2.5951265719005234

Epoch: 6| Step: 13
Training loss: 0.4450200442289636
Validation loss: 2.5895032516405947

Epoch: 367| Step: 0
Training loss: 0.3908915563919103
Validation loss: 2.6045277052790046

Epoch: 6| Step: 1
Training loss: 0.4226927425968093
Validation loss: 2.575982353886013

Epoch: 6| Step: 2
Training loss: 0.2202322840921202
Validation loss: 2.5595828383568526

Epoch: 6| Step: 3
Training loss: 0.2334604220900833
Validation loss: 2.5803697396465948

Epoch: 6| Step: 4
Training loss: 0.24475803127252863
Validation loss: 2.6292901459654265

Epoch: 6| Step: 5
Training loss: 0.38364182382698575
Validation loss: 2.5783785021992403

Epoch: 6| Step: 6
Training loss: 0.334785548967078
Validation loss: 2.6076514559911317

Epoch: 6| Step: 7
Training loss: 0.4365077175919767
Validation loss: 2.5773034987938575

Epoch: 6| Step: 8
Training loss: 0.4454281974539405
Validation loss: 2.5914243899107787

Epoch: 6| Step: 9
Training loss: 0.23788098032275004
Validation loss: 2.5725149271381156

Epoch: 6| Step: 10
Training loss: 0.2310848970890499
Validation loss: 2.5828839904309895

Epoch: 6| Step: 11
Training loss: 0.4671705338577397
Validation loss: 2.601280671372047

Epoch: 6| Step: 12
Training loss: 0.28404969588358964
Validation loss: 2.53882510505572

Epoch: 6| Step: 13
Training loss: 0.22019086313887043
Validation loss: 2.5863205459016583

Epoch: 368| Step: 0
Training loss: 0.18424398851163434
Validation loss: 2.5818543945953136

Epoch: 6| Step: 1
Training loss: 0.3260167832471693
Validation loss: 2.583607478155406

Epoch: 6| Step: 2
Training loss: 0.5158609948370421
Validation loss: 2.6164517392824695

Epoch: 6| Step: 3
Training loss: 0.4371359195779815
Validation loss: 2.5889868393185584

Epoch: 6| Step: 4
Training loss: 0.36570890474631573
Validation loss: 2.550195941237412

Epoch: 6| Step: 5
Training loss: 0.3176290173357214
Validation loss: 2.5170744517139716

Epoch: 6| Step: 6
Training loss: 0.2677866547798451
Validation loss: 2.5695139448645308

Epoch: 6| Step: 7
Training loss: 0.2873280270015328
Validation loss: 2.5148963033327445

Epoch: 6| Step: 8
Training loss: 0.37099702477997276
Validation loss: 2.5240390357398086

Epoch: 6| Step: 9
Training loss: 0.3873741876261915
Validation loss: 2.5748086222022777

Epoch: 6| Step: 10
Training loss: 0.26705498616106704
Validation loss: 2.566994159361347

Epoch: 6| Step: 11
Training loss: 0.40880332517279355
Validation loss: 2.5679155674747642

Epoch: 6| Step: 12
Training loss: 0.22135087553083363
Validation loss: 2.570220662362129

Epoch: 6| Step: 13
Training loss: 0.3584950911825611
Validation loss: 2.5659448752072587

Epoch: 369| Step: 0
Training loss: 0.2783903736473705
Validation loss: 2.5942343299071484

Epoch: 6| Step: 1
Training loss: 0.44886090496733483
Validation loss: 2.543157813540051

Epoch: 6| Step: 2
Training loss: 0.3160344164227716
Validation loss: 2.5755659452162365

Epoch: 6| Step: 3
Training loss: 0.41179536544531803
Validation loss: 2.547176249403949

Epoch: 6| Step: 4
Training loss: 0.3913802855934884
Validation loss: 2.6049309547075645

Epoch: 6| Step: 5
Training loss: 0.3915831640016804
Validation loss: 2.587129630452301

Epoch: 6| Step: 6
Training loss: 0.4105691012709668
Validation loss: 2.6069116497312232

Epoch: 6| Step: 7
Training loss: 0.4335071545981758
Validation loss: 2.600109072378107

Epoch: 6| Step: 8
Training loss: 0.33535683149531953
Validation loss: 2.6289114574232144

Epoch: 6| Step: 9
Training loss: 0.3972143772194569
Validation loss: 2.623487031637099

Epoch: 6| Step: 10
Training loss: 0.2770446991815937
Validation loss: 2.64035022653293

Epoch: 6| Step: 11
Training loss: 0.17819798965112174
Validation loss: 2.66339186607606

Epoch: 6| Step: 12
Training loss: 0.30308287465479744
Validation loss: 2.612932355026628

Epoch: 6| Step: 13
Training loss: 0.2682297561540268
Validation loss: 2.6104999229981294

Epoch: 370| Step: 0
Training loss: 0.20914173440849165
Validation loss: 2.6269066425246876

Epoch: 6| Step: 1
Training loss: 0.30469755009435284
Validation loss: 2.5868189065853016

Epoch: 6| Step: 2
Training loss: 0.495872117644064
Validation loss: 2.6403349767923108

Epoch: 6| Step: 3
Training loss: 0.31788254349533646
Validation loss: 2.650976513412278

Epoch: 6| Step: 4
Training loss: 0.29776155956788064
Validation loss: 2.6070153404656877

Epoch: 6| Step: 5
Training loss: 0.2635726035408882
Validation loss: 2.5970439240080947

Epoch: 6| Step: 6
Training loss: 0.3629533251581564
Validation loss: 2.5736581159909435

Epoch: 6| Step: 7
Training loss: 0.3860067884510396
Validation loss: 2.585233595463576

Epoch: 6| Step: 8
Training loss: 0.26159648031920485
Validation loss: 2.593611154943104

Epoch: 6| Step: 9
Training loss: 0.3008548225488314
Validation loss: 2.5443772101989857

Epoch: 6| Step: 10
Training loss: 0.4901437865677023
Validation loss: 2.568024621305396

Epoch: 6| Step: 11
Training loss: 0.3710997932343561
Validation loss: 2.545840729470299

Epoch: 6| Step: 12
Training loss: 0.2663847072762273
Validation loss: 2.600143833654483

Epoch: 6| Step: 13
Training loss: 0.5312388923830168
Validation loss: 2.5553200339979596

Epoch: 371| Step: 0
Training loss: 0.2067609047527844
Validation loss: 2.5495806616459156

Epoch: 6| Step: 1
Training loss: 0.2802053761001208
Validation loss: 2.611281060045411

Epoch: 6| Step: 2
Training loss: 0.3253223297143812
Validation loss: 2.5991388854533652

Epoch: 6| Step: 3
Training loss: 0.4950849533874292
Validation loss: 2.6086359640936454

Epoch: 6| Step: 4
Training loss: 0.5394043322352776
Validation loss: 2.6206108623959596

Epoch: 6| Step: 5
Training loss: 0.2725055617018619
Validation loss: 2.624461279386063

Epoch: 6| Step: 6
Training loss: 0.3372657377884822
Validation loss: 2.594184189773668

Epoch: 6| Step: 7
Training loss: 0.30725234663744616
Validation loss: 2.582221025595568

Epoch: 6| Step: 8
Training loss: 0.2757449744900117
Validation loss: 2.6027003354140628

Epoch: 6| Step: 9
Training loss: 0.4682219869326974
Validation loss: 2.5783932811950954

Epoch: 6| Step: 10
Training loss: 0.3497046122484611
Validation loss: 2.6110604970544

Epoch: 6| Step: 11
Training loss: 0.4122326381802774
Validation loss: 2.5669602624781023

Epoch: 6| Step: 12
Training loss: 0.2139409168955701
Validation loss: 2.5948117274016904

Epoch: 6| Step: 13
Training loss: 0.23505097500887545
Validation loss: 2.576999917747281

Epoch: 372| Step: 0
Training loss: 0.29481745759856565
Validation loss: 2.57155511295355

Epoch: 6| Step: 1
Training loss: 0.41727679007883717
Validation loss: 2.5217078536204

Epoch: 6| Step: 2
Training loss: 0.3530062805054737
Validation loss: 2.5369721042017215

Epoch: 6| Step: 3
Training loss: 0.42938735188981947
Validation loss: 2.5375533371472323

Epoch: 6| Step: 4
Training loss: 0.23319657027395385
Validation loss: 2.538202517432995

Epoch: 6| Step: 5
Training loss: 0.4141291438758108
Validation loss: 2.522377778368106

Epoch: 6| Step: 6
Training loss: 0.3009958368723202
Validation loss: 2.502427939229925

Epoch: 6| Step: 7
Training loss: 0.27480479757581944
Validation loss: 2.4767602176710977

Epoch: 6| Step: 8
Training loss: 0.23084861355919414
Validation loss: 2.5301886191391003

Epoch: 6| Step: 9
Training loss: 0.3893622970652046
Validation loss: 2.4955601604350894

Epoch: 6| Step: 10
Training loss: 0.25337136488736
Validation loss: 2.5067756964823547

Epoch: 6| Step: 11
Training loss: 0.39242782372581936
Validation loss: 2.5006241706278622

Epoch: 6| Step: 12
Training loss: 0.40917304131474974
Validation loss: 2.5376789412020186

Epoch: 6| Step: 13
Training loss: 0.41683034860751644
Validation loss: 2.5447116332714046

Epoch: 373| Step: 0
Training loss: 0.2915843552292321
Validation loss: 2.506767083930091

Epoch: 6| Step: 1
Training loss: 0.4452598105596895
Validation loss: 2.5553456449935728

Epoch: 6| Step: 2
Training loss: 0.3892048004848199
Validation loss: 2.5411778142454162

Epoch: 6| Step: 3
Training loss: 0.38944070580059426
Validation loss: 2.5801873861138844

Epoch: 6| Step: 4
Training loss: 0.4455034616166736
Validation loss: 2.53859814003266

Epoch: 6| Step: 5
Training loss: 0.24966602070724422
Validation loss: 2.586942864862522

Epoch: 6| Step: 6
Training loss: 0.3180314698092501
Validation loss: 2.588746203146751

Epoch: 6| Step: 7
Training loss: 0.35789687482018856
Validation loss: 2.579077679423953

Epoch: 6| Step: 8
Training loss: 0.36392546518255064
Validation loss: 2.5744099937552383

Epoch: 6| Step: 9
Training loss: 0.24496282603248046
Validation loss: 2.5750031474120414

Epoch: 6| Step: 10
Training loss: 0.3211772457444851
Validation loss: 2.5701102483809772

Epoch: 6| Step: 11
Training loss: 0.45847275809641563
Validation loss: 2.595176225586611

Epoch: 6| Step: 12
Training loss: 0.3286055724102768
Validation loss: 2.6114436980657434

Epoch: 6| Step: 13
Training loss: 0.27777092233119144
Validation loss: 2.557094006365624

Epoch: 374| Step: 0
Training loss: 0.2732114266019795
Validation loss: 2.5560451609326837

Epoch: 6| Step: 1
Training loss: 0.3966378727581298
Validation loss: 2.556763728177094

Epoch: 6| Step: 2
Training loss: 0.24998579133902957
Validation loss: 2.563945141665897

Epoch: 6| Step: 3
Training loss: 0.47986530773513286
Validation loss: 2.5702007194714365

Epoch: 6| Step: 4
Training loss: 0.3291333463358849
Validation loss: 2.57904409791613

Epoch: 6| Step: 5
Training loss: 0.3349064707611601
Validation loss: 2.5864125661690416

Epoch: 6| Step: 6
Training loss: 0.3406378139920373
Validation loss: 2.582535440046732

Epoch: 6| Step: 7
Training loss: 0.41970241045792495
Validation loss: 2.614710880965174

Epoch: 6| Step: 8
Training loss: 0.20338706387493063
Validation loss: 2.6051232164070113

Epoch: 6| Step: 9
Training loss: 0.33864373966900857
Validation loss: 2.5951876648456635

Epoch: 6| Step: 10
Training loss: 0.31080218682360544
Validation loss: 2.603222424685295

Epoch: 6| Step: 11
Training loss: 0.4476394090929887
Validation loss: 2.570328324767265

Epoch: 6| Step: 12
Training loss: 0.36916542979062633
Validation loss: 2.537658850668774

Epoch: 6| Step: 13
Training loss: 0.25687161622057886
Validation loss: 2.5515025586562983

Epoch: 375| Step: 0
Training loss: 0.2134276537348504
Validation loss: 2.5353127328918355

Epoch: 6| Step: 1
Training loss: 0.5057183440988875
Validation loss: 2.5571289859524455

Epoch: 6| Step: 2
Training loss: 0.35518920302498797
Validation loss: 2.560490463803225

Epoch: 6| Step: 3
Training loss: 0.41287164563286904
Validation loss: 2.552262371547794

Epoch: 6| Step: 4
Training loss: 0.3227687607202129
Validation loss: 2.5973024637936923

Epoch: 6| Step: 5
Training loss: 0.27816232580824807
Validation loss: 2.573019915335797

Epoch: 6| Step: 6
Training loss: 0.37850254221255203
Validation loss: 2.6086160741123137

Epoch: 6| Step: 7
Training loss: 0.1594654572188225
Validation loss: 2.587833248097519

Epoch: 6| Step: 8
Training loss: 0.27965005805159726
Validation loss: 2.6294681689846717

Epoch: 6| Step: 9
Training loss: 0.37238516714475467
Validation loss: 2.611626280039455

Epoch: 6| Step: 10
Training loss: 0.23267053077375544
Validation loss: 2.632629838056674

Epoch: 6| Step: 11
Training loss: 0.41763570475966993
Validation loss: 2.6309374185087844

Epoch: 6| Step: 12
Training loss: 0.5412401084788941
Validation loss: 2.629364327263256

Epoch: 6| Step: 13
Training loss: 0.356810980531147
Validation loss: 2.612431780813539

Epoch: 376| Step: 0
Training loss: 0.4332270403246724
Validation loss: 2.570253750222889

Epoch: 6| Step: 1
Training loss: 0.26237969423195706
Validation loss: 2.639767374452591

Epoch: 6| Step: 2
Training loss: 0.2473223083393391
Validation loss: 2.6020636262653736

Epoch: 6| Step: 3
Training loss: 0.29187260606343546
Validation loss: 2.6232998992811187

Epoch: 6| Step: 4
Training loss: 0.4214840949961781
Validation loss: 2.5975995743729463

Epoch: 6| Step: 5
Training loss: 0.5299843128149989
Validation loss: 2.554012044589112

Epoch: 6| Step: 6
Training loss: 0.29012457874518977
Validation loss: 2.5989891824912124

Epoch: 6| Step: 7
Training loss: 0.2589432023405954
Validation loss: 2.5491514165682454

Epoch: 6| Step: 8
Training loss: 0.4307881736544885
Validation loss: 2.536136896316028

Epoch: 6| Step: 9
Training loss: 0.3691526945855665
Validation loss: 2.519216556138176

Epoch: 6| Step: 10
Training loss: 0.3378802281362254
Validation loss: 2.521688109088354

Epoch: 6| Step: 11
Training loss: 0.2725644205660336
Validation loss: 2.50943411742114

Epoch: 6| Step: 12
Training loss: 0.24288553732583132
Validation loss: 2.4876271386505517

Epoch: 6| Step: 13
Training loss: 0.2890214633165319
Validation loss: 2.489293037288619

Epoch: 377| Step: 0
Training loss: 0.4220412950898569
Validation loss: 2.510457714876879

Epoch: 6| Step: 1
Training loss: 0.20223940769639512
Validation loss: 2.5382572161054417

Epoch: 6| Step: 2
Training loss: 0.4231150028957926
Validation loss: 2.5733875389974252

Epoch: 6| Step: 3
Training loss: 0.20915888692691711
Validation loss: 2.580194871787458

Epoch: 6| Step: 4
Training loss: 0.2895704008663449
Validation loss: 2.5833469182774356

Epoch: 6| Step: 5
Training loss: 0.46869789469722023
Validation loss: 2.5335462225589755

Epoch: 6| Step: 6
Training loss: 0.35819103257995444
Validation loss: 2.555766389841556

Epoch: 6| Step: 7
Training loss: 0.28150607742978784
Validation loss: 2.567537078674358

Epoch: 6| Step: 8
Training loss: 0.3878552469675384
Validation loss: 2.4890647475416037

Epoch: 6| Step: 9
Training loss: 0.3414968318059189
Validation loss: 2.500667140503805

Epoch: 6| Step: 10
Training loss: 0.4712731799387136
Validation loss: 2.518340309334668

Epoch: 6| Step: 11
Training loss: 0.36314512594261833
Validation loss: 2.487663911730908

Epoch: 6| Step: 12
Training loss: 0.2793901461137463
Validation loss: 2.523622465972639

Epoch: 6| Step: 13
Training loss: 0.20962685909140646
Validation loss: 2.524955371993102

Epoch: 378| Step: 0
Training loss: 0.25076565619737146
Validation loss: 2.5205588242567165

Epoch: 6| Step: 1
Training loss: 0.2476416454160579
Validation loss: 2.5175152138649715

Epoch: 6| Step: 2
Training loss: 0.36460444752543386
Validation loss: 2.5133086194307674

Epoch: 6| Step: 3
Training loss: 0.2956057318846001
Validation loss: 2.5425248126287334

Epoch: 6| Step: 4
Training loss: 0.22567321278075794
Validation loss: 2.5698174370985902

Epoch: 6| Step: 5
Training loss: 0.4907231724674679
Validation loss: 2.5805224257426116

Epoch: 6| Step: 6
Training loss: 0.2516670525123678
Validation loss: 2.6124202914530192

Epoch: 6| Step: 7
Training loss: 0.2202384749968334
Validation loss: 2.6312673591779867

Epoch: 6| Step: 8
Training loss: 0.40104890998475334
Validation loss: 2.602189564649527

Epoch: 6| Step: 9
Training loss: 0.46888618080539557
Validation loss: 2.5605457005824626

Epoch: 6| Step: 10
Training loss: 0.28831547789789935
Validation loss: 2.595254378034593

Epoch: 6| Step: 11
Training loss: 0.2658928754596618
Validation loss: 2.5986509271813247

Epoch: 6| Step: 12
Training loss: 0.4248947048180063
Validation loss: 2.582240711220315

Epoch: 6| Step: 13
Training loss: 0.5198637966444817
Validation loss: 2.564549401679405

Epoch: 379| Step: 0
Training loss: 0.18939630895273835
Validation loss: 2.582212246210514

Epoch: 6| Step: 1
Training loss: 0.3406257292538457
Validation loss: 2.5692868171536074

Epoch: 6| Step: 2
Training loss: 0.371659179378298
Validation loss: 2.6009860718319224

Epoch: 6| Step: 3
Training loss: 0.35343330436462556
Validation loss: 2.611449008538233

Epoch: 6| Step: 4
Training loss: 0.22665056621704638
Validation loss: 2.595663079027151

Epoch: 6| Step: 5
Training loss: 0.47395076501134437
Validation loss: 2.621533133433778

Epoch: 6| Step: 6
Training loss: 0.4497864163357197
Validation loss: 2.628741388155899

Epoch: 6| Step: 7
Training loss: 0.23671680991004104
Validation loss: 2.662630666341603

Epoch: 6| Step: 8
Training loss: 0.15745656741074734
Validation loss: 2.634178763562156

Epoch: 6| Step: 9
Training loss: 0.4303608906339075
Validation loss: 2.57895060843672

Epoch: 6| Step: 10
Training loss: 0.36915087811798186
Validation loss: 2.6086937369515995

Epoch: 6| Step: 11
Training loss: 0.4581710101724619
Validation loss: 2.59630849242279

Epoch: 6| Step: 12
Training loss: 0.20595692851180242
Validation loss: 2.6097897455499033

Epoch: 6| Step: 13
Training loss: 0.16204531679368891
Validation loss: 2.6336513665510157

Epoch: 380| Step: 0
Training loss: 0.17659719556688347
Validation loss: 2.589033174790252

Epoch: 6| Step: 1
Training loss: 0.32756212184034766
Validation loss: 2.563694175191268

Epoch: 6| Step: 2
Training loss: 0.28935379094780983
Validation loss: 2.583098773714339

Epoch: 6| Step: 3
Training loss: 0.40325884777870125
Validation loss: 2.6172079919029057

Epoch: 6| Step: 4
Training loss: 0.4101240417913412
Validation loss: 2.622406275328897

Epoch: 6| Step: 5
Training loss: 0.27273954141269724
Validation loss: 2.6135834191909235

Epoch: 6| Step: 6
Training loss: 0.40949493864329395
Validation loss: 2.602697345959729

Epoch: 6| Step: 7
Training loss: 0.4775348655344631
Validation loss: 2.5767841072648094

Epoch: 6| Step: 8
Training loss: 0.36519198248137896
Validation loss: 2.605824310059288

Epoch: 6| Step: 9
Training loss: 0.3297354482522933
Validation loss: 2.585710807599046

Epoch: 6| Step: 10
Training loss: 0.2952162807882643
Validation loss: 2.586705751143871

Epoch: 6| Step: 11
Training loss: 0.337329773889454
Validation loss: 2.579335857794378

Epoch: 6| Step: 12
Training loss: 0.31906566790167246
Validation loss: 2.585481173218027

Epoch: 6| Step: 13
Training loss: 0.49659608954200857
Validation loss: 2.5585474073491383

Epoch: 381| Step: 0
Training loss: 0.2553611738856661
Validation loss: 2.53791632870724

Epoch: 6| Step: 1
Training loss: 0.37654514668474554
Validation loss: 2.5593255151446757

Epoch: 6| Step: 2
Training loss: 0.21190754049786065
Validation loss: 2.6002615675600493

Epoch: 6| Step: 3
Training loss: 0.4498137141459527
Validation loss: 2.638826812686136

Epoch: 6| Step: 4
Training loss: 0.504223331966097
Validation loss: 2.6063437787808157

Epoch: 6| Step: 5
Training loss: 0.4846986181778175
Validation loss: 2.614771760462782

Epoch: 6| Step: 6
Training loss: 0.3418756993546385
Validation loss: 2.608627319306666

Epoch: 6| Step: 7
Training loss: 0.21554174612759003
Validation loss: 2.573110184489787

Epoch: 6| Step: 8
Training loss: 0.37867251787077977
Validation loss: 2.5158773968349024

Epoch: 6| Step: 9
Training loss: 0.38091987716180314
Validation loss: 2.500154306407767

Epoch: 6| Step: 10
Training loss: 0.20379217325694995
Validation loss: 2.4693036074608057

Epoch: 6| Step: 11
Training loss: 0.6508835079090545
Validation loss: 2.4924089023080267

Epoch: 6| Step: 12
Training loss: 0.3891192214860273
Validation loss: 2.4747356409096155

Epoch: 6| Step: 13
Training loss: 0.47153503853712375
Validation loss: 2.4932307751162397

Epoch: 382| Step: 0
Training loss: 0.5000574853753175
Validation loss: 2.52090363356594

Epoch: 6| Step: 1
Training loss: 0.3504259812496359
Validation loss: 2.4714620130065543

Epoch: 6| Step: 2
Training loss: 0.40445024465383034
Validation loss: 2.518150331325103

Epoch: 6| Step: 3
Training loss: 0.29464084296343107
Validation loss: 2.53325511169891

Epoch: 6| Step: 4
Training loss: 0.3515664100429537
Validation loss: 2.566948499682617

Epoch: 6| Step: 5
Training loss: 0.21545503524275383
Validation loss: 2.5947710486880293

Epoch: 6| Step: 6
Training loss: 0.5198221181181725
Validation loss: 2.588947034551338

Epoch: 6| Step: 7
Training loss: 0.4374486518427055
Validation loss: 2.6066769617259404

Epoch: 6| Step: 8
Training loss: 0.4230855598268398
Validation loss: 2.6448742736186786

Epoch: 6| Step: 9
Training loss: 0.4074775233535062
Validation loss: 2.627123034236623

Epoch: 6| Step: 10
Training loss: 0.4112214561458588
Validation loss: 2.6644294651304707

Epoch: 6| Step: 11
Training loss: 0.4926010090218609
Validation loss: 2.637890215033704

Epoch: 6| Step: 12
Training loss: 0.6449080319596948
Validation loss: 2.5936110234799843

Epoch: 6| Step: 13
Training loss: 0.565242466212888
Validation loss: 2.564729797385301

Epoch: 383| Step: 0
Training loss: 0.33340903132926225
Validation loss: 2.548311898308562

Epoch: 6| Step: 1
Training loss: 0.4588143053901383
Validation loss: 2.5264206340158806

Epoch: 6| Step: 2
Training loss: 0.3656958861796875
Validation loss: 2.507528177573597

Epoch: 6| Step: 3
Training loss: 0.4955775060422806
Validation loss: 2.504192446579273

Epoch: 6| Step: 4
Training loss: 0.3670778922580901
Validation loss: 2.5132070028766855

Epoch: 6| Step: 5
Training loss: 0.306991813398299
Validation loss: 2.5168600208051006

Epoch: 6| Step: 6
Training loss: 0.2870271526079519
Validation loss: 2.5118756101179733

Epoch: 6| Step: 7
Training loss: 0.4101637340044514
Validation loss: 2.5471296728537767

Epoch: 6| Step: 8
Training loss: 0.3633702487011613
Validation loss: 2.550682339952806

Epoch: 6| Step: 9
Training loss: 0.30513449427747275
Validation loss: 2.5899760958693343

Epoch: 6| Step: 10
Training loss: 0.3660719544210877
Validation loss: 2.6045640523284144

Epoch: 6| Step: 11
Training loss: 0.5098322390005973
Validation loss: 2.5833779574961766

Epoch: 6| Step: 12
Training loss: 0.3199173653346471
Validation loss: 2.5426687493954927

Epoch: 6| Step: 13
Training loss: 0.3020557303259074
Validation loss: 2.5125649312142553

Epoch: 384| Step: 0
Training loss: 0.3086940988521571
Validation loss: 2.568851778374223

Epoch: 6| Step: 1
Training loss: 0.34110782377571713
Validation loss: 2.519627941833029

Epoch: 6| Step: 2
Training loss: 0.3160784636500445
Validation loss: 2.5306897578349674

Epoch: 6| Step: 3
Training loss: 0.3634559867401505
Validation loss: 2.5155693786378683

Epoch: 6| Step: 4
Training loss: 0.34314725874879076
Validation loss: 2.5450656114814323

Epoch: 6| Step: 5
Training loss: 0.2506560420078375
Validation loss: 2.5620613017751683

Epoch: 6| Step: 6
Training loss: 0.6324081306307031
Validation loss: 2.565225026154854

Epoch: 6| Step: 7
Training loss: 0.3994313168704455
Validation loss: 2.5711346764503733

Epoch: 6| Step: 8
Training loss: 0.2492782186988827
Validation loss: 2.6110004836741534

Epoch: 6| Step: 9
Training loss: 0.30721705010317985
Validation loss: 2.5820549310117626

Epoch: 6| Step: 10
Training loss: 0.3077181211519174
Validation loss: 2.6022379496379573

Epoch: 6| Step: 11
Training loss: 0.47595207016722396
Validation loss: 2.611356300735021

Epoch: 6| Step: 12
Training loss: 0.5844247235853749
Validation loss: 2.6061071946989913

Epoch: 6| Step: 13
Training loss: 0.5069849754341932
Validation loss: 2.559475337948516

Epoch: 385| Step: 0
Training loss: 0.3825795769035859
Validation loss: 2.5423099178580184

Epoch: 6| Step: 1
Training loss: 0.49446011192820744
Validation loss: 2.5033871808237342

Epoch: 6| Step: 2
Training loss: 0.2575696032164131
Validation loss: 2.446339947263365

Epoch: 6| Step: 3
Training loss: 0.29709486599687795
Validation loss: 2.4634239229169927

Epoch: 6| Step: 4
Training loss: 0.31221542514164285
Validation loss: 2.486262871293134

Epoch: 6| Step: 5
Training loss: 0.4648678076152558
Validation loss: 2.430672114126919

Epoch: 6| Step: 6
Training loss: 0.28205550926889067
Validation loss: 2.4910129100470466

Epoch: 6| Step: 7
Training loss: 0.24384385191150076
Validation loss: 2.471704747303546

Epoch: 6| Step: 8
Training loss: 0.27382685324989847
Validation loss: 2.531647083245316

Epoch: 6| Step: 9
Training loss: 0.38894800699941756
Validation loss: 2.540265495100321

Epoch: 6| Step: 10
Training loss: 0.287797117122476
Validation loss: 2.5723986460194004

Epoch: 6| Step: 11
Training loss: 0.36637341773147974
Validation loss: 2.557487824288456

Epoch: 6| Step: 12
Training loss: 0.5156653417353674
Validation loss: 2.562440341762229

Epoch: 6| Step: 13
Training loss: 0.269489575356938
Validation loss: 2.574165015157984

Epoch: 386| Step: 0
Training loss: 0.18784620192112203
Validation loss: 2.5773983485397087

Epoch: 6| Step: 1
Training loss: 0.3974557637245803
Validation loss: 2.570101146334776

Epoch: 6| Step: 2
Training loss: 0.4041036245331256
Validation loss: 2.5935835799136804

Epoch: 6| Step: 3
Training loss: 0.328416399763422
Validation loss: 2.578947906570746

Epoch: 6| Step: 4
Training loss: 0.35647902655868596
Validation loss: 2.58922285501431

Epoch: 6| Step: 5
Training loss: 0.34932594958144697
Validation loss: 2.60359631467902

Epoch: 6| Step: 6
Training loss: 0.3913603727213983
Validation loss: 2.5725408801678094

Epoch: 6| Step: 7
Training loss: 0.32216475092867075
Validation loss: 2.5510292067757967

Epoch: 6| Step: 8
Training loss: 0.2557334444396529
Validation loss: 2.54009138566736

Epoch: 6| Step: 9
Training loss: 0.2143372895128793
Validation loss: 2.5268925013559826

Epoch: 6| Step: 10
Training loss: 0.24628198327607712
Validation loss: 2.5300376234037985

Epoch: 6| Step: 11
Training loss: 0.32459398180364896
Validation loss: 2.4682947779886257

Epoch: 6| Step: 12
Training loss: 0.3176974922686068
Validation loss: 2.5072396930500735

Epoch: 6| Step: 13
Training loss: 0.3135023017369878
Validation loss: 2.4989994754177896

Epoch: 387| Step: 0
Training loss: 0.21223899435573992
Validation loss: 2.530471013446565

Epoch: 6| Step: 1
Training loss: 0.26558786020369857
Validation loss: 2.4772281489070207

Epoch: 6| Step: 2
Training loss: 0.41009913455562064
Validation loss: 2.5034651563019015

Epoch: 6| Step: 3
Training loss: 0.24540640193983568
Validation loss: 2.518064961058198

Epoch: 6| Step: 4
Training loss: 0.39112253928210505
Validation loss: 2.51471516583678

Epoch: 6| Step: 5
Training loss: 0.46527204897502583
Validation loss: 2.482092761212806

Epoch: 6| Step: 6
Training loss: 0.34318919385618113
Validation loss: 2.4960485101189995

Epoch: 6| Step: 7
Training loss: 0.36795570285611234
Validation loss: 2.5032827523048287

Epoch: 6| Step: 8
Training loss: 0.2513941989663361
Validation loss: 2.5208208644324324

Epoch: 6| Step: 9
Training loss: 0.2923975780889362
Validation loss: 2.5314982282531124

Epoch: 6| Step: 10
Training loss: 0.2930043771062048
Validation loss: 2.5177682663352505

Epoch: 6| Step: 11
Training loss: 0.29164332341831933
Validation loss: 2.5520117871265615

Epoch: 6| Step: 12
Training loss: 0.32907213028512367
Validation loss: 2.5232119886008255

Epoch: 6| Step: 13
Training loss: 0.3171084700160565
Validation loss: 2.5708941981383515

Epoch: 388| Step: 0
Training loss: 0.2415531063597471
Validation loss: 2.6087498104103783

Epoch: 6| Step: 1
Training loss: 0.31733447367015144
Validation loss: 2.6009981360597725

Epoch: 6| Step: 2
Training loss: 0.3541749738205182
Validation loss: 2.5962259923736437

Epoch: 6| Step: 3
Training loss: 0.3171134862377176
Validation loss: 2.614530375457912

Epoch: 6| Step: 4
Training loss: 0.14274378519509182
Validation loss: 2.6009917368020914

Epoch: 6| Step: 5
Training loss: 0.4676317545921238
Validation loss: 2.659285779577274

Epoch: 6| Step: 6
Training loss: 0.4192767666067152
Validation loss: 2.6233995053821206

Epoch: 6| Step: 7
Training loss: 0.433317199354716
Validation loss: 2.619798328576545

Epoch: 6| Step: 8
Training loss: 0.18530786077472272
Validation loss: 2.654192594478604

Epoch: 6| Step: 9
Training loss: 0.17935886599590364
Validation loss: 2.59255344304259

Epoch: 6| Step: 10
Training loss: 0.37742356113822345
Validation loss: 2.592510241902203

Epoch: 6| Step: 11
Training loss: 0.3123363543231684
Validation loss: 2.5352780231182854

Epoch: 6| Step: 12
Training loss: 0.19502633111108514
Validation loss: 2.5116385218695583

Epoch: 6| Step: 13
Training loss: 0.1563474232220983
Validation loss: 2.5426779141010707

Epoch: 389| Step: 0
Training loss: 0.33474694581593584
Validation loss: 2.5200281330985685

Epoch: 6| Step: 1
Training loss: 0.43608063976409217
Validation loss: 2.523195359302638

Epoch: 6| Step: 2
Training loss: 0.23794492061227138
Validation loss: 2.5172635760075046

Epoch: 6| Step: 3
Training loss: 0.41779935381000743
Validation loss: 2.5028896741091797

Epoch: 6| Step: 4
Training loss: 0.24284635417053918
Validation loss: 2.526775270243239

Epoch: 6| Step: 5
Training loss: 0.39753216379422124
Validation loss: 2.5127005250804335

Epoch: 6| Step: 6
Training loss: 0.3302553479853907
Validation loss: 2.541243060104506

Epoch: 6| Step: 7
Training loss: 0.28696161477241977
Validation loss: 2.5384298132343295

Epoch: 6| Step: 8
Training loss: 0.23406352963494856
Validation loss: 2.528719962489934

Epoch: 6| Step: 9
Training loss: 0.3770166057046032
Validation loss: 2.5894858303317068

Epoch: 6| Step: 10
Training loss: 0.43608304878863186
Validation loss: 2.590416564239403

Epoch: 6| Step: 11
Training loss: 0.3443724350565465
Validation loss: 2.589744026341511

Epoch: 6| Step: 12
Training loss: 0.17278537452854206
Validation loss: 2.511654426436062

Epoch: 6| Step: 13
Training loss: 0.27077813533569906
Validation loss: 2.492015899450257

Epoch: 390| Step: 0
Training loss: 0.2472038963368045
Validation loss: 2.467721016690832

Epoch: 6| Step: 1
Training loss: 0.26037537565309526
Validation loss: 2.46951539820304

Epoch: 6| Step: 2
Training loss: 0.39326477731633586
Validation loss: 2.4578959717490783

Epoch: 6| Step: 3
Training loss: 0.3500064427770537
Validation loss: 2.463903631596203

Epoch: 6| Step: 4
Training loss: 0.29014813976220694
Validation loss: 2.5326631349533044

Epoch: 6| Step: 5
Training loss: 0.30509062532612224
Validation loss: 2.5313743642794035

Epoch: 6| Step: 6
Training loss: 0.27531713492641197
Validation loss: 2.5245706740484346

Epoch: 6| Step: 7
Training loss: 0.31551991639623755
Validation loss: 2.487404125474833

Epoch: 6| Step: 8
Training loss: 0.3330357895003299
Validation loss: 2.5348560226202226

Epoch: 6| Step: 9
Training loss: 0.30948738888852134
Validation loss: 2.560659182070421

Epoch: 6| Step: 10
Training loss: 0.22668953326764565
Validation loss: 2.545607681777655

Epoch: 6| Step: 11
Training loss: 0.2419174365216891
Validation loss: 2.57006425104737

Epoch: 6| Step: 12
Training loss: 0.6043927383581169
Validation loss: 2.597515273665483

Epoch: 6| Step: 13
Training loss: 0.14084022000317697
Validation loss: 2.572528042703759

Epoch: 391| Step: 0
Training loss: 0.3850802185967545
Validation loss: 2.5577837193690676

Epoch: 6| Step: 1
Training loss: 0.4355852939784664
Validation loss: 2.5206440307298768

Epoch: 6| Step: 2
Training loss: 0.17905846662788769
Validation loss: 2.521928473243418

Epoch: 6| Step: 3
Training loss: 0.355256258154396
Validation loss: 2.5342331665144764

Epoch: 6| Step: 4
Training loss: 0.2942028628257018
Validation loss: 2.5065552292477435

Epoch: 6| Step: 5
Training loss: 0.2877664507870472
Validation loss: 2.490556706240149

Epoch: 6| Step: 6
Training loss: 0.2833959646399707
Validation loss: 2.529297659509546

Epoch: 6| Step: 7
Training loss: 0.24412891359849714
Validation loss: 2.4803436999669186

Epoch: 6| Step: 8
Training loss: 0.19547938846207077
Validation loss: 2.4853264876351306

Epoch: 6| Step: 9
Training loss: 0.38608520322361
Validation loss: 2.4774958006572603

Epoch: 6| Step: 10
Training loss: 0.275823239812159
Validation loss: 2.5053271091369043

Epoch: 6| Step: 11
Training loss: 0.16559333948508148
Validation loss: 2.541554687739116

Epoch: 6| Step: 12
Training loss: 0.35651399133681366
Validation loss: 2.492584529665305

Epoch: 6| Step: 13
Training loss: 0.18921497950746594
Validation loss: 2.485813759518898

Epoch: 392| Step: 0
Training loss: 0.2898230599270252
Validation loss: 2.558614355481967

Epoch: 6| Step: 1
Training loss: 0.4745187712163144
Validation loss: 2.5626591168576116

Epoch: 6| Step: 2
Training loss: 0.3707427925134669
Validation loss: 2.579139472589712

Epoch: 6| Step: 3
Training loss: 0.3204020282024846
Validation loss: 2.5646330556606647

Epoch: 6| Step: 4
Training loss: 0.3606568777252253
Validation loss: 2.5660774895814162

Epoch: 6| Step: 5
Training loss: 0.1370460815189256
Validation loss: 2.5518364397422064

Epoch: 6| Step: 6
Training loss: 0.16834939475692806
Validation loss: 2.565734274847809

Epoch: 6| Step: 7
Training loss: 0.24330035759989324
Validation loss: 2.558500206139168

Epoch: 6| Step: 8
Training loss: 0.21797600122237806
Validation loss: 2.551117804085465

Epoch: 6| Step: 9
Training loss: 0.23658887806800072
Validation loss: 2.574875376531316

Epoch: 6| Step: 10
Training loss: 0.3722208874810582
Validation loss: 2.5368438836681615

Epoch: 6| Step: 11
Training loss: 0.1586609209562879
Validation loss: 2.5283708523094015

Epoch: 6| Step: 12
Training loss: 0.312012936585248
Validation loss: 2.5493241369331963

Epoch: 6| Step: 13
Training loss: 0.29198883207810905
Validation loss: 2.5358598970953077

Epoch: 393| Step: 0
Training loss: 0.39438702052639396
Validation loss: 2.510661465604514

Epoch: 6| Step: 1
Training loss: 0.29695866058497145
Validation loss: 2.540717977882896

Epoch: 6| Step: 2
Training loss: 0.2514294349406713
Validation loss: 2.5494670047893306

Epoch: 6| Step: 3
Training loss: 0.25105094549566664
Validation loss: 2.533732271828402

Epoch: 6| Step: 4
Training loss: 0.26982426955739996
Validation loss: 2.565928894521137

Epoch: 6| Step: 5
Training loss: 0.44226112965865066
Validation loss: 2.543577068999812

Epoch: 6| Step: 6
Training loss: 0.2869610825164105
Validation loss: 2.55325968646387

Epoch: 6| Step: 7
Training loss: 0.25132134055768385
Validation loss: 2.541910108073217

Epoch: 6| Step: 8
Training loss: 0.17463798672561365
Validation loss: 2.59231394887746

Epoch: 6| Step: 9
Training loss: 0.205617558509883
Validation loss: 2.5773979277975765

Epoch: 6| Step: 10
Training loss: 0.2221650678843497
Validation loss: 2.6129491942005787

Epoch: 6| Step: 11
Training loss: 0.44182929300352897
Validation loss: 2.5495200092879915

Epoch: 6| Step: 12
Training loss: 0.3366927152335617
Validation loss: 2.569340363663157

Epoch: 6| Step: 13
Training loss: 0.343620644419331
Validation loss: 2.5561317048816132

Epoch: 394| Step: 0
Training loss: 0.3798707896391855
Validation loss: 2.5475003876147864

Epoch: 6| Step: 1
Training loss: 0.23803153789553436
Validation loss: 2.525817994817548

Epoch: 6| Step: 2
Training loss: 0.4780763439279067
Validation loss: 2.5058761203649382

Epoch: 6| Step: 3
Training loss: 0.32676590147341
Validation loss: 2.5517568349688236

Epoch: 6| Step: 4
Training loss: 0.26394331347137723
Validation loss: 2.4997633714361935

Epoch: 6| Step: 5
Training loss: 0.21318082541163705
Validation loss: 2.523149424703925

Epoch: 6| Step: 6
Training loss: 0.3266753918754088
Validation loss: 2.552081282420001

Epoch: 6| Step: 7
Training loss: 0.2028059287395294
Validation loss: 2.5268117840548503

Epoch: 6| Step: 8
Training loss: 0.17414398641923137
Validation loss: 2.5281504769811503

Epoch: 6| Step: 9
Training loss: 0.19158280268142514
Validation loss: 2.538901526157716

Epoch: 6| Step: 10
Training loss: 0.35294658744979107
Validation loss: 2.517442916052016

Epoch: 6| Step: 11
Training loss: 0.25535685570669275
Validation loss: 2.5248356313133047

Epoch: 6| Step: 12
Training loss: 0.28018043383900015
Validation loss: 2.569563153654747

Epoch: 6| Step: 13
Training loss: 0.3088933239066894
Validation loss: 2.5841588162883764

Epoch: 395| Step: 0
Training loss: 0.3044693483763567
Validation loss: 2.5672707516274196

Epoch: 6| Step: 1
Training loss: 0.29050010745822935
Validation loss: 2.5790122525590267

Epoch: 6| Step: 2
Training loss: 0.1811677869604485
Validation loss: 2.5855585676995356

Epoch: 6| Step: 3
Training loss: 0.2685543407091156
Validation loss: 2.5742259144280686

Epoch: 6| Step: 4
Training loss: 0.2995287467163423
Validation loss: 2.563630877731766

Epoch: 6| Step: 5
Training loss: 0.38286936590599463
Validation loss: 2.5539986637982555

Epoch: 6| Step: 6
Training loss: 0.2726310554384592
Validation loss: 2.572346419904348

Epoch: 6| Step: 7
Training loss: 0.23384853680523804
Validation loss: 2.5215582192238064

Epoch: 6| Step: 8
Training loss: 0.2804705096431352
Validation loss: 2.5608666559622826

Epoch: 6| Step: 9
Training loss: 0.3940772475372791
Validation loss: 2.5446789860078525

Epoch: 6| Step: 10
Training loss: 0.3622643378890756
Validation loss: 2.5365837332156693

Epoch: 6| Step: 11
Training loss: 0.25374532147966244
Validation loss: 2.5139314798999197

Epoch: 6| Step: 12
Training loss: 0.21512502118143248
Validation loss: 2.497188708158465

Epoch: 6| Step: 13
Training loss: 0.4622534861734907
Validation loss: 2.495877242819539

Epoch: 396| Step: 0
Training loss: 0.24987250295615546
Validation loss: 2.544361389270293

Epoch: 6| Step: 1
Training loss: 0.27093760916103815
Validation loss: 2.5375689863438087

Epoch: 6| Step: 2
Training loss: 0.2963472745436989
Validation loss: 2.557293159697121

Epoch: 6| Step: 3
Training loss: 0.3109508501953657
Validation loss: 2.48858946921625

Epoch: 6| Step: 4
Training loss: 0.23444340025662733
Validation loss: 2.5615355885061852

Epoch: 6| Step: 5
Training loss: 0.2047809991519206
Validation loss: 2.533351773560297

Epoch: 6| Step: 6
Training loss: 0.34900455263660657
Validation loss: 2.557157466133935

Epoch: 6| Step: 7
Training loss: 0.24289824422601813
Validation loss: 2.5303339838289216

Epoch: 6| Step: 8
Training loss: 0.1334990958020668
Validation loss: 2.5515664985955513

Epoch: 6| Step: 9
Training loss: 0.4133193346442277
Validation loss: 2.5479750540916224

Epoch: 6| Step: 10
Training loss: 0.21351687163328562
Validation loss: 2.546277763640661

Epoch: 6| Step: 11
Training loss: 0.37938773641307144
Validation loss: 2.542105245717652

Epoch: 6| Step: 12
Training loss: 0.3182199090754657
Validation loss: 2.559671487640525

Epoch: 6| Step: 13
Training loss: 0.41780158291850567
Validation loss: 2.540314493395955

Epoch: 397| Step: 0
Training loss: 0.3756207652813295
Validation loss: 2.5352143397722164

Epoch: 6| Step: 1
Training loss: 0.25134016483059246
Validation loss: 2.5472433766341407

Epoch: 6| Step: 2
Training loss: 0.13797493537352512
Validation loss: 2.543263506823145

Epoch: 6| Step: 3
Training loss: 0.3089584175713378
Validation loss: 2.556354293181983

Epoch: 6| Step: 4
Training loss: 0.32062052825873033
Validation loss: 2.54132458607027

Epoch: 6| Step: 5
Training loss: 0.3597544035678498
Validation loss: 2.5286584174139173

Epoch: 6| Step: 6
Training loss: 0.3318070271669923
Validation loss: 2.524191489217679

Epoch: 6| Step: 7
Training loss: 0.28424856655510944
Validation loss: 2.5500695955196266

Epoch: 6| Step: 8
Training loss: 0.3486919299526488
Validation loss: 2.5491489264935985

Epoch: 6| Step: 9
Training loss: 0.3264186405370219
Validation loss: 2.5902770327777453

Epoch: 6| Step: 10
Training loss: 0.2082925736768184
Validation loss: 2.567017052811976

Epoch: 6| Step: 11
Training loss: 0.2503693951014151
Validation loss: 2.5496756769851747

Epoch: 6| Step: 12
Training loss: 0.20704423215937018
Validation loss: 2.5466529079476414

Epoch: 6| Step: 13
Training loss: 0.3020473806866286
Validation loss: 2.5556782240233895

Epoch: 398| Step: 0
Training loss: 0.41490792390543596
Validation loss: 2.5293350399924766

Epoch: 6| Step: 1
Training loss: 0.4287021088614359
Validation loss: 2.5764268032195266

Epoch: 6| Step: 2
Training loss: 0.18107397641307788
Validation loss: 2.5299740898481646

Epoch: 6| Step: 3
Training loss: 0.1517764189322216
Validation loss: 2.5316278529340286

Epoch: 6| Step: 4
Training loss: 0.25530701630211733
Validation loss: 2.5523987291203145

Epoch: 6| Step: 5
Training loss: 0.2146976928151444
Validation loss: 2.5954533457272664

Epoch: 6| Step: 6
Training loss: 0.28192822484611557
Validation loss: 2.5743264622938855

Epoch: 6| Step: 7
Training loss: 0.269823220272198
Validation loss: 2.549636525918022

Epoch: 6| Step: 8
Training loss: 0.19087619763568808
Validation loss: 2.537955954517764

Epoch: 6| Step: 9
Training loss: 0.26273836258179906
Validation loss: 2.5560112392060255

Epoch: 6| Step: 10
Training loss: 0.2881567269976914
Validation loss: 2.541152659716039

Epoch: 6| Step: 11
Training loss: 0.36228613793116043
Validation loss: 2.528173073702799

Epoch: 6| Step: 12
Training loss: 0.20524570339435766
Validation loss: 2.5446032910217924

Epoch: 6| Step: 13
Training loss: 0.22674119413661858
Validation loss: 2.538579047458946

Epoch: 399| Step: 0
Training loss: 0.35243021587090284
Validation loss: 2.5392801514285432

Epoch: 6| Step: 1
Training loss: 0.36361506722142733
Validation loss: 2.558225200968326

Epoch: 6| Step: 2
Training loss: 0.2572425263823422
Validation loss: 2.531411424961463

Epoch: 6| Step: 3
Training loss: 0.1771890637835031
Validation loss: 2.5639682358187814

Epoch: 6| Step: 4
Training loss: 0.44691440168484065
Validation loss: 2.5746757157375324

Epoch: 6| Step: 5
Training loss: 0.3615069385063184
Validation loss: 2.5670291163953705

Epoch: 6| Step: 6
Training loss: 0.12726051822624057
Validation loss: 2.5515516265084246

Epoch: 6| Step: 7
Training loss: 0.33282691763153005
Validation loss: 2.5851028637536286

Epoch: 6| Step: 8
Training loss: 0.15657468677914563
Validation loss: 2.5689745748234887

Epoch: 6| Step: 9
Training loss: 0.2482464880762115
Validation loss: 2.5701522121376392

Epoch: 6| Step: 10
Training loss: 0.24371131534978183
Validation loss: 2.5503828627093523

Epoch: 6| Step: 11
Training loss: 0.12639764893248856
Validation loss: 2.5275189343331097

Epoch: 6| Step: 12
Training loss: 0.16790926789397853
Validation loss: 2.535818727128851

Epoch: 6| Step: 13
Training loss: 0.20130252299357407
Validation loss: 2.576128276740359

Epoch: 400| Step: 0
Training loss: 0.20416648416283942
Validation loss: 2.554563817072136

Epoch: 6| Step: 1
Training loss: 0.31662457786649384
Validation loss: 2.558104050186782

Epoch: 6| Step: 2
Training loss: 0.3018639140334537
Validation loss: 2.5705767576508065

Epoch: 6| Step: 3
Training loss: 0.37765897375031315
Validation loss: 2.540755458742034

Epoch: 6| Step: 4
Training loss: 0.1303694507052437
Validation loss: 2.541525215161333

Epoch: 6| Step: 5
Training loss: 0.363383125048995
Validation loss: 2.5099903221729845

Epoch: 6| Step: 6
Training loss: 0.2335375128066671
Validation loss: 2.5444320234849425

Epoch: 6| Step: 7
Training loss: 0.22814910382473724
Validation loss: 2.565910874542111

Epoch: 6| Step: 8
Training loss: 0.3408914398912393
Validation loss: 2.55401929430755

Epoch: 6| Step: 9
Training loss: 0.1468923672594167
Validation loss: 2.5766217306077253

Epoch: 6| Step: 10
Training loss: 0.4421295889685573
Validation loss: 2.59906351054745

Epoch: 6| Step: 11
Training loss: 0.201988258109661
Validation loss: 2.590498692139548

Epoch: 6| Step: 12
Training loss: 0.21051758896902478
Validation loss: 2.544167053448449

Epoch: 6| Step: 13
Training loss: 0.318754045142891
Validation loss: 2.528506150632071

Epoch: 401| Step: 0
Training loss: 0.28721750260415185
Validation loss: 2.5362200773653862

Epoch: 6| Step: 1
Training loss: 0.11441935832073982
Validation loss: 2.5070347858345823

Epoch: 6| Step: 2
Training loss: 0.3530895974971544
Validation loss: 2.5399115090349063

Epoch: 6| Step: 3
Training loss: 0.18645409098830248
Validation loss: 2.517983542326237

Epoch: 6| Step: 4
Training loss: 0.2283822020620184
Validation loss: 2.5549856739883943

Epoch: 6| Step: 5
Training loss: 0.34855469327997385
Validation loss: 2.5189473877191886

Epoch: 6| Step: 6
Training loss: 0.22634712209300292
Validation loss: 2.5167512079077814

Epoch: 6| Step: 7
Training loss: 0.3409040178839045
Validation loss: 2.511844047613672

Epoch: 6| Step: 8
Training loss: 0.3438061971677876
Validation loss: 2.534876975797324

Epoch: 6| Step: 9
Training loss: 0.15946568498949526
Validation loss: 2.5137141506601863

Epoch: 6| Step: 10
Training loss: 0.22112872854618276
Validation loss: 2.508769749200513

Epoch: 6| Step: 11
Training loss: 0.2387348220030058
Validation loss: 2.537065154983196

Epoch: 6| Step: 12
Training loss: 0.4119550226067646
Validation loss: 2.5370379589162204

Epoch: 6| Step: 13
Training loss: 0.274022403206644
Validation loss: 2.5337874823397937

Epoch: 402| Step: 0
Training loss: 0.39038750104282155
Validation loss: 2.515788741563891

Epoch: 6| Step: 1
Training loss: 0.15639610612045218
Validation loss: 2.5736730266837315

Epoch: 6| Step: 2
Training loss: 0.3127743113107625
Validation loss: 2.5589687117434665

Epoch: 6| Step: 3
Training loss: 0.2871401115106086
Validation loss: 2.5758271239844657

Epoch: 6| Step: 4
Training loss: 0.31923216553971323
Validation loss: 2.5651926429639054

Epoch: 6| Step: 5
Training loss: 0.3278672704770859
Validation loss: 2.546256929451453

Epoch: 6| Step: 6
Training loss: 0.2230571350303279
Validation loss: 2.5066327165103672

Epoch: 6| Step: 7
Training loss: 0.22871740512840805
Validation loss: 2.572307774846578

Epoch: 6| Step: 8
Training loss: 0.2722534291889507
Validation loss: 2.521425698711253

Epoch: 6| Step: 9
Training loss: 0.33348751475971383
Validation loss: 2.493792120391

Epoch: 6| Step: 10
Training loss: 0.23944294831647384
Validation loss: 2.4962823883079643

Epoch: 6| Step: 11
Training loss: 0.2629185263577529
Validation loss: 2.54070016151689

Epoch: 6| Step: 12
Training loss: 0.36290415809453486
Validation loss: 2.48982039895103

Epoch: 6| Step: 13
Training loss: 0.2924666743774977
Validation loss: 2.5112066032408467

Epoch: 403| Step: 0
Training loss: 0.3297856406269577
Validation loss: 2.50604239552114

Epoch: 6| Step: 1
Training loss: 0.13510434113062073
Validation loss: 2.515095774000998

Epoch: 6| Step: 2
Training loss: 0.26023531162044167
Validation loss: 2.5194901037167274

Epoch: 6| Step: 3
Training loss: 0.17209100696247226
Validation loss: 2.5111032451792963

Epoch: 6| Step: 4
Training loss: 0.2851065762248093
Validation loss: 2.5322851122826417

Epoch: 6| Step: 5
Training loss: 0.32324361656772
Validation loss: 2.5010903431603504

Epoch: 6| Step: 6
Training loss: 0.2951288570618949
Validation loss: 2.5178893516087006

Epoch: 6| Step: 7
Training loss: 0.227585308958125
Validation loss: 2.512921827864207

Epoch: 6| Step: 8
Training loss: 0.31731216818202523
Validation loss: 2.4776532883047717

Epoch: 6| Step: 9
Training loss: 0.23116190173006146
Validation loss: 2.540407950039027

Epoch: 6| Step: 10
Training loss: 0.2504549357506871
Validation loss: 2.4966811628756123

Epoch: 6| Step: 11
Training loss: 0.1989439022029951
Validation loss: 2.4964939728438966

Epoch: 6| Step: 12
Training loss: 0.36740923334785686
Validation loss: 2.5064705461842345

Epoch: 6| Step: 13
Training loss: 0.28190702941502616
Validation loss: 2.54072872293671

Epoch: 404| Step: 0
Training loss: 0.26850610466984215
Validation loss: 2.4592079393870914

Epoch: 6| Step: 1
Training loss: 0.22855047628577993
Validation loss: 2.5326714656023506

Epoch: 6| Step: 2
Training loss: 0.26955720527732796
Validation loss: 2.5070082600000503

Epoch: 6| Step: 3
Training loss: 0.3963446347380829
Validation loss: 2.5205335514238607

Epoch: 6| Step: 4
Training loss: 0.28778766773469017
Validation loss: 2.5606639516128498

Epoch: 6| Step: 5
Training loss: 0.30144736607252365
Validation loss: 2.5328396396544677

Epoch: 6| Step: 6
Training loss: 0.2875685620447278
Validation loss: 2.483506703964607

Epoch: 6| Step: 7
Training loss: 0.3145872031641192
Validation loss: 2.5398451307766288

Epoch: 6| Step: 8
Training loss: 0.23010843203660883
Validation loss: 2.5313917378867217

Epoch: 6| Step: 9
Training loss: 0.22407541245798465
Validation loss: 2.514569646562895

Epoch: 6| Step: 10
Training loss: 0.17642827164315336
Validation loss: 2.5131863668276373

Epoch: 6| Step: 11
Training loss: 0.28482336706910344
Validation loss: 2.53241951765229

Epoch: 6| Step: 12
Training loss: 0.2052060591060141
Validation loss: 2.5654406458292436

Epoch: 6| Step: 13
Training loss: 0.3274346878541176
Validation loss: 2.5399717398251775

Epoch: 405| Step: 0
Training loss: 0.29681958133028213
Validation loss: 2.5923688808958905

Epoch: 6| Step: 1
Training loss: 0.34505086454740036
Validation loss: 2.5556959249395566

Epoch: 6| Step: 2
Training loss: 0.16024739881619698
Validation loss: 2.5253673313484213

Epoch: 6| Step: 3
Training loss: 0.3530233971255127
Validation loss: 2.5582938570781644

Epoch: 6| Step: 4
Training loss: 0.27930234356841754
Validation loss: 2.557567470203742

Epoch: 6| Step: 5
Training loss: 0.30393489173132415
Validation loss: 2.5413120458794016

Epoch: 6| Step: 6
Training loss: 0.20768827870188822
Validation loss: 2.506895159036354

Epoch: 6| Step: 7
Training loss: 0.2757275191314171
Validation loss: 2.4982903490071964

Epoch: 6| Step: 8
Training loss: 0.2863501806988953
Validation loss: 2.510951199762096

Epoch: 6| Step: 9
Training loss: 0.1656796084204272
Validation loss: 2.512630859870646

Epoch: 6| Step: 10
Training loss: 0.32427828598322117
Validation loss: 2.5031760458059376

Epoch: 6| Step: 11
Training loss: 0.22263967720058625
Validation loss: 2.4692291640044215

Epoch: 6| Step: 12
Training loss: 0.2837372445713928
Validation loss: 2.49279099543722

Epoch: 6| Step: 13
Training loss: 0.21453396397462482
Validation loss: 2.45313901409334

Epoch: 406| Step: 0
Training loss: 0.26309110470733393
Validation loss: 2.5036633292906614

Epoch: 6| Step: 1
Training loss: 0.1753425846703598
Validation loss: 2.4885998124973043

Epoch: 6| Step: 2
Training loss: 0.30177184877805263
Validation loss: 2.4931973375421115

Epoch: 6| Step: 3
Training loss: 0.2944355801694044
Validation loss: 2.492753946266076

Epoch: 6| Step: 4
Training loss: 0.32617366813121096
Validation loss: 2.497280471096075

Epoch: 6| Step: 5
Training loss: 0.1195204652022345
Validation loss: 2.481001181316131

Epoch: 6| Step: 6
Training loss: 0.2519347309820602
Validation loss: 2.503907049631782

Epoch: 6| Step: 7
Training loss: 0.41897888760420454
Validation loss: 2.512926835683507

Epoch: 6| Step: 8
Training loss: 0.2168497502224816
Validation loss: 2.4785312797645256

Epoch: 6| Step: 9
Training loss: 0.1586314278743897
Validation loss: 2.483140535159491

Epoch: 6| Step: 10
Training loss: 0.34214914969221966
Validation loss: 2.476186173862487

Epoch: 6| Step: 11
Training loss: 0.2283711424962705
Validation loss: 2.5037908423335447

Epoch: 6| Step: 12
Training loss: 0.19879933694053942
Validation loss: 2.5116161550731846

Epoch: 6| Step: 13
Training loss: 0.2278697676295939
Validation loss: 2.5427039864100536

Epoch: 407| Step: 0
Training loss: 0.34655531680588897
Validation loss: 2.5367623652917977

Epoch: 6| Step: 1
Training loss: 0.17756848400979933
Validation loss: 2.547243104896067

Epoch: 6| Step: 2
Training loss: 0.24758565630642076
Validation loss: 2.5672345386492457

Epoch: 6| Step: 3
Training loss: 0.16556410817257733
Validation loss: 2.5496840566179806

Epoch: 6| Step: 4
Training loss: 0.18595520063504273
Validation loss: 2.5572129749086647

Epoch: 6| Step: 5
Training loss: 0.3586003205272946
Validation loss: 2.5409409418073094

Epoch: 6| Step: 6
Training loss: 0.30094430888030327
Validation loss: 2.570601373432782

Epoch: 6| Step: 7
Training loss: 0.31834994343085643
Validation loss: 2.5038819599110873

Epoch: 6| Step: 8
Training loss: 0.2287760660558321
Validation loss: 2.532333230356369

Epoch: 6| Step: 9
Training loss: 0.2763236452990082
Validation loss: 2.5644166018150543

Epoch: 6| Step: 10
Training loss: 0.2402818524346531
Validation loss: 2.520150239456723

Epoch: 6| Step: 11
Training loss: 0.2797480187392792
Validation loss: 2.511853225020408

Epoch: 6| Step: 12
Training loss: 0.18126577234702004
Validation loss: 2.5326840182090224

Epoch: 6| Step: 13
Training loss: 0.1341970029983068
Validation loss: 2.5529376446929817

Epoch: 408| Step: 0
Training loss: 0.22369490515236481
Validation loss: 2.552962203104721

Epoch: 6| Step: 1
Training loss: 0.15267660995010593
Validation loss: 2.5369198020901895

Epoch: 6| Step: 2
Training loss: 0.2329323076314794
Validation loss: 2.544118761162232

Epoch: 6| Step: 3
Training loss: 0.23431554676027688
Validation loss: 2.5215985672227164

Epoch: 6| Step: 4
Training loss: 0.36569829026913403
Validation loss: 2.557385450544485

Epoch: 6| Step: 5
Training loss: 0.3358867629127696
Validation loss: 2.535868395675578

Epoch: 6| Step: 6
Training loss: 0.1379908980589168
Validation loss: 2.516215795207431

Epoch: 6| Step: 7
Training loss: 0.2298492737760475
Validation loss: 2.5076951127321365

Epoch: 6| Step: 8
Training loss: 0.35424775242546774
Validation loss: 2.50899584650431

Epoch: 6| Step: 9
Training loss: 0.16563770812242265
Validation loss: 2.5560984853660718

Epoch: 6| Step: 10
Training loss: 0.1755875686043582
Validation loss: 2.5298297097369136

Epoch: 6| Step: 11
Training loss: 0.2739587039848305
Validation loss: 2.5005578997774967

Epoch: 6| Step: 12
Training loss: 0.4360949741183697
Validation loss: 2.5090226070233377

Epoch: 6| Step: 13
Training loss: 0.29094377693264156
Validation loss: 2.4870033026328695

Epoch: 409| Step: 0
Training loss: 0.19048675268962717
Validation loss: 2.5150492151949804

Epoch: 6| Step: 1
Training loss: 0.31914278774392446
Validation loss: 2.527338366776866

Epoch: 6| Step: 2
Training loss: 0.25810895117129057
Validation loss: 2.5299828792584336

Epoch: 6| Step: 3
Training loss: 0.2674612917924899
Validation loss: 2.50816725287129

Epoch: 6| Step: 4
Training loss: 0.4148063815253196
Validation loss: 2.526451816547203

Epoch: 6| Step: 5
Training loss: 0.33884996046091664
Validation loss: 2.519066065950018

Epoch: 6| Step: 6
Training loss: 0.2766985844006877
Validation loss: 2.530312671856584

Epoch: 6| Step: 7
Training loss: 0.21820345790139717
Validation loss: 2.5383973083757327

Epoch: 6| Step: 8
Training loss: 0.27182683682518843
Validation loss: 2.526353873388038

Epoch: 6| Step: 9
Training loss: 0.34384092298879837
Validation loss: 2.576579177722771

Epoch: 6| Step: 10
Training loss: 0.2285298726131495
Validation loss: 2.520069118003731

Epoch: 6| Step: 11
Training loss: 0.2845503758847776
Validation loss: 2.5672478719229925

Epoch: 6| Step: 12
Training loss: 0.18631146154526976
Validation loss: 2.5467625642296516

Epoch: 6| Step: 13
Training loss: 0.28938432769078
Validation loss: 2.5483521707928887

Epoch: 410| Step: 0
Training loss: 0.20237350834184256
Validation loss: 2.579563722624596

Epoch: 6| Step: 1
Training loss: 0.3394004846807974
Validation loss: 2.5726592066406084

Epoch: 6| Step: 2
Training loss: 0.27761922506795306
Validation loss: 2.561101494312401

Epoch: 6| Step: 3
Training loss: 0.31497580170404105
Validation loss: 2.593111660674928

Epoch: 6| Step: 4
Training loss: 0.23241911814360916
Validation loss: 2.531110153274888

Epoch: 6| Step: 5
Training loss: 0.336759946652858
Validation loss: 2.5456498047294587

Epoch: 6| Step: 6
Training loss: 0.17660899773774855
Validation loss: 2.5578440645239158

Epoch: 6| Step: 7
Training loss: 0.3106306191057046
Validation loss: 2.5304200890564004

Epoch: 6| Step: 8
Training loss: 0.3054301674128352
Validation loss: 2.5415283411257716

Epoch: 6| Step: 9
Training loss: 0.25313653919621015
Validation loss: 2.5356792258963137

Epoch: 6| Step: 10
Training loss: 0.15128090152649123
Validation loss: 2.530455023511184

Epoch: 6| Step: 11
Training loss: 0.30803503086772477
Validation loss: 2.523573842504132

Epoch: 6| Step: 12
Training loss: 0.2002053421113293
Validation loss: 2.521319567625921

Epoch: 6| Step: 13
Training loss: 0.1820014323424474
Validation loss: 2.539380394003806

Epoch: 411| Step: 0
Training loss: 0.2811010549125161
Validation loss: 2.5144413924251

Epoch: 6| Step: 1
Training loss: 0.20596257180167937
Validation loss: 2.525415811666171

Epoch: 6| Step: 2
Training loss: 0.2559180447236893
Validation loss: 2.5403578030979364

Epoch: 6| Step: 3
Training loss: 0.336020891795316
Validation loss: 2.55134453860822

Epoch: 6| Step: 4
Training loss: 0.31308120086190083
Validation loss: 2.5248670222760303

Epoch: 6| Step: 5
Training loss: 0.16494699878595837
Validation loss: 2.5170639692888916

Epoch: 6| Step: 6
Training loss: 0.32085057166882214
Validation loss: 2.5129023963596393

Epoch: 6| Step: 7
Training loss: 0.2651676279390639
Validation loss: 2.541841776958472

Epoch: 6| Step: 8
Training loss: 0.1158608966953824
Validation loss: 2.5318662702709473

Epoch: 6| Step: 9
Training loss: 0.2629866562094416
Validation loss: 2.51165755385277

Epoch: 6| Step: 10
Training loss: 0.1960969715689667
Validation loss: 2.5059234749310897

Epoch: 6| Step: 11
Training loss: 0.18412372511560246
Validation loss: 2.54445811686222

Epoch: 6| Step: 12
Training loss: 0.42769629600719117
Validation loss: 2.548256317371808

Epoch: 6| Step: 13
Training loss: 0.3754759986168225
Validation loss: 2.5463847852362593

Epoch: 412| Step: 0
Training loss: 0.13330100482181342
Validation loss: 2.5708792483935574

Epoch: 6| Step: 1
Training loss: 0.24242723044142098
Validation loss: 2.5452913723055426

Epoch: 6| Step: 2
Training loss: 0.19980106145378249
Validation loss: 2.56894999285116

Epoch: 6| Step: 3
Training loss: 0.26029091977978686
Validation loss: 2.566956886222751

Epoch: 6| Step: 4
Training loss: 0.2715264843454365
Validation loss: 2.5710335944407796

Epoch: 6| Step: 5
Training loss: 0.36161767853420385
Validation loss: 2.546971085577504

Epoch: 6| Step: 6
Training loss: 0.3121028761014022
Validation loss: 2.5167894724879596

Epoch: 6| Step: 7
Training loss: 0.2917275265934943
Validation loss: 2.5332206388783907

Epoch: 6| Step: 8
Training loss: 0.22328415390272568
Validation loss: 2.5383487982535335

Epoch: 6| Step: 9
Training loss: 0.38210033813971755
Validation loss: 2.501896304119926

Epoch: 6| Step: 10
Training loss: 0.2909353004560903
Validation loss: 2.5168971133921656

Epoch: 6| Step: 11
Training loss: 0.20004830894561132
Validation loss: 2.5162229801110407

Epoch: 6| Step: 12
Training loss: 0.14867662944397908
Validation loss: 2.493449511843662

Epoch: 6| Step: 13
Training loss: 0.3116226157997328
Validation loss: 2.5279893341102304

Epoch: 413| Step: 0
Training loss: 0.1597072891209011
Validation loss: 2.5249025239732856

Epoch: 6| Step: 1
Training loss: 0.20016510898421794
Validation loss: 2.561679010260285

Epoch: 6| Step: 2
Training loss: 0.2980700707564982
Validation loss: 2.5189256812066483

Epoch: 6| Step: 3
Training loss: 0.2668114140180843
Validation loss: 2.5438293247936503

Epoch: 6| Step: 4
Training loss: 0.28428592858936286
Validation loss: 2.5346263839472347

Epoch: 6| Step: 5
Training loss: 0.18050402176885968
Validation loss: 2.541583655131622

Epoch: 6| Step: 6
Training loss: 0.27901711491077336
Validation loss: 2.5370105887522967

Epoch: 6| Step: 7
Training loss: 0.3684558268834987
Validation loss: 2.5343932837153766

Epoch: 6| Step: 8
Training loss: 0.20449238643254
Validation loss: 2.535814082721213

Epoch: 6| Step: 9
Training loss: 0.1966584558779972
Validation loss: 2.518401318662489

Epoch: 6| Step: 10
Training loss: 0.34650838138715184
Validation loss: 2.532654808325794

Epoch: 6| Step: 11
Training loss: 0.2518168531843045
Validation loss: 2.48542891968517

Epoch: 6| Step: 12
Training loss: 0.16238728795825058
Validation loss: 2.519245381476361

Epoch: 6| Step: 13
Training loss: 0.4404965199853735
Validation loss: 2.5171682171627157

Epoch: 414| Step: 0
Training loss: 0.2178807528759989
Validation loss: 2.507210961791886

Epoch: 6| Step: 1
Training loss: 0.18787210020237313
Validation loss: 2.4888303152249063

Epoch: 6| Step: 2
Training loss: 0.2920163505023062
Validation loss: 2.4910719085405666

Epoch: 6| Step: 3
Training loss: 0.19466329444010813
Validation loss: 2.530647233409124

Epoch: 6| Step: 4
Training loss: 0.19962400468639077
Validation loss: 2.5220649959243673

Epoch: 6| Step: 5
Training loss: 0.1618772131168386
Validation loss: 2.531337952741083

Epoch: 6| Step: 6
Training loss: 0.28360525060616687
Validation loss: 2.5206438659665102

Epoch: 6| Step: 7
Training loss: 0.17961268318650633
Validation loss: 2.5201050519841584

Epoch: 6| Step: 8
Training loss: 0.3556179529976836
Validation loss: 2.5251106281021083

Epoch: 6| Step: 9
Training loss: 0.3556933269998724
Validation loss: 2.5364806724309683

Epoch: 6| Step: 10
Training loss: 0.23142746160371863
Validation loss: 2.5050602266363504

Epoch: 6| Step: 11
Training loss: 0.30191697549518987
Validation loss: 2.541595512119023

Epoch: 6| Step: 12
Training loss: 0.27628362895423325
Validation loss: 2.5365080432594644

Epoch: 6| Step: 13
Training loss: 0.29121440780485647
Validation loss: 2.5338232657820754

Epoch: 415| Step: 0
Training loss: 0.23583155868225383
Validation loss: 2.5306596126975243

Epoch: 6| Step: 1
Training loss: 0.3280266092013385
Validation loss: 2.573411986432265

Epoch: 6| Step: 2
Training loss: 0.25107579922558854
Validation loss: 2.5518922661853125

Epoch: 6| Step: 3
Training loss: 0.2981363904524433
Validation loss: 2.5196633962711994

Epoch: 6| Step: 4
Training loss: 0.32458335414114325
Validation loss: 2.5108532109666

Epoch: 6| Step: 5
Training loss: 0.15620135503759972
Validation loss: 2.5336960338063435

Epoch: 6| Step: 6
Training loss: 0.14039269438902352
Validation loss: 2.5298928881961937

Epoch: 6| Step: 7
Training loss: 0.38053066055441415
Validation loss: 2.5387858835998163

Epoch: 6| Step: 8
Training loss: 0.3088670679113645
Validation loss: 2.5467370662333786

Epoch: 6| Step: 9
Training loss: 0.25657650859377734
Validation loss: 2.5575803085852233

Epoch: 6| Step: 10
Training loss: 0.23048084841508915
Validation loss: 2.535322580689835

Epoch: 6| Step: 11
Training loss: 0.14757948651147682
Validation loss: 2.5395152001569445

Epoch: 6| Step: 12
Training loss: 0.1939110736262329
Validation loss: 2.516457660060996

Epoch: 6| Step: 13
Training loss: 0.2436258840623163
Validation loss: 2.5334669153500387

Epoch: 416| Step: 0
Training loss: 0.15986309902061932
Validation loss: 2.478923700562981

Epoch: 6| Step: 1
Training loss: 0.1730421868629989
Validation loss: 2.551921524098291

Epoch: 6| Step: 2
Training loss: 0.2380670147230112
Validation loss: 2.5468859898475857

Epoch: 6| Step: 3
Training loss: 0.2952882877899527
Validation loss: 2.538277089804207

Epoch: 6| Step: 4
Training loss: 0.1785588268533789
Validation loss: 2.5819314122552135

Epoch: 6| Step: 5
Training loss: 0.17786976614494648
Validation loss: 2.5405623475990113

Epoch: 6| Step: 6
Training loss: 0.29450857495111754
Validation loss: 2.4889939732521356

Epoch: 6| Step: 7
Training loss: 0.3668566897760419
Validation loss: 2.547735655023261

Epoch: 6| Step: 8
Training loss: 0.2873363117004097
Validation loss: 2.530195595157137

Epoch: 6| Step: 9
Training loss: 0.2849509924446785
Validation loss: 2.567100120063307

Epoch: 6| Step: 10
Training loss: 0.42345735707474363
Validation loss: 2.545042946913654

Epoch: 6| Step: 11
Training loss: 0.16723780944613678
Validation loss: 2.5529753428023434

Epoch: 6| Step: 12
Training loss: 0.24657095704846999
Validation loss: 2.5745842358764737

Epoch: 6| Step: 13
Training loss: 0.24453467802381
Validation loss: 2.5488922366302176

Epoch: 417| Step: 0
Training loss: 0.15045272486311909
Validation loss: 2.549076605156531

Epoch: 6| Step: 1
Training loss: 0.3474502274490679
Validation loss: 2.5330632590891193

Epoch: 6| Step: 2
Training loss: 0.2473231217125713
Validation loss: 2.5309182489853477

Epoch: 6| Step: 3
Training loss: 0.3496612851268479
Validation loss: 2.528296545948356

Epoch: 6| Step: 4
Training loss: 0.3477095016671664
Validation loss: 2.5293908279167656

Epoch: 6| Step: 5
Training loss: 0.26622049114411545
Validation loss: 2.514248594152508

Epoch: 6| Step: 6
Training loss: 0.3793906428900044
Validation loss: 2.5356064465652937

Epoch: 6| Step: 7
Training loss: 0.3006202712846991
Validation loss: 2.542562429439437

Epoch: 6| Step: 8
Training loss: 0.21715946634073324
Validation loss: 2.529489177210287

Epoch: 6| Step: 9
Training loss: 0.29353992732155193
Validation loss: 2.5224314171452873

Epoch: 6| Step: 10
Training loss: 0.23592962605556328
Validation loss: 2.5123904327221624

Epoch: 6| Step: 11
Training loss: 0.22778169850203087
Validation loss: 2.5198685055545793

Epoch: 6| Step: 12
Training loss: 0.28014011734458966
Validation loss: 2.4952351929469514

Epoch: 6| Step: 13
Training loss: 0.19358250238166613
Validation loss: 2.4984208888001698

Epoch: 418| Step: 0
Training loss: 0.39212963239653204
Validation loss: 2.5279822221984736

Epoch: 6| Step: 1
Training loss: 0.25249399489636376
Validation loss: 2.5323709395874823

Epoch: 6| Step: 2
Training loss: 0.18864589456999228
Validation loss: 2.4500925165488145

Epoch: 6| Step: 3
Training loss: 0.36620739744382713
Validation loss: 2.472238050876169

Epoch: 6| Step: 4
Training loss: 0.3772390398022212
Validation loss: 2.497085133310692

Epoch: 6| Step: 5
Training loss: 0.22826933018285017
Validation loss: 2.521838887050342

Epoch: 6| Step: 6
Training loss: 0.3840772987848164
Validation loss: 2.487001168329225

Epoch: 6| Step: 7
Training loss: 0.33295948203626285
Validation loss: 2.4936396486375276

Epoch: 6| Step: 8
Training loss: 0.2024886360040982
Validation loss: 2.5190089492127905

Epoch: 6| Step: 9
Training loss: 0.3087231087267364
Validation loss: 2.4949938888913916

Epoch: 6| Step: 10
Training loss: 0.23695228060840112
Validation loss: 2.5435886984881457

Epoch: 6| Step: 11
Training loss: 0.19793144074727462
Validation loss: 2.529145382051669

Epoch: 6| Step: 12
Training loss: 0.1900548130577075
Validation loss: 2.609314426885499

Epoch: 6| Step: 13
Training loss: 0.11496235778869687
Validation loss: 2.589372601342705

Epoch: 419| Step: 0
Training loss: 0.3785821964391831
Validation loss: 2.611587397047615

Epoch: 6| Step: 1
Training loss: 0.36110401936235004
Validation loss: 2.583510613254969

Epoch: 6| Step: 2
Training loss: 0.24508505682829432
Validation loss: 2.598772470940901

Epoch: 6| Step: 3
Training loss: 0.32760509673786603
Validation loss: 2.620091282061367

Epoch: 6| Step: 4
Training loss: 0.17613218033694697
Validation loss: 2.5603565792914824

Epoch: 6| Step: 5
Training loss: 0.2458223178114327
Validation loss: 2.576105685683163

Epoch: 6| Step: 6
Training loss: 0.2071579959051748
Validation loss: 2.6022852126265743

Epoch: 6| Step: 7
Training loss: 0.20552942482484599
Validation loss: 2.582138781354445

Epoch: 6| Step: 8
Training loss: 0.16828478977691827
Validation loss: 2.5898279039147516

Epoch: 6| Step: 9
Training loss: 0.1899481921712183
Validation loss: 2.6003336104342765

Epoch: 6| Step: 10
Training loss: 0.35316265251486634
Validation loss: 2.586203740093491

Epoch: 6| Step: 11
Training loss: 0.19200806498725315
Validation loss: 2.602238358482498

Epoch: 6| Step: 12
Training loss: 0.22403369604034626
Validation loss: 2.5918876889894555

Epoch: 6| Step: 13
Training loss: 0.3031204837777253
Validation loss: 2.5489882049311463

Epoch: 420| Step: 0
Training loss: 0.31802687804875546
Validation loss: 2.560477390205205

Epoch: 6| Step: 1
Training loss: 0.20058770220759353
Validation loss: 2.5420591783231057

Epoch: 6| Step: 2
Training loss: 0.21781506161982697
Validation loss: 2.532267450199378

Epoch: 6| Step: 3
Training loss: 0.13939710822335075
Validation loss: 2.5286356334130575

Epoch: 6| Step: 4
Training loss: 0.38665651533487233
Validation loss: 2.5580030991795746

Epoch: 6| Step: 5
Training loss: 0.274066011978318
Validation loss: 2.5560208538010376

Epoch: 6| Step: 6
Training loss: 0.2828668241857529
Validation loss: 2.5517411502138896

Epoch: 6| Step: 7
Training loss: 0.2544463209273786
Validation loss: 2.5647602622612946

Epoch: 6| Step: 8
Training loss: 0.10609756765533598
Validation loss: 2.505587894800734

Epoch: 6| Step: 9
Training loss: 0.2352154603345202
Validation loss: 2.5219486087831555

Epoch: 6| Step: 10
Training loss: 0.23245513101081303
Validation loss: 2.524903650495448

Epoch: 6| Step: 11
Training loss: 0.10479768320877927
Validation loss: 2.5396186132520238

Epoch: 6| Step: 12
Training loss: 0.30351059368190486
Validation loss: 2.565503332048933

Epoch: 6| Step: 13
Training loss: 0.26659016008411546
Validation loss: 2.5316288172251773

Epoch: 421| Step: 0
Training loss: 0.2389580152352058
Validation loss: 2.5458329481813338

Epoch: 6| Step: 1
Training loss: 0.12135176704009823
Validation loss: 2.5169029457280176

Epoch: 6| Step: 2
Training loss: 0.2655593286003058
Validation loss: 2.4984983179504803

Epoch: 6| Step: 3
Training loss: 0.3123590270595722
Validation loss: 2.510438691157791

Epoch: 6| Step: 4
Training loss: 0.17397226829356216
Validation loss: 2.491040988349243

Epoch: 6| Step: 5
Training loss: 0.24087375750119774
Validation loss: 2.55312281808923

Epoch: 6| Step: 6
Training loss: 0.15165532897223066
Validation loss: 2.531048188240917

Epoch: 6| Step: 7
Training loss: 0.286223153183845
Validation loss: 2.51878919600205

Epoch: 6| Step: 8
Training loss: 0.4035945449567255
Validation loss: 2.5308003635821024

Epoch: 6| Step: 9
Training loss: 0.32786261194599464
Validation loss: 2.512658295623915

Epoch: 6| Step: 10
Training loss: 0.1726737319933422
Validation loss: 2.5494735328729132

Epoch: 6| Step: 11
Training loss: 0.1871885454725005
Validation loss: 2.559485879053597

Epoch: 6| Step: 12
Training loss: 0.14360918580566667
Validation loss: 2.559461274059512

Epoch: 6| Step: 13
Training loss: 0.28452371963348305
Validation loss: 2.5488066297118293

Epoch: 422| Step: 0
Training loss: 0.23697030484045217
Validation loss: 2.531017072466518

Epoch: 6| Step: 1
Training loss: 0.15703370723414997
Validation loss: 2.538868490652534

Epoch: 6| Step: 2
Training loss: 0.41176768234723865
Validation loss: 2.492794556859415

Epoch: 6| Step: 3
Training loss: 0.12592712437695322
Validation loss: 2.507686263860729

Epoch: 6| Step: 4
Training loss: 0.21922859561314956
Validation loss: 2.487122377484603

Epoch: 6| Step: 5
Training loss: 0.24008361613991722
Validation loss: 2.52713704506888

Epoch: 6| Step: 6
Training loss: 0.2531375252014889
Validation loss: 2.520038308684844

Epoch: 6| Step: 7
Training loss: 0.3153380624070893
Validation loss: 2.5332520838090895

Epoch: 6| Step: 8
Training loss: 0.23064797108698698
Validation loss: 2.5270524765051627

Epoch: 6| Step: 9
Training loss: 0.2320512974873562
Validation loss: 2.5289654313968413

Epoch: 6| Step: 10
Training loss: 0.1989591159522224
Validation loss: 2.5329910852320805

Epoch: 6| Step: 11
Training loss: 0.22643615225070496
Validation loss: 2.5393408111174938

Epoch: 6| Step: 12
Training loss: 0.1329740915671206
Validation loss: 2.5503691975038265

Epoch: 6| Step: 13
Training loss: 0.12195729937059177
Validation loss: 2.5438554263686126

Epoch: 423| Step: 0
Training loss: 0.20528128415689753
Validation loss: 2.5699618944749316

Epoch: 6| Step: 1
Training loss: 0.32357249138083716
Validation loss: 2.5488263990268845

Epoch: 6| Step: 2
Training loss: 0.3480549786755638
Validation loss: 2.56645802861916

Epoch: 6| Step: 3
Training loss: 0.2771161986103198
Validation loss: 2.5670428082616428

Epoch: 6| Step: 4
Training loss: 0.19716944096446865
Validation loss: 2.4976967538297674

Epoch: 6| Step: 5
Training loss: 0.2329331072809445
Validation loss: 2.555558519438222

Epoch: 6| Step: 6
Training loss: 0.20205043868288894
Validation loss: 2.526036941698123

Epoch: 6| Step: 7
Training loss: 0.15424781333178705
Validation loss: 2.5338717765454595

Epoch: 6| Step: 8
Training loss: 0.19435049606308513
Validation loss: 2.527173268598553

Epoch: 6| Step: 9
Training loss: 0.17252656588684667
Validation loss: 2.527059102056154

Epoch: 6| Step: 10
Training loss: 0.2703298127688515
Validation loss: 2.505803367038645

Epoch: 6| Step: 11
Training loss: 0.17496184524910455
Validation loss: 2.5170105787239203

Epoch: 6| Step: 12
Training loss: 0.14959709326229775
Validation loss: 2.517161937317067

Epoch: 6| Step: 13
Training loss: 0.26572555153477534
Validation loss: 2.5315527381071132

Epoch: 424| Step: 0
Training loss: 0.33957312759712244
Validation loss: 2.496524979787681

Epoch: 6| Step: 1
Training loss: 0.2768841145007656
Validation loss: 2.5061481176381837

Epoch: 6| Step: 2
Training loss: 0.17871887939816636
Validation loss: 2.56046790248086

Epoch: 6| Step: 3
Training loss: 0.3034744814132256
Validation loss: 2.540558635176524

Epoch: 6| Step: 4
Training loss: 0.18511997100868902
Validation loss: 2.5201278808101986

Epoch: 6| Step: 5
Training loss: 0.20040535491584055
Validation loss: 2.560416298096469

Epoch: 6| Step: 6
Training loss: 0.3290249653318462
Validation loss: 2.5506736178508316

Epoch: 6| Step: 7
Training loss: 0.27098396892744836
Validation loss: 2.5268989092002876

Epoch: 6| Step: 8
Training loss: 0.2327269387313689
Validation loss: 2.5165441331110783

Epoch: 6| Step: 9
Training loss: 0.18028628054546747
Validation loss: 2.5255404114670417

Epoch: 6| Step: 10
Training loss: 0.209795065719384
Validation loss: 2.538430392935036

Epoch: 6| Step: 11
Training loss: 0.20669295003642235
Validation loss: 2.539445433662005

Epoch: 6| Step: 12
Training loss: 0.2906556431192153
Validation loss: 2.49638518825902

Epoch: 6| Step: 13
Training loss: 0.21908340421023503
Validation loss: 2.4740027759923167

Epoch: 425| Step: 0
Training loss: 0.3036219230298063
Validation loss: 2.5098875503671145

Epoch: 6| Step: 1
Training loss: 0.30694612240200825
Validation loss: 2.4995426956944238

Epoch: 6| Step: 2
Training loss: 0.1258790355767532
Validation loss: 2.5366821035379212

Epoch: 6| Step: 3
Training loss: 0.22471602851663705
Validation loss: 2.521895006498461

Epoch: 6| Step: 4
Training loss: 0.3102245217235308
Validation loss: 2.5094077921553093

Epoch: 6| Step: 5
Training loss: 0.2608463779260872
Validation loss: 2.547019731425667

Epoch: 6| Step: 6
Training loss: 0.3211018674989209
Validation loss: 2.56101740664928

Epoch: 6| Step: 7
Training loss: 0.16004918753336708
Validation loss: 2.521311023564693

Epoch: 6| Step: 8
Training loss: 0.17908969203336733
Validation loss: 2.5587530165913512

Epoch: 6| Step: 9
Training loss: 0.146509994809542
Validation loss: 2.5257231355576395

Epoch: 6| Step: 10
Training loss: 0.2765291096848807
Validation loss: 2.4942924237530253

Epoch: 6| Step: 11
Training loss: 0.15066080471133572
Validation loss: 2.5419553481485013

Epoch: 6| Step: 12
Training loss: 0.2639079838182536
Validation loss: 2.589273187261604

Epoch: 6| Step: 13
Training loss: 0.24660739579379654
Validation loss: 2.576966304686561

Epoch: 426| Step: 0
Training loss: 0.23629496475746156
Validation loss: 2.5635316124321426

Epoch: 6| Step: 1
Training loss: 0.2131841368587494
Validation loss: 2.5433967444013375

Epoch: 6| Step: 2
Training loss: 0.1506272164157974
Validation loss: 2.554898017557917

Epoch: 6| Step: 3
Training loss: 0.14016042900872222
Validation loss: 2.5315134986649652

Epoch: 6| Step: 4
Training loss: 0.4082622941496754
Validation loss: 2.539969508220847

Epoch: 6| Step: 5
Training loss: 0.21880584242443712
Validation loss: 2.529111071149217

Epoch: 6| Step: 6
Training loss: 0.23064369092321904
Validation loss: 2.54811918075181

Epoch: 6| Step: 7
Training loss: 0.36164777895760813
Validation loss: 2.5566252981041555

Epoch: 6| Step: 8
Training loss: 0.13755450252248183
Validation loss: 2.539398075264118

Epoch: 6| Step: 9
Training loss: 0.15830883568070753
Validation loss: 2.550752803150958

Epoch: 6| Step: 10
Training loss: 0.17771081453881662
Validation loss: 2.5256299607636197

Epoch: 6| Step: 11
Training loss: 0.18602371180618554
Validation loss: 2.5425370083012693

Epoch: 6| Step: 12
Training loss: 0.14964250790312691
Validation loss: 2.5012223388257824

Epoch: 6| Step: 13
Training loss: 0.24383960476844604
Validation loss: 2.5214546917191343

Epoch: 427| Step: 0
Training loss: 0.3073853118364393
Validation loss: 2.5269379342039593

Epoch: 6| Step: 1
Training loss: 0.19612451555169147
Validation loss: 2.527904876204062

Epoch: 6| Step: 2
Training loss: 0.2513297745991727
Validation loss: 2.5190525366779637

Epoch: 6| Step: 3
Training loss: 0.2111070446060549
Validation loss: 2.533181681314413

Epoch: 6| Step: 4
Training loss: 0.20611784631450114
Validation loss: 2.5414536735041295

Epoch: 6| Step: 5
Training loss: 0.333085775338419
Validation loss: 2.5086532173626286

Epoch: 6| Step: 6
Training loss: 0.16148751261799876
Validation loss: 2.4622756947464115

Epoch: 6| Step: 7
Training loss: 0.1787116879306734
Validation loss: 2.4508237467249714

Epoch: 6| Step: 8
Training loss: 0.29689280556939573
Validation loss: 2.4693532030012526

Epoch: 6| Step: 9
Training loss: 0.21281582279384062
Validation loss: 2.4745334356184086

Epoch: 6| Step: 10
Training loss: 0.23252704388731482
Validation loss: 2.4783434251149394

Epoch: 6| Step: 11
Training loss: 0.20682467645206917
Validation loss: 2.503302345529224

Epoch: 6| Step: 12
Training loss: 0.2927004921135514
Validation loss: 2.5131832413133917

Epoch: 6| Step: 13
Training loss: 0.35715654040418343
Validation loss: 2.4991275880241806

Epoch: 428| Step: 0
Training loss: 0.1343899688034971
Validation loss: 2.5010039180156425

Epoch: 6| Step: 1
Training loss: 0.12226552232000652
Validation loss: 2.499971141443531

Epoch: 6| Step: 2
Training loss: 0.3457107435346024
Validation loss: 2.5270834108114975

Epoch: 6| Step: 3
Training loss: 0.23810893222335358
Validation loss: 2.506112237740128

Epoch: 6| Step: 4
Training loss: 0.188843710464885
Validation loss: 2.522815042016899

Epoch: 6| Step: 5
Training loss: 0.30537610612591637
Validation loss: 2.517366683174919

Epoch: 6| Step: 6
Training loss: 0.1783953000321711
Validation loss: 2.514596142080226

Epoch: 6| Step: 7
Training loss: 0.25728307174247084
Validation loss: 2.5260656689103045

Epoch: 6| Step: 8
Training loss: 0.3596738112071187
Validation loss: 2.522105424756985

Epoch: 6| Step: 9
Training loss: 0.25676563881861453
Validation loss: 2.529566208979263

Epoch: 6| Step: 10
Training loss: 0.20144092752545173
Validation loss: 2.5117328056327857

Epoch: 6| Step: 11
Training loss: 0.17304947939391854
Validation loss: 2.5312054993649795

Epoch: 6| Step: 12
Training loss: 0.17296321947927243
Validation loss: 2.505068303176413

Epoch: 6| Step: 13
Training loss: 0.20225402359679368
Validation loss: 2.5322283210481107

Epoch: 429| Step: 0
Training loss: 0.17836296097989068
Validation loss: 2.5175927089981966

Epoch: 6| Step: 1
Training loss: 0.2294939325144552
Validation loss: 2.5272244115890565

Epoch: 6| Step: 2
Training loss: 0.15948017403986042
Validation loss: 2.512658505803688

Epoch: 6| Step: 3
Training loss: 0.12660980753311005
Validation loss: 2.5224517082339073

Epoch: 6| Step: 4
Training loss: 0.24093701179494514
Validation loss: 2.531685516595194

Epoch: 6| Step: 5
Training loss: 0.3030114167552202
Validation loss: 2.519913005977774

Epoch: 6| Step: 6
Training loss: 0.286303199318056
Validation loss: 2.5304502537636977

Epoch: 6| Step: 7
Training loss: 0.1167409734366057
Validation loss: 2.532116709035398

Epoch: 6| Step: 8
Training loss: 0.28171972944244894
Validation loss: 2.57464406677377

Epoch: 6| Step: 9
Training loss: 0.20196720421004902
Validation loss: 2.543465101272781

Epoch: 6| Step: 10
Training loss: 0.16244264608379927
Validation loss: 2.5299145837039028

Epoch: 6| Step: 11
Training loss: 0.17428856314756397
Validation loss: 2.5293627942382617

Epoch: 6| Step: 12
Training loss: 0.2940995708250697
Validation loss: 2.5381015611913473

Epoch: 6| Step: 13
Training loss: 0.2622079263171045
Validation loss: 2.5423193740203778

Epoch: 430| Step: 0
Training loss: 0.14822812120449158
Validation loss: 2.5778698687757906

Epoch: 6| Step: 1
Training loss: 0.14622381560765063
Validation loss: 2.516399246309326

Epoch: 6| Step: 2
Training loss: 0.11817201477278569
Validation loss: 2.5619678700138677

Epoch: 6| Step: 3
Training loss: 0.19311071069871086
Validation loss: 2.5624140713278396

Epoch: 6| Step: 4
Training loss: 0.2104049777728028
Validation loss: 2.5841276182927135

Epoch: 6| Step: 5
Training loss: 0.23387160282226468
Validation loss: 2.536233062217763

Epoch: 6| Step: 6
Training loss: 0.1230505382658599
Validation loss: 2.5451471328536552

Epoch: 6| Step: 7
Training loss: 0.26989819247501634
Validation loss: 2.5664339639528317

Epoch: 6| Step: 8
Training loss: 0.1716967764064433
Validation loss: 2.5634738773267425

Epoch: 6| Step: 9
Training loss: 0.33672867249209454
Validation loss: 2.5546485858025805

Epoch: 6| Step: 10
Training loss: 0.14472025035112546
Validation loss: 2.580905059512081

Epoch: 6| Step: 11
Training loss: 0.18864481832658458
Validation loss: 2.5392998909231608

Epoch: 6| Step: 12
Training loss: 0.4016346284084403
Validation loss: 2.5487497167644406

Epoch: 6| Step: 13
Training loss: 0.23348763489248828
Validation loss: 2.543846252552152

Epoch: 431| Step: 0
Training loss: 0.15479502360664457
Validation loss: 2.529208294806881

Epoch: 6| Step: 1
Training loss: 0.25220407511850795
Validation loss: 2.5560136945118415

Epoch: 6| Step: 2
Training loss: 0.16489840613840334
Validation loss: 2.5460753588152296

Epoch: 6| Step: 3
Training loss: 0.19766279405760043
Validation loss: 2.5645557654156725

Epoch: 6| Step: 4
Training loss: 0.19445182948525788
Validation loss: 2.4937424680921105

Epoch: 6| Step: 5
Training loss: 0.30658107835429943
Validation loss: 2.4999005456851386

Epoch: 6| Step: 6
Training loss: 0.13181636806345612
Validation loss: 2.5422014359412897

Epoch: 6| Step: 7
Training loss: 0.278335477181609
Validation loss: 2.5347429788702036

Epoch: 6| Step: 8
Training loss: 0.2527895063970574
Validation loss: 2.5072569516877206

Epoch: 6| Step: 9
Training loss: 0.20371962590035875
Validation loss: 2.49390566653533

Epoch: 6| Step: 10
Training loss: 0.22174035305136242
Validation loss: 2.509403241892184

Epoch: 6| Step: 11
Training loss: 0.28859062600006874
Validation loss: 2.5279670328808987

Epoch: 6| Step: 12
Training loss: 0.145566857922149
Validation loss: 2.521889075919664

Epoch: 6| Step: 13
Training loss: 0.1603611182410136
Validation loss: 2.492558743318685

Epoch: 432| Step: 0
Training loss: 0.18398672009247125
Validation loss: 2.524583337000943

Epoch: 6| Step: 1
Training loss: 0.2554320632770413
Validation loss: 2.492885144647856

Epoch: 6| Step: 2
Training loss: 0.19353894844308972
Validation loss: 2.5143439969425234

Epoch: 6| Step: 3
Training loss: 0.1168231186678644
Validation loss: 2.520052403876717

Epoch: 6| Step: 4
Training loss: 0.2212566422688481
Validation loss: 2.498208300170583

Epoch: 6| Step: 5
Training loss: 0.243526693905789
Validation loss: 2.5235360272151923

Epoch: 6| Step: 6
Training loss: 0.31972270257166013
Validation loss: 2.531829676963722

Epoch: 6| Step: 7
Training loss: 0.18623085442009504
Validation loss: 2.5546246677978566

Epoch: 6| Step: 8
Training loss: 0.2225527690210603
Validation loss: 2.5014986150812266

Epoch: 6| Step: 9
Training loss: 0.23600173511564354
Validation loss: 2.539963915575599

Epoch: 6| Step: 10
Training loss: 0.15527334153274353
Validation loss: 2.5588798442529797

Epoch: 6| Step: 11
Training loss: 0.1796088046363114
Validation loss: 2.523130968634625

Epoch: 6| Step: 12
Training loss: 0.17203131525002055
Validation loss: 2.5606082443249796

Epoch: 6| Step: 13
Training loss: 0.41618956032555365
Validation loss: 2.5192846390090278

Epoch: 433| Step: 0
Training loss: 0.2570388340628265
Validation loss: 2.5122793373881254

Epoch: 6| Step: 1
Training loss: 0.303796627308072
Validation loss: 2.5292346770113783

Epoch: 6| Step: 2
Training loss: 0.1750103789896115
Validation loss: 2.5024360816352678

Epoch: 6| Step: 3
Training loss: 0.2434204083197777
Validation loss: 2.508395161342146

Epoch: 6| Step: 4
Training loss: 0.37117842661849054
Validation loss: 2.5337599030352

Epoch: 6| Step: 5
Training loss: 0.1068804186289478
Validation loss: 2.5213150358098324

Epoch: 6| Step: 6
Training loss: 0.14085495875751383
Validation loss: 2.4936200195851383

Epoch: 6| Step: 7
Training loss: 0.1237473456021007
Validation loss: 2.5167037575942683

Epoch: 6| Step: 8
Training loss: 0.24873085785780308
Validation loss: 2.516759202110661

Epoch: 6| Step: 9
Training loss: 0.18367933753855092
Validation loss: 2.523969010068403

Epoch: 6| Step: 10
Training loss: 0.19109739959799996
Validation loss: 2.4965748601617417

Epoch: 6| Step: 11
Training loss: 0.2555568887164983
Validation loss: 2.520640610362224

Epoch: 6| Step: 12
Training loss: 0.21026612213976306
Validation loss: 2.541024215550167

Epoch: 6| Step: 13
Training loss: 0.19099189712340683
Validation loss: 2.5426750711024813

Epoch: 434| Step: 0
Training loss: 0.1244449511260596
Validation loss: 2.5360731915751478

Epoch: 6| Step: 1
Training loss: 0.30620093925806674
Validation loss: 2.527779340227051

Epoch: 6| Step: 2
Training loss: 0.19245049694707728
Validation loss: 2.529617539723904

Epoch: 6| Step: 3
Training loss: 0.12850096598681418
Validation loss: 2.517758843714769

Epoch: 6| Step: 4
Training loss: 0.18450414894641595
Validation loss: 2.5345626063447106

Epoch: 6| Step: 5
Training loss: 0.14870101977805456
Validation loss: 2.57506937701515

Epoch: 6| Step: 6
Training loss: 0.15782194368980954
Validation loss: 2.569314914118669

Epoch: 6| Step: 7
Training loss: 0.2925851472182524
Validation loss: 2.545638203287908

Epoch: 6| Step: 8
Training loss: 0.2613724937464753
Validation loss: 2.549480724605531

Epoch: 6| Step: 9
Training loss: 0.31165747315103565
Validation loss: 2.5049331282265874

Epoch: 6| Step: 10
Training loss: 0.2438490537970799
Validation loss: 2.5267314395799736

Epoch: 6| Step: 11
Training loss: 0.274480804797984
Validation loss: 2.5466698390843434

Epoch: 6| Step: 12
Training loss: 0.1937112592604854
Validation loss: 2.5298591751765698

Epoch: 6| Step: 13
Training loss: 0.16624811946730308
Validation loss: 2.51781640525451

Epoch: 435| Step: 0
Training loss: 0.19357322657976248
Validation loss: 2.5177992510717626

Epoch: 6| Step: 1
Training loss: 0.16520540894373034
Validation loss: 2.5450600149251126

Epoch: 6| Step: 2
Training loss: 0.27686934125211055
Validation loss: 2.5599955383705413

Epoch: 6| Step: 3
Training loss: 0.17127514872918265
Validation loss: 2.4961150532091234

Epoch: 6| Step: 4
Training loss: 0.19490068890061818
Validation loss: 2.521709519366013

Epoch: 6| Step: 5
Training loss: 0.3922906838659832
Validation loss: 2.5138730829135145

Epoch: 6| Step: 6
Training loss: 0.09583404888874163
Validation loss: 2.571081188249228

Epoch: 6| Step: 7
Training loss: 0.21204470637441397
Validation loss: 2.5371932557139436

Epoch: 6| Step: 8
Training loss: 0.2830848973232618
Validation loss: 2.5690765366529407

Epoch: 6| Step: 9
Training loss: 0.2856081165023249
Validation loss: 2.5862428292640196

Epoch: 6| Step: 10
Training loss: 0.3904417371011607
Validation loss: 2.5938958133097616

Epoch: 6| Step: 11
Training loss: 0.17288008416851097
Validation loss: 2.553746741930558

Epoch: 6| Step: 12
Training loss: 0.2314929108425095
Validation loss: 2.531960322248044

Epoch: 6| Step: 13
Training loss: 0.28802278764049055
Validation loss: 2.5402409612848897

Epoch: 436| Step: 0
Training loss: 0.31310019076928486
Validation loss: 2.5106829877828853

Epoch: 6| Step: 1
Training loss: 0.24671470170084991
Validation loss: 2.491622372626348

Epoch: 6| Step: 2
Training loss: 0.25495979637286886
Validation loss: 2.4580602840109065

Epoch: 6| Step: 3
Training loss: 0.3331001690633374
Validation loss: 2.4538590849683883

Epoch: 6| Step: 4
Training loss: 0.2609181756727585
Validation loss: 2.475924090929868

Epoch: 6| Step: 5
Training loss: 0.21668548127855028
Validation loss: 2.4796596285859507

Epoch: 6| Step: 6
Training loss: 0.23206841013908336
Validation loss: 2.4926869876839426

Epoch: 6| Step: 7
Training loss: 0.2919324092849894
Validation loss: 2.490914680325311

Epoch: 6| Step: 8
Training loss: 0.315555653649488
Validation loss: 2.474036655362819

Epoch: 6| Step: 9
Training loss: 0.2285897876346549
Validation loss: 2.4742919828145826

Epoch: 6| Step: 10
Training loss: 0.3439021207430696
Validation loss: 2.5042308644114186

Epoch: 6| Step: 11
Training loss: 0.32886564588564904
Validation loss: 2.4872126631973783

Epoch: 6| Step: 12
Training loss: 0.2152373609664577
Validation loss: 2.4718129669329723

Epoch: 6| Step: 13
Training loss: 0.22856534107331594
Validation loss: 2.494383647802157

Epoch: 437| Step: 0
Training loss: 0.22876181749138152
Validation loss: 2.475146325215995

Epoch: 6| Step: 1
Training loss: 0.13466491253146318
Validation loss: 2.50778391637809

Epoch: 6| Step: 2
Training loss: 0.11754265452962832
Validation loss: 2.4867863158592427

Epoch: 6| Step: 3
Training loss: 0.21373857262666457
Validation loss: 2.5003082762123308

Epoch: 6| Step: 4
Training loss: 0.2511230516220469
Validation loss: 2.5121858599078712

Epoch: 6| Step: 5
Training loss: 0.2685000277293669
Validation loss: 2.5272015274198973

Epoch: 6| Step: 6
Training loss: 0.23572690008700176
Validation loss: 2.53068860349783

Epoch: 6| Step: 7
Training loss: 0.3334854370023065
Validation loss: 2.5420538595425786

Epoch: 6| Step: 8
Training loss: 0.3580079823195434
Validation loss: 2.54516300681555

Epoch: 6| Step: 9
Training loss: 0.24677463978356678
Validation loss: 2.569799155580653

Epoch: 6| Step: 10
Training loss: 0.223206559456214
Validation loss: 2.5457024445992205

Epoch: 6| Step: 11
Training loss: 0.3945818764714406
Validation loss: 2.5714509165115764

Epoch: 6| Step: 12
Training loss: 0.25756921270870936
Validation loss: 2.529968976695516

Epoch: 6| Step: 13
Training loss: 0.15308586953821837
Validation loss: 2.569788294648382

Epoch: 438| Step: 0
Training loss: 0.29813289176044394
Validation loss: 2.5563328170528847

Epoch: 6| Step: 1
Training loss: 0.2169001908746867
Validation loss: 2.5466620706470477

Epoch: 6| Step: 2
Training loss: 0.14274470513748855
Validation loss: 2.5629282527721204

Epoch: 6| Step: 3
Training loss: 0.187199849054131
Validation loss: 2.569764054661734

Epoch: 6| Step: 4
Training loss: 0.19820266479992096
Validation loss: 2.611114949514686

Epoch: 6| Step: 5
Training loss: 0.2741750307362945
Validation loss: 2.5381123122714255

Epoch: 6| Step: 6
Training loss: 0.30555053894062234
Validation loss: 2.564808109918125

Epoch: 6| Step: 7
Training loss: 0.3879402789616662
Validation loss: 2.5373382595212024

Epoch: 6| Step: 8
Training loss: 0.34733731931841705
Validation loss: 2.5386795257435453

Epoch: 6| Step: 9
Training loss: 0.3250831891843243
Validation loss: 2.5388312454865125

Epoch: 6| Step: 10
Training loss: 0.28040296107057183
Validation loss: 2.5548207990617358

Epoch: 6| Step: 11
Training loss: 0.4538353416485058
Validation loss: 2.5370219931915647

Epoch: 6| Step: 12
Training loss: 0.3686513332327831
Validation loss: 2.564395405643116

Epoch: 6| Step: 13
Training loss: 0.31993447070542264
Validation loss: 2.564422862412443

Epoch: 439| Step: 0
Training loss: 0.24166385892903186
Validation loss: 2.567410778275488

Epoch: 6| Step: 1
Training loss: 0.27015255071116107
Validation loss: 2.5047224989011236

Epoch: 6| Step: 2
Training loss: 0.2791118675982959
Validation loss: 2.5086328718927855

Epoch: 6| Step: 3
Training loss: 0.28185585781660305
Validation loss: 2.5223237867826453

Epoch: 6| Step: 4
Training loss: 0.445921464777434
Validation loss: 2.532611770784848

Epoch: 6| Step: 5
Training loss: 0.16229487342404514
Validation loss: 2.5170978200722898

Epoch: 6| Step: 6
Training loss: 0.16962905295216876
Validation loss: 2.519488553010287

Epoch: 6| Step: 7
Training loss: 0.2392085744835199
Validation loss: 2.4810165827376855

Epoch: 6| Step: 8
Training loss: 0.2796376690081409
Validation loss: 2.469552463296955

Epoch: 6| Step: 9
Training loss: 0.4231893058381138
Validation loss: 2.4340972076754865

Epoch: 6| Step: 10
Training loss: 0.4145584734774774
Validation loss: 2.4675266967702987

Epoch: 6| Step: 11
Training loss: 0.22901312966063156
Validation loss: 2.4518137773565396

Epoch: 6| Step: 12
Training loss: 0.3278384660595541
Validation loss: 2.4166340891163145

Epoch: 6| Step: 13
Training loss: 0.2352716064761888
Validation loss: 2.3893718795719727

Epoch: 440| Step: 0
Training loss: 0.31078982896121277
Validation loss: 2.361104463772602

Epoch: 6| Step: 1
Training loss: 0.38762742992870874
Validation loss: 2.394140773669569

Epoch: 6| Step: 2
Training loss: 0.3473926251886219
Validation loss: 2.4057831744876146

Epoch: 6| Step: 3
Training loss: 0.43795742236651664
Validation loss: 2.395874080516546

Epoch: 6| Step: 4
Training loss: 0.2511936836800874
Validation loss: 2.404330798286376

Epoch: 6| Step: 5
Training loss: 0.22132027684498634
Validation loss: 2.4486047019131107

Epoch: 6| Step: 6
Training loss: 0.32359951126517933
Validation loss: 2.454275185158542

Epoch: 6| Step: 7
Training loss: 0.4033315439946441
Validation loss: 2.4817750425855807

Epoch: 6| Step: 8
Training loss: 0.3625691315074552
Validation loss: 2.4693208587156485

Epoch: 6| Step: 9
Training loss: 0.2634838140011507
Validation loss: 2.4971839097754662

Epoch: 6| Step: 10
Training loss: 0.3447747777661381
Validation loss: 2.4859021658289677

Epoch: 6| Step: 11
Training loss: 0.4837853626761187
Validation loss: 2.469672566906025

Epoch: 6| Step: 12
Training loss: 0.23113414110940078
Validation loss: 2.480655442029368

Epoch: 6| Step: 13
Training loss: 0.24574273674060212
Validation loss: 2.50324333803964

Epoch: 441| Step: 0
Training loss: 0.39575558660158244
Validation loss: 2.5144771402175445

Epoch: 6| Step: 1
Training loss: 0.38128141836564894
Validation loss: 2.5384142407978123

Epoch: 6| Step: 2
Training loss: 0.19538431754564647
Validation loss: 2.4925488242748317

Epoch: 6| Step: 3
Training loss: 0.1925337243109219
Validation loss: 2.526473705987505

Epoch: 6| Step: 4
Training loss: 0.2792455185843946
Validation loss: 2.4800807456597225

Epoch: 6| Step: 5
Training loss: 0.368913934119472
Validation loss: 2.4499644380281786

Epoch: 6| Step: 6
Training loss: 0.26613461470179206
Validation loss: 2.468970949714906

Epoch: 6| Step: 7
Training loss: 0.24873428012307638
Validation loss: 2.517680145026722

Epoch: 6| Step: 8
Training loss: 0.4432477432404378
Validation loss: 2.5345750180946247

Epoch: 6| Step: 9
Training loss: 0.26225629801865313
Validation loss: 2.5627121536147164

Epoch: 6| Step: 10
Training loss: 0.3386988372805866
Validation loss: 2.582560394503408

Epoch: 6| Step: 11
Training loss: 0.2769466969721971
Validation loss: 2.563521497982056

Epoch: 6| Step: 12
Training loss: 0.272409550459406
Validation loss: 2.5826859835753795

Epoch: 6| Step: 13
Training loss: 0.21568730946733874
Validation loss: 2.5330228482777177

Epoch: 442| Step: 0
Training loss: 0.23624832603073465
Validation loss: 2.521222840003107

Epoch: 6| Step: 1
Training loss: 0.2513721776791512
Validation loss: 2.468686382470397

Epoch: 6| Step: 2
Training loss: 0.36006277033817713
Validation loss: 2.4703472199690877

Epoch: 6| Step: 3
Training loss: 0.2631200030615758
Validation loss: 2.452783645885913

Epoch: 6| Step: 4
Training loss: 0.4073539004215337
Validation loss: 2.451412796059947

Epoch: 6| Step: 5
Training loss: 0.5172079814070825
Validation loss: 2.4384265050681067

Epoch: 6| Step: 6
Training loss: 0.42577894017704176
Validation loss: 2.442024101717009

Epoch: 6| Step: 7
Training loss: 0.3536236213409097
Validation loss: 2.4193143589126693

Epoch: 6| Step: 8
Training loss: 0.28627154011036826
Validation loss: 2.47908293873163

Epoch: 6| Step: 9
Training loss: 0.29735114162075815
Validation loss: 2.441626109996965

Epoch: 6| Step: 10
Training loss: 0.3534912817566534
Validation loss: 2.4915759624428753

Epoch: 6| Step: 11
Training loss: 0.1846670976816953
Validation loss: 2.4909351684554957

Epoch: 6| Step: 12
Training loss: 0.2778540872356981
Validation loss: 2.4755700994534564

Epoch: 6| Step: 13
Training loss: 0.3648294049859379
Validation loss: 2.5256337194908904

Epoch: 443| Step: 0
Training loss: 0.3942586126747428
Validation loss: 2.5003439533342173

Epoch: 6| Step: 1
Training loss: 0.39325560760865114
Validation loss: 2.4704515941229603

Epoch: 6| Step: 2
Training loss: 0.14290529755584225
Validation loss: 2.458975068042422

Epoch: 6| Step: 3
Training loss: 0.23399974664242387
Validation loss: 2.4762010606582687

Epoch: 6| Step: 4
Training loss: 0.3288859218377302
Validation loss: 2.425941693821475

Epoch: 6| Step: 5
Training loss: 0.22517087659904989
Validation loss: 2.4885365499463266

Epoch: 6| Step: 6
Training loss: 0.24931733982555393
Validation loss: 2.470438915209624

Epoch: 6| Step: 7
Training loss: 0.3735993772662852
Validation loss: 2.509670291285598

Epoch: 6| Step: 8
Training loss: 0.24591096265918552
Validation loss: 2.484621637977002

Epoch: 6| Step: 9
Training loss: 0.26466884745480895
Validation loss: 2.5142336501931464

Epoch: 6| Step: 10
Training loss: 0.32908831832905133
Validation loss: 2.500495189928072

Epoch: 6| Step: 11
Training loss: 0.34984371919619045
Validation loss: 2.515336574722027

Epoch: 6| Step: 12
Training loss: 0.21248786344651396
Validation loss: 2.519769779992984

Epoch: 6| Step: 13
Training loss: 0.12742149080491047
Validation loss: 2.4765024847852026

Epoch: 444| Step: 0
Training loss: 0.21621719392651284
Validation loss: 2.490999235615059

Epoch: 6| Step: 1
Training loss: 0.33416900216370143
Validation loss: 2.4963804407056442

Epoch: 6| Step: 2
Training loss: 0.35166339486115766
Validation loss: 2.4786310655746644

Epoch: 6| Step: 3
Training loss: 0.21912950565734818
Validation loss: 2.4873944486923185

Epoch: 6| Step: 4
Training loss: 0.2741774084983161
Validation loss: 2.5039074090052655

Epoch: 6| Step: 5
Training loss: 0.30638546866869976
Validation loss: 2.5284398587501564

Epoch: 6| Step: 6
Training loss: 0.3591312120592783
Validation loss: 2.490837700384648

Epoch: 6| Step: 7
Training loss: 0.27122350550171326
Validation loss: 2.4598281518969123

Epoch: 6| Step: 8
Training loss: 0.2043412822213267
Validation loss: 2.446902824192004

Epoch: 6| Step: 9
Training loss: 0.18096990729943263
Validation loss: 2.4550249809579925

Epoch: 6| Step: 10
Training loss: 0.2380164504256329
Validation loss: 2.470443431392469

Epoch: 6| Step: 11
Training loss: 0.26904764880975124
Validation loss: 2.4874546339787718

Epoch: 6| Step: 12
Training loss: 0.21264688730475423
Validation loss: 2.468312442914344

Epoch: 6| Step: 13
Training loss: 0.2294851748429891
Validation loss: 2.49664287813443

Epoch: 445| Step: 0
Training loss: 0.2423374419433584
Validation loss: 2.512449354970334

Epoch: 6| Step: 1
Training loss: 0.22213709690104
Validation loss: 2.4891274569820276

Epoch: 6| Step: 2
Training loss: 0.2422013432637962
Validation loss: 2.4798381024071534

Epoch: 6| Step: 3
Training loss: 0.2075190824616011
Validation loss: 2.51009378223463

Epoch: 6| Step: 4
Training loss: 0.24759884418666883
Validation loss: 2.5192849982241263

Epoch: 6| Step: 5
Training loss: 0.21085612175471685
Validation loss: 2.5353984839964814

Epoch: 6| Step: 6
Training loss: 0.2578383346098041
Validation loss: 2.544780272157433

Epoch: 6| Step: 7
Training loss: 0.23260780719129556
Validation loss: 2.5410051969476415

Epoch: 6| Step: 8
Training loss: 0.2900002193450098
Validation loss: 2.5112000828717242

Epoch: 6| Step: 9
Training loss: 0.19388274444567816
Validation loss: 2.501480162734458

Epoch: 6| Step: 10
Training loss: 0.31379963516398923
Validation loss: 2.4861239185493362

Epoch: 6| Step: 11
Training loss: 0.29919296631641584
Validation loss: 2.503052394452469

Epoch: 6| Step: 12
Training loss: 0.1541004862584581
Validation loss: 2.4715955230354023

Epoch: 6| Step: 13
Training loss: 0.15507006972601084
Validation loss: 2.485334799533708

Epoch: 446| Step: 0
Training loss: 0.2735380124232731
Validation loss: 2.49415628653461

Epoch: 6| Step: 1
Training loss: 0.33525254037891616
Validation loss: 2.4662185645919266

Epoch: 6| Step: 2
Training loss: 0.2400018916204531
Validation loss: 2.5104087751514115

Epoch: 6| Step: 3
Training loss: 0.2433665018890335
Validation loss: 2.499690401739378

Epoch: 6| Step: 4
Training loss: 0.15891202409769473
Validation loss: 2.475370321559958

Epoch: 6| Step: 5
Training loss: 0.15849845893867315
Validation loss: 2.4740574324771867

Epoch: 6| Step: 6
Training loss: 0.19017025808992036
Validation loss: 2.546371800805247

Epoch: 6| Step: 7
Training loss: 0.2682421721234421
Validation loss: 2.517916957113872

Epoch: 6| Step: 8
Training loss: 0.21313252835667126
Validation loss: 2.494065403654182

Epoch: 6| Step: 9
Training loss: 0.222332367488397
Validation loss: 2.522411972508913

Epoch: 6| Step: 10
Training loss: 0.18664992871734032
Validation loss: 2.507475080853255

Epoch: 6| Step: 11
Training loss: 0.3760086640364161
Validation loss: 2.526747653970194

Epoch: 6| Step: 12
Training loss: 0.17901388661833323
Validation loss: 2.546522430027398

Epoch: 6| Step: 13
Training loss: 0.2865643030731817
Validation loss: 2.5444497260640877

Epoch: 447| Step: 0
Training loss: 0.11653877945050009
Validation loss: 2.4971781751105193

Epoch: 6| Step: 1
Training loss: 0.2676367312661487
Validation loss: 2.4989844084664394

Epoch: 6| Step: 2
Training loss: 0.31857623571772736
Validation loss: 2.5158264409687576

Epoch: 6| Step: 3
Training loss: 0.23971507693408092
Validation loss: 2.518932617174235

Epoch: 6| Step: 4
Training loss: 0.12761345573272542
Validation loss: 2.530358499213986

Epoch: 6| Step: 5
Training loss: 0.21282747189403586
Validation loss: 2.4937050376453476

Epoch: 6| Step: 6
Training loss: 0.2213756476058405
Validation loss: 2.509572852122493

Epoch: 6| Step: 7
Training loss: 0.17040835273028776
Validation loss: 2.4953291204882473

Epoch: 6| Step: 8
Training loss: 0.21728057856506075
Validation loss: 2.4886042122804355

Epoch: 6| Step: 9
Training loss: 0.24772527075874082
Validation loss: 2.5109453469653262

Epoch: 6| Step: 10
Training loss: 0.22459147008765992
Validation loss: 2.4941084623730343

Epoch: 6| Step: 11
Training loss: 0.2283720315224577
Validation loss: 2.524026672733613

Epoch: 6| Step: 12
Training loss: 0.16326373795776805
Validation loss: 2.505347768990393

Epoch: 6| Step: 13
Training loss: 0.15693920246539256
Validation loss: 2.516706860400683

Epoch: 448| Step: 0
Training loss: 0.3207361861738246
Validation loss: 2.5046590859979654

Epoch: 6| Step: 1
Training loss: 0.1532513834060875
Validation loss: 2.4927092232492236

Epoch: 6| Step: 2
Training loss: 0.268480602796245
Validation loss: 2.5431258096374276

Epoch: 6| Step: 3
Training loss: 0.2921338200345578
Validation loss: 2.4912427747908454

Epoch: 6| Step: 4
Training loss: 0.18885227172084634
Validation loss: 2.5128165611162867

Epoch: 6| Step: 5
Training loss: 0.27604471810771586
Validation loss: 2.473499181309487

Epoch: 6| Step: 6
Training loss: 0.30686888733348383
Validation loss: 2.4675696113289938

Epoch: 6| Step: 7
Training loss: 0.26825342099549415
Validation loss: 2.4914160543946444

Epoch: 6| Step: 8
Training loss: 0.21018281789981696
Validation loss: 2.4739801963958388

Epoch: 6| Step: 9
Training loss: 0.1452774425999722
Validation loss: 2.4723621224511905

Epoch: 6| Step: 10
Training loss: 0.20714795224231652
Validation loss: 2.5027610196374153

Epoch: 6| Step: 11
Training loss: 0.21282879342711525
Validation loss: 2.5221752810932077

Epoch: 6| Step: 12
Training loss: 0.17684353809778786
Validation loss: 2.5216439460041116

Epoch: 6| Step: 13
Training loss: 0.1794651667001217
Validation loss: 2.529686670250574

Epoch: 449| Step: 0
Training loss: 0.17697269592520473
Validation loss: 2.4920937174000133

Epoch: 6| Step: 1
Training loss: 0.23953505043354292
Validation loss: 2.5078422149266557

Epoch: 6| Step: 2
Training loss: 0.13105822869645928
Validation loss: 2.5043888248683475

Epoch: 6| Step: 3
Training loss: 0.14793631368321786
Validation loss: 2.5345877423257135

Epoch: 6| Step: 4
Training loss: 0.3203369224355874
Validation loss: 2.5224294962674336

Epoch: 6| Step: 5
Training loss: 0.21182759010543983
Validation loss: 2.557923882755968

Epoch: 6| Step: 6
Training loss: 0.2621816697455659
Validation loss: 2.5643113360158902

Epoch: 6| Step: 7
Training loss: 0.22892668017720322
Validation loss: 2.518392813563036

Epoch: 6| Step: 8
Training loss: 0.32221376406367686
Validation loss: 2.5010995067258968

Epoch: 6| Step: 9
Training loss: 0.35219995139856564
Validation loss: 2.51444200620416

Epoch: 6| Step: 10
Training loss: 0.20148263465333846
Validation loss: 2.4902447541720503

Epoch: 6| Step: 11
Training loss: 0.2410878164534065
Validation loss: 2.536984570857054

Epoch: 6| Step: 12
Training loss: 0.22289482519214934
Validation loss: 2.529963788547506

Epoch: 6| Step: 13
Training loss: 0.30185304145244324
Validation loss: 2.4969661721618106

Epoch: 450| Step: 0
Training loss: 0.2913907724519523
Validation loss: 2.5555531755856595

Epoch: 6| Step: 1
Training loss: 0.2850289779286458
Validation loss: 2.535374462250202

Epoch: 6| Step: 2
Training loss: 0.2410548705262741
Validation loss: 2.5441213952189647

Epoch: 6| Step: 3
Training loss: 0.1915241189937149
Validation loss: 2.507188484943343

Epoch: 6| Step: 4
Training loss: 0.19697326296938428
Validation loss: 2.5038852649496808

Epoch: 6| Step: 5
Training loss: 0.12185597867349991
Validation loss: 2.5080790180828587

Epoch: 6| Step: 6
Training loss: 0.3156487970540138
Validation loss: 2.5399135145976643

Epoch: 6| Step: 7
Training loss: 0.24078029538311313
Validation loss: 2.507327245232034

Epoch: 6| Step: 8
Training loss: 0.2963136334625882
Validation loss: 2.5484709413387647

Epoch: 6| Step: 9
Training loss: 0.1863804213990934
Validation loss: 2.5656198177660268

Epoch: 6| Step: 10
Training loss: 0.24126282415746228
Validation loss: 2.534410991170118

Epoch: 6| Step: 11
Training loss: 0.19477755721563858
Validation loss: 2.496397197793221

Epoch: 6| Step: 12
Training loss: 0.10721927958563086
Validation loss: 2.544781986771044

Epoch: 6| Step: 13
Training loss: 0.26010134521398304
Validation loss: 2.4876289359406614

Epoch: 451| Step: 0
Training loss: 0.3307241967596262
Validation loss: 2.5010373526978946

Epoch: 6| Step: 1
Training loss: 0.2748916922042097
Validation loss: 2.475975209472672

Epoch: 6| Step: 2
Training loss: 0.16358627730374856
Validation loss: 2.5018245376465886

Epoch: 6| Step: 3
Training loss: 0.13893819139199595
Validation loss: 2.47433742207241

Epoch: 6| Step: 4
Training loss: 0.1146139885975584
Validation loss: 2.52155933453145

Epoch: 6| Step: 5
Training loss: 0.30713128360380076
Validation loss: 2.490439757616718

Epoch: 6| Step: 6
Training loss: 0.18404669384534933
Validation loss: 2.501281129047909

Epoch: 6| Step: 7
Training loss: 0.32338197572466376
Validation loss: 2.51873671835736

Epoch: 6| Step: 8
Training loss: 0.13968916612523288
Validation loss: 2.5138463477689514

Epoch: 6| Step: 9
Training loss: 0.18130414828080035
Validation loss: 2.501993203576009

Epoch: 6| Step: 10
Training loss: 0.1349547206699968
Validation loss: 2.5293285116241973

Epoch: 6| Step: 11
Training loss: 0.23397803067122427
Validation loss: 2.5071889844424162

Epoch: 6| Step: 12
Training loss: 0.2334409379769774
Validation loss: 2.5277080692678795

Epoch: 6| Step: 13
Training loss: 0.13794488136616034
Validation loss: 2.531625727644154

Epoch: 452| Step: 0
Training loss: 0.20361556822592475
Validation loss: 2.5253937445422716

Epoch: 6| Step: 1
Training loss: 0.1675471070400155
Validation loss: 2.5005101862613106

Epoch: 6| Step: 2
Training loss: 0.22982198677006843
Validation loss: 2.5284909801773456

Epoch: 6| Step: 3
Training loss: 0.1863030534746909
Validation loss: 2.5321771647186915

Epoch: 6| Step: 4
Training loss: 0.17253412311747893
Validation loss: 2.5538704302989736

Epoch: 6| Step: 5
Training loss: 0.2911048214824354
Validation loss: 2.5006567789610137

Epoch: 6| Step: 6
Training loss: 0.18174814303051598
Validation loss: 2.5165295440548094

Epoch: 6| Step: 7
Training loss: 0.24491340403532344
Validation loss: 2.5019961232840715

Epoch: 6| Step: 8
Training loss: 0.26526326905569547
Validation loss: 2.55443667275246

Epoch: 6| Step: 9
Training loss: 0.14895193777048382
Validation loss: 2.502530310531455

Epoch: 6| Step: 10
Training loss: 0.14126242441628176
Validation loss: 2.5298838572976017

Epoch: 6| Step: 11
Training loss: 0.1781612760848246
Validation loss: 2.504664503635553

Epoch: 6| Step: 12
Training loss: 0.27025224477151494
Validation loss: 2.5523147203542065

Epoch: 6| Step: 13
Training loss: 0.21420792213526121
Validation loss: 2.5569875187223183

Epoch: 453| Step: 0
Training loss: 0.17004293207330873
Validation loss: 2.5218882098140862

Epoch: 6| Step: 1
Training loss: 0.2742491800318573
Validation loss: 2.527050138130929

Epoch: 6| Step: 2
Training loss: 0.16974694466544946
Validation loss: 2.5029295891714263

Epoch: 6| Step: 3
Training loss: 0.27314549249201003
Validation loss: 2.467224735083798

Epoch: 6| Step: 4
Training loss: 0.22264596011829046
Validation loss: 2.468519738766199

Epoch: 6| Step: 5
Training loss: 0.26542973353460614
Validation loss: 2.5084713745752873

Epoch: 6| Step: 6
Training loss: 0.21527793533480086
Validation loss: 2.472102486973646

Epoch: 6| Step: 7
Training loss: 0.19538987534420002
Validation loss: 2.5102865191932757

Epoch: 6| Step: 8
Training loss: 0.196407102326552
Validation loss: 2.4944494300722604

Epoch: 6| Step: 9
Training loss: 0.23303655077847293
Validation loss: 2.4881631254536916

Epoch: 6| Step: 10
Training loss: 0.2759730355698144
Validation loss: 2.4774173648138698

Epoch: 6| Step: 11
Training loss: 0.21958827435425393
Validation loss: 2.4316932880411626

Epoch: 6| Step: 12
Training loss: 0.1932850704571072
Validation loss: 2.471803637751784

Epoch: 6| Step: 13
Training loss: 0.36117991939153626
Validation loss: 2.464892427456441

Epoch: 454| Step: 0
Training loss: 0.17348611597058386
Validation loss: 2.449360722675033

Epoch: 6| Step: 1
Training loss: 0.3172340161646048
Validation loss: 2.478094953706493

Epoch: 6| Step: 2
Training loss: 0.12631353509904472
Validation loss: 2.4818766765833784

Epoch: 6| Step: 3
Training loss: 0.2642461668438459
Validation loss: 2.461584642271925

Epoch: 6| Step: 4
Training loss: 0.12045750054604094
Validation loss: 2.5058646969444625

Epoch: 6| Step: 5
Training loss: 0.12339993566223698
Validation loss: 2.4887335117991882

Epoch: 6| Step: 6
Training loss: 0.19426830590950306
Validation loss: 2.5109789162578355

Epoch: 6| Step: 7
Training loss: 0.14358223112393223
Validation loss: 2.511398765321749

Epoch: 6| Step: 8
Training loss: 0.17127251148186698
Validation loss: 2.5117673508615095

Epoch: 6| Step: 9
Training loss: 0.20620667696159303
Validation loss: 2.522644609235103

Epoch: 6| Step: 10
Training loss: 0.2335277901215407
Validation loss: 2.502327785886868

Epoch: 6| Step: 11
Training loss: 0.2842685783290267
Validation loss: 2.5001376093656775

Epoch: 6| Step: 12
Training loss: 0.19058332847628012
Validation loss: 2.509397222537268

Epoch: 6| Step: 13
Training loss: 0.09127437746033669
Validation loss: 2.5062142099811844

Epoch: 455| Step: 0
Training loss: 0.3394888636275235
Validation loss: 2.5050111753211888

Epoch: 6| Step: 1
Training loss: 0.2803235557485268
Validation loss: 2.516048271713416

Epoch: 6| Step: 2
Training loss: 0.19419708275332453
Validation loss: 2.498415877814369

Epoch: 6| Step: 3
Training loss: 0.1324149943001669
Validation loss: 2.5191849543310836

Epoch: 6| Step: 4
Training loss: 0.22407800596843291
Validation loss: 2.5005372095764375

Epoch: 6| Step: 5
Training loss: 0.1769716434178231
Validation loss: 2.5284542477823617

Epoch: 6| Step: 6
Training loss: 0.21836257584192906
Validation loss: 2.473317082991884

Epoch: 6| Step: 7
Training loss: 0.13340380812818578
Validation loss: 2.4833416081045865

Epoch: 6| Step: 8
Training loss: 0.11920450405433697
Validation loss: 2.4946123643995457

Epoch: 6| Step: 9
Training loss: 0.08204421724280272
Validation loss: 2.5012067486973852

Epoch: 6| Step: 10
Training loss: 0.15992589410670865
Validation loss: 2.4745600308804296

Epoch: 6| Step: 11
Training loss: 0.21588158061473595
Validation loss: 2.5138224821086697

Epoch: 6| Step: 12
Training loss: 0.1550219256233091
Validation loss: 2.475600718135567

Epoch: 6| Step: 13
Training loss: 0.2189718466885869
Validation loss: 2.458106966130943

Epoch: 456| Step: 0
Training loss: 0.15999497457897174
Validation loss: 2.452732976331491

Epoch: 6| Step: 1
Training loss: 0.158922731084996
Validation loss: 2.5001204102754664

Epoch: 6| Step: 2
Training loss: 0.24097702329322265
Validation loss: 2.449286955269583

Epoch: 6| Step: 3
Training loss: 0.10276030332936402
Validation loss: 2.4574579947262505

Epoch: 6| Step: 4
Training loss: 0.2877704768198776
Validation loss: 2.4874819939123913

Epoch: 6| Step: 5
Training loss: 0.2729402107294588
Validation loss: 2.4441768773489803

Epoch: 6| Step: 6
Training loss: 0.1409652553958999
Validation loss: 2.462098813871881

Epoch: 6| Step: 7
Training loss: 0.1649745724874103
Validation loss: 2.4844002547308732

Epoch: 6| Step: 8
Training loss: 0.294601430550635
Validation loss: 2.4761127801022553

Epoch: 6| Step: 9
Training loss: 0.17396320495141934
Validation loss: 2.4751581923294133

Epoch: 6| Step: 10
Training loss: 0.15681402212447965
Validation loss: 2.5042821532143495

Epoch: 6| Step: 11
Training loss: 0.16019510170086243
Validation loss: 2.520864346329627

Epoch: 6| Step: 12
Training loss: 0.23326360726504336
Validation loss: 2.560496844635977

Epoch: 6| Step: 13
Training loss: 0.15951011157122386
Validation loss: 2.5104294217782637

Epoch: 457| Step: 0
Training loss: 0.18996983293355496
Validation loss: 2.5280683831885247

Epoch: 6| Step: 1
Training loss: 0.287090430640276
Validation loss: 2.517818126011903

Epoch: 6| Step: 2
Training loss: 0.31594806038462925
Validation loss: 2.4867434020033747

Epoch: 6| Step: 3
Training loss: 0.15431889244117203
Validation loss: 2.517912985780284

Epoch: 6| Step: 4
Training loss: 0.19959124167356207
Validation loss: 2.5015542536425506

Epoch: 6| Step: 5
Training loss: 0.2062145535035853
Validation loss: 2.5412038013144502

Epoch: 6| Step: 6
Training loss: 0.24942698224927842
Validation loss: 2.519884680681002

Epoch: 6| Step: 7
Training loss: 0.21983964341428228
Validation loss: 2.5095248559220584

Epoch: 6| Step: 8
Training loss: 0.13887272648019053
Validation loss: 2.5641016802932186

Epoch: 6| Step: 9
Training loss: 0.23626334508413036
Validation loss: 2.5682013619754334

Epoch: 6| Step: 10
Training loss: 0.14547301522792444
Validation loss: 2.542300969386836

Epoch: 6| Step: 11
Training loss: 0.17868591091667607
Validation loss: 2.518546495415273

Epoch: 6| Step: 12
Training loss: 0.18028611523984378
Validation loss: 2.510774268257212

Epoch: 6| Step: 13
Training loss: 0.1759123207558688
Validation loss: 2.513819666390452

Epoch: 458| Step: 0
Training loss: 0.1888878046753409
Validation loss: 2.516971874439567

Epoch: 6| Step: 1
Training loss: 0.24824437966568097
Validation loss: 2.494780954286626

Epoch: 6| Step: 2
Training loss: 0.28215287246397897
Validation loss: 2.4816759611709807

Epoch: 6| Step: 3
Training loss: 0.2007364913390594
Validation loss: 2.4984040878234928

Epoch: 6| Step: 4
Training loss: 0.1649844570226544
Validation loss: 2.4820286428440483

Epoch: 6| Step: 5
Training loss: 0.27392435328473475
Validation loss: 2.4943525803231053

Epoch: 6| Step: 6
Training loss: 0.15701619284830165
Validation loss: 2.5303816435782585

Epoch: 6| Step: 7
Training loss: 0.2339123769555242
Validation loss: 2.5482884761538354

Epoch: 6| Step: 8
Training loss: 0.3065856714270103
Validation loss: 2.50898965246906

Epoch: 6| Step: 9
Training loss: 0.19745173975259447
Validation loss: 2.5440609744709115

Epoch: 6| Step: 10
Training loss: 0.28919070210362813
Validation loss: 2.5482469692570535

Epoch: 6| Step: 11
Training loss: 0.1731851075161011
Validation loss: 2.5518837893244752

Epoch: 6| Step: 12
Training loss: 0.15609686022648805
Validation loss: 2.545281004073937

Epoch: 6| Step: 13
Training loss: 0.11091096419652546
Validation loss: 2.5515062089366927

Epoch: 459| Step: 0
Training loss: 0.16074448232762412
Validation loss: 2.5670792106940197

Epoch: 6| Step: 1
Training loss: 0.21615592615087587
Validation loss: 2.570705339538285

Epoch: 6| Step: 2
Training loss: 0.21502143274811436
Validation loss: 2.5880025676678993

Epoch: 6| Step: 3
Training loss: 0.22524820783454674
Validation loss: 2.5508362201444217

Epoch: 6| Step: 4
Training loss: 0.24531046022186706
Validation loss: 2.562163035930028

Epoch: 6| Step: 5
Training loss: 0.21968730151898683
Validation loss: 2.546825605495153

Epoch: 6| Step: 6
Training loss: 0.1469378255842943
Validation loss: 2.55979235342138

Epoch: 6| Step: 7
Training loss: 0.2221611273414353
Validation loss: 2.5639772436518706

Epoch: 6| Step: 8
Training loss: 0.24887801767547793
Validation loss: 2.5663073108248082

Epoch: 6| Step: 9
Training loss: 0.1989626453757901
Validation loss: 2.5925394478426282

Epoch: 6| Step: 10
Training loss: 0.12646270809064084
Validation loss: 2.5834071416429927

Epoch: 6| Step: 11
Training loss: 0.19048458188471035
Validation loss: 2.5410764127521395

Epoch: 6| Step: 12
Training loss: 0.2659651177585992
Validation loss: 2.5657838948446168

Epoch: 6| Step: 13
Training loss: 0.24464157589446633
Validation loss: 2.5468363947395707

Epoch: 460| Step: 0
Training loss: 0.1655435526065742
Validation loss: 2.5588926750482113

Epoch: 6| Step: 1
Training loss: 0.12913924892082393
Validation loss: 2.5783780776399134

Epoch: 6| Step: 2
Training loss: 0.28914579273997487
Validation loss: 2.542996837327969

Epoch: 6| Step: 3
Training loss: 0.17395412507553948
Validation loss: 2.5592223293857908

Epoch: 6| Step: 4
Training loss: 0.14841974930285667
Validation loss: 2.5284280850612286

Epoch: 6| Step: 5
Training loss: 0.11830498040329346
Validation loss: 2.5086411709513667

Epoch: 6| Step: 6
Training loss: 0.1826316093421185
Validation loss: 2.5154827895286025

Epoch: 6| Step: 7
Training loss: 0.2047156718573975
Validation loss: 2.514131484194215

Epoch: 6| Step: 8
Training loss: 0.15732361777419912
Validation loss: 2.5186931579978236

Epoch: 6| Step: 9
Training loss: 0.28791102902532634
Validation loss: 2.517718952465818

Epoch: 6| Step: 10
Training loss: 0.2762863391389817
Validation loss: 2.5139080260204123

Epoch: 6| Step: 11
Training loss: 0.18786444610500444
Validation loss: 2.511968249008436

Epoch: 6| Step: 12
Training loss: 0.11890761853983221
Validation loss: 2.532676162335299

Epoch: 6| Step: 13
Training loss: 0.19095074696640704
Validation loss: 2.5253411082219555

Epoch: 461| Step: 0
Training loss: 0.15495311637509887
Validation loss: 2.4579144613381962

Epoch: 6| Step: 1
Training loss: 0.1061357318475264
Validation loss: 2.500715042730808

Epoch: 6| Step: 2
Training loss: 0.2579305118615211
Validation loss: 2.501265593095159

Epoch: 6| Step: 3
Training loss: 0.19398986250958294
Validation loss: 2.5276267349778894

Epoch: 6| Step: 4
Training loss: 0.14431077017641578
Validation loss: 2.5211291114647216

Epoch: 6| Step: 5
Training loss: 0.1315446815294255
Validation loss: 2.5541117395878152

Epoch: 6| Step: 6
Training loss: 0.17382825894297035
Validation loss: 2.499828576804453

Epoch: 6| Step: 7
Training loss: 0.19545933925683165
Validation loss: 2.547524755917686

Epoch: 6| Step: 8
Training loss: 0.22625417941274487
Validation loss: 2.5306504042146223

Epoch: 6| Step: 9
Training loss: 0.15407366844651324
Validation loss: 2.522045822915921

Epoch: 6| Step: 10
Training loss: 0.1143396524621447
Validation loss: 2.519277859704844

Epoch: 6| Step: 11
Training loss: 0.1983179595909875
Validation loss: 2.503273966436917

Epoch: 6| Step: 12
Training loss: 0.3328196086034828
Validation loss: 2.5320511166362962

Epoch: 6| Step: 13
Training loss: 0.23138888190217813
Validation loss: 2.513862605495638

Epoch: 462| Step: 0
Training loss: 0.16732068683828014
Validation loss: 2.4904758190425187

Epoch: 6| Step: 1
Training loss: 0.13709663212348536
Validation loss: 2.4996555614075944

Epoch: 6| Step: 2
Training loss: 0.23767963661780372
Validation loss: 2.4876874007500085

Epoch: 6| Step: 3
Training loss: 0.18641072008092388
Validation loss: 2.4830637075684674

Epoch: 6| Step: 4
Training loss: 0.18282227041756868
Validation loss: 2.5072894727363466

Epoch: 6| Step: 5
Training loss: 0.13193540705995482
Validation loss: 2.50060418119263

Epoch: 6| Step: 6
Training loss: 0.16712495757040371
Validation loss: 2.5019614400675283

Epoch: 6| Step: 7
Training loss: 0.28157071530278444
Validation loss: 2.507569517071014

Epoch: 6| Step: 8
Training loss: 0.17336298291138208
Validation loss: 2.5013090157282933

Epoch: 6| Step: 9
Training loss: 0.2058162122786089
Validation loss: 2.5216333117757412

Epoch: 6| Step: 10
Training loss: 0.20153212466281556
Validation loss: 2.4672667498727234

Epoch: 6| Step: 11
Training loss: 0.1515040547954288
Validation loss: 2.5229716532436064

Epoch: 6| Step: 12
Training loss: 0.23287624536120882
Validation loss: 2.488159712467886

Epoch: 6| Step: 13
Training loss: 0.06433711665797867
Validation loss: 2.513672973409219

Epoch: 463| Step: 0
Training loss: 0.2143560943941966
Validation loss: 2.5126047267565004

Epoch: 6| Step: 1
Training loss: 0.19916477594183107
Validation loss: 2.520562066744458

Epoch: 6| Step: 2
Training loss: 0.17249055653444648
Validation loss: 2.5106856487496376

Epoch: 6| Step: 3
Training loss: 0.18697786149195478
Validation loss: 2.5046761658974463

Epoch: 6| Step: 4
Training loss: 0.12314457269436459
Validation loss: 2.5475898191004065

Epoch: 6| Step: 5
Training loss: 0.24614397172281732
Validation loss: 2.5222406424407113

Epoch: 6| Step: 6
Training loss: 0.17117980682715694
Validation loss: 2.5250983810062237

Epoch: 6| Step: 7
Training loss: 0.2349475225739728
Validation loss: 2.53706270761183

Epoch: 6| Step: 8
Training loss: 0.16416903284004725
Validation loss: 2.528992624054152

Epoch: 6| Step: 9
Training loss: 0.20834475525698898
Validation loss: 2.4814968312748262

Epoch: 6| Step: 10
Training loss: 0.12873188421425885
Validation loss: 2.5090341690752695

Epoch: 6| Step: 11
Training loss: 0.29926181314012806
Validation loss: 2.4768438500642787

Epoch: 6| Step: 12
Training loss: 0.17922661595264555
Validation loss: 2.4860822564760796

Epoch: 6| Step: 13
Training loss: 0.13850437041128302
Validation loss: 2.481891052029078

Epoch: 464| Step: 0
Training loss: 0.1785647310124927
Validation loss: 2.4792547255984654

Epoch: 6| Step: 1
Training loss: 0.30613277683060713
Validation loss: 2.523917638594436

Epoch: 6| Step: 2
Training loss: 0.1202590693693934
Validation loss: 2.495440211237754

Epoch: 6| Step: 3
Training loss: 0.14890081477778125
Validation loss: 2.5403900830594086

Epoch: 6| Step: 4
Training loss: 0.13374155830098475
Validation loss: 2.532386193601082

Epoch: 6| Step: 5
Training loss: 0.16401295822183629
Validation loss: 2.5477338045420965

Epoch: 6| Step: 6
Training loss: 0.14756895997086328
Validation loss: 2.524088515597807

Epoch: 6| Step: 7
Training loss: 0.11382074390402673
Validation loss: 2.521445749555928

Epoch: 6| Step: 8
Training loss: 0.27971894710782286
Validation loss: 2.5338006116952543

Epoch: 6| Step: 9
Training loss: 0.24008738665307716
Validation loss: 2.549362406360899

Epoch: 6| Step: 10
Training loss: 0.16706495762989249
Validation loss: 2.535514249706796

Epoch: 6| Step: 11
Training loss: 0.10922599758883138
Validation loss: 2.525603678191555

Epoch: 6| Step: 12
Training loss: 0.2234021792471146
Validation loss: 2.5385034816303063

Epoch: 6| Step: 13
Training loss: 0.19510172915391416
Validation loss: 2.502743649074096

Epoch: 465| Step: 0
Training loss: 0.19493826298443592
Validation loss: 2.4975145783017836

Epoch: 6| Step: 1
Training loss: 0.13907358253979998
Validation loss: 2.4980716631131874

Epoch: 6| Step: 2
Training loss: 0.1053095914724878
Validation loss: 2.518090857303492

Epoch: 6| Step: 3
Training loss: 0.24812031957694472
Validation loss: 2.5334619549621125

Epoch: 6| Step: 4
Training loss: 0.15756452264361379
Validation loss: 2.5205481956211666

Epoch: 6| Step: 5
Training loss: 0.14569837138012576
Validation loss: 2.5079599139806397

Epoch: 6| Step: 6
Training loss: 0.23520014470434117
Validation loss: 2.5413596732580763

Epoch: 6| Step: 7
Training loss: 0.1509136110656372
Validation loss: 2.499174071850681

Epoch: 6| Step: 8
Training loss: 0.1302850775258241
Validation loss: 2.509963870471383

Epoch: 6| Step: 9
Training loss: 0.14796969457765938
Validation loss: 2.5501762388349047

Epoch: 6| Step: 10
Training loss: 0.25618725799415104
Validation loss: 2.4926130967977667

Epoch: 6| Step: 11
Training loss: 0.19534576132798745
Validation loss: 2.5019373247585692

Epoch: 6| Step: 12
Training loss: 0.2732117674815705
Validation loss: 2.566393986200657

Epoch: 6| Step: 13
Training loss: 0.15840735616164162
Validation loss: 2.5188194012717413

Epoch: 466| Step: 0
Training loss: 0.2066396933175845
Validation loss: 2.511681950427366

Epoch: 6| Step: 1
Training loss: 0.31541638892517226
Validation loss: 2.4974784132112524

Epoch: 6| Step: 2
Training loss: 0.10392395492523321
Validation loss: 2.5060718398893034

Epoch: 6| Step: 3
Training loss: 0.12895213379797332
Validation loss: 2.505900168101034

Epoch: 6| Step: 4
Training loss: 0.12181897036991597
Validation loss: 2.4888477149110058

Epoch: 6| Step: 5
Training loss: 0.20953920281015354
Validation loss: 2.512646326060922

Epoch: 6| Step: 6
Training loss: 0.23258697832483363
Validation loss: 2.512095023115279

Epoch: 6| Step: 7
Training loss: 0.22101522001335228
Validation loss: 2.482710913749667

Epoch: 6| Step: 8
Training loss: 0.12940852971200345
Validation loss: 2.494290469385313

Epoch: 6| Step: 9
Training loss: 0.2334207978969691
Validation loss: 2.5092219571509475

Epoch: 6| Step: 10
Training loss: 0.15733866515746103
Validation loss: 2.520399866046419

Epoch: 6| Step: 11
Training loss: 0.13896604686224295
Validation loss: 2.499650558537708

Epoch: 6| Step: 12
Training loss: 0.1510798958104409
Validation loss: 2.5298590556009013

Epoch: 6| Step: 13
Training loss: 0.1382475930542461
Validation loss: 2.5017529638146994

Epoch: 467| Step: 0
Training loss: 0.16810815592945247
Validation loss: 2.510995887827764

Epoch: 6| Step: 1
Training loss: 0.1782167721129738
Validation loss: 2.4920778783085584

Epoch: 6| Step: 2
Training loss: 0.16657237214217377
Validation loss: 2.498566571366776

Epoch: 6| Step: 3
Training loss: 0.2660157331110753
Validation loss: 2.513884749365976

Epoch: 6| Step: 4
Training loss: 0.24970606571349493
Validation loss: 2.503191284164013

Epoch: 6| Step: 5
Training loss: 0.11385773444482498
Validation loss: 2.5240567295014835

Epoch: 6| Step: 6
Training loss: 0.22495082112461548
Validation loss: 2.5114846653535117

Epoch: 6| Step: 7
Training loss: 0.17698147359298344
Validation loss: 2.4801595153881575

Epoch: 6| Step: 8
Training loss: 0.10710189151845553
Validation loss: 2.477164253905661

Epoch: 6| Step: 9
Training loss: 0.10091978520729276
Validation loss: 2.4643765162970426

Epoch: 6| Step: 10
Training loss: 0.1960841765479512
Validation loss: 2.544402814463864

Epoch: 6| Step: 11
Training loss: 0.24732504969769592
Validation loss: 2.4774015172620434

Epoch: 6| Step: 12
Training loss: 0.13142343908777684
Validation loss: 2.5097804576661633

Epoch: 6| Step: 13
Training loss: 0.13413319566578527
Validation loss: 2.516031413699646

Epoch: 468| Step: 0
Training loss: 0.16255755688970153
Validation loss: 2.4665528693621073

Epoch: 6| Step: 1
Training loss: 0.12880261908405755
Validation loss: 2.5178122204490783

Epoch: 6| Step: 2
Training loss: 0.17289157986107911
Validation loss: 2.5118079735074716

Epoch: 6| Step: 3
Training loss: 0.3135563638902986
Validation loss: 2.457485020975683

Epoch: 6| Step: 4
Training loss: 0.13197795142005933
Validation loss: 2.489843319857906

Epoch: 6| Step: 5
Training loss: 0.22309330659056284
Validation loss: 2.4821115942099996

Epoch: 6| Step: 6
Training loss: 0.13460129241455726
Validation loss: 2.4968617964624467

Epoch: 6| Step: 7
Training loss: 0.14995525557020106
Validation loss: 2.5261203660155718

Epoch: 6| Step: 8
Training loss: 0.18542558821813349
Validation loss: 2.507678427818216

Epoch: 6| Step: 9
Training loss: 0.20308153897948378
Validation loss: 2.517116256722808

Epoch: 6| Step: 10
Training loss: 0.2339182933925327
Validation loss: 2.498181396357781

Epoch: 6| Step: 11
Training loss: 0.11862438955793093
Validation loss: 2.50931565435953

Epoch: 6| Step: 12
Training loss: 0.10915958103390805
Validation loss: 2.51015279873508

Epoch: 6| Step: 13
Training loss: 0.11902822993151016
Validation loss: 2.5082419930484328

Epoch: 469| Step: 0
Training loss: 0.1698399762942496
Validation loss: 2.4977412079258503

Epoch: 6| Step: 1
Training loss: 0.23965489659391698
Validation loss: 2.4969624267494153

Epoch: 6| Step: 2
Training loss: 0.10480559221773651
Validation loss: 2.5514921815025557

Epoch: 6| Step: 3
Training loss: 0.2920363657520109
Validation loss: 2.5366199198776807

Epoch: 6| Step: 4
Training loss: 0.23774034046983572
Validation loss: 2.534455320209516

Epoch: 6| Step: 5
Training loss: 0.16682247550561435
Validation loss: 2.5278813552264983

Epoch: 6| Step: 6
Training loss: 0.15588889117393656
Validation loss: 2.5549013438993664

Epoch: 6| Step: 7
Training loss: 0.0955799877355664
Validation loss: 2.5359459203377694

Epoch: 6| Step: 8
Training loss: 0.1021974230973315
Validation loss: 2.5280886401880993

Epoch: 6| Step: 9
Training loss: 0.174512010775825
Validation loss: 2.5104874750818658

Epoch: 6| Step: 10
Training loss: 0.15742752902760573
Validation loss: 2.5301888157039967

Epoch: 6| Step: 11
Training loss: 0.15732089464783008
Validation loss: 2.5210322509471452

Epoch: 6| Step: 12
Training loss: 0.18672785118299629
Validation loss: 2.592029201847508

Epoch: 6| Step: 13
Training loss: 0.10854516966701817
Validation loss: 2.564265131687513

Epoch: 470| Step: 0
Training loss: 0.20394918238269497
Validation loss: 2.5423558223947618

Epoch: 6| Step: 1
Training loss: 0.1284490917478846
Validation loss: 2.535709013109859

Epoch: 6| Step: 2
Training loss: 0.13262953497101976
Validation loss: 2.5868599204445872

Epoch: 6| Step: 3
Training loss: 0.2894328554291913
Validation loss: 2.586737777799491

Epoch: 6| Step: 4
Training loss: 0.2498113695433547
Validation loss: 2.5618232385626163

Epoch: 6| Step: 5
Training loss: 0.21634728836919548
Validation loss: 2.5090756686962097

Epoch: 6| Step: 6
Training loss: 0.12438231831254694
Validation loss: 2.554392876140096

Epoch: 6| Step: 7
Training loss: 0.1427779821880628
Validation loss: 2.558296174911234

Epoch: 6| Step: 8
Training loss: 0.11687936803998654
Validation loss: 2.5407698986035148

Epoch: 6| Step: 9
Training loss: 0.14029431536406742
Validation loss: 2.5052406858641856

Epoch: 6| Step: 10
Training loss: 0.16075852590334858
Validation loss: 2.52233725175517

Epoch: 6| Step: 11
Training loss: 0.15644997079036108
Validation loss: 2.507258600449393

Epoch: 6| Step: 12
Training loss: 0.13395984914534104
Validation loss: 2.5376686994646627

Epoch: 6| Step: 13
Training loss: 0.1139369436858339
Validation loss: 2.5042641871658815

Epoch: 471| Step: 0
Training loss: 0.22572079875512177
Validation loss: 2.4991298412241147

Epoch: 6| Step: 1
Training loss: 0.12630971577448152
Validation loss: 2.5230493567356413

Epoch: 6| Step: 2
Training loss: 0.13250063295483105
Validation loss: 2.5115713606597025

Epoch: 6| Step: 3
Training loss: 0.08529582287673552
Validation loss: 2.520737198620585

Epoch: 6| Step: 4
Training loss: 0.1309154376172704
Validation loss: 2.5391323083158404

Epoch: 6| Step: 5
Training loss: 0.2543135237627477
Validation loss: 2.5237182899848625

Epoch: 6| Step: 6
Training loss: 0.2592089000529737
Validation loss: 2.5212051532992916

Epoch: 6| Step: 7
Training loss: 0.13786334073129172
Validation loss: 2.536303362829236

Epoch: 6| Step: 8
Training loss: 0.1889416387144436
Validation loss: 2.497837404903548

Epoch: 6| Step: 9
Training loss: 0.10789707156291675
Validation loss: 2.4925668202546234

Epoch: 6| Step: 10
Training loss: 0.1275572998887764
Validation loss: 2.4839566467300185

Epoch: 6| Step: 11
Training loss: 0.17407708609435077
Validation loss: 2.5244758339278324

Epoch: 6| Step: 12
Training loss: 0.10657050706056892
Validation loss: 2.5416924892050488

Epoch: 6| Step: 13
Training loss: 0.20073608306017915
Validation loss: 2.5187850179018927

Epoch: 472| Step: 0
Training loss: 0.15725533595303332
Validation loss: 2.516910443407117

Epoch: 6| Step: 1
Training loss: 0.10728221831647268
Validation loss: 2.553283361722766

Epoch: 6| Step: 2
Training loss: 0.15879113218265423
Validation loss: 2.538672211517514

Epoch: 6| Step: 3
Training loss: 0.14773573123868144
Validation loss: 2.574639207127308

Epoch: 6| Step: 4
Training loss: 0.08444607321916843
Validation loss: 2.525342460930396

Epoch: 6| Step: 5
Training loss: 0.17270633825392984
Validation loss: 2.5316927183531326

Epoch: 6| Step: 6
Training loss: 0.15440901773377497
Validation loss: 2.5332843419839173

Epoch: 6| Step: 7
Training loss: 0.22045368682478267
Validation loss: 2.51832135737765

Epoch: 6| Step: 8
Training loss: 0.16652564636777079
Validation loss: 2.5188164313455212

Epoch: 6| Step: 9
Training loss: 0.09309558150918648
Validation loss: 2.551468115346078

Epoch: 6| Step: 10
Training loss: 0.17330714172502007
Validation loss: 2.551960700886899

Epoch: 6| Step: 11
Training loss: 0.27159095977185643
Validation loss: 2.531559104787991

Epoch: 6| Step: 12
Training loss: 0.2500269547474828
Validation loss: 2.5127417570370203

Epoch: 6| Step: 13
Training loss: 0.11317501759724895
Validation loss: 2.5003486410708713

Epoch: 473| Step: 0
Training loss: 0.17987532750233096
Validation loss: 2.480557764336052

Epoch: 6| Step: 1
Training loss: 0.1412814567043798
Validation loss: 2.4828467773804737

Epoch: 6| Step: 2
Training loss: 0.34628656152982856
Validation loss: 2.5083108674553447

Epoch: 6| Step: 3
Training loss: 0.2902783392650299
Validation loss: 2.498292293575855

Epoch: 6| Step: 4
Training loss: 0.2270332247601585
Validation loss: 2.4755090256137295

Epoch: 6| Step: 5
Training loss: 0.1764916159540486
Validation loss: 2.557258726209882

Epoch: 6| Step: 6
Training loss: 0.13593503577092525
Validation loss: 2.5275433532798157

Epoch: 6| Step: 7
Training loss: 0.09862579660674117
Validation loss: 2.521208100075047

Epoch: 6| Step: 8
Training loss: 0.16015951804571707
Validation loss: 2.5405469388406883

Epoch: 6| Step: 9
Training loss: 0.17661402845018975
Validation loss: 2.52794437600556

Epoch: 6| Step: 10
Training loss: 0.19791368222914424
Validation loss: 2.5300417352972935

Epoch: 6| Step: 11
Training loss: 0.16505855242072234
Validation loss: 2.5094523892009564

Epoch: 6| Step: 12
Training loss: 0.1430342315844796
Validation loss: 2.5451437595169755

Epoch: 6| Step: 13
Training loss: 0.2710021284651485
Validation loss: 2.5440973278601224

Epoch: 474| Step: 0
Training loss: 0.19338025837648912
Validation loss: 2.5246965269615145

Epoch: 6| Step: 1
Training loss: 0.17800040823375307
Validation loss: 2.5287357717877987

Epoch: 6| Step: 2
Training loss: 0.2034264217090983
Validation loss: 2.545035644176235

Epoch: 6| Step: 3
Training loss: 0.3311046686392902
Validation loss: 2.5147950348423946

Epoch: 6| Step: 4
Training loss: 0.23484296968626128
Validation loss: 2.5026703334794838

Epoch: 6| Step: 5
Training loss: 0.17867758184275337
Validation loss: 2.511417396928946

Epoch: 6| Step: 6
Training loss: 0.17250130074121195
Validation loss: 2.4758112919621063

Epoch: 6| Step: 7
Training loss: 0.17826583548262664
Validation loss: 2.496495739105054

Epoch: 6| Step: 8
Training loss: 0.1383281531235328
Validation loss: 2.4947437553490177

Epoch: 6| Step: 9
Training loss: 0.14114776770707882
Validation loss: 2.5033460968956276

Epoch: 6| Step: 10
Training loss: 0.18704482300983685
Validation loss: 2.4514432516244917

Epoch: 6| Step: 11
Training loss: 0.13256115832362506
Validation loss: 2.454501077835646

Epoch: 6| Step: 12
Training loss: 0.2758465638233811
Validation loss: 2.4504829984349987

Epoch: 6| Step: 13
Training loss: 0.13207225811666737
Validation loss: 2.498889802719222

Epoch: 475| Step: 0
Training loss: 0.27589899850783167
Validation loss: 2.472964203362233

Epoch: 6| Step: 1
Training loss: 0.19034454202808165
Validation loss: 2.4708270941521713

Epoch: 6| Step: 2
Training loss: 0.11333334481307046
Validation loss: 2.471530916587409

Epoch: 6| Step: 3
Training loss: 0.19527303296921203
Validation loss: 2.508409916262571

Epoch: 6| Step: 4
Training loss: 0.14929330221679035
Validation loss: 2.4609949772261217

Epoch: 6| Step: 5
Training loss: 0.22996192096015863
Validation loss: 2.4955279724432553

Epoch: 6| Step: 6
Training loss: 0.12005837869446488
Validation loss: 2.491477906177893

Epoch: 6| Step: 7
Training loss: 0.14624699750491774
Validation loss: 2.5194500648625273

Epoch: 6| Step: 8
Training loss: 0.2403448362632193
Validation loss: 2.5139350572627164

Epoch: 6| Step: 9
Training loss: 0.1756587290277592
Validation loss: 2.4908452950486466

Epoch: 6| Step: 10
Training loss: 0.1240438534610932
Validation loss: 2.494092457224493

Epoch: 6| Step: 11
Training loss: 0.2719335613539768
Validation loss: 2.517290397068571

Epoch: 6| Step: 12
Training loss: 0.15555977361204956
Validation loss: 2.4828655321228714

Epoch: 6| Step: 13
Training loss: 0.13885271343015412
Validation loss: 2.5172098933086637

Epoch: 476| Step: 0
Training loss: 0.13426650957268743
Validation loss: 2.4934962305514623

Epoch: 6| Step: 1
Training loss: 0.20797156076229986
Validation loss: 2.482305734933016

Epoch: 6| Step: 2
Training loss: 0.18486655142219716
Validation loss: 2.4809844034225694

Epoch: 6| Step: 3
Training loss: 0.11227648422373536
Validation loss: 2.4873930964751705

Epoch: 6| Step: 4
Training loss: 0.2859879084486933
Validation loss: 2.4951111059389857

Epoch: 6| Step: 5
Training loss: 0.17288243292884473
Validation loss: 2.4925051621163417

Epoch: 6| Step: 6
Training loss: 0.2640545364172232
Validation loss: 2.467961008858524

Epoch: 6| Step: 7
Training loss: 0.24729309291048018
Validation loss: 2.5228825100474013

Epoch: 6| Step: 8
Training loss: 0.23270488786551535
Validation loss: 2.531133653363898

Epoch: 6| Step: 9
Training loss: 0.11306546475586329
Validation loss: 2.503486085480069

Epoch: 6| Step: 10
Training loss: 0.13365690985849646
Validation loss: 2.5083112619699244

Epoch: 6| Step: 11
Training loss: 0.17980430786967888
Validation loss: 2.4996570003205516

Epoch: 6| Step: 12
Training loss: 0.13398721736417638
Validation loss: 2.5179645439039184

Epoch: 6| Step: 13
Training loss: 0.09734617119283938
Validation loss: 2.5268526071884283

Epoch: 477| Step: 0
Training loss: 0.10207043691190312
Validation loss: 2.501127797741428

Epoch: 6| Step: 1
Training loss: 0.25330584035458764
Validation loss: 2.5146534717006452

Epoch: 6| Step: 2
Training loss: 0.15167405801052683
Validation loss: 2.466829068952484

Epoch: 6| Step: 3
Training loss: 0.25065434771582706
Validation loss: 2.5008354370304287

Epoch: 6| Step: 4
Training loss: 0.15764382478807268
Validation loss: 2.5629844117624345

Epoch: 6| Step: 5
Training loss: 0.269512576686462
Validation loss: 2.5116539773289044

Epoch: 6| Step: 6
Training loss: 0.15798472411439987
Validation loss: 2.554453059531776

Epoch: 6| Step: 7
Training loss: 0.1336974644873115
Validation loss: 2.508906896974592

Epoch: 6| Step: 8
Training loss: 0.25958973085032033
Validation loss: 2.512004720870821

Epoch: 6| Step: 9
Training loss: 0.1531362278870121
Validation loss: 2.502247295591645

Epoch: 6| Step: 10
Training loss: 0.1060988799555792
Validation loss: 2.5391188778861578

Epoch: 6| Step: 11
Training loss: 0.16213224433538725
Validation loss: 2.510010787374602

Epoch: 6| Step: 12
Training loss: 0.19762380582483635
Validation loss: 2.499407790398132

Epoch: 6| Step: 13
Training loss: 0.17497358740155844
Validation loss: 2.49720262690748

Epoch: 478| Step: 0
Training loss: 0.21757190085913444
Validation loss: 2.5012569969304743

Epoch: 6| Step: 1
Training loss: 0.2948576876282907
Validation loss: 2.5164756017084224

Epoch: 6| Step: 2
Training loss: 0.15589572559082612
Validation loss: 2.5033666619856985

Epoch: 6| Step: 3
Training loss: 0.241673053905058
Validation loss: 2.516705959914908

Epoch: 6| Step: 4
Training loss: 0.09683591569513257
Validation loss: 2.4779239410094585

Epoch: 6| Step: 5
Training loss: 0.13532966254946133
Validation loss: 2.4834736815414984

Epoch: 6| Step: 6
Training loss: 0.22751747487360582
Validation loss: 2.509012581153896

Epoch: 6| Step: 7
Training loss: 0.11074632320721373
Validation loss: 2.4720607524480083

Epoch: 6| Step: 8
Training loss: 0.1921821554727905
Validation loss: 2.4887368099148475

Epoch: 6| Step: 9
Training loss: 0.17825167694011884
Validation loss: 2.4878018901832886

Epoch: 6| Step: 10
Training loss: 0.23013345121181136
Validation loss: 2.4775485904860317

Epoch: 6| Step: 11
Training loss: 0.13716985667267168
Validation loss: 2.4769784827677466

Epoch: 6| Step: 12
Training loss: 0.15836827758885108
Validation loss: 2.483647127457258

Epoch: 6| Step: 13
Training loss: 0.08363261132837481
Validation loss: 2.482469197797926

Epoch: 479| Step: 0
Training loss: 0.11004810469434706
Validation loss: 2.4935885005121796

Epoch: 6| Step: 1
Training loss: 0.1361311615524996
Validation loss: 2.4921904533122623

Epoch: 6| Step: 2
Training loss: 0.10993716404724188
Validation loss: 2.5085849174918122

Epoch: 6| Step: 3
Training loss: 0.12510525474133402
Validation loss: 2.5245611996406643

Epoch: 6| Step: 4
Training loss: 0.16838471892350262
Validation loss: 2.5130261475926976

Epoch: 6| Step: 5
Training loss: 0.2566238513963565
Validation loss: 2.507409273262151

Epoch: 6| Step: 6
Training loss: 0.2871949723509608
Validation loss: 2.485069934610862

Epoch: 6| Step: 7
Training loss: 0.12526214946042644
Validation loss: 2.48737261936527

Epoch: 6| Step: 8
Training loss: 0.20858857294866145
Validation loss: 2.5076654167643864

Epoch: 6| Step: 9
Training loss: 0.12900169047229415
Validation loss: 2.4953011900946978

Epoch: 6| Step: 10
Training loss: 0.14581606683239634
Validation loss: 2.5045000798198593

Epoch: 6| Step: 11
Training loss: 0.13742640460184627
Validation loss: 2.496175149422307

Epoch: 6| Step: 12
Training loss: 0.31518681154359346
Validation loss: 2.4964724633795585

Epoch: 6| Step: 13
Training loss: 0.35950654151758654
Validation loss: 2.5244300033635048

Epoch: 480| Step: 0
Training loss: 0.20055505947625238
Validation loss: 2.5071023088715023

Epoch: 6| Step: 1
Training loss: 0.224902956287181
Validation loss: 2.4939537130234863

Epoch: 6| Step: 2
Training loss: 0.2720227015695231
Validation loss: 2.459693391860026

Epoch: 6| Step: 3
Training loss: 0.25671031185777315
Validation loss: 2.489037606880534

Epoch: 6| Step: 4
Training loss: 0.15587929619846816
Validation loss: 2.4670171236227323

Epoch: 6| Step: 5
Training loss: 0.16710743635924782
Validation loss: 2.4485897431378403

Epoch: 6| Step: 6
Training loss: 0.16268794671611736
Validation loss: 2.4620663206603477

Epoch: 6| Step: 7
Training loss: 0.1785920169576027
Validation loss: 2.434592878520757

Epoch: 6| Step: 8
Training loss: 0.19879168193318422
Validation loss: 2.4299200251585322

Epoch: 6| Step: 9
Training loss: 0.30726778077650324
Validation loss: 2.4828383619004324

Epoch: 6| Step: 10
Training loss: 0.2666877635170471
Validation loss: 2.4449675459957665

Epoch: 6| Step: 11
Training loss: 0.19582471439657784
Validation loss: 2.4476285836060367

Epoch: 6| Step: 12
Training loss: 0.13101550652140911
Validation loss: 2.436848522091108

Epoch: 6| Step: 13
Training loss: 0.12030195741164881
Validation loss: 2.435432919622125

Epoch: 481| Step: 0
Training loss: 0.1946454961264737
Validation loss: 2.4489970964489007

Epoch: 6| Step: 1
Training loss: 0.1836524220318066
Validation loss: 2.4932124600307786

Epoch: 6| Step: 2
Training loss: 0.16688213849247446
Validation loss: 2.4093497715266494

Epoch: 6| Step: 3
Training loss: 0.16507146731634434
Validation loss: 2.46763697069946

Epoch: 6| Step: 4
Training loss: 0.17183682169408182
Validation loss: 2.4405207189392453

Epoch: 6| Step: 5
Training loss: 0.13958071020019658
Validation loss: 2.4816801025765844

Epoch: 6| Step: 6
Training loss: 0.23619511699734666
Validation loss: 2.452632306185108

Epoch: 6| Step: 7
Training loss: 0.21381412352943835
Validation loss: 2.4790387943167325

Epoch: 6| Step: 8
Training loss: 0.185658632050948
Validation loss: 2.4946936950073533

Epoch: 6| Step: 9
Training loss: 0.2661319271169784
Validation loss: 2.4548412845765104

Epoch: 6| Step: 10
Training loss: 0.1949915442253423
Validation loss: 2.457521317698871

Epoch: 6| Step: 11
Training loss: 0.19556549852290656
Validation loss: 2.4728428901206625

Epoch: 6| Step: 12
Training loss: 0.24542700045212265
Validation loss: 2.469978999622818

Epoch: 6| Step: 13
Training loss: 0.250818061503641
Validation loss: 2.469259269526995

Epoch: 482| Step: 0
Training loss: 0.19678928916397437
Validation loss: 2.49158552626687

Epoch: 6| Step: 1
Training loss: 0.1871186391492146
Validation loss: 2.479421123938364

Epoch: 6| Step: 2
Training loss: 0.1483657814237656
Validation loss: 2.4716443952817264

Epoch: 6| Step: 3
Training loss: 0.1771981671064145
Validation loss: 2.4517339390393764

Epoch: 6| Step: 4
Training loss: 0.263115925485159
Validation loss: 2.4770552786508415

Epoch: 6| Step: 5
Training loss: 0.28617529179446627
Validation loss: 2.4992638539840564

Epoch: 6| Step: 6
Training loss: 0.1439966418235661
Validation loss: 2.4824536339596444

Epoch: 6| Step: 7
Training loss: 0.19247089828627642
Validation loss: 2.4929411826629573

Epoch: 6| Step: 8
Training loss: 0.19041629646364058
Validation loss: 2.4591479963409646

Epoch: 6| Step: 9
Training loss: 0.19596197860618236
Validation loss: 2.4591208736926604

Epoch: 6| Step: 10
Training loss: 0.2244946974864092
Validation loss: 2.4601428166726635

Epoch: 6| Step: 11
Training loss: 0.10566837792036875
Validation loss: 2.461148669559518

Epoch: 6| Step: 12
Training loss: 0.08713555509231724
Validation loss: 2.4636234562201116

Epoch: 6| Step: 13
Training loss: 0.22367836767240756
Validation loss: 2.483506357123057

Epoch: 483| Step: 0
Training loss: 0.27751370716178647
Validation loss: 2.452829268284458

Epoch: 6| Step: 1
Training loss: 0.13167208626715357
Validation loss: 2.4629408940603086

Epoch: 6| Step: 2
Training loss: 0.15172660978173236
Validation loss: 2.5090385401775928

Epoch: 6| Step: 3
Training loss: 0.1969824732242869
Validation loss: 2.453939904072098

Epoch: 6| Step: 4
Training loss: 0.19711498136103392
Validation loss: 2.481088405521506

Epoch: 6| Step: 5
Training loss: 0.18119512294499007
Validation loss: 2.4839372167261047

Epoch: 6| Step: 6
Training loss: 0.1965335064050455
Validation loss: 2.4992735607159746

Epoch: 6| Step: 7
Training loss: 0.12908019265556497
Validation loss: 2.4975876531387042

Epoch: 6| Step: 8
Training loss: 0.14428919421140454
Validation loss: 2.5259174938443616

Epoch: 6| Step: 9
Training loss: 0.12638271271793125
Validation loss: 2.4742053800503396

Epoch: 6| Step: 10
Training loss: 0.1812250654564359
Validation loss: 2.490482748289853

Epoch: 6| Step: 11
Training loss: 0.2882619675594445
Validation loss: 2.4798119012881075

Epoch: 6| Step: 12
Training loss: 0.14659452747243704
Validation loss: 2.510297301061273

Epoch: 6| Step: 13
Training loss: 0.08782623104329557
Validation loss: 2.489843043914547

Epoch: 484| Step: 0
Training loss: 0.22088024324185682
Validation loss: 2.4925681994919273

Epoch: 6| Step: 1
Training loss: 0.20909402769221674
Validation loss: 2.4781124458387587

Epoch: 6| Step: 2
Training loss: 0.18598401625787003
Validation loss: 2.463744107434751

Epoch: 6| Step: 3
Training loss: 0.13101552784688097
Validation loss: 2.518071278357567

Epoch: 6| Step: 4
Training loss: 0.16116115436410844
Validation loss: 2.4886360025684655

Epoch: 6| Step: 5
Training loss: 0.14381923433598343
Validation loss: 2.5187881629279913

Epoch: 6| Step: 6
Training loss: 0.22097770523388113
Validation loss: 2.519682027812944

Epoch: 6| Step: 7
Training loss: 0.2712762432763512
Validation loss: 2.5278796230646243

Epoch: 6| Step: 8
Training loss: 0.1993122722789508
Validation loss: 2.5309871778690525

Epoch: 6| Step: 9
Training loss: 0.24471951327632943
Validation loss: 2.5457023972680366

Epoch: 6| Step: 10
Training loss: 0.16708724902226843
Validation loss: 2.557433448207627

Epoch: 6| Step: 11
Training loss: 0.11981297947808062
Validation loss: 2.513390142172451

Epoch: 6| Step: 12
Training loss: 0.15304322930161465
Validation loss: 2.5197914049637733

Epoch: 6| Step: 13
Training loss: 0.1460343824210231
Validation loss: 2.5238688704803445

Epoch: 485| Step: 0
Training loss: 0.17653025948869033
Validation loss: 2.5361847229729837

Epoch: 6| Step: 1
Training loss: 0.1399192984262294
Validation loss: 2.5443965978058904

Epoch: 6| Step: 2
Training loss: 0.37642233048195683
Validation loss: 2.535638056029514

Epoch: 6| Step: 3
Training loss: 0.13954943368633504
Validation loss: 2.512469980746926

Epoch: 6| Step: 4
Training loss: 0.20743729701065286
Validation loss: 2.5021107479509355

Epoch: 6| Step: 5
Training loss: 0.11578820782320202
Validation loss: 2.521809827044239

Epoch: 6| Step: 6
Training loss: 0.15027252117658
Validation loss: 2.5448981587227713

Epoch: 6| Step: 7
Training loss: 0.15741198724026903
Validation loss: 2.5174471865035195

Epoch: 6| Step: 8
Training loss: 0.13479310598617095
Validation loss: 2.497718593513417

Epoch: 6| Step: 9
Training loss: 0.1917977805028855
Validation loss: 2.5088404494587104

Epoch: 6| Step: 10
Training loss: 0.2004540794695355
Validation loss: 2.5387562213497388

Epoch: 6| Step: 11
Training loss: 0.14094970884962887
Validation loss: 2.5250258048554426

Epoch: 6| Step: 12
Training loss: 0.19553496089399486
Validation loss: 2.5480274064655544

Epoch: 6| Step: 13
Training loss: 0.22855596104855308
Validation loss: 2.517173172994816

Epoch: 486| Step: 0
Training loss: 0.14060839581479792
Validation loss: 2.56090715446368

Epoch: 6| Step: 1
Training loss: 0.11421975700258054
Validation loss: 2.5032587296062836

Epoch: 6| Step: 2
Training loss: 0.16966450591630358
Validation loss: 2.542581927679459

Epoch: 6| Step: 3
Training loss: 0.20368652490064648
Validation loss: 2.5222594257010167

Epoch: 6| Step: 4
Training loss: 0.15887178000271693
Validation loss: 2.5497451942249536

Epoch: 6| Step: 5
Training loss: 0.2799295981276259
Validation loss: 2.508899522519334

Epoch: 6| Step: 6
Training loss: 0.2164664714903133
Validation loss: 2.538490111497864

Epoch: 6| Step: 7
Training loss: 0.13218595171307995
Validation loss: 2.5137894255207365

Epoch: 6| Step: 8
Training loss: 0.22024101220258763
Validation loss: 2.5250682346022795

Epoch: 6| Step: 9
Training loss: 0.17499260950661363
Validation loss: 2.5283789385445976

Epoch: 6| Step: 10
Training loss: 0.1185262622409896
Validation loss: 2.546899449779491

Epoch: 6| Step: 11
Training loss: 0.18208025980638815
Validation loss: 2.5316972467821106

Epoch: 6| Step: 12
Training loss: 0.12244274545759563
Validation loss: 2.512612234200634

Epoch: 6| Step: 13
Training loss: 0.15269241415158266
Validation loss: 2.471171306852859

Epoch: 487| Step: 0
Training loss: 0.23218184185706872
Validation loss: 2.520094935669583

Epoch: 6| Step: 1
Training loss: 0.16255066453212064
Validation loss: 2.5450683291711886

Epoch: 6| Step: 2
Training loss: 0.1720301892007938
Validation loss: 2.499513929038948

Epoch: 6| Step: 3
Training loss: 0.14022643510448313
Validation loss: 2.505499840325893

Epoch: 6| Step: 4
Training loss: 0.16035586222414286
Validation loss: 2.550967385409865

Epoch: 6| Step: 5
Training loss: 0.1378098883673326
Validation loss: 2.5436856802122625

Epoch: 6| Step: 6
Training loss: 0.15725954669400033
Validation loss: 2.535622773048357

Epoch: 6| Step: 7
Training loss: 0.18659142059178024
Validation loss: 2.496572826971948

Epoch: 6| Step: 8
Training loss: 0.13213885792135632
Validation loss: 2.5338897248979464

Epoch: 6| Step: 9
Training loss: 0.14940542931641482
Validation loss: 2.484122502554609

Epoch: 6| Step: 10
Training loss: 0.2013802143992922
Validation loss: 2.4739340687173326

Epoch: 6| Step: 11
Training loss: 0.21057741902592444
Validation loss: 2.4956713531256405

Epoch: 6| Step: 12
Training loss: 0.12903667845131442
Validation loss: 2.4877243306085908

Epoch: 6| Step: 13
Training loss: 0.15122010868634364
Validation loss: 2.482103229170917

Epoch: 488| Step: 0
Training loss: 0.15348914745576564
Validation loss: 2.5121461975385055

Epoch: 6| Step: 1
Training loss: 0.20810117104011577
Validation loss: 2.4620037612219887

Epoch: 6| Step: 2
Training loss: 0.15885626812363063
Validation loss: 2.478114086576534

Epoch: 6| Step: 3
Training loss: 0.14995500714320395
Validation loss: 2.4626361147183107

Epoch: 6| Step: 4
Training loss: 0.14404029197145393
Validation loss: 2.4746365249830085

Epoch: 6| Step: 5
Training loss: 0.2242841937427506
Validation loss: 2.5021374307247974

Epoch: 6| Step: 6
Training loss: 0.12426292395729027
Validation loss: 2.475491875994989

Epoch: 6| Step: 7
Training loss: 0.13714251919164416
Validation loss: 2.4538689070561133

Epoch: 6| Step: 8
Training loss: 0.1368994744510887
Validation loss: 2.467736464635179

Epoch: 6| Step: 9
Training loss: 0.1162342520976093
Validation loss: 2.4821551696275015

Epoch: 6| Step: 10
Training loss: 0.2004356244519574
Validation loss: 2.4520162053406374

Epoch: 6| Step: 11
Training loss: 0.22345354982899476
Validation loss: 2.488982323515102

Epoch: 6| Step: 12
Training loss: 0.18055177240402337
Validation loss: 2.4885921048743906

Epoch: 6| Step: 13
Training loss: 0.20114880957361433
Validation loss: 2.5007979145126487

Epoch: 489| Step: 0
Training loss: 0.15897835244433628
Validation loss: 2.5223475537115787

Epoch: 6| Step: 1
Training loss: 0.16380540822166617
Validation loss: 2.489243907000791

Epoch: 6| Step: 2
Training loss: 0.19193665330924303
Validation loss: 2.5587372534903037

Epoch: 6| Step: 3
Training loss: 0.22003536988540395
Validation loss: 2.5252335668512833

Epoch: 6| Step: 4
Training loss: 0.13919985021022707
Validation loss: 2.539890642306991

Epoch: 6| Step: 5
Training loss: 0.22987983915598653
Validation loss: 2.539263886825804

Epoch: 6| Step: 6
Training loss: 0.20477832497193438
Validation loss: 2.5604355362204236

Epoch: 6| Step: 7
Training loss: 0.21930662929149117
Validation loss: 2.5122645929480103

Epoch: 6| Step: 8
Training loss: 0.21703339467866797
Validation loss: 2.5240326460273583

Epoch: 6| Step: 9
Training loss: 0.299561479562366
Validation loss: 2.530357053444055

Epoch: 6| Step: 10
Training loss: 0.21653406864819597
Validation loss: 2.5199897327973266

Epoch: 6| Step: 11
Training loss: 0.2604171355561168
Validation loss: 2.525232636411776

Epoch: 6| Step: 12
Training loss: 0.18127733221819947
Validation loss: 2.525893500680449

Epoch: 6| Step: 13
Training loss: 0.18642339969670468
Validation loss: 2.458860620965441

Epoch: 490| Step: 0
Training loss: 0.17342374678372452
Validation loss: 2.4993815313343126

Epoch: 6| Step: 1
Training loss: 0.2495424285324381
Validation loss: 2.510847668843841

Epoch: 6| Step: 2
Training loss: 0.30098506908042644
Validation loss: 2.5373026802388807

Epoch: 6| Step: 3
Training loss: 0.17581410630770794
Validation loss: 2.5419821991346296

Epoch: 6| Step: 4
Training loss: 0.10016266642324231
Validation loss: 2.5467068956235193

Epoch: 6| Step: 5
Training loss: 0.23436427091836562
Validation loss: 2.54238951894134

Epoch: 6| Step: 6
Training loss: 0.20071667029681106
Validation loss: 2.518104691059001

Epoch: 6| Step: 7
Training loss: 0.2805217347530175
Validation loss: 2.49971777850905

Epoch: 6| Step: 8
Training loss: 0.1859709661483447
Validation loss: 2.50834561976136

Epoch: 6| Step: 9
Training loss: 0.10637895458078721
Validation loss: 2.495824025090345

Epoch: 6| Step: 10
Training loss: 0.18804614675116962
Validation loss: 2.5388011046239796

Epoch: 6| Step: 11
Training loss: 0.13485757482832356
Validation loss: 2.5235375632437727

Epoch: 6| Step: 12
Training loss: 0.14155696955987285
Validation loss: 2.506015669928289

Epoch: 6| Step: 13
Training loss: 0.1290158542757144
Validation loss: 2.514567504561668

Epoch: 491| Step: 0
Training loss: 0.18217389980217946
Validation loss: 2.513115195130144

Epoch: 6| Step: 1
Training loss: 0.1732613614211635
Validation loss: 2.526571728211741

Epoch: 6| Step: 2
Training loss: 0.1869365849971538
Validation loss: 2.5252498446649496

Epoch: 6| Step: 3
Training loss: 0.15604261702548197
Validation loss: 2.486642566424351

Epoch: 6| Step: 4
Training loss: 0.18904627541212787
Validation loss: 2.5039777653537265

Epoch: 6| Step: 5
Training loss: 0.17671799606445737
Validation loss: 2.5019705891715134

Epoch: 6| Step: 6
Training loss: 0.18168747205507677
Validation loss: 2.5079845264299823

Epoch: 6| Step: 7
Training loss: 0.13292275088111236
Validation loss: 2.508762440763963

Epoch: 6| Step: 8
Training loss: 0.1727835580706488
Validation loss: 2.492254528577081

Epoch: 6| Step: 9
Training loss: 0.2404271647044378
Validation loss: 2.5568241405200105

Epoch: 6| Step: 10
Training loss: 0.1694095935368434
Validation loss: 2.517689374473987

Epoch: 6| Step: 11
Training loss: 0.14613766647634796
Validation loss: 2.4798705891566706

Epoch: 6| Step: 12
Training loss: 0.21064066310791957
Validation loss: 2.4736767880779316

Epoch: 6| Step: 13
Training loss: 0.2713777071845463
Validation loss: 2.485295059371223

Epoch: 492| Step: 0
Training loss: 0.11854761705886561
Validation loss: 2.47874854031084

Epoch: 6| Step: 1
Training loss: 0.14737007676540942
Validation loss: 2.4931520965174494

Epoch: 6| Step: 2
Training loss: 0.1675801995066748
Validation loss: 2.4884367101071607

Epoch: 6| Step: 3
Training loss: 0.11219486173899537
Validation loss: 2.474744647225587

Epoch: 6| Step: 4
Training loss: 0.1861649708622247
Validation loss: 2.4944423016708424

Epoch: 6| Step: 5
Training loss: 0.3558251616762837
Validation loss: 2.4292738805468868

Epoch: 6| Step: 6
Training loss: 0.13309113641543135
Validation loss: 2.44571483601585

Epoch: 6| Step: 7
Training loss: 0.18902014384008542
Validation loss: 2.4865437568071207

Epoch: 6| Step: 8
Training loss: 0.12264325534722942
Validation loss: 2.4825744522635658

Epoch: 6| Step: 9
Training loss: 0.2373647103713509
Validation loss: 2.4687547581124343

Epoch: 6| Step: 10
Training loss: 0.2485265224433563
Validation loss: 2.4986013068378226

Epoch: 6| Step: 11
Training loss: 0.20303901356254644
Validation loss: 2.4981066096862654

Epoch: 6| Step: 12
Training loss: 0.24010411274234278
Validation loss: 2.474879099939426

Epoch: 6| Step: 13
Training loss: 0.18182461147088508
Validation loss: 2.508340409884536

Epoch: 493| Step: 0
Training loss: 0.2102763977636101
Validation loss: 2.505439167611704

Epoch: 6| Step: 1
Training loss: 0.2131416608081798
Validation loss: 2.5277688646690897

Epoch: 6| Step: 2
Training loss: 0.16409359932374765
Validation loss: 2.525898737786432

Epoch: 6| Step: 3
Training loss: 0.144857039433491
Validation loss: 2.5291572000422633

Epoch: 6| Step: 4
Training loss: 0.17242634729860376
Validation loss: 2.531318642857723

Epoch: 6| Step: 5
Training loss: 0.1826456221204392
Validation loss: 2.537705318182981

Epoch: 6| Step: 6
Training loss: 0.1985085112503006
Validation loss: 2.5767730698286333

Epoch: 6| Step: 7
Training loss: 0.26047922654527395
Validation loss: 2.6049187069423576

Epoch: 6| Step: 8
Training loss: 0.2325249932042937
Validation loss: 2.594497551192646

Epoch: 6| Step: 9
Training loss: 0.17830409449418674
Validation loss: 2.599995987051335

Epoch: 6| Step: 10
Training loss: 0.20383012783050553
Validation loss: 2.524183250426421

Epoch: 6| Step: 11
Training loss: 0.12210242802633337
Validation loss: 2.542137774765538

Epoch: 6| Step: 12
Training loss: 0.1559596403664489
Validation loss: 2.5502258097048767

Epoch: 6| Step: 13
Training loss: 0.196802890151088
Validation loss: 2.554965304137973

Epoch: 494| Step: 0
Training loss: 0.15662958410645197
Validation loss: 2.5011094882090905

Epoch: 6| Step: 1
Training loss: 0.1611291480370189
Validation loss: 2.5078244982567117

Epoch: 6| Step: 2
Training loss: 0.21406664322233512
Validation loss: 2.5317043725605926

Epoch: 6| Step: 3
Training loss: 0.15812441551530193
Validation loss: 2.510007946442404

Epoch: 6| Step: 4
Training loss: 0.1721610430851571
Validation loss: 2.498547876764976

Epoch: 6| Step: 5
Training loss: 0.16729273158178265
Validation loss: 2.509771228757054

Epoch: 6| Step: 6
Training loss: 0.16405387129118035
Validation loss: 2.5345751586886243

Epoch: 6| Step: 7
Training loss: 0.28105377928777286
Validation loss: 2.5106619894296203

Epoch: 6| Step: 8
Training loss: 0.12973110402378324
Validation loss: 2.510925361080242

Epoch: 6| Step: 9
Training loss: 0.19176416603763613
Validation loss: 2.51275801782949

Epoch: 6| Step: 10
Training loss: 0.12394950194781956
Validation loss: 2.4952789491163228

Epoch: 6| Step: 11
Training loss: 0.16320817900301302
Validation loss: 2.55187670683442

Epoch: 6| Step: 12
Training loss: 0.16285554521850804
Validation loss: 2.559511649689172

Epoch: 6| Step: 13
Training loss: 0.27316712227046913
Validation loss: 2.5209086186648553

Epoch: 495| Step: 0
Training loss: 0.11130836796708375
Validation loss: 2.5856485765854287

Epoch: 6| Step: 1
Training loss: 0.10773556597288571
Validation loss: 2.552988760588085

Epoch: 6| Step: 2
Training loss: 0.23479106847714504
Validation loss: 2.5484537535769203

Epoch: 6| Step: 3
Training loss: 0.20680225951848358
Validation loss: 2.5028464591744117

Epoch: 6| Step: 4
Training loss: 0.1546089360586049
Validation loss: 2.5836145183136656

Epoch: 6| Step: 5
Training loss: 0.13613893995902648
Validation loss: 2.5324122106541114

Epoch: 6| Step: 6
Training loss: 0.12752630979096785
Validation loss: 2.5520791256945046

Epoch: 6| Step: 7
Training loss: 0.14050003963517413
Validation loss: 2.509772846755305

Epoch: 6| Step: 8
Training loss: 0.20478225436721828
Validation loss: 2.5735611326210748

Epoch: 6| Step: 9
Training loss: 0.23668912632969966
Validation loss: 2.5098128341678754

Epoch: 6| Step: 10
Training loss: 0.21040076386123596
Validation loss: 2.5415418228751117

Epoch: 6| Step: 11
Training loss: 0.17200884159437124
Validation loss: 2.4955811641266403

Epoch: 6| Step: 12
Training loss: 0.16320275217637298
Validation loss: 2.5364863920195924

Epoch: 6| Step: 13
Training loss: 0.11713577559509288
Validation loss: 2.5614918532213733

Epoch: 496| Step: 0
Training loss: 0.23776526162404973
Validation loss: 2.53904724823289

Epoch: 6| Step: 1
Training loss: 0.11041256813398971
Validation loss: 2.5223186113679836

Epoch: 6| Step: 2
Training loss: 0.2266194337801971
Validation loss: 2.474551649637863

Epoch: 6| Step: 3
Training loss: 0.1719711154173363
Validation loss: 2.5186534952977873

Epoch: 6| Step: 4
Training loss: 0.13874622823125035
Validation loss: 2.4930788381978144

Epoch: 6| Step: 5
Training loss: 0.10108126740134402
Validation loss: 2.455701902210751

Epoch: 6| Step: 6
Training loss: 0.1152023578066201
Validation loss: 2.493878477816169

Epoch: 6| Step: 7
Training loss: 0.10928461478471746
Validation loss: 2.5161843261169414

Epoch: 6| Step: 8
Training loss: 0.09953155469623201
Validation loss: 2.4579201692288932

Epoch: 6| Step: 9
Training loss: 0.18257431302153576
Validation loss: 2.5033193814325925

Epoch: 6| Step: 10
Training loss: 0.09795045404995906
Validation loss: 2.4734864558309706

Epoch: 6| Step: 11
Training loss: 0.2126550420885165
Validation loss: 2.4838433032418967

Epoch: 6| Step: 12
Training loss: 0.10077665359158428
Validation loss: 2.464837524058812

Epoch: 6| Step: 13
Training loss: 0.12633574093029687
Validation loss: 2.473448592014773

Epoch: 497| Step: 0
Training loss: 0.11319321467245787
Validation loss: 2.505025277800597

Epoch: 6| Step: 1
Training loss: 0.16021475072400188
Validation loss: 2.470714044844701

Epoch: 6| Step: 2
Training loss: 0.15413766203641244
Validation loss: 2.4753583249697906

Epoch: 6| Step: 3
Training loss: 0.14671684891562925
Validation loss: 2.474567086020585

Epoch: 6| Step: 4
Training loss: 0.1010357788261436
Validation loss: 2.5055839637811643

Epoch: 6| Step: 5
Training loss: 0.22519147328712896
Validation loss: 2.458609084954112

Epoch: 6| Step: 6
Training loss: 0.214123611358843
Validation loss: 2.486352135994613

Epoch: 6| Step: 7
Training loss: 0.0933075936816764
Validation loss: 2.522670824315093

Epoch: 6| Step: 8
Training loss: 0.09687375329353688
Validation loss: 2.487460922863469

Epoch: 6| Step: 9
Training loss: 0.10365884697587502
Validation loss: 2.518710805342234

Epoch: 6| Step: 10
Training loss: 0.1191931749362104
Validation loss: 2.5222210032134407

Epoch: 6| Step: 11
Training loss: 0.2243025383920231
Validation loss: 2.491274451143365

Epoch: 6| Step: 12
Training loss: 0.1312868693769263
Validation loss: 2.485478020175945

Epoch: 6| Step: 13
Training loss: 0.20102985702345139
Validation loss: 2.5578273486737113

Epoch: 498| Step: 0
Training loss: 0.2035455019175334
Validation loss: 2.518972116713015

Epoch: 6| Step: 1
Training loss: 0.0641515351517264
Validation loss: 2.516409109544744

Epoch: 6| Step: 2
Training loss: 0.08926488631283541
Validation loss: 2.5094679265707382

Epoch: 6| Step: 3
Training loss: 0.21897164253675142
Validation loss: 2.495685049980989

Epoch: 6| Step: 4
Training loss: 0.13669334584317197
Validation loss: 2.4917161637069043

Epoch: 6| Step: 5
Training loss: 0.15848212894539418
Validation loss: 2.4802971846863238

Epoch: 6| Step: 6
Training loss: 0.1260998809841307
Validation loss: 2.5075477452932877

Epoch: 6| Step: 7
Training loss: 0.12747979590739703
Validation loss: 2.496397368778091

Epoch: 6| Step: 8
Training loss: 0.1169788131647665
Validation loss: 2.525965099910186

Epoch: 6| Step: 9
Training loss: 0.1554007578020631
Validation loss: 2.5364646243627833

Epoch: 6| Step: 10
Training loss: 0.17820516003989906
Validation loss: 2.4944238187081504

Epoch: 6| Step: 11
Training loss: 0.16801101685062272
Validation loss: 2.509621529272904

Epoch: 6| Step: 12
Training loss: 0.16275011538649423
Validation loss: 2.5126651693095923

Epoch: 6| Step: 13
Training loss: 0.05078014042449047
Validation loss: 2.522346669468747

Epoch: 499| Step: 0
Training loss: 0.24271585912592614
Validation loss: 2.524039555772919

Epoch: 6| Step: 1
Training loss: 0.17739741903892917
Validation loss: 2.522331513295143

Epoch: 6| Step: 2
Training loss: 0.0792600374675635
Validation loss: 2.525059813890873

Epoch: 6| Step: 3
Training loss: 0.14947068631199836
Validation loss: 2.5210904551557407

Epoch: 6| Step: 4
Training loss: 0.09589510268960591
Validation loss: 2.5441546547370435

Epoch: 6| Step: 5
Training loss: 0.20479142266301326
Validation loss: 2.5546468075647386

Epoch: 6| Step: 6
Training loss: 0.19433602376197934
Validation loss: 2.560152020087403

Epoch: 6| Step: 7
Training loss: 0.11497590609492252
Validation loss: 2.5212280837605405

Epoch: 6| Step: 8
Training loss: 0.2279026417511336
Validation loss: 2.5256704289594465

Epoch: 6| Step: 9
Training loss: 0.11068590540413126
Validation loss: 2.502955444331954

Epoch: 6| Step: 10
Training loss: 0.14594108923270124
Validation loss: 2.496202614041822

Epoch: 6| Step: 11
Training loss: 0.12874021819371467
Validation loss: 2.551319493862725

Epoch: 6| Step: 12
Training loss: 0.12557621112849277
Validation loss: 2.523710254844891

Epoch: 6| Step: 13
Training loss: 0.10699495096805582
Validation loss: 2.507221559031528

Epoch: 500| Step: 0
Training loss: 0.15186009292676186
Validation loss: 2.530870140981954

Epoch: 6| Step: 1
Training loss: 0.10828685172152361
Validation loss: 2.5274231408125116

Epoch: 6| Step: 2
Training loss: 0.12039058863535931
Validation loss: 2.518182819604773

Epoch: 6| Step: 3
Training loss: 0.09008125342753706
Validation loss: 2.4989428838599643

Epoch: 6| Step: 4
Training loss: 0.07943569362069972
Validation loss: 2.513610015020517

Epoch: 6| Step: 5
Training loss: 0.23780010455506612
Validation loss: 2.524667453137974

Epoch: 6| Step: 6
Training loss: 0.14467649636332763
Validation loss: 2.5233514399577923

Epoch: 6| Step: 7
Training loss: 0.11902806953153064
Validation loss: 2.524257749977931

Epoch: 6| Step: 8
Training loss: 0.15931729646513293
Validation loss: 2.4867530462680865

Epoch: 6| Step: 9
Training loss: 0.2740503255821651
Validation loss: 2.53009799602929

Epoch: 6| Step: 10
Training loss: 0.10799515082590347
Validation loss: 2.5371366632625243

Epoch: 6| Step: 11
Training loss: 0.18302243193672046
Validation loss: 2.5372792261726467

Epoch: 6| Step: 12
Training loss: 0.08916194993353073
Validation loss: 2.5292603788198718

Epoch: 6| Step: 13
Training loss: 0.23733923703712895
Validation loss: 2.525623854215571

Epoch: 501| Step: 0
Training loss: 0.23462191926420256
Validation loss: 2.5272395607362106

Epoch: 6| Step: 1
Training loss: 0.10419064980821785
Validation loss: 2.5537616152883675

Epoch: 6| Step: 2
Training loss: 0.14653206366884403
Validation loss: 2.501607954100598

Epoch: 6| Step: 3
Training loss: 0.16983269949429125
Validation loss: 2.5231939998549513

Epoch: 6| Step: 4
Training loss: 0.1382427223865674
Validation loss: 2.528738071599508

Epoch: 6| Step: 5
Training loss: 0.0903815211226001
Validation loss: 2.5521532202755965

Epoch: 6| Step: 6
Training loss: 0.1265172518389652
Validation loss: 2.5350967320099596

Epoch: 6| Step: 7
Training loss: 0.14599412897631475
Validation loss: 2.5010412862509828

Epoch: 6| Step: 8
Training loss: 0.14093505930214564
Validation loss: 2.491499765389493

Epoch: 6| Step: 9
Training loss: 0.15356493830035636
Validation loss: 2.4767138457313234

Epoch: 6| Step: 10
Training loss: 0.14573947974526635
Validation loss: 2.5020088113458954

Epoch: 6| Step: 11
Training loss: 0.2661029638687658
Validation loss: 2.471287163116665

Epoch: 6| Step: 12
Training loss: 0.13470866893266728
Validation loss: 2.5062816804549817

Epoch: 6| Step: 13
Training loss: 0.16309555390839203
Validation loss: 2.5065706577527753

Epoch: 502| Step: 0
Training loss: 0.10573289607036741
Validation loss: 2.4735299800546087

Epoch: 6| Step: 1
Training loss: 0.17087437051518992
Validation loss: 2.48657465379216

Epoch: 6| Step: 2
Training loss: 0.10136382220494103
Validation loss: 2.507744213011891

Epoch: 6| Step: 3
Training loss: 0.16304796313556533
Validation loss: 2.495988854052208

Epoch: 6| Step: 4
Training loss: 0.14646154225737806
Validation loss: 2.4795539293594553

Epoch: 6| Step: 5
Training loss: 0.19160545454048353
Validation loss: 2.4946140975659854

Epoch: 6| Step: 6
Training loss: 0.09334306514598585
Validation loss: 2.4792322853471838

Epoch: 6| Step: 7
Training loss: 0.21968285019838835
Validation loss: 2.487247703076604

Epoch: 6| Step: 8
Training loss: 0.15873329783420648
Validation loss: 2.439107856292771

Epoch: 6| Step: 9
Training loss: 0.13000683133809718
Validation loss: 2.4755325802557206

Epoch: 6| Step: 10
Training loss: 0.23174145419476058
Validation loss: 2.426017298082662

Epoch: 6| Step: 11
Training loss: 0.12428665014778446
Validation loss: 2.4600733565267903

Epoch: 6| Step: 12
Training loss: 0.14070457617664256
Validation loss: 2.476817165469182

Epoch: 6| Step: 13
Training loss: 0.13011089175730475
Validation loss: 2.4529449298043575

Epoch: 503| Step: 0
Training loss: 0.15805653267739764
Validation loss: 2.460782713351125

Epoch: 6| Step: 1
Training loss: 0.10912285419093494
Validation loss: 2.500103219270248

Epoch: 6| Step: 2
Training loss: 0.2729878679730765
Validation loss: 2.470567421877036

Epoch: 6| Step: 3
Training loss: 0.12896298113824975
Validation loss: 2.4807038422917325

Epoch: 6| Step: 4
Training loss: 0.09472620364248986
Validation loss: 2.4865610688780464

Epoch: 6| Step: 5
Training loss: 0.1281077986893705
Validation loss: 2.5234453511094532

Epoch: 6| Step: 6
Training loss: 0.08051230897428448
Validation loss: 2.5025910804021136

Epoch: 6| Step: 7
Training loss: 0.07875954603719165
Validation loss: 2.4960515364073603

Epoch: 6| Step: 8
Training loss: 0.19607335664704206
Validation loss: 2.496418877862527

Epoch: 6| Step: 9
Training loss: 0.17216629031829683
Validation loss: 2.5007133491608924

Epoch: 6| Step: 10
Training loss: 0.181636553893048
Validation loss: 2.4533899552271383

Epoch: 6| Step: 11
Training loss: 0.11928602242335662
Validation loss: 2.5048717038696804

Epoch: 6| Step: 12
Training loss: 0.1793292247036849
Validation loss: 2.4784181774270055

Epoch: 6| Step: 13
Training loss: 0.1234480207522895
Validation loss: 2.5028593037382323

Epoch: 504| Step: 0
Training loss: 0.21039491204994545
Validation loss: 2.4813325692523045

Epoch: 6| Step: 1
Training loss: 0.08074693394566564
Validation loss: 2.479226975514443

Epoch: 6| Step: 2
Training loss: 0.16080097940285162
Validation loss: 2.4797755943261364

Epoch: 6| Step: 3
Training loss: 0.11956536298675116
Validation loss: 2.4786436136339116

Epoch: 6| Step: 4
Training loss: 0.26663449541630646
Validation loss: 2.487085868523507

Epoch: 6| Step: 5
Training loss: 0.12772364440082112
Validation loss: 2.497789055931829

Epoch: 6| Step: 6
Training loss: 0.21734539439979975
Validation loss: 2.5083725280024303

Epoch: 6| Step: 7
Training loss: 0.18097752363977718
Validation loss: 2.4665653832454852

Epoch: 6| Step: 8
Training loss: 0.1195130663174088
Validation loss: 2.4537134932291784

Epoch: 6| Step: 9
Training loss: 0.07868430382760848
Validation loss: 2.4815144316635314

Epoch: 6| Step: 10
Training loss: 0.11914171937533685
Validation loss: 2.468581283575857

Epoch: 6| Step: 11
Training loss: 0.13318757780297458
Validation loss: 2.4856228466880093

Epoch: 6| Step: 12
Training loss: 0.22384430325876575
Validation loss: 2.4771229451515038

Epoch: 6| Step: 13
Training loss: 0.2829648956129002
Validation loss: 2.508523537586798

Epoch: 505| Step: 0
Training loss: 0.10237742354158316
Validation loss: 2.51159279389358

Epoch: 6| Step: 1
Training loss: 0.1289268462748661
Validation loss: 2.507915271995071

Epoch: 6| Step: 2
Training loss: 0.20304797619546353
Validation loss: 2.5220845865590857

Epoch: 6| Step: 3
Training loss: 0.10200079008309489
Validation loss: 2.51339486677611

Epoch: 6| Step: 4
Training loss: 0.24277678446714424
Validation loss: 2.506613141136186

Epoch: 6| Step: 5
Training loss: 0.08316892527710644
Validation loss: 2.5569334232639656

Epoch: 6| Step: 6
Training loss: 0.08790406548199249
Validation loss: 2.5640641667651805

Epoch: 6| Step: 7
Training loss: 0.13466615737902932
Validation loss: 2.518390205530376

Epoch: 6| Step: 8
Training loss: 0.1718986397438505
Validation loss: 2.5575327737744544

Epoch: 6| Step: 9
Training loss: 0.20700422146542308
Validation loss: 2.54948297402892

Epoch: 6| Step: 10
Training loss: 0.12676017476894522
Validation loss: 2.5086331171553464

Epoch: 6| Step: 11
Training loss: 0.12327161579658462
Validation loss: 2.5701053906353994

Epoch: 6| Step: 12
Training loss: 0.14125113699885827
Validation loss: 2.5344442005961203

Epoch: 6| Step: 13
Training loss: 0.11841983541394986
Validation loss: 2.5018114828274283

Epoch: 506| Step: 0
Training loss: 0.13090645242194113
Validation loss: 2.4978436081194704

Epoch: 6| Step: 1
Training loss: 0.12330836183499155
Validation loss: 2.5063804074745963

Epoch: 6| Step: 2
Training loss: 0.10249095878326892
Validation loss: 2.4937052192237634

Epoch: 6| Step: 3
Training loss: 0.19514536382092593
Validation loss: 2.506330001127443

Epoch: 6| Step: 4
Training loss: 0.1809391093141343
Validation loss: 2.497932255769919

Epoch: 6| Step: 5
Training loss: 0.21034386779255929
Validation loss: 2.503741276714021

Epoch: 6| Step: 6
Training loss: 0.18762925778919656
Validation loss: 2.4991724798161052

Epoch: 6| Step: 7
Training loss: 0.1783557447180151
Validation loss: 2.497031386919896

Epoch: 6| Step: 8
Training loss: 0.1365599800287636
Validation loss: 2.505730198774639

Epoch: 6| Step: 9
Training loss: 0.15045813494323873
Validation loss: 2.481873677943949

Epoch: 6| Step: 10
Training loss: 0.16585817163204258
Validation loss: 2.5033131887133524

Epoch: 6| Step: 11
Training loss: 0.19563478582482355
Validation loss: 2.475940512760323

Epoch: 6| Step: 12
Training loss: 0.15871270843727117
Validation loss: 2.4884562811452517

Epoch: 6| Step: 13
Training loss: 0.13570521557855136
Validation loss: 2.497495641786998

Epoch: 507| Step: 0
Training loss: 0.21735687786634322
Validation loss: 2.500542458778979

Epoch: 6| Step: 1
Training loss: 0.10357066256816536
Validation loss: 2.5534983994704934

Epoch: 6| Step: 2
Training loss: 0.12616562517825794
Validation loss: 2.505962198450203

Epoch: 6| Step: 3
Training loss: 0.18488759819460407
Validation loss: 2.4738406428703748

Epoch: 6| Step: 4
Training loss: 0.12617259335387201
Validation loss: 2.4797553013979976

Epoch: 6| Step: 5
Training loss: 0.2737582641381851
Validation loss: 2.480924443509518

Epoch: 6| Step: 6
Training loss: 0.16943220308376233
Validation loss: 2.4833597575211486

Epoch: 6| Step: 7
Training loss: 0.11624433534418312
Validation loss: 2.535674192492466

Epoch: 6| Step: 8
Training loss: 0.14546313656056875
Validation loss: 2.504992179831381

Epoch: 6| Step: 9
Training loss: 0.271002485870031
Validation loss: 2.518766255551334

Epoch: 6| Step: 10
Training loss: 0.09955206325544508
Validation loss: 2.543656066029308

Epoch: 6| Step: 11
Training loss: 0.1199332666733377
Validation loss: 2.5509843205721947

Epoch: 6| Step: 12
Training loss: 0.10439169142083733
Validation loss: 2.5183149490857586

Epoch: 6| Step: 13
Training loss: 0.17997498941179052
Validation loss: 2.482079636179762

Epoch: 508| Step: 0
Training loss: 0.09863169357873752
Validation loss: 2.525820633749642

Epoch: 6| Step: 1
Training loss: 0.12596837837781436
Validation loss: 2.5126822753900644

Epoch: 6| Step: 2
Training loss: 0.13655318726008442
Validation loss: 2.5374272752572016

Epoch: 6| Step: 3
Training loss: 0.14662941427976406
Validation loss: 2.5284310852684264

Epoch: 6| Step: 4
Training loss: 0.18480535205116033
Validation loss: 2.493841565075619

Epoch: 6| Step: 5
Training loss: 0.19139251854357153
Validation loss: 2.494229108243845

Epoch: 6| Step: 6
Training loss: 0.21397125638460734
Validation loss: 2.500263731386819

Epoch: 6| Step: 7
Training loss: 0.12536841727658152
Validation loss: 2.5139831079512738

Epoch: 6| Step: 8
Training loss: 0.11350603656480919
Validation loss: 2.5297481122790892

Epoch: 6| Step: 9
Training loss: 0.2607092532957149
Validation loss: 2.5054143500672463

Epoch: 6| Step: 10
Training loss: 0.20967552835937567
Validation loss: 2.5090543416796223

Epoch: 6| Step: 11
Training loss: 0.18328817788613805
Validation loss: 2.489230619359646

Epoch: 6| Step: 12
Training loss: 0.16725021081926833
Validation loss: 2.4851569543739056

Epoch: 6| Step: 13
Training loss: 0.06232343073388275
Validation loss: 2.442218670742454

Epoch: 509| Step: 0
Training loss: 0.1442796992482376
Validation loss: 2.47328497867445

Epoch: 6| Step: 1
Training loss: 0.20945674773586723
Validation loss: 2.459881097331273

Epoch: 6| Step: 2
Training loss: 0.1525629984579105
Validation loss: 2.471107353279423

Epoch: 6| Step: 3
Training loss: 0.18731372242637812
Validation loss: 2.4627229988831423

Epoch: 6| Step: 4
Training loss: 0.16559870484183686
Validation loss: 2.4501418048917567

Epoch: 6| Step: 5
Training loss: 0.232162250439713
Validation loss: 2.4586896691987463

Epoch: 6| Step: 6
Training loss: 0.20853225430167144
Validation loss: 2.4577657949301437

Epoch: 6| Step: 7
Training loss: 0.09493153801543514
Validation loss: 2.49226713431027

Epoch: 6| Step: 8
Training loss: 0.13293721149997945
Validation loss: 2.4737364842544007

Epoch: 6| Step: 9
Training loss: 0.1596898696764649
Validation loss: 2.489146552942165

Epoch: 6| Step: 10
Training loss: 0.16395479595212986
Validation loss: 2.474873128170504

Epoch: 6| Step: 11
Training loss: 0.15463323990122863
Validation loss: 2.4892599299355176

Epoch: 6| Step: 12
Training loss: 0.219609326770062
Validation loss: 2.505276713319501

Epoch: 6| Step: 13
Training loss: 0.19076542723866743
Validation loss: 2.476512519857698

Epoch: 510| Step: 0
Training loss: 0.13139130530043447
Validation loss: 2.4425944626173917

Epoch: 6| Step: 1
Training loss: 0.1315744349645485
Validation loss: 2.4660255764999164

Epoch: 6| Step: 2
Training loss: 0.17775884396982203
Validation loss: 2.4945206560567064

Epoch: 6| Step: 3
Training loss: 0.255829336135673
Validation loss: 2.4743631066540432

Epoch: 6| Step: 4
Training loss: 0.16341347268878018
Validation loss: 2.497801316332274

Epoch: 6| Step: 5
Training loss: 0.31688764238437483
Validation loss: 2.4898009127708605

Epoch: 6| Step: 6
Training loss: 0.2029579374239271
Validation loss: 2.5151751602729404

Epoch: 6| Step: 7
Training loss: 0.14587681979128714
Validation loss: 2.475666478622653

Epoch: 6| Step: 8
Training loss: 0.1887206735154458
Validation loss: 2.495215768060482

Epoch: 6| Step: 9
Training loss: 0.2031082549895868
Validation loss: 2.511536886228905

Epoch: 6| Step: 10
Training loss: 0.15979727778929972
Validation loss: 2.5765415607971818

Epoch: 6| Step: 11
Training loss: 0.29198185318740555
Validation loss: 2.5183437837258853

Epoch: 6| Step: 12
Training loss: 0.2362189158799757
Validation loss: 2.5774298990306477

Epoch: 6| Step: 13
Training loss: 0.1467622029610076
Validation loss: 2.5639733001666207

Epoch: 511| Step: 0
Training loss: 0.20783487034620382
Validation loss: 2.541721374337163

Epoch: 6| Step: 1
Training loss: 0.19595981142331667
Validation loss: 2.5510423483902285

Epoch: 6| Step: 2
Training loss: 0.11000910088701896
Validation loss: 2.5282264972524957

Epoch: 6| Step: 3
Training loss: 0.17801768391276612
Validation loss: 2.5403713662417267

Epoch: 6| Step: 4
Training loss: 0.31079566634444983
Validation loss: 2.50644657040377

Epoch: 6| Step: 5
Training loss: 0.18197839362473947
Validation loss: 2.5387929374781666

Epoch: 6| Step: 6
Training loss: 0.19137885423126644
Validation loss: 2.536094731609827

Epoch: 6| Step: 7
Training loss: 0.1550043882048769
Validation loss: 2.527125347480638

Epoch: 6| Step: 8
Training loss: 0.09962518416965649
Validation loss: 2.5475975082301034

Epoch: 6| Step: 9
Training loss: 0.18150990407169887
Validation loss: 2.5440667344560026

Epoch: 6| Step: 10
Training loss: 0.21813490936647542
Validation loss: 2.529316414181798

Epoch: 6| Step: 11
Training loss: 0.19267466719276785
Validation loss: 2.5306089342222595

Epoch: 6| Step: 12
Training loss: 0.32447371741056874
Validation loss: 2.5489896511968375

Epoch: 6| Step: 13
Training loss: 0.182942564659922
Validation loss: 2.5179300419544695

Epoch: 512| Step: 0
Training loss: 0.17630508043248186
Validation loss: 2.4896648512228996

Epoch: 6| Step: 1
Training loss: 0.13453467939571492
Validation loss: 2.520163697731755

Epoch: 6| Step: 2
Training loss: 0.11276141464314496
Validation loss: 2.4693406243434026

Epoch: 6| Step: 3
Training loss: 0.22987419961434233
Validation loss: 2.481337666912352

Epoch: 6| Step: 4
Training loss: 0.11598475267034539
Validation loss: 2.459996249351707

Epoch: 6| Step: 5
Training loss: 0.18878415559737394
Validation loss: 2.4689021553658375

Epoch: 6| Step: 6
Training loss: 0.25457830252934166
Validation loss: 2.464831854548737

Epoch: 6| Step: 7
Training loss: 0.2578240016336826
Validation loss: 2.4455630554663403

Epoch: 6| Step: 8
Training loss: 0.1716712155383686
Validation loss: 2.4941467551811964

Epoch: 6| Step: 9
Training loss: 0.13129997096871246
Validation loss: 2.4875072016400224

Epoch: 6| Step: 10
Training loss: 0.15746050069715725
Validation loss: 2.4881015508639206

Epoch: 6| Step: 11
Training loss: 0.2004035239130171
Validation loss: 2.4970675257599155

Epoch: 6| Step: 12
Training loss: 0.14908518155793918
Validation loss: 2.500579151627301

Epoch: 6| Step: 13
Training loss: 0.2708852455321005
Validation loss: 2.4895000051656466

Epoch: 513| Step: 0
Training loss: 0.20227455959279197
Validation loss: 2.479710359967668

Epoch: 6| Step: 1
Training loss: 0.12770572743575656
Validation loss: 2.5107391360338904

Epoch: 6| Step: 2
Training loss: 0.2077672758585496
Validation loss: 2.505548600698466

Epoch: 6| Step: 3
Training loss: 0.19036830988905457
Validation loss: 2.5249494303266404

Epoch: 6| Step: 4
Training loss: 0.22433376818017725
Validation loss: 2.5317539051284337

Epoch: 6| Step: 5
Training loss: 0.1421915850209733
Validation loss: 2.5257864456633605

Epoch: 6| Step: 6
Training loss: 0.13757240274845106
Validation loss: 2.540952870401001

Epoch: 6| Step: 7
Training loss: 0.14319302941098103
Validation loss: 2.5513271139745037

Epoch: 6| Step: 8
Training loss: 0.27855883633620315
Validation loss: 2.5343924365503354

Epoch: 6| Step: 9
Training loss: 0.18094569755919387
Validation loss: 2.5353865323037104

Epoch: 6| Step: 10
Training loss: 0.33121031082549335
Validation loss: 2.5576350975182445

Epoch: 6| Step: 11
Training loss: 0.19501136453230855
Validation loss: 2.484882616834537

Epoch: 6| Step: 12
Training loss: 0.18829811622135195
Validation loss: 2.5173088455479333

Epoch: 6| Step: 13
Training loss: 0.2761335160136789
Validation loss: 2.4939253025910513

Epoch: 514| Step: 0
Training loss: 0.14261345882760493
Validation loss: 2.504534170019074

Epoch: 6| Step: 1
Training loss: 0.2664460228011648
Validation loss: 2.4936583183517693

Epoch: 6| Step: 2
Training loss: 0.1905157237221997
Validation loss: 2.460247429923963

Epoch: 6| Step: 3
Training loss: 0.15723388370504257
Validation loss: 2.4458966716373256

Epoch: 6| Step: 4
Training loss: 0.18195943643737705
Validation loss: 2.4413487959469458

Epoch: 6| Step: 5
Training loss: 0.2335263863205994
Validation loss: 2.4149585169047523

Epoch: 6| Step: 6
Training loss: 0.22493194968267302
Validation loss: 2.4411241278946063

Epoch: 6| Step: 7
Training loss: 0.21200988290801054
Validation loss: 2.4238005521175956

Epoch: 6| Step: 8
Training loss: 0.15366316686799117
Validation loss: 2.422660271621145

Epoch: 6| Step: 9
Training loss: 0.14176976966832608
Validation loss: 2.421337638357082

Epoch: 6| Step: 10
Training loss: 0.21498063668394976
Validation loss: 2.452388506824472

Epoch: 6| Step: 11
Training loss: 0.2084377037316146
Validation loss: 2.4865995284317144

Epoch: 6| Step: 12
Training loss: 0.257813800461697
Validation loss: 2.4683523069358473

Epoch: 6| Step: 13
Training loss: 0.3121233458370119
Validation loss: 2.4781399678815337

Epoch: 515| Step: 0
Training loss: 0.11736935174979621
Validation loss: 2.4560394875736127

Epoch: 6| Step: 1
Training loss: 0.1995048712228917
Validation loss: 2.5265988471946614

Epoch: 6| Step: 2
Training loss: 0.08035402047102613
Validation loss: 2.487679208009793

Epoch: 6| Step: 3
Training loss: 0.2969961170286283
Validation loss: 2.502349502168428

Epoch: 6| Step: 4
Training loss: 0.1869023852552283
Validation loss: 2.503930783528746

Epoch: 6| Step: 5
Training loss: 0.1259128572122632
Validation loss: 2.5053257717150594

Epoch: 6| Step: 6
Training loss: 0.18441278304884604
Validation loss: 2.4923298413500508

Epoch: 6| Step: 7
Training loss: 0.31997895901765133
Validation loss: 2.505189265999667

Epoch: 6| Step: 8
Training loss: 0.23092925406718304
Validation loss: 2.509103648061127

Epoch: 6| Step: 9
Training loss: 0.22842689160764798
Validation loss: 2.528904137618791

Epoch: 6| Step: 10
Training loss: 0.20635302130913896
Validation loss: 2.493661372214357

Epoch: 6| Step: 11
Training loss: 0.3235180418195546
Validation loss: 2.5272396144995954

Epoch: 6| Step: 12
Training loss: 0.34264316963525315
Validation loss: 2.4855906094274647

Epoch: 6| Step: 13
Training loss: 0.1849753159731824
Validation loss: 2.460043422043294

Epoch: 516| Step: 0
Training loss: 0.19934648270983182
Validation loss: 2.4443152674920468

Epoch: 6| Step: 1
Training loss: 0.24528868249817037
Validation loss: 2.4572386498655554

Epoch: 6| Step: 2
Training loss: 0.18194610790187096
Validation loss: 2.418258411882019

Epoch: 6| Step: 3
Training loss: 0.2453364649079636
Validation loss: 2.4581241723777665

Epoch: 6| Step: 4
Training loss: 0.25827401208168904
Validation loss: 2.4698321228274933

Epoch: 6| Step: 5
Training loss: 0.2944053269414236
Validation loss: 2.482658303391393

Epoch: 6| Step: 6
Training loss: 0.2083581740749151
Validation loss: 2.492858527897664

Epoch: 6| Step: 7
Training loss: 0.09366982727421437
Validation loss: 2.520838810111266

Epoch: 6| Step: 8
Training loss: 0.397925178410166
Validation loss: 2.5295810157393834

Epoch: 6| Step: 9
Training loss: 0.15083866755614622
Validation loss: 2.441566056597744

Epoch: 6| Step: 10
Training loss: 0.4926713654062201
Validation loss: 2.45264783139602

Epoch: 6| Step: 11
Training loss: 0.2511977471631769
Validation loss: 2.417375593372636

Epoch: 6| Step: 12
Training loss: 0.2864002891457153
Validation loss: 2.4783487619252353

Epoch: 6| Step: 13
Training loss: 0.2546409540997619
Validation loss: 2.4776838491678204

Epoch: 517| Step: 0
Training loss: 0.1809495165726728
Validation loss: 2.4830819612281294

Epoch: 6| Step: 1
Training loss: 0.19290126130021462
Validation loss: 2.5322528120192422

Epoch: 6| Step: 2
Training loss: 0.3395485417947983
Validation loss: 2.531569422888466

Epoch: 6| Step: 3
Training loss: 0.18076165115297477
Validation loss: 2.539896014570908

Epoch: 6| Step: 4
Training loss: 0.24665356344434336
Validation loss: 2.5370779879818537

Epoch: 6| Step: 5
Training loss: 0.25222857891125716
Validation loss: 2.502880772142538

Epoch: 6| Step: 6
Training loss: 0.2736932239922641
Validation loss: 2.533967476016428

Epoch: 6| Step: 7
Training loss: 0.3466140147585926
Validation loss: 2.5338788830560333

Epoch: 6| Step: 8
Training loss: 0.19491286400280455
Validation loss: 2.538224988810202

Epoch: 6| Step: 9
Training loss: 0.32203641890107554
Validation loss: 2.538987982502849

Epoch: 6| Step: 10
Training loss: 0.19119459244067163
Validation loss: 2.4889214685760144

Epoch: 6| Step: 11
Training loss: 0.3092806450655871
Validation loss: 2.4856522967556858

Epoch: 6| Step: 12
Training loss: 0.1377614653739121
Validation loss: 2.514212674866732

Epoch: 6| Step: 13
Training loss: 0.23115767137184068
Validation loss: 2.4858489897958354

Epoch: 518| Step: 0
Training loss: 0.25421223909355567
Validation loss: 2.526066724379977

Epoch: 6| Step: 1
Training loss: 0.18808595176054999
Validation loss: 2.5377463327830436

Epoch: 6| Step: 2
Training loss: 0.22967473338452044
Validation loss: 2.482986932838091

Epoch: 6| Step: 3
Training loss: 0.3534017136971029
Validation loss: 2.4880991939140085

Epoch: 6| Step: 4
Training loss: 0.1856985977641683
Validation loss: 2.5084734839683227

Epoch: 6| Step: 5
Training loss: 0.2501167680318908
Validation loss: 2.505631301359523

Epoch: 6| Step: 6
Training loss: 0.26361478964656754
Validation loss: 2.4318185437336415

Epoch: 6| Step: 7
Training loss: 0.24108610900073746
Validation loss: 2.407665727425628

Epoch: 6| Step: 8
Training loss: 0.20984197395692247
Validation loss: 2.4118743908235296

Epoch: 6| Step: 9
Training loss: 0.2998046875
Validation loss: 2.370564775322636

Epoch: 6| Step: 10
Training loss: 0.2872322753686742
Validation loss: 2.3817356828176965

Epoch: 6| Step: 11
Training loss: 0.15310322523997713
Validation loss: 2.399422880088723

Epoch: 6| Step: 12
Training loss: 0.2569786081641759
Validation loss: 2.4152963391455424

Epoch: 6| Step: 13
Training loss: 0.23070396123489756
Validation loss: 2.457595615087714

Epoch: 519| Step: 0
Training loss: 0.2168517515820248
Validation loss: 2.455166008079113

Epoch: 6| Step: 1
Training loss: 0.31348798261619226
Validation loss: 2.4747008252957308

Epoch: 6| Step: 2
Training loss: 0.2713121650147144
Validation loss: 2.4521836323762622

Epoch: 6| Step: 3
Training loss: 0.35309318466674694
Validation loss: 2.4863337032179915

Epoch: 6| Step: 4
Training loss: 0.22724427213049367
Validation loss: 2.4639765015243253

Epoch: 6| Step: 5
Training loss: 0.24367009405944998
Validation loss: 2.4434227643258257

Epoch: 6| Step: 6
Training loss: 0.13266261141680794
Validation loss: 2.4686151615411114

Epoch: 6| Step: 7
Training loss: 0.2374298173957347
Validation loss: 2.441805071801432

Epoch: 6| Step: 8
Training loss: 0.20408619361945773
Validation loss: 2.4704882451353387

Epoch: 6| Step: 9
Training loss: 0.14214652199331193
Validation loss: 2.4539829225130227

Epoch: 6| Step: 10
Training loss: 0.18439784393389563
Validation loss: 2.4850158107461993

Epoch: 6| Step: 11
Training loss: 0.17577578218221215
Validation loss: 2.4273861425022782

Epoch: 6| Step: 12
Training loss: 0.13994657263366542
Validation loss: 2.470142153184504

Epoch: 6| Step: 13
Training loss: 0.15625901792252114
Validation loss: 2.447434683751738

Epoch: 520| Step: 0
Training loss: 0.207694081217969
Validation loss: 2.4359892819410596

Epoch: 6| Step: 1
Training loss: 0.21326740415575685
Validation loss: 2.475600849652071

Epoch: 6| Step: 2
Training loss: 0.1417776262864092
Validation loss: 2.4410467288208166

Epoch: 6| Step: 3
Training loss: 0.15668020033865374
Validation loss: 2.473055554335067

Epoch: 6| Step: 4
Training loss: 0.24791557110750065
Validation loss: 2.4845483448170205

Epoch: 6| Step: 5
Training loss: 0.15879194742657737
Validation loss: 2.4669135591916453

Epoch: 6| Step: 6
Training loss: 0.25042215110138555
Validation loss: 2.4589220082240324

Epoch: 6| Step: 7
Training loss: 0.22654686249008685
Validation loss: 2.495142555432954

Epoch: 6| Step: 8
Training loss: 0.1358657452963728
Validation loss: 2.4377945857890198

Epoch: 6| Step: 9
Training loss: 0.24834993576682965
Validation loss: 2.5003139790902873

Epoch: 6| Step: 10
Training loss: 0.1089308867233595
Validation loss: 2.4888071923659605

Epoch: 6| Step: 11
Training loss: 0.2552318886506477
Validation loss: 2.498991034571371

Epoch: 6| Step: 12
Training loss: 0.17179184766199035
Validation loss: 2.4772352838957437

Epoch: 6| Step: 13
Training loss: 0.17540486093192323
Validation loss: 2.467855382519767

Epoch: 521| Step: 0
Training loss: 0.14255398062503927
Validation loss: 2.5023328397517357

Epoch: 6| Step: 1
Training loss: 0.18719445605719115
Validation loss: 2.5061552996937793

Epoch: 6| Step: 2
Training loss: 0.18745598673816158
Validation loss: 2.500460524852646

Epoch: 6| Step: 3
Training loss: 0.20931219076952184
Validation loss: 2.502384114439731

Epoch: 6| Step: 4
Training loss: 0.22566548715980006
Validation loss: 2.476148083177276

Epoch: 6| Step: 5
Training loss: 0.13156756176124984
Validation loss: 2.4785418351677158

Epoch: 6| Step: 6
Training loss: 0.18169678055858696
Validation loss: 2.4852918193533204

Epoch: 6| Step: 7
Training loss: 0.25993221362150726
Validation loss: 2.490691789620438

Epoch: 6| Step: 8
Training loss: 0.15639375987375884
Validation loss: 2.4862475085572484

Epoch: 6| Step: 9
Training loss: 0.18585020668856253
Validation loss: 2.486098869004705

Epoch: 6| Step: 10
Training loss: 0.15843590341512193
Validation loss: 2.5104024018062914

Epoch: 6| Step: 11
Training loss: 0.2021105265427893
Validation loss: 2.4465030824046936

Epoch: 6| Step: 12
Training loss: 0.24373852996248588
Validation loss: 2.4503739408768554

Epoch: 6| Step: 13
Training loss: 0.11889685252796489
Validation loss: 2.4787266720753878

Epoch: 522| Step: 0
Training loss: 0.19062030739558433
Validation loss: 2.4677143814210254

Epoch: 6| Step: 1
Training loss: 0.14688404238035668
Validation loss: 2.4518082303900117

Epoch: 6| Step: 2
Training loss: 0.1926607747718382
Validation loss: 2.4497946094126046

Epoch: 6| Step: 3
Training loss: 0.11771311504081405
Validation loss: 2.4924466323746803

Epoch: 6| Step: 4
Training loss: 0.17608011059204695
Validation loss: 2.4852978372628645

Epoch: 6| Step: 5
Training loss: 0.2244148988102269
Validation loss: 2.489739252034835

Epoch: 6| Step: 6
Training loss: 0.20772133383500435
Validation loss: 2.5008046208980197

Epoch: 6| Step: 7
Training loss: 0.08149211691325885
Validation loss: 2.46626883650479

Epoch: 6| Step: 8
Training loss: 0.20659139079101582
Validation loss: 2.4220935478139083

Epoch: 6| Step: 9
Training loss: 0.10894356941286742
Validation loss: 2.451177629445196

Epoch: 6| Step: 10
Training loss: 0.12067132765564202
Validation loss: 2.4615849677279877

Epoch: 6| Step: 11
Training loss: 0.1162926843173364
Validation loss: 2.4512441988805334

Epoch: 6| Step: 12
Training loss: 0.14553739259865453
Validation loss: 2.45929488055617

Epoch: 6| Step: 13
Training loss: 0.13886384705121857
Validation loss: 2.4417028565416015

Epoch: 523| Step: 0
Training loss: 0.20054634765864765
Validation loss: 2.4371637197058154

Epoch: 6| Step: 1
Training loss: 0.11711528460331036
Validation loss: 2.471047696297404

Epoch: 6| Step: 2
Training loss: 0.1557564928858302
Validation loss: 2.42042754785939

Epoch: 6| Step: 3
Training loss: 0.23490273348505641
Validation loss: 2.457322148556428

Epoch: 6| Step: 4
Training loss: 0.1792371746061077
Validation loss: 2.4675109285525547

Epoch: 6| Step: 5
Training loss: 0.1731312423400062
Validation loss: 2.4635462551563743

Epoch: 6| Step: 6
Training loss: 0.21621908915107593
Validation loss: 2.475395253381877

Epoch: 6| Step: 7
Training loss: 0.13049597598865392
Validation loss: 2.447187555909273

Epoch: 6| Step: 8
Training loss: 0.12953400202865856
Validation loss: 2.476202477999971

Epoch: 6| Step: 9
Training loss: 0.09643210875744239
Validation loss: 2.4845767863754524

Epoch: 6| Step: 10
Training loss: 0.1258965097434237
Validation loss: 2.4320842774573186

Epoch: 6| Step: 11
Training loss: 0.1780280736258523
Validation loss: 2.4596557023985772

Epoch: 6| Step: 12
Training loss: 0.16438519440792573
Validation loss: 2.4950259101257686

Epoch: 6| Step: 13
Training loss: 0.19279324855867228
Validation loss: 2.4904858719262783

Epoch: 524| Step: 0
Training loss: 0.1772633378649222
Validation loss: 2.4415694816903666

Epoch: 6| Step: 1
Training loss: 0.1652780641914828
Validation loss: 2.446538144728309

Epoch: 6| Step: 2
Training loss: 0.22868567440412513
Validation loss: 2.4877607513666344

Epoch: 6| Step: 3
Training loss: 0.23598471036577898
Validation loss: 2.4879266436601175

Epoch: 6| Step: 4
Training loss: 0.1698026951667929
Validation loss: 2.491043944049921

Epoch: 6| Step: 5
Training loss: 0.2349168712360898
Validation loss: 2.440359703025985

Epoch: 6| Step: 6
Training loss: 0.202295857730499
Validation loss: 2.484640136076479

Epoch: 6| Step: 7
Training loss: 0.1105655856524058
Validation loss: 2.4840702843358566

Epoch: 6| Step: 8
Training loss: 0.19939343890364433
Validation loss: 2.4566857594425326

Epoch: 6| Step: 9
Training loss: 0.1617414251270024
Validation loss: 2.492511976182869

Epoch: 6| Step: 10
Training loss: 0.12860142183188958
Validation loss: 2.475982508041792

Epoch: 6| Step: 11
Training loss: 0.18001484079573407
Validation loss: 2.473191705561618

Epoch: 6| Step: 12
Training loss: 0.16937758429691832
Validation loss: 2.490606116340629

Epoch: 6| Step: 13
Training loss: 0.10333459247057825
Validation loss: 2.4220354220913674

Epoch: 525| Step: 0
Training loss: 0.2095099996078569
Validation loss: 2.434503124962491

Epoch: 6| Step: 1
Training loss: 0.11021510692526482
Validation loss: 2.4627644154088846

Epoch: 6| Step: 2
Training loss: 0.2041009510523932
Validation loss: 2.4326324167991467

Epoch: 6| Step: 3
Training loss: 0.17646348274014323
Validation loss: 2.459709414995702

Epoch: 6| Step: 4
Training loss: 0.25546732560906843
Validation loss: 2.4542928037090834

Epoch: 6| Step: 5
Training loss: 0.13572637891309605
Validation loss: 2.468579732044887

Epoch: 6| Step: 6
Training loss: 0.12452409720130911
Validation loss: 2.4448300777908165

Epoch: 6| Step: 7
Training loss: 0.19268534927083494
Validation loss: 2.455412601248959

Epoch: 6| Step: 8
Training loss: 0.21723964943279273
Validation loss: 2.4565953750185012

Epoch: 6| Step: 9
Training loss: 0.11012672204415136
Validation loss: 2.4245772556642065

Epoch: 6| Step: 10
Training loss: 0.09351215889131298
Validation loss: 2.3928589114952183

Epoch: 6| Step: 11
Training loss: 0.23770774551762466
Validation loss: 2.411412790774218

Epoch: 6| Step: 12
Training loss: 0.15034578323654504
Validation loss: 2.439485852155246

Epoch: 6| Step: 13
Training loss: 0.11198873442058811
Validation loss: 2.4526221096438974

Epoch: 526| Step: 0
Training loss: 0.2039966222212277
Validation loss: 2.438101944221709

Epoch: 6| Step: 1
Training loss: 0.11939872862871408
Validation loss: 2.3905310604633905

Epoch: 6| Step: 2
Training loss: 0.19152512070540356
Validation loss: 2.42900591901518

Epoch: 6| Step: 3
Training loss: 0.14284644941025504
Validation loss: 2.4485617983826895

Epoch: 6| Step: 4
Training loss: 0.24599120107572858
Validation loss: 2.440371386853929

Epoch: 6| Step: 5
Training loss: 0.11183928792786796
Validation loss: 2.422638721966608

Epoch: 6| Step: 6
Training loss: 0.11805285193777289
Validation loss: 2.426464983222942

Epoch: 6| Step: 7
Training loss: 0.19882390218271215
Validation loss: 2.449393214880563

Epoch: 6| Step: 8
Training loss: 0.10222962783369087
Validation loss: 2.428248850249451

Epoch: 6| Step: 9
Training loss: 0.17056116883879155
Validation loss: 2.422063489784364

Epoch: 6| Step: 10
Training loss: 0.10967210029843041
Validation loss: 2.40906384851155

Epoch: 6| Step: 11
Training loss: 0.11314577189890843
Validation loss: 2.4034243521312475

Epoch: 6| Step: 12
Training loss: 0.25359516159858747
Validation loss: 2.3960213860697452

Epoch: 6| Step: 13
Training loss: 0.14774956151571256
Validation loss: 2.4257340620403576

Epoch: 527| Step: 0
Training loss: 0.2211768964509365
Validation loss: 2.4022389779002915

Epoch: 6| Step: 1
Training loss: 0.1332052118803531
Validation loss: 2.405077490516805

Epoch: 6| Step: 2
Training loss: 0.15986706630767628
Validation loss: 2.4267574871270416

Epoch: 6| Step: 3
Training loss: 0.17339270417045477
Validation loss: 2.4349220611824975

Epoch: 6| Step: 4
Training loss: 0.17384163128962188
Validation loss: 2.437363001504972

Epoch: 6| Step: 5
Training loss: 0.20047470693441963
Validation loss: 2.4715255912462957

Epoch: 6| Step: 6
Training loss: 0.13782936361725232
Validation loss: 2.4527326679921644

Epoch: 6| Step: 7
Training loss: 0.18712373570898694
Validation loss: 2.4638149894922954

Epoch: 6| Step: 8
Training loss: 0.19347476406174216
Validation loss: 2.4759899950322484

Epoch: 6| Step: 9
Training loss: 0.1340390883301916
Validation loss: 2.4729828959544466

Epoch: 6| Step: 10
Training loss: 0.22283538505550718
Validation loss: 2.4667670647172564

Epoch: 6| Step: 11
Training loss: 0.08538177280751141
Validation loss: 2.4990787110886443

Epoch: 6| Step: 12
Training loss: 0.1453493586831663
Validation loss: 2.4618273333248815

Epoch: 6| Step: 13
Training loss: 0.16289348439696003
Validation loss: 2.479831444767754

Epoch: 528| Step: 0
Training loss: 0.19648316498643575
Validation loss: 2.4797980343130384

Epoch: 6| Step: 1
Training loss: 0.15520296956934665
Validation loss: 2.456218819210395

Epoch: 6| Step: 2
Training loss: 0.2286145900736109
Validation loss: 2.457933181553459

Epoch: 6| Step: 3
Training loss: 0.1476722239376277
Validation loss: 2.4849158320287184

Epoch: 6| Step: 4
Training loss: 0.14010878360921697
Validation loss: 2.4847886895588416

Epoch: 6| Step: 5
Training loss: 0.12358498604925065
Validation loss: 2.464082015308515

Epoch: 6| Step: 6
Training loss: 0.16092017043429804
Validation loss: 2.4483234763051906

Epoch: 6| Step: 7
Training loss: 0.15663249168304158
Validation loss: 2.467753790735042

Epoch: 6| Step: 8
Training loss: 0.15959150484103204
Validation loss: 2.4757156287938513

Epoch: 6| Step: 9
Training loss: 0.1733476287812892
Validation loss: 2.46139017484043

Epoch: 6| Step: 10
Training loss: 0.09796080782211145
Validation loss: 2.4711595051435125

Epoch: 6| Step: 11
Training loss: 0.12403743770006355
Validation loss: 2.457161052573666

Epoch: 6| Step: 12
Training loss: 0.16007434681333602
Validation loss: 2.496625469624217

Epoch: 6| Step: 13
Training loss: 0.08311191090090889
Validation loss: 2.5020814649632945

Epoch: 529| Step: 0
Training loss: 0.19551445057029293
Validation loss: 2.515173114598775

Epoch: 6| Step: 1
Training loss: 0.11526160807395294
Validation loss: 2.5080811472267723

Epoch: 6| Step: 2
Training loss: 0.14339479637667052
Validation loss: 2.465987444265425

Epoch: 6| Step: 3
Training loss: 0.09187823606163706
Validation loss: 2.5183953157245407

Epoch: 6| Step: 4
Training loss: 0.1232481702631025
Validation loss: 2.5017732499527834

Epoch: 6| Step: 5
Training loss: 0.1698312408065976
Validation loss: 2.5059456500809305

Epoch: 6| Step: 6
Training loss: 0.14707096271953746
Validation loss: 2.4955281121552204

Epoch: 6| Step: 7
Training loss: 0.1272784320084775
Validation loss: 2.522999287985604

Epoch: 6| Step: 8
Training loss: 0.1198227110490403
Validation loss: 2.5085907282752817

Epoch: 6| Step: 9
Training loss: 0.22265844176702732
Validation loss: 2.481445104842073

Epoch: 6| Step: 10
Training loss: 0.12064570169003067
Validation loss: 2.486205165420861

Epoch: 6| Step: 11
Training loss: 0.1492537093029077
Validation loss: 2.493281623656618

Epoch: 6| Step: 12
Training loss: 0.07646404986986426
Validation loss: 2.470832273665003

Epoch: 6| Step: 13
Training loss: 0.1343273069887723
Validation loss: 2.4849512426817717

Epoch: 530| Step: 0
Training loss: 0.21742644270588998
Validation loss: 2.4650547539285217

Epoch: 6| Step: 1
Training loss: 0.07600683281010592
Validation loss: 2.4628279824068104

Epoch: 6| Step: 2
Training loss: 0.14371675957024926
Validation loss: 2.4947833259897463

Epoch: 6| Step: 3
Training loss: 0.15023021069337897
Validation loss: 2.4793121434463186

Epoch: 6| Step: 4
Training loss: 0.11899998055310651
Validation loss: 2.4554092528906755

Epoch: 6| Step: 5
Training loss: 0.1816550525965093
Validation loss: 2.460120561607427

Epoch: 6| Step: 6
Training loss: 0.1180536605606515
Validation loss: 2.4767564784480918

Epoch: 6| Step: 7
Training loss: 0.20848944695841737
Validation loss: 2.4771189389470702

Epoch: 6| Step: 8
Training loss: 0.12355173323913782
Validation loss: 2.45701292279488

Epoch: 6| Step: 9
Training loss: 0.11846831850523215
Validation loss: 2.456886005887054

Epoch: 6| Step: 10
Training loss: 0.15628208188669074
Validation loss: 2.4499093397860756

Epoch: 6| Step: 11
Training loss: 0.11401759677968297
Validation loss: 2.470788148889733

Epoch: 6| Step: 12
Training loss: 0.13055834377963274
Validation loss: 2.438373183673508

Epoch: 6| Step: 13
Training loss: 0.1009320904548826
Validation loss: 2.47091294120462

Epoch: 531| Step: 0
Training loss: 0.12118308940202481
Validation loss: 2.4511072322615304

Epoch: 6| Step: 1
Training loss: 0.10868197808927542
Validation loss: 2.474730881865373

Epoch: 6| Step: 2
Training loss: 0.14137420818164453
Validation loss: 2.4124070432456803

Epoch: 6| Step: 3
Training loss: 0.17122680180633806
Validation loss: 2.4483630406763535

Epoch: 6| Step: 4
Training loss: 0.09336859884943768
Validation loss: 2.4563756739480387

Epoch: 6| Step: 5
Training loss: 0.08219961927809716
Validation loss: 2.4640807689042803

Epoch: 6| Step: 6
Training loss: 0.17498992184161294
Validation loss: 2.4598464471839803

Epoch: 6| Step: 7
Training loss: 0.21531974774745385
Validation loss: 2.4791296458683685

Epoch: 6| Step: 8
Training loss: 0.15783110782715226
Validation loss: 2.445843812348771

Epoch: 6| Step: 9
Training loss: 0.0961917741642611
Validation loss: 2.462580479656568

Epoch: 6| Step: 10
Training loss: 0.12944717775725742
Validation loss: 2.449975464434108

Epoch: 6| Step: 11
Training loss: 0.141774486319039
Validation loss: 2.41464990332984

Epoch: 6| Step: 12
Training loss: 0.10549505223688009
Validation loss: 2.46300069951971

Epoch: 6| Step: 13
Training loss: 0.11011393035125738
Validation loss: 2.4290269430481204

Epoch: 532| Step: 0
Training loss: 0.08186677497397986
Validation loss: 2.4497854485825505

Epoch: 6| Step: 1
Training loss: 0.07259289635342325
Validation loss: 2.416325105483677

Epoch: 6| Step: 2
Training loss: 0.14062559604518457
Validation loss: 2.4169959719816685

Epoch: 6| Step: 3
Training loss: 0.17923687323584309
Validation loss: 2.435124834781506

Epoch: 6| Step: 4
Training loss: 0.17973393379322422
Validation loss: 2.431900987664977

Epoch: 6| Step: 5
Training loss: 0.12115062254858118
Validation loss: 2.4616846521138926

Epoch: 6| Step: 6
Training loss: 0.12715530435562533
Validation loss: 2.424958994469779

Epoch: 6| Step: 7
Training loss: 0.10976347310274888
Validation loss: 2.4654044227436303

Epoch: 6| Step: 8
Training loss: 0.1983050166947404
Validation loss: 2.454233771091182

Epoch: 6| Step: 9
Training loss: 0.09161013012086364
Validation loss: 2.440473090101922

Epoch: 6| Step: 10
Training loss: 0.17851481072304823
Validation loss: 2.436993859021202

Epoch: 6| Step: 11
Training loss: 0.12686283128382989
Validation loss: 2.47455414018559

Epoch: 6| Step: 12
Training loss: 0.12776397572083045
Validation loss: 2.450102002688971

Epoch: 6| Step: 13
Training loss: 0.08929719223173033
Validation loss: 2.442818343727154

Epoch: 533| Step: 0
Training loss: 0.22679189874312566
Validation loss: 2.454752212880487

Epoch: 6| Step: 1
Training loss: 0.13707055740573731
Validation loss: 2.4535124136914352

Epoch: 6| Step: 2
Training loss: 0.06817551136875956
Validation loss: 2.449296976245354

Epoch: 6| Step: 3
Training loss: 0.08880186824362353
Validation loss: 2.449082254207446

Epoch: 6| Step: 4
Training loss: 0.07868859728933593
Validation loss: 2.460938586006765

Epoch: 6| Step: 5
Training loss: 0.13880429191573782
Validation loss: 2.4359010364128393

Epoch: 6| Step: 6
Training loss: 0.1775633229884807
Validation loss: 2.4222042678952707

Epoch: 6| Step: 7
Training loss: 0.23724230978634708
Validation loss: 2.4030289513248144

Epoch: 6| Step: 8
Training loss: 0.13617913841227464
Validation loss: 2.442671628982765

Epoch: 6| Step: 9
Training loss: 0.15827378708247078
Validation loss: 2.4409335847474845

Epoch: 6| Step: 10
Training loss: 0.12473600793252512
Validation loss: 2.456379130573953

Epoch: 6| Step: 11
Training loss: 0.17082483614068342
Validation loss: 2.4611616322635865

Epoch: 6| Step: 12
Training loss: 0.1034992312999412
Validation loss: 2.4606784979203646

Epoch: 6| Step: 13
Training loss: 0.1032865030897644
Validation loss: 2.4674787196001526

Epoch: 534| Step: 0
Training loss: 0.07504460168378081
Validation loss: 2.4994047892003954

Epoch: 6| Step: 1
Training loss: 0.15442781083663082
Validation loss: 2.4592232651530663

Epoch: 6| Step: 2
Training loss: 0.14772844366213098
Validation loss: 2.4924023317336914

Epoch: 6| Step: 3
Training loss: 0.14835927809581032
Validation loss: 2.5083055190171097

Epoch: 6| Step: 4
Training loss: 0.12958745429589316
Validation loss: 2.458684295190615

Epoch: 6| Step: 5
Training loss: 0.20511825713803375
Validation loss: 2.4890962404723873

Epoch: 6| Step: 6
Training loss: 0.1839576321095645
Validation loss: 2.4741349490236404

Epoch: 6| Step: 7
Training loss: 0.17749266904816569
Validation loss: 2.4854271249300353

Epoch: 6| Step: 8
Training loss: 0.1814137549412713
Validation loss: 2.4907719874082117

Epoch: 6| Step: 9
Training loss: 0.1396854724992912
Validation loss: 2.4741043723006486

Epoch: 6| Step: 10
Training loss: 0.10157981596564508
Validation loss: 2.4883020740478057

Epoch: 6| Step: 11
Training loss: 0.08745315076675295
Validation loss: 2.4403977923931577

Epoch: 6| Step: 12
Training loss: 0.12979061037749204
Validation loss: 2.512316902716046

Epoch: 6| Step: 13
Training loss: 0.0970446172665653
Validation loss: 2.5114633628769094

Epoch: 535| Step: 0
Training loss: 0.09460977354997374
Validation loss: 2.475900978002626

Epoch: 6| Step: 1
Training loss: 0.13594980622635866
Validation loss: 2.5029920966857353

Epoch: 6| Step: 2
Training loss: 0.09234174376049518
Validation loss: 2.4880282257504067

Epoch: 6| Step: 3
Training loss: 0.10573551209048188
Validation loss: 2.477347488191722

Epoch: 6| Step: 4
Training loss: 0.18411097817531108
Validation loss: 2.47639553534257

Epoch: 6| Step: 5
Training loss: 0.173314423107465
Validation loss: 2.4932429952094504

Epoch: 6| Step: 6
Training loss: 0.10832941590005889
Validation loss: 2.4837527779005026

Epoch: 6| Step: 7
Training loss: 0.08258961066252068
Validation loss: 2.4839566694357664

Epoch: 6| Step: 8
Training loss: 0.1885152786890383
Validation loss: 2.5066543126549106

Epoch: 6| Step: 9
Training loss: 0.18606660231699126
Validation loss: 2.5223037497784775

Epoch: 6| Step: 10
Training loss: 0.15894481086979925
Validation loss: 2.478824592568297

Epoch: 6| Step: 11
Training loss: 0.11214785613251782
Validation loss: 2.474250845765687

Epoch: 6| Step: 12
Training loss: 0.2071396615825416
Validation loss: 2.5220915250206266

Epoch: 6| Step: 13
Training loss: 0.12283907100565325
Validation loss: 2.478661378565311

Epoch: 536| Step: 0
Training loss: 0.16575331440872684
Validation loss: 2.541219148082539

Epoch: 6| Step: 1
Training loss: 0.1281551747145583
Validation loss: 2.4946459566810835

Epoch: 6| Step: 2
Training loss: 0.14256636035405357
Validation loss: 2.5194988869651156

Epoch: 6| Step: 3
Training loss: 0.2281480833028045
Validation loss: 2.487315444790648

Epoch: 6| Step: 4
Training loss: 0.1472468495732218
Validation loss: 2.4739265195466573

Epoch: 6| Step: 5
Training loss: 0.1006106235247766
Validation loss: 2.4661025076317573

Epoch: 6| Step: 6
Training loss: 0.1251617219945511
Validation loss: 2.4867854746405587

Epoch: 6| Step: 7
Training loss: 0.1981898647469222
Validation loss: 2.459656343919504

Epoch: 6| Step: 8
Training loss: 0.08474209432490422
Validation loss: 2.49691287856254

Epoch: 6| Step: 9
Training loss: 0.0677449680523646
Validation loss: 2.466213898780046

Epoch: 6| Step: 10
Training loss: 0.13366572409947147
Validation loss: 2.437414276660266

Epoch: 6| Step: 11
Training loss: 0.16566798331656446
Validation loss: 2.4439113659655685

Epoch: 6| Step: 12
Training loss: 0.13483931420324832
Validation loss: 2.4335743540184467

Epoch: 6| Step: 13
Training loss: 0.2370497350456722
Validation loss: 2.4484195176168555

Epoch: 537| Step: 0
Training loss: 0.10318137130928892
Validation loss: 2.4219338152224354

Epoch: 6| Step: 1
Training loss: 0.13010112799625345
Validation loss: 2.427224778358915

Epoch: 6| Step: 2
Training loss: 0.09318065615492972
Validation loss: 2.4142132874050386

Epoch: 6| Step: 3
Training loss: 0.10722218940586259
Validation loss: 2.4261592722165597

Epoch: 6| Step: 4
Training loss: 0.18926056189651064
Validation loss: 2.4617060729302267

Epoch: 6| Step: 5
Training loss: 0.19301062257037813
Validation loss: 2.401690519387689

Epoch: 6| Step: 6
Training loss: 0.16801673735962808
Validation loss: 2.403731082588437

Epoch: 6| Step: 7
Training loss: 0.1439208596110595
Validation loss: 2.433905062162165

Epoch: 6| Step: 8
Training loss: 0.13500137027071546
Validation loss: 2.412635213233836

Epoch: 6| Step: 9
Training loss: 0.09416801916722321
Validation loss: 2.435706525033525

Epoch: 6| Step: 10
Training loss: 0.16241653481310597
Validation loss: 2.419732162625921

Epoch: 6| Step: 11
Training loss: 0.1279237105159952
Validation loss: 2.4476698151180045

Epoch: 6| Step: 12
Training loss: 0.14910896166980311
Validation loss: 2.4108821315424844

Epoch: 6| Step: 13
Training loss: 0.16764412049485566
Validation loss: 2.467457606305543

Epoch: 538| Step: 0
Training loss: 0.11124714198084604
Validation loss: 2.451666571982824

Epoch: 6| Step: 1
Training loss: 0.21870110169614196
Validation loss: 2.4540031308281702

Epoch: 6| Step: 2
Training loss: 0.08498464998844948
Validation loss: 2.463471204803704

Epoch: 6| Step: 3
Training loss: 0.09027010883052593
Validation loss: 2.4256113965285895

Epoch: 6| Step: 4
Training loss: 0.18420996634498613
Validation loss: 2.421771695318484

Epoch: 6| Step: 5
Training loss: 0.19968298508460616
Validation loss: 2.426955705125128

Epoch: 6| Step: 6
Training loss: 0.1186826612255541
Validation loss: 2.459812527137742

Epoch: 6| Step: 7
Training loss: 0.11012380440038061
Validation loss: 2.456844554438711

Epoch: 6| Step: 8
Training loss: 0.08239405307080326
Validation loss: 2.4402189852979723

Epoch: 6| Step: 9
Training loss: 0.24353789888838878
Validation loss: 2.433531661666951

Epoch: 6| Step: 10
Training loss: 0.14551003345612268
Validation loss: 2.473316282798935

Epoch: 6| Step: 11
Training loss: 0.12152790105525833
Validation loss: 2.487968232601308

Epoch: 6| Step: 12
Training loss: 0.13360536452328003
Validation loss: 2.492705622623742

Epoch: 6| Step: 13
Training loss: 0.15216512478362004
Validation loss: 2.4754064129925943

Epoch: 539| Step: 0
Training loss: 0.16766861226525567
Validation loss: 2.4777754094754636

Epoch: 6| Step: 1
Training loss: 0.20766178416504935
Validation loss: 2.470552187755564

Epoch: 6| Step: 2
Training loss: 0.19551749915211944
Validation loss: 2.480208407521065

Epoch: 6| Step: 3
Training loss: 0.08172624515347485
Validation loss: 2.481683042567488

Epoch: 6| Step: 4
Training loss: 0.10941980500083338
Validation loss: 2.477309055235279

Epoch: 6| Step: 5
Training loss: 0.19793643769008365
Validation loss: 2.469633389595659

Epoch: 6| Step: 6
Training loss: 0.11592401618897917
Validation loss: 2.4966632848591557

Epoch: 6| Step: 7
Training loss: 0.09354875740895847
Validation loss: 2.4967521931235233

Epoch: 6| Step: 8
Training loss: 0.16633285058844327
Validation loss: 2.479355541620161

Epoch: 6| Step: 9
Training loss: 0.11555210051414211
Validation loss: 2.5170516748926963

Epoch: 6| Step: 10
Training loss: 0.12274593685504193
Validation loss: 2.5257004001896037

Epoch: 6| Step: 11
Training loss: 0.12294303205830362
Validation loss: 2.5018716763509747

Epoch: 6| Step: 12
Training loss: 0.11716733202639645
Validation loss: 2.4979235803977695

Epoch: 6| Step: 13
Training loss: 0.17889606288575183
Validation loss: 2.5131997547770335

Epoch: 540| Step: 0
Training loss: 0.24570053717822707
Validation loss: 2.510444775414081

Epoch: 6| Step: 1
Training loss: 0.0625421113957378
Validation loss: 2.49995334950883

Epoch: 6| Step: 2
Training loss: 0.16379352500726277
Validation loss: 2.520150882363106

Epoch: 6| Step: 3
Training loss: 0.089100693368582
Validation loss: 2.5130242980766524

Epoch: 6| Step: 4
Training loss: 0.16171702047703973
Validation loss: 2.5213671700132503

Epoch: 6| Step: 5
Training loss: 0.10692075974600371
Validation loss: 2.4950499607165444

Epoch: 6| Step: 6
Training loss: 0.1909334708161726
Validation loss: 2.4831008269877404

Epoch: 6| Step: 7
Training loss: 0.1871646226139782
Validation loss: 2.484044367806893

Epoch: 6| Step: 8
Training loss: 0.16147495127855988
Validation loss: 2.5049047655631886

Epoch: 6| Step: 9
Training loss: 0.18395108085720718
Validation loss: 2.468981772867603

Epoch: 6| Step: 10
Training loss: 0.12522162965729225
Validation loss: 2.47916995846523

Epoch: 6| Step: 11
Training loss: 0.1690977269013263
Validation loss: 2.4791629102193644

Epoch: 6| Step: 12
Training loss: 0.11471641643730944
Validation loss: 2.486567247128649

Epoch: 6| Step: 13
Training loss: 0.13847427662198883
Validation loss: 2.4881404306844432

Epoch: 541| Step: 0
Training loss: 0.16943724900406132
Validation loss: 2.446279377130425

Epoch: 6| Step: 1
Training loss: 0.07432124627151396
Validation loss: 2.4543156333686285

Epoch: 6| Step: 2
Training loss: 0.18657517838968568
Validation loss: 2.4743863189041932

Epoch: 6| Step: 3
Training loss: 0.18498905052825632
Validation loss: 2.495315850354041

Epoch: 6| Step: 4
Training loss: 0.15095068943059567
Validation loss: 2.4991708426454706

Epoch: 6| Step: 5
Training loss: 0.17768995547401026
Validation loss: 2.5067762993547915

Epoch: 6| Step: 6
Training loss: 0.1925942087324288
Validation loss: 2.471666182005707

Epoch: 6| Step: 7
Training loss: 0.0788733729005363
Validation loss: 2.4766282194224436

Epoch: 6| Step: 8
Training loss: 0.1227978767966235
Validation loss: 2.499903588845783

Epoch: 6| Step: 9
Training loss: 0.12485680350165544
Validation loss: 2.4610013647170397

Epoch: 6| Step: 10
Training loss: 0.1491513404573673
Validation loss: 2.5187611751175663

Epoch: 6| Step: 11
Training loss: 0.15883218829487597
Validation loss: 2.488454066185776

Epoch: 6| Step: 12
Training loss: 0.1954530210440589
Validation loss: 2.491791677170148

Epoch: 6| Step: 13
Training loss: 0.12411411604938061
Validation loss: 2.492343802662999

Epoch: 542| Step: 0
Training loss: 0.12650355921042922
Validation loss: 2.4838537153127755

Epoch: 6| Step: 1
Training loss: 0.12940718391024347
Validation loss: 2.4953868490914486

Epoch: 6| Step: 2
Training loss: 0.1617633331966999
Validation loss: 2.531567516032944

Epoch: 6| Step: 3
Training loss: 0.18239772073091273
Validation loss: 2.4801860694437083

Epoch: 6| Step: 4
Training loss: 0.12919118485734402
Validation loss: 2.5003427906265214

Epoch: 6| Step: 5
Training loss: 0.1481203153730569
Validation loss: 2.49521282808948

Epoch: 6| Step: 6
Training loss: 0.1278817618484959
Validation loss: 2.529107367259005

Epoch: 6| Step: 7
Training loss: 0.11591446749919893
Validation loss: 2.5462031884777816

Epoch: 6| Step: 8
Training loss: 0.12091259711670917
Validation loss: 2.5072800608369237

Epoch: 6| Step: 9
Training loss: 0.11006234677946916
Validation loss: 2.544852316163308

Epoch: 6| Step: 10
Training loss: 0.15749369017321596
Validation loss: 2.545106356377424

Epoch: 6| Step: 11
Training loss: 0.17032306270917003
Validation loss: 2.510765745489963

Epoch: 6| Step: 12
Training loss: 0.21952352679911377
Validation loss: 2.4993516819693036

Epoch: 6| Step: 13
Training loss: 0.059549153979129736
Validation loss: 2.5079409633135894

Epoch: 543| Step: 0
Training loss: 0.10903059857644828
Validation loss: 2.493264142836633

Epoch: 6| Step: 1
Training loss: 0.08362722974208006
Validation loss: 2.48990972865051

Epoch: 6| Step: 2
Training loss: 0.09739396636196873
Validation loss: 2.5247994564914285

Epoch: 6| Step: 3
Training loss: 0.16351242606346023
Validation loss: 2.484815642943981

Epoch: 6| Step: 4
Training loss: 0.24089690859763938
Validation loss: 2.514412153122154

Epoch: 6| Step: 5
Training loss: 0.15567853853122657
Validation loss: 2.477385358646335

Epoch: 6| Step: 6
Training loss: 0.16214755769112763
Validation loss: 2.488732515436223

Epoch: 6| Step: 7
Training loss: 0.12150106070147722
Validation loss: 2.517687186759985

Epoch: 6| Step: 8
Training loss: 0.12044996205387096
Validation loss: 2.456470195050987

Epoch: 6| Step: 9
Training loss: 0.09871183666699801
Validation loss: 2.5199522917685373

Epoch: 6| Step: 10
Training loss: 0.11696096618246342
Validation loss: 2.4964462119496242

Epoch: 6| Step: 11
Training loss: 0.12831227409465543
Validation loss: 2.498605214471145

Epoch: 6| Step: 12
Training loss: 0.19143054769011594
Validation loss: 2.516736739232394

Epoch: 6| Step: 13
Training loss: 0.10725495634764261
Validation loss: 2.5344328725599254

Epoch: 544| Step: 0
Training loss: 0.2059700055148498
Validation loss: 2.492397258761194

Epoch: 6| Step: 1
Training loss: 0.06101172760484005
Validation loss: 2.5234791528638314

Epoch: 6| Step: 2
Training loss: 0.10312460877604401
Validation loss: 2.536281772510882

Epoch: 6| Step: 3
Training loss: 0.16301292795344924
Validation loss: 2.5171272405309804

Epoch: 6| Step: 4
Training loss: 0.1296335208537588
Validation loss: 2.516946581886732

Epoch: 6| Step: 5
Training loss: 0.1662889586599114
Validation loss: 2.526494834211395

Epoch: 6| Step: 6
Training loss: 0.09878362324659622
Validation loss: 2.479085289259041

Epoch: 6| Step: 7
Training loss: 0.13184723982223776
Validation loss: 2.4981102066320178

Epoch: 6| Step: 8
Training loss: 0.1335115687477914
Validation loss: 2.5226825872731795

Epoch: 6| Step: 9
Training loss: 0.10259820050193788
Validation loss: 2.481071516623589

Epoch: 6| Step: 10
Training loss: 0.11282348220078138
Validation loss: 2.4501694614166203

Epoch: 6| Step: 11
Training loss: 0.12996447297800348
Validation loss: 2.4738111983080997

Epoch: 6| Step: 12
Training loss: 0.1353939928427269
Validation loss: 2.474124000757905

Epoch: 6| Step: 13
Training loss: 0.22823404423283686
Validation loss: 2.47560645773713

Epoch: 545| Step: 0
Training loss: 0.2310736444456618
Validation loss: 2.465508055765474

Epoch: 6| Step: 1
Training loss: 0.14252180136626152
Validation loss: 2.4755173818673972

Epoch: 6| Step: 2
Training loss: 0.14560427444551538
Validation loss: 2.526362551085757

Epoch: 6| Step: 3
Training loss: 0.22388171208605712
Validation loss: 2.5051155389524014

Epoch: 6| Step: 4
Training loss: 0.17977792081928215
Validation loss: 2.488718624513742

Epoch: 6| Step: 5
Training loss: 0.1409869503021516
Validation loss: 2.533208044402201

Epoch: 6| Step: 6
Training loss: 0.17289670796473242
Validation loss: 2.5027315035390214

Epoch: 6| Step: 7
Training loss: 0.16290376962368344
Validation loss: 2.4826996578970664

Epoch: 6| Step: 8
Training loss: 0.1683540139816203
Validation loss: 2.4951598813055176

Epoch: 6| Step: 9
Training loss: 0.1552699706452286
Validation loss: 2.4968479815687967

Epoch: 6| Step: 10
Training loss: 0.11170815137460373
Validation loss: 2.48533355759878

Epoch: 6| Step: 11
Training loss: 0.21991619827776668
Validation loss: 2.462707201990259

Epoch: 6| Step: 12
Training loss: 0.16380001255317436
Validation loss: 2.478565682662764

Epoch: 6| Step: 13
Training loss: 0.11406730191038607
Validation loss: 2.487157388228641

Epoch: 546| Step: 0
Training loss: 0.12797648178283408
Validation loss: 2.436138713743418

Epoch: 6| Step: 1
Training loss: 0.11431156426490491
Validation loss: 2.4507338302368806

Epoch: 6| Step: 2
Training loss: 0.18185000503488638
Validation loss: 2.4482458556119475

Epoch: 6| Step: 3
Training loss: 0.0797708769385374
Validation loss: 2.4630237992329325

Epoch: 6| Step: 4
Training loss: 0.1391549360400414
Validation loss: 2.4653756921544385

Epoch: 6| Step: 5
Training loss: 0.12998029449474138
Validation loss: 2.464597215777111

Epoch: 6| Step: 6
Training loss: 0.25908373484534897
Validation loss: 2.475260799187173

Epoch: 6| Step: 7
Training loss: 0.11077578621936994
Validation loss: 2.4570901329815094

Epoch: 6| Step: 8
Training loss: 0.10277454493791213
Validation loss: 2.481039660408372

Epoch: 6| Step: 9
Training loss: 0.22166056277420743
Validation loss: 2.4473305849992593

Epoch: 6| Step: 10
Training loss: 0.18390048558446945
Validation loss: 2.4468746134330837

Epoch: 6| Step: 11
Training loss: 0.10521904649655901
Validation loss: 2.458041846623745

Epoch: 6| Step: 12
Training loss: 0.12924539860922304
Validation loss: 2.4367656542898137

Epoch: 6| Step: 13
Training loss: 0.05790437433091769
Validation loss: 2.4797545394665934

Epoch: 547| Step: 0
Training loss: 0.13560888207815552
Validation loss: 2.4788362450552204

Epoch: 6| Step: 1
Training loss: 0.16608766787778825
Validation loss: 2.447095777230554

Epoch: 6| Step: 2
Training loss: 0.11677548378475863
Validation loss: 2.458345104152502

Epoch: 6| Step: 3
Training loss: 0.14037638118069504
Validation loss: 2.4766200739441775

Epoch: 6| Step: 4
Training loss: 0.12042647759301416
Validation loss: 2.4498000055377847

Epoch: 6| Step: 5
Training loss: 0.2071052185211342
Validation loss: 2.5094252519512006

Epoch: 6| Step: 6
Training loss: 0.1807654534463648
Validation loss: 2.4794718271137395

Epoch: 6| Step: 7
Training loss: 0.17814442210805248
Validation loss: 2.4656648830997434

Epoch: 6| Step: 8
Training loss: 0.06585038924204466
Validation loss: 2.4920204464843563

Epoch: 6| Step: 9
Training loss: 0.11727029736465788
Validation loss: 2.4873735758194955

Epoch: 6| Step: 10
Training loss: 0.20415076433908033
Validation loss: 2.50743426327588

Epoch: 6| Step: 11
Training loss: 0.15424027189371275
Validation loss: 2.492172406266902

Epoch: 6| Step: 12
Training loss: 0.09256826098722881
Validation loss: 2.4639315547799674

Epoch: 6| Step: 13
Training loss: 0.13956419531257622
Validation loss: 2.4861681441663834

Epoch: 548| Step: 0
Training loss: 0.13655047960649364
Validation loss: 2.478633314135288

Epoch: 6| Step: 1
Training loss: 0.12349966165003008
Validation loss: 2.503634995248858

Epoch: 6| Step: 2
Training loss: 0.1833460232197299
Validation loss: 2.502561624788199

Epoch: 6| Step: 3
Training loss: 0.10680589933574998
Validation loss: 2.461359801212447

Epoch: 6| Step: 4
Training loss: 0.13883840608712417
Validation loss: 2.4801963976381165

Epoch: 6| Step: 5
Training loss: 0.10406682077092383
Validation loss: 2.4713268053973243

Epoch: 6| Step: 6
Training loss: 0.25048273389001574
Validation loss: 2.471672663531992

Epoch: 6| Step: 7
Training loss: 0.08997026636946583
Validation loss: 2.477607072767891

Epoch: 6| Step: 8
Training loss: 0.1161227973907719
Validation loss: 2.4522798993791386

Epoch: 6| Step: 9
Training loss: 0.1300656745152945
Validation loss: 2.443795386786375

Epoch: 6| Step: 10
Training loss: 0.14676448742874315
Validation loss: 2.469451783781209

Epoch: 6| Step: 11
Training loss: 0.17624854388210412
Validation loss: 2.4458600850102816

Epoch: 6| Step: 12
Training loss: 0.14578347049056473
Validation loss: 2.481437785147329

Epoch: 6| Step: 13
Training loss: 0.05323527781415431
Validation loss: 2.455041692952943

Epoch: 549| Step: 0
Training loss: 0.10322438511984056
Validation loss: 2.4706988860763572

Epoch: 6| Step: 1
Training loss: 0.18714801214206028
Validation loss: 2.4935070855343504

Epoch: 6| Step: 2
Training loss: 0.1152468084642812
Validation loss: 2.4883057541948723

Epoch: 6| Step: 3
Training loss: 0.13307940087194448
Validation loss: 2.4988356791280575

Epoch: 6| Step: 4
Training loss: 0.21831458900035372
Validation loss: 2.4732739810385724

Epoch: 6| Step: 5
Training loss: 0.11275114795159635
Validation loss: 2.485333794845533

Epoch: 6| Step: 6
Training loss: 0.11136338863362942
Validation loss: 2.518036244380429

Epoch: 6| Step: 7
Training loss: 0.15114534179700467
Validation loss: 2.497302673717618

Epoch: 6| Step: 8
Training loss: 0.14496187547458894
Validation loss: 2.5339411370172864

Epoch: 6| Step: 9
Training loss: 0.15412424788403675
Validation loss: 2.5203935311889394

Epoch: 6| Step: 10
Training loss: 0.10468615150294847
Validation loss: 2.503314931729313

Epoch: 6| Step: 11
Training loss: 0.1443779364200562
Validation loss: 2.49453832269247

Epoch: 6| Step: 12
Training loss: 0.10865568446280159
Validation loss: 2.5056385268455923

Epoch: 6| Step: 13
Training loss: 0.15947865570052117
Validation loss: 2.5062563199121706

Epoch: 550| Step: 0
Training loss: 0.09927824556945629
Validation loss: 2.5119628471230904

Epoch: 6| Step: 1
Training loss: 0.09591048508774443
Validation loss: 2.4931456955106817

Epoch: 6| Step: 2
Training loss: 0.13830628357064198
Validation loss: 2.4888272198974133

Epoch: 6| Step: 3
Training loss: 0.09952824692110662
Validation loss: 2.488762958793022

Epoch: 6| Step: 4
Training loss: 0.18319841187683605
Validation loss: 2.476304497553603

Epoch: 6| Step: 5
Training loss: 0.06327390230754422
Validation loss: 2.4744795236765054

Epoch: 6| Step: 6
Training loss: 0.17962120740625712
Validation loss: 2.4645919737519075

Epoch: 6| Step: 7
Training loss: 0.16892809035881645
Validation loss: 2.5007542313312783

Epoch: 6| Step: 8
Training loss: 0.22520561690961016
Validation loss: 2.45133799125792

Epoch: 6| Step: 9
Training loss: 0.09005878464184867
Validation loss: 2.4549019839003448

Epoch: 6| Step: 10
Training loss: 0.18748742299813645
Validation loss: 2.4606754687600167

Epoch: 6| Step: 11
Training loss: 0.10385116142196074
Validation loss: 2.4552290059153443

Epoch: 6| Step: 12
Training loss: 0.11438495132143314
Validation loss: 2.495589362770947

Epoch: 6| Step: 13
Training loss: 0.07591644276743141
Validation loss: 2.481220240368126

Epoch: 551| Step: 0
Training loss: 0.1647548259417572
Validation loss: 2.4956728002423425

Epoch: 6| Step: 1
Training loss: 0.09107993559347337
Validation loss: 2.4817336530454543

Epoch: 6| Step: 2
Training loss: 0.07453486606734737
Validation loss: 2.4924635100226165

Epoch: 6| Step: 3
Training loss: 0.10813098854366052
Validation loss: 2.463475097916812

Epoch: 6| Step: 4
Training loss: 0.06610032395547316
Validation loss: 2.473478308557204

Epoch: 6| Step: 5
Training loss: 0.09946558896703833
Validation loss: 2.482350627826559

Epoch: 6| Step: 6
Training loss: 0.09288309543209411
Validation loss: 2.457357304282438

Epoch: 6| Step: 7
Training loss: 0.12711530010432168
Validation loss: 2.5045229344508426

Epoch: 6| Step: 8
Training loss: 0.1971435546875
Validation loss: 2.5056836032994885

Epoch: 6| Step: 9
Training loss: 0.2108172939551645
Validation loss: 2.4875091237200606

Epoch: 6| Step: 10
Training loss: 0.1274048252147682
Validation loss: 2.5153691982054127

Epoch: 6| Step: 11
Training loss: 0.20615182187128622
Validation loss: 2.5239235867528236

Epoch: 6| Step: 12
Training loss: 0.10581427947371498
Validation loss: 2.4842172393168136

Epoch: 6| Step: 13
Training loss: 0.15406784733125659
Validation loss: 2.4859662848377124

Epoch: 552| Step: 0
Training loss: 0.10113052974112269
Validation loss: 2.5009198219403443

Epoch: 6| Step: 1
Training loss: 0.11464353401446777
Validation loss: 2.508616048867734

Epoch: 6| Step: 2
Training loss: 0.09662863799669863
Validation loss: 2.5128301198824348

Epoch: 6| Step: 3
Training loss: 0.17197422934510745
Validation loss: 2.510780427258259

Epoch: 6| Step: 4
Training loss: 0.11255331299425031
Validation loss: 2.461334705867862

Epoch: 6| Step: 5
Training loss: 0.12249647519212727
Validation loss: 2.4478259839340795

Epoch: 6| Step: 6
Training loss: 0.10011078818175044
Validation loss: 2.4488112267992808

Epoch: 6| Step: 7
Training loss: 0.28528582881763437
Validation loss: 2.4362715535509585

Epoch: 6| Step: 8
Training loss: 0.17364667144150547
Validation loss: 2.4640589494452225

Epoch: 6| Step: 9
Training loss: 0.1235036772173763
Validation loss: 2.4818467137840576

Epoch: 6| Step: 10
Training loss: 0.14906104152093885
Validation loss: 2.4689559258730025

Epoch: 6| Step: 11
Training loss: 0.11447460848489746
Validation loss: 2.4284445205846628

Epoch: 6| Step: 12
Training loss: 0.1756383633026382
Validation loss: 2.50575824056111

Epoch: 6| Step: 13
Training loss: 0.1254395119268592
Validation loss: 2.512630397674096

Epoch: 553| Step: 0
Training loss: 0.20838502699543748
Validation loss: 2.4927811858164532

Epoch: 6| Step: 1
Training loss: 0.18771687521711947
Validation loss: 2.472901882815765

Epoch: 6| Step: 2
Training loss: 0.1046289769682112
Validation loss: 2.4627174806522083

Epoch: 6| Step: 3
Training loss: 0.15739666284897563
Validation loss: 2.5407929965608314

Epoch: 6| Step: 4
Training loss: 0.12488637916118103
Validation loss: 2.475571190950172

Epoch: 6| Step: 5
Training loss: 0.1802255825284131
Validation loss: 2.4352572240634407

Epoch: 6| Step: 6
Training loss: 0.21865042054803
Validation loss: 2.4655149808382246

Epoch: 6| Step: 7
Training loss: 0.17478944402966876
Validation loss: 2.470298135258059

Epoch: 6| Step: 8
Training loss: 0.1671860222439209
Validation loss: 2.4554382332136524

Epoch: 6| Step: 9
Training loss: 0.1841611211648087
Validation loss: 2.4262609044750643

Epoch: 6| Step: 10
Training loss: 0.17406961190232642
Validation loss: 2.440530208669979

Epoch: 6| Step: 11
Training loss: 0.11966310518298627
Validation loss: 2.4469539591614304

Epoch: 6| Step: 12
Training loss: 0.1839355169002062
Validation loss: 2.4794307654072156

Epoch: 6| Step: 13
Training loss: 0.212702300392166
Validation loss: 2.4857413069846244

Epoch: 554| Step: 0
Training loss: 0.13062307744231239
Validation loss: 2.485527866450046

Epoch: 6| Step: 1
Training loss: 0.1441199404133603
Validation loss: 2.509863413157003

Epoch: 6| Step: 2
Training loss: 0.10763350793974202
Validation loss: 2.514062986447338

Epoch: 6| Step: 3
Training loss: 0.2325128970106952
Validation loss: 2.4875838188255095

Epoch: 6| Step: 4
Training loss: 0.24657237723308453
Validation loss: 2.519209187438989

Epoch: 6| Step: 5
Training loss: 0.17042707014992156
Validation loss: 2.4716824309079555

Epoch: 6| Step: 6
Training loss: 0.26088333595640784
Validation loss: 2.4602955887465976

Epoch: 6| Step: 7
Training loss: 0.14986258858727344
Validation loss: 2.45490499407739

Epoch: 6| Step: 8
Training loss: 0.2597235021641812
Validation loss: 2.417357142093512

Epoch: 6| Step: 9
Training loss: 0.2069009334755181
Validation loss: 2.373986691342693

Epoch: 6| Step: 10
Training loss: 0.20384364281417178
Validation loss: 2.365571466123768

Epoch: 6| Step: 11
Training loss: 0.23195225690741547
Validation loss: 2.38936930801371

Epoch: 6| Step: 12
Training loss: 0.19956769489416679
Validation loss: 2.348372194719153

Epoch: 6| Step: 13
Training loss: 0.16506403107783432
Validation loss: 2.4075574770608084

Epoch: 555| Step: 0
Training loss: 0.19618926666596948
Validation loss: 2.433469500112306

Epoch: 6| Step: 1
Training loss: 0.2653571910533557
Validation loss: 2.4443933223908028

Epoch: 6| Step: 2
Training loss: 0.31263205599076677
Validation loss: 2.456121558960922

Epoch: 6| Step: 3
Training loss: 0.15844732440306716
Validation loss: 2.437677780285731

Epoch: 6| Step: 4
Training loss: 0.21338528726145686
Validation loss: 2.4344208986838427

Epoch: 6| Step: 5
Training loss: 0.24270154635854668
Validation loss: 2.508861769097019

Epoch: 6| Step: 6
Training loss: 0.28972633276430493
Validation loss: 2.5249603064491533

Epoch: 6| Step: 7
Training loss: 0.18237037094992364
Validation loss: 2.526719193237932

Epoch: 6| Step: 8
Training loss: 0.37945862453308915
Validation loss: 2.4824338968358837

Epoch: 6| Step: 9
Training loss: 0.20867746759116293
Validation loss: 2.4444108794965023

Epoch: 6| Step: 10
Training loss: 0.3325976085444396
Validation loss: 2.4709090437287187

Epoch: 6| Step: 11
Training loss: 0.2243147119666531
Validation loss: 2.4504153940234072

Epoch: 6| Step: 12
Training loss: 0.30400050792761457
Validation loss: 2.4614649043267294

Epoch: 6| Step: 13
Training loss: 0.1588192586117467
Validation loss: 2.477686532123748

Epoch: 556| Step: 0
Training loss: 0.2601310482935122
Validation loss: 2.4381239759992

Epoch: 6| Step: 1
Training loss: 0.2004986024068225
Validation loss: 2.439872192138437

Epoch: 6| Step: 2
Training loss: 0.31141321031875824
Validation loss: 2.3895044008004236

Epoch: 6| Step: 3
Training loss: 0.19192687094550284
Validation loss: 2.4725573646207124

Epoch: 6| Step: 4
Training loss: 0.3456914328629189
Validation loss: 2.4447580947653123

Epoch: 6| Step: 5
Training loss: 0.2429484288343635
Validation loss: 2.4708269136160714

Epoch: 6| Step: 6
Training loss: 0.1837078612368303
Validation loss: 2.5347318332108006

Epoch: 6| Step: 7
Training loss: 0.26696676874167946
Validation loss: 2.5047661151786986

Epoch: 6| Step: 8
Training loss: 0.27416715000616293
Validation loss: 2.519273637640228

Epoch: 6| Step: 9
Training loss: 0.22349339933003837
Validation loss: 2.5239401838282944

Epoch: 6| Step: 10
Training loss: 0.3306471980887181
Validation loss: 2.5289417530192906

Epoch: 6| Step: 11
Training loss: 0.24247956354507683
Validation loss: 2.502697805695829

Epoch: 6| Step: 12
Training loss: 0.23651038778831732
Validation loss: 2.509659511576044

Epoch: 6| Step: 13
Training loss: 0.21860549615708794
Validation loss: 2.4673742342348213

Epoch: 557| Step: 0
Training loss: 0.2795402693426174
Validation loss: 2.5138408224430937

Epoch: 6| Step: 1
Training loss: 0.1774851445408817
Validation loss: 2.547830918272218

Epoch: 6| Step: 2
Training loss: 0.2216996759486078
Validation loss: 2.4886202604518046

Epoch: 6| Step: 3
Training loss: 0.23251999458866024
Validation loss: 2.5459782163847122

Epoch: 6| Step: 4
Training loss: 0.25301162394105325
Validation loss: 2.4877461857036693

Epoch: 6| Step: 5
Training loss: 0.12451940774550974
Validation loss: 2.54920776039388

Epoch: 6| Step: 6
Training loss: 0.27177350682008167
Validation loss: 2.511705072959907

Epoch: 6| Step: 7
Training loss: 0.3745876270142873
Validation loss: 2.5506343127423947

Epoch: 6| Step: 8
Training loss: 0.18197028690509953
Validation loss: 2.478718285270454

Epoch: 6| Step: 9
Training loss: 0.09989943998858092
Validation loss: 2.4648400166213507

Epoch: 6| Step: 10
Training loss: 0.16955971215223956
Validation loss: 2.4434482067833647

Epoch: 6| Step: 11
Training loss: 0.24205599567845473
Validation loss: 2.4251205011825823

Epoch: 6| Step: 12
Training loss: 0.20880681810809568
Validation loss: 2.3960611988510805

Epoch: 6| Step: 13
Training loss: 0.5160878156227829
Validation loss: 2.3833208966965125

Epoch: 558| Step: 0
Training loss: 0.16604482730512118
Validation loss: 2.4578655278217743

Epoch: 6| Step: 1
Training loss: 0.2469778604136375
Validation loss: 2.4918227333674574

Epoch: 6| Step: 2
Training loss: 0.45895077196848616
Validation loss: 2.5407150638253477

Epoch: 6| Step: 3
Training loss: 0.8189559619228434
Validation loss: 2.639202615633275

Epoch: 6| Step: 4
Training loss: 0.37253039492059464
Validation loss: 2.493719208303881

Epoch: 6| Step: 5
Training loss: 0.16506514258546123
Validation loss: 2.4378068213908675

Epoch: 6| Step: 6
Training loss: 0.22032891679024605
Validation loss: 2.4053173508414045

Epoch: 6| Step: 7
Training loss: 0.5384517194892803
Validation loss: 2.3937340394136486

Epoch: 6| Step: 8
Training loss: 0.483432930380413
Validation loss: 2.430552596301862

Epoch: 6| Step: 9
Training loss: 0.7381602193132097
Validation loss: 2.4174250352342845

Epoch: 6| Step: 10
Training loss: 0.544751458541157
Validation loss: 2.3307830982129305

Epoch: 6| Step: 11
Training loss: 0.35947686285922015
Validation loss: 2.346324038363624

Epoch: 6| Step: 12
Training loss: 0.481681966747608
Validation loss: 2.3533749695234683

Epoch: 6| Step: 13
Training loss: 0.4021144324548457
Validation loss: 2.3177746882980923

Epoch: 559| Step: 0
Training loss: 0.40773735669506384
Validation loss: 2.3049954983912393

Epoch: 6| Step: 1
Training loss: 0.32578765487778455
Validation loss: 2.3227057868689314

Epoch: 6| Step: 2
Training loss: 0.6112240833802812
Validation loss: 2.360739903361645

Epoch: 6| Step: 3
Training loss: 0.42628471985419814
Validation loss: 2.3883322511371157

Epoch: 6| Step: 4
Training loss: 0.3866072985410613
Validation loss: 2.4311051321836152

Epoch: 6| Step: 5
Training loss: 0.31424129056203864
Validation loss: 2.4919874859573046

Epoch: 6| Step: 6
Training loss: 1.0024756543254598
Validation loss: 2.5091423572392

Epoch: 6| Step: 7
Training loss: 0.4747327479381155
Validation loss: 2.3629087776480886

Epoch: 6| Step: 8
Training loss: 0.6081466031133413
Validation loss: 2.3871247529106014

Epoch: 6| Step: 9
Training loss: 0.6627913482183068
Validation loss: 2.49086812624563

Epoch: 6| Step: 10
Training loss: 0.9128971985958565
Validation loss: 2.571184631933655

Epoch: 6| Step: 11
Training loss: 1.837392611836438
Validation loss: 2.550069442710704

Epoch: 6| Step: 12
Training loss: 1.1176146110970826
Validation loss: 2.372147085263369

Epoch: 6| Step: 13
Training loss: 0.3860930187383602
Validation loss: 2.361444143610575

Epoch: 560| Step: 0
Training loss: 0.6278754132250657
Validation loss: 2.370558449388807

Epoch: 6| Step: 1
Training loss: 0.6514734870612893
Validation loss: 2.465250191097768

Epoch: 6| Step: 2
Training loss: 0.949521836608758
Validation loss: 2.4951760583814875

Epoch: 6| Step: 3
Training loss: 0.6564774346203226
Validation loss: 2.5642946613240998

Epoch: 6| Step: 4
Training loss: 0.6945521665841269
Validation loss: 2.6106376518336467

Epoch: 6| Step: 5
Training loss: 0.98772094886403
Validation loss: 2.6248614699008326

Epoch: 6| Step: 6
Training loss: 0.9351619175330491
Validation loss: 2.674937556613929

Epoch: 6| Step: 7
Training loss: 0.5838963879290126
Validation loss: 2.6341073714107734

Epoch: 6| Step: 8
Training loss: 0.7303608697389096
Validation loss: 2.6854951787393544

Epoch: 6| Step: 9
Training loss: 0.7402814382121052
Validation loss: 2.7011151523631596

Epoch: 6| Step: 10
Training loss: 0.731186132005696
Validation loss: 2.6677550199003557

Epoch: 6| Step: 11
Training loss: 0.6853090400799804
Validation loss: 2.669095887044317

Epoch: 6| Step: 12
Training loss: 0.5958480908715952
Validation loss: 2.5851521625609886

Epoch: 6| Step: 13
Training loss: 0.672590163436988
Validation loss: 2.477794852620157

Epoch: 561| Step: 0
Training loss: 0.7254544905329848
Validation loss: 2.4439097867093493

Epoch: 6| Step: 1
Training loss: 0.46379744155962793
Validation loss: 2.4064995756514467

Epoch: 6| Step: 2
Training loss: 0.6297833504623572
Validation loss: 2.361834027970522

Epoch: 6| Step: 3
Training loss: 0.5512224959520794
Validation loss: 2.3449641948584716

Epoch: 6| Step: 4
Training loss: 0.5692495604435057
Validation loss: 2.4194643511990694

Epoch: 6| Step: 5
Training loss: 0.6017795022722284
Validation loss: 2.512926480915481

Epoch: 6| Step: 6
Training loss: 0.5098845244554043
Validation loss: 2.5425272761688795

Epoch: 6| Step: 7
Training loss: 0.3833754351376806
Validation loss: 2.5404515891417367

Epoch: 6| Step: 8
Training loss: 0.28291255909087304
Validation loss: 2.478982680923429

Epoch: 6| Step: 9
Training loss: 0.4880685419262379
Validation loss: 2.4611191611718235

Epoch: 6| Step: 10
Training loss: 0.5391421051955844
Validation loss: 2.465724012179212

Epoch: 6| Step: 11
Training loss: 0.4793969893105939
Validation loss: 2.426890542013043

Epoch: 6| Step: 12
Training loss: 0.39592327384411063
Validation loss: 2.431166975366438

Epoch: 6| Step: 13
Training loss: 0.5978983968231865
Validation loss: 2.513519815651757

Epoch: 562| Step: 0
Training loss: 0.25192392165212635
Validation loss: 2.580159132319357

Epoch: 6| Step: 1
Training loss: 0.495111559472836
Validation loss: 2.6292941786924926

Epoch: 6| Step: 2
Training loss: 0.3592654766208049
Validation loss: 2.6564712982356884

Epoch: 6| Step: 3
Training loss: 0.6267127648816511
Validation loss: 2.69709968114345

Epoch: 6| Step: 4
Training loss: 0.4323929664163272
Validation loss: 2.6150052244555804

Epoch: 6| Step: 5
Training loss: 0.36822620545329227
Validation loss: 2.531428535512338

Epoch: 6| Step: 6
Training loss: 0.36355037359979997
Validation loss: 2.4542278869715917

Epoch: 6| Step: 7
Training loss: 0.4160753663915749
Validation loss: 2.403897860069545

Epoch: 6| Step: 8
Training loss: 0.5900090724845594
Validation loss: 2.3713469792349158

Epoch: 6| Step: 9
Training loss: 0.628458325587767
Validation loss: 2.444710958503559

Epoch: 6| Step: 10
Training loss: 0.3916581415033165
Validation loss: 2.513187112502949

Epoch: 6| Step: 11
Training loss: 0.42059031668022084
Validation loss: 2.4779536325914258

Epoch: 6| Step: 12
Training loss: 0.4710413244123311
Validation loss: 2.4422051584739353

Epoch: 6| Step: 13
Training loss: 0.659754071944761
Validation loss: 2.490788130198333

Epoch: 563| Step: 0
Training loss: 0.6724112167391255
Validation loss: 2.460618346380324

Epoch: 6| Step: 1
Training loss: 0.3568660604356037
Validation loss: 2.46110129149064

Epoch: 6| Step: 2
Training loss: 0.6754395387233486
Validation loss: 2.491458605828677

Epoch: 6| Step: 3
Training loss: 0.5155116736980044
Validation loss: 2.4157859575103284

Epoch: 6| Step: 4
Training loss: 0.6579898749126146
Validation loss: 2.3039789149556236

Epoch: 6| Step: 5
Training loss: 0.7152798682452849
Validation loss: 2.299289925293587

Epoch: 6| Step: 6
Training loss: 0.6015735476581686
Validation loss: 2.3511100608797415

Epoch: 6| Step: 7
Training loss: 0.4976829096481715
Validation loss: 2.5330879894367446

Epoch: 6| Step: 8
Training loss: 0.5478518616918607
Validation loss: 2.619724608879496

Epoch: 6| Step: 9
Training loss: 0.5132644546060197
Validation loss: 2.714274204440081

Epoch: 6| Step: 10
Training loss: 0.9683976301644032
Validation loss: 2.7444831656250184

Epoch: 6| Step: 11
Training loss: 0.8400016813601969
Validation loss: 2.7672382903091983

Epoch: 6| Step: 12
Training loss: 0.45732873217522096
Validation loss: 2.6382797738187183

Epoch: 6| Step: 13
Training loss: 0.21347445306320345
Validation loss: 2.5647948659151956

Epoch: 564| Step: 0
Training loss: 0.20410011144970977
Validation loss: 2.4710874549835053

Epoch: 6| Step: 1
Training loss: 0.7253220747118907
Validation loss: 2.489517214296924

Epoch: 6| Step: 2
Training loss: 0.5907157364028643
Validation loss: 2.476903845622618

Epoch: 6| Step: 3
Training loss: 0.7972782087290846
Validation loss: 2.508984560923849

Epoch: 6| Step: 4
Training loss: 0.49004947169329616
Validation loss: 2.5020809562477617

Epoch: 6| Step: 5
Training loss: 0.42600074849824116
Validation loss: 2.4585629973449934

Epoch: 6| Step: 6
Training loss: 0.5111008619176933
Validation loss: 2.4827062835789673

Epoch: 6| Step: 7
Training loss: 0.25816393510097013
Validation loss: 2.5228731903611203

Epoch: 6| Step: 8
Training loss: 0.45861434630327214
Validation loss: 2.5559786660613906

Epoch: 6| Step: 9
Training loss: 0.7663557885654784
Validation loss: 2.552484098053092

Epoch: 6| Step: 10
Training loss: 0.9872679208310864
Validation loss: 2.5887349948840446

Epoch: 6| Step: 11
Training loss: 0.5833837935784385
Validation loss: 2.462368729605446

Epoch: 6| Step: 12
Training loss: 0.35025786879887916
Validation loss: 2.469864235178704

Epoch: 6| Step: 13
Training loss: 0.4622363524704613
Validation loss: 2.440792628069404

Epoch: 565| Step: 0
Training loss: 0.5109295182377497
Validation loss: 2.417843179737072

Epoch: 6| Step: 1
Training loss: 0.6881628309170541
Validation loss: 2.4195204494905074

Epoch: 6| Step: 2
Training loss: 0.5193089748239507
Validation loss: 2.4190932712193076

Epoch: 6| Step: 3
Training loss: 0.45153501684378705
Validation loss: 2.4363499198159073

Epoch: 6| Step: 4
Training loss: 0.5164437584809993
Validation loss: 2.3772893395136707

Epoch: 6| Step: 5
Training loss: 0.2247893980313625
Validation loss: 2.385672991344531

Epoch: 6| Step: 6
Training loss: 0.536610208388799
Validation loss: 2.3860439015579273

Epoch: 6| Step: 7
Training loss: 0.4396054491322344
Validation loss: 2.4152793601020583

Epoch: 6| Step: 8
Training loss: 0.22125755988152712
Validation loss: 2.406733960290943

Epoch: 6| Step: 9
Training loss: 0.5286427640277727
Validation loss: 2.3920606602131245

Epoch: 6| Step: 10
Training loss: 0.28219822144022244
Validation loss: 2.384000138817248

Epoch: 6| Step: 11
Training loss: 0.28221547458079793
Validation loss: 2.386691748426045

Epoch: 6| Step: 12
Training loss: 0.3287357368566137
Validation loss: 2.3867584757439806

Epoch: 6| Step: 13
Training loss: 0.25642793397495944
Validation loss: 2.443125482529875

Epoch: 566| Step: 0
Training loss: 0.408577906664287
Validation loss: 2.422832592650608

Epoch: 6| Step: 1
Training loss: 0.3488649829388646
Validation loss: 2.4603630639058034

Epoch: 6| Step: 2
Training loss: 0.3074331792863986
Validation loss: 2.4550013047409025

Epoch: 6| Step: 3
Training loss: 0.3431672662228285
Validation loss: 2.4493809628451797

Epoch: 6| Step: 4
Training loss: 0.29852018509082123
Validation loss: 2.440054082037456

Epoch: 6| Step: 5
Training loss: 0.27019987240625243
Validation loss: 2.4412014478530977

Epoch: 6| Step: 6
Training loss: 0.35888231754848066
Validation loss: 2.4773792439047755

Epoch: 6| Step: 7
Training loss: 0.39698849654647206
Validation loss: 2.4737840291629087

Epoch: 6| Step: 8
Training loss: 0.2706725517501875
Validation loss: 2.473648681605268

Epoch: 6| Step: 9
Training loss: 0.2840959877947362
Validation loss: 2.4708659910735813

Epoch: 6| Step: 10
Training loss: 0.19396014276910903
Validation loss: 2.466326945950107

Epoch: 6| Step: 11
Training loss: 0.3847251134932877
Validation loss: 2.426255424827214

Epoch: 6| Step: 12
Training loss: 0.3553973954235718
Validation loss: 2.4776505432304683

Epoch: 6| Step: 13
Training loss: 0.3349705019105298
Validation loss: 2.466305059047875

Epoch: 567| Step: 0
Training loss: 0.22572808514224302
Validation loss: 2.460390458358967

Epoch: 6| Step: 1
Training loss: 0.2578084829768874
Validation loss: 2.4979619188903524

Epoch: 6| Step: 2
Training loss: 0.17869509433914307
Validation loss: 2.5148750888794007

Epoch: 6| Step: 3
Training loss: 0.3250494965129099
Validation loss: 2.5185767682318505

Epoch: 6| Step: 4
Training loss: 0.17836304452390467
Validation loss: 2.538365355547604

Epoch: 6| Step: 5
Training loss: 0.28948791233087573
Validation loss: 2.5110655136592475

Epoch: 6| Step: 6
Training loss: 0.2749497557386655
Validation loss: 2.51841280839037

Epoch: 6| Step: 7
Training loss: 0.2620208903558275
Validation loss: 2.5398569918426444

Epoch: 6| Step: 8
Training loss: 0.3420430958675756
Validation loss: 2.529710069047578

Epoch: 6| Step: 9
Training loss: 0.17620352780004386
Validation loss: 2.5325516068889145

Epoch: 6| Step: 10
Training loss: 0.21467419783014882
Validation loss: 2.5433754672975386

Epoch: 6| Step: 11
Training loss: 0.31337611648016794
Validation loss: 2.5051197930655977

Epoch: 6| Step: 12
Training loss: 0.21018047831249415
Validation loss: 2.5245294123874102

Epoch: 6| Step: 13
Training loss: 0.22583990127231518
Validation loss: 2.5443144014792405

Epoch: 568| Step: 0
Training loss: 0.25271161078591775
Validation loss: 2.532759294079278

Epoch: 6| Step: 1
Training loss: 0.14145806374919787
Validation loss: 2.5222897276431495

Epoch: 6| Step: 2
Training loss: 0.16289335289736112
Validation loss: 2.470823783284014

Epoch: 6| Step: 3
Training loss: 0.2770390650275691
Validation loss: 2.5207464829808406

Epoch: 6| Step: 4
Training loss: 0.2424335153128832
Validation loss: 2.4946178069389116

Epoch: 6| Step: 5
Training loss: 0.21759837003309532
Validation loss: 2.456823079756984

Epoch: 6| Step: 6
Training loss: 0.1915678295962301
Validation loss: 2.4402534786850807

Epoch: 6| Step: 7
Training loss: 0.17146645019974524
Validation loss: 2.4374926051345027

Epoch: 6| Step: 8
Training loss: 0.2473042552837571
Validation loss: 2.43561508630936

Epoch: 6| Step: 9
Training loss: 0.21379710054960693
Validation loss: 2.450988330186395

Epoch: 6| Step: 10
Training loss: 0.13063689435530662
Validation loss: 2.4517952490799924

Epoch: 6| Step: 11
Training loss: 0.2618098598573858
Validation loss: 2.470942062360666

Epoch: 6| Step: 12
Training loss: 0.25214510264654966
Validation loss: 2.428159064905743

Epoch: 6| Step: 13
Training loss: 0.2581913793896173
Validation loss: 2.4256044383850237

Epoch: 569| Step: 0
Training loss: 0.21641545637633497
Validation loss: 2.4334559063403955

Epoch: 6| Step: 1
Training loss: 0.2660652887307086
Validation loss: 2.434627904930144

Epoch: 6| Step: 2
Training loss: 0.1917083652547163
Validation loss: 2.4187137657326567

Epoch: 6| Step: 3
Training loss: 0.19697654429027783
Validation loss: 2.4590524199146584

Epoch: 6| Step: 4
Training loss: 0.24532806019119796
Validation loss: 2.4098455932525966

Epoch: 6| Step: 5
Training loss: 0.148588480209143
Validation loss: 2.3750118153855135

Epoch: 6| Step: 6
Training loss: 0.12183609044859478
Validation loss: 2.3986784432617494

Epoch: 6| Step: 7
Training loss: 0.1545447157767878
Validation loss: 2.3973355613302196

Epoch: 6| Step: 8
Training loss: 0.19505663324472625
Validation loss: 2.424342819050322

Epoch: 6| Step: 9
Training loss: 0.1601622743171347
Validation loss: 2.436910374427559

Epoch: 6| Step: 10
Training loss: 0.1655008975707663
Validation loss: 2.406817509529707

Epoch: 6| Step: 11
Training loss: 0.27660955039628987
Validation loss: 2.41107029675299

Epoch: 6| Step: 12
Training loss: 0.21009153695666577
Validation loss: 2.445382341681407

Epoch: 6| Step: 13
Training loss: 0.21762471616201717
Validation loss: 2.4367188368603188

Epoch: 570| Step: 0
Training loss: 0.2147823592820169
Validation loss: 2.428150232100316

Epoch: 6| Step: 1
Training loss: 0.23799249475480141
Validation loss: 2.4260696272218736

Epoch: 6| Step: 2
Training loss: 0.1581073753802748
Validation loss: 2.3911663576232964

Epoch: 6| Step: 3
Training loss: 0.20912906949677668
Validation loss: 2.440311026811005

Epoch: 6| Step: 4
Training loss: 0.18467894894189077
Validation loss: 2.387644507174234

Epoch: 6| Step: 5
Training loss: 0.1751667141829991
Validation loss: 2.4691522576107747

Epoch: 6| Step: 6
Training loss: 0.15723894793139978
Validation loss: 2.443637295447087

Epoch: 6| Step: 7
Training loss: 0.11440259368058493
Validation loss: 2.4487245028324995

Epoch: 6| Step: 8
Training loss: 0.14108330167271319
Validation loss: 2.484017296139084

Epoch: 6| Step: 9
Training loss: 0.17252345653012663
Validation loss: 2.4714813709711607

Epoch: 6| Step: 10
Training loss: 0.1954927185207488
Validation loss: 2.468804531863279

Epoch: 6| Step: 11
Training loss: 0.1673367219850704
Validation loss: 2.4743534089167523

Epoch: 6| Step: 12
Training loss: 0.21779480217794905
Validation loss: 2.471783439098215

Epoch: 6| Step: 13
Training loss: 0.18898404440312763
Validation loss: 2.484137351078056

Epoch: 571| Step: 0
Training loss: 0.17592048428916907
Validation loss: 2.503414745531107

Epoch: 6| Step: 1
Training loss: 0.1895341503270475
Validation loss: 2.502848915420661

Epoch: 6| Step: 2
Training loss: 0.23909029643204938
Validation loss: 2.4862619355496367

Epoch: 6| Step: 3
Training loss: 0.140635595982094
Validation loss: 2.4613722810880856

Epoch: 6| Step: 4
Training loss: 0.1767906032095427
Validation loss: 2.4942201630333245

Epoch: 6| Step: 5
Training loss: 0.1487706799417095
Validation loss: 2.4832280651684338

Epoch: 6| Step: 6
Training loss: 0.1608797803167079
Validation loss: 2.4406489427341245

Epoch: 6| Step: 7
Training loss: 0.2480569071505657
Validation loss: 2.439780171897836

Epoch: 6| Step: 8
Training loss: 0.20755117736069845
Validation loss: 2.436768870719406

Epoch: 6| Step: 9
Training loss: 0.16715774360455848
Validation loss: 2.451223285918517

Epoch: 6| Step: 10
Training loss: 0.14099597344880177
Validation loss: 2.4668893610738194

Epoch: 6| Step: 11
Training loss: 0.24516496534641097
Validation loss: 2.4384589358576507

Epoch: 6| Step: 12
Training loss: 0.2652920852598116
Validation loss: 2.4492174436959524

Epoch: 6| Step: 13
Training loss: 0.14110833129648892
Validation loss: 2.464446276460167

Epoch: 572| Step: 0
Training loss: 0.17986800622631532
Validation loss: 2.4635628812489974

Epoch: 6| Step: 1
Training loss: 0.22955947863394793
Validation loss: 2.460258872900724

Epoch: 6| Step: 2
Training loss: 0.14996614868934943
Validation loss: 2.4620072526386516

Epoch: 6| Step: 3
Training loss: 0.17700584670421238
Validation loss: 2.466458681124277

Epoch: 6| Step: 4
Training loss: 0.19125350384837303
Validation loss: 2.4670704800698178

Epoch: 6| Step: 5
Training loss: 0.23894970576606844
Validation loss: 2.4495350120837416

Epoch: 6| Step: 6
Training loss: 0.12988428961121856
Validation loss: 2.496524417055388

Epoch: 6| Step: 7
Training loss: 0.21407358669891222
Validation loss: 2.4768275739548873

Epoch: 6| Step: 8
Training loss: 0.181504608829427
Validation loss: 2.4643731832389255

Epoch: 6| Step: 9
Training loss: 0.20305239773762185
Validation loss: 2.4577662632719757

Epoch: 6| Step: 10
Training loss: 0.10786858357677975
Validation loss: 2.465175635635607

Epoch: 6| Step: 11
Training loss: 0.1734189135240764
Validation loss: 2.484175984893736

Epoch: 6| Step: 12
Training loss: 0.16226391148110145
Validation loss: 2.440648751562586

Epoch: 6| Step: 13
Training loss: 0.15754835003509743
Validation loss: 2.449460235757896

Epoch: 573| Step: 0
Training loss: 0.20838249739057918
Validation loss: 2.473469054840589

Epoch: 6| Step: 1
Training loss: 0.1703666259781561
Validation loss: 2.4681872638634803

Epoch: 6| Step: 2
Training loss: 0.13958697533719394
Validation loss: 2.463425018754767

Epoch: 6| Step: 3
Training loss: 0.08949455526175995
Validation loss: 2.493313210357741

Epoch: 6| Step: 4
Training loss: 0.13168118188870664
Validation loss: 2.44366282222156

Epoch: 6| Step: 5
Training loss: 0.19585496908922348
Validation loss: 2.453805681020566

Epoch: 6| Step: 6
Training loss: 0.15143215876994667
Validation loss: 2.4693465835372646

Epoch: 6| Step: 7
Training loss: 0.21623047737794848
Validation loss: 2.4890821507386987

Epoch: 6| Step: 8
Training loss: 0.20479237767022063
Validation loss: 2.4533907640090935

Epoch: 6| Step: 9
Training loss: 0.19112999111566906
Validation loss: 2.435325430853397

Epoch: 6| Step: 10
Training loss: 0.1872378642799577
Validation loss: 2.4341828993318586

Epoch: 6| Step: 11
Training loss: 0.2022988869851401
Validation loss: 2.456347882999881

Epoch: 6| Step: 12
Training loss: 0.18300851925578077
Validation loss: 2.484922421367004

Epoch: 6| Step: 13
Training loss: 0.13666994041014802
Validation loss: 2.4785106353139357

Epoch: 574| Step: 0
Training loss: 0.12846142428859847
Validation loss: 2.484821034204957

Epoch: 6| Step: 1
Training loss: 0.13172542744020754
Validation loss: 2.492575852650901

Epoch: 6| Step: 2
Training loss: 0.25222705764804615
Validation loss: 2.474237283848835

Epoch: 6| Step: 3
Training loss: 0.17520160472376645
Validation loss: 2.5032263087876947

Epoch: 6| Step: 4
Training loss: 0.12465580849415132
Validation loss: 2.4980676920440343

Epoch: 6| Step: 5
Training loss: 0.17777365994423797
Validation loss: 2.501511344610286

Epoch: 6| Step: 6
Training loss: 0.15326840439223807
Validation loss: 2.5102871457326454

Epoch: 6| Step: 7
Training loss: 0.18770096856684348
Validation loss: 2.48781808212943

Epoch: 6| Step: 8
Training loss: 0.15237656875605488
Validation loss: 2.5133439166794767

Epoch: 6| Step: 9
Training loss: 0.1467069714767481
Validation loss: 2.5164521893688416

Epoch: 6| Step: 10
Training loss: 0.17863948623533166
Validation loss: 2.5026744104373164

Epoch: 6| Step: 11
Training loss: 0.11969379689233274
Validation loss: 2.4911578799329157

Epoch: 6| Step: 12
Training loss: 0.20762159642502134
Validation loss: 2.500228264344913

Epoch: 6| Step: 13
Training loss: 0.1440316017967624
Validation loss: 2.491939600626413

Epoch: 575| Step: 0
Training loss: 0.11839230617504105
Validation loss: 2.5162614753381236

Epoch: 6| Step: 1
Training loss: 0.12015867679759477
Validation loss: 2.494362653297722

Epoch: 6| Step: 2
Training loss: 0.11909086329495787
Validation loss: 2.473490164239924

Epoch: 6| Step: 3
Training loss: 0.1353067645956387
Validation loss: 2.4920311314674644

Epoch: 6| Step: 4
Training loss: 0.12561170097197158
Validation loss: 2.5051318681786756

Epoch: 6| Step: 5
Training loss: 0.13059426255181464
Validation loss: 2.4587719388545914

Epoch: 6| Step: 6
Training loss: 0.10711822073961681
Validation loss: 2.5204102023676787

Epoch: 6| Step: 7
Training loss: 0.11714370226980936
Validation loss: 2.4983651147867048

Epoch: 6| Step: 8
Training loss: 0.18402051024111857
Validation loss: 2.4966950536497152

Epoch: 6| Step: 9
Training loss: 0.1077363871994378
Validation loss: 2.493250220608931

Epoch: 6| Step: 10
Training loss: 0.1359684588267655
Validation loss: 2.490735206178608

Epoch: 6| Step: 11
Training loss: 0.14568511350437127
Validation loss: 2.4666098802920504

Epoch: 6| Step: 12
Training loss: 0.23595640409916893
Validation loss: 2.489737421258892

Epoch: 6| Step: 13
Training loss: 0.15351309470889377
Validation loss: 2.436756110971727

Epoch: 576| Step: 0
Training loss: 0.07526272687149194
Validation loss: 2.447124516579963

Epoch: 6| Step: 1
Training loss: 0.14037080148242118
Validation loss: 2.4409315356687995

Epoch: 6| Step: 2
Training loss: 0.09807833531587934
Validation loss: 2.45712730569098

Epoch: 6| Step: 3
Training loss: 0.20511379839934704
Validation loss: 2.4389234256574968

Epoch: 6| Step: 4
Training loss: 0.13592726625090162
Validation loss: 2.4501993219203215

Epoch: 6| Step: 5
Training loss: 0.09048146954823565
Validation loss: 2.42651885445666

Epoch: 6| Step: 6
Training loss: 0.1558119653955799
Validation loss: 2.45231564904206

Epoch: 6| Step: 7
Training loss: 0.1492515066153076
Validation loss: 2.466226276649734

Epoch: 6| Step: 8
Training loss: 0.20093731028843018
Validation loss: 2.449990941081775

Epoch: 6| Step: 9
Training loss: 0.1231609451523726
Validation loss: 2.462471299383925

Epoch: 6| Step: 10
Training loss: 0.1521358171353483
Validation loss: 2.450177462548068

Epoch: 6| Step: 11
Training loss: 0.10328683220556172
Validation loss: 2.449950568491765

Epoch: 6| Step: 12
Training loss: 0.12697574707362763
Validation loss: 2.483878989793352

Epoch: 6| Step: 13
Training loss: 0.31657857087775454
Validation loss: 2.5003981529583506

Epoch: 577| Step: 0
Training loss: 0.11623234912221146
Validation loss: 2.471833776221493

Epoch: 6| Step: 1
Training loss: 0.16864140689908577
Validation loss: 2.4970031105799553

Epoch: 6| Step: 2
Training loss: 0.14715638827076213
Validation loss: 2.499621522105731

Epoch: 6| Step: 3
Training loss: 0.18245210172525184
Validation loss: 2.494891603961693

Epoch: 6| Step: 4
Training loss: 0.08986683217299828
Validation loss: 2.4777440033840463

Epoch: 6| Step: 5
Training loss: 0.15988562561177416
Validation loss: 2.4906974774626813

Epoch: 6| Step: 6
Training loss: 0.22470442377904398
Validation loss: 2.4483337766107374

Epoch: 6| Step: 7
Training loss: 0.13462444871933044
Validation loss: 2.4983582181756407

Epoch: 6| Step: 8
Training loss: 0.15409264750251608
Validation loss: 2.4585434917834057

Epoch: 6| Step: 9
Training loss: 0.1296570615782108
Validation loss: 2.4936966926057744

Epoch: 6| Step: 10
Training loss: 0.10806732900567856
Validation loss: 2.489133927028186

Epoch: 6| Step: 11
Training loss: 0.1263573016230902
Validation loss: 2.50254594517172

Epoch: 6| Step: 12
Training loss: 0.12427836223342631
Validation loss: 2.467895844999252

Epoch: 6| Step: 13
Training loss: 0.22939551732032837
Validation loss: 2.5277838792163454

Epoch: 578| Step: 0
Training loss: 0.1394305095980744
Validation loss: 2.5378070028692807

Epoch: 6| Step: 1
Training loss: 0.1580561791366991
Validation loss: 2.527168895386602

Epoch: 6| Step: 2
Training loss: 0.12726574333986293
Validation loss: 2.5441139351581374

Epoch: 6| Step: 3
Training loss: 0.17813886998368292
Validation loss: 2.560098338475152

Epoch: 6| Step: 4
Training loss: 0.15677945318213185
Validation loss: 2.5282366545452413

Epoch: 6| Step: 5
Training loss: 0.19273335814159445
Validation loss: 2.556032228584507

Epoch: 6| Step: 6
Training loss: 0.18267880384542007
Validation loss: 2.550598109313015

Epoch: 6| Step: 7
Training loss: 0.19927350395082782
Validation loss: 2.5523231194468226

Epoch: 6| Step: 8
Training loss: 0.11161058548318009
Validation loss: 2.539659157593113

Epoch: 6| Step: 9
Training loss: 0.18233874712098005
Validation loss: 2.527954549643615

Epoch: 6| Step: 10
Training loss: 0.12192582543951942
Validation loss: 2.553635048437174

Epoch: 6| Step: 11
Training loss: 0.14081203420488345
Validation loss: 2.4870255289694083

Epoch: 6| Step: 12
Training loss: 0.13599895644664098
Validation loss: 2.5231317530292077

Epoch: 6| Step: 13
Training loss: 0.10057981713201841
Validation loss: 2.4857091341728577

Epoch: 579| Step: 0
Training loss: 0.15174372201357833
Validation loss: 2.4928986411094542

Epoch: 6| Step: 1
Training loss: 0.19221570653092085
Validation loss: 2.517745497827036

Epoch: 6| Step: 2
Training loss: 0.13122897831280075
Validation loss: 2.5203043512244503

Epoch: 6| Step: 3
Training loss: 0.11075041435941332
Validation loss: 2.474498703149556

Epoch: 6| Step: 4
Training loss: 0.16279090532209117
Validation loss: 2.497400015737104

Epoch: 6| Step: 5
Training loss: 0.1288292250114934
Validation loss: 2.4908927516538615

Epoch: 6| Step: 6
Training loss: 0.1047148960477831
Validation loss: 2.4931288008869816

Epoch: 6| Step: 7
Training loss: 0.15736830583201625
Validation loss: 2.4437925040210424

Epoch: 6| Step: 8
Training loss: 0.14854328878135853
Validation loss: 2.4545647632669723

Epoch: 6| Step: 9
Training loss: 0.12251310530208347
Validation loss: 2.468015976769397

Epoch: 6| Step: 10
Training loss: 0.1489929047949767
Validation loss: 2.4328145692578773

Epoch: 6| Step: 11
Training loss: 0.12184205649256394
Validation loss: 2.41582568280802

Epoch: 6| Step: 12
Training loss: 0.1222976741589205
Validation loss: 2.4568182901886653

Epoch: 6| Step: 13
Training loss: 0.1756631825556314
Validation loss: 2.4528580151856705

Epoch: 580| Step: 0
Training loss: 0.21443595331090629
Validation loss: 2.4289164677420465

Epoch: 6| Step: 1
Training loss: 0.15560885255605048
Validation loss: 2.4512771304726297

Epoch: 6| Step: 2
Training loss: 0.14247227358241754
Validation loss: 2.4086025719703614

Epoch: 6| Step: 3
Training loss: 0.13927757262094898
Validation loss: 2.4263540153884393

Epoch: 6| Step: 4
Training loss: 0.0942054206994241
Validation loss: 2.4119949436565675

Epoch: 6| Step: 5
Training loss: 0.11837620253591592
Validation loss: 2.4088182278485055

Epoch: 6| Step: 6
Training loss: 0.12161295853645109
Validation loss: 2.4418410861079054

Epoch: 6| Step: 7
Training loss: 0.15731542457329403
Validation loss: 2.4419804175099675

Epoch: 6| Step: 8
Training loss: 0.16357691748371342
Validation loss: 2.454230010604521

Epoch: 6| Step: 9
Training loss: 0.1992334005167311
Validation loss: 2.4637791059721663

Epoch: 6| Step: 10
Training loss: 0.12116393624056317
Validation loss: 2.468082607761955

Epoch: 6| Step: 11
Training loss: 0.11716450624584766
Validation loss: 2.4646514208573675

Epoch: 6| Step: 12
Training loss: 0.12125924553229288
Validation loss: 2.4682685088636553

Epoch: 6| Step: 13
Training loss: 0.15709872409336126
Validation loss: 2.4642979926606787

Epoch: 581| Step: 0
Training loss: 0.09600540515682397
Validation loss: 2.4548350410995385

Epoch: 6| Step: 1
Training loss: 0.10348901316618965
Validation loss: 2.450522343292683

Epoch: 6| Step: 2
Training loss: 0.15565973488836016
Validation loss: 2.452609821474965

Epoch: 6| Step: 3
Training loss: 0.3424230888078862
Validation loss: 2.4727120715147923

Epoch: 6| Step: 4
Training loss: 0.10518383466371617
Validation loss: 2.4757903659599028

Epoch: 6| Step: 5
Training loss: 0.13806620487873536
Validation loss: 2.4599921600226207

Epoch: 6| Step: 6
Training loss: 0.11939827232172195
Validation loss: 2.4297122553770496

Epoch: 6| Step: 7
Training loss: 0.13801363410407727
Validation loss: 2.4532479126794855

Epoch: 6| Step: 8
Training loss: 0.1808653663648037
Validation loss: 2.480468206362785

Epoch: 6| Step: 9
Training loss: 0.08102122155983638
Validation loss: 2.450689585234918

Epoch: 6| Step: 10
Training loss: 0.1133385135349727
Validation loss: 2.471379629489542

Epoch: 6| Step: 11
Training loss: 0.10662717769362208
Validation loss: 2.487913058400076

Epoch: 6| Step: 12
Training loss: 0.16258110214139862
Validation loss: 2.5100997876631963

Epoch: 6| Step: 13
Training loss: 0.23806712425950505
Validation loss: 2.478760758886193

Epoch: 582| Step: 0
Training loss: 0.16791231848653607
Validation loss: 2.473872802153941

Epoch: 6| Step: 1
Training loss: 0.17615689829330972
Validation loss: 2.462360536436282

Epoch: 6| Step: 2
Training loss: 0.17706583909031398
Validation loss: 2.4762715198835923

Epoch: 6| Step: 3
Training loss: 0.09836356076854925
Validation loss: 2.4803953656500246

Epoch: 6| Step: 4
Training loss: 0.11634310651499272
Validation loss: 2.480649980224619

Epoch: 6| Step: 5
Training loss: 0.14170373979082418
Validation loss: 2.429927673065265

Epoch: 6| Step: 6
Training loss: 0.13728364319238215
Validation loss: 2.475120491843665

Epoch: 6| Step: 7
Training loss: 0.10075813664196898
Validation loss: 2.4549273966754246

Epoch: 6| Step: 8
Training loss: 0.13023449317089228
Validation loss: 2.4373871120061956

Epoch: 6| Step: 9
Training loss: 0.14528746209758248
Validation loss: 2.428892564468333

Epoch: 6| Step: 10
Training loss: 0.19452806301646958
Validation loss: 2.406501877760626

Epoch: 6| Step: 11
Training loss: 0.1831944770642646
Validation loss: 2.446404384827226

Epoch: 6| Step: 12
Training loss: 0.17697021199773857
Validation loss: 2.4194212901310843

Epoch: 6| Step: 13
Training loss: 0.09542348938377891
Validation loss: 2.4189423746840353

Epoch: 583| Step: 0
Training loss: 0.14108734156438388
Validation loss: 2.4335745657612047

Epoch: 6| Step: 1
Training loss: 0.18470389966235118
Validation loss: 2.4501107029936984

Epoch: 6| Step: 2
Training loss: 0.06425296162206542
Validation loss: 2.4260376194071647

Epoch: 6| Step: 3
Training loss: 0.14639284453194046
Validation loss: 2.4417433833506825

Epoch: 6| Step: 4
Training loss: 0.14835529811936402
Validation loss: 2.433177001551175

Epoch: 6| Step: 5
Training loss: 0.13692333717875776
Validation loss: 2.4622410173882066

Epoch: 6| Step: 6
Training loss: 0.07473910646696294
Validation loss: 2.4719298706710044

Epoch: 6| Step: 7
Training loss: 0.10648509253430165
Validation loss: 2.4346212863478613

Epoch: 6| Step: 8
Training loss: 0.1625129433208833
Validation loss: 2.47904787496817

Epoch: 6| Step: 9
Training loss: 0.18185123416139912
Validation loss: 2.4505001907357093

Epoch: 6| Step: 10
Training loss: 0.0755869463673373
Validation loss: 2.413963635762479

Epoch: 6| Step: 11
Training loss: 0.16460569467218772
Validation loss: 2.414533873410018

Epoch: 6| Step: 12
Training loss: 0.11151505136442547
Validation loss: 2.446362383234523

Epoch: 6| Step: 13
Training loss: 0.11061160918456991
Validation loss: 2.4229922329273754

Epoch: 584| Step: 0
Training loss: 0.1825707218397864
Validation loss: 2.449340128564604

Epoch: 6| Step: 1
Training loss: 0.13596201324870266
Validation loss: 2.405497492561774

Epoch: 6| Step: 2
Training loss: 0.14480822031729765
Validation loss: 2.4565276220877985

Epoch: 6| Step: 3
Training loss: 0.21825980712599663
Validation loss: 2.4112783374708706

Epoch: 6| Step: 4
Training loss: 0.10549979282874064
Validation loss: 2.422589547888502

Epoch: 6| Step: 5
Training loss: 0.1330712266679067
Validation loss: 2.4407547937962315

Epoch: 6| Step: 6
Training loss: 0.19851618655987444
Validation loss: 2.440335158611099

Epoch: 6| Step: 7
Training loss: 0.12677296546448044
Validation loss: 2.475561457557818

Epoch: 6| Step: 8
Training loss: 0.17865903548864487
Validation loss: 2.4618096955412274

Epoch: 6| Step: 9
Training loss: 0.17978820881072943
Validation loss: 2.4407871306297433

Epoch: 6| Step: 10
Training loss: 0.10538266342042815
Validation loss: 2.4649978219532502

Epoch: 6| Step: 11
Training loss: 0.1521006625462008
Validation loss: 2.438831041126243

Epoch: 6| Step: 12
Training loss: 0.2060624433025066
Validation loss: 2.4327581257474638

Epoch: 6| Step: 13
Training loss: 0.09888240186960609
Validation loss: 2.46684882492745

Epoch: 585| Step: 0
Training loss: 0.17047202181451654
Validation loss: 2.4538346008811738

Epoch: 6| Step: 1
Training loss: 0.1530775164434102
Validation loss: 2.4678417335159817

Epoch: 6| Step: 2
Training loss: 0.13005179691499583
Validation loss: 2.4786653750367593

Epoch: 6| Step: 3
Training loss: 0.13651795628668012
Validation loss: 2.4773540541976433

Epoch: 6| Step: 4
Training loss: 0.31916757981059335
Validation loss: 2.485295716451702

Epoch: 6| Step: 5
Training loss: 0.15445807040473178
Validation loss: 2.5087452910947388

Epoch: 6| Step: 6
Training loss: 0.15498128432868719
Validation loss: 2.4900273199057437

Epoch: 6| Step: 7
Training loss: 0.1617580824395815
Validation loss: 2.5130788515970166

Epoch: 6| Step: 8
Training loss: 0.18616342002696637
Validation loss: 2.4735934564308817

Epoch: 6| Step: 9
Training loss: 0.14014412199130166
Validation loss: 2.4545402663743934

Epoch: 6| Step: 10
Training loss: 0.1489531382463986
Validation loss: 2.4710572586502693

Epoch: 6| Step: 11
Training loss: 0.1528908491449755
Validation loss: 2.4499617655233648

Epoch: 6| Step: 12
Training loss: 0.11662058395557975
Validation loss: 2.45885193076874

Epoch: 6| Step: 13
Training loss: 0.1578701010949744
Validation loss: 2.473454841885319

Epoch: 586| Step: 0
Training loss: 0.14072880622296183
Validation loss: 2.467096268363118

Epoch: 6| Step: 1
Training loss: 0.1729385135725709
Validation loss: 2.46098050550161

Epoch: 6| Step: 2
Training loss: 0.23874831154111417
Validation loss: 2.470937262290643

Epoch: 6| Step: 3
Training loss: 0.13217357210412944
Validation loss: 2.48066872806466

Epoch: 6| Step: 4
Training loss: 0.1377737349530506
Validation loss: 2.456483553972577

Epoch: 6| Step: 5
Training loss: 0.1505193840328872
Validation loss: 2.492827753018662

Epoch: 6| Step: 6
Training loss: 0.1884641791510324
Validation loss: 2.485317114280563

Epoch: 6| Step: 7
Training loss: 0.1260944302976614
Validation loss: 2.492218149059532

Epoch: 6| Step: 8
Training loss: 0.17674189964870946
Validation loss: 2.469063610813628

Epoch: 6| Step: 9
Training loss: 0.10379212716272394
Validation loss: 2.5009250877661273

Epoch: 6| Step: 10
Training loss: 0.13559202766863132
Validation loss: 2.5044689254308103

Epoch: 6| Step: 11
Training loss: 0.18079010973876336
Validation loss: 2.477320264693574

Epoch: 6| Step: 12
Training loss: 0.13580482739132632
Validation loss: 2.518192616298506

Epoch: 6| Step: 13
Training loss: 0.10663064082011758
Validation loss: 2.524038937217899

Epoch: 587| Step: 0
Training loss: 0.1091388938386954
Validation loss: 2.5200845899169644

Epoch: 6| Step: 1
Training loss: 0.1718576812688425
Validation loss: 2.5246019007542024

Epoch: 6| Step: 2
Training loss: 0.12609323377397225
Validation loss: 2.5161115914217027

Epoch: 6| Step: 3
Training loss: 0.11641978882776521
Validation loss: 2.497565519770173

Epoch: 6| Step: 4
Training loss: 0.15724497148300234
Validation loss: 2.4933953801757474

Epoch: 6| Step: 5
Training loss: 0.08804730648791403
Validation loss: 2.5128596530500076

Epoch: 6| Step: 6
Training loss: 0.13872296104218282
Validation loss: 2.483509763600464

Epoch: 6| Step: 7
Training loss: 0.19162204800127977
Validation loss: 2.493369610954474

Epoch: 6| Step: 8
Training loss: 0.10669830425218993
Validation loss: 2.496324553837289

Epoch: 6| Step: 9
Training loss: 0.13673586738241916
Validation loss: 2.4669214634083794

Epoch: 6| Step: 10
Training loss: 0.11790520712459263
Validation loss: 2.471735174278639

Epoch: 6| Step: 11
Training loss: 0.11596617045986243
Validation loss: 2.4663036069132294

Epoch: 6| Step: 12
Training loss: 0.17093800222996047
Validation loss: 2.481569106591304

Epoch: 6| Step: 13
Training loss: 0.13859545254011033
Validation loss: 2.4656778173821254

Epoch: 588| Step: 0
Training loss: 0.08836965617884089
Validation loss: 2.4410605959108658

Epoch: 6| Step: 1
Training loss: 0.08853621208929682
Validation loss: 2.4364767298421084

Epoch: 6| Step: 2
Training loss: 0.14183395652259603
Validation loss: 2.464584353317965

Epoch: 6| Step: 3
Training loss: 0.17676865560246327
Validation loss: 2.466030452143871

Epoch: 6| Step: 4
Training loss: 0.16929063069895608
Validation loss: 2.452490360874571

Epoch: 6| Step: 5
Training loss: 0.1351037827674786
Validation loss: 2.4794316352287633

Epoch: 6| Step: 6
Training loss: 0.13251336855744505
Validation loss: 2.4498628530650164

Epoch: 6| Step: 7
Training loss: 0.12375016782007495
Validation loss: 2.4548947323086385

Epoch: 6| Step: 8
Training loss: 0.1501474209888057
Validation loss: 2.464253254644837

Epoch: 6| Step: 9
Training loss: 0.10841788297940838
Validation loss: 2.5025990916667813

Epoch: 6| Step: 10
Training loss: 0.11175017915141704
Validation loss: 2.4912990092494334

Epoch: 6| Step: 11
Training loss: 0.14497446715060802
Validation loss: 2.5187294734475785

Epoch: 6| Step: 12
Training loss: 0.13099363186787827
Validation loss: 2.5004216751189086

Epoch: 6| Step: 13
Training loss: 0.17986341862710045
Validation loss: 2.482630102400823

Epoch: 589| Step: 0
Training loss: 0.13574167978754392
Validation loss: 2.515277671186194

Epoch: 6| Step: 1
Training loss: 0.13033038300224153
Validation loss: 2.497756815066249

Epoch: 6| Step: 2
Training loss: 0.22895916662391408
Validation loss: 2.497077671583525

Epoch: 6| Step: 3
Training loss: 0.14367520210765658
Validation loss: 2.527605606072978

Epoch: 6| Step: 4
Training loss: 0.11627182847862616
Validation loss: 2.500982953715007

Epoch: 6| Step: 5
Training loss: 0.1607083828538392
Validation loss: 2.486606792723904

Epoch: 6| Step: 6
Training loss: 0.09138898319602984
Validation loss: 2.493121787990689

Epoch: 6| Step: 7
Training loss: 0.08980589566739289
Validation loss: 2.4666781087503007

Epoch: 6| Step: 8
Training loss: 0.17499359408643156
Validation loss: 2.4833936166008614

Epoch: 6| Step: 9
Training loss: 0.14376141461373193
Validation loss: 2.472996501033239

Epoch: 6| Step: 10
Training loss: 0.11944254937519892
Validation loss: 2.4795385110983776

Epoch: 6| Step: 11
Training loss: 0.07105639453554985
Validation loss: 2.4868489940979654

Epoch: 6| Step: 12
Training loss: 0.11412819822134669
Validation loss: 2.469870658117827

Epoch: 6| Step: 13
Training loss: 0.07920999512458461
Validation loss: 2.4852485516607037

Epoch: 590| Step: 0
Training loss: 0.1547203349415795
Validation loss: 2.494663299362062

Epoch: 6| Step: 1
Training loss: 0.11014382887536944
Validation loss: 2.4608948844036425

Epoch: 6| Step: 2
Training loss: 0.12330149237809726
Validation loss: 2.48693639873851

Epoch: 6| Step: 3
Training loss: 0.16516673775668816
Validation loss: 2.501723880564336

Epoch: 6| Step: 4
Training loss: 0.11273091330735208
Validation loss: 2.4877014180022052

Epoch: 6| Step: 5
Training loss: 0.17742282684084285
Validation loss: 2.4706054647446445

Epoch: 6| Step: 6
Training loss: 0.11066159018364768
Validation loss: 2.502626498592661

Epoch: 6| Step: 7
Training loss: 0.10760155302875964
Validation loss: 2.4811296079570715

Epoch: 6| Step: 8
Training loss: 0.07543603957270895
Validation loss: 2.4905895894597454

Epoch: 6| Step: 9
Training loss: 0.1426047274188638
Validation loss: 2.4630548861317623

Epoch: 6| Step: 10
Training loss: 0.1333644700822938
Validation loss: 2.474396877484224

Epoch: 6| Step: 11
Training loss: 0.1677370469369561
Validation loss: 2.4814764692571223

Epoch: 6| Step: 12
Training loss: 0.15764519538345334
Validation loss: 2.4429654610241003

Epoch: 6| Step: 13
Training loss: 0.21374558776071664
Validation loss: 2.4310410829036058

Epoch: 591| Step: 0
Training loss: 0.11620571220895988
Validation loss: 2.480207707747228

Epoch: 6| Step: 1
Training loss: 0.13026865674444568
Validation loss: 2.477823160374146

Epoch: 6| Step: 2
Training loss: 0.10473092160798039
Validation loss: 2.4530962128573575

Epoch: 6| Step: 3
Training loss: 0.09968203344274608
Validation loss: 2.48508555891851

Epoch: 6| Step: 4
Training loss: 0.13918664914304898
Validation loss: 2.458285108781204

Epoch: 6| Step: 5
Training loss: 0.08621040815079394
Validation loss: 2.474105633342783

Epoch: 6| Step: 6
Training loss: 0.12360334964321217
Validation loss: 2.474551279785096

Epoch: 6| Step: 7
Training loss: 0.1916170419239924
Validation loss: 2.5070259926640173

Epoch: 6| Step: 8
Training loss: 0.12303951407925016
Validation loss: 2.489024738884091

Epoch: 6| Step: 9
Training loss: 0.17319353403147691
Validation loss: 2.451064159165867

Epoch: 6| Step: 10
Training loss: 0.08249018502823845
Validation loss: 2.4320630943317787

Epoch: 6| Step: 11
Training loss: 0.11197472903603611
Validation loss: 2.441752972271496

Epoch: 6| Step: 12
Training loss: 0.12794621921331462
Validation loss: 2.4293005734490327

Epoch: 6| Step: 13
Training loss: 0.0821247958221757
Validation loss: 2.4595396448096776

Epoch: 592| Step: 0
Training loss: 0.08156192011097228
Validation loss: 2.437214720833261

Epoch: 6| Step: 1
Training loss: 0.13967583127536576
Validation loss: 2.432089136289644

Epoch: 6| Step: 2
Training loss: 0.12818600551342238
Validation loss: 2.4328493135720137

Epoch: 6| Step: 3
Training loss: 0.1280436481420682
Validation loss: 2.4396059726682444

Epoch: 6| Step: 4
Training loss: 0.15151933591227648
Validation loss: 2.4162602413487915

Epoch: 6| Step: 5
Training loss: 0.0979162807363994
Validation loss: 2.4565786161961842

Epoch: 6| Step: 6
Training loss: 0.14548311087856305
Validation loss: 2.429056827574548

Epoch: 6| Step: 7
Training loss: 0.12006950595055395
Validation loss: 2.473265487637681

Epoch: 6| Step: 8
Training loss: 0.1546632545428121
Validation loss: 2.4863113871776283

Epoch: 6| Step: 9
Training loss: 0.11929250245115741
Validation loss: 2.4742271856691724

Epoch: 6| Step: 10
Training loss: 0.11138879645301282
Validation loss: 2.455073649731879

Epoch: 6| Step: 11
Training loss: 0.11700673068663915
Validation loss: 2.454427032501167

Epoch: 6| Step: 12
Training loss: 0.15351368318062483
Validation loss: 2.4722343810309693

Epoch: 6| Step: 13
Training loss: 0.10017402805810532
Validation loss: 2.459644488002078

Epoch: 593| Step: 0
Training loss: 0.11764191896109755
Validation loss: 2.4421439777109093

Epoch: 6| Step: 1
Training loss: 0.15299554310607344
Validation loss: 2.4448959272009

Epoch: 6| Step: 2
Training loss: 0.11893755381668646
Validation loss: 2.4585629514644567

Epoch: 6| Step: 3
Training loss: 0.09944429930776848
Validation loss: 2.4482003394301843

Epoch: 6| Step: 4
Training loss: 0.15911457859877992
Validation loss: 2.4162558042625877

Epoch: 6| Step: 5
Training loss: 0.09427419778535141
Validation loss: 2.4405521271388024

Epoch: 6| Step: 6
Training loss: 0.18973045107944747
Validation loss: 2.4313760527111743

Epoch: 6| Step: 7
Training loss: 0.10329817478860695
Validation loss: 2.465244686843035

Epoch: 6| Step: 8
Training loss: 0.14230017808569959
Validation loss: 2.4680446761035824

Epoch: 6| Step: 9
Training loss: 0.12549578425319702
Validation loss: 2.46537765904506

Epoch: 6| Step: 10
Training loss: 0.11814004086427102
Validation loss: 2.463376724419605

Epoch: 6| Step: 11
Training loss: 0.14598667152645606
Validation loss: 2.4621594217388822

Epoch: 6| Step: 12
Training loss: 0.14209100388515392
Validation loss: 2.46191744574673

Epoch: 6| Step: 13
Training loss: 0.08994153133553454
Validation loss: 2.485070438039955

Epoch: 594| Step: 0
Training loss: 0.12594509471020013
Validation loss: 2.5069853467296217

Epoch: 6| Step: 1
Training loss: 0.08191105574663768
Validation loss: 2.509670392925339

Epoch: 6| Step: 2
Training loss: 0.17770286951538922
Validation loss: 2.494008995150256

Epoch: 6| Step: 3
Training loss: 0.177849826414674
Validation loss: 2.4713841823345404

Epoch: 6| Step: 4
Training loss: 0.18259444069588918
Validation loss: 2.5141630291987838

Epoch: 6| Step: 5
Training loss: 0.1232380214899902
Validation loss: 2.484856256890926

Epoch: 6| Step: 6
Training loss: 0.08874581505922143
Validation loss: 2.4724700105401323

Epoch: 6| Step: 7
Training loss: 0.0908654162480517
Validation loss: 2.4693033416805927

Epoch: 6| Step: 8
Training loss: 0.1639159206268517
Validation loss: 2.4725526770731285

Epoch: 6| Step: 9
Training loss: 0.10814065179795561
Validation loss: 2.4620881442422284

Epoch: 6| Step: 10
Training loss: 0.09859572553695788
Validation loss: 2.443672740369499

Epoch: 6| Step: 11
Training loss: 0.12183365579066459
Validation loss: 2.481256983383426

Epoch: 6| Step: 12
Training loss: 0.14453209412817988
Validation loss: 2.5048958554060543

Epoch: 6| Step: 13
Training loss: 0.15326484964769427
Validation loss: 2.487927915213579

Epoch: 595| Step: 0
Training loss: 0.097583505239357
Validation loss: 2.4619523286342084

Epoch: 6| Step: 1
Training loss: 0.15058302029209641
Validation loss: 2.496747592072484

Epoch: 6| Step: 2
Training loss: 0.10034827979462577
Validation loss: 2.4742115544429786

Epoch: 6| Step: 3
Training loss: 0.1362826749792304
Validation loss: 2.4938761165602457

Epoch: 6| Step: 4
Training loss: 0.14746343850547497
Validation loss: 2.4899568380963975

Epoch: 6| Step: 5
Training loss: 0.12669115179921586
Validation loss: 2.475434190889169

Epoch: 6| Step: 6
Training loss: 0.12517228770280267
Validation loss: 2.4611764380682564

Epoch: 6| Step: 7
Training loss: 0.14786151766804256
Validation loss: 2.491432847444562

Epoch: 6| Step: 8
Training loss: 0.15788154531586945
Validation loss: 2.482371341550527

Epoch: 6| Step: 9
Training loss: 0.10172514546705745
Validation loss: 2.5150959210352206

Epoch: 6| Step: 10
Training loss: 0.1311710900992652
Validation loss: 2.5252415707488254

Epoch: 6| Step: 11
Training loss: 0.15918780815145608
Validation loss: 2.5093913502809815

Epoch: 6| Step: 12
Training loss: 0.152062676417103
Validation loss: 2.5262594538686094

Epoch: 6| Step: 13
Training loss: 0.15312990282928968
Validation loss: 2.5001238823007053

Epoch: 596| Step: 0
Training loss: 0.0706511791413982
Validation loss: 2.515128241853649

Epoch: 6| Step: 1
Training loss: 0.1492846558110279
Validation loss: 2.4835440139227254

Epoch: 6| Step: 2
Training loss: 0.11312923837725411
Validation loss: 2.474548605343903

Epoch: 6| Step: 3
Training loss: 0.10350089598178044
Validation loss: 2.5209651554238133

Epoch: 6| Step: 4
Training loss: 0.13645626483931658
Validation loss: 2.508941900051473

Epoch: 6| Step: 5
Training loss: 0.11205009960268437
Validation loss: 2.4808972375617873

Epoch: 6| Step: 6
Training loss: 0.10135762016996633
Validation loss: 2.4805819593373055

Epoch: 6| Step: 7
Training loss: 0.1073585670495198
Validation loss: 2.4857211751761734

Epoch: 6| Step: 8
Training loss: 0.1402356001606502
Validation loss: 2.4970292242272816

Epoch: 6| Step: 9
Training loss: 0.09336870358359531
Validation loss: 2.501014515929617

Epoch: 6| Step: 10
Training loss: 0.1355718875420466
Validation loss: 2.472972765699344

Epoch: 6| Step: 11
Training loss: 0.08847570650473988
Validation loss: 2.4649324653531415

Epoch: 6| Step: 12
Training loss: 0.17008828093836642
Validation loss: 2.4698606749450716

Epoch: 6| Step: 13
Training loss: 0.09982485464778353
Validation loss: 2.4777875785304864

Epoch: 597| Step: 0
Training loss: 0.1293667817500186
Validation loss: 2.5148089091551387

Epoch: 6| Step: 1
Training loss: 0.12046462108844196
Validation loss: 2.4689884633973733

Epoch: 6| Step: 2
Training loss: 0.12322242641865908
Validation loss: 2.476041362258427

Epoch: 6| Step: 3
Training loss: 0.14786794211440518
Validation loss: 2.4717660582710206

Epoch: 6| Step: 4
Training loss: 0.0965805605167925
Validation loss: 2.516906452787767

Epoch: 6| Step: 5
Training loss: 0.18660789095708438
Validation loss: 2.491854438355859

Epoch: 6| Step: 6
Training loss: 0.13146550447136152
Validation loss: 2.529040194535427

Epoch: 6| Step: 7
Training loss: 0.1432727913455297
Validation loss: 2.485978230237027

Epoch: 6| Step: 8
Training loss: 0.1344508420028899
Validation loss: 2.489719051643981

Epoch: 6| Step: 9
Training loss: 0.08030814188699234
Validation loss: 2.470485622850721

Epoch: 6| Step: 10
Training loss: 0.14395892390747864
Validation loss: 2.45952968328569

Epoch: 6| Step: 11
Training loss: 0.1061866794212635
Validation loss: 2.4786131261457065

Epoch: 6| Step: 12
Training loss: 0.1209581022986655
Validation loss: 2.4734174377810594

Epoch: 6| Step: 13
Training loss: 0.12413779940909482
Validation loss: 2.4518565000799777

Epoch: 598| Step: 0
Training loss: 0.12488427616821178
Validation loss: 2.469309338339683

Epoch: 6| Step: 1
Training loss: 0.14372526790531223
Validation loss: 2.458832148075652

Epoch: 6| Step: 2
Training loss: 0.14521387352584028
Validation loss: 2.4880057085250233

Epoch: 6| Step: 3
Training loss: 0.16642507661514272
Validation loss: 2.4477093680602127

Epoch: 6| Step: 4
Training loss: 0.13324279362281485
Validation loss: 2.4404685489214333

Epoch: 6| Step: 5
Training loss: 0.13353420960806497
Validation loss: 2.4789233851396206

Epoch: 6| Step: 6
Training loss: 0.14953976373740746
Validation loss: 2.504227648637094

Epoch: 6| Step: 7
Training loss: 0.13839313538914497
Validation loss: 2.4634311077742037

Epoch: 6| Step: 8
Training loss: 0.1217412021604187
Validation loss: 2.458585682037144

Epoch: 6| Step: 9
Training loss: 0.10379592714159722
Validation loss: 2.484973447653741

Epoch: 6| Step: 10
Training loss: 0.07975692412944438
Validation loss: 2.48644030354918

Epoch: 6| Step: 11
Training loss: 0.12640386016859387
Validation loss: 2.482780173216243

Epoch: 6| Step: 12
Training loss: 0.09134330701639021
Validation loss: 2.474605163746234

Epoch: 6| Step: 13
Training loss: 0.08282471827575112
Validation loss: 2.4985016526841664

Epoch: 599| Step: 0
Training loss: 0.14141534201756156
Validation loss: 2.489813008120831

Epoch: 6| Step: 1
Training loss: 0.08868231249814043
Validation loss: 2.4635507007245834

Epoch: 6| Step: 2
Training loss: 0.11270454788711294
Validation loss: 2.4807549972029723

Epoch: 6| Step: 3
Training loss: 0.1376033232194038
Validation loss: 2.429817375872051

Epoch: 6| Step: 4
Training loss: 0.1392128426382762
Validation loss: 2.468690070051437

Epoch: 6| Step: 5
Training loss: 0.14731038852605907
Validation loss: 2.427950664531218

Epoch: 6| Step: 6
Training loss: 0.0907034994375565
Validation loss: 2.4466050910936934

Epoch: 6| Step: 7
Training loss: 0.16664757221832974
Validation loss: 2.475291369392775

Epoch: 6| Step: 8
Training loss: 0.1172999398905957
Validation loss: 2.436378704900662

Epoch: 6| Step: 9
Training loss: 0.13367976994166647
Validation loss: 2.4494072560815257

Epoch: 6| Step: 10
Training loss: 0.11203464300079906
Validation loss: 2.4455606580433855

Epoch: 6| Step: 11
Training loss: 0.08919917962574796
Validation loss: 2.4629381263429444

Epoch: 6| Step: 12
Training loss: 0.08049966185991872
Validation loss: 2.4690423254731733

Epoch: 6| Step: 13
Training loss: 0.11927504460911226
Validation loss: 2.464855218962087

Epoch: 600| Step: 0
Training loss: 0.06265660870894113
Validation loss: 2.4576539624635143

Epoch: 6| Step: 1
Training loss: 0.09759284345216168
Validation loss: 2.4523068122949048

Epoch: 6| Step: 2
Training loss: 0.11521114907336143
Validation loss: 2.480778238517765

Epoch: 6| Step: 3
Training loss: 0.133055009744431
Validation loss: 2.4420019707506975

Epoch: 6| Step: 4
Training loss: 0.14077319178238795
Validation loss: 2.457557142374884

Epoch: 6| Step: 5
Training loss: 0.09047338406317945
Validation loss: 2.4377050384535925

Epoch: 6| Step: 6
Training loss: 0.13115523470762164
Validation loss: 2.447086104482561

Epoch: 6| Step: 7
Training loss: 0.0952430096561774
Validation loss: 2.4822702478113836

Epoch: 6| Step: 8
Training loss: 0.11406277042513628
Validation loss: 2.4752850801422532

Epoch: 6| Step: 9
Training loss: 0.09393337316642228
Validation loss: 2.434486175095844

Epoch: 6| Step: 10
Training loss: 0.07948718148948448
Validation loss: 2.4599456220616585

Epoch: 6| Step: 11
Training loss: 0.1261410341864557
Validation loss: 2.4284993494527285

Epoch: 6| Step: 12
Training loss: 0.0920862193117452
Validation loss: 2.4471385870361875

Epoch: 6| Step: 13
Training loss: 0.10377086804399649
Validation loss: 2.4788733569354107

Testing loss: 2.840680007206137
