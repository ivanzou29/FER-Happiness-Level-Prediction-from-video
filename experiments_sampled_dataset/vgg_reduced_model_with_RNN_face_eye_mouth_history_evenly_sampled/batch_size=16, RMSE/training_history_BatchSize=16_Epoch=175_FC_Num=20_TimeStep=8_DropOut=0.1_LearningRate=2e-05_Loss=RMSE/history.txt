Epoch: 1| Step: 0
Training loss: 5.673404876102498
Validation loss: 5.730701429646471

Epoch: 6| Step: 1
Training loss: 5.385803012037542
Validation loss: 5.711885563041254

Epoch: 6| Step: 2
Training loss: 5.440705505511677
Validation loss: 5.695165856010948

Epoch: 6| Step: 3
Training loss: 6.823030784370876
Validation loss: 5.6791700330632535

Epoch: 6| Step: 4
Training loss: 4.402749260383185
Validation loss: 5.661601480462073

Epoch: 6| Step: 5
Training loss: 5.6234603470117985
Validation loss: 5.64167355535343

Epoch: 6| Step: 6
Training loss: 5.899273662794019
Validation loss: 5.618824909794072

Epoch: 6| Step: 7
Training loss: 6.132668501991794
Validation loss: 5.592905127065096

Epoch: 6| Step: 8
Training loss: 4.8805189926079615
Validation loss: 5.562739738671026

Epoch: 6| Step: 9
Training loss: 6.087775015444631
Validation loss: 5.52801328127745

Epoch: 6| Step: 10
Training loss: 5.42208149541483
Validation loss: 5.488305952681966

Epoch: 6| Step: 11
Training loss: 5.447781368445223
Validation loss: 5.443576516428545

Epoch: 6| Step: 12
Training loss: 5.951180528484848
Validation loss: 5.395370816427534

Epoch: 6| Step: 13
Training loss: 4.7720132004586455
Validation loss: 5.342057866955118

Epoch: 2| Step: 0
Training loss: 4.3051578105574375
Validation loss: 5.287107637171464

Epoch: 6| Step: 1
Training loss: 5.303549373373509
Validation loss: 5.230053427618285

Epoch: 6| Step: 2
Training loss: 4.762916670867027
Validation loss: 5.171156879451911

Epoch: 6| Step: 3
Training loss: 5.535912396801766
Validation loss: 5.107270863867776

Epoch: 6| Step: 4
Training loss: 6.052943297156661
Validation loss: 5.04276918854701

Epoch: 6| Step: 5
Training loss: 4.451699975871116
Validation loss: 4.976021537626791

Epoch: 6| Step: 6
Training loss: 4.646532812904315
Validation loss: 4.914328135616423

Epoch: 6| Step: 7
Training loss: 5.787616585201951
Validation loss: 4.853284471603491

Epoch: 6| Step: 8
Training loss: 3.8322880743448327
Validation loss: 4.798100266811716

Epoch: 6| Step: 9
Training loss: 4.5672016739992385
Validation loss: 4.742863763392247

Epoch: 6| Step: 10
Training loss: 4.783774513518734
Validation loss: 4.692959886739182

Epoch: 6| Step: 11
Training loss: 5.388385694591355
Validation loss: 4.647142167514104

Epoch: 6| Step: 12
Training loss: 4.479945530560289
Validation loss: 4.605198679313874

Epoch: 6| Step: 13
Training loss: 5.689743773150208
Validation loss: 4.565257445152693

Epoch: 3| Step: 0
Training loss: 5.5041893696034006
Validation loss: 4.534515931745646

Epoch: 6| Step: 1
Training loss: 4.41658701315015
Validation loss: 4.503555194662821

Epoch: 6| Step: 2
Training loss: 5.363390783204164
Validation loss: 4.479121804304835

Epoch: 6| Step: 3
Training loss: 3.152535396077727
Validation loss: 4.460501967503695

Epoch: 6| Step: 4
Training loss: 4.762375621222794
Validation loss: 4.448761919655643

Epoch: 6| Step: 5
Training loss: 4.545006646716941
Validation loss: 4.429773770885005

Epoch: 6| Step: 6
Training loss: 4.306189522505408
Validation loss: 4.403809770549295

Epoch: 6| Step: 7
Training loss: 3.6270009799279674
Validation loss: 4.387975814976436

Epoch: 6| Step: 8
Training loss: 5.487817276317785
Validation loss: 4.393709297197611

Epoch: 6| Step: 9
Training loss: 4.9367644329465685
Validation loss: 4.352246024514411

Epoch: 6| Step: 10
Training loss: 4.214062156012454
Validation loss: 4.337961646973946

Epoch: 6| Step: 11
Training loss: 4.070876186825976
Validation loss: 4.325236550379542

Epoch: 6| Step: 12
Training loss: 3.77319259322673
Validation loss: 4.313568092347244

Epoch: 6| Step: 13
Training loss: 4.651831661967068
Validation loss: 4.297668541266248

Epoch: 4| Step: 0
Training loss: 4.134698736616505
Validation loss: 4.274249780323319

Epoch: 6| Step: 1
Training loss: 3.426337967877248
Validation loss: 4.253019528179249

Epoch: 6| Step: 2
Training loss: 4.852679678387515
Validation loss: 4.236931355100965

Epoch: 6| Step: 3
Training loss: 4.301341783408442
Validation loss: 4.219919082984786

Epoch: 6| Step: 4
Training loss: 4.572092710514523
Validation loss: 4.1983447833569185

Epoch: 6| Step: 5
Training loss: 5.05711549346639
Validation loss: 4.169641127499882

Epoch: 6| Step: 6
Training loss: 3.9198428052407728
Validation loss: 4.1404654783453045

Epoch: 6| Step: 7
Training loss: 4.003388638417454
Validation loss: 4.124539837817927

Epoch: 6| Step: 8
Training loss: 3.759445121282406
Validation loss: 4.109404495603164

Epoch: 6| Step: 9
Training loss: 4.2851262052416415
Validation loss: 4.0983089289037675

Epoch: 6| Step: 10
Training loss: 4.876112590888713
Validation loss: 4.093718765892367

Epoch: 6| Step: 11
Training loss: 4.26139873698257
Validation loss: 4.079978736863857

Epoch: 6| Step: 12
Training loss: 4.421724458430138
Validation loss: 4.061280855642181

Epoch: 6| Step: 13
Training loss: 3.37489459968159
Validation loss: 4.047839867343783

Epoch: 5| Step: 0
Training loss: 4.451945901670568
Validation loss: 4.034371606801161

Epoch: 6| Step: 1
Training loss: 4.96190550964255
Validation loss: 4.02526182539506

Epoch: 6| Step: 2
Training loss: 4.311609590907356
Validation loss: 4.010661710943183

Epoch: 6| Step: 3
Training loss: 3.983525563367388
Validation loss: 4.018819539404902

Epoch: 6| Step: 4
Training loss: 3.7573219026653843
Validation loss: 4.008281840277472

Epoch: 6| Step: 5
Training loss: 4.966240591083008
Validation loss: 3.9854806188416716

Epoch: 6| Step: 6
Training loss: 3.985305976560224
Validation loss: 3.957451797448945

Epoch: 6| Step: 7
Training loss: 3.7746491629157517
Validation loss: 3.946825342493821

Epoch: 6| Step: 8
Training loss: 4.140926709968915
Validation loss: 3.9499373211241986

Epoch: 6| Step: 9
Training loss: 3.729459839845642
Validation loss: 3.9257839195729303

Epoch: 6| Step: 10
Training loss: 4.220310854920311
Validation loss: 3.918873388908999

Epoch: 6| Step: 11
Training loss: 3.2130817762286137
Validation loss: 3.9143882810578794

Epoch: 6| Step: 12
Training loss: 4.0750391016295255
Validation loss: 3.9092164711574986

Epoch: 6| Step: 13
Training loss: 3.5733211870366617
Validation loss: 3.900815340126146

Epoch: 6| Step: 0
Training loss: 3.7772985572044457
Validation loss: 3.8836350385877587

Epoch: 6| Step: 1
Training loss: 3.9864900846722833
Validation loss: 3.8664766823669043

Epoch: 6| Step: 2
Training loss: 3.2159583568628762
Validation loss: 3.8505284217232205

Epoch: 6| Step: 3
Training loss: 3.051638122652884
Validation loss: 3.8366786600913336

Epoch: 6| Step: 4
Training loss: 4.608705012880728
Validation loss: 3.8438640117035345

Epoch: 6| Step: 5
Training loss: 2.4386644760769944
Validation loss: 3.8194735593360405

Epoch: 6| Step: 6
Training loss: 4.981887435811422
Validation loss: 3.8123238581853602

Epoch: 6| Step: 7
Training loss: 4.064764712047506
Validation loss: 3.8063377582686937

Epoch: 6| Step: 8
Training loss: 3.9899353721948922
Validation loss: 3.7977968001149427

Epoch: 6| Step: 9
Training loss: 3.6385159256872153
Validation loss: 3.7859282510656738

Epoch: 6| Step: 10
Training loss: 4.307559735752389
Validation loss: 3.779312503874911

Epoch: 6| Step: 11
Training loss: 4.38259033075214
Validation loss: 3.764798250916691

Epoch: 6| Step: 12
Training loss: 4.354051847023904
Validation loss: 3.758618188755991

Epoch: 6| Step: 13
Training loss: 4.427070934801878
Validation loss: 3.749964871806024

Epoch: 7| Step: 0
Training loss: 4.525657412156496
Validation loss: 3.7490446316201718

Epoch: 6| Step: 1
Training loss: 3.1810793068289653
Validation loss: 3.739808645849507

Epoch: 6| Step: 2
Training loss: 2.956020489870739
Validation loss: 3.7353850972407994

Epoch: 6| Step: 3
Training loss: 4.3382212630070685
Validation loss: 3.727023474656512

Epoch: 6| Step: 4
Training loss: 3.8577765115856937
Validation loss: 3.7130090857155187

Epoch: 6| Step: 5
Training loss: 4.344175688378524
Validation loss: 3.703080874484292

Epoch: 6| Step: 6
Training loss: 2.809896578124298
Validation loss: 3.703706700404697

Epoch: 6| Step: 7
Training loss: 3.3014812381851977
Validation loss: 3.705905663504007

Epoch: 6| Step: 8
Training loss: 4.16945712427669
Validation loss: 3.6939487566277704

Epoch: 6| Step: 9
Training loss: 3.4800873107480634
Validation loss: 3.686514244184934

Epoch: 6| Step: 10
Training loss: 4.773920562326147
Validation loss: 3.6959592684252343

Epoch: 6| Step: 11
Training loss: 4.215012767043865
Validation loss: 3.6793983718095014

Epoch: 6| Step: 12
Training loss: 3.6147108394475795
Validation loss: 3.667924121872322

Epoch: 6| Step: 13
Training loss: 4.5227282137671585
Validation loss: 3.651207297997678

Epoch: 8| Step: 0
Training loss: 3.6513341477259527
Validation loss: 3.642610921857527

Epoch: 6| Step: 1
Training loss: 3.7700442898928794
Validation loss: 3.6525772526342126

Epoch: 6| Step: 2
Training loss: 4.694841459642355
Validation loss: 3.6409204447565346

Epoch: 6| Step: 3
Training loss: 3.632190150614663
Validation loss: 3.627543838654573

Epoch: 6| Step: 4
Training loss: 3.5478737387054657
Validation loss: 3.6256383490113273

Epoch: 6| Step: 5
Training loss: 3.504353676491773
Validation loss: 3.6281897033702997

Epoch: 6| Step: 6
Training loss: 3.560209106561901
Validation loss: 3.623804930065206

Epoch: 6| Step: 7
Training loss: 3.9068114830838034
Validation loss: 3.614669885769669

Epoch: 6| Step: 8
Training loss: 3.265587911440853
Validation loss: 3.6024752352690257

Epoch: 6| Step: 9
Training loss: 4.193358920150185
Validation loss: 3.593302754825247

Epoch: 6| Step: 10
Training loss: 2.935425533139601
Validation loss: 3.5857984742122655

Epoch: 6| Step: 11
Training loss: 4.0931009258518145
Validation loss: 3.5800210625872237

Epoch: 6| Step: 12
Training loss: 4.416986034050821
Validation loss: 3.576727028420069

Epoch: 6| Step: 13
Training loss: 3.803887943169711
Validation loss: 3.5691111312864887

Epoch: 9| Step: 0
Training loss: 3.5701484892922455
Validation loss: 3.561221318018915

Epoch: 6| Step: 1
Training loss: 2.942111352552012
Validation loss: 3.5502327785638204

Epoch: 6| Step: 2
Training loss: 3.9989372272071932
Validation loss: 3.542325273595317

Epoch: 6| Step: 3
Training loss: 4.547548224564125
Validation loss: 3.536715880870547

Epoch: 6| Step: 4
Training loss: 3.4561607859791534
Validation loss: 3.5290628873406944

Epoch: 6| Step: 5
Training loss: 2.540327490622624
Validation loss: 3.5261724384208595

Epoch: 6| Step: 6
Training loss: 3.7900990749484116
Validation loss: 3.5210887837867144

Epoch: 6| Step: 7
Training loss: 3.427809772586007
Validation loss: 3.5138242394246757

Epoch: 6| Step: 8
Training loss: 2.9855871485082948
Validation loss: 3.5102573179808116

Epoch: 6| Step: 9
Training loss: 4.152421837518344
Validation loss: 3.5044794189451243

Epoch: 6| Step: 10
Training loss: 3.6760802517288544
Validation loss: 3.5003860659171684

Epoch: 6| Step: 11
Training loss: 4.24822063222228
Validation loss: 3.4943588255563616

Epoch: 6| Step: 12
Training loss: 3.9370584391703387
Validation loss: 3.48787459570905

Epoch: 6| Step: 13
Training loss: 4.795009585819468
Validation loss: 3.4812486726580083

Epoch: 10| Step: 0
Training loss: 3.650148697005905
Validation loss: 3.474006502077336

Epoch: 6| Step: 1
Training loss: 3.867534213466506
Validation loss: 3.469025680464674

Epoch: 6| Step: 2
Training loss: 4.65776702950801
Validation loss: 3.4634434297101198

Epoch: 6| Step: 3
Training loss: 3.5300801457716635
Validation loss: 3.4544977642446764

Epoch: 6| Step: 4
Training loss: 3.4267611521250467
Validation loss: 3.4493699361475545

Epoch: 6| Step: 5
Training loss: 4.073356325008688
Validation loss: 3.4446272272822442

Epoch: 6| Step: 6
Training loss: 2.8670068834672566
Validation loss: 3.4374977313171238

Epoch: 6| Step: 7
Training loss: 3.5978223201101134
Validation loss: 3.431893956315254

Epoch: 6| Step: 8
Training loss: 3.953236695170426
Validation loss: 3.4277586057386333

Epoch: 6| Step: 9
Training loss: 3.8876625640340743
Validation loss: 3.421649247583245

Epoch: 6| Step: 10
Training loss: 3.6185442561297125
Validation loss: 3.416062463439863

Epoch: 6| Step: 11
Training loss: 3.2536773417944866
Validation loss: 3.409619648098296

Epoch: 6| Step: 12
Training loss: 3.4171875502346962
Validation loss: 3.4050764546133463

Epoch: 6| Step: 13
Training loss: 2.6864637994334677
Validation loss: 3.3994533229014516

Epoch: 11| Step: 0
Training loss: 4.350967667912139
Validation loss: 3.3994233173169994

Epoch: 6| Step: 1
Training loss: 4.7717729778662905
Validation loss: 3.394934142556195

Epoch: 6| Step: 2
Training loss: 3.6142183645425576
Validation loss: 3.386676235334027

Epoch: 6| Step: 3
Training loss: 3.1373085237109244
Validation loss: 3.3810211890013204

Epoch: 6| Step: 4
Training loss: 3.3950628955166886
Validation loss: 3.375859267013985

Epoch: 6| Step: 5
Training loss: 2.6626751551078134
Validation loss: 3.3724490300683843

Epoch: 6| Step: 6
Training loss: 3.665669623556179
Validation loss: 3.3666287024579056

Epoch: 6| Step: 7
Training loss: 3.1241041806832714
Validation loss: 3.363659042595778

Epoch: 6| Step: 8
Training loss: 2.6961706592132284
Validation loss: 3.3570132906137102

Epoch: 6| Step: 9
Training loss: 3.3746073459107366
Validation loss: 3.354018589043572

Epoch: 6| Step: 10
Training loss: 3.9649545137314592
Validation loss: 3.349084150210152

Epoch: 6| Step: 11
Training loss: 3.6184521435583705
Validation loss: 3.345805334883975

Epoch: 6| Step: 12
Training loss: 3.6194966074757304
Validation loss: 3.343064423520204

Epoch: 6| Step: 13
Training loss: 4.0125281122001235
Validation loss: 3.340350872466291

Epoch: 12| Step: 0
Training loss: 3.3568785861970434
Validation loss: 3.334939026691914

Epoch: 6| Step: 1
Training loss: 3.8375017197198154
Validation loss: 3.3309684552713787

Epoch: 6| Step: 2
Training loss: 3.324799931752532
Validation loss: 3.3254077107201

Epoch: 6| Step: 3
Training loss: 3.3769347685121387
Validation loss: 3.321914333946084

Epoch: 6| Step: 4
Training loss: 3.636085660019845
Validation loss: 3.3173506998242552

Epoch: 6| Step: 5
Training loss: 2.954362236691015
Validation loss: 3.3116694187064706

Epoch: 6| Step: 6
Training loss: 4.059234715387788
Validation loss: 3.3078315312972926

Epoch: 6| Step: 7
Training loss: 4.304590019880849
Validation loss: 3.3041230686033543

Epoch: 6| Step: 8
Training loss: 3.208833399522118
Validation loss: 3.2980397218991255

Epoch: 6| Step: 9
Training loss: 3.8591340642309913
Validation loss: 3.29122300673882

Epoch: 6| Step: 10
Training loss: 3.4841390623945414
Validation loss: 3.283042506389682

Epoch: 6| Step: 11
Training loss: 2.9106962586228295
Validation loss: 3.2804491619618816

Epoch: 6| Step: 12
Training loss: 3.5873302672105507
Validation loss: 3.282420773885074

Epoch: 6| Step: 13
Training loss: 3.500596812999203
Validation loss: 3.271313360033235

Epoch: 13| Step: 0
Training loss: 4.041205127489359
Validation loss: 3.26357180602026

Epoch: 6| Step: 1
Training loss: 3.881166043809404
Validation loss: 3.2615065965140375

Epoch: 6| Step: 2
Training loss: 3.4631310394019654
Validation loss: 3.259902527232263

Epoch: 6| Step: 3
Training loss: 3.222829955072331
Validation loss: 3.255957970849155

Epoch: 6| Step: 4
Training loss: 3.790830974218932
Validation loss: 3.263497415276129

Epoch: 6| Step: 5
Training loss: 3.191953054250189
Validation loss: 3.2665052641103958

Epoch: 6| Step: 6
Training loss: 3.8912849326178685
Validation loss: 3.2597342832688723

Epoch: 6| Step: 7
Training loss: 3.0574760489722665
Validation loss: 3.237655573068666

Epoch: 6| Step: 8
Training loss: 2.7896780836002617
Validation loss: 3.2317906547717845

Epoch: 6| Step: 9
Training loss: 3.7548163955033047
Validation loss: 3.2278224172895276

Epoch: 6| Step: 10
Training loss: 4.114390746168648
Validation loss: 3.2278957622153204

Epoch: 6| Step: 11
Training loss: 2.7076374822848113
Validation loss: 3.225681470582781

Epoch: 6| Step: 12
Training loss: 3.4915523762233103
Validation loss: 3.2206087258225384

Epoch: 6| Step: 13
Training loss: 2.991365245060842
Validation loss: 3.2190674353375615

Epoch: 14| Step: 0
Training loss: 3.421809226322773
Validation loss: 3.214462058055658

Epoch: 6| Step: 1
Training loss: 4.469927012553851
Validation loss: 3.209981751892114

Epoch: 6| Step: 2
Training loss: 3.2891731152995987
Validation loss: 3.2032177295163096

Epoch: 6| Step: 3
Training loss: 3.5557962889105417
Validation loss: 3.200393756872287

Epoch: 6| Step: 4
Training loss: 3.1228396768646163
Validation loss: 3.200717267409911

Epoch: 6| Step: 5
Training loss: 3.950467509356389
Validation loss: 3.199329277600515

Epoch: 6| Step: 6
Training loss: 3.6694390190932116
Validation loss: 3.1897089464459047

Epoch: 6| Step: 7
Training loss: 2.7433185907325437
Validation loss: 3.194478703000517

Epoch: 6| Step: 8
Training loss: 3.7940595572808733
Validation loss: 3.198706993626882

Epoch: 6| Step: 9
Training loss: 2.8639849413470553
Validation loss: 3.1980693594032057

Epoch: 6| Step: 10
Training loss: 3.700251369701065
Validation loss: 3.188943972972988

Epoch: 6| Step: 11
Training loss: 3.505689084478435
Validation loss: 3.1841643395292616

Epoch: 6| Step: 12
Training loss: 2.9781846960115033
Validation loss: 3.1790193922761936

Epoch: 6| Step: 13
Training loss: 2.480023874352503
Validation loss: 3.1742208080716106

Epoch: 15| Step: 0
Training loss: 3.2340297053948
Validation loss: 3.172515518351056

Epoch: 6| Step: 1
Training loss: 3.1583057922397133
Validation loss: 3.169772515110974

Epoch: 6| Step: 2
Training loss: 2.495936333553471
Validation loss: 3.168218627978404

Epoch: 6| Step: 3
Training loss: 3.5958143856275773
Validation loss: 3.1647128736285732

Epoch: 6| Step: 4
Training loss: 4.155767656603751
Validation loss: 3.16223703601351

Epoch: 6| Step: 5
Training loss: 3.3908396006935857
Validation loss: 3.159695066160815

Epoch: 6| Step: 6
Training loss: 3.4109162732318783
Validation loss: 3.1564344995702216

Epoch: 6| Step: 7
Training loss: 3.567664435272056
Validation loss: 3.154989825359186

Epoch: 6| Step: 8
Training loss: 3.234964952706483
Validation loss: 3.1523917101860515

Epoch: 6| Step: 9
Training loss: 3.240725415107779
Validation loss: 3.148185619547726

Epoch: 6| Step: 10
Training loss: 3.984787025839196
Validation loss: 3.1467639486760497

Epoch: 6| Step: 11
Training loss: 3.5037355923637117
Validation loss: 3.1429264242153434

Epoch: 6| Step: 12
Training loss: 2.9784288537565655
Validation loss: 3.139967867044985

Epoch: 6| Step: 13
Training loss: 3.8587445813713424
Validation loss: 3.1381059949155086

Epoch: 16| Step: 0
Training loss: 3.490217843894469
Validation loss: 3.136124586821087

Epoch: 6| Step: 1
Training loss: 3.770214908252146
Validation loss: 3.133765359818294

Epoch: 6| Step: 2
Training loss: 3.6506650606193194
Validation loss: 3.1314611176973086

Epoch: 6| Step: 3
Training loss: 3.66592327442617
Validation loss: 3.1288049040917607

Epoch: 6| Step: 4
Training loss: 2.813393853457139
Validation loss: 3.1269249990103667

Epoch: 6| Step: 5
Training loss: 3.3562327748572325
Validation loss: 3.1264410638110887

Epoch: 6| Step: 6
Training loss: 2.9463664225839885
Validation loss: 3.127818076117837

Epoch: 6| Step: 7
Training loss: 2.7894788586228536
Validation loss: 3.1196796436088055

Epoch: 6| Step: 8
Training loss: 3.3288072056999227
Validation loss: 3.1170116647086252

Epoch: 6| Step: 9
Training loss: 3.249758491345964
Validation loss: 3.1157011607357323

Epoch: 6| Step: 10
Training loss: 3.4537760263263824
Validation loss: 3.113596310214239

Epoch: 6| Step: 11
Training loss: 3.7688684701091533
Validation loss: 3.114291601167806

Epoch: 6| Step: 12
Training loss: 3.474599905789163
Validation loss: 3.120416979609007

Epoch: 6| Step: 13
Training loss: 3.76295509500952
Validation loss: 3.121570288395189

Epoch: 17| Step: 0
Training loss: 3.975628996212718
Validation loss: 3.1068355987217773

Epoch: 6| Step: 1
Training loss: 2.9134887457742016
Validation loss: 3.103199203432313

Epoch: 6| Step: 2
Training loss: 2.7806965995310957
Validation loss: 3.1000755425728377

Epoch: 6| Step: 3
Training loss: 2.813607231053184
Validation loss: 3.1007160571132695

Epoch: 6| Step: 4
Training loss: 2.719665899233689
Validation loss: 3.100240537101957

Epoch: 6| Step: 5
Training loss: 2.9829980359891026
Validation loss: 3.0988096120666326

Epoch: 6| Step: 6
Training loss: 4.023297175951042
Validation loss: 3.1007292683605074

Epoch: 6| Step: 7
Training loss: 3.780105543731938
Validation loss: 3.10277301506443

Epoch: 6| Step: 8
Training loss: 2.9279754111919933
Validation loss: 3.100093884920343

Epoch: 6| Step: 9
Training loss: 3.253500154027705
Validation loss: 3.0937117392654985

Epoch: 6| Step: 10
Training loss: 3.5992169800197784
Validation loss: 3.0915211222192314

Epoch: 6| Step: 11
Training loss: 3.8499115970915385
Validation loss: 3.08569962236442

Epoch: 6| Step: 12
Training loss: 3.9753031057278725
Validation loss: 3.0855146515840173

Epoch: 6| Step: 13
Training loss: 3.017119042495565
Validation loss: 3.0844913490352597

Epoch: 18| Step: 0
Training loss: 2.7288746471306076
Validation loss: 3.0775727232107744

Epoch: 6| Step: 1
Training loss: 3.1051177204317484
Validation loss: 3.080389909097179

Epoch: 6| Step: 2
Training loss: 3.480245837812865
Validation loss: 3.0818578725731736

Epoch: 6| Step: 3
Training loss: 3.5118465209392764
Validation loss: 3.094274628656279

Epoch: 6| Step: 4
Training loss: 3.5138136881210222
Validation loss: 3.0852458161551097

Epoch: 6| Step: 5
Training loss: 3.2604554065356903
Validation loss: 3.0711896058361443

Epoch: 6| Step: 6
Training loss: 3.149339418931336
Validation loss: 3.0802146931336303

Epoch: 6| Step: 7
Training loss: 3.123044584749395
Validation loss: 3.073243975983819

Epoch: 6| Step: 8
Training loss: 2.915646692585768
Validation loss: 3.0667989416294663

Epoch: 6| Step: 9
Training loss: 3.148830796280733
Validation loss: 3.062640814926786

Epoch: 6| Step: 10
Training loss: 3.522886516517976
Validation loss: 3.0632515211837883

Epoch: 6| Step: 11
Training loss: 4.15949048369922
Validation loss: 3.0623876682061018

Epoch: 6| Step: 12
Training loss: 3.393557497750635
Validation loss: 3.064509787280392

Epoch: 6| Step: 13
Training loss: 3.9414531905344035
Validation loss: 3.0609696419247086

Epoch: 19| Step: 0
Training loss: 3.6159866349977596
Validation loss: 3.058599712780021

Epoch: 6| Step: 1
Training loss: 3.283786338369848
Validation loss: 3.061113352930122

Epoch: 6| Step: 2
Training loss: 3.171829298470019
Validation loss: 3.0482827257318723

Epoch: 6| Step: 3
Training loss: 3.296031391994275
Validation loss: 3.049514171881804

Epoch: 6| Step: 4
Training loss: 3.5687280390342657
Validation loss: 3.048437131521116

Epoch: 6| Step: 5
Training loss: 3.1176931788497546
Validation loss: 3.043439899169184

Epoch: 6| Step: 6
Training loss: 3.0891970646153863
Validation loss: 3.032983346694234

Epoch: 6| Step: 7
Training loss: 3.2297831941480486
Validation loss: 3.0294160986112137

Epoch: 6| Step: 8
Training loss: 3.5940875350999644
Validation loss: 3.026006560771236

Epoch: 6| Step: 9
Training loss: 3.5630899576612878
Validation loss: 3.028417321105212

Epoch: 6| Step: 10
Training loss: 3.3320562936393996
Validation loss: 3.0317534999140974

Epoch: 6| Step: 11
Training loss: 2.247943149960991
Validation loss: 3.0251870752678207

Epoch: 6| Step: 12
Training loss: 3.166774915216972
Validation loss: 3.0261028700777395

Epoch: 6| Step: 13
Training loss: 4.4196946662629495
Validation loss: 3.0205796943974543

Epoch: 20| Step: 0
Training loss: 3.4201335220596025
Validation loss: 3.018015531245866

Epoch: 6| Step: 1
Training loss: 3.824924423368705
Validation loss: 3.0135526171952987

Epoch: 6| Step: 2
Training loss: 3.1838438719804496
Validation loss: 3.0127797217440957

Epoch: 6| Step: 3
Training loss: 2.609847705534088
Validation loss: 3.0058090392420707

Epoch: 6| Step: 4
Training loss: 3.8309445332509977
Validation loss: 3.0085400301709138

Epoch: 6| Step: 5
Training loss: 3.7210417025248064
Validation loss: 3.0032150693998694

Epoch: 6| Step: 6
Training loss: 3.268632298059014
Validation loss: 3.0032338483926195

Epoch: 6| Step: 7
Training loss: 3.488568848376549
Validation loss: 3.0031351043530163

Epoch: 6| Step: 8
Training loss: 2.33252029786268
Validation loss: 2.998023279178778

Epoch: 6| Step: 9
Training loss: 3.379336079506866
Validation loss: 2.99514708704719

Epoch: 6| Step: 10
Training loss: 3.442646266514353
Validation loss: 2.9964828896288545

Epoch: 6| Step: 11
Training loss: 3.218878289786367
Validation loss: 2.994757397184968

Epoch: 6| Step: 12
Training loss: 3.3451398296239168
Validation loss: 2.993882127263972

Epoch: 6| Step: 13
Training loss: 2.188583541631704
Validation loss: 2.9936845970472605

Epoch: 21| Step: 0
Training loss: 3.366401173412278
Validation loss: 3.0011301236384527

Epoch: 6| Step: 1
Training loss: 3.626659539603729
Validation loss: 3.034919208681764

Epoch: 6| Step: 2
Training loss: 3.3751229157847384
Validation loss: 2.996317004178199

Epoch: 6| Step: 3
Training loss: 4.175032545865146
Validation loss: 2.979754341713182

Epoch: 6| Step: 4
Training loss: 3.620869618282677
Validation loss: 2.9812745814050516

Epoch: 6| Step: 5
Training loss: 3.2402017050229137
Validation loss: 2.978001386798562

Epoch: 6| Step: 6
Training loss: 3.4478867789794987
Validation loss: 2.978134180016579

Epoch: 6| Step: 7
Training loss: 2.8454216036965776
Validation loss: 2.9759341813700795

Epoch: 6| Step: 8
Training loss: 2.8719829817137525
Validation loss: 2.975509455990575

Epoch: 6| Step: 9
Training loss: 3.1500255280928626
Validation loss: 2.9748518096423284

Epoch: 6| Step: 10
Training loss: 2.9706792084322435
Validation loss: 2.976308989958831

Epoch: 6| Step: 11
Training loss: 3.4722246517596753
Validation loss: 2.980098027760603

Epoch: 6| Step: 12
Training loss: 2.6000369069340983
Validation loss: 2.9811702272589313

Epoch: 6| Step: 13
Training loss: 2.301128885790045
Validation loss: 2.97513538079104

Epoch: 22| Step: 0
Training loss: 3.5521295419560523
Validation loss: 2.9690576399344257

Epoch: 6| Step: 1
Training loss: 3.766205675615717
Validation loss: 2.9624076360528284

Epoch: 6| Step: 2
Training loss: 3.0112430973694364
Validation loss: 2.964853622898037

Epoch: 6| Step: 3
Training loss: 3.4908078602541153
Validation loss: 2.9645863677368265

Epoch: 6| Step: 4
Training loss: 3.178177758663228
Validation loss: 2.977148300963016

Epoch: 6| Step: 5
Training loss: 3.7268342692765795
Validation loss: 2.9561210088896295

Epoch: 6| Step: 6
Training loss: 3.1212556913948037
Validation loss: 2.9522929250177414

Epoch: 6| Step: 7
Training loss: 2.901636543212511
Validation loss: 2.9519759338250067

Epoch: 6| Step: 8
Training loss: 2.6887594421306056
Validation loss: 2.9514596269894215

Epoch: 6| Step: 9
Training loss: 4.139148376887288
Validation loss: 2.961365686584023

Epoch: 6| Step: 10
Training loss: 1.9066799491917625
Validation loss: 2.984665214705867

Epoch: 6| Step: 11
Training loss: 3.2596028117575124
Validation loss: 2.974400126408986

Epoch: 6| Step: 12
Training loss: 3.045288298791086
Validation loss: 2.953397371191401

Epoch: 6| Step: 13
Training loss: 3.1761390324964616
Validation loss: 2.949121215572258

Epoch: 23| Step: 0
Training loss: 3.195432180387812
Validation loss: 2.945199159497943

Epoch: 6| Step: 1
Training loss: 3.3104189687680465
Validation loss: 2.934983000078837

Epoch: 6| Step: 2
Training loss: 2.5014079897434454
Validation loss: 2.9366985284546407

Epoch: 6| Step: 3
Training loss: 3.478127253858139
Validation loss: 2.9360339578319623

Epoch: 6| Step: 4
Training loss: 3.663179010456148
Validation loss: 2.93852579903727

Epoch: 6| Step: 5
Training loss: 3.7546942257989593
Validation loss: 2.9378223909914674

Epoch: 6| Step: 6
Training loss: 3.511799133534957
Validation loss: 2.9336307162224946

Epoch: 6| Step: 7
Training loss: 3.344844745859121
Validation loss: 2.932340250232244

Epoch: 6| Step: 8
Training loss: 3.7670275343700568
Validation loss: 2.928191586125201

Epoch: 6| Step: 9
Training loss: 2.8103383552229797
Validation loss: 2.925627401996899

Epoch: 6| Step: 10
Training loss: 3.269241885343269
Validation loss: 2.924994938063082

Epoch: 6| Step: 11
Training loss: 3.131893337046105
Validation loss: 2.935646563320236

Epoch: 6| Step: 12
Training loss: 2.1122149529093153
Validation loss: 2.955434326511981

Epoch: 6| Step: 13
Training loss: 2.648733206925708
Validation loss: 3.0036426855654184

Epoch: 24| Step: 0
Training loss: 3.2202384988351223
Validation loss: 3.143413067138322

Epoch: 6| Step: 1
Training loss: 2.562606623222398
Validation loss: 3.0744213332445143

Epoch: 6| Step: 2
Training loss: 3.6504321639390187
Validation loss: 3.0142541126659164

Epoch: 6| Step: 3
Training loss: 3.036693286911672
Validation loss: 2.9378819842368378

Epoch: 6| Step: 4
Training loss: 3.9931770785355853
Validation loss: 2.9124322774126497

Epoch: 6| Step: 5
Training loss: 2.7385566344395653
Validation loss: 2.921230466835451

Epoch: 6| Step: 6
Training loss: 3.51699232850419
Validation loss: 2.9302662083841486

Epoch: 6| Step: 7
Training loss: 3.689973809580912
Validation loss: 2.93432406053498

Epoch: 6| Step: 8
Training loss: 2.841951409296995
Validation loss: 2.9207733992386458

Epoch: 6| Step: 9
Training loss: 2.874552152831064
Validation loss: 2.917811996550819

Epoch: 6| Step: 10
Training loss: 3.171004603435215
Validation loss: 2.9182398835217405

Epoch: 6| Step: 11
Training loss: 3.330614332059246
Validation loss: 2.9237300188789943

Epoch: 6| Step: 12
Training loss: 3.3857335964431674
Validation loss: 2.9325378019742883

Epoch: 6| Step: 13
Training loss: 3.0819882388673387
Validation loss: 2.9458244572723147

Epoch: 25| Step: 0
Training loss: 3.5052494464218413
Validation loss: 2.9150144684855572

Epoch: 6| Step: 1
Training loss: 2.8319580068653782
Validation loss: 2.9084220370846685

Epoch: 6| Step: 2
Training loss: 2.76615254171443
Validation loss: 2.9008346722073597

Epoch: 6| Step: 3
Training loss: 2.692763917645644
Validation loss: 2.903967930940855

Epoch: 6| Step: 4
Training loss: 3.0981086314040023
Validation loss: 2.905038331176227

Epoch: 6| Step: 5
Training loss: 3.3322281594806706
Validation loss: 2.9061128864280072

Epoch: 6| Step: 6
Training loss: 3.524258469307251
Validation loss: 2.9058395503439347

Epoch: 6| Step: 7
Training loss: 2.7135904396833395
Validation loss: 2.9009722296704834

Epoch: 6| Step: 8
Training loss: 2.940434065973575
Validation loss: 2.9022699281354103

Epoch: 6| Step: 9
Training loss: 4.007928143890781
Validation loss: 2.900671963957535

Epoch: 6| Step: 10
Training loss: 3.3699106060815556
Validation loss: 2.9012446635239266

Epoch: 6| Step: 11
Training loss: 3.5565402054999185
Validation loss: 2.8999452977931806

Epoch: 6| Step: 12
Training loss: 3.017936650677486
Validation loss: 2.902151841400489

Epoch: 6| Step: 13
Training loss: 3.333936747929807
Validation loss: 2.903075443667299

Epoch: 26| Step: 0
Training loss: 2.8018763488180847
Validation loss: 2.927435883960385

Epoch: 6| Step: 1
Training loss: 3.1281060613617195
Validation loss: 2.979100060889062

Epoch: 6| Step: 2
Training loss: 3.0179150044560723
Validation loss: 2.986385713316818

Epoch: 6| Step: 3
Training loss: 2.7864343564912253
Validation loss: 3.01585889781959

Epoch: 6| Step: 4
Training loss: 3.048923840385761
Validation loss: 2.9067433512198133

Epoch: 6| Step: 5
Training loss: 3.689703460811335
Validation loss: 2.889718185039011

Epoch: 6| Step: 6
Training loss: 2.910219168782922
Validation loss: 2.889437937314424

Epoch: 6| Step: 7
Training loss: 3.0625417278327487
Validation loss: 2.9012816557737358

Epoch: 6| Step: 8
Training loss: 3.0188522858596993
Validation loss: 2.929360786624272

Epoch: 6| Step: 9
Training loss: 3.1430870009253233
Validation loss: 2.9485201813382695

Epoch: 6| Step: 10
Training loss: 3.497794955334081
Validation loss: 2.9394706760708744

Epoch: 6| Step: 11
Training loss: 3.339964390410686
Validation loss: 2.9156844376435407

Epoch: 6| Step: 12
Training loss: 4.027653945831624
Validation loss: 2.890407271362599

Epoch: 6| Step: 13
Training loss: 3.394057404310853
Validation loss: 2.887847680972952

Epoch: 27| Step: 0
Training loss: 3.1490362842706845
Validation loss: 2.896524054948117

Epoch: 6| Step: 1
Training loss: 3.2253022399745066
Validation loss: 2.898570750748274

Epoch: 6| Step: 2
Training loss: 3.585618347725658
Validation loss: 2.9025071841895924

Epoch: 6| Step: 3
Training loss: 3.111306822010011
Validation loss: 2.9147853212730204

Epoch: 6| Step: 4
Training loss: 3.4875159369210516
Validation loss: 2.9431632786950037

Epoch: 6| Step: 5
Training loss: 3.34905328611057
Validation loss: 2.910840211768464

Epoch: 6| Step: 6
Training loss: 2.5513437769549574
Validation loss: 2.8998236428944772

Epoch: 6| Step: 7
Training loss: 3.383190248467298
Validation loss: 2.9056825078244186

Epoch: 6| Step: 8
Training loss: 3.2602161349864787
Validation loss: 2.9084291803802187

Epoch: 6| Step: 9
Training loss: 3.178031771482431
Validation loss: 2.9106077526824428

Epoch: 6| Step: 10
Training loss: 3.4923349643781263
Validation loss: 2.910702725195417

Epoch: 6| Step: 11
Training loss: 3.3187243444453265
Validation loss: 2.9069663038455023

Epoch: 6| Step: 12
Training loss: 2.394185425520781
Validation loss: 2.901491229559409

Epoch: 6| Step: 13
Training loss: 3.3390898271869593
Validation loss: 2.8990557902557894

Epoch: 28| Step: 0
Training loss: 2.870731003870274
Validation loss: 2.8963289389329687

Epoch: 6| Step: 1
Training loss: 3.0682835366184764
Validation loss: 2.914988015067435

Epoch: 6| Step: 2
Training loss: 3.330567229477339
Validation loss: 2.924211732103214

Epoch: 6| Step: 3
Training loss: 3.0548214309873707
Validation loss: 2.9397053466009293

Epoch: 6| Step: 4
Training loss: 3.1699318030690185
Validation loss: 2.8916559590867834

Epoch: 6| Step: 5
Training loss: 3.6002541770214163
Validation loss: 2.866058301606033

Epoch: 6| Step: 6
Training loss: 2.9817611671968507
Validation loss: 2.866998882269719

Epoch: 6| Step: 7
Training loss: 3.6993192922912668
Validation loss: 2.8678378616854965

Epoch: 6| Step: 8
Training loss: 3.4621612934023167
Validation loss: 2.869781433972207

Epoch: 6| Step: 9
Training loss: 3.1849703755340935
Validation loss: 2.8736446176491444

Epoch: 6| Step: 10
Training loss: 2.7863470798041834
Validation loss: 2.8759948325416453

Epoch: 6| Step: 11
Training loss: 3.715163352527304
Validation loss: 2.871859293368313

Epoch: 6| Step: 12
Training loss: 2.723431557557478
Validation loss: 2.8650413264895254

Epoch: 6| Step: 13
Training loss: 2.5622397499977447
Validation loss: 2.8617909539661612

Epoch: 29| Step: 0
Training loss: 2.48822318447998
Validation loss: 2.8621273779278353

Epoch: 6| Step: 1
Training loss: 2.843474993141507
Validation loss: 2.8605812254559404

Epoch: 6| Step: 2
Training loss: 3.22273319036941
Validation loss: 2.8651026420430306

Epoch: 6| Step: 3
Training loss: 3.2977218625017293
Validation loss: 2.8692929521827493

Epoch: 6| Step: 4
Training loss: 3.208861930865431
Validation loss: 2.884197005912654

Epoch: 6| Step: 5
Training loss: 2.8797553167776733
Validation loss: 2.8841801122342687

Epoch: 6| Step: 6
Training loss: 3.8546709435288693
Validation loss: 2.8847477037736815

Epoch: 6| Step: 7
Training loss: 3.6723055972587852
Validation loss: 2.8749336834250414

Epoch: 6| Step: 8
Training loss: 2.554958690749811
Validation loss: 2.8551714306527227

Epoch: 6| Step: 9
Training loss: 2.6985741382456316
Validation loss: 2.853673028320082

Epoch: 6| Step: 10
Training loss: 2.8749462620232547
Validation loss: 2.8522055999381415

Epoch: 6| Step: 11
Training loss: 3.268276178799491
Validation loss: 2.849278444269999

Epoch: 6| Step: 12
Training loss: 3.7241566567419095
Validation loss: 2.850113770157618

Epoch: 6| Step: 13
Training loss: 3.6329203928030593
Validation loss: 2.8510262716020964

Epoch: 30| Step: 0
Training loss: 3.142174182106753
Validation loss: 2.8469277501156522

Epoch: 6| Step: 1
Training loss: 3.1434507800181133
Validation loss: 2.846408143019739

Epoch: 6| Step: 2
Training loss: 3.5254447277704486
Validation loss: 2.846089477739427

Epoch: 6| Step: 3
Training loss: 3.560008733931554
Validation loss: 2.8502641541407376

Epoch: 6| Step: 4
Training loss: 3.221302686859186
Validation loss: 2.8523901690783426

Epoch: 6| Step: 5
Training loss: 2.780147033755027
Validation loss: 2.856961680800902

Epoch: 6| Step: 6
Training loss: 3.105495467161016
Validation loss: 2.8520777020164023

Epoch: 6| Step: 7
Training loss: 3.123963145860453
Validation loss: 2.851098677801667

Epoch: 6| Step: 8
Training loss: 3.1947650766940083
Validation loss: 2.8535167570024083

Epoch: 6| Step: 9
Training loss: 2.3032399949825693
Validation loss: 2.8640910302640408

Epoch: 6| Step: 10
Training loss: 2.61317286245239
Validation loss: 2.8733155700644253

Epoch: 6| Step: 11
Training loss: 3.2584728422486315
Validation loss: 2.906898222475913

Epoch: 6| Step: 12
Training loss: 3.838618132383028
Validation loss: 2.898131956086777

Epoch: 6| Step: 13
Training loss: 3.0361650084232945
Validation loss: 2.851930506828045

Epoch: 31| Step: 0
Training loss: 3.882431042237517
Validation loss: 2.836135442873377

Epoch: 6| Step: 1
Training loss: 2.9016597141954574
Validation loss: 2.8398950567662005

Epoch: 6| Step: 2
Training loss: 2.930174113233257
Validation loss: 2.838436397885873

Epoch: 6| Step: 3
Training loss: 2.8472838190957317
Validation loss: 2.838127696857345

Epoch: 6| Step: 4
Training loss: 3.1473135255291163
Validation loss: 2.840939585483843

Epoch: 6| Step: 5
Training loss: 3.2736571609249787
Validation loss: 2.8428302617643237

Epoch: 6| Step: 6
Training loss: 2.43323574218837
Validation loss: 2.8425496464200464

Epoch: 6| Step: 7
Training loss: 3.17391045566292
Validation loss: 2.8427135323564663

Epoch: 6| Step: 8
Training loss: 3.2331882824429763
Validation loss: 2.840912941789301

Epoch: 6| Step: 9
Training loss: 2.795818107855358
Validation loss: 2.8393447472998203

Epoch: 6| Step: 10
Training loss: 2.7330592886463965
Validation loss: 2.839751844161209

Epoch: 6| Step: 11
Training loss: 3.9352858842585663
Validation loss: 2.8356490332418587

Epoch: 6| Step: 12
Training loss: 3.055899533263072
Validation loss: 2.8323940557577645

Epoch: 6| Step: 13
Training loss: 3.744809182046066
Validation loss: 2.8327008421496305

Epoch: 32| Step: 0
Training loss: 2.6992756331063052
Validation loss: 2.8297961273237804

Epoch: 6| Step: 1
Training loss: 3.5584170049497743
Validation loss: 2.825801230310263

Epoch: 6| Step: 2
Training loss: 3.48121095700517
Validation loss: 2.8276470339959205

Epoch: 6| Step: 3
Training loss: 3.2899731170576323
Validation loss: 2.825755690821894

Epoch: 6| Step: 4
Training loss: 3.7531278916728166
Validation loss: 2.825766497852719

Epoch: 6| Step: 5
Training loss: 3.122840440331764
Validation loss: 2.8257156340455847

Epoch: 6| Step: 6
Training loss: 3.1710519709422917
Validation loss: 2.8225803841680124

Epoch: 6| Step: 7
Training loss: 2.7696251685139925
Validation loss: 2.826482416040163

Epoch: 6| Step: 8
Training loss: 3.357876465597764
Validation loss: 2.8273324662161547

Epoch: 6| Step: 9
Training loss: 3.520342023228745
Validation loss: 2.829231139710422

Epoch: 6| Step: 10
Training loss: 2.61811434148284
Validation loss: 2.828922923102662

Epoch: 6| Step: 11
Training loss: 2.4809343036285543
Validation loss: 2.820577682223615

Epoch: 6| Step: 12
Training loss: 2.7870475264960066
Validation loss: 2.8190431328605086

Epoch: 6| Step: 13
Training loss: 2.7879621969311805
Validation loss: 2.8156267439443132

Epoch: 33| Step: 0
Training loss: 3.2370788771641665
Validation loss: 2.8153163868661233

Epoch: 6| Step: 1
Training loss: 3.1465468113373904
Validation loss: 2.8155704068293326

Epoch: 6| Step: 2
Training loss: 3.464948065562585
Validation loss: 2.8149391963722277

Epoch: 6| Step: 3
Training loss: 3.2686308392309136
Validation loss: 2.813774693258728

Epoch: 6| Step: 4
Training loss: 3.1985470691990505
Validation loss: 2.8135414346561354

Epoch: 6| Step: 5
Training loss: 3.43129044528047
Validation loss: 2.8202147035240825

Epoch: 6| Step: 6
Training loss: 2.674948190918224
Validation loss: 2.8125429485145514

Epoch: 6| Step: 7
Training loss: 3.330404584437891
Validation loss: 2.8152365425385053

Epoch: 6| Step: 8
Training loss: 2.5367020653733143
Validation loss: 2.823944700752594

Epoch: 6| Step: 9
Training loss: 2.9380497519459516
Validation loss: 2.8199935676852186

Epoch: 6| Step: 10
Training loss: 2.6067886783828715
Validation loss: 2.8235598458322144

Epoch: 6| Step: 11
Training loss: 3.3400302054130124
Validation loss: 2.8101472062561066

Epoch: 6| Step: 12
Training loss: 3.08081649609203
Validation loss: 2.792117105607032

Epoch: 6| Step: 13
Training loss: 3.2433651910872365
Validation loss: 2.7821831330916558

Epoch: 34| Step: 0
Training loss: 3.2896581549869834
Validation loss: 2.784128967245114

Epoch: 6| Step: 1
Training loss: 3.5159328749740433
Validation loss: 2.788524512950233

Epoch: 6| Step: 2
Training loss: 3.588322795658139
Validation loss: 2.782713394126227

Epoch: 6| Step: 3
Training loss: 2.521850842971157
Validation loss: 2.7836331735111393

Epoch: 6| Step: 4
Training loss: 3.296212658632658
Validation loss: 2.7800747032424398

Epoch: 6| Step: 5
Training loss: 2.8777409631770996
Validation loss: 2.7804239089437357

Epoch: 6| Step: 6
Training loss: 2.6341648873268144
Validation loss: 2.7817087139688668

Epoch: 6| Step: 7
Training loss: 2.6842384952036773
Validation loss: 2.7838723500090934

Epoch: 6| Step: 8
Training loss: 2.9304396820864067
Validation loss: 2.7988865494919377

Epoch: 6| Step: 9
Training loss: 3.3101521934716707
Validation loss: 2.792512514527716

Epoch: 6| Step: 10
Training loss: 2.735765637588464
Validation loss: 2.8025522555984836

Epoch: 6| Step: 11
Training loss: 3.2184362165961673
Validation loss: 2.8002467081927667

Epoch: 6| Step: 12
Training loss: 3.252793358746385
Validation loss: 2.7997447337710044

Epoch: 6| Step: 13
Training loss: 3.6117746542321965
Validation loss: 2.8026199135080865

Epoch: 35| Step: 0
Training loss: 2.8813131925392934
Validation loss: 2.7784721971554

Epoch: 6| Step: 1
Training loss: 3.240800896545452
Validation loss: 2.7689956750486786

Epoch: 6| Step: 2
Training loss: 2.631272224821705
Validation loss: 2.7629491932767976

Epoch: 6| Step: 3
Training loss: 3.0115829021526346
Validation loss: 2.7638773067055316

Epoch: 6| Step: 4
Training loss: 2.886682905044283
Validation loss: 2.76154172557148

Epoch: 6| Step: 5
Training loss: 3.5428878623535915
Validation loss: 2.760732786280972

Epoch: 6| Step: 6
Training loss: 3.3874527818830633
Validation loss: 2.759084476121879

Epoch: 6| Step: 7
Training loss: 2.6453417123532392
Validation loss: 2.758507300212321

Epoch: 6| Step: 8
Training loss: 3.628272322523038
Validation loss: 2.758970093721982

Epoch: 6| Step: 9
Training loss: 2.6649466470956704
Validation loss: 2.7591972984243727

Epoch: 6| Step: 10
Training loss: 2.9405965513825474
Validation loss: 2.7562059200407116

Epoch: 6| Step: 11
Training loss: 2.812048473141139
Validation loss: 2.7528656415954478

Epoch: 6| Step: 12
Training loss: 3.2094950533720454
Validation loss: 2.75660814943072

Epoch: 6| Step: 13
Training loss: 3.6715616295385143
Validation loss: 2.7519055101142085

Epoch: 36| Step: 0
Training loss: 2.6733905442538157
Validation loss: 2.753636144202

Epoch: 6| Step: 1
Training loss: 3.3620121031117254
Validation loss: 2.758212313667587

Epoch: 6| Step: 2
Training loss: 3.500371095875106
Validation loss: 2.7580237175404734

Epoch: 6| Step: 3
Training loss: 3.2752511546968077
Validation loss: 2.7692217516868416

Epoch: 6| Step: 4
Training loss: 2.692128387705514
Validation loss: 2.7480587078213787

Epoch: 6| Step: 5
Training loss: 3.4879552127080036
Validation loss: 2.7457410754273504

Epoch: 6| Step: 6
Training loss: 2.248177956240298
Validation loss: 2.746645448509948

Epoch: 6| Step: 7
Training loss: 3.673658871034765
Validation loss: 2.7486332734759573

Epoch: 6| Step: 8
Training loss: 2.644428741406674
Validation loss: 2.7433227922567522

Epoch: 6| Step: 9
Training loss: 3.4247847774852547
Validation loss: 2.7438639267496057

Epoch: 6| Step: 10
Training loss: 2.67377310808423
Validation loss: 2.748225136224349

Epoch: 6| Step: 11
Training loss: 2.322114289841361
Validation loss: 2.7542420685715907

Epoch: 6| Step: 12
Training loss: 3.6073925304200363
Validation loss: 2.7556135294223947

Epoch: 6| Step: 13
Training loss: 3.0757288247413372
Validation loss: 2.770903450831755

Epoch: 37| Step: 0
Training loss: 2.9975482140768532
Validation loss: 2.7523815036138166

Epoch: 6| Step: 1
Training loss: 3.1601806941460358
Validation loss: 2.7404047492820456

Epoch: 6| Step: 2
Training loss: 3.1281094149602393
Validation loss: 2.740650576597738

Epoch: 6| Step: 3
Training loss: 2.5649989898858117
Validation loss: 2.7366380253052784

Epoch: 6| Step: 4
Training loss: 3.6239363326570535
Validation loss: 2.7366003138405013

Epoch: 6| Step: 5
Training loss: 3.1126031268703103
Validation loss: 2.7371522736631073

Epoch: 6| Step: 6
Training loss: 2.7517037749103657
Validation loss: 2.737153545577428

Epoch: 6| Step: 7
Training loss: 3.2777516926160324
Validation loss: 2.7373619311109225

Epoch: 6| Step: 8
Training loss: 2.619516002998611
Validation loss: 2.7372227881506923

Epoch: 6| Step: 9
Training loss: 3.3287166732168356
Validation loss: 2.7367033568273156

Epoch: 6| Step: 10
Training loss: 3.377080770433141
Validation loss: 2.735438768985001

Epoch: 6| Step: 11
Training loss: 3.2104570535194323
Validation loss: 2.7363572040620183

Epoch: 6| Step: 12
Training loss: 2.808105765912978
Validation loss: 2.732791505179464

Epoch: 6| Step: 13
Training loss: 2.425454920934695
Validation loss: 2.7334727684169993

Epoch: 38| Step: 0
Training loss: 3.2569177803153666
Validation loss: 2.734984660119756

Epoch: 6| Step: 1
Training loss: 3.1472862543152256
Validation loss: 2.736608793719335

Epoch: 6| Step: 2
Training loss: 3.2576910128914363
Validation loss: 2.752286888631203

Epoch: 6| Step: 3
Training loss: 3.308574726000502
Validation loss: 2.7614221717785616

Epoch: 6| Step: 4
Training loss: 2.6860299636521567
Validation loss: 2.7626205354934457

Epoch: 6| Step: 5
Training loss: 2.951451548989533
Validation loss: 2.7657964556058166

Epoch: 6| Step: 6
Training loss: 3.20921409374434
Validation loss: 2.7359906698551306

Epoch: 6| Step: 7
Training loss: 3.770268153764921
Validation loss: 2.72716068309258

Epoch: 6| Step: 8
Training loss: 2.8315264232169857
Validation loss: 2.727755112883799

Epoch: 6| Step: 9
Training loss: 2.9268712049480423
Validation loss: 2.7303079142885487

Epoch: 6| Step: 10
Training loss: 2.7475738226680537
Validation loss: 2.735547624876534

Epoch: 6| Step: 11
Training loss: 2.7075400926997664
Validation loss: 2.741416665515717

Epoch: 6| Step: 12
Training loss: 3.112875343579162
Validation loss: 2.745387065973282

Epoch: 6| Step: 13
Training loss: 2.6762592417785918
Validation loss: 2.7369163036615705

Epoch: 39| Step: 0
Training loss: 3.165355276985668
Validation loss: 2.732301695393061

Epoch: 6| Step: 1
Training loss: 2.23504820598869
Validation loss: 2.7274120269754767

Epoch: 6| Step: 2
Training loss: 3.416410359018796
Validation loss: 2.724724588271175

Epoch: 6| Step: 3
Training loss: 3.3855564186399176
Validation loss: 2.72568563656655

Epoch: 6| Step: 4
Training loss: 3.356879296435879
Validation loss: 2.727242721045758

Epoch: 6| Step: 5
Training loss: 2.609481626604913
Validation loss: 2.731858857314639

Epoch: 6| Step: 6
Training loss: 3.1053188839624424
Validation loss: 2.7563596389881933

Epoch: 6| Step: 7
Training loss: 3.3873902813361823
Validation loss: 2.7804834577617705

Epoch: 6| Step: 8
Training loss: 3.040566824722092
Validation loss: 2.758330311327587

Epoch: 6| Step: 9
Training loss: 3.180597948201795
Validation loss: 2.7369176562408066

Epoch: 6| Step: 10
Training loss: 2.7699993475076616
Validation loss: 2.7208495179937304

Epoch: 6| Step: 11
Training loss: 2.6027094515048423
Validation loss: 2.719220399974086

Epoch: 6| Step: 12
Training loss: 3.457083112252225
Validation loss: 2.720932007220083

Epoch: 6| Step: 13
Training loss: 2.7787824678776456
Validation loss: 2.7216715878037983

Epoch: 40| Step: 0
Training loss: 2.882320041514528
Validation loss: 2.724261511445453

Epoch: 6| Step: 1
Training loss: 2.6909901334651867
Validation loss: 2.7254446375317665

Epoch: 6| Step: 2
Training loss: 2.9624505920153057
Validation loss: 2.726331734017238

Epoch: 6| Step: 3
Training loss: 3.191826371329869
Validation loss: 2.7267559958477805

Epoch: 6| Step: 4
Training loss: 2.672001707407697
Validation loss: 2.7274518562766703

Epoch: 6| Step: 5
Training loss: 3.4332429361633907
Validation loss: 2.7225315959208927

Epoch: 6| Step: 6
Training loss: 3.06804606333225
Validation loss: 2.721238214670381

Epoch: 6| Step: 7
Training loss: 3.4021839756902272
Validation loss: 2.718611637678156

Epoch: 6| Step: 8
Training loss: 2.7553336698487443
Validation loss: 2.7172896249285476

Epoch: 6| Step: 9
Training loss: 3.1840255350881312
Validation loss: 2.715407287698478

Epoch: 6| Step: 10
Training loss: 2.749667320936112
Validation loss: 2.7122681128236326

Epoch: 6| Step: 11
Training loss: 3.575223720993047
Validation loss: 2.7149171082902113

Epoch: 6| Step: 12
Training loss: 2.975032383077348
Validation loss: 2.717085948934989

Epoch: 6| Step: 13
Training loss: 3.2373391542282857
Validation loss: 2.7207382206127413

Epoch: 41| Step: 0
Training loss: 2.8037697823413756
Validation loss: 2.7154667121051297

Epoch: 6| Step: 1
Training loss: 2.647998694693252
Validation loss: 2.715694056069675

Epoch: 6| Step: 2
Training loss: 2.7491906448926624
Validation loss: 2.718628072167485

Epoch: 6| Step: 3
Training loss: 3.138458263674562
Validation loss: 2.7138448890669413

Epoch: 6| Step: 4
Training loss: 2.911700152805263
Validation loss: 2.7151821697219787

Epoch: 6| Step: 5
Training loss: 3.400391326150488
Validation loss: 2.714922258385852

Epoch: 6| Step: 6
Training loss: 3.298707714785511
Validation loss: 2.7150710394301654

Epoch: 6| Step: 7
Training loss: 2.591726685919651
Validation loss: 2.71346675134906

Epoch: 6| Step: 8
Training loss: 3.4252831891899773
Validation loss: 2.712527374950563

Epoch: 6| Step: 9
Training loss: 2.5398511395424648
Validation loss: 2.707864430793754

Epoch: 6| Step: 10
Training loss: 3.2275191175159077
Validation loss: 2.708493694798758

Epoch: 6| Step: 11
Training loss: 3.3924363040215306
Validation loss: 2.7103490410360194

Epoch: 6| Step: 12
Training loss: 3.158051533738184
Validation loss: 2.7091815478465975

Epoch: 6| Step: 13
Training loss: 3.229339660604732
Validation loss: 2.710494140388946

Epoch: 42| Step: 0
Training loss: 2.293956745195542
Validation loss: 2.7089158263967077

Epoch: 6| Step: 1
Training loss: 3.062443012563694
Validation loss: 2.707143508644938

Epoch: 6| Step: 2
Training loss: 3.370053657987487
Validation loss: 2.704891058726071

Epoch: 6| Step: 3
Training loss: 2.2263279841545778
Validation loss: 2.703507494439244

Epoch: 6| Step: 4
Training loss: 2.9323971843988517
Validation loss: 2.700488225486658

Epoch: 6| Step: 5
Training loss: 3.0343580534252577
Validation loss: 2.7002718580861753

Epoch: 6| Step: 6
Training loss: 3.308710485783752
Validation loss: 2.700460616130306

Epoch: 6| Step: 7
Training loss: 3.3193992884786456
Validation loss: 2.6998682755636643

Epoch: 6| Step: 8
Training loss: 2.279090800118132
Validation loss: 2.7033566402871387

Epoch: 6| Step: 9
Training loss: 3.055127826769746
Validation loss: 2.708242193034242

Epoch: 6| Step: 10
Training loss: 3.555424406361438
Validation loss: 2.7186164884466444

Epoch: 6| Step: 11
Training loss: 2.9086130031426976
Validation loss: 2.717466835860874

Epoch: 6| Step: 12
Training loss: 3.37704815353027
Validation loss: 2.7229520342490035

Epoch: 6| Step: 13
Training loss: 3.552274652215528
Validation loss: 2.7153908280511527

Epoch: 43| Step: 0
Training loss: 2.9580782569917425
Validation loss: 2.701034517136653

Epoch: 6| Step: 1
Training loss: 3.0354080783056605
Validation loss: 2.7006094183268226

Epoch: 6| Step: 2
Training loss: 3.2643263575512047
Validation loss: 2.6962405720446365

Epoch: 6| Step: 3
Training loss: 3.4172630409853118
Validation loss: 2.6944053365715686

Epoch: 6| Step: 4
Training loss: 2.7947420479579193
Validation loss: 2.692360150453717

Epoch: 6| Step: 5
Training loss: 3.143376146539388
Validation loss: 2.6906767325773058

Epoch: 6| Step: 6
Training loss: 2.928579380277146
Validation loss: 2.6904137334824596

Epoch: 6| Step: 7
Training loss: 3.089320547220933
Validation loss: 2.6930688994397407

Epoch: 6| Step: 8
Training loss: 2.902829361923184
Validation loss: 2.690540205279759

Epoch: 6| Step: 9
Training loss: 2.401230766699921
Validation loss: 2.6909324169004583

Epoch: 6| Step: 10
Training loss: 2.9368735112042175
Validation loss: 2.6916330907717416

Epoch: 6| Step: 11
Training loss: 3.2509183319826267
Validation loss: 2.701645004438052

Epoch: 6| Step: 12
Training loss: 2.6694656127326786
Validation loss: 2.6891718989439752

Epoch: 6| Step: 13
Training loss: 3.6210437100439465
Validation loss: 2.6888819053715944

Epoch: 44| Step: 0
Training loss: 2.704671075816232
Validation loss: 2.689884937144948

Epoch: 6| Step: 1
Training loss: 3.2835311952668467
Validation loss: 2.6900551990866113

Epoch: 6| Step: 2
Training loss: 3.0634364039446265
Validation loss: 2.6917506545793586

Epoch: 6| Step: 3
Training loss: 2.5872475800425034
Validation loss: 2.693422191739563

Epoch: 6| Step: 4
Training loss: 2.7812142530565724
Validation loss: 2.6931655653316384

Epoch: 6| Step: 5
Training loss: 3.265199478388264
Validation loss: 2.690756678757307

Epoch: 6| Step: 6
Training loss: 3.0005565762798168
Validation loss: 2.692785210116088

Epoch: 6| Step: 7
Training loss: 2.9992652629118304
Validation loss: 2.689935396805316

Epoch: 6| Step: 8
Training loss: 2.8701419420398104
Validation loss: 2.6877570347735995

Epoch: 6| Step: 9
Training loss: 2.767478192664759
Validation loss: 2.6894208964370923

Epoch: 6| Step: 10
Training loss: 3.5647970456941507
Validation loss: 2.6902454334641637

Epoch: 6| Step: 11
Training loss: 3.245950523549391
Validation loss: 2.693310235937326

Epoch: 6| Step: 12
Training loss: 2.7039592536023176
Validation loss: 2.697462798135418

Epoch: 6| Step: 13
Training loss: 3.7325985565766517
Validation loss: 2.70236193197846

Epoch: 45| Step: 0
Training loss: 2.7658437006626677
Validation loss: 2.700775829975638

Epoch: 6| Step: 1
Training loss: 3.5130385993902293
Validation loss: 2.709083040341646

Epoch: 6| Step: 2
Training loss: 3.3099536825667673
Validation loss: 2.697406382417806

Epoch: 6| Step: 3
Training loss: 2.6967744704657197
Validation loss: 2.6916012711998665

Epoch: 6| Step: 4
Training loss: 2.3676084641421475
Validation loss: 2.6829550923325884

Epoch: 6| Step: 5
Training loss: 3.2512128474229502
Validation loss: 2.678782536732524

Epoch: 6| Step: 6
Training loss: 2.899413569120453
Validation loss: 2.6799709514922516

Epoch: 6| Step: 7
Training loss: 3.0847972453306887
Validation loss: 2.681885243938455

Epoch: 6| Step: 8
Training loss: 3.210434625976816
Validation loss: 2.6793626827409436

Epoch: 6| Step: 9
Training loss: 2.800475206240509
Validation loss: 2.6782839475980715

Epoch: 6| Step: 10
Training loss: 3.3595579585443747
Validation loss: 2.6781558612835354

Epoch: 6| Step: 11
Training loss: 2.905649430764481
Validation loss: 2.6784145355177182

Epoch: 6| Step: 12
Training loss: 3.203542096033634
Validation loss: 2.6772771958015396

Epoch: 6| Step: 13
Training loss: 2.538460528100086
Validation loss: 2.677469145218848

Epoch: 46| Step: 0
Training loss: 2.7559823077039516
Validation loss: 2.6728690773103687

Epoch: 6| Step: 1
Training loss: 3.124570893390365
Validation loss: 2.6752208971190465

Epoch: 6| Step: 2
Training loss: 3.3130766168791697
Validation loss: 2.673546929599665

Epoch: 6| Step: 3
Training loss: 2.014149088511258
Validation loss: 2.6728538980065086

Epoch: 6| Step: 4
Training loss: 2.981627152936124
Validation loss: 2.6710302013666607

Epoch: 6| Step: 5
Training loss: 3.3481014850325472
Validation loss: 2.6701006492935666

Epoch: 6| Step: 6
Training loss: 2.8586179637899907
Validation loss: 2.679928267029678

Epoch: 6| Step: 7
Training loss: 3.672986970092693
Validation loss: 2.6933621448458966

Epoch: 6| Step: 8
Training loss: 3.185209910184262
Validation loss: 2.7097176761488533

Epoch: 6| Step: 9
Training loss: 2.875378791070608
Validation loss: 2.7215834823875538

Epoch: 6| Step: 10
Training loss: 3.3512940199229297
Validation loss: 2.691513607324161

Epoch: 6| Step: 11
Training loss: 3.2179152508108984
Validation loss: 2.6718266028239355

Epoch: 6| Step: 12
Training loss: 2.396285393124687
Validation loss: 2.667444033783295

Epoch: 6| Step: 13
Training loss: 2.6760376744718806
Validation loss: 2.6676580184797554

Epoch: 47| Step: 0
Training loss: 3.2303958317231434
Validation loss: 2.6701300607582956

Epoch: 6| Step: 1
Training loss: 3.7335339480949075
Validation loss: 2.6719617231670743

Epoch: 6| Step: 2
Training loss: 3.042677428338792
Validation loss: 2.6721718760002773

Epoch: 6| Step: 3
Training loss: 3.062832716949158
Validation loss: 2.672560077184865

Epoch: 6| Step: 4
Training loss: 2.7921660436863593
Validation loss: 2.674332397343389

Epoch: 6| Step: 5
Training loss: 2.6623254745664804
Validation loss: 2.6722678300097478

Epoch: 6| Step: 6
Training loss: 3.2477020062234816
Validation loss: 2.673010378048546

Epoch: 6| Step: 7
Training loss: 3.2487638029808497
Validation loss: 2.6717094739997873

Epoch: 6| Step: 8
Training loss: 2.419255569021129
Validation loss: 2.667140419341546

Epoch: 6| Step: 9
Training loss: 2.156322754447974
Validation loss: 2.665372824642492

Epoch: 6| Step: 10
Training loss: 3.7725013851216316
Validation loss: 2.6627367335664163

Epoch: 6| Step: 11
Training loss: 2.66709472280354
Validation loss: 2.661552194598992

Epoch: 6| Step: 12
Training loss: 2.509439196305831
Validation loss: 2.6591823010978626

Epoch: 6| Step: 13
Training loss: 3.3166597267218845
Validation loss: 2.666537783248723

Epoch: 48| Step: 0
Training loss: 2.968767346783202
Validation loss: 2.6866949325061307

Epoch: 6| Step: 1
Training loss: 2.5983111251589945
Validation loss: 2.7090209472992526

Epoch: 6| Step: 2
Training loss: 3.3584002832849684
Validation loss: 2.7220160414464987

Epoch: 6| Step: 3
Training loss: 2.616887408460121
Validation loss: 2.704684641507487

Epoch: 6| Step: 4
Training loss: 2.9547263350171282
Validation loss: 2.667384184422407

Epoch: 6| Step: 5
Training loss: 2.714624014544968
Validation loss: 2.662161399716898

Epoch: 6| Step: 6
Training loss: 3.638736480614391
Validation loss: 2.655889205992286

Epoch: 6| Step: 7
Training loss: 2.8100467578893875
Validation loss: 2.6573380463482845

Epoch: 6| Step: 8
Training loss: 2.9982860755553564
Validation loss: 2.6569184023908488

Epoch: 6| Step: 9
Training loss: 3.2765945105564844
Validation loss: 2.659292234737901

Epoch: 6| Step: 10
Training loss: 2.5005285657972234
Validation loss: 2.662651803099397

Epoch: 6| Step: 11
Training loss: 3.149600133795974
Validation loss: 2.6656709537392715

Epoch: 6| Step: 12
Training loss: 2.5329736563016336
Validation loss: 2.6643499153731827

Epoch: 6| Step: 13
Training loss: 3.998190589785401
Validation loss: 2.6677061443641246

Epoch: 49| Step: 0
Training loss: 3.2352915768944865
Validation loss: 2.666439255476247

Epoch: 6| Step: 1
Training loss: 2.122875947221712
Validation loss: 2.6678743998702648

Epoch: 6| Step: 2
Training loss: 2.6971708663659126
Validation loss: 2.6642306478673246

Epoch: 6| Step: 3
Training loss: 2.4138517318614756
Validation loss: 2.664654455810649

Epoch: 6| Step: 4
Training loss: 3.7303928227711647
Validation loss: 2.6616245164352055

Epoch: 6| Step: 5
Training loss: 3.183591952645198
Validation loss: 2.659476408445596

Epoch: 6| Step: 6
Training loss: 2.889288515995263
Validation loss: 2.6593357815978926

Epoch: 6| Step: 7
Training loss: 2.9645260928416803
Validation loss: 2.6557935618132826

Epoch: 6| Step: 8
Training loss: 4.049252080734179
Validation loss: 2.6543406274395798

Epoch: 6| Step: 9
Training loss: 3.3268183619199903
Validation loss: 2.6517440362197897

Epoch: 6| Step: 10
Training loss: 2.383941082949639
Validation loss: 2.6496490254220837

Epoch: 6| Step: 11
Training loss: 2.780751987403407
Validation loss: 2.649292901404118

Epoch: 6| Step: 12
Training loss: 2.6496056425216503
Validation loss: 2.6473146503043217

Epoch: 6| Step: 13
Training loss: 3.1879845045280315
Validation loss: 2.6486722630552912

Epoch: 50| Step: 0
Training loss: 2.8413451369905767
Validation loss: 2.6499015992992656

Epoch: 6| Step: 1
Training loss: 2.3480763495865182
Validation loss: 2.6557106575588167

Epoch: 6| Step: 2
Training loss: 3.2444263495487897
Validation loss: 2.7018432983309686

Epoch: 6| Step: 3
Training loss: 3.0065395287180476
Validation loss: 2.714087484849753

Epoch: 6| Step: 4
Training loss: 2.4968362817161425
Validation loss: 2.6601754761059313

Epoch: 6| Step: 5
Training loss: 2.7256359723103607
Validation loss: 2.6522139131261744

Epoch: 6| Step: 6
Training loss: 3.671193680556929
Validation loss: 2.644875130467708

Epoch: 6| Step: 7
Training loss: 2.9804489115083532
Validation loss: 2.6464089536233026

Epoch: 6| Step: 8
Training loss: 2.9030670455880276
Validation loss: 2.6461743797180315

Epoch: 6| Step: 9
Training loss: 3.0927934805555153
Validation loss: 2.6461065427608

Epoch: 6| Step: 10
Training loss: 3.2104797779557943
Validation loss: 2.644974912709816

Epoch: 6| Step: 11
Training loss: 2.4435896486713458
Validation loss: 2.649862847906943

Epoch: 6| Step: 12
Training loss: 3.371050890741816
Validation loss: 2.6445494021795777

Epoch: 6| Step: 13
Training loss: 3.393599089187939
Validation loss: 2.6479955395142767

Epoch: 51| Step: 0
Training loss: 2.7886598440632935
Validation loss: 2.644004974563412

Epoch: 6| Step: 1
Training loss: 3.7099263630677046
Validation loss: 2.6458859317723182

Epoch: 6| Step: 2
Training loss: 2.533915117451398
Validation loss: 2.6431508511193504

Epoch: 6| Step: 3
Training loss: 3.5168810147833485
Validation loss: 2.64223960992499

Epoch: 6| Step: 4
Training loss: 2.8234401278544254
Validation loss: 2.649250293594134

Epoch: 6| Step: 5
Training loss: 3.1646200560062425
Validation loss: 2.657763246622924

Epoch: 6| Step: 6
Training loss: 2.8888144931832143
Validation loss: 2.6496438626251897

Epoch: 6| Step: 7
Training loss: 3.1129185406657065
Validation loss: 2.644488484038698

Epoch: 6| Step: 8
Training loss: 3.0514610793237935
Validation loss: 2.6469325859361805

Epoch: 6| Step: 9
Training loss: 2.521640952971522
Validation loss: 2.6471408897424715

Epoch: 6| Step: 10
Training loss: 3.1718868762766426
Validation loss: 2.6452814588730447

Epoch: 6| Step: 11
Training loss: 2.829611371857816
Validation loss: 2.647475334730489

Epoch: 6| Step: 12
Training loss: 2.8282023888216044
Validation loss: 2.6421618080807554

Epoch: 6| Step: 13
Training loss: 2.5627063575089704
Validation loss: 2.642008373987574

Epoch: 52| Step: 0
Training loss: 2.8167555085867515
Validation loss: 2.6401132086563113

Epoch: 6| Step: 1
Training loss: 3.192852836354839
Validation loss: 2.638842545235349

Epoch: 6| Step: 2
Training loss: 3.228312241920761
Validation loss: 2.6349436147199943

Epoch: 6| Step: 3
Training loss: 2.776322274879651
Validation loss: 2.635101824521693

Epoch: 6| Step: 4
Training loss: 3.427295032830618
Validation loss: 2.634957649334426

Epoch: 6| Step: 5
Training loss: 3.3686038974651766
Validation loss: 2.634386361145232

Epoch: 6| Step: 6
Training loss: 2.521464896625482
Validation loss: 2.6432300040046064

Epoch: 6| Step: 7
Training loss: 2.505789633157266
Validation loss: 2.6704878949402246

Epoch: 6| Step: 8
Training loss: 2.797429802280612
Validation loss: 2.695853091530142

Epoch: 6| Step: 9
Training loss: 2.876345775589568
Validation loss: 2.6580421979083493

Epoch: 6| Step: 10
Training loss: 3.0766359396984777
Validation loss: 2.6359727569415723

Epoch: 6| Step: 11
Training loss: 2.9553803404719576
Validation loss: 2.6295463912497414

Epoch: 6| Step: 12
Training loss: 2.8211211421611764
Validation loss: 2.626238874852392

Epoch: 6| Step: 13
Training loss: 3.3974700603050123
Validation loss: 2.6302355780825586

Epoch: 53| Step: 0
Training loss: 2.9762866275332756
Validation loss: 2.622853326712398

Epoch: 6| Step: 1
Training loss: 2.524971416047213
Validation loss: 2.6263284988722515

Epoch: 6| Step: 2
Training loss: 2.027864187248808
Validation loss: 2.6226956380159647

Epoch: 6| Step: 3
Training loss: 3.0235904783044223
Validation loss: 2.6237993243609186

Epoch: 6| Step: 4
Training loss: 3.5084097508846566
Validation loss: 2.633662004028946

Epoch: 6| Step: 5
Training loss: 2.8169979156497265
Validation loss: 2.6199461986519497

Epoch: 6| Step: 6
Training loss: 2.9529583596336857
Validation loss: 2.618974662532246

Epoch: 6| Step: 7
Training loss: 2.973841587498672
Validation loss: 2.622727613247877

Epoch: 6| Step: 8
Training loss: 3.101465334199027
Validation loss: 2.622750044160425

Epoch: 6| Step: 9
Training loss: 3.1857594244310983
Validation loss: 2.626136027096291

Epoch: 6| Step: 10
Training loss: 3.5133453437942506
Validation loss: 2.623469410919853

Epoch: 6| Step: 11
Training loss: 2.898840698823542
Validation loss: 2.6244206763442897

Epoch: 6| Step: 12
Training loss: 2.819176949859938
Validation loss: 2.62343494601048

Epoch: 6| Step: 13
Training loss: 2.9349815448655163
Validation loss: 2.6196671580693702

Epoch: 54| Step: 0
Training loss: 3.15383289810315
Validation loss: 2.620821096862976

Epoch: 6| Step: 1
Training loss: 2.707978054121112
Validation loss: 2.6198477470661468

Epoch: 6| Step: 2
Training loss: 2.685383251407459
Validation loss: 2.6176329903188997

Epoch: 6| Step: 3
Training loss: 2.9545247630748603
Validation loss: 2.6147937292079226

Epoch: 6| Step: 4
Training loss: 3.3773805205518412
Validation loss: 2.61620038683148

Epoch: 6| Step: 5
Training loss: 3.191281338398504
Validation loss: 2.6204608379091763

Epoch: 6| Step: 6
Training loss: 2.7984284929549093
Validation loss: 2.638156451326351

Epoch: 6| Step: 7
Training loss: 2.956716140224202
Validation loss: 2.6600666072900054

Epoch: 6| Step: 8
Training loss: 2.9032602005633756
Validation loss: 2.6550167263338325

Epoch: 6| Step: 9
Training loss: 2.859690164175659
Validation loss: 2.656797729229703

Epoch: 6| Step: 10
Training loss: 2.829068021407576
Validation loss: 2.646841571358165

Epoch: 6| Step: 11
Training loss: 3.3565907850530756
Validation loss: 2.6140480495320935

Epoch: 6| Step: 12
Training loss: 2.9284800571715466
Validation loss: 2.6090547987702575

Epoch: 6| Step: 13
Training loss: 2.7365620613163135
Validation loss: 2.612769455949893

Epoch: 55| Step: 0
Training loss: 2.893342261703474
Validation loss: 2.6119789147499834

Epoch: 6| Step: 1
Training loss: 2.877958351305763
Validation loss: 2.6184821379494267

Epoch: 6| Step: 2
Training loss: 2.9556599389034046
Validation loss: 2.6151194797141244

Epoch: 6| Step: 3
Training loss: 2.837459103461821
Validation loss: 2.61559394046332

Epoch: 6| Step: 4
Training loss: 2.958307149708529
Validation loss: 2.6141987989984536

Epoch: 6| Step: 5
Training loss: 3.380178082080462
Validation loss: 2.6116707782459216

Epoch: 6| Step: 6
Training loss: 2.7541037197874236
Validation loss: 2.608054396912158

Epoch: 6| Step: 7
Training loss: 3.1010472712894868
Validation loss: 2.6071659095383484

Epoch: 6| Step: 8
Training loss: 2.9750395956529934
Validation loss: 2.616537647137686

Epoch: 6| Step: 9
Training loss: 3.1515038185538304
Validation loss: 2.624972644591101

Epoch: 6| Step: 10
Training loss: 3.1793502141347454
Validation loss: 2.6270406382510574

Epoch: 6| Step: 11
Training loss: 2.291728267419738
Validation loss: 2.638657742580998

Epoch: 6| Step: 12
Training loss: 2.639882000106691
Validation loss: 2.6452363974865323

Epoch: 6| Step: 13
Training loss: 3.5136683465622918
Validation loss: 2.6547066825077024

Epoch: 56| Step: 0
Training loss: 2.9421674293161675
Validation loss: 2.668066901804344

Epoch: 6| Step: 1
Training loss: 3.254186135077924
Validation loss: 2.642002569420382

Epoch: 6| Step: 2
Training loss: 2.9524703334574403
Validation loss: 2.6318369778261155

Epoch: 6| Step: 3
Training loss: 2.967140644942966
Validation loss: 2.6133415477262374

Epoch: 6| Step: 4
Training loss: 3.014687189731086
Validation loss: 2.6019373940834134

Epoch: 6| Step: 5
Training loss: 3.2896027834806283
Validation loss: 2.594958475157943

Epoch: 6| Step: 6
Training loss: 3.168079680018758
Validation loss: 2.594587947555256

Epoch: 6| Step: 7
Training loss: 2.64913364139822
Validation loss: 2.5997110928465013

Epoch: 6| Step: 8
Training loss: 3.250985509665895
Validation loss: 2.6061415110214154

Epoch: 6| Step: 9
Training loss: 2.8819140349677066
Validation loss: 2.6094040702333796

Epoch: 6| Step: 10
Training loss: 2.8170686702029752
Validation loss: 2.6053889163156887

Epoch: 6| Step: 11
Training loss: 2.4436507260970797
Validation loss: 2.606633833858934

Epoch: 6| Step: 12
Training loss: 2.6549100300977844
Validation loss: 2.6073668147150566

Epoch: 6| Step: 13
Training loss: 3.0181107628115837
Validation loss: 2.604088817458276

Epoch: 57| Step: 0
Training loss: 2.7384236906827226
Validation loss: 2.5956203627405494

Epoch: 6| Step: 1
Training loss: 3.167866395926666
Validation loss: 2.5912087013869782

Epoch: 6| Step: 2
Training loss: 2.8172220220582234
Validation loss: 2.612229234665525

Epoch: 6| Step: 3
Training loss: 2.818582865629883
Validation loss: 2.7251886832889105

Epoch: 6| Step: 4
Training loss: 2.8126381734179517
Validation loss: 2.779364300229661

Epoch: 6| Step: 5
Training loss: 2.6984763332062083
Validation loss: 2.810394062898892

Epoch: 6| Step: 6
Training loss: 3.171863574679238
Validation loss: 2.7338893326640314

Epoch: 6| Step: 7
Training loss: 3.1289009160866676
Validation loss: 2.627139982009736

Epoch: 6| Step: 8
Training loss: 2.8441607838825136
Validation loss: 2.590938878721028

Epoch: 6| Step: 9
Training loss: 3.1151817197744336
Validation loss: 2.5978581195499753

Epoch: 6| Step: 10
Training loss: 2.6618426518871776
Validation loss: 2.612879456571863

Epoch: 6| Step: 11
Training loss: 3.359608628776543
Validation loss: 2.6479455692653473

Epoch: 6| Step: 12
Training loss: 3.151293952027091
Validation loss: 2.646915811866041

Epoch: 6| Step: 13
Training loss: 3.4185363646990825
Validation loss: 2.6111990085054146

Epoch: 58| Step: 0
Training loss: 3.5035578491783266
Validation loss: 2.5999176985759247

Epoch: 6| Step: 1
Training loss: 2.8271248244911993
Validation loss: 2.5973397262490185

Epoch: 6| Step: 2
Training loss: 3.185775290228283
Validation loss: 2.597237786225247

Epoch: 6| Step: 3
Training loss: 2.953125322937317
Validation loss: 2.6241131420707338

Epoch: 6| Step: 4
Training loss: 2.334686046135753
Validation loss: 2.654982834132795

Epoch: 6| Step: 5
Training loss: 3.3975708305829513
Validation loss: 2.6871838241761186

Epoch: 6| Step: 6
Training loss: 2.7536113608184114
Validation loss: 2.6556623905549315

Epoch: 6| Step: 7
Training loss: 2.5801428094418064
Validation loss: 2.634560416051466

Epoch: 6| Step: 8
Training loss: 2.7355431377598345
Validation loss: 2.655102556156398

Epoch: 6| Step: 9
Training loss: 3.063717035857859
Validation loss: 2.66068188507142

Epoch: 6| Step: 10
Training loss: 2.96046657390437
Validation loss: 2.692162699780355

Epoch: 6| Step: 11
Training loss: 3.2448202083959066
Validation loss: 2.619185518707708

Epoch: 6| Step: 12
Training loss: 2.963437919387377
Validation loss: 2.604981884421287

Epoch: 6| Step: 13
Training loss: 2.437110282847643
Validation loss: 2.595750280806367

Epoch: 59| Step: 0
Training loss: 3.0098956932168615
Validation loss: 2.5969364219659496

Epoch: 6| Step: 1
Training loss: 2.9620307776109702
Validation loss: 2.5959687047377433

Epoch: 6| Step: 2
Training loss: 2.5759376263204827
Validation loss: 2.5949667063412902

Epoch: 6| Step: 3
Training loss: 3.1613126131481075
Validation loss: 2.5933106978625635

Epoch: 6| Step: 4
Training loss: 3.456163545323972
Validation loss: 2.5942830085293704

Epoch: 6| Step: 5
Training loss: 3.4584864080784357
Validation loss: 2.5956292202338567

Epoch: 6| Step: 6
Training loss: 3.0357698387384286
Validation loss: 2.601708209496313

Epoch: 6| Step: 7
Training loss: 3.33947480601074
Validation loss: 2.611746470032983

Epoch: 6| Step: 8
Training loss: 2.89328144803381
Validation loss: 2.623459326250255

Epoch: 6| Step: 9
Training loss: 2.830800008486879
Validation loss: 2.6364876755031927

Epoch: 6| Step: 10
Training loss: 3.2229548275510425
Validation loss: 2.6654120363173783

Epoch: 6| Step: 11
Training loss: 1.7982703057464127
Validation loss: 2.6763895271401643

Epoch: 6| Step: 12
Training loss: 2.4048154443682717
Validation loss: 2.6944282116697162

Epoch: 6| Step: 13
Training loss: 2.9456730224787147
Validation loss: 2.723443041727045

Epoch: 60| Step: 0
Training loss: 3.0892342642698
Validation loss: 2.6930321838066167

Epoch: 6| Step: 1
Training loss: 2.694028332839521
Validation loss: 2.670278540839555

Epoch: 6| Step: 2
Training loss: 3.04993273551436
Validation loss: 2.672978225533815

Epoch: 6| Step: 3
Training loss: 3.5317193453647797
Validation loss: 2.6663449757363

Epoch: 6| Step: 4
Training loss: 2.7074094125628445
Validation loss: 2.6558272023460368

Epoch: 6| Step: 5
Training loss: 2.769063417765813
Validation loss: 2.654561473531419

Epoch: 6| Step: 6
Training loss: 3.199053749608359
Validation loss: 2.6493234302415907

Epoch: 6| Step: 7
Training loss: 2.684477770151487
Validation loss: 2.6591910558125273

Epoch: 6| Step: 8
Training loss: 3.1787184379711815
Validation loss: 2.6670463782609724

Epoch: 6| Step: 9
Training loss: 3.4961380769274393
Validation loss: 2.66732647511139

Epoch: 6| Step: 10
Training loss: 3.3854551498964582
Validation loss: 2.6560615776739276

Epoch: 6| Step: 11
Training loss: 2.1032066295364036
Validation loss: 2.6556346120138064

Epoch: 6| Step: 12
Training loss: 2.5405588289209144
Validation loss: 2.668993190409199

Epoch: 6| Step: 13
Training loss: 3.131069849736774
Validation loss: 2.6721011924025633

Epoch: 61| Step: 0
Training loss: 3.0853264698665486
Validation loss: 2.6539395634589034

Epoch: 6| Step: 1
Training loss: 3.0844825115230594
Validation loss: 2.6369936140989823

Epoch: 6| Step: 2
Training loss: 3.0508819055498244
Validation loss: 2.639023630868472

Epoch: 6| Step: 3
Training loss: 2.99972755466587
Validation loss: 2.6171035079690044

Epoch: 6| Step: 4
Training loss: 2.65860374733533
Validation loss: 2.5988284684459773

Epoch: 6| Step: 5
Training loss: 3.3130128571421746
Validation loss: 2.5856772849734084

Epoch: 6| Step: 6
Training loss: 3.218952357773599
Validation loss: 2.577494113331712

Epoch: 6| Step: 7
Training loss: 2.630808443908921
Validation loss: 2.5736490185233505

Epoch: 6| Step: 8
Training loss: 2.9369837530490064
Validation loss: 2.5750134009460472

Epoch: 6| Step: 9
Training loss: 2.8456153201536165
Validation loss: 2.5747958747025126

Epoch: 6| Step: 10
Training loss: 2.6772984122675005
Validation loss: 2.5699372541131242

Epoch: 6| Step: 11
Training loss: 3.1483548061216817
Validation loss: 2.572103955814429

Epoch: 6| Step: 12
Training loss: 2.883850241689346
Validation loss: 2.5753260374718145

Epoch: 6| Step: 13
Training loss: 2.9703872181636655
Validation loss: 2.5803339181504414

Epoch: 62| Step: 0
Training loss: 2.7671135813373264
Validation loss: 2.576964354821117

Epoch: 6| Step: 1
Training loss: 3.103110592473477
Validation loss: 2.5836910826409936

Epoch: 6| Step: 2
Training loss: 3.1749685451120886
Validation loss: 2.5993243590263706

Epoch: 6| Step: 3
Training loss: 3.3553318977203825
Validation loss: 2.6149102358680754

Epoch: 6| Step: 4
Training loss: 2.5059927639502857
Validation loss: 2.615365949659344

Epoch: 6| Step: 5
Training loss: 2.9505017451953623
Validation loss: 2.6067393973469284

Epoch: 6| Step: 6
Training loss: 2.614630061690768
Validation loss: 2.5900886739191917

Epoch: 6| Step: 7
Training loss: 3.310199730600818
Validation loss: 2.5808092370223665

Epoch: 6| Step: 8
Training loss: 3.0983554969666565
Validation loss: 2.57036793513094

Epoch: 6| Step: 9
Training loss: 2.610481621455986
Validation loss: 2.565321403779586

Epoch: 6| Step: 10
Training loss: 2.6789530200719165
Validation loss: 2.561912129037113

Epoch: 6| Step: 11
Training loss: 3.1122748113466416
Validation loss: 2.5614432360105983

Epoch: 6| Step: 12
Training loss: 2.765895851794871
Validation loss: 2.559515126286203

Epoch: 6| Step: 13
Training loss: 2.865524100520968
Validation loss: 2.562373026361457

Epoch: 63| Step: 0
Training loss: 2.5563266173728114
Validation loss: 2.56645152875415

Epoch: 6| Step: 1
Training loss: 3.590852182769229
Validation loss: 2.5599573888440132

Epoch: 6| Step: 2
Training loss: 3.014582320298607
Validation loss: 2.560877971180909

Epoch: 6| Step: 3
Training loss: 2.845779700679124
Validation loss: 2.557610642112812

Epoch: 6| Step: 4
Training loss: 2.5657722235754843
Validation loss: 2.560245072024215

Epoch: 6| Step: 5
Training loss: 2.667921387013252
Validation loss: 2.5589252511734686

Epoch: 6| Step: 6
Training loss: 3.6146367020565155
Validation loss: 2.545519410346204

Epoch: 6| Step: 7
Training loss: 3.1711367795684002
Validation loss: 2.5494674889661595

Epoch: 6| Step: 8
Training loss: 2.8797713782378573
Validation loss: 2.5492861635920967

Epoch: 6| Step: 9
Training loss: 2.621847712269072
Validation loss: 2.55536361708159

Epoch: 6| Step: 10
Training loss: 2.6287488054172123
Validation loss: 2.552338111587689

Epoch: 6| Step: 11
Training loss: 2.6356918030509875
Validation loss: 2.5572881492866406

Epoch: 6| Step: 12
Training loss: 2.8900586372419466
Validation loss: 2.5558935241834697

Epoch: 6| Step: 13
Training loss: 3.136898125903186
Validation loss: 2.547685246791984

Epoch: 64| Step: 0
Training loss: 2.8778529731355893
Validation loss: 2.5592431411693806

Epoch: 6| Step: 1
Training loss: 2.3571261368195655
Validation loss: 2.5584896068643466

Epoch: 6| Step: 2
Training loss: 3.0634698694439955
Validation loss: 2.5636949261754745

Epoch: 6| Step: 3
Training loss: 3.1937768505781774
Validation loss: 2.572360126322525

Epoch: 6| Step: 4
Training loss: 3.504939000446454
Validation loss: 2.58772324085571

Epoch: 6| Step: 5
Training loss: 2.667202081176733
Validation loss: 2.5858223766822226

Epoch: 6| Step: 6
Training loss: 2.819323168079196
Validation loss: 2.6116747262760214

Epoch: 6| Step: 7
Training loss: 2.9785791809305247
Validation loss: 2.6171604390797016

Epoch: 6| Step: 8
Training loss: 2.8543623882672446
Validation loss: 2.617669134831301

Epoch: 6| Step: 9
Training loss: 2.790693986644452
Validation loss: 2.610014501771898

Epoch: 6| Step: 10
Training loss: 3.0783403195431145
Validation loss: 2.589611175606286

Epoch: 6| Step: 11
Training loss: 2.574637348600117
Validation loss: 2.5682979712867673

Epoch: 6| Step: 12
Training loss: 2.855430675832005
Validation loss: 2.5659675167567024

Epoch: 6| Step: 13
Training loss: 3.150529720028787
Validation loss: 2.5610506214209154

Epoch: 65| Step: 0
Training loss: 3.1010275891161423
Validation loss: 2.54355324644906

Epoch: 6| Step: 1
Training loss: 2.6229674326554258
Validation loss: 2.544531743720144

Epoch: 6| Step: 2
Training loss: 2.7245318439349764
Validation loss: 2.548636599225092

Epoch: 6| Step: 3
Training loss: 2.830731450103054
Validation loss: 2.5543638251806655

Epoch: 6| Step: 4
Training loss: 3.0973067982467963
Validation loss: 2.5579662934783314

Epoch: 6| Step: 5
Training loss: 2.685910309215099
Validation loss: 2.56040447920439

Epoch: 6| Step: 6
Training loss: 2.94670416133495
Validation loss: 2.561102617424534

Epoch: 6| Step: 7
Training loss: 2.840076295338258
Validation loss: 2.560411734352503

Epoch: 6| Step: 8
Training loss: 2.7034037010858962
Validation loss: 2.5552947227222433

Epoch: 6| Step: 9
Training loss: 3.2300498164914733
Validation loss: 2.549896334479884

Epoch: 6| Step: 10
Training loss: 3.31509369845759
Validation loss: 2.5472276962934224

Epoch: 6| Step: 11
Training loss: 2.886425535102186
Validation loss: 2.5467627021375834

Epoch: 6| Step: 12
Training loss: 3.2752852221039945
Validation loss: 2.553921642962319

Epoch: 6| Step: 13
Training loss: 2.34450132407462
Validation loss: 2.559084600316966

Epoch: 66| Step: 0
Training loss: 2.945868563587504
Validation loss: 2.569766089799869

Epoch: 6| Step: 1
Training loss: 3.122980609737106
Validation loss: 2.5706448973880804

Epoch: 6| Step: 2
Training loss: 2.5329599138740764
Validation loss: 2.5732156308246354

Epoch: 6| Step: 3
Training loss: 3.032169006096257
Validation loss: 2.5634862911041716

Epoch: 6| Step: 4
Training loss: 2.9169871199633755
Validation loss: 2.558261716844402

Epoch: 6| Step: 5
Training loss: 3.290651929551341
Validation loss: 2.5494912808899595

Epoch: 6| Step: 6
Training loss: 2.7290225585474803
Validation loss: 2.5370472851770565

Epoch: 6| Step: 7
Training loss: 2.5385362285127386
Validation loss: 2.5354998345133324

Epoch: 6| Step: 8
Training loss: 2.6586258977380655
Validation loss: 2.542220474082661

Epoch: 6| Step: 9
Training loss: 2.5292307959213343
Validation loss: 2.539768645707463

Epoch: 6| Step: 10
Training loss: 3.0459511945875906
Validation loss: 2.5409344513293135

Epoch: 6| Step: 11
Training loss: 3.2902661655905114
Validation loss: 2.5364979413245448

Epoch: 6| Step: 12
Training loss: 3.0410276987256304
Validation loss: 2.539161539599378

Epoch: 6| Step: 13
Training loss: 3.2390642312427538
Validation loss: 2.536070456664538

Epoch: 67| Step: 0
Training loss: 3.047216621223
Validation loss: 2.545406386943054

Epoch: 6| Step: 1
Training loss: 3.5151201351901666
Validation loss: 2.5452969270576746

Epoch: 6| Step: 2
Training loss: 2.5837631073182328
Validation loss: 2.550014829522125

Epoch: 6| Step: 3
Training loss: 3.273540049109679
Validation loss: 2.554063551020952

Epoch: 6| Step: 4
Training loss: 2.846282669570121
Validation loss: 2.565892336891156

Epoch: 6| Step: 5
Training loss: 3.0630919215314085
Validation loss: 2.6085975741020024

Epoch: 6| Step: 6
Training loss: 3.050364682017273
Validation loss: 2.5773927585322487

Epoch: 6| Step: 7
Training loss: 2.6448551582527133
Validation loss: 2.5620706630250853

Epoch: 6| Step: 8
Training loss: 2.6450624819840938
Validation loss: 2.5510908754032315

Epoch: 6| Step: 9
Training loss: 2.8884774143259784
Validation loss: 2.5541154383331577

Epoch: 6| Step: 10
Training loss: 3.0685480303835084
Validation loss: 2.550391028927642

Epoch: 6| Step: 11
Training loss: 2.214274015263886
Validation loss: 2.540244167548108

Epoch: 6| Step: 12
Training loss: 2.8091818839669767
Validation loss: 2.5428722944170197

Epoch: 6| Step: 13
Training loss: 2.737694518263422
Validation loss: 2.539171586513328

Epoch: 68| Step: 0
Training loss: 2.621840983046237
Validation loss: 2.5319910528183693

Epoch: 6| Step: 1
Training loss: 2.974481931825498
Validation loss: 2.535596681765647

Epoch: 6| Step: 2
Training loss: 2.675392913483198
Validation loss: 2.533922945202542

Epoch: 6| Step: 3
Training loss: 2.8279312657551365
Validation loss: 2.53512222269984

Epoch: 6| Step: 4
Training loss: 3.0196271044678054
Validation loss: 2.54807184572689

Epoch: 6| Step: 5
Training loss: 3.1373240265757523
Validation loss: 2.5485756236324546

Epoch: 6| Step: 6
Training loss: 2.9923693250585344
Validation loss: 2.5493524348047982

Epoch: 6| Step: 7
Training loss: 3.08230879661662
Validation loss: 2.544291764730144

Epoch: 6| Step: 8
Training loss: 3.0136297869509208
Validation loss: 2.5388788204472617

Epoch: 6| Step: 9
Training loss: 3.425123371213397
Validation loss: 2.5417031817248272

Epoch: 6| Step: 10
Training loss: 2.6924924388839546
Validation loss: 2.5352527928614075

Epoch: 6| Step: 11
Training loss: 2.694275145002143
Validation loss: 2.5430950674472204

Epoch: 6| Step: 12
Training loss: 2.3627349978842425
Validation loss: 2.540436993073529

Epoch: 6| Step: 13
Training loss: 2.88831265726263
Validation loss: 2.531579096892259

Epoch: 69| Step: 0
Training loss: 2.6477919610463987
Validation loss: 2.529692689971291

Epoch: 6| Step: 1
Training loss: 2.9031059732624622
Validation loss: 2.5297054863906183

Epoch: 6| Step: 2
Training loss: 2.617942678332532
Validation loss: 2.527765477268612

Epoch: 6| Step: 3
Training loss: 3.0053715300695254
Validation loss: 2.5276341481064453

Epoch: 6| Step: 4
Training loss: 3.0841711469726123
Validation loss: 2.525671963182439

Epoch: 6| Step: 5
Training loss: 2.9390402469066346
Validation loss: 2.529514935975461

Epoch: 6| Step: 6
Training loss: 2.6934303678211675
Validation loss: 2.534042624732638

Epoch: 6| Step: 7
Training loss: 2.976252341944427
Validation loss: 2.541300558804471

Epoch: 6| Step: 8
Training loss: 2.6455152024975224
Validation loss: 2.551032246728566

Epoch: 6| Step: 9
Training loss: 2.9902584540894486
Validation loss: 2.5667635716253066

Epoch: 6| Step: 10
Training loss: 3.219285198270755
Validation loss: 2.585927023099797

Epoch: 6| Step: 11
Training loss: 3.3928190243522915
Validation loss: 2.6474419676639336

Epoch: 6| Step: 12
Training loss: 2.716492691398126
Validation loss: 2.608483917211311

Epoch: 6| Step: 13
Training loss: 2.608073658148739
Validation loss: 2.573792917706283

Epoch: 70| Step: 0
Training loss: 3.4233556879558638
Validation loss: 2.553854341934664

Epoch: 6| Step: 1
Training loss: 2.7382973576614775
Validation loss: 2.5324770304224096

Epoch: 6| Step: 2
Training loss: 2.8890865046410132
Validation loss: 2.5318715324866865

Epoch: 6| Step: 3
Training loss: 3.056019368275087
Validation loss: 2.537352940098589

Epoch: 6| Step: 4
Training loss: 2.7554754020798815
Validation loss: 2.5366333301869695

Epoch: 6| Step: 5
Training loss: 2.3244823658931346
Validation loss: 2.542812747327787

Epoch: 6| Step: 6
Training loss: 2.910755725535517
Validation loss: 2.539314794382236

Epoch: 6| Step: 7
Training loss: 2.730139716628886
Validation loss: 2.541384033863794

Epoch: 6| Step: 8
Training loss: 3.254290756093455
Validation loss: 2.5385562383809392

Epoch: 6| Step: 9
Training loss: 3.2716241516315065
Validation loss: 2.536670161935539

Epoch: 6| Step: 10
Training loss: 2.8678978811728877
Validation loss: 2.531540307995048

Epoch: 6| Step: 11
Training loss: 2.7447829611324726
Validation loss: 2.526293058649335

Epoch: 6| Step: 12
Training loss: 2.879026827105195
Validation loss: 2.5245051049346245

Epoch: 6| Step: 13
Training loss: 2.700855250361363
Validation loss: 2.520108197906076

Epoch: 71| Step: 0
Training loss: 2.884874387019621
Validation loss: 2.526345238280542

Epoch: 6| Step: 1
Training loss: 3.231592723150662
Validation loss: 2.5343422241931997

Epoch: 6| Step: 2
Training loss: 3.0656451210038274
Validation loss: 2.574553527778463

Epoch: 6| Step: 3
Training loss: 2.810474683776859
Validation loss: 2.5567710377745008

Epoch: 6| Step: 4
Training loss: 3.0491781284325015
Validation loss: 2.5558026910841414

Epoch: 6| Step: 5
Training loss: 2.6122021007894185
Validation loss: 2.5377513989493456

Epoch: 6| Step: 6
Training loss: 2.9052168127359974
Validation loss: 2.5226858747942074

Epoch: 6| Step: 7
Training loss: 2.4508497049233857
Validation loss: 2.5184343366013398

Epoch: 6| Step: 8
Training loss: 2.998459738469512
Validation loss: 2.5214081484039212

Epoch: 6| Step: 9
Training loss: 2.458282103785982
Validation loss: 2.5204941495873823

Epoch: 6| Step: 10
Training loss: 2.404982195687167
Validation loss: 2.5215770451847055

Epoch: 6| Step: 11
Training loss: 3.0210386710698707
Validation loss: 2.5311446426850175

Epoch: 6| Step: 12
Training loss: 3.6381801533020406
Validation loss: 2.5437673148429893

Epoch: 6| Step: 13
Training loss: 2.8201225406995647
Validation loss: 2.5556412975675675

Epoch: 72| Step: 0
Training loss: 2.944146611087519
Validation loss: 2.5935367813370043

Epoch: 6| Step: 1
Training loss: 2.8674446011474073
Validation loss: 2.607492395694561

Epoch: 6| Step: 2
Training loss: 2.9253967602940905
Validation loss: 2.643037427398333

Epoch: 6| Step: 3
Training loss: 1.9516910018945675
Validation loss: 2.633786932774405

Epoch: 6| Step: 4
Training loss: 3.4653065403568752
Validation loss: 2.626830951328903

Epoch: 6| Step: 5
Training loss: 2.317983569543649
Validation loss: 2.5952784984779185

Epoch: 6| Step: 6
Training loss: 3.088464711320382
Validation loss: 2.5949484404735954

Epoch: 6| Step: 7
Training loss: 2.499703294313313
Validation loss: 2.5702138249025333

Epoch: 6| Step: 8
Training loss: 2.892361835684704
Validation loss: 2.546014817288462

Epoch: 6| Step: 9
Training loss: 3.2077047219359023
Validation loss: 2.545043161721952

Epoch: 6| Step: 10
Training loss: 3.0201369611996567
Validation loss: 2.5435428882666655

Epoch: 6| Step: 11
Training loss: 2.8741593168376127
Validation loss: 2.546463552206234

Epoch: 6| Step: 12
Training loss: 3.4124344145232817
Validation loss: 2.5493832946131887

Epoch: 6| Step: 13
Training loss: 3.0061366577353845
Validation loss: 2.5522081804575034

Epoch: 73| Step: 0
Training loss: 3.0692054363960755
Validation loss: 2.5509568387512056

Epoch: 6| Step: 1
Training loss: 3.1295812976356348
Validation loss: 2.5493972109693512

Epoch: 6| Step: 2
Training loss: 3.1056615997510044
Validation loss: 2.544921302822104

Epoch: 6| Step: 3
Training loss: 2.5214711372861265
Validation loss: 2.5333569244113177

Epoch: 6| Step: 4
Training loss: 2.8490818887217997
Validation loss: 2.5292932382781492

Epoch: 6| Step: 5
Training loss: 2.968623750913427
Validation loss: 2.530370283170611

Epoch: 6| Step: 6
Training loss: 2.6750879433694776
Validation loss: 2.528116297585516

Epoch: 6| Step: 7
Training loss: 2.604284746671924
Validation loss: 2.527770249039535

Epoch: 6| Step: 8
Training loss: 2.5957852387195284
Validation loss: 2.536983174841267

Epoch: 6| Step: 9
Training loss: 2.7701933463474098
Validation loss: 2.5480333798379657

Epoch: 6| Step: 10
Training loss: 3.374465052276892
Validation loss: 2.5727370516097396

Epoch: 6| Step: 11
Training loss: 3.083170362409865
Validation loss: 2.552508671876506

Epoch: 6| Step: 12
Training loss: 2.734664291337406
Validation loss: 2.5474896389202906

Epoch: 6| Step: 13
Training loss: 3.3469112105774865
Validation loss: 2.541805891570751

Epoch: 74| Step: 0
Training loss: 2.8761831419865387
Validation loss: 2.5309808776140614

Epoch: 6| Step: 1
Training loss: 2.500128742717777
Validation loss: 2.527592897405993

Epoch: 6| Step: 2
Training loss: 2.613497464254845
Validation loss: 2.522128227599264

Epoch: 6| Step: 3
Training loss: 2.6410350594033316
Validation loss: 2.5215494319650187

Epoch: 6| Step: 4
Training loss: 2.959521435636296
Validation loss: 2.5247315416280602

Epoch: 6| Step: 5
Training loss: 3.050847520487007
Validation loss: 2.5216057317056473

Epoch: 6| Step: 6
Training loss: 2.5587429323457536
Validation loss: 2.531045537540275

Epoch: 6| Step: 7
Training loss: 3.4640793155989864
Validation loss: 2.560231635191805

Epoch: 6| Step: 8
Training loss: 3.3456015050880117
Validation loss: 2.590808224132182

Epoch: 6| Step: 9
Training loss: 2.8277561516258545
Validation loss: 2.623879871956319

Epoch: 6| Step: 10
Training loss: 2.845185305388222
Validation loss: 2.668397977526223

Epoch: 6| Step: 11
Training loss: 4.122227748674068
Validation loss: 2.654429032210167

Epoch: 6| Step: 12
Training loss: 1.9645932836135656
Validation loss: 2.5367883121986092

Epoch: 6| Step: 13
Training loss: 2.247883330891378
Validation loss: 2.5056834293673433

Epoch: 75| Step: 0
Training loss: 3.15383607315256
Validation loss: 2.5319210911476473

Epoch: 6| Step: 1
Training loss: 3.414664418388718
Validation loss: 2.572748136254778

Epoch: 6| Step: 2
Training loss: 3.456039924514598
Validation loss: 2.577202738811736

Epoch: 6| Step: 3
Training loss: 2.761765022375792
Validation loss: 2.5405932203342365

Epoch: 6| Step: 4
Training loss: 2.522361124259236
Validation loss: 2.537075114204173

Epoch: 6| Step: 5
Training loss: 2.72729456126981
Validation loss: 2.5253833753231794

Epoch: 6| Step: 6
Training loss: 3.0591147260448555
Validation loss: 2.5115895071632357

Epoch: 6| Step: 7
Training loss: 2.770362890552269
Validation loss: 2.50666560974941

Epoch: 6| Step: 8
Training loss: 3.0544611464049534
Validation loss: 2.5346563752007256

Epoch: 6| Step: 9
Training loss: 2.7827461590321008
Validation loss: 2.631503029555617

Epoch: 6| Step: 10
Training loss: 3.0143616555061117
Validation loss: 2.6758841689780852

Epoch: 6| Step: 11
Training loss: 2.8127149711681065
Validation loss: 2.6475084050699977

Epoch: 6| Step: 12
Training loss: 2.8939374759987877
Validation loss: 2.6056591995689886

Epoch: 6| Step: 13
Training loss: 2.6758303449818586
Validation loss: 2.628165494270246

Epoch: 76| Step: 0
Training loss: 2.9482329685285644
Validation loss: 2.579207054125596

Epoch: 6| Step: 1
Training loss: 2.893927260174764
Validation loss: 2.541492713073832

Epoch: 6| Step: 2
Training loss: 3.127783184449616
Validation loss: 2.5206510016342984

Epoch: 6| Step: 3
Training loss: 2.9148625561616925
Validation loss: 2.519125828355197

Epoch: 6| Step: 4
Training loss: 2.42422145261869
Validation loss: 2.52401759951612

Epoch: 6| Step: 5
Training loss: 2.8423629563979547
Validation loss: 2.5352971193162674

Epoch: 6| Step: 6
Training loss: 3.331323367343317
Validation loss: 2.5288582119292533

Epoch: 6| Step: 7
Training loss: 2.768945887677825
Validation loss: 2.533143684588696

Epoch: 6| Step: 8
Training loss: 3.204172251629933
Validation loss: 2.534179946476099

Epoch: 6| Step: 9
Training loss: 2.8249385016845165
Validation loss: 2.5409469520175247

Epoch: 6| Step: 10
Training loss: 3.0503760934552706
Validation loss: 2.5454199483646716

Epoch: 6| Step: 11
Training loss: 2.721291505131727
Validation loss: 2.5517412084843594

Epoch: 6| Step: 12
Training loss: 2.911857200055598
Validation loss: 2.5567602247769092

Epoch: 6| Step: 13
Training loss: 2.6679139697146503
Validation loss: 2.5602986033680346

Epoch: 77| Step: 0
Training loss: 2.9563105119314756
Validation loss: 2.5813648429441955

Epoch: 6| Step: 1
Training loss: 3.0287016548835632
Validation loss: 2.6125085702096014

Epoch: 6| Step: 2
Training loss: 2.936447604347991
Validation loss: 2.6385301402962

Epoch: 6| Step: 3
Training loss: 3.3008163540570457
Validation loss: 2.6440018708557527

Epoch: 6| Step: 4
Training loss: 2.5835484650977207
Validation loss: 2.6400074987687216

Epoch: 6| Step: 5
Training loss: 2.3563387704817904
Validation loss: 2.624917434823684

Epoch: 6| Step: 6
Training loss: 3.0587507380588703
Validation loss: 2.617186382344276

Epoch: 6| Step: 7
Training loss: 3.008091187880529
Validation loss: 2.576076087426293

Epoch: 6| Step: 8
Training loss: 2.723735053768527
Validation loss: 2.567106405074344

Epoch: 6| Step: 9
Training loss: 2.926746896615863
Validation loss: 2.54884513321569

Epoch: 6| Step: 10
Training loss: 2.785428112827275
Validation loss: 2.540237965943106

Epoch: 6| Step: 11
Training loss: 3.124943694561111
Validation loss: 2.537058536364028

Epoch: 6| Step: 12
Training loss: 3.1718073494748413
Validation loss: 2.532249754583841

Epoch: 6| Step: 13
Training loss: 2.230350203963072
Validation loss: 2.5291448194819086

Epoch: 78| Step: 0
Training loss: 2.7389989502797896
Validation loss: 2.5296625628483658

Epoch: 6| Step: 1
Training loss: 2.79065801893566
Validation loss: 2.5325421876453302

Epoch: 6| Step: 2
Training loss: 3.21120331121102
Validation loss: 2.5359287750619934

Epoch: 6| Step: 3
Training loss: 3.1887114971353068
Validation loss: 2.535560665526961

Epoch: 6| Step: 4
Training loss: 2.485958146753414
Validation loss: 2.5394341743740463

Epoch: 6| Step: 5
Training loss: 2.9910182012771327
Validation loss: 2.543740469598323

Epoch: 6| Step: 6
Training loss: 3.206330867587793
Validation loss: 2.5552322004189563

Epoch: 6| Step: 7
Training loss: 2.328906651304582
Validation loss: 2.5540052917176004

Epoch: 6| Step: 8
Training loss: 3.434724415436784
Validation loss: 2.5599805720470776

Epoch: 6| Step: 9
Training loss: 2.793998048425319
Validation loss: 2.553828371665718

Epoch: 6| Step: 10
Training loss: 2.895652564098921
Validation loss: 2.559701497427429

Epoch: 6| Step: 11
Training loss: 2.883667857732701
Validation loss: 2.5737456066265

Epoch: 6| Step: 12
Training loss: 2.2893081897731573
Validation loss: 2.558550708906272

Epoch: 6| Step: 13
Training loss: 2.9056102089475684
Validation loss: 2.5523341189820656

Epoch: 79| Step: 0
Training loss: 2.7469458526396155
Validation loss: 2.5563641130731285

Epoch: 6| Step: 1
Training loss: 2.676382089247812
Validation loss: 2.59506677066553

Epoch: 6| Step: 2
Training loss: 2.846668632054004
Validation loss: 2.5956779615858636

Epoch: 6| Step: 3
Training loss: 2.931261296037003
Validation loss: 2.6021895813976887

Epoch: 6| Step: 4
Training loss: 2.5182445463850307
Validation loss: 2.591510822728005

Epoch: 6| Step: 5
Training loss: 3.699443161792924
Validation loss: 2.6109177261730667

Epoch: 6| Step: 6
Training loss: 2.5500090804592843
Validation loss: 2.5969994732990167

Epoch: 6| Step: 7
Training loss: 3.3684988632438047
Validation loss: 2.5846243902762502

Epoch: 6| Step: 8
Training loss: 3.3737400670168594
Validation loss: 2.5952387111837645

Epoch: 6| Step: 9
Training loss: 2.6718927572452236
Validation loss: 2.601676445957249

Epoch: 6| Step: 10
Training loss: 3.1214148746525425
Validation loss: 2.605252582848838

Epoch: 6| Step: 11
Training loss: 3.0270011461883986
Validation loss: 2.5900994546758396

Epoch: 6| Step: 12
Training loss: 2.5824282711736326
Validation loss: 2.581592484991568

Epoch: 6| Step: 13
Training loss: 1.9287568601138925
Validation loss: 2.575215976282245

Epoch: 80| Step: 0
Training loss: 3.17250843957811
Validation loss: 2.5761126259285914

Epoch: 6| Step: 1
Training loss: 2.598305619609731
Validation loss: 2.5849082054989303

Epoch: 6| Step: 2
Training loss: 3.6760903693662863
Validation loss: 2.5968558965410526

Epoch: 6| Step: 3
Training loss: 3.0959726691604494
Validation loss: 2.585365516924966

Epoch: 6| Step: 4
Training loss: 3.4274327680698087
Validation loss: 2.5661114820447124

Epoch: 6| Step: 5
Training loss: 2.7193969307648382
Validation loss: 2.560285341044602

Epoch: 6| Step: 6
Training loss: 3.312583490435149
Validation loss: 2.5597505603451145

Epoch: 6| Step: 7
Training loss: 1.7326097182283906
Validation loss: 2.5568453608551907

Epoch: 6| Step: 8
Training loss: 3.3943008678294353
Validation loss: 2.55416709674934

Epoch: 6| Step: 9
Training loss: 2.324836200153453
Validation loss: 2.5460224346488416

Epoch: 6| Step: 10
Training loss: 2.818592762420615
Validation loss: 2.543995670886725

Epoch: 6| Step: 11
Training loss: 2.656555158252486
Validation loss: 2.5427285488883595

Epoch: 6| Step: 12
Training loss: 2.2525693210854056
Validation loss: 2.538092432232094

Epoch: 6| Step: 13
Training loss: 3.2590729175708018
Validation loss: 2.5363889682497156

Epoch: 81| Step: 0
Training loss: 2.699818965352809
Validation loss: 2.540467180120305

Epoch: 6| Step: 1
Training loss: 3.1289109743156436
Validation loss: 2.538914197908683

Epoch: 6| Step: 2
Training loss: 2.429392904103271
Validation loss: 2.547384251812877

Epoch: 6| Step: 3
Training loss: 3.164250573114134
Validation loss: 2.550679607137938

Epoch: 6| Step: 4
Training loss: 2.916027398670136
Validation loss: 2.5646831507787184

Epoch: 6| Step: 5
Training loss: 3.162226994608339
Validation loss: 2.5826108863743777

Epoch: 6| Step: 6
Training loss: 3.172157462936783
Validation loss: 2.599153277627241

Epoch: 6| Step: 7
Training loss: 3.2349478541420966
Validation loss: 2.610750903192505

Epoch: 6| Step: 8
Training loss: 2.616371323587894
Validation loss: 2.590127273413313

Epoch: 6| Step: 9
Training loss: 2.8626533433911816
Validation loss: 2.5665388555177477

Epoch: 6| Step: 10
Training loss: 2.7652291914471916
Validation loss: 2.5592270194646165

Epoch: 6| Step: 11
Training loss: 2.5150721161591374
Validation loss: 2.5568308353121325

Epoch: 6| Step: 12
Training loss: 2.5886868615880134
Validation loss: 2.546295636627453

Epoch: 6| Step: 13
Training loss: 3.3911235108849485
Validation loss: 2.5430790661595184

Epoch: 82| Step: 0
Training loss: 3.0764505702126783
Validation loss: 2.543502300758234

Epoch: 6| Step: 1
Training loss: 3.005154314442651
Validation loss: 2.529901902849173

Epoch: 6| Step: 2
Training loss: 2.5579301978303977
Validation loss: 2.527680247155902

Epoch: 6| Step: 3
Training loss: 2.4812508378880236
Validation loss: 2.5279147305493486

Epoch: 6| Step: 4
Training loss: 2.8703660522847754
Validation loss: 2.530065930280934

Epoch: 6| Step: 5
Training loss: 3.1674840441078365
Validation loss: 2.526493910831947

Epoch: 6| Step: 6
Training loss: 2.997941582536225
Validation loss: 2.5136060980765706

Epoch: 6| Step: 7
Training loss: 3.081636546187011
Validation loss: 2.503909592377243

Epoch: 6| Step: 8
Training loss: 2.2009197046659197
Validation loss: 2.49339964091907

Epoch: 6| Step: 9
Training loss: 2.9779933584125104
Validation loss: 2.4869463710923654

Epoch: 6| Step: 10
Training loss: 3.066633898794944
Validation loss: 2.4891577461697185

Epoch: 6| Step: 11
Training loss: 2.9267455932239916
Validation loss: 2.511419384414717

Epoch: 6| Step: 12
Training loss: 2.8435834898774837
Validation loss: 2.5609175174923102

Epoch: 6| Step: 13
Training loss: 3.162823469785405
Validation loss: 2.580710381150315

Epoch: 83| Step: 0
Training loss: 3.0079453476141147
Validation loss: 2.5030203565797144

Epoch: 6| Step: 1
Training loss: 2.226043747820764
Validation loss: 2.4911149703761133

Epoch: 6| Step: 2
Training loss: 3.0683203681977167
Validation loss: 2.486434145088646

Epoch: 6| Step: 3
Training loss: 2.677353980092434
Validation loss: 2.493128568495133

Epoch: 6| Step: 4
Training loss: 2.4217608024991826
Validation loss: 2.5022884774729053

Epoch: 6| Step: 5
Training loss: 2.902993787873836
Validation loss: 2.5043711503064072

Epoch: 6| Step: 6
Training loss: 3.3082227622771465
Validation loss: 2.508264575951121

Epoch: 6| Step: 7
Training loss: 2.50110134661001
Validation loss: 2.510889874638959

Epoch: 6| Step: 8
Training loss: 3.03147368244851
Validation loss: 2.512200035384361

Epoch: 6| Step: 9
Training loss: 3.0776574413891624
Validation loss: 2.5121486997988094

Epoch: 6| Step: 10
Training loss: 3.110835666800386
Validation loss: 2.5145819999917687

Epoch: 6| Step: 11
Training loss: 3.1293772748904973
Validation loss: 2.5159295560842843

Epoch: 6| Step: 12
Training loss: 2.8399490273965218
Validation loss: 2.5130576309824613

Epoch: 6| Step: 13
Training loss: 3.3882730650588537
Validation loss: 2.5130158706727403

Epoch: 84| Step: 0
Training loss: 3.0579438865009085
Validation loss: 2.509485970802851

Epoch: 6| Step: 1
Training loss: 2.5655477124187858
Validation loss: 2.509430968333797

Epoch: 6| Step: 2
Training loss: 3.0368195324919793
Validation loss: 2.5060887608074984

Epoch: 6| Step: 3
Training loss: 3.008632320294506
Validation loss: 2.502924439206988

Epoch: 6| Step: 4
Training loss: 3.3128083283500938
Validation loss: 2.4993277948353527

Epoch: 6| Step: 5
Training loss: 3.093209267572766
Validation loss: 2.49850252484455

Epoch: 6| Step: 6
Training loss: 2.943128509681409
Validation loss: 2.498853714983757

Epoch: 6| Step: 7
Training loss: 3.194433711674301
Validation loss: 2.4986212568912296

Epoch: 6| Step: 8
Training loss: 2.2191475525492557
Validation loss: 2.4969158416865436

Epoch: 6| Step: 9
Training loss: 2.980353236928488
Validation loss: 2.5053829097921434

Epoch: 6| Step: 10
Training loss: 2.294285358869372
Validation loss: 2.536891985001683

Epoch: 6| Step: 11
Training loss: 3.071817199225329
Validation loss: 2.590258245905762

Epoch: 6| Step: 12
Training loss: 2.6106001667415137
Validation loss: 2.690470053800605

Epoch: 6| Step: 13
Training loss: 2.416165420464893
Validation loss: 2.7858562912021894

Epoch: 85| Step: 0
Training loss: 3.0332584609408313
Validation loss: 2.798742550175981

Epoch: 6| Step: 1
Training loss: 2.678096910861301
Validation loss: 2.6582093387904937

Epoch: 6| Step: 2
Training loss: 2.880272384584384
Validation loss: 2.572298133922423

Epoch: 6| Step: 3
Training loss: 3.0224525759678365
Validation loss: 2.5150497625699035

Epoch: 6| Step: 4
Training loss: 2.9293847499821073
Validation loss: 2.486805783394495

Epoch: 6| Step: 5
Training loss: 3.2727350104847384
Validation loss: 2.4955252223759996

Epoch: 6| Step: 6
Training loss: 2.8163761978556594
Validation loss: 2.498040319255177

Epoch: 6| Step: 7
Training loss: 3.1545484129582264
Validation loss: 2.4980788683888444

Epoch: 6| Step: 8
Training loss: 3.2837166370429376
Validation loss: 2.49871928214608

Epoch: 6| Step: 9
Training loss: 2.7063107102700643
Validation loss: 2.499260435129313

Epoch: 6| Step: 10
Training loss: 2.4868937266321325
Validation loss: 2.499272331862005

Epoch: 6| Step: 11
Training loss: 2.657225665253891
Validation loss: 2.4991126013462917

Epoch: 6| Step: 12
Training loss: 2.7512791866295143
Validation loss: 2.4915321607917154

Epoch: 6| Step: 13
Training loss: 3.2401649141138322
Validation loss: 2.4944953572081996

Epoch: 86| Step: 0
Training loss: 2.4989929078098023
Validation loss: 2.4981898163372094

Epoch: 6| Step: 1
Training loss: 3.415202005200882
Validation loss: 2.5028588151543554

Epoch: 6| Step: 2
Training loss: 2.61952474054608
Validation loss: 2.5148649229836777

Epoch: 6| Step: 3
Training loss: 2.70273618161885
Validation loss: 2.5142292432580406

Epoch: 6| Step: 4
Training loss: 3.0090573595791263
Validation loss: 2.5281835506279906

Epoch: 6| Step: 5
Training loss: 3.1771462522853184
Validation loss: 2.5322845149770123

Epoch: 6| Step: 6
Training loss: 2.69075781730318
Validation loss: 2.538377203329108

Epoch: 6| Step: 7
Training loss: 2.7323396791715866
Validation loss: 2.547252818004546

Epoch: 6| Step: 8
Training loss: 2.9003955571296447
Validation loss: 2.5445300249078664

Epoch: 6| Step: 9
Training loss: 2.8075258137305137
Validation loss: 2.5792911277521933

Epoch: 6| Step: 10
Training loss: 2.568166840157445
Validation loss: 2.603427629180984

Epoch: 6| Step: 11
Training loss: 3.5612885941904286
Validation loss: 2.6191040994770485

Epoch: 6| Step: 12
Training loss: 2.728710563538957
Validation loss: 2.609385158751644

Epoch: 6| Step: 13
Training loss: 2.624140371621138
Validation loss: 2.5906996617977676

Epoch: 87| Step: 0
Training loss: 3.181421055719732
Validation loss: 2.553515543237079

Epoch: 6| Step: 1
Training loss: 3.1319262233146765
Validation loss: 2.523431175816043

Epoch: 6| Step: 2
Training loss: 2.805016543497677
Validation loss: 2.5175677994537558

Epoch: 6| Step: 3
Training loss: 2.7138801895604336
Validation loss: 2.512305672871508

Epoch: 6| Step: 4
Training loss: 2.459743440166651
Validation loss: 2.5051873206445565

Epoch: 6| Step: 5
Training loss: 3.025179260238902
Validation loss: 2.4924466519173945

Epoch: 6| Step: 6
Training loss: 2.6898389884381415
Validation loss: 2.496438181966806

Epoch: 6| Step: 7
Training loss: 2.5466634276337854
Validation loss: 2.490278321983673

Epoch: 6| Step: 8
Training loss: 2.4541557721952407
Validation loss: 2.488495322830562

Epoch: 6| Step: 9
Training loss: 2.891639984916546
Validation loss: 2.4879601762859185

Epoch: 6| Step: 10
Training loss: 3.073387566816827
Validation loss: 2.486248825307979

Epoch: 6| Step: 11
Training loss: 2.821675401896794
Validation loss: 2.4815569545305167

Epoch: 6| Step: 12
Training loss: 3.1922845273949525
Validation loss: 2.4823807234463593

Epoch: 6| Step: 13
Training loss: 3.017331762040634
Validation loss: 2.4795772894578123

Epoch: 88| Step: 0
Training loss: 2.6086718131441193
Validation loss: 2.47897141486467

Epoch: 6| Step: 1
Training loss: 1.8690693202912392
Validation loss: 2.480038869393082

Epoch: 6| Step: 2
Training loss: 2.9391051431793955
Validation loss: 2.4831431125913497

Epoch: 6| Step: 3
Training loss: 3.174636765975949
Validation loss: 2.4795431859562815

Epoch: 6| Step: 4
Training loss: 2.66701811222982
Validation loss: 2.4823467095806273

Epoch: 6| Step: 5
Training loss: 3.3570399485993163
Validation loss: 2.480585166234671

Epoch: 6| Step: 6
Training loss: 2.9455831792895073
Validation loss: 2.472397547517126

Epoch: 6| Step: 7
Training loss: 2.520410570576727
Validation loss: 2.4681149963196614

Epoch: 6| Step: 8
Training loss: 3.294297498914228
Validation loss: 2.4715556081169634

Epoch: 6| Step: 9
Training loss: 3.1121353855054
Validation loss: 2.4691064135203136

Epoch: 6| Step: 10
Training loss: 2.847541545132805
Validation loss: 2.469418253656052

Epoch: 6| Step: 11
Training loss: 2.630682652576493
Validation loss: 2.47057598888889

Epoch: 6| Step: 12
Training loss: 3.0170185249222654
Validation loss: 2.4737584784739473

Epoch: 6| Step: 13
Training loss: 2.713394678470558
Validation loss: 2.4700197334957665

Epoch: 89| Step: 0
Training loss: 3.0004734619370614
Validation loss: 2.473463365729742

Epoch: 6| Step: 1
Training loss: 2.6843120385492245
Validation loss: 2.493848858643889

Epoch: 6| Step: 2
Training loss: 3.062253669641273
Validation loss: 2.5063833266747673

Epoch: 6| Step: 3
Training loss: 2.475222540974822
Validation loss: 2.5385355316890097

Epoch: 6| Step: 4
Training loss: 2.588871239623385
Validation loss: 2.554393915890552

Epoch: 6| Step: 5
Training loss: 3.117661060128224
Validation loss: 2.5451502135754085

Epoch: 6| Step: 6
Training loss: 3.0373900844953425
Validation loss: 2.531640315780222

Epoch: 6| Step: 7
Training loss: 3.2599651442460575
Validation loss: 2.5155900797238346

Epoch: 6| Step: 8
Training loss: 2.847995816302709
Validation loss: 2.501110319485058

Epoch: 6| Step: 9
Training loss: 3.263221695977331
Validation loss: 2.494422605964485

Epoch: 6| Step: 10
Training loss: 2.508146174683912
Validation loss: 2.4794031411119724

Epoch: 6| Step: 11
Training loss: 2.7289240100718417
Validation loss: 2.469059844879192

Epoch: 6| Step: 12
Training loss: 2.3159350065424564
Validation loss: 2.474090430333476

Epoch: 6| Step: 13
Training loss: 2.7156027631650344
Validation loss: 2.4815347887208477

Epoch: 90| Step: 0
Training loss: 2.723203147132839
Validation loss: 2.490780724742377

Epoch: 6| Step: 1
Training loss: 2.6067002344368513
Validation loss: 2.494357681693851

Epoch: 6| Step: 2
Training loss: 2.6112215737949915
Validation loss: 2.511962848143663

Epoch: 6| Step: 3
Training loss: 2.6504537733703164
Validation loss: 2.509715944480519

Epoch: 6| Step: 4
Training loss: 3.028145370178679
Validation loss: 2.5092356926797135

Epoch: 6| Step: 5
Training loss: 3.1200077616766215
Validation loss: 2.50050997300992

Epoch: 6| Step: 6
Training loss: 2.9943610282544917
Validation loss: 2.4962007202231478

Epoch: 6| Step: 7
Training loss: 3.1537686404638565
Validation loss: 2.486437889863385

Epoch: 6| Step: 8
Training loss: 3.1269677642536773
Validation loss: 2.4850756549210895

Epoch: 6| Step: 9
Training loss: 2.6897821716829626
Validation loss: 2.4871961019142765

Epoch: 6| Step: 10
Training loss: 2.916690572004899
Validation loss: 2.4891606979270815

Epoch: 6| Step: 11
Training loss: 2.8883093554218164
Validation loss: 2.5138670701822567

Epoch: 6| Step: 12
Training loss: 3.032583985325346
Validation loss: 2.529419144059286

Epoch: 6| Step: 13
Training loss: 2.6452203075479113
Validation loss: 2.5360247365688986

Epoch: 91| Step: 0
Training loss: 3.521372526215281
Validation loss: 2.5495022011382007

Epoch: 6| Step: 1
Training loss: 3.2852550949847923
Validation loss: 2.5901870045957893

Epoch: 6| Step: 2
Training loss: 2.1277669955589915
Validation loss: 2.5994738982052827

Epoch: 6| Step: 3
Training loss: 3.0253617819093948
Validation loss: 2.579361527509714

Epoch: 6| Step: 4
Training loss: 2.517742900324374
Validation loss: 2.5757509738398157

Epoch: 6| Step: 5
Training loss: 2.9067808917405333
Validation loss: 2.5462902129262095

Epoch: 6| Step: 6
Training loss: 2.2289718709191635
Validation loss: 2.5293622428659317

Epoch: 6| Step: 7
Training loss: 3.182684458431039
Validation loss: 2.4980075854290527

Epoch: 6| Step: 8
Training loss: 2.53021266073645
Validation loss: 2.493271333215224

Epoch: 6| Step: 9
Training loss: 3.194452221257423
Validation loss: 2.4849537284806544

Epoch: 6| Step: 10
Training loss: 2.405964128431383
Validation loss: 2.4791134395729744

Epoch: 6| Step: 11
Training loss: 3.0774468773875023
Validation loss: 2.4763405888293866

Epoch: 6| Step: 12
Training loss: 2.4634870613181103
Validation loss: 2.4724432061570565

Epoch: 6| Step: 13
Training loss: 3.128752324846039
Validation loss: 2.471412591524437

Epoch: 92| Step: 0
Training loss: 2.8416156514381123
Validation loss: 2.4702520882674

Epoch: 6| Step: 1
Training loss: 2.655499520590697
Validation loss: 2.4728905600264066

Epoch: 6| Step: 2
Training loss: 3.1856100425795666
Validation loss: 2.4710050392664056

Epoch: 6| Step: 3
Training loss: 2.628143335883988
Validation loss: 2.4683522960305053

Epoch: 6| Step: 4
Training loss: 2.8041331984028086
Validation loss: 2.474417565581059

Epoch: 6| Step: 5
Training loss: 2.7548489735880355
Validation loss: 2.4746773217859928

Epoch: 6| Step: 6
Training loss: 2.929555661096058
Validation loss: 2.4803702411981448

Epoch: 6| Step: 7
Training loss: 2.548104112477291
Validation loss: 2.4782234683688715

Epoch: 6| Step: 8
Training loss: 3.228094370014413
Validation loss: 2.47692167685251

Epoch: 6| Step: 9
Training loss: 3.0430013436957886
Validation loss: 2.475495526512555

Epoch: 6| Step: 10
Training loss: 2.4903777915197183
Validation loss: 2.478241992501935

Epoch: 6| Step: 11
Training loss: 2.8063596028629427
Validation loss: 2.4850506474227423

Epoch: 6| Step: 12
Training loss: 2.9697297738185533
Validation loss: 2.5091933047839237

Epoch: 6| Step: 13
Training loss: 2.487610539419565
Validation loss: 2.517586986199312

Epoch: 93| Step: 0
Training loss: 2.9586636712550636
Validation loss: 2.504102442906788

Epoch: 6| Step: 1
Training loss: 3.1468438216088286
Validation loss: 2.509753878111761

Epoch: 6| Step: 2
Training loss: 2.9372866938636144
Validation loss: 2.5190541059714064

Epoch: 6| Step: 3
Training loss: 3.2489101343145905
Validation loss: 2.530834707295503

Epoch: 6| Step: 4
Training loss: 2.4248131434231337
Validation loss: 2.5343282393298945

Epoch: 6| Step: 5
Training loss: 2.5141145898746355
Validation loss: 2.5304022498274024

Epoch: 6| Step: 6
Training loss: 2.8807790971336096
Validation loss: 2.5230423619748965

Epoch: 6| Step: 7
Training loss: 2.838008912280164
Validation loss: 2.506543590047527

Epoch: 6| Step: 8
Training loss: 3.2221483974842244
Validation loss: 2.4961790213131487

Epoch: 6| Step: 9
Training loss: 2.706359868098982
Validation loss: 2.4810363869343437

Epoch: 6| Step: 10
Training loss: 2.845590519820823
Validation loss: 2.4714207111173288

Epoch: 6| Step: 11
Training loss: 2.3286441505771314
Validation loss: 2.471906056645969

Epoch: 6| Step: 12
Training loss: 2.5425961363554896
Validation loss: 2.47398053110178

Epoch: 6| Step: 13
Training loss: 2.910216711043495
Validation loss: 2.474631859762295

Epoch: 94| Step: 0
Training loss: 2.48459197242519
Validation loss: 2.470860022056061

Epoch: 6| Step: 1
Training loss: 2.8646623265327715
Validation loss: 2.462979334720292

Epoch: 6| Step: 2
Training loss: 2.393919824696557
Validation loss: 2.4653582957886573

Epoch: 6| Step: 3
Training loss: 2.5151349650698847
Validation loss: 2.4732967422555303

Epoch: 6| Step: 4
Training loss: 2.8419653354278336
Validation loss: 2.4910094376726173

Epoch: 6| Step: 5
Training loss: 3.3706125068397657
Validation loss: 2.532895156564189

Epoch: 6| Step: 6
Training loss: 3.168451274808398
Validation loss: 2.5559525438567015

Epoch: 6| Step: 7
Training loss: 3.223142423081514
Validation loss: 2.5583740220183344

Epoch: 6| Step: 8
Training loss: 2.0723605408355366
Validation loss: 2.5432014598915056

Epoch: 6| Step: 9
Training loss: 3.070244785950185
Validation loss: 2.527379037367549

Epoch: 6| Step: 10
Training loss: 3.319891977046514
Validation loss: 2.509261135494537

Epoch: 6| Step: 11
Training loss: 2.6503143412013856
Validation loss: 2.484638660608405

Epoch: 6| Step: 12
Training loss: 2.515021020638382
Validation loss: 2.481977218256773

Epoch: 6| Step: 13
Training loss: 3.129364018284793
Validation loss: 2.4657531467916507

Epoch: 95| Step: 0
Training loss: 2.806813573851048
Validation loss: 2.459846661355124

Epoch: 6| Step: 1
Training loss: 2.586680878800089
Validation loss: 2.4666443133096574

Epoch: 6| Step: 2
Training loss: 3.0552565881139784
Validation loss: 2.4648941081958555

Epoch: 6| Step: 3
Training loss: 2.7179612517356238
Validation loss: 2.4737488022021377

Epoch: 6| Step: 4
Training loss: 2.7919204558597555
Validation loss: 2.4746159078680443

Epoch: 6| Step: 5
Training loss: 2.955821909968892
Validation loss: 2.4748396932494177

Epoch: 6| Step: 6
Training loss: 2.79446409516433
Validation loss: 2.4773454164554303

Epoch: 6| Step: 7
Training loss: 2.685392129774629
Validation loss: 2.4690788551578606

Epoch: 6| Step: 8
Training loss: 2.9109485341393797
Validation loss: 2.4711915530436226

Epoch: 6| Step: 9
Training loss: 2.863827932921656
Validation loss: 2.4708098975106676

Epoch: 6| Step: 10
Training loss: 3.0238306543980022
Validation loss: 2.465200858269234

Epoch: 6| Step: 11
Training loss: 2.6943548740386554
Validation loss: 2.4650801530360926

Epoch: 6| Step: 12
Training loss: 2.9822925272274254
Validation loss: 2.472468523661925

Epoch: 6| Step: 13
Training loss: 3.226083937062042
Validation loss: 2.4986908797290623

Epoch: 96| Step: 0
Training loss: 2.2889313643978215
Validation loss: 2.485227811371503

Epoch: 6| Step: 1
Training loss: 3.188042987126829
Validation loss: 2.4909774728698473

Epoch: 6| Step: 2
Training loss: 2.259446552668426
Validation loss: 2.493975001618652

Epoch: 6| Step: 3
Training loss: 2.9463699830410524
Validation loss: 2.4889212677219694

Epoch: 6| Step: 4
Training loss: 2.5266872773885742
Validation loss: 2.4891628628215687

Epoch: 6| Step: 5
Training loss: 2.4150427152279796
Validation loss: 2.4765472064858267

Epoch: 6| Step: 6
Training loss: 3.077431227832091
Validation loss: 2.4750313570520692

Epoch: 6| Step: 7
Training loss: 2.865459368296368
Validation loss: 2.476669231068925

Epoch: 6| Step: 8
Training loss: 3.135634067302548
Validation loss: 2.4777591250001234

Epoch: 6| Step: 9
Training loss: 2.7389886788464683
Validation loss: 2.475506823924155

Epoch: 6| Step: 10
Training loss: 2.4581657180110112
Validation loss: 2.480824833649521

Epoch: 6| Step: 11
Training loss: 3.1774674146948785
Validation loss: 2.487167901869369

Epoch: 6| Step: 12
Training loss: 3.472826238018219
Validation loss: 2.4789575881740196

Epoch: 6| Step: 13
Training loss: 2.429047135236156
Validation loss: 2.472726457732414

Epoch: 97| Step: 0
Training loss: 2.9023003761059143
Validation loss: 2.4828569166524406

Epoch: 6| Step: 1
Training loss: 2.383520202602315
Validation loss: 2.4853521236360456

Epoch: 6| Step: 2
Training loss: 3.1753857355764117
Validation loss: 2.501926198951525

Epoch: 6| Step: 3
Training loss: 2.46901266897728
Validation loss: 2.515136033790519

Epoch: 6| Step: 4
Training loss: 2.872357854422019
Validation loss: 2.5196782602072436

Epoch: 6| Step: 5
Training loss: 2.695183526975406
Validation loss: 2.5104783442518355

Epoch: 6| Step: 6
Training loss: 2.3437715656559917
Validation loss: 2.5095520784159744

Epoch: 6| Step: 7
Training loss: 3.1439980380607873
Validation loss: 2.513894823875198

Epoch: 6| Step: 8
Training loss: 2.905462178743157
Validation loss: 2.4991691634160804

Epoch: 6| Step: 9
Training loss: 2.331831880414638
Validation loss: 2.480809076585168

Epoch: 6| Step: 10
Training loss: 3.1445533893824664
Validation loss: 2.46380812935616

Epoch: 6| Step: 11
Training loss: 3.0672003039861857
Validation loss: 2.4671251612812353

Epoch: 6| Step: 12
Training loss: 2.626052826965255
Validation loss: 2.4607059003220217

Epoch: 6| Step: 13
Training loss: 3.572426868968889
Validation loss: 2.4642791140327884

Epoch: 98| Step: 0
Training loss: 2.7852259302183797
Validation loss: 2.457495510297635

Epoch: 6| Step: 1
Training loss: 2.8521119306945093
Validation loss: 2.455553566435648

Epoch: 6| Step: 2
Training loss: 3.035430542323528
Validation loss: 2.4591788591051706

Epoch: 6| Step: 3
Training loss: 2.4376126776841005
Validation loss: 2.4602460607020338

Epoch: 6| Step: 4
Training loss: 2.5177181847131935
Validation loss: 2.4598302800748133

Epoch: 6| Step: 5
Training loss: 3.0263429230230887
Validation loss: 2.456078674007478

Epoch: 6| Step: 6
Training loss: 2.78376544826488
Validation loss: 2.4624978156626915

Epoch: 6| Step: 7
Training loss: 3.025253184418452
Validation loss: 2.4644488136290033

Epoch: 6| Step: 8
Training loss: 3.0706496502527227
Validation loss: 2.4737317611145575

Epoch: 6| Step: 9
Training loss: 2.694333990745491
Validation loss: 2.4787418435462154

Epoch: 6| Step: 10
Training loss: 2.505613319405905
Validation loss: 2.482623822964186

Epoch: 6| Step: 11
Training loss: 2.762317123228654
Validation loss: 2.5221162933226533

Epoch: 6| Step: 12
Training loss: 2.640823266525879
Validation loss: 2.5038872164357233

Epoch: 6| Step: 13
Training loss: 3.2975936034179867
Validation loss: 2.5236946273894136

Epoch: 99| Step: 0
Training loss: 2.633725152461991
Validation loss: 2.5381226562542833

Epoch: 6| Step: 1
Training loss: 2.3404520864751093
Validation loss: 2.554660128262134

Epoch: 6| Step: 2
Training loss: 3.084088739872398
Validation loss: 2.5154608141277404

Epoch: 6| Step: 3
Training loss: 2.440697162650563
Validation loss: 2.5160143762413814

Epoch: 6| Step: 4
Training loss: 3.011116096176519
Validation loss: 2.5425219603841933

Epoch: 6| Step: 5
Training loss: 3.2063557032957415
Validation loss: 2.541989406010436

Epoch: 6| Step: 6
Training loss: 3.2211271230156306
Validation loss: 2.528837793823467

Epoch: 6| Step: 7
Training loss: 3.0693059538087657
Validation loss: 2.507304853779585

Epoch: 6| Step: 8
Training loss: 2.3799683653708543
Validation loss: 2.5128231415649767

Epoch: 6| Step: 9
Training loss: 2.9113793177565084
Validation loss: 2.483016810121609

Epoch: 6| Step: 10
Training loss: 2.590735464651444
Validation loss: 2.4801706990427355

Epoch: 6| Step: 11
Training loss: 3.2942106500287283
Validation loss: 2.469447192595698

Epoch: 6| Step: 12
Training loss: 2.3595479939683033
Validation loss: 2.469416789856081

Epoch: 6| Step: 13
Training loss: 2.45322724147508
Validation loss: 2.4743527541108983

Epoch: 100| Step: 0
Training loss: 2.625820031825977
Validation loss: 2.476040494093185

Epoch: 6| Step: 1
Training loss: 3.1407601246778785
Validation loss: 2.4695386840477127

Epoch: 6| Step: 2
Training loss: 3.33314014510772
Validation loss: 2.4686506517990927

Epoch: 6| Step: 3
Training loss: 2.791316641504444
Validation loss: 2.470183374224775

Epoch: 6| Step: 4
Training loss: 3.0008011384010445
Validation loss: 2.4902882984555457

Epoch: 6| Step: 5
Training loss: 3.4928649654852473
Validation loss: 2.472981862404942

Epoch: 6| Step: 6
Training loss: 2.827207806479401
Validation loss: 2.476474956966802

Epoch: 6| Step: 7
Training loss: 3.098395664627111
Validation loss: 2.488312156319044

Epoch: 6| Step: 8
Training loss: 2.163031266944559
Validation loss: 2.4882188200840027

Epoch: 6| Step: 9
Training loss: 2.203028034213648
Validation loss: 2.4837793663073224

Epoch: 6| Step: 10
Training loss: 2.2981534760355022
Validation loss: 2.4843946319277017

Epoch: 6| Step: 11
Training loss: 2.758164856097816
Validation loss: 2.512242115393275

Epoch: 6| Step: 12
Training loss: 2.840493486001782
Validation loss: 2.4798668809850124

Epoch: 6| Step: 13
Training loss: 2.6554438545786154
Validation loss: 2.478066767511262

Epoch: 101| Step: 0
Training loss: 2.4888544545270403
Validation loss: 2.4711046974160324

Epoch: 6| Step: 1
Training loss: 2.8626583405391224
Validation loss: 2.458893967681145

Epoch: 6| Step: 2
Training loss: 2.8542113660296176
Validation loss: 2.4688506266204695

Epoch: 6| Step: 3
Training loss: 2.899603842938529
Validation loss: 2.478126170690584

Epoch: 6| Step: 4
Training loss: 2.4811306288132244
Validation loss: 2.4857954506332725

Epoch: 6| Step: 5
Training loss: 2.7899276289218653
Validation loss: 2.47913239033899

Epoch: 6| Step: 6
Training loss: 2.280263190889719
Validation loss: 2.50374403209183

Epoch: 6| Step: 7
Training loss: 2.8261963395731895
Validation loss: 2.5052926899952124

Epoch: 6| Step: 8
Training loss: 3.2672134259735492
Validation loss: 2.499034131010276

Epoch: 6| Step: 9
Training loss: 2.5292513456628534
Validation loss: 2.4920975205363605

Epoch: 6| Step: 10
Training loss: 3.007553446129136
Validation loss: 2.4824302482597695

Epoch: 6| Step: 11
Training loss: 3.5544272526642633
Validation loss: 2.461223028794083

Epoch: 6| Step: 12
Training loss: 2.7137188014657956
Validation loss: 2.462660525873808

Epoch: 6| Step: 13
Training loss: 2.533700769112711
Validation loss: 2.4600553792066924

Epoch: 102| Step: 0
Training loss: 2.6151459431814095
Validation loss: 2.4537207154007405

Epoch: 6| Step: 1
Training loss: 3.336592670221023
Validation loss: 2.462988020762874

Epoch: 6| Step: 2
Training loss: 2.8351703373298056
Validation loss: 2.4566595644560256

Epoch: 6| Step: 3
Training loss: 2.5652536622971054
Validation loss: 2.4611234507093247

Epoch: 6| Step: 4
Training loss: 2.62819359289552
Validation loss: 2.4604394859685397

Epoch: 6| Step: 5
Training loss: 2.784753971019283
Validation loss: 2.457828974376058

Epoch: 6| Step: 6
Training loss: 2.044612653465189
Validation loss: 2.4562483713348726

Epoch: 6| Step: 7
Training loss: 3.48958044858595
Validation loss: 2.457641475702296

Epoch: 6| Step: 8
Training loss: 3.0229712627027987
Validation loss: 2.462781262777512

Epoch: 6| Step: 9
Training loss: 2.712589519095893
Validation loss: 2.4602851040685954

Epoch: 6| Step: 10
Training loss: 2.9542135825868323
Validation loss: 2.4928602699964113

Epoch: 6| Step: 11
Training loss: 2.7101697026851097
Validation loss: 2.4938054669955676

Epoch: 6| Step: 12
Training loss: 2.9406920600728146
Validation loss: 2.52092323831058

Epoch: 6| Step: 13
Training loss: 2.1871837932382485
Validation loss: 2.5386723599632885

Epoch: 103| Step: 0
Training loss: 2.920075050852684
Validation loss: 2.543763833856045

Epoch: 6| Step: 1
Training loss: 2.9942379293040013
Validation loss: 2.5280855021688287

Epoch: 6| Step: 2
Training loss: 2.8191766115788046
Validation loss: 2.503325634558057

Epoch: 6| Step: 3
Training loss: 2.663122553865661
Validation loss: 2.497192481976529

Epoch: 6| Step: 4
Training loss: 2.6098572062750858
Validation loss: 2.4850265660812325

Epoch: 6| Step: 5
Training loss: 2.716887087938768
Validation loss: 2.462508659457921

Epoch: 6| Step: 6
Training loss: 2.5738956787025673
Validation loss: 2.450901475101558

Epoch: 6| Step: 7
Training loss: 3.0448380924269585
Validation loss: 2.4513483411223937

Epoch: 6| Step: 8
Training loss: 2.7659307623339284
Validation loss: 2.449309105192728

Epoch: 6| Step: 9
Training loss: 2.7260954273730564
Validation loss: 2.4537267710380815

Epoch: 6| Step: 10
Training loss: 3.4864919757540056
Validation loss: 2.450707836290411

Epoch: 6| Step: 11
Training loss: 2.6531203738330635
Validation loss: 2.4478316100945

Epoch: 6| Step: 12
Training loss: 2.8740780222793907
Validation loss: 2.450617977270495

Epoch: 6| Step: 13
Training loss: 2.290513135564679
Validation loss: 2.4532681740736817

Epoch: 104| Step: 0
Training loss: 2.876625596597174
Validation loss: 2.4757812008764706

Epoch: 6| Step: 1
Training loss: 3.1986332358738347
Validation loss: 2.48000330745147

Epoch: 6| Step: 2
Training loss: 2.7676754694088115
Validation loss: 2.4927264858158584

Epoch: 6| Step: 3
Training loss: 3.060155009663155
Validation loss: 2.515089967289063

Epoch: 6| Step: 4
Training loss: 2.898961762675154
Validation loss: 2.545451449057538

Epoch: 6| Step: 5
Training loss: 2.7777028126667593
Validation loss: 2.546890843564405

Epoch: 6| Step: 6
Training loss: 2.4764462031546617
Validation loss: 2.548362067795307

Epoch: 6| Step: 7
Training loss: 2.55529703223982
Validation loss: 2.5349472331110334

Epoch: 6| Step: 8
Training loss: 2.676536197388366
Validation loss: 2.5390542014264845

Epoch: 6| Step: 9
Training loss: 2.684826785561638
Validation loss: 2.543505389015766

Epoch: 6| Step: 10
Training loss: 2.7956344154722994
Validation loss: 2.5692013539538805

Epoch: 6| Step: 11
Training loss: 2.6389402172606866
Validation loss: 2.527011183845711

Epoch: 6| Step: 12
Training loss: 2.731554593139279
Validation loss: 2.4982559355353873

Epoch: 6| Step: 13
Training loss: 2.8651678055491057
Validation loss: 2.4885409488111288

Epoch: 105| Step: 0
Training loss: 3.309694361563885
Validation loss: 2.4678803887033385

Epoch: 6| Step: 1
Training loss: 3.1140656482242304
Validation loss: 2.454211280161388

Epoch: 6| Step: 2
Training loss: 2.9752745557764877
Validation loss: 2.4525019858662094

Epoch: 6| Step: 3
Training loss: 2.3777086973801413
Validation loss: 2.4655662580051647

Epoch: 6| Step: 4
Training loss: 2.669178544596781
Validation loss: 2.480145490138531

Epoch: 6| Step: 5
Training loss: 2.311782416278847
Validation loss: 2.4901302318926106

Epoch: 6| Step: 6
Training loss: 3.080060011786864
Validation loss: 2.5025345926009437

Epoch: 6| Step: 7
Training loss: 2.911965441456813
Validation loss: 2.4960711422300697

Epoch: 6| Step: 8
Training loss: 2.9312116803427943
Validation loss: 2.4873349679638914

Epoch: 6| Step: 9
Training loss: 2.97157474449107
Validation loss: 2.480561933445831

Epoch: 6| Step: 10
Training loss: 3.1496184526700852
Validation loss: 2.472734167118136

Epoch: 6| Step: 11
Training loss: 2.6688938575583325
Validation loss: 2.4741475716942705

Epoch: 6| Step: 12
Training loss: 3.0533931555849865
Validation loss: 2.4726376850573204

Epoch: 6| Step: 13
Training loss: 1.9755954713916641
Validation loss: 2.4734797582935024

Epoch: 106| Step: 0
Training loss: 2.5534892874052857
Validation loss: 2.480263423907781

Epoch: 6| Step: 1
Training loss: 3.1902525741414904
Validation loss: 2.503520394289614

Epoch: 6| Step: 2
Training loss: 3.545604730417353
Validation loss: 2.4972328017251444

Epoch: 6| Step: 3
Training loss: 2.8939246238272265
Validation loss: 2.521658955846304

Epoch: 6| Step: 4
Training loss: 2.066337714113327
Validation loss: 2.556667451108226

Epoch: 6| Step: 5
Training loss: 2.8076851214607332
Validation loss: 2.5917486640433745

Epoch: 6| Step: 6
Training loss: 2.7420706438776565
Validation loss: 2.5834034173557576

Epoch: 6| Step: 7
Training loss: 2.3937868638349977
Validation loss: 2.5554759422760793

Epoch: 6| Step: 8
Training loss: 2.882304159692716
Validation loss: 2.5674058877129853

Epoch: 6| Step: 9
Training loss: 2.8335892804796567
Validation loss: 2.5197868408945876

Epoch: 6| Step: 10
Training loss: 2.729579273124388
Validation loss: 2.5040904493391714

Epoch: 6| Step: 11
Training loss: 2.6779244631597443
Validation loss: 2.4689498816296647

Epoch: 6| Step: 12
Training loss: 2.855397277021035
Validation loss: 2.456744722706995

Epoch: 6| Step: 13
Training loss: 2.6255456266548642
Validation loss: 2.4587294337829193

Epoch: 107| Step: 0
Training loss: 2.4397150392322975
Validation loss: 2.4735035737505475

Epoch: 6| Step: 1
Training loss: 2.324228084769857
Validation loss: 2.4783529275101284

Epoch: 6| Step: 2
Training loss: 2.742987708903835
Validation loss: 2.4753334621661414

Epoch: 6| Step: 3
Training loss: 2.6724265795222535
Validation loss: 2.5324746727616105

Epoch: 6| Step: 4
Training loss: 3.2695978994196153
Validation loss: 2.5575623560834884

Epoch: 6| Step: 5
Training loss: 2.6534827684209916
Validation loss: 2.572087782157337

Epoch: 6| Step: 6
Training loss: 2.775785499953869
Validation loss: 2.6296621711792185

Epoch: 6| Step: 7
Training loss: 2.938304385170486
Validation loss: 2.6699095499325667

Epoch: 6| Step: 8
Training loss: 2.856365016232525
Validation loss: 2.6809066806418724

Epoch: 6| Step: 9
Training loss: 2.9726809526938456
Validation loss: 2.5741391681361128

Epoch: 6| Step: 10
Training loss: 2.275296529371463
Validation loss: 2.540792143962173

Epoch: 6| Step: 11
Training loss: 3.0093764957729277
Validation loss: 2.5301807413323547

Epoch: 6| Step: 12
Training loss: 3.309603450335723
Validation loss: 2.47769540458554

Epoch: 6| Step: 13
Training loss: 2.521355493444451
Validation loss: 2.464743491296915

Epoch: 108| Step: 0
Training loss: 2.3206092310790156
Validation loss: 2.4584922183003073

Epoch: 6| Step: 1
Training loss: 3.079742471406586
Validation loss: 2.457912167748051

Epoch: 6| Step: 2
Training loss: 2.520630021737013
Validation loss: 2.4567327358645894

Epoch: 6| Step: 3
Training loss: 2.6647472228789018
Validation loss: 2.4554012646311274

Epoch: 6| Step: 4
Training loss: 2.796055679083424
Validation loss: 2.4624740822011493

Epoch: 6| Step: 5
Training loss: 3.066467517799549
Validation loss: 2.4736980791402137

Epoch: 6| Step: 6
Training loss: 2.131151495751876
Validation loss: 2.4756591087052113

Epoch: 6| Step: 7
Training loss: 3.6059468160082964
Validation loss: 2.5091276812118815

Epoch: 6| Step: 8
Training loss: 2.710041964582575
Validation loss: 2.525686582661828

Epoch: 6| Step: 9
Training loss: 2.478909123825105
Validation loss: 2.5316943253792807

Epoch: 6| Step: 10
Training loss: 3.0535974142933613
Validation loss: 2.5222985077491153

Epoch: 6| Step: 11
Training loss: 3.038952195389361
Validation loss: 2.5280634781227183

Epoch: 6| Step: 12
Training loss: 2.8995329645226513
Validation loss: 2.529948988080867

Epoch: 6| Step: 13
Training loss: 2.237414766531654
Validation loss: 2.5236281588312623

Epoch: 109| Step: 0
Training loss: 2.6491167215889244
Validation loss: 2.4987914117331

Epoch: 6| Step: 1
Training loss: 2.9562564777198452
Validation loss: 2.4891441995565775

Epoch: 6| Step: 2
Training loss: 2.0878154858877718
Validation loss: 2.4825222138747054

Epoch: 6| Step: 3
Training loss: 2.8917059449561475
Validation loss: 2.474759472250579

Epoch: 6| Step: 4
Training loss: 2.8493844689347627
Validation loss: 2.4903134118924113

Epoch: 6| Step: 5
Training loss: 2.699107188501552
Validation loss: 2.505076775737781

Epoch: 6| Step: 6
Training loss: 2.5029975087134004
Validation loss: 2.5146824013375397

Epoch: 6| Step: 7
Training loss: 3.3773840501875023
Validation loss: 2.4860005688614217

Epoch: 6| Step: 8
Training loss: 2.4319094589721435
Validation loss: 2.4910988965968035

Epoch: 6| Step: 9
Training loss: 2.1567329197670793
Validation loss: 2.5191299641656726

Epoch: 6| Step: 10
Training loss: 2.7069725041256034
Validation loss: 2.5209080695112354

Epoch: 6| Step: 11
Training loss: 3.1986883932533643
Validation loss: 2.524395547127197

Epoch: 6| Step: 12
Training loss: 3.3627526624404003
Validation loss: 2.505909721247216

Epoch: 6| Step: 13
Training loss: 2.2008771318234794
Validation loss: 2.5076306575875345

Epoch: 110| Step: 0
Training loss: 2.7765072449449306
Validation loss: 2.487403048446369

Epoch: 6| Step: 1
Training loss: 3.086096032814741
Validation loss: 2.5020429672516955

Epoch: 6| Step: 2
Training loss: 2.0995094452963703
Validation loss: 2.4994625498285368

Epoch: 6| Step: 3
Training loss: 2.284732094549811
Validation loss: 2.47419178990815

Epoch: 6| Step: 4
Training loss: 2.4170353926062664
Validation loss: 2.486702248252947

Epoch: 6| Step: 5
Training loss: 2.832270497706774
Validation loss: 2.464579539305236

Epoch: 6| Step: 6
Training loss: 3.1185492502555627
Validation loss: 2.484802219679895

Epoch: 6| Step: 7
Training loss: 2.7647857254635575
Validation loss: 2.489885596490334

Epoch: 6| Step: 8
Training loss: 3.0535700868939837
Validation loss: 2.472746577146602

Epoch: 6| Step: 9
Training loss: 2.9783763415179534
Validation loss: 2.477319708464726

Epoch: 6| Step: 10
Training loss: 3.4483819899176877
Validation loss: 2.476462170174514

Epoch: 6| Step: 11
Training loss: 2.5003757194476433
Validation loss: 2.50961901580987

Epoch: 6| Step: 12
Training loss: 2.5126452124086165
Validation loss: 2.5211979607319286

Epoch: 6| Step: 13
Training loss: 2.5494631856716845
Validation loss: 2.488779976790651

Epoch: 111| Step: 0
Training loss: 2.53364948466656
Validation loss: 2.492884477741409

Epoch: 6| Step: 1
Training loss: 2.5564185760799636
Validation loss: 2.505866177306474

Epoch: 6| Step: 2
Training loss: 2.805282487159479
Validation loss: 2.5456111330520073

Epoch: 6| Step: 3
Training loss: 2.785989131224409
Validation loss: 2.553162709440631

Epoch: 6| Step: 4
Training loss: 3.0578521959849914
Validation loss: 2.5752783409350335

Epoch: 6| Step: 5
Training loss: 2.308726660296032
Validation loss: 2.6107443496147376

Epoch: 6| Step: 6
Training loss: 3.350802675562475
Validation loss: 2.63904577367114

Epoch: 6| Step: 7
Training loss: 2.867427639168797
Validation loss: 2.5421591237439065

Epoch: 6| Step: 8
Training loss: 2.6414133734664835
Validation loss: 2.469253725412397

Epoch: 6| Step: 9
Training loss: 2.780103554340677
Validation loss: 2.467757127538002

Epoch: 6| Step: 10
Training loss: 2.921118653674098
Validation loss: 2.4953302074515573

Epoch: 6| Step: 11
Training loss: 2.6239562002922696
Validation loss: 2.534480814315917

Epoch: 6| Step: 12
Training loss: 2.9207093876884676
Validation loss: 2.545421089474684

Epoch: 6| Step: 13
Training loss: 3.3995076215669524
Validation loss: 2.543887338455413

Epoch: 112| Step: 0
Training loss: 2.199167688024278
Validation loss: 2.4960737725558233

Epoch: 6| Step: 1
Training loss: 2.849507299298404
Validation loss: 2.473324557320516

Epoch: 6| Step: 2
Training loss: 2.5413291790472274
Validation loss: 2.46008963823182

Epoch: 6| Step: 3
Training loss: 2.900630316800335
Validation loss: 2.454585537050263

Epoch: 6| Step: 4
Training loss: 2.9670803795994316
Validation loss: 2.454397479337078

Epoch: 6| Step: 5
Training loss: 2.4097433122877887
Validation loss: 2.473947251990759

Epoch: 6| Step: 6
Training loss: 2.8507139014507934
Validation loss: 2.5239827577734517

Epoch: 6| Step: 7
Training loss: 2.7742540473808774
Validation loss: 2.5625558102240396

Epoch: 6| Step: 8
Training loss: 3.2490524964886247
Validation loss: 2.599825219542085

Epoch: 6| Step: 9
Training loss: 3.3380557622623166
Validation loss: 2.631658859820645

Epoch: 6| Step: 10
Training loss: 2.6010607902935
Validation loss: 2.6893545449888796

Epoch: 6| Step: 11
Training loss: 3.283457567475497
Validation loss: 2.586759676410241

Epoch: 6| Step: 12
Training loss: 2.3978595845056514
Validation loss: 2.538630992233402

Epoch: 6| Step: 13
Training loss: 2.898269360541715
Validation loss: 2.495544733714057

Epoch: 113| Step: 0
Training loss: 2.9345504887017615
Validation loss: 2.4953795959758858

Epoch: 6| Step: 1
Training loss: 2.6594086659471214
Validation loss: 2.4680931387770233

Epoch: 6| Step: 2
Training loss: 2.654325977696414
Validation loss: 2.4558049320781286

Epoch: 6| Step: 3
Training loss: 3.105835092876875
Validation loss: 2.4516277228454224

Epoch: 6| Step: 4
Training loss: 2.8248669314481707
Validation loss: 2.4465356157058675

Epoch: 6| Step: 5
Training loss: 2.7087308934219574
Validation loss: 2.45988037197339

Epoch: 6| Step: 6
Training loss: 2.6494596866176248
Validation loss: 2.458622313905977

Epoch: 6| Step: 7
Training loss: 2.8395613119307472
Validation loss: 2.474538738946366

Epoch: 6| Step: 8
Training loss: 3.1253832772770145
Validation loss: 2.4801989765790693

Epoch: 6| Step: 9
Training loss: 3.2935661597584547
Validation loss: 2.5002373798021007

Epoch: 6| Step: 10
Training loss: 2.287101139669471
Validation loss: 2.516109816514907

Epoch: 6| Step: 11
Training loss: 1.7222189834865074
Validation loss: 2.495680290823423

Epoch: 6| Step: 12
Training loss: 2.7530332656108714
Validation loss: 2.477295262730289

Epoch: 6| Step: 13
Training loss: 2.668555891852954
Validation loss: 2.4519187271534184

Epoch: 114| Step: 0
Training loss: 2.093715838253257
Validation loss: 2.4551170531971174

Epoch: 6| Step: 1
Training loss: 2.512914204023577
Validation loss: 2.452513934849282

Epoch: 6| Step: 2
Training loss: 2.85893471251613
Validation loss: 2.4547217383186553

Epoch: 6| Step: 3
Training loss: 2.784039759121822
Validation loss: 2.44158374690796

Epoch: 6| Step: 4
Training loss: 2.8497495976252085
Validation loss: 2.4570814177423252

Epoch: 6| Step: 5
Training loss: 2.7567288698545687
Validation loss: 2.4558645699627397

Epoch: 6| Step: 6
Training loss: 2.4851712084610527
Validation loss: 2.4849074898415475

Epoch: 6| Step: 7
Training loss: 2.953840542445599
Validation loss: 2.5143605741546793

Epoch: 6| Step: 8
Training loss: 2.763398044351533
Validation loss: 2.584607680989629

Epoch: 6| Step: 9
Training loss: 2.2268931360868622
Validation loss: 2.5991684987328165

Epoch: 6| Step: 10
Training loss: 3.0131618738202963
Validation loss: 2.6426041175279376

Epoch: 6| Step: 11
Training loss: 3.0722032311488516
Validation loss: 2.6843203698773475

Epoch: 6| Step: 12
Training loss: 3.3935601674865827
Validation loss: 2.664712221065085

Epoch: 6| Step: 13
Training loss: 2.507808031690188
Validation loss: 2.523727833585004

Epoch: 115| Step: 0
Training loss: 2.734512674407965
Validation loss: 2.460513520720316

Epoch: 6| Step: 1
Training loss: 2.367116794852166
Validation loss: 2.42710762235348

Epoch: 6| Step: 2
Training loss: 2.7167508898202035
Validation loss: 2.4424479244058603

Epoch: 6| Step: 3
Training loss: 2.3678348273072554
Validation loss: 2.4410153742458207

Epoch: 6| Step: 4
Training loss: 2.6944998137912344
Validation loss: 2.441334833884902

Epoch: 6| Step: 5
Training loss: 2.8531471343503236
Validation loss: 2.4506285315530945

Epoch: 6| Step: 6
Training loss: 2.7650143223921004
Validation loss: 2.4455314097134093

Epoch: 6| Step: 7
Training loss: 2.82232467431198
Validation loss: 2.439269648491821

Epoch: 6| Step: 8
Training loss: 3.015177164771738
Validation loss: 2.4341543273560227

Epoch: 6| Step: 9
Training loss: 2.8562277895274644
Validation loss: 2.43536882441856

Epoch: 6| Step: 10
Training loss: 3.0166187921873604
Validation loss: 2.456527518771057

Epoch: 6| Step: 11
Training loss: 2.9879019303269416
Validation loss: 2.462624542250127

Epoch: 6| Step: 12
Training loss: 2.899509447635284
Validation loss: 2.4873114158367082

Epoch: 6| Step: 13
Training loss: 2.4587274224738502
Validation loss: 2.4883840992371504

Epoch: 116| Step: 0
Training loss: 3.1193277378128563
Validation loss: 2.5208696508338164

Epoch: 6| Step: 1
Training loss: 3.129631577523967
Validation loss: 2.528402203436919

Epoch: 6| Step: 2
Training loss: 3.3670659939467735
Validation loss: 2.503631061162987

Epoch: 6| Step: 3
Training loss: 3.1723817317191836
Validation loss: 2.474749151407201

Epoch: 6| Step: 4
Training loss: 2.868781288657837
Validation loss: 2.4461294690864865

Epoch: 6| Step: 5
Training loss: 2.200444532045932
Validation loss: 2.451707388428551

Epoch: 6| Step: 6
Training loss: 2.773978854791185
Validation loss: 2.4527356625402588

Epoch: 6| Step: 7
Training loss: 2.807518510494201
Validation loss: 2.461642031747728

Epoch: 6| Step: 8
Training loss: 3.0406468044647923
Validation loss: 2.464392982827939

Epoch: 6| Step: 9
Training loss: 2.974043774198626
Validation loss: 2.461300336058615

Epoch: 6| Step: 10
Training loss: 2.7797792810873494
Validation loss: 2.455452994180502

Epoch: 6| Step: 11
Training loss: 2.3250273508083374
Validation loss: 2.452374651520195

Epoch: 6| Step: 12
Training loss: 2.1248682766647606
Validation loss: 2.453201247823157

Epoch: 6| Step: 13
Training loss: 2.347483395323767
Validation loss: 2.4554250695887907

Epoch: 117| Step: 0
Training loss: 2.5354440111385155
Validation loss: 2.4676122269726206

Epoch: 6| Step: 1
Training loss: 2.719735153431225
Validation loss: 2.492038988421674

Epoch: 6| Step: 2
Training loss: 3.0162771834133837
Validation loss: 2.532503000988965

Epoch: 6| Step: 3
Training loss: 2.8965281652328714
Validation loss: 2.562501950867253

Epoch: 6| Step: 4
Training loss: 3.1320394955966853
Validation loss: 2.578177084199356

Epoch: 6| Step: 5
Training loss: 2.4532671844679803
Validation loss: 2.663503118819001

Epoch: 6| Step: 6
Training loss: 2.2173341343722077
Validation loss: 2.6738727544013043

Epoch: 6| Step: 7
Training loss: 2.929352031574583
Validation loss: 2.66741099531833

Epoch: 6| Step: 8
Training loss: 2.737453275656293
Validation loss: 2.601474144449683

Epoch: 6| Step: 9
Training loss: 3.4487950031238124
Validation loss: 2.5026386845879616

Epoch: 6| Step: 10
Training loss: 2.8075196993944305
Validation loss: 2.4655634006945872

Epoch: 6| Step: 11
Training loss: 2.15432089051239
Validation loss: 2.4529683376785263

Epoch: 6| Step: 12
Training loss: 2.78391301253774
Validation loss: 2.4463963493492

Epoch: 6| Step: 13
Training loss: 2.822446992847749
Validation loss: 2.443410780851763

Epoch: 118| Step: 0
Training loss: 2.91290751213549
Validation loss: 2.440718620086296

Epoch: 6| Step: 1
Training loss: 2.980428272937383
Validation loss: 2.447307638850616

Epoch: 6| Step: 2
Training loss: 2.5820027175227134
Validation loss: 2.44398411239759

Epoch: 6| Step: 3
Training loss: 2.9631970321953496
Validation loss: 2.4408319500519022

Epoch: 6| Step: 4
Training loss: 2.635461578187498
Validation loss: 2.44263106667191

Epoch: 6| Step: 5
Training loss: 3.0459273992190745
Validation loss: 2.446923361285817

Epoch: 6| Step: 6
Training loss: 2.5350358696380537
Validation loss: 2.44889496520365

Epoch: 6| Step: 7
Training loss: 2.9235089471222433
Validation loss: 2.4418652290338922

Epoch: 6| Step: 8
Training loss: 2.8539894958602194
Validation loss: 2.440605833173099

Epoch: 6| Step: 9
Training loss: 2.9767172465311345
Validation loss: 2.446091435956484

Epoch: 6| Step: 10
Training loss: 3.2015823743435106
Validation loss: 2.4474146202238605

Epoch: 6| Step: 11
Training loss: 2.499493070705368
Validation loss: 2.4638619933452146

Epoch: 6| Step: 12
Training loss: 1.8898330164616775
Validation loss: 2.5200346001067717

Epoch: 6| Step: 13
Training loss: 2.0594577894226367
Validation loss: 2.5582268745029544

Epoch: 119| Step: 0
Training loss: 2.3875573116433952
Validation loss: 2.6484539440323447

Epoch: 6| Step: 1
Training loss: 3.2045392147669984
Validation loss: 2.6830154246929143

Epoch: 6| Step: 2
Training loss: 3.032096980423589
Validation loss: 2.713183686783163

Epoch: 6| Step: 3
Training loss: 2.1428422791101753
Validation loss: 2.727071385333265

Epoch: 6| Step: 4
Training loss: 2.6564900009337578
Validation loss: 2.7297155665382116

Epoch: 6| Step: 5
Training loss: 2.4606134110445024
Validation loss: 2.6283147483162

Epoch: 6| Step: 6
Training loss: 3.1240263375748496
Validation loss: 2.576597783751728

Epoch: 6| Step: 7
Training loss: 2.4377265238041774
Validation loss: 2.4933505278020727

Epoch: 6| Step: 8
Training loss: 2.352181388043252
Validation loss: 2.450248514211373

Epoch: 6| Step: 9
Training loss: 3.152238619539162
Validation loss: 2.432916767011115

Epoch: 6| Step: 10
Training loss: 2.5418605938914265
Validation loss: 2.4554340465036906

Epoch: 6| Step: 11
Training loss: 3.0277787615884315
Validation loss: 2.491346403188586

Epoch: 6| Step: 12
Training loss: 3.075923074015861
Validation loss: 2.5128435622709184

Epoch: 6| Step: 13
Training loss: 3.17731674254143
Validation loss: 2.52496719030383

Epoch: 120| Step: 0
Training loss: 2.7284860902906702
Validation loss: 2.492049956739758

Epoch: 6| Step: 1
Training loss: 2.869405860144984
Validation loss: 2.469910586253543

Epoch: 6| Step: 2
Training loss: 2.8414557288253697
Validation loss: 2.4575414280684544

Epoch: 6| Step: 3
Training loss: 2.6611360378420823
Validation loss: 2.4600243471522987

Epoch: 6| Step: 4
Training loss: 2.5318770397275054
Validation loss: 2.47508482142903

Epoch: 6| Step: 5
Training loss: 2.3337032388212444
Validation loss: 2.501573237832353

Epoch: 6| Step: 6
Training loss: 3.2929562967773123
Validation loss: 2.5734055683866988

Epoch: 6| Step: 7
Training loss: 2.0826067102392836
Validation loss: 2.627065773521139

Epoch: 6| Step: 8
Training loss: 2.90168452830535
Validation loss: 2.648844409953801

Epoch: 6| Step: 9
Training loss: 2.6160425215248835
Validation loss: 2.7164600380803425

Epoch: 6| Step: 10
Training loss: 2.7303905994326105
Validation loss: 2.721776467538459

Epoch: 6| Step: 11
Training loss: 2.6066180072285063
Validation loss: 2.713913461477632

Epoch: 6| Step: 12
Training loss: 3.0592232125866055
Validation loss: 2.6444200619093152

Epoch: 6| Step: 13
Training loss: 3.1738577222177664
Validation loss: 2.605158345734406

Epoch: 121| Step: 0
Training loss: 2.3103659809722648
Validation loss: 2.51390108842718

Epoch: 6| Step: 1
Training loss: 2.7464114964418727
Validation loss: 2.4894505937073363

Epoch: 6| Step: 2
Training loss: 2.3198794593408474
Validation loss: 2.479832394826395

Epoch: 6| Step: 3
Training loss: 2.671850282432041
Validation loss: 2.471500042104059

Epoch: 6| Step: 4
Training loss: 2.459408627271694
Validation loss: 2.46778661420841

Epoch: 6| Step: 5
Training loss: 2.9500519440813786
Validation loss: 2.4648734961775247

Epoch: 6| Step: 6
Training loss: 2.963100156875034
Validation loss: 2.4682938795750435

Epoch: 6| Step: 7
Training loss: 3.1123170975101657
Validation loss: 2.4659829708624135

Epoch: 6| Step: 8
Training loss: 2.7834181317719504
Validation loss: 2.46581066641824

Epoch: 6| Step: 9
Training loss: 3.061665479659458
Validation loss: 2.461762242717902

Epoch: 6| Step: 10
Training loss: 2.8187762274018873
Validation loss: 2.4705378293466502

Epoch: 6| Step: 11
Training loss: 2.4695898631355875
Validation loss: 2.506260895323713

Epoch: 6| Step: 12
Training loss: 2.7711941094584773
Validation loss: 2.551402907902831

Epoch: 6| Step: 13
Training loss: 3.336522642895986
Validation loss: 2.611010474094962

Epoch: 122| Step: 0
Training loss: 2.8968462007442857
Validation loss: 2.6348375359134644

Epoch: 6| Step: 1
Training loss: 2.6687753108876855
Validation loss: 2.607499598478886

Epoch: 6| Step: 2
Training loss: 2.2178600836910514
Validation loss: 2.5920659476778924

Epoch: 6| Step: 3
Training loss: 3.485335829109557
Validation loss: 2.5709882682505536

Epoch: 6| Step: 4
Training loss: 2.5000728596560675
Validation loss: 2.500831633855758

Epoch: 6| Step: 5
Training loss: 2.733539911542915
Validation loss: 2.461329828213082

Epoch: 6| Step: 6
Training loss: 3.1497648484393035
Validation loss: 2.4499407374966404

Epoch: 6| Step: 7
Training loss: 2.205374144559756
Validation loss: 2.444566824962586

Epoch: 6| Step: 8
Training loss: 1.6778846469145132
Validation loss: 2.4282540857425943

Epoch: 6| Step: 9
Training loss: 3.5460477023802364
Validation loss: 2.4392803191392654

Epoch: 6| Step: 10
Training loss: 2.409370281843224
Validation loss: 2.4352791631471127

Epoch: 6| Step: 11
Training loss: 2.9769520742436804
Validation loss: 2.448786734640823

Epoch: 6| Step: 12
Training loss: 2.688833127831653
Validation loss: 2.4501659039547277

Epoch: 6| Step: 13
Training loss: 2.2159738500064377
Validation loss: 2.4500197516309203

Epoch: 123| Step: 0
Training loss: 2.1637905790070824
Validation loss: 2.4503731949188525

Epoch: 6| Step: 1
Training loss: 2.466861340427201
Validation loss: 2.459336366279767

Epoch: 6| Step: 2
Training loss: 2.3587292930773636
Validation loss: 2.4592207225930514

Epoch: 6| Step: 3
Training loss: 2.3301745104619402
Validation loss: 2.466348936602879

Epoch: 6| Step: 4
Training loss: 1.9308729353020888
Validation loss: 2.46217234840588

Epoch: 6| Step: 5
Training loss: 2.8640865010672605
Validation loss: 2.4615097367635554

Epoch: 6| Step: 6
Training loss: 3.1008201498646515
Validation loss: 2.465359125601057

Epoch: 6| Step: 7
Training loss: 3.0383927654146077
Validation loss: 2.4670473590151527

Epoch: 6| Step: 8
Training loss: 2.804053274717878
Validation loss: 2.4646458788596037

Epoch: 6| Step: 9
Training loss: 2.823085868991581
Validation loss: 2.465885344071857

Epoch: 6| Step: 10
Training loss: 3.0752426051758057
Validation loss: 2.474493745768607

Epoch: 6| Step: 11
Training loss: 3.3240867794749986
Validation loss: 2.489789793481403

Epoch: 6| Step: 12
Training loss: 2.8816974416589387
Validation loss: 2.4981973835193716

Epoch: 6| Step: 13
Training loss: 2.333019973512413
Validation loss: 2.5037501868843015

Epoch: 124| Step: 0
Training loss: 2.349589486485859
Validation loss: 2.4965778647614054

Epoch: 6| Step: 1
Training loss: 2.6308726060473715
Validation loss: 2.4767126641670956

Epoch: 6| Step: 2
Training loss: 2.5602747862086983
Validation loss: 2.47331440462483

Epoch: 6| Step: 3
Training loss: 2.9837115284261784
Validation loss: 2.4545689953259733

Epoch: 6| Step: 4
Training loss: 1.9270745010860908
Validation loss: 2.449748108479755

Epoch: 6| Step: 5
Training loss: 3.245193154533254
Validation loss: 2.4274555262269484

Epoch: 6| Step: 6
Training loss: 2.2250950310804405
Validation loss: 2.4363832747488616

Epoch: 6| Step: 7
Training loss: 2.1505717825742052
Validation loss: 2.42418101200665

Epoch: 6| Step: 8
Training loss: 3.1113918798395743
Validation loss: 2.4356370447994973

Epoch: 6| Step: 9
Training loss: 2.8674565742483695
Validation loss: 2.420091757028493

Epoch: 6| Step: 10
Training loss: 2.7602223357887423
Validation loss: 2.4312624596464376

Epoch: 6| Step: 11
Training loss: 2.7661198749783504
Validation loss: 2.448206731244514

Epoch: 6| Step: 12
Training loss: 2.9901857378372227
Validation loss: 2.4741249353931196

Epoch: 6| Step: 13
Training loss: 2.9258012961909223
Validation loss: 2.5074731209131316

Epoch: 125| Step: 0
Training loss: 2.4736685706986603
Validation loss: 2.620486428592819

Epoch: 6| Step: 1
Training loss: 2.6274922664974962
Validation loss: 2.7737202993685868

Epoch: 6| Step: 2
Training loss: 3.499831331821048
Validation loss: 2.915824015727153

Epoch: 6| Step: 3
Training loss: 3.4815281755128233
Validation loss: 2.850590644631903

Epoch: 6| Step: 4
Training loss: 2.4489118027792975
Validation loss: 2.6579394628865396

Epoch: 6| Step: 5
Training loss: 2.702823335429814
Validation loss: 2.5327791076751724

Epoch: 6| Step: 6
Training loss: 2.978231447765187
Validation loss: 2.484396750412387

Epoch: 6| Step: 7
Training loss: 2.731174536040031
Validation loss: 2.4351761528527036

Epoch: 6| Step: 8
Training loss: 2.4723968610861196
Validation loss: 2.434940755229135

Epoch: 6| Step: 9
Training loss: 2.6327622406008193
Validation loss: 2.427982977086676

Epoch: 6| Step: 10
Training loss: 2.7541721080393478
Validation loss: 2.4353174735631815

Epoch: 6| Step: 11
Training loss: 2.137999100444951
Validation loss: 2.4408467048222153

Epoch: 6| Step: 12
Training loss: 2.7122210451476296
Validation loss: 2.4312189179217327

Epoch: 6| Step: 13
Training loss: 2.9267930037298724
Validation loss: 2.4347715133630774

Epoch: 126| Step: 0
Training loss: 2.578000984677052
Validation loss: 2.447816541339425

Epoch: 6| Step: 1
Training loss: 2.689889067734264
Validation loss: 2.451027757406554

Epoch: 6| Step: 2
Training loss: 2.7609590297479123
Validation loss: 2.4851154377928637

Epoch: 6| Step: 3
Training loss: 2.0258506024512637
Validation loss: 2.5022840658927032

Epoch: 6| Step: 4
Training loss: 2.685154623342448
Validation loss: 2.5094243238231577

Epoch: 6| Step: 5
Training loss: 3.115583346441409
Validation loss: 2.5213609585815635

Epoch: 6| Step: 6
Training loss: 2.8213945252225123
Validation loss: 2.518989786528535

Epoch: 6| Step: 7
Training loss: 2.8311936396026955
Validation loss: 2.5457584035418828

Epoch: 6| Step: 8
Training loss: 2.837130377133816
Validation loss: 2.5594504033144907

Epoch: 6| Step: 9
Training loss: 2.985657581122026
Validation loss: 2.6174291424168654

Epoch: 6| Step: 10
Training loss: 2.709116915298119
Validation loss: 2.6090096712934616

Epoch: 6| Step: 11
Training loss: 2.213977678029631
Validation loss: 2.58305311287536

Epoch: 6| Step: 12
Training loss: 2.2905820418385074
Validation loss: 2.541081967638187

Epoch: 6| Step: 13
Training loss: 3.1174063928373257
Validation loss: 2.509037042273821

Epoch: 127| Step: 0
Training loss: 2.747720987806268
Validation loss: 2.5090853783395355

Epoch: 6| Step: 1
Training loss: 2.7336768430698655
Validation loss: 2.482876204361185

Epoch: 6| Step: 2
Training loss: 2.406210762793931
Validation loss: 2.478935957573428

Epoch: 6| Step: 3
Training loss: 2.7971818638398416
Validation loss: 2.482088926221148

Epoch: 6| Step: 4
Training loss: 2.4631064892886143
Validation loss: 2.47802116179492

Epoch: 6| Step: 5
Training loss: 2.339273577526561
Validation loss: 2.483933817027443

Epoch: 6| Step: 6
Training loss: 3.160596064834351
Validation loss: 2.4822279643793945

Epoch: 6| Step: 7
Training loss: 1.9977599951367895
Validation loss: 2.4973008012644624

Epoch: 6| Step: 8
Training loss: 2.678239614733798
Validation loss: 2.504754330514439

Epoch: 6| Step: 9
Training loss: 2.430319455502144
Validation loss: 2.5185802305911236

Epoch: 6| Step: 10
Training loss: 2.8704100748504096
Validation loss: 2.504304509759861

Epoch: 6| Step: 11
Training loss: 3.0109938405916834
Validation loss: 2.5034176640932686

Epoch: 6| Step: 12
Training loss: 2.8682353835935857
Validation loss: 2.520862580871002

Epoch: 6| Step: 13
Training loss: 2.5273423349650694
Validation loss: 2.510854805805113

Epoch: 128| Step: 0
Training loss: 2.3827888862815594
Validation loss: 2.506782754529456

Epoch: 6| Step: 1
Training loss: 2.7637051745454113
Validation loss: 2.50279483135234

Epoch: 6| Step: 2
Training loss: 2.5123734399604785
Validation loss: 2.4969862569426104

Epoch: 6| Step: 3
Training loss: 1.6876116115252882
Validation loss: 2.499025186585538

Epoch: 6| Step: 4
Training loss: 3.0511003979393507
Validation loss: 2.505633819334306

Epoch: 6| Step: 5
Training loss: 2.853880225145677
Validation loss: 2.506006889549784

Epoch: 6| Step: 6
Training loss: 2.4376441717304007
Validation loss: 2.5096679709360226

Epoch: 6| Step: 7
Training loss: 2.6460079425856913
Validation loss: 2.4970646833203256

Epoch: 6| Step: 8
Training loss: 3.1359287659086768
Validation loss: 2.4804580715376887

Epoch: 6| Step: 9
Training loss: 2.686133991219839
Validation loss: 2.4917710314676094

Epoch: 6| Step: 10
Training loss: 1.9238387828860872
Validation loss: 2.509990146496528

Epoch: 6| Step: 11
Training loss: 2.380155889711044
Validation loss: 2.5089376074596346

Epoch: 6| Step: 12
Training loss: 3.2129442019184076
Validation loss: 2.5187500727336007

Epoch: 6| Step: 13
Training loss: 2.8456662606997956
Validation loss: 2.532379800653952

Epoch: 129| Step: 0
Training loss: 2.5695511174325523
Validation loss: 2.533987090977053

Epoch: 6| Step: 1
Training loss: 2.4372313913872796
Validation loss: 2.537994294351368

Epoch: 6| Step: 2
Training loss: 2.430784707544787
Validation loss: 2.545797781916493

Epoch: 6| Step: 3
Training loss: 2.63480498763105
Validation loss: 2.5684336991186654

Epoch: 6| Step: 4
Training loss: 3.297788375958564
Validation loss: 2.583420552208082

Epoch: 6| Step: 5
Training loss: 1.9444424931955386
Validation loss: 2.588545144219641

Epoch: 6| Step: 6
Training loss: 2.5202206163868333
Validation loss: 2.5546330201583416

Epoch: 6| Step: 7
Training loss: 2.4534060566254667
Validation loss: 2.551200567028654

Epoch: 6| Step: 8
Training loss: 2.9060480191174585
Validation loss: 2.5305357790977823

Epoch: 6| Step: 9
Training loss: 3.240576359853748
Validation loss: 2.5108153848166617

Epoch: 6| Step: 10
Training loss: 1.9628710693599873
Validation loss: 2.491065801923887

Epoch: 6| Step: 11
Training loss: 2.6854744308410705
Validation loss: 2.4788512007407633

Epoch: 6| Step: 12
Training loss: 2.6156479591811297
Validation loss: 2.481021127197915

Epoch: 6| Step: 13
Training loss: 2.818701709409784
Validation loss: 2.484209438634296

Epoch: 130| Step: 0
Training loss: 2.1176180806390037
Validation loss: 2.4703651742813793

Epoch: 6| Step: 1
Training loss: 2.327585144944028
Validation loss: 2.477430030261282

Epoch: 6| Step: 2
Training loss: 2.719768289626043
Validation loss: 2.485021255218051

Epoch: 6| Step: 3
Training loss: 1.9460537275795395
Validation loss: 2.532190577295688

Epoch: 6| Step: 4
Training loss: 2.627475842510929
Validation loss: 2.587534570267353

Epoch: 6| Step: 5
Training loss: 3.1805919513720733
Validation loss: 2.7182518447617094

Epoch: 6| Step: 6
Training loss: 3.5294925063378337
Validation loss: 2.8898865594381498

Epoch: 6| Step: 7
Training loss: 3.0509781816640764
Validation loss: 2.843824475095339

Epoch: 6| Step: 8
Training loss: 2.7496953275274105
Validation loss: 2.7337917501590794

Epoch: 6| Step: 9
Training loss: 2.9858279860378816
Validation loss: 2.5649475586209536

Epoch: 6| Step: 10
Training loss: 3.0032774188911984
Validation loss: 2.5081029588374966

Epoch: 6| Step: 11
Training loss: 2.9370123275794255
Validation loss: 2.4568698344272333

Epoch: 6| Step: 12
Training loss: 2.3060544889948673
Validation loss: 2.4437509930820576

Epoch: 6| Step: 13
Training loss: 1.5845674506986438
Validation loss: 2.441324966094788

Epoch: 131| Step: 0
Training loss: 1.8617546177337205
Validation loss: 2.446459491273476

Epoch: 6| Step: 1
Training loss: 2.6624249658175154
Validation loss: 2.4506122466180833

Epoch: 6| Step: 2
Training loss: 2.468298762163299
Validation loss: 2.444992339592395

Epoch: 6| Step: 3
Training loss: 3.1592373449143487
Validation loss: 2.4468279485658107

Epoch: 6| Step: 4
Training loss: 2.4554783897684027
Validation loss: 2.466027255427441

Epoch: 6| Step: 5
Training loss: 2.709449029634891
Validation loss: 2.482157870472596

Epoch: 6| Step: 6
Training loss: 2.6058904715449422
Validation loss: 2.5057526805193366

Epoch: 6| Step: 7
Training loss: 2.6134500263720826
Validation loss: 2.536994134782408

Epoch: 6| Step: 8
Training loss: 2.5661056086987375
Validation loss: 2.552759172373255

Epoch: 6| Step: 9
Training loss: 2.9445948852237613
Validation loss: 2.5991084176542043

Epoch: 6| Step: 10
Training loss: 2.388333687348571
Validation loss: 2.6270834833150483

Epoch: 6| Step: 11
Training loss: 2.473153062901745
Validation loss: 2.6986175879645575

Epoch: 6| Step: 12
Training loss: 3.4972219341083703
Validation loss: 2.72160787167649

Epoch: 6| Step: 13
Training loss: 2.6806380918596244
Validation loss: 2.6606404819650082

Epoch: 132| Step: 0
Training loss: 2.861681065583334
Validation loss: 2.594882180796666

Epoch: 6| Step: 1
Training loss: 2.221476853721662
Validation loss: 2.5398668684518095

Epoch: 6| Step: 2
Training loss: 2.815548918412731
Validation loss: 2.495603041842373

Epoch: 6| Step: 3
Training loss: 1.7285470733367982
Validation loss: 2.4654503627066613

Epoch: 6| Step: 4
Training loss: 2.305414841531288
Validation loss: 2.456925556542757

Epoch: 6| Step: 5
Training loss: 2.5622556616431855
Validation loss: 2.435825226899482

Epoch: 6| Step: 6
Training loss: 2.9954965486132523
Validation loss: 2.453875578719296

Epoch: 6| Step: 7
Training loss: 3.276976063486962
Validation loss: 2.4426465630906815

Epoch: 6| Step: 8
Training loss: 2.663395414985571
Validation loss: 2.4444393184784623

Epoch: 6| Step: 9
Training loss: 2.490450836946262
Validation loss: 2.4285477968817037

Epoch: 6| Step: 10
Training loss: 2.4934551399315517
Validation loss: 2.4375591412887667

Epoch: 6| Step: 11
Training loss: 2.8658364254364552
Validation loss: 2.4502178507558936

Epoch: 6| Step: 12
Training loss: 2.815065527741064
Validation loss: 2.5030229411946525

Epoch: 6| Step: 13
Training loss: 2.8462587127083103
Validation loss: 2.578189854755475

Epoch: 133| Step: 0
Training loss: 3.0249746589545
Validation loss: 2.688038150395948

Epoch: 6| Step: 1
Training loss: 2.4350170302529857
Validation loss: 2.7805412655035315

Epoch: 6| Step: 2
Training loss: 2.525207748931254
Validation loss: 2.8783104319327926

Epoch: 6| Step: 3
Training loss: 3.29109632806279
Validation loss: 2.9821209058770637

Epoch: 6| Step: 4
Training loss: 2.4544737200096516
Validation loss: 2.952063454820799

Epoch: 6| Step: 5
Training loss: 2.836276788093284
Validation loss: 2.7962931402812288

Epoch: 6| Step: 6
Training loss: 2.779727133114024
Validation loss: 2.6176318640390215

Epoch: 6| Step: 7
Training loss: 2.14193195624604
Validation loss: 2.5401629268364707

Epoch: 6| Step: 8
Training loss: 2.436564045722474
Validation loss: 2.514240016885383

Epoch: 6| Step: 9
Training loss: 2.351379995773011
Validation loss: 2.4690139523481767

Epoch: 6| Step: 10
Training loss: 2.9247230072588843
Validation loss: 2.4621022208132715

Epoch: 6| Step: 11
Training loss: 1.8788738922061057
Validation loss: 2.4697537690142672

Epoch: 6| Step: 12
Training loss: 2.9899450918405974
Validation loss: 2.49190976396793

Epoch: 6| Step: 13
Training loss: 3.087786851909028
Validation loss: 2.501241155393524

Epoch: 134| Step: 0
Training loss: 2.8719124178270037
Validation loss: 2.5163056274418634

Epoch: 6| Step: 1
Training loss: 3.0075290298646356
Validation loss: 2.5020956157178524

Epoch: 6| Step: 2
Training loss: 2.5529488062673478
Validation loss: 2.508480888291753

Epoch: 6| Step: 3
Training loss: 2.97597563958196
Validation loss: 2.522737898863051

Epoch: 6| Step: 4
Training loss: 2.4820159652282556
Validation loss: 2.54887621339991

Epoch: 6| Step: 5
Training loss: 2.1206020396479586
Validation loss: 2.564167271658191

Epoch: 6| Step: 6
Training loss: 2.7426562655778213
Validation loss: 2.5828429724941753

Epoch: 6| Step: 7
Training loss: 1.9245644336715872
Validation loss: 2.592921709275513

Epoch: 6| Step: 8
Training loss: 2.9365378894202907
Validation loss: 2.623473853243599

Epoch: 6| Step: 9
Training loss: 2.756067085684279
Validation loss: 2.6405650845204782

Epoch: 6| Step: 10
Training loss: 2.7789255780182494
Validation loss: 2.6154094123653144

Epoch: 6| Step: 11
Training loss: 2.7343232068197474
Validation loss: 2.6363684894594765

Epoch: 6| Step: 12
Training loss: 1.7301698861471437
Validation loss: 2.625930273614502

Epoch: 6| Step: 13
Training loss: 3.18835647146547
Validation loss: 2.629780276878086

Epoch: 135| Step: 0
Training loss: 2.737268976365788
Validation loss: 2.600557794915743

Epoch: 6| Step: 1
Training loss: 2.3172663463674876
Validation loss: 2.56259480042656

Epoch: 6| Step: 2
Training loss: 2.351014336351228
Validation loss: 2.539658929711392

Epoch: 6| Step: 3
Training loss: 2.4120670700996643
Validation loss: 2.5072229762197713

Epoch: 6| Step: 4
Training loss: 2.5947592736458978
Validation loss: 2.4901464395843464

Epoch: 6| Step: 5
Training loss: 2.7186552886250843
Validation loss: 2.4535341973769005

Epoch: 6| Step: 6
Training loss: 2.109160009660267
Validation loss: 2.45034233319222

Epoch: 6| Step: 7
Training loss: 2.60815382838457
Validation loss: 2.4270769717992966

Epoch: 6| Step: 8
Training loss: 2.8098199578977976
Validation loss: 2.426179056098215

Epoch: 6| Step: 9
Training loss: 2.939593928313723
Validation loss: 2.4258519699807852

Epoch: 6| Step: 10
Training loss: 2.7434917076379017
Validation loss: 2.4247396738087277

Epoch: 6| Step: 11
Training loss: 3.0605658826986337
Validation loss: 2.4345316991629873

Epoch: 6| Step: 12
Training loss: 2.4528738488573363
Validation loss: 2.4345960322713482

Epoch: 6| Step: 13
Training loss: 2.809990080819322
Validation loss: 2.443240692909429

Epoch: 136| Step: 0
Training loss: 3.00711931440123
Validation loss: 2.470533088158248

Epoch: 6| Step: 1
Training loss: 2.329073719042167
Validation loss: 2.5383772507968794

Epoch: 6| Step: 2
Training loss: 1.7764100692967
Validation loss: 2.600565480233447

Epoch: 6| Step: 3
Training loss: 2.321372871988303
Validation loss: 2.678583416186813

Epoch: 6| Step: 4
Training loss: 3.0534084598455298
Validation loss: 2.720009289239467

Epoch: 6| Step: 5
Training loss: 2.629408631070018
Validation loss: 2.7015633478274075

Epoch: 6| Step: 6
Training loss: 2.3701599393870336
Validation loss: 2.648586648321737

Epoch: 6| Step: 7
Training loss: 2.747703199986058
Validation loss: 2.617010037523615

Epoch: 6| Step: 8
Training loss: 2.225018417625066
Validation loss: 2.601379519157589

Epoch: 6| Step: 9
Training loss: 2.801844779333871
Validation loss: 2.5861207501609114

Epoch: 6| Step: 10
Training loss: 3.2834273607245064
Validation loss: 2.572585066384807

Epoch: 6| Step: 11
Training loss: 1.8536765347287678
Validation loss: 2.552506563721507

Epoch: 6| Step: 12
Training loss: 2.785900984785279
Validation loss: 2.520907289509499

Epoch: 6| Step: 13
Training loss: 2.4694845338172198
Validation loss: 2.525117694293054

Epoch: 137| Step: 0
Training loss: 1.844685527290583
Validation loss: 2.5322762630334634

Epoch: 6| Step: 1
Training loss: 2.523759189568199
Validation loss: 2.5200789470387117

Epoch: 6| Step: 2
Training loss: 2.466773292024049
Validation loss: 2.5248555431348185

Epoch: 6| Step: 3
Training loss: 2.2439976207564145
Validation loss: 2.5460988667767666

Epoch: 6| Step: 4
Training loss: 2.54184596153689
Validation loss: 2.5466572728676646

Epoch: 6| Step: 5
Training loss: 2.808718703757273
Validation loss: 2.554599491131395

Epoch: 6| Step: 6
Training loss: 2.5895694915409733
Validation loss: 2.5697937495615926

Epoch: 6| Step: 7
Training loss: 2.9820442085494245
Validation loss: 2.581713680457657

Epoch: 6| Step: 8
Training loss: 1.933022401185539
Validation loss: 2.597272293763104

Epoch: 6| Step: 9
Training loss: 2.4286569452055424
Validation loss: 2.60913220585715

Epoch: 6| Step: 10
Training loss: 2.60027842864839
Validation loss: 2.6144837917480896

Epoch: 6| Step: 11
Training loss: 3.5579805316874893
Validation loss: 2.5968305310580155

Epoch: 6| Step: 12
Training loss: 1.9125584512392655
Validation loss: 2.5805772968246803

Epoch: 6| Step: 13
Training loss: 2.7159117868786615
Validation loss: 2.56520440931365

Epoch: 138| Step: 0
Training loss: 2.4143924425933343
Validation loss: 2.5459386716328036

Epoch: 6| Step: 1
Training loss: 2.8091471714402125
Validation loss: 2.5345204791721914

Epoch: 6| Step: 2
Training loss: 2.478116194912636
Validation loss: 2.530397225682908

Epoch: 6| Step: 3
Training loss: 2.7537223592194326
Validation loss: 2.546084131910769

Epoch: 6| Step: 4
Training loss: 2.282202534840889
Validation loss: 2.5590053211983563

Epoch: 6| Step: 5
Training loss: 2.3736509205819507
Validation loss: 2.580087959921819

Epoch: 6| Step: 6
Training loss: 2.6757851705035147
Validation loss: 2.60223221595594

Epoch: 6| Step: 7
Training loss: 2.5240663860858352
Validation loss: 2.6031607501780427

Epoch: 6| Step: 8
Training loss: 2.794899183990262
Validation loss: 2.601285637453936

Epoch: 6| Step: 9
Training loss: 2.4951764303142965
Validation loss: 2.571469222675419

Epoch: 6| Step: 10
Training loss: 2.2643425830749666
Validation loss: 2.564636808205257

Epoch: 6| Step: 11
Training loss: 1.863612243555465
Validation loss: 2.5574869361567605

Epoch: 6| Step: 12
Training loss: 2.3246332392030924
Validation loss: 2.534263037995591

Epoch: 6| Step: 13
Training loss: 3.1501213474212393
Validation loss: 2.5081350580202892

Epoch: 139| Step: 0
Training loss: 2.475875614831979
Validation loss: 2.4782339795667467

Epoch: 6| Step: 1
Training loss: 2.0908316015502684
Validation loss: 2.450599185743736

Epoch: 6| Step: 2
Training loss: 2.691767033062933
Validation loss: 2.453196234864394

Epoch: 6| Step: 3
Training loss: 2.672914358620206
Validation loss: 2.4326254924382558

Epoch: 6| Step: 4
Training loss: 1.7328076540549844
Validation loss: 2.4299272457790706

Epoch: 6| Step: 5
Training loss: 3.0112649499024062
Validation loss: 2.4229354584967115

Epoch: 6| Step: 6
Training loss: 2.2678575762479043
Validation loss: 2.4278457572887753

Epoch: 6| Step: 7
Training loss: 2.0240449325037093
Validation loss: 2.440990719846478

Epoch: 6| Step: 8
Training loss: 2.800910893502952
Validation loss: 2.440338150513268

Epoch: 6| Step: 9
Training loss: 2.9153522981308444
Validation loss: 2.4632096913183563

Epoch: 6| Step: 10
Training loss: 2.25872604737409
Validation loss: 2.4752104944714075

Epoch: 6| Step: 11
Training loss: 2.869585827174201
Validation loss: 2.494740819959855

Epoch: 6| Step: 12
Training loss: 2.9319605439928353
Validation loss: 2.528232231458418

Epoch: 6| Step: 13
Training loss: 2.278193372582143
Validation loss: 2.555338038370075

Epoch: 140| Step: 0
Training loss: 2.4900071702417295
Validation loss: 2.6405784329534385

Epoch: 6| Step: 1
Training loss: 2.2200526322320315
Validation loss: 2.717674754671295

Epoch: 6| Step: 2
Training loss: 2.104443811980254
Validation loss: 2.789177326676508

Epoch: 6| Step: 3
Training loss: 2.355213461432652
Validation loss: 2.8280525350071195

Epoch: 6| Step: 4
Training loss: 2.94868547279225
Validation loss: 2.8490127759541544

Epoch: 6| Step: 5
Training loss: 2.7252811601811975
Validation loss: 2.8366015780029405

Epoch: 6| Step: 6
Training loss: 2.8988911975393106
Validation loss: 2.773539458172457

Epoch: 6| Step: 7
Training loss: 2.5726563686228334
Validation loss: 2.6599890782115616

Epoch: 6| Step: 8
Training loss: 2.55108491220472
Validation loss: 2.575382386506428

Epoch: 6| Step: 9
Training loss: 2.4071110757667795
Validation loss: 2.500138527098341

Epoch: 6| Step: 10
Training loss: 2.578546847885592
Validation loss: 2.4453598752268766

Epoch: 6| Step: 11
Training loss: 2.9323835251255477
Validation loss: 2.4421836211978127

Epoch: 6| Step: 12
Training loss: 2.758616300591726
Validation loss: 2.456732826650505

Epoch: 6| Step: 13
Training loss: 2.0791312628148124
Validation loss: 2.453927478332223

Epoch: 141| Step: 0
Training loss: 2.2922863440339283
Validation loss: 2.4660053045293635

Epoch: 6| Step: 1
Training loss: 2.7504936988867956
Validation loss: 2.4606535487798817

Epoch: 6| Step: 2
Training loss: 3.0430839232757156
Validation loss: 2.4526458150996913

Epoch: 6| Step: 3
Training loss: 2.1940114791973193
Validation loss: 2.4721344241328356

Epoch: 6| Step: 4
Training loss: 2.708516383709719
Validation loss: 2.472759922263938

Epoch: 6| Step: 5
Training loss: 1.9426635109756452
Validation loss: 2.5081457883203724

Epoch: 6| Step: 6
Training loss: 2.3394454082031166
Validation loss: 2.543557683209427

Epoch: 6| Step: 7
Training loss: 1.980906180504133
Validation loss: 2.597876399498251

Epoch: 6| Step: 8
Training loss: 2.3994568885766503
Validation loss: 2.661939328789127

Epoch: 6| Step: 9
Training loss: 2.4958912464315572
Validation loss: 2.6974696618404996

Epoch: 6| Step: 10
Training loss: 2.477733732220721
Validation loss: 2.7206733396392497

Epoch: 6| Step: 11
Training loss: 2.904183257907085
Validation loss: 2.7070452565420036

Epoch: 6| Step: 12
Training loss: 2.947303807116822
Validation loss: 2.744703491112197

Epoch: 6| Step: 13
Training loss: 3.1939782525781064
Validation loss: 2.718896006905819

Epoch: 142| Step: 0
Training loss: 2.1340875971082696
Validation loss: 2.6563196181572732

Epoch: 6| Step: 1
Training loss: 2.712409331744486
Validation loss: 2.6137423795253922

Epoch: 6| Step: 2
Training loss: 2.8418797641476794
Validation loss: 2.582262418261525

Epoch: 6| Step: 3
Training loss: 1.7468085479380429
Validation loss: 2.5245865885363186

Epoch: 6| Step: 4
Training loss: 2.267898471228278
Validation loss: 2.507537648861779

Epoch: 6| Step: 5
Training loss: 1.3687532886483038
Validation loss: 2.483636421371966

Epoch: 6| Step: 6
Training loss: 2.7014521014203288
Validation loss: 2.4627931795836995

Epoch: 6| Step: 7
Training loss: 3.0009315951622044
Validation loss: 2.48346235740221

Epoch: 6| Step: 8
Training loss: 2.8418009020590023
Validation loss: 2.462993087693639

Epoch: 6| Step: 9
Training loss: 1.7107903404178981
Validation loss: 2.478677873277001

Epoch: 6| Step: 10
Training loss: 2.3708434624838257
Validation loss: 2.493668224757917

Epoch: 6| Step: 11
Training loss: 3.259759188691968
Validation loss: 2.4977030908269153

Epoch: 6| Step: 12
Training loss: 3.0263808952678426
Validation loss: 2.513701777668322

Epoch: 6| Step: 13
Training loss: 2.3373016150839985
Validation loss: 2.528177174432465

Epoch: 143| Step: 0
Training loss: 2.2807541399768376
Validation loss: 2.568412516634596

Epoch: 6| Step: 1
Training loss: 2.468500148829594
Validation loss: 2.5898534706265033

Epoch: 6| Step: 2
Training loss: 2.102223345577235
Validation loss: 2.6338403262664443

Epoch: 6| Step: 3
Training loss: 2.3017205230061775
Validation loss: 2.6819032245432597

Epoch: 6| Step: 4
Training loss: 2.7821279275963344
Validation loss: 2.7150756349741614

Epoch: 6| Step: 5
Training loss: 2.814554777831142
Validation loss: 2.711828340948992

Epoch: 6| Step: 6
Training loss: 2.598597214149257
Validation loss: 2.699427353517603

Epoch: 6| Step: 7
Training loss: 2.615417610797486
Validation loss: 2.6759668544382595

Epoch: 6| Step: 8
Training loss: 2.30674729193461
Validation loss: 2.626224478341822

Epoch: 6| Step: 9
Training loss: 2.48582118905358
Validation loss: 2.584618296150275

Epoch: 6| Step: 10
Training loss: 2.156891879311647
Validation loss: 2.5667543108896798

Epoch: 6| Step: 11
Training loss: 2.829629740133426
Validation loss: 2.545426871560891

Epoch: 6| Step: 12
Training loss: 1.9464793554857953
Validation loss: 2.5328695306066336

Epoch: 6| Step: 13
Training loss: 2.8200742668490903
Validation loss: 2.509589020567818

Epoch: 144| Step: 0
Training loss: 2.202394404916415
Validation loss: 2.5112052138227616

Epoch: 6| Step: 1
Training loss: 2.411334820763879
Validation loss: 2.512435648234902

Epoch: 6| Step: 2
Training loss: 2.820580889751887
Validation loss: 2.506582707978158

Epoch: 6| Step: 3
Training loss: 2.1849930703339147
Validation loss: 2.508757709480067

Epoch: 6| Step: 4
Training loss: 2.165378652325449
Validation loss: 2.5133245781999816

Epoch: 6| Step: 5
Training loss: 2.5003341451498726
Validation loss: 2.518427738748736

Epoch: 6| Step: 6
Training loss: 2.403977249678931
Validation loss: 2.551190898091896

Epoch: 6| Step: 7
Training loss: 2.1696632155551483
Validation loss: 2.5575682821270282

Epoch: 6| Step: 8
Training loss: 2.410317092548883
Validation loss: 2.5717282186967445

Epoch: 6| Step: 9
Training loss: 2.8180981341156057
Validation loss: 2.5824774622053095

Epoch: 6| Step: 10
Training loss: 2.1447545892426465
Validation loss: 2.6128169248313804

Epoch: 6| Step: 11
Training loss: 2.645180198574091
Validation loss: 2.6381765422759567

Epoch: 6| Step: 12
Training loss: 2.382935767815649
Validation loss: 2.6644351611853065

Epoch: 6| Step: 13
Training loss: 2.5175322890270833
Validation loss: 2.6616269321056945

Epoch: 145| Step: 0
Training loss: 2.0074599138297993
Validation loss: 2.674814421402083

Epoch: 6| Step: 1
Training loss: 2.4844571465880474
Validation loss: 2.6710142216968715

Epoch: 6| Step: 2
Training loss: 2.3417149164335553
Validation loss: 2.660494272873515

Epoch: 6| Step: 3
Training loss: 2.5661910850871306
Validation loss: 2.6374688375708555

Epoch: 6| Step: 4
Training loss: 2.423424305194324
Validation loss: 2.6355038359781444

Epoch: 6| Step: 5
Training loss: 1.9663298733367114
Validation loss: 2.6401445699667154

Epoch: 6| Step: 6
Training loss: 2.3554412182263285
Validation loss: 2.6433359574432913

Epoch: 6| Step: 7
Training loss: 2.5970830987760563
Validation loss: 2.606498945438814

Epoch: 6| Step: 8
Training loss: 2.635088109781811
Validation loss: 2.5870248225970602

Epoch: 6| Step: 9
Training loss: 2.0114172255827714
Validation loss: 2.5796411008511675

Epoch: 6| Step: 10
Training loss: 2.5538089653149942
Validation loss: 2.5661251498352096

Epoch: 6| Step: 11
Training loss: 2.2673028455189526
Validation loss: 2.573000790235136

Epoch: 6| Step: 12
Training loss: 3.066016844303172
Validation loss: 2.5559825225845056

Epoch: 6| Step: 13
Training loss: 1.7977170215266625
Validation loss: 2.57261876160222

Epoch: 146| Step: 0
Training loss: 2.7770249067047446
Validation loss: 2.577306184479153

Epoch: 6| Step: 1
Training loss: 2.043308207972986
Validation loss: 2.5938002285848674

Epoch: 6| Step: 2
Training loss: 2.2686652469830477
Validation loss: 2.6036730298846207

Epoch: 6| Step: 3
Training loss: 2.331447815875761
Validation loss: 2.6324019875339655

Epoch: 6| Step: 4
Training loss: 2.5332100896805763
Validation loss: 2.6493380815201357

Epoch: 6| Step: 5
Training loss: 2.2463741757688176
Validation loss: 2.6591022685005354

Epoch: 6| Step: 6
Training loss: 2.388986362518948
Validation loss: 2.673864451402466

Epoch: 6| Step: 7
Training loss: 2.1395567295855913
Validation loss: 2.6933006574040976

Epoch: 6| Step: 8
Training loss: 1.935715130095431
Validation loss: 2.7176773912532064

Epoch: 6| Step: 9
Training loss: 2.5633854150462385
Validation loss: 2.7067380155413483

Epoch: 6| Step: 10
Training loss: 2.1324549784050113
Validation loss: 2.6846088560687957

Epoch: 6| Step: 11
Training loss: 2.939472429079055
Validation loss: 2.6455660326397634

Epoch: 6| Step: 12
Training loss: 2.2640491135058665
Validation loss: 2.5906763824042494

Epoch: 6| Step: 13
Training loss: 2.59601301262273
Validation loss: 2.55166179766016

Epoch: 147| Step: 0
Training loss: 2.4826463167187622
Validation loss: 2.5213255890211896

Epoch: 6| Step: 1
Training loss: 1.955005930235471
Validation loss: 2.5083242032402047

Epoch: 6| Step: 2
Training loss: 1.9323751289322721
Validation loss: 2.504096244957635

Epoch: 6| Step: 3
Training loss: 2.5286501495816878
Validation loss: 2.5030132490029016

Epoch: 6| Step: 4
Training loss: 2.1048376945933516
Validation loss: 2.5003719289026707

Epoch: 6| Step: 5
Training loss: 2.0352585193908843
Validation loss: 2.519940170169355

Epoch: 6| Step: 6
Training loss: 2.2560766602606073
Validation loss: 2.5216720990430423

Epoch: 6| Step: 7
Training loss: 2.5830592245887734
Validation loss: 2.5359408434881194

Epoch: 6| Step: 8
Training loss: 2.8586201322786744
Validation loss: 2.5645434427848044

Epoch: 6| Step: 9
Training loss: 2.3528637501655854
Validation loss: 2.573631460011173

Epoch: 6| Step: 10
Training loss: 2.8756975074188182
Validation loss: 2.600774611525963

Epoch: 6| Step: 11
Training loss: 2.369738623615818
Validation loss: 2.606386345385838

Epoch: 6| Step: 12
Training loss: 2.48039127739497
Validation loss: 2.62168250788684

Epoch: 6| Step: 13
Training loss: 2.39395796865918
Validation loss: 2.5922028134743895

Epoch: 148| Step: 0
Training loss: 2.52202838492699
Validation loss: 2.5688929802915035

Epoch: 6| Step: 1
Training loss: 1.8644858251325918
Validation loss: 2.574322617317722

Epoch: 6| Step: 2
Training loss: 2.349562900556066
Validation loss: 2.5612494055431907

Epoch: 6| Step: 3
Training loss: 2.4630005923110554
Validation loss: 2.564877132556247

Epoch: 6| Step: 4
Training loss: 2.586054865544937
Validation loss: 2.563506392235558

Epoch: 6| Step: 5
Training loss: 1.6863438212972226
Validation loss: 2.574725596542499

Epoch: 6| Step: 6
Training loss: 2.248471482625188
Validation loss: 2.5956182826870027

Epoch: 6| Step: 7
Training loss: 2.7843512914057085
Validation loss: 2.62066234775123

Epoch: 6| Step: 8
Training loss: 1.7910740633783382
Validation loss: 2.5795414558296956

Epoch: 6| Step: 9
Training loss: 2.946240023570595
Validation loss: 2.560921549772257

Epoch: 6| Step: 10
Training loss: 1.7767283285914548
Validation loss: 2.5612353003477986

Epoch: 6| Step: 11
Training loss: 2.4316550380785196
Validation loss: 2.5471477391449056

Epoch: 6| Step: 12
Training loss: 2.408128673828871
Validation loss: 2.549632078117668

Epoch: 6| Step: 13
Training loss: 2.413696952722885
Validation loss: 2.5519642430224043

Epoch: 149| Step: 0
Training loss: 2.65907012231819
Validation loss: 2.560884285978167

Epoch: 6| Step: 1
Training loss: 1.7748482760205353
Validation loss: 2.5746187194420345

Epoch: 6| Step: 2
Training loss: 2.5001278844549435
Validation loss: 2.590205010086613

Epoch: 6| Step: 3
Training loss: 3.044245597706478
Validation loss: 2.6472207285714173

Epoch: 6| Step: 4
Training loss: 1.830407828449968
Validation loss: 2.656520540670472

Epoch: 6| Step: 5
Training loss: 2.4407476650775064
Validation loss: 2.6254591288830023

Epoch: 6| Step: 6
Training loss: 2.4288729071820874
Validation loss: 2.5752589747750134

Epoch: 6| Step: 7
Training loss: 2.3097223663279056
Validation loss: 2.534081347506391

Epoch: 6| Step: 8
Training loss: 1.5082558884242523
Validation loss: 2.5235726701817964

Epoch: 6| Step: 9
Training loss: 2.440821512006337
Validation loss: 2.5014353436156345

Epoch: 6| Step: 10
Training loss: 2.2831102911984176
Validation loss: 2.4901736031632278

Epoch: 6| Step: 11
Training loss: 2.089466438814437
Validation loss: 2.484866623449274

Epoch: 6| Step: 12
Training loss: 2.641355334527118
Validation loss: 2.5013397144442244

Epoch: 6| Step: 13
Training loss: 2.0584153852698024
Validation loss: 2.523417801003711

Epoch: 150| Step: 0
Training loss: 2.609487382673001
Validation loss: 2.5408466774124783

Epoch: 6| Step: 1
Training loss: 2.6641236239494037
Validation loss: 2.549389688162074

Epoch: 6| Step: 2
Training loss: 2.1428836684628827
Validation loss: 2.5714556730161946

Epoch: 6| Step: 3
Training loss: 2.4111676188506364
Validation loss: 2.585326931615396

Epoch: 6| Step: 4
Training loss: 2.446923745791541
Validation loss: 2.5976748629666555

Epoch: 6| Step: 5
Training loss: 1.64291440082071
Validation loss: 2.616506700490154

Epoch: 6| Step: 6
Training loss: 2.028497209764705
Validation loss: 2.637065798678612

Epoch: 6| Step: 7
Training loss: 2.1263035534590626
Validation loss: 2.6707626202358794

Epoch: 6| Step: 8
Training loss: 2.457838935491625
Validation loss: 2.700512721754518

Epoch: 6| Step: 9
Training loss: 2.12192705902374
Validation loss: 2.682097065205598

Epoch: 6| Step: 10
Training loss: 2.656473127979143
Validation loss: 2.6810585412369856

Epoch: 6| Step: 11
Training loss: 2.063185837896523
Validation loss: 2.663301352365721

Epoch: 6| Step: 12
Training loss: 2.5223584776422814
Validation loss: 2.628601428087924

Epoch: 6| Step: 13
Training loss: 1.7275831563011446
Validation loss: 2.6485262237719205

Epoch: 151| Step: 0
Training loss: 1.9674582709379327
Validation loss: 2.6540954895438564

Epoch: 6| Step: 1
Training loss: 2.215710559478884
Validation loss: 2.6632273674387226

Epoch: 6| Step: 2
Training loss: 1.8553943498652687
Validation loss: 2.6518737259548626

Epoch: 6| Step: 3
Training loss: 2.3112131610779523
Validation loss: 2.6133973316449457

Epoch: 6| Step: 4
Training loss: 2.410550819385091
Validation loss: 2.5740240619309644

Epoch: 6| Step: 5
Training loss: 2.4050379090682075
Validation loss: 2.515317634786207

Epoch: 6| Step: 6
Training loss: 2.6114186946709546
Validation loss: 2.488673478737737

Epoch: 6| Step: 7
Training loss: 2.49715557407846
Validation loss: 2.4556680486263702

Epoch: 6| Step: 8
Training loss: 1.8259356830463187
Validation loss: 2.463914603425606

Epoch: 6| Step: 9
Training loss: 2.2057129289974444
Validation loss: 2.4623219429581056

Epoch: 6| Step: 10
Training loss: 2.093734171793308
Validation loss: 2.459890221606492

Epoch: 6| Step: 11
Training loss: 2.163848535860359
Validation loss: 2.46769886477242

Epoch: 6| Step: 12
Training loss: 2.4410562249084027
Validation loss: 2.515799024480082

Epoch: 6| Step: 13
Training loss: 3.3318469230228795
Validation loss: 2.5197334195084666

Epoch: 152| Step: 0
Training loss: 2.9088213630449933
Validation loss: 2.5722636954908222

Epoch: 6| Step: 1
Training loss: 2.360822423103384
Validation loss: 2.6265344563876027

Epoch: 6| Step: 2
Training loss: 1.9385809805394076
Validation loss: 2.6552953202465206

Epoch: 6| Step: 3
Training loss: 1.285419286460412
Validation loss: 2.689494124588171

Epoch: 6| Step: 4
Training loss: 1.9468402302241041
Validation loss: 2.732842492492511

Epoch: 6| Step: 5
Training loss: 2.8357863372785688
Validation loss: 2.769784741136033

Epoch: 6| Step: 6
Training loss: 2.658896081925956
Validation loss: 2.709492941735269

Epoch: 6| Step: 7
Training loss: 2.1356037585168073
Validation loss: 2.641961921567277

Epoch: 6| Step: 8
Training loss: 2.1143863630088133
Validation loss: 2.5690141930871584

Epoch: 6| Step: 9
Training loss: 2.5923776328067367
Validation loss: 2.5288955735643306

Epoch: 6| Step: 10
Training loss: 2.5478876827043924
Validation loss: 2.5113007883752467

Epoch: 6| Step: 11
Training loss: 2.177839144936338
Validation loss: 2.500080929748569

Epoch: 6| Step: 12
Training loss: 1.902775208346944
Validation loss: 2.479939731534777

Epoch: 6| Step: 13
Training loss: 1.607919201215829
Validation loss: 2.454076594549421

Epoch: 153| Step: 0
Training loss: 2.4195111952268635
Validation loss: 2.4482937992041216

Epoch: 6| Step: 1
Training loss: 1.4726754346655306
Validation loss: 2.4430189754875813

Epoch: 6| Step: 2
Training loss: 2.3566950046430843
Validation loss: 2.44464447962449

Epoch: 6| Step: 3
Training loss: 2.149094359813643
Validation loss: 2.4934779945262093

Epoch: 6| Step: 4
Training loss: 1.742228007166421
Validation loss: 2.538115920701051

Epoch: 6| Step: 5
Training loss: 2.279941549388477
Validation loss: 2.598709542038963

Epoch: 6| Step: 6
Training loss: 2.4192151630239263
Validation loss: 2.6635267088007986

Epoch: 6| Step: 7
Training loss: 2.3201293873058746
Validation loss: 2.6505678730482196

Epoch: 6| Step: 8
Training loss: 2.157567381972453
Validation loss: 2.666113711204042

Epoch: 6| Step: 9
Training loss: 2.6579633684525996
Validation loss: 2.639339151668481

Epoch: 6| Step: 10
Training loss: 2.0846677194285057
Validation loss: 2.602870886224085

Epoch: 6| Step: 11
Training loss: 2.833750656659589
Validation loss: 2.553042446088133

Epoch: 6| Step: 12
Training loss: 2.4902737244133752
Validation loss: 2.5094114285799107

Epoch: 6| Step: 13
Training loss: 2.315672373834052
Validation loss: 2.4988787013025417

Epoch: 154| Step: 0
Training loss: 2.3716604947483217
Validation loss: 2.479558377245017

Epoch: 6| Step: 1
Training loss: 2.2509221200710168
Validation loss: 2.4514942725402302

Epoch: 6| Step: 2
Training loss: 2.503856545370058
Validation loss: 2.4350405638798547

Epoch: 6| Step: 3
Training loss: 2.294830865881608
Validation loss: 2.446792947497731

Epoch: 6| Step: 4
Training loss: 1.560149905020429
Validation loss: 2.458473309688734

Epoch: 6| Step: 5
Training loss: 2.2657102371493014
Validation loss: 2.460311177094024

Epoch: 6| Step: 6
Training loss: 2.0266307245798467
Validation loss: 2.456949284126361

Epoch: 6| Step: 7
Training loss: 1.7235664160370272
Validation loss: 2.468304840198405

Epoch: 6| Step: 8
Training loss: 2.2063132949697564
Validation loss: 2.51887290718024

Epoch: 6| Step: 9
Training loss: 2.9039867161113313
Validation loss: 2.551519341563443

Epoch: 6| Step: 10
Training loss: 2.3905089107076867
Validation loss: 2.570561405142201

Epoch: 6| Step: 11
Training loss: 2.3034716486311186
Validation loss: 2.626418567862574

Epoch: 6| Step: 12
Training loss: 2.0215697634441607
Validation loss: 2.6646900221612215

Epoch: 6| Step: 13
Training loss: 2.459101982425097
Validation loss: 2.696741224751655

Epoch: 155| Step: 0
Training loss: 2.0504327968476384
Validation loss: 2.686790576812209

Epoch: 6| Step: 1
Training loss: 2.1083862247793586
Validation loss: 2.647404682195418

Epoch: 6| Step: 2
Training loss: 2.4093938329532074
Validation loss: 2.6296339771072024

Epoch: 6| Step: 3
Training loss: 2.129102673349632
Validation loss: 2.613396817621376

Epoch: 6| Step: 4
Training loss: 2.0273244632692906
Validation loss: 2.5844436135847957

Epoch: 6| Step: 5
Training loss: 2.574033692904868
Validation loss: 2.5616723111255437

Epoch: 6| Step: 6
Training loss: 2.158188100909244
Validation loss: 2.53796989312845

Epoch: 6| Step: 7
Training loss: 1.9942442206693176
Validation loss: 2.511031308961391

Epoch: 6| Step: 8
Training loss: 1.851864045774085
Validation loss: 2.51533716280256

Epoch: 6| Step: 9
Training loss: 2.0318812636505053
Validation loss: 2.4784261773540783

Epoch: 6| Step: 10
Training loss: 2.782651569525954
Validation loss: 2.457909853295434

Epoch: 6| Step: 11
Training loss: 2.060915251431748
Validation loss: 2.470204033264758

Epoch: 6| Step: 12
Training loss: 2.019534673632555
Validation loss: 2.4568287134878113

Epoch: 6| Step: 13
Training loss: 2.5454624682154527
Validation loss: 2.4624392233623955

Epoch: 156| Step: 0
Training loss: 2.087785680718809
Validation loss: 2.499474579962236

Epoch: 6| Step: 1
Training loss: 2.2749110948566655
Validation loss: 2.529728367163426

Epoch: 6| Step: 2
Training loss: 2.3649801405865234
Validation loss: 2.5577243179719225

Epoch: 6| Step: 3
Training loss: 1.790834640294174
Validation loss: 2.6034983023783633

Epoch: 6| Step: 4
Training loss: 2.2595403587010514
Validation loss: 2.5888485646832606

Epoch: 6| Step: 5
Training loss: 2.376456566931986
Validation loss: 2.5943060668173636

Epoch: 6| Step: 6
Training loss: 1.9401899553486235
Validation loss: 2.5740265364074824

Epoch: 6| Step: 7
Training loss: 2.1678477760448356
Validation loss: 2.566164127764015

Epoch: 6| Step: 8
Training loss: 2.0328904790091364
Validation loss: 2.5568314328994344

Epoch: 6| Step: 9
Training loss: 2.0544106184491886
Validation loss: 2.5485754164147494

Epoch: 6| Step: 10
Training loss: 2.3758971878760193
Validation loss: 2.550629882261051

Epoch: 6| Step: 11
Training loss: 2.389255305831269
Validation loss: 2.5502450623765154

Epoch: 6| Step: 12
Training loss: 2.3449968200531894
Validation loss: 2.552187586537005

Epoch: 6| Step: 13
Training loss: 1.783462956729613
Validation loss: 2.557717760831101

Epoch: 157| Step: 0
Training loss: 2.3763957690579
Validation loss: 2.516552001651531

Epoch: 6| Step: 1
Training loss: 1.957715917885642
Validation loss: 2.519241135951958

Epoch: 6| Step: 2
Training loss: 1.7291888806245224
Validation loss: 2.510610551937507

Epoch: 6| Step: 3
Training loss: 2.6926268535119045
Validation loss: 2.4905853980211012

Epoch: 6| Step: 4
Training loss: 2.1473254845866685
Validation loss: 2.510074490208811

Epoch: 6| Step: 5
Training loss: 2.3338853886893935
Validation loss: 2.527254036232585

Epoch: 6| Step: 6
Training loss: 2.5577501143745467
Validation loss: 2.571270390139568

Epoch: 6| Step: 7
Training loss: 1.7928680857073123
Validation loss: 2.5982895074245196

Epoch: 6| Step: 8
Training loss: 2.373074503922237
Validation loss: 2.656701488597329

Epoch: 6| Step: 9
Training loss: 2.332582648183749
Validation loss: 2.7177213779294047

Epoch: 6| Step: 10
Training loss: 1.6299876184519815
Validation loss: 2.703711737244051

Epoch: 6| Step: 11
Training loss: 2.096006856703281
Validation loss: 2.6805224785249986

Epoch: 6| Step: 12
Training loss: 2.036255523130866
Validation loss: 2.6499528299855664

Epoch: 6| Step: 13
Training loss: 2.541624214776725
Validation loss: 2.5970725207437204

Epoch: 158| Step: 0
Training loss: 2.475154247679261
Validation loss: 2.5638024606428775

Epoch: 6| Step: 1
Training loss: 1.6985225259647623
Validation loss: 2.551728456261764

Epoch: 6| Step: 2
Training loss: 2.414379210205515
Validation loss: 2.5301210100410096

Epoch: 6| Step: 3
Training loss: 2.0296947687619435
Validation loss: 2.520246332813331

Epoch: 6| Step: 4
Training loss: 2.658255952846894
Validation loss: 2.5191043869592145

Epoch: 6| Step: 5
Training loss: 2.2128465585790593
Validation loss: 2.5028571056221773

Epoch: 6| Step: 6
Training loss: 1.949254404479615
Validation loss: 2.53632152038728

Epoch: 6| Step: 7
Training loss: 2.1489184032089033
Validation loss: 2.5263005802138023

Epoch: 6| Step: 8
Training loss: 2.4997506971033046
Validation loss: 2.5331197436769246

Epoch: 6| Step: 9
Training loss: 2.2692992835413426
Validation loss: 2.561843414786399

Epoch: 6| Step: 10
Training loss: 1.4388086747468738
Validation loss: 2.5531482372500944

Epoch: 6| Step: 11
Training loss: 1.5675204683029131
Validation loss: 2.5594313140422904

Epoch: 6| Step: 12
Training loss: 1.989964819745737
Validation loss: 2.5590472326357627

Epoch: 6| Step: 13
Training loss: 2.077435830935057
Validation loss: 2.572721649214887

Epoch: 159| Step: 0
Training loss: 1.9160784012118226
Validation loss: 2.5848608509080044

Epoch: 6| Step: 1
Training loss: 2.6572059257628453
Validation loss: 2.5944257108822963

Epoch: 6| Step: 2
Training loss: 1.8520619165521761
Validation loss: 2.5864729332385554

Epoch: 6| Step: 3
Training loss: 2.060135613208997
Validation loss: 2.57508483206974

Epoch: 6| Step: 4
Training loss: 1.869840516822119
Validation loss: 2.5399943393766606

Epoch: 6| Step: 5
Training loss: 1.8516113017286346
Validation loss: 2.536827716629331

Epoch: 6| Step: 6
Training loss: 1.9144466715269788
Validation loss: 2.5243670771408167

Epoch: 6| Step: 7
Training loss: 1.7681099613179858
Validation loss: 2.5241211681570124

Epoch: 6| Step: 8
Training loss: 2.3848735962965626
Validation loss: 2.5414442156337875

Epoch: 6| Step: 9
Training loss: 2.3721423776169672
Validation loss: 2.5315834655237475

Epoch: 6| Step: 10
Training loss: 2.016831502667029
Validation loss: 2.5471814719391475

Epoch: 6| Step: 11
Training loss: 2.5667670473888986
Validation loss: 2.577068526305987

Epoch: 6| Step: 12
Training loss: 1.7068615442763204
Validation loss: 2.5527186269561772

Epoch: 6| Step: 13
Training loss: 2.207756638950737
Validation loss: 2.56195186752236

Epoch: 160| Step: 0
Training loss: 2.4323690158435745
Validation loss: 2.5677721665885

Epoch: 6| Step: 1
Training loss: 2.273752931296214
Validation loss: 2.5823897397614526

Epoch: 6| Step: 2
Training loss: 1.8935024968431247
Validation loss: 2.584374523295475

Epoch: 6| Step: 3
Training loss: 2.0884502007170878
Validation loss: 2.5811933766740527

Epoch: 6| Step: 4
Training loss: 2.016434854262437
Validation loss: 2.5859537288011665

Epoch: 6| Step: 5
Training loss: 1.9723093464312387
Validation loss: 2.5855662262113905

Epoch: 6| Step: 6
Training loss: 2.523593578885396
Validation loss: 2.566593843763286

Epoch: 6| Step: 7
Training loss: 1.2770901116112967
Validation loss: 2.5933092081037197

Epoch: 6| Step: 8
Training loss: 1.8390954960250856
Validation loss: 2.6090619849589016

Epoch: 6| Step: 9
Training loss: 1.8423552976228101
Validation loss: 2.6246514486942485

Epoch: 6| Step: 10
Training loss: 2.515889692893522
Validation loss: 2.6388500578491083

Epoch: 6| Step: 11
Training loss: 2.2541665599585583
Validation loss: 2.618451676403064

Epoch: 6| Step: 12
Training loss: 1.3730936707163868
Validation loss: 2.6126110330231658

Epoch: 6| Step: 13
Training loss: 2.42534423429875
Validation loss: 2.6168721317123977

Epoch: 161| Step: 0
Training loss: 2.0858998956041015
Validation loss: 2.6134906311339954

Epoch: 6| Step: 1
Training loss: 1.9439486583005217
Validation loss: 2.587830786327614

Epoch: 6| Step: 2
Training loss: 1.7549789988247488
Validation loss: 2.5745926698598383

Epoch: 6| Step: 3
Training loss: 2.298322779258007
Validation loss: 2.5939227176530664

Epoch: 6| Step: 4
Training loss: 2.1159028945592238
Validation loss: 2.5817632237110115

Epoch: 6| Step: 5
Training loss: 2.140992181848312
Validation loss: 2.6115451468875728

Epoch: 6| Step: 6
Training loss: 1.6757811788634527
Validation loss: 2.6022497243350244

Epoch: 6| Step: 7
Training loss: 2.857884252949947
Validation loss: 2.612061679851041

Epoch: 6| Step: 8
Training loss: 1.3281414704143024
Validation loss: 2.588233371975957

Epoch: 6| Step: 9
Training loss: 2.252568474341657
Validation loss: 2.5856003362575772

Epoch: 6| Step: 10
Training loss: 2.3787621264967975
Validation loss: 2.6044196985842922

Epoch: 6| Step: 11
Training loss: 1.4436768220133123
Validation loss: 2.604245547832968

Epoch: 6| Step: 12
Training loss: 1.3535703177363054
Validation loss: 2.600487411491047

Epoch: 6| Step: 13
Training loss: 2.623930031832153
Validation loss: 2.590526832175195

Epoch: 162| Step: 0
Training loss: 2.595370050994486
Validation loss: 2.6009897443307364

Epoch: 6| Step: 1
Training loss: 2.300355311605437
Validation loss: 2.6243007810760988

Epoch: 6| Step: 2
Training loss: 2.1626114921273647
Validation loss: 2.6283858140246865

Epoch: 6| Step: 3
Training loss: 1.1898280963631946
Validation loss: 2.6435334436279976

Epoch: 6| Step: 4
Training loss: 2.3078816666307675
Validation loss: 2.6378180248299445

Epoch: 6| Step: 5
Training loss: 1.8982788773189885
Validation loss: 2.6137577334152597

Epoch: 6| Step: 6
Training loss: 1.133514817984455
Validation loss: 2.605856821884143

Epoch: 6| Step: 7
Training loss: 2.0404304213005404
Validation loss: 2.578368376390529

Epoch: 6| Step: 8
Training loss: 2.0022007040127545
Validation loss: 2.5816286028226534

Epoch: 6| Step: 9
Training loss: 2.287714330085621
Validation loss: 2.61239111837754

Epoch: 6| Step: 10
Training loss: 1.4095856841080237
Validation loss: 2.637183930545224

Epoch: 6| Step: 11
Training loss: 2.329390725793306
Validation loss: 2.65504902877142

Epoch: 6| Step: 12
Training loss: 1.9393896916552467
Validation loss: 2.6451195159375174

Epoch: 6| Step: 13
Training loss: 2.386841216745999
Validation loss: 2.6246552091971456

Epoch: 163| Step: 0
Training loss: 1.668773876690871
Validation loss: 2.6174291081361196

Epoch: 6| Step: 1
Training loss: 2.053048760379036
Validation loss: 2.5892704288401864

Epoch: 6| Step: 2
Training loss: 1.9691248945513327
Validation loss: 2.6125865387924065

Epoch: 6| Step: 3
Training loss: 2.214318053277477
Validation loss: 2.604451483789517

Epoch: 6| Step: 4
Training loss: 2.1015171202117218
Validation loss: 2.591263426319257

Epoch: 6| Step: 5
Training loss: 2.294139868425829
Validation loss: 2.5892847615103913

Epoch: 6| Step: 6
Training loss: 1.810412882401082
Validation loss: 2.5824671906568466

Epoch: 6| Step: 7
Training loss: 2.32654963708195
Validation loss: 2.5856383890217893

Epoch: 6| Step: 8
Training loss: 1.6821440010888395
Validation loss: 2.6050643345060105

Epoch: 6| Step: 9
Training loss: 1.9515872852959733
Validation loss: 2.5945188823542438

Epoch: 6| Step: 10
Training loss: 1.5297152554699136
Validation loss: 2.589441571146078

Epoch: 6| Step: 11
Training loss: 2.0778927780847587
Validation loss: 2.597159631274086

Epoch: 6| Step: 12
Training loss: 2.1178950292350183
Validation loss: 2.5742614514493085

Epoch: 6| Step: 13
Training loss: 2.2486002064592916
Validation loss: 2.5949219908464527

Epoch: 164| Step: 0
Training loss: 1.1611570415102463
Validation loss: 2.5711545004242344

Epoch: 6| Step: 1
Training loss: 2.6755942174882374
Validation loss: 2.5656644953846968

Epoch: 6| Step: 2
Training loss: 2.303828709831346
Validation loss: 2.5705673919732424

Epoch: 6| Step: 3
Training loss: 1.994994635419397
Validation loss: 2.5592802174994835

Epoch: 6| Step: 4
Training loss: 2.288519889393398
Validation loss: 2.5631971653936074

Epoch: 6| Step: 5
Training loss: 1.2441515480412377
Validation loss: 2.568428151484695

Epoch: 6| Step: 6
Training loss: 1.8659294710639809
Validation loss: 2.54085088784501

Epoch: 6| Step: 7
Training loss: 1.616454543456574
Validation loss: 2.5483891902941984

Epoch: 6| Step: 8
Training loss: 1.8906000939612415
Validation loss: 2.5466917419836603

Epoch: 6| Step: 9
Training loss: 2.079325164482082
Validation loss: 2.544261201877299

Epoch: 6| Step: 10
Training loss: 2.0280554666928285
Validation loss: 2.552201018509071

Epoch: 6| Step: 11
Training loss: 1.9953442863017588
Validation loss: 2.552285214831884

Epoch: 6| Step: 12
Training loss: 2.3402527211322903
Validation loss: 2.5926171112008003

Epoch: 6| Step: 13
Training loss: 2.0595715858741324
Validation loss: 2.5743935667094493

Epoch: 165| Step: 0
Training loss: 2.039672409569879
Validation loss: 2.613728626271113

Epoch: 6| Step: 1
Training loss: 1.687350019218469
Validation loss: 2.641013785556831

Epoch: 6| Step: 2
Training loss: 1.6477909356856109
Validation loss: 2.6787636489768882

Epoch: 6| Step: 3
Training loss: 2.0136008337977747
Validation loss: 2.724657181806913

Epoch: 6| Step: 4
Training loss: 2.1817819247339885
Validation loss: 2.7005184632131516

Epoch: 6| Step: 5
Training loss: 2.38646210884274
Validation loss: 2.702920678239957

Epoch: 6| Step: 6
Training loss: 1.9611102024336822
Validation loss: 2.685348924308913

Epoch: 6| Step: 7
Training loss: 2.6318864863536158
Validation loss: 2.666696087485213

Epoch: 6| Step: 8
Training loss: 1.8601066368052304
Validation loss: 2.5954795039908833

Epoch: 6| Step: 9
Training loss: 1.9289087121699808
Validation loss: 2.576329527536844

Epoch: 6| Step: 10
Training loss: 1.906700393749702
Validation loss: 2.5571995321692556

Epoch: 6| Step: 11
Training loss: 1.329694381678129
Validation loss: 2.509317224634046

Epoch: 6| Step: 12
Training loss: 1.974971870028886
Validation loss: 2.5146919002215715

Epoch: 6| Step: 13
Training loss: 1.617853736934006
Validation loss: 2.5166214106070317

Epoch: 166| Step: 0
Training loss: 2.2574576656727556
Validation loss: 2.5373379564113456

Epoch: 6| Step: 1
Training loss: 1.4196735988828955
Validation loss: 2.5697634441199795

Epoch: 6| Step: 2
Training loss: 2.139460337321808
Validation loss: 2.620838637568098

Epoch: 6| Step: 3
Training loss: 2.2511482487738927
Validation loss: 2.6236392223343956

Epoch: 6| Step: 4
Training loss: 2.154435098870551
Validation loss: 2.6475185530651157

Epoch: 6| Step: 5
Training loss: 1.7442341915035895
Validation loss: 2.697120685598927

Epoch: 6| Step: 6
Training loss: 2.0334232148905236
Validation loss: 2.6696663640243203

Epoch: 6| Step: 7
Training loss: 2.00759660918289
Validation loss: 2.6595650193987597

Epoch: 6| Step: 8
Training loss: 1.718781210876066
Validation loss: 2.6178447869606822

Epoch: 6| Step: 9
Training loss: 1.807974591979694
Validation loss: 2.599605459926803

Epoch: 6| Step: 10
Training loss: 2.2211134237142005
Validation loss: 2.5599303198103467

Epoch: 6| Step: 11
Training loss: 1.608899092445779
Validation loss: 2.5497341900565584

Epoch: 6| Step: 12
Training loss: 1.3473112687552404
Validation loss: 2.5251475116751414

Epoch: 6| Step: 13
Training loss: 2.794674908425042
Validation loss: 2.499389266201469

Epoch: 167| Step: 0
Training loss: 2.1218213261373515
Validation loss: 2.5324968239561128

Epoch: 6| Step: 1
Training loss: 1.810129259457347
Validation loss: 2.5591652433653134

Epoch: 6| Step: 2
Training loss: 2.0633503865824774
Validation loss: 2.5716033306423407

Epoch: 6| Step: 3
Training loss: 1.0595613118857348
Validation loss: 2.6438338928790315

Epoch: 6| Step: 4
Training loss: 1.6760733823302405
Validation loss: 2.659481093308554

Epoch: 6| Step: 5
Training loss: 2.351263287033673
Validation loss: 2.6675173962421757

Epoch: 6| Step: 6
Training loss: 1.6968398004467384
Validation loss: 2.683065040858059

Epoch: 6| Step: 7
Training loss: 2.515524062506959
Validation loss: 2.7058269050354755

Epoch: 6| Step: 8
Training loss: 1.6706599874147294
Validation loss: 2.709096348309386

Epoch: 6| Step: 9
Training loss: 2.167228723641363
Validation loss: 2.6992788480126593

Epoch: 6| Step: 10
Training loss: 1.8866785649350166
Validation loss: 2.696485877312157

Epoch: 6| Step: 11
Training loss: 2.0817551420827893
Validation loss: 2.6738945769754325

Epoch: 6| Step: 12
Training loss: 1.7127303393194213
Validation loss: 2.6552190363941452

Epoch: 6| Step: 13
Training loss: 1.9928060132453942
Validation loss: 2.6196969635194303

Epoch: 168| Step: 0
Training loss: 2.079840618776285
Validation loss: 2.587606578120297

Epoch: 6| Step: 1
Training loss: 2.0343219709150406
Validation loss: 2.546925872187967

Epoch: 6| Step: 2
Training loss: 1.8407042610965096
Validation loss: 2.5273789876645205

Epoch: 6| Step: 3
Training loss: 1.9524464763773388
Validation loss: 2.5339640655391906

Epoch: 6| Step: 4
Training loss: 1.7985778700785597
Validation loss: 2.5379231617629787

Epoch: 6| Step: 5
Training loss: 2.3212681096551204
Validation loss: 2.5709851880767682

Epoch: 6| Step: 6
Training loss: 1.7519461845337023
Validation loss: 2.6065682587391916

Epoch: 6| Step: 7
Training loss: 1.876391403186518
Validation loss: 2.6190876502965157

Epoch: 6| Step: 8
Training loss: 1.9100932167434055
Validation loss: 2.642336843000229

Epoch: 6| Step: 9
Training loss: 1.7650387896416948
Validation loss: 2.665470532469863

Epoch: 6| Step: 10
Training loss: 1.5914800597777423
Validation loss: 2.6575595067218747

Epoch: 6| Step: 11
Training loss: 2.446895294300169
Validation loss: 2.632334621523771

Epoch: 6| Step: 12
Training loss: 1.4869288910908431
Validation loss: 2.598661484977318

Epoch: 6| Step: 13
Training loss: 1.9942485843618514
Validation loss: 2.5873532656719758

Epoch: 169| Step: 0
Training loss: 1.9032333769108045
Validation loss: 2.5843168778647816

Epoch: 6| Step: 1
Training loss: 1.94179348374575
Validation loss: 2.5754017104279514

Epoch: 6| Step: 2
Training loss: 1.9353120201352936
Validation loss: 2.5853541065933525

Epoch: 6| Step: 3
Training loss: 1.6560771779997383
Validation loss: 2.625238660187392

Epoch: 6| Step: 4
Training loss: 1.6737208649177104
Validation loss: 2.6273500799414258

Epoch: 6| Step: 5
Training loss: 1.6556566723119395
Validation loss: 2.6486128001497677

Epoch: 6| Step: 6
Training loss: 1.563135399370098
Validation loss: 2.6665798475632534

Epoch: 6| Step: 7
Training loss: 2.410018842789682
Validation loss: 2.6991556939435672

Epoch: 6| Step: 8
Training loss: 2.086154654982903
Validation loss: 2.6609857951768703

Epoch: 6| Step: 9
Training loss: 2.2411900870489814
Validation loss: 2.6523938587259237

Epoch: 6| Step: 10
Training loss: 2.428801641852687
Validation loss: 2.61728161254015

Epoch: 6| Step: 11
Training loss: 1.7181596609139227
Validation loss: 2.5716701372697774

Epoch: 6| Step: 12
Training loss: 1.4429928697553973
Validation loss: 2.5581606477934646

Epoch: 6| Step: 13
Training loss: 1.1999985337248427
Validation loss: 2.544095559377907

Epoch: 170| Step: 0
Training loss: 2.0468199045468487
Validation loss: 2.5486852927477512

Epoch: 6| Step: 1
Training loss: 2.2064839182357767
Validation loss: 2.5512229354739695

Epoch: 6| Step: 2
Training loss: 1.8687737402795446
Validation loss: 2.5393709092299583

Epoch: 6| Step: 3
Training loss: 1.435019966013172
Validation loss: 2.562606073000414

Epoch: 6| Step: 4
Training loss: 1.7096702027879602
Validation loss: 2.5694344447668493

Epoch: 6| Step: 5
Training loss: 2.053895863085601
Validation loss: 2.57426673156905

Epoch: 6| Step: 6
Training loss: 2.1737817312055725
Validation loss: 2.581545787564197

Epoch: 6| Step: 7
Training loss: 1.6693586860982161
Validation loss: 2.6071528679245923

Epoch: 6| Step: 8
Training loss: 2.3275176414534124
Validation loss: 2.625191315819773

Epoch: 6| Step: 9
Training loss: 1.3960880597494383
Validation loss: 2.6288871433492766

Epoch: 6| Step: 10
Training loss: 1.9385365820368259
Validation loss: 2.6549746062770727

Epoch: 6| Step: 11
Training loss: 1.8414684338563625
Validation loss: 2.626401278190395

Epoch: 6| Step: 12
Training loss: 1.271442840413441
Validation loss: 2.6210143433333357

Epoch: 6| Step: 13
Training loss: 2.069405526201319
Validation loss: 2.6187174336955246

Epoch: 171| Step: 0
Training loss: 2.3721574537243537
Validation loss: 2.627886487473788

Epoch: 6| Step: 1
Training loss: 2.0591844438716644
Validation loss: 2.6558449944922544

Epoch: 6| Step: 2
Training loss: 1.9044765289855339
Validation loss: 2.6645885652172305

Epoch: 6| Step: 3
Training loss: 2.0625730559386217
Validation loss: 2.6735789582918263

Epoch: 6| Step: 4
Training loss: 2.553984192329543
Validation loss: 2.6864679419629227

Epoch: 6| Step: 5
Training loss: 1.4679607949439772
Validation loss: 2.665860462477723

Epoch: 6| Step: 6
Training loss: 1.8414776263445714
Validation loss: 2.640244082394374

Epoch: 6| Step: 7
Training loss: 1.536168276892154
Validation loss: 2.6331697751466447

Epoch: 6| Step: 8
Training loss: 1.273529423865396
Validation loss: 2.6211996446345465

Epoch: 6| Step: 9
Training loss: 1.6555937420553721
Validation loss: 2.593804004164803

Epoch: 6| Step: 10
Training loss: 1.438117185038421
Validation loss: 2.5833155333361906

Epoch: 6| Step: 11
Training loss: 1.889570146856032
Validation loss: 2.5718360701862326

Epoch: 6| Step: 12
Training loss: 1.5211559719845056
Validation loss: 2.574553910150754

Epoch: 6| Step: 13
Training loss: 1.9432602440168847
Validation loss: 2.6034204673210657

Epoch: 172| Step: 0
Training loss: 1.635286637824666
Validation loss: 2.626693571868109

Epoch: 6| Step: 1
Training loss: 2.0732980757451815
Validation loss: 2.6771826882254253

Epoch: 6| Step: 2
Training loss: 1.5165594307573451
Validation loss: 2.666640307183373

Epoch: 6| Step: 3
Training loss: 2.4026703403196428
Validation loss: 2.6759270884800275

Epoch: 6| Step: 4
Training loss: 1.7615652757602145
Validation loss: 2.641103730358025

Epoch: 6| Step: 5
Training loss: 2.2894303478701907
Validation loss: 2.64194302383846

Epoch: 6| Step: 6
Training loss: 1.5768645134334103
Validation loss: 2.642431828466856

Epoch: 6| Step: 7
Training loss: 1.6255948371831506
Validation loss: 2.6246556086892143

Epoch: 6| Step: 8
Training loss: 1.8759656962408162
Validation loss: 2.6291649996480486

Epoch: 6| Step: 9
Training loss: 1.4759917594245437
Validation loss: 2.607910284534747

Epoch: 6| Step: 10
Training loss: 1.6944103037759521
Validation loss: 2.6138057404667943

Epoch: 6| Step: 11
Training loss: 2.0344337747876144
Validation loss: 2.611534412450147

Epoch: 6| Step: 12
Training loss: 1.6885551403464314
Validation loss: 2.613573655382979

Epoch: 6| Step: 13
Training loss: 1.7546944323408737
Validation loss: 2.635402222366435

Epoch: 173| Step: 0
Training loss: 2.125803515041832
Validation loss: 2.6291111884494542

Epoch: 6| Step: 1
Training loss: 1.7649109333248463
Validation loss: 2.646777830233697

Epoch: 6| Step: 2
Training loss: 1.3867285499763753
Validation loss: 2.6417364800740177

Epoch: 6| Step: 3
Training loss: 1.95952838254767
Validation loss: 2.610831076646227

Epoch: 6| Step: 4
Training loss: 2.393307346620865
Validation loss: 2.617623730325168

Epoch: 6| Step: 5
Training loss: 1.8891152903813953
Validation loss: 2.6225390855168

Epoch: 6| Step: 6
Training loss: 1.8745242468933716
Validation loss: 2.6058322612139095

Epoch: 6| Step: 7
Training loss: 2.1879898612713276
Validation loss: 2.623321730155232

Epoch: 6| Step: 8
Training loss: 1.6554622576209554
Validation loss: 2.631611595399251

Epoch: 6| Step: 9
Training loss: 1.9047175642086434
Validation loss: 2.666766800910307

Epoch: 6| Step: 10
Training loss: 1.4129863458744478
Validation loss: 2.6651728436296445

Epoch: 6| Step: 11
Training loss: 1.4958118940143443
Validation loss: 2.6635568569727335

Epoch: 6| Step: 12
Training loss: 1.2724611717100944
Validation loss: 2.6460760426903494

Epoch: 6| Step: 13
Training loss: 1.3981737282335518
Validation loss: 2.6589996641011426

Epoch: 174| Step: 0
Training loss: 0.9743169066684123
Validation loss: 2.6563995367493147

Epoch: 6| Step: 1
Training loss: 2.293965683445097
Validation loss: 2.638978964868165

Epoch: 6| Step: 2
Training loss: 2.1017551262934697
Validation loss: 2.634120900987873

Epoch: 6| Step: 3
Training loss: 1.5522172174590745
Validation loss: 2.612331600485675

Epoch: 6| Step: 4
Training loss: 1.3659640260179113
Validation loss: 2.630439527047458

Epoch: 6| Step: 5
Training loss: 1.9732489271519875
Validation loss: 2.606597856952474

Epoch: 6| Step: 6
Training loss: 1.6478700067768146
Validation loss: 2.5680169009959832

Epoch: 6| Step: 7
Training loss: 1.5759806652916295
Validation loss: 2.5764963046388187

Epoch: 6| Step: 8
Training loss: 2.1815134146271578
Validation loss: 2.5799194445128526

Epoch: 6| Step: 9
Training loss: 1.6335419845953734
Validation loss: 2.591504105741789

Epoch: 6| Step: 10
Training loss: 1.7886989174085928
Validation loss: 2.595987561875755

Epoch: 6| Step: 11
Training loss: 1.5349490581595924
Validation loss: 2.6634177045703056

Epoch: 6| Step: 12
Training loss: 2.0054361849712863
Validation loss: 2.703467465520624

Epoch: 6| Step: 13
Training loss: 2.5394050249732465
Validation loss: 2.697889569621134

Epoch: 175| Step: 0
Training loss: 1.388950883223516
Validation loss: 2.710591762428728

Epoch: 6| Step: 1
Training loss: 2.1014518850492396
Validation loss: 2.6938626768132705

Epoch: 6| Step: 2
Training loss: 2.064427948566328
Validation loss: 2.7014345043127923

Epoch: 6| Step: 3
Training loss: 1.9507644426494877
Validation loss: 2.655680096924516

Epoch: 6| Step: 4
Training loss: 1.7898098912859965
Validation loss: 2.5989551061239116

Epoch: 6| Step: 5
Training loss: 1.6305175423004536
Validation loss: 2.5485877418152643

Epoch: 6| Step: 6
Training loss: 1.4814010543096412
Validation loss: 2.5605124432170516

Epoch: 6| Step: 7
Training loss: 1.7473590541859465
Validation loss: 2.551685227028898

Epoch: 6| Step: 8
Training loss: 2.0496858123432697
Validation loss: 2.5930378649515267

Epoch: 6| Step: 9
Training loss: 2.257495263856163
Validation loss: 2.6639794113669026

Epoch: 6| Step: 10
Training loss: 1.1963748574145712
Validation loss: 2.674269065093486

Epoch: 6| Step: 11
Training loss: 1.9591961305978056
Validation loss: 2.7159537009868195

Epoch: 6| Step: 12
Training loss: 1.8588052084957971
Validation loss: 2.6970915675132665

Epoch: 6| Step: 13
Training loss: 1.9297985091306542
Validation loss: 2.674199569102412

Testing loss: 2.3907336817729465
