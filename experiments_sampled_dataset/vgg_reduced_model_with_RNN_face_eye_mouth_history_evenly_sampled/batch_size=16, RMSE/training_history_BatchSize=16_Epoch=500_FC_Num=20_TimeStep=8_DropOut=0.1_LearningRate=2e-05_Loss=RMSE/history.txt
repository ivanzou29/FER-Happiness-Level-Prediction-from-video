Epoch: 1| Step: 0
Training loss: 4.80302427703739
Validation loss: 5.803177303727659

Epoch: 6| Step: 1
Training loss: 5.661540049852512
Validation loss: 5.786500151565172

Epoch: 6| Step: 2
Training loss: 6.517980501982094
Validation loss: 5.771101409358813

Epoch: 6| Step: 3
Training loss: 5.501110484983297
Validation loss: 5.756127216076689

Epoch: 6| Step: 4
Training loss: 6.557205534943238
Validation loss: 5.739692412553821

Epoch: 6| Step: 5
Training loss: 5.277654563848651
Validation loss: 5.720924907513921

Epoch: 6| Step: 6
Training loss: 5.662568835920072
Validation loss: 5.6999953869561875

Epoch: 6| Step: 7
Training loss: 5.168520666567689
Validation loss: 5.6760236564149675

Epoch: 6| Step: 8
Training loss: 5.210451392244006
Validation loss: 5.648263146939038

Epoch: 6| Step: 9
Training loss: 5.942918092289355
Validation loss: 5.61624068749944

Epoch: 6| Step: 10
Training loss: 6.7673991566343155
Validation loss: 5.579948838801726

Epoch: 6| Step: 11
Training loss: 4.899856580854123
Validation loss: 5.540629462931884

Epoch: 6| Step: 12
Training loss: 5.671590834716089
Validation loss: 5.496989829454916

Epoch: 6| Step: 13
Training loss: 5.875270106822749
Validation loss: 5.451282136584814

Epoch: 2| Step: 0
Training loss: 6.126055568122972
Validation loss: 5.401097450565941

Epoch: 6| Step: 1
Training loss: 5.503460922256352
Validation loss: 5.3484082531095885

Epoch: 6| Step: 2
Training loss: 5.034576832509987
Validation loss: 5.294777766711757

Epoch: 6| Step: 3
Training loss: 5.683088331264703
Validation loss: 5.239620376515009

Epoch: 6| Step: 4
Training loss: 4.474468067457218
Validation loss: 5.182461698251951

Epoch: 6| Step: 5
Training loss: 5.554050328533212
Validation loss: 5.124027352986373

Epoch: 6| Step: 6
Training loss: 5.561878984053137
Validation loss: 5.06441799642478

Epoch: 6| Step: 7
Training loss: 4.41747569225901
Validation loss: 5.005846764344807

Epoch: 6| Step: 8
Training loss: 5.095065643217112
Validation loss: 4.9496156710898935

Epoch: 6| Step: 9
Training loss: 4.914537173393046
Validation loss: 4.895543425212225

Epoch: 6| Step: 10
Training loss: 5.377787377390074
Validation loss: 4.847005714678675

Epoch: 6| Step: 11
Training loss: 5.602394967888349
Validation loss: 4.799602250997636

Epoch: 6| Step: 12
Training loss: 3.1580399074146817
Validation loss: 4.755939017726007

Epoch: 6| Step: 13
Training loss: 4.2848406582453835
Validation loss: 4.712288201281134

Epoch: 3| Step: 0
Training loss: 5.132365446784329
Validation loss: 4.667682740716412

Epoch: 6| Step: 1
Training loss: 4.468223273973025
Validation loss: 4.615867815788743

Epoch: 6| Step: 2
Training loss: 4.911132715406889
Validation loss: 4.5775251994144455

Epoch: 6| Step: 3
Training loss: 5.030906902485337
Validation loss: 4.548938035816009

Epoch: 6| Step: 4
Training loss: 4.617233353595282
Validation loss: 4.518406671442455

Epoch: 6| Step: 5
Training loss: 4.787948005770011
Validation loss: 4.49210180913332

Epoch: 6| Step: 6
Training loss: 4.852883077807472
Validation loss: 4.470373988609408

Epoch: 6| Step: 7
Training loss: 4.587969614049701
Validation loss: 4.450380291692599

Epoch: 6| Step: 8
Training loss: 4.782656194805347
Validation loss: 4.430476123795006

Epoch: 6| Step: 9
Training loss: 4.770319593107546
Validation loss: 4.403414066504227

Epoch: 6| Step: 10
Training loss: 4.151286897710696
Validation loss: 4.373025292055832

Epoch: 6| Step: 11
Training loss: 4.018445401194698
Validation loss: 4.349074574062189

Epoch: 6| Step: 12
Training loss: 3.1305284045566237
Validation loss: 4.328207616186714

Epoch: 6| Step: 13
Training loss: 4.742212436868125
Validation loss: 4.306146743645917

Epoch: 4| Step: 0
Training loss: 4.758534444020726
Validation loss: 4.280793931808839

Epoch: 6| Step: 1
Training loss: 5.478559839950813
Validation loss: 4.257337303622262

Epoch: 6| Step: 2
Training loss: 4.596663608526955
Validation loss: 4.2391336349731485

Epoch: 6| Step: 3
Training loss: 3.460310282824066
Validation loss: 4.223813193198589

Epoch: 6| Step: 4
Training loss: 3.7147958714300904
Validation loss: 4.208778839426236

Epoch: 6| Step: 5
Training loss: 3.878612434192523
Validation loss: 4.19570267128413

Epoch: 6| Step: 6
Training loss: 4.297145765616642
Validation loss: 4.178039938781892

Epoch: 6| Step: 7
Training loss: 3.979347318106953
Validation loss: 4.158868552463856

Epoch: 6| Step: 8
Training loss: 4.579636672488545
Validation loss: 4.145339581888845

Epoch: 6| Step: 9
Training loss: 4.700708319675349
Validation loss: 4.127449809698349

Epoch: 6| Step: 10
Training loss: 4.371466381290597
Validation loss: 4.10908187406559

Epoch: 6| Step: 11
Training loss: 3.9645437944571813
Validation loss: 4.089773642118545

Epoch: 6| Step: 12
Training loss: 4.434774932139225
Validation loss: 4.075360217273358

Epoch: 6| Step: 13
Training loss: 3.0781837109228745
Validation loss: 4.062171718311094

Epoch: 5| Step: 0
Training loss: 4.574362605151476
Validation loss: 4.04857320594289

Epoch: 6| Step: 1
Training loss: 4.607086544600976
Validation loss: 4.025685420190982

Epoch: 6| Step: 2
Training loss: 4.674189883944274
Validation loss: 4.007667463239682

Epoch: 6| Step: 3
Training loss: 4.227659411004981
Validation loss: 3.989910880280975

Epoch: 6| Step: 4
Training loss: 4.440891313184503
Validation loss: 3.971240448785287

Epoch: 6| Step: 5
Training loss: 3.5925986394434406
Validation loss: 3.9565701601876393

Epoch: 6| Step: 6
Training loss: 4.052299957891872
Validation loss: 3.945591511704426

Epoch: 6| Step: 7
Training loss: 4.166537982225077
Validation loss: 3.9030890399718676

Epoch: 6| Step: 8
Training loss: 4.952954791781729
Validation loss: 3.909545723580667

Epoch: 6| Step: 9
Training loss: 3.666985295640994
Validation loss: 3.8658450623450906

Epoch: 6| Step: 10
Training loss: 3.5191824991091516
Validation loss: 3.852373005898387

Epoch: 6| Step: 11
Training loss: 4.0768584992342225
Validation loss: 3.8499010572756234

Epoch: 6| Step: 12
Training loss: 2.5051800467836594
Validation loss: 3.8370592010113933

Epoch: 6| Step: 13
Training loss: 3.343463350647652
Validation loss: 3.820709961434892

Epoch: 6| Step: 0
Training loss: 4.118519402909686
Validation loss: 3.8177419580777006

Epoch: 6| Step: 1
Training loss: 4.045030563861445
Validation loss: 3.8118773741579086

Epoch: 6| Step: 2
Training loss: 3.6586572270545004
Validation loss: 3.7952727375477187

Epoch: 6| Step: 3
Training loss: 4.344628553942042
Validation loss: 3.785802284206162

Epoch: 6| Step: 4
Training loss: 4.787301018068287
Validation loss: 3.7769977603574385

Epoch: 6| Step: 5
Training loss: 2.9322609140376925
Validation loss: 3.768136980324223

Epoch: 6| Step: 6
Training loss: 3.3067905957573807
Validation loss: 3.77422817157549

Epoch: 6| Step: 7
Training loss: 4.05519503612414
Validation loss: 3.756279798814723

Epoch: 6| Step: 8
Training loss: 3.853230268118622
Validation loss: 3.7341819778859575

Epoch: 6| Step: 9
Training loss: 3.814263608163258
Validation loss: 3.7350974842650246

Epoch: 6| Step: 10
Training loss: 4.266463312627691
Validation loss: 3.7311645717896282

Epoch: 6| Step: 11
Training loss: 4.049444730393504
Validation loss: 3.721258660028546

Epoch: 6| Step: 12
Training loss: 3.3962237985868793
Validation loss: 3.712531773014943

Epoch: 6| Step: 13
Training loss: 4.335633303307265
Validation loss: 3.707446834507812

Epoch: 7| Step: 0
Training loss: 4.169686990237711
Validation loss: 3.7070251255249977

Epoch: 6| Step: 1
Training loss: 3.4068040309715992
Validation loss: 3.702297893863963

Epoch: 6| Step: 2
Training loss: 4.485880635537904
Validation loss: 3.6923014820802336

Epoch: 6| Step: 3
Training loss: 4.166169225880864
Validation loss: 3.6794065405605876

Epoch: 6| Step: 4
Training loss: 3.1881566586742602
Validation loss: 3.67546413499571

Epoch: 6| Step: 5
Training loss: 3.9446271546601492
Validation loss: 3.685147916904791

Epoch: 6| Step: 6
Training loss: 3.9349812520027694
Validation loss: 3.6755355472645634

Epoch: 6| Step: 7
Training loss: 3.528823694154854
Validation loss: 3.6652851960873836

Epoch: 6| Step: 8
Training loss: 4.467949001844253
Validation loss: 3.6565939032731407

Epoch: 6| Step: 9
Training loss: 4.903813042392249
Validation loss: 3.652040437847355

Epoch: 6| Step: 10
Training loss: 2.9205955927401193
Validation loss: 3.6523967148372876

Epoch: 6| Step: 11
Training loss: 2.8920068685468516
Validation loss: 3.654289434444076

Epoch: 6| Step: 12
Training loss: 3.3011409405536467
Validation loss: 3.655553829476428

Epoch: 6| Step: 13
Training loss: 4.34067388057993
Validation loss: 3.651966756417086

Epoch: 8| Step: 0
Training loss: 4.441832241004444
Validation loss: 3.6313127622093675

Epoch: 6| Step: 1
Training loss: 3.4907678368286263
Validation loss: 3.6264816992900566

Epoch: 6| Step: 2
Training loss: 3.090137260375964
Validation loss: 3.6304310279417957

Epoch: 6| Step: 3
Training loss: 3.6816353147756797
Validation loss: 3.6322702762461354

Epoch: 6| Step: 4
Training loss: 3.851409475757047
Validation loss: 3.631916501523278

Epoch: 6| Step: 5
Training loss: 2.8774097129517315
Validation loss: 3.6189601129258424

Epoch: 6| Step: 6
Training loss: 4.225992950592444
Validation loss: 3.615408714004596

Epoch: 6| Step: 7
Training loss: 4.207737317070515
Validation loss: 3.6148018629804968

Epoch: 6| Step: 8
Training loss: 4.082042230472672
Validation loss: 3.6101010643540814

Epoch: 6| Step: 9
Training loss: 3.5274320234403773
Validation loss: 3.606029290719372

Epoch: 6| Step: 10
Training loss: 3.1631433729637997
Validation loss: 3.6000275500871566

Epoch: 6| Step: 11
Training loss: 4.81943913342528
Validation loss: 3.59776990429797

Epoch: 6| Step: 12
Training loss: 4.399725229180245
Validation loss: 3.5937097619413603

Epoch: 6| Step: 13
Training loss: 1.763623749170354
Validation loss: 3.5910658005111022

Epoch: 9| Step: 0
Training loss: 4.322974490349656
Validation loss: 3.5888924075969055

Epoch: 6| Step: 1
Training loss: 2.8490012175536306
Validation loss: 3.5842942630441375

Epoch: 6| Step: 2
Training loss: 3.1940152769159327
Validation loss: 3.5852948152911615

Epoch: 6| Step: 3
Training loss: 3.2553379531484876
Validation loss: 3.5826827877914242

Epoch: 6| Step: 4
Training loss: 4.297035907853667
Validation loss: 3.580077668137671

Epoch: 6| Step: 5
Training loss: 4.14205781150123
Validation loss: 3.5777311458039933

Epoch: 6| Step: 6
Training loss: 4.342255479322362
Validation loss: 3.5764411015808846

Epoch: 6| Step: 7
Training loss: 3.961505916823591
Validation loss: 3.574573285025825

Epoch: 6| Step: 8
Training loss: 3.9971764851217726
Validation loss: 3.5707884250262287

Epoch: 6| Step: 9
Training loss: 2.7886497555459426
Validation loss: 3.567998728091387

Epoch: 6| Step: 10
Training loss: 3.984325692862801
Validation loss: 3.568149448780953

Epoch: 6| Step: 11
Training loss: 3.6603224807169377
Validation loss: 3.5650410882495183

Epoch: 6| Step: 12
Training loss: 3.8525016831203103
Validation loss: 3.5639844880377685

Epoch: 6| Step: 13
Training loss: 3.795716788006373
Validation loss: 3.5626167676895477

Epoch: 10| Step: 0
Training loss: 3.043174021779079
Validation loss: 3.5606988794953773

Epoch: 6| Step: 1
Training loss: 3.5004334862520676
Validation loss: 3.5598041327483845

Epoch: 6| Step: 2
Training loss: 3.7597931462060914
Validation loss: 3.556978945636539

Epoch: 6| Step: 3
Training loss: 3.4685490180548717
Validation loss: 3.555054643961372

Epoch: 6| Step: 4
Training loss: 3.5954616285262437
Validation loss: 3.5529559559385673

Epoch: 6| Step: 5
Training loss: 3.1514496510263497
Validation loss: 3.549134915428054

Epoch: 6| Step: 6
Training loss: 3.9047773102823045
Validation loss: 3.5443235610126322

Epoch: 6| Step: 7
Training loss: 4.07827396047692
Validation loss: 3.5367525573864618

Epoch: 6| Step: 8
Training loss: 4.3644600473743544
Validation loss: 3.5441523786038984

Epoch: 6| Step: 9
Training loss: 3.6960162083489205
Validation loss: 3.5404930607217313

Epoch: 6| Step: 10
Training loss: 4.1275026070247485
Validation loss: 3.5306841932131947

Epoch: 6| Step: 11
Training loss: 3.5995775822660017
Validation loss: 3.5254409347860793

Epoch: 6| Step: 12
Training loss: 4.0070319354405735
Validation loss: 3.525592255407411

Epoch: 6| Step: 13
Training loss: 4.160681864169514
Validation loss: 3.526344860051873

Epoch: 11| Step: 0
Training loss: 3.5187423787280085
Validation loss: 3.5259645272772566

Epoch: 6| Step: 1
Training loss: 3.5607339597465417
Validation loss: 3.520617039640867

Epoch: 6| Step: 2
Training loss: 3.937695089684285
Validation loss: 3.520932420381279

Epoch: 6| Step: 3
Training loss: 4.635840830166273
Validation loss: 3.52001211821054

Epoch: 6| Step: 4
Training loss: 3.7323038271167257
Validation loss: 3.516803860103556

Epoch: 6| Step: 5
Training loss: 3.7322215491112516
Validation loss: 3.5157540479740748

Epoch: 6| Step: 6
Training loss: 3.346064399414162
Validation loss: 3.51278761619394

Epoch: 6| Step: 7
Training loss: 4.328763949057532
Validation loss: 3.511817211400712

Epoch: 6| Step: 8
Training loss: 3.735714723972023
Validation loss: 3.5128358543380522

Epoch: 6| Step: 9
Training loss: 3.0154069416486187
Validation loss: 3.5117073966410177

Epoch: 6| Step: 10
Training loss: 3.382386213758482
Validation loss: 3.5107302175897384

Epoch: 6| Step: 11
Training loss: 3.7387619745846483
Validation loss: 3.50697689544296

Epoch: 6| Step: 12
Training loss: 4.33041508541753
Validation loss: 3.504347317777249

Epoch: 6| Step: 13
Training loss: 1.6109611324497162
Validation loss: 3.502129207414408

Epoch: 12| Step: 0
Training loss: 2.8936899792768043
Validation loss: 3.501203892472295

Epoch: 6| Step: 1
Training loss: 4.02513901369752
Validation loss: 3.50007849559863

Epoch: 6| Step: 2
Training loss: 3.7574358650261956
Validation loss: 3.496185123718171

Epoch: 6| Step: 3
Training loss: 3.8308295213670553
Validation loss: 3.492414248132504

Epoch: 6| Step: 4
Training loss: 3.6221920845582614
Validation loss: 3.4861217071494623

Epoch: 6| Step: 5
Training loss: 3.381620624417433
Validation loss: 3.481703548763157

Epoch: 6| Step: 6
Training loss: 3.6608448337577197
Validation loss: 3.477875305128049

Epoch: 6| Step: 7
Training loss: 3.476725439475217
Validation loss: 3.478375839733193

Epoch: 6| Step: 8
Training loss: 3.9850428601189303
Validation loss: 3.478845040718771

Epoch: 6| Step: 9
Training loss: 3.657815190656048
Validation loss: 3.4752966893355515

Epoch: 6| Step: 10
Training loss: 4.025981920727587
Validation loss: 3.468122866647027

Epoch: 6| Step: 11
Training loss: 3.5714463451488188
Validation loss: 3.471304840531835

Epoch: 6| Step: 12
Training loss: 3.814814506010875
Validation loss: 3.474060104824407

Epoch: 6| Step: 13
Training loss: 4.134961440288277
Validation loss: 3.465477434838874

Epoch: 13| Step: 0
Training loss: 3.7916454831604054
Validation loss: 3.4665001443674823

Epoch: 6| Step: 1
Training loss: 3.5643836947433214
Validation loss: 3.464271321380741

Epoch: 6| Step: 2
Training loss: 3.229212820071928
Validation loss: 3.4640197710123193

Epoch: 6| Step: 3
Training loss: 3.5153581984265316
Validation loss: 3.4590702396075326

Epoch: 6| Step: 4
Training loss: 3.189290460104883
Validation loss: 3.457972708762007

Epoch: 6| Step: 5
Training loss: 4.344116195501627
Validation loss: 3.4569993043756853

Epoch: 6| Step: 6
Training loss: 4.208353074030638
Validation loss: 3.4551870328823697

Epoch: 6| Step: 7
Training loss: 3.3640232308908975
Validation loss: 3.4531063936261486

Epoch: 6| Step: 8
Training loss: 3.1557873679548125
Validation loss: 3.45234080088773

Epoch: 6| Step: 9
Training loss: 3.3474915863455577
Validation loss: 3.4538694904454537

Epoch: 6| Step: 10
Training loss: 3.805745003309129
Validation loss: 3.450699593233411

Epoch: 6| Step: 11
Training loss: 3.5972587374123037
Validation loss: 3.448400560821614

Epoch: 6| Step: 12
Training loss: 4.192303535712422
Validation loss: 3.4453733381779585

Epoch: 6| Step: 13
Training loss: 4.072404964267817
Validation loss: 3.444324728230203

Epoch: 14| Step: 0
Training loss: 4.404101125084517
Validation loss: 3.444954782941683

Epoch: 6| Step: 1
Training loss: 3.4716292794775736
Validation loss: 3.4426035682738285

Epoch: 6| Step: 2
Training loss: 4.427202338320849
Validation loss: 3.4410456236049125

Epoch: 6| Step: 3
Training loss: 3.919618725042913
Validation loss: 3.43920698097634

Epoch: 6| Step: 4
Training loss: 3.668570602163944
Validation loss: 3.4373902677172796

Epoch: 6| Step: 5
Training loss: 3.787742652296274
Validation loss: 3.437462880520542

Epoch: 6| Step: 6
Training loss: 3.3968500748801644
Validation loss: 3.4357058969535226

Epoch: 6| Step: 7
Training loss: 2.9326677549856908
Validation loss: 3.435150447281219

Epoch: 6| Step: 8
Training loss: 2.7151177357248537
Validation loss: 3.434337201313974

Epoch: 6| Step: 9
Training loss: 3.3438096085698805
Validation loss: 3.432728564514083

Epoch: 6| Step: 10
Training loss: 4.046907520531737
Validation loss: 3.432506900291634

Epoch: 6| Step: 11
Training loss: 3.6797473683923507
Validation loss: 3.4313065953343487

Epoch: 6| Step: 12
Training loss: 3.9152199257845965
Validation loss: 3.429600976002102

Epoch: 6| Step: 13
Training loss: 2.5331582305859426
Validation loss: 3.4300801195411466

Epoch: 15| Step: 0
Training loss: 4.003816214688913
Validation loss: 3.4267146379772617

Epoch: 6| Step: 1
Training loss: 4.679007606599629
Validation loss: 3.4261214961859183

Epoch: 6| Step: 2
Training loss: 3.5996700453548245
Validation loss: 3.424753188307895

Epoch: 6| Step: 3
Training loss: 2.9054648046218
Validation loss: 3.4235895850595695

Epoch: 6| Step: 4
Training loss: 4.219901372832728
Validation loss: 3.422467547409889

Epoch: 6| Step: 5
Training loss: 3.4472642417667196
Validation loss: 3.4215546021241328

Epoch: 6| Step: 6
Training loss: 4.121190942278075
Validation loss: 3.4211443596156657

Epoch: 6| Step: 7
Training loss: 3.1389273994656537
Validation loss: 3.4195409300609296

Epoch: 6| Step: 8
Training loss: 4.150758255776936
Validation loss: 3.4186197266748852

Epoch: 6| Step: 9
Training loss: 3.596603189732575
Validation loss: 3.4174718115733174

Epoch: 6| Step: 10
Training loss: 2.677096345822861
Validation loss: 3.4161956536479003

Epoch: 6| Step: 11
Training loss: 2.9618437092390586
Validation loss: 3.415763488495282

Epoch: 6| Step: 12
Training loss: 3.3998373722002744
Validation loss: 3.4140794208779637

Epoch: 6| Step: 13
Training loss: 3.5205384230638703
Validation loss: 3.413003365766013

Epoch: 16| Step: 0
Training loss: 2.7041308345291775
Validation loss: 3.4121389098906354

Epoch: 6| Step: 1
Training loss: 4.547657273368936
Validation loss: 3.4116788097615767

Epoch: 6| Step: 2
Training loss: 3.4557752838545506
Validation loss: 3.410705587563889

Epoch: 6| Step: 3
Training loss: 3.8804359454616764
Validation loss: 3.41021277333809

Epoch: 6| Step: 4
Training loss: 3.9809384354346893
Validation loss: 3.4083718190859895

Epoch: 6| Step: 5
Training loss: 4.438625139324271
Validation loss: 3.4077769455789455

Epoch: 6| Step: 6
Training loss: 3.428384242170485
Validation loss: 3.406412461512006

Epoch: 6| Step: 7
Training loss: 3.278497467845214
Validation loss: 3.405523578893576

Epoch: 6| Step: 8
Training loss: 3.4031712328359913
Validation loss: 3.4041850520008627

Epoch: 6| Step: 9
Training loss: 3.0785514419963924
Validation loss: 3.4037728613767184

Epoch: 6| Step: 10
Training loss: 3.986653712282429
Validation loss: 3.4033199705125288

Epoch: 6| Step: 11
Training loss: 3.647282223491603
Validation loss: 3.4015535730905984

Epoch: 6| Step: 12
Training loss: 2.933064459991434
Validation loss: 3.400256125076208

Epoch: 6| Step: 13
Training loss: 3.6211598543554935
Validation loss: 3.3995508248937556

Epoch: 17| Step: 0
Training loss: 4.440635755231961
Validation loss: 3.39821996920271

Epoch: 6| Step: 1
Training loss: 3.710919639142873
Validation loss: 3.3977311372079457

Epoch: 6| Step: 2
Training loss: 3.9914789037537615
Validation loss: 3.396431982944978

Epoch: 6| Step: 3
Training loss: 3.499938691828418
Validation loss: 3.3961375045111986

Epoch: 6| Step: 4
Training loss: 3.8063760570579652
Validation loss: 3.395048097624405

Epoch: 6| Step: 5
Training loss: 3.4439243279449867
Validation loss: 3.393266313195106

Epoch: 6| Step: 6
Training loss: 3.306295089558444
Validation loss: 3.392308010604433

Epoch: 6| Step: 7
Training loss: 3.5597236924687894
Validation loss: 3.3915888863843042

Epoch: 6| Step: 8
Training loss: 3.272455400435483
Validation loss: 3.3903487412270477

Epoch: 6| Step: 9
Training loss: 3.0096902113767507
Validation loss: 3.3896168990340474

Epoch: 6| Step: 10
Training loss: 2.990662507367087
Validation loss: 3.388745826764648

Epoch: 6| Step: 11
Training loss: 3.719583369889246
Validation loss: 3.38785537056272

Epoch: 6| Step: 12
Training loss: 3.7297339549565542
Validation loss: 3.386850718894016

Epoch: 6| Step: 13
Training loss: 4.22686100891045
Validation loss: 3.3862426527630856

Epoch: 18| Step: 0
Training loss: 3.359840822082416
Validation loss: 3.3844397900655645

Epoch: 6| Step: 1
Training loss: 3.8207404710196173
Validation loss: 3.383979719331179

Epoch: 6| Step: 2
Training loss: 3.054152341829007
Validation loss: 3.3839362672042372

Epoch: 6| Step: 3
Training loss: 3.9018418731089786
Validation loss: 3.382278643904268

Epoch: 6| Step: 4
Training loss: 3.8107748662413474
Validation loss: 3.380566027425578

Epoch: 6| Step: 5
Training loss: 2.982340653568231
Validation loss: 3.3803979175291605

Epoch: 6| Step: 6
Training loss: 4.39706372342014
Validation loss: 3.3796176275122374

Epoch: 6| Step: 7
Training loss: 2.8672257506602135
Validation loss: 3.3790632344351605

Epoch: 6| Step: 8
Training loss: 3.8364933644474375
Validation loss: 3.3781636950219918

Epoch: 6| Step: 9
Training loss: 4.512426807940654
Validation loss: 3.3778689885773185

Epoch: 6| Step: 10
Training loss: 3.4738256761805437
Validation loss: 3.3770606428214576

Epoch: 6| Step: 11
Training loss: 3.19618776454017
Validation loss: 3.376068549199403

Epoch: 6| Step: 12
Training loss: 3.800953875833136
Validation loss: 3.3746359084493744

Epoch: 6| Step: 13
Training loss: 2.599836813867408
Validation loss: 3.37382943998491

Epoch: 19| Step: 0
Training loss: 3.3060300007478345
Validation loss: 3.3735642457522763

Epoch: 6| Step: 1
Training loss: 3.685060890553892
Validation loss: 3.371797331113407

Epoch: 6| Step: 2
Training loss: 3.6185101259940375
Validation loss: 3.3713588967513357

Epoch: 6| Step: 3
Training loss: 4.257656829508039
Validation loss: 3.3696529838352194

Epoch: 6| Step: 4
Training loss: 3.2947991511673673
Validation loss: 3.369155730715513

Epoch: 6| Step: 5
Training loss: 3.2010747535221227
Validation loss: 3.367233415763621

Epoch: 6| Step: 6
Training loss: 3.3920906520462006
Validation loss: 3.3656938257415523

Epoch: 6| Step: 7
Training loss: 3.8615118744215753
Validation loss: 3.3646861105453656

Epoch: 6| Step: 8
Training loss: 3.6525034170898496
Validation loss: 3.363037778959529

Epoch: 6| Step: 9
Training loss: 3.326443672835138
Validation loss: 3.3615314191238865

Epoch: 6| Step: 10
Training loss: 3.7615406473527586
Validation loss: 3.3593031871509957

Epoch: 6| Step: 11
Training loss: 3.8814456613951562
Validation loss: 3.356667088715514

Epoch: 6| Step: 12
Training loss: 3.698463564266391
Validation loss: 3.357329768365402

Epoch: 6| Step: 13
Training loss: 3.0549967187342526
Validation loss: 3.352929095579383

Epoch: 20| Step: 0
Training loss: 3.6936550173351277
Validation loss: 3.3538996786959903

Epoch: 6| Step: 1
Training loss: 3.094884645102576
Validation loss: 3.3550435130708625

Epoch: 6| Step: 2
Training loss: 3.848956791624071
Validation loss: 3.3531440292335426

Epoch: 6| Step: 3
Training loss: 4.016085705879875
Validation loss: 3.353995011852544

Epoch: 6| Step: 4
Training loss: 3.480184318659818
Validation loss: 3.3497853760282403

Epoch: 6| Step: 5
Training loss: 3.3936228354218563
Validation loss: 3.3479281934949183

Epoch: 6| Step: 6
Training loss: 3.095676939459442
Validation loss: 3.346279485932231

Epoch: 6| Step: 7
Training loss: 4.098205936825865
Validation loss: 3.344639572881816

Epoch: 6| Step: 8
Training loss: 3.122219832643052
Validation loss: 3.344459857790914

Epoch: 6| Step: 9
Training loss: 4.054551550436433
Validation loss: 3.343100022203589

Epoch: 6| Step: 10
Training loss: 3.3631162170964695
Validation loss: 3.342973893705703

Epoch: 6| Step: 11
Training loss: 3.4966237268517495
Validation loss: 3.3401778711192938

Epoch: 6| Step: 12
Training loss: 3.1662186422801972
Validation loss: 3.339725973061192

Epoch: 6| Step: 13
Training loss: 4.3011792628472785
Validation loss: 3.3389112192394705

Epoch: 21| Step: 0
Training loss: 2.61878012409956
Validation loss: 3.338058265954865

Epoch: 6| Step: 1
Training loss: 3.5076287100376615
Validation loss: 3.3367084080144305

Epoch: 6| Step: 2
Training loss: 4.954919917039764
Validation loss: 3.3354479809125337

Epoch: 6| Step: 3
Training loss: 3.744596020818649
Validation loss: 3.3342136948395855

Epoch: 6| Step: 4
Training loss: 3.494558600411008
Validation loss: 3.3330314289292535

Epoch: 6| Step: 5
Training loss: 2.832587499251871
Validation loss: 3.331067944918401

Epoch: 6| Step: 6
Training loss: 3.9096662307683943
Validation loss: 3.330567574316781

Epoch: 6| Step: 7
Training loss: 2.651402616878846
Validation loss: 3.3289695960999186

Epoch: 6| Step: 8
Training loss: 4.119909208463984
Validation loss: 3.326989029657884

Epoch: 6| Step: 9
Training loss: 3.768399431362338
Validation loss: 3.3284636756590285

Epoch: 6| Step: 10
Training loss: 2.7512076933821707
Validation loss: 3.329701954900075

Epoch: 6| Step: 11
Training loss: 3.5289571964892574
Validation loss: 3.3263622350831814

Epoch: 6| Step: 12
Training loss: 4.122391540692187
Validation loss: 3.3200241614170616

Epoch: 6| Step: 13
Training loss: 2.795239188617323
Validation loss: 3.315620466386179

Epoch: 22| Step: 0
Training loss: 2.732494994051607
Validation loss: 3.315684548655171

Epoch: 6| Step: 1
Training loss: 3.723552904089483
Validation loss: 3.313071119838114

Epoch: 6| Step: 2
Training loss: 3.6477121943246167
Validation loss: 3.312072780531641

Epoch: 6| Step: 3
Training loss: 3.3155906222446108
Validation loss: 3.3098032757615448

Epoch: 6| Step: 4
Training loss: 3.3418980398644864
Validation loss: 3.3085265750809003

Epoch: 6| Step: 5
Training loss: 3.4572186952625024
Validation loss: 3.3093090061754413

Epoch: 6| Step: 6
Training loss: 3.604978054789335
Validation loss: 3.308203415321437

Epoch: 6| Step: 7
Training loss: 3.9316220688133265
Validation loss: 3.3079815131625634

Epoch: 6| Step: 8
Training loss: 3.45006940467793
Validation loss: 3.3063257821243375

Epoch: 6| Step: 9
Training loss: 3.6397756478054277
Validation loss: 3.305389656296792

Epoch: 6| Step: 10
Training loss: 3.9350555340387814
Validation loss: 3.3045778710413463

Epoch: 6| Step: 11
Training loss: 4.063717938299319
Validation loss: 3.3031360478533234

Epoch: 6| Step: 12
Training loss: 3.239457270059449
Validation loss: 3.3026372687474534

Epoch: 6| Step: 13
Training loss: 3.3440600099974085
Validation loss: 3.301508829103292

Epoch: 23| Step: 0
Training loss: 2.350309221741934
Validation loss: 3.2997722631362194

Epoch: 6| Step: 1
Training loss: 3.3851155465040765
Validation loss: 3.2980147526497627

Epoch: 6| Step: 2
Training loss: 3.686630922481087
Validation loss: 3.2981849007904347

Epoch: 6| Step: 3
Training loss: 3.2384022872999654
Validation loss: 3.299720954532475

Epoch: 6| Step: 4
Training loss: 3.321126393813045
Validation loss: 3.297917732861152

Epoch: 6| Step: 5
Training loss: 3.210897997685085
Validation loss: 3.295130739631628

Epoch: 6| Step: 6
Training loss: 3.489192762390418
Validation loss: 3.295291288723576

Epoch: 6| Step: 7
Training loss: 4.764437368025514
Validation loss: 3.2944492330530584

Epoch: 6| Step: 8
Training loss: 3.5031544230686196
Validation loss: 3.2950744082026633

Epoch: 6| Step: 9
Training loss: 3.0554821024841683
Validation loss: 3.291373849796358

Epoch: 6| Step: 10
Training loss: 3.8339065178512204
Validation loss: 3.291691814392486

Epoch: 6| Step: 11
Training loss: 4.332668302319013
Validation loss: 3.2913603717381337

Epoch: 6| Step: 12
Training loss: 3.614310848874579
Validation loss: 3.289591637681911

Epoch: 6| Step: 13
Training loss: 2.8891026792728978
Validation loss: 3.2891857028757427

Epoch: 24| Step: 0
Training loss: 3.769140984290777
Validation loss: 3.2877199046163943

Epoch: 6| Step: 1
Training loss: 3.3068945618769856
Validation loss: 3.2875703006612444

Epoch: 6| Step: 2
Training loss: 3.6656274767881127
Validation loss: 3.286905118728076

Epoch: 6| Step: 3
Training loss: 3.11707032253523
Validation loss: 3.284687322819262

Epoch: 6| Step: 4
Training loss: 2.3960496777143314
Validation loss: 3.2863801977733336

Epoch: 6| Step: 5
Training loss: 3.4033947097768587
Validation loss: 3.286223600711667

Epoch: 6| Step: 6
Training loss: 2.9989502977689995
Validation loss: 3.288909594439148

Epoch: 6| Step: 7
Training loss: 3.777999363428146
Validation loss: 3.2817451693305366

Epoch: 6| Step: 8
Training loss: 4.421913389436935
Validation loss: 3.2800327439815966

Epoch: 6| Step: 9
Training loss: 4.042771545613174
Validation loss: 3.2781021730961655

Epoch: 6| Step: 10
Training loss: 3.689110097291286
Validation loss: 3.276206894184757

Epoch: 6| Step: 11
Training loss: 4.308842974291313
Validation loss: 3.2762025857222343

Epoch: 6| Step: 12
Training loss: 2.848328980572185
Validation loss: 3.2776338307432296

Epoch: 6| Step: 13
Training loss: 2.648165348439746
Validation loss: 3.277970752391055

Epoch: 25| Step: 0
Training loss: 3.7794934440966723
Validation loss: 3.2775728371828787

Epoch: 6| Step: 1
Training loss: 2.991964386671954
Validation loss: 3.274312950083619

Epoch: 6| Step: 2
Training loss: 4.226028606095919
Validation loss: 3.2764477506074905

Epoch: 6| Step: 3
Training loss: 3.495473659655681
Validation loss: 3.2764646826766786

Epoch: 6| Step: 4
Training loss: 3.704983401859803
Validation loss: 3.2734375266275992

Epoch: 6| Step: 5
Training loss: 3.4991372271216394
Validation loss: 3.2730225499192254

Epoch: 6| Step: 6
Training loss: 3.4412669955775117
Validation loss: 3.270555530792619

Epoch: 6| Step: 7
Training loss: 3.952762270483208
Validation loss: 3.2679190307094346

Epoch: 6| Step: 8
Training loss: 3.4561770660817386
Validation loss: 3.2677872530313405

Epoch: 6| Step: 9
Training loss: 3.1472885269254087
Validation loss: 3.267678463563211

Epoch: 6| Step: 10
Training loss: 3.297133304547164
Validation loss: 3.2674386931225996

Epoch: 6| Step: 11
Training loss: 2.9529315542006636
Validation loss: 3.265502702876548

Epoch: 6| Step: 12
Training loss: 3.6542131015751713
Validation loss: 3.2647519976753534

Epoch: 6| Step: 13
Training loss: 3.397712156564288
Validation loss: 3.2624861668879785

Epoch: 26| Step: 0
Training loss: 3.5900730064003126
Validation loss: 3.260208609697301

Epoch: 6| Step: 1
Training loss: 3.3442080175139073
Validation loss: 3.262743781494642

Epoch: 6| Step: 2
Training loss: 3.3988887092706954
Validation loss: 3.2614650986047913

Epoch: 6| Step: 3
Training loss: 2.898522882155058
Validation loss: 3.260582877815258

Epoch: 6| Step: 4
Training loss: 3.018916887997373
Validation loss: 3.2568413736004955

Epoch: 6| Step: 5
Training loss: 3.872604244791841
Validation loss: 3.2602074474828577

Epoch: 6| Step: 6
Training loss: 4.043797327911431
Validation loss: 3.260346413310578

Epoch: 6| Step: 7
Training loss: 4.087817370491518
Validation loss: 3.255047926102822

Epoch: 6| Step: 8
Training loss: 3.3639722019094815
Validation loss: 3.252028992258867

Epoch: 6| Step: 9
Training loss: 3.726227239406806
Validation loss: 3.2529720020013775

Epoch: 6| Step: 10
Training loss: 3.325818906055172
Validation loss: 3.2551979843795507

Epoch: 6| Step: 11
Training loss: 3.502842430131854
Validation loss: 3.253409388777142

Epoch: 6| Step: 12
Training loss: 3.1340291616888183
Validation loss: 3.252228781184785

Epoch: 6| Step: 13
Training loss: 3.6460473279366123
Validation loss: 3.2540653602847973

Epoch: 27| Step: 0
Training loss: 3.5505769878593405
Validation loss: 3.250309417484413

Epoch: 6| Step: 1
Training loss: 3.6553450548604536
Validation loss: 3.2510780679374776

Epoch: 6| Step: 2
Training loss: 2.888807560517679
Validation loss: 3.2475160125431377

Epoch: 6| Step: 3
Training loss: 3.5911391352461255
Validation loss: 3.2463869184311247

Epoch: 6| Step: 4
Training loss: 4.0102046497663695
Validation loss: 3.2454050078580137

Epoch: 6| Step: 5
Training loss: 2.7969664659941404
Validation loss: 3.2442283180184153

Epoch: 6| Step: 6
Training loss: 4.054593888159502
Validation loss: 3.243993686546018

Epoch: 6| Step: 7
Training loss: 2.5407185479803287
Validation loss: 3.244627488382423

Epoch: 6| Step: 8
Training loss: 3.1608683723286393
Validation loss: 3.243996991466037

Epoch: 6| Step: 9
Training loss: 3.9852047523728262
Validation loss: 3.2453863433539007

Epoch: 6| Step: 10
Training loss: 3.575279203596132
Validation loss: 3.243890668082551

Epoch: 6| Step: 11
Training loss: 4.409997739553413
Validation loss: 3.240486878157813

Epoch: 6| Step: 12
Training loss: 2.650032575874916
Validation loss: 3.241573236311999

Epoch: 6| Step: 13
Training loss: 3.4694004308187365
Validation loss: 3.2364202865716885

Epoch: 28| Step: 0
Training loss: 3.800677369629995
Validation loss: 3.2375868471088087

Epoch: 6| Step: 1
Training loss: 1.896319994102997
Validation loss: 3.2342849932137323

Epoch: 6| Step: 2
Training loss: 2.7034596142356597
Validation loss: 3.2338605751736185

Epoch: 6| Step: 3
Training loss: 3.939369484463171
Validation loss: 3.2346152827214425

Epoch: 6| Step: 4
Training loss: 4.245646771695658
Validation loss: 3.2324454934947884

Epoch: 6| Step: 5
Training loss: 3.4140499298073794
Validation loss: 3.230322338808447

Epoch: 6| Step: 6
Training loss: 3.1886606534241477
Validation loss: 3.235552509582437

Epoch: 6| Step: 7
Training loss: 4.14690685590569
Validation loss: 3.2310667599813323

Epoch: 6| Step: 8
Training loss: 3.9536380962560282
Validation loss: 3.2278283803796928

Epoch: 6| Step: 9
Training loss: 2.921849867768752
Validation loss: 3.2317312694188742

Epoch: 6| Step: 10
Training loss: 2.982673519487599
Validation loss: 3.2362272105107732

Epoch: 6| Step: 11
Training loss: 4.371103786153581
Validation loss: 3.23322574107475

Epoch: 6| Step: 12
Training loss: 3.018666685230179
Validation loss: 3.2376391966047335

Epoch: 6| Step: 13
Training loss: 3.176899355371548
Validation loss: 3.22808112013283

Epoch: 29| Step: 0
Training loss: 3.617485413116593
Validation loss: 3.226609364947164

Epoch: 6| Step: 1
Training loss: 3.2037984000608435
Validation loss: 3.2230410782445684

Epoch: 6| Step: 2
Training loss: 3.7285135787710466
Validation loss: 3.2223891296753493

Epoch: 6| Step: 3
Training loss: 3.6587909444141187
Validation loss: 3.225309212416056

Epoch: 6| Step: 4
Training loss: 3.245330390274774
Validation loss: 3.2214611696662807

Epoch: 6| Step: 5
Training loss: 2.933552138519795
Validation loss: 3.2237116667792063

Epoch: 6| Step: 6
Training loss: 3.0850983456558017
Validation loss: 3.221827974647944

Epoch: 6| Step: 7
Training loss: 3.1249353020646433
Validation loss: 3.221268508545158

Epoch: 6| Step: 8
Training loss: 2.3640171891312067
Validation loss: 3.2198654855916313

Epoch: 6| Step: 9
Training loss: 4.207880556028618
Validation loss: 3.2192383668576317

Epoch: 6| Step: 10
Training loss: 4.168181995774938
Validation loss: 3.2174794689916544

Epoch: 6| Step: 11
Training loss: 3.9209112069764043
Validation loss: 3.221511759902888

Epoch: 6| Step: 12
Training loss: 3.653843797072913
Validation loss: 3.219670020168286

Epoch: 6| Step: 13
Training loss: 3.0758412210684933
Validation loss: 3.221159722222388

Epoch: 30| Step: 0
Training loss: 3.7256409727258757
Validation loss: 3.221369547843729

Epoch: 6| Step: 1
Training loss: 3.242821615323389
Validation loss: 3.220071510367235

Epoch: 6| Step: 2
Training loss: 3.3475542620476695
Validation loss: 3.211998196077331

Epoch: 6| Step: 3
Training loss: 3.6738369509131092
Validation loss: 3.211844519138913

Epoch: 6| Step: 4
Training loss: 3.615201664492753
Validation loss: 3.21236008341444

Epoch: 6| Step: 5
Training loss: 2.6824137440773903
Validation loss: 3.2096400998990826

Epoch: 6| Step: 6
Training loss: 3.7708089135715825
Validation loss: 3.2113681519686557

Epoch: 6| Step: 7
Training loss: 2.7367726304622324
Validation loss: 3.2123363076662446

Epoch: 6| Step: 8
Training loss: 3.417264715437769
Validation loss: 3.212274055105283

Epoch: 6| Step: 9
Training loss: 3.634104902837041
Validation loss: 3.20843686971671

Epoch: 6| Step: 10
Training loss: 3.3063911393440746
Validation loss: 3.206111450758315

Epoch: 6| Step: 11
Training loss: 3.957404914528173
Validation loss: 3.2099080854925566

Epoch: 6| Step: 12
Training loss: 3.338428719564459
Validation loss: 3.218205327129841

Epoch: 6| Step: 13
Training loss: 4.097383473702017
Validation loss: 3.2060637168498123

Epoch: 31| Step: 0
Training loss: 2.7364173455297376
Validation loss: 3.205939800157107

Epoch: 6| Step: 1
Training loss: 3.470277604533513
Validation loss: 3.206398119125034

Epoch: 6| Step: 2
Training loss: 3.579750990918561
Validation loss: 3.2094692850260813

Epoch: 6| Step: 3
Training loss: 2.6664266975036837
Validation loss: 3.2012299372956208

Epoch: 6| Step: 4
Training loss: 3.937280557966205
Validation loss: 3.201839338069998

Epoch: 6| Step: 5
Training loss: 3.7924610744985787
Validation loss: 3.2013284987185298

Epoch: 6| Step: 6
Training loss: 3.3871794038646437
Validation loss: 3.196432027893552

Epoch: 6| Step: 7
Training loss: 2.8280267856467862
Validation loss: 3.190654812423107

Epoch: 6| Step: 8
Training loss: 3.1023055947233433
Validation loss: 3.1898814278501533

Epoch: 6| Step: 9
Training loss: 3.828523949835034
Validation loss: 3.190707205588731

Epoch: 6| Step: 10
Training loss: 4.452412223657531
Validation loss: 3.188190994146884

Epoch: 6| Step: 11
Training loss: 2.81438349069174
Validation loss: 3.190129509080784

Epoch: 6| Step: 12
Training loss: 3.7004116757226106
Validation loss: 3.1874082183331587

Epoch: 6| Step: 13
Training loss: 3.4906720792623025
Validation loss: 3.195534984871021

Epoch: 32| Step: 0
Training loss: 4.166850861610633
Validation loss: 3.2121136432975153

Epoch: 6| Step: 1
Training loss: 3.2958194434978054
Validation loss: 3.1851579722951917

Epoch: 6| Step: 2
Training loss: 3.614474438759365
Validation loss: 3.183482833914127

Epoch: 6| Step: 3
Training loss: 2.595072489554714
Validation loss: 3.185541360693814

Epoch: 6| Step: 4
Training loss: 2.9063592705642445
Validation loss: 3.1970254010751598

Epoch: 6| Step: 5
Training loss: 3.296395361844783
Validation loss: 3.2103371506673986

Epoch: 6| Step: 6
Training loss: 3.9969795267068937
Validation loss: 3.1965474141486068

Epoch: 6| Step: 7
Training loss: 3.194886568590069
Validation loss: 3.187663328879089

Epoch: 6| Step: 8
Training loss: 3.7390745590787047
Validation loss: 3.1826899728541043

Epoch: 6| Step: 9
Training loss: 2.8158916791651456
Validation loss: 3.200621718082065

Epoch: 6| Step: 10
Training loss: 3.4764914516089855
Validation loss: 3.2005616871162554

Epoch: 6| Step: 11
Training loss: 3.5821471949525123
Validation loss: 3.1934768454952374

Epoch: 6| Step: 12
Training loss: 3.695838681073425
Validation loss: 3.1842220372666894

Epoch: 6| Step: 13
Training loss: 3.583816200073352
Validation loss: 3.1817711958247967

Epoch: 33| Step: 0
Training loss: 3.2930628716716335
Validation loss: 3.18491867199849

Epoch: 6| Step: 1
Training loss: 3.0235573599465115
Validation loss: 3.176646631905041

Epoch: 6| Step: 2
Training loss: 3.518633153137369
Validation loss: 3.1742164734428884

Epoch: 6| Step: 3
Training loss: 3.9949291989733147
Validation loss: 3.1751480111964407

Epoch: 6| Step: 4
Training loss: 3.8593953861825567
Validation loss: 3.1730692694494467

Epoch: 6| Step: 5
Training loss: 2.916317964326794
Validation loss: 3.1690165819763605

Epoch: 6| Step: 6
Training loss: 3.9368606532723116
Validation loss: 3.171083555354808

Epoch: 6| Step: 7
Training loss: 3.6510952860785353
Validation loss: 3.167714666598782

Epoch: 6| Step: 8
Training loss: 3.3311891017020976
Validation loss: 3.1657134879162006

Epoch: 6| Step: 9
Training loss: 3.5541931479310875
Validation loss: 3.166775930383799

Epoch: 6| Step: 10
Training loss: 3.490025886068011
Validation loss: 3.164605040872967

Epoch: 6| Step: 11
Training loss: 2.7116659543396575
Validation loss: 3.163671952176503

Epoch: 6| Step: 12
Training loss: 3.1312064527578634
Validation loss: 3.1650486187127225

Epoch: 6| Step: 13
Training loss: 3.1901483940120827
Validation loss: 3.1666004992201513

Epoch: 34| Step: 0
Training loss: 3.434416896852611
Validation loss: 3.1656219905142544

Epoch: 6| Step: 1
Training loss: 3.023583539249948
Validation loss: 3.1675837016884776

Epoch: 6| Step: 2
Training loss: 3.559287915324126
Validation loss: 3.1643031895834492

Epoch: 6| Step: 3
Training loss: 4.299655749712998
Validation loss: 3.160960279836039

Epoch: 6| Step: 4
Training loss: 3.5614536823526106
Validation loss: 3.1601266477659533

Epoch: 6| Step: 5
Training loss: 3.226678656826388
Validation loss: 3.156728436347035

Epoch: 6| Step: 6
Training loss: 2.822378400509549
Validation loss: 3.155664778575951

Epoch: 6| Step: 7
Training loss: 3.698600612664795
Validation loss: 3.156235650890007

Epoch: 6| Step: 8
Training loss: 3.5916673015644074
Validation loss: 3.155688836696731

Epoch: 6| Step: 9
Training loss: 3.1253455924628017
Validation loss: 3.155705618130687

Epoch: 6| Step: 10
Training loss: 2.473906142370265
Validation loss: 3.1539738376304416

Epoch: 6| Step: 11
Training loss: 3.704063071370996
Validation loss: 3.1506463967963967

Epoch: 6| Step: 12
Training loss: 2.9412297047678027
Validation loss: 3.1503187827882058

Epoch: 6| Step: 13
Training loss: 4.235850397366176
Validation loss: 3.149556532233034

Epoch: 35| Step: 0
Training loss: 4.1185233393863765
Validation loss: 3.1491252319342573

Epoch: 6| Step: 1
Training loss: 3.5196653757565937
Validation loss: 3.1471455431518014

Epoch: 6| Step: 2
Training loss: 3.415242774566475
Validation loss: 3.1437309137832967

Epoch: 6| Step: 3
Training loss: 3.205853746701377
Validation loss: 3.142660350908368

Epoch: 6| Step: 4
Training loss: 3.0915282006801403
Validation loss: 3.146520563327701

Epoch: 6| Step: 5
Training loss: 3.7226872477887034
Validation loss: 3.1512434775883853

Epoch: 6| Step: 6
Training loss: 3.02694727116441
Validation loss: 3.1607341186546893

Epoch: 6| Step: 7
Training loss: 3.5967133619113247
Validation loss: 3.175020459126714

Epoch: 6| Step: 8
Training loss: 3.1036098074621266
Validation loss: 3.1442735066377097

Epoch: 6| Step: 9
Training loss: 3.5633162517037076
Validation loss: 3.142313110538508

Epoch: 6| Step: 10
Training loss: 3.143306669066176
Validation loss: 3.148003623634777

Epoch: 6| Step: 11
Training loss: 3.568275321216872
Validation loss: 3.150998163427217

Epoch: 6| Step: 12
Training loss: 3.0865922836777746
Validation loss: 3.1448087636681543

Epoch: 6| Step: 13
Training loss: 3.422596894502521
Validation loss: 3.1425176982397747

Epoch: 36| Step: 0
Training loss: 2.2937052127301087
Validation loss: 3.1403035963809267

Epoch: 6| Step: 1
Training loss: 3.3636545290913364
Validation loss: 3.139127088922209

Epoch: 6| Step: 2
Training loss: 3.561113857506936
Validation loss: 3.13612544514869

Epoch: 6| Step: 3
Training loss: 3.351569044555819
Validation loss: 3.135960126917693

Epoch: 6| Step: 4
Training loss: 3.26460578746819
Validation loss: 3.1331437593771634

Epoch: 6| Step: 5
Training loss: 2.8876759925482385
Validation loss: 3.1309900460292592

Epoch: 6| Step: 6
Training loss: 3.70316118311206
Validation loss: 3.1294314722127083

Epoch: 6| Step: 7
Training loss: 3.4335061193400267
Validation loss: 3.1330717688018703

Epoch: 6| Step: 8
Training loss: 3.5489020248050016
Validation loss: 3.1256950081371575

Epoch: 6| Step: 9
Training loss: 3.1724448608224063
Validation loss: 3.127203530750546

Epoch: 6| Step: 10
Training loss: 3.421892976060446
Validation loss: 3.130388958026714

Epoch: 6| Step: 11
Training loss: 4.095096978051137
Validation loss: 3.1273222615193155

Epoch: 6| Step: 12
Training loss: 3.5893036246107064
Validation loss: 3.1296550035147552

Epoch: 6| Step: 13
Training loss: 3.5644360016711993
Validation loss: 3.127358640431655

Epoch: 37| Step: 0
Training loss: 3.602064383203019
Validation loss: 3.124709808657979

Epoch: 6| Step: 1
Training loss: 2.7995988592538747
Validation loss: 3.1192948929557716

Epoch: 6| Step: 2
Training loss: 3.5108363111078753
Validation loss: 3.121518983464721

Epoch: 6| Step: 3
Training loss: 3.3742995771587285
Validation loss: 3.1200004799608188

Epoch: 6| Step: 4
Training loss: 4.0740356989379345
Validation loss: 3.117182155903397

Epoch: 6| Step: 5
Training loss: 3.0385242760262714
Validation loss: 3.117418470041482

Epoch: 6| Step: 6
Training loss: 3.382144994270362
Validation loss: 3.115117315818428

Epoch: 6| Step: 7
Training loss: 3.1168012260180027
Validation loss: 3.1157244931676793

Epoch: 6| Step: 8
Training loss: 3.3534583218477056
Validation loss: 3.121258525869352

Epoch: 6| Step: 9
Training loss: 2.820722639953785
Validation loss: 3.122174767312735

Epoch: 6| Step: 10
Training loss: 3.2088206197756617
Validation loss: 3.1202522981514935

Epoch: 6| Step: 11
Training loss: 3.5254479739102726
Validation loss: 3.1133308922888787

Epoch: 6| Step: 12
Training loss: 3.8163833851749174
Validation loss: 3.112935242192566

Epoch: 6| Step: 13
Training loss: 3.64241815374263
Validation loss: 3.111331290690636

Epoch: 38| Step: 0
Training loss: 3.5048863497822773
Validation loss: 3.111116083959579

Epoch: 6| Step: 1
Training loss: 2.577984892766116
Validation loss: 3.109290932475127

Epoch: 6| Step: 2
Training loss: 3.036831779918256
Validation loss: 3.1202979400770117

Epoch: 6| Step: 3
Training loss: 3.7202319870671583
Validation loss: 3.1654221882930216

Epoch: 6| Step: 4
Training loss: 3.4852718003184093
Validation loss: 3.125120365737052

Epoch: 6| Step: 5
Training loss: 3.384589805372989
Validation loss: 3.1062187541371373

Epoch: 6| Step: 6
Training loss: 3.738082641300339
Validation loss: 3.1079346182652605

Epoch: 6| Step: 7
Training loss: 3.6943259989044877
Validation loss: 3.105650143811838

Epoch: 6| Step: 8
Training loss: 2.9701618250677595
Validation loss: 3.1102148892118304

Epoch: 6| Step: 9
Training loss: 2.374067324158574
Validation loss: 3.1226587019729513

Epoch: 6| Step: 10
Training loss: 2.251163182001045
Validation loss: 3.1182625183117327

Epoch: 6| Step: 11
Training loss: 3.890949771914754
Validation loss: 3.107537347246764

Epoch: 6| Step: 12
Training loss: 4.132166561421866
Validation loss: 3.1056670478698063

Epoch: 6| Step: 13
Training loss: 4.139213810967052
Validation loss: 3.1034855915448825

Epoch: 39| Step: 0
Training loss: 2.840410556399594
Validation loss: 3.103929395926885

Epoch: 6| Step: 1
Training loss: 3.445595519882347
Validation loss: 3.1005047720305265

Epoch: 6| Step: 2
Training loss: 3.524431244979243
Validation loss: 3.0995798528849363

Epoch: 6| Step: 3
Training loss: 3.871486670822773
Validation loss: 3.0988099669776816

Epoch: 6| Step: 4
Training loss: 3.551109844316817
Validation loss: 3.0978480435381557

Epoch: 6| Step: 5
Training loss: 3.1843165039439842
Validation loss: 3.0967133326824476

Epoch: 6| Step: 6
Training loss: 3.425423371816115
Validation loss: 3.098385340199695

Epoch: 6| Step: 7
Training loss: 3.8590038290961197
Validation loss: 3.0967049423245916

Epoch: 6| Step: 8
Training loss: 2.389692136975281
Validation loss: 3.0946526510019674

Epoch: 6| Step: 9
Training loss: 3.000558801106301
Validation loss: 3.092502652040625

Epoch: 6| Step: 10
Training loss: 2.8244580685850282
Validation loss: 3.092658015818566

Epoch: 6| Step: 11
Training loss: 3.1846716805298083
Validation loss: 3.093354242210494

Epoch: 6| Step: 12
Training loss: 3.6674708149274653
Validation loss: 3.0928568963254053

Epoch: 6| Step: 13
Training loss: 4.3565502791167985
Validation loss: 3.090232346674603

Epoch: 40| Step: 0
Training loss: 2.537417398245208
Validation loss: 3.0898546655023216

Epoch: 6| Step: 1
Training loss: 3.488773460733004
Validation loss: 3.0881906035375075

Epoch: 6| Step: 2
Training loss: 3.3353631197371794
Validation loss: 3.0868462674768145

Epoch: 6| Step: 3
Training loss: 2.992015704210652
Validation loss: 3.0916649603954376

Epoch: 6| Step: 4
Training loss: 3.8528910544997554
Validation loss: 3.0904558314281783

Epoch: 6| Step: 5
Training loss: 3.742807611680595
Validation loss: 3.089791130863563

Epoch: 6| Step: 6
Training loss: 3.1523473803417756
Validation loss: 3.087590454578019

Epoch: 6| Step: 7
Training loss: 3.59889105565094
Validation loss: 3.084841643370763

Epoch: 6| Step: 8
Training loss: 3.4260142474393223
Validation loss: 3.0831583456211993

Epoch: 6| Step: 9
Training loss: 3.38996283046634
Validation loss: 3.0814403725145456

Epoch: 6| Step: 10
Training loss: 3.2775596574814028
Validation loss: 3.0799954901945767

Epoch: 6| Step: 11
Training loss: 3.0858636388510443
Validation loss: 3.0810545893162185

Epoch: 6| Step: 12
Training loss: 3.3805290426612764
Validation loss: 3.079890453895291

Epoch: 6| Step: 13
Training loss: 3.577354781364366
Validation loss: 3.0792115661481576

Epoch: 41| Step: 0
Training loss: 2.703643484499773
Validation loss: 3.077121565859655

Epoch: 6| Step: 1
Training loss: 4.093230469329675
Validation loss: 3.0786483317274986

Epoch: 6| Step: 2
Training loss: 2.738910336138578
Validation loss: 3.0754628720894286

Epoch: 6| Step: 3
Training loss: 3.7877674524533242
Validation loss: 3.076657741061152

Epoch: 6| Step: 4
Training loss: 3.689661717816275
Validation loss: 3.0763689646337298

Epoch: 6| Step: 5
Training loss: 2.8827043218397064
Validation loss: 3.0743031711752686

Epoch: 6| Step: 6
Training loss: 3.1368631636082167
Validation loss: 3.073905545163725

Epoch: 6| Step: 7
Training loss: 3.786784763598955
Validation loss: 3.0724762545520243

Epoch: 6| Step: 8
Training loss: 3.3819220870939395
Validation loss: 3.072126001440549

Epoch: 6| Step: 9
Training loss: 3.2191443340630554
Validation loss: 3.072527916986352

Epoch: 6| Step: 10
Training loss: 3.0000281332604204
Validation loss: 3.069418315553206

Epoch: 6| Step: 11
Training loss: 3.261017537836937
Validation loss: 3.0694732449983713

Epoch: 6| Step: 12
Training loss: 3.1953080230905373
Validation loss: 3.0698947876493965

Epoch: 6| Step: 13
Training loss: 3.749791457417478
Validation loss: 3.068528910049788

Epoch: 42| Step: 0
Training loss: 3.5884338864703023
Validation loss: 3.067212315594096

Epoch: 6| Step: 1
Training loss: 3.059253295098622
Validation loss: 3.0668616694540023

Epoch: 6| Step: 2
Training loss: 2.5510687439679463
Validation loss: 3.0674628193230316

Epoch: 6| Step: 3
Training loss: 2.9678150511746035
Validation loss: 3.063461229873714

Epoch: 6| Step: 4
Training loss: 3.596966705346342
Validation loss: 3.077225990200857

Epoch: 6| Step: 5
Training loss: 3.3003950807295492
Validation loss: 3.0692068672274337

Epoch: 6| Step: 6
Training loss: 3.3868762972924804
Validation loss: 3.0594050891979525

Epoch: 6| Step: 7
Training loss: 3.408861751368249
Validation loss: 3.064986696232313

Epoch: 6| Step: 8
Training loss: 2.8962501024716243
Validation loss: 3.1048037914437563

Epoch: 6| Step: 9
Training loss: 3.4482076162951216
Validation loss: 3.0709183079690185

Epoch: 6| Step: 10
Training loss: 3.6882823825310034
Validation loss: 3.0680312665994407

Epoch: 6| Step: 11
Training loss: 4.023744678807836
Validation loss: 3.0687913819057853

Epoch: 6| Step: 12
Training loss: 3.614291455066673
Validation loss: 3.0637472650283772

Epoch: 6| Step: 13
Training loss: 2.5701528574983596
Validation loss: 3.060457589505463

Epoch: 43| Step: 0
Training loss: 2.5706664424331587
Validation loss: 3.0588605952373116

Epoch: 6| Step: 1
Training loss: 3.5869458345397236
Validation loss: 3.058167742399281

Epoch: 6| Step: 2
Training loss: 3.536365550888267
Validation loss: 3.0595123873220524

Epoch: 6| Step: 3
Training loss: 2.4749571594229676
Validation loss: 3.0643682768559652

Epoch: 6| Step: 4
Training loss: 3.605568732531633
Validation loss: 3.062139560633089

Epoch: 6| Step: 5
Training loss: 4.087103653569899
Validation loss: 3.068700139982087

Epoch: 6| Step: 6
Training loss: 2.6845198675462414
Validation loss: 3.064589782945857

Epoch: 6| Step: 7
Training loss: 3.5657039757289577
Validation loss: 3.058022011747124

Epoch: 6| Step: 8
Training loss: 3.7999001841234934
Validation loss: 3.0566226261912535

Epoch: 6| Step: 9
Training loss: 3.6290694447461376
Validation loss: 3.055236537111426

Epoch: 6| Step: 10
Training loss: 3.6577745177371748
Validation loss: 3.0581034915950407

Epoch: 6| Step: 11
Training loss: 2.707815697916281
Validation loss: 3.05339511941775

Epoch: 6| Step: 12
Training loss: 3.239340541037343
Validation loss: 3.054260477511895

Epoch: 6| Step: 13
Training loss: 2.51549136357729
Validation loss: 3.0534674377920608

Epoch: 44| Step: 0
Training loss: 3.2786680689939667
Validation loss: 3.0562505034926883

Epoch: 6| Step: 1
Training loss: 3.294864131690603
Validation loss: 3.063860005505831

Epoch: 6| Step: 2
Training loss: 3.137703214956591
Validation loss: 3.0617384793568094

Epoch: 6| Step: 3
Training loss: 3.3158351015474663
Validation loss: 3.0570098774483276

Epoch: 6| Step: 4
Training loss: 3.9646342405390795
Validation loss: 3.049749771147059

Epoch: 6| Step: 5
Training loss: 3.1318217777685047
Validation loss: 3.048575475324713

Epoch: 6| Step: 6
Training loss: 3.1169932216439635
Validation loss: 3.04841877984387

Epoch: 6| Step: 7
Training loss: 3.6436072974290763
Validation loss: 3.045137858552676

Epoch: 6| Step: 8
Training loss: 2.847218169749614
Validation loss: 3.0471420604366894

Epoch: 6| Step: 9
Training loss: 3.5100025570417257
Validation loss: 3.0444293021130484

Epoch: 6| Step: 10
Training loss: 3.7765288080394224
Validation loss: 3.0434322843185195

Epoch: 6| Step: 11
Training loss: 2.96858118480756
Validation loss: 3.045080064626559

Epoch: 6| Step: 12
Training loss: 2.679248473568227
Validation loss: 3.043048284979966

Epoch: 6| Step: 13
Training loss: 3.619510572025707
Validation loss: 3.043233590630908

Epoch: 45| Step: 0
Training loss: 3.50762925380915
Validation loss: 3.042855009690053

Epoch: 6| Step: 1
Training loss: 3.3583806895158403
Validation loss: 3.043304618172807

Epoch: 6| Step: 2
Training loss: 2.743349703913343
Validation loss: 3.041213779106905

Epoch: 6| Step: 3
Training loss: 3.1637662018866366
Validation loss: 3.043166776930263

Epoch: 6| Step: 4
Training loss: 3.0192689374560544
Validation loss: 3.042338051210753

Epoch: 6| Step: 5
Training loss: 3.6322504080436686
Validation loss: 3.0440316360981594

Epoch: 6| Step: 6
Training loss: 3.486189297174619
Validation loss: 3.048399884783687

Epoch: 6| Step: 7
Training loss: 3.9598456990399358
Validation loss: 3.0500373031470662

Epoch: 6| Step: 8
Training loss: 2.7332306129258575
Validation loss: 3.0387757982215757

Epoch: 6| Step: 9
Training loss: 3.171256019066319
Validation loss: 3.03416334331372

Epoch: 6| Step: 10
Training loss: 3.0862772694182916
Validation loss: 3.0347217198033696

Epoch: 6| Step: 11
Training loss: 3.436852688964083
Validation loss: 3.037587953535891

Epoch: 6| Step: 12
Training loss: 3.5730426792058836
Validation loss: 3.04048686648423

Epoch: 6| Step: 13
Training loss: 3.2527561238783678
Validation loss: 3.0425891772439533

Epoch: 46| Step: 0
Training loss: 3.2831816300976917
Validation loss: 3.0329984293651644

Epoch: 6| Step: 1
Training loss: 3.1511778915005473
Validation loss: 3.0316345813234546

Epoch: 6| Step: 2
Training loss: 2.749143467073203
Validation loss: 3.033433038237423

Epoch: 6| Step: 3
Training loss: 2.9035403838347214
Validation loss: 3.04447860862777

Epoch: 6| Step: 4
Training loss: 3.4529642611415343
Validation loss: 3.0626414678402694

Epoch: 6| Step: 5
Training loss: 2.7125645572697357
Validation loss: 3.0708109392016425

Epoch: 6| Step: 6
Training loss: 3.501430763990562
Validation loss: 3.0669625094333317

Epoch: 6| Step: 7
Training loss: 3.6564460114977164
Validation loss: 3.088831396035826

Epoch: 6| Step: 8
Training loss: 3.541200644556149
Validation loss: 3.110138530032477

Epoch: 6| Step: 9
Training loss: 3.707277955025146
Validation loss: 3.082766523757912

Epoch: 6| Step: 10
Training loss: 3.147069288239531
Validation loss: 3.0622083731436365

Epoch: 6| Step: 11
Training loss: 3.3023936289334017
Validation loss: 3.057921066409675

Epoch: 6| Step: 12
Training loss: 4.174514221437669
Validation loss: 3.0439595618146025

Epoch: 6| Step: 13
Training loss: 2.615283694952467
Validation loss: 3.0362321332501088

Epoch: 47| Step: 0
Training loss: 2.975394593043747
Validation loss: 3.080329431719862

Epoch: 6| Step: 1
Training loss: 3.6260316630357616
Validation loss: 3.112594786757936

Epoch: 6| Step: 2
Training loss: 3.368852455973278
Validation loss: 3.0482043113399517

Epoch: 6| Step: 3
Training loss: 3.511724045593546
Validation loss: 3.0224762575854416

Epoch: 6| Step: 4
Training loss: 3.376209042472655
Validation loss: 3.015537019883235

Epoch: 6| Step: 5
Training loss: 2.771367205669373
Validation loss: 3.017023252796888

Epoch: 6| Step: 6
Training loss: 2.731166330273681
Validation loss: 3.030266794624778

Epoch: 6| Step: 7
Training loss: 3.7774140628554744
Validation loss: 3.048351916639557

Epoch: 6| Step: 8
Training loss: 2.6453356737900706
Validation loss: 3.044617139038166

Epoch: 6| Step: 9
Training loss: 3.9862037201925533
Validation loss: 3.0518164409690915

Epoch: 6| Step: 10
Training loss: 2.827993906260053
Validation loss: 3.0391283798679765

Epoch: 6| Step: 11
Training loss: 4.108466102255062
Validation loss: 3.0202312787492684

Epoch: 6| Step: 12
Training loss: 3.0502822995476326
Validation loss: 3.011601933716583

Epoch: 6| Step: 13
Training loss: 3.1411900557640036
Validation loss: 3.0079796776446135

Epoch: 48| Step: 0
Training loss: 3.5394409516279595
Validation loss: 3.0084305067482617

Epoch: 6| Step: 1
Training loss: 3.083123346000025
Validation loss: 3.00652444292141

Epoch: 6| Step: 2
Training loss: 3.1965668321864125
Validation loss: 3.008024451836216

Epoch: 6| Step: 3
Training loss: 2.700916689212507
Validation loss: 3.0086997100312063

Epoch: 6| Step: 4
Training loss: 3.4204254563919934
Validation loss: 3.0078642869594825

Epoch: 6| Step: 5
Training loss: 2.8649457852491715
Validation loss: 3.0103728361473436

Epoch: 6| Step: 6
Training loss: 3.4066493648928278
Validation loss: 3.014016172573277

Epoch: 6| Step: 7
Training loss: 3.725827446505382
Validation loss: 3.0083178637547725

Epoch: 6| Step: 8
Training loss: 3.3336299446381394
Validation loss: 3.0062050124839232

Epoch: 6| Step: 9
Training loss: 3.648629879831606
Validation loss: 3.0013874837879326

Epoch: 6| Step: 10
Training loss: 3.807911096673085
Validation loss: 3.00066472195613

Epoch: 6| Step: 11
Training loss: 2.758748789805608
Validation loss: 3.000028786128042

Epoch: 6| Step: 12
Training loss: 3.0905412159238743
Validation loss: 2.9997101117292884

Epoch: 6| Step: 13
Training loss: 3.075528826637228
Validation loss: 2.999156861196563

Epoch: 49| Step: 0
Training loss: 3.593348870488573
Validation loss: 2.998432551506337

Epoch: 6| Step: 1
Training loss: 2.8257020297453486
Validation loss: 2.9959328968121395

Epoch: 6| Step: 2
Training loss: 3.5513610702165734
Validation loss: 2.9969051456189524

Epoch: 6| Step: 3
Training loss: 3.2540281714853534
Validation loss: 2.995066736259016

Epoch: 6| Step: 4
Training loss: 3.1286774931494836
Validation loss: 2.994743791209118

Epoch: 6| Step: 5
Training loss: 2.4279335290146387
Validation loss: 2.994732117277081

Epoch: 6| Step: 6
Training loss: 2.924305603547525
Validation loss: 2.994504607336935

Epoch: 6| Step: 7
Training loss: 3.5592485279793737
Validation loss: 2.991631440488763

Epoch: 6| Step: 8
Training loss: 3.894480682932435
Validation loss: 2.9951469997421794

Epoch: 6| Step: 9
Training loss: 3.307398340302103
Validation loss: 2.9963432503649656

Epoch: 6| Step: 10
Training loss: 3.3116678596216698
Validation loss: 2.9927594535093136

Epoch: 6| Step: 11
Training loss: 2.9613065867011223
Validation loss: 2.992109371101215

Epoch: 6| Step: 12
Training loss: 3.734741065306956
Validation loss: 2.9889670470651275

Epoch: 6| Step: 13
Training loss: 2.9132651703263677
Validation loss: 2.9887438786036875

Epoch: 50| Step: 0
Training loss: 3.5627307482493658
Validation loss: 2.987238198523131

Epoch: 6| Step: 1
Training loss: 3.5322985147409627
Validation loss: 2.987346800596356

Epoch: 6| Step: 2
Training loss: 3.5136277692739712
Validation loss: 2.9879764267100737

Epoch: 6| Step: 3
Training loss: 3.2131763087748504
Validation loss: 2.986415968113604

Epoch: 6| Step: 4
Training loss: 2.888589007960319
Validation loss: 2.985107424773484

Epoch: 6| Step: 5
Training loss: 3.129247906303757
Validation loss: 2.9876587732740165

Epoch: 6| Step: 6
Training loss: 3.595900978227132
Validation loss: 2.981614272915351

Epoch: 6| Step: 7
Training loss: 2.9428786687024004
Validation loss: 2.985261235431161

Epoch: 6| Step: 8
Training loss: 3.2979659313989234
Validation loss: 2.9858281603342696

Epoch: 6| Step: 9
Training loss: 3.591691596939645
Validation loss: 2.986254534401517

Epoch: 6| Step: 10
Training loss: 3.411066552104808
Validation loss: 2.9836017173983334

Epoch: 6| Step: 11
Training loss: 2.886522175415432
Validation loss: 2.9910527041626427

Epoch: 6| Step: 12
Training loss: 2.9659640440970394
Validation loss: 2.9922646810003735

Epoch: 6| Step: 13
Training loss: 2.7893874035251147
Validation loss: 2.984133464460616

Epoch: 51| Step: 0
Training loss: 2.9682441682040976
Validation loss: 2.985668271319379

Epoch: 6| Step: 1
Training loss: 2.932651495439097
Validation loss: 2.9828843964896636

Epoch: 6| Step: 2
Training loss: 3.2147605393905403
Validation loss: 2.9792228680234656

Epoch: 6| Step: 3
Training loss: 3.312742836166396
Validation loss: 2.976330041252821

Epoch: 6| Step: 4
Training loss: 3.745088157889447
Validation loss: 2.9745820252085897

Epoch: 6| Step: 5
Training loss: 2.7766023013686745
Validation loss: 2.975366167411593

Epoch: 6| Step: 6
Training loss: 2.7097723048087805
Validation loss: 2.9738532684377423

Epoch: 6| Step: 7
Training loss: 3.3717614636472755
Validation loss: 2.9742808799133194

Epoch: 6| Step: 8
Training loss: 3.8258180479025317
Validation loss: 2.9737654197544234

Epoch: 6| Step: 9
Training loss: 3.698824030633889
Validation loss: 2.973904596785055

Epoch: 6| Step: 10
Training loss: 3.348766805927728
Validation loss: 2.9708112071208483

Epoch: 6| Step: 11
Training loss: 3.4877658646945773
Validation loss: 2.9751912538871883

Epoch: 6| Step: 12
Training loss: 3.096335053552018
Validation loss: 2.9705083970826904

Epoch: 6| Step: 13
Training loss: 2.6117628672916267
Validation loss: 2.972119045859491

Epoch: 52| Step: 0
Training loss: 3.1436082326423747
Validation loss: 2.969719048691624

Epoch: 6| Step: 1
Training loss: 2.213873218314459
Validation loss: 2.9683308511118502

Epoch: 6| Step: 2
Training loss: 3.216810215990095
Validation loss: 2.9709166793155717

Epoch: 6| Step: 3
Training loss: 3.844344798642178
Validation loss: 3.0059663397379945

Epoch: 6| Step: 4
Training loss: 3.056790537707557
Validation loss: 2.9969996519639728

Epoch: 6| Step: 5
Training loss: 3.35754486622093
Validation loss: 2.978657447831558

Epoch: 6| Step: 6
Training loss: 2.911954797624476
Validation loss: 2.963569439568397

Epoch: 6| Step: 7
Training loss: 3.641200204358812
Validation loss: 2.9664547158610395

Epoch: 6| Step: 8
Training loss: 3.1153115194209886
Validation loss: 2.9808116467172887

Epoch: 6| Step: 9
Training loss: 3.202275605510853
Validation loss: 2.992827143264823

Epoch: 6| Step: 10
Training loss: 3.1351340199225897
Validation loss: 2.9773873723128768

Epoch: 6| Step: 11
Training loss: 3.7495926953689986
Validation loss: 2.979988503396431

Epoch: 6| Step: 12
Training loss: 3.2895839395617137
Validation loss: 2.970064326707305

Epoch: 6| Step: 13
Training loss: 3.6299624184168424
Validation loss: 2.964099054720197

Epoch: 53| Step: 0
Training loss: 2.822197535132353
Validation loss: 2.9599970798927013

Epoch: 6| Step: 1
Training loss: 3.6069671393817933
Validation loss: 2.9605803205391528

Epoch: 6| Step: 2
Training loss: 2.745725430658347
Validation loss: 2.964408568794408

Epoch: 6| Step: 3
Training loss: 3.415198654272476
Validation loss: 2.9683678476580706

Epoch: 6| Step: 4
Training loss: 3.663223268095198
Validation loss: 2.9773515288496637

Epoch: 6| Step: 5
Training loss: 3.4338266339271812
Validation loss: 2.9643715799127595

Epoch: 6| Step: 6
Training loss: 3.7884933830808603
Validation loss: 2.9592768787687147

Epoch: 6| Step: 7
Training loss: 3.1021491199808007
Validation loss: 2.9578097699210835

Epoch: 6| Step: 8
Training loss: 2.683477007729558
Validation loss: 2.9580584962686327

Epoch: 6| Step: 9
Training loss: 3.3772027633292425
Validation loss: 2.958095383827199

Epoch: 6| Step: 10
Training loss: 2.7779355820230736
Validation loss: 2.9569716395322785

Epoch: 6| Step: 11
Training loss: 2.951608742896419
Validation loss: 2.9602282006227867

Epoch: 6| Step: 12
Training loss: 3.8186764324487807
Validation loss: 2.956630194577631

Epoch: 6| Step: 13
Training loss: 2.958747154269927
Validation loss: 2.9523875881741626

Epoch: 54| Step: 0
Training loss: 3.828860465264225
Validation loss: 2.9522403073985144

Epoch: 6| Step: 1
Training loss: 3.7203806659809273
Validation loss: 2.9518087978146514

Epoch: 6| Step: 2
Training loss: 3.250539588150826
Validation loss: 2.954242597911875

Epoch: 6| Step: 3
Training loss: 2.941608234578035
Validation loss: 2.950386810596786

Epoch: 6| Step: 4
Training loss: 3.5669224377009807
Validation loss: 2.955778814306029

Epoch: 6| Step: 5
Training loss: 2.4418880383993113
Validation loss: 2.9703736282931117

Epoch: 6| Step: 6
Training loss: 3.3900272528078994
Validation loss: 2.9785248208202395

Epoch: 6| Step: 7
Training loss: 3.5230945496379285
Validation loss: 2.9840902553332587

Epoch: 6| Step: 8
Training loss: 3.118681967687018
Validation loss: 2.9643789689048954

Epoch: 6| Step: 9
Training loss: 3.1095229837292298
Validation loss: 2.9768298520534633

Epoch: 6| Step: 10
Training loss: 3.4633335748941034
Validation loss: 2.9582732710286574

Epoch: 6| Step: 11
Training loss: 2.943739412778699
Validation loss: 2.9443854295550387

Epoch: 6| Step: 12
Training loss: 3.0950561232400715
Validation loss: 2.944176774006845

Epoch: 6| Step: 13
Training loss: 2.250084981373121
Validation loss: 2.944319857322484

Epoch: 55| Step: 0
Training loss: 3.3943468050346772
Validation loss: 2.9432822825436054

Epoch: 6| Step: 1
Training loss: 2.893069661456502
Validation loss: 2.944937757798184

Epoch: 6| Step: 2
Training loss: 3.8000618076317245
Validation loss: 2.943753588911818

Epoch: 6| Step: 3
Training loss: 2.4618945001825927
Validation loss: 2.943628148925414

Epoch: 6| Step: 4
Training loss: 3.189107003618691
Validation loss: 2.9446112398862794

Epoch: 6| Step: 5
Training loss: 2.7249660244844756
Validation loss: 2.9422028170068706

Epoch: 6| Step: 6
Training loss: 3.9110858738210217
Validation loss: 2.9424333445899102

Epoch: 6| Step: 7
Training loss: 3.665361316559749
Validation loss: 2.9418698780958787

Epoch: 6| Step: 8
Training loss: 2.5652940915404865
Validation loss: 2.9434113204673573

Epoch: 6| Step: 9
Training loss: 3.2661531012228195
Validation loss: 2.940881174761248

Epoch: 6| Step: 10
Training loss: 3.26247301346298
Validation loss: 2.9393969598223673

Epoch: 6| Step: 11
Training loss: 2.902189309694776
Validation loss: 2.938785682675458

Epoch: 6| Step: 12
Training loss: 3.7685655691084152
Validation loss: 2.938083200678618

Epoch: 6| Step: 13
Training loss: 2.859978283886393
Validation loss: 2.9364035171671197

Epoch: 56| Step: 0
Training loss: 3.8664546387735945
Validation loss: 2.936943509415547

Epoch: 6| Step: 1
Training loss: 3.2078949930218856
Validation loss: 2.933378280810808

Epoch: 6| Step: 2
Training loss: 3.354042256261407
Validation loss: 2.937249691609271

Epoch: 6| Step: 3
Training loss: 3.1089874486120785
Validation loss: 2.944677260954965

Epoch: 6| Step: 4
Training loss: 3.8077212542283534
Validation loss: 2.9690550910211604

Epoch: 6| Step: 5
Training loss: 2.8378395448775295
Validation loss: 2.9418251924475127

Epoch: 6| Step: 6
Training loss: 3.0737817785754156
Validation loss: 2.9334366569285844

Epoch: 6| Step: 7
Training loss: 2.6588732164219224
Validation loss: 2.934612113962451

Epoch: 6| Step: 8
Training loss: 3.351625526386923
Validation loss: 2.931905309039307

Epoch: 6| Step: 9
Training loss: 1.9695026230689288
Validation loss: 2.9345938192347485

Epoch: 6| Step: 10
Training loss: 3.1566131685014307
Validation loss: 2.939501586423006

Epoch: 6| Step: 11
Training loss: 3.1071177201279965
Validation loss: 2.9424485289657247

Epoch: 6| Step: 12
Training loss: 3.9421080010888256
Validation loss: 2.9399341158516052

Epoch: 6| Step: 13
Training loss: 3.328086028967842
Validation loss: 2.933938053263431

Epoch: 57| Step: 0
Training loss: 3.3922336120142145
Validation loss: 2.9329001412602076

Epoch: 6| Step: 1
Training loss: 3.1301780525727456
Validation loss: 2.9321239850941136

Epoch: 6| Step: 2
Training loss: 3.12667359360156
Validation loss: 2.9316574200807435

Epoch: 6| Step: 3
Training loss: 2.5536917049347476
Validation loss: 2.9300560329082392

Epoch: 6| Step: 4
Training loss: 2.941716353849628
Validation loss: 2.9280849277758563

Epoch: 6| Step: 5
Training loss: 3.0993073766415593
Validation loss: 2.9296020355337746

Epoch: 6| Step: 6
Training loss: 3.350130926961393
Validation loss: 2.9317752225466034

Epoch: 6| Step: 7
Training loss: 3.6476745461213214
Validation loss: 2.939867511267248

Epoch: 6| Step: 8
Training loss: 3.687838264079882
Validation loss: 2.941728678263528

Epoch: 6| Step: 9
Training loss: 2.9633573040101777
Validation loss: 2.9238461819616144

Epoch: 6| Step: 10
Training loss: 3.370058610219697
Validation loss: 2.93452808936087

Epoch: 6| Step: 11
Training loss: 2.6061095860847097
Validation loss: 2.944842247518198

Epoch: 6| Step: 12
Training loss: 3.9672044763430963
Validation loss: 2.9479741055716335

Epoch: 6| Step: 13
Training loss: 2.767493785792596
Validation loss: 2.9307196672473257

Epoch: 58| Step: 0
Training loss: 2.8121407173403568
Validation loss: 2.928549911972655

Epoch: 6| Step: 1
Training loss: 3.2056483308385997
Validation loss: 2.929248614289491

Epoch: 6| Step: 2
Training loss: 3.3591957221875863
Validation loss: 2.9266934851035913

Epoch: 6| Step: 3
Training loss: 2.8416559243395363
Validation loss: 2.924348390694318

Epoch: 6| Step: 4
Training loss: 3.6717889004616295
Validation loss: 2.9227627211840708

Epoch: 6| Step: 5
Training loss: 2.335580243505356
Validation loss: 2.9198943817230436

Epoch: 6| Step: 6
Training loss: 3.1144642036305057
Validation loss: 2.921082158375283

Epoch: 6| Step: 7
Training loss: 2.9211912936186795
Validation loss: 2.925249976761733

Epoch: 6| Step: 8
Training loss: 3.0443864098313345
Validation loss: 2.9275368205016274

Epoch: 6| Step: 9
Training loss: 3.1477755851781355
Validation loss: 2.929501895617402

Epoch: 6| Step: 10
Training loss: 3.997205831214135
Validation loss: 2.9274184569004866

Epoch: 6| Step: 11
Training loss: 3.8793975734038577
Validation loss: 2.922748514287291

Epoch: 6| Step: 12
Training loss: 3.397561006314085
Validation loss: 2.9194545647233

Epoch: 6| Step: 13
Training loss: 2.6054509060776243
Validation loss: 2.914602456008149

Epoch: 59| Step: 0
Training loss: 3.1636279902750974
Validation loss: 2.9110540282133366

Epoch: 6| Step: 1
Training loss: 3.2123797442419257
Validation loss: 2.9113993732943233

Epoch: 6| Step: 2
Training loss: 2.844943623981469
Validation loss: 2.914163617359674

Epoch: 6| Step: 3
Training loss: 3.498196409640597
Validation loss: 2.911155992438704

Epoch: 6| Step: 4
Training loss: 3.140790792615534
Validation loss: 2.9138375142403015

Epoch: 6| Step: 5
Training loss: 3.0300992374095284
Validation loss: 2.908904536788652

Epoch: 6| Step: 6
Training loss: 3.424243403491133
Validation loss: 2.910369859481222

Epoch: 6| Step: 7
Training loss: 3.3094361729141677
Validation loss: 2.910088537496144

Epoch: 6| Step: 8
Training loss: 2.9758918387128546
Validation loss: 2.9098986831921523

Epoch: 6| Step: 9
Training loss: 3.0386388331376195
Validation loss: 2.908828501834584

Epoch: 6| Step: 10
Training loss: 3.1550387333881793
Validation loss: 2.9062620558120926

Epoch: 6| Step: 11
Training loss: 3.129482259129308
Validation loss: 2.905606854413883

Epoch: 6| Step: 12
Training loss: 3.5345663516375554
Validation loss: 2.905768776389388

Epoch: 6| Step: 13
Training loss: 3.3758646952285756
Validation loss: 2.90506643099489

Epoch: 60| Step: 0
Training loss: 3.3442775987454603
Validation loss: 2.903786850285256

Epoch: 6| Step: 1
Training loss: 3.6985979052667717
Validation loss: 2.905894611147219

Epoch: 6| Step: 2
Training loss: 3.1557060755021116
Validation loss: 2.9028089009769267

Epoch: 6| Step: 3
Training loss: 3.421675724166821
Validation loss: 2.90617946274963

Epoch: 6| Step: 4
Training loss: 3.5172626665269453
Validation loss: 2.9159229997593963

Epoch: 6| Step: 5
Training loss: 3.160114302197644
Validation loss: 2.9012009250408197

Epoch: 6| Step: 6
Training loss: 3.405545783085066
Validation loss: 2.9021880120575325

Epoch: 6| Step: 7
Training loss: 2.556712803065851
Validation loss: 2.899679225059147

Epoch: 6| Step: 8
Training loss: 3.0463769750229854
Validation loss: 2.8985288735114914

Epoch: 6| Step: 9
Training loss: 2.4242100441641434
Validation loss: 2.899321894560455

Epoch: 6| Step: 10
Training loss: 3.093112147688588
Validation loss: 2.895870778327213

Epoch: 6| Step: 11
Training loss: 3.029894338849103
Validation loss: 2.8959242979894997

Epoch: 6| Step: 12
Training loss: 3.255629139467516
Validation loss: 2.896395420621439

Epoch: 6| Step: 13
Training loss: 3.583969872884488
Validation loss: 2.893802844277121

Epoch: 61| Step: 0
Training loss: 2.619509540835381
Validation loss: 2.8941511513766414

Epoch: 6| Step: 1
Training loss: 3.3493455788526196
Validation loss: 2.8947979756829016

Epoch: 6| Step: 2
Training loss: 4.423717748347086
Validation loss: 2.8935934622918347

Epoch: 6| Step: 3
Training loss: 3.475123555573451
Validation loss: 2.894766147835819

Epoch: 6| Step: 4
Training loss: 3.2204298061899563
Validation loss: 2.896095594804896

Epoch: 6| Step: 5
Training loss: 2.4574013144779485
Validation loss: 2.9153167559910855

Epoch: 6| Step: 6
Training loss: 3.765698064198133
Validation loss: 2.9216307508978874

Epoch: 6| Step: 7
Training loss: 2.4563961694143073
Validation loss: 2.9097627662121295

Epoch: 6| Step: 8
Training loss: 2.8542548024475534
Validation loss: 2.8969483800918363

Epoch: 6| Step: 9
Training loss: 2.9497832913731905
Validation loss: 2.894229061799741

Epoch: 6| Step: 10
Training loss: 2.9719654538802462
Validation loss: 2.8887529416776014

Epoch: 6| Step: 11
Training loss: 2.6940198369304746
Validation loss: 2.8881978823510215

Epoch: 6| Step: 12
Training loss: 2.9406226584803212
Validation loss: 2.8874149803099987

Epoch: 6| Step: 13
Training loss: 4.245837248606026
Validation loss: 2.8852283497330546

Epoch: 62| Step: 0
Training loss: 2.7913332118448952
Validation loss: 2.884728351639123

Epoch: 6| Step: 1
Training loss: 3.5110150439429826
Validation loss: 2.8863667322268864

Epoch: 6| Step: 2
Training loss: 3.4642643148354013
Validation loss: 2.8884943689620393

Epoch: 6| Step: 3
Training loss: 3.9734411673879557
Validation loss: 2.888310175556822

Epoch: 6| Step: 4
Training loss: 2.5079592843043756
Validation loss: 2.889739790838135

Epoch: 6| Step: 5
Training loss: 2.9457675572182658
Validation loss: 2.8839334386815954

Epoch: 6| Step: 6
Training loss: 2.816863003119734
Validation loss: 2.881622557083069

Epoch: 6| Step: 7
Training loss: 3.6580899817326973
Validation loss: 2.883662381359523

Epoch: 6| Step: 8
Training loss: 3.3167294545835877
Validation loss: 2.8803390882393876

Epoch: 6| Step: 9
Training loss: 3.021003946331418
Validation loss: 2.879023486120264

Epoch: 6| Step: 10
Training loss: 2.8019994749168107
Validation loss: 2.8803043872759617

Epoch: 6| Step: 11
Training loss: 3.1362216123206146
Validation loss: 2.8954703365453733

Epoch: 6| Step: 12
Training loss: 3.2656670526598583
Validation loss: 2.9366658880405394

Epoch: 6| Step: 13
Training loss: 3.0232772587542778
Validation loss: 2.953737145875194

Epoch: 63| Step: 0
Training loss: 3.523830214308354
Validation loss: 2.9070011332195413

Epoch: 6| Step: 1
Training loss: 3.3702992799346654
Validation loss: 2.8827715801700013

Epoch: 6| Step: 2
Training loss: 3.7642797069341345
Validation loss: 2.877285495200072

Epoch: 6| Step: 3
Training loss: 2.067879337442984
Validation loss: 2.8766746966870747

Epoch: 6| Step: 4
Training loss: 2.6989915589309765
Validation loss: 2.8786037004083447

Epoch: 6| Step: 5
Training loss: 3.125543470808723
Validation loss: 2.880685663730302

Epoch: 6| Step: 6
Training loss: 3.709561448203883
Validation loss: 2.8797665523313167

Epoch: 6| Step: 7
Training loss: 2.8011857383128564
Validation loss: 2.8808745066066526

Epoch: 6| Step: 8
Training loss: 3.5574851628072532
Validation loss: 2.8808156384790546

Epoch: 6| Step: 9
Training loss: 2.9832831977027108
Validation loss: 2.8784058056685127

Epoch: 6| Step: 10
Training loss: 2.6785051501112265
Validation loss: 2.8780840952591924

Epoch: 6| Step: 11
Training loss: 3.3701108204536347
Validation loss: 2.874555202922297

Epoch: 6| Step: 12
Training loss: 3.4938927909592183
Validation loss: 2.8720528761900432

Epoch: 6| Step: 13
Training loss: 2.6238195399010027
Validation loss: 2.8749866333695793

Epoch: 64| Step: 0
Training loss: 2.6106681132301217
Validation loss: 2.873534523265494

Epoch: 6| Step: 1
Training loss: 3.3450524476277455
Validation loss: 2.873194995974484

Epoch: 6| Step: 2
Training loss: 3.2378964626919116
Validation loss: 2.871426419876237

Epoch: 6| Step: 3
Training loss: 3.1267079073118555
Validation loss: 2.867975219376371

Epoch: 6| Step: 4
Training loss: 3.4403960079869385
Validation loss: 2.870927222013074

Epoch: 6| Step: 5
Training loss: 2.6351215865804014
Validation loss: 2.8738276341502753

Epoch: 6| Step: 6
Training loss: 3.1718103561954876
Validation loss: 2.8746287555166483

Epoch: 6| Step: 7
Training loss: 2.815922837164705
Validation loss: 2.883320104288992

Epoch: 6| Step: 8
Training loss: 3.2610169529431787
Validation loss: 2.8714310401686194

Epoch: 6| Step: 9
Training loss: 3.795184477291559
Validation loss: 2.867009920125117

Epoch: 6| Step: 10
Training loss: 2.5622830182762932
Validation loss: 2.867775736590578

Epoch: 6| Step: 11
Training loss: 3.534193449475831
Validation loss: 2.866304558317177

Epoch: 6| Step: 12
Training loss: 3.2801790942167655
Validation loss: 2.8683943297410055

Epoch: 6| Step: 13
Training loss: 3.4045925482525363
Validation loss: 2.8706156831761622

Epoch: 65| Step: 0
Training loss: 3.3463494010129406
Validation loss: 2.869341490678292

Epoch: 6| Step: 1
Training loss: 2.9077457967627276
Validation loss: 2.868729845258991

Epoch: 6| Step: 2
Training loss: 3.3929955418403135
Validation loss: 2.866223168878517

Epoch: 6| Step: 3
Training loss: 3.80723545991432
Validation loss: 2.866776318776943

Epoch: 6| Step: 4
Training loss: 3.3492822248220273
Validation loss: 2.869593205619058

Epoch: 6| Step: 5
Training loss: 2.7689729243449843
Validation loss: 2.8701614916692813

Epoch: 6| Step: 6
Training loss: 3.1562490935371534
Validation loss: 2.869773959532211

Epoch: 6| Step: 7
Training loss: 3.4437318666399572
Validation loss: 2.8668147215798903

Epoch: 6| Step: 8
Training loss: 2.7047288138916175
Validation loss: 2.8647562216812914

Epoch: 6| Step: 9
Training loss: 2.6467865155595294
Validation loss: 2.862973057312487

Epoch: 6| Step: 10
Training loss: 3.416363741463906
Validation loss: 2.86174832351509

Epoch: 6| Step: 11
Training loss: 3.2669801957318625
Validation loss: 2.858474769944877

Epoch: 6| Step: 12
Training loss: 2.9617028367025835
Validation loss: 2.8550203371725327

Epoch: 6| Step: 13
Training loss: 2.7432463685532005
Validation loss: 2.8613913863699247

Epoch: 66| Step: 0
Training loss: 3.040663427441369
Validation loss: 2.8643924259474307

Epoch: 6| Step: 1
Training loss: 2.596179238219675
Validation loss: 2.873323774943092

Epoch: 6| Step: 2
Training loss: 3.2582483526076564
Validation loss: 2.876519119734036

Epoch: 6| Step: 3
Training loss: 3.3490641069492915
Validation loss: 2.863150764895222

Epoch: 6| Step: 4
Training loss: 1.9456469390053752
Validation loss: 2.8547328916965093

Epoch: 6| Step: 5
Training loss: 3.587225256843367
Validation loss: 2.8532327882106756

Epoch: 6| Step: 6
Training loss: 3.222204040242195
Validation loss: 2.8543277195335555

Epoch: 6| Step: 7
Training loss: 3.3175951081522506
Validation loss: 2.854212607335931

Epoch: 6| Step: 8
Training loss: 3.7533986267409305
Validation loss: 2.851635194650575

Epoch: 6| Step: 9
Training loss: 3.625795474411874
Validation loss: 2.8563842733259794

Epoch: 6| Step: 10
Training loss: 2.911378171268744
Validation loss: 2.8526471974208008

Epoch: 6| Step: 11
Training loss: 3.075366337982025
Validation loss: 2.8523667182940997

Epoch: 6| Step: 12
Training loss: 3.004978182137446
Validation loss: 2.849622484616264

Epoch: 6| Step: 13
Training loss: 3.330056359899547
Validation loss: 2.8521523178491064

Epoch: 67| Step: 0
Training loss: 3.428426384696157
Validation loss: 2.8502224279298223

Epoch: 6| Step: 1
Training loss: 4.015118637517433
Validation loss: 2.8564871335883675

Epoch: 6| Step: 2
Training loss: 2.915003402210691
Validation loss: 2.861937697549805

Epoch: 6| Step: 3
Training loss: 2.827185037273887
Validation loss: 2.856691690720325

Epoch: 6| Step: 4
Training loss: 3.2534619013078543
Validation loss: 2.849764450016672

Epoch: 6| Step: 5
Training loss: 3.3894626013682787
Validation loss: 2.8480854920361987

Epoch: 6| Step: 6
Training loss: 2.364279191094999
Validation loss: 2.850336804554332

Epoch: 6| Step: 7
Training loss: 3.0501144012508403
Validation loss: 2.847663774391374

Epoch: 6| Step: 8
Training loss: 3.596297182390836
Validation loss: 2.846593220447155

Epoch: 6| Step: 9
Training loss: 2.4448070064584084
Validation loss: 2.8461701503712455

Epoch: 6| Step: 10
Training loss: 3.5925714301731
Validation loss: 2.8456745957490424

Epoch: 6| Step: 11
Training loss: 2.9801021965475742
Validation loss: 2.847117757860894

Epoch: 6| Step: 12
Training loss: 2.9590705884201913
Validation loss: 2.8466890597396275

Epoch: 6| Step: 13
Training loss: 2.646923431349729
Validation loss: 2.8439105850705806

Epoch: 68| Step: 0
Training loss: 3.2664212802923447
Validation loss: 2.8441206672352966

Epoch: 6| Step: 1
Training loss: 2.754053682750117
Validation loss: 2.8435421614955994

Epoch: 6| Step: 2
Training loss: 3.069837227647102
Validation loss: 2.842132542896886

Epoch: 6| Step: 3
Training loss: 3.2921974301471324
Validation loss: 2.841612870926856

Epoch: 6| Step: 4
Training loss: 2.9810649630465633
Validation loss: 2.839813879980758

Epoch: 6| Step: 5
Training loss: 2.810470611831236
Validation loss: 2.8427514152220428

Epoch: 6| Step: 6
Training loss: 2.9050487373715277
Validation loss: 2.8366718453933992

Epoch: 6| Step: 7
Training loss: 2.9451269602327246
Validation loss: 2.8381299234561324

Epoch: 6| Step: 8
Training loss: 3.848990984388037
Validation loss: 2.8375221398665134

Epoch: 6| Step: 9
Training loss: 3.731851531187981
Validation loss: 2.834336182667143

Epoch: 6| Step: 10
Training loss: 3.354184989800172
Validation loss: 2.833686865068487

Epoch: 6| Step: 11
Training loss: 3.3533491161068554
Validation loss: 2.835524161401362

Epoch: 6| Step: 12
Training loss: 2.207611817825295
Validation loss: 2.836719074043028

Epoch: 6| Step: 13
Training loss: 3.1087417341060286
Validation loss: 2.833891358216601

Epoch: 69| Step: 0
Training loss: 3.1891959671283994
Validation loss: 2.83434185474459

Epoch: 6| Step: 1
Training loss: 3.0738052031844867
Validation loss: 2.833180608620457

Epoch: 6| Step: 2
Training loss: 2.7081078264302465
Validation loss: 2.8334501744258365

Epoch: 6| Step: 3
Training loss: 3.5455742017743876
Validation loss: 2.835193235909276

Epoch: 6| Step: 4
Training loss: 3.5581174965167404
Validation loss: 2.8339693132620507

Epoch: 6| Step: 5
Training loss: 3.3583813994370075
Validation loss: 2.8307035135028134

Epoch: 6| Step: 6
Training loss: 3.0057254833321596
Validation loss: 2.8270612044055543

Epoch: 6| Step: 7
Training loss: 3.24621743380869
Validation loss: 2.8281924377316403

Epoch: 6| Step: 8
Training loss: 3.488936239948472
Validation loss: 2.829793030800889

Epoch: 6| Step: 9
Training loss: 2.8502799716427942
Validation loss: 2.8265952890507426

Epoch: 6| Step: 10
Training loss: 2.985259718850147
Validation loss: 2.8259255855919525

Epoch: 6| Step: 11
Training loss: 2.8589215362018403
Validation loss: 2.828319672713798

Epoch: 6| Step: 12
Training loss: 3.05927184323581
Validation loss: 2.827828800089431

Epoch: 6| Step: 13
Training loss: 2.526220151488025
Validation loss: 2.829748941672909

Epoch: 70| Step: 0
Training loss: 2.8903684760014574
Validation loss: 2.8278997722840344

Epoch: 6| Step: 1
Training loss: 3.678122153074448
Validation loss: 2.8343862618072935

Epoch: 6| Step: 2
Training loss: 3.3289200813598776
Validation loss: 2.8466088512104095

Epoch: 6| Step: 3
Training loss: 2.902089904938373
Validation loss: 2.8735399270483972

Epoch: 6| Step: 4
Training loss: 2.8408998731983806
Validation loss: 2.8690639401191724

Epoch: 6| Step: 5
Training loss: 3.2048002002824556
Validation loss: 2.8275679671620355

Epoch: 6| Step: 6
Training loss: 2.6691516582897967
Validation loss: 2.8262050223140607

Epoch: 6| Step: 7
Training loss: 2.9090831442209133
Validation loss: 2.838254535231013

Epoch: 6| Step: 8
Training loss: 3.5773050626456877
Validation loss: 2.845814244732952

Epoch: 6| Step: 9
Training loss: 3.358984352286603
Validation loss: 2.8544345805120934

Epoch: 6| Step: 10
Training loss: 2.995157147648739
Validation loss: 2.8464593710925317

Epoch: 6| Step: 11
Training loss: 2.457467675680427
Validation loss: 2.8195731874199255

Epoch: 6| Step: 12
Training loss: 3.2422125022567596
Validation loss: 2.818462704303219

Epoch: 6| Step: 13
Training loss: 3.928140081529943
Validation loss: 2.826579896799912

Epoch: 71| Step: 0
Training loss: 3.1162524051710534
Validation loss: 2.8332733591911645

Epoch: 6| Step: 1
Training loss: 2.7710433727381805
Validation loss: 2.845474619904791

Epoch: 6| Step: 2
Training loss: 3.0383488226527304
Validation loss: 2.857557837703953

Epoch: 6| Step: 3
Training loss: 3.2168093265924766
Validation loss: 2.8357680450429235

Epoch: 6| Step: 4
Training loss: 2.714113513245303
Validation loss: 2.827841269102959

Epoch: 6| Step: 5
Training loss: 3.124574098174487
Validation loss: 2.8266636475535125

Epoch: 6| Step: 6
Training loss: 3.5305858426346064
Validation loss: 2.823347010664773

Epoch: 6| Step: 7
Training loss: 3.22414708650595
Validation loss: 2.818418712632462

Epoch: 6| Step: 8
Training loss: 3.328019261359449
Validation loss: 2.8173618547549366

Epoch: 6| Step: 9
Training loss: 3.263821920875734
Validation loss: 2.816997280426904

Epoch: 6| Step: 10
Training loss: 2.817825108127958
Validation loss: 2.8158459830555276

Epoch: 6| Step: 11
Training loss: 3.550476262556758
Validation loss: 2.8115895218402582

Epoch: 6| Step: 12
Training loss: 2.7621842009646267
Validation loss: 2.8137397358134324

Epoch: 6| Step: 13
Training loss: 3.2560740710744347
Validation loss: 2.8197441974932866

Epoch: 72| Step: 0
Training loss: 3.641385371490644
Validation loss: 2.8612606887461114

Epoch: 6| Step: 1
Training loss: 2.595071938313224
Validation loss: 2.847487913778039

Epoch: 6| Step: 2
Training loss: 3.299806710564636
Validation loss: 2.830908688534494

Epoch: 6| Step: 3
Training loss: 3.1227647034816033
Validation loss: 2.820009954065928

Epoch: 6| Step: 4
Training loss: 3.004514000258042
Validation loss: 2.8123017983004814

Epoch: 6| Step: 5
Training loss: 3.4426472360765383
Validation loss: 2.8108668116834874

Epoch: 6| Step: 6
Training loss: 3.2837999880398008
Validation loss: 2.811959937415421

Epoch: 6| Step: 7
Training loss: 3.369352065376087
Validation loss: 2.8141902297451202

Epoch: 6| Step: 8
Training loss: 3.1304472177829794
Validation loss: 2.817602921282378

Epoch: 6| Step: 9
Training loss: 3.074142125494405
Validation loss: 2.8289964894904496

Epoch: 6| Step: 10
Training loss: 3.2988171393763204
Validation loss: 2.8495999286978067

Epoch: 6| Step: 11
Training loss: 3.099583837816194
Validation loss: 2.8262654869046155

Epoch: 6| Step: 12
Training loss: 2.804601471413033
Validation loss: 2.8194613635462793

Epoch: 6| Step: 13
Training loss: 1.8638481381404335
Validation loss: 2.816384246382034

Epoch: 73| Step: 0
Training loss: 2.877569957316925
Validation loss: 2.8185692369072286

Epoch: 6| Step: 1
Training loss: 3.504146435861024
Validation loss: 2.81319829095261

Epoch: 6| Step: 2
Training loss: 2.9642447568916714
Validation loss: 2.8103717239515302

Epoch: 6| Step: 3
Training loss: 3.4614064607149646
Validation loss: 2.8086949768814873

Epoch: 6| Step: 4
Training loss: 3.283348066680951
Validation loss: 2.806506329919932

Epoch: 6| Step: 5
Training loss: 2.8193498062093942
Validation loss: 2.8075949990357447

Epoch: 6| Step: 6
Training loss: 2.7367658353517985
Validation loss: 2.8042500207532672

Epoch: 6| Step: 7
Training loss: 2.692668557872456
Validation loss: 2.8054949519931736

Epoch: 6| Step: 8
Training loss: 3.1436011034550875
Validation loss: 2.811982562778198

Epoch: 6| Step: 9
Training loss: 3.1860931882286727
Validation loss: 2.8071457627095855

Epoch: 6| Step: 10
Training loss: 3.0192623043329183
Validation loss: 2.813106716622319

Epoch: 6| Step: 11
Training loss: 3.123668692249226
Validation loss: 2.810423613452982

Epoch: 6| Step: 12
Training loss: 2.9051445940442773
Validation loss: 2.816354769293013

Epoch: 6| Step: 13
Training loss: 4.22409419896832
Validation loss: 2.814884177005615

Epoch: 74| Step: 0
Training loss: 3.6297612984520393
Validation loss: 2.8042164201072044

Epoch: 6| Step: 1
Training loss: 3.2528603511167193
Validation loss: 2.805754095272207

Epoch: 6| Step: 2
Training loss: 3.3277488818335486
Validation loss: 2.800001694529324

Epoch: 6| Step: 3
Training loss: 2.115099338155566
Validation loss: 2.797007892306948

Epoch: 6| Step: 4
Training loss: 3.4619292136480864
Validation loss: 2.795519762317011

Epoch: 6| Step: 5
Training loss: 3.0244189500384304
Validation loss: 2.7897433318039195

Epoch: 6| Step: 6
Training loss: 3.6956663063149837
Validation loss: 2.785926558490261

Epoch: 6| Step: 7
Training loss: 2.7673498260085005
Validation loss: 2.7923198707756254

Epoch: 6| Step: 8
Training loss: 2.908474634740302
Validation loss: 2.7867605314398745

Epoch: 6| Step: 9
Training loss: 3.134411791265098
Validation loss: 2.791409089558961

Epoch: 6| Step: 10
Training loss: 3.4045445083485357
Validation loss: 2.788209436276602

Epoch: 6| Step: 11
Training loss: 2.358117077710766
Validation loss: 2.7888147378450205

Epoch: 6| Step: 12
Training loss: 3.101830920079735
Validation loss: 2.7905485824956524

Epoch: 6| Step: 13
Training loss: 2.840379499144034
Validation loss: 2.7927450574518593

Epoch: 75| Step: 0
Training loss: 2.261600260686168
Validation loss: 2.7924944657857638

Epoch: 6| Step: 1
Training loss: 2.938472181109645
Validation loss: 2.8000290832166415

Epoch: 6| Step: 2
Training loss: 3.072697070190332
Validation loss: 2.8030900380021904

Epoch: 6| Step: 3
Training loss: 2.886303780221124
Validation loss: 2.802551690281612

Epoch: 6| Step: 4
Training loss: 2.741783003575646
Validation loss: 2.797781881518314

Epoch: 6| Step: 5
Training loss: 2.9345097032530543
Validation loss: 2.789862614756701

Epoch: 6| Step: 6
Training loss: 2.715279918733768
Validation loss: 2.77994923662788

Epoch: 6| Step: 7
Training loss: 3.6400075233297886
Validation loss: 2.7819130210817917

Epoch: 6| Step: 8
Training loss: 3.568576382290315
Validation loss: 2.7768166278089788

Epoch: 6| Step: 9
Training loss: 3.051048823893392
Validation loss: 2.7742516521570506

Epoch: 6| Step: 10
Training loss: 3.231328884320285
Validation loss: 2.77668626235352

Epoch: 6| Step: 11
Training loss: 2.8754172644296476
Validation loss: 2.7733183314504943

Epoch: 6| Step: 12
Training loss: 3.6339907468469077
Validation loss: 2.776189536059888

Epoch: 6| Step: 13
Training loss: 3.9438644320032124
Validation loss: 2.7811916760455144

Epoch: 76| Step: 0
Training loss: 2.524868680352969
Validation loss: 2.7691507679655305

Epoch: 6| Step: 1
Training loss: 3.1340423985615518
Validation loss: 2.777430301659122

Epoch: 6| Step: 2
Training loss: 3.2251681439235984
Validation loss: 2.840594956035065

Epoch: 6| Step: 3
Training loss: 2.903727924001906
Validation loss: 2.817192918644411

Epoch: 6| Step: 4
Training loss: 3.2652688448223195
Validation loss: 2.791781013717003

Epoch: 6| Step: 5
Training loss: 3.2097397401064702
Validation loss: 2.7820256216222963

Epoch: 6| Step: 6
Training loss: 3.270533618842274
Validation loss: 2.7749021104735787

Epoch: 6| Step: 7
Training loss: 2.8573564585813376
Validation loss: 2.774445382305522

Epoch: 6| Step: 8
Training loss: 3.1221211715340598
Validation loss: 2.772422962460119

Epoch: 6| Step: 9
Training loss: 3.273122257903842
Validation loss: 2.776870034770629

Epoch: 6| Step: 10
Training loss: 3.2901781958002867
Validation loss: 2.7850347514079563

Epoch: 6| Step: 11
Training loss: 2.8262889655901433
Validation loss: 2.799995106884714

Epoch: 6| Step: 12
Training loss: 3.228842310868871
Validation loss: 2.8286385725665624

Epoch: 6| Step: 13
Training loss: 3.398648941653297
Validation loss: 2.8453502243224453

Epoch: 77| Step: 0
Training loss: 3.026697259599898
Validation loss: 2.7911549391342714

Epoch: 6| Step: 1
Training loss: 3.088276346184919
Validation loss: 2.7856440743188786

Epoch: 6| Step: 2
Training loss: 2.947310602187459
Validation loss: 2.772799294444459

Epoch: 6| Step: 3
Training loss: 3.250346238693152
Validation loss: 2.7722993827831446

Epoch: 6| Step: 4
Training loss: 3.3536455843521
Validation loss: 2.7768032764850896

Epoch: 6| Step: 5
Training loss: 2.9887142889872043
Validation loss: 2.7708803706895653

Epoch: 6| Step: 6
Training loss: 2.6178852119197447
Validation loss: 2.7720351633990115

Epoch: 6| Step: 7
Training loss: 2.8786983751379673
Validation loss: 2.7704798182775567

Epoch: 6| Step: 8
Training loss: 3.2419821800575255
Validation loss: 2.7727016213935136

Epoch: 6| Step: 9
Training loss: 2.7106119009822454
Validation loss: 2.7722811811759906

Epoch: 6| Step: 10
Training loss: 3.5621407310962274
Validation loss: 2.769728095430347

Epoch: 6| Step: 11
Training loss: 3.3343502083082854
Validation loss: 2.7666030794074676

Epoch: 6| Step: 12
Training loss: 3.3651686278400414
Validation loss: 2.771385885974318

Epoch: 6| Step: 13
Training loss: 2.3167105823809475
Validation loss: 2.7722014507546024

Epoch: 78| Step: 0
Training loss: 2.7768746582140937
Validation loss: 2.7673188992870568

Epoch: 6| Step: 1
Training loss: 3.361102276694998
Validation loss: 2.778114336674052

Epoch: 6| Step: 2
Training loss: 2.6963493674780024
Validation loss: 2.770182539067918

Epoch: 6| Step: 3
Training loss: 3.146613338013173
Validation loss: 2.7645273015637737

Epoch: 6| Step: 4
Training loss: 2.685777777715564
Validation loss: 2.761459573046615

Epoch: 6| Step: 5
Training loss: 3.4072546920861617
Validation loss: 2.765748235544121

Epoch: 6| Step: 6
Training loss: 3.362231933799356
Validation loss: 2.7651173671656664

Epoch: 6| Step: 7
Training loss: 2.7192752374626656
Validation loss: 2.7638214350305748

Epoch: 6| Step: 8
Training loss: 3.169575125202777
Validation loss: 2.7609129230736382

Epoch: 6| Step: 9
Training loss: 2.766023337778092
Validation loss: 2.7579248705186683

Epoch: 6| Step: 10
Training loss: 3.3952051685570757
Validation loss: 2.7601366089476493

Epoch: 6| Step: 11
Training loss: 3.2483698351162786
Validation loss: 2.760806271685386

Epoch: 6| Step: 12
Training loss: 3.1442604090465314
Validation loss: 2.7571029087165995

Epoch: 6| Step: 13
Training loss: 3.1877813776024793
Validation loss: 2.756664294710684

Epoch: 79| Step: 0
Training loss: 3.3189536511712614
Validation loss: 2.754969798083456

Epoch: 6| Step: 1
Training loss: 2.5651584884132816
Validation loss: 2.754767826624738

Epoch: 6| Step: 2
Training loss: 2.7420848164257086
Validation loss: 2.7514526580052414

Epoch: 6| Step: 3
Training loss: 3.1475683484522956
Validation loss: 2.753947343812784

Epoch: 6| Step: 4
Training loss: 3.8028185129286607
Validation loss: 2.7560150239044017

Epoch: 6| Step: 5
Training loss: 3.137607016391097
Validation loss: 2.7478452408926097

Epoch: 6| Step: 6
Training loss: 3.286968951248948
Validation loss: 2.747378627853667

Epoch: 6| Step: 7
Training loss: 2.0607743413399957
Validation loss: 2.752910519702456

Epoch: 6| Step: 8
Training loss: 2.538738993062548
Validation loss: 2.7541364015226892

Epoch: 6| Step: 9
Training loss: 2.9759953476654113
Validation loss: 2.7536577433626612

Epoch: 6| Step: 10
Training loss: 3.301727917594254
Validation loss: 2.753141101790398

Epoch: 6| Step: 11
Training loss: 3.7111312655005064
Validation loss: 2.753602797372034

Epoch: 6| Step: 12
Training loss: 3.2848612939823085
Validation loss: 2.7531195497912235

Epoch: 6| Step: 13
Training loss: 2.440663070479474
Validation loss: 2.751001669689846

Epoch: 80| Step: 0
Training loss: 3.451141754519805
Validation loss: 2.759639118914079

Epoch: 6| Step: 1
Training loss: 3.0398029906031225
Validation loss: 2.7579081989137744

Epoch: 6| Step: 2
Training loss: 2.5692255104429313
Validation loss: 2.7529509541655903

Epoch: 6| Step: 3
Training loss: 2.907506199548857
Validation loss: 2.7507214089387992

Epoch: 6| Step: 4
Training loss: 3.4485598115096643
Validation loss: 2.7405915457786896

Epoch: 6| Step: 5
Training loss: 2.9532276922869043
Validation loss: 2.741163008826555

Epoch: 6| Step: 6
Training loss: 3.2566908407989765
Validation loss: 2.743004122583703

Epoch: 6| Step: 7
Training loss: 2.920124529181962
Validation loss: 2.7417751390538063

Epoch: 6| Step: 8
Training loss: 3.0513876337986328
Validation loss: 2.738201596899978

Epoch: 6| Step: 9
Training loss: 3.038805168652203
Validation loss: 2.7436455110164237

Epoch: 6| Step: 10
Training loss: 2.4824046832914246
Validation loss: 2.7378489113655546

Epoch: 6| Step: 11
Training loss: 3.3169088712910426
Validation loss: 2.7385793560537857

Epoch: 6| Step: 12
Training loss: 2.947433881462942
Validation loss: 2.7364185409631543

Epoch: 6| Step: 13
Training loss: 3.6196008133373767
Validation loss: 2.733145293553946

Epoch: 81| Step: 0
Training loss: 3.2392294016786183
Validation loss: 2.7348898285486296

Epoch: 6| Step: 1
Training loss: 2.6018869925082155
Validation loss: 2.7375097744629966

Epoch: 6| Step: 2
Training loss: 3.1040435015589445
Validation loss: 2.7337541316566227

Epoch: 6| Step: 3
Training loss: 3.8999355702091063
Validation loss: 2.732181679396102

Epoch: 6| Step: 4
Training loss: 3.5266934594889516
Validation loss: 2.7340983232958727

Epoch: 6| Step: 5
Training loss: 3.20606227273128
Validation loss: 2.7441419030174385

Epoch: 6| Step: 6
Training loss: 2.8874081419498427
Validation loss: 2.7474440053660913

Epoch: 6| Step: 7
Training loss: 3.233750435055356
Validation loss: 2.7523102448505146

Epoch: 6| Step: 8
Training loss: 3.060820449842146
Validation loss: 2.755073065935931

Epoch: 6| Step: 9
Training loss: 2.9001902090373646
Validation loss: 2.747289524413671

Epoch: 6| Step: 10
Training loss: 3.075611618127608
Validation loss: 2.7440718849087666

Epoch: 6| Step: 11
Training loss: 2.1433598110448115
Validation loss: 2.7429845050377724

Epoch: 6| Step: 12
Training loss: 2.695711056639994
Validation loss: 2.7392079872003112

Epoch: 6| Step: 13
Training loss: 3.1186104110638913
Validation loss: 2.7381006111367965

Epoch: 82| Step: 0
Training loss: 2.8249382484911214
Validation loss: 2.752571457735757

Epoch: 6| Step: 1
Training loss: 3.5001730194922986
Validation loss: 2.7826557687815585

Epoch: 6| Step: 2
Training loss: 2.5841869871670577
Validation loss: 2.7558926424315233

Epoch: 6| Step: 3
Training loss: 3.1837899551310787
Validation loss: 2.742578829656174

Epoch: 6| Step: 4
Training loss: 3.2706986579787065
Validation loss: 2.7302835200871107

Epoch: 6| Step: 5
Training loss: 2.7414767221745833
Validation loss: 2.7235045019203117

Epoch: 6| Step: 6
Training loss: 2.9084897178716043
Validation loss: 2.7279883831968763

Epoch: 6| Step: 7
Training loss: 3.4222488547468197
Validation loss: 2.7276022988968336

Epoch: 6| Step: 8
Training loss: 2.4850874545022874
Validation loss: 2.7251836090382553

Epoch: 6| Step: 9
Training loss: 3.3062926378006683
Validation loss: 2.7242985204380394

Epoch: 6| Step: 10
Training loss: 2.788586316744572
Validation loss: 2.7303395334689577

Epoch: 6| Step: 11
Training loss: 3.5258876629794496
Validation loss: 2.746128528588116

Epoch: 6| Step: 12
Training loss: 3.0196105235995914
Validation loss: 2.747285037811829

Epoch: 6| Step: 13
Training loss: 3.092822311492186
Validation loss: 2.7546041667418555

Epoch: 83| Step: 0
Training loss: 3.0835557462188135
Validation loss: 2.748401093125975

Epoch: 6| Step: 1
Training loss: 3.5512336467942425
Validation loss: 2.7326856728864763

Epoch: 6| Step: 2
Training loss: 2.796649177854262
Validation loss: 2.7259732365453377

Epoch: 6| Step: 3
Training loss: 3.2682852245047127
Validation loss: 2.7205931992869226

Epoch: 6| Step: 4
Training loss: 2.5366297878670787
Validation loss: 2.721473119347508

Epoch: 6| Step: 5
Training loss: 3.35196880732114
Validation loss: 2.7191444877390847

Epoch: 6| Step: 6
Training loss: 2.483266139134796
Validation loss: 2.7193597414645243

Epoch: 6| Step: 7
Training loss: 2.457205810168161
Validation loss: 2.726751466058221

Epoch: 6| Step: 8
Training loss: 3.0719069206620544
Validation loss: 2.7238921976214496

Epoch: 6| Step: 9
Training loss: 3.341835258080637
Validation loss: 2.720950512752144

Epoch: 6| Step: 10
Training loss: 2.888771576414986
Validation loss: 2.7193694822755763

Epoch: 6| Step: 11
Training loss: 3.3392776098655697
Validation loss: 2.717690106239688

Epoch: 6| Step: 12
Training loss: 2.7831080370269783
Validation loss: 2.717697515976984

Epoch: 6| Step: 13
Training loss: 3.887460425074261
Validation loss: 2.7177918239900385

Epoch: 84| Step: 0
Training loss: 2.927900822382481
Validation loss: 2.721544460201015

Epoch: 6| Step: 1
Training loss: 3.205699946344962
Validation loss: 2.730594834960011

Epoch: 6| Step: 2
Training loss: 3.0769948675877137
Validation loss: 2.7449593385480315

Epoch: 6| Step: 3
Training loss: 3.2562960747737475
Validation loss: 2.7678953427198

Epoch: 6| Step: 4
Training loss: 2.704559474760104
Validation loss: 2.795254031658325

Epoch: 6| Step: 5
Training loss: 3.5854396100430455
Validation loss: 2.840725195719205

Epoch: 6| Step: 6
Training loss: 3.3516555453102845
Validation loss: 2.8078711233559304

Epoch: 6| Step: 7
Training loss: 3.0978157223688854
Validation loss: 2.7502185188425625

Epoch: 6| Step: 8
Training loss: 2.4064667839390905
Validation loss: 2.724073630920008

Epoch: 6| Step: 9
Training loss: 2.4851054911030235
Validation loss: 2.7113093045866825

Epoch: 6| Step: 10
Training loss: 3.0886902711744275
Validation loss: 2.717747834680824

Epoch: 6| Step: 11
Training loss: 3.767341317604833
Validation loss: 2.716007356595444

Epoch: 6| Step: 12
Training loss: 2.7658016342395486
Validation loss: 2.719449412643828

Epoch: 6| Step: 13
Training loss: 2.6062096681836042
Validation loss: 2.72490760316926

Epoch: 85| Step: 0
Training loss: 3.4325512029130922
Validation loss: 2.736171663511426

Epoch: 6| Step: 1
Training loss: 2.77906301858945
Validation loss: 2.7524338651104165

Epoch: 6| Step: 2
Training loss: 3.3842530740206995
Validation loss: 2.770694323622649

Epoch: 6| Step: 3
Training loss: 2.6660101698375964
Validation loss: 2.7398472635459674

Epoch: 6| Step: 4
Training loss: 2.9616308683751753
Validation loss: 2.7292678583794263

Epoch: 6| Step: 5
Training loss: 2.44252337722758
Validation loss: 2.719225719162747

Epoch: 6| Step: 6
Training loss: 2.5268837275744733
Validation loss: 2.716858139238463

Epoch: 6| Step: 7
Training loss: 2.554019945752339
Validation loss: 2.7118023936646116

Epoch: 6| Step: 8
Training loss: 2.9850332123459857
Validation loss: 2.726223674312543

Epoch: 6| Step: 9
Training loss: 2.7465415361598073
Validation loss: 2.728182734516699

Epoch: 6| Step: 10
Training loss: 3.9261253395924514
Validation loss: 2.72058676801744

Epoch: 6| Step: 11
Training loss: 3.2471291994190388
Validation loss: 2.7108893377632364

Epoch: 6| Step: 12
Training loss: 3.361749138363407
Validation loss: 2.704676101347855

Epoch: 6| Step: 13
Training loss: 3.6652028600904525
Validation loss: 2.7071251530554608

Epoch: 86| Step: 0
Training loss: 3.2013847275654266
Validation loss: 2.7101204162575936

Epoch: 6| Step: 1
Training loss: 3.8194461768560624
Validation loss: 2.7107743545166323

Epoch: 6| Step: 2
Training loss: 3.0798972977198367
Validation loss: 2.711032123550879

Epoch: 6| Step: 3
Training loss: 3.135607911082937
Validation loss: 2.7084435146312438

Epoch: 6| Step: 4
Training loss: 3.0043994116778374
Validation loss: 2.7072149581757126

Epoch: 6| Step: 5
Training loss: 2.652497007636163
Validation loss: 2.7029436638515256

Epoch: 6| Step: 6
Training loss: 3.0026170124309632
Validation loss: 2.706080709790947

Epoch: 6| Step: 7
Training loss: 2.435614712649129
Validation loss: 2.710786995015752

Epoch: 6| Step: 8
Training loss: 3.4328004096282307
Validation loss: 2.7147113419842506

Epoch: 6| Step: 9
Training loss: 3.0435820170895638
Validation loss: 2.719765179059982

Epoch: 6| Step: 10
Training loss: 3.137522821229409
Validation loss: 2.7295396072965024

Epoch: 6| Step: 11
Training loss: 3.3360605686187226
Validation loss: 2.719728743697968

Epoch: 6| Step: 12
Training loss: 2.1199221809067863
Validation loss: 2.712959269723558

Epoch: 6| Step: 13
Training loss: 2.6961645576333764
Validation loss: 2.7101552809427796

Epoch: 87| Step: 0
Training loss: 3.0815124461850956
Validation loss: 2.710270144785212

Epoch: 6| Step: 1
Training loss: 3.0319142351224553
Validation loss: 2.6992384158939275

Epoch: 6| Step: 2
Training loss: 3.144406296042203
Validation loss: 2.6977234992683488

Epoch: 6| Step: 3
Training loss: 3.0055855569930583
Validation loss: 2.7004442846782024

Epoch: 6| Step: 4
Training loss: 2.7387224786055517
Validation loss: 2.7032472923167084

Epoch: 6| Step: 5
Training loss: 3.4656121435176317
Validation loss: 2.707323272825753

Epoch: 6| Step: 6
Training loss: 3.186330244057313
Validation loss: 2.7190693757395805

Epoch: 6| Step: 7
Training loss: 3.743605820772374
Validation loss: 2.723719527318405

Epoch: 6| Step: 8
Training loss: 2.06996710433253
Validation loss: 2.7217242481141373

Epoch: 6| Step: 9
Training loss: 2.9873126685493254
Validation loss: 2.7183196618668806

Epoch: 6| Step: 10
Training loss: 2.7385490602142215
Validation loss: 2.711269101987709

Epoch: 6| Step: 11
Training loss: 3.225787422985435
Validation loss: 2.706464618451313

Epoch: 6| Step: 12
Training loss: 2.941414355587271
Validation loss: 2.701368524815031

Epoch: 6| Step: 13
Training loss: 3.0982739288506753
Validation loss: 2.6957246541067073

Epoch: 88| Step: 0
Training loss: 3.4559822516868643
Validation loss: 2.6922092068371364

Epoch: 6| Step: 1
Training loss: 2.373205611331902
Validation loss: 2.744499341506369

Epoch: 6| Step: 2
Training loss: 2.8205551085380858
Validation loss: 2.8598558817357853

Epoch: 6| Step: 3
Training loss: 3.2251798239556484
Validation loss: 2.930398118552067

Epoch: 6| Step: 4
Training loss: 3.1965902520501364
Validation loss: 2.8205715034722765

Epoch: 6| Step: 5
Training loss: 3.1914546594018187
Validation loss: 2.7146450212852566

Epoch: 6| Step: 6
Training loss: 3.3266358961875016
Validation loss: 2.6982059612684286

Epoch: 6| Step: 7
Training loss: 3.3305546304975264
Validation loss: 2.6972977322674736

Epoch: 6| Step: 8
Training loss: 2.9648191428388433
Validation loss: 2.7073101568920874

Epoch: 6| Step: 9
Training loss: 2.4935933993700408
Validation loss: 2.7289073426047783

Epoch: 6| Step: 10
Training loss: 3.2420010064963036
Validation loss: 2.77550373861666

Epoch: 6| Step: 11
Training loss: 2.836744797822609
Validation loss: 2.810916290671056

Epoch: 6| Step: 12
Training loss: 3.5230375684629407
Validation loss: 2.8578729627639508

Epoch: 6| Step: 13
Training loss: 2.690188903557241
Validation loss: 2.7815826270572876

Epoch: 89| Step: 0
Training loss: 3.111334561845978
Validation loss: 2.824107760944175

Epoch: 6| Step: 1
Training loss: 2.9533629952255076
Validation loss: 2.8019173484490785

Epoch: 6| Step: 2
Training loss: 2.562876789955132
Validation loss: 2.782654444883536

Epoch: 6| Step: 3
Training loss: 3.3211123232433186
Validation loss: 2.7817434684518156

Epoch: 6| Step: 4
Training loss: 3.3078338579110906
Validation loss: 2.781275362989334

Epoch: 6| Step: 5
Training loss: 3.7215719335047117
Validation loss: 2.7727483808080997

Epoch: 6| Step: 6
Training loss: 2.953701709767458
Validation loss: 2.76062690428029

Epoch: 6| Step: 7
Training loss: 3.1820872106391556
Validation loss: 2.744172793863148

Epoch: 6| Step: 8
Training loss: 2.518519282600603
Validation loss: 2.7489986731481273

Epoch: 6| Step: 9
Training loss: 3.221460034854468
Validation loss: 2.78512111560484

Epoch: 6| Step: 10
Training loss: 2.751052828304745
Validation loss: 2.7681732608896854

Epoch: 6| Step: 11
Training loss: 3.3268183619199903
Validation loss: 2.7834148657606663

Epoch: 6| Step: 12
Training loss: 3.2644289007380194
Validation loss: 2.803836792782418

Epoch: 6| Step: 13
Training loss: 2.8569894647293865
Validation loss: 2.776488466135813

Epoch: 90| Step: 0
Training loss: 3.2970176051245126
Validation loss: 2.7340358053796296

Epoch: 6| Step: 1
Training loss: 3.175881697414001
Validation loss: 2.701368404290058

Epoch: 6| Step: 2
Training loss: 2.4342874729155257
Validation loss: 2.691714478130362

Epoch: 6| Step: 3
Training loss: 3.086965500747881
Validation loss: 2.6883849003308513

Epoch: 6| Step: 4
Training loss: 3.403495584842872
Validation loss: 2.693746172109459

Epoch: 6| Step: 5
Training loss: 2.4747865488505925
Validation loss: 2.701336442206096

Epoch: 6| Step: 6
Training loss: 3.0761419579398397
Validation loss: 2.723884384973265

Epoch: 6| Step: 7
Training loss: 2.9528104422831887
Validation loss: 2.692110415400985

Epoch: 6| Step: 8
Training loss: 3.0457360902249606
Validation loss: 2.698201208724725

Epoch: 6| Step: 9
Training loss: 3.2389675098849526
Validation loss: 2.7054326207608295

Epoch: 6| Step: 10
Training loss: 2.457421300642716
Validation loss: 2.70850765875698

Epoch: 6| Step: 11
Training loss: 3.486142381694175
Validation loss: 2.7233072270259044

Epoch: 6| Step: 12
Training loss: 3.132384768084398
Validation loss: 2.710588750097593

Epoch: 6| Step: 13
Training loss: 3.089331351714088
Validation loss: 2.7148306562347417

Epoch: 91| Step: 0
Training loss: 2.8498797742682416
Validation loss: 2.711266591551164

Epoch: 6| Step: 1
Training loss: 2.9699815303857564
Validation loss: 2.7127888123079753

Epoch: 6| Step: 2
Training loss: 2.6654049352073934
Validation loss: 2.71442848465095

Epoch: 6| Step: 3
Training loss: 2.6825166675799954
Validation loss: 2.7273384821377182

Epoch: 6| Step: 4
Training loss: 2.8676787327186624
Validation loss: 2.768768942922381

Epoch: 6| Step: 5
Training loss: 3.1742580838574814
Validation loss: 2.7603825968526134

Epoch: 6| Step: 6
Training loss: 3.1534583710390054
Validation loss: 2.7644803493086085

Epoch: 6| Step: 7
Training loss: 3.21857074127277
Validation loss: 2.7059196059237496

Epoch: 6| Step: 8
Training loss: 3.3928641383737137
Validation loss: 2.6922002966732976

Epoch: 6| Step: 9
Training loss: 3.188508416523502
Validation loss: 2.6910499465378903

Epoch: 6| Step: 10
Training loss: 3.165236116493798
Validation loss: 2.699357525122658

Epoch: 6| Step: 11
Training loss: 2.7252759111343354
Validation loss: 2.7144799717717984

Epoch: 6| Step: 12
Training loss: 3.1857458037308577
Validation loss: 2.7234815302858335

Epoch: 6| Step: 13
Training loss: 3.2094773734014663
Validation loss: 2.7279116022559644

Epoch: 92| Step: 0
Training loss: 2.955044238796954
Validation loss: 2.700654616125264

Epoch: 6| Step: 1
Training loss: 3.1434947704661833
Validation loss: 2.691683935777158

Epoch: 6| Step: 2
Training loss: 3.3902652391403882
Validation loss: 2.68345541784911

Epoch: 6| Step: 3
Training loss: 3.4358691421654814
Validation loss: 2.6830778845179846

Epoch: 6| Step: 4
Training loss: 3.1857282913164062
Validation loss: 2.677922386723769

Epoch: 6| Step: 5
Training loss: 2.3350215889629053
Validation loss: 2.679866378564958

Epoch: 6| Step: 6
Training loss: 2.8479579770920473
Validation loss: 2.6836339086561587

Epoch: 6| Step: 7
Training loss: 2.6234264198600887
Validation loss: 2.684211792216897

Epoch: 6| Step: 8
Training loss: 3.196317855001313
Validation loss: 2.679432762405909

Epoch: 6| Step: 9
Training loss: 3.09947245631354
Validation loss: 2.6803162152115894

Epoch: 6| Step: 10
Training loss: 2.7098206959770796
Validation loss: 2.6787808408977254

Epoch: 6| Step: 11
Training loss: 3.2395714926222183
Validation loss: 2.6798764623830595

Epoch: 6| Step: 12
Training loss: 3.364326837327101
Validation loss: 2.6837721752479027

Epoch: 6| Step: 13
Training loss: 2.365812399532967
Validation loss: 2.695640084891101

Epoch: 93| Step: 0
Training loss: 3.3270363616653276
Validation loss: 2.697989823228517

Epoch: 6| Step: 1
Training loss: 3.141666676110656
Validation loss: 2.706569403584437

Epoch: 6| Step: 2
Training loss: 3.4623976268851844
Validation loss: 2.695098997853222

Epoch: 6| Step: 3
Training loss: 2.2554359468004472
Validation loss: 2.6806418139892387

Epoch: 6| Step: 4
Training loss: 2.8464081466223714
Validation loss: 2.677256260690883

Epoch: 6| Step: 5
Training loss: 3.6146112417120237
Validation loss: 2.6743971276299905

Epoch: 6| Step: 6
Training loss: 3.1967200278030647
Validation loss: 2.6733221694782334

Epoch: 6| Step: 7
Training loss: 2.478354590845771
Validation loss: 2.669849172027289

Epoch: 6| Step: 8
Training loss: 2.248067873965239
Validation loss: 2.6665655755934443

Epoch: 6| Step: 9
Training loss: 3.060728533915609
Validation loss: 2.66758147117413

Epoch: 6| Step: 10
Training loss: 2.55457307985117
Validation loss: 2.6642762039698584

Epoch: 6| Step: 11
Training loss: 3.7157234249441538
Validation loss: 2.657293114161891

Epoch: 6| Step: 12
Training loss: 2.784303510542333
Validation loss: 2.655840030039834

Epoch: 6| Step: 13
Training loss: 3.279731907936905
Validation loss: 2.653312010888357

Epoch: 94| Step: 0
Training loss: 3.031162535988474
Validation loss: 2.6580292361688667

Epoch: 6| Step: 1
Training loss: 3.0110003335649145
Validation loss: 2.65668851742172

Epoch: 6| Step: 2
Training loss: 3.3452170888024324
Validation loss: 2.6621005903990813

Epoch: 6| Step: 3
Training loss: 3.6072082621513832
Validation loss: 2.6635218462536088

Epoch: 6| Step: 4
Training loss: 2.651382114656415
Validation loss: 2.663303361269439

Epoch: 6| Step: 5
Training loss: 2.3170947230589087
Validation loss: 2.6595899725972396

Epoch: 6| Step: 6
Training loss: 2.902110443390252
Validation loss: 2.661140473162743

Epoch: 6| Step: 7
Training loss: 2.888664281704861
Validation loss: 2.6584941632387573

Epoch: 6| Step: 8
Training loss: 3.0248855947503412
Validation loss: 2.65110424092082

Epoch: 6| Step: 9
Training loss: 2.63717380694159
Validation loss: 2.6483735446369105

Epoch: 6| Step: 10
Training loss: 3.0341829877577
Validation loss: 2.649440074081292

Epoch: 6| Step: 11
Training loss: 3.1686469127131045
Validation loss: 2.648097247850991

Epoch: 6| Step: 12
Training loss: 3.1679976493749664
Validation loss: 2.659663906411454

Epoch: 6| Step: 13
Training loss: 3.2749119171644216
Validation loss: 2.663588264685235

Epoch: 95| Step: 0
Training loss: 2.8881721605992006
Validation loss: 2.6633258104488253

Epoch: 6| Step: 1
Training loss: 3.697392400551998
Validation loss: 2.680924466518634

Epoch: 6| Step: 2
Training loss: 2.8390685732770757
Validation loss: 2.6827238931535855

Epoch: 6| Step: 3
Training loss: 2.464872381222381
Validation loss: 2.6975345449446153

Epoch: 6| Step: 4
Training loss: 3.0429145308672547
Validation loss: 2.674900368801765

Epoch: 6| Step: 5
Training loss: 3.354691616388078
Validation loss: 2.665017299200777

Epoch: 6| Step: 6
Training loss: 3.1082405819660837
Validation loss: 2.6531969344645945

Epoch: 6| Step: 7
Training loss: 3.3148376565482085
Validation loss: 2.656380162678237

Epoch: 6| Step: 8
Training loss: 2.7654918918797673
Validation loss: 2.6538823229965267

Epoch: 6| Step: 9
Training loss: 2.530547433061495
Validation loss: 2.6514915837035695

Epoch: 6| Step: 10
Training loss: 2.9960668530307513
Validation loss: 2.65684052188119

Epoch: 6| Step: 11
Training loss: 3.187879502387241
Validation loss: 2.6584857138484015

Epoch: 6| Step: 12
Training loss: 2.9020289459572637
Validation loss: 2.6626809964477323

Epoch: 6| Step: 13
Training loss: 2.8426486387283534
Validation loss: 2.6595571691224937

Epoch: 96| Step: 0
Training loss: 2.9105638871382435
Validation loss: 2.6613093508788714

Epoch: 6| Step: 1
Training loss: 3.0820430083346677
Validation loss: 2.667684095303757

Epoch: 6| Step: 2
Training loss: 2.4188121501813633
Validation loss: 2.6646621583017613

Epoch: 6| Step: 3
Training loss: 3.1699636930197603
Validation loss: 2.662343849187563

Epoch: 6| Step: 4
Training loss: 3.011203984106511
Validation loss: 2.6622526498484236

Epoch: 6| Step: 5
Training loss: 2.4799961871456246
Validation loss: 2.6574387526967986

Epoch: 6| Step: 6
Training loss: 3.741178691170415
Validation loss: 2.655021515141428

Epoch: 6| Step: 7
Training loss: 2.950193534580315
Validation loss: 2.657382597673736

Epoch: 6| Step: 8
Training loss: 2.710642070228352
Validation loss: 2.6559048818725

Epoch: 6| Step: 9
Training loss: 3.361852681415128
Validation loss: 2.6520090450905403

Epoch: 6| Step: 10
Training loss: 2.7653615362678226
Validation loss: 2.65040403324868

Epoch: 6| Step: 11
Training loss: 3.395060086512142
Validation loss: 2.6477009566443246

Epoch: 6| Step: 12
Training loss: 3.098046142362557
Validation loss: 2.645895191684239

Epoch: 6| Step: 13
Training loss: 2.7163190826043446
Validation loss: 2.642508118622291

Epoch: 97| Step: 0
Training loss: 2.6001390566686373
Validation loss: 2.6441330737432693

Epoch: 6| Step: 1
Training loss: 2.789401592082582
Validation loss: 2.6396321221712165

Epoch: 6| Step: 2
Training loss: 2.6608561352729367
Validation loss: 2.6395873003875936

Epoch: 6| Step: 3
Training loss: 3.3534570421135235
Validation loss: 2.639766506234002

Epoch: 6| Step: 4
Training loss: 3.199989831431445
Validation loss: 2.6502412860694444

Epoch: 6| Step: 5
Training loss: 2.9161140645013557
Validation loss: 2.6525626409309604

Epoch: 6| Step: 6
Training loss: 2.6312844570921103
Validation loss: 2.6522546677384287

Epoch: 6| Step: 7
Training loss: 2.7209465536849953
Validation loss: 2.662046115981232

Epoch: 6| Step: 8
Training loss: 2.982815799541457
Validation loss: 2.6530767123933425

Epoch: 6| Step: 9
Training loss: 3.350308270291175
Validation loss: 2.6567719817089976

Epoch: 6| Step: 10
Training loss: 3.093884243605373
Validation loss: 2.6743456031162514

Epoch: 6| Step: 11
Training loss: 2.974118488406448
Validation loss: 2.6651768239857603

Epoch: 6| Step: 12
Training loss: 3.2583581115352884
Validation loss: 2.647690547919377

Epoch: 6| Step: 13
Training loss: 3.1916066063657285
Validation loss: 2.647708756867566

Epoch: 98| Step: 0
Training loss: 3.4139323264299426
Validation loss: 2.6372181331452644

Epoch: 6| Step: 1
Training loss: 2.7559370628777895
Validation loss: 2.632540027346937

Epoch: 6| Step: 2
Training loss: 3.3254124149024
Validation loss: 2.633355674581382

Epoch: 6| Step: 3
Training loss: 2.798135228448287
Validation loss: 2.6334664575809663

Epoch: 6| Step: 4
Training loss: 2.8958661377144206
Validation loss: 2.63076297675274

Epoch: 6| Step: 5
Training loss: 2.6594655040577138
Validation loss: 2.6322820905775846

Epoch: 6| Step: 6
Training loss: 2.775190202535279
Validation loss: 2.632502141277998

Epoch: 6| Step: 7
Training loss: 3.253617254385818
Validation loss: 2.6305010366005392

Epoch: 6| Step: 8
Training loss: 2.7206599224573753
Validation loss: 2.629744738490458

Epoch: 6| Step: 9
Training loss: 3.1315093338528968
Validation loss: 2.6380146918453953

Epoch: 6| Step: 10
Training loss: 2.9858666332225225
Validation loss: 2.643902821786823

Epoch: 6| Step: 11
Training loss: 2.8877962034814364
Validation loss: 2.6471627573985064

Epoch: 6| Step: 12
Training loss: 2.7232407937110934
Validation loss: 2.6417048047980636

Epoch: 6| Step: 13
Training loss: 3.6091134112796337
Validation loss: 2.636939957795434

Epoch: 99| Step: 0
Training loss: 3.5092881800849285
Validation loss: 2.631358950439963

Epoch: 6| Step: 1
Training loss: 2.55859524093468
Validation loss: 2.635377690934423

Epoch: 6| Step: 2
Training loss: 2.89316294834963
Validation loss: 2.635506580055527

Epoch: 6| Step: 3
Training loss: 2.5321098091817413
Validation loss: 2.6381176556826764

Epoch: 6| Step: 4
Training loss: 2.8824231057940524
Validation loss: 2.6449695101075354

Epoch: 6| Step: 5
Training loss: 3.4564805793762923
Validation loss: 2.6582753228908165

Epoch: 6| Step: 6
Training loss: 2.4059109139252493
Validation loss: 2.6483781562119577

Epoch: 6| Step: 7
Training loss: 2.9786571431544187
Validation loss: 2.646526724142748

Epoch: 6| Step: 8
Training loss: 3.3998513974644995
Validation loss: 2.6339037633945868

Epoch: 6| Step: 9
Training loss: 2.7560157866669455
Validation loss: 2.631918125405383

Epoch: 6| Step: 10
Training loss: 3.1092418853023256
Validation loss: 2.6296686912590608

Epoch: 6| Step: 11
Training loss: 2.7229693764972454
Validation loss: 2.6214709137328867

Epoch: 6| Step: 12
Training loss: 3.570092259131197
Validation loss: 2.618088662006463

Epoch: 6| Step: 13
Training loss: 2.2570408753229123
Validation loss: 2.620565478532252

Epoch: 100| Step: 0
Training loss: 3.339145520489761
Validation loss: 2.6229666331569903

Epoch: 6| Step: 1
Training loss: 2.978671550734206
Validation loss: 2.6331515007071613

Epoch: 6| Step: 2
Training loss: 3.410200155877865
Validation loss: 2.658306982024431

Epoch: 6| Step: 3
Training loss: 3.078491808728139
Validation loss: 2.6794007874226957

Epoch: 6| Step: 4
Training loss: 2.4448091519064645
Validation loss: 2.6415534996521983

Epoch: 6| Step: 5
Training loss: 2.4361241688143376
Validation loss: 2.62735533338195

Epoch: 6| Step: 6
Training loss: 3.098132487725311
Validation loss: 2.6232592030133737

Epoch: 6| Step: 7
Training loss: 2.7434505151478388
Validation loss: 2.622268883053207

Epoch: 6| Step: 8
Training loss: 3.061653175829585
Validation loss: 2.6288904404339672

Epoch: 6| Step: 9
Training loss: 3.0116145688652405
Validation loss: 2.630269833023137

Epoch: 6| Step: 10
Training loss: 2.838462189194583
Validation loss: 2.629625396963259

Epoch: 6| Step: 11
Training loss: 3.2018004120972705
Validation loss: 2.6334599955782445

Epoch: 6| Step: 12
Training loss: 3.1123989104128444
Validation loss: 2.6327978570525494

Epoch: 6| Step: 13
Training loss: 2.4255057407264817
Validation loss: 2.6285962775925635

Epoch: 101| Step: 0
Training loss: 2.9636552964311575
Validation loss: 2.6319480254037924

Epoch: 6| Step: 1
Training loss: 2.9387215854142408
Validation loss: 2.635649006491859

Epoch: 6| Step: 2
Training loss: 3.0286969316960293
Validation loss: 2.6401410820504285

Epoch: 6| Step: 3
Training loss: 2.8230917807079927
Validation loss: 2.6531176615011947

Epoch: 6| Step: 4
Training loss: 3.238156085016999
Validation loss: 2.6350535506945905

Epoch: 6| Step: 5
Training loss: 3.2383115833734624
Validation loss: 2.6290239820533157

Epoch: 6| Step: 6
Training loss: 2.6220253938773546
Validation loss: 2.6228581043581345

Epoch: 6| Step: 7
Training loss: 3.8029375066123845
Validation loss: 2.6234852805152156

Epoch: 6| Step: 8
Training loss: 2.4409284688743202
Validation loss: 2.6200374978112575

Epoch: 6| Step: 9
Training loss: 2.5421218985526304
Validation loss: 2.6244852456896597

Epoch: 6| Step: 10
Training loss: 2.2494624873363844
Validation loss: 2.6217191950127985

Epoch: 6| Step: 11
Training loss: 2.8108161123973234
Validation loss: 2.616134179361867

Epoch: 6| Step: 12
Training loss: 3.697047400948936
Validation loss: 2.617909363772182

Epoch: 6| Step: 13
Training loss: 2.394731771464851
Validation loss: 2.618552639801577

Epoch: 102| Step: 0
Training loss: 3.49789692500354
Validation loss: 2.617276784555157

Epoch: 6| Step: 1
Training loss: 2.770260476765833
Validation loss: 2.615754956349077

Epoch: 6| Step: 2
Training loss: 2.674637999951794
Validation loss: 2.6197039428994544

Epoch: 6| Step: 3
Training loss: 2.1445390322462394
Validation loss: 2.618245415006703

Epoch: 6| Step: 4
Training loss: 3.4435848134157374
Validation loss: 2.619606154532002

Epoch: 6| Step: 5
Training loss: 2.830475394283017
Validation loss: 2.6140866306432433

Epoch: 6| Step: 6
Training loss: 3.2302715421214736
Validation loss: 2.617998546349097

Epoch: 6| Step: 7
Training loss: 3.037527760822296
Validation loss: 2.611761497012835

Epoch: 6| Step: 8
Training loss: 3.0200817006156564
Validation loss: 2.6103360275089194

Epoch: 6| Step: 9
Training loss: 3.446901123833248
Validation loss: 2.6089424932702987

Epoch: 6| Step: 10
Training loss: 2.396472436553393
Validation loss: 2.617356166507476

Epoch: 6| Step: 11
Training loss: 2.7397530120017133
Validation loss: 2.6362119349695203

Epoch: 6| Step: 12
Training loss: 3.4560636556379123
Validation loss: 2.6391592018640475

Epoch: 6| Step: 13
Training loss: 2.2967689126356
Validation loss: 2.625876208678335

Epoch: 103| Step: 0
Training loss: 3.218298723010688
Validation loss: 2.6255318571150497

Epoch: 6| Step: 1
Training loss: 3.618645853971798
Validation loss: 2.610857279186745

Epoch: 6| Step: 2
Training loss: 3.1916233395124807
Validation loss: 2.6084114325898446

Epoch: 6| Step: 3
Training loss: 3.0830002338460067
Validation loss: 2.6102379029198204

Epoch: 6| Step: 4
Training loss: 2.586210852981698
Validation loss: 2.6079557244629092

Epoch: 6| Step: 5
Training loss: 2.5232787658085796
Validation loss: 2.6173617769467463

Epoch: 6| Step: 6
Training loss: 3.3064228668884166
Validation loss: 2.6171654465367133

Epoch: 6| Step: 7
Training loss: 2.9018560849554493
Validation loss: 2.6190158237710857

Epoch: 6| Step: 8
Training loss: 2.7154540329682573
Validation loss: 2.6219229860832933

Epoch: 6| Step: 9
Training loss: 2.4667587941810267
Validation loss: 2.6273394978957003

Epoch: 6| Step: 10
Training loss: 2.944978487619477
Validation loss: 2.6215414261529992

Epoch: 6| Step: 11
Training loss: 3.0470379125617026
Validation loss: 2.6271332258456623

Epoch: 6| Step: 12
Training loss: 2.8529445695596647
Validation loss: 2.6252081642489458

Epoch: 6| Step: 13
Training loss: 3.023546635829056
Validation loss: 2.621951497734807

Epoch: 104| Step: 0
Training loss: 3.0903316840757626
Validation loss: 2.632415518572011

Epoch: 6| Step: 1
Training loss: 3.1689957201788266
Validation loss: 2.641412933804401

Epoch: 6| Step: 2
Training loss: 3.3933530459427854
Validation loss: 2.6660344896021346

Epoch: 6| Step: 3
Training loss: 3.2492501787709673
Validation loss: 2.6653987006807687

Epoch: 6| Step: 4
Training loss: 2.943220047921711
Validation loss: 2.669511030521396

Epoch: 6| Step: 5
Training loss: 2.6813982515764287
Validation loss: 2.6687707038190234

Epoch: 6| Step: 6
Training loss: 2.545482324937858
Validation loss: 2.670838435179696

Epoch: 6| Step: 7
Training loss: 2.515784785722684
Validation loss: 2.6786479968501538

Epoch: 6| Step: 8
Training loss: 2.9585650357771165
Validation loss: 2.679595795495526

Epoch: 6| Step: 9
Training loss: 3.0591190905202352
Validation loss: 2.683574753766138

Epoch: 6| Step: 10
Training loss: 2.9279408856037112
Validation loss: 2.6796457509888327

Epoch: 6| Step: 11
Training loss: 2.6909184560565924
Validation loss: 2.679210412649697

Epoch: 6| Step: 12
Training loss: 3.2209346727333084
Validation loss: 2.68271596539248

Epoch: 6| Step: 13
Training loss: 3.566269336090456
Validation loss: 2.690008876843987

Epoch: 105| Step: 0
Training loss: 3.045004089302612
Validation loss: 2.6741275307964836

Epoch: 6| Step: 1
Training loss: 3.1177352385799697
Validation loss: 2.6765322856475064

Epoch: 6| Step: 2
Training loss: 2.5982178962843485
Validation loss: 2.6767630091974826

Epoch: 6| Step: 3
Training loss: 2.8652936205105197
Validation loss: 2.6809228294139102

Epoch: 6| Step: 4
Training loss: 2.040924391464217
Validation loss: 2.7097850597261006

Epoch: 6| Step: 5
Training loss: 3.375301771447976
Validation loss: 2.716484199685792

Epoch: 6| Step: 6
Training loss: 2.700264712885261
Validation loss: 2.7286664298758443

Epoch: 6| Step: 7
Training loss: 2.551340225919463
Validation loss: 2.722433969796475

Epoch: 6| Step: 8
Training loss: 3.2698354636511278
Validation loss: 2.729336418077293

Epoch: 6| Step: 9
Training loss: 2.7330783058223624
Validation loss: 2.6886169047243014

Epoch: 6| Step: 10
Training loss: 3.2818434405693706
Validation loss: 2.6516835792040157

Epoch: 6| Step: 11
Training loss: 3.391629118715438
Validation loss: 2.6480287171126036

Epoch: 6| Step: 12
Training loss: 3.79509539558421
Validation loss: 2.6529132923155325

Epoch: 6| Step: 13
Training loss: 2.5237847907061735
Validation loss: 2.6573049314372055

Epoch: 106| Step: 0
Training loss: 2.8381456758022825
Validation loss: 2.6699264109484813

Epoch: 6| Step: 1
Training loss: 2.9680735570321723
Validation loss: 2.6799793790606454

Epoch: 6| Step: 2
Training loss: 2.950364209984526
Validation loss: 2.693332489261883

Epoch: 6| Step: 3
Training loss: 3.027983645829617
Validation loss: 2.6920889909392725

Epoch: 6| Step: 4
Training loss: 3.1027659044196993
Validation loss: 2.6890575353237414

Epoch: 6| Step: 5
Training loss: 2.6225943668576983
Validation loss: 2.696856703650013

Epoch: 6| Step: 6
Training loss: 2.5071622296595204
Validation loss: 2.692437290136216

Epoch: 6| Step: 7
Training loss: 2.9446428180143673
Validation loss: 2.679624281879298

Epoch: 6| Step: 8
Training loss: 3.39104490712432
Validation loss: 2.6699791868723732

Epoch: 6| Step: 9
Training loss: 3.0454876210811777
Validation loss: 2.660220300822693

Epoch: 6| Step: 10
Training loss: 3.530660664490883
Validation loss: 2.652229322682727

Epoch: 6| Step: 11
Training loss: 2.907858126783019
Validation loss: 2.649119356727619

Epoch: 6| Step: 12
Training loss: 3.688921508938471
Validation loss: 2.6433301654899055

Epoch: 6| Step: 13
Training loss: 2.1623168955994005
Validation loss: 2.640909033436848

Epoch: 107| Step: 0
Training loss: 3.228940664606855
Validation loss: 2.6359130279752816

Epoch: 6| Step: 1
Training loss: 2.9088567712693036
Validation loss: 2.6364470155521578

Epoch: 6| Step: 2
Training loss: 2.8350573138005832
Validation loss: 2.6409930328107514

Epoch: 6| Step: 3
Training loss: 2.7338668787093767
Validation loss: 2.647669963213963

Epoch: 6| Step: 4
Training loss: 2.9143591517590783
Validation loss: 2.660022031526433

Epoch: 6| Step: 5
Training loss: 2.7692517999111304
Validation loss: 2.6920763616829695

Epoch: 6| Step: 6
Training loss: 2.83166888845565
Validation loss: 2.7039877193941693

Epoch: 6| Step: 7
Training loss: 3.3813897856694064
Validation loss: 2.719110841417674

Epoch: 6| Step: 8
Training loss: 3.2599044413690885
Validation loss: 2.6613192545529123

Epoch: 6| Step: 9
Training loss: 2.9771801565525577
Validation loss: 2.6375940642121543

Epoch: 6| Step: 10
Training loss: 3.3013708908438524
Validation loss: 2.6355114719184

Epoch: 6| Step: 11
Training loss: 2.778871011711671
Validation loss: 2.6397576064914183

Epoch: 6| Step: 12
Training loss: 2.961293060775457
Validation loss: 2.6415724554860427

Epoch: 6| Step: 13
Training loss: 2.8823531283622397
Validation loss: 2.6484763632364174

Epoch: 108| Step: 0
Training loss: 3.379281330789443
Validation loss: 2.6550086646640323

Epoch: 6| Step: 1
Training loss: 3.1773659668992904
Validation loss: 2.662434647727823

Epoch: 6| Step: 2
Training loss: 2.9386445108721975
Validation loss: 2.6757888878866836

Epoch: 6| Step: 3
Training loss: 2.5422356599209546
Validation loss: 2.686986658129572

Epoch: 6| Step: 4
Training loss: 2.8299876449369186
Validation loss: 2.674197249151014

Epoch: 6| Step: 5
Training loss: 2.8745493328315526
Validation loss: 2.6623292165208747

Epoch: 6| Step: 6
Training loss: 2.839559128887397
Validation loss: 2.654863879704576

Epoch: 6| Step: 7
Training loss: 3.1021306745009447
Validation loss: 2.6528109887513596

Epoch: 6| Step: 8
Training loss: 3.2131788315833516
Validation loss: 2.6471516928519874

Epoch: 6| Step: 9
Training loss: 3.0622721996052373
Validation loss: 2.648228139416014

Epoch: 6| Step: 10
Training loss: 2.7088630940655043
Validation loss: 2.64759366057616

Epoch: 6| Step: 11
Training loss: 2.9541064049547088
Validation loss: 2.6406627879746236

Epoch: 6| Step: 12
Training loss: 2.992882869387482
Validation loss: 2.6400993043787206

Epoch: 6| Step: 13
Training loss: 3.7438563565795593
Validation loss: 2.637851739106093

Epoch: 109| Step: 0
Training loss: 2.7066291631565202
Validation loss: 2.635436732134603

Epoch: 6| Step: 1
Training loss: 3.0978354249489044
Validation loss: 2.6336350510605393

Epoch: 6| Step: 2
Training loss: 3.015446949184271
Validation loss: 2.6358752341540956

Epoch: 6| Step: 3
Training loss: 2.9608122061839866
Validation loss: 2.6343342827611687

Epoch: 6| Step: 4
Training loss: 3.3198030686858457
Validation loss: 2.63492273632926

Epoch: 6| Step: 5
Training loss: 2.898701699443804
Validation loss: 2.634882593195931

Epoch: 6| Step: 6
Training loss: 3.429415959272994
Validation loss: 2.6395754659500033

Epoch: 6| Step: 7
Training loss: 3.291205715949288
Validation loss: 2.643843451847076

Epoch: 6| Step: 8
Training loss: 2.6528994802504733
Validation loss: 2.6440238304060246

Epoch: 6| Step: 9
Training loss: 2.83705894638638
Validation loss: 2.662077076377831

Epoch: 6| Step: 10
Training loss: 3.0273372920798054
Validation loss: 2.6655747487941768

Epoch: 6| Step: 11
Training loss: 2.282385452086959
Validation loss: 2.668718718127136

Epoch: 6| Step: 12
Training loss: 3.20192312627005
Validation loss: 2.7022451874876987

Epoch: 6| Step: 13
Training loss: 2.932969678387143
Validation loss: 2.67953408304755

Epoch: 110| Step: 0
Training loss: 3.270138628293057
Validation loss: 2.660461440077271

Epoch: 6| Step: 1
Training loss: 3.383653073791593
Validation loss: 2.6434586513493112

Epoch: 6| Step: 2
Training loss: 3.2281657154510475
Validation loss: 2.635117151245215

Epoch: 6| Step: 3
Training loss: 2.8810099934143443
Validation loss: 2.6297780123011503

Epoch: 6| Step: 4
Training loss: 2.605076613077562
Validation loss: 2.625355185227012

Epoch: 6| Step: 5
Training loss: 2.8692233889739156
Validation loss: 2.6238816726439653

Epoch: 6| Step: 6
Training loss: 3.624423014004883
Validation loss: 2.619820070713135

Epoch: 6| Step: 7
Training loss: 3.276203743827501
Validation loss: 2.623129737520153

Epoch: 6| Step: 8
Training loss: 3.05229823339975
Validation loss: 2.621833162576378

Epoch: 6| Step: 9
Training loss: 2.172498325395542
Validation loss: 2.6224354210634417

Epoch: 6| Step: 10
Training loss: 2.545992833045767
Validation loss: 2.6225351861010946

Epoch: 6| Step: 11
Training loss: 2.3018122955076072
Validation loss: 2.6185351736098776

Epoch: 6| Step: 12
Training loss: 2.9135741778348625
Validation loss: 2.620520500853076

Epoch: 6| Step: 13
Training loss: 3.2622457295568963
Validation loss: 2.6190102726700504

Epoch: 111| Step: 0
Training loss: 2.280672183083192
Validation loss: 2.6179151424392755

Epoch: 6| Step: 1
Training loss: 3.07233981305452
Validation loss: 2.6166893543895084

Epoch: 6| Step: 2
Training loss: 2.1548623305244314
Validation loss: 2.6152398998063036

Epoch: 6| Step: 3
Training loss: 2.570501442315781
Validation loss: 2.617447754836585

Epoch: 6| Step: 4
Training loss: 3.0302251282706587
Validation loss: 2.613697921982602

Epoch: 6| Step: 5
Training loss: 3.3995567145000742
Validation loss: 2.6140166801387874

Epoch: 6| Step: 6
Training loss: 2.788824504026349
Validation loss: 2.6146298508836

Epoch: 6| Step: 7
Training loss: 3.038535575001839
Validation loss: 2.61320807781281

Epoch: 6| Step: 8
Training loss: 2.726268850870912
Validation loss: 2.6146672850676898

Epoch: 6| Step: 9
Training loss: 2.987478829153216
Validation loss: 2.61347739154366

Epoch: 6| Step: 10
Training loss: 3.324381123935361
Validation loss: 2.61202433199081

Epoch: 6| Step: 11
Training loss: 3.2265834853849946
Validation loss: 2.6144696158510112

Epoch: 6| Step: 12
Training loss: 3.254203132558584
Validation loss: 2.617950211751501

Epoch: 6| Step: 13
Training loss: 3.674251355580728
Validation loss: 2.618155678790752

Epoch: 112| Step: 0
Training loss: 2.9147395352290983
Validation loss: 2.6184154487010702

Epoch: 6| Step: 1
Training loss: 2.8704079152685984
Validation loss: 2.6270645439409783

Epoch: 6| Step: 2
Training loss: 3.125677569366226
Validation loss: 2.6410003694332906

Epoch: 6| Step: 3
Training loss: 3.651847209938933
Validation loss: 2.627077695539572

Epoch: 6| Step: 4
Training loss: 2.7122996313389
Validation loss: 2.610781369159278

Epoch: 6| Step: 5
Training loss: 3.157833495299143
Validation loss: 2.611165598087951

Epoch: 6| Step: 6
Training loss: 2.9622339314277584
Validation loss: 2.618632677188146

Epoch: 6| Step: 7
Training loss: 2.276015036374053
Validation loss: 2.620106933376039

Epoch: 6| Step: 8
Training loss: 2.6829257450186152
Validation loss: 2.6189919483736213

Epoch: 6| Step: 9
Training loss: 3.308779372375649
Validation loss: 2.634249216104585

Epoch: 6| Step: 10
Training loss: 2.906251968875341
Validation loss: 2.6241235515063464

Epoch: 6| Step: 11
Training loss: 3.46201102870196
Validation loss: 2.6157615140344403

Epoch: 6| Step: 12
Training loss: 2.7432106478555927
Validation loss: 2.615986925331471

Epoch: 6| Step: 13
Training loss: 2.4303485915457115
Validation loss: 2.6130847915616204

Epoch: 113| Step: 0
Training loss: 2.910927402808491
Validation loss: 2.6146700127740283

Epoch: 6| Step: 1
Training loss: 3.1229384679629244
Validation loss: 2.613981260889356

Epoch: 6| Step: 2
Training loss: 3.1231146656573068
Validation loss: 2.6129277701765163

Epoch: 6| Step: 3
Training loss: 2.994561511055275
Validation loss: 2.6130856892480585

Epoch: 6| Step: 4
Training loss: 3.099198293077494
Validation loss: 2.6127746553057642

Epoch: 6| Step: 5
Training loss: 2.2770271408346576
Validation loss: 2.613095094334476

Epoch: 6| Step: 6
Training loss: 2.931354994205032
Validation loss: 2.6128164165807006

Epoch: 6| Step: 7
Training loss: 2.3611982765813138
Validation loss: 2.6165116053401936

Epoch: 6| Step: 8
Training loss: 3.3373523007975456
Validation loss: 2.624318898326778

Epoch: 6| Step: 9
Training loss: 2.692970386102908
Validation loss: 2.617932051405949

Epoch: 6| Step: 10
Training loss: 3.202738222170363
Validation loss: 2.613591146639346

Epoch: 6| Step: 11
Training loss: 3.129139714097438
Validation loss: 2.6107404424019447

Epoch: 6| Step: 12
Training loss: 2.9101613294313893
Validation loss: 2.6107046507251743

Epoch: 6| Step: 13
Training loss: 3.448335528021941
Validation loss: 2.6099620726300232

Epoch: 114| Step: 0
Training loss: 2.8675879424893242
Validation loss: 2.609292638966226

Epoch: 6| Step: 1
Training loss: 3.434026870924561
Validation loss: 2.607432378600514

Epoch: 6| Step: 2
Training loss: 3.1029928834263747
Validation loss: 2.6080806902585585

Epoch: 6| Step: 3
Training loss: 3.2021444168833404
Validation loss: 2.6084680354660983

Epoch: 6| Step: 4
Training loss: 2.5746581841415837
Validation loss: 2.6083945788638214

Epoch: 6| Step: 5
Training loss: 2.7597817800471516
Validation loss: 2.6062376828494154

Epoch: 6| Step: 6
Training loss: 2.5437852336870956
Validation loss: 2.6074135708036232

Epoch: 6| Step: 7
Training loss: 3.153167730368913
Validation loss: 2.605501165408374

Epoch: 6| Step: 8
Training loss: 2.8147088595808416
Validation loss: 2.6068623651194534

Epoch: 6| Step: 9
Training loss: 3.963789475556284
Validation loss: 2.606552522195999

Epoch: 6| Step: 10
Training loss: 2.559588942010609
Validation loss: 2.612795470287148

Epoch: 6| Step: 11
Training loss: 2.962251477339904
Validation loss: 2.6124825687163504

Epoch: 6| Step: 12
Training loss: 2.4418472257996626
Validation loss: 2.615444197693161

Epoch: 6| Step: 13
Training loss: 2.513829603485508
Validation loss: 2.623987508503151

Epoch: 115| Step: 0
Training loss: 2.796932965748836
Validation loss: 2.6369137227700654

Epoch: 6| Step: 1
Training loss: 3.2566220237564005
Validation loss: 2.641549400236287

Epoch: 6| Step: 2
Training loss: 2.8451387137602113
Validation loss: 2.642911467328618

Epoch: 6| Step: 3
Training loss: 2.489118067042716
Validation loss: 2.68900158393374

Epoch: 6| Step: 4
Training loss: 2.3444766126276892
Validation loss: 2.723005286462741

Epoch: 6| Step: 5
Training loss: 2.8744312221323094
Validation loss: 2.658232888953553

Epoch: 6| Step: 6
Training loss: 3.0824622564797237
Validation loss: 2.6261215333773227

Epoch: 6| Step: 7
Training loss: 3.2511770611141504
Validation loss: 2.607869411023899

Epoch: 6| Step: 8
Training loss: 2.8370762580032256
Validation loss: 2.6018902380861406

Epoch: 6| Step: 9
Training loss: 3.159378012515178
Validation loss: 2.5987800495729987

Epoch: 6| Step: 10
Training loss: 3.249090947882171
Validation loss: 2.5997957779275938

Epoch: 6| Step: 11
Training loss: 3.1093102836583353
Validation loss: 2.600023953798383

Epoch: 6| Step: 12
Training loss: 2.987770425855164
Validation loss: 2.599765568790464

Epoch: 6| Step: 13
Training loss: 3.0616497494377803
Validation loss: 2.599878043413717

Epoch: 116| Step: 0
Training loss: 2.74669726320774
Validation loss: 2.60306134760343

Epoch: 6| Step: 1
Training loss: 3.783896536785676
Validation loss: 2.6086030353261638

Epoch: 6| Step: 2
Training loss: 2.7802989919685275
Validation loss: 2.61619231775104

Epoch: 6| Step: 3
Training loss: 3.1637232469070393
Validation loss: 2.6369906382448236

Epoch: 6| Step: 4
Training loss: 2.733042539464392
Validation loss: 2.6484357189119603

Epoch: 6| Step: 5
Training loss: 2.94649734747078
Validation loss: 2.6695209719519197

Epoch: 6| Step: 6
Training loss: 3.044123419506587
Validation loss: 2.687973629386792

Epoch: 6| Step: 7
Training loss: 3.2659463678688003
Validation loss: 2.7207701790305356

Epoch: 6| Step: 8
Training loss: 2.5994848254465825
Validation loss: 2.6675879821820585

Epoch: 6| Step: 9
Training loss: 2.887255710324979
Validation loss: 2.6351519604968843

Epoch: 6| Step: 10
Training loss: 2.9104075892931953
Validation loss: 2.628422257870159

Epoch: 6| Step: 11
Training loss: 3.2348501252680593
Validation loss: 2.6199761222612987

Epoch: 6| Step: 12
Training loss: 2.403759844477625
Validation loss: 2.6219855304240327

Epoch: 6| Step: 13
Training loss: 2.8340296357192973
Validation loss: 2.6237372209349066

Epoch: 117| Step: 0
Training loss: 2.672676724620584
Validation loss: 2.628226446426858

Epoch: 6| Step: 1
Training loss: 3.035153107905388
Validation loss: 2.6318815819085746

Epoch: 6| Step: 2
Training loss: 2.71697475309018
Validation loss: 2.6366144898772883

Epoch: 6| Step: 3
Training loss: 2.728568314826575
Validation loss: 2.634493096475993

Epoch: 6| Step: 4
Training loss: 2.647334766653008
Validation loss: 2.639206962507717

Epoch: 6| Step: 5
Training loss: 3.533297864867875
Validation loss: 2.6393081120115176

Epoch: 6| Step: 6
Training loss: 3.0678730754733574
Validation loss: 2.637108455588309

Epoch: 6| Step: 7
Training loss: 3.3907349740049617
Validation loss: 2.6376769537546756

Epoch: 6| Step: 8
Training loss: 2.729027363568335
Validation loss: 2.639111112993228

Epoch: 6| Step: 9
Training loss: 2.648351887357267
Validation loss: 2.636374039990596

Epoch: 6| Step: 10
Training loss: 3.1095722078440144
Validation loss: 2.639786132371726

Epoch: 6| Step: 11
Training loss: 3.2737480507896186
Validation loss: 2.6341618197132313

Epoch: 6| Step: 12
Training loss: 3.03588277204958
Validation loss: 2.6336693474458164

Epoch: 6| Step: 13
Training loss: 3.148249239534722
Validation loss: 2.6323065758672435

Epoch: 118| Step: 0
Training loss: 2.8353102649808988
Validation loss: 2.627708774862808

Epoch: 6| Step: 1
Training loss: 2.9659605071614665
Validation loss: 2.626995528440384

Epoch: 6| Step: 2
Training loss: 2.7033302361517246
Validation loss: 2.623768954835838

Epoch: 6| Step: 3
Training loss: 3.0579292286778874
Validation loss: 2.619501113477252

Epoch: 6| Step: 4
Training loss: 3.1659115510057294
Validation loss: 2.6179181683757764

Epoch: 6| Step: 5
Training loss: 2.7660504892062057
Validation loss: 2.618405496324492

Epoch: 6| Step: 6
Training loss: 2.6312396051559443
Validation loss: 2.6181369832770316

Epoch: 6| Step: 7
Training loss: 2.7936208537246485
Validation loss: 2.6284242680727865

Epoch: 6| Step: 8
Training loss: 2.91787364145955
Validation loss: 2.640324797303545

Epoch: 6| Step: 9
Training loss: 2.753421735414275
Validation loss: 2.6504084468710305

Epoch: 6| Step: 10
Training loss: 3.4449684161550254
Validation loss: 2.673939138155082

Epoch: 6| Step: 11
Training loss: 3.301711598038741
Validation loss: 2.697890475674133

Epoch: 6| Step: 12
Training loss: 3.396709836087164
Validation loss: 2.648546821665231

Epoch: 6| Step: 13
Training loss: 2.5162903279058924
Validation loss: 2.620146691365267

Epoch: 119| Step: 0
Training loss: 2.1233011074205743
Validation loss: 2.6080774514012752

Epoch: 6| Step: 1
Training loss: 2.878122541362363
Validation loss: 2.5981469344049457

Epoch: 6| Step: 2
Training loss: 2.7911810855925454
Validation loss: 2.5918178634003306

Epoch: 6| Step: 3
Training loss: 3.00692664638672
Validation loss: 2.5900183554023593

Epoch: 6| Step: 4
Training loss: 2.637431092288677
Validation loss: 2.58720595698501

Epoch: 6| Step: 5
Training loss: 2.906663106455358
Validation loss: 2.5819992046810434

Epoch: 6| Step: 6
Training loss: 3.275334429955475
Validation loss: 2.5829600131573898

Epoch: 6| Step: 7
Training loss: 2.653566418558506
Validation loss: 2.584760264525937

Epoch: 6| Step: 8
Training loss: 2.712261744991797
Validation loss: 2.5848689409310834

Epoch: 6| Step: 9
Training loss: 2.738827812729519
Validation loss: 2.5866781195964337

Epoch: 6| Step: 10
Training loss: 2.938812611901462
Validation loss: 2.5871388648270166

Epoch: 6| Step: 11
Training loss: 3.4867441650394317
Validation loss: 2.5915729624335677

Epoch: 6| Step: 12
Training loss: 3.7503012218294636
Validation loss: 2.5971977012356615

Epoch: 6| Step: 13
Training loss: 2.8398417350835357
Validation loss: 2.6003497474174515

Epoch: 120| Step: 0
Training loss: 2.2299404286865427
Validation loss: 2.6065643049416507

Epoch: 6| Step: 1
Training loss: 3.783261607382257
Validation loss: 2.6023858388026095

Epoch: 6| Step: 2
Training loss: 2.907536047780083
Validation loss: 2.593232219918748

Epoch: 6| Step: 3
Training loss: 3.104415542217995
Validation loss: 2.588866880520697

Epoch: 6| Step: 4
Training loss: 2.423803730487636
Validation loss: 2.6049524774689115

Epoch: 6| Step: 5
Training loss: 2.77742281129229
Validation loss: 2.6128384400320317

Epoch: 6| Step: 6
Training loss: 3.0028861785465915
Validation loss: 2.635212704361045

Epoch: 6| Step: 7
Training loss: 2.678515119414875
Validation loss: 2.637746312771925

Epoch: 6| Step: 8
Training loss: 3.198579568321353
Validation loss: 2.6212075618642188

Epoch: 6| Step: 9
Training loss: 2.4466245988387394
Validation loss: 2.5959630870715875

Epoch: 6| Step: 10
Training loss: 3.408269161251369
Validation loss: 2.582390277329907

Epoch: 6| Step: 11
Training loss: 2.7307884891364074
Validation loss: 2.5735175294809465

Epoch: 6| Step: 12
Training loss: 3.0580896812346956
Validation loss: 2.573331702677785

Epoch: 6| Step: 13
Training loss: 3.052555364533138
Validation loss: 2.574863004718933

Epoch: 121| Step: 0
Training loss: 3.320563237315726
Validation loss: 2.5779194172828905

Epoch: 6| Step: 1
Training loss: 2.5515251535367742
Validation loss: 2.578470396271283

Epoch: 6| Step: 2
Training loss: 2.170215988485023
Validation loss: 2.5807228421497084

Epoch: 6| Step: 3
Training loss: 2.715765531742547
Validation loss: 2.576489823132878

Epoch: 6| Step: 4
Training loss: 2.7321172493982075
Validation loss: 2.581096344199927

Epoch: 6| Step: 5
Training loss: 3.1343926228629706
Validation loss: 2.579780280410948

Epoch: 6| Step: 6
Training loss: 2.9024234314116746
Validation loss: 2.576882130835939

Epoch: 6| Step: 7
Training loss: 3.2872222318898756
Validation loss: 2.578681001344212

Epoch: 6| Step: 8
Training loss: 2.978928954415345
Validation loss: 2.5795352741636393

Epoch: 6| Step: 9
Training loss: 2.8254288947035775
Validation loss: 2.5793945080525513

Epoch: 6| Step: 10
Training loss: 3.1754872466347646
Validation loss: 2.5774275476769875

Epoch: 6| Step: 11
Training loss: 3.7294352912408515
Validation loss: 2.5748239832389785

Epoch: 6| Step: 12
Training loss: 2.675032595854768
Validation loss: 2.575079898090477

Epoch: 6| Step: 13
Training loss: 2.7130343987505414
Validation loss: 2.574154328009101

Epoch: 122| Step: 0
Training loss: 3.2502957722985575
Validation loss: 2.572424909661975

Epoch: 6| Step: 1
Training loss: 3.055515655102932
Validation loss: 2.573043798844858

Epoch: 6| Step: 2
Training loss: 2.9168074619279376
Validation loss: 2.574675740630382

Epoch: 6| Step: 3
Training loss: 2.7258442367138165
Validation loss: 2.583660409355815

Epoch: 6| Step: 4
Training loss: 2.833837651267312
Validation loss: 2.600680014998164

Epoch: 6| Step: 5
Training loss: 2.8124503237257885
Validation loss: 2.6163088566881316

Epoch: 6| Step: 6
Training loss: 3.1944611774688183
Validation loss: 2.6061672501799884

Epoch: 6| Step: 7
Training loss: 2.850035878005821
Validation loss: 2.6273395193623186

Epoch: 6| Step: 8
Training loss: 2.9028838978361513
Validation loss: 2.6082458371599686

Epoch: 6| Step: 9
Training loss: 3.0187049119950635
Validation loss: 2.609139982843438

Epoch: 6| Step: 10
Training loss: 2.663035175104068
Validation loss: 2.6078844844282325

Epoch: 6| Step: 11
Training loss: 2.644570377122383
Validation loss: 2.620363599250221

Epoch: 6| Step: 12
Training loss: 2.850257888637146
Validation loss: 2.6685857449609167

Epoch: 6| Step: 13
Training loss: 3.4113519938350376
Validation loss: 2.656175432600227

Epoch: 123| Step: 0
Training loss: 2.539904082281924
Validation loss: 2.664500403236786

Epoch: 6| Step: 1
Training loss: 3.3420168939662265
Validation loss: 2.646123404311438

Epoch: 6| Step: 2
Training loss: 3.010854792584865
Validation loss: 2.599214944647721

Epoch: 6| Step: 3
Training loss: 2.046061812912978
Validation loss: 2.572658853881547

Epoch: 6| Step: 4
Training loss: 2.9653995279475516
Validation loss: 2.569948143344698

Epoch: 6| Step: 5
Training loss: 3.316768702817657
Validation loss: 2.573498379189418

Epoch: 6| Step: 6
Training loss: 3.1423125786074824
Validation loss: 2.575045919481803

Epoch: 6| Step: 7
Training loss: 2.6988756593865344
Validation loss: 2.575034022382752

Epoch: 6| Step: 8
Training loss: 3.277749655938787
Validation loss: 2.573418779033176

Epoch: 6| Step: 9
Training loss: 2.8320260304370004
Validation loss: 2.568485164380999

Epoch: 6| Step: 10
Training loss: 3.2623259750080025
Validation loss: 2.5665302562249073

Epoch: 6| Step: 11
Training loss: 3.05694574655215
Validation loss: 2.5667953317395287

Epoch: 6| Step: 12
Training loss: 2.7547162968108942
Validation loss: 2.565161086873496

Epoch: 6| Step: 13
Training loss: 2.85087848977331
Validation loss: 2.563601609453291

Epoch: 124| Step: 0
Training loss: 3.3188700336365837
Validation loss: 2.564563537629483

Epoch: 6| Step: 1
Training loss: 2.313703584622788
Validation loss: 2.5619167841715598

Epoch: 6| Step: 2
Training loss: 2.7688178473914986
Validation loss: 2.5635922232932242

Epoch: 6| Step: 3
Training loss: 3.5485381541722516
Validation loss: 2.560734155166073

Epoch: 6| Step: 4
Training loss: 2.948704231298344
Validation loss: 2.5576416799296315

Epoch: 6| Step: 5
Training loss: 3.1399301547889764
Validation loss: 2.5659393002120887

Epoch: 6| Step: 6
Training loss: 3.108422521653084
Validation loss: 2.5700078816702208

Epoch: 6| Step: 7
Training loss: 2.7808870228709703
Validation loss: 2.5475575247035134

Epoch: 6| Step: 8
Training loss: 2.604611920757383
Validation loss: 2.5453152682292988

Epoch: 6| Step: 9
Training loss: 3.0058844393651234
Validation loss: 2.559443363798843

Epoch: 6| Step: 10
Training loss: 2.733477810398578
Validation loss: 2.5660598343027474

Epoch: 6| Step: 11
Training loss: 2.5398233535496773
Validation loss: 2.5765610421875946

Epoch: 6| Step: 12
Training loss: 2.88073026723409
Validation loss: 2.5825842979834377

Epoch: 6| Step: 13
Training loss: 2.7428996582369267
Validation loss: 2.575247942748078

Epoch: 125| Step: 0
Training loss: 2.5923537207363365
Validation loss: 2.6168602807584995

Epoch: 6| Step: 1
Training loss: 3.07865258357397
Validation loss: 2.5880125438462076

Epoch: 6| Step: 2
Training loss: 3.0136566853959397
Validation loss: 2.569159627122757

Epoch: 6| Step: 3
Training loss: 2.4982742074896636
Validation loss: 2.522781174457374

Epoch: 6| Step: 4
Training loss: 2.848431433306588
Validation loss: 2.5247879481044517

Epoch: 6| Step: 5
Training loss: 3.180519688684902
Validation loss: 2.529393375956887

Epoch: 6| Step: 6
Training loss: 3.0812801707804383
Validation loss: 2.531409131629454

Epoch: 6| Step: 7
Training loss: 2.204070409200527
Validation loss: 2.5323142332921624

Epoch: 6| Step: 8
Training loss: 2.4246866947983463
Validation loss: 2.5380532444025588

Epoch: 6| Step: 9
Training loss: 2.6883523166157324
Validation loss: 2.5390701240822646

Epoch: 6| Step: 10
Training loss: 3.5298291614030566
Validation loss: 2.5284205809789055

Epoch: 6| Step: 11
Training loss: 2.8923746948004627
Validation loss: 2.5255508576951433

Epoch: 6| Step: 12
Training loss: 3.3148924626878276
Validation loss: 2.525944601582633

Epoch: 6| Step: 13
Training loss: 3.3550954129200803
Validation loss: 2.5185639483509696

Epoch: 126| Step: 0
Training loss: 2.3370190416310357
Validation loss: 2.5182564654155204

Epoch: 6| Step: 1
Training loss: 3.4074243043704797
Validation loss: 2.516609235272726

Epoch: 6| Step: 2
Training loss: 2.4388055483984714
Validation loss: 2.515213432521872

Epoch: 6| Step: 3
Training loss: 2.704232931476256
Validation loss: 2.5150037490228665

Epoch: 6| Step: 4
Training loss: 3.029418549347605
Validation loss: 2.5166744488217745

Epoch: 6| Step: 5
Training loss: 2.5703860565142165
Validation loss: 2.530043575919705

Epoch: 6| Step: 6
Training loss: 3.2228113125573543
Validation loss: 2.528738214038736

Epoch: 6| Step: 7
Training loss: 2.8796066198307617
Validation loss: 2.5356657149985016

Epoch: 6| Step: 8
Training loss: 3.4318818391319463
Validation loss: 2.544618561372443

Epoch: 6| Step: 9
Training loss: 3.301663072158215
Validation loss: 2.5583705057923667

Epoch: 6| Step: 10
Training loss: 3.0559140447841275
Validation loss: 2.558521280308971

Epoch: 6| Step: 11
Training loss: 2.548236132161599
Validation loss: 2.5652660904472655

Epoch: 6| Step: 12
Training loss: 2.795881894216251
Validation loss: 2.5627369244663822

Epoch: 6| Step: 13
Training loss: 2.407444347875243
Validation loss: 2.557382479293023

Epoch: 127| Step: 0
Training loss: 2.544947263249946
Validation loss: 2.5601427434469186

Epoch: 6| Step: 1
Training loss: 2.8513247038049383
Validation loss: 2.5608954859956246

Epoch: 6| Step: 2
Training loss: 2.4739498954762906
Validation loss: 2.5524002628454454

Epoch: 6| Step: 3
Training loss: 2.7035831658489564
Validation loss: 2.5638724912658137

Epoch: 6| Step: 4
Training loss: 2.8588910136202794
Validation loss: 2.5617143057744434

Epoch: 6| Step: 5
Training loss: 3.0766850700392845
Validation loss: 2.5497108845300076

Epoch: 6| Step: 6
Training loss: 3.010058230980597
Validation loss: 2.549409832060263

Epoch: 6| Step: 7
Training loss: 2.980234839383631
Validation loss: 2.5416370953622067

Epoch: 6| Step: 8
Training loss: 3.1773905787922505
Validation loss: 2.519316738186618

Epoch: 6| Step: 9
Training loss: 3.205171852205877
Validation loss: 2.512071846001943

Epoch: 6| Step: 10
Training loss: 3.1793140688847332
Validation loss: 2.511886320356715

Epoch: 6| Step: 11
Training loss: 3.0433075193526915
Validation loss: 2.51143452069543

Epoch: 6| Step: 12
Training loss: 2.695966469859001
Validation loss: 2.520199512872737

Epoch: 6| Step: 13
Training loss: 2.1989921602158837
Validation loss: 2.518497865560563

Epoch: 128| Step: 0
Training loss: 3.1063358655762943
Validation loss: 2.5227379684736837

Epoch: 6| Step: 1
Training loss: 2.9058027025786655
Validation loss: 2.5255166319511857

Epoch: 6| Step: 2
Training loss: 3.1417856681270036
Validation loss: 2.5236861685722825

Epoch: 6| Step: 3
Training loss: 2.6938410626307063
Validation loss: 2.526044990749644

Epoch: 6| Step: 4
Training loss: 2.876249788061314
Validation loss: 2.5229987123601596

Epoch: 6| Step: 5
Training loss: 2.978396193814567
Validation loss: 2.5250543780803385

Epoch: 6| Step: 6
Training loss: 2.8887088507606458
Validation loss: 2.523955103835604

Epoch: 6| Step: 7
Training loss: 2.7060162731845767
Validation loss: 2.521919109878049

Epoch: 6| Step: 8
Training loss: 3.2409102164464376
Validation loss: 2.5185420858477006

Epoch: 6| Step: 9
Training loss: 3.066604977139284
Validation loss: 2.5229351712422785

Epoch: 6| Step: 10
Training loss: 3.142518796295545
Validation loss: 2.519969991335027

Epoch: 6| Step: 11
Training loss: 2.400801596289984
Validation loss: 2.533302890552037

Epoch: 6| Step: 12
Training loss: 2.8560822084920874
Validation loss: 2.546178635354037

Epoch: 6| Step: 13
Training loss: 2.133870403912993
Validation loss: 2.5364950072582686

Epoch: 129| Step: 0
Training loss: 3.069481812523428
Validation loss: 2.550183456733587

Epoch: 6| Step: 1
Training loss: 2.440327691446004
Validation loss: 2.5312141173855385

Epoch: 6| Step: 2
Training loss: 2.421790435299079
Validation loss: 2.540198574044202

Epoch: 6| Step: 3
Training loss: 2.9514559111122187
Validation loss: 2.538843027478553

Epoch: 6| Step: 4
Training loss: 3.1968624767308014
Validation loss: 2.5442010363596324

Epoch: 6| Step: 5
Training loss: 3.2341626968365977
Validation loss: 2.542512482288324

Epoch: 6| Step: 6
Training loss: 2.806245418961148
Validation loss: 2.5258475172057535

Epoch: 6| Step: 7
Training loss: 2.9639334707374116
Validation loss: 2.5091396537669337

Epoch: 6| Step: 8
Training loss: 2.446452304776678
Validation loss: 2.5126857127125937

Epoch: 6| Step: 9
Training loss: 2.7478077560100993
Validation loss: 2.521810396333239

Epoch: 6| Step: 10
Training loss: 2.60666099619269
Validation loss: 2.5260750148759414

Epoch: 6| Step: 11
Training loss: 3.518520129539909
Validation loss: 2.536196881155065

Epoch: 6| Step: 12
Training loss: 3.272573862429784
Validation loss: 2.553948289844563

Epoch: 6| Step: 13
Training loss: 2.9186239668695504
Validation loss: 2.566066734781771

Epoch: 130| Step: 0
Training loss: 2.2832751756301572
Validation loss: 2.567720607162548

Epoch: 6| Step: 1
Training loss: 2.800195012794676
Validation loss: 2.560058277808532

Epoch: 6| Step: 2
Training loss: 2.9304759681183596
Validation loss: 2.5596990847190693

Epoch: 6| Step: 3
Training loss: 2.967927035655872
Validation loss: 2.5582806244457794

Epoch: 6| Step: 4
Training loss: 2.732984178231395
Validation loss: 2.559594865365303

Epoch: 6| Step: 5
Training loss: 3.285110382594484
Validation loss: 2.5567988471423693

Epoch: 6| Step: 6
Training loss: 3.0379974146336597
Validation loss: 2.547998496231805

Epoch: 6| Step: 7
Training loss: 2.6999727071159705
Validation loss: 2.5504085474081575

Epoch: 6| Step: 8
Training loss: 3.2399329746048204
Validation loss: 2.5481657190938405

Epoch: 6| Step: 9
Training loss: 3.162336165817095
Validation loss: 2.553343833318713

Epoch: 6| Step: 10
Training loss: 3.0249005703308964
Validation loss: 2.55599738393529

Epoch: 6| Step: 11
Training loss: 3.087639525191439
Validation loss: 2.563089038409072

Epoch: 6| Step: 12
Training loss: 3.1093489295978363
Validation loss: 2.5645384425408055

Epoch: 6| Step: 13
Training loss: 2.4206990986658665
Validation loss: 2.5837964087133622

Epoch: 131| Step: 0
Training loss: 3.3259948217428503
Validation loss: 2.5913786541692456

Epoch: 6| Step: 1
Training loss: 3.4725760589025665
Validation loss: 2.6380789828849327

Epoch: 6| Step: 2
Training loss: 2.4453190325079976
Validation loss: 2.624615296800355

Epoch: 6| Step: 3
Training loss: 2.6751809887844797
Validation loss: 2.5882249824421497

Epoch: 6| Step: 4
Training loss: 3.0912547211508787
Validation loss: 2.581775758073919

Epoch: 6| Step: 5
Training loss: 3.3456934334725363
Validation loss: 2.5594153628018264

Epoch: 6| Step: 6
Training loss: 2.433081902181801
Validation loss: 2.56031195674108

Epoch: 6| Step: 7
Training loss: 3.0279069536594965
Validation loss: 2.5523028549063524

Epoch: 6| Step: 8
Training loss: 3.251539892569924
Validation loss: 2.552126911754776

Epoch: 6| Step: 9
Training loss: 2.9529375289266877
Validation loss: 2.543555839767679

Epoch: 6| Step: 10
Training loss: 2.7780492988974284
Validation loss: 2.5354774031890206

Epoch: 6| Step: 11
Training loss: 2.7879279898616556
Validation loss: 2.5397611862358493

Epoch: 6| Step: 12
Training loss: 2.0720023689992906
Validation loss: 2.5361910163658306

Epoch: 6| Step: 13
Training loss: 2.62270463768733
Validation loss: 2.5375329677901863

Epoch: 132| Step: 0
Training loss: 3.492760801087134
Validation loss: 2.546285030849276

Epoch: 6| Step: 1
Training loss: 2.922544678019402
Validation loss: 2.55121254411952

Epoch: 6| Step: 2
Training loss: 3.4414787154952076
Validation loss: 2.5618188144224705

Epoch: 6| Step: 3
Training loss: 3.060403846071594
Validation loss: 2.581926380152757

Epoch: 6| Step: 4
Training loss: 2.804500137913987
Validation loss: 2.5798121664709104

Epoch: 6| Step: 5
Training loss: 2.659356129957013
Validation loss: 2.5945748733488534

Epoch: 6| Step: 6
Training loss: 2.3279295973734144
Validation loss: 2.607859725110186

Epoch: 6| Step: 7
Training loss: 2.7655312042710483
Validation loss: 2.6131167038798364

Epoch: 6| Step: 8
Training loss: 2.93256710694418
Validation loss: 2.6110107303597982

Epoch: 6| Step: 9
Training loss: 2.720093230865595
Validation loss: 2.5663333376198603

Epoch: 6| Step: 10
Training loss: 2.5685591355300432
Validation loss: 2.5838845680738376

Epoch: 6| Step: 11
Training loss: 2.536509759422099
Validation loss: 2.572984031368958

Epoch: 6| Step: 12
Training loss: 2.4484795971472755
Validation loss: 2.550454794693798

Epoch: 6| Step: 13
Training loss: 3.6224887963036827
Validation loss: 2.5182237240861807

Epoch: 133| Step: 0
Training loss: 3.3821631814941875
Validation loss: 2.5159845193994146

Epoch: 6| Step: 1
Training loss: 2.6451920059980885
Validation loss: 2.515515875839599

Epoch: 6| Step: 2
Training loss: 3.2109970495637534
Validation loss: 2.5094947665910903

Epoch: 6| Step: 3
Training loss: 3.026614705562592
Validation loss: 2.5115193752742937

Epoch: 6| Step: 4
Training loss: 2.7830048928856885
Validation loss: 2.5049880646858145

Epoch: 6| Step: 5
Training loss: 2.9207929759881206
Validation loss: 2.506402649157506

Epoch: 6| Step: 6
Training loss: 2.796438001878828
Validation loss: 2.502775811358602

Epoch: 6| Step: 7
Training loss: 2.780174133006576
Validation loss: 2.517179721685236

Epoch: 6| Step: 8
Training loss: 2.2617181175112457
Validation loss: 2.5119288465144067

Epoch: 6| Step: 9
Training loss: 2.6748052223096397
Validation loss: 2.5239630051367237

Epoch: 6| Step: 10
Training loss: 2.7684592686378706
Validation loss: 2.5226933339450404

Epoch: 6| Step: 11
Training loss: 3.1118624911389197
Validation loss: 2.5316509221509613

Epoch: 6| Step: 12
Training loss: 3.2803564399014222
Validation loss: 2.552654473838698

Epoch: 6| Step: 13
Training loss: 2.052675023114667
Validation loss: 2.5165555875136953

Epoch: 134| Step: 0
Training loss: 3.1093684057424578
Validation loss: 2.5061946241776827

Epoch: 6| Step: 1
Training loss: 2.64315259600197
Validation loss: 2.5062101091171503

Epoch: 6| Step: 2
Training loss: 2.96156517763692
Validation loss: 2.502618140661949

Epoch: 6| Step: 3
Training loss: 2.873304115672007
Validation loss: 2.500258678979012

Epoch: 6| Step: 4
Training loss: 2.904276352010121
Validation loss: 2.5047832322177834

Epoch: 6| Step: 5
Training loss: 2.3725046802148992
Validation loss: 2.5044317444830857

Epoch: 6| Step: 6
Training loss: 3.2805390087216066
Validation loss: 2.5051825959120473

Epoch: 6| Step: 7
Training loss: 2.5288721854785505
Validation loss: 2.5017094141319007

Epoch: 6| Step: 8
Training loss: 3.521746515132187
Validation loss: 2.5031527912311127

Epoch: 6| Step: 9
Training loss: 2.2234012045883533
Validation loss: 2.5022652279684077

Epoch: 6| Step: 10
Training loss: 3.4078740439264443
Validation loss: 2.50109465434537

Epoch: 6| Step: 11
Training loss: 2.995024051219424
Validation loss: 2.5011649201810577

Epoch: 6| Step: 12
Training loss: 2.359368330586083
Validation loss: 2.5074442246541158

Epoch: 6| Step: 13
Training loss: 2.583083499599996
Validation loss: 2.516592144679406

Epoch: 135| Step: 0
Training loss: 2.745604035948519
Validation loss: 2.5386053827719177

Epoch: 6| Step: 1
Training loss: 3.1993946218065883
Validation loss: 2.581589139416715

Epoch: 6| Step: 2
Training loss: 3.2731946613852347
Validation loss: 2.579538172691055

Epoch: 6| Step: 3
Training loss: 2.7739114705586014
Validation loss: 2.563721554473269

Epoch: 6| Step: 4
Training loss: 3.2458280048318464
Validation loss: 2.544888872817789

Epoch: 6| Step: 5
Training loss: 2.7599915279037255
Validation loss: 2.520698249497293

Epoch: 6| Step: 6
Training loss: 2.7873537615404826
Validation loss: 2.5085732948625417

Epoch: 6| Step: 7
Training loss: 1.906540145055181
Validation loss: 2.5083100303892305

Epoch: 6| Step: 8
Training loss: 3.271745267115933
Validation loss: 2.5058215767970298

Epoch: 6| Step: 9
Training loss: 3.037142659584493
Validation loss: 2.5162541800011478

Epoch: 6| Step: 10
Training loss: 2.8582838300713016
Validation loss: 2.512482139406783

Epoch: 6| Step: 11
Training loss: 3.0488276557995313
Validation loss: 2.5107357511842605

Epoch: 6| Step: 12
Training loss: 2.1106570268572704
Validation loss: 2.523265230676192

Epoch: 6| Step: 13
Training loss: 2.859825223904303
Validation loss: 2.565953300620522

Epoch: 136| Step: 0
Training loss: 3.110482483508371
Validation loss: 2.618486442855099

Epoch: 6| Step: 1
Training loss: 2.8078549491717655
Validation loss: 2.624696509908712

Epoch: 6| Step: 2
Training loss: 1.920381229123605
Validation loss: 2.61412803850631

Epoch: 6| Step: 3
Training loss: 2.9655436015238528
Validation loss: 2.610335322352876

Epoch: 6| Step: 4
Training loss: 3.253761169203391
Validation loss: 2.5566387719395562

Epoch: 6| Step: 5
Training loss: 2.8495009403632174
Validation loss: 2.5130351044134174

Epoch: 6| Step: 6
Training loss: 2.704893647110991
Validation loss: 2.4999516113274405

Epoch: 6| Step: 7
Training loss: 2.907541623789311
Validation loss: 2.5041786516519857

Epoch: 6| Step: 8
Training loss: 3.398949314907844
Validation loss: 2.516629172963115

Epoch: 6| Step: 9
Training loss: 3.0094359141173284
Validation loss: 2.5221841088618886

Epoch: 6| Step: 10
Training loss: 3.000693558948797
Validation loss: 2.525498105374776

Epoch: 6| Step: 11
Training loss: 2.9428751040213466
Validation loss: 2.522733169908496

Epoch: 6| Step: 12
Training loss: 2.800851052237746
Validation loss: 2.5292856019561074

Epoch: 6| Step: 13
Training loss: 2.924190807081628
Validation loss: 2.517942316789612

Epoch: 137| Step: 0
Training loss: 2.9073277597750806
Validation loss: 2.512454667037227

Epoch: 6| Step: 1
Training loss: 2.309544298215014
Validation loss: 2.512102869873415

Epoch: 6| Step: 2
Training loss: 2.7058446355908106
Validation loss: 2.5073738347013386

Epoch: 6| Step: 3
Training loss: 2.964210492885141
Validation loss: 2.5053018555858277

Epoch: 6| Step: 4
Training loss: 2.62437267981997
Validation loss: 2.499299308555246

Epoch: 6| Step: 5
Training loss: 3.279654705434315
Validation loss: 2.499251893100809

Epoch: 6| Step: 6
Training loss: 3.3733348270709484
Validation loss: 2.5057408672439863

Epoch: 6| Step: 7
Training loss: 3.0104007038542417
Validation loss: 2.53910836228063

Epoch: 6| Step: 8
Training loss: 2.476727501219181
Validation loss: 2.585117983628815

Epoch: 6| Step: 9
Training loss: 2.7656134481242676
Validation loss: 2.6593293332910934

Epoch: 6| Step: 10
Training loss: 3.7493617468318465
Validation loss: 2.668923453300195

Epoch: 6| Step: 11
Training loss: 2.8045132298639515
Validation loss: 2.630073122983818

Epoch: 6| Step: 12
Training loss: 2.6364517189725643
Validation loss: 2.5973834239694757

Epoch: 6| Step: 13
Training loss: 2.8512166688836404
Validation loss: 2.567858866398123

Epoch: 138| Step: 0
Training loss: 3.0253455476992044
Validation loss: 2.536315401171319

Epoch: 6| Step: 1
Training loss: 1.9200114076990742
Validation loss: 2.515223451765936

Epoch: 6| Step: 2
Training loss: 2.9928463840388786
Validation loss: 2.5119431163141273

Epoch: 6| Step: 3
Training loss: 3.1865192475263595
Validation loss: 2.5054696627511874

Epoch: 6| Step: 4
Training loss: 2.680257041618036
Validation loss: 2.5016405885521316

Epoch: 6| Step: 5
Training loss: 3.0615908771978044
Validation loss: 2.507222807506927

Epoch: 6| Step: 6
Training loss: 2.5276955974294375
Validation loss: 2.507677651879993

Epoch: 6| Step: 7
Training loss: 2.514998648246872
Validation loss: 2.508226083197308

Epoch: 6| Step: 8
Training loss: 2.6251118954015857
Validation loss: 2.5097021605055594

Epoch: 6| Step: 9
Training loss: 3.3146237457004863
Validation loss: 2.51481875161347

Epoch: 6| Step: 10
Training loss: 3.0635489399622697
Validation loss: 2.5109203719863387

Epoch: 6| Step: 11
Training loss: 2.8414464990189607
Validation loss: 2.5164761248326397

Epoch: 6| Step: 12
Training loss: 3.04560676981016
Validation loss: 2.5336690368259944

Epoch: 6| Step: 13
Training loss: 3.180944995460932
Validation loss: 2.567516114451882

Epoch: 139| Step: 0
Training loss: 3.1503639858607135
Validation loss: 2.591736122519301

Epoch: 6| Step: 1
Training loss: 2.699235002438408
Validation loss: 2.6001383359296604

Epoch: 6| Step: 2
Training loss: 2.693399651705512
Validation loss: 2.602707597754555

Epoch: 6| Step: 3
Training loss: 2.762921407326666
Validation loss: 2.580374233319079

Epoch: 6| Step: 4
Training loss: 3.0631151165478783
Validation loss: 2.5464344671636203

Epoch: 6| Step: 5
Training loss: 3.4024471788419537
Validation loss: 2.5440722283974404

Epoch: 6| Step: 6
Training loss: 3.598000177600765
Validation loss: 2.521633929904201

Epoch: 6| Step: 7
Training loss: 2.778083627605147
Validation loss: 2.518882387717154

Epoch: 6| Step: 8
Training loss: 3.0541186181036366
Validation loss: 2.515264490499249

Epoch: 6| Step: 9
Training loss: 2.878800575252686
Validation loss: 2.5117235777732336

Epoch: 6| Step: 10
Training loss: 2.8725140646116256
Validation loss: 2.508546894646467

Epoch: 6| Step: 11
Training loss: 2.608891425181161
Validation loss: 2.513458194171682

Epoch: 6| Step: 12
Training loss: 2.306182066374336
Validation loss: 2.516973874854533

Epoch: 6| Step: 13
Training loss: 2.210211644804982
Validation loss: 2.5161996708723193

Epoch: 140| Step: 0
Training loss: 3.060167631157831
Validation loss: 2.5139053327721017

Epoch: 6| Step: 1
Training loss: 2.78673612451765
Validation loss: 2.5201355888778907

Epoch: 6| Step: 2
Training loss: 3.21212026526261
Validation loss: 2.5198240338497744

Epoch: 6| Step: 3
Training loss: 2.8649061726223577
Validation loss: 2.5100442425181555

Epoch: 6| Step: 4
Training loss: 3.0636378140339326
Validation loss: 2.5036774967032924

Epoch: 6| Step: 5
Training loss: 2.997035787364273
Validation loss: 2.4924733759212376

Epoch: 6| Step: 6
Training loss: 2.5817570850980265
Validation loss: 2.4882477278829147

Epoch: 6| Step: 7
Training loss: 2.5134907074015307
Validation loss: 2.4853228335061166

Epoch: 6| Step: 8
Training loss: 2.4919015367566955
Validation loss: 2.4841996018344923

Epoch: 6| Step: 9
Training loss: 2.857078755885806
Validation loss: 2.482638238486601

Epoch: 6| Step: 10
Training loss: 2.998521122404975
Validation loss: 2.4885789466439427

Epoch: 6| Step: 11
Training loss: 2.4944868332910484
Validation loss: 2.5003053171087184

Epoch: 6| Step: 12
Training loss: 3.3839236366187104
Validation loss: 2.5234629164560927

Epoch: 6| Step: 13
Training loss: 2.802845129290347
Validation loss: 2.560830334403349

Epoch: 141| Step: 0
Training loss: 2.426752900208811
Validation loss: 2.660573380970831

Epoch: 6| Step: 1
Training loss: 2.5531846038323076
Validation loss: 2.7854672137984378

Epoch: 6| Step: 2
Training loss: 2.579177549110178
Validation loss: 2.7771680871056743

Epoch: 6| Step: 3
Training loss: 3.1194526263120546
Validation loss: 2.712640426824357

Epoch: 6| Step: 4
Training loss: 3.051399822752813
Validation loss: 2.669580181853538

Epoch: 6| Step: 5
Training loss: 2.654666742936342
Validation loss: 2.5814506800562986

Epoch: 6| Step: 6
Training loss: 3.0492519399335434
Validation loss: 2.5294066238997774

Epoch: 6| Step: 7
Training loss: 3.4139091404879007
Validation loss: 2.5042762147074042

Epoch: 6| Step: 8
Training loss: 2.879135805913226
Validation loss: 2.5033991050521136

Epoch: 6| Step: 9
Training loss: 2.692090394609554
Validation loss: 2.512864117478191

Epoch: 6| Step: 10
Training loss: 3.1697843830895374
Validation loss: 2.5184938824189147

Epoch: 6| Step: 11
Training loss: 2.8268416216826067
Validation loss: 2.5188300483979282

Epoch: 6| Step: 12
Training loss: 2.820503629934014
Validation loss: 2.5243411701288014

Epoch: 6| Step: 13
Training loss: 3.053983875614311
Validation loss: 2.5369060901337597

Epoch: 142| Step: 0
Training loss: 3.2008810976081867
Validation loss: 2.5407689178538684

Epoch: 6| Step: 1
Training loss: 3.0835235811942887
Validation loss: 2.54327714015157

Epoch: 6| Step: 2
Training loss: 2.92486468271105
Validation loss: 2.5386944146676127

Epoch: 6| Step: 3
Training loss: 3.1977844376620226
Validation loss: 2.540474724303156

Epoch: 6| Step: 4
Training loss: 2.915549872801187
Validation loss: 2.5308005803590086

Epoch: 6| Step: 5
Training loss: 2.903572900423499
Validation loss: 2.529888027201485

Epoch: 6| Step: 6
Training loss: 2.7395875783290298
Validation loss: 2.53314972443127

Epoch: 6| Step: 7
Training loss: 2.5548909424202697
Validation loss: 2.5337025195549185

Epoch: 6| Step: 8
Training loss: 2.870968853575936
Validation loss: 2.5329650118800955

Epoch: 6| Step: 9
Training loss: 3.452644970700169
Validation loss: 2.5298198162360315

Epoch: 6| Step: 10
Training loss: 2.900987023067806
Validation loss: 2.530766454988298

Epoch: 6| Step: 11
Training loss: 2.2616580302730203
Validation loss: 2.5304875027399865

Epoch: 6| Step: 12
Training loss: 2.849957910862714
Validation loss: 2.5232508471054604

Epoch: 6| Step: 13
Training loss: 2.9401544792436343
Validation loss: 2.520517247220222

Epoch: 143| Step: 0
Training loss: 3.044550238656062
Validation loss: 2.518292371815628

Epoch: 6| Step: 1
Training loss: 2.5783660775957387
Validation loss: 2.5226080300238594

Epoch: 6| Step: 2
Training loss: 2.654988426858567
Validation loss: 2.541670953742624

Epoch: 6| Step: 3
Training loss: 2.8509816871571396
Validation loss: 2.5533542431082528

Epoch: 6| Step: 4
Training loss: 2.1800370568441876
Validation loss: 2.5307801607033418

Epoch: 6| Step: 5
Training loss: 2.933597651046008
Validation loss: 2.5356353464312105

Epoch: 6| Step: 6
Training loss: 2.6843001367434853
Validation loss: 2.5399841311989935

Epoch: 6| Step: 7
Training loss: 3.4057560833846745
Validation loss: 2.5363330097969885

Epoch: 6| Step: 8
Training loss: 3.668884358065995
Validation loss: 2.551447397893035

Epoch: 6| Step: 9
Training loss: 3.1572910518177877
Validation loss: 2.554084796299672

Epoch: 6| Step: 10
Training loss: 2.6556679480624474
Validation loss: 2.535989624091882

Epoch: 6| Step: 11
Training loss: 2.887345056381273
Validation loss: 2.5533848768405

Epoch: 6| Step: 12
Training loss: 2.631630470875746
Validation loss: 2.539191787242603

Epoch: 6| Step: 13
Training loss: 2.781660242578011
Validation loss: 2.5338872491660163

Epoch: 144| Step: 0
Training loss: 1.459380600324255
Validation loss: 2.5300906296369288

Epoch: 6| Step: 1
Training loss: 2.5404394553586145
Validation loss: 2.5230805555303935

Epoch: 6| Step: 2
Training loss: 2.803022820386967
Validation loss: 2.534821173092094

Epoch: 6| Step: 3
Training loss: 2.7715490654888484
Validation loss: 2.53365738204309

Epoch: 6| Step: 4
Training loss: 3.034803686690137
Validation loss: 2.532824641413436

Epoch: 6| Step: 5
Training loss: 2.8062106701106253
Validation loss: 2.5079289421031348

Epoch: 6| Step: 6
Training loss: 3.203154921973428
Validation loss: 2.499923382887387

Epoch: 6| Step: 7
Training loss: 3.018726078673175
Validation loss: 2.496788387215049

Epoch: 6| Step: 8
Training loss: 3.067869500598922
Validation loss: 2.4923304194299845

Epoch: 6| Step: 9
Training loss: 2.8571258203815963
Validation loss: 2.4903564155556204

Epoch: 6| Step: 10
Training loss: 2.9967326809659607
Validation loss: 2.4868984644627083

Epoch: 6| Step: 11
Training loss: 3.100944553572123
Validation loss: 2.4882999321008006

Epoch: 6| Step: 12
Training loss: 2.804393019664012
Validation loss: 2.4816679438280955

Epoch: 6| Step: 13
Training loss: 3.6198554529657962
Validation loss: 2.5000236284513484

Epoch: 145| Step: 0
Training loss: 2.8021398678055163
Validation loss: 2.5013986305304834

Epoch: 6| Step: 1
Training loss: 3.1146721120235883
Validation loss: 2.490414824570066

Epoch: 6| Step: 2
Training loss: 2.4410521227543294
Validation loss: 2.4808298481323825

Epoch: 6| Step: 3
Training loss: 2.8196439082638043
Validation loss: 2.484898145857119

Epoch: 6| Step: 4
Training loss: 2.965060541522311
Validation loss: 2.4872798312502638

Epoch: 6| Step: 5
Training loss: 2.7858784770436382
Validation loss: 2.4878854610513366

Epoch: 6| Step: 6
Training loss: 2.736193504534464
Validation loss: 2.489644435016571

Epoch: 6| Step: 7
Training loss: 2.9733683751982207
Validation loss: 2.5006125776360624

Epoch: 6| Step: 8
Training loss: 2.5211275943060163
Validation loss: 2.5160180229865157

Epoch: 6| Step: 9
Training loss: 2.4999387733591463
Validation loss: 2.537902665065925

Epoch: 6| Step: 10
Training loss: 3.121690141705341
Validation loss: 2.5544701978949598

Epoch: 6| Step: 11
Training loss: 3.2092472277560455
Validation loss: 2.5688137803316953

Epoch: 6| Step: 12
Training loss: 2.989049316632421
Validation loss: 2.56779711026823

Epoch: 6| Step: 13
Training loss: 3.2361153605755657
Validation loss: 2.5784798207367374

Epoch: 146| Step: 0
Training loss: 2.8632799177179713
Validation loss: 2.5631819217113665

Epoch: 6| Step: 1
Training loss: 2.4104553729493663
Validation loss: 2.549989254965232

Epoch: 6| Step: 2
Training loss: 3.17170541995881
Validation loss: 2.547347717886106

Epoch: 6| Step: 3
Training loss: 2.8018115927001177
Validation loss: 2.5446079798361816

Epoch: 6| Step: 4
Training loss: 2.5453612152552116
Validation loss: 2.5423199634222415

Epoch: 6| Step: 5
Training loss: 2.8861821854175935
Validation loss: 2.54766081763529

Epoch: 6| Step: 6
Training loss: 3.3671651250887975
Validation loss: 2.549317504888358

Epoch: 6| Step: 7
Training loss: 3.03433306711218
Validation loss: 2.521662829273873

Epoch: 6| Step: 8
Training loss: 2.888470480851414
Validation loss: 2.512297781847584

Epoch: 6| Step: 9
Training loss: 2.544171261408939
Validation loss: 2.494925247970753

Epoch: 6| Step: 10
Training loss: 2.758611633536667
Validation loss: 2.4965361378802773

Epoch: 6| Step: 11
Training loss: 2.9888006020812874
Validation loss: 2.4906643074635175

Epoch: 6| Step: 12
Training loss: 2.573108393106155
Validation loss: 2.478706555693353

Epoch: 6| Step: 13
Training loss: 3.3486588711529817
Validation loss: 2.4757491067670054

Epoch: 147| Step: 0
Training loss: 2.555667420947354
Validation loss: 2.480848466991654

Epoch: 6| Step: 1
Training loss: 2.5510343510772207
Validation loss: 2.491939666467896

Epoch: 6| Step: 2
Training loss: 2.2776130006730644
Validation loss: 2.520019911215192

Epoch: 6| Step: 3
Training loss: 2.535589007807873
Validation loss: 2.553577413346343

Epoch: 6| Step: 4
Training loss: 2.9387947637928526
Validation loss: 2.58175608119212

Epoch: 6| Step: 5
Training loss: 3.0352112361291765
Validation loss: 2.5539320664575373

Epoch: 6| Step: 6
Training loss: 2.9921543527863728
Validation loss: 2.515917876696403

Epoch: 6| Step: 7
Training loss: 2.788470806541522
Validation loss: 2.5037661231290906

Epoch: 6| Step: 8
Training loss: 2.8639133479046883
Validation loss: 2.480915644596363

Epoch: 6| Step: 9
Training loss: 2.7404887705995487
Validation loss: 2.4739928789214956

Epoch: 6| Step: 10
Training loss: 3.1309501458691367
Validation loss: 2.4739423391001094

Epoch: 6| Step: 11
Training loss: 3.389314600430795
Validation loss: 2.4712373709012185

Epoch: 6| Step: 12
Training loss: 2.7587557036146864
Validation loss: 2.4826967495718266

Epoch: 6| Step: 13
Training loss: 3.409415637647363
Validation loss: 2.4776923025902655

Epoch: 148| Step: 0
Training loss: 2.9165821789811597
Validation loss: 2.4827500891503047

Epoch: 6| Step: 1
Training loss: 2.6911120426947424
Validation loss: 2.485546048379302

Epoch: 6| Step: 2
Training loss: 2.6901678992984834
Validation loss: 2.4769657927591058

Epoch: 6| Step: 3
Training loss: 1.8308257669400443
Validation loss: 2.4809437152419873

Epoch: 6| Step: 4
Training loss: 3.220763826463296
Validation loss: 2.5048503502705617

Epoch: 6| Step: 5
Training loss: 3.25546758407744
Validation loss: 2.4828345363207984

Epoch: 6| Step: 6
Training loss: 2.783111378010828
Validation loss: 2.503999004559668

Epoch: 6| Step: 7
Training loss: 2.380459483535203
Validation loss: 2.5069749381843898

Epoch: 6| Step: 8
Training loss: 2.767396521145646
Validation loss: 2.533011179894631

Epoch: 6| Step: 9
Training loss: 3.3716576591920737
Validation loss: 2.553397796492582

Epoch: 6| Step: 10
Training loss: 2.8426711163310046
Validation loss: 2.511848035176523

Epoch: 6| Step: 11
Training loss: 3.111621754231425
Validation loss: 2.506096749127038

Epoch: 6| Step: 12
Training loss: 2.7815885873498445
Validation loss: 2.4814001056826056

Epoch: 6| Step: 13
Training loss: 2.7233875228489564
Validation loss: 2.481108922097167

Epoch: 149| Step: 0
Training loss: 2.4239236350226943
Validation loss: 2.4774976989438056

Epoch: 6| Step: 1
Training loss: 3.0583795348236817
Validation loss: 2.4726855631655713

Epoch: 6| Step: 2
Training loss: 2.5751468912837248
Validation loss: 2.4698124223745572

Epoch: 6| Step: 3
Training loss: 3.250062795179106
Validation loss: 2.4674391926430395

Epoch: 6| Step: 4
Training loss: 2.7688101837299377
Validation loss: 2.471583036694641

Epoch: 6| Step: 5
Training loss: 2.8480731674611017
Validation loss: 2.470613965214775

Epoch: 6| Step: 6
Training loss: 2.73016818552045
Validation loss: 2.4752401191738116

Epoch: 6| Step: 7
Training loss: 2.581570074820456
Validation loss: 2.482190540653601

Epoch: 6| Step: 8
Training loss: 2.479005877839845
Validation loss: 2.49981201757202

Epoch: 6| Step: 9
Training loss: 3.041070818783002
Validation loss: 2.526881065403477

Epoch: 6| Step: 10
Training loss: 3.131776709809852
Validation loss: 2.5283325399331757

Epoch: 6| Step: 11
Training loss: 2.5003141205854758
Validation loss: 2.5817989052271026

Epoch: 6| Step: 12
Training loss: 2.984720260061695
Validation loss: 2.5944836662789412

Epoch: 6| Step: 13
Training loss: 3.4602883722605635
Validation loss: 2.6084875629375617

Epoch: 150| Step: 0
Training loss: 3.1314867977063203
Validation loss: 2.5636016724542494

Epoch: 6| Step: 1
Training loss: 2.9860609794568274
Validation loss: 2.4844656657049207

Epoch: 6| Step: 2
Training loss: 2.858520546909196
Validation loss: 2.4760597852018567

Epoch: 6| Step: 3
Training loss: 3.1679238952396367
Validation loss: 2.469028758828234

Epoch: 6| Step: 4
Training loss: 3.355532981959435
Validation loss: 2.473120444373975

Epoch: 6| Step: 5
Training loss: 2.409320012317361
Validation loss: 2.4780847921056495

Epoch: 6| Step: 6
Training loss: 2.831198355433193
Validation loss: 2.4861614057752632

Epoch: 6| Step: 7
Training loss: 3.261870055201317
Validation loss: 2.497006484784505

Epoch: 6| Step: 8
Training loss: 2.2378666412192296
Validation loss: 2.5144931308230003

Epoch: 6| Step: 9
Training loss: 2.889999404431978
Validation loss: 2.5472778780760748

Epoch: 6| Step: 10
Training loss: 2.5845803563221117
Validation loss: 2.5636665436194224

Epoch: 6| Step: 11
Training loss: 3.353121877137336
Validation loss: 2.5551794488574053

Epoch: 6| Step: 12
Training loss: 2.7786758168589105
Validation loss: 2.5224452169327045

Epoch: 6| Step: 13
Training loss: 2.6829067278106846
Validation loss: 2.4866533915298343

Epoch: 151| Step: 0
Training loss: 2.938179911392668
Validation loss: 2.47667965673813

Epoch: 6| Step: 1
Training loss: 2.6220602195161895
Validation loss: 2.4738585365948103

Epoch: 6| Step: 2
Training loss: 2.7380415393863236
Validation loss: 2.48621592695332

Epoch: 6| Step: 3
Training loss: 2.47596131738572
Validation loss: 2.533645262266677

Epoch: 6| Step: 4
Training loss: 2.9788016960470127
Validation loss: 2.620668986089562

Epoch: 6| Step: 5
Training loss: 2.5681046392209725
Validation loss: 2.6834419445063418

Epoch: 6| Step: 6
Training loss: 3.0044667052241225
Validation loss: 2.748280333383534

Epoch: 6| Step: 7
Training loss: 2.7579025815780907
Validation loss: 2.7122878438389244

Epoch: 6| Step: 8
Training loss: 3.3260733858088045
Validation loss: 2.616394004961777

Epoch: 6| Step: 9
Training loss: 2.908272316482982
Validation loss: 2.553136750712575

Epoch: 6| Step: 10
Training loss: 3.386131438090942
Validation loss: 2.4883198297799334

Epoch: 6| Step: 11
Training loss: 2.8032935458643404
Validation loss: 2.48006312010786

Epoch: 6| Step: 12
Training loss: 2.8855822317132125
Validation loss: 2.47550833279629

Epoch: 6| Step: 13
Training loss: 2.629999123489756
Validation loss: 2.48861196416225

Epoch: 152| Step: 0
Training loss: 3.1748724243485236
Validation loss: 2.4842109349967783

Epoch: 6| Step: 1
Training loss: 2.7507182830476973
Validation loss: 2.4811627039409574

Epoch: 6| Step: 2
Training loss: 2.9466722825228424
Validation loss: 2.4746088673707747

Epoch: 6| Step: 3
Training loss: 3.0330704403931534
Validation loss: 2.4750864310289185

Epoch: 6| Step: 4
Training loss: 3.4454121477936517
Validation loss: 2.4707972598638674

Epoch: 6| Step: 5
Training loss: 2.4043171042761893
Validation loss: 2.468158443882055

Epoch: 6| Step: 6
Training loss: 2.7249710116463155
Validation loss: 2.4731517961909595

Epoch: 6| Step: 7
Training loss: 2.5377237869575917
Validation loss: 2.481498933637569

Epoch: 6| Step: 8
Training loss: 2.8602817119223793
Validation loss: 2.4911360480799387

Epoch: 6| Step: 9
Training loss: 2.760411494028295
Validation loss: 2.5160301553302316

Epoch: 6| Step: 10
Training loss: 2.6065944087297304
Validation loss: 2.554684708248702

Epoch: 6| Step: 11
Training loss: 2.7550383276791632
Validation loss: 2.579765849223253

Epoch: 6| Step: 12
Training loss: 2.9421385807097167
Validation loss: 2.5901328784974185

Epoch: 6| Step: 13
Training loss: 2.9909225459348243
Validation loss: 2.578009428365444

Epoch: 153| Step: 0
Training loss: 3.2559594022858294
Validation loss: 2.5760029999100804

Epoch: 6| Step: 1
Training loss: 2.8635616815690197
Validation loss: 2.545074364889875

Epoch: 6| Step: 2
Training loss: 2.421549522925348
Validation loss: 2.5011788921384577

Epoch: 6| Step: 3
Training loss: 2.825730463973749
Validation loss: 2.489766380928666

Epoch: 6| Step: 4
Training loss: 2.892466520414075
Validation loss: 2.474105426105007

Epoch: 6| Step: 5
Training loss: 3.142612416783849
Validation loss: 2.466591928786002

Epoch: 6| Step: 6
Training loss: 3.360818809921195
Validation loss: 2.459928976731617

Epoch: 6| Step: 7
Training loss: 2.6679246041484026
Validation loss: 2.4634363330171336

Epoch: 6| Step: 8
Training loss: 2.97892415231147
Validation loss: 2.4672545668525183

Epoch: 6| Step: 9
Training loss: 2.3713441116406933
Validation loss: 2.4672628263752996

Epoch: 6| Step: 10
Training loss: 2.485127077288201
Validation loss: 2.469308079000954

Epoch: 6| Step: 11
Training loss: 2.6105557813867786
Validation loss: 2.4687904093955364

Epoch: 6| Step: 12
Training loss: 3.0558141791585407
Validation loss: 2.4654772514336436

Epoch: 6| Step: 13
Training loss: 3.0255485478674657
Validation loss: 2.4654860524134934

Epoch: 154| Step: 0
Training loss: 3.1120115823799863
Validation loss: 2.4660732030197834

Epoch: 6| Step: 1
Training loss: 2.562880511061148
Validation loss: 2.462149133458676

Epoch: 6| Step: 2
Training loss: 3.0159456547057792
Validation loss: 2.4607271744269346

Epoch: 6| Step: 3
Training loss: 2.580977832401917
Validation loss: 2.4641617006385723

Epoch: 6| Step: 4
Training loss: 2.974328992808041
Validation loss: 2.476322606408179

Epoch: 6| Step: 5
Training loss: 2.455255057454472
Validation loss: 2.4980784350569083

Epoch: 6| Step: 6
Training loss: 2.891056502844024
Validation loss: 2.5469889879213325

Epoch: 6| Step: 7
Training loss: 3.620965619994092
Validation loss: 2.557959693361188

Epoch: 6| Step: 8
Training loss: 2.9720333213632477
Validation loss: 2.5578034593912986

Epoch: 6| Step: 9
Training loss: 2.9785457221840033
Validation loss: 2.508597038774972

Epoch: 6| Step: 10
Training loss: 2.751565747581355
Validation loss: 2.5016175174890747

Epoch: 6| Step: 11
Training loss: 2.807403864178434
Validation loss: 2.486534328242674

Epoch: 6| Step: 12
Training loss: 2.827900745921642
Validation loss: 2.485655725045156

Epoch: 6| Step: 13
Training loss: 1.9896208142117138
Validation loss: 2.473176743639831

Epoch: 155| Step: 0
Training loss: 2.7568801297987813
Validation loss: 2.464679663216969

Epoch: 6| Step: 1
Training loss: 2.34493327470862
Validation loss: 2.4734391964499842

Epoch: 6| Step: 2
Training loss: 1.662433095173744
Validation loss: 2.4730096810115243

Epoch: 6| Step: 3
Training loss: 2.870845778779255
Validation loss: 2.4708413346736586

Epoch: 6| Step: 4
Training loss: 3.272255622709137
Validation loss: 2.4736454812609905

Epoch: 6| Step: 5
Training loss: 2.6945951972378968
Validation loss: 2.4769339913801525

Epoch: 6| Step: 6
Training loss: 3.064078722049581
Validation loss: 2.4713492946100635

Epoch: 6| Step: 7
Training loss: 2.851548119077607
Validation loss: 2.4748951423286663

Epoch: 6| Step: 8
Training loss: 3.430874073996464
Validation loss: 2.469886701899096

Epoch: 6| Step: 9
Training loss: 2.7632960626767598
Validation loss: 2.4718957767816723

Epoch: 6| Step: 10
Training loss: 2.941933390887023
Validation loss: 2.4673345926090686

Epoch: 6| Step: 11
Training loss: 2.976842191276302
Validation loss: 2.468764604530735

Epoch: 6| Step: 12
Training loss: 2.7940051310061373
Validation loss: 2.4724276300132493

Epoch: 6| Step: 13
Training loss: 2.7152012431834787
Validation loss: 2.470272391806263

Epoch: 156| Step: 0
Training loss: 2.8859723562501496
Validation loss: 2.464530939926246

Epoch: 6| Step: 1
Training loss: 3.016229914737862
Validation loss: 2.464869406619437

Epoch: 6| Step: 2
Training loss: 2.541538099778985
Validation loss: 2.4642693729704237

Epoch: 6| Step: 3
Training loss: 3.3275436824966462
Validation loss: 2.470790169057379

Epoch: 6| Step: 4
Training loss: 1.8736290051952351
Validation loss: 2.4646395296786814

Epoch: 6| Step: 5
Training loss: 2.8137706005777696
Validation loss: 2.465536187452789

Epoch: 6| Step: 6
Training loss: 2.6594577045781693
Validation loss: 2.470705553019813

Epoch: 6| Step: 7
Training loss: 2.9256844396324797
Validation loss: 2.471618292448716

Epoch: 6| Step: 8
Training loss: 2.7499172891836356
Validation loss: 2.474121884875106

Epoch: 6| Step: 9
Training loss: 2.789049848426312
Validation loss: 2.4755331638114937

Epoch: 6| Step: 10
Training loss: 2.9647063976130674
Validation loss: 2.477470421218035

Epoch: 6| Step: 11
Training loss: 3.2561926897097986
Validation loss: 2.481912853131735

Epoch: 6| Step: 12
Training loss: 2.906618484599355
Validation loss: 2.4851833665749554

Epoch: 6| Step: 13
Training loss: 2.531951242022638
Validation loss: 2.488031246853504

Epoch: 157| Step: 0
Training loss: 2.5210556268543236
Validation loss: 2.486021914218445

Epoch: 6| Step: 1
Training loss: 2.3428512884691575
Validation loss: 2.490369920574458

Epoch: 6| Step: 2
Training loss: 2.638340791590116
Validation loss: 2.4952569565718425

Epoch: 6| Step: 3
Training loss: 2.8101321955635767
Validation loss: 2.49546551013852

Epoch: 6| Step: 4
Training loss: 3.3043022201716727
Validation loss: 2.493486866317233

Epoch: 6| Step: 5
Training loss: 3.0590975798312954
Validation loss: 2.4883445149205707

Epoch: 6| Step: 6
Training loss: 2.8317153649261755
Validation loss: 2.488402906254509

Epoch: 6| Step: 7
Training loss: 2.6965299206528517
Validation loss: 2.489732003575178

Epoch: 6| Step: 8
Training loss: 2.3580217333075995
Validation loss: 2.4939697509284318

Epoch: 6| Step: 9
Training loss: 2.688572957742226
Validation loss: 2.4874220112936998

Epoch: 6| Step: 10
Training loss: 3.0803378908175714
Validation loss: 2.486389977560821

Epoch: 6| Step: 11
Training loss: 3.095659995756345
Validation loss: 2.492899602642143

Epoch: 6| Step: 12
Training loss: 3.092006153342378
Validation loss: 2.4782898099247217

Epoch: 6| Step: 13
Training loss: 2.5654461369678665
Validation loss: 2.4827096209374857

Epoch: 158| Step: 0
Training loss: 2.909848190490222
Validation loss: 2.473037482719

Epoch: 6| Step: 1
Training loss: 3.396881097895142
Validation loss: 2.468745005114357

Epoch: 6| Step: 2
Training loss: 3.1335976394480816
Validation loss: 2.468022990369446

Epoch: 6| Step: 3
Training loss: 3.0609388459510822
Validation loss: 2.469816494406033

Epoch: 6| Step: 4
Training loss: 2.152457620201312
Validation loss: 2.4689477955783232

Epoch: 6| Step: 5
Training loss: 3.252981285709806
Validation loss: 2.4646999377696766

Epoch: 6| Step: 6
Training loss: 2.800628359996276
Validation loss: 2.462770562793825

Epoch: 6| Step: 7
Training loss: 2.9536623188424906
Validation loss: 2.4677253030635633

Epoch: 6| Step: 8
Training loss: 2.5416702729079717
Validation loss: 2.4719441525459174

Epoch: 6| Step: 9
Training loss: 2.5169100115348884
Validation loss: 2.4777108306944884

Epoch: 6| Step: 10
Training loss: 2.532319772978363
Validation loss: 2.481286109187743

Epoch: 6| Step: 11
Training loss: 2.2030321466885727
Validation loss: 2.49023716848604

Epoch: 6| Step: 12
Training loss: 2.793519121909255
Validation loss: 2.5003678194819914

Epoch: 6| Step: 13
Training loss: 2.7595016882425223
Validation loss: 2.489755142042597

Epoch: 159| Step: 0
Training loss: 2.736609891642513
Validation loss: 2.495356206075613

Epoch: 6| Step: 1
Training loss: 3.067196417400594
Validation loss: 2.511308180789737

Epoch: 6| Step: 2
Training loss: 3.126804593696748
Validation loss: 2.5131260163775604

Epoch: 6| Step: 3
Training loss: 2.276652262219966
Validation loss: 2.5207339217793887

Epoch: 6| Step: 4
Training loss: 2.8482558217075784
Validation loss: 2.519355182580193

Epoch: 6| Step: 5
Training loss: 3.2072701777528856
Validation loss: 2.5089253376160427

Epoch: 6| Step: 6
Training loss: 2.6845279494599947
Validation loss: 2.497702410324105

Epoch: 6| Step: 7
Training loss: 2.1066204028341136
Validation loss: 2.4775744347567015

Epoch: 6| Step: 8
Training loss: 3.059970511749399
Validation loss: 2.4745789398539526

Epoch: 6| Step: 9
Training loss: 2.6793161029184125
Validation loss: 2.471285950430141

Epoch: 6| Step: 10
Training loss: 2.5926610660088683
Validation loss: 2.476815534222827

Epoch: 6| Step: 11
Training loss: 3.1774512072762944
Validation loss: 2.476524605575475

Epoch: 6| Step: 12
Training loss: 3.222829955072331
Validation loss: 2.478291370893291

Epoch: 6| Step: 13
Training loss: 1.9528144284325972
Validation loss: 2.4741276646917143

Epoch: 160| Step: 0
Training loss: 2.3917477034642194
Validation loss: 2.482953088346272

Epoch: 6| Step: 1
Training loss: 2.8704859914246805
Validation loss: 2.5025052346673937

Epoch: 6| Step: 2
Training loss: 2.175114253759268
Validation loss: 2.5105087919661733

Epoch: 6| Step: 3
Training loss: 2.897048329390994
Validation loss: 2.540712717845149

Epoch: 6| Step: 4
Training loss: 2.9483248334826455
Validation loss: 2.561694790286148

Epoch: 6| Step: 5
Training loss: 3.1394906343993836
Validation loss: 2.587005485903327

Epoch: 6| Step: 6
Training loss: 3.5781028780190876
Validation loss: 2.6004156913099377

Epoch: 6| Step: 7
Training loss: 2.1995658532838087
Validation loss: 2.5435847793308164

Epoch: 6| Step: 8
Training loss: 2.9016367075463747
Validation loss: 2.5216905154662355

Epoch: 6| Step: 9
Training loss: 2.8874309316854503
Validation loss: 2.4917564877036256

Epoch: 6| Step: 10
Training loss: 2.483024181947241
Validation loss: 2.4760473006661843

Epoch: 6| Step: 11
Training loss: 2.476121640602262
Validation loss: 2.4689733555562783

Epoch: 6| Step: 12
Training loss: 3.510348416503556
Validation loss: 2.4800669478950925

Epoch: 6| Step: 13
Training loss: 2.7221782598600317
Validation loss: 2.487757922123765

Epoch: 161| Step: 0
Training loss: 2.8281336831649764
Validation loss: 2.4929791278244995

Epoch: 6| Step: 1
Training loss: 3.5355579126961447
Validation loss: 2.497434380439013

Epoch: 6| Step: 2
Training loss: 2.985498666180677
Validation loss: 2.4992147207044133

Epoch: 6| Step: 3
Training loss: 2.723387610393815
Validation loss: 2.502947068038942

Epoch: 6| Step: 4
Training loss: 2.670551172865731
Validation loss: 2.5032895626369895

Epoch: 6| Step: 5
Training loss: 2.4714151796313595
Validation loss: 2.502528673508695

Epoch: 6| Step: 6
Training loss: 2.867054616566877
Validation loss: 2.494604040251037

Epoch: 6| Step: 7
Training loss: 2.3768760900622827
Validation loss: 2.489515187185556

Epoch: 6| Step: 8
Training loss: 3.141693692550644
Validation loss: 2.481136899629914

Epoch: 6| Step: 9
Training loss: 3.027429906788122
Validation loss: 2.4752492904035424

Epoch: 6| Step: 10
Training loss: 3.103516700509175
Validation loss: 2.4779163357109586

Epoch: 6| Step: 11
Training loss: 2.8439533873546172
Validation loss: 2.481049998482176

Epoch: 6| Step: 12
Training loss: 2.9398954647968534
Validation loss: 2.500323158830379

Epoch: 6| Step: 13
Training loss: 2.754243178081556
Validation loss: 2.507264504796642

Epoch: 162| Step: 0
Training loss: 2.7741952639987275
Validation loss: 2.5231547320244685

Epoch: 6| Step: 1
Training loss: 2.6246687362187315
Validation loss: 2.5084213567084275

Epoch: 6| Step: 2
Training loss: 3.0300562759561784
Validation loss: 2.5246724074500246

Epoch: 6| Step: 3
Training loss: 2.7130662107392403
Validation loss: 2.5121947503319646

Epoch: 6| Step: 4
Training loss: 2.3916248898285577
Validation loss: 2.5196752434732606

Epoch: 6| Step: 5
Training loss: 3.099269682473157
Validation loss: 2.5205682964182654

Epoch: 6| Step: 6
Training loss: 2.3398064561014786
Validation loss: 2.486577805535239

Epoch: 6| Step: 7
Training loss: 3.203665487698095
Validation loss: 2.479555988911363

Epoch: 6| Step: 8
Training loss: 2.6108999764413037
Validation loss: 2.481355394992294

Epoch: 6| Step: 9
Training loss: 2.870584497247026
Validation loss: 2.4752127399250323

Epoch: 6| Step: 10
Training loss: 2.5323061211530584
Validation loss: 2.4763920341899333

Epoch: 6| Step: 11
Training loss: 3.2533116707575687
Validation loss: 2.4787974763045364

Epoch: 6| Step: 12
Training loss: 3.2518475489618903
Validation loss: 2.4770726223652666

Epoch: 6| Step: 13
Training loss: 2.217929312209918
Validation loss: 2.4754676374574243

Epoch: 163| Step: 0
Training loss: 2.842310446774294
Validation loss: 2.4813549806945345

Epoch: 6| Step: 1
Training loss: 2.548125258542334
Validation loss: 2.488120457385279

Epoch: 6| Step: 2
Training loss: 2.201366615650711
Validation loss: 2.481546673322016

Epoch: 6| Step: 3
Training loss: 2.7672158531145112
Validation loss: 2.484697437729281

Epoch: 6| Step: 4
Training loss: 2.9458604702560653
Validation loss: 2.501727742842732

Epoch: 6| Step: 5
Training loss: 1.8968957990986062
Validation loss: 2.5155093798891395

Epoch: 6| Step: 6
Training loss: 3.172745007492465
Validation loss: 2.554790960231888

Epoch: 6| Step: 7
Training loss: 2.8292867898135867
Validation loss: 2.562728065328133

Epoch: 6| Step: 8
Training loss: 2.322872919831081
Validation loss: 2.565000425124943

Epoch: 6| Step: 9
Training loss: 3.057034968572042
Validation loss: 2.547759218101728

Epoch: 6| Step: 10
Training loss: 3.2025416889797578
Validation loss: 2.5264948879906273

Epoch: 6| Step: 11
Training loss: 3.215813788237384
Validation loss: 2.501478062816999

Epoch: 6| Step: 12
Training loss: 3.375251478080293
Validation loss: 2.4967193140586597

Epoch: 6| Step: 13
Training loss: 2.1743360887309517
Validation loss: 2.484807516567064

Epoch: 164| Step: 0
Training loss: 2.6897959992721
Validation loss: 2.488980800151266

Epoch: 6| Step: 1
Training loss: 2.550660952758903
Validation loss: 2.483584433443754

Epoch: 6| Step: 2
Training loss: 2.554282060000621
Validation loss: 2.484388511736029

Epoch: 6| Step: 3
Training loss: 3.1607074044732286
Validation loss: 2.4831299972398204

Epoch: 6| Step: 4
Training loss: 2.8461813122381696
Validation loss: 2.47982941439094

Epoch: 6| Step: 5
Training loss: 3.360960120670767
Validation loss: 2.473273158027851

Epoch: 6| Step: 6
Training loss: 2.898795956555359
Validation loss: 2.4751361841360002

Epoch: 6| Step: 7
Training loss: 3.2824627769434103
Validation loss: 2.4731104276723284

Epoch: 6| Step: 8
Training loss: 2.630097933929329
Validation loss: 2.465813900843695

Epoch: 6| Step: 9
Training loss: 2.3167098619930293
Validation loss: 2.4653018138159957

Epoch: 6| Step: 10
Training loss: 3.0122137986353104
Validation loss: 2.4735576318519974

Epoch: 6| Step: 11
Training loss: 2.754817557550885
Validation loss: 2.468554751638925

Epoch: 6| Step: 12
Training loss: 2.489203792568029
Validation loss: 2.4757401009985704

Epoch: 6| Step: 13
Training loss: 2.655716158010898
Validation loss: 2.4877556086446875

Epoch: 165| Step: 0
Training loss: 3.083164176081112
Validation loss: 2.5018108720979564

Epoch: 6| Step: 1
Training loss: 2.414553891634119
Validation loss: 2.5379401127528607

Epoch: 6| Step: 2
Training loss: 3.4372788791629416
Validation loss: 2.5684671343889933

Epoch: 6| Step: 3
Training loss: 3.016498656538315
Validation loss: 2.6231297179737263

Epoch: 6| Step: 4
Training loss: 2.7249976971817786
Validation loss: 2.60812844499759

Epoch: 6| Step: 5
Training loss: 3.0305552522134866
Validation loss: 2.599289765308453

Epoch: 6| Step: 6
Training loss: 2.5811793874175613
Validation loss: 2.558472998439853

Epoch: 6| Step: 7
Training loss: 3.0570535301685378
Validation loss: 2.5109456119112403

Epoch: 6| Step: 8
Training loss: 3.124334188104326
Validation loss: 2.477525919034284

Epoch: 6| Step: 9
Training loss: 2.4392386862189537
Validation loss: 2.4652679672712314

Epoch: 6| Step: 10
Training loss: 2.908770381002002
Validation loss: 2.46188243323964

Epoch: 6| Step: 11
Training loss: 2.428757075418718
Validation loss: 2.467279970849357

Epoch: 6| Step: 12
Training loss: 2.5717925010974683
Validation loss: 2.466586065832409

Epoch: 6| Step: 13
Training loss: 2.7633489521200287
Validation loss: 2.4696886493436625

Epoch: 166| Step: 0
Training loss: 2.025924744619557
Validation loss: 2.4758805694460526

Epoch: 6| Step: 1
Training loss: 3.0655129072906586
Validation loss: 2.4710569079863607

Epoch: 6| Step: 2
Training loss: 3.150447232423077
Validation loss: 2.4740205991170625

Epoch: 6| Step: 3
Training loss: 3.016121462736293
Validation loss: 2.4764214273617653

Epoch: 6| Step: 4
Training loss: 2.758609213579083
Validation loss: 2.487220693073724

Epoch: 6| Step: 5
Training loss: 2.4490323277150923
Validation loss: 2.4954838703269115

Epoch: 6| Step: 6
Training loss: 3.0862069700384747
Validation loss: 2.511597340189892

Epoch: 6| Step: 7
Training loss: 2.7545791994162983
Validation loss: 2.5267317236700544

Epoch: 6| Step: 8
Training loss: 3.2810154422302436
Validation loss: 2.53953450071441

Epoch: 6| Step: 9
Training loss: 2.793230804740676
Validation loss: 2.5572673446500804

Epoch: 6| Step: 10
Training loss: 2.317210066023749
Validation loss: 2.5725301115308934

Epoch: 6| Step: 11
Training loss: 2.39694714294644
Validation loss: 2.5612134347391495

Epoch: 6| Step: 12
Training loss: 3.0679215690107
Validation loss: 2.5614920053488786

Epoch: 6| Step: 13
Training loss: 3.249717259946207
Validation loss: 2.532702431487955

Epoch: 167| Step: 0
Training loss: 3.2762987837494233
Validation loss: 2.514623679240201

Epoch: 6| Step: 1
Training loss: 2.8063210323324075
Validation loss: 2.5087936527078303

Epoch: 6| Step: 2
Training loss: 3.046503601913539
Validation loss: 2.495489219534991

Epoch: 6| Step: 3
Training loss: 2.7656318104115916
Validation loss: 2.483642166144161

Epoch: 6| Step: 4
Training loss: 2.7646162704272688
Validation loss: 2.4893405404784423

Epoch: 6| Step: 5
Training loss: 3.0728949249705346
Validation loss: 2.4867062080900557

Epoch: 6| Step: 6
Training loss: 2.5055199718086625
Validation loss: 2.4843733056103208

Epoch: 6| Step: 7
Training loss: 2.9317956282411513
Validation loss: 2.4831289875298763

Epoch: 6| Step: 8
Training loss: 2.7823804636707576
Validation loss: 2.486065703646272

Epoch: 6| Step: 9
Training loss: 2.8595012365939834
Validation loss: 2.4874934399158044

Epoch: 6| Step: 10
Training loss: 2.3596350924391287
Validation loss: 2.4921037627286364

Epoch: 6| Step: 11
Training loss: 2.58997999382393
Validation loss: 2.5007664336259516

Epoch: 6| Step: 12
Training loss: 3.0211254811698294
Validation loss: 2.509280035324787

Epoch: 6| Step: 13
Training loss: 1.9025888148065333
Validation loss: 2.5107620247472315

Epoch: 168| Step: 0
Training loss: 2.88839107487262
Validation loss: 2.5164584475544367

Epoch: 6| Step: 1
Training loss: 2.5688567053543574
Validation loss: 2.5300915152263603

Epoch: 6| Step: 2
Training loss: 3.113162393825936
Validation loss: 2.5396225016847653

Epoch: 6| Step: 3
Training loss: 2.874669097433437
Validation loss: 2.549441891823977

Epoch: 6| Step: 4
Training loss: 3.013376296870832
Validation loss: 2.554807270482913

Epoch: 6| Step: 5
Training loss: 3.15888821467421
Validation loss: 2.53059187232836

Epoch: 6| Step: 6
Training loss: 2.7392038486217487
Validation loss: 2.5032658185640257

Epoch: 6| Step: 7
Training loss: 3.061736965490277
Validation loss: 2.5081299862050157

Epoch: 6| Step: 8
Training loss: 2.3693247799794994
Validation loss: 2.496462125503178

Epoch: 6| Step: 9
Training loss: 2.606428847362756
Validation loss: 2.4914832176834945

Epoch: 6| Step: 10
Training loss: 2.517854827756117
Validation loss: 2.4919312778374616

Epoch: 6| Step: 11
Training loss: 2.849642506982681
Validation loss: 2.481759882942822

Epoch: 6| Step: 12
Training loss: 3.033033023542509
Validation loss: 2.463081359699

Epoch: 6| Step: 13
Training loss: 1.7137652157609564
Validation loss: 2.4631018076938123

Epoch: 169| Step: 0
Training loss: 2.36455971682234
Validation loss: 2.4630709586966706

Epoch: 6| Step: 1
Training loss: 2.7290907016888304
Validation loss: 2.4600446058821785

Epoch: 6| Step: 2
Training loss: 3.05289994252711
Validation loss: 2.462352783119257

Epoch: 6| Step: 3
Training loss: 2.8066965202441265
Validation loss: 2.4600112539214543

Epoch: 6| Step: 4
Training loss: 2.596289253507478
Validation loss: 2.4657266270512532

Epoch: 6| Step: 5
Training loss: 2.336621238640574
Validation loss: 2.469206100539973

Epoch: 6| Step: 6
Training loss: 3.2339089467872837
Validation loss: 2.463828442295947

Epoch: 6| Step: 7
Training loss: 2.7903950390360417
Validation loss: 2.4655812369961736

Epoch: 6| Step: 8
Training loss: 3.019351534411734
Validation loss: 2.475366059817703

Epoch: 6| Step: 9
Training loss: 2.752382546811122
Validation loss: 2.478397157583484

Epoch: 6| Step: 10
Training loss: 2.9375785654802735
Validation loss: 2.489559891893688

Epoch: 6| Step: 11
Training loss: 3.2278755970539126
Validation loss: 2.4826863966704473

Epoch: 6| Step: 12
Training loss: 2.2767540510096964
Validation loss: 2.482470077656349

Epoch: 6| Step: 13
Training loss: 2.4768929727322417
Validation loss: 2.4854350331890562

Epoch: 170| Step: 0
Training loss: 3.1979536785423486
Validation loss: 2.483757395798726

Epoch: 6| Step: 1
Training loss: 2.7966738154335484
Validation loss: 2.483778044118817

Epoch: 6| Step: 2
Training loss: 2.5791489850631155
Validation loss: 2.4931475967913554

Epoch: 6| Step: 3
Training loss: 2.1748875643728285
Validation loss: 2.495306975305614

Epoch: 6| Step: 4
Training loss: 2.7749816893927144
Validation loss: 2.4974682416851834

Epoch: 6| Step: 5
Training loss: 3.3534570421135235
Validation loss: 2.493722497512536

Epoch: 6| Step: 6
Training loss: 2.7281670426213034
Validation loss: 2.5036255337721345

Epoch: 6| Step: 7
Training loss: 2.553240351598295
Validation loss: 2.51051697760165

Epoch: 6| Step: 8
Training loss: 2.713544224440723
Validation loss: 2.5151384816024493

Epoch: 6| Step: 9
Training loss: 2.8619236661593286
Validation loss: 2.5139611225004623

Epoch: 6| Step: 10
Training loss: 1.9855406934246806
Validation loss: 2.4939899662307186

Epoch: 6| Step: 11
Training loss: 3.1230951225557075
Validation loss: 2.4867706543000136

Epoch: 6| Step: 12
Training loss: 3.1017349925467936
Validation loss: 2.4828253580032764

Epoch: 6| Step: 13
Training loss: 2.7458484697479464
Validation loss: 2.467104100294546

Epoch: 171| Step: 0
Training loss: 3.0208520998317043
Validation loss: 2.4581190828955535

Epoch: 6| Step: 1
Training loss: 2.519023992056962
Validation loss: 2.4606530591086644

Epoch: 6| Step: 2
Training loss: 3.03556233835215
Validation loss: 2.4561853631127772

Epoch: 6| Step: 3
Training loss: 3.236679951266976
Validation loss: 2.4610039262715078

Epoch: 6| Step: 4
Training loss: 2.4165930462727783
Validation loss: 2.4611558282471915

Epoch: 6| Step: 5
Training loss: 3.126325097476637
Validation loss: 2.4608095989075394

Epoch: 6| Step: 6
Training loss: 2.8124348950797953
Validation loss: 2.463985775024284

Epoch: 6| Step: 7
Training loss: 2.642945122451105
Validation loss: 2.464069580369256

Epoch: 6| Step: 8
Training loss: 2.432143561505359
Validation loss: 2.477441236585227

Epoch: 6| Step: 9
Training loss: 2.3227639140951366
Validation loss: 2.497353640039333

Epoch: 6| Step: 10
Training loss: 2.683261189961929
Validation loss: 2.5173836656539996

Epoch: 6| Step: 11
Training loss: 2.766618539399244
Validation loss: 2.5271462379495073

Epoch: 6| Step: 12
Training loss: 2.674149376217047
Validation loss: 2.5173154050878357

Epoch: 6| Step: 13
Training loss: 3.18300611069093
Validation loss: 2.4975328864739073

Epoch: 172| Step: 0
Training loss: 2.604957816428572
Validation loss: 2.4989405027680283

Epoch: 6| Step: 1
Training loss: 2.1824644713770813
Validation loss: 2.490094495942945

Epoch: 6| Step: 2
Training loss: 3.1972352004890245
Validation loss: 2.4753695106384854

Epoch: 6| Step: 3
Training loss: 2.985230008821164
Validation loss: 2.4768906351322038

Epoch: 6| Step: 4
Training loss: 2.9720273850258767
Validation loss: 2.4856795187289693

Epoch: 6| Step: 5
Training loss: 2.6043753781923735
Validation loss: 2.498098611722848

Epoch: 6| Step: 6
Training loss: 3.05395686394806
Validation loss: 2.4944542460481935

Epoch: 6| Step: 7
Training loss: 2.220648691924402
Validation loss: 2.4947686343418964

Epoch: 6| Step: 8
Training loss: 2.9260622100996154
Validation loss: 2.4831649682594032

Epoch: 6| Step: 9
Training loss: 2.883951101843564
Validation loss: 2.4678691322123805

Epoch: 6| Step: 10
Training loss: 2.4137907893775785
Validation loss: 2.4708498908790286

Epoch: 6| Step: 11
Training loss: 2.923245195417959
Validation loss: 2.4650083063464026

Epoch: 6| Step: 12
Training loss: 2.1528880128700316
Validation loss: 2.4687075826111773

Epoch: 6| Step: 13
Training loss: 3.855338638413713
Validation loss: 2.464697899088356

Epoch: 173| Step: 0
Training loss: 2.735309724443514
Validation loss: 2.4694216328505427

Epoch: 6| Step: 1
Training loss: 2.660643948789278
Validation loss: 2.4678269271857802

Epoch: 6| Step: 2
Training loss: 2.3927046761812107
Validation loss: 2.470933512699576

Epoch: 6| Step: 3
Training loss: 2.7609326917933514
Validation loss: 2.4598781146082644

Epoch: 6| Step: 4
Training loss: 3.031007737379226
Validation loss: 2.4667013475889576

Epoch: 6| Step: 5
Training loss: 2.9586760810414607
Validation loss: 2.4648288944581265

Epoch: 6| Step: 6
Training loss: 2.8665767507719737
Validation loss: 2.467701701430017

Epoch: 6| Step: 7
Training loss: 2.9327815692878145
Validation loss: 2.474547252841165

Epoch: 6| Step: 8
Training loss: 2.7310678591543915
Validation loss: 2.4864393271460243

Epoch: 6| Step: 9
Training loss: 2.806789789768766
Validation loss: 2.506757128042563

Epoch: 6| Step: 10
Training loss: 2.2306130491167977
Validation loss: 2.490357812487941

Epoch: 6| Step: 11
Training loss: 2.904341532524856
Validation loss: 2.476930180486477

Epoch: 6| Step: 12
Training loss: 2.64716094543086
Validation loss: 2.467907850336844

Epoch: 6| Step: 13
Training loss: 3.187180895820491
Validation loss: 2.4692920916762944

Epoch: 174| Step: 0
Training loss: 2.926981823519723
Validation loss: 2.4774861612299026

Epoch: 6| Step: 1
Training loss: 2.9599714087059095
Validation loss: 2.47731823432832

Epoch: 6| Step: 2
Training loss: 2.5930935132295696
Validation loss: 2.4760354911362077

Epoch: 6| Step: 3
Training loss: 2.736734908674508
Validation loss: 2.4800471338896517

Epoch: 6| Step: 4
Training loss: 2.3523590665107674
Validation loss: 2.48246399196254

Epoch: 6| Step: 5
Training loss: 3.019102789125629
Validation loss: 2.4871223764538373

Epoch: 6| Step: 6
Training loss: 3.400657472432649
Validation loss: 2.507643468444926

Epoch: 6| Step: 7
Training loss: 2.623433326776944
Validation loss: 2.4952276784265184

Epoch: 6| Step: 8
Training loss: 3.1082813889268492
Validation loss: 2.5036110619442473

Epoch: 6| Step: 9
Training loss: 2.5081257371975054
Validation loss: 2.4890805409197507

Epoch: 6| Step: 10
Training loss: 2.402054535118855
Validation loss: 2.4879847830774713

Epoch: 6| Step: 11
Training loss: 2.7311960978830414
Validation loss: 2.472776122509253

Epoch: 6| Step: 12
Training loss: 2.2957133774709386
Validation loss: 2.476848750989462

Epoch: 6| Step: 13
Training loss: 3.043855706793891
Validation loss: 2.470062713718664

Epoch: 175| Step: 0
Training loss: 2.705461319316427
Validation loss: 2.4634256056990154

Epoch: 6| Step: 1
Training loss: 2.173896013898076
Validation loss: 2.4708803589884867

Epoch: 6| Step: 2
Training loss: 3.5406897300735682
Validation loss: 2.4622242105735688

Epoch: 6| Step: 3
Training loss: 2.525316796400043
Validation loss: 2.4692505775125753

Epoch: 6| Step: 4
Training loss: 2.74801963244981
Validation loss: 2.4558971786315924

Epoch: 6| Step: 5
Training loss: 2.8137572127681496
Validation loss: 2.4623472135635116

Epoch: 6| Step: 6
Training loss: 2.3385378038222955
Validation loss: 2.4669036700517952

Epoch: 6| Step: 7
Training loss: 2.3735389230741815
Validation loss: 2.4628938767920108

Epoch: 6| Step: 8
Training loss: 2.593177088694499
Validation loss: 2.4715924424272036

Epoch: 6| Step: 9
Training loss: 3.2873965867171204
Validation loss: 2.4718523129765586

Epoch: 6| Step: 10
Training loss: 3.154742494645091
Validation loss: 2.497316543583215

Epoch: 6| Step: 11
Training loss: 2.5768143530201044
Validation loss: 2.5057907166060964

Epoch: 6| Step: 12
Training loss: 2.9663570999763462
Validation loss: 2.539321168860379

Epoch: 6| Step: 13
Training loss: 2.3815208060801147
Validation loss: 2.521191175895742

Epoch: 176| Step: 0
Training loss: 2.4950903366644774
Validation loss: 2.517831380895408

Epoch: 6| Step: 1
Training loss: 2.5238634818770582
Validation loss: 2.5034417211083255

Epoch: 6| Step: 2
Training loss: 2.8062477978398235
Validation loss: 2.487059777260248

Epoch: 6| Step: 3
Training loss: 2.6321894873555305
Validation loss: 2.486430315761949

Epoch: 6| Step: 4
Training loss: 2.922930195442443
Validation loss: 2.470591786314442

Epoch: 6| Step: 5
Training loss: 2.9872505754231953
Validation loss: 2.4588613017917917

Epoch: 6| Step: 6
Training loss: 2.686330407715649
Validation loss: 2.452941254348847

Epoch: 6| Step: 7
Training loss: 2.9243078863860905
Validation loss: 2.459564568768274

Epoch: 6| Step: 8
Training loss: 2.6057412435396747
Validation loss: 2.4592931579414206

Epoch: 6| Step: 9
Training loss: 2.37103120573658
Validation loss: 2.455432201634466

Epoch: 6| Step: 10
Training loss: 2.6252649264389447
Validation loss: 2.4595751419872256

Epoch: 6| Step: 11
Training loss: 2.909170672558624
Validation loss: 2.455909609019842

Epoch: 6| Step: 12
Training loss: 2.95669259433782
Validation loss: 2.458419924115327

Epoch: 6| Step: 13
Training loss: 3.172619661760369
Validation loss: 2.456342638503352

Epoch: 177| Step: 0
Training loss: 2.5347439235182123
Validation loss: 2.4629336026432562

Epoch: 6| Step: 1
Training loss: 2.6301471564603056
Validation loss: 2.4724827070334556

Epoch: 6| Step: 2
Training loss: 2.6546470742293784
Validation loss: 2.4804996771802483

Epoch: 6| Step: 3
Training loss: 2.6060940336767824
Validation loss: 2.4945307865463997

Epoch: 6| Step: 4
Training loss: 2.4117234635623683
Validation loss: 2.504529152327906

Epoch: 6| Step: 5
Training loss: 3.104102643950765
Validation loss: 2.526696539885233

Epoch: 6| Step: 6
Training loss: 2.603014200149123
Validation loss: 2.523588146011818

Epoch: 6| Step: 7
Training loss: 3.441376736846704
Validation loss: 2.508718333202525

Epoch: 6| Step: 8
Training loss: 2.5705466120347933
Validation loss: 2.4873589486258845

Epoch: 6| Step: 9
Training loss: 2.83225147311859
Validation loss: 2.4731017834013804

Epoch: 6| Step: 10
Training loss: 2.2204894648342606
Validation loss: 2.4630441217636854

Epoch: 6| Step: 11
Training loss: 2.8225258044000068
Validation loss: 2.4579297758736596

Epoch: 6| Step: 12
Training loss: 2.9524721100060827
Validation loss: 2.461903105705365

Epoch: 6| Step: 13
Training loss: 3.0071725932535425
Validation loss: 2.456208786812662

Epoch: 178| Step: 0
Training loss: 2.7190718186305056
Validation loss: 2.457764167728429

Epoch: 6| Step: 1
Training loss: 2.1985345728196544
Validation loss: 2.4549030261060327

Epoch: 6| Step: 2
Training loss: 3.214856654126213
Validation loss: 2.4573967252943993

Epoch: 6| Step: 3
Training loss: 3.021904766326703
Validation loss: 2.4523635653387363

Epoch: 6| Step: 4
Training loss: 2.91372015939011
Validation loss: 2.456697795560112

Epoch: 6| Step: 5
Training loss: 2.8378870964684704
Validation loss: 2.453093059899586

Epoch: 6| Step: 6
Training loss: 2.855416982366757
Validation loss: 2.453327644777034

Epoch: 6| Step: 7
Training loss: 2.471983132486912
Validation loss: 2.454726612394108

Epoch: 6| Step: 8
Training loss: 2.759396106470763
Validation loss: 2.4618285649893292

Epoch: 6| Step: 9
Training loss: 2.5499739252889078
Validation loss: 2.4665440186614918

Epoch: 6| Step: 10
Training loss: 2.7691247208577527
Validation loss: 2.4782245566280183

Epoch: 6| Step: 11
Training loss: 2.588332619979115
Validation loss: 2.4826986299415617

Epoch: 6| Step: 12
Training loss: 2.6684299143035495
Validation loss: 2.4881677923500254

Epoch: 6| Step: 13
Training loss: 2.679417632724585
Validation loss: 2.4894842515209596

Epoch: 179| Step: 0
Training loss: 2.1866869914265554
Validation loss: 2.4842448216898156

Epoch: 6| Step: 1
Training loss: 3.109658386505135
Validation loss: 2.478694001747117

Epoch: 6| Step: 2
Training loss: 2.9380805882463106
Validation loss: 2.475070785549349

Epoch: 6| Step: 3
Training loss: 3.2349776291700176
Validation loss: 2.4744054457424287

Epoch: 6| Step: 4
Training loss: 2.7864376079228257
Validation loss: 2.463751004688453

Epoch: 6| Step: 5
Training loss: 2.27393998822932
Validation loss: 2.471908363179463

Epoch: 6| Step: 6
Training loss: 2.582805292450621
Validation loss: 2.473148770387366

Epoch: 6| Step: 7
Training loss: 3.1510341339441643
Validation loss: 2.4707429151708493

Epoch: 6| Step: 8
Training loss: 2.5284670377954823
Validation loss: 2.4723423032098086

Epoch: 6| Step: 9
Training loss: 2.5176141113360946
Validation loss: 2.469453660221445

Epoch: 6| Step: 10
Training loss: 2.7430446404563185
Validation loss: 2.466058073680398

Epoch: 6| Step: 11
Training loss: 2.804239986494642
Validation loss: 2.4699560749771043

Epoch: 6| Step: 12
Training loss: 2.487610635261969
Validation loss: 2.471011679187313

Epoch: 6| Step: 13
Training loss: 2.9190447966799713
Validation loss: 2.46990762913575

Epoch: 180| Step: 0
Training loss: 2.390048786607098
Validation loss: 2.479842361632922

Epoch: 6| Step: 1
Training loss: 2.7367828230962497
Validation loss: 2.471903121101915

Epoch: 6| Step: 2
Training loss: 2.8061354785821933
Validation loss: 2.4741083984111456

Epoch: 6| Step: 3
Training loss: 3.1602066469830326
Validation loss: 2.4827065696089416

Epoch: 6| Step: 4
Training loss: 2.844325416114321
Validation loss: 2.482962242444302

Epoch: 6| Step: 5
Training loss: 2.9692236271556043
Validation loss: 2.505016345557255

Epoch: 6| Step: 6
Training loss: 2.5287125667379087
Validation loss: 2.530762373649054

Epoch: 6| Step: 7
Training loss: 2.6847507697851243
Validation loss: 2.5207799039538146

Epoch: 6| Step: 8
Training loss: 2.9079078129844347
Validation loss: 2.499329552939477

Epoch: 6| Step: 9
Training loss: 3.050893002464654
Validation loss: 2.4721266278412988

Epoch: 6| Step: 10
Training loss: 2.6717979018481754
Validation loss: 2.478151471516546

Epoch: 6| Step: 11
Training loss: 2.349799930902841
Validation loss: 2.4658999374985964

Epoch: 6| Step: 12
Training loss: 2.913004419744447
Validation loss: 2.468801194399148

Epoch: 6| Step: 13
Training loss: 1.9806635834151933
Validation loss: 2.4647244257370455

Epoch: 181| Step: 0
Training loss: 2.819812592981987
Validation loss: 2.4605719452892973

Epoch: 6| Step: 1
Training loss: 2.636290474477407
Validation loss: 2.4695907621157867

Epoch: 6| Step: 2
Training loss: 3.0240353330838823
Validation loss: 2.4731220127517144

Epoch: 6| Step: 3
Training loss: 3.0659369042679514
Validation loss: 2.4839826606726367

Epoch: 6| Step: 4
Training loss: 2.358502965786565
Validation loss: 2.4901942137234956

Epoch: 6| Step: 5
Training loss: 1.8796529257774337
Validation loss: 2.479952398055696

Epoch: 6| Step: 6
Training loss: 2.9296875
Validation loss: 2.481613730786914

Epoch: 6| Step: 7
Training loss: 3.1035500411087327
Validation loss: 2.463823429108772

Epoch: 6| Step: 8
Training loss: 3.127355527033705
Validation loss: 2.467590834050995

Epoch: 6| Step: 9
Training loss: 1.8957689784379173
Validation loss: 2.4686248641661948

Epoch: 6| Step: 10
Training loss: 2.938756308863207
Validation loss: 2.462800702506342

Epoch: 6| Step: 11
Training loss: 2.523235490112251
Validation loss: 2.456937334801993

Epoch: 6| Step: 12
Training loss: 2.426908516761699
Validation loss: 2.4644620507631223

Epoch: 6| Step: 13
Training loss: 3.454520517469137
Validation loss: 2.4593241679495477

Epoch: 182| Step: 0
Training loss: 2.5145940148843873
Validation loss: 2.4540197745657375

Epoch: 6| Step: 1
Training loss: 2.673308049539816
Validation loss: 2.4728060542204826

Epoch: 6| Step: 2
Training loss: 2.7351850781069684
Validation loss: 2.4695691366722645

Epoch: 6| Step: 3
Training loss: 2.5384983785885944
Validation loss: 2.4763713708701256

Epoch: 6| Step: 4
Training loss: 2.8103387794042187
Validation loss: 2.464128683225688

Epoch: 6| Step: 5
Training loss: 3.1938604585839765
Validation loss: 2.487847844203464

Epoch: 6| Step: 6
Training loss: 2.9399866171292217
Validation loss: 2.4918209205834327

Epoch: 6| Step: 7
Training loss: 3.265700635992359
Validation loss: 2.507917089501208

Epoch: 6| Step: 8
Training loss: 2.965961954090165
Validation loss: 2.494659596222689

Epoch: 6| Step: 9
Training loss: 2.1547877564318383
Validation loss: 2.492431180211271

Epoch: 6| Step: 10
Training loss: 2.353783455325793
Validation loss: 2.476517987681817

Epoch: 6| Step: 11
Training loss: 2.975952726768019
Validation loss: 2.4729264201860435

Epoch: 6| Step: 12
Training loss: 2.0717058207626833
Validation loss: 2.465266940886324

Epoch: 6| Step: 13
Training loss: 2.727767197259746
Validation loss: 2.45565077923504

Epoch: 183| Step: 0
Training loss: 2.6667837077523
Validation loss: 2.4603499412180425

Epoch: 6| Step: 1
Training loss: 2.8181194539035648
Validation loss: 2.458088093144668

Epoch: 6| Step: 2
Training loss: 3.1695948330409123
Validation loss: 2.4641220062907165

Epoch: 6| Step: 3
Training loss: 2.6694799028102025
Validation loss: 2.4602834045503914

Epoch: 6| Step: 4
Training loss: 3.0366375424788665
Validation loss: 2.4656331106411984

Epoch: 6| Step: 5
Training loss: 2.4626730959708008
Validation loss: 2.462873031523316

Epoch: 6| Step: 6
Training loss: 2.2185094998534356
Validation loss: 2.4625607237932003

Epoch: 6| Step: 7
Training loss: 2.9700012782444114
Validation loss: 2.4613754109418142

Epoch: 6| Step: 8
Training loss: 1.9963848700494058
Validation loss: 2.467704027995863

Epoch: 6| Step: 9
Training loss: 2.936254034189804
Validation loss: 2.4736159079355566

Epoch: 6| Step: 10
Training loss: 2.8904425486127647
Validation loss: 2.483182699812189

Epoch: 6| Step: 11
Training loss: 3.078147152273953
Validation loss: 2.490555265672224

Epoch: 6| Step: 12
Training loss: 2.1418711800898786
Validation loss: 2.4881992152382417

Epoch: 6| Step: 13
Training loss: 3.4154133862891567
Validation loss: 2.483872058121317

Epoch: 184| Step: 0
Training loss: 2.6151058287932774
Validation loss: 2.480256314684869

Epoch: 6| Step: 1
Training loss: 2.9938588865224873
Validation loss: 2.4703675865481203

Epoch: 6| Step: 2
Training loss: 2.3106723470792305
Validation loss: 2.4666250036485353

Epoch: 6| Step: 3
Training loss: 3.2266058006798657
Validation loss: 2.4716397952038105

Epoch: 6| Step: 4
Training loss: 2.8875247310223378
Validation loss: 2.478048713818648

Epoch: 6| Step: 5
Training loss: 2.1488865608462207
Validation loss: 2.469769876873338

Epoch: 6| Step: 6
Training loss: 3.0430135662417044
Validation loss: 2.4900764995977

Epoch: 6| Step: 7
Training loss: 2.315990803148526
Validation loss: 2.4781344643250347

Epoch: 6| Step: 8
Training loss: 2.4452575092409026
Validation loss: 2.485256066439771

Epoch: 6| Step: 9
Training loss: 2.7744316790678383
Validation loss: 2.490771502628849

Epoch: 6| Step: 10
Training loss: 2.2405027646143685
Validation loss: 2.48482135249069

Epoch: 6| Step: 11
Training loss: 2.473390780481809
Validation loss: 2.5388927671180985

Epoch: 6| Step: 12
Training loss: 3.139021582785372
Validation loss: 2.6164860590638237

Epoch: 6| Step: 13
Training loss: 3.355014543800269
Validation loss: 2.6743743246801985

Epoch: 185| Step: 0
Training loss: 2.8358675525120396
Validation loss: 2.7024178894500026

Epoch: 6| Step: 1
Training loss: 2.4304736665524547
Validation loss: 2.7529056185432723

Epoch: 6| Step: 2
Training loss: 2.823916597150552
Validation loss: 2.740098536496332

Epoch: 6| Step: 3
Training loss: 2.716183733774753
Validation loss: 2.6514639562920377

Epoch: 6| Step: 4
Training loss: 2.331436873813213
Validation loss: 2.58050762913681

Epoch: 6| Step: 5
Training loss: 2.5257336825308405
Validation loss: 2.549724709109717

Epoch: 6| Step: 6
Training loss: 3.514432713405978
Validation loss: 2.5362546559831656

Epoch: 6| Step: 7
Training loss: 2.707084005703245
Validation loss: 2.524871272555579

Epoch: 6| Step: 8
Training loss: 2.3647778020761567
Validation loss: 2.502109610654453

Epoch: 6| Step: 9
Training loss: 2.3756429906102157
Validation loss: 2.4846341392735067

Epoch: 6| Step: 10
Training loss: 2.932708728643291
Validation loss: 2.467276040099558

Epoch: 6| Step: 11
Training loss: 2.8956334619132913
Validation loss: 2.466001674269659

Epoch: 6| Step: 12
Training loss: 3.1728278171241344
Validation loss: 2.478310515177352

Epoch: 6| Step: 13
Training loss: 2.763426860826376
Validation loss: 2.469972745627862

Epoch: 186| Step: 0
Training loss: 2.433006742412414
Validation loss: 2.470632531874794

Epoch: 6| Step: 1
Training loss: 3.255421884271267
Validation loss: 2.4644948645058338

Epoch: 6| Step: 2
Training loss: 2.48970515592876
Validation loss: 2.464409689550177

Epoch: 6| Step: 3
Training loss: 2.0829189905757906
Validation loss: 2.46729428899155

Epoch: 6| Step: 4
Training loss: 2.8148053363822645
Validation loss: 2.466194785855081

Epoch: 6| Step: 5
Training loss: 3.061322355587424
Validation loss: 2.4810489434943093

Epoch: 6| Step: 6
Training loss: 2.6962018743260194
Validation loss: 2.484137560574937

Epoch: 6| Step: 7
Training loss: 2.2191505607835134
Validation loss: 2.50081398540941

Epoch: 6| Step: 8
Training loss: 2.3442182963146516
Validation loss: 2.5126707941477826

Epoch: 6| Step: 9
Training loss: 2.4315824815777023
Validation loss: 2.5104997832431852

Epoch: 6| Step: 10
Training loss: 2.6801463810244135
Validation loss: 2.5030854801761

Epoch: 6| Step: 11
Training loss: 3.1212014572408058
Validation loss: 2.484851346998129

Epoch: 6| Step: 12
Training loss: 2.7469315315826277
Validation loss: 2.471087565991127

Epoch: 6| Step: 13
Training loss: 3.8926496637931978
Validation loss: 2.4438535281222427

Epoch: 187| Step: 0
Training loss: 2.555746156615172
Validation loss: 2.4427784345285395

Epoch: 6| Step: 1
Training loss: 3.1806561168633483
Validation loss: 2.437643907756749

Epoch: 6| Step: 2
Training loss: 2.4841049335448404
Validation loss: 2.4464947245028448

Epoch: 6| Step: 3
Training loss: 2.515155819565041
Validation loss: 2.443333358208412

Epoch: 6| Step: 4
Training loss: 2.961317214170805
Validation loss: 2.449835367051835

Epoch: 6| Step: 5
Training loss: 2.7266535265574063
Validation loss: 2.4483324572693546

Epoch: 6| Step: 6
Training loss: 2.7625815677251886
Validation loss: 2.4561122077543045

Epoch: 6| Step: 7
Training loss: 2.526126149655755
Validation loss: 2.4725936453785438

Epoch: 6| Step: 8
Training loss: 2.2087702288993905
Validation loss: 2.517429921859089

Epoch: 6| Step: 9
Training loss: 2.678832693528013
Validation loss: 2.5590045728451507

Epoch: 6| Step: 10
Training loss: 2.7859919552875163
Validation loss: 2.595385611361245

Epoch: 6| Step: 11
Training loss: 2.8725344825315013
Validation loss: 2.615910214521216

Epoch: 6| Step: 12
Training loss: 3.350319656380083
Validation loss: 2.580430720985985

Epoch: 6| Step: 13
Training loss: 2.8511113058070157
Validation loss: 2.474992725506224

Epoch: 188| Step: 0
Training loss: 2.4612395570454995
Validation loss: 2.4516144624247986

Epoch: 6| Step: 1
Training loss: 1.8155541174704062
Validation loss: 2.445203920053323

Epoch: 6| Step: 2
Training loss: 2.713222365285438
Validation loss: 2.4660307442663694

Epoch: 6| Step: 3
Training loss: 3.316251537726686
Validation loss: 2.480503437115252

Epoch: 6| Step: 4
Training loss: 2.285286663279208
Validation loss: 2.4989659488394738

Epoch: 6| Step: 5
Training loss: 3.136957712916601
Validation loss: 2.486414937563702

Epoch: 6| Step: 6
Training loss: 2.867483513542746
Validation loss: 2.4698310978203155

Epoch: 6| Step: 7
Training loss: 2.5917284337704176
Validation loss: 2.472105737018704

Epoch: 6| Step: 8
Training loss: 3.149106241013075
Validation loss: 2.458701702805322

Epoch: 6| Step: 9
Training loss: 2.7769836964992356
Validation loss: 2.450206321649364

Epoch: 6| Step: 10
Training loss: 3.258263572733092
Validation loss: 2.44896641418397

Epoch: 6| Step: 11
Training loss: 3.1546528618296343
Validation loss: 2.4542770758135877

Epoch: 6| Step: 12
Training loss: 2.428751578180779
Validation loss: 2.457885509168789

Epoch: 6| Step: 13
Training loss: 2.469604633982382
Validation loss: 2.5089726836768764

Epoch: 189| Step: 0
Training loss: 2.3674473383846184
Validation loss: 2.5185768562795587

Epoch: 6| Step: 1
Training loss: 2.7510781342182433
Validation loss: 2.555793376589558

Epoch: 6| Step: 2
Training loss: 3.091522802277142
Validation loss: 2.5688048802755805

Epoch: 6| Step: 3
Training loss: 2.3926082188796167
Validation loss: 2.5754696831918733

Epoch: 6| Step: 4
Training loss: 2.58642370718307
Validation loss: 2.572228766739202

Epoch: 6| Step: 5
Training loss: 2.7776667625707696
Validation loss: 2.5670354819737917

Epoch: 6| Step: 6
Training loss: 2.8920690280384824
Validation loss: 2.568225861274025

Epoch: 6| Step: 7
Training loss: 3.5156852208383906
Validation loss: 2.516315913339838

Epoch: 6| Step: 8
Training loss: 2.794343793946896
Validation loss: 2.495791744973316

Epoch: 6| Step: 9
Training loss: 2.3853038333598944
Validation loss: 2.455493715321097

Epoch: 6| Step: 10
Training loss: 2.6764464059784023
Validation loss: 2.445066672215766

Epoch: 6| Step: 11
Training loss: 2.7877806381116983
Validation loss: 2.4384157444732124

Epoch: 6| Step: 12
Training loss: 2.9303161760363894
Validation loss: 2.436245579977107

Epoch: 6| Step: 13
Training loss: 1.7713910365303103
Validation loss: 2.4359709374481224

Epoch: 190| Step: 0
Training loss: 2.613422840428065
Validation loss: 2.4350258213047113

Epoch: 6| Step: 1
Training loss: 2.7944074433213117
Validation loss: 2.443576447446144

Epoch: 6| Step: 2
Training loss: 2.653671718741945
Validation loss: 2.4415341558606802

Epoch: 6| Step: 3
Training loss: 3.1019179287056873
Validation loss: 2.432700927969726

Epoch: 6| Step: 4
Training loss: 2.613200963359371
Validation loss: 2.4498936057245126

Epoch: 6| Step: 5
Training loss: 2.4159285854243717
Validation loss: 2.4633017355087214

Epoch: 6| Step: 6
Training loss: 2.792434150377032
Validation loss: 2.46986452529081

Epoch: 6| Step: 7
Training loss: 2.9969085023218613
Validation loss: 2.462266137854342

Epoch: 6| Step: 8
Training loss: 2.8827192089833855
Validation loss: 2.4781195663845486

Epoch: 6| Step: 9
Training loss: 2.667254909564137
Validation loss: 2.481612014883865

Epoch: 6| Step: 10
Training loss: 2.678954533019202
Validation loss: 2.4950040242668643

Epoch: 6| Step: 11
Training loss: 2.7886052972380617
Validation loss: 2.488834063089665

Epoch: 6| Step: 12
Training loss: 1.9313201792783339
Validation loss: 2.4730817948992265

Epoch: 6| Step: 13
Training loss: 3.2398945617002815
Validation loss: 2.461603736836509

Epoch: 191| Step: 0
Training loss: 2.7599270848303803
Validation loss: 2.4580764914425934

Epoch: 6| Step: 1
Training loss: 2.6674719329758863
Validation loss: 2.456580515514253

Epoch: 6| Step: 2
Training loss: 3.105803772710852
Validation loss: 2.454622055243122

Epoch: 6| Step: 3
Training loss: 3.2330195586028543
Validation loss: 2.453726160877922

Epoch: 6| Step: 4
Training loss: 2.0361904218468854
Validation loss: 2.4489630271775322

Epoch: 6| Step: 5
Training loss: 2.7299315179193226
Validation loss: 2.4568486124855173

Epoch: 6| Step: 6
Training loss: 3.036377964079418
Validation loss: 2.457395139056083

Epoch: 6| Step: 7
Training loss: 2.635411188373727
Validation loss: 2.4668408653982294

Epoch: 6| Step: 8
Training loss: 2.500826126930593
Validation loss: 2.465580454048252

Epoch: 6| Step: 9
Training loss: 2.3767143888172053
Validation loss: 2.474383600251624

Epoch: 6| Step: 10
Training loss: 2.359911927018399
Validation loss: 2.484659613204734

Epoch: 6| Step: 11
Training loss: 3.021155785199165
Validation loss: 2.488144009066682

Epoch: 6| Step: 12
Training loss: 2.4166484919774445
Validation loss: 2.510879111141213

Epoch: 6| Step: 13
Training loss: 2.654670604811461
Validation loss: 2.5420131706041884

Epoch: 192| Step: 0
Training loss: 2.319037192930994
Validation loss: 2.5452028793899957

Epoch: 6| Step: 1
Training loss: 2.681590658390553
Validation loss: 2.5697344521981957

Epoch: 6| Step: 2
Training loss: 2.0415641084200766
Validation loss: 2.583676844955582

Epoch: 6| Step: 3
Training loss: 2.6258356489943893
Validation loss: 2.570568419197557

Epoch: 6| Step: 4
Training loss: 2.8604297464455555
Validation loss: 2.530718092366591

Epoch: 6| Step: 5
Training loss: 2.9027997938311914
Validation loss: 2.5383620721742792

Epoch: 6| Step: 6
Training loss: 3.066746472965015
Validation loss: 2.5356108244348894

Epoch: 6| Step: 7
Training loss: 2.376195606650613
Validation loss: 2.5280384293841855

Epoch: 6| Step: 8
Training loss: 2.266193818344372
Validation loss: 2.53179790502444

Epoch: 6| Step: 9
Training loss: 3.4344342519076223
Validation loss: 2.5447324952236885

Epoch: 6| Step: 10
Training loss: 3.157226713530386
Validation loss: 2.521156396777725

Epoch: 6| Step: 11
Training loss: 3.0039052975656815
Validation loss: 2.5076321195273255

Epoch: 6| Step: 12
Training loss: 2.8514778856239
Validation loss: 2.5077957512086

Epoch: 6| Step: 13
Training loss: 3.2370999416776844
Validation loss: 2.5056774092614345

Epoch: 193| Step: 0
Training loss: 2.430093222348768
Validation loss: 2.4981460239245386

Epoch: 6| Step: 1
Training loss: 2.672581094166278
Validation loss: 2.500097265709956

Epoch: 6| Step: 2
Training loss: 2.645700125957993
Validation loss: 2.4898538406904662

Epoch: 6| Step: 3
Training loss: 2.821181229550534
Validation loss: 2.4997673490415973

Epoch: 6| Step: 4
Training loss: 2.7329669051610943
Validation loss: 2.509718275511338

Epoch: 6| Step: 5
Training loss: 2.99250795725033
Validation loss: 2.5390938846992794

Epoch: 6| Step: 6
Training loss: 2.3551725641026096
Validation loss: 2.5670181898142466

Epoch: 6| Step: 7
Training loss: 2.926816627234786
Validation loss: 2.5689676132982635

Epoch: 6| Step: 8
Training loss: 2.191893824226468
Validation loss: 2.629105699617995

Epoch: 6| Step: 9
Training loss: 2.5547263232906303
Validation loss: 2.6555371084874166

Epoch: 6| Step: 10
Training loss: 2.942146360137064
Validation loss: 2.697896578101822

Epoch: 6| Step: 11
Training loss: 3.1241444751775207
Validation loss: 2.687631376336348

Epoch: 6| Step: 12
Training loss: 2.909599588905874
Validation loss: 2.6287301062473745

Epoch: 6| Step: 13
Training loss: 3.3641661079210357
Validation loss: 2.613918907525507

Epoch: 194| Step: 0
Training loss: 2.773038851603717
Validation loss: 2.571534769676648

Epoch: 6| Step: 1
Training loss: 2.987041460544483
Validation loss: 2.548033395935969

Epoch: 6| Step: 2
Training loss: 2.5295398727987295
Validation loss: 2.5351130071679946

Epoch: 6| Step: 3
Training loss: 2.6893673996016765
Validation loss: 2.5257510396205274

Epoch: 6| Step: 4
Training loss: 3.038793243012643
Validation loss: 2.5252724866308074

Epoch: 6| Step: 5
Training loss: 2.791016650082912
Validation loss: 2.5165651368842084

Epoch: 6| Step: 6
Training loss: 2.7541193886381468
Validation loss: 2.5027209200661185

Epoch: 6| Step: 7
Training loss: 2.92683780676674
Validation loss: 2.497612791718626

Epoch: 6| Step: 8
Training loss: 2.573901792239982
Validation loss: 2.493954065607687

Epoch: 6| Step: 9
Training loss: 2.1567164483238077
Validation loss: 2.4815819078753445

Epoch: 6| Step: 10
Training loss: 2.8853540149777195
Validation loss: 2.4780375924881755

Epoch: 6| Step: 11
Training loss: 3.044916080765414
Validation loss: 2.480424805951892

Epoch: 6| Step: 12
Training loss: 2.652710115414215
Validation loss: 2.485529473412846

Epoch: 6| Step: 13
Training loss: 2.119094271526449
Validation loss: 2.480985411938684

Epoch: 195| Step: 0
Training loss: 2.9196700481916817
Validation loss: 2.483230525334173

Epoch: 6| Step: 1
Training loss: 2.6592419099059774
Validation loss: 2.4915962033404018

Epoch: 6| Step: 2
Training loss: 3.0158696050712273
Validation loss: 2.4882986937063567

Epoch: 6| Step: 3
Training loss: 2.551165564942051
Validation loss: 2.4977707773494076

Epoch: 6| Step: 4
Training loss: 2.9299470913637533
Validation loss: 2.5317871605458024

Epoch: 6| Step: 5
Training loss: 2.716303722343623
Validation loss: 2.554426127872627

Epoch: 6| Step: 6
Training loss: 2.340008508552667
Validation loss: 2.568647791904446

Epoch: 6| Step: 7
Training loss: 3.1964313814557292
Validation loss: 2.5819305603332694

Epoch: 6| Step: 8
Training loss: 2.55351206951527
Validation loss: 2.5698159352167647

Epoch: 6| Step: 9
Training loss: 2.7306884327979644
Validation loss: 2.566370037809378

Epoch: 6| Step: 10
Training loss: 3.0009868905919737
Validation loss: 2.5376891677446443

Epoch: 6| Step: 11
Training loss: 2.747810011946854
Validation loss: 2.5132162038681587

Epoch: 6| Step: 12
Training loss: 2.098806964221623
Validation loss: 2.4980130287812647

Epoch: 6| Step: 13
Training loss: 2.4055027978215175
Validation loss: 2.49420710438677

Epoch: 196| Step: 0
Training loss: 2.8218091549378155
Validation loss: 2.482720884489366

Epoch: 6| Step: 1
Training loss: 2.95419953995579
Validation loss: 2.482309752388989

Epoch: 6| Step: 2
Training loss: 2.8611263060757817
Validation loss: 2.489738331498618

Epoch: 6| Step: 3
Training loss: 2.7961465750109227
Validation loss: 2.475320209635164

Epoch: 6| Step: 4
Training loss: 2.4986439842034605
Validation loss: 2.473329894335972

Epoch: 6| Step: 5
Training loss: 2.9763600037747975
Validation loss: 2.4765266924908773

Epoch: 6| Step: 6
Training loss: 2.629116373039546
Validation loss: 2.464636822118343

Epoch: 6| Step: 7
Training loss: 1.7099306113681836
Validation loss: 2.4754068220720744

Epoch: 6| Step: 8
Training loss: 3.0599209572051467
Validation loss: 2.4696802318464424

Epoch: 6| Step: 9
Training loss: 2.2570423541880276
Validation loss: 2.4895406214696814

Epoch: 6| Step: 10
Training loss: 2.2324340499585986
Validation loss: 2.5037189632640673

Epoch: 6| Step: 11
Training loss: 2.6807442852864023
Validation loss: 2.5552552479083688

Epoch: 6| Step: 12
Training loss: 2.1589750678640196
Validation loss: 2.5939386612751916

Epoch: 6| Step: 13
Training loss: 3.50922486008696
Validation loss: 2.608544695849022

Epoch: 197| Step: 0
Training loss: 2.600697783221988
Validation loss: 2.6543634856293106

Epoch: 6| Step: 1
Training loss: 2.6403237797408927
Validation loss: 2.637096205127985

Epoch: 6| Step: 2
Training loss: 3.2154203803944905
Validation loss: 2.604115433383798

Epoch: 6| Step: 3
Training loss: 2.992531699360875
Validation loss: 2.546624330422031

Epoch: 6| Step: 4
Training loss: 2.5008320377511324
Validation loss: 2.5306037220598925

Epoch: 6| Step: 5
Training loss: 1.7435294828818417
Validation loss: 2.531044013158252

Epoch: 6| Step: 6
Training loss: 2.743785772763845
Validation loss: 2.544217349003407

Epoch: 6| Step: 7
Training loss: 2.76565206913174
Validation loss: 2.545647946689641

Epoch: 6| Step: 8
Training loss: 2.3853817955255727
Validation loss: 2.5458440616038502

Epoch: 6| Step: 9
Training loss: 3.566669099278081
Validation loss: 2.560722556990619

Epoch: 6| Step: 10
Training loss: 2.9293254984683013
Validation loss: 2.557188766097077

Epoch: 6| Step: 11
Training loss: 2.7668895524415418
Validation loss: 2.5466017041389906

Epoch: 6| Step: 12
Training loss: 2.018768579734123
Validation loss: 2.542388749563522

Epoch: 6| Step: 13
Training loss: 3.270493378355353
Validation loss: 2.5361101148541443

Epoch: 198| Step: 0
Training loss: 2.736002236237086
Validation loss: 2.51838578652742

Epoch: 6| Step: 1
Training loss: 2.4969852389753706
Validation loss: 2.5269200308253494

Epoch: 6| Step: 2
Training loss: 2.435505760353652
Validation loss: 2.5121794482108206

Epoch: 6| Step: 3
Training loss: 2.6081393851261274
Validation loss: 2.5108150672734872

Epoch: 6| Step: 4
Training loss: 2.8553712256772816
Validation loss: 2.526031877409718

Epoch: 6| Step: 5
Training loss: 2.4008856093084434
Validation loss: 2.5537551122204687

Epoch: 6| Step: 6
Training loss: 2.402202124414036
Validation loss: 2.5863348304895575

Epoch: 6| Step: 7
Training loss: 3.5144325777262804
Validation loss: 2.5677642812842305

Epoch: 6| Step: 8
Training loss: 2.79215272306485
Validation loss: 2.5621152639507017

Epoch: 6| Step: 9
Training loss: 2.5314680405885515
Validation loss: 2.5454815262808324

Epoch: 6| Step: 10
Training loss: 2.5208853934300706
Validation loss: 2.525196475399009

Epoch: 6| Step: 11
Training loss: 2.838809742065845
Validation loss: 2.5028024491427208

Epoch: 6| Step: 12
Training loss: 2.390973932070685
Validation loss: 2.4782429255841056

Epoch: 6| Step: 13
Training loss: 2.3356198506327868
Validation loss: 2.479271324418714

Epoch: 199| Step: 0
Training loss: 2.470912613864607
Validation loss: 2.480531147598437

Epoch: 6| Step: 1
Training loss: 2.651401897505304
Validation loss: 2.479134209298817

Epoch: 6| Step: 2
Training loss: 2.238557648694154
Validation loss: 2.490348829695019

Epoch: 6| Step: 3
Training loss: 2.3860895354489946
Validation loss: 2.5027937373877998

Epoch: 6| Step: 4
Training loss: 2.781444928485508
Validation loss: 2.515848047865689

Epoch: 6| Step: 5
Training loss: 2.63117962015946
Validation loss: 2.514821190049808

Epoch: 6| Step: 6
Training loss: 2.4721090907620598
Validation loss: 2.506554798659665

Epoch: 6| Step: 7
Training loss: 3.1626837092782583
Validation loss: 2.4952073570526228

Epoch: 6| Step: 8
Training loss: 3.2109416581101424
Validation loss: 2.493937339904022

Epoch: 6| Step: 9
Training loss: 2.7311670286377345
Validation loss: 2.4910060239553964

Epoch: 6| Step: 10
Training loss: 2.552825715956215
Validation loss: 2.4960569367797816

Epoch: 6| Step: 11
Training loss: 2.048543468443384
Validation loss: 2.4948195435070764

Epoch: 6| Step: 12
Training loss: 2.7654504235982316
Validation loss: 2.5073897601844775

Epoch: 6| Step: 13
Training loss: 3.324179302837702
Validation loss: 2.498715168981452

Epoch: 200| Step: 0
Training loss: 2.411750945978304
Validation loss: 2.507263974126811

Epoch: 6| Step: 1
Training loss: 2.483006130227838
Validation loss: 2.5146050367264845

Epoch: 6| Step: 2
Training loss: 2.707748252075634
Validation loss: 2.5179998965339214

Epoch: 6| Step: 3
Training loss: 2.388598212465475
Validation loss: 2.5000333937598893

Epoch: 6| Step: 4
Training loss: 2.924198634256553
Validation loss: 2.493193201386158

Epoch: 6| Step: 5
Training loss: 2.4466233320149153
Validation loss: 2.4941857283500046

Epoch: 6| Step: 6
Training loss: 2.3543174042731527
Validation loss: 2.4869916337782105

Epoch: 6| Step: 7
Training loss: 2.876829311713316
Validation loss: 2.4846212892274853

Epoch: 6| Step: 8
Training loss: 2.4075001033097636
Validation loss: 2.4740267532464193

Epoch: 6| Step: 9
Training loss: 2.6023296336349717
Validation loss: 2.483020764478976

Epoch: 6| Step: 10
Training loss: 2.762103408722873
Validation loss: 2.490075673904139

Epoch: 6| Step: 11
Training loss: 2.8664734494350226
Validation loss: 2.4890631727301105

Epoch: 6| Step: 12
Training loss: 2.5810957929532803
Validation loss: 2.489613335170752

Epoch: 6| Step: 13
Training loss: 3.1434348522902877
Validation loss: 2.4974600358643584

Epoch: 201| Step: 0
Training loss: 2.7539581943239413
Validation loss: 2.491298417552678

Epoch: 6| Step: 1
Training loss: 2.5586785455295136
Validation loss: 2.5017858566546316

Epoch: 6| Step: 2
Training loss: 2.7597324507029466
Validation loss: 2.497830008030805

Epoch: 6| Step: 3
Training loss: 1.925826190168778
Validation loss: 2.4878164704620485

Epoch: 6| Step: 4
Training loss: 2.3782761714974563
Validation loss: 2.4905667217411676

Epoch: 6| Step: 5
Training loss: 2.891271735347549
Validation loss: 2.4843730135808015

Epoch: 6| Step: 6
Training loss: 2.426912839301286
Validation loss: 2.499406285696915

Epoch: 6| Step: 7
Training loss: 2.693794685577287
Validation loss: 2.4979243326819134

Epoch: 6| Step: 8
Training loss: 2.2737626829627224
Validation loss: 2.491217507100346

Epoch: 6| Step: 9
Training loss: 2.8299965751276757
Validation loss: 2.486340337259843

Epoch: 6| Step: 10
Training loss: 2.4277809242947828
Validation loss: 2.514870487344928

Epoch: 6| Step: 11
Training loss: 2.8356548410165106
Validation loss: 2.516633577733005

Epoch: 6| Step: 12
Training loss: 3.0992335264114756
Validation loss: 2.5065255614538184

Epoch: 6| Step: 13
Training loss: 2.3409029134818686
Validation loss: 2.5117148132655704

Epoch: 202| Step: 0
Training loss: 2.336431444693371
Validation loss: 2.5154477276534757

Epoch: 6| Step: 1
Training loss: 2.709400543831658
Validation loss: 2.505293422670653

Epoch: 6| Step: 2
Training loss: 2.1231738827220896
Validation loss: 2.532671821906535

Epoch: 6| Step: 3
Training loss: 2.3964808929592163
Validation loss: 2.5566511226422772

Epoch: 6| Step: 4
Training loss: 2.8072413980846678
Validation loss: 2.562280626008313

Epoch: 6| Step: 5
Training loss: 2.8580686159326034
Validation loss: 2.5659605430768586

Epoch: 6| Step: 6
Training loss: 2.634446901763338
Validation loss: 2.544218580332208

Epoch: 6| Step: 7
Training loss: 3.1473586740193444
Validation loss: 2.558149138164873

Epoch: 6| Step: 8
Training loss: 2.870610244417379
Validation loss: 2.562033057719801

Epoch: 6| Step: 9
Training loss: 2.582570999218302
Validation loss: 2.5532910076012074

Epoch: 6| Step: 10
Training loss: 2.4399606071481594
Validation loss: 2.525700952361331

Epoch: 6| Step: 11
Training loss: 1.8764849186979116
Validation loss: 2.5144638391046987

Epoch: 6| Step: 12
Training loss: 2.8742605170543363
Validation loss: 2.505835844544921

Epoch: 6| Step: 13
Training loss: 2.977277534687468
Validation loss: 2.4889231784097903

Epoch: 203| Step: 0
Training loss: 2.0026401736458044
Validation loss: 2.4957976194392324

Epoch: 6| Step: 1
Training loss: 2.7285353728817396
Validation loss: 2.49735167831509

Epoch: 6| Step: 2
Training loss: 2.688960632132506
Validation loss: 2.488281823869079

Epoch: 6| Step: 3
Training loss: 2.2567616693548493
Validation loss: 2.473406820086433

Epoch: 6| Step: 4
Training loss: 2.605798337299034
Validation loss: 2.4767876238038733

Epoch: 6| Step: 5
Training loss: 2.742818993348529
Validation loss: 2.48079713781414

Epoch: 6| Step: 6
Training loss: 2.758934765234285
Validation loss: 2.5022750367796656

Epoch: 6| Step: 7
Training loss: 2.9915638565065183
Validation loss: 2.51902981946843

Epoch: 6| Step: 8
Training loss: 2.1554829435582885
Validation loss: 2.5601606067578078

Epoch: 6| Step: 9
Training loss: 2.322088929457133
Validation loss: 2.583019103179025

Epoch: 6| Step: 10
Training loss: 2.4310026381308436
Validation loss: 2.59803327966492

Epoch: 6| Step: 11
Training loss: 3.132159766788326
Validation loss: 2.582180777980578

Epoch: 6| Step: 12
Training loss: 2.705642586217146
Validation loss: 2.60485042299658

Epoch: 6| Step: 13
Training loss: 3.1296446806349065
Validation loss: 2.581879600393132

Epoch: 204| Step: 0
Training loss: 2.2491902907738437
Validation loss: 2.5555466545054593

Epoch: 6| Step: 1
Training loss: 3.0253200141049774
Validation loss: 2.525256473930332

Epoch: 6| Step: 2
Training loss: 2.4621387274770457
Validation loss: 2.5204423787531445

Epoch: 6| Step: 3
Training loss: 3.2385389273799494
Validation loss: 2.526966691753946

Epoch: 6| Step: 4
Training loss: 1.560413493351411
Validation loss: 2.522018190432729

Epoch: 6| Step: 5
Training loss: 2.2630143481923644
Validation loss: 2.522839568479828

Epoch: 6| Step: 6
Training loss: 2.5179602168048376
Validation loss: 2.5325178624512117

Epoch: 6| Step: 7
Training loss: 2.8137587379648656
Validation loss: 2.519727407026236

Epoch: 6| Step: 8
Training loss: 2.6108124023273835
Validation loss: 2.5303715171850762

Epoch: 6| Step: 9
Training loss: 2.5369242423673652
Validation loss: 2.5544407323238874

Epoch: 6| Step: 10
Training loss: 3.0154301871983686
Validation loss: 2.5953485045775175

Epoch: 6| Step: 11
Training loss: 2.5912502146388183
Validation loss: 2.5963462766687764

Epoch: 6| Step: 12
Training loss: 2.5673413946236
Validation loss: 2.584237912518954

Epoch: 6| Step: 13
Training loss: 2.8114717087221974
Validation loss: 2.571767464586324

Epoch: 205| Step: 0
Training loss: 2.568275084762289
Validation loss: 2.55559699394398

Epoch: 6| Step: 1
Training loss: 1.8250650733947116
Validation loss: 2.5354793091262517

Epoch: 6| Step: 2
Training loss: 1.9251678913768542
Validation loss: 2.5338883570234723

Epoch: 6| Step: 3
Training loss: 2.6533552665219258
Validation loss: 2.540080652047335

Epoch: 6| Step: 4
Training loss: 2.5249520589979597
Validation loss: 2.5355081871860947

Epoch: 6| Step: 5
Training loss: 3.138082661421938
Validation loss: 2.5175603953796832

Epoch: 6| Step: 6
Training loss: 2.7765505230698437
Validation loss: 2.5305192349056003

Epoch: 6| Step: 7
Training loss: 2.642905881056733
Validation loss: 2.5263603358732336

Epoch: 6| Step: 8
Training loss: 2.4084430955559757
Validation loss: 2.532111568823389

Epoch: 6| Step: 9
Training loss: 2.4752357370643563
Validation loss: 2.530938952157668

Epoch: 6| Step: 10
Training loss: 2.854173776288239
Validation loss: 2.5324636325225844

Epoch: 6| Step: 11
Training loss: 2.5843043399547176
Validation loss: 2.5320290820282483

Epoch: 6| Step: 12
Training loss: 2.8291045963480452
Validation loss: 2.5189692344919754

Epoch: 6| Step: 13
Training loss: 2.003183453877886
Validation loss: 2.5137811526372387

Epoch: 206| Step: 0
Training loss: 1.9829150258304833
Validation loss: 2.5150151329716306

Epoch: 6| Step: 1
Training loss: 2.4124403753472774
Validation loss: 2.5179359085511925

Epoch: 6| Step: 2
Training loss: 2.983140300565236
Validation loss: 2.507656339554066

Epoch: 6| Step: 3
Training loss: 2.158577809670152
Validation loss: 2.501566436150207

Epoch: 6| Step: 4
Training loss: 2.8584419771090377
Validation loss: 2.4842925710399637

Epoch: 6| Step: 5
Training loss: 2.0821968284740335
Validation loss: 2.4881621358170816

Epoch: 6| Step: 6
Training loss: 2.644773396121773
Validation loss: 2.513983133954963

Epoch: 6| Step: 7
Training loss: 2.2514496477847357
Validation loss: 2.521488951247287

Epoch: 6| Step: 8
Training loss: 2.2905537301460615
Validation loss: 2.560357727762431

Epoch: 6| Step: 9
Training loss: 3.0906615591635096
Validation loss: 2.521523343498072

Epoch: 6| Step: 10
Training loss: 2.3452105231228417
Validation loss: 2.4790487332901816

Epoch: 6| Step: 11
Training loss: 2.8493377786202116
Validation loss: 2.4604563398791153

Epoch: 6| Step: 12
Training loss: 2.8483207774978365
Validation loss: 2.4715607223118594

Epoch: 6| Step: 13
Training loss: 2.4370269316326665
Validation loss: 2.4762975301851853

Epoch: 207| Step: 0
Training loss: 2.2610522195622558
Validation loss: 2.4810274034578605

Epoch: 6| Step: 1
Training loss: 3.000218860272312
Validation loss: 2.494668363615916

Epoch: 6| Step: 2
Training loss: 2.455418383342411
Validation loss: 2.4974068657212443

Epoch: 6| Step: 3
Training loss: 2.450938228094909
Validation loss: 2.505263112650164

Epoch: 6| Step: 4
Training loss: 2.5308192322201792
Validation loss: 2.5343567420687516

Epoch: 6| Step: 5
Training loss: 2.691262118130203
Validation loss: 2.5659666975001674

Epoch: 6| Step: 6
Training loss: 2.616731518551233
Validation loss: 2.5953493353027266

Epoch: 6| Step: 7
Training loss: 2.3733511772806533
Validation loss: 2.6170083565179327

Epoch: 6| Step: 8
Training loss: 2.5381911440536626
Validation loss: 2.6288426201112554

Epoch: 6| Step: 9
Training loss: 2.517362859148025
Validation loss: 2.61785804265558

Epoch: 6| Step: 10
Training loss: 2.1242670029171515
Validation loss: 2.590714795023093

Epoch: 6| Step: 11
Training loss: 3.2539269124962957
Validation loss: 2.581185022857375

Epoch: 6| Step: 12
Training loss: 2.3404959914302093
Validation loss: 2.5599564514971322

Epoch: 6| Step: 13
Training loss: 2.7625892486654693
Validation loss: 2.532387671619816

Epoch: 208| Step: 0
Training loss: 2.01927882965239
Validation loss: 2.4998672880818282

Epoch: 6| Step: 1
Training loss: 1.9508975946444316
Validation loss: 2.5009342037587383

Epoch: 6| Step: 2
Training loss: 2.2475736038664813
Validation loss: 2.5021071823710446

Epoch: 6| Step: 3
Training loss: 2.791077812681924
Validation loss: 2.4975881622562217

Epoch: 6| Step: 4
Training loss: 2.3452280089060262
Validation loss: 2.4941995713512988

Epoch: 6| Step: 5
Training loss: 2.0411237916164313
Validation loss: 2.494697579473842

Epoch: 6| Step: 6
Training loss: 2.234323354270914
Validation loss: 2.492545105137472

Epoch: 6| Step: 7
Training loss: 2.396926254659471
Validation loss: 2.482613082519467

Epoch: 6| Step: 8
Training loss: 2.719929757052704
Validation loss: 2.4959419200845154

Epoch: 6| Step: 9
Training loss: 2.9708650784359123
Validation loss: 2.499150855947073

Epoch: 6| Step: 10
Training loss: 2.720030647413715
Validation loss: 2.4960884750089396

Epoch: 6| Step: 11
Training loss: 2.804183362105286
Validation loss: 2.522943376512356

Epoch: 6| Step: 12
Training loss: 3.0609776352592206
Validation loss: 2.5281158138828075

Epoch: 6| Step: 13
Training loss: 2.1093398479782244
Validation loss: 2.534777426941443

Epoch: 209| Step: 0
Training loss: 2.4353215190574082
Validation loss: 2.545393493202114

Epoch: 6| Step: 1
Training loss: 1.7317347319623655
Validation loss: 2.5370182786199527

Epoch: 6| Step: 2
Training loss: 2.186816299405085
Validation loss: 2.5248480654953673

Epoch: 6| Step: 3
Training loss: 2.1843704725663358
Validation loss: 2.5380243811594947

Epoch: 6| Step: 4
Training loss: 2.2326507317555393
Validation loss: 2.573957735711801

Epoch: 6| Step: 5
Training loss: 2.4715388516770522
Validation loss: 2.55124619905197

Epoch: 6| Step: 6
Training loss: 2.9914275715811045
Validation loss: 2.569139797734667

Epoch: 6| Step: 7
Training loss: 2.750065282566966
Validation loss: 2.5755334262786187

Epoch: 6| Step: 8
Training loss: 2.239353741846479
Validation loss: 2.546790572975979

Epoch: 6| Step: 9
Training loss: 3.1010029862237873
Validation loss: 2.5342822895329773

Epoch: 6| Step: 10
Training loss: 2.17482727066463
Validation loss: 2.5195625513728177

Epoch: 6| Step: 11
Training loss: 3.037637175300014
Validation loss: 2.5337094727446234

Epoch: 6| Step: 12
Training loss: 2.603830992363366
Validation loss: 2.5319588449923596

Epoch: 6| Step: 13
Training loss: 2.6708007794646287
Validation loss: 2.5325035982430633

Epoch: 210| Step: 0
Training loss: 2.9800581943026994
Validation loss: 2.5291942744608193

Epoch: 6| Step: 1
Training loss: 1.9912581127166715
Validation loss: 2.527171548124515

Epoch: 6| Step: 2
Training loss: 1.9447768366254525
Validation loss: 2.557181461703833

Epoch: 6| Step: 3
Training loss: 2.2307336118874863
Validation loss: 2.5552336531834383

Epoch: 6| Step: 4
Training loss: 2.8482077735590683
Validation loss: 2.580792336151134

Epoch: 6| Step: 5
Training loss: 2.1492377992740517
Validation loss: 2.572917913488317

Epoch: 6| Step: 6
Training loss: 2.477855356947292
Validation loss: 2.5478093652663714

Epoch: 6| Step: 7
Training loss: 2.671597293453613
Validation loss: 2.5305760401818893

Epoch: 6| Step: 8
Training loss: 2.8076372281893445
Validation loss: 2.4987023769859262

Epoch: 6| Step: 9
Training loss: 2.240914864192379
Validation loss: 2.4834698135846875

Epoch: 6| Step: 10
Training loss: 2.6785231304355617
Validation loss: 2.4915647049672933

Epoch: 6| Step: 11
Training loss: 2.37894192874004
Validation loss: 2.4871473600293226

Epoch: 6| Step: 12
Training loss: 2.8405478757621867
Validation loss: 2.4938122569491425

Epoch: 6| Step: 13
Training loss: 2.119676091623066
Validation loss: 2.4877355817608264

Epoch: 211| Step: 0
Training loss: 2.823821613675229
Validation loss: 2.502158759833586

Epoch: 6| Step: 1
Training loss: 2.887362892231516
Validation loss: 2.4974848605967286

Epoch: 6| Step: 2
Training loss: 2.289905900479436
Validation loss: 2.5087436024348375

Epoch: 6| Step: 3
Training loss: 2.6434817238903388
Validation loss: 2.5246798028520367

Epoch: 6| Step: 4
Training loss: 2.5698004215391843
Validation loss: 2.527250675530831

Epoch: 6| Step: 5
Training loss: 2.1740029428386687
Validation loss: 2.5530339087803577

Epoch: 6| Step: 6
Training loss: 1.8783842698067328
Validation loss: 2.5265560342370095

Epoch: 6| Step: 7
Training loss: 2.3844812771971413
Validation loss: 2.5180837204893973

Epoch: 6| Step: 8
Training loss: 3.086736879751712
Validation loss: 2.5130828780052914

Epoch: 6| Step: 9
Training loss: 2.6812670976142567
Validation loss: 2.495935164684022

Epoch: 6| Step: 10
Training loss: 1.7903917863108565
Validation loss: 2.51108664901585

Epoch: 6| Step: 11
Training loss: 2.280844874531103
Validation loss: 2.516497604922027

Epoch: 6| Step: 12
Training loss: 2.5959214462421265
Validation loss: 2.525851958677965

Epoch: 6| Step: 13
Training loss: 1.3969260630992577
Validation loss: 2.523136979610719

Epoch: 212| Step: 0
Training loss: 2.3674952744433764
Validation loss: 2.541979243664189

Epoch: 6| Step: 1
Training loss: 2.6398363910898746
Validation loss: 2.5813107483664273

Epoch: 6| Step: 2
Training loss: 2.0077500389269165
Validation loss: 2.5658933000450164

Epoch: 6| Step: 3
Training loss: 2.187896801518074
Validation loss: 2.525133605333379

Epoch: 6| Step: 4
Training loss: 2.5564848850220474
Validation loss: 2.5054162768277677

Epoch: 6| Step: 5
Training loss: 2.4267682265244357
Validation loss: 2.5089281966339274

Epoch: 6| Step: 6
Training loss: 2.477572262323131
Validation loss: 2.5139854120810603

Epoch: 6| Step: 7
Training loss: 2.536643416423073
Validation loss: 2.524018622324201

Epoch: 6| Step: 8
Training loss: 2.714576675121918
Validation loss: 2.5362471002583296

Epoch: 6| Step: 9
Training loss: 2.6658881859135994
Validation loss: 2.544080261703512

Epoch: 6| Step: 10
Training loss: 2.269362740490115
Validation loss: 2.5605172530816076

Epoch: 6| Step: 11
Training loss: 2.581910561930988
Validation loss: 2.6003582052940373

Epoch: 6| Step: 12
Training loss: 2.7521955222269217
Validation loss: 2.634060450203613

Epoch: 6| Step: 13
Training loss: 1.334988440988626
Validation loss: 2.666521934329673

Epoch: 213| Step: 0
Training loss: 2.915868777175682
Validation loss: 2.6616510231939725

Epoch: 6| Step: 1
Training loss: 2.0073463700393868
Validation loss: 2.6586794046972386

Epoch: 6| Step: 2
Training loss: 2.657697754299847
Validation loss: 2.6081904659742903

Epoch: 6| Step: 3
Training loss: 2.771819338406308
Validation loss: 2.5318393666803485

Epoch: 6| Step: 4
Training loss: 2.2251359619432924
Validation loss: 2.4711631931837377

Epoch: 6| Step: 5
Training loss: 1.9414721349209312
Validation loss: 2.4482554347719

Epoch: 6| Step: 6
Training loss: 2.5208625056152503
Validation loss: 2.454205405389192

Epoch: 6| Step: 7
Training loss: 2.40468377998565
Validation loss: 2.4473112423686834

Epoch: 6| Step: 8
Training loss: 2.399313602044512
Validation loss: 2.4402404033397893

Epoch: 6| Step: 9
Training loss: 2.4589693464406217
Validation loss: 2.4433811789060838

Epoch: 6| Step: 10
Training loss: 2.430864055370966
Validation loss: 2.448807132401641

Epoch: 6| Step: 11
Training loss: 2.235575960094412
Validation loss: 2.4395706294402677

Epoch: 6| Step: 12
Training loss: 2.924803709307015
Validation loss: 2.456967698409751

Epoch: 6| Step: 13
Training loss: 2.6373321949879522
Validation loss: 2.499142413560325

Epoch: 214| Step: 0
Training loss: 2.8219407049663876
Validation loss: 2.482783880134443

Epoch: 6| Step: 1
Training loss: 3.152585158623482
Validation loss: 2.4709693524983454

Epoch: 6| Step: 2
Training loss: 2.129156983335489
Validation loss: 2.480661782254993

Epoch: 6| Step: 3
Training loss: 2.078340676954195
Validation loss: 2.466781848309629

Epoch: 6| Step: 4
Training loss: 2.442319653352946
Validation loss: 2.4621724337851707

Epoch: 6| Step: 5
Training loss: 2.539481260539608
Validation loss: 2.480883154997943

Epoch: 6| Step: 6
Training loss: 2.3609403760426724
Validation loss: 2.502090821622075

Epoch: 6| Step: 7
Training loss: 2.231577796258601
Validation loss: 2.521110045228305

Epoch: 6| Step: 8
Training loss: 2.4164117042832682
Validation loss: 2.5485017303399955

Epoch: 6| Step: 9
Training loss: 2.3186644792851725
Validation loss: 2.5538337351888445

Epoch: 6| Step: 10
Training loss: 2.3598395894378963
Validation loss: 2.573890670730503

Epoch: 6| Step: 11
Training loss: 2.124912484554741
Validation loss: 2.5730348964823277

Epoch: 6| Step: 12
Training loss: 2.3974705837700543
Validation loss: 2.5556263619203015

Epoch: 6| Step: 13
Training loss: 2.063313410492801
Validation loss: 2.5277445330937787

Epoch: 215| Step: 0
Training loss: 2.0000355240527967
Validation loss: 2.5257574772581863

Epoch: 6| Step: 1
Training loss: 2.8033632855472717
Validation loss: 2.5031981828215923

Epoch: 6| Step: 2
Training loss: 2.25911160486265
Validation loss: 2.48966507364093

Epoch: 6| Step: 3
Training loss: 2.178551162339584
Validation loss: 2.4758005597584676

Epoch: 6| Step: 4
Training loss: 2.325557445025761
Validation loss: 2.469076615547187

Epoch: 6| Step: 5
Training loss: 2.268414483600645
Validation loss: 2.475901965809772

Epoch: 6| Step: 6
Training loss: 2.2173524135258793
Validation loss: 2.464935082104921

Epoch: 6| Step: 7
Training loss: 2.827918450837542
Validation loss: 2.4450462406289564

Epoch: 6| Step: 8
Training loss: 1.9983754712843522
Validation loss: 2.457490513400966

Epoch: 6| Step: 9
Training loss: 2.0502366278316604
Validation loss: 2.4532758745926846

Epoch: 6| Step: 10
Training loss: 2.235589184344849
Validation loss: 2.4428376206608373

Epoch: 6| Step: 11
Training loss: 2.958583086960089
Validation loss: 2.452742638307575

Epoch: 6| Step: 12
Training loss: 2.5824349184504585
Validation loss: 2.465229817078505

Epoch: 6| Step: 13
Training loss: 2.872481196435749
Validation loss: 2.4872077182731434

Epoch: 216| Step: 0
Training loss: 2.472530319598821
Validation loss: 2.485613087679178

Epoch: 6| Step: 1
Training loss: 2.6181241764842267
Validation loss: 2.495881670346249

Epoch: 6| Step: 2
Training loss: 2.1191392749131643
Validation loss: 2.4952749576780757

Epoch: 6| Step: 3
Training loss: 1.5656192924106136
Validation loss: 2.4987458498048842

Epoch: 6| Step: 4
Training loss: 2.191379920950901
Validation loss: 2.4750409682334396

Epoch: 6| Step: 5
Training loss: 2.130170254417514
Validation loss: 2.4844202868311434

Epoch: 6| Step: 6
Training loss: 2.376797648276363
Validation loss: 2.4658776704543395

Epoch: 6| Step: 7
Training loss: 2.483271995742731
Validation loss: 2.4698751078720957

Epoch: 6| Step: 8
Training loss: 2.3855445083498985
Validation loss: 2.450965347155795

Epoch: 6| Step: 9
Training loss: 2.6657662858448545
Validation loss: 2.4605595415801718

Epoch: 6| Step: 10
Training loss: 2.466711144003375
Validation loss: 2.4915634095466315

Epoch: 6| Step: 11
Training loss: 2.678799228972389
Validation loss: 2.4934203266010404

Epoch: 6| Step: 12
Training loss: 2.6254641712877316
Validation loss: 2.5260819058415978

Epoch: 6| Step: 13
Training loss: 2.197223523902213
Validation loss: 2.523960030090009

Epoch: 217| Step: 0
Training loss: 2.117066890194973
Validation loss: 2.5214770281790546

Epoch: 6| Step: 1
Training loss: 2.4515691792364898
Validation loss: 2.5183558244445288

Epoch: 6| Step: 2
Training loss: 2.410189289874325
Validation loss: 2.5392785441552452

Epoch: 6| Step: 3
Training loss: 2.4620229113680225
Validation loss: 2.5501055490934816

Epoch: 6| Step: 4
Training loss: 2.4303656609847315
Validation loss: 2.5515722687651827

Epoch: 6| Step: 5
Training loss: 2.338489580034552
Validation loss: 2.5512903370661193

Epoch: 6| Step: 6
Training loss: 2.1918002775631895
Validation loss: 2.531556295632536

Epoch: 6| Step: 7
Training loss: 2.361902764937733
Validation loss: 2.536256144887893

Epoch: 6| Step: 8
Training loss: 2.1019923114508963
Validation loss: 2.5328068029255566

Epoch: 6| Step: 9
Training loss: 2.0756630906604703
Validation loss: 2.499645942309605

Epoch: 6| Step: 10
Training loss: 2.7002525282138867
Validation loss: 2.4685269638337246

Epoch: 6| Step: 11
Training loss: 2.088822216746516
Validation loss: 2.4504436267907224

Epoch: 6| Step: 12
Training loss: 2.710332005845258
Validation loss: 2.426919784714729

Epoch: 6| Step: 13
Training loss: 2.487273534692768
Validation loss: 2.419879786135233

Epoch: 218| Step: 0
Training loss: 2.4935397602075815
Validation loss: 2.408620991860678

Epoch: 6| Step: 1
Training loss: 2.4552690405954585
Validation loss: 2.4064536667029053

Epoch: 6| Step: 2
Training loss: 2.217222090619995
Validation loss: 2.4033519796472156

Epoch: 6| Step: 3
Training loss: 2.130801527879732
Validation loss: 2.4094101166438064

Epoch: 6| Step: 4
Training loss: 2.902219541209944
Validation loss: 2.408479814694243

Epoch: 6| Step: 5
Training loss: 2.071046864523174
Validation loss: 2.39682762269342

Epoch: 6| Step: 6
Training loss: 2.750762226934942
Validation loss: 2.4108596966249567

Epoch: 6| Step: 7
Training loss: 2.039214497597522
Validation loss: 2.4025394515054357

Epoch: 6| Step: 8
Training loss: 2.5073187511351045
Validation loss: 2.4173644203888403

Epoch: 6| Step: 9
Training loss: 2.3412348157855685
Validation loss: 2.4540845223530603

Epoch: 6| Step: 10
Training loss: 1.9741940990821623
Validation loss: 2.4596229491715875

Epoch: 6| Step: 11
Training loss: 2.2110267863762396
Validation loss: 2.487116752589385

Epoch: 6| Step: 12
Training loss: 2.498680147813862
Validation loss: 2.5160629572999613

Epoch: 6| Step: 13
Training loss: 2.7866428682537
Validation loss: 2.562940095035489

Epoch: 219| Step: 0
Training loss: 2.5701847682393195
Validation loss: 2.583954949338112

Epoch: 6| Step: 1
Training loss: 2.678402962609388
Validation loss: 2.5788436022407937

Epoch: 6| Step: 2
Training loss: 1.8198320794453922
Validation loss: 2.5488806459237012

Epoch: 6| Step: 3
Training loss: 2.2531449273401463
Validation loss: 2.5033246606445214

Epoch: 6| Step: 4
Training loss: 2.183585997757091
Validation loss: 2.4988922905541955

Epoch: 6| Step: 5
Training loss: 2.177487045407219
Validation loss: 2.496692124148568

Epoch: 6| Step: 6
Training loss: 2.3181229352697588
Validation loss: 2.489377326352215

Epoch: 6| Step: 7
Training loss: 2.280636012394945
Validation loss: 2.50515763255754

Epoch: 6| Step: 8
Training loss: 3.0182745960010386
Validation loss: 2.514124703230958

Epoch: 6| Step: 9
Training loss: 2.4897651978362227
Validation loss: 2.5118833524392135

Epoch: 6| Step: 10
Training loss: 2.128737472703398
Validation loss: 2.5066028440598203

Epoch: 6| Step: 11
Training loss: 1.7232038185597989
Validation loss: 2.4773890436271477

Epoch: 6| Step: 12
Training loss: 2.371430073095821
Validation loss: 2.4981661356499756

Epoch: 6| Step: 13
Training loss: 2.934267091239639
Validation loss: 2.4982283015930404

Epoch: 220| Step: 0
Training loss: 2.227029102356253
Validation loss: 2.4803560305793093

Epoch: 6| Step: 1
Training loss: 2.5663525533647205
Validation loss: 2.4957239066786316

Epoch: 6| Step: 2
Training loss: 1.8238447896523278
Validation loss: 2.4943139396831886

Epoch: 6| Step: 3
Training loss: 2.6825355986751003
Validation loss: 2.4869556347073476

Epoch: 6| Step: 4
Training loss: 2.3879936546739784
Validation loss: 2.4686310847095756

Epoch: 6| Step: 5
Training loss: 2.538057568557789
Validation loss: 2.4638451325563664

Epoch: 6| Step: 6
Training loss: 2.068120522976984
Validation loss: 2.4647445719862633

Epoch: 6| Step: 7
Training loss: 2.188073873175926
Validation loss: 2.4564284088812816

Epoch: 6| Step: 8
Training loss: 1.8349227373451906
Validation loss: 2.46393585398781

Epoch: 6| Step: 9
Training loss: 2.947728145398969
Validation loss: 2.465450647619107

Epoch: 6| Step: 10
Training loss: 2.1360804076758537
Validation loss: 2.4657309948691015

Epoch: 6| Step: 11
Training loss: 1.921723522636603
Validation loss: 2.476398092361031

Epoch: 6| Step: 12
Training loss: 2.608487829278328
Validation loss: 2.502981445690981

Epoch: 6| Step: 13
Training loss: 2.286015171444561
Validation loss: 2.5062085430333547

Epoch: 221| Step: 0
Training loss: 2.159776981991075
Validation loss: 2.488526064751983

Epoch: 6| Step: 1
Training loss: 2.7899639478699036
Validation loss: 2.4967920599875817

Epoch: 6| Step: 2
Training loss: 2.533673574370547
Validation loss: 2.495693751624638

Epoch: 6| Step: 3
Training loss: 2.2633949617283102
Validation loss: 2.480286413494373

Epoch: 6| Step: 4
Training loss: 2.663668516676923
Validation loss: 2.4926987792612327

Epoch: 6| Step: 5
Training loss: 1.8060571006543438
Validation loss: 2.480291838373164

Epoch: 6| Step: 6
Training loss: 2.42612581370551
Validation loss: 2.4715678555095386

Epoch: 6| Step: 7
Training loss: 2.0657466419778525
Validation loss: 2.469952314555133

Epoch: 6| Step: 8
Training loss: 2.863351860060464
Validation loss: 2.4560417996135304

Epoch: 6| Step: 9
Training loss: 1.7157872413396555
Validation loss: 2.4693837513484906

Epoch: 6| Step: 10
Training loss: 2.1822473950929333
Validation loss: 2.466347227750331

Epoch: 6| Step: 11
Training loss: 1.8612146332956465
Validation loss: 2.4600993932391315

Epoch: 6| Step: 12
Training loss: 2.1639720470928836
Validation loss: 2.4764647343705852

Epoch: 6| Step: 13
Training loss: 2.3915609883565696
Validation loss: 2.469778968767771

Epoch: 222| Step: 0
Training loss: 2.007393166061555
Validation loss: 2.4764818772522887

Epoch: 6| Step: 1
Training loss: 2.383493394967769
Validation loss: 2.4742396835333245

Epoch: 6| Step: 2
Training loss: 2.499200120756901
Validation loss: 2.452442540090671

Epoch: 6| Step: 3
Training loss: 2.27041319947361
Validation loss: 2.4421643543231104

Epoch: 6| Step: 4
Training loss: 2.726117641588945
Validation loss: 2.4390634350792846

Epoch: 6| Step: 5
Training loss: 2.7611104033495044
Validation loss: 2.436076972833762

Epoch: 6| Step: 6
Training loss: 1.9875693255155829
Validation loss: 2.4437132135282917

Epoch: 6| Step: 7
Training loss: 2.476945432306005
Validation loss: 2.425318285342827

Epoch: 6| Step: 8
Training loss: 2.005313490715335
Validation loss: 2.4291723891209323

Epoch: 6| Step: 9
Training loss: 2.0069675671551828
Validation loss: 2.437721208747804

Epoch: 6| Step: 10
Training loss: 2.264604009576604
Validation loss: 2.4698945571587974

Epoch: 6| Step: 11
Training loss: 2.301704571204886
Validation loss: 2.4692448392297193

Epoch: 6| Step: 12
Training loss: 2.3487364557757826
Validation loss: 2.4686457075979846

Epoch: 6| Step: 13
Training loss: 1.7982539317738913
Validation loss: 2.472667414196416

Epoch: 223| Step: 0
Training loss: 1.8088032084180543
Validation loss: 2.48397662151558

Epoch: 6| Step: 1
Training loss: 2.619497617647297
Validation loss: 2.453322571468468

Epoch: 6| Step: 2
Training loss: 2.889835394161176
Validation loss: 2.453592014946055

Epoch: 6| Step: 3
Training loss: 1.7430286515157698
Validation loss: 2.489018836588364

Epoch: 6| Step: 4
Training loss: 2.4142729534769636
Validation loss: 2.492517399652242

Epoch: 6| Step: 5
Training loss: 2.2902586223705237
Validation loss: 2.4884464343475163

Epoch: 6| Step: 6
Training loss: 1.963219701407115
Validation loss: 2.468623550476815

Epoch: 6| Step: 7
Training loss: 2.0414914685289918
Validation loss: 2.4543588896430055

Epoch: 6| Step: 8
Training loss: 2.531076119184478
Validation loss: 2.436433359428738

Epoch: 6| Step: 9
Training loss: 1.7343195313527624
Validation loss: 2.4389706516973764

Epoch: 6| Step: 10
Training loss: 2.570009347030326
Validation loss: 2.408546747325893

Epoch: 6| Step: 11
Training loss: 2.5571007019550414
Validation loss: 2.4233583669027756

Epoch: 6| Step: 12
Training loss: 2.052059915734946
Validation loss: 2.419577090025786

Epoch: 6| Step: 13
Training loss: 2.5571717482119802
Validation loss: 2.428694411657537

Epoch: 224| Step: 0
Training loss: 2.522987916183413
Validation loss: 2.4350446561577925

Epoch: 6| Step: 1
Training loss: 2.0774493732549777
Validation loss: 2.458443862518741

Epoch: 6| Step: 2
Training loss: 2.132108467355975
Validation loss: 2.471649643612703

Epoch: 6| Step: 3
Training loss: 2.041608368437008
Validation loss: 2.4772046900741675

Epoch: 6| Step: 4
Training loss: 2.1046124983736427
Validation loss: 2.481510763139782

Epoch: 6| Step: 5
Training loss: 2.332565476458342
Validation loss: 2.475896113512631

Epoch: 6| Step: 6
Training loss: 2.3501554315987994
Validation loss: 2.4730877331572247

Epoch: 6| Step: 7
Training loss: 2.052199565351838
Validation loss: 2.43798049511438

Epoch: 6| Step: 8
Training loss: 1.4369230356437916
Validation loss: 2.4281547466962508

Epoch: 6| Step: 9
Training loss: 2.2354319813379417
Validation loss: 2.429858335665527

Epoch: 6| Step: 10
Training loss: 2.5605863543390495
Validation loss: 2.441000619444798

Epoch: 6| Step: 11
Training loss: 2.551559072610173
Validation loss: 2.444292782839001

Epoch: 6| Step: 12
Training loss: 2.0212297214677455
Validation loss: 2.462846478688208

Epoch: 6| Step: 13
Training loss: 3.169406174356148
Validation loss: 2.4646035707880514

Epoch: 225| Step: 0
Training loss: 2.432182576403535
Validation loss: 2.445342381022959

Epoch: 6| Step: 1
Training loss: 2.292182748655714
Validation loss: 2.438730890905354

Epoch: 6| Step: 2
Training loss: 2.1090352102626078
Validation loss: 2.4113992868836136

Epoch: 6| Step: 3
Training loss: 2.1332488679059165
Validation loss: 2.4364599970428125

Epoch: 6| Step: 4
Training loss: 2.2424476818160937
Validation loss: 2.427654966064911

Epoch: 6| Step: 5
Training loss: 1.772178841833585
Validation loss: 2.4756632353232026

Epoch: 6| Step: 6
Training loss: 2.038621525929388
Validation loss: 2.5073090714592623

Epoch: 6| Step: 7
Training loss: 2.287826881608388
Validation loss: 2.5137104862946438

Epoch: 6| Step: 8
Training loss: 2.4590572864488354
Validation loss: 2.4910176246057674

Epoch: 6| Step: 9
Training loss: 3.030221823702398
Validation loss: 2.4806403866413937

Epoch: 6| Step: 10
Training loss: 2.558253141838358
Validation loss: 2.4588709751357136

Epoch: 6| Step: 11
Training loss: 2.15603990498771
Validation loss: 2.419768979028883

Epoch: 6| Step: 12
Training loss: 1.8301338179184186
Validation loss: 2.4185772543845103

Epoch: 6| Step: 13
Training loss: 2.1222696153675904
Validation loss: 2.4129653244295493

Epoch: 226| Step: 0
Training loss: 2.2884091431057514
Validation loss: 2.4395664901098013

Epoch: 6| Step: 1
Training loss: 2.0133210254865617
Validation loss: 2.4345261465170753

Epoch: 6| Step: 2
Training loss: 2.0462964820126537
Validation loss: 2.4486920802744043

Epoch: 6| Step: 3
Training loss: 1.8960738047025036
Validation loss: 2.472474208840648

Epoch: 6| Step: 4
Training loss: 2.29825846210085
Validation loss: 2.484807591883064

Epoch: 6| Step: 5
Training loss: 2.643572725164727
Validation loss: 2.4965131860013243

Epoch: 6| Step: 6
Training loss: 2.1631090838913964
Validation loss: 2.531783923827228

Epoch: 6| Step: 7
Training loss: 2.221252212480378
Validation loss: 2.55335136656475

Epoch: 6| Step: 8
Training loss: 2.8611658043762223
Validation loss: 2.578623802281547

Epoch: 6| Step: 9
Training loss: 2.049690232482289
Validation loss: 2.587615154431152

Epoch: 6| Step: 10
Training loss: 2.4898520501545742
Validation loss: 2.581092579828591

Epoch: 6| Step: 11
Training loss: 2.1412664413043627
Validation loss: 2.534868296906796

Epoch: 6| Step: 12
Training loss: 2.0396549927926593
Validation loss: 2.4718001456523364

Epoch: 6| Step: 13
Training loss: 2.24200204753527
Validation loss: 2.420575366728094

Epoch: 227| Step: 0
Training loss: 2.736891716389677
Validation loss: 2.358450934840796

Epoch: 6| Step: 1
Training loss: 2.3534931355901634
Validation loss: 2.346676862411127

Epoch: 6| Step: 2
Training loss: 2.180087035830259
Validation loss: 2.3489691941405133

Epoch: 6| Step: 3
Training loss: 2.2329216345136045
Validation loss: 2.3701910415086997

Epoch: 6| Step: 4
Training loss: 2.117158108327755
Validation loss: 2.3857845417330172

Epoch: 6| Step: 5
Training loss: 2.5624734830647347
Validation loss: 2.370982836219824

Epoch: 6| Step: 6
Training loss: 2.201954632200788
Validation loss: 2.3473134527235135

Epoch: 6| Step: 7
Training loss: 2.644499875760161
Validation loss: 2.342735863045291

Epoch: 6| Step: 8
Training loss: 1.3967942540941987
Validation loss: 2.3568704104877765

Epoch: 6| Step: 9
Training loss: 2.3480080136319974
Validation loss: 2.365510608485868

Epoch: 6| Step: 10
Training loss: 2.384399685913127
Validation loss: 2.3731210148523005

Epoch: 6| Step: 11
Training loss: 2.366844530093299
Validation loss: 2.415737597980496

Epoch: 6| Step: 12
Training loss: 2.3598550472356608
Validation loss: 2.4166374126979124

Epoch: 6| Step: 13
Training loss: 1.930720435068662
Validation loss: 2.3970021703579025

Epoch: 228| Step: 0
Training loss: 2.4167776301548605
Validation loss: 2.4075427796929514

Epoch: 6| Step: 1
Training loss: 2.849062641658865
Validation loss: 2.4264909687801834

Epoch: 6| Step: 2
Training loss: 2.1986970164045543
Validation loss: 2.4462972618134113

Epoch: 6| Step: 3
Training loss: 2.6898208178435405
Validation loss: 2.442661893585816

Epoch: 6| Step: 4
Training loss: 1.9015545157623053
Validation loss: 2.4384963000669897

Epoch: 6| Step: 5
Training loss: 1.9668264528870785
Validation loss: 2.4511606766979694

Epoch: 6| Step: 6
Training loss: 2.122617620257736
Validation loss: 2.4528983576891252

Epoch: 6| Step: 7
Training loss: 2.364396366564341
Validation loss: 2.4453567395517823

Epoch: 6| Step: 8
Training loss: 2.317244534038172
Validation loss: 2.4451725548307697

Epoch: 6| Step: 9
Training loss: 2.009178320482912
Validation loss: 2.4680297858142266

Epoch: 6| Step: 10
Training loss: 1.2142213656100684
Validation loss: 2.4740617804064278

Epoch: 6| Step: 11
Training loss: 1.8272426464722507
Validation loss: 2.4535465916726236

Epoch: 6| Step: 12
Training loss: 1.9905648598202277
Validation loss: 2.4676336150337033

Epoch: 6| Step: 13
Training loss: 2.5530263183647723
Validation loss: 2.4697201734410807

Epoch: 229| Step: 0
Training loss: 2.1523975843284506
Validation loss: 2.4533715151352085

Epoch: 6| Step: 1
Training loss: 2.061972117060666
Validation loss: 2.436554621034687

Epoch: 6| Step: 2
Training loss: 2.236893095256117
Validation loss: 2.415597933576585

Epoch: 6| Step: 3
Training loss: 1.885386879476659
Validation loss: 2.4142934017939526

Epoch: 6| Step: 4
Training loss: 1.7963615679088416
Validation loss: 2.40823727003934

Epoch: 6| Step: 5
Training loss: 2.078428318001679
Validation loss: 2.4134298758667914

Epoch: 6| Step: 6
Training loss: 1.8018799448358946
Validation loss: 2.425585311974742

Epoch: 6| Step: 7
Training loss: 2.4790013576071446
Validation loss: 2.4197646034684523

Epoch: 6| Step: 8
Training loss: 2.0847451448998147
Validation loss: 2.4373398121589744

Epoch: 6| Step: 9
Training loss: 2.1853250863154523
Validation loss: 2.452036772793235

Epoch: 6| Step: 10
Training loss: 2.3757105316605642
Validation loss: 2.4784182188024384

Epoch: 6| Step: 11
Training loss: 2.572802789512944
Validation loss: 2.461855008527995

Epoch: 6| Step: 12
Training loss: 2.275582785944303
Validation loss: 2.45418968424578

Epoch: 6| Step: 13
Training loss: 2.6377769324827924
Validation loss: 2.455527864680932

Epoch: 230| Step: 0
Training loss: 2.3113307574426236
Validation loss: 2.4506267950006517

Epoch: 6| Step: 1
Training loss: 1.546746682133437
Validation loss: 2.4354429586546735

Epoch: 6| Step: 2
Training loss: 1.7415304955115989
Validation loss: 2.443703602400546

Epoch: 6| Step: 3
Training loss: 1.9998215357311686
Validation loss: 2.4211549406308843

Epoch: 6| Step: 4
Training loss: 2.604207386970048
Validation loss: 2.4137531924897213

Epoch: 6| Step: 5
Training loss: 2.1091945994906465
Validation loss: 2.4167959633405443

Epoch: 6| Step: 6
Training loss: 2.14242711747794
Validation loss: 2.4376990134771828

Epoch: 6| Step: 7
Training loss: 2.1634165767334
Validation loss: 2.432559849403155

Epoch: 6| Step: 8
Training loss: 1.9998074677302067
Validation loss: 2.4550493764225685

Epoch: 6| Step: 9
Training loss: 1.9362040461682848
Validation loss: 2.425106812511746

Epoch: 6| Step: 10
Training loss: 2.2644755637580682
Validation loss: 2.4177686702037646

Epoch: 6| Step: 11
Training loss: 2.612775037971668
Validation loss: 2.4110726710540327

Epoch: 6| Step: 12
Training loss: 1.8783409870378769
Validation loss: 2.3819692651798072

Epoch: 6| Step: 13
Training loss: 2.8330374357508448
Validation loss: 2.38482372629085

Epoch: 231| Step: 0
Training loss: 2.018283362532583
Validation loss: 2.3808310245241695

Epoch: 6| Step: 1
Training loss: 1.4096265733254607
Validation loss: 2.403208361570821

Epoch: 6| Step: 2
Training loss: 2.1472096766732784
Validation loss: 2.4483192585809097

Epoch: 6| Step: 3
Training loss: 1.9086060269460983
Validation loss: 2.470249307985517

Epoch: 6| Step: 4
Training loss: 1.7774098813675636
Validation loss: 2.495403934923836

Epoch: 6| Step: 5
Training loss: 2.1515797333868654
Validation loss: 2.500664190026318

Epoch: 6| Step: 6
Training loss: 2.6325582047536984
Validation loss: 2.480193348385835

Epoch: 6| Step: 7
Training loss: 1.6880161767518918
Validation loss: 2.4585526606470642

Epoch: 6| Step: 8
Training loss: 2.158325633718928
Validation loss: 2.451339158384721

Epoch: 6| Step: 9
Training loss: 2.427436595524787
Validation loss: 2.445487612565362

Epoch: 6| Step: 10
Training loss: 2.676620908546376
Validation loss: 2.4264243879751657

Epoch: 6| Step: 11
Training loss: 2.1923916211195538
Validation loss: 2.411462664785787

Epoch: 6| Step: 12
Training loss: 2.222774670065933
Validation loss: 2.399016361996028

Epoch: 6| Step: 13
Training loss: 2.2610885980887576
Validation loss: 2.408184331448946

Epoch: 232| Step: 0
Training loss: 2.2897771038871535
Validation loss: 2.4381870976796285

Epoch: 6| Step: 1
Training loss: 1.62193008358712
Validation loss: 2.4501613859706795

Epoch: 6| Step: 2
Training loss: 2.2417452173285177
Validation loss: 2.4285976884683245

Epoch: 6| Step: 3
Training loss: 2.5107124650309456
Validation loss: 2.398534950969356

Epoch: 6| Step: 4
Training loss: 1.854755979461225
Validation loss: 2.3817459406489165

Epoch: 6| Step: 5
Training loss: 1.5047630346557257
Validation loss: 2.3863294882262824

Epoch: 6| Step: 6
Training loss: 2.6401610559407453
Validation loss: 2.3891500820861613

Epoch: 6| Step: 7
Training loss: 1.8843242859856286
Validation loss: 2.3998562167279567

Epoch: 6| Step: 8
Training loss: 2.2156759108275037
Validation loss: 2.4155422483116418

Epoch: 6| Step: 9
Training loss: 1.7557838771658172
Validation loss: 2.426547409632017

Epoch: 6| Step: 10
Training loss: 2.206471600088492
Validation loss: 2.471278098555779

Epoch: 6| Step: 11
Training loss: 2.531670617842798
Validation loss: 2.482485320224609

Epoch: 6| Step: 12
Training loss: 1.9563481705380756
Validation loss: 2.491900506938796

Epoch: 6| Step: 13
Training loss: 1.99873842742986
Validation loss: 2.4929664914989016

Epoch: 233| Step: 0
Training loss: 2.1779627385170417
Validation loss: 2.4686422307625415

Epoch: 6| Step: 1
Training loss: 2.3214714675125987
Validation loss: 2.476065645395101

Epoch: 6| Step: 2
Training loss: 2.2440122828291917
Validation loss: 2.4733657605638943

Epoch: 6| Step: 3
Training loss: 1.5488145017084889
Validation loss: 2.479428330680731

Epoch: 6| Step: 4
Training loss: 1.977408669022866
Validation loss: 2.493578529019195

Epoch: 6| Step: 5
Training loss: 2.1646505169788353
Validation loss: 2.483236045470585

Epoch: 6| Step: 6
Training loss: 2.546173654422043
Validation loss: 2.490324361045127

Epoch: 6| Step: 7
Training loss: 1.9488789294684454
Validation loss: 2.4694505421635387

Epoch: 6| Step: 8
Training loss: 2.272463350577522
Validation loss: 2.4366316362108575

Epoch: 6| Step: 9
Training loss: 1.4627418187730366
Validation loss: 2.4283460645162944

Epoch: 6| Step: 10
Training loss: 1.6712657495753735
Validation loss: 2.4300809083474535

Epoch: 6| Step: 11
Training loss: 2.3939485074196476
Validation loss: 2.4352091259272135

Epoch: 6| Step: 12
Training loss: 1.9088878828109461
Validation loss: 2.435694317298266

Epoch: 6| Step: 13
Training loss: 2.3000610467853257
Validation loss: 2.4086169887981477

Epoch: 234| Step: 0
Training loss: 1.8978159950710345
Validation loss: 2.4235794669503665

Epoch: 6| Step: 1
Training loss: 2.7189486200852215
Validation loss: 2.4354056823404724

Epoch: 6| Step: 2
Training loss: 2.5502325288555374
Validation loss: 2.4401861471572164

Epoch: 6| Step: 3
Training loss: 1.8487127723066519
Validation loss: 2.3961835540137213

Epoch: 6| Step: 4
Training loss: 2.01198302079425
Validation loss: 2.3963379644583505

Epoch: 6| Step: 5
Training loss: 1.553207229494476
Validation loss: 2.3814192495395208

Epoch: 6| Step: 6
Training loss: 1.9747899969937468
Validation loss: 2.3666498220723278

Epoch: 6| Step: 7
Training loss: 1.9263333347521006
Validation loss: 2.3609992417196537

Epoch: 6| Step: 8
Training loss: 1.6797159591747854
Validation loss: 2.3714066546783408

Epoch: 6| Step: 9
Training loss: 2.0010092096378926
Validation loss: 2.3728773992287597

Epoch: 6| Step: 10
Training loss: 1.7162378158192406
Validation loss: 2.3979696571273443

Epoch: 6| Step: 11
Training loss: 2.3156458103413433
Validation loss: 2.4375565288037433

Epoch: 6| Step: 12
Training loss: 2.3593374085115824
Validation loss: 2.458099163937509

Epoch: 6| Step: 13
Training loss: 2.461806564677584
Validation loss: 2.4759456774345496

Epoch: 235| Step: 0
Training loss: 2.280729155980752
Validation loss: 2.4823044005991566

Epoch: 6| Step: 1
Training loss: 2.165494919870707
Validation loss: 2.481283414626087

Epoch: 6| Step: 2
Training loss: 2.1357759002969066
Validation loss: 2.4696297075754243

Epoch: 6| Step: 3
Training loss: 2.0876253421637667
Validation loss: 2.464995618155386

Epoch: 6| Step: 4
Training loss: 1.7702351700541803
Validation loss: 2.4832155051739306

Epoch: 6| Step: 5
Training loss: 2.178456823832132
Validation loss: 2.458101703485878

Epoch: 6| Step: 6
Training loss: 1.6878822741382462
Validation loss: 2.47251545736032

Epoch: 6| Step: 7
Training loss: 1.8976056823651823
Validation loss: 2.458803354766449

Epoch: 6| Step: 8
Training loss: 1.95682035668983
Validation loss: 2.45139792187334

Epoch: 6| Step: 9
Training loss: 1.6023944461712931
Validation loss: 2.4556057385626433

Epoch: 6| Step: 10
Training loss: 2.2289028784094285
Validation loss: 2.4478300579793095

Epoch: 6| Step: 11
Training loss: 1.9754353200432346
Validation loss: 2.457517956565962

Epoch: 6| Step: 12
Training loss: 2.476879689214341
Validation loss: 2.452913748483221

Epoch: 6| Step: 13
Training loss: 2.378523672124413
Validation loss: 2.4597176133477143

Epoch: 236| Step: 0
Training loss: 2.6844000569818336
Validation loss: 2.452051989167823

Epoch: 6| Step: 1
Training loss: 2.351558241729429
Validation loss: 2.446966143725119

Epoch: 6| Step: 2
Training loss: 2.0632800158923446
Validation loss: 2.4532068522508554

Epoch: 6| Step: 3
Training loss: 1.2195210096575688
Validation loss: 2.427569031303991

Epoch: 6| Step: 4
Training loss: 2.2246179488421256
Validation loss: 2.4334351665660243

Epoch: 6| Step: 5
Training loss: 1.6042629642399673
Validation loss: 2.411349282919316

Epoch: 6| Step: 6
Training loss: 1.6269629433508512
Validation loss: 2.414089063219566

Epoch: 6| Step: 7
Training loss: 1.9300764672543036
Validation loss: 2.4229295258786587

Epoch: 6| Step: 8
Training loss: 2.117076350035847
Validation loss: 2.4164446522617316

Epoch: 6| Step: 9
Training loss: 2.14453125
Validation loss: 2.426012134111153

Epoch: 6| Step: 10
Training loss: 1.7622421400674462
Validation loss: 2.439723131392027

Epoch: 6| Step: 11
Training loss: 2.16583267691371
Validation loss: 2.4471948785279207

Epoch: 6| Step: 12
Training loss: 2.0712892927127404
Validation loss: 2.4701941002173156

Epoch: 6| Step: 13
Training loss: 1.9999017691330843
Validation loss: 2.4845499761455163

Epoch: 237| Step: 0
Training loss: 2.2463627131761132
Validation loss: 2.434802925180288

Epoch: 6| Step: 1
Training loss: 2.174248365994844
Validation loss: 2.411612798332383

Epoch: 6| Step: 2
Training loss: 2.7637282942010564
Validation loss: 2.41704090376328

Epoch: 6| Step: 3
Training loss: 1.6097884156414919
Validation loss: 2.401335864632261

Epoch: 6| Step: 4
Training loss: 2.023071491616861
Validation loss: 2.398134192681738

Epoch: 6| Step: 5
Training loss: 1.660921956919939
Validation loss: 2.412897421612881

Epoch: 6| Step: 6
Training loss: 2.2019591797831204
Validation loss: 2.42926887836528

Epoch: 6| Step: 7
Training loss: 1.764162183433654
Validation loss: 2.4212151111692095

Epoch: 6| Step: 8
Training loss: 2.125923404896406
Validation loss: 2.4322802099876957

Epoch: 6| Step: 9
Training loss: 0.9501404859166381
Validation loss: 2.4262157598803644

Epoch: 6| Step: 10
Training loss: 2.2951180102356834
Validation loss: 2.439809045754991

Epoch: 6| Step: 11
Training loss: 2.463954275363393
Validation loss: 2.422295822329802

Epoch: 6| Step: 12
Training loss: 1.5275946603716164
Validation loss: 2.4027743824877454

Epoch: 6| Step: 13
Training loss: 1.109845504920471
Validation loss: 2.3947303326673666

Epoch: 238| Step: 0
Training loss: 2.172995189248881
Validation loss: 2.3913079308486185

Epoch: 6| Step: 1
Training loss: 1.8163298560044066
Validation loss: 2.409503607412996

Epoch: 6| Step: 2
Training loss: 1.6125695827167874
Validation loss: 2.4478396984629303

Epoch: 6| Step: 3
Training loss: 1.5058391089751721
Validation loss: 2.4360939432026596

Epoch: 6| Step: 4
Training loss: 2.127099963007031
Validation loss: 2.4538601333630754

Epoch: 6| Step: 5
Training loss: 2.0804251654454085
Validation loss: 2.4496621539135934

Epoch: 6| Step: 6
Training loss: 2.568813640613627
Validation loss: 2.4254782873267255

Epoch: 6| Step: 7
Training loss: 1.687190415983441
Validation loss: 2.4257022585286854

Epoch: 6| Step: 8
Training loss: 1.9505760955791434
Validation loss: 2.410342474436683

Epoch: 6| Step: 9
Training loss: 1.8490935656742522
Validation loss: 2.4079966007984477

Epoch: 6| Step: 10
Training loss: 1.706031209590887
Validation loss: 2.4116112967880525

Epoch: 6| Step: 11
Training loss: 2.1649857627629583
Validation loss: 2.404330233168757

Epoch: 6| Step: 12
Training loss: 2.4659908666263686
Validation loss: 2.3956895939392724

Epoch: 6| Step: 13
Training loss: 1.7178632355987842
Validation loss: 2.394000006737753

Epoch: 239| Step: 0
Training loss: 2.1230080187767846
Validation loss: 2.375524058270329

Epoch: 6| Step: 1
Training loss: 1.8184033643603301
Validation loss: 2.3706924653837866

Epoch: 6| Step: 2
Training loss: 1.862301678947655
Validation loss: 2.3818304191515036

Epoch: 6| Step: 3
Training loss: 2.3248729137840165
Validation loss: 2.3615844758949494

Epoch: 6| Step: 4
Training loss: 2.1486086135693023
Validation loss: 2.4024513624039416

Epoch: 6| Step: 5
Training loss: 2.06545900725348
Validation loss: 2.3944964207690718

Epoch: 6| Step: 6
Training loss: 1.8442570263973224
Validation loss: 2.3919542925019672

Epoch: 6| Step: 7
Training loss: 1.8142455016100507
Validation loss: 2.401823837908904

Epoch: 6| Step: 8
Training loss: 2.016603572373393
Validation loss: 2.4124758153059482

Epoch: 6| Step: 9
Training loss: 1.3795912988805856
Validation loss: 2.4195890108899136

Epoch: 6| Step: 10
Training loss: 1.6718938238207242
Validation loss: 2.400571918152016

Epoch: 6| Step: 11
Training loss: 2.2249757701111683
Validation loss: 2.3939975341190114

Epoch: 6| Step: 12
Training loss: 2.2005270933404546
Validation loss: 2.4080362113315172

Epoch: 6| Step: 13
Training loss: 1.6948849890520277
Validation loss: 2.419790089672468

Epoch: 240| Step: 0
Training loss: 1.6927094757858725
Validation loss: 2.4131755272648188

Epoch: 6| Step: 1
Training loss: 1.7009088639205945
Validation loss: 2.413934038573106

Epoch: 6| Step: 2
Training loss: 2.822501308011748
Validation loss: 2.436426543199924

Epoch: 6| Step: 3
Training loss: 1.7402758866313628
Validation loss: 2.4466395900614306

Epoch: 6| Step: 4
Training loss: 1.9305878673871315
Validation loss: 2.4407980740305697

Epoch: 6| Step: 5
Training loss: 1.7393331366821934
Validation loss: 2.4186473529471826

Epoch: 6| Step: 6
Training loss: 2.109841189261075
Validation loss: 2.3940159592971506

Epoch: 6| Step: 7
Training loss: 2.5985050965656082
Validation loss: 2.402522888627734

Epoch: 6| Step: 8
Training loss: 1.8079054904981184
Validation loss: 2.377086254176065

Epoch: 6| Step: 9
Training loss: 1.3657749399236454
Validation loss: 2.3885843660079464

Epoch: 6| Step: 10
Training loss: 1.7046922944138725
Validation loss: 2.3919715078516304

Epoch: 6| Step: 11
Training loss: 1.7941044553586256
Validation loss: 2.3956263220453407

Epoch: 6| Step: 12
Training loss: 2.0282169879571654
Validation loss: 2.4067003851148705

Epoch: 6| Step: 13
Training loss: 1.7834071432270264
Validation loss: 2.3983107938169623

Epoch: 241| Step: 0
Training loss: 2.1144499587918517
Validation loss: 2.3938606076649562

Epoch: 6| Step: 1
Training loss: 1.7653939425089558
Validation loss: 2.388927323673767

Epoch: 6| Step: 2
Training loss: 1.8795564601056425
Validation loss: 2.386460568377528

Epoch: 6| Step: 3
Training loss: 1.3136293910856378
Validation loss: 2.4295914141020147

Epoch: 6| Step: 4
Training loss: 1.9279572919373245
Validation loss: 2.414234718471602

Epoch: 6| Step: 5
Training loss: 2.1489150747610193
Validation loss: 2.4200165211557603

Epoch: 6| Step: 6
Training loss: 1.6812302003283106
Validation loss: 2.39770476417937

Epoch: 6| Step: 7
Training loss: 1.9355314159834531
Validation loss: 2.3961566815636544

Epoch: 6| Step: 8
Training loss: 1.782726211532504
Validation loss: 2.397200898100055

Epoch: 6| Step: 9
Training loss: 2.356758131692004
Validation loss: 2.4040462127684634

Epoch: 6| Step: 10
Training loss: 1.9490663396232673
Validation loss: 2.408349973443191

Epoch: 6| Step: 11
Training loss: 2.029332356147347
Validation loss: 2.3932778110497157

Epoch: 6| Step: 12
Training loss: 1.970076099223316
Validation loss: 2.3866084259460707

Epoch: 6| Step: 13
Training loss: 2.049488641182999
Validation loss: 2.3817359067036765

Epoch: 242| Step: 0
Training loss: 1.7001813595466018
Validation loss: 2.380169152952736

Epoch: 6| Step: 1
Training loss: 1.773466404078539
Validation loss: 2.3695578839238376

Epoch: 6| Step: 2
Training loss: 2.0308917389888523
Validation loss: 2.3554415316828687

Epoch: 6| Step: 3
Training loss: 1.9814130048153125
Validation loss: 2.362011999490033

Epoch: 6| Step: 4
Training loss: 1.8393131470982256
Validation loss: 2.3427481672491335

Epoch: 6| Step: 5
Training loss: 1.9637819610267586
Validation loss: 2.351731225312622

Epoch: 6| Step: 6
Training loss: 2.654533639527627
Validation loss: 2.346594591403691

Epoch: 6| Step: 7
Training loss: 2.1076703000298527
Validation loss: 2.360912602947311

Epoch: 6| Step: 8
Training loss: 2.0172312642379877
Validation loss: 2.3791618021989343

Epoch: 6| Step: 9
Training loss: 2.2297331069527058
Validation loss: 2.420885249145236

Epoch: 6| Step: 10
Training loss: 1.230961679694218
Validation loss: 2.4071359696019523

Epoch: 6| Step: 11
Training loss: 1.433335948912134
Validation loss: 2.472241678200148

Epoch: 6| Step: 12
Training loss: 1.597327088861779
Validation loss: 2.4667309788693004

Epoch: 6| Step: 13
Training loss: 2.1820686487365775
Validation loss: 2.460805840135434

Epoch: 243| Step: 0
Training loss: 1.8011733681170616
Validation loss: 2.429281967385365

Epoch: 6| Step: 1
Training loss: 1.6611911554872214
Validation loss: 2.41812053900239

Epoch: 6| Step: 2
Training loss: 1.8632957729837254
Validation loss: 2.4168990977800147

Epoch: 6| Step: 3
Training loss: 1.2697496431744144
Validation loss: 2.438610317292077

Epoch: 6| Step: 4
Training loss: 1.6839890867772171
Validation loss: 2.457301169430988

Epoch: 6| Step: 5
Training loss: 1.4852248318974437
Validation loss: 2.4652384223976065

Epoch: 6| Step: 6
Training loss: 1.7616240820644453
Validation loss: 2.4756302853552636

Epoch: 6| Step: 7
Training loss: 2.071633317064657
Validation loss: 2.468782618120114

Epoch: 6| Step: 8
Training loss: 2.2121423464565586
Validation loss: 2.4983288973613393

Epoch: 6| Step: 9
Training loss: 2.663698233034734
Validation loss: 2.4955329897415646

Epoch: 6| Step: 10
Training loss: 2.0916313725668907
Validation loss: 2.4355749748720683

Epoch: 6| Step: 11
Training loss: 1.7093958070594009
Validation loss: 2.4072805477026886

Epoch: 6| Step: 12
Training loss: 1.8762515659313033
Validation loss: 2.4025240069083433

Epoch: 6| Step: 13
Training loss: 2.347011483969303
Validation loss: 2.394605922660481

Epoch: 244| Step: 0
Training loss: 2.0891767061182756
Validation loss: 2.406099124818796

Epoch: 6| Step: 1
Training loss: 2.7033499916243877
Validation loss: 2.3863475928468447

Epoch: 6| Step: 2
Training loss: 1.7429133387178255
Validation loss: 2.3753025097589697

Epoch: 6| Step: 3
Training loss: 1.976384633621826
Validation loss: 2.3969190929191764

Epoch: 6| Step: 4
Training loss: 1.853278157947451
Validation loss: 2.445612603078913

Epoch: 6| Step: 5
Training loss: 1.8253995353535135
Validation loss: 2.5189209608703176

Epoch: 6| Step: 6
Training loss: 1.7442631011029102
Validation loss: 2.562489591347769

Epoch: 6| Step: 7
Training loss: 1.8701591307714858
Validation loss: 2.540019930292301

Epoch: 6| Step: 8
Training loss: 1.9948332328217362
Validation loss: 2.411362368208765

Epoch: 6| Step: 9
Training loss: 1.8411798181774015
Validation loss: 2.3684684888093637

Epoch: 6| Step: 10
Training loss: 2.0280626378515327
Validation loss: 2.3729189405243396

Epoch: 6| Step: 11
Training loss: 2.3984227878976707
Validation loss: 2.368750481655942

Epoch: 6| Step: 12
Training loss: 1.634599064188822
Validation loss: 2.361306009647315

Epoch: 6| Step: 13
Training loss: 1.9583577972940212
Validation loss: 2.3690147055674546

Epoch: 245| Step: 0
Training loss: 1.9702657284127594
Validation loss: 2.350766700687582

Epoch: 6| Step: 1
Training loss: 1.7613303016349657
Validation loss: 2.349159000957531

Epoch: 6| Step: 2
Training loss: 1.525753354209677
Validation loss: 2.3651152574407623

Epoch: 6| Step: 3
Training loss: 1.8495800495340555
Validation loss: 2.3688168750811847

Epoch: 6| Step: 4
Training loss: 1.5601566289864024
Validation loss: 2.4073391023661705

Epoch: 6| Step: 5
Training loss: 2.1503810899680746
Validation loss: 2.434981940480173

Epoch: 6| Step: 6
Training loss: 2.437869997553086
Validation loss: 2.4924601507533937

Epoch: 6| Step: 7
Training loss: 2.258281830579271
Validation loss: 2.4432375188390303

Epoch: 6| Step: 8
Training loss: 1.8035058450712536
Validation loss: 2.3993001486594645

Epoch: 6| Step: 9
Training loss: 1.7210967255651906
Validation loss: 2.386652656935583

Epoch: 6| Step: 10
Training loss: 2.3518859032574086
Validation loss: 2.3676452269990222

Epoch: 6| Step: 11
Training loss: 1.855952856254348
Validation loss: 2.362547923544613

Epoch: 6| Step: 12
Training loss: 1.7014752718563162
Validation loss: 2.356954087592153

Epoch: 6| Step: 13
Training loss: 1.778789158897398
Validation loss: 2.3583826625246034

Epoch: 246| Step: 0
Training loss: 2.150905897337031
Validation loss: 2.3744125233309115

Epoch: 6| Step: 1
Training loss: 1.7953564405251554
Validation loss: 2.3896535880590672

Epoch: 6| Step: 2
Training loss: 2.3629681844873955
Validation loss: 2.4290186949364068

Epoch: 6| Step: 3
Training loss: 1.9541613461463363
Validation loss: 2.417749724094107

Epoch: 6| Step: 4
Training loss: 1.9985621767619703
Validation loss: 2.4020735580632064

Epoch: 6| Step: 5
Training loss: 1.771605633641043
Validation loss: 2.384824486302427

Epoch: 6| Step: 6
Training loss: 1.6855250917443805
Validation loss: 2.401623707907206

Epoch: 6| Step: 7
Training loss: 1.4941348007188362
Validation loss: 2.3826537075486454

Epoch: 6| Step: 8
Training loss: 1.3435801465228303
Validation loss: 2.394450594315801

Epoch: 6| Step: 9
Training loss: 2.1813599654408544
Validation loss: 2.386884980504965

Epoch: 6| Step: 10
Training loss: 1.7695344836477076
Validation loss: 2.4280825015957106

Epoch: 6| Step: 11
Training loss: 1.919453095089817
Validation loss: 2.412635612767422

Epoch: 6| Step: 12
Training loss: 1.896653329883921
Validation loss: 2.386501810391803

Epoch: 6| Step: 13
Training loss: 1.5718870098041993
Validation loss: 2.3563338386802566

Epoch: 247| Step: 0
Training loss: 1.8402306540671627
Validation loss: 2.3694138934500284

Epoch: 6| Step: 1
Training loss: 2.0503317494732283
Validation loss: 2.337946460143587

Epoch: 6| Step: 2
Training loss: 1.9017445836778006
Validation loss: 2.3441696589771657

Epoch: 6| Step: 3
Training loss: 1.9716464942530065
Validation loss: 2.3399917347843298

Epoch: 6| Step: 4
Training loss: 2.1549051486071047
Validation loss: 2.335121830271821

Epoch: 6| Step: 5
Training loss: 1.5576575964585977
Validation loss: 2.315065265351153

Epoch: 6| Step: 6
Training loss: 2.086691045202294
Validation loss: 2.3259574146762914

Epoch: 6| Step: 7
Training loss: 1.8031156225638278
Validation loss: 2.316172587748014

Epoch: 6| Step: 8
Training loss: 1.6940929051654123
Validation loss: 2.3848979977343583

Epoch: 6| Step: 9
Training loss: 1.721419255752095
Validation loss: 2.4027846609306236

Epoch: 6| Step: 10
Training loss: 1.1192551266346404
Validation loss: 2.42095793245847

Epoch: 6| Step: 11
Training loss: 1.8936266440323277
Validation loss: 2.406443825266544

Epoch: 6| Step: 12
Training loss: 2.1172762356000963
Validation loss: 2.3770825247883507

Epoch: 6| Step: 13
Training loss: 1.751715364344871
Validation loss: 2.3476566999039585

Epoch: 248| Step: 0
Training loss: 2.064310377485597
Validation loss: 2.3424934710604264

Epoch: 6| Step: 1
Training loss: 1.7742729067883163
Validation loss: 2.338401891294658

Epoch: 6| Step: 2
Training loss: 2.2891398862705605
Validation loss: 2.34918226411546

Epoch: 6| Step: 3
Training loss: 1.8097449443318099
Validation loss: 2.3316797115285266

Epoch: 6| Step: 4
Training loss: 1.8246974929507191
Validation loss: 2.351724440471667

Epoch: 6| Step: 5
Training loss: 1.3943395830185044
Validation loss: 2.3701292002902936

Epoch: 6| Step: 6
Training loss: 1.7225188116145398
Validation loss: 2.3912325977075404

Epoch: 6| Step: 7
Training loss: 1.7070751053612838
Validation loss: 2.4018270645737045

Epoch: 6| Step: 8
Training loss: 1.719514226070921
Validation loss: 2.427747404710845

Epoch: 6| Step: 9
Training loss: 2.016227454705666
Validation loss: 2.413424771800416

Epoch: 6| Step: 10
Training loss: 1.7448437886969554
Validation loss: 2.400508673488996

Epoch: 6| Step: 11
Training loss: 1.7571858963474838
Validation loss: 2.3930629819057643

Epoch: 6| Step: 12
Training loss: 2.345965342988453
Validation loss: 2.371568865377018

Epoch: 6| Step: 13
Training loss: 1.302029580596216
Validation loss: 2.356917457640304

Epoch: 249| Step: 0
Training loss: 1.9483882992672892
Validation loss: 2.34978211801641

Epoch: 6| Step: 1
Training loss: 1.8514021791994
Validation loss: 2.3665930533179322

Epoch: 6| Step: 2
Training loss: 2.242518171323983
Validation loss: 2.35824502704031

Epoch: 6| Step: 3
Training loss: 1.4028098094333978
Validation loss: 2.3493184586968336

Epoch: 6| Step: 4
Training loss: 1.3175100345699942
Validation loss: 2.3719608570042654

Epoch: 6| Step: 5
Training loss: 2.059882381377603
Validation loss: 2.341501508550798

Epoch: 6| Step: 6
Training loss: 1.8723884196835439
Validation loss: 2.355329369263305

Epoch: 6| Step: 7
Training loss: 1.9529451821520663
Validation loss: 2.358000633927682

Epoch: 6| Step: 8
Training loss: 1.8169156580503751
Validation loss: 2.336304893661871

Epoch: 6| Step: 9
Training loss: 1.7774371112155198
Validation loss: 2.3448732994427925

Epoch: 6| Step: 10
Training loss: 1.8216965942972485
Validation loss: 2.3222893904868624

Epoch: 6| Step: 11
Training loss: 1.8559224106174745
Validation loss: 2.3651599554103853

Epoch: 6| Step: 12
Training loss: 1.7488775740928921
Validation loss: 2.383492735636415

Epoch: 6| Step: 13
Training loss: 0.9062817337794071
Validation loss: 2.4303359608009516

Epoch: 250| Step: 0
Training loss: 1.7041792100415214
Validation loss: 2.4432541729568444

Epoch: 6| Step: 1
Training loss: 1.7771066360764451
Validation loss: 2.487050504240612

Epoch: 6| Step: 2
Training loss: 2.0079742247762353
Validation loss: 2.494253723595506

Epoch: 6| Step: 3
Training loss: 2.190363617239457
Validation loss: 2.4244569731804257

Epoch: 6| Step: 4
Training loss: 1.1645503717897603
Validation loss: 2.3704582801212726

Epoch: 6| Step: 5
Training loss: 2.205362468865286
Validation loss: 2.331118959789003

Epoch: 6| Step: 6
Training loss: 1.9285820022172049
Validation loss: 2.332097757705165

Epoch: 6| Step: 7
Training loss: 1.694455330019868
Validation loss: 2.335154880064147

Epoch: 6| Step: 8
Training loss: 1.5551126943395284
Validation loss: 2.317870565619447

Epoch: 6| Step: 9
Training loss: 2.0338052962745223
Validation loss: 2.3372718927857723

Epoch: 6| Step: 10
Training loss: 1.6478475807777544
Validation loss: 2.3439479468101037

Epoch: 6| Step: 11
Training loss: 1.5174356243926874
Validation loss: 2.3217490453153524

Epoch: 6| Step: 12
Training loss: 2.1170962831336
Validation loss: 2.363990497598053

Epoch: 6| Step: 13
Training loss: 1.354247408685006
Validation loss: 2.3522525824518814

Epoch: 251| Step: 0
Training loss: 1.8612806027921536
Validation loss: 2.385495840964457

Epoch: 6| Step: 1
Training loss: 1.8902301848984544
Validation loss: 2.40040767357939

Epoch: 6| Step: 2
Training loss: 1.7845869429494885
Validation loss: 2.3795068279327047

Epoch: 6| Step: 3
Training loss: 1.7837110550177007
Validation loss: 2.3755722846014544

Epoch: 6| Step: 4
Training loss: 1.5950622392188374
Validation loss: 2.3679964355303627

Epoch: 6| Step: 5
Training loss: 1.5563274532791755
Validation loss: 2.3602334563100626

Epoch: 6| Step: 6
Training loss: 1.9327252527896965
Validation loss: 2.3451664396998133

Epoch: 6| Step: 7
Training loss: 2.1288492457606143
Validation loss: 2.3401434480791106

Epoch: 6| Step: 8
Training loss: 1.6581522256432797
Validation loss: 2.31267802731915

Epoch: 6| Step: 9
Training loss: 1.6837723143868224
Validation loss: 2.3271349557966112

Epoch: 6| Step: 10
Training loss: 1.557115968044594
Validation loss: 2.318169215025148

Epoch: 6| Step: 11
Training loss: 1.28045331795536
Validation loss: 2.3413376007187416

Epoch: 6| Step: 12
Training loss: 2.10967811949674
Validation loss: 2.355316126145927

Epoch: 6| Step: 13
Training loss: 2.0263787179641826
Validation loss: 2.359075887911998

Epoch: 252| Step: 0
Training loss: 1.682529688512277
Validation loss: 2.3669868979072684

Epoch: 6| Step: 1
Training loss: 1.8923688680351778
Validation loss: 2.3352251367651085

Epoch: 6| Step: 2
Training loss: 2.0002889424459367
Validation loss: 2.3506802976900794

Epoch: 6| Step: 3
Training loss: 1.2541971314913432
Validation loss: 2.3533809140794615

Epoch: 6| Step: 4
Training loss: 2.051519816783349
Validation loss: 2.3367866358059954

Epoch: 6| Step: 5
Training loss: 1.7601017265831946
Validation loss: 2.3476515958913677

Epoch: 6| Step: 6
Training loss: 1.5495409870370684
Validation loss: 2.37217274101555

Epoch: 6| Step: 7
Training loss: 1.461806339838578
Validation loss: 2.351646078718516

Epoch: 6| Step: 8
Training loss: 1.947455149221039
Validation loss: 2.3270998102436664

Epoch: 6| Step: 9
Training loss: 1.8760209165191974
Validation loss: 2.331250800306612

Epoch: 6| Step: 10
Training loss: 1.8369223692329457
Validation loss: 2.3207951890223266

Epoch: 6| Step: 11
Training loss: 2.088317427801687
Validation loss: 2.313146094627204

Epoch: 6| Step: 12
Training loss: 1.7178106341907902
Validation loss: 2.3231752110942994

Epoch: 6| Step: 13
Training loss: 0.6790689964703435
Validation loss: 2.3283083399545914

Epoch: 253| Step: 0
Training loss: 2.2667654389944984
Validation loss: 2.3641512592895726

Epoch: 6| Step: 1
Training loss: 1.6382522136569075
Validation loss: 2.358655822537312

Epoch: 6| Step: 2
Training loss: 1.3280929561564059
Validation loss: 2.3686493289447443

Epoch: 6| Step: 3
Training loss: 1.8947656860024393
Validation loss: 2.3886080694715184

Epoch: 6| Step: 4
Training loss: 1.9141422177276954
Validation loss: 2.3917464911798763

Epoch: 6| Step: 5
Training loss: 1.8948815719920336
Validation loss: 2.378236464143063

Epoch: 6| Step: 6
Training loss: 1.7104106771323202
Validation loss: 2.376971885062525

Epoch: 6| Step: 7
Training loss: 1.833235225075373
Validation loss: 2.3372170363950926

Epoch: 6| Step: 8
Training loss: 2.2154822127330482
Validation loss: 2.3306524896007956

Epoch: 6| Step: 9
Training loss: 1.8472999406621178
Validation loss: 2.3141265775850535

Epoch: 6| Step: 10
Training loss: 1.342575713425469
Validation loss: 2.3017522402762176

Epoch: 6| Step: 11
Training loss: 1.5569599355395258
Validation loss: 2.3048370140414645

Epoch: 6| Step: 12
Training loss: 1.2288568019922221
Validation loss: 2.350445428462693

Epoch: 6| Step: 13
Training loss: 1.2069489781263212
Validation loss: 2.3697610248440393

Epoch: 254| Step: 0
Training loss: 1.8711900785811857
Validation loss: 2.3991508859253896

Epoch: 6| Step: 1
Training loss: 1.7659278542372137
Validation loss: 2.390605683275154

Epoch: 6| Step: 2
Training loss: 1.283335964811195
Validation loss: 2.3694432282474045

Epoch: 6| Step: 3
Training loss: 1.5793900659746052
Validation loss: 2.3295975640751574

Epoch: 6| Step: 4
Training loss: 2.1809668939273763
Validation loss: 2.3251608840652307

Epoch: 6| Step: 5
Training loss: 1.5184140842514113
Validation loss: 2.311217795388633

Epoch: 6| Step: 6
Training loss: 1.9627117018499831
Validation loss: 2.323713398751582

Epoch: 6| Step: 7
Training loss: 2.029472864797101
Validation loss: 2.314237287357088

Epoch: 6| Step: 8
Training loss: 2.0416276370100217
Validation loss: 2.339193537237475

Epoch: 6| Step: 9
Training loss: 1.712142450359989
Validation loss: 2.3635899647813234

Epoch: 6| Step: 10
Training loss: 1.5709779762166662
Validation loss: 2.3930258542649927

Epoch: 6| Step: 11
Training loss: 0.7544761440734976
Validation loss: 2.409060708159562

Epoch: 6| Step: 12
Training loss: 1.9267083774108325
Validation loss: 2.4190169063536335

Epoch: 6| Step: 13
Training loss: 1.6647669774026312
Validation loss: 2.3710844094435277

Epoch: 255| Step: 0
Training loss: 1.714704712116888
Validation loss: 2.3435366860943874

Epoch: 6| Step: 1
Training loss: 1.5698612001135865
Validation loss: 2.3152839539803964

Epoch: 6| Step: 2
Training loss: 1.413398544648467
Validation loss: 2.310484505891511

Epoch: 6| Step: 3
Training loss: 1.9520024850469937
Validation loss: 2.2937152115211523

Epoch: 6| Step: 4
Training loss: 1.7674625253549043
Validation loss: 2.311902286849428

Epoch: 6| Step: 5
Training loss: 1.3250390496887527
Validation loss: 2.310371822032667

Epoch: 6| Step: 6
Training loss: 1.4063481190677187
Validation loss: 2.345899732226998

Epoch: 6| Step: 7
Training loss: 1.839597908328054
Validation loss: 2.375439791500709

Epoch: 6| Step: 8
Training loss: 1.551688517421082
Validation loss: 2.400005637481864

Epoch: 6| Step: 9
Training loss: 2.208391752609941
Validation loss: 2.4074819485134533

Epoch: 6| Step: 10
Training loss: 1.3981903539738194
Validation loss: 2.4166511641936195

Epoch: 6| Step: 11
Training loss: 1.9919947512262586
Validation loss: 2.3911091003835074

Epoch: 6| Step: 12
Training loss: 1.9546646763287066
Validation loss: 2.349884918561334

Epoch: 6| Step: 13
Training loss: 1.6822206779438178
Validation loss: 2.3222818914908174

Epoch: 256| Step: 0
Training loss: 1.825707557114897
Validation loss: 2.2979806584555855

Epoch: 6| Step: 1
Training loss: 1.6810243476406996
Validation loss: 2.2864233309498525

Epoch: 6| Step: 2
Training loss: 1.1869742584908167
Validation loss: 2.2896858992345446

Epoch: 6| Step: 3
Training loss: 1.6856614446324654
Validation loss: 2.294066458178495

Epoch: 6| Step: 4
Training loss: 1.6484529756660267
Validation loss: 2.317040891500295

Epoch: 6| Step: 5
Training loss: 2.0020461344628955
Validation loss: 2.315681012383612

Epoch: 6| Step: 6
Training loss: 1.480201072952465
Validation loss: 2.338639436783687

Epoch: 6| Step: 7
Training loss: 2.054157377251699
Validation loss: 2.348184249067411

Epoch: 6| Step: 8
Training loss: 1.8977209552084522
Validation loss: 2.3370023550067276

Epoch: 6| Step: 9
Training loss: 1.5033189295538982
Validation loss: 2.342813292879742

Epoch: 6| Step: 10
Training loss: 1.7228994046522348
Validation loss: 2.3658667207588113

Epoch: 6| Step: 11
Training loss: 1.4694939210603095
Validation loss: 2.3312547965570722

Epoch: 6| Step: 12
Training loss: 1.428917098799328
Validation loss: 2.313658607802505

Epoch: 6| Step: 13
Training loss: 1.8698081296516564
Validation loss: 2.3023699009164824

Epoch: 257| Step: 0
Training loss: 1.333567921545362
Validation loss: 2.272007481632309

Epoch: 6| Step: 1
Training loss: 1.355993076019839
Validation loss: 2.2946225572829406

Epoch: 6| Step: 2
Training loss: 1.975946805450329
Validation loss: 2.3035533496953677

Epoch: 6| Step: 3
Training loss: 1.789315951189491
Validation loss: 2.2962135990561032

Epoch: 6| Step: 4
Training loss: 2.0040228439825984
Validation loss: 2.30481544001858

Epoch: 6| Step: 5
Training loss: 1.9859851702379425
Validation loss: 2.3284296751884455

Epoch: 6| Step: 6
Training loss: 1.702313571082958
Validation loss: 2.3288501040597507

Epoch: 6| Step: 7
Training loss: 1.4614002494480813
Validation loss: 2.3604559239263416

Epoch: 6| Step: 8
Training loss: 1.7960741995286282
Validation loss: 2.3620283243798115

Epoch: 6| Step: 9
Training loss: 1.9369077700279709
Validation loss: 2.4198543241831385

Epoch: 6| Step: 10
Training loss: 1.5293698348257052
Validation loss: 2.4028458558859054

Epoch: 6| Step: 11
Training loss: 1.974220486614881
Validation loss: 2.3693662661655743

Epoch: 6| Step: 12
Training loss: 1.0444749107944982
Validation loss: 2.36957648290954

Epoch: 6| Step: 13
Training loss: 0.9874010048510944
Validation loss: 2.323271588312905

Epoch: 258| Step: 0
Training loss: 2.1345400119515374
Validation loss: 2.3260009352353843

Epoch: 6| Step: 1
Training loss: 1.990169205876118
Validation loss: 2.310295779458623

Epoch: 6| Step: 2
Training loss: 1.4641753032142293
Validation loss: 2.293729374165171

Epoch: 6| Step: 3
Training loss: 1.2573599623256735
Validation loss: 2.305533768872612

Epoch: 6| Step: 4
Training loss: 1.8312027283904422
Validation loss: 2.32530818206207

Epoch: 6| Step: 5
Training loss: 1.3533835959065956
Validation loss: 2.291824379767673

Epoch: 6| Step: 6
Training loss: 1.5690911700940575
Validation loss: 2.3007875622055947

Epoch: 6| Step: 7
Training loss: 1.3614106994717312
Validation loss: 2.3225821282625305

Epoch: 6| Step: 8
Training loss: 1.4676877502485377
Validation loss: 2.3181716347116605

Epoch: 6| Step: 9
Training loss: 1.9727326935412781
Validation loss: 2.3246906753095167

Epoch: 6| Step: 10
Training loss: 1.5742958371808928
Validation loss: 2.335322903753366

Epoch: 6| Step: 11
Training loss: 2.0967836181012327
Validation loss: 2.3344524581276342

Epoch: 6| Step: 12
Training loss: 1.2296839072963868
Validation loss: 2.3123309354389603

Epoch: 6| Step: 13
Training loss: 1.352275594121052
Validation loss: 2.276172418392143

Epoch: 259| Step: 0
Training loss: 1.819126381223426
Validation loss: 2.2528678444293204

Epoch: 6| Step: 1
Training loss: 1.9638852764038262
Validation loss: 2.254508282817708

Epoch: 6| Step: 2
Training loss: 1.3591211016088673
Validation loss: 2.2682233316129286

Epoch: 6| Step: 3
Training loss: 1.7154519777305863
Validation loss: 2.317613469544805

Epoch: 6| Step: 4
Training loss: 1.7355449957261095
Validation loss: 2.3136249356954384

Epoch: 6| Step: 5
Training loss: 1.553605206127067
Validation loss: 2.3037619691325872

Epoch: 6| Step: 6
Training loss: 1.305767503177394
Validation loss: 2.2994802417812306

Epoch: 6| Step: 7
Training loss: 1.5805286194365196
Validation loss: 2.2843764835695866

Epoch: 6| Step: 8
Training loss: 0.9702256254413986
Validation loss: 2.2955385502352272

Epoch: 6| Step: 9
Training loss: 2.027682413909951
Validation loss: 2.3101596136216838

Epoch: 6| Step: 10
Training loss: 1.1073013051649139
Validation loss: 2.3304060185307724

Epoch: 6| Step: 11
Training loss: 1.7508913222594031
Validation loss: 2.3604830779069985

Epoch: 6| Step: 12
Training loss: 2.0944112615995083
Validation loss: 2.3324270781114866

Epoch: 6| Step: 13
Training loss: 1.4496941210954708
Validation loss: 2.3371970215867788

Epoch: 260| Step: 0
Training loss: 1.7514547023899665
Validation loss: 2.2939486160296094

Epoch: 6| Step: 1
Training loss: 1.8644461199462803
Validation loss: 2.3007588284377367

Epoch: 6| Step: 2
Training loss: 1.44456652386244
Validation loss: 2.2966606347601517

Epoch: 6| Step: 3
Training loss: 1.393881595711253
Validation loss: 2.2706172426730844

Epoch: 6| Step: 4
Training loss: 1.5964553908780152
Validation loss: 2.2746388774728596

Epoch: 6| Step: 5
Training loss: 1.463523575024991
Validation loss: 2.2864893858999955

Epoch: 6| Step: 6
Training loss: 1.7483886384656366
Validation loss: 2.2906099043836137

Epoch: 6| Step: 7
Training loss: 1.5943481220535414
Validation loss: 2.3040194503121705

Epoch: 6| Step: 8
Training loss: 1.4268792092273332
Validation loss: 2.310554511940641

Epoch: 6| Step: 9
Training loss: 1.8971374832871666
Validation loss: 2.320648788821112

Epoch: 6| Step: 10
Training loss: 1.7420162920797664
Validation loss: 2.3228997792261428

Epoch: 6| Step: 11
Training loss: 1.461169056212778
Validation loss: 2.3360856834001504

Epoch: 6| Step: 12
Training loss: 1.643093758478685
Validation loss: 2.3005360901476526

Epoch: 6| Step: 13
Training loss: 1.8335669614300236
Validation loss: 2.2514251015096307

Epoch: 261| Step: 0
Training loss: 1.820194551633228
Validation loss: 2.297071775370558

Epoch: 6| Step: 1
Training loss: 1.68476731185068
Validation loss: 2.3089356972279997

Epoch: 6| Step: 2
Training loss: 1.6967616765238913
Validation loss: 2.317660003928811

Epoch: 6| Step: 3
Training loss: 1.611205680125167
Validation loss: 2.350295464943458

Epoch: 6| Step: 4
Training loss: 1.0722516168398506
Validation loss: 2.3409465909556397

Epoch: 6| Step: 5
Training loss: 1.7066807856323427
Validation loss: 2.3585186519126884

Epoch: 6| Step: 6
Training loss: 1.6032521336879002
Validation loss: 2.3514461437444742

Epoch: 6| Step: 7
Training loss: 1.7747164916236253
Validation loss: 2.3026130507441787

Epoch: 6| Step: 8
Training loss: 1.3673981422553416
Validation loss: 2.3299248545967965

Epoch: 6| Step: 9
Training loss: 1.0422061032031789
Validation loss: 2.3174838366751644

Epoch: 6| Step: 10
Training loss: 1.7361943093603742
Validation loss: 2.331752938100639

Epoch: 6| Step: 11
Training loss: 2.036729084042816
Validation loss: 2.322050151413619

Epoch: 6| Step: 12
Training loss: 1.1189152089465992
Validation loss: 2.316929244618366

Epoch: 6| Step: 13
Training loss: 1.4696327965313734
Validation loss: 2.3316265498524884

Epoch: 262| Step: 0
Training loss: 1.7560376510667735
Validation loss: 2.3177958596490176

Epoch: 6| Step: 1
Training loss: 1.3844516328220562
Validation loss: 2.3300151641266336

Epoch: 6| Step: 2
Training loss: 1.6654949201851676
Validation loss: 2.3059861239937285

Epoch: 6| Step: 3
Training loss: 1.438640225197232
Validation loss: 2.291591962079604

Epoch: 6| Step: 4
Training loss: 1.376332980711074
Validation loss: 2.2998686130754646

Epoch: 6| Step: 5
Training loss: 1.5675092129231256
Validation loss: 2.287350282566776

Epoch: 6| Step: 6
Training loss: 1.4243774191755076
Validation loss: 2.302020541516895

Epoch: 6| Step: 7
Training loss: 1.8602564669756707
Validation loss: 2.311235253279297

Epoch: 6| Step: 8
Training loss: 1.2854817914411347
Validation loss: 2.28410279089315

Epoch: 6| Step: 9
Training loss: 1.6874432024404264
Validation loss: 2.2935660779243703

Epoch: 6| Step: 10
Training loss: 1.4671654777783487
Validation loss: 2.310942857537484

Epoch: 6| Step: 11
Training loss: 1.9020570386202074
Validation loss: 2.3331808188324348

Epoch: 6| Step: 12
Training loss: 1.6558607111783945
Validation loss: 2.3105727781398313

Epoch: 6| Step: 13
Training loss: 1.4126264329887315
Validation loss: 2.284440440241116

Epoch: 263| Step: 0
Training loss: 1.4009965891718272
Validation loss: 2.288019347682269

Epoch: 6| Step: 1
Training loss: 1.6267157080298256
Validation loss: 2.323414750300926

Epoch: 6| Step: 2
Training loss: 1.8649653535340012
Validation loss: 2.3516132247196837

Epoch: 6| Step: 3
Training loss: 1.9872806332043929
Validation loss: 2.377715660372286

Epoch: 6| Step: 4
Training loss: 1.356922480430269
Validation loss: 2.41835729135945

Epoch: 6| Step: 5
Training loss: 1.543353609785407
Validation loss: 2.3858570935913157

Epoch: 6| Step: 6
Training loss: 1.5743137832618803
Validation loss: 2.381516316110872

Epoch: 6| Step: 7
Training loss: 1.0512230947455696
Validation loss: 2.365803670961159

Epoch: 6| Step: 8
Training loss: 1.3566667610812018
Validation loss: 2.325337840090829

Epoch: 6| Step: 9
Training loss: 1.3813817871882497
Validation loss: 2.3049439446247724

Epoch: 6| Step: 10
Training loss: 2.129179042872263
Validation loss: 2.3251756319257444

Epoch: 6| Step: 11
Training loss: 1.7633250963322744
Validation loss: 2.3060928289836586

Epoch: 6| Step: 12
Training loss: 1.0789850094366416
Validation loss: 2.3415183246045084

Epoch: 6| Step: 13
Training loss: 1.363294759863777
Validation loss: 2.329186306004644

Epoch: 264| Step: 0
Training loss: 1.5739523233853951
Validation loss: 2.345182560465432

Epoch: 6| Step: 1
Training loss: 2.0728015835763705
Validation loss: 2.3591633472015103

Epoch: 6| Step: 2
Training loss: 1.18251492021112
Validation loss: 2.3684419026440846

Epoch: 6| Step: 3
Training loss: 1.3543372804805
Validation loss: 2.3612023654637975

Epoch: 6| Step: 4
Training loss: 1.352343471445532
Validation loss: 2.362167345656329

Epoch: 6| Step: 5
Training loss: 2.046048528951527
Validation loss: 2.363493403952528

Epoch: 6| Step: 6
Training loss: 1.3592252100707574
Validation loss: 2.338042433515366

Epoch: 6| Step: 7
Training loss: 1.5669050302507403
Validation loss: 2.3356316720513126

Epoch: 6| Step: 8
Training loss: 1.4750167587104095
Validation loss: 2.3349562723598827

Epoch: 6| Step: 9
Training loss: 1.6118710614644773
Validation loss: 2.290438273777865

Epoch: 6| Step: 10
Training loss: 1.4980663711094864
Validation loss: 2.29082791779763

Epoch: 6| Step: 11
Training loss: 1.4227926625645717
Validation loss: 2.317792910868928

Epoch: 6| Step: 12
Training loss: 1.4565805346574117
Validation loss: 2.3131771121792677

Epoch: 6| Step: 13
Training loss: 1.7553390393891817
Validation loss: 2.33706034220041

Epoch: 265| Step: 0
Training loss: 1.4182910395292068
Validation loss: 2.368106081842389

Epoch: 6| Step: 1
Training loss: 1.5691645587428205
Validation loss: 2.3450569976835136

Epoch: 6| Step: 2
Training loss: 1.6994564898567242
Validation loss: 2.3407014508114483

Epoch: 6| Step: 3
Training loss: 0.9656461089953403
Validation loss: 2.323173349476861

Epoch: 6| Step: 4
Training loss: 1.3171715931141192
Validation loss: 2.3163177971929074

Epoch: 6| Step: 5
Training loss: 1.240340389016011
Validation loss: 2.3259132584310485

Epoch: 6| Step: 6
Training loss: 1.6583822668066874
Validation loss: 2.310955191239476

Epoch: 6| Step: 7
Training loss: 1.3526516092896543
Validation loss: 2.3156560764134735

Epoch: 6| Step: 8
Training loss: 1.493995888874163
Validation loss: 2.321771973605148

Epoch: 6| Step: 9
Training loss: 1.5283952688537785
Validation loss: 2.3315849595148066

Epoch: 6| Step: 10
Training loss: 1.786104580597172
Validation loss: 2.309394116490246

Epoch: 6| Step: 11
Training loss: 1.8419687103985454
Validation loss: 2.3036137519305906

Epoch: 6| Step: 12
Training loss: 1.7713345061544647
Validation loss: 2.3287461140453094

Epoch: 6| Step: 13
Training loss: 1.5396171383723212
Validation loss: 2.34215727363975

Epoch: 266| Step: 0
Training loss: 1.241180491580517
Validation loss: 2.3362737069289214

Epoch: 6| Step: 1
Training loss: 1.4829468934523746
Validation loss: 2.3486219166630486

Epoch: 6| Step: 2
Training loss: 1.9431371820607224
Validation loss: 2.346487360662381

Epoch: 6| Step: 3
Training loss: 1.1542533440296694
Validation loss: 2.3844324155478653

Epoch: 6| Step: 4
Training loss: 1.2273514755268127
Validation loss: 2.365777750543211

Epoch: 6| Step: 5
Training loss: 1.5130471398522787
Validation loss: 2.314380301472164

Epoch: 6| Step: 6
Training loss: 1.281854021932059
Validation loss: 2.3267877480372157

Epoch: 6| Step: 7
Training loss: 1.3744961509026246
Validation loss: 2.337539701205251

Epoch: 6| Step: 8
Training loss: 1.4747883467033571
Validation loss: 2.338495160095878

Epoch: 6| Step: 9
Training loss: 1.4015262526776229
Validation loss: 2.3209974539504676

Epoch: 6| Step: 10
Training loss: 1.6800161350701575
Validation loss: 2.3328744426806893

Epoch: 6| Step: 11
Training loss: 1.649340124827603
Validation loss: 2.2913177232030697

Epoch: 6| Step: 12
Training loss: 2.1283571987661167
Validation loss: 2.303264752051091

Epoch: 6| Step: 13
Training loss: 1.4682758458748368
Validation loss: 2.2918323766434763

Epoch: 267| Step: 0
Training loss: 1.790051848870045
Validation loss: 2.2864748997877316

Epoch: 6| Step: 1
Training loss: 1.5266915023788104
Validation loss: 2.30212977554662

Epoch: 6| Step: 2
Training loss: 1.793832342404454
Validation loss: 2.3119349322808014

Epoch: 6| Step: 3
Training loss: 1.8881270245033277
Validation loss: 2.3474539821377394

Epoch: 6| Step: 4
Training loss: 1.2868253310531603
Validation loss: 2.3626860798418035

Epoch: 6| Step: 5
Training loss: 1.5379280517922884
Validation loss: 2.357264086682191

Epoch: 6| Step: 6
Training loss: 1.7171465243170487
Validation loss: 2.299184767782998

Epoch: 6| Step: 7
Training loss: 1.483090457248756
Validation loss: 2.30627215624044

Epoch: 6| Step: 8
Training loss: 1.4371735575332076
Validation loss: 2.311667151276688

Epoch: 6| Step: 9
Training loss: 0.9568501826680279
Validation loss: 2.3149679313138942

Epoch: 6| Step: 10
Training loss: 1.3085115321507195
Validation loss: 2.3088529408082223

Epoch: 6| Step: 11
Training loss: 1.2671745139701913
Validation loss: 2.3067729810179056

Epoch: 6| Step: 12
Training loss: 0.9879641419942294
Validation loss: 2.3017609778467785

Epoch: 6| Step: 13
Training loss: 1.701405067972429
Validation loss: 2.320141009202833

Epoch: 268| Step: 0
Training loss: 1.1547259003031554
Validation loss: 2.326322984769538

Epoch: 6| Step: 1
Training loss: 1.339492929867849
Validation loss: 2.3206573182604076

Epoch: 6| Step: 2
Training loss: 1.186783072239617
Validation loss: 2.332894770400433

Epoch: 6| Step: 3
Training loss: 1.245448169473605
Validation loss: 2.3341546059947462

Epoch: 6| Step: 4
Training loss: 1.0781488830574772
Validation loss: 2.298883730158998

Epoch: 6| Step: 5
Training loss: 1.1950706287085833
Validation loss: 2.316262980234717

Epoch: 6| Step: 6
Training loss: 1.7831952365395751
Validation loss: 2.3119709559349757

Epoch: 6| Step: 7
Training loss: 1.5291140704070356
Validation loss: 2.316532786946419

Epoch: 6| Step: 8
Training loss: 1.2734323513184356
Validation loss: 2.358406290163411

Epoch: 6| Step: 9
Training loss: 1.6543339856881991
Validation loss: 2.3429105254747733

Epoch: 6| Step: 10
Training loss: 1.4943000259641421
Validation loss: 2.3610813300248994

Epoch: 6| Step: 11
Training loss: 2.2225947849242362
Validation loss: 2.3858018940125407

Epoch: 6| Step: 12
Training loss: 1.5245052410572377
Validation loss: 2.3514283793068693

Epoch: 6| Step: 13
Training loss: 1.702076650518452
Validation loss: 2.341600130754957

Epoch: 269| Step: 0
Training loss: 1.5235466551189356
Validation loss: 2.3275152314830154

Epoch: 6| Step: 1
Training loss: 1.8059728759638227
Validation loss: 2.308907831541937

Epoch: 6| Step: 2
Training loss: 1.2974547044201477
Validation loss: 2.29709614859712

Epoch: 6| Step: 3
Training loss: 1.6855224749057711
Validation loss: 2.2996853557479278

Epoch: 6| Step: 4
Training loss: 1.5890620979000998
Validation loss: 2.323700935284296

Epoch: 6| Step: 5
Training loss: 1.6538599871839974
Validation loss: 2.367279344984432

Epoch: 6| Step: 6
Training loss: 1.2604592476369925
Validation loss: 2.3865131208832384

Epoch: 6| Step: 7
Training loss: 1.2579967292779515
Validation loss: 2.411680527905686

Epoch: 6| Step: 8
Training loss: 1.709923430619138
Validation loss: 2.380336706762409

Epoch: 6| Step: 9
Training loss: 1.5827676448510313
Validation loss: 2.3731252787227204

Epoch: 6| Step: 10
Training loss: 1.235884311076482
Validation loss: 2.337839383220408

Epoch: 6| Step: 11
Training loss: 1.0609090899566795
Validation loss: 2.3133869460166907

Epoch: 6| Step: 12
Training loss: 0.9981483363108974
Validation loss: 2.3140769510527726

Epoch: 6| Step: 13
Training loss: 1.299323103814709
Validation loss: 2.2912494689852356

Epoch: 270| Step: 0
Training loss: 1.2955960321201336
Validation loss: 2.2971089271669896

Epoch: 6| Step: 1
Training loss: 1.4185034214122387
Validation loss: 2.2644423292255493

Epoch: 6| Step: 2
Training loss: 0.8081233181091414
Validation loss: 2.305934900331546

Epoch: 6| Step: 3
Training loss: 1.6920375570859039
Validation loss: 2.326364196424271

Epoch: 6| Step: 4
Training loss: 0.7365921316227388
Validation loss: 2.3313758376920735

Epoch: 6| Step: 5
Training loss: 1.4401310601462456
Validation loss: 2.30983892871223

Epoch: 6| Step: 6
Training loss: 1.8136759922063836
Validation loss: 2.2734914032618567

Epoch: 6| Step: 7
Training loss: 2.181927367570588
Validation loss: 2.256458123638

Epoch: 6| Step: 8
Training loss: 1.7440186187686455
Validation loss: 2.264183865293673

Epoch: 6| Step: 9
Training loss: 1.1174189187830683
Validation loss: 2.295386491642843

Epoch: 6| Step: 10
Training loss: 1.4016384380611195
Validation loss: 2.290574954434894

Epoch: 6| Step: 11
Training loss: 1.4905351207834932
Validation loss: 2.309565161503916

Epoch: 6| Step: 12
Training loss: 1.0286041766395455
Validation loss: 2.3507461752602676

Epoch: 6| Step: 13
Training loss: 1.5052135779829514
Validation loss: 2.38130740423077

Epoch: 271| Step: 0
Training loss: 1.4264270730723325
Validation loss: 2.3598622410683636

Epoch: 6| Step: 1
Training loss: 1.2406905649381863
Validation loss: 2.3600087984139027

Epoch: 6| Step: 2
Training loss: 1.393627269113801
Validation loss: 2.3429872974082246

Epoch: 6| Step: 3
Training loss: 1.3104850197306632
Validation loss: 2.3462003241555154

Epoch: 6| Step: 4
Training loss: 1.2218151185174828
Validation loss: 2.340549227671252

Epoch: 6| Step: 5
Training loss: 1.5659105843731798
Validation loss: 2.3552930683370614

Epoch: 6| Step: 6
Training loss: 1.560428237702369
Validation loss: 2.418966813982397

Epoch: 6| Step: 7
Training loss: 1.5922811134378299
Validation loss: 2.403708232169734

Epoch: 6| Step: 8
Training loss: 1.935195906428738
Validation loss: 2.424519425018001

Epoch: 6| Step: 9
Training loss: 1.5508575036353376
Validation loss: 2.4689799344873102

Epoch: 6| Step: 10
Training loss: 1.5779977879381812
Validation loss: 2.456905789642032

Epoch: 6| Step: 11
Training loss: 1.1427508883809752
Validation loss: 2.440990480390388

Epoch: 6| Step: 12
Training loss: 1.112965857017235
Validation loss: 2.3927977777257143

Epoch: 6| Step: 13
Training loss: 1.2590922603844057
Validation loss: 2.3372291360187947

Epoch: 272| Step: 0
Training loss: 0.9729973068690103
Validation loss: 2.3260968768627253

Epoch: 6| Step: 1
Training loss: 1.6350624607999424
Validation loss: 2.3205385572759596

Epoch: 6| Step: 2
Training loss: 1.272049972908077
Validation loss: 2.3240401192036195

Epoch: 6| Step: 3
Training loss: 1.4512568945642896
Validation loss: 2.332582744900738

Epoch: 6| Step: 4
Training loss: 1.3961716094931174
Validation loss: 2.354194555644645

Epoch: 6| Step: 5
Training loss: 1.194124117242069
Validation loss: 2.3568354434888836

Epoch: 6| Step: 6
Training loss: 1.2797926546333411
Validation loss: 2.3490199508499714

Epoch: 6| Step: 7
Training loss: 1.263734889633445
Validation loss: 2.3444104888990207

Epoch: 6| Step: 8
Training loss: 1.431792413801698
Validation loss: 2.3590791306641443

Epoch: 6| Step: 9
Training loss: 0.9779548180095619
Validation loss: 2.33888237725372

Epoch: 6| Step: 10
Training loss: 1.3867856291641125
Validation loss: 2.3179662896668143

Epoch: 6| Step: 11
Training loss: 1.8800438749996842
Validation loss: 2.330671374856294

Epoch: 6| Step: 12
Training loss: 1.3789278196209358
Validation loss: 2.322470373559048

Epoch: 6| Step: 13
Training loss: 2.0820579312388077
Validation loss: 2.322534957360037

Epoch: 273| Step: 0
Training loss: 1.116732097720498
Validation loss: 2.3283216849376958

Epoch: 6| Step: 1
Training loss: 1.1667488897958742
Validation loss: 2.322270669997804

Epoch: 6| Step: 2
Training loss: 0.9817413946269518
Validation loss: 2.299994165547779

Epoch: 6| Step: 3
Training loss: 1.8901459268214096
Validation loss: 2.298211399898047

Epoch: 6| Step: 4
Training loss: 1.615973565225335
Validation loss: 2.2962994580256835

Epoch: 6| Step: 5
Training loss: 1.3039154235261157
Validation loss: 2.3018157392162584

Epoch: 6| Step: 6
Training loss: 1.1009034694725417
Validation loss: 2.3165422533944287

Epoch: 6| Step: 7
Training loss: 1.4600251148624304
Validation loss: 2.33185719970279

Epoch: 6| Step: 8
Training loss: 1.4627294311537686
Validation loss: 2.30493571517912

Epoch: 6| Step: 9
Training loss: 1.2421043416144468
Validation loss: 2.311089259148

Epoch: 6| Step: 10
Training loss: 1.4221566728215218
Validation loss: 2.323213775041294

Epoch: 6| Step: 11
Training loss: 1.6796535754659172
Validation loss: 2.3213655428650326

Epoch: 6| Step: 12
Training loss: 1.354386042896241
Validation loss: 2.3423195721303727

Epoch: 6| Step: 13
Training loss: 1.1977141941732479
Validation loss: 2.352545421086402

Epoch: 274| Step: 0
Training loss: 1.4739021676980695
Validation loss: 2.353550658205465

Epoch: 6| Step: 1
Training loss: 1.4942715456581834
Validation loss: 2.374093961790865

Epoch: 6| Step: 2
Training loss: 2.125622938514614
Validation loss: 2.3584432508118827

Epoch: 6| Step: 3
Training loss: 1.4397631535195023
Validation loss: 2.3705302882613353

Epoch: 6| Step: 4
Training loss: 1.0928956100717764
Validation loss: 2.334896190143589

Epoch: 6| Step: 5
Training loss: 1.1743224970606079
Validation loss: 2.3253361521919054

Epoch: 6| Step: 6
Training loss: 1.5355672892686358
Validation loss: 2.293404776006374

Epoch: 6| Step: 7
Training loss: 1.3808549721740717
Validation loss: 2.2783351160139937

Epoch: 6| Step: 8
Training loss: 1.3611535462535358
Validation loss: 2.2893648906459467

Epoch: 6| Step: 9
Training loss: 0.9318716854289801
Validation loss: 2.324585586074245

Epoch: 6| Step: 10
Training loss: 1.262723634760672
Validation loss: 2.3022452702878193

Epoch: 6| Step: 11
Training loss: 1.2899988646095661
Validation loss: 2.3591546315194347

Epoch: 6| Step: 12
Training loss: 0.7669492285509891
Validation loss: 2.3962564832138877

Epoch: 6| Step: 13
Training loss: 0.7686727547022619
Validation loss: 2.3845284902331207

Epoch: 275| Step: 0
Training loss: 0.9599656253362617
Validation loss: 2.431557556517848

Epoch: 6| Step: 1
Training loss: 1.335580030656216
Validation loss: 2.427303069947475

Epoch: 6| Step: 2
Training loss: 1.3224694504842027
Validation loss: 2.3910798153504182

Epoch: 6| Step: 3
Training loss: 1.3895406889007749
Validation loss: 2.3471545698149088

Epoch: 6| Step: 4
Training loss: 1.1513297064377455
Validation loss: 2.3156896918626977

Epoch: 6| Step: 5
Training loss: 1.7382422282093062
Validation loss: 2.295415636093212

Epoch: 6| Step: 6
Training loss: 1.6334862300127777
Validation loss: 2.3052659654897303

Epoch: 6| Step: 7
Training loss: 1.2702092165091678
Validation loss: 2.3431695209700165

Epoch: 6| Step: 8
Training loss: 1.6432078783819588
Validation loss: 2.3928445647176044

Epoch: 6| Step: 9
Training loss: 1.3453668581163227
Validation loss: 2.4130572803966444

Epoch: 6| Step: 10
Training loss: 1.5261062330663229
Validation loss: 2.394095293243295

Epoch: 6| Step: 11
Training loss: 0.7023982636848444
Validation loss: 2.3951471088766176

Epoch: 6| Step: 12
Training loss: 1.3040926828006387
Validation loss: 2.3902408967681956

Epoch: 6| Step: 13
Training loss: 0.590693083376193
Validation loss: 2.3193253682731734

Epoch: 276| Step: 0
Training loss: 1.3659929561070339
Validation loss: 2.3120190276275467

Epoch: 6| Step: 1
Training loss: 1.201236084253089
Validation loss: 2.2896789551714583

Epoch: 6| Step: 2
Training loss: 0.9236130252298839
Validation loss: 2.2835465105650323

Epoch: 6| Step: 3
Training loss: 0.9067812710679297
Validation loss: 2.263764410847266

Epoch: 6| Step: 4
Training loss: 1.6645388212526842
Validation loss: 2.2956268231813186

Epoch: 6| Step: 5
Training loss: 1.4346441843269602
Validation loss: 2.3023483405208087

Epoch: 6| Step: 6
Training loss: 1.4135655747118048
Validation loss: 2.324202645972379

Epoch: 6| Step: 7
Training loss: 1.4166125492904293
Validation loss: 2.3626519307934606

Epoch: 6| Step: 8
Training loss: 1.5437463273842558
Validation loss: 2.40130421360171

Epoch: 6| Step: 9
Training loss: 1.1608159408489584
Validation loss: 2.4153008878509827

Epoch: 6| Step: 10
Training loss: 1.7485748346168228
Validation loss: 2.368027750110895

Epoch: 6| Step: 11
Training loss: 0.7125634265576105
Validation loss: 2.3420295181380704

Epoch: 6| Step: 12
Training loss: 1.055024269873434
Validation loss: 2.3207758069473226

Epoch: 6| Step: 13
Training loss: 1.192729827598338
Validation loss: 2.319751787625914

Epoch: 277| Step: 0
Training loss: 1.5703645763966767
Validation loss: 2.3020824494919543

Epoch: 6| Step: 1
Training loss: 1.0560029480163289
Validation loss: 2.310621045346456

Epoch: 6| Step: 2
Training loss: 1.0728119116941817
Validation loss: 2.321851504804089

Epoch: 6| Step: 3
Training loss: 1.082891734913686
Validation loss: 2.3155834191441667

Epoch: 6| Step: 4
Training loss: 1.1653586730238858
Validation loss: 2.3827430525352016

Epoch: 6| Step: 5
Training loss: 1.4764614978941353
Validation loss: 2.4046552711558484

Epoch: 6| Step: 6
Training loss: 1.5080956702101467
Validation loss: 2.3925317930147467

Epoch: 6| Step: 7
Training loss: 1.691306166297734
Validation loss: 2.3888377485201246

Epoch: 6| Step: 8
Training loss: 1.1520968932491427
Validation loss: 2.376583767303924

Epoch: 6| Step: 9
Training loss: 1.3644997471648053
Validation loss: 2.4356058447803477

Epoch: 6| Step: 10
Training loss: 1.1895432211041674
Validation loss: 2.4378532151644565

Epoch: 6| Step: 11
Training loss: 1.0939213209853567
Validation loss: 2.4165608906608043

Epoch: 6| Step: 12
Training loss: 1.2612009787130143
Validation loss: 2.377222808504624

Epoch: 6| Step: 13
Training loss: 1.127699051433603
Validation loss: 2.348803866257275

Epoch: 278| Step: 0
Training loss: 1.371369467289061
Validation loss: 2.298229399435994

Epoch: 6| Step: 1
Training loss: 0.6695690504907552
Validation loss: 2.294845919254288

Epoch: 6| Step: 2
Training loss: 1.968127803273535
Validation loss: 2.3143027312166446

Epoch: 6| Step: 3
Training loss: 1.256557810256885
Validation loss: 2.312325404215798

Epoch: 6| Step: 4
Training loss: 1.109477938322245
Validation loss: 2.2999677475696085

Epoch: 6| Step: 5
Training loss: 1.3826260629609666
Validation loss: 2.351002363286913

Epoch: 6| Step: 6
Training loss: 1.1512689265415326
Validation loss: 2.408880218302904

Epoch: 6| Step: 7
Training loss: 1.0543352457182533
Validation loss: 2.430533184489611

Epoch: 6| Step: 8
Training loss: 1.1703767481282275
Validation loss: 2.4686271394953163

Epoch: 6| Step: 9
Training loss: 1.4101794127361016
Validation loss: 2.3956590807564324

Epoch: 6| Step: 10
Training loss: 1.589911682027253
Validation loss: 2.3501353889873893

Epoch: 6| Step: 11
Training loss: 1.2591009707998757
Validation loss: 2.2977868048400136

Epoch: 6| Step: 12
Training loss: 0.9177188289589172
Validation loss: 2.267944912820181

Epoch: 6| Step: 13
Training loss: 1.5195967554716983
Validation loss: 2.2801467873335373

Epoch: 279| Step: 0
Training loss: 1.4375819307281767
Validation loss: 2.30836420073735

Epoch: 6| Step: 1
Training loss: 1.3925746152600846
Validation loss: 2.3034922291452657

Epoch: 6| Step: 2
Training loss: 1.1503686562789865
Validation loss: 2.3529262004279334

Epoch: 6| Step: 3
Training loss: 1.0589786969816772
Validation loss: 2.365697463714075

Epoch: 6| Step: 4
Training loss: 1.2081398425347427
Validation loss: 2.3828122697598437

Epoch: 6| Step: 5
Training loss: 1.5058460754519705
Validation loss: 2.371540641118193

Epoch: 6| Step: 6
Training loss: 1.592807416243558
Validation loss: 2.3677152428971184

Epoch: 6| Step: 7
Training loss: 1.1175194093866267
Validation loss: 2.3621005249286346

Epoch: 6| Step: 8
Training loss: 1.0396128752848672
Validation loss: 2.331720436548016

Epoch: 6| Step: 9
Training loss: 1.270970628961792
Validation loss: 2.3549701275357053

Epoch: 6| Step: 10
Training loss: 1.2181173296354666
Validation loss: 2.3237535545580843

Epoch: 6| Step: 11
Training loss: 1.2548707004066493
Validation loss: 2.347768388078267

Epoch: 6| Step: 12
Training loss: 1.0239534315196954
Validation loss: 2.3368982719458797

Epoch: 6| Step: 13
Training loss: 1.4171820525850118
Validation loss: 2.339047397519258

Epoch: 280| Step: 0
Training loss: 1.212058157888324
Validation loss: 2.3358176786397964

Epoch: 6| Step: 1
Training loss: 1.6508099446508535
Validation loss: 2.324407262508598

Epoch: 6| Step: 2
Training loss: 1.259857931377802
Validation loss: 2.3797416645996754

Epoch: 6| Step: 3
Training loss: 1.1802976937510399
Validation loss: 2.335070549141394

Epoch: 6| Step: 4
Training loss: 1.2390096068667922
Validation loss: 2.3485209383825976

Epoch: 6| Step: 5
Training loss: 0.8167688030160439
Validation loss: 2.3226856828873146

Epoch: 6| Step: 6
Training loss: 1.4614074277633444
Validation loss: 2.306560589329659

Epoch: 6| Step: 7
Training loss: 1.1828397861089879
Validation loss: 2.269553065673889

Epoch: 6| Step: 8
Training loss: 1.0760665814351729
Validation loss: 2.2635546810914495

Epoch: 6| Step: 9
Training loss: 1.1166934541554316
Validation loss: 2.2807935650584565

Epoch: 6| Step: 10
Training loss: 1.311162357801514
Validation loss: 2.294743753230687

Epoch: 6| Step: 11
Training loss: 1.077606076287553
Validation loss: 2.3018503887419164

Epoch: 6| Step: 12
Training loss: 1.1411390322063697
Validation loss: 2.2973624426467607

Epoch: 6| Step: 13
Training loss: 1.7902737977100631
Validation loss: 2.298699039277395

Epoch: 281| Step: 0
Training loss: 1.7573783507917187
Validation loss: 2.265897809818336

Epoch: 6| Step: 1
Training loss: 1.552065531310668
Validation loss: 2.2721801760925833

Epoch: 6| Step: 2
Training loss: 1.2531405098352446
Validation loss: 2.276223538639188

Epoch: 6| Step: 3
Training loss: 1.4604315059994495
Validation loss: 2.3242064381500227

Epoch: 6| Step: 4
Training loss: 0.8941805622719308
Validation loss: 2.3251291685713387

Epoch: 6| Step: 5
Training loss: 1.2626002866741346
Validation loss: 2.3653680510207957

Epoch: 6| Step: 6
Training loss: 1.3333761188476996
Validation loss: 2.387375937572956

Epoch: 6| Step: 7
Training loss: 1.583758280430609
Validation loss: 2.414195608914995

Epoch: 6| Step: 8
Training loss: 1.091422083199845
Validation loss: 2.39665745760854

Epoch: 6| Step: 9
Training loss: 0.6580644682228811
Validation loss: 2.376035421425769

Epoch: 6| Step: 10
Training loss: 0.7103930893581214
Validation loss: 2.3539856356413935

Epoch: 6| Step: 11
Training loss: 1.3804788240454833
Validation loss: 2.3565459879360517

Epoch: 6| Step: 12
Training loss: 1.0434933032674087
Validation loss: 2.32410001105903

Epoch: 6| Step: 13
Training loss: 0.7205841048879041
Validation loss: 2.300809289877096

Epoch: 282| Step: 0
Training loss: 1.1119655396864578
Validation loss: 2.288080852421786

Epoch: 6| Step: 1
Training loss: 1.2090867204130762
Validation loss: 2.306087495129861

Epoch: 6| Step: 2
Training loss: 1.1880371986788296
Validation loss: 2.2849146252881862

Epoch: 6| Step: 3
Training loss: 0.9314819456716833
Validation loss: 2.3149006955772258

Epoch: 6| Step: 4
Training loss: 1.50926265258945
Validation loss: 2.3411960351181595

Epoch: 6| Step: 5
Training loss: 1.4138557325063272
Validation loss: 2.3530904961972996

Epoch: 6| Step: 6
Training loss: 1.2336306681795093
Validation loss: 2.3549007865041145

Epoch: 6| Step: 7
Training loss: 0.7913367855695169
Validation loss: 2.3368321125985987

Epoch: 6| Step: 8
Training loss: 1.0841636165856499
Validation loss: 2.3482152530518694

Epoch: 6| Step: 9
Training loss: 1.6447205060850298
Validation loss: 2.3298514121188476

Epoch: 6| Step: 10
Training loss: 1.3126724674806407
Validation loss: 2.3360676364451964

Epoch: 6| Step: 11
Training loss: 1.188100963913278
Validation loss: 2.347963747983088

Epoch: 6| Step: 12
Training loss: 1.0231848251944409
Validation loss: 2.3069944242795

Epoch: 6| Step: 13
Training loss: 1.2914531387706265
Validation loss: 2.3627419019261877

Epoch: 283| Step: 0
Training loss: 0.9783093811874475
Validation loss: 2.3601324958030996

Epoch: 6| Step: 1
Training loss: 1.3103827702070745
Validation loss: 2.4113543414106076

Epoch: 6| Step: 2
Training loss: 1.022298572258604
Validation loss: 2.409037202745017

Epoch: 6| Step: 3
Training loss: 0.95441936717052
Validation loss: 2.4122015272650947

Epoch: 6| Step: 4
Training loss: 0.6259810377606699
Validation loss: 2.395719250659822

Epoch: 6| Step: 5
Training loss: 0.9107352449372154
Validation loss: 2.378775066651277

Epoch: 6| Step: 6
Training loss: 1.5757770256473806
Validation loss: 2.371143601719201

Epoch: 6| Step: 7
Training loss: 0.8911629775312021
Validation loss: 2.3464939028066016

Epoch: 6| Step: 8
Training loss: 1.65620249554147
Validation loss: 2.3362346749187233

Epoch: 6| Step: 9
Training loss: 1.047454275166586
Validation loss: 2.30801942861151

Epoch: 6| Step: 10
Training loss: 1.4751362042660585
Validation loss: 2.31405087332147

Epoch: 6| Step: 11
Training loss: 1.137702332831076
Validation loss: 2.31228533266437

Epoch: 6| Step: 12
Training loss: 1.2729879884774968
Validation loss: 2.327145315497846

Epoch: 6| Step: 13
Training loss: 1.6362910110078457
Validation loss: 2.341959985524182

Epoch: 284| Step: 0
Training loss: 0.5742371744327058
Validation loss: 2.3145173050373398

Epoch: 6| Step: 1
Training loss: 0.9816263971234999
Validation loss: 2.3163929132891306

Epoch: 6| Step: 2
Training loss: 1.2891727747132378
Validation loss: 2.311413420711695

Epoch: 6| Step: 3
Training loss: 0.9216820789782262
Validation loss: 2.310970273809865

Epoch: 6| Step: 4
Training loss: 1.2696455683956127
Validation loss: 2.2990744136788024

Epoch: 6| Step: 5
Training loss: 1.1493402682642435
Validation loss: 2.328397492789893

Epoch: 6| Step: 6
Training loss: 1.4324530863111788
Validation loss: 2.314553418644623

Epoch: 6| Step: 7
Training loss: 1.3664286223947035
Validation loss: 2.296726794885521

Epoch: 6| Step: 8
Training loss: 1.5174060856574563
Validation loss: 2.3124744798559704

Epoch: 6| Step: 9
Training loss: 0.9320261415531826
Validation loss: 2.28520406457916

Epoch: 6| Step: 10
Training loss: 0.9111653247523562
Validation loss: 2.2825130630146493

Epoch: 6| Step: 11
Training loss: 1.5986700968277385
Validation loss: 2.29768026194981

Epoch: 6| Step: 12
Training loss: 1.1740553853294335
Validation loss: 2.319717451909136

Epoch: 6| Step: 13
Training loss: 0.8536575164522994
Validation loss: 2.341753810025539

Epoch: 285| Step: 0
Training loss: 0.905319920470929
Validation loss: 2.369056322170145

Epoch: 6| Step: 1
Training loss: 1.0784586514543468
Validation loss: 2.3843734096310576

Epoch: 6| Step: 2
Training loss: 1.2190153860039634
Validation loss: 2.4089648536232997

Epoch: 6| Step: 3
Training loss: 1.502823080405187
Validation loss: 2.3965884145470193

Epoch: 6| Step: 4
Training loss: 1.254339220632469
Validation loss: 2.3675873256740854

Epoch: 6| Step: 5
Training loss: 1.0825744257091066
Validation loss: 2.3533856723278643

Epoch: 6| Step: 6
Training loss: 1.015300288010993
Validation loss: 2.3805355679021476

Epoch: 6| Step: 7
Training loss: 1.0361674426131473
Validation loss: 2.372143190324268

Epoch: 6| Step: 8
Training loss: 1.359294494349692
Validation loss: 2.3717738515508566

Epoch: 6| Step: 9
Training loss: 0.972758215036951
Validation loss: 2.381311331549565

Epoch: 6| Step: 10
Training loss: 1.241078391452558
Validation loss: 2.3997035528811694

Epoch: 6| Step: 11
Training loss: 1.6570818269700547
Validation loss: 2.3615066622455583

Epoch: 6| Step: 12
Training loss: 0.5604088377376187
Validation loss: 2.3747536585995848

Epoch: 6| Step: 13
Training loss: 1.0410452833119834
Validation loss: 2.335818232894685

Epoch: 286| Step: 0
Training loss: 1.142109466684245
Validation loss: 2.3295675497987864

Epoch: 6| Step: 1
Training loss: 1.0410029140362003
Validation loss: 2.3267827128334715

Epoch: 6| Step: 2
Training loss: 1.0379567393363582
Validation loss: 2.321291856640122

Epoch: 6| Step: 3
Training loss: 1.4886484569188063
Validation loss: 2.3138135878043857

Epoch: 6| Step: 4
Training loss: 0.8199081514254107
Validation loss: 2.317898889837752

Epoch: 6| Step: 5
Training loss: 0.9473276648901042
Validation loss: 2.344501338289723

Epoch: 6| Step: 6
Training loss: 1.1286458701835078
Validation loss: 2.337332638933752

Epoch: 6| Step: 7
Training loss: 0.9647015300752438
Validation loss: 2.3685565440149725

Epoch: 6| Step: 8
Training loss: 1.447710100254209
Validation loss: 2.381398588916862

Epoch: 6| Step: 9
Training loss: 1.6804977946518078
Validation loss: 2.376962212766382

Epoch: 6| Step: 10
Training loss: 0.8289615076973698
Validation loss: 2.38689074762482

Epoch: 6| Step: 11
Training loss: 1.1182624607018758
Validation loss: 2.3576830005938554

Epoch: 6| Step: 12
Training loss: 1.146734363134109
Validation loss: 2.3466277778608657

Epoch: 6| Step: 13
Training loss: 1.003843431696755
Validation loss: 2.343980915903953

Epoch: 287| Step: 0
Training loss: 1.5367527394106644
Validation loss: 2.3416295348129617

Epoch: 6| Step: 1
Training loss: 1.6568932633632707
Validation loss: 2.336660393655914

Epoch: 6| Step: 2
Training loss: 0.6856479624586446
Validation loss: 2.341741612262379

Epoch: 6| Step: 3
Training loss: 0.8577422149714069
Validation loss: 2.3915992642709596

Epoch: 6| Step: 4
Training loss: 1.0682335034968544
Validation loss: 2.3904932972265005

Epoch: 6| Step: 5
Training loss: 0.9865642000702693
Validation loss: 2.4066802099582723

Epoch: 6| Step: 6
Training loss: 1.2916334927308395
Validation loss: 2.3510313651495536

Epoch: 6| Step: 7
Training loss: 1.1465983293559414
Validation loss: 2.3776922796033246

Epoch: 6| Step: 8
Training loss: 1.102393411859999
Validation loss: 2.343440044512464

Epoch: 6| Step: 9
Training loss: 1.196282884231495
Validation loss: 2.31670651677861

Epoch: 6| Step: 10
Training loss: 0.7880365103309189
Validation loss: 2.3067762295024177

Epoch: 6| Step: 11
Training loss: 1.114692837098405
Validation loss: 2.302248311361697

Epoch: 6| Step: 12
Training loss: 1.2624122438052183
Validation loss: 2.3178890318678147

Epoch: 6| Step: 13
Training loss: 1.032968880360967
Validation loss: 2.3249494907248476

Epoch: 288| Step: 0
Training loss: 1.128734958417502
Validation loss: 2.3207713055018617

Epoch: 6| Step: 1
Training loss: 0.5839705704808495
Validation loss: 2.351001451674053

Epoch: 6| Step: 2
Training loss: 0.9983210177821527
Validation loss: 2.3795355324796614

Epoch: 6| Step: 3
Training loss: 1.1952302193839024
Validation loss: 2.3683747041909875

Epoch: 6| Step: 4
Training loss: 1.1231922354126853
Validation loss: 2.3718760377885237

Epoch: 6| Step: 5
Training loss: 1.1261949550712802
Validation loss: 2.3765952533621464

Epoch: 6| Step: 6
Training loss: 0.9776488708344422
Validation loss: 2.3577666613635704

Epoch: 6| Step: 7
Training loss: 0.9330734654661937
Validation loss: 2.3652298595332897

Epoch: 6| Step: 8
Training loss: 1.0996933899895436
Validation loss: 2.3309568932661766

Epoch: 6| Step: 9
Training loss: 1.6597409435725559
Validation loss: 2.3395575300160956

Epoch: 6| Step: 10
Training loss: 1.1163482715028288
Validation loss: 2.3140510483630865

Epoch: 6| Step: 11
Training loss: 1.3882773223804221
Validation loss: 2.3183917448427556

Epoch: 6| Step: 12
Training loss: 1.2450314002309482
Validation loss: 2.29578413097581

Epoch: 6| Step: 13
Training loss: 0.9022210107862026
Validation loss: 2.311857847736898

Epoch: 289| Step: 0
Training loss: 1.041366260444729
Validation loss: 2.341004301400416

Epoch: 6| Step: 1
Training loss: 1.2130163744916436
Validation loss: 2.388689118835726

Epoch: 6| Step: 2
Training loss: 1.6601649385112716
Validation loss: 2.396741702532055

Epoch: 6| Step: 3
Training loss: 1.4134160455681717
Validation loss: 2.381045818158154

Epoch: 6| Step: 4
Training loss: 0.6368184391919993
Validation loss: 2.3760422620048636

Epoch: 6| Step: 5
Training loss: 0.8568901898730142
Validation loss: 2.379319205028579

Epoch: 6| Step: 6
Training loss: 0.940487361735839
Validation loss: 2.348381526270882

Epoch: 6| Step: 7
Training loss: 1.0036683153142938
Validation loss: 2.3703063921502565

Epoch: 6| Step: 8
Training loss: 1.165653396137837
Validation loss: 2.371192630708223

Epoch: 6| Step: 9
Training loss: 0.9341036629053993
Validation loss: 2.331085203916071

Epoch: 6| Step: 10
Training loss: 1.299402829707527
Validation loss: 2.3412989980432197

Epoch: 6| Step: 11
Training loss: 1.1189038091024839
Validation loss: 2.3474461070340005

Epoch: 6| Step: 12
Training loss: 1.1393391402769755
Validation loss: 2.3210247713380716

Epoch: 6| Step: 13
Training loss: 0.6976247124629478
Validation loss: 2.3312431899268216

Epoch: 290| Step: 0
Training loss: 0.8501027395763618
Validation loss: 2.323954111380394

Epoch: 6| Step: 1
Training loss: 1.3205887093637485
Validation loss: 2.37067315169847

Epoch: 6| Step: 2
Training loss: 1.0549866993684904
Validation loss: 2.396654487123779

Epoch: 6| Step: 3
Training loss: 1.6643099891838196
Validation loss: 2.33996212882542

Epoch: 6| Step: 4
Training loss: 0.9501364082983477
Validation loss: 2.333809638814056

Epoch: 6| Step: 5
Training loss: 0.8906844939053394
Validation loss: 2.3387317468311224

Epoch: 6| Step: 6
Training loss: 0.8905136975793674
Validation loss: 2.2680339110150385

Epoch: 6| Step: 7
Training loss: 1.3079913674457573
Validation loss: 2.28745264992475

Epoch: 6| Step: 8
Training loss: 1.0396909032501667
Validation loss: 2.275294370559315

Epoch: 6| Step: 9
Training loss: 1.2282691308008284
Validation loss: 2.298453544119623

Epoch: 6| Step: 10
Training loss: 1.066147769441075
Validation loss: 2.2812526746131008

Epoch: 6| Step: 11
Training loss: 1.2401005710302415
Validation loss: 2.3337428014577997

Epoch: 6| Step: 12
Training loss: 1.0295412182553305
Validation loss: 2.317336816843207

Epoch: 6| Step: 13
Training loss: 0.357280244542748
Validation loss: 2.350719638401315

Epoch: 291| Step: 0
Training loss: 0.9235789505339623
Validation loss: 2.3783920634660825

Epoch: 6| Step: 1
Training loss: 0.8480923141894082
Validation loss: 2.380726564498323

Epoch: 6| Step: 2
Training loss: 1.6360471526581455
Validation loss: 2.3593560674209675

Epoch: 6| Step: 3
Training loss: 0.9665461359572068
Validation loss: 2.3671858451905434

Epoch: 6| Step: 4
Training loss: 1.4048825715159063
Validation loss: 2.3437327317999754

Epoch: 6| Step: 5
Training loss: 0.8906217206928045
Validation loss: 2.356184538271946

Epoch: 6| Step: 6
Training loss: 1.12622480476471
Validation loss: 2.354213665307861

Epoch: 6| Step: 7
Training loss: 0.7154259317368743
Validation loss: 2.3505605609206883

Epoch: 6| Step: 8
Training loss: 1.099463553101693
Validation loss: 2.3431228619015636

Epoch: 6| Step: 9
Training loss: 0.8263768151591799
Validation loss: 2.362230138714711

Epoch: 6| Step: 10
Training loss: 1.2261766932484877
Validation loss: 2.355757949139357

Epoch: 6| Step: 11
Training loss: 1.3568040498363811
Validation loss: 2.3361537546669284

Epoch: 6| Step: 12
Training loss: 0.8052624620517287
Validation loss: 2.3562995877790964

Epoch: 6| Step: 13
Training loss: 1.3143162195518672
Validation loss: 2.3540595122167822

Epoch: 292| Step: 0
Training loss: 1.0047515991076719
Validation loss: 2.3378320881743675

Epoch: 6| Step: 1
Training loss: 0.8992481720698732
Validation loss: 2.3516140325299832

Epoch: 6| Step: 2
Training loss: 1.295109477773105
Validation loss: 2.348795410105673

Epoch: 6| Step: 3
Training loss: 0.9954871032009733
Validation loss: 2.326817117271071

Epoch: 6| Step: 4
Training loss: 1.081436213957487
Validation loss: 2.3486768646983336

Epoch: 6| Step: 5
Training loss: 1.0219777303497721
Validation loss: 2.3543738124212896

Epoch: 6| Step: 6
Training loss: 1.0528556456631928
Validation loss: 2.3689745323941813

Epoch: 6| Step: 7
Training loss: 0.5138664892257881
Validation loss: 2.36606900732148

Epoch: 6| Step: 8
Training loss: 0.924564511653517
Validation loss: 2.3458521821562663

Epoch: 6| Step: 9
Training loss: 1.2691829262232748
Validation loss: 2.3669065627358172

Epoch: 6| Step: 10
Training loss: 0.7495579608979234
Validation loss: 2.3330995003776778

Epoch: 6| Step: 11
Training loss: 1.7149056182336866
Validation loss: 2.36754531346425

Epoch: 6| Step: 12
Training loss: 1.1843081291867366
Validation loss: 2.368282631604893

Epoch: 6| Step: 13
Training loss: 1.123524227694296
Validation loss: 2.3768647132192693

Epoch: 293| Step: 0
Training loss: 1.3696802139871744
Validation loss: 2.3440460696244454

Epoch: 6| Step: 1
Training loss: 0.906288475009137
Validation loss: 2.314134327341791

Epoch: 6| Step: 2
Training loss: 0.6103344968317311
Validation loss: 2.33638536648008

Epoch: 6| Step: 3
Training loss: 1.206656586111405
Validation loss: 2.312708729683476

Epoch: 6| Step: 4
Training loss: 1.1277235759327724
Validation loss: 2.3430672299834394

Epoch: 6| Step: 5
Training loss: 1.1663534674994847
Validation loss: 2.3569729649589655

Epoch: 6| Step: 6
Training loss: 1.020862514052831
Validation loss: 2.3813392112358622

Epoch: 6| Step: 7
Training loss: 1.0825206324701209
Validation loss: 2.4457559391539245

Epoch: 6| Step: 8
Training loss: 1.5576399942001946
Validation loss: 2.4556534100533125

Epoch: 6| Step: 9
Training loss: 0.9155858054251099
Validation loss: 2.4427682514285975

Epoch: 6| Step: 10
Training loss: 1.0508867515722744
Validation loss: 2.432031045754668

Epoch: 6| Step: 11
Training loss: 1.1810116441622625
Validation loss: 2.3884649564342246

Epoch: 6| Step: 12
Training loss: 0.972768110714027
Validation loss: 2.3733589502255006

Epoch: 6| Step: 13
Training loss: 1.0656251387162552
Validation loss: 2.3776054215642146

Epoch: 294| Step: 0
Training loss: 0.8346690956180419
Validation loss: 2.3440585791240345

Epoch: 6| Step: 1
Training loss: 0.7525248942265392
Validation loss: 2.3585016570647928

Epoch: 6| Step: 2
Training loss: 1.3060779586003473
Validation loss: 2.370354369891883

Epoch: 6| Step: 3
Training loss: 0.8925195587109448
Validation loss: 2.346081453114341

Epoch: 6| Step: 4
Training loss: 0.4917745523030001
Validation loss: 2.3877653245433463

Epoch: 6| Step: 5
Training loss: 0.7827817396870326
Validation loss: 2.4075847003634947

Epoch: 6| Step: 6
Training loss: 1.0956057472952896
Validation loss: 2.4182186984543916

Epoch: 6| Step: 7
Training loss: 1.0524031590469776
Validation loss: 2.420730172572968

Epoch: 6| Step: 8
Training loss: 0.8033956509540572
Validation loss: 2.406473277013791

Epoch: 6| Step: 9
Training loss: 1.288595172672682
Validation loss: 2.3857902330711043

Epoch: 6| Step: 10
Training loss: 1.6592186288378246
Validation loss: 2.3765165056534787

Epoch: 6| Step: 11
Training loss: 1.346711643163507
Validation loss: 2.3479868461041424

Epoch: 6| Step: 12
Training loss: 0.9583983330175585
Validation loss: 2.3585204801966726

Epoch: 6| Step: 13
Training loss: 1.4022118126478955
Validation loss: 2.3034042843352256

Epoch: 295| Step: 0
Training loss: 0.5906851874065971
Validation loss: 2.312630974215369

Epoch: 6| Step: 1
Training loss: 0.9756285817522262
Validation loss: 2.317460182310631

Epoch: 6| Step: 2
Training loss: 1.2318293723564548
Validation loss: 2.328877431711825

Epoch: 6| Step: 3
Training loss: 1.185273844468022
Validation loss: 2.3124957906368206

Epoch: 6| Step: 4
Training loss: 1.2051260519775888
Validation loss: 2.323556281579249

Epoch: 6| Step: 5
Training loss: 1.5432037560847853
Validation loss: 2.356031005418927

Epoch: 6| Step: 6
Training loss: 0.9279057715852198
Validation loss: 2.351382978206528

Epoch: 6| Step: 7
Training loss: 0.8322709861990197
Validation loss: 2.371733562435277

Epoch: 6| Step: 8
Training loss: 0.9364822903723924
Validation loss: 2.349096173346969

Epoch: 6| Step: 9
Training loss: 0.8781648348532589
Validation loss: 2.3448561816445945

Epoch: 6| Step: 10
Training loss: 1.1762528598438486
Validation loss: 2.341274170673449

Epoch: 6| Step: 11
Training loss: 1.0478544066320326
Validation loss: 2.34324216092054

Epoch: 6| Step: 12
Training loss: 1.1793319469491916
Validation loss: 2.3775209584547063

Epoch: 6| Step: 13
Training loss: 0.9292524906830125
Validation loss: 2.397710509017033

Epoch: 296| Step: 0
Training loss: 0.8928765397008496
Validation loss: 2.3825982368491463

Epoch: 6| Step: 1
Training loss: 0.7965931113322363
Validation loss: 2.3959332060539995

Epoch: 6| Step: 2
Training loss: 0.9279477165267658
Validation loss: 2.353345061327023

Epoch: 6| Step: 3
Training loss: 0.9767951993265053
Validation loss: 2.3370706129298786

Epoch: 6| Step: 4
Training loss: 0.8615036004999146
Validation loss: 2.3396328582078834

Epoch: 6| Step: 5
Training loss: 0.9976995950123551
Validation loss: 2.322279351342548

Epoch: 6| Step: 6
Training loss: 1.1551989856246605
Validation loss: 2.326856646599248

Epoch: 6| Step: 7
Training loss: 1.1663073713086514
Validation loss: 2.3445551079408484

Epoch: 6| Step: 8
Training loss: 0.8273296495484201
Validation loss: 2.3568925321099536

Epoch: 6| Step: 9
Training loss: 1.0922915953445096
Validation loss: 2.3670634635182903

Epoch: 6| Step: 10
Training loss: 0.7617587739259507
Validation loss: 2.376736252932181

Epoch: 6| Step: 11
Training loss: 1.0185945965710286
Validation loss: 2.357622125272532

Epoch: 6| Step: 12
Training loss: 1.4561391763716665
Validation loss: 2.3822930732604273

Epoch: 6| Step: 13
Training loss: 1.9192226063963587
Validation loss: 2.38692109042594

Epoch: 297| Step: 0
Training loss: 1.4321090119388313
Validation loss: 2.374159672359681

Epoch: 6| Step: 1
Training loss: 1.6549588334878758
Validation loss: 2.3413057484931823

Epoch: 6| Step: 2
Training loss: 0.710487432861325
Validation loss: 2.3418193409881147

Epoch: 6| Step: 3
Training loss: 0.501942972162186
Validation loss: 2.3372735863241747

Epoch: 6| Step: 4
Training loss: 1.1245923893325862
Validation loss: 2.3461992210971774

Epoch: 6| Step: 5
Training loss: 1.1426179275752866
Validation loss: 2.325479931209783

Epoch: 6| Step: 6
Training loss: 0.8639195356694558
Validation loss: 2.2784922865832917

Epoch: 6| Step: 7
Training loss: 0.9464946952505926
Validation loss: 2.3163262263694127

Epoch: 6| Step: 8
Training loss: 1.11939826383117
Validation loss: 2.3316837906043926

Epoch: 6| Step: 9
Training loss: 0.9869822533122221
Validation loss: 2.350520335740915

Epoch: 6| Step: 10
Training loss: 0.9259397475659183
Validation loss: 2.3946320845200986

Epoch: 6| Step: 11
Training loss: 1.1225170710227745
Validation loss: 2.3990960114512863

Epoch: 6| Step: 12
Training loss: 0.7839299204436444
Validation loss: 2.421506862070369

Epoch: 6| Step: 13
Training loss: 0.5707780166145927
Validation loss: 2.3854829066386083

Epoch: 298| Step: 0
Training loss: 1.0334803420265655
Validation loss: 2.3855550431831705

Epoch: 6| Step: 1
Training loss: 0.9537387810243482
Validation loss: 2.398330411918282

Epoch: 6| Step: 2
Training loss: 0.7651149841610292
Validation loss: 2.4395165748429677

Epoch: 6| Step: 3
Training loss: 1.0122343539034278
Validation loss: 2.4469330105801395

Epoch: 6| Step: 4
Training loss: 0.7377962002535121
Validation loss: 2.41443860248102

Epoch: 6| Step: 5
Training loss: 1.115183439945509
Validation loss: 2.422767317055457

Epoch: 6| Step: 6
Training loss: 0.6486861889571678
Validation loss: 2.396998263399874

Epoch: 6| Step: 7
Training loss: 1.361837983943543
Validation loss: 2.332379696333051

Epoch: 6| Step: 8
Training loss: 1.6507883529401954
Validation loss: 2.3560427625086633

Epoch: 6| Step: 9
Training loss: 0.7834102138032655
Validation loss: 2.3652383506846286

Epoch: 6| Step: 10
Training loss: 0.8424180431857233
Validation loss: 2.3702915606018378

Epoch: 6| Step: 11
Training loss: 1.107076601164227
Validation loss: 2.3480284046802105

Epoch: 6| Step: 12
Training loss: 0.8306059471913155
Validation loss: 2.323293245849838

Epoch: 6| Step: 13
Training loss: 1.2641860882636216
Validation loss: 2.359932586731855

Epoch: 299| Step: 0
Training loss: 1.5627964501490232
Validation loss: 2.362104193858194

Epoch: 6| Step: 1
Training loss: 0.9919806437488217
Validation loss: 2.3410094691853702

Epoch: 6| Step: 2
Training loss: 0.9261663738394657
Validation loss: 2.3642093195869025

Epoch: 6| Step: 3
Training loss: 1.2264038274874498
Validation loss: 2.339594248224064

Epoch: 6| Step: 4
Training loss: 0.9908867066116391
Validation loss: 2.332877566906028

Epoch: 6| Step: 5
Training loss: 0.7528902629816987
Validation loss: 2.328492010082545

Epoch: 6| Step: 6
Training loss: 0.9854247233334991
Validation loss: 2.3161402505352213

Epoch: 6| Step: 7
Training loss: 0.9816891799011837
Validation loss: 2.3390684738716936

Epoch: 6| Step: 8
Training loss: 1.0042044348888706
Validation loss: 2.3191187281124637

Epoch: 6| Step: 9
Training loss: 1.2631415974669922
Validation loss: 2.3326029465739992

Epoch: 6| Step: 10
Training loss: 0.9365477494155996
Validation loss: 2.335241360190043

Epoch: 6| Step: 11
Training loss: 0.41269880330333053
Validation loss: 2.369075293016728

Epoch: 6| Step: 12
Training loss: 1.107155850329824
Validation loss: 2.3930238991477664

Epoch: 6| Step: 13
Training loss: 0.8536477761346394
Validation loss: 2.3925245774023467

Epoch: 300| Step: 0
Training loss: 0.5757763038122599
Validation loss: 2.4034088945539347

Epoch: 6| Step: 1
Training loss: 0.5915465628144199
Validation loss: 2.3901184701426645

Epoch: 6| Step: 2
Training loss: 0.7225052134447855
Validation loss: 2.3833326428641364

Epoch: 6| Step: 3
Training loss: 1.7717081115817732
Validation loss: 2.3845767053958666

Epoch: 6| Step: 4
Training loss: 1.157381123067725
Validation loss: 2.3800856473676246

Epoch: 6| Step: 5
Training loss: 0.9888506067262084
Validation loss: 2.3502085169401914

Epoch: 6| Step: 6
Training loss: 0.7891433221196701
Validation loss: 2.358575869355521

Epoch: 6| Step: 7
Training loss: 0.7690315754364377
Validation loss: 2.345747455165982

Epoch: 6| Step: 8
Training loss: 1.185295518250112
Validation loss: 2.3509930792131026

Epoch: 6| Step: 9
Training loss: 1.0203282540523202
Validation loss: 2.377209346570576

Epoch: 6| Step: 10
Training loss: 0.7275125178672629
Validation loss: 2.381894000471463

Epoch: 6| Step: 11
Training loss: 0.83591735672969
Validation loss: 2.3807077446451115

Epoch: 6| Step: 12
Training loss: 1.4842093927458122
Validation loss: 2.3841632566916426

Epoch: 6| Step: 13
Training loss: 0.9032777848413976
Validation loss: 2.420802798590541

Epoch: 301| Step: 0
Training loss: 1.055051331107481
Validation loss: 2.430641014913282

Epoch: 6| Step: 1
Training loss: 0.6266934816815531
Validation loss: 2.4211431492452293

Epoch: 6| Step: 2
Training loss: 0.926114855185176
Validation loss: 2.414015853966933

Epoch: 6| Step: 3
Training loss: 1.6485769203852023
Validation loss: 2.406916668359897

Epoch: 6| Step: 4
Training loss: 0.6836970006078811
Validation loss: 2.4094530331748714

Epoch: 6| Step: 5
Training loss: 0.9415164740524568
Validation loss: 2.358973942161937

Epoch: 6| Step: 6
Training loss: 0.8642403638554663
Validation loss: 2.3897379361372466

Epoch: 6| Step: 7
Training loss: 1.0227698558072573
Validation loss: 2.3583891879768504

Epoch: 6| Step: 8
Training loss: 0.9964255285289846
Validation loss: 2.3782588090435333

Epoch: 6| Step: 9
Training loss: 1.1788912985165156
Validation loss: 2.3648487506058817

Epoch: 6| Step: 10
Training loss: 1.0955801774130367
Validation loss: 2.3635173948448656

Epoch: 6| Step: 11
Training loss: 0.9828784405006371
Validation loss: 2.361008180244237

Epoch: 6| Step: 12
Training loss: 0.9399181016287098
Validation loss: 2.347254138977183

Epoch: 6| Step: 13
Training loss: 0.707214542466917
Validation loss: 2.3613790959192484

Epoch: 302| Step: 0
Training loss: 0.8684317451827214
Validation loss: 2.375234241516467

Epoch: 6| Step: 1
Training loss: 0.7979102795961952
Validation loss: 2.3601865741019554

Epoch: 6| Step: 2
Training loss: 1.2665781270420096
Validation loss: 2.3853240281052988

Epoch: 6| Step: 3
Training loss: 1.0034396501041116
Validation loss: 2.353039970017048

Epoch: 6| Step: 4
Training loss: 0.8890009344201171
Validation loss: 2.3790722354361655

Epoch: 6| Step: 5
Training loss: 1.0391457889991556
Validation loss: 2.3869831544355997

Epoch: 6| Step: 6
Training loss: 0.8182087033483296
Validation loss: 2.3765193481285967

Epoch: 6| Step: 7
Training loss: 0.5319755872381061
Validation loss: 2.3880997216212143

Epoch: 6| Step: 8
Training loss: 1.0438794792407171
Validation loss: 2.3412752645549038

Epoch: 6| Step: 9
Training loss: 1.1472650888381344
Validation loss: 2.335602121685719

Epoch: 6| Step: 10
Training loss: 1.6391527381981388
Validation loss: 2.32408955615585

Epoch: 6| Step: 11
Training loss: 0.7615257605580591
Validation loss: 2.341092585837655

Epoch: 6| Step: 12
Training loss: 0.872635575940095
Validation loss: 2.341116723061414

Epoch: 6| Step: 13
Training loss: 1.0156419019026295
Validation loss: 2.35023945522474

Epoch: 303| Step: 0
Training loss: 0.8559474911895267
Validation loss: 2.3635927316924756

Epoch: 6| Step: 1
Training loss: 0.9028278059832172
Validation loss: 2.3490906986804228

Epoch: 6| Step: 2
Training loss: 0.9550895456204634
Validation loss: 2.3783354715088363

Epoch: 6| Step: 3
Training loss: 1.0868206686662474
Validation loss: 2.383084021580555

Epoch: 6| Step: 4
Training loss: 0.8058656752354418
Validation loss: 2.375637764351344

Epoch: 6| Step: 5
Training loss: 1.1925250694150926
Validation loss: 2.37782683151628

Epoch: 6| Step: 6
Training loss: 0.7874630117055545
Validation loss: 2.374436196599061

Epoch: 6| Step: 7
Training loss: 0.5924068366819176
Validation loss: 2.382620380523347

Epoch: 6| Step: 8
Training loss: 0.9341542305290131
Validation loss: 2.399049459115043

Epoch: 6| Step: 9
Training loss: 0.6788982544528032
Validation loss: 2.3635808787472814

Epoch: 6| Step: 10
Training loss: 0.945454358262597
Validation loss: 2.3744233180940615

Epoch: 6| Step: 11
Training loss: 1.1427901112108252
Validation loss: 2.3608987043324876

Epoch: 6| Step: 12
Training loss: 0.799704520971225
Validation loss: 2.361267696507059

Epoch: 6| Step: 13
Training loss: 2.1121083951862785
Validation loss: 2.3366478577150662

Epoch: 304| Step: 0
Training loss: 0.9304021765068456
Validation loss: 2.3374980471795177

Epoch: 6| Step: 1
Training loss: 0.963364026302264
Validation loss: 2.358003883594569

Epoch: 6| Step: 2
Training loss: 0.9061237773468656
Validation loss: 2.384369877648319

Epoch: 6| Step: 3
Training loss: 0.6680171569773817
Validation loss: 2.3546764363802386

Epoch: 6| Step: 4
Training loss: 0.8701029389966934
Validation loss: 2.354051854147741

Epoch: 6| Step: 5
Training loss: 1.5839138556233172
Validation loss: 2.349817321438936

Epoch: 6| Step: 6
Training loss: 0.8941049017879872
Validation loss: 2.323662570289024

Epoch: 6| Step: 7
Training loss: 0.9136768407796797
Validation loss: 2.3590514443288755

Epoch: 6| Step: 8
Training loss: 0.8057270927049066
Validation loss: 2.3333882412917695

Epoch: 6| Step: 9
Training loss: 1.0332350266260273
Validation loss: 2.3206526265755563

Epoch: 6| Step: 10
Training loss: 1.0797462988381745
Validation loss: 2.335459815447428

Epoch: 6| Step: 11
Training loss: 0.951814125253526
Validation loss: 2.327664484127914

Epoch: 6| Step: 12
Training loss: 1.0819531354009653
Validation loss: 2.327640343979192

Epoch: 6| Step: 13
Training loss: 0.5366108193077762
Validation loss: 2.351188967141178

Epoch: 305| Step: 0
Training loss: 0.97300867030955
Validation loss: 2.354335947254818

Epoch: 6| Step: 1
Training loss: 0.5136845518223212
Validation loss: 2.360382171521589

Epoch: 6| Step: 2
Training loss: 0.8129066036767505
Validation loss: 2.3523674918700346

Epoch: 6| Step: 3
Training loss: 0.6919576741267474
Validation loss: 2.403555037566178

Epoch: 6| Step: 4
Training loss: 1.2350156063375632
Validation loss: 2.375514116755795

Epoch: 6| Step: 5
Training loss: 0.8623934016489291
Validation loss: 2.3811998536814576

Epoch: 6| Step: 6
Training loss: 0.7610418197279417
Validation loss: 2.3675955517461977

Epoch: 6| Step: 7
Training loss: 0.9557814865274153
Validation loss: 2.3608579136325663

Epoch: 6| Step: 8
Training loss: 0.8163661673165413
Validation loss: 2.3427061352793603

Epoch: 6| Step: 9
Training loss: 1.3606288870956136
Validation loss: 2.3335216663388096

Epoch: 6| Step: 10
Training loss: 1.5725908594612226
Validation loss: 2.372901485932979

Epoch: 6| Step: 11
Training loss: 0.9919791716284837
Validation loss: 2.366859385408267

Epoch: 6| Step: 12
Training loss: 0.6802327172629478
Validation loss: 2.3481491357978186

Epoch: 6| Step: 13
Training loss: 0.8182092497061045
Validation loss: 2.357508453930587

Epoch: 306| Step: 0
Training loss: 0.8014133098884099
Validation loss: 2.3544702888585394

Epoch: 6| Step: 1
Training loss: 0.40468350412170806
Validation loss: 2.3672108426536

Epoch: 6| Step: 2
Training loss: 0.5036363692185039
Validation loss: 2.375956059558048

Epoch: 6| Step: 3
Training loss: 0.976403520995093
Validation loss: 2.3785162458743567

Epoch: 6| Step: 4
Training loss: 0.9085774624415096
Validation loss: 2.402510673405594

Epoch: 6| Step: 5
Training loss: 0.9916146795018754
Validation loss: 2.4104625455221993

Epoch: 6| Step: 6
Training loss: 1.1835064242035112
Validation loss: 2.409761223445842

Epoch: 6| Step: 7
Training loss: 0.9998287113833428
Validation loss: 2.3960346652733215

Epoch: 6| Step: 8
Training loss: 0.912418451976455
Validation loss: 2.395001539281703

Epoch: 6| Step: 9
Training loss: 0.6380110655575377
Validation loss: 2.3654171141018185

Epoch: 6| Step: 10
Training loss: 0.9300623867172502
Validation loss: 2.392099980553029

Epoch: 6| Step: 11
Training loss: 1.1772055379621282
Validation loss: 2.3518113773956664

Epoch: 6| Step: 12
Training loss: 0.9658957240765841
Validation loss: 2.326511638620964

Epoch: 6| Step: 13
Training loss: 1.9311139475481287
Validation loss: 2.360830721612883

Epoch: 307| Step: 0
Training loss: 0.7557347315647572
Validation loss: 2.363454513957918

Epoch: 6| Step: 1
Training loss: 1.0718149374101584
Validation loss: 2.3899369332375624

Epoch: 6| Step: 2
Training loss: 0.7256647531822652
Validation loss: 2.4209413494566294

Epoch: 6| Step: 3
Training loss: 0.8520050298873647
Validation loss: 2.414846119274541

Epoch: 6| Step: 4
Training loss: 1.5646273055248945
Validation loss: 2.433934657702989

Epoch: 6| Step: 5
Training loss: 0.8137782385829609
Validation loss: 2.450494024599925

Epoch: 6| Step: 6
Training loss: 1.0837579714120031
Validation loss: 2.4388602168669347

Epoch: 6| Step: 7
Training loss: 0.676523671786996
Validation loss: 2.429361827559076

Epoch: 6| Step: 8
Training loss: 0.6976083933445084
Validation loss: 2.388664527523368

Epoch: 6| Step: 9
Training loss: 0.7945913616535643
Validation loss: 2.3564461284451585

Epoch: 6| Step: 10
Training loss: 1.1798223961509422
Validation loss: 2.386807809633643

Epoch: 6| Step: 11
Training loss: 0.8787536488615983
Validation loss: 2.3708000568172753

Epoch: 6| Step: 12
Training loss: 1.097025897305449
Validation loss: 2.3593213996755895

Epoch: 6| Step: 13
Training loss: 0.7784964291607666
Validation loss: 2.3733691578478684

Epoch: 308| Step: 0
Training loss: 0.7945838978296471
Validation loss: 2.347725594798135

Epoch: 6| Step: 1
Training loss: 0.5143700557948536
Validation loss: 2.3410082054390546

Epoch: 6| Step: 2
Training loss: 1.1625110092462145
Validation loss: 2.4072080382208636

Epoch: 6| Step: 3
Training loss: 1.507944763391248
Validation loss: 2.3828431228184255

Epoch: 6| Step: 4
Training loss: 0.8915048569778553
Validation loss: 2.3740888773607405

Epoch: 6| Step: 5
Training loss: 1.1368844347410791
Validation loss: 2.3921050229494902

Epoch: 6| Step: 6
Training loss: 0.7742300500439664
Validation loss: 2.375565496627567

Epoch: 6| Step: 7
Training loss: 0.9312257622758473
Validation loss: 2.3502623368199353

Epoch: 6| Step: 8
Training loss: 1.0350359576885195
Validation loss: 2.3709223088701186

Epoch: 6| Step: 9
Training loss: 0.7028036654855501
Validation loss: 2.3568867671835516

Epoch: 6| Step: 10
Training loss: 1.15577595246305
Validation loss: 2.3661195824899512

Epoch: 6| Step: 11
Training loss: 0.5404516096394123
Validation loss: 2.408577483610482

Epoch: 6| Step: 12
Training loss: 0.8695490873825867
Validation loss: 2.420264852519755

Epoch: 6| Step: 13
Training loss: 0.8671040881482339
Validation loss: 2.396365063813581

Epoch: 309| Step: 0
Training loss: 0.5179335615308238
Validation loss: 2.388886476601199

Epoch: 6| Step: 1
Training loss: 0.696042288645109
Validation loss: 2.388247061214181

Epoch: 6| Step: 2
Training loss: 1.3254743716547805
Validation loss: 2.3661034949405972

Epoch: 6| Step: 3
Training loss: 0.6903701173802047
Validation loss: 2.385153673241

Epoch: 6| Step: 4
Training loss: 0.8830886003966492
Validation loss: 2.37179094099394

Epoch: 6| Step: 5
Training loss: 0.5807324966768548
Validation loss: 2.3879954952819578

Epoch: 6| Step: 6
Training loss: 0.8782128205284662
Validation loss: 2.3976634079987473

Epoch: 6| Step: 7
Training loss: 1.2380471956011074
Validation loss: 2.434232324719582

Epoch: 6| Step: 8
Training loss: 0.6731769898720141
Validation loss: 2.4013550299200963

Epoch: 6| Step: 9
Training loss: 0.8262789320966069
Validation loss: 2.379134901275157

Epoch: 6| Step: 10
Training loss: 1.5847989209301898
Validation loss: 2.41305107063987

Epoch: 6| Step: 11
Training loss: 0.8313116624376371
Validation loss: 2.4094132432402575

Epoch: 6| Step: 12
Training loss: 1.084054425699664
Validation loss: 2.387792638217801

Epoch: 6| Step: 13
Training loss: 0.6537498350854377
Validation loss: 2.4210497881595585

Epoch: 310| Step: 0
Training loss: 1.708204970150537
Validation loss: 2.4016239406137827

Epoch: 6| Step: 1
Training loss: 0.599784899937667
Validation loss: 2.4200316443662993

Epoch: 6| Step: 2
Training loss: 0.920028324002173
Validation loss: 2.4319696069344583

Epoch: 6| Step: 3
Training loss: 1.0607597460599096
Validation loss: 2.406576031450295

Epoch: 6| Step: 4
Training loss: 0.7696042486122099
Validation loss: 2.3729180891892394

Epoch: 6| Step: 5
Training loss: 0.6853136062439192
Validation loss: 2.389834002960433

Epoch: 6| Step: 6
Training loss: 0.7583298244674604
Validation loss: 2.377604362188482

Epoch: 6| Step: 7
Training loss: 0.9012159425223555
Validation loss: 2.3620502359794213

Epoch: 6| Step: 8
Training loss: 1.2907528054271342
Validation loss: 2.3423134063241777

Epoch: 6| Step: 9
Training loss: 0.7332739184614775
Validation loss: 2.379428437318585

Epoch: 6| Step: 10
Training loss: 0.7642911853518067
Validation loss: 2.3516242794868907

Epoch: 6| Step: 11
Training loss: 0.8216995864319315
Validation loss: 2.3380927876412225

Epoch: 6| Step: 12
Training loss: 0.4617792945061964
Validation loss: 2.376860463607132

Epoch: 6| Step: 13
Training loss: 0.9646410400947321
Validation loss: 2.3550609826862945

Epoch: 311| Step: 0
Training loss: 0.5534476271423815
Validation loss: 2.355304011681403

Epoch: 6| Step: 1
Training loss: 0.8839966250998169
Validation loss: 2.38074168316032

Epoch: 6| Step: 2
Training loss: 0.9945206730737891
Validation loss: 2.371985583662204

Epoch: 6| Step: 3
Training loss: 0.7915889216613075
Validation loss: 2.364901448398928

Epoch: 6| Step: 4
Training loss: 1.001401038999268
Validation loss: 2.326455382481116

Epoch: 6| Step: 5
Training loss: 0.815276902555927
Validation loss: 2.3307511138478487

Epoch: 6| Step: 6
Training loss: 0.5705392987509449
Validation loss: 2.3281822778406402

Epoch: 6| Step: 7
Training loss: 0.7207326908818414
Validation loss: 2.373046980870971

Epoch: 6| Step: 8
Training loss: 0.9343804911066179
Validation loss: 2.343355295724291

Epoch: 6| Step: 9
Training loss: 0.8163173207303577
Validation loss: 2.379235701937471

Epoch: 6| Step: 10
Training loss: 1.6857494175092609
Validation loss: 2.407203089230128

Epoch: 6| Step: 11
Training loss: 0.8442174534961574
Validation loss: 2.399139335814684

Epoch: 6| Step: 12
Training loss: 0.9641406628842304
Validation loss: 2.453308182233442

Epoch: 6| Step: 13
Training loss: 0.9836814495860149
Validation loss: 2.4111857618444614

Epoch: 312| Step: 0
Training loss: 0.7625422012657678
Validation loss: 2.449133480797783

Epoch: 6| Step: 1
Training loss: 0.7047557992253403
Validation loss: 2.3958310534309

Epoch: 6| Step: 2
Training loss: 0.6051134112752902
Validation loss: 2.407891462472826

Epoch: 6| Step: 3
Training loss: 0.8626668132956772
Validation loss: 2.373972846593383

Epoch: 6| Step: 4
Training loss: 0.7104140649861626
Validation loss: 2.375008855607816

Epoch: 6| Step: 5
Training loss: 1.7258734385301764
Validation loss: 2.3899121375445467

Epoch: 6| Step: 6
Training loss: 0.9265350620781012
Validation loss: 2.3731335169264627

Epoch: 6| Step: 7
Training loss: 0.7236853205978057
Validation loss: 2.359555729267451

Epoch: 6| Step: 8
Training loss: 1.0510750398860376
Validation loss: 2.4119645384319335

Epoch: 6| Step: 9
Training loss: 0.878688700560573
Validation loss: 2.3904129385734154

Epoch: 6| Step: 10
Training loss: 1.027944642917997
Validation loss: 2.3792941516075135

Epoch: 6| Step: 11
Training loss: 0.7875883098314967
Validation loss: 2.4205249634521766

Epoch: 6| Step: 12
Training loss: 1.0383399803250937
Validation loss: 2.401635817158941

Epoch: 6| Step: 13
Training loss: 0.6692829032037183
Validation loss: 2.4331013115719005

Epoch: 313| Step: 0
Training loss: 1.095003118641214
Validation loss: 2.410094919423411

Epoch: 6| Step: 1
Training loss: 0.7646465277130325
Validation loss: 2.393753065828429

Epoch: 6| Step: 2
Training loss: 0.5270107489454205
Validation loss: 2.406883315149072

Epoch: 6| Step: 3
Training loss: 0.5151994278330024
Validation loss: 2.3585635988092166

Epoch: 6| Step: 4
Training loss: 0.7877978397444358
Validation loss: 2.3801445813227624

Epoch: 6| Step: 5
Training loss: 0.5836703116204901
Validation loss: 2.3705668598111953

Epoch: 6| Step: 6
Training loss: 1.0516394758462633
Validation loss: 2.348363747384033

Epoch: 6| Step: 7
Training loss: 1.6456709512046057
Validation loss: 2.3979867004680107

Epoch: 6| Step: 8
Training loss: 0.9089551539820493
Validation loss: 2.3385060274737555

Epoch: 6| Step: 9
Training loss: 0.4894662591948398
Validation loss: 2.3888135096695833

Epoch: 6| Step: 10
Training loss: 0.9711329162997775
Validation loss: 2.397301318763434

Epoch: 6| Step: 11
Training loss: 1.1023326373063957
Validation loss: 2.4235775121517436

Epoch: 6| Step: 12
Training loss: 1.0346722316969166
Validation loss: 2.4562148123098897

Epoch: 6| Step: 13
Training loss: 0.6273652620534569
Validation loss: 2.4758787211742503

Epoch: 314| Step: 0
Training loss: 0.8657840679007872
Validation loss: 2.490707445050661

Epoch: 6| Step: 1
Training loss: 0.6616357780600616
Validation loss: 2.4768306894537377

Epoch: 6| Step: 2
Training loss: 0.6540070532395098
Validation loss: 2.426757545229359

Epoch: 6| Step: 3
Training loss: 0.7707225659833589
Validation loss: 2.4209547270556677

Epoch: 6| Step: 4
Training loss: 0.9368929487039797
Validation loss: 2.4181556365038475

Epoch: 6| Step: 5
Training loss: 1.063212828778641
Validation loss: 2.3987563939582093

Epoch: 6| Step: 6
Training loss: 0.4528598996476477
Validation loss: 2.4095552158109124

Epoch: 6| Step: 7
Training loss: 0.5092415289569903
Validation loss: 2.390898158433649

Epoch: 6| Step: 8
Training loss: 0.765889725364404
Validation loss: 2.389522070725714

Epoch: 6| Step: 9
Training loss: 0.8187722414213513
Validation loss: 2.402549847795351

Epoch: 6| Step: 10
Training loss: 1.076400594066568
Validation loss: 2.39169033740993

Epoch: 6| Step: 11
Training loss: 0.8035338567094272
Validation loss: 2.3814993820365826

Epoch: 6| Step: 12
Training loss: 1.7660336991979741
Validation loss: 2.3853707118125387

Epoch: 6| Step: 13
Training loss: 1.0562057305262706
Validation loss: 2.391022486881692

Epoch: 315| Step: 0
Training loss: 0.7754059989423611
Validation loss: 2.396605144661939

Epoch: 6| Step: 1
Training loss: 0.9270735143648721
Validation loss: 2.4243779771579677

Epoch: 6| Step: 2
Training loss: 0.5873453393231175
Validation loss: 2.408866653919973

Epoch: 6| Step: 3
Training loss: 1.0614146691882285
Validation loss: 2.418887076945603

Epoch: 6| Step: 4
Training loss: 0.9565104410386318
Validation loss: 2.3836861711156843

Epoch: 6| Step: 5
Training loss: 0.7817388530969762
Validation loss: 2.3700820324862852

Epoch: 6| Step: 6
Training loss: 0.7130611685988617
Validation loss: 2.3797309152375385

Epoch: 6| Step: 7
Training loss: 0.4830835723387214
Validation loss: 2.3684610326551447

Epoch: 6| Step: 8
Training loss: 1.6327831502950572
Validation loss: 2.409066428045329

Epoch: 6| Step: 9
Training loss: 0.9001306915760146
Validation loss: 2.4177379298856096

Epoch: 6| Step: 10
Training loss: 0.669733627161927
Validation loss: 2.434487728873635

Epoch: 6| Step: 11
Training loss: 0.9838103233949713
Validation loss: 2.4345624032866198

Epoch: 6| Step: 12
Training loss: 1.035826498445368
Validation loss: 2.416054685995805

Epoch: 6| Step: 13
Training loss: 0.7816494874008568
Validation loss: 2.3934990956282842

Epoch: 316| Step: 0
Training loss: 0.8672070200329806
Validation loss: 2.349476284159425

Epoch: 6| Step: 1
Training loss: 0.6839616929699034
Validation loss: 2.353156997002715

Epoch: 6| Step: 2
Training loss: 0.9561634411000789
Validation loss: 2.339555163129835

Epoch: 6| Step: 3
Training loss: 0.8293283464638563
Validation loss: 2.3848709723209174

Epoch: 6| Step: 4
Training loss: 0.7233751999330879
Validation loss: 2.368028801320917

Epoch: 6| Step: 5
Training loss: 1.2201509981827634
Validation loss: 2.4400897345036925

Epoch: 6| Step: 6
Training loss: 0.5658927957960972
Validation loss: 2.4803678112697467

Epoch: 6| Step: 7
Training loss: 0.8900731702794062
Validation loss: 2.545310848633418

Epoch: 6| Step: 8
Training loss: 0.9878600659212412
Validation loss: 2.4964279692331384

Epoch: 6| Step: 9
Training loss: 1.638830165924505
Validation loss: 2.489158623663899

Epoch: 6| Step: 10
Training loss: 0.7513203918941239
Validation loss: 2.463559700061887

Epoch: 6| Step: 11
Training loss: 0.9252965760978494
Validation loss: 2.425667777523554

Epoch: 6| Step: 12
Training loss: 0.7205165218282916
Validation loss: 2.4133408744860527

Epoch: 6| Step: 13
Training loss: 0.9713385668499914
Validation loss: 2.3925854776021267

Epoch: 317| Step: 0
Training loss: 1.1069546475825034
Validation loss: 2.3972661324953557

Epoch: 6| Step: 1
Training loss: 0.7423220863786401
Validation loss: 2.3942317362133294

Epoch: 6| Step: 2
Training loss: 0.7147284242749925
Validation loss: 2.50868949216262

Epoch: 6| Step: 3
Training loss: 0.8052921800932668
Validation loss: 2.545212305163021

Epoch: 6| Step: 4
Training loss: 1.6986334132368577
Validation loss: 2.537240149052531

Epoch: 6| Step: 5
Training loss: 1.1265497659288919
Validation loss: 2.5365153667581133

Epoch: 6| Step: 6
Training loss: 1.0056676589329567
Validation loss: 2.483273103469067

Epoch: 6| Step: 7
Training loss: 0.6439282226145961
Validation loss: 2.443685988283451

Epoch: 6| Step: 8
Training loss: 1.0352221773854142
Validation loss: 2.4372227955238372

Epoch: 6| Step: 9
Training loss: 0.5347004641059844
Validation loss: 2.3995439166560697

Epoch: 6| Step: 10
Training loss: 0.8923013871653803
Validation loss: 2.393024729403222

Epoch: 6| Step: 11
Training loss: 0.909189521252874
Validation loss: 2.406679404652841

Epoch: 6| Step: 12
Training loss: 0.4567931932771038
Validation loss: 2.374886960727306

Epoch: 6| Step: 13
Training loss: 0.7980458129337991
Validation loss: 2.386017798640014

Epoch: 318| Step: 0
Training loss: 0.9456358742703244
Validation loss: 2.3804056224017285

Epoch: 6| Step: 1
Training loss: 0.6707165956116456
Validation loss: 2.3600741266508285

Epoch: 6| Step: 2
Training loss: 0.9449887627735798
Validation loss: 2.3554557982648365

Epoch: 6| Step: 3
Training loss: 0.8109064981932894
Validation loss: 2.395138691646082

Epoch: 6| Step: 4
Training loss: 0.5628655093835426
Validation loss: 2.403062155335878

Epoch: 6| Step: 5
Training loss: 1.0081332975118236
Validation loss: 2.409344007623833

Epoch: 6| Step: 6
Training loss: 0.48360965622485813
Validation loss: 2.429959210799105

Epoch: 6| Step: 7
Training loss: 1.5666194780155471
Validation loss: 2.4103136448502007

Epoch: 6| Step: 8
Training loss: 1.0673465146718764
Validation loss: 2.444652497265706

Epoch: 6| Step: 9
Training loss: 0.47338785345548773
Validation loss: 2.4404497412220585

Epoch: 6| Step: 10
Training loss: 0.6928476513800986
Validation loss: 2.403747746992525

Epoch: 6| Step: 11
Training loss: 1.134306192544376
Validation loss: 2.42317521161321

Epoch: 6| Step: 12
Training loss: 0.9265954023054882
Validation loss: 2.4044756303541797

Epoch: 6| Step: 13
Training loss: 0.4953399548307278
Validation loss: 2.407826304068261

Epoch: 319| Step: 0
Training loss: 1.12753804330864
Validation loss: 2.399290524704109

Epoch: 6| Step: 1
Training loss: 0.5459113759263066
Validation loss: 2.404912619836943

Epoch: 6| Step: 2
Training loss: 0.5694254940518686
Validation loss: 2.3850485243611748

Epoch: 6| Step: 3
Training loss: 0.8365677926227781
Validation loss: 2.411722713090518

Epoch: 6| Step: 4
Training loss: 1.5710713085694448
Validation loss: 2.4029322192505544

Epoch: 6| Step: 5
Training loss: 0.36072231748142536
Validation loss: 2.4386164062468874

Epoch: 6| Step: 6
Training loss: 0.8940405353406773
Validation loss: 2.466128206251237

Epoch: 6| Step: 7
Training loss: 1.0217245778653958
Validation loss: 2.459418031614403

Epoch: 6| Step: 8
Training loss: 0.6966762028236175
Validation loss: 2.4369122796069305

Epoch: 6| Step: 9
Training loss: 0.726113211245987
Validation loss: 2.4361491281813055

Epoch: 6| Step: 10
Training loss: 0.8495650005810325
Validation loss: 2.4198540953485352

Epoch: 6| Step: 11
Training loss: 0.9172030887871166
Validation loss: 2.3803956915817923

Epoch: 6| Step: 12
Training loss: 0.751042952163873
Validation loss: 2.3628670576525606

Epoch: 6| Step: 13
Training loss: 1.0493344127446707
Validation loss: 2.3691562883064066

Epoch: 320| Step: 0
Training loss: 0.516298085945094
Validation loss: 2.389432793873475

Epoch: 6| Step: 1
Training loss: 0.7955019472291373
Validation loss: 2.388828323343253

Epoch: 6| Step: 2
Training loss: 0.6910443625073142
Validation loss: 2.4172637768966254

Epoch: 6| Step: 3
Training loss: 0.5873159850860399
Validation loss: 2.4485783977030757

Epoch: 6| Step: 4
Training loss: 1.1399289973216014
Validation loss: 2.425382009833555

Epoch: 6| Step: 5
Training loss: 0.9438453828218869
Validation loss: 2.463958763894588

Epoch: 6| Step: 6
Training loss: 1.0161538727776471
Validation loss: 2.4570311738325645

Epoch: 6| Step: 7
Training loss: 0.8480926304531534
Validation loss: 2.4509829372004326

Epoch: 6| Step: 8
Training loss: 0.6704430957545375
Validation loss: 2.45222841756896

Epoch: 6| Step: 9
Training loss: 1.5612792014330015
Validation loss: 2.3971434326130536

Epoch: 6| Step: 10
Training loss: 0.8233734424437922
Validation loss: 2.428861487855389

Epoch: 6| Step: 11
Training loss: 0.6427108720289281
Validation loss: 2.398636087448832

Epoch: 6| Step: 12
Training loss: 0.7984251390907516
Validation loss: 2.4139907549612

Epoch: 6| Step: 13
Training loss: 0.8549333055037619
Validation loss: 2.388381891170535

Epoch: 321| Step: 0
Training loss: 0.679380150067445
Validation loss: 2.3664371310131003

Epoch: 6| Step: 1
Training loss: 0.630699609892921
Validation loss: 2.404980723581133

Epoch: 6| Step: 2
Training loss: 1.7497052216897073
Validation loss: 2.3939519855137896

Epoch: 6| Step: 3
Training loss: 0.7946986229373516
Validation loss: 2.3690243053432374

Epoch: 6| Step: 4
Training loss: 0.9168263570809857
Validation loss: 2.365264404910482

Epoch: 6| Step: 5
Training loss: 0.7695721455662525
Validation loss: 2.3729695922523457

Epoch: 6| Step: 6
Training loss: 0.6662867377424524
Validation loss: 2.351995407918979

Epoch: 6| Step: 7
Training loss: 0.5443192297729378
Validation loss: 2.366813581130718

Epoch: 6| Step: 8
Training loss: 0.9342139829369485
Validation loss: 2.3701782329570245

Epoch: 6| Step: 9
Training loss: 0.7514774551969277
Validation loss: 2.3851726267616287

Epoch: 6| Step: 10
Training loss: 0.8527296274973061
Validation loss: 2.4416286084056065

Epoch: 6| Step: 11
Training loss: 0.9072615469930665
Validation loss: 2.405190962324114

Epoch: 6| Step: 12
Training loss: 0.7498967179073587
Validation loss: 2.413794779611508

Epoch: 6| Step: 13
Training loss: 0.5870529239035562
Validation loss: 2.406589435639425

Epoch: 322| Step: 0
Training loss: 0.9523407883633258
Validation loss: 2.428003125163535

Epoch: 6| Step: 1
Training loss: 0.7143165854186094
Validation loss: 2.411793245794122

Epoch: 6| Step: 2
Training loss: 0.8943506250052242
Validation loss: 2.39526436475764

Epoch: 6| Step: 3
Training loss: 0.6918093266112357
Validation loss: 2.3896593200679055

Epoch: 6| Step: 4
Training loss: 0.9248638516829276
Validation loss: 2.406133283733743

Epoch: 6| Step: 5
Training loss: 0.8745748645129517
Validation loss: 2.405852335157758

Epoch: 6| Step: 6
Training loss: 0.6972062756153088
Validation loss: 2.3907925298215833

Epoch: 6| Step: 7
Training loss: 0.6675801847994184
Validation loss: 2.4137781473977813

Epoch: 6| Step: 8
Training loss: 0.8218177064717216
Validation loss: 2.417697548892034

Epoch: 6| Step: 9
Training loss: 0.5146185849994243
Validation loss: 2.419622049102674

Epoch: 6| Step: 10
Training loss: 0.49491505004705283
Validation loss: 2.4233847102752586

Epoch: 6| Step: 11
Training loss: 0.4696246887258798
Validation loss: 2.426729240784915

Epoch: 6| Step: 12
Training loss: 1.6501249381649727
Validation loss: 2.4196734708239847

Epoch: 6| Step: 13
Training loss: 1.1115560984970105
Validation loss: 2.4507421077796474

Epoch: 323| Step: 0
Training loss: 0.7913731650001462
Validation loss: 2.449416279123797

Epoch: 6| Step: 1
Training loss: 0.8369113917625305
Validation loss: 2.4098922130937184

Epoch: 6| Step: 2
Training loss: 0.8870460477572034
Validation loss: 2.41209914638846

Epoch: 6| Step: 3
Training loss: 0.7372988264848793
Validation loss: 2.4405722775444194

Epoch: 6| Step: 4
Training loss: 0.8204107316556278
Validation loss: 2.4580537957935324

Epoch: 6| Step: 5
Training loss: 0.39187772150630873
Validation loss: 2.4451186670634515

Epoch: 6| Step: 6
Training loss: 0.26880620102641023
Validation loss: 2.4339990655744894

Epoch: 6| Step: 7
Training loss: 0.5063651366053615
Validation loss: 2.454847260692267

Epoch: 6| Step: 8
Training loss: 1.0032951186961816
Validation loss: 2.440025108115087

Epoch: 6| Step: 9
Training loss: 0.9749238571365716
Validation loss: 2.415464056047637

Epoch: 6| Step: 10
Training loss: 0.721807899494128
Validation loss: 2.419439215470565

Epoch: 6| Step: 11
Training loss: 1.6287890787772126
Validation loss: 2.3922891954925287

Epoch: 6| Step: 12
Training loss: 0.9101229813025109
Validation loss: 2.389212566218269

Epoch: 6| Step: 13
Training loss: 0.7772006569282869
Validation loss: 2.3867045392486994

Epoch: 324| Step: 0
Training loss: 0.9108716257136751
Validation loss: 2.4051184916399317

Epoch: 6| Step: 1
Training loss: 1.6062599330253577
Validation loss: 2.3915027066415018

Epoch: 6| Step: 2
Training loss: 0.4739712164947907
Validation loss: 2.392321944175978

Epoch: 6| Step: 3
Training loss: 0.5984927786851144
Validation loss: 2.438440473269263

Epoch: 6| Step: 4
Training loss: 0.6597159457884146
Validation loss: 2.4496313282301783

Epoch: 6| Step: 5
Training loss: 1.2171442261668335
Validation loss: 2.3957945240474583

Epoch: 6| Step: 6
Training loss: 0.8170875006735931
Validation loss: 2.419262931677749

Epoch: 6| Step: 7
Training loss: 0.7574201531707881
Validation loss: 2.4266016781187845

Epoch: 6| Step: 8
Training loss: 0.7477276073432926
Validation loss: 2.3920441405262025

Epoch: 6| Step: 9
Training loss: 0.8295711270489237
Validation loss: 2.3972710864939177

Epoch: 6| Step: 10
Training loss: 0.7600565061769682
Validation loss: 2.403183973769618

Epoch: 6| Step: 11
Training loss: 0.6435632314389812
Validation loss: 2.4240564990986124

Epoch: 6| Step: 12
Training loss: 0.7359382143442368
Validation loss: 2.4238498824894337

Epoch: 6| Step: 13
Training loss: 0.5459853428979791
Validation loss: 2.417898821553047

Epoch: 325| Step: 0
Training loss: 1.0464585458060511
Validation loss: 2.415572413754973

Epoch: 6| Step: 1
Training loss: 0.7226331552475214
Validation loss: 2.4229692668416414

Epoch: 6| Step: 2
Training loss: 1.1197145598131064
Validation loss: 2.4254657823660732

Epoch: 6| Step: 3
Training loss: 0.7064609018577411
Validation loss: 2.4219846310977116

Epoch: 6| Step: 4
Training loss: 0.44677195728160923
Validation loss: 2.432708650385804

Epoch: 6| Step: 5
Training loss: 0.4001887673270495
Validation loss: 2.3793102940810176

Epoch: 6| Step: 6
Training loss: 0.7092008654248658
Validation loss: 2.40838111247843

Epoch: 6| Step: 7
Training loss: 0.8390385515997204
Validation loss: 2.3651010003482993

Epoch: 6| Step: 8
Training loss: 0.6769772568774712
Validation loss: 2.3837251327254063

Epoch: 6| Step: 9
Training loss: 0.5609627486898154
Validation loss: 2.3952639173740855

Epoch: 6| Step: 10
Training loss: 1.186311227165011
Validation loss: 2.402622533069721

Epoch: 6| Step: 11
Training loss: 0.40875043180717036
Validation loss: 2.4184884318292723

Epoch: 6| Step: 12
Training loss: 1.5360538101009467
Validation loss: 2.4298265771675363

Epoch: 6| Step: 13
Training loss: 0.7086170180095437
Validation loss: 2.3996344858207004

Epoch: 326| Step: 0
Training loss: 1.680990591918107
Validation loss: 2.4616725102012977

Epoch: 6| Step: 1
Training loss: 0.8537264286434469
Validation loss: 2.4543175741305876

Epoch: 6| Step: 2
Training loss: 0.8442902071920642
Validation loss: 2.4671962901407998

Epoch: 6| Step: 3
Training loss: 0.6856032345637066
Validation loss: 2.4362681778333197

Epoch: 6| Step: 4
Training loss: 0.46888106421177395
Validation loss: 2.4265279826830435

Epoch: 6| Step: 5
Training loss: 0.6831792174006394
Validation loss: 2.415238509710379

Epoch: 6| Step: 6
Training loss: 0.3952207488987253
Validation loss: 2.4004900802813105

Epoch: 6| Step: 7
Training loss: 0.8297058706889894
Validation loss: 2.368445998504644

Epoch: 6| Step: 8
Training loss: 0.7531615616403872
Validation loss: 2.409031355088379

Epoch: 6| Step: 9
Training loss: 0.8854376996104003
Validation loss: 2.416983392375656

Epoch: 6| Step: 10
Training loss: 0.9239291565311987
Validation loss: 2.4312046319579648

Epoch: 6| Step: 11
Training loss: 0.7006374224293984
Validation loss: 2.4739963171503563

Epoch: 6| Step: 12
Training loss: 0.7485301396450047
Validation loss: 2.460328133477708

Epoch: 6| Step: 13
Training loss: 0.7488298427062614
Validation loss: 2.443000712113926

Epoch: 327| Step: 0
Training loss: 0.560732980065935
Validation loss: 2.435825119547219

Epoch: 6| Step: 1
Training loss: 0.5327868670788867
Validation loss: 2.399878040927119

Epoch: 6| Step: 2
Training loss: 1.60145732255155
Validation loss: 2.432997932474576

Epoch: 6| Step: 3
Training loss: 0.6295738941253353
Validation loss: 2.416233523218721

Epoch: 6| Step: 4
Training loss: 0.9856187138813555
Validation loss: 2.4135001218073575

Epoch: 6| Step: 5
Training loss: 0.7715079388460326
Validation loss: 2.3997887089398477

Epoch: 6| Step: 6
Training loss: 0.8514789925322972
Validation loss: 2.4273887754383927

Epoch: 6| Step: 7
Training loss: 0.9156416269817231
Validation loss: 2.4067603737828587

Epoch: 6| Step: 8
Training loss: 0.8179960331925553
Validation loss: 2.438822639062077

Epoch: 6| Step: 9
Training loss: 1.009102343413252
Validation loss: 2.4337604129655146

Epoch: 6| Step: 10
Training loss: 0.1890845991255214
Validation loss: 2.4225181516870222

Epoch: 6| Step: 11
Training loss: 0.4798114125750136
Validation loss: 2.4165030495825746

Epoch: 6| Step: 12
Training loss: 0.8663650943210186
Validation loss: 2.4404676003462327

Epoch: 6| Step: 13
Training loss: 0.683014651649624
Validation loss: 2.4261940542503986

Epoch: 328| Step: 0
Training loss: 0.7247137524059624
Validation loss: 2.4118865315178177

Epoch: 6| Step: 1
Training loss: 0.7860803053480899
Validation loss: 2.4004077574175597

Epoch: 6| Step: 2
Training loss: 0.8254240723389552
Validation loss: 2.4229583307353644

Epoch: 6| Step: 3
Training loss: 0.5388513787423185
Validation loss: 2.3937383415353586

Epoch: 6| Step: 4
Training loss: 0.7822706041069974
Validation loss: 2.410573973975071

Epoch: 6| Step: 5
Training loss: 0.6972373294164615
Validation loss: 2.412262204889208

Epoch: 6| Step: 6
Training loss: 0.49855156552978824
Validation loss: 2.4712167920804102

Epoch: 6| Step: 7
Training loss: 0.6306622081928985
Validation loss: 2.4486761729732573

Epoch: 6| Step: 8
Training loss: 0.7589612296634949
Validation loss: 2.4124936912998636

Epoch: 6| Step: 9
Training loss: 1.0375141280717513
Validation loss: 2.4443484182908803

Epoch: 6| Step: 10
Training loss: 0.736456012497356
Validation loss: 2.411313252290798

Epoch: 6| Step: 11
Training loss: 1.5734614592984808
Validation loss: 2.4120025421128095

Epoch: 6| Step: 12
Training loss: 0.83429792526812
Validation loss: 2.3944475397230622

Epoch: 6| Step: 13
Training loss: 0.7844716593848702
Validation loss: 2.410087691507158

Epoch: 329| Step: 0
Training loss: 0.8415353461699957
Validation loss: 2.426606462883048

Epoch: 6| Step: 1
Training loss: 0.5642220311160567
Validation loss: 2.4196269366686107

Epoch: 6| Step: 2
Training loss: 0.6685162358505776
Validation loss: 2.4265598857758244

Epoch: 6| Step: 3
Training loss: 0.43212669932346054
Validation loss: 2.418792681243129

Epoch: 6| Step: 4
Training loss: 1.1022164858669639
Validation loss: 2.4524567159294977

Epoch: 6| Step: 5
Training loss: 1.7191165186486201
Validation loss: 2.430688942932474

Epoch: 6| Step: 6
Training loss: 0.7072029116135854
Validation loss: 2.4462358627083955

Epoch: 6| Step: 7
Training loss: 0.7963545352460076
Validation loss: 2.443243835497381

Epoch: 6| Step: 8
Training loss: 0.7879484640517395
Validation loss: 2.4478326354116198

Epoch: 6| Step: 9
Training loss: 0.5869510023326717
Validation loss: 2.431900866435255

Epoch: 6| Step: 10
Training loss: 0.6090315315433447
Validation loss: 2.4471715204502495

Epoch: 6| Step: 11
Training loss: 0.7400650193028416
Validation loss: 2.4497099881596025

Epoch: 6| Step: 12
Training loss: 0.6054829749620567
Validation loss: 2.434354453676961

Epoch: 6| Step: 13
Training loss: 0.7690857890484587
Validation loss: 2.445097294898655

Epoch: 330| Step: 0
Training loss: 0.3131540249413436
Validation loss: 2.4544072956144807

Epoch: 6| Step: 1
Training loss: 0.7145004698936673
Validation loss: 2.4848011729913693

Epoch: 6| Step: 2
Training loss: 0.7759495793607231
Validation loss: 2.4600026949292406

Epoch: 6| Step: 3
Training loss: 0.8568001059002281
Validation loss: 2.466241106103015

Epoch: 6| Step: 4
Training loss: 0.669856321280496
Validation loss: 2.475295112382536

Epoch: 6| Step: 5
Training loss: 0.5954994228594055
Validation loss: 2.429570623400708

Epoch: 6| Step: 6
Training loss: 1.684348377590659
Validation loss: 2.44801501144414

Epoch: 6| Step: 7
Training loss: 0.6690287962562088
Validation loss: 2.4788945221810237

Epoch: 6| Step: 8
Training loss: 0.7576305131559012
Validation loss: 2.4153358060843217

Epoch: 6| Step: 9
Training loss: 1.0779087568498398
Validation loss: 2.443306254116377

Epoch: 6| Step: 10
Training loss: 0.6535790904546697
Validation loss: 2.422650045757513

Epoch: 6| Step: 11
Training loss: 0.6530583744654395
Validation loss: 2.434541257518861

Epoch: 6| Step: 12
Training loss: 0.817776675111982
Validation loss: 2.421858847753123

Epoch: 6| Step: 13
Training loss: 0.487793869918892
Validation loss: 2.3902364971850494

Epoch: 331| Step: 0
Training loss: 0.7851096371910603
Validation loss: 2.4668593960238248

Epoch: 6| Step: 1
Training loss: 0.6164167879506833
Validation loss: 2.439202697600568

Epoch: 6| Step: 2
Training loss: 1.5794699952118547
Validation loss: 2.4376953831298698

Epoch: 6| Step: 3
Training loss: 0.6511989073013703
Validation loss: 2.4481815544782113

Epoch: 6| Step: 4
Training loss: 0.4564298928316511
Validation loss: 2.4453597829703613

Epoch: 6| Step: 5
Training loss: 0.7278602659112203
Validation loss: 2.4189847034770606

Epoch: 6| Step: 6
Training loss: 1.0598799995658066
Validation loss: 2.3994004675743192

Epoch: 6| Step: 7
Training loss: 0.9091998793575478
Validation loss: 2.3774334218223245

Epoch: 6| Step: 8
Training loss: 0.6697713833037082
Validation loss: 2.386321636670787

Epoch: 6| Step: 9
Training loss: 0.637338208256051
Validation loss: 2.365810768684939

Epoch: 6| Step: 10
Training loss: 0.6653268110349596
Validation loss: 2.3913933622856756

Epoch: 6| Step: 11
Training loss: 0.7815277750201199
Validation loss: 2.3916314124785187

Epoch: 6| Step: 12
Training loss: 0.6143338348940649
Validation loss: 2.4049617023124985

Epoch: 6| Step: 13
Training loss: 0.7920291012441145
Validation loss: 2.427166153928898

Epoch: 332| Step: 0
Training loss: 0.44416769007313806
Validation loss: 2.423154301853203

Epoch: 6| Step: 1
Training loss: 0.8491544009537301
Validation loss: 2.4045618013803796

Epoch: 6| Step: 2
Training loss: 1.5989924954255559
Validation loss: 2.4490919714101924

Epoch: 6| Step: 3
Training loss: 1.0870183601618602
Validation loss: 2.428376260936095

Epoch: 6| Step: 4
Training loss: 0.8120955414210794
Validation loss: 2.4274476117856607

Epoch: 6| Step: 5
Training loss: 0.48781065579443933
Validation loss: 2.4003255294559662

Epoch: 6| Step: 6
Training loss: 0.7483397226832572
Validation loss: 2.3960891733271925

Epoch: 6| Step: 7
Training loss: 0.4262406032399059
Validation loss: 2.386428394556755

Epoch: 6| Step: 8
Training loss: 0.5731881683215936
Validation loss: 2.4098564005702485

Epoch: 6| Step: 9
Training loss: 0.5523216944584597
Validation loss: 2.4403017095674437

Epoch: 6| Step: 10
Training loss: 0.5882602176224715
Validation loss: 2.426811935782916

Epoch: 6| Step: 11
Training loss: 0.8606253111595639
Validation loss: 2.4513894551653275

Epoch: 6| Step: 12
Training loss: 0.9083900833483904
Validation loss: 2.434549829153444

Epoch: 6| Step: 13
Training loss: 0.37448824295412847
Validation loss: 2.419713414120967

Epoch: 333| Step: 0
Training loss: 0.4258422107978046
Validation loss: 2.3890406633183097

Epoch: 6| Step: 1
Training loss: 0.8274453811252891
Validation loss: 2.396576226306644

Epoch: 6| Step: 2
Training loss: 0.6326351623713866
Validation loss: 2.3818608156535515

Epoch: 6| Step: 3
Training loss: 0.7895566695919112
Validation loss: 2.4315197103397175

Epoch: 6| Step: 4
Training loss: 0.6313550200774151
Validation loss: 2.393671030704898

Epoch: 6| Step: 5
Training loss: 0.9419635057284691
Validation loss: 2.392508651330805

Epoch: 6| Step: 6
Training loss: 0.5814634792474217
Validation loss: 2.43541041822825

Epoch: 6| Step: 7
Training loss: 0.8022193463092844
Validation loss: 2.402230984648795

Epoch: 6| Step: 8
Training loss: 0.4435591730640996
Validation loss: 2.4459028808071666

Epoch: 6| Step: 9
Training loss: 1.632713351365092
Validation loss: 2.4631610607484205

Epoch: 6| Step: 10
Training loss: 0.7253149663841326
Validation loss: 2.443018189506316

Epoch: 6| Step: 11
Training loss: 0.8211419771007047
Validation loss: 2.452395993715784

Epoch: 6| Step: 12
Training loss: 0.7380674345226403
Validation loss: 2.456911911513263

Epoch: 6| Step: 13
Training loss: 0.4185731030220974
Validation loss: 2.409493639585225

Epoch: 334| Step: 0
Training loss: 0.49739194705370293
Validation loss: 2.391469203847724

Epoch: 6| Step: 1
Training loss: 0.6541982092410389
Validation loss: 2.366402040497317

Epoch: 6| Step: 2
Training loss: 0.7970417820545534
Validation loss: 2.372687569249169

Epoch: 6| Step: 3
Training loss: 1.744069677877086
Validation loss: 2.3628565491491265

Epoch: 6| Step: 4
Training loss: 0.7568662575831882
Validation loss: 2.3668642833633506

Epoch: 6| Step: 5
Training loss: 0.8792069662418629
Validation loss: 2.37205053017162

Epoch: 6| Step: 6
Training loss: 0.7663497608454484
Validation loss: 2.3782338355393735

Epoch: 6| Step: 7
Training loss: 0.6889864068607467
Validation loss: 2.3768511521842295

Epoch: 6| Step: 8
Training loss: 0.8625783000179197
Validation loss: 2.4022846189635474

Epoch: 6| Step: 9
Training loss: 0.7437052416757406
Validation loss: 2.4048608755639265

Epoch: 6| Step: 10
Training loss: 0.6781223956291007
Validation loss: 2.403475503880682

Epoch: 6| Step: 11
Training loss: 0.4122343551808666
Validation loss: 2.4368824098839728

Epoch: 6| Step: 12
Training loss: 0.2349503607521689
Validation loss: 2.4221652769643285

Epoch: 6| Step: 13
Training loss: 0.4895384815313858
Validation loss: 2.465062370828299

Epoch: 335| Step: 0
Training loss: 0.5742116655185182
Validation loss: 2.471807346611134

Epoch: 6| Step: 1
Training loss: 0.7064466852412599
Validation loss: 2.438949017535628

Epoch: 6| Step: 2
Training loss: 0.7070527468622111
Validation loss: 2.4295778155146315

Epoch: 6| Step: 3
Training loss: 0.7234217120892807
Validation loss: 2.4198434004849667

Epoch: 6| Step: 4
Training loss: 0.8290081712943576
Validation loss: 2.42310583810383

Epoch: 6| Step: 5
Training loss: 0.9107771626038978
Validation loss: 2.4407937855341055

Epoch: 6| Step: 6
Training loss: 0.715822394187159
Validation loss: 2.4604181437330648

Epoch: 6| Step: 7
Training loss: 0.8593639719862367
Validation loss: 2.475030176238334

Epoch: 6| Step: 8
Training loss: 1.585491549928608
Validation loss: 2.4662945157201337

Epoch: 6| Step: 9
Training loss: 0.6113173755029728
Validation loss: 2.4560049570245432

Epoch: 6| Step: 10
Training loss: 0.639315219892384
Validation loss: 2.4594274004804713

Epoch: 6| Step: 11
Training loss: 0.7907703160568516
Validation loss: 2.4106521174791022

Epoch: 6| Step: 12
Training loss: 0.6426887996637813
Validation loss: 2.4512332665567227

Epoch: 6| Step: 13
Training loss: 0.3657628891616993
Validation loss: 2.403346645105644

Epoch: 336| Step: 0
Training loss: 0.8633686901705311
Validation loss: 2.4167996823624596

Epoch: 6| Step: 1
Training loss: 0.7195808749735825
Validation loss: 2.408653777128815

Epoch: 6| Step: 2
Training loss: 0.7517091033132619
Validation loss: 2.383667889795285

Epoch: 6| Step: 3
Training loss: 0.772083214232972
Validation loss: 2.4506461030931384

Epoch: 6| Step: 4
Training loss: 0.7779349374558053
Validation loss: 2.4161969420736242

Epoch: 6| Step: 5
Training loss: 0.4771625305917665
Validation loss: 2.4073191721730987

Epoch: 6| Step: 6
Training loss: 0.33313413220998056
Validation loss: 2.4332417603052945

Epoch: 6| Step: 7
Training loss: 0.633314286957835
Validation loss: 2.4185149967878936

Epoch: 6| Step: 8
Training loss: 1.084177800697275
Validation loss: 2.421834449283037

Epoch: 6| Step: 9
Training loss: 0.3558741343480667
Validation loss: 2.454213446636774

Epoch: 6| Step: 10
Training loss: 0.6884484035063122
Validation loss: 2.466211717378727

Epoch: 6| Step: 11
Training loss: 1.6260987748506173
Validation loss: 2.433833442265972

Epoch: 6| Step: 12
Training loss: 0.54066929938894
Validation loss: 2.4439411036259533

Epoch: 6| Step: 13
Training loss: 0.7048899856587145
Validation loss: 2.4237043592356002

Epoch: 337| Step: 0
Training loss: 0.6716459682350122
Validation loss: 2.4649873375155043

Epoch: 6| Step: 1
Training loss: 0.4375745164899166
Validation loss: 2.4469887232480114

Epoch: 6| Step: 2
Training loss: 0.6474798093321033
Validation loss: 2.455148571218692

Epoch: 6| Step: 3
Training loss: 0.6537162367962399
Validation loss: 2.439613521906128

Epoch: 6| Step: 4
Training loss: 0.6912193907915805
Validation loss: 2.469669318849205

Epoch: 6| Step: 5
Training loss: 0.5958694475962363
Validation loss: 2.4706180172474332

Epoch: 6| Step: 6
Training loss: 0.5011112857387395
Validation loss: 2.4412261857110495

Epoch: 6| Step: 7
Training loss: 0.7235960751576258
Validation loss: 2.450088657627551

Epoch: 6| Step: 8
Training loss: 0.6043245147716386
Validation loss: 2.4422672719348446

Epoch: 6| Step: 9
Training loss: 0.7658349352692906
Validation loss: 2.438427756174739

Epoch: 6| Step: 10
Training loss: 0.9933210490787804
Validation loss: 2.4403579266002033

Epoch: 6| Step: 11
Training loss: 0.756199171391608
Validation loss: 2.4344927429725645

Epoch: 6| Step: 12
Training loss: 1.6695066415403865
Validation loss: 2.450941306422043

Epoch: 6| Step: 13
Training loss: 0.5180952547689902
Validation loss: 2.452764262642095

Epoch: 338| Step: 0
Training loss: 0.7414691058286761
Validation loss: 2.4549759626965084

Epoch: 6| Step: 1
Training loss: 1.5872163173690468
Validation loss: 2.4300454640360707

Epoch: 6| Step: 2
Training loss: 0.7298785186306456
Validation loss: 2.389038712451315

Epoch: 6| Step: 3
Training loss: 0.2702094681028971
Validation loss: 2.394556999419394

Epoch: 6| Step: 4
Training loss: 0.6309210685113212
Validation loss: 2.383525326607912

Epoch: 6| Step: 5
Training loss: 0.6656730867307725
Validation loss: 2.4108984360181087

Epoch: 6| Step: 6
Training loss: 0.6342588073982038
Validation loss: 2.4091143500449617

Epoch: 6| Step: 7
Training loss: 0.9128350387449587
Validation loss: 2.4176981400451667

Epoch: 6| Step: 8
Training loss: 0.7666089100090763
Validation loss: 2.4154917676059435

Epoch: 6| Step: 9
Training loss: 0.7151819481794616
Validation loss: 2.4009619475752384

Epoch: 6| Step: 10
Training loss: 0.4955091411014919
Validation loss: 2.3960132570551704

Epoch: 6| Step: 11
Training loss: 0.7098334826382459
Validation loss: 2.383934659701072

Epoch: 6| Step: 12
Training loss: 0.8794308601428577
Validation loss: 2.396729487260534

Epoch: 6| Step: 13
Training loss: 0.3577406665376212
Validation loss: 2.427961624081718

Epoch: 339| Step: 0
Training loss: 0.8752578968366318
Validation loss: 2.4507115331403737

Epoch: 6| Step: 1
Training loss: 0.7598358357209725
Validation loss: 2.4257578970947034

Epoch: 6| Step: 2
Training loss: 0.6418258762598362
Validation loss: 2.4067096225958062

Epoch: 6| Step: 3
Training loss: 0.8011305256648689
Validation loss: 2.4292999487114155

Epoch: 6| Step: 4
Training loss: 1.5782991823061965
Validation loss: 2.444513298239874

Epoch: 6| Step: 5
Training loss: 0.6884301136121025
Validation loss: 2.4613710900761454

Epoch: 6| Step: 6
Training loss: 0.6683630420934247
Validation loss: 2.4478053926212713

Epoch: 6| Step: 7
Training loss: 0.7483638958187607
Validation loss: 2.4576189726678423

Epoch: 6| Step: 8
Training loss: 0.5075362407729491
Validation loss: 2.460351962662515

Epoch: 6| Step: 9
Training loss: 0.22495417459387063
Validation loss: 2.468281025473925

Epoch: 6| Step: 10
Training loss: 0.8777599403994071
Validation loss: 2.4615883097687146

Epoch: 6| Step: 11
Training loss: 0.6165196390620475
Validation loss: 2.4463787745308156

Epoch: 6| Step: 12
Training loss: 0.6435196538486219
Validation loss: 2.450047326609217

Epoch: 6| Step: 13
Training loss: 0.3363635887384967
Validation loss: 2.4295886131421702

Epoch: 340| Step: 0
Training loss: 0.7910173580951307
Validation loss: 2.421454535434656

Epoch: 6| Step: 1
Training loss: 0.7923260419036926
Validation loss: 2.395734759456798

Epoch: 6| Step: 2
Training loss: 0.4800989231853173
Validation loss: 2.4084761312566036

Epoch: 6| Step: 3
Training loss: 0.8156530382737595
Validation loss: 2.4063854171434205

Epoch: 6| Step: 4
Training loss: 0.30367948608438866
Validation loss: 2.4201562610657383

Epoch: 6| Step: 5
Training loss: 0.8866633595378647
Validation loss: 2.401914964171973

Epoch: 6| Step: 6
Training loss: 0.8735540909311582
Validation loss: 2.378002334545939

Epoch: 6| Step: 7
Training loss: 0.6300876964355299
Validation loss: 2.4184625396974186

Epoch: 6| Step: 8
Training loss: 0.6217737134561178
Validation loss: 2.414604689229812

Epoch: 6| Step: 9
Training loss: 0.5968101346385222
Validation loss: 2.429893111172016

Epoch: 6| Step: 10
Training loss: 0.5320058942626025
Validation loss: 2.4381147137497967

Epoch: 6| Step: 11
Training loss: 0.5315300259546619
Validation loss: 2.401487983825719

Epoch: 6| Step: 12
Training loss: 0.6065882515882369
Validation loss: 2.4419677477207062

Epoch: 6| Step: 13
Training loss: 2.026463547219448
Validation loss: 2.4141969023120367

Epoch: 341| Step: 0
Training loss: 0.8190272116745816
Validation loss: 2.4285808430602356

Epoch: 6| Step: 1
Training loss: 0.4846210316349677
Validation loss: 2.4412724908754706

Epoch: 6| Step: 2
Training loss: 0.5105081755163753
Validation loss: 2.4416063699063733

Epoch: 6| Step: 3
Training loss: 0.7778228356918784
Validation loss: 2.424145088553095

Epoch: 6| Step: 4
Training loss: 0.7908272978214353
Validation loss: 2.439134259745028

Epoch: 6| Step: 5
Training loss: 0.5656074942730337
Validation loss: 2.4615001404452848

Epoch: 6| Step: 6
Training loss: 0.36892025540888884
Validation loss: 2.4353050096511337

Epoch: 6| Step: 7
Training loss: 0.7225695996271843
Validation loss: 2.4650646099261193

Epoch: 6| Step: 8
Training loss: 0.6053641444258281
Validation loss: 2.4542105144779707

Epoch: 6| Step: 9
Training loss: 0.6748515884286886
Validation loss: 2.410509008791688

Epoch: 6| Step: 10
Training loss: 1.704224607730912
Validation loss: 2.4379469569802583

Epoch: 6| Step: 11
Training loss: 0.47903025454539006
Validation loss: 2.4713105723106463

Epoch: 6| Step: 12
Training loss: 0.7653942149577376
Validation loss: 2.4324606240177116

Epoch: 6| Step: 13
Training loss: 0.5811824882431532
Validation loss: 2.441605227526628

Epoch: 342| Step: 0
Training loss: 0.45602758355641393
Validation loss: 2.473587658783542

Epoch: 6| Step: 1
Training loss: 1.936498321508837
Validation loss: 2.464017577047971

Epoch: 6| Step: 2
Training loss: 0.25456068357011125
Validation loss: 2.4243864409140414

Epoch: 6| Step: 3
Training loss: 0.258840562986184
Validation loss: 2.4837082540676065

Epoch: 6| Step: 4
Training loss: 0.6564005724419162
Validation loss: 2.4532727469455278

Epoch: 6| Step: 5
Training loss: 0.5690387977720882
Validation loss: 2.4463598456468536

Epoch: 6| Step: 6
Training loss: 0.7551864664704786
Validation loss: 2.4566404726826465

Epoch: 6| Step: 7
Training loss: 0.6710374624252273
Validation loss: 2.4415435728768804

Epoch: 6| Step: 8
Training loss: 0.7178010896299801
Validation loss: 2.444515560354912

Epoch: 6| Step: 9
Training loss: 0.31520657280864994
Validation loss: 2.4519463821942065

Epoch: 6| Step: 10
Training loss: 0.6755555056985341
Validation loss: 2.4166853527058128

Epoch: 6| Step: 11
Training loss: 0.7303266744090994
Validation loss: 2.3962228971036166

Epoch: 6| Step: 12
Training loss: 0.7028135033545619
Validation loss: 2.4031438992151313

Epoch: 6| Step: 13
Training loss: 0.5779088621522441
Validation loss: 2.4201625606387296

Epoch: 343| Step: 0
Training loss: 0.7981057106620576
Validation loss: 2.4353530879981484

Epoch: 6| Step: 1
Training loss: 0.6458468102515394
Validation loss: 2.4414057323168135

Epoch: 6| Step: 2
Training loss: 0.8702244205523664
Validation loss: 2.499069824270388

Epoch: 6| Step: 3
Training loss: 0.49830501075091693
Validation loss: 2.477182297485785

Epoch: 6| Step: 4
Training loss: 0.7087590303468059
Validation loss: 2.4912735466101346

Epoch: 6| Step: 5
Training loss: 0.7012591719410052
Validation loss: 2.4457271155887987

Epoch: 6| Step: 6
Training loss: 0.7274740919763157
Validation loss: 2.3963972122742385

Epoch: 6| Step: 7
Training loss: 0.444948984983045
Validation loss: 2.397274086692495

Epoch: 6| Step: 8
Training loss: 0.596552409131176
Validation loss: 2.366253908390729

Epoch: 6| Step: 9
Training loss: 0.5870945505388637
Validation loss: 2.392161553862938

Epoch: 6| Step: 10
Training loss: 0.574719243337156
Validation loss: 2.4237322605780243

Epoch: 6| Step: 11
Training loss: 0.8962269997405424
Validation loss: 2.430856398282077

Epoch: 6| Step: 12
Training loss: 0.6332711335641724
Validation loss: 2.40840209514758

Epoch: 6| Step: 13
Training loss: 2.1096919068946067
Validation loss: 2.468484589866294

Epoch: 344| Step: 0
Training loss: 0.7300166398594903
Validation loss: 2.437167890466417

Epoch: 6| Step: 1
Training loss: 0.8359838455044798
Validation loss: 2.4382784189216213

Epoch: 6| Step: 2
Training loss: 0.618100758184225
Validation loss: 2.4287714665545073

Epoch: 6| Step: 3
Training loss: 0.6878085094441865
Validation loss: 2.468644785427054

Epoch: 6| Step: 4
Training loss: 0.38978002711617826
Validation loss: 2.4071320183857834

Epoch: 6| Step: 5
Training loss: 0.6377661579497239
Validation loss: 2.4159883035739176

Epoch: 6| Step: 6
Training loss: 1.633547895637192
Validation loss: 2.446856847172468

Epoch: 6| Step: 7
Training loss: 0.703910664196336
Validation loss: 2.4799138576414004

Epoch: 6| Step: 8
Training loss: 0.7362326805525786
Validation loss: 2.46552264414681

Epoch: 6| Step: 9
Training loss: 0.7766553427999023
Validation loss: 2.4575370008386495

Epoch: 6| Step: 10
Training loss: 0.5572422457258606
Validation loss: 2.449303625821541

Epoch: 6| Step: 11
Training loss: 0.7494699273899655
Validation loss: 2.4370763372112707

Epoch: 6| Step: 12
Training loss: 0.6440931507426332
Validation loss: 2.4300968450638556

Epoch: 6| Step: 13
Training loss: 0.23003798168600204
Validation loss: 2.404315959106655

Epoch: 345| Step: 0
Training loss: 0.4158285194830567
Validation loss: 2.4389172744008563

Epoch: 6| Step: 1
Training loss: 0.5878591180513939
Validation loss: 2.413341859218218

Epoch: 6| Step: 2
Training loss: 0.5871224691893991
Validation loss: 2.4397933621410703

Epoch: 6| Step: 3
Training loss: 0.8595275396736087
Validation loss: 2.4789161541773512

Epoch: 6| Step: 4
Training loss: 0.8755289931014452
Validation loss: 2.470590667713933

Epoch: 6| Step: 5
Training loss: 0.44495757498118227
Validation loss: 2.4874581978881776

Epoch: 6| Step: 6
Training loss: 0.873814222133984
Validation loss: 2.530006440482891

Epoch: 6| Step: 7
Training loss: 1.5961325545035476
Validation loss: 2.5346390806115235

Epoch: 6| Step: 8
Training loss: 0.7107004881448546
Validation loss: 2.4625979929818818

Epoch: 6| Step: 9
Training loss: 0.7347848032872456
Validation loss: 2.4540863358515193

Epoch: 6| Step: 10
Training loss: 0.8874272948021575
Validation loss: 2.4382701779229303

Epoch: 6| Step: 11
Training loss: 0.5675870229150939
Validation loss: 2.4211475996106246

Epoch: 6| Step: 12
Training loss: 0.6012791796243627
Validation loss: 2.4142017392710207

Epoch: 6| Step: 13
Training loss: 0.21835423328712986
Validation loss: 2.3693779473465173

Epoch: 346| Step: 0
Training loss: 0.715649926696829
Validation loss: 2.353396755806671

Epoch: 6| Step: 1
Training loss: 0.7826023223203952
Validation loss: 2.3716674571213647

Epoch: 6| Step: 2
Training loss: 0.7120823707001148
Validation loss: 2.408496473384411

Epoch: 6| Step: 3
Training loss: 0.687274852646073
Validation loss: 2.4352193732711385

Epoch: 6| Step: 4
Training loss: 0.5902893454845627
Validation loss: 2.485670038412025

Epoch: 6| Step: 5
Training loss: 1.685076633601095
Validation loss: 2.4983267157821336

Epoch: 6| Step: 6
Training loss: 0.4610953949576095
Validation loss: 2.46843897899708

Epoch: 6| Step: 7
Training loss: 0.6339729641811769
Validation loss: 2.5089327916962314

Epoch: 6| Step: 8
Training loss: 0.6220173955474986
Validation loss: 2.4838456936458515

Epoch: 6| Step: 9
Training loss: 0.7090757537046958
Validation loss: 2.4575278615673533

Epoch: 6| Step: 10
Training loss: 0.8927684889785397
Validation loss: 2.4659962725331273

Epoch: 6| Step: 11
Training loss: 0.5694159685422121
Validation loss: 2.441371758723934

Epoch: 6| Step: 12
Training loss: 0.7461624513321989
Validation loss: 2.463496249766117

Epoch: 6| Step: 13
Training loss: 0.4117284523908303
Validation loss: 2.477723360651258

Epoch: 347| Step: 0
Training loss: 0.7296904635318149
Validation loss: 2.478354849448849

Epoch: 6| Step: 1
Training loss: 0.7322518113108354
Validation loss: 2.4642488155457207

Epoch: 6| Step: 2
Training loss: 0.917532049965353
Validation loss: 2.4293874156909254

Epoch: 6| Step: 3
Training loss: 0.5957562782462636
Validation loss: 2.40706450590304

Epoch: 6| Step: 4
Training loss: 0.7351259085447382
Validation loss: 2.4192664116590614

Epoch: 6| Step: 5
Training loss: 0.646206891302532
Validation loss: 2.3661718597692234

Epoch: 6| Step: 6
Training loss: 0.5323097653929548
Validation loss: 2.396702750359646

Epoch: 6| Step: 7
Training loss: 0.47326871110408103
Validation loss: 2.3544593623271686

Epoch: 6| Step: 8
Training loss: 0.6498870733173826
Validation loss: 2.3680842224877656

Epoch: 6| Step: 9
Training loss: 1.570398280899032
Validation loss: 2.378374170994335

Epoch: 6| Step: 10
Training loss: 0.7427642990220198
Validation loss: 2.360427869263632

Epoch: 6| Step: 11
Training loss: 0.9040168345073857
Validation loss: 2.387040487552613

Epoch: 6| Step: 12
Training loss: 0.4727271318487561
Validation loss: 2.374033337742756

Epoch: 6| Step: 13
Training loss: 0.6124611005302956
Validation loss: 2.3803510223038877

Epoch: 348| Step: 0
Training loss: 0.8614710475132538
Validation loss: 2.451777108590512

Epoch: 6| Step: 1
Training loss: 0.4312274387926476
Validation loss: 2.4418427218207266

Epoch: 6| Step: 2
Training loss: 0.46138941707321846
Validation loss: 2.4856051376994657

Epoch: 6| Step: 3
Training loss: 0.5739314599735542
Validation loss: 2.4335342384411813

Epoch: 6| Step: 4
Training loss: 0.5423238478393583
Validation loss: 2.412143027399788

Epoch: 6| Step: 5
Training loss: 0.5483499255998675
Validation loss: 2.392645436575432

Epoch: 6| Step: 6
Training loss: 0.7822841284973268
Validation loss: 2.349895879454436

Epoch: 6| Step: 7
Training loss: 0.7687014060440196
Validation loss: 2.413635268137389

Epoch: 6| Step: 8
Training loss: 0.5306193029953807
Validation loss: 2.3956983821646567

Epoch: 6| Step: 9
Training loss: 0.566845559067502
Validation loss: 2.4141794774984433

Epoch: 6| Step: 10
Training loss: 0.740498800028177
Validation loss: 2.44335019791162

Epoch: 6| Step: 11
Training loss: 0.7330001785933835
Validation loss: 2.467573093831496

Epoch: 6| Step: 12
Training loss: 1.7200691016310903
Validation loss: 2.4700519487536834

Epoch: 6| Step: 13
Training loss: 0.6505608550670364
Validation loss: 2.5061991794991947

Epoch: 349| Step: 0
Training loss: 0.7020061916529291
Validation loss: 2.4955040312443346

Epoch: 6| Step: 1
Training loss: 0.668184256785112
Validation loss: 2.4904172755775407

Epoch: 6| Step: 2
Training loss: 0.6023740619795399
Validation loss: 2.4763004040976244

Epoch: 6| Step: 3
Training loss: 0.755349038707697
Validation loss: 2.5011660020457853

Epoch: 6| Step: 4
Training loss: 0.5760251650478758
Validation loss: 2.450706252522196

Epoch: 6| Step: 5
Training loss: 1.6628981264145462
Validation loss: 2.448224976724936

Epoch: 6| Step: 6
Training loss: 0.4307714488423012
Validation loss: 2.424919449982605

Epoch: 6| Step: 7
Training loss: 0.6733358160372875
Validation loss: 2.4379391775478028

Epoch: 6| Step: 8
Training loss: 0.6499938671116173
Validation loss: 2.387005951235058

Epoch: 6| Step: 9
Training loss: 0.4934030086162736
Validation loss: 2.4071804357794115

Epoch: 6| Step: 10
Training loss: 0.30459148165600913
Validation loss: 2.4258256777082963

Epoch: 6| Step: 11
Training loss: 0.581170924765775
Validation loss: 2.4025381390279894

Epoch: 6| Step: 12
Training loss: 0.8550060884917017
Validation loss: 2.422905461964341

Epoch: 6| Step: 13
Training loss: 0.8836472202517833
Validation loss: 2.373286514811901

Epoch: 350| Step: 0
Training loss: 0.7413792274623417
Validation loss: 2.378272825567229

Epoch: 6| Step: 1
Training loss: 0.8659184423281664
Validation loss: 2.411346566554018

Epoch: 6| Step: 2
Training loss: 0.6331820645086328
Validation loss: 2.4046154012980776

Epoch: 6| Step: 3
Training loss: 0.21211203543608612
Validation loss: 2.4474723068749236

Epoch: 6| Step: 4
Training loss: 1.6417101949481758
Validation loss: 2.43949881174356

Epoch: 6| Step: 5
Training loss: 0.5378148110676417
Validation loss: 2.4589527195236816

Epoch: 6| Step: 6
Training loss: 0.5315829523941032
Validation loss: 2.474785342022444

Epoch: 6| Step: 7
Training loss: 0.5688920818221042
Validation loss: 2.440846122951556

Epoch: 6| Step: 8
Training loss: 0.7859992061834233
Validation loss: 2.41882921624244

Epoch: 6| Step: 9
Training loss: 0.560835547997843
Validation loss: 2.4279617206949067

Epoch: 6| Step: 10
Training loss: 0.5041677698275685
Validation loss: 2.436661766775323

Epoch: 6| Step: 11
Training loss: 0.851348780139639
Validation loss: 2.4218209548090934

Epoch: 6| Step: 12
Training loss: 0.40221475181344024
Validation loss: 2.435942255944382

Epoch: 6| Step: 13
Training loss: 0.5524307063824682
Validation loss: 2.4212219861035917

Epoch: 351| Step: 0
Training loss: 1.6412640008380057
Validation loss: 2.437546593131624

Epoch: 6| Step: 1
Training loss: 0.6117395838360096
Validation loss: 2.431556716224377

Epoch: 6| Step: 2
Training loss: 0.7790253818818421
Validation loss: 2.498310965462569

Epoch: 6| Step: 3
Training loss: 0.7258596815224184
Validation loss: 2.406521276218792

Epoch: 6| Step: 4
Training loss: 0.46062661047748416
Validation loss: 2.427788324454333

Epoch: 6| Step: 5
Training loss: 0.7683309498403103
Validation loss: 2.4448289159454495

Epoch: 6| Step: 6
Training loss: 0.6427785914355577
Validation loss: 2.457597092187538

Epoch: 6| Step: 7
Training loss: 0.4617009064248854
Validation loss: 2.447866657054319

Epoch: 6| Step: 8
Training loss: 0.4908164015468795
Validation loss: 2.452817436852748

Epoch: 6| Step: 9
Training loss: 0.6470038179774299
Validation loss: 2.4595464626506467

Epoch: 6| Step: 10
Training loss: 0.7248769096590119
Validation loss: 2.4150818524656494

Epoch: 6| Step: 11
Training loss: 0.49799499241482875
Validation loss: 2.435371876108091

Epoch: 6| Step: 12
Training loss: 0.348747341460346
Validation loss: 2.388315571485061

Epoch: 6| Step: 13
Training loss: 0.5953078162141707
Validation loss: 2.394997090641399

Epoch: 352| Step: 0
Training loss: 0.6215393339417092
Validation loss: 2.40760904571729

Epoch: 6| Step: 1
Training loss: 0.6330795666434165
Validation loss: 2.4317713738288846

Epoch: 6| Step: 2
Training loss: 0.7682202785861417
Validation loss: 2.4424152621321182

Epoch: 6| Step: 3
Training loss: 0.38120955971907533
Validation loss: 2.4726086315650213

Epoch: 6| Step: 4
Training loss: 0.5033352596149258
Validation loss: 2.4694659663120038

Epoch: 6| Step: 5
Training loss: 0.4932034316259114
Validation loss: 2.4708285882435255

Epoch: 6| Step: 6
Training loss: 0.42895935091203985
Validation loss: 2.5025297747600437

Epoch: 6| Step: 7
Training loss: 0.7110307234123083
Validation loss: 2.415500816512427

Epoch: 6| Step: 8
Training loss: 0.6835173863946244
Validation loss: 2.429720940063194

Epoch: 6| Step: 9
Training loss: 0.7997930989339977
Validation loss: 2.369703312610232

Epoch: 6| Step: 10
Training loss: 0.9284423054532569
Validation loss: 2.3544750492607327

Epoch: 6| Step: 11
Training loss: 1.6801102217211696
Validation loss: 2.3768447216401327

Epoch: 6| Step: 12
Training loss: 0.44167348486058056
Validation loss: 2.368456642946347

Epoch: 6| Step: 13
Training loss: 0.27336065029861806
Validation loss: 2.3736550312149527

Epoch: 353| Step: 0
Training loss: 0.6069676948965954
Validation loss: 2.4095210905119893

Epoch: 6| Step: 1
Training loss: 0.30817408938638136
Validation loss: 2.4027708327417696

Epoch: 6| Step: 2
Training loss: 0.7703132335357578
Validation loss: 2.42866908117345

Epoch: 6| Step: 3
Training loss: 0.3026821583661116
Validation loss: 2.41375736121784

Epoch: 6| Step: 4
Training loss: 1.6242050280411071
Validation loss: 2.4274173256609375

Epoch: 6| Step: 5
Training loss: 0.8864622711440833
Validation loss: 2.384286713801885

Epoch: 6| Step: 6
Training loss: 0.7030057170141663
Validation loss: 2.3861186872622087

Epoch: 6| Step: 7
Training loss: 0.35787511968927116
Validation loss: 2.356731991041867

Epoch: 6| Step: 8
Training loss: 0.5632396709106278
Validation loss: 2.383734381806347

Epoch: 6| Step: 9
Training loss: 0.8784919949309589
Validation loss: 2.3769960397461833

Epoch: 6| Step: 10
Training loss: 0.5698807009281901
Validation loss: 2.416148721808666

Epoch: 6| Step: 11
Training loss: 0.5336625631483588
Validation loss: 2.3906643761235054

Epoch: 6| Step: 12
Training loss: 0.6886847864283273
Validation loss: 2.402084257335944

Epoch: 6| Step: 13
Training loss: 0.616938577021309
Validation loss: 2.383133708540059

Epoch: 354| Step: 0
Training loss: 0.6079041262408013
Validation loss: 2.400971654522043

Epoch: 6| Step: 1
Training loss: 0.43638366236485204
Validation loss: 2.3968517280892025

Epoch: 6| Step: 2
Training loss: 0.541515656353229
Validation loss: 2.4484255968361004

Epoch: 6| Step: 3
Training loss: 0.8012146312030917
Validation loss: 2.4017035783118152

Epoch: 6| Step: 4
Training loss: 0.6738786319103383
Validation loss: 2.4462134795490154

Epoch: 6| Step: 5
Training loss: 0.5671079826837127
Validation loss: 2.4515975806688983

Epoch: 6| Step: 6
Training loss: 1.652344904328793
Validation loss: 2.4861781724486076

Epoch: 6| Step: 7
Training loss: 0.738678073705751
Validation loss: 2.472495317401896

Epoch: 6| Step: 8
Training loss: 0.5107338724134172
Validation loss: 2.4878359247838997

Epoch: 6| Step: 9
Training loss: 0.575909700390275
Validation loss: 2.503857986988182

Epoch: 6| Step: 10
Training loss: 0.9421374382016897
Validation loss: 2.467543339678722

Epoch: 6| Step: 11
Training loss: 0.43846777756350486
Validation loss: 2.4753058353850967

Epoch: 6| Step: 12
Training loss: 0.32860082231457605
Validation loss: 2.476006004339005

Epoch: 6| Step: 13
Training loss: 0.3681292125286013
Validation loss: 2.4647378756571507

Epoch: 355| Step: 0
Training loss: 0.5073484501269987
Validation loss: 2.418200854179838

Epoch: 6| Step: 1
Training loss: 0.5740240376752614
Validation loss: 2.4049152752453953

Epoch: 6| Step: 2
Training loss: 0.6872353261045074
Validation loss: 2.4071988495120906

Epoch: 6| Step: 3
Training loss: 0.5339293233179958
Validation loss: 2.3777041012874016

Epoch: 6| Step: 4
Training loss: 1.7532123645902606
Validation loss: 2.407870348655558

Epoch: 6| Step: 5
Training loss: 0.5309643257822964
Validation loss: 2.3870818516451355

Epoch: 6| Step: 6
Training loss: 0.37634069471252257
Validation loss: 2.3912321096339335

Epoch: 6| Step: 7
Training loss: 0.7749214194052528
Validation loss: 2.37845740253177

Epoch: 6| Step: 8
Training loss: 0.7397294952242586
Validation loss: 2.3843626706670067

Epoch: 6| Step: 9
Training loss: 0.820644565764489
Validation loss: 2.3967720703685655

Epoch: 6| Step: 10
Training loss: 0.3975576709501407
Validation loss: 2.4009851508607007

Epoch: 6| Step: 11
Training loss: 0.7221600865468465
Validation loss: 2.400322781924755

Epoch: 6| Step: 12
Training loss: 0.293547097601014
Validation loss: 2.4446249028576403

Epoch: 6| Step: 13
Training loss: 0.19846618850465353
Validation loss: 2.4227082353032054

Epoch: 356| Step: 0
Training loss: 0.5803501506006922
Validation loss: 2.420319633659002

Epoch: 6| Step: 1
Training loss: 0.6656644012538061
Validation loss: 2.405018711303404

Epoch: 6| Step: 2
Training loss: 1.7031324893891737
Validation loss: 2.410021472892775

Epoch: 6| Step: 3
Training loss: 0.2929736073409182
Validation loss: 2.4074114982162493

Epoch: 6| Step: 4
Training loss: 0.6152500211149148
Validation loss: 2.3974982980012114

Epoch: 6| Step: 5
Training loss: 0.5603794286426546
Validation loss: 2.389678985592078

Epoch: 6| Step: 6
Training loss: 0.2906260603198326
Validation loss: 2.4448985449505343

Epoch: 6| Step: 7
Training loss: 0.7673315375274183
Validation loss: 2.448057951784861

Epoch: 6| Step: 8
Training loss: 0.6290953452588575
Validation loss: 2.4670226499020185

Epoch: 6| Step: 9
Training loss: 0.6591460494889465
Validation loss: 2.4815686138157047

Epoch: 6| Step: 10
Training loss: 0.5960532988375792
Validation loss: 2.455634557881378

Epoch: 6| Step: 11
Training loss: 0.5430160337209542
Validation loss: 2.4475170373950528

Epoch: 6| Step: 12
Training loss: 0.5399483851207566
Validation loss: 2.4508236599042945

Epoch: 6| Step: 13
Training loss: 0.6934795221813405
Validation loss: 2.427250397733166

Epoch: 357| Step: 0
Training loss: 0.5872840667139044
Validation loss: 2.4448102303971146

Epoch: 6| Step: 1
Training loss: 0.41137599322379664
Validation loss: 2.4314530458206143

Epoch: 6| Step: 2
Training loss: 0.6237959708357341
Validation loss: 2.389593615166805

Epoch: 6| Step: 3
Training loss: 0.587075006693516
Validation loss: 2.4254835161167008

Epoch: 6| Step: 4
Training loss: 0.38284548792492457
Validation loss: 2.42027588659464

Epoch: 6| Step: 5
Training loss: 1.627913723817575
Validation loss: 2.4747905495075933

Epoch: 6| Step: 6
Training loss: 0.830685489825752
Validation loss: 2.4016479455637323

Epoch: 6| Step: 7
Training loss: 0.2766170921970873
Validation loss: 2.4132632153513196

Epoch: 6| Step: 8
Training loss: 0.8191406599271273
Validation loss: 2.457468869105758

Epoch: 6| Step: 9
Training loss: 0.4060499725875404
Validation loss: 2.413415065015472

Epoch: 6| Step: 10
Training loss: 0.6126526934192865
Validation loss: 2.3987740654657763

Epoch: 6| Step: 11
Training loss: 0.762050575948337
Validation loss: 2.4239424091325836

Epoch: 6| Step: 12
Training loss: 0.4187281296840552
Validation loss: 2.408433023813588

Epoch: 6| Step: 13
Training loss: 0.6594769747013806
Validation loss: 2.409625745996998

Epoch: 358| Step: 0
Training loss: 0.4942541180575615
Validation loss: 2.408510625809429

Epoch: 6| Step: 1
Training loss: 0.8047523472405979
Validation loss: 2.3875989556160078

Epoch: 6| Step: 2
Training loss: 0.6100223721638456
Validation loss: 2.3992050186480043

Epoch: 6| Step: 3
Training loss: 0.23870015452866972
Validation loss: 2.39137688301453

Epoch: 6| Step: 4
Training loss: 0.6081041631627927
Validation loss: 2.4180050716196493

Epoch: 6| Step: 5
Training loss: 0.7433745277933123
Validation loss: 2.4192909239800144

Epoch: 6| Step: 6
Training loss: 0.5904224159330516
Validation loss: 2.4294377026339085

Epoch: 6| Step: 7
Training loss: 0.6551857220175186
Validation loss: 2.439994253141379

Epoch: 6| Step: 8
Training loss: 0.5721156994757745
Validation loss: 2.4480843152561325

Epoch: 6| Step: 9
Training loss: 1.62050248359318
Validation loss: 2.4494364319650224

Epoch: 6| Step: 10
Training loss: 0.7246585222630016
Validation loss: 2.431692606988132

Epoch: 6| Step: 11
Training loss: 0.3851162044297082
Validation loss: 2.4142794882074696

Epoch: 6| Step: 12
Training loss: 0.5115800917204213
Validation loss: 2.4164581969163685

Epoch: 6| Step: 13
Training loss: 0.5064518231886629
Validation loss: 2.430222821252579

Epoch: 359| Step: 0
Training loss: 0.5032715755694621
Validation loss: 2.4094638209735364

Epoch: 6| Step: 1
Training loss: 0.7278051516996047
Validation loss: 2.392346565404021

Epoch: 6| Step: 2
Training loss: 0.8251807939504973
Validation loss: 2.438304622126357

Epoch: 6| Step: 3
Training loss: 0.389557084390938
Validation loss: 2.4527491343032013

Epoch: 6| Step: 4
Training loss: 0.45823507628460525
Validation loss: 2.441366108750983

Epoch: 6| Step: 5
Training loss: 0.8020133611369955
Validation loss: 2.4462334638488326

Epoch: 6| Step: 6
Training loss: 0.7440295199054832
Validation loss: 2.4099345130892167

Epoch: 6| Step: 7
Training loss: 0.6762335702306992
Validation loss: 2.4274231300819316

Epoch: 6| Step: 8
Training loss: 0.5814881831450219
Validation loss: 2.4282994310388233

Epoch: 6| Step: 9
Training loss: 0.4095315444636678
Validation loss: 2.4467364131040137

Epoch: 6| Step: 10
Training loss: 0.47018616332371593
Validation loss: 2.4219549112305194

Epoch: 6| Step: 11
Training loss: 1.567211448357143
Validation loss: 2.4196386305512054

Epoch: 6| Step: 12
Training loss: 0.5216486239994768
Validation loss: 2.443148540360468

Epoch: 6| Step: 13
Training loss: 0.19407135477919077
Validation loss: 2.4566323642431604

Epoch: 360| Step: 0
Training loss: 0.5300023631277123
Validation loss: 2.4300528657392784

Epoch: 6| Step: 1
Training loss: 0.5247499892446981
Validation loss: 2.4379474764494513

Epoch: 6| Step: 2
Training loss: 0.5351434135289733
Validation loss: 2.408600561909666

Epoch: 6| Step: 3
Training loss: 0.589055096202837
Validation loss: 2.418291770402798

Epoch: 6| Step: 4
Training loss: 0.6978060126953334
Validation loss: 2.434925425605582

Epoch: 6| Step: 5
Training loss: 0.3758162515879011
Validation loss: 2.421639549091628

Epoch: 6| Step: 6
Training loss: 0.8509211793834106
Validation loss: 2.43305830430207

Epoch: 6| Step: 7
Training loss: 0.6811036451425606
Validation loss: 2.4251634187716875

Epoch: 6| Step: 8
Training loss: 0.45913628844049675
Validation loss: 2.418523887042666

Epoch: 6| Step: 9
Training loss: 0.34656660357867264
Validation loss: 2.4122129978272677

Epoch: 6| Step: 10
Training loss: 0.579696452644909
Validation loss: 2.4099947180417995

Epoch: 6| Step: 11
Training loss: 1.5618671661583488
Validation loss: 2.386364181511212

Epoch: 6| Step: 12
Training loss: 0.8818932532591702
Validation loss: 2.4169306952065526

Epoch: 6| Step: 13
Training loss: 0.43681187668926585
Validation loss: 2.428155909129439

Epoch: 361| Step: 0
Training loss: 0.6042870094761468
Validation loss: 2.4625707042873786

Epoch: 6| Step: 1
Training loss: 1.6913718557054391
Validation loss: 2.426001295996359

Epoch: 6| Step: 2
Training loss: 0.6199232383862066
Validation loss: 2.4007915010328156

Epoch: 6| Step: 3
Training loss: 0.5954461716090246
Validation loss: 2.412641804466962

Epoch: 6| Step: 4
Training loss: 0.40300910525767686
Validation loss: 2.4136301623810503

Epoch: 6| Step: 5
Training loss: 0.4746529515987073
Validation loss: 2.382784270131608

Epoch: 6| Step: 6
Training loss: 0.7323179451001862
Validation loss: 2.3875387721968853

Epoch: 6| Step: 7
Training loss: 0.4362594864696463
Validation loss: 2.421039555493648

Epoch: 6| Step: 8
Training loss: 0.572221096767113
Validation loss: 2.4313177005123277

Epoch: 6| Step: 9
Training loss: 0.6037368615815827
Validation loss: 2.4113345943102664

Epoch: 6| Step: 10
Training loss: 0.7607288677729153
Validation loss: 2.473610583973953

Epoch: 6| Step: 11
Training loss: 0.5575491467867304
Validation loss: 2.4327127118104057

Epoch: 6| Step: 12
Training loss: 0.5298491971032075
Validation loss: 2.4475002651169837

Epoch: 6| Step: 13
Training loss: 0.25853518142579035
Validation loss: 2.415001385259795

Epoch: 362| Step: 0
Training loss: 0.7114341175059593
Validation loss: 2.404173198895884

Epoch: 6| Step: 1
Training loss: 0.6040729060808614
Validation loss: 2.400945090857943

Epoch: 6| Step: 2
Training loss: 0.7441658155928383
Validation loss: 2.3981024288384525

Epoch: 6| Step: 3
Training loss: 0.34677569712036016
Validation loss: 2.411512488864011

Epoch: 6| Step: 4
Training loss: 0.5637783518341867
Validation loss: 2.4061309024277304

Epoch: 6| Step: 5
Training loss: 0.5918343661175827
Validation loss: 2.4572917162989225

Epoch: 6| Step: 6
Training loss: 0.5463208797219339
Validation loss: 2.4380409990800422

Epoch: 6| Step: 7
Training loss: 0.5328221899141503
Validation loss: 2.4407617491873026

Epoch: 6| Step: 8
Training loss: 1.6600891817794554
Validation loss: 2.4056146179956817

Epoch: 6| Step: 9
Training loss: 0.5271713257520511
Validation loss: 2.3932824685527376

Epoch: 6| Step: 10
Training loss: 0.4655968471951265
Validation loss: 2.3761710155087035

Epoch: 6| Step: 11
Training loss: 0.5535752333672905
Validation loss: 2.3993070126626588

Epoch: 6| Step: 12
Training loss: 0.5574734530949516
Validation loss: 2.4200873778143803

Epoch: 6| Step: 13
Training loss: 0.694223408225137
Validation loss: 2.4576262021389237

Epoch: 363| Step: 0
Training loss: 0.48676292867981813
Validation loss: 2.408695823744359

Epoch: 6| Step: 1
Training loss: 0.437390364806308
Validation loss: 2.407030943325655

Epoch: 6| Step: 2
Training loss: 1.704576696051773
Validation loss: 2.420273463593642

Epoch: 6| Step: 3
Training loss: 0.6805785685062967
Validation loss: 2.4037940451667015

Epoch: 6| Step: 4
Training loss: 0.6601687774372457
Validation loss: 2.388737386317734

Epoch: 6| Step: 5
Training loss: 0.5689700539339798
Validation loss: 2.366136711145836

Epoch: 6| Step: 6
Training loss: 0.5433710926583235
Validation loss: 2.375648825488583

Epoch: 6| Step: 7
Training loss: 0.6560096300511515
Validation loss: 2.3829339378232275

Epoch: 6| Step: 8
Training loss: 0.6681200045835131
Validation loss: 2.3991832716733716

Epoch: 6| Step: 9
Training loss: 0.586256779466809
Validation loss: 2.3966405064348577

Epoch: 6| Step: 10
Training loss: 0.4708012363864461
Validation loss: 2.37741556041657

Epoch: 6| Step: 11
Training loss: 0.4458343560067447
Validation loss: 2.4244942581635636

Epoch: 6| Step: 12
Training loss: 0.7452227316483794
Validation loss: 2.438067446682667

Epoch: 6| Step: 13
Training loss: 0.1511859855177815
Validation loss: 2.4873557216030857

Epoch: 364| Step: 0
Training loss: 0.730703346809542
Validation loss: 2.4757238921896514

Epoch: 6| Step: 1
Training loss: 0.7367797599764794
Validation loss: 2.4689065300262123

Epoch: 6| Step: 2
Training loss: 0.27262638223569646
Validation loss: 2.440039141761455

Epoch: 6| Step: 3
Training loss: 0.5715604740563679
Validation loss: 2.436013575473786

Epoch: 6| Step: 4
Training loss: 0.8405823055046875
Validation loss: 2.433783052857101

Epoch: 6| Step: 5
Training loss: 0.48322504189697474
Validation loss: 2.4155319822322214

Epoch: 6| Step: 6
Training loss: 0.5176983099977093
Validation loss: 2.4349058686140035

Epoch: 6| Step: 7
Training loss: 0.3739006498294416
Validation loss: 2.4121953429377023

Epoch: 6| Step: 8
Training loss: 0.4744699218329512
Validation loss: 2.432424043450204

Epoch: 6| Step: 9
Training loss: 1.5914455283499966
Validation loss: 2.407790031199706

Epoch: 6| Step: 10
Training loss: 0.6337298114277187
Validation loss: 2.4422286259842245

Epoch: 6| Step: 11
Training loss: 0.5130631643991053
Validation loss: 2.432672978267095

Epoch: 6| Step: 12
Training loss: 0.6972213431864039
Validation loss: 2.461294241767842

Epoch: 6| Step: 13
Training loss: 0.7475951102997476
Validation loss: 2.4126807511359694

Epoch: 365| Step: 0
Training loss: 0.43721121384914396
Validation loss: 2.3940733884875

Epoch: 6| Step: 1
Training loss: 0.428971439542389
Validation loss: 2.418123952246299

Epoch: 6| Step: 2
Training loss: 0.6136225825666412
Validation loss: 2.383727538027641

Epoch: 6| Step: 3
Training loss: 0.5757873286388343
Validation loss: 2.3595863611072527

Epoch: 6| Step: 4
Training loss: 0.6741108176962187
Validation loss: 2.3831265903345806

Epoch: 6| Step: 5
Training loss: 0.5309886289409936
Validation loss: 2.356265792256277

Epoch: 6| Step: 6
Training loss: 0.7090948770124172
Validation loss: 2.3856304605056957

Epoch: 6| Step: 7
Training loss: 0.36050465544288474
Validation loss: 2.4428176384897955

Epoch: 6| Step: 8
Training loss: 0.7022087060691233
Validation loss: 2.496687764288761

Epoch: 6| Step: 9
Training loss: 0.6832838391390826
Validation loss: 2.5071155294019403

Epoch: 6| Step: 10
Training loss: 0.3373854283731274
Validation loss: 2.5187895161022515

Epoch: 6| Step: 11
Training loss: 0.5939770314692008
Validation loss: 2.4987851113524773

Epoch: 6| Step: 12
Training loss: 0.7037182106914831
Validation loss: 2.459530170053574

Epoch: 6| Step: 13
Training loss: 2.1617284644280503
Validation loss: 2.4450438175351326

Epoch: 366| Step: 0
Training loss: 0.4186462900210349
Validation loss: 2.4182222117424574

Epoch: 6| Step: 1
Training loss: 0.31215959128267035
Validation loss: 2.4010281464438945

Epoch: 6| Step: 2
Training loss: 0.4938925923501957
Validation loss: 2.389628125886931

Epoch: 6| Step: 3
Training loss: 0.6998445065684401
Validation loss: 2.4225656477980344

Epoch: 6| Step: 4
Training loss: 0.8248749060147332
Validation loss: 2.4303793759421257

Epoch: 6| Step: 5
Training loss: 0.693189831273798
Validation loss: 2.4466676212114566

Epoch: 6| Step: 6
Training loss: 0.42212501817431536
Validation loss: 2.4734277123576223

Epoch: 6| Step: 7
Training loss: 1.5957687159006524
Validation loss: 2.4570116811517857

Epoch: 6| Step: 8
Training loss: 0.6920700981172963
Validation loss: 2.4638936083789527

Epoch: 6| Step: 9
Training loss: 0.6663651653831352
Validation loss: 2.433340521883436

Epoch: 6| Step: 10
Training loss: 0.8079988806924526
Validation loss: 2.403899772216441

Epoch: 6| Step: 11
Training loss: 0.4069060566911003
Validation loss: 2.4429144241170953

Epoch: 6| Step: 12
Training loss: 0.351689040404872
Validation loss: 2.4328258103831333

Epoch: 6| Step: 13
Training loss: 0.258464768388401
Validation loss: 2.457990699307046

Epoch: 367| Step: 0
Training loss: 0.5559801432919658
Validation loss: 2.462910558292613

Epoch: 6| Step: 1
Training loss: 0.6870267930102061
Validation loss: 2.4769387441214628

Epoch: 6| Step: 2
Training loss: 0.6229583773049618
Validation loss: 2.5131609545704143

Epoch: 6| Step: 3
Training loss: 0.6264448155258862
Validation loss: 2.4942772430600755

Epoch: 6| Step: 4
Training loss: 0.24240204322137937
Validation loss: 2.4839067957597694

Epoch: 6| Step: 5
Training loss: 0.6083615752636321
Validation loss: 2.5076127697139547

Epoch: 6| Step: 6
Training loss: 1.5795432789939134
Validation loss: 2.492846762014682

Epoch: 6| Step: 7
Training loss: 0.3870280406512372
Validation loss: 2.533304936765812

Epoch: 6| Step: 8
Training loss: 0.5426639277571059
Validation loss: 2.5061049133699353

Epoch: 6| Step: 9
Training loss: 0.6970224036429468
Validation loss: 2.4471419142352135

Epoch: 6| Step: 10
Training loss: 0.6136384154776746
Validation loss: 2.461642516015043

Epoch: 6| Step: 11
Training loss: 0.5474543091681999
Validation loss: 2.4553053136947955

Epoch: 6| Step: 12
Training loss: 0.5039400488585439
Validation loss: 2.4843897417605874

Epoch: 6| Step: 13
Training loss: 0.5840589800994436
Validation loss: 2.463048798263931

Epoch: 368| Step: 0
Training loss: 0.5472051986019355
Validation loss: 2.4250824879473347

Epoch: 6| Step: 1
Training loss: 0.43614528585210854
Validation loss: 2.4293725554436016

Epoch: 6| Step: 2
Training loss: 0.6480973512054782
Validation loss: 2.420292931742289

Epoch: 6| Step: 3
Training loss: 0.35358508360285157
Validation loss: 2.417593473202412

Epoch: 6| Step: 4
Training loss: 0.6424570172400695
Validation loss: 2.3778883399357804

Epoch: 6| Step: 5
Training loss: 0.540803172128166
Validation loss: 2.3751607537174597

Epoch: 6| Step: 6
Training loss: 1.6481352614892337
Validation loss: 2.342202151421388

Epoch: 6| Step: 7
Training loss: 0.6567233512911452
Validation loss: 2.375261292119455

Epoch: 6| Step: 8
Training loss: 0.30493008908685665
Validation loss: 2.366300335620714

Epoch: 6| Step: 9
Training loss: 0.39996877637830736
Validation loss: 2.3465753535970575

Epoch: 6| Step: 10
Training loss: 0.8051600133717978
Validation loss: 2.4026916966914396

Epoch: 6| Step: 11
Training loss: 0.814194782367706
Validation loss: 2.4070125032793053

Epoch: 6| Step: 12
Training loss: 0.33055760471904716
Validation loss: 2.4156674882083187

Epoch: 6| Step: 13
Training loss: 0.3095183825333674
Validation loss: 2.4564076559013874

Epoch: 369| Step: 0
Training loss: 0.4964733323640734
Validation loss: 2.436412198332533

Epoch: 6| Step: 1
Training loss: 0.7358661689934716
Validation loss: 2.445347614515192

Epoch: 6| Step: 2
Training loss: 0.6501221890409842
Validation loss: 2.424946944596511

Epoch: 6| Step: 3
Training loss: 0.36820522250284854
Validation loss: 2.4321474109525463

Epoch: 6| Step: 4
Training loss: 1.6198747946780794
Validation loss: 2.421643457581474

Epoch: 6| Step: 5
Training loss: 0.6481070998100925
Validation loss: 2.4510073195527933

Epoch: 6| Step: 6
Training loss: 0.4241250048726489
Validation loss: 2.4659492490643085

Epoch: 6| Step: 7
Training loss: 0.6685462373850884
Validation loss: 2.4526028860955513

Epoch: 6| Step: 8
Training loss: 0.35284211086020506
Validation loss: 2.4317715509391244

Epoch: 6| Step: 9
Training loss: 0.648505793272802
Validation loss: 2.462526792725396

Epoch: 6| Step: 10
Training loss: 0.5540384605601643
Validation loss: 2.4236777511982983

Epoch: 6| Step: 11
Training loss: 0.4254260375080234
Validation loss: 2.402173358814873

Epoch: 6| Step: 12
Training loss: 0.44318130883274287
Validation loss: 2.3759778410956662

Epoch: 6| Step: 13
Training loss: 0.4895708829906417
Validation loss: 2.380152725220337

Epoch: 370| Step: 0
Training loss: 0.556091090874184
Validation loss: 2.382775660216095

Epoch: 6| Step: 1
Training loss: 0.42887458197968853
Validation loss: 2.3903405641408466

Epoch: 6| Step: 2
Training loss: 0.7097288904252139
Validation loss: 2.395343219620108

Epoch: 6| Step: 3
Training loss: 1.5279776972196564
Validation loss: 2.402059226832995

Epoch: 6| Step: 4
Training loss: 0.764173494167743
Validation loss: 2.422070338495535

Epoch: 6| Step: 5
Training loss: 0.7484604610990572
Validation loss: 2.4625735525778705

Epoch: 6| Step: 6
Training loss: 0.36962316148292307
Validation loss: 2.4348522716497225

Epoch: 6| Step: 7
Training loss: 0.5622412563320875
Validation loss: 2.414482091119501

Epoch: 6| Step: 8
Training loss: 0.5301144468700313
Validation loss: 2.3805640457406585

Epoch: 6| Step: 9
Training loss: 0.46637341113754116
Validation loss: 2.371207449052504

Epoch: 6| Step: 10
Training loss: 0.4032171085019444
Validation loss: 2.3772138511451537

Epoch: 6| Step: 11
Training loss: 0.5822065972530011
Validation loss: 2.4032630872095617

Epoch: 6| Step: 12
Training loss: 0.4914753469578775
Validation loss: 2.41080299696454

Epoch: 6| Step: 13
Training loss: 0.20735720400363267
Validation loss: 2.395656730773648

Epoch: 371| Step: 0
Training loss: 0.46737548847892235
Validation loss: 2.4116132054766317

Epoch: 6| Step: 1
Training loss: 0.6248318445970259
Validation loss: 2.384694306869298

Epoch: 6| Step: 2
Training loss: 0.24228057303469996
Validation loss: 2.3976500191312518

Epoch: 6| Step: 3
Training loss: 0.7611795717931064
Validation loss: 2.4035734572077594

Epoch: 6| Step: 4
Training loss: 0.3709018010071826
Validation loss: 2.4321816361912703

Epoch: 6| Step: 5
Training loss: 0.6418109708829646
Validation loss: 2.388342334654298

Epoch: 6| Step: 6
Training loss: 0.47941256170815744
Validation loss: 2.3835287124896976

Epoch: 6| Step: 7
Training loss: 0.47521397263546356
Validation loss: 2.4033905435184644

Epoch: 6| Step: 8
Training loss: 0.5796521610480005
Validation loss: 2.3879712484189954

Epoch: 6| Step: 9
Training loss: 0.3416130334445097
Validation loss: 2.3759476002356283

Epoch: 6| Step: 10
Training loss: 0.4671996545645828
Validation loss: 2.3773578398983695

Epoch: 6| Step: 11
Training loss: 1.5760909465070145
Validation loss: 2.370584865282117

Epoch: 6| Step: 12
Training loss: 0.6058363506140557
Validation loss: 2.367209850644239

Epoch: 6| Step: 13
Training loss: 0.38647956387108706
Validation loss: 2.345008726482674

Epoch: 372| Step: 0
Training loss: 0.5526183313201652
Validation loss: 2.3658984644525396

Epoch: 6| Step: 1
Training loss: 1.493424467104558
Validation loss: 2.3710816242444306

Epoch: 6| Step: 2
Training loss: 0.19069774052802166
Validation loss: 2.3837812267746568

Epoch: 6| Step: 3
Training loss: 0.38977450288994486
Validation loss: 2.39574845115955

Epoch: 6| Step: 4
Training loss: 0.5174584016343996
Validation loss: 2.4062270179506555

Epoch: 6| Step: 5
Training loss: 0.6540718716580158
Validation loss: 2.412917529910922

Epoch: 6| Step: 6
Training loss: 0.46748266560245705
Validation loss: 2.4108892624380402

Epoch: 6| Step: 7
Training loss: 0.5402768596237126
Validation loss: 2.3944748582753834

Epoch: 6| Step: 8
Training loss: 0.573761297168752
Validation loss: 2.3975837312673143

Epoch: 6| Step: 9
Training loss: 0.6483555707533775
Validation loss: 2.409058906525753

Epoch: 6| Step: 10
Training loss: 0.3234685698619183
Validation loss: 2.368540215413472

Epoch: 6| Step: 11
Training loss: 0.517780250092954
Validation loss: 2.336739595856253

Epoch: 6| Step: 12
Training loss: 0.6634811549439051
Validation loss: 2.3591641209130194

Epoch: 6| Step: 13
Training loss: 0.540909739574804
Validation loss: 2.3735578710542287

Epoch: 373| Step: 0
Training loss: 0.4102089802588532
Validation loss: 2.3705832717826385

Epoch: 6| Step: 1
Training loss: 0.5292386519161917
Validation loss: 2.361952247325583

Epoch: 6| Step: 2
Training loss: 0.5560340387110095
Validation loss: 2.3849098920010827

Epoch: 6| Step: 3
Training loss: 0.44397039783123915
Validation loss: 2.406938186761809

Epoch: 6| Step: 4
Training loss: 0.42157759603359235
Validation loss: 2.4042579684584076

Epoch: 6| Step: 5
Training loss: 0.736552884634293
Validation loss: 2.429975173633813

Epoch: 6| Step: 6
Training loss: 0.7209633044852818
Validation loss: 2.488025067086339

Epoch: 6| Step: 7
Training loss: 0.5315102332521527
Validation loss: 2.464326804994324

Epoch: 6| Step: 8
Training loss: 0.3788927213475618
Validation loss: 2.4926270740085097

Epoch: 6| Step: 9
Training loss: 0.6470333200480095
Validation loss: 2.4491001822751457

Epoch: 6| Step: 10
Training loss: 0.45160624414305095
Validation loss: 2.446959540181065

Epoch: 6| Step: 11
Training loss: 0.2167445110970213
Validation loss: 2.4143177331223122

Epoch: 6| Step: 12
Training loss: 0.5731947715164105
Validation loss: 2.373681119420037

Epoch: 6| Step: 13
Training loss: 1.9528387241369969
Validation loss: 2.3476999874687587

Epoch: 374| Step: 0
Training loss: 0.5077144234654264
Validation loss: 2.342319020508362

Epoch: 6| Step: 1
Training loss: 0.28479036608308084
Validation loss: 2.333838927922311

Epoch: 6| Step: 2
Training loss: 0.5437177801999997
Validation loss: 2.350004915301232

Epoch: 6| Step: 3
Training loss: 0.6333496263148319
Validation loss: 2.3457395694150853

Epoch: 6| Step: 4
Training loss: 0.7692557679295748
Validation loss: 2.3804876585870587

Epoch: 6| Step: 5
Training loss: 0.6814612559768325
Validation loss: 2.3865628492415056

Epoch: 6| Step: 6
Training loss: 0.6427480594675452
Validation loss: 2.379264672663683

Epoch: 6| Step: 7
Training loss: 0.41988873018265865
Validation loss: 2.3739213841948015

Epoch: 6| Step: 8
Training loss: 1.4224811142403555
Validation loss: 2.3972692653057823

Epoch: 6| Step: 9
Training loss: 0.6934893419124705
Validation loss: 2.3921149137319953

Epoch: 6| Step: 10
Training loss: 0.23763243095020425
Validation loss: 2.405913591141382

Epoch: 6| Step: 11
Training loss: 0.4685282977656225
Validation loss: 2.3720448593655714

Epoch: 6| Step: 12
Training loss: 0.44740264992485507
Validation loss: 2.3938257809922385

Epoch: 6| Step: 13
Training loss: 0.21352011680414565
Validation loss: 2.4085679957124215

Epoch: 375| Step: 0
Training loss: 0.3659303531225724
Validation loss: 2.378107326577133

Epoch: 6| Step: 1
Training loss: 0.42352347257795925
Validation loss: 2.355838828802924

Epoch: 6| Step: 2
Training loss: 0.33850645713620214
Validation loss: 2.3810728132352654

Epoch: 6| Step: 3
Training loss: 0.6093051087818122
Validation loss: 2.3996936816251284

Epoch: 6| Step: 4
Training loss: 1.5725617503063627
Validation loss: 2.3892842977726225

Epoch: 6| Step: 5
Training loss: 0.49813186817866717
Validation loss: 2.362911224754178

Epoch: 6| Step: 6
Training loss: 0.5834812306063316
Validation loss: 2.423972425618993

Epoch: 6| Step: 7
Training loss: 0.49729929148540886
Validation loss: 2.416596404918796

Epoch: 6| Step: 8
Training loss: 0.4495472411863921
Validation loss: 2.407532472581128

Epoch: 6| Step: 9
Training loss: 0.7581253192646207
Validation loss: 2.4405725601090036

Epoch: 6| Step: 10
Training loss: 0.5819841916306782
Validation loss: 2.4619580183123078

Epoch: 6| Step: 11
Training loss: 0.3775946933829581
Validation loss: 2.466972696792342

Epoch: 6| Step: 12
Training loss: 0.27996333175919186
Validation loss: 2.4095124213280763

Epoch: 6| Step: 13
Training loss: 0.7761810655438517
Validation loss: 2.4092143826709234

Epoch: 376| Step: 0
Training loss: 0.4853337551357896
Validation loss: 2.3846452904759086

Epoch: 6| Step: 1
Training loss: 0.6518918373735025
Validation loss: 2.4036477780331182

Epoch: 6| Step: 2
Training loss: 0.43559494095457574
Validation loss: 2.389349621700674

Epoch: 6| Step: 3
Training loss: 0.3714830264158269
Validation loss: 2.4075605437706993

Epoch: 6| Step: 4
Training loss: 0.4472539975183311
Validation loss: 2.408886100914336

Epoch: 6| Step: 5
Training loss: 1.381037073423618
Validation loss: 2.389124974018281

Epoch: 6| Step: 6
Training loss: 0.7540864877248752
Validation loss: 2.4295176874787683

Epoch: 6| Step: 7
Training loss: 0.5768680310887455
Validation loss: 2.4125254590646787

Epoch: 6| Step: 8
Training loss: 0.5848079474963903
Validation loss: 2.3930121834091023

Epoch: 6| Step: 9
Training loss: 0.4968384987241512
Validation loss: 2.4147803411472855

Epoch: 6| Step: 10
Training loss: 0.228523792218709
Validation loss: 2.3740791895394007

Epoch: 6| Step: 11
Training loss: 0.5380754140942946
Validation loss: 2.3819685333165017

Epoch: 6| Step: 12
Training loss: 0.31793662243994364
Validation loss: 2.3924324344546295

Epoch: 6| Step: 13
Training loss: 0.9962343602885352
Validation loss: 2.3905549108472055

Epoch: 377| Step: 0
Training loss: 0.5653684645533752
Validation loss: 2.384643903108481

Epoch: 6| Step: 1
Training loss: 1.466739577229543
Validation loss: 2.395311536496361

Epoch: 6| Step: 2
Training loss: 0.49664930339946034
Validation loss: 2.4063143775488025

Epoch: 6| Step: 3
Training loss: 0.42229042086286545
Validation loss: 2.4022550240856253

Epoch: 6| Step: 4
Training loss: 0.5367607511164135
Validation loss: 2.427135874854517

Epoch: 6| Step: 5
Training loss: 0.42691452675563
Validation loss: 2.416669398622026

Epoch: 6| Step: 6
Training loss: 0.4157881495416881
Validation loss: 2.3995487340065424

Epoch: 6| Step: 7
Training loss: 0.7829868845760776
Validation loss: 2.4138221821550654

Epoch: 6| Step: 8
Training loss: 0.5218311542663271
Validation loss: 2.398594479054757

Epoch: 6| Step: 9
Training loss: 0.5195158188901642
Validation loss: 2.3851967392399733

Epoch: 6| Step: 10
Training loss: 0.5116460035026542
Validation loss: 2.3962494772755165

Epoch: 6| Step: 11
Training loss: 0.6065823558326612
Validation loss: 2.3975803213944102

Epoch: 6| Step: 12
Training loss: 0.2164292698539326
Validation loss: 2.4023794808320478

Epoch: 6| Step: 13
Training loss: 0.5173824012210373
Validation loss: 2.400936637362393

Epoch: 378| Step: 0
Training loss: 0.4008007647130147
Validation loss: 2.4023797529490594

Epoch: 6| Step: 1
Training loss: 0.3380731409428958
Validation loss: 2.387126105006944

Epoch: 6| Step: 2
Training loss: 1.4384729990037752
Validation loss: 2.345007186117045

Epoch: 6| Step: 3
Training loss: 0.5746303821616209
Validation loss: 2.378846678631257

Epoch: 6| Step: 4
Training loss: 0.6918202254642601
Validation loss: 2.387817268571187

Epoch: 6| Step: 5
Training loss: 0.47093166643869594
Validation loss: 2.3802422664037755

Epoch: 6| Step: 6
Training loss: 0.6823343938208338
Validation loss: 2.4054041658221683

Epoch: 6| Step: 7
Training loss: 0.5646503988130985
Validation loss: 2.410773328006129

Epoch: 6| Step: 8
Training loss: 0.4635392163958421
Validation loss: 2.4158213430835644

Epoch: 6| Step: 9
Training loss: 0.348972571732521
Validation loss: 2.4294920875287715

Epoch: 6| Step: 10
Training loss: 0.3317350300384475
Validation loss: 2.4330824985531847

Epoch: 6| Step: 11
Training loss: 0.5183078444163827
Validation loss: 2.408491814433884

Epoch: 6| Step: 12
Training loss: 0.38986345443924314
Validation loss: 2.387661251104744

Epoch: 6| Step: 13
Training loss: 0.7152986173669995
Validation loss: 2.364825214979358

Epoch: 379| Step: 0
Training loss: 0.4179502821790717
Validation loss: 2.3757380335662837

Epoch: 6| Step: 1
Training loss: 0.6547194297852182
Validation loss: 2.3389724373794847

Epoch: 6| Step: 2
Training loss: 1.4174218502401061
Validation loss: 2.328184620364379

Epoch: 6| Step: 3
Training loss: 0.25470740761212435
Validation loss: 2.3499869924223256

Epoch: 6| Step: 4
Training loss: 0.5238563797376118
Validation loss: 2.3477044405575915

Epoch: 6| Step: 5
Training loss: 0.38271326608374023
Validation loss: 2.3671806473702017

Epoch: 6| Step: 6
Training loss: 0.6407202673066461
Validation loss: 2.4023976571135655

Epoch: 6| Step: 7
Training loss: 0.3495695421766881
Validation loss: 2.385690868835614

Epoch: 6| Step: 8
Training loss: 0.5399033719164
Validation loss: 2.438413156035778

Epoch: 6| Step: 9
Training loss: 0.5526332156078224
Validation loss: 2.441474911878902

Epoch: 6| Step: 10
Training loss: 0.5619622680225747
Validation loss: 2.4685627232967264

Epoch: 6| Step: 11
Training loss: 0.44956737756330445
Validation loss: 2.427463856745228

Epoch: 6| Step: 12
Training loss: 0.39952973647086415
Validation loss: 2.42464831474291

Epoch: 6| Step: 13
Training loss: 0.8211650596018631
Validation loss: 2.37182479308718

Epoch: 380| Step: 0
Training loss: 0.40550464331605995
Validation loss: 2.384754240644721

Epoch: 6| Step: 1
Training loss: 0.5365950462677107
Validation loss: 2.4107858602612398

Epoch: 6| Step: 2
Training loss: 0.508240797917439
Validation loss: 2.421938657370594

Epoch: 6| Step: 3
Training loss: 0.3627967064152812
Validation loss: 2.385204302150167

Epoch: 6| Step: 4
Training loss: 0.32117105189287315
Validation loss: 2.3640337582696134

Epoch: 6| Step: 5
Training loss: 0.4500996783909033
Validation loss: 2.3684178155068434

Epoch: 6| Step: 6
Training loss: 1.479867697421201
Validation loss: 2.398064266343601

Epoch: 6| Step: 7
Training loss: 0.3011675001883007
Validation loss: 2.413055078033068

Epoch: 6| Step: 8
Training loss: 0.5636360035437891
Validation loss: 2.445661869807614

Epoch: 6| Step: 9
Training loss: 0.6199017007642277
Validation loss: 2.382459071842452

Epoch: 6| Step: 10
Training loss: 0.3586511786191159
Validation loss: 2.4155160826179576

Epoch: 6| Step: 11
Training loss: 0.567274992738979
Validation loss: 2.3673603454081067

Epoch: 6| Step: 12
Training loss: 0.4903775800082335
Validation loss: 2.341561565800161

Epoch: 6| Step: 13
Training loss: 0.7561599567497627
Validation loss: 2.3117418384990738

Epoch: 381| Step: 0
Training loss: 0.5049280555862692
Validation loss: 2.2862461819597772

Epoch: 6| Step: 1
Training loss: 0.26864059461377016
Validation loss: 2.326683385978563

Epoch: 6| Step: 2
Training loss: 0.5076411031363652
Validation loss: 2.354617554172788

Epoch: 6| Step: 3
Training loss: 0.5255058757769262
Validation loss: 2.2809843953013136

Epoch: 6| Step: 4
Training loss: 0.41414896943847107
Validation loss: 2.3413885250560247

Epoch: 6| Step: 5
Training loss: 0.5657181868532184
Validation loss: 2.344376291253722

Epoch: 6| Step: 6
Training loss: 0.6182934232472141
Validation loss: 2.380806233598212

Epoch: 6| Step: 7
Training loss: 0.4038355494292903
Validation loss: 2.4067407732676025

Epoch: 6| Step: 8
Training loss: 0.5950547488853357
Validation loss: 2.441304180284022

Epoch: 6| Step: 9
Training loss: 0.42763023327990246
Validation loss: 2.4157773850928375

Epoch: 6| Step: 10
Training loss: 0.4864522476823078
Validation loss: 2.4173640958725695

Epoch: 6| Step: 11
Training loss: 1.4058066622938867
Validation loss: 2.39242481349072

Epoch: 6| Step: 12
Training loss: 0.4265372188468252
Validation loss: 2.39393096842079

Epoch: 6| Step: 13
Training loss: 0.6702476799130436
Validation loss: 2.3658846075888804

Epoch: 382| Step: 0
Training loss: 0.5239056728233573
Validation loss: 2.409627887659999

Epoch: 6| Step: 1
Training loss: 0.16875889586913323
Validation loss: 2.3793526397074793

Epoch: 6| Step: 2
Training loss: 0.47203982171487074
Validation loss: 2.3414038375070203

Epoch: 6| Step: 3
Training loss: 1.330404636453313
Validation loss: 2.3280511340442294

Epoch: 6| Step: 4
Training loss: 0.6434624798350521
Validation loss: 2.351194245564375

Epoch: 6| Step: 5
Training loss: 0.3926157387701133
Validation loss: 2.3659624999226336

Epoch: 6| Step: 6
Training loss: 0.5461308457159283
Validation loss: 2.4047199291350774

Epoch: 6| Step: 7
Training loss: 0.49682731159651217
Validation loss: 2.371961260687021

Epoch: 6| Step: 8
Training loss: 0.7725133673119376
Validation loss: 2.375290702295228

Epoch: 6| Step: 9
Training loss: 0.500225314395319
Validation loss: 2.3416143043069595

Epoch: 6| Step: 10
Training loss: 0.6451793533294212
Validation loss: 2.3569443777436607

Epoch: 6| Step: 11
Training loss: 0.4864788204946241
Validation loss: 2.291271625004083

Epoch: 6| Step: 12
Training loss: 0.48373801894223056
Validation loss: 2.281282083912528

Epoch: 6| Step: 13
Training loss: 0.488134774172486
Validation loss: 2.2705685631560044

Epoch: 383| Step: 0
Training loss: 0.6069776867342805
Validation loss: 2.2877797639386266

Epoch: 6| Step: 1
Training loss: 0.4559086437127202
Validation loss: 2.28093507722292

Epoch: 6| Step: 2
Training loss: 0.5738875802999576
Validation loss: 2.293239550053127

Epoch: 6| Step: 3
Training loss: 0.6697338941544915
Validation loss: 2.321722933399947

Epoch: 6| Step: 4
Training loss: 0.561862531360275
Validation loss: 2.330068976502573

Epoch: 6| Step: 5
Training loss: 0.29361565693427255
Validation loss: 2.343242202494708

Epoch: 6| Step: 6
Training loss: 0.33995582661758666
Validation loss: 2.3624993868530404

Epoch: 6| Step: 7
Training loss: 0.6809826054893285
Validation loss: 2.379721385584281

Epoch: 6| Step: 8
Training loss: 0.6694395592310332
Validation loss: 2.3707831235150407

Epoch: 6| Step: 9
Training loss: 0.5316834364561223
Validation loss: 2.3769458289307495

Epoch: 6| Step: 10
Training loss: 0.4192635454606729
Validation loss: 2.3589652947896367

Epoch: 6| Step: 11
Training loss: 1.2487917782932576
Validation loss: 2.3571057874956205

Epoch: 6| Step: 12
Training loss: 0.4624460233946116
Validation loss: 2.349333085735959

Epoch: 6| Step: 13
Training loss: 0.3954041521780552
Validation loss: 2.359976447557793

Epoch: 384| Step: 0
Training loss: 0.46511041381445173
Validation loss: 2.3798147844513795

Epoch: 6| Step: 1
Training loss: 0.45634039806338406
Validation loss: 2.3366567171411106

Epoch: 6| Step: 2
Training loss: 1.2491876346608866
Validation loss: 2.424948796536315

Epoch: 6| Step: 3
Training loss: 0.6382479412674713
Validation loss: 2.4829826722952673

Epoch: 6| Step: 4
Training loss: 0.7294873259151299
Validation loss: 2.4902693703026437

Epoch: 6| Step: 5
Training loss: 0.692840080830662
Validation loss: 2.401910896032716

Epoch: 6| Step: 6
Training loss: 0.7621489263817159
Validation loss: 2.3802386453579287

Epoch: 6| Step: 7
Training loss: 0.5305680778894152
Validation loss: 2.3743804210910002

Epoch: 6| Step: 8
Training loss: 0.6011703996844714
Validation loss: 2.3006833367266597

Epoch: 6| Step: 9
Training loss: 0.6766325158942623
Validation loss: 2.2718315512033334

Epoch: 6| Step: 10
Training loss: 0.5323225862166251
Validation loss: 2.275672065039135

Epoch: 6| Step: 11
Training loss: 0.4487960485246171
Validation loss: 2.2516721171563474

Epoch: 6| Step: 12
Training loss: 0.5407349998273642
Validation loss: 2.263289309940129

Epoch: 6| Step: 13
Training loss: 0.3876008656187007
Validation loss: 2.275432419994916

Epoch: 385| Step: 0
Training loss: 0.5735953963341047
Validation loss: 2.333809125824355

Epoch: 6| Step: 1
Training loss: 0.5961664617945307
Validation loss: 2.4170268341660486

Epoch: 6| Step: 2
Training loss: 0.5144114229046343
Validation loss: 2.4188974845818754

Epoch: 6| Step: 3
Training loss: 0.5980373239782346
Validation loss: 2.430917724448621

Epoch: 6| Step: 4
Training loss: 0.5131601605931604
Validation loss: 2.3875398319965315

Epoch: 6| Step: 5
Training loss: 1.1388360194725344
Validation loss: 2.364256167567634

Epoch: 6| Step: 6
Training loss: 0.49643171617927195
Validation loss: 2.3632253169877706

Epoch: 6| Step: 7
Training loss: 0.6104247270600917
Validation loss: 2.3097324400718358

Epoch: 6| Step: 8
Training loss: 0.45947703441516313
Validation loss: 2.3804507332840052

Epoch: 6| Step: 9
Training loss: 0.7318156670969271
Validation loss: 2.3578498766423435

Epoch: 6| Step: 10
Training loss: 0.5729854340174859
Validation loss: 2.3658081853326727

Epoch: 6| Step: 11
Training loss: 0.672120204804143
Validation loss: 2.380528177543689

Epoch: 6| Step: 12
Training loss: 0.3639316069767698
Validation loss: 2.3766257383945595

Epoch: 6| Step: 13
Training loss: 0.688046476611562
Validation loss: 2.407476019343914

Epoch: 386| Step: 0
Training loss: 0.37762793981322645
Validation loss: 2.3455471693164394

Epoch: 6| Step: 1
Training loss: 0.4755253684700518
Validation loss: 2.3372948618442395

Epoch: 6| Step: 2
Training loss: 0.4581406000247323
Validation loss: 2.3420833084156034

Epoch: 6| Step: 3
Training loss: 0.5810787420342637
Validation loss: 2.316356184229059

Epoch: 6| Step: 4
Training loss: 0.5006357561877575
Validation loss: 2.324899725814145

Epoch: 6| Step: 5
Training loss: 0.33618090926612304
Validation loss: 2.350108434522616

Epoch: 6| Step: 6
Training loss: 0.750435821744825
Validation loss: 2.34613857940759

Epoch: 6| Step: 7
Training loss: 1.2071435376130715
Validation loss: 2.380931656471859

Epoch: 6| Step: 8
Training loss: 0.5466895742772805
Validation loss: 2.3656033254021605

Epoch: 6| Step: 9
Training loss: 0.5868961883717537
Validation loss: 2.4181839098421656

Epoch: 6| Step: 10
Training loss: 0.7263187696952622
Validation loss: 2.3554870972626

Epoch: 6| Step: 11
Training loss: 0.5148199617160727
Validation loss: 2.349811616615402

Epoch: 6| Step: 12
Training loss: 0.3537915243842555
Validation loss: 2.347223668944359

Epoch: 6| Step: 13
Training loss: 0.3661481269377511
Validation loss: 2.304187099776593

Epoch: 387| Step: 0
Training loss: 0.37396596362406054
Validation loss: 2.3456204996057393

Epoch: 6| Step: 1
Training loss: 0.45243230028743947
Validation loss: 2.314586223837037

Epoch: 6| Step: 2
Training loss: 0.6918153576183171
Validation loss: 2.309877221423873

Epoch: 6| Step: 3
Training loss: 0.6753259790038293
Validation loss: 2.328069220017355

Epoch: 6| Step: 4
Training loss: 0.4937638365339936
Validation loss: 2.3394577406711305

Epoch: 6| Step: 5
Training loss: 0.48596588493436227
Validation loss: 2.410261309742112

Epoch: 6| Step: 6
Training loss: 0.5908865142807588
Validation loss: 2.354621769892507

Epoch: 6| Step: 7
Training loss: 0.4557428376100075
Validation loss: 2.361833768549183

Epoch: 6| Step: 8
Training loss: 0.3939980974139348
Validation loss: 2.399016200634165

Epoch: 6| Step: 9
Training loss: 1.124090780963462
Validation loss: 2.426368065767835

Epoch: 6| Step: 10
Training loss: 0.5966626553516059
Validation loss: 2.4475000456756435

Epoch: 6| Step: 11
Training loss: 0.5493812895708831
Validation loss: 2.441537879726086

Epoch: 6| Step: 12
Training loss: 0.49053751171524107
Validation loss: 2.4138170258147715

Epoch: 6| Step: 13
Training loss: 0.5201505540723269
Validation loss: 2.3873692894698975

Epoch: 388| Step: 0
Training loss: 1.1777432316436007
Validation loss: 2.411170015915401

Epoch: 6| Step: 1
Training loss: 0.5571512122540816
Validation loss: 2.405621382989438

Epoch: 6| Step: 2
Training loss: 0.4074817470838945
Validation loss: 2.344786347998522

Epoch: 6| Step: 3
Training loss: 0.3066109806966054
Validation loss: 2.3234895326924407

Epoch: 6| Step: 4
Training loss: 0.3224700510549781
Validation loss: 2.3508795364898

Epoch: 6| Step: 5
Training loss: 0.7424548821918098
Validation loss: 2.3585409602500462

Epoch: 6| Step: 6
Training loss: 0.4242572457847396
Validation loss: 2.367194242686781

Epoch: 6| Step: 7
Training loss: 0.6257134656829213
Validation loss: 2.3288000019809827

Epoch: 6| Step: 8
Training loss: 0.33575301316557377
Validation loss: 2.3469152296121543

Epoch: 6| Step: 9
Training loss: 0.4849967657551633
Validation loss: 2.351244164294687

Epoch: 6| Step: 10
Training loss: 0.602423262635964
Validation loss: 2.3704956465875857

Epoch: 6| Step: 11
Training loss: 0.4527442582164982
Validation loss: 2.3346614251579045

Epoch: 6| Step: 12
Training loss: 0.3837886742354509
Validation loss: 2.324066222733761

Epoch: 6| Step: 13
Training loss: 0.5611193720704654
Validation loss: 2.33730536626608

Epoch: 389| Step: 0
Training loss: 0.5258480194003717
Validation loss: 2.3392250543734265

Epoch: 6| Step: 1
Training loss: 0.5033868878128123
Validation loss: 2.3090520739417575

Epoch: 6| Step: 2
Training loss: 0.5734622149637406
Validation loss: 2.3209849460760057

Epoch: 6| Step: 3
Training loss: 0.5019507797720778
Validation loss: 2.2825439515501977

Epoch: 6| Step: 4
Training loss: 0.45471304464519685
Validation loss: 2.3321572711492227

Epoch: 6| Step: 5
Training loss: 0.5637248267497511
Validation loss: 2.3123911671525015

Epoch: 6| Step: 6
Training loss: 0.3996489191112985
Validation loss: 2.3023875973709145

Epoch: 6| Step: 7
Training loss: 0.35043340143317797
Validation loss: 2.3409238647093793

Epoch: 6| Step: 8
Training loss: 1.1214587318627103
Validation loss: 2.332487274487974

Epoch: 6| Step: 9
Training loss: 0.4954694288736948
Validation loss: 2.366003834858702

Epoch: 6| Step: 10
Training loss: 0.4108065400114201
Validation loss: 2.3418270719005587

Epoch: 6| Step: 11
Training loss: 0.4156262003372183
Validation loss: 2.3596260715744397

Epoch: 6| Step: 12
Training loss: 0.21824883203204873
Validation loss: 2.35766314539063

Epoch: 6| Step: 13
Training loss: 0.6415371564940415
Validation loss: 2.3543921350057864

Epoch: 390| Step: 0
Training loss: 0.38673192782057586
Validation loss: 2.3511818743435673

Epoch: 6| Step: 1
Training loss: 0.7551661424799896
Validation loss: 2.3088267263472266

Epoch: 6| Step: 2
Training loss: 0.46053683113878097
Validation loss: 2.3098136000354175

Epoch: 6| Step: 3
Training loss: 0.47784532582686345
Validation loss: 2.3364117292896123

Epoch: 6| Step: 4
Training loss: 0.38928886783517436
Validation loss: 2.3284410742647084

Epoch: 6| Step: 5
Training loss: 0.30725335297178924
Validation loss: 2.3255987418997544

Epoch: 6| Step: 6
Training loss: 0.37102981819770403
Validation loss: 2.362960323115809

Epoch: 6| Step: 7
Training loss: 0.4976852300760543
Validation loss: 2.337742621808241

Epoch: 6| Step: 8
Training loss: 1.0291753765978313
Validation loss: 2.3860670328807316

Epoch: 6| Step: 9
Training loss: 0.2854058336141914
Validation loss: 2.406482290586891

Epoch: 6| Step: 10
Training loss: 0.22421136504980915
Validation loss: 2.419418024413864

Epoch: 6| Step: 11
Training loss: 0.5634852628515514
Validation loss: 2.412694712194364

Epoch: 6| Step: 12
Training loss: 0.5863904092683553
Validation loss: 2.3756402852160305

Epoch: 6| Step: 13
Training loss: 0.58840759967153
Validation loss: 2.381655418337687

Epoch: 391| Step: 0
Training loss: 0.4558569011604764
Validation loss: 2.338850174814871

Epoch: 6| Step: 1
Training loss: 1.0550550597408543
Validation loss: 2.3132663444767516

Epoch: 6| Step: 2
Training loss: 0.5014041912242244
Validation loss: 2.3447853978888604

Epoch: 6| Step: 3
Training loss: 0.29120860006109406
Validation loss: 2.301712298742596

Epoch: 6| Step: 4
Training loss: 0.7982571153619316
Validation loss: 2.3320937958778067

Epoch: 6| Step: 5
Training loss: 0.5108582344748329
Validation loss: 2.359975557878543

Epoch: 6| Step: 6
Training loss: 0.40955843273828657
Validation loss: 2.3676318080593655

Epoch: 6| Step: 7
Training loss: 0.4611506211858274
Validation loss: 2.381174436767779

Epoch: 6| Step: 8
Training loss: 0.6508725188185857
Validation loss: 2.3762834499615826

Epoch: 6| Step: 9
Training loss: 0.36679791012618934
Validation loss: 2.400766340656685

Epoch: 6| Step: 10
Training loss: 0.4382741414137933
Validation loss: 2.4355600060676235

Epoch: 6| Step: 11
Training loss: 0.15908252933768458
Validation loss: 2.3956620546156766

Epoch: 6| Step: 12
Training loss: 0.48351904395271184
Validation loss: 2.387301612209161

Epoch: 6| Step: 13
Training loss: 0.4049976743525383
Validation loss: 2.4034786867292603

Epoch: 392| Step: 0
Training loss: 0.3522681254494646
Validation loss: 2.371572072670187

Epoch: 6| Step: 1
Training loss: 0.29365630532508064
Validation loss: 2.3902620354617605

Epoch: 6| Step: 2
Training loss: 0.567232331955303
Validation loss: 2.3956433767065795

Epoch: 6| Step: 3
Training loss: 0.49117463965568503
Validation loss: 2.3968146548592495

Epoch: 6| Step: 4
Training loss: 0.482284588140472
Validation loss: 2.3799902836115354

Epoch: 6| Step: 5
Training loss: 0.38242041691783646
Validation loss: 2.425192188638965

Epoch: 6| Step: 6
Training loss: 0.511249035458949
Validation loss: 2.454772642530846

Epoch: 6| Step: 7
Training loss: 0.4254942285289743
Validation loss: 2.436673194787066

Epoch: 6| Step: 8
Training loss: 0.5166875699131938
Validation loss: 2.486890171191553

Epoch: 6| Step: 9
Training loss: 0.5918478109767374
Validation loss: 2.4350121083029808

Epoch: 6| Step: 10
Training loss: 0.37260834647928626
Validation loss: 2.414982711491304

Epoch: 6| Step: 11
Training loss: 1.1057014894308288
Validation loss: 2.390463841637735

Epoch: 6| Step: 12
Training loss: 0.5630717550629226
Validation loss: 2.3483370667928645

Epoch: 6| Step: 13
Training loss: 0.44010537803829297
Validation loss: 2.3429888259716973

Epoch: 393| Step: 0
Training loss: 0.7452272106449732
Validation loss: 2.3521560270418256

Epoch: 6| Step: 1
Training loss: 0.42810617252356226
Validation loss: 2.3424918546211186

Epoch: 6| Step: 2
Training loss: 0.5249331726956834
Validation loss: 2.357315647912677

Epoch: 6| Step: 3
Training loss: 0.3557036325981863
Validation loss: 2.287898113193216

Epoch: 6| Step: 4
Training loss: 1.0229042352877917
Validation loss: 2.2953927941127312

Epoch: 6| Step: 5
Training loss: 0.5330675113356098
Validation loss: 2.286021499750805

Epoch: 6| Step: 6
Training loss: 0.15762930874263487
Validation loss: 2.317848014609064

Epoch: 6| Step: 7
Training loss: 0.2924524207828434
Validation loss: 2.2940110290468487

Epoch: 6| Step: 8
Training loss: 0.6426409426887334
Validation loss: 2.29571297433945

Epoch: 6| Step: 9
Training loss: 0.5206610649046065
Validation loss: 2.2742818658375596

Epoch: 6| Step: 10
Training loss: 0.475232504107737
Validation loss: 2.2826403703090388

Epoch: 6| Step: 11
Training loss: 0.2869023984819438
Validation loss: 2.297733548516879

Epoch: 6| Step: 12
Training loss: 0.5419668655666287
Validation loss: 2.3023241531754715

Epoch: 6| Step: 13
Training loss: 0.3520384004614226
Validation loss: 2.3188537943479175

Epoch: 394| Step: 0
Training loss: 0.2700173376177071
Validation loss: 2.3278852362569316

Epoch: 6| Step: 1
Training loss: 0.28415881732455067
Validation loss: 2.2916260295259248

Epoch: 6| Step: 2
Training loss: 0.46305686444325933
Validation loss: 2.3680869278536596

Epoch: 6| Step: 3
Training loss: 1.0143421580979286
Validation loss: 2.322014717470856

Epoch: 6| Step: 4
Training loss: 0.46553563470101356
Validation loss: 2.3559222933561834

Epoch: 6| Step: 5
Training loss: 0.5599016204061769
Validation loss: 2.363106233765116

Epoch: 6| Step: 6
Training loss: 0.30126329907071964
Validation loss: 2.3506629909712347

Epoch: 6| Step: 7
Training loss: 0.4062600868146619
Validation loss: 2.360736581444559

Epoch: 6| Step: 8
Training loss: 0.44482773612984
Validation loss: 2.3604599836846103

Epoch: 6| Step: 9
Training loss: 0.6329546874628146
Validation loss: 2.3285959613520193

Epoch: 6| Step: 10
Training loss: 0.6442480678951259
Validation loss: 2.315556320990487

Epoch: 6| Step: 11
Training loss: 0.42113640379871586
Validation loss: 2.3063053988056263

Epoch: 6| Step: 12
Training loss: 0.2344308945445531
Validation loss: 2.330910004029044

Epoch: 6| Step: 13
Training loss: 0.4338048129118557
Validation loss: 2.329393093102553

Epoch: 395| Step: 0
Training loss: 0.3325534976858454
Validation loss: 2.3124231571288982

Epoch: 6| Step: 1
Training loss: 0.3253959060002267
Validation loss: 2.3152861469243184

Epoch: 6| Step: 2
Training loss: 0.5823738574696191
Validation loss: 2.312997061165106

Epoch: 6| Step: 3
Training loss: 0.6937118708811917
Validation loss: 2.3239272371438724

Epoch: 6| Step: 4
Training loss: 0.2654142385089259
Validation loss: 2.3413126686422836

Epoch: 6| Step: 5
Training loss: 0.5263539668247074
Validation loss: 2.3574707663441297

Epoch: 6| Step: 6
Training loss: 0.3560214304916306
Validation loss: 2.350254436220908

Epoch: 6| Step: 7
Training loss: 0.3592227737778828
Validation loss: 2.3750633507630474

Epoch: 6| Step: 8
Training loss: 0.4423503063798035
Validation loss: 2.3560685332347773

Epoch: 6| Step: 9
Training loss: 0.3141579516152342
Validation loss: 2.361817160096968

Epoch: 6| Step: 10
Training loss: 0.5113184870430127
Validation loss: 2.3195776547960802

Epoch: 6| Step: 11
Training loss: 1.0654051836449476
Validation loss: 2.319427761848649

Epoch: 6| Step: 12
Training loss: 0.41176813470039947
Validation loss: 2.3145584627307256

Epoch: 6| Step: 13
Training loss: 0.37012370966899294
Validation loss: 2.283518536575227

Epoch: 396| Step: 0
Training loss: 0.583709218195566
Validation loss: 2.2769404312932413

Epoch: 6| Step: 1
Training loss: 0.5724670264064401
Validation loss: 2.3225215515315143

Epoch: 6| Step: 2
Training loss: 0.4070091307445354
Validation loss: 2.341849463706218

Epoch: 6| Step: 3
Training loss: 0.524814388979081
Validation loss: 2.288004961454524

Epoch: 6| Step: 4
Training loss: 0.37703263229957756
Validation loss: 2.2951726005958157

Epoch: 6| Step: 5
Training loss: 0.3669875391837824
Validation loss: 2.3150239278575158

Epoch: 6| Step: 6
Training loss: 0.4997870021372892
Validation loss: 2.328096959865442

Epoch: 6| Step: 7
Training loss: 0.5279156444853792
Validation loss: 2.317713451667896

Epoch: 6| Step: 8
Training loss: 0.29941324531259517
Validation loss: 2.366824167924596

Epoch: 6| Step: 9
Training loss: 0.6744640500842944
Validation loss: 2.387521892649747

Epoch: 6| Step: 10
Training loss: 0.44951812056698964
Validation loss: 2.354307868665733

Epoch: 6| Step: 11
Training loss: 0.9575019457426296
Validation loss: 2.3757400773662343

Epoch: 6| Step: 12
Training loss: 0.15159657847333863
Validation loss: 2.3750082230654956

Epoch: 6| Step: 13
Training loss: 0.497787767216143
Validation loss: 2.4030975490433684

Epoch: 397| Step: 0
Training loss: 0.26834578278392335
Validation loss: 2.3637164974892007

Epoch: 6| Step: 1
Training loss: 0.443758662904883
Validation loss: 2.3790575458203924

Epoch: 6| Step: 2
Training loss: 0.47502664190164895
Validation loss: 2.4000061747768915

Epoch: 6| Step: 3
Training loss: 0.4147154859400456
Validation loss: 2.4075403034132297

Epoch: 6| Step: 4
Training loss: 0.5726110047580998
Validation loss: 2.3697765682965075

Epoch: 6| Step: 5
Training loss: 0.44237772620773935
Validation loss: 2.3821604147947415

Epoch: 6| Step: 6
Training loss: 0.31056940248940595
Validation loss: 2.3644941709866205

Epoch: 6| Step: 7
Training loss: 1.074447385558642
Validation loss: 2.3599970909552273

Epoch: 6| Step: 8
Training loss: 0.3739915042322789
Validation loss: 2.411561536940407

Epoch: 6| Step: 9
Training loss: 0.37278528678550954
Validation loss: 2.3864620272002575

Epoch: 6| Step: 10
Training loss: 0.48109107303896737
Validation loss: 2.3549053555243344

Epoch: 6| Step: 11
Training loss: 0.39397943261000584
Validation loss: 2.3688090320374116

Epoch: 6| Step: 12
Training loss: 0.2643579528714426
Validation loss: 2.359479726232676

Epoch: 6| Step: 13
Training loss: 0.5613878965576141
Validation loss: 2.373745410420136

Epoch: 398| Step: 0
Training loss: 0.5072468762007816
Validation loss: 2.3039834002507256

Epoch: 6| Step: 1
Training loss: 0.342242468159616
Validation loss: 2.291673334359978

Epoch: 6| Step: 2
Training loss: 0.2581169180724757
Validation loss: 2.3267306286856857

Epoch: 6| Step: 3
Training loss: 0.568851166415538
Validation loss: 2.329088060181622

Epoch: 6| Step: 4
Training loss: 0.5536915609208883
Validation loss: 2.325057216954237

Epoch: 6| Step: 5
Training loss: 0.5835823027319195
Validation loss: 2.3216353227857454

Epoch: 6| Step: 6
Training loss: 0.3445689892156931
Validation loss: 2.307884145979214

Epoch: 6| Step: 7
Training loss: 0.4250912806713957
Validation loss: 2.338599453267456

Epoch: 6| Step: 8
Training loss: 0.44461620839682064
Validation loss: 2.3521858271985434

Epoch: 6| Step: 9
Training loss: 0.5734766362111403
Validation loss: 2.3517356827593368

Epoch: 6| Step: 10
Training loss: 0.4300993073086459
Validation loss: 2.3595082582837468

Epoch: 6| Step: 11
Training loss: 0.26151788889416777
Validation loss: 2.350829220835321

Epoch: 6| Step: 12
Training loss: 0.3737295804139029
Validation loss: 2.3335180249783547

Epoch: 6| Step: 13
Training loss: 1.19703236434321
Validation loss: 2.319241838516286

Epoch: 399| Step: 0
Training loss: 0.24229184333278767
Validation loss: 2.346480893885664

Epoch: 6| Step: 1
Training loss: 0.532462139664203
Validation loss: 2.341627903544727

Epoch: 6| Step: 2
Training loss: 0.3609546277494752
Validation loss: 2.3396053669040384

Epoch: 6| Step: 3
Training loss: 0.2866580036059373
Validation loss: 2.3565557823766032

Epoch: 6| Step: 4
Training loss: 0.9305053767787383
Validation loss: 2.323936888032752

Epoch: 6| Step: 5
Training loss: 0.2079244097208788
Validation loss: 2.3789625112867663

Epoch: 6| Step: 6
Training loss: 0.5570873943780954
Validation loss: 2.352625215798153

Epoch: 6| Step: 7
Training loss: 0.5439824035161759
Validation loss: 2.347715599450057

Epoch: 6| Step: 8
Training loss: 0.29177583059389295
Validation loss: 2.343104205016401

Epoch: 6| Step: 9
Training loss: 0.5414419319317555
Validation loss: 2.3232164719666235

Epoch: 6| Step: 10
Training loss: 0.4456817702076339
Validation loss: 2.3557454364708454

Epoch: 6| Step: 11
Training loss: 0.6044608063324997
Validation loss: 2.3429668701461077

Epoch: 6| Step: 12
Training loss: 0.4373108591220935
Validation loss: 2.338887491634094

Epoch: 6| Step: 13
Training loss: 0.5533195336710374
Validation loss: 2.308250447111163

Epoch: 400| Step: 0
Training loss: 0.3434213020454958
Validation loss: 2.3542754274930875

Epoch: 6| Step: 1
Training loss: 0.5415515655100485
Validation loss: 2.309821336515592

Epoch: 6| Step: 2
Training loss: 0.9676092568641894
Validation loss: 2.350811706920823

Epoch: 6| Step: 3
Training loss: 0.5228825944334855
Validation loss: 2.335197254342746

Epoch: 6| Step: 4
Training loss: 0.42392794580616583
Validation loss: 2.3437634348056995

Epoch: 6| Step: 5
Training loss: 0.37071751043065354
Validation loss: 2.3345488760258903

Epoch: 6| Step: 6
Training loss: 0.4294661211722896
Validation loss: 2.3840174970949635

Epoch: 6| Step: 7
Training loss: 0.4757502309274439
Validation loss: 2.318315652381318

Epoch: 6| Step: 8
Training loss: 0.27615591000351153
Validation loss: 2.2995644124379178

Epoch: 6| Step: 9
Training loss: 0.654545750897875
Validation loss: 2.316540003539527

Epoch: 6| Step: 10
Training loss: 0.5223623022218987
Validation loss: 2.349115800300911

Epoch: 6| Step: 11
Training loss: 0.44023009385309525
Validation loss: 2.302230323757763

Epoch: 6| Step: 12
Training loss: 0.33765582928858595
Validation loss: 2.310558787529032

Epoch: 6| Step: 13
Training loss: 0.2182329914210028
Validation loss: 2.3228869129778587

Epoch: 401| Step: 0
Training loss: 0.4757827727445341
Validation loss: 2.305653710797736

Epoch: 6| Step: 1
Training loss: 0.9238988030719157
Validation loss: 2.310569453997462

Epoch: 6| Step: 2
Training loss: 0.6222980268128044
Validation loss: 2.316193422323433

Epoch: 6| Step: 3
Training loss: 0.314263304288401
Validation loss: 2.3497819314533395

Epoch: 6| Step: 4
Training loss: 0.23362743045569295
Validation loss: 2.3420970236933623

Epoch: 6| Step: 5
Training loss: 0.30539416014703097
Validation loss: 2.358670042504893

Epoch: 6| Step: 6
Training loss: 0.43526264718539287
Validation loss: 2.3077937968907256

Epoch: 6| Step: 7
Training loss: 0.4928745439717415
Validation loss: 2.3442636169097537

Epoch: 6| Step: 8
Training loss: 0.5229234591140437
Validation loss: 2.339539123029197

Epoch: 6| Step: 9
Training loss: 0.44658574232690407
Validation loss: 2.3695595132748215

Epoch: 6| Step: 10
Training loss: 0.37596744674927274
Validation loss: 2.383655866723168

Epoch: 6| Step: 11
Training loss: 0.47075257100979834
Validation loss: 2.3785684220655274

Epoch: 6| Step: 12
Training loss: 0.4356586330023844
Validation loss: 2.3449815277842068

Epoch: 6| Step: 13
Training loss: 0.13983944854301134
Validation loss: 2.339374334706024

Epoch: 402| Step: 0
Training loss: 0.39909353662780406
Validation loss: 2.3744863517072434

Epoch: 6| Step: 1
Training loss: 0.4320495705057099
Validation loss: 2.37455089189326

Epoch: 6| Step: 2
Training loss: 0.4920935162624667
Validation loss: 2.3558818229306215

Epoch: 6| Step: 3
Training loss: 0.3482180567247257
Validation loss: 2.3385369531259794

Epoch: 6| Step: 4
Training loss: 0.2466259983258118
Validation loss: 2.3176353912286842

Epoch: 6| Step: 5
Training loss: 0.7361348756117033
Validation loss: 2.3684268277812746

Epoch: 6| Step: 6
Training loss: 0.24973048643397427
Validation loss: 2.3568377386338932

Epoch: 6| Step: 7
Training loss: 0.5398235201323031
Validation loss: 2.3630030851462855

Epoch: 6| Step: 8
Training loss: 0.3708649582540014
Validation loss: 2.346750183618358

Epoch: 6| Step: 9
Training loss: 0.36722621307827125
Validation loss: 2.3319243818865414

Epoch: 6| Step: 10
Training loss: 0.26128774710193087
Validation loss: 2.3416168880751536

Epoch: 6| Step: 11
Training loss: 0.3608691006208984
Validation loss: 2.370824402518873

Epoch: 6| Step: 12
Training loss: 0.4003337540593876
Validation loss: 2.4224782382330474

Epoch: 6| Step: 13
Training loss: 1.135250231008836
Validation loss: 2.3992052494521023

Epoch: 403| Step: 0
Training loss: 0.5102927161246151
Validation loss: 2.453707002398624

Epoch: 6| Step: 1
Training loss: 0.8636461065167162
Validation loss: 2.393797003625844

Epoch: 6| Step: 2
Training loss: 0.37386436167191
Validation loss: 2.3780095753572126

Epoch: 6| Step: 3
Training loss: 0.24569317595893772
Validation loss: 2.374396861227825

Epoch: 6| Step: 4
Training loss: 0.46752620526678534
Validation loss: 2.345835382416247

Epoch: 6| Step: 5
Training loss: 0.41282965102508723
Validation loss: 2.272191022159664

Epoch: 6| Step: 6
Training loss: 0.5055710843720687
Validation loss: 2.2817480358658577

Epoch: 6| Step: 7
Training loss: 0.6050485198607851
Validation loss: 2.274266740603986

Epoch: 6| Step: 8
Training loss: 0.5011060521346679
Validation loss: 2.3020352817149963

Epoch: 6| Step: 9
Training loss: 0.46080564779042477
Validation loss: 2.3088195955714963

Epoch: 6| Step: 10
Training loss: 0.2938270457663034
Validation loss: 2.363721562474343

Epoch: 6| Step: 11
Training loss: 0.6197924627304308
Validation loss: 2.403085682922826

Epoch: 6| Step: 12
Training loss: 0.6546527179591962
Validation loss: 2.4040724265201736

Epoch: 6| Step: 13
Training loss: 0.19450548338392876
Validation loss: 2.365028722840519

Epoch: 404| Step: 0
Training loss: 0.5058875057690898
Validation loss: 2.284329065786601

Epoch: 6| Step: 1
Training loss: 0.37909774267364316
Validation loss: 2.338066643893822

Epoch: 6| Step: 2
Training loss: 0.47316662369712553
Validation loss: 2.3322139987255586

Epoch: 6| Step: 3
Training loss: 0.40981936470578223
Validation loss: 2.3255242555298192

Epoch: 6| Step: 4
Training loss: 0.45462265469877267
Validation loss: 2.300499599923162

Epoch: 6| Step: 5
Training loss: 0.31662434255363797
Validation loss: 2.287845722577738

Epoch: 6| Step: 6
Training loss: 0.5409243399938182
Validation loss: 2.3280876450130576

Epoch: 6| Step: 7
Training loss: 0.43711210834647407
Validation loss: 2.335749704042634

Epoch: 6| Step: 8
Training loss: 0.34885241433530556
Validation loss: 2.407665758304324

Epoch: 6| Step: 9
Training loss: 0.3439607082822536
Validation loss: 2.393094072393468

Epoch: 6| Step: 10
Training loss: 0.7032372279141408
Validation loss: 2.381903827101328

Epoch: 6| Step: 11
Training loss: 0.5484006309614857
Validation loss: 2.3911489788726463

Epoch: 6| Step: 12
Training loss: 0.20240463386586585
Validation loss: 2.3765388818276936

Epoch: 6| Step: 13
Training loss: 1.2314387781875855
Validation loss: 2.394957059999839

Epoch: 405| Step: 0
Training loss: 0.5276745923993945
Validation loss: 2.3118547261551496

Epoch: 6| Step: 1
Training loss: 0.4837737812929158
Validation loss: 2.3906962398643783

Epoch: 6| Step: 2
Training loss: 0.2852738020559105
Validation loss: 2.3747861147361307

Epoch: 6| Step: 3
Training loss: 0.8777332531693084
Validation loss: 2.338639857728404

Epoch: 6| Step: 4
Training loss: 0.3265121192946558
Validation loss: 2.3016964961341566

Epoch: 6| Step: 5
Training loss: 0.4849483726493039
Validation loss: 2.3239227919961696

Epoch: 6| Step: 6
Training loss: 0.43862025703698865
Validation loss: 2.291381022381412

Epoch: 6| Step: 7
Training loss: 0.35320358836601995
Validation loss: 2.2710020682429786

Epoch: 6| Step: 8
Training loss: 0.5342769220483337
Validation loss: 2.2574567202591127

Epoch: 6| Step: 9
Training loss: 0.5400250176091692
Validation loss: 2.263206141197232

Epoch: 6| Step: 10
Training loss: 0.3628421098124849
Validation loss: 2.249278038168527

Epoch: 6| Step: 11
Training loss: 0.3644777712813874
Validation loss: 2.289176803949816

Epoch: 6| Step: 12
Training loss: 0.5075011839641422
Validation loss: 2.2919902345620797

Epoch: 6| Step: 13
Training loss: 0.10053039146681661
Validation loss: 2.3082123873063085

Epoch: 406| Step: 0
Training loss: 0.6076695467768535
Validation loss: 2.297460286552866

Epoch: 6| Step: 1
Training loss: 0.53077774936082
Validation loss: 2.306600710597724

Epoch: 6| Step: 2
Training loss: 0.5379013880454155
Validation loss: 2.317554832611866

Epoch: 6| Step: 3
Training loss: 0.3300141831261712
Validation loss: 2.2539064115137974

Epoch: 6| Step: 4
Training loss: 0.49655943512495865
Validation loss: 2.327596383770649

Epoch: 6| Step: 5
Training loss: 0.31907261482144705
Validation loss: 2.2797107788373707

Epoch: 6| Step: 6
Training loss: 0.18083613681011776
Validation loss: 2.3456753649408695

Epoch: 6| Step: 7
Training loss: 0.3745994415398186
Validation loss: 2.3038768011951363

Epoch: 6| Step: 8
Training loss: 0.25477796714761075
Validation loss: 2.281615862443646

Epoch: 6| Step: 9
Training loss: 0.3902111531508937
Validation loss: 2.3009396816800844

Epoch: 6| Step: 10
Training loss: 0.4983325512932007
Validation loss: 2.3460661941410414

Epoch: 6| Step: 11
Training loss: 0.8198323615773395
Validation loss: 2.367214111083246

Epoch: 6| Step: 12
Training loss: 0.3781214382855098
Validation loss: 2.362397829750248

Epoch: 6| Step: 13
Training loss: 0.5802146160212477
Validation loss: 2.345694271325483

Epoch: 407| Step: 0
Training loss: 0.6098200077925191
Validation loss: 2.37738069233157

Epoch: 6| Step: 1
Training loss: 0.5940141090457809
Validation loss: 2.372094826190057

Epoch: 6| Step: 2
Training loss: 0.37991815319273897
Validation loss: 2.3797444770985843

Epoch: 6| Step: 3
Training loss: 0.4336371013517577
Validation loss: 2.360231933483869

Epoch: 6| Step: 4
Training loss: 0.33844456991981264
Validation loss: 2.349586027691528

Epoch: 6| Step: 5
Training loss: 0.39490438511245035
Validation loss: 2.344229172156299

Epoch: 6| Step: 6
Training loss: 0.38245601014641284
Validation loss: 2.3390524622180595

Epoch: 6| Step: 7
Training loss: 0.48885176326058755
Validation loss: 2.3484429271312357

Epoch: 6| Step: 8
Training loss: 0.4385643851979176
Validation loss: 2.332204393630137

Epoch: 6| Step: 9
Training loss: 0.3532248507751348
Validation loss: 2.3624992436146646

Epoch: 6| Step: 10
Training loss: 0.4228140481778127
Validation loss: 2.3602690588809674

Epoch: 6| Step: 11
Training loss: 0.8122143610130141
Validation loss: 2.388671284712762

Epoch: 6| Step: 12
Training loss: 0.44133948774898996
Validation loss: 2.4052666203670765

Epoch: 6| Step: 13
Training loss: 0.600864575266453
Validation loss: 2.383302903004393

Epoch: 408| Step: 0
Training loss: 0.4738055985671083
Validation loss: 2.371553163955043

Epoch: 6| Step: 1
Training loss: 0.3276543193245446
Validation loss: 2.29558428578999

Epoch: 6| Step: 2
Training loss: 0.5179847990975953
Validation loss: 2.328098613828715

Epoch: 6| Step: 3
Training loss: 0.38000621605482066
Validation loss: 2.29200745749331

Epoch: 6| Step: 4
Training loss: 0.3291654439895392
Validation loss: 2.270688940174438

Epoch: 6| Step: 5
Training loss: 0.5340708285196271
Validation loss: 2.2978191732991333

Epoch: 6| Step: 6
Training loss: 0.29037524176680723
Validation loss: 2.2684668042585288

Epoch: 6| Step: 7
Training loss: 0.7938615255027692
Validation loss: 2.3247131345784116

Epoch: 6| Step: 8
Training loss: 0.3563326932066035
Validation loss: 2.3399765801692967

Epoch: 6| Step: 9
Training loss: 0.47120993780349296
Validation loss: 2.402189724534309

Epoch: 6| Step: 10
Training loss: 0.46761030884695154
Validation loss: 2.3900722159731624

Epoch: 6| Step: 11
Training loss: 0.5570362759613531
Validation loss: 2.324487492104763

Epoch: 6| Step: 12
Training loss: 0.373967358242074
Validation loss: 2.2852148701472945

Epoch: 6| Step: 13
Training loss: 0.642413295023777
Validation loss: 2.2376293230932034

Epoch: 409| Step: 0
Training loss: 0.5237295560101535
Validation loss: 2.228295323171826

Epoch: 6| Step: 1
Training loss: 0.5145355042792279
Validation loss: 2.2354979822134005

Epoch: 6| Step: 2
Training loss: 0.5293640431933233
Validation loss: 2.244515362149192

Epoch: 6| Step: 3
Training loss: 0.6813839317048496
Validation loss: 2.2752708792606846

Epoch: 6| Step: 4
Training loss: 0.5223121217217559
Validation loss: 2.3521569951550374

Epoch: 6| Step: 5
Training loss: 0.5850010318420961
Validation loss: 2.409621740347975

Epoch: 6| Step: 6
Training loss: 0.545982886591154
Validation loss: 2.406396742843479

Epoch: 6| Step: 7
Training loss: 0.5492947044324248
Validation loss: 2.452726743688688

Epoch: 6| Step: 8
Training loss: 0.5273538659149825
Validation loss: 2.37406687817978

Epoch: 6| Step: 9
Training loss: 0.3023488081279785
Validation loss: 2.3383316357548654

Epoch: 6| Step: 10
Training loss: 0.5362099347119429
Validation loss: 2.313317330440912

Epoch: 6| Step: 11
Training loss: 0.2872860682695594
Validation loss: 2.2782553552629183

Epoch: 6| Step: 12
Training loss: 0.44164067347830116
Validation loss: 2.313682397986196

Epoch: 6| Step: 13
Training loss: 0.1825200398755934
Validation loss: 2.332132845526675

Epoch: 410| Step: 0
Training loss: 0.3604419667215405
Validation loss: 2.355318005895979

Epoch: 6| Step: 1
Training loss: 0.40921766883267396
Validation loss: 2.3429507045921283

Epoch: 6| Step: 2
Training loss: 0.24853878355845466
Validation loss: 2.3906211212253274

Epoch: 6| Step: 3
Training loss: 0.592002656618163
Validation loss: 2.3995653777765007

Epoch: 6| Step: 4
Training loss: 0.4403566016480169
Validation loss: 2.3873997743762994

Epoch: 6| Step: 5
Training loss: 0.34145045572580884
Validation loss: 2.3675926362961093

Epoch: 6| Step: 6
Training loss: 0.45125450269402256
Validation loss: 2.3736892541724353

Epoch: 6| Step: 7
Training loss: 0.43919975606098594
Validation loss: 2.3657928834638597

Epoch: 6| Step: 8
Training loss: 0.398487181464526
Validation loss: 2.3187220422343837

Epoch: 6| Step: 9
Training loss: 0.4164602563128873
Validation loss: 2.3586199651872777

Epoch: 6| Step: 10
Training loss: 0.5551676753785173
Validation loss: 2.3394483833868396

Epoch: 6| Step: 11
Training loss: 0.8077626402942356
Validation loss: 2.3051035738192125

Epoch: 6| Step: 12
Training loss: 0.17376660747883194
Validation loss: 2.3436355119860535

Epoch: 6| Step: 13
Training loss: 0.26023413778092114
Validation loss: 2.325287386708464

Epoch: 411| Step: 0
Training loss: 0.8558369022902894
Validation loss: 2.3357226631401633

Epoch: 6| Step: 1
Training loss: 0.596631087151626
Validation loss: 2.347558620985613

Epoch: 6| Step: 2
Training loss: 0.24856845954846782
Validation loss: 2.337461486879921

Epoch: 6| Step: 3
Training loss: 0.5906863730701082
Validation loss: 2.3752134488424956

Epoch: 6| Step: 4
Training loss: 0.4431238094792696
Validation loss: 2.3605633080471002

Epoch: 6| Step: 5
Training loss: 0.35199604852311633
Validation loss: 2.323923053994812

Epoch: 6| Step: 6
Training loss: 0.20866005233127052
Validation loss: 2.3291813552337226

Epoch: 6| Step: 7
Training loss: 0.3293938626311704
Validation loss: 2.2630272971206247

Epoch: 6| Step: 8
Training loss: 0.2664223372448858
Validation loss: 2.23180523708959

Epoch: 6| Step: 9
Training loss: 0.46206136858819796
Validation loss: 2.247982469651444

Epoch: 6| Step: 10
Training loss: 0.6229073060224397
Validation loss: 2.2335284598823306

Epoch: 6| Step: 11
Training loss: 0.31164232813479015
Validation loss: 2.268144090112139

Epoch: 6| Step: 12
Training loss: 0.36099755914555076
Validation loss: 2.338303000990203

Epoch: 6| Step: 13
Training loss: 0.36183465044199786
Validation loss: 2.39105505348899

Epoch: 412| Step: 0
Training loss: 0.35848272512226087
Validation loss: 2.3998337316130858

Epoch: 6| Step: 1
Training loss: 0.7259385085376002
Validation loss: 2.3675876017899085

Epoch: 6| Step: 2
Training loss: 0.5609051559601645
Validation loss: 2.2972802904067415

Epoch: 6| Step: 3
Training loss: 0.21070411804949643
Validation loss: 2.2561433059862313

Epoch: 6| Step: 4
Training loss: 0.4174327979282066
Validation loss: 2.2516285313437856

Epoch: 6| Step: 5
Training loss: 0.5003301305481992
Validation loss: 2.2130273971240366

Epoch: 6| Step: 6
Training loss: 0.5926794137810393
Validation loss: 2.20737578802441

Epoch: 6| Step: 7
Training loss: 0.406293426540114
Validation loss: 2.245089092088748

Epoch: 6| Step: 8
Training loss: 0.5440771740945369
Validation loss: 2.2168297124861565

Epoch: 6| Step: 9
Training loss: 0.2876858017560752
Validation loss: 2.2867301687572548

Epoch: 6| Step: 10
Training loss: 0.2630185404133076
Validation loss: 2.2997075430846876

Epoch: 6| Step: 11
Training loss: 0.2704506824084922
Validation loss: 2.3443016250804107

Epoch: 6| Step: 12
Training loss: 0.5958181301480379
Validation loss: 2.334511572764764

Epoch: 6| Step: 13
Training loss: 0.39639363871396416
Validation loss: 2.335537397592984

Epoch: 413| Step: 0
Training loss: 0.5337361616265943
Validation loss: 2.297898767065588

Epoch: 6| Step: 1
Training loss: 0.5389751695299397
Validation loss: 2.2662054962484772

Epoch: 6| Step: 2
Training loss: 0.38097229286256856
Validation loss: 2.2733532523094895

Epoch: 6| Step: 3
Training loss: 0.23032478103089013
Validation loss: 2.272243967779689

Epoch: 6| Step: 4
Training loss: 0.7080074336609978
Validation loss: 2.2876523145647734

Epoch: 6| Step: 5
Training loss: 0.318199714456924
Validation loss: 2.2805837371042723

Epoch: 6| Step: 6
Training loss: 0.3381805058469694
Validation loss: 2.31770103668211

Epoch: 6| Step: 7
Training loss: 0.35367896590087927
Validation loss: 2.339668521143437

Epoch: 6| Step: 8
Training loss: 0.43654733204142687
Validation loss: 2.380469409781222

Epoch: 6| Step: 9
Training loss: 0.5942855226895003
Validation loss: 2.4173356878039094

Epoch: 6| Step: 10
Training loss: 0.513932774648801
Validation loss: 2.362683250020763

Epoch: 6| Step: 11
Training loss: 0.4451734091389632
Validation loss: 2.3340048534174382

Epoch: 6| Step: 12
Training loss: 0.3086509651549658
Validation loss: 2.2850216859838715

Epoch: 6| Step: 13
Training loss: 0.36944398071304574
Validation loss: 2.284901578805799

Epoch: 414| Step: 0
Training loss: 0.4070992030496464
Validation loss: 2.288903900311244

Epoch: 6| Step: 1
Training loss: 0.5246182120708658
Validation loss: 2.276567484300327

Epoch: 6| Step: 2
Training loss: 0.3646419432623153
Validation loss: 2.306295006074404

Epoch: 6| Step: 3
Training loss: 0.43271678871607855
Validation loss: 2.280606340716496

Epoch: 6| Step: 4
Training loss: 0.5987993914036662
Validation loss: 2.289196946316073

Epoch: 6| Step: 5
Training loss: 0.6594839792453078
Validation loss: 2.311201794332359

Epoch: 6| Step: 6
Training loss: 0.4314198684615326
Validation loss: 2.3299518450554895

Epoch: 6| Step: 7
Training loss: 0.45397742430710136
Validation loss: 2.31908237330691

Epoch: 6| Step: 8
Training loss: 0.37853866129122854
Validation loss: 2.3360995524094967

Epoch: 6| Step: 9
Training loss: 0.2958266293858569
Validation loss: 2.3080677747615654

Epoch: 6| Step: 10
Training loss: 0.27963998699994685
Validation loss: 2.297811733904586

Epoch: 6| Step: 11
Training loss: 0.4648052488138176
Validation loss: 2.2708604309942912

Epoch: 6| Step: 12
Training loss: 0.49868032525678224
Validation loss: 2.2605255911244733

Epoch: 6| Step: 13
Training loss: 0.42176022557794896
Validation loss: 2.304776532633145

Epoch: 415| Step: 0
Training loss: 0.5203845824752867
Validation loss: 2.2957579185975683

Epoch: 6| Step: 1
Training loss: 0.8192691889457586
Validation loss: 2.2790010081355665

Epoch: 6| Step: 2
Training loss: 0.42972039183524297
Validation loss: 2.294286086298409

Epoch: 6| Step: 3
Training loss: 0.5896534138962616
Validation loss: 2.275589422655151

Epoch: 6| Step: 4
Training loss: 0.4121230245200964
Validation loss: 2.2915262456608123

Epoch: 6| Step: 5
Training loss: 0.2500435820976935
Validation loss: 2.2927681719065087

Epoch: 6| Step: 6
Training loss: 0.34222741395016887
Validation loss: 2.266836247835361

Epoch: 6| Step: 7
Training loss: 0.525370317371529
Validation loss: 2.256859535490108

Epoch: 6| Step: 8
Training loss: 0.3192591443600558
Validation loss: 2.2573433091999595

Epoch: 6| Step: 9
Training loss: 0.47183018212606304
Validation loss: 2.278423602586949

Epoch: 6| Step: 10
Training loss: 0.36508516333840524
Validation loss: 2.2733126612633874

Epoch: 6| Step: 11
Training loss: 0.23310137242911855
Validation loss: 2.2939241501284595

Epoch: 6| Step: 12
Training loss: 0.39344947108932354
Validation loss: 2.3157555529927007

Epoch: 6| Step: 13
Training loss: 0.4539092117974566
Validation loss: 2.3569929211477443

Epoch: 416| Step: 0
Training loss: 0.3311857116141251
Validation loss: 2.317189819767584

Epoch: 6| Step: 1
Training loss: 0.5266661069460603
Validation loss: 2.3121710889535434

Epoch: 6| Step: 2
Training loss: 0.4015997145808486
Validation loss: 2.3664547199505486

Epoch: 6| Step: 3
Training loss: 0.3169301722722643
Validation loss: 2.367382201700579

Epoch: 6| Step: 4
Training loss: 0.4426520667129232
Validation loss: 2.3461962506497334

Epoch: 6| Step: 5
Training loss: 0.3322288037672473
Validation loss: 2.3467691403341515

Epoch: 6| Step: 6
Training loss: 0.7507027274361077
Validation loss: 2.3521229463766744

Epoch: 6| Step: 7
Training loss: 0.35412216841955574
Validation loss: 2.3856664615377645

Epoch: 6| Step: 8
Training loss: 0.4420038414740738
Validation loss: 2.3549797358473925

Epoch: 6| Step: 9
Training loss: 0.36154028360201124
Validation loss: 2.3151281339352785

Epoch: 6| Step: 10
Training loss: 0.43240602734755673
Validation loss: 2.322200458539963

Epoch: 6| Step: 11
Training loss: 0.45255085316898863
Validation loss: 2.310189528270334

Epoch: 6| Step: 12
Training loss: 0.32221693191259576
Validation loss: 2.3325060118978143

Epoch: 6| Step: 13
Training loss: 0.3543154483456493
Validation loss: 2.311692739109686

Epoch: 417| Step: 0
Training loss: 0.44406824117622967
Validation loss: 2.302018889976278

Epoch: 6| Step: 1
Training loss: 0.4041467286465159
Validation loss: 2.3319904825873343

Epoch: 6| Step: 2
Training loss: 0.18996068469279193
Validation loss: 2.3262101236700023

Epoch: 6| Step: 3
Training loss: 0.30192452674052234
Validation loss: 2.303160651473636

Epoch: 6| Step: 4
Training loss: 0.3332617230782271
Validation loss: 2.2896304558682665

Epoch: 6| Step: 5
Training loss: 0.43893069260663453
Validation loss: 2.2586122352478513

Epoch: 6| Step: 6
Training loss: 0.37555195004466446
Validation loss: 2.2883561054549153

Epoch: 6| Step: 7
Training loss: 0.626473406690796
Validation loss: 2.3389585218335767

Epoch: 6| Step: 8
Training loss: 0.3558233399890029
Validation loss: 2.3313642487087045

Epoch: 6| Step: 9
Training loss: 0.4996054254753045
Validation loss: 2.3496540760796947

Epoch: 6| Step: 10
Training loss: 0.4810107515802882
Validation loss: 2.3588128167490603

Epoch: 6| Step: 11
Training loss: 0.4654441290186506
Validation loss: 2.321632119109676

Epoch: 6| Step: 12
Training loss: 0.2923348244100174
Validation loss: 2.3421947019508536

Epoch: 6| Step: 13
Training loss: 0.5325687253507814
Validation loss: 2.3315900569164456

Epoch: 418| Step: 0
Training loss: 0.6013350118545288
Validation loss: 2.315694550806875

Epoch: 6| Step: 1
Training loss: 0.36704438037860077
Validation loss: 2.3058146661720245

Epoch: 6| Step: 2
Training loss: 0.39861929243038274
Validation loss: 2.3092719253977574

Epoch: 6| Step: 3
Training loss: 0.25727788808482493
Validation loss: 2.3613498883893453

Epoch: 6| Step: 4
Training loss: 0.29452960977679427
Validation loss: 2.3114239060547623

Epoch: 6| Step: 5
Training loss: 0.3319348251351357
Validation loss: 2.364601462246229

Epoch: 6| Step: 6
Training loss: 0.6296083783971252
Validation loss: 2.3650671398157352

Epoch: 6| Step: 7
Training loss: 0.5879282891764597
Validation loss: 2.3607102046705672

Epoch: 6| Step: 8
Training loss: 0.3508599573205716
Validation loss: 2.3545935346608173

Epoch: 6| Step: 9
Training loss: 0.4302031630635639
Validation loss: 2.3502676462300824

Epoch: 6| Step: 10
Training loss: 0.3076740757247099
Validation loss: 2.3221438462463166

Epoch: 6| Step: 11
Training loss: 0.3110891442027395
Validation loss: 2.3194909531883714

Epoch: 6| Step: 12
Training loss: 0.3750386218209544
Validation loss: 2.3033275665269897

Epoch: 6| Step: 13
Training loss: 0.45150325214866494
Validation loss: 2.3285601690201556

Epoch: 419| Step: 0
Training loss: 0.2746785202988904
Validation loss: 2.35386874406175

Epoch: 6| Step: 1
Training loss: 0.5052432280874215
Validation loss: 2.339050523363657

Epoch: 6| Step: 2
Training loss: 0.25237323423394237
Validation loss: 2.348518926566719

Epoch: 6| Step: 3
Training loss: 0.4999399149078481
Validation loss: 2.3211266597511724

Epoch: 6| Step: 4
Training loss: 0.5066265636601613
Validation loss: 2.339314188427022

Epoch: 6| Step: 5
Training loss: 0.31414659142965085
Validation loss: 2.3664859184346634

Epoch: 6| Step: 6
Training loss: 0.4616980662610476
Validation loss: 2.393742096380599

Epoch: 6| Step: 7
Training loss: 0.32211636641393265
Validation loss: 2.4036776842601806

Epoch: 6| Step: 8
Training loss: 0.3863088381189011
Validation loss: 2.4258269538079276

Epoch: 6| Step: 9
Training loss: 0.6776231789957646
Validation loss: 2.374526642159748

Epoch: 6| Step: 10
Training loss: 0.475813542915944
Validation loss: 2.398692935767862

Epoch: 6| Step: 11
Training loss: 0.31500921184830405
Validation loss: 2.389524685570664

Epoch: 6| Step: 12
Training loss: 0.26109034978363554
Validation loss: 2.385027930648936

Epoch: 6| Step: 13
Training loss: 0.19962647732443023
Validation loss: 2.415810336416486

Epoch: 420| Step: 0
Training loss: 0.2965486388991923
Validation loss: 2.3988471921679744

Epoch: 6| Step: 1
Training loss: 0.27317164985094555
Validation loss: 2.373323249666139

Epoch: 6| Step: 2
Training loss: 0.29866200236438417
Validation loss: 2.3488794561876665

Epoch: 6| Step: 3
Training loss: 0.4923411992187669
Validation loss: 2.3226084463067576

Epoch: 6| Step: 4
Training loss: 0.3503689745419955
Validation loss: 2.364631220480972

Epoch: 6| Step: 5
Training loss: 0.37778124986873074
Validation loss: 2.361886684485197

Epoch: 6| Step: 6
Training loss: 0.36624161655348403
Validation loss: 2.3029295554289537

Epoch: 6| Step: 7
Training loss: 0.3345401890650366
Validation loss: 2.3708060739253702

Epoch: 6| Step: 8
Training loss: 0.3185803635176338
Validation loss: 2.387882889223282

Epoch: 6| Step: 9
Training loss: 0.42144322375625776
Validation loss: 2.3777362602726946

Epoch: 6| Step: 10
Training loss: 0.529065014494651
Validation loss: 2.347045495214007

Epoch: 6| Step: 11
Training loss: 0.6863704852871172
Validation loss: 2.359103325105815

Epoch: 6| Step: 12
Training loss: 0.35896543301324807
Validation loss: 2.3863201423100997

Epoch: 6| Step: 13
Training loss: 0.3530863584627127
Validation loss: 2.364598031915586

Epoch: 421| Step: 0
Training loss: 0.6809999794588912
Validation loss: 2.3238425737933217

Epoch: 6| Step: 1
Training loss: 0.2677010998447512
Validation loss: 2.3339848385233433

Epoch: 6| Step: 2
Training loss: 0.298200921462015
Validation loss: 2.3145842379055632

Epoch: 6| Step: 3
Training loss: 0.34879446689598276
Validation loss: 2.304420251300466

Epoch: 6| Step: 4
Training loss: 0.23180915305003935
Validation loss: 2.3176533195563516

Epoch: 6| Step: 5
Training loss: 0.4529792617046614
Validation loss: 2.334643206872684

Epoch: 6| Step: 6
Training loss: 0.5639062892356768
Validation loss: 2.3243982108075465

Epoch: 6| Step: 7
Training loss: 0.3898431009657967
Validation loss: 2.3353887403089875

Epoch: 6| Step: 8
Training loss: 0.33319771014304844
Validation loss: 2.3297760801736063

Epoch: 6| Step: 9
Training loss: 0.3993531159627199
Validation loss: 2.317906515827471

Epoch: 6| Step: 10
Training loss: 0.2729493825294399
Validation loss: 2.2808226661202338

Epoch: 6| Step: 11
Training loss: 0.34579688487191446
Validation loss: 2.307432929566234

Epoch: 6| Step: 12
Training loss: 0.4086874137874827
Validation loss: 2.2879881016821817

Epoch: 6| Step: 13
Training loss: 0.26253166915956355
Validation loss: 2.2715331742724727

Epoch: 422| Step: 0
Training loss: 0.4778679961066206
Validation loss: 2.3025248474463518

Epoch: 6| Step: 1
Training loss: 0.44293017345562957
Validation loss: 2.354948095084028

Epoch: 6| Step: 2
Training loss: 0.3309252100347383
Validation loss: 2.353553333439075

Epoch: 6| Step: 3
Training loss: 0.2864139334630833
Validation loss: 2.332638401016297

Epoch: 6| Step: 4
Training loss: 0.4388943998611824
Validation loss: 2.3327254684303593

Epoch: 6| Step: 5
Training loss: 0.8131692770793361
Validation loss: 2.366697867440725

Epoch: 6| Step: 6
Training loss: 0.23157976164682495
Validation loss: 2.36669137139651

Epoch: 6| Step: 7
Training loss: 0.1359402357571554
Validation loss: 2.327367250334274

Epoch: 6| Step: 8
Training loss: 0.2858657371644962
Validation loss: 2.3118298495484764

Epoch: 6| Step: 9
Training loss: 0.33491213251122987
Validation loss: 2.3035146925465444

Epoch: 6| Step: 10
Training loss: 0.29916673063677757
Validation loss: 2.283198335017758

Epoch: 6| Step: 11
Training loss: 0.40108413182471125
Validation loss: 2.2801936883356357

Epoch: 6| Step: 12
Training loss: 0.3835244856257862
Validation loss: 2.3028229237325246

Epoch: 6| Step: 13
Training loss: 0.39232038701060123
Validation loss: 2.3076511633452146

Epoch: 423| Step: 0
Training loss: 0.3562896179455866
Validation loss: 2.2934678309097913

Epoch: 6| Step: 1
Training loss: 0.30946873102319983
Validation loss: 2.317204701336268

Epoch: 6| Step: 2
Training loss: 0.5696788298365094
Validation loss: 2.351896339240275

Epoch: 6| Step: 3
Training loss: 0.3511013397224918
Validation loss: 2.3894684280883176

Epoch: 6| Step: 4
Training loss: 0.4075401434403685
Validation loss: 2.3933789318862035

Epoch: 6| Step: 5
Training loss: 0.32724421223708866
Validation loss: 2.349126063066106

Epoch: 6| Step: 6
Training loss: 0.2759940523192619
Validation loss: 2.342454274555216

Epoch: 6| Step: 7
Training loss: 0.45036196985593385
Validation loss: 2.3665903830752715

Epoch: 6| Step: 8
Training loss: 0.5598415496297443
Validation loss: 2.3327299490059668

Epoch: 6| Step: 9
Training loss: 0.42325331563715535
Validation loss: 2.3253776613612227

Epoch: 6| Step: 10
Training loss: 0.4102441239456311
Validation loss: 2.3345793517092583

Epoch: 6| Step: 11
Training loss: 0.19223702420667488
Validation loss: 2.299817899135624

Epoch: 6| Step: 12
Training loss: 0.4327680268833041
Validation loss: 2.2972265547489044

Epoch: 6| Step: 13
Training loss: 0.1713297496567288
Validation loss: 2.344266518176637

Epoch: 424| Step: 0
Training loss: 0.30340148272016876
Validation loss: 2.3168284939171184

Epoch: 6| Step: 1
Training loss: 0.6150435136504961
Validation loss: 2.3706485519345972

Epoch: 6| Step: 2
Training loss: 0.2424247487174761
Validation loss: 2.3569212803909387

Epoch: 6| Step: 3
Training loss: 0.2674771556948506
Validation loss: 2.3400569727338825

Epoch: 6| Step: 4
Training loss: 0.6172134780245317
Validation loss: 2.360809606073072

Epoch: 6| Step: 5
Training loss: 0.16861704538139008
Validation loss: 2.3744256523822598

Epoch: 6| Step: 6
Training loss: 0.22683397011407083
Validation loss: 2.3505991341945425

Epoch: 6| Step: 7
Training loss: 0.40590148428297584
Validation loss: 2.333360033131558

Epoch: 6| Step: 8
Training loss: 0.3586794092263221
Validation loss: 2.3622977311743596

Epoch: 6| Step: 9
Training loss: 0.4860556271844475
Validation loss: 2.309721789161872

Epoch: 6| Step: 10
Training loss: 0.3939165671305204
Validation loss: 2.3100492921689475

Epoch: 6| Step: 11
Training loss: 0.3400752495841959
Validation loss: 2.3057721266042956

Epoch: 6| Step: 12
Training loss: 0.32397709308698475
Validation loss: 2.2730992978367315

Epoch: 6| Step: 13
Training loss: 0.3820926944490022
Validation loss: 2.294118676559444

Epoch: 425| Step: 0
Training loss: 0.27633738272799857
Validation loss: 2.347028998934391

Epoch: 6| Step: 1
Training loss: 0.3962791550677706
Validation loss: 2.292168786162022

Epoch: 6| Step: 2
Training loss: 0.43950727341094004
Validation loss: 2.3510920452906094

Epoch: 6| Step: 3
Training loss: 0.462780098254164
Validation loss: 2.331972770021569

Epoch: 6| Step: 4
Training loss: 0.5558030368673235
Validation loss: 2.352020538487908

Epoch: 6| Step: 5
Training loss: 0.3072945007365945
Validation loss: 2.3421272046837656

Epoch: 6| Step: 6
Training loss: 0.41726954078515394
Validation loss: 2.3410904592270265

Epoch: 6| Step: 7
Training loss: 0.2911156092169635
Validation loss: 2.296066681881812

Epoch: 6| Step: 8
Training loss: 0.49790235928472387
Validation loss: 2.3189761466212198

Epoch: 6| Step: 9
Training loss: 0.2442568006666887
Validation loss: 2.291683062348394

Epoch: 6| Step: 10
Training loss: 0.42492984375001613
Validation loss: 2.3093459501929754

Epoch: 6| Step: 11
Training loss: 0.4115510928543498
Validation loss: 2.276577594395757

Epoch: 6| Step: 12
Training loss: 0.2082972415814684
Validation loss: 2.270289147492795

Epoch: 6| Step: 13
Training loss: 0.23634783607440132
Validation loss: 2.3034507256989696

Epoch: 426| Step: 0
Training loss: 0.5986026675427104
Validation loss: 2.30723551783228

Epoch: 6| Step: 1
Training loss: 0.43911526726052713
Validation loss: 2.336143261527613

Epoch: 6| Step: 2
Training loss: 0.38605704676127134
Validation loss: 2.3444459446589243

Epoch: 6| Step: 3
Training loss: 0.3022122710843751
Validation loss: 2.3472656189274694

Epoch: 6| Step: 4
Training loss: 0.3626718023565603
Validation loss: 2.335005455138076

Epoch: 6| Step: 5
Training loss: 0.2623928555305358
Validation loss: 2.2989859095795544

Epoch: 6| Step: 6
Training loss: 0.43994597878233854
Validation loss: 2.3065576111813506

Epoch: 6| Step: 7
Training loss: 0.4221420326004708
Validation loss: 2.2971495480386075

Epoch: 6| Step: 8
Training loss: 0.40832818775762597
Validation loss: 2.3101624961291765

Epoch: 6| Step: 9
Training loss: 0.310244791186961
Validation loss: 2.26582044664357

Epoch: 6| Step: 10
Training loss: 0.23542331852137727
Validation loss: 2.2878725673853997

Epoch: 6| Step: 11
Training loss: 0.3406806812797194
Validation loss: 2.315860798272263

Epoch: 6| Step: 12
Training loss: 0.3977243736087116
Validation loss: 2.3034961377750234

Epoch: 6| Step: 13
Training loss: 0.4685430387740047
Validation loss: 2.3218941892187224

Epoch: 427| Step: 0
Training loss: 0.326885937950834
Validation loss: 2.329140739363386

Epoch: 6| Step: 1
Training loss: 0.2333159041423351
Validation loss: 2.2969277728605344

Epoch: 6| Step: 2
Training loss: 0.358153860017787
Validation loss: 2.3024152747404116

Epoch: 6| Step: 3
Training loss: 0.30526651483204864
Validation loss: 2.314919880436691

Epoch: 6| Step: 4
Training loss: 0.4734446672960887
Validation loss: 2.3184531791795777

Epoch: 6| Step: 5
Training loss: 0.40715293310121486
Validation loss: 2.322899926010002

Epoch: 6| Step: 6
Training loss: 0.6418990051030051
Validation loss: 2.334012970483401

Epoch: 6| Step: 7
Training loss: 0.4584277084750714
Validation loss: 2.34630950196517

Epoch: 6| Step: 8
Training loss: 0.17913213196496708
Validation loss: 2.3445093337248535

Epoch: 6| Step: 9
Training loss: 0.2534852278579316
Validation loss: 2.3698663143790824

Epoch: 6| Step: 10
Training loss: 0.36638655457095665
Validation loss: 2.34900839107228

Epoch: 6| Step: 11
Training loss: 0.44623904292227967
Validation loss: 2.385068756739055

Epoch: 6| Step: 12
Training loss: 0.3793128673195298
Validation loss: 2.360671377966122

Epoch: 6| Step: 13
Training loss: 0.14756476302917987
Validation loss: 2.349597580262916

Epoch: 428| Step: 0
Training loss: 0.39417133343993915
Validation loss: 2.32786451788768

Epoch: 6| Step: 1
Training loss: 0.4375987111857629
Validation loss: 2.3221603675077778

Epoch: 6| Step: 2
Training loss: 0.22119649245454326
Validation loss: 2.3225282875698867

Epoch: 6| Step: 3
Training loss: 0.26828549852156514
Validation loss: 2.3071856419613006

Epoch: 6| Step: 4
Training loss: 0.27360513180903046
Validation loss: 2.3135516755486853

Epoch: 6| Step: 5
Training loss: 0.4620192329410097
Validation loss: 2.2898273667792557

Epoch: 6| Step: 6
Training loss: 0.23087922412723608
Validation loss: 2.304792591644596

Epoch: 6| Step: 7
Training loss: 0.49617436272176646
Validation loss: 2.3031928164058155

Epoch: 6| Step: 8
Training loss: 0.32242819413614804
Validation loss: 2.3138961512957397

Epoch: 6| Step: 9
Training loss: 0.2744256421018325
Validation loss: 2.3038491113391055

Epoch: 6| Step: 10
Training loss: 0.2560224522974471
Validation loss: 2.3292021675522188

Epoch: 6| Step: 11
Training loss: 0.40274829340951457
Validation loss: 2.335723616387513

Epoch: 6| Step: 12
Training loss: 0.3257014485602219
Validation loss: 2.2830788994113345

Epoch: 6| Step: 13
Training loss: 0.7156822831327929
Validation loss: 2.2641241175072735

Epoch: 429| Step: 0
Training loss: 0.3234112000944949
Validation loss: 2.2876051159735313

Epoch: 6| Step: 1
Training loss: 0.7278586690499784
Validation loss: 2.29523256215274

Epoch: 6| Step: 2
Training loss: 0.293857345852337
Validation loss: 2.294530408953935

Epoch: 6| Step: 3
Training loss: 0.2626832867106822
Validation loss: 2.3145369028962315

Epoch: 6| Step: 4
Training loss: 0.32446024989078925
Validation loss: 2.3124254187497106

Epoch: 6| Step: 5
Training loss: 0.45221137974342474
Validation loss: 2.305116472041846

Epoch: 6| Step: 6
Training loss: 0.3974961398794974
Validation loss: 2.298539638962314

Epoch: 6| Step: 7
Training loss: 0.3828111959941219
Validation loss: 2.303385676363883

Epoch: 6| Step: 8
Training loss: 0.1799521466892946
Validation loss: 2.2937571671847734

Epoch: 6| Step: 9
Training loss: 0.41185830590390726
Validation loss: 2.3248454844760342

Epoch: 6| Step: 10
Training loss: 0.18062386967790414
Validation loss: 2.3151402044947815

Epoch: 6| Step: 11
Training loss: 0.2779133950750552
Validation loss: 2.3076199520902163

Epoch: 6| Step: 12
Training loss: 0.4353024605211561
Validation loss: 2.2905301905249673

Epoch: 6| Step: 13
Training loss: 0.17973703240730984
Validation loss: 2.3153732296450733

Epoch: 430| Step: 0
Training loss: 0.585653592310404
Validation loss: 2.348960251003958

Epoch: 6| Step: 1
Training loss: 0.2965520055379217
Validation loss: 2.347492071886612

Epoch: 6| Step: 2
Training loss: 0.6910154455862896
Validation loss: 2.36509741031801

Epoch: 6| Step: 3
Training loss: 0.48099275253014623
Validation loss: 2.389111090910753

Epoch: 6| Step: 4
Training loss: 0.4986820434222065
Validation loss: 2.364418977792701

Epoch: 6| Step: 5
Training loss: 0.2819775865809054
Validation loss: 2.3571948772987317

Epoch: 6| Step: 6
Training loss: 0.3547274226772741
Validation loss: 2.339961011870483

Epoch: 6| Step: 7
Training loss: 0.28373964723530554
Validation loss: 2.3086927402538184

Epoch: 6| Step: 8
Training loss: 0.3814756835472382
Validation loss: 2.2420092078730773

Epoch: 6| Step: 9
Training loss: 0.337392274123888
Validation loss: 2.2162671354875227

Epoch: 6| Step: 10
Training loss: 0.6155235458661142
Validation loss: 2.253280943328074

Epoch: 6| Step: 11
Training loss: 0.40074255758384264
Validation loss: 2.252719965845069

Epoch: 6| Step: 12
Training loss: 0.3171711964480883
Validation loss: 2.246292758594739

Epoch: 6| Step: 13
Training loss: 0.35538165104828084
Validation loss: 2.2737457976364737

Epoch: 431| Step: 0
Training loss: 0.3658172933165712
Validation loss: 2.2892749204416605

Epoch: 6| Step: 1
Training loss: 0.15579421801525664
Validation loss: 2.303820043531314

Epoch: 6| Step: 2
Training loss: 0.5950905573877008
Validation loss: 2.327005570215581

Epoch: 6| Step: 3
Training loss: 0.41725668458515275
Validation loss: 2.286607824084214

Epoch: 6| Step: 4
Training loss: 0.3763419419488868
Validation loss: 2.3031201455267185

Epoch: 6| Step: 5
Training loss: 0.3164837353807482
Validation loss: 2.3390761985319872

Epoch: 6| Step: 6
Training loss: 0.3157484610973862
Validation loss: 2.308671343287709

Epoch: 6| Step: 7
Training loss: 0.29314431334274016
Validation loss: 2.3048743788014368

Epoch: 6| Step: 8
Training loss: 0.3527177901820628
Validation loss: 2.3309844348778253

Epoch: 6| Step: 9
Training loss: 0.3080692542023131
Validation loss: 2.320353885802357

Epoch: 6| Step: 10
Training loss: 0.5268897185979184
Validation loss: 2.293098326554836

Epoch: 6| Step: 11
Training loss: 0.2822011520403794
Validation loss: 2.318137381756941

Epoch: 6| Step: 12
Training loss: 0.27907027542371593
Validation loss: 2.2715654219484356

Epoch: 6| Step: 13
Training loss: 0.2821868551760178
Validation loss: 2.282922520749986

Epoch: 432| Step: 0
Training loss: 0.30641335976622847
Validation loss: 2.326115308664319

Epoch: 6| Step: 1
Training loss: 0.497696727262348
Validation loss: 2.3258202798010257

Epoch: 6| Step: 2
Training loss: 0.4295665570759485
Validation loss: 2.2887960176160926

Epoch: 6| Step: 3
Training loss: 0.3328914718778304
Validation loss: 2.288539612982591

Epoch: 6| Step: 4
Training loss: 0.5723020782838233
Validation loss: 2.3229855259072307

Epoch: 6| Step: 5
Training loss: 0.31421217364728177
Validation loss: 2.3133638936179994

Epoch: 6| Step: 6
Training loss: 0.23677112893722302
Validation loss: 2.318822136867375

Epoch: 6| Step: 7
Training loss: 0.4575938975537065
Validation loss: 2.3278144045076883

Epoch: 6| Step: 8
Training loss: 0.40425526132975675
Validation loss: 2.368093507758287

Epoch: 6| Step: 9
Training loss: 0.2722485716198178
Validation loss: 2.2968544137688043

Epoch: 6| Step: 10
Training loss: 0.243440096037003
Validation loss: 2.3324498321903

Epoch: 6| Step: 11
Training loss: 0.42819232898528764
Validation loss: 2.287426711361486

Epoch: 6| Step: 12
Training loss: 0.1630480031192431
Validation loss: 2.238000519239595

Epoch: 6| Step: 13
Training loss: 0.27704108204098393
Validation loss: 2.2881706415773766

Epoch: 433| Step: 0
Training loss: 0.3301155701113418
Validation loss: 2.2743555162166045

Epoch: 6| Step: 1
Training loss: 0.4066422842616694
Validation loss: 2.265659429043172

Epoch: 6| Step: 2
Training loss: 0.33323579965643646
Validation loss: 2.2939748608163795

Epoch: 6| Step: 3
Training loss: 0.18627205730884142
Validation loss: 2.3052127662953668

Epoch: 6| Step: 4
Training loss: 0.2198977841721856
Validation loss: 2.350240375859558

Epoch: 6| Step: 5
Training loss: 0.3117380628602378
Validation loss: 2.32745281039778

Epoch: 6| Step: 6
Training loss: 0.6505972273484611
Validation loss: 2.3005579561456275

Epoch: 6| Step: 7
Training loss: 0.32750450229462
Validation loss: 2.2777084863112544

Epoch: 6| Step: 8
Training loss: 0.16998599475958828
Validation loss: 2.3036895565813698

Epoch: 6| Step: 9
Training loss: 0.2749248380249301
Validation loss: 2.2978264419704533

Epoch: 6| Step: 10
Training loss: 0.5123953386761793
Validation loss: 2.2877020335746776

Epoch: 6| Step: 11
Training loss: 0.5011984647861298
Validation loss: 2.279287235866571

Epoch: 6| Step: 12
Training loss: 0.20251374707242709
Validation loss: 2.281729633852662

Epoch: 6| Step: 13
Training loss: 0.4267062018500506
Validation loss: 2.2834403681280775

Epoch: 434| Step: 0
Training loss: 0.2976905512632354
Validation loss: 2.279884210194074

Epoch: 6| Step: 1
Training loss: 0.25463596536399463
Validation loss: 2.3258599798325994

Epoch: 6| Step: 2
Training loss: 0.26299954633528594
Validation loss: 2.241258848877779

Epoch: 6| Step: 3
Training loss: 0.22798605632913657
Validation loss: 2.2996889341853075

Epoch: 6| Step: 4
Training loss: 0.3141104685271883
Validation loss: 2.2943651556775024

Epoch: 6| Step: 5
Training loss: 0.4357134239726512
Validation loss: 2.279022624047386

Epoch: 6| Step: 6
Training loss: 0.4127735372517764
Validation loss: 2.2914179017154908

Epoch: 6| Step: 7
Training loss: 0.4045315489872859
Validation loss: 2.352890076525746

Epoch: 6| Step: 8
Training loss: 0.11708168974952503
Validation loss: 2.3480210730509556

Epoch: 6| Step: 9
Training loss: 0.28216479460406363
Validation loss: 2.3620361107079497

Epoch: 6| Step: 10
Training loss: 0.3522996274299449
Validation loss: 2.3265428956069854

Epoch: 6| Step: 11
Training loss: 0.4058956471482088
Validation loss: 2.3413594272909592

Epoch: 6| Step: 12
Training loss: 0.6638260139790025
Validation loss: 2.3865707982922144

Epoch: 6| Step: 13
Training loss: 0.30392479190306254
Validation loss: 2.336417702740954

Epoch: 435| Step: 0
Training loss: 0.3335929495379741
Validation loss: 2.37477872753606

Epoch: 6| Step: 1
Training loss: 0.19302381432570168
Validation loss: 2.3704766643968105

Epoch: 6| Step: 2
Training loss: 0.3443775084831693
Validation loss: 2.353030677095441

Epoch: 6| Step: 3
Training loss: 0.2582884931616036
Validation loss: 2.354730439657572

Epoch: 6| Step: 4
Training loss: 0.20679037008225565
Validation loss: 2.338735524219661

Epoch: 6| Step: 5
Training loss: 0.12702533428968
Validation loss: 2.347298178823519

Epoch: 6| Step: 6
Training loss: 0.2680547881952699
Validation loss: 2.319891815150757

Epoch: 6| Step: 7
Training loss: 0.42517287861452996
Validation loss: 2.2848826490442065

Epoch: 6| Step: 8
Training loss: 0.5832533327376159
Validation loss: 2.280940796960832

Epoch: 6| Step: 9
Training loss: 0.4593618747886197
Validation loss: 2.2978021233493386

Epoch: 6| Step: 10
Training loss: 0.4221844774274963
Validation loss: 2.2983551111678047

Epoch: 6| Step: 11
Training loss: 0.20607243140599504
Validation loss: 2.3192360794858686

Epoch: 6| Step: 12
Training loss: 0.3011676486222205
Validation loss: 2.3262875756863193

Epoch: 6| Step: 13
Training loss: 0.4889694247175003
Validation loss: 2.3194953178561146

Epoch: 436| Step: 0
Training loss: 0.15297983109937144
Validation loss: 2.378850691916249

Epoch: 6| Step: 1
Training loss: 0.5643892615069938
Validation loss: 2.297653965763503

Epoch: 6| Step: 2
Training loss: 0.25328049946131925
Validation loss: 2.3326243119528725

Epoch: 6| Step: 3
Training loss: 0.3161673409165382
Validation loss: 2.335752648811706

Epoch: 6| Step: 4
Training loss: 0.20459447778083192
Validation loss: 2.319439009806485

Epoch: 6| Step: 5
Training loss: 0.3035593175676084
Validation loss: 2.3400977617562786

Epoch: 6| Step: 6
Training loss: 0.5539968247064423
Validation loss: 2.3297166467534987

Epoch: 6| Step: 7
Training loss: 0.4041369578005058
Validation loss: 2.3036941737548546

Epoch: 6| Step: 8
Training loss: 0.2367449308464982
Validation loss: 2.307251118057121

Epoch: 6| Step: 9
Training loss: 0.2987178898358085
Validation loss: 2.267478305368124

Epoch: 6| Step: 10
Training loss: 0.39084123348610267
Validation loss: 2.28870018470126

Epoch: 6| Step: 11
Training loss: 0.3016167468361893
Validation loss: 2.313235198456048

Epoch: 6| Step: 12
Training loss: 0.3580018637704551
Validation loss: 2.331983590840986

Epoch: 6| Step: 13
Training loss: 0.1301918011342628
Validation loss: 2.3550705707610486

Epoch: 437| Step: 0
Training loss: 0.3847752874874845
Validation loss: 2.3760642509884895

Epoch: 6| Step: 1
Training loss: 0.34398248786763835
Validation loss: 2.371216007452848

Epoch: 6| Step: 2
Training loss: 0.4205805204036776
Validation loss: 2.3983288854897404

Epoch: 6| Step: 3
Training loss: 0.4523251149188316
Validation loss: 2.3475226017752653

Epoch: 6| Step: 4
Training loss: 0.5297757055608672
Validation loss: 2.327961267006378

Epoch: 6| Step: 5
Training loss: 0.22325445426820395
Validation loss: 2.3423394304362453

Epoch: 6| Step: 6
Training loss: 0.3164899150294758
Validation loss: 2.3014712169722897

Epoch: 6| Step: 7
Training loss: 0.10578510733802234
Validation loss: 2.2635786150612205

Epoch: 6| Step: 8
Training loss: 0.4146695455532218
Validation loss: 2.300439791254728

Epoch: 6| Step: 9
Training loss: 0.3501109143331109
Validation loss: 2.2828805411486948

Epoch: 6| Step: 10
Training loss: 0.325080083645414
Validation loss: 2.3042629656702496

Epoch: 6| Step: 11
Training loss: 0.2857020915145478
Validation loss: 2.298817351080041

Epoch: 6| Step: 12
Training loss: 0.3639237045157586
Validation loss: 2.3173166590919263

Epoch: 6| Step: 13
Training loss: 0.17811745451957325
Validation loss: 2.2781828774899577

Epoch: 438| Step: 0
Training loss: 0.2314652703931258
Validation loss: 2.2928375247399515

Epoch: 6| Step: 1
Training loss: 0.4348013274553314
Validation loss: 2.2585445113998217

Epoch: 6| Step: 2
Training loss: 0.18040280396398015
Validation loss: 2.3097707967039414

Epoch: 6| Step: 3
Training loss: 0.40773158238937107
Validation loss: 2.253893926008163

Epoch: 6| Step: 4
Training loss: 0.3544537021564159
Validation loss: 2.256413544107785

Epoch: 6| Step: 5
Training loss: 0.4129789137121783
Validation loss: 2.251658757374419

Epoch: 6| Step: 6
Training loss: 0.3447238284426758
Validation loss: 2.296291397440288

Epoch: 6| Step: 7
Training loss: 0.4718322507175937
Validation loss: 2.2704241544757413

Epoch: 6| Step: 8
Training loss: 0.1643002354363933
Validation loss: 2.2673052968764784

Epoch: 6| Step: 9
Training loss: 0.20696472502672036
Validation loss: 2.300606923214437

Epoch: 6| Step: 10
Training loss: 0.5121066246860887
Validation loss: 2.2842234507302908

Epoch: 6| Step: 11
Training loss: 0.4040833429918834
Validation loss: 2.286617676488383

Epoch: 6| Step: 12
Training loss: 0.1865604423843986
Validation loss: 2.347791564556914

Epoch: 6| Step: 13
Training loss: 0.40884090410172325
Validation loss: 2.3525609387983755

Epoch: 439| Step: 0
Training loss: 0.24592613385412124
Validation loss: 2.3239481886282864

Epoch: 6| Step: 1
Training loss: 0.3682909273891896
Validation loss: 2.325639297269394

Epoch: 6| Step: 2
Training loss: 0.23328879107214245
Validation loss: 2.2930033554459666

Epoch: 6| Step: 3
Training loss: 0.5547893860421867
Validation loss: 2.268549636051841

Epoch: 6| Step: 4
Training loss: 0.34927029922600755
Validation loss: 2.2785177755395

Epoch: 6| Step: 5
Training loss: 0.2099021296980588
Validation loss: 2.2919026806098133

Epoch: 6| Step: 6
Training loss: 0.45316460863831365
Validation loss: 2.2679530114165956

Epoch: 6| Step: 7
Training loss: 0.25050336111977495
Validation loss: 2.2564496014746513

Epoch: 6| Step: 8
Training loss: 0.4654322513280794
Validation loss: 2.2480642156389288

Epoch: 6| Step: 9
Training loss: 0.295408088109367
Validation loss: 2.245935117479786

Epoch: 6| Step: 10
Training loss: 0.1574678879123958
Validation loss: 2.235417281336338

Epoch: 6| Step: 11
Training loss: 0.33843337552277536
Validation loss: 2.1949673777208467

Epoch: 6| Step: 12
Training loss: 0.5947087477848705
Validation loss: 2.225384722350053

Epoch: 6| Step: 13
Training loss: 0.18291819850595928
Validation loss: 2.252342447249754

Epoch: 440| Step: 0
Training loss: 0.4498840215689425
Validation loss: 2.2386255592006608

Epoch: 6| Step: 1
Training loss: 0.35382711270979905
Validation loss: 2.1981042947967024

Epoch: 6| Step: 2
Training loss: 0.4261102542681384
Validation loss: 2.2252324378679305

Epoch: 6| Step: 3
Training loss: 0.45200202169641374
Validation loss: 2.2543842471862985

Epoch: 6| Step: 4
Training loss: 0.4084457698413847
Validation loss: 2.2358580306611384

Epoch: 6| Step: 5
Training loss: 0.31100537982500875
Validation loss: 2.2470470269907805

Epoch: 6| Step: 6
Training loss: 0.29645855455709763
Validation loss: 2.275607679987981

Epoch: 6| Step: 7
Training loss: 0.2985265369312785
Validation loss: 2.2828939338286824

Epoch: 6| Step: 8
Training loss: 0.30047034010761475
Validation loss: 2.3198143407814786

Epoch: 6| Step: 9
Training loss: 0.5600806234428795
Validation loss: 2.3669339291949227

Epoch: 6| Step: 10
Training loss: 0.2845947406994922
Validation loss: 2.3457168611896493

Epoch: 6| Step: 11
Training loss: 0.2287001313247312
Validation loss: 2.3107963989466223

Epoch: 6| Step: 12
Training loss: 0.3857643990218098
Validation loss: 2.3032130476809423

Epoch: 6| Step: 13
Training loss: 0.38925340174325984
Validation loss: 2.295663723646081

Epoch: 441| Step: 0
Training loss: 0.1713953151883612
Validation loss: 2.2438012535348837

Epoch: 6| Step: 1
Training loss: 0.41710805958113356
Validation loss: 2.297484845351775

Epoch: 6| Step: 2
Training loss: 0.3090084283583559
Validation loss: 2.2987936485014315

Epoch: 6| Step: 3
Training loss: 0.48256952906482936
Validation loss: 2.3429177565631187

Epoch: 6| Step: 4
Training loss: 0.41726793378181576
Validation loss: 2.3205607352482516

Epoch: 6| Step: 5
Training loss: 0.28614266804982447
Validation loss: 2.3043593284092525

Epoch: 6| Step: 6
Training loss: 0.38968522512449505
Validation loss: 2.2588561990675577

Epoch: 6| Step: 7
Training loss: 0.5262257345227533
Validation loss: 2.2707689480677473

Epoch: 6| Step: 8
Training loss: 0.3924535677105785
Validation loss: 2.292790156711221

Epoch: 6| Step: 9
Training loss: 0.19014445731427665
Validation loss: 2.2680318018068704

Epoch: 6| Step: 10
Training loss: 0.45724381288416865
Validation loss: 2.3089493551441667

Epoch: 6| Step: 11
Training loss: 0.3050362962481819
Validation loss: 2.3229075830378467

Epoch: 6| Step: 12
Training loss: 0.2170131738439012
Validation loss: 2.3213953810262673

Epoch: 6| Step: 13
Training loss: 0.26891343170896176
Validation loss: 2.332567919678138

Epoch: 442| Step: 0
Training loss: 0.35069417743651715
Validation loss: 2.3469345148802745

Epoch: 6| Step: 1
Training loss: 0.2078397456930356
Validation loss: 2.310792696813601

Epoch: 6| Step: 2
Training loss: 0.3256563235279978
Validation loss: 2.3317435334052012

Epoch: 6| Step: 3
Training loss: 0.32445759765349236
Validation loss: 2.3299849659811755

Epoch: 6| Step: 4
Training loss: 0.30558183435423164
Validation loss: 2.291115672377233

Epoch: 6| Step: 5
Training loss: 0.2572699965619045
Validation loss: 2.301330348231141

Epoch: 6| Step: 6
Training loss: 0.4699395186741998
Validation loss: 2.2930719023598254

Epoch: 6| Step: 7
Training loss: 0.4036941273829322
Validation loss: 2.285839462552739

Epoch: 6| Step: 8
Training loss: 0.430576687554
Validation loss: 2.287703313320354

Epoch: 6| Step: 9
Training loss: 0.2868009974204959
Validation loss: 2.301094332910399

Epoch: 6| Step: 10
Training loss: 0.31494773444390245
Validation loss: 2.3161632498437776

Epoch: 6| Step: 11
Training loss: 0.2528322245632831
Validation loss: 2.303315452428041

Epoch: 6| Step: 12
Training loss: 0.40119176590590777
Validation loss: 2.3250920388974805

Epoch: 6| Step: 13
Training loss: 0.19019536983405294
Validation loss: 2.3091992970642954

Epoch: 443| Step: 0
Training loss: 0.2738429469560748
Validation loss: 2.3433456509630397

Epoch: 6| Step: 1
Training loss: 0.2883037067340104
Validation loss: 2.3614914899163013

Epoch: 6| Step: 2
Training loss: 0.593915640162878
Validation loss: 2.371303655759959

Epoch: 6| Step: 3
Training loss: 0.21008357525072263
Validation loss: 2.3687530466475115

Epoch: 6| Step: 4
Training loss: 0.41857016601992836
Validation loss: 2.347173318472598

Epoch: 6| Step: 5
Training loss: 0.28175687150098644
Validation loss: 2.33617341408731

Epoch: 6| Step: 6
Training loss: 0.2096847491929567
Validation loss: 2.33830502872198

Epoch: 6| Step: 7
Training loss: 0.3856591630267249
Validation loss: 2.3583881705162186

Epoch: 6| Step: 8
Training loss: 0.23193653305600495
Validation loss: 2.352992246642551

Epoch: 6| Step: 9
Training loss: 0.36918008179684425
Validation loss: 2.317411379417705

Epoch: 6| Step: 10
Training loss: 0.38654998025071324
Validation loss: 2.316405273862279

Epoch: 6| Step: 11
Training loss: 0.22422608552955575
Validation loss: 2.3179819655973715

Epoch: 6| Step: 12
Training loss: 0.37384323679515624
Validation loss: 2.311109520023157

Epoch: 6| Step: 13
Training loss: 0.19634359940106136
Validation loss: 2.3243286250232895

Epoch: 444| Step: 0
Training loss: 0.40347157890646435
Validation loss: 2.3202001514693538

Epoch: 6| Step: 1
Training loss: 0.5440745448444981
Validation loss: 2.328880235461253

Epoch: 6| Step: 2
Training loss: 0.39204837869601555
Validation loss: 2.3271239207472396

Epoch: 6| Step: 3
Training loss: 0.3031349239494579
Validation loss: 2.3316771860162535

Epoch: 6| Step: 4
Training loss: 0.4756100626942122
Validation loss: 2.3325575285576177

Epoch: 6| Step: 5
Training loss: 0.3035303787317912
Validation loss: 2.3733417224678157

Epoch: 6| Step: 6
Training loss: 0.175738000847439
Validation loss: 2.2995110835678414

Epoch: 6| Step: 7
Training loss: 0.21256114241377655
Validation loss: 2.320702535585414

Epoch: 6| Step: 8
Training loss: 0.32188754011003345
Validation loss: 2.3085250176586167

Epoch: 6| Step: 9
Training loss: 0.30034612169719505
Validation loss: 2.2747864147516217

Epoch: 6| Step: 10
Training loss: 0.33009153259855784
Validation loss: 2.273830433847848

Epoch: 6| Step: 11
Training loss: 0.34948587633827705
Validation loss: 2.3158901942726895

Epoch: 6| Step: 12
Training loss: 0.21039135307755474
Validation loss: 2.2900970136099987

Epoch: 6| Step: 13
Training loss: 0.3180677330169787
Validation loss: 2.322361314707893

Epoch: 445| Step: 0
Training loss: 0.3559438234660073
Validation loss: 2.34642299801392

Epoch: 6| Step: 1
Training loss: 0.2870273213333119
Validation loss: 2.3483162613981214

Epoch: 6| Step: 2
Training loss: 0.3967919495560976
Validation loss: 2.3609253455798136

Epoch: 6| Step: 3
Training loss: 0.4999675293154133
Validation loss: 2.344211740711318

Epoch: 6| Step: 4
Training loss: 0.3727690575958058
Validation loss: 2.29841868611482

Epoch: 6| Step: 5
Training loss: 0.435412843891258
Validation loss: 2.325571843124918

Epoch: 6| Step: 6
Training loss: 0.26447129743562364
Validation loss: 2.2868139482968193

Epoch: 6| Step: 7
Training loss: 0.1904164627569374
Validation loss: 2.274625708373353

Epoch: 6| Step: 8
Training loss: 0.3412735775079102
Validation loss: 2.2891195250169893

Epoch: 6| Step: 9
Training loss: 0.09560922473079607
Validation loss: 2.2655473864835893

Epoch: 6| Step: 10
Training loss: 0.3358577034680835
Validation loss: 2.281605392645183

Epoch: 6| Step: 11
Training loss: 0.23615739503537198
Validation loss: 2.330269353931076

Epoch: 6| Step: 12
Training loss: 0.3532036832903335
Validation loss: 2.2791551632605955

Epoch: 6| Step: 13
Training loss: 0.1168215401865015
Validation loss: 2.3195797922880907

Epoch: 446| Step: 0
Training loss: 0.173163810857155
Validation loss: 2.2985827980998876

Epoch: 6| Step: 1
Training loss: 0.16694856932890492
Validation loss: 2.306915329918339

Epoch: 6| Step: 2
Training loss: 0.41723625669707554
Validation loss: 2.2865970119250103

Epoch: 6| Step: 3
Training loss: 0.23651745203510452
Validation loss: 2.315317056084617

Epoch: 6| Step: 4
Training loss: 0.3619326097292742
Validation loss: 2.304725943930049

Epoch: 6| Step: 5
Training loss: 0.2756562135932292
Validation loss: 2.294171599426732

Epoch: 6| Step: 6
Training loss: 0.4234294158614291
Validation loss: 2.2998494163608307

Epoch: 6| Step: 7
Training loss: 0.2235492816826694
Validation loss: 2.327570027403048

Epoch: 6| Step: 8
Training loss: 0.3759233115000831
Validation loss: 2.3061881542542193

Epoch: 6| Step: 9
Training loss: 0.3127000883406053
Validation loss: 2.27178894291629

Epoch: 6| Step: 10
Training loss: 0.3505820271478477
Validation loss: 2.295455472758481

Epoch: 6| Step: 11
Training loss: 0.3087166288040212
Validation loss: 2.320135365109546

Epoch: 6| Step: 12
Training loss: 0.3817060010469776
Validation loss: 2.3287755675658257

Epoch: 6| Step: 13
Training loss: 0.19643193828806033
Validation loss: 2.3184859944313168

Epoch: 447| Step: 0
Training loss: 0.287189939444956
Validation loss: 2.3227545425372194

Epoch: 6| Step: 1
Training loss: 0.28696193931828234
Validation loss: 2.34257052697139

Epoch: 6| Step: 2
Training loss: 0.4048869300702838
Validation loss: 2.3272352041297246

Epoch: 6| Step: 3
Training loss: 0.3323902545418157
Validation loss: 2.343011849496442

Epoch: 6| Step: 4
Training loss: 0.5498155284510685
Validation loss: 2.3339781597142397

Epoch: 6| Step: 5
Training loss: 0.15320357355210673
Validation loss: 2.3038245018727093

Epoch: 6| Step: 6
Training loss: 0.14002727262062187
Validation loss: 2.2825186642356763

Epoch: 6| Step: 7
Training loss: 0.19674655872277683
Validation loss: 2.2932660578357162

Epoch: 6| Step: 8
Training loss: 0.18737325755703085
Validation loss: 2.2917433132058593

Epoch: 6| Step: 9
Training loss: 0.2847142386415574
Validation loss: 2.315494705720941

Epoch: 6| Step: 10
Training loss: 0.41997996083773365
Validation loss: 2.308721421360454

Epoch: 6| Step: 11
Training loss: 0.20208432383310934
Validation loss: 2.3160370258870797

Epoch: 6| Step: 12
Training loss: 0.24270238289203575
Validation loss: 2.320313439138198

Epoch: 6| Step: 13
Training loss: 0.4196745920646159
Validation loss: 2.3443109017537918

Epoch: 448| Step: 0
Training loss: 0.2898647927925401
Validation loss: 2.326365961818849

Epoch: 6| Step: 1
Training loss: 0.2949442191849021
Validation loss: 2.341635336206691

Epoch: 6| Step: 2
Training loss: 0.1743660543567239
Validation loss: 2.3146792660840436

Epoch: 6| Step: 3
Training loss: 0.32008454887828386
Validation loss: 2.3203819487968746

Epoch: 6| Step: 4
Training loss: 0.6163191904297307
Validation loss: 2.3224901620525435

Epoch: 6| Step: 5
Training loss: 0.25975112587755445
Validation loss: 2.3567902243253904

Epoch: 6| Step: 6
Training loss: 0.3273733931345793
Validation loss: 2.3352219860395227

Epoch: 6| Step: 7
Training loss: 0.2436932775938155
Validation loss: 2.3259789336808603

Epoch: 6| Step: 8
Training loss: 0.2709359042022771
Validation loss: 2.328390797403402

Epoch: 6| Step: 9
Training loss: 0.24588520053810123
Validation loss: 2.3241724671653414

Epoch: 6| Step: 10
Training loss: 0.2322089157265461
Validation loss: 2.2870590904860926

Epoch: 6| Step: 11
Training loss: 0.46065493182340544
Validation loss: 2.337094012868227

Epoch: 6| Step: 12
Training loss: 0.1942306309915241
Validation loss: 2.345618929039304

Epoch: 6| Step: 13
Training loss: 0.30325758236842604
Validation loss: 2.3437493546461083

Epoch: 449| Step: 0
Training loss: 0.23985883000585087
Validation loss: 2.3299558138258813

Epoch: 6| Step: 1
Training loss: 0.2557495988244185
Validation loss: 2.323873188226268

Epoch: 6| Step: 2
Training loss: 0.4714754819623892
Validation loss: 2.3148450072540174

Epoch: 6| Step: 3
Training loss: 0.202674522090874
Validation loss: 2.3173654960615675

Epoch: 6| Step: 4
Training loss: 0.1959405148348752
Validation loss: 2.3043117455341804

Epoch: 6| Step: 5
Training loss: 0.35408275909912945
Validation loss: 2.2981568984542813

Epoch: 6| Step: 6
Training loss: 0.3571669706650967
Validation loss: 2.303887203165653

Epoch: 6| Step: 7
Training loss: 0.38705782041796105
Validation loss: 2.3274015216611645

Epoch: 6| Step: 8
Training loss: 0.3662407011016874
Validation loss: 2.309402541520419

Epoch: 6| Step: 9
Training loss: 0.3749114965269038
Validation loss: 2.3099785105879387

Epoch: 6| Step: 10
Training loss: 0.40008903868437723
Validation loss: 2.3393750952368575

Epoch: 6| Step: 11
Training loss: 0.19540776790320347
Validation loss: 2.331835454595688

Epoch: 6| Step: 12
Training loss: 0.12460344339321965
Validation loss: 2.330243804509253

Epoch: 6| Step: 13
Training loss: 0.14163262914359237
Validation loss: 2.3151826538732667

Epoch: 450| Step: 0
Training loss: 0.14393920393758042
Validation loss: 2.324686007203854

Epoch: 6| Step: 1
Training loss: 0.2698552492449312
Validation loss: 2.3491568969273837

Epoch: 6| Step: 2
Training loss: 0.42780996551766054
Validation loss: 2.344587241864443

Epoch: 6| Step: 3
Training loss: 0.3523989369887839
Validation loss: 2.319708476951493

Epoch: 6| Step: 4
Training loss: 0.4920377503514153
Validation loss: 2.327150254075896

Epoch: 6| Step: 5
Training loss: 0.2348858193985853
Validation loss: 2.2830583050012367

Epoch: 6| Step: 6
Training loss: 0.3209813392249374
Validation loss: 2.3129328505816646

Epoch: 6| Step: 7
Training loss: 0.21384182435578647
Validation loss: 2.3407939128205113

Epoch: 6| Step: 8
Training loss: 0.17138293661525272
Validation loss: 2.355634626044463

Epoch: 6| Step: 9
Training loss: 0.39978288256543626
Validation loss: 2.340332693429778

Epoch: 6| Step: 10
Training loss: 0.29530919138755407
Validation loss: 2.3626964659504095

Epoch: 6| Step: 11
Training loss: 0.22814075173904247
Validation loss: 2.364735349671258

Epoch: 6| Step: 12
Training loss: 0.33364291889626035
Validation loss: 2.354274987565413

Epoch: 6| Step: 13
Training loss: 0.1963160102527976
Validation loss: 2.3891379846637704

Epoch: 451| Step: 0
Training loss: 0.32490754784055803
Validation loss: 2.3924480840364803

Epoch: 6| Step: 1
Training loss: 0.17843875064511783
Validation loss: 2.352895684540654

Epoch: 6| Step: 2
Training loss: 0.4669910968558779
Validation loss: 2.333697182073861

Epoch: 6| Step: 3
Training loss: 0.23831919852576194
Validation loss: 2.3476226341771915

Epoch: 6| Step: 4
Training loss: 0.2409079343563948
Validation loss: 2.3570188141800044

Epoch: 6| Step: 5
Training loss: 0.4036016706692963
Validation loss: 2.32770275618065

Epoch: 6| Step: 6
Training loss: 0.14330393111443124
Validation loss: 2.3465719766678252

Epoch: 6| Step: 7
Training loss: 0.4855742682342994
Validation loss: 2.32877029006837

Epoch: 6| Step: 8
Training loss: 0.27082324314883954
Validation loss: 2.3448043923556487

Epoch: 6| Step: 9
Training loss: 0.2655705368080995
Validation loss: 2.3618349223769273

Epoch: 6| Step: 10
Training loss: 0.2551085250988932
Validation loss: 2.31185125415288

Epoch: 6| Step: 11
Training loss: 0.37651051839191335
Validation loss: 2.30874124552778

Epoch: 6| Step: 12
Training loss: 0.3553032961603659
Validation loss: 2.287979813490423

Epoch: 6| Step: 13
Training loss: 0.17162469497397947
Validation loss: 2.297346796474836

Epoch: 452| Step: 0
Training loss: 0.1932787486279159
Validation loss: 2.2637823218894635

Epoch: 6| Step: 1
Training loss: 0.17850508585731548
Validation loss: 2.295268330810508

Epoch: 6| Step: 2
Training loss: 0.332262811135352
Validation loss: 2.3276026540959425

Epoch: 6| Step: 3
Training loss: 0.2872575649928647
Validation loss: 2.324190656120446

Epoch: 6| Step: 4
Training loss: 0.5231677256902885
Validation loss: 2.3345706046440866

Epoch: 6| Step: 5
Training loss: 0.26493189647352433
Validation loss: 2.3349433836129556

Epoch: 6| Step: 6
Training loss: 0.48456598946466145
Validation loss: 2.3649039145817823

Epoch: 6| Step: 7
Training loss: 0.26289557158987176
Validation loss: 2.409142023972288

Epoch: 6| Step: 8
Training loss: 0.16338117225110735
Validation loss: 2.362513547876832

Epoch: 6| Step: 9
Training loss: 0.35737628333310634
Validation loss: 2.412846020169775

Epoch: 6| Step: 10
Training loss: 0.23616403605190192
Validation loss: 2.3677302497467436

Epoch: 6| Step: 11
Training loss: 0.10443442967688321
Validation loss: 2.37032267938292

Epoch: 6| Step: 12
Training loss: 0.33678124062555037
Validation loss: 2.374507224704273

Epoch: 6| Step: 13
Training loss: 0.15005354447157118
Validation loss: 2.349266775416983

Epoch: 453| Step: 0
Training loss: 0.20673603026002974
Validation loss: 2.305537712959521

Epoch: 6| Step: 1
Training loss: 0.3305543026757917
Validation loss: 2.2920991524911885

Epoch: 6| Step: 2
Training loss: 0.32122796356009187
Validation loss: 2.307920991538048

Epoch: 6| Step: 3
Training loss: 0.2682566844688611
Validation loss: 2.2867406565723347

Epoch: 6| Step: 4
Training loss: 0.31760724862016
Validation loss: 2.3265133758046024

Epoch: 6| Step: 5
Training loss: 0.18914413817592476
Validation loss: 2.3697347496001235

Epoch: 6| Step: 6
Training loss: 0.2761439173034903
Validation loss: 2.3537064615309156

Epoch: 6| Step: 7
Training loss: 0.5049219761901027
Validation loss: 2.3651886909992257

Epoch: 6| Step: 8
Training loss: 0.310853674626149
Validation loss: 2.3587026403402556

Epoch: 6| Step: 9
Training loss: 0.1360143978385629
Validation loss: 2.3701081113455067

Epoch: 6| Step: 10
Training loss: 0.35957326810120405
Validation loss: 2.3321443405511157

Epoch: 6| Step: 11
Training loss: 0.39160441637782956
Validation loss: 2.346043366689047

Epoch: 6| Step: 12
Training loss: 0.2153313738408509
Validation loss: 2.3248517506422703

Epoch: 6| Step: 13
Training loss: 0.2909083328623269
Validation loss: 2.3140266310375703

Epoch: 454| Step: 0
Training loss: 0.4721874718252662
Validation loss: 2.2822473727870505

Epoch: 6| Step: 1
Training loss: 0.21123160063448707
Validation loss: 2.2649173580530535

Epoch: 6| Step: 2
Training loss: 0.3929478626501802
Validation loss: 2.3074557123542716

Epoch: 6| Step: 3
Training loss: 0.26764509657710417
Validation loss: 2.2907801859105237

Epoch: 6| Step: 4
Training loss: 0.13037147236172567
Validation loss: 2.299434313910773

Epoch: 6| Step: 5
Training loss: 0.27145165994150333
Validation loss: 2.308650693456106

Epoch: 6| Step: 6
Training loss: 0.43393570071625776
Validation loss: 2.3124895026299352

Epoch: 6| Step: 7
Training loss: 0.29768839885280435
Validation loss: 2.3404762752136583

Epoch: 6| Step: 8
Training loss: 0.24145050353064676
Validation loss: 2.3816768119147746

Epoch: 6| Step: 9
Training loss: 0.3294099557015115
Validation loss: 2.3289747458213856

Epoch: 6| Step: 10
Training loss: 0.2318471245448757
Validation loss: 2.3051281012332607

Epoch: 6| Step: 11
Training loss: 0.3502256832367474
Validation loss: 2.3181888522343987

Epoch: 6| Step: 12
Training loss: 0.2968925044269941
Validation loss: 2.2950853154916486

Epoch: 6| Step: 13
Training loss: 0.43356714940310503
Validation loss: 2.309508116825843

Epoch: 455| Step: 0
Training loss: 0.39523413337478447
Validation loss: 2.2754261084320535

Epoch: 6| Step: 1
Training loss: 0.19182900045129414
Validation loss: 2.321026547973304

Epoch: 6| Step: 2
Training loss: 0.3071601257467801
Validation loss: 2.2908787910248773

Epoch: 6| Step: 3
Training loss: 0.23478211172040436
Validation loss: 2.317302283823181

Epoch: 6| Step: 4
Training loss: 0.22222083164978723
Validation loss: 2.320691957669255

Epoch: 6| Step: 5
Training loss: 0.5176672516864746
Validation loss: 2.323457865551949

Epoch: 6| Step: 6
Training loss: 0.1880968647255473
Validation loss: 2.354685394551603

Epoch: 6| Step: 7
Training loss: 0.3600153401205935
Validation loss: 2.3784406854259164

Epoch: 6| Step: 8
Training loss: 0.26226351394235503
Validation loss: 2.3692594785022845

Epoch: 6| Step: 9
Training loss: 0.29368474570340775
Validation loss: 2.3820571022112134

Epoch: 6| Step: 10
Training loss: 0.3745984072864724
Validation loss: 2.3430847350438104

Epoch: 6| Step: 11
Training loss: 0.3379328045399772
Validation loss: 2.326589502622939

Epoch: 6| Step: 12
Training loss: 0.22897718554285784
Validation loss: 2.336222053295323

Epoch: 6| Step: 13
Training loss: 0.31378636248241476
Validation loss: 2.334993982982092

Epoch: 456| Step: 0
Training loss: 0.46944482487162137
Validation loss: 2.309106464779006

Epoch: 6| Step: 1
Training loss: 0.2925803598234543
Validation loss: 2.330635039660286

Epoch: 6| Step: 2
Training loss: 0.19218459786185527
Validation loss: 2.3387125863010136

Epoch: 6| Step: 3
Training loss: 0.34922176590199655
Validation loss: 2.3596668015424105

Epoch: 6| Step: 4
Training loss: 0.29428000421777856
Validation loss: 2.3828885103122315

Epoch: 6| Step: 5
Training loss: 0.4381906303519206
Validation loss: 2.4319190318510615

Epoch: 6| Step: 6
Training loss: 0.45710442438152105
Validation loss: 2.4130690794216907

Epoch: 6| Step: 7
Training loss: 0.17507240636730045
Validation loss: 2.3658391972933766

Epoch: 6| Step: 8
Training loss: 0.24502958578900239
Validation loss: 2.3533296348455335

Epoch: 6| Step: 9
Training loss: 0.31350453569851516
Validation loss: 2.3563950606129938

Epoch: 6| Step: 10
Training loss: 0.2855733668696985
Validation loss: 2.347286630225642

Epoch: 6| Step: 11
Training loss: 0.19813366442305763
Validation loss: 2.3447202767394324

Epoch: 6| Step: 12
Training loss: 0.1559559976714299
Validation loss: 2.330546539479022

Epoch: 6| Step: 13
Training loss: 0.3426760021523182
Validation loss: 2.337612495262013

Epoch: 457| Step: 0
Training loss: 0.19371359583112777
Validation loss: 2.3221991172155048

Epoch: 6| Step: 1
Training loss: 0.31396370467814366
Validation loss: 2.3233441254258658

Epoch: 6| Step: 2
Training loss: 0.49088053275055804
Validation loss: 2.3223200905258494

Epoch: 6| Step: 3
Training loss: 0.3653684563770236
Validation loss: 2.342609212657533

Epoch: 6| Step: 4
Training loss: 0.151498061177151
Validation loss: 2.334514399946645

Epoch: 6| Step: 5
Training loss: 0.2838193306267897
Validation loss: 2.3637007254680893

Epoch: 6| Step: 6
Training loss: 0.16980198763466386
Validation loss: 2.3539602091306007

Epoch: 6| Step: 7
Training loss: 0.1444846928847636
Validation loss: 2.3586764383646757

Epoch: 6| Step: 8
Training loss: 0.43725628535997013
Validation loss: 2.3393854675815366

Epoch: 6| Step: 9
Training loss: 0.2582893873849423
Validation loss: 2.3418996308859077

Epoch: 6| Step: 10
Training loss: 0.35604733759272084
Validation loss: 2.36027155271351

Epoch: 6| Step: 11
Training loss: 0.1731344214692074
Validation loss: 2.3647502637685216

Epoch: 6| Step: 12
Training loss: 0.27790448093912906
Validation loss: 2.3749473492540263

Epoch: 6| Step: 13
Training loss: 0.15950974957495553
Validation loss: 2.347073576033551

Epoch: 458| Step: 0
Training loss: 0.3793129458887582
Validation loss: 2.324061186046032

Epoch: 6| Step: 1
Training loss: 0.17434405259876892
Validation loss: 2.3260875049563885

Epoch: 6| Step: 2
Training loss: 0.28953746488419685
Validation loss: 2.326404026573846

Epoch: 6| Step: 3
Training loss: 0.25194750639099167
Validation loss: 2.3425358099912277

Epoch: 6| Step: 4
Training loss: 0.2632715647922417
Validation loss: 2.315821982360423

Epoch: 6| Step: 5
Training loss: 0.4315730943974616
Validation loss: 2.359003874627398

Epoch: 6| Step: 6
Training loss: 0.26803676253711317
Validation loss: 2.3011908728983985

Epoch: 6| Step: 7
Training loss: 0.21413559814142094
Validation loss: 2.317830515829445

Epoch: 6| Step: 8
Training loss: 0.27084691521016585
Validation loss: 2.3362919668165176

Epoch: 6| Step: 9
Training loss: 0.23544749603843732
Validation loss: 2.3228182233554264

Epoch: 6| Step: 10
Training loss: 0.1938785076813996
Validation loss: 2.3704557742942174

Epoch: 6| Step: 11
Training loss: 0.4302213993197368
Validation loss: 2.341480892050868

Epoch: 6| Step: 12
Training loss: 0.30581910951099794
Validation loss: 2.3478014421988456

Epoch: 6| Step: 13
Training loss: 0.17112810234200218
Validation loss: 2.383705246004374

Epoch: 459| Step: 0
Training loss: 0.12095794445785225
Validation loss: 2.349856468221202

Epoch: 6| Step: 1
Training loss: 0.1573108660325499
Validation loss: 2.3631730553459427

Epoch: 6| Step: 2
Training loss: 0.16295975240591676
Validation loss: 2.3650995608682095

Epoch: 6| Step: 3
Training loss: 0.40477376261506615
Validation loss: 2.339401687359778

Epoch: 6| Step: 4
Training loss: 0.31253838303402365
Validation loss: 2.3235704923778746

Epoch: 6| Step: 5
Training loss: 0.3393155740024955
Validation loss: 2.3337774509634786

Epoch: 6| Step: 6
Training loss: 0.2635874577773563
Validation loss: 2.327487654326925

Epoch: 6| Step: 7
Training loss: 0.1970168329420142
Validation loss: 2.3561836101672675

Epoch: 6| Step: 8
Training loss: 0.31365880689560305
Validation loss: 2.342693041854854

Epoch: 6| Step: 9
Training loss: 0.4916870206590767
Validation loss: 2.317825137093256

Epoch: 6| Step: 10
Training loss: 0.24250332943115316
Validation loss: 2.352980288000885

Epoch: 6| Step: 11
Training loss: 0.22037798638735617
Validation loss: 2.362370283775289

Epoch: 6| Step: 12
Training loss: 0.2991306419231041
Validation loss: 2.3642504216808637

Epoch: 6| Step: 13
Training loss: 0.21400788438836382
Validation loss: 2.3199796300106246

Epoch: 460| Step: 0
Training loss: 0.14960923257128755
Validation loss: 2.308054832496714

Epoch: 6| Step: 1
Training loss: 0.17276678862123357
Validation loss: 2.2996857916264237

Epoch: 6| Step: 2
Training loss: 0.2356039411458436
Validation loss: 2.3205253233054894

Epoch: 6| Step: 3
Training loss: 0.36717006966633936
Validation loss: 2.2978464884340015

Epoch: 6| Step: 4
Training loss: 0.1413556956974767
Validation loss: 2.2539004411827093

Epoch: 6| Step: 5
Training loss: 0.2899518893470918
Validation loss: 2.2759178914351996

Epoch: 6| Step: 6
Training loss: 0.2518069264497405
Validation loss: 2.2771807068209546

Epoch: 6| Step: 7
Training loss: 0.35938260858193755
Validation loss: 2.2884634795725116

Epoch: 6| Step: 8
Training loss: 0.4515020310196761
Validation loss: 2.288858477050969

Epoch: 6| Step: 9
Training loss: 0.16251739032931964
Validation loss: 2.30300909057269

Epoch: 6| Step: 10
Training loss: 0.4453478514710188
Validation loss: 2.3123565680342213

Epoch: 6| Step: 11
Training loss: 0.34194385093295204
Validation loss: 2.315158162110855

Epoch: 6| Step: 12
Training loss: 0.17248384511496312
Validation loss: 2.311262221296095

Epoch: 6| Step: 13
Training loss: 0.16893729703554414
Validation loss: 2.313393187257313

Epoch: 461| Step: 0
Training loss: 0.30347385536387766
Validation loss: 2.324843456031977

Epoch: 6| Step: 1
Training loss: 0.2630760241979295
Validation loss: 2.3335420417028585

Epoch: 6| Step: 2
Training loss: 0.26544684157472975
Validation loss: 2.3481204318765565

Epoch: 6| Step: 3
Training loss: 0.1689054794982077
Validation loss: 2.3073522802887543

Epoch: 6| Step: 4
Training loss: 0.21772663828145494
Validation loss: 2.306842647393894

Epoch: 6| Step: 5
Training loss: 0.18001980737145773
Validation loss: 2.3161713281597383

Epoch: 6| Step: 6
Training loss: 0.5750375476270693
Validation loss: 2.286197212313258

Epoch: 6| Step: 7
Training loss: 0.3525719561249549
Validation loss: 2.2749932807048747

Epoch: 6| Step: 8
Training loss: 0.2481208826030924
Validation loss: 2.2894143384299603

Epoch: 6| Step: 9
Training loss: 0.3027740821639575
Validation loss: 2.2903895806839834

Epoch: 6| Step: 10
Training loss: 0.2469238178659761
Validation loss: 2.2786184653236874

Epoch: 6| Step: 11
Training loss: 0.1800166618894096
Validation loss: 2.3217076700278714

Epoch: 6| Step: 12
Training loss: 0.3390850718847333
Validation loss: 2.3257553292314457

Epoch: 6| Step: 13
Training loss: 0.09038963028006837
Validation loss: 2.350282868654254

Epoch: 462| Step: 0
Training loss: 0.11652739097085564
Validation loss: 2.2720229547698803

Epoch: 6| Step: 1
Training loss: 0.1532009656443678
Validation loss: 2.320389438465474

Epoch: 6| Step: 2
Training loss: 0.4324418308853305
Validation loss: 2.342546297477955

Epoch: 6| Step: 3
Training loss: 0.28243829777033647
Validation loss: 2.3675486420703504

Epoch: 6| Step: 4
Training loss: 0.25036436588941074
Validation loss: 2.372012026623542

Epoch: 6| Step: 5
Training loss: 0.343936977686235
Validation loss: 2.3263881426423154

Epoch: 6| Step: 6
Training loss: 0.15269171272615378
Validation loss: 2.3417261257628628

Epoch: 6| Step: 7
Training loss: 0.2316064957408413
Validation loss: 2.3007068114660445

Epoch: 6| Step: 8
Training loss: 0.43862892001714027
Validation loss: 2.321160501911287

Epoch: 6| Step: 9
Training loss: 0.20295571645835078
Validation loss: 2.3053810473487695

Epoch: 6| Step: 10
Training loss: 0.313095955025085
Validation loss: 2.300564030492339

Epoch: 6| Step: 11
Training loss: 0.24397891983642114
Validation loss: 2.316290740280894

Epoch: 6| Step: 12
Training loss: 0.4705738982412223
Validation loss: 2.2997870659225477

Epoch: 6| Step: 13
Training loss: 0.14783408466071674
Validation loss: 2.3132280114500063

Epoch: 463| Step: 0
Training loss: 0.1358386458584741
Validation loss: 2.340110226631012

Epoch: 6| Step: 1
Training loss: 0.3981087019861622
Validation loss: 2.336001722996494

Epoch: 6| Step: 2
Training loss: 0.36510093821768363
Validation loss: 2.3336158667818827

Epoch: 6| Step: 3
Training loss: 0.24949678798129282
Validation loss: 2.3197035590003647

Epoch: 6| Step: 4
Training loss: 0.2896724914728588
Validation loss: 2.3248844777849222

Epoch: 6| Step: 5
Training loss: 0.34673135936512617
Validation loss: 2.309239200133446

Epoch: 6| Step: 6
Training loss: 0.2708904300928171
Validation loss: 2.317812507023926

Epoch: 6| Step: 7
Training loss: 0.18256678370132245
Validation loss: 2.32133621896207

Epoch: 6| Step: 8
Training loss: 0.3674971918076638
Validation loss: 2.3100566577502057

Epoch: 6| Step: 9
Training loss: 0.24045118767232238
Validation loss: 2.317325746198261

Epoch: 6| Step: 10
Training loss: 0.27361624188999456
Validation loss: 2.3427664237277814

Epoch: 6| Step: 11
Training loss: 0.3746099629163852
Validation loss: 2.3338623564178227

Epoch: 6| Step: 12
Training loss: 0.16512973822531934
Validation loss: 2.3913683045719996

Epoch: 6| Step: 13
Training loss: 0.3949362875763903
Validation loss: 2.39383589491582

Epoch: 464| Step: 0
Training loss: 0.2342562851658046
Validation loss: 2.420764899706072

Epoch: 6| Step: 1
Training loss: 0.1891109483293009
Validation loss: 2.361340463691685

Epoch: 6| Step: 2
Training loss: 0.333703039701665
Validation loss: 2.359956448703938

Epoch: 6| Step: 3
Training loss: 0.42308818372415974
Validation loss: 2.3787169868243705

Epoch: 6| Step: 4
Training loss: 0.24535454128615
Validation loss: 2.367505952396389

Epoch: 6| Step: 5
Training loss: 0.1345367007641089
Validation loss: 2.348368797994552

Epoch: 6| Step: 6
Training loss: 0.29500872867812006
Validation loss: 2.329192109774052

Epoch: 6| Step: 7
Training loss: 0.1661708779029362
Validation loss: 2.295392452910879

Epoch: 6| Step: 8
Training loss: 0.21877292104253548
Validation loss: 2.336452812369089

Epoch: 6| Step: 9
Training loss: 0.18836723872904682
Validation loss: 2.365180222431699

Epoch: 6| Step: 10
Training loss: 0.39865093498397836
Validation loss: 2.3355604901819147

Epoch: 6| Step: 11
Training loss: 0.26390284559223365
Validation loss: 2.3386460666541757

Epoch: 6| Step: 12
Training loss: 0.4206773394064789
Validation loss: 2.3464795555152205

Epoch: 6| Step: 13
Training loss: 0.30738269405966256
Validation loss: 2.3627720101706315

Epoch: 465| Step: 0
Training loss: 0.2182737172218949
Validation loss: 2.301838291371083

Epoch: 6| Step: 1
Training loss: 0.1700594060459367
Validation loss: 2.324980539361084

Epoch: 6| Step: 2
Training loss: 0.4235402549135942
Validation loss: 2.3232898030796565

Epoch: 6| Step: 3
Training loss: 0.20444568116131742
Validation loss: 2.3131807251589662

Epoch: 6| Step: 4
Training loss: 0.14511203063591882
Validation loss: 2.325213447698503

Epoch: 6| Step: 5
Training loss: 0.35035860772289795
Validation loss: 2.296095440593285

Epoch: 6| Step: 6
Training loss: 0.30559518300040445
Validation loss: 2.319462884940137

Epoch: 6| Step: 7
Training loss: 0.36871618261283234
Validation loss: 2.3467493468232483

Epoch: 6| Step: 8
Training loss: 0.2803559929352938
Validation loss: 2.3366993143285035

Epoch: 6| Step: 9
Training loss: 0.27358165755636443
Validation loss: 2.2952107336600602

Epoch: 6| Step: 10
Training loss: 0.2439194860294347
Validation loss: 2.3292148921533045

Epoch: 6| Step: 11
Training loss: 0.36198802177886624
Validation loss: 2.3168442005064267

Epoch: 6| Step: 12
Training loss: 0.3341523244547476
Validation loss: 2.3383612020586857

Epoch: 6| Step: 13
Training loss: 0.2295222242462149
Validation loss: 2.2878538992008832

Epoch: 466| Step: 0
Training loss: 0.26126134101764287
Validation loss: 2.304318939211211

Epoch: 6| Step: 1
Training loss: 0.21063891223386283
Validation loss: 2.2921908415841252

Epoch: 6| Step: 2
Training loss: 0.3341281313786907
Validation loss: 2.301608343477956

Epoch: 6| Step: 3
Training loss: 0.4337164730944285
Validation loss: 2.3354098343115077

Epoch: 6| Step: 4
Training loss: 0.18287338807861656
Validation loss: 2.3435772728936466

Epoch: 6| Step: 5
Training loss: 0.26824439416024676
Validation loss: 2.3022374142545043

Epoch: 6| Step: 6
Training loss: 0.17956447536233064
Validation loss: 2.302068167295785

Epoch: 6| Step: 7
Training loss: 0.2527868979826729
Validation loss: 2.3429411807155054

Epoch: 6| Step: 8
Training loss: 0.20883599477339537
Validation loss: 2.3482079946069354

Epoch: 6| Step: 9
Training loss: 0.2075336047617535
Validation loss: 2.3469061511170035

Epoch: 6| Step: 10
Training loss: 0.19665099221606533
Validation loss: 2.340202246421289

Epoch: 6| Step: 11
Training loss: 0.44486188676719973
Validation loss: 2.3031996743671797

Epoch: 6| Step: 12
Training loss: 0.2126461602787741
Validation loss: 2.3304549128681846

Epoch: 6| Step: 13
Training loss: 0.5438827396474254
Validation loss: 2.340688803987831

Epoch: 467| Step: 0
Training loss: 0.15582876645840418
Validation loss: 2.3136412729087414

Epoch: 6| Step: 1
Training loss: 0.3172317614937857
Validation loss: 2.31827528848119

Epoch: 6| Step: 2
Training loss: 0.29679290991753077
Validation loss: 2.33409173695956

Epoch: 6| Step: 3
Training loss: 0.3407617425735456
Validation loss: 2.3237894303015025

Epoch: 6| Step: 4
Training loss: 0.359675986257325
Validation loss: 2.3048102622675306

Epoch: 6| Step: 5
Training loss: 0.19239772216029427
Validation loss: 2.2980877072671024

Epoch: 6| Step: 6
Training loss: 0.2709332504951178
Validation loss: 2.2905509796536534

Epoch: 6| Step: 7
Training loss: 0.20121666492982032
Validation loss: 2.3244585676825644

Epoch: 6| Step: 8
Training loss: 0.2223240230921039
Validation loss: 2.3322300386410784

Epoch: 6| Step: 9
Training loss: 0.35487928876875213
Validation loss: 2.3648910405369343

Epoch: 6| Step: 10
Training loss: 0.316376578741155
Validation loss: 2.348417906741897

Epoch: 6| Step: 11
Training loss: 0.2755741292585189
Validation loss: 2.3331035264259374

Epoch: 6| Step: 12
Training loss: 0.4570650104540873
Validation loss: 2.3561122864596804

Epoch: 6| Step: 13
Training loss: 0.7125947939405007
Validation loss: 2.345425721672826

Epoch: 468| Step: 0
Training loss: 0.328981077512414
Validation loss: 2.3377313549959267

Epoch: 6| Step: 1
Training loss: 0.24588663983392625
Validation loss: 2.3518809054363894

Epoch: 6| Step: 2
Training loss: 0.15845685791698272
Validation loss: 2.351350931157951

Epoch: 6| Step: 3
Training loss: 0.1428187182385309
Validation loss: 2.376018154270735

Epoch: 6| Step: 4
Training loss: 0.2899878742502868
Validation loss: 2.3017061605982296

Epoch: 6| Step: 5
Training loss: 0.2718740589300947
Validation loss: 2.267038164158917

Epoch: 6| Step: 6
Training loss: 0.3431241233133536
Validation loss: 2.2734591789580665

Epoch: 6| Step: 7
Training loss: 0.3135385659952714
Validation loss: 2.2837804811726796

Epoch: 6| Step: 8
Training loss: 0.2681355621685063
Validation loss: 2.2838002209971138

Epoch: 6| Step: 9
Training loss: 0.39943480496071126
Validation loss: 2.3106463507488937

Epoch: 6| Step: 10
Training loss: 0.39593708619394935
Validation loss: 2.305535495731905

Epoch: 6| Step: 11
Training loss: 0.438536998772262
Validation loss: 2.3244701745518213

Epoch: 6| Step: 12
Training loss: 0.5064621210159318
Validation loss: 2.33699338664425

Epoch: 6| Step: 13
Training loss: 0.49485895468958474
Validation loss: 2.3660836058414034

Epoch: 469| Step: 0
Training loss: 0.3043090719929755
Validation loss: 2.3324508818489993

Epoch: 6| Step: 1
Training loss: 0.3148540050265797
Validation loss: 2.3154340808600944

Epoch: 6| Step: 2
Training loss: 0.24074690505144827
Validation loss: 2.321811188019535

Epoch: 6| Step: 3
Training loss: 0.13715949541720968
Validation loss: 2.3269030534247688

Epoch: 6| Step: 4
Training loss: 0.41911198783947207
Validation loss: 2.3439128707025225

Epoch: 6| Step: 5
Training loss: 0.31028631063317186
Validation loss: 2.3201357004627714

Epoch: 6| Step: 6
Training loss: 0.3334425161282915
Validation loss: 2.313298119546513

Epoch: 6| Step: 7
Training loss: 0.27492321199448116
Validation loss: 2.3631980236575205

Epoch: 6| Step: 8
Training loss: 0.3211708547083693
Validation loss: 2.341509873345524

Epoch: 6| Step: 9
Training loss: 0.5122060421187721
Validation loss: 2.334059556843522

Epoch: 6| Step: 10
Training loss: 0.3009197981154804
Validation loss: 2.364561478636369

Epoch: 6| Step: 11
Training loss: 0.5946224729152674
Validation loss: 2.357135618609173

Epoch: 6| Step: 12
Training loss: 0.15202780508939148
Validation loss: 2.297181012593943

Epoch: 6| Step: 13
Training loss: 0.22667730645377565
Validation loss: 2.2979387140823357

Epoch: 470| Step: 0
Training loss: 0.2702070416370852
Validation loss: 2.275283279573275

Epoch: 6| Step: 1
Training loss: 0.18962343170910595
Validation loss: 2.2787938647492476

Epoch: 6| Step: 2
Training loss: 0.37196941459447047
Validation loss: 2.2588999683021447

Epoch: 6| Step: 3
Training loss: 0.20431317762167403
Validation loss: 2.2884464008078735

Epoch: 6| Step: 4
Training loss: 0.26188509195588155
Validation loss: 2.31013511854376

Epoch: 6| Step: 5
Training loss: 0.39111651968121286
Validation loss: 2.315929566949013

Epoch: 6| Step: 6
Training loss: 0.2923396667978236
Validation loss: 2.337435135910101

Epoch: 6| Step: 7
Training loss: 0.34544889078120916
Validation loss: 2.3168480484358236

Epoch: 6| Step: 8
Training loss: 0.1781389536327916
Validation loss: 2.3072755748639757

Epoch: 6| Step: 9
Training loss: 0.1762335996910917
Validation loss: 2.319525633778256

Epoch: 6| Step: 10
Training loss: 0.41619503826848175
Validation loss: 2.3466678310620495

Epoch: 6| Step: 11
Training loss: 0.36729494511350497
Validation loss: 2.3435151877415015

Epoch: 6| Step: 12
Training loss: 0.26639290214056216
Validation loss: 2.351112778417209

Epoch: 6| Step: 13
Training loss: 0.13465844605479485
Validation loss: 2.3292448625461724

Epoch: 471| Step: 0
Training loss: 0.3823348198562188
Validation loss: 2.3244182815035836

Epoch: 6| Step: 1
Training loss: 0.4277039956927204
Validation loss: 2.2914711638555896

Epoch: 6| Step: 2
Training loss: 0.2720891405150858
Validation loss: 2.3217073487042668

Epoch: 6| Step: 3
Training loss: 0.21813188655388005
Validation loss: 2.338709036880394

Epoch: 6| Step: 4
Training loss: 0.32187887161667084
Validation loss: 2.358142499624737

Epoch: 6| Step: 5
Training loss: 0.22588501133236277
Validation loss: 2.331343982419428

Epoch: 6| Step: 6
Training loss: 0.22950734839175124
Validation loss: 2.345220869658835

Epoch: 6| Step: 7
Training loss: 0.3102009123731584
Validation loss: 2.3127090095800376

Epoch: 6| Step: 8
Training loss: 0.2592046603466003
Validation loss: 2.296227686560124

Epoch: 6| Step: 9
Training loss: 0.353819279373791
Validation loss: 2.2762558251715257

Epoch: 6| Step: 10
Training loss: 0.22637567545370338
Validation loss: 2.292181270093843

Epoch: 6| Step: 11
Training loss: 0.21066565126979653
Validation loss: 2.2818103124087483

Epoch: 6| Step: 12
Training loss: 0.3229508138362873
Validation loss: 2.2693162245467664

Epoch: 6| Step: 13
Training loss: 0.3210791159866116
Validation loss: 2.2555498487293684

Epoch: 472| Step: 0
Training loss: 0.2704953903485912
Validation loss: 2.287091587231784

Epoch: 6| Step: 1
Training loss: 0.3723056879731559
Validation loss: 2.3046886690893555

Epoch: 6| Step: 2
Training loss: 0.24772808284702622
Validation loss: 2.331102449231702

Epoch: 6| Step: 3
Training loss: 0.20954582519245524
Validation loss: 2.3004170487534554

Epoch: 6| Step: 4
Training loss: 0.1902178637723801
Validation loss: 2.3414637812034647

Epoch: 6| Step: 5
Training loss: 0.37941778202564613
Validation loss: 2.321892007484387

Epoch: 6| Step: 6
Training loss: 0.4206613815694022
Validation loss: 2.2873574029382087

Epoch: 6| Step: 7
Training loss: 0.38903641977183806
Validation loss: 2.326995661311978

Epoch: 6| Step: 8
Training loss: 0.16594950537347825
Validation loss: 2.2942616139392986

Epoch: 6| Step: 9
Training loss: 0.2090844155558263
Validation loss: 2.307212628422575

Epoch: 6| Step: 10
Training loss: 0.16245081574447118
Validation loss: 2.2819469071226

Epoch: 6| Step: 11
Training loss: 0.12014676714534206
Validation loss: 2.3217925089454963

Epoch: 6| Step: 12
Training loss: 0.3964674621883442
Validation loss: 2.336403672128535

Epoch: 6| Step: 13
Training loss: 0.33657522439590043
Validation loss: 2.34202233301815

Epoch: 473| Step: 0
Training loss: 0.1726256364980533
Validation loss: 2.3410759342714687

Epoch: 6| Step: 1
Training loss: 0.1509472158416747
Validation loss: 2.3368085166792403

Epoch: 6| Step: 2
Training loss: 0.44599307071537464
Validation loss: 2.3530155781304836

Epoch: 6| Step: 3
Training loss: 0.1938197983102937
Validation loss: 2.282446697551568

Epoch: 6| Step: 4
Training loss: 0.19596802377908418
Validation loss: 2.3106075127005643

Epoch: 6| Step: 5
Training loss: 0.3290872542443218
Validation loss: 2.3490451645446084

Epoch: 6| Step: 6
Training loss: 0.18799362175031356
Validation loss: 2.3032221793008336

Epoch: 6| Step: 7
Training loss: 0.23928927000678749
Validation loss: 2.318270899399632

Epoch: 6| Step: 8
Training loss: 0.3486270209507241
Validation loss: 2.3083124911999686

Epoch: 6| Step: 9
Training loss: 0.31350687658792936
Validation loss: 2.328480020297621

Epoch: 6| Step: 10
Training loss: 0.2697371097521746
Validation loss: 2.3082827088238655

Epoch: 6| Step: 11
Training loss: 0.28513522919815093
Validation loss: 2.2835250188698883

Epoch: 6| Step: 12
Training loss: 0.3346077527833636
Validation loss: 2.326183853538054

Epoch: 6| Step: 13
Training loss: 0.19473316101097393
Validation loss: 2.3192705604997768

Epoch: 474| Step: 0
Training loss: 0.2795398162416273
Validation loss: 2.3369792931202515

Epoch: 6| Step: 1
Training loss: 0.21426443543538937
Validation loss: 2.355412323449198

Epoch: 6| Step: 2
Training loss: 0.277240707167768
Validation loss: 2.3511664522052524

Epoch: 6| Step: 3
Training loss: 0.3401688084454717
Validation loss: 2.3240468635261347

Epoch: 6| Step: 4
Training loss: 0.20776345670982543
Validation loss: 2.334921341154584

Epoch: 6| Step: 5
Training loss: 0.13246498503332535
Validation loss: 2.3299199053951933

Epoch: 6| Step: 6
Training loss: 0.17932951553203133
Validation loss: 2.314098114136005

Epoch: 6| Step: 7
Training loss: 0.240562509497595
Validation loss: 2.2835717011765877

Epoch: 6| Step: 8
Training loss: 0.31237165676555023
Validation loss: 2.3256907648623932

Epoch: 6| Step: 9
Training loss: 0.2615667442606375
Validation loss: 2.307464222788924

Epoch: 6| Step: 10
Training loss: 0.4752424123480403
Validation loss: 2.3299470103424187

Epoch: 6| Step: 11
Training loss: 0.1891749788305211
Validation loss: 2.3485584246485343

Epoch: 6| Step: 12
Training loss: 0.1250597989573709
Validation loss: 2.333175466693519

Epoch: 6| Step: 13
Training loss: 0.15041848952526468
Validation loss: 2.3297579150181833

Epoch: 475| Step: 0
Training loss: 0.32623482285198474
Validation loss: 2.342219936580754

Epoch: 6| Step: 1
Training loss: 0.15219337426584478
Validation loss: 2.3324250342783075

Epoch: 6| Step: 2
Training loss: 0.2375943962528903
Validation loss: 2.3336775512274968

Epoch: 6| Step: 3
Training loss: 0.13427746859457976
Validation loss: 2.3112769569054774

Epoch: 6| Step: 4
Training loss: 0.16948241923735277
Validation loss: 2.32694460294956

Epoch: 6| Step: 5
Training loss: 0.176777443401615
Validation loss: 2.32330021192659

Epoch: 6| Step: 6
Training loss: 0.22850973985706854
Validation loss: 2.2810264789186494

Epoch: 6| Step: 7
Training loss: 0.2554967363292803
Validation loss: 2.31451404138818

Epoch: 6| Step: 8
Training loss: 0.4231289841141759
Validation loss: 2.328516985850411

Epoch: 6| Step: 9
Training loss: 0.1750338825990888
Validation loss: 2.336579225922327

Epoch: 6| Step: 10
Training loss: 0.2526789567613239
Validation loss: 2.326703375534898

Epoch: 6| Step: 11
Training loss: 0.3177372874944132
Validation loss: 2.3345332858071535

Epoch: 6| Step: 12
Training loss: 0.4096904107404324
Validation loss: 2.37115557903648

Epoch: 6| Step: 13
Training loss: 0.2904778446376359
Validation loss: 2.3579820480084286

Epoch: 476| Step: 0
Training loss: 0.33295898974544924
Validation loss: 2.3585630151170096

Epoch: 6| Step: 1
Training loss: 0.29521987713893083
Validation loss: 2.336294860974476

Epoch: 6| Step: 2
Training loss: 0.35314404470012406
Validation loss: 2.313016940680568

Epoch: 6| Step: 3
Training loss: 0.28487962866149136
Validation loss: 2.346350003105717

Epoch: 6| Step: 4
Training loss: 0.1378982482402277
Validation loss: 2.301759809497964

Epoch: 6| Step: 5
Training loss: 0.3004868540514556
Validation loss: 2.3215055641569378

Epoch: 6| Step: 6
Training loss: 0.3046880868759372
Validation loss: 2.3562670641395695

Epoch: 6| Step: 7
Training loss: 0.45646423640134653
Validation loss: 2.3576222720693707

Epoch: 6| Step: 8
Training loss: 0.23127582637807056
Validation loss: 2.3607798213844915

Epoch: 6| Step: 9
Training loss: 0.33995805111676325
Validation loss: 2.339902670913099

Epoch: 6| Step: 10
Training loss: 0.15400956360579948
Validation loss: 2.377733173425753

Epoch: 6| Step: 11
Training loss: 0.20440395896664626
Validation loss: 2.386989744543785

Epoch: 6| Step: 12
Training loss: 0.18901139309454748
Validation loss: 2.3758982938712845

Epoch: 6| Step: 13
Training loss: 0.13344737086761266
Validation loss: 2.3557047812659997

Epoch: 477| Step: 0
Training loss: 0.13845010270605346
Validation loss: 2.331734439818047

Epoch: 6| Step: 1
Training loss: 0.19648397077818408
Validation loss: 2.358740551974279

Epoch: 6| Step: 2
Training loss: 0.16343998881573038
Validation loss: 2.338278097954347

Epoch: 6| Step: 3
Training loss: 0.15120362704872606
Validation loss: 2.3678109245504717

Epoch: 6| Step: 4
Training loss: 0.16904087891766142
Validation loss: 2.3614684533227503

Epoch: 6| Step: 5
Training loss: 0.22135183482718326
Validation loss: 2.379740569816812

Epoch: 6| Step: 6
Training loss: 0.3576878043037972
Validation loss: 2.329672846771395

Epoch: 6| Step: 7
Training loss: 0.18229189373183868
Validation loss: 2.364132677264246

Epoch: 6| Step: 8
Training loss: 0.32020318096452466
Validation loss: 2.351111082580424

Epoch: 6| Step: 9
Training loss: 0.4039697844305492
Validation loss: 2.3474604839109383

Epoch: 6| Step: 10
Training loss: 0.21246407149020358
Validation loss: 2.359095817074629

Epoch: 6| Step: 11
Training loss: 0.27561214006140844
Validation loss: 2.3337365218149015

Epoch: 6| Step: 12
Training loss: 0.44319623726950025
Validation loss: 2.3175249278574617

Epoch: 6| Step: 13
Training loss: 0.2928670452330356
Validation loss: 2.344167014045579

Epoch: 478| Step: 0
Training loss: 0.18828088356710526
Validation loss: 2.2808790125794065

Epoch: 6| Step: 1
Training loss: 0.4329437676514786
Validation loss: 2.2689605990072446

Epoch: 6| Step: 2
Training loss: 0.22706705670833782
Validation loss: 2.2983237920770963

Epoch: 6| Step: 3
Training loss: 0.2239540158824092
Validation loss: 2.293631518082613

Epoch: 6| Step: 4
Training loss: 0.1994256646707014
Validation loss: 2.2844532295650155

Epoch: 6| Step: 5
Training loss: 0.3201089537924958
Validation loss: 2.2880414078083686

Epoch: 6| Step: 6
Training loss: 0.37707393074255824
Validation loss: 2.330049155551799

Epoch: 6| Step: 7
Training loss: 0.4187115993257864
Validation loss: 2.33461257499442

Epoch: 6| Step: 8
Training loss: 0.19292978287126988
Validation loss: 2.369818131493901

Epoch: 6| Step: 9
Training loss: 0.16667408231291203
Validation loss: 2.3484585177992474

Epoch: 6| Step: 10
Training loss: 0.15961067968461737
Validation loss: 2.3251163515962183

Epoch: 6| Step: 11
Training loss: 0.26886243353490863
Validation loss: 2.3159698449868924

Epoch: 6| Step: 12
Training loss: 0.20003987302282597
Validation loss: 2.334625777975656

Epoch: 6| Step: 13
Training loss: 0.19160101187623957
Validation loss: 2.3376832746842173

Epoch: 479| Step: 0
Training loss: 0.16498299498422994
Validation loss: 2.3551652019199807

Epoch: 6| Step: 1
Training loss: 0.2285950351556412
Validation loss: 2.341433068298279

Epoch: 6| Step: 2
Training loss: 0.2976715794818579
Validation loss: 2.345309694951211

Epoch: 6| Step: 3
Training loss: 0.2585392447938894
Validation loss: 2.354975315838379

Epoch: 6| Step: 4
Training loss: 0.24488693608669887
Validation loss: 2.376468382627028

Epoch: 6| Step: 5
Training loss: 0.43265831194297083
Validation loss: 2.336753047105382

Epoch: 6| Step: 6
Training loss: 0.28041891648824535
Validation loss: 2.328317860374656

Epoch: 6| Step: 7
Training loss: 0.3159463860821398
Validation loss: 2.318799400527532

Epoch: 6| Step: 8
Training loss: 0.20374579200026763
Validation loss: 2.282694259532321

Epoch: 6| Step: 9
Training loss: 0.22671484757843405
Validation loss: 2.2568689580325154

Epoch: 6| Step: 10
Training loss: 0.3087478928745043
Validation loss: 2.308761646931089

Epoch: 6| Step: 11
Training loss: 0.23322442882360359
Validation loss: 2.287768339595275

Epoch: 6| Step: 12
Training loss: 0.28474382073711685
Validation loss: 2.304262301469287

Epoch: 6| Step: 13
Training loss: 0.22455991117416885
Validation loss: 2.290459720192206

Epoch: 480| Step: 0
Training loss: 0.38314077354183407
Validation loss: 2.263196982350442

Epoch: 6| Step: 1
Training loss: 0.1433602398006954
Validation loss: 2.2743190511878013

Epoch: 6| Step: 2
Training loss: 0.24706366307655284
Validation loss: 2.2922714136505444

Epoch: 6| Step: 3
Training loss: 0.24973269417614857
Validation loss: 2.2922462878884615

Epoch: 6| Step: 4
Training loss: 0.3590106775985796
Validation loss: 2.291766477930142

Epoch: 6| Step: 5
Training loss: 0.29462147249093495
Validation loss: 2.348731909683115

Epoch: 6| Step: 6
Training loss: 0.20398612157160853
Validation loss: 2.3168837578009955

Epoch: 6| Step: 7
Training loss: 0.3033653206234011
Validation loss: 2.3246623081245334

Epoch: 6| Step: 8
Training loss: 0.16313834119370452
Validation loss: 2.3491499584162723

Epoch: 6| Step: 9
Training loss: 0.314223590739563
Validation loss: 2.3495426319376596

Epoch: 6| Step: 10
Training loss: 0.1545076982160486
Validation loss: 2.3598192070214217

Epoch: 6| Step: 11
Training loss: 0.41613773112074504
Validation loss: 2.3367981880242215

Epoch: 6| Step: 12
Training loss: 0.3344526744359204
Validation loss: 2.4182381031054065

Epoch: 6| Step: 13
Training loss: 0.2565159853542167
Validation loss: 2.30696677517718

Epoch: 481| Step: 0
Training loss: 0.249840290494136
Validation loss: 2.318943424536239

Epoch: 6| Step: 1
Training loss: 0.17496883421356088
Validation loss: 2.278284933782352

Epoch: 6| Step: 2
Training loss: 0.25050407493726135
Validation loss: 2.2605047713948925

Epoch: 6| Step: 3
Training loss: 0.354084147863034
Validation loss: 2.232801132479198

Epoch: 6| Step: 4
Training loss: 0.1811525185473645
Validation loss: 2.2419069484878626

Epoch: 6| Step: 5
Training loss: 0.21831549338323428
Validation loss: 2.1984758441905536

Epoch: 6| Step: 6
Training loss: 0.2710493705547985
Validation loss: 2.2477074426340775

Epoch: 6| Step: 7
Training loss: 0.3179861584146126
Validation loss: 2.2469456620496153

Epoch: 6| Step: 8
Training loss: 0.38290443095076576
Validation loss: 2.279415417261383

Epoch: 6| Step: 9
Training loss: 0.18581991685204108
Validation loss: 2.2829950277230604

Epoch: 6| Step: 10
Training loss: 0.3933053185028421
Validation loss: 2.295959977938403

Epoch: 6| Step: 11
Training loss: 0.25986246584105266
Validation loss: 2.298617099313454

Epoch: 6| Step: 12
Training loss: 0.2568948192329449
Validation loss: 2.3126237808973937

Epoch: 6| Step: 13
Training loss: 0.4208804699808838
Validation loss: 2.322671572082954

Epoch: 482| Step: 0
Training loss: 0.23453455897874478
Validation loss: 2.340163648022707

Epoch: 6| Step: 1
Training loss: 0.26172282087661597
Validation loss: 2.3026054887807033

Epoch: 6| Step: 2
Training loss: 0.14078740173176552
Validation loss: 2.3010265965307743

Epoch: 6| Step: 3
Training loss: 0.3756886754833839
Validation loss: 2.263334600723209

Epoch: 6| Step: 4
Training loss: 0.2748760393746689
Validation loss: 2.2841543245773557

Epoch: 6| Step: 5
Training loss: 0.2675239062545088
Validation loss: 2.2701463601950627

Epoch: 6| Step: 6
Training loss: 0.38808638597144757
Validation loss: 2.300370658703012

Epoch: 6| Step: 7
Training loss: 0.35454750154922454
Validation loss: 2.341611326401098

Epoch: 6| Step: 8
Training loss: 0.1626098330408725
Validation loss: 2.327042952487648

Epoch: 6| Step: 9
Training loss: 0.3708689962697639
Validation loss: 2.353409415495029

Epoch: 6| Step: 10
Training loss: 0.2214509228937552
Validation loss: 2.3101091871917507

Epoch: 6| Step: 11
Training loss: 0.26199197030047777
Validation loss: 2.3231375425697154

Epoch: 6| Step: 12
Training loss: 0.22735493294914075
Validation loss: 2.325725994539263

Epoch: 6| Step: 13
Training loss: 0.31101375248682367
Validation loss: 2.318849658430339

Epoch: 483| Step: 0
Training loss: 0.3503485808563017
Validation loss: 2.340788661324184

Epoch: 6| Step: 1
Training loss: 0.309500436688548
Validation loss: 2.3461357635015134

Epoch: 6| Step: 2
Training loss: 0.3579211057728887
Validation loss: 2.338037084830011

Epoch: 6| Step: 3
Training loss: 0.2049037191744624
Validation loss: 2.3464408156421928

Epoch: 6| Step: 4
Training loss: 0.3199066405342851
Validation loss: 2.4037046416746275

Epoch: 6| Step: 5
Training loss: 0.4086629659403212
Validation loss: 2.414211863403637

Epoch: 6| Step: 6
Training loss: 0.3463166821304211
Validation loss: 2.384761563618677

Epoch: 6| Step: 7
Training loss: 0.16070505642692298
Validation loss: 2.303042177087008

Epoch: 6| Step: 8
Training loss: 0.2528764381471508
Validation loss: 2.3275131299162997

Epoch: 6| Step: 9
Training loss: 0.20095732275212877
Validation loss: 2.290042686236515

Epoch: 6| Step: 10
Training loss: 0.237406461578773
Validation loss: 2.3106127063079867

Epoch: 6| Step: 11
Training loss: 0.2359036977187466
Validation loss: 2.312546880058951

Epoch: 6| Step: 12
Training loss: 0.24845184098843887
Validation loss: 2.3325537922710677

Epoch: 6| Step: 13
Training loss: 0.29861966510221233
Validation loss: 2.3630328960565974

Epoch: 484| Step: 0
Training loss: 0.2628055468851709
Validation loss: 2.3472887069897017

Epoch: 6| Step: 1
Training loss: 0.32087441909999004
Validation loss: 2.3284351609991427

Epoch: 6| Step: 2
Training loss: 0.2294668630059773
Validation loss: 2.289221015908947

Epoch: 6| Step: 3
Training loss: 0.1941985406588498
Validation loss: 2.31071809152279

Epoch: 6| Step: 4
Training loss: 0.37813067944257384
Validation loss: 2.2768229390660184

Epoch: 6| Step: 5
Training loss: 0.18424108701470363
Validation loss: 2.309049560874252

Epoch: 6| Step: 6
Training loss: 0.22626339143038257
Validation loss: 2.2736481616641533

Epoch: 6| Step: 7
Training loss: 0.20310545790641368
Validation loss: 2.2633730799031397

Epoch: 6| Step: 8
Training loss: 0.45547749427528283
Validation loss: 2.303951818291038

Epoch: 6| Step: 9
Training loss: 0.20733886034560592
Validation loss: 2.332984624316383

Epoch: 6| Step: 10
Training loss: 0.1576028077515962
Validation loss: 2.322732519613579

Epoch: 6| Step: 11
Training loss: 0.24968182164635502
Validation loss: 2.3292767432246073

Epoch: 6| Step: 12
Training loss: 0.28779556381976523
Validation loss: 2.30692007510084

Epoch: 6| Step: 13
Training loss: 0.4308781167568608
Validation loss: 2.315654023866943

Epoch: 485| Step: 0
Training loss: 0.1996458841368438
Validation loss: 2.2601358613451334

Epoch: 6| Step: 1
Training loss: 0.1994093375995952
Validation loss: 2.269695461082728

Epoch: 6| Step: 2
Training loss: 0.2582427971122539
Validation loss: 2.2251151843764987

Epoch: 6| Step: 3
Training loss: 0.3141170862311422
Validation loss: 2.2181087181271266

Epoch: 6| Step: 4
Training loss: 0.36905673249443505
Validation loss: 2.243628020108238

Epoch: 6| Step: 5
Training loss: 0.21499043572299667
Validation loss: 2.221089556744909

Epoch: 6| Step: 6
Training loss: 0.2892444012486637
Validation loss: 2.2015860744973548

Epoch: 6| Step: 7
Training loss: 0.32852459599315004
Validation loss: 2.2472636778664574

Epoch: 6| Step: 8
Training loss: 0.2867841110776803
Validation loss: 2.2890036076747227

Epoch: 6| Step: 9
Training loss: 0.2513762530964747
Validation loss: 2.3139445231209694

Epoch: 6| Step: 10
Training loss: 0.30249698314265805
Validation loss: 2.3191257288371108

Epoch: 6| Step: 11
Training loss: 0.3073952616086577
Validation loss: 2.3036541612824535

Epoch: 6| Step: 12
Training loss: 0.2752506630912922
Validation loss: 2.3149580614165353

Epoch: 6| Step: 13
Training loss: 0.2566724917108952
Validation loss: 2.282202798820753

Epoch: 486| Step: 0
Training loss: 0.1438894196980839
Validation loss: 2.2675172930944645

Epoch: 6| Step: 1
Training loss: 0.3519344058123496
Validation loss: 2.287152127176469

Epoch: 6| Step: 2
Training loss: 0.3007673780536944
Validation loss: 2.300079987607711

Epoch: 6| Step: 3
Training loss: 0.19287715854042625
Validation loss: 2.30222369090818

Epoch: 6| Step: 4
Training loss: 0.17839226164296335
Validation loss: 2.3202190825764855

Epoch: 6| Step: 5
Training loss: 0.1991391396869327
Validation loss: 2.2914416621284985

Epoch: 6| Step: 6
Training loss: 0.21463592187355626
Validation loss: 2.274701056750612

Epoch: 6| Step: 7
Training loss: 0.22069566427128057
Validation loss: 2.3121275478526098

Epoch: 6| Step: 8
Training loss: 0.26541303143090333
Validation loss: 2.367196261915216

Epoch: 6| Step: 9
Training loss: 0.21330057273220926
Validation loss: 2.3472267642406734

Epoch: 6| Step: 10
Training loss: 0.363830745590107
Validation loss: 2.316211139894047

Epoch: 6| Step: 11
Training loss: 0.31792734237351544
Validation loss: 2.318479540223159

Epoch: 6| Step: 12
Training loss: 0.31687099563355775
Validation loss: 2.321244849478617

Epoch: 6| Step: 13
Training loss: 0.3203564009006272
Validation loss: 2.314835003380831

Epoch: 487| Step: 0
Training loss: 0.2718870757698712
Validation loss: 2.3089263295007196

Epoch: 6| Step: 1
Training loss: 0.2604658398296894
Validation loss: 2.3381214726760615

Epoch: 6| Step: 2
Training loss: 0.23049811806500092
Validation loss: 2.3378156447665126

Epoch: 6| Step: 3
Training loss: 0.526498696737678
Validation loss: 2.37628993165127

Epoch: 6| Step: 4
Training loss: 0.21590641082236467
Validation loss: 2.3922097480668336

Epoch: 6| Step: 5
Training loss: 0.23328286665441222
Validation loss: 2.399745452919796

Epoch: 6| Step: 6
Training loss: 0.16715278487893792
Validation loss: 2.3745956076618095

Epoch: 6| Step: 7
Training loss: 0.2422233139752859
Validation loss: 2.3732318070993506

Epoch: 6| Step: 8
Training loss: 0.29231716175778727
Validation loss: 2.363424056994616

Epoch: 6| Step: 9
Training loss: 0.37740772881723134
Validation loss: 2.303992039231621

Epoch: 6| Step: 10
Training loss: 0.12210231361546217
Validation loss: 2.248760442526373

Epoch: 6| Step: 11
Training loss: 0.16866558820343733
Validation loss: 2.278933233228572

Epoch: 6| Step: 12
Training loss: 0.27120067675373855
Validation loss: 2.291080886799082

Epoch: 6| Step: 13
Training loss: 0.18390824388964264
Validation loss: 2.2693042305177893

Epoch: 488| Step: 0
Training loss: 0.2119989093440944
Validation loss: 2.2754855031285706

Epoch: 6| Step: 1
Training loss: 0.3096215599794529
Validation loss: 2.260067324472736

Epoch: 6| Step: 2
Training loss: 0.29969313344742265
Validation loss: 2.336335544500436

Epoch: 6| Step: 3
Training loss: 0.17561109042320486
Validation loss: 2.360138889329043

Epoch: 6| Step: 4
Training loss: 0.27865310314831937
Validation loss: 2.34338947763755

Epoch: 6| Step: 5
Training loss: 0.3313511783897223
Validation loss: 2.355925627502378

Epoch: 6| Step: 6
Training loss: 0.1781057523065672
Validation loss: 2.3762312732259905

Epoch: 6| Step: 7
Training loss: 0.1810896834508516
Validation loss: 2.3840648150192356

Epoch: 6| Step: 8
Training loss: 0.20706378932969433
Validation loss: 2.335226686876624

Epoch: 6| Step: 9
Training loss: 0.4661317180293667
Validation loss: 2.3135086128201507

Epoch: 6| Step: 10
Training loss: 0.3751206204019836
Validation loss: 2.346352767402168

Epoch: 6| Step: 11
Training loss: 0.2165301718671937
Validation loss: 2.301434158988388

Epoch: 6| Step: 12
Training loss: 0.19150300402625725
Validation loss: 2.3272878139944235

Epoch: 6| Step: 13
Training loss: 0.15097236207988995
Validation loss: 2.331342930063079

Epoch: 489| Step: 0
Training loss: 0.1286647875975773
Validation loss: 2.340044957847341

Epoch: 6| Step: 1
Training loss: 0.14072734366981407
Validation loss: 2.310902029829671

Epoch: 6| Step: 2
Training loss: 0.25739623189504457
Validation loss: 2.296945244493014

Epoch: 6| Step: 3
Training loss: 0.3424270923311898
Validation loss: 2.283727507778049

Epoch: 6| Step: 4
Training loss: 0.1985072351309396
Validation loss: 2.28703569536806

Epoch: 6| Step: 5
Training loss: 0.327209284803169
Validation loss: 2.3048665851184196

Epoch: 6| Step: 6
Training loss: 0.27214006788060197
Validation loss: 2.270295369449395

Epoch: 6| Step: 7
Training loss: 0.1318214125932395
Validation loss: 2.2752283601708307

Epoch: 6| Step: 8
Training loss: 0.3038261538476189
Validation loss: 2.241176622459457

Epoch: 6| Step: 9
Training loss: 0.13817175824597075
Validation loss: 2.2626924018133545

Epoch: 6| Step: 10
Training loss: 0.22082732933957536
Validation loss: 2.281573357100591

Epoch: 6| Step: 11
Training loss: 0.30830466334762846
Validation loss: 2.288310768788696

Epoch: 6| Step: 12
Training loss: 0.14555888591725058
Validation loss: 2.2787262884371846

Epoch: 6| Step: 13
Training loss: 0.21765602265159198
Validation loss: 2.2846879415962333

Epoch: 490| Step: 0
Training loss: 0.19521171830668044
Validation loss: 2.337598570523775

Epoch: 6| Step: 1
Training loss: 0.32260532392902536
Validation loss: 2.2821976894008147

Epoch: 6| Step: 2
Training loss: 0.05347299757583855
Validation loss: 2.3254417576217397

Epoch: 6| Step: 3
Training loss: 0.3522144735985612
Validation loss: 2.2862478516222757

Epoch: 6| Step: 4
Training loss: 0.13210768067476372
Validation loss: 2.309946232605769

Epoch: 6| Step: 5
Training loss: 0.27465490720678687
Validation loss: 2.3099182836640213

Epoch: 6| Step: 6
Training loss: 0.2773766565277708
Validation loss: 2.2940431982217007

Epoch: 6| Step: 7
Training loss: 0.21082533397281703
Validation loss: 2.2985016888338627

Epoch: 6| Step: 8
Training loss: 0.27169148346161603
Validation loss: 2.3148380799668264

Epoch: 6| Step: 9
Training loss: 0.1950439227747955
Validation loss: 2.3142397870367883

Epoch: 6| Step: 10
Training loss: 0.19528429781433387
Validation loss: 2.3258016108797492

Epoch: 6| Step: 11
Training loss: 0.280374169939014
Validation loss: 2.3027520664268915

Epoch: 6| Step: 12
Training loss: 0.15043015394036965
Validation loss: 2.32986089817483

Epoch: 6| Step: 13
Training loss: 0.10230606491833713
Validation loss: 2.3366426309122312

Epoch: 491| Step: 0
Training loss: 0.2383120157360456
Validation loss: 2.3256677319049825

Epoch: 6| Step: 1
Training loss: 0.1602230979228287
Validation loss: 2.296078650276928

Epoch: 6| Step: 2
Training loss: 0.1473115075474075
Validation loss: 2.2989547105956505

Epoch: 6| Step: 3
Training loss: 0.1919995280324579
Validation loss: 2.296565452635193

Epoch: 6| Step: 4
Training loss: 0.1666917943390569
Validation loss: 2.283988845862827

Epoch: 6| Step: 5
Training loss: 0.3752986989910243
Validation loss: 2.3057489547121834

Epoch: 6| Step: 6
Training loss: 0.309056647103551
Validation loss: 2.2891961377579153

Epoch: 6| Step: 7
Training loss: 0.13499773465127915
Validation loss: 2.306442593029745

Epoch: 6| Step: 8
Training loss: 0.09941292070733622
Validation loss: 2.273309172121595

Epoch: 6| Step: 9
Training loss: 0.14537615227960127
Validation loss: 2.3160435898440697

Epoch: 6| Step: 10
Training loss: 0.30995027347096643
Validation loss: 2.2748138937587328

Epoch: 6| Step: 11
Training loss: 0.2915813528468629
Validation loss: 2.2834260894615546

Epoch: 6| Step: 12
Training loss: 0.2745390366485072
Validation loss: 2.2719260555137155

Epoch: 6| Step: 13
Training loss: 0.34875119761121204
Validation loss: 2.279342796981573

Epoch: 492| Step: 0
Training loss: 0.22743560010510128
Validation loss: 2.269139078821158

Epoch: 6| Step: 1
Training loss: 0.2814137326590175
Validation loss: 2.3069384700919406

Epoch: 6| Step: 2
Training loss: 0.16257566583983368
Validation loss: 2.259060659696193

Epoch: 6| Step: 3
Training loss: 0.23621436604704807
Validation loss: 2.264230353637691

Epoch: 6| Step: 4
Training loss: 0.16244393032434268
Validation loss: 2.2786105736789297

Epoch: 6| Step: 5
Training loss: 0.28698858977191943
Validation loss: 2.3214229919031184

Epoch: 6| Step: 6
Training loss: 0.2565189334339785
Validation loss: 2.296946455470665

Epoch: 6| Step: 7
Training loss: 0.43267775341971176
Validation loss: 2.305881665428206

Epoch: 6| Step: 8
Training loss: 0.2985657930486008
Validation loss: 2.26560061522626

Epoch: 6| Step: 9
Training loss: 0.22524724859363
Validation loss: 2.282748261473018

Epoch: 6| Step: 10
Training loss: 0.19723870310869443
Validation loss: 2.2474264075491743

Epoch: 6| Step: 11
Training loss: 0.23206558487267506
Validation loss: 2.235648005624424

Epoch: 6| Step: 12
Training loss: 0.13178769394531858
Validation loss: 2.26801057510593

Epoch: 6| Step: 13
Training loss: 0.24924252166500852
Validation loss: 2.2539576096667955

Epoch: 493| Step: 0
Training loss: 0.13558298833657004
Validation loss: 2.3115713909588456

Epoch: 6| Step: 1
Training loss: 0.30610723330451595
Validation loss: 2.2386520242718926

Epoch: 6| Step: 2
Training loss: 0.18451253804194245
Validation loss: 2.2717046391662286

Epoch: 6| Step: 3
Training loss: 0.15509272201600166
Validation loss: 2.251343835112243

Epoch: 6| Step: 4
Training loss: 0.20203873979650316
Validation loss: 2.268386128048329

Epoch: 6| Step: 5
Training loss: 0.281851760515254
Validation loss: 2.29407545187583

Epoch: 6| Step: 6
Training loss: 0.22713074455334104
Validation loss: 2.2436496134593455

Epoch: 6| Step: 7
Training loss: 0.18923477489299095
Validation loss: 2.2750530303900964

Epoch: 6| Step: 8
Training loss: 0.18333074317713557
Validation loss: 2.266983327727242

Epoch: 6| Step: 9
Training loss: 0.35208123402091923
Validation loss: 2.3031659275461873

Epoch: 6| Step: 10
Training loss: 0.29566443982669127
Validation loss: 2.304383182891195

Epoch: 6| Step: 11
Training loss: 0.21377142412611927
Validation loss: 2.310292596954256

Epoch: 6| Step: 12
Training loss: 0.25051799397171404
Validation loss: 2.32004944236979

Epoch: 6| Step: 13
Training loss: 0.2689266057043039
Validation loss: 2.3045418274929808

Epoch: 494| Step: 0
Training loss: 0.2993030638466889
Validation loss: 2.351501570892645

Epoch: 6| Step: 1
Training loss: 0.22624285939577002
Validation loss: 2.321592874616252

Epoch: 6| Step: 2
Training loss: 0.2221353695605915
Validation loss: 2.279315009282547

Epoch: 6| Step: 3
Training loss: 0.10021438305603372
Validation loss: 2.312636213162721

Epoch: 6| Step: 4
Training loss: 0.393725015210878
Validation loss: 2.3169601893953935

Epoch: 6| Step: 5
Training loss: 0.26303654173723734
Validation loss: 2.271138198888117

Epoch: 6| Step: 6
Training loss: 0.2265839402149861
Validation loss: 2.3177872400423603

Epoch: 6| Step: 7
Training loss: 0.2974738430697658
Validation loss: 2.2846860256154375

Epoch: 6| Step: 8
Training loss: 0.19256532792909306
Validation loss: 2.30607390030581

Epoch: 6| Step: 9
Training loss: 0.26884302093023893
Validation loss: 2.266273629872401

Epoch: 6| Step: 10
Training loss: 0.17330600784384165
Validation loss: 2.23468413345352

Epoch: 6| Step: 11
Training loss: 0.3974127587963309
Validation loss: 2.238241393363972

Epoch: 6| Step: 12
Training loss: 0.25538957576355303
Validation loss: 2.2466657138398993

Epoch: 6| Step: 13
Training loss: 0.2510053566174922
Validation loss: 2.2230224307735105

Epoch: 495| Step: 0
Training loss: 0.3333909188636807
Validation loss: 2.243977788990984

Epoch: 6| Step: 1
Training loss: 0.2697827092209353
Validation loss: 2.233567104202112

Epoch: 6| Step: 2
Training loss: 0.2790920066398901
Validation loss: 2.2733059231777033

Epoch: 6| Step: 3
Training loss: 0.27216440560506805
Validation loss: 2.2625071649931403

Epoch: 6| Step: 4
Training loss: 0.16545537773902153
Validation loss: 2.312260492011638

Epoch: 6| Step: 5
Training loss: 0.1353501552382024
Validation loss: 2.3234111543388636

Epoch: 6| Step: 6
Training loss: 0.4514983346090937
Validation loss: 2.3613880167212273

Epoch: 6| Step: 7
Training loss: 0.21809126237794355
Validation loss: 2.366302993189939

Epoch: 6| Step: 8
Training loss: 0.19041005546902884
Validation loss: 2.3656358052119373

Epoch: 6| Step: 9
Training loss: 0.16191046932821263
Validation loss: 2.3456569185277694

Epoch: 6| Step: 10
Training loss: 0.30661941260570635
Validation loss: 2.3252424432149232

Epoch: 6| Step: 11
Training loss: 0.3214234184238094
Validation loss: 2.3304626748798416

Epoch: 6| Step: 12
Training loss: 0.26927553015375083
Validation loss: 2.2999675892904405

Epoch: 6| Step: 13
Training loss: 0.265815161908076
Validation loss: 2.2722820365957723

Epoch: 496| Step: 0
Training loss: 0.185150989023143
Validation loss: 2.2472457800476597

Epoch: 6| Step: 1
Training loss: 0.22481969854513148
Validation loss: 2.2626910376755456

Epoch: 6| Step: 2
Training loss: 0.22785168565851105
Validation loss: 2.2447782194925714

Epoch: 6| Step: 3
Training loss: 0.323720859943094
Validation loss: 2.279988170699056

Epoch: 6| Step: 4
Training loss: 0.13431685819961686
Validation loss: 2.2829823105201283

Epoch: 6| Step: 5
Training loss: 0.19973651136765636
Validation loss: 2.2540385520824144

Epoch: 6| Step: 6
Training loss: 0.27521038244284973
Validation loss: 2.291274765676823

Epoch: 6| Step: 7
Training loss: 0.33495230705331125
Validation loss: 2.2488685540935345

Epoch: 6| Step: 8
Training loss: 0.313058080641644
Validation loss: 2.2737929231231253

Epoch: 6| Step: 9
Training loss: 0.14980944510294555
Validation loss: 2.289104879719762

Epoch: 6| Step: 10
Training loss: 0.3824478670508361
Validation loss: 2.2411638688585804

Epoch: 6| Step: 11
Training loss: 0.1790768571992988
Validation loss: 2.214520518228638

Epoch: 6| Step: 12
Training loss: 0.28597305837609543
Validation loss: 2.2202613861573393

Epoch: 6| Step: 13
Training loss: 0.18500071000272236
Validation loss: 2.2853280753706273

Epoch: 497| Step: 0
Training loss: 0.24468888329885885
Validation loss: 2.3147764455789694

Epoch: 6| Step: 1
Training loss: 0.2975276499008464
Validation loss: 2.34243747890098

Epoch: 6| Step: 2
Training loss: 0.3824147084454023
Validation loss: 2.335092215266826

Epoch: 6| Step: 3
Training loss: 0.20860155641042813
Validation loss: 2.34535270795493

Epoch: 6| Step: 4
Training loss: 0.3220510404151856
Validation loss: 2.3591745192668094

Epoch: 6| Step: 5
Training loss: 0.14476818562119995
Validation loss: 2.322203044037267

Epoch: 6| Step: 6
Training loss: 0.1528296180997711
Validation loss: 2.318967882400931

Epoch: 6| Step: 7
Training loss: 0.21788441178308246
Validation loss: 2.300657100494159

Epoch: 6| Step: 8
Training loss: 0.20257685133139725
Validation loss: 2.3342450626914153

Epoch: 6| Step: 9
Training loss: 0.2967782113758295
Validation loss: 2.29754735088007

Epoch: 6| Step: 10
Training loss: 0.26887357332603945
Validation loss: 2.3393466568043806

Epoch: 6| Step: 11
Training loss: 0.2119920209241177
Validation loss: 2.3404890809152135

Epoch: 6| Step: 12
Training loss: 0.32607722479527684
Validation loss: 2.3213777019192423

Epoch: 6| Step: 13
Training loss: 0.07077623467960961
Validation loss: 2.3770647588885296

Epoch: 498| Step: 0
Training loss: 0.32995138048593364
Validation loss: 2.3313420635456867

Epoch: 6| Step: 1
Training loss: 0.1762850588143769
Validation loss: 2.388270481956469

Epoch: 6| Step: 2
Training loss: 0.21695150411163122
Validation loss: 2.3681005515270117

Epoch: 6| Step: 3
Training loss: 0.19803001061139414
Validation loss: 2.326668873554432

Epoch: 6| Step: 4
Training loss: 0.17324779914274102
Validation loss: 2.3612727613164224

Epoch: 6| Step: 5
Training loss: 0.2071842042450834
Validation loss: 2.3639271494117

Epoch: 6| Step: 6
Training loss: 0.25362655199515155
Validation loss: 2.363630072202885

Epoch: 6| Step: 7
Training loss: 0.1469976334243478
Validation loss: 2.3119435415494087

Epoch: 6| Step: 8
Training loss: 0.18114141343859194
Validation loss: 2.3198168648421

Epoch: 6| Step: 9
Training loss: 0.18480378980626194
Validation loss: 2.3303662331302437

Epoch: 6| Step: 10
Training loss: 0.2280417362220928
Validation loss: 2.3148866624608857

Epoch: 6| Step: 11
Training loss: 0.22150471373594935
Validation loss: 2.3219933864060556

Epoch: 6| Step: 12
Training loss: 0.40331477052885073
Validation loss: 2.3289408108157503

Epoch: 6| Step: 13
Training loss: 0.26779617001613043
Validation loss: 2.25974761972451

Epoch: 499| Step: 0
Training loss: 0.23743164528177677
Validation loss: 2.282559828913599

Epoch: 6| Step: 1
Training loss: 0.1404149155149113
Validation loss: 2.2930570268423676

Epoch: 6| Step: 2
Training loss: 0.1593004073162493
Validation loss: 2.28617923074069

Epoch: 6| Step: 3
Training loss: 0.343887832491604
Validation loss: 2.300013549982349

Epoch: 6| Step: 4
Training loss: 0.35013140697943196
Validation loss: 2.340880394892145

Epoch: 6| Step: 5
Training loss: 0.26560720215804107
Validation loss: 2.3400780509487533

Epoch: 6| Step: 6
Training loss: 0.269406289697451
Validation loss: 2.2883980142968694

Epoch: 6| Step: 7
Training loss: 0.1917452826323763
Validation loss: 2.2947749994108637

Epoch: 6| Step: 8
Training loss: 0.18052063480974548
Validation loss: 2.2894613519150866

Epoch: 6| Step: 9
Training loss: 0.17406600577078787
Validation loss: 2.2504380317039243

Epoch: 6| Step: 10
Training loss: 0.20552718633341016
Validation loss: 2.264764674330192

Epoch: 6| Step: 11
Training loss: 0.32690827393623195
Validation loss: 2.2816694129474233

Epoch: 6| Step: 12
Training loss: 0.18703004433507006
Validation loss: 2.3238987740414685

Epoch: 6| Step: 13
Training loss: 0.23748497727214393
Validation loss: 2.3238741722588627

Epoch: 500| Step: 0
Training loss: 0.38869583592766715
Validation loss: 2.358763829320542

Epoch: 6| Step: 1
Training loss: 0.3200945577949238
Validation loss: 2.345578021807009

Epoch: 6| Step: 2
Training loss: 0.1955337320499141
Validation loss: 2.2979171506001546

Epoch: 6| Step: 3
Training loss: 0.12445840255050322
Validation loss: 2.3009584637437666

Epoch: 6| Step: 4
Training loss: 0.2880690488875789
Validation loss: 2.299732346541417

Epoch: 6| Step: 5
Training loss: 0.269662811126091
Validation loss: 2.2726100301939174

Epoch: 6| Step: 6
Training loss: 0.15731016743930842
Validation loss: 2.25491049881396

Epoch: 6| Step: 7
Training loss: 0.2730327608010616
Validation loss: 2.273596297948649

Epoch: 6| Step: 8
Training loss: 0.19570973055840726
Validation loss: 2.281551169826196

Epoch: 6| Step: 9
Training loss: 0.22443371413651514
Validation loss: 2.2899026840395305

Epoch: 6| Step: 10
Training loss: 0.23517610016240362
Validation loss: 2.366798314601362

Epoch: 6| Step: 11
Training loss: 0.2597059310358472
Validation loss: 2.3772093681390642

Epoch: 6| Step: 12
Training loss: 0.16805431493147097
Validation loss: 2.3869100423227865

Epoch: 6| Step: 13
Training loss: 0.3317307851784999
Validation loss: 2.3884289927540396

Testing loss: 2.786121999817152
