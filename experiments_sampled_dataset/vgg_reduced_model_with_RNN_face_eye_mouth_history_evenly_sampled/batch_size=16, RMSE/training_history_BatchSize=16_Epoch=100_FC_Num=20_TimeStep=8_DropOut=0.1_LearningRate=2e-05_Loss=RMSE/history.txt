Epoch: 1| Step: 0
Training loss: 6.639016349274756
Validation loss: 5.833824366750147

Epoch: 6| Step: 1
Training loss: 6.096127716208398
Validation loss: 5.814542060814592

Epoch: 6| Step: 2
Training loss: 4.617111076329235
Validation loss: 5.794669403898533

Epoch: 6| Step: 3
Training loss: 6.924236643889775
Validation loss: 5.772146764155946

Epoch: 6| Step: 4
Training loss: 5.063190742746763
Validation loss: 5.747890711508193

Epoch: 6| Step: 5
Training loss: 6.0862527748488615
Validation loss: 5.721078914107057

Epoch: 6| Step: 6
Training loss: 5.909290318358914
Validation loss: 5.689423284700952

Epoch: 6| Step: 7
Training loss: 5.309118114451612
Validation loss: 5.654228554929817

Epoch: 6| Step: 8
Training loss: 5.987120474173342
Validation loss: 5.6136693814643115

Epoch: 6| Step: 9
Training loss: 4.974171685507968
Validation loss: 5.568825513874798

Epoch: 6| Step: 10
Training loss: 5.532548482607481
Validation loss: 5.518313994620903

Epoch: 6| Step: 11
Training loss: 4.064859028116108
Validation loss: 5.461860027798293

Epoch: 6| Step: 12
Training loss: 6.480611789221574
Validation loss: 5.399385554496056

Epoch: 6| Step: 13
Training loss: 4.82918124697275
Validation loss: 5.335738715731233

Epoch: 2| Step: 0
Training loss: 5.535263932714462
Validation loss: 5.265077772041041

Epoch: 6| Step: 1
Training loss: 5.7589843882478124
Validation loss: 5.191818681289243

Epoch: 6| Step: 2
Training loss: 5.508420740185278
Validation loss: 5.120533375126102

Epoch: 6| Step: 3
Training loss: 4.96267155655817
Validation loss: 5.050248700603915

Epoch: 6| Step: 4
Training loss: 4.905540658004871
Validation loss: 4.986054225976509

Epoch: 6| Step: 5
Training loss: 5.166964963279962
Validation loss: 4.926288366384654

Epoch: 6| Step: 6
Training loss: 4.324745594105548
Validation loss: 4.869522342952206

Epoch: 6| Step: 7
Training loss: 4.629466194376307
Validation loss: 4.817635838418527

Epoch: 6| Step: 8
Training loss: 4.649811870091745
Validation loss: 4.768365586710781

Epoch: 6| Step: 9
Training loss: 4.989949233536498
Validation loss: 4.723864530402273

Epoch: 6| Step: 10
Training loss: 2.926988502857812
Validation loss: 4.68875465802274

Epoch: 6| Step: 11
Training loss: 4.8011946224722495
Validation loss: 4.65673923558119

Epoch: 6| Step: 12
Training loss: 5.781968520594394
Validation loss: 4.625967157993682

Epoch: 6| Step: 13
Training loss: 4.994634419638723
Validation loss: 4.592182208036966

Epoch: 3| Step: 0
Training loss: 4.989173994482132
Validation loss: 4.5577586957526

Epoch: 6| Step: 1
Training loss: 4.508443328775387
Validation loss: 4.523096711790993

Epoch: 6| Step: 2
Training loss: 5.324277321933418
Validation loss: 4.5052684447274425

Epoch: 6| Step: 3
Training loss: 3.9989468857141857
Validation loss: 4.489810820305245

Epoch: 6| Step: 4
Training loss: 5.406208721730962
Validation loss: 4.473067935349897

Epoch: 6| Step: 5
Training loss: 4.014553298138381
Validation loss: 4.450213328593523

Epoch: 6| Step: 6
Training loss: 4.46830779335229
Validation loss: 4.4222790649308035

Epoch: 6| Step: 7
Training loss: 5.035161363881713
Validation loss: 4.39638536621593

Epoch: 6| Step: 8
Training loss: 5.054659010557755
Validation loss: 4.373571079901531

Epoch: 6| Step: 9
Training loss: 4.145027785259849
Validation loss: 4.346559654738965

Epoch: 6| Step: 10
Training loss: 4.327600771007827
Validation loss: 4.319245441556154

Epoch: 6| Step: 11
Training loss: 3.070173342902441
Validation loss: 4.297436060814307

Epoch: 6| Step: 12
Training loss: 3.4775370057123234
Validation loss: 4.281475171697049

Epoch: 6| Step: 13
Training loss: 5.347768064880603
Validation loss: 4.26379010092286

Epoch: 4| Step: 0
Training loss: 3.3915901744068093
Validation loss: 4.23848219519397

Epoch: 6| Step: 1
Training loss: 3.7770684190228776
Validation loss: 4.219693073704514

Epoch: 6| Step: 2
Training loss: 4.691808729352895
Validation loss: 4.211040907945899

Epoch: 6| Step: 3
Training loss: 4.588414421727573
Validation loss: 4.185351765221915

Epoch: 6| Step: 4
Training loss: 4.866119512517898
Validation loss: 4.1658321004218655

Epoch: 6| Step: 5
Training loss: 3.4174444352316113
Validation loss: 4.146324297251703

Epoch: 6| Step: 6
Training loss: 4.313820899241462
Validation loss: 4.129703215817

Epoch: 6| Step: 7
Training loss: 4.631656290166011
Validation loss: 4.109609107411814

Epoch: 6| Step: 8
Training loss: 4.860557093460487
Validation loss: 4.0843043442070215

Epoch: 6| Step: 9
Training loss: 3.9496449467880623
Validation loss: 4.062787281666545

Epoch: 6| Step: 10
Training loss: 5.099904467118033
Validation loss: 4.051087593244788

Epoch: 6| Step: 11
Training loss: 4.084816073102218
Validation loss: 4.035142633665117

Epoch: 6| Step: 12
Training loss: 3.9870629911209097
Validation loss: 4.016553688800689

Epoch: 6| Step: 13
Training loss: 2.702473909320921
Validation loss: 4.000607780201877

Epoch: 5| Step: 0
Training loss: 5.122055138055454
Validation loss: 3.985071635526282

Epoch: 6| Step: 1
Training loss: 3.9215454935812666
Validation loss: 3.9707556305956238

Epoch: 6| Step: 2
Training loss: 3.7519808306011164
Validation loss: 3.9580362637004916

Epoch: 6| Step: 3
Training loss: 4.308015122212652
Validation loss: 3.949258444106529

Epoch: 6| Step: 4
Training loss: 2.6278912198736024
Validation loss: 3.93904201811727

Epoch: 6| Step: 5
Training loss: 2.7913717332355947
Validation loss: 3.9274499719373086

Epoch: 6| Step: 6
Training loss: 4.167782036586389
Validation loss: 3.920191311048924

Epoch: 6| Step: 7
Training loss: 4.648758769754055
Validation loss: 3.9091031456916476

Epoch: 6| Step: 8
Training loss: 4.039514394601095
Validation loss: 3.8994675214152026

Epoch: 6| Step: 9
Training loss: 5.001528696972619
Validation loss: 3.893540647072713

Epoch: 6| Step: 10
Training loss: 3.5639883579701928
Validation loss: 3.8814286564845784

Epoch: 6| Step: 11
Training loss: 3.9201574934247723
Validation loss: 3.8703056399010594

Epoch: 6| Step: 12
Training loss: 3.7570525925716836
Validation loss: 3.8636807061283487

Epoch: 6| Step: 13
Training loss: 5.007455226871339
Validation loss: 3.8551285164052014

Epoch: 6| Step: 0
Training loss: 4.680908043955446
Validation loss: 3.846009438843053

Epoch: 6| Step: 1
Training loss: 4.073144670561582
Validation loss: 3.8363886708775907

Epoch: 6| Step: 2
Training loss: 3.5903649351328677
Validation loss: 3.8280718346211136

Epoch: 6| Step: 3
Training loss: 2.7013471633403965
Validation loss: 3.8186402106516986

Epoch: 6| Step: 4
Training loss: 3.416881244403219
Validation loss: 3.8118338753569714

Epoch: 6| Step: 5
Training loss: 4.451605072299941
Validation loss: 3.8034766790298606

Epoch: 6| Step: 6
Training loss: 4.725351730253461
Validation loss: 3.7947936043939814

Epoch: 6| Step: 7
Training loss: 3.6982281334315084
Validation loss: 3.7884908657882668

Epoch: 6| Step: 8
Training loss: 3.825899434771561
Validation loss: 3.7802269993422026

Epoch: 6| Step: 9
Training loss: 3.7666382751970224
Validation loss: 3.7738346077817555

Epoch: 6| Step: 10
Training loss: 4.641856226083786
Validation loss: 3.767033681068778

Epoch: 6| Step: 11
Training loss: 3.955273914906951
Validation loss: 3.7568755775325506

Epoch: 6| Step: 12
Training loss: 3.5375381791174183
Validation loss: 3.750131783853092

Epoch: 6| Step: 13
Training loss: 4.0531033341086795
Validation loss: 3.7462843859999855

Epoch: 7| Step: 0
Training loss: 3.2466380997588358
Validation loss: 3.7373812796103145

Epoch: 6| Step: 1
Training loss: 5.362967574357809
Validation loss: 3.7336498161694953

Epoch: 6| Step: 2
Training loss: 4.5459381921261155
Validation loss: 3.7226260590681335

Epoch: 6| Step: 3
Training loss: 4.015136451540259
Validation loss: 3.71921854642733

Epoch: 6| Step: 4
Training loss: 3.9027604041989314
Validation loss: 3.711376786194441

Epoch: 6| Step: 5
Training loss: 4.215106888724653
Validation loss: 3.7062802486295148

Epoch: 6| Step: 6
Training loss: 3.5723690729195177
Validation loss: 3.701454455583443

Epoch: 6| Step: 7
Training loss: 3.9476038558083024
Validation loss: 3.690614292144211

Epoch: 6| Step: 8
Training loss: 3.9545218069391925
Validation loss: 3.6831064108590943

Epoch: 6| Step: 9
Training loss: 3.3959512670590173
Validation loss: 3.677633192411336

Epoch: 6| Step: 10
Training loss: 2.96290156865975
Validation loss: 3.6730712268633146

Epoch: 6| Step: 11
Training loss: 3.2395497082174427
Validation loss: 3.6688127967684316

Epoch: 6| Step: 12
Training loss: 3.134690480505107
Validation loss: 3.661644962432103

Epoch: 6| Step: 13
Training loss: 4.519782980038478
Validation loss: 3.656354497582463

Epoch: 8| Step: 0
Training loss: 4.170457920756284
Validation loss: 3.6470924732201055

Epoch: 6| Step: 1
Training loss: 2.3743690857357986
Validation loss: 3.6422150356109015

Epoch: 6| Step: 2
Training loss: 3.8452763201930877
Validation loss: 3.6418629590277765

Epoch: 6| Step: 3
Training loss: 3.776025993928502
Validation loss: 3.6331050335576185

Epoch: 6| Step: 4
Training loss: 4.006829630181789
Validation loss: 3.6237425442480444

Epoch: 6| Step: 5
Training loss: 3.28380463472301
Validation loss: 3.6194058408374166

Epoch: 6| Step: 6
Training loss: 4.305107968490608
Validation loss: 3.617066255462261

Epoch: 6| Step: 7
Training loss: 4.400601926726034
Validation loss: 3.611962086473131

Epoch: 6| Step: 8
Training loss: 4.251891220265943
Validation loss: 3.6057090429894347

Epoch: 6| Step: 9
Training loss: 2.9731788125820677
Validation loss: 3.5965530898769056

Epoch: 6| Step: 10
Training loss: 3.7937257366881387
Validation loss: 3.591843882187013

Epoch: 6| Step: 11
Training loss: 3.3136122653559195
Validation loss: 3.587820672236345

Epoch: 6| Step: 12
Training loss: 4.576628456669331
Validation loss: 3.582959145318091

Epoch: 6| Step: 13
Training loss: 3.484430834404106
Validation loss: 3.576038109363424

Epoch: 9| Step: 0
Training loss: 3.730113387033557
Validation loss: 3.57309912553499

Epoch: 6| Step: 1
Training loss: 4.086750832127107
Validation loss: 3.5760404880172696

Epoch: 6| Step: 2
Training loss: 3.9396147120352603
Validation loss: 3.5605449367240243

Epoch: 6| Step: 3
Training loss: 3.35532180766367
Validation loss: 3.567032724532499

Epoch: 6| Step: 4
Training loss: 4.838023486139914
Validation loss: 3.573853913359254

Epoch: 6| Step: 5
Training loss: 2.36795031654586
Validation loss: 3.5540016375380077

Epoch: 6| Step: 6
Training loss: 3.787178877005356
Validation loss: 3.5460248915620274

Epoch: 6| Step: 7
Training loss: 3.86819919492219
Validation loss: 3.5452444710512396

Epoch: 6| Step: 8
Training loss: 3.3087652493000443
Validation loss: 3.544746769799368

Epoch: 6| Step: 9
Training loss: 3.7903403732730485
Validation loss: 3.541815216211274

Epoch: 6| Step: 10
Training loss: 3.489459514793559
Validation loss: 3.5332738449253274

Epoch: 6| Step: 11
Training loss: 4.218873876942848
Validation loss: 3.5262512928973346

Epoch: 6| Step: 12
Training loss: 3.62202739510163
Validation loss: 3.5224622664592133

Epoch: 6| Step: 13
Training loss: 3.609856775670876
Validation loss: 3.5198000178996587

Epoch: 10| Step: 0
Training loss: 4.589284789767551
Validation loss: 3.5162147893191444

Epoch: 6| Step: 1
Training loss: 3.5452420008691314
Validation loss: 3.507362371739544

Epoch: 6| Step: 2
Training loss: 4.15830082597175
Validation loss: 3.5030659959833326

Epoch: 6| Step: 3
Training loss: 3.53135640481973
Validation loss: 3.5005899318893885

Epoch: 6| Step: 4
Training loss: 3.2800952150899754
Validation loss: 3.495815374314155

Epoch: 6| Step: 5
Training loss: 3.702472355627987
Validation loss: 3.490757499315304

Epoch: 6| Step: 6
Training loss: 3.752318746216207
Validation loss: 3.4876233437842044

Epoch: 6| Step: 7
Training loss: 3.1075697982940835
Validation loss: 3.4843554612788243

Epoch: 6| Step: 8
Training loss: 3.510125092453665
Validation loss: 3.4825793447120765

Epoch: 6| Step: 9
Training loss: 3.8902582815373985
Validation loss: 3.477799657241108

Epoch: 6| Step: 10
Training loss: 3.724293399844459
Validation loss: 3.474152347313803

Epoch: 6| Step: 11
Training loss: 3.1960567736112706
Validation loss: 3.4705667280742825

Epoch: 6| Step: 12
Training loss: 3.8225066392141085
Validation loss: 3.4668553366289294

Epoch: 6| Step: 13
Training loss: 3.9009953671378734
Validation loss: 3.465769965716878

Epoch: 11| Step: 0
Training loss: 3.9776003219641187
Validation loss: 3.463343151891515

Epoch: 6| Step: 1
Training loss: 3.0806013496220133
Validation loss: 3.4673463567644744

Epoch: 6| Step: 2
Training loss: 3.489921910196562
Validation loss: 3.472449015002674

Epoch: 6| Step: 3
Training loss: 4.318388967701634
Validation loss: 3.4828362853071293

Epoch: 6| Step: 4
Training loss: 2.8297451710629877
Validation loss: 3.4609279459752433

Epoch: 6| Step: 5
Training loss: 3.430251368439869
Validation loss: 3.4633211598445923

Epoch: 6| Step: 6
Training loss: 4.002547406613381
Validation loss: 3.4574100187469146

Epoch: 6| Step: 7
Training loss: 3.6314103897049463
Validation loss: 3.455562172667852

Epoch: 6| Step: 8
Training loss: 3.7191972223203793
Validation loss: 3.4528208977190697

Epoch: 6| Step: 9
Training loss: 4.40672483658787
Validation loss: 3.4492248565575547

Epoch: 6| Step: 10
Training loss: 3.1586376261677094
Validation loss: 3.4597887094477042

Epoch: 6| Step: 11
Training loss: 4.24534351841585
Validation loss: 3.4437871078720184

Epoch: 6| Step: 12
Training loss: 3.024474446694985
Validation loss: 3.449399458205041

Epoch: 6| Step: 13
Training loss: 3.7728322809402726
Validation loss: 3.4603976421672002

Epoch: 12| Step: 0
Training loss: 3.6744936432024953
Validation loss: 3.4626787172642355

Epoch: 6| Step: 1
Training loss: 4.517092350868467
Validation loss: 3.448500068831014

Epoch: 6| Step: 2
Training loss: 3.0096629606111396
Validation loss: 3.4382785351779406

Epoch: 6| Step: 3
Training loss: 3.902287296654346
Validation loss: 3.4332453749210017

Epoch: 6| Step: 4
Training loss: 3.943224061455338
Validation loss: 3.43493081715117

Epoch: 6| Step: 5
Training loss: 3.6443878505416767
Validation loss: 3.4396936064306356

Epoch: 6| Step: 6
Training loss: 4.137781858495695
Validation loss: 3.437077242900759

Epoch: 6| Step: 7
Training loss: 3.336669841489193
Validation loss: 3.4283573956503863

Epoch: 6| Step: 8
Training loss: 2.5161008207137363
Validation loss: 3.424074792055813

Epoch: 6| Step: 9
Training loss: 3.7229554575454147
Validation loss: 3.4222258345209275

Epoch: 6| Step: 10
Training loss: 3.6264266791132527
Validation loss: 3.422151030077992

Epoch: 6| Step: 11
Training loss: 3.4112306630504547
Validation loss: 3.4216131924075905

Epoch: 6| Step: 12
Training loss: 2.954743441370382
Validation loss: 3.433072371162167

Epoch: 6| Step: 13
Training loss: 4.730825976138195
Validation loss: 3.4171866874821957

Epoch: 13| Step: 0
Training loss: 4.58937726186608
Validation loss: 3.417723561014116

Epoch: 6| Step: 1
Training loss: 3.807743044013527
Validation loss: 3.423979481384318

Epoch: 6| Step: 2
Training loss: 3.6829738965151666
Validation loss: 3.439254205750723

Epoch: 6| Step: 3
Training loss: 3.3576860307296497
Validation loss: 3.429575300636724

Epoch: 6| Step: 4
Training loss: 3.3464904678234046
Validation loss: 3.429162505449882

Epoch: 6| Step: 5
Training loss: 3.7791254049037284
Validation loss: 3.448978171570243

Epoch: 6| Step: 6
Training loss: 2.93879638635266
Validation loss: 3.4650353553304836

Epoch: 6| Step: 7
Training loss: 3.6027586433911023
Validation loss: 3.4757094590858024

Epoch: 6| Step: 8
Training loss: 3.0933933245114233
Validation loss: 3.4875294228695073

Epoch: 6| Step: 9
Training loss: 3.338699948054579
Validation loss: 3.4772612288608724

Epoch: 6| Step: 10
Training loss: 4.704839552313415
Validation loss: 3.4510248713745506

Epoch: 6| Step: 11
Training loss: 2.6977268186564305
Validation loss: 3.4257110088238476

Epoch: 6| Step: 12
Training loss: 3.753911203942816
Validation loss: 3.4173543784678646

Epoch: 6| Step: 13
Training loss: 4.336754964114806
Validation loss: 3.421594263325743

Epoch: 14| Step: 0
Training loss: 3.1385697809313386
Validation loss: 3.4780849337026414

Epoch: 6| Step: 1
Training loss: 4.195237029407297
Validation loss: 3.4148381550422813

Epoch: 6| Step: 2
Training loss: 4.143767693713403
Validation loss: 3.40790792749314

Epoch: 6| Step: 3
Training loss: 3.370732187483356
Validation loss: 3.4103594719426833

Epoch: 6| Step: 4
Training loss: 3.886589439196282
Validation loss: 3.413852567209809

Epoch: 6| Step: 5
Training loss: 4.085359317286886
Validation loss: 3.4281415480308732

Epoch: 6| Step: 6
Training loss: 4.0503056540356654
Validation loss: 3.4038566255878773

Epoch: 6| Step: 7
Training loss: 3.4007620742786537
Validation loss: 3.3959832404048607

Epoch: 6| Step: 8
Training loss: 3.5152595838738
Validation loss: 3.3918920857833927

Epoch: 6| Step: 9
Training loss: 2.7935036740528947
Validation loss: 3.3918635990217694

Epoch: 6| Step: 10
Training loss: 3.6269970358643726
Validation loss: 3.400954806868761

Epoch: 6| Step: 11
Training loss: 3.105291243944245
Validation loss: 3.4117736134663166

Epoch: 6| Step: 12
Training loss: 3.5993701277824237
Validation loss: 3.405715299817713

Epoch: 6| Step: 13
Training loss: 3.8040111653417794
Validation loss: 3.386928131712136

Epoch: 15| Step: 0
Training loss: 3.7020781119672415
Validation loss: 3.3838501688894005

Epoch: 6| Step: 1
Training loss: 4.194310358078288
Validation loss: 3.3839455885946075

Epoch: 6| Step: 2
Training loss: 4.129153847826869
Validation loss: 3.383508643540651

Epoch: 6| Step: 3
Training loss: 4.080015949891273
Validation loss: 3.382621636413366

Epoch: 6| Step: 4
Training loss: 4.197073625421874
Validation loss: 3.381310619001697

Epoch: 6| Step: 5
Training loss: 3.9579646825617028
Validation loss: 3.383135528779342

Epoch: 6| Step: 6
Training loss: 2.4241649015631554
Validation loss: 3.3808396657088893

Epoch: 6| Step: 7
Training loss: 3.7010943160574197
Validation loss: 3.3824685263907526

Epoch: 6| Step: 8
Training loss: 3.750626320987285
Validation loss: 3.381072740891896

Epoch: 6| Step: 9
Training loss: 2.9013137735427423
Validation loss: 3.3762371373884785

Epoch: 6| Step: 10
Training loss: 3.314736960491516
Validation loss: 3.3747999708541943

Epoch: 6| Step: 11
Training loss: 2.401584710022797
Validation loss: 3.3731840862601623

Epoch: 6| Step: 12
Training loss: 3.571412298982879
Validation loss: 3.370286324405319

Epoch: 6| Step: 13
Training loss: 3.547826698104793
Validation loss: 3.368941199161014

Epoch: 16| Step: 0
Training loss: 4.4333302423758
Validation loss: 3.368304765217486

Epoch: 6| Step: 1
Training loss: 3.519106078213852
Validation loss: 3.3665479184845246

Epoch: 6| Step: 2
Training loss: 3.524669626324068
Validation loss: 3.3653597210100044

Epoch: 6| Step: 3
Training loss: 3.916117907018368
Validation loss: 3.3646302761708253

Epoch: 6| Step: 4
Training loss: 3.1173237935723277
Validation loss: 3.3638416294268376

Epoch: 6| Step: 5
Training loss: 4.281483219226551
Validation loss: 3.3626892133586983

Epoch: 6| Step: 6
Training loss: 2.9919707615693603
Validation loss: 3.361966816052033

Epoch: 6| Step: 7
Training loss: 3.312922900573088
Validation loss: 3.3610941535248253

Epoch: 6| Step: 8
Training loss: 3.6437424831410996
Validation loss: 3.360471448374291

Epoch: 6| Step: 9
Training loss: 2.9196984655334997
Validation loss: 3.3590522658784083

Epoch: 6| Step: 10
Training loss: 3.9514339886180876
Validation loss: 3.358184606597895

Epoch: 6| Step: 11
Training loss: 4.062497652493312
Validation loss: 3.3574654167713645

Epoch: 6| Step: 12
Training loss: 3.047536455394824
Validation loss: 3.3563201713028428

Epoch: 6| Step: 13
Training loss: 2.8350825426575574
Validation loss: 3.3552520550953555

Epoch: 17| Step: 0
Training loss: 3.7527255008450036
Validation loss: 3.3545411337252697

Epoch: 6| Step: 1
Training loss: 3.916503388809419
Validation loss: 3.3529718837021685

Epoch: 6| Step: 2
Training loss: 3.3504377847692344
Validation loss: 3.3522455691752087

Epoch: 6| Step: 3
Training loss: 3.5831772230578856
Validation loss: 3.351608201476961

Epoch: 6| Step: 4
Training loss: 4.171554724582962
Validation loss: 3.3502324737639366

Epoch: 6| Step: 5
Training loss: 4.317270266678007
Validation loss: 3.349411452914511

Epoch: 6| Step: 6
Training loss: 3.514725226654891
Validation loss: 3.348036703905705

Epoch: 6| Step: 7
Training loss: 2.41449286812815
Validation loss: 3.346665485364549

Epoch: 6| Step: 8
Training loss: 4.155864496924422
Validation loss: 3.3460877214246407

Epoch: 6| Step: 9
Training loss: 4.283413528305173
Validation loss: 3.3451547808534428

Epoch: 6| Step: 10
Training loss: 2.9393155594886293
Validation loss: 3.343813857522135

Epoch: 6| Step: 11
Training loss: 2.5034141116394366
Validation loss: 3.3428445808667133

Epoch: 6| Step: 12
Training loss: 3.0779225239263996
Validation loss: 3.3417890225010725

Epoch: 6| Step: 13
Training loss: 3.455573409287538
Validation loss: 3.3411532295262902

Epoch: 18| Step: 0
Training loss: 3.472947888309312
Validation loss: 3.3400065739958533

Epoch: 6| Step: 1
Training loss: 3.5543078544691116
Validation loss: 3.339266051006223

Epoch: 6| Step: 2
Training loss: 4.555161099814547
Validation loss: 3.338195285730043

Epoch: 6| Step: 3
Training loss: 3.7725797511544803
Validation loss: 3.337691077080831

Epoch: 6| Step: 4
Training loss: 3.3889292330676843
Validation loss: 3.3359973373093594

Epoch: 6| Step: 5
Training loss: 3.2487586658533933
Validation loss: 3.3355261440093127

Epoch: 6| Step: 6
Training loss: 4.26262159425804
Validation loss: 3.3343698417992034

Epoch: 6| Step: 7
Training loss: 3.5297439199179528
Validation loss: 3.3333300580244485

Epoch: 6| Step: 8
Training loss: 1.8752036937696772
Validation loss: 3.332446196134317

Epoch: 6| Step: 9
Training loss: 2.7463011575135035
Validation loss: 3.3312749218875717

Epoch: 6| Step: 10
Training loss: 4.067954758894223
Validation loss: 3.3301259673810213

Epoch: 6| Step: 11
Training loss: 4.263364982656516
Validation loss: 3.3294884107793483

Epoch: 6| Step: 12
Training loss: 3.0950598207772098
Validation loss: 3.327924496753509

Epoch: 6| Step: 13
Training loss: 3.149661600010401
Validation loss: 3.327200741654451

Epoch: 19| Step: 0
Training loss: 3.548047649110892
Validation loss: 3.3256152588955215

Epoch: 6| Step: 1
Training loss: 3.465008341461314
Validation loss: 3.324489476779038

Epoch: 6| Step: 2
Training loss: 3.735756207657855
Validation loss: 3.3232351767588755

Epoch: 6| Step: 3
Training loss: 3.362332909271989
Validation loss: 3.321626820545366

Epoch: 6| Step: 4
Training loss: 3.6595623955440195
Validation loss: 3.3209602850363362

Epoch: 6| Step: 5
Training loss: 3.825126875225483
Validation loss: 3.318400280397036

Epoch: 6| Step: 6
Training loss: 4.372071512208066
Validation loss: 3.316756657018382

Epoch: 6| Step: 7
Training loss: 3.237181694260499
Validation loss: 3.3162977211813027

Epoch: 6| Step: 8
Training loss: 2.6788269974629615
Validation loss: 3.3169700674449407

Epoch: 6| Step: 9
Training loss: 3.419941395039952
Validation loss: 3.3142798036895114

Epoch: 6| Step: 10
Training loss: 3.604411622177723
Validation loss: 3.313894512714285

Epoch: 6| Step: 11
Training loss: 3.753394815495861
Validation loss: 3.312988961820384

Epoch: 6| Step: 12
Training loss: 3.1200210580359693
Validation loss: 3.3112337149695272

Epoch: 6| Step: 13
Training loss: 3.948690226248275
Validation loss: 3.310322509232795

Epoch: 20| Step: 0
Training loss: 3.9767375675179024
Validation loss: 3.309049657893153

Epoch: 6| Step: 1
Training loss: 3.8761498990829977
Validation loss: 3.307753448507174

Epoch: 6| Step: 2
Training loss: 2.5180345451524397
Validation loss: 3.307175102760364

Epoch: 6| Step: 3
Training loss: 2.604993053287901
Validation loss: 3.3054856129542047

Epoch: 6| Step: 4
Training loss: 3.4443723472788506
Validation loss: 3.305037843613129

Epoch: 6| Step: 5
Training loss: 3.394583645713651
Validation loss: 3.3040043069812945

Epoch: 6| Step: 6
Training loss: 3.6271442779965786
Validation loss: 3.3031032316476834

Epoch: 6| Step: 7
Training loss: 3.7995435340175443
Validation loss: 3.3021673117627874

Epoch: 6| Step: 8
Training loss: 3.6216765328799694
Validation loss: 3.301149664780016

Epoch: 6| Step: 9
Training loss: 4.4788414179090275
Validation loss: 3.3002402066847436

Epoch: 6| Step: 10
Training loss: 3.4637252567746977
Validation loss: 3.2995394719433655

Epoch: 6| Step: 11
Training loss: 4.05869572853715
Validation loss: 3.298535400339243

Epoch: 6| Step: 12
Training loss: 3.203447130334088
Validation loss: 3.2975954847925024

Epoch: 6| Step: 13
Training loss: 2.6222348863040845
Validation loss: 3.296703068784931

Epoch: 21| Step: 0
Training loss: 2.864991056152018
Validation loss: 3.2959298118030804

Epoch: 6| Step: 1
Training loss: 4.048092456455354
Validation loss: 3.294810391394085

Epoch: 6| Step: 2
Training loss: 3.239235584365624
Validation loss: 3.293956884077061

Epoch: 6| Step: 3
Training loss: 2.9904287562861853
Validation loss: 3.29297426035695

Epoch: 6| Step: 4
Training loss: 3.284630333061199
Validation loss: 3.292078750712467

Epoch: 6| Step: 5
Training loss: 3.373315744115435
Validation loss: 3.2915454627750265

Epoch: 6| Step: 6
Training loss: 3.538620809651279
Validation loss: 3.290475969290124

Epoch: 6| Step: 7
Training loss: 3.280217471472928
Validation loss: 3.2896559573516466

Epoch: 6| Step: 8
Training loss: 3.5552582335004246
Validation loss: 3.288950383617167

Epoch: 6| Step: 9
Training loss: 3.7176370958960243
Validation loss: 3.288124953798839

Epoch: 6| Step: 10
Training loss: 3.97946378920082
Validation loss: 3.287150697349264

Epoch: 6| Step: 11
Training loss: 3.4379682742125746
Validation loss: 3.2863528714448442

Epoch: 6| Step: 12
Training loss: 4.349112075859701
Validation loss: 3.2851379892680797

Epoch: 6| Step: 13
Training loss: 3.559648945676396
Validation loss: 3.2844836449399795

Epoch: 22| Step: 0
Training loss: 3.630911380914534
Validation loss: 3.2833014275592576

Epoch: 6| Step: 1
Training loss: 3.3821771390647486
Validation loss: 3.2827446240237657

Epoch: 6| Step: 2
Training loss: 3.355206693601321
Validation loss: 3.2817326000862197

Epoch: 6| Step: 3
Training loss: 3.813138564366573
Validation loss: 3.280436526795302

Epoch: 6| Step: 4
Training loss: 3.140334690018252
Validation loss: 3.279809838676958

Epoch: 6| Step: 5
Training loss: 3.897765443778257
Validation loss: 3.2787280288364284

Epoch: 6| Step: 6
Training loss: 4.546160559877053
Validation loss: 3.2778558665000626

Epoch: 6| Step: 7
Training loss: 3.1280716105505677
Validation loss: 3.277256453396466

Epoch: 6| Step: 8
Training loss: 2.7954826938596313
Validation loss: 3.2758249589749022

Epoch: 6| Step: 9
Training loss: 4.01554520227134
Validation loss: 3.2747632703004173

Epoch: 6| Step: 10
Training loss: 2.783393034228099
Validation loss: 3.2741584881531427

Epoch: 6| Step: 11
Training loss: 3.9716214583034772
Validation loss: 3.2731173955456314

Epoch: 6| Step: 12
Training loss: 3.336963933405136
Validation loss: 3.272212382386518

Epoch: 6| Step: 13
Training loss: 2.725862254641734
Validation loss: 3.271517994217704

Epoch: 23| Step: 0
Training loss: 3.9047069706303517
Validation loss: 3.270447524792438

Epoch: 6| Step: 1
Training loss: 3.3482622735353886
Validation loss: 3.269702547918669

Epoch: 6| Step: 2
Training loss: 4.032500553592235
Validation loss: 3.2684599071289577

Epoch: 6| Step: 3
Training loss: 3.1722458495777994
Validation loss: 3.267786335144179

Epoch: 6| Step: 4
Training loss: 3.8736321280740458
Validation loss: 3.2665342162400526

Epoch: 6| Step: 5
Training loss: 2.5025677845374807
Validation loss: 3.26560655939872

Epoch: 6| Step: 6
Training loss: 2.974423578662793
Validation loss: 3.2648095150289778

Epoch: 6| Step: 7
Training loss: 4.639521714914594
Validation loss: 3.2637096215871004

Epoch: 6| Step: 8
Training loss: 3.5611595174984543
Validation loss: 3.2627506409236133

Epoch: 6| Step: 9
Training loss: 3.715463676832584
Validation loss: 3.261081210442227

Epoch: 6| Step: 10
Training loss: 3.0292594115389755
Validation loss: 3.2598741201772232

Epoch: 6| Step: 11
Training loss: 3.279015352344085
Validation loss: 3.2582521513511633

Epoch: 6| Step: 12
Training loss: 3.076118086087272
Validation loss: 3.2575011666381553

Epoch: 6| Step: 13
Training loss: 3.609420577913325
Validation loss: 3.2559303679342757

Epoch: 24| Step: 0
Training loss: 2.779509782175883
Validation loss: 3.255258759270048

Epoch: 6| Step: 1
Training loss: 3.5796486887832195
Validation loss: 3.254281786503861

Epoch: 6| Step: 2
Training loss: 2.948053758935914
Validation loss: 3.253126021444895

Epoch: 6| Step: 3
Training loss: 3.9817263906562976
Validation loss: 3.252115187640339

Epoch: 6| Step: 4
Training loss: 3.4457222831080174
Validation loss: 3.251761586155145

Epoch: 6| Step: 5
Training loss: 4.023274420238678
Validation loss: 3.2509117835273584

Epoch: 6| Step: 6
Training loss: 3.973265714603388
Validation loss: 3.2496526996395954

Epoch: 6| Step: 7
Training loss: 3.117211822185422
Validation loss: 3.248762341543881

Epoch: 6| Step: 8
Training loss: 3.799285374754795
Validation loss: 3.2480734391290667

Epoch: 6| Step: 9
Training loss: 3.440759119508578
Validation loss: 3.2472728191460694

Epoch: 6| Step: 10
Training loss: 2.985153016939986
Validation loss: 3.2463744586718333

Epoch: 6| Step: 11
Training loss: 2.9644262047466574
Validation loss: 3.245842630014274

Epoch: 6| Step: 12
Training loss: 3.816059389623898
Validation loss: 3.2443588961890124

Epoch: 6| Step: 13
Training loss: 4.059210516553705
Validation loss: 3.244006386208333

Epoch: 25| Step: 0
Training loss: 3.3873925336281716
Validation loss: 3.2430164197220273

Epoch: 6| Step: 1
Training loss: 2.483216501427664
Validation loss: 3.242495604176463

Epoch: 6| Step: 2
Training loss: 3.3480584738671446
Validation loss: 3.2414810693985996

Epoch: 6| Step: 3
Training loss: 3.464652588397367
Validation loss: 3.241047549695407

Epoch: 6| Step: 4
Training loss: 4.08095688986822
Validation loss: 3.240921247269705

Epoch: 6| Step: 5
Training loss: 4.088129276284479
Validation loss: 3.2393573916567044

Epoch: 6| Step: 6
Training loss: 3.555671572448125
Validation loss: 3.2382487044031243

Epoch: 6| Step: 7
Training loss: 3.712157488606167
Validation loss: 3.237300859424686

Epoch: 6| Step: 8
Training loss: 2.9995374322950625
Validation loss: 3.2369963094118956

Epoch: 6| Step: 9
Training loss: 3.7738796314720156
Validation loss: 3.2359124995196

Epoch: 6| Step: 10
Training loss: 3.377528620894416
Validation loss: 3.235125899530161

Epoch: 6| Step: 11
Training loss: 3.1054139330362394
Validation loss: 3.233997912898727

Epoch: 6| Step: 12
Training loss: 3.653045945825485
Validation loss: 3.233267951886158

Epoch: 6| Step: 13
Training loss: 3.5892819700784138
Validation loss: 3.2325283249996852

Epoch: 26| Step: 0
Training loss: 2.5716397183634516
Validation loss: 3.231551109243665

Epoch: 6| Step: 1
Training loss: 3.7046001087758964
Validation loss: 3.2308477248953413

Epoch: 6| Step: 2
Training loss: 2.0866439708820144
Validation loss: 3.2302234890504784

Epoch: 6| Step: 3
Training loss: 3.194590741184559
Validation loss: 3.229097757123566

Epoch: 6| Step: 4
Training loss: 4.199744244009138
Validation loss: 3.228448618201375

Epoch: 6| Step: 5
Training loss: 3.2221697075901696
Validation loss: 3.227674341999256

Epoch: 6| Step: 6
Training loss: 3.772583037436423
Validation loss: 3.2269880733251477

Epoch: 6| Step: 7
Training loss: 3.699641267036676
Validation loss: 3.225836293943866

Epoch: 6| Step: 8
Training loss: 3.7262703643109276
Validation loss: 3.2248558276759582

Epoch: 6| Step: 9
Training loss: 4.0539872404555455
Validation loss: 3.22437917564276

Epoch: 6| Step: 10
Training loss: 3.5956258107606667
Validation loss: 3.2234222466306925

Epoch: 6| Step: 11
Training loss: 2.8883796838151277
Validation loss: 3.2226142072623105

Epoch: 6| Step: 12
Training loss: 3.3343002983098393
Validation loss: 3.221693982260086

Epoch: 6| Step: 13
Training loss: 4.437179338931417
Validation loss: 3.2210732954001577

Epoch: 27| Step: 0
Training loss: 3.8427949044428984
Validation loss: 3.220316988830372

Epoch: 6| Step: 1
Training loss: 3.074011518190009
Validation loss: 3.219448967481362

Epoch: 6| Step: 2
Training loss: 3.8539001922590743
Validation loss: 3.2185058580806367

Epoch: 6| Step: 3
Training loss: 3.0834778073116715
Validation loss: 3.2174169239177206

Epoch: 6| Step: 4
Training loss: 2.8344623522772445
Validation loss: 3.216579342111115

Epoch: 6| Step: 5
Training loss: 2.8857149229359225
Validation loss: 3.2158147456721573

Epoch: 6| Step: 6
Training loss: 3.4528943843559134
Validation loss: 3.2153799476840113

Epoch: 6| Step: 7
Training loss: 4.003260713967321
Validation loss: 3.214204582450928

Epoch: 6| Step: 8
Training loss: 3.3750666859007903
Validation loss: 3.2137436929485323

Epoch: 6| Step: 9
Training loss: 3.1700407089363183
Validation loss: 3.212510787813602

Epoch: 6| Step: 10
Training loss: 3.7927350366091175
Validation loss: 3.2115679830177326

Epoch: 6| Step: 11
Training loss: 3.555248710849368
Validation loss: 3.2110164217362525

Epoch: 6| Step: 12
Training loss: 4.471204390449164
Validation loss: 3.2099311476548014

Epoch: 6| Step: 13
Training loss: 2.064063433315577
Validation loss: 3.2094089818148066

Epoch: 28| Step: 0
Training loss: 3.404854864984898
Validation loss: 3.208186418045907

Epoch: 6| Step: 1
Training loss: 3.890570582733144
Validation loss: 3.2077551239337514

Epoch: 6| Step: 2
Training loss: 3.2112000443911395
Validation loss: 3.2067100393320174

Epoch: 6| Step: 3
Training loss: 3.642369192231827
Validation loss: 3.206325867161543

Epoch: 6| Step: 4
Training loss: 2.3577330477949165
Validation loss: 3.2053548483153205

Epoch: 6| Step: 5
Training loss: 3.3821564141665146
Validation loss: 3.2047523692481192

Epoch: 6| Step: 6
Training loss: 3.837134149365202
Validation loss: 3.204021139016606

Epoch: 6| Step: 7
Training loss: 3.636878054168987
Validation loss: 3.2033565298500593

Epoch: 6| Step: 8
Training loss: 3.2069063522421075
Validation loss: 3.2021979558398423

Epoch: 6| Step: 9
Training loss: 3.196774919869346
Validation loss: 3.2014791939049263

Epoch: 6| Step: 10
Training loss: 3.7109534333539522
Validation loss: 3.2007491421824095

Epoch: 6| Step: 11
Training loss: 4.0715719020921455
Validation loss: 3.2000742208297566

Epoch: 6| Step: 12
Training loss: 3.1858924851317325
Validation loss: 3.199006915327202

Epoch: 6| Step: 13
Training loss: 3.42898448090867
Validation loss: 3.1981507533947378

Epoch: 29| Step: 0
Training loss: 3.836841360225251
Validation loss: 3.1976069684244663

Epoch: 6| Step: 1
Training loss: 3.9114087030112548
Validation loss: 3.1967508886672884

Epoch: 6| Step: 2
Training loss: 3.188670074525937
Validation loss: 3.196007237126398

Epoch: 6| Step: 3
Training loss: 2.518802981138896
Validation loss: 3.195405931187677

Epoch: 6| Step: 4
Training loss: 4.030017279878964
Validation loss: 3.19449070389757

Epoch: 6| Step: 5
Training loss: 2.8526214723524688
Validation loss: 3.193661055975821

Epoch: 6| Step: 6
Training loss: 3.027639066997142
Validation loss: 3.193002537731149

Epoch: 6| Step: 7
Training loss: 3.4149505368137145
Validation loss: 3.1918245047175016

Epoch: 6| Step: 8
Training loss: 3.6228372107039575
Validation loss: 3.1913195363415086

Epoch: 6| Step: 9
Training loss: 4.08240036459145
Validation loss: 3.1906392472897886

Epoch: 6| Step: 10
Training loss: 3.2040515582999953
Validation loss: 3.189533697188577

Epoch: 6| Step: 11
Training loss: 3.8257127284807173
Validation loss: 3.1889652244013487

Epoch: 6| Step: 12
Training loss: 3.0267771332141304
Validation loss: 3.1880002128957248

Epoch: 6| Step: 13
Training loss: 3.3860653925719504
Validation loss: 3.187160875238693

Epoch: 30| Step: 0
Training loss: 2.9623533703534974
Validation loss: 3.186500721630254

Epoch: 6| Step: 1
Training loss: 3.224808407792279
Validation loss: 3.1857145851816577

Epoch: 6| Step: 2
Training loss: 4.066451747614107
Validation loss: 3.1851075467406105

Epoch: 6| Step: 3
Training loss: 2.6457058032281493
Validation loss: 3.1842880392849864

Epoch: 6| Step: 4
Training loss: 3.8761127473949437
Validation loss: 3.183523869837468

Epoch: 6| Step: 5
Training loss: 3.2884404914927177
Validation loss: 3.1827913717735474

Epoch: 6| Step: 6
Training loss: 4.026772785135803
Validation loss: 3.1823169649579155

Epoch: 6| Step: 7
Training loss: 3.450300900149827
Validation loss: 3.1817350474597057

Epoch: 6| Step: 8
Training loss: 3.210535028855594
Validation loss: 3.1810049630412025

Epoch: 6| Step: 9
Training loss: 3.727966555916081
Validation loss: 3.1801438078891398

Epoch: 6| Step: 10
Training loss: 3.777675357689337
Validation loss: 3.179148054777394

Epoch: 6| Step: 11
Training loss: 3.121470174421772
Validation loss: 3.178507067915082

Epoch: 6| Step: 12
Training loss: 3.370533990633983
Validation loss: 3.1775338958734154

Epoch: 6| Step: 13
Training loss: 2.9673665889069767
Validation loss: 3.1767760570828343

Epoch: 31| Step: 0
Training loss: 3.6856652560727454
Validation loss: 3.1760293477469954

Epoch: 6| Step: 1
Training loss: 3.274077796678199
Validation loss: 3.1755358131387434

Epoch: 6| Step: 2
Training loss: 3.5839523106109947
Validation loss: 3.174684521814102

Epoch: 6| Step: 3
Training loss: 3.7980594749755645
Validation loss: 3.1738422540266567

Epoch: 6| Step: 4
Training loss: 3.2782558767777616
Validation loss: 3.1730539759697227

Epoch: 6| Step: 5
Training loss: 2.9477108365688434
Validation loss: 3.1721211799634745

Epoch: 6| Step: 6
Training loss: 4.1340436345618
Validation loss: 3.171503468472677

Epoch: 6| Step: 7
Training loss: 3.493922815842732
Validation loss: 3.170801984756991

Epoch: 6| Step: 8
Training loss: 3.1573982793834103
Validation loss: 3.1699125469863256

Epoch: 6| Step: 9
Training loss: 4.104559219615317
Validation loss: 3.1693340513646753

Epoch: 6| Step: 10
Training loss: 2.8263254921374683
Validation loss: 3.168212928150519

Epoch: 6| Step: 11
Training loss: 3.2098972092567295
Validation loss: 3.1675400142203016

Epoch: 6| Step: 12
Training loss: 3.435994460122524
Validation loss: 3.167071124500752

Epoch: 6| Step: 13
Training loss: 2.384621855629975
Validation loss: 3.1661640074847064

Epoch: 32| Step: 0
Training loss: 3.3291716026934783
Validation loss: 3.165458538332649

Epoch: 6| Step: 1
Training loss: 3.1427462422014116
Validation loss: 3.1648222976841955

Epoch: 6| Step: 2
Training loss: 3.0989170274733175
Validation loss: 3.1644393285308485

Epoch: 6| Step: 3
Training loss: 3.4739872341679123
Validation loss: 3.1637378213595637

Epoch: 6| Step: 4
Training loss: 3.198239056534727
Validation loss: 3.1620460444170777

Epoch: 6| Step: 5
Training loss: 3.136605494676664
Validation loss: 3.162358131908542

Epoch: 6| Step: 6
Training loss: 4.13887971767516
Validation loss: 3.161412633131158

Epoch: 6| Step: 7
Training loss: 3.010385022552562
Validation loss: 3.1606605356904325

Epoch: 6| Step: 8
Training loss: 3.095709594334723
Validation loss: 3.1599685384223397

Epoch: 6| Step: 9
Training loss: 3.538311539695299
Validation loss: 3.1592355953747804

Epoch: 6| Step: 10
Training loss: 4.487784867024634
Validation loss: 3.1583951963874366

Epoch: 6| Step: 11
Training loss: 3.4382606358377155
Validation loss: 3.1578519401428053

Epoch: 6| Step: 12
Training loss: 2.9995377502355076
Validation loss: 3.15615770840002

Epoch: 6| Step: 13
Training loss: 3.686541933935387
Validation loss: 3.1558414236608114

Epoch: 33| Step: 0
Training loss: 4.334398041040282
Validation loss: 3.1550230689253835

Epoch: 6| Step: 1
Training loss: 3.4601037116851967
Validation loss: 3.154137776053222

Epoch: 6| Step: 2
Training loss: 2.9670042024537024
Validation loss: 3.153057820545489

Epoch: 6| Step: 3
Training loss: 3.6581015829890897
Validation loss: 3.1529298512904447

Epoch: 6| Step: 4
Training loss: 3.7158050416489754
Validation loss: 3.151552059961547

Epoch: 6| Step: 5
Training loss: 2.958912340552641
Validation loss: 3.15056171034953

Epoch: 6| Step: 6
Training loss: 2.789932414504416
Validation loss: 3.1488301091326862

Epoch: 6| Step: 7
Training loss: 2.9568835363948196
Validation loss: 3.1576588224843394

Epoch: 6| Step: 8
Training loss: 3.3119908067419015
Validation loss: 3.1485385225634865

Epoch: 6| Step: 9
Training loss: 3.8307920546289256
Validation loss: 3.1484521737104463

Epoch: 6| Step: 10
Training loss: 3.1524804899865906
Validation loss: 3.1484184902737593

Epoch: 6| Step: 11
Training loss: 3.2579290062725597
Validation loss: 3.1459224688028065

Epoch: 6| Step: 12
Training loss: 3.3820836645388344
Validation loss: 3.1458629741764965

Epoch: 6| Step: 13
Training loss: 4.047072711371508
Validation loss: 3.1448552528222957

Epoch: 34| Step: 0
Training loss: 3.813458931817439
Validation loss: 3.144459732109621

Epoch: 6| Step: 1
Training loss: 3.962718675999439
Validation loss: 3.1429036697602917

Epoch: 6| Step: 2
Training loss: 3.4687346037102005
Validation loss: 3.1422037935571097

Epoch: 6| Step: 3
Training loss: 3.3097996771546563
Validation loss: 3.1410806964330025

Epoch: 6| Step: 4
Training loss: 2.884839345600853
Validation loss: 3.1401570893508897

Epoch: 6| Step: 5
Training loss: 2.8896264903378275
Validation loss: 3.1387332072775243

Epoch: 6| Step: 6
Training loss: 3.734757663162534
Validation loss: 3.1391867561248157

Epoch: 6| Step: 7
Training loss: 3.0967813148532017
Validation loss: 3.138867699563718

Epoch: 6| Step: 8
Training loss: 2.574675500663301
Validation loss: 3.1381067023844547

Epoch: 6| Step: 9
Training loss: 4.037604004078409
Validation loss: 3.136982710488929

Epoch: 6| Step: 10
Training loss: 3.6360899876452994
Validation loss: 3.142004586845584

Epoch: 6| Step: 11
Training loss: 3.1053916681667912
Validation loss: 3.1450135460568744

Epoch: 6| Step: 12
Training loss: 2.926380620662204
Validation loss: 3.134414794598588

Epoch: 6| Step: 13
Training loss: 4.241855671586932
Validation loss: 3.133388638668313

Epoch: 35| Step: 0
Training loss: 3.7411079522010553
Validation loss: 3.1326149416948863

Epoch: 6| Step: 1
Training loss: 3.3116998245839575
Validation loss: 3.1327784790126305

Epoch: 6| Step: 2
Training loss: 3.181935108810695
Validation loss: 3.131915898098188

Epoch: 6| Step: 3
Training loss: 3.7190620868420754
Validation loss: 3.132506153773796

Epoch: 6| Step: 4
Training loss: 3.3923745980976747
Validation loss: 3.132107999339894

Epoch: 6| Step: 5
Training loss: 3.7312882566807084
Validation loss: 3.1319768961089887

Epoch: 6| Step: 6
Training loss: 3.091734258387565
Validation loss: 3.131393465976808

Epoch: 6| Step: 7
Training loss: 3.7835408987055676
Validation loss: 3.1306172164038584

Epoch: 6| Step: 8
Training loss: 3.1232939068379735
Validation loss: 3.1295627222154603

Epoch: 6| Step: 9
Training loss: 3.4702336343170908
Validation loss: 3.1290007464280305

Epoch: 6| Step: 10
Training loss: 3.2084495391278005
Validation loss: 3.128084993108131

Epoch: 6| Step: 11
Training loss: 3.092549100592454
Validation loss: 3.1276617203774184

Epoch: 6| Step: 12
Training loss: 3.2750885288998446
Validation loss: 3.1262705691313584

Epoch: 6| Step: 13
Training loss: 3.45775435476806
Validation loss: 3.125908958567025

Epoch: 36| Step: 0
Training loss: 3.5755299315460687
Validation loss: 3.1252024775713125

Epoch: 6| Step: 1
Training loss: 3.070497929455423
Validation loss: 3.124576301974462

Epoch: 6| Step: 2
Training loss: 3.8434026297558344
Validation loss: 3.123338711421909

Epoch: 6| Step: 3
Training loss: 3.271747307530937
Validation loss: 3.1227544768629754

Epoch: 6| Step: 4
Training loss: 3.7990982391114767
Validation loss: 3.1217047300865612

Epoch: 6| Step: 5
Training loss: 3.621856115389049
Validation loss: 3.1208535534908077

Epoch: 6| Step: 6
Training loss: 3.715639753127907
Validation loss: 3.12012332849731

Epoch: 6| Step: 7
Training loss: 1.9411423194825475
Validation loss: 3.117837067647362

Epoch: 6| Step: 8
Training loss: 3.8528046684423787
Validation loss: 3.1181486715615585

Epoch: 6| Step: 9
Training loss: 3.3252393363917596
Validation loss: 3.1175558817447997

Epoch: 6| Step: 10
Training loss: 2.684490914556597
Validation loss: 3.115638827060997

Epoch: 6| Step: 11
Training loss: 3.8403768237315457
Validation loss: 3.115186565303741

Epoch: 6| Step: 12
Training loss: 3.2117029470371827
Validation loss: 3.112947720513518

Epoch: 6| Step: 13
Training loss: 3.1425231966726956
Validation loss: 3.112065648824196

Epoch: 37| Step: 0
Training loss: 3.426211600855658
Validation loss: 3.1121915503398023

Epoch: 6| Step: 1
Training loss: 3.039693810954562
Validation loss: 3.1100338836386747

Epoch: 6| Step: 2
Training loss: 3.487846936979652
Validation loss: 3.108540632085336

Epoch: 6| Step: 3
Training loss: 3.3655242706498205
Validation loss: 3.1054439263781184

Epoch: 6| Step: 4
Training loss: 4.142474758184096
Validation loss: 3.105764791275562

Epoch: 6| Step: 5
Training loss: 3.095118826709669
Validation loss: 3.104114769612385

Epoch: 6| Step: 6
Training loss: 2.600847758952181
Validation loss: 3.107418959428629

Epoch: 6| Step: 7
Training loss: 3.242505161395998
Validation loss: 3.107018201560811

Epoch: 6| Step: 8
Training loss: 3.0608631352830153
Validation loss: 3.1101582946761557

Epoch: 6| Step: 9
Training loss: 3.7576386536417754
Validation loss: 3.113274428508273

Epoch: 6| Step: 10
Training loss: 3.6221625963489887
Validation loss: 3.1006486854085376

Epoch: 6| Step: 11
Training loss: 3.3079373587935654
Validation loss: 3.0973454731124987

Epoch: 6| Step: 12
Training loss: 3.456012605926694
Validation loss: 3.0972894959590285

Epoch: 6| Step: 13
Training loss: 3.716681538254161
Validation loss: 3.097414235145813

Epoch: 38| Step: 0
Training loss: 2.86108647390414
Validation loss: 3.096632712283008

Epoch: 6| Step: 1
Training loss: 3.264157928488862
Validation loss: 3.0983322927193484

Epoch: 6| Step: 2
Training loss: 2.955703497731785
Validation loss: 3.0980831563240474

Epoch: 6| Step: 3
Training loss: 3.5730905889028826
Validation loss: 3.0978559384058686

Epoch: 6| Step: 4
Training loss: 2.993879432508344
Validation loss: 3.096824012910214

Epoch: 6| Step: 5
Training loss: 4.412949899533859
Validation loss: 3.0957768888579

Epoch: 6| Step: 6
Training loss: 3.704981471335841
Validation loss: 3.0922243531464577

Epoch: 6| Step: 7
Training loss: 3.344481486231186
Validation loss: 3.0884391699734968

Epoch: 6| Step: 8
Training loss: 3.0300926279948137
Validation loss: 3.085503494317109

Epoch: 6| Step: 9
Training loss: 2.5302429079593938
Validation loss: 3.084686200062855

Epoch: 6| Step: 10
Training loss: 3.9158572043626023
Validation loss: 3.0865026203441674

Epoch: 6| Step: 11
Training loss: 3.14834026631416
Validation loss: 3.0875684696938794

Epoch: 6| Step: 12
Training loss: 3.810945287667576
Validation loss: 3.0854575587051496

Epoch: 6| Step: 13
Training loss: 3.153830025436644
Validation loss: 3.082812253316691

Epoch: 39| Step: 0
Training loss: 3.6659974152118333
Validation loss: 3.084329113942737

Epoch: 6| Step: 1
Training loss: 3.4838501402358832
Validation loss: 3.081276351874932

Epoch: 6| Step: 2
Training loss: 3.49874283146916
Validation loss: 3.0830766373672183

Epoch: 6| Step: 3
Training loss: 3.7731779336999667
Validation loss: 3.0779699512736625

Epoch: 6| Step: 4
Training loss: 3.8252408120139916
Validation loss: 3.0801735784252156

Epoch: 6| Step: 5
Training loss: 3.5836397675777416
Validation loss: 3.078946862699938

Epoch: 6| Step: 6
Training loss: 2.6926515574467773
Validation loss: 3.079752994848024

Epoch: 6| Step: 7
Training loss: 2.1545353581945905
Validation loss: 3.083216526664766

Epoch: 6| Step: 8
Training loss: 3.378218776025888
Validation loss: 3.0891550594878705

Epoch: 6| Step: 9
Training loss: 3.3990548110318017
Validation loss: 3.1047391201902643

Epoch: 6| Step: 10
Training loss: 3.83897935018826
Validation loss: 3.14344627165562

Epoch: 6| Step: 11
Training loss: 2.954959521589248
Validation loss: 3.0778507143566856

Epoch: 6| Step: 12
Training loss: 2.6808648817652534
Validation loss: 3.076431970651057

Epoch: 6| Step: 13
Training loss: 3.959005693586225
Validation loss: 3.0970882280899588

Epoch: 40| Step: 0
Training loss: 3.5488527136514016
Validation loss: 3.0802608650651804

Epoch: 6| Step: 1
Training loss: 3.807639729270925
Validation loss: 3.195321047830861

Epoch: 6| Step: 2
Training loss: 3.658106927375724
Validation loss: 3.2170219254748846

Epoch: 6| Step: 3
Training loss: 3.4664604260155394
Validation loss: 3.141415325912812

Epoch: 6| Step: 4
Training loss: 3.9297668570360735
Validation loss: 3.127071389779858

Epoch: 6| Step: 5
Training loss: 3.142927701579137
Validation loss: 3.114826458904635

Epoch: 6| Step: 6
Training loss: 3.067962290555732
Validation loss: 3.1234531076945165

Epoch: 6| Step: 7
Training loss: 3.136967745312635
Validation loss: 3.1405845479901244

Epoch: 6| Step: 8
Training loss: 3.5894994394185296
Validation loss: 3.1469326528343005

Epoch: 6| Step: 9
Training loss: 2.8122975594460504
Validation loss: 3.1665664202545143

Epoch: 6| Step: 10
Training loss: 3.3189137104123523
Validation loss: 3.1543319447739817

Epoch: 6| Step: 11
Training loss: 3.4821938842835416
Validation loss: 3.1302414742660303

Epoch: 6| Step: 12
Training loss: 3.1506326373158493
Validation loss: 3.1135855536948394

Epoch: 6| Step: 13
Training loss: 3.520598966182953
Validation loss: 3.0768071433992294

Epoch: 41| Step: 0
Training loss: 3.318918020589327
Validation loss: 3.0788857599659325

Epoch: 6| Step: 1
Training loss: 4.166843308837086
Validation loss: 3.087115055296312

Epoch: 6| Step: 2
Training loss: 2.864496699092413
Validation loss: 3.056922759669214

Epoch: 6| Step: 3
Training loss: 2.7509090481653655
Validation loss: 3.0522174023892137

Epoch: 6| Step: 4
Training loss: 2.9646190613456636
Validation loss: 3.0696039485201703

Epoch: 6| Step: 5
Training loss: 3.3541242861390326
Validation loss: 3.089903806357341

Epoch: 6| Step: 6
Training loss: 3.560139459600109
Validation loss: 3.0731355539447778

Epoch: 6| Step: 7
Training loss: 3.58261186892255
Validation loss: 3.0501755441156355

Epoch: 6| Step: 8
Training loss: 3.316281301708
Validation loss: 3.037882324468678

Epoch: 6| Step: 9
Training loss: 2.384724834571296
Validation loss: 3.0371507240690625

Epoch: 6| Step: 10
Training loss: 3.8918847185647287
Validation loss: 3.0522626380170776

Epoch: 6| Step: 11
Training loss: 2.913287757790566
Validation loss: 3.044829128876993

Epoch: 6| Step: 12
Training loss: 3.8605857525251395
Validation loss: 3.0584383967923454

Epoch: 6| Step: 13
Training loss: 3.6072033711150104
Validation loss: 3.0587242520960007

Epoch: 42| Step: 0
Training loss: 3.6251325911904155
Validation loss: 3.047757300604059

Epoch: 6| Step: 1
Training loss: 2.715283870012669
Validation loss: 3.032924031275535

Epoch: 6| Step: 2
Training loss: 3.3594192856819345
Validation loss: 3.0311465696604385

Epoch: 6| Step: 3
Training loss: 4.286134036262356
Validation loss: 3.023892942521615

Epoch: 6| Step: 4
Training loss: 2.2730915029143324
Validation loss: 3.0204713247358757

Epoch: 6| Step: 5
Training loss: 3.411235275935696
Validation loss: 3.0228795477436115

Epoch: 6| Step: 6
Training loss: 4.121958680709756
Validation loss: 3.0199498087841126

Epoch: 6| Step: 7
Training loss: 3.6558227289407035
Validation loss: 3.0206337738033597

Epoch: 6| Step: 8
Training loss: 3.2406787717031116
Validation loss: 3.0177088147575732

Epoch: 6| Step: 9
Training loss: 2.9380557569350816
Validation loss: 3.0202711790907366

Epoch: 6| Step: 10
Training loss: 3.215092034097893
Validation loss: 3.0200652954126195

Epoch: 6| Step: 11
Training loss: 3.078151025032748
Validation loss: 3.02581458789111

Epoch: 6| Step: 12
Training loss: 2.786035428382619
Validation loss: 3.0324852078780085

Epoch: 6| Step: 13
Training loss: 3.107977164745518
Validation loss: 3.0565855144266183

Epoch: 43| Step: 0
Training loss: 3.3797156274112723
Validation loss: 3.0360121081010254

Epoch: 6| Step: 1
Training loss: 3.344600248527278
Validation loss: 3.040079339545918

Epoch: 6| Step: 2
Training loss: 3.0854637072006126
Validation loss: 3.0393671020775788

Epoch: 6| Step: 3
Training loss: 3.2305109650922184
Validation loss: 3.0236360277483145

Epoch: 6| Step: 4
Training loss: 2.475184108167255
Validation loss: 3.012723428471314

Epoch: 6| Step: 5
Training loss: 3.1096746405756437
Validation loss: 3.013080960312113

Epoch: 6| Step: 6
Training loss: 3.4166585100278177
Validation loss: 3.0103105612284553

Epoch: 6| Step: 7
Training loss: 3.553213228792719
Validation loss: 3.008986528979743

Epoch: 6| Step: 8
Training loss: 3.038943251596808
Validation loss: 3.0115310872016052

Epoch: 6| Step: 9
Training loss: 3.3922913846872067
Validation loss: 3.0097524616530973

Epoch: 6| Step: 10
Training loss: 3.5196908455248295
Validation loss: 3.010927646544487

Epoch: 6| Step: 11
Training loss: 3.0154681387312197
Validation loss: 3.0065121027312265

Epoch: 6| Step: 12
Training loss: 3.804152433459983
Validation loss: 3.011731111417515

Epoch: 6| Step: 13
Training loss: 4.013419529019857
Validation loss: 3.0083327624524085

Epoch: 44| Step: 0
Training loss: 3.7557499354342867
Validation loss: 3.007109455800421

Epoch: 6| Step: 1
Training loss: 3.453052640821336
Validation loss: 3.011235198475776

Epoch: 6| Step: 2
Training loss: 3.0977587688938577
Validation loss: 3.0090626119983512

Epoch: 6| Step: 3
Training loss: 3.3041111508901335
Validation loss: 3.0077151336699988

Epoch: 6| Step: 4
Training loss: 2.6982367091307937
Validation loss: 3.0099998980730533

Epoch: 6| Step: 5
Training loss: 3.305112265845708
Validation loss: 3.011914297387924

Epoch: 6| Step: 6
Training loss: 4.010075278015559
Validation loss: 3.0104971266503253

Epoch: 6| Step: 7
Training loss: 3.8913468147093537
Validation loss: 3.0105387526708496

Epoch: 6| Step: 8
Training loss: 2.7763137731737486
Validation loss: 3.010944847396272

Epoch: 6| Step: 9
Training loss: 2.849399195470246
Validation loss: 3.0084450751067755

Epoch: 6| Step: 10
Training loss: 3.4901349139437716
Validation loss: 3.011082509419903

Epoch: 6| Step: 11
Training loss: 2.6788358975592823
Validation loss: 3.0045445452117234

Epoch: 6| Step: 12
Training loss: 3.372454778482605
Validation loss: 3.0088139831738094

Epoch: 6| Step: 13
Training loss: 2.8459400505137427
Validation loss: 3.012016456917914

Epoch: 45| Step: 0
Training loss: 3.2517475418312634
Validation loss: 3.020220717679731

Epoch: 6| Step: 1
Training loss: 3.441512384412619
Validation loss: 3.0242029109249327

Epoch: 6| Step: 2
Training loss: 2.2755518778363117
Validation loss: 3.0169801170393336

Epoch: 6| Step: 3
Training loss: 3.345900512502275
Validation loss: 3.0108053986341794

Epoch: 6| Step: 4
Training loss: 3.9912860845552838
Validation loss: 3.0087532778645727

Epoch: 6| Step: 5
Training loss: 3.608564938225598
Validation loss: 2.9980450724410974

Epoch: 6| Step: 6
Training loss: 3.0850221459383684
Validation loss: 2.9989353191201604

Epoch: 6| Step: 7
Training loss: 3.4633204951215113
Validation loss: 2.9979476984456306

Epoch: 6| Step: 8
Training loss: 3.155848109275597
Validation loss: 2.9967820604940494

Epoch: 6| Step: 9
Training loss: 3.875734444204689
Validation loss: 2.9985502373555777

Epoch: 6| Step: 10
Training loss: 2.5036321957204004
Validation loss: 2.9954592358343075

Epoch: 6| Step: 11
Training loss: 3.3074437544488604
Validation loss: 2.996824886451317

Epoch: 6| Step: 12
Training loss: 2.893193438996373
Validation loss: 2.998139034937855

Epoch: 6| Step: 13
Training loss: 3.4144993552742062
Validation loss: 3.0003833252399885

Epoch: 46| Step: 0
Training loss: 3.61407165130367
Validation loss: 3.025919145991231

Epoch: 6| Step: 1
Training loss: 3.0633870611228486
Validation loss: 2.996205498956575

Epoch: 6| Step: 2
Training loss: 4.324779332876554
Validation loss: 2.991178939076259

Epoch: 6| Step: 3
Training loss: 3.481155344910708
Validation loss: 2.990048786494728

Epoch: 6| Step: 4
Training loss: 2.395190896408221
Validation loss: 2.993239633837754

Epoch: 6| Step: 5
Training loss: 3.425704415828795
Validation loss: 3.0018489380108333

Epoch: 6| Step: 6
Training loss: 3.1124719886591734
Validation loss: 2.9920689204220587

Epoch: 6| Step: 7
Training loss: 3.052337913615005
Validation loss: 2.989713838265705

Epoch: 6| Step: 8
Training loss: 3.6958576469668127
Validation loss: 2.988133759102376

Epoch: 6| Step: 9
Training loss: 2.515390610289536
Validation loss: 2.9869183792185834

Epoch: 6| Step: 10
Training loss: 3.618703701533491
Validation loss: 2.986709017051856

Epoch: 6| Step: 11
Training loss: 2.97098561485606
Validation loss: 2.985974063448629

Epoch: 6| Step: 12
Training loss: 3.135097973279781
Validation loss: 2.99732843349659

Epoch: 6| Step: 13
Training loss: 2.834779613345241
Validation loss: 3.0168992277588464

Epoch: 47| Step: 0
Training loss: 3.666830680531221
Validation loss: 3.085221671564414

Epoch: 6| Step: 1
Training loss: 3.319927309918042
Validation loss: 3.0250293055672253

Epoch: 6| Step: 2
Training loss: 3.2737537313223743
Validation loss: 2.9958254031144933

Epoch: 6| Step: 3
Training loss: 3.4043176051792807
Validation loss: 2.9924707939669197

Epoch: 6| Step: 4
Training loss: 3.203118747612038
Validation loss: 2.9904721018626748

Epoch: 6| Step: 5
Training loss: 3.062289016618332
Validation loss: 2.990281174983661

Epoch: 6| Step: 6
Training loss: 3.7091065075830225
Validation loss: 2.9880285883450397

Epoch: 6| Step: 7
Training loss: 3.70209305303468
Validation loss: 2.9919738744679565

Epoch: 6| Step: 8
Training loss: 3.4319938256446054
Validation loss: 2.987930237558293

Epoch: 6| Step: 9
Training loss: 2.9248402282899058
Validation loss: 2.981441432786351

Epoch: 6| Step: 10
Training loss: 3.0104784755675413
Validation loss: 2.9823466948794795

Epoch: 6| Step: 11
Training loss: 2.7984936681378985
Validation loss: 2.9838770218077983

Epoch: 6| Step: 12
Training loss: 3.2617064698496376
Validation loss: 2.9830604857655305

Epoch: 6| Step: 13
Training loss: 2.5704909613435003
Validation loss: 2.9830834771912644

Epoch: 48| Step: 0
Training loss: 3.483160517176251
Validation loss: 2.9803647177305734

Epoch: 6| Step: 1
Training loss: 3.0746038600410297
Validation loss: 2.9805396734200746

Epoch: 6| Step: 2
Training loss: 3.7952613698342894
Validation loss: 2.980580653857097

Epoch: 6| Step: 3
Training loss: 3.398313182442418
Validation loss: 2.9918049669777624

Epoch: 6| Step: 4
Training loss: 3.3820623751076284
Validation loss: 2.9870889490838746

Epoch: 6| Step: 5
Training loss: 2.7213697417815856
Validation loss: 2.9882220407221016

Epoch: 6| Step: 6
Training loss: 3.8602780663933953
Validation loss: 2.984827894737402

Epoch: 6| Step: 7
Training loss: 3.3951220245230314
Validation loss: 2.9826569686982753

Epoch: 6| Step: 8
Training loss: 2.7712955423965315
Validation loss: 2.981328813126755

Epoch: 6| Step: 9
Training loss: 3.4702465506259563
Validation loss: 2.979336413134105

Epoch: 6| Step: 10
Training loss: 3.72180819383394
Validation loss: 2.978068411700214

Epoch: 6| Step: 11
Training loss: 2.6689669304260795
Validation loss: 2.9791543003556775

Epoch: 6| Step: 12
Training loss: 2.921109838816351
Validation loss: 2.9731451464765337

Epoch: 6| Step: 13
Training loss: 1.9643415715586274
Validation loss: 2.972944619860484

Epoch: 49| Step: 0
Training loss: 3.6050148261793122
Validation loss: 2.973497574045529

Epoch: 6| Step: 1
Training loss: 2.770421583133335
Validation loss: 2.9719329575408624

Epoch: 6| Step: 2
Training loss: 2.889163085770971
Validation loss: 2.9719382298528183

Epoch: 6| Step: 3
Training loss: 2.829899183978025
Validation loss: 2.9749448708231037

Epoch: 6| Step: 4
Training loss: 2.80801338916423
Validation loss: 2.974303607362655

Epoch: 6| Step: 5
Training loss: 3.1196909247655373
Validation loss: 2.975560740260515

Epoch: 6| Step: 6
Training loss: 3.4097356198201516
Validation loss: 2.9772523603751577

Epoch: 6| Step: 7
Training loss: 3.0215140441739843
Validation loss: 2.9855046152319455

Epoch: 6| Step: 8
Training loss: 3.5899215872444175
Validation loss: 2.971304703925276

Epoch: 6| Step: 9
Training loss: 4.1631146867776385
Validation loss: 2.968674937380326

Epoch: 6| Step: 10
Training loss: 3.661296263897699
Validation loss: 2.9689766383380234

Epoch: 6| Step: 11
Training loss: 3.2852299848666298
Validation loss: 2.9680380433304547

Epoch: 6| Step: 12
Training loss: 2.8469547197756127
Validation loss: 2.96551581109055

Epoch: 6| Step: 13
Training loss: 3.258260206749936
Validation loss: 2.9634788231575615

Epoch: 50| Step: 0
Training loss: 3.884626920207924
Validation loss: 2.9668008637318604

Epoch: 6| Step: 1
Training loss: 3.4325784303910862
Validation loss: 2.9646048310615445

Epoch: 6| Step: 2
Training loss: 3.658401117297881
Validation loss: 2.9635595243297908

Epoch: 6| Step: 3
Training loss: 3.2132211254309166
Validation loss: 2.9646376239118677

Epoch: 6| Step: 4
Training loss: 2.769994527487737
Validation loss: 2.9652179857586507

Epoch: 6| Step: 5
Training loss: 3.1971123063804585
Validation loss: 2.968211997331871

Epoch: 6| Step: 6
Training loss: 3.2008694778807696
Validation loss: 2.9701762755824586

Epoch: 6| Step: 7
Training loss: 3.4101380722417867
Validation loss: 2.975216044103182

Epoch: 6| Step: 8
Training loss: 2.7606209349478186
Validation loss: 2.9794169007570734

Epoch: 6| Step: 9
Training loss: 3.8192703916406456
Validation loss: 2.9922312142114387

Epoch: 6| Step: 10
Training loss: 2.591800186626558
Validation loss: 2.9957420715053007

Epoch: 6| Step: 11
Training loss: 3.1752169437332163
Validation loss: 3.008981572070378

Epoch: 6| Step: 12
Training loss: 3.185139698456198
Validation loss: 2.975724321215698

Epoch: 6| Step: 13
Training loss: 2.653561027651696
Validation loss: 2.9649971523415455

Epoch: 51| Step: 0
Training loss: 3.25193802197131
Validation loss: 2.9623032940334215

Epoch: 6| Step: 1
Training loss: 3.152925761405364
Validation loss: 2.962229983280298

Epoch: 6| Step: 2
Training loss: 3.8964898819274993
Validation loss: 2.957987839835408

Epoch: 6| Step: 3
Training loss: 2.7580267198912845
Validation loss: 2.9653241220184587

Epoch: 6| Step: 4
Training loss: 2.9162654782443265
Validation loss: 2.964066984162746

Epoch: 6| Step: 5
Training loss: 3.2230061658989055
Validation loss: 2.9655141037343817

Epoch: 6| Step: 6
Training loss: 2.7778474375149544
Validation loss: 2.962190906548875

Epoch: 6| Step: 7
Training loss: 3.3418108584781954
Validation loss: 2.962656987083564

Epoch: 6| Step: 8
Training loss: 2.4611672914788842
Validation loss: 2.9577762929147973

Epoch: 6| Step: 9
Training loss: 3.5605861140614157
Validation loss: 2.959740170046107

Epoch: 6| Step: 10
Training loss: 3.342768159550683
Validation loss: 2.956815557878895

Epoch: 6| Step: 11
Training loss: 3.9010599065472213
Validation loss: 2.9577175616258353

Epoch: 6| Step: 12
Training loss: 3.633856510560545
Validation loss: 2.9562959971089886

Epoch: 6| Step: 13
Training loss: 2.2400575948872086
Validation loss: 2.9574456992659397

Epoch: 52| Step: 0
Training loss: 3.1253672574722464
Validation loss: 2.9565943717374776

Epoch: 6| Step: 1
Training loss: 2.84702874950368
Validation loss: 2.955149066147454

Epoch: 6| Step: 2
Training loss: 3.92118689591155
Validation loss: 2.9536882019611994

Epoch: 6| Step: 3
Training loss: 2.7511747625342027
Validation loss: 2.9525186159529366

Epoch: 6| Step: 4
Training loss: 3.2649040338920994
Validation loss: 2.955120797118905

Epoch: 6| Step: 5
Training loss: 2.9248645196822527
Validation loss: 2.9563140708184035

Epoch: 6| Step: 6
Training loss: 3.1961271930922632
Validation loss: 2.953934446086147

Epoch: 6| Step: 7
Training loss: 2.6607810475649916
Validation loss: 2.9504383316990643

Epoch: 6| Step: 8
Training loss: 3.503266309054069
Validation loss: 2.9518227536792794

Epoch: 6| Step: 9
Training loss: 3.9730460876818117
Validation loss: 2.9504355529503865

Epoch: 6| Step: 10
Training loss: 2.453434821324046
Validation loss: 2.9481544748016475

Epoch: 6| Step: 11
Training loss: 2.8266682113187396
Validation loss: 2.944768202590283

Epoch: 6| Step: 12
Training loss: 3.9142356118544863
Validation loss: 2.9488504054946523

Epoch: 6| Step: 13
Training loss: 3.4726757482403956
Validation loss: 2.947637644715298

Epoch: 53| Step: 0
Training loss: 2.703788014504904
Validation loss: 2.947361813483155

Epoch: 6| Step: 1
Training loss: 2.994562147992744
Validation loss: 2.9460909631158665

Epoch: 6| Step: 2
Training loss: 3.084308126511146
Validation loss: 2.946729098117399

Epoch: 6| Step: 3
Training loss: 3.6628314392313603
Validation loss: 2.9462298220341934

Epoch: 6| Step: 4
Training loss: 3.4306286191860407
Validation loss: 2.942277678436916

Epoch: 6| Step: 5
Training loss: 3.4055478833519905
Validation loss: 2.9452418720368887

Epoch: 6| Step: 6
Training loss: 3.8022705171397595
Validation loss: 2.942349886627384

Epoch: 6| Step: 7
Training loss: 3.4734105598616467
Validation loss: 2.9440284467901545

Epoch: 6| Step: 8
Training loss: 2.9962750197262347
Validation loss: 2.943309185435963

Epoch: 6| Step: 9
Training loss: 3.231289188582703
Validation loss: 2.9459686318775455

Epoch: 6| Step: 10
Training loss: 2.4750399075768255
Validation loss: 2.9438480694668296

Epoch: 6| Step: 11
Training loss: 3.0217535963001567
Validation loss: 2.945812376263146

Epoch: 6| Step: 12
Training loss: 3.4663730759889244
Validation loss: 2.946254193762778

Epoch: 6| Step: 13
Training loss: 3.0129968130637357
Validation loss: 2.945706889420987

Epoch: 54| Step: 0
Training loss: 3.182979594710245
Validation loss: 2.9465882468526905

Epoch: 6| Step: 1
Training loss: 2.882639809995332
Validation loss: 2.945872357002619

Epoch: 6| Step: 2
Training loss: 3.3249327344472146
Validation loss: 2.947633715285189

Epoch: 6| Step: 3
Training loss: 3.500787646358668
Validation loss: 2.954655811476992

Epoch: 6| Step: 4
Training loss: 3.55831877968259
Validation loss: 2.968591440799126

Epoch: 6| Step: 5
Training loss: 3.474070000557619
Validation loss: 2.98165595909897

Epoch: 6| Step: 6
Training loss: 2.7547725532370833
Validation loss: 2.9666900396261666

Epoch: 6| Step: 7
Training loss: 3.6889249990092545
Validation loss: 2.95388067564278

Epoch: 6| Step: 8
Training loss: 2.9078117194320723
Validation loss: 2.9385589400597203

Epoch: 6| Step: 9
Training loss: 3.435067165556558
Validation loss: 2.9356222982694007

Epoch: 6| Step: 10
Training loss: 2.963789318890602
Validation loss: 2.9332813436155623

Epoch: 6| Step: 11
Training loss: 3.0957990854113717
Validation loss: 2.9323663670158115

Epoch: 6| Step: 12
Training loss: 3.1460225804143636
Validation loss: 2.9343140726846197

Epoch: 6| Step: 13
Training loss: 2.8621772417571245
Validation loss: 2.93087516791642

Epoch: 55| Step: 0
Training loss: 2.923475836742554
Validation loss: 2.9294611238914805

Epoch: 6| Step: 1
Training loss: 3.747005411380864
Validation loss: 2.9326727254936102

Epoch: 6| Step: 2
Training loss: 3.714333740908991
Validation loss: 2.928375858833388

Epoch: 6| Step: 3
Training loss: 2.8435694039817685
Validation loss: 2.9253504033217093

Epoch: 6| Step: 4
Training loss: 3.907418770461378
Validation loss: 2.9238088210956192

Epoch: 6| Step: 5
Training loss: 2.391138657382065
Validation loss: 2.922762512427305

Epoch: 6| Step: 6
Training loss: 3.018854655155673
Validation loss: 2.921174580535893

Epoch: 6| Step: 7
Training loss: 2.736671573233378
Validation loss: 2.921083597694473

Epoch: 6| Step: 8
Training loss: 2.349049185090557
Validation loss: 2.918874507636719

Epoch: 6| Step: 9
Training loss: 3.2648872381720193
Validation loss: 2.9171646613004265

Epoch: 6| Step: 10
Training loss: 3.4294475219466665
Validation loss: 2.9185999696191716

Epoch: 6| Step: 11
Training loss: 3.381250597941404
Validation loss: 2.9171595633049248

Epoch: 6| Step: 12
Training loss: 3.34362864051269
Validation loss: 2.9230603115984723

Epoch: 6| Step: 13
Training loss: 3.5539512458681553
Validation loss: 2.917630252378477

Epoch: 56| Step: 0
Training loss: 2.8390531213297896
Validation loss: 2.916536149534144

Epoch: 6| Step: 1
Training loss: 3.2948621055911946
Validation loss: 2.9145814822280793

Epoch: 6| Step: 2
Training loss: 3.4856169672519983
Validation loss: 2.9137598333773838

Epoch: 6| Step: 3
Training loss: 3.045814212125013
Validation loss: 2.914573954675659

Epoch: 6| Step: 4
Training loss: 3.0638745395681375
Validation loss: 2.9141247459044335

Epoch: 6| Step: 5
Training loss: 3.044389229139963
Validation loss: 2.9145573179945785

Epoch: 6| Step: 6
Training loss: 3.3671025311930145
Validation loss: 2.914671387390809

Epoch: 6| Step: 7
Training loss: 3.4225289055305135
Validation loss: 2.9129019235153284

Epoch: 6| Step: 8
Training loss: 2.8172639977113065
Validation loss: 2.913550980179112

Epoch: 6| Step: 9
Training loss: 2.8858983341320754
Validation loss: 2.912717823092281

Epoch: 6| Step: 10
Training loss: 3.869740023296189
Validation loss: 2.911489077340113

Epoch: 6| Step: 11
Training loss: 3.4784995865278066
Validation loss: 2.9098645580732225

Epoch: 6| Step: 12
Training loss: 2.8666832088022747
Validation loss: 2.909935752199725

Epoch: 6| Step: 13
Training loss: 3.2659232993524845
Validation loss: 2.910661080639066

Epoch: 57| Step: 0
Training loss: 2.8679271440389877
Validation loss: 2.9098853500041315

Epoch: 6| Step: 1
Training loss: 3.1811834841746163
Validation loss: 2.9103145961788477

Epoch: 6| Step: 2
Training loss: 3.7419470468889844
Validation loss: 2.9153028865423534

Epoch: 6| Step: 3
Training loss: 2.648577931149666
Validation loss: 2.9260934180459652

Epoch: 6| Step: 4
Training loss: 2.905917897271634
Validation loss: 2.93778765824926

Epoch: 6| Step: 5
Training loss: 3.4804254565559334
Validation loss: 2.932443344298645

Epoch: 6| Step: 6
Training loss: 4.012928335554218
Validation loss: 2.91596611739252

Epoch: 6| Step: 7
Training loss: 3.255947393315738
Validation loss: 2.902831314572421

Epoch: 6| Step: 8
Training loss: 2.522122539486734
Validation loss: 2.9034880234857434

Epoch: 6| Step: 9
Training loss: 2.9937708079465093
Validation loss: 2.9013569722119485

Epoch: 6| Step: 10
Training loss: 3.5779716092343183
Validation loss: 2.9064436517336705

Epoch: 6| Step: 11
Training loss: 2.8987556550240967
Validation loss: 2.9105996934225615

Epoch: 6| Step: 12
Training loss: 3.326793852179588
Validation loss: 2.9289813304533228

Epoch: 6| Step: 13
Training loss: 3.032736502259745
Validation loss: 2.945334848659854

Epoch: 58| Step: 0
Training loss: 3.4662180414662793
Validation loss: 2.9487981993933823

Epoch: 6| Step: 1
Training loss: 3.1919832303364353
Validation loss: 2.947841016447414

Epoch: 6| Step: 2
Training loss: 3.2885457627411205
Validation loss: 2.943764179600456

Epoch: 6| Step: 3
Training loss: 3.1817405877002973
Validation loss: 2.9431716703730504

Epoch: 6| Step: 4
Training loss: 3.388748141702996
Validation loss: 2.928664785299676

Epoch: 6| Step: 5
Training loss: 3.0735659845411036
Validation loss: 2.905984254865507

Epoch: 6| Step: 6
Training loss: 2.937354713255928
Validation loss: 2.8969602737312425

Epoch: 6| Step: 7
Training loss: 3.587135397430249
Validation loss: 2.8956026038616787

Epoch: 6| Step: 8
Training loss: 3.0528365281012952
Validation loss: 2.8948977902319593

Epoch: 6| Step: 9
Training loss: 2.5105364020405
Validation loss: 2.897948970608582

Epoch: 6| Step: 10
Training loss: 4.130583711990088
Validation loss: 2.9117971305310864

Epoch: 6| Step: 11
Training loss: 2.7827602957745055
Validation loss: 2.907135176646055

Epoch: 6| Step: 12
Training loss: 2.813541050138457
Validation loss: 2.9142980605991875

Epoch: 6| Step: 13
Training loss: 3.185190149257383
Validation loss: 2.9033323539873606

Epoch: 59| Step: 0
Training loss: 2.9117998845224378
Validation loss: 2.8951792441206834

Epoch: 6| Step: 1
Training loss: 3.5148056770970864
Validation loss: 2.888388332289251

Epoch: 6| Step: 2
Training loss: 3.266918163609203
Validation loss: 2.8886456418378708

Epoch: 6| Step: 3
Training loss: 3.7789869866491563
Validation loss: 2.8898201001130794

Epoch: 6| Step: 4
Training loss: 3.2345143163779633
Validation loss: 2.890047845312052

Epoch: 6| Step: 5
Training loss: 2.986609615933398
Validation loss: 2.888610891117646

Epoch: 6| Step: 6
Training loss: 2.9521243706118727
Validation loss: 2.8883662672681045

Epoch: 6| Step: 7
Training loss: 3.2195984546188945
Validation loss: 2.8892347367675537

Epoch: 6| Step: 8
Training loss: 3.5381688216985694
Validation loss: 2.8868857044366183

Epoch: 6| Step: 9
Training loss: 3.0388619717140632
Validation loss: 2.8857824966510686

Epoch: 6| Step: 10
Training loss: 2.303634868690316
Validation loss: 2.888022920566027

Epoch: 6| Step: 11
Training loss: 3.4434529863551617
Validation loss: 2.888723533016657

Epoch: 6| Step: 12
Training loss: 3.3092001547296137
Validation loss: 2.88709279267071

Epoch: 6| Step: 13
Training loss: 2.402661905698191
Validation loss: 2.889435454800615

Epoch: 60| Step: 0
Training loss: 3.234060668414002
Validation loss: 2.912677921031266

Epoch: 6| Step: 1
Training loss: 3.472775434716547
Validation loss: 2.8981137778322736

Epoch: 6| Step: 2
Training loss: 3.66455178969215
Validation loss: 2.8877555904158876

Epoch: 6| Step: 3
Training loss: 3.021479956161927
Validation loss: 2.887510842612492

Epoch: 6| Step: 4
Training loss: 2.9117442054956175
Validation loss: 2.8862527619406144

Epoch: 6| Step: 5
Training loss: 2.841577056038649
Validation loss: 2.881733313042531

Epoch: 6| Step: 6
Training loss: 3.478528510556566
Validation loss: 2.8814826737385957

Epoch: 6| Step: 7
Training loss: 3.687750339092461
Validation loss: 2.8833687596299704

Epoch: 6| Step: 8
Training loss: 2.9951616053215204
Validation loss: 2.882856280035566

Epoch: 6| Step: 9
Training loss: 2.6125375918371407
Validation loss: 2.8814720196216563

Epoch: 6| Step: 10
Training loss: 3.0900323282174105
Validation loss: 2.880475943250411

Epoch: 6| Step: 11
Training loss: 2.861781707329417
Validation loss: 2.8820176172404235

Epoch: 6| Step: 12
Training loss: 2.9654252558852647
Validation loss: 2.8806913878259204

Epoch: 6| Step: 13
Training loss: 3.5962729181295963
Validation loss: 2.8819591113802594

Epoch: 61| Step: 0
Training loss: 3.0584557746956293
Validation loss: 2.8796657797508667

Epoch: 6| Step: 1
Training loss: 3.141087132704876
Validation loss: 2.8805260127681693

Epoch: 6| Step: 2
Training loss: 3.6728703874401245
Validation loss: 2.879153506521663

Epoch: 6| Step: 3
Training loss: 3.161724064744498
Validation loss: 2.8783235462092462

Epoch: 6| Step: 4
Training loss: 3.0297284584365562
Validation loss: 2.878310175418232

Epoch: 6| Step: 5
Training loss: 3.634723644639354
Validation loss: 2.8830228063479275

Epoch: 6| Step: 6
Training loss: 2.673497471451656
Validation loss: 2.8794672154787886

Epoch: 6| Step: 7
Training loss: 2.9819626570166498
Validation loss: 2.877105009148465

Epoch: 6| Step: 8
Training loss: 3.5116652504788806
Validation loss: 2.875821656479019

Epoch: 6| Step: 9
Training loss: 3.075347421760079
Validation loss: 2.8748955620713494

Epoch: 6| Step: 10
Training loss: 2.9867357433652884
Validation loss: 2.8729383898022354

Epoch: 6| Step: 11
Training loss: 3.209092698500746
Validation loss: 2.871703970638868

Epoch: 6| Step: 12
Training loss: 2.7165951136271773
Validation loss: 2.8702742127338485

Epoch: 6| Step: 13
Training loss: 3.430439303989997
Validation loss: 2.8730851145739025

Epoch: 62| Step: 0
Training loss: 4.007621894453289
Validation loss: 2.8713801674381294

Epoch: 6| Step: 1
Training loss: 3.1942014371427674
Validation loss: 2.8708505812830705

Epoch: 6| Step: 2
Training loss: 3.230395536504102
Validation loss: 2.8690626730706508

Epoch: 6| Step: 3
Training loss: 2.633047755566401
Validation loss: 2.871137686404343

Epoch: 6| Step: 4
Training loss: 2.6108144113597898
Validation loss: 2.8685230150046626

Epoch: 6| Step: 5
Training loss: 3.472242779141079
Validation loss: 2.8674006251421407

Epoch: 6| Step: 6
Training loss: 3.1718966478633193
Validation loss: 2.86860726244676

Epoch: 6| Step: 7
Training loss: 2.784156395136697
Validation loss: 2.8674503105490095

Epoch: 6| Step: 8
Training loss: 2.7527727540405844
Validation loss: 2.8677477094150423

Epoch: 6| Step: 9
Training loss: 3.545110187835702
Validation loss: 2.866154322755371

Epoch: 6| Step: 10
Training loss: 3.198552883286468
Validation loss: 2.86568125040008

Epoch: 6| Step: 11
Training loss: 3.065930838693823
Validation loss: 2.86553547507627

Epoch: 6| Step: 12
Training loss: 3.3575545235394224
Validation loss: 2.8649521224311854

Epoch: 6| Step: 13
Training loss: 2.7137764348974542
Validation loss: 2.8679046713000194

Epoch: 63| Step: 0
Training loss: 2.676390017570975
Validation loss: 2.8665290276017132

Epoch: 6| Step: 1
Training loss: 3.2176947484213843
Validation loss: 2.8695457023604485

Epoch: 6| Step: 2
Training loss: 3.3181626484413376
Validation loss: 2.8657376723148142

Epoch: 6| Step: 3
Training loss: 3.4321310944495265
Validation loss: 2.8625819817339577

Epoch: 6| Step: 4
Training loss: 2.4088094401288282
Validation loss: 2.863847664404673

Epoch: 6| Step: 5
Training loss: 3.9229260742161136
Validation loss: 2.8644905300526875

Epoch: 6| Step: 6
Training loss: 3.447403668889736
Validation loss: 2.863909169327419

Epoch: 6| Step: 7
Training loss: 2.832019295502786
Validation loss: 2.8631872545493304

Epoch: 6| Step: 8
Training loss: 2.9962993685554618
Validation loss: 2.8613533372533673

Epoch: 6| Step: 9
Training loss: 3.332146306080655
Validation loss: 2.8603030220235612

Epoch: 6| Step: 10
Training loss: 2.8756036539328083
Validation loss: 2.858030660717132

Epoch: 6| Step: 11
Training loss: 3.0123953646773995
Validation loss: 2.857023928880149

Epoch: 6| Step: 12
Training loss: 3.392239375269083
Validation loss: 2.8551452506440884

Epoch: 6| Step: 13
Training loss: 3.117519733822303
Validation loss: 2.857897809008196

Epoch: 64| Step: 0
Training loss: 3.2074032380753454
Validation loss: 2.8575360711153053

Epoch: 6| Step: 1
Training loss: 3.4035353736300116
Validation loss: 2.8577453839713227

Epoch: 6| Step: 2
Training loss: 2.5620127889297604
Validation loss: 2.8567838906426952

Epoch: 6| Step: 3
Training loss: 3.402696067884334
Validation loss: 2.857109195537304

Epoch: 6| Step: 4
Training loss: 3.1297239075788936
Validation loss: 2.8546204505249198

Epoch: 6| Step: 5
Training loss: 3.3876450623705425
Validation loss: 2.854318542128331

Epoch: 6| Step: 6
Training loss: 2.7218846632986295
Validation loss: 2.854130803915773

Epoch: 6| Step: 7
Training loss: 3.742139461583302
Validation loss: 2.858497451346557

Epoch: 6| Step: 8
Training loss: 2.865174795414124
Validation loss: 2.8544884998685203

Epoch: 6| Step: 9
Training loss: 3.062233426695345
Validation loss: 2.8553819331890122

Epoch: 6| Step: 10
Training loss: 3.6489385550780864
Validation loss: 2.8528043781660624

Epoch: 6| Step: 11
Training loss: 2.6285806485423104
Validation loss: 2.851422825054634

Epoch: 6| Step: 12
Training loss: 2.935980870696487
Validation loss: 2.8525698220056177

Epoch: 6| Step: 13
Training loss: 3.238504620660522
Validation loss: 2.8520845477848864

Epoch: 65| Step: 0
Training loss: 2.9190603152529193
Validation loss: 2.850366821530544

Epoch: 6| Step: 1
Training loss: 2.685708801936433
Validation loss: 2.8491090737394273

Epoch: 6| Step: 2
Training loss: 2.860939806734631
Validation loss: 2.8515746494674388

Epoch: 6| Step: 3
Training loss: 3.2701720198902153
Validation loss: 2.850256571854278

Epoch: 6| Step: 4
Training loss: 3.0566772848740094
Validation loss: 2.8516299857979712

Epoch: 6| Step: 5
Training loss: 3.1298311654767654
Validation loss: 2.850483143996

Epoch: 6| Step: 6
Training loss: 3.9546171847527662
Validation loss: 2.8485586876624214

Epoch: 6| Step: 7
Training loss: 3.6454707955443824
Validation loss: 2.848532300180251

Epoch: 6| Step: 8
Training loss: 2.312203259373771
Validation loss: 2.8463960795791814

Epoch: 6| Step: 9
Training loss: 2.8299076089503896
Validation loss: 2.847816334835531

Epoch: 6| Step: 10
Training loss: 3.207291289368017
Validation loss: 2.8463161910943624

Epoch: 6| Step: 11
Training loss: 3.2038153671996286
Validation loss: 2.8441932041666846

Epoch: 6| Step: 12
Training loss: 3.6002631832983645
Validation loss: 2.845236042792485

Epoch: 6| Step: 13
Training loss: 2.862891031401339
Validation loss: 2.8437329147206056

Epoch: 66| Step: 0
Training loss: 2.5687211046658818
Validation loss: 2.8436799111169853

Epoch: 6| Step: 1
Training loss: 2.8747920085472662
Validation loss: 2.845348202493434

Epoch: 6| Step: 2
Training loss: 3.2102923336786295
Validation loss: 2.8454365381427067

Epoch: 6| Step: 3
Training loss: 3.0658843355601664
Validation loss: 2.840671048510358

Epoch: 6| Step: 4
Training loss: 2.999451269192378
Validation loss: 2.8430103979601813

Epoch: 6| Step: 5
Training loss: 3.0119502155500757
Validation loss: 2.8385472945155366

Epoch: 6| Step: 6
Training loss: 3.2431734723026695
Validation loss: 2.8438538518056267

Epoch: 6| Step: 7
Training loss: 3.0947898889564556
Validation loss: 2.8424285167531704

Epoch: 6| Step: 8
Training loss: 3.3767626362826326
Validation loss: 2.8378926503353683

Epoch: 6| Step: 9
Training loss: 3.1086661139360996
Validation loss: 2.8397359373225166

Epoch: 6| Step: 10
Training loss: 3.4579696157608715
Validation loss: 2.838238970461887

Epoch: 6| Step: 11
Training loss: 3.548153147018841
Validation loss: 2.8387833046022974

Epoch: 6| Step: 12
Training loss: 2.9868799052863704
Validation loss: 2.83832865278247

Epoch: 6| Step: 13
Training loss: 3.350363634785115
Validation loss: 2.83937118224443

Epoch: 67| Step: 0
Training loss: 2.63267729550719
Validation loss: 2.8374768363755614

Epoch: 6| Step: 1
Training loss: 3.7737753896500412
Validation loss: 2.8359218773145574

Epoch: 6| Step: 2
Training loss: 3.7525659047844817
Validation loss: 2.8343730667960956

Epoch: 6| Step: 3
Training loss: 2.7295138499811227
Validation loss: 2.8370020291155202

Epoch: 6| Step: 4
Training loss: 2.6795994157466203
Validation loss: 2.83393007185723

Epoch: 6| Step: 5
Training loss: 2.9322443269981595
Validation loss: 2.8337191446326186

Epoch: 6| Step: 6
Training loss: 3.221762275388836
Validation loss: 2.8352836529285192

Epoch: 6| Step: 7
Training loss: 3.1861135421990503
Validation loss: 2.8366000732224235

Epoch: 6| Step: 8
Training loss: 3.113813596464212
Validation loss: 2.8342102842279226

Epoch: 6| Step: 9
Training loss: 2.736023150050508
Validation loss: 2.843884942333894

Epoch: 6| Step: 10
Training loss: 3.1320172677568916
Validation loss: 2.8400538008095926

Epoch: 6| Step: 11
Training loss: 3.333445419970143
Validation loss: 2.8432030145543834

Epoch: 6| Step: 12
Training loss: 2.802084647441873
Validation loss: 2.8329636123253743

Epoch: 6| Step: 13
Training loss: 3.870029337769329
Validation loss: 2.8286106986780473

Epoch: 68| Step: 0
Training loss: 3.7361437068558816
Validation loss: 2.8291273428554082

Epoch: 6| Step: 1
Training loss: 2.721989773105354
Validation loss: 2.826596541577748

Epoch: 6| Step: 2
Training loss: 3.436354567684154
Validation loss: 2.829012569988943

Epoch: 6| Step: 3
Training loss: 2.9562390575246744
Validation loss: 2.8278672341014732

Epoch: 6| Step: 4
Training loss: 3.204193086023302
Validation loss: 2.828399473559254

Epoch: 6| Step: 5
Training loss: 2.9486057478099825
Validation loss: 2.825578677169096

Epoch: 6| Step: 6
Training loss: 2.5538608718532814
Validation loss: 2.8257900859228493

Epoch: 6| Step: 7
Training loss: 3.3202460069169204
Validation loss: 2.8255919082584153

Epoch: 6| Step: 8
Training loss: 3.0230977658568556
Validation loss: 2.82337043008321

Epoch: 6| Step: 9
Training loss: 2.926520260629758
Validation loss: 2.8243199714693543

Epoch: 6| Step: 10
Training loss: 3.764235877402299
Validation loss: 2.8216780666804286

Epoch: 6| Step: 11
Training loss: 3.0717161430504225
Validation loss: 2.821591503081604

Epoch: 6| Step: 12
Training loss: 2.8244986705375106
Validation loss: 2.819818222450771

Epoch: 6| Step: 13
Training loss: 3.0361439633218357
Validation loss: 2.8274647158288264

Epoch: 69| Step: 0
Training loss: 3.2380677303513545
Validation loss: 2.8188298520705923

Epoch: 6| Step: 1
Training loss: 2.954556557160971
Validation loss: 2.8222661173325045

Epoch: 6| Step: 2
Training loss: 3.170287087133238
Validation loss: 2.8204814292290425

Epoch: 6| Step: 3
Training loss: 3.1719405444659508
Validation loss: 2.820454689986257

Epoch: 6| Step: 4
Training loss: 3.7814948893291476
Validation loss: 2.8193468564319124

Epoch: 6| Step: 5
Training loss: 3.3857551444625162
Validation loss: 2.8196182139503323

Epoch: 6| Step: 6
Training loss: 2.990730747756911
Validation loss: 2.8185582085446432

Epoch: 6| Step: 7
Training loss: 2.930158165317923
Validation loss: 2.8213461768181545

Epoch: 6| Step: 8
Training loss: 3.321650408296533
Validation loss: 2.8226881182553356

Epoch: 6| Step: 9
Training loss: 3.23521581952824
Validation loss: 2.8209896238898353

Epoch: 6| Step: 10
Training loss: 2.8030237560211377
Validation loss: 2.8372716483927065

Epoch: 6| Step: 11
Training loss: 3.1517156379347333
Validation loss: 2.8393337635160854

Epoch: 6| Step: 12
Training loss: 2.1868189160137486
Validation loss: 2.8422045965897684

Epoch: 6| Step: 13
Training loss: 3.1522431576170726
Validation loss: 2.841939869987252

Epoch: 70| Step: 0
Training loss: 3.2340162879944163
Validation loss: 2.818507730382461

Epoch: 6| Step: 1
Training loss: 2.3436289438137896
Validation loss: 2.8187933875523825

Epoch: 6| Step: 2
Training loss: 2.898992192331875
Validation loss: 2.8419525386890836

Epoch: 6| Step: 3
Training loss: 3.2966876948514936
Validation loss: 2.915573777330913

Epoch: 6| Step: 4
Training loss: 3.5964427645204755
Validation loss: 2.9188080065722146

Epoch: 6| Step: 5
Training loss: 2.741550730270503
Validation loss: 2.878359112282254

Epoch: 6| Step: 6
Training loss: 3.3330116752559658
Validation loss: 2.83118044918025

Epoch: 6| Step: 7
Training loss: 3.0633665143506934
Validation loss: 2.8127617435051597

Epoch: 6| Step: 8
Training loss: 3.091597916351931
Validation loss: 2.8215040836444127

Epoch: 6| Step: 9
Training loss: 3.531755799384954
Validation loss: 2.927394398630043

Epoch: 6| Step: 10
Training loss: 3.029757417341291
Validation loss: 3.092205225006669

Epoch: 6| Step: 11
Training loss: 3.6461846463921623
Validation loss: 3.0525862005726334

Epoch: 6| Step: 12
Training loss: 3.0672091653829194
Validation loss: 2.9129239910217173

Epoch: 6| Step: 13
Training loss: 3.0006489051926564
Validation loss: 2.849574254389879

Epoch: 71| Step: 0
Training loss: 3.051206981538528
Validation loss: 2.8276819609442665

Epoch: 6| Step: 1
Training loss: 3.0713662239412907
Validation loss: 2.817562086207782

Epoch: 6| Step: 2
Training loss: 3.7916907564732396
Validation loss: 2.8171519083646266

Epoch: 6| Step: 3
Training loss: 2.9109511550689517
Validation loss: 2.8146755632188687

Epoch: 6| Step: 4
Training loss: 2.810548656428596
Validation loss: 2.8117088089183015

Epoch: 6| Step: 5
Training loss: 3.080340986821552
Validation loss: 2.8102324775832987

Epoch: 6| Step: 6
Training loss: 3.0729149425092266
Validation loss: 2.8116688109686705

Epoch: 6| Step: 7
Training loss: 2.9833720654010345
Validation loss: 2.809463230613569

Epoch: 6| Step: 8
Training loss: 2.5932719697859197
Validation loss: 2.810284524735814

Epoch: 6| Step: 9
Training loss: 3.5655788034159532
Validation loss: 2.8058818799418836

Epoch: 6| Step: 10
Training loss: 2.807728088842298
Validation loss: 2.8046425226138942

Epoch: 6| Step: 11
Training loss: 3.3883152842818864
Validation loss: 2.8042658518807504

Epoch: 6| Step: 12
Training loss: 3.228718995267757
Validation loss: 2.802233374990253

Epoch: 6| Step: 13
Training loss: 3.2380945315213325
Validation loss: 2.801214169721285

Epoch: 72| Step: 0
Training loss: 3.120195433780216
Validation loss: 2.797562133981142

Epoch: 6| Step: 1
Training loss: 2.865267991984965
Validation loss: 2.799146466681094

Epoch: 6| Step: 2
Training loss: 3.862668628159713
Validation loss: 2.799671744810159

Epoch: 6| Step: 3
Training loss: 3.2546526543944494
Validation loss: 2.8007744326097836

Epoch: 6| Step: 4
Training loss: 2.781299376317322
Validation loss: 2.8020392028380745

Epoch: 6| Step: 5
Training loss: 3.388047886984048
Validation loss: 2.7997798265815805

Epoch: 6| Step: 6
Training loss: 2.8197237282553984
Validation loss: 2.8033424360696104

Epoch: 6| Step: 7
Training loss: 2.495222868053049
Validation loss: 2.8019756444812467

Epoch: 6| Step: 8
Training loss: 3.0077633544077504
Validation loss: 2.804085243550962

Epoch: 6| Step: 9
Training loss: 2.889763121087279
Validation loss: 2.802188510082028

Epoch: 6| Step: 10
Training loss: 3.482088305147322
Validation loss: 2.803734023521964

Epoch: 6| Step: 11
Training loss: 2.8369623019242014
Validation loss: 2.802772030815565

Epoch: 6| Step: 12
Training loss: 3.0793216141536037
Validation loss: 2.7952726293711914

Epoch: 6| Step: 13
Training loss: 3.6094501702213644
Validation loss: 2.7935689320147805

Epoch: 73| Step: 0
Training loss: 3.1250813282874166
Validation loss: 2.7947097209021106

Epoch: 6| Step: 1
Training loss: 3.5028103036266978
Validation loss: 2.8043723606737374

Epoch: 6| Step: 2
Training loss: 3.5196274417175477
Validation loss: 2.80245072450607

Epoch: 6| Step: 3
Training loss: 2.8141594971202206
Validation loss: 2.7946621717201725

Epoch: 6| Step: 4
Training loss: 2.7677451590108997
Validation loss: 2.806266135418701

Epoch: 6| Step: 5
Training loss: 3.1268311285539774
Validation loss: 2.8030836263554053

Epoch: 6| Step: 6
Training loss: 2.5509124768838465
Validation loss: 2.811003188480353

Epoch: 6| Step: 7
Training loss: 3.115940389481677
Validation loss: 2.815064724515938

Epoch: 6| Step: 8
Training loss: 3.407223623574614
Validation loss: 2.8093502806785184

Epoch: 6| Step: 9
Training loss: 3.25062672367648
Validation loss: 2.7889555306248432

Epoch: 6| Step: 10
Training loss: 2.5364973520858785
Validation loss: 2.788354339044842

Epoch: 6| Step: 11
Training loss: 3.251153594468311
Validation loss: 2.7894057241945704

Epoch: 6| Step: 12
Training loss: 3.0982662336345435
Validation loss: 2.788833446523836

Epoch: 6| Step: 13
Training loss: 3.21615911112939
Validation loss: 2.7889961622449255

Epoch: 74| Step: 0
Training loss: 3.2153216130834443
Validation loss: 2.787177308442798

Epoch: 6| Step: 1
Training loss: 3.177863270232757
Validation loss: 2.7901161634553158

Epoch: 6| Step: 2
Training loss: 3.2077967372531164
Validation loss: 2.78999899279448

Epoch: 6| Step: 3
Training loss: 3.371591047292887
Validation loss: 2.790107880196383

Epoch: 6| Step: 4
Training loss: 3.178462361872458
Validation loss: 2.79087393765073

Epoch: 6| Step: 5
Training loss: 3.414274510275727
Validation loss: 2.787325808663474

Epoch: 6| Step: 6
Training loss: 3.4504491872966643
Validation loss: 2.784648292579026

Epoch: 6| Step: 7
Training loss: 3.2509404802368316
Validation loss: 2.784180802574649

Epoch: 6| Step: 8
Training loss: 2.5594643080037884
Validation loss: 2.782645613813494

Epoch: 6| Step: 9
Training loss: 2.964474138584272
Validation loss: 2.7859509347765368

Epoch: 6| Step: 10
Training loss: 2.5131203639953705
Validation loss: 2.780602865964778

Epoch: 6| Step: 11
Training loss: 3.2165383453336838
Validation loss: 2.7818041557365816

Epoch: 6| Step: 12
Training loss: 3.1690355943418442
Validation loss: 2.7831226223678693

Epoch: 6| Step: 13
Training loss: 1.9423969895433792
Validation loss: 2.7930982834334084

Epoch: 75| Step: 0
Training loss: 2.2208540704938717
Validation loss: 2.808226922709956

Epoch: 6| Step: 1
Training loss: 3.5995787744985943
Validation loss: 2.8292485862116683

Epoch: 6| Step: 2
Training loss: 3.359979619463917
Validation loss: 2.8965125905507088

Epoch: 6| Step: 3
Training loss: 3.6089557883159284
Validation loss: 2.8665399420597395

Epoch: 6| Step: 4
Training loss: 2.6171219091594384
Validation loss: 2.8337318238507385

Epoch: 6| Step: 5
Training loss: 2.5328608908904844
Validation loss: 2.805988707465076

Epoch: 6| Step: 6
Training loss: 3.180182341140267
Validation loss: 2.7798441695664753

Epoch: 6| Step: 7
Training loss: 3.4786091127421788
Validation loss: 2.7721140126484247

Epoch: 6| Step: 8
Training loss: 3.491110821335482
Validation loss: 2.7732770541488927

Epoch: 6| Step: 9
Training loss: 2.603458206447906
Validation loss: 2.770408883447144

Epoch: 6| Step: 10
Training loss: 3.261257774077654
Validation loss: 2.7679140992492846

Epoch: 6| Step: 11
Training loss: 2.9308331093468545
Validation loss: 2.773977009214012

Epoch: 6| Step: 12
Training loss: 3.1884174896422888
Validation loss: 2.7729946228293296

Epoch: 6| Step: 13
Training loss: 2.5684689110435173
Validation loss: 2.777323501794867

Epoch: 76| Step: 0
Training loss: 2.733200082399693
Validation loss: 2.7740666546039887

Epoch: 6| Step: 1
Training loss: 3.772962583743072
Validation loss: 2.766616774162404

Epoch: 6| Step: 2
Training loss: 2.908945453865447
Validation loss: 2.77562439089268

Epoch: 6| Step: 3
Training loss: 2.064156531733967
Validation loss: 2.778953221475192

Epoch: 6| Step: 4
Training loss: 2.2905897442236953
Validation loss: 2.8025076116801175

Epoch: 6| Step: 5
Training loss: 3.326909232715045
Validation loss: 2.779684651492037

Epoch: 6| Step: 6
Training loss: 2.7952350091828198
Validation loss: 2.771215865950954

Epoch: 6| Step: 7
Training loss: 2.922954828978884
Validation loss: 2.770284169139686

Epoch: 6| Step: 8
Training loss: 3.302744770090087
Validation loss: 2.765287055712701

Epoch: 6| Step: 9
Training loss: 3.7976147594276792
Validation loss: 2.767654874437112

Epoch: 6| Step: 10
Training loss: 2.9980659608513007
Validation loss: 2.7657238443373284

Epoch: 6| Step: 11
Training loss: 3.2515674625855633
Validation loss: 2.7634893372367473

Epoch: 6| Step: 12
Training loss: 3.6205083709270216
Validation loss: 2.763326968551833

Epoch: 6| Step: 13
Training loss: 2.641858687376401
Validation loss: 2.7659092608677933

Epoch: 77| Step: 0
Training loss: 2.9934009452043004
Validation loss: 2.764209395912984

Epoch: 6| Step: 1
Training loss: 2.894057097319254
Validation loss: 2.7661721191427646

Epoch: 6| Step: 2
Training loss: 2.981622675028669
Validation loss: 2.764346924546169

Epoch: 6| Step: 3
Training loss: 3.420390046392079
Validation loss: 2.764081400551463

Epoch: 6| Step: 4
Training loss: 2.6038062698210243
Validation loss: 2.763443851662848

Epoch: 6| Step: 5
Training loss: 3.5903090215947198
Validation loss: 2.7594505060307837

Epoch: 6| Step: 6
Training loss: 3.3203241325623436
Validation loss: 2.7654030272041896

Epoch: 6| Step: 7
Training loss: 2.99984899776629
Validation loss: 2.760114241270723

Epoch: 6| Step: 8
Training loss: 3.106640096995586
Validation loss: 2.762887127767743

Epoch: 6| Step: 9
Training loss: 2.983831865508433
Validation loss: 2.7624358216177236

Epoch: 6| Step: 10
Training loss: 2.7947420479579193
Validation loss: 2.7638180568148973

Epoch: 6| Step: 11
Training loss: 2.3780550130603793
Validation loss: 2.7723445769596102

Epoch: 6| Step: 12
Training loss: 3.5815597107332793
Validation loss: 2.7655478401189453

Epoch: 6| Step: 13
Training loss: 3.4341240691409824
Validation loss: 2.7610224951544104

Epoch: 78| Step: 0
Training loss: 3.130376844054245
Validation loss: 2.7671560706608394

Epoch: 6| Step: 1
Training loss: 3.038496342267447
Validation loss: 2.7695484153613297

Epoch: 6| Step: 2
Training loss: 2.764903346160737
Validation loss: 2.76232447172582

Epoch: 6| Step: 3
Training loss: 2.6398474095780067
Validation loss: 2.7629919767470033

Epoch: 6| Step: 4
Training loss: 2.85085641140384
Validation loss: 2.769340946550798

Epoch: 6| Step: 5
Training loss: 3.5181676189574262
Validation loss: 2.7689364448730593

Epoch: 6| Step: 6
Training loss: 3.5516201996385353
Validation loss: 2.771168167592137

Epoch: 6| Step: 7
Training loss: 2.952157159679474
Validation loss: 2.765766375866467

Epoch: 6| Step: 8
Training loss: 3.369118829186745
Validation loss: 2.7885701575739774

Epoch: 6| Step: 9
Training loss: 2.905500089635866
Validation loss: 2.7696746409994684

Epoch: 6| Step: 10
Training loss: 2.656007912767642
Validation loss: 2.7753415213614354

Epoch: 6| Step: 11
Training loss: 3.0569819348181775
Validation loss: 2.778215499421362

Epoch: 6| Step: 12
Training loss: 2.9283854528517304
Validation loss: 2.7869749307775127

Epoch: 6| Step: 13
Training loss: 3.8577180463832015
Validation loss: 2.79623424995094

Epoch: 79| Step: 0
Training loss: 3.095487780857878
Validation loss: 2.792051710874408

Epoch: 6| Step: 1
Training loss: 2.7874198799422323
Validation loss: 2.787043305342376

Epoch: 6| Step: 2
Training loss: 3.0595533246915076
Validation loss: 2.785907367420978

Epoch: 6| Step: 3
Training loss: 2.8662267421306167
Validation loss: 2.7840080472331046

Epoch: 6| Step: 4
Training loss: 3.2565523267161893
Validation loss: 2.774495934008102

Epoch: 6| Step: 5
Training loss: 3.539971982123066
Validation loss: 2.769249666977499

Epoch: 6| Step: 6
Training loss: 2.9840543085326
Validation loss: 2.7588872160181612

Epoch: 6| Step: 7
Training loss: 3.0922845008906026
Validation loss: 2.7566199557326714

Epoch: 6| Step: 8
Training loss: 2.990366568405944
Validation loss: 2.755804434765066

Epoch: 6| Step: 9
Training loss: 3.142544136314022
Validation loss: 2.7588010787738475

Epoch: 6| Step: 10
Training loss: 3.6131944140748042
Validation loss: 2.7621394744607204

Epoch: 6| Step: 11
Training loss: 2.592629064071293
Validation loss: 2.7713485326389264

Epoch: 6| Step: 12
Training loss: 2.8989407084554415
Validation loss: 2.7945321901651985

Epoch: 6| Step: 13
Training loss: 3.234762859585145
Validation loss: 2.7975972046859505

Epoch: 80| Step: 0
Training loss: 2.8896081734056933
Validation loss: 2.794400577354027

Epoch: 6| Step: 1
Training loss: 2.753914301434374
Validation loss: 2.7605038496580296

Epoch: 6| Step: 2
Training loss: 3.476268833058632
Validation loss: 2.7465554812224826

Epoch: 6| Step: 3
Training loss: 3.1551149045692704
Validation loss: 2.7491320044715724

Epoch: 6| Step: 4
Training loss: 2.9430353483720815
Validation loss: 2.751292541147876

Epoch: 6| Step: 5
Training loss: 3.4045802232106173
Validation loss: 2.75241475440195

Epoch: 6| Step: 6
Training loss: 2.9222503257853756
Validation loss: 2.7537636307966493

Epoch: 6| Step: 7
Training loss: 3.1940796206110353
Validation loss: 2.763852784897716

Epoch: 6| Step: 8
Training loss: 3.5388574267122825
Validation loss: 2.796731972349978

Epoch: 6| Step: 9
Training loss: 3.104098496339249
Validation loss: 2.749147294146606

Epoch: 6| Step: 10
Training loss: 3.4727435792942294
Validation loss: 2.7453943309225495

Epoch: 6| Step: 11
Training loss: 3.016588442580323
Validation loss: 2.753695871984704

Epoch: 6| Step: 12
Training loss: 2.3035095307914975
Validation loss: 2.7638814166865293

Epoch: 6| Step: 13
Training loss: 2.3026511296180856
Validation loss: 2.78476307664525

Epoch: 81| Step: 0
Training loss: 2.9246545310474814
Validation loss: 2.7696923997104808

Epoch: 6| Step: 1
Training loss: 3.1979790266254606
Validation loss: 2.751897370822625

Epoch: 6| Step: 2
Training loss: 3.6703810229508456
Validation loss: 2.748296381507951

Epoch: 6| Step: 3
Training loss: 2.980832698894117
Validation loss: 2.7470267005820115

Epoch: 6| Step: 4
Training loss: 2.6953780456534253
Validation loss: 2.743835795233741

Epoch: 6| Step: 5
Training loss: 3.396927842445975
Validation loss: 2.7467308217426383

Epoch: 6| Step: 6
Training loss: 3.423342316147392
Validation loss: 2.7483457211612303

Epoch: 6| Step: 7
Training loss: 2.645353519056327
Validation loss: 2.756086984969899

Epoch: 6| Step: 8
Training loss: 3.40972946660001
Validation loss: 2.7411738313828113

Epoch: 6| Step: 9
Training loss: 2.869410346994817
Validation loss: 2.743330830831177

Epoch: 6| Step: 10
Training loss: 2.6487338370117626
Validation loss: 2.7378034164961003

Epoch: 6| Step: 11
Training loss: 2.5731108022079914
Validation loss: 2.7380830014449073

Epoch: 6| Step: 12
Training loss: 3.303540041859112
Validation loss: 2.7354265413692676

Epoch: 6| Step: 13
Training loss: 2.6290253248072344
Validation loss: 2.7366875245612414

Epoch: 82| Step: 0
Training loss: 2.857845042999169
Validation loss: 2.7370239121772486

Epoch: 6| Step: 1
Training loss: 3.4525709441324413
Validation loss: 2.7385159471887466

Epoch: 6| Step: 2
Training loss: 2.925546063696996
Validation loss: 2.7375180604820004

Epoch: 6| Step: 3
Training loss: 2.9290222226410467
Validation loss: 2.7356308544962507

Epoch: 6| Step: 4
Training loss: 3.457300208022664
Validation loss: 2.7376444378931346

Epoch: 6| Step: 5
Training loss: 3.160120790563188
Validation loss: 2.7364089119007806

Epoch: 6| Step: 6
Training loss: 3.0446764716796606
Validation loss: 2.73494585819942

Epoch: 6| Step: 7
Training loss: 2.5878889666857896
Validation loss: 2.7390089605379138

Epoch: 6| Step: 8
Training loss: 3.1353776661083206
Validation loss: 2.7352519533207524

Epoch: 6| Step: 9
Training loss: 2.7935867159445675
Validation loss: 2.734344919159377

Epoch: 6| Step: 10
Training loss: 3.1829960735942797
Validation loss: 2.731538784526876

Epoch: 6| Step: 11
Training loss: 3.2017097137697474
Validation loss: 2.7319409202814606

Epoch: 6| Step: 12
Training loss: 2.955088774869276
Validation loss: 2.731743054334885

Epoch: 6| Step: 13
Training loss: 3.0626619257255707
Validation loss: 2.7311632401983337

Epoch: 83| Step: 0
Training loss: 3.155047499212974
Validation loss: 2.7368349472266322

Epoch: 6| Step: 1
Training loss: 3.171124148640174
Validation loss: 2.7304844896958835

Epoch: 6| Step: 2
Training loss: 2.7748679327253365
Validation loss: 2.731191591414665

Epoch: 6| Step: 3
Training loss: 3.426397253001464
Validation loss: 2.730825950409828

Epoch: 6| Step: 4
Training loss: 2.525031752433929
Validation loss: 2.7328075504506164

Epoch: 6| Step: 5
Training loss: 2.879721703328821
Validation loss: 2.73378123691116

Epoch: 6| Step: 6
Training loss: 2.616184327038986
Validation loss: 2.7285564021797866

Epoch: 6| Step: 7
Training loss: 3.111342071482788
Validation loss: 2.7352572703882245

Epoch: 6| Step: 8
Training loss: 2.9470429939936853
Validation loss: 2.7412773224909897

Epoch: 6| Step: 9
Training loss: 3.5531321717578237
Validation loss: 2.7340586273883547

Epoch: 6| Step: 10
Training loss: 2.689965647368196
Validation loss: 2.7263441096197387

Epoch: 6| Step: 11
Training loss: 2.596693000888445
Validation loss: 2.728523987190227

Epoch: 6| Step: 12
Training loss: 3.948115857952984
Validation loss: 2.7272210179644563

Epoch: 6| Step: 13
Training loss: 2.935966091209657
Validation loss: 2.7215882393145336

Epoch: 84| Step: 0
Training loss: 2.808563614260482
Validation loss: 2.726094739935074

Epoch: 6| Step: 1
Training loss: 2.9301679293580225
Validation loss: 2.7247176445631474

Epoch: 6| Step: 2
Training loss: 2.4032076143070493
Validation loss: 2.7198670501340874

Epoch: 6| Step: 3
Training loss: 3.122278936179479
Validation loss: 2.7238686965508587

Epoch: 6| Step: 4
Training loss: 3.1297955148219523
Validation loss: 2.7230454137025273

Epoch: 6| Step: 5
Training loss: 2.728431039535359
Validation loss: 2.7180595629217614

Epoch: 6| Step: 6
Training loss: 3.5192131212007665
Validation loss: 2.723947576334808

Epoch: 6| Step: 7
Training loss: 2.9236066450224345
Validation loss: 2.7234311066616357

Epoch: 6| Step: 8
Training loss: 3.014433788570223
Validation loss: 2.71809655826849

Epoch: 6| Step: 9
Training loss: 2.9451088265743612
Validation loss: 2.71785035958819

Epoch: 6| Step: 10
Training loss: 3.389558545291408
Validation loss: 2.7162637984725966

Epoch: 6| Step: 11
Training loss: 3.103300669327819
Validation loss: 2.7171133336891855

Epoch: 6| Step: 12
Training loss: 3.0894242687954128
Validation loss: 2.72150610250234

Epoch: 6| Step: 13
Training loss: 3.5945594207780727
Validation loss: 2.715862633918752

Epoch: 85| Step: 0
Training loss: 3.3137283926553978
Validation loss: 2.717366388064911

Epoch: 6| Step: 1
Training loss: 3.1617601094558223
Validation loss: 2.7204406304001694

Epoch: 6| Step: 2
Training loss: 2.9466279428909385
Validation loss: 2.71254108470237

Epoch: 6| Step: 3
Training loss: 3.104549017449331
Validation loss: 2.713710698791876

Epoch: 6| Step: 4
Training loss: 3.8044102624544003
Validation loss: 2.71092088554823

Epoch: 6| Step: 5
Training loss: 3.0238207197178735
Validation loss: 2.7144307815511715

Epoch: 6| Step: 6
Training loss: 3.1457671775345846
Validation loss: 2.718310109214929

Epoch: 6| Step: 7
Training loss: 2.782850169505712
Validation loss: 2.718192612339584

Epoch: 6| Step: 8
Training loss: 2.7295847759341036
Validation loss: 2.716758704109563

Epoch: 6| Step: 9
Training loss: 3.05607709961145
Validation loss: 2.719679815726777

Epoch: 6| Step: 10
Training loss: 3.4685503927999344
Validation loss: 2.718701768710623

Epoch: 6| Step: 11
Training loss: 2.2975815704775417
Validation loss: 2.7194703745684015

Epoch: 6| Step: 12
Training loss: 2.6319171050795376
Validation loss: 2.719569274097497

Epoch: 6| Step: 13
Training loss: 2.74253482194908
Validation loss: 2.719584211513629

Epoch: 86| Step: 0
Training loss: 3.291973212410087
Validation loss: 2.7169193369881994

Epoch: 6| Step: 1
Training loss: 3.4724999854992067
Validation loss: 2.7113298136583697

Epoch: 6| Step: 2
Training loss: 2.4158480562215647
Validation loss: 2.7197262740614168

Epoch: 6| Step: 3
Training loss: 2.5940323641485277
Validation loss: 2.7312804935290833

Epoch: 6| Step: 4
Training loss: 3.1661876182269233
Validation loss: 2.7603577709512805

Epoch: 6| Step: 5
Training loss: 3.058155013731759
Validation loss: 2.7340081691057434

Epoch: 6| Step: 6
Training loss: 2.9598910211142164
Validation loss: 2.74094496617896

Epoch: 6| Step: 7
Training loss: 3.401164326736628
Validation loss: 2.7256119294551815

Epoch: 6| Step: 8
Training loss: 2.8880389218441835
Validation loss: 2.7052408729391817

Epoch: 6| Step: 9
Training loss: 3.031034166969731
Validation loss: 2.714121583074034

Epoch: 6| Step: 10
Training loss: 3.2543418931531667
Validation loss: 2.7134180529529517

Epoch: 6| Step: 11
Training loss: 3.2356606107582877
Validation loss: 2.70953094059772

Epoch: 6| Step: 12
Training loss: 2.7389240897983527
Validation loss: 2.710772332560908

Epoch: 6| Step: 13
Training loss: 2.827329660777404
Validation loss: 2.7100151942131054

Epoch: 87| Step: 0
Training loss: 2.508724629074775
Validation loss: 2.7091964356075624

Epoch: 6| Step: 1
Training loss: 3.698508560020171
Validation loss: 2.7094173719847388

Epoch: 6| Step: 2
Training loss: 3.514433120445039
Validation loss: 2.7046143573715344

Epoch: 6| Step: 3
Training loss: 3.1955303686803234
Validation loss: 2.7069973726198806

Epoch: 6| Step: 4
Training loss: 3.4540765754414986
Validation loss: 2.710126507228092

Epoch: 6| Step: 5
Training loss: 3.155692627292268
Validation loss: 2.7038372779317488

Epoch: 6| Step: 6
Training loss: 2.407893424682435
Validation loss: 2.706145857262893

Epoch: 6| Step: 7
Training loss: 3.3274971096562216
Validation loss: 2.7060323010053464

Epoch: 6| Step: 8
Training loss: 2.981694320740955
Validation loss: 2.7049899482445516

Epoch: 6| Step: 9
Training loss: 2.9389795675953034
Validation loss: 2.702222136640026

Epoch: 6| Step: 10
Training loss: 2.552771360075416
Validation loss: 2.7066794006398283

Epoch: 6| Step: 11
Training loss: 2.3156992458945362
Validation loss: 2.714044398975478

Epoch: 6| Step: 12
Training loss: 2.655964555549813
Validation loss: 2.7110648441362164

Epoch: 6| Step: 13
Training loss: 3.5813675892749792
Validation loss: 2.708048339943777

Epoch: 88| Step: 0
Training loss: 2.9510565078170057
Validation loss: 2.7064201059198707

Epoch: 6| Step: 1
Training loss: 2.9292607111007776
Validation loss: 2.702116728472153

Epoch: 6| Step: 2
Training loss: 3.7368165019538893
Validation loss: 2.7073821853200224

Epoch: 6| Step: 3
Training loss: 2.8388297305212937
Validation loss: 2.7184313081785496

Epoch: 6| Step: 4
Training loss: 3.3055339477716164
Validation loss: 2.723882966628395

Epoch: 6| Step: 5
Training loss: 2.8087643716102373
Validation loss: 2.7245929709437724

Epoch: 6| Step: 6
Training loss: 2.962658545521004
Validation loss: 2.725395833340397

Epoch: 6| Step: 7
Training loss: 3.3073777235153923
Validation loss: 2.7250799187866983

Epoch: 6| Step: 8
Training loss: 2.74828215610594
Validation loss: 2.6987437332491617

Epoch: 6| Step: 9
Training loss: 2.7557744175977166
Validation loss: 2.699828550196449

Epoch: 6| Step: 10
Training loss: 3.100593011802953
Validation loss: 2.698504255471512

Epoch: 6| Step: 11
Training loss: 2.5060068445378607
Validation loss: 2.697591550996798

Epoch: 6| Step: 12
Training loss: 3.4240847903207876
Validation loss: 2.698021931379742

Epoch: 6| Step: 13
Training loss: 2.5742828407471157
Validation loss: 2.6964378353475924

Epoch: 89| Step: 0
Training loss: 3.469865361880434
Validation loss: 2.6977341682403577

Epoch: 6| Step: 1
Training loss: 3.6103041472660724
Validation loss: 2.696414630271099

Epoch: 6| Step: 2
Training loss: 3.2379110421489528
Validation loss: 2.6928892461425065

Epoch: 6| Step: 3
Training loss: 1.9452399427984697
Validation loss: 2.6937051144683695

Epoch: 6| Step: 4
Training loss: 2.8835701295789056
Validation loss: 2.7017443591114536

Epoch: 6| Step: 5
Training loss: 2.933156800015397
Validation loss: 2.7093205194949435

Epoch: 6| Step: 6
Training loss: 2.7715475170639348
Validation loss: 2.723878962882488

Epoch: 6| Step: 7
Training loss: 2.818174529275949
Validation loss: 2.750228470552843

Epoch: 6| Step: 8
Training loss: 2.921691888793545
Validation loss: 2.767963380959388

Epoch: 6| Step: 9
Training loss: 3.0981226373955524
Validation loss: 2.7087750887868167

Epoch: 6| Step: 10
Training loss: 2.7592641667780615
Validation loss: 2.6921291114327444

Epoch: 6| Step: 11
Training loss: 3.0482171648212883
Validation loss: 2.6956221502654065

Epoch: 6| Step: 12
Training loss: 3.133475749519557
Validation loss: 2.698058591463883

Epoch: 6| Step: 13
Training loss: 3.7766272921640622
Validation loss: 2.6978939468948147

Epoch: 90| Step: 0
Training loss: 2.2348525597329942
Validation loss: 2.6972933278888758

Epoch: 6| Step: 1
Training loss: 2.9625589163671964
Validation loss: 2.696676709481298

Epoch: 6| Step: 2
Training loss: 3.2176301359877586
Validation loss: 2.7090586225159656

Epoch: 6| Step: 3
Training loss: 2.7593603356253618
Validation loss: 2.713292272432976

Epoch: 6| Step: 4
Training loss: 3.1597165248572625
Validation loss: 2.7019004744028003

Epoch: 6| Step: 5
Training loss: 3.6639318381886663
Validation loss: 2.6978029610476124

Epoch: 6| Step: 6
Training loss: 3.0869543790371825
Validation loss: 2.6969328411392475

Epoch: 6| Step: 7
Training loss: 3.175388138242506
Validation loss: 2.69558260484055

Epoch: 6| Step: 8
Training loss: 2.886051993998124
Validation loss: 2.6946040019643074

Epoch: 6| Step: 9
Training loss: 2.6718973080780164
Validation loss: 2.6929055986611097

Epoch: 6| Step: 10
Training loss: 3.0197147446873567
Validation loss: 2.693906816333384

Epoch: 6| Step: 11
Training loss: 3.890626225605354
Validation loss: 2.694391829021307

Epoch: 6| Step: 12
Training loss: 2.3542716303918647
Validation loss: 2.68964732704093

Epoch: 6| Step: 13
Training loss: 3.196122866516344
Validation loss: 2.68578574702862

Epoch: 91| Step: 0
Training loss: 3.031702066906534
Validation loss: 2.688293925465307

Epoch: 6| Step: 1
Training loss: 3.213220383438389
Validation loss: 2.6901767599689936

Epoch: 6| Step: 2
Training loss: 3.299031496978196
Validation loss: 2.6889896046859296

Epoch: 6| Step: 3
Training loss: 3.0682947260057607
Validation loss: 2.7023023152113685

Epoch: 6| Step: 4
Training loss: 2.2708898998062934
Validation loss: 2.7006549217890212

Epoch: 6| Step: 5
Training loss: 3.8190214319739
Validation loss: 2.6966512096289628

Epoch: 6| Step: 6
Training loss: 2.525932849755632
Validation loss: 2.7024020242309303

Epoch: 6| Step: 7
Training loss: 3.042523842485427
Validation loss: 2.6967378024313895

Epoch: 6| Step: 8
Training loss: 3.0812496843008996
Validation loss: 2.6977716665815974

Epoch: 6| Step: 9
Training loss: 2.8241539152309074
Validation loss: 2.692960205662411

Epoch: 6| Step: 10
Training loss: 3.7640257165741757
Validation loss: 2.6857259637179665

Epoch: 6| Step: 11
Training loss: 2.5935181663499125
Validation loss: 2.6875535502229515

Epoch: 6| Step: 12
Training loss: 2.855171490811604
Validation loss: 2.686801314959911

Epoch: 6| Step: 13
Training loss: 1.835318408231028
Validation loss: 2.68494766844312

Epoch: 92| Step: 0
Training loss: 3.4598884456489993
Validation loss: 2.6807570893806547

Epoch: 6| Step: 1
Training loss: 3.2868737846353406
Validation loss: 2.6789082236218666

Epoch: 6| Step: 2
Training loss: 3.1795588286887813
Validation loss: 2.6870344550035377

Epoch: 6| Step: 3
Training loss: 2.852903954591022
Validation loss: 2.683925626948184

Epoch: 6| Step: 4
Training loss: 3.137818862092538
Validation loss: 2.684024724419242

Epoch: 6| Step: 5
Training loss: 3.0904634531844493
Validation loss: 2.67954676472099

Epoch: 6| Step: 6
Training loss: 3.0255800684110494
Validation loss: 2.6794200821064758

Epoch: 6| Step: 7
Training loss: 3.524549490635431
Validation loss: 2.679122099322876

Epoch: 6| Step: 8
Training loss: 2.5433056867437593
Validation loss: 2.6757387870914515

Epoch: 6| Step: 9
Training loss: 2.1766572623563305
Validation loss: 2.6755559177429893

Epoch: 6| Step: 10
Training loss: 2.632545706704479
Validation loss: 2.6792462326230746

Epoch: 6| Step: 11
Training loss: 3.3891333889615245
Validation loss: 2.6732675928756917

Epoch: 6| Step: 12
Training loss: 2.930702298203173
Validation loss: 2.6794259060770034

Epoch: 6| Step: 13
Training loss: 2.401898400189984
Validation loss: 2.6764141098738987

Epoch: 93| Step: 0
Training loss: 2.239422944705769
Validation loss: 2.6696060641656447

Epoch: 6| Step: 1
Training loss: 3.6697043638143185
Validation loss: 2.7175622924022176

Epoch: 6| Step: 2
Training loss: 2.405267886590225
Validation loss: 2.76955380635881

Epoch: 6| Step: 3
Training loss: 3.679942776193615
Validation loss: 2.8244222975752367

Epoch: 6| Step: 4
Training loss: 3.188489872435849
Validation loss: 2.6951554076510424

Epoch: 6| Step: 5
Training loss: 3.1169840428393965
Validation loss: 2.668847881736448

Epoch: 6| Step: 6
Training loss: 3.341502923037472
Validation loss: 2.676221670000322

Epoch: 6| Step: 7
Training loss: 2.7042165327446024
Validation loss: 2.6782862506088194

Epoch: 6| Step: 8
Training loss: 2.887155791404886
Validation loss: 2.6780590795964554

Epoch: 6| Step: 9
Training loss: 2.8542885487467515
Validation loss: 2.680096482211691

Epoch: 6| Step: 10
Training loss: 3.304972895570265
Validation loss: 2.683140046695609

Epoch: 6| Step: 11
Training loss: 2.959807087050389
Validation loss: 2.684320569003748

Epoch: 6| Step: 12
Training loss: 2.982728673797149
Validation loss: 2.6845445897410665

Epoch: 6| Step: 13
Training loss: 1.901381419578701
Validation loss: 2.68638125097351

Epoch: 94| Step: 0
Training loss: 3.2819096946589625
Validation loss: 2.687127353887061

Epoch: 6| Step: 1
Training loss: 2.5604947315438227
Validation loss: 2.680065197173798

Epoch: 6| Step: 2
Training loss: 2.9871131359189906
Validation loss: 2.6827267982096488

Epoch: 6| Step: 3
Training loss: 3.8723912225151533
Validation loss: 2.6802546886501553

Epoch: 6| Step: 4
Training loss: 3.35910132424477
Validation loss: 2.6780893312493776

Epoch: 6| Step: 5
Training loss: 3.1721025958408156
Validation loss: 2.677379316155861

Epoch: 6| Step: 6
Training loss: 2.7553362657426943
Validation loss: 2.6758833843320184

Epoch: 6| Step: 7
Training loss: 2.744688279426409
Validation loss: 2.677192155890914

Epoch: 6| Step: 8
Training loss: 3.032518888133224
Validation loss: 2.674586850066452

Epoch: 6| Step: 9
Training loss: 2.9292905004452074
Validation loss: 2.6740160595232925

Epoch: 6| Step: 10
Training loss: 2.627361960664151
Validation loss: 2.67536173466691

Epoch: 6| Step: 11
Training loss: 2.28101608958375
Validation loss: 2.673344055043603

Epoch: 6| Step: 12
Training loss: 3.410701537696907
Validation loss: 2.6745637611762283

Epoch: 6| Step: 13
Training loss: 2.9549748515496734
Validation loss: 2.671710351988513

Epoch: 95| Step: 0
Training loss: 2.807488957669562
Validation loss: 2.672311337145791

Epoch: 6| Step: 1
Training loss: 3.14516686122707
Validation loss: 2.674130720332962

Epoch: 6| Step: 2
Training loss: 3.6709941700322997
Validation loss: 2.670897808803382

Epoch: 6| Step: 3
Training loss: 2.4035895366144486
Validation loss: 2.6722570094771103

Epoch: 6| Step: 4
Training loss: 2.8445202130253127
Validation loss: 2.6692613388520945

Epoch: 6| Step: 5
Training loss: 3.311919827306344
Validation loss: 2.66863797821021

Epoch: 6| Step: 6
Training loss: 3.7048142841450074
Validation loss: 2.66689201013008

Epoch: 6| Step: 7
Training loss: 3.327611176133168
Validation loss: 2.671228605638052

Epoch: 6| Step: 8
Training loss: 3.228023466154928
Validation loss: 2.674982405182893

Epoch: 6| Step: 9
Training loss: 3.0704404692638105
Validation loss: 2.686952819981915

Epoch: 6| Step: 10
Training loss: 3.0082634922138096
Validation loss: 2.691612382567008

Epoch: 6| Step: 11
Training loss: 2.2464894352555596
Validation loss: 2.7338731465179884

Epoch: 6| Step: 12
Training loss: 2.2122079818171874
Validation loss: 2.7788317828679805

Epoch: 6| Step: 13
Training loss: 2.671152474493395
Validation loss: 2.785078909562009

Epoch: 96| Step: 0
Training loss: 3.7118511159487815
Validation loss: 2.8056134007773084

Epoch: 6| Step: 1
Training loss: 2.6049577249036417
Validation loss: 2.8000273161535714

Epoch: 6| Step: 2
Training loss: 4.029150127599172
Validation loss: 2.803542457183123

Epoch: 6| Step: 3
Training loss: 2.9297685535662743
Validation loss: 2.7720677447060638

Epoch: 6| Step: 4
Training loss: 2.966559153833916
Validation loss: 2.7351803532626757

Epoch: 6| Step: 5
Training loss: 2.7710464701505617
Validation loss: 2.699649626870905

Epoch: 6| Step: 6
Training loss: 3.0136614321554327
Validation loss: 2.6828738491844644

Epoch: 6| Step: 7
Training loss: 2.9841490655028613
Validation loss: 2.6617744475922964

Epoch: 6| Step: 8
Training loss: 2.7074322203995913
Validation loss: 2.675608846596778

Epoch: 6| Step: 9
Training loss: 3.3496939334261326
Validation loss: 2.7411848746108256

Epoch: 6| Step: 10
Training loss: 2.489814704986545
Validation loss: 2.790342102715128

Epoch: 6| Step: 11
Training loss: 3.3825765267545074
Validation loss: 2.8329944649235177

Epoch: 6| Step: 12
Training loss: 2.7478035911989167
Validation loss: 2.6836639962074322

Epoch: 6| Step: 13
Training loss: 2.8376143781153065
Validation loss: 2.6678202086315954

Epoch: 97| Step: 0
Training loss: 2.7997234480387605
Validation loss: 2.6592473047210903

Epoch: 6| Step: 1
Training loss: 1.9844687732556987
Validation loss: 2.6579194123311045

Epoch: 6| Step: 2
Training loss: 3.280211802133806
Validation loss: 2.653937809246789

Epoch: 6| Step: 3
Training loss: 3.1749628380230135
Validation loss: 2.6587678927585054

Epoch: 6| Step: 4
Training loss: 3.0230868823771635
Validation loss: 2.6698318784221433

Epoch: 6| Step: 5
Training loss: 3.901131045340872
Validation loss: 2.6850850195474454

Epoch: 6| Step: 6
Training loss: 2.9976050035730673
Validation loss: 2.725458024574532

Epoch: 6| Step: 7
Training loss: 3.091920253776428
Validation loss: 2.793633431372544

Epoch: 6| Step: 8
Training loss: 3.5860320434074784
Validation loss: 2.850264557089679

Epoch: 6| Step: 9
Training loss: 3.46147823199831
Validation loss: 2.825557621436201

Epoch: 6| Step: 10
Training loss: 2.728730135263018
Validation loss: 2.724251250319633

Epoch: 6| Step: 11
Training loss: 2.367007107045923
Validation loss: 2.6548334879680477

Epoch: 6| Step: 12
Training loss: 2.777359116051682
Validation loss: 2.6523179080140453

Epoch: 6| Step: 13
Training loss: 2.8850710738764063
Validation loss: 2.6605581883670126

Epoch: 98| Step: 0
Training loss: 3.1885003408856845
Validation loss: 2.684914094866742

Epoch: 6| Step: 1
Training loss: 2.6216745656891414
Validation loss: 2.662875540311352

Epoch: 6| Step: 2
Training loss: 2.7051858267706566
Validation loss: 2.6633843350953788

Epoch: 6| Step: 3
Training loss: 3.0068148457059043
Validation loss: 2.6715610782449843

Epoch: 6| Step: 4
Training loss: 2.604040208925063
Validation loss: 2.684139490629492

Epoch: 6| Step: 5
Training loss: 3.382941051974275
Validation loss: 2.682931267073787

Epoch: 6| Step: 6
Training loss: 3.2085064597710535
Validation loss: 2.682340296826055

Epoch: 6| Step: 7
Training loss: 2.4284053252821374
Validation loss: 2.689926159837124

Epoch: 6| Step: 8
Training loss: 3.007546945714442
Validation loss: 2.6921775226290174

Epoch: 6| Step: 9
Training loss: 3.3811219816952094
Validation loss: 2.69590595566792

Epoch: 6| Step: 10
Training loss: 3.0654158432408787
Validation loss: 2.691859564813542

Epoch: 6| Step: 11
Training loss: 3.556493815828157
Validation loss: 2.687644386085493

Epoch: 6| Step: 12
Training loss: 3.134373150080461
Validation loss: 2.685800077223881

Epoch: 6| Step: 13
Training loss: 2.3989539568904346
Validation loss: 2.656751836461746

Epoch: 99| Step: 0
Training loss: 2.3028506442961736
Validation loss: 2.672463760508605

Epoch: 6| Step: 1
Training loss: 3.1750703698717757
Validation loss: 2.7154275151598566

Epoch: 6| Step: 2
Training loss: 3.6129478836925286
Validation loss: 2.7067955854555206

Epoch: 6| Step: 3
Training loss: 2.7247429927753677
Validation loss: 2.65877427878851

Epoch: 6| Step: 4
Training loss: 2.7677187133487218
Validation loss: 2.646181349329175

Epoch: 6| Step: 5
Training loss: 2.836878260585191
Validation loss: 2.641793163701538

Epoch: 6| Step: 6
Training loss: 2.783039845813608
Validation loss: 2.6399166173731268

Epoch: 6| Step: 7
Training loss: 3.397442270761094
Validation loss: 2.6404733533591274

Epoch: 6| Step: 8
Training loss: 2.8628309033629633
Validation loss: 2.6368034637831284

Epoch: 6| Step: 9
Training loss: 2.949259978757764
Validation loss: 2.638248467107099

Epoch: 6| Step: 10
Training loss: 3.316782648049072
Validation loss: 2.637933063669698

Epoch: 6| Step: 11
Training loss: 2.994914990525787
Validation loss: 2.641242643197117

Epoch: 6| Step: 12
Training loss: 3.233594717360631
Validation loss: 2.6412083490593896

Epoch: 6| Step: 13
Training loss: 2.43986455228734
Validation loss: 2.6343951291695538

Epoch: 100| Step: 0
Training loss: 3.344886372778866
Validation loss: 2.6341720697329682

Epoch: 6| Step: 1
Training loss: 2.5208248632199406
Validation loss: 2.636804108386929

Epoch: 6| Step: 2
Training loss: 2.4840131772071126
Validation loss: 2.634554807206718

Epoch: 6| Step: 3
Training loss: 3.1308310466396203
Validation loss: 2.6365461269128727

Epoch: 6| Step: 4
Training loss: 3.331810285390216
Validation loss: 2.6391550385030715

Epoch: 6| Step: 5
Training loss: 3.1273044481745402
Validation loss: 2.6444319105358263

Epoch: 6| Step: 6
Training loss: 3.0933185623353405
Validation loss: 2.6495545512259855

Epoch: 6| Step: 7
Training loss: 3.051158534909546
Validation loss: 2.649690494816848

Epoch: 6| Step: 8
Training loss: 3.2146568568473044
Validation loss: 2.649383348920637

Epoch: 6| Step: 9
Training loss: 2.352427174720978
Validation loss: 2.6608585872891597

Epoch: 6| Step: 10
Training loss: 2.495372685976775
Validation loss: 2.670017210873539

Epoch: 6| Step: 11
Training loss: 3.7090224293729737
Validation loss: 2.67244603008032

Epoch: 6| Step: 12
Training loss: 3.0505127147540256
Validation loss: 2.6719675413267256

Epoch: 6| Step: 13
Training loss: 2.354464036732894
Validation loss: 2.652622454064953

Testing loss: 2.8537453147822616
