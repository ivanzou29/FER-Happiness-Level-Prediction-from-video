Epoch: 1| Step: 0
Training loss: 6.772243724549292
Validation loss: 5.78410786745682

Epoch: 5| Step: 1
Training loss: 6.5274024837460765
Validation loss: 5.768747968978541

Epoch: 5| Step: 2
Training loss: 3.893724424911933
Validation loss: 5.754243983190471

Epoch: 5| Step: 3
Training loss: 4.928190702340243
Validation loss: 5.738764950326642

Epoch: 5| Step: 4
Training loss: 5.06352110560808
Validation loss: 5.720858046354445

Epoch: 5| Step: 5
Training loss: 5.534634346811474
Validation loss: 5.7010699718840945

Epoch: 5| Step: 6
Training loss: 5.763892929300427
Validation loss: 5.677972070995854

Epoch: 5| Step: 7
Training loss: 5.4741583538684315
Validation loss: 5.652139200899722

Epoch: 5| Step: 8
Training loss: 6.6922641789837165
Validation loss: 5.621396842012247

Epoch: 5| Step: 9
Training loss: 4.945989722093516
Validation loss: 5.587989820786199

Epoch: 5| Step: 10
Training loss: 6.762599629851091
Validation loss: 5.549388844014233

Epoch: 2| Step: 0
Training loss: 5.194154630431125
Validation loss: 5.508313958735252

Epoch: 5| Step: 1
Training loss: 5.3331677689285275
Validation loss: 5.462067397758259

Epoch: 5| Step: 2
Training loss: 5.813181847398029
Validation loss: 5.414137860359218

Epoch: 5| Step: 3
Training loss: 5.614719915291666
Validation loss: 5.362589451624424

Epoch: 5| Step: 4
Training loss: 5.455989926706451
Validation loss: 5.308436102360181

Epoch: 5| Step: 5
Training loss: 5.776634889850212
Validation loss: 5.250721654793574

Epoch: 5| Step: 6
Training loss: 5.5923195826793854
Validation loss: 5.1888608446032585

Epoch: 5| Step: 7
Training loss: 5.150394328307352
Validation loss: 5.125354421442397

Epoch: 5| Step: 8
Training loss: 5.145550533456881
Validation loss: 5.060540003559808

Epoch: 5| Step: 9
Training loss: 4.033346414676187
Validation loss: 4.99315280707305

Epoch: 5| Step: 10
Training loss: 4.894762135727992
Validation loss: 4.927547939803185

Epoch: 3| Step: 0
Training loss: 5.524351484117241
Validation loss: 4.860103203762124

Epoch: 5| Step: 1
Training loss: 4.523019827368066
Validation loss: 4.7935156437775435

Epoch: 5| Step: 2
Training loss: 4.715544363334749
Validation loss: 4.72803137001805

Epoch: 5| Step: 3
Training loss: 3.6399442502877206
Validation loss: 4.670492798223021

Epoch: 5| Step: 4
Training loss: 4.914345446568942
Validation loss: 4.62089947238796

Epoch: 5| Step: 5
Training loss: 5.404504042040276
Validation loss: 4.57388350196628

Epoch: 5| Step: 6
Training loss: 5.638860622057459
Validation loss: 4.533199297523783

Epoch: 5| Step: 7
Training loss: 3.8926390065563194
Validation loss: 4.4955719270924215

Epoch: 5| Step: 8
Training loss: 4.726319563746441
Validation loss: 4.466415969493753

Epoch: 5| Step: 9
Training loss: 3.642289333810059
Validation loss: 4.4469011394386895

Epoch: 5| Step: 10
Training loss: 4.562420569995661
Validation loss: 4.433304475959777

Epoch: 4| Step: 0
Training loss: 4.198900333131088
Validation loss: 4.413752126857675

Epoch: 5| Step: 1
Training loss: 4.6225827060230555
Validation loss: 4.398476515978519

Epoch: 5| Step: 2
Training loss: 4.06275821745475
Validation loss: 4.380315743059855

Epoch: 5| Step: 3
Training loss: 4.918412216589801
Validation loss: 4.3649950282883

Epoch: 5| Step: 4
Training loss: 4.973243840480276
Validation loss: 4.348838997374508

Epoch: 5| Step: 5
Training loss: 4.555578965744614
Validation loss: 4.328422183456581

Epoch: 5| Step: 6
Training loss: 4.851183104001015
Validation loss: 4.311388968529922

Epoch: 5| Step: 7
Training loss: 2.6950702945409586
Validation loss: 4.300231102630466

Epoch: 5| Step: 8
Training loss: 4.617065634628004
Validation loss: 4.2911698451735605

Epoch: 5| Step: 9
Training loss: 4.4311456450104325
Validation loss: 4.2818176717137355

Epoch: 5| Step: 10
Training loss: 4.6946941863574
Validation loss: 4.2681612160783775

Epoch: 5| Step: 0
Training loss: 4.132417656366005
Validation loss: 4.2488631864033115

Epoch: 5| Step: 1
Training loss: 4.680072240027391
Validation loss: 4.225987939773815

Epoch: 5| Step: 2
Training loss: 3.966385384745752
Validation loss: 4.191682742267067

Epoch: 5| Step: 3
Training loss: 4.1086650278596855
Validation loss: 4.151529488998534

Epoch: 5| Step: 4
Training loss: 4.195492987417653
Validation loss: 4.130283751603034

Epoch: 5| Step: 5
Training loss: 2.945471316641981
Validation loss: 4.122231797284034

Epoch: 5| Step: 6
Training loss: 5.558774064571446
Validation loss: 4.114842868697062

Epoch: 5| Step: 7
Training loss: 3.198732220330863
Validation loss: 4.098559668674398

Epoch: 5| Step: 8
Training loss: 4.968059179878044
Validation loss: 4.0785902467734845

Epoch: 5| Step: 9
Training loss: 4.457704779028402
Validation loss: 4.055991965788482

Epoch: 5| Step: 10
Training loss: 4.106405483420104
Validation loss: 4.047235525174315

Epoch: 6| Step: 0
Training loss: 4.257233466576672
Validation loss: 4.027513279832905

Epoch: 5| Step: 1
Training loss: 4.774868564893878
Validation loss: 4.0093742678992985

Epoch: 5| Step: 2
Training loss: 3.7098685240776907
Validation loss: 3.9979646411190215

Epoch: 5| Step: 3
Training loss: 3.8494192354187935
Validation loss: 3.9874550483477447

Epoch: 5| Step: 4
Training loss: 4.683885325056672
Validation loss: 3.9837490232676958

Epoch: 5| Step: 5
Training loss: 3.6201019080976446
Validation loss: 3.973854539784712

Epoch: 5| Step: 6
Training loss: 4.552169601123467
Validation loss: 3.958953265276987

Epoch: 5| Step: 7
Training loss: 4.175708623813009
Validation loss: 3.951081817604536

Epoch: 5| Step: 8
Training loss: 3.7577487995672905
Validation loss: 3.9398689676694594

Epoch: 5| Step: 9
Training loss: 3.8152785885185123
Validation loss: 3.9303933523748023

Epoch: 5| Step: 10
Training loss: 3.972713503804797
Validation loss: 3.921411674927856

Epoch: 7| Step: 0
Training loss: 4.641922586304215
Validation loss: 3.9126127536397464

Epoch: 5| Step: 1
Training loss: 4.353590980449223
Validation loss: 3.8869545119588573

Epoch: 5| Step: 2
Training loss: 4.11881393359842
Validation loss: 3.8602087621414483

Epoch: 5| Step: 3
Training loss: 4.664384942594275
Validation loss: 3.854008411904409

Epoch: 5| Step: 4
Training loss: 4.191419446769765
Validation loss: 3.8438683975223746

Epoch: 5| Step: 5
Training loss: 4.494906828087594
Validation loss: 3.8398110808068293

Epoch: 5| Step: 6
Training loss: 4.279645855949269
Validation loss: 3.836823212838433

Epoch: 5| Step: 7
Training loss: 3.98838395034121
Validation loss: 3.826401617875431

Epoch: 5| Step: 8
Training loss: 3.3064489697761688
Validation loss: 3.81653381974794

Epoch: 5| Step: 9
Training loss: 2.433112279004743
Validation loss: 3.8087833160687175

Epoch: 5| Step: 10
Training loss: 2.9580060392760448
Validation loss: 3.8026406012784024

Epoch: 8| Step: 0
Training loss: 4.4680926499694404
Validation loss: 3.791869772783662

Epoch: 5| Step: 1
Training loss: 4.037105831593148
Validation loss: 3.7807572105645617

Epoch: 5| Step: 2
Training loss: 3.4740159212493182
Validation loss: 3.7705866741428444

Epoch: 5| Step: 3
Training loss: 3.564960901332207
Validation loss: 3.7615406977867227

Epoch: 5| Step: 4
Training loss: 3.804533342375523
Validation loss: 3.7518469128339897

Epoch: 5| Step: 5
Training loss: 4.45375072700865
Validation loss: 3.7471899161739963

Epoch: 5| Step: 6
Training loss: 3.648860669968473
Validation loss: 3.7439477365992686

Epoch: 5| Step: 7
Training loss: 3.5911654259043733
Validation loss: 3.7354954951152903

Epoch: 5| Step: 8
Training loss: 4.112997916553359
Validation loss: 3.734789546214317

Epoch: 5| Step: 9
Training loss: 4.556977365463931
Validation loss: 3.7326309882949484

Epoch: 5| Step: 10
Training loss: 3.2392835733920635
Validation loss: 3.725082577246168

Epoch: 9| Step: 0
Training loss: 3.8391190831723145
Validation loss: 3.709854816726807

Epoch: 5| Step: 1
Training loss: 3.7228980771400977
Validation loss: 3.7008451650016188

Epoch: 5| Step: 2
Training loss: 3.589772552680806
Validation loss: 3.688367283831867

Epoch: 5| Step: 3
Training loss: 4.083050906216918
Validation loss: 3.6811524910435462

Epoch: 5| Step: 4
Training loss: 3.7386404281471846
Validation loss: 3.674085401995272

Epoch: 5| Step: 5
Training loss: 3.860962081948253
Validation loss: 3.6645345324558676

Epoch: 5| Step: 6
Training loss: 3.460309456012868
Validation loss: 3.6557894433222824

Epoch: 5| Step: 7
Training loss: 4.021846716009957
Validation loss: 3.65115118995436

Epoch: 5| Step: 8
Training loss: 4.237371419120479
Validation loss: 3.6464458198380294

Epoch: 5| Step: 9
Training loss: 4.018149684367959
Validation loss: 3.6373868601523323

Epoch: 5| Step: 10
Training loss: 3.814263108106378
Validation loss: 3.629424645506981

Epoch: 10| Step: 0
Training loss: 3.4429674536778534
Validation loss: 3.617020983688079

Epoch: 5| Step: 1
Training loss: 3.435444165072127
Validation loss: 3.613233641909734

Epoch: 5| Step: 2
Training loss: 4.380331659867715
Validation loss: 3.611310468607794

Epoch: 5| Step: 3
Training loss: 3.764617278567551
Validation loss: 3.600855155609655

Epoch: 5| Step: 4
Training loss: 3.5350491502250483
Validation loss: 3.593463089071381

Epoch: 5| Step: 5
Training loss: 4.072807265013204
Validation loss: 3.5875222179880644

Epoch: 5| Step: 6
Training loss: 3.6492396255056136
Validation loss: 3.580499907223442

Epoch: 5| Step: 7
Training loss: 4.042820139931765
Validation loss: 3.571240291613346

Epoch: 5| Step: 8
Training loss: 3.113871175091924
Validation loss: 3.5606247061327734

Epoch: 5| Step: 9
Training loss: 4.597333898401189
Validation loss: 3.562718175868408

Epoch: 5| Step: 10
Training loss: 3.2882105070422494
Validation loss: 3.5502323915155505

Epoch: 11| Step: 0
Training loss: 3.422184899637173
Validation loss: 3.549903229234059

Epoch: 5| Step: 1
Training loss: 3.9878884774993604
Validation loss: 3.5527311739965524

Epoch: 5| Step: 2
Training loss: 3.764271599775962
Validation loss: 3.5481377123382902

Epoch: 5| Step: 3
Training loss: 4.146261503004116
Validation loss: 3.5334057062665525

Epoch: 5| Step: 4
Training loss: 3.297334033413247
Validation loss: 3.5222916912468536

Epoch: 5| Step: 5
Training loss: 2.7300585000613675
Validation loss: 3.5134201796437465

Epoch: 5| Step: 6
Training loss: 3.9806307084936106
Validation loss: 3.507471147236024

Epoch: 5| Step: 7
Training loss: 4.099937829267344
Validation loss: 3.5008103447784396

Epoch: 5| Step: 8
Training loss: 3.332750142261221
Validation loss: 3.493415385591237

Epoch: 5| Step: 9
Training loss: 3.0933304319148873
Validation loss: 3.4842595995880288

Epoch: 5| Step: 10
Training loss: 4.886958396152218
Validation loss: 3.4716655950082984

Epoch: 12| Step: 0
Training loss: 4.145747402712762
Validation loss: 3.461958483464176

Epoch: 5| Step: 1
Training loss: 3.7391844867043336
Validation loss: 3.457067121177459

Epoch: 5| Step: 2
Training loss: 3.522810582045628
Validation loss: 3.454279974315214

Epoch: 5| Step: 3
Training loss: 3.1824117701332457
Validation loss: 3.442531162202271

Epoch: 5| Step: 4
Training loss: 3.491855409265789
Validation loss: 3.428699880522746

Epoch: 5| Step: 5
Training loss: 4.575565599176583
Validation loss: 3.4159981193322126

Epoch: 5| Step: 6
Training loss: 3.244892214732177
Validation loss: 3.4130070042823832

Epoch: 5| Step: 7
Training loss: 3.0712755551670385
Validation loss: 3.412228011147178

Epoch: 5| Step: 8
Training loss: 3.121065333001892
Validation loss: 3.3889077506192447

Epoch: 5| Step: 9
Training loss: 3.6548639262240483
Validation loss: 3.382689542292304

Epoch: 5| Step: 10
Training loss: 4.153029032704247
Validation loss: 3.377700309546677

Epoch: 13| Step: 0
Training loss: 4.265341054108256
Validation loss: 3.3667152320464155

Epoch: 5| Step: 1
Training loss: 3.4174377377690908
Validation loss: 3.3685893904989355

Epoch: 5| Step: 2
Training loss: 3.754092462944528
Validation loss: 3.3555954555133236

Epoch: 5| Step: 3
Training loss: 2.6576814272684484
Validation loss: 3.3459533142326565

Epoch: 5| Step: 4
Training loss: 3.2642674887107526
Validation loss: 3.336809295370722

Epoch: 5| Step: 5
Training loss: 3.7174244289246317
Validation loss: 3.33357655396701

Epoch: 5| Step: 6
Training loss: 3.479204524095041
Validation loss: 3.32789431460975

Epoch: 5| Step: 7
Training loss: 3.8231253224875212
Validation loss: 3.3292829883158377

Epoch: 5| Step: 8
Training loss: 3.912953964075681
Validation loss: 3.3217441093348947

Epoch: 5| Step: 9
Training loss: 3.2340798358487617
Validation loss: 3.307449062414252

Epoch: 5| Step: 10
Training loss: 3.5432801703851653
Validation loss: 3.2998294194577626

Epoch: 14| Step: 0
Training loss: 3.61434026921443
Validation loss: 3.3108232789394525

Epoch: 5| Step: 1
Training loss: 2.6628947901067157
Validation loss: 3.2825223613193817

Epoch: 5| Step: 2
Training loss: 3.0062771928790606
Validation loss: 3.287679662387897

Epoch: 5| Step: 3
Training loss: 4.131645860043838
Validation loss: 3.287112202942695

Epoch: 5| Step: 4
Training loss: 3.8575420274008763
Validation loss: 3.2852769711740724

Epoch: 5| Step: 5
Training loss: 3.730682462791975
Validation loss: 3.270708571725281

Epoch: 5| Step: 6
Training loss: 3.7948011221058016
Validation loss: 3.2579881013802923

Epoch: 5| Step: 7
Training loss: 3.7821697030889383
Validation loss: 3.266196974332896

Epoch: 5| Step: 8
Training loss: 3.006162830127915
Validation loss: 3.2472184459702063

Epoch: 5| Step: 9
Training loss: 3.793494961004303
Validation loss: 3.239264813468082

Epoch: 5| Step: 10
Training loss: 2.8884878145066186
Validation loss: 3.2341438263551976

Epoch: 15| Step: 0
Training loss: 3.132002347611562
Validation loss: 3.228023186602579

Epoch: 5| Step: 1
Training loss: 3.64319726013362
Validation loss: 3.2216260234943075

Epoch: 5| Step: 2
Training loss: 3.8754087663211867
Validation loss: 3.2145909057559474

Epoch: 5| Step: 3
Training loss: 3.939327118824849
Validation loss: 3.2036695288119668

Epoch: 5| Step: 4
Training loss: 3.0206945628596484
Validation loss: 3.2010596507042024

Epoch: 5| Step: 5
Training loss: 3.406944554062776
Validation loss: 3.190228906854242

Epoch: 5| Step: 6
Training loss: 3.6337161017097506
Validation loss: 3.184093834218602

Epoch: 5| Step: 7
Training loss: 3.4722893331188036
Validation loss: 3.1797826238297686

Epoch: 5| Step: 8
Training loss: 3.1120613800212906
Validation loss: 3.1792657407226437

Epoch: 5| Step: 9
Training loss: 3.417160618750008
Validation loss: 3.187991466913311

Epoch: 5| Step: 10
Training loss: 3.222690873393553
Validation loss: 3.1735610008943436

Epoch: 16| Step: 0
Training loss: 3.8909207273793807
Validation loss: 3.1549381635511238

Epoch: 5| Step: 1
Training loss: 3.222023197765416
Validation loss: 3.1482074343767543

Epoch: 5| Step: 2
Training loss: 3.1650785345425123
Validation loss: 3.1401794930629823

Epoch: 5| Step: 3
Training loss: 3.8185654216305447
Validation loss: 3.137644658522503

Epoch: 5| Step: 4
Training loss: 3.198419454772465
Validation loss: 3.1310430679126613

Epoch: 5| Step: 5
Training loss: 3.0607748038033065
Validation loss: 3.122877639837174

Epoch: 5| Step: 6
Training loss: 3.5863728310952507
Validation loss: 3.1218183461463505

Epoch: 5| Step: 7
Training loss: 3.9295257474398206
Validation loss: 3.1144529982030327

Epoch: 5| Step: 8
Training loss: 2.784481871124123
Validation loss: 3.1139818555200143

Epoch: 5| Step: 9
Training loss: 3.5396636384981632
Validation loss: 3.1045978315799068

Epoch: 5| Step: 10
Training loss: 2.8563000764359385
Validation loss: 3.1015580960626288

Epoch: 17| Step: 0
Training loss: 3.6716156563582656
Validation loss: 3.092626502518859

Epoch: 5| Step: 1
Training loss: 3.559753563955824
Validation loss: 3.086911107627411

Epoch: 5| Step: 2
Training loss: 2.9605983247978607
Validation loss: 3.0896280248470056

Epoch: 5| Step: 3
Training loss: 3.1641218768541317
Validation loss: 3.100279496209984

Epoch: 5| Step: 4
Training loss: 3.0519476503454674
Validation loss: 3.075873628121692

Epoch: 5| Step: 5
Training loss: 3.028325193733973
Validation loss: 3.069645160534393

Epoch: 5| Step: 6
Training loss: 3.306230045251174
Validation loss: 3.070163888848639

Epoch: 5| Step: 7
Training loss: 3.4894315012833306
Validation loss: 3.062875922584212

Epoch: 5| Step: 8
Training loss: 3.8668199152558222
Validation loss: 3.0611819004200203

Epoch: 5| Step: 9
Training loss: 3.615095880906814
Validation loss: 3.0535932039588256

Epoch: 5| Step: 10
Training loss: 3.0274508549601955
Validation loss: 3.0495033482128857

Epoch: 18| Step: 0
Training loss: 2.792240159830178
Validation loss: 3.0432832652689887

Epoch: 5| Step: 1
Training loss: 4.483449807243554
Validation loss: 3.0429478092424276

Epoch: 5| Step: 2
Training loss: 3.222277587838822
Validation loss: 3.035595671991535

Epoch: 5| Step: 3
Training loss: 3.0930708322736344
Validation loss: 3.0327707477746357

Epoch: 5| Step: 4
Training loss: 3.116413374075274
Validation loss: 3.0285864730304075

Epoch: 5| Step: 5
Training loss: 3.0514556100370944
Validation loss: 3.029694168379727

Epoch: 5| Step: 6
Training loss: 3.3362460920554664
Validation loss: 3.0302952509348584

Epoch: 5| Step: 7
Training loss: 3.656678133946268
Validation loss: 3.029298779134806

Epoch: 5| Step: 8
Training loss: 3.4460974251142273
Validation loss: 3.030568244839867

Epoch: 5| Step: 9
Training loss: 2.874404182061992
Validation loss: 3.014521918244646

Epoch: 5| Step: 10
Training loss: 3.0746175078404536
Validation loss: 3.0075540905439895

Epoch: 19| Step: 0
Training loss: 3.158583882911097
Validation loss: 3.0045007985438708

Epoch: 5| Step: 1
Training loss: 3.2471168640929986
Validation loss: 2.9989805848094786

Epoch: 5| Step: 2
Training loss: 3.0212186019585396
Validation loss: 3.0025305398192503

Epoch: 5| Step: 3
Training loss: 3.4848782984145577
Validation loss: 3.0018461052233825

Epoch: 5| Step: 4
Training loss: 3.4419242824048446
Validation loss: 2.994901106209328

Epoch: 5| Step: 5
Training loss: 2.817159903714325
Validation loss: 2.99102590328479

Epoch: 5| Step: 6
Training loss: 2.8585272194041997
Validation loss: 2.9913897709749095

Epoch: 5| Step: 7
Training loss: 2.8500815530452437
Validation loss: 2.987962575359046

Epoch: 5| Step: 8
Training loss: 3.353475242731528
Validation loss: 2.9869623293248635

Epoch: 5| Step: 9
Training loss: 3.892260716996577
Validation loss: 2.9770815765461327

Epoch: 5| Step: 10
Training loss: 3.878921247532059
Validation loss: 2.973621228977474

Epoch: 20| Step: 0
Training loss: 3.1867851502911537
Validation loss: 2.96989365004555

Epoch: 5| Step: 1
Training loss: 3.3406935653572942
Validation loss: 2.9803567120541885

Epoch: 5| Step: 2
Training loss: 3.4478080863028886
Validation loss: 2.977988699424963

Epoch: 5| Step: 3
Training loss: 2.6381031160366506
Validation loss: 2.9688091278664563

Epoch: 5| Step: 4
Training loss: 3.331548228700688
Validation loss: 2.964075089622405

Epoch: 5| Step: 5
Training loss: 3.0470399469574554
Validation loss: 2.964006446147787

Epoch: 5| Step: 6
Training loss: 3.2067807061371405
Validation loss: 2.9645891582996273

Epoch: 5| Step: 7
Training loss: 3.081320406281533
Validation loss: 2.960409359485864

Epoch: 5| Step: 8
Training loss: 3.4582237471410853
Validation loss: 2.960386045613836

Epoch: 5| Step: 9
Training loss: 3.631445055136669
Validation loss: 2.9528076675032016

Epoch: 5| Step: 10
Training loss: 3.4272897459131473
Validation loss: 2.9460306030682863

Epoch: 21| Step: 0
Training loss: 3.265011816543764
Validation loss: 2.947294482570428

Epoch: 5| Step: 1
Training loss: 3.3161665579330624
Validation loss: 2.9493691804601747

Epoch: 5| Step: 2
Training loss: 2.771925995195282
Validation loss: 2.9475565867651894

Epoch: 5| Step: 3
Training loss: 2.95879534126999
Validation loss: 2.9391920077379754

Epoch: 5| Step: 4
Training loss: 3.221999666778718
Validation loss: 2.9319895784317938

Epoch: 5| Step: 5
Training loss: 3.0855929025360207
Validation loss: 2.931527471254126

Epoch: 5| Step: 6
Training loss: 3.5682548754026753
Validation loss: 2.9298319419338124

Epoch: 5| Step: 7
Training loss: 3.413651710081405
Validation loss: 2.9236062863801098

Epoch: 5| Step: 8
Training loss: 2.862046291592735
Validation loss: 2.9209302202037155

Epoch: 5| Step: 9
Training loss: 3.5359096335519533
Validation loss: 2.922958142553468

Epoch: 5| Step: 10
Training loss: 3.490387249860923
Validation loss: 2.9226163842958095

Epoch: 22| Step: 0
Training loss: 3.076238528543759
Validation loss: 2.91180629934002

Epoch: 5| Step: 1
Training loss: 2.9756551646238245
Validation loss: 2.9077938679478863

Epoch: 5| Step: 2
Training loss: 2.719681065177121
Validation loss: 2.9047233055035075

Epoch: 5| Step: 3
Training loss: 3.6132766311203586
Validation loss: 2.9072962278219636

Epoch: 5| Step: 4
Training loss: 3.135316376122408
Validation loss: 2.9048548982146865

Epoch: 5| Step: 5
Training loss: 3.2505458960198284
Validation loss: 2.901636955814184

Epoch: 5| Step: 6
Training loss: 3.0220455149183776
Validation loss: 2.891098165545396

Epoch: 5| Step: 7
Training loss: 3.809647540512714
Validation loss: 2.8910379147577285

Epoch: 5| Step: 8
Training loss: 3.2730690833008795
Validation loss: 2.888035257518479

Epoch: 5| Step: 9
Training loss: 3.3262403999657417
Validation loss: 2.881750411441822

Epoch: 5| Step: 10
Training loss: 2.8345323344411995
Validation loss: 2.8852560524984248

Epoch: 23| Step: 0
Training loss: 3.1145661692747075
Validation loss: 2.8987880767081915

Epoch: 5| Step: 1
Training loss: 3.44046918774337
Validation loss: 2.8858722072324734

Epoch: 5| Step: 2
Training loss: 3.052862456326209
Validation loss: 2.889640035885535

Epoch: 5| Step: 3
Training loss: 3.106519144782374
Validation loss: 2.896900973188249

Epoch: 5| Step: 4
Training loss: 3.408958268330624
Validation loss: 2.8911286531395683

Epoch: 5| Step: 5
Training loss: 2.914839817311321
Validation loss: 2.8907709361461467

Epoch: 5| Step: 6
Training loss: 2.6814371963990546
Validation loss: 2.8783028424766957

Epoch: 5| Step: 7
Training loss: 3.361000413008769
Validation loss: 2.8923649184032176

Epoch: 5| Step: 8
Training loss: 3.7969627841173486
Validation loss: 2.8955100011721315

Epoch: 5| Step: 9
Training loss: 2.9270434031811767
Validation loss: 2.8675148673012365

Epoch: 5| Step: 10
Training loss: 3.228247398869942
Validation loss: 2.8630592042859417

Epoch: 24| Step: 0
Training loss: 3.94481101295328
Validation loss: 2.8704849348832315

Epoch: 5| Step: 1
Training loss: 2.8395908668140124
Validation loss: 2.864333117045624

Epoch: 5| Step: 2
Training loss: 2.48948020136205
Validation loss: 2.861273579222986

Epoch: 5| Step: 3
Training loss: 3.4946842698235208
Validation loss: 2.8600348828459716

Epoch: 5| Step: 4
Training loss: 2.7570899254513166
Validation loss: 2.853843708118332

Epoch: 5| Step: 5
Training loss: 3.1455279743125186
Validation loss: 2.851083494268604

Epoch: 5| Step: 6
Training loss: 3.029561624572928
Validation loss: 2.8450186792259267

Epoch: 5| Step: 7
Training loss: 3.0359503101308323
Validation loss: 2.840882326792425

Epoch: 5| Step: 8
Training loss: 3.165272422504419
Validation loss: 2.842183120122443

Epoch: 5| Step: 9
Training loss: 3.2101066609663103
Validation loss: 2.850661354998194

Epoch: 5| Step: 10
Training loss: 3.6165347735941547
Validation loss: 2.900305994359098

Epoch: 25| Step: 0
Training loss: 3.0746055660192706
Validation loss: 2.8475679273913186

Epoch: 5| Step: 1
Training loss: 2.743262099418493
Validation loss: 2.828672099718781

Epoch: 5| Step: 2
Training loss: 3.1330210171605497
Validation loss: 2.8278238565282776

Epoch: 5| Step: 3
Training loss: 3.398923361237197
Validation loss: 2.8277734032438255

Epoch: 5| Step: 4
Training loss: 3.231561588928726
Validation loss: 2.833051972169247

Epoch: 5| Step: 5
Training loss: 3.060224193513114
Validation loss: 2.8251555272678224

Epoch: 5| Step: 6
Training loss: 3.518280111753921
Validation loss: 2.8240937358610254

Epoch: 5| Step: 7
Training loss: 3.3062480731807065
Validation loss: 2.8175854536239267

Epoch: 5| Step: 8
Training loss: 2.7638031729522274
Validation loss: 2.825424004106256

Epoch: 5| Step: 9
Training loss: 3.2027602569580202
Validation loss: 2.8286464729128378

Epoch: 5| Step: 10
Training loss: 3.0500021512383553
Validation loss: 2.831891288877321

Epoch: 26| Step: 0
Training loss: 2.8412998249805614
Validation loss: 2.84617116459692

Epoch: 5| Step: 1
Training loss: 2.9071835894959692
Validation loss: 2.8749745525216546

Epoch: 5| Step: 2
Training loss: 2.826316044207439
Validation loss: 2.8840668288800275

Epoch: 5| Step: 3
Training loss: 3.3172374892275234
Validation loss: 2.847871434525813

Epoch: 5| Step: 4
Training loss: 2.576410081564313
Validation loss: 2.8043852749601483

Epoch: 5| Step: 5
Training loss: 3.0981058609805903
Validation loss: 2.8085750488104075

Epoch: 5| Step: 6
Training loss: 3.245222982495305
Validation loss: 2.821509621603557

Epoch: 5| Step: 7
Training loss: 3.4123178733879658
Validation loss: 2.830593136465718

Epoch: 5| Step: 8
Training loss: 3.380669811626705
Validation loss: 2.8358643342496657

Epoch: 5| Step: 9
Training loss: 3.4759755528493503
Validation loss: 2.827305061838582

Epoch: 5| Step: 10
Training loss: 3.410541595675103
Validation loss: 2.8138249948463785

Epoch: 27| Step: 0
Training loss: 2.809230939080248
Validation loss: 2.804047039440991

Epoch: 5| Step: 1
Training loss: 3.1412185943041515
Validation loss: 2.799985733541571

Epoch: 5| Step: 2
Training loss: 2.9586204783458956
Validation loss: 2.798701242056636

Epoch: 5| Step: 3
Training loss: 3.871410430057312
Validation loss: 2.8091063685921402

Epoch: 5| Step: 4
Training loss: 3.7463663934771256
Validation loss: 2.8237910821075682

Epoch: 5| Step: 5
Training loss: 2.9547663572733156
Validation loss: 2.8145294615186502

Epoch: 5| Step: 6
Training loss: 3.338256887270684
Validation loss: 2.80343912113954

Epoch: 5| Step: 7
Training loss: 3.364301183501279
Validation loss: 2.845655010326558

Epoch: 5| Step: 8
Training loss: 2.457881325584443
Validation loss: 2.7848261753940036

Epoch: 5| Step: 9
Training loss: 3.0176397521012865
Validation loss: 2.7861670434500163

Epoch: 5| Step: 10
Training loss: 2.218629753185504
Validation loss: 2.789478919279445

Epoch: 28| Step: 0
Training loss: 3.0727515397183205
Validation loss: 2.793809247306883

Epoch: 5| Step: 1
Training loss: 3.018235099902944
Validation loss: 2.8021490605724972

Epoch: 5| Step: 2
Training loss: 2.551940187345228
Validation loss: 2.810174762445758

Epoch: 5| Step: 3
Training loss: 3.0218167162287477
Validation loss: 2.82172433248352

Epoch: 5| Step: 4
Training loss: 3.542617729992805
Validation loss: 2.8115144887539567

Epoch: 5| Step: 5
Training loss: 3.3076891242269575
Validation loss: 2.795152738993701

Epoch: 5| Step: 6
Training loss: 3.2722948214888397
Validation loss: 2.7914858982832436

Epoch: 5| Step: 7
Training loss: 2.8935083803352484
Validation loss: 2.785238281610429

Epoch: 5| Step: 8
Training loss: 3.8042623607441954
Validation loss: 2.781410965703824

Epoch: 5| Step: 9
Training loss: 2.918894343921856
Validation loss: 2.780407123295152

Epoch: 5| Step: 10
Training loss: 2.665913405921564
Validation loss: 2.777150018028301

Epoch: 29| Step: 0
Training loss: 3.0532558823081173
Validation loss: 2.7770682432289058

Epoch: 5| Step: 1
Training loss: 3.153474248139534
Validation loss: 2.7819630509704156

Epoch: 5| Step: 2
Training loss: 3.5300828473362516
Validation loss: 2.783918007368494

Epoch: 5| Step: 3
Training loss: 2.675490403901159
Validation loss: 2.789277556943538

Epoch: 5| Step: 4
Training loss: 3.418152478320894
Validation loss: 2.8080827432208295

Epoch: 5| Step: 5
Training loss: 2.8142703948043124
Validation loss: 2.781152793344207

Epoch: 5| Step: 6
Training loss: 2.9551108812935847
Validation loss: 2.782180969527913

Epoch: 5| Step: 7
Training loss: 3.095352374402034
Validation loss: 2.793052528318666

Epoch: 5| Step: 8
Training loss: 3.126185535618894
Validation loss: 2.81173726156768

Epoch: 5| Step: 9
Training loss: 3.061087925064085
Validation loss: 2.816491501131921

Epoch: 5| Step: 10
Training loss: 3.4482177111227736
Validation loss: 2.8282486734388916

Epoch: 30| Step: 0
Training loss: 3.271574450718901
Validation loss: 2.807629799235349

Epoch: 5| Step: 1
Training loss: 2.862139423431814
Validation loss: 2.792906141794892

Epoch: 5| Step: 2
Training loss: 3.3092854575055646
Validation loss: 2.775978435967613

Epoch: 5| Step: 3
Training loss: 3.1423869338593304
Validation loss: 2.7700966910496527

Epoch: 5| Step: 4
Training loss: 3.390972488809197
Validation loss: 2.7658689444731066

Epoch: 5| Step: 5
Training loss: 3.2525098352774675
Validation loss: 2.766298151312938

Epoch: 5| Step: 6
Training loss: 2.949812065215812
Validation loss: 2.7659974929299582

Epoch: 5| Step: 7
Training loss: 2.9130162055851088
Validation loss: 2.765225752835644

Epoch: 5| Step: 8
Training loss: 3.363746531132809
Validation loss: 2.7733587974555824

Epoch: 5| Step: 9
Training loss: 2.980314838240111
Validation loss: 2.7926366520099273

Epoch: 5| Step: 10
Training loss: 2.5608416517846506
Validation loss: 2.7926278006392473

Epoch: 31| Step: 0
Training loss: 3.275002917805311
Validation loss: 2.775368686009198

Epoch: 5| Step: 1
Training loss: 3.0814084582951717
Validation loss: 2.765581985657301

Epoch: 5| Step: 2
Training loss: 3.138156357156292
Validation loss: 2.7629864133559927

Epoch: 5| Step: 3
Training loss: 2.6331471759650977
Validation loss: 2.77059412616148

Epoch: 5| Step: 4
Training loss: 3.1215010318781893
Validation loss: 2.7685875116283967

Epoch: 5| Step: 5
Training loss: 3.427269989465154
Validation loss: 2.7738337204728727

Epoch: 5| Step: 6
Training loss: 3.5491868605662087
Validation loss: 2.770799902332545

Epoch: 5| Step: 7
Training loss: 2.80064623732071
Validation loss: 2.7641055910772745

Epoch: 5| Step: 8
Training loss: 2.8834813280289846
Validation loss: 2.7649542892832266

Epoch: 5| Step: 9
Training loss: 2.8111449474146215
Validation loss: 2.7674716433951794

Epoch: 5| Step: 10
Training loss: 3.3773651312972572
Validation loss: 2.771850864183098

Epoch: 32| Step: 0
Training loss: 2.7156482410204603
Validation loss: 2.7768150901688564

Epoch: 5| Step: 1
Training loss: 2.843592880435863
Validation loss: 2.779810043358462

Epoch: 5| Step: 2
Training loss: 3.732561636822715
Validation loss: 2.7847560819510964

Epoch: 5| Step: 3
Training loss: 2.6126315873148203
Validation loss: 2.7682643323963023

Epoch: 5| Step: 4
Training loss: 2.957778251760005
Validation loss: 2.7647380033321705

Epoch: 5| Step: 5
Training loss: 3.265998052434113
Validation loss: 2.7626876801080895

Epoch: 5| Step: 6
Training loss: 3.0610273284739002
Validation loss: 2.757950847717887

Epoch: 5| Step: 7
Training loss: 3.4317253853540493
Validation loss: 2.75721408454631

Epoch: 5| Step: 8
Training loss: 2.7715802918733092
Validation loss: 2.7502072518150076

Epoch: 5| Step: 9
Training loss: 2.942328198391672
Validation loss: 2.7454035045276823

Epoch: 5| Step: 10
Training loss: 3.4706242626978723
Validation loss: 2.745770244336392

Epoch: 33| Step: 0
Training loss: 3.1988876972621005
Validation loss: 2.746739693148856

Epoch: 5| Step: 1
Training loss: 2.913683828341381
Validation loss: 2.7635678069280925

Epoch: 5| Step: 2
Training loss: 3.6781473034334002
Validation loss: 2.7483822099580695

Epoch: 5| Step: 3
Training loss: 2.509997975322013
Validation loss: 2.7424832698064825

Epoch: 5| Step: 4
Training loss: 3.4283071881603027
Validation loss: 2.740314719306378

Epoch: 5| Step: 5
Training loss: 3.2595154773141646
Validation loss: 2.738818991514785

Epoch: 5| Step: 6
Training loss: 3.182959070889924
Validation loss: 2.7381374592940726

Epoch: 5| Step: 7
Training loss: 2.2179183475885274
Validation loss: 2.7417047622202824

Epoch: 5| Step: 8
Training loss: 3.0869939227154037
Validation loss: 2.7434767135010745

Epoch: 5| Step: 9
Training loss: 3.4095076635688284
Validation loss: 2.7428494598015667

Epoch: 5| Step: 10
Training loss: 2.5361905331923107
Validation loss: 2.7457767314611363

Epoch: 34| Step: 0
Training loss: 3.102999644902437
Validation loss: 2.745929804670838

Epoch: 5| Step: 1
Training loss: 3.5178737653819527
Validation loss: 2.7450903753542653

Epoch: 5| Step: 2
Training loss: 3.1314765954785266
Validation loss: 2.7434653365539687

Epoch: 5| Step: 3
Training loss: 2.7351671215932005
Validation loss: 2.7424770955243476

Epoch: 5| Step: 4
Training loss: 2.8060626640745454
Validation loss: 2.7391285613392076

Epoch: 5| Step: 5
Training loss: 3.0478686155302332
Validation loss: 2.7382434806496896

Epoch: 5| Step: 6
Training loss: 2.896619694559026
Validation loss: 2.7375943378775496

Epoch: 5| Step: 7
Training loss: 2.2950927670747343
Validation loss: 2.7376910937616725

Epoch: 5| Step: 8
Training loss: 3.5993752944185746
Validation loss: 2.7346813905693477

Epoch: 5| Step: 9
Training loss: 3.1194151755734048
Validation loss: 2.736728326113532

Epoch: 5| Step: 10
Training loss: 3.350719852823344
Validation loss: 2.740303593051514

Epoch: 35| Step: 0
Training loss: 2.791893897606416
Validation loss: 2.7318393042519693

Epoch: 5| Step: 1
Training loss: 3.2268884969809917
Validation loss: 2.7318458591793866

Epoch: 5| Step: 2
Training loss: 2.851080030620575
Validation loss: 2.7327444645244436

Epoch: 5| Step: 3
Training loss: 3.234237299397414
Validation loss: 2.734721258363308

Epoch: 5| Step: 4
Training loss: 3.005270460909116
Validation loss: 2.7313866965715943

Epoch: 5| Step: 5
Training loss: 3.1955548406726013
Validation loss: 2.7353382585547896

Epoch: 5| Step: 6
Training loss: 3.2088931367317093
Validation loss: 2.7302698111638537

Epoch: 5| Step: 7
Training loss: 2.6329217090086523
Validation loss: 2.727827506499033

Epoch: 5| Step: 8
Training loss: 2.6922166819438256
Validation loss: 2.7269127390425614

Epoch: 5| Step: 9
Training loss: 3.3051264045308097
Validation loss: 2.728629929223457

Epoch: 5| Step: 10
Training loss: 3.473653403439111
Validation loss: 2.7471023742653267

Epoch: 36| Step: 0
Training loss: 3.084615921768326
Validation loss: 2.7658522002566617

Epoch: 5| Step: 1
Training loss: 2.963096777446226
Validation loss: 2.736454405596507

Epoch: 5| Step: 2
Training loss: 2.6908815091064535
Validation loss: 2.7235865163415216

Epoch: 5| Step: 3
Training loss: 3.3711967231520923
Validation loss: 2.722402759772813

Epoch: 5| Step: 4
Training loss: 2.902731786076594
Validation loss: 2.7231743945494236

Epoch: 5| Step: 5
Training loss: 3.2023034507596355
Validation loss: 2.7237767383103137

Epoch: 5| Step: 6
Training loss: 3.0511957294868304
Validation loss: 2.7238696631387374

Epoch: 5| Step: 7
Training loss: 3.2326487481749617
Validation loss: 2.7237417298513265

Epoch: 5| Step: 8
Training loss: 3.2576981851477798
Validation loss: 2.7230166406241745

Epoch: 5| Step: 9
Training loss: 2.797019144957632
Validation loss: 2.722825440964391

Epoch: 5| Step: 10
Training loss: 3.045784623104023
Validation loss: 2.7222344729787067

Epoch: 37| Step: 0
Training loss: 3.1333486806885933
Validation loss: 2.7213361069581015

Epoch: 5| Step: 1
Training loss: 2.826921322780606
Validation loss: 2.723340882690142

Epoch: 5| Step: 2
Training loss: 3.3705208336854433
Validation loss: 2.722177996167009

Epoch: 5| Step: 3
Training loss: 3.59606354920582
Validation loss: 2.719588921034103

Epoch: 5| Step: 4
Training loss: 3.337027807086137
Validation loss: 2.71951405226712

Epoch: 5| Step: 5
Training loss: 3.0614625380206926
Validation loss: 2.7201726819338616

Epoch: 5| Step: 6
Training loss: 2.992135229226859
Validation loss: 2.718968796686576

Epoch: 5| Step: 7
Training loss: 3.3165671373574095
Validation loss: 2.719457590604032

Epoch: 5| Step: 8
Training loss: 2.665068763575792
Validation loss: 2.7184899752350034

Epoch: 5| Step: 9
Training loss: 2.7162325373727705
Validation loss: 2.717153674371323

Epoch: 5| Step: 10
Training loss: 2.299155938719272
Validation loss: 2.7167978507092867

Epoch: 38| Step: 0
Training loss: 3.4457772216164444
Validation loss: 2.715029396856282

Epoch: 5| Step: 1
Training loss: 3.2846426726788134
Validation loss: 2.7121698478670058

Epoch: 5| Step: 2
Training loss: 2.957321979134001
Validation loss: 2.714354212125842

Epoch: 5| Step: 3
Training loss: 3.5261327073455435
Validation loss: 2.7139275855297

Epoch: 5| Step: 4
Training loss: 2.955632835308425
Validation loss: 2.7177868444065423

Epoch: 5| Step: 5
Training loss: 2.467437781696424
Validation loss: 2.7200058980801822

Epoch: 5| Step: 6
Training loss: 2.689982576136547
Validation loss: 2.7464531644462356

Epoch: 5| Step: 7
Training loss: 2.989368674694071
Validation loss: 2.728155280453332

Epoch: 5| Step: 8
Training loss: 2.9935995808762663
Validation loss: 2.711967917140478

Epoch: 5| Step: 9
Training loss: 2.935375013161948
Validation loss: 2.7113885100374513

Epoch: 5| Step: 10
Training loss: 3.048498415668283
Validation loss: 2.718213315162861

Epoch: 39| Step: 0
Training loss: 2.811029600847277
Validation loss: 2.728236358226322

Epoch: 5| Step: 1
Training loss: 2.9739695391246213
Validation loss: 2.74441131411657

Epoch: 5| Step: 2
Training loss: 3.1859005673799574
Validation loss: 2.7739909392711635

Epoch: 5| Step: 3
Training loss: 2.958367754955352
Validation loss: 2.7541814925584838

Epoch: 5| Step: 4
Training loss: 3.5478210531907988
Validation loss: 2.7454882487377996

Epoch: 5| Step: 5
Training loss: 3.1608738031536294
Validation loss: 2.713145603958979

Epoch: 5| Step: 6
Training loss: 3.0430347205320825
Validation loss: 2.711930028995203

Epoch: 5| Step: 7
Training loss: 3.1906259206084924
Validation loss: 2.7103973027297017

Epoch: 5| Step: 8
Training loss: 2.587764037293107
Validation loss: 2.719190543218385

Epoch: 5| Step: 9
Training loss: 2.863528044552467
Validation loss: 2.7576353084812193

Epoch: 5| Step: 10
Training loss: 3.3306034512788236
Validation loss: 2.8161075858030946

Epoch: 40| Step: 0
Training loss: 2.8022400955159927
Validation loss: 2.7891327646413195

Epoch: 5| Step: 1
Training loss: 3.607084001333457
Validation loss: 2.7282429312069176

Epoch: 5| Step: 2
Training loss: 2.9428904969313265
Validation loss: 2.7015767839356233

Epoch: 5| Step: 3
Training loss: 2.6096283566946266
Validation loss: 2.696149948776761

Epoch: 5| Step: 4
Training loss: 3.3961915059364833
Validation loss: 2.6993713796392487

Epoch: 5| Step: 5
Training loss: 3.3781964741784716
Validation loss: 2.713269598892791

Epoch: 5| Step: 6
Training loss: 2.6114610568259216
Validation loss: 2.7398560393442875

Epoch: 5| Step: 7
Training loss: 2.968778429397183
Validation loss: 2.790135535067364

Epoch: 5| Step: 8
Training loss: 3.155556630938829
Validation loss: 2.83465880914444

Epoch: 5| Step: 9
Training loss: 3.412653512261533
Validation loss: 2.8438324626157185

Epoch: 5| Step: 10
Training loss: 2.797973331910575
Validation loss: 2.7610781672032423

Epoch: 41| Step: 0
Training loss: 3.1514440526533853
Validation loss: 2.7243993148838648

Epoch: 5| Step: 1
Training loss: 3.4042271198210607
Validation loss: 2.7058010887450297

Epoch: 5| Step: 2
Training loss: 2.9687491969057302
Validation loss: 2.7090726393949436

Epoch: 5| Step: 3
Training loss: 3.6786863094808737
Validation loss: 2.7243940716659236

Epoch: 5| Step: 4
Training loss: 2.3157386782770017
Validation loss: 2.747990256987264

Epoch: 5| Step: 5
Training loss: 3.071311264079135
Validation loss: 2.830493731591401

Epoch: 5| Step: 6
Training loss: 2.8986633706318288
Validation loss: 2.7787186036000042

Epoch: 5| Step: 7
Training loss: 2.841602562622255
Validation loss: 2.755485295728562

Epoch: 5| Step: 8
Training loss: 3.0092785717814508
Validation loss: 2.729173866142866

Epoch: 5| Step: 9
Training loss: 2.934912658119661
Validation loss: 2.724794435532567

Epoch: 5| Step: 10
Training loss: 3.020151170900684
Validation loss: 2.704436260662454

Epoch: 42| Step: 0
Training loss: 2.733983213421983
Validation loss: 2.701682923899833

Epoch: 5| Step: 1
Training loss: 3.5761133394393574
Validation loss: 2.6954531948706255

Epoch: 5| Step: 2
Training loss: 2.9820315762030702
Validation loss: 2.691318659786884

Epoch: 5| Step: 3
Training loss: 3.347282041557727
Validation loss: 2.688042267609889

Epoch: 5| Step: 4
Training loss: 2.9700038470619026
Validation loss: 2.6839545430530527

Epoch: 5| Step: 5
Training loss: 3.0681484837118016
Validation loss: 2.6895839827242787

Epoch: 5| Step: 6
Training loss: 2.639661443849755
Validation loss: 2.6910074482884814

Epoch: 5| Step: 7
Training loss: 2.584665037252867
Validation loss: 2.6928862130568807

Epoch: 5| Step: 8
Training loss: 3.216466890235534
Validation loss: 2.705734458686899

Epoch: 5| Step: 9
Training loss: 3.084008185963336
Validation loss: 2.7202150440185986

Epoch: 5| Step: 10
Training loss: 3.2415860640859844
Validation loss: 2.730152504097674

Epoch: 43| Step: 0
Training loss: 2.977838518067267
Validation loss: 2.709025197285239

Epoch: 5| Step: 1
Training loss: 3.146369501026112
Validation loss: 2.690285132623034

Epoch: 5| Step: 2
Training loss: 2.7791996802828907
Validation loss: 2.6825382960752986

Epoch: 5| Step: 3
Training loss: 3.0732696502884007
Validation loss: 2.6806994967740523

Epoch: 5| Step: 4
Training loss: 2.467288876577321
Validation loss: 2.6794387183848913

Epoch: 5| Step: 5
Training loss: 2.954748766912972
Validation loss: 2.6764734713981273

Epoch: 5| Step: 6
Training loss: 3.1841061045253327
Validation loss: 2.683582934056727

Epoch: 5| Step: 7
Training loss: 3.478974814845474
Validation loss: 2.706225987790877

Epoch: 5| Step: 8
Training loss: 2.805768582992652
Validation loss: 2.6997861350588583

Epoch: 5| Step: 9
Training loss: 3.1438824665532548
Validation loss: 2.687273988523313

Epoch: 5| Step: 10
Training loss: 3.2925644306201747
Validation loss: 2.682666813897472

Epoch: 44| Step: 0
Training loss: 2.7920769821692115
Validation loss: 2.676516458555363

Epoch: 5| Step: 1
Training loss: 2.622070676210403
Validation loss: 2.674925684977172

Epoch: 5| Step: 2
Training loss: 3.196524019635308
Validation loss: 2.6719941450457316

Epoch: 5| Step: 3
Training loss: 2.2090017518726897
Validation loss: 2.673955557666692

Epoch: 5| Step: 4
Training loss: 3.1278293770990215
Validation loss: 2.67750661714939

Epoch: 5| Step: 5
Training loss: 3.1491907321494605
Validation loss: 2.673741564963815

Epoch: 5| Step: 6
Training loss: 3.5831592576674716
Validation loss: 2.6728322012163344

Epoch: 5| Step: 7
Training loss: 2.8481483400588496
Validation loss: 2.6679330678474384

Epoch: 5| Step: 8
Training loss: 3.093505387317091
Validation loss: 2.6710931967490477

Epoch: 5| Step: 9
Training loss: 3.118476773144792
Validation loss: 2.671636463669815

Epoch: 5| Step: 10
Training loss: 3.2827137906369166
Validation loss: 2.6819092993030194

Epoch: 45| Step: 0
Training loss: 2.719740851482886
Validation loss: 2.6913959979183186

Epoch: 5| Step: 1
Training loss: 3.2875045022099636
Validation loss: 2.693722006412007

Epoch: 5| Step: 2
Training loss: 2.74038706739473
Validation loss: 2.7009972719570223

Epoch: 5| Step: 3
Training loss: 2.3339543424453764
Validation loss: 2.682709482500027

Epoch: 5| Step: 4
Training loss: 3.2428548470759684
Validation loss: 2.6743980459555754

Epoch: 5| Step: 5
Training loss: 3.4868489194346934
Validation loss: 2.6791111160505805

Epoch: 5| Step: 6
Training loss: 3.4070414052495694
Validation loss: 2.6845430503403414

Epoch: 5| Step: 7
Training loss: 3.4639901160083744
Validation loss: 2.677389456259191

Epoch: 5| Step: 8
Training loss: 2.6587482148573836
Validation loss: 2.664243070411698

Epoch: 5| Step: 9
Training loss: 2.917025371473869
Validation loss: 2.6651119265099004

Epoch: 5| Step: 10
Training loss: 2.5727579374167746
Validation loss: 2.669642323180432

Epoch: 46| Step: 0
Training loss: 3.0367912690120558
Validation loss: 2.6721162445438376

Epoch: 5| Step: 1
Training loss: 2.721717355150627
Validation loss: 2.672106740664899

Epoch: 5| Step: 2
Training loss: 3.1538025081827996
Validation loss: 2.672646603545284

Epoch: 5| Step: 3
Training loss: 3.0385198819688704
Validation loss: 2.670682101456788

Epoch: 5| Step: 4
Training loss: 2.888334119135916
Validation loss: 2.6710738659099205

Epoch: 5| Step: 5
Training loss: 3.427966822380193
Validation loss: 2.670688252615799

Epoch: 5| Step: 6
Training loss: 2.8307531800899484
Validation loss: 2.670720066975046

Epoch: 5| Step: 7
Training loss: 2.6703047572024228
Validation loss: 2.6708523762024567

Epoch: 5| Step: 8
Training loss: 3.136284252966442
Validation loss: 2.6707147577288155

Epoch: 5| Step: 9
Training loss: 3.1711424935432135
Validation loss: 2.667039832287758

Epoch: 5| Step: 10
Training loss: 3.1672413622393365
Validation loss: 2.6656909421429886

Epoch: 47| Step: 0
Training loss: 2.9935968730206777
Validation loss: 2.6638445116799336

Epoch: 5| Step: 1
Training loss: 3.124216515553871
Validation loss: 2.6616779207346433

Epoch: 5| Step: 2
Training loss: 3.542762287689536
Validation loss: 2.659366494951038

Epoch: 5| Step: 3
Training loss: 2.7155146147282534
Validation loss: 2.658663243761263

Epoch: 5| Step: 4
Training loss: 2.751893085504346
Validation loss: 2.6587593410660375

Epoch: 5| Step: 5
Training loss: 2.459823598507158
Validation loss: 2.6541777681266097

Epoch: 5| Step: 6
Training loss: 2.6863133671787716
Validation loss: 2.6537402211291283

Epoch: 5| Step: 7
Training loss: 3.3624103406559698
Validation loss: 2.652676760073702

Epoch: 5| Step: 8
Training loss: 2.7721554654054743
Validation loss: 2.6534491851192756

Epoch: 5| Step: 9
Training loss: 2.8892266267625075
Validation loss: 2.6498985489355924

Epoch: 5| Step: 10
Training loss: 3.724748533836858
Validation loss: 2.6506085059564795

Epoch: 48| Step: 0
Training loss: 3.0579423271613737
Validation loss: 2.644074728971416

Epoch: 5| Step: 1
Training loss: 3.4752983623827993
Validation loss: 2.64257281645093

Epoch: 5| Step: 2
Training loss: 2.848380542212862
Validation loss: 2.6417803357298766

Epoch: 5| Step: 3
Training loss: 3.122000208149035
Validation loss: 2.6408832343929274

Epoch: 5| Step: 4
Training loss: 2.804447854517405
Validation loss: 2.63773948804138

Epoch: 5| Step: 5
Training loss: 3.070872326158627
Validation loss: 2.6348202022420226

Epoch: 5| Step: 6
Training loss: 3.0649457235337803
Validation loss: 2.6405019540328456

Epoch: 5| Step: 7
Training loss: 3.231650269027221
Validation loss: 2.6338085316940965

Epoch: 5| Step: 8
Training loss: 2.639975563861
Validation loss: 2.6331519758247217

Epoch: 5| Step: 9
Training loss: 2.617157437735461
Validation loss: 2.6336756317746413

Epoch: 5| Step: 10
Training loss: 2.8997046484667783
Validation loss: 2.6363102072047333

Epoch: 49| Step: 0
Training loss: 3.112986705061734
Validation loss: 2.637251212540164

Epoch: 5| Step: 1
Training loss: 3.4715240658246356
Validation loss: 2.6391798437224177

Epoch: 5| Step: 2
Training loss: 2.9934955656045235
Validation loss: 2.6384161253838068

Epoch: 5| Step: 3
Training loss: 2.495791134825163
Validation loss: 2.6341547998086816

Epoch: 5| Step: 4
Training loss: 2.7346704813842106
Validation loss: 2.632883846932261

Epoch: 5| Step: 5
Training loss: 3.072103429394264
Validation loss: 2.6301299195656163

Epoch: 5| Step: 6
Training loss: 2.6021325572244454
Validation loss: 2.6297041624329505

Epoch: 5| Step: 7
Training loss: 3.2448180040951
Validation loss: 2.6296027244245352

Epoch: 5| Step: 8
Training loss: 2.9346744664857063
Validation loss: 2.6308609204770756

Epoch: 5| Step: 9
Training loss: 2.855673306466298
Validation loss: 2.6272461486479486

Epoch: 5| Step: 10
Training loss: 3.1952938461691907
Validation loss: 2.6262169803720203

Epoch: 50| Step: 0
Training loss: 2.595401651687373
Validation loss: 2.626705765925343

Epoch: 5| Step: 1
Training loss: 3.006369821932356
Validation loss: 2.6344689798834082

Epoch: 5| Step: 2
Training loss: 3.0990210433299663
Validation loss: 2.62648480305251

Epoch: 5| Step: 3
Training loss: 2.814057152217208
Validation loss: 2.6299272040770845

Epoch: 5| Step: 4
Training loss: 3.066293196811263
Validation loss: 2.625250830241814

Epoch: 5| Step: 5
Training loss: 2.8358855439778385
Validation loss: 2.6247060828997046

Epoch: 5| Step: 6
Training loss: 2.812025072477083
Validation loss: 2.6230000828686864

Epoch: 5| Step: 7
Training loss: 2.604763135629959
Validation loss: 2.624330347317496

Epoch: 5| Step: 8
Training loss: 3.5438733276221153
Validation loss: 2.622090649895912

Epoch: 5| Step: 9
Training loss: 3.143871546191128
Validation loss: 2.6374301222106977

Epoch: 5| Step: 10
Training loss: 3.2964708704287013
Validation loss: 2.6348065697133833

Epoch: 51| Step: 0
Training loss: 2.8524213777718095
Validation loss: 2.6332754489626695

Epoch: 5| Step: 1
Training loss: 2.658704364279143
Validation loss: 2.6335481881835756

Epoch: 5| Step: 2
Training loss: 2.727404620131392
Validation loss: 2.632694746507219

Epoch: 5| Step: 3
Training loss: 2.8821330936892506
Validation loss: 2.634622469667942

Epoch: 5| Step: 4
Training loss: 3.052062797260307
Validation loss: 2.641050549715412

Epoch: 5| Step: 5
Training loss: 2.8728855484532825
Validation loss: 2.6466071951398558

Epoch: 5| Step: 6
Training loss: 2.745254323187692
Validation loss: 2.641924238537241

Epoch: 5| Step: 7
Training loss: 3.3639798563060412
Validation loss: 2.631214956969426

Epoch: 5| Step: 8
Training loss: 3.2377749646635046
Validation loss: 2.6228964943023634

Epoch: 5| Step: 9
Training loss: 3.0812801707804383
Validation loss: 2.6187238155803065

Epoch: 5| Step: 10
Training loss: 3.243735217463155
Validation loss: 2.6177613556274792

Epoch: 52| Step: 0
Training loss: 3.314096893606891
Validation loss: 2.62118881574259

Epoch: 5| Step: 1
Training loss: 2.561031944483806
Validation loss: 2.6240162331771546

Epoch: 5| Step: 2
Training loss: 2.9740293441997396
Validation loss: 2.6256467898413924

Epoch: 5| Step: 3
Training loss: 2.8683431099949104
Validation loss: 2.621575916933692

Epoch: 5| Step: 4
Training loss: 3.503038449881425
Validation loss: 2.620538364448661

Epoch: 5| Step: 5
Training loss: 3.006009440799997
Validation loss: 2.6175880366848268

Epoch: 5| Step: 6
Training loss: 2.92106543764696
Validation loss: 2.618336284894769

Epoch: 5| Step: 7
Training loss: 2.8436242379686343
Validation loss: 2.6169889994049984

Epoch: 5| Step: 8
Training loss: 2.942811911231374
Validation loss: 2.615202263057633

Epoch: 5| Step: 9
Training loss: 2.817365464499233
Validation loss: 2.6151341491053977

Epoch: 5| Step: 10
Training loss: 2.8596891637094246
Validation loss: 2.6147472972581203

Epoch: 53| Step: 0
Training loss: 2.677505539034431
Validation loss: 2.6161392740373586

Epoch: 5| Step: 1
Training loss: 3.55356803285939
Validation loss: 2.6200804769638095

Epoch: 5| Step: 2
Training loss: 2.637281027287086
Validation loss: 2.6295646878185277

Epoch: 5| Step: 3
Training loss: 2.861366453988162
Validation loss: 2.619920309135935

Epoch: 5| Step: 4
Training loss: 3.1964956765159798
Validation loss: 2.615661834658556

Epoch: 5| Step: 5
Training loss: 2.786831944217096
Validation loss: 2.613026741498279

Epoch: 5| Step: 6
Training loss: 3.34882105678968
Validation loss: 2.6099395494929882

Epoch: 5| Step: 7
Training loss: 3.0904728650486564
Validation loss: 2.612723480595194

Epoch: 5| Step: 8
Training loss: 2.829253250917052
Validation loss: 2.608775150900261

Epoch: 5| Step: 9
Training loss: 2.855573952298539
Validation loss: 2.6099086974892862

Epoch: 5| Step: 10
Training loss: 2.647823836537457
Validation loss: 2.6111972776147687

Epoch: 54| Step: 0
Training loss: 2.8434820363319306
Validation loss: 2.608402378688982

Epoch: 5| Step: 1
Training loss: 2.93648138038348
Validation loss: 2.610100705969093

Epoch: 5| Step: 2
Training loss: 3.4247217051359655
Validation loss: 2.610523820085863

Epoch: 5| Step: 3
Training loss: 2.286099022603768
Validation loss: 2.6126781873682794

Epoch: 5| Step: 4
Training loss: 2.357618574961018
Validation loss: 2.6266898591792844

Epoch: 5| Step: 5
Training loss: 3.2313483630912256
Validation loss: 2.6532652925820295

Epoch: 5| Step: 6
Training loss: 3.135012798131102
Validation loss: 2.6601569804981935

Epoch: 5| Step: 7
Training loss: 2.869879765666981
Validation loss: 2.6209425686304937

Epoch: 5| Step: 8
Training loss: 2.8694341105639913
Validation loss: 2.6132957099661525

Epoch: 5| Step: 9
Training loss: 3.358903434834931
Validation loss: 2.606958970578388

Epoch: 5| Step: 10
Training loss: 3.1530098477254263
Validation loss: 2.6046487144680253

Epoch: 55| Step: 0
Training loss: 3.532453213845558
Validation loss: 2.6039769165476208

Epoch: 5| Step: 1
Training loss: 3.284241974348013
Validation loss: 2.6082917469568456

Epoch: 5| Step: 2
Training loss: 2.9009597374095506
Validation loss: 2.609777968525727

Epoch: 5| Step: 3
Training loss: 3.241578856180266
Validation loss: 2.612303652153159

Epoch: 5| Step: 4
Training loss: 2.6652084973278387
Validation loss: 2.6132936361333163

Epoch: 5| Step: 5
Training loss: 2.876312785418684
Validation loss: 2.608614378361299

Epoch: 5| Step: 6
Training loss: 2.648667677157664
Validation loss: 2.6059520863672847

Epoch: 5| Step: 7
Training loss: 2.8409727179598003
Validation loss: 2.6070185540917463

Epoch: 5| Step: 8
Training loss: 2.782851283270636
Validation loss: 2.6035452264073906

Epoch: 5| Step: 9
Training loss: 2.8934068645269035
Validation loss: 2.6048369711951356

Epoch: 5| Step: 10
Training loss: 2.8766864308561972
Validation loss: 2.603466918126357

Epoch: 56| Step: 0
Training loss: 3.3884609365633422
Validation loss: 2.5998911580036657

Epoch: 5| Step: 1
Training loss: 3.0538915977799883
Validation loss: 2.5987863955814174

Epoch: 5| Step: 2
Training loss: 2.447893139881679
Validation loss: 2.5998174028589807

Epoch: 5| Step: 3
Training loss: 2.7542174684241627
Validation loss: 2.608754396215603

Epoch: 5| Step: 4
Training loss: 2.9568566052806644
Validation loss: 2.622655154263871

Epoch: 5| Step: 5
Training loss: 2.8036730958729352
Validation loss: 2.7029588866313725

Epoch: 5| Step: 6
Training loss: 2.6589636012667284
Validation loss: 2.728498498402763

Epoch: 5| Step: 7
Training loss: 2.83264237748875
Validation loss: 2.761521914794446

Epoch: 5| Step: 8
Training loss: 3.1435971596424084
Validation loss: 2.7820229345227796

Epoch: 5| Step: 9
Training loss: 3.7163049690089567
Validation loss: 2.6190838543924007

Epoch: 5| Step: 10
Training loss: 2.814934418695252
Validation loss: 2.6015998482652365

Epoch: 57| Step: 0
Training loss: 2.5003597954290298
Validation loss: 2.6309924912321248

Epoch: 5| Step: 1
Training loss: 3.0938295296359275
Validation loss: 2.7116236109112264

Epoch: 5| Step: 2
Training loss: 3.341162562854932
Validation loss: 2.777418986259218

Epoch: 5| Step: 3
Training loss: 3.643008651040397
Validation loss: 2.744174466103085

Epoch: 5| Step: 4
Training loss: 2.9601455474845286
Validation loss: 2.6441868778529787

Epoch: 5| Step: 5
Training loss: 2.5965276345806747
Validation loss: 2.6175993329495073

Epoch: 5| Step: 6
Training loss: 2.9709987756603984
Validation loss: 2.6019525447120837

Epoch: 5| Step: 7
Training loss: 2.851070831971036
Validation loss: 2.6002412615457025

Epoch: 5| Step: 8
Training loss: 3.329183061071586
Validation loss: 2.6247658573856096

Epoch: 5| Step: 9
Training loss: 2.82647125619835
Validation loss: 2.673954968038655

Epoch: 5| Step: 10
Training loss: 2.9251520883520286
Validation loss: 2.7087666022197023

Epoch: 58| Step: 0
Training loss: 2.850118360236711
Validation loss: 2.7156946234192474

Epoch: 5| Step: 1
Training loss: 3.300244241403578
Validation loss: 2.75909916987461

Epoch: 5| Step: 2
Training loss: 3.3521932795298657
Validation loss: 2.7909720880217446

Epoch: 5| Step: 3
Training loss: 2.8873282113104324
Validation loss: 2.698013357777749

Epoch: 5| Step: 4
Training loss: 2.740267524328403
Validation loss: 2.623334906381192

Epoch: 5| Step: 5
Training loss: 3.316857836276209
Validation loss: 2.6148537905816798

Epoch: 5| Step: 6
Training loss: 3.068830836332685
Validation loss: 2.6132162870753346

Epoch: 5| Step: 7
Training loss: 3.24541840029241
Validation loss: 2.613227081313758

Epoch: 5| Step: 8
Training loss: 2.685391863424041
Validation loss: 2.6134511093308714

Epoch: 5| Step: 9
Training loss: 2.7016395500496238
Validation loss: 2.628655260449759

Epoch: 5| Step: 10
Training loss: 2.6825148900055185
Validation loss: 2.6337740521806627

Epoch: 59| Step: 0
Training loss: 2.6950699406821443
Validation loss: 2.6351013234879033

Epoch: 5| Step: 1
Training loss: 2.889723518636369
Validation loss: 2.6316852514646754

Epoch: 5| Step: 2
Training loss: 2.9614981973447114
Validation loss: 2.621038624804417

Epoch: 5| Step: 3
Training loss: 2.7455848450202436
Validation loss: 2.6126092147548925

Epoch: 5| Step: 4
Training loss: 2.9289865697967623
Validation loss: 2.6126553314563616

Epoch: 5| Step: 5
Training loss: 2.586317789287279
Validation loss: 2.603660059391851

Epoch: 5| Step: 6
Training loss: 3.3719544974952895
Validation loss: 2.603008307642166

Epoch: 5| Step: 7
Training loss: 3.550050767347508
Validation loss: 2.6080003329721673

Epoch: 5| Step: 8
Training loss: 2.983756595471639
Validation loss: 2.6082881505924576

Epoch: 5| Step: 9
Training loss: 2.8683813452447438
Validation loss: 2.6137278180616494

Epoch: 5| Step: 10
Training loss: 3.0711709101379143
Validation loss: 2.620084626604029

Epoch: 60| Step: 0
Training loss: 2.74952017326051
Validation loss: 2.6304634418066875

Epoch: 5| Step: 1
Training loss: 2.8255241616693865
Validation loss: 2.628774552397991

Epoch: 5| Step: 2
Training loss: 3.197380758273701
Validation loss: 2.6283856009070012

Epoch: 5| Step: 3
Training loss: 2.646574462258212
Validation loss: 2.626047157971438

Epoch: 5| Step: 4
Training loss: 2.561810656612239
Validation loss: 2.5966444474162054

Epoch: 5| Step: 5
Training loss: 2.513503607725154
Validation loss: 2.585438858363629

Epoch: 5| Step: 6
Training loss: 3.478566618625385
Validation loss: 2.5833046458699416

Epoch: 5| Step: 7
Training loss: 2.769055754783895
Validation loss: 2.5846385736441784

Epoch: 5| Step: 8
Training loss: 3.1230346603106973
Validation loss: 2.5946017192712545

Epoch: 5| Step: 9
Training loss: 3.5612284750269496
Validation loss: 2.5917040893772385

Epoch: 5| Step: 10
Training loss: 2.9593021436220557
Validation loss: 2.613337359911349

Epoch: 61| Step: 0
Training loss: 2.2334804211286343
Validation loss: 2.595719664098365

Epoch: 5| Step: 1
Training loss: 3.1963873736503903
Validation loss: 2.586835605552968

Epoch: 5| Step: 2
Training loss: 2.886298989218472
Validation loss: 2.5843952892630107

Epoch: 5| Step: 3
Training loss: 3.6177830380936022
Validation loss: 2.5851887726044454

Epoch: 5| Step: 4
Training loss: 3.5380297368656066
Validation loss: 2.586098890253404

Epoch: 5| Step: 5
Training loss: 2.7216089935483803
Validation loss: 2.5879624644497192

Epoch: 5| Step: 6
Training loss: 2.960286171972349
Validation loss: 2.5905353211331423

Epoch: 5| Step: 7
Training loss: 2.2274815854254384
Validation loss: 2.590167357960423

Epoch: 5| Step: 8
Training loss: 2.836112024911336
Validation loss: 2.5933662325355553

Epoch: 5| Step: 9
Training loss: 3.0881509689230464
Validation loss: 2.5982092607422103

Epoch: 5| Step: 10
Training loss: 2.7687679040472015
Validation loss: 2.5919070763002465

Epoch: 62| Step: 0
Training loss: 2.0109982876307986
Validation loss: 2.5879816414416057

Epoch: 5| Step: 1
Training loss: 2.766635602370672
Validation loss: 2.5867146827703267

Epoch: 5| Step: 2
Training loss: 2.9552268969697137
Validation loss: 2.5826431335511337

Epoch: 5| Step: 3
Training loss: 2.5826654391183266
Validation loss: 2.58572762080044

Epoch: 5| Step: 4
Training loss: 3.0410965337261833
Validation loss: 2.5861509149735

Epoch: 5| Step: 5
Training loss: 3.0127010104281613
Validation loss: 2.5842330852981616

Epoch: 5| Step: 6
Training loss: 3.3422491680517736
Validation loss: 2.580891222656808

Epoch: 5| Step: 7
Training loss: 3.301550997756008
Validation loss: 2.5818251869389894

Epoch: 5| Step: 8
Training loss: 3.1328554221849236
Validation loss: 2.5805780965412377

Epoch: 5| Step: 9
Training loss: 2.902983932434883
Validation loss: 2.577869594299231

Epoch: 5| Step: 10
Training loss: 3.183182728451957
Validation loss: 2.5788357577484

Epoch: 63| Step: 0
Training loss: 2.948812090392638
Validation loss: 2.5780243009637847

Epoch: 5| Step: 1
Training loss: 3.2145251351455353
Validation loss: 2.575512895439467

Epoch: 5| Step: 2
Training loss: 2.515083491644002
Validation loss: 2.574216586924387

Epoch: 5| Step: 3
Training loss: 3.2928206115199896
Validation loss: 2.580530650568246

Epoch: 5| Step: 4
Training loss: 3.2000577802209964
Validation loss: 2.5836769149088594

Epoch: 5| Step: 5
Training loss: 2.5209394910754153
Validation loss: 2.576752704072795

Epoch: 5| Step: 6
Training loss: 3.107487551356552
Validation loss: 2.5774522039602665

Epoch: 5| Step: 7
Training loss: 2.6351628438876697
Validation loss: 2.5735308780185147

Epoch: 5| Step: 8
Training loss: 3.047367779912258
Validation loss: 2.57278905057749

Epoch: 5| Step: 9
Training loss: 2.8070182785129423
Validation loss: 2.57380535243332

Epoch: 5| Step: 10
Training loss: 2.9324323079523347
Validation loss: 2.5667513135283797

Epoch: 64| Step: 0
Training loss: 2.847548745720243
Validation loss: 2.567736608646637

Epoch: 5| Step: 1
Training loss: 3.309367732255284
Validation loss: 2.5678079646468603

Epoch: 5| Step: 2
Training loss: 2.3409313291754286
Validation loss: 2.5658678292995654

Epoch: 5| Step: 3
Training loss: 3.057135418219486
Validation loss: 2.5711997474089547

Epoch: 5| Step: 4
Training loss: 3.01378943361727
Validation loss: 2.5684056234560773

Epoch: 5| Step: 5
Training loss: 3.36734992606904
Validation loss: 2.5751420679276076

Epoch: 5| Step: 6
Training loss: 2.9412794757084257
Validation loss: 2.579798702367569

Epoch: 5| Step: 7
Training loss: 2.7900159045077153
Validation loss: 2.5872574114920535

Epoch: 5| Step: 8
Training loss: 2.7110498058791315
Validation loss: 2.5788532122333603

Epoch: 5| Step: 9
Training loss: 2.591249846602425
Validation loss: 2.583604381273513

Epoch: 5| Step: 10
Training loss: 3.253733031572669
Validation loss: 2.5947969974595075

Epoch: 65| Step: 0
Training loss: 2.953554798315967
Validation loss: 2.6157062676427913

Epoch: 5| Step: 1
Training loss: 3.139616087751303
Validation loss: 2.6638549275387544

Epoch: 5| Step: 2
Training loss: 2.603767445799298
Validation loss: 2.755385702634016

Epoch: 5| Step: 3
Training loss: 3.6131806890567293
Validation loss: 2.777085317692791

Epoch: 5| Step: 4
Training loss: 3.322052192447937
Validation loss: 2.6361835542122494

Epoch: 5| Step: 5
Training loss: 2.8041653372849766
Validation loss: 2.562218949547084

Epoch: 5| Step: 6
Training loss: 2.8434914272253575
Validation loss: 2.565633676029711

Epoch: 5| Step: 7
Training loss: 2.3413895991754456
Validation loss: 2.5820361200593607

Epoch: 5| Step: 8
Training loss: 3.177074661659955
Validation loss: 2.6132531656526004

Epoch: 5| Step: 9
Training loss: 3.0895588546952744
Validation loss: 2.669754162400861

Epoch: 5| Step: 10
Training loss: 2.829052009188046
Validation loss: 2.691763635847719

Epoch: 66| Step: 0
Training loss: 3.1644479775795995
Validation loss: 2.6611978522898085

Epoch: 5| Step: 1
Training loss: 3.167338918972316
Validation loss: 2.627011917370653

Epoch: 5| Step: 2
Training loss: 3.1022926835502127
Validation loss: 2.6131114061166545

Epoch: 5| Step: 3
Training loss: 2.3766102602321078
Validation loss: 2.594387251428121

Epoch: 5| Step: 4
Training loss: 3.1366799852153995
Validation loss: 2.5917269915710586

Epoch: 5| Step: 5
Training loss: 3.182661835180844
Validation loss: 2.57772207483127

Epoch: 5| Step: 6
Training loss: 3.2694602238495687
Validation loss: 2.5784518097205753

Epoch: 5| Step: 7
Training loss: 3.0651831258857674
Validation loss: 2.5694213503267473

Epoch: 5| Step: 8
Training loss: 2.5616569993236484
Validation loss: 2.5658241698574678

Epoch: 5| Step: 9
Training loss: 2.8520211464952627
Validation loss: 2.564711664025122

Epoch: 5| Step: 10
Training loss: 2.622479909378059
Validation loss: 2.573767448440694

Epoch: 67| Step: 0
Training loss: 2.7097069313673288
Validation loss: 2.602487303325662

Epoch: 5| Step: 1
Training loss: 2.9754069330490456
Validation loss: 2.6284780065296633

Epoch: 5| Step: 2
Training loss: 3.05592527946278
Validation loss: 2.643291678548967

Epoch: 5| Step: 3
Training loss: 2.747749795153769
Validation loss: 2.625255859375211

Epoch: 5| Step: 4
Training loss: 2.6018552873145557
Validation loss: 2.5953175917304185

Epoch: 5| Step: 5
Training loss: 3.246594625635915
Validation loss: 2.579902391739194

Epoch: 5| Step: 6
Training loss: 2.5674826398372157
Validation loss: 2.5613176042482566

Epoch: 5| Step: 7
Training loss: 3.034337938673644
Validation loss: 2.5613819357347785

Epoch: 5| Step: 8
Training loss: 2.575593572553046
Validation loss: 2.564286896293324

Epoch: 5| Step: 9
Training loss: 3.651925684211404
Validation loss: 2.557454895045844

Epoch: 5| Step: 10
Training loss: 3.058062238051154
Validation loss: 2.5578662776531216

Epoch: 68| Step: 0
Training loss: 2.310804312416346
Validation loss: 2.559679661783082

Epoch: 5| Step: 1
Training loss: 3.271399544142689
Validation loss: 2.5575588136821628

Epoch: 5| Step: 2
Training loss: 3.102687525956816
Validation loss: 2.5585588029636708

Epoch: 5| Step: 3
Training loss: 3.3419882152721705
Validation loss: 2.556383571228438

Epoch: 5| Step: 4
Training loss: 2.2560348112247754
Validation loss: 2.557039933211698

Epoch: 5| Step: 5
Training loss: 3.2296888523994056
Validation loss: 2.558858304161609

Epoch: 5| Step: 6
Training loss: 2.9784997758287335
Validation loss: 2.560027581730944

Epoch: 5| Step: 7
Training loss: 3.099433687227161
Validation loss: 2.5633180414536305

Epoch: 5| Step: 8
Training loss: 2.763779795126762
Validation loss: 2.5552731313407406

Epoch: 5| Step: 9
Training loss: 2.826017321491004
Validation loss: 2.563012022681407

Epoch: 5| Step: 10
Training loss: 2.7986276771763983
Validation loss: 2.5633603824319287

Epoch: 69| Step: 0
Training loss: 3.3049587562284484
Validation loss: 2.5623781428862507

Epoch: 5| Step: 1
Training loss: 2.829488688940941
Validation loss: 2.5617806420115032

Epoch: 5| Step: 2
Training loss: 2.239155490432331
Validation loss: 2.559819938681214

Epoch: 5| Step: 3
Training loss: 3.3754451599412776
Validation loss: 2.556738081251516

Epoch: 5| Step: 4
Training loss: 2.7962682481425256
Validation loss: 2.5490333817401294

Epoch: 5| Step: 5
Training loss: 2.6312511126953093
Validation loss: 2.546099650136805

Epoch: 5| Step: 6
Training loss: 2.4326830487120024
Validation loss: 2.5478504244909224

Epoch: 5| Step: 7
Training loss: 2.979970827919949
Validation loss: 2.556655351167446

Epoch: 5| Step: 8
Training loss: 3.538376360604834
Validation loss: 2.5700002974956155

Epoch: 5| Step: 9
Training loss: 2.7233744786335947
Validation loss: 2.576203878365742

Epoch: 5| Step: 10
Training loss: 3.1451838414446263
Validation loss: 2.610098051081431

Epoch: 70| Step: 0
Training loss: 2.6438156805153916
Validation loss: 2.5831711295097866

Epoch: 5| Step: 1
Training loss: 2.725826306133334
Validation loss: 2.5844500533206767

Epoch: 5| Step: 2
Training loss: 2.998933284575853
Validation loss: 2.570481046817019

Epoch: 5| Step: 3
Training loss: 2.8129981553457797
Validation loss: 2.5637461775778143

Epoch: 5| Step: 4
Training loss: 2.5637201335177267
Validation loss: 2.5493052162016756

Epoch: 5| Step: 5
Training loss: 3.0560368438217327
Validation loss: 2.5446120974019846

Epoch: 5| Step: 6
Training loss: 2.739342150690305
Validation loss: 2.5475071008715258

Epoch: 5| Step: 7
Training loss: 2.890672837969866
Validation loss: 2.544906539983488

Epoch: 5| Step: 8
Training loss: 3.481228215750401
Validation loss: 2.547170201555917

Epoch: 5| Step: 9
Training loss: 3.1222696201924585
Validation loss: 2.553467235992606

Epoch: 5| Step: 10
Training loss: 3.086426824090652
Validation loss: 2.5538857677049704

Epoch: 71| Step: 0
Training loss: 2.6076986444576753
Validation loss: 2.5472416385164056

Epoch: 5| Step: 1
Training loss: 2.834031823021994
Validation loss: 2.542344236173131

Epoch: 5| Step: 2
Training loss: 2.7254779921409256
Validation loss: 2.540626091640202

Epoch: 5| Step: 3
Training loss: 2.9243972418098867
Validation loss: 2.542847620411387

Epoch: 5| Step: 4
Training loss: 2.639484768788319
Validation loss: 2.546451179274398

Epoch: 5| Step: 5
Training loss: 3.3840074785208527
Validation loss: 2.55988205650534

Epoch: 5| Step: 6
Training loss: 2.9135100221921433
Validation loss: 2.5851794509387798

Epoch: 5| Step: 7
Training loss: 2.825089316517492
Validation loss: 2.6016383498917603

Epoch: 5| Step: 8
Training loss: 3.1286698727133735
Validation loss: 2.5558899844843457

Epoch: 5| Step: 9
Training loss: 2.9128518542809196
Validation loss: 2.5403736550151

Epoch: 5| Step: 10
Training loss: 3.194027817320153
Validation loss: 2.538629702147622

Epoch: 72| Step: 0
Training loss: 3.5060175527948187
Validation loss: 2.543509975030966

Epoch: 5| Step: 1
Training loss: 3.3197776453404155
Validation loss: 2.547600866242166

Epoch: 5| Step: 2
Training loss: 2.6016375556635127
Validation loss: 2.551742059433997

Epoch: 5| Step: 3
Training loss: 2.677257982387998
Validation loss: 2.554988597857836

Epoch: 5| Step: 4
Training loss: 2.775639393319681
Validation loss: 2.559285468425245

Epoch: 5| Step: 5
Training loss: 2.4599103449169233
Validation loss: 2.5593623488786137

Epoch: 5| Step: 6
Training loss: 3.1348985685400064
Validation loss: 2.554283280455604

Epoch: 5| Step: 7
Training loss: 2.5237161110524675
Validation loss: 2.547980213614612

Epoch: 5| Step: 8
Training loss: 2.6788206783766233
Validation loss: 2.5458722209288216

Epoch: 5| Step: 9
Training loss: 3.385190625591746
Validation loss: 2.546406853683867

Epoch: 5| Step: 10
Training loss: 2.937919099819626
Validation loss: 2.5462427099917546

Epoch: 73| Step: 0
Training loss: 2.9521550598978816
Validation loss: 2.545893118684535

Epoch: 5| Step: 1
Training loss: 3.1801857897628665
Validation loss: 2.5563179305748243

Epoch: 5| Step: 2
Training loss: 2.7638791710849406
Validation loss: 2.557917144721733

Epoch: 5| Step: 3
Training loss: 2.865609797746276
Validation loss: 2.5647681238158393

Epoch: 5| Step: 4
Training loss: 3.0453153873467103
Validation loss: 2.5711040178882385

Epoch: 5| Step: 5
Training loss: 2.6447221019401033
Validation loss: 2.5544559669497326

Epoch: 5| Step: 6
Training loss: 2.8027010287650422
Validation loss: 2.542604526212702

Epoch: 5| Step: 7
Training loss: 2.9697784248698196
Validation loss: 2.5380229862206924

Epoch: 5| Step: 8
Training loss: 3.1518235090483637
Validation loss: 2.5332721657754496

Epoch: 5| Step: 9
Training loss: 2.653562555076404
Validation loss: 2.5333813336358006

Epoch: 5| Step: 10
Training loss: 3.033928857410571
Validation loss: 2.532073599575458

Epoch: 74| Step: 0
Training loss: 2.589901654500914
Validation loss: 2.532504494123947

Epoch: 5| Step: 1
Training loss: 2.905244386671982
Validation loss: 2.5316148518028845

Epoch: 5| Step: 2
Training loss: 3.0406144991749238
Validation loss: 2.532714118501051

Epoch: 5| Step: 3
Training loss: 3.6401610508597404
Validation loss: 2.532555188318067

Epoch: 5| Step: 4
Training loss: 2.8614994349314977
Validation loss: 2.529567774790643

Epoch: 5| Step: 5
Training loss: 2.860838135306816
Validation loss: 2.5322859495226684

Epoch: 5| Step: 6
Training loss: 2.8082227607790866
Validation loss: 2.5288679814596153

Epoch: 5| Step: 7
Training loss: 3.095267800129191
Validation loss: 2.526636468505186

Epoch: 5| Step: 8
Training loss: 2.8176001188942115
Validation loss: 2.5348638565679895

Epoch: 5| Step: 9
Training loss: 2.596951267118631
Validation loss: 2.536276798423194

Epoch: 5| Step: 10
Training loss: 2.5421917690810996
Validation loss: 2.5422220855465287

Epoch: 75| Step: 0
Training loss: 2.4672836584543
Validation loss: 2.5583057278085053

Epoch: 5| Step: 1
Training loss: 2.5410406769698475
Validation loss: 2.572064307398739

Epoch: 5| Step: 2
Training loss: 3.2794207605768344
Validation loss: 2.5845899023328798

Epoch: 5| Step: 3
Training loss: 2.5937798739631734
Validation loss: 2.5637237734022706

Epoch: 5| Step: 4
Training loss: 3.2876070476552517
Validation loss: 2.5337595559901636

Epoch: 5| Step: 5
Training loss: 2.508837243935692
Validation loss: 2.527408333582563

Epoch: 5| Step: 6
Training loss: 3.422476658988815
Validation loss: 2.5259481467080684

Epoch: 5| Step: 7
Training loss: 3.5539615770193937
Validation loss: 2.5312059065162176

Epoch: 5| Step: 8
Training loss: 2.95349538589564
Validation loss: 2.5373239183438376

Epoch: 5| Step: 9
Training loss: 2.768603256849101
Validation loss: 2.5385833636494435

Epoch: 5| Step: 10
Training loss: 2.3314977192107778
Validation loss: 2.5408504620599137

Epoch: 76| Step: 0
Training loss: 2.3677029190191776
Validation loss: 2.540814246859344

Epoch: 5| Step: 1
Training loss: 3.461194995403121
Validation loss: 2.5391650950463385

Epoch: 5| Step: 2
Training loss: 2.9667483357821594
Validation loss: 2.540177773760963

Epoch: 5| Step: 3
Training loss: 3.2529867093377325
Validation loss: 2.5371768322311596

Epoch: 5| Step: 4
Training loss: 2.8685917962360237
Validation loss: 2.539955261636809

Epoch: 5| Step: 5
Training loss: 2.8711817721413526
Validation loss: 2.534046548025242

Epoch: 5| Step: 6
Training loss: 2.7255337148738974
Validation loss: 2.532734166269214

Epoch: 5| Step: 7
Training loss: 3.0130045677983515
Validation loss: 2.5334431181496044

Epoch: 5| Step: 8
Training loss: 2.6230812326142448
Validation loss: 2.5316437445774564

Epoch: 5| Step: 9
Training loss: 3.209393132204058
Validation loss: 2.532916056631355

Epoch: 5| Step: 10
Training loss: 2.386860295420479
Validation loss: 2.5341605838932297

Epoch: 77| Step: 0
Training loss: 2.9365684168383446
Validation loss: 2.561228970400913

Epoch: 5| Step: 1
Training loss: 2.7759553038217164
Validation loss: 2.568276936414276

Epoch: 5| Step: 2
Training loss: 3.3193573419341504
Validation loss: 2.607897082477496

Epoch: 5| Step: 3
Training loss: 2.6198078759199457
Validation loss: 2.62747804565131

Epoch: 5| Step: 4
Training loss: 2.893065870582756
Validation loss: 2.604082062033983

Epoch: 5| Step: 5
Training loss: 3.362445935803818
Validation loss: 2.5739916973119863

Epoch: 5| Step: 6
Training loss: 2.611465439078594
Validation loss: 2.528686458901327

Epoch: 5| Step: 7
Training loss: 2.450075525949195
Validation loss: 2.524485543238831

Epoch: 5| Step: 8
Training loss: 3.2730266886834247
Validation loss: 2.5314840666587957

Epoch: 5| Step: 9
Training loss: 2.398722777656954
Validation loss: 2.541044275692117

Epoch: 5| Step: 10
Training loss: 3.539268639226239
Validation loss: 2.5492863224817555

Epoch: 78| Step: 0
Training loss: 2.642552592061839
Validation loss: 2.5547274958676565

Epoch: 5| Step: 1
Training loss: 3.0697516397421643
Validation loss: 2.5463234375714614

Epoch: 5| Step: 2
Training loss: 3.026793989900833
Validation loss: 2.54565913015543

Epoch: 5| Step: 3
Training loss: 3.1045073934532446
Validation loss: 2.5462450478564045

Epoch: 5| Step: 4
Training loss: 3.106340777722842
Validation loss: 2.5409795947676144

Epoch: 5| Step: 5
Training loss: 3.346991278216165
Validation loss: 2.538558765102853

Epoch: 5| Step: 6
Training loss: 2.876930086518837
Validation loss: 2.5330914638412274

Epoch: 5| Step: 7
Training loss: 2.346484915547684
Validation loss: 2.534003960045497

Epoch: 5| Step: 8
Training loss: 2.816371457206425
Validation loss: 2.5454393381009566

Epoch: 5| Step: 9
Training loss: 3.0873826904250516
Validation loss: 2.568725952055034

Epoch: 5| Step: 10
Training loss: 2.5531423019513957
Validation loss: 2.571178312521928

Epoch: 79| Step: 0
Training loss: 2.5188049689038077
Validation loss: 2.569046314557232

Epoch: 5| Step: 1
Training loss: 2.876527794955468
Validation loss: 2.547997595737249

Epoch: 5| Step: 2
Training loss: 3.078928266561253
Validation loss: 2.5511179166352442

Epoch: 5| Step: 3
Training loss: 3.182644605445338
Validation loss: 2.540647464420747

Epoch: 5| Step: 4
Training loss: 2.6150766543063226
Validation loss: 2.5388212174212454

Epoch: 5| Step: 5
Training loss: 3.020684460007962
Validation loss: 2.523094656080385

Epoch: 5| Step: 6
Training loss: 3.1533089711684403
Validation loss: 2.5232496797130963

Epoch: 5| Step: 7
Training loss: 2.8062008995739296
Validation loss: 2.524409481399945

Epoch: 5| Step: 8
Training loss: 2.8062801673813924
Validation loss: 2.524096258037294

Epoch: 5| Step: 9
Training loss: 2.9008098260821455
Validation loss: 2.5255330033587757

Epoch: 5| Step: 10
Training loss: 2.9660027893423697
Validation loss: 2.5256313539193296

Epoch: 80| Step: 0
Training loss: 2.823490370744647
Validation loss: 2.5250898492236056

Epoch: 5| Step: 1
Training loss: 2.632135774026514
Validation loss: 2.527474607890238

Epoch: 5| Step: 2
Training loss: 2.8767676517034197
Validation loss: 2.5280799770347877

Epoch: 5| Step: 3
Training loss: 2.727987796789713
Validation loss: 2.525103135989119

Epoch: 5| Step: 4
Training loss: 3.417038796481204
Validation loss: 2.5273904578803705

Epoch: 5| Step: 5
Training loss: 3.1462003649561474
Validation loss: 2.5334375799078206

Epoch: 5| Step: 6
Training loss: 2.7631677605875895
Validation loss: 2.54991352960949

Epoch: 5| Step: 7
Training loss: 2.6959937077910126
Validation loss: 2.5816827006704615

Epoch: 5| Step: 8
Training loss: 3.117109637136493
Validation loss: 2.628859090169497

Epoch: 5| Step: 9
Training loss: 3.1162998398376978
Validation loss: 2.6259016118585974

Epoch: 5| Step: 10
Training loss: 2.734781551110381
Validation loss: 2.6107439116615465

Epoch: 81| Step: 0
Training loss: 3.013293061395214
Validation loss: 2.598432887561504

Epoch: 5| Step: 1
Training loss: 2.852263064093491
Validation loss: 2.5768687797609937

Epoch: 5| Step: 2
Training loss: 2.7649929380412916
Validation loss: 2.576285489129318

Epoch: 5| Step: 3
Training loss: 3.1800764816011906
Validation loss: 2.5712400243326363

Epoch: 5| Step: 4
Training loss: 2.7434751959545527
Validation loss: 2.5674504299063377

Epoch: 5| Step: 5
Training loss: 2.7701570263915904
Validation loss: 2.5801669320509

Epoch: 5| Step: 6
Training loss: 3.0263960210085794
Validation loss: 2.5783513630730988

Epoch: 5| Step: 7
Training loss: 3.0293074213529345
Validation loss: 2.5700197362000314

Epoch: 5| Step: 8
Training loss: 2.5186087405441833
Validation loss: 2.562360887330493

Epoch: 5| Step: 9
Training loss: 3.3855000803525885
Validation loss: 2.5455051409424807

Epoch: 5| Step: 10
Training loss: 2.860404574449008
Validation loss: 2.534054615137468

Epoch: 82| Step: 0
Training loss: 2.878636423869405
Validation loss: 2.5263105433093758

Epoch: 5| Step: 1
Training loss: 2.8203028628536004
Validation loss: 2.5161631029100384

Epoch: 5| Step: 2
Training loss: 3.3622051294075375
Validation loss: 2.5174011266515

Epoch: 5| Step: 3
Training loss: 2.5873203786525494
Validation loss: 2.5167141274313316

Epoch: 5| Step: 4
Training loss: 2.6137215053878733
Validation loss: 2.5149630500672187

Epoch: 5| Step: 5
Training loss: 3.074512045997525
Validation loss: 2.5173142828078845

Epoch: 5| Step: 6
Training loss: 2.5167347610389688
Validation loss: 2.515483171707789

Epoch: 5| Step: 7
Training loss: 2.764917056752154
Validation loss: 2.5175955500269747

Epoch: 5| Step: 8
Training loss: 3.4206780556778074
Validation loss: 2.5157502161748675

Epoch: 5| Step: 9
Training loss: 2.9777912797511044
Validation loss: 2.518252796461342

Epoch: 5| Step: 10
Training loss: 2.7771226926410164
Validation loss: 2.5392994709355112

Epoch: 83| Step: 0
Training loss: 2.570100816166796
Validation loss: 2.5457542284156114

Epoch: 5| Step: 1
Training loss: 3.300709307185653
Validation loss: 2.5583687872589653

Epoch: 5| Step: 2
Training loss: 2.8284950646500184
Validation loss: 2.592549536102191

Epoch: 5| Step: 3
Training loss: 3.032802695367089
Validation loss: 2.587688141337095

Epoch: 5| Step: 4
Training loss: 2.2076243456059856
Validation loss: 2.5414940334808125

Epoch: 5| Step: 5
Training loss: 2.8655913272988407
Validation loss: 2.5192379670683422

Epoch: 5| Step: 6
Training loss: 3.3394842300099805
Validation loss: 2.516546656466257

Epoch: 5| Step: 7
Training loss: 2.903183170060218
Validation loss: 2.5157286838470156

Epoch: 5| Step: 8
Training loss: 2.5774854386933064
Validation loss: 2.5171477602481973

Epoch: 5| Step: 9
Training loss: 2.9936306413975418
Validation loss: 2.518208645411243

Epoch: 5| Step: 10
Training loss: 3.1519905280053195
Validation loss: 2.5157095298050343

Epoch: 84| Step: 0
Training loss: 2.924822457948937
Validation loss: 2.518242777053694

Epoch: 5| Step: 1
Training loss: 3.1562046765387506
Validation loss: 2.517882121060582

Epoch: 5| Step: 2
Training loss: 2.9222286234770634
Validation loss: 2.51902702483653

Epoch: 5| Step: 3
Training loss: 2.4348885656782135
Validation loss: 2.519831054839788

Epoch: 5| Step: 4
Training loss: 2.619944290558928
Validation loss: 2.518933190166741

Epoch: 5| Step: 5
Training loss: 2.917557407785178
Validation loss: 2.51980719600963

Epoch: 5| Step: 6
Training loss: 3.0461215139035116
Validation loss: 2.5212852203850376

Epoch: 5| Step: 7
Training loss: 2.7504015542674485
Validation loss: 2.515164675028571

Epoch: 5| Step: 8
Training loss: 2.8627604470186045
Validation loss: 2.5102284290719754

Epoch: 5| Step: 9
Training loss: 3.141111421636419
Validation loss: 2.5120003875877517

Epoch: 5| Step: 10
Training loss: 3.002520138484809
Validation loss: 2.514605970588603

Epoch: 85| Step: 0
Training loss: 2.643153317620682
Validation loss: 2.5133681030846295

Epoch: 5| Step: 1
Training loss: 3.065410554406282
Validation loss: 2.515381516112811

Epoch: 5| Step: 2
Training loss: 2.680906680163743
Validation loss: 2.519220049673568

Epoch: 5| Step: 3
Training loss: 2.6908241827383796
Validation loss: 2.5387991123194427

Epoch: 5| Step: 4
Training loss: 2.6222907117566754
Validation loss: 2.5420633847303895

Epoch: 5| Step: 5
Training loss: 3.072431381614008
Validation loss: 2.5276090190440894

Epoch: 5| Step: 6
Training loss: 2.6991867748083482
Validation loss: 2.5126793839135684

Epoch: 5| Step: 7
Training loss: 2.6433263200215467
Validation loss: 2.50473112027488

Epoch: 5| Step: 8
Training loss: 2.928588498295073
Validation loss: 2.5048028556681214

Epoch: 5| Step: 9
Training loss: 3.1319531715273357
Validation loss: 2.5078183503968074

Epoch: 5| Step: 10
Training loss: 3.6189531338459116
Validation loss: 2.511465249269594

Epoch: 86| Step: 0
Training loss: 3.301667838124493
Validation loss: 2.5182910799637215

Epoch: 5| Step: 1
Training loss: 3.146940495435451
Validation loss: 2.5255626112996112

Epoch: 5| Step: 2
Training loss: 3.194061258157366
Validation loss: 2.528631010282769

Epoch: 5| Step: 3
Training loss: 2.814050713175013
Validation loss: 2.5246199170401953

Epoch: 5| Step: 4
Training loss: 3.0100447657098304
Validation loss: 2.5228665284130445

Epoch: 5| Step: 5
Training loss: 2.9870828057922445
Validation loss: 2.516307104717831

Epoch: 5| Step: 6
Training loss: 2.507585366679528
Validation loss: 2.5116469467500226

Epoch: 5| Step: 7
Training loss: 2.9837888771212384
Validation loss: 2.5040052365354404

Epoch: 5| Step: 8
Training loss: 2.96129901863128
Validation loss: 2.511033529529449

Epoch: 5| Step: 9
Training loss: 2.314272433281522
Validation loss: 2.5350687685082374

Epoch: 5| Step: 10
Training loss: 2.542578882664755
Validation loss: 2.5607492952861985

Epoch: 87| Step: 0
Training loss: 3.1765134373228574
Validation loss: 2.58657658797318

Epoch: 5| Step: 1
Training loss: 3.1381034787429076
Validation loss: 2.5579025701416267

Epoch: 5| Step: 2
Training loss: 2.6824402308138064
Validation loss: 2.56403738404997

Epoch: 5| Step: 3
Training loss: 2.8617673777604744
Validation loss: 2.5842180435766995

Epoch: 5| Step: 4
Training loss: 2.9454075319860205
Validation loss: 2.5963588917014797

Epoch: 5| Step: 5
Training loss: 2.7881998389606117
Validation loss: 2.6143655235624745

Epoch: 5| Step: 6
Training loss: 3.039706831147328
Validation loss: 2.590513894823109

Epoch: 5| Step: 7
Training loss: 2.3958100580384074
Validation loss: 2.563307165061935

Epoch: 5| Step: 8
Training loss: 3.0303672212968915
Validation loss: 2.53447917365388

Epoch: 5| Step: 9
Training loss: 2.805558943248084
Validation loss: 2.5169925059342653

Epoch: 5| Step: 10
Training loss: 3.048146456966941
Validation loss: 2.522456652669286

Epoch: 88| Step: 0
Training loss: 2.8366963866037036
Validation loss: 2.531512575090713

Epoch: 5| Step: 1
Training loss: 2.6794557165325816
Validation loss: 2.538423451666831

Epoch: 5| Step: 2
Training loss: 3.0586790265390933
Validation loss: 2.537114683936989

Epoch: 5| Step: 3
Training loss: 2.5529993294798303
Validation loss: 2.5464155944276192

Epoch: 5| Step: 4
Training loss: 2.9871626212541345
Validation loss: 2.553667876350464

Epoch: 5| Step: 5
Training loss: 3.180930604620851
Validation loss: 2.542905465424481

Epoch: 5| Step: 6
Training loss: 2.672118237226463
Validation loss: 2.5305470815235824

Epoch: 5| Step: 7
Training loss: 3.093428161526843
Validation loss: 2.5129373784686315

Epoch: 5| Step: 8
Training loss: 2.9863891196150045
Validation loss: 2.5128278804975843

Epoch: 5| Step: 9
Training loss: 2.740668677718157
Validation loss: 2.511247807661978

Epoch: 5| Step: 10
Training loss: 3.1654455105808634
Validation loss: 2.5122442614181026

Epoch: 89| Step: 0
Training loss: 2.752283015624611
Validation loss: 2.5138554984895496

Epoch: 5| Step: 1
Training loss: 2.686739614394033
Validation loss: 2.51399810183789

Epoch: 5| Step: 2
Training loss: 2.4736978708319346
Validation loss: 2.514882430521532

Epoch: 5| Step: 3
Training loss: 3.4065072898635567
Validation loss: 2.5135352677027023

Epoch: 5| Step: 4
Training loss: 2.807191968479229
Validation loss: 2.512413064049215

Epoch: 5| Step: 5
Training loss: 2.7777535395094586
Validation loss: 2.5065726112391817

Epoch: 5| Step: 6
Training loss: 3.095832201074844
Validation loss: 2.5056780180253506

Epoch: 5| Step: 7
Training loss: 2.870338309415468
Validation loss: 2.5085195253218013

Epoch: 5| Step: 8
Training loss: 2.916811385424517
Validation loss: 2.515358314245477

Epoch: 5| Step: 9
Training loss: 2.852461999611654
Validation loss: 2.5225132167269133

Epoch: 5| Step: 10
Training loss: 3.020853678316906
Validation loss: 2.5241520622141653

Epoch: 90| Step: 0
Training loss: 3.122224872523126
Validation loss: 2.5198026401082254

Epoch: 5| Step: 1
Training loss: 3.3095744907671323
Validation loss: 2.520683385473658

Epoch: 5| Step: 2
Training loss: 3.078148856288423
Validation loss: 2.5048297129248143

Epoch: 5| Step: 3
Training loss: 2.5159379278752856
Validation loss: 2.502153649265562

Epoch: 5| Step: 4
Training loss: 2.945788438626658
Validation loss: 2.4994529628095283

Epoch: 5| Step: 5
Training loss: 3.2869576358508077
Validation loss: 2.4950076585657412

Epoch: 5| Step: 6
Training loss: 3.2922319015456196
Validation loss: 2.500548636830198

Epoch: 5| Step: 7
Training loss: 2.3695387038035993
Validation loss: 2.4995002667552466

Epoch: 5| Step: 8
Training loss: 2.646862450652115
Validation loss: 2.499011475978991

Epoch: 5| Step: 9
Training loss: 2.486052612478364
Validation loss: 2.5022638776402206

Epoch: 5| Step: 10
Training loss: 2.3421241716064904
Validation loss: 2.497577283952491

Epoch: 91| Step: 0
Training loss: 3.4206972926073664
Validation loss: 2.5079957194026745

Epoch: 5| Step: 1
Training loss: 2.9635054994509256
Validation loss: 2.5052385128620935

Epoch: 5| Step: 2
Training loss: 2.535980889871117
Validation loss: 2.508008650034967

Epoch: 5| Step: 3
Training loss: 2.648163817902003
Validation loss: 2.496968907294945

Epoch: 5| Step: 4
Training loss: 3.137994224256132
Validation loss: 2.4980235213633724

Epoch: 5| Step: 5
Training loss: 2.768033374502486
Validation loss: 2.4998717029014643

Epoch: 5| Step: 6
Training loss: 2.8943754043529397
Validation loss: 2.492746048885088

Epoch: 5| Step: 7
Training loss: 2.348106404592087
Validation loss: 2.498446816784345

Epoch: 5| Step: 8
Training loss: 2.827897289234652
Validation loss: 2.4930702950412296

Epoch: 5| Step: 9
Training loss: 2.5707879365924367
Validation loss: 2.495854679824213

Epoch: 5| Step: 10
Training loss: 3.4196501165851516
Validation loss: 2.4919635915015625

Epoch: 92| Step: 0
Training loss: 2.8796281465901594
Validation loss: 2.4955592492369965

Epoch: 5| Step: 1
Training loss: 3.062896858503812
Validation loss: 2.4970688279501085

Epoch: 5| Step: 2
Training loss: 2.980485228646697
Validation loss: 2.4960673153630513

Epoch: 5| Step: 3
Training loss: 2.3072120417395743
Validation loss: 2.4984498109240807

Epoch: 5| Step: 4
Training loss: 3.032054833603286
Validation loss: 2.4937746472615516

Epoch: 5| Step: 5
Training loss: 3.1139359497754926
Validation loss: 2.503573567714475

Epoch: 5| Step: 6
Training loss: 2.903664864561838
Validation loss: 2.5049878763775744

Epoch: 5| Step: 7
Training loss: 2.9728197010233366
Validation loss: 2.505173956904417

Epoch: 5| Step: 8
Training loss: 2.830639137911639
Validation loss: 2.5007020600323684

Epoch: 5| Step: 9
Training loss: 2.071748861440293
Validation loss: 2.5045003490302524

Epoch: 5| Step: 10
Training loss: 3.3542518052062658
Validation loss: 2.509227227009389

Epoch: 93| Step: 0
Training loss: 3.651516842179187
Validation loss: 2.4979398062851925

Epoch: 5| Step: 1
Training loss: 2.521099885661789
Validation loss: 2.4895098817788264

Epoch: 5| Step: 2
Training loss: 2.607897311523437
Validation loss: 2.487836593558931

Epoch: 5| Step: 3
Training loss: 2.201435171523933
Validation loss: 2.4885446945362455

Epoch: 5| Step: 4
Training loss: 2.599481890480868
Validation loss: 2.491275189999617

Epoch: 5| Step: 5
Training loss: 2.682264862420431
Validation loss: 2.4927514070535874

Epoch: 5| Step: 6
Training loss: 3.1061163460973518
Validation loss: 2.488041764529482

Epoch: 5| Step: 7
Training loss: 3.107032391819158
Validation loss: 2.4937368283163077

Epoch: 5| Step: 8
Training loss: 3.2482340489796426
Validation loss: 2.490470139958464

Epoch: 5| Step: 9
Training loss: 2.8105735963103866
Validation loss: 2.4920818923555474

Epoch: 5| Step: 10
Training loss: 2.810587084113434
Validation loss: 2.489329974222715

Epoch: 94| Step: 0
Training loss: 2.901999862649863
Validation loss: 2.4918852190825604

Epoch: 5| Step: 1
Training loss: 2.5853744769797395
Validation loss: 2.495563000864439

Epoch: 5| Step: 2
Training loss: 2.639022973206712
Validation loss: 2.498489170496612

Epoch: 5| Step: 3
Training loss: 2.751497901101883
Validation loss: 2.498520760109337

Epoch: 5| Step: 4
Training loss: 2.8713923500124396
Validation loss: 2.494902060348815

Epoch: 5| Step: 5
Training loss: 2.9974185645564186
Validation loss: 2.496135779037918

Epoch: 5| Step: 6
Training loss: 2.7520943382749685
Validation loss: 2.490591938391579

Epoch: 5| Step: 7
Training loss: 3.3124830137573027
Validation loss: 2.494053041114573

Epoch: 5| Step: 8
Training loss: 2.555255138550669
Validation loss: 2.492596087485915

Epoch: 5| Step: 9
Training loss: 3.189030747206495
Validation loss: 2.4937023263040725

Epoch: 5| Step: 10
Training loss: 2.8436420126732256
Validation loss: 2.4968776329287747

Epoch: 95| Step: 0
Training loss: 3.1080880880551556
Validation loss: 2.5143760546853344

Epoch: 5| Step: 1
Training loss: 2.3663112919804528
Validation loss: 2.53028752988139

Epoch: 5| Step: 2
Training loss: 2.825568882874976
Validation loss: 2.5479233033371145

Epoch: 5| Step: 3
Training loss: 2.8882997800621104
Validation loss: 2.528212905459401

Epoch: 5| Step: 4
Training loss: 2.762964898255441
Validation loss: 2.506512169050934

Epoch: 5| Step: 5
Training loss: 2.6756733447962175
Validation loss: 2.4994973395162474

Epoch: 5| Step: 6
Training loss: 3.450483459654122
Validation loss: 2.499861392413901

Epoch: 5| Step: 7
Training loss: 2.992602605885133
Validation loss: 2.497282681306706

Epoch: 5| Step: 8
Training loss: 2.628062051751759
Validation loss: 2.4936923943321445

Epoch: 5| Step: 9
Training loss: 3.071710709828562
Validation loss: 2.496030825798903

Epoch: 5| Step: 10
Training loss: 2.514838812575244
Validation loss: 2.4953690758387945

Epoch: 96| Step: 0
Training loss: 2.9346361200504045
Validation loss: 2.490563407263275

Epoch: 5| Step: 1
Training loss: 2.4816724364771057
Validation loss: 2.4906479024269625

Epoch: 5| Step: 2
Training loss: 3.037744545217236
Validation loss: 2.4863583111555956

Epoch: 5| Step: 3
Training loss: 3.0249477035163417
Validation loss: 2.4848179137645454

Epoch: 5| Step: 4
Training loss: 2.9591954725649052
Validation loss: 2.4865967592111375

Epoch: 5| Step: 5
Training loss: 2.5684249115331523
Validation loss: 2.4864469811260586

Epoch: 5| Step: 6
Training loss: 2.7853351551608125
Validation loss: 2.484929315032101

Epoch: 5| Step: 7
Training loss: 2.6397698276055843
Validation loss: 2.4867832891200985

Epoch: 5| Step: 8
Training loss: 3.027327683929143
Validation loss: 2.488654864339373

Epoch: 5| Step: 9
Training loss: 2.7848850455264533
Validation loss: 2.4898420183934387

Epoch: 5| Step: 10
Training loss: 3.2715875683351587
Validation loss: 2.4924504370296523

Epoch: 97| Step: 0
Training loss: 3.2203742808450118
Validation loss: 2.4871942661741624

Epoch: 5| Step: 1
Training loss: 2.2996202528553553
Validation loss: 2.4893967005077866

Epoch: 5| Step: 2
Training loss: 2.6584899433685467
Validation loss: 2.4853459201874974

Epoch: 5| Step: 3
Training loss: 3.01493898801293
Validation loss: 2.4848212281683906

Epoch: 5| Step: 4
Training loss: 2.896958953398087
Validation loss: 2.4868191107952704

Epoch: 5| Step: 5
Training loss: 3.2361488085412495
Validation loss: 2.4825512380913253

Epoch: 5| Step: 6
Training loss: 2.893948186098155
Validation loss: 2.488385881557136

Epoch: 5| Step: 7
Training loss: 2.5458080654690516
Validation loss: 2.4894303909741753

Epoch: 5| Step: 8
Training loss: 3.063279344693841
Validation loss: 2.4925168195586034

Epoch: 5| Step: 9
Training loss: 2.6989188572833127
Validation loss: 2.486563059219779

Epoch: 5| Step: 10
Training loss: 2.7709991481949023
Validation loss: 2.495983907513479

Epoch: 98| Step: 0
Training loss: 2.6634218223045014
Validation loss: 2.49563027546283

Epoch: 5| Step: 1
Training loss: 2.799012800301206
Validation loss: 2.5106039258656043

Epoch: 5| Step: 2
Training loss: 2.171302994524431
Validation loss: 2.5394500270091145

Epoch: 5| Step: 3
Training loss: 3.323031687564477
Validation loss: 2.6096291907331386

Epoch: 5| Step: 4
Training loss: 2.8652069152889172
Validation loss: 2.558081287927049

Epoch: 5| Step: 5
Training loss: 3.276951180954394
Validation loss: 2.506120004004246

Epoch: 5| Step: 6
Training loss: 3.0651940154608472
Validation loss: 2.4843441128076433

Epoch: 5| Step: 7
Training loss: 2.7072903507743673
Validation loss: 2.4840380135099305

Epoch: 5| Step: 8
Training loss: 2.531780140309092
Validation loss: 2.4845540322776967

Epoch: 5| Step: 9
Training loss: 3.097926701672909
Validation loss: 2.485335552533819

Epoch: 5| Step: 10
Training loss: 3.022878984619109
Validation loss: 2.4904512147316926

Epoch: 99| Step: 0
Training loss: 2.6792773052367935
Validation loss: 2.4964823226772275

Epoch: 5| Step: 1
Training loss: 2.9305299895398247
Validation loss: 2.4995514682674327

Epoch: 5| Step: 2
Training loss: 3.056330012422812
Validation loss: 2.506136569635251

Epoch: 5| Step: 3
Training loss: 2.6078846952891417
Validation loss: 2.505564661587514

Epoch: 5| Step: 4
Training loss: 3.114889191544082
Validation loss: 2.510063769175102

Epoch: 5| Step: 5
Training loss: 2.7197869614309993
Validation loss: 2.5144839487777464

Epoch: 5| Step: 6
Training loss: 2.838632191372371
Validation loss: 2.5013927876663535

Epoch: 5| Step: 7
Training loss: 3.154298689047466
Validation loss: 2.4928312228602807

Epoch: 5| Step: 8
Training loss: 2.993296923030087
Validation loss: 2.4901870448299355

Epoch: 5| Step: 9
Training loss: 2.392376924735336
Validation loss: 2.4965122997964073

Epoch: 5| Step: 10
Training loss: 3.1233013877198457
Validation loss: 2.4927530988337634

Epoch: 100| Step: 0
Training loss: 3.2226370146206245
Validation loss: 2.5010898839561824

Epoch: 5| Step: 1
Training loss: 2.6220846790225605
Validation loss: 2.5024990020294626

Epoch: 5| Step: 2
Training loss: 2.8882692377543857
Validation loss: 2.4924938172970843

Epoch: 5| Step: 3
Training loss: 2.9950347182565364
Validation loss: 2.4924353222603446

Epoch: 5| Step: 4
Training loss: 2.4814007307339168
Validation loss: 2.494277867967878

Epoch: 5| Step: 5
Training loss: 3.198814804416489
Validation loss: 2.4980173924856715

Epoch: 5| Step: 6
Training loss: 2.2041227637992282
Validation loss: 2.5004554969363118

Epoch: 5| Step: 7
Training loss: 3.417844584798285
Validation loss: 2.4921880709122566

Epoch: 5| Step: 8
Training loss: 2.9487247684914477
Validation loss: 2.5258034248178327

Epoch: 5| Step: 9
Training loss: 2.5820295879225927
Validation loss: 2.5185149910638245

Epoch: 5| Step: 10
Training loss: 2.715588364611917
Validation loss: 2.534151320352334

Epoch: 101| Step: 0
Training loss: 3.156995477546882
Validation loss: 2.5347638217286095

Epoch: 5| Step: 1
Training loss: 3.022406192708979
Validation loss: 2.5382241353489405

Epoch: 5| Step: 2
Training loss: 3.480645480308893
Validation loss: 2.539660684122519

Epoch: 5| Step: 3
Training loss: 2.5788589819892858
Validation loss: 2.541222790940223

Epoch: 5| Step: 4
Training loss: 2.754946508147907
Validation loss: 2.54930982899142

Epoch: 5| Step: 5
Training loss: 2.8832666716467803
Validation loss: 2.52135631296158

Epoch: 5| Step: 6
Training loss: 2.2133755131612807
Validation loss: 2.511660509788741

Epoch: 5| Step: 7
Training loss: 3.014842351837506
Validation loss: 2.5089979053892493

Epoch: 5| Step: 8
Training loss: 2.686731539133153
Validation loss: 2.5120227111615723

Epoch: 5| Step: 9
Training loss: 3.013888634966377
Validation loss: 2.5117478257108394

Epoch: 5| Step: 10
Training loss: 2.758072535545091
Validation loss: 2.5067634329312436

Epoch: 102| Step: 0
Training loss: 2.322103919839177
Validation loss: 2.506003166856426

Epoch: 5| Step: 1
Training loss: 3.31173610876186
Validation loss: 2.5119002791156224

Epoch: 5| Step: 2
Training loss: 2.6719896615393726
Validation loss: 2.5070898603015057

Epoch: 5| Step: 3
Training loss: 2.8743937309237118
Validation loss: 2.513580268837567

Epoch: 5| Step: 4
Training loss: 2.4362721407233123
Validation loss: 2.5192765978689686

Epoch: 5| Step: 5
Training loss: 3.050088918671749
Validation loss: 2.518436020799316

Epoch: 5| Step: 6
Training loss: 3.2718557391833984
Validation loss: 2.525983326708358

Epoch: 5| Step: 7
Training loss: 3.0563549749214425
Validation loss: 2.5103455679268984

Epoch: 5| Step: 8
Training loss: 3.086160154398373
Validation loss: 2.5099451902829513

Epoch: 5| Step: 9
Training loss: 2.6069046479036624
Validation loss: 2.5083150057671086

Epoch: 5| Step: 10
Training loss: 2.7333973908090172
Validation loss: 2.504219268409614

Epoch: 103| Step: 0
Training loss: 3.3791546151494662
Validation loss: 2.5109699847737756

Epoch: 5| Step: 1
Training loss: 2.3913514273988485
Validation loss: 2.508822543642829

Epoch: 5| Step: 2
Training loss: 2.918091634795333
Validation loss: 2.501945659347126

Epoch: 5| Step: 3
Training loss: 3.1107179434918883
Validation loss: 2.5066182426120647

Epoch: 5| Step: 4
Training loss: 3.007485587449393
Validation loss: 2.513330833973146

Epoch: 5| Step: 5
Training loss: 2.585876003121907
Validation loss: 2.5194723290430563

Epoch: 5| Step: 6
Training loss: 2.5843494529337843
Validation loss: 2.5247754831645137

Epoch: 5| Step: 7
Training loss: 2.7891026769143163
Validation loss: 2.5446345469346063

Epoch: 5| Step: 8
Training loss: 3.1375235811236437
Validation loss: 2.5693545261366877

Epoch: 5| Step: 9
Training loss: 2.7996945793606516
Validation loss: 2.5569681744474013

Epoch: 5| Step: 10
Training loss: 2.925628698876774
Validation loss: 2.53077769104635

Epoch: 104| Step: 0
Training loss: 2.9586295037820154
Validation loss: 2.51455080637103

Epoch: 5| Step: 1
Training loss: 2.7518656211136983
Validation loss: 2.5072642900747586

Epoch: 5| Step: 2
Training loss: 3.0568849118636905
Validation loss: 2.4960201456126225

Epoch: 5| Step: 3
Training loss: 2.985223779261459
Validation loss: 2.4915302922333993

Epoch: 5| Step: 4
Training loss: 2.287063298465734
Validation loss: 2.490277972996884

Epoch: 5| Step: 5
Training loss: 3.018485654388961
Validation loss: 2.4819394436896056

Epoch: 5| Step: 6
Training loss: 2.7719535188617397
Validation loss: 2.4698064746846047

Epoch: 5| Step: 7
Training loss: 3.0841440904751822
Validation loss: 2.465239850201725

Epoch: 5| Step: 8
Training loss: 2.8076779035554496
Validation loss: 2.462282680968262

Epoch: 5| Step: 9
Training loss: 2.5861646661927895
Validation loss: 2.4722066739905264

Epoch: 5| Step: 10
Training loss: 3.0382818087172443
Validation loss: 2.4771480254377978

Epoch: 105| Step: 0
Training loss: 2.4699156701213476
Validation loss: 2.4884533862443323

Epoch: 5| Step: 1
Training loss: 2.7204807078303728
Validation loss: 2.4882350103473185

Epoch: 5| Step: 2
Training loss: 3.284122481288865
Validation loss: 2.508208805675617

Epoch: 5| Step: 3
Training loss: 2.878044341010194
Validation loss: 2.501621114510641

Epoch: 5| Step: 4
Training loss: 2.9909681420295575
Validation loss: 2.5094744698290476

Epoch: 5| Step: 5
Training loss: 3.1698644119291046
Validation loss: 2.506041523938838

Epoch: 5| Step: 6
Training loss: 2.8446442591831604
Validation loss: 2.4943517313783565

Epoch: 5| Step: 7
Training loss: 2.580684708957512
Validation loss: 2.4752259847456513

Epoch: 5| Step: 8
Training loss: 3.1124332282935705
Validation loss: 2.477789644206511

Epoch: 5| Step: 9
Training loss: 2.4346003769641364
Validation loss: 2.4755795138557013

Epoch: 5| Step: 10
Training loss: 2.8756961808891206
Validation loss: 2.477911949022934

Epoch: 106| Step: 0
Training loss: 3.339781786249027
Validation loss: 2.475831585117498

Epoch: 5| Step: 1
Training loss: 3.051117589094276
Validation loss: 2.4706801676434456

Epoch: 5| Step: 2
Training loss: 2.5420937622269895
Validation loss: 2.4709501627494843

Epoch: 5| Step: 3
Training loss: 2.2972262366968472
Validation loss: 2.4694942818183616

Epoch: 5| Step: 4
Training loss: 2.877882134776377
Validation loss: 2.470576379052482

Epoch: 5| Step: 5
Training loss: 3.1140815730451092
Validation loss: 2.466045315001579

Epoch: 5| Step: 6
Training loss: 2.7646943158945
Validation loss: 2.4671893781000094

Epoch: 5| Step: 7
Training loss: 2.847703470223206
Validation loss: 2.464414905436398

Epoch: 5| Step: 8
Training loss: 2.647349536427648
Validation loss: 2.4658110355026834

Epoch: 5| Step: 9
Training loss: 2.934637744909524
Validation loss: 2.466998285547215

Epoch: 5| Step: 10
Training loss: 2.811691846239201
Validation loss: 2.4654712995244537

Epoch: 107| Step: 0
Training loss: 3.180663462830002
Validation loss: 2.4693378461498505

Epoch: 5| Step: 1
Training loss: 2.398158451708972
Validation loss: 2.4712468464169857

Epoch: 5| Step: 2
Training loss: 2.8981689986820776
Validation loss: 2.4712645016521093

Epoch: 5| Step: 3
Training loss: 2.5070230067216555
Validation loss: 2.4661552747029045

Epoch: 5| Step: 4
Training loss: 2.763398993401897
Validation loss: 2.464231425269299

Epoch: 5| Step: 5
Training loss: 2.8162870553834374
Validation loss: 2.463641321134793

Epoch: 5| Step: 6
Training loss: 2.910769977755597
Validation loss: 2.4632628159313144

Epoch: 5| Step: 7
Training loss: 3.2802436375265183
Validation loss: 2.4636628003805927

Epoch: 5| Step: 8
Training loss: 2.6200711434292887
Validation loss: 2.463134795157815

Epoch: 5| Step: 9
Training loss: 2.990774592980157
Validation loss: 2.4624922479965883

Epoch: 5| Step: 10
Training loss: 2.8135590148940803
Validation loss: 2.460819519829731

Epoch: 108| Step: 0
Training loss: 2.628807576157094
Validation loss: 2.465092296363811

Epoch: 5| Step: 1
Training loss: 2.5242198758726406
Validation loss: 2.4599209208183166

Epoch: 5| Step: 2
Training loss: 2.826383950502256
Validation loss: 2.469190453101539

Epoch: 5| Step: 3
Training loss: 3.1011073934047637
Validation loss: 2.4677366692912237

Epoch: 5| Step: 4
Training loss: 2.8023985977271706
Validation loss: 2.477698151679513

Epoch: 5| Step: 5
Training loss: 2.7799531291880046
Validation loss: 2.4806006291472773

Epoch: 5| Step: 6
Training loss: 3.2313344918572886
Validation loss: 2.480757724891013

Epoch: 5| Step: 7
Training loss: 2.900695086082278
Validation loss: 2.489721889470024

Epoch: 5| Step: 8
Training loss: 2.438846118622457
Validation loss: 2.486315957017478

Epoch: 5| Step: 9
Training loss: 3.139893252022151
Validation loss: 2.4742001899842623

Epoch: 5| Step: 10
Training loss: 2.811939522739975
Validation loss: 2.4641706727756625

Epoch: 109| Step: 0
Training loss: 2.6152615421129077
Validation loss: 2.474728093148212

Epoch: 5| Step: 1
Training loss: 3.010689763724179
Validation loss: 2.4695280808197357

Epoch: 5| Step: 2
Training loss: 2.695146019258421
Validation loss: 2.4722080096265318

Epoch: 5| Step: 3
Training loss: 2.7425462102343867
Validation loss: 2.4737786848366126

Epoch: 5| Step: 4
Training loss: 2.841509596733764
Validation loss: 2.4802388438742113

Epoch: 5| Step: 5
Training loss: 2.679150941920273
Validation loss: 2.464677542346828

Epoch: 5| Step: 6
Training loss: 2.932428893180875
Validation loss: 2.477094316844141

Epoch: 5| Step: 7
Training loss: 2.505039571575162
Validation loss: 2.4780834627406856

Epoch: 5| Step: 8
Training loss: 3.2148519077869615
Validation loss: 2.490117067376539

Epoch: 5| Step: 9
Training loss: 2.819704872677324
Validation loss: 2.495812132464224

Epoch: 5| Step: 10
Training loss: 3.1639267127016657
Validation loss: 2.4863939688272856

Epoch: 110| Step: 0
Training loss: 3.270527203725359
Validation loss: 2.4789814725185315

Epoch: 5| Step: 1
Training loss: 3.032121041591885
Validation loss: 2.4680861658862407

Epoch: 5| Step: 2
Training loss: 3.0350995346917107
Validation loss: 2.4640478232362253

Epoch: 5| Step: 3
Training loss: 2.754097400280966
Validation loss: 2.458396894809221

Epoch: 5| Step: 4
Training loss: 2.901256907141343
Validation loss: 2.462483379057439

Epoch: 5| Step: 5
Training loss: 2.980038993119502
Validation loss: 2.458981629935969

Epoch: 5| Step: 6
Training loss: 2.671724549457947
Validation loss: 2.458077872302489

Epoch: 5| Step: 7
Training loss: 2.5697894738204337
Validation loss: 2.459775463794857

Epoch: 5| Step: 8
Training loss: 2.5937389695266204
Validation loss: 2.4625703295120687

Epoch: 5| Step: 9
Training loss: 2.594952775529174
Validation loss: 2.464012262519937

Epoch: 5| Step: 10
Training loss: 2.715660707789908
Validation loss: 2.470325549258943

Epoch: 111| Step: 0
Training loss: 2.5184190291292903
Validation loss: 2.4648122061787334

Epoch: 5| Step: 1
Training loss: 3.0633907968847978
Validation loss: 2.482115808220739

Epoch: 5| Step: 2
Training loss: 2.4961477163388084
Validation loss: 2.4716176016523628

Epoch: 5| Step: 3
Training loss: 1.9835627538025373
Validation loss: 2.484014339301866

Epoch: 5| Step: 4
Training loss: 3.348146062246715
Validation loss: 2.4888134222093994

Epoch: 5| Step: 5
Training loss: 2.192149099284178
Validation loss: 2.4889480934387036

Epoch: 5| Step: 6
Training loss: 2.821512405571037
Validation loss: 2.5088027043441654

Epoch: 5| Step: 7
Training loss: 3.1964521171268876
Validation loss: 2.517276647440484

Epoch: 5| Step: 8
Training loss: 3.170625337119059
Validation loss: 2.472856260636041

Epoch: 5| Step: 9
Training loss: 3.2185108873752966
Validation loss: 2.4567811096731003

Epoch: 5| Step: 10
Training loss: 2.8928934629874985
Validation loss: 2.4552200021467834

Epoch: 112| Step: 0
Training loss: 3.1363018894274157
Validation loss: 2.455104070586674

Epoch: 5| Step: 1
Training loss: 2.844973290557719
Validation loss: 2.4590916052496437

Epoch: 5| Step: 2
Training loss: 3.1564542496566905
Validation loss: 2.452573738472706

Epoch: 5| Step: 3
Training loss: 3.082051362913619
Validation loss: 2.4530257035184766

Epoch: 5| Step: 4
Training loss: 2.1947240074626935
Validation loss: 2.4568703864164863

Epoch: 5| Step: 5
Training loss: 2.71522969308756
Validation loss: 2.4592263351943537

Epoch: 5| Step: 6
Training loss: 2.8184171526637862
Validation loss: 2.468520032671184

Epoch: 5| Step: 7
Training loss: 2.737598023771624
Validation loss: 2.4747323052287156

Epoch: 5| Step: 8
Training loss: 2.829020490133246
Validation loss: 2.4585294271618467

Epoch: 5| Step: 9
Training loss: 3.1325424724844426
Validation loss: 2.4572232209536886

Epoch: 5| Step: 10
Training loss: 2.434889544854569
Validation loss: 2.4548598754964486

Epoch: 113| Step: 0
Training loss: 2.750569891400331
Validation loss: 2.4518362139500383

Epoch: 5| Step: 1
Training loss: 2.213375944029978
Validation loss: 2.4509216586162843

Epoch: 5| Step: 2
Training loss: 2.3424831781424538
Validation loss: 2.4536328923521156

Epoch: 5| Step: 3
Training loss: 3.0250258893883415
Validation loss: 2.4521290617807816

Epoch: 5| Step: 4
Training loss: 3.1735117029767927
Validation loss: 2.4524268850022963

Epoch: 5| Step: 5
Training loss: 3.0539498377529437
Validation loss: 2.4498076641117996

Epoch: 5| Step: 6
Training loss: 2.9153702897559346
Validation loss: 2.4577091155217894

Epoch: 5| Step: 7
Training loss: 3.0028258366188867
Validation loss: 2.4599443016529765

Epoch: 5| Step: 8
Training loss: 2.857844876147165
Validation loss: 2.4507807659296827

Epoch: 5| Step: 9
Training loss: 2.7871773811068543
Validation loss: 2.4624937044609454

Epoch: 5| Step: 10
Training loss: 2.8670622670943153
Validation loss: 2.472835652781996

Epoch: 114| Step: 0
Training loss: 2.81882173231248
Validation loss: 2.4805697528331296

Epoch: 5| Step: 1
Training loss: 2.625902747283246
Validation loss: 2.4893079795833937

Epoch: 5| Step: 2
Training loss: 3.11523498726483
Validation loss: 2.520390262038212

Epoch: 5| Step: 3
Training loss: 2.234575062578259
Validation loss: 2.54544747284297

Epoch: 5| Step: 4
Training loss: 2.800804148730703
Validation loss: 2.5956583209558204

Epoch: 5| Step: 5
Training loss: 2.2544483081731665
Validation loss: 2.6281758359571

Epoch: 5| Step: 6
Training loss: 3.3592147434068242
Validation loss: 2.5429687116910964

Epoch: 5| Step: 7
Training loss: 2.9134825264842257
Validation loss: 2.4588042347523595

Epoch: 5| Step: 8
Training loss: 2.7865281331004104
Validation loss: 2.455165409762641

Epoch: 5| Step: 9
Training loss: 2.7868549575649597
Validation loss: 2.4736289934113356

Epoch: 5| Step: 10
Training loss: 3.2506444732194217
Validation loss: 2.484529543704594

Epoch: 115| Step: 0
Training loss: 3.013101579424379
Validation loss: 2.49690730549789

Epoch: 5| Step: 1
Training loss: 2.605466828352693
Validation loss: 2.4954147497607098

Epoch: 5| Step: 2
Training loss: 2.6602966002691897
Validation loss: 2.4910532145535296

Epoch: 5| Step: 3
Training loss: 2.9690832653710713
Validation loss: 2.4883250697263373

Epoch: 5| Step: 4
Training loss: 2.906922621467119
Validation loss: 2.469837829125497

Epoch: 5| Step: 5
Training loss: 2.9586662499162615
Validation loss: 2.461425709905421

Epoch: 5| Step: 6
Training loss: 3.0565112979330027
Validation loss: 2.454775283689366

Epoch: 5| Step: 7
Training loss: 2.934771630209815
Validation loss: 2.4491665705664456

Epoch: 5| Step: 8
Training loss: 2.807301782555599
Validation loss: 2.4771426107502914

Epoch: 5| Step: 9
Training loss: 2.7722194522120978
Validation loss: 2.535129718068753

Epoch: 5| Step: 10
Training loss: 3.074661242425947
Validation loss: 2.6417808966334877

Epoch: 116| Step: 0
Training loss: 2.9879549135026306
Validation loss: 2.5730531276109554

Epoch: 5| Step: 1
Training loss: 2.725595997019908
Validation loss: 2.503287171342018

Epoch: 5| Step: 2
Training loss: 2.512327888628972
Validation loss: 2.4589413179059254

Epoch: 5| Step: 3
Training loss: 3.4409420466754597
Validation loss: 2.457165332327619

Epoch: 5| Step: 4
Training loss: 3.2241149930016677
Validation loss: 2.4725567072655372

Epoch: 5| Step: 5
Training loss: 2.7565011426901496
Validation loss: 2.476662421547131

Epoch: 5| Step: 6
Training loss: 2.7723286735908608
Validation loss: 2.487494057252327

Epoch: 5| Step: 7
Training loss: 2.501675139922605
Validation loss: 2.491833130615168

Epoch: 5| Step: 8
Training loss: 2.8444384066530892
Validation loss: 2.4980057956062773

Epoch: 5| Step: 9
Training loss: 2.806151451640388
Validation loss: 2.507319304287523

Epoch: 5| Step: 10
Training loss: 2.9726721303267514
Validation loss: 2.504388292565512

Epoch: 117| Step: 0
Training loss: 3.3310229082696927
Validation loss: 2.5037973154441864

Epoch: 5| Step: 1
Training loss: 2.908246738780589
Validation loss: 2.4965497193455333

Epoch: 5| Step: 2
Training loss: 3.313183983776265
Validation loss: 2.496044675514173

Epoch: 5| Step: 3
Training loss: 2.5088801978082462
Validation loss: 2.495439317460479

Epoch: 5| Step: 4
Training loss: 2.847876269470958
Validation loss: 2.493241132046262

Epoch: 5| Step: 5
Training loss: 2.82630094432512
Validation loss: 2.4935303066906562

Epoch: 5| Step: 6
Training loss: 3.1176111989811517
Validation loss: 2.487629395568543

Epoch: 5| Step: 7
Training loss: 2.8855285255609884
Validation loss: 2.4784875020299504

Epoch: 5| Step: 8
Training loss: 2.8668412251517337
Validation loss: 2.4713428682524374

Epoch: 5| Step: 9
Training loss: 2.7125022395955347
Validation loss: 2.4705974861883933

Epoch: 5| Step: 10
Training loss: 2.365558630391473
Validation loss: 2.4830993516374376

Epoch: 118| Step: 0
Training loss: 2.800065676736327
Validation loss: 2.477198588857728

Epoch: 5| Step: 1
Training loss: 2.9749934348667058
Validation loss: 2.475172794782297

Epoch: 5| Step: 2
Training loss: 2.915929610356483
Validation loss: 2.49610542354845

Epoch: 5| Step: 3
Training loss: 2.878925463173676
Validation loss: 2.5008533108488025

Epoch: 5| Step: 4
Training loss: 2.504543943330743
Validation loss: 2.5006836069337623

Epoch: 5| Step: 5
Training loss: 2.5324107205017143
Validation loss: 2.5373414765249183

Epoch: 5| Step: 6
Training loss: 2.7543145925373715
Validation loss: 2.548406766798952

Epoch: 5| Step: 7
Training loss: 2.5947215087749522
Validation loss: 2.5824317695335215

Epoch: 5| Step: 8
Training loss: 3.533636181526207
Validation loss: 2.587883878804734

Epoch: 5| Step: 9
Training loss: 3.134265439066911
Validation loss: 2.499970384647965

Epoch: 5| Step: 10
Training loss: 2.4538772304389336
Validation loss: 2.448332191306799

Epoch: 119| Step: 0
Training loss: 2.8565589921289383
Validation loss: 2.4423114879214416

Epoch: 5| Step: 1
Training loss: 2.809827594558965
Validation loss: 2.4497026976520937

Epoch: 5| Step: 2
Training loss: 2.6964827056618765
Validation loss: 2.4568489370037563

Epoch: 5| Step: 3
Training loss: 2.9669690060232576
Validation loss: 2.4613186094662494

Epoch: 5| Step: 4
Training loss: 2.8997355636525426
Validation loss: 2.473953847746137

Epoch: 5| Step: 5
Training loss: 3.2750164584845565
Validation loss: 2.473097771719624

Epoch: 5| Step: 6
Training loss: 2.856603728246095
Validation loss: 2.4691078328579827

Epoch: 5| Step: 7
Training loss: 2.4716717777555184
Validation loss: 2.460239531357756

Epoch: 5| Step: 8
Training loss: 2.898384361088441
Validation loss: 2.4558505004379443

Epoch: 5| Step: 9
Training loss: 2.761428666695919
Validation loss: 2.463698743346103

Epoch: 5| Step: 10
Training loss: 2.666257161248413
Validation loss: 2.4737376573949232

Epoch: 120| Step: 0
Training loss: 3.276095310534114
Validation loss: 2.552529049279258

Epoch: 5| Step: 1
Training loss: 3.127929230165046
Validation loss: 2.624944262442649

Epoch: 5| Step: 2
Training loss: 2.52046089468634
Validation loss: 2.6764545266388

Epoch: 5| Step: 3
Training loss: 3.052144194290181
Validation loss: 2.6988304213465972

Epoch: 5| Step: 4
Training loss: 3.088933412732605
Validation loss: 2.6384409735010643

Epoch: 5| Step: 5
Training loss: 2.539634663597963
Validation loss: 2.5303434437136723

Epoch: 5| Step: 6
Training loss: 2.5281021890448128
Validation loss: 2.4778324575798143

Epoch: 5| Step: 7
Training loss: 3.2185637781290395
Validation loss: 2.462507750604797

Epoch: 5| Step: 8
Training loss: 2.4076740955377427
Validation loss: 2.452240149390591

Epoch: 5| Step: 9
Training loss: 2.721895086869095
Validation loss: 2.4529350211901244

Epoch: 5| Step: 10
Training loss: 3.214615916896459
Validation loss: 2.456898894562391

Epoch: 121| Step: 0
Training loss: 2.9833583198509737
Validation loss: 2.4640771441324563

Epoch: 5| Step: 1
Training loss: 2.8196880462926677
Validation loss: 2.4591462772720463

Epoch: 5| Step: 2
Training loss: 2.504639992647114
Validation loss: 2.46205063513424

Epoch: 5| Step: 3
Training loss: 2.449900360416819
Validation loss: 2.4692637754087157

Epoch: 5| Step: 4
Training loss: 3.0652014825756853
Validation loss: 2.479604412702118

Epoch: 5| Step: 5
Training loss: 3.054878092329804
Validation loss: 2.4952727713740592

Epoch: 5| Step: 6
Training loss: 3.1013821566251885
Validation loss: 2.49011247568568

Epoch: 5| Step: 7
Training loss: 2.7692821912596557
Validation loss: 2.4858952171103166

Epoch: 5| Step: 8
Training loss: 3.0717304246163386
Validation loss: 2.481293906662369

Epoch: 5| Step: 9
Training loss: 2.3298320272581963
Validation loss: 2.4743300564850648

Epoch: 5| Step: 10
Training loss: 2.846093689685269
Validation loss: 2.463698330241449

Epoch: 122| Step: 0
Training loss: 3.242753092139016
Validation loss: 2.459258000700484

Epoch: 5| Step: 1
Training loss: 3.181464820908326
Validation loss: 2.463150296844344

Epoch: 5| Step: 2
Training loss: 2.7996674135775392
Validation loss: 2.466105131458424

Epoch: 5| Step: 3
Training loss: 2.7428751460971816
Validation loss: 2.468406015681352

Epoch: 5| Step: 4
Training loss: 2.603230900802748
Validation loss: 2.4821119815274617

Epoch: 5| Step: 5
Training loss: 3.1405888645503564
Validation loss: 2.507747969923074

Epoch: 5| Step: 6
Training loss: 2.7344256587104203
Validation loss: 2.5126628032619767

Epoch: 5| Step: 7
Training loss: 2.7322282483944242
Validation loss: 2.4983302231366706

Epoch: 5| Step: 8
Training loss: 2.29523684673656
Validation loss: 2.4751325558751454

Epoch: 5| Step: 9
Training loss: 2.9355190983902935
Validation loss: 2.4638166335081286

Epoch: 5| Step: 10
Training loss: 2.5524656567332085
Validation loss: 2.464563559794538

Epoch: 123| Step: 0
Training loss: 2.72018920689151
Validation loss: 2.4608509971102746

Epoch: 5| Step: 1
Training loss: 2.8923944779438435
Validation loss: 2.4584080987333237

Epoch: 5| Step: 2
Training loss: 2.8086288089182236
Validation loss: 2.4607369216977943

Epoch: 5| Step: 3
Training loss: 2.6350325554532223
Validation loss: 2.4573117951628864

Epoch: 5| Step: 4
Training loss: 3.0619292992540457
Validation loss: 2.4524272435567873

Epoch: 5| Step: 5
Training loss: 3.220383313032989
Validation loss: 2.4582307695782246

Epoch: 5| Step: 6
Training loss: 2.6860356444424434
Validation loss: 2.4514550713875685

Epoch: 5| Step: 7
Training loss: 2.6257500258192135
Validation loss: 2.466812688312914

Epoch: 5| Step: 8
Training loss: 2.272207550098872
Validation loss: 2.456333719180655

Epoch: 5| Step: 9
Training loss: 2.5257461427419194
Validation loss: 2.4627759539092295

Epoch: 5| Step: 10
Training loss: 3.3404471939771048
Validation loss: 2.4589121901606776

Epoch: 124| Step: 0
Training loss: 2.9400304081700166
Validation loss: 2.4636096255986977

Epoch: 5| Step: 1
Training loss: 2.6480891806057367
Validation loss: 2.471858655039267

Epoch: 5| Step: 2
Training loss: 3.0852195194235734
Validation loss: 2.462272983545588

Epoch: 5| Step: 3
Training loss: 3.5054801544554848
Validation loss: 2.4558972256058014

Epoch: 5| Step: 4
Training loss: 3.0171459098331894
Validation loss: 2.453441763755993

Epoch: 5| Step: 5
Training loss: 2.679457585116707
Validation loss: 2.455797468106475

Epoch: 5| Step: 6
Training loss: 2.6297123708925825
Validation loss: 2.450483865193059

Epoch: 5| Step: 7
Training loss: 2.125711882783261
Validation loss: 2.4476459473041037

Epoch: 5| Step: 8
Training loss: 2.7261023365383377
Validation loss: 2.4450638784987464

Epoch: 5| Step: 9
Training loss: 2.8980258536228765
Validation loss: 2.450051074681196

Epoch: 5| Step: 10
Training loss: 2.464808927794832
Validation loss: 2.463828770056895

Epoch: 125| Step: 0
Training loss: 2.34663660944127
Validation loss: 2.458815434735098

Epoch: 5| Step: 1
Training loss: 3.137985714706669
Validation loss: 2.4753406632029646

Epoch: 5| Step: 2
Training loss: 2.955826588284117
Validation loss: 2.4625459450503593

Epoch: 5| Step: 3
Training loss: 2.9956004944055072
Validation loss: 2.465785290950529

Epoch: 5| Step: 4
Training loss: 2.9045152306324002
Validation loss: 2.4656254892660554

Epoch: 5| Step: 5
Training loss: 2.98046667016433
Validation loss: 2.470708602567813

Epoch: 5| Step: 6
Training loss: 2.8903052900688198
Validation loss: 2.460796680708856

Epoch: 5| Step: 7
Training loss: 2.9397022838754037
Validation loss: 2.454634728124922

Epoch: 5| Step: 8
Training loss: 2.5486255082899776
Validation loss: 2.4415645088995017

Epoch: 5| Step: 9
Training loss: 2.0922438485019472
Validation loss: 2.443842139981643

Epoch: 5| Step: 10
Training loss: 2.9577924386143657
Validation loss: 2.446796122194672

Epoch: 126| Step: 0
Training loss: 3.320108708130092
Validation loss: 2.4323086774991447

Epoch: 5| Step: 1
Training loss: 3.1576959300621326
Validation loss: 2.43503451125447

Epoch: 5| Step: 2
Training loss: 2.741042634467495
Validation loss: 2.4332670179015534

Epoch: 5| Step: 3
Training loss: 2.831930561248872
Validation loss: 2.44195111527462

Epoch: 5| Step: 4
Training loss: 2.4180710975789728
Validation loss: 2.4411088696573153

Epoch: 5| Step: 5
Training loss: 2.744395701000837
Validation loss: 2.445881671668578

Epoch: 5| Step: 6
Training loss: 2.51386289307962
Validation loss: 2.440080016122124

Epoch: 5| Step: 7
Training loss: 2.782901145212869
Validation loss: 2.454731973134871

Epoch: 5| Step: 8
Training loss: 2.752863520178576
Validation loss: 2.450647862123206

Epoch: 5| Step: 9
Training loss: 2.686171802289648
Validation loss: 2.457462338641872

Epoch: 5| Step: 10
Training loss: 2.8782106798902807
Validation loss: 2.4553754318146406

Epoch: 127| Step: 0
Training loss: 2.6924947411672653
Validation loss: 2.4582435813302888

Epoch: 5| Step: 1
Training loss: 2.745961344797629
Validation loss: 2.4603465516478873

Epoch: 5| Step: 2
Training loss: 2.7736211151806893
Validation loss: 2.4773179300838417

Epoch: 5| Step: 3
Training loss: 2.9956667122025014
Validation loss: 2.506900969646007

Epoch: 5| Step: 4
Training loss: 3.4391004131329646
Validation loss: 2.5001347372191534

Epoch: 5| Step: 5
Training loss: 2.2026862390693878
Validation loss: 2.4431357428401523

Epoch: 5| Step: 6
Training loss: 3.24070496271961
Validation loss: 2.4268076215146746

Epoch: 5| Step: 7
Training loss: 2.4172293128630464
Validation loss: 2.4354021743669825

Epoch: 5| Step: 8
Training loss: 2.8125103420491278
Validation loss: 2.43829363704375

Epoch: 5| Step: 9
Training loss: 3.113490768906567
Validation loss: 2.4362281129270658

Epoch: 5| Step: 10
Training loss: 2.4525968140946697
Validation loss: 2.435530640797447

Epoch: 128| Step: 0
Training loss: 2.9900551311806947
Validation loss: 2.431652282194024

Epoch: 5| Step: 1
Training loss: 2.796796744333376
Validation loss: 2.4316072914634974

Epoch: 5| Step: 2
Training loss: 3.171293759763951
Validation loss: 2.4272425771524446

Epoch: 5| Step: 3
Training loss: 2.4830327276622524
Validation loss: 2.4388191628086227

Epoch: 5| Step: 4
Training loss: 3.336990511863876
Validation loss: 2.4415159900571397

Epoch: 5| Step: 5
Training loss: 2.187852449634031
Validation loss: 2.4584156778294988

Epoch: 5| Step: 6
Training loss: 2.650481119206293
Validation loss: 2.4925061310005976

Epoch: 5| Step: 7
Training loss: 2.6008940516698242
Validation loss: 2.5485668721904275

Epoch: 5| Step: 8
Training loss: 2.96413359850853
Validation loss: 2.5738662512490036

Epoch: 5| Step: 9
Training loss: 3.0735107537263446
Validation loss: 2.5795528014341897

Epoch: 5| Step: 10
Training loss: 2.6913091589435933
Validation loss: 2.55522526566441

Epoch: 129| Step: 0
Training loss: 3.106179747372299
Validation loss: 2.4885102348887336

Epoch: 5| Step: 1
Training loss: 2.8648662265616784
Validation loss: 2.450181484553276

Epoch: 5| Step: 2
Training loss: 2.7960065633563063
Validation loss: 2.430173157135492

Epoch: 5| Step: 3
Training loss: 3.0043948089981383
Validation loss: 2.431232847393707

Epoch: 5| Step: 4
Training loss: 3.0325957781454305
Validation loss: 2.435551095895991

Epoch: 5| Step: 5
Training loss: 2.655043114637176
Validation loss: 2.4293448998613405

Epoch: 5| Step: 6
Training loss: 2.773269003464354
Validation loss: 2.4320104134724065

Epoch: 5| Step: 7
Training loss: 2.780839011011528
Validation loss: 2.4299578456107924

Epoch: 5| Step: 8
Training loss: 3.0176174716791557
Validation loss: 2.4337117680343696

Epoch: 5| Step: 9
Training loss: 2.1793925861757293
Validation loss: 2.443448014257051

Epoch: 5| Step: 10
Training loss: 2.677847361111234
Validation loss: 2.4403475285480187

Epoch: 130| Step: 0
Training loss: 3.2635804122993424
Validation loss: 2.4553735754163424

Epoch: 5| Step: 1
Training loss: 2.8376357193136865
Validation loss: 2.475248361371428

Epoch: 5| Step: 2
Training loss: 2.807260507234937
Validation loss: 2.48335963467417

Epoch: 5| Step: 3
Training loss: 3.3721654786292428
Validation loss: 2.5108313211440785

Epoch: 5| Step: 4
Training loss: 2.7284018534462917
Validation loss: 2.556742777892832

Epoch: 5| Step: 5
Training loss: 2.9123009478611728
Validation loss: 2.5360410168911347

Epoch: 5| Step: 6
Training loss: 2.3634744360283486
Validation loss: 2.524210853115024

Epoch: 5| Step: 7
Training loss: 2.332472256314542
Validation loss: 2.508118358401181

Epoch: 5| Step: 8
Training loss: 2.2680875877812054
Validation loss: 2.510805928955918

Epoch: 5| Step: 9
Training loss: 2.923557062522835
Validation loss: 2.49936347569593

Epoch: 5| Step: 10
Training loss: 2.8750313466892496
Validation loss: 2.488012358716577

Epoch: 131| Step: 0
Training loss: 3.212954887512723
Validation loss: 2.4749852137467303

Epoch: 5| Step: 1
Training loss: 2.9986187616199333
Validation loss: 2.4679290488551566

Epoch: 5| Step: 2
Training loss: 2.9278617357846786
Validation loss: 2.4481468806323496

Epoch: 5| Step: 3
Training loss: 2.7630080433416766
Validation loss: 2.447836840359361

Epoch: 5| Step: 4
Training loss: 2.4687582088285698
Validation loss: 2.441880015355825

Epoch: 5| Step: 5
Training loss: 2.754616330634414
Validation loss: 2.4404438501300216

Epoch: 5| Step: 6
Training loss: 3.2421160218965754
Validation loss: 2.435556567261005

Epoch: 5| Step: 7
Training loss: 2.1531422651730905
Validation loss: 2.4351084651146806

Epoch: 5| Step: 8
Training loss: 2.769651940302673
Validation loss: 2.4411080063967696

Epoch: 5| Step: 9
Training loss: 2.836069151289509
Validation loss: 2.453817386495614

Epoch: 5| Step: 10
Training loss: 2.456574074524167
Validation loss: 2.4994264201037404

Epoch: 132| Step: 0
Training loss: 2.480068192467362
Validation loss: 2.552257507956996

Epoch: 5| Step: 1
Training loss: 2.5598589615415572
Validation loss: 2.60983370386205

Epoch: 5| Step: 2
Training loss: 2.877467216351345
Validation loss: 2.6628216555480653

Epoch: 5| Step: 3
Training loss: 3.140754810895866
Validation loss: 2.7007671246303446

Epoch: 5| Step: 4
Training loss: 2.8200243858202882
Validation loss: 2.6761793874685025

Epoch: 5| Step: 5
Training loss: 2.7552995768812174
Validation loss: 2.6499984873935487

Epoch: 5| Step: 6
Training loss: 2.794088925961015
Validation loss: 2.5402815696165186

Epoch: 5| Step: 7
Training loss: 2.9075896754256934
Validation loss: 2.489307536743223

Epoch: 5| Step: 8
Training loss: 3.031320944673576
Validation loss: 2.449524562981128

Epoch: 5| Step: 9
Training loss: 2.970906167298964
Validation loss: 2.443541134368975

Epoch: 5| Step: 10
Training loss: 2.4155695386987026
Validation loss: 2.440275502593755

Epoch: 133| Step: 0
Training loss: 2.770590683104757
Validation loss: 2.4544671972439316

Epoch: 5| Step: 1
Training loss: 2.578815344658889
Validation loss: 2.4490038201159976

Epoch: 5| Step: 2
Training loss: 2.9069311512765004
Validation loss: 2.4405976042348887

Epoch: 5| Step: 3
Training loss: 2.806247967759652
Validation loss: 2.435334614496146

Epoch: 5| Step: 4
Training loss: 2.6016710046817146
Validation loss: 2.4461739663485793

Epoch: 5| Step: 5
Training loss: 3.0110223462236223
Validation loss: 2.446263740501338

Epoch: 5| Step: 6
Training loss: 2.7678491302233623
Validation loss: 2.4796393662419995

Epoch: 5| Step: 7
Training loss: 2.7236933874135203
Validation loss: 2.51325394900204

Epoch: 5| Step: 8
Training loss: 2.7676568622466755
Validation loss: 2.521325387698176

Epoch: 5| Step: 9
Training loss: 3.2739394356188978
Validation loss: 2.5245758367225473

Epoch: 5| Step: 10
Training loss: 2.499233509817896
Validation loss: 2.5020741421136226

Epoch: 134| Step: 0
Training loss: 2.795784508572072
Validation loss: 2.4883155067643297

Epoch: 5| Step: 1
Training loss: 2.916491112648254
Validation loss: 2.511293719546755

Epoch: 5| Step: 2
Training loss: 2.9386615485765826
Validation loss: 2.549023749840866

Epoch: 5| Step: 3
Training loss: 3.022192568103689
Validation loss: 2.602446353508337

Epoch: 5| Step: 4
Training loss: 3.230987691654527
Validation loss: 2.601123052724476

Epoch: 5| Step: 5
Training loss: 2.7133721843565515
Validation loss: 2.5283420032505584

Epoch: 5| Step: 6
Training loss: 2.669358434712808
Validation loss: 2.4483162156998435

Epoch: 5| Step: 7
Training loss: 2.691232617539588
Validation loss: 2.4573358059136114

Epoch: 5| Step: 8
Training loss: 2.384537069629656
Validation loss: 2.4642815795916744

Epoch: 5| Step: 9
Training loss: 2.7426919934956793
Validation loss: 2.481597110960814

Epoch: 5| Step: 10
Training loss: 3.0903147110654823
Validation loss: 2.4857184843908575

Epoch: 135| Step: 0
Training loss: 2.813267751384323
Validation loss: 2.4783037437843314

Epoch: 5| Step: 1
Training loss: 2.272342378796516
Validation loss: 2.4685629039984156

Epoch: 5| Step: 2
Training loss: 3.0494652326196565
Validation loss: 2.461974594735457

Epoch: 5| Step: 3
Training loss: 2.8930040621578996
Validation loss: 2.4418513161192554

Epoch: 5| Step: 4
Training loss: 2.7278636024977105
Validation loss: 2.4336121450684405

Epoch: 5| Step: 5
Training loss: 2.194501299329483
Validation loss: 2.4306518911401396

Epoch: 5| Step: 6
Training loss: 2.56690906725899
Validation loss: 2.4314724081148036

Epoch: 5| Step: 7
Training loss: 2.743098354944624
Validation loss: 2.44931089187329

Epoch: 5| Step: 8
Training loss: 3.2081687852021914
Validation loss: 2.5183946459028683

Epoch: 5| Step: 9
Training loss: 3.293442227137317
Validation loss: 2.567658874665055

Epoch: 5| Step: 10
Training loss: 2.923887814082616
Validation loss: 2.5764102268406903

Epoch: 136| Step: 0
Training loss: 2.8539387038772017
Validation loss: 2.576517078382339

Epoch: 5| Step: 1
Training loss: 2.596579605360224
Validation loss: 2.5552577189898145

Epoch: 5| Step: 2
Training loss: 2.6422335448671714
Validation loss: 2.486961934646792

Epoch: 5| Step: 3
Training loss: 3.044648124520868
Validation loss: 2.4517444231655143

Epoch: 5| Step: 4
Training loss: 2.6036286268729576
Validation loss: 2.4334980242943547

Epoch: 5| Step: 5
Training loss: 2.665169673191907
Validation loss: 2.442927314095778

Epoch: 5| Step: 6
Training loss: 2.3177107793102145
Validation loss: 2.4352031126722395

Epoch: 5| Step: 7
Training loss: 3.51384652823814
Validation loss: 2.4235182422896546

Epoch: 5| Step: 8
Training loss: 2.6092071479216403
Validation loss: 2.418581331059571

Epoch: 5| Step: 9
Training loss: 2.7055465347780223
Validation loss: 2.4254299688420944

Epoch: 5| Step: 10
Training loss: 2.8316634998300083
Validation loss: 2.4248380616878014

Epoch: 137| Step: 0
Training loss: 2.914942386116728
Validation loss: 2.431638044110562

Epoch: 5| Step: 1
Training loss: 2.554092664616345
Validation loss: 2.4270890533479856

Epoch: 5| Step: 2
Training loss: 2.7177388733541408
Validation loss: 2.435390060898295

Epoch: 5| Step: 3
Training loss: 2.6512312206158968
Validation loss: 2.48804634304052

Epoch: 5| Step: 4
Training loss: 2.2989243687372207
Validation loss: 2.570391351077756

Epoch: 5| Step: 5
Training loss: 2.4522969008409783
Validation loss: 2.64503064203098

Epoch: 5| Step: 6
Training loss: 3.0446302703737884
Validation loss: 2.721166170510189

Epoch: 5| Step: 7
Training loss: 3.5285593770639343
Validation loss: 2.738984836642858

Epoch: 5| Step: 8
Training loss: 3.171483358624283
Validation loss: 2.605922047958395

Epoch: 5| Step: 9
Training loss: 2.8188436386896494
Validation loss: 2.462302973175361

Epoch: 5| Step: 10
Training loss: 2.68561416819099
Validation loss: 2.4399301506257536

Epoch: 138| Step: 0
Training loss: 3.0081232083836604
Validation loss: 2.440178466265246

Epoch: 5| Step: 1
Training loss: 2.271378466301139
Validation loss: 2.459212806134743

Epoch: 5| Step: 2
Training loss: 2.9953365637380247
Validation loss: 2.460734514054639

Epoch: 5| Step: 3
Training loss: 3.0287825776858046
Validation loss: 2.462516352422903

Epoch: 5| Step: 4
Training loss: 2.6510463232412955
Validation loss: 2.4657037148554934

Epoch: 5| Step: 5
Training loss: 2.8378595401665594
Validation loss: 2.464462688432307

Epoch: 5| Step: 6
Training loss: 2.7889421367585774
Validation loss: 2.460006337689155

Epoch: 5| Step: 7
Training loss: 2.4933303556407482
Validation loss: 2.4559593753509494

Epoch: 5| Step: 8
Training loss: 2.9101315081267867
Validation loss: 2.4477487915396967

Epoch: 5| Step: 9
Training loss: 3.1933423523055464
Validation loss: 2.434900265230589

Epoch: 5| Step: 10
Training loss: 2.4582597969393
Validation loss: 2.434067451913182

Epoch: 139| Step: 0
Training loss: 3.042250346439319
Validation loss: 2.440048368600938

Epoch: 5| Step: 1
Training loss: 2.925333026935813
Validation loss: 2.4343344855949183

Epoch: 5| Step: 2
Training loss: 2.86508758730594
Validation loss: 2.453432986445613

Epoch: 5| Step: 3
Training loss: 2.4307624426090433
Validation loss: 2.478983868127667

Epoch: 5| Step: 4
Training loss: 2.663924496116266
Validation loss: 2.5606730952133234

Epoch: 5| Step: 5
Training loss: 2.222111157449877
Validation loss: 2.5944113967315627

Epoch: 5| Step: 6
Training loss: 3.3349386323375607
Validation loss: 2.645721621807906

Epoch: 5| Step: 7
Training loss: 3.2739458440497313
Validation loss: 2.63523389273361

Epoch: 5| Step: 8
Training loss: 2.397334438490622
Validation loss: 2.5496534628817087

Epoch: 5| Step: 9
Training loss: 2.714419807979491
Validation loss: 2.46370142696382

Epoch: 5| Step: 10
Training loss: 2.5975307807163324
Validation loss: 2.424093063164293

Epoch: 140| Step: 0
Training loss: 2.2635370564900223
Validation loss: 2.410624102496272

Epoch: 5| Step: 1
Training loss: 2.8273306726942233
Validation loss: 2.4099685846646195

Epoch: 5| Step: 2
Training loss: 2.813103335622794
Validation loss: 2.40782980909635

Epoch: 5| Step: 3
Training loss: 3.1480900499389173
Validation loss: 2.4192691795334373

Epoch: 5| Step: 4
Training loss: 3.098997501585237
Validation loss: 2.4275108051445042

Epoch: 5| Step: 5
Training loss: 3.2623439532263965
Validation loss: 2.434981245607233

Epoch: 5| Step: 6
Training loss: 2.2824553349314485
Validation loss: 2.4407923297753267

Epoch: 5| Step: 7
Training loss: 2.951118554593597
Validation loss: 2.4352104386929128

Epoch: 5| Step: 8
Training loss: 2.739556335393547
Validation loss: 2.44688011500712

Epoch: 5| Step: 9
Training loss: 2.1066829881558946
Validation loss: 2.4702629654804875

Epoch: 5| Step: 10
Training loss: 2.7275536601997032
Validation loss: 2.4765849276942364

Epoch: 141| Step: 0
Training loss: 3.143519647550518
Validation loss: 2.495993939753474

Epoch: 5| Step: 1
Training loss: 2.3352027171193304
Validation loss: 2.5147339145761243

Epoch: 5| Step: 2
Training loss: 2.4050664591974873
Validation loss: 2.5519510338255866

Epoch: 5| Step: 3
Training loss: 3.0016840340724196
Validation loss: 2.569800362680606

Epoch: 5| Step: 4
Training loss: 2.325529149045241
Validation loss: 2.5514459178532136

Epoch: 5| Step: 5
Training loss: 2.6838561794560443
Validation loss: 2.5411059384565133

Epoch: 5| Step: 6
Training loss: 2.006895100633386
Validation loss: 2.5536811650099303

Epoch: 5| Step: 7
Training loss: 3.198088468395546
Validation loss: 2.546020946420806

Epoch: 5| Step: 8
Training loss: 3.362749542846603
Validation loss: 2.540158990787283

Epoch: 5| Step: 9
Training loss: 2.6515207713344187
Validation loss: 2.5084265096954934

Epoch: 5| Step: 10
Training loss: 2.8227225280295194
Validation loss: 2.452713737973688

Epoch: 142| Step: 0
Training loss: 2.897321542768835
Validation loss: 2.421244974056755

Epoch: 5| Step: 1
Training loss: 2.615695448351706
Validation loss: 2.425330281576803

Epoch: 5| Step: 2
Training loss: 2.206620061599287
Validation loss: 2.4229242005824174

Epoch: 5| Step: 3
Training loss: 2.6341399064153417
Validation loss: 2.444905265209044

Epoch: 5| Step: 4
Training loss: 2.6806809610692324
Validation loss: 2.4450299615024718

Epoch: 5| Step: 5
Training loss: 3.169562638493825
Validation loss: 2.4399865642905936

Epoch: 5| Step: 6
Training loss: 2.9301479130408015
Validation loss: 2.4421894724023088

Epoch: 5| Step: 7
Training loss: 2.5270145915326827
Validation loss: 2.43955901849019

Epoch: 5| Step: 8
Training loss: 3.1074065298568314
Validation loss: 2.459063484281011

Epoch: 5| Step: 9
Training loss: 2.345727823526039
Validation loss: 2.4774661630883754

Epoch: 5| Step: 10
Training loss: 2.860627947341771
Validation loss: 2.5053000044605382

Epoch: 143| Step: 0
Training loss: 2.7344546933141163
Validation loss: 2.557931244160856

Epoch: 5| Step: 1
Training loss: 2.8711101920766446
Validation loss: 2.5508774085339754

Epoch: 5| Step: 2
Training loss: 2.8787109640028157
Validation loss: 2.507417660209263

Epoch: 5| Step: 3
Training loss: 2.4056162804722807
Validation loss: 2.4513902980725986

Epoch: 5| Step: 4
Training loss: 2.724800918026342
Validation loss: 2.4326389749269017

Epoch: 5| Step: 5
Training loss: 2.8785839133277555
Validation loss: 2.4222327543375086

Epoch: 5| Step: 6
Training loss: 2.8888458550337206
Validation loss: 2.425461676040446

Epoch: 5| Step: 7
Training loss: 2.4663647101707076
Validation loss: 2.4338588691003578

Epoch: 5| Step: 8
Training loss: 2.8737987828438687
Validation loss: 2.4446663905681225

Epoch: 5| Step: 9
Training loss: 2.6103548505871546
Validation loss: 2.4749382906293587

Epoch: 5| Step: 10
Training loss: 2.9129654606540356
Validation loss: 2.5125940399863795

Epoch: 144| Step: 0
Training loss: 1.7979030819317412
Validation loss: 2.5510295243379746

Epoch: 5| Step: 1
Training loss: 2.8317906349831756
Validation loss: 2.575032598709476

Epoch: 5| Step: 2
Training loss: 3.155425162225645
Validation loss: 2.545753959539662

Epoch: 5| Step: 3
Training loss: 2.5533217766336733
Validation loss: 2.5267650492440468

Epoch: 5| Step: 4
Training loss: 2.9376100560126295
Validation loss: 2.492868376807095

Epoch: 5| Step: 5
Training loss: 2.8795206767798924
Validation loss: 2.469704433760431

Epoch: 5| Step: 6
Training loss: 2.9693777926365033
Validation loss: 2.447301576757524

Epoch: 5| Step: 7
Training loss: 2.342974114737835
Validation loss: 2.4428632407962527

Epoch: 5| Step: 8
Training loss: 3.2873440781665733
Validation loss: 2.449325528579332

Epoch: 5| Step: 9
Training loss: 2.370383946669076
Validation loss: 2.438549856888349

Epoch: 5| Step: 10
Training loss: 2.176817943209684
Validation loss: 2.4610752424609355

Epoch: 145| Step: 0
Training loss: 2.655830888781955
Validation loss: 2.4866982399552784

Epoch: 5| Step: 1
Training loss: 2.2753765842512075
Validation loss: 2.517947831078953

Epoch: 5| Step: 2
Training loss: 3.1320375164118683
Validation loss: 2.5587810919637333

Epoch: 5| Step: 3
Training loss: 3.1311501066374015
Validation loss: 2.5764059809859376

Epoch: 5| Step: 4
Training loss: 2.8454841105343083
Validation loss: 2.5581953707814886

Epoch: 5| Step: 5
Training loss: 2.401455747655321
Validation loss: 2.521217790448604

Epoch: 5| Step: 6
Training loss: 3.072490201333843
Validation loss: 2.5155447975967857

Epoch: 5| Step: 7
Training loss: 2.801851586799901
Validation loss: 2.5001081781670336

Epoch: 5| Step: 8
Training loss: 2.2151650493431183
Validation loss: 2.482194498392914

Epoch: 5| Step: 9
Training loss: 3.014415280909186
Validation loss: 2.5027509730378306

Epoch: 5| Step: 10
Training loss: 1.8708734243241922
Validation loss: 2.4769347665992507

Epoch: 146| Step: 0
Training loss: 2.472389339365901
Validation loss: 2.4610274561965224

Epoch: 5| Step: 1
Training loss: 2.329332281877047
Validation loss: 2.459742318717191

Epoch: 5| Step: 2
Training loss: 2.484471157300386
Validation loss: 2.4640888861265506

Epoch: 5| Step: 3
Training loss: 2.7068816084462903
Validation loss: 2.4645066965696087

Epoch: 5| Step: 4
Training loss: 2.523227836472996
Validation loss: 2.4703556206649457

Epoch: 5| Step: 5
Training loss: 2.4964330021803107
Validation loss: 2.491726461085336

Epoch: 5| Step: 6
Training loss: 3.021929855401074
Validation loss: 2.501794066731851

Epoch: 5| Step: 7
Training loss: 3.090326900782299
Validation loss: 2.532690456950388

Epoch: 5| Step: 8
Training loss: 2.747655215682116
Validation loss: 2.5684473410769324

Epoch: 5| Step: 9
Training loss: 2.8677013466876122
Validation loss: 2.56287228460879

Epoch: 5| Step: 10
Training loss: 2.9119287610090834
Validation loss: 2.5449468693779074

Epoch: 147| Step: 0
Training loss: 2.011615283860821
Validation loss: 2.5082599214061427

Epoch: 5| Step: 1
Training loss: 2.816242610076812
Validation loss: 2.4948199288516464

Epoch: 5| Step: 2
Training loss: 2.738750510065544
Validation loss: 2.4719619282883256

Epoch: 5| Step: 3
Training loss: 2.711430221765565
Validation loss: 2.453407842412308

Epoch: 5| Step: 4
Training loss: 2.6045376831246196
Validation loss: 2.444352205516586

Epoch: 5| Step: 5
Training loss: 2.8969138528631886
Validation loss: 2.446786738491081

Epoch: 5| Step: 6
Training loss: 2.777668135916332
Validation loss: 2.4440978820073984

Epoch: 5| Step: 7
Training loss: 2.709717489768838
Validation loss: 2.4503424325848036

Epoch: 5| Step: 8
Training loss: 2.8035683271757126
Validation loss: 2.461872913350433

Epoch: 5| Step: 9
Training loss: 2.7401524135216664
Validation loss: 2.4818323546089447

Epoch: 5| Step: 10
Training loss: 2.3295778183475777
Validation loss: 2.506776690020144

Epoch: 148| Step: 0
Training loss: 2.9128819751342503
Validation loss: 2.568658474018496

Epoch: 5| Step: 1
Training loss: 2.4035726737932364
Validation loss: 2.5956982479902875

Epoch: 5| Step: 2
Training loss: 2.93548872249869
Validation loss: 2.582516319400357

Epoch: 5| Step: 3
Training loss: 2.689666318511972
Validation loss: 2.51462351102389

Epoch: 5| Step: 4
Training loss: 2.9227910365329413
Validation loss: 2.4841446782983727

Epoch: 5| Step: 5
Training loss: 2.272351821751827
Validation loss: 2.471980337558691

Epoch: 5| Step: 6
Training loss: 2.870418713161407
Validation loss: 2.4530182582627758

Epoch: 5| Step: 7
Training loss: 2.7733669218297394
Validation loss: 2.45980411336392

Epoch: 5| Step: 8
Training loss: 2.847093565807232
Validation loss: 2.4647031642914627

Epoch: 5| Step: 9
Training loss: 2.179057587421525
Validation loss: 2.4594370153099208

Epoch: 5| Step: 10
Training loss: 2.935266172956639
Validation loss: 2.4568738162599706

Epoch: 149| Step: 0
Training loss: 2.5240222737558256
Validation loss: 2.457511677118652

Epoch: 5| Step: 1
Training loss: 2.1953304195012087
Validation loss: 2.472934269936818

Epoch: 5| Step: 2
Training loss: 2.9157181605331126
Validation loss: 2.529080644148705

Epoch: 5| Step: 3
Training loss: 2.886798697514377
Validation loss: 2.5894402791486444

Epoch: 5| Step: 4
Training loss: 2.6799923915185677
Validation loss: 2.574865251880968

Epoch: 5| Step: 5
Training loss: 2.8976411368067723
Validation loss: 2.5557527338607144

Epoch: 5| Step: 6
Training loss: 2.8325694868380746
Validation loss: 2.586345426666793

Epoch: 5| Step: 7
Training loss: 2.846314667581511
Validation loss: 2.6067459324730273

Epoch: 5| Step: 8
Training loss: 2.6493845458869996
Validation loss: 2.5864491886030794

Epoch: 5| Step: 9
Training loss: 2.189685710494131
Validation loss: 2.5125323213161406

Epoch: 5| Step: 10
Training loss: 2.86511787744591
Validation loss: 2.4671611145928307

Epoch: 150| Step: 0
Training loss: 2.576215834745055
Validation loss: 2.4719163686178187

Epoch: 5| Step: 1
Training loss: 2.6953629198748774
Validation loss: 2.4899737614491566

Epoch: 5| Step: 2
Training loss: 2.1157942688701077
Validation loss: 2.5056840043665054

Epoch: 5| Step: 3
Training loss: 2.4778741197240515
Validation loss: 2.5433809203976208

Epoch: 5| Step: 4
Training loss: 2.823078774915546
Validation loss: 2.566926118463396

Epoch: 5| Step: 5
Training loss: 2.984992158198959
Validation loss: 2.5711805758661903

Epoch: 5| Step: 6
Training loss: 3.1006646766576926
Validation loss: 2.567636976894004

Epoch: 5| Step: 7
Training loss: 2.669416043433367
Validation loss: 2.568105517691164

Epoch: 5| Step: 8
Training loss: 2.545892724958829
Validation loss: 2.5427584949892927

Epoch: 5| Step: 9
Training loss: 2.1791092300382715
Validation loss: 2.5157036457877564

Epoch: 5| Step: 10
Training loss: 3.005302670131433
Validation loss: 2.519040705883672

Epoch: 151| Step: 0
Training loss: 2.467436332306387
Validation loss: 2.5099904253318277

Epoch: 5| Step: 1
Training loss: 2.3777199278634327
Validation loss: 2.4857065918893255

Epoch: 5| Step: 2
Training loss: 3.237531807643806
Validation loss: 2.510492881162974

Epoch: 5| Step: 3
Training loss: 2.265176241925211
Validation loss: 2.52201602629558

Epoch: 5| Step: 4
Training loss: 2.48655930947855
Validation loss: 2.511395790703246

Epoch: 5| Step: 5
Training loss: 3.047848277042846
Validation loss: 2.50654402166031

Epoch: 5| Step: 6
Training loss: 2.6322493587626807
Validation loss: 2.518230900715777

Epoch: 5| Step: 7
Training loss: 2.2473236697130736
Validation loss: 2.505034273462607

Epoch: 5| Step: 8
Training loss: 2.4092832001095426
Validation loss: 2.5097745199114896

Epoch: 5| Step: 9
Training loss: 2.809081564441883
Validation loss: 2.504812618720055

Epoch: 5| Step: 10
Training loss: 2.6616358290358715
Validation loss: 2.4917838857961487

Epoch: 152| Step: 0
Training loss: 2.690735311163101
Validation loss: 2.4608602105065196

Epoch: 5| Step: 1
Training loss: 2.3873973325055036
Validation loss: 2.457056708572184

Epoch: 5| Step: 2
Training loss: 2.6490720815733915
Validation loss: 2.446917565928597

Epoch: 5| Step: 3
Training loss: 2.9062844551258995
Validation loss: 2.454905105816762

Epoch: 5| Step: 4
Training loss: 2.2194757483477177
Validation loss: 2.4593155846752874

Epoch: 5| Step: 5
Training loss: 3.114286750953272
Validation loss: 2.4586612866079793

Epoch: 5| Step: 6
Training loss: 2.5958277641550964
Validation loss: 2.476403147382065

Epoch: 5| Step: 7
Training loss: 2.5382242080699116
Validation loss: 2.471128726651119

Epoch: 5| Step: 8
Training loss: 2.5288114693185766
Validation loss: 2.4825435158198994

Epoch: 5| Step: 9
Training loss: 2.463064673110176
Validation loss: 2.4857625271987303

Epoch: 5| Step: 10
Training loss: 2.8126598736570285
Validation loss: 2.492622596989936

Epoch: 153| Step: 0
Training loss: 2.4215751216183885
Validation loss: 2.4946025069604056

Epoch: 5| Step: 1
Training loss: 2.265057722960341
Validation loss: 2.516967244145058

Epoch: 5| Step: 2
Training loss: 2.4579538817583773
Validation loss: 2.5199942616558353

Epoch: 5| Step: 3
Training loss: 2.9472340758438142
Validation loss: 2.5302970588359024

Epoch: 5| Step: 4
Training loss: 2.8513737028146675
Validation loss: 2.5333838240293387

Epoch: 5| Step: 5
Training loss: 2.6974643244607113
Validation loss: 2.5197276150902064

Epoch: 5| Step: 6
Training loss: 2.6887085437283225
Validation loss: 2.4755950183899667

Epoch: 5| Step: 7
Training loss: 2.422982928440663
Validation loss: 2.4738077318414833

Epoch: 5| Step: 8
Training loss: 2.4796865115917908
Validation loss: 2.455293297898447

Epoch: 5| Step: 9
Training loss: 2.4678358485998952
Validation loss: 2.458141462980532

Epoch: 5| Step: 10
Training loss: 3.0353692764286704
Validation loss: 2.454802755120264

Epoch: 154| Step: 0
Training loss: 2.345249967611874
Validation loss: 2.4531390767960386

Epoch: 5| Step: 1
Training loss: 2.8395194979624776
Validation loss: 2.478093789353122

Epoch: 5| Step: 2
Training loss: 2.8613901177158136
Validation loss: 2.4809495442657363

Epoch: 5| Step: 3
Training loss: 2.6312486662147747
Validation loss: 2.4980802096905355

Epoch: 5| Step: 4
Training loss: 2.7256914294010883
Validation loss: 2.523543643347728

Epoch: 5| Step: 5
Training loss: 2.4936868109859747
Validation loss: 2.5125994670428784

Epoch: 5| Step: 6
Training loss: 2.67483214092337
Validation loss: 2.5056206830698824

Epoch: 5| Step: 7
Training loss: 2.5100747240957655
Validation loss: 2.501277568434988

Epoch: 5| Step: 8
Training loss: 2.4201565460139878
Validation loss: 2.4699779274512115

Epoch: 5| Step: 9
Training loss: 2.0870343585547033
Validation loss: 2.47013716526536

Epoch: 5| Step: 10
Training loss: 2.933961238269595
Validation loss: 2.4770506161743793

Epoch: 155| Step: 0
Training loss: 2.305457035191348
Validation loss: 2.4668371812883354

Epoch: 5| Step: 1
Training loss: 2.4181601305332605
Validation loss: 2.4822257841413844

Epoch: 5| Step: 2
Training loss: 2.548223875483899
Validation loss: 2.484798381647856

Epoch: 5| Step: 3
Training loss: 2.895684345904388
Validation loss: 2.491414156937524

Epoch: 5| Step: 4
Training loss: 2.144011999196309
Validation loss: 2.5062859489549454

Epoch: 5| Step: 5
Training loss: 2.2098252157423808
Validation loss: 2.5121039934610443

Epoch: 5| Step: 6
Training loss: 3.063841856657654
Validation loss: 2.525197703312411

Epoch: 5| Step: 7
Training loss: 2.4275556331274286
Validation loss: 2.5108573961392584

Epoch: 5| Step: 8
Training loss: 2.2830631940920454
Validation loss: 2.4960650907242936

Epoch: 5| Step: 9
Training loss: 3.0170006653175214
Validation loss: 2.4931127215821838

Epoch: 5| Step: 10
Training loss: 2.9839498007287326
Validation loss: 2.489799160294237

Epoch: 156| Step: 0
Training loss: 2.407966793990967
Validation loss: 2.5048065627461016

Epoch: 5| Step: 1
Training loss: 2.3187992800182564
Validation loss: 2.535415279973056

Epoch: 5| Step: 2
Training loss: 2.2793643421690635
Validation loss: 2.5553839356018284

Epoch: 5| Step: 3
Training loss: 1.969517512805065
Validation loss: 2.5836094617058127

Epoch: 5| Step: 4
Training loss: 2.9236751457766688
Validation loss: 2.59960328050063

Epoch: 5| Step: 5
Training loss: 2.920846849991618
Validation loss: 2.52692479709108

Epoch: 5| Step: 6
Training loss: 2.8554567266333737
Validation loss: 2.4675097540100657

Epoch: 5| Step: 7
Training loss: 2.5614550250883847
Validation loss: 2.4423288553070233

Epoch: 5| Step: 8
Training loss: 2.466714430252075
Validation loss: 2.421029431851726

Epoch: 5| Step: 9
Training loss: 2.7517500424090917
Validation loss: 2.4259230746774914

Epoch: 5| Step: 10
Training loss: 2.9956332851321603
Validation loss: 2.4370745499767184

Epoch: 157| Step: 0
Training loss: 2.7672132683646784
Validation loss: 2.4358262856872352

Epoch: 5| Step: 1
Training loss: 2.8008618629165527
Validation loss: 2.4409918698655306

Epoch: 5| Step: 2
Training loss: 2.5229859317140866
Validation loss: 2.4634436500036934

Epoch: 5| Step: 3
Training loss: 2.7366144219761526
Validation loss: 2.5000258962253925

Epoch: 5| Step: 4
Training loss: 2.5750230102992395
Validation loss: 2.5384437351040883

Epoch: 5| Step: 5
Training loss: 2.7096752559159545
Validation loss: 2.610591085078938

Epoch: 5| Step: 6
Training loss: 2.4860176078313994
Validation loss: 2.6434343944638323

Epoch: 5| Step: 7
Training loss: 2.877058204653473
Validation loss: 2.6497300933662307

Epoch: 5| Step: 8
Training loss: 2.486332919587384
Validation loss: 2.5829086179521044

Epoch: 5| Step: 9
Training loss: 1.9495317288106404
Validation loss: 2.500855761876909

Epoch: 5| Step: 10
Training loss: 2.775797438956802
Validation loss: 2.470183050420503

Epoch: 158| Step: 0
Training loss: 2.269155763433428
Validation loss: 2.4488769194316884

Epoch: 5| Step: 1
Training loss: 2.4395928812423797
Validation loss: 2.4492294872067095

Epoch: 5| Step: 2
Training loss: 2.189575409685843
Validation loss: 2.4613054772909857

Epoch: 5| Step: 3
Training loss: 2.3443174565330556
Validation loss: 2.476685209072247

Epoch: 5| Step: 4
Training loss: 2.9770313604546343
Validation loss: 2.486081331492173

Epoch: 5| Step: 5
Training loss: 2.8980219046934423
Validation loss: 2.4718555872045873

Epoch: 5| Step: 6
Training loss: 2.2916053994976613
Validation loss: 2.455066012023052

Epoch: 5| Step: 7
Training loss: 3.1403731060073232
Validation loss: 2.4626743472514785

Epoch: 5| Step: 8
Training loss: 2.6907222858700477
Validation loss: 2.4472790556411455

Epoch: 5| Step: 9
Training loss: 2.228744027070382
Validation loss: 2.4474061334508104

Epoch: 5| Step: 10
Training loss: 2.539646022941875
Validation loss: 2.458919853195326

Epoch: 159| Step: 0
Training loss: 2.3997093581008793
Validation loss: 2.4930547860728685

Epoch: 5| Step: 1
Training loss: 2.829650973037386
Validation loss: 2.5387583580894764

Epoch: 5| Step: 2
Training loss: 2.7584463801272907
Validation loss: 2.5538410079997957

Epoch: 5| Step: 3
Training loss: 2.464442781217148
Validation loss: 2.543874443061729

Epoch: 5| Step: 4
Training loss: 2.2384838392037736
Validation loss: 2.5388923066731945

Epoch: 5| Step: 5
Training loss: 2.702211258643619
Validation loss: 2.524551835885037

Epoch: 5| Step: 6
Training loss: 2.046196628589927
Validation loss: 2.5198877724491178

Epoch: 5| Step: 7
Training loss: 2.4092858719822665
Validation loss: 2.503107838192067

Epoch: 5| Step: 8
Training loss: 3.0344994815078623
Validation loss: 2.468362571438062

Epoch: 5| Step: 9
Training loss: 2.671074462892399
Validation loss: 2.4635506757495036

Epoch: 5| Step: 10
Training loss: 1.9231398227381995
Validation loss: 2.434925491935892

Epoch: 160| Step: 0
Training loss: 3.32627150811399
Validation loss: 2.444007104435258

Epoch: 5| Step: 1
Training loss: 2.7471137072203526
Validation loss: 2.4359797703108272

Epoch: 5| Step: 2
Training loss: 2.2171306879723685
Validation loss: 2.4435927362558862

Epoch: 5| Step: 3
Training loss: 2.2878427217485924
Validation loss: 2.433233055524223

Epoch: 5| Step: 4
Training loss: 2.4099936159927844
Validation loss: 2.4388160129423913

Epoch: 5| Step: 5
Training loss: 2.6020231555081397
Validation loss: 2.4423430704288713

Epoch: 5| Step: 6
Training loss: 1.9325938712511508
Validation loss: 2.475135804013003

Epoch: 5| Step: 7
Training loss: 2.4913062567515056
Validation loss: 2.4842934884343686

Epoch: 5| Step: 8
Training loss: 2.5870418898616006
Validation loss: 2.4971861334175145

Epoch: 5| Step: 9
Training loss: 2.5085318891274895
Validation loss: 2.508244609588871

Epoch: 5| Step: 10
Training loss: 2.2160727238203943
Validation loss: 2.5039795201929946

Epoch: 161| Step: 0
Training loss: 2.4716981113188794
Validation loss: 2.5064670982927204

Epoch: 5| Step: 1
Training loss: 2.1622059704878898
Validation loss: 2.485350379368988

Epoch: 5| Step: 2
Training loss: 2.992916008532625
Validation loss: 2.46390989735436

Epoch: 5| Step: 3
Training loss: 2.3470354576471837
Validation loss: 2.4446721781536898

Epoch: 5| Step: 4
Training loss: 2.508934459281804
Validation loss: 2.4502692063601375

Epoch: 5| Step: 5
Training loss: 2.3885500012027903
Validation loss: 2.4472585382931737

Epoch: 5| Step: 6
Training loss: 2.599585437736102
Validation loss: 2.451683233673915

Epoch: 5| Step: 7
Training loss: 1.7557788529141636
Validation loss: 2.459314014789725

Epoch: 5| Step: 8
Training loss: 2.8181500796659136
Validation loss: 2.468095753735826

Epoch: 5| Step: 9
Training loss: 2.3844922758086495
Validation loss: 2.48553799710573

Epoch: 5| Step: 10
Training loss: 2.7145346047006265
Validation loss: 2.509673983512539

Epoch: 162| Step: 0
Training loss: 2.2083360444058266
Validation loss: 2.526141153162451

Epoch: 5| Step: 1
Training loss: 2.3893374297959826
Validation loss: 2.5420495684060747

Epoch: 5| Step: 2
Training loss: 2.4150517976627928
Validation loss: 2.5490164572509713

Epoch: 5| Step: 3
Training loss: 2.549052799305071
Validation loss: 2.570209441138781

Epoch: 5| Step: 4
Training loss: 2.4457328849411217
Validation loss: 2.5922488897131304

Epoch: 5| Step: 5
Training loss: 2.6528691935696562
Validation loss: 2.592982991596217

Epoch: 5| Step: 6
Training loss: 2.645646326459887
Validation loss: 2.580305814991622

Epoch: 5| Step: 7
Training loss: 2.5682178066675205
Validation loss: 2.5345274291064297

Epoch: 5| Step: 8
Training loss: 2.3359068801557115
Validation loss: 2.5029865863200333

Epoch: 5| Step: 9
Training loss: 2.218251131953193
Validation loss: 2.4767634031223684

Epoch: 5| Step: 10
Training loss: 2.8139703933579017
Validation loss: 2.469532618392323

Epoch: 163| Step: 0
Training loss: 2.231985775461298
Validation loss: 2.463181334270614

Epoch: 5| Step: 1
Training loss: 2.512027229125059
Validation loss: 2.4524039279976035

Epoch: 5| Step: 2
Training loss: 2.317806136107249
Validation loss: 2.4581000212309276

Epoch: 5| Step: 3
Training loss: 3.250209801577809
Validation loss: 2.492210621327455

Epoch: 5| Step: 4
Training loss: 2.4920430395656017
Validation loss: 2.498157937252618

Epoch: 5| Step: 5
Training loss: 2.1817842195497406
Validation loss: 2.5233869264035946

Epoch: 5| Step: 6
Training loss: 2.548041047506702
Validation loss: 2.544564319325572

Epoch: 5| Step: 7
Training loss: 2.3058140991460165
Validation loss: 2.538237972496135

Epoch: 5| Step: 8
Training loss: 1.8840862729876966
Validation loss: 2.5387667929429103

Epoch: 5| Step: 9
Training loss: 2.652554173612938
Validation loss: 2.5436245743460457

Epoch: 5| Step: 10
Training loss: 2.102325868052086
Validation loss: 2.5465292173393523

Epoch: 164| Step: 0
Training loss: 2.6555151427779413
Validation loss: 2.5241874409195164

Epoch: 5| Step: 1
Training loss: 2.3717120651149903
Validation loss: 2.509775668035113

Epoch: 5| Step: 2
Training loss: 2.8581425246304764
Validation loss: 2.495486125275829

Epoch: 5| Step: 3
Training loss: 2.2312696525498965
Validation loss: 2.463801159946059

Epoch: 5| Step: 4
Training loss: 2.3814961784247237
Validation loss: 2.4629748579355137

Epoch: 5| Step: 5
Training loss: 2.4204272465259304
Validation loss: 2.4726143164216

Epoch: 5| Step: 6
Training loss: 2.2713036239751645
Validation loss: 2.478820665646145

Epoch: 5| Step: 7
Training loss: 1.9096345715685845
Validation loss: 2.491788214111637

Epoch: 5| Step: 8
Training loss: 2.407626266258132
Validation loss: 2.507517772815194

Epoch: 5| Step: 9
Training loss: 2.675114948262911
Validation loss: 2.5467340704788817

Epoch: 5| Step: 10
Training loss: 2.277492825845417
Validation loss: 2.5928874285892203

Epoch: 165| Step: 0
Training loss: 2.850482223939764
Validation loss: 2.638352397390436

Epoch: 5| Step: 1
Training loss: 1.850568351561395
Validation loss: 2.7022887925848127

Epoch: 5| Step: 2
Training loss: 2.316297866318465
Validation loss: 2.755975903204824

Epoch: 5| Step: 3
Training loss: 2.86498806030555
Validation loss: 2.701624673784989

Epoch: 5| Step: 4
Training loss: 2.630381018883841
Validation loss: 2.6198472010376133

Epoch: 5| Step: 5
Training loss: 2.4959463634168815
Validation loss: 2.536367710186984

Epoch: 5| Step: 6
Training loss: 2.5437102518561248
Validation loss: 2.5005097894906796

Epoch: 5| Step: 7
Training loss: 1.9999181611483239
Validation loss: 2.5032840498537534

Epoch: 5| Step: 8
Training loss: 2.3107699546922236
Validation loss: 2.5195359905605645

Epoch: 5| Step: 9
Training loss: 2.5060012313401345
Validation loss: 2.532315314503798

Epoch: 5| Step: 10
Training loss: 2.404849648167583
Validation loss: 2.5030412776986566

Epoch: 166| Step: 0
Training loss: 2.4360290392693544
Validation loss: 2.479786741977924

Epoch: 5| Step: 1
Training loss: 2.3193845595232445
Validation loss: 2.4604013718757107

Epoch: 5| Step: 2
Training loss: 2.5852957214379084
Validation loss: 2.469156587182612

Epoch: 5| Step: 3
Training loss: 2.1077372657012035
Validation loss: 2.4788273006620267

Epoch: 5| Step: 4
Training loss: 2.870799105310533
Validation loss: 2.4966777610206465

Epoch: 5| Step: 5
Training loss: 2.5304205206490917
Validation loss: 2.5486365388718664

Epoch: 5| Step: 6
Training loss: 2.780488928056832
Validation loss: 2.5755950158234127

Epoch: 5| Step: 7
Training loss: 2.011108424370495
Validation loss: 2.5896057317486116

Epoch: 5| Step: 8
Training loss: 1.960906191876096
Validation loss: 2.6231708579926747

Epoch: 5| Step: 9
Training loss: 2.302672562485425
Validation loss: 2.659437554611835

Epoch: 5| Step: 10
Training loss: 2.310162058343381
Validation loss: 2.6647375734225074

Epoch: 167| Step: 0
Training loss: 2.012815543132318
Validation loss: 2.6135145871964003

Epoch: 5| Step: 1
Training loss: 2.527166675808724
Validation loss: 2.566913894100618

Epoch: 5| Step: 2
Training loss: 2.3895846827225227
Validation loss: 2.502393665641681

Epoch: 5| Step: 3
Training loss: 2.1996734853678226
Validation loss: 2.507049145867615

Epoch: 5| Step: 4
Training loss: 2.854904599174155
Validation loss: 2.4967415658225356

Epoch: 5| Step: 5
Training loss: 2.1296670936508018
Validation loss: 2.4898219671056885

Epoch: 5| Step: 6
Training loss: 2.5861664178026262
Validation loss: 2.5085156479511093

Epoch: 5| Step: 7
Training loss: 2.0988043514845653
Validation loss: 2.5183009933067697

Epoch: 5| Step: 8
Training loss: 2.2423306196837234
Validation loss: 2.5532931070761

Epoch: 5| Step: 9
Training loss: 2.5711755665940994
Validation loss: 2.5851409183862812

Epoch: 5| Step: 10
Training loss: 2.7511677430130126
Validation loss: 2.610945507692763

Epoch: 168| Step: 0
Training loss: 2.2486835443199022
Validation loss: 2.6279823171529175

Epoch: 5| Step: 1
Training loss: 2.452481908391238
Validation loss: 2.6380477495904335

Epoch: 5| Step: 2
Training loss: 2.3383495928778406
Validation loss: 2.6366356105906332

Epoch: 5| Step: 3
Training loss: 2.2467577143632513
Validation loss: 2.6391387006962046

Epoch: 5| Step: 4
Training loss: 2.4542516563047005
Validation loss: 2.621215477602925

Epoch: 5| Step: 5
Training loss: 2.2817203611637145
Validation loss: 2.5964807318313796

Epoch: 5| Step: 6
Training loss: 2.416008125114673
Validation loss: 2.570025289376063

Epoch: 5| Step: 7
Training loss: 2.4548471808019556
Validation loss: 2.5684787864255303

Epoch: 5| Step: 8
Training loss: 2.3778157859014497
Validation loss: 2.5663083372569173

Epoch: 5| Step: 9
Training loss: 2.3594908022724526
Validation loss: 2.5695518078407207

Epoch: 5| Step: 10
Training loss: 2.45795252377479
Validation loss: 2.5639639423638343

Epoch: 169| Step: 0
Training loss: 2.504520335006181
Validation loss: 2.5572415263349337

Epoch: 5| Step: 1
Training loss: 2.0804082044442964
Validation loss: 2.5541831891658773

Epoch: 5| Step: 2
Training loss: 2.1706335238161127
Validation loss: 2.5547755800935885

Epoch: 5| Step: 3
Training loss: 2.169575633555562
Validation loss: 2.5537664097594366

Epoch: 5| Step: 4
Training loss: 2.4908284753943715
Validation loss: 2.5260521152196937

Epoch: 5| Step: 5
Training loss: 2.2122494744313044
Validation loss: 2.5347445101302886

Epoch: 5| Step: 6
Training loss: 2.2050927214903853
Validation loss: 2.5447899019847053

Epoch: 5| Step: 7
Training loss: 2.4393498175120447
Validation loss: 2.533392681553036

Epoch: 5| Step: 8
Training loss: 2.3011159345788204
Validation loss: 2.558922333805803

Epoch: 5| Step: 9
Training loss: 2.859025944317533
Validation loss: 2.5871839670252976

Epoch: 5| Step: 10
Training loss: 2.0612329000916927
Validation loss: 2.621121604606009

Epoch: 170| Step: 0
Training loss: 2.121745927842944
Validation loss: 2.6323565293981144

Epoch: 5| Step: 1
Training loss: 2.312039200519747
Validation loss: 2.6081070069307026

Epoch: 5| Step: 2
Training loss: 2.1853126489002905
Validation loss: 2.5677389718697854

Epoch: 5| Step: 3
Training loss: 2.151281742125537
Validation loss: 2.5672547572256046

Epoch: 5| Step: 4
Training loss: 2.6393073592302234
Validation loss: 2.5635939333249462

Epoch: 5| Step: 5
Training loss: 2.422519819495475
Validation loss: 2.5862426756186214

Epoch: 5| Step: 6
Training loss: 1.7292164561752033
Validation loss: 2.587799284381975

Epoch: 5| Step: 7
Training loss: 2.416451071845505
Validation loss: 2.591041129887614

Epoch: 5| Step: 8
Training loss: 2.347688341476793
Validation loss: 2.593119351254255

Epoch: 5| Step: 9
Training loss: 2.5148742692890296
Validation loss: 2.5656496665483988

Epoch: 5| Step: 10
Training loss: 2.763243431067625
Validation loss: 2.543971800861584

Epoch: 171| Step: 0
Training loss: 2.247352950363672
Validation loss: 2.5484435833085737

Epoch: 5| Step: 1
Training loss: 2.0367753220380935
Validation loss: 2.5698066356008202

Epoch: 5| Step: 2
Training loss: 2.102713457627476
Validation loss: 2.606733689301638

Epoch: 5| Step: 3
Training loss: 2.6957796880542517
Validation loss: 2.6171121115334497

Epoch: 5| Step: 4
Training loss: 2.4162435709339385
Validation loss: 2.5917454107111904

Epoch: 5| Step: 5
Training loss: 1.6286997126723017
Validation loss: 2.572468340977368

Epoch: 5| Step: 6
Training loss: 2.5374673850683567
Validation loss: 2.5370406771213583

Epoch: 5| Step: 7
Training loss: 2.28482287982977
Validation loss: 2.504817964381703

Epoch: 5| Step: 8
Training loss: 2.2729287118939316
Validation loss: 2.4870411033672704

Epoch: 5| Step: 9
Training loss: 2.512820463477473
Validation loss: 2.516600478612004

Epoch: 5| Step: 10
Training loss: 2.9716148607577444
Validation loss: 2.540026474581292

Epoch: 172| Step: 0
Training loss: 2.3311698511167864
Validation loss: 2.5809441479791144

Epoch: 5| Step: 1
Training loss: 2.069820129577672
Validation loss: 2.6237467690903036

Epoch: 5| Step: 2
Training loss: 2.5629758625598114
Validation loss: 2.6838730464642095

Epoch: 5| Step: 3
Training loss: 2.4521717722157352
Validation loss: 2.726628216321353

Epoch: 5| Step: 4
Training loss: 2.015194040993985
Validation loss: 2.7614823132378605

Epoch: 5| Step: 5
Training loss: 2.2489090499908206
Validation loss: 2.762959000780131

Epoch: 5| Step: 6
Training loss: 2.671284303565394
Validation loss: 2.738019306745526

Epoch: 5| Step: 7
Training loss: 1.9291541717761815
Validation loss: 2.649880237005261

Epoch: 5| Step: 8
Training loss: 2.5582408399564236
Validation loss: 2.5850924385102463

Epoch: 5| Step: 9
Training loss: 2.3571355435641888
Validation loss: 2.55595683371796

Epoch: 5| Step: 10
Training loss: 2.5351278482735906
Validation loss: 2.514191582103511

Epoch: 173| Step: 0
Training loss: 2.6449358361579547
Validation loss: 2.519480027160386

Epoch: 5| Step: 1
Training loss: 2.6897810193806593
Validation loss: 2.531221799542721

Epoch: 5| Step: 2
Training loss: 2.346829235377379
Validation loss: 2.5324001841274106

Epoch: 5| Step: 3
Training loss: 2.4116414098816508
Validation loss: 2.5359888335652685

Epoch: 5| Step: 4
Training loss: 2.078519855359466
Validation loss: 2.5363956805935817

Epoch: 5| Step: 5
Training loss: 1.7895366590080561
Validation loss: 2.561593592478001

Epoch: 5| Step: 6
Training loss: 2.0725153881279383
Validation loss: 2.583622810692524

Epoch: 5| Step: 7
Training loss: 1.9961275519627582
Validation loss: 2.5741711937857414

Epoch: 5| Step: 8
Training loss: 2.6772147912034487
Validation loss: 2.6024917607783173

Epoch: 5| Step: 9
Training loss: 1.9839432013787586
Validation loss: 2.6065608901146695

Epoch: 5| Step: 10
Training loss: 2.305706768617888
Validation loss: 2.603883935818772

Epoch: 174| Step: 0
Training loss: 1.8259641478195332
Validation loss: 2.624167656574279

Epoch: 5| Step: 1
Training loss: 2.3586678360949964
Validation loss: 2.645421065215948

Epoch: 5| Step: 2
Training loss: 1.638948583144364
Validation loss: 2.643053187261749

Epoch: 5| Step: 3
Training loss: 1.8134312046276353
Validation loss: 2.622331359998133

Epoch: 5| Step: 4
Training loss: 2.291459114617235
Validation loss: 2.648103058420911

Epoch: 5| Step: 5
Training loss: 2.4229000752461265
Validation loss: 2.6748490629182835

Epoch: 5| Step: 6
Training loss: 2.2171924120557596
Validation loss: 2.660875535524971

Epoch: 5| Step: 7
Training loss: 2.3986463424764466
Validation loss: 2.668953494405174

Epoch: 5| Step: 8
Training loss: 2.4565749480035595
Validation loss: 2.6915907217400976

Epoch: 5| Step: 9
Training loss: 2.5580939583720568
Validation loss: 2.663816894973067

Epoch: 5| Step: 10
Training loss: 2.36606090162871
Validation loss: 2.652827731344044

Epoch: 175| Step: 0
Training loss: 1.7555452772368096
Validation loss: 2.603538465633935

Epoch: 5| Step: 1
Training loss: 1.5174382168606193
Validation loss: 2.58248457195524

Epoch: 5| Step: 2
Training loss: 2.6718057545394713
Validation loss: 2.564166918730667

Epoch: 5| Step: 3
Training loss: 2.3117267243665793
Validation loss: 2.5271463901156457

Epoch: 5| Step: 4
Training loss: 2.0388424341705544
Validation loss: 2.5092104227837337

Epoch: 5| Step: 5
Training loss: 2.7680336329009974
Validation loss: 2.510255552021975

Epoch: 5| Step: 6
Training loss: 2.1309632049634746
Validation loss: 2.496710913763439

Epoch: 5| Step: 7
Training loss: 2.8285077083726042
Validation loss: 2.512904808090219

Epoch: 5| Step: 8
Training loss: 2.046428719128014
Validation loss: 2.5405212891557913

Epoch: 5| Step: 9
Training loss: 2.1536232248677902
Validation loss: 2.560465837924957

Epoch: 5| Step: 10
Training loss: 1.986018964175585
Validation loss: 2.665928686287709

Epoch: 176| Step: 0
Training loss: 2.369733291298244
Validation loss: 2.7342457055435174

Epoch: 5| Step: 1
Training loss: 2.6314832461673814
Validation loss: 2.7243849694080855

Epoch: 5| Step: 2
Training loss: 2.1128588129075854
Validation loss: 2.7006884767194594

Epoch: 5| Step: 3
Training loss: 2.161567985480279
Validation loss: 2.7099439774425695

Epoch: 5| Step: 4
Training loss: 2.1450559325139475
Validation loss: 2.692471354523721

Epoch: 5| Step: 5
Training loss: 1.8279531675262
Validation loss: 2.647245839286163

Epoch: 5| Step: 6
Training loss: 2.3152435112044514
Validation loss: 2.629004126377559

Epoch: 5| Step: 7
Training loss: 2.076121576369198
Validation loss: 2.6068376152703574

Epoch: 5| Step: 8
Training loss: 2.484658854840834
Validation loss: 2.580196429726878

Epoch: 5| Step: 9
Training loss: 2.113349166032627
Validation loss: 2.552333712187935

Epoch: 5| Step: 10
Training loss: 1.6992079460414433
Validation loss: 2.5319207322064967

Epoch: 177| Step: 0
Training loss: 1.777738422547613
Validation loss: 2.5325312742361175

Epoch: 5| Step: 1
Training loss: 2.0355436282222596
Validation loss: 2.537667548807232

Epoch: 5| Step: 2
Training loss: 2.3701497795966753
Validation loss: 2.5502810200107087

Epoch: 5| Step: 3
Training loss: 2.0343767016706953
Validation loss: 2.555235835338481

Epoch: 5| Step: 4
Training loss: 2.3751552932563675
Validation loss: 2.5767522076119596

Epoch: 5| Step: 5
Training loss: 1.960232064463673
Validation loss: 2.602067088374105

Epoch: 5| Step: 6
Training loss: 2.460930718306628
Validation loss: 2.599551584173341

Epoch: 5| Step: 7
Training loss: 1.975258860946844
Validation loss: 2.615377629964963

Epoch: 5| Step: 8
Training loss: 2.073055882467594
Validation loss: 2.594875392512413

Epoch: 5| Step: 9
Training loss: 2.214541567686411
Validation loss: 2.5868073252676247

Epoch: 5| Step: 10
Training loss: 2.4033326137434066
Validation loss: 2.5740778036992134

Epoch: 178| Step: 0
Training loss: 1.78308639896407
Validation loss: 2.5746975317386744

Epoch: 5| Step: 1
Training loss: 1.9108682565316193
Validation loss: 2.577270865504517

Epoch: 5| Step: 2
Training loss: 2.2952807855979422
Validation loss: 2.5952273847622127

Epoch: 5| Step: 3
Training loss: 2.120570334245122
Validation loss: 2.609457139349666

Epoch: 5| Step: 4
Training loss: 2.0801211070603176
Validation loss: 2.6356734789837497

Epoch: 5| Step: 5
Training loss: 2.404668907802557
Validation loss: 2.622371789603881

Epoch: 5| Step: 6
Training loss: 2.0307331307910528
Validation loss: 2.6037902881625636

Epoch: 5| Step: 7
Training loss: 2.0285664364544176
Validation loss: 2.5930307950126625

Epoch: 5| Step: 8
Training loss: 2.192210547937131
Validation loss: 2.5748863663466697

Epoch: 5| Step: 9
Training loss: 2.4399836675691398
Validation loss: 2.5500173343340315

Epoch: 5| Step: 10
Training loss: 1.9936900736732581
Validation loss: 2.52523030092081

Epoch: 179| Step: 0
Training loss: 2.153240813087451
Validation loss: 2.515352811605614

Epoch: 5| Step: 1
Training loss: 1.9834196539400994
Validation loss: 2.5087730151001204

Epoch: 5| Step: 2
Training loss: 2.1195383006399386
Validation loss: 2.5003152925344465

Epoch: 5| Step: 3
Training loss: 2.312353490363918
Validation loss: 2.508996572478572

Epoch: 5| Step: 4
Training loss: 2.36130732550031
Validation loss: 2.53547196544617

Epoch: 5| Step: 5
Training loss: 1.8469875811297194
Validation loss: 2.569050853981407

Epoch: 5| Step: 6
Training loss: 2.352099284502875
Validation loss: 2.6234005881425744

Epoch: 5| Step: 7
Training loss: 2.2231568106369366
Validation loss: 2.641310008158737

Epoch: 5| Step: 8
Training loss: 2.146435501889011
Validation loss: 2.651120257436099

Epoch: 5| Step: 9
Training loss: 2.017665096745977
Validation loss: 2.647331497381498

Epoch: 5| Step: 10
Training loss: 1.8365307437889735
Validation loss: 2.6443954590197682

Epoch: 180| Step: 0
Training loss: 1.9053196121791334
Validation loss: 2.6107702918275244

Epoch: 5| Step: 1
Training loss: 2.3953659818069757
Validation loss: 2.6086840855460323

Epoch: 5| Step: 2
Training loss: 2.3407643947678167
Validation loss: 2.591654771768874

Epoch: 5| Step: 3
Training loss: 2.129379023981169
Validation loss: 2.566400633053319

Epoch: 5| Step: 4
Training loss: 1.5497454588064017
Validation loss: 2.575442724442108

Epoch: 5| Step: 5
Training loss: 2.102213818898699
Validation loss: 2.5411952544989695

Epoch: 5| Step: 6
Training loss: 2.4343031435584948
Validation loss: 2.545465387916699

Epoch: 5| Step: 7
Training loss: 2.2763272825693113
Validation loss: 2.5447315361498566

Epoch: 5| Step: 8
Training loss: 1.905751272530139
Validation loss: 2.547429850554994

Epoch: 5| Step: 9
Training loss: 2.072054033326039
Validation loss: 2.5753883631258985

Epoch: 5| Step: 10
Training loss: 2.0216267263812804
Validation loss: 2.6074402776577768

Epoch: 181| Step: 0
Training loss: 1.8445385038886775
Validation loss: 2.632579303476352

Epoch: 5| Step: 1
Training loss: 2.550249356812268
Validation loss: 2.6312285623136744

Epoch: 5| Step: 2
Training loss: 1.672640402450214
Validation loss: 2.5954061104438355

Epoch: 5| Step: 3
Training loss: 2.0440217143732466
Validation loss: 2.5929965187345734

Epoch: 5| Step: 4
Training loss: 1.8799611895187305
Validation loss: 2.5683658211268967

Epoch: 5| Step: 5
Training loss: 2.0738297437128734
Validation loss: 2.564016331221658

Epoch: 5| Step: 6
Training loss: 2.424343893427381
Validation loss: 2.5572096255087295

Epoch: 5| Step: 7
Training loss: 2.1641402798663356
Validation loss: 2.55372527398915

Epoch: 5| Step: 8
Training loss: 2.0256634696737277
Validation loss: 2.564526035855703

Epoch: 5| Step: 9
Training loss: 1.8230349111808126
Validation loss: 2.5338559234106834

Epoch: 5| Step: 10
Training loss: 2.2258718389819747
Validation loss: 2.542490977971066

Epoch: 182| Step: 0
Training loss: 2.179976468090475
Validation loss: 2.5305362101642017

Epoch: 5| Step: 1
Training loss: 1.940554088335089
Validation loss: 2.5158318325203557

Epoch: 5| Step: 2
Training loss: 1.8780148745222978
Validation loss: 2.5132343894981175

Epoch: 5| Step: 3
Training loss: 2.0017899609575744
Validation loss: 2.506888460763179

Epoch: 5| Step: 4
Training loss: 1.4782943660814263
Validation loss: 2.5148695800852545

Epoch: 5| Step: 5
Training loss: 1.6970350945192705
Validation loss: 2.526002242492463

Epoch: 5| Step: 6
Training loss: 2.2791007381669495
Validation loss: 2.5550141680271485

Epoch: 5| Step: 7
Training loss: 2.0358562180987843
Validation loss: 2.5979476588848245

Epoch: 5| Step: 8
Training loss: 2.444748591035561
Validation loss: 2.605013090010279

Epoch: 5| Step: 9
Training loss: 2.5121734824503092
Validation loss: 2.6114240115753544

Epoch: 5| Step: 10
Training loss: 1.8637353755548571
Validation loss: 2.591742384881088

Epoch: 183| Step: 0
Training loss: 1.94069334637723
Validation loss: 2.593482313935322

Epoch: 5| Step: 1
Training loss: 2.536159510833672
Validation loss: 2.613065093398417

Epoch: 5| Step: 2
Training loss: 1.9121582523758085
Validation loss: 2.585507094256725

Epoch: 5| Step: 3
Training loss: 1.9771512327068
Validation loss: 2.5561151473309023

Epoch: 5| Step: 4
Training loss: 1.8189821416304324
Validation loss: 2.5335312214176504

Epoch: 5| Step: 5
Training loss: 1.8704677482298295
Validation loss: 2.5269405658793382

Epoch: 5| Step: 6
Training loss: 1.5637940960589327
Validation loss: 2.5245866190004027

Epoch: 5| Step: 7
Training loss: 2.142028125980767
Validation loss: 2.522621359332789

Epoch: 5| Step: 8
Training loss: 2.235915393306869
Validation loss: 2.532115894013312

Epoch: 5| Step: 9
Training loss: 2.2406896180181746
Validation loss: 2.538525950848284

Epoch: 5| Step: 10
Training loss: 1.9347456766413695
Validation loss: 2.579826036938017

Epoch: 184| Step: 0
Training loss: 1.6415857317704114
Validation loss: 2.6328818635033495

Epoch: 5| Step: 1
Training loss: 2.1111155922602336
Validation loss: 2.6711928134732785

Epoch: 5| Step: 2
Training loss: 2.2643770135022443
Validation loss: 2.6094456879790484

Epoch: 5| Step: 3
Training loss: 2.168071132682424
Validation loss: 2.5790243072506236

Epoch: 5| Step: 4
Training loss: 1.9700519555884548
Validation loss: 2.533181048799339

Epoch: 5| Step: 5
Training loss: 1.9786950469685078
Validation loss: 2.515616568060356

Epoch: 5| Step: 6
Training loss: 2.3419487707462356
Validation loss: 2.519592496053302

Epoch: 5| Step: 7
Training loss: 1.8779233395791046
Validation loss: 2.4888615906923666

Epoch: 5| Step: 8
Training loss: 2.1872921436194357
Validation loss: 2.493769185405715

Epoch: 5| Step: 9
Training loss: 1.8701655050465102
Validation loss: 2.517190789238856

Epoch: 5| Step: 10
Training loss: 2.1218781820955983
Validation loss: 2.5617697630954606

Epoch: 185| Step: 0
Training loss: 1.7387758387189023
Validation loss: 2.5719263260678615

Epoch: 5| Step: 1
Training loss: 2.51816567962578
Validation loss: 2.6379830991887188

Epoch: 5| Step: 2
Training loss: 1.779872294570385
Validation loss: 2.676259721696166

Epoch: 5| Step: 3
Training loss: 1.8412013137709933
Validation loss: 2.6947639391001825

Epoch: 5| Step: 4
Training loss: 1.991472003580038
Validation loss: 2.676188481253216

Epoch: 5| Step: 5
Training loss: 2.1296325004791714
Validation loss: 2.6757453558562005

Epoch: 5| Step: 6
Training loss: 1.7329849308721306
Validation loss: 2.6873853048016136

Epoch: 5| Step: 7
Training loss: 1.8159142268758504
Validation loss: 2.6331147226481346

Epoch: 5| Step: 8
Training loss: 1.896633594115091
Validation loss: 2.633702892894875

Epoch: 5| Step: 9
Training loss: 1.9973523973684968
Validation loss: 2.609867106772666

Epoch: 5| Step: 10
Training loss: 2.3918304396147474
Validation loss: 2.575953204549209

Epoch: 186| Step: 0
Training loss: 1.5326880883794902
Validation loss: 2.526212347057857

Epoch: 5| Step: 1
Training loss: 1.8886040218752795
Validation loss: 2.50641664254745

Epoch: 5| Step: 2
Training loss: 2.4310421617022353
Validation loss: 2.4858789806697383

Epoch: 5| Step: 3
Training loss: 1.9137711283727772
Validation loss: 2.5102573504721524

Epoch: 5| Step: 4
Training loss: 1.479985059972052
Validation loss: 2.5252762946193807

Epoch: 5| Step: 5
Training loss: 1.8196470165646352
Validation loss: 2.548937050046176

Epoch: 5| Step: 6
Training loss: 2.3344030539424026
Validation loss: 2.5707709718332

Epoch: 5| Step: 7
Training loss: 2.148322084968108
Validation loss: 2.563417211014474

Epoch: 5| Step: 8
Training loss: 1.951842352270089
Validation loss: 2.5214723837896442

Epoch: 5| Step: 9
Training loss: 2.289643718373272
Validation loss: 2.5330242894898367

Epoch: 5| Step: 10
Training loss: 1.8828575793682778
Validation loss: 2.5080797591437154

Epoch: 187| Step: 0
Training loss: 1.7930231356215869
Validation loss: 2.5380298275750524

Epoch: 5| Step: 1
Training loss: 1.4672455082517668
Validation loss: 2.54332897133275

Epoch: 5| Step: 2
Training loss: 2.0754857333544625
Validation loss: 2.551775526545812

Epoch: 5| Step: 3
Training loss: 2.146449164257097
Validation loss: 2.5799329795313866

Epoch: 5| Step: 4
Training loss: 1.8995261504925456
Validation loss: 2.5935729552363282

Epoch: 5| Step: 5
Training loss: 1.9795494579429584
Validation loss: 2.6102626440995853

Epoch: 5| Step: 6
Training loss: 2.2966961434202426
Validation loss: 2.608043358129647

Epoch: 5| Step: 7
Training loss: 1.9739105165136968
Validation loss: 2.595803097729376

Epoch: 5| Step: 8
Training loss: 1.950094633985026
Validation loss: 2.5952410424487677

Epoch: 5| Step: 9
Training loss: 1.9736174706000067
Validation loss: 2.5717002707126304

Epoch: 5| Step: 10
Training loss: 2.0419990762004203
Validation loss: 2.6104285387943897

Epoch: 188| Step: 0
Training loss: 1.9248803683672486
Validation loss: 2.623285860933358

Epoch: 5| Step: 1
Training loss: 1.9286885629635735
Validation loss: 2.5634549800278736

Epoch: 5| Step: 2
Training loss: 1.6719907916604866
Validation loss: 2.5670546994534256

Epoch: 5| Step: 3
Training loss: 2.179076078244872
Validation loss: 2.5396364957536437

Epoch: 5| Step: 4
Training loss: 2.0140670551399467
Validation loss: 2.5345918448145834

Epoch: 5| Step: 5
Training loss: 1.7854174666994573
Validation loss: 2.550419284806152

Epoch: 5| Step: 6
Training loss: 1.9774182544117618
Validation loss: 2.5777062079350763

Epoch: 5| Step: 7
Training loss: 1.90624937463969
Validation loss: 2.5869978108418388

Epoch: 5| Step: 8
Training loss: 2.5501640940208348
Validation loss: 2.6234293299922427

Epoch: 5| Step: 9
Training loss: 1.6926819393349875
Validation loss: 2.586672870758367

Epoch: 5| Step: 10
Training loss: 1.6748933729708089
Validation loss: 2.581285976985615

Epoch: 189| Step: 0
Training loss: 1.889114154522791
Validation loss: 2.565848593938355

Epoch: 5| Step: 1
Training loss: 1.8187581248937599
Validation loss: 2.5679729491472716

Epoch: 5| Step: 2
Training loss: 2.0933826181153883
Validation loss: 2.562657709318333

Epoch: 5| Step: 3
Training loss: 2.3377745686393405
Validation loss: 2.5710396424924347

Epoch: 5| Step: 4
Training loss: 1.787585519198759
Validation loss: 2.569608982371698

Epoch: 5| Step: 5
Training loss: 2.160645910575125
Validation loss: 2.5927378239592116

Epoch: 5| Step: 6
Training loss: 1.9265509686275752
Validation loss: 2.550508209873202

Epoch: 5| Step: 7
Training loss: 2.0622351505273486
Validation loss: 2.5818718395954097

Epoch: 5| Step: 8
Training loss: 1.8179037504621123
Validation loss: 2.5854145092842917

Epoch: 5| Step: 9
Training loss: 1.8378535884161784
Validation loss: 2.545712757741129

Epoch: 5| Step: 10
Training loss: 1.0618865542263123
Validation loss: 2.5239969695816242

Epoch: 190| Step: 0
Training loss: 2.11958160734272
Validation loss: 2.5164808344738123

Epoch: 5| Step: 1
Training loss: 2.258672108407579
Validation loss: 2.5376708987443584

Epoch: 5| Step: 2
Training loss: 1.7067344285258268
Validation loss: 2.530689683377959

Epoch: 5| Step: 3
Training loss: 1.7806929001560425
Validation loss: 2.5343892461495368

Epoch: 5| Step: 4
Training loss: 2.038895055684746
Validation loss: 2.551518866818732

Epoch: 5| Step: 5
Training loss: 2.074562058710974
Validation loss: 2.5424224013064833

Epoch: 5| Step: 6
Training loss: 1.628273308089146
Validation loss: 2.57093499338772

Epoch: 5| Step: 7
Training loss: 1.7031963928377971
Validation loss: 2.5724162896837024

Epoch: 5| Step: 8
Training loss: 2.1493764594123856
Validation loss: 2.5838737564258265

Epoch: 5| Step: 9
Training loss: 1.2372984731709324
Validation loss: 2.599157520844871

Epoch: 5| Step: 10
Training loss: 1.996189421210518
Validation loss: 2.590093736683709

Epoch: 191| Step: 0
Training loss: 1.5550489149342328
Validation loss: 2.549365303494887

Epoch: 5| Step: 1
Training loss: 1.565925809854277
Validation loss: 2.5487117821403347

Epoch: 5| Step: 2
Training loss: 2.0251827298830354
Validation loss: 2.56728669000912

Epoch: 5| Step: 3
Training loss: 1.6665819464449712
Validation loss: 2.5520952081728407

Epoch: 5| Step: 4
Training loss: 1.9576469868981177
Validation loss: 2.5393324316781176

Epoch: 5| Step: 5
Training loss: 1.740460347960877
Validation loss: 2.511100965459357

Epoch: 5| Step: 6
Training loss: 2.2499189362228087
Validation loss: 2.54490099042344

Epoch: 5| Step: 7
Training loss: 1.6174671465737291
Validation loss: 2.5295903841881517

Epoch: 5| Step: 8
Training loss: 1.9028997529126461
Validation loss: 2.5420404929562697

Epoch: 5| Step: 9
Training loss: 2.25800003276112
Validation loss: 2.538197517313667

Epoch: 5| Step: 10
Training loss: 1.8426261321415562
Validation loss: 2.5515317466867935

Epoch: 192| Step: 0
Training loss: 1.8881740604354305
Validation loss: 2.562367883813532

Epoch: 5| Step: 1
Training loss: 1.7172315652623906
Validation loss: 2.556403711160745

Epoch: 5| Step: 2
Training loss: 2.0481490036061585
Validation loss: 2.5677276848887485

Epoch: 5| Step: 3
Training loss: 1.9775033151668726
Validation loss: 2.575740096201429

Epoch: 5| Step: 4
Training loss: 1.5684688240141393
Validation loss: 2.6037269985713913

Epoch: 5| Step: 5
Training loss: 1.9467906927527032
Validation loss: 2.5801771312821145

Epoch: 5| Step: 6
Training loss: 2.057223187687111
Validation loss: 2.5965277155420807

Epoch: 5| Step: 7
Training loss: 1.831294645735167
Validation loss: 2.591410931730057

Epoch: 5| Step: 8
Training loss: 2.082496920213563
Validation loss: 2.611523594527097

Epoch: 5| Step: 9
Training loss: 1.4309850755735651
Validation loss: 2.5911406947927134

Epoch: 5| Step: 10
Training loss: 1.3157494601640531
Validation loss: 2.606837365479289

Epoch: 193| Step: 0
Training loss: 2.1727528067445476
Validation loss: 2.6176852491723457

Epoch: 5| Step: 1
Training loss: 1.8988726709755983
Validation loss: 2.603362924562222

Epoch: 5| Step: 2
Training loss: 1.544250573920078
Validation loss: 2.619771957608739

Epoch: 5| Step: 3
Training loss: 1.8283747314987042
Validation loss: 2.6163297425181424

Epoch: 5| Step: 4
Training loss: 1.8249093490452248
Validation loss: 2.6125659262512224

Epoch: 5| Step: 5
Training loss: 1.9580783136855469
Validation loss: 2.620607169948319

Epoch: 5| Step: 6
Training loss: 1.841154890744072
Validation loss: 2.605540201213157

Epoch: 5| Step: 7
Training loss: 1.9660769890528027
Validation loss: 2.626328053756483

Epoch: 5| Step: 8
Training loss: 1.5890593222077138
Validation loss: 2.6055485841899646

Epoch: 5| Step: 9
Training loss: 1.6084987884697162
Validation loss: 2.603959656065664

Epoch: 5| Step: 10
Training loss: 1.5853498901794494
Validation loss: 2.584383297319025

Epoch: 194| Step: 0
Training loss: 1.5939550828815399
Validation loss: 2.5867566645694047

Epoch: 5| Step: 1
Training loss: 1.4775915042019547
Validation loss: 2.5935396597682807

Epoch: 5| Step: 2
Training loss: 1.420463280390845
Validation loss: 2.600875687462612

Epoch: 5| Step: 3
Training loss: 2.126136475884583
Validation loss: 2.578011642952086

Epoch: 5| Step: 4
Training loss: 2.1559140593292163
Validation loss: 2.6487319554640223

Epoch: 5| Step: 5
Training loss: 1.4902709316504466
Validation loss: 2.6091598393543207

Epoch: 5| Step: 6
Training loss: 1.6185990959143273
Validation loss: 2.647226054431607

Epoch: 5| Step: 7
Training loss: 1.923863940220237
Validation loss: 2.6952668407128293

Epoch: 5| Step: 8
Training loss: 2.0414813080809475
Validation loss: 2.6959856592979223

Epoch: 5| Step: 9
Training loss: 1.7943001252446942
Validation loss: 2.6749083618960894

Epoch: 5| Step: 10
Training loss: 1.8269617014829027
Validation loss: 2.6451047889553663

Epoch: 195| Step: 0
Training loss: 1.7087342171822635
Validation loss: 2.588166809637397

Epoch: 5| Step: 1
Training loss: 1.4085950583791977
Validation loss: 2.545218106861056

Epoch: 5| Step: 2
Training loss: 1.8288155580087468
Validation loss: 2.5367954226658664

Epoch: 5| Step: 3
Training loss: 2.030483042368357
Validation loss: 2.5179342998710497

Epoch: 5| Step: 4
Training loss: 1.4686267882266495
Validation loss: 2.489865564086868

Epoch: 5| Step: 5
Training loss: 2.63420796979145
Validation loss: 2.4843707310025978

Epoch: 5| Step: 6
Training loss: 1.7823684259677741
Validation loss: 2.494155147666734

Epoch: 5| Step: 7
Training loss: 1.8386935062404357
Validation loss: 2.517311522424805

Epoch: 5| Step: 8
Training loss: 1.3467112890882875
Validation loss: 2.5032082163607434

Epoch: 5| Step: 9
Training loss: 1.938940558645292
Validation loss: 2.543445030741622

Epoch: 5| Step: 10
Training loss: 1.1960732027826704
Validation loss: 2.563245589312862

Epoch: 196| Step: 0
Training loss: 1.941283070515319
Validation loss: 2.568516322312304

Epoch: 5| Step: 1
Training loss: 1.5410587899432258
Validation loss: 2.592902617267163

Epoch: 5| Step: 2
Training loss: 1.763070207709271
Validation loss: 2.5734061222768654

Epoch: 5| Step: 3
Training loss: 1.2555985483940753
Validation loss: 2.549528787624359

Epoch: 5| Step: 4
Training loss: 1.7954745598830906
Validation loss: 2.546798993809835

Epoch: 5| Step: 5
Training loss: 1.695596135052314
Validation loss: 2.5416666821325644

Epoch: 5| Step: 6
Training loss: 2.1111935158870296
Validation loss: 2.5418704294328283

Epoch: 5| Step: 7
Training loss: 1.824351205856866
Validation loss: 2.5113864533998336

Epoch: 5| Step: 8
Training loss: 1.6850846984132328
Validation loss: 2.545735722231993

Epoch: 5| Step: 9
Training loss: 1.9293136543429392
Validation loss: 2.588534529316234

Epoch: 5| Step: 10
Training loss: 1.5851525680326262
Validation loss: 2.5867731379778007

Epoch: 197| Step: 0
Training loss: 2.062577332867507
Validation loss: 2.599691146415451

Epoch: 5| Step: 1
Training loss: 2.099280497498544
Validation loss: 2.655101250246461

Epoch: 5| Step: 2
Training loss: 1.3904832917779866
Validation loss: 2.653397304072735

Epoch: 5| Step: 3
Training loss: 1.3207504178244547
Validation loss: 2.6343362067067053

Epoch: 5| Step: 4
Training loss: 2.1171109231423544
Validation loss: 2.6436384423186077

Epoch: 5| Step: 5
Training loss: 1.5591415169320477
Validation loss: 2.6178116033609733

Epoch: 5| Step: 6
Training loss: 1.7421151732070241
Validation loss: 2.570086739600034

Epoch: 5| Step: 7
Training loss: 2.1326898672319192
Validation loss: 2.581190375222641

Epoch: 5| Step: 8
Training loss: 1.303298210506576
Validation loss: 2.543525395068465

Epoch: 5| Step: 9
Training loss: 1.0092843714793727
Validation loss: 2.539124375465759

Epoch: 5| Step: 10
Training loss: 2.080947450750654
Validation loss: 2.559102955872267

Epoch: 198| Step: 0
Training loss: 2.2796815679942313
Validation loss: 2.548640779688382

Epoch: 5| Step: 1
Training loss: 1.7868858989798146
Validation loss: 2.5686320086827474

Epoch: 5| Step: 2
Training loss: 1.1306657641871318
Validation loss: 2.5639230341964745

Epoch: 5| Step: 3
Training loss: 1.746445929663626
Validation loss: 2.6098120617303735

Epoch: 5| Step: 4
Training loss: 1.9140553999788597
Validation loss: 2.628488544003379

Epoch: 5| Step: 5
Training loss: 1.6669763118477343
Validation loss: 2.6269753656415267

Epoch: 5| Step: 6
Training loss: 1.2510866210551446
Validation loss: 2.6227985053415077

Epoch: 5| Step: 7
Training loss: 1.8622479082562584
Validation loss: 2.6376957809675563

Epoch: 5| Step: 8
Training loss: 1.8924948533264083
Validation loss: 2.6547936594245076

Epoch: 5| Step: 9
Training loss: 1.3564796306094544
Validation loss: 2.6249747804913746

Epoch: 5| Step: 10
Training loss: 1.8210871934875001
Validation loss: 2.6084383542943814

Epoch: 199| Step: 0
Training loss: 2.0542313101954592
Validation loss: 2.5794641024422305

Epoch: 5| Step: 1
Training loss: 1.5493127129742459
Validation loss: 2.554011686745087

Epoch: 5| Step: 2
Training loss: 1.9624200816799116
Validation loss: 2.545809112753703

Epoch: 5| Step: 3
Training loss: 1.8648810406501448
Validation loss: 2.504964766550669

Epoch: 5| Step: 4
Training loss: 1.702185975633124
Validation loss: 2.532288868218203

Epoch: 5| Step: 5
Training loss: 1.4465882315812153
Validation loss: 2.536462210776293

Epoch: 5| Step: 6
Training loss: 1.5833416068546902
Validation loss: 2.544884804053563

Epoch: 5| Step: 7
Training loss: 1.822071453514891
Validation loss: 2.561507846576734

Epoch: 5| Step: 8
Training loss: 1.7804143183423615
Validation loss: 2.5809714202574683

Epoch: 5| Step: 9
Training loss: 1.5774103945086255
Validation loss: 2.585044421850091

Epoch: 5| Step: 10
Training loss: 1.2915261048570728
Validation loss: 2.54579370554182

Epoch: 200| Step: 0
Training loss: 1.784390742404527
Validation loss: 2.546942352586074

Epoch: 5| Step: 1
Training loss: 1.9657267412257595
Validation loss: 2.4971157735897647

Epoch: 5| Step: 2
Training loss: 1.8536701680624634
Validation loss: 2.5331537432260496

Epoch: 5| Step: 3
Training loss: 1.548153743669564
Validation loss: 2.520577494948468

Epoch: 5| Step: 4
Training loss: 1.7913476600831226
Validation loss: 2.510399491364507

Epoch: 5| Step: 5
Training loss: 1.7656640242593495
Validation loss: 2.5132318322156095

Epoch: 5| Step: 6
Training loss: 1.3057649925783739
Validation loss: 2.532218167617922

Epoch: 5| Step: 7
Training loss: 1.543021517466976
Validation loss: 2.540085266449767

Epoch: 5| Step: 8
Training loss: 1.825143126532073
Validation loss: 2.5521698562658144

Epoch: 5| Step: 9
Training loss: 1.5316261296655325
Validation loss: 2.6116971755530156

Epoch: 5| Step: 10
Training loss: 1.7541911482140868
Validation loss: 2.619337274219315

Epoch: 201| Step: 0
Training loss: 1.5769645276624764
Validation loss: 2.6155283165214445

Epoch: 5| Step: 1
Training loss: 1.8074134617055848
Validation loss: 2.5889672261549705

Epoch: 5| Step: 2
Training loss: 1.4173229417775832
Validation loss: 2.6295989797711696

Epoch: 5| Step: 3
Training loss: 1.4367238312756376
Validation loss: 2.588052088598863

Epoch: 5| Step: 4
Training loss: 1.8594878346803505
Validation loss: 2.5691035671953237

Epoch: 5| Step: 5
Training loss: 1.5745684138359481
Validation loss: 2.549938186517214

Epoch: 5| Step: 6
Training loss: 1.660265176228954
Validation loss: 2.538086280923264

Epoch: 5| Step: 7
Training loss: 1.779105920521408
Validation loss: 2.570738436119371

Epoch: 5| Step: 8
Training loss: 1.5495257544258987
Validation loss: 2.5979566495545683

Epoch: 5| Step: 9
Training loss: 1.8592638254989091
Validation loss: 2.5876779826080516

Epoch: 5| Step: 10
Training loss: 1.8203238294519013
Validation loss: 2.6088130887005736

Epoch: 202| Step: 0
Training loss: 1.9153289342104542
Validation loss: 2.6336185018460365

Epoch: 5| Step: 1
Training loss: 1.3267574674756655
Validation loss: 2.626973386046645

Epoch: 5| Step: 2
Training loss: 1.8926123900406937
Validation loss: 2.641135165324758

Epoch: 5| Step: 3
Training loss: 2.0712388755117437
Validation loss: 2.628600657611131

Epoch: 5| Step: 4
Training loss: 1.2662313445243072
Validation loss: 2.6282697081685664

Epoch: 5| Step: 5
Training loss: 1.9318642636275083
Validation loss: 2.6435637752011987

Epoch: 5| Step: 6
Training loss: 1.1831354947438308
Validation loss: 2.619378537908696

Epoch: 5| Step: 7
Training loss: 1.675970462529687
Validation loss: 2.587404025660266

Epoch: 5| Step: 8
Training loss: 1.6283911752855715
Validation loss: 2.581335587043388

Epoch: 5| Step: 9
Training loss: 1.555905732219176
Validation loss: 2.578080005818681

Epoch: 5| Step: 10
Training loss: 1.3327862789530813
Validation loss: 2.5845168353719075

Epoch: 203| Step: 0
Training loss: 1.5450957883998035
Validation loss: 2.6082163628193946

Epoch: 5| Step: 1
Training loss: 1.8162004251665067
Validation loss: 2.58475588658826

Epoch: 5| Step: 2
Training loss: 1.9513130022394511
Validation loss: 2.61124039638041

Epoch: 5| Step: 3
Training loss: 1.0183557039874378
Validation loss: 2.616724696814694

Epoch: 5| Step: 4
Training loss: 1.4299567964336364
Validation loss: 2.6353570475058974

Epoch: 5| Step: 5
Training loss: 1.6192253652008841
Validation loss: 2.641252437696594

Epoch: 5| Step: 6
Training loss: 1.2651785545837542
Validation loss: 2.6120935133938574

Epoch: 5| Step: 7
Training loss: 1.9063072196002087
Validation loss: 2.6256651497099606

Epoch: 5| Step: 8
Training loss: 1.2485440835346415
Validation loss: 2.6099647080109833

Epoch: 5| Step: 9
Training loss: 1.969814073531674
Validation loss: 2.5833090848178326

Epoch: 5| Step: 10
Training loss: 1.9068661303768724
Validation loss: 2.570377994713655

Epoch: 204| Step: 0
Training loss: 1.6941145782544198
Validation loss: 2.5210117150529077

Epoch: 5| Step: 1
Training loss: 1.6614651894104067
Validation loss: 2.49358920578381

Epoch: 5| Step: 2
Training loss: 1.555832254497615
Validation loss: 2.516039584424687

Epoch: 5| Step: 3
Training loss: 1.3725332327677462
Validation loss: 2.5294157416388443

Epoch: 5| Step: 4
Training loss: 1.3775176926738384
Validation loss: 2.5388553516583765

Epoch: 5| Step: 5
Training loss: 1.8609047375156405
Validation loss: 2.5557148349719174

Epoch: 5| Step: 6
Training loss: 1.736779067501717
Validation loss: 2.5671359509611884

Epoch: 5| Step: 7
Training loss: 1.8984711569483084
Validation loss: 2.596942949184112

Epoch: 5| Step: 8
Training loss: 1.4990964393360193
Validation loss: 2.624757920610891

Epoch: 5| Step: 9
Training loss: 1.7112848634700333
Validation loss: 2.614852256722706

Epoch: 5| Step: 10
Training loss: 1.4580420702763273
Validation loss: 2.5716251856672434

Epoch: 205| Step: 0
Training loss: 1.3935542597833523
Validation loss: 2.53214777889915

Epoch: 5| Step: 1
Training loss: 1.9544840242519017
Validation loss: 2.497451632928077

Epoch: 5| Step: 2
Training loss: 1.7475748970015228
Validation loss: 2.4933837535736747

Epoch: 5| Step: 3
Training loss: 1.808902063311361
Validation loss: 2.4881111027991634

Epoch: 5| Step: 4
Training loss: 1.6125814106816592
Validation loss: 2.500799946317636

Epoch: 5| Step: 5
Training loss: 1.5427779840290567
Validation loss: 2.5331925575128973

Epoch: 5| Step: 6
Training loss: 1.129050592084648
Validation loss: 2.5589093729189267

Epoch: 5| Step: 7
Training loss: 1.6519003559523449
Validation loss: 2.5673822902622634

Epoch: 5| Step: 8
Training loss: 1.7941453185747855
Validation loss: 2.5801933744557637

Epoch: 5| Step: 9
Training loss: 1.5644636403848386
Validation loss: 2.589586504415023

Epoch: 5| Step: 10
Training loss: 1.4840277014560628
Validation loss: 2.6394560648213345

Epoch: 206| Step: 0
Training loss: 1.5293875286179957
Validation loss: 2.623983077796046

Epoch: 5| Step: 1
Training loss: 1.4756378023334646
Validation loss: 2.629373758459662

Epoch: 5| Step: 2
Training loss: 1.4643226612228106
Validation loss: 2.629922826267821

Epoch: 5| Step: 3
Training loss: 1.4061737887606167
Validation loss: 2.604245705338273

Epoch: 5| Step: 4
Training loss: 1.3442195249469018
Validation loss: 2.5730899202614927

Epoch: 5| Step: 5
Training loss: 1.5633708053170248
Validation loss: 2.5635825360919866

Epoch: 5| Step: 6
Training loss: 1.8320293629846025
Validation loss: 2.56725268015294

Epoch: 5| Step: 7
Training loss: 1.436005188318937
Validation loss: 2.5391173361385566

Epoch: 5| Step: 8
Training loss: 2.081433867159698
Validation loss: 2.5162346713276706

Epoch: 5| Step: 9
Training loss: 1.3376719052370376
Validation loss: 2.498323368501211

Epoch: 5| Step: 10
Training loss: 2.0020339875056283
Validation loss: 2.545500362635725

Epoch: 207| Step: 0
Training loss: 1.5725046675086685
Validation loss: 2.5631121512778856

Epoch: 5| Step: 1
Training loss: 1.6746086517467678
Validation loss: 2.6061537717300465

Epoch: 5| Step: 2
Training loss: 1.571034128052713
Validation loss: 2.6390350199510113

Epoch: 5| Step: 3
Training loss: 1.672948617341079
Validation loss: 2.6187174013895795

Epoch: 5| Step: 4
Training loss: 1.0152630674586907
Validation loss: 2.6192304273063574

Epoch: 5| Step: 5
Training loss: 1.7213482724395193
Validation loss: 2.590857536580646

Epoch: 5| Step: 6
Training loss: 1.5102593526362755
Validation loss: 2.595590804786152

Epoch: 5| Step: 7
Training loss: 1.7903172786127506
Validation loss: 2.560577875223142

Epoch: 5| Step: 8
Training loss: 1.7316618997448885
Validation loss: 2.546493629556148

Epoch: 5| Step: 9
Training loss: 1.6662606062555114
Validation loss: 2.5212906114482965

Epoch: 5| Step: 10
Training loss: 1.4244336592281988
Validation loss: 2.5138969970432163

Epoch: 208| Step: 0
Training loss: 2.189657183078378
Validation loss: 2.525078234033692

Epoch: 5| Step: 1
Training loss: 1.5106654872053569
Validation loss: 2.528110148368514

Epoch: 5| Step: 2
Training loss: 1.2341602476641222
Validation loss: 2.547296244234593

Epoch: 5| Step: 3
Training loss: 1.482957745624678
Validation loss: 2.5519163825898765

Epoch: 5| Step: 4
Training loss: 1.4892631755794827
Validation loss: 2.5355948133258934

Epoch: 5| Step: 5
Training loss: 1.4658563394712798
Validation loss: 2.584880163973766

Epoch: 5| Step: 6
Training loss: 1.1328244438857145
Validation loss: 2.574528791954457

Epoch: 5| Step: 7
Training loss: 1.1067069839310948
Validation loss: 2.586702189188367

Epoch: 5| Step: 8
Training loss: 2.170478426671634
Validation loss: 2.5938295504640196

Epoch: 5| Step: 9
Training loss: 1.7207545295510511
Validation loss: 2.570091994381849

Epoch: 5| Step: 10
Training loss: 1.2836139549666528
Validation loss: 2.5481916535107074

Epoch: 209| Step: 0
Training loss: 1.4951574518225017
Validation loss: 2.5567414382880758

Epoch: 5| Step: 1
Training loss: 1.4560199735969228
Validation loss: 2.553269088016334

Epoch: 5| Step: 2
Training loss: 1.5344095136874576
Validation loss: 2.5228743315075697

Epoch: 5| Step: 3
Training loss: 1.5832958300649624
Validation loss: 2.5539806309123096

Epoch: 5| Step: 4
Training loss: 1.5002811486294365
Validation loss: 2.5467181896999525

Epoch: 5| Step: 5
Training loss: 1.869530010422241
Validation loss: 2.5416692491340394

Epoch: 5| Step: 6
Training loss: 1.2583617912426068
Validation loss: 2.5364320821911934

Epoch: 5| Step: 7
Training loss: 1.7576377951376911
Validation loss: 2.5654738912710395

Epoch: 5| Step: 8
Training loss: 1.0013941345100967
Validation loss: 2.5730617479466122

Epoch: 5| Step: 9
Training loss: 1.885931194203224
Validation loss: 2.574886868145417

Epoch: 5| Step: 10
Training loss: 1.5793772346532098
Validation loss: 2.5605585520651015

Epoch: 210| Step: 0
Training loss: 1.587044540909975
Validation loss: 2.558798665214715

Epoch: 5| Step: 1
Training loss: 1.2877810958369373
Validation loss: 2.5523433958795154

Epoch: 5| Step: 2
Training loss: 1.349683215802886
Validation loss: 2.552207338703597

Epoch: 5| Step: 3
Training loss: 1.64759052809354
Validation loss: 2.5501896421951304

Epoch: 5| Step: 4
Training loss: 1.5188901671731576
Validation loss: 2.5528905586803035

Epoch: 5| Step: 5
Training loss: 1.5097307248048168
Validation loss: 2.6037041113453046

Epoch: 5| Step: 6
Training loss: 1.6525266289116447
Validation loss: 2.5740334419223445

Epoch: 5| Step: 7
Training loss: 1.734665717426444
Validation loss: 2.6080532016197093

Epoch: 5| Step: 8
Training loss: 1.4239430740904364
Validation loss: 2.645743708553636

Epoch: 5| Step: 9
Training loss: 1.8234540819265654
Validation loss: 2.6336459884173897

Epoch: 5| Step: 10
Training loss: 1.4571968373149402
Validation loss: 2.615820760815072

Epoch: 211| Step: 0
Training loss: 1.8499886950585624
Validation loss: 2.657571083578076

Epoch: 5| Step: 1
Training loss: 1.403073389340322
Validation loss: 2.6224502528665123

Epoch: 5| Step: 2
Training loss: 1.1801948719429762
Validation loss: 2.586897796119026

Epoch: 5| Step: 3
Training loss: 1.25886557903596
Validation loss: 2.6083840201671755

Epoch: 5| Step: 4
Training loss: 1.4360039431005125
Validation loss: 2.602154153869477

Epoch: 5| Step: 5
Training loss: 1.2031356018391959
Validation loss: 2.5625949234767553

Epoch: 5| Step: 6
Training loss: 1.5864643293014036
Validation loss: 2.5438285603863466

Epoch: 5| Step: 7
Training loss: 1.7278749474734696
Validation loss: 2.528397161629982

Epoch: 5| Step: 8
Training loss: 1.839647092250709
Validation loss: 2.5338514362746234

Epoch: 5| Step: 9
Training loss: 1.5495856838852993
Validation loss: 2.5475375352206933

Epoch: 5| Step: 10
Training loss: 1.6231834087945254
Validation loss: 2.5412501439839406

Epoch: 212| Step: 0
Training loss: 1.5956117564158658
Validation loss: 2.5404864835365384

Epoch: 5| Step: 1
Training loss: 0.9777303502803544
Validation loss: 2.546389923818879

Epoch: 5| Step: 2
Training loss: 1.3147887301705625
Validation loss: 2.5568758081289844

Epoch: 5| Step: 3
Training loss: 1.8741689111682869
Validation loss: 2.5558521919476607

Epoch: 5| Step: 4
Training loss: 1.264414031349801
Validation loss: 2.579213718152979

Epoch: 5| Step: 5
Training loss: 1.7667034535206765
Validation loss: 2.5735476213698374

Epoch: 5| Step: 6
Training loss: 1.007742591030071
Validation loss: 2.5721974514533565

Epoch: 5| Step: 7
Training loss: 1.6355541519721086
Validation loss: 2.621624268782461

Epoch: 5| Step: 8
Training loss: 1.6203892659291557
Validation loss: 2.6480279944021654

Epoch: 5| Step: 9
Training loss: 1.5979097720133792
Validation loss: 2.5892155855450434

Epoch: 5| Step: 10
Training loss: 1.6604845148804355
Validation loss: 2.626411466743558

Epoch: 213| Step: 0
Training loss: 1.1878749355897
Validation loss: 2.623327993341722

Epoch: 5| Step: 1
Training loss: 1.5578138651789248
Validation loss: 2.6211546484956054

Epoch: 5| Step: 2
Training loss: 1.746093067279998
Validation loss: 2.616822619310975

Epoch: 5| Step: 3
Training loss: 1.9243777966331883
Validation loss: 2.6419788571166656

Epoch: 5| Step: 4
Training loss: 1.3312254227353006
Validation loss: 2.6162495700064126

Epoch: 5| Step: 5
Training loss: 1.135150889983259
Validation loss: 2.610584421113962

Epoch: 5| Step: 6
Training loss: 1.5371535802589729
Validation loss: 2.60943107895954

Epoch: 5| Step: 7
Training loss: 1.093088167768531
Validation loss: 2.611415066289803

Epoch: 5| Step: 8
Training loss: 1.4854729055465108
Validation loss: 2.5725942712528966

Epoch: 5| Step: 9
Training loss: 1.6216062172381434
Validation loss: 2.5467340543726653

Epoch: 5| Step: 10
Training loss: 1.7225872553634833
Validation loss: 2.5369627806960557

Epoch: 214| Step: 0
Training loss: 1.3070110713953889
Validation loss: 2.519638535686883

Epoch: 5| Step: 1
Training loss: 1.4944726512725521
Validation loss: 2.492920085771244

Epoch: 5| Step: 2
Training loss: 1.2296216682931076
Validation loss: 2.5032307391899864

Epoch: 5| Step: 3
Training loss: 1.5281533049475897
Validation loss: 2.515127296973274

Epoch: 5| Step: 4
Training loss: 1.2195040008804614
Validation loss: 2.502978130240822

Epoch: 5| Step: 5
Training loss: 2.1976807333582205
Validation loss: 2.527571466979964

Epoch: 5| Step: 6
Training loss: 1.1342426611679937
Validation loss: 2.5367638589515096

Epoch: 5| Step: 7
Training loss: 1.5158639306574686
Validation loss: 2.533300499252637

Epoch: 5| Step: 8
Training loss: 1.8897004822653642
Validation loss: 2.590140534371437

Epoch: 5| Step: 9
Training loss: 1.5058093427567112
Validation loss: 2.5797343769893675

Epoch: 5| Step: 10
Training loss: 0.6591917361818413
Validation loss: 2.622911336693135

Epoch: 215| Step: 0
Training loss: 1.3516600909859053
Validation loss: 2.611444638038322

Epoch: 5| Step: 1
Training loss: 1.4643255919499263
Validation loss: 2.6176354475660992

Epoch: 5| Step: 2
Training loss: 1.4113070792860236
Validation loss: 2.6347036613546773

Epoch: 5| Step: 3
Training loss: 1.5891917248360419
Validation loss: 2.6155021735183936

Epoch: 5| Step: 4
Training loss: 1.5808355640213987
Validation loss: 2.642775449552475

Epoch: 5| Step: 5
Training loss: 1.371332522737124
Validation loss: 2.6045403308842774

Epoch: 5| Step: 6
Training loss: 1.264621006730741
Validation loss: 2.5616299392428936

Epoch: 5| Step: 7
Training loss: 1.915634008389523
Validation loss: 2.5570323677213818

Epoch: 5| Step: 8
Training loss: 1.419197831915798
Validation loss: 2.561514790344111

Epoch: 5| Step: 9
Training loss: 1.6004253537313795
Validation loss: 2.53771556482363

Epoch: 5| Step: 10
Training loss: 1.1045160400621246
Validation loss: 2.5302698801972734

Epoch: 216| Step: 0
Training loss: 1.4756164749590777
Validation loss: 2.512613719769959

Epoch: 5| Step: 1
Training loss: 1.3945854026901412
Validation loss: 2.5368321227083848

Epoch: 5| Step: 2
Training loss: 1.464846354164352
Validation loss: 2.542315132743055

Epoch: 5| Step: 3
Training loss: 1.754382096545656
Validation loss: 2.5422492826267886

Epoch: 5| Step: 4
Training loss: 1.7435930680513694
Validation loss: 2.5388536895889464

Epoch: 5| Step: 5
Training loss: 1.7761491386882913
Validation loss: 2.5788635250168293

Epoch: 5| Step: 6
Training loss: 1.1878995725074588
Validation loss: 2.5809121656471135

Epoch: 5| Step: 7
Training loss: 1.0832747052296368
Validation loss: 2.572874775233674

Epoch: 5| Step: 8
Training loss: 1.4967204641317813
Validation loss: 2.5847679214358115

Epoch: 5| Step: 9
Training loss: 1.142757147433458
Validation loss: 2.603703895715072

Epoch: 5| Step: 10
Training loss: 1.5149681791734377
Validation loss: 2.6111978981043436

Epoch: 217| Step: 0
Training loss: 1.8739810718162644
Validation loss: 2.600550287020589

Epoch: 5| Step: 1
Training loss: 1.4931140838901047
Validation loss: 2.572150181792327

Epoch: 5| Step: 2
Training loss: 1.1632068740914463
Validation loss: 2.5608725323140358

Epoch: 5| Step: 3
Training loss: 1.3739286063301683
Validation loss: 2.5524168886881267

Epoch: 5| Step: 4
Training loss: 1.1312654652249705
Validation loss: 2.541882498897225

Epoch: 5| Step: 5
Training loss: 1.5556432958487199
Validation loss: 2.513763336066146

Epoch: 5| Step: 6
Training loss: 1.5386533241674147
Validation loss: 2.5921414711708364

Epoch: 5| Step: 7
Training loss: 1.3085893773247839
Validation loss: 2.638253557946911

Epoch: 5| Step: 8
Training loss: 1.3673974448179749
Validation loss: 2.6252545918391967

Epoch: 5| Step: 9
Training loss: 1.7907410455884867
Validation loss: 2.648754632671068

Epoch: 5| Step: 10
Training loss: 1.3278058285634253
Validation loss: 2.628382371464808

Epoch: 218| Step: 0
Training loss: 1.8749818165215302
Validation loss: 2.6326234207426507

Epoch: 5| Step: 1
Training loss: 1.752982867186016
Validation loss: 2.581074076721436

Epoch: 5| Step: 2
Training loss: 1.0129149446168104
Validation loss: 2.580898191752699

Epoch: 5| Step: 3
Training loss: 1.5204196088488355
Validation loss: 2.5862811778787886

Epoch: 5| Step: 4
Training loss: 1.1919286864441263
Validation loss: 2.5602004224967243

Epoch: 5| Step: 5
Training loss: 1.513705739288528
Validation loss: 2.5575664177102095

Epoch: 5| Step: 6
Training loss: 1.523552210474985
Validation loss: 2.5509123733699104

Epoch: 5| Step: 7
Training loss: 1.0700980758283232
Validation loss: 2.543375658811418

Epoch: 5| Step: 8
Training loss: 1.6197173008503898
Validation loss: 2.5502866875390042

Epoch: 5| Step: 9
Training loss: 1.5345439903290505
Validation loss: 2.5743813658556625

Epoch: 5| Step: 10
Training loss: 1.0551724484597125
Validation loss: 2.5914354609036967

Epoch: 219| Step: 0
Training loss: 1.616255118235828
Validation loss: 2.5748409815311195

Epoch: 5| Step: 1
Training loss: 1.501058046391436
Validation loss: 2.594233596657419

Epoch: 5| Step: 2
Training loss: 1.5315084433925323
Validation loss: 2.5806216027353526

Epoch: 5| Step: 3
Training loss: 1.279239938648311
Validation loss: 2.5734124760659727

Epoch: 5| Step: 4
Training loss: 1.0525433255518255
Validation loss: 2.5528516180955734

Epoch: 5| Step: 5
Training loss: 1.421369861121479
Validation loss: 2.553607599660891

Epoch: 5| Step: 6
Training loss: 1.518388097524269
Validation loss: 2.5402614714093605

Epoch: 5| Step: 7
Training loss: 1.2679509582963584
Validation loss: 2.5589268000218457

Epoch: 5| Step: 8
Training loss: 1.1874220471143895
Validation loss: 2.568339681173601

Epoch: 5| Step: 9
Training loss: 1.7031206603388662
Validation loss: 2.5881164192237955

Epoch: 5| Step: 10
Training loss: 1.6291299570277922
Validation loss: 2.603617929706399

Epoch: 220| Step: 0
Training loss: 1.4822509023708994
Validation loss: 2.605416735141757

Epoch: 5| Step: 1
Training loss: 1.7843377638905007
Validation loss: 2.628638053758395

Epoch: 5| Step: 2
Training loss: 1.5013523363589991
Validation loss: 2.634845832489243

Epoch: 5| Step: 3
Training loss: 1.2691482200876685
Validation loss: 2.633061812943299

Epoch: 5| Step: 4
Training loss: 1.4547221113076267
Validation loss: 2.6345353590970357

Epoch: 5| Step: 5
Training loss: 1.163949384889924
Validation loss: 2.592306405238994

Epoch: 5| Step: 6
Training loss: 1.3496249207679194
Validation loss: 2.568399363084462

Epoch: 5| Step: 7
Training loss: 1.6749505960950404
Validation loss: 2.5433981283292058

Epoch: 5| Step: 8
Training loss: 1.3337542892572993
Validation loss: 2.5358104432142894

Epoch: 5| Step: 9
Training loss: 1.3142803016175004
Validation loss: 2.5205895372017517

Epoch: 5| Step: 10
Training loss: 1.1108559408174354
Validation loss: 2.497685300184964

Epoch: 221| Step: 0
Training loss: 1.4241272411986738
Validation loss: 2.5072559271543398

Epoch: 5| Step: 1
Training loss: 1.3726699333399073
Validation loss: 2.53240895296927

Epoch: 5| Step: 2
Training loss: 1.2805889564308455
Validation loss: 2.530342897114247

Epoch: 5| Step: 3
Training loss: 1.8981070525244401
Validation loss: 2.494817455452265

Epoch: 5| Step: 4
Training loss: 1.4844394870603579
Validation loss: 2.537343148678191

Epoch: 5| Step: 5
Training loss: 1.0286735949411743
Validation loss: 2.574132616955909

Epoch: 5| Step: 6
Training loss: 1.445353574426909
Validation loss: 2.624259853662387

Epoch: 5| Step: 7
Training loss: 1.786307466622325
Validation loss: 2.6511516287543873

Epoch: 5| Step: 8
Training loss: 1.303160224639729
Validation loss: 2.6437846313557323

Epoch: 5| Step: 9
Training loss: 1.1215789489305164
Validation loss: 2.644546933102713

Epoch: 5| Step: 10
Training loss: 1.0724292067524963
Validation loss: 2.623083873383972

Epoch: 222| Step: 0
Training loss: 1.4747120398346756
Validation loss: 2.6291873268865547

Epoch: 5| Step: 1
Training loss: 1.9544534666621711
Validation loss: 2.622820051067687

Epoch: 5| Step: 2
Training loss: 1.381357105987362
Validation loss: 2.602955077500048

Epoch: 5| Step: 3
Training loss: 0.843705599994167
Validation loss: 2.5842534238480317

Epoch: 5| Step: 4
Training loss: 1.3510006304498723
Validation loss: 2.5283079237856945

Epoch: 5| Step: 5
Training loss: 1.1193889988077672
Validation loss: 2.5312439870212224

Epoch: 5| Step: 6
Training loss: 0.9885084773053744
Validation loss: 2.565365910214048

Epoch: 5| Step: 7
Training loss: 1.3402279672716886
Validation loss: 2.578401254300913

Epoch: 5| Step: 8
Training loss: 1.1371796712372646
Validation loss: 2.560843057819374

Epoch: 5| Step: 9
Training loss: 1.5884185326385838
Validation loss: 2.5527557854952945

Epoch: 5| Step: 10
Training loss: 1.8028104193654437
Validation loss: 2.5543492323333394

Epoch: 223| Step: 0
Training loss: 1.4615703170988186
Validation loss: 2.5680382978811154

Epoch: 5| Step: 1
Training loss: 1.2900792591378982
Validation loss: 2.5653541560973685

Epoch: 5| Step: 2
Training loss: 1.9182514673767086
Validation loss: 2.5958534604036947

Epoch: 5| Step: 3
Training loss: 1.4265553502449957
Validation loss: 2.5917818826161936

Epoch: 5| Step: 4
Training loss: 1.080362127398417
Validation loss: 2.5760152318959286

Epoch: 5| Step: 5
Training loss: 1.4576655175790212
Validation loss: 2.601843356137682

Epoch: 5| Step: 6
Training loss: 0.9951710335461017
Validation loss: 2.572665246386414

Epoch: 5| Step: 7
Training loss: 1.4024126466280973
Validation loss: 2.614097898887788

Epoch: 5| Step: 8
Training loss: 1.5057599422019563
Validation loss: 2.6269234721449055

Epoch: 5| Step: 9
Training loss: 1.1613961218807112
Validation loss: 2.6027777162693715

Epoch: 5| Step: 10
Training loss: 1.3128053219205578
Validation loss: 2.630088346447842

Epoch: 224| Step: 0
Training loss: 1.376768405509348
Validation loss: 2.610753595712496

Epoch: 5| Step: 1
Training loss: 1.4763003323443056
Validation loss: 2.5739320006506583

Epoch: 5| Step: 2
Training loss: 1.1988946433209597
Validation loss: 2.5737322093986617

Epoch: 5| Step: 3
Training loss: 1.2575355367018919
Validation loss: 2.548489965840848

Epoch: 5| Step: 4
Training loss: 1.2258842682688884
Validation loss: 2.567997532485854

Epoch: 5| Step: 5
Training loss: 1.0634297061963014
Validation loss: 2.549049760008819

Epoch: 5| Step: 6
Training loss: 1.4551910970982802
Validation loss: 2.554567251730577

Epoch: 5| Step: 7
Training loss: 1.2335717690305092
Validation loss: 2.551358079519298

Epoch: 5| Step: 8
Training loss: 1.9894621514236006
Validation loss: 2.580863286485452

Epoch: 5| Step: 9
Training loss: 1.5521370368558987
Validation loss: 2.5630782980756663

Epoch: 5| Step: 10
Training loss: 0.9183564037175953
Validation loss: 2.5817036531282875

Epoch: 225| Step: 0
Training loss: 1.2602764661174546
Validation loss: 2.588441176110513

Epoch: 5| Step: 1
Training loss: 1.5020872534896057
Validation loss: 2.590066842056684

Epoch: 5| Step: 2
Training loss: 1.53616455200542
Validation loss: 2.62865525362289

Epoch: 5| Step: 3
Training loss: 1.285017753953409
Validation loss: 2.6154901271831674

Epoch: 5| Step: 4
Training loss: 1.288602989832506
Validation loss: 2.618683762363298

Epoch: 5| Step: 5
Training loss: 1.4839814316855189
Validation loss: 2.619883682930401

Epoch: 5| Step: 6
Training loss: 1.4767172596073994
Validation loss: 2.605445686202952

Epoch: 5| Step: 7
Training loss: 1.164328883881089
Validation loss: 2.560217656565621

Epoch: 5| Step: 8
Training loss: 1.029100316080036
Validation loss: 2.564057548849964

Epoch: 5| Step: 9
Training loss: 1.51260231869984
Validation loss: 2.5728543875881593

Epoch: 5| Step: 10
Training loss: 1.2766314278977422
Validation loss: 2.5451777465106145

Epoch: 226| Step: 0
Training loss: 1.5176659439580078
Validation loss: 2.5535336326172198

Epoch: 5| Step: 1
Training loss: 1.7937568478337276
Validation loss: 2.534147861563885

Epoch: 5| Step: 2
Training loss: 1.382197615129138
Validation loss: 2.5645692215769795

Epoch: 5| Step: 3
Training loss: 1.2920919251527903
Validation loss: 2.5450627366500433

Epoch: 5| Step: 4
Training loss: 1.4035434532220217
Validation loss: 2.5249302995277154

Epoch: 5| Step: 5
Training loss: 1.1405386173511938
Validation loss: 2.5890651142350922

Epoch: 5| Step: 6
Training loss: 1.2461763073589656
Validation loss: 2.5769773422899185

Epoch: 5| Step: 7
Training loss: 1.381612397030387
Validation loss: 2.586231937765172

Epoch: 5| Step: 8
Training loss: 1.3498558779892627
Validation loss: 2.601597681349326

Epoch: 5| Step: 9
Training loss: 1.2994237466230805
Validation loss: 2.548766651071513

Epoch: 5| Step: 10
Training loss: 0.9011905120919912
Validation loss: 2.5615480407006426

Epoch: 227| Step: 0
Training loss: 1.330976364954802
Validation loss: 2.5190580149529636

Epoch: 5| Step: 1
Training loss: 1.5882232430256427
Validation loss: 2.56220813652784

Epoch: 5| Step: 2
Training loss: 0.9747432395111634
Validation loss: 2.564176006348986

Epoch: 5| Step: 3
Training loss: 1.0662981474583322
Validation loss: 2.5236742518214306

Epoch: 5| Step: 4
Training loss: 1.3054444635530325
Validation loss: 2.5296849970899653

Epoch: 5| Step: 5
Training loss: 1.8055221146967255
Validation loss: 2.531743990794123

Epoch: 5| Step: 6
Training loss: 0.7727802450974207
Validation loss: 2.5069805128996263

Epoch: 5| Step: 7
Training loss: 1.2870591288413007
Validation loss: 2.50282398000481

Epoch: 5| Step: 8
Training loss: 1.3613297450139437
Validation loss: 2.4586240906904955

Epoch: 5| Step: 9
Training loss: 1.6708589122206337
Validation loss: 2.475458761153429

Epoch: 5| Step: 10
Training loss: 1.0982049948269412
Validation loss: 2.4449499325961193

Epoch: 228| Step: 0
Training loss: 1.4210699967574447
Validation loss: 2.4715960624007525

Epoch: 5| Step: 1
Training loss: 1.61586755521884
Validation loss: 2.5030028162583107

Epoch: 5| Step: 2
Training loss: 1.3125202086573182
Validation loss: 2.505126403965683

Epoch: 5| Step: 3
Training loss: 1.3052603554715803
Validation loss: 2.5199574252456722

Epoch: 5| Step: 4
Training loss: 1.6619389555332487
Validation loss: 2.549506792455124

Epoch: 5| Step: 5
Training loss: 1.0752592838669723
Validation loss: 2.555124001255335

Epoch: 5| Step: 6
Training loss: 1.2190785087545437
Validation loss: 2.5725391890383804

Epoch: 5| Step: 7
Training loss: 1.2692729511120702
Validation loss: 2.5782274928746545

Epoch: 5| Step: 8
Training loss: 0.8257399708401273
Validation loss: 2.5835720617504387

Epoch: 5| Step: 9
Training loss: 1.2476083286472162
Validation loss: 2.5936123944521885

Epoch: 5| Step: 10
Training loss: 1.3941737552895082
Validation loss: 2.573601576297526

Epoch: 229| Step: 0
Training loss: 1.429828741048818
Validation loss: 2.5406263469320183

Epoch: 5| Step: 1
Training loss: 1.482156159280514
Validation loss: 2.564177893454203

Epoch: 5| Step: 2
Training loss: 1.0666288485876159
Validation loss: 2.5571799488918083

Epoch: 5| Step: 3
Training loss: 1.6708833837583492
Validation loss: 2.5488862511895167

Epoch: 5| Step: 4
Training loss: 1.067889066456838
Validation loss: 2.5032456679288857

Epoch: 5| Step: 5
Training loss: 1.3244291605368
Validation loss: 2.5569494476382

Epoch: 5| Step: 6
Training loss: 1.4531411611006975
Validation loss: 2.5552586741128183

Epoch: 5| Step: 7
Training loss: 1.3014585089384452
Validation loss: 2.5769214414905455

Epoch: 5| Step: 8
Training loss: 1.0509094954158693
Validation loss: 2.565038120853481

Epoch: 5| Step: 9
Training loss: 1.1974908763083991
Validation loss: 2.5901577652014947

Epoch: 5| Step: 10
Training loss: 1.2570978823890295
Validation loss: 2.6126837067864046

Epoch: 230| Step: 0
Training loss: 1.5594570283586269
Validation loss: 2.658341078724936

Epoch: 5| Step: 1
Training loss: 1.7056248368444535
Validation loss: 2.6072561203594575

Epoch: 5| Step: 2
Training loss: 1.14095019577682
Validation loss: 2.6524147271753935

Epoch: 5| Step: 3
Training loss: 1.326713395270204
Validation loss: 2.5896038478286605

Epoch: 5| Step: 4
Training loss: 1.1743935541836188
Validation loss: 2.604331172218186

Epoch: 5| Step: 5
Training loss: 1.2080230588575311
Validation loss: 2.5772792389712333

Epoch: 5| Step: 6
Training loss: 1.3438477147969112
Validation loss: 2.566609035218346

Epoch: 5| Step: 7
Training loss: 1.1204839769381234
Validation loss: 2.545529034355946

Epoch: 5| Step: 8
Training loss: 1.106954701428109
Validation loss: 2.5502192976206617

Epoch: 5| Step: 9
Training loss: 1.6520506686829408
Validation loss: 2.552939368890787

Epoch: 5| Step: 10
Training loss: 0.5747655483845717
Validation loss: 2.5396211348791273

Epoch: 231| Step: 0
Training loss: 1.1653786713443002
Validation loss: 2.568009247549383

Epoch: 5| Step: 1
Training loss: 1.736363345154779
Validation loss: 2.560402460655524

Epoch: 5| Step: 2
Training loss: 1.1167658296841911
Validation loss: 2.556543131941806

Epoch: 5| Step: 3
Training loss: 1.4920422548237176
Validation loss: 2.580237881698111

Epoch: 5| Step: 4
Training loss: 1.8217542447987827
Validation loss: 2.571328422769473

Epoch: 5| Step: 5
Training loss: 1.1259197078488052
Validation loss: 2.5933209457392103

Epoch: 5| Step: 6
Training loss: 0.9389030130692091
Validation loss: 2.5851693061516743

Epoch: 5| Step: 7
Training loss: 1.1729056340314739
Validation loss: 2.5764665377355445

Epoch: 5| Step: 8
Training loss: 1.0612017048337135
Validation loss: 2.5649470668715963

Epoch: 5| Step: 9
Training loss: 1.1138283974469994
Validation loss: 2.5651504971322185

Epoch: 5| Step: 10
Training loss: 1.1326937909245478
Validation loss: 2.5621392791272997

Epoch: 232| Step: 0
Training loss: 1.1312621458465881
Validation loss: 2.5873132643557573

Epoch: 5| Step: 1
Training loss: 1.2741447778089467
Validation loss: 2.563616680638418

Epoch: 5| Step: 2
Training loss: 1.1185176373635706
Validation loss: 2.599149268164886

Epoch: 5| Step: 3
Training loss: 1.4242868613290274
Validation loss: 2.6160836622609356

Epoch: 5| Step: 4
Training loss: 1.61881944072937
Validation loss: 2.630712657733115

Epoch: 5| Step: 5
Training loss: 1.3713417807006536
Validation loss: 2.623967220981425

Epoch: 5| Step: 6
Training loss: 1.2837896530728046
Validation loss: 2.6401566688833773

Epoch: 5| Step: 7
Training loss: 1.230323807187452
Validation loss: 2.619385230393962

Epoch: 5| Step: 8
Training loss: 1.0618786958716584
Validation loss: 2.6191813598126505

Epoch: 5| Step: 9
Training loss: 1.1373266842611593
Validation loss: 2.6137964791742614

Epoch: 5| Step: 10
Training loss: 1.4633231039421066
Validation loss: 2.6133436892087465

Epoch: 233| Step: 0
Training loss: 1.1894821388952908
Validation loss: 2.595159372838494

Epoch: 5| Step: 1
Training loss: 1.2436764987716065
Validation loss: 2.589626353801146

Epoch: 5| Step: 2
Training loss: 0.9213425990115827
Validation loss: 2.5835984772429574

Epoch: 5| Step: 3
Training loss: 1.3770162365024716
Validation loss: 2.603756327797224

Epoch: 5| Step: 4
Training loss: 1.481567136398814
Validation loss: 2.587518096752748

Epoch: 5| Step: 5
Training loss: 1.4098807195166443
Validation loss: 2.6160331020456704

Epoch: 5| Step: 6
Training loss: 1.4929169474686743
Validation loss: 2.5855075017807345

Epoch: 5| Step: 7
Training loss: 1.3954198661411374
Validation loss: 2.649877253371488

Epoch: 5| Step: 8
Training loss: 1.168671259548072
Validation loss: 2.6911566950647234

Epoch: 5| Step: 9
Training loss: 1.0748335864760383
Validation loss: 2.703236375769404

Epoch: 5| Step: 10
Training loss: 1.2079673519775291
Validation loss: 2.705700438105514

Epoch: 234| Step: 0
Training loss: 1.292806609437472
Validation loss: 2.7051757955978735

Epoch: 5| Step: 1
Training loss: 1.6088113631110377
Validation loss: 2.674275859870413

Epoch: 5| Step: 2
Training loss: 1.1639334587924612
Validation loss: 2.6333683191955424

Epoch: 5| Step: 3
Training loss: 1.3290935799206922
Validation loss: 2.626456397225401

Epoch: 5| Step: 4
Training loss: 1.5460191921705935
Validation loss: 2.5865858312602175

Epoch: 5| Step: 5
Training loss: 1.3139805844206511
Validation loss: 2.6245960592810818

Epoch: 5| Step: 6
Training loss: 1.3266596171097542
Validation loss: 2.5605432586332757

Epoch: 5| Step: 7
Training loss: 0.9915278186617894
Validation loss: 2.586485963158363

Epoch: 5| Step: 8
Training loss: 1.0741704756553558
Validation loss: 2.6194517329786313

Epoch: 5| Step: 9
Training loss: 1.3472293785840248
Validation loss: 2.659115248147858

Epoch: 5| Step: 10
Training loss: 0.9410236895109954
Validation loss: 2.6720308331430593

Epoch: 235| Step: 0
Training loss: 1.5463985133105225
Validation loss: 2.7067510385874414

Epoch: 5| Step: 1
Training loss: 1.1929234584162434
Validation loss: 2.6861282820055443

Epoch: 5| Step: 2
Training loss: 1.0369874124599892
Validation loss: 2.6659834948654564

Epoch: 5| Step: 3
Training loss: 1.2146241704096468
Validation loss: 2.622891010059018

Epoch: 5| Step: 4
Training loss: 1.7390243484959793
Validation loss: 2.595708365454253

Epoch: 5| Step: 5
Training loss: 1.4596398450209735
Validation loss: 2.5697969458879473

Epoch: 5| Step: 6
Training loss: 1.1059127832449502
Validation loss: 2.5557711153516482

Epoch: 5| Step: 7
Training loss: 1.006046670308918
Validation loss: 2.5597850083852207

Epoch: 5| Step: 8
Training loss: 1.2049262199924546
Validation loss: 2.5240714812332286

Epoch: 5| Step: 9
Training loss: 1.1091532955801526
Validation loss: 2.5233885620861933

Epoch: 5| Step: 10
Training loss: 1.0109034607712086
Validation loss: 2.5029392258653993

Epoch: 236| Step: 0
Training loss: 1.349020888990417
Validation loss: 2.527086778836946

Epoch: 5| Step: 1
Training loss: 0.9683006844348453
Validation loss: 2.564956199201495

Epoch: 5| Step: 2
Training loss: 1.0069890169531555
Validation loss: 2.5525285440895646

Epoch: 5| Step: 3
Training loss: 1.3687403116797798
Validation loss: 2.557410826334852

Epoch: 5| Step: 4
Training loss: 1.5541581829476983
Validation loss: 2.5899885301062406

Epoch: 5| Step: 5
Training loss: 1.1479350437601807
Validation loss: 2.55499707746165

Epoch: 5| Step: 6
Training loss: 1.2762367981649152
Validation loss: 2.607754010357

Epoch: 5| Step: 7
Training loss: 1.2338782650982918
Validation loss: 2.5826534877814633

Epoch: 5| Step: 8
Training loss: 1.149412143806146
Validation loss: 2.5363379817529097

Epoch: 5| Step: 9
Training loss: 1.2880651141168897
Validation loss: 2.5437547725848293

Epoch: 5| Step: 10
Training loss: 1.2918712648763122
Validation loss: 2.5228916066539626

Epoch: 237| Step: 0
Training loss: 0.9810564020237948
Validation loss: 2.516423695733564

Epoch: 5| Step: 1
Training loss: 1.1857636456220138
Validation loss: 2.520645175936683

Epoch: 5| Step: 2
Training loss: 1.410368589016632
Validation loss: 2.5257970426138483

Epoch: 5| Step: 3
Training loss: 0.8331593133108811
Validation loss: 2.5731493893754167

Epoch: 5| Step: 4
Training loss: 1.3449680219628046
Validation loss: 2.5655723629628806

Epoch: 5| Step: 5
Training loss: 1.4579706104231127
Validation loss: 2.5618199202080456

Epoch: 5| Step: 6
Training loss: 0.7807721774872121
Validation loss: 2.579270593527124

Epoch: 5| Step: 7
Training loss: 1.3169827882515326
Validation loss: 2.568914236653695

Epoch: 5| Step: 8
Training loss: 1.0209071787899098
Validation loss: 2.555938991177804

Epoch: 5| Step: 9
Training loss: 1.623719958349749
Validation loss: 2.582912738975726

Epoch: 5| Step: 10
Training loss: 1.263001253690724
Validation loss: 2.5707369701776184

Epoch: 238| Step: 0
Training loss: 1.5958589550116173
Validation loss: 2.5567696921684266

Epoch: 5| Step: 1
Training loss: 1.5552995713340234
Validation loss: 2.578852179362183

Epoch: 5| Step: 2
Training loss: 1.0433391242023997
Validation loss: 2.54318770821644

Epoch: 5| Step: 3
Training loss: 0.8359789258728231
Validation loss: 2.5905394221072915

Epoch: 5| Step: 4
Training loss: 0.965444431890763
Validation loss: 2.5844775519629968

Epoch: 5| Step: 5
Training loss: 1.1115626940701593
Validation loss: 2.6311950564448194

Epoch: 5| Step: 6
Training loss: 1.0564757833742917
Validation loss: 2.664049361617584

Epoch: 5| Step: 7
Training loss: 1.1388942704164056
Validation loss: 2.692095131277137

Epoch: 5| Step: 8
Training loss: 1.4637798056756297
Validation loss: 2.6727377657103095

Epoch: 5| Step: 9
Training loss: 1.3004963880794576
Validation loss: 2.6759542889651615

Epoch: 5| Step: 10
Training loss: 1.1213397244688221
Validation loss: 2.661835334186295

Epoch: 239| Step: 0
Training loss: 1.185196549818622
Validation loss: 2.6331304065694043

Epoch: 5| Step: 1
Training loss: 1.0267856953306966
Validation loss: 2.62226861126867

Epoch: 5| Step: 2
Training loss: 1.3798174130545426
Validation loss: 2.628111837215436

Epoch: 5| Step: 3
Training loss: 0.8016691170441524
Validation loss: 2.627448653381949

Epoch: 5| Step: 4
Training loss: 1.2958647228417404
Validation loss: 2.6308359539925785

Epoch: 5| Step: 5
Training loss: 1.0664891360981912
Validation loss: 2.614997886467534

Epoch: 5| Step: 6
Training loss: 1.448516428750586
Validation loss: 2.621794977071445

Epoch: 5| Step: 7
Training loss: 1.210401256329678
Validation loss: 2.6293141062795913

Epoch: 5| Step: 8
Training loss: 0.9596503716817054
Validation loss: 2.602186793319934

Epoch: 5| Step: 9
Training loss: 0.7397825527963643
Validation loss: 2.667837336541436

Epoch: 5| Step: 10
Training loss: 1.9064659871794767
Validation loss: 2.6432777880812774

Epoch: 240| Step: 0
Training loss: 1.621914869343964
Validation loss: 2.6523204694130325

Epoch: 5| Step: 1
Training loss: 1.180033702449867
Validation loss: 2.642219389292122

Epoch: 5| Step: 2
Training loss: 0.8120642006820384
Validation loss: 2.641202195247037

Epoch: 5| Step: 3
Training loss: 0.9453807837674899
Validation loss: 2.6608589717111446

Epoch: 5| Step: 4
Training loss: 1.6193192294906804
Validation loss: 2.6509835777411377

Epoch: 5| Step: 5
Training loss: 1.4310492195659066
Validation loss: 2.6239734269377837

Epoch: 5| Step: 6
Training loss: 1.3662979283699412
Validation loss: 2.6178861236285567

Epoch: 5| Step: 7
Training loss: 0.9725054275439691
Validation loss: 2.589720762115945

Epoch: 5| Step: 8
Training loss: 0.9804341587484638
Validation loss: 2.5776634024327394

Epoch: 5| Step: 9
Training loss: 1.26022874466358
Validation loss: 2.5531571461969085

Epoch: 5| Step: 10
Training loss: 0.5994716573112864
Validation loss: 2.581046504074526

Epoch: 241| Step: 0
Training loss: 1.2205248404963398
Validation loss: 2.5865894607726454

Epoch: 5| Step: 1
Training loss: 1.1711678978348166
Validation loss: 2.567976693816395

Epoch: 5| Step: 2
Training loss: 0.7407422902391263
Validation loss: 2.5864271267907393

Epoch: 5| Step: 3
Training loss: 0.9738090149082786
Validation loss: 2.6144527148885572

Epoch: 5| Step: 4
Training loss: 1.505070461131904
Validation loss: 2.6261414830865673

Epoch: 5| Step: 5
Training loss: 0.9148306594029334
Validation loss: 2.6302779500482427

Epoch: 5| Step: 6
Training loss: 1.5261887966572132
Validation loss: 2.62246788043162

Epoch: 5| Step: 7
Training loss: 1.2876863011502386
Validation loss: 2.6364645514788023

Epoch: 5| Step: 8
Training loss: 1.4727930465828334
Validation loss: 2.6240707213618064

Epoch: 5| Step: 9
Training loss: 1.2744593352830207
Validation loss: 2.596645809875803

Epoch: 5| Step: 10
Training loss: 0.9124831877426868
Validation loss: 2.5950977121852485

Epoch: 242| Step: 0
Training loss: 1.2366756776308316
Validation loss: 2.5611120127087

Epoch: 5| Step: 1
Training loss: 1.1757304538640787
Validation loss: 2.563130903074913

Epoch: 5| Step: 2
Training loss: 1.5598715990972354
Validation loss: 2.5488130775126607

Epoch: 5| Step: 3
Training loss: 0.8546133075431485
Validation loss: 2.5587372444730567

Epoch: 5| Step: 4
Training loss: 0.7815139706022475
Validation loss: 2.5922610816317224

Epoch: 5| Step: 5
Training loss: 1.3536039601574676
Validation loss: 2.608290174346627

Epoch: 5| Step: 6
Training loss: 0.9635036598476548
Validation loss: 2.5798450746736523

Epoch: 5| Step: 7
Training loss: 1.146952596840608
Validation loss: 2.6231035197672186

Epoch: 5| Step: 8
Training loss: 1.2195306869593512
Validation loss: 2.6173405183332803

Epoch: 5| Step: 9
Training loss: 1.6112283201808513
Validation loss: 2.6318684572375073

Epoch: 5| Step: 10
Training loss: 1.1400643630011764
Validation loss: 2.645370727985184

Epoch: 243| Step: 0
Training loss: 1.169181780691377
Validation loss: 2.6354265074615295

Epoch: 5| Step: 1
Training loss: 1.2546769385172412
Validation loss: 2.6136341886386902

Epoch: 5| Step: 2
Training loss: 1.1086924427665705
Validation loss: 2.5555714546851607

Epoch: 5| Step: 3
Training loss: 0.6983394315001165
Validation loss: 2.5627132900260423

Epoch: 5| Step: 4
Training loss: 0.9921504336664865
Validation loss: 2.5618270282463693

Epoch: 5| Step: 5
Training loss: 1.152853177501553
Validation loss: 2.61022335137052

Epoch: 5| Step: 6
Training loss: 1.1792477425963466
Validation loss: 2.6131569370974916

Epoch: 5| Step: 7
Training loss: 1.0655459332708441
Validation loss: 2.6453198422420536

Epoch: 5| Step: 8
Training loss: 1.696729358022009
Validation loss: 2.6708811948417304

Epoch: 5| Step: 9
Training loss: 1.2333888690060852
Validation loss: 2.6878216248866074

Epoch: 5| Step: 10
Training loss: 1.3728648861433774
Validation loss: 2.706201306408759

Epoch: 244| Step: 0
Training loss: 1.4849403509368497
Validation loss: 2.7019635897488006

Epoch: 5| Step: 1
Training loss: 1.1500485596563155
Validation loss: 2.6852560211815915

Epoch: 5| Step: 2
Training loss: 1.3319214806396413
Validation loss: 2.6618284777962864

Epoch: 5| Step: 3
Training loss: 0.9520151211254961
Validation loss: 2.6424072875911735

Epoch: 5| Step: 4
Training loss: 1.0399910356061899
Validation loss: 2.5997354411499285

Epoch: 5| Step: 5
Training loss: 0.8242018277568958
Validation loss: 2.59308674003576

Epoch: 5| Step: 6
Training loss: 1.1259032438150662
Validation loss: 2.594888821857454

Epoch: 5| Step: 7
Training loss: 1.125804295724225
Validation loss: 2.634073513343179

Epoch: 5| Step: 8
Training loss: 1.649516832527706
Validation loss: 2.622636637450513

Epoch: 5| Step: 9
Training loss: 1.2577547806474747
Validation loss: 2.576722360091397

Epoch: 5| Step: 10
Training loss: 0.9683980917875168
Validation loss: 2.587158229260248

Epoch: 245| Step: 0
Training loss: 0.8275098135098328
Validation loss: 2.6038881201312125

Epoch: 5| Step: 1
Training loss: 1.048778852445536
Validation loss: 2.6024161997668886

Epoch: 5| Step: 2
Training loss: 1.0731063909588991
Validation loss: 2.62799494616176

Epoch: 5| Step: 3
Training loss: 1.2157959962427827
Validation loss: 2.625264489931586

Epoch: 5| Step: 4
Training loss: 1.5709889032177162
Validation loss: 2.6451791101911413

Epoch: 5| Step: 5
Training loss: 1.1925460616198784
Validation loss: 2.638297663895495

Epoch: 5| Step: 6
Training loss: 0.9794775219139812
Validation loss: 2.610003198217723

Epoch: 5| Step: 7
Training loss: 0.891427498379479
Validation loss: 2.6451263594253076

Epoch: 5| Step: 8
Training loss: 1.7973538631409047
Validation loss: 2.6328574838559735

Epoch: 5| Step: 9
Training loss: 0.9373113760338917
Validation loss: 2.6158888774694926

Epoch: 5| Step: 10
Training loss: 1.039250808517292
Validation loss: 2.6042121220385024

Epoch: 246| Step: 0
Training loss: 0.8445486598024468
Validation loss: 2.573272525695452

Epoch: 5| Step: 1
Training loss: 1.0494670378155304
Validation loss: 2.594139814581533

Epoch: 5| Step: 2
Training loss: 1.5738505271212926
Validation loss: 2.6040916350025474

Epoch: 5| Step: 3
Training loss: 1.1352824152166323
Validation loss: 2.570628304668255

Epoch: 5| Step: 4
Training loss: 1.4607679299255159
Validation loss: 2.6150291156647865

Epoch: 5| Step: 5
Training loss: 1.0258750715733305
Validation loss: 2.617107979710174

Epoch: 5| Step: 6
Training loss: 0.7725925261136738
Validation loss: 2.631972521593568

Epoch: 5| Step: 7
Training loss: 1.2284084934409287
Validation loss: 2.6500935890696398

Epoch: 5| Step: 8
Training loss: 0.5576369086684743
Validation loss: 2.6470047755014745

Epoch: 5| Step: 9
Training loss: 1.2340844210708493
Validation loss: 2.67385545709715

Epoch: 5| Step: 10
Training loss: 1.5615857310510888
Validation loss: 2.7052558089210086

Epoch: 247| Step: 0
Training loss: 1.1176403168350928
Validation loss: 2.6476047687851394

Epoch: 5| Step: 1
Training loss: 1.0456013689488948
Validation loss: 2.655903005405014

Epoch: 5| Step: 2
Training loss: 0.9686482591424649
Validation loss: 2.6123010466102405

Epoch: 5| Step: 3
Training loss: 0.8904568028154757
Validation loss: 2.558640156938527

Epoch: 5| Step: 4
Training loss: 1.4026426034055088
Validation loss: 2.5593687535589518

Epoch: 5| Step: 5
Training loss: 1.5909204234920984
Validation loss: 2.53304810074581

Epoch: 5| Step: 6
Training loss: 1.1131665622463445
Validation loss: 2.5388714593368475

Epoch: 5| Step: 7
Training loss: 0.9554271411335444
Validation loss: 2.5537105831273914

Epoch: 5| Step: 8
Training loss: 1.0673739336068553
Validation loss: 2.5566665145606158

Epoch: 5| Step: 9
Training loss: 1.3729669105393303
Validation loss: 2.6185401806408

Epoch: 5| Step: 10
Training loss: 1.1937077040444228
Validation loss: 2.643873882646975

Epoch: 248| Step: 0
Training loss: 0.8833484879279371
Validation loss: 2.649225963212166

Epoch: 5| Step: 1
Training loss: 0.9330499573648442
Validation loss: 2.6239408269397857

Epoch: 5| Step: 2
Training loss: 1.1507609213427434
Validation loss: 2.686391524101593

Epoch: 5| Step: 3
Training loss: 1.1992629847615837
Validation loss: 2.6714485648283763

Epoch: 5| Step: 4
Training loss: 1.4286664641649105
Validation loss: 2.650615560627084

Epoch: 5| Step: 5
Training loss: 1.5138884358692173
Validation loss: 2.6566170693973366

Epoch: 5| Step: 6
Training loss: 1.2038778946574071
Validation loss: 2.6297366675879554

Epoch: 5| Step: 7
Training loss: 0.9892578125
Validation loss: 2.618821206165997

Epoch: 5| Step: 8
Training loss: 1.0070184344296726
Validation loss: 2.6087892899346254

Epoch: 5| Step: 9
Training loss: 1.1225144160646987
Validation loss: 2.6114305595206613

Epoch: 5| Step: 10
Training loss: 1.1034033794199898
Validation loss: 2.619741733198864

Epoch: 249| Step: 0
Training loss: 0.804795526456913
Validation loss: 2.6098126029823145

Epoch: 5| Step: 1
Training loss: 1.2084090877770828
Validation loss: 2.5946291498455025

Epoch: 5| Step: 2
Training loss: 1.3381154115164968
Validation loss: 2.5653103160249375

Epoch: 5| Step: 3
Training loss: 1.2286994929910804
Validation loss: 2.57775407486335

Epoch: 5| Step: 4
Training loss: 0.7807485497027878
Validation loss: 2.5466420469552737

Epoch: 5| Step: 5
Training loss: 1.3064421772473684
Validation loss: 2.532466960998762

Epoch: 5| Step: 6
Training loss: 1.007526327503854
Validation loss: 2.595514763842343

Epoch: 5| Step: 7
Training loss: 0.8334047684251348
Validation loss: 2.566136961361035

Epoch: 5| Step: 8
Training loss: 1.1264252112088216
Validation loss: 2.5843764715379858

Epoch: 5| Step: 9
Training loss: 1.188010507572471
Validation loss: 2.5827979771263507

Epoch: 5| Step: 10
Training loss: 1.595700883805418
Validation loss: 2.570053314427509

Epoch: 250| Step: 0
Training loss: 1.1659625630789296
Validation loss: 2.520105918448251

Epoch: 5| Step: 1
Training loss: 1.5743272616185666
Validation loss: 2.4843387261872647

Epoch: 5| Step: 2
Training loss: 1.0640953092516316
Validation loss: 2.5098461479279552

Epoch: 5| Step: 3
Training loss: 1.0658216725641863
Validation loss: 2.5007580325733727

Epoch: 5| Step: 4
Training loss: 0.9678843537639439
Validation loss: 2.5099558607537222

Epoch: 5| Step: 5
Training loss: 1.5743082555878505
Validation loss: 2.516116001173236

Epoch: 5| Step: 6
Training loss: 0.682275296274505
Validation loss: 2.521237090755319

Epoch: 5| Step: 7
Training loss: 1.1882449373393815
Validation loss: 2.513106891464125

Epoch: 5| Step: 8
Training loss: 0.8205782142079949
Validation loss: 2.569559507575321

Epoch: 5| Step: 9
Training loss: 1.0072541575399279
Validation loss: 2.5651368071584053

Epoch: 5| Step: 10
Training loss: 0.9830436483240942
Validation loss: 2.607976102625031

Epoch: 251| Step: 0
Training loss: 1.3703877949227385
Validation loss: 2.6160226300380183

Epoch: 5| Step: 1
Training loss: 1.251578097776069
Validation loss: 2.61682843466651

Epoch: 5| Step: 2
Training loss: 1.1190713857699046
Validation loss: 2.635700470439229

Epoch: 5| Step: 3
Training loss: 1.395653793782763
Validation loss: 2.5757340756093865

Epoch: 5| Step: 4
Training loss: 1.001027294827176
Validation loss: 2.5929702325986055

Epoch: 5| Step: 5
Training loss: 0.6983124810961997
Validation loss: 2.563189808110354

Epoch: 5| Step: 6
Training loss: 1.4170353447134316
Validation loss: 2.5699226698922915

Epoch: 5| Step: 7
Training loss: 1.3494390664521991
Validation loss: 2.587382396062245

Epoch: 5| Step: 8
Training loss: 0.7556146821989097
Validation loss: 2.595814300163415

Epoch: 5| Step: 9
Training loss: 1.1134195877591528
Validation loss: 2.611245561473621

Epoch: 5| Step: 10
Training loss: 0.5249094692012732
Validation loss: 2.609589418882641

Epoch: 252| Step: 0
Training loss: 1.313793680134551
Validation loss: 2.6408544864096712

Epoch: 5| Step: 1
Training loss: 1.0699743028924096
Validation loss: 2.623234705594362

Epoch: 5| Step: 2
Training loss: 0.9055700052963839
Validation loss: 2.6203322443159305

Epoch: 5| Step: 3
Training loss: 0.865749576018822
Validation loss: 2.634252723500409

Epoch: 5| Step: 4
Training loss: 0.8609613515661931
Validation loss: 2.6162167512754766

Epoch: 5| Step: 5
Training loss: 1.0780881239624476
Validation loss: 2.59345569020664

Epoch: 5| Step: 6
Training loss: 1.2861419422517881
Validation loss: 2.5791934586412877

Epoch: 5| Step: 7
Training loss: 0.9043659488670583
Validation loss: 2.5859629624181424

Epoch: 5| Step: 8
Training loss: 1.134404714316027
Validation loss: 2.571684530149868

Epoch: 5| Step: 9
Training loss: 1.2608281349298518
Validation loss: 2.565037417236938

Epoch: 5| Step: 10
Training loss: 1.527324393459505
Validation loss: 2.580856917266236

Epoch: 253| Step: 0
Training loss: 1.4144945696405924
Validation loss: 2.5662424384836284

Epoch: 5| Step: 1
Training loss: 0.9553291599367092
Validation loss: 2.6207079510161524

Epoch: 5| Step: 2
Training loss: 1.0828241410943904
Validation loss: 2.6716181817481663

Epoch: 5| Step: 3
Training loss: 0.7797589760471922
Validation loss: 2.714467388136127

Epoch: 5| Step: 4
Training loss: 1.0813286769224193
Validation loss: 2.701177584686935

Epoch: 5| Step: 5
Training loss: 1.057202822455522
Validation loss: 2.73591314647334

Epoch: 5| Step: 6
Training loss: 0.5868437815397594
Validation loss: 2.7268351108218436

Epoch: 5| Step: 7
Training loss: 1.1884826810455176
Validation loss: 2.6715362263055966

Epoch: 5| Step: 8
Training loss: 1.5810160829521067
Validation loss: 2.6597053671308077

Epoch: 5| Step: 9
Training loss: 1.3554038876012107
Validation loss: 2.569755334475624

Epoch: 5| Step: 10
Training loss: 1.0388158060797794
Validation loss: 2.562603216846216

Epoch: 254| Step: 0
Training loss: 1.6937462387887783
Validation loss: 2.539912313480752

Epoch: 5| Step: 1
Training loss: 0.974557695566671
Validation loss: 2.518985329903767

Epoch: 5| Step: 2
Training loss: 1.474398768461006
Validation loss: 2.580738100434368

Epoch: 5| Step: 3
Training loss: 0.7439216832349009
Validation loss: 2.59399340570139

Epoch: 5| Step: 4
Training loss: 0.748175149382444
Validation loss: 2.6408162924815053

Epoch: 5| Step: 5
Training loss: 1.1697732006233543
Validation loss: 2.6732132779279043

Epoch: 5| Step: 6
Training loss: 1.0275850194019491
Validation loss: 2.731970017889282

Epoch: 5| Step: 7
Training loss: 1.3023226657893012
Validation loss: 2.7104734902136234

Epoch: 5| Step: 8
Training loss: 0.9004407690818566
Validation loss: 2.723206185990723

Epoch: 5| Step: 9
Training loss: 0.8895895443296736
Validation loss: 2.671582511873435

Epoch: 5| Step: 10
Training loss: 1.1340939869928386
Validation loss: 2.626162520123137

Epoch: 255| Step: 0
Training loss: 1.3867836090823595
Validation loss: 2.605089519440269

Epoch: 5| Step: 1
Training loss: 1.0054478664645121
Validation loss: 2.5729154115411186

Epoch: 5| Step: 2
Training loss: 1.0771425719114434
Validation loss: 2.58418981648983

Epoch: 5| Step: 3
Training loss: 1.0008864050480137
Validation loss: 2.551940841329929

Epoch: 5| Step: 4
Training loss: 1.7398990260894276
Validation loss: 2.5831633666376512

Epoch: 5| Step: 5
Training loss: 1.1093835964675736
Validation loss: 2.549836116931734

Epoch: 5| Step: 6
Training loss: 0.6996758953868267
Validation loss: 2.6098126000353896

Epoch: 5| Step: 7
Training loss: 1.1600011342963887
Validation loss: 2.588858855474656

Epoch: 5| Step: 8
Training loss: 0.8272691298596176
Validation loss: 2.598106802264673

Epoch: 5| Step: 9
Training loss: 0.884194768865919
Validation loss: 2.6243802182258227

Epoch: 5| Step: 10
Training loss: 0.9657899487296079
Validation loss: 2.586825028231246

Epoch: 256| Step: 0
Training loss: 1.3578741184734977
Validation loss: 2.592131037148064

Epoch: 5| Step: 1
Training loss: 1.0594626938974476
Validation loss: 2.5858632407824524

Epoch: 5| Step: 2
Training loss: 0.7771106926513864
Validation loss: 2.584641966353367

Epoch: 5| Step: 3
Training loss: 1.1438161549431354
Validation loss: 2.578700288617094

Epoch: 5| Step: 4
Training loss: 0.7480547633141114
Validation loss: 2.6118435083066287

Epoch: 5| Step: 5
Training loss: 1.1343212734982184
Validation loss: 2.593569843565401

Epoch: 5| Step: 6
Training loss: 0.7834677308697394
Validation loss: 2.6102114363451885

Epoch: 5| Step: 7
Training loss: 1.6432261600456803
Validation loss: 2.5960338128830207

Epoch: 5| Step: 8
Training loss: 1.064136423016267
Validation loss: 2.6128006882337655

Epoch: 5| Step: 9
Training loss: 1.060497303852717
Validation loss: 2.6096623575468088

Epoch: 5| Step: 10
Training loss: 1.0760843618710967
Validation loss: 2.6259325210078455

Epoch: 257| Step: 0
Training loss: 1.0081942522795841
Validation loss: 2.6020923757169796

Epoch: 5| Step: 1
Training loss: 1.15232062882326
Validation loss: 2.5848879930982305

Epoch: 5| Step: 2
Training loss: 1.442850356106262
Validation loss: 2.551743560399962

Epoch: 5| Step: 3
Training loss: 1.0674020219280154
Validation loss: 2.565041884798925

Epoch: 5| Step: 4
Training loss: 0.8610773737940006
Validation loss: 2.551824021532909

Epoch: 5| Step: 5
Training loss: 0.9136228889945116
Validation loss: 2.547559265624667

Epoch: 5| Step: 6
Training loss: 1.1230120048085108
Validation loss: 2.544422268374181

Epoch: 5| Step: 7
Training loss: 0.9195982086252964
Validation loss: 2.584328999076283

Epoch: 5| Step: 8
Training loss: 1.2223936536282172
Validation loss: 2.5822859939042773

Epoch: 5| Step: 9
Training loss: 0.988653271280405
Validation loss: 2.5989729315149477

Epoch: 5| Step: 10
Training loss: 1.2500066280189268
Validation loss: 2.609446337376067

Epoch: 258| Step: 0
Training loss: 0.8873417552046294
Validation loss: 2.6194785813424515

Epoch: 5| Step: 1
Training loss: 1.1644519947946126
Validation loss: 2.6094256626963532

Epoch: 5| Step: 2
Training loss: 1.1188109013694276
Validation loss: 2.6213811275459444

Epoch: 5| Step: 3
Training loss: 1.1009983214210513
Validation loss: 2.593985105460427

Epoch: 5| Step: 4
Training loss: 1.02340034242691
Validation loss: 2.5574339985400547

Epoch: 5| Step: 5
Training loss: 0.9704232378440028
Validation loss: 2.57767915621329

Epoch: 5| Step: 6
Training loss: 0.9212692986463604
Validation loss: 2.560082093977936

Epoch: 5| Step: 7
Training loss: 0.9569710225986818
Validation loss: 2.5196391848286117

Epoch: 5| Step: 8
Training loss: 0.5946766999988439
Validation loss: 2.5462970471704724

Epoch: 5| Step: 9
Training loss: 1.3589951433904799
Validation loss: 2.5275731151686416

Epoch: 5| Step: 10
Training loss: 1.6801066031012508
Validation loss: 2.5226258085176667

Epoch: 259| Step: 0
Training loss: 1.127393401830996
Validation loss: 2.5520452185558167

Epoch: 5| Step: 1
Training loss: 0.9565454924055051
Validation loss: 2.551927882657139

Epoch: 5| Step: 2
Training loss: 0.6992161287226638
Validation loss: 2.542105221514336

Epoch: 5| Step: 3
Training loss: 1.1350110522332861
Validation loss: 2.5908906310197892

Epoch: 5| Step: 4
Training loss: 1.2889486551586824
Validation loss: 2.576369364054118

Epoch: 5| Step: 5
Training loss: 1.2328295146894517
Validation loss: 2.6296651114564598

Epoch: 5| Step: 6
Training loss: 1.5106847415548683
Validation loss: 2.6319672676286134

Epoch: 5| Step: 7
Training loss: 0.9099731261089409
Validation loss: 2.605320901026326

Epoch: 5| Step: 8
Training loss: 1.0132873629089294
Validation loss: 2.628548894219746

Epoch: 5| Step: 9
Training loss: 0.9664432688155248
Validation loss: 2.597500787043379

Epoch: 5| Step: 10
Training loss: 0.7304442702490705
Validation loss: 2.600685061087497

Epoch: 260| Step: 0
Training loss: 1.1854461174621165
Validation loss: 2.585937535689595

Epoch: 5| Step: 1
Training loss: 1.0048156063342413
Validation loss: 2.5975348045203437

Epoch: 5| Step: 2
Training loss: 0.9574475998148116
Validation loss: 2.6119546521150556

Epoch: 5| Step: 3
Training loss: 1.2089312269025088
Validation loss: 2.6249984588852913

Epoch: 5| Step: 4
Training loss: 0.40259581142242146
Validation loss: 2.5685122750065204

Epoch: 5| Step: 5
Training loss: 0.8429010853731329
Validation loss: 2.649607061925257

Epoch: 5| Step: 6
Training loss: 0.9293702169165702
Validation loss: 2.617434163072088

Epoch: 5| Step: 7
Training loss: 1.0877630134949097
Validation loss: 2.6047265374282103

Epoch: 5| Step: 8
Training loss: 1.0514386471141932
Validation loss: 2.5909791505805653

Epoch: 5| Step: 9
Training loss: 1.7162989392287136
Validation loss: 2.6027647895783828

Epoch: 5| Step: 10
Training loss: 0.9449370087716242
Validation loss: 2.620930516244452

Epoch: 261| Step: 0
Training loss: 0.5537225631220029
Validation loss: 2.6234852746520825

Epoch: 5| Step: 1
Training loss: 1.303041802181504
Validation loss: 2.5963175297464165

Epoch: 5| Step: 2
Training loss: 1.2334325548589449
Validation loss: 2.590910663013191

Epoch: 5| Step: 3
Training loss: 0.8980387590662996
Validation loss: 2.619870113588759

Epoch: 5| Step: 4
Training loss: 1.0151252690890196
Validation loss: 2.63285806029245

Epoch: 5| Step: 5
Training loss: 0.7826765007008312
Validation loss: 2.6362698780669236

Epoch: 5| Step: 6
Training loss: 1.5553001078640258
Validation loss: 2.6457762172258237

Epoch: 5| Step: 7
Training loss: 1.3572522832739204
Validation loss: 2.6338486230633835

Epoch: 5| Step: 8
Training loss: 0.5977589388122753
Validation loss: 2.639411102610044

Epoch: 5| Step: 9
Training loss: 0.8575127625141233
Validation loss: 2.67972359581704

Epoch: 5| Step: 10
Training loss: 1.0020186791344514
Validation loss: 2.644563191936325

Epoch: 262| Step: 0
Training loss: 0.907567710504758
Validation loss: 2.6604609563462547

Epoch: 5| Step: 1
Training loss: 1.3561241917776097
Validation loss: 2.6526464563532732

Epoch: 5| Step: 2
Training loss: 0.9472175507291996
Validation loss: 2.625916341099639

Epoch: 5| Step: 3
Training loss: 0.896724926291993
Validation loss: 2.6151641120911058

Epoch: 5| Step: 4
Training loss: 1.2374699097645292
Validation loss: 2.6445508184805786

Epoch: 5| Step: 5
Training loss: 1.2060529577574894
Validation loss: 2.6275295110899264

Epoch: 5| Step: 6
Training loss: 0.5674438706338818
Validation loss: 2.596665717501025

Epoch: 5| Step: 7
Training loss: 0.8774451423951829
Validation loss: 2.618769453581787

Epoch: 5| Step: 8
Training loss: 0.8934953513534176
Validation loss: 2.5935721298728978

Epoch: 5| Step: 9
Training loss: 0.7599970996951929
Validation loss: 2.5731113412168196

Epoch: 5| Step: 10
Training loss: 1.6347481237862476
Validation loss: 2.5807288441497893

Epoch: 263| Step: 0
Training loss: 1.3617558730860009
Validation loss: 2.590287246634743

Epoch: 5| Step: 1
Training loss: 1.637979827351418
Validation loss: 2.5914901513698525

Epoch: 5| Step: 2
Training loss: 0.8589372733864675
Validation loss: 2.5789624715630928

Epoch: 5| Step: 3
Training loss: 0.8557469512212027
Validation loss: 2.5849097888630945

Epoch: 5| Step: 4
Training loss: 0.7585077144655469
Validation loss: 2.6037771863194847

Epoch: 5| Step: 5
Training loss: 0.9760092121592377
Validation loss: 2.630796853551989

Epoch: 5| Step: 6
Training loss: 0.8035364900289877
Validation loss: 2.632361445618884

Epoch: 5| Step: 7
Training loss: 0.695030176516158
Validation loss: 2.6542274674705917

Epoch: 5| Step: 8
Training loss: 0.9811510850167974
Validation loss: 2.6341835167739505

Epoch: 5| Step: 9
Training loss: 1.3324848197086632
Validation loss: 2.6680352556694547

Epoch: 5| Step: 10
Training loss: 0.8182441065780288
Validation loss: 2.62636384336141

Epoch: 264| Step: 0
Training loss: 1.0874888912817426
Validation loss: 2.642678797208456

Epoch: 5| Step: 1
Training loss: 0.9419905879042504
Validation loss: 2.6239432333370356

Epoch: 5| Step: 2
Training loss: 1.2385347028728493
Validation loss: 2.594523738854621

Epoch: 5| Step: 3
Training loss: 1.0581152140507901
Validation loss: 2.5961187137030595

Epoch: 5| Step: 4
Training loss: 1.0339574241800722
Validation loss: 2.5676518476695067

Epoch: 5| Step: 5
Training loss: 0.7371416934902938
Validation loss: 2.5828465864223635

Epoch: 5| Step: 6
Training loss: 0.9256046625719695
Validation loss: 2.5641680195044554

Epoch: 5| Step: 7
Training loss: 1.4774958168654762
Validation loss: 2.5409397563100793

Epoch: 5| Step: 8
Training loss: 0.7286778082840695
Validation loss: 2.5548435913740857

Epoch: 5| Step: 9
Training loss: 1.0629932156379502
Validation loss: 2.5873784129466055

Epoch: 5| Step: 10
Training loss: 0.9880722789947676
Validation loss: 2.606669219189687

Epoch: 265| Step: 0
Training loss: 0.9485607613872282
Validation loss: 2.588853378346645

Epoch: 5| Step: 1
Training loss: 0.7206383652783463
Validation loss: 2.6113551550586243

Epoch: 5| Step: 2
Training loss: 1.4724523266521419
Validation loss: 2.591463044693641

Epoch: 5| Step: 3
Training loss: 1.041647713806664
Validation loss: 2.6062760107131813

Epoch: 5| Step: 4
Training loss: 0.7882007387631605
Validation loss: 2.5858516502275584

Epoch: 5| Step: 5
Training loss: 1.1167609727711971
Validation loss: 2.6227822611368645

Epoch: 5| Step: 6
Training loss: 0.8225129179244469
Validation loss: 2.577002967851196

Epoch: 5| Step: 7
Training loss: 0.9859770197134491
Validation loss: 2.6003040750000457

Epoch: 5| Step: 8
Training loss: 0.907021358675913
Validation loss: 2.5789344374582406

Epoch: 5| Step: 9
Training loss: 1.3507138272387205
Validation loss: 2.586360708527991

Epoch: 5| Step: 10
Training loss: 1.0244014364651786
Validation loss: 2.597868137814388

Epoch: 266| Step: 0
Training loss: 1.4897719399439746
Validation loss: 2.603287828044129

Epoch: 5| Step: 1
Training loss: 0.9849569931420286
Validation loss: 2.582465126812229

Epoch: 5| Step: 2
Training loss: 1.0698466157157518
Validation loss: 2.583672492965

Epoch: 5| Step: 3
Training loss: 0.9212297023778336
Validation loss: 2.5946015473475708

Epoch: 5| Step: 4
Training loss: 0.864802474473065
Validation loss: 2.5811029472316904

Epoch: 5| Step: 5
Training loss: 0.3561432486090078
Validation loss: 2.5975389368826067

Epoch: 5| Step: 6
Training loss: 0.896898626886908
Validation loss: 2.6053849499046846

Epoch: 5| Step: 7
Training loss: 1.1507111444503966
Validation loss: 2.621623622402013

Epoch: 5| Step: 8
Training loss: 1.1387185141170777
Validation loss: 2.5822104204361986

Epoch: 5| Step: 9
Training loss: 1.1595963690890063
Validation loss: 2.579886639610141

Epoch: 5| Step: 10
Training loss: 1.0451713478114537
Validation loss: 2.6224374299897417

Epoch: 267| Step: 0
Training loss: 1.138585187121508
Validation loss: 2.5864603294593587

Epoch: 5| Step: 1
Training loss: 0.8834071899223381
Validation loss: 2.572262103594828

Epoch: 5| Step: 2
Training loss: 1.4763603273876535
Validation loss: 2.572282875903846

Epoch: 5| Step: 3
Training loss: 1.0922238738152181
Validation loss: 2.6178235450005354

Epoch: 5| Step: 4
Training loss: 0.9226130747565146
Validation loss: 2.5850386178014118

Epoch: 5| Step: 5
Training loss: 0.8910881979560498
Validation loss: 2.5915640762383325

Epoch: 5| Step: 6
Training loss: 0.6912106382741763
Validation loss: 2.6263330788748593

Epoch: 5| Step: 7
Training loss: 0.7432763394571866
Validation loss: 2.61339749203205

Epoch: 5| Step: 8
Training loss: 1.1309782766183518
Validation loss: 2.589297840151239

Epoch: 5| Step: 9
Training loss: 1.0380656688071532
Validation loss: 2.6081247697725036

Epoch: 5| Step: 10
Training loss: 1.0003942666067553
Validation loss: 2.6037848355511266

Epoch: 268| Step: 0
Training loss: 0.6993432600098994
Validation loss: 2.58742147782986

Epoch: 5| Step: 1
Training loss: 1.160836993008824
Validation loss: 2.599809230174637

Epoch: 5| Step: 2
Training loss: 0.734250971283366
Validation loss: 2.5693004610678396

Epoch: 5| Step: 3
Training loss: 0.9640925645390969
Validation loss: 2.582593300445204

Epoch: 5| Step: 4
Training loss: 0.765105518905106
Validation loss: 2.573480537731536

Epoch: 5| Step: 5
Training loss: 1.2312947725007688
Validation loss: 2.58814273781783

Epoch: 5| Step: 6
Training loss: 0.9392012736373597
Validation loss: 2.5454119948237475

Epoch: 5| Step: 7
Training loss: 1.559116285493184
Validation loss: 2.5433045930684286

Epoch: 5| Step: 8
Training loss: 0.8457558419445589
Validation loss: 2.574045497023527

Epoch: 5| Step: 9
Training loss: 1.1641955203661036
Validation loss: 2.5564175998295724

Epoch: 5| Step: 10
Training loss: 0.8055272581530836
Validation loss: 2.5216121316345173

Epoch: 269| Step: 0
Training loss: 1.2374228983278233
Validation loss: 2.553152782850172

Epoch: 5| Step: 1
Training loss: 1.014790353405444
Validation loss: 2.5384677586080207

Epoch: 5| Step: 2
Training loss: 0.5148198748828287
Validation loss: 2.576440588428679

Epoch: 5| Step: 3
Training loss: 0.9015828016299364
Validation loss: 2.5624391562068793

Epoch: 5| Step: 4
Training loss: 1.573849163733789
Validation loss: 2.5549534790948867

Epoch: 5| Step: 5
Training loss: 0.8738790893699094
Validation loss: 2.5595108564114004

Epoch: 5| Step: 6
Training loss: 1.1579121679324107
Validation loss: 2.590725286206081

Epoch: 5| Step: 7
Training loss: 1.0244559542197167
Validation loss: 2.6058715857213994

Epoch: 5| Step: 8
Training loss: 0.43413019074056103
Validation loss: 2.595011590492372

Epoch: 5| Step: 9
Training loss: 0.8052441421646283
Validation loss: 2.5952160474250627

Epoch: 5| Step: 10
Training loss: 1.07009072338062
Validation loss: 2.6099965681123343

Epoch: 270| Step: 0
Training loss: 0.9462815984189469
Validation loss: 2.634401968402894

Epoch: 5| Step: 1
Training loss: 0.9640979432649796
Validation loss: 2.6148825807859026

Epoch: 5| Step: 2
Training loss: 1.0110346421703151
Validation loss: 2.6199645965114224

Epoch: 5| Step: 3
Training loss: 0.9564198935186369
Validation loss: 2.6233544023443294

Epoch: 5| Step: 4
Training loss: 0.9571899905220632
Validation loss: 2.607899402426872

Epoch: 5| Step: 5
Training loss: 0.9724217940414982
Validation loss: 2.6467523649304066

Epoch: 5| Step: 6
Training loss: 0.9079863586976537
Validation loss: 2.6138636624009117

Epoch: 5| Step: 7
Training loss: 1.0553813206330795
Validation loss: 2.6217189349054446

Epoch: 5| Step: 8
Training loss: 0.981318436198134
Validation loss: 2.5942441081974086

Epoch: 5| Step: 9
Training loss: 1.4634349508057638
Validation loss: 2.581080931100663

Epoch: 5| Step: 10
Training loss: 0.6484220801668678
Validation loss: 2.5698590584787246

Epoch: 271| Step: 0
Training loss: 0.7919197096393029
Validation loss: 2.530868882393364

Epoch: 5| Step: 1
Training loss: 0.7057566877866448
Validation loss: 2.5590385150011197

Epoch: 5| Step: 2
Training loss: 1.0528637978117368
Validation loss: 2.54682014064514

Epoch: 5| Step: 3
Training loss: 0.9084403435787579
Validation loss: 2.5454962626208184

Epoch: 5| Step: 4
Training loss: 0.8350357825213078
Validation loss: 2.5473863184166516

Epoch: 5| Step: 5
Training loss: 0.8481176851950877
Validation loss: 2.5657920125451903

Epoch: 5| Step: 6
Training loss: 1.5295533102870293
Validation loss: 2.572368596499646

Epoch: 5| Step: 7
Training loss: 0.8943680193699951
Validation loss: 2.5961588647260605

Epoch: 5| Step: 8
Training loss: 1.2128804524312995
Validation loss: 2.6307441583940303

Epoch: 5| Step: 9
Training loss: 1.1254472373379736
Validation loss: 2.640450905040525

Epoch: 5| Step: 10
Training loss: 0.7967376216576822
Validation loss: 2.645542556743555

Epoch: 272| Step: 0
Training loss: 1.016525280350536
Validation loss: 2.6384898091395397

Epoch: 5| Step: 1
Training loss: 0.5698555461310071
Validation loss: 2.5952697548678114

Epoch: 5| Step: 2
Training loss: 0.9898744188478741
Validation loss: 2.625303871977895

Epoch: 5| Step: 3
Training loss: 1.3166421288404917
Validation loss: 2.611474356704469

Epoch: 5| Step: 4
Training loss: 1.339814210794094
Validation loss: 2.5709014186983365

Epoch: 5| Step: 5
Training loss: 0.8853102938014912
Validation loss: 2.5899503056740376

Epoch: 5| Step: 6
Training loss: 0.8393460595545003
Validation loss: 2.56577083572906

Epoch: 5| Step: 7
Training loss: 0.656542213413406
Validation loss: 2.606219984855396

Epoch: 5| Step: 8
Training loss: 1.0281887278183988
Validation loss: 2.577563436284992

Epoch: 5| Step: 9
Training loss: 0.6688489635720428
Validation loss: 2.5676975297857623

Epoch: 5| Step: 10
Training loss: 1.3916384829258044
Validation loss: 2.5777205710905027

Epoch: 273| Step: 0
Training loss: 0.6416331012005567
Validation loss: 2.594187755291141

Epoch: 5| Step: 1
Training loss: 0.9642382123136142
Validation loss: 2.5504162883509145

Epoch: 5| Step: 2
Training loss: 1.1917503985529738
Validation loss: 2.5778115149985217

Epoch: 5| Step: 3
Training loss: 0.7320537404907663
Validation loss: 2.5414548254735605

Epoch: 5| Step: 4
Training loss: 0.9252895868486185
Validation loss: 2.552593273843271

Epoch: 5| Step: 5
Training loss: 1.0694288518245079
Validation loss: 2.5551209511207116

Epoch: 5| Step: 6
Training loss: 0.8144148490565668
Validation loss: 2.5410566850401644

Epoch: 5| Step: 7
Training loss: 1.0391693060341003
Validation loss: 2.5352717345374116

Epoch: 5| Step: 8
Training loss: 1.574881667278585
Validation loss: 2.532796241882319

Epoch: 5| Step: 9
Training loss: 0.8066620904684967
Validation loss: 2.530676582962397

Epoch: 5| Step: 10
Training loss: 0.9628304545886816
Validation loss: 2.5035650716340245

Epoch: 274| Step: 0
Training loss: 1.0957803681969884
Validation loss: 2.56368361439007

Epoch: 5| Step: 1
Training loss: 0.7766118653723385
Validation loss: 2.5648836963819748

Epoch: 5| Step: 2
Training loss: 0.8888291439866338
Validation loss: 2.5799931365183597

Epoch: 5| Step: 3
Training loss: 0.9036305817444732
Validation loss: 2.5765844048365087

Epoch: 5| Step: 4
Training loss: 0.9969307468336962
Validation loss: 2.552747542985531

Epoch: 5| Step: 5
Training loss: 0.9328829561395426
Validation loss: 2.583158023818915

Epoch: 5| Step: 6
Training loss: 1.5267115696851512
Validation loss: 2.5857342695100183

Epoch: 5| Step: 7
Training loss: 0.7208860831906083
Validation loss: 2.577945279606325

Epoch: 5| Step: 8
Training loss: 0.7098962473617395
Validation loss: 2.5940004483092585

Epoch: 5| Step: 9
Training loss: 1.022142012589022
Validation loss: 2.5838131798013944

Epoch: 5| Step: 10
Training loss: 1.1092246585037844
Validation loss: 2.5710598575693395

Epoch: 275| Step: 0
Training loss: 0.6642176951649253
Validation loss: 2.55022056123571

Epoch: 5| Step: 1
Training loss: 1.0513311032320156
Validation loss: 2.5799212579968067

Epoch: 5| Step: 2
Training loss: 0.9242562396845174
Validation loss: 2.568408472159666

Epoch: 5| Step: 3
Training loss: 0.8310107209424125
Validation loss: 2.5680899188109945

Epoch: 5| Step: 4
Training loss: 0.6174433938231763
Validation loss: 2.5765935600954455

Epoch: 5| Step: 5
Training loss: 1.164618647295298
Validation loss: 2.5913277108583244

Epoch: 5| Step: 6
Training loss: 0.9467182898437672
Validation loss: 2.613473776810927

Epoch: 5| Step: 7
Training loss: 1.5472742971761355
Validation loss: 2.5993009911806477

Epoch: 5| Step: 8
Training loss: 1.035932544909288
Validation loss: 2.651523394173647

Epoch: 5| Step: 9
Training loss: 0.8799182406288355
Validation loss: 2.635910070352832

Epoch: 5| Step: 10
Training loss: 0.795923375400146
Validation loss: 2.616892561427888

Epoch: 276| Step: 0
Training loss: 0.8699849003544761
Validation loss: 2.6473875925240624

Epoch: 5| Step: 1
Training loss: 1.032886593652609
Validation loss: 2.6479878417912195

Epoch: 5| Step: 2
Training loss: 0.9179677111031356
Validation loss: 2.580220744588066

Epoch: 5| Step: 3
Training loss: 1.4810707659869207
Validation loss: 2.618542082414224

Epoch: 5| Step: 4
Training loss: 1.0730855062034723
Validation loss: 2.60433491087487

Epoch: 5| Step: 5
Training loss: 0.9889508719223409
Validation loss: 2.6009391804854776

Epoch: 5| Step: 6
Training loss: 1.0252798256729754
Validation loss: 2.5986996986708246

Epoch: 5| Step: 7
Training loss: 0.76895100361581
Validation loss: 2.6431928802590745

Epoch: 5| Step: 8
Training loss: 0.7372473688140102
Validation loss: 2.6059330622786123

Epoch: 5| Step: 9
Training loss: 0.7892102395918411
Validation loss: 2.601803009062045

Epoch: 5| Step: 10
Training loss: 0.7610915903347812
Validation loss: 2.626229747700318

Epoch: 277| Step: 0
Training loss: 1.073728747884734
Validation loss: 2.617202794497594

Epoch: 5| Step: 1
Training loss: 1.1543498535391448
Validation loss: 2.6416087421549173

Epoch: 5| Step: 2
Training loss: 0.9815557768797021
Validation loss: 2.6128809121154064

Epoch: 5| Step: 3
Training loss: 0.9601711846253993
Validation loss: 2.614449056398255

Epoch: 5| Step: 4
Training loss: 0.8104466387804986
Validation loss: 2.600973597519184

Epoch: 5| Step: 5
Training loss: 0.7696228360121965
Validation loss: 2.5674536191648367

Epoch: 5| Step: 6
Training loss: 0.8260785494279473
Validation loss: 2.5503210784498314

Epoch: 5| Step: 7
Training loss: 0.8642462260875894
Validation loss: 2.5694280851316904

Epoch: 5| Step: 8
Training loss: 1.5086262933035073
Validation loss: 2.5498021719222126

Epoch: 5| Step: 9
Training loss: 0.8571481810983437
Validation loss: 2.542842498866769

Epoch: 5| Step: 10
Training loss: 0.41478572518681994
Validation loss: 2.5561310359221365

Epoch: 278| Step: 0
Training loss: 1.4290598340972052
Validation loss: 2.535375409696373

Epoch: 5| Step: 1
Training loss: 1.0113245369091308
Validation loss: 2.5520214820852223

Epoch: 5| Step: 2
Training loss: 0.6747336232903538
Validation loss: 2.5871151183760737

Epoch: 5| Step: 3
Training loss: 0.8242590654827444
Validation loss: 2.5874072973317723

Epoch: 5| Step: 4
Training loss: 1.1811772722733689
Validation loss: 2.5776578378641366

Epoch: 5| Step: 5
Training loss: 0.7150040743785091
Validation loss: 2.5826383807757707

Epoch: 5| Step: 6
Training loss: 0.9210178787264705
Validation loss: 2.600357344620827

Epoch: 5| Step: 7
Training loss: 1.1682361819696812
Validation loss: 2.6328541362375923

Epoch: 5| Step: 8
Training loss: 0.8993562064682581
Validation loss: 2.6474889901426977

Epoch: 5| Step: 9
Training loss: 0.6531485201967435
Validation loss: 2.6560616442729863

Epoch: 5| Step: 10
Training loss: 0.801814496618805
Validation loss: 2.621968959501621

Epoch: 279| Step: 0
Training loss: 0.8973134846393295
Validation loss: 2.619806944330137

Epoch: 5| Step: 1
Training loss: 1.5801679776628894
Validation loss: 2.5867018819521306

Epoch: 5| Step: 2
Training loss: 0.9413149777562105
Validation loss: 2.625832370529253

Epoch: 5| Step: 3
Training loss: 0.9529593902293368
Validation loss: 2.633251669754432

Epoch: 5| Step: 4
Training loss: 0.7707161470638462
Validation loss: 2.6152021405221446

Epoch: 5| Step: 5
Training loss: 0.936735668140948
Validation loss: 2.6245244147643967

Epoch: 5| Step: 6
Training loss: 0.9044299429421655
Validation loss: 2.6411957162571813

Epoch: 5| Step: 7
Training loss: 0.8434209535211714
Validation loss: 2.6275550158549548

Epoch: 5| Step: 8
Training loss: 0.6391234128690964
Validation loss: 2.6296867803014345

Epoch: 5| Step: 9
Training loss: 1.0498735556081016
Validation loss: 2.64470630355439

Epoch: 5| Step: 10
Training loss: 0.605671215045893
Validation loss: 2.634893801694322

Epoch: 280| Step: 0
Training loss: 1.1202490412191466
Validation loss: 2.621251650469023

Epoch: 5| Step: 1
Training loss: 0.8138911002747138
Validation loss: 2.6535823004154646

Epoch: 5| Step: 2
Training loss: 0.8116219250790999
Validation loss: 2.6036225181503094

Epoch: 5| Step: 3
Training loss: 1.6197367308235482
Validation loss: 2.5800206608035237

Epoch: 5| Step: 4
Training loss: 0.6707693139521975
Validation loss: 2.561885057641589

Epoch: 5| Step: 5
Training loss: 1.0440264992328805
Validation loss: 2.569998246582526

Epoch: 5| Step: 6
Training loss: 0.5366070704758189
Validation loss: 2.55175930541945

Epoch: 5| Step: 7
Training loss: 0.8602954789932934
Validation loss: 2.5381402210304698

Epoch: 5| Step: 8
Training loss: 0.8669275805005043
Validation loss: 2.5600362309060247

Epoch: 5| Step: 9
Training loss: 0.5643854859688618
Validation loss: 2.5542590940605403

Epoch: 5| Step: 10
Training loss: 1.0802147004624376
Validation loss: 2.5405312201963652

Epoch: 281| Step: 0
Training loss: 0.38811921359554064
Validation loss: 2.5517920469527637

Epoch: 5| Step: 1
Training loss: 0.8104683711630394
Validation loss: 2.5861935009398453

Epoch: 5| Step: 2
Training loss: 0.9442793189100759
Validation loss: 2.6047440890785527

Epoch: 5| Step: 3
Training loss: 1.0768066306614321
Validation loss: 2.5768965115177487

Epoch: 5| Step: 4
Training loss: 0.9980352591419043
Validation loss: 2.60684432323336

Epoch: 5| Step: 5
Training loss: 0.9884658460143565
Validation loss: 2.6065377036948947

Epoch: 5| Step: 6
Training loss: 0.6875711534266099
Validation loss: 2.6019543832359053

Epoch: 5| Step: 7
Training loss: 0.8177317759723203
Validation loss: 2.6314861011142323

Epoch: 5| Step: 8
Training loss: 0.7676762719535545
Validation loss: 2.6025281392170125

Epoch: 5| Step: 9
Training loss: 0.8365633751711794
Validation loss: 2.6008479521482433

Epoch: 5| Step: 10
Training loss: 1.6448663293160781
Validation loss: 2.633512780467056

Epoch: 282| Step: 0
Training loss: 0.6727295918638502
Validation loss: 2.6364524356186827

Epoch: 5| Step: 1
Training loss: 0.7283272998379503
Validation loss: 2.60494159678287

Epoch: 5| Step: 2
Training loss: 1.5150574083435855
Validation loss: 2.6303482263758826

Epoch: 5| Step: 3
Training loss: 0.7217939438663857
Validation loss: 2.6071941184545553

Epoch: 5| Step: 4
Training loss: 0.9306452009725463
Validation loss: 2.6007233717153837

Epoch: 5| Step: 5
Training loss: 0.7504803788036492
Validation loss: 2.5764638382397096

Epoch: 5| Step: 6
Training loss: 0.8987908373429755
Validation loss: 2.579447507814943

Epoch: 5| Step: 7
Training loss: 1.0974523823342355
Validation loss: 2.543145416460636

Epoch: 5| Step: 8
Training loss: 0.7370510852531164
Validation loss: 2.595425496166558

Epoch: 5| Step: 9
Training loss: 1.012464977176722
Validation loss: 2.558837298891373

Epoch: 5| Step: 10
Training loss: 0.9887650402579337
Validation loss: 2.5959402266939327

Epoch: 283| Step: 0
Training loss: 0.5906942942503751
Validation loss: 2.587505092341393

Epoch: 5| Step: 1
Training loss: 0.7219653151520881
Validation loss: 2.6208270412696706

Epoch: 5| Step: 2
Training loss: 1.0647875899061006
Validation loss: 2.5725307747311477

Epoch: 5| Step: 3
Training loss: 0.5272586895193625
Validation loss: 2.588799955192913

Epoch: 5| Step: 4
Training loss: 1.5283069744076518
Validation loss: 2.576679776035295

Epoch: 5| Step: 5
Training loss: 0.7256240937377633
Validation loss: 2.6014396758954828

Epoch: 5| Step: 6
Training loss: 0.7812464904706329
Validation loss: 2.6338548894443115

Epoch: 5| Step: 7
Training loss: 0.9417609025563605
Validation loss: 2.6495122079053255

Epoch: 5| Step: 8
Training loss: 0.7996201447850378
Validation loss: 2.6617502487861895

Epoch: 5| Step: 9
Training loss: 1.1719170626402955
Validation loss: 2.6990153658989127

Epoch: 5| Step: 10
Training loss: 0.9979351302146429
Validation loss: 2.6710622151270864

Epoch: 284| Step: 0
Training loss: 0.9163305070800417
Validation loss: 2.6603741714586464

Epoch: 5| Step: 1
Training loss: 1.0003189531932681
Validation loss: 2.642934801695903

Epoch: 5| Step: 2
Training loss: 0.9957633873118363
Validation loss: 2.6413341214953103

Epoch: 5| Step: 3
Training loss: 0.5337810528318605
Validation loss: 2.6309782084295095

Epoch: 5| Step: 4
Training loss: 0.7058775113619928
Validation loss: 2.6099370378515747

Epoch: 5| Step: 5
Training loss: 1.386253644286612
Validation loss: 2.6198967247755665

Epoch: 5| Step: 6
Training loss: 0.7783587552751315
Validation loss: 2.5842568423594305

Epoch: 5| Step: 7
Training loss: 1.148652919365626
Validation loss: 2.604292303848853

Epoch: 5| Step: 8
Training loss: 0.9884211625887622
Validation loss: 2.619932704979667

Epoch: 5| Step: 9
Training loss: 0.7658643543019669
Validation loss: 2.6294406787149405

Epoch: 5| Step: 10
Training loss: 0.9668700527663799
Validation loss: 2.642912460614829

Epoch: 285| Step: 0
Training loss: 0.9882539285494372
Validation loss: 2.6067289863507277

Epoch: 5| Step: 1
Training loss: 1.0211343256645597
Validation loss: 2.582042955998747

Epoch: 5| Step: 2
Training loss: 0.8534231594114232
Validation loss: 2.5756659495745606

Epoch: 5| Step: 3
Training loss: 0.7515229418965251
Validation loss: 2.5855161043893657

Epoch: 5| Step: 4
Training loss: 1.4852000302800454
Validation loss: 2.568106299329729

Epoch: 5| Step: 5
Training loss: 0.7773751487333085
Validation loss: 2.5978338503613805

Epoch: 5| Step: 6
Training loss: 0.7714690001681986
Validation loss: 2.5855698174943513

Epoch: 5| Step: 7
Training loss: 0.7552540644688167
Validation loss: 2.643750754192664

Epoch: 5| Step: 8
Training loss: 1.049484076224203
Validation loss: 2.6734223015228187

Epoch: 5| Step: 9
Training loss: 0.9599207639777043
Validation loss: 2.7232759319306865

Epoch: 5| Step: 10
Training loss: 0.8699557478930084
Validation loss: 2.7059755414586477

Epoch: 286| Step: 0
Training loss: 0.8278017672818275
Validation loss: 2.6445747956337433

Epoch: 5| Step: 1
Training loss: 0.8317060954571519
Validation loss: 2.6448739101362575

Epoch: 5| Step: 2
Training loss: 0.831439564536946
Validation loss: 2.5772075911374994

Epoch: 5| Step: 3
Training loss: 0.7162076102690006
Validation loss: 2.562272668774657

Epoch: 5| Step: 4
Training loss: 0.9689898347843044
Validation loss: 2.5746641584592855

Epoch: 5| Step: 5
Training loss: 0.6126413347704767
Validation loss: 2.594528047447193

Epoch: 5| Step: 6
Training loss: 0.8680779979771702
Validation loss: 2.5763875536763203

Epoch: 5| Step: 7
Training loss: 1.1278351451009325
Validation loss: 2.534247533275035

Epoch: 5| Step: 8
Training loss: 0.9883955938360667
Validation loss: 2.5512048538267615

Epoch: 5| Step: 9
Training loss: 1.516809217160625
Validation loss: 2.5224619893963705

Epoch: 5| Step: 10
Training loss: 0.6160489941099823
Validation loss: 2.5573765127209573

Epoch: 287| Step: 0
Training loss: 1.015844233399374
Validation loss: 2.5137570721907143

Epoch: 5| Step: 1
Training loss: 0.8182488414617507
Validation loss: 2.541556722770247

Epoch: 5| Step: 2
Training loss: 0.9795051490177117
Validation loss: 2.559707410506296

Epoch: 5| Step: 3
Training loss: 0.7549365420546613
Validation loss: 2.5710568467808477

Epoch: 5| Step: 4
Training loss: 0.6973759967204012
Validation loss: 2.598633508993186

Epoch: 5| Step: 5
Training loss: 1.1256079090945366
Validation loss: 2.6019167897962543

Epoch: 5| Step: 6
Training loss: 0.9600752707119306
Validation loss: 2.6090365013387453

Epoch: 5| Step: 7
Training loss: 1.5176671221742395
Validation loss: 2.5872133034448597

Epoch: 5| Step: 8
Training loss: 0.7819313892549244
Validation loss: 2.5854978272822224

Epoch: 5| Step: 9
Training loss: 0.5889393017391225
Validation loss: 2.559756807817433

Epoch: 5| Step: 10
Training loss: 0.7295852050307001
Validation loss: 2.539822392622082

Epoch: 288| Step: 0
Training loss: 0.9666810553948725
Validation loss: 2.54448264930962

Epoch: 5| Step: 1
Training loss: 0.9918609442192698
Validation loss: 2.5227834527682194

Epoch: 5| Step: 2
Training loss: 0.9323943985469244
Validation loss: 2.5286980194992172

Epoch: 5| Step: 3
Training loss: 0.8792771976528192
Validation loss: 2.5351266691592205

Epoch: 5| Step: 4
Training loss: 0.9211105474569511
Validation loss: 2.5224196128704004

Epoch: 5| Step: 5
Training loss: 0.7658801140331969
Validation loss: 2.5371943601069966

Epoch: 5| Step: 6
Training loss: 1.4292698651451758
Validation loss: 2.5814588656763453

Epoch: 5| Step: 7
Training loss: 0.6077098593062251
Validation loss: 2.6200553735061813

Epoch: 5| Step: 8
Training loss: 1.1436873830529124
Validation loss: 2.641512540145516

Epoch: 5| Step: 9
Training loss: 0.5762285624920804
Validation loss: 2.6339871924504252

Epoch: 5| Step: 10
Training loss: 0.9900844543249906
Validation loss: 2.6042683879715405

Epoch: 289| Step: 0
Training loss: 0.7783775164978701
Validation loss: 2.576827849629878

Epoch: 5| Step: 1
Training loss: 0.7130607924446353
Validation loss: 2.528168654053847

Epoch: 5| Step: 2
Training loss: 0.9773602088621812
Validation loss: 2.523197518364163

Epoch: 5| Step: 3
Training loss: 1.1065287007273907
Validation loss: 2.510123639694592

Epoch: 5| Step: 4
Training loss: 1.0218918755214041
Validation loss: 2.520235440416469

Epoch: 5| Step: 5
Training loss: 0.9581669822000499
Validation loss: 2.5317661757215095

Epoch: 5| Step: 6
Training loss: 1.101334676788687
Validation loss: 2.5938546201261583

Epoch: 5| Step: 7
Training loss: 0.6812453995995535
Validation loss: 2.6117487983420076

Epoch: 5| Step: 8
Training loss: 1.4422792515029106
Validation loss: 2.66712385598692

Epoch: 5| Step: 9
Training loss: 0.9764698747577196
Validation loss: 2.6883168697311426

Epoch: 5| Step: 10
Training loss: 0.7814746533686983
Validation loss: 2.7031592720719013

Epoch: 290| Step: 0
Training loss: 1.1411658794407231
Validation loss: 2.652770406974104

Epoch: 5| Step: 1
Training loss: 0.6655626294639849
Validation loss: 2.6115460617914015

Epoch: 5| Step: 2
Training loss: 0.845492647334184
Validation loss: 2.6340788273420785

Epoch: 5| Step: 3
Training loss: 1.4517844795190966
Validation loss: 2.608989336087235

Epoch: 5| Step: 4
Training loss: 0.6601691837285277
Validation loss: 2.5803613762087854

Epoch: 5| Step: 5
Training loss: 0.7854046404969336
Validation loss: 2.556883803464272

Epoch: 5| Step: 6
Training loss: 0.8428406583603358
Validation loss: 2.554197921472036

Epoch: 5| Step: 7
Training loss: 1.0172086839476984
Validation loss: 2.4953527001914457

Epoch: 5| Step: 8
Training loss: 1.0720749982640072
Validation loss: 2.5052425748957887

Epoch: 5| Step: 9
Training loss: 0.9143665166788564
Validation loss: 2.522107812948518

Epoch: 5| Step: 10
Training loss: 1.0497827146137988
Validation loss: 2.535315688549776

Epoch: 291| Step: 0
Training loss: 0.64186594725468
Validation loss: 2.5170001001069524

Epoch: 5| Step: 1
Training loss: 1.0443730419238744
Validation loss: 2.560313488729785

Epoch: 5| Step: 2
Training loss: 1.0875310389156065
Validation loss: 2.606024811055575

Epoch: 5| Step: 3
Training loss: 0.8765142145304466
Validation loss: 2.5855346746129446

Epoch: 5| Step: 4
Training loss: 0.6840277683647487
Validation loss: 2.5513701362554926

Epoch: 5| Step: 5
Training loss: 1.0792304190776238
Validation loss: 2.603157846931746

Epoch: 5| Step: 6
Training loss: 0.9195939631698268
Validation loss: 2.579700000066549

Epoch: 5| Step: 7
Training loss: 0.8835568286254742
Validation loss: 2.5624739542792216

Epoch: 5| Step: 8
Training loss: 1.5548222929062698
Validation loss: 2.5539237800633705

Epoch: 5| Step: 9
Training loss: 0.8537597307178467
Validation loss: 2.577630114298207

Epoch: 5| Step: 10
Training loss: 0.6165963734265539
Validation loss: 2.5303592833943878

Epoch: 292| Step: 0
Training loss: 0.6309538023582207
Validation loss: 2.5213306820813757

Epoch: 5| Step: 1
Training loss: 0.6794907953917477
Validation loss: 2.538257178735429

Epoch: 5| Step: 2
Training loss: 0.5022137036041824
Validation loss: 2.5141935439439265

Epoch: 5| Step: 3
Training loss: 0.6560171259092529
Validation loss: 2.5216511505158508

Epoch: 5| Step: 4
Training loss: 1.0852968810034291
Validation loss: 2.533242029610212

Epoch: 5| Step: 5
Training loss: 0.8256411098782657
Validation loss: 2.5494439793851007

Epoch: 5| Step: 6
Training loss: 0.972537267064044
Validation loss: 2.5416485506565674

Epoch: 5| Step: 7
Training loss: 1.628075843112886
Validation loss: 2.5579888267542783

Epoch: 5| Step: 8
Training loss: 0.8961373116531725
Validation loss: 2.5523288738438787

Epoch: 5| Step: 9
Training loss: 0.7100841724844594
Validation loss: 2.564273821555956

Epoch: 5| Step: 10
Training loss: 1.0132207730377232
Validation loss: 2.606167443227636

Epoch: 293| Step: 0
Training loss: 0.8441324779959377
Validation loss: 2.5876686510857962

Epoch: 5| Step: 1
Training loss: 1.4189643832327783
Validation loss: 2.612580759133122

Epoch: 5| Step: 2
Training loss: 1.2156363597035107
Validation loss: 2.6360572442722803

Epoch: 5| Step: 3
Training loss: 0.8706542475840867
Validation loss: 2.61517955174196

Epoch: 5| Step: 4
Training loss: 0.7720788138336739
Validation loss: 2.5797321261186483

Epoch: 5| Step: 5
Training loss: 0.6315342980552461
Validation loss: 2.5953753592898026

Epoch: 5| Step: 6
Training loss: 0.9680553222070963
Validation loss: 2.551660958740094

Epoch: 5| Step: 7
Training loss: 0.7834663234257883
Validation loss: 2.5214372994621566

Epoch: 5| Step: 8
Training loss: 0.5274759197614542
Validation loss: 2.5381218876031646

Epoch: 5| Step: 9
Training loss: 0.4821251022006444
Validation loss: 2.5704832748710653

Epoch: 5| Step: 10
Training loss: 0.9998874004866941
Validation loss: 2.5775394494422166

Epoch: 294| Step: 0
Training loss: 0.9552111074781052
Validation loss: 2.593462792101998

Epoch: 5| Step: 1
Training loss: 0.8350807505525378
Validation loss: 2.5658001522015645

Epoch: 5| Step: 2
Training loss: 0.7376333956580842
Validation loss: 2.584437826537969

Epoch: 5| Step: 3
Training loss: 0.837760933039993
Validation loss: 2.588507212427735

Epoch: 5| Step: 4
Training loss: 1.5167931056853838
Validation loss: 2.584812735723916

Epoch: 5| Step: 5
Training loss: 0.8810858932174584
Validation loss: 2.5757457913162125

Epoch: 5| Step: 6
Training loss: 0.7450646298172229
Validation loss: 2.6091157144427584

Epoch: 5| Step: 7
Training loss: 0.7600915204958704
Validation loss: 2.622251436970687

Epoch: 5| Step: 8
Training loss: 0.7324328612457288
Validation loss: 2.5682299679257414

Epoch: 5| Step: 9
Training loss: 0.6750281884347522
Validation loss: 2.589257516893827

Epoch: 5| Step: 10
Training loss: 0.8468941985484395
Validation loss: 2.606579576205615

Epoch: 295| Step: 0
Training loss: 0.7687007081891148
Validation loss: 2.6009324415221586

Epoch: 5| Step: 1
Training loss: 0.9329878944089999
Validation loss: 2.5788802178405508

Epoch: 5| Step: 2
Training loss: 0.7018888627718867
Validation loss: 2.5758584289823037

Epoch: 5| Step: 3
Training loss: 0.896986145682284
Validation loss: 2.60110730097884

Epoch: 5| Step: 4
Training loss: 0.5437605045663189
Validation loss: 2.546548599636238

Epoch: 5| Step: 5
Training loss: 0.8758898365718054
Validation loss: 2.5760557420349532

Epoch: 5| Step: 6
Training loss: 0.9470406491257366
Validation loss: 2.573635709447074

Epoch: 5| Step: 7
Training loss: 1.516833108984464
Validation loss: 2.603561786584894

Epoch: 5| Step: 8
Training loss: 0.7127488922945459
Validation loss: 2.592385375009227

Epoch: 5| Step: 9
Training loss: 0.5720643089763455
Validation loss: 2.6060824612872193

Epoch: 5| Step: 10
Training loss: 0.7895470443948559
Validation loss: 2.5765972862660713

Epoch: 296| Step: 0
Training loss: 0.7049615187660265
Validation loss: 2.5911816461819024

Epoch: 5| Step: 1
Training loss: 0.926574881922828
Validation loss: 2.5687880910411467

Epoch: 5| Step: 2
Training loss: 0.7887888518859132
Validation loss: 2.5570814928800787

Epoch: 5| Step: 3
Training loss: 0.9087690005618265
Validation loss: 2.5645699173248757

Epoch: 5| Step: 4
Training loss: 0.7405019794775078
Validation loss: 2.60452508014547

Epoch: 5| Step: 5
Training loss: 0.8437872277983315
Validation loss: 2.581797941056146

Epoch: 5| Step: 6
Training loss: 0.7995988629893606
Validation loss: 2.5764999593094497

Epoch: 5| Step: 7
Training loss: 0.4860859156694274
Validation loss: 2.549134329940872

Epoch: 5| Step: 8
Training loss: 0.2885666796220663
Validation loss: 2.6023820313432555

Epoch: 5| Step: 9
Training loss: 0.8275528136626327
Validation loss: 2.5638692415576574

Epoch: 5| Step: 10
Training loss: 1.6847634909616527
Validation loss: 2.5620724621262227

Epoch: 297| Step: 0
Training loss: 0.9784911679925302
Validation loss: 2.547960893521837

Epoch: 5| Step: 1
Training loss: 0.7121051380159067
Validation loss: 2.5360419175876876

Epoch: 5| Step: 2
Training loss: 0.7643201569090913
Validation loss: 2.5457679793181702

Epoch: 5| Step: 3
Training loss: 0.7416489102527567
Validation loss: 2.5249445019412877

Epoch: 5| Step: 4
Training loss: 0.7478545417238133
Validation loss: 2.5477119820453846

Epoch: 5| Step: 5
Training loss: 0.5627618815838272
Validation loss: 2.5381793246945747

Epoch: 5| Step: 6
Training loss: 0.5121821278353771
Validation loss: 2.5124437515745

Epoch: 5| Step: 7
Training loss: 0.7655875138428534
Validation loss: 2.5528182248434224

Epoch: 5| Step: 8
Training loss: 1.0135268620307916
Validation loss: 2.534732270137755

Epoch: 5| Step: 9
Training loss: 1.3923388432058939
Validation loss: 2.5649305692257145

Epoch: 5| Step: 10
Training loss: 0.9778538824817433
Validation loss: 2.5374480364575005

Epoch: 298| Step: 0
Training loss: 0.8735593789219497
Validation loss: 2.5502055546356583

Epoch: 5| Step: 1
Training loss: 0.6199110033780221
Validation loss: 2.5792298297310143

Epoch: 5| Step: 2
Training loss: 0.6925190951541275
Validation loss: 2.585434243598083

Epoch: 5| Step: 3
Training loss: 1.1781038176152605
Validation loss: 2.617409403489189

Epoch: 5| Step: 4
Training loss: 0.5237465415876824
Validation loss: 2.6427005679155964

Epoch: 5| Step: 5
Training loss: 1.567668073608256
Validation loss: 2.6412019079393594

Epoch: 5| Step: 6
Training loss: 0.6715807603117063
Validation loss: 2.630537743999425

Epoch: 5| Step: 7
Training loss: 0.633450269151661
Validation loss: 2.59655486709084

Epoch: 5| Step: 8
Training loss: 0.5350139178043306
Validation loss: 2.5774748180276394

Epoch: 5| Step: 9
Training loss: 0.7320054154534472
Validation loss: 2.5580220437693995

Epoch: 5| Step: 10
Training loss: 0.914108536041904
Validation loss: 2.5555103797212966

Epoch: 299| Step: 0
Training loss: 0.4777319426954208
Validation loss: 2.52236351881504

Epoch: 5| Step: 1
Training loss: 0.6572924463314826
Validation loss: 2.5528443525082354

Epoch: 5| Step: 2
Training loss: 1.1077687092076896
Validation loss: 2.5262506093894577

Epoch: 5| Step: 3
Training loss: 0.7488631135331185
Validation loss: 2.5771113824748335

Epoch: 5| Step: 4
Training loss: 0.8867190860966117
Validation loss: 2.594410791001918

Epoch: 5| Step: 5
Training loss: 1.4017063062840724
Validation loss: 2.5761271780917046

Epoch: 5| Step: 6
Training loss: 0.7087464577049798
Validation loss: 2.5864470050292714

Epoch: 5| Step: 7
Training loss: 0.7318751621653363
Validation loss: 2.6126311653779624

Epoch: 5| Step: 8
Training loss: 0.939358204826624
Validation loss: 2.5834841636213737

Epoch: 5| Step: 9
Training loss: 0.6756719379547198
Validation loss: 2.5985499413033444

Epoch: 5| Step: 10
Training loss: 0.7565239244700681
Validation loss: 2.6007113264207438

Epoch: 300| Step: 0
Training loss: 1.431164088440166
Validation loss: 2.583890333540026

Epoch: 5| Step: 1
Training loss: 0.698772884976817
Validation loss: 2.5987844758982424

Epoch: 5| Step: 2
Training loss: 0.9079586233172682
Validation loss: 2.6064506651225723

Epoch: 5| Step: 3
Training loss: 0.8079860449190163
Validation loss: 2.5651826919688454

Epoch: 5| Step: 4
Training loss: 0.7150900994732657
Validation loss: 2.5614107769831738

Epoch: 5| Step: 5
Training loss: 0.6048006370826171
Validation loss: 2.5597868261183843

Epoch: 5| Step: 6
Training loss: 0.878581991780144
Validation loss: 2.5738920372664085

Epoch: 5| Step: 7
Training loss: 0.9139953001702842
Validation loss: 2.577153146683027

Epoch: 5| Step: 8
Training loss: 0.9891005727180641
Validation loss: 2.5541680091207057

Epoch: 5| Step: 9
Training loss: 0.6196519443085923
Validation loss: 2.554991027556682

Epoch: 5| Step: 10
Training loss: 0.38042389842273305
Validation loss: 2.5507321030044317

Epoch: 301| Step: 0
Training loss: 0.7891272338903246
Validation loss: 2.532748310245661

Epoch: 5| Step: 1
Training loss: 0.631609491396054
Validation loss: 2.5180890644481018

Epoch: 5| Step: 2
Training loss: 0.6482644367221378
Validation loss: 2.517206953055308

Epoch: 5| Step: 3
Training loss: 0.3670648410539947
Validation loss: 2.514693113894483

Epoch: 5| Step: 4
Training loss: 0.6220575208561445
Validation loss: 2.5083201027596433

Epoch: 5| Step: 5
Training loss: 0.9204844315811453
Validation loss: 2.5166703823197722

Epoch: 5| Step: 6
Training loss: 0.7281698679709211
Validation loss: 2.5372788533388433

Epoch: 5| Step: 7
Training loss: 1.601916167124279
Validation loss: 2.5748615341559193

Epoch: 5| Step: 8
Training loss: 0.836968935366094
Validation loss: 2.561819254735336

Epoch: 5| Step: 9
Training loss: 0.8134294109257364
Validation loss: 2.5833779793280938

Epoch: 5| Step: 10
Training loss: 0.9161716157553882
Validation loss: 2.6107562082005185

Epoch: 302| Step: 0
Training loss: 0.8039654204870177
Validation loss: 2.5984688176867823

Epoch: 5| Step: 1
Training loss: 0.5048371226077317
Validation loss: 2.644445917575855

Epoch: 5| Step: 2
Training loss: 0.7097995579889876
Validation loss: 2.604922298609163

Epoch: 5| Step: 3
Training loss: 0.47306604196918645
Validation loss: 2.6163637189930458

Epoch: 5| Step: 4
Training loss: 0.8257211668736162
Validation loss: 2.5879618958441437

Epoch: 5| Step: 5
Training loss: 0.6732587537284948
Validation loss: 2.551417605018468

Epoch: 5| Step: 6
Training loss: 0.785343128947428
Validation loss: 2.539935811867382

Epoch: 5| Step: 7
Training loss: 1.0623288297215607
Validation loss: 2.5662474244186244

Epoch: 5| Step: 8
Training loss: 0.783197645515433
Validation loss: 2.5667261828982855

Epoch: 5| Step: 9
Training loss: 1.56534066426046
Validation loss: 2.5320797877654146

Epoch: 5| Step: 10
Training loss: 0.432262869722185
Validation loss: 2.5594336769208854

Epoch: 303| Step: 0
Training loss: 1.007203206251433
Validation loss: 2.5522351370275485

Epoch: 5| Step: 1
Training loss: 0.7276495727992857
Validation loss: 2.524311186314992

Epoch: 5| Step: 2
Training loss: 0.6167036163584051
Validation loss: 2.5541894442336206

Epoch: 5| Step: 3
Training loss: 0.5809114936888684
Validation loss: 2.5721926494767025

Epoch: 5| Step: 4
Training loss: 0.5775475582340338
Validation loss: 2.5821706938884796

Epoch: 5| Step: 5
Training loss: 0.6363052710637804
Validation loss: 2.5791541001152916

Epoch: 5| Step: 6
Training loss: 0.7703135817328667
Validation loss: 2.5682261317901762

Epoch: 5| Step: 7
Training loss: 0.7505320410296429
Validation loss: 2.5215539023583964

Epoch: 5| Step: 8
Training loss: 0.9197136386134241
Validation loss: 2.552684596749697

Epoch: 5| Step: 9
Training loss: 0.7465498563670661
Validation loss: 2.533564991821436

Epoch: 5| Step: 10
Training loss: 1.5488658385718161
Validation loss: 2.5045926332619852

Epoch: 304| Step: 0
Training loss: 0.6688432601715177
Validation loss: 2.5150096030781697

Epoch: 5| Step: 1
Training loss: 1.6133801889446207
Validation loss: 2.5207511704052927

Epoch: 5| Step: 2
Training loss: 0.5551905164549722
Validation loss: 2.5045044885202574

Epoch: 5| Step: 3
Training loss: 0.6231401188354472
Validation loss: 2.5426764292087736

Epoch: 5| Step: 4
Training loss: 0.7283820881299826
Validation loss: 2.5408588697888965

Epoch: 5| Step: 5
Training loss: 0.41233074877480685
Validation loss: 2.5361500938705834

Epoch: 5| Step: 6
Training loss: 0.9774269245472498
Validation loss: 2.5761871403366086

Epoch: 5| Step: 7
Training loss: 0.6189004329878969
Validation loss: 2.5801603077453774

Epoch: 5| Step: 8
Training loss: 0.5005830107568742
Validation loss: 2.613164155661932

Epoch: 5| Step: 9
Training loss: 0.9733126160679078
Validation loss: 2.6365368740320503

Epoch: 5| Step: 10
Training loss: 0.8543929560127174
Validation loss: 2.6170086905640195

Epoch: 305| Step: 0
Training loss: 0.740928264288455
Validation loss: 2.6119079341300577

Epoch: 5| Step: 1
Training loss: 1.0638338579952191
Validation loss: 2.608777165432357

Epoch: 5| Step: 2
Training loss: 0.8714920980606289
Validation loss: 2.618489568973886

Epoch: 5| Step: 3
Training loss: 0.8252493755981893
Validation loss: 2.582182530307225

Epoch: 5| Step: 4
Training loss: 0.8035164988378095
Validation loss: 2.568112583375705

Epoch: 5| Step: 5
Training loss: 0.5859824099813805
Validation loss: 2.5051295733027725

Epoch: 5| Step: 6
Training loss: 0.5623448740785498
Validation loss: 2.5084134652183265

Epoch: 5| Step: 7
Training loss: 0.7522472648507493
Validation loss: 2.539891693545625

Epoch: 5| Step: 8
Training loss: 1.4251518637061962
Validation loss: 2.526288158254825

Epoch: 5| Step: 9
Training loss: 0.5917156402933278
Validation loss: 2.5396362655986224

Epoch: 5| Step: 10
Training loss: 0.5582327576574145
Validation loss: 2.5354929918935163

Epoch: 306| Step: 0
Training loss: 0.5852863508372196
Validation loss: 2.552148423276238

Epoch: 5| Step: 1
Training loss: 1.1264137286232825
Validation loss: 2.5745659897003295

Epoch: 5| Step: 2
Training loss: 0.8179503080808534
Validation loss: 2.5881608625261046

Epoch: 5| Step: 3
Training loss: 1.538194673115771
Validation loss: 2.6278438886629747

Epoch: 5| Step: 4
Training loss: 0.8390595079080948
Validation loss: 2.6110298725846985

Epoch: 5| Step: 5
Training loss: 0.4758533141333107
Validation loss: 2.6179915908205507

Epoch: 5| Step: 6
Training loss: 0.42930398645316165
Validation loss: 2.6033647069445083

Epoch: 5| Step: 7
Training loss: 0.4418752929546243
Validation loss: 2.590590497692165

Epoch: 5| Step: 8
Training loss: 0.45025986810595264
Validation loss: 2.5709489865346593

Epoch: 5| Step: 9
Training loss: 0.755581038137251
Validation loss: 2.554576526037961

Epoch: 5| Step: 10
Training loss: 0.9864342962852398
Validation loss: 2.5582315894554064

Epoch: 307| Step: 0
Training loss: 0.6492138087776621
Validation loss: 2.530619176166017

Epoch: 5| Step: 1
Training loss: 0.4260609609188011
Validation loss: 2.5458151804506737

Epoch: 5| Step: 2
Training loss: 0.8512422151811758
Validation loss: 2.5124202537053786

Epoch: 5| Step: 3
Training loss: 0.8268452598776848
Validation loss: 2.5477623162927423

Epoch: 5| Step: 4
Training loss: 0.657134164377288
Validation loss: 2.5671057085159226

Epoch: 5| Step: 5
Training loss: 0.908081735681729
Validation loss: 2.549960820896194

Epoch: 5| Step: 6
Training loss: 0.7739516196766224
Validation loss: 2.555662680198702

Epoch: 5| Step: 7
Training loss: 0.7392936506365319
Validation loss: 2.5897006828057814

Epoch: 5| Step: 8
Training loss: 1.5227880414019757
Validation loss: 2.5959214926576717

Epoch: 5| Step: 9
Training loss: 0.6188340736838153
Validation loss: 2.6087690424363554

Epoch: 5| Step: 10
Training loss: 0.5376444977216156
Validation loss: 2.609191001853305

Epoch: 308| Step: 0
Training loss: 0.48727071334043864
Validation loss: 2.609895511434594

Epoch: 5| Step: 1
Training loss: 0.8669356934217356
Validation loss: 2.589947012468837

Epoch: 5| Step: 2
Training loss: 0.6979394643295956
Validation loss: 2.6001202621759796

Epoch: 5| Step: 3
Training loss: 0.7861668928826838
Validation loss: 2.5909152917718554

Epoch: 5| Step: 4
Training loss: 0.5801371021023546
Validation loss: 2.6111457038123347

Epoch: 5| Step: 5
Training loss: 0.4861406171638886
Validation loss: 2.587018733134714

Epoch: 5| Step: 6
Training loss: 0.99257397070942
Validation loss: 2.545023966401057

Epoch: 5| Step: 7
Training loss: 0.5185296578841204
Validation loss: 2.557716808631021

Epoch: 5| Step: 8
Training loss: 0.7245686563325542
Validation loss: 2.5420871319926572

Epoch: 5| Step: 9
Training loss: 0.6450967100001883
Validation loss: 2.570600496314164

Epoch: 5| Step: 10
Training loss: 1.6635494963721047
Validation loss: 2.575861344087842

Epoch: 309| Step: 0
Training loss: 0.7575752437474214
Validation loss: 2.607122194358266

Epoch: 5| Step: 1
Training loss: 0.7662717462039538
Validation loss: 2.638666274408935

Epoch: 5| Step: 2
Training loss: 0.3708930024707514
Validation loss: 2.603280659890967

Epoch: 5| Step: 3
Training loss: 1.4028051780735644
Validation loss: 2.5827806545146705

Epoch: 5| Step: 4
Training loss: 0.6285015012151107
Validation loss: 2.6156128251865427

Epoch: 5| Step: 5
Training loss: 0.6694913320315011
Validation loss: 2.5756726964181453

Epoch: 5| Step: 6
Training loss: 0.6692282864792706
Validation loss: 2.594820576787476

Epoch: 5| Step: 7
Training loss: 0.744425641442382
Validation loss: 2.628344858535365

Epoch: 5| Step: 8
Training loss: 0.6785997038880233
Validation loss: 2.5975490491509734

Epoch: 5| Step: 9
Training loss: 0.8877045113702764
Validation loss: 2.595013748089217

Epoch: 5| Step: 10
Training loss: 0.9335078116091623
Validation loss: 2.586143597217279

Epoch: 310| Step: 0
Training loss: 0.9531604572642401
Validation loss: 2.5964716521258318

Epoch: 5| Step: 1
Training loss: 0.5518648026972596
Validation loss: 2.6027381027122662

Epoch: 5| Step: 2
Training loss: 0.5203291996289279
Validation loss: 2.573823776317267

Epoch: 5| Step: 3
Training loss: 0.5968276119893603
Validation loss: 2.592000146429072

Epoch: 5| Step: 4
Training loss: 1.6424950250930577
Validation loss: 2.619585340820923

Epoch: 5| Step: 5
Training loss: 0.8030983130032483
Validation loss: 2.6065368632576846

Epoch: 5| Step: 6
Training loss: 0.6921192092446579
Validation loss: 2.5939922422263373

Epoch: 5| Step: 7
Training loss: 0.7528547158128474
Validation loss: 2.5733150037486436

Epoch: 5| Step: 8
Training loss: 0.567160715568896
Validation loss: 2.580100147700784

Epoch: 5| Step: 9
Training loss: 0.6456794222100374
Validation loss: 2.587034170315031

Epoch: 5| Step: 10
Training loss: 0.4375960040343272
Validation loss: 2.580694474017026

Epoch: 311| Step: 0
Training loss: 0.6650930598403755
Validation loss: 2.538825210072257

Epoch: 5| Step: 1
Training loss: 0.8053259677671187
Validation loss: 2.5746570340838346

Epoch: 5| Step: 2
Training loss: 0.8236535471132885
Validation loss: 2.5070757489842794

Epoch: 5| Step: 3
Training loss: 0.8562277296748143
Validation loss: 2.510818558204123

Epoch: 5| Step: 4
Training loss: 1.513523650756785
Validation loss: 2.512484049013045

Epoch: 5| Step: 5
Training loss: 0.6985084719516175
Validation loss: 2.540017204173112

Epoch: 5| Step: 6
Training loss: 0.6487200018207617
Validation loss: 2.535028042289577

Epoch: 5| Step: 7
Training loss: 0.7548148653903497
Validation loss: 2.5427132560966412

Epoch: 5| Step: 8
Training loss: 0.44808601534362813
Validation loss: 2.568378426861589

Epoch: 5| Step: 9
Training loss: 0.6124999056056981
Validation loss: 2.5580696466561004

Epoch: 5| Step: 10
Training loss: 0.7279621711690781
Validation loss: 2.5668908414306406

Epoch: 312| Step: 0
Training loss: 0.6124820969359034
Validation loss: 2.5587312389795125

Epoch: 5| Step: 1
Training loss: 0.7330370544731988
Validation loss: 2.5600804757311675

Epoch: 5| Step: 2
Training loss: 0.5338299319341229
Validation loss: 2.5637389168664475

Epoch: 5| Step: 3
Training loss: 0.7886908760823815
Validation loss: 2.533573295220263

Epoch: 5| Step: 4
Training loss: 0.38835173030520354
Validation loss: 2.5480637988461816

Epoch: 5| Step: 5
Training loss: 0.743022168281868
Validation loss: 2.5461474859938233

Epoch: 5| Step: 6
Training loss: 0.600564103388683
Validation loss: 2.5425551213419784

Epoch: 5| Step: 7
Training loss: 1.5664064783110416
Validation loss: 2.557978299023199

Epoch: 5| Step: 8
Training loss: 0.8435163527635108
Validation loss: 2.5742064327937655

Epoch: 5| Step: 9
Training loss: 0.8214959463482691
Validation loss: 2.593757349669304

Epoch: 5| Step: 10
Training loss: 0.6544982144890218
Validation loss: 2.563424234616969

Epoch: 313| Step: 0
Training loss: 1.0270493234158142
Validation loss: 2.5894390445727167

Epoch: 5| Step: 1
Training loss: 1.4274900464781495
Validation loss: 2.6299048689853

Epoch: 5| Step: 2
Training loss: 0.5888392756538634
Validation loss: 2.6506645211099293

Epoch: 5| Step: 3
Training loss: 0.9570957084279751
Validation loss: 2.6542864361215406

Epoch: 5| Step: 4
Training loss: 0.6225011941216594
Validation loss: 2.650443845055832

Epoch: 5| Step: 5
Training loss: 0.6385878061382418
Validation loss: 2.6402713290982534

Epoch: 5| Step: 6
Training loss: 0.5507811688362224
Validation loss: 2.598227183012215

Epoch: 5| Step: 7
Training loss: 0.8772849493796996
Validation loss: 2.625546025035029

Epoch: 5| Step: 8
Training loss: 0.5259338746878056
Validation loss: 2.591112323968303

Epoch: 5| Step: 9
Training loss: 0.5847463325574667
Validation loss: 2.584439710255868

Epoch: 5| Step: 10
Training loss: 0.5090706424986923
Validation loss: 2.567453311622236

Epoch: 314| Step: 0
Training loss: 0.43508226049851473
Validation loss: 2.5801847054147755

Epoch: 5| Step: 1
Training loss: 0.7770635972231189
Validation loss: 2.5879918177999106

Epoch: 5| Step: 2
Training loss: 0.6374341771794441
Validation loss: 2.573397483170618

Epoch: 5| Step: 3
Training loss: 0.6175920874545228
Validation loss: 2.5631761541728895

Epoch: 5| Step: 4
Training loss: 0.8032312642015956
Validation loss: 2.586638215870246

Epoch: 5| Step: 5
Training loss: 0.9180617914326294
Validation loss: 2.593763448020843

Epoch: 5| Step: 6
Training loss: 0.5465149920641732
Validation loss: 2.6032974068875885

Epoch: 5| Step: 7
Training loss: 0.7944761334022031
Validation loss: 2.5939763782450447

Epoch: 5| Step: 8
Training loss: 0.5206275501623814
Validation loss: 2.6352149632948287

Epoch: 5| Step: 9
Training loss: 0.8105879440014389
Validation loss: 2.6102649943570557

Epoch: 5| Step: 10
Training loss: 1.5310885285857716
Validation loss: 2.5686844979495183

Epoch: 315| Step: 0
Training loss: 0.692633557884827
Validation loss: 2.551137910220754

Epoch: 5| Step: 1
Training loss: 0.6861439683084916
Validation loss: 2.559193079808751

Epoch: 5| Step: 2
Training loss: 0.821264205356874
Validation loss: 2.5515781353756037

Epoch: 5| Step: 3
Training loss: 0.5946692327920147
Validation loss: 2.566023929932752

Epoch: 5| Step: 4
Training loss: 1.511577905210078
Validation loss: 2.556274237398628

Epoch: 5| Step: 5
Training loss: 0.4890657759974144
Validation loss: 2.5902700156762943

Epoch: 5| Step: 6
Training loss: 0.7319177138506265
Validation loss: 2.5847121588756505

Epoch: 5| Step: 7
Training loss: 0.7432685207185515
Validation loss: 2.596060765182449

Epoch: 5| Step: 8
Training loss: 0.5837345928715655
Validation loss: 2.6338508666202443

Epoch: 5| Step: 9
Training loss: 0.6643382229319601
Validation loss: 2.647078629851311

Epoch: 5| Step: 10
Training loss: 0.7662105267611377
Validation loss: 2.6461503734620777

Epoch: 316| Step: 0
Training loss: 0.8985052663705017
Validation loss: 2.635556218083621

Epoch: 5| Step: 1
Training loss: 0.6923417050919651
Validation loss: 2.6449062404906245

Epoch: 5| Step: 2
Training loss: 0.3691138807831653
Validation loss: 2.6163927684067168

Epoch: 5| Step: 3
Training loss: 0.6559939566165234
Validation loss: 2.649419922433613

Epoch: 5| Step: 4
Training loss: 0.5084421216007913
Validation loss: 2.592923300105079

Epoch: 5| Step: 5
Training loss: 0.8426102605146538
Validation loss: 2.5588772905092956

Epoch: 5| Step: 6
Training loss: 0.8616959874042336
Validation loss: 2.5199868453819105

Epoch: 5| Step: 7
Training loss: 1.5621657967781573
Validation loss: 2.566784671834946

Epoch: 5| Step: 8
Training loss: 0.5419703573693485
Validation loss: 2.5511257267738463

Epoch: 5| Step: 9
Training loss: 0.8557754384906182
Validation loss: 2.569944513273451

Epoch: 5| Step: 10
Training loss: 0.28927916062296827
Validation loss: 2.608737100518921

Epoch: 317| Step: 0
Training loss: 0.4345511957314311
Validation loss: 2.6121842508477258

Epoch: 5| Step: 1
Training loss: 0.7181811362055887
Validation loss: 2.6190993604987973

Epoch: 5| Step: 2
Training loss: 0.7374722524045982
Validation loss: 2.600083065204813

Epoch: 5| Step: 3
Training loss: 0.6615883456638233
Validation loss: 2.5698095555761102

Epoch: 5| Step: 4
Training loss: 0.9264712438305014
Validation loss: 2.56889845407107

Epoch: 5| Step: 5
Training loss: 1.4621227169014148
Validation loss: 2.5544438003319323

Epoch: 5| Step: 6
Training loss: 0.7161681200663297
Validation loss: 2.5505686407221395

Epoch: 5| Step: 7
Training loss: 0.549459969304237
Validation loss: 2.554368546260054

Epoch: 5| Step: 8
Training loss: 0.3853973199095429
Validation loss: 2.54475782290296

Epoch: 5| Step: 9
Training loss: 0.8204578452547068
Validation loss: 2.5466971119804787

Epoch: 5| Step: 10
Training loss: 0.8406214816789138
Validation loss: 2.555799993836294

Epoch: 318| Step: 0
Training loss: 0.5052887632967558
Validation loss: 2.5693718614408243

Epoch: 5| Step: 1
Training loss: 0.47751750000247006
Validation loss: 2.565631458752521

Epoch: 5| Step: 2
Training loss: 0.6536215414166207
Validation loss: 2.577486754586558

Epoch: 5| Step: 3
Training loss: 1.5651236822230752
Validation loss: 2.6119725428856424

Epoch: 5| Step: 4
Training loss: 0.6070207209514713
Validation loss: 2.6584123972392946

Epoch: 5| Step: 5
Training loss: 1.0814456939007646
Validation loss: 2.672073731548406

Epoch: 5| Step: 6
Training loss: 0.7829277715120442
Validation loss: 2.6508870476915036

Epoch: 5| Step: 7
Training loss: 0.5529101735845102
Validation loss: 2.635335478787978

Epoch: 5| Step: 8
Training loss: 0.7622255644417616
Validation loss: 2.6185975886243997

Epoch: 5| Step: 9
Training loss: 0.7005035062630011
Validation loss: 2.6038209615967074

Epoch: 5| Step: 10
Training loss: 0.3120111098305935
Validation loss: 2.5860108946112095

Epoch: 319| Step: 0
Training loss: 1.5032512873458996
Validation loss: 2.5777159136656147

Epoch: 5| Step: 1
Training loss: 0.6923435990994787
Validation loss: 2.544974494669443

Epoch: 5| Step: 2
Training loss: 0.6729634583643576
Validation loss: 2.564085316183911

Epoch: 5| Step: 3
Training loss: 0.7780156897553893
Validation loss: 2.5512736707220944

Epoch: 5| Step: 4
Training loss: 0.5017290023188646
Validation loss: 2.5431528085465693

Epoch: 5| Step: 5
Training loss: 0.7167165435763706
Validation loss: 2.5863597983442643

Epoch: 5| Step: 6
Training loss: 0.8521116393470075
Validation loss: 2.5833196080610983

Epoch: 5| Step: 7
Training loss: 0.6500540885062006
Validation loss: 2.5868145955583377

Epoch: 5| Step: 8
Training loss: 0.4172965375159232
Validation loss: 2.5866313078306984

Epoch: 5| Step: 9
Training loss: 0.6731160257320353
Validation loss: 2.5894670357394087

Epoch: 5| Step: 10
Training loss: 0.7346354489403661
Validation loss: 2.5885141134802216

Epoch: 320| Step: 0
Training loss: 0.7479567112381164
Validation loss: 2.6047350972311882

Epoch: 5| Step: 1
Training loss: 0.609668025454131
Validation loss: 2.6047465309266644

Epoch: 5| Step: 2
Training loss: 0.7249560901893554
Validation loss: 2.6451017068914706

Epoch: 5| Step: 3
Training loss: 0.5344141248690837
Validation loss: 2.629061456039154

Epoch: 5| Step: 4
Training loss: 0.7457775624342087
Validation loss: 2.623199313080024

Epoch: 5| Step: 5
Training loss: 0.6341381081689431
Validation loss: 2.6110169204734732

Epoch: 5| Step: 6
Training loss: 1.455288332918082
Validation loss: 2.6211314664681424

Epoch: 5| Step: 7
Training loss: 0.5681468133547137
Validation loss: 2.6094074783922223

Epoch: 5| Step: 8
Training loss: 0.7211078034888209
Validation loss: 2.576503018960293

Epoch: 5| Step: 9
Training loss: 0.7043733746730734
Validation loss: 2.6394348977160598

Epoch: 5| Step: 10
Training loss: 0.7124598207354675
Validation loss: 2.668434538292968

Epoch: 321| Step: 0
Training loss: 0.7316339348906205
Validation loss: 2.6150309489163854

Epoch: 5| Step: 1
Training loss: 0.4497624299991282
Validation loss: 2.648220089994605

Epoch: 5| Step: 2
Training loss: 0.6744336047794915
Validation loss: 2.629663096353015

Epoch: 5| Step: 3
Training loss: 0.37318773256676996
Validation loss: 2.6572658403574665

Epoch: 5| Step: 4
Training loss: 0.755486053615781
Validation loss: 2.685087658532499

Epoch: 5| Step: 5
Training loss: 0.6641323950391878
Validation loss: 2.6780007253541394

Epoch: 5| Step: 6
Training loss: 0.5877592884256275
Validation loss: 2.6603210300847735

Epoch: 5| Step: 7
Training loss: 0.45497559141356114
Validation loss: 2.6614537582292317

Epoch: 5| Step: 8
Training loss: 0.9409776400464481
Validation loss: 2.621179798152107

Epoch: 5| Step: 9
Training loss: 1.5704857270455403
Validation loss: 2.638283052363403

Epoch: 5| Step: 10
Training loss: 0.5489136435784201
Validation loss: 2.625603909616382

Epoch: 322| Step: 0
Training loss: 0.5115250664998582
Validation loss: 2.6026131197507816

Epoch: 5| Step: 1
Training loss: 0.5365483909000522
Validation loss: 2.5798777419797254

Epoch: 5| Step: 2
Training loss: 0.7736548686669481
Validation loss: 2.607117327893098

Epoch: 5| Step: 3
Training loss: 0.6479029922841352
Validation loss: 2.623128091710522

Epoch: 5| Step: 4
Training loss: 0.5301647320739761
Validation loss: 2.582315785060104

Epoch: 5| Step: 5
Training loss: 0.8637628032105304
Validation loss: 2.5958302183410233

Epoch: 5| Step: 6
Training loss: 0.7695656783249678
Validation loss: 2.620781065427503

Epoch: 5| Step: 7
Training loss: 1.4525957681990522
Validation loss: 2.6169191000308447

Epoch: 5| Step: 8
Training loss: 0.662107146942981
Validation loss: 2.6321021589314597

Epoch: 5| Step: 9
Training loss: 0.5991121647425123
Validation loss: 2.627802369132757

Epoch: 5| Step: 10
Training loss: 0.4952542869463206
Validation loss: 2.6338620065087612

Epoch: 323| Step: 0
Training loss: 1.4304492359507486
Validation loss: 2.631728184079904

Epoch: 5| Step: 1
Training loss: 0.6672465340719754
Validation loss: 2.6587490421652538

Epoch: 5| Step: 2
Training loss: 0.44951483878528664
Validation loss: 2.630153857608898

Epoch: 5| Step: 3
Training loss: 0.6070584500968205
Validation loss: 2.6048801854016963

Epoch: 5| Step: 4
Training loss: 0.5867287443201232
Validation loss: 2.600885491053698

Epoch: 5| Step: 5
Training loss: 0.678101717641523
Validation loss: 2.585131457711917

Epoch: 5| Step: 6
Training loss: 0.5938117597483197
Validation loss: 2.5899421671833585

Epoch: 5| Step: 7
Training loss: 0.19633128532905056
Validation loss: 2.6081243087717194

Epoch: 5| Step: 8
Training loss: 0.7527342863137273
Validation loss: 2.566125040940741

Epoch: 5| Step: 9
Training loss: 0.740217545854004
Validation loss: 2.5903357223177172

Epoch: 5| Step: 10
Training loss: 1.0618934583041961
Validation loss: 2.582746432784072

Epoch: 324| Step: 0
Training loss: 0.3926124367973512
Validation loss: 2.6084201965236544

Epoch: 5| Step: 1
Training loss: 0.5331288659781812
Validation loss: 2.6034360662264877

Epoch: 5| Step: 2
Training loss: 0.9190663046240894
Validation loss: 2.6096741277250146

Epoch: 5| Step: 3
Training loss: 0.6682270509880114
Validation loss: 2.6095329277649117

Epoch: 5| Step: 4
Training loss: 0.482243802336819
Validation loss: 2.613967515757167

Epoch: 5| Step: 5
Training loss: 0.521277511657369
Validation loss: 2.611558962686587

Epoch: 5| Step: 6
Training loss: 0.4855197791520712
Validation loss: 2.606217208958592

Epoch: 5| Step: 7
Training loss: 0.7451283865270785
Validation loss: 2.592727265772344

Epoch: 5| Step: 8
Training loss: 0.7104710316668573
Validation loss: 2.5861576171159686

Epoch: 5| Step: 9
Training loss: 0.7293859197588574
Validation loss: 2.5918301631826997

Epoch: 5| Step: 10
Training loss: 1.6004103819745146
Validation loss: 2.6110783416690606

Epoch: 325| Step: 0
Training loss: 0.7044806445355059
Validation loss: 2.607694815262293

Epoch: 5| Step: 1
Training loss: 0.5719247785905723
Validation loss: 2.619088608570563

Epoch: 5| Step: 2
Training loss: 0.5055383967391809
Validation loss: 2.6002616789686046

Epoch: 5| Step: 3
Training loss: 0.6831797408763578
Validation loss: 2.6061026007926684

Epoch: 5| Step: 4
Training loss: 0.6715692889197474
Validation loss: 2.598145535237196

Epoch: 5| Step: 5
Training loss: 0.5881363111375112
Validation loss: 2.582924980918006

Epoch: 5| Step: 6
Training loss: 0.6317178182432298
Validation loss: 2.6040729576396213

Epoch: 5| Step: 7
Training loss: 0.6684017005240166
Validation loss: 2.5832456090232094

Epoch: 5| Step: 8
Training loss: 0.3830509805352324
Validation loss: 2.578820901510733

Epoch: 5| Step: 9
Training loss: 1.5922918193809912
Validation loss: 2.574531668734737

Epoch: 5| Step: 10
Training loss: 0.7343866469088681
Validation loss: 2.569692530504004

Epoch: 326| Step: 0
Training loss: 0.4763438239004629
Validation loss: 2.5772306599520167

Epoch: 5| Step: 1
Training loss: 0.7602401467550024
Validation loss: 2.572913874601022

Epoch: 5| Step: 2
Training loss: 0.8462016198036597
Validation loss: 2.5531083647509507

Epoch: 5| Step: 3
Training loss: 0.4931652711154744
Validation loss: 2.565755484438911

Epoch: 5| Step: 4
Training loss: 0.7946618331982468
Validation loss: 2.5958526110755873

Epoch: 5| Step: 5
Training loss: 0.6894467275176805
Validation loss: 2.633924240096428

Epoch: 5| Step: 6
Training loss: 0.6572574421173627
Validation loss: 2.5993954455757637

Epoch: 5| Step: 7
Training loss: 0.5015920683799496
Validation loss: 2.6140864854993064

Epoch: 5| Step: 8
Training loss: 0.5832185859444886
Validation loss: 2.6220665991312235

Epoch: 5| Step: 9
Training loss: 0.6524952238646178
Validation loss: 2.630340532562352

Epoch: 5| Step: 10
Training loss: 1.5151577258705236
Validation loss: 2.624012085846448

Epoch: 327| Step: 0
Training loss: 0.7100708258588723
Validation loss: 2.6161956543523814

Epoch: 5| Step: 1
Training loss: 0.6740754489070525
Validation loss: 2.604013545959357

Epoch: 5| Step: 2
Training loss: 0.5366781827429501
Validation loss: 2.5990146206135583

Epoch: 5| Step: 3
Training loss: 0.47571911210316536
Validation loss: 2.591483579750691

Epoch: 5| Step: 4
Training loss: 0.866986500583258
Validation loss: 2.588614676801829

Epoch: 5| Step: 5
Training loss: 0.5065778836097682
Validation loss: 2.6217204564353147

Epoch: 5| Step: 6
Training loss: 1.3187672980019245
Validation loss: 2.63429918826879

Epoch: 5| Step: 7
Training loss: 0.6896351257958188
Validation loss: 2.5671296385598628

Epoch: 5| Step: 8
Training loss: 0.5920146629524826
Validation loss: 2.5637800119616228

Epoch: 5| Step: 9
Training loss: 0.7434973952934647
Validation loss: 2.5987125173371273

Epoch: 5| Step: 10
Training loss: 0.6911220936457956
Validation loss: 2.6050717359024267

Epoch: 328| Step: 0
Training loss: 0.7747387199503899
Validation loss: 2.608184940487833

Epoch: 5| Step: 1
Training loss: 0.6454835734238541
Validation loss: 2.580411269307326

Epoch: 5| Step: 2
Training loss: 0.4930964961837034
Validation loss: 2.5906669201739647

Epoch: 5| Step: 3
Training loss: 0.5267532150413045
Validation loss: 2.6112625391543274

Epoch: 5| Step: 4
Training loss: 0.32880274849871766
Validation loss: 2.605048665146048

Epoch: 5| Step: 5
Training loss: 0.7121992128822585
Validation loss: 2.621435962421846

Epoch: 5| Step: 6
Training loss: 0.7167977896952185
Validation loss: 2.630743611703642

Epoch: 5| Step: 7
Training loss: 0.8001610936452351
Validation loss: 2.614219475155687

Epoch: 5| Step: 8
Training loss: 0.5246008854546239
Validation loss: 2.605776625250146

Epoch: 5| Step: 9
Training loss: 0.7269810527210956
Validation loss: 2.5906908497926477

Epoch: 5| Step: 10
Training loss: 1.5498419158060146
Validation loss: 2.584713050050595

Epoch: 329| Step: 0
Training loss: 0.46353011884842565
Validation loss: 2.5262547929014696

Epoch: 5| Step: 1
Training loss: 0.8592734536950957
Validation loss: 2.521826599667508

Epoch: 5| Step: 2
Training loss: 1.0702715121029527
Validation loss: 2.5139890954211257

Epoch: 5| Step: 3
Training loss: 0.45451733003652106
Validation loss: 2.538323177360179

Epoch: 5| Step: 4
Training loss: 0.6036109478678129
Validation loss: 2.5274551386581634

Epoch: 5| Step: 5
Training loss: 0.47264822645707116
Validation loss: 2.5578171635578086

Epoch: 5| Step: 6
Training loss: 0.793300991267291
Validation loss: 2.5820914971015427

Epoch: 5| Step: 7
Training loss: 0.680712289073162
Validation loss: 2.6380042060291036

Epoch: 5| Step: 8
Training loss: 1.3798523161826004
Validation loss: 2.6520692336896294

Epoch: 5| Step: 9
Training loss: 0.5304917646536478
Validation loss: 2.6471393658758284

Epoch: 5| Step: 10
Training loss: 0.610013016460248
Validation loss: 2.6467629274770648

Epoch: 330| Step: 0
Training loss: 0.5187161583949756
Validation loss: 2.6150645942469093

Epoch: 5| Step: 1
Training loss: 0.748829245728165
Validation loss: 2.5850265083469983

Epoch: 5| Step: 2
Training loss: 0.579581873645311
Validation loss: 2.5826211226085634

Epoch: 5| Step: 3
Training loss: 0.546245185036465
Validation loss: 2.54766415946357

Epoch: 5| Step: 4
Training loss: 0.8663434913133177
Validation loss: 2.567710617042116

Epoch: 5| Step: 5
Training loss: 0.5290399188085696
Validation loss: 2.5721212740833117

Epoch: 5| Step: 6
Training loss: 0.6367229391322963
Validation loss: 2.577122716892649

Epoch: 5| Step: 7
Training loss: 0.7491541702393762
Validation loss: 2.6243376189148244

Epoch: 5| Step: 8
Training loss: 0.5504112353503314
Validation loss: 2.655732849467473

Epoch: 5| Step: 9
Training loss: 1.4133665785538176
Validation loss: 2.6371695456646975

Epoch: 5| Step: 10
Training loss: 0.9215873657473165
Validation loss: 2.6798660121756344

Epoch: 331| Step: 0
Training loss: 0.8235409376696227
Validation loss: 2.6511463122307326

Epoch: 5| Step: 1
Training loss: 0.5593865111035036
Validation loss: 2.6325414238156166

Epoch: 5| Step: 2
Training loss: 0.5835822516640177
Validation loss: 2.6053084504209294

Epoch: 5| Step: 3
Training loss: 1.2884649567936468
Validation loss: 2.6068688094628696

Epoch: 5| Step: 4
Training loss: 0.6746337276584751
Validation loss: 2.5722923160629234

Epoch: 5| Step: 5
Training loss: 0.5434892204465022
Validation loss: 2.5234083324267913

Epoch: 5| Step: 6
Training loss: 0.9277308413789612
Validation loss: 2.5538204222271363

Epoch: 5| Step: 7
Training loss: 0.5847461541755966
Validation loss: 2.5574996927456217

Epoch: 5| Step: 8
Training loss: 0.8403693395353348
Validation loss: 2.576027710631175

Epoch: 5| Step: 9
Training loss: 0.3763791789592843
Validation loss: 2.577066778460294

Epoch: 5| Step: 10
Training loss: 0.5823969364263842
Validation loss: 2.6385571996898003

Epoch: 332| Step: 0
Training loss: 0.6143977941202138
Validation loss: 2.6599766570035484

Epoch: 5| Step: 1
Training loss: 0.7697605624042598
Validation loss: 2.6862951841883076

Epoch: 5| Step: 2
Training loss: 0.5409421354433488
Validation loss: 2.6622958776981362

Epoch: 5| Step: 3
Training loss: 0.7003647986191129
Validation loss: 2.6475523432844983

Epoch: 5| Step: 4
Training loss: 0.40406403770655724
Validation loss: 2.6547451999941214

Epoch: 5| Step: 5
Training loss: 1.2907763560956982
Validation loss: 2.6074345849116725

Epoch: 5| Step: 6
Training loss: 0.5512877495917028
Validation loss: 2.59770445000607

Epoch: 5| Step: 7
Training loss: 0.755313409971258
Validation loss: 2.5742524527140564

Epoch: 5| Step: 8
Training loss: 0.6500814120953724
Validation loss: 2.543270417745379

Epoch: 5| Step: 9
Training loss: 0.7697434108683795
Validation loss: 2.5304940676290646

Epoch: 5| Step: 10
Training loss: 0.6960502525294057
Validation loss: 2.4913567921340407

Epoch: 333| Step: 0
Training loss: 0.8102190204901962
Validation loss: 2.519224376643982

Epoch: 5| Step: 1
Training loss: 0.7320368046992553
Validation loss: 2.553138272447055

Epoch: 5| Step: 2
Training loss: 0.5651882888364913
Validation loss: 2.553525886065189

Epoch: 5| Step: 3
Training loss: 0.7245157186436586
Validation loss: 2.554530376454281

Epoch: 5| Step: 4
Training loss: 0.5507916929729462
Validation loss: 2.570397539275195

Epoch: 5| Step: 5
Training loss: 0.5294322723969993
Validation loss: 2.5754840911706687

Epoch: 5| Step: 6
Training loss: 0.6665058289664346
Validation loss: 2.5942438334768716

Epoch: 5| Step: 7
Training loss: 0.5145514901793964
Validation loss: 2.599802425665618

Epoch: 5| Step: 8
Training loss: 1.1116429102664573
Validation loss: 2.5518980928806267

Epoch: 5| Step: 9
Training loss: 0.7793932021033766
Validation loss: 2.5379513544260988

Epoch: 5| Step: 10
Training loss: 0.4679568574187124
Validation loss: 2.512131135450387

Epoch: 334| Step: 0
Training loss: 0.38769857948137443
Validation loss: 2.5382606975742044

Epoch: 5| Step: 1
Training loss: 0.39019265090228616
Validation loss: 2.5207709207506217

Epoch: 5| Step: 2
Training loss: 1.039395615951867
Validation loss: 2.508658867546964

Epoch: 5| Step: 3
Training loss: 0.622173618140713
Validation loss: 2.5382829548234485

Epoch: 5| Step: 4
Training loss: 0.8193976978035956
Validation loss: 2.52871466634291

Epoch: 5| Step: 5
Training loss: 0.8600716974623079
Validation loss: 2.567209276938538

Epoch: 5| Step: 6
Training loss: 0.718505569027613
Validation loss: 2.55415089583015

Epoch: 5| Step: 7
Training loss: 0.4988329798283691
Validation loss: 2.5758429651332464

Epoch: 5| Step: 8
Training loss: 0.7118066777372948
Validation loss: 2.5864996432150047

Epoch: 5| Step: 9
Training loss: 0.5868448733964943
Validation loss: 2.5857148934212812

Epoch: 5| Step: 10
Training loss: 0.44675708161981625
Validation loss: 2.6036639102751775

Epoch: 335| Step: 0
Training loss: 0.22682919918751152
Validation loss: 2.610141082912211

Epoch: 5| Step: 1
Training loss: 0.45236937231256286
Validation loss: 2.641012622654095

Epoch: 5| Step: 2
Training loss: 0.7401521984373579
Validation loss: 2.639391695625667

Epoch: 5| Step: 3
Training loss: 0.7232342856869433
Validation loss: 2.5985349839354224

Epoch: 5| Step: 4
Training loss: 0.7330842138654213
Validation loss: 2.6256035327258114

Epoch: 5| Step: 5
Training loss: 0.6162766120844063
Validation loss: 2.580271877878291

Epoch: 5| Step: 6
Training loss: 0.7086049054833325
Validation loss: 2.5716340978943033

Epoch: 5| Step: 7
Training loss: 0.7219651500343176
Validation loss: 2.601811812991568

Epoch: 5| Step: 8
Training loss: 0.6690783514561985
Validation loss: 2.5728600382733084

Epoch: 5| Step: 9
Training loss: 0.5743115408525419
Validation loss: 2.547985753449623

Epoch: 5| Step: 10
Training loss: 1.0450832349309096
Validation loss: 2.567761463814615

Epoch: 336| Step: 0
Training loss: 0.6372691858605317
Validation loss: 2.5903721071853556

Epoch: 5| Step: 1
Training loss: 0.7158671906279926
Validation loss: 2.607293722356999

Epoch: 5| Step: 2
Training loss: 0.8862522595461515
Validation loss: 2.58097677058249

Epoch: 5| Step: 3
Training loss: 0.6843835028899651
Validation loss: 2.5687997426198206

Epoch: 5| Step: 4
Training loss: 0.4754717962071533
Validation loss: 2.566300787601905

Epoch: 5| Step: 5
Training loss: 0.9349226172957394
Validation loss: 2.5829026835474327

Epoch: 5| Step: 6
Training loss: 0.33914241552154856
Validation loss: 2.555516368707599

Epoch: 5| Step: 7
Training loss: 0.6421258604442318
Validation loss: 2.562069584364287

Epoch: 5| Step: 8
Training loss: 0.8346251409238291
Validation loss: 2.605040942372966

Epoch: 5| Step: 9
Training loss: 0.692299691229419
Validation loss: 2.607366557108848

Epoch: 5| Step: 10
Training loss: 0.40910841291482253
Validation loss: 2.6149096241025465

Epoch: 337| Step: 0
Training loss: 0.6379962812617275
Validation loss: 2.6049696934832722

Epoch: 5| Step: 1
Training loss: 0.6064478187693532
Validation loss: 2.6135331617728745

Epoch: 5| Step: 2
Training loss: 0.7972095011834471
Validation loss: 2.607413122950462

Epoch: 5| Step: 3
Training loss: 0.49701059278716725
Validation loss: 2.6020115157507666

Epoch: 5| Step: 4
Training loss: 0.7952951590515522
Validation loss: 2.6217275761273005

Epoch: 5| Step: 5
Training loss: 0.7702177442106934
Validation loss: 2.598986169040162

Epoch: 5| Step: 6
Training loss: 0.7095527157437793
Validation loss: 2.5939630103929407

Epoch: 5| Step: 7
Training loss: 0.59917449091426
Validation loss: 2.5546166285122016

Epoch: 5| Step: 8
Training loss: 0.7863456864345469
Validation loss: 2.5431043145387253

Epoch: 5| Step: 9
Training loss: 0.5747534409860131
Validation loss: 2.553770190318007

Epoch: 5| Step: 10
Training loss: 0.46239676869947965
Validation loss: 2.589226304589153

Epoch: 338| Step: 0
Training loss: 0.9385622682049738
Validation loss: 2.617454541387683

Epoch: 5| Step: 1
Training loss: 0.5997684777129747
Validation loss: 2.6271078716566345

Epoch: 5| Step: 2
Training loss: 0.8408172288366255
Validation loss: 2.6171251632718535

Epoch: 5| Step: 3
Training loss: 0.4785106425123255
Validation loss: 2.614729917664697

Epoch: 5| Step: 4
Training loss: 0.9061631128160665
Validation loss: 2.5924566795180546

Epoch: 5| Step: 5
Training loss: 0.5253553981387125
Validation loss: 2.5978881169919172

Epoch: 5| Step: 6
Training loss: 0.489836238578383
Validation loss: 2.565865347454497

Epoch: 5| Step: 7
Training loss: 0.48736397606161086
Validation loss: 2.569164772041641

Epoch: 5| Step: 8
Training loss: 0.5589297157930527
Validation loss: 2.550302499856254

Epoch: 5| Step: 9
Training loss: 0.5790552181850374
Validation loss: 2.56547944529335

Epoch: 5| Step: 10
Training loss: 0.4750894543840547
Validation loss: 2.5256604201996797

Epoch: 339| Step: 0
Training loss: 0.6679677238233391
Validation loss: 2.546145173211376

Epoch: 5| Step: 1
Training loss: 0.6028400083823916
Validation loss: 2.5236900653000167

Epoch: 5| Step: 2
Training loss: 0.6180580614755908
Validation loss: 2.4921713189549903

Epoch: 5| Step: 3
Training loss: 0.5207557874807558
Validation loss: 2.5026848440387286

Epoch: 5| Step: 4
Training loss: 0.5243846522773933
Validation loss: 2.5267751971927663

Epoch: 5| Step: 5
Training loss: 0.6907973544787458
Validation loss: 2.5413740330205803

Epoch: 5| Step: 6
Training loss: 0.8517890768735947
Validation loss: 2.537865219856896

Epoch: 5| Step: 7
Training loss: 0.8729164316242299
Validation loss: 2.5444256880072262

Epoch: 5| Step: 8
Training loss: 0.3387473166454496
Validation loss: 2.5329618267661616

Epoch: 5| Step: 9
Training loss: 0.6520606928745217
Validation loss: 2.5277139141848934

Epoch: 5| Step: 10
Training loss: 0.45601666963897775
Validation loss: 2.5145792743312203

Epoch: 340| Step: 0
Training loss: 0.7016960671087819
Validation loss: 2.5434075960689992

Epoch: 5| Step: 1
Training loss: 0.7046732915896495
Validation loss: 2.5647364715411003

Epoch: 5| Step: 2
Training loss: 0.42481735035230683
Validation loss: 2.548263506503456

Epoch: 5| Step: 3
Training loss: 0.6104018533968504
Validation loss: 2.555723111546574

Epoch: 5| Step: 4
Training loss: 1.019932167471735
Validation loss: 2.603301155891773

Epoch: 5| Step: 5
Training loss: 0.5374559983273905
Validation loss: 2.5955862811592687

Epoch: 5| Step: 6
Training loss: 0.47471631576037526
Validation loss: 2.612295610781827

Epoch: 5| Step: 7
Training loss: 0.7160417700789548
Validation loss: 2.576009317437971

Epoch: 5| Step: 8
Training loss: 0.41066252933209835
Validation loss: 2.5752615013235296

Epoch: 5| Step: 9
Training loss: 0.4759778830064216
Validation loss: 2.570189682689631

Epoch: 5| Step: 10
Training loss: 0.46043764910922713
Validation loss: 2.584147284060993

Epoch: 341| Step: 0
Training loss: 0.49440480886261007
Validation loss: 2.586420369839863

Epoch: 5| Step: 1
Training loss: 0.7920453939192801
Validation loss: 2.6052164933839816

Epoch: 5| Step: 2
Training loss: 0.6133439341783065
Validation loss: 2.61995970595379

Epoch: 5| Step: 3
Training loss: 0.6356561839913497
Validation loss: 2.6114884114257477

Epoch: 5| Step: 4
Training loss: 0.5062672800482245
Validation loss: 2.6284250298231138

Epoch: 5| Step: 5
Training loss: 0.6641002644291211
Validation loss: 2.6239961070822955

Epoch: 5| Step: 6
Training loss: 0.8015977743912636
Validation loss: 2.651187680846957

Epoch: 5| Step: 7
Training loss: 0.7595782992903616
Validation loss: 2.6163550884713045

Epoch: 5| Step: 8
Training loss: 0.46628651192194337
Validation loss: 2.576344430231752

Epoch: 5| Step: 9
Training loss: 0.4943605920980466
Validation loss: 2.5697743550379357

Epoch: 5| Step: 10
Training loss: 0.19892105598811463
Validation loss: 2.5702312511622756

Epoch: 342| Step: 0
Training loss: 0.6561431797828035
Validation loss: 2.5624090599252547

Epoch: 5| Step: 1
Training loss: 0.6400047416436856
Validation loss: 2.5916823027764626

Epoch: 5| Step: 2
Training loss: 0.2717075117001578
Validation loss: 2.5246170483751493

Epoch: 5| Step: 3
Training loss: 0.3547335346949438
Validation loss: 2.5138029010228604

Epoch: 5| Step: 4
Training loss: 0.6926870390599565
Validation loss: 2.5501234600944582

Epoch: 5| Step: 5
Training loss: 0.46500070310354913
Validation loss: 2.5651812838154773

Epoch: 5| Step: 6
Training loss: 0.7844050595424283
Validation loss: 2.547978096179033

Epoch: 5| Step: 7
Training loss: 0.6629954347942365
Validation loss: 2.542094523626281

Epoch: 5| Step: 8
Training loss: 0.6447314789453705
Validation loss: 2.5606889765475587

Epoch: 5| Step: 9
Training loss: 0.7346373556103158
Validation loss: 2.572319119467657

Epoch: 5| Step: 10
Training loss: 0.508286123220147
Validation loss: 2.543847583830876

Epoch: 343| Step: 0
Training loss: 0.8051397293560519
Validation loss: 2.5685079941378026

Epoch: 5| Step: 1
Training loss: 0.41157388472976847
Validation loss: 2.562571827952031

Epoch: 5| Step: 2
Training loss: 0.8132949754654271
Validation loss: 2.6042595815182548

Epoch: 5| Step: 3
Training loss: 0.6655686520290269
Validation loss: 2.6085041143428978

Epoch: 5| Step: 4
Training loss: 0.3367280197637747
Validation loss: 2.623537690539949

Epoch: 5| Step: 5
Training loss: 0.7014993736905968
Validation loss: 2.651563127054642

Epoch: 5| Step: 6
Training loss: 0.7517049008165918
Validation loss: 2.6110997175399953

Epoch: 5| Step: 7
Training loss: 0.8365388650159596
Validation loss: 2.648144138650998

Epoch: 5| Step: 8
Training loss: 0.3495634570948435
Validation loss: 2.659789090482587

Epoch: 5| Step: 9
Training loss: 0.44330025165265885
Validation loss: 2.6257108515948904

Epoch: 5| Step: 10
Training loss: 0.28784041206214406
Validation loss: 2.607547272426021

Epoch: 344| Step: 0
Training loss: 0.4483595551063188
Validation loss: 2.590305276171423

Epoch: 5| Step: 1
Training loss: 0.6582386222345735
Validation loss: 2.5300864002844974

Epoch: 5| Step: 2
Training loss: 0.6270171516025523
Validation loss: 2.524672724519572

Epoch: 5| Step: 3
Training loss: 0.597213032255018
Validation loss: 2.5207804022852183

Epoch: 5| Step: 4
Training loss: 0.6226640918577708
Validation loss: 2.4956275029087434

Epoch: 5| Step: 5
Training loss: 0.5831433878183837
Validation loss: 2.531543760725687

Epoch: 5| Step: 6
Training loss: 0.5622962476674005
Validation loss: 2.5046946274520208

Epoch: 5| Step: 7
Training loss: 0.6213908174827129
Validation loss: 2.5493620181989973

Epoch: 5| Step: 8
Training loss: 0.7156510510762809
Validation loss: 2.5599606605424565

Epoch: 5| Step: 9
Training loss: 0.5737870078939856
Validation loss: 2.5780489704335685

Epoch: 5| Step: 10
Training loss: 0.6433501084846802
Validation loss: 2.5564623901346017

Epoch: 345| Step: 0
Training loss: 0.2506922436162892
Validation loss: 2.5454848014780387

Epoch: 5| Step: 1
Training loss: 0.6758419296276116
Validation loss: 2.586655504719347

Epoch: 5| Step: 2
Training loss: 0.6912143246927992
Validation loss: 2.591433142043579

Epoch: 5| Step: 3
Training loss: 0.4753190061085059
Validation loss: 2.5575139939628566

Epoch: 5| Step: 4
Training loss: 0.5347416517792906
Validation loss: 2.5202363162450396

Epoch: 5| Step: 5
Training loss: 0.5932779945684075
Validation loss: 2.5490417101808527

Epoch: 5| Step: 6
Training loss: 0.5721031192581818
Validation loss: 2.5323023895400967

Epoch: 5| Step: 7
Training loss: 0.6671618892212103
Validation loss: 2.503522799698003

Epoch: 5| Step: 8
Training loss: 0.6223064315835631
Validation loss: 2.571293984809937

Epoch: 5| Step: 9
Training loss: 0.5977502636735399
Validation loss: 2.5373523364082478

Epoch: 5| Step: 10
Training loss: 0.6457187002233957
Validation loss: 2.5960889545412047

Epoch: 346| Step: 0
Training loss: 0.6100110866758588
Validation loss: 2.5923864232555838

Epoch: 5| Step: 1
Training loss: 0.38938127886147395
Validation loss: 2.603772076316976

Epoch: 5| Step: 2
Training loss: 0.5804182140998815
Validation loss: 2.595893498995505

Epoch: 5| Step: 3
Training loss: 0.6658384025804085
Validation loss: 2.5952790378218245

Epoch: 5| Step: 4
Training loss: 0.5170219744267901
Validation loss: 2.60915646133122

Epoch: 5| Step: 5
Training loss: 0.5692479636533264
Validation loss: 2.5545288008546807

Epoch: 5| Step: 6
Training loss: 0.3931861458122765
Validation loss: 2.573206576625366

Epoch: 5| Step: 7
Training loss: 0.5707061401955957
Validation loss: 2.553624236215548

Epoch: 5| Step: 8
Training loss: 0.6292944000593281
Validation loss: 2.56005622844399

Epoch: 5| Step: 9
Training loss: 0.8254351927481742
Validation loss: 2.582498618666973

Epoch: 5| Step: 10
Training loss: 0.6151859567148682
Validation loss: 2.591873826691432

Epoch: 347| Step: 0
Training loss: 0.5013940867098522
Validation loss: 2.6139510229742635

Epoch: 5| Step: 1
Training loss: 0.5370418159304512
Validation loss: 2.5991241667186653

Epoch: 5| Step: 2
Training loss: 0.6278650894279028
Validation loss: 2.5985756303645715

Epoch: 5| Step: 3
Training loss: 0.4642228539849436
Validation loss: 2.5899837314203893

Epoch: 5| Step: 4
Training loss: 0.6771907550010032
Validation loss: 2.620648998633881

Epoch: 5| Step: 5
Training loss: 0.7229456141793076
Validation loss: 2.608064151893541

Epoch: 5| Step: 6
Training loss: 0.6673688369640743
Validation loss: 2.5746904871122336

Epoch: 5| Step: 7
Training loss: 0.8327701493422042
Validation loss: 2.631209839845234

Epoch: 5| Step: 8
Training loss: 0.5251832574075801
Validation loss: 2.6025152955092334

Epoch: 5| Step: 9
Training loss: 0.49386471369445945
Validation loss: 2.6005244922671142

Epoch: 5| Step: 10
Training loss: 0.276184345055555
Validation loss: 2.5739385010475124

Epoch: 348| Step: 0
Training loss: 0.6214775003548122
Validation loss: 2.5602425977458187

Epoch: 5| Step: 1
Training loss: 0.5145780743267141
Validation loss: 2.535118211070595

Epoch: 5| Step: 2
Training loss: 0.3811508628274979
Validation loss: 2.5606487318958164

Epoch: 5| Step: 3
Training loss: 0.6193772594822571
Validation loss: 2.51752409157881

Epoch: 5| Step: 4
Training loss: 0.7066071434376313
Validation loss: 2.5445587478616765

Epoch: 5| Step: 5
Training loss: 0.6220181861009628
Validation loss: 2.551857652829377

Epoch: 5| Step: 6
Training loss: 0.46724888133613646
Validation loss: 2.556573097727706

Epoch: 5| Step: 7
Training loss: 0.5498377788335466
Validation loss: 2.5621984190795537

Epoch: 5| Step: 8
Training loss: 0.4775543210452885
Validation loss: 2.6061042258756597

Epoch: 5| Step: 9
Training loss: 0.7090204403113904
Validation loss: 2.608810441346723

Epoch: 5| Step: 10
Training loss: 0.6612667021417798
Validation loss: 2.650883834056655

Epoch: 349| Step: 0
Training loss: 0.6201921312596906
Validation loss: 2.6658316011024468

Epoch: 5| Step: 1
Training loss: 0.4390597468931283
Validation loss: 2.6475964095523694

Epoch: 5| Step: 2
Training loss: 0.4828033329115018
Validation loss: 2.65529949691967

Epoch: 5| Step: 3
Training loss: 0.5881066163176546
Validation loss: 2.629026861611168

Epoch: 5| Step: 4
Training loss: 0.48926873109249597
Validation loss: 2.608818726356448

Epoch: 5| Step: 5
Training loss: 0.736471754075011
Validation loss: 2.5821804960196917

Epoch: 5| Step: 6
Training loss: 0.48535765676682735
Validation loss: 2.5447884140432757

Epoch: 5| Step: 7
Training loss: 0.8495702624909643
Validation loss: 2.5124204955370546

Epoch: 5| Step: 8
Training loss: 0.6551783303657418
Validation loss: 2.4676630637020143

Epoch: 5| Step: 9
Training loss: 0.6100323628220571
Validation loss: 2.50599711734005

Epoch: 5| Step: 10
Training loss: 0.5290865321821465
Validation loss: 2.4864908326624224

Epoch: 350| Step: 0
Training loss: 0.5825050780684841
Validation loss: 2.4799514645829683

Epoch: 5| Step: 1
Training loss: 0.5578846732499072
Validation loss: 2.538519678392549

Epoch: 5| Step: 2
Training loss: 0.44024947173559675
Validation loss: 2.570672535228258

Epoch: 5| Step: 3
Training loss: 0.4886802264017557
Validation loss: 2.5853385126234136

Epoch: 5| Step: 4
Training loss: 0.8769357590347114
Validation loss: 2.589383429633307

Epoch: 5| Step: 5
Training loss: 0.5592115493741435
Validation loss: 2.5962363971024023

Epoch: 5| Step: 6
Training loss: 0.559787142354014
Validation loss: 2.5800418771567935

Epoch: 5| Step: 7
Training loss: 0.5876199092648536
Validation loss: 2.5698937256548655

Epoch: 5| Step: 8
Training loss: 0.460640472141907
Validation loss: 2.53440622987929

Epoch: 5| Step: 9
Training loss: 0.8042707011932501
Validation loss: 2.5664895647675543

Epoch: 5| Step: 10
Training loss: 0.5059787211787721
Validation loss: 2.529724108829939

Testing loss: 2.588048149768762
