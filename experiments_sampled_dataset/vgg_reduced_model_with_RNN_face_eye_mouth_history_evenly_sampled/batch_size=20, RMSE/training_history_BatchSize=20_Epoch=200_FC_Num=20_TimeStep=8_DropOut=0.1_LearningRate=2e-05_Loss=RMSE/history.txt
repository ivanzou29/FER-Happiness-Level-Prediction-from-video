Epoch: 1| Step: 0
Training loss: 5.954253322574925
Validation loss: 5.830979264541564

Epoch: 5| Step: 1
Training loss: 5.538940772694979
Validation loss: 5.81762993969489

Epoch: 5| Step: 2
Training loss: 5.817120100271811
Validation loss: 5.801081462455628

Epoch: 5| Step: 3
Training loss: 5.9058666609436505
Validation loss: 5.783192893839702

Epoch: 5| Step: 4
Training loss: 5.3795538839986285
Validation loss: 5.762809488605085

Epoch: 5| Step: 5
Training loss: 6.609527658273208
Validation loss: 5.740236618763441

Epoch: 5| Step: 6
Training loss: 5.892246336884707
Validation loss: 5.714376973194001

Epoch: 5| Step: 7
Training loss: 5.811529263067363
Validation loss: 5.6844196995514435

Epoch: 5| Step: 8
Training loss: 5.332883617196286
Validation loss: 5.650216702447159

Epoch: 5| Step: 9
Training loss: 6.0234077344027845
Validation loss: 5.61113960132712

Epoch: 5| Step: 10
Training loss: 4.808667725428645
Validation loss: 5.566624751801156

Epoch: 2| Step: 0
Training loss: 6.641197700488418
Validation loss: 5.516655635398277

Epoch: 5| Step: 1
Training loss: 6.1681836642220835
Validation loss: 5.462563772888287

Epoch: 5| Step: 2
Training loss: 5.6398544841959595
Validation loss: 5.404469074549646

Epoch: 5| Step: 3
Training loss: 5.278985435227284
Validation loss: 5.3407024738449325

Epoch: 5| Step: 4
Training loss: 4.064903604600885
Validation loss: 5.274067792396407

Epoch: 5| Step: 5
Training loss: 5.794193768506707
Validation loss: 5.205728109507856

Epoch: 5| Step: 6
Training loss: 5.046889550155593
Validation loss: 5.1349300263856374

Epoch: 5| Step: 7
Training loss: 5.11768246651988
Validation loss: 5.06057381760205

Epoch: 5| Step: 8
Training loss: 4.8917122019392725
Validation loss: 4.988324925861696

Epoch: 5| Step: 9
Training loss: 4.018517547102064
Validation loss: 4.917074378816143

Epoch: 5| Step: 10
Training loss: 4.727424782528315
Validation loss: 4.850750790175913

Epoch: 3| Step: 0
Training loss: 5.1596036235356255
Validation loss: 4.791670555908565

Epoch: 5| Step: 1
Training loss: 4.782965458315527
Validation loss: 4.741274831117502

Epoch: 5| Step: 2
Training loss: 5.059619602183432
Validation loss: 4.696968833012198

Epoch: 5| Step: 3
Training loss: 4.93833472040839
Validation loss: 4.655015762996947

Epoch: 5| Step: 4
Training loss: 4.396320165400161
Validation loss: 4.6153922467711626

Epoch: 5| Step: 5
Training loss: 3.798557866149704
Validation loss: 4.580275279270311

Epoch: 5| Step: 6
Training loss: 4.80996478791543
Validation loss: 4.551160454930267

Epoch: 5| Step: 7
Training loss: 4.994895809335582
Validation loss: 4.529045458658914

Epoch: 5| Step: 8
Training loss: 4.535237419197183
Validation loss: 4.487514763437986

Epoch: 5| Step: 9
Training loss: 4.381898291671066
Validation loss: 4.443328219050643

Epoch: 5| Step: 10
Training loss: 4.575965762737213
Validation loss: 4.420047412626001

Epoch: 4| Step: 0
Training loss: 4.002300792838107
Validation loss: 4.399183847015079

Epoch: 5| Step: 1
Training loss: 4.8452740640355145
Validation loss: 4.360849081356952

Epoch: 5| Step: 2
Training loss: 4.527670873980442
Validation loss: 4.322802917114634

Epoch: 5| Step: 3
Training loss: 4.56443055995706
Validation loss: 4.289995832165128

Epoch: 5| Step: 4
Training loss: 4.096834607656286
Validation loss: 4.259390461017389

Epoch: 5| Step: 5
Training loss: 4.080381507240335
Validation loss: 4.235099816114642

Epoch: 5| Step: 6
Training loss: 4.512678722952898
Validation loss: 4.1985877880321985

Epoch: 5| Step: 7
Training loss: 4.950629053700524
Validation loss: 4.161752988564891

Epoch: 5| Step: 8
Training loss: 4.170445801029104
Validation loss: 4.135843643575279

Epoch: 5| Step: 9
Training loss: 4.222354507604806
Validation loss: 4.112731216842331

Epoch: 5| Step: 10
Training loss: 3.8323689505410736
Validation loss: 4.09462362932644

Epoch: 5| Step: 0
Training loss: 4.441447906164591
Validation loss: 4.08049341323568

Epoch: 5| Step: 1
Training loss: 3.6991080214172944
Validation loss: 4.053170307829114

Epoch: 5| Step: 2
Training loss: 3.633571356813254
Validation loss: 4.035712101841903

Epoch: 5| Step: 3
Training loss: 4.583255327890294
Validation loss: 4.016820269485626

Epoch: 5| Step: 4
Training loss: 3.2711725889207295
Validation loss: 4.008618444052112

Epoch: 5| Step: 5
Training loss: 4.273161661287354
Validation loss: 3.983395416528361

Epoch: 5| Step: 6
Training loss: 4.151169963594648
Validation loss: 3.955154070057311

Epoch: 5| Step: 7
Training loss: 3.7303521742256454
Validation loss: 3.9355613427107565

Epoch: 5| Step: 8
Training loss: 3.9208915054811078
Validation loss: 3.917917820624383

Epoch: 5| Step: 9
Training loss: 4.231197727618633
Validation loss: 3.903111151215812

Epoch: 5| Step: 10
Training loss: 5.320107432263028
Validation loss: 3.8855491025521993

Epoch: 6| Step: 0
Training loss: 3.7561536525867547
Validation loss: 3.8627900256803556

Epoch: 5| Step: 1
Training loss: 3.528912876436246
Validation loss: 3.845626029082362

Epoch: 5| Step: 2
Training loss: 3.7680794089225085
Validation loss: 3.836953770549782

Epoch: 5| Step: 3
Training loss: 3.9232046601340915
Validation loss: 3.8285387228732386

Epoch: 5| Step: 4
Training loss: 4.648689224736228
Validation loss: 3.820701909601502

Epoch: 5| Step: 5
Training loss: 3.3916264474594553
Validation loss: 3.7986763130220162

Epoch: 5| Step: 6
Training loss: 4.029855176344377
Validation loss: 3.781756497397787

Epoch: 5| Step: 7
Training loss: 3.7703879218021563
Validation loss: 3.7660601999310965

Epoch: 5| Step: 8
Training loss: 4.016916030382213
Validation loss: 3.755230111969842

Epoch: 5| Step: 9
Training loss: 4.625042476974493
Validation loss: 3.743640823740398

Epoch: 5| Step: 10
Training loss: 4.057209502119874
Validation loss: 3.7326774897498787

Epoch: 7| Step: 0
Training loss: 3.491532983398226
Validation loss: 3.7240582031149434

Epoch: 5| Step: 1
Training loss: 4.085388963687441
Validation loss: 3.7155640306902913

Epoch: 5| Step: 2
Training loss: 4.130560854683437
Validation loss: 3.6996147826592116

Epoch: 5| Step: 3
Training loss: 3.832803661959847
Validation loss: 3.691304422634241

Epoch: 5| Step: 4
Training loss: 3.640014466267439
Validation loss: 3.6812840681384973

Epoch: 5| Step: 5
Training loss: 3.8886910040024234
Validation loss: 3.6752860251444073

Epoch: 5| Step: 6
Training loss: 3.769452567588795
Validation loss: 3.6581354572698372

Epoch: 5| Step: 7
Training loss: 3.4530664499419705
Validation loss: 3.6469814961911724

Epoch: 5| Step: 8
Training loss: 4.302660123692626
Validation loss: 3.6385605847746403

Epoch: 5| Step: 9
Training loss: 3.9855989857495095
Validation loss: 3.6284913833336496

Epoch: 5| Step: 10
Training loss: 3.817416913340589
Validation loss: 3.6215644471474566

Epoch: 8| Step: 0
Training loss: 3.6383749103019936
Validation loss: 3.616606531446127

Epoch: 5| Step: 1
Training loss: 3.2824056860803625
Validation loss: 3.6119680995886805

Epoch: 5| Step: 2
Training loss: 3.642762305790991
Validation loss: 3.6089508144051483

Epoch: 5| Step: 3
Training loss: 2.9698954731436134
Validation loss: 3.6060545713630088

Epoch: 5| Step: 4
Training loss: 3.887796622486807
Validation loss: 3.593590050945865

Epoch: 5| Step: 5
Training loss: 4.355602751582133
Validation loss: 3.574576518107325

Epoch: 5| Step: 6
Training loss: 4.603210257823813
Validation loss: 3.5660932000707954

Epoch: 5| Step: 7
Training loss: 3.8713535256318767
Validation loss: 3.5606048658283322

Epoch: 5| Step: 8
Training loss: 3.5643196143660423
Validation loss: 3.550352364349245

Epoch: 5| Step: 9
Training loss: 3.739612051482515
Validation loss: 3.543673384141106

Epoch: 5| Step: 10
Training loss: 3.704807720059807
Validation loss: 3.536061634278811

Epoch: 9| Step: 0
Training loss: 3.964545478312662
Validation loss: 3.5291064950636066

Epoch: 5| Step: 1
Training loss: 3.5614783177238616
Validation loss: 3.535904192922491

Epoch: 5| Step: 2
Training loss: 3.417193829565897
Validation loss: 3.5131805358566472

Epoch: 5| Step: 3
Training loss: 3.9658675652426854
Validation loss: 3.5081962885074796

Epoch: 5| Step: 4
Training loss: 3.7089118649112827
Validation loss: 3.5026926678669987

Epoch: 5| Step: 5
Training loss: 3.918807695806706
Validation loss: 3.4968108796834674

Epoch: 5| Step: 6
Training loss: 3.6873611165417715
Validation loss: 3.4895284154639032

Epoch: 5| Step: 7
Training loss: 3.947137814528381
Validation loss: 3.481432266900108

Epoch: 5| Step: 8
Training loss: 4.125851167658137
Validation loss: 3.472678072194201

Epoch: 5| Step: 9
Training loss: 2.820737431603753
Validation loss: 3.4679040517494264

Epoch: 5| Step: 10
Training loss: 3.4542027513362425
Validation loss: 3.465221845311736

Epoch: 10| Step: 0
Training loss: 4.116525672835323
Validation loss: 3.4580832587535286

Epoch: 5| Step: 1
Training loss: 3.846225964530302
Validation loss: 3.450874203468952

Epoch: 5| Step: 2
Training loss: 3.6895359690358194
Validation loss: 3.4403577572936013

Epoch: 5| Step: 3
Training loss: 3.4388448685345185
Validation loss: 3.4422327330278297

Epoch: 5| Step: 4
Training loss: 3.9818281822823263
Validation loss: 3.4404078395946724

Epoch: 5| Step: 5
Training loss: 3.6207945534429578
Validation loss: 3.4297927936334247

Epoch: 5| Step: 6
Training loss: 2.7487046051787307
Validation loss: 3.4160642210320877

Epoch: 5| Step: 7
Training loss: 3.3895837266042927
Validation loss: 3.4122959401543036

Epoch: 5| Step: 8
Training loss: 3.2637802827409796
Validation loss: 3.4207711201028013

Epoch: 5| Step: 9
Training loss: 3.6301934758689116
Validation loss: 3.421760792796979

Epoch: 5| Step: 10
Training loss: 4.329662944898906
Validation loss: 3.4153971370630107

Epoch: 11| Step: 0
Training loss: 3.0478831652879355
Validation loss: 3.386403048991703

Epoch: 5| Step: 1
Training loss: 3.9287473490575913
Validation loss: 3.381774872038498

Epoch: 5| Step: 2
Training loss: 3.605535405329149
Validation loss: 3.3837656760739736

Epoch: 5| Step: 3
Training loss: 3.6818887723070377
Validation loss: 3.3809048457586157

Epoch: 5| Step: 4
Training loss: 3.689687306457499
Validation loss: 3.3723851750330094

Epoch: 5| Step: 5
Training loss: 4.239826592192227
Validation loss: 3.3524899601047884

Epoch: 5| Step: 6
Training loss: 3.4413163241567486
Validation loss: 3.3453380366197876

Epoch: 5| Step: 7
Training loss: 3.2133534941561845
Validation loss: 3.3752482621837316

Epoch: 5| Step: 8
Training loss: 3.567056251948577
Validation loss: 3.3372337291932923

Epoch: 5| Step: 9
Training loss: 3.4561211891383716
Validation loss: 3.3302700985420373

Epoch: 5| Step: 10
Training loss: 3.5168644733451067
Validation loss: 3.3219603630447767

Epoch: 12| Step: 0
Training loss: 4.009958031261124
Validation loss: 3.313288069611234

Epoch: 5| Step: 1
Training loss: 3.99836578364453
Validation loss: 3.3048191514152103

Epoch: 5| Step: 2
Training loss: 3.4738137340429875
Validation loss: 3.2958611389018553

Epoch: 5| Step: 3
Training loss: 3.9556807748807574
Validation loss: 3.289967467646557

Epoch: 5| Step: 4
Training loss: 3.7566416099906426
Validation loss: 3.2896187126645353

Epoch: 5| Step: 5
Training loss: 2.923290868412306
Validation loss: 3.288132178180019

Epoch: 5| Step: 6
Training loss: 3.2304070500267152
Validation loss: 3.275266399130429

Epoch: 5| Step: 7
Training loss: 3.3865962550836035
Validation loss: 3.268977846289789

Epoch: 5| Step: 8
Training loss: 2.668095732273932
Validation loss: 3.2633291775358764

Epoch: 5| Step: 9
Training loss: 3.43866390984395
Validation loss: 3.26132596663262

Epoch: 5| Step: 10
Training loss: 3.7585097080525016
Validation loss: 3.255372991257268

Epoch: 13| Step: 0
Training loss: 3.153739005911432
Validation loss: 3.2527932121532523

Epoch: 5| Step: 1
Training loss: 3.4718686767300793
Validation loss: 3.2509308405680093

Epoch: 5| Step: 2
Training loss: 3.458380243067504
Validation loss: 3.2856275009696962

Epoch: 5| Step: 3
Training loss: 3.6795906977464075
Validation loss: 3.245230687889112

Epoch: 5| Step: 4
Training loss: 3.596531330728962
Validation loss: 3.2354587671021298

Epoch: 5| Step: 5
Training loss: 3.113422002925132
Validation loss: 3.2344363928392728

Epoch: 5| Step: 6
Training loss: 3.6227423115754593
Validation loss: 3.2331335471180935

Epoch: 5| Step: 7
Training loss: 3.569908469813914
Validation loss: 3.23497151204556

Epoch: 5| Step: 8
Training loss: 3.7053539151359853
Validation loss: 3.227236637713677

Epoch: 5| Step: 9
Training loss: 3.7519813389588585
Validation loss: 3.221791815792659

Epoch: 5| Step: 10
Training loss: 3.1219175776880213
Validation loss: 3.2257280749366988

Epoch: 14| Step: 0
Training loss: 2.6845840781238106
Validation loss: 3.233185586533851

Epoch: 5| Step: 1
Training loss: 3.395123709895291
Validation loss: 3.238834853462565

Epoch: 5| Step: 2
Training loss: 3.7033048819459924
Validation loss: 3.2199162680973954

Epoch: 5| Step: 3
Training loss: 4.508055576269591
Validation loss: 3.208316431106219

Epoch: 5| Step: 4
Training loss: 3.710852820785505
Validation loss: 3.2045646099581386

Epoch: 5| Step: 5
Training loss: 3.38146071702904
Validation loss: 3.2055946431765223

Epoch: 5| Step: 6
Training loss: 3.518376879787766
Validation loss: 3.212368862009531

Epoch: 5| Step: 7
Training loss: 2.799703435859925
Validation loss: 3.21211673719432

Epoch: 5| Step: 8
Training loss: 3.152403347581766
Validation loss: 3.2062339663496946

Epoch: 5| Step: 9
Training loss: 3.3936037260395695
Validation loss: 3.193184163108461

Epoch: 5| Step: 10
Training loss: 3.548925538056612
Validation loss: 3.1831176007159367

Epoch: 15| Step: 0
Training loss: 3.218146999133543
Validation loss: 3.178769732654655

Epoch: 5| Step: 1
Training loss: 3.5956126817624527
Validation loss: 3.1824138984361756

Epoch: 5| Step: 2
Training loss: 3.518343539841336
Validation loss: 3.18152733948994

Epoch: 5| Step: 3
Training loss: 3.380214618663303
Validation loss: 3.1722393375234303

Epoch: 5| Step: 4
Training loss: 3.2605481268529704
Validation loss: 3.161462432722979

Epoch: 5| Step: 5
Training loss: 3.7663008847045103
Validation loss: 3.148043306020338

Epoch: 5| Step: 6
Training loss: 3.6434715832036217
Validation loss: 3.132437526972725

Epoch: 5| Step: 7
Training loss: 3.588841942938424
Validation loss: 3.1235265732479083

Epoch: 5| Step: 8
Training loss: 3.166620120325486
Validation loss: 3.1182951274041018

Epoch: 5| Step: 9
Training loss: 3.4889272196365604
Validation loss: 3.140402937709358

Epoch: 5| Step: 10
Training loss: 2.6976495755419894
Validation loss: 3.108656594692772

Epoch: 16| Step: 0
Training loss: 2.508729475894409
Validation loss: 3.1150840340077393

Epoch: 5| Step: 1
Training loss: 4.028965739013855
Validation loss: 3.1167459750146125

Epoch: 5| Step: 2
Training loss: 3.2834269250481802
Validation loss: 3.118317234372658

Epoch: 5| Step: 3
Training loss: 3.2612592362038773
Validation loss: 3.0996480459482814

Epoch: 5| Step: 4
Training loss: 2.9440274053210254
Validation loss: 3.1128647328098262

Epoch: 5| Step: 5
Training loss: 3.4044153714854546
Validation loss: 3.0965397217368773

Epoch: 5| Step: 6
Training loss: 3.6581486393933624
Validation loss: 3.0996386023943896

Epoch: 5| Step: 7
Training loss: 3.487156053215505
Validation loss: 3.0962737359055663

Epoch: 5| Step: 8
Training loss: 3.295954281934304
Validation loss: 3.104238270766968

Epoch: 5| Step: 9
Training loss: 3.3155960872730605
Validation loss: 3.0964453805280447

Epoch: 5| Step: 10
Training loss: 3.740648180030126
Validation loss: 3.083105434441795

Epoch: 17| Step: 0
Training loss: 3.523223667465114
Validation loss: 3.0790893932860874

Epoch: 5| Step: 1
Training loss: 3.677916017362812
Validation loss: 3.07139022955025

Epoch: 5| Step: 2
Training loss: 2.9375715855743048
Validation loss: 3.0705817499402226

Epoch: 5| Step: 3
Training loss: 3.3216733769031457
Validation loss: 3.068724281733413

Epoch: 5| Step: 4
Training loss: 3.581447874131644
Validation loss: 3.066873464214806

Epoch: 5| Step: 5
Training loss: 2.9122727858033257
Validation loss: 3.0654120212977536

Epoch: 5| Step: 6
Training loss: 3.3227940519824046
Validation loss: 3.060892650572143

Epoch: 5| Step: 7
Training loss: 2.916882497885324
Validation loss: 3.0525954226857683

Epoch: 5| Step: 8
Training loss: 3.882972391624258
Validation loss: 3.0518761636997156

Epoch: 5| Step: 9
Training loss: 3.304937979942972
Validation loss: 3.052816771076035

Epoch: 5| Step: 10
Training loss: 3.242541631638699
Validation loss: 3.044176966971666

Epoch: 18| Step: 0
Training loss: 3.411687727730997
Validation loss: 3.039968947020986

Epoch: 5| Step: 1
Training loss: 3.504559136062506
Validation loss: 3.039002785276716

Epoch: 5| Step: 2
Training loss: 3.650433600812099
Validation loss: 3.035807460841654

Epoch: 5| Step: 3
Training loss: 2.6386685318435057
Validation loss: 3.0359174186480615

Epoch: 5| Step: 4
Training loss: 3.512100555405454
Validation loss: 3.03829750466743

Epoch: 5| Step: 5
Training loss: 3.095090633414914
Validation loss: 3.0397812706965994

Epoch: 5| Step: 6
Training loss: 2.718389202162036
Validation loss: 3.0338170377756835

Epoch: 5| Step: 7
Training loss: 3.5791660443543383
Validation loss: 3.0313458526378496

Epoch: 5| Step: 8
Training loss: 2.7114660094176086
Validation loss: 3.029188188386495

Epoch: 5| Step: 9
Training loss: 3.747757050170741
Validation loss: 3.02788939196124

Epoch: 5| Step: 10
Training loss: 3.750069935464407
Validation loss: 3.0261806355663907

Epoch: 19| Step: 0
Training loss: 2.9817048755441493
Validation loss: 3.0228320965035795

Epoch: 5| Step: 1
Training loss: 3.7047234155787527
Validation loss: 3.024151097727802

Epoch: 5| Step: 2
Training loss: 3.3212741311962226
Validation loss: 3.0244818515970833

Epoch: 5| Step: 3
Training loss: 3.2661129527605794
Validation loss: 3.02280988403645

Epoch: 5| Step: 4
Training loss: 3.364634667980256
Validation loss: 3.022567660782234

Epoch: 5| Step: 5
Training loss: 3.201537990522796
Validation loss: 3.0240701561095626

Epoch: 5| Step: 6
Training loss: 3.0994149178920773
Validation loss: 3.015292528967542

Epoch: 5| Step: 7
Training loss: 3.642881291841022
Validation loss: 3.0233874263709692

Epoch: 5| Step: 8
Training loss: 3.3982508816397634
Validation loss: 3.030725551949366

Epoch: 5| Step: 9
Training loss: 3.1743551245163117
Validation loss: 3.022501404681695

Epoch: 5| Step: 10
Training loss: 3.200340735652969
Validation loss: 3.012538344637423

Epoch: 20| Step: 0
Training loss: 3.4979270518370082
Validation loss: 3.0189594288294592

Epoch: 5| Step: 1
Training loss: 3.7373988466385253
Validation loss: 3.0223407083512113

Epoch: 5| Step: 2
Training loss: 2.531218822899481
Validation loss: 2.998633471690165

Epoch: 5| Step: 3
Training loss: 2.825789019020544
Validation loss: 2.996441506394445

Epoch: 5| Step: 4
Training loss: 2.896555657258832
Validation loss: 2.9984329721631573

Epoch: 5| Step: 5
Training loss: 3.301100784274763
Validation loss: 3.0025608180677557

Epoch: 5| Step: 6
Training loss: 3.226673927876943
Validation loss: 3.0135232065203237

Epoch: 5| Step: 7
Training loss: 3.466564968035693
Validation loss: 3.014671460994435

Epoch: 5| Step: 8
Training loss: 3.584258440645141
Validation loss: 3.013988656412653

Epoch: 5| Step: 9
Training loss: 3.7607073191628824
Validation loss: 3.005249061265127

Epoch: 5| Step: 10
Training loss: 3.145561930757284
Validation loss: 2.9940961149712275

Epoch: 21| Step: 0
Training loss: 4.2553744273957825
Validation loss: 2.9896309249866944

Epoch: 5| Step: 1
Training loss: 3.278422417980974
Validation loss: 2.9823321683763453

Epoch: 5| Step: 2
Training loss: 3.3369860821354536
Validation loss: 2.9808546943812764

Epoch: 5| Step: 3
Training loss: 2.995717966319264
Validation loss: 2.978514189334001

Epoch: 5| Step: 4
Training loss: 3.0678828674993914
Validation loss: 2.9770360140512846

Epoch: 5| Step: 5
Training loss: 2.877941119919183
Validation loss: 2.9754012653724753

Epoch: 5| Step: 6
Training loss: 3.9182816415673902
Validation loss: 2.9732511515135123

Epoch: 5| Step: 7
Training loss: 2.42429324597132
Validation loss: 2.972634661278107

Epoch: 5| Step: 8
Training loss: 2.937222569127723
Validation loss: 2.974531310131888

Epoch: 5| Step: 9
Training loss: 3.0895455815758353
Validation loss: 2.977164632656978

Epoch: 5| Step: 10
Training loss: 3.4216977426263897
Validation loss: 2.980374171918971

Epoch: 22| Step: 0
Training loss: 3.0773102122462435
Validation loss: 2.981239943855957

Epoch: 5| Step: 1
Training loss: 2.881781168733631
Validation loss: 2.9914459412280325

Epoch: 5| Step: 2
Training loss: 3.116594224655694
Validation loss: 2.9961575790652324

Epoch: 5| Step: 3
Training loss: 2.81733745359934
Validation loss: 2.9912341259656854

Epoch: 5| Step: 4
Training loss: 2.882476704380097
Validation loss: 2.9673802884464506

Epoch: 5| Step: 5
Training loss: 2.7357033255164382
Validation loss: 2.965092295262415

Epoch: 5| Step: 6
Training loss: 3.7657378247085815
Validation loss: 2.9648084120534803

Epoch: 5| Step: 7
Training loss: 3.1763904920880774
Validation loss: 2.96522664182802

Epoch: 5| Step: 8
Training loss: 3.836010095099729
Validation loss: 2.9624159836017703

Epoch: 5| Step: 9
Training loss: 3.8118728371992603
Validation loss: 2.959242348458626

Epoch: 5| Step: 10
Training loss: 3.5665001078661387
Validation loss: 2.9599745725791173

Epoch: 23| Step: 0
Training loss: 3.210195785208453
Validation loss: 2.9621849184650393

Epoch: 5| Step: 1
Training loss: 3.419581092922672
Validation loss: 2.966491034939579

Epoch: 5| Step: 2
Training loss: 3.4052846398044876
Validation loss: 2.97625593728122

Epoch: 5| Step: 3
Training loss: 2.6669410524665786
Validation loss: 2.9737803148337982

Epoch: 5| Step: 4
Training loss: 3.5608197984915075
Validation loss: 2.97641006237434

Epoch: 5| Step: 5
Training loss: 3.016526161701323
Validation loss: 2.9663142299695613

Epoch: 5| Step: 6
Training loss: 3.183449209477627
Validation loss: 2.9591789256103387

Epoch: 5| Step: 7
Training loss: 3.106680004053042
Validation loss: 2.9576923005722744

Epoch: 5| Step: 8
Training loss: 2.9375490225089953
Validation loss: 2.9562589578866367

Epoch: 5| Step: 9
Training loss: 3.5004740802669994
Validation loss: 2.958287110603785

Epoch: 5| Step: 10
Training loss: 3.6414259655722976
Validation loss: 2.958471364035396

Epoch: 24| Step: 0
Training loss: 3.6852730961176743
Validation loss: 2.9533475544690186

Epoch: 5| Step: 1
Training loss: 3.0497263551119556
Validation loss: 2.9499265355382436

Epoch: 5| Step: 2
Training loss: 3.6756523020521206
Validation loss: 2.947632855993444

Epoch: 5| Step: 3
Training loss: 3.033389879754605
Validation loss: 2.9493015233413

Epoch: 5| Step: 4
Training loss: 3.2215857004989297
Validation loss: 2.9487258169955637

Epoch: 5| Step: 5
Training loss: 3.1776898081443803
Validation loss: 2.9548547708042876

Epoch: 5| Step: 6
Training loss: 2.8337376997873833
Validation loss: 2.951832622361201

Epoch: 5| Step: 7
Training loss: 3.201435667088341
Validation loss: 2.9540175819646617

Epoch: 5| Step: 8
Training loss: 3.2598959575034843
Validation loss: 2.951073275795129

Epoch: 5| Step: 9
Training loss: 3.261417434388835
Validation loss: 2.9472314758720977

Epoch: 5| Step: 10
Training loss: 3.082907432490422
Validation loss: 2.946773673732386

Epoch: 25| Step: 0
Training loss: 3.9140793120428605
Validation loss: 2.9429161829627883

Epoch: 5| Step: 1
Training loss: 3.031831351307892
Validation loss: 2.9416725042434475

Epoch: 5| Step: 2
Training loss: 3.2033081002354704
Validation loss: 2.9408468939625396

Epoch: 5| Step: 3
Training loss: 2.6507442185086036
Validation loss: 2.9390377452313072

Epoch: 5| Step: 4
Training loss: 3.0240583546270963
Validation loss: 2.9348441575991293

Epoch: 5| Step: 5
Training loss: 3.1409914932111493
Validation loss: 2.937190207730098

Epoch: 5| Step: 6
Training loss: 3.2021676470432507
Validation loss: 2.9433960452505303

Epoch: 5| Step: 7
Training loss: 3.5817157435852836
Validation loss: 2.938223832317076

Epoch: 5| Step: 8
Training loss: 3.348662573458811
Validation loss: 2.9371275952643936

Epoch: 5| Step: 9
Training loss: 3.1059572999159806
Validation loss: 2.9338931340863312

Epoch: 5| Step: 10
Training loss: 3.0480870110414964
Validation loss: 2.9344493828014295

Epoch: 26| Step: 0
Training loss: 3.1512092146452817
Validation loss: 2.931426509457373

Epoch: 5| Step: 1
Training loss: 3.4657698192556694
Validation loss: 2.9290569788012606

Epoch: 5| Step: 2
Training loss: 2.807170225971661
Validation loss: 2.9282930796827022

Epoch: 5| Step: 3
Training loss: 2.8951263845524497
Validation loss: 2.9237453494926515

Epoch: 5| Step: 4
Training loss: 3.4335518097730096
Validation loss: 2.9263310238394813

Epoch: 5| Step: 5
Training loss: 3.4887394278464186
Validation loss: 2.9271116938855797

Epoch: 5| Step: 6
Training loss: 3.136172958528541
Validation loss: 2.9262295585998004

Epoch: 5| Step: 7
Training loss: 2.9693365220371226
Validation loss: 2.9289292183444453

Epoch: 5| Step: 8
Training loss: 3.3538510349792734
Validation loss: 2.9302169170508874

Epoch: 5| Step: 9
Training loss: 3.3249023308427503
Validation loss: 2.9367888389845573

Epoch: 5| Step: 10
Training loss: 3.246675551661476
Validation loss: 2.9337702662647938

Epoch: 27| Step: 0
Training loss: 3.037262449669338
Validation loss: 2.9263014479150504

Epoch: 5| Step: 1
Training loss: 2.8741267992902535
Validation loss: 2.9216859844217207

Epoch: 5| Step: 2
Training loss: 3.600467142949778
Validation loss: 2.920119038654607

Epoch: 5| Step: 3
Training loss: 2.9366223261845414
Validation loss: 2.9198603734262782

Epoch: 5| Step: 4
Training loss: 3.0057256419751055
Validation loss: 2.92234450060173

Epoch: 5| Step: 5
Training loss: 2.349855735084179
Validation loss: 2.927080389943966

Epoch: 5| Step: 6
Training loss: 3.5142897040979153
Validation loss: 2.9226651538391626

Epoch: 5| Step: 7
Training loss: 3.2692105262440325
Validation loss: 2.92314454919372

Epoch: 5| Step: 8
Training loss: 3.2661354359602353
Validation loss: 2.9212127543966693

Epoch: 5| Step: 9
Training loss: 3.464257707889932
Validation loss: 2.9147321672826703

Epoch: 5| Step: 10
Training loss: 3.7627826267688484
Validation loss: 2.9153778574610567

Epoch: 28| Step: 0
Training loss: 3.6271821392930415
Validation loss: 2.9193467502847934

Epoch: 5| Step: 1
Training loss: 2.58209570084321
Validation loss: 2.9189566598083885

Epoch: 5| Step: 2
Training loss: 3.4062369810083055
Validation loss: 2.9151766444406144

Epoch: 5| Step: 3
Training loss: 2.3260873159418365
Validation loss: 2.9133530024415064

Epoch: 5| Step: 4
Training loss: 3.508430001806461
Validation loss: 2.911429370048732

Epoch: 5| Step: 5
Training loss: 2.96196879843506
Validation loss: 2.910643995294663

Epoch: 5| Step: 6
Training loss: 3.3821729095039945
Validation loss: 2.909856848281762

Epoch: 5| Step: 7
Training loss: 4.034503422354508
Validation loss: 2.9089631167369046

Epoch: 5| Step: 8
Training loss: 2.9370074569404863
Validation loss: 2.9088159058251355

Epoch: 5| Step: 9
Training loss: 3.116354771339754
Validation loss: 2.9066233867572095

Epoch: 5| Step: 10
Training loss: 2.9729521876037346
Validation loss: 2.9070912269567506

Epoch: 29| Step: 0
Training loss: 3.750189458511589
Validation loss: 2.9138765558102317

Epoch: 5| Step: 1
Training loss: 3.0251849346535793
Validation loss: 2.9230579181555005

Epoch: 5| Step: 2
Training loss: 3.303167764753176
Validation loss: 2.9386454687549723

Epoch: 5| Step: 3
Training loss: 2.598230834743436
Validation loss: 2.9185562004803978

Epoch: 5| Step: 4
Training loss: 2.9956611410500136
Validation loss: 2.903986025761336

Epoch: 5| Step: 5
Training loss: 3.670195759637693
Validation loss: 2.9036529613031963

Epoch: 5| Step: 6
Training loss: 2.7120983265856804
Validation loss: 2.906157233761962

Epoch: 5| Step: 7
Training loss: 3.101300821868096
Validation loss: 2.9099649367950886

Epoch: 5| Step: 8
Training loss: 3.50437952968304
Validation loss: 2.903514423631326

Epoch: 5| Step: 9
Training loss: 3.062259275356487
Validation loss: 2.904148527151028

Epoch: 5| Step: 10
Training loss: 3.4025005738021736
Validation loss: 2.9151347463248496

Epoch: 30| Step: 0
Training loss: 3.2827535908137375
Validation loss: 2.9040465146291665

Epoch: 5| Step: 1
Training loss: 3.7844563910932343
Validation loss: 2.9028026199461916

Epoch: 5| Step: 2
Training loss: 3.060363958816795
Validation loss: 2.9175908208177135

Epoch: 5| Step: 3
Training loss: 3.394133830977419
Validation loss: 2.930156130263891

Epoch: 5| Step: 4
Training loss: 3.33963058416042
Validation loss: 2.917836450130167

Epoch: 5| Step: 5
Training loss: 2.7040604753221067
Validation loss: 2.909017780890719

Epoch: 5| Step: 6
Training loss: 2.915602044672412
Validation loss: 2.9049973387700097

Epoch: 5| Step: 7
Training loss: 3.284370319279639
Validation loss: 2.9026179134137826

Epoch: 5| Step: 8
Training loss: 2.999078927105911
Validation loss: 2.9009515081828057

Epoch: 5| Step: 9
Training loss: 3.324677450267233
Validation loss: 2.9042375371228104

Epoch: 5| Step: 10
Training loss: 2.894593190548463
Validation loss: 2.9004872879090935

Epoch: 31| Step: 0
Training loss: 3.401357654576793
Validation loss: 2.903160528704727

Epoch: 5| Step: 1
Training loss: 2.87862019042885
Validation loss: 2.901965050107733

Epoch: 5| Step: 2
Training loss: 3.5901469869461358
Validation loss: 2.9017635740463

Epoch: 5| Step: 3
Training loss: 3.365908634344286
Validation loss: 2.900749871578138

Epoch: 5| Step: 4
Training loss: 3.3840453828334174
Validation loss: 2.9028211830375477

Epoch: 5| Step: 5
Training loss: 2.149481169620582
Validation loss: 2.899226421903649

Epoch: 5| Step: 6
Training loss: 3.88973290200628
Validation loss: 2.898965622775714

Epoch: 5| Step: 7
Training loss: 2.491446932116307
Validation loss: 2.9000672587543157

Epoch: 5| Step: 8
Training loss: 3.0469189762952196
Validation loss: 2.897133527724934

Epoch: 5| Step: 9
Training loss: 3.0526484637823295
Validation loss: 2.8955366971725156

Epoch: 5| Step: 10
Training loss: 3.4132446426799956
Validation loss: 2.896779842680893

Epoch: 32| Step: 0
Training loss: 3.1971852380414396
Validation loss: 2.8945809222872603

Epoch: 5| Step: 1
Training loss: 3.512703050059243
Validation loss: 2.8939420045419175

Epoch: 5| Step: 2
Training loss: 3.1141651770186916
Validation loss: 2.8937462386860298

Epoch: 5| Step: 3
Training loss: 2.4131618165174404
Validation loss: 2.8928697574245894

Epoch: 5| Step: 4
Training loss: 3.2796180663226178
Validation loss: 2.8917785879147235

Epoch: 5| Step: 5
Training loss: 2.6694153289142153
Validation loss: 2.896610721952417

Epoch: 5| Step: 6
Training loss: 2.385899079918441
Validation loss: 2.904733772842375

Epoch: 5| Step: 7
Training loss: 3.9050040737624174
Validation loss: 2.924581587918668

Epoch: 5| Step: 8
Training loss: 3.391146008942594
Validation loss: 2.8978122675538622

Epoch: 5| Step: 9
Training loss: 3.0618098512856227
Validation loss: 2.894652299244515

Epoch: 5| Step: 10
Training loss: 3.796759709621158
Validation loss: 2.8917778255011535

Epoch: 33| Step: 0
Training loss: 3.7991065229767913
Validation loss: 2.8841631589027688

Epoch: 5| Step: 1
Training loss: 3.4790455384022163
Validation loss: 2.881852453504617

Epoch: 5| Step: 2
Training loss: 2.5572453097759977
Validation loss: 2.8802926389191805

Epoch: 5| Step: 3
Training loss: 3.1329602898724205
Validation loss: 2.8813076636442627

Epoch: 5| Step: 4
Training loss: 3.001935016922451
Validation loss: 2.881888388786909

Epoch: 5| Step: 5
Training loss: 3.5344692173819543
Validation loss: 2.88018866082436

Epoch: 5| Step: 6
Training loss: 2.8864904579257296
Validation loss: 2.876297608422589

Epoch: 5| Step: 7
Training loss: 3.544471766792736
Validation loss: 2.875607701403077

Epoch: 5| Step: 8
Training loss: 2.9200574148098752
Validation loss: 2.877844977150205

Epoch: 5| Step: 9
Training loss: 2.5781099261218894
Validation loss: 2.878722487717367

Epoch: 5| Step: 10
Training loss: 3.227775142651823
Validation loss: 2.873454496663541

Epoch: 34| Step: 0
Training loss: 3.0516146841436185
Validation loss: 2.8800411995125104

Epoch: 5| Step: 1
Training loss: 2.988470014207583
Validation loss: 2.8821807835255777

Epoch: 5| Step: 2
Training loss: 2.876655765246101
Validation loss: 2.879944717373418

Epoch: 5| Step: 3
Training loss: 2.846398597828872
Validation loss: 2.880436165051261

Epoch: 5| Step: 4
Training loss: 3.059086668554446
Validation loss: 2.876859464859081

Epoch: 5| Step: 5
Training loss: 3.3311981197132003
Validation loss: 2.873975597138951

Epoch: 5| Step: 6
Training loss: 2.9765256544020375
Validation loss: 2.870746801476528

Epoch: 5| Step: 7
Training loss: 3.6747991078800983
Validation loss: 2.8711856472679496

Epoch: 5| Step: 8
Training loss: 3.2523371289323517
Validation loss: 2.869151925352093

Epoch: 5| Step: 9
Training loss: 3.4388189386399834
Validation loss: 2.8670077973263504

Epoch: 5| Step: 10
Training loss: 3.241301413178697
Validation loss: 2.865972302924245

Epoch: 35| Step: 0
Training loss: 3.9436881470099405
Validation loss: 2.865961295064115

Epoch: 5| Step: 1
Training loss: 2.778684482943235
Validation loss: 2.864054934336002

Epoch: 5| Step: 2
Training loss: 2.9335368591562507
Validation loss: 2.8660367104923026

Epoch: 5| Step: 3
Training loss: 3.0371875617950335
Validation loss: 2.8621721506166744

Epoch: 5| Step: 4
Training loss: 3.2904054342052977
Validation loss: 2.8640917902016922

Epoch: 5| Step: 5
Training loss: 3.3357019274258923
Validation loss: 2.861723379909686

Epoch: 5| Step: 6
Training loss: 3.1228499073088836
Validation loss: 2.8650872338653963

Epoch: 5| Step: 7
Training loss: 2.970750957557879
Validation loss: 2.86856285115854

Epoch: 5| Step: 8
Training loss: 3.106912989640249
Validation loss: 2.870772793663126

Epoch: 5| Step: 9
Training loss: 2.9956554107109317
Validation loss: 2.873006312209433

Epoch: 5| Step: 10
Training loss: 3.106058623714336
Validation loss: 2.867328279225616

Epoch: 36| Step: 0
Training loss: 2.8912737144226637
Validation loss: 2.8637865985958024

Epoch: 5| Step: 1
Training loss: 3.1447223107716895
Validation loss: 2.8620125077782785

Epoch: 5| Step: 2
Training loss: 2.367434246435125
Validation loss: 2.860417233967234

Epoch: 5| Step: 3
Training loss: 3.1693420820082023
Validation loss: 2.8608735289512786

Epoch: 5| Step: 4
Training loss: 3.708391782035688
Validation loss: 2.8599038050051253

Epoch: 5| Step: 5
Training loss: 3.533992006578888
Validation loss: 2.8562198407100965

Epoch: 5| Step: 6
Training loss: 3.3568035841301764
Validation loss: 2.8532935264242245

Epoch: 5| Step: 7
Training loss: 3.3091364643989296
Validation loss: 2.8536282336812504

Epoch: 5| Step: 8
Training loss: 2.7950612585898758
Validation loss: 2.860213693491541

Epoch: 5| Step: 9
Training loss: 3.056540627108296
Validation loss: 2.863391424355232

Epoch: 5| Step: 10
Training loss: 3.1427859942321863
Validation loss: 2.854526124981729

Epoch: 37| Step: 0
Training loss: 2.783558262703994
Validation loss: 2.8487271063983424

Epoch: 5| Step: 1
Training loss: 3.03754173218744
Validation loss: 2.857787792454892

Epoch: 5| Step: 2
Training loss: 3.384733786546016
Validation loss: 2.8648226861528845

Epoch: 5| Step: 3
Training loss: 3.3653922196187054
Validation loss: 2.8637440354510746

Epoch: 5| Step: 4
Training loss: 3.257007966080722
Validation loss: 2.872779298848846

Epoch: 5| Step: 5
Training loss: 3.329811492716422
Validation loss: 2.873437257896404

Epoch: 5| Step: 6
Training loss: 3.1421407960733765
Validation loss: 2.868419871346333

Epoch: 5| Step: 7
Training loss: 2.7465481334713755
Validation loss: 2.8536533881917685

Epoch: 5| Step: 8
Training loss: 3.448005851829148
Validation loss: 2.8491602433516543

Epoch: 5| Step: 9
Training loss: 3.2370613478491213
Validation loss: 2.8476807352580926

Epoch: 5| Step: 10
Training loss: 2.9049760220665743
Validation loss: 2.850653132555324

Epoch: 38| Step: 0
Training loss: 3.4834885089630534
Validation loss: 2.853229657821557

Epoch: 5| Step: 1
Training loss: 3.559136392233446
Validation loss: 2.8553330604245653

Epoch: 5| Step: 2
Training loss: 3.467356633947183
Validation loss: 2.8751662270035485

Epoch: 5| Step: 3
Training loss: 3.3896778383466355
Validation loss: 2.8734524946093596

Epoch: 5| Step: 4
Training loss: 2.7181313347934526
Validation loss: 2.8882088036853713

Epoch: 5| Step: 5
Training loss: 3.3666055623417095
Validation loss: 2.870132442731474

Epoch: 5| Step: 6
Training loss: 3.0133368948124906
Validation loss: 2.851184539762073

Epoch: 5| Step: 7
Training loss: 3.180678004795586
Validation loss: 2.8450698971750907

Epoch: 5| Step: 8
Training loss: 2.6801427337727324
Validation loss: 2.8395456658468166

Epoch: 5| Step: 9
Training loss: 2.342435544490036
Validation loss: 2.837800260327945

Epoch: 5| Step: 10
Training loss: 3.1167602246227615
Validation loss: 2.842239972424471

Epoch: 39| Step: 0
Training loss: 3.3072211470807695
Validation loss: 2.8480241368712242

Epoch: 5| Step: 1
Training loss: 2.7361247540524847
Validation loss: 2.848897921433902

Epoch: 5| Step: 2
Training loss: 2.830664237692329
Validation loss: 2.8570099254014236

Epoch: 5| Step: 3
Training loss: 3.048613067216953
Validation loss: 2.8446753518872483

Epoch: 5| Step: 4
Training loss: 3.329805048600012
Validation loss: 2.8419141679729147

Epoch: 5| Step: 5
Training loss: 3.505093002500327
Validation loss: 2.8369245279095203

Epoch: 5| Step: 6
Training loss: 2.640253887395071
Validation loss: 2.833192920161272

Epoch: 5| Step: 7
Training loss: 3.545952227370175
Validation loss: 2.8353219176212487

Epoch: 5| Step: 8
Training loss: 2.8217019333262523
Validation loss: 2.8339115062018427

Epoch: 5| Step: 9
Training loss: 2.8541338470873865
Validation loss: 2.8373988015102443

Epoch: 5| Step: 10
Training loss: 3.8954671731867396
Validation loss: 2.8367781704279253

Epoch: 40| Step: 0
Training loss: 2.7171473547858294
Validation loss: 2.84095757505896

Epoch: 5| Step: 1
Training loss: 2.9211643599173547
Validation loss: 2.8373126822972305

Epoch: 5| Step: 2
Training loss: 2.6404733106394427
Validation loss: 2.841030009570436

Epoch: 5| Step: 3
Training loss: 3.7312165634216217
Validation loss: 2.8441357324520347

Epoch: 5| Step: 4
Training loss: 3.2834253275678233
Validation loss: 2.8381452557769844

Epoch: 5| Step: 5
Training loss: 3.0455242586373745
Validation loss: 2.83619749361711

Epoch: 5| Step: 6
Training loss: 2.9001127681511223
Validation loss: 2.8299378118172296

Epoch: 5| Step: 7
Training loss: 3.293518961669859
Validation loss: 2.8285315527387915

Epoch: 5| Step: 8
Training loss: 3.358846223600656
Validation loss: 2.8275623721623053

Epoch: 5| Step: 9
Training loss: 3.2559437320355586
Validation loss: 2.828025022480109

Epoch: 5| Step: 10
Training loss: 3.1315140542414337
Validation loss: 2.8266284232368646

Epoch: 41| Step: 0
Training loss: 2.5662026056000102
Validation loss: 2.8248111189455694

Epoch: 5| Step: 1
Training loss: 2.8689361977249006
Validation loss: 2.8284977692331355

Epoch: 5| Step: 2
Training loss: 3.262201732579236
Validation loss: 2.837422778967234

Epoch: 5| Step: 3
Training loss: 3.196347542334713
Validation loss: 2.8471574694092245

Epoch: 5| Step: 4
Training loss: 3.525772572799814
Validation loss: 2.8429822276340038

Epoch: 5| Step: 5
Training loss: 3.3482873381865033
Validation loss: 2.82662430472574

Epoch: 5| Step: 6
Training loss: 3.299575639662693
Validation loss: 2.8214809358569903

Epoch: 5| Step: 7
Training loss: 2.4012091213482014
Validation loss: 2.816259988662091

Epoch: 5| Step: 8
Training loss: 3.409705412996549
Validation loss: 2.8172359867125456

Epoch: 5| Step: 9
Training loss: 3.3326325315663143
Validation loss: 2.8168679431644406

Epoch: 5| Step: 10
Training loss: 2.9358036743652502
Validation loss: 2.8142865721990917

Epoch: 42| Step: 0
Training loss: 2.7913297098739256
Validation loss: 2.815871095431971

Epoch: 5| Step: 1
Training loss: 2.8303955405588854
Validation loss: 2.813805180446781

Epoch: 5| Step: 2
Training loss: 2.833858179586063
Validation loss: 2.8117391817418755

Epoch: 5| Step: 3
Training loss: 3.020285528213522
Validation loss: 2.8140202013163433

Epoch: 5| Step: 4
Training loss: 3.4888918215205456
Validation loss: 2.8150265801654446

Epoch: 5| Step: 5
Training loss: 3.630888661250569
Validation loss: 2.811647551682796

Epoch: 5| Step: 6
Training loss: 2.9153912253253598
Validation loss: 2.8128590198556918

Epoch: 5| Step: 7
Training loss: 3.067504219730027
Validation loss: 2.81443780844198

Epoch: 5| Step: 8
Training loss: 3.0846173130382817
Validation loss: 2.813107600602657

Epoch: 5| Step: 9
Training loss: 3.4313363041820106
Validation loss: 2.8140360139197744

Epoch: 5| Step: 10
Training loss: 3.066788609471332
Validation loss: 2.8095352297437097

Epoch: 43| Step: 0
Training loss: 3.0541757608636524
Validation loss: 2.810825382587691

Epoch: 5| Step: 1
Training loss: 3.1026351188604395
Validation loss: 2.8159869565190885

Epoch: 5| Step: 2
Training loss: 3.7028664285385258
Validation loss: 2.8179938016479054

Epoch: 5| Step: 3
Training loss: 3.5743192064520226
Validation loss: 2.813244154002722

Epoch: 5| Step: 4
Training loss: 2.683165403604363
Validation loss: 2.819453979386619

Epoch: 5| Step: 5
Training loss: 3.2722337644496156
Validation loss: 2.81721787614596

Epoch: 5| Step: 6
Training loss: 2.9220450448722888
Validation loss: 2.816597560358349

Epoch: 5| Step: 7
Training loss: 3.134125470072665
Validation loss: 2.810561810506184

Epoch: 5| Step: 8
Training loss: 3.0204402448593672
Validation loss: 2.8049273992012

Epoch: 5| Step: 9
Training loss: 2.4023487122027003
Validation loss: 2.8022845662173683

Epoch: 5| Step: 10
Training loss: 3.1801994342764828
Validation loss: 2.8031657401457815

Epoch: 44| Step: 0
Training loss: 3.7646678167059577
Validation loss: 2.8007808646458128

Epoch: 5| Step: 1
Training loss: 2.5287137924370326
Validation loss: 2.80161156147885

Epoch: 5| Step: 2
Training loss: 3.2474340433025866
Validation loss: 2.798891666900909

Epoch: 5| Step: 3
Training loss: 3.082538983546357
Validation loss: 2.80077653512838

Epoch: 5| Step: 4
Training loss: 3.2833575065484575
Validation loss: 2.801028185227415

Epoch: 5| Step: 5
Training loss: 2.7211346746144183
Validation loss: 2.7999825532357936

Epoch: 5| Step: 6
Training loss: 3.6231803273097105
Validation loss: 2.7989003335922367

Epoch: 5| Step: 7
Training loss: 2.665654039839665
Validation loss: 2.796512875694045

Epoch: 5| Step: 8
Training loss: 3.092420195873562
Validation loss: 2.7959635625477124

Epoch: 5| Step: 9
Training loss: 2.963986399733915
Validation loss: 2.8049182329055045

Epoch: 5| Step: 10
Training loss: 2.940399200169913
Validation loss: 2.8039606657158287

Epoch: 45| Step: 0
Training loss: 3.010126665308078
Validation loss: 2.8170396562096314

Epoch: 5| Step: 1
Training loss: 2.8926354917083184
Validation loss: 2.8025018623655202

Epoch: 5| Step: 2
Training loss: 2.985644005804197
Validation loss: 2.7963498831876463

Epoch: 5| Step: 3
Training loss: 3.2898115089012503
Validation loss: 2.8002461607205578

Epoch: 5| Step: 4
Training loss: 3.20966233970178
Validation loss: 2.7931203603523898

Epoch: 5| Step: 5
Training loss: 3.0708650281108127
Validation loss: 2.7945352780557733

Epoch: 5| Step: 6
Training loss: 2.932915376739789
Validation loss: 2.7962864237987612

Epoch: 5| Step: 7
Training loss: 3.496543267190603
Validation loss: 2.7928478574788222

Epoch: 5| Step: 8
Training loss: 3.3065588592316013
Validation loss: 2.7939909337121187

Epoch: 5| Step: 9
Training loss: 3.095132846230583
Validation loss: 2.7937538154838255

Epoch: 5| Step: 10
Training loss: 2.756575612321438
Validation loss: 2.789344818118923

Epoch: 46| Step: 0
Training loss: 3.5568276470855005
Validation loss: 2.790938188817723

Epoch: 5| Step: 1
Training loss: 2.1970648779824336
Validation loss: 2.7883114868580803

Epoch: 5| Step: 2
Training loss: 2.9890008197169426
Validation loss: 2.7906260405129273

Epoch: 5| Step: 3
Training loss: 3.5277502220726307
Validation loss: 2.7869882467111338

Epoch: 5| Step: 4
Training loss: 2.771808242424027
Validation loss: 2.7851515169616476

Epoch: 5| Step: 5
Training loss: 3.2786392724918634
Validation loss: 2.785413151158042

Epoch: 5| Step: 6
Training loss: 2.550379208810747
Validation loss: 2.788516222205249

Epoch: 5| Step: 7
Training loss: 3.4279659877678856
Validation loss: 2.790443649015153

Epoch: 5| Step: 8
Training loss: 3.277049400378635
Validation loss: 2.805199726609813

Epoch: 5| Step: 9
Training loss: 3.1462593211239405
Validation loss: 2.7905933855810665

Epoch: 5| Step: 10
Training loss: 3.0169489825028366
Validation loss: 2.784975980174685

Epoch: 47| Step: 0
Training loss: 3.2208186048505687
Validation loss: 2.784851204788161

Epoch: 5| Step: 1
Training loss: 2.7364643071204653
Validation loss: 2.7809166518959567

Epoch: 5| Step: 2
Training loss: 3.0611477416012844
Validation loss: 2.784207775090697

Epoch: 5| Step: 3
Training loss: 2.8278518460542488
Validation loss: 2.7827458144797763

Epoch: 5| Step: 4
Training loss: 3.3429234989506456
Validation loss: 2.789722039601326

Epoch: 5| Step: 5
Training loss: 3.7421432842915645
Validation loss: 2.7838369765517825

Epoch: 5| Step: 6
Training loss: 2.831065635488921
Validation loss: 2.782755215031104

Epoch: 5| Step: 7
Training loss: 2.8780014293208493
Validation loss: 2.782578582724248

Epoch: 5| Step: 8
Training loss: 3.1842991334152853
Validation loss: 2.7769049015115366

Epoch: 5| Step: 9
Training loss: 2.997508285803713
Validation loss: 2.7839626565581432

Epoch: 5| Step: 10
Training loss: 3.020029123178482
Validation loss: 2.7866059420688734

Epoch: 48| Step: 0
Training loss: 3.1881888150213205
Validation loss: 2.7842139820564324

Epoch: 5| Step: 1
Training loss: 3.0391757816491456
Validation loss: 2.7902516856562456

Epoch: 5| Step: 2
Training loss: 3.37630451563718
Validation loss: 2.793197590105349

Epoch: 5| Step: 3
Training loss: 2.5343926783085076
Validation loss: 2.785518298071829

Epoch: 5| Step: 4
Training loss: 3.7619507144698994
Validation loss: 2.7733158152471087

Epoch: 5| Step: 5
Training loss: 3.4991076558033845
Validation loss: 2.777662608380899

Epoch: 5| Step: 6
Training loss: 2.7347932332212794
Validation loss: 2.776818618753931

Epoch: 5| Step: 7
Training loss: 2.791588416829575
Validation loss: 2.7728050489477836

Epoch: 5| Step: 8
Training loss: 3.3025914391933795
Validation loss: 2.7789362359803413

Epoch: 5| Step: 9
Training loss: 2.619808330950562
Validation loss: 2.7776652295545246

Epoch: 5| Step: 10
Training loss: 2.882795463036124
Validation loss: 2.774607647333633

Epoch: 49| Step: 0
Training loss: 2.769834084895541
Validation loss: 2.7702056768484025

Epoch: 5| Step: 1
Training loss: 3.317928113300054
Validation loss: 2.7694136592304415

Epoch: 5| Step: 2
Training loss: 3.5054608386813166
Validation loss: 2.7702578615417712

Epoch: 5| Step: 3
Training loss: 3.270485505158695
Validation loss: 2.770882784556138

Epoch: 5| Step: 4
Training loss: 2.655043114637176
Validation loss: 2.771463443877357

Epoch: 5| Step: 5
Training loss: 2.8103301260942737
Validation loss: 2.7763153318679494

Epoch: 5| Step: 6
Training loss: 3.39678030715531
Validation loss: 2.772941602100463

Epoch: 5| Step: 7
Training loss: 2.826925455368854
Validation loss: 2.7796409388835257

Epoch: 5| Step: 8
Training loss: 3.1912941883821615
Validation loss: 2.7922984201064165

Epoch: 5| Step: 9
Training loss: 2.582175477309332
Validation loss: 2.79067734177281

Epoch: 5| Step: 10
Training loss: 3.50552477076643
Validation loss: 2.79854574856348

Epoch: 50| Step: 0
Training loss: 3.2235511600723825
Validation loss: 2.7780226772462435

Epoch: 5| Step: 1
Training loss: 2.6435959033832157
Validation loss: 2.7671215628428096

Epoch: 5| Step: 2
Training loss: 2.9881851878963404
Validation loss: 2.763341130420648

Epoch: 5| Step: 3
Training loss: 3.1155150858049026
Validation loss: 2.7665687741147784

Epoch: 5| Step: 4
Training loss: 3.070945771504042
Validation loss: 2.7743568866571273

Epoch: 5| Step: 5
Training loss: 2.9149718310400248
Validation loss: 2.7759115980574323

Epoch: 5| Step: 6
Training loss: 3.2167479575629407
Validation loss: 2.7773945701662557

Epoch: 5| Step: 7
Training loss: 3.1004298373599104
Validation loss: 2.7738330051242586

Epoch: 5| Step: 8
Training loss: 2.852798653831314
Validation loss: 2.7755910893343305

Epoch: 5| Step: 9
Training loss: 3.418567190914045
Validation loss: 2.7746334627984632

Epoch: 5| Step: 10
Training loss: 3.4261706836625736
Validation loss: 2.7714274291742758

Epoch: 51| Step: 0
Training loss: 2.6690667993984114
Validation loss: 2.768051865216798

Epoch: 5| Step: 1
Training loss: 2.672867529267025
Validation loss: 2.7652963394701238

Epoch: 5| Step: 2
Training loss: 2.9639078907316283
Validation loss: 2.7656635049770095

Epoch: 5| Step: 3
Training loss: 3.240388302081496
Validation loss: 2.7645886746400157

Epoch: 5| Step: 4
Training loss: 3.4748572121244523
Validation loss: 2.762594589212423

Epoch: 5| Step: 5
Training loss: 3.1423403482237102
Validation loss: 2.757846346239639

Epoch: 5| Step: 6
Training loss: 2.9088034948422425
Validation loss: 2.756052179496946

Epoch: 5| Step: 7
Training loss: 3.448528838579242
Validation loss: 2.759821334478742

Epoch: 5| Step: 8
Training loss: 3.209891564269752
Validation loss: 2.7604893064006055

Epoch: 5| Step: 9
Training loss: 3.2428211741916395
Validation loss: 2.7711007612694263

Epoch: 5| Step: 10
Training loss: 2.692382901053
Validation loss: 2.7818820728739557

Epoch: 52| Step: 0
Training loss: 2.793884127339266
Validation loss: 2.782955740278962

Epoch: 5| Step: 1
Training loss: 2.930631358375087
Validation loss: 2.787180893813826

Epoch: 5| Step: 2
Training loss: 3.3463332990695824
Validation loss: 2.7937124611299344

Epoch: 5| Step: 3
Training loss: 3.665761590284371
Validation loss: 2.802463889149933

Epoch: 5| Step: 4
Training loss: 2.489198716166645
Validation loss: 2.76393585225641

Epoch: 5| Step: 5
Training loss: 2.9003810895255713
Validation loss: 2.7514038194472668

Epoch: 5| Step: 6
Training loss: 3.250179139115309
Validation loss: 2.7525716654294894

Epoch: 5| Step: 7
Training loss: 3.1272006106680768
Validation loss: 2.7546344349115306

Epoch: 5| Step: 8
Training loss: 3.3815542087747645
Validation loss: 2.754586502477834

Epoch: 5| Step: 9
Training loss: 2.707661256787183
Validation loss: 2.7566395329715547

Epoch: 5| Step: 10
Training loss: 3.104702913872863
Validation loss: 2.7591718477006433

Epoch: 53| Step: 0
Training loss: 3.4783707277426164
Validation loss: 2.759907597791371

Epoch: 5| Step: 1
Training loss: 2.9491084804509606
Validation loss: 2.7573798971320316

Epoch: 5| Step: 2
Training loss: 2.7321147187081367
Validation loss: 2.75809459166748

Epoch: 5| Step: 3
Training loss: 3.0838028490155915
Validation loss: 2.7527235421653335

Epoch: 5| Step: 4
Training loss: 2.9044254277093278
Validation loss: 2.756375539625131

Epoch: 5| Step: 5
Training loss: 3.014237475025345
Validation loss: 2.7565272104985366

Epoch: 5| Step: 6
Training loss: 3.8763539809790397
Validation loss: 2.7593226578379424

Epoch: 5| Step: 7
Training loss: 3.055577453380686
Validation loss: 2.7648497511616816

Epoch: 5| Step: 8
Training loss: 2.811294636454704
Validation loss: 2.7652013375508813

Epoch: 5| Step: 9
Training loss: 3.203405749415104
Validation loss: 2.77800721150748

Epoch: 5| Step: 10
Training loss: 2.329138823077218
Validation loss: 2.8019214492941398

Epoch: 54| Step: 0
Training loss: 3.00688049937546
Validation loss: 2.7757337193487586

Epoch: 5| Step: 1
Training loss: 2.367317825607488
Validation loss: 2.776339898730568

Epoch: 5| Step: 2
Training loss: 2.917050708736704
Validation loss: 2.766784510182718

Epoch: 5| Step: 3
Training loss: 3.383651805477397
Validation loss: 2.760009806842808

Epoch: 5| Step: 4
Training loss: 3.477501491653265
Validation loss: 2.748470096177624

Epoch: 5| Step: 5
Training loss: 3.2123169546263615
Validation loss: 2.740844030985839

Epoch: 5| Step: 6
Training loss: 3.012872892861974
Validation loss: 2.745194865598701

Epoch: 5| Step: 7
Training loss: 2.8504489344325425
Validation loss: 2.74107320951494

Epoch: 5| Step: 8
Training loss: 3.1368625555648566
Validation loss: 2.741389188748837

Epoch: 5| Step: 9
Training loss: 3.1297380768016874
Validation loss: 2.7398696918817858

Epoch: 5| Step: 10
Training loss: 3.044708107423702
Validation loss: 2.741244377092045

Epoch: 55| Step: 0
Training loss: 2.926313486824155
Validation loss: 2.7406297102567874

Epoch: 5| Step: 1
Training loss: 2.3423366099629144
Validation loss: 2.7380930927634823

Epoch: 5| Step: 2
Training loss: 3.0541425057809066
Validation loss: 2.7375115191365778

Epoch: 5| Step: 3
Training loss: 3.2696658600108672
Validation loss: 2.739436501530752

Epoch: 5| Step: 4
Training loss: 2.872446335838236
Validation loss: 2.743043678756083

Epoch: 5| Step: 5
Training loss: 3.6788787925021227
Validation loss: 2.748961721578597

Epoch: 5| Step: 6
Training loss: 2.8489001243172707
Validation loss: 2.7501930195179773

Epoch: 5| Step: 7
Training loss: 2.914066918091071
Validation loss: 2.7485817508383747

Epoch: 5| Step: 8
Training loss: 3.1289793998939874
Validation loss: 2.7447415638567234

Epoch: 5| Step: 9
Training loss: 3.232047455184326
Validation loss: 2.7425770171646673

Epoch: 5| Step: 10
Training loss: 3.2046570626259037
Validation loss: 2.7419717902108838

Epoch: 56| Step: 0
Training loss: 3.1363513013976623
Validation loss: 2.740758769026148

Epoch: 5| Step: 1
Training loss: 2.843754024293169
Validation loss: 2.7350757475621124

Epoch: 5| Step: 2
Training loss: 2.473866050739108
Validation loss: 2.731445671970605

Epoch: 5| Step: 3
Training loss: 3.2309358897907567
Validation loss: 2.7314731473984653

Epoch: 5| Step: 4
Training loss: 2.918852032791497
Validation loss: 2.730092144803538

Epoch: 5| Step: 5
Training loss: 3.5230199731395415
Validation loss: 2.7356901779049227

Epoch: 5| Step: 6
Training loss: 3.059855974086578
Validation loss: 2.743418040654069

Epoch: 5| Step: 7
Training loss: 3.2746830211732183
Validation loss: 2.7375594574243896

Epoch: 5| Step: 8
Training loss: 2.9013933188931778
Validation loss: 2.737611803689888

Epoch: 5| Step: 9
Training loss: 2.8854387927440714
Validation loss: 2.737368655438073

Epoch: 5| Step: 10
Training loss: 3.18285570073199
Validation loss: 2.7306225696214987

Epoch: 57| Step: 0
Training loss: 2.79922131201041
Validation loss: 2.73147246882236

Epoch: 5| Step: 1
Training loss: 3.199251540392092
Validation loss: 2.7296321180478254

Epoch: 5| Step: 2
Training loss: 3.272085707327764
Validation loss: 2.7333827652301834

Epoch: 5| Step: 3
Training loss: 2.876714444019712
Validation loss: 2.7344925862474025

Epoch: 5| Step: 4
Training loss: 2.939399754239319
Validation loss: 2.7381354987404145

Epoch: 5| Step: 5
Training loss: 3.0253884184344764
Validation loss: 2.7450909478350694

Epoch: 5| Step: 6
Training loss: 2.9096156495049716
Validation loss: 2.7518198660841042

Epoch: 5| Step: 7
Training loss: 3.254663056544149
Validation loss: 2.732042985759484

Epoch: 5| Step: 8
Training loss: 3.0095477758704186
Validation loss: 2.7252900506136712

Epoch: 5| Step: 9
Training loss: 3.208368392026177
Validation loss: 2.7248472537653394

Epoch: 5| Step: 10
Training loss: 2.95379275891144
Validation loss: 2.733278219231121

Epoch: 58| Step: 0
Training loss: 3.445090358086188
Validation loss: 2.7325868896921803

Epoch: 5| Step: 1
Training loss: 3.0170166283320885
Validation loss: 2.7315299163095093

Epoch: 5| Step: 2
Training loss: 2.7213977767638085
Validation loss: 2.735613596263186

Epoch: 5| Step: 3
Training loss: 3.0088996804965897
Validation loss: 2.7309344879432262

Epoch: 5| Step: 4
Training loss: 3.027317288190801
Validation loss: 2.741385507952124

Epoch: 5| Step: 5
Training loss: 3.3783325413867815
Validation loss: 2.7516266196896666

Epoch: 5| Step: 6
Training loss: 2.9507730796484717
Validation loss: 2.7750466826626217

Epoch: 5| Step: 7
Training loss: 3.6294692540004885
Validation loss: 2.7740715923078834

Epoch: 5| Step: 8
Training loss: 2.9094442226152535
Validation loss: 2.77254079176014

Epoch: 5| Step: 9
Training loss: 3.015673384994771
Validation loss: 2.773740475906048

Epoch: 5| Step: 10
Training loss: 2.469983239522432
Validation loss: 2.771917414340428

Epoch: 59| Step: 0
Training loss: 3.6122625781118876
Validation loss: 2.7694111709531484

Epoch: 5| Step: 1
Training loss: 2.990456182324991
Validation loss: 2.7684342105016224

Epoch: 5| Step: 2
Training loss: 3.719216966561692
Validation loss: 2.7674112078197366

Epoch: 5| Step: 3
Training loss: 2.6089846381849697
Validation loss: 2.771090333134867

Epoch: 5| Step: 4
Training loss: 3.1360765609737693
Validation loss: 2.7691939453558114

Epoch: 5| Step: 5
Training loss: 3.120142862276993
Validation loss: 2.77667923992697

Epoch: 5| Step: 6
Training loss: 3.087816501719462
Validation loss: 2.7798584178997974

Epoch: 5| Step: 7
Training loss: 2.9600822401220768
Validation loss: 2.7867215019724965

Epoch: 5| Step: 8
Training loss: 2.6344458157579465
Validation loss: 2.779251532831566

Epoch: 5| Step: 9
Training loss: 3.129223372906048
Validation loss: 2.7771945157120306

Epoch: 5| Step: 10
Training loss: 2.599771427230947
Validation loss: 2.7605942975265654

Epoch: 60| Step: 0
Training loss: 3.013597350271431
Validation loss: 2.7590796165924054

Epoch: 5| Step: 1
Training loss: 2.6316435168526304
Validation loss: 2.7507300093149496

Epoch: 5| Step: 2
Training loss: 2.5345312444311676
Validation loss: 2.74672312538953

Epoch: 5| Step: 3
Training loss: 3.4770931224711865
Validation loss: 2.7356361652045122

Epoch: 5| Step: 4
Training loss: 3.1211240000685185
Validation loss: 2.7181563681079

Epoch: 5| Step: 5
Training loss: 3.0645015170553704
Validation loss: 2.7091616806536667

Epoch: 5| Step: 6
Training loss: 3.0860142951777627
Validation loss: 2.7154774897969665

Epoch: 5| Step: 7
Training loss: 3.135208089149437
Validation loss: 2.710034562293005

Epoch: 5| Step: 8
Training loss: 3.3969035578196696
Validation loss: 2.7201506717482498

Epoch: 5| Step: 9
Training loss: 3.0951738260045416
Validation loss: 2.7126344123791952

Epoch: 5| Step: 10
Training loss: 2.8046183883100086
Validation loss: 2.7096253455144503

Epoch: 61| Step: 0
Training loss: 3.0059783495582093
Validation loss: 2.7140450696294387

Epoch: 5| Step: 1
Training loss: 3.0324129056570626
Validation loss: 2.7118841361758173

Epoch: 5| Step: 2
Training loss: 2.594699456041373
Validation loss: 2.7164887843455148

Epoch: 5| Step: 3
Training loss: 3.0159209901695556
Validation loss: 2.7176617179388822

Epoch: 5| Step: 4
Training loss: 3.4622527437030497
Validation loss: 2.727256436725028

Epoch: 5| Step: 5
Training loss: 3.371610422864257
Validation loss: 2.728161238128835

Epoch: 5| Step: 6
Training loss: 2.60035746391232
Validation loss: 2.7252271688301555

Epoch: 5| Step: 7
Training loss: 3.633191554485124
Validation loss: 2.7229964921331944

Epoch: 5| Step: 8
Training loss: 2.941577273155147
Validation loss: 2.711095257037562

Epoch: 5| Step: 9
Training loss: 2.6617081158523264
Validation loss: 2.711563772321248

Epoch: 5| Step: 10
Training loss: 2.8233361771204053
Validation loss: 2.7088207068236487

Epoch: 62| Step: 0
Training loss: 3.1762966662104763
Validation loss: 2.713261702745657

Epoch: 5| Step: 1
Training loss: 2.461725792954956
Validation loss: 2.7172679395275527

Epoch: 5| Step: 2
Training loss: 3.0828147830171635
Validation loss: 2.726883213296273

Epoch: 5| Step: 3
Training loss: 2.8614391110087842
Validation loss: 2.729237011119789

Epoch: 5| Step: 4
Training loss: 2.7342134264484272
Validation loss: 2.725372057394695

Epoch: 5| Step: 5
Training loss: 2.8307509902538657
Validation loss: 2.713968429811582

Epoch: 5| Step: 6
Training loss: 3.4482710887612815
Validation loss: 2.705147858798849

Epoch: 5| Step: 7
Training loss: 3.0227534188047818
Validation loss: 2.7008402359394377

Epoch: 5| Step: 8
Training loss: 2.9665366505053505
Validation loss: 2.699641462977469

Epoch: 5| Step: 9
Training loss: 3.454547157697851
Validation loss: 2.702797041803145

Epoch: 5| Step: 10
Training loss: 3.1458623686875766
Validation loss: 2.701515617265808

Epoch: 63| Step: 0
Training loss: 3.265728962534748
Validation loss: 2.6998341259883882

Epoch: 5| Step: 1
Training loss: 3.1784188553883337
Validation loss: 2.698403745934954

Epoch: 5| Step: 2
Training loss: 3.2607715807581314
Validation loss: 2.7005222376839364

Epoch: 5| Step: 3
Training loss: 2.9604069780535256
Validation loss: 2.6997181638576033

Epoch: 5| Step: 4
Training loss: 2.7592020397478474
Validation loss: 2.7030624628049704

Epoch: 5| Step: 5
Training loss: 2.535100292652133
Validation loss: 2.7042121633351663

Epoch: 5| Step: 6
Training loss: 2.9581327415121605
Validation loss: 2.703422957218942

Epoch: 5| Step: 7
Training loss: 3.395359372878826
Validation loss: 2.695808285863121

Epoch: 5| Step: 8
Training loss: 3.294103098985459
Validation loss: 2.6952661102188222

Epoch: 5| Step: 9
Training loss: 2.644776911855264
Validation loss: 2.697093196704791

Epoch: 5| Step: 10
Training loss: 2.8109089907716034
Validation loss: 2.6931441997152614

Epoch: 64| Step: 0
Training loss: 2.951937805192565
Validation loss: 2.6950344404165643

Epoch: 5| Step: 1
Training loss: 3.259794003115691
Validation loss: 2.6947880621573788

Epoch: 5| Step: 2
Training loss: 2.2639808740111262
Validation loss: 2.6894884939972927

Epoch: 5| Step: 3
Training loss: 3.3758727464059954
Validation loss: 2.693847817557219

Epoch: 5| Step: 4
Training loss: 3.320954240602582
Validation loss: 2.7069058129296297

Epoch: 5| Step: 5
Training loss: 3.2654921217171955
Validation loss: 2.7126570619314863

Epoch: 5| Step: 6
Training loss: 3.271172151612232
Validation loss: 2.7070080457639687

Epoch: 5| Step: 7
Training loss: 2.842207437857415
Validation loss: 2.704525261191778

Epoch: 5| Step: 8
Training loss: 3.1425506609563585
Validation loss: 2.689308189705802

Epoch: 5| Step: 9
Training loss: 2.017851080806997
Validation loss: 2.6857988525788623

Epoch: 5| Step: 10
Training loss: 3.1812008717159084
Validation loss: 2.687515285455152

Epoch: 65| Step: 0
Training loss: 2.7070676242426788
Validation loss: 2.6889146790719236

Epoch: 5| Step: 1
Training loss: 3.47930813499848
Validation loss: 2.6864048404601526

Epoch: 5| Step: 2
Training loss: 2.8717327626467255
Validation loss: 2.6865477643284623

Epoch: 5| Step: 3
Training loss: 2.827593084231516
Validation loss: 2.6844326743445444

Epoch: 5| Step: 4
Training loss: 3.6201613129982078
Validation loss: 2.687129986096152

Epoch: 5| Step: 5
Training loss: 2.9091142875642326
Validation loss: 2.6861728998315573

Epoch: 5| Step: 6
Training loss: 2.6552775678641103
Validation loss: 2.6878606406909853

Epoch: 5| Step: 7
Training loss: 2.895215487720545
Validation loss: 2.6825759289451803

Epoch: 5| Step: 8
Training loss: 3.01169721741654
Validation loss: 2.6799996816432605

Epoch: 5| Step: 9
Training loss: 3.2806656089997546
Validation loss: 2.683005188324436

Epoch: 5| Step: 10
Training loss: 2.7129370271409585
Validation loss: 2.6796453678269363

Epoch: 66| Step: 0
Training loss: 3.5432812469855195
Validation loss: 2.6838183376729434

Epoch: 5| Step: 1
Training loss: 2.9003135182827213
Validation loss: 2.686156532094822

Epoch: 5| Step: 2
Training loss: 3.2298602600103825
Validation loss: 2.693788670929255

Epoch: 5| Step: 3
Training loss: 2.9392102721004165
Validation loss: 2.6864403240249426

Epoch: 5| Step: 4
Training loss: 3.1762498272952437
Validation loss: 2.6950361069989786

Epoch: 5| Step: 5
Training loss: 3.1488329163431943
Validation loss: 2.691580680856181

Epoch: 5| Step: 6
Training loss: 2.909860972331135
Validation loss: 2.688601047697807

Epoch: 5| Step: 7
Training loss: 2.6496108615111282
Validation loss: 2.6785241851703114

Epoch: 5| Step: 8
Training loss: 2.3827420583850185
Validation loss: 2.6764836163700916

Epoch: 5| Step: 9
Training loss: 2.9921540340613824
Validation loss: 2.6766521380636576

Epoch: 5| Step: 10
Training loss: 3.090287862658862
Validation loss: 2.6777840478496593

Epoch: 67| Step: 0
Training loss: 3.5437220873397797
Validation loss: 2.6860623531583214

Epoch: 5| Step: 1
Training loss: 2.5602680813970644
Validation loss: 2.6836631813566174

Epoch: 5| Step: 2
Training loss: 2.760084648078186
Validation loss: 2.6909946843926713

Epoch: 5| Step: 3
Training loss: 3.183740680322984
Validation loss: 2.691824349827803

Epoch: 5| Step: 4
Training loss: 3.417175270620335
Validation loss: 2.7003398068058053

Epoch: 5| Step: 5
Training loss: 2.9906889746190117
Validation loss: 2.704861914345566

Epoch: 5| Step: 6
Training loss: 2.693757158522155
Validation loss: 2.6877831483736943

Epoch: 5| Step: 7
Training loss: 3.1171305945228776
Validation loss: 2.6773876858133225

Epoch: 5| Step: 8
Training loss: 3.3066782625312934
Validation loss: 2.6730370385237845

Epoch: 5| Step: 9
Training loss: 2.567171908683587
Validation loss: 2.67774669181575

Epoch: 5| Step: 10
Training loss: 2.762405590670817
Validation loss: 2.6784906421047765

Epoch: 68| Step: 0
Training loss: 3.015912452398482
Validation loss: 2.6778222975370722

Epoch: 5| Step: 1
Training loss: 3.184765858570073
Validation loss: 2.675976122346986

Epoch: 5| Step: 2
Training loss: 2.8377269637297227
Validation loss: 2.679361492469212

Epoch: 5| Step: 3
Training loss: 2.857558210018655
Validation loss: 2.677867655924404

Epoch: 5| Step: 4
Training loss: 2.967198980629613
Validation loss: 2.6719457605818753

Epoch: 5| Step: 5
Training loss: 3.2509814027731316
Validation loss: 2.676503443565846

Epoch: 5| Step: 6
Training loss: 2.8326871546489705
Validation loss: 2.6783193932603067

Epoch: 5| Step: 7
Training loss: 3.0172470553114548
Validation loss: 2.686915260341169

Epoch: 5| Step: 8
Training loss: 2.9572561926806324
Validation loss: 2.6958714924872105

Epoch: 5| Step: 9
Training loss: 3.2068358720746537
Validation loss: 2.7186854827131874

Epoch: 5| Step: 10
Training loss: 2.826774907183982
Validation loss: 2.7220285478040203

Epoch: 69| Step: 0
Training loss: 2.822851670609041
Validation loss: 2.7346826823819783

Epoch: 5| Step: 1
Training loss: 3.038561154471855
Validation loss: 2.720449056990628

Epoch: 5| Step: 2
Training loss: 3.209429235845131
Validation loss: 2.7058654750505915

Epoch: 5| Step: 3
Training loss: 3.3772177297468122
Validation loss: 2.701509697622885

Epoch: 5| Step: 4
Training loss: 2.868425730743351
Validation loss: 2.6881064159832224

Epoch: 5| Step: 5
Training loss: 2.953619214236581
Validation loss: 2.689163479210916

Epoch: 5| Step: 6
Training loss: 3.0957172959060513
Validation loss: 2.6880224158473194

Epoch: 5| Step: 7
Training loss: 2.904025959855162
Validation loss: 2.686482914562764

Epoch: 5| Step: 8
Training loss: 2.973544455532542
Validation loss: 2.6821832839059025

Epoch: 5| Step: 9
Training loss: 2.70816936485633
Validation loss: 2.6651123507192627

Epoch: 5| Step: 10
Training loss: 3.0372754802848636
Validation loss: 2.6715621222939077

Epoch: 70| Step: 0
Training loss: 2.3308648494389583
Validation loss: 2.6660786032868016

Epoch: 5| Step: 1
Training loss: 3.1319974757119793
Validation loss: 2.662888360045513

Epoch: 5| Step: 2
Training loss: 2.6017543046141713
Validation loss: 2.6602402270667245

Epoch: 5| Step: 3
Training loss: 3.487665923078559
Validation loss: 2.6642989817290186

Epoch: 5| Step: 4
Training loss: 3.45213020460178
Validation loss: 2.662911518398021

Epoch: 5| Step: 5
Training loss: 3.314480459429861
Validation loss: 2.6584330178605198

Epoch: 5| Step: 6
Training loss: 2.7217136760077243
Validation loss: 2.6627796945727265

Epoch: 5| Step: 7
Training loss: 2.764744591531483
Validation loss: 2.665885192308008

Epoch: 5| Step: 8
Training loss: 3.0339926670315265
Validation loss: 2.6747966519243658

Epoch: 5| Step: 9
Training loss: 2.963987204118668
Validation loss: 2.70414876012503

Epoch: 5| Step: 10
Training loss: 2.9436441649507556
Validation loss: 2.715268278242146

Epoch: 71| Step: 0
Training loss: 3.117397062289263
Validation loss: 2.6761165482171654

Epoch: 5| Step: 1
Training loss: 3.1156497690331575
Validation loss: 2.656458810395967

Epoch: 5| Step: 2
Training loss: 3.5317840172385098
Validation loss: 2.6535988787352243

Epoch: 5| Step: 3
Training loss: 3.0139539763360967
Validation loss: 2.654147056547971

Epoch: 5| Step: 4
Training loss: 2.8655758519674377
Validation loss: 2.649611897760875

Epoch: 5| Step: 5
Training loss: 3.1292959058734144
Validation loss: 2.649437231223927

Epoch: 5| Step: 6
Training loss: 2.8983476732837783
Validation loss: 2.6495425581165857

Epoch: 5| Step: 7
Training loss: 3.5593930800785043
Validation loss: 2.6570562144123104

Epoch: 5| Step: 8
Training loss: 2.381834235822219
Validation loss: 2.6500545463977128

Epoch: 5| Step: 9
Training loss: 2.067856739269098
Validation loss: 2.6548867324235497

Epoch: 5| Step: 10
Training loss: 2.9281905355213644
Validation loss: 2.658536562630107

Epoch: 72| Step: 0
Training loss: 2.6468647025492396
Validation loss: 2.6592330252116296

Epoch: 5| Step: 1
Training loss: 3.4261027656102874
Validation loss: 2.67089934743011

Epoch: 5| Step: 2
Training loss: 2.944381445284716
Validation loss: 2.6639397070534594

Epoch: 5| Step: 3
Training loss: 2.0417792101092793
Validation loss: 2.6494855903474677

Epoch: 5| Step: 4
Training loss: 3.126069305579083
Validation loss: 2.638301097890163

Epoch: 5| Step: 5
Training loss: 3.0547800659827997
Validation loss: 2.6422263911664583

Epoch: 5| Step: 6
Training loss: 3.2930876324644522
Validation loss: 2.646387406685558

Epoch: 5| Step: 7
Training loss: 3.269467516133215
Validation loss: 2.657844726828569

Epoch: 5| Step: 8
Training loss: 3.2760531006306746
Validation loss: 2.6673416897151876

Epoch: 5| Step: 9
Training loss: 2.525862623863164
Validation loss: 2.68525125335588

Epoch: 5| Step: 10
Training loss: 2.9979738704975456
Validation loss: 2.68643913307192

Epoch: 73| Step: 0
Training loss: 2.8071452558528702
Validation loss: 2.7022819980418444

Epoch: 5| Step: 1
Training loss: 2.421535049698378
Validation loss: 2.7100463255385954

Epoch: 5| Step: 2
Training loss: 3.3016698600475025
Validation loss: 2.697222797448555

Epoch: 5| Step: 3
Training loss: 3.0564081755663697
Validation loss: 2.667301139672056

Epoch: 5| Step: 4
Training loss: 3.2535291730324087
Validation loss: 2.65455656848667

Epoch: 5| Step: 5
Training loss: 2.8222998382712126
Validation loss: 2.6402019820379583

Epoch: 5| Step: 6
Training loss: 2.800208039729438
Validation loss: 2.642593835215964

Epoch: 5| Step: 7
Training loss: 3.1948758225643834
Validation loss: 2.637775928515684

Epoch: 5| Step: 8
Training loss: 2.939653459483452
Validation loss: 2.6389660241281705

Epoch: 5| Step: 9
Training loss: 3.5226970156715423
Validation loss: 2.640712004828475

Epoch: 5| Step: 10
Training loss: 2.372776596941166
Validation loss: 2.633819756443525

Epoch: 74| Step: 0
Training loss: 2.9792500375317297
Validation loss: 2.632821580962406

Epoch: 5| Step: 1
Training loss: 3.571756083594024
Validation loss: 2.632449081946406

Epoch: 5| Step: 2
Training loss: 2.721718493931946
Validation loss: 2.6350922367614817

Epoch: 5| Step: 3
Training loss: 3.347030883920111
Validation loss: 2.636886893455829

Epoch: 5| Step: 4
Training loss: 2.0512787714956424
Validation loss: 2.6310611582944157

Epoch: 5| Step: 5
Training loss: 2.722977344291207
Validation loss: 2.633249169639326

Epoch: 5| Step: 6
Training loss: 3.219604823107951
Validation loss: 2.6313909889457894

Epoch: 5| Step: 7
Training loss: 2.5847954662872383
Validation loss: 2.647725453295985

Epoch: 5| Step: 8
Training loss: 3.586834564698941
Validation loss: 2.640785543948767

Epoch: 5| Step: 9
Training loss: 2.318250979787487
Validation loss: 2.6579692934503094

Epoch: 5| Step: 10
Training loss: 3.2512961517308394
Validation loss: 2.6521945307115025

Epoch: 75| Step: 0
Training loss: 2.878085098238521
Validation loss: 2.659745905747412

Epoch: 5| Step: 1
Training loss: 2.0228597044332015
Validation loss: 2.690607398358608

Epoch: 5| Step: 2
Training loss: 2.4426358231855754
Validation loss: 2.704271457391849

Epoch: 5| Step: 3
Training loss: 3.1165876456730075
Validation loss: 2.6973023694981952

Epoch: 5| Step: 4
Training loss: 3.5895565611286853
Validation loss: 2.6792030055533753

Epoch: 5| Step: 5
Training loss: 3.4257342031939104
Validation loss: 2.6286809352024694

Epoch: 5| Step: 6
Training loss: 3.1699253347851575
Validation loss: 2.619373313001725

Epoch: 5| Step: 7
Training loss: 2.9338603095440603
Validation loss: 2.6276903375644434

Epoch: 5| Step: 8
Training loss: 3.0249839593131007
Validation loss: 2.644746104681754

Epoch: 5| Step: 9
Training loss: 3.056083652829356
Validation loss: 2.644403330069188

Epoch: 5| Step: 10
Training loss: 2.8024398595803874
Validation loss: 2.622851577122278

Epoch: 76| Step: 0
Training loss: 3.3168277899424874
Validation loss: 2.6255033257581797

Epoch: 5| Step: 1
Training loss: 3.0821571856201815
Validation loss: 2.6282667916909577

Epoch: 5| Step: 2
Training loss: 2.7612150561158044
Validation loss: 2.629138455943993

Epoch: 5| Step: 3
Training loss: 2.759024637342496
Validation loss: 2.6312090009554936

Epoch: 5| Step: 4
Training loss: 2.6402571382428794
Validation loss: 2.6576676428775463

Epoch: 5| Step: 5
Training loss: 2.824707157857063
Validation loss: 2.702319506324268

Epoch: 5| Step: 6
Training loss: 3.364741239985706
Validation loss: 2.691809338366758

Epoch: 5| Step: 7
Training loss: 3.2896206126276044
Validation loss: 2.6415727291664486

Epoch: 5| Step: 8
Training loss: 2.7860451840627354
Validation loss: 2.6218054094003502

Epoch: 5| Step: 9
Training loss: 2.9215508755509663
Validation loss: 2.639827703291289

Epoch: 5| Step: 10
Training loss: 3.020734184654992
Validation loss: 2.6815164725198715

Epoch: 77| Step: 0
Training loss: 3.462497333842329
Validation loss: 2.693073381170628

Epoch: 5| Step: 1
Training loss: 3.105991996013009
Validation loss: 2.65649319427601

Epoch: 5| Step: 2
Training loss: 2.8386778819213654
Validation loss: 2.6355704663497987

Epoch: 5| Step: 3
Training loss: 3.2403593125495003
Validation loss: 2.6250702779711523

Epoch: 5| Step: 4
Training loss: 3.1297651962105153
Validation loss: 2.6278762022060485

Epoch: 5| Step: 5
Training loss: 2.7474025250153007
Validation loss: 2.6215504757484993

Epoch: 5| Step: 6
Training loss: 3.101807092203455
Validation loss: 2.6233631026765107

Epoch: 5| Step: 7
Training loss: 2.6388077662084353
Validation loss: 2.636324201481418

Epoch: 5| Step: 8
Training loss: 2.9748781900552674
Validation loss: 2.6582065872876637

Epoch: 5| Step: 9
Training loss: 2.6840043510367635
Validation loss: 2.667703197965195

Epoch: 5| Step: 10
Training loss: 2.9112196240410744
Validation loss: 2.6832349664289303

Epoch: 78| Step: 0
Training loss: 3.0333806051685945
Validation loss: 2.70269540093366

Epoch: 5| Step: 1
Training loss: 2.949251086329349
Validation loss: 2.7092783863795167

Epoch: 5| Step: 2
Training loss: 3.080971268432924
Validation loss: 2.689574678779994

Epoch: 5| Step: 3
Training loss: 3.1387678890105883
Validation loss: 2.681017600066231

Epoch: 5| Step: 4
Training loss: 2.8551673156026163
Validation loss: 2.6667214229048293

Epoch: 5| Step: 5
Training loss: 2.796778330917128
Validation loss: 2.636886840955816

Epoch: 5| Step: 6
Training loss: 2.7194419068101787
Validation loss: 2.624816638111138

Epoch: 5| Step: 7
Training loss: 2.7800704512142493
Validation loss: 2.62801308281849

Epoch: 5| Step: 8
Training loss: 2.7700979839305635
Validation loss: 2.636025331530929

Epoch: 5| Step: 9
Training loss: 3.4772921021636263
Validation loss: 2.6662619024642713

Epoch: 5| Step: 10
Training loss: 3.1070850316822685
Validation loss: 2.6649664899013707

Epoch: 79| Step: 0
Training loss: 2.684074614196933
Validation loss: 2.6585551789589927

Epoch: 5| Step: 1
Training loss: 2.9458512438311018
Validation loss: 2.6504900380740244

Epoch: 5| Step: 2
Training loss: 2.955450847590671
Validation loss: 2.617344900536712

Epoch: 5| Step: 3
Training loss: 3.2461686659338005
Validation loss: 2.6094843135575463

Epoch: 5| Step: 4
Training loss: 2.7478668435886764
Validation loss: 2.606004704396242

Epoch: 5| Step: 5
Training loss: 3.3122747092737983
Validation loss: 2.6063150845859417

Epoch: 5| Step: 6
Training loss: 2.6741592726026218
Validation loss: 2.6076536041127563

Epoch: 5| Step: 7
Training loss: 2.6036831114368533
Validation loss: 2.6129403787402485

Epoch: 5| Step: 8
Training loss: 2.937283934093683
Validation loss: 2.610652371940345

Epoch: 5| Step: 9
Training loss: 2.988788476917264
Validation loss: 2.6133449605598775

Epoch: 5| Step: 10
Training loss: 3.4465291130710174
Validation loss: 2.6210064626883076

Epoch: 80| Step: 0
Training loss: 2.1187613292830054
Validation loss: 2.6268148901648236

Epoch: 5| Step: 1
Training loss: 3.6068418126288995
Validation loss: 2.624307256840206

Epoch: 5| Step: 2
Training loss: 2.674347564421032
Validation loss: 2.6289357390919044

Epoch: 5| Step: 3
Training loss: 2.839980257261184
Validation loss: 2.6115701338561643

Epoch: 5| Step: 4
Training loss: 3.2789048306450943
Validation loss: 2.6096239919869704

Epoch: 5| Step: 5
Training loss: 3.093043391133334
Validation loss: 2.6044340413973424

Epoch: 5| Step: 6
Training loss: 3.500448198231332
Validation loss: 2.603575109091482

Epoch: 5| Step: 7
Training loss: 2.636952210439932
Validation loss: 2.6019116357430967

Epoch: 5| Step: 8
Training loss: 2.7398726645347935
Validation loss: 2.603690613252177

Epoch: 5| Step: 9
Training loss: 2.9746079322776375
Validation loss: 2.601034632965235

Epoch: 5| Step: 10
Training loss: 2.735134084786608
Validation loss: 2.601712610147145

Epoch: 81| Step: 0
Training loss: 3.074699858617269
Validation loss: 2.6024442207903107

Epoch: 5| Step: 1
Training loss: 2.603492914145131
Validation loss: 2.596981383623317

Epoch: 5| Step: 2
Training loss: 3.1663653247069954
Validation loss: 2.6010379614133754

Epoch: 5| Step: 3
Training loss: 3.0565702680101583
Validation loss: 2.6031615616682875

Epoch: 5| Step: 4
Training loss: 2.9124139208209066
Validation loss: 2.6041005306254603

Epoch: 5| Step: 5
Training loss: 2.6463896899863157
Validation loss: 2.597668477727481

Epoch: 5| Step: 6
Training loss: 2.7291064267875136
Validation loss: 2.600559956783319

Epoch: 5| Step: 7
Training loss: 2.8090700215255833
Validation loss: 2.600524093997112

Epoch: 5| Step: 8
Training loss: 2.9704981425314365
Validation loss: 2.6092389200032717

Epoch: 5| Step: 9
Training loss: 3.278740786307882
Validation loss: 2.6083469331804765

Epoch: 5| Step: 10
Training loss: 3.1358440695065304
Validation loss: 2.600260709812602

Epoch: 82| Step: 0
Training loss: 2.626278520490068
Validation loss: 2.605831068837406

Epoch: 5| Step: 1
Training loss: 2.7086832749651495
Validation loss: 2.615822257354204

Epoch: 5| Step: 2
Training loss: 2.609120887672328
Validation loss: 2.63505648690176

Epoch: 5| Step: 3
Training loss: 3.6282641743096797
Validation loss: 2.654420518692507

Epoch: 5| Step: 4
Training loss: 3.0371572607257917
Validation loss: 2.641394297111699

Epoch: 5| Step: 5
Training loss: 2.9203862768235602
Validation loss: 2.6291957573248013

Epoch: 5| Step: 6
Training loss: 3.0881552923616407
Validation loss: 2.614932163254057

Epoch: 5| Step: 7
Training loss: 2.924147431107491
Validation loss: 2.59961972575454

Epoch: 5| Step: 8
Training loss: 3.0310650012007176
Validation loss: 2.590052766113951

Epoch: 5| Step: 9
Training loss: 2.697948195421744
Validation loss: 2.594352915994745

Epoch: 5| Step: 10
Training loss: 3.0127552984810086
Validation loss: 2.5897960451500905

Epoch: 83| Step: 0
Training loss: 3.0764065510683167
Validation loss: 2.5923785856259816

Epoch: 5| Step: 1
Training loss: 2.589235352275389
Validation loss: 2.5929557235498284

Epoch: 5| Step: 2
Training loss: 2.93642129774353
Validation loss: 2.591916417290422

Epoch: 5| Step: 3
Training loss: 2.787992213288958
Validation loss: 2.5891433531201162

Epoch: 5| Step: 4
Training loss: 2.6013848871310166
Validation loss: 2.5893263343200315

Epoch: 5| Step: 5
Training loss: 3.2279790027318387
Validation loss: 2.592813631427549

Epoch: 5| Step: 6
Training loss: 2.912565526920965
Validation loss: 2.5892205242714152

Epoch: 5| Step: 7
Training loss: 2.9668510386863702
Validation loss: 2.5924425952900623

Epoch: 5| Step: 8
Training loss: 2.949182371205682
Validation loss: 2.5929956309008766

Epoch: 5| Step: 9
Training loss: 3.032711659818104
Validation loss: 2.591319638031378

Epoch: 5| Step: 10
Training loss: 3.297097727406979
Validation loss: 2.5844272870167577

Epoch: 84| Step: 0
Training loss: 2.7980196011928986
Validation loss: 2.5846611421932684

Epoch: 5| Step: 1
Training loss: 2.759369062371956
Validation loss: 2.583406409289572

Epoch: 5| Step: 2
Training loss: 2.89461822996844
Validation loss: 2.5868957754495945

Epoch: 5| Step: 3
Training loss: 3.267204669193963
Validation loss: 2.5902807481718604

Epoch: 5| Step: 4
Training loss: 3.0468005048986044
Validation loss: 2.584736623177653

Epoch: 5| Step: 5
Training loss: 3.184381193355269
Validation loss: 2.5825194483604057

Epoch: 5| Step: 6
Training loss: 2.2525007338104577
Validation loss: 2.586310924997425

Epoch: 5| Step: 7
Training loss: 3.042618188999527
Validation loss: 2.5927122659142983

Epoch: 5| Step: 8
Training loss: 2.8925210868574562
Validation loss: 2.5989128034988487

Epoch: 5| Step: 9
Training loss: 2.6418004777233124
Validation loss: 2.6083728048837065

Epoch: 5| Step: 10
Training loss: 3.53742265920037
Validation loss: 2.61074973466546

Epoch: 85| Step: 0
Training loss: 2.9844908367264917
Validation loss: 2.6148145781185526

Epoch: 5| Step: 1
Training loss: 2.7371872745064803
Validation loss: 2.6168830480226264

Epoch: 5| Step: 2
Training loss: 3.4588838774838164
Validation loss: 2.6104720277276936

Epoch: 5| Step: 3
Training loss: 2.920618123512328
Validation loss: 2.614751579879671

Epoch: 5| Step: 4
Training loss: 2.9609597237993484
Validation loss: 2.614859592178192

Epoch: 5| Step: 5
Training loss: 3.1619970291094783
Validation loss: 2.6028953694512555

Epoch: 5| Step: 6
Training loss: 2.620346485843348
Validation loss: 2.5837076192534347

Epoch: 5| Step: 7
Training loss: 2.352883104351017
Validation loss: 2.5786826327724306

Epoch: 5| Step: 8
Training loss: 3.0274483348870143
Validation loss: 2.577682768430211

Epoch: 5| Step: 9
Training loss: 3.146512713976587
Validation loss: 2.579831344424007

Epoch: 5| Step: 10
Training loss: 2.8400035954842173
Validation loss: 2.5850649731850166

Epoch: 86| Step: 0
Training loss: 3.1294313673546825
Validation loss: 2.585579540307727

Epoch: 5| Step: 1
Training loss: 3.165033638822104
Validation loss: 2.593057438428037

Epoch: 5| Step: 2
Training loss: 3.1330678935604284
Validation loss: 2.587004174356344

Epoch: 5| Step: 3
Training loss: 3.2495875463659356
Validation loss: 2.5892761194425264

Epoch: 5| Step: 4
Training loss: 3.067073287819586
Validation loss: 2.59225398831163

Epoch: 5| Step: 5
Training loss: 2.6492768254575614
Validation loss: 2.5897993959614234

Epoch: 5| Step: 6
Training loss: 3.1493972564958574
Validation loss: 2.5844891615753856

Epoch: 5| Step: 7
Training loss: 2.65473706410769
Validation loss: 2.5800188901164707

Epoch: 5| Step: 8
Training loss: 2.666847361959388
Validation loss: 2.5828917596017957

Epoch: 5| Step: 9
Training loss: 2.516495074386521
Validation loss: 2.581645090085581

Epoch: 5| Step: 10
Training loss: 2.925026239782811
Validation loss: 2.575786463943065

Epoch: 87| Step: 0
Training loss: 3.172287787275589
Validation loss: 2.572836398179172

Epoch: 5| Step: 1
Training loss: 2.9225278726754587
Validation loss: 2.5793706982559783

Epoch: 5| Step: 2
Training loss: 2.8590382862389543
Validation loss: 2.587363045196708

Epoch: 5| Step: 3
Training loss: 3.254626722130025
Validation loss: 2.5928299269406665

Epoch: 5| Step: 4
Training loss: 3.0839141779732606
Validation loss: 2.6231094902760836

Epoch: 5| Step: 5
Training loss: 2.6818803095270503
Validation loss: 2.6178596996127226

Epoch: 5| Step: 6
Training loss: 2.5707299725380186
Validation loss: 2.6196436423799994

Epoch: 5| Step: 7
Training loss: 3.1272373582561728
Validation loss: 2.6611185604487892

Epoch: 5| Step: 8
Training loss: 2.663678004465744
Validation loss: 2.6575962223822245

Epoch: 5| Step: 9
Training loss: 3.391451405310493
Validation loss: 2.63350036093198

Epoch: 5| Step: 10
Training loss: 2.3771980554399748
Validation loss: 2.6036365758711533

Epoch: 88| Step: 0
Training loss: 3.0952092592062925
Validation loss: 2.582995234490472

Epoch: 5| Step: 1
Training loss: 2.7596244586927288
Validation loss: 2.5822325957132053

Epoch: 5| Step: 2
Training loss: 3.057633250367022
Validation loss: 2.57467162832835

Epoch: 5| Step: 3
Training loss: 3.304091090860926
Validation loss: 2.5747439650528388

Epoch: 5| Step: 4
Training loss: 2.5837103250721194
Validation loss: 2.5729616548244305

Epoch: 5| Step: 5
Training loss: 2.989068140881047
Validation loss: 2.572273823404572

Epoch: 5| Step: 6
Training loss: 2.7987506906321986
Validation loss: 2.573112655361715

Epoch: 5| Step: 7
Training loss: 3.257849530711678
Validation loss: 2.5683360917503504

Epoch: 5| Step: 8
Training loss: 2.5866671451915546
Validation loss: 2.5717843968545337

Epoch: 5| Step: 9
Training loss: 2.516549361149761
Validation loss: 2.568685144677026

Epoch: 5| Step: 10
Training loss: 3.1241049438414
Validation loss: 2.56504440142214

Epoch: 89| Step: 0
Training loss: 3.2725230102662635
Validation loss: 2.5639699515989522

Epoch: 5| Step: 1
Training loss: 3.224104344395101
Validation loss: 2.5675786920889467

Epoch: 5| Step: 2
Training loss: 2.762002415097318
Validation loss: 2.5705222425658367

Epoch: 5| Step: 3
Training loss: 2.4322209045006162
Validation loss: 2.566001881335467

Epoch: 5| Step: 4
Training loss: 2.829349821638888
Validation loss: 2.5671644429563427

Epoch: 5| Step: 5
Training loss: 3.2186000752022292
Validation loss: 2.571260003032016

Epoch: 5| Step: 6
Training loss: 2.6692147200974414
Validation loss: 2.5694635588040193

Epoch: 5| Step: 7
Training loss: 3.129238611063903
Validation loss: 2.5685262623883958

Epoch: 5| Step: 8
Training loss: 2.8095656452266153
Validation loss: 2.5761669092680064

Epoch: 5| Step: 9
Training loss: 2.7308946531099068
Validation loss: 2.590743183064784

Epoch: 5| Step: 10
Training loss: 3.0161679426430386
Validation loss: 2.5927721343089236

Epoch: 90| Step: 0
Training loss: 3.3468057805159708
Validation loss: 2.601053256252976

Epoch: 5| Step: 1
Training loss: 2.8575672209167897
Validation loss: 2.603817735655343

Epoch: 5| Step: 2
Training loss: 3.0670827714604876
Validation loss: 2.5932492324896406

Epoch: 5| Step: 3
Training loss: 3.125173792774793
Validation loss: 2.587105025771142

Epoch: 5| Step: 4
Training loss: 3.1543538658260983
Validation loss: 2.5791327760657095

Epoch: 5| Step: 5
Training loss: 2.6727705675981697
Validation loss: 2.5730863225198304

Epoch: 5| Step: 6
Training loss: 2.672578774728428
Validation loss: 2.5709937166292036

Epoch: 5| Step: 7
Training loss: 1.937042797657624
Validation loss: 2.568574438125415

Epoch: 5| Step: 8
Training loss: 2.746296035457153
Validation loss: 2.5687185666942254

Epoch: 5| Step: 9
Training loss: 3.462570872769277
Validation loss: 2.564668325764508

Epoch: 5| Step: 10
Training loss: 2.846820389425873
Validation loss: 2.565257098632681

Epoch: 91| Step: 0
Training loss: 2.8417661684874536
Validation loss: 2.5648225343087203

Epoch: 5| Step: 1
Training loss: 3.06755520622487
Validation loss: 2.562607511580552

Epoch: 5| Step: 2
Training loss: 2.949916650920071
Validation loss: 2.567808032536502

Epoch: 5| Step: 3
Training loss: 2.9434867077011044
Validation loss: 2.57884752994561

Epoch: 5| Step: 4
Training loss: 3.1957343459600533
Validation loss: 2.5702927094284944

Epoch: 5| Step: 5
Training loss: 3.021566437961223
Validation loss: 2.5719698011875733

Epoch: 5| Step: 6
Training loss: 3.1698630580745597
Validation loss: 2.567961458539576

Epoch: 5| Step: 7
Training loss: 2.9885694177845346
Validation loss: 2.5691985151099628

Epoch: 5| Step: 8
Training loss: 2.8175494324918087
Validation loss: 2.5709908907329337

Epoch: 5| Step: 9
Training loss: 2.2444678218282963
Validation loss: 2.565114903847873

Epoch: 5| Step: 10
Training loss: 2.720061238104408
Validation loss: 2.5599155183456967

Epoch: 92| Step: 0
Training loss: 3.0147697540478733
Validation loss: 2.570737767969152

Epoch: 5| Step: 1
Training loss: 2.364105433990041
Validation loss: 2.569030864089448

Epoch: 5| Step: 2
Training loss: 2.8419045968629733
Validation loss: 2.5671010523051305

Epoch: 5| Step: 3
Training loss: 3.0648687116125197
Validation loss: 2.5736301252127003

Epoch: 5| Step: 4
Training loss: 3.417635446918625
Validation loss: 2.5670472743308927

Epoch: 5| Step: 5
Training loss: 3.4028205055789345
Validation loss: 2.5680254079600466

Epoch: 5| Step: 6
Training loss: 2.65975379980436
Validation loss: 2.5629175777835362

Epoch: 5| Step: 7
Training loss: 2.542743725643006
Validation loss: 2.559458474494007

Epoch: 5| Step: 8
Training loss: 2.369729669339841
Validation loss: 2.5594635367472485

Epoch: 5| Step: 9
Training loss: 2.711748864730101
Validation loss: 2.5617304310903553

Epoch: 5| Step: 10
Training loss: 3.481253829762186
Validation loss: 2.562945203426318

Epoch: 93| Step: 0
Training loss: 2.9046710247292817
Validation loss: 2.562085371990653

Epoch: 5| Step: 1
Training loss: 2.9562553486362324
Validation loss: 2.563847969366296

Epoch: 5| Step: 2
Training loss: 3.3776366213393927
Validation loss: 2.5796144858255285

Epoch: 5| Step: 3
Training loss: 2.674411395191469
Validation loss: 2.581834963572215

Epoch: 5| Step: 4
Training loss: 1.8642122194161226
Validation loss: 2.5638789896698615

Epoch: 5| Step: 5
Training loss: 3.0010479050562293
Validation loss: 2.5583811376264043

Epoch: 5| Step: 6
Training loss: 3.010670282753101
Validation loss: 2.5547191372933504

Epoch: 5| Step: 7
Training loss: 3.117269949910144
Validation loss: 2.557300635195268

Epoch: 5| Step: 8
Training loss: 2.762093568480706
Validation loss: 2.559098532038202

Epoch: 5| Step: 9
Training loss: 3.3680132851236695
Validation loss: 2.5592068636847802

Epoch: 5| Step: 10
Training loss: 2.7618458245163575
Validation loss: 2.5597815361607634

Epoch: 94| Step: 0
Training loss: 2.719094002544162
Validation loss: 2.5562146083663255

Epoch: 5| Step: 1
Training loss: 2.7907564377881764
Validation loss: 2.5560098029312686

Epoch: 5| Step: 2
Training loss: 2.957953809293688
Validation loss: 2.560050515950585

Epoch: 5| Step: 3
Training loss: 3.4790952907405717
Validation loss: 2.5714542722858176

Epoch: 5| Step: 4
Training loss: 2.8504450868764932
Validation loss: 2.580752731812839

Epoch: 5| Step: 5
Training loss: 2.847133258783987
Validation loss: 2.6024449438459483

Epoch: 5| Step: 6
Training loss: 3.4156329909612464
Validation loss: 2.6105413730222944

Epoch: 5| Step: 7
Training loss: 3.199879709605476
Validation loss: 2.612605509526476

Epoch: 5| Step: 8
Training loss: 2.7061334527624754
Validation loss: 2.641817086794942

Epoch: 5| Step: 9
Training loss: 2.102823439314664
Validation loss: 2.6307504078074575

Epoch: 5| Step: 10
Training loss: 2.72388245651347
Validation loss: 2.6381220694532304

Epoch: 95| Step: 0
Training loss: 2.997809245977561
Validation loss: 2.614544587795449

Epoch: 5| Step: 1
Training loss: 3.219517440414526
Validation loss: 2.567106151417249

Epoch: 5| Step: 2
Training loss: 2.418525791865865
Validation loss: 2.554660461429206

Epoch: 5| Step: 3
Training loss: 2.5041100096256987
Validation loss: 2.552453773908114

Epoch: 5| Step: 4
Training loss: 2.8182533757082884
Validation loss: 2.5510325592656535

Epoch: 5| Step: 5
Training loss: 3.3266194121445327
Validation loss: 2.5615639426314183

Epoch: 5| Step: 6
Training loss: 2.6438164019531176
Validation loss: 2.5641160786633845

Epoch: 5| Step: 7
Training loss: 2.7994756275716486
Validation loss: 2.5650529427309694

Epoch: 5| Step: 8
Training loss: 2.816657659602765
Validation loss: 2.5667531023572208

Epoch: 5| Step: 9
Training loss: 3.3828282873476874
Validation loss: 2.567254318843581

Epoch: 5| Step: 10
Training loss: 3.161979083557245
Validation loss: 2.5665801674813196

Epoch: 96| Step: 0
Training loss: 3.3690078664966934
Validation loss: 2.560995314948904

Epoch: 5| Step: 1
Training loss: 3.2880315546716705
Validation loss: 2.5595081089840863

Epoch: 5| Step: 2
Training loss: 2.846487216102603
Validation loss: 2.5527782492748576

Epoch: 5| Step: 3
Training loss: 2.4590329505540183
Validation loss: 2.5479452910464793

Epoch: 5| Step: 4
Training loss: 2.9238992298885695
Validation loss: 2.546841714101591

Epoch: 5| Step: 5
Training loss: 2.7651700437660542
Validation loss: 2.554626166066622

Epoch: 5| Step: 6
Training loss: 2.877441861968083
Validation loss: 2.563921911319919

Epoch: 5| Step: 7
Training loss: 2.3947353556083977
Validation loss: 2.5958232379783457

Epoch: 5| Step: 8
Training loss: 3.167773973378014
Validation loss: 2.6100497479589806

Epoch: 5| Step: 9
Training loss: 2.9710833565116164
Validation loss: 2.6021802634922158

Epoch: 5| Step: 10
Training loss: 2.9116181049398757
Validation loss: 2.5839252658782947

Epoch: 97| Step: 0
Training loss: 2.650460879716667
Validation loss: 2.561205106840945

Epoch: 5| Step: 1
Training loss: 2.775406603193362
Validation loss: 2.5592170312492435

Epoch: 5| Step: 2
Training loss: 3.4171138718866163
Validation loss: 2.550785597805182

Epoch: 5| Step: 3
Training loss: 3.0351659904726263
Validation loss: 2.5545144387679204

Epoch: 5| Step: 4
Training loss: 2.5583568667179546
Validation loss: 2.5461355555580476

Epoch: 5| Step: 5
Training loss: 2.94205495056658
Validation loss: 2.5486857313061027

Epoch: 5| Step: 6
Training loss: 2.598380310567005
Validation loss: 2.5542986324447976

Epoch: 5| Step: 7
Training loss: 2.6971530103550094
Validation loss: 2.5508535787855

Epoch: 5| Step: 8
Training loss: 2.9540334444625738
Validation loss: 2.559794277308606

Epoch: 5| Step: 9
Training loss: 3.295600536305555
Validation loss: 2.5581423756702177

Epoch: 5| Step: 10
Training loss: 2.9034988343302346
Validation loss: 2.564934013490368

Epoch: 98| Step: 0
Training loss: 2.65740780000269
Validation loss: 2.5508169990703706

Epoch: 5| Step: 1
Training loss: 2.9324599511939535
Validation loss: 2.5504683609345675

Epoch: 5| Step: 2
Training loss: 2.889214083716437
Validation loss: 2.5456364560176072

Epoch: 5| Step: 3
Training loss: 2.8749990048614107
Validation loss: 2.544704162096041

Epoch: 5| Step: 4
Training loss: 2.662136780226234
Validation loss: 2.5526521006676717

Epoch: 5| Step: 5
Training loss: 2.4860812871506837
Validation loss: 2.5513923369196694

Epoch: 5| Step: 6
Training loss: 3.388050138838877
Validation loss: 2.5684359049935432

Epoch: 5| Step: 7
Training loss: 3.0390905854562624
Validation loss: 2.568694706843593

Epoch: 5| Step: 8
Training loss: 2.868441356935203
Validation loss: 2.5884043580226037

Epoch: 5| Step: 9
Training loss: 2.8745674139568917
Validation loss: 2.585658933652776

Epoch: 5| Step: 10
Training loss: 3.254881933505732
Validation loss: 2.5620908192895357

Epoch: 99| Step: 0
Training loss: 2.0085561837088934
Validation loss: 2.554990584562

Epoch: 5| Step: 1
Training loss: 2.7998549287544012
Validation loss: 2.547384132053464

Epoch: 5| Step: 2
Training loss: 2.6598883450528885
Validation loss: 2.5439168023102257

Epoch: 5| Step: 3
Training loss: 2.8112516387758273
Validation loss: 2.5406990979998967

Epoch: 5| Step: 4
Training loss: 2.9590652706557483
Validation loss: 2.541004785313118

Epoch: 5| Step: 5
Training loss: 3.2080263924024357
Validation loss: 2.541005288758274

Epoch: 5| Step: 6
Training loss: 3.404571119457822
Validation loss: 2.540404565363578

Epoch: 5| Step: 7
Training loss: 3.421441316339116
Validation loss: 2.544877555008633

Epoch: 5| Step: 8
Training loss: 2.702506551390549
Validation loss: 2.5411519383885315

Epoch: 5| Step: 9
Training loss: 3.0971460679921914
Validation loss: 2.5452258938068515

Epoch: 5| Step: 10
Training loss: 2.5041811311614013
Validation loss: 2.5392189057218406

Epoch: 100| Step: 0
Training loss: 2.8228278527359123
Validation loss: 2.5487185243936454

Epoch: 5| Step: 1
Training loss: 2.4960659544923938
Validation loss: 2.5660033369943163

Epoch: 5| Step: 2
Training loss: 3.130430919246317
Validation loss: 2.580680992662186

Epoch: 5| Step: 3
Training loss: 2.6205365516807944
Validation loss: 2.6014165822900974

Epoch: 5| Step: 4
Training loss: 3.002975418859098
Validation loss: 2.625651318308458

Epoch: 5| Step: 5
Training loss: 2.83484168200987
Validation loss: 2.5772072449694203

Epoch: 5| Step: 6
Training loss: 2.86775405649652
Validation loss: 2.5516851024479177

Epoch: 5| Step: 7
Training loss: 2.9518449219078504
Validation loss: 2.538943750777187

Epoch: 5| Step: 8
Training loss: 3.2903051498031
Validation loss: 2.5361278573262767

Epoch: 5| Step: 9
Training loss: 2.7779198758549395
Validation loss: 2.5375334315126126

Epoch: 5| Step: 10
Training loss: 3.027720018199496
Validation loss: 2.542946179906973

Epoch: 101| Step: 0
Training loss: 2.9591509982995636
Validation loss: 2.5407187820733967

Epoch: 5| Step: 1
Training loss: 3.011177538819006
Validation loss: 2.544860262386998

Epoch: 5| Step: 2
Training loss: 3.0080196953291036
Validation loss: 2.537102843395741

Epoch: 5| Step: 3
Training loss: 2.727312831872785
Validation loss: 2.5303385025316296

Epoch: 5| Step: 4
Training loss: 2.2482275869481816
Validation loss: 2.5396299494502745

Epoch: 5| Step: 5
Training loss: 3.400334111795248
Validation loss: 2.5515582788694213

Epoch: 5| Step: 6
Training loss: 3.459846961986355
Validation loss: 2.5743102209400295

Epoch: 5| Step: 7
Training loss: 2.277526848108219
Validation loss: 2.59305700045359

Epoch: 5| Step: 8
Training loss: 2.982144625804367
Validation loss: 2.664304385548675

Epoch: 5| Step: 9
Training loss: 2.887439684217261
Validation loss: 2.6924556287436436

Epoch: 5| Step: 10
Training loss: 2.960289393531827
Validation loss: 2.6628320003133874

Epoch: 102| Step: 0
Training loss: 3.1323582802732024
Validation loss: 2.5911971208914837

Epoch: 5| Step: 1
Training loss: 2.9218606387514714
Validation loss: 2.5360052323929674

Epoch: 5| Step: 2
Training loss: 3.3794891736607378
Validation loss: 2.5342492782815964

Epoch: 5| Step: 3
Training loss: 3.2067128998033385
Validation loss: 2.5448670480877897

Epoch: 5| Step: 4
Training loss: 2.4900878863163824
Validation loss: 2.567083723636901

Epoch: 5| Step: 5
Training loss: 2.831486006241253
Validation loss: 2.571253200241488

Epoch: 5| Step: 6
Training loss: 2.564064571698251
Validation loss: 2.575810343198469

Epoch: 5| Step: 7
Training loss: 3.1208806162071747
Validation loss: 2.563780388441127

Epoch: 5| Step: 8
Training loss: 3.0854395983812077
Validation loss: 2.561461055222233

Epoch: 5| Step: 9
Training loss: 2.814649396375652
Validation loss: 2.554055498927813

Epoch: 5| Step: 10
Training loss: 2.813123167724284
Validation loss: 2.5486634944920183

Epoch: 103| Step: 0
Training loss: 3.1008682819280917
Validation loss: 2.5503139262803054

Epoch: 5| Step: 1
Training loss: 2.633855958173214
Validation loss: 2.5413568416465777

Epoch: 5| Step: 2
Training loss: 2.767815191416849
Validation loss: 2.533448217207116

Epoch: 5| Step: 3
Training loss: 2.437588910168572
Validation loss: 2.5318210392682463

Epoch: 5| Step: 4
Training loss: 3.18867186901836
Validation loss: 2.554732925238477

Epoch: 5| Step: 5
Training loss: 3.2331785486146107
Validation loss: 2.5609856189256206

Epoch: 5| Step: 6
Training loss: 3.077503586990906
Validation loss: 2.5780109975698258

Epoch: 5| Step: 7
Training loss: 2.2979812553046304
Validation loss: 2.562393364337031

Epoch: 5| Step: 8
Training loss: 3.155535626535063
Validation loss: 2.5535440376172067

Epoch: 5| Step: 9
Training loss: 2.9079935729783513
Validation loss: 2.5478461380861206

Epoch: 5| Step: 10
Training loss: 2.96639809053518
Validation loss: 2.5415668161979683

Epoch: 104| Step: 0
Training loss: 2.7708339452145316
Validation loss: 2.5324520364742398

Epoch: 5| Step: 1
Training loss: 2.473656233696611
Validation loss: 2.5413923137332577

Epoch: 5| Step: 2
Training loss: 2.60293149011343
Validation loss: 2.532605627421674

Epoch: 5| Step: 3
Training loss: 2.7841984411361995
Validation loss: 2.530237850062856

Epoch: 5| Step: 4
Training loss: 2.9916417991291797
Validation loss: 2.5295505913512257

Epoch: 5| Step: 5
Training loss: 3.202045686823561
Validation loss: 2.5379092794634106

Epoch: 5| Step: 6
Training loss: 3.260015899759848
Validation loss: 2.5338934450676147

Epoch: 5| Step: 7
Training loss: 2.9904314670105245
Validation loss: 2.5349444843441424

Epoch: 5| Step: 8
Training loss: 2.818175459879753
Validation loss: 2.5303426585152025

Epoch: 5| Step: 9
Training loss: 2.7921987472504046
Validation loss: 2.537780802718256

Epoch: 5| Step: 10
Training loss: 2.9744604502998437
Validation loss: 2.5418404375691788

Epoch: 105| Step: 0
Training loss: 2.943688549526143
Validation loss: 2.535504150890091

Epoch: 5| Step: 1
Training loss: 2.5127563231941528
Validation loss: 2.5363618922874887

Epoch: 5| Step: 2
Training loss: 3.090154851594971
Validation loss: 2.530023049332203

Epoch: 5| Step: 3
Training loss: 2.883477689918345
Validation loss: 2.5325392034434944

Epoch: 5| Step: 4
Training loss: 2.6977197484404285
Validation loss: 2.5373661944753474

Epoch: 5| Step: 5
Training loss: 2.6696177088194997
Validation loss: 2.529101485016084

Epoch: 5| Step: 6
Training loss: 3.5062076831242766
Validation loss: 2.5386875846975845

Epoch: 5| Step: 7
Training loss: 2.543860963092979
Validation loss: 2.544770019711047

Epoch: 5| Step: 8
Training loss: 2.4806608831530785
Validation loss: 2.5431399951135343

Epoch: 5| Step: 9
Training loss: 3.148484298320387
Validation loss: 2.5488753519384693

Epoch: 5| Step: 10
Training loss: 3.0869767768858765
Validation loss: 2.541949227871079

Epoch: 106| Step: 0
Training loss: 3.230375756766885
Validation loss: 2.536863092377466

Epoch: 5| Step: 1
Training loss: 2.503635147819997
Validation loss: 2.5270154254464487

Epoch: 5| Step: 2
Training loss: 2.677581048160861
Validation loss: 2.5252537897398297

Epoch: 5| Step: 3
Training loss: 2.7233155600233574
Validation loss: 2.5264834811869172

Epoch: 5| Step: 4
Training loss: 2.3577942257849855
Validation loss: 2.5269808330115047

Epoch: 5| Step: 5
Training loss: 2.951754943486828
Validation loss: 2.522568242898316

Epoch: 5| Step: 6
Training loss: 2.928748547451491
Validation loss: 2.5235832169997163

Epoch: 5| Step: 7
Training loss: 3.2120089263221914
Validation loss: 2.5296052414795067

Epoch: 5| Step: 8
Training loss: 2.909707422656344
Validation loss: 2.5234414275896406

Epoch: 5| Step: 9
Training loss: 3.294109902452934
Validation loss: 2.5233547860413785

Epoch: 5| Step: 10
Training loss: 2.885201144288795
Validation loss: 2.5310819816453898

Epoch: 107| Step: 0
Training loss: 2.7055446842122275
Validation loss: 2.5284057187541786

Epoch: 5| Step: 1
Training loss: 2.7640380616776223
Validation loss: 2.5324835749695445

Epoch: 5| Step: 2
Training loss: 2.6008360252215694
Validation loss: 2.53663144229784

Epoch: 5| Step: 3
Training loss: 2.897298501671529
Validation loss: 2.5486425792167875

Epoch: 5| Step: 4
Training loss: 2.7738470930217276
Validation loss: 2.5542988361872343

Epoch: 5| Step: 5
Training loss: 2.7380636566820744
Validation loss: 2.5620864836648227

Epoch: 5| Step: 6
Training loss: 2.9916598101212357
Validation loss: 2.537815620696051

Epoch: 5| Step: 7
Training loss: 3.473130904929424
Validation loss: 2.5404552421821913

Epoch: 5| Step: 8
Training loss: 2.5692189217878085
Validation loss: 2.5272467721203467

Epoch: 5| Step: 9
Training loss: 3.370816216034371
Validation loss: 2.5249119006431107

Epoch: 5| Step: 10
Training loss: 2.595598412461838
Validation loss: 2.515828810664613

Epoch: 108| Step: 0
Training loss: 3.204985287732235
Validation loss: 2.5220190392131134

Epoch: 5| Step: 1
Training loss: 2.745469696633539
Validation loss: 2.516776013486061

Epoch: 5| Step: 2
Training loss: 3.1130185656608163
Validation loss: 2.5132445084364923

Epoch: 5| Step: 3
Training loss: 2.573005818870064
Validation loss: 2.516636348537127

Epoch: 5| Step: 4
Training loss: 3.319542362430653
Validation loss: 2.5167766450309363

Epoch: 5| Step: 5
Training loss: 2.885932867008243
Validation loss: 2.524638164719943

Epoch: 5| Step: 6
Training loss: 2.676460480624682
Validation loss: 2.5201586328307877

Epoch: 5| Step: 7
Training loss: 2.885394338436473
Validation loss: 2.523811503865269

Epoch: 5| Step: 8
Training loss: 2.4079673880653125
Validation loss: 2.5254072804483845

Epoch: 5| Step: 9
Training loss: 2.5046907288071827
Validation loss: 2.5344270340344894

Epoch: 5| Step: 10
Training loss: 3.191492161242292
Validation loss: 2.525126395021121

Epoch: 109| Step: 0
Training loss: 3.695170426006612
Validation loss: 2.5246090059410755

Epoch: 5| Step: 1
Training loss: 2.0730986651040872
Validation loss: 2.5238030017611184

Epoch: 5| Step: 2
Training loss: 2.546693198613404
Validation loss: 2.5216902729986064

Epoch: 5| Step: 3
Training loss: 2.885608836544542
Validation loss: 2.5301468568580914

Epoch: 5| Step: 4
Training loss: 2.862821575908684
Validation loss: 2.5450309480912523

Epoch: 5| Step: 5
Training loss: 2.6857767124660334
Validation loss: 2.561510679932343

Epoch: 5| Step: 6
Training loss: 2.864701110268203
Validation loss: 2.5818756336116424

Epoch: 5| Step: 7
Training loss: 3.2693884669110216
Validation loss: 2.5999831692897866

Epoch: 5| Step: 8
Training loss: 2.826922672197841
Validation loss: 2.615386866544329

Epoch: 5| Step: 9
Training loss: 3.1758818475572346
Validation loss: 2.54716683291142

Epoch: 5| Step: 10
Training loss: 2.4028349583558932
Validation loss: 2.5241279892983512

Epoch: 110| Step: 0
Training loss: 3.5188548531502493
Validation loss: 2.512993324346426

Epoch: 5| Step: 1
Training loss: 2.307813173576778
Validation loss: 2.5228217244245315

Epoch: 5| Step: 2
Training loss: 3.0251415881604564
Validation loss: 2.5259807539153183

Epoch: 5| Step: 3
Training loss: 3.207811304864229
Validation loss: 2.5289506828692803

Epoch: 5| Step: 4
Training loss: 2.4570577404735023
Validation loss: 2.5364799416891706

Epoch: 5| Step: 5
Training loss: 3.053197004392582
Validation loss: 2.533118865218469

Epoch: 5| Step: 6
Training loss: 2.9265261263402134
Validation loss: 2.5350042010889373

Epoch: 5| Step: 7
Training loss: 2.760908339756079
Validation loss: 2.5259460123259587

Epoch: 5| Step: 8
Training loss: 2.7732279953605885
Validation loss: 2.522987952763478

Epoch: 5| Step: 9
Training loss: 2.869301497361975
Validation loss: 2.520334090775153

Epoch: 5| Step: 10
Training loss: 2.785572079812083
Validation loss: 2.5197242412977423

Epoch: 111| Step: 0
Training loss: 2.9803449172546563
Validation loss: 2.5190636010918146

Epoch: 5| Step: 1
Training loss: 2.7914811447520735
Validation loss: 2.521243993926985

Epoch: 5| Step: 2
Training loss: 2.962390714150673
Validation loss: 2.5302100892042856

Epoch: 5| Step: 3
Training loss: 2.920708571384684
Validation loss: 2.537884780448833

Epoch: 5| Step: 4
Training loss: 2.819511236350719
Validation loss: 2.545908464876897

Epoch: 5| Step: 5
Training loss: 3.1599202486428677
Validation loss: 2.5453863458194554

Epoch: 5| Step: 6
Training loss: 3.5385318720407537
Validation loss: 2.543219323248722

Epoch: 5| Step: 7
Training loss: 2.7974127566835936
Validation loss: 2.5386414103463255

Epoch: 5| Step: 8
Training loss: 2.549478615957843
Validation loss: 2.5280866840602085

Epoch: 5| Step: 9
Training loss: 2.4146044471570223
Validation loss: 2.528709939948125

Epoch: 5| Step: 10
Training loss: 2.4331755791656
Validation loss: 2.523521747793645

Epoch: 112| Step: 0
Training loss: 2.9718428713308316
Validation loss: 2.5194020446681495

Epoch: 5| Step: 1
Training loss: 2.4787459991622853
Validation loss: 2.5163276357075617

Epoch: 5| Step: 2
Training loss: 3.1938449315483908
Validation loss: 2.5150140086458896

Epoch: 5| Step: 3
Training loss: 3.055921378537373
Validation loss: 2.5230085208372035

Epoch: 5| Step: 4
Training loss: 2.644972793929541
Validation loss: 2.525591553010524

Epoch: 5| Step: 5
Training loss: 3.234237889134122
Validation loss: 2.539793265845904

Epoch: 5| Step: 6
Training loss: 2.959539642104575
Validation loss: 2.5328668200709297

Epoch: 5| Step: 7
Training loss: 2.7522615323548867
Validation loss: 2.5146668972059034

Epoch: 5| Step: 8
Training loss: 3.0832221724258817
Validation loss: 2.5093330534979774

Epoch: 5| Step: 9
Training loss: 2.3756309474277493
Validation loss: 2.505516759991074

Epoch: 5| Step: 10
Training loss: 2.6587181741507178
Validation loss: 2.508240615275261

Epoch: 113| Step: 0
Training loss: 2.7679118383953987
Validation loss: 2.5048704480816717

Epoch: 5| Step: 1
Training loss: 2.5614705692933417
Validation loss: 2.5039791587822076

Epoch: 5| Step: 2
Training loss: 3.098479999629733
Validation loss: 2.508882648147345

Epoch: 5| Step: 3
Training loss: 3.1990819210093857
Validation loss: 2.5076922975456624

Epoch: 5| Step: 4
Training loss: 2.8573496164714447
Validation loss: 2.5113714719929945

Epoch: 5| Step: 5
Training loss: 2.8161067300749343
Validation loss: 2.511543640494537

Epoch: 5| Step: 6
Training loss: 2.7685235131071133
Validation loss: 2.5201009508354293

Epoch: 5| Step: 7
Training loss: 2.8249082027138095
Validation loss: 2.527458297239231

Epoch: 5| Step: 8
Training loss: 2.8874471155913684
Validation loss: 2.5521819624050606

Epoch: 5| Step: 9
Training loss: 3.072258485469295
Validation loss: 2.5564829962493234

Epoch: 5| Step: 10
Training loss: 2.545193356886268
Validation loss: 2.533690706576101

Epoch: 114| Step: 0
Training loss: 2.8273617046341606
Validation loss: 2.531954014289379

Epoch: 5| Step: 1
Training loss: 2.3349570573864664
Validation loss: 2.5230644796387844

Epoch: 5| Step: 2
Training loss: 3.5836509445546207
Validation loss: 2.5209871189440656

Epoch: 5| Step: 3
Training loss: 3.0094072350095673
Validation loss: 2.508439196913653

Epoch: 5| Step: 4
Training loss: 3.0608812063122075
Validation loss: 2.5029418515341546

Epoch: 5| Step: 5
Training loss: 2.4588509569643406
Validation loss: 2.503565941006483

Epoch: 5| Step: 6
Training loss: 3.1044378140881688
Validation loss: 2.503037115304573

Epoch: 5| Step: 7
Training loss: 2.7897045774846254
Validation loss: 2.510998367752187

Epoch: 5| Step: 8
Training loss: 2.7933823926102948
Validation loss: 2.5117278931618343

Epoch: 5| Step: 9
Training loss: 2.4516691516558486
Validation loss: 2.5208256310433677

Epoch: 5| Step: 10
Training loss: 2.8285289496993147
Validation loss: 2.528049045796162

Epoch: 115| Step: 0
Training loss: 2.4005292785676957
Validation loss: 2.529537750568596

Epoch: 5| Step: 1
Training loss: 3.3584132037513412
Validation loss: 2.548755706549136

Epoch: 5| Step: 2
Training loss: 2.576353076869857
Validation loss: 2.555431467246036

Epoch: 5| Step: 3
Training loss: 2.689770294081693
Validation loss: 2.5753750620427995

Epoch: 5| Step: 4
Training loss: 2.8703102340232447
Validation loss: 2.580486553711993

Epoch: 5| Step: 5
Training loss: 2.7102166792333735
Validation loss: 2.5814166576896698

Epoch: 5| Step: 6
Training loss: 2.686724173764153
Validation loss: 2.5532182297580484

Epoch: 5| Step: 7
Training loss: 2.9531937848512055
Validation loss: 2.531728756201072

Epoch: 5| Step: 8
Training loss: 2.8590017606683777
Validation loss: 2.514184764594197

Epoch: 5| Step: 9
Training loss: 3.1155418698652246
Validation loss: 2.497756063758029

Epoch: 5| Step: 10
Training loss: 3.196090342413317
Validation loss: 2.5040987890466475

Epoch: 116| Step: 0
Training loss: 2.965402583151835
Validation loss: 2.504948104131875

Epoch: 5| Step: 1
Training loss: 3.056757155077051
Validation loss: 2.502874030861151

Epoch: 5| Step: 2
Training loss: 2.928753920262278
Validation loss: 2.4948202700099893

Epoch: 5| Step: 3
Training loss: 2.921615507465333
Validation loss: 2.4938191908039262

Epoch: 5| Step: 4
Training loss: 2.6554788704320424
Validation loss: 2.495574570059007

Epoch: 5| Step: 5
Training loss: 3.128454206675655
Validation loss: 2.4949853718150203

Epoch: 5| Step: 6
Training loss: 2.4899831368361744
Validation loss: 2.500665900032457

Epoch: 5| Step: 7
Training loss: 2.586381948948366
Validation loss: 2.5114577057319103

Epoch: 5| Step: 8
Training loss: 3.0113005786921927
Validation loss: 2.5215964362756607

Epoch: 5| Step: 9
Training loss: 2.6210253460709025
Validation loss: 2.539253815036955

Epoch: 5| Step: 10
Training loss: 3.1837875588054696
Validation loss: 2.5593348378196525

Epoch: 117| Step: 0
Training loss: 3.4989833717703336
Validation loss: 2.5367235889513284

Epoch: 5| Step: 1
Training loss: 3.4936155945066676
Validation loss: 2.5216932156492438

Epoch: 5| Step: 2
Training loss: 3.425143140043224
Validation loss: 2.5156784566576373

Epoch: 5| Step: 3
Training loss: 2.5643555040801487
Validation loss: 2.4989854148476516

Epoch: 5| Step: 4
Training loss: 2.6978218228866067
Validation loss: 2.4917109939099453

Epoch: 5| Step: 5
Training loss: 2.4137620461161857
Validation loss: 2.494704795522254

Epoch: 5| Step: 6
Training loss: 2.812747351048017
Validation loss: 2.488669453012469

Epoch: 5| Step: 7
Training loss: 2.6376466827824685
Validation loss: 2.4938785806135026

Epoch: 5| Step: 8
Training loss: 2.184307493550163
Validation loss: 2.495573341438155

Epoch: 5| Step: 9
Training loss: 2.842830467372816
Validation loss: 2.4934939696904896

Epoch: 5| Step: 10
Training loss: 2.405846896404763
Validation loss: 2.5017970291981815

Epoch: 118| Step: 0
Training loss: 3.3512479194313087
Validation loss: 2.5048188435541423

Epoch: 5| Step: 1
Training loss: 2.891826483041474
Validation loss: 2.5128608079257004

Epoch: 5| Step: 2
Training loss: 2.8484361205984388
Validation loss: 2.5381844718090063

Epoch: 5| Step: 3
Training loss: 3.170921746189739
Validation loss: 2.532798453490284

Epoch: 5| Step: 4
Training loss: 2.24643573313656
Validation loss: 2.5079124833779196

Epoch: 5| Step: 5
Training loss: 3.0738652376258253
Validation loss: 2.4978927232106103

Epoch: 5| Step: 6
Training loss: 2.6365926076597175
Validation loss: 2.506136172732442

Epoch: 5| Step: 7
Training loss: 2.5471039651561074
Validation loss: 2.5144849764833452

Epoch: 5| Step: 8
Training loss: 2.5700797581449333
Validation loss: 2.5217018458458034

Epoch: 5| Step: 9
Training loss: 3.101545127224251
Validation loss: 2.5193453425808436

Epoch: 5| Step: 10
Training loss: 2.698252083880693
Validation loss: 2.516659319608227

Epoch: 119| Step: 0
Training loss: 3.4793755626592358
Validation loss: 2.5092676067535926

Epoch: 5| Step: 1
Training loss: 2.749673477208195
Validation loss: 2.505748024889258

Epoch: 5| Step: 2
Training loss: 2.2609365425028747
Validation loss: 2.5023778917449455

Epoch: 5| Step: 3
Training loss: 2.591676917674244
Validation loss: 2.5012319810724626

Epoch: 5| Step: 4
Training loss: 2.505054989970699
Validation loss: 2.4995965426994764

Epoch: 5| Step: 5
Training loss: 2.8448712161235217
Validation loss: 2.49186154020973

Epoch: 5| Step: 6
Training loss: 2.9102899507877646
Validation loss: 2.49672256286346

Epoch: 5| Step: 7
Training loss: 2.848779611136521
Validation loss: 2.491278653771269

Epoch: 5| Step: 8
Training loss: 2.9534543777127267
Validation loss: 2.4947604109067787

Epoch: 5| Step: 9
Training loss: 3.098187741338251
Validation loss: 2.492544310088859

Epoch: 5| Step: 10
Training loss: 2.7377047945522284
Validation loss: 2.4996107239314904

Epoch: 120| Step: 0
Training loss: 3.3090806983290992
Validation loss: 2.501480864756251

Epoch: 5| Step: 1
Training loss: 2.840642551749784
Validation loss: 2.500485893940244

Epoch: 5| Step: 2
Training loss: 3.1042945033297533
Validation loss: 2.502623907934196

Epoch: 5| Step: 3
Training loss: 2.4143735814812484
Validation loss: 2.4962643071723107

Epoch: 5| Step: 4
Training loss: 2.7980045190247043
Validation loss: 2.4988156835932114

Epoch: 5| Step: 5
Training loss: 2.615975079187338
Validation loss: 2.492766358442515

Epoch: 5| Step: 6
Training loss: 3.461671084121239
Validation loss: 2.491141686025461

Epoch: 5| Step: 7
Training loss: 2.5110141365020984
Validation loss: 2.503048803584561

Epoch: 5| Step: 8
Training loss: 2.702201729687709
Validation loss: 2.5112638821234987

Epoch: 5| Step: 9
Training loss: 2.5147871434743028
Validation loss: 2.5315119360824534

Epoch: 5| Step: 10
Training loss: 2.7000408769974715
Validation loss: 2.549147063964445

Epoch: 121| Step: 0
Training loss: 2.7555151169469023
Validation loss: 2.5641701430667236

Epoch: 5| Step: 1
Training loss: 2.8897997528711805
Validation loss: 2.607774473165322

Epoch: 5| Step: 2
Training loss: 3.0950947930975032
Validation loss: 2.6492686214908217

Epoch: 5| Step: 3
Training loss: 3.167653699606749
Validation loss: 2.623839433833608

Epoch: 5| Step: 4
Training loss: 2.593325660648453
Validation loss: 2.5772860745964996

Epoch: 5| Step: 5
Training loss: 2.583269754263193
Validation loss: 2.553132774919662

Epoch: 5| Step: 6
Training loss: 2.50415199728259
Validation loss: 2.5360058551055777

Epoch: 5| Step: 7
Training loss: 2.771144553085284
Validation loss: 2.522429052127743

Epoch: 5| Step: 8
Training loss: 3.300614825686127
Validation loss: 2.530510350101433

Epoch: 5| Step: 9
Training loss: 2.481472310981865
Validation loss: 2.597232120470122

Epoch: 5| Step: 10
Training loss: 3.5592971592296414
Validation loss: 2.6718102182046364

Epoch: 122| Step: 0
Training loss: 2.812379283433641
Validation loss: 2.5619143955642922

Epoch: 5| Step: 1
Training loss: 3.116398991260505
Validation loss: 2.534122313525453

Epoch: 5| Step: 2
Training loss: 2.836936081293638
Validation loss: 2.526351117808143

Epoch: 5| Step: 3
Training loss: 2.5723707312310258
Validation loss: 2.585360098833397

Epoch: 5| Step: 4
Training loss: 2.828200955714523
Validation loss: 2.7261725237124534

Epoch: 5| Step: 5
Training loss: 2.879076845246573
Validation loss: 2.8210146423135605

Epoch: 5| Step: 6
Training loss: 2.7629052706373014
Validation loss: 2.8403983221739555

Epoch: 5| Step: 7
Training loss: 3.3839418142831024
Validation loss: 2.8176640181108072

Epoch: 5| Step: 8
Training loss: 3.094336868263841
Validation loss: 2.705919674137943

Epoch: 5| Step: 9
Training loss: 3.1580088030141003
Validation loss: 2.614641623702533

Epoch: 5| Step: 10
Training loss: 3.3620488371107395
Validation loss: 2.570670838382035

Epoch: 123| Step: 0
Training loss: 2.6015861441422743
Validation loss: 2.5422271690125235

Epoch: 5| Step: 1
Training loss: 3.029491583090166
Validation loss: 2.5353004784525535

Epoch: 5| Step: 2
Training loss: 2.8405156449187743
Validation loss: 2.4999163316241404

Epoch: 5| Step: 3
Training loss: 2.274662068179373
Validation loss: 2.498678699104378

Epoch: 5| Step: 4
Training loss: 2.964778130449725
Validation loss: 2.516056094934623

Epoch: 5| Step: 5
Training loss: 2.843112245247223
Validation loss: 2.530222848557851

Epoch: 5| Step: 6
Training loss: 3.143411946559261
Validation loss: 2.5688633598063477

Epoch: 5| Step: 7
Training loss: 2.7192017629332073
Validation loss: 2.582726122071305

Epoch: 5| Step: 8
Training loss: 2.834326925153897
Validation loss: 2.6325183644586296

Epoch: 5| Step: 9
Training loss: 3.5373137408175377
Validation loss: 2.684655858763735

Epoch: 5| Step: 10
Training loss: 2.914169350472766
Validation loss: 2.635283465855418

Epoch: 124| Step: 0
Training loss: 2.8363004930287925
Validation loss: 2.609608853477782

Epoch: 5| Step: 1
Training loss: 2.874402357262808
Validation loss: 2.584519083067521

Epoch: 5| Step: 2
Training loss: 3.0772355241961105
Validation loss: 2.564242395125257

Epoch: 5| Step: 3
Training loss: 2.8429210418782307
Validation loss: 2.5975222119767913

Epoch: 5| Step: 4
Training loss: 2.5848357743534107
Validation loss: 2.5839179522365505

Epoch: 5| Step: 5
Training loss: 2.8141198473842395
Validation loss: 2.5715854560985507

Epoch: 5| Step: 6
Training loss: 2.7650860622318922
Validation loss: 2.58932658382022

Epoch: 5| Step: 7
Training loss: 3.235430706425205
Validation loss: 2.581158851826392

Epoch: 5| Step: 8
Training loss: 2.8620409601614023
Validation loss: 2.550134809912935

Epoch: 5| Step: 9
Training loss: 2.6805270912183246
Validation loss: 2.5206764105906148

Epoch: 5| Step: 10
Training loss: 3.048110476676878
Validation loss: 2.515837164958341

Epoch: 125| Step: 0
Training loss: 3.2222830631460804
Validation loss: 2.505506062429401

Epoch: 5| Step: 1
Training loss: 3.4422513549810887
Validation loss: 2.5079970400679388

Epoch: 5| Step: 2
Training loss: 2.8329467135668436
Validation loss: 2.519904372706845

Epoch: 5| Step: 3
Training loss: 3.084503999773964
Validation loss: 2.5178187613681815

Epoch: 5| Step: 4
Training loss: 2.7620355621302504
Validation loss: 2.513186858504133

Epoch: 5| Step: 5
Training loss: 2.4483182428915042
Validation loss: 2.510338385604826

Epoch: 5| Step: 6
Training loss: 2.880648827051802
Validation loss: 2.5135080159325165

Epoch: 5| Step: 7
Training loss: 2.880162952104667
Validation loss: 2.504865416735627

Epoch: 5| Step: 8
Training loss: 2.053915364625019
Validation loss: 2.5014277606069983

Epoch: 5| Step: 9
Training loss: 2.653417355949862
Validation loss: 2.5038441492629153

Epoch: 5| Step: 10
Training loss: 2.9874528123009907
Validation loss: 2.543746670726855

Epoch: 126| Step: 0
Training loss: 3.0328286376398
Validation loss: 2.534895311455057

Epoch: 5| Step: 1
Training loss: 2.5062972865792674
Validation loss: 2.524484160113659

Epoch: 5| Step: 2
Training loss: 2.672992138132849
Validation loss: 2.509514567728378

Epoch: 5| Step: 3
Training loss: 2.701428184016454
Validation loss: 2.4942561790531865

Epoch: 5| Step: 4
Training loss: 2.949995855554805
Validation loss: 2.4891395164671297

Epoch: 5| Step: 5
Training loss: 3.1398868737221965
Validation loss: 2.486330828529765

Epoch: 5| Step: 6
Training loss: 3.070108266157755
Validation loss: 2.4878569112502684

Epoch: 5| Step: 7
Training loss: 3.2377086910899466
Validation loss: 2.484483232163774

Epoch: 5| Step: 8
Training loss: 3.1807007920718546
Validation loss: 2.483952250067626

Epoch: 5| Step: 9
Training loss: 2.526692844631025
Validation loss: 2.484462646457297

Epoch: 5| Step: 10
Training loss: 2.113452840949897
Validation loss: 2.4845657755220545

Epoch: 127| Step: 0
Training loss: 2.7720956914494295
Validation loss: 2.482383695138591

Epoch: 5| Step: 1
Training loss: 2.3982240662681185
Validation loss: 2.4891031534763

Epoch: 5| Step: 2
Training loss: 3.0308283876412454
Validation loss: 2.501049682764519

Epoch: 5| Step: 3
Training loss: 2.645406423254385
Validation loss: 2.487952606303585

Epoch: 5| Step: 4
Training loss: 3.161762673289928
Validation loss: 2.488778088654652

Epoch: 5| Step: 5
Training loss: 2.4266221313616807
Validation loss: 2.4949939361570257

Epoch: 5| Step: 6
Training loss: 2.690407710323124
Validation loss: 2.4864132466262774

Epoch: 5| Step: 7
Training loss: 2.599364122247373
Validation loss: 2.481774130974642

Epoch: 5| Step: 8
Training loss: 3.472169307729404
Validation loss: 2.48951679569367

Epoch: 5| Step: 9
Training loss: 2.799389609153733
Validation loss: 2.4744459772422576

Epoch: 5| Step: 10
Training loss: 3.049963691370236
Validation loss: 2.4861198175440964

Epoch: 128| Step: 0
Training loss: 3.0503535831804607
Validation loss: 2.4976935278465855

Epoch: 5| Step: 1
Training loss: 2.8521047416275502
Validation loss: 2.4943288590947263

Epoch: 5| Step: 2
Training loss: 3.2564162960531755
Validation loss: 2.4978037662497896

Epoch: 5| Step: 3
Training loss: 2.696047652233772
Validation loss: 2.4986952463536416

Epoch: 5| Step: 4
Training loss: 3.0757491338989555
Validation loss: 2.4930189419091007

Epoch: 5| Step: 5
Training loss: 2.249456127979406
Validation loss: 2.4935265324706797

Epoch: 5| Step: 6
Training loss: 3.1320215306425023
Validation loss: 2.4901195022046916

Epoch: 5| Step: 7
Training loss: 2.8744534512020614
Validation loss: 2.493099437079914

Epoch: 5| Step: 8
Training loss: 2.556333985383017
Validation loss: 2.494220144532339

Epoch: 5| Step: 9
Training loss: 2.691488455747465
Validation loss: 2.4847294312177626

Epoch: 5| Step: 10
Training loss: 2.5364150109530748
Validation loss: 2.4908523112666483

Epoch: 129| Step: 0
Training loss: 2.4351648736237466
Validation loss: 2.491705282402301

Epoch: 5| Step: 1
Training loss: 2.6653532330163086
Validation loss: 2.485327035367203

Epoch: 5| Step: 2
Training loss: 2.8827393892109634
Validation loss: 2.4824429356360067

Epoch: 5| Step: 3
Training loss: 2.5096787968321848
Validation loss: 2.4774078316665165

Epoch: 5| Step: 4
Training loss: 3.0632665803573125
Validation loss: 2.484829535566789

Epoch: 5| Step: 5
Training loss: 2.6355347638313416
Validation loss: 2.48556342567411

Epoch: 5| Step: 6
Training loss: 2.868080935444169
Validation loss: 2.4831303451663627

Epoch: 5| Step: 7
Training loss: 3.1810187474945226
Validation loss: 2.4816373576491983

Epoch: 5| Step: 8
Training loss: 3.043535172481233
Validation loss: 2.4836102907742936

Epoch: 5| Step: 9
Training loss: 3.0423793393284404
Validation loss: 2.4846873954744977

Epoch: 5| Step: 10
Training loss: 2.646998371730487
Validation loss: 2.4906146453046407

Epoch: 130| Step: 0
Training loss: 3.0326610309209956
Validation loss: 2.48189924011847

Epoch: 5| Step: 1
Training loss: 2.7666501661367793
Validation loss: 2.486295662822457

Epoch: 5| Step: 2
Training loss: 2.6585017813604304
Validation loss: 2.4790280238619573

Epoch: 5| Step: 3
Training loss: 2.9767643417047513
Validation loss: 2.4779079606477183

Epoch: 5| Step: 4
Training loss: 2.805425010346557
Validation loss: 2.476015787753288

Epoch: 5| Step: 5
Training loss: 2.9969500296610962
Validation loss: 2.4785797618447125

Epoch: 5| Step: 6
Training loss: 2.813272073524719
Validation loss: 2.4815247419321578

Epoch: 5| Step: 7
Training loss: 2.145470363201557
Validation loss: 2.483423607190161

Epoch: 5| Step: 8
Training loss: 3.0517284373586224
Validation loss: 2.4802432264467678

Epoch: 5| Step: 9
Training loss: 2.9666281093992115
Validation loss: 2.4782218137381986

Epoch: 5| Step: 10
Training loss: 2.7779118081712117
Validation loss: 2.47543028447948

Epoch: 131| Step: 0
Training loss: 2.720952249199816
Validation loss: 2.48751909583909

Epoch: 5| Step: 1
Training loss: 3.0237393487283013
Validation loss: 2.4893306776113073

Epoch: 5| Step: 2
Training loss: 2.8234433366707794
Validation loss: 2.498948003046061

Epoch: 5| Step: 3
Training loss: 2.483812184431282
Validation loss: 2.501475299818965

Epoch: 5| Step: 4
Training loss: 3.198016153749245
Validation loss: 2.5085418543227864

Epoch: 5| Step: 5
Training loss: 3.116859055427262
Validation loss: 2.510175477300704

Epoch: 5| Step: 6
Training loss: 2.724559233829619
Validation loss: 2.4848728363479706

Epoch: 5| Step: 7
Training loss: 2.644470664926395
Validation loss: 2.47741480833003

Epoch: 5| Step: 8
Training loss: 2.455400517068193
Validation loss: 2.470764196236827

Epoch: 5| Step: 9
Training loss: 2.8549961267769057
Validation loss: 2.472591017032201

Epoch: 5| Step: 10
Training loss: 3.025570297077659
Validation loss: 2.4686141687411896

Epoch: 132| Step: 0
Training loss: 3.0079448720364623
Validation loss: 2.471038628783128

Epoch: 5| Step: 1
Training loss: 2.967545114253017
Validation loss: 2.4677622085702073

Epoch: 5| Step: 2
Training loss: 2.5735671936595637
Validation loss: 2.4703601110560682

Epoch: 5| Step: 3
Training loss: 3.4945348577994593
Validation loss: 2.4708703051919896

Epoch: 5| Step: 4
Training loss: 2.3862091369487226
Validation loss: 2.4731093651511458

Epoch: 5| Step: 5
Training loss: 2.818455642250987
Validation loss: 2.47603185487471

Epoch: 5| Step: 6
Training loss: 2.8982404040340053
Validation loss: 2.4763814509891082

Epoch: 5| Step: 7
Training loss: 2.5870188500683815
Validation loss: 2.4875643012123634

Epoch: 5| Step: 8
Training loss: 2.3653103779206073
Validation loss: 2.4982654111909426

Epoch: 5| Step: 9
Training loss: 3.0160054179378184
Validation loss: 2.508093388491518

Epoch: 5| Step: 10
Training loss: 2.649663230801948
Validation loss: 2.516726371525782

Epoch: 133| Step: 0
Training loss: 2.971033282370565
Validation loss: 2.510967478275912

Epoch: 5| Step: 1
Training loss: 2.135881612140027
Validation loss: 2.52689684663913

Epoch: 5| Step: 2
Training loss: 3.055948528874924
Validation loss: 2.508996445267052

Epoch: 5| Step: 3
Training loss: 2.7055169255734124
Validation loss: 2.490545102413528

Epoch: 5| Step: 4
Training loss: 3.198737139659221
Validation loss: 2.481816120511615

Epoch: 5| Step: 5
Training loss: 2.6616830351470937
Validation loss: 2.48059503907056

Epoch: 5| Step: 6
Training loss: 2.645785914519304
Validation loss: 2.473023555469954

Epoch: 5| Step: 7
Training loss: 2.424251940466525
Validation loss: 2.4798330926385495

Epoch: 5| Step: 8
Training loss: 3.2775263411498545
Validation loss: 2.4714782207222195

Epoch: 5| Step: 9
Training loss: 2.636386516974005
Validation loss: 2.46561200363731

Epoch: 5| Step: 10
Training loss: 3.0545404501250584
Validation loss: 2.467807262147664

Epoch: 134| Step: 0
Training loss: 3.328178154605968
Validation loss: 2.46760491507437

Epoch: 5| Step: 1
Training loss: 2.705476741134558
Validation loss: 2.4745499195137985

Epoch: 5| Step: 2
Training loss: 3.1115278142819633
Validation loss: 2.4759664095378433

Epoch: 5| Step: 3
Training loss: 2.9450311096309894
Validation loss: 2.482371981848359

Epoch: 5| Step: 4
Training loss: 2.6016328819308367
Validation loss: 2.4811617936549006

Epoch: 5| Step: 5
Training loss: 3.1585983755647247
Validation loss: 2.4770683273285505

Epoch: 5| Step: 6
Training loss: 2.48187782934907
Validation loss: 2.4831932447349834

Epoch: 5| Step: 7
Training loss: 2.915179900021147
Validation loss: 2.4811179579747678

Epoch: 5| Step: 8
Training loss: 2.192580834772232
Validation loss: 2.4865168834999176

Epoch: 5| Step: 9
Training loss: 2.3558642812863435
Validation loss: 2.483379781497448

Epoch: 5| Step: 10
Training loss: 3.2132557020926997
Validation loss: 2.484398653229045

Epoch: 135| Step: 0
Training loss: 2.7017983946395963
Validation loss: 2.503035949751052

Epoch: 5| Step: 1
Training loss: 2.5623615506615365
Validation loss: 2.4985399002221613

Epoch: 5| Step: 2
Training loss: 3.1868653507090325
Validation loss: 2.496791738607366

Epoch: 5| Step: 3
Training loss: 3.0665082586535823
Validation loss: 2.4921717890605772

Epoch: 5| Step: 4
Training loss: 2.5900725987101896
Validation loss: 2.4982596523281075

Epoch: 5| Step: 5
Training loss: 2.9604027901918655
Validation loss: 2.4967822337431165

Epoch: 5| Step: 6
Training loss: 2.5481243228794495
Validation loss: 2.50763108236803

Epoch: 5| Step: 7
Training loss: 2.943597835811499
Validation loss: 2.5054877061052365

Epoch: 5| Step: 8
Training loss: 2.9790843783309215
Validation loss: 2.4812677203993907

Epoch: 5| Step: 9
Training loss: 2.701963053673071
Validation loss: 2.468622761224361

Epoch: 5| Step: 10
Training loss: 2.570744625974412
Validation loss: 2.463237570330576

Epoch: 136| Step: 0
Training loss: 3.055598208582483
Validation loss: 2.4767098600846866

Epoch: 5| Step: 1
Training loss: 2.553606370349577
Validation loss: 2.4640802195706613

Epoch: 5| Step: 2
Training loss: 3.096567893559156
Validation loss: 2.470401781952965

Epoch: 5| Step: 3
Training loss: 2.781884967457851
Validation loss: 2.471052776788285

Epoch: 5| Step: 4
Training loss: 2.54003690362389
Validation loss: 2.4746431051747226

Epoch: 5| Step: 5
Training loss: 2.859390675652899
Validation loss: 2.4790853233845875

Epoch: 5| Step: 6
Training loss: 2.509437581157253
Validation loss: 2.4953749040413165

Epoch: 5| Step: 7
Training loss: 2.6476830952471757
Validation loss: 2.5339985444332083

Epoch: 5| Step: 8
Training loss: 3.0653486432521015
Validation loss: 2.546953639075823

Epoch: 5| Step: 9
Training loss: 3.192918398212526
Validation loss: 2.5530479523452994

Epoch: 5| Step: 10
Training loss: 2.711113300174948
Validation loss: 2.5477920804691574

Epoch: 137| Step: 0
Training loss: 3.0087069680053142
Validation loss: 2.5314262730839663

Epoch: 5| Step: 1
Training loss: 3.2096743732845443
Validation loss: 2.487441403770708

Epoch: 5| Step: 2
Training loss: 2.30381484240031
Validation loss: 2.4725616063200127

Epoch: 5| Step: 3
Training loss: 2.631588342800434
Validation loss: 2.471367912799288

Epoch: 5| Step: 4
Training loss: 3.2269867625028543
Validation loss: 2.4626926531444493

Epoch: 5| Step: 5
Training loss: 2.8640402169201016
Validation loss: 2.4682484838170384

Epoch: 5| Step: 6
Training loss: 2.917381217257882
Validation loss: 2.4709899338986197

Epoch: 5| Step: 7
Training loss: 2.7967766259650473
Validation loss: 2.4719733102966317

Epoch: 5| Step: 8
Training loss: 2.6736383698189923
Validation loss: 2.4679475546897187

Epoch: 5| Step: 9
Training loss: 2.7328243545440873
Validation loss: 2.461833633785802

Epoch: 5| Step: 10
Training loss: 2.5433374656187047
Validation loss: 2.479699133916714

Epoch: 138| Step: 0
Training loss: 3.06010093921405
Validation loss: 2.4937947469525006

Epoch: 5| Step: 1
Training loss: 2.628619196780574
Validation loss: 2.5063690323808085

Epoch: 5| Step: 2
Training loss: 2.6382463565289043
Validation loss: 2.5109364424180907

Epoch: 5| Step: 3
Training loss: 2.3860792436446667
Validation loss: 2.518204320767695

Epoch: 5| Step: 4
Training loss: 3.3334645881242415
Validation loss: 2.5104476367863118

Epoch: 5| Step: 5
Training loss: 2.4221458037548476
Validation loss: 2.5275575470962246

Epoch: 5| Step: 6
Training loss: 2.4976015029457943
Validation loss: 2.5529013720008376

Epoch: 5| Step: 7
Training loss: 3.1483720720559
Validation loss: 2.5569648683403696

Epoch: 5| Step: 8
Training loss: 2.470898912233918
Validation loss: 2.541006042412459

Epoch: 5| Step: 9
Training loss: 2.6129624609953357
Validation loss: 2.5031257551863266

Epoch: 5| Step: 10
Training loss: 3.494226325632914
Validation loss: 2.491676187848604

Epoch: 139| Step: 0
Training loss: 2.351704336559036
Validation loss: 2.472577355807156

Epoch: 5| Step: 1
Training loss: 2.9234800775017784
Validation loss: 2.468798133149301

Epoch: 5| Step: 2
Training loss: 2.6260778848061364
Validation loss: 2.469837154438835

Epoch: 5| Step: 3
Training loss: 2.6381870730792114
Validation loss: 2.4694757377443985

Epoch: 5| Step: 4
Training loss: 3.2493094664354443
Validation loss: 2.478992896238855

Epoch: 5| Step: 5
Training loss: 3.169887577795051
Validation loss: 2.4792196306579264

Epoch: 5| Step: 6
Training loss: 2.4784369369773622
Validation loss: 2.4790095635142175

Epoch: 5| Step: 7
Training loss: 2.885191558613573
Validation loss: 2.483537614990923

Epoch: 5| Step: 8
Training loss: 2.819243505883287
Validation loss: 2.484517505180909

Epoch: 5| Step: 9
Training loss: 2.496984952527631
Validation loss: 2.4761687504310426

Epoch: 5| Step: 10
Training loss: 3.1397758588548412
Validation loss: 2.500941728809803

Epoch: 140| Step: 0
Training loss: 3.027524881174047
Validation loss: 2.514088798490483

Epoch: 5| Step: 1
Training loss: 2.9298614857191607
Validation loss: 2.510027682760422

Epoch: 5| Step: 2
Training loss: 2.913005074514624
Validation loss: 2.5358783838593655

Epoch: 5| Step: 3
Training loss: 2.970489474206167
Validation loss: 2.5600649020565074

Epoch: 5| Step: 4
Training loss: 2.737261572779657
Validation loss: 2.5575545585841013

Epoch: 5| Step: 5
Training loss: 2.4532142185582226
Validation loss: 2.504829416115884

Epoch: 5| Step: 6
Training loss: 3.0962355676283067
Validation loss: 2.5096233225590527

Epoch: 5| Step: 7
Training loss: 2.387639693722098
Validation loss: 2.4822997975549437

Epoch: 5| Step: 8
Training loss: 3.0632958448549283
Validation loss: 2.47018071529228

Epoch: 5| Step: 9
Training loss: 2.845056589968303
Validation loss: 2.469924209293476

Epoch: 5| Step: 10
Training loss: 2.269968223853516
Validation loss: 2.476688546263348

Epoch: 141| Step: 0
Training loss: 2.8007891666827183
Validation loss: 2.467500072454769

Epoch: 5| Step: 1
Training loss: 2.9491683046182433
Validation loss: 2.4648343153943744

Epoch: 5| Step: 2
Training loss: 2.5051210405417326
Validation loss: 2.4773853865863953

Epoch: 5| Step: 3
Training loss: 2.3582096885196777
Validation loss: 2.4865726155185026

Epoch: 5| Step: 4
Training loss: 2.3349757431371354
Validation loss: 2.489677685534516

Epoch: 5| Step: 5
Training loss: 3.2285620010469818
Validation loss: 2.49050878053242

Epoch: 5| Step: 6
Training loss: 2.4052653093777603
Validation loss: 2.4965715598215117

Epoch: 5| Step: 7
Training loss: 2.9135493013247604
Validation loss: 2.4909137211140013

Epoch: 5| Step: 8
Training loss: 2.7873361411066457
Validation loss: 2.482946656916586

Epoch: 5| Step: 9
Training loss: 3.309210385415071
Validation loss: 2.4957180084132484

Epoch: 5| Step: 10
Training loss: 2.9336990764214543
Validation loss: 2.4804875002433255

Epoch: 142| Step: 0
Training loss: 3.0191108440559598
Validation loss: 2.4804237972078402

Epoch: 5| Step: 1
Training loss: 2.8785342179266196
Validation loss: 2.4735192965112702

Epoch: 5| Step: 2
Training loss: 3.3547191915094525
Validation loss: 2.4798488641746586

Epoch: 5| Step: 3
Training loss: 2.560087044845362
Validation loss: 2.4726807089384844

Epoch: 5| Step: 4
Training loss: 2.9374064978469954
Validation loss: 2.4720496456607424

Epoch: 5| Step: 5
Training loss: 2.486902450789667
Validation loss: 2.476590369479763

Epoch: 5| Step: 6
Training loss: 3.330321397593195
Validation loss: 2.483202674628993

Epoch: 5| Step: 7
Training loss: 2.635761997279901
Validation loss: 2.4836456679146024

Epoch: 5| Step: 8
Training loss: 2.3861984459976586
Validation loss: 2.48691639618317

Epoch: 5| Step: 9
Training loss: 2.107176023042152
Validation loss: 2.5306686479189726

Epoch: 5| Step: 10
Training loss: 2.660049503554143
Validation loss: 2.5064270846073553

Epoch: 143| Step: 0
Training loss: 3.018158002030332
Validation loss: 2.5054456364637057

Epoch: 5| Step: 1
Training loss: 2.9322415624824485
Validation loss: 2.4955655628981206

Epoch: 5| Step: 2
Training loss: 2.8193273963706353
Validation loss: 2.496908370212934

Epoch: 5| Step: 3
Training loss: 3.2371537071222236
Validation loss: 2.487556171447762

Epoch: 5| Step: 4
Training loss: 2.505616840093299
Validation loss: 2.4862922405709313

Epoch: 5| Step: 5
Training loss: 2.292921855388494
Validation loss: 2.4886088077843165

Epoch: 5| Step: 6
Training loss: 2.4998681033626964
Validation loss: 2.484085718330153

Epoch: 5| Step: 7
Training loss: 2.5911707175639807
Validation loss: 2.4806079389106004

Epoch: 5| Step: 8
Training loss: 3.0601956787374047
Validation loss: 2.4851637088990595

Epoch: 5| Step: 9
Training loss: 2.361708339878955
Validation loss: 2.4868243209153564

Epoch: 5| Step: 10
Training loss: 3.1221567570922724
Validation loss: 2.4856974087063795

Epoch: 144| Step: 0
Training loss: 2.482140453843211
Validation loss: 2.481322143502721

Epoch: 5| Step: 1
Training loss: 2.8987380537713863
Validation loss: 2.494398312940267

Epoch: 5| Step: 2
Training loss: 2.5790765104626248
Validation loss: 2.4841659136991714

Epoch: 5| Step: 3
Training loss: 2.62622159961594
Validation loss: 2.465620352882616

Epoch: 5| Step: 4
Training loss: 2.5581011348890805
Validation loss: 2.4622574617592905

Epoch: 5| Step: 5
Training loss: 2.9098157440265133
Validation loss: 2.461489744218023

Epoch: 5| Step: 6
Training loss: 2.8420361395195104
Validation loss: 2.4618291684552194

Epoch: 5| Step: 7
Training loss: 2.914558920622849
Validation loss: 2.4544276163746845

Epoch: 5| Step: 8
Training loss: 2.4770533318998056
Validation loss: 2.4575958174587877

Epoch: 5| Step: 9
Training loss: 2.8632337870703792
Validation loss: 2.462029076744115

Epoch: 5| Step: 10
Training loss: 3.402599093012363
Validation loss: 2.4659913490000682

Epoch: 145| Step: 0
Training loss: 2.605739047600871
Validation loss: 2.4654259048261076

Epoch: 5| Step: 1
Training loss: 2.9576655605793745
Validation loss: 2.467606458906922

Epoch: 5| Step: 2
Training loss: 3.023155810420156
Validation loss: 2.4762727415166723

Epoch: 5| Step: 3
Training loss: 2.806213303901653
Validation loss: 2.49891702719342

Epoch: 5| Step: 4
Training loss: 2.155790528810178
Validation loss: 2.5044907823192117

Epoch: 5| Step: 5
Training loss: 2.6893571159163545
Validation loss: 2.5097982279448776

Epoch: 5| Step: 6
Training loss: 2.879467851165558
Validation loss: 2.5005925265953617

Epoch: 5| Step: 7
Training loss: 3.132605186699611
Validation loss: 2.502515094783634

Epoch: 5| Step: 8
Training loss: 2.6034570159382104
Validation loss: 2.4982980185003387

Epoch: 5| Step: 9
Training loss: 2.4257634602998555
Validation loss: 2.496341510016609

Epoch: 5| Step: 10
Training loss: 3.176726591166129
Validation loss: 2.4797888075393573

Epoch: 146| Step: 0
Training loss: 2.246541862568111
Validation loss: 2.4636657998534233

Epoch: 5| Step: 1
Training loss: 2.839782294404671
Validation loss: 2.4487602394923145

Epoch: 5| Step: 2
Training loss: 3.291345379436543
Validation loss: 2.4471517994257854

Epoch: 5| Step: 3
Training loss: 3.114770549816299
Validation loss: 2.4500073897196106

Epoch: 5| Step: 4
Training loss: 2.4258627271252826
Validation loss: 2.4572062034980315

Epoch: 5| Step: 5
Training loss: 2.6717997757879677
Validation loss: 2.460785489743531

Epoch: 5| Step: 6
Training loss: 2.1292127476114415
Validation loss: 2.4637876705749524

Epoch: 5| Step: 7
Training loss: 2.1944764197980255
Validation loss: 2.4742511804350156

Epoch: 5| Step: 8
Training loss: 3.100908109492383
Validation loss: 2.4800506288485833

Epoch: 5| Step: 9
Training loss: 3.494910763541351
Validation loss: 2.477652845450925

Epoch: 5| Step: 10
Training loss: 2.6797019135112543
Validation loss: 2.4724970168209115

Epoch: 147| Step: 0
Training loss: 2.7037761984308486
Validation loss: 2.4704267530217545

Epoch: 5| Step: 1
Training loss: 3.0147941116710775
Validation loss: 2.4678471447177004

Epoch: 5| Step: 2
Training loss: 2.864245326590157
Validation loss: 2.459774188110553

Epoch: 5| Step: 3
Training loss: 2.6851663437787625
Validation loss: 2.4636828424089137

Epoch: 5| Step: 4
Training loss: 3.135725916484958
Validation loss: 2.4637085444158076

Epoch: 5| Step: 5
Training loss: 2.7099811725032823
Validation loss: 2.468281630997482

Epoch: 5| Step: 6
Training loss: 2.327298625753175
Validation loss: 2.49571042960456

Epoch: 5| Step: 7
Training loss: 3.1509545348339794
Validation loss: 2.4759595147323665

Epoch: 5| Step: 8
Training loss: 2.600014532488777
Validation loss: 2.485713561762271

Epoch: 5| Step: 9
Training loss: 2.193136637002636
Validation loss: 2.491278579679947

Epoch: 5| Step: 10
Training loss: 2.9732665389160773
Validation loss: 2.4782995367393554

Epoch: 148| Step: 0
Training loss: 2.1288439820308818
Validation loss: 2.474967555014376

Epoch: 5| Step: 1
Training loss: 2.7097884939503674
Validation loss: 2.4762843946236233

Epoch: 5| Step: 2
Training loss: 2.165760792359789
Validation loss: 2.4714906992942454

Epoch: 5| Step: 3
Training loss: 2.821775442671643
Validation loss: 2.479341074957284

Epoch: 5| Step: 4
Training loss: 3.119758176968797
Validation loss: 2.4807923449285907

Epoch: 5| Step: 5
Training loss: 2.654591929223673
Validation loss: 2.46522459563701

Epoch: 5| Step: 6
Training loss: 2.732650125607809
Validation loss: 2.4678598379853662

Epoch: 5| Step: 7
Training loss: 2.859932266713747
Validation loss: 2.454367058863948

Epoch: 5| Step: 8
Training loss: 2.804737398771606
Validation loss: 2.4687862245605343

Epoch: 5| Step: 9
Training loss: 3.5028831323572067
Validation loss: 2.466972758104247

Epoch: 5| Step: 10
Training loss: 2.5594352444928066
Validation loss: 2.468338521506159

Epoch: 149| Step: 0
Training loss: 2.621290492307607
Validation loss: 2.4497097338581915

Epoch: 5| Step: 1
Training loss: 2.5721420687094163
Validation loss: 2.4563644325745133

Epoch: 5| Step: 2
Training loss: 3.262182145693979
Validation loss: 2.464524631017681

Epoch: 5| Step: 3
Training loss: 2.69527525945174
Validation loss: 2.4814205473617075

Epoch: 5| Step: 4
Training loss: 2.9398185832304566
Validation loss: 2.4916764882821125

Epoch: 5| Step: 5
Training loss: 2.231441145544523
Validation loss: 2.479842136266305

Epoch: 5| Step: 6
Training loss: 2.540135271420213
Validation loss: 2.4771157730992006

Epoch: 5| Step: 7
Training loss: 2.688421047204247
Validation loss: 2.480077981564686

Epoch: 5| Step: 8
Training loss: 2.5053690477450963
Validation loss: 2.477597518103823

Epoch: 5| Step: 9
Training loss: 2.919748766816783
Validation loss: 2.479720913970328

Epoch: 5| Step: 10
Training loss: 3.405181577213101
Validation loss: 2.4840081366406284

Epoch: 150| Step: 0
Training loss: 2.718724743955967
Validation loss: 2.473032021194176

Epoch: 5| Step: 1
Training loss: 2.6006900825231893
Validation loss: 2.4782084613092663

Epoch: 5| Step: 2
Training loss: 2.8990389053455337
Validation loss: 2.46795481882811

Epoch: 5| Step: 3
Training loss: 2.7804379081248154
Validation loss: 2.481283275145247

Epoch: 5| Step: 4
Training loss: 2.5476836810467414
Validation loss: 2.467636751490474

Epoch: 5| Step: 5
Training loss: 2.9368308096429003
Validation loss: 2.4617871191812006

Epoch: 5| Step: 6
Training loss: 2.936570690144014
Validation loss: 2.4742873389616378

Epoch: 5| Step: 7
Training loss: 2.701943288059701
Validation loss: 2.4753757888000925

Epoch: 5| Step: 8
Training loss: 2.965325558883209
Validation loss: 2.464755046015353

Epoch: 5| Step: 9
Training loss: 2.601451332993441
Validation loss: 2.4665125236085275

Epoch: 5| Step: 10
Training loss: 2.685441759306456
Validation loss: 2.481515891426612

Epoch: 151| Step: 0
Training loss: 3.1329029098745136
Validation loss: 2.4676069284977893

Epoch: 5| Step: 1
Training loss: 2.572373326392278
Validation loss: 2.461302817100375

Epoch: 5| Step: 2
Training loss: 2.8173406693663487
Validation loss: 2.4556467181647923

Epoch: 5| Step: 3
Training loss: 2.8449664186664565
Validation loss: 2.4450092659061746

Epoch: 5| Step: 4
Training loss: 2.692845373644737
Validation loss: 2.449003242277047

Epoch: 5| Step: 5
Training loss: 3.0282381176365463
Validation loss: 2.4508830309307585

Epoch: 5| Step: 6
Training loss: 2.7507366580918666
Validation loss: 2.44695191512421

Epoch: 5| Step: 7
Training loss: 2.9975087630372097
Validation loss: 2.4629739461318043

Epoch: 5| Step: 8
Training loss: 2.5513844266144226
Validation loss: 2.454583477435156

Epoch: 5| Step: 9
Training loss: 1.7046479581587757
Validation loss: 2.464942580809857

Epoch: 5| Step: 10
Training loss: 3.024872353122615
Validation loss: 2.494185332628984

Epoch: 152| Step: 0
Training loss: 2.813266903905035
Validation loss: 2.495915904964577

Epoch: 5| Step: 1
Training loss: 3.167564432140678
Validation loss: 2.492915732683335

Epoch: 5| Step: 2
Training loss: 2.7465630641706205
Validation loss: 2.5016239521573382

Epoch: 5| Step: 3
Training loss: 2.4319569087100934
Validation loss: 2.4910907521248262

Epoch: 5| Step: 4
Training loss: 3.026100582702647
Validation loss: 2.486101310861752

Epoch: 5| Step: 5
Training loss: 2.835011901292259
Validation loss: 2.4765742159232125

Epoch: 5| Step: 6
Training loss: 2.41451488811479
Validation loss: 2.466850451332859

Epoch: 5| Step: 7
Training loss: 2.5904346097001887
Validation loss: 2.454970423919153

Epoch: 5| Step: 8
Training loss: 2.609483179830886
Validation loss: 2.4514088806531986

Epoch: 5| Step: 9
Training loss: 2.749185094602982
Validation loss: 2.449522006167681

Epoch: 5| Step: 10
Training loss: 2.9638768404908706
Validation loss: 2.450124913250591

Epoch: 153| Step: 0
Training loss: 2.905924953208393
Validation loss: 2.441267218193466

Epoch: 5| Step: 1
Training loss: 2.8447629361195856
Validation loss: 2.4549657456057696

Epoch: 5| Step: 2
Training loss: 3.1653441294180955
Validation loss: 2.4775094745999895

Epoch: 5| Step: 3
Training loss: 2.74809042781541
Validation loss: 2.4758197134657545

Epoch: 5| Step: 4
Training loss: 2.9326030414556423
Validation loss: 2.4701168938265656

Epoch: 5| Step: 5
Training loss: 2.6495785576008024
Validation loss: 2.474109551687762

Epoch: 5| Step: 6
Training loss: 2.29509837669005
Validation loss: 2.4764583450971203

Epoch: 5| Step: 7
Training loss: 2.8067151234295467
Validation loss: 2.4671455580956367

Epoch: 5| Step: 8
Training loss: 2.5886729544203746
Validation loss: 2.46397933882573

Epoch: 5| Step: 9
Training loss: 2.2435775860607254
Validation loss: 2.4721901381763

Epoch: 5| Step: 10
Training loss: 3.0217297681843016
Validation loss: 2.4861732022657175

Epoch: 154| Step: 0
Training loss: 2.729212306759709
Validation loss: 2.4965396467234955

Epoch: 5| Step: 1
Training loss: 2.9523824737181603
Validation loss: 2.4931024026797153

Epoch: 5| Step: 2
Training loss: 2.9554708538809256
Validation loss: 2.4900672151623198

Epoch: 5| Step: 3
Training loss: 2.4488470595530343
Validation loss: 2.502326830026016

Epoch: 5| Step: 4
Training loss: 2.656077211033305
Validation loss: 2.4960542735698135

Epoch: 5| Step: 5
Training loss: 2.7812854035942336
Validation loss: 2.4622433298519897

Epoch: 5| Step: 6
Training loss: 3.184678268591425
Validation loss: 2.4429870186916354

Epoch: 5| Step: 7
Training loss: 2.863653931556968
Validation loss: 2.4553645095320484

Epoch: 5| Step: 8
Training loss: 2.727836507988106
Validation loss: 2.455873146508426

Epoch: 5| Step: 9
Training loss: 2.2104451740043345
Validation loss: 2.4708595862850533

Epoch: 5| Step: 10
Training loss: 3.0569806869540663
Validation loss: 2.4798052771771

Epoch: 155| Step: 0
Training loss: 3.3009699118605713
Validation loss: 2.469775436437376

Epoch: 5| Step: 1
Training loss: 3.2047082477197404
Validation loss: 2.46252918924668

Epoch: 5| Step: 2
Training loss: 3.0443229746969322
Validation loss: 2.46145011067237

Epoch: 5| Step: 3
Training loss: 2.632298812786064
Validation loss: 2.4513801967615443

Epoch: 5| Step: 4
Training loss: 2.5209500834854492
Validation loss: 2.4659483768262143

Epoch: 5| Step: 5
Training loss: 2.607187233414694
Validation loss: 2.482411874143106

Epoch: 5| Step: 6
Training loss: 2.58408282287777
Validation loss: 2.5101459043819214

Epoch: 5| Step: 7
Training loss: 2.3777110036444307
Validation loss: 2.532703705866938

Epoch: 5| Step: 8
Training loss: 2.6750761787761967
Validation loss: 2.5233582367648015

Epoch: 5| Step: 9
Training loss: 2.9776365890370284
Validation loss: 2.4992851824853255

Epoch: 5| Step: 10
Training loss: 2.8668329087189006
Validation loss: 2.470543840131079

Epoch: 156| Step: 0
Training loss: 3.0373514649294027
Validation loss: 2.456227951871411

Epoch: 5| Step: 1
Training loss: 2.0339078680382072
Validation loss: 2.4400890663005343

Epoch: 5| Step: 2
Training loss: 3.0068817680312847
Validation loss: 2.4437344005732946

Epoch: 5| Step: 3
Training loss: 3.2621666515074046
Validation loss: 2.452388748826413

Epoch: 5| Step: 4
Training loss: 3.3491026914975004
Validation loss: 2.4532574932079476

Epoch: 5| Step: 5
Training loss: 2.217714309744056
Validation loss: 2.4549098797983477

Epoch: 5| Step: 6
Training loss: 2.5927916445335306
Validation loss: 2.449558328785729

Epoch: 5| Step: 7
Training loss: 2.26246938948183
Validation loss: 2.442951438941092

Epoch: 5| Step: 8
Training loss: 3.1457189745464054
Validation loss: 2.446213710109806

Epoch: 5| Step: 9
Training loss: 2.7323546002540633
Validation loss: 2.4635707316977467

Epoch: 5| Step: 10
Training loss: 2.432984399816858
Validation loss: 2.470998554951424

Epoch: 157| Step: 0
Training loss: 2.821397567357933
Validation loss: 2.4754751177201646

Epoch: 5| Step: 1
Training loss: 2.8533383209268113
Validation loss: 2.4822142766667805

Epoch: 5| Step: 2
Training loss: 2.7457197865311533
Validation loss: 2.4814449498734596

Epoch: 5| Step: 3
Training loss: 2.799555341290426
Validation loss: 2.483199013761321

Epoch: 5| Step: 4
Training loss: 2.26841479891149
Validation loss: 2.4778484529132268

Epoch: 5| Step: 5
Training loss: 2.8039309190465804
Validation loss: 2.479625526733811

Epoch: 5| Step: 6
Training loss: 2.9737695922462715
Validation loss: 2.4821210530015625

Epoch: 5| Step: 7
Training loss: 2.904002150952512
Validation loss: 2.4668708888700692

Epoch: 5| Step: 8
Training loss: 2.611372679827454
Validation loss: 2.4738518680446564

Epoch: 5| Step: 9
Training loss: 2.8538845693212203
Validation loss: 2.4818820943708872

Epoch: 5| Step: 10
Training loss: 2.7132531206082633
Validation loss: 2.47380596078088

Epoch: 158| Step: 0
Training loss: 3.1180695550194137
Validation loss: 2.460577934054823

Epoch: 5| Step: 1
Training loss: 2.9319158192372696
Validation loss: 2.4622150085284513

Epoch: 5| Step: 2
Training loss: 2.354024213233687
Validation loss: 2.457806638904893

Epoch: 5| Step: 3
Training loss: 3.149023261848364
Validation loss: 2.456485532157556

Epoch: 5| Step: 4
Training loss: 2.273954457238797
Validation loss: 2.4467874562052776

Epoch: 5| Step: 5
Training loss: 2.3415140294549333
Validation loss: 2.4590991957918664

Epoch: 5| Step: 6
Training loss: 2.970261520277353
Validation loss: 2.449246068133101

Epoch: 5| Step: 7
Training loss: 2.5861850401075377
Validation loss: 2.4494984253772087

Epoch: 5| Step: 8
Training loss: 2.9475870835606095
Validation loss: 2.451842739532711

Epoch: 5| Step: 9
Training loss: 2.963038200067801
Validation loss: 2.45412408159557

Epoch: 5| Step: 10
Training loss: 2.409539389537483
Validation loss: 2.468747913779762

Epoch: 159| Step: 0
Training loss: 3.141117342035013
Validation loss: 2.478418318103474

Epoch: 5| Step: 1
Training loss: 2.9790880597465743
Validation loss: 2.482702231656221

Epoch: 5| Step: 2
Training loss: 2.8736472886601834
Validation loss: 2.4941733165559796

Epoch: 5| Step: 3
Training loss: 3.0115987355505593
Validation loss: 2.493039475473662

Epoch: 5| Step: 4
Training loss: 2.181170434238416
Validation loss: 2.4993815646698874

Epoch: 5| Step: 5
Training loss: 2.5701907978406364
Validation loss: 2.4885437199889444

Epoch: 5| Step: 6
Training loss: 2.9622984805557375
Validation loss: 2.4754427565925465

Epoch: 5| Step: 7
Training loss: 2.7676937318722286
Validation loss: 2.45234455197657

Epoch: 5| Step: 8
Training loss: 2.1627014507329583
Validation loss: 2.444867522890522

Epoch: 5| Step: 9
Training loss: 2.4085831663262343
Validation loss: 2.4490703544284584

Epoch: 5| Step: 10
Training loss: 3.0773543734147997
Validation loss: 2.4576411001753087

Epoch: 160| Step: 0
Training loss: 2.7544845082167115
Validation loss: 2.4473123590391936

Epoch: 5| Step: 1
Training loss: 2.4153174437715244
Validation loss: 2.4501327199106537

Epoch: 5| Step: 2
Training loss: 2.6447632094829623
Validation loss: 2.4492579743852856

Epoch: 5| Step: 3
Training loss: 2.207147375782059
Validation loss: 2.456290989268444

Epoch: 5| Step: 4
Training loss: 3.2107728048071786
Validation loss: 2.458645672680676

Epoch: 5| Step: 5
Training loss: 3.1377384718281305
Validation loss: 2.4684251338141743

Epoch: 5| Step: 6
Training loss: 2.764424208829004
Validation loss: 2.4610273551520803

Epoch: 5| Step: 7
Training loss: 2.418927965344541
Validation loss: 2.4904566766585177

Epoch: 5| Step: 8
Training loss: 3.002729763416031
Validation loss: 2.4943774935367227

Epoch: 5| Step: 9
Training loss: 2.830483480610475
Validation loss: 2.4995823419000818

Epoch: 5| Step: 10
Training loss: 2.698750478754182
Validation loss: 2.47489201610639

Epoch: 161| Step: 0
Training loss: 3.0347527784433335
Validation loss: 2.4533120590799435

Epoch: 5| Step: 1
Training loss: 2.518680399271475
Validation loss: 2.4474842594644493

Epoch: 5| Step: 2
Training loss: 2.527083275887493
Validation loss: 2.4490234194531473

Epoch: 5| Step: 3
Training loss: 3.181238194651705
Validation loss: 2.4485234067391364

Epoch: 5| Step: 4
Training loss: 2.771879204335083
Validation loss: 2.44879967955441

Epoch: 5| Step: 5
Training loss: 3.1105743088902296
Validation loss: 2.4490466729844376

Epoch: 5| Step: 6
Training loss: 2.7889819734632963
Validation loss: 2.445489443446316

Epoch: 5| Step: 7
Training loss: 2.24914184735646
Validation loss: 2.4592509162356375

Epoch: 5| Step: 8
Training loss: 2.583158815293178
Validation loss: 2.4430239348241507

Epoch: 5| Step: 9
Training loss: 2.7894139856430025
Validation loss: 2.449396466798678

Epoch: 5| Step: 10
Training loss: 2.7125169182175086
Validation loss: 2.4498558502617245

Epoch: 162| Step: 0
Training loss: 2.856426949727302
Validation loss: 2.456425881170402

Epoch: 5| Step: 1
Training loss: 2.909990917860193
Validation loss: 2.4615627366367057

Epoch: 5| Step: 2
Training loss: 2.5693035522415
Validation loss: 2.477743507778372

Epoch: 5| Step: 3
Training loss: 2.748563217749028
Validation loss: 2.4932522071531187

Epoch: 5| Step: 4
Training loss: 2.230963283036628
Validation loss: 2.5183825045906976

Epoch: 5| Step: 5
Training loss: 3.068516951217188
Validation loss: 2.516618727393337

Epoch: 5| Step: 6
Training loss: 3.0144100607791184
Validation loss: 2.500214209659803

Epoch: 5| Step: 7
Training loss: 2.164357960496496
Validation loss: 2.463595908326047

Epoch: 5| Step: 8
Training loss: 2.9898506780483816
Validation loss: 2.463496282546633

Epoch: 5| Step: 9
Training loss: 2.951881752499125
Validation loss: 2.44897112332422

Epoch: 5| Step: 10
Training loss: 2.3907247285673026
Validation loss: 2.451671805568758

Epoch: 163| Step: 0
Training loss: 2.3489146993324366
Validation loss: 2.4516101897118885

Epoch: 5| Step: 1
Training loss: 3.281228346980267
Validation loss: 2.4522296469979197

Epoch: 5| Step: 2
Training loss: 3.2831703016466047
Validation loss: 2.4485099567480257

Epoch: 5| Step: 3
Training loss: 2.884380958030226
Validation loss: 2.446216306537206

Epoch: 5| Step: 4
Training loss: 2.738316947932877
Validation loss: 2.4491914922724978

Epoch: 5| Step: 5
Training loss: 2.759531495785636
Validation loss: 2.4471157333727684

Epoch: 5| Step: 6
Training loss: 2.6078519659330173
Validation loss: 2.444426152256266

Epoch: 5| Step: 7
Training loss: 2.607930954516509
Validation loss: 2.4481967005703718

Epoch: 5| Step: 8
Training loss: 2.6632241638815386
Validation loss: 2.444906608419678

Epoch: 5| Step: 9
Training loss: 2.216173744847704
Validation loss: 2.4497822338074755

Epoch: 5| Step: 10
Training loss: 2.8712653076401544
Validation loss: 2.484655349855285

Epoch: 164| Step: 0
Training loss: 2.728423786733994
Validation loss: 2.527358830470006

Epoch: 5| Step: 1
Training loss: 3.3053285234064167
Validation loss: 2.576261973011924

Epoch: 5| Step: 2
Training loss: 2.88347702844319
Validation loss: 2.6336805134106775

Epoch: 5| Step: 3
Training loss: 2.6877947800895643
Validation loss: 2.631536994247776

Epoch: 5| Step: 4
Training loss: 2.816914125064568
Validation loss: 2.6079259539038997

Epoch: 5| Step: 5
Training loss: 2.7083135653043344
Validation loss: 2.5532578766346905

Epoch: 5| Step: 6
Training loss: 2.94098894419014
Validation loss: 2.5123176894665624

Epoch: 5| Step: 7
Training loss: 2.571247058471718
Validation loss: 2.4834124975421124

Epoch: 5| Step: 8
Training loss: 2.597994445354347
Validation loss: 2.4474038310602544

Epoch: 5| Step: 9
Training loss: 3.1314114222539273
Validation loss: 2.4460644929102706

Epoch: 5| Step: 10
Training loss: 2.573365413024391
Validation loss: 2.452219155014638

Epoch: 165| Step: 0
Training loss: 3.1500126611364316
Validation loss: 2.4646109727246484

Epoch: 5| Step: 1
Training loss: 2.5469826517581415
Validation loss: 2.469711352256697

Epoch: 5| Step: 2
Training loss: 2.5509771531778087
Validation loss: 2.4761176669442264

Epoch: 5| Step: 3
Training loss: 3.0032124803327465
Validation loss: 2.468710416552033

Epoch: 5| Step: 4
Training loss: 2.6027871305319596
Validation loss: 2.4635748088429934

Epoch: 5| Step: 5
Training loss: 2.579648024628406
Validation loss: 2.4434636030687775

Epoch: 5| Step: 6
Training loss: 2.9509296633418294
Validation loss: 2.455815632137781

Epoch: 5| Step: 7
Training loss: 3.1277572674828833
Validation loss: 2.4477959499471837

Epoch: 5| Step: 8
Training loss: 2.4551208540931597
Validation loss: 2.461245380654906

Epoch: 5| Step: 9
Training loss: 2.960248479465983
Validation loss: 2.4865910836395946

Epoch: 5| Step: 10
Training loss: 2.1944147086509656
Validation loss: 2.501296342052874

Epoch: 166| Step: 0
Training loss: 2.7945428427311003
Validation loss: 2.515994701659613

Epoch: 5| Step: 1
Training loss: 2.7497053855525007
Validation loss: 2.5279853243452464

Epoch: 5| Step: 2
Training loss: 2.277614780217816
Validation loss: 2.548127364285611

Epoch: 5| Step: 3
Training loss: 2.785518071666703
Validation loss: 2.5627593967896254

Epoch: 5| Step: 4
Training loss: 3.045539602440221
Validation loss: 2.551382066329326

Epoch: 5| Step: 5
Training loss: 2.9165967297116424
Validation loss: 2.535119789632797

Epoch: 5| Step: 6
Training loss: 2.7324174249706883
Validation loss: 2.5091996781350496

Epoch: 5| Step: 7
Training loss: 2.2899390095080796
Validation loss: 2.481797789365179

Epoch: 5| Step: 8
Training loss: 2.981753171288211
Validation loss: 2.482475858690206

Epoch: 5| Step: 9
Training loss: 2.526713320654512
Validation loss: 2.4719881187554593

Epoch: 5| Step: 10
Training loss: 3.242086018272484
Validation loss: 2.4707589221603783

Epoch: 167| Step: 0
Training loss: 2.7940065816530053
Validation loss: 2.4663365489542595

Epoch: 5| Step: 1
Training loss: 2.958871568600546
Validation loss: 2.455502693029078

Epoch: 5| Step: 2
Training loss: 2.8361416157389545
Validation loss: 2.4454253518380615

Epoch: 5| Step: 3
Training loss: 2.3682958444325726
Validation loss: 2.449901229997078

Epoch: 5| Step: 4
Training loss: 2.7591710189129066
Validation loss: 2.4582092277467384

Epoch: 5| Step: 5
Training loss: 2.9393522226244784
Validation loss: 2.4756282090752713

Epoch: 5| Step: 6
Training loss: 2.7314316957561915
Validation loss: 2.4880691854962156

Epoch: 5| Step: 7
Training loss: 2.1967175965876256
Validation loss: 2.4967727442444096

Epoch: 5| Step: 8
Training loss: 3.293473065947345
Validation loss: 2.501715589301293

Epoch: 5| Step: 9
Training loss: 2.6829925707736613
Validation loss: 2.540543489768559

Epoch: 5| Step: 10
Training loss: 2.6969778030268494
Validation loss: 2.5384584941215187

Epoch: 168| Step: 0
Training loss: 2.639148909044605
Validation loss: 2.5475535658645083

Epoch: 5| Step: 1
Training loss: 2.3361677483723544
Validation loss: 2.533965720698696

Epoch: 5| Step: 2
Training loss: 1.978193311430793
Validation loss: 2.5110825683601905

Epoch: 5| Step: 3
Training loss: 2.7934854096263266
Validation loss: 2.504787766309832

Epoch: 5| Step: 4
Training loss: 3.3168367032373456
Validation loss: 2.494656775831597

Epoch: 5| Step: 5
Training loss: 2.2945992750319815
Validation loss: 2.4720751341596556

Epoch: 5| Step: 6
Training loss: 2.986930352332893
Validation loss: 2.4543438076918593

Epoch: 5| Step: 7
Training loss: 3.2480788788448844
Validation loss: 2.442078726478821

Epoch: 5| Step: 8
Training loss: 2.6747200970959257
Validation loss: 2.436727480793211

Epoch: 5| Step: 9
Training loss: 2.897179178771774
Validation loss: 2.4363644639233897

Epoch: 5| Step: 10
Training loss: 2.9599834908205445
Validation loss: 2.4446564282126224

Epoch: 169| Step: 0
Training loss: 2.377382990287287
Validation loss: 2.4526865640326685

Epoch: 5| Step: 1
Training loss: 2.561629915224055
Validation loss: 2.445976835168313

Epoch: 5| Step: 2
Training loss: 2.4873728388962832
Validation loss: 2.437077505908377

Epoch: 5| Step: 3
Training loss: 3.108333700826042
Validation loss: 2.4441158497831528

Epoch: 5| Step: 4
Training loss: 2.2876861913397097
Validation loss: 2.45052512607907

Epoch: 5| Step: 5
Training loss: 2.908252641347261
Validation loss: 2.449329346836089

Epoch: 5| Step: 6
Training loss: 2.9616967186577536
Validation loss: 2.450625893248235

Epoch: 5| Step: 7
Training loss: 2.4095317705461956
Validation loss: 2.4758012022733915

Epoch: 5| Step: 8
Training loss: 2.604632608056119
Validation loss: 2.482806999201327

Epoch: 5| Step: 9
Training loss: 3.256453635498495
Validation loss: 2.488834328329296

Epoch: 5| Step: 10
Training loss: 3.04153569257401
Validation loss: 2.4927476439955707

Epoch: 170| Step: 0
Training loss: 2.846191029295845
Validation loss: 2.515870583893811

Epoch: 5| Step: 1
Training loss: 2.228675990306641
Validation loss: 2.5108108136205307

Epoch: 5| Step: 2
Training loss: 2.9625931994751107
Validation loss: 2.5404702599579574

Epoch: 5| Step: 3
Training loss: 3.291760712901747
Validation loss: 2.5275359064135734

Epoch: 5| Step: 4
Training loss: 2.775457457906169
Validation loss: 2.4994697182730925

Epoch: 5| Step: 5
Training loss: 2.591780132823186
Validation loss: 2.483539864270492

Epoch: 5| Step: 6
Training loss: 2.9703355269565415
Validation loss: 2.4790479121966005

Epoch: 5| Step: 7
Training loss: 2.2752632072693295
Validation loss: 2.4674840619870078

Epoch: 5| Step: 8
Training loss: 2.5466497590800277
Validation loss: 2.469636094792254

Epoch: 5| Step: 9
Training loss: 2.82582183969047
Validation loss: 2.45652789864269

Epoch: 5| Step: 10
Training loss: 2.9025645525027195
Validation loss: 2.459849631609943

Epoch: 171| Step: 0
Training loss: 2.591122134817559
Validation loss: 2.4473561958106163

Epoch: 5| Step: 1
Training loss: 2.412141992757702
Validation loss: 2.4574208843963445

Epoch: 5| Step: 2
Training loss: 2.920633307195564
Validation loss: 2.4657724310499423

Epoch: 5| Step: 3
Training loss: 2.913674990990759
Validation loss: 2.474700040053373

Epoch: 5| Step: 4
Training loss: 2.697989640789349
Validation loss: 2.475871486497068

Epoch: 5| Step: 5
Training loss: 3.308119846889879
Validation loss: 2.4764270900079075

Epoch: 5| Step: 6
Training loss: 2.5828640932075215
Validation loss: 2.4761483099154415

Epoch: 5| Step: 7
Training loss: 2.5418426786252644
Validation loss: 2.4621905851468906

Epoch: 5| Step: 8
Training loss: 2.1922394771490863
Validation loss: 2.4731006804486984

Epoch: 5| Step: 9
Training loss: 3.156162525135675
Validation loss: 2.4916852152424114

Epoch: 5| Step: 10
Training loss: 2.562933071106508
Validation loss: 2.510449305408013

Epoch: 172| Step: 0
Training loss: 3.0066749700641657
Validation loss: 2.5059332085529253

Epoch: 5| Step: 1
Training loss: 2.639762873114863
Validation loss: 2.5093434083315107

Epoch: 5| Step: 2
Training loss: 2.7378972501235115
Validation loss: 2.4999116389748663

Epoch: 5| Step: 3
Training loss: 2.673640242468811
Validation loss: 2.5026508899869566

Epoch: 5| Step: 4
Training loss: 2.585434694762675
Validation loss: 2.479780352993231

Epoch: 5| Step: 5
Training loss: 2.6883430045943846
Validation loss: 2.4900057247228005

Epoch: 5| Step: 6
Training loss: 2.4627076579415363
Validation loss: 2.4670181742194655

Epoch: 5| Step: 7
Training loss: 2.9913607817307915
Validation loss: 2.4591979812105738

Epoch: 5| Step: 8
Training loss: 2.9186151444773025
Validation loss: 2.453353677842951

Epoch: 5| Step: 9
Training loss: 2.7922466491684577
Validation loss: 2.4502629496637165

Epoch: 5| Step: 10
Training loss: 2.5682684936689366
Validation loss: 2.4490159149239017

Epoch: 173| Step: 0
Training loss: 3.0767735646675893
Validation loss: 2.456205792323958

Epoch: 5| Step: 1
Training loss: 2.916594113855335
Validation loss: 2.4601284100149194

Epoch: 5| Step: 2
Training loss: 2.2657510656602433
Validation loss: 2.471377520593129

Epoch: 5| Step: 3
Training loss: 2.568100461492144
Validation loss: 2.4701416415236817

Epoch: 5| Step: 4
Training loss: 3.069566941921531
Validation loss: 2.4704555369425014

Epoch: 5| Step: 5
Training loss: 2.559519173796417
Validation loss: 2.4887908456482246

Epoch: 5| Step: 6
Training loss: 2.5906122370682767
Validation loss: 2.484989860233208

Epoch: 5| Step: 7
Training loss: 2.7275046221084662
Validation loss: 2.500844337051623

Epoch: 5| Step: 8
Training loss: 2.4736330052679554
Validation loss: 2.5395159108448566

Epoch: 5| Step: 9
Training loss: 2.638210208242466
Validation loss: 2.5815778712821653

Epoch: 5| Step: 10
Training loss: 2.966775016377672
Validation loss: 2.585292749539825

Epoch: 174| Step: 0
Training loss: 2.5702177917284996
Validation loss: 2.5986690890893667

Epoch: 5| Step: 1
Training loss: 2.662839815903757
Validation loss: 2.591089451960175

Epoch: 5| Step: 2
Training loss: 2.752196648397235
Validation loss: 2.6223924834395413

Epoch: 5| Step: 3
Training loss: 3.117744721058945
Validation loss: 2.628572596497373

Epoch: 5| Step: 4
Training loss: 2.4471855424472
Validation loss: 2.594022030630625

Epoch: 5| Step: 5
Training loss: 2.5266092403431624
Validation loss: 2.54447807512282

Epoch: 5| Step: 6
Training loss: 2.571713700456701
Validation loss: 2.5068699008284803

Epoch: 5| Step: 7
Training loss: 2.2377212116706784
Validation loss: 2.461470457652485

Epoch: 5| Step: 8
Training loss: 2.811235355459482
Validation loss: 2.4497925593737615

Epoch: 5| Step: 9
Training loss: 3.3107980638480625
Validation loss: 2.4556605581393622

Epoch: 5| Step: 10
Training loss: 3.010045082540423
Validation loss: 2.4606524381637467

Epoch: 175| Step: 0
Training loss: 3.3835745783394606
Validation loss: 2.487314522326712

Epoch: 5| Step: 1
Training loss: 2.6377979923785277
Validation loss: 2.497315655610263

Epoch: 5| Step: 2
Training loss: 2.153220550232966
Validation loss: 2.480665009718145

Epoch: 5| Step: 3
Training loss: 2.2901707593061715
Validation loss: 2.4753034605549997

Epoch: 5| Step: 4
Training loss: 2.792520980687842
Validation loss: 2.4715629949382203

Epoch: 5| Step: 5
Training loss: 2.7014383334941465
Validation loss: 2.465105148372814

Epoch: 5| Step: 6
Training loss: 2.813052229178423
Validation loss: 2.466990768150579

Epoch: 5| Step: 7
Training loss: 2.6659235117443245
Validation loss: 2.4944832686324667

Epoch: 5| Step: 8
Training loss: 2.2345178731842434
Validation loss: 2.4876803374759593

Epoch: 5| Step: 9
Training loss: 3.032940894371336
Validation loss: 2.488735344086205

Epoch: 5| Step: 10
Training loss: 3.3363755807291895
Validation loss: 2.47847506178836

Epoch: 176| Step: 0
Training loss: 2.659781408578242
Validation loss: 2.474518501493558

Epoch: 5| Step: 1
Training loss: 2.9360909836519418
Validation loss: 2.4749588374707696

Epoch: 5| Step: 2
Training loss: 2.1402090740570814
Validation loss: 2.474317301088455

Epoch: 5| Step: 3
Training loss: 1.955787857604044
Validation loss: 2.46970164455773

Epoch: 5| Step: 4
Training loss: 2.2155516231637584
Validation loss: 2.473808703903464

Epoch: 5| Step: 5
Training loss: 2.862222223255534
Validation loss: 2.487416123231192

Epoch: 5| Step: 6
Training loss: 3.263392657350225
Validation loss: 2.4930742457920516

Epoch: 5| Step: 7
Training loss: 2.9157055679098045
Validation loss: 2.496400627244283

Epoch: 5| Step: 8
Training loss: 2.3579508544291325
Validation loss: 2.504794931796129

Epoch: 5| Step: 9
Training loss: 3.5883107030296375
Validation loss: 2.4976761066442763

Epoch: 5| Step: 10
Training loss: 2.3332323211421975
Validation loss: 2.4944195432702303

Epoch: 177| Step: 0
Training loss: 2.6708171155638527
Validation loss: 2.4875912708990953

Epoch: 5| Step: 1
Training loss: 2.7804859269102753
Validation loss: 2.4900540626677152

Epoch: 5| Step: 2
Training loss: 2.6680405077911766
Validation loss: 2.4889864342238166

Epoch: 5| Step: 3
Training loss: 2.350368158436906
Validation loss: 2.492456612510247

Epoch: 5| Step: 4
Training loss: 3.0859422900971527
Validation loss: 2.493886506275179

Epoch: 5| Step: 5
Training loss: 3.0568183042907173
Validation loss: 2.4864805471099722

Epoch: 5| Step: 6
Training loss: 2.542825768079737
Validation loss: 2.490472537383782

Epoch: 5| Step: 7
Training loss: 2.5772296622407547
Validation loss: 2.490502943001071

Epoch: 5| Step: 8
Training loss: 2.602038732247741
Validation loss: 2.4756276560906807

Epoch: 5| Step: 9
Training loss: 2.6910859070967987
Validation loss: 2.4814460728791263

Epoch: 5| Step: 10
Training loss: 2.462930604880947
Validation loss: 2.4683254516055406

Epoch: 178| Step: 0
Training loss: 2.545227454013408
Validation loss: 2.4768447215705853

Epoch: 5| Step: 1
Training loss: 2.889793812613444
Validation loss: 2.491809290750353

Epoch: 5| Step: 2
Training loss: 2.5851450279179025
Validation loss: 2.50348186955195

Epoch: 5| Step: 3
Training loss: 2.628595977203581
Validation loss: 2.514417988163285

Epoch: 5| Step: 4
Training loss: 2.8739089554161237
Validation loss: 2.519796886719403

Epoch: 5| Step: 5
Training loss: 2.5736063806259653
Validation loss: 2.518028470072114

Epoch: 5| Step: 6
Training loss: 2.7285014693508067
Validation loss: 2.513489468159177

Epoch: 5| Step: 7
Training loss: 3.0684031987839564
Validation loss: 2.5156940218129638

Epoch: 5| Step: 8
Training loss: 2.5138304570703514
Validation loss: 2.5188237899979775

Epoch: 5| Step: 9
Training loss: 2.3811319397022124
Validation loss: 2.539928100552751

Epoch: 5| Step: 10
Training loss: 2.626334259991031
Validation loss: 2.5590257420399136

Epoch: 179| Step: 0
Training loss: 2.677351664789421
Validation loss: 2.5688169344650604

Epoch: 5| Step: 1
Training loss: 3.000798595947409
Validation loss: 2.5662661553040547

Epoch: 5| Step: 2
Training loss: 2.3328370406641517
Validation loss: 2.5570546821439044

Epoch: 5| Step: 3
Training loss: 2.709308937613722
Validation loss: 2.543820608420414

Epoch: 5| Step: 4
Training loss: 3.0068570291461456
Validation loss: 2.548373275565927

Epoch: 5| Step: 5
Training loss: 2.6380203312342707
Validation loss: 2.5524924885534226

Epoch: 5| Step: 6
Training loss: 2.971593358506152
Validation loss: 2.550447872078642

Epoch: 5| Step: 7
Training loss: 2.180649521160373
Validation loss: 2.5595408094879497

Epoch: 5| Step: 8
Training loss: 2.6781252207806028
Validation loss: 2.5808090423262318

Epoch: 5| Step: 9
Training loss: 2.657713273857588
Validation loss: 2.5885148503308923

Epoch: 5| Step: 10
Training loss: 1.9677904000509594
Validation loss: 2.573552958738444

Epoch: 180| Step: 0
Training loss: 3.009899020101182
Validation loss: 2.5858497734866854

Epoch: 5| Step: 1
Training loss: 2.396527054460268
Validation loss: 2.5661441833185354

Epoch: 5| Step: 2
Training loss: 2.8859386499853894
Validation loss: 2.569720854484128

Epoch: 5| Step: 3
Training loss: 2.9163455968068406
Validation loss: 2.570023514794978

Epoch: 5| Step: 4
Training loss: 2.2860489625801903
Validation loss: 2.5642608687224158

Epoch: 5| Step: 5
Training loss: 2.3892908300312024
Validation loss: 2.5527521013502965

Epoch: 5| Step: 6
Training loss: 2.667334105491129
Validation loss: 2.5349500516558874

Epoch: 5| Step: 7
Training loss: 2.4659992780042397
Validation loss: 2.5411507469366335

Epoch: 5| Step: 8
Training loss: 2.8903481840640013
Validation loss: 2.529489816476168

Epoch: 5| Step: 9
Training loss: 2.5493875291595485
Validation loss: 2.5293915921263634

Epoch: 5| Step: 10
Training loss: 2.3171059386393376
Validation loss: 2.5486891593008933

Epoch: 181| Step: 0
Training loss: 2.7399206981181625
Validation loss: 2.5641219465684295

Epoch: 5| Step: 1
Training loss: 2.657910534790384
Validation loss: 2.5688493004100126

Epoch: 5| Step: 2
Training loss: 2.75791347416068
Validation loss: 2.5469067343390552

Epoch: 5| Step: 3
Training loss: 2.4408920356912804
Validation loss: 2.5330274218967754

Epoch: 5| Step: 4
Training loss: 2.5345211791227698
Validation loss: 2.5220200018415397

Epoch: 5| Step: 5
Training loss: 2.712910750268449
Validation loss: 2.508219765631747

Epoch: 5| Step: 6
Training loss: 2.2252403215215635
Validation loss: 2.5004528619924336

Epoch: 5| Step: 7
Training loss: 2.835619359522644
Validation loss: 2.5060229403407552

Epoch: 5| Step: 8
Training loss: 2.690973476833475
Validation loss: 2.5365448778379376

Epoch: 5| Step: 9
Training loss: 2.9489068479006275
Validation loss: 2.5734976260851536

Epoch: 5| Step: 10
Training loss: 2.800988608628915
Validation loss: 2.609113234433151

Epoch: 182| Step: 0
Training loss: 3.149886713564247
Validation loss: 2.5885667720249126

Epoch: 5| Step: 1
Training loss: 2.667843370298115
Validation loss: 2.577953264539429

Epoch: 5| Step: 2
Training loss: 2.3401667351292654
Validation loss: 2.6242482465940054

Epoch: 5| Step: 3
Training loss: 2.891321376739166
Validation loss: 2.669286926525153

Epoch: 5| Step: 4
Training loss: 2.6499206531089636
Validation loss: 2.6744535810612673

Epoch: 5| Step: 5
Training loss: 3.0011246480506615
Validation loss: 2.6909112688708423

Epoch: 5| Step: 6
Training loss: 2.292393678884955
Validation loss: 2.645823139471083

Epoch: 5| Step: 7
Training loss: 2.3408899786253965
Validation loss: 2.6062536391720257

Epoch: 5| Step: 8
Training loss: 2.2987787570368123
Validation loss: 2.5894952038163273

Epoch: 5| Step: 9
Training loss: 2.331522261442731
Validation loss: 2.567526206176267

Epoch: 5| Step: 10
Training loss: 3.1582351333798506
Validation loss: 2.584611839971518

Epoch: 183| Step: 0
Training loss: 2.703775669351698
Validation loss: 2.604597357461951

Epoch: 5| Step: 1
Training loss: 2.0409074526508166
Validation loss: 2.597306348285513

Epoch: 5| Step: 2
Training loss: 2.054922460313676
Validation loss: 2.603596340280015

Epoch: 5| Step: 3
Training loss: 3.274780580581262
Validation loss: 2.567148264143596

Epoch: 5| Step: 4
Training loss: 2.337616996081144
Validation loss: 2.540514856638186

Epoch: 5| Step: 5
Training loss: 2.5825385029702326
Validation loss: 2.517246194511899

Epoch: 5| Step: 6
Training loss: 2.5643592230404226
Validation loss: 2.514259939715177

Epoch: 5| Step: 7
Training loss: 3.481166987910417
Validation loss: 2.5330208554767446

Epoch: 5| Step: 8
Training loss: 2.6639178731820157
Validation loss: 2.5421944757249832

Epoch: 5| Step: 9
Training loss: 2.338392823600654
Validation loss: 2.5458328517615763

Epoch: 5| Step: 10
Training loss: 2.777096679685955
Validation loss: 2.564901767555912

Epoch: 184| Step: 0
Training loss: 2.895558698699148
Validation loss: 2.56891733527772

Epoch: 5| Step: 1
Training loss: 2.504604867011153
Validation loss: 2.5744139630778093

Epoch: 5| Step: 2
Training loss: 2.3354786706112574
Validation loss: 2.5897749047467866

Epoch: 5| Step: 3
Training loss: 2.6901825225339486
Validation loss: 2.6068305119504456

Epoch: 5| Step: 4
Training loss: 2.6153586303274494
Validation loss: 2.65040860066576

Epoch: 5| Step: 5
Training loss: 2.659140596021884
Validation loss: 2.6543436949124843

Epoch: 5| Step: 6
Training loss: 2.3706059213278405
Validation loss: 2.6397162238481364

Epoch: 5| Step: 7
Training loss: 2.806840415644695
Validation loss: 2.6142793550675196

Epoch: 5| Step: 8
Training loss: 2.6135828502740415
Validation loss: 2.5826224706278467

Epoch: 5| Step: 9
Training loss: 3.164841694902983
Validation loss: 2.567304725295581

Epoch: 5| Step: 10
Training loss: 1.786815848503937
Validation loss: 2.53356216364075

Epoch: 185| Step: 0
Training loss: 2.0788314880437935
Validation loss: 2.5259510270553887

Epoch: 5| Step: 1
Training loss: 2.7176761479565807
Validation loss: 2.5282466708512663

Epoch: 5| Step: 2
Training loss: 2.2538610814161792
Validation loss: 2.547734271439048

Epoch: 5| Step: 3
Training loss: 2.8152890257905265
Validation loss: 2.5850872995067893

Epoch: 5| Step: 4
Training loss: 1.9856627483580072
Validation loss: 2.603459649041638

Epoch: 5| Step: 5
Training loss: 2.769136774676844
Validation loss: 2.6311077700404053

Epoch: 5| Step: 6
Training loss: 2.8614616076479966
Validation loss: 2.6066348444113974

Epoch: 5| Step: 7
Training loss: 2.8714901605059215
Validation loss: 2.5886613744651132

Epoch: 5| Step: 8
Training loss: 2.7680065009255777
Validation loss: 2.601483596935057

Epoch: 5| Step: 9
Training loss: 2.82706275507035
Validation loss: 2.610230018221616

Epoch: 5| Step: 10
Training loss: 2.506778682207958
Validation loss: 2.6393172988399978

Epoch: 186| Step: 0
Training loss: 2.8306573310634615
Validation loss: 2.698847305908662

Epoch: 5| Step: 1
Training loss: 2.673379218103302
Validation loss: 2.719926000088538

Epoch: 5| Step: 2
Training loss: 2.717571573165929
Validation loss: 2.730723117495283

Epoch: 5| Step: 3
Training loss: 2.340022263380251
Validation loss: 2.7032071244023057

Epoch: 5| Step: 4
Training loss: 2.615782312108483
Validation loss: 2.658074625610113

Epoch: 5| Step: 5
Training loss: 2.7117453479039404
Validation loss: 2.608240995398003

Epoch: 5| Step: 6
Training loss: 2.69898811381812
Validation loss: 2.5699894962676306

Epoch: 5| Step: 7
Training loss: 2.3396792855519157
Validation loss: 2.5509155893348914

Epoch: 5| Step: 8
Training loss: 2.894140137311843
Validation loss: 2.59414647286052

Epoch: 5| Step: 9
Training loss: 2.726086943943634
Validation loss: 2.6573600664503725

Epoch: 5| Step: 10
Training loss: 2.3100243797501974
Validation loss: 2.695441352721138

Epoch: 187| Step: 0
Training loss: 3.1977067478795753
Validation loss: 2.7181947711899386

Epoch: 5| Step: 1
Training loss: 2.7601120306857174
Validation loss: 2.6190721543985616

Epoch: 5| Step: 2
Training loss: 2.946067166973512
Validation loss: 2.5527111079113816

Epoch: 5| Step: 3
Training loss: 2.904982259568165
Validation loss: 2.5064685557971282

Epoch: 5| Step: 4
Training loss: 2.152447097429497
Validation loss: 2.5107597426753476

Epoch: 5| Step: 5
Training loss: 2.614923482909618
Validation loss: 2.5701271456831973

Epoch: 5| Step: 6
Training loss: 2.5581950801641904
Validation loss: 2.606906359026179

Epoch: 5| Step: 7
Training loss: 2.7887009672182868
Validation loss: 2.6711899313836955

Epoch: 5| Step: 8
Training loss: 2.67874680626163
Validation loss: 2.734290506724576

Epoch: 5| Step: 9
Training loss: 2.491835231458883
Validation loss: 2.736309553887619

Epoch: 5| Step: 10
Training loss: 2.8329864364390898
Validation loss: 2.7781828868615555

Epoch: 188| Step: 0
Training loss: 2.3472102752421633
Validation loss: 2.77223233595343

Epoch: 5| Step: 1
Training loss: 2.0419650995034986
Validation loss: 2.7376022584232738

Epoch: 5| Step: 2
Training loss: 3.2204533486472036
Validation loss: 2.7206327995526456

Epoch: 5| Step: 3
Training loss: 1.9041525135585535
Validation loss: 2.646926812506749

Epoch: 5| Step: 4
Training loss: 2.235669381349272
Validation loss: 2.6065857753670985

Epoch: 5| Step: 5
Training loss: 2.09908241933799
Validation loss: 2.563221745527753

Epoch: 5| Step: 6
Training loss: 3.332149454325528
Validation loss: 2.540175765379135

Epoch: 5| Step: 7
Training loss: 2.510827364639631
Validation loss: 2.564789743216475

Epoch: 5| Step: 8
Training loss: 2.6456786783830135
Validation loss: 2.5831681561598305

Epoch: 5| Step: 9
Training loss: 2.6678772403779307
Validation loss: 2.6062792813183395

Epoch: 5| Step: 10
Training loss: 2.903909048059084
Validation loss: 2.6716292284501924

Epoch: 189| Step: 0
Training loss: 3.0237366678638655
Validation loss: 2.690354541850021

Epoch: 5| Step: 1
Training loss: 2.373338821097612
Validation loss: 2.6394801086520787

Epoch: 5| Step: 2
Training loss: 2.799370020431651
Validation loss: 2.588826461921426

Epoch: 5| Step: 3
Training loss: 2.7083113645004926
Validation loss: 2.5169781282774055

Epoch: 5| Step: 4
Training loss: 2.2364366530025093
Validation loss: 2.485707167384162

Epoch: 5| Step: 5
Training loss: 2.231586236489617
Validation loss: 2.5068303742238705

Epoch: 5| Step: 6
Training loss: 2.845911231773708
Validation loss: 2.5279439455113004

Epoch: 5| Step: 7
Training loss: 2.5476093754671774
Validation loss: 2.5610131582986626

Epoch: 5| Step: 8
Training loss: 2.4016702839993784
Validation loss: 2.5931086413822464

Epoch: 5| Step: 9
Training loss: 2.705514017509055
Validation loss: 2.6225483213120673

Epoch: 5| Step: 10
Training loss: 2.98110383193251
Validation loss: 2.617340470338611

Epoch: 190| Step: 0
Training loss: 2.342417223596568
Validation loss: 2.6113733258001037

Epoch: 5| Step: 1
Training loss: 2.2312597151686364
Validation loss: 2.6011903361062423

Epoch: 5| Step: 2
Training loss: 2.4737945395339778
Validation loss: 2.569063490283051

Epoch: 5| Step: 3
Training loss: 2.605400667916714
Validation loss: 2.5544690056298127

Epoch: 5| Step: 4
Training loss: 2.707490604063798
Validation loss: 2.561224945611558

Epoch: 5| Step: 5
Training loss: 2.0707475313132555
Validation loss: 2.543489556616665

Epoch: 5| Step: 6
Training loss: 2.838231863678426
Validation loss: 2.5648457564975673

Epoch: 5| Step: 7
Training loss: 2.604479280145885
Validation loss: 2.5548916428106025

Epoch: 5| Step: 8
Training loss: 2.52250961392615
Validation loss: 2.571843857280658

Epoch: 5| Step: 9
Training loss: 2.513465949977353
Validation loss: 2.5704848616353257

Epoch: 5| Step: 10
Training loss: 2.7601112532652756
Validation loss: 2.5683553524010008

Epoch: 191| Step: 0
Training loss: 2.225787754122978
Validation loss: 2.5766077473742417

Epoch: 5| Step: 1
Training loss: 2.4328061416729088
Validation loss: 2.6008609307508554

Epoch: 5| Step: 2
Training loss: 2.4453063574765603
Validation loss: 2.6059361119660487

Epoch: 5| Step: 3
Training loss: 2.4529754204309766
Validation loss: 2.5929260922112918

Epoch: 5| Step: 4
Training loss: 1.8791591926082103
Validation loss: 2.6257483631013834

Epoch: 5| Step: 5
Training loss: 2.9407467045667026
Validation loss: 2.6332309434558767

Epoch: 5| Step: 6
Training loss: 2.507116773839958
Validation loss: 2.633533031445705

Epoch: 5| Step: 7
Training loss: 2.522078676755665
Validation loss: 2.6566772493731747

Epoch: 5| Step: 8
Training loss: 2.7416514337303943
Validation loss: 2.666119270003354

Epoch: 5| Step: 9
Training loss: 2.794018869455089
Validation loss: 2.633692273103326

Epoch: 5| Step: 10
Training loss: 2.6247817357465815
Validation loss: 2.5822780288219476

Epoch: 192| Step: 0
Training loss: 2.2867776449352237
Validation loss: 2.5555402171732946

Epoch: 5| Step: 1
Training loss: 2.4090390576038385
Validation loss: 2.531755544518754

Epoch: 5| Step: 2
Training loss: 2.0147008625555993
Validation loss: 2.513952670703371

Epoch: 5| Step: 3
Training loss: 2.962734351566414
Validation loss: 2.5164278349662985

Epoch: 5| Step: 4
Training loss: 2.8688323164954164
Validation loss: 2.542065209084681

Epoch: 5| Step: 5
Training loss: 2.976687611431096
Validation loss: 2.5385557001141152

Epoch: 5| Step: 6
Training loss: 2.251881766201911
Validation loss: 2.5665526169234134

Epoch: 5| Step: 7
Training loss: 2.585542861928446
Validation loss: 2.537921378877122

Epoch: 5| Step: 8
Training loss: 2.0198648498193252
Validation loss: 2.544697597598613

Epoch: 5| Step: 9
Training loss: 2.5852514549747805
Validation loss: 2.533405669765818

Epoch: 5| Step: 10
Training loss: 2.399472786693621
Validation loss: 2.5236203489248648

Epoch: 193| Step: 0
Training loss: 2.6450110131306674
Validation loss: 2.5248908251708357

Epoch: 5| Step: 1
Training loss: 2.587704426526755
Validation loss: 2.5311544378267867

Epoch: 5| Step: 2
Training loss: 2.5167494446570156
Validation loss: 2.5538712534358714

Epoch: 5| Step: 3
Training loss: 2.7027540007439814
Validation loss: 2.568015186422275

Epoch: 5| Step: 4
Training loss: 2.7096561624788973
Validation loss: 2.567364189616406

Epoch: 5| Step: 5
Training loss: 2.280769192963695
Validation loss: 2.59274851855381

Epoch: 5| Step: 6
Training loss: 2.285039810735364
Validation loss: 2.5949204857115564

Epoch: 5| Step: 7
Training loss: 2.526940527327444
Validation loss: 2.5900790135629594

Epoch: 5| Step: 8
Training loss: 2.363697160425767
Validation loss: 2.5767130625181185

Epoch: 5| Step: 9
Training loss: 2.4407434647220705
Validation loss: 2.5727998270985575

Epoch: 5| Step: 10
Training loss: 2.258227036380389
Validation loss: 2.5536586293622925

Epoch: 194| Step: 0
Training loss: 2.714234383893633
Validation loss: 2.542750421211605

Epoch: 5| Step: 1
Training loss: 2.1553898076875786
Validation loss: 2.5281331480264995

Epoch: 5| Step: 2
Training loss: 2.7067296684462
Validation loss: 2.5092933291792456

Epoch: 5| Step: 3
Training loss: 2.3420709317588244
Validation loss: 2.5107580385227757

Epoch: 5| Step: 4
Training loss: 2.5234740641398465
Validation loss: 2.4785508824726246

Epoch: 5| Step: 5
Training loss: 2.4136327465940024
Validation loss: 2.490520823035349

Epoch: 5| Step: 6
Training loss: 2.1363619937189453
Validation loss: 2.4988426308475833

Epoch: 5| Step: 7
Training loss: 2.5174483805178167
Validation loss: 2.5162692759917094

Epoch: 5| Step: 8
Training loss: 2.577655911396747
Validation loss: 2.5375609425273837

Epoch: 5| Step: 9
Training loss: 2.1712491897115913
Validation loss: 2.5640581847464725

Epoch: 5| Step: 10
Training loss: 2.781917620477868
Validation loss: 2.5784400824468885

Epoch: 195| Step: 0
Training loss: 2.703503444397815
Validation loss: 2.6306543027975833

Epoch: 5| Step: 1
Training loss: 2.239342988594835
Validation loss: 2.679513483213031

Epoch: 5| Step: 2
Training loss: 2.6885655087390923
Validation loss: 2.6866600620449463

Epoch: 5| Step: 3
Training loss: 2.7891146443939436
Validation loss: 2.6433357256490178

Epoch: 5| Step: 4
Training loss: 2.5547302429169907
Validation loss: 2.5402172487385477

Epoch: 5| Step: 5
Training loss: 2.4815025758347526
Validation loss: 2.4981911524483382

Epoch: 5| Step: 6
Training loss: 2.0516932031117188
Validation loss: 2.4862875345807254

Epoch: 5| Step: 7
Training loss: 1.661252940844824
Validation loss: 2.4858691422261736

Epoch: 5| Step: 8
Training loss: 2.6997507898679425
Validation loss: 2.5105567218727542

Epoch: 5| Step: 9
Training loss: 2.6331824883180177
Validation loss: 2.5107900363724576

Epoch: 5| Step: 10
Training loss: 2.7529858072277387
Validation loss: 2.506115272846475

Epoch: 196| Step: 0
Training loss: 2.6768662083864627
Validation loss: 2.539607103375457

Epoch: 5| Step: 1
Training loss: 2.9773323084887413
Validation loss: 2.5279174017730988

Epoch: 5| Step: 2
Training loss: 2.006611386844124
Validation loss: 2.53959654436546

Epoch: 5| Step: 3
Training loss: 2.155087143625207
Validation loss: 2.5370300377062738

Epoch: 5| Step: 4
Training loss: 2.4551198829856644
Validation loss: 2.5445930197275906

Epoch: 5| Step: 5
Training loss: 2.5307072187027946
Validation loss: 2.545968907735083

Epoch: 5| Step: 6
Training loss: 2.7448617442460805
Validation loss: 2.5463336470151496

Epoch: 5| Step: 7
Training loss: 2.4201963452220707
Validation loss: 2.55267246286531

Epoch: 5| Step: 8
Training loss: 2.450386024737133
Validation loss: 2.5495476453595236

Epoch: 5| Step: 9
Training loss: 2.5632674765921672
Validation loss: 2.5473132204093285

Epoch: 5| Step: 10
Training loss: 2.395949573737686
Validation loss: 2.524998004968993

Epoch: 197| Step: 0
Training loss: 2.0716157086407483
Validation loss: 2.5413932236295484

Epoch: 5| Step: 1
Training loss: 2.503396587901797
Validation loss: 2.5313633425347852

Epoch: 5| Step: 2
Training loss: 2.3249938185414822
Validation loss: 2.5276449274807455

Epoch: 5| Step: 3
Training loss: 2.5748749563725593
Validation loss: 2.5261699624058633

Epoch: 5| Step: 4
Training loss: 2.472246808085781
Validation loss: 2.5153597747514986

Epoch: 5| Step: 5
Training loss: 2.376594108857896
Validation loss: 2.522507483748722

Epoch: 5| Step: 6
Training loss: 2.5621655873993427
Validation loss: 2.5340119989659167

Epoch: 5| Step: 7
Training loss: 2.375985994959185
Validation loss: 2.5419790490195386

Epoch: 5| Step: 8
Training loss: 2.8362888927659573
Validation loss: 2.549150918754647

Epoch: 5| Step: 9
Training loss: 2.441961557940207
Validation loss: 2.5699524178243274

Epoch: 5| Step: 10
Training loss: 2.1418789720011455
Validation loss: 2.573957460818067

Epoch: 198| Step: 0
Training loss: 2.9047749375371823
Validation loss: 2.6046653109366527

Epoch: 5| Step: 1
Training loss: 1.9847751123944484
Validation loss: 2.6090633949765016

Epoch: 5| Step: 2
Training loss: 2.1722586313542225
Validation loss: 2.5886922925231746

Epoch: 5| Step: 3
Training loss: 2.199935335596127
Validation loss: 2.585316661471812

Epoch: 5| Step: 4
Training loss: 2.251865249599975
Validation loss: 2.5697394622842418

Epoch: 5| Step: 5
Training loss: 2.2572705103421593
Validation loss: 2.5608763424251904

Epoch: 5| Step: 6
Training loss: 2.7554276396515944
Validation loss: 2.5697519824685133

Epoch: 5| Step: 7
Training loss: 2.6574397395883613
Validation loss: 2.523797451507067

Epoch: 5| Step: 8
Training loss: 2.649524296943048
Validation loss: 2.517803866090425

Epoch: 5| Step: 9
Training loss: 2.0856384748801484
Validation loss: 2.5173603518867598

Epoch: 5| Step: 10
Training loss: 2.7091361005410715
Validation loss: 2.5245357444828325

Epoch: 199| Step: 0
Training loss: 2.3882413462112
Validation loss: 2.509167742762996

Epoch: 5| Step: 1
Training loss: 2.324374563940776
Validation loss: 2.496560027079994

Epoch: 5| Step: 2
Training loss: 2.5174388151489997
Validation loss: 2.4706209465360454

Epoch: 5| Step: 3
Training loss: 2.7499575178159534
Validation loss: 2.500938420906341

Epoch: 5| Step: 4
Training loss: 2.0919256660427816
Validation loss: 2.5070249598555887

Epoch: 5| Step: 5
Training loss: 2.196733225430092
Validation loss: 2.5408457229257246

Epoch: 5| Step: 6
Training loss: 2.084974888346183
Validation loss: 2.563343219498254

Epoch: 5| Step: 7
Training loss: 2.4996928026286405
Validation loss: 2.5391845148774217

Epoch: 5| Step: 8
Training loss: 2.3867361314705673
Validation loss: 2.5776788001630004

Epoch: 5| Step: 9
Training loss: 2.5433200294709963
Validation loss: 2.595500975241009

Epoch: 5| Step: 10
Training loss: 2.5520785480895563
Validation loss: 2.5819685718636793

Epoch: 200| Step: 0
Training loss: 2.3017864007028215
Validation loss: 2.589964982014322

Epoch: 5| Step: 1
Training loss: 2.012882111092937
Validation loss: 2.5528793034592425

Epoch: 5| Step: 2
Training loss: 2.4444287930575137
Validation loss: 2.5222196869467517

Epoch: 5| Step: 3
Training loss: 2.3917123154416386
Validation loss: 2.5290105087056816

Epoch: 5| Step: 4
Training loss: 2.651087332721299
Validation loss: 2.548637150451154

Epoch: 5| Step: 5
Training loss: 2.4012020716731795
Validation loss: 2.5508649504805962

Epoch: 5| Step: 6
Training loss: 2.2736231148051496
Validation loss: 2.5685653186598776

Epoch: 5| Step: 7
Training loss: 2.6492658461870513
Validation loss: 2.5786123611237257

Epoch: 5| Step: 8
Training loss: 2.4110580562530135
Validation loss: 2.5876166390469706

Epoch: 5| Step: 9
Training loss: 2.2951879209153385
Validation loss: 2.6093501958760523

Epoch: 5| Step: 10
Training loss: 1.8540982294489687
Validation loss: 2.6264246006263323

Testing loss: 2.649185640135742
