Epoch: 1| Step: 0
Training loss: 4.226733304730887
Validation loss: 5.818120926605827

Epoch: 5| Step: 1
Training loss: 6.136362552321624
Validation loss: 5.793785988761092

Epoch: 5| Step: 2
Training loss: 6.035434358478916
Validation loss: 5.770623479557533

Epoch: 5| Step: 3
Training loss: 6.603422329550211
Validation loss: 5.747696706347881

Epoch: 5| Step: 4
Training loss: 4.349493825993824
Validation loss: 5.722178248763394

Epoch: 5| Step: 5
Training loss: 6.726683009681974
Validation loss: 5.6929249548096434

Epoch: 5| Step: 6
Training loss: 5.540984128446348
Validation loss: 5.658550484688161

Epoch: 5| Step: 7
Training loss: 5.288988391802175
Validation loss: 5.6198261781531285

Epoch: 5| Step: 8
Training loss: 6.217002124616049
Validation loss: 5.575270425182763

Epoch: 5| Step: 9
Training loss: 5.401082121189603
Validation loss: 5.524068232079668

Epoch: 5| Step: 10
Training loss: 5.699399468090914
Validation loss: 5.466261779733894

Epoch: 2| Step: 0
Training loss: 5.551584399089143
Validation loss: 5.402121054097023

Epoch: 5| Step: 1
Training loss: 4.2603792345909985
Validation loss: 5.3335996447236464

Epoch: 5| Step: 2
Training loss: 5.856617515211525
Validation loss: 5.262181265955783

Epoch: 5| Step: 3
Training loss: 4.465777068488691
Validation loss: 5.187501468749665

Epoch: 5| Step: 4
Training loss: 4.753132841064888
Validation loss: 5.113863394495271

Epoch: 5| Step: 5
Training loss: 5.094471511759671
Validation loss: 5.041890160327351

Epoch: 5| Step: 6
Training loss: 5.536372684403602
Validation loss: 4.968718219267705

Epoch: 5| Step: 7
Training loss: 5.32378400789511
Validation loss: 4.898247418656595

Epoch: 5| Step: 8
Training loss: 5.076083386168411
Validation loss: 4.82660732302718

Epoch: 5| Step: 9
Training loss: 5.533072823209845
Validation loss: 4.747332581195174

Epoch: 5| Step: 10
Training loss: 4.253713668233145
Validation loss: 4.680476454254884

Epoch: 3| Step: 0
Training loss: 3.860825362636068
Validation loss: 4.633057703238994

Epoch: 5| Step: 1
Training loss: 4.597090771432626
Validation loss: 4.590271292876791

Epoch: 5| Step: 2
Training loss: 5.643547674631177
Validation loss: 4.549319051140518

Epoch: 5| Step: 3
Training loss: 4.175309385611583
Validation loss: 4.506890507671886

Epoch: 5| Step: 4
Training loss: 3.973078012349105
Validation loss: 4.46777231857579

Epoch: 5| Step: 5
Training loss: 4.659644201882239
Validation loss: 4.426440539760033

Epoch: 5| Step: 6
Training loss: 5.168689680381766
Validation loss: 4.382110499122717

Epoch: 5| Step: 7
Training loss: 3.923078375164471
Validation loss: 4.3350893080300406

Epoch: 5| Step: 8
Training loss: 5.698169467857535
Validation loss: 4.283308539820164

Epoch: 5| Step: 9
Training loss: 2.8156610315115276
Validation loss: 4.233751256278732

Epoch: 5| Step: 10
Training loss: 4.614454464228833
Validation loss: 4.217029507835083

Epoch: 4| Step: 0
Training loss: 3.884770289322866
Validation loss: 4.159200396627787

Epoch: 5| Step: 1
Training loss: 4.681071845663937
Validation loss: 4.135250618976672

Epoch: 5| Step: 2
Training loss: 3.94182784790657
Validation loss: 4.114296969875523

Epoch: 5| Step: 3
Training loss: 4.246543376176906
Validation loss: 4.090401551388232

Epoch: 5| Step: 4
Training loss: 4.323436635316818
Validation loss: 4.069704102076529

Epoch: 5| Step: 5
Training loss: 4.4256008882462385
Validation loss: 4.0387127459600665

Epoch: 5| Step: 6
Training loss: 4.02878465600277
Validation loss: 4.005015320800245

Epoch: 5| Step: 7
Training loss: 3.4728976359968207
Validation loss: 3.9798463574750227

Epoch: 5| Step: 8
Training loss: 4.409339200637585
Validation loss: 3.9603913833939957

Epoch: 5| Step: 9
Training loss: 3.8976093398754292
Validation loss: 3.945830619561504

Epoch: 5| Step: 10
Training loss: 4.648238695525548
Validation loss: 3.925793976166983

Epoch: 5| Step: 0
Training loss: 4.7846563833302564
Validation loss: 3.9099230987570706

Epoch: 5| Step: 1
Training loss: 3.779712963609839
Validation loss: 3.8873095604988643

Epoch: 5| Step: 2
Training loss: 4.331690892710402
Validation loss: 3.8627157118479696

Epoch: 5| Step: 3
Training loss: 4.483221776394504
Validation loss: 3.8462971830360244

Epoch: 5| Step: 4
Training loss: 4.134591482294698
Validation loss: 3.823731502256817

Epoch: 5| Step: 5
Training loss: 3.7622832986773918
Validation loss: 3.804005757716463

Epoch: 5| Step: 6
Training loss: 3.2473896988130377
Validation loss: 3.789499711392745

Epoch: 5| Step: 7
Training loss: 3.8713043802276923
Validation loss: 3.7715435108301687

Epoch: 5| Step: 8
Training loss: 4.111180362175432
Validation loss: 3.7567256829200493

Epoch: 5| Step: 9
Training loss: 2.936166988415731
Validation loss: 3.7397958379365384

Epoch: 5| Step: 10
Training loss: 4.171002586098718
Validation loss: 3.7245166050600695

Epoch: 6| Step: 0
Training loss: 3.7670456355251916
Validation loss: 3.7059107341870487

Epoch: 5| Step: 1
Training loss: 4.299304843867544
Validation loss: 3.6899774945781076

Epoch: 5| Step: 2
Training loss: 3.671733447653862
Validation loss: 3.6713309913764434

Epoch: 5| Step: 3
Training loss: 4.136045982975892
Validation loss: 3.655366459702387

Epoch: 5| Step: 4
Training loss: 3.767718607654999
Validation loss: 3.642686163489304

Epoch: 5| Step: 5
Training loss: 3.6226918995155963
Validation loss: 3.631297383069778

Epoch: 5| Step: 6
Training loss: 3.65576755568562
Validation loss: 3.608289021396094

Epoch: 5| Step: 7
Training loss: 4.352894550037379
Validation loss: 3.59976277241999

Epoch: 5| Step: 8
Training loss: 3.6993504856262174
Validation loss: 3.5888214771405984

Epoch: 5| Step: 9
Training loss: 3.790086871236082
Validation loss: 3.580885838039078

Epoch: 5| Step: 10
Training loss: 3.0902287644822506
Validation loss: 3.5639293000423224

Epoch: 7| Step: 0
Training loss: 3.9026565502762427
Validation loss: 3.556189585039785

Epoch: 5| Step: 1
Training loss: 3.72879364591727
Validation loss: 3.545090549964315

Epoch: 5| Step: 2
Training loss: 3.6651026829260327
Validation loss: 3.532560218151636

Epoch: 5| Step: 3
Training loss: 3.646310582486445
Validation loss: 3.5298275563262007

Epoch: 5| Step: 4
Training loss: 3.5725018823083468
Validation loss: 3.5160311206609447

Epoch: 5| Step: 5
Training loss: 3.4956949187662087
Validation loss: 3.5045353587899135

Epoch: 5| Step: 6
Training loss: 4.706796626024941
Validation loss: 3.504057643124437

Epoch: 5| Step: 7
Training loss: 3.288245890312379
Validation loss: 3.493388207374568

Epoch: 5| Step: 8
Training loss: 4.284846222476199
Validation loss: 3.502064627711964

Epoch: 5| Step: 9
Training loss: 3.3221615657847297
Validation loss: 3.5065181907816605

Epoch: 5| Step: 10
Training loss: 3.0242866683897707
Validation loss: 3.491688168504254

Epoch: 8| Step: 0
Training loss: 3.3946384285708517
Validation loss: 3.4946361435193007

Epoch: 5| Step: 1
Training loss: 3.600978448143863
Validation loss: 3.4851019500275116

Epoch: 5| Step: 2
Training loss: 3.270090800433317
Validation loss: 3.4760163439890333

Epoch: 5| Step: 3
Training loss: 3.658945768935999
Validation loss: 3.471067287756533

Epoch: 5| Step: 4
Training loss: 3.914344518555914
Validation loss: 3.456382243097542

Epoch: 5| Step: 5
Training loss: 3.6489118966035345
Validation loss: 3.454602208176442

Epoch: 5| Step: 6
Training loss: 4.013439489166758
Validation loss: 3.442150486600335

Epoch: 5| Step: 7
Training loss: 3.5778428678600696
Validation loss: 3.440749069855525

Epoch: 5| Step: 8
Training loss: 4.266607262277321
Validation loss: 3.4388588301309833

Epoch: 5| Step: 9
Training loss: 3.660644238164004
Validation loss: 3.4261044028187295

Epoch: 5| Step: 10
Training loss: 3.1987122447985867
Validation loss: 3.416840044410235

Epoch: 9| Step: 0
Training loss: 3.769502534905201
Validation loss: 3.412998846909563

Epoch: 5| Step: 1
Training loss: 3.4991484014717726
Validation loss: 3.4060044431087007

Epoch: 5| Step: 2
Training loss: 3.7461291362216844
Validation loss: 3.397443015531079

Epoch: 5| Step: 3
Training loss: 3.6265746018233695
Validation loss: 3.386393667746087

Epoch: 5| Step: 4
Training loss: 3.674070310747391
Validation loss: 3.379261395323663

Epoch: 5| Step: 5
Training loss: 3.501458272953063
Validation loss: 3.368374451461713

Epoch: 5| Step: 6
Training loss: 4.155747462129303
Validation loss: 3.361384560299661

Epoch: 5| Step: 7
Training loss: 3.9002743600050738
Validation loss: 3.360235393946623

Epoch: 5| Step: 8
Training loss: 3.065178770044903
Validation loss: 3.356342936260439

Epoch: 5| Step: 9
Training loss: 3.685199990092801
Validation loss: 3.348674881529227

Epoch: 5| Step: 10
Training loss: 2.7235921950404496
Validation loss: 3.3431801197723336

Epoch: 10| Step: 0
Training loss: 4.531390589144432
Validation loss: 3.343194342848463

Epoch: 5| Step: 1
Training loss: 3.4735367198368836
Validation loss: 3.335280696845529

Epoch: 5| Step: 2
Training loss: 4.3661920439998845
Validation loss: 3.3283209543959575

Epoch: 5| Step: 3
Training loss: 3.888963336837481
Validation loss: 3.3229487713288233

Epoch: 5| Step: 4
Training loss: 3.331511158395052
Validation loss: 3.320334826206761

Epoch: 5| Step: 5
Training loss: 3.1280539276859853
Validation loss: 3.3203606375112886

Epoch: 5| Step: 6
Training loss: 3.698090168639178
Validation loss: 3.314472204981761

Epoch: 5| Step: 7
Training loss: 2.415408651081881
Validation loss: 3.3121706426781232

Epoch: 5| Step: 8
Training loss: 3.2802039522634603
Validation loss: 3.3081174406569023

Epoch: 5| Step: 9
Training loss: 3.1332249548274875
Validation loss: 3.305589241650587

Epoch: 5| Step: 10
Training loss: 3.433678739882446
Validation loss: 3.302386002575822

Epoch: 11| Step: 0
Training loss: 2.977012780441103
Validation loss: 3.2972686918205465

Epoch: 5| Step: 1
Training loss: 3.399427668701225
Validation loss: 3.294029363501313

Epoch: 5| Step: 2
Training loss: 4.1186208238735365
Validation loss: 3.28879505715064

Epoch: 5| Step: 3
Training loss: 3.1894665803643
Validation loss: 3.2837776741882068

Epoch: 5| Step: 4
Training loss: 3.1795957209957697
Validation loss: 3.2829650334616702

Epoch: 5| Step: 5
Training loss: 3.7347879221401925
Validation loss: 3.279783179850025

Epoch: 5| Step: 6
Training loss: 3.155989230119438
Validation loss: 3.2774328574415263

Epoch: 5| Step: 7
Training loss: 3.879185784631173
Validation loss: 3.2722134870619684

Epoch: 5| Step: 8
Training loss: 3.529746891921957
Validation loss: 3.278345400470767

Epoch: 5| Step: 9
Training loss: 4.067343304317424
Validation loss: 3.282542556281773

Epoch: 5| Step: 10
Training loss: 3.3391263849468826
Validation loss: 3.2748739701286116

Epoch: 12| Step: 0
Training loss: 3.2221720753710192
Validation loss: 3.271725905050009

Epoch: 5| Step: 1
Training loss: 3.5756336850969506
Validation loss: 3.262447352383948

Epoch: 5| Step: 2
Training loss: 3.5720445701150862
Validation loss: 3.2598028002499357

Epoch: 5| Step: 3
Training loss: 2.8980093997147356
Validation loss: 3.2565271133641858

Epoch: 5| Step: 4
Training loss: 3.982406429094311
Validation loss: 3.251951273980107

Epoch: 5| Step: 5
Training loss: 3.63069008796283
Validation loss: 3.2538481081544646

Epoch: 5| Step: 6
Training loss: 4.164299763116224
Validation loss: 3.245913853086855

Epoch: 5| Step: 7
Training loss: 3.3792374465121076
Validation loss: 3.244243904198386

Epoch: 5| Step: 8
Training loss: 3.153896398484041
Validation loss: 3.2462170168303546

Epoch: 5| Step: 9
Training loss: 3.7175561607443908
Validation loss: 3.242595042789602

Epoch: 5| Step: 10
Training loss: 2.960136365584607
Validation loss: 3.2408915751003553

Epoch: 13| Step: 0
Training loss: 3.8010253827843994
Validation loss: 3.242592456690582

Epoch: 5| Step: 1
Training loss: 2.986778050741241
Validation loss: 3.237881175331487

Epoch: 5| Step: 2
Training loss: 3.6963116381823786
Validation loss: 3.2334349295872986

Epoch: 5| Step: 3
Training loss: 3.6167354424847407
Validation loss: 3.22839425038623

Epoch: 5| Step: 4
Training loss: 3.6094384125923074
Validation loss: 3.2242332560084273

Epoch: 5| Step: 5
Training loss: 2.819087980523338
Validation loss: 3.219721775565874

Epoch: 5| Step: 6
Training loss: 3.0094557199714287
Validation loss: 3.2186071593363828

Epoch: 5| Step: 7
Training loss: 3.8847981523980737
Validation loss: 3.215987325608974

Epoch: 5| Step: 8
Training loss: 3.143162399800716
Validation loss: 3.2132084748337904

Epoch: 5| Step: 9
Training loss: 3.4694276439896945
Validation loss: 3.2096072095650605

Epoch: 5| Step: 10
Training loss: 4.112299469577846
Validation loss: 3.209161136770369

Epoch: 14| Step: 0
Training loss: 4.010697127935039
Validation loss: 3.2034384713401867

Epoch: 5| Step: 1
Training loss: 3.7005072890303827
Validation loss: 3.20028718004543

Epoch: 5| Step: 2
Training loss: 2.934890724500369
Validation loss: 3.1948128117066013

Epoch: 5| Step: 3
Training loss: 3.679509832867478
Validation loss: 3.192699440724906

Epoch: 5| Step: 4
Training loss: 3.545738542293091
Validation loss: 3.1854159036251803

Epoch: 5| Step: 5
Training loss: 3.307372533255132
Validation loss: 3.1837650915547253

Epoch: 5| Step: 6
Training loss: 3.0569217247941687
Validation loss: 3.1756175441136825

Epoch: 5| Step: 7
Training loss: 3.1474736633895697
Validation loss: 3.172667695220593

Epoch: 5| Step: 8
Training loss: 3.162662752208035
Validation loss: 3.1705050938901733

Epoch: 5| Step: 9
Training loss: 3.3308529844476635
Validation loss: 3.1652750823046465

Epoch: 5| Step: 10
Training loss: 3.958864651541352
Validation loss: 3.1561071427914453

Epoch: 15| Step: 0
Training loss: 4.005106527409532
Validation loss: 3.1519662952539744

Epoch: 5| Step: 1
Training loss: 3.3674221443856034
Validation loss: 3.146751791831723

Epoch: 5| Step: 2
Training loss: 3.1984085715308317
Validation loss: 3.144131931699595

Epoch: 5| Step: 3
Training loss: 3.23737111663556
Validation loss: 3.1437493320956027

Epoch: 5| Step: 4
Training loss: 3.2899109387155416
Validation loss: 3.1406299866724643

Epoch: 5| Step: 5
Training loss: 3.4245664558841025
Validation loss: 3.1426916969505023

Epoch: 5| Step: 6
Training loss: 3.341733948624012
Validation loss: 3.1381358146749494

Epoch: 5| Step: 7
Training loss: 3.493471187050699
Validation loss: 3.138920958765306

Epoch: 5| Step: 8
Training loss: 3.4821348644346513
Validation loss: 3.1368862528234294

Epoch: 5| Step: 9
Training loss: 3.2096849212027023
Validation loss: 3.1524276338994053

Epoch: 5| Step: 10
Training loss: 3.4297684158129975
Validation loss: 3.132172900247171

Epoch: 16| Step: 0
Training loss: 3.595394521189641
Validation loss: 3.1321400092021587

Epoch: 5| Step: 1
Training loss: 3.288036630440372
Validation loss: 3.130239305576231

Epoch: 5| Step: 2
Training loss: 3.8912955935632
Validation loss: 3.1258973816405367

Epoch: 5| Step: 3
Training loss: 3.0396734177694706
Validation loss: 3.1238325075207487

Epoch: 5| Step: 4
Training loss: 3.9200520325146284
Validation loss: 3.1224819350295787

Epoch: 5| Step: 5
Training loss: 3.3654906916406735
Validation loss: 3.120079381565006

Epoch: 5| Step: 6
Training loss: 3.3256743815597893
Validation loss: 3.1157553688559516

Epoch: 5| Step: 7
Training loss: 4.023499601310785
Validation loss: 3.1143177347378743

Epoch: 5| Step: 8
Training loss: 2.7998955468721998
Validation loss: 3.1137307997981543

Epoch: 5| Step: 9
Training loss: 2.810664786171088
Validation loss: 3.1144418495323243

Epoch: 5| Step: 10
Training loss: 2.980895725528998
Validation loss: 3.11486440349188

Epoch: 17| Step: 0
Training loss: 3.23094622071308
Validation loss: 3.106397983190874

Epoch: 5| Step: 1
Training loss: 3.341096056564656
Validation loss: 3.1280271311040897

Epoch: 5| Step: 2
Training loss: 3.876088389472424
Validation loss: 3.1084395508395852

Epoch: 5| Step: 3
Training loss: 3.782273587486842
Validation loss: 3.107771677511424

Epoch: 5| Step: 4
Training loss: 3.2635441771659037
Validation loss: 3.10832849821261

Epoch: 5| Step: 5
Training loss: 3.175179399843638
Validation loss: 3.1103047690433607

Epoch: 5| Step: 6
Training loss: 3.071849021142056
Validation loss: 3.112845247245086

Epoch: 5| Step: 7
Training loss: 2.8325763888045605
Validation loss: 3.111664382117585

Epoch: 5| Step: 8
Training loss: 3.7407690238792677
Validation loss: 3.1102123335777865

Epoch: 5| Step: 9
Training loss: 3.720173923774576
Validation loss: 3.1085141060401673

Epoch: 5| Step: 10
Training loss: 2.979740878878771
Validation loss: 3.1075241525685375

Epoch: 18| Step: 0
Training loss: 3.1194099782925133
Validation loss: 3.1050610371204614

Epoch: 5| Step: 1
Training loss: 3.5104186438187974
Validation loss: 3.1050617347802074

Epoch: 5| Step: 2
Training loss: 3.632147090227265
Validation loss: 3.100704592823695

Epoch: 5| Step: 3
Training loss: 3.3319771550964994
Validation loss: 3.0995816121111357

Epoch: 5| Step: 4
Training loss: 3.2200917530611335
Validation loss: 3.096682671133224

Epoch: 5| Step: 5
Training loss: 3.375188751594008
Validation loss: 3.0929745153516115

Epoch: 5| Step: 6
Training loss: 2.981808822367627
Validation loss: 3.0923191058323485

Epoch: 5| Step: 7
Training loss: 3.1868098390676556
Validation loss: 3.0892259457137663

Epoch: 5| Step: 8
Training loss: 3.5338190236753557
Validation loss: 3.08833496871836

Epoch: 5| Step: 9
Training loss: 3.578003727219561
Validation loss: 3.0858843540128817

Epoch: 5| Step: 10
Training loss: 3.6187983112701056
Validation loss: 3.0844481635887147

Epoch: 19| Step: 0
Training loss: 3.9647987701420266
Validation loss: 3.0833457795756356

Epoch: 5| Step: 1
Training loss: 3.3032945082378435
Validation loss: 3.0825315775581745

Epoch: 5| Step: 2
Training loss: 2.911077939718922
Validation loss: 3.080844345701735

Epoch: 5| Step: 3
Training loss: 3.466893429553306
Validation loss: 3.079010014128741

Epoch: 5| Step: 4
Training loss: 3.4528421829885305
Validation loss: 3.0788527467992304

Epoch: 5| Step: 5
Training loss: 3.091986876268652
Validation loss: 3.076099324501283

Epoch: 5| Step: 6
Training loss: 3.451519070546785
Validation loss: 3.075388603489926

Epoch: 5| Step: 7
Training loss: 2.9158700854294826
Validation loss: 3.0729649048626055

Epoch: 5| Step: 8
Training loss: 3.2053729845134455
Validation loss: 3.073149902324541

Epoch: 5| Step: 9
Training loss: 3.09018170115723
Validation loss: 3.0730262854983907

Epoch: 5| Step: 10
Training loss: 4.03551216439191
Validation loss: 3.0706731672152947

Epoch: 20| Step: 0
Training loss: 3.2665938258970417
Validation loss: 3.06791017938227

Epoch: 5| Step: 1
Training loss: 2.6821578402914352
Validation loss: 3.064590146002595

Epoch: 5| Step: 2
Training loss: 2.883601879190062
Validation loss: 3.0623088573603074

Epoch: 5| Step: 3
Training loss: 3.365411630878378
Validation loss: 3.0610311994421253

Epoch: 5| Step: 4
Training loss: 3.8883115945451716
Validation loss: 3.060706240495302

Epoch: 5| Step: 5
Training loss: 3.3272701114657526
Validation loss: 3.056670593704

Epoch: 5| Step: 6
Training loss: 3.13189638208548
Validation loss: 3.0548534265894762

Epoch: 5| Step: 7
Training loss: 3.3107459264458123
Validation loss: 3.05361787148324

Epoch: 5| Step: 8
Training loss: 3.28865755537735
Validation loss: 3.051688973517949

Epoch: 5| Step: 9
Training loss: 3.615483650998805
Validation loss: 3.049532442988451

Epoch: 5| Step: 10
Training loss: 3.9202220822698814
Validation loss: 3.047650221192403

Epoch: 21| Step: 0
Training loss: 3.234901864451507
Validation loss: 3.0456626228022916

Epoch: 5| Step: 1
Training loss: 3.605462137300951
Validation loss: 3.0439044229385743

Epoch: 5| Step: 2
Training loss: 3.5142150764366415
Validation loss: 3.0424721795105563

Epoch: 5| Step: 3
Training loss: 3.4240813088255138
Validation loss: 3.0393432652832653

Epoch: 5| Step: 4
Training loss: 3.952004254960461
Validation loss: 3.039825936587243

Epoch: 5| Step: 5
Training loss: 2.817940938001703
Validation loss: 3.0349636411903984

Epoch: 5| Step: 6
Training loss: 2.3949404393317963
Validation loss: 3.036157856617745

Epoch: 5| Step: 7
Training loss: 3.892105004880849
Validation loss: 3.0340329719562544

Epoch: 5| Step: 8
Training loss: 3.0610215647254684
Validation loss: 3.031037805587703

Epoch: 5| Step: 9
Training loss: 2.844930382867359
Validation loss: 3.0319003967895948

Epoch: 5| Step: 10
Training loss: 3.567199685622734
Validation loss: 3.0447011743975194

Epoch: 22| Step: 0
Training loss: 3.1229126634799034
Validation loss: 3.0274190541248776

Epoch: 5| Step: 1
Training loss: 2.9280884307890203
Validation loss: 3.025264412627568

Epoch: 5| Step: 2
Training loss: 2.95181778328338
Validation loss: 3.025937513818529

Epoch: 5| Step: 3
Training loss: 3.2055229329330293
Validation loss: 3.0296240944212056

Epoch: 5| Step: 4
Training loss: 3.724182776598864
Validation loss: 3.0241540215209564

Epoch: 5| Step: 5
Training loss: 3.6560948004754303
Validation loss: 3.021726892101211

Epoch: 5| Step: 6
Training loss: 4.133372508652963
Validation loss: 3.021862989764615

Epoch: 5| Step: 7
Training loss: 2.592944100433172
Validation loss: 3.0193020909659767

Epoch: 5| Step: 8
Training loss: 3.804332176081531
Validation loss: 3.017760574608072

Epoch: 5| Step: 9
Training loss: 2.884659503697188
Validation loss: 3.0166400244930127

Epoch: 5| Step: 10
Training loss: 3.129278077547774
Validation loss: 3.0190405074682336

Epoch: 23| Step: 0
Training loss: 3.084537082112208
Validation loss: 3.015127907950564

Epoch: 5| Step: 1
Training loss: 3.1856693171785873
Validation loss: 3.0170075770259883

Epoch: 5| Step: 2
Training loss: 3.3057657561444174
Validation loss: 3.014186059525817

Epoch: 5| Step: 3
Training loss: 3.8205195645811276
Validation loss: 3.016264377410121

Epoch: 5| Step: 4
Training loss: 3.6182999352439977
Validation loss: 3.014874486009714

Epoch: 5| Step: 5
Training loss: 3.703822975534095
Validation loss: 3.012542588522606

Epoch: 5| Step: 6
Training loss: 3.7295475486448137
Validation loss: 3.012269852069704

Epoch: 5| Step: 7
Training loss: 3.156779934047027
Validation loss: 3.0115314941109497

Epoch: 5| Step: 8
Training loss: 2.9940895031411174
Validation loss: 3.0084475804210298

Epoch: 5| Step: 9
Training loss: 2.9738895299182224
Validation loss: 3.005978370026545

Epoch: 5| Step: 10
Training loss: 2.457348825766371
Validation loss: 3.009493484475761

Epoch: 24| Step: 0
Training loss: 3.28198074196623
Validation loss: 3.019232132439147

Epoch: 5| Step: 1
Training loss: 3.1708901666334235
Validation loss: 3.026828756626548

Epoch: 5| Step: 2
Training loss: 3.2034626108282596
Validation loss: 3.009549697611443

Epoch: 5| Step: 3
Training loss: 3.6888567481370655
Validation loss: 3.00265400488559

Epoch: 5| Step: 4
Training loss: 3.3586295786807976
Validation loss: 2.9986030520470206

Epoch: 5| Step: 5
Training loss: 3.0321361386980357
Validation loss: 2.9970496190220706

Epoch: 5| Step: 6
Training loss: 2.722212329725426
Validation loss: 2.9962447618077834

Epoch: 5| Step: 7
Training loss: 3.6768338098055504
Validation loss: 2.995600257348368

Epoch: 5| Step: 8
Training loss: 3.2276008172987622
Validation loss: 2.9964068867452

Epoch: 5| Step: 9
Training loss: 3.826366783735176
Validation loss: 2.991256693751328

Epoch: 5| Step: 10
Training loss: 2.864025232683411
Validation loss: 2.9937854459294075

Epoch: 25| Step: 0
Training loss: 2.936724783690014
Validation loss: 2.995248757996625

Epoch: 5| Step: 1
Training loss: 3.6636494157637376
Validation loss: 3.002288593162798

Epoch: 5| Step: 2
Training loss: 3.4325695398097738
Validation loss: 2.996363698890718

Epoch: 5| Step: 3
Training loss: 3.654511388846796
Validation loss: 2.9889511452425017

Epoch: 5| Step: 4
Training loss: 2.932707590493865
Validation loss: 2.9892251319384044

Epoch: 5| Step: 5
Training loss: 3.0254903916026863
Validation loss: 2.98892753679802

Epoch: 5| Step: 6
Training loss: 3.3955585079890405
Validation loss: 2.9896256032702873

Epoch: 5| Step: 7
Training loss: 3.5620060628489196
Validation loss: 2.986564447730094

Epoch: 5| Step: 8
Training loss: 2.9978855947051133
Validation loss: 2.9865501314473732

Epoch: 5| Step: 9
Training loss: 3.072070989245507
Validation loss: 2.9842922184394136

Epoch: 5| Step: 10
Training loss: 3.428628327828519
Validation loss: 2.9899495915807326

Epoch: 26| Step: 0
Training loss: 3.2466436808540737
Validation loss: 3.012218385112164

Epoch: 5| Step: 1
Training loss: 3.0005057226532337
Validation loss: 3.0006234758519996

Epoch: 5| Step: 2
Training loss: 3.8121554109530082
Validation loss: 3.0349955209308184

Epoch: 5| Step: 3
Training loss: 2.6054936397799158
Validation loss: 2.999957831233366

Epoch: 5| Step: 4
Training loss: 3.521061605844652
Validation loss: 3.0064930858464374

Epoch: 5| Step: 5
Training loss: 3.599939075590228
Validation loss: 3.0120760342625403

Epoch: 5| Step: 6
Training loss: 3.920107013643006
Validation loss: 3.008033136426645

Epoch: 5| Step: 7
Training loss: 3.094065794577471
Validation loss: 2.9978867491568364

Epoch: 5| Step: 8
Training loss: 2.848496719891463
Validation loss: 2.9878733577007344

Epoch: 5| Step: 9
Training loss: 3.6500542466822523
Validation loss: 2.988601752958146

Epoch: 5| Step: 10
Training loss: 2.6571819690017353
Validation loss: 2.983497845070205

Epoch: 27| Step: 0
Training loss: 2.9618375914852186
Validation loss: 2.9826334685856315

Epoch: 5| Step: 1
Training loss: 3.5982143370997854
Validation loss: 2.991309351827052

Epoch: 5| Step: 2
Training loss: 2.9118568725414704
Validation loss: 2.9780476042620667

Epoch: 5| Step: 3
Training loss: 3.169608372706023
Validation loss: 2.9748922341774633

Epoch: 5| Step: 4
Training loss: 3.337698764097197
Validation loss: 2.9780321847469864

Epoch: 5| Step: 5
Training loss: 2.634465635285873
Validation loss: 3.0169926939753706

Epoch: 5| Step: 6
Training loss: 3.9370869011118788
Validation loss: 3.001019270510301

Epoch: 5| Step: 7
Training loss: 3.4557591398425007
Validation loss: 2.9785968216308976

Epoch: 5| Step: 8
Training loss: 2.8374749001892687
Validation loss: 2.9756349528686856

Epoch: 5| Step: 9
Training loss: 3.4648598516836264
Validation loss: 2.977755671879134

Epoch: 5| Step: 10
Training loss: 3.663550888164167
Validation loss: 2.9852224902373488

Epoch: 28| Step: 0
Training loss: 3.084989532502406
Validation loss: 2.971750710256931

Epoch: 5| Step: 1
Training loss: 2.893697229814639
Validation loss: 2.9663808145917736

Epoch: 5| Step: 2
Training loss: 3.0438724689010206
Validation loss: 2.965116777383482

Epoch: 5| Step: 3
Training loss: 3.2122390225454684
Validation loss: 2.969069199815767

Epoch: 5| Step: 4
Training loss: 3.833597187968132
Validation loss: 2.975418182209116

Epoch: 5| Step: 5
Training loss: 3.3654059633688784
Validation loss: 2.9777229029627006

Epoch: 5| Step: 6
Training loss: 2.5468964371042313
Validation loss: 2.969742659630953

Epoch: 5| Step: 7
Training loss: 3.521063501783765
Validation loss: 2.9673960095339194

Epoch: 5| Step: 8
Training loss: 2.806811705109021
Validation loss: 2.9700039454641414

Epoch: 5| Step: 9
Training loss: 3.9734610883497883
Validation loss: 2.9663957528008504

Epoch: 5| Step: 10
Training loss: 3.4057621037746197
Validation loss: 2.9603325231207003

Epoch: 29| Step: 0
Training loss: 3.172806025325346
Validation loss: 2.956056245081931

Epoch: 5| Step: 1
Training loss: 2.980693363710329
Validation loss: 2.9557765540387795

Epoch: 5| Step: 2
Training loss: 3.3925566203172064
Validation loss: 2.957386511511253

Epoch: 5| Step: 3
Training loss: 3.579962512624521
Validation loss: 2.953855447736714

Epoch: 5| Step: 4
Training loss: 3.1707488066693514
Validation loss: 2.9521020672726856

Epoch: 5| Step: 5
Training loss: 3.0848556746939404
Validation loss: 2.950551215499796

Epoch: 5| Step: 6
Training loss: 3.604524201463087
Validation loss: 2.9505785682182766

Epoch: 5| Step: 7
Training loss: 3.2303456440985814
Validation loss: 2.951045063282775

Epoch: 5| Step: 8
Training loss: 3.489694136193682
Validation loss: 2.948999366459274

Epoch: 5| Step: 9
Training loss: 2.916797980122748
Validation loss: 2.9477818436974

Epoch: 5| Step: 10
Training loss: 3.120425576504496
Validation loss: 2.95158885113542

Epoch: 30| Step: 0
Training loss: 3.388716059240043
Validation loss: 2.9752322140715872

Epoch: 5| Step: 1
Training loss: 2.5734083089464144
Validation loss: 2.9665408106957742

Epoch: 5| Step: 2
Training loss: 3.533725782108341
Validation loss: 2.9980448159098567

Epoch: 5| Step: 3
Training loss: 3.243482363322872
Validation loss: 2.9786548873376777

Epoch: 5| Step: 4
Training loss: 3.7945836064176723
Validation loss: 2.9515361914328633

Epoch: 5| Step: 5
Training loss: 2.8619576552568695
Validation loss: 2.945079151966494

Epoch: 5| Step: 6
Training loss: 3.3460726648023065
Validation loss: 2.9438007568514903

Epoch: 5| Step: 7
Training loss: 3.7896429816709425
Validation loss: 2.9455562788892284

Epoch: 5| Step: 8
Training loss: 2.8616897302437625
Validation loss: 2.9481458033896737

Epoch: 5| Step: 9
Training loss: 3.4539034557180224
Validation loss: 2.9498973769491474

Epoch: 5| Step: 10
Training loss: 2.5721544894900763
Validation loss: 2.9470694232587804

Epoch: 31| Step: 0
Training loss: 3.741407595857453
Validation loss: 2.9467963723504726

Epoch: 5| Step: 1
Training loss: 2.9178659607376662
Validation loss: 2.9423216375207537

Epoch: 5| Step: 2
Training loss: 3.5850648171325985
Validation loss: 2.9390796157385557

Epoch: 5| Step: 3
Training loss: 3.6412811342919125
Validation loss: 2.938316295504747

Epoch: 5| Step: 4
Training loss: 3.468640987298497
Validation loss: 2.9371062856864154

Epoch: 5| Step: 5
Training loss: 3.2055044872756513
Validation loss: 2.9363353814485293

Epoch: 5| Step: 6
Training loss: 3.2466768734854408
Validation loss: 2.942831654986058

Epoch: 5| Step: 7
Training loss: 2.897648377457963
Validation loss: 2.9535412655341347

Epoch: 5| Step: 8
Training loss: 3.309841024493756
Validation loss: 2.9443612539367923

Epoch: 5| Step: 9
Training loss: 3.0172987330204992
Validation loss: 2.935936594882726

Epoch: 5| Step: 10
Training loss: 2.2536039100052427
Validation loss: 2.9323252172176684

Epoch: 32| Step: 0
Training loss: 3.414983908753583
Validation loss: 2.9331090422452135

Epoch: 5| Step: 1
Training loss: 3.0697699691131652
Validation loss: 2.9312508315946153

Epoch: 5| Step: 2
Training loss: 3.5999733817917843
Validation loss: 2.9320353617810544

Epoch: 5| Step: 3
Training loss: 3.207476827726559
Validation loss: 2.929103656962163

Epoch: 5| Step: 4
Training loss: 3.561550482314371
Validation loss: 2.929996642725697

Epoch: 5| Step: 5
Training loss: 3.567464748708299
Validation loss: 2.9289414687733983

Epoch: 5| Step: 6
Training loss: 2.881187084115135
Validation loss: 2.9287811658108738

Epoch: 5| Step: 7
Training loss: 2.9043082036282923
Validation loss: 2.9259020543030756

Epoch: 5| Step: 8
Training loss: 3.0116153605287894
Validation loss: 2.925507788644842

Epoch: 5| Step: 9
Training loss: 3.2148336639802295
Validation loss: 2.9241465955990456

Epoch: 5| Step: 10
Training loss: 2.9940546251103255
Validation loss: 2.9249737644693004

Epoch: 33| Step: 0
Training loss: 2.542027828217298
Validation loss: 2.9236925285084516

Epoch: 5| Step: 1
Training loss: 3.209458356181534
Validation loss: 2.9232999397838464

Epoch: 5| Step: 2
Training loss: 2.7231078902103887
Validation loss: 2.9215177842225444

Epoch: 5| Step: 3
Training loss: 3.1983435694809184
Validation loss: 2.9241037528958542

Epoch: 5| Step: 4
Training loss: 3.5490847522615394
Validation loss: 2.9262472397960146

Epoch: 5| Step: 5
Training loss: 2.9173464028427767
Validation loss: 2.9314982039897814

Epoch: 5| Step: 6
Training loss: 3.3030482345510044
Validation loss: 2.928167814370165

Epoch: 5| Step: 7
Training loss: 3.1126302423765075
Validation loss: 2.918585854014064

Epoch: 5| Step: 8
Training loss: 3.5097580168253653
Validation loss: 2.916686627250847

Epoch: 5| Step: 9
Training loss: 3.449658617461497
Validation loss: 2.9207112011108953

Epoch: 5| Step: 10
Training loss: 3.824333461954208
Validation loss: 2.9191443196239213

Epoch: 34| Step: 0
Training loss: 2.9951538043897985
Validation loss: 2.9171519387047824

Epoch: 5| Step: 1
Training loss: 3.5187301824902644
Validation loss: 2.916761534476715

Epoch: 5| Step: 2
Training loss: 3.0120135409188835
Validation loss: 2.917018024241681

Epoch: 5| Step: 3
Training loss: 3.435478587119791
Validation loss: 2.9181802273827624

Epoch: 5| Step: 4
Training loss: 3.206896092567227
Validation loss: 2.915975706523981

Epoch: 5| Step: 5
Training loss: 3.290540639406382
Validation loss: 2.9200505352493633

Epoch: 5| Step: 6
Training loss: 2.979378397071203
Validation loss: 2.9153921890895527

Epoch: 5| Step: 7
Training loss: 2.958222687134085
Validation loss: 2.9163189515195422

Epoch: 5| Step: 8
Training loss: 3.3397633682304386
Validation loss: 2.917781310673829

Epoch: 5| Step: 9
Training loss: 3.494113877238316
Validation loss: 2.917180472851253

Epoch: 5| Step: 10
Training loss: 3.0835223440712602
Validation loss: 2.919072713365355

Epoch: 35| Step: 0
Training loss: 3.809188279918397
Validation loss: 2.9156550175021394

Epoch: 5| Step: 1
Training loss: 2.8351259357663943
Validation loss: 2.909618627596224

Epoch: 5| Step: 2
Training loss: 2.663302315908134
Validation loss: 2.9091790503745623

Epoch: 5| Step: 3
Training loss: 3.1250547785726237
Validation loss: 2.9083741455242165

Epoch: 5| Step: 4
Training loss: 3.1867547753521888
Validation loss: 2.9094492574702966

Epoch: 5| Step: 5
Training loss: 3.452971718264398
Validation loss: 2.910499108458803

Epoch: 5| Step: 6
Training loss: 3.4480138728488896
Validation loss: 2.922092798352283

Epoch: 5| Step: 7
Training loss: 3.124480547647393
Validation loss: 2.936456952861544

Epoch: 5| Step: 8
Training loss: 3.7768064509282757
Validation loss: 2.9627014978455666

Epoch: 5| Step: 9
Training loss: 3.229868232236018
Validation loss: 2.936609286310517

Epoch: 5| Step: 10
Training loss: 2.4051251445100306
Validation loss: 2.8981477370191544

Epoch: 36| Step: 0
Training loss: 2.9595050013829085
Validation loss: 2.941768966239742

Epoch: 5| Step: 1
Training loss: 2.971894215422402
Validation loss: 2.999893157519416

Epoch: 5| Step: 2
Training loss: 4.015463977954721
Validation loss: 2.9031071989608983

Epoch: 5| Step: 3
Training loss: 3.6945739395150095
Validation loss: 2.901820432285567

Epoch: 5| Step: 4
Training loss: 2.6854282644261613
Validation loss: 2.8995536139219085

Epoch: 5| Step: 5
Training loss: 3.0387921445961195
Validation loss: 2.908149314728599

Epoch: 5| Step: 6
Training loss: 2.6132774181936593
Validation loss: 2.9241777968117195

Epoch: 5| Step: 7
Training loss: 3.282099005443127
Validation loss: 2.965419869981293

Epoch: 5| Step: 8
Training loss: 3.647475056448577
Validation loss: 2.9655958638114504

Epoch: 5| Step: 9
Training loss: 3.3716702460060852
Validation loss: 2.924265893794031

Epoch: 5| Step: 10
Training loss: 2.7663997276248655
Validation loss: 2.901969754290962

Epoch: 37| Step: 0
Training loss: 3.64223028981829
Validation loss: 2.9006055396310026

Epoch: 5| Step: 1
Training loss: 2.8059220426120732
Validation loss: 2.9080701710410075

Epoch: 5| Step: 2
Training loss: 3.6410067771506998
Validation loss: 2.891445877246036

Epoch: 5| Step: 3
Training loss: 2.445742438304558
Validation loss: 2.8978369146730576

Epoch: 5| Step: 4
Training loss: 3.42888783232444
Validation loss: 2.9085373836485955

Epoch: 5| Step: 5
Training loss: 3.630779000757792
Validation loss: 2.9106697228010607

Epoch: 5| Step: 6
Training loss: 3.4629625032197584
Validation loss: 2.9081149204854944

Epoch: 5| Step: 7
Training loss: 2.991968689729193
Validation loss: 2.891774488609628

Epoch: 5| Step: 8
Training loss: 2.5741641975144827
Validation loss: 2.892296152968102

Epoch: 5| Step: 9
Training loss: 3.1988601204095013
Validation loss: 2.892703314975757

Epoch: 5| Step: 10
Training loss: 3.122287030375143
Validation loss: 2.8918686550252177

Epoch: 38| Step: 0
Training loss: 3.715607669876532
Validation loss: 2.8865418761068047

Epoch: 5| Step: 1
Training loss: 2.5768354485303266
Validation loss: 2.887892796151258

Epoch: 5| Step: 2
Training loss: 2.9153100991563767
Validation loss: 2.88678290072036

Epoch: 5| Step: 3
Training loss: 3.162363608815462
Validation loss: 2.8908553936553787

Epoch: 5| Step: 4
Training loss: 3.7386190008733715
Validation loss: 2.8868011716390036

Epoch: 5| Step: 5
Training loss: 3.1657631906998103
Validation loss: 2.8848792719188414

Epoch: 5| Step: 6
Training loss: 2.822340809173733
Validation loss: 2.8857881999764703

Epoch: 5| Step: 7
Training loss: 3.2488207511639295
Validation loss: 2.881236907265115

Epoch: 5| Step: 8
Training loss: 3.049541538989502
Validation loss: 2.8832229965393017

Epoch: 5| Step: 9
Training loss: 2.8652501850173047
Validation loss: 2.880278129082804

Epoch: 5| Step: 10
Training loss: 3.6554281501121486
Validation loss: 2.882513933927805

Epoch: 39| Step: 0
Training loss: 3.0040640324499694
Validation loss: 2.8869224313409108

Epoch: 5| Step: 1
Training loss: 3.4407679889288807
Validation loss: 2.888178524930024

Epoch: 5| Step: 2
Training loss: 3.368656271796612
Validation loss: 2.8846083096947797

Epoch: 5| Step: 3
Training loss: 3.2344675834046788
Validation loss: 2.8756598722499622

Epoch: 5| Step: 4
Training loss: 3.332456823185194
Validation loss: 2.8741541158030066

Epoch: 5| Step: 5
Training loss: 2.1976753090290693
Validation loss: 2.874086876130106

Epoch: 5| Step: 6
Training loss: 3.5377969731742493
Validation loss: 2.881024579650079

Epoch: 5| Step: 7
Training loss: 3.2572006273046297
Validation loss: 2.8722077739330465

Epoch: 5| Step: 8
Training loss: 3.625884244212603
Validation loss: 2.877946160003538

Epoch: 5| Step: 9
Training loss: 3.0532841495511667
Validation loss: 2.8844655937510635

Epoch: 5| Step: 10
Training loss: 2.67505478847404
Validation loss: 2.868427166097171

Epoch: 40| Step: 0
Training loss: 3.2927800641467515
Validation loss: 2.867856306937045

Epoch: 5| Step: 1
Training loss: 3.7194735039609412
Validation loss: 2.8702558580472917

Epoch: 5| Step: 2
Training loss: 2.3992131373825183
Validation loss: 2.868571226922365

Epoch: 5| Step: 3
Training loss: 3.9007715489064227
Validation loss: 2.8664662132115137

Epoch: 5| Step: 4
Training loss: 2.999418520205306
Validation loss: 2.866876896115247

Epoch: 5| Step: 5
Training loss: 2.8360111447695044
Validation loss: 2.865576764493634

Epoch: 5| Step: 6
Training loss: 3.284092716241743
Validation loss: 2.863460377194951

Epoch: 5| Step: 7
Training loss: 3.434528245361869
Validation loss: 2.863536538894375

Epoch: 5| Step: 8
Training loss: 3.0320757498224107
Validation loss: 2.86530643647677

Epoch: 5| Step: 9
Training loss: 3.008894292321637
Validation loss: 2.8619907410305196

Epoch: 5| Step: 10
Training loss: 2.6693790668160933
Validation loss: 2.8622551429587273

Epoch: 41| Step: 0
Training loss: 3.194710747127586
Validation loss: 2.858684413141102

Epoch: 5| Step: 1
Training loss: 2.864945119495263
Validation loss: 2.8592509294293706

Epoch: 5| Step: 2
Training loss: 3.2782957310759238
Validation loss: 2.856869575455011

Epoch: 5| Step: 3
Training loss: 3.007506833088533
Validation loss: 2.856852431339745

Epoch: 5| Step: 4
Training loss: 3.5244804919359547
Validation loss: 2.8588056028220685

Epoch: 5| Step: 5
Training loss: 3.0034881022970024
Validation loss: 2.8572711831527933

Epoch: 5| Step: 6
Training loss: 3.3672876188258627
Validation loss: 2.856213836896948

Epoch: 5| Step: 7
Training loss: 2.748225506559825
Validation loss: 2.860066409689229

Epoch: 5| Step: 8
Training loss: 2.840957444212972
Validation loss: 2.863393381515705

Epoch: 5| Step: 9
Training loss: 3.6692990621650043
Validation loss: 2.864970474408862

Epoch: 5| Step: 10
Training loss: 3.260483924895124
Validation loss: 2.86649983274261

Epoch: 42| Step: 0
Training loss: 3.715440575824804
Validation loss: 2.8635051272509537

Epoch: 5| Step: 1
Training loss: 3.1800421439683078
Validation loss: 2.8509799327914624

Epoch: 5| Step: 2
Training loss: 2.987575712002749
Validation loss: 2.853529518052462

Epoch: 5| Step: 3
Training loss: 2.7169840547320505
Validation loss: 2.8512252160879337

Epoch: 5| Step: 4
Training loss: 3.154826532543343
Validation loss: 2.855118669029494

Epoch: 5| Step: 5
Training loss: 2.6701351993062943
Validation loss: 2.858284960185298

Epoch: 5| Step: 6
Training loss: 3.2525167257478524
Validation loss: 2.8552118813783425

Epoch: 5| Step: 7
Training loss: 3.098341799829279
Validation loss: 2.862782469401959

Epoch: 5| Step: 8
Training loss: 3.532374110263294
Validation loss: 2.860487225527781

Epoch: 5| Step: 9
Training loss: 3.2354603296311173
Validation loss: 2.856771323607946

Epoch: 5| Step: 10
Training loss: 3.1991005527520784
Validation loss: 2.852579253979475

Epoch: 43| Step: 0
Training loss: 3.361042265454045
Validation loss: 2.8498417999481354

Epoch: 5| Step: 1
Training loss: 2.892069192915994
Validation loss: 2.845590321619094

Epoch: 5| Step: 2
Training loss: 3.168284220574876
Validation loss: 2.847038080073573

Epoch: 5| Step: 3
Training loss: 3.1419852428320403
Validation loss: 2.844857853017292

Epoch: 5| Step: 4
Training loss: 3.170189771537508
Validation loss: 2.843787828491551

Epoch: 5| Step: 5
Training loss: 3.1221162842154175
Validation loss: 2.8453021054833934

Epoch: 5| Step: 6
Training loss: 3.669222778843123
Validation loss: 2.846723534222391

Epoch: 5| Step: 7
Training loss: 2.574678834311867
Validation loss: 2.8481700919817228

Epoch: 5| Step: 8
Training loss: 3.267490274054391
Validation loss: 2.8543470532425217

Epoch: 5| Step: 9
Training loss: 2.835599516597905
Validation loss: 2.8509796522367283

Epoch: 5| Step: 10
Training loss: 3.490403233709068
Validation loss: 2.839315209718636

Epoch: 44| Step: 0
Training loss: 3.2442498323637903
Validation loss: 2.839477598509954

Epoch: 5| Step: 1
Training loss: 3.1519268379434267
Validation loss: 2.8397638726331884

Epoch: 5| Step: 2
Training loss: 3.040533107141338
Validation loss: 2.842184417193827

Epoch: 5| Step: 3
Training loss: 3.1907327751466465
Validation loss: 2.8448524019621386

Epoch: 5| Step: 4
Training loss: 2.914116989321742
Validation loss: 2.8525718369187074

Epoch: 5| Step: 5
Training loss: 3.3683236101762986
Validation loss: 2.849124122926833

Epoch: 5| Step: 6
Training loss: 2.947803688355622
Validation loss: 2.8425159194896903

Epoch: 5| Step: 7
Training loss: 3.596300231985859
Validation loss: 2.843231610081979

Epoch: 5| Step: 8
Training loss: 3.087372342455155
Validation loss: 2.840368955304558

Epoch: 5| Step: 9
Training loss: 2.9429101025211417
Validation loss: 2.836499078482584

Epoch: 5| Step: 10
Training loss: 3.2542032790882036
Validation loss: 2.8368415292198326

Epoch: 45| Step: 0
Training loss: 3.028907578699009
Validation loss: 2.8337084050236103

Epoch: 5| Step: 1
Training loss: 2.597392179217438
Validation loss: 2.8346720276961905

Epoch: 5| Step: 2
Training loss: 3.537982026273919
Validation loss: 2.8317091407664465

Epoch: 5| Step: 3
Training loss: 2.987430306742985
Validation loss: 2.8341888484911806

Epoch: 5| Step: 4
Training loss: 3.281391395065493
Validation loss: 2.830313247129326

Epoch: 5| Step: 5
Training loss: 3.5368402843183837
Validation loss: 2.831504455611981

Epoch: 5| Step: 6
Training loss: 2.9505759242751424
Validation loss: 2.832069240452455

Epoch: 5| Step: 7
Training loss: 3.1093881884731296
Validation loss: 2.828902185880308

Epoch: 5| Step: 8
Training loss: 3.1487358463055566
Validation loss: 2.8327265354478723

Epoch: 5| Step: 9
Training loss: 3.5900526847267535
Validation loss: 2.8354479091041447

Epoch: 5| Step: 10
Training loss: 2.532437175638019
Validation loss: 2.836820823675305

Epoch: 46| Step: 0
Training loss: 2.9331980919728093
Validation loss: 2.8541839664355

Epoch: 5| Step: 1
Training loss: 2.728734678678885
Validation loss: 2.8357372587830065

Epoch: 5| Step: 2
Training loss: 3.147144440193587
Validation loss: 2.836989711513698

Epoch: 5| Step: 3
Training loss: 3.7031680076451674
Validation loss: 2.8268628446943533

Epoch: 5| Step: 4
Training loss: 3.112950708319481
Validation loss: 2.8217291677126792

Epoch: 5| Step: 5
Training loss: 2.9845878165693924
Validation loss: 2.82125602008277

Epoch: 5| Step: 6
Training loss: 3.4463867450381294
Validation loss: 2.822526053268415

Epoch: 5| Step: 7
Training loss: 2.5954554822142972
Validation loss: 2.82366834605089

Epoch: 5| Step: 8
Training loss: 3.5279195828776984
Validation loss: 2.829461359810335

Epoch: 5| Step: 9
Training loss: 3.2272754832804265
Validation loss: 2.8323498695385125

Epoch: 5| Step: 10
Training loss: 2.894655294501716
Validation loss: 2.8280419887211523

Epoch: 47| Step: 0
Training loss: 2.661496713937626
Validation loss: 2.8202755410645697

Epoch: 5| Step: 1
Training loss: 3.645641881366415
Validation loss: 2.8157503349247324

Epoch: 5| Step: 2
Training loss: 2.872273022587543
Validation loss: 2.8151329486576104

Epoch: 5| Step: 3
Training loss: 3.1235789310404725
Validation loss: 2.8231635948144733

Epoch: 5| Step: 4
Training loss: 3.40994957716011
Validation loss: 2.821475426008671

Epoch: 5| Step: 5
Training loss: 2.929685384113819
Validation loss: 2.8265192938158825

Epoch: 5| Step: 6
Training loss: 3.4153819731505832
Validation loss: 2.819996884969089

Epoch: 5| Step: 7
Training loss: 2.7909623201697693
Validation loss: 2.8132429347157615

Epoch: 5| Step: 8
Training loss: 3.157931644659027
Validation loss: 2.8139139173984757

Epoch: 5| Step: 9
Training loss: 3.3231093172453403
Validation loss: 2.812584875505596

Epoch: 5| Step: 10
Training loss: 2.921199128830618
Validation loss: 2.8089313759683514

Epoch: 48| Step: 0
Training loss: 3.193323238996613
Validation loss: 2.8110898273387592

Epoch: 5| Step: 1
Training loss: 3.0358075359992576
Validation loss: 2.808486462920481

Epoch: 5| Step: 2
Training loss: 3.048356542093961
Validation loss: 2.809324890089145

Epoch: 5| Step: 3
Training loss: 1.9759005919675636
Validation loss: 2.8059974271538417

Epoch: 5| Step: 4
Training loss: 3.644941791336515
Validation loss: 2.8112374702167493

Epoch: 5| Step: 5
Training loss: 3.419893710174572
Validation loss: 2.806256823674522

Epoch: 5| Step: 6
Training loss: 2.8595517630216785
Validation loss: 2.8091574108451822

Epoch: 5| Step: 7
Training loss: 2.9300009597932983
Validation loss: 2.8059983590552715

Epoch: 5| Step: 8
Training loss: 3.4264875703856457
Validation loss: 2.8097962567444643

Epoch: 5| Step: 9
Training loss: 3.302829517728875
Validation loss: 2.804949939624647

Epoch: 5| Step: 10
Training loss: 3.195805816996128
Validation loss: 2.8153341527098554

Epoch: 49| Step: 0
Training loss: 3.139250193444061
Validation loss: 2.8532732232927684

Epoch: 5| Step: 1
Training loss: 3.41586137601111
Validation loss: 2.8894828564274304

Epoch: 5| Step: 2
Training loss: 2.9400231097085134
Validation loss: 2.8771318928527445

Epoch: 5| Step: 3
Training loss: 3.0344267254397472
Validation loss: 2.9008486355762275

Epoch: 5| Step: 4
Training loss: 3.0445005897424924
Validation loss: 2.9118723114469427

Epoch: 5| Step: 5
Training loss: 3.836449862755732
Validation loss: 2.852222825913861

Epoch: 5| Step: 6
Training loss: 3.2663325223195363
Validation loss: 2.797678332700064

Epoch: 5| Step: 7
Training loss: 3.2823372628981424
Validation loss: 2.8000402083637566

Epoch: 5| Step: 8
Training loss: 2.629835942159153
Validation loss: 2.808376018742258

Epoch: 5| Step: 9
Training loss: 2.5561647955910898
Validation loss: 2.8384788365488465

Epoch: 5| Step: 10
Training loss: 3.4375588151928627
Validation loss: 2.8611050594526146

Epoch: 50| Step: 0
Training loss: 3.038357925134165
Validation loss: 2.811473898985179

Epoch: 5| Step: 1
Training loss: 3.152417868649253
Validation loss: 2.799771680876674

Epoch: 5| Step: 2
Training loss: 2.662040412888406
Validation loss: 2.7929972283382734

Epoch: 5| Step: 3
Training loss: 3.6048787172526446
Validation loss: 2.7941920288620548

Epoch: 5| Step: 4
Training loss: 2.6978284509638635
Validation loss: 2.842930280423814

Epoch: 5| Step: 5
Training loss: 3.191790666155156
Validation loss: 2.9107347513405624

Epoch: 5| Step: 6
Training loss: 3.5747816966168435
Validation loss: 2.863569389772515

Epoch: 5| Step: 7
Training loss: 3.098056146850487
Validation loss: 2.803074986774211

Epoch: 5| Step: 8
Training loss: 3.1025103218589316
Validation loss: 2.799321205545715

Epoch: 5| Step: 9
Training loss: 3.039113022254377
Validation loss: 2.80165749616267

Epoch: 5| Step: 10
Training loss: 3.0947820309994327
Validation loss: 2.8402987053656914

Epoch: 51| Step: 0
Training loss: 3.2232942076882165
Validation loss: 2.8079710323716482

Epoch: 5| Step: 1
Training loss: 3.6214300532376935
Validation loss: 2.833254607359763

Epoch: 5| Step: 2
Training loss: 2.8994449807841223
Validation loss: 2.8126998575132696

Epoch: 5| Step: 3
Training loss: 2.5304027128303352
Validation loss: 2.8048915372353305

Epoch: 5| Step: 4
Training loss: 2.617043015776267
Validation loss: 2.8057164712557583

Epoch: 5| Step: 5
Training loss: 2.8102133886421097
Validation loss: 2.7958171340485065

Epoch: 5| Step: 6
Training loss: 3.4389419305751114
Validation loss: 2.7937238041360613

Epoch: 5| Step: 7
Training loss: 3.111686728980989
Validation loss: 2.7913314705034673

Epoch: 5| Step: 8
Training loss: 3.4303047476311916
Validation loss: 2.7878741101173383

Epoch: 5| Step: 9
Training loss: 3.66077801319969
Validation loss: 2.788279379466027

Epoch: 5| Step: 10
Training loss: 2.72163676326261
Validation loss: 2.7882562822528785

Epoch: 52| Step: 0
Training loss: 3.1758600767142866
Validation loss: 2.7965344929648603

Epoch: 5| Step: 1
Training loss: 2.712578268723805
Validation loss: 2.833387850888984

Epoch: 5| Step: 2
Training loss: 3.134298452581687
Validation loss: 2.8984206079498773

Epoch: 5| Step: 3
Training loss: 3.034594706036908
Validation loss: 2.997121781261183

Epoch: 5| Step: 4
Training loss: 3.041297385038287
Validation loss: 3.0322499885464627

Epoch: 5| Step: 5
Training loss: 3.0832990352338236
Validation loss: 2.8242043841581594

Epoch: 5| Step: 6
Training loss: 3.0779240731435564
Validation loss: 2.7962474777839095

Epoch: 5| Step: 7
Training loss: 2.6471496871861304
Validation loss: 2.7874901326469903

Epoch: 5| Step: 8
Training loss: 3.1557112130053495
Validation loss: 2.7915859593378762

Epoch: 5| Step: 9
Training loss: 3.697368283869285
Validation loss: 2.8132422084287336

Epoch: 5| Step: 10
Training loss: 3.5204044660195106
Validation loss: 2.8276788439737284

Epoch: 53| Step: 0
Training loss: 3.5887975652260415
Validation loss: 2.8557435929410735

Epoch: 5| Step: 1
Training loss: 3.0912215564497427
Validation loss: 2.8534553389340602

Epoch: 5| Step: 2
Training loss: 3.544722656032615
Validation loss: 2.8408272323225474

Epoch: 5| Step: 3
Training loss: 2.8501735701326703
Validation loss: 2.8283775106724685

Epoch: 5| Step: 4
Training loss: 3.207285045101958
Validation loss: 2.8117899519119076

Epoch: 5| Step: 5
Training loss: 2.9965474607062603
Validation loss: 2.799775632865063

Epoch: 5| Step: 6
Training loss: 2.9953246242255926
Validation loss: 2.793582239459564

Epoch: 5| Step: 7
Training loss: 2.949130470015663
Validation loss: 2.791488183208019

Epoch: 5| Step: 8
Training loss: 3.223044336244228
Validation loss: 2.8029573572305977

Epoch: 5| Step: 9
Training loss: 2.9018115535046762
Validation loss: 2.802968676543879

Epoch: 5| Step: 10
Training loss: 2.9109429646562033
Validation loss: 2.803825674470533

Epoch: 54| Step: 0
Training loss: 3.169202458509469
Validation loss: 2.8247319373366153

Epoch: 5| Step: 1
Training loss: 2.65345365647638
Validation loss: 2.8514410294504997

Epoch: 5| Step: 2
Training loss: 2.818031635645617
Validation loss: 2.8460125807085856

Epoch: 5| Step: 3
Training loss: 3.3841259809270037
Validation loss: 2.82435011608895

Epoch: 5| Step: 4
Training loss: 3.7858991809122737
Validation loss: 2.8332200106108827

Epoch: 5| Step: 5
Training loss: 3.5275192132611775
Validation loss: 2.784634781328308

Epoch: 5| Step: 6
Training loss: 3.143018730765593
Validation loss: 2.783262910026277

Epoch: 5| Step: 7
Training loss: 3.119302820659626
Validation loss: 2.7811485835231315

Epoch: 5| Step: 8
Training loss: 3.271289785490845
Validation loss: 2.8090740653847224

Epoch: 5| Step: 9
Training loss: 2.35738708419854
Validation loss: 2.799551044675562

Epoch: 5| Step: 10
Training loss: 2.835816940393259
Validation loss: 2.7941323354682885

Epoch: 55| Step: 0
Training loss: 3.2351400603879807
Validation loss: 2.787376769660347

Epoch: 5| Step: 1
Training loss: 3.084187380757139
Validation loss: 2.7953253916142313

Epoch: 5| Step: 2
Training loss: 3.055934797699874
Validation loss: 2.7775954833425804

Epoch: 5| Step: 3
Training loss: 3.1893708965402947
Validation loss: 2.7751455590879948

Epoch: 5| Step: 4
Training loss: 3.0804078597480338
Validation loss: 2.7679143872973118

Epoch: 5| Step: 5
Training loss: 3.288522417755068
Validation loss: 2.767544345903004

Epoch: 5| Step: 6
Training loss: 2.9536019399295608
Validation loss: 2.7651071964619462

Epoch: 5| Step: 7
Training loss: 2.356719284477393
Validation loss: 2.7649747662198623

Epoch: 5| Step: 8
Training loss: 3.6317721282039064
Validation loss: 2.765469489647922

Epoch: 5| Step: 9
Training loss: 3.236922730342359
Validation loss: 2.765535557448091

Epoch: 5| Step: 10
Training loss: 2.7234680629291255
Validation loss: 2.770300593216187

Epoch: 56| Step: 0
Training loss: 2.680969376539597
Validation loss: 2.7821423033746107

Epoch: 5| Step: 1
Training loss: 2.566628642440468
Validation loss: 2.806255980472773

Epoch: 5| Step: 2
Training loss: 2.835951287522442
Validation loss: 2.8271215654452333

Epoch: 5| Step: 3
Training loss: 3.3924862020685635
Validation loss: 2.8342043133902064

Epoch: 5| Step: 4
Training loss: 3.3861465058646956
Validation loss: 2.781274728825245

Epoch: 5| Step: 5
Training loss: 2.923192344348155
Validation loss: 2.7641427677613026

Epoch: 5| Step: 6
Training loss: 3.250497633175765
Validation loss: 2.755630211188761

Epoch: 5| Step: 7
Training loss: 3.5174170779693763
Validation loss: 2.755794558076772

Epoch: 5| Step: 8
Training loss: 3.1310488333584003
Validation loss: 2.754488905842582

Epoch: 5| Step: 9
Training loss: 3.0618199741755316
Validation loss: 2.7533367558686743

Epoch: 5| Step: 10
Training loss: 3.1728416435671365
Validation loss: 2.7529178150845555

Epoch: 57| Step: 0
Training loss: 3.1705984168101
Validation loss: 2.7502769151804265

Epoch: 5| Step: 1
Training loss: 2.6386950059126795
Validation loss: 2.7501392236036453

Epoch: 5| Step: 2
Training loss: 2.948781042901804
Validation loss: 2.7514898584359955

Epoch: 5| Step: 3
Training loss: 3.4728504036522305
Validation loss: 2.747656720656681

Epoch: 5| Step: 4
Training loss: 3.042823954554092
Validation loss: 2.754369697448887

Epoch: 5| Step: 5
Training loss: 3.697949361880477
Validation loss: 2.7511332871823995

Epoch: 5| Step: 6
Training loss: 2.6215473356773518
Validation loss: 2.7492083195812103

Epoch: 5| Step: 7
Training loss: 3.0283614090951363
Validation loss: 2.749243560448644

Epoch: 5| Step: 8
Training loss: 2.812763795137503
Validation loss: 2.762270043380609

Epoch: 5| Step: 9
Training loss: 2.7978035008960984
Validation loss: 2.759283421441605

Epoch: 5| Step: 10
Training loss: 3.439244053306355
Validation loss: 2.7492401605899803

Epoch: 58| Step: 0
Training loss: 2.994366442581144
Validation loss: 2.7473209173574196

Epoch: 5| Step: 1
Training loss: 3.027704584090553
Validation loss: 2.744439177244923

Epoch: 5| Step: 2
Training loss: 3.520793997339819
Validation loss: 2.743585820466657

Epoch: 5| Step: 3
Training loss: 3.561348444554432
Validation loss: 2.7481067942264

Epoch: 5| Step: 4
Training loss: 3.0515876515060514
Validation loss: 2.744439259447646

Epoch: 5| Step: 5
Training loss: 2.7350150966750673
Validation loss: 2.749787118228669

Epoch: 5| Step: 6
Training loss: 2.9456039001240106
Validation loss: 2.746899888734824

Epoch: 5| Step: 7
Training loss: 3.0594482787165402
Validation loss: 2.746111755494109

Epoch: 5| Step: 8
Training loss: 2.6626011036763626
Validation loss: 2.7430540957554506

Epoch: 5| Step: 9
Training loss: 3.25443141770403
Validation loss: 2.7434241249785947

Epoch: 5| Step: 10
Training loss: 2.8208549168116464
Validation loss: 2.7452731372882515

Epoch: 59| Step: 0
Training loss: 2.8055147528959887
Validation loss: 2.746344645599416

Epoch: 5| Step: 1
Training loss: 3.4995480654353757
Validation loss: 2.743053442474489

Epoch: 5| Step: 2
Training loss: 3.10886628096441
Validation loss: 2.743486923278079

Epoch: 5| Step: 3
Training loss: 2.8422240470394544
Validation loss: 2.743011149911547

Epoch: 5| Step: 4
Training loss: 2.8726871973299866
Validation loss: 2.7461025814542848

Epoch: 5| Step: 5
Training loss: 2.9934522381156983
Validation loss: 2.7475249664809436

Epoch: 5| Step: 6
Training loss: 3.1727918981482346
Validation loss: 2.7487312962649106

Epoch: 5| Step: 7
Training loss: 3.2184486618463297
Validation loss: 2.757526139168443

Epoch: 5| Step: 8
Training loss: 3.393971843739814
Validation loss: 2.7611180233887604

Epoch: 5| Step: 9
Training loss: 2.8825599125560424
Validation loss: 2.741706818402159

Epoch: 5| Step: 10
Training loss: 2.8759019514939888
Validation loss: 2.7381241838653443

Epoch: 60| Step: 0
Training loss: 3.3459761864999877
Validation loss: 2.7396483609926428

Epoch: 5| Step: 1
Training loss: 3.20938198902294
Validation loss: 2.739961592807248

Epoch: 5| Step: 2
Training loss: 2.9573916337836845
Validation loss: 2.740386871874572

Epoch: 5| Step: 3
Training loss: 2.7271980484939538
Validation loss: 2.745525961843552

Epoch: 5| Step: 4
Training loss: 2.793045661774276
Validation loss: 2.750070789130817

Epoch: 5| Step: 5
Training loss: 3.2564837996005056
Validation loss: 2.75024499575616

Epoch: 5| Step: 6
Training loss: 3.057213092857873
Validation loss: 2.7504757668177326

Epoch: 5| Step: 7
Training loss: 3.0013370713230865
Validation loss: 2.7439007638463235

Epoch: 5| Step: 8
Training loss: 2.834593062755375
Validation loss: 2.7381989707180927

Epoch: 5| Step: 9
Training loss: 3.270234427725369
Validation loss: 2.7353410055740683

Epoch: 5| Step: 10
Training loss: 3.3607776641081686
Validation loss: 2.733506604662039

Epoch: 61| Step: 0
Training loss: 3.4372052152988535
Validation loss: 2.730444766600082

Epoch: 5| Step: 1
Training loss: 3.210016197330098
Validation loss: 2.7283359754751557

Epoch: 5| Step: 2
Training loss: 3.0905174552944192
Validation loss: 2.7339652668307526

Epoch: 5| Step: 3
Training loss: 2.9239054270217073
Validation loss: 2.750483242022643

Epoch: 5| Step: 4
Training loss: 3.155065030789499
Validation loss: 2.756704538339659

Epoch: 5| Step: 5
Training loss: 3.0149285495572773
Validation loss: 2.767297799549788

Epoch: 5| Step: 6
Training loss: 3.1572792716660323
Validation loss: 2.7483227388844433

Epoch: 5| Step: 7
Training loss: 2.308878976206856
Validation loss: 2.7356255306578396

Epoch: 5| Step: 8
Training loss: 2.853659666004319
Validation loss: 2.7220081405332874

Epoch: 5| Step: 9
Training loss: 3.2318820652453866
Validation loss: 2.7218956209029397

Epoch: 5| Step: 10
Training loss: 3.2878528826209346
Validation loss: 2.724522243433684

Epoch: 62| Step: 0
Training loss: 3.07209582383989
Validation loss: 2.7217971591140095

Epoch: 5| Step: 1
Training loss: 2.7622258909086357
Validation loss: 2.7251946587384506

Epoch: 5| Step: 2
Training loss: 2.912395256025414
Validation loss: 2.720709677547151

Epoch: 5| Step: 3
Training loss: 3.291712764626447
Validation loss: 2.722585969352901

Epoch: 5| Step: 4
Training loss: 3.0899082567737057
Validation loss: 2.7190378159560136

Epoch: 5| Step: 5
Training loss: 2.990970214562802
Validation loss: 2.719628372845671

Epoch: 5| Step: 6
Training loss: 3.146495437839413
Validation loss: 2.7193628567366592

Epoch: 5| Step: 7
Training loss: 2.697526105696081
Validation loss: 2.718039640835915

Epoch: 5| Step: 8
Training loss: 3.341478521008307
Validation loss: 2.7191282732189284

Epoch: 5| Step: 9
Training loss: 2.9048468371146052
Validation loss: 2.7199716050035474

Epoch: 5| Step: 10
Training loss: 3.3388954645629156
Validation loss: 2.72747500971624

Epoch: 63| Step: 0
Training loss: 2.8276280762176893
Validation loss: 2.7284134576366643

Epoch: 5| Step: 1
Training loss: 3.3201874114764456
Validation loss: 2.724713922897719

Epoch: 5| Step: 2
Training loss: 2.595180071277513
Validation loss: 2.718239935945653

Epoch: 5| Step: 3
Training loss: 2.5585084857274376
Validation loss: 2.7156549501999536

Epoch: 5| Step: 4
Training loss: 3.2198995370771475
Validation loss: 2.712045712850966

Epoch: 5| Step: 5
Training loss: 3.387637461445724
Validation loss: 2.717303848419747

Epoch: 5| Step: 6
Training loss: 2.410523521101271
Validation loss: 2.709537264701185

Epoch: 5| Step: 7
Training loss: 3.163622865628154
Validation loss: 2.71158385827465

Epoch: 5| Step: 8
Training loss: 3.4877418024058238
Validation loss: 2.711944213478845

Epoch: 5| Step: 9
Training loss: 2.8082332883799617
Validation loss: 2.711063939176491

Epoch: 5| Step: 10
Training loss: 3.63800268730748
Validation loss: 2.711197670413742

Epoch: 64| Step: 0
Training loss: 3.5157720238354453
Validation loss: 2.7119080833116773

Epoch: 5| Step: 1
Training loss: 2.8923519440182943
Validation loss: 2.7106228039041276

Epoch: 5| Step: 2
Training loss: 2.6484690076366046
Validation loss: 2.712149200998008

Epoch: 5| Step: 3
Training loss: 2.554396119838961
Validation loss: 2.7163626528915508

Epoch: 5| Step: 4
Training loss: 3.5583272220699054
Validation loss: 2.7241273421038334

Epoch: 5| Step: 5
Training loss: 3.359258037571434
Validation loss: 2.709606118321317

Epoch: 5| Step: 6
Training loss: 3.3516077425377313
Validation loss: 2.706171032710404

Epoch: 5| Step: 7
Training loss: 2.441969271017402
Validation loss: 2.7077282465501216

Epoch: 5| Step: 8
Training loss: 2.9645064693592014
Validation loss: 2.709868057937134

Epoch: 5| Step: 9
Training loss: 2.9042083788320396
Validation loss: 2.7085331984259957

Epoch: 5| Step: 10
Training loss: 3.124346550332909
Validation loss: 2.7066213949224633

Epoch: 65| Step: 0
Training loss: 3.236349931089783
Validation loss: 2.7090500639700785

Epoch: 5| Step: 1
Training loss: 2.902593465872374
Validation loss: 2.7088241261816544

Epoch: 5| Step: 2
Training loss: 3.250620269273199
Validation loss: 2.703903520498956

Epoch: 5| Step: 3
Training loss: 3.176710530071967
Validation loss: 2.7040708547807273

Epoch: 5| Step: 4
Training loss: 2.68960648420098
Validation loss: 2.7039583491088153

Epoch: 5| Step: 5
Training loss: 2.8351301404897065
Validation loss: 2.7011497802200877

Epoch: 5| Step: 6
Training loss: 2.79643152226691
Validation loss: 2.7009582171660522

Epoch: 5| Step: 7
Training loss: 3.2861246865612754
Validation loss: 2.707935925679373

Epoch: 5| Step: 8
Training loss: 3.2043408575112173
Validation loss: 2.700440175930181

Epoch: 5| Step: 9
Training loss: 2.960793202288662
Validation loss: 2.7003101746867864

Epoch: 5| Step: 10
Training loss: 3.035996172343418
Validation loss: 2.7021694444548796

Epoch: 66| Step: 0
Training loss: 3.245923640341939
Validation loss: 2.699504175391404

Epoch: 5| Step: 1
Training loss: 3.625665669324094
Validation loss: 2.7012585497098147

Epoch: 5| Step: 2
Training loss: 2.8346060157177506
Validation loss: 2.6967396485835833

Epoch: 5| Step: 3
Training loss: 3.2261668556138305
Validation loss: 2.6981441167377542

Epoch: 5| Step: 4
Training loss: 3.1504593408307207
Validation loss: 2.7005476658599417

Epoch: 5| Step: 5
Training loss: 2.5302649571090035
Validation loss: 2.699852809365313

Epoch: 5| Step: 6
Training loss: 2.563838981077465
Validation loss: 2.699216040300979

Epoch: 5| Step: 7
Training loss: 3.107720476401995
Validation loss: 2.7028516784986345

Epoch: 5| Step: 8
Training loss: 3.3738373060544293
Validation loss: 2.6998668417535696

Epoch: 5| Step: 9
Training loss: 2.6478283386945325
Validation loss: 2.7083143500206264

Epoch: 5| Step: 10
Training loss: 2.8363959832447745
Validation loss: 2.724573510640696

Epoch: 67| Step: 0
Training loss: 2.832820135275666
Validation loss: 2.75616739083376

Epoch: 5| Step: 1
Training loss: 3.2984771451460415
Validation loss: 2.753461927742903

Epoch: 5| Step: 2
Training loss: 3.518685056043039
Validation loss: 2.6951368391480544

Epoch: 5| Step: 3
Training loss: 3.400442509745601
Validation loss: 2.691648710874115

Epoch: 5| Step: 4
Training loss: 3.0508884699268535
Validation loss: 2.695218580124623

Epoch: 5| Step: 5
Training loss: 2.471309928109525
Validation loss: 2.697434177950662

Epoch: 5| Step: 6
Training loss: 2.6881587973135024
Validation loss: 2.701991670480263

Epoch: 5| Step: 7
Training loss: 2.8287781019243554
Validation loss: 2.7171003433261385

Epoch: 5| Step: 8
Training loss: 3.0652039716099226
Validation loss: 2.712268585424479

Epoch: 5| Step: 9
Training loss: 3.012506483395513
Validation loss: 2.707930056993423

Epoch: 5| Step: 10
Training loss: 3.465235949212668
Validation loss: 2.7074752344322857

Epoch: 68| Step: 0
Training loss: 2.755891471259542
Validation loss: 2.702054358645077

Epoch: 5| Step: 1
Training loss: 3.142291485674877
Validation loss: 2.6992308339138344

Epoch: 5| Step: 2
Training loss: 3.1281853272740188
Validation loss: 2.6982051940400784

Epoch: 5| Step: 3
Training loss: 3.845593514340675
Validation loss: 2.6951584952550864

Epoch: 5| Step: 4
Training loss: 3.239208792636702
Validation loss: 2.6944401691165902

Epoch: 5| Step: 5
Training loss: 2.889940335406929
Validation loss: 2.6890932431958174

Epoch: 5| Step: 6
Training loss: 3.2951390907672535
Validation loss: 2.690870167021719

Epoch: 5| Step: 7
Training loss: 3.039318240665494
Validation loss: 2.6875533460896732

Epoch: 5| Step: 8
Training loss: 2.565780679530673
Validation loss: 2.688336699293412

Epoch: 5| Step: 9
Training loss: 2.5314163341736946
Validation loss: 2.686892930968904

Epoch: 5| Step: 10
Training loss: 2.621175705016473
Validation loss: 2.6879189573226543

Epoch: 69| Step: 0
Training loss: 2.832114088228127
Validation loss: 2.700276853829291

Epoch: 5| Step: 1
Training loss: 3.192405366861669
Validation loss: 2.7352939675257075

Epoch: 5| Step: 2
Training loss: 3.1446756080994716
Validation loss: 2.7571956364452714

Epoch: 5| Step: 3
Training loss: 3.310740021329154
Validation loss: 2.696335187476911

Epoch: 5| Step: 4
Training loss: 2.9718279492878548
Validation loss: 2.6915860070440045

Epoch: 5| Step: 5
Training loss: 2.9207911801708906
Validation loss: 2.686326856658384

Epoch: 5| Step: 6
Training loss: 2.2607510461489504
Validation loss: 2.6840203240491625

Epoch: 5| Step: 7
Training loss: 3.1346881987614954
Validation loss: 2.684994764506411

Epoch: 5| Step: 8
Training loss: 3.3991179387954196
Validation loss: 2.6836246777018227

Epoch: 5| Step: 9
Training loss: 2.8520692975906594
Validation loss: 2.68505690331122

Epoch: 5| Step: 10
Training loss: 3.207326227299043
Validation loss: 2.683981367994632

Epoch: 70| Step: 0
Training loss: 2.4294585583142103
Validation loss: 2.683847828060347

Epoch: 5| Step: 1
Training loss: 2.6344400237216306
Validation loss: 2.6838489160453145

Epoch: 5| Step: 2
Training loss: 2.531994368753303
Validation loss: 2.6828767043892086

Epoch: 5| Step: 3
Training loss: 3.161952994463513
Validation loss: 2.6828658989330214

Epoch: 5| Step: 4
Training loss: 3.4145473947703247
Validation loss: 2.6860252344232562

Epoch: 5| Step: 5
Training loss: 3.4107447375334052
Validation loss: 2.6854285718230293

Epoch: 5| Step: 6
Training loss: 3.119015724007958
Validation loss: 2.685587151457508

Epoch: 5| Step: 7
Training loss: 2.9289111927201392
Validation loss: 2.694308047205328

Epoch: 5| Step: 8
Training loss: 3.2909976585192076
Validation loss: 2.7052846154881625

Epoch: 5| Step: 9
Training loss: 3.118043098528663
Validation loss: 2.6960016098207533

Epoch: 5| Step: 10
Training loss: 3.065096785742538
Validation loss: 2.6822127377901808

Epoch: 71| Step: 0
Training loss: 2.6378503250394614
Validation loss: 2.676269042233984

Epoch: 5| Step: 1
Training loss: 2.9733613189383803
Validation loss: 2.6761712707629686

Epoch: 5| Step: 2
Training loss: 3.1683013779020173
Validation loss: 2.6760900807990677

Epoch: 5| Step: 3
Training loss: 3.110096756635125
Validation loss: 2.676553917004791

Epoch: 5| Step: 4
Training loss: 3.137422513574881
Validation loss: 2.676939882444545

Epoch: 5| Step: 5
Training loss: 2.571188270224715
Validation loss: 2.678049064560311

Epoch: 5| Step: 6
Training loss: 3.1707042920142303
Validation loss: 2.677232972665625

Epoch: 5| Step: 7
Training loss: 2.7420702091357607
Validation loss: 2.680607734122884

Epoch: 5| Step: 8
Training loss: 3.1520448375165673
Validation loss: 2.6920335244269897

Epoch: 5| Step: 9
Training loss: 3.38845558905406
Validation loss: 2.6999237729246284

Epoch: 5| Step: 10
Training loss: 3.100797544452415
Validation loss: 2.6991946219007907

Epoch: 72| Step: 0
Training loss: 3.6217439431941454
Validation loss: 2.693884163301031

Epoch: 5| Step: 1
Training loss: 2.775580811074711
Validation loss: 2.682820992947841

Epoch: 5| Step: 2
Training loss: 2.7236097901781107
Validation loss: 2.6787267640676804

Epoch: 5| Step: 3
Training loss: 3.1402663600226095
Validation loss: 2.6784073205220995

Epoch: 5| Step: 4
Training loss: 3.654723019731064
Validation loss: 2.670202398928812

Epoch: 5| Step: 5
Training loss: 3.124793389166008
Validation loss: 2.6686761495668936

Epoch: 5| Step: 6
Training loss: 2.554186757326584
Validation loss: 2.6671165873792555

Epoch: 5| Step: 7
Training loss: 2.974812150682484
Validation loss: 2.665709495525245

Epoch: 5| Step: 8
Training loss: 2.990390327517979
Validation loss: 2.665191945052439

Epoch: 5| Step: 9
Training loss: 2.212389789142402
Validation loss: 2.662808960651308

Epoch: 5| Step: 10
Training loss: 3.136819080159133
Validation loss: 2.66520815874211

Epoch: 73| Step: 0
Training loss: 2.9342032255325443
Validation loss: 2.6632860627009953

Epoch: 5| Step: 1
Training loss: 2.802112725728865
Validation loss: 2.662755037955139

Epoch: 5| Step: 2
Training loss: 2.489164138893127
Validation loss: 2.666489513214376

Epoch: 5| Step: 3
Training loss: 2.9831108891193145
Validation loss: 2.669864069787771

Epoch: 5| Step: 4
Training loss: 3.2192225433432426
Validation loss: 2.674344525644196

Epoch: 5| Step: 5
Training loss: 3.041537573875006
Validation loss: 2.6768829700377497

Epoch: 5| Step: 6
Training loss: 2.610054704231701
Validation loss: 2.67993457776477

Epoch: 5| Step: 7
Training loss: 3.071790965299734
Validation loss: 2.6730566515175087

Epoch: 5| Step: 8
Training loss: 3.645854027099009
Validation loss: 2.671451690748201

Epoch: 5| Step: 9
Training loss: 2.913966118494497
Validation loss: 2.6623814540787207

Epoch: 5| Step: 10
Training loss: 3.2995957271437737
Validation loss: 2.660331652469812

Epoch: 74| Step: 0
Training loss: 3.062866811777726
Validation loss: 2.660229428924764

Epoch: 5| Step: 1
Training loss: 2.3182234173882477
Validation loss: 2.6613450804179726

Epoch: 5| Step: 2
Training loss: 3.266298653509948
Validation loss: 2.65814850802097

Epoch: 5| Step: 3
Training loss: 3.2326106912375816
Validation loss: 2.660100332562694

Epoch: 5| Step: 4
Training loss: 2.7728773814073633
Validation loss: 2.6581756946495947

Epoch: 5| Step: 5
Training loss: 3.263018868646946
Validation loss: 2.6594673895791834

Epoch: 5| Step: 6
Training loss: 2.8915466488896695
Validation loss: 2.6581925018246073

Epoch: 5| Step: 7
Training loss: 2.8117615472070265
Validation loss: 2.657151080852959

Epoch: 5| Step: 8
Training loss: 3.562497590716702
Validation loss: 2.656616161571603

Epoch: 5| Step: 9
Training loss: 2.671808074648392
Validation loss: 2.6563420308123273

Epoch: 5| Step: 10
Training loss: 3.0415585816570845
Validation loss: 2.659340512981245

Epoch: 75| Step: 0
Training loss: 2.5782650996202228
Validation loss: 2.652953098356282

Epoch: 5| Step: 1
Training loss: 2.721091917017085
Validation loss: 2.6532971844467994

Epoch: 5| Step: 2
Training loss: 2.9105792871005978
Validation loss: 2.654563471665775

Epoch: 5| Step: 3
Training loss: 2.8178715591020453
Validation loss: 2.657672141863654

Epoch: 5| Step: 4
Training loss: 3.178179108975841
Validation loss: 2.6548434061432937

Epoch: 5| Step: 5
Training loss: 2.7218829990273807
Validation loss: 2.6535697555050115

Epoch: 5| Step: 6
Training loss: 2.692591789473252
Validation loss: 2.6519633845961157

Epoch: 5| Step: 7
Training loss: 3.4423904310642643
Validation loss: 2.6547765738632396

Epoch: 5| Step: 8
Training loss: 3.5159857670796453
Validation loss: 2.65810548180881

Epoch: 5| Step: 9
Training loss: 3.2973497961856824
Validation loss: 2.675289248282072

Epoch: 5| Step: 10
Training loss: 2.9309710729831613
Validation loss: 2.6636658275977427

Epoch: 76| Step: 0
Training loss: 3.0447234553395206
Validation loss: 2.650720249770814

Epoch: 5| Step: 1
Training loss: 2.2925921103173916
Validation loss: 2.649932184974964

Epoch: 5| Step: 2
Training loss: 2.985566864885077
Validation loss: 2.6520563713236767

Epoch: 5| Step: 3
Training loss: 3.0946351913874173
Validation loss: 2.6530699792783397

Epoch: 5| Step: 4
Training loss: 3.251627147935614
Validation loss: 2.6534139618078543

Epoch: 5| Step: 5
Training loss: 2.733156292306803
Validation loss: 2.6514651851929565

Epoch: 5| Step: 6
Training loss: 3.283935610401294
Validation loss: 2.6532467951827905

Epoch: 5| Step: 7
Training loss: 3.0479724961489194
Validation loss: 2.655300697012011

Epoch: 5| Step: 8
Training loss: 3.0845910333886595
Validation loss: 2.6538675915113132

Epoch: 5| Step: 9
Training loss: 3.0174987980066668
Validation loss: 2.6536757240776385

Epoch: 5| Step: 10
Training loss: 3.0958285044602065
Validation loss: 2.652408527839338

Epoch: 77| Step: 0
Training loss: 2.732747580017241
Validation loss: 2.649736659849163

Epoch: 5| Step: 1
Training loss: 3.3130841010116203
Validation loss: 2.6485707490920487

Epoch: 5| Step: 2
Training loss: 3.2629913953877523
Validation loss: 2.652778535362559

Epoch: 5| Step: 3
Training loss: 2.8328578400389453
Validation loss: 2.649603634843131

Epoch: 5| Step: 4
Training loss: 2.6596652346604497
Validation loss: 2.649785264087981

Epoch: 5| Step: 5
Training loss: 2.6548269611299493
Validation loss: 2.6487627036967587

Epoch: 5| Step: 6
Training loss: 3.672860520586988
Validation loss: 2.6548466178821015

Epoch: 5| Step: 7
Training loss: 3.6500543773206258
Validation loss: 2.6673801641103263

Epoch: 5| Step: 8
Training loss: 2.538614744173668
Validation loss: 2.679612346814981

Epoch: 5| Step: 9
Training loss: 2.912875427149152
Validation loss: 2.6976529482390994

Epoch: 5| Step: 10
Training loss: 2.3528350732525833
Validation loss: 2.6861914176819153

Epoch: 78| Step: 0
Training loss: 2.829049649484874
Validation loss: 2.6807485743635495

Epoch: 5| Step: 1
Training loss: 3.1780155669419847
Validation loss: 2.698579903778687

Epoch: 5| Step: 2
Training loss: 2.746045390282532
Validation loss: 2.691041678437447

Epoch: 5| Step: 3
Training loss: 3.367686365262203
Validation loss: 2.6422065221535314

Epoch: 5| Step: 4
Training loss: 3.32190793470562
Validation loss: 2.645695468048632

Epoch: 5| Step: 5
Training loss: 2.885751936584632
Validation loss: 2.651095900458411

Epoch: 5| Step: 6
Training loss: 3.0260292004817084
Validation loss: 2.664161221039718

Epoch: 5| Step: 7
Training loss: 3.115720322355046
Validation loss: 2.6570929997410357

Epoch: 5| Step: 8
Training loss: 2.9583168208418087
Validation loss: 2.6567805735714023

Epoch: 5| Step: 9
Training loss: 2.734695415797049
Validation loss: 2.654534718280582

Epoch: 5| Step: 10
Training loss: 2.9844224536578214
Validation loss: 2.6505935502635154

Epoch: 79| Step: 0
Training loss: 3.26765138095932
Validation loss: 2.6533453601754835

Epoch: 5| Step: 1
Training loss: 3.170067483562739
Validation loss: 2.648926724374708

Epoch: 5| Step: 2
Training loss: 2.869988593367927
Validation loss: 2.6449596760636482

Epoch: 5| Step: 3
Training loss: 2.903172165535778
Validation loss: 2.6418810781248667

Epoch: 5| Step: 4
Training loss: 2.824944409523953
Validation loss: 2.642127331814734

Epoch: 5| Step: 5
Training loss: 2.9646015294459986
Validation loss: 2.6464277056373158

Epoch: 5| Step: 6
Training loss: 3.197452043378
Validation loss: 2.6459369752167086

Epoch: 5| Step: 7
Training loss: 3.261057017923101
Validation loss: 2.64724673991479

Epoch: 5| Step: 8
Training loss: 2.7536846098752963
Validation loss: 2.648053022432325

Epoch: 5| Step: 9
Training loss: 2.5754982253349765
Validation loss: 2.646452694554062

Epoch: 5| Step: 10
Training loss: 3.0965055274168725
Validation loss: 2.6470544526257567

Epoch: 80| Step: 0
Training loss: 2.967183392417921
Validation loss: 2.642028505509544

Epoch: 5| Step: 1
Training loss: 2.751102139955286
Validation loss: 2.645382838371653

Epoch: 5| Step: 2
Training loss: 3.3413209737938305
Validation loss: 2.646272126498631

Epoch: 5| Step: 3
Training loss: 3.43822152628273
Validation loss: 2.643595498995304

Epoch: 5| Step: 4
Training loss: 2.9694537483103676
Validation loss: 2.6531372478183126

Epoch: 5| Step: 5
Training loss: 2.81504875831996
Validation loss: 2.6558354179075314

Epoch: 5| Step: 6
Training loss: 3.024772881422983
Validation loss: 2.6496654203316568

Epoch: 5| Step: 7
Training loss: 2.5724849158494494
Validation loss: 2.6479926118456114

Epoch: 5| Step: 8
Training loss: 3.2454050299760353
Validation loss: 2.6529503462336295

Epoch: 5| Step: 9
Training loss: 2.622414905487581
Validation loss: 2.6494630529266687

Epoch: 5| Step: 10
Training loss: 3.0140685180793825
Validation loss: 2.6406129789555117

Epoch: 81| Step: 0
Training loss: 2.5065081760677215
Validation loss: 2.638704984748096

Epoch: 5| Step: 1
Training loss: 3.2034444510101947
Validation loss: 2.638538384453231

Epoch: 5| Step: 2
Training loss: 2.6230102445611054
Validation loss: 2.6379288264575025

Epoch: 5| Step: 3
Training loss: 2.3828552242263488
Validation loss: 2.636795899642294

Epoch: 5| Step: 4
Training loss: 2.9102180218381144
Validation loss: 2.6371898361247483

Epoch: 5| Step: 5
Training loss: 3.4133420135963854
Validation loss: 2.6414606944606462

Epoch: 5| Step: 6
Training loss: 3.0455270768926725
Validation loss: 2.636215628413201

Epoch: 5| Step: 7
Training loss: 2.864756039123801
Validation loss: 2.636312015933438

Epoch: 5| Step: 8
Training loss: 3.0886606297518036
Validation loss: 2.6355025402979333

Epoch: 5| Step: 9
Training loss: 3.311726317832383
Validation loss: 2.638524969345668

Epoch: 5| Step: 10
Training loss: 3.276913929558327
Validation loss: 2.639472008270629

Epoch: 82| Step: 0
Training loss: 3.2218308010085117
Validation loss: 2.643649831884564

Epoch: 5| Step: 1
Training loss: 3.1947746290497427
Validation loss: 2.6463804473044426

Epoch: 5| Step: 2
Training loss: 2.9209978551598823
Validation loss: 2.6439187801155093

Epoch: 5| Step: 3
Training loss: 2.321119277387446
Validation loss: 2.6629090422786557

Epoch: 5| Step: 4
Training loss: 2.86126796411797
Validation loss: 2.672232148660122

Epoch: 5| Step: 5
Training loss: 3.363816842244676
Validation loss: 2.7305051753715377

Epoch: 5| Step: 6
Training loss: 2.9392733800940816
Validation loss: 2.7315062960582916

Epoch: 5| Step: 7
Training loss: 3.4398677647480342
Validation loss: 2.709970111855414

Epoch: 5| Step: 8
Training loss: 2.30608457473407
Validation loss: 2.634584375142449

Epoch: 5| Step: 9
Training loss: 3.297959425057217
Validation loss: 2.627913486719793

Epoch: 5| Step: 10
Training loss: 2.7771007147147526
Validation loss: 2.6314742784673992

Epoch: 83| Step: 0
Training loss: 3.2168530550175407
Validation loss: 2.6352189032909794

Epoch: 5| Step: 1
Training loss: 3.0630123721877607
Validation loss: 2.636666844083816

Epoch: 5| Step: 2
Training loss: 3.110672876358647
Validation loss: 2.6403391013965782

Epoch: 5| Step: 3
Training loss: 3.0411928060337905
Validation loss: 2.6427106140828696

Epoch: 5| Step: 4
Training loss: 3.2041360887540886
Validation loss: 2.6381756055115013

Epoch: 5| Step: 5
Training loss: 2.9246814326074504
Validation loss: 2.6421946169745834

Epoch: 5| Step: 6
Training loss: 3.168459552041396
Validation loss: 2.6410840586828805

Epoch: 5| Step: 7
Training loss: 2.839691451867453
Validation loss: 2.6384184835990188

Epoch: 5| Step: 8
Training loss: 2.7585250323046404
Validation loss: 2.640807037088497

Epoch: 5| Step: 9
Training loss: 2.6232802797775023
Validation loss: 2.6401975115423073

Epoch: 5| Step: 10
Training loss: 2.964084372190898
Validation loss: 2.6391645192222013

Epoch: 84| Step: 0
Training loss: 3.3983983530881092
Validation loss: 2.637471189829007

Epoch: 5| Step: 1
Training loss: 2.442011057898177
Validation loss: 2.63886989578755

Epoch: 5| Step: 2
Training loss: 3.1532437955256483
Validation loss: 2.6358481462550585

Epoch: 5| Step: 3
Training loss: 2.7450882656727504
Validation loss: 2.6355016025830293

Epoch: 5| Step: 4
Training loss: 3.330424056445658
Validation loss: 2.634531553338372

Epoch: 5| Step: 5
Training loss: 2.9589516615869056
Validation loss: 2.6358066497110144

Epoch: 5| Step: 6
Training loss: 2.9011277209427813
Validation loss: 2.6325092853717815

Epoch: 5| Step: 7
Training loss: 2.632500785689857
Validation loss: 2.633082555177572

Epoch: 5| Step: 8
Training loss: 2.6619805845703297
Validation loss: 2.6315440844583455

Epoch: 5| Step: 9
Training loss: 3.1780271201876094
Validation loss: 2.6289460757984693

Epoch: 5| Step: 10
Training loss: 3.3828697287848244
Validation loss: 2.627928094448844

Epoch: 85| Step: 0
Training loss: 2.8887341062536893
Validation loss: 2.624611223673997

Epoch: 5| Step: 1
Training loss: 3.3747610784662903
Validation loss: 2.622600911351523

Epoch: 5| Step: 2
Training loss: 3.096584678306388
Validation loss: 2.629438878909274

Epoch: 5| Step: 3
Training loss: 2.413997908533639
Validation loss: 2.6272071060223903

Epoch: 5| Step: 4
Training loss: 2.894790699562734
Validation loss: 2.6387873099148234

Epoch: 5| Step: 5
Training loss: 2.65406862334337
Validation loss: 2.6368879862336363

Epoch: 5| Step: 6
Training loss: 3.055463219220416
Validation loss: 2.6624348104567956

Epoch: 5| Step: 7
Training loss: 2.960883872319022
Validation loss: 2.6628040053312594

Epoch: 5| Step: 8
Training loss: 3.1933974517512027
Validation loss: 2.6726980764032637

Epoch: 5| Step: 9
Training loss: 2.9088189041245225
Validation loss: 2.6581825884299937

Epoch: 5| Step: 10
Training loss: 3.12917567699234
Validation loss: 2.6345892074142263

Epoch: 86| Step: 0
Training loss: 3.304969432879903
Validation loss: 2.6151954687011973

Epoch: 5| Step: 1
Training loss: 3.113017493434419
Validation loss: 2.6159281880003786

Epoch: 5| Step: 2
Training loss: 2.4109560043010516
Validation loss: 2.613627158719498

Epoch: 5| Step: 3
Training loss: 3.0606964405860335
Validation loss: 2.62226440153768

Epoch: 5| Step: 4
Training loss: 2.533651837186806
Validation loss: 2.6211325912442693

Epoch: 5| Step: 5
Training loss: 3.100395386615186
Validation loss: 2.621370977141872

Epoch: 5| Step: 6
Training loss: 2.873995066278161
Validation loss: 2.6180077452838533

Epoch: 5| Step: 7
Training loss: 2.5921247974834776
Validation loss: 2.619518799056119

Epoch: 5| Step: 8
Training loss: 3.298646857530864
Validation loss: 2.612605870629477

Epoch: 5| Step: 9
Training loss: 3.535961957131365
Validation loss: 2.6115454246963874

Epoch: 5| Step: 10
Training loss: 2.6554719570821783
Validation loss: 2.6124530411001334

Epoch: 87| Step: 0
Training loss: 2.6821605070076555
Validation loss: 2.622423023363529

Epoch: 5| Step: 1
Training loss: 3.211549426797626
Validation loss: 2.649461162220707

Epoch: 5| Step: 2
Training loss: 2.848993183785262
Validation loss: 2.6206703360590486

Epoch: 5| Step: 3
Training loss: 2.99656942040741
Validation loss: 2.622069597789357

Epoch: 5| Step: 4
Training loss: 3.049817977226488
Validation loss: 2.6156253076025537

Epoch: 5| Step: 5
Training loss: 2.890040818028459
Validation loss: 2.609308164449339

Epoch: 5| Step: 6
Training loss: 2.693573055961225
Validation loss: 2.604261993304197

Epoch: 5| Step: 7
Training loss: 2.8499115645758764
Validation loss: 2.6078903732902505

Epoch: 5| Step: 8
Training loss: 3.0039927615244855
Validation loss: 2.605723714347568

Epoch: 5| Step: 9
Training loss: 3.481723614840667
Validation loss: 2.606696775531229

Epoch: 5| Step: 10
Training loss: 2.7930445520745004
Validation loss: 2.605555506520963

Epoch: 88| Step: 0
Training loss: 3.1111996918132507
Validation loss: 2.60519320299029

Epoch: 5| Step: 1
Training loss: 2.3682990659006
Validation loss: 2.6033340980520574

Epoch: 5| Step: 2
Training loss: 3.3271300928647487
Validation loss: 2.602374931623445

Epoch: 5| Step: 3
Training loss: 3.0818483711783373
Validation loss: 2.610501229123888

Epoch: 5| Step: 4
Training loss: 2.5938762955768286
Validation loss: 2.606293528321622

Epoch: 5| Step: 5
Training loss: 3.1588205879273783
Validation loss: 2.6210438224282524

Epoch: 5| Step: 6
Training loss: 2.994312776616936
Validation loss: 2.637462790702567

Epoch: 5| Step: 7
Training loss: 3.229648988860486
Validation loss: 2.649108113579955

Epoch: 5| Step: 8
Training loss: 3.0529888142225587
Validation loss: 2.6262603005952356

Epoch: 5| Step: 9
Training loss: 2.6410147475235655
Validation loss: 2.6100080092080957

Epoch: 5| Step: 10
Training loss: 2.8744604184870473
Validation loss: 2.609052615937587

Epoch: 89| Step: 0
Training loss: 2.949388835120324
Validation loss: 2.607261477217085

Epoch: 5| Step: 1
Training loss: 2.8140740122710537
Validation loss: 2.6044993621618953

Epoch: 5| Step: 2
Training loss: 3.192394463117315
Validation loss: 2.607331049487408

Epoch: 5| Step: 3
Training loss: 2.6244983193698648
Validation loss: 2.6058497562265632

Epoch: 5| Step: 4
Training loss: 2.627340091154901
Validation loss: 2.6099929691858534

Epoch: 5| Step: 5
Training loss: 3.558097528391459
Validation loss: 2.6112814448937023

Epoch: 5| Step: 6
Training loss: 2.4138169642147593
Validation loss: 2.6079496651962253

Epoch: 5| Step: 7
Training loss: 2.9507252464403506
Validation loss: 2.6145790458604496

Epoch: 5| Step: 8
Training loss: 3.118054721060917
Validation loss: 2.611272015112469

Epoch: 5| Step: 9
Training loss: 3.2009540923669038
Validation loss: 2.623543851585504

Epoch: 5| Step: 10
Training loss: 2.94434727402461
Validation loss: 2.6488564812309394

Epoch: 90| Step: 0
Training loss: 2.9365773476719226
Validation loss: 2.6582432293949587

Epoch: 5| Step: 1
Training loss: 3.028870897576285
Validation loss: 2.6598312046590555

Epoch: 5| Step: 2
Training loss: 3.1205250552564707
Validation loss: 2.6695300221555516

Epoch: 5| Step: 3
Training loss: 3.0782450541209703
Validation loss: 2.676090668519701

Epoch: 5| Step: 4
Training loss: 2.9641305419962727
Validation loss: 2.660082215184249

Epoch: 5| Step: 5
Training loss: 2.591481607173511
Validation loss: 2.6414949901748423

Epoch: 5| Step: 6
Training loss: 3.416785230362717
Validation loss: 2.6410043784549897

Epoch: 5| Step: 7
Training loss: 2.3418836156006035
Validation loss: 2.6337398973261634

Epoch: 5| Step: 8
Training loss: 3.0048021981996045
Validation loss: 2.605808228622419

Epoch: 5| Step: 9
Training loss: 3.1452522162143173
Validation loss: 2.6024108526376835

Epoch: 5| Step: 10
Training loss: 2.8605497688134003
Validation loss: 2.5989557305226647

Epoch: 91| Step: 0
Training loss: 3.334526102919977
Validation loss: 2.5967841195001067

Epoch: 5| Step: 1
Training loss: 3.0921157990518555
Validation loss: 2.598704199120976

Epoch: 5| Step: 2
Training loss: 2.7862309633462945
Validation loss: 2.5999389093430163

Epoch: 5| Step: 3
Training loss: 2.732144301455959
Validation loss: 2.6004471606930206

Epoch: 5| Step: 4
Training loss: 2.82174451828383
Validation loss: 2.6016960372139883

Epoch: 5| Step: 5
Training loss: 2.948203532321533
Validation loss: 2.5974181560880187

Epoch: 5| Step: 6
Training loss: 3.6569201515499365
Validation loss: 2.598459761700334

Epoch: 5| Step: 7
Training loss: 2.660858644133517
Validation loss: 2.5975620925965184

Epoch: 5| Step: 8
Training loss: 2.766248212521575
Validation loss: 2.5962888614997666

Epoch: 5| Step: 9
Training loss: 2.7473339682509423
Validation loss: 2.5951316431122655

Epoch: 5| Step: 10
Training loss: 2.806755727214208
Validation loss: 2.59675007244416

Epoch: 92| Step: 0
Training loss: 2.6628091050650045
Validation loss: 2.596447189290065

Epoch: 5| Step: 1
Training loss: 3.3563130463374016
Validation loss: 2.608577153130289

Epoch: 5| Step: 2
Training loss: 2.839489606475213
Validation loss: 2.6234856772538695

Epoch: 5| Step: 3
Training loss: 2.8844945285617607
Validation loss: 2.643645852087784

Epoch: 5| Step: 4
Training loss: 2.8404221398295855
Validation loss: 2.6709631703831898

Epoch: 5| Step: 5
Training loss: 3.026651886667247
Validation loss: 2.6882594953483676

Epoch: 5| Step: 6
Training loss: 3.1720035320228646
Validation loss: 2.6973635547251837

Epoch: 5| Step: 7
Training loss: 3.0606757199566132
Validation loss: 2.6931508840443827

Epoch: 5| Step: 8
Training loss: 2.9731926051936366
Validation loss: 2.682086796656996

Epoch: 5| Step: 9
Training loss: 2.8842452295936267
Validation loss: 2.6791412964972703

Epoch: 5| Step: 10
Training loss: 2.8903463693309477
Validation loss: 2.6361733975923385

Epoch: 93| Step: 0
Training loss: 3.048985928661572
Validation loss: 2.6288344030846487

Epoch: 5| Step: 1
Training loss: 2.7986375593434953
Validation loss: 2.6231355515982826

Epoch: 5| Step: 2
Training loss: 2.984189971460698
Validation loss: 2.617191862868871

Epoch: 5| Step: 3
Training loss: 2.8508055635995584
Validation loss: 2.6215045663798935

Epoch: 5| Step: 4
Training loss: 2.922336807067322
Validation loss: 2.624320728996396

Epoch: 5| Step: 5
Training loss: 2.8520649506501514
Validation loss: 2.6092789104007514

Epoch: 5| Step: 6
Training loss: 2.8337659692503623
Validation loss: 2.606708105224892

Epoch: 5| Step: 7
Training loss: 2.7439798002528293
Validation loss: 2.6069863911018194

Epoch: 5| Step: 8
Training loss: 3.2418246514297584
Validation loss: 2.612254774482962

Epoch: 5| Step: 9
Training loss: 3.2521984294210298
Validation loss: 2.6051764484993885

Epoch: 5| Step: 10
Training loss: 3.1394285133899826
Validation loss: 2.603619148697222

Epoch: 94| Step: 0
Training loss: 3.4208488144952125
Validation loss: 2.6000820486549774

Epoch: 5| Step: 1
Training loss: 3.1918995731588793
Validation loss: 2.594418327533448

Epoch: 5| Step: 2
Training loss: 2.743239154921822
Validation loss: 2.5860197632087263

Epoch: 5| Step: 3
Training loss: 2.9753691115721517
Validation loss: 2.588846578710293

Epoch: 5| Step: 4
Training loss: 3.060324382667373
Validation loss: 2.58680816369096

Epoch: 5| Step: 5
Training loss: 2.2539475038875154
Validation loss: 2.585639291279654

Epoch: 5| Step: 6
Training loss: 2.8913193976966762
Validation loss: 2.58967606443942

Epoch: 5| Step: 7
Training loss: 2.497066588803686
Validation loss: 2.592640815168544

Epoch: 5| Step: 8
Training loss: 2.772532828629381
Validation loss: 2.607738298664907

Epoch: 5| Step: 9
Training loss: 3.3783294361796496
Validation loss: 2.6210677358643553

Epoch: 5| Step: 10
Training loss: 3.0898548613106156
Validation loss: 2.6547578504030227

Epoch: 95| Step: 0
Training loss: 2.482528095989145
Validation loss: 2.6958513950221437

Epoch: 5| Step: 1
Training loss: 3.6766611924970816
Validation loss: 2.7368869738842627

Epoch: 5| Step: 2
Training loss: 3.0185110878240775
Validation loss: 2.6426854646399573

Epoch: 5| Step: 3
Training loss: 2.3863040545072756
Validation loss: 2.5909213107289095

Epoch: 5| Step: 4
Training loss: 3.3006885041518883
Validation loss: 2.5847077654828285

Epoch: 5| Step: 5
Training loss: 2.685045585316393
Validation loss: 2.5789259456036717

Epoch: 5| Step: 6
Training loss: 3.161722707404244
Validation loss: 2.5834104392155113

Epoch: 5| Step: 7
Training loss: 2.776241722317876
Validation loss: 2.58927326349934

Epoch: 5| Step: 8
Training loss: 2.6620518768437487
Validation loss: 2.5933435672410776

Epoch: 5| Step: 9
Training loss: 2.562883301887114
Validation loss: 2.597957870214937

Epoch: 5| Step: 10
Training loss: 3.531730011579994
Validation loss: 2.6148478752439557

Epoch: 96| Step: 0
Training loss: 3.2562262243182656
Validation loss: 2.6118631744582306

Epoch: 5| Step: 1
Training loss: 2.9887085453287177
Validation loss: 2.610157762319487

Epoch: 5| Step: 2
Training loss: 3.0881665641552285
Validation loss: 2.6055681197665828

Epoch: 5| Step: 3
Training loss: 2.963774838964921
Validation loss: 2.592062614632102

Epoch: 5| Step: 4
Training loss: 2.635669912200289
Validation loss: 2.582941646501156

Epoch: 5| Step: 5
Training loss: 2.5693315761852475
Validation loss: 2.5794303674416024

Epoch: 5| Step: 6
Training loss: 2.980506506764452
Validation loss: 2.5807222242667494

Epoch: 5| Step: 7
Training loss: 2.568630607410622
Validation loss: 2.5733162839173724

Epoch: 5| Step: 8
Training loss: 3.039622120460514
Validation loss: 2.577795072832152

Epoch: 5| Step: 9
Training loss: 3.407751749748658
Validation loss: 2.59933094830074

Epoch: 5| Step: 10
Training loss: 2.8104287043813954
Validation loss: 2.6271261637400816

Epoch: 97| Step: 0
Training loss: 3.080790029243257
Validation loss: 2.6554395835203994

Epoch: 5| Step: 1
Training loss: 2.818813612530978
Validation loss: 2.654865016261672

Epoch: 5| Step: 2
Training loss: 3.076562940172248
Validation loss: 2.6294980632055873

Epoch: 5| Step: 3
Training loss: 3.3717201685247287
Validation loss: 2.5897026037779005

Epoch: 5| Step: 4
Training loss: 3.099653987647597
Validation loss: 2.5727955219759764

Epoch: 5| Step: 5
Training loss: 3.1422986178334
Validation loss: 2.571654952783681

Epoch: 5| Step: 6
Training loss: 3.3652556291950693
Validation loss: 2.575640833762711

Epoch: 5| Step: 7
Training loss: 1.8924630428318798
Validation loss: 2.5722647619036145

Epoch: 5| Step: 8
Training loss: 2.849195527425841
Validation loss: 2.5766415909670863

Epoch: 5| Step: 9
Training loss: 2.2774344110518454
Validation loss: 2.578467223621982

Epoch: 5| Step: 10
Training loss: 3.1180151125166673
Validation loss: 2.580465504939004

Epoch: 98| Step: 0
Training loss: 3.395489275456303
Validation loss: 2.5781695568700425

Epoch: 5| Step: 1
Training loss: 3.143180452784194
Validation loss: 2.579862481587716

Epoch: 5| Step: 2
Training loss: 2.94169025645825
Validation loss: 2.5836708577418372

Epoch: 5| Step: 3
Training loss: 3.1660111066631855
Validation loss: 2.5789112352695556

Epoch: 5| Step: 4
Training loss: 2.58403438366905
Validation loss: 2.576869945744364

Epoch: 5| Step: 5
Training loss: 3.0776413280967585
Validation loss: 2.5719829683740976

Epoch: 5| Step: 6
Training loss: 3.259195084694633
Validation loss: 2.576845575388356

Epoch: 5| Step: 7
Training loss: 1.9747534151300072
Validation loss: 2.570835330023859

Epoch: 5| Step: 8
Training loss: 3.1432714746509713
Validation loss: 2.5706137662541253

Epoch: 5| Step: 9
Training loss: 2.3811523657780267
Validation loss: 2.571371139316182

Epoch: 5| Step: 10
Training loss: 3.129900789729963
Validation loss: 2.5721516907830586

Epoch: 99| Step: 0
Training loss: 3.0677818371570402
Validation loss: 2.5664208641927884

Epoch: 5| Step: 1
Training loss: 3.045946967792287
Validation loss: 2.565714153201517

Epoch: 5| Step: 2
Training loss: 2.423277811658834
Validation loss: 2.567505504469134

Epoch: 5| Step: 3
Training loss: 2.6342810092508095
Validation loss: 2.5717955992441084

Epoch: 5| Step: 4
Training loss: 3.123577709781751
Validation loss: 2.580135973436112

Epoch: 5| Step: 5
Training loss: 3.2694428681490706
Validation loss: 2.576564968397016

Epoch: 5| Step: 6
Training loss: 3.116244907367338
Validation loss: 2.5709508611897625

Epoch: 5| Step: 7
Training loss: 2.112160545930031
Validation loss: 2.5752923811606605

Epoch: 5| Step: 8
Training loss: 3.2796672091644683
Validation loss: 2.5717384374390484

Epoch: 5| Step: 9
Training loss: 2.9874611121802994
Validation loss: 2.567598708263584

Epoch: 5| Step: 10
Training loss: 2.9817830758766597
Validation loss: 2.5705298252004782

Epoch: 100| Step: 0
Training loss: 3.12625874917363
Validation loss: 2.5697646696926197

Epoch: 5| Step: 1
Training loss: 2.722908960597588
Validation loss: 2.568126535500017

Epoch: 5| Step: 2
Training loss: 3.634377025757846
Validation loss: 2.5749092857055786

Epoch: 5| Step: 3
Training loss: 3.015742956829219
Validation loss: 2.5740938274129275

Epoch: 5| Step: 4
Training loss: 2.7422628799902484
Validation loss: 2.576639864720794

Epoch: 5| Step: 5
Training loss: 2.857863062958247
Validation loss: 2.5781794895592682

Epoch: 5| Step: 6
Training loss: 2.9014666170168297
Validation loss: 2.5834021531014226

Epoch: 5| Step: 7
Training loss: 2.7153877426822732
Validation loss: 2.5979782513098724

Epoch: 5| Step: 8
Training loss: 2.839119631287438
Validation loss: 2.6063832952416117

Epoch: 5| Step: 9
Training loss: 2.377023938769014
Validation loss: 2.60455040612653

Epoch: 5| Step: 10
Training loss: 3.088992844424816
Validation loss: 2.613604640683058

Epoch: 101| Step: 0
Training loss: 2.992317057461573
Validation loss: 2.6005267369709135

Epoch: 5| Step: 1
Training loss: 2.4073856200620707
Validation loss: 2.6222568150105174

Epoch: 5| Step: 2
Training loss: 3.1504638814715893
Validation loss: 2.648248299164425

Epoch: 5| Step: 3
Training loss: 2.9580382795455566
Validation loss: 2.677480594818268

Epoch: 5| Step: 4
Training loss: 3.4855953525693466
Validation loss: 2.6144286772094336

Epoch: 5| Step: 5
Training loss: 3.1823109294768286
Validation loss: 2.5820294648057054

Epoch: 5| Step: 6
Training loss: 2.6818928443672414
Validation loss: 2.563447292459624

Epoch: 5| Step: 7
Training loss: 3.010697999543961
Validation loss: 2.56924024230733

Epoch: 5| Step: 8
Training loss: 2.576984500043482
Validation loss: 2.5689759449723755

Epoch: 5| Step: 9
Training loss: 2.69746317544007
Validation loss: 2.5691897301404047

Epoch: 5| Step: 10
Training loss: 2.942404528213925
Validation loss: 2.5728454686274853

Epoch: 102| Step: 0
Training loss: 2.9973192953661147
Validation loss: 2.5728962692230066

Epoch: 5| Step: 1
Training loss: 2.6164714687781196
Validation loss: 2.5675261312897675

Epoch: 5| Step: 2
Training loss: 2.7105939575979114
Validation loss: 2.570957049536213

Epoch: 5| Step: 3
Training loss: 2.8826249224416007
Validation loss: 2.5701757602180137

Epoch: 5| Step: 4
Training loss: 3.4143098440417803
Validation loss: 2.5714822000136865

Epoch: 5| Step: 5
Training loss: 2.7628806771059247
Validation loss: 2.5734942968835024

Epoch: 5| Step: 6
Training loss: 2.532867574122416
Validation loss: 2.5721765765437956

Epoch: 5| Step: 7
Training loss: 3.2676980771280877
Validation loss: 2.5744109527266055

Epoch: 5| Step: 8
Training loss: 2.5513320958985353
Validation loss: 2.5791956334464876

Epoch: 5| Step: 9
Training loss: 3.307409297423159
Validation loss: 2.579337631932068

Epoch: 5| Step: 10
Training loss: 2.9674800365004663
Validation loss: 2.592091774186848

Epoch: 103| Step: 0
Training loss: 2.890041807987646
Validation loss: 2.6060891672591087

Epoch: 5| Step: 1
Training loss: 2.8733479272718134
Validation loss: 2.616088030890493

Epoch: 5| Step: 2
Training loss: 3.059519348791552
Validation loss: 2.627297756700717

Epoch: 5| Step: 3
Training loss: 3.317768010551428
Validation loss: 2.607049150209502

Epoch: 5| Step: 4
Training loss: 3.027797502537055
Validation loss: 2.5962845612601515

Epoch: 5| Step: 5
Training loss: 2.7633267783657445
Validation loss: 2.568711855977694

Epoch: 5| Step: 6
Training loss: 3.169352162346003
Validation loss: 2.5644076010236256

Epoch: 5| Step: 7
Training loss: 3.42514397534338
Validation loss: 2.560988363766827

Epoch: 5| Step: 8
Training loss: 2.681097343740762
Validation loss: 2.5547709751656367

Epoch: 5| Step: 9
Training loss: 2.705770708241893
Validation loss: 2.556896892929966

Epoch: 5| Step: 10
Training loss: 1.804374304342846
Validation loss: 2.5606578635366586

Epoch: 104| Step: 0
Training loss: 2.642214776185394
Validation loss: 2.56162613425577

Epoch: 5| Step: 1
Training loss: 2.964031284069366
Validation loss: 2.5685985715662976

Epoch: 5| Step: 2
Training loss: 2.860759795840446
Validation loss: 2.571342889346613

Epoch: 5| Step: 3
Training loss: 3.232212836660384
Validation loss: 2.555228969820945

Epoch: 5| Step: 4
Training loss: 2.956596312289727
Validation loss: 2.5592246794349056

Epoch: 5| Step: 5
Training loss: 2.6110344823680967
Validation loss: 2.559531837123462

Epoch: 5| Step: 6
Training loss: 2.8444032023671886
Validation loss: 2.580241259825576

Epoch: 5| Step: 7
Training loss: 3.3549669310166577
Validation loss: 2.5937242661094158

Epoch: 5| Step: 8
Training loss: 2.4446496034513383
Validation loss: 2.605099600431214

Epoch: 5| Step: 9
Training loss: 3.219428129888988
Validation loss: 2.5986811995882526

Epoch: 5| Step: 10
Training loss: 2.881392297106421
Validation loss: 2.5842229377879793

Epoch: 105| Step: 0
Training loss: 3.225297509006951
Validation loss: 2.5840742720468906

Epoch: 5| Step: 1
Training loss: 2.394716339674422
Validation loss: 2.5504561546884403

Epoch: 5| Step: 2
Training loss: 3.2829931079653885
Validation loss: 2.5542750253108193

Epoch: 5| Step: 3
Training loss: 3.1429852019886177
Validation loss: 2.554777795754374

Epoch: 5| Step: 4
Training loss: 2.7376147450824186
Validation loss: 2.555697197382536

Epoch: 5| Step: 5
Training loss: 2.6825122236415946
Validation loss: 2.559800406497207

Epoch: 5| Step: 6
Training loss: 2.927808968049923
Validation loss: 2.5619316050946503

Epoch: 5| Step: 7
Training loss: 2.8886693989276915
Validation loss: 2.5636650976336277

Epoch: 5| Step: 8
Training loss: 2.94542226409776
Validation loss: 2.5650358201066257

Epoch: 5| Step: 9
Training loss: 2.9774168695716696
Validation loss: 2.5624195279327244

Epoch: 5| Step: 10
Training loss: 2.8973282904840723
Validation loss: 2.5624630963149024

Epoch: 106| Step: 0
Training loss: 2.8703108985327423
Validation loss: 2.5664937171497217

Epoch: 5| Step: 1
Training loss: 3.0375952623287668
Validation loss: 2.562489969517535

Epoch: 5| Step: 2
Training loss: 3.337398307479728
Validation loss: 2.561071808738646

Epoch: 5| Step: 3
Training loss: 2.583827607235505
Validation loss: 2.5640470015435284

Epoch: 5| Step: 4
Training loss: 2.9148239490876295
Validation loss: 2.5631057079415207

Epoch: 5| Step: 5
Training loss: 2.833100552439743
Validation loss: 2.560087858973737

Epoch: 5| Step: 6
Training loss: 2.8026518593580585
Validation loss: 2.55881621630353

Epoch: 5| Step: 7
Training loss: 3.331262962788452
Validation loss: 2.54997898023171

Epoch: 5| Step: 8
Training loss: 2.755192622600873
Validation loss: 2.556159174693813

Epoch: 5| Step: 9
Training loss: 2.909556650950507
Validation loss: 2.582905102372324

Epoch: 5| Step: 10
Training loss: 2.717415931755919
Validation loss: 2.608771707520822

Epoch: 107| Step: 0
Training loss: 3.0758951698466954
Validation loss: 2.617029904852218

Epoch: 5| Step: 1
Training loss: 2.5234538452752844
Validation loss: 2.6003370640015984

Epoch: 5| Step: 2
Training loss: 2.135251728914251
Validation loss: 2.5837279083594855

Epoch: 5| Step: 3
Training loss: 3.16279964912155
Validation loss: 2.584756713775059

Epoch: 5| Step: 4
Training loss: 2.9201486965099916
Validation loss: 2.591427354776981

Epoch: 5| Step: 5
Training loss: 3.6250565623112774
Validation loss: 2.6157780458754956

Epoch: 5| Step: 6
Training loss: 3.492245940331762
Validation loss: 2.612455665136435

Epoch: 5| Step: 7
Training loss: 2.7672734924085676
Validation loss: 2.580449608218012

Epoch: 5| Step: 8
Training loss: 2.858892514738467
Validation loss: 2.570548552805978

Epoch: 5| Step: 9
Training loss: 2.3768596395697874
Validation loss: 2.548114029558954

Epoch: 5| Step: 10
Training loss: 2.8825915078743867
Validation loss: 2.5430400852181982

Epoch: 108| Step: 0
Training loss: 3.034768019582094
Validation loss: 2.5447696832342643

Epoch: 5| Step: 1
Training loss: 2.7122664038982847
Validation loss: 2.5431210928886094

Epoch: 5| Step: 2
Training loss: 3.09364056634499
Validation loss: 2.542678765311219

Epoch: 5| Step: 3
Training loss: 3.127105613864628
Validation loss: 2.546038490942814

Epoch: 5| Step: 4
Training loss: 3.002866964538034
Validation loss: 2.5435185785747576

Epoch: 5| Step: 5
Training loss: 2.7988646691885415
Validation loss: 2.543392343646826

Epoch: 5| Step: 6
Training loss: 2.5754857281078567
Validation loss: 2.542684940798283

Epoch: 5| Step: 7
Training loss: 3.0092220025867236
Validation loss: 2.540714758091277

Epoch: 5| Step: 8
Training loss: 2.6285719410972805
Validation loss: 2.5408382666162272

Epoch: 5| Step: 9
Training loss: 2.6154317403880283
Validation loss: 2.5430088137404385

Epoch: 5| Step: 10
Training loss: 3.4335483378769545
Validation loss: 2.548948774262809

Epoch: 109| Step: 0
Training loss: 3.031454806930158
Validation loss: 2.5489488154991284

Epoch: 5| Step: 1
Training loss: 3.1444065993345194
Validation loss: 2.5740724216053006

Epoch: 5| Step: 2
Training loss: 2.7160490804515804
Validation loss: 2.6133716744862907

Epoch: 5| Step: 3
Training loss: 2.717393997356905
Validation loss: 2.6554691119935754

Epoch: 5| Step: 4
Training loss: 2.996057303752818
Validation loss: 2.648968399602497

Epoch: 5| Step: 5
Training loss: 3.2791617878575043
Validation loss: 2.6465525529317486

Epoch: 5| Step: 6
Training loss: 2.29971532303818
Validation loss: 2.6017819809996974

Epoch: 5| Step: 7
Training loss: 2.9164214621514257
Validation loss: 2.557879440266872

Epoch: 5| Step: 8
Training loss: 3.134954695184116
Validation loss: 2.556718542569525

Epoch: 5| Step: 9
Training loss: 2.7996937277727065
Validation loss: 2.5454263075537567

Epoch: 5| Step: 10
Training loss: 2.8585635842282193
Validation loss: 2.5579330531890387

Epoch: 110| Step: 0
Training loss: 2.5218121753605343
Validation loss: 2.543518054460926

Epoch: 5| Step: 1
Training loss: 2.4622027338754737
Validation loss: 2.5489314127074074

Epoch: 5| Step: 2
Training loss: 3.1182406756854135
Validation loss: 2.5482898121540187

Epoch: 5| Step: 3
Training loss: 3.643833432951782
Validation loss: 2.548389110821403

Epoch: 5| Step: 4
Training loss: 2.4724788270666687
Validation loss: 2.549562215413444

Epoch: 5| Step: 5
Training loss: 2.976987472994751
Validation loss: 2.558311845532121

Epoch: 5| Step: 6
Training loss: 3.102754224617436
Validation loss: 2.5688182652776446

Epoch: 5| Step: 7
Training loss: 2.225381959855102
Validation loss: 2.580490732251024

Epoch: 5| Step: 8
Training loss: 2.5292170331570536
Validation loss: 2.5801750119517575

Epoch: 5| Step: 9
Training loss: 3.402276477520924
Validation loss: 2.618705717379985

Epoch: 5| Step: 10
Training loss: 3.266679219461833
Validation loss: 2.647881806307592

Epoch: 111| Step: 0
Training loss: 2.629912547989153
Validation loss: 2.6276165812233745

Epoch: 5| Step: 1
Training loss: 2.901923291644419
Validation loss: 2.6080796021209154

Epoch: 5| Step: 2
Training loss: 2.780243938089902
Validation loss: 2.599167783642695

Epoch: 5| Step: 3
Training loss: 3.2007917140038256
Validation loss: 2.5748417556489422

Epoch: 5| Step: 4
Training loss: 2.784721864957673
Validation loss: 2.5549956315863365

Epoch: 5| Step: 5
Training loss: 3.1017097803310625
Validation loss: 2.541751916794832

Epoch: 5| Step: 6
Training loss: 3.1202762760204887
Validation loss: 2.538745639614486

Epoch: 5| Step: 7
Training loss: 2.7276878330019074
Validation loss: 2.5385921676858305

Epoch: 5| Step: 8
Training loss: 2.5084441628372973
Validation loss: 2.5414069900583995

Epoch: 5| Step: 9
Training loss: 2.979166968996971
Validation loss: 2.536925674289413

Epoch: 5| Step: 10
Training loss: 3.345818566035979
Validation loss: 2.538193449943401

Epoch: 112| Step: 0
Training loss: 2.7377348394126555
Validation loss: 2.5392466841943717

Epoch: 5| Step: 1
Training loss: 2.5780120824881396
Validation loss: 2.5412751845626844

Epoch: 5| Step: 2
Training loss: 2.6787460942313324
Validation loss: 2.545260705625295

Epoch: 5| Step: 3
Training loss: 2.693514459140987
Validation loss: 2.5528576364164617

Epoch: 5| Step: 4
Training loss: 3.2576921838731425
Validation loss: 2.5675277178846074

Epoch: 5| Step: 5
Training loss: 3.1076026350827486
Validation loss: 2.574431473433282

Epoch: 5| Step: 6
Training loss: 3.00850235595408
Validation loss: 2.588580204387601

Epoch: 5| Step: 7
Training loss: 3.013819811410738
Validation loss: 2.6110652857235395

Epoch: 5| Step: 8
Training loss: 2.655112797268139
Validation loss: 2.6154770065144

Epoch: 5| Step: 9
Training loss: 2.836544928114382
Validation loss: 2.6165619005881364

Epoch: 5| Step: 10
Training loss: 3.3356112961668978
Validation loss: 2.635458075318726

Epoch: 113| Step: 0
Training loss: 2.427637934591418
Validation loss: 2.626921150454216

Epoch: 5| Step: 1
Training loss: 2.641168843081793
Validation loss: 2.6184846972005476

Epoch: 5| Step: 2
Training loss: 3.2082890263920545
Validation loss: 2.5974909163943156

Epoch: 5| Step: 3
Training loss: 3.248878578967522
Validation loss: 2.558196369903465

Epoch: 5| Step: 4
Training loss: 3.2441451815045514
Validation loss: 2.534712078369928

Epoch: 5| Step: 5
Training loss: 3.475527628628966
Validation loss: 2.5387518620315688

Epoch: 5| Step: 6
Training loss: 3.128053622808133
Validation loss: 2.5362121151900356

Epoch: 5| Step: 7
Training loss: 2.7861228004059067
Validation loss: 2.5380364699236075

Epoch: 5| Step: 8
Training loss: 2.705454181187988
Validation loss: 2.538368049102309

Epoch: 5| Step: 9
Training loss: 2.556130284721556
Validation loss: 2.5406873508499492

Epoch: 5| Step: 10
Training loss: 2.370820232370803
Validation loss: 2.536874602577084

Epoch: 114| Step: 0
Training loss: 2.577002726111193
Validation loss: 2.535368698695962

Epoch: 5| Step: 1
Training loss: 3.2867192780911596
Validation loss: 2.5289198991337476

Epoch: 5| Step: 2
Training loss: 2.366081961636606
Validation loss: 2.5368844372383155

Epoch: 5| Step: 3
Training loss: 2.6618733738761926
Validation loss: 2.5492841784761624

Epoch: 5| Step: 4
Training loss: 3.0413031861671453
Validation loss: 2.5810270610097157

Epoch: 5| Step: 5
Training loss: 2.926739890877729
Validation loss: 2.6060665211316336

Epoch: 5| Step: 6
Training loss: 3.310566319771435
Validation loss: 2.630056119543338

Epoch: 5| Step: 7
Training loss: 2.791132225767007
Validation loss: 2.6910664216930584

Epoch: 5| Step: 8
Training loss: 2.7425594240634137
Validation loss: 2.7160004859351923

Epoch: 5| Step: 9
Training loss: 2.5230117296935792
Validation loss: 2.6534731456311498

Epoch: 5| Step: 10
Training loss: 3.6731204254241336
Validation loss: 2.647158122400228

Epoch: 115| Step: 0
Training loss: 2.8388507266464633
Validation loss: 2.5953304132723214

Epoch: 5| Step: 1
Training loss: 2.7232365037784496
Validation loss: 2.56930240776931

Epoch: 5| Step: 2
Training loss: 3.178211816372761
Validation loss: 2.5544434360249872

Epoch: 5| Step: 3
Training loss: 2.9529336534301036
Validation loss: 2.543130059643403

Epoch: 5| Step: 4
Training loss: 2.7370317903511503
Validation loss: 2.5393426556000143

Epoch: 5| Step: 5
Training loss: 2.603036640403231
Validation loss: 2.5308261659813454

Epoch: 5| Step: 6
Training loss: 2.837225167160675
Validation loss: 2.5367190972869853

Epoch: 5| Step: 7
Training loss: 2.7690215724602076
Validation loss: 2.5398502755246004

Epoch: 5| Step: 8
Training loss: 3.1059976763105572
Validation loss: 2.542911830397586

Epoch: 5| Step: 9
Training loss: 3.119131758264636
Validation loss: 2.5387695284831575

Epoch: 5| Step: 10
Training loss: 3.0609991327363675
Validation loss: 2.5321506653559944

Epoch: 116| Step: 0
Training loss: 2.887916409410795
Validation loss: 2.530614844365783

Epoch: 5| Step: 1
Training loss: 2.4357478373197945
Validation loss: 2.5281683797585273

Epoch: 5| Step: 2
Training loss: 2.648350356927329
Validation loss: 2.5278089036016462

Epoch: 5| Step: 3
Training loss: 3.2563566984828163
Validation loss: 2.527258246993854

Epoch: 5| Step: 4
Training loss: 2.9653035286096205
Validation loss: 2.5262056629636223

Epoch: 5| Step: 5
Training loss: 2.887526052117999
Validation loss: 2.526598676731653

Epoch: 5| Step: 6
Training loss: 3.4885046055487114
Validation loss: 2.5362440860485087

Epoch: 5| Step: 7
Training loss: 2.3081991048775596
Validation loss: 2.5404153399990013

Epoch: 5| Step: 8
Training loss: 2.716638380812222
Validation loss: 2.552458716471024

Epoch: 5| Step: 9
Training loss: 3.1192138510405067
Validation loss: 2.5677620358949818

Epoch: 5| Step: 10
Training loss: 2.9722439734434483
Validation loss: 2.5866864239580165

Epoch: 117| Step: 0
Training loss: 3.206400466570944
Validation loss: 2.656701600533995

Epoch: 5| Step: 1
Training loss: 2.7297980667718926
Validation loss: 2.6437840437260216

Epoch: 5| Step: 2
Training loss: 2.9939880531291827
Validation loss: 2.6153379582749046

Epoch: 5| Step: 3
Training loss: 2.339123138885255
Validation loss: 2.605999213133283

Epoch: 5| Step: 4
Training loss: 2.6186325411071825
Validation loss: 2.5953064375301174

Epoch: 5| Step: 5
Training loss: 2.686119967260514
Validation loss: 2.608370235711114

Epoch: 5| Step: 6
Training loss: 2.897677668998587
Validation loss: 2.6113708930937607

Epoch: 5| Step: 7
Training loss: 3.044904179059788
Validation loss: 2.564846054357531

Epoch: 5| Step: 8
Training loss: 3.1913756202152386
Validation loss: 2.5447967463025964

Epoch: 5| Step: 9
Training loss: 2.992150846809612
Validation loss: 2.5242813859672353

Epoch: 5| Step: 10
Training loss: 3.1247581388338674
Validation loss: 2.5254514772043595

Epoch: 118| Step: 0
Training loss: 2.4849224327154658
Validation loss: 2.522131970199546

Epoch: 5| Step: 1
Training loss: 2.900573765787791
Validation loss: 2.5247367313892703

Epoch: 5| Step: 2
Training loss: 2.8861816897761177
Validation loss: 2.524934228856593

Epoch: 5| Step: 3
Training loss: 2.793741954134763
Validation loss: 2.5186654902590577

Epoch: 5| Step: 4
Training loss: 2.797173681241003
Validation loss: 2.524849075782662

Epoch: 5| Step: 5
Training loss: 2.8584493170544314
Validation loss: 2.5240038814562613

Epoch: 5| Step: 6
Training loss: 2.6465811285934633
Validation loss: 2.530365652064979

Epoch: 5| Step: 7
Training loss: 2.8168247456931392
Validation loss: 2.5317866461543894

Epoch: 5| Step: 8
Training loss: 2.911530158852173
Validation loss: 2.5325634737699985

Epoch: 5| Step: 9
Training loss: 3.462742044410107
Validation loss: 2.541466914059988

Epoch: 5| Step: 10
Training loss: 3.2158343989309612
Validation loss: 2.5434403594382156

Epoch: 119| Step: 0
Training loss: 2.6199032486093783
Validation loss: 2.5441868437001096

Epoch: 5| Step: 1
Training loss: 2.6331832126690187
Validation loss: 2.553997377961842

Epoch: 5| Step: 2
Training loss: 2.9381008751095217
Validation loss: 2.599880530260593

Epoch: 5| Step: 3
Training loss: 2.543763676637066
Validation loss: 2.625936091254741

Epoch: 5| Step: 4
Training loss: 3.080201818368778
Validation loss: 2.684878086018582

Epoch: 5| Step: 5
Training loss: 2.627486912833595
Validation loss: 2.680614259396442

Epoch: 5| Step: 6
Training loss: 3.230687052167159
Validation loss: 2.714300121483789

Epoch: 5| Step: 7
Training loss: 2.705856618856417
Validation loss: 2.689246077635924

Epoch: 5| Step: 8
Training loss: 3.2752317914399116
Validation loss: 2.6767177000919604

Epoch: 5| Step: 9
Training loss: 2.9939759489735764
Validation loss: 2.588688277752

Epoch: 5| Step: 10
Training loss: 3.252757443231369
Validation loss: 2.572224092393879

Epoch: 120| Step: 0
Training loss: 3.145692902182104
Validation loss: 2.5553456359643576

Epoch: 5| Step: 1
Training loss: 3.024897890495612
Validation loss: 2.5313292044954956

Epoch: 5| Step: 2
Training loss: 3.246544247799109
Validation loss: 2.5218991113372566

Epoch: 5| Step: 3
Training loss: 2.442885294172823
Validation loss: 2.521054850965809

Epoch: 5| Step: 4
Training loss: 2.726054321850526
Validation loss: 2.5268860508845217

Epoch: 5| Step: 5
Training loss: 2.9238454121274184
Validation loss: 2.529612839338914

Epoch: 5| Step: 6
Training loss: 2.7133128728102953
Validation loss: 2.526226018114216

Epoch: 5| Step: 7
Training loss: 2.7055674196470987
Validation loss: 2.527092038831566

Epoch: 5| Step: 8
Training loss: 2.9416823137279633
Validation loss: 2.527865946753064

Epoch: 5| Step: 9
Training loss: 3.1887515733715737
Validation loss: 2.529013104772513

Epoch: 5| Step: 10
Training loss: 2.9262895333586583
Validation loss: 2.527888182447806

Epoch: 121| Step: 0
Training loss: 2.7335954699384146
Validation loss: 2.5247920929168868

Epoch: 5| Step: 1
Training loss: 3.0846176222092976
Validation loss: 2.526347312454423

Epoch: 5| Step: 2
Training loss: 3.0489404182355213
Validation loss: 2.525533630683667

Epoch: 5| Step: 3
Training loss: 2.4767286563815
Validation loss: 2.532590343349674

Epoch: 5| Step: 4
Training loss: 2.6296162659669173
Validation loss: 2.5424749819563974

Epoch: 5| Step: 5
Training loss: 2.785995463967995
Validation loss: 2.568202382160318

Epoch: 5| Step: 6
Training loss: 2.9339734274942213
Validation loss: 2.5880073621025486

Epoch: 5| Step: 7
Training loss: 2.8149017251783603
Validation loss: 2.5999006477980258

Epoch: 5| Step: 8
Training loss: 3.3094160010776035
Validation loss: 2.5778001716752206

Epoch: 5| Step: 9
Training loss: 2.673415961031093
Validation loss: 2.556729598397556

Epoch: 5| Step: 10
Training loss: 3.358893497469628
Validation loss: 2.5642538324150856

Epoch: 122| Step: 0
Training loss: 2.734739268426146
Validation loss: 2.5932452356477844

Epoch: 5| Step: 1
Training loss: 2.9055357024481188
Validation loss: 2.596819388292407

Epoch: 5| Step: 2
Training loss: 3.2024309104119504
Validation loss: 2.6007591928174323

Epoch: 5| Step: 3
Training loss: 2.88246826763172
Validation loss: 2.579179197121893

Epoch: 5| Step: 4
Training loss: 2.86128529591453
Validation loss: 2.574056177652587

Epoch: 5| Step: 5
Training loss: 2.24823914607968
Validation loss: 2.551448036932367

Epoch: 5| Step: 6
Training loss: 3.207948207446647
Validation loss: 2.548113516451283

Epoch: 5| Step: 7
Training loss: 2.8527580367852567
Validation loss: 2.5521641627845226

Epoch: 5| Step: 8
Training loss: 2.765317910596805
Validation loss: 2.550436971962328

Epoch: 5| Step: 9
Training loss: 2.9303496972971854
Validation loss: 2.5569731814744445

Epoch: 5| Step: 10
Training loss: 3.2154995700110445
Validation loss: 2.5632389522815324

Epoch: 123| Step: 0
Training loss: 2.6425050442015
Validation loss: 2.549170630590313

Epoch: 5| Step: 1
Training loss: 2.8334078685456023
Validation loss: 2.542047614953286

Epoch: 5| Step: 2
Training loss: 3.128130298651934
Validation loss: 2.537191721890041

Epoch: 5| Step: 3
Training loss: 3.472820196583441
Validation loss: 2.5428307132258996

Epoch: 5| Step: 4
Training loss: 2.0700327558275435
Validation loss: 2.5387909683923446

Epoch: 5| Step: 5
Training loss: 3.0753585854461183
Validation loss: 2.5490619010805764

Epoch: 5| Step: 6
Training loss: 3.2355947359941823
Validation loss: 2.5605964989050545

Epoch: 5| Step: 7
Training loss: 2.814611532398051
Validation loss: 2.584836045114851

Epoch: 5| Step: 8
Training loss: 2.48367520439057
Validation loss: 2.597510605346022

Epoch: 5| Step: 9
Training loss: 2.655989510722302
Validation loss: 2.6057578802739876

Epoch: 5| Step: 10
Training loss: 2.9609014262314397
Validation loss: 2.606997757888238

Epoch: 124| Step: 0
Training loss: 3.386461083137165
Validation loss: 2.5827873872396254

Epoch: 5| Step: 1
Training loss: 2.9878607560055124
Validation loss: 2.557592543478746

Epoch: 5| Step: 2
Training loss: 2.3724444845314796
Validation loss: 2.5277327166121415

Epoch: 5| Step: 3
Training loss: 2.5770762766990996
Validation loss: 2.527414783735386

Epoch: 5| Step: 4
Training loss: 3.1466933500106844
Validation loss: 2.523366816564548

Epoch: 5| Step: 5
Training loss: 2.9962342787589975
Validation loss: 2.5226471955931054

Epoch: 5| Step: 6
Training loss: 2.5479908938342493
Validation loss: 2.527711620033757

Epoch: 5| Step: 7
Training loss: 2.9376585897287537
Validation loss: 2.5249298375519547

Epoch: 5| Step: 8
Training loss: 2.6917730560378192
Validation loss: 2.523582630840794

Epoch: 5| Step: 9
Training loss: 2.894846704670643
Validation loss: 2.5217839974538583

Epoch: 5| Step: 10
Training loss: 3.1061854273265057
Validation loss: 2.5279544538095955

Epoch: 125| Step: 0
Training loss: 2.6832572803816164
Validation loss: 2.5389890548142575

Epoch: 5| Step: 1
Training loss: 3.010300120349331
Validation loss: 2.5406472878369692

Epoch: 5| Step: 2
Training loss: 2.963594477517606
Validation loss: 2.5561946093577426

Epoch: 5| Step: 3
Training loss: 3.00710425026883
Validation loss: 2.5795051477710436

Epoch: 5| Step: 4
Training loss: 2.485880557498425
Validation loss: 2.5728205878419987

Epoch: 5| Step: 5
Training loss: 2.5913979770274183
Validation loss: 2.583570142669913

Epoch: 5| Step: 6
Training loss: 2.951746704751068
Validation loss: 2.5708028120771766

Epoch: 5| Step: 7
Training loss: 2.9580542383489457
Validation loss: 2.5768254668854658

Epoch: 5| Step: 8
Training loss: 3.449904100495013
Validation loss: 2.5652449977341525

Epoch: 5| Step: 9
Training loss: 2.534547047825386
Validation loss: 2.5674263256141074

Epoch: 5| Step: 10
Training loss: 2.705014753460093
Validation loss: 2.5665972508362147

Epoch: 126| Step: 0
Training loss: 2.5296529747513703
Validation loss: 2.568601575754607

Epoch: 5| Step: 1
Training loss: 2.913763854240561
Validation loss: 2.541573859836419

Epoch: 5| Step: 2
Training loss: 2.8961546099894906
Validation loss: 2.5236420739766006

Epoch: 5| Step: 3
Training loss: 2.339738388109337
Validation loss: 2.531853176955884

Epoch: 5| Step: 4
Training loss: 3.2482268558259872
Validation loss: 2.5233119378534963

Epoch: 5| Step: 5
Training loss: 3.2501093039105196
Validation loss: 2.51711820609891

Epoch: 5| Step: 6
Training loss: 2.893386264293424
Validation loss: 2.5158290536971517

Epoch: 5| Step: 7
Training loss: 2.4453423348943724
Validation loss: 2.5153431648852678

Epoch: 5| Step: 8
Training loss: 3.175510221320418
Validation loss: 2.5187314683953126

Epoch: 5| Step: 9
Training loss: 2.959998150386748
Validation loss: 2.5159522156947594

Epoch: 5| Step: 10
Training loss: 2.704553480260261
Validation loss: 2.51796002233974

Epoch: 127| Step: 0
Training loss: 2.9749456705213477
Validation loss: 2.5232534328420635

Epoch: 5| Step: 1
Training loss: 3.248010319763852
Validation loss: 2.5213243627807658

Epoch: 5| Step: 2
Training loss: 2.9782962905922683
Validation loss: 2.532590013352798

Epoch: 5| Step: 3
Training loss: 2.630007554250101
Validation loss: 2.53951399582314

Epoch: 5| Step: 4
Training loss: 3.0997101371362348
Validation loss: 2.545560129347173

Epoch: 5| Step: 5
Training loss: 2.818000416356984
Validation loss: 2.558295248980765

Epoch: 5| Step: 6
Training loss: 2.372708268988019
Validation loss: 2.57718334831748

Epoch: 5| Step: 7
Training loss: 2.509044879182019
Validation loss: 2.6059683612084994

Epoch: 5| Step: 8
Training loss: 3.117397062289263
Validation loss: 2.6275006896903688

Epoch: 5| Step: 9
Training loss: 2.6324772380775836
Validation loss: 2.5971523879683645

Epoch: 5| Step: 10
Training loss: 3.1147387071382275
Validation loss: 2.589772059252747

Epoch: 128| Step: 0
Training loss: 3.191093513545917
Validation loss: 2.5811996318385457

Epoch: 5| Step: 1
Training loss: 2.5851031568002907
Validation loss: 2.5629547309931318

Epoch: 5| Step: 2
Training loss: 2.139177264415296
Validation loss: 2.547518132270728

Epoch: 5| Step: 3
Training loss: 3.0405837617843647
Validation loss: 2.531322645823382

Epoch: 5| Step: 4
Training loss: 3.025092566468928
Validation loss: 2.522327282112659

Epoch: 5| Step: 5
Training loss: 3.15932896068319
Validation loss: 2.5074775867525583

Epoch: 5| Step: 6
Training loss: 3.0963854113072626
Validation loss: 2.510957144944045

Epoch: 5| Step: 7
Training loss: 2.6202209201884603
Validation loss: 2.5144131013300037

Epoch: 5| Step: 8
Training loss: 3.300231526662582
Validation loss: 2.514590383405714

Epoch: 5| Step: 9
Training loss: 2.2807092940312703
Validation loss: 2.513532488890381

Epoch: 5| Step: 10
Training loss: 2.9660547168234976
Validation loss: 2.512475858052089

Epoch: 129| Step: 0
Training loss: 2.667675443419484
Validation loss: 2.511132143232142

Epoch: 5| Step: 1
Training loss: 3.2363580346667837
Validation loss: 2.521264770437866

Epoch: 5| Step: 2
Training loss: 2.612612149692422
Validation loss: 2.529928474405819

Epoch: 5| Step: 3
Training loss: 2.835149145761284
Validation loss: 2.5406452616633746

Epoch: 5| Step: 4
Training loss: 2.60774326129694
Validation loss: 2.571822694909365

Epoch: 5| Step: 5
Training loss: 2.6750788525519402
Validation loss: 2.5775192667833413

Epoch: 5| Step: 6
Training loss: 2.997317227223023
Validation loss: 2.6088252759274146

Epoch: 5| Step: 7
Training loss: 2.6923403952781735
Validation loss: 2.596162715873692

Epoch: 5| Step: 8
Training loss: 2.940636928100393
Validation loss: 2.590693179212749

Epoch: 5| Step: 9
Training loss: 3.1333486806885933
Validation loss: 2.5782119790995344

Epoch: 5| Step: 10
Training loss: 2.771492719469688
Validation loss: 2.563437963739103

Epoch: 130| Step: 0
Training loss: 2.684816218076651
Validation loss: 2.532861486541964

Epoch: 5| Step: 1
Training loss: 2.5482464239828353
Validation loss: 2.527892856629539

Epoch: 5| Step: 2
Training loss: 2.7071043502823957
Validation loss: 2.522870188625254

Epoch: 5| Step: 3
Training loss: 3.218933544666312
Validation loss: 2.525428141478554

Epoch: 5| Step: 4
Training loss: 2.5823247745592517
Validation loss: 2.5286130469081463

Epoch: 5| Step: 5
Training loss: 2.8645506330993427
Validation loss: 2.531036795374159

Epoch: 5| Step: 6
Training loss: 2.398277848984595
Validation loss: 2.532348148494581

Epoch: 5| Step: 7
Training loss: 3.0840496227858694
Validation loss: 2.5305395026784963

Epoch: 5| Step: 8
Training loss: 2.909268524155529
Validation loss: 2.543260204573043

Epoch: 5| Step: 9
Training loss: 3.1160095589702927
Validation loss: 2.5397542354824996

Epoch: 5| Step: 10
Training loss: 3.098924721073405
Validation loss: 2.526237478342961

Epoch: 131| Step: 0
Training loss: 2.7178647584201565
Validation loss: 2.523313319589245

Epoch: 5| Step: 1
Training loss: 2.8790972166246624
Validation loss: 2.514825192260846

Epoch: 5| Step: 2
Training loss: 3.263595315342302
Validation loss: 2.512557343022619

Epoch: 5| Step: 3
Training loss: 2.7636143331299854
Validation loss: 2.520012924322662

Epoch: 5| Step: 4
Training loss: 2.434001857772532
Validation loss: 2.5101242652532973

Epoch: 5| Step: 5
Training loss: 2.7837532008494836
Validation loss: 2.5113307973697965

Epoch: 5| Step: 6
Training loss: 3.111614705002484
Validation loss: 2.5181654169666055

Epoch: 5| Step: 7
Training loss: 2.5905204797880237
Validation loss: 2.5228169981675594

Epoch: 5| Step: 8
Training loss: 3.007662048540358
Validation loss: 2.5334783165149295

Epoch: 5| Step: 9
Training loss: 2.681786607518234
Validation loss: 2.5500095378915315

Epoch: 5| Step: 10
Training loss: 3.0573684362145075
Validation loss: 2.551037735718407

Epoch: 132| Step: 0
Training loss: 2.7284986731645025
Validation loss: 2.572692496315505

Epoch: 5| Step: 1
Training loss: 2.9937408638259275
Validation loss: 2.5843623715460535

Epoch: 5| Step: 2
Training loss: 2.4430947286233793
Validation loss: 2.5784702421627426

Epoch: 5| Step: 3
Training loss: 3.3387460789859187
Validation loss: 2.583191958742552

Epoch: 5| Step: 4
Training loss: 2.975026132164312
Validation loss: 2.583060722244174

Epoch: 5| Step: 5
Training loss: 2.845687373948344
Validation loss: 2.544684462508258

Epoch: 5| Step: 6
Training loss: 2.9814464320440903
Validation loss: 2.5265269696353365

Epoch: 5| Step: 7
Training loss: 2.6754044093388054
Validation loss: 2.5129478872887856

Epoch: 5| Step: 8
Training loss: 2.5214814437979185
Validation loss: 2.5214364087996786

Epoch: 5| Step: 9
Training loss: 3.12295297334793
Validation loss: 2.515698945901235

Epoch: 5| Step: 10
Training loss: 2.6225456389464292
Validation loss: 2.5128633472220665

Epoch: 133| Step: 0
Training loss: 2.66979372935092
Validation loss: 2.5137679661431305

Epoch: 5| Step: 1
Training loss: 2.8214398188996275
Validation loss: 2.519064812149615

Epoch: 5| Step: 2
Training loss: 3.0248985210453045
Validation loss: 2.525410290335151

Epoch: 5| Step: 3
Training loss: 2.498961423676141
Validation loss: 2.5169526412444845

Epoch: 5| Step: 4
Training loss: 2.5761783533253455
Validation loss: 2.5145237261834925

Epoch: 5| Step: 5
Training loss: 2.6356716309100205
Validation loss: 2.5142510688293456

Epoch: 5| Step: 6
Training loss: 2.986083175962225
Validation loss: 2.5269450236917494

Epoch: 5| Step: 7
Training loss: 2.9527697475639556
Validation loss: 2.524011841515327

Epoch: 5| Step: 8
Training loss: 3.1102641765589367
Validation loss: 2.523935851738032

Epoch: 5| Step: 9
Training loss: 3.1979310142037844
Validation loss: 2.5270047833875906

Epoch: 5| Step: 10
Training loss: 2.5930075444568903
Validation loss: 2.539396282308763

Epoch: 134| Step: 0
Training loss: 2.623173850501959
Validation loss: 2.5266547401775115

Epoch: 5| Step: 1
Training loss: 2.9349224063422867
Validation loss: 2.538469062914927

Epoch: 5| Step: 2
Training loss: 3.4819264383099418
Validation loss: 2.54542636294732

Epoch: 5| Step: 3
Training loss: 2.937560060576987
Validation loss: 2.5765509291360775

Epoch: 5| Step: 4
Training loss: 2.4047341464291727
Validation loss: 2.5785456955853485

Epoch: 5| Step: 5
Training loss: 2.723177844837806
Validation loss: 2.5753361538401536

Epoch: 5| Step: 6
Training loss: 2.683828818341376
Validation loss: 2.5830646951455787

Epoch: 5| Step: 7
Training loss: 2.79173326175646
Validation loss: 2.5810564892605408

Epoch: 5| Step: 8
Training loss: 2.971332591204443
Validation loss: 2.552135008104002

Epoch: 5| Step: 9
Training loss: 2.530078758250268
Validation loss: 2.5449363446109396

Epoch: 5| Step: 10
Training loss: 2.8912610153338045
Validation loss: 2.5181372399936546

Epoch: 135| Step: 0
Training loss: 2.3077031465422575
Validation loss: 2.511750089533787

Epoch: 5| Step: 1
Training loss: 3.149123199989314
Validation loss: 2.509098140899954

Epoch: 5| Step: 2
Training loss: 3.014527906968534
Validation loss: 2.516000689946502

Epoch: 5| Step: 3
Training loss: 2.8466912454203617
Validation loss: 2.5055860500257903

Epoch: 5| Step: 4
Training loss: 2.5239536950266483
Validation loss: 2.503336471496772

Epoch: 5| Step: 5
Training loss: 2.915507676686409
Validation loss: 2.512584673465356

Epoch: 5| Step: 6
Training loss: 2.517782956144494
Validation loss: 2.5148221656275633

Epoch: 5| Step: 7
Training loss: 3.368320637307329
Validation loss: 2.5430705538729583

Epoch: 5| Step: 8
Training loss: 2.710373173882006
Validation loss: 2.564548109137263

Epoch: 5| Step: 9
Training loss: 2.8643372216127436
Validation loss: 2.599235899778613

Epoch: 5| Step: 10
Training loss: 2.879402604398234
Validation loss: 2.5876302190067886

Epoch: 136| Step: 0
Training loss: 2.4399958816868783
Validation loss: 2.5682955596667942

Epoch: 5| Step: 1
Training loss: 3.190497391527954
Validation loss: 2.543396358352861

Epoch: 5| Step: 2
Training loss: 2.735317656290883
Validation loss: 2.537334073065693

Epoch: 5| Step: 3
Training loss: 2.1194793571084243
Validation loss: 2.552843840351333

Epoch: 5| Step: 4
Training loss: 2.9919315557352077
Validation loss: 2.543465323017878

Epoch: 5| Step: 5
Training loss: 3.2449994865146694
Validation loss: 2.5313075707382082

Epoch: 5| Step: 6
Training loss: 2.8626133658936155
Validation loss: 2.5271829847913883

Epoch: 5| Step: 7
Training loss: 2.644271048925958
Validation loss: 2.5302048529163703

Epoch: 5| Step: 8
Training loss: 2.747192076348468
Validation loss: 2.527063039234176

Epoch: 5| Step: 9
Training loss: 3.0117719474873716
Validation loss: 2.547689310077527

Epoch: 5| Step: 10
Training loss: 2.766772360870153
Validation loss: 2.5506388718685193

Epoch: 137| Step: 0
Training loss: 2.6070646920029765
Validation loss: 2.499525726615459

Epoch: 5| Step: 1
Training loss: 2.8167506839327814
Validation loss: 2.496808685453367

Epoch: 5| Step: 2
Training loss: 2.755578538412553
Validation loss: 2.496415162436881

Epoch: 5| Step: 3
Training loss: 2.8782166440540684
Validation loss: 2.508870505763797

Epoch: 5| Step: 4
Training loss: 2.69494759121187
Validation loss: 2.5057845944490458

Epoch: 5| Step: 5
Training loss: 2.761142956656447
Validation loss: 2.511127011110888

Epoch: 5| Step: 6
Training loss: 2.8022477528337353
Validation loss: 2.5085894488003726

Epoch: 5| Step: 7
Training loss: 3.3352693339745993
Validation loss: 2.5231045734115427

Epoch: 5| Step: 8
Training loss: 2.793462962994598
Validation loss: 2.5432829623921465

Epoch: 5| Step: 9
Training loss: 2.5575970521114617
Validation loss: 2.5888704365270985

Epoch: 5| Step: 10
Training loss: 3.3117991731727536
Validation loss: 2.623461562079572

Epoch: 138| Step: 0
Training loss: 2.8473322177718945
Validation loss: 2.63846630914787

Epoch: 5| Step: 1
Training loss: 3.13251020157379
Validation loss: 2.6125437189655725

Epoch: 5| Step: 2
Training loss: 2.7438964735136855
Validation loss: 2.5796385666665365

Epoch: 5| Step: 3
Training loss: 2.4273064528522865
Validation loss: 2.5482986631375426

Epoch: 5| Step: 4
Training loss: 2.639107262348652
Validation loss: 2.5349853322503875

Epoch: 5| Step: 5
Training loss: 3.0799892608653523
Validation loss: 2.5295475955122684

Epoch: 5| Step: 6
Training loss: 2.8209919203595546
Validation loss: 2.5373250105555614

Epoch: 5| Step: 7
Training loss: 2.678543958977216
Validation loss: 2.5503842800386267

Epoch: 5| Step: 8
Training loss: 2.799000278883113
Validation loss: 2.5386246781282575

Epoch: 5| Step: 9
Training loss: 2.5655648116417513
Validation loss: 2.5245070841477504

Epoch: 5| Step: 10
Training loss: 3.235625094553206
Validation loss: 2.505554941370091

Epoch: 139| Step: 0
Training loss: 2.5755041499251634
Validation loss: 2.522802695368642

Epoch: 5| Step: 1
Training loss: 2.902920199788539
Validation loss: 2.524194911883163

Epoch: 5| Step: 2
Training loss: 2.342819843095006
Validation loss: 2.538579285788795

Epoch: 5| Step: 3
Training loss: 2.9221744485905705
Validation loss: 2.5639041292092544

Epoch: 5| Step: 4
Training loss: 2.8350922977554
Validation loss: 2.5948650238209905

Epoch: 5| Step: 5
Training loss: 2.5444178986124784
Validation loss: 2.6182065142853053

Epoch: 5| Step: 6
Training loss: 3.042863915024608
Validation loss: 2.7231881373092115

Epoch: 5| Step: 7
Training loss: 2.9589070225037934
Validation loss: 2.6921971799658717

Epoch: 5| Step: 8
Training loss: 2.910112500981978
Validation loss: 2.650591324747054

Epoch: 5| Step: 9
Training loss: 2.9034571200003394
Validation loss: 2.548693578067893

Epoch: 5| Step: 10
Training loss: 3.2575540051261584
Validation loss: 2.519354667685627

Epoch: 140| Step: 0
Training loss: 2.5674957331814174
Validation loss: 2.5089837792588594

Epoch: 5| Step: 1
Training loss: 3.0355838587334927
Validation loss: 2.5275638629841892

Epoch: 5| Step: 2
Training loss: 3.2249018572874033
Validation loss: 2.5500983053388686

Epoch: 5| Step: 3
Training loss: 3.259333486466363
Validation loss: 2.5785041488025526

Epoch: 5| Step: 4
Training loss: 3.105381687311426
Validation loss: 2.614821140123135

Epoch: 5| Step: 5
Training loss: 2.701167196957943
Validation loss: 2.651642721066778

Epoch: 5| Step: 6
Training loss: 2.677355850143406
Validation loss: 2.620953812290026

Epoch: 5| Step: 7
Training loss: 3.095185842527113
Validation loss: 2.5758099366284415

Epoch: 5| Step: 8
Training loss: 2.8584404757542488
Validation loss: 2.5616698552387747

Epoch: 5| Step: 9
Training loss: 2.9582762018695705
Validation loss: 2.550198177464049

Epoch: 5| Step: 10
Training loss: 2.6164490526262907
Validation loss: 2.560414407718209

Epoch: 141| Step: 0
Training loss: 3.0245006180603538
Validation loss: 2.6215086365097644

Epoch: 5| Step: 1
Training loss: 2.8049270400080046
Validation loss: 2.656497958708494

Epoch: 5| Step: 2
Training loss: 2.486997743440654
Validation loss: 2.7054624620974868

Epoch: 5| Step: 3
Training loss: 3.0537857324646547
Validation loss: 2.8187836160654585

Epoch: 5| Step: 4
Training loss: 3.844601792647811
Validation loss: 2.985998756417114

Epoch: 5| Step: 5
Training loss: 3.094018019038711
Validation loss: 2.716317900976312

Epoch: 5| Step: 6
Training loss: 2.7728255335513197
Validation loss: 2.553006518309556

Epoch: 5| Step: 7
Training loss: 2.4051587491371595
Validation loss: 2.501045657484675

Epoch: 5| Step: 8
Training loss: 2.8173398231122286
Validation loss: 2.5087091637436996

Epoch: 5| Step: 9
Training loss: 3.23231772632443
Validation loss: 2.519712351593838

Epoch: 5| Step: 10
Training loss: 2.924537954761458
Validation loss: 2.5145824394003933

Epoch: 142| Step: 0
Training loss: 3.0197346410315746
Validation loss: 2.5116665584231224

Epoch: 5| Step: 1
Training loss: 3.4330729327167724
Validation loss: 2.509393243339354

Epoch: 5| Step: 2
Training loss: 3.08600100681291
Validation loss: 2.5034383775943967

Epoch: 5| Step: 3
Training loss: 2.5198873105662645
Validation loss: 2.4999979080683663

Epoch: 5| Step: 4
Training loss: 3.064874779288662
Validation loss: 2.5003564539457646

Epoch: 5| Step: 5
Training loss: 2.954008747250591
Validation loss: 2.50693448929915

Epoch: 5| Step: 6
Training loss: 2.911019789822089
Validation loss: 2.507507169670709

Epoch: 5| Step: 7
Training loss: 2.6307878718185487
Validation loss: 2.5317991737832557

Epoch: 5| Step: 8
Training loss: 2.2439227151940675
Validation loss: 2.5787015914634233

Epoch: 5| Step: 9
Training loss: 2.1512949304138917
Validation loss: 2.6173173475800326

Epoch: 5| Step: 10
Training loss: 3.302249234401231
Validation loss: 2.7111515013775174

Epoch: 143| Step: 0
Training loss: 2.870684494641206
Validation loss: 2.68627891644869

Epoch: 5| Step: 1
Training loss: 2.8854325129949476
Validation loss: 2.6051984420677616

Epoch: 5| Step: 2
Training loss: 2.878046991904382
Validation loss: 2.553170712136177

Epoch: 5| Step: 3
Training loss: 2.4814952738722855
Validation loss: 2.5206149106716897

Epoch: 5| Step: 4
Training loss: 3.139405122764711
Validation loss: 2.498642981788783

Epoch: 5| Step: 5
Training loss: 2.9310709624119196
Validation loss: 2.4859065363547317

Epoch: 5| Step: 6
Training loss: 2.386637834591461
Validation loss: 2.499304809100032

Epoch: 5| Step: 7
Training loss: 3.138481205559295
Validation loss: 2.4960536203485777

Epoch: 5| Step: 8
Training loss: 2.7896664603973917
Validation loss: 2.4994396484130497

Epoch: 5| Step: 9
Training loss: 2.6906916274484143
Validation loss: 2.496487350380327

Epoch: 5| Step: 10
Training loss: 3.2939668819242653
Validation loss: 2.497502878492437

Epoch: 144| Step: 0
Training loss: 2.5702563804366942
Validation loss: 2.492946134210746

Epoch: 5| Step: 1
Training loss: 3.3372131338670132
Validation loss: 2.4919946465851597

Epoch: 5| Step: 2
Training loss: 2.7540580978193887
Validation loss: 2.4930423516811153

Epoch: 5| Step: 3
Training loss: 2.1160626678561374
Validation loss: 2.497477704931942

Epoch: 5| Step: 4
Training loss: 3.110433733706569
Validation loss: 2.513543020210762

Epoch: 5| Step: 5
Training loss: 2.78466176141525
Validation loss: 2.542656391269945

Epoch: 5| Step: 6
Training loss: 2.842945362318784
Validation loss: 2.5916089916218366

Epoch: 5| Step: 7
Training loss: 3.0860291286337334
Validation loss: 2.6643085846630776

Epoch: 5| Step: 8
Training loss: 2.829577499770853
Validation loss: 2.6599500294698806

Epoch: 5| Step: 9
Training loss: 2.9797415189842384
Validation loss: 2.603361293829072

Epoch: 5| Step: 10
Training loss: 2.6340204292148144
Validation loss: 2.572203558063687

Epoch: 145| Step: 0
Training loss: 2.9403306025214277
Validation loss: 2.5547639789506498

Epoch: 5| Step: 1
Training loss: 2.833721713954324
Validation loss: 2.5191618251472803

Epoch: 5| Step: 2
Training loss: 3.003749411746002
Validation loss: 2.5182604631849785

Epoch: 5| Step: 3
Training loss: 3.3309158300726858
Validation loss: 2.5120596067751513

Epoch: 5| Step: 4
Training loss: 2.6828880659335406
Validation loss: 2.5032913179586966

Epoch: 5| Step: 5
Training loss: 2.6896918474128793
Validation loss: 2.514933507451291

Epoch: 5| Step: 6
Training loss: 2.989594852722163
Validation loss: 2.507505949963719

Epoch: 5| Step: 7
Training loss: 2.4744204333885245
Validation loss: 2.5150621034474034

Epoch: 5| Step: 8
Training loss: 2.5351455288558933
Validation loss: 2.5181986187016085

Epoch: 5| Step: 9
Training loss: 2.561066761676406
Validation loss: 2.527180666826455

Epoch: 5| Step: 10
Training loss: 2.7653340332075733
Validation loss: 2.524082857294661

Epoch: 146| Step: 0
Training loss: 2.2142789682382227
Validation loss: 2.5206403174491676

Epoch: 5| Step: 1
Training loss: 2.3606772965467764
Validation loss: 2.5130779355295765

Epoch: 5| Step: 2
Training loss: 2.7731305019624135
Validation loss: 2.51158697678623

Epoch: 5| Step: 3
Training loss: 2.6290670405241774
Validation loss: 2.507481462661236

Epoch: 5| Step: 4
Training loss: 2.9142969768370657
Validation loss: 2.502159685021509

Epoch: 5| Step: 5
Training loss: 3.1654108635947673
Validation loss: 2.5025418598092837

Epoch: 5| Step: 6
Training loss: 3.125201562103151
Validation loss: 2.50716010791546

Epoch: 5| Step: 7
Training loss: 3.0093996294544767
Validation loss: 2.5312201243584225

Epoch: 5| Step: 8
Training loss: 2.9855449839716632
Validation loss: 2.557810971484644

Epoch: 5| Step: 9
Training loss: 2.85755020030757
Validation loss: 2.5814907722157985

Epoch: 5| Step: 10
Training loss: 2.619234019412872
Validation loss: 2.5997648903504507

Epoch: 147| Step: 0
Training loss: 2.1853140672055953
Validation loss: 2.6013351893453556

Epoch: 5| Step: 1
Training loss: 2.557570297900887
Validation loss: 2.611086429498786

Epoch: 5| Step: 2
Training loss: 2.8993602836352177
Validation loss: 2.588583377516851

Epoch: 5| Step: 3
Training loss: 2.6599818325139366
Validation loss: 2.577783402241547

Epoch: 5| Step: 4
Training loss: 2.6855411931758075
Validation loss: 2.587137137657602

Epoch: 5| Step: 5
Training loss: 3.2873957164164884
Validation loss: 2.568913309560627

Epoch: 5| Step: 6
Training loss: 2.8796791478086115
Validation loss: 2.551084145449333

Epoch: 5| Step: 7
Training loss: 2.951936028322365
Validation loss: 2.5236093949012215

Epoch: 5| Step: 8
Training loss: 2.5895074364201287
Validation loss: 2.5089998590293763

Epoch: 5| Step: 9
Training loss: 2.9859648459243773
Validation loss: 2.5016590827561918

Epoch: 5| Step: 10
Training loss: 3.086998556707037
Validation loss: 2.50647222052201

Epoch: 148| Step: 0
Training loss: 2.677300015201682
Validation loss: 2.5082569297781414

Epoch: 5| Step: 1
Training loss: 2.838264960471422
Validation loss: 2.505113658011908

Epoch: 5| Step: 2
Training loss: 3.025695745992061
Validation loss: 2.527975077308188

Epoch: 5| Step: 3
Training loss: 2.1633486896003173
Validation loss: 2.5467974657710455

Epoch: 5| Step: 4
Training loss: 3.0651613466195458
Validation loss: 2.5748528411897635

Epoch: 5| Step: 5
Training loss: 2.463833028864236
Validation loss: 2.5607712679734007

Epoch: 5| Step: 6
Training loss: 2.8579041079964402
Validation loss: 2.5664483412470975

Epoch: 5| Step: 7
Training loss: 2.868639170514966
Validation loss: 2.564034720460803

Epoch: 5| Step: 8
Training loss: 2.9228004988961627
Validation loss: 2.5732429347014127

Epoch: 5| Step: 9
Training loss: 3.2303614385233326
Validation loss: 2.5415582262209484

Epoch: 5| Step: 10
Training loss: 3.110809148787605
Validation loss: 2.5145885360596933

Epoch: 149| Step: 0
Training loss: 2.556125247961093
Validation loss: 2.5136553406706437

Epoch: 5| Step: 1
Training loss: 3.3560089990906667
Validation loss: 2.509608154923798

Epoch: 5| Step: 2
Training loss: 3.0420100571304998
Validation loss: 2.509092333845947

Epoch: 5| Step: 3
Training loss: 3.0058360554346404
Validation loss: 2.5071539093449364

Epoch: 5| Step: 4
Training loss: 2.9231884294160837
Validation loss: 2.5065484584717677

Epoch: 5| Step: 5
Training loss: 2.2629448132025
Validation loss: 2.521873597795557

Epoch: 5| Step: 6
Training loss: 2.7462032290865794
Validation loss: 2.5120155050593302

Epoch: 5| Step: 7
Training loss: 2.751063314687555
Validation loss: 2.511688465462819

Epoch: 5| Step: 8
Training loss: 2.5513193868484
Validation loss: 2.5334584304700525

Epoch: 5| Step: 9
Training loss: 2.71761649168983
Validation loss: 2.5432012280430336

Epoch: 5| Step: 10
Training loss: 2.641040746701672
Validation loss: 2.560999593360059

Epoch: 150| Step: 0
Training loss: 3.342067259435297
Validation loss: 2.563860282340918

Epoch: 5| Step: 1
Training loss: 3.0084368961785746
Validation loss: 2.5644567448502125

Epoch: 5| Step: 2
Training loss: 2.730467178278786
Validation loss: 2.5441444184113

Epoch: 5| Step: 3
Training loss: 2.374212234754243
Validation loss: 2.522494886090617

Epoch: 5| Step: 4
Training loss: 3.1761216172443483
Validation loss: 2.5133603112768372

Epoch: 5| Step: 5
Training loss: 2.6952618138067033
Validation loss: 2.5040312075413333

Epoch: 5| Step: 6
Training loss: 2.471506053141552
Validation loss: 2.499648405803202

Epoch: 5| Step: 7
Training loss: 2.677040238287136
Validation loss: 2.4861188451398

Epoch: 5| Step: 8
Training loss: 2.775915451949953
Validation loss: 2.498083663000298

Epoch: 5| Step: 9
Training loss: 2.7982669541932434
Validation loss: 2.5129967612434965

Epoch: 5| Step: 10
Training loss: 2.6029411992903126
Validation loss: 2.5156612657314916

Epoch: 151| Step: 0
Training loss: 3.1373778300417534
Validation loss: 2.535196659669804

Epoch: 5| Step: 1
Training loss: 2.9905223545807296
Validation loss: 2.5444008265455516

Epoch: 5| Step: 2
Training loss: 3.0468508988429797
Validation loss: 2.552513259794278

Epoch: 5| Step: 3
Training loss: 2.3055341814064048
Validation loss: 2.5509622253963613

Epoch: 5| Step: 4
Training loss: 2.832476729510372
Validation loss: 2.5375233760920675

Epoch: 5| Step: 5
Training loss: 2.6037190980950053
Validation loss: 2.5191577646957932

Epoch: 5| Step: 6
Training loss: 3.4097916975192475
Validation loss: 2.5220304052189713

Epoch: 5| Step: 7
Training loss: 2.5907759563791584
Validation loss: 2.5231172274651037

Epoch: 5| Step: 8
Training loss: 3.0989534949684305
Validation loss: 2.525810512415096

Epoch: 5| Step: 9
Training loss: 2.3533173663576568
Validation loss: 2.4966412952675623

Epoch: 5| Step: 10
Training loss: 1.9610271053434845
Validation loss: 2.5053323411406754

Epoch: 152| Step: 0
Training loss: 2.876154957858455
Validation loss: 2.499327371207978

Epoch: 5| Step: 1
Training loss: 2.4647911295888747
Validation loss: 2.5150229441165517

Epoch: 5| Step: 2
Training loss: 3.0452828184181566
Validation loss: 2.540606330159507

Epoch: 5| Step: 3
Training loss: 2.8454447297107825
Validation loss: 2.5592552418975862

Epoch: 5| Step: 4
Training loss: 2.441556733643487
Validation loss: 2.5524500064654987

Epoch: 5| Step: 5
Training loss: 2.3693937086263803
Validation loss: 2.5528127462095114

Epoch: 5| Step: 6
Training loss: 2.8404291905899313
Validation loss: 2.541894056966845

Epoch: 5| Step: 7
Training loss: 2.6416439821570954
Validation loss: 2.5249906236979482

Epoch: 5| Step: 8
Training loss: 3.4126009748003074
Validation loss: 2.5232795968930093

Epoch: 5| Step: 9
Training loss: 2.4107837323878107
Validation loss: 2.5298050144204045

Epoch: 5| Step: 10
Training loss: 3.1400812541872143
Validation loss: 2.519823406120835

Epoch: 153| Step: 0
Training loss: 2.753233828867148
Validation loss: 2.523674176649522

Epoch: 5| Step: 1
Training loss: 3.183691404752251
Validation loss: 2.541231860230908

Epoch: 5| Step: 2
Training loss: 2.4847674749565702
Validation loss: 2.535840401255677

Epoch: 5| Step: 3
Training loss: 2.438202389973034
Validation loss: 2.548585893964599

Epoch: 5| Step: 4
Training loss: 3.1917437558206054
Validation loss: 2.595546133625203

Epoch: 5| Step: 5
Training loss: 3.0205935328222075
Validation loss: 2.5843611082568247

Epoch: 5| Step: 6
Training loss: 2.9534320974376245
Validation loss: 2.564208979751025

Epoch: 5| Step: 7
Training loss: 2.139410412222552
Validation loss: 2.569379117209698

Epoch: 5| Step: 8
Training loss: 2.8405052369641397
Validation loss: 2.553653421077588

Epoch: 5| Step: 9
Training loss: 3.0286939403401147
Validation loss: 2.542415321701634

Epoch: 5| Step: 10
Training loss: 2.282457841899567
Validation loss: 2.522383610227666

Epoch: 154| Step: 0
Training loss: 2.8736829643511568
Validation loss: 2.5106998056375773

Epoch: 5| Step: 1
Training loss: 3.448007926232594
Validation loss: 2.517298834604063

Epoch: 5| Step: 2
Training loss: 2.5948914923059965
Validation loss: 2.4987990807142935

Epoch: 5| Step: 3
Training loss: 2.7567715936300927
Validation loss: 2.5074771450764857

Epoch: 5| Step: 4
Training loss: 3.057629039720721
Validation loss: 2.502014270584225

Epoch: 5| Step: 5
Training loss: 2.774684915611214
Validation loss: 2.501542838668709

Epoch: 5| Step: 6
Training loss: 2.940144910549774
Validation loss: 2.499057901953434

Epoch: 5| Step: 7
Training loss: 2.4066340152431143
Validation loss: 2.489040874981576

Epoch: 5| Step: 8
Training loss: 2.514524420485564
Validation loss: 2.4898104689980096

Epoch: 5| Step: 9
Training loss: 2.65480540767577
Validation loss: 2.490769345308078

Epoch: 5| Step: 10
Training loss: 2.268028300019632
Validation loss: 2.5000981537203653

Epoch: 155| Step: 0
Training loss: 3.0464295673001383
Validation loss: 2.517196388687494

Epoch: 5| Step: 1
Training loss: 2.822863157171061
Validation loss: 2.546667065723742

Epoch: 5| Step: 2
Training loss: 2.7206780623509133
Validation loss: 2.5736693879208565

Epoch: 5| Step: 3
Training loss: 2.978881093100813
Validation loss: 2.6163988923860417

Epoch: 5| Step: 4
Training loss: 2.6431553020711247
Validation loss: 2.6432153566950305

Epoch: 5| Step: 5
Training loss: 2.843569907050674
Validation loss: 2.575703338421397

Epoch: 5| Step: 6
Training loss: 2.7800196808866198
Validation loss: 2.5624256758537167

Epoch: 5| Step: 7
Training loss: 2.479565553605156
Validation loss: 2.528477158635195

Epoch: 5| Step: 8
Training loss: 2.8983358277947557
Validation loss: 2.50705415340234

Epoch: 5| Step: 9
Training loss: 2.6937136123217553
Validation loss: 2.5071985321665817

Epoch: 5| Step: 10
Training loss: 2.515187764524591
Validation loss: 2.503572231403864

Epoch: 156| Step: 0
Training loss: 2.926574355069338
Validation loss: 2.4993272737634142

Epoch: 5| Step: 1
Training loss: 2.8196232764577926
Validation loss: 2.4938739593551764

Epoch: 5| Step: 2
Training loss: 2.8348687630339238
Validation loss: 2.5047044799729434

Epoch: 5| Step: 3
Training loss: 2.8498612018717826
Validation loss: 2.506835754443868

Epoch: 5| Step: 4
Training loss: 2.4144680830599086
Validation loss: 2.5002496697236034

Epoch: 5| Step: 5
Training loss: 2.661813183523726
Validation loss: 2.504708895478262

Epoch: 5| Step: 6
Training loss: 2.4343242008261314
Validation loss: 2.5078793856901913

Epoch: 5| Step: 7
Training loss: 2.629337632494282
Validation loss: 2.5299916696514675

Epoch: 5| Step: 8
Training loss: 3.1060495661153777
Validation loss: 2.529019149918198

Epoch: 5| Step: 9
Training loss: 2.208377069963843
Validation loss: 2.538464342562946

Epoch: 5| Step: 10
Training loss: 3.4555066211202603
Validation loss: 2.5495194904300504

Epoch: 157| Step: 0
Training loss: 2.5647458725053927
Validation loss: 2.5536516953540795

Epoch: 5| Step: 1
Training loss: 2.4793726624462664
Validation loss: 2.5695049524504108

Epoch: 5| Step: 2
Training loss: 2.5803824049674264
Validation loss: 2.5549276695065584

Epoch: 5| Step: 3
Training loss: 2.884921328630591
Validation loss: 2.5793354204717347

Epoch: 5| Step: 4
Training loss: 2.625470255555217
Validation loss: 2.592800529487834

Epoch: 5| Step: 5
Training loss: 3.318210933030259
Validation loss: 2.5591458945146703

Epoch: 5| Step: 6
Training loss: 2.473839836628976
Validation loss: 2.5449734571146863

Epoch: 5| Step: 7
Training loss: 2.9515807943347645
Validation loss: 2.5260978818490165

Epoch: 5| Step: 8
Training loss: 2.7721866849593426
Validation loss: 2.4897969372624797

Epoch: 5| Step: 9
Training loss: 2.845840524093755
Validation loss: 2.4838231302464306

Epoch: 5| Step: 10
Training loss: 2.809363332688118
Validation loss: 2.466339381981464

Epoch: 158| Step: 0
Training loss: 2.9316936490666174
Validation loss: 2.473868504670683

Epoch: 5| Step: 1
Training loss: 3.1308286097794427
Validation loss: 2.4735510910068466

Epoch: 5| Step: 2
Training loss: 3.064152174614429
Validation loss: 2.470839178627663

Epoch: 5| Step: 3
Training loss: 2.3456007707230264
Validation loss: 2.474991879243228

Epoch: 5| Step: 4
Training loss: 2.595448868284802
Validation loss: 2.4656471295429863

Epoch: 5| Step: 5
Training loss: 3.197266967251169
Validation loss: 2.469078585200261

Epoch: 5| Step: 6
Training loss: 2.6791730114360885
Validation loss: 2.484491757382345

Epoch: 5| Step: 7
Training loss: 2.679184046125823
Validation loss: 2.491018868852586

Epoch: 5| Step: 8
Training loss: 2.552206345272913
Validation loss: 2.5375577540897023

Epoch: 5| Step: 9
Training loss: 2.5624868811294808
Validation loss: 2.562407764302509

Epoch: 5| Step: 10
Training loss: 2.5412913707212126
Validation loss: 2.570072317822072

Epoch: 159| Step: 0
Training loss: 2.329598798796585
Validation loss: 2.6123922616369337

Epoch: 5| Step: 1
Training loss: 2.4292530517747393
Validation loss: 2.5608121443986622

Epoch: 5| Step: 2
Training loss: 2.8430104394399693
Validation loss: 2.5689938286913745

Epoch: 5| Step: 3
Training loss: 2.4936848031988883
Validation loss: 2.5633188375536835

Epoch: 5| Step: 4
Training loss: 2.9349934049204047
Validation loss: 2.527944110812992

Epoch: 5| Step: 5
Training loss: 3.256014906584338
Validation loss: 2.5153131604437844

Epoch: 5| Step: 6
Training loss: 2.716593446115383
Validation loss: 2.5126920180293184

Epoch: 5| Step: 7
Training loss: 2.667898152033091
Validation loss: 2.501534682082794

Epoch: 5| Step: 8
Training loss: 2.6921996786646876
Validation loss: 2.5033301810190163

Epoch: 5| Step: 9
Training loss: 2.9914892592112166
Validation loss: 2.4975378833210744

Epoch: 5| Step: 10
Training loss: 2.9093730922409997
Validation loss: 2.506061076157687

Epoch: 160| Step: 0
Training loss: 2.557652983354888
Validation loss: 2.501446723722234

Epoch: 5| Step: 1
Training loss: 3.1212552330819574
Validation loss: 2.5143889086634887

Epoch: 5| Step: 2
Training loss: 3.11304583072226
Validation loss: 2.5161286852791407

Epoch: 5| Step: 3
Training loss: 2.7392692144092026
Validation loss: 2.511766158739567

Epoch: 5| Step: 4
Training loss: 2.748232013075474
Validation loss: 2.506859925918933

Epoch: 5| Step: 5
Training loss: 2.4743097209678258
Validation loss: 2.5068971654469117

Epoch: 5| Step: 6
Training loss: 2.1915291872406883
Validation loss: 2.5130113697888645

Epoch: 5| Step: 7
Training loss: 2.36365146732173
Validation loss: 2.5193760784596213

Epoch: 5| Step: 8
Training loss: 2.912185678179593
Validation loss: 2.5670098727583395

Epoch: 5| Step: 9
Training loss: 3.1540811470831334
Validation loss: 2.6039350991606662

Epoch: 5| Step: 10
Training loss: 2.977218595670504
Validation loss: 2.6300683204295345

Epoch: 161| Step: 0
Training loss: 3.2013300634915853
Validation loss: 2.6551232464153065

Epoch: 5| Step: 1
Training loss: 2.4580297336502643
Validation loss: 2.664014683598267

Epoch: 5| Step: 2
Training loss: 3.3562077695438033
Validation loss: 2.6681855520107414

Epoch: 5| Step: 3
Training loss: 3.060197392747822
Validation loss: 2.6619163700041533

Epoch: 5| Step: 4
Training loss: 2.517468174086386
Validation loss: 2.571585321515625

Epoch: 5| Step: 5
Training loss: 2.862098938943885
Validation loss: 2.5385195481159735

Epoch: 5| Step: 6
Training loss: 2.2781571625374
Validation loss: 2.506771873173457

Epoch: 5| Step: 7
Training loss: 2.8598734103377264
Validation loss: 2.492930989539226

Epoch: 5| Step: 8
Training loss: 2.5193946978802817
Validation loss: 2.4826540541597413

Epoch: 5| Step: 9
Training loss: 2.3120952973772626
Validation loss: 2.4730741057746637

Epoch: 5| Step: 10
Training loss: 2.752465270167194
Validation loss: 2.4785503849596306

Epoch: 162| Step: 0
Training loss: 2.499147460531287
Validation loss: 2.483917947577113

Epoch: 5| Step: 1
Training loss: 2.7159809612342847
Validation loss: 2.483190127927239

Epoch: 5| Step: 2
Training loss: 3.2605592414143407
Validation loss: 2.4840339782081466

Epoch: 5| Step: 3
Training loss: 2.856394230312476
Validation loss: 2.498452542380847

Epoch: 5| Step: 4
Training loss: 2.8528696904846935
Validation loss: 2.5206314557960523

Epoch: 5| Step: 5
Training loss: 2.7655696540079107
Validation loss: 2.5420688618232803

Epoch: 5| Step: 6
Training loss: 2.7593672479021647
Validation loss: 2.5732997283476626

Epoch: 5| Step: 7
Training loss: 2.7574517119425805
Validation loss: 2.581398023330687

Epoch: 5| Step: 8
Training loss: 2.436535766814998
Validation loss: 2.5740189904667274

Epoch: 5| Step: 9
Training loss: 3.122063745056824
Validation loss: 2.5577650446365907

Epoch: 5| Step: 10
Training loss: 2.0854531629521063
Validation loss: 2.5366624518105003

Epoch: 163| Step: 0
Training loss: 2.7512115930617482
Validation loss: 2.5242838162783414

Epoch: 5| Step: 1
Training loss: 2.6052356712943685
Validation loss: 2.5139187316794134

Epoch: 5| Step: 2
Training loss: 2.5960045633026128
Validation loss: 2.491260258474892

Epoch: 5| Step: 3
Training loss: 3.2120458912783643
Validation loss: 2.496206224001313

Epoch: 5| Step: 4
Training loss: 2.8657580562139873
Validation loss: 2.4925355192821876

Epoch: 5| Step: 5
Training loss: 2.6620893134790675
Validation loss: 2.489604880006769

Epoch: 5| Step: 6
Training loss: 2.5782246888278655
Validation loss: 2.510141280900942

Epoch: 5| Step: 7
Training loss: 2.6800328691089583
Validation loss: 2.523086894818212

Epoch: 5| Step: 8
Training loss: 2.1203816660518937
Validation loss: 2.55044175157458

Epoch: 5| Step: 9
Training loss: 2.5780241975440337
Validation loss: 2.593043154293266

Epoch: 5| Step: 10
Training loss: 3.4436288469607343
Validation loss: 2.6161766817239154

Epoch: 164| Step: 0
Training loss: 2.7531472316714654
Validation loss: 2.6251719536155704

Epoch: 5| Step: 1
Training loss: 3.020646258294576
Validation loss: 2.638770951372148

Epoch: 5| Step: 2
Training loss: 2.783749089816852
Validation loss: 2.6678735177363486

Epoch: 5| Step: 3
Training loss: 2.792415708193485
Validation loss: 2.5934611521782744

Epoch: 5| Step: 4
Training loss: 2.656958362148285
Validation loss: 2.5538900389538726

Epoch: 5| Step: 5
Training loss: 2.8522963324277786
Validation loss: 2.4950086470283597

Epoch: 5| Step: 6
Training loss: 2.863857736879568
Validation loss: 2.4800196495511573

Epoch: 5| Step: 7
Training loss: 2.594396763330982
Validation loss: 2.472542215338996

Epoch: 5| Step: 8
Training loss: 2.750511295297491
Validation loss: 2.474839513006031

Epoch: 5| Step: 9
Training loss: 2.5121027770064766
Validation loss: 2.4795982817210285

Epoch: 5| Step: 10
Training loss: 2.9191341498594214
Validation loss: 2.477850250571184

Epoch: 165| Step: 0
Training loss: 2.1176002916457635
Validation loss: 2.476903306378061

Epoch: 5| Step: 1
Training loss: 2.8349846534380907
Validation loss: 2.4951564784039086

Epoch: 5| Step: 2
Training loss: 2.5205430948772816
Validation loss: 2.5391405450454956

Epoch: 5| Step: 3
Training loss: 2.5484846212496737
Validation loss: 2.6082191709903184

Epoch: 5| Step: 4
Training loss: 3.113229327564595
Validation loss: 2.702576045147938

Epoch: 5| Step: 5
Training loss: 2.8583076861447783
Validation loss: 2.740569257118452

Epoch: 5| Step: 6
Training loss: 3.1241966740905474
Validation loss: 2.7305545416966095

Epoch: 5| Step: 7
Training loss: 2.285230534316112
Validation loss: 2.7181829724717983

Epoch: 5| Step: 8
Training loss: 2.8587824306474965
Validation loss: 2.697340215998121

Epoch: 5| Step: 9
Training loss: 3.182988283587005
Validation loss: 2.617951938177363

Epoch: 5| Step: 10
Training loss: 3.1646616427334346
Validation loss: 2.528510700483373

Epoch: 166| Step: 0
Training loss: 2.806394604735805
Validation loss: 2.4938063140702704

Epoch: 5| Step: 1
Training loss: 2.4715771482397484
Validation loss: 2.4801144334664698

Epoch: 5| Step: 2
Training loss: 3.0100349439449254
Validation loss: 2.483607891885975

Epoch: 5| Step: 3
Training loss: 2.600294382595876
Validation loss: 2.506865472767115

Epoch: 5| Step: 4
Training loss: 3.1636914447744835
Validation loss: 2.5192555841382984

Epoch: 5| Step: 5
Training loss: 2.8482856211973253
Validation loss: 2.5220761731660355

Epoch: 5| Step: 6
Training loss: 2.6819829868115552
Validation loss: 2.5043619331970515

Epoch: 5| Step: 7
Training loss: 2.681382602355972
Validation loss: 2.496004292407695

Epoch: 5| Step: 8
Training loss: 2.797819777170017
Validation loss: 2.4777655885187113

Epoch: 5| Step: 9
Training loss: 2.84654266394064
Validation loss: 2.4784612002632813

Epoch: 5| Step: 10
Training loss: 3.074969848236876
Validation loss: 2.482143409814183

Epoch: 167| Step: 0
Training loss: 2.726160057994431
Validation loss: 2.505139360153555

Epoch: 5| Step: 1
Training loss: 2.531125854461901
Validation loss: 2.564606052971564

Epoch: 5| Step: 2
Training loss: 3.180081279843509
Validation loss: 2.632544477736173

Epoch: 5| Step: 3
Training loss: 2.6927453240830435
Validation loss: 2.7089605893970985

Epoch: 5| Step: 4
Training loss: 2.728131648838816
Validation loss: 2.765840156222297

Epoch: 5| Step: 5
Training loss: 2.810927311622769
Validation loss: 2.8466843965882247

Epoch: 5| Step: 6
Training loss: 2.433336369847881
Validation loss: 2.908465134583909

Epoch: 5| Step: 7
Training loss: 3.2019587184572806
Validation loss: 2.981809783579408

Epoch: 5| Step: 8
Training loss: 3.4676901082990135
Validation loss: 2.96905573861112

Epoch: 5| Step: 9
Training loss: 3.2862650012881502
Validation loss: 2.871699030296958

Epoch: 5| Step: 10
Training loss: 2.1414933496942425
Validation loss: 2.746431408747023

Epoch: 168| Step: 0
Training loss: 2.912005723916182
Validation loss: 2.6442046853042576

Epoch: 5| Step: 1
Training loss: 2.684125600471264
Validation loss: 2.51705124202619

Epoch: 5| Step: 2
Training loss: 2.9589091174938744
Validation loss: 2.487310974702445

Epoch: 5| Step: 3
Training loss: 2.692269816498997
Validation loss: 2.504738015714892

Epoch: 5| Step: 4
Training loss: 2.555873583847865
Validation loss: 2.56482029533996

Epoch: 5| Step: 5
Training loss: 2.871219305290396
Validation loss: 2.5616929759083638

Epoch: 5| Step: 6
Training loss: 3.296644302179162
Validation loss: 2.540764619502189

Epoch: 5| Step: 7
Training loss: 2.8681037124971
Validation loss: 2.5040191399181766

Epoch: 5| Step: 8
Training loss: 2.8641279563770343
Validation loss: 2.474466333396517

Epoch: 5| Step: 9
Training loss: 2.605095557805013
Validation loss: 2.4642368225517606

Epoch: 5| Step: 10
Training loss: 3.0533573932893585
Validation loss: 2.4719914031743597

Epoch: 169| Step: 0
Training loss: 2.549308690627689
Validation loss: 2.5094960823811516

Epoch: 5| Step: 1
Training loss: 3.258636443599933
Validation loss: 2.604182642405739

Epoch: 5| Step: 2
Training loss: 3.263193055418443
Validation loss: 2.6994461517734574

Epoch: 5| Step: 3
Training loss: 2.959635345060675
Validation loss: 2.758651351577085

Epoch: 5| Step: 4
Training loss: 2.766195981842382
Validation loss: 2.773371370859684

Epoch: 5| Step: 5
Training loss: 2.5558029679305423
Validation loss: 2.7481722775527375

Epoch: 5| Step: 6
Training loss: 1.8819388741023295
Validation loss: 2.7005413301977765

Epoch: 5| Step: 7
Training loss: 2.6021726883592344
Validation loss: 2.649936933148158

Epoch: 5| Step: 8
Training loss: 2.6981785670431226
Validation loss: 2.586471426656039

Epoch: 5| Step: 9
Training loss: 3.158116459173434
Validation loss: 2.5407382853808875

Epoch: 5| Step: 10
Training loss: 2.6514580979752638
Validation loss: 2.500220040923075

Epoch: 170| Step: 0
Training loss: 2.548720083468032
Validation loss: 2.480029578391446

Epoch: 5| Step: 1
Training loss: 2.4884051377432734
Validation loss: 2.471348406642999

Epoch: 5| Step: 2
Training loss: 2.975384336377019
Validation loss: 2.466068230260934

Epoch: 5| Step: 3
Training loss: 2.8931220738974455
Validation loss: 2.464120961481796

Epoch: 5| Step: 4
Training loss: 2.5613207080588816
Validation loss: 2.4652685350584433

Epoch: 5| Step: 5
Training loss: 2.847865218670107
Validation loss: 2.465643479000771

Epoch: 5| Step: 6
Training loss: 2.8715887979350856
Validation loss: 2.471958849173838

Epoch: 5| Step: 7
Training loss: 2.970775194566703
Validation loss: 2.4792820028223113

Epoch: 5| Step: 8
Training loss: 2.699927936581259
Validation loss: 2.4890821085105754

Epoch: 5| Step: 9
Training loss: 2.9144637008084486
Validation loss: 2.4976242426166446

Epoch: 5| Step: 10
Training loss: 2.5293022479732987
Validation loss: 2.5102386908506067

Epoch: 171| Step: 0
Training loss: 2.5912329168718085
Validation loss: 2.5212949104621893

Epoch: 5| Step: 1
Training loss: 2.6444520924383674
Validation loss: 2.533605092958885

Epoch: 5| Step: 2
Training loss: 2.5202662142661607
Validation loss: 2.54606136690881

Epoch: 5| Step: 3
Training loss: 2.8417884852754165
Validation loss: 2.5749747023279133

Epoch: 5| Step: 4
Training loss: 2.6469744126567916
Validation loss: 2.6082544178488036

Epoch: 5| Step: 5
Training loss: 2.935112165293102
Validation loss: 2.605776921874807

Epoch: 5| Step: 6
Training loss: 2.8409547587105357
Validation loss: 2.592325523394901

Epoch: 5| Step: 7
Training loss: 2.49084953339423
Validation loss: 2.5724045707721794

Epoch: 5| Step: 8
Training loss: 3.000721844614245
Validation loss: 2.5539689338100002

Epoch: 5| Step: 9
Training loss: 2.7148552544439246
Validation loss: 2.5382671251993743

Epoch: 5| Step: 10
Training loss: 2.7868766874662
Validation loss: 2.538794210314625

Epoch: 172| Step: 0
Training loss: 2.754212361089912
Validation loss: 2.540526834660093

Epoch: 5| Step: 1
Training loss: 2.609520639706683
Validation loss: 2.534106258615416

Epoch: 5| Step: 2
Training loss: 2.220022239745494
Validation loss: 2.5423449823717634

Epoch: 5| Step: 3
Training loss: 2.9634425856793927
Validation loss: 2.5491030698658204

Epoch: 5| Step: 4
Training loss: 2.678754727585929
Validation loss: 2.544925793105571

Epoch: 5| Step: 5
Training loss: 2.971808694928139
Validation loss: 2.544149569580222

Epoch: 5| Step: 6
Training loss: 2.613855410055287
Validation loss: 2.558896515157364

Epoch: 5| Step: 7
Training loss: 2.71842586295144
Validation loss: 2.561882769073359

Epoch: 5| Step: 8
Training loss: 2.5651832116561954
Validation loss: 2.562086744823131

Epoch: 5| Step: 9
Training loss: 2.4319779862925914
Validation loss: 2.57239170671633

Epoch: 5| Step: 10
Training loss: 3.0911280763539755
Validation loss: 2.581506157048007

Epoch: 173| Step: 0
Training loss: 2.725910272712653
Validation loss: 2.5906938748717874

Epoch: 5| Step: 1
Training loss: 2.4301181423839466
Validation loss: 2.585313806608586

Epoch: 5| Step: 2
Training loss: 2.2594784197214657
Validation loss: 2.591303837576345

Epoch: 5| Step: 3
Training loss: 2.9248855503220823
Validation loss: 2.6078913740170035

Epoch: 5| Step: 4
Training loss: 2.690464070787553
Validation loss: 2.6057184064727386

Epoch: 5| Step: 5
Training loss: 2.5293689850061005
Validation loss: 2.588726288096206

Epoch: 5| Step: 6
Training loss: 2.688120748112537
Validation loss: 2.5955663232776773

Epoch: 5| Step: 7
Training loss: 2.8463716265022785
Validation loss: 2.578143770877325

Epoch: 5| Step: 8
Training loss: 3.003052430164254
Validation loss: 2.574332302942106

Epoch: 5| Step: 9
Training loss: 2.6265078255830727
Validation loss: 2.5506032328740207

Epoch: 5| Step: 10
Training loss: 2.986145612729286
Validation loss: 2.5463750255251227

Epoch: 174| Step: 0
Training loss: 2.294229969666738
Validation loss: 2.553054898536794

Epoch: 5| Step: 1
Training loss: 2.7838401306388487
Validation loss: 2.5493808409663896

Epoch: 5| Step: 2
Training loss: 2.560418469826974
Validation loss: 2.5474544640766332

Epoch: 5| Step: 3
Training loss: 3.010531694971136
Validation loss: 2.5523299375370785

Epoch: 5| Step: 4
Training loss: 2.931865889340543
Validation loss: 2.5734311936517367

Epoch: 5| Step: 5
Training loss: 2.365853112937456
Validation loss: 2.5839107601131266

Epoch: 5| Step: 6
Training loss: 2.705281714755224
Validation loss: 2.5949608676794056

Epoch: 5| Step: 7
Training loss: 2.809842528414157
Validation loss: 2.585918915567838

Epoch: 5| Step: 8
Training loss: 2.5529281671073143
Validation loss: 2.597365960268254

Epoch: 5| Step: 9
Training loss: 2.931824578620325
Validation loss: 2.5764456879622424

Epoch: 5| Step: 10
Training loss: 2.4935435847849967
Validation loss: 2.5814902955347923

Epoch: 175| Step: 0
Training loss: 2.8978766132569587
Validation loss: 2.565181320793255

Epoch: 5| Step: 1
Training loss: 3.1885781054370703
Validation loss: 2.5570915776624266

Epoch: 5| Step: 2
Training loss: 2.4961048299098767
Validation loss: 2.5404541361793376

Epoch: 5| Step: 3
Training loss: 2.11654664648008
Validation loss: 2.536890037682905

Epoch: 5| Step: 4
Training loss: 2.3819222209797015
Validation loss: 2.5440979888993134

Epoch: 5| Step: 5
Training loss: 2.651224745828438
Validation loss: 2.5578470562867555

Epoch: 5| Step: 6
Training loss: 2.6827364555872273
Validation loss: 2.5682111934663223

Epoch: 5| Step: 7
Training loss: 3.185451372821189
Validation loss: 2.5919001506523807

Epoch: 5| Step: 8
Training loss: 2.647439143964615
Validation loss: 2.613885880049575

Epoch: 5| Step: 9
Training loss: 2.9242348346680593
Validation loss: 2.6366690502397363

Epoch: 5| Step: 10
Training loss: 1.7756116538534807
Validation loss: 2.629869153402454

Epoch: 176| Step: 0
Training loss: 2.694538746218099
Validation loss: 2.6415614403114187

Epoch: 5| Step: 1
Training loss: 2.8849728974072555
Validation loss: 2.624532025017561

Epoch: 5| Step: 2
Training loss: 2.763275700402612
Validation loss: 2.6054911760014257

Epoch: 5| Step: 3
Training loss: 2.2395150344252
Validation loss: 2.581823191095237

Epoch: 5| Step: 4
Training loss: 3.049327626142789
Validation loss: 2.5758073290051966

Epoch: 5| Step: 5
Training loss: 2.520222035420412
Validation loss: 2.6006172816002833

Epoch: 5| Step: 6
Training loss: 2.5907001258991715
Validation loss: 2.634790057047118

Epoch: 5| Step: 7
Training loss: 2.978863004845262
Validation loss: 2.6121338909391754

Epoch: 5| Step: 8
Training loss: 2.5848454592642107
Validation loss: 2.57729297088051

Epoch: 5| Step: 9
Training loss: 2.6083439600263905
Validation loss: 2.5516490761863837

Epoch: 5| Step: 10
Training loss: 2.4902914362335045
Validation loss: 2.537690908364164

Epoch: 177| Step: 0
Training loss: 2.6708204184788746
Validation loss: 2.526894570007939

Epoch: 5| Step: 1
Training loss: 2.393157515146771
Validation loss: 2.5400112503024816

Epoch: 5| Step: 2
Training loss: 2.9365497431894583
Validation loss: 2.556085761902468

Epoch: 5| Step: 3
Training loss: 2.79898690560601
Validation loss: 2.5619866121745445

Epoch: 5| Step: 4
Training loss: 2.6671667722802797
Validation loss: 2.5813148729341724

Epoch: 5| Step: 5
Training loss: 3.3001082778275235
Validation loss: 2.5865467428131557

Epoch: 5| Step: 6
Training loss: 2.698862054997761
Validation loss: 2.5872897246134015

Epoch: 5| Step: 7
Training loss: 2.5473756824591516
Validation loss: 2.6043718915900635

Epoch: 5| Step: 8
Training loss: 2.6323548776705334
Validation loss: 2.6118899025585507

Epoch: 5| Step: 9
Training loss: 2.1649382984628276
Validation loss: 2.6244211452277297

Epoch: 5| Step: 10
Training loss: 2.517134503801792
Validation loss: 2.6385748527582638

Epoch: 178| Step: 0
Training loss: 2.83652072090261
Validation loss: 2.6632990286965694

Epoch: 5| Step: 1
Training loss: 2.7742535317425894
Validation loss: 2.657760036479508

Epoch: 5| Step: 2
Training loss: 2.478918260797112
Validation loss: 2.630885902802908

Epoch: 5| Step: 3
Training loss: 2.7581840459371465
Validation loss: 2.618388975197944

Epoch: 5| Step: 4
Training loss: 2.78173301017306
Validation loss: 2.6187594643714345

Epoch: 5| Step: 5
Training loss: 2.4041759916110377
Validation loss: 2.6165149993421095

Epoch: 5| Step: 6
Training loss: 2.619634139454815
Validation loss: 2.606725012635801

Epoch: 5| Step: 7
Training loss: 2.53586111276859
Validation loss: 2.6098622994517138

Epoch: 5| Step: 8
Training loss: 2.656856961185703
Validation loss: 2.594305736765317

Epoch: 5| Step: 9
Training loss: 2.8048523240816094
Validation loss: 2.574498131988474

Epoch: 5| Step: 10
Training loss: 2.421299035280341
Validation loss: 2.5567714358411395

Epoch: 179| Step: 0
Training loss: 2.2251471052938845
Validation loss: 2.553398650906187

Epoch: 5| Step: 1
Training loss: 2.9779241856441434
Validation loss: 2.5577018981338435

Epoch: 5| Step: 2
Training loss: 3.099822894543987
Validation loss: 2.559515583021158

Epoch: 5| Step: 3
Training loss: 2.436268617687068
Validation loss: 2.539248612542565

Epoch: 5| Step: 4
Training loss: 2.6661477080662292
Validation loss: 2.5312710012569646

Epoch: 5| Step: 5
Training loss: 2.6768317395049497
Validation loss: 2.5432133516737125

Epoch: 5| Step: 6
Training loss: 2.7258505342555592
Validation loss: 2.5503574742883575

Epoch: 5| Step: 7
Training loss: 2.6342057975832103
Validation loss: 2.558851624692724

Epoch: 5| Step: 8
Training loss: 2.1819739159721663
Validation loss: 2.5841153820477865

Epoch: 5| Step: 9
Training loss: 2.972399426067011
Validation loss: 2.64968566299478

Epoch: 5| Step: 10
Training loss: 2.2837113988628026
Validation loss: 2.677212881793241

Epoch: 180| Step: 0
Training loss: 3.5993678756566525
Validation loss: 2.7081629722407614

Epoch: 5| Step: 1
Training loss: 2.9042694562529707
Validation loss: 2.6956618158902543

Epoch: 5| Step: 2
Training loss: 2.542422093761034
Validation loss: 2.634796171347959

Epoch: 5| Step: 3
Training loss: 2.788431646556155
Validation loss: 2.5968549527686635

Epoch: 5| Step: 4
Training loss: 2.4767852586751102
Validation loss: 2.5968678160803833

Epoch: 5| Step: 5
Training loss: 2.63930121652684
Validation loss: 2.589898758168275

Epoch: 5| Step: 6
Training loss: 2.755747078406152
Validation loss: 2.5899456346071674

Epoch: 5| Step: 7
Training loss: 2.40129729018343
Validation loss: 2.5874381986694845

Epoch: 5| Step: 8
Training loss: 2.035909385223544
Validation loss: 2.597030485570737

Epoch: 5| Step: 9
Training loss: 1.9031327822170652
Validation loss: 2.587689705662902

Epoch: 5| Step: 10
Training loss: 2.601410274233281
Validation loss: 2.5879773571164204

Epoch: 181| Step: 0
Training loss: 2.6862397011141876
Validation loss: 2.585081023998169

Epoch: 5| Step: 1
Training loss: 2.4955465705025173
Validation loss: 2.5831017739407414

Epoch: 5| Step: 2
Training loss: 2.4386395456082766
Validation loss: 2.585240469555453

Epoch: 5| Step: 3
Training loss: 2.2559214133447236
Validation loss: 2.570467775194555

Epoch: 5| Step: 4
Training loss: 2.55572833868469
Validation loss: 2.5749629054557164

Epoch: 5| Step: 5
Training loss: 2.6978441815353675
Validation loss: 2.5864802907009614

Epoch: 5| Step: 6
Training loss: 2.9645416950260377
Validation loss: 2.5961184757180176

Epoch: 5| Step: 7
Training loss: 2.74271137852155
Validation loss: 2.6135470376879346

Epoch: 5| Step: 8
Training loss: 2.916140390781548
Validation loss: 2.6031444681243214

Epoch: 5| Step: 9
Training loss: 2.0811961719780534
Validation loss: 2.609238914108126

Epoch: 5| Step: 10
Training loss: 2.7405034733168945
Validation loss: 2.610695757965463

Epoch: 182| Step: 0
Training loss: 2.7140267219886502
Validation loss: 2.627226877699689

Epoch: 5| Step: 1
Training loss: 2.423862158869137
Validation loss: 2.6237637176645183

Epoch: 5| Step: 2
Training loss: 2.664359336268291
Validation loss: 2.6453370431524985

Epoch: 5| Step: 3
Training loss: 2.9835622589535076
Validation loss: 2.6384063514483502

Epoch: 5| Step: 4
Training loss: 2.9210231579649752
Validation loss: 2.6388798759046033

Epoch: 5| Step: 5
Training loss: 2.620137115414107
Validation loss: 2.6163718860193623

Epoch: 5| Step: 6
Training loss: 1.9892398344640485
Validation loss: 2.5993239290117764

Epoch: 5| Step: 7
Training loss: 2.7611224921555024
Validation loss: 2.598218669850708

Epoch: 5| Step: 8
Training loss: 2.427929993878691
Validation loss: 2.6029324553203

Epoch: 5| Step: 9
Training loss: 2.574321738977373
Validation loss: 2.6145388502151037

Epoch: 5| Step: 10
Training loss: 2.2027308334644125
Validation loss: 2.6269026598078318

Epoch: 183| Step: 0
Training loss: 2.5985289520300854
Validation loss: 2.6105353904637307

Epoch: 5| Step: 1
Training loss: 2.8861985415385405
Validation loss: 2.618738965029762

Epoch: 5| Step: 2
Training loss: 2.2365058395203756
Validation loss: 2.6238099871250817

Epoch: 5| Step: 3
Training loss: 2.540026860132647
Validation loss: 2.635715068081314

Epoch: 5| Step: 4
Training loss: 2.7028305687169736
Validation loss: 2.646472342791149

Epoch: 5| Step: 5
Training loss: 2.3965323271613497
Validation loss: 2.6264642088096775

Epoch: 5| Step: 6
Training loss: 2.639621340732176
Validation loss: 2.610857491280435

Epoch: 5| Step: 7
Training loss: 2.9503874831383046
Validation loss: 2.571794710072417

Epoch: 5| Step: 8
Training loss: 2.624195338852014
Validation loss: 2.562821393851163

Epoch: 5| Step: 9
Training loss: 2.235474002762906
Validation loss: 2.557638498483027

Epoch: 5| Step: 10
Training loss: 2.4782460744752237
Validation loss: 2.5453930681768906

Epoch: 184| Step: 0
Training loss: 2.4102491363976495
Validation loss: 2.5516882471111195

Epoch: 5| Step: 1
Training loss: 2.2309469321730546
Validation loss: 2.5771530874949966

Epoch: 5| Step: 2
Training loss: 2.4116913344416298
Validation loss: 2.613108879864688

Epoch: 5| Step: 3
Training loss: 2.0209330373596495
Validation loss: 2.658781767866816

Epoch: 5| Step: 4
Training loss: 3.0566924166938088
Validation loss: 2.7059854934013474

Epoch: 5| Step: 5
Training loss: 2.87109242134323
Validation loss: 2.7434121628342716

Epoch: 5| Step: 6
Training loss: 2.763623305254525
Validation loss: 2.7049712605445477

Epoch: 5| Step: 7
Training loss: 2.7936608797404943
Validation loss: 2.667346779812157

Epoch: 5| Step: 8
Training loss: 2.310903255680925
Validation loss: 2.603497993185457

Epoch: 5| Step: 9
Training loss: 2.35781930324617
Validation loss: 2.6018619135329333

Epoch: 5| Step: 10
Training loss: 2.912339097191261
Validation loss: 2.587210643898006

Epoch: 185| Step: 0
Training loss: 2.552206065022933
Validation loss: 2.5828517477502

Epoch: 5| Step: 1
Training loss: 2.2389922552277235
Validation loss: 2.599571377831453

Epoch: 5| Step: 2
Training loss: 2.8409062513857437
Validation loss: 2.6453869822402125

Epoch: 5| Step: 3
Training loss: 2.7347654227409404
Validation loss: 2.663073841676397

Epoch: 5| Step: 4
Training loss: 2.3342428024424526
Validation loss: 2.6514704150253525

Epoch: 5| Step: 5
Training loss: 2.178093877977756
Validation loss: 2.624644664147341

Epoch: 5| Step: 6
Training loss: 2.5771880325681327
Validation loss: 2.626607656522915

Epoch: 5| Step: 7
Training loss: 2.2824907456008803
Validation loss: 2.6167847702004323

Epoch: 5| Step: 8
Training loss: 2.810996777098717
Validation loss: 2.6180400891633853

Epoch: 5| Step: 9
Training loss: 2.7651688366573475
Validation loss: 2.6100991079293774

Epoch: 5| Step: 10
Training loss: 2.6735717561365697
Validation loss: 2.6042589416563033

Epoch: 186| Step: 0
Training loss: 2.2324797588596996
Validation loss: 2.601550671935712

Epoch: 5| Step: 1
Training loss: 2.114977481983696
Validation loss: 2.603188720840302

Epoch: 5| Step: 2
Training loss: 2.6923819269698397
Validation loss: 2.5936466606143243

Epoch: 5| Step: 3
Training loss: 2.7508111971064944
Validation loss: 2.621689595412562

Epoch: 5| Step: 4
Training loss: 2.581112142580815
Validation loss: 2.6282359363301144

Epoch: 5| Step: 5
Training loss: 2.5993609119793883
Validation loss: 2.604766672887555

Epoch: 5| Step: 6
Training loss: 1.9923301496109596
Validation loss: 2.594588644146176

Epoch: 5| Step: 7
Training loss: 2.769026566377646
Validation loss: 2.569453672240794

Epoch: 5| Step: 8
Training loss: 2.7116925070417888
Validation loss: 2.5769344739434805

Epoch: 5| Step: 9
Training loss: 2.8732722522707355
Validation loss: 2.577270089629531

Epoch: 5| Step: 10
Training loss: 2.3707051846464937
Validation loss: 2.576024274232963

Epoch: 187| Step: 0
Training loss: 2.4610012470042246
Validation loss: 2.605542541955522

Epoch: 5| Step: 1
Training loss: 2.0757112180405692
Validation loss: 2.5964358385191777

Epoch: 5| Step: 2
Training loss: 2.9112089774819134
Validation loss: 2.604335657030564

Epoch: 5| Step: 3
Training loss: 2.7161068399958004
Validation loss: 2.5944346930061397

Epoch: 5| Step: 4
Training loss: 3.0955247508744566
Validation loss: 2.5532694293974134

Epoch: 5| Step: 5
Training loss: 2.8091645701930634
Validation loss: 2.5571685792136227

Epoch: 5| Step: 6
Training loss: 2.109292374864697
Validation loss: 2.5478341874307096

Epoch: 5| Step: 7
Training loss: 2.3058910266242547
Validation loss: 2.594457367542814

Epoch: 5| Step: 8
Training loss: 2.8234838687739234
Validation loss: 2.615884562408893

Epoch: 5| Step: 9
Training loss: 2.278957312230582
Validation loss: 2.62543073051145

Epoch: 5| Step: 10
Training loss: 1.8121151351097085
Validation loss: 2.6370303312548105

Epoch: 188| Step: 0
Training loss: 3.131463043214086
Validation loss: 2.6171715158125326

Epoch: 5| Step: 1
Training loss: 3.056094262771411
Validation loss: 2.574390532434612

Epoch: 5| Step: 2
Training loss: 2.4443913391394316
Validation loss: 2.565218364263405

Epoch: 5| Step: 3
Training loss: 2.0396622400603075
Validation loss: 2.5489629263272238

Epoch: 5| Step: 4
Training loss: 1.9948415990677288
Validation loss: 2.5529344794765065

Epoch: 5| Step: 5
Training loss: 2.4198594104503703
Validation loss: 2.557748970746558

Epoch: 5| Step: 6
Training loss: 2.3806513757263583
Validation loss: 2.5572940168191787

Epoch: 5| Step: 7
Training loss: 2.6101197419158133
Validation loss: 2.5625874474163606

Epoch: 5| Step: 8
Training loss: 2.639443037062637
Validation loss: 2.5874341076420904

Epoch: 5| Step: 9
Training loss: 2.5934016901566883
Validation loss: 2.6083254507145495

Epoch: 5| Step: 10
Training loss: 2.1001980688147426
Validation loss: 2.649821227380673

Epoch: 189| Step: 0
Training loss: 2.3469751166514636
Validation loss: 2.6704923195286763

Epoch: 5| Step: 1
Training loss: 2.659599526023507
Validation loss: 2.722944721662038

Epoch: 5| Step: 2
Training loss: 2.889970035067642
Validation loss: 2.7703599885565513

Epoch: 5| Step: 3
Training loss: 2.3930180359291033
Validation loss: 2.735886276922929

Epoch: 5| Step: 4
Training loss: 1.9924817634619072
Validation loss: 2.698133860803151

Epoch: 5| Step: 5
Training loss: 2.4084051810066467
Validation loss: 2.641825615212549

Epoch: 5| Step: 6
Training loss: 2.702226346088422
Validation loss: 2.6155524185861685

Epoch: 5| Step: 7
Training loss: 2.640867414012823
Validation loss: 2.5896576157316002

Epoch: 5| Step: 8
Training loss: 2.397022140343386
Validation loss: 2.569978076523214

Epoch: 5| Step: 9
Training loss: 2.650755641373961
Validation loss: 2.542939330608285

Epoch: 5| Step: 10
Training loss: 2.7172165854302914
Validation loss: 2.543466433758936

Epoch: 190| Step: 0
Training loss: 2.180769675636065
Validation loss: 2.550836398032901

Epoch: 5| Step: 1
Training loss: 2.5701074025611192
Validation loss: 2.535877786389154

Epoch: 5| Step: 2
Training loss: 2.2500040266212884
Validation loss: 2.542458592591904

Epoch: 5| Step: 3
Training loss: 2.140996302124422
Validation loss: 2.579651266384808

Epoch: 5| Step: 4
Training loss: 2.167914532507582
Validation loss: 2.6016573728668537

Epoch: 5| Step: 5
Training loss: 3.062783675776742
Validation loss: 2.63288322376379

Epoch: 5| Step: 6
Training loss: 2.693835486805823
Validation loss: 2.6362055730541325

Epoch: 5| Step: 7
Training loss: 2.3183875528115956
Validation loss: 2.664987093478596

Epoch: 5| Step: 8
Training loss: 2.4563862692425116
Validation loss: 2.6703421952623105

Epoch: 5| Step: 9
Training loss: 2.5959411925251366
Validation loss: 2.66672412812969

Epoch: 5| Step: 10
Training loss: 3.1991299161582956
Validation loss: 2.6851414669103395

Epoch: 191| Step: 0
Training loss: 2.6467911996377764
Validation loss: 2.6288458333849096

Epoch: 5| Step: 1
Training loss: 2.2842640235339315
Validation loss: 2.6153332002194785

Epoch: 5| Step: 2
Training loss: 2.454877871021958
Validation loss: 2.5721378257761356

Epoch: 5| Step: 3
Training loss: 2.7686250438866717
Validation loss: 2.540600869085957

Epoch: 5| Step: 4
Training loss: 2.774796789478536
Validation loss: 2.566404269136159

Epoch: 5| Step: 5
Training loss: 2.198835593634611
Validation loss: 2.544093361621372

Epoch: 5| Step: 6
Training loss: 2.2457215639327157
Validation loss: 2.5355482818567108

Epoch: 5| Step: 7
Training loss: 2.029064117388695
Validation loss: 2.565616392408184

Epoch: 5| Step: 8
Training loss: 2.3496032866972243
Validation loss: 2.5770669933349564

Epoch: 5| Step: 9
Training loss: 2.951791613659194
Validation loss: 2.585668552025573

Epoch: 5| Step: 10
Training loss: 2.746748649460039
Validation loss: 2.5841573296860156

Epoch: 192| Step: 0
Training loss: 2.2986303356195235
Validation loss: 2.597364656420363

Epoch: 5| Step: 1
Training loss: 1.838818566180425
Validation loss: 2.5927946721053985

Epoch: 5| Step: 2
Training loss: 2.8383571926449904
Validation loss: 2.59983723295032

Epoch: 5| Step: 3
Training loss: 2.247080179961223
Validation loss: 2.564157497647386

Epoch: 5| Step: 4
Training loss: 3.0136297869509208
Validation loss: 2.549911740026479

Epoch: 5| Step: 5
Training loss: 2.4020523514835346
Validation loss: 2.5500707194691863

Epoch: 5| Step: 6
Training loss: 2.670323864157632
Validation loss: 2.545039449791729

Epoch: 5| Step: 7
Training loss: 1.9310013472099483
Validation loss: 2.5660715592116365

Epoch: 5| Step: 8
Training loss: 2.5603038401895497
Validation loss: 2.563565748656571

Epoch: 5| Step: 9
Training loss: 2.4500370879188207
Validation loss: 2.580187923644394

Epoch: 5| Step: 10
Training loss: 2.749338937545871
Validation loss: 2.6071014373313344

Epoch: 193| Step: 0
Training loss: 2.540547942885089
Validation loss: 2.613144220681459

Epoch: 5| Step: 1
Training loss: 2.275843549845376
Validation loss: 2.626857253871448

Epoch: 5| Step: 2
Training loss: 2.8166191454458205
Validation loss: 2.6074482071702816

Epoch: 5| Step: 3
Training loss: 2.9036604306434275
Validation loss: 2.6350030625966814

Epoch: 5| Step: 4
Training loss: 2.7981724633269986
Validation loss: 2.638620222224965

Epoch: 5| Step: 5
Training loss: 2.4460752230015395
Validation loss: 2.5898629655250285

Epoch: 5| Step: 6
Training loss: 2.499323085695051
Validation loss: 2.55808668261996

Epoch: 5| Step: 7
Training loss: 2.0285694922470583
Validation loss: 2.5295179166507515

Epoch: 5| Step: 8
Training loss: 2.4314293214227845
Validation loss: 2.519038595162359

Epoch: 5| Step: 9
Training loss: 1.939058599844675
Validation loss: 2.512294301135891

Epoch: 5| Step: 10
Training loss: 2.2441966130349997
Validation loss: 2.522005484105395

Epoch: 194| Step: 0
Training loss: 1.8114277529059233
Validation loss: 2.537661279280932

Epoch: 5| Step: 1
Training loss: 2.5982705673391817
Validation loss: 2.556599795189227

Epoch: 5| Step: 2
Training loss: 2.3364007292772646
Validation loss: 2.577964858783346

Epoch: 5| Step: 3
Training loss: 2.4296204781564543
Validation loss: 2.619939830508382

Epoch: 5| Step: 4
Training loss: 2.622248615475101
Validation loss: 2.6414750758684797

Epoch: 5| Step: 5
Training loss: 2.40792085179761
Validation loss: 2.6461307993715453

Epoch: 5| Step: 6
Training loss: 2.291505310851503
Validation loss: 2.680088433805658

Epoch: 5| Step: 7
Training loss: 2.344927580961688
Validation loss: 2.6585370105498356

Epoch: 5| Step: 8
Training loss: 2.764233341403862
Validation loss: 2.6796916061269935

Epoch: 5| Step: 9
Training loss: 2.7824652085095622
Validation loss: 2.663976495490247

Epoch: 5| Step: 10
Training loss: 2.478383931778844
Validation loss: 2.620253632020243

Epoch: 195| Step: 0
Training loss: 1.8234455177111246
Validation loss: 2.5491286588448236

Epoch: 5| Step: 1
Training loss: 2.588264731951188
Validation loss: 2.5160446107472856

Epoch: 5| Step: 2
Training loss: 2.599129945724523
Validation loss: 2.505765020633996

Epoch: 5| Step: 3
Training loss: 2.1443445788020963
Validation loss: 2.4945972534802654

Epoch: 5| Step: 4
Training loss: 2.6284365184738108
Validation loss: 2.4886745315235674

Epoch: 5| Step: 5
Training loss: 2.5988237324466392
Validation loss: 2.4829054763738063

Epoch: 5| Step: 6
Training loss: 2.481456842136733
Validation loss: 2.5066702938457226

Epoch: 5| Step: 7
Training loss: 2.1595704317330053
Validation loss: 2.52385321048677

Epoch: 5| Step: 8
Training loss: 2.668098323685984
Validation loss: 2.5432458393319988

Epoch: 5| Step: 9
Training loss: 2.7695089535696735
Validation loss: 2.57708238169649

Epoch: 5| Step: 10
Training loss: 2.2045428536139666
Validation loss: 2.605047896068111

Epoch: 196| Step: 0
Training loss: 2.394250850222061
Validation loss: 2.6617598445420736

Epoch: 5| Step: 1
Training loss: 2.0763195484140837
Validation loss: 2.6925187522081386

Epoch: 5| Step: 2
Training loss: 2.1533531964963584
Validation loss: 2.6769490828204754

Epoch: 5| Step: 3
Training loss: 2.471841638776384
Validation loss: 2.682910699056679

Epoch: 5| Step: 4
Training loss: 2.5885204311756023
Validation loss: 2.634898289945109

Epoch: 5| Step: 5
Training loss: 2.871159019506828
Validation loss: 2.608086009053098

Epoch: 5| Step: 6
Training loss: 2.5600040654805802
Validation loss: 2.5624221771932456

Epoch: 5| Step: 7
Training loss: 2.591334401590323
Validation loss: 2.5518028920535176

Epoch: 5| Step: 8
Training loss: 3.0734553667721496
Validation loss: 2.5344858920671576

Epoch: 5| Step: 9
Training loss: 2.0011752966829763
Validation loss: 2.5317601244775623

Epoch: 5| Step: 10
Training loss: 2.109882095984005
Validation loss: 2.5492027451539987

Epoch: 197| Step: 0
Training loss: 2.9372542258178744
Validation loss: 2.5474750217903552

Epoch: 5| Step: 1
Training loss: 1.9706213398230064
Validation loss: 2.583518360695273

Epoch: 5| Step: 2
Training loss: 2.66863263696261
Validation loss: 2.637764089838895

Epoch: 5| Step: 3
Training loss: 2.7216488521979483
Validation loss: 2.6533290469423103

Epoch: 5| Step: 4
Training loss: 2.4210237052856742
Validation loss: 2.647568444226553

Epoch: 5| Step: 5
Training loss: 2.3091367028214016
Validation loss: 2.6342630247455503

Epoch: 5| Step: 6
Training loss: 2.5893707073525056
Validation loss: 2.6326907793629717

Epoch: 5| Step: 7
Training loss: 2.35711410017761
Validation loss: 2.6022932598098927

Epoch: 5| Step: 8
Training loss: 2.189404666578763
Validation loss: 2.585203893464672

Epoch: 5| Step: 9
Training loss: 2.064935921882496
Validation loss: 2.5510012159263877

Epoch: 5| Step: 10
Training loss: 2.2235810244916303
Validation loss: 2.513054714434612

Epoch: 198| Step: 0
Training loss: 2.164974860382366
Validation loss: 2.50342303014254

Epoch: 5| Step: 1
Training loss: 2.1559885944638038
Validation loss: 2.502314346429274

Epoch: 5| Step: 2
Training loss: 2.951213399618932
Validation loss: 2.479281362760488

Epoch: 5| Step: 3
Training loss: 2.598420040877107
Validation loss: 2.4803037558036283

Epoch: 5| Step: 4
Training loss: 2.0688765242225666
Validation loss: 2.481629466213372

Epoch: 5| Step: 5
Training loss: 2.2026151242949155
Validation loss: 2.50519558711418

Epoch: 5| Step: 6
Training loss: 2.567043091885234
Validation loss: 2.5418631667484775

Epoch: 5| Step: 7
Training loss: 2.3353965924024407
Validation loss: 2.5554392762397313

Epoch: 5| Step: 8
Training loss: 1.9573065588849647
Validation loss: 2.5800925703390245

Epoch: 5| Step: 9
Training loss: 2.4487399617369583
Validation loss: 2.576334904915548

Epoch: 5| Step: 10
Training loss: 2.8954073549183934
Validation loss: 2.5833513263892174

Epoch: 199| Step: 0
Training loss: 2.268371390706186
Validation loss: 2.588624066315456

Epoch: 5| Step: 1
Training loss: 2.4860360212961776
Validation loss: 2.5697683513951115

Epoch: 5| Step: 2
Training loss: 2.498374792174475
Validation loss: 2.5558493723801505

Epoch: 5| Step: 3
Training loss: 2.472088837567371
Validation loss: 2.520841665787241

Epoch: 5| Step: 4
Training loss: 2.648760300490697
Validation loss: 2.504368439636275

Epoch: 5| Step: 5
Training loss: 2.2936330739500335
Validation loss: 2.522727680814317

Epoch: 5| Step: 6
Training loss: 2.477650304213301
Validation loss: 2.5047965847371376

Epoch: 5| Step: 7
Training loss: 1.8364528500855006
Validation loss: 2.5169922390785313

Epoch: 5| Step: 8
Training loss: 2.4447346452440883
Validation loss: 2.520856743458683

Epoch: 5| Step: 9
Training loss: 2.347004474669759
Validation loss: 2.513100348482409

Epoch: 5| Step: 10
Training loss: 2.4900807052769847
Validation loss: 2.5409849137789564

Epoch: 200| Step: 0
Training loss: 2.370389478687029
Validation loss: 2.5561484518790465

Epoch: 5| Step: 1
Training loss: 2.6711487257042696
Validation loss: 2.585615703577721

Epoch: 5| Step: 2
Training loss: 1.5390518885212783
Validation loss: 2.605741928294407

Epoch: 5| Step: 3
Training loss: 2.169547391178252
Validation loss: 2.6213624521021304

Epoch: 5| Step: 4
Training loss: 1.9749619106048206
Validation loss: 2.612824648169072

Epoch: 5| Step: 5
Training loss: 2.1225136066984627
Validation loss: 2.600859392089496

Epoch: 5| Step: 6
Training loss: 2.6717666693248012
Validation loss: 2.5613392577780565

Epoch: 5| Step: 7
Training loss: 2.3248236886720344
Validation loss: 2.5374360439020602

Epoch: 5| Step: 8
Training loss: 2.7248524547144526
Validation loss: 2.507717794866883

Epoch: 5| Step: 9
Training loss: 2.5772007990725587
Validation loss: 2.4990264114576144

Epoch: 5| Step: 10
Training loss: 2.871241891373713
Validation loss: 2.4814992358197823

Epoch: 201| Step: 0
Training loss: 2.365385068066752
Validation loss: 2.493830969574873

Epoch: 5| Step: 1
Training loss: 2.160340561686574
Validation loss: 2.4838769400186154

Epoch: 5| Step: 2
Training loss: 2.4926735335292265
Validation loss: 2.5150126926846603

Epoch: 5| Step: 3
Training loss: 1.9200008527435952
Validation loss: 2.5098468047095333

Epoch: 5| Step: 4
Training loss: 1.8991279759245319
Validation loss: 2.5405141664117825

Epoch: 5| Step: 5
Training loss: 2.7620560198661184
Validation loss: 2.5445277499482133

Epoch: 5| Step: 6
Training loss: 2.6588789552335745
Validation loss: 2.5436669730303945

Epoch: 5| Step: 7
Training loss: 1.7831849413777163
Validation loss: 2.5597743002582036

Epoch: 5| Step: 8
Training loss: 2.7199734971213827
Validation loss: 2.5745115322010514

Epoch: 5| Step: 9
Training loss: 2.6045954440302217
Validation loss: 2.579659842808372

Epoch: 5| Step: 10
Training loss: 2.1819927098810665
Validation loss: 2.5689738503307735

Epoch: 202| Step: 0
Training loss: 2.793611124499829
Validation loss: 2.5408477428856404

Epoch: 5| Step: 1
Training loss: 2.5247903038046617
Validation loss: 2.518899749780224

Epoch: 5| Step: 2
Training loss: 2.2548865131993776
Validation loss: 2.5134975737110556

Epoch: 5| Step: 3
Training loss: 2.3674037318410464
Validation loss: 2.504869216856143

Epoch: 5| Step: 4
Training loss: 2.110602918604822
Validation loss: 2.507279582316813

Epoch: 5| Step: 5
Training loss: 2.43774344377885
Validation loss: 2.5212008704016804

Epoch: 5| Step: 6
Training loss: 2.3309443255517754
Validation loss: 2.5411162626869013

Epoch: 5| Step: 7
Training loss: 1.8817215287370888
Validation loss: 2.5365164158581757

Epoch: 5| Step: 8
Training loss: 2.1239288098533224
Validation loss: 2.537546024726491

Epoch: 5| Step: 9
Training loss: 2.3670715706516265
Validation loss: 2.5459390150037606

Epoch: 5| Step: 10
Training loss: 2.5615307905620255
Validation loss: 2.520155603447517

Epoch: 203| Step: 0
Training loss: 1.8665000256452295
Validation loss: 2.5245465147460937

Epoch: 5| Step: 1
Training loss: 2.440007118621198
Validation loss: 2.5118701672089907

Epoch: 5| Step: 2
Training loss: 2.2522485941178454
Validation loss: 2.507643858975182

Epoch: 5| Step: 3
Training loss: 2.9240288777001693
Validation loss: 2.4957940171062036

Epoch: 5| Step: 4
Training loss: 2.118233735419071
Validation loss: 2.5086899928956883

Epoch: 5| Step: 5
Training loss: 2.0804781103836794
Validation loss: 2.488069988157068

Epoch: 5| Step: 6
Training loss: 1.9409263831382073
Validation loss: 2.503095048161386

Epoch: 5| Step: 7
Training loss: 2.156801236222476
Validation loss: 2.5194753760371245

Epoch: 5| Step: 8
Training loss: 2.6772934253550207
Validation loss: 2.5277741719254414

Epoch: 5| Step: 9
Training loss: 2.451646687391428
Validation loss: 2.5200646154750075

Epoch: 5| Step: 10
Training loss: 2.288170963128924
Validation loss: 2.538337278579224

Epoch: 204| Step: 0
Training loss: 2.3938812817462294
Validation loss: 2.526312507915965

Epoch: 5| Step: 1
Training loss: 2.148893772572479
Validation loss: 2.549934187137739

Epoch: 5| Step: 2
Training loss: 2.4260031680018033
Validation loss: 2.54086814015313

Epoch: 5| Step: 3
Training loss: 2.234043763690841
Validation loss: 2.5459856707312256

Epoch: 5| Step: 4
Training loss: 2.496116673897082
Validation loss: 2.5376106537533856

Epoch: 5| Step: 5
Training loss: 2.7288929071545227
Validation loss: 2.522263874507928

Epoch: 5| Step: 6
Training loss: 1.6951347293027423
Validation loss: 2.5003775260294034

Epoch: 5| Step: 7
Training loss: 2.5367137198109004
Validation loss: 2.531541887269259

Epoch: 5| Step: 8
Training loss: 1.9754644065205131
Validation loss: 2.5272736282334685

Epoch: 5| Step: 9
Training loss: 2.1268994313197993
Validation loss: 2.5418259099911715

Epoch: 5| Step: 10
Training loss: 2.5699293784446433
Validation loss: 2.5630345251003135

Epoch: 205| Step: 0
Training loss: 2.7925147481202743
Validation loss: 2.5717267931934202

Epoch: 5| Step: 1
Training loss: 2.4117237601368737
Validation loss: 2.584029149303061

Epoch: 5| Step: 2
Training loss: 2.105358000551412
Validation loss: 2.571411199205011

Epoch: 5| Step: 3
Training loss: 2.301434927601184
Validation loss: 2.546519385697678

Epoch: 5| Step: 4
Training loss: 2.4917571554263978
Validation loss: 2.5317657929625317

Epoch: 5| Step: 5
Training loss: 2.2561250604501324
Validation loss: 2.493148676479573

Epoch: 5| Step: 6
Training loss: 2.301752426277109
Validation loss: 2.4710523908497892

Epoch: 5| Step: 7
Training loss: 2.39170115066107
Validation loss: 2.4813409038280607

Epoch: 5| Step: 8
Training loss: 2.2145033478908593
Validation loss: 2.498895433430012

Epoch: 5| Step: 9
Training loss: 2.596488334431218
Validation loss: 2.529546691489802

Epoch: 5| Step: 10
Training loss: 1.6506712184041072
Validation loss: 2.5620294054269626

Epoch: 206| Step: 0
Training loss: 2.4862239842806213
Validation loss: 2.5800806756445693

Epoch: 5| Step: 1
Training loss: 2.3064043277701196
Validation loss: 2.595279334164582

Epoch: 5| Step: 2
Training loss: 2.2553420757665887
Validation loss: 2.5742626644238324

Epoch: 5| Step: 3
Training loss: 2.1868644881125294
Validation loss: 2.5554160207374257

Epoch: 5| Step: 4
Training loss: 2.097460405523899
Validation loss: 2.5018615621367726

Epoch: 5| Step: 5
Training loss: 2.35598308963892
Validation loss: 2.462377407390697

Epoch: 5| Step: 6
Training loss: 2.4557667497096487
Validation loss: 2.4390740645860376

Epoch: 5| Step: 7
Training loss: 2.346234340056571
Validation loss: 2.4401670882889235

Epoch: 5| Step: 8
Training loss: 2.0257682190816912
Validation loss: 2.431812593780885

Epoch: 5| Step: 9
Training loss: 2.4564716811765535
Validation loss: 2.435926600581975

Epoch: 5| Step: 10
Training loss: 2.3048288075721275
Validation loss: 2.4391537985991683

Epoch: 207| Step: 0
Training loss: 1.9262525125000725
Validation loss: 2.47244303610782

Epoch: 5| Step: 1
Training loss: 2.7201994616639
Validation loss: 2.4775655727264905

Epoch: 5| Step: 2
Training loss: 2.365810887883172
Validation loss: 2.4744445547502587

Epoch: 5| Step: 3
Training loss: 2.2188024380357083
Validation loss: 2.5177460059230885

Epoch: 5| Step: 4
Training loss: 2.3253044093211326
Validation loss: 2.5721168083522614

Epoch: 5| Step: 5
Training loss: 2.4172729082559714
Validation loss: 2.5825685215129077

Epoch: 5| Step: 6
Training loss: 2.2476223993122457
Validation loss: 2.575873213479744

Epoch: 5| Step: 7
Training loss: 1.9797292679352543
Validation loss: 2.5577767293901705

Epoch: 5| Step: 8
Training loss: 2.5440225366157985
Validation loss: 2.5258327474275517

Epoch: 5| Step: 9
Training loss: 1.8351822618611695
Validation loss: 2.5160565361236333

Epoch: 5| Step: 10
Training loss: 2.620437744641391
Validation loss: 2.508483001764742

Epoch: 208| Step: 0
Training loss: 1.912943610309929
Validation loss: 2.49717302663086

Epoch: 5| Step: 1
Training loss: 2.385030945711085
Validation loss: 2.5131854314179396

Epoch: 5| Step: 2
Training loss: 1.9952176255961103
Validation loss: 2.524230317409494

Epoch: 5| Step: 3
Training loss: 2.6348633518291797
Validation loss: 2.554162160503452

Epoch: 5| Step: 4
Training loss: 2.2611412141104603
Validation loss: 2.59822245627711

Epoch: 5| Step: 5
Training loss: 2.0389569134614867
Validation loss: 2.6334622117218203

Epoch: 5| Step: 6
Training loss: 1.9318743218205081
Validation loss: 2.641162898837463

Epoch: 5| Step: 7
Training loss: 2.431654743934914
Validation loss: 2.636732096514845

Epoch: 5| Step: 8
Training loss: 2.852616457622173
Validation loss: 2.6361080136579838

Epoch: 5| Step: 9
Training loss: 2.347286455478122
Validation loss: 2.592052306888887

Epoch: 5| Step: 10
Training loss: 2.1270259848201425
Validation loss: 2.5077228981847512

Epoch: 209| Step: 0
Training loss: 1.812424888369906
Validation loss: 2.4821121602098972

Epoch: 5| Step: 1
Training loss: 2.071378843528032
Validation loss: 2.4662917517662644

Epoch: 5| Step: 2
Training loss: 2.4902654907676123
Validation loss: 2.4561293204666894

Epoch: 5| Step: 3
Training loss: 2.471398007828392
Validation loss: 2.4564446959601063

Epoch: 5| Step: 4
Training loss: 2.3496628499149113
Validation loss: 2.487683502245671

Epoch: 5| Step: 5
Training loss: 2.226157596647435
Validation loss: 2.479356944750652

Epoch: 5| Step: 6
Training loss: 2.6136633988440967
Validation loss: 2.5079791496965713

Epoch: 5| Step: 7
Training loss: 2.441672446425262
Validation loss: 2.5678442294400843

Epoch: 5| Step: 8
Training loss: 1.7480812452975785
Validation loss: 2.622829702260132

Epoch: 5| Step: 9
Training loss: 2.4098316635603405
Validation loss: 2.652641866695318

Epoch: 5| Step: 10
Training loss: 2.4170193140838863
Validation loss: 2.6967708675672926

Epoch: 210| Step: 0
Training loss: 1.6937730541279048
Validation loss: 2.6250894944365446

Epoch: 5| Step: 1
Training loss: 2.5833706289080807
Validation loss: 2.5727983912281305

Epoch: 5| Step: 2
Training loss: 2.106212930324812
Validation loss: 2.520525296607551

Epoch: 5| Step: 3
Training loss: 2.244441796554078
Validation loss: 2.4792937679357223

Epoch: 5| Step: 4
Training loss: 1.987177394379933
Validation loss: 2.4379469243819853

Epoch: 5| Step: 5
Training loss: 1.9231951141717452
Validation loss: 2.4434853966022416

Epoch: 5| Step: 6
Training loss: 2.744067121179719
Validation loss: 2.435321331678433

Epoch: 5| Step: 7
Training loss: 2.263129708349202
Validation loss: 2.416423782926836

Epoch: 5| Step: 8
Training loss: 2.389692935131782
Validation loss: 2.421539596742284

Epoch: 5| Step: 9
Training loss: 2.289080206376165
Validation loss: 2.4510116069140304

Epoch: 5| Step: 10
Training loss: 2.4139903036142467
Validation loss: 2.48147253620043

Epoch: 211| Step: 0
Training loss: 2.444007891147442
Validation loss: 2.529188581967302

Epoch: 5| Step: 1
Training loss: 2.2072345471218733
Validation loss: 2.595451338632901

Epoch: 5| Step: 2
Training loss: 2.7141146552170228
Validation loss: 2.6406126721667116

Epoch: 5| Step: 3
Training loss: 2.6521195554294876
Validation loss: 2.6522195435886258

Epoch: 5| Step: 4
Training loss: 1.7275599019641164
Validation loss: 2.6401212954180626

Epoch: 5| Step: 5
Training loss: 2.235692842694953
Validation loss: 2.6317851012880085

Epoch: 5| Step: 6
Training loss: 1.8012173800985996
Validation loss: 2.599799227278912

Epoch: 5| Step: 7
Training loss: 2.07257428688385
Validation loss: 2.5846465031836625

Epoch: 5| Step: 8
Training loss: 2.4471213381185946
Validation loss: 2.5805719700106793

Epoch: 5| Step: 9
Training loss: 1.2122005643482339
Validation loss: 2.5345280354925985

Epoch: 5| Step: 10
Training loss: 2.721097086516401
Validation loss: 2.501503516895312

Epoch: 212| Step: 0
Training loss: 2.635283445426324
Validation loss: 2.5147734637530013

Epoch: 5| Step: 1
Training loss: 2.1926885922616273
Validation loss: 2.491959033047304

Epoch: 5| Step: 2
Training loss: 2.1718402009001143
Validation loss: 2.495567218870376

Epoch: 5| Step: 3
Training loss: 1.942482233739489
Validation loss: 2.4996362667662995

Epoch: 5| Step: 4
Training loss: 2.47854284778071
Validation loss: 2.5101574870478203

Epoch: 5| Step: 5
Training loss: 2.023380116713171
Validation loss: 2.5351094627237494

Epoch: 5| Step: 6
Training loss: 1.9930650760306576
Validation loss: 2.5151852347097807

Epoch: 5| Step: 7
Training loss: 1.860283637621517
Validation loss: 2.5357557175430308

Epoch: 5| Step: 8
Training loss: 2.41479935248889
Validation loss: 2.5293787809429165

Epoch: 5| Step: 9
Training loss: 2.32348908583243
Validation loss: 2.5331341501497193

Epoch: 5| Step: 10
Training loss: 2.266126590320619
Validation loss: 2.534548624720363

Epoch: 213| Step: 0
Training loss: 1.9614189134534046
Validation loss: 2.5274831691521666

Epoch: 5| Step: 1
Training loss: 2.255662362879804
Validation loss: 2.5216842905980807

Epoch: 5| Step: 2
Training loss: 2.35302526660328
Validation loss: 2.487285104308576

Epoch: 5| Step: 3
Training loss: 2.396870551670925
Validation loss: 2.511153018718907

Epoch: 5| Step: 4
Training loss: 2.158126014954488
Validation loss: 2.507500007845405

Epoch: 5| Step: 5
Training loss: 2.0761900189558786
Validation loss: 2.5047005639434006

Epoch: 5| Step: 6
Training loss: 2.1796505285702974
Validation loss: 2.510147829553178

Epoch: 5| Step: 7
Training loss: 1.6489240461661734
Validation loss: 2.4948907110154392

Epoch: 5| Step: 8
Training loss: 2.2270461243202515
Validation loss: 2.4925641101179514

Epoch: 5| Step: 9
Training loss: 2.528342095521024
Validation loss: 2.5169095063257716

Epoch: 5| Step: 10
Training loss: 2.1555525163037
Validation loss: 2.531523333899697

Epoch: 214| Step: 0
Training loss: 1.8924598302571611
Validation loss: 2.5361159272661036

Epoch: 5| Step: 1
Training loss: 2.095702214876317
Validation loss: 2.5522236915818306

Epoch: 5| Step: 2
Training loss: 2.1983073702366704
Validation loss: 2.5294257882424587

Epoch: 5| Step: 3
Training loss: 2.360953907938
Validation loss: 2.500855693194849

Epoch: 5| Step: 4
Training loss: 2.5049214559031867
Validation loss: 2.4823990446081505

Epoch: 5| Step: 5
Training loss: 1.9054292256352712
Validation loss: 2.4740131434709083

Epoch: 5| Step: 6
Training loss: 2.021701966889785
Validation loss: 2.4783092252418557

Epoch: 5| Step: 7
Training loss: 2.284955712020694
Validation loss: 2.4735580547106673

Epoch: 5| Step: 8
Training loss: 2.2344964267841276
Validation loss: 2.4788639152260594

Epoch: 5| Step: 9
Training loss: 2.1100163367845766
Validation loss: 2.4744826084606637

Epoch: 5| Step: 10
Training loss: 2.5712388986691885
Validation loss: 2.4930331389620153

Epoch: 215| Step: 0
Training loss: 2.2593928419492944
Validation loss: 2.5300044523990572

Epoch: 5| Step: 1
Training loss: 2.024198411127497
Validation loss: 2.570146560486448

Epoch: 5| Step: 2
Training loss: 1.673884102632016
Validation loss: 2.6049588104087937

Epoch: 5| Step: 3
Training loss: 2.254205799526985
Validation loss: 2.641862824157647

Epoch: 5| Step: 4
Training loss: 2.334878024197071
Validation loss: 2.6232760716699985

Epoch: 5| Step: 5
Training loss: 2.187748813102678
Validation loss: 2.6177145170043405

Epoch: 5| Step: 6
Training loss: 2.024105123895937
Validation loss: 2.612323561163103

Epoch: 5| Step: 7
Training loss: 2.5829147697089363
Validation loss: 2.5795106606499076

Epoch: 5| Step: 8
Training loss: 2.0764523995792694
Validation loss: 2.561915836534171

Epoch: 5| Step: 9
Training loss: 2.1478256186555456
Validation loss: 2.544721280484814

Epoch: 5| Step: 10
Training loss: 2.298355352099393
Validation loss: 2.5097485552210848

Epoch: 216| Step: 0
Training loss: 2.089328253083584
Validation loss: 2.4955358754026284

Epoch: 5| Step: 1
Training loss: 1.8546782084411448
Validation loss: 2.4640640870026105

Epoch: 5| Step: 2
Training loss: 2.0333101828877966
Validation loss: 2.4785550518551385

Epoch: 5| Step: 3
Training loss: 2.6291044934191747
Validation loss: 2.472222191381721

Epoch: 5| Step: 4
Training loss: 2.475306821358371
Validation loss: 2.4753888774005555

Epoch: 5| Step: 5
Training loss: 1.9178637069869904
Validation loss: 2.481671440636546

Epoch: 5| Step: 6
Training loss: 1.5876576533094087
Validation loss: 2.4998254304869447

Epoch: 5| Step: 7
Training loss: 2.30345757204118
Validation loss: 2.513066530564002

Epoch: 5| Step: 8
Training loss: 2.265704344313769
Validation loss: 2.504383108748908

Epoch: 5| Step: 9
Training loss: 2.413076353652306
Validation loss: 2.552020010414768

Epoch: 5| Step: 10
Training loss: 1.8736992456689026
Validation loss: 2.5445032934997247

Epoch: 217| Step: 0
Training loss: 2.0901597399103937
Validation loss: 2.527752938776387

Epoch: 5| Step: 1
Training loss: 2.004141096664443
Validation loss: 2.5156210561303705

Epoch: 5| Step: 2
Training loss: 1.9684920974623206
Validation loss: 2.517983824348897

Epoch: 5| Step: 3
Training loss: 1.8922577420465758
Validation loss: 2.510158123321808

Epoch: 5| Step: 4
Training loss: 2.398154972098892
Validation loss: 2.5294337408674052

Epoch: 5| Step: 5
Training loss: 2.558187903910713
Validation loss: 2.5472700370175456

Epoch: 5| Step: 6
Training loss: 2.116758521282164
Validation loss: 2.538316565051214

Epoch: 5| Step: 7
Training loss: 1.9238386589575185
Validation loss: 2.546649257757395

Epoch: 5| Step: 8
Training loss: 2.0039561007063877
Validation loss: 2.550477753678337

Epoch: 5| Step: 9
Training loss: 2.3030435162108933
Validation loss: 2.543363809114967

Epoch: 5| Step: 10
Training loss: 2.1810548930092475
Validation loss: 2.524378360978138

Epoch: 218| Step: 0
Training loss: 2.1430760294519358
Validation loss: 2.513456459209773

Epoch: 5| Step: 1
Training loss: 1.7253367357947649
Validation loss: 2.516795906054905

Epoch: 5| Step: 2
Training loss: 1.8974248123853013
Validation loss: 2.521806227304928

Epoch: 5| Step: 3
Training loss: 2.233782816487344
Validation loss: 2.538946671916377

Epoch: 5| Step: 4
Training loss: 2.2316520478289945
Validation loss: 2.541960535017872

Epoch: 5| Step: 5
Training loss: 2.1031481351897794
Validation loss: 2.5387597970554414

Epoch: 5| Step: 6
Training loss: 1.9202159140300188
Validation loss: 2.5625957067961522

Epoch: 5| Step: 7
Training loss: 2.518575797671077
Validation loss: 2.545738318362507

Epoch: 5| Step: 8
Training loss: 1.9352052081017117
Validation loss: 2.5734060485576773

Epoch: 5| Step: 9
Training loss: 2.2425441126062298
Validation loss: 2.5503679455222708

Epoch: 5| Step: 10
Training loss: 2.4122188898468937
Validation loss: 2.5549943492618135

Epoch: 219| Step: 0
Training loss: 2.224367686230436
Validation loss: 2.525291915332464

Epoch: 5| Step: 1
Training loss: 2.299288772413712
Validation loss: 2.494837798498459

Epoch: 5| Step: 2
Training loss: 1.6979761249764351
Validation loss: 2.4881799636404227

Epoch: 5| Step: 3
Training loss: 1.7963431193107073
Validation loss: 2.4850420807931033

Epoch: 5| Step: 4
Training loss: 2.50406335584787
Validation loss: 2.47287339095247

Epoch: 5| Step: 5
Training loss: 1.8852086944810185
Validation loss: 2.481572061176705

Epoch: 5| Step: 6
Training loss: 2.796444481475732
Validation loss: 2.4836621635868603

Epoch: 5| Step: 7
Training loss: 2.009548876226603
Validation loss: 2.508477555582421

Epoch: 5| Step: 8
Training loss: 1.7747037291082812
Validation loss: 2.5206713040039004

Epoch: 5| Step: 9
Training loss: 1.8787360798313084
Validation loss: 2.5602550802606725

Epoch: 5| Step: 10
Training loss: 2.1240653058014307
Validation loss: 2.5486979736923856

Epoch: 220| Step: 0
Training loss: 2.411000306454184
Validation loss: 2.57041951127017

Epoch: 5| Step: 1
Training loss: 2.087190173336304
Validation loss: 2.555660691007641

Epoch: 5| Step: 2
Training loss: 2.2670974682020995
Validation loss: 2.5204599823190543

Epoch: 5| Step: 3
Training loss: 1.9642116978559467
Validation loss: 2.490230510337898

Epoch: 5| Step: 4
Training loss: 2.330082831813666
Validation loss: 2.4685492308665586

Epoch: 5| Step: 5
Training loss: 2.146521473391305
Validation loss: 2.483831215978383

Epoch: 5| Step: 6
Training loss: 1.663315152977998
Validation loss: 2.484163555595149

Epoch: 5| Step: 7
Training loss: 2.1605864332761
Validation loss: 2.4929030374189844

Epoch: 5| Step: 8
Training loss: 1.6841816240892553
Validation loss: 2.5098062320369054

Epoch: 5| Step: 9
Training loss: 2.4842009093509363
Validation loss: 2.54182909912642

Epoch: 5| Step: 10
Training loss: 1.8615593141199054
Validation loss: 2.537718774277543

Epoch: 221| Step: 0
Training loss: 2.270986592665166
Validation loss: 2.558380974291305

Epoch: 5| Step: 1
Training loss: 1.9095087182504464
Validation loss: 2.5507250655595852

Epoch: 5| Step: 2
Training loss: 2.332140538196333
Validation loss: 2.5391283646111087

Epoch: 5| Step: 3
Training loss: 1.6836693695858291
Validation loss: 2.5273319509174725

Epoch: 5| Step: 4
Training loss: 2.1771625948505786
Validation loss: 2.541599031379244

Epoch: 5| Step: 5
Training loss: 2.2768431648250815
Validation loss: 2.5655559322908945

Epoch: 5| Step: 6
Training loss: 2.025330707248662
Validation loss: 2.5525030685393024

Epoch: 5| Step: 7
Training loss: 2.0785588550140512
Validation loss: 2.5504527873685268

Epoch: 5| Step: 8
Training loss: 2.1245890949373387
Validation loss: 2.558926588633151

Epoch: 5| Step: 9
Training loss: 2.280835884863091
Validation loss: 2.5428304400080854

Epoch: 5| Step: 10
Training loss: 1.690879193444381
Validation loss: 2.5492453235933206

Epoch: 222| Step: 0
Training loss: 1.647166118913669
Validation loss: 2.557597194447003

Epoch: 5| Step: 1
Training loss: 2.3305831323547346
Validation loss: 2.5381816901868444

Epoch: 5| Step: 2
Training loss: 1.6936442521645492
Validation loss: 2.540669967147877

Epoch: 5| Step: 3
Training loss: 2.027731327355155
Validation loss: 2.5415632393980068

Epoch: 5| Step: 4
Training loss: 1.898973616892346
Validation loss: 2.551192757119165

Epoch: 5| Step: 5
Training loss: 2.0274880418530654
Validation loss: 2.543634308327283

Epoch: 5| Step: 6
Training loss: 1.9540009632362014
Validation loss: 2.5430322290768625

Epoch: 5| Step: 7
Training loss: 2.394010353371932
Validation loss: 2.538967405546764

Epoch: 5| Step: 8
Training loss: 2.362195684623442
Validation loss: 2.5525784800504736

Epoch: 5| Step: 9
Training loss: 2.190102255537278
Validation loss: 2.591224235296287

Epoch: 5| Step: 10
Training loss: 2.2647974015461183
Validation loss: 2.6013459619277883

Epoch: 223| Step: 0
Training loss: 2.2292359480980206
Validation loss: 2.589486262970052

Epoch: 5| Step: 1
Training loss: 2.4511322869375345
Validation loss: 2.6145548191206274

Epoch: 5| Step: 2
Training loss: 1.1450223422473491
Validation loss: 2.5897812421343476

Epoch: 5| Step: 3
Training loss: 2.1931047843812386
Validation loss: 2.5622105188579205

Epoch: 5| Step: 4
Training loss: 1.7545398680624518
Validation loss: 2.5581049872102604

Epoch: 5| Step: 5
Training loss: 2.0206960126750557
Validation loss: 2.5535752523627857

Epoch: 5| Step: 6
Training loss: 1.8795216399192978
Validation loss: 2.5442352092584626

Epoch: 5| Step: 7
Training loss: 2.4684855645437427
Validation loss: 2.5187926789343273

Epoch: 5| Step: 8
Training loss: 1.842544031949867
Validation loss: 2.531380462525364

Epoch: 5| Step: 9
Training loss: 2.1656046856784754
Validation loss: 2.5226346641811626

Epoch: 5| Step: 10
Training loss: 2.2287382504447133
Validation loss: 2.5007496191907848

Epoch: 224| Step: 0
Training loss: 2.1855334570424234
Validation loss: 2.4909986870718925

Epoch: 5| Step: 1
Training loss: 1.823896489891357
Validation loss: 2.520692015059461

Epoch: 5| Step: 2
Training loss: 2.2376227616885536
Validation loss: 2.5061569752651045

Epoch: 5| Step: 3
Training loss: 1.837201791037117
Validation loss: 2.5327376401468693

Epoch: 5| Step: 4
Training loss: 1.5538830233257759
Validation loss: 2.5619244333036018

Epoch: 5| Step: 5
Training loss: 2.367967130987054
Validation loss: 2.571622627633056

Epoch: 5| Step: 6
Training loss: 2.0645790025631636
Validation loss: 2.5736544005065856

Epoch: 5| Step: 7
Training loss: 2.422104953800839
Validation loss: 2.606123234943093

Epoch: 5| Step: 8
Training loss: 1.988440186868783
Validation loss: 2.563419683228739

Epoch: 5| Step: 9
Training loss: 2.081711964701047
Validation loss: 2.5266735667207727

Epoch: 5| Step: 10
Training loss: 1.8477917998515836
Validation loss: 2.5253322107831666

Epoch: 225| Step: 0
Training loss: 2.305040028652736
Validation loss: 2.49535508316585

Epoch: 5| Step: 1
Training loss: 1.6778572224059791
Validation loss: 2.4852677970831025

Epoch: 5| Step: 2
Training loss: 1.6997136940807718
Validation loss: 2.505619996532166

Epoch: 5| Step: 3
Training loss: 2.1313970431169587
Validation loss: 2.499076992815618

Epoch: 5| Step: 4
Training loss: 2.385571192993326
Validation loss: 2.5316103434795654

Epoch: 5| Step: 5
Training loss: 1.8455050246078066
Validation loss: 2.520668774607287

Epoch: 5| Step: 6
Training loss: 2.1713827110409665
Validation loss: 2.53134476152487

Epoch: 5| Step: 7
Training loss: 2.465785020632345
Validation loss: 2.5471555383080893

Epoch: 5| Step: 8
Training loss: 2.091175831302063
Validation loss: 2.5571429513866226

Epoch: 5| Step: 9
Training loss: 1.589613839286302
Validation loss: 2.567842907607149

Epoch: 5| Step: 10
Training loss: 1.851870225532652
Validation loss: 2.575781431779143

Epoch: 226| Step: 0
Training loss: 1.2878261301253815
Validation loss: 2.587581913575721

Epoch: 5| Step: 1
Training loss: 2.2075983179820393
Validation loss: 2.579178132574036

Epoch: 5| Step: 2
Training loss: 2.0617464018163902
Validation loss: 2.5764675108667814

Epoch: 5| Step: 3
Training loss: 1.9952172073634806
Validation loss: 2.5996194999239215

Epoch: 5| Step: 4
Training loss: 1.8541976268912361
Validation loss: 2.5960454117973595

Epoch: 5| Step: 5
Training loss: 2.15546248055874
Validation loss: 2.5706923762289033

Epoch: 5| Step: 6
Training loss: 2.3484653088007548
Validation loss: 2.5477005781643527

Epoch: 5| Step: 7
Training loss: 1.7008670222777336
Validation loss: 2.540367287214579

Epoch: 5| Step: 8
Training loss: 1.6205413980395593
Validation loss: 2.51861828518377

Epoch: 5| Step: 9
Training loss: 2.4385899772133346
Validation loss: 2.5436660034762872

Epoch: 5| Step: 10
Training loss: 2.3214756782698767
Validation loss: 2.532323836622048

Epoch: 227| Step: 0
Training loss: 2.67508856724798
Validation loss: 2.515637133220094

Epoch: 5| Step: 1
Training loss: 2.044284724939531
Validation loss: 2.5288503228817576

Epoch: 5| Step: 2
Training loss: 1.8901292135079293
Validation loss: 2.5358299124936137

Epoch: 5| Step: 3
Training loss: 2.0909766433192156
Validation loss: 2.528978600485026

Epoch: 5| Step: 4
Training loss: 1.969359470065284
Validation loss: 2.5498322762478023

Epoch: 5| Step: 5
Training loss: 1.6242015784504078
Validation loss: 2.5568458822371305

Epoch: 5| Step: 6
Training loss: 1.4897309699177008
Validation loss: 2.557626663747574

Epoch: 5| Step: 7
Training loss: 2.097692848042583
Validation loss: 2.5439520462233904

Epoch: 5| Step: 8
Training loss: 2.4461112865792853
Validation loss: 2.534353723587539

Epoch: 5| Step: 9
Training loss: 1.6793179127594835
Validation loss: 2.5271096143368816

Epoch: 5| Step: 10
Training loss: 1.7976475257446316
Validation loss: 2.538535965941501

Epoch: 228| Step: 0
Training loss: 1.9302914558487547
Validation loss: 2.5315530621631512

Epoch: 5| Step: 1
Training loss: 2.12697935482277
Validation loss: 2.52730450809965

Epoch: 5| Step: 2
Training loss: 1.7869416705379695
Validation loss: 2.5590506828153

Epoch: 5| Step: 3
Training loss: 2.2638206926721374
Validation loss: 2.553582336165473

Epoch: 5| Step: 4
Training loss: 2.348561954817295
Validation loss: 2.5742644769134353

Epoch: 5| Step: 5
Training loss: 2.007522146404478
Validation loss: 2.5860187381566444

Epoch: 5| Step: 6
Training loss: 2.2791136052605174
Validation loss: 2.558143520124482

Epoch: 5| Step: 7
Training loss: 1.8249613457335558
Validation loss: 2.5663819980479063

Epoch: 5| Step: 8
Training loss: 1.8967904689499484
Validation loss: 2.589857816190094

Epoch: 5| Step: 9
Training loss: 1.3920875744648946
Validation loss: 2.5756378557010513

Epoch: 5| Step: 10
Training loss: 2.0728750815765045
Validation loss: 2.5699663474911056

Epoch: 229| Step: 0
Training loss: 2.4780698214493526
Validation loss: 2.600133282863505

Epoch: 5| Step: 1
Training loss: 1.774776205541896
Validation loss: 2.6008952295532

Epoch: 5| Step: 2
Training loss: 1.6473049956065862
Validation loss: 2.6017486073097187

Epoch: 5| Step: 3
Training loss: 1.9200641195200323
Validation loss: 2.6092159445539576

Epoch: 5| Step: 4
Training loss: 1.531659441333508
Validation loss: 2.5988075277862426

Epoch: 5| Step: 5
Training loss: 1.984653062937616
Validation loss: 2.622574428289433

Epoch: 5| Step: 6
Training loss: 2.1965210326933384
Validation loss: 2.562503631613234

Epoch: 5| Step: 7
Training loss: 2.2382405595259702
Validation loss: 2.548886161674333

Epoch: 5| Step: 8
Training loss: 2.312263476673686
Validation loss: 2.5253717421953876

Epoch: 5| Step: 9
Training loss: 1.706858541101296
Validation loss: 2.5212361024074976

Epoch: 5| Step: 10
Training loss: 1.9969059137330436
Validation loss: 2.531181690018991

Epoch: 230| Step: 0
Training loss: 2.2826332183768487
Validation loss: 2.531157345673075

Epoch: 5| Step: 1
Training loss: 2.1879675229327997
Validation loss: 2.5237389577507527

Epoch: 5| Step: 2
Training loss: 1.3862666292973214
Validation loss: 2.5571516133261376

Epoch: 5| Step: 3
Training loss: 2.1532994967814756
Validation loss: 2.553535334827519

Epoch: 5| Step: 4
Training loss: 2.021491687411291
Validation loss: 2.5921621086540845

Epoch: 5| Step: 5
Training loss: 1.9491127612208534
Validation loss: 2.5860258788156547

Epoch: 5| Step: 6
Training loss: 2.044005967655914
Validation loss: 2.572139152378766

Epoch: 5| Step: 7
Training loss: 1.8658602797808683
Validation loss: 2.546226003560568

Epoch: 5| Step: 8
Training loss: 2.0081751158296437
Validation loss: 2.5387763415711375

Epoch: 5| Step: 9
Training loss: 1.988851349344344
Validation loss: 2.5174166332925814

Epoch: 5| Step: 10
Training loss: 2.020943655037403
Validation loss: 2.5102264048985057

Epoch: 231| Step: 0
Training loss: 1.6393706840199453
Validation loss: 2.525295960844861

Epoch: 5| Step: 1
Training loss: 1.971476166014401
Validation loss: 2.5214824289994144

Epoch: 5| Step: 2
Training loss: 2.194012239872357
Validation loss: 2.5561930428072595

Epoch: 5| Step: 3
Training loss: 1.8775888372704637
Validation loss: 2.5550513879995074

Epoch: 5| Step: 4
Training loss: 1.8256749746971594
Validation loss: 2.545835176911682

Epoch: 5| Step: 5
Training loss: 2.0014218997931645
Validation loss: 2.572297807524658

Epoch: 5| Step: 6
Training loss: 1.4508956707937606
Validation loss: 2.571396120864113

Epoch: 5| Step: 7
Training loss: 1.7442405475558802
Validation loss: 2.570743542975234

Epoch: 5| Step: 8
Training loss: 2.4552911804058217
Validation loss: 2.5736924137423216

Epoch: 5| Step: 9
Training loss: 2.3815298161343095
Validation loss: 2.568807830331237

Epoch: 5| Step: 10
Training loss: 1.8295493812454278
Validation loss: 2.5383876436925554

Epoch: 232| Step: 0
Training loss: 1.9970888169604197
Validation loss: 2.560300404715688

Epoch: 5| Step: 1
Training loss: 1.5545251656130536
Validation loss: 2.522933199941219

Epoch: 5| Step: 2
Training loss: 1.9885762113911405
Validation loss: 2.5416676050430196

Epoch: 5| Step: 3
Training loss: 2.2069360763148955
Validation loss: 2.5324045037627236

Epoch: 5| Step: 4
Training loss: 2.2107768185731747
Validation loss: 2.5654932163788446

Epoch: 5| Step: 5
Training loss: 1.4095439479751948
Validation loss: 2.541642107375047

Epoch: 5| Step: 6
Training loss: 1.7271339540996966
Validation loss: 2.5796426193731574

Epoch: 5| Step: 7
Training loss: 2.2125018620887293
Validation loss: 2.6158901897247566

Epoch: 5| Step: 8
Training loss: 1.8917567121049654
Validation loss: 2.581259304431999

Epoch: 5| Step: 9
Training loss: 1.9280999328863349
Validation loss: 2.6052307245504513

Epoch: 5| Step: 10
Training loss: 2.160967545152211
Validation loss: 2.621790162286845

Epoch: 233| Step: 0
Training loss: 1.8685990747853907
Validation loss: 2.5672129697953445

Epoch: 5| Step: 1
Training loss: 2.055159713961457
Validation loss: 2.5771487001162634

Epoch: 5| Step: 2
Training loss: 1.9704926059819388
Validation loss: 2.556982078598429

Epoch: 5| Step: 3
Training loss: 1.824780984042943
Validation loss: 2.539208581349107

Epoch: 5| Step: 4
Training loss: 2.2357072393079105
Validation loss: 2.536730818346456

Epoch: 5| Step: 5
Training loss: 2.0662901761025507
Validation loss: 2.5411774177714492

Epoch: 5| Step: 6
Training loss: 1.9660983924110607
Validation loss: 2.5411336256809007

Epoch: 5| Step: 7
Training loss: 1.7787348742187075
Validation loss: 2.6059935319954177

Epoch: 5| Step: 8
Training loss: 2.159999738269366
Validation loss: 2.618407558275958

Epoch: 5| Step: 9
Training loss: 1.650190677606966
Validation loss: 2.641703494691155

Epoch: 5| Step: 10
Training loss: 1.6559395409157711
Validation loss: 2.6274962053899604

Epoch: 234| Step: 0
Training loss: 1.5295441915931214
Validation loss: 2.6471918261871945

Epoch: 5| Step: 1
Training loss: 1.845128142396127
Validation loss: 2.6252705873566646

Epoch: 5| Step: 2
Training loss: 1.6654797460262998
Validation loss: 2.6077041262433824

Epoch: 5| Step: 3
Training loss: 2.458718210469608
Validation loss: 2.567005890988246

Epoch: 5| Step: 4
Training loss: 1.8053159073792047
Validation loss: 2.5439158671149613

Epoch: 5| Step: 5
Training loss: 1.9894120573714467
Validation loss: 2.518021735237427

Epoch: 5| Step: 6
Training loss: 1.6107504439139446
Validation loss: 2.507919233093649

Epoch: 5| Step: 7
Training loss: 1.954032504011486
Validation loss: 2.5383756500215466

Epoch: 5| Step: 8
Training loss: 2.4581951059392186
Validation loss: 2.5528633223258153

Epoch: 5| Step: 9
Training loss: 1.9772061592862744
Validation loss: 2.6155276294280148

Epoch: 5| Step: 10
Training loss: 1.778777564901449
Validation loss: 2.581913069062551

Epoch: 235| Step: 0
Training loss: 1.2051983097926764
Validation loss: 2.618559660413679

Epoch: 5| Step: 1
Training loss: 2.454000523312986
Validation loss: 2.6402468623264737

Epoch: 5| Step: 2
Training loss: 2.099732236594244
Validation loss: 2.6566563063278608

Epoch: 5| Step: 3
Training loss: 1.8221163346117972
Validation loss: 2.537510625159383

Epoch: 5| Step: 4
Training loss: 1.7812255723851003
Validation loss: 2.5374085830603614

Epoch: 5| Step: 5
Training loss: 2.2111762359374505
Validation loss: 2.522350847767492

Epoch: 5| Step: 6
Training loss: 1.8071192092037518
Validation loss: 2.4953868305991125

Epoch: 5| Step: 7
Training loss: 2.4365027906502457
Validation loss: 2.4575335531435627

Epoch: 5| Step: 8
Training loss: 1.9629017995639633
Validation loss: 2.471741535311143

Epoch: 5| Step: 9
Training loss: 2.043062226179194
Validation loss: 2.472691275838381

Epoch: 5| Step: 10
Training loss: 1.1878089001085927
Validation loss: 2.538008275175668

Epoch: 236| Step: 0
Training loss: 1.6178942624071062
Validation loss: 2.5902820605340913

Epoch: 5| Step: 1
Training loss: 2.162312485166818
Validation loss: 2.614792467385142

Epoch: 5| Step: 2
Training loss: 2.2333753790622097
Validation loss: 2.650849811646786

Epoch: 5| Step: 3
Training loss: 1.8576509833808685
Validation loss: 2.6256236123255747

Epoch: 5| Step: 4
Training loss: 1.9002375604789215
Validation loss: 2.5520152769542825

Epoch: 5| Step: 5
Training loss: 1.6104292888401677
Validation loss: 2.5269281196741544

Epoch: 5| Step: 6
Training loss: 1.7749737374955237
Validation loss: 2.5004537785841205

Epoch: 5| Step: 7
Training loss: 1.9194269483437176
Validation loss: 2.437131843919391

Epoch: 5| Step: 8
Training loss: 2.3732384623985765
Validation loss: 2.447800378038015

Epoch: 5| Step: 9
Training loss: 1.6186345946660736
Validation loss: 2.4425981397354493

Epoch: 5| Step: 10
Training loss: 1.9031575868820196
Validation loss: 2.4273246008996057

Epoch: 237| Step: 0
Training loss: 1.9336063885516561
Validation loss: 2.436115101275446

Epoch: 5| Step: 1
Training loss: 1.9285855873032214
Validation loss: 2.4576290864108246

Epoch: 5| Step: 2
Training loss: 1.7805973664345793
Validation loss: 2.473820341673423

Epoch: 5| Step: 3
Training loss: 1.8425125236551445
Validation loss: 2.501179374900657

Epoch: 5| Step: 4
Training loss: 1.2747714305272537
Validation loss: 2.5257614885299877

Epoch: 5| Step: 5
Training loss: 2.0573580831760103
Validation loss: 2.561306010716616

Epoch: 5| Step: 6
Training loss: 1.753756918210382
Validation loss: 2.5990412934341554

Epoch: 5| Step: 7
Training loss: 1.9048277755541851
Validation loss: 2.607314854437663

Epoch: 5| Step: 8
Training loss: 1.960299445068829
Validation loss: 2.6409597556618842

Epoch: 5| Step: 9
Training loss: 1.9496805565171278
Validation loss: 2.620400199181019

Epoch: 5| Step: 10
Training loss: 2.465911392191663
Validation loss: 2.586026300136721

Epoch: 238| Step: 0
Training loss: 1.429059083335157
Validation loss: 2.5521560012352884

Epoch: 5| Step: 1
Training loss: 2.080184948107971
Validation loss: 2.51921408023323

Epoch: 5| Step: 2
Training loss: 1.9980677569091472
Validation loss: 2.510877064008977

Epoch: 5| Step: 3
Training loss: 1.885581738181489
Validation loss: 2.5250638648515173

Epoch: 5| Step: 4
Training loss: 1.835665678639259
Validation loss: 2.5492554313301894

Epoch: 5| Step: 5
Training loss: 1.3633730182530126
Validation loss: 2.5247939348279216

Epoch: 5| Step: 6
Training loss: 1.9332977993209879
Validation loss: 2.5428606621563783

Epoch: 5| Step: 7
Training loss: 2.3640100285467445
Validation loss: 2.5469592797855682

Epoch: 5| Step: 8
Training loss: 1.7358245977705995
Validation loss: 2.5894544861348012

Epoch: 5| Step: 9
Training loss: 1.9908698417964161
Validation loss: 2.6052919466104423

Epoch: 5| Step: 10
Training loss: 1.7501711761680006
Validation loss: 2.611199220571348

Epoch: 239| Step: 0
Training loss: 2.0739968966071842
Validation loss: 2.6122190477181735

Epoch: 5| Step: 1
Training loss: 2.0179829371385973
Validation loss: 2.607597625549992

Epoch: 5| Step: 2
Training loss: 1.5522154510727795
Validation loss: 2.642180346213432

Epoch: 5| Step: 3
Training loss: 1.2791628235915582
Validation loss: 2.6207595401102615

Epoch: 5| Step: 4
Training loss: 2.079973359670964
Validation loss: 2.6126167507964766

Epoch: 5| Step: 5
Training loss: 1.565597058806388
Validation loss: 2.6246538534632156

Epoch: 5| Step: 6
Training loss: 1.7906586302683207
Validation loss: 2.6129345478635013

Epoch: 5| Step: 7
Training loss: 2.3700847961450595
Validation loss: 2.6038644673552436

Epoch: 5| Step: 8
Training loss: 1.698741486270502
Validation loss: 2.56101390606494

Epoch: 5| Step: 9
Training loss: 1.645185979052267
Validation loss: 2.538407343796583

Epoch: 5| Step: 10
Training loss: 2.2028086550155854
Validation loss: 2.5468712635618083

Epoch: 240| Step: 0
Training loss: 2.4461887727383873
Validation loss: 2.563327480624025

Epoch: 5| Step: 1
Training loss: 1.7167945835762226
Validation loss: 2.5398434784392343

Epoch: 5| Step: 2
Training loss: 1.444036466904151
Validation loss: 2.5326213284476076

Epoch: 5| Step: 3
Training loss: 1.6984786603304083
Validation loss: 2.5582494119973798

Epoch: 5| Step: 4
Training loss: 1.768367494126732
Validation loss: 2.535605523470809

Epoch: 5| Step: 5
Training loss: 1.7769193373122165
Validation loss: 2.5476835441949266

Epoch: 5| Step: 6
Training loss: 1.6701742059679403
Validation loss: 2.5822610015518346

Epoch: 5| Step: 7
Training loss: 1.930697281146001
Validation loss: 2.588216884089507

Epoch: 5| Step: 8
Training loss: 1.8751110679790919
Validation loss: 2.577664708289547

Epoch: 5| Step: 9
Training loss: 1.7004520544501225
Validation loss: 2.593800817654769

Epoch: 5| Step: 10
Training loss: 2.18235566281339
Validation loss: 2.5518713502487436

Epoch: 241| Step: 0
Training loss: 1.7477975337183853
Validation loss: 2.5212662427745283

Epoch: 5| Step: 1
Training loss: 1.8118578332283166
Validation loss: 2.5305210199673946

Epoch: 5| Step: 2
Training loss: 1.6461447006762726
Validation loss: 2.5105276139863193

Epoch: 5| Step: 3
Training loss: 1.9964784374682425
Validation loss: 2.5017769845763445

Epoch: 5| Step: 4
Training loss: 1.8077045009470272
Validation loss: 2.5244812257938327

Epoch: 5| Step: 5
Training loss: 2.0164932628304335
Validation loss: 2.5617166297696494

Epoch: 5| Step: 6
Training loss: 1.7689507144770946
Validation loss: 2.566378765502507

Epoch: 5| Step: 7
Training loss: 1.8993559448451218
Validation loss: 2.5836709708580363

Epoch: 5| Step: 8
Training loss: 1.7381384630172227
Validation loss: 2.611484050808576

Epoch: 5| Step: 9
Training loss: 1.9400157592565943
Validation loss: 2.5901135367984094

Epoch: 5| Step: 10
Training loss: 1.7748459923783182
Validation loss: 2.5979439327458667

Epoch: 242| Step: 0
Training loss: 1.7219113493196365
Validation loss: 2.6094472893662597

Epoch: 5| Step: 1
Training loss: 1.305314147670547
Validation loss: 2.591992098444868

Epoch: 5| Step: 2
Training loss: 1.834092337098661
Validation loss: 2.5747146458688794

Epoch: 5| Step: 3
Training loss: 2.0078485982893093
Validation loss: 2.567369999171748

Epoch: 5| Step: 4
Training loss: 1.5213418484922299
Validation loss: 2.5197511928490783

Epoch: 5| Step: 5
Training loss: 1.3641847605933575
Validation loss: 2.4919692466068906

Epoch: 5| Step: 6
Training loss: 2.30202669330038
Validation loss: 2.4906175912180815

Epoch: 5| Step: 7
Training loss: 1.8846152131935412
Validation loss: 2.481105586718595

Epoch: 5| Step: 8
Training loss: 1.9154550897067761
Validation loss: 2.4974623803873452

Epoch: 5| Step: 9
Training loss: 1.9885425208602623
Validation loss: 2.4970025171547983

Epoch: 5| Step: 10
Training loss: 2.0049505951614086
Validation loss: 2.519276651802289

Epoch: 243| Step: 0
Training loss: 1.360938433746473
Validation loss: 2.54248745288722

Epoch: 5| Step: 1
Training loss: 2.422933925349618
Validation loss: 2.5683685900219

Epoch: 5| Step: 2
Training loss: 1.9279773872046606
Validation loss: 2.6306792115605293

Epoch: 5| Step: 3
Training loss: 1.7443723108208709
Validation loss: 2.679850489849804

Epoch: 5| Step: 4
Training loss: 1.5039654608625994
Validation loss: 2.6662682883331446

Epoch: 5| Step: 5
Training loss: 2.022656146270879
Validation loss: 2.635186338316296

Epoch: 5| Step: 6
Training loss: 1.9174513730842564
Validation loss: 2.628397183364864

Epoch: 5| Step: 7
Training loss: 1.7267772144047002
Validation loss: 2.5923896223821736

Epoch: 5| Step: 8
Training loss: 1.6079571598618696
Validation loss: 2.5689211703811203

Epoch: 5| Step: 9
Training loss: 1.3266812724039498
Validation loss: 2.568392655526512

Epoch: 5| Step: 10
Training loss: 2.0573877497258914
Validation loss: 2.5501995019084354

Epoch: 244| Step: 0
Training loss: 1.9364182928937927
Validation loss: 2.533254208999516

Epoch: 5| Step: 1
Training loss: 1.9780501244522548
Validation loss: 2.5315899303554006

Epoch: 5| Step: 2
Training loss: 2.0115844681746076
Validation loss: 2.5405382253331705

Epoch: 5| Step: 3
Training loss: 1.5765185347174377
Validation loss: 2.5479150949997735

Epoch: 5| Step: 4
Training loss: 1.7023833173518819
Validation loss: 2.577641675185766

Epoch: 5| Step: 5
Training loss: 1.4673453574120514
Validation loss: 2.608674000717747

Epoch: 5| Step: 6
Training loss: 1.4090508437123999
Validation loss: 2.646242598575211

Epoch: 5| Step: 7
Training loss: 1.5652990066516395
Validation loss: 2.638077396934398

Epoch: 5| Step: 8
Training loss: 2.2014884551830933
Validation loss: 2.647706132912213

Epoch: 5| Step: 9
Training loss: 1.8053085117385177
Validation loss: 2.6430690120177385

Epoch: 5| Step: 10
Training loss: 1.8628375726761772
Validation loss: 2.6293337685115135

Epoch: 245| Step: 0
Training loss: 1.9095644043726363
Validation loss: 2.5988229916136354

Epoch: 5| Step: 1
Training loss: 1.5898618954834427
Validation loss: 2.570417537488558

Epoch: 5| Step: 2
Training loss: 2.0368269434711794
Validation loss: 2.5225894891998077

Epoch: 5| Step: 3
Training loss: 2.104572735371248
Validation loss: 2.5383439423424883

Epoch: 5| Step: 4
Training loss: 1.5888280224794216
Validation loss: 2.5201559096412236

Epoch: 5| Step: 5
Training loss: 1.6566840988459872
Validation loss: 2.532205253294917

Epoch: 5| Step: 6
Training loss: 1.8843187820373886
Validation loss: 2.554355726863239

Epoch: 5| Step: 7
Training loss: 1.5796779130442893
Validation loss: 2.5625212733768565

Epoch: 5| Step: 8
Training loss: 1.67683885897243
Validation loss: 2.6077032040930064

Epoch: 5| Step: 9
Training loss: 1.4519023058159062
Validation loss: 2.575429460470399

Epoch: 5| Step: 10
Training loss: 1.8033532829497414
Validation loss: 2.5821152242244927

Epoch: 246| Step: 0
Training loss: 1.7286171403805928
Validation loss: 2.5446587593239047

Epoch: 5| Step: 1
Training loss: 1.1056775546265705
Validation loss: 2.563409803358186

Epoch: 5| Step: 2
Training loss: 1.928642947773153
Validation loss: 2.5423390934468713

Epoch: 5| Step: 3
Training loss: 1.9180138110676916
Validation loss: 2.538135564710038

Epoch: 5| Step: 4
Training loss: 2.1256485117750707
Validation loss: 2.545056009894533

Epoch: 5| Step: 5
Training loss: 2.336755717707934
Validation loss: 2.5317533968058337

Epoch: 5| Step: 6
Training loss: 1.375545610202059
Validation loss: 2.570491709344651

Epoch: 5| Step: 7
Training loss: 2.0907172258274387
Validation loss: 2.563925446929564

Epoch: 5| Step: 8
Training loss: 1.3746391603191976
Validation loss: 2.571641645350135

Epoch: 5| Step: 9
Training loss: 0.9164907691270107
Validation loss: 2.5612709205209567

Epoch: 5| Step: 10
Training loss: 1.7507951837178413
Validation loss: 2.581114771661975

Epoch: 247| Step: 0
Training loss: 1.5807103800613018
Validation loss: 2.5724830333431994

Epoch: 5| Step: 1
Training loss: 2.2668419036258207
Validation loss: 2.524616156803544

Epoch: 5| Step: 2
Training loss: 1.5236192643720095
Validation loss: 2.5308772554144188

Epoch: 5| Step: 3
Training loss: 1.638202950239593
Validation loss: 2.5547336086128607

Epoch: 5| Step: 4
Training loss: 1.28315941490849
Validation loss: 2.5417113576746067

Epoch: 5| Step: 5
Training loss: 1.5506969207973196
Validation loss: 2.537401647079639

Epoch: 5| Step: 6
Training loss: 1.629672375734103
Validation loss: 2.5196150433590194

Epoch: 5| Step: 7
Training loss: 1.2143275399978697
Validation loss: 2.5486566323935116

Epoch: 5| Step: 8
Training loss: 1.8781195438959524
Validation loss: 2.5172662371469676

Epoch: 5| Step: 9
Training loss: 2.1848944268811277
Validation loss: 2.510629168971811

Epoch: 5| Step: 10
Training loss: 1.9504710973315853
Validation loss: 2.5368850587245664

Epoch: 248| Step: 0
Training loss: 1.6106269189233269
Validation loss: 2.527051567532182

Epoch: 5| Step: 1
Training loss: 1.6190471185020934
Validation loss: 2.5215190596158616

Epoch: 5| Step: 2
Training loss: 1.6588270902794378
Validation loss: 2.533248659212765

Epoch: 5| Step: 3
Training loss: 1.8228823486004218
Validation loss: 2.525053437929627

Epoch: 5| Step: 4
Training loss: 2.178882628019084
Validation loss: 2.5699168810708857

Epoch: 5| Step: 5
Training loss: 1.971452099993393
Validation loss: 2.554978443567986

Epoch: 5| Step: 6
Training loss: 1.6388910485736532
Validation loss: 2.586476969289499

Epoch: 5| Step: 7
Training loss: 1.15695076404284
Validation loss: 2.568084369436112

Epoch: 5| Step: 8
Training loss: 2.150508811537059
Validation loss: 2.550729113952109

Epoch: 5| Step: 9
Training loss: 1.31103347408819
Validation loss: 2.5374209364345703

Epoch: 5| Step: 10
Training loss: 1.495990958803569
Validation loss: 2.513027790529003

Epoch: 249| Step: 0
Training loss: 1.6613838234898815
Validation loss: 2.5428038848103633

Epoch: 5| Step: 1
Training loss: 1.85226420694701
Validation loss: 2.5742203648363406

Epoch: 5| Step: 2
Training loss: 1.5709826809069911
Validation loss: 2.566131813368685

Epoch: 5| Step: 3
Training loss: 2.198208998874851
Validation loss: 2.5607580931936096

Epoch: 5| Step: 4
Training loss: 1.3938942958565923
Validation loss: 2.581999630630726

Epoch: 5| Step: 5
Training loss: 1.4941196415244287
Validation loss: 2.6058119789333447

Epoch: 5| Step: 6
Training loss: 1.5280376916450762
Validation loss: 2.5852673231610144

Epoch: 5| Step: 7
Training loss: 2.2013710561431825
Validation loss: 2.6203971995908457

Epoch: 5| Step: 8
Training loss: 1.4887857858503024
Validation loss: 2.620561348240763

Epoch: 5| Step: 9
Training loss: 1.395684713545955
Validation loss: 2.6109212708027267

Epoch: 5| Step: 10
Training loss: 1.7002779761414701
Validation loss: 2.5823010682244276

Epoch: 250| Step: 0
Training loss: 1.5910564174803314
Validation loss: 2.5543746704023307

Epoch: 5| Step: 1
Training loss: 1.7007548787951077
Validation loss: 2.5262593320929607

Epoch: 5| Step: 2
Training loss: 1.3657859812114392
Validation loss: 2.507517574473109

Epoch: 5| Step: 3
Training loss: 1.4112680548568022
Validation loss: 2.5240030089664436

Epoch: 5| Step: 4
Training loss: 1.6420449061601317
Validation loss: 2.533274764558898

Epoch: 5| Step: 5
Training loss: 2.0739026304690644
Validation loss: 2.5448882281019305

Epoch: 5| Step: 6
Training loss: 1.5099255081143312
Validation loss: 2.578814052308249

Epoch: 5| Step: 7
Training loss: 1.922577892258344
Validation loss: 2.601583995937839

Epoch: 5| Step: 8
Training loss: 1.7587037264356211
Validation loss: 2.612298494058895

Epoch: 5| Step: 9
Training loss: 1.6437903975827644
Validation loss: 2.6368272561702497

Epoch: 5| Step: 10
Training loss: 1.9776683021040138
Validation loss: 2.6062497867050904

Epoch: 251| Step: 0
Training loss: 1.7679565024699715
Validation loss: 2.564248369715888

Epoch: 5| Step: 1
Training loss: 2.0150583343013193
Validation loss: 2.542701383148508

Epoch: 5| Step: 2
Training loss: 1.7485140213571895
Validation loss: 2.5139302031432074

Epoch: 5| Step: 3
Training loss: 1.9886371166673695
Validation loss: 2.5502520810409375

Epoch: 5| Step: 4
Training loss: 1.6922231203734888
Validation loss: 2.517725917213681

Epoch: 5| Step: 5
Training loss: 1.8640154465702505
Validation loss: 2.4987714455968724

Epoch: 5| Step: 6
Training loss: 1.4182030350258452
Validation loss: 2.533468954347971

Epoch: 5| Step: 7
Training loss: 1.483742107187182
Validation loss: 2.5599659961959618

Epoch: 5| Step: 8
Training loss: 1.3783107260464855
Validation loss: 2.570612435872433

Epoch: 5| Step: 9
Training loss: 1.4427921073452337
Validation loss: 2.5830463729031226

Epoch: 5| Step: 10
Training loss: 1.4194469470959867
Validation loss: 2.594535011038568

Epoch: 252| Step: 0
Training loss: 1.365798462559724
Validation loss: 2.5638781447482786

Epoch: 5| Step: 1
Training loss: 1.5856454514570526
Validation loss: 2.608831435358896

Epoch: 5| Step: 2
Training loss: 2.1130217500389565
Validation loss: 2.5930440638612255

Epoch: 5| Step: 3
Training loss: 1.6047406924159522
Validation loss: 2.588466691152212

Epoch: 5| Step: 4
Training loss: 1.5396742016616936
Validation loss: 2.5858259547209683

Epoch: 5| Step: 5
Training loss: 1.5994156753954882
Validation loss: 2.543588486328697

Epoch: 5| Step: 6
Training loss: 1.528134036671261
Validation loss: 2.5228483720764463

Epoch: 5| Step: 7
Training loss: 1.7346503924051844
Validation loss: 2.488849898618643

Epoch: 5| Step: 8
Training loss: 1.8479510791875842
Validation loss: 2.505619197447046

Epoch: 5| Step: 9
Training loss: 1.376761824934415
Validation loss: 2.5320902788997626

Epoch: 5| Step: 10
Training loss: 1.8196580881122821
Validation loss: 2.5507516011078124

Epoch: 253| Step: 0
Training loss: 1.4664250091669795
Validation loss: 2.547895086186311

Epoch: 5| Step: 1
Training loss: 1.688138417173337
Validation loss: 2.5533430983666903

Epoch: 5| Step: 2
Training loss: 2.0284959168838506
Validation loss: 2.576386681015212

Epoch: 5| Step: 3
Training loss: 1.3843816270518934
Validation loss: 2.5618648467215084

Epoch: 5| Step: 4
Training loss: 1.3448741557585493
Validation loss: 2.571162710348332

Epoch: 5| Step: 5
Training loss: 1.7853943647180974
Validation loss: 2.5751971920280226

Epoch: 5| Step: 6
Training loss: 1.3793478628720504
Validation loss: 2.5891698830668597

Epoch: 5| Step: 7
Training loss: 1.795067118184167
Validation loss: 2.5759996809127705

Epoch: 5| Step: 8
Training loss: 1.711119759663005
Validation loss: 2.592533376277566

Epoch: 5| Step: 9
Training loss: 1.574280314034439
Validation loss: 2.6051441525512273

Epoch: 5| Step: 10
Training loss: 1.836985317472654
Validation loss: 2.5799241168398814

Epoch: 254| Step: 0
Training loss: 1.8066487410079526
Validation loss: 2.588205708202386

Epoch: 5| Step: 1
Training loss: 1.4084287507653204
Validation loss: 2.5731488040463835

Epoch: 5| Step: 2
Training loss: 1.496693622853287
Validation loss: 2.5631360140860484

Epoch: 5| Step: 3
Training loss: 1.6606374245244508
Validation loss: 2.5381363697187576

Epoch: 5| Step: 4
Training loss: 1.1574244334063544
Validation loss: 2.533672132515928

Epoch: 5| Step: 5
Training loss: 1.9111022478952822
Validation loss: 2.523865763273935

Epoch: 5| Step: 6
Training loss: 1.6857361935838362
Validation loss: 2.5664441967827756

Epoch: 5| Step: 7
Training loss: 1.70147674316421
Validation loss: 2.5572505368101663

Epoch: 5| Step: 8
Training loss: 1.7381138410213457
Validation loss: 2.571050834167347

Epoch: 5| Step: 9
Training loss: 1.4612356279513194
Validation loss: 2.5918798018801423

Epoch: 5| Step: 10
Training loss: 1.4717348489631092
Validation loss: 2.618866530197286

Epoch: 255| Step: 0
Training loss: 1.4293961358352936
Validation loss: 2.607381036111455

Epoch: 5| Step: 1
Training loss: 1.7461577879493766
Validation loss: 2.6111389126457945

Epoch: 5| Step: 2
Training loss: 1.539348285302301
Validation loss: 2.578039669689327

Epoch: 5| Step: 3
Training loss: 1.714273970711311
Validation loss: 2.5927576300842095

Epoch: 5| Step: 4
Training loss: 1.8234391108671655
Validation loss: 2.581271826344338

Epoch: 5| Step: 5
Training loss: 1.3621421799074724
Validation loss: 2.6131654947927183

Epoch: 5| Step: 6
Training loss: 1.632090577781531
Validation loss: 2.6046339633844

Epoch: 5| Step: 7
Training loss: 1.2398958960794346
Validation loss: 2.613235376846496

Epoch: 5| Step: 8
Training loss: 2.0709729562685513
Validation loss: 2.5844209851065063

Epoch: 5| Step: 9
Training loss: 1.243723082131326
Validation loss: 2.5656541470332916

Epoch: 5| Step: 10
Training loss: 1.3141475509353098
Validation loss: 2.5635488166060516

Epoch: 256| Step: 0
Training loss: 1.2895385787831413
Validation loss: 2.560226531399959

Epoch: 5| Step: 1
Training loss: 1.7879095235287918
Validation loss: 2.538690952980361

Epoch: 5| Step: 2
Training loss: 1.673488871892716
Validation loss: 2.5619035052080865

Epoch: 5| Step: 3
Training loss: 2.095966247934754
Validation loss: 2.5542698172793084

Epoch: 5| Step: 4
Training loss: 1.062398569090006
Validation loss: 2.5491466968891543

Epoch: 5| Step: 5
Training loss: 1.5371534251550234
Validation loss: 2.597609748581402

Epoch: 5| Step: 6
Training loss: 1.2143018685396325
Validation loss: 2.5766103830414586

Epoch: 5| Step: 7
Training loss: 1.6011503852394202
Validation loss: 2.60061780209291

Epoch: 5| Step: 8
Training loss: 1.87350289657772
Validation loss: 2.6171899723585557

Epoch: 5| Step: 9
Training loss: 1.288277543099034
Validation loss: 2.5997078790624704

Epoch: 5| Step: 10
Training loss: 1.3909016880420917
Validation loss: 2.589190783352429

Epoch: 257| Step: 0
Training loss: 0.8380928417980215
Validation loss: 2.5346564743213715

Epoch: 5| Step: 1
Training loss: 1.5013690105341313
Validation loss: 2.5778240327742177

Epoch: 5| Step: 2
Training loss: 1.5136324969676307
Validation loss: 2.554136352956048

Epoch: 5| Step: 3
Training loss: 1.8835815505238298
Validation loss: 2.5406708228146586

Epoch: 5| Step: 4
Training loss: 1.609709029115743
Validation loss: 2.5496081804215818

Epoch: 5| Step: 5
Training loss: 1.7958191796591032
Validation loss: 2.5746447110085615

Epoch: 5| Step: 6
Training loss: 1.7419216483459985
Validation loss: 2.5611851618150396

Epoch: 5| Step: 7
Training loss: 1.64591925030599
Validation loss: 2.5397647524514664

Epoch: 5| Step: 8
Training loss: 1.430755966411377
Validation loss: 2.5592293755197666

Epoch: 5| Step: 9
Training loss: 1.5595598405595121
Validation loss: 2.5945445342567917

Epoch: 5| Step: 10
Training loss: 0.9981822838346321
Validation loss: 2.590857387166893

Epoch: 258| Step: 0
Training loss: 1.5182239233573116
Validation loss: 2.5755055678631154

Epoch: 5| Step: 1
Training loss: 1.5279478161523998
Validation loss: 2.585979696653914

Epoch: 5| Step: 2
Training loss: 1.3876457017571313
Validation loss: 2.5835017811942986

Epoch: 5| Step: 3
Training loss: 1.2188284433013694
Validation loss: 2.580374895993532

Epoch: 5| Step: 4
Training loss: 2.14549481088886
Validation loss: 2.5669725375538692

Epoch: 5| Step: 5
Training loss: 1.163708831517838
Validation loss: 2.56534996239698

Epoch: 5| Step: 6
Training loss: 1.3737193125524463
Validation loss: 2.6062127401716655

Epoch: 5| Step: 7
Training loss: 1.3872640907505542
Validation loss: 2.6520861752617795

Epoch: 5| Step: 8
Training loss: 1.4703093833768692
Validation loss: 2.7011583884741293

Epoch: 5| Step: 9
Training loss: 1.4171774261352095
Validation loss: 2.6741312849965233

Epoch: 5| Step: 10
Training loss: 2.075423011405032
Validation loss: 2.7017912221631732

Epoch: 259| Step: 0
Training loss: 1.1491002356895077
Validation loss: 2.6525022431661474

Epoch: 5| Step: 1
Training loss: 1.2640830171520854
Validation loss: 2.6231740567132835

Epoch: 5| Step: 2
Training loss: 1.522368383622335
Validation loss: 2.595436226110723

Epoch: 5| Step: 3
Training loss: 1.1310932662041697
Validation loss: 2.559508239193978

Epoch: 5| Step: 4
Training loss: 1.5055853647578805
Validation loss: 2.5288634560742964

Epoch: 5| Step: 5
Training loss: 2.0081831890453024
Validation loss: 2.530730528036614

Epoch: 5| Step: 6
Training loss: 1.6713174621159153
Validation loss: 2.547215606865989

Epoch: 5| Step: 7
Training loss: 1.6145199506890882
Validation loss: 2.5231007651935027

Epoch: 5| Step: 8
Training loss: 1.3597206903894299
Validation loss: 2.546638216554387

Epoch: 5| Step: 9
Training loss: 1.3578011181950231
Validation loss: 2.591947152115149

Epoch: 5| Step: 10
Training loss: 1.7615615537761686
Validation loss: 2.610239190515882

Epoch: 260| Step: 0
Training loss: 1.1799958186156332
Validation loss: 2.59542918591716

Epoch: 5| Step: 1
Training loss: 1.4228613649552955
Validation loss: 2.5988579614632084

Epoch: 5| Step: 2
Training loss: 1.5646213626769008
Validation loss: 2.578692494888129

Epoch: 5| Step: 3
Training loss: 1.3469128756054494
Validation loss: 2.545532478687133

Epoch: 5| Step: 4
Training loss: 1.5028260946977667
Validation loss: 2.5297164748219547

Epoch: 5| Step: 5
Training loss: 1.6728365263343878
Validation loss: 2.5294519639549846

Epoch: 5| Step: 6
Training loss: 1.4379222913020593
Validation loss: 2.565956401821048

Epoch: 5| Step: 7
Training loss: 1.5655136038311892
Validation loss: 2.544173284774436

Epoch: 5| Step: 8
Training loss: 1.9349264465073484
Validation loss: 2.585421358105768

Epoch: 5| Step: 9
Training loss: 1.0309687144123463
Validation loss: 2.591290160127638

Epoch: 5| Step: 10
Training loss: 1.7763911450633274
Validation loss: 2.622383605874431

Epoch: 261| Step: 0
Training loss: 1.0048876763199226
Validation loss: 2.6151033946574995

Epoch: 5| Step: 1
Training loss: 1.673627487496452
Validation loss: 2.6196109185272474

Epoch: 5| Step: 2
Training loss: 1.707709136375706
Validation loss: 2.6376774309728717

Epoch: 5| Step: 3
Training loss: 1.073949551230388
Validation loss: 2.587928817445529

Epoch: 5| Step: 4
Training loss: 1.5163024489474255
Validation loss: 2.5819185589274785

Epoch: 5| Step: 5
Training loss: 1.3556712766058863
Validation loss: 2.5791968421125704

Epoch: 5| Step: 6
Training loss: 1.8321797975615415
Validation loss: 2.5442029811055327

Epoch: 5| Step: 7
Training loss: 1.3164129058941296
Validation loss: 2.5614854068100406

Epoch: 5| Step: 8
Training loss: 1.2152977981129336
Validation loss: 2.5619580175662517

Epoch: 5| Step: 9
Training loss: 1.5882967984272993
Validation loss: 2.5377478228330057

Epoch: 5| Step: 10
Training loss: 1.713586994101128
Validation loss: 2.568737733657612

Epoch: 262| Step: 0
Training loss: 1.5625144957823685
Validation loss: 2.5764239385056977

Epoch: 5| Step: 1
Training loss: 1.4454593893104122
Validation loss: 2.6050686340300357

Epoch: 5| Step: 2
Training loss: 1.3440933232519283
Validation loss: 2.6015669945123703

Epoch: 5| Step: 3
Training loss: 1.3195190302642676
Validation loss: 2.5988970640043223

Epoch: 5| Step: 4
Training loss: 1.7019739723636051
Validation loss: 2.6162449488341615

Epoch: 5| Step: 5
Training loss: 1.442848125345953
Validation loss: 2.5593455247467523

Epoch: 5| Step: 6
Training loss: 0.8993006001994233
Validation loss: 2.5739487767505373

Epoch: 5| Step: 7
Training loss: 1.340972602791943
Validation loss: 2.5638201184674476

Epoch: 5| Step: 8
Training loss: 1.4319596709214641
Validation loss: 2.5667961287586305

Epoch: 5| Step: 9
Training loss: 1.7086228691309373
Validation loss: 2.607574348067365

Epoch: 5| Step: 10
Training loss: 1.6343627579122952
Validation loss: 2.5423240080564957

Epoch: 263| Step: 0
Training loss: 1.4023872730014924
Validation loss: 2.535511084983822

Epoch: 5| Step: 1
Training loss: 1.580671012935726
Validation loss: 2.522151088681261

Epoch: 5| Step: 2
Training loss: 1.457108973662131
Validation loss: 2.508293315581995

Epoch: 5| Step: 3
Training loss: 1.5834060535127759
Validation loss: 2.5202887555445805

Epoch: 5| Step: 4
Training loss: 1.1866557483135087
Validation loss: 2.554472582423584

Epoch: 5| Step: 5
Training loss: 1.2987765882779263
Validation loss: 2.5520820177354033

Epoch: 5| Step: 6
Training loss: 1.1550359280270308
Validation loss: 2.585974123213719

Epoch: 5| Step: 7
Training loss: 1.5992395441579066
Validation loss: 2.575637811906001

Epoch: 5| Step: 8
Training loss: 1.088327919205133
Validation loss: 2.557967947639104

Epoch: 5| Step: 9
Training loss: 1.7851988539004637
Validation loss: 2.5737888737177066

Epoch: 5| Step: 10
Training loss: 1.5005169613422018
Validation loss: 2.5556973729264523

Epoch: 264| Step: 0
Training loss: 1.326646273318854
Validation loss: 2.5791447263221765

Epoch: 5| Step: 1
Training loss: 1.6532695512364008
Validation loss: 2.567551264574149

Epoch: 5| Step: 2
Training loss: 1.6410275646593515
Validation loss: 2.5803031970087216

Epoch: 5| Step: 3
Training loss: 1.3415586212834327
Validation loss: 2.564562125137586

Epoch: 5| Step: 4
Training loss: 1.3516794054926076
Validation loss: 2.5546053698570486

Epoch: 5| Step: 5
Training loss: 1.5500686507250088
Validation loss: 2.543263829387027

Epoch: 5| Step: 6
Training loss: 1.3840779263465066
Validation loss: 2.531063311463047

Epoch: 5| Step: 7
Training loss: 0.9637289982052314
Validation loss: 2.534623345052447

Epoch: 5| Step: 8
Training loss: 1.3177725835322192
Validation loss: 2.5265263861887504

Epoch: 5| Step: 9
Training loss: 1.6685470543371654
Validation loss: 2.5375818905441494

Epoch: 5| Step: 10
Training loss: 1.1640522079524829
Validation loss: 2.5570377906943826

Epoch: 265| Step: 0
Training loss: 1.068876709593288
Validation loss: 2.562539413233083

Epoch: 5| Step: 1
Training loss: 1.365728591726019
Validation loss: 2.577944661554864

Epoch: 5| Step: 2
Training loss: 1.3573604871741787
Validation loss: 2.590674623948046

Epoch: 5| Step: 3
Training loss: 0.9682285382024413
Validation loss: 2.5947751073996828

Epoch: 5| Step: 4
Training loss: 1.6034672273308692
Validation loss: 2.6133998620323986

Epoch: 5| Step: 5
Training loss: 1.2011799137497774
Validation loss: 2.598850442738646

Epoch: 5| Step: 6
Training loss: 1.4742305041533432
Validation loss: 2.597605824572851

Epoch: 5| Step: 7
Training loss: 1.4056488023560083
Validation loss: 2.6185520004951472

Epoch: 5| Step: 8
Training loss: 1.7747027887087834
Validation loss: 2.6105316400642318

Epoch: 5| Step: 9
Training loss: 1.426061733300648
Validation loss: 2.6022064792523745

Epoch: 5| Step: 10
Training loss: 1.5899605672972845
Validation loss: 2.567846273088306

Epoch: 266| Step: 0
Training loss: 1.5035266744000002
Validation loss: 2.560234014354392

Epoch: 5| Step: 1
Training loss: 1.282091934097562
Validation loss: 2.5591150352244307

Epoch: 5| Step: 2
Training loss: 1.3898786620825934
Validation loss: 2.5565887708881347

Epoch: 5| Step: 3
Training loss: 1.3383902180808451
Validation loss: 2.5313504906925774

Epoch: 5| Step: 4
Training loss: 1.1532848071674127
Validation loss: 2.5341998450683016

Epoch: 5| Step: 5
Training loss: 1.4308252029025021
Validation loss: 2.545131417941799

Epoch: 5| Step: 6
Training loss: 1.6252810895334742
Validation loss: 2.571862627151494

Epoch: 5| Step: 7
Training loss: 1.3849654598267154
Validation loss: 2.570109917715425

Epoch: 5| Step: 8
Training loss: 1.3873704265543503
Validation loss: 2.588404940397038

Epoch: 5| Step: 9
Training loss: 1.3565334129422584
Validation loss: 2.6159121627974438

Epoch: 5| Step: 10
Training loss: 1.3533017648732606
Validation loss: 2.6101121200890987

Epoch: 267| Step: 0
Training loss: 1.4084705199439382
Validation loss: 2.5870437350181015

Epoch: 5| Step: 1
Training loss: 1.6877542939909131
Validation loss: 2.569658039693214

Epoch: 5| Step: 2
Training loss: 1.5625877355738995
Validation loss: 2.5820281383201578

Epoch: 5| Step: 3
Training loss: 1.3749468533041598
Validation loss: 2.56594773963107

Epoch: 5| Step: 4
Training loss: 1.5417946513208012
Validation loss: 2.572903936031698

Epoch: 5| Step: 5
Training loss: 1.0334399119655537
Validation loss: 2.5739307581382436

Epoch: 5| Step: 6
Training loss: 1.3972664303839935
Validation loss: 2.6022902615141628

Epoch: 5| Step: 7
Training loss: 1.354828213222191
Validation loss: 2.6161717076515116

Epoch: 5| Step: 8
Training loss: 1.3175608837674568
Validation loss: 2.6688161050962353

Epoch: 5| Step: 9
Training loss: 1.2797416088695823
Validation loss: 2.6984918604952504

Epoch: 5| Step: 10
Training loss: 1.4495384501173227
Validation loss: 2.7250266694841754

Epoch: 268| Step: 0
Training loss: 1.3782549392442855
Validation loss: 2.6893243361686343

Epoch: 5| Step: 1
Training loss: 1.0900427523811798
Validation loss: 2.6495652298371675

Epoch: 5| Step: 2
Training loss: 1.467311723059198
Validation loss: 2.5877784446816623

Epoch: 5| Step: 3
Training loss: 1.1211032135992665
Validation loss: 2.5402388368935913

Epoch: 5| Step: 4
Training loss: 1.1015283024667382
Validation loss: 2.5361567300230705

Epoch: 5| Step: 5
Training loss: 1.4879183589626928
Validation loss: 2.5353990795573633

Epoch: 5| Step: 6
Training loss: 1.4166680878276803
Validation loss: 2.526977275131714

Epoch: 5| Step: 7
Training loss: 1.6808253492935787
Validation loss: 2.5395415893597555

Epoch: 5| Step: 8
Training loss: 1.5470486938368473
Validation loss: 2.5813920953845173

Epoch: 5| Step: 9
Training loss: 1.0507259425246198
Validation loss: 2.586741881820989

Epoch: 5| Step: 10
Training loss: 1.8926781469473697
Validation loss: 2.598431257680787

Epoch: 269| Step: 0
Training loss: 1.3524323238850389
Validation loss: 2.5995473997839884

Epoch: 5| Step: 1
Training loss: 1.4163967698248654
Validation loss: 2.5761138997312854

Epoch: 5| Step: 2
Training loss: 1.7301070478979845
Validation loss: 2.5894568622085017

Epoch: 5| Step: 3
Training loss: 1.6604889659704514
Validation loss: 2.5660621780899433

Epoch: 5| Step: 4
Training loss: 1.239274357774698
Validation loss: 2.58195820892925

Epoch: 5| Step: 5
Training loss: 1.0960279992870858
Validation loss: 2.566119226568813

Epoch: 5| Step: 6
Training loss: 1.2248604013737212
Validation loss: 2.5870747764574227

Epoch: 5| Step: 7
Training loss: 1.5393069310380871
Validation loss: 2.5870033444197715

Epoch: 5| Step: 8
Training loss: 0.9296216861285703
Validation loss: 2.6025457933629723

Epoch: 5| Step: 9
Training loss: 1.4818536325214995
Validation loss: 2.594889424511638

Epoch: 5| Step: 10
Training loss: 1.1212581819641911
Validation loss: 2.6227215695366533

Epoch: 270| Step: 0
Training loss: 1.5721192096276908
Validation loss: 2.639861812399324

Epoch: 5| Step: 1
Training loss: 0.7370584443028556
Validation loss: 2.655329746225759

Epoch: 5| Step: 2
Training loss: 1.4182760783083659
Validation loss: 2.6682005849264088

Epoch: 5| Step: 3
Training loss: 1.3920796105294038
Validation loss: 2.658364893886361

Epoch: 5| Step: 4
Training loss: 1.6275892170537394
Validation loss: 2.6169768648907983

Epoch: 5| Step: 5
Training loss: 0.8069471464989122
Validation loss: 2.6208944262464704

Epoch: 5| Step: 6
Training loss: 1.2557102429253422
Validation loss: 2.602180494026545

Epoch: 5| Step: 7
Training loss: 1.5930729344129637
Validation loss: 2.5883884793548804

Epoch: 5| Step: 8
Training loss: 1.4513589936036533
Validation loss: 2.6337437801526216

Epoch: 5| Step: 9
Training loss: 1.3811627476954491
Validation loss: 2.629642582570571

Epoch: 5| Step: 10
Training loss: 1.271543768039072
Validation loss: 2.6384097580950407

Epoch: 271| Step: 0
Training loss: 1.0513432924693533
Validation loss: 2.6426487203157754

Epoch: 5| Step: 1
Training loss: 1.2996853631073797
Validation loss: 2.647894600847389

Epoch: 5| Step: 2
Training loss: 1.0893126256597845
Validation loss: 2.630248544231902

Epoch: 5| Step: 3
Training loss: 1.7244499020487383
Validation loss: 2.611545594032134

Epoch: 5| Step: 4
Training loss: 1.1787304058853347
Validation loss: 2.6476377029177693

Epoch: 5| Step: 5
Training loss: 1.8590517163729388
Validation loss: 2.606996904323854

Epoch: 5| Step: 6
Training loss: 0.9757269374615201
Validation loss: 2.6092367171828683

Epoch: 5| Step: 7
Training loss: 0.9850775315903674
Validation loss: 2.60178202435467

Epoch: 5| Step: 8
Training loss: 1.3247962075183783
Validation loss: 2.5992917881783026

Epoch: 5| Step: 9
Training loss: 1.5240288002616944
Validation loss: 2.582599524424571

Epoch: 5| Step: 10
Training loss: 1.3099435250288287
Validation loss: 2.5639176307859946

Epoch: 272| Step: 0
Training loss: 1.2482982495771837
Validation loss: 2.5852044180522147

Epoch: 5| Step: 1
Training loss: 1.0611129570712488
Validation loss: 2.5795949524620183

Epoch: 5| Step: 2
Training loss: 1.6061068192725976
Validation loss: 2.564863448619773

Epoch: 5| Step: 3
Training loss: 1.2694066852200614
Validation loss: 2.5902876029313533

Epoch: 5| Step: 4
Training loss: 1.4047588495755474
Validation loss: 2.586522605367398

Epoch: 5| Step: 5
Training loss: 0.9682691365091087
Validation loss: 2.6074898856286812

Epoch: 5| Step: 6
Training loss: 1.2650320759954763
Validation loss: 2.585554996231435

Epoch: 5| Step: 7
Training loss: 1.432814550034316
Validation loss: 2.5909660868580597

Epoch: 5| Step: 8
Training loss: 1.3427919032821205
Validation loss: 2.623127453519218

Epoch: 5| Step: 9
Training loss: 1.2977017903934889
Validation loss: 2.595045896464871

Epoch: 5| Step: 10
Training loss: 1.4845066212975095
Validation loss: 2.595808987827672

Epoch: 273| Step: 0
Training loss: 1.2739017319081538
Validation loss: 2.591510338986869

Epoch: 5| Step: 1
Training loss: 1.2407831374690745
Validation loss: 2.592259795984348

Epoch: 5| Step: 2
Training loss: 1.0626739471761304
Validation loss: 2.5789132512602984

Epoch: 5| Step: 3
Training loss: 1.3136378306260368
Validation loss: 2.5986615708048615

Epoch: 5| Step: 4
Training loss: 1.2848509915860005
Validation loss: 2.574871567719987

Epoch: 5| Step: 5
Training loss: 1.778995425569551
Validation loss: 2.6083390378517795

Epoch: 5| Step: 6
Training loss: 1.0155047418848966
Validation loss: 2.6019165139152505

Epoch: 5| Step: 7
Training loss: 1.083808843473744
Validation loss: 2.6000936369051484

Epoch: 5| Step: 8
Training loss: 1.4319486820040257
Validation loss: 2.5876181122684985

Epoch: 5| Step: 9
Training loss: 1.3871097497018379
Validation loss: 2.5831279520832666

Epoch: 5| Step: 10
Training loss: 1.34994692521492
Validation loss: 2.5659636557582197

Epoch: 274| Step: 0
Training loss: 1.280181718533604
Validation loss: 2.5711386887185603

Epoch: 5| Step: 1
Training loss: 1.2924124912764585
Validation loss: 2.5605578001610305

Epoch: 5| Step: 2
Training loss: 1.3506054438949724
Validation loss: 2.5712361946819926

Epoch: 5| Step: 3
Training loss: 0.9570591513789946
Validation loss: 2.5868635624557483

Epoch: 5| Step: 4
Training loss: 1.4534903446450267
Validation loss: 2.6038264771447586

Epoch: 5| Step: 5
Training loss: 1.3712599781267973
Validation loss: 2.609141720011687

Epoch: 5| Step: 6
Training loss: 1.4925110151692722
Validation loss: 2.618536682548933

Epoch: 5| Step: 7
Training loss: 1.3586840133997777
Validation loss: 2.620193414107991

Epoch: 5| Step: 8
Training loss: 0.9940412730277375
Validation loss: 2.6062437185539973

Epoch: 5| Step: 9
Training loss: 1.254420285018081
Validation loss: 2.62996040710075

Epoch: 5| Step: 10
Training loss: 1.351177270927584
Validation loss: 2.6038782190525653

Epoch: 275| Step: 0
Training loss: 1.2726369108132223
Validation loss: 2.6107973954152053

Epoch: 5| Step: 1
Training loss: 1.3861741836907882
Validation loss: 2.6369637795751326

Epoch: 5| Step: 2
Training loss: 1.5019055025366292
Validation loss: 2.6786506144220485

Epoch: 5| Step: 3
Training loss: 1.1740297978923326
Validation loss: 2.6577130741845694

Epoch: 5| Step: 4
Training loss: 1.1542209141970339
Validation loss: 2.654517041935852

Epoch: 5| Step: 5
Training loss: 1.254189242458668
Validation loss: 2.643579501379284

Epoch: 5| Step: 6
Training loss: 1.366130572907757
Validation loss: 2.604354134651729

Epoch: 5| Step: 7
Training loss: 1.236364523787231
Validation loss: 2.6126674870231263

Epoch: 5| Step: 8
Training loss: 1.1120211781673714
Validation loss: 2.591524590022219

Epoch: 5| Step: 9
Training loss: 1.5679453758242357
Validation loss: 2.615984904591619

Epoch: 5| Step: 10
Training loss: 1.0111191788259546
Validation loss: 2.6029626188395354

Epoch: 276| Step: 0
Training loss: 1.1672231278094962
Validation loss: 2.6233189723548476

Epoch: 5| Step: 1
Training loss: 1.329923959723811
Validation loss: 2.618625647960783

Epoch: 5| Step: 2
Training loss: 0.9994824977790753
Validation loss: 2.605835114257785

Epoch: 5| Step: 3
Training loss: 1.7368548423582961
Validation loss: 2.6008943858142

Epoch: 5| Step: 4
Training loss: 1.2813111267395088
Validation loss: 2.6162081085100244

Epoch: 5| Step: 5
Training loss: 1.2238006598455697
Validation loss: 2.6462920967383226

Epoch: 5| Step: 6
Training loss: 1.6390845923666777
Validation loss: 2.6159432076189466

Epoch: 5| Step: 7
Training loss: 1.0405321555203149
Validation loss: 2.6331376219791203

Epoch: 5| Step: 8
Training loss: 0.8838116553353595
Validation loss: 2.6162696528049985

Epoch: 5| Step: 9
Training loss: 1.3563324652708333
Validation loss: 2.595216388227503

Epoch: 5| Step: 10
Training loss: 1.190583141722501
Validation loss: 2.618185381009973

Epoch: 277| Step: 0
Training loss: 1.294468588915389
Validation loss: 2.674318004740542

Epoch: 5| Step: 1
Training loss: 1.1452258609408665
Validation loss: 2.617049864111631

Epoch: 5| Step: 2
Training loss: 1.1232747518468473
Validation loss: 2.630086466669644

Epoch: 5| Step: 3
Training loss: 1.1954745014587307
Validation loss: 2.620496839716933

Epoch: 5| Step: 4
Training loss: 1.6287042506270875
Validation loss: 2.615300462132481

Epoch: 5| Step: 5
Training loss: 1.598489185142743
Validation loss: 2.6158246633796316

Epoch: 5| Step: 6
Training loss: 1.0304248282765807
Validation loss: 2.570286575337749

Epoch: 5| Step: 7
Training loss: 1.345673625827572
Validation loss: 2.5724555689251623

Epoch: 5| Step: 8
Training loss: 1.2661130929425235
Validation loss: 2.5592971943186247

Epoch: 5| Step: 9
Training loss: 1.2230886359016127
Validation loss: 2.582426637148065

Epoch: 5| Step: 10
Training loss: 0.8580922002559906
Validation loss: 2.58615280537397

Epoch: 278| Step: 0
Training loss: 1.3550077418426403
Validation loss: 2.600654820878028

Epoch: 5| Step: 1
Training loss: 1.5848122348940883
Validation loss: 2.623647379415817

Epoch: 5| Step: 2
Training loss: 1.3163849690242493
Validation loss: 2.6015063016803643

Epoch: 5| Step: 3
Training loss: 1.1626312879034086
Validation loss: 2.617039824255825

Epoch: 5| Step: 4
Training loss: 1.17411072133196
Validation loss: 2.614629807741666

Epoch: 5| Step: 5
Training loss: 1.222397066865268
Validation loss: 2.6297425718567253

Epoch: 5| Step: 6
Training loss: 1.3354126194710583
Validation loss: 2.622401579955372

Epoch: 5| Step: 7
Training loss: 1.1063146152052645
Validation loss: 2.596701883353696

Epoch: 5| Step: 8
Training loss: 1.0380401170581957
Validation loss: 2.5868430739703268

Epoch: 5| Step: 9
Training loss: 1.0971108164075285
Validation loss: 2.5709010038731774

Epoch: 5| Step: 10
Training loss: 1.2739133823269508
Validation loss: 2.5604691820641388

Epoch: 279| Step: 0
Training loss: 0.8603179613321805
Validation loss: 2.538031369983269

Epoch: 5| Step: 1
Training loss: 1.454803563782735
Validation loss: 2.5704802659005734

Epoch: 5| Step: 2
Training loss: 1.082800856578588
Validation loss: 2.574130967705119

Epoch: 5| Step: 3
Training loss: 1.2985276412430837
Validation loss: 2.5980395534904357

Epoch: 5| Step: 4
Training loss: 1.0709416009419812
Validation loss: 2.652226933250391

Epoch: 5| Step: 5
Training loss: 1.256846323392767
Validation loss: 2.602912153398752

Epoch: 5| Step: 6
Training loss: 1.0961750394623104
Validation loss: 2.6282177280540417

Epoch: 5| Step: 7
Training loss: 1.3472056644553936
Validation loss: 2.6015619087458766

Epoch: 5| Step: 8
Training loss: 1.6766112079637538
Validation loss: 2.631898116719026

Epoch: 5| Step: 9
Training loss: 1.0513110332030886
Validation loss: 2.6146363005947495

Epoch: 5| Step: 10
Training loss: 1.3444544254323068
Validation loss: 2.6064070067976957

Epoch: 280| Step: 0
Training loss: 1.3890062833551888
Validation loss: 2.6202404843276423

Epoch: 5| Step: 1
Training loss: 1.3037929551974818
Validation loss: 2.611273492659826

Epoch: 5| Step: 2
Training loss: 1.1457742444610652
Validation loss: 2.642538831588894

Epoch: 5| Step: 3
Training loss: 1.2374529550260527
Validation loss: 2.630856729854437

Epoch: 5| Step: 4
Training loss: 1.2994286088403073
Validation loss: 2.634084732097145

Epoch: 5| Step: 5
Training loss: 1.0459285272282348
Validation loss: 2.6317488145730983

Epoch: 5| Step: 6
Training loss: 1.2597744253871392
Validation loss: 2.623076308773731

Epoch: 5| Step: 7
Training loss: 1.2522820146351907
Validation loss: 2.547620904536188

Epoch: 5| Step: 8
Training loss: 1.1381098569127577
Validation loss: 2.579582592352948

Epoch: 5| Step: 9
Training loss: 1.3906142416548606
Validation loss: 2.5436930974359773

Epoch: 5| Step: 10
Training loss: 1.1118329716630715
Validation loss: 2.5452482654054

Epoch: 281| Step: 0
Training loss: 0.938635773903126
Validation loss: 2.580971994872875

Epoch: 5| Step: 1
Training loss: 1.2373588809073208
Validation loss: 2.5596284140901933

Epoch: 5| Step: 2
Training loss: 1.257598764018308
Validation loss: 2.6319410366084957

Epoch: 5| Step: 3
Training loss: 1.1343227448000537
Validation loss: 2.640103220578008

Epoch: 5| Step: 4
Training loss: 1.581237292332908
Validation loss: 2.629776305337221

Epoch: 5| Step: 5
Training loss: 1.0706368950195826
Validation loss: 2.645143667235396

Epoch: 5| Step: 6
Training loss: 1.6285275538230206
Validation loss: 2.6419666947386053

Epoch: 5| Step: 7
Training loss: 1.3483135002824622
Validation loss: 2.579508702769273

Epoch: 5| Step: 8
Training loss: 0.9081923617473775
Validation loss: 2.578737893935497

Epoch: 5| Step: 9
Training loss: 1.2525080791372718
Validation loss: 2.556891836624198

Epoch: 5| Step: 10
Training loss: 0.8348901908304673
Validation loss: 2.5661725534564286

Epoch: 282| Step: 0
Training loss: 1.5659895268865887
Validation loss: 2.560958124303569

Epoch: 5| Step: 1
Training loss: 0.8950017499640208
Validation loss: 2.56438196056627

Epoch: 5| Step: 2
Training loss: 1.4153425629653698
Validation loss: 2.5714419876981793

Epoch: 5| Step: 3
Training loss: 0.6801521204045968
Validation loss: 2.5994227506100835

Epoch: 5| Step: 4
Training loss: 1.3086601582088557
Validation loss: 2.597221849036547

Epoch: 5| Step: 5
Training loss: 1.054811145457701
Validation loss: 2.6124929999612805

Epoch: 5| Step: 6
Training loss: 1.6081310761059318
Validation loss: 2.6221758548402225

Epoch: 5| Step: 7
Training loss: 0.8861588714514559
Validation loss: 2.6283880705351397

Epoch: 5| Step: 8
Training loss: 1.169241833344903
Validation loss: 2.6420794007906387

Epoch: 5| Step: 9
Training loss: 1.0422106212699185
Validation loss: 2.618838368697077

Epoch: 5| Step: 10
Training loss: 1.2830349189216568
Validation loss: 2.619689063253733

Epoch: 283| Step: 0
Training loss: 1.5244811566853238
Validation loss: 2.628683087594755

Epoch: 5| Step: 1
Training loss: 0.9201804929400549
Validation loss: 2.6000247317574305

Epoch: 5| Step: 2
Training loss: 1.4061535696239837
Validation loss: 2.589217524204193

Epoch: 5| Step: 3
Training loss: 1.2740135060317572
Validation loss: 2.5983419609525154

Epoch: 5| Step: 4
Training loss: 1.061924161261354
Validation loss: 2.604352787052764

Epoch: 5| Step: 5
Training loss: 0.8528339098978793
Validation loss: 2.6076828469013735

Epoch: 5| Step: 6
Training loss: 0.9768189970768545
Validation loss: 2.6327440168889304

Epoch: 5| Step: 7
Training loss: 1.43202019170559
Validation loss: 2.6313927718282244

Epoch: 5| Step: 8
Training loss: 1.3561304329759698
Validation loss: 2.6595331564255993

Epoch: 5| Step: 9
Training loss: 1.1890524704619208
Validation loss: 2.6232171686949544

Epoch: 5| Step: 10
Training loss: 0.9854307719397939
Validation loss: 2.6238247984562744

Epoch: 284| Step: 0
Training loss: 0.5888290772513228
Validation loss: 2.621886816123678

Epoch: 5| Step: 1
Training loss: 1.6017878676228539
Validation loss: 2.6118924672875177

Epoch: 5| Step: 2
Training loss: 1.4624426936472241
Validation loss: 2.5987954080113247

Epoch: 5| Step: 3
Training loss: 0.9990640969453087
Validation loss: 2.5835860043138785

Epoch: 5| Step: 4
Training loss: 0.9229503114536636
Validation loss: 2.5770908244155075

Epoch: 5| Step: 5
Training loss: 0.9750257072972188
Validation loss: 2.5750630054119172

Epoch: 5| Step: 6
Training loss: 0.9739533626545152
Validation loss: 2.6070353075609916

Epoch: 5| Step: 7
Training loss: 1.347436859406737
Validation loss: 2.606486406038736

Epoch: 5| Step: 8
Training loss: 1.754328823372037
Validation loss: 2.5954390461337944

Epoch: 5| Step: 9
Training loss: 0.8470420897788933
Validation loss: 2.632820216775221

Epoch: 5| Step: 10
Training loss: 1.012023173010362
Validation loss: 2.626614599971561

Epoch: 285| Step: 0
Training loss: 0.9948513885200007
Validation loss: 2.641324027386679

Epoch: 5| Step: 1
Training loss: 0.988082292757025
Validation loss: 2.644663104210153

Epoch: 5| Step: 2
Training loss: 1.1295568050269875
Validation loss: 2.6261497749205454

Epoch: 5| Step: 3
Training loss: 1.0188463036824267
Validation loss: 2.6384317000591078

Epoch: 5| Step: 4
Training loss: 1.483565742344818
Validation loss: 2.638288465742879

Epoch: 5| Step: 5
Training loss: 1.1199080946373525
Validation loss: 2.649970606429789

Epoch: 5| Step: 6
Training loss: 0.9846804614165087
Validation loss: 2.6532095313823696

Epoch: 5| Step: 7
Training loss: 1.5104788493368
Validation loss: 2.6288878171992196

Epoch: 5| Step: 8
Training loss: 0.9571796224371459
Validation loss: 2.6342539477789835

Epoch: 5| Step: 9
Training loss: 1.4254817282242591
Validation loss: 2.615781481992019

Epoch: 5| Step: 10
Training loss: 1.1410919174394827
Validation loss: 2.6515383245597914

Epoch: 286| Step: 0
Training loss: 0.7953083120659244
Validation loss: 2.64186524431238

Epoch: 5| Step: 1
Training loss: 1.1047911707295348
Validation loss: 2.626842977374737

Epoch: 5| Step: 2
Training loss: 1.164720899524196
Validation loss: 2.619501389463629

Epoch: 5| Step: 3
Training loss: 1.5591919021290468
Validation loss: 2.6407009928603746

Epoch: 5| Step: 4
Training loss: 0.9977883677875233
Validation loss: 2.6466404167796966

Epoch: 5| Step: 5
Training loss: 1.3311655134157288
Validation loss: 2.6297306360856396

Epoch: 5| Step: 6
Training loss: 1.0621884394094696
Validation loss: 2.5970775723616817

Epoch: 5| Step: 7
Training loss: 1.1113874422946566
Validation loss: 2.5911395728277364

Epoch: 5| Step: 8
Training loss: 1.193844660655751
Validation loss: 2.5884516685853263

Epoch: 5| Step: 9
Training loss: 1.3274787227987261
Validation loss: 2.586818757929319

Epoch: 5| Step: 10
Training loss: 1.0462139376825297
Validation loss: 2.558830302773629

Epoch: 287| Step: 0
Training loss: 0.9749394165681481
Validation loss: 2.578337437443568

Epoch: 5| Step: 1
Training loss: 1.1716783485716533
Validation loss: 2.6082378963117834

Epoch: 5| Step: 2
Training loss: 1.2740608047275712
Validation loss: 2.6048201937449007

Epoch: 5| Step: 3
Training loss: 0.7787913736095846
Validation loss: 2.6019260130725512

Epoch: 5| Step: 4
Training loss: 1.3627258306111976
Validation loss: 2.6252776437120837

Epoch: 5| Step: 5
Training loss: 1.0387665750257595
Validation loss: 2.611991977906628

Epoch: 5| Step: 6
Training loss: 1.3333413849031213
Validation loss: 2.606539327031302

Epoch: 5| Step: 7
Training loss: 1.144113093208031
Validation loss: 2.6300372824803837

Epoch: 5| Step: 8
Training loss: 1.1993223263622612
Validation loss: 2.6240613062767153

Epoch: 5| Step: 9
Training loss: 0.9341876642746774
Validation loss: 2.6037264284854755

Epoch: 5| Step: 10
Training loss: 1.2539835873340455
Validation loss: 2.5832680294689063

Epoch: 288| Step: 0
Training loss: 1.2775821754915286
Validation loss: 2.59941598799069

Epoch: 5| Step: 1
Training loss: 0.8892139165087016
Validation loss: 2.5514560671110815

Epoch: 5| Step: 2
Training loss: 1.1776799178304282
Validation loss: 2.573891232484418

Epoch: 5| Step: 3
Training loss: 1.0650926820964377
Validation loss: 2.5753430025865174

Epoch: 5| Step: 4
Training loss: 1.4086505745138451
Validation loss: 2.610014157008326

Epoch: 5| Step: 5
Training loss: 0.5766954015544178
Validation loss: 2.5862986475376766

Epoch: 5| Step: 6
Training loss: 1.4951571329014353
Validation loss: 2.5976171722051067

Epoch: 5| Step: 7
Training loss: 1.3650584182535013
Validation loss: 2.592497122607313

Epoch: 5| Step: 8
Training loss: 0.8371233149946302
Validation loss: 2.58356850142825

Epoch: 5| Step: 9
Training loss: 1.1346805297671096
Validation loss: 2.5828882070266554

Epoch: 5| Step: 10
Training loss: 0.958778716680581
Validation loss: 2.598017448006412

Epoch: 289| Step: 0
Training loss: 1.0415737810047594
Validation loss: 2.5722793796874908

Epoch: 5| Step: 1
Training loss: 1.2540017445170362
Validation loss: 2.62815792965463

Epoch: 5| Step: 2
Training loss: 1.6096751109175789
Validation loss: 2.6586662040355242

Epoch: 5| Step: 3
Training loss: 0.9305224476012425
Validation loss: 2.632423851023483

Epoch: 5| Step: 4
Training loss: 0.6424290214474165
Validation loss: 2.61104423161589

Epoch: 5| Step: 5
Training loss: 1.0932526138696623
Validation loss: 2.6589379267836177

Epoch: 5| Step: 6
Training loss: 0.8260881818941225
Validation loss: 2.631498856030043

Epoch: 5| Step: 7
Training loss: 1.2047574251812512
Validation loss: 2.6148235186373885

Epoch: 5| Step: 8
Training loss: 1.2786644690166227
Validation loss: 2.620507197971517

Epoch: 5| Step: 9
Training loss: 0.9339252665413569
Validation loss: 2.606460102019222

Epoch: 5| Step: 10
Training loss: 1.3200761030395793
Validation loss: 2.615923054693247

Epoch: 290| Step: 0
Training loss: 0.8691973035526539
Validation loss: 2.5786590405894985

Epoch: 5| Step: 1
Training loss: 1.3565059947645246
Validation loss: 2.627941499266199

Epoch: 5| Step: 2
Training loss: 1.0939451860925988
Validation loss: 2.602107566329784

Epoch: 5| Step: 3
Training loss: 1.4979068138566054
Validation loss: 2.6263798418842903

Epoch: 5| Step: 4
Training loss: 0.9741474960688127
Validation loss: 2.634641990113417

Epoch: 5| Step: 5
Training loss: 0.9111130887070829
Validation loss: 2.6203754725155477

Epoch: 5| Step: 6
Training loss: 0.8456186864691932
Validation loss: 2.63716354039739

Epoch: 5| Step: 7
Training loss: 1.1552085310050353
Validation loss: 2.60916277915446

Epoch: 5| Step: 8
Training loss: 1.1314856289108146
Validation loss: 2.6270972359396367

Epoch: 5| Step: 9
Training loss: 0.7410864442758377
Validation loss: 2.604443510701494

Epoch: 5| Step: 10
Training loss: 1.452158698922428
Validation loss: 2.590435983343146

Epoch: 291| Step: 0
Training loss: 1.0875323542901183
Validation loss: 2.5850283479999656

Epoch: 5| Step: 1
Training loss: 1.1626685584316117
Validation loss: 2.5902489187304174

Epoch: 5| Step: 2
Training loss: 1.1472358385426928
Validation loss: 2.568643928447418

Epoch: 5| Step: 3
Training loss: 1.102494406999514
Validation loss: 2.5608337431377883

Epoch: 5| Step: 4
Training loss: 1.460960347206042
Validation loss: 2.5923221654649895

Epoch: 5| Step: 5
Training loss: 1.3042745793377173
Validation loss: 2.573083997086791

Epoch: 5| Step: 6
Training loss: 1.0220882461581144
Validation loss: 2.609211188107618

Epoch: 5| Step: 7
Training loss: 0.6754493559877546
Validation loss: 2.6337398330828097

Epoch: 5| Step: 8
Training loss: 0.9056848210597956
Validation loss: 2.614777764702794

Epoch: 5| Step: 9
Training loss: 0.9801971545715378
Validation loss: 2.6531389465162594

Epoch: 5| Step: 10
Training loss: 1.0255454100994086
Validation loss: 2.64276064936402

Epoch: 292| Step: 0
Training loss: 1.358386283068714
Validation loss: 2.6408518294333083

Epoch: 5| Step: 1
Training loss: 0.917660308314488
Validation loss: 2.659482425504703

Epoch: 5| Step: 2
Training loss: 1.0690441552188081
Validation loss: 2.640393366335146

Epoch: 5| Step: 3
Training loss: 0.7548228803879365
Validation loss: 2.627997940981928

Epoch: 5| Step: 4
Training loss: 1.2449570975514186
Validation loss: 2.623331846625653

Epoch: 5| Step: 5
Training loss: 0.9179898848028291
Validation loss: 2.628949829183087

Epoch: 5| Step: 6
Training loss: 1.0265080639298994
Validation loss: 2.630871433789785

Epoch: 5| Step: 7
Training loss: 1.5803031619676573
Validation loss: 2.6541972703161485

Epoch: 5| Step: 8
Training loss: 0.6706355216915393
Validation loss: 2.633534824559513

Epoch: 5| Step: 9
Training loss: 1.0952192519869208
Validation loss: 2.5987780993042797

Epoch: 5| Step: 10
Training loss: 1.1446246737214854
Validation loss: 2.633654900051836

Epoch: 293| Step: 0
Training loss: 1.1257436731488135
Validation loss: 2.613265281160149

Epoch: 5| Step: 1
Training loss: 0.9392975422592604
Validation loss: 2.631355325197814

Epoch: 5| Step: 2
Training loss: 0.7996418732494872
Validation loss: 2.6218148560539696

Epoch: 5| Step: 3
Training loss: 1.381266359948672
Validation loss: 2.624810522051018

Epoch: 5| Step: 4
Training loss: 1.3934062619417502
Validation loss: 2.5972928401388224

Epoch: 5| Step: 5
Training loss: 1.0405457887487057
Validation loss: 2.5842838291954755

Epoch: 5| Step: 6
Training loss: 1.1381971570372413
Validation loss: 2.5766002472992864

Epoch: 5| Step: 7
Training loss: 1.1588531779881521
Validation loss: 2.5866996133582782

Epoch: 5| Step: 8
Training loss: 0.7564619949435704
Validation loss: 2.5685995112488325

Epoch: 5| Step: 9
Training loss: 1.0509573636430822
Validation loss: 2.5837203446136643

Epoch: 5| Step: 10
Training loss: 0.8546544209831424
Validation loss: 2.579013723737403

Epoch: 294| Step: 0
Training loss: 1.0240077402969718
Validation loss: 2.5786246354121896

Epoch: 5| Step: 1
Training loss: 0.9199344123909289
Validation loss: 2.5823356879974964

Epoch: 5| Step: 2
Training loss: 1.243646065284628
Validation loss: 2.613155322286789

Epoch: 5| Step: 3
Training loss: 0.9342693932602587
Validation loss: 2.5881094566875933

Epoch: 5| Step: 4
Training loss: 0.7974400480450773
Validation loss: 2.60652308575335

Epoch: 5| Step: 5
Training loss: 0.7091192112011774
Validation loss: 2.605156513407956

Epoch: 5| Step: 6
Training loss: 1.117066917047437
Validation loss: 2.6037979570472642

Epoch: 5| Step: 7
Training loss: 1.3001288533541961
Validation loss: 2.6119438673407354

Epoch: 5| Step: 8
Training loss: 1.1439492370006685
Validation loss: 2.6040877542332304

Epoch: 5| Step: 9
Training loss: 1.3435582312431686
Validation loss: 2.5734522650931853

Epoch: 5| Step: 10
Training loss: 1.1075168683250711
Validation loss: 2.617891069961592

Epoch: 295| Step: 0
Training loss: 0.651140828528114
Validation loss: 2.5990991074433896

Epoch: 5| Step: 1
Training loss: 1.1769405492192393
Validation loss: 2.596330567036254

Epoch: 5| Step: 2
Training loss: 1.4272911959923766
Validation loss: 2.6028396204791964

Epoch: 5| Step: 3
Training loss: 0.919516115542103
Validation loss: 2.600723816777577

Epoch: 5| Step: 4
Training loss: 1.3924219758177598
Validation loss: 2.593279684604108

Epoch: 5| Step: 5
Training loss: 0.8146766337616407
Validation loss: 2.5865417048226083

Epoch: 5| Step: 6
Training loss: 0.866277337351639
Validation loss: 2.579436124973891

Epoch: 5| Step: 7
Training loss: 1.2830916404196715
Validation loss: 2.5932833077136483

Epoch: 5| Step: 8
Training loss: 1.0879121021499827
Validation loss: 2.5787842515169492

Epoch: 5| Step: 9
Training loss: 0.8974180989631414
Validation loss: 2.6001413401577027

Epoch: 5| Step: 10
Training loss: 0.913782582256577
Validation loss: 2.5939720484758566

Epoch: 296| Step: 0
Training loss: 1.2097590465077332
Validation loss: 2.590776782633387

Epoch: 5| Step: 1
Training loss: 0.7473093884460648
Validation loss: 2.5934210147465713

Epoch: 5| Step: 2
Training loss: 1.0116246595779237
Validation loss: 2.5800097634077575

Epoch: 5| Step: 3
Training loss: 0.9870158300241499
Validation loss: 2.607767385177349

Epoch: 5| Step: 4
Training loss: 1.415212174403871
Validation loss: 2.5994276255630995

Epoch: 5| Step: 5
Training loss: 0.355071673948399
Validation loss: 2.6183684866630714

Epoch: 5| Step: 6
Training loss: 0.6646169703789347
Validation loss: 2.601828904452289

Epoch: 5| Step: 7
Training loss: 1.3199324201855227
Validation loss: 2.596732186380406

Epoch: 5| Step: 8
Training loss: 1.1027420978768934
Validation loss: 2.6403255051307695

Epoch: 5| Step: 9
Training loss: 1.161294911381498
Validation loss: 2.6633716890832404

Epoch: 5| Step: 10
Training loss: 1.2330901786887634
Validation loss: 2.622020578538131

Epoch: 297| Step: 0
Training loss: 1.163485287922891
Validation loss: 2.6229641491392073

Epoch: 5| Step: 1
Training loss: 0.8703426321624528
Validation loss: 2.6372736113000506

Epoch: 5| Step: 2
Training loss: 1.1055887649144698
Validation loss: 2.616813859025595

Epoch: 5| Step: 3
Training loss: 1.1160663768109023
Validation loss: 2.6048888992136976

Epoch: 5| Step: 4
Training loss: 1.2988132103085153
Validation loss: 2.6158998537441827

Epoch: 5| Step: 5
Training loss: 1.0598828114202494
Validation loss: 2.573103214226995

Epoch: 5| Step: 6
Training loss: 0.895132237740064
Validation loss: 2.6160484983491306

Epoch: 5| Step: 7
Training loss: 1.2921099158616378
Validation loss: 2.6044176836346993

Epoch: 5| Step: 8
Training loss: 0.6923544464972426
Validation loss: 2.5682178665605857

Epoch: 5| Step: 9
Training loss: 0.6813940569603059
Validation loss: 2.5666494291286317

Epoch: 5| Step: 10
Training loss: 1.1375832432899684
Validation loss: 2.6169929374527334

Epoch: 298| Step: 0
Training loss: 1.1765799613558665
Validation loss: 2.6300478185805023

Epoch: 5| Step: 1
Training loss: 0.9547382210151989
Validation loss: 2.573582393758878

Epoch: 5| Step: 2
Training loss: 0.7236259758712559
Validation loss: 2.581626912681095

Epoch: 5| Step: 3
Training loss: 0.7873165340757817
Validation loss: 2.598165840856632

Epoch: 5| Step: 4
Training loss: 1.1353539207456316
Validation loss: 2.601822609219037

Epoch: 5| Step: 5
Training loss: 1.0126094947289936
Validation loss: 2.5913763708729842

Epoch: 5| Step: 6
Training loss: 1.0793409815531625
Validation loss: 2.583536884003996

Epoch: 5| Step: 7
Training loss: 0.7555838385793763
Validation loss: 2.559769553094409

Epoch: 5| Step: 8
Training loss: 1.01240840073668
Validation loss: 2.5972503613936824

Epoch: 5| Step: 9
Training loss: 1.0330913173125675
Validation loss: 2.607276463184153

Epoch: 5| Step: 10
Training loss: 1.5678591565889783
Validation loss: 2.5902054831843433

Epoch: 299| Step: 0
Training loss: 1.213730869633531
Validation loss: 2.592005566465801

Epoch: 5| Step: 1
Training loss: 1.158902862325806
Validation loss: 2.6046710530421424

Epoch: 5| Step: 2
Training loss: 1.1021479680818989
Validation loss: 2.589886394770724

Epoch: 5| Step: 3
Training loss: 0.9608188959135998
Validation loss: 2.5914587878879196

Epoch: 5| Step: 4
Training loss: 0.8989604920456753
Validation loss: 2.6043918130002575

Epoch: 5| Step: 5
Training loss: 0.5343252538090812
Validation loss: 2.576464818337124

Epoch: 5| Step: 6
Training loss: 1.0705640733867545
Validation loss: 2.588288710521808

Epoch: 5| Step: 7
Training loss: 0.9719828223861275
Validation loss: 2.619633682926003

Epoch: 5| Step: 8
Training loss: 1.2088147662227187
Validation loss: 2.6328021609463392

Epoch: 5| Step: 9
Training loss: 0.6913894608177958
Validation loss: 2.6148753306902686

Epoch: 5| Step: 10
Training loss: 1.1925410635093987
Validation loss: 2.6244324267334123

Epoch: 300| Step: 0
Training loss: 1.0420901137208558
Validation loss: 2.61235641506481

Epoch: 5| Step: 1
Training loss: 0.8867535017152514
Validation loss: 2.614677307560609

Epoch: 5| Step: 2
Training loss: 1.049474534749426
Validation loss: 2.6339738923714306

Epoch: 5| Step: 3
Training loss: 0.7093814967189855
Validation loss: 2.571086847817

Epoch: 5| Step: 4
Training loss: 0.9943290486918547
Validation loss: 2.584495219304412

Epoch: 5| Step: 5
Training loss: 0.921261502456803
Validation loss: 2.584836360507262

Epoch: 5| Step: 6
Training loss: 1.1436155125496192
Validation loss: 2.5239817694850735

Epoch: 5| Step: 7
Training loss: 1.416770239391118
Validation loss: 2.5832611540979595

Epoch: 5| Step: 8
Training loss: 0.9789045706793164
Validation loss: 2.5711486216478074

Epoch: 5| Step: 9
Training loss: 0.9801531279879203
Validation loss: 2.562726848894835

Epoch: 5| Step: 10
Training loss: 0.6721944271424133
Validation loss: 2.542750825506028

Epoch: 301| Step: 0
Training loss: 1.1872127587105819
Validation loss: 2.567106862455972

Epoch: 5| Step: 1
Training loss: 1.1755167007655343
Validation loss: 2.5520791945048247

Epoch: 5| Step: 2
Training loss: 1.0016628982760802
Validation loss: 2.5446698524362543

Epoch: 5| Step: 3
Training loss: 1.0280893615296909
Validation loss: 2.5581781461378625

Epoch: 5| Step: 4
Training loss: 1.0000621657122128
Validation loss: 2.554431642688629

Epoch: 5| Step: 5
Training loss: 1.061670708990461
Validation loss: 2.5357235130499864

Epoch: 5| Step: 6
Training loss: 0.8815289847119597
Validation loss: 2.5166342398739734

Epoch: 5| Step: 7
Training loss: 0.8164854604450866
Validation loss: 2.5523898973767274

Epoch: 5| Step: 8
Training loss: 1.1675186565795441
Validation loss: 2.554220568789365

Epoch: 5| Step: 9
Training loss: 1.0499658079483911
Validation loss: 2.5620530371704273

Epoch: 5| Step: 10
Training loss: 0.644145757817811
Validation loss: 2.5886507521156066

Epoch: 302| Step: 0
Training loss: 0.6695035289959136
Validation loss: 2.5326882715658674

Epoch: 5| Step: 1
Training loss: 1.5171307821308984
Validation loss: 2.573078674686724

Epoch: 5| Step: 2
Training loss: 0.8837755065215539
Validation loss: 2.574450300119148

Epoch: 5| Step: 3
Training loss: 0.7205178040628331
Validation loss: 2.566313556320693

Epoch: 5| Step: 4
Training loss: 0.9537147198472573
Validation loss: 2.581534413726889

Epoch: 5| Step: 5
Training loss: 1.1422876233262342
Validation loss: 2.546243510423692

Epoch: 5| Step: 6
Training loss: 0.9934195130895717
Validation loss: 2.5595665785688735

Epoch: 5| Step: 7
Training loss: 0.9725502906289367
Validation loss: 2.5406339441221792

Epoch: 5| Step: 8
Training loss: 0.8627867512244141
Validation loss: 2.513749049573309

Epoch: 5| Step: 9
Training loss: 1.025316101272523
Validation loss: 2.5465902348843032

Epoch: 5| Step: 10
Training loss: 0.9815082283160937
Validation loss: 2.5899117441265385

Epoch: 303| Step: 0
Training loss: 1.269977667154108
Validation loss: 2.543511900146971

Epoch: 5| Step: 1
Training loss: 0.9811450707769841
Validation loss: 2.568383550387826

Epoch: 5| Step: 2
Training loss: 0.9129911485725511
Validation loss: 2.561720288512916

Epoch: 5| Step: 3
Training loss: 0.950767164666716
Validation loss: 2.6185407758935826

Epoch: 5| Step: 4
Training loss: 0.9477831184016363
Validation loss: 2.6120549833236915

Epoch: 5| Step: 5
Training loss: 0.9763129563979812
Validation loss: 2.598781259981832

Epoch: 5| Step: 6
Training loss: 1.042806319829171
Validation loss: 2.62415045171958

Epoch: 5| Step: 7
Training loss: 1.1143682694245236
Validation loss: 2.6035075840566093

Epoch: 5| Step: 8
Training loss: 0.7438417971083409
Validation loss: 2.5949237103644434

Epoch: 5| Step: 9
Training loss: 1.0763771152194248
Validation loss: 2.5852466534459153

Epoch: 5| Step: 10
Training loss: 0.47587701870304977
Validation loss: 2.5759380980576623

Epoch: 304| Step: 0
Training loss: 1.0137918213897266
Validation loss: 2.584015529583871

Epoch: 5| Step: 1
Training loss: 0.9422851511895662
Validation loss: 2.6144532051709746

Epoch: 5| Step: 2
Training loss: 1.0155910779716606
Validation loss: 2.6133697488404017

Epoch: 5| Step: 3
Training loss: 0.7918351061134778
Validation loss: 2.603581910140808

Epoch: 5| Step: 4
Training loss: 0.906779759228177
Validation loss: 2.6020381548952365

Epoch: 5| Step: 5
Training loss: 1.1166588125854155
Validation loss: 2.6518396176375227

Epoch: 5| Step: 6
Training loss: 1.1806873858777251
Validation loss: 2.6290062960577063

Epoch: 5| Step: 7
Training loss: 1.0334832833815522
Validation loss: 2.652103206623635

Epoch: 5| Step: 8
Training loss: 1.0585789978575997
Validation loss: 2.5931837242358995

Epoch: 5| Step: 9
Training loss: 0.631825041640137
Validation loss: 2.6053649809851445

Epoch: 5| Step: 10
Training loss: 0.7473514202537014
Validation loss: 2.586456424218047

Epoch: 305| Step: 0
Training loss: 0.7253131584746311
Validation loss: 2.5806309984828593

Epoch: 5| Step: 1
Training loss: 0.9983490189820354
Validation loss: 2.577720656620755

Epoch: 5| Step: 2
Training loss: 0.9137825170280992
Validation loss: 2.5543686245431845

Epoch: 5| Step: 3
Training loss: 1.1330308900984012
Validation loss: 2.5966063624320075

Epoch: 5| Step: 4
Training loss: 0.9036458516556063
Validation loss: 2.601310239080779

Epoch: 5| Step: 5
Training loss: 0.7133558871441205
Validation loss: 2.6628120212572384

Epoch: 5| Step: 6
Training loss: 1.03293079616356
Validation loss: 2.6362649482270535

Epoch: 5| Step: 7
Training loss: 1.0458346079379113
Validation loss: 2.6341020998058466

Epoch: 5| Step: 8
Training loss: 0.9560698994097518
Validation loss: 2.6413186998170612

Epoch: 5| Step: 9
Training loss: 0.9931371754595562
Validation loss: 2.5992236784385656

Epoch: 5| Step: 10
Training loss: 1.0758276525613881
Validation loss: 2.5887966793397243

Epoch: 306| Step: 0
Training loss: 0.6827456417566221
Validation loss: 2.572803316629038

Epoch: 5| Step: 1
Training loss: 1.324834134858462
Validation loss: 2.587416521798209

Epoch: 5| Step: 2
Training loss: 0.9425196098695817
Validation loss: 2.5947719635783084

Epoch: 5| Step: 3
Training loss: 0.9276016622284985
Validation loss: 2.5712247376014505

Epoch: 5| Step: 4
Training loss: 1.0594393460247138
Validation loss: 2.551089210251292

Epoch: 5| Step: 5
Training loss: 0.8351347446795248
Validation loss: 2.583674702697568

Epoch: 5| Step: 6
Training loss: 0.749533269615864
Validation loss: 2.5634776245677524

Epoch: 5| Step: 7
Training loss: 1.2503453731243643
Validation loss: 2.5851885266715704

Epoch: 5| Step: 8
Training loss: 0.7205938654424342
Validation loss: 2.5384643163050797

Epoch: 5| Step: 9
Training loss: 0.7341524558003579
Validation loss: 2.5779811546789912

Epoch: 5| Step: 10
Training loss: 0.6075476120709182
Validation loss: 2.5565328995928702

Epoch: 307| Step: 0
Training loss: 0.742222112551254
Validation loss: 2.590510211431467

Epoch: 5| Step: 1
Training loss: 1.1816963624025185
Validation loss: 2.6034485228321547

Epoch: 5| Step: 2
Training loss: 0.9792091211624995
Validation loss: 2.56349938185888

Epoch: 5| Step: 3
Training loss: 0.9827062600939966
Validation loss: 2.5896176698096016

Epoch: 5| Step: 4
Training loss: 0.9747305204211525
Validation loss: 2.5543164051475906

Epoch: 5| Step: 5
Training loss: 0.8617175339995422
Validation loss: 2.571198977678455

Epoch: 5| Step: 6
Training loss: 0.9797529974402704
Validation loss: 2.5649436985858625

Epoch: 5| Step: 7
Training loss: 0.908869837031038
Validation loss: 2.5528499932569657

Epoch: 5| Step: 8
Training loss: 0.848025123039604
Validation loss: 2.5888699810099824

Epoch: 5| Step: 9
Training loss: 0.6834693359509232
Validation loss: 2.605745565558985

Epoch: 5| Step: 10
Training loss: 0.855392557173862
Validation loss: 2.6171595663001224

Epoch: 308| Step: 0
Training loss: 1.150179935973749
Validation loss: 2.6072125335360883

Epoch: 5| Step: 1
Training loss: 1.172762420341315
Validation loss: 2.587666515104635

Epoch: 5| Step: 2
Training loss: 0.5623715042002214
Validation loss: 2.586633504133364

Epoch: 5| Step: 3
Training loss: 0.446522524347774
Validation loss: 2.610335613057898

Epoch: 5| Step: 4
Training loss: 0.8696532719929285
Validation loss: 2.592235704812557

Epoch: 5| Step: 5
Training loss: 0.8272201344876673
Validation loss: 2.5612608351786785

Epoch: 5| Step: 6
Training loss: 1.0152700537547075
Validation loss: 2.5884704863966115

Epoch: 5| Step: 7
Training loss: 0.756108836720964
Validation loss: 2.5829648268770886

Epoch: 5| Step: 8
Training loss: 1.028743761769103
Validation loss: 2.5799523235242545

Epoch: 5| Step: 9
Training loss: 0.9077696719547651
Validation loss: 2.567330758954723

Epoch: 5| Step: 10
Training loss: 0.9175477056548094
Validation loss: 2.567659284023396

Epoch: 309| Step: 0
Training loss: 0.9530676527437504
Validation loss: 2.5778757401804175

Epoch: 5| Step: 1
Training loss: 0.7769746910696281
Validation loss: 2.5919244605641794

Epoch: 5| Step: 2
Training loss: 0.9829964445909406
Validation loss: 2.5892322888579162

Epoch: 5| Step: 3
Training loss: 0.5667069261872477
Validation loss: 2.5498362486409496

Epoch: 5| Step: 4
Training loss: 1.0531033522194926
Validation loss: 2.5762472016916593

Epoch: 5| Step: 5
Training loss: 1.1186566596278869
Validation loss: 2.5657014214675526

Epoch: 5| Step: 6
Training loss: 1.1128199642266363
Validation loss: 2.5733633797365503

Epoch: 5| Step: 7
Training loss: 0.8609335897533422
Validation loss: 2.5716024932431747

Epoch: 5| Step: 8
Training loss: 0.8697182782367779
Validation loss: 2.5503946476275337

Epoch: 5| Step: 9
Training loss: 0.7632194408117948
Validation loss: 2.575647775260712

Epoch: 5| Step: 10
Training loss: 0.30497683945254395
Validation loss: 2.5713407557559282

Epoch: 310| Step: 0
Training loss: 0.7227913395167008
Validation loss: 2.566513258327823

Epoch: 5| Step: 1
Training loss: 1.0927235828034998
Validation loss: 2.59924754802034

Epoch: 5| Step: 2
Training loss: 0.9818806304381694
Validation loss: 2.601381664574404

Epoch: 5| Step: 3
Training loss: 0.9840355242329533
Validation loss: 2.5873170305757576

Epoch: 5| Step: 4
Training loss: 0.7987192541422555
Validation loss: 2.586253533865156

Epoch: 5| Step: 5
Training loss: 1.2621267031227144
Validation loss: 2.541976765221476

Epoch: 5| Step: 6
Training loss: 0.5660789333239706
Validation loss: 2.561342097325543

Epoch: 5| Step: 7
Training loss: 0.9790885298915692
Validation loss: 2.5588162663978

Epoch: 5| Step: 8
Training loss: 0.8261989652191789
Validation loss: 2.5492510698531827

Epoch: 5| Step: 9
Training loss: 0.6147099030547327
Validation loss: 2.557789627359708

Epoch: 5| Step: 10
Training loss: 0.720890051938432
Validation loss: 2.533511184004184

Epoch: 311| Step: 0
Training loss: 0.5637823428838052
Validation loss: 2.5779525724034826

Epoch: 5| Step: 1
Training loss: 0.5829725654209317
Validation loss: 2.5711510365742147

Epoch: 5| Step: 2
Training loss: 1.0281470461629652
Validation loss: 2.5911623316042904

Epoch: 5| Step: 3
Training loss: 1.1338715437032247
Validation loss: 2.6257565824628477

Epoch: 5| Step: 4
Training loss: 0.9882728666771717
Validation loss: 2.5823822728595283

Epoch: 5| Step: 5
Training loss: 0.8757075106010439
Validation loss: 2.616898558842615

Epoch: 5| Step: 6
Training loss: 1.07500897559034
Validation loss: 2.635814003687379

Epoch: 5| Step: 7
Training loss: 0.7807341207525654
Validation loss: 2.589875047911248

Epoch: 5| Step: 8
Training loss: 1.0447554696463168
Validation loss: 2.6039178669529464

Epoch: 5| Step: 9
Training loss: 0.5293658165883901
Validation loss: 2.5705029911702737

Epoch: 5| Step: 10
Training loss: 0.9087400756461933
Validation loss: 2.5798681338161056

Epoch: 312| Step: 0
Training loss: 0.4684287878019047
Validation loss: 2.5726769710859356

Epoch: 5| Step: 1
Training loss: 0.9844972443743065
Validation loss: 2.564888501047781

Epoch: 5| Step: 2
Training loss: 0.8183341011023043
Validation loss: 2.58405873980045

Epoch: 5| Step: 3
Training loss: 0.8420815395869032
Validation loss: 2.613133834221679

Epoch: 5| Step: 4
Training loss: 0.7503161558723913
Validation loss: 2.600414485605313

Epoch: 5| Step: 5
Training loss: 0.8467022849898561
Validation loss: 2.6127634147151393

Epoch: 5| Step: 6
Training loss: 0.8853710873409787
Validation loss: 2.614537481391204

Epoch: 5| Step: 7
Training loss: 0.7281807546593764
Validation loss: 2.594989060095068

Epoch: 5| Step: 8
Training loss: 0.8385167128046647
Validation loss: 2.562519848754428

Epoch: 5| Step: 9
Training loss: 1.020703223104724
Validation loss: 2.554441539219393

Epoch: 5| Step: 10
Training loss: 1.2428451332755428
Validation loss: 2.543064137380421

Epoch: 313| Step: 0
Training loss: 0.658243466734202
Validation loss: 2.5387429797840304

Epoch: 5| Step: 1
Training loss: 0.6737262151196531
Validation loss: 2.5445324721496156

Epoch: 5| Step: 2
Training loss: 1.0855168687448906
Validation loss: 2.6012826769252113

Epoch: 5| Step: 3
Training loss: 0.7290311324087464
Validation loss: 2.569800581155661

Epoch: 5| Step: 4
Training loss: 1.314828034169321
Validation loss: 2.5731173156389047

Epoch: 5| Step: 5
Training loss: 0.8101843333365993
Validation loss: 2.597489333297025

Epoch: 5| Step: 6
Training loss: 0.7797454843002043
Validation loss: 2.566379748452466

Epoch: 5| Step: 7
Training loss: 1.051228481258456
Validation loss: 2.592933108056978

Epoch: 5| Step: 8
Training loss: 0.6070783815288868
Validation loss: 2.613701881663374

Epoch: 5| Step: 9
Training loss: 0.629579314221779
Validation loss: 2.5619804441876295

Epoch: 5| Step: 10
Training loss: 0.7351611778750844
Validation loss: 2.5632857971934184

Epoch: 314| Step: 0
Training loss: 1.072993186271343
Validation loss: 2.589339122163821

Epoch: 5| Step: 1
Training loss: 1.0950450314881752
Validation loss: 2.6023354124183653

Epoch: 5| Step: 2
Training loss: 0.6680279978749575
Validation loss: 2.5997464629447578

Epoch: 5| Step: 3
Training loss: 0.5377635509285711
Validation loss: 2.6094250820659846

Epoch: 5| Step: 4
Training loss: 0.7392840966574884
Validation loss: 2.576079499871274

Epoch: 5| Step: 5
Training loss: 0.7367105882016578
Validation loss: 2.589866036115497

Epoch: 5| Step: 6
Training loss: 1.0948163964660125
Validation loss: 2.5999985235792185

Epoch: 5| Step: 7
Training loss: 0.5482558392441197
Validation loss: 2.57419511142868

Epoch: 5| Step: 8
Training loss: 0.6988108206877964
Validation loss: 2.55991094169147

Epoch: 5| Step: 9
Training loss: 0.8098025661788683
Validation loss: 2.5619230063479446

Epoch: 5| Step: 10
Training loss: 1.0801605689813456
Validation loss: 2.569137444780814

Epoch: 315| Step: 0
Training loss: 0.7040408210108905
Validation loss: 2.562026780776044

Epoch: 5| Step: 1
Training loss: 0.9897111341703697
Validation loss: 2.639883700536221

Epoch: 5| Step: 2
Training loss: 0.6042369741330798
Validation loss: 2.5781657176253208

Epoch: 5| Step: 3
Training loss: 0.2752778383706808
Validation loss: 2.6099383914075527

Epoch: 5| Step: 4
Training loss: 0.9415300849730845
Validation loss: 2.6107431801028005

Epoch: 5| Step: 5
Training loss: 1.1067261570907865
Validation loss: 2.632688498787898

Epoch: 5| Step: 6
Training loss: 0.8243349183282398
Validation loss: 2.5773123376720237

Epoch: 5| Step: 7
Training loss: 0.5898897772003282
Validation loss: 2.6020356474498523

Epoch: 5| Step: 8
Training loss: 0.9704787610995883
Validation loss: 2.558216299148667

Epoch: 5| Step: 9
Training loss: 0.7809971972572746
Validation loss: 2.567061390534015

Epoch: 5| Step: 10
Training loss: 1.0544921128876559
Validation loss: 2.5879591905082395

Epoch: 316| Step: 0
Training loss: 0.7316384563424088
Validation loss: 2.5441721672884117

Epoch: 5| Step: 1
Training loss: 0.9026202814358936
Validation loss: 2.563164596552823

Epoch: 5| Step: 2
Training loss: 1.0137676568616174
Validation loss: 2.529336092070744

Epoch: 5| Step: 3
Training loss: 0.6259983195839895
Validation loss: 2.5181402035944385

Epoch: 5| Step: 4
Training loss: 0.4942762618441752
Validation loss: 2.5373517357488455

Epoch: 5| Step: 5
Training loss: 0.9009338858350334
Validation loss: 2.503119608076076

Epoch: 5| Step: 6
Training loss: 1.21331759936922
Validation loss: 2.5608001461327747

Epoch: 5| Step: 7
Training loss: 0.9207286496158625
Validation loss: 2.541456571583848

Epoch: 5| Step: 8
Training loss: 0.7156729553013287
Validation loss: 2.5476706378282183

Epoch: 5| Step: 9
Training loss: 0.6109174866581284
Validation loss: 2.560564244902876

Epoch: 5| Step: 10
Training loss: 0.7567865958588328
Validation loss: 2.5266502747504673

Epoch: 317| Step: 0
Training loss: 0.9356951824971314
Validation loss: 2.526013888447476

Epoch: 5| Step: 1
Training loss: 0.8447231050100846
Validation loss: 2.5542111501634355

Epoch: 5| Step: 2
Training loss: 1.0968541374287448
Validation loss: 2.5445219023455117

Epoch: 5| Step: 3
Training loss: 0.5730241299037236
Validation loss: 2.5447159204226057

Epoch: 5| Step: 4
Training loss: 0.7764266849008102
Validation loss: 2.5568003020247145

Epoch: 5| Step: 5
Training loss: 0.830628300266297
Validation loss: 2.5938028902704566

Epoch: 5| Step: 6
Training loss: 0.8444004024521823
Validation loss: 2.5673815253785035

Epoch: 5| Step: 7
Training loss: 0.9145393757839593
Validation loss: 2.552782506308776

Epoch: 5| Step: 8
Training loss: 0.6201707711685828
Validation loss: 2.6034040913731964

Epoch: 5| Step: 9
Training loss: 0.6947358129452272
Validation loss: 2.577142002398422

Epoch: 5| Step: 10
Training loss: 0.8838345173480079
Validation loss: 2.597568411972316

Epoch: 318| Step: 0
Training loss: 0.7635559618463028
Validation loss: 2.620504723851151

Epoch: 5| Step: 1
Training loss: 0.746195162127273
Validation loss: 2.614042595760711

Epoch: 5| Step: 2
Training loss: 0.4943314436426054
Validation loss: 2.625547750371958

Epoch: 5| Step: 3
Training loss: 1.0471078983698634
Validation loss: 2.622203526859833

Epoch: 5| Step: 4
Training loss: 0.9374786374519213
Validation loss: 2.6342189767868516

Epoch: 5| Step: 5
Training loss: 0.8538204321007284
Validation loss: 2.6336815715028785

Epoch: 5| Step: 6
Training loss: 0.9355239387519848
Validation loss: 2.635116119997096

Epoch: 5| Step: 7
Training loss: 0.4709753302027848
Validation loss: 2.613590839621331

Epoch: 5| Step: 8
Training loss: 0.7146957327598297
Validation loss: 2.621085672998944

Epoch: 5| Step: 9
Training loss: 1.1619406184914394
Validation loss: 2.59509303457743

Epoch: 5| Step: 10
Training loss: 0.5322501641036282
Validation loss: 2.6095931431293153

Epoch: 319| Step: 0
Training loss: 0.8551409367633592
Validation loss: 2.5808749381823595

Epoch: 5| Step: 1
Training loss: 0.8408153502775322
Validation loss: 2.558260802926697

Epoch: 5| Step: 2
Training loss: 0.9748559918791334
Validation loss: 2.5886170526560326

Epoch: 5| Step: 3
Training loss: 0.7527260511142969
Validation loss: 2.559830748769132

Epoch: 5| Step: 4
Training loss: 1.0935285616555954
Validation loss: 2.568376838795956

Epoch: 5| Step: 5
Training loss: 0.7358280578357927
Validation loss: 2.5675839050758795

Epoch: 5| Step: 6
Training loss: 0.5744741481678239
Validation loss: 2.572927848516283

Epoch: 5| Step: 7
Training loss: 0.9622851280545794
Validation loss: 2.593745235948256

Epoch: 5| Step: 8
Training loss: 0.47753840721413054
Validation loss: 2.5693706701038774

Epoch: 5| Step: 9
Training loss: 0.7727254036253492
Validation loss: 2.5736181857084053

Epoch: 5| Step: 10
Training loss: 0.4464042398089051
Validation loss: 2.5731157987457594

Epoch: 320| Step: 0
Training loss: 0.9197526845019255
Validation loss: 2.6129864699746883

Epoch: 5| Step: 1
Training loss: 1.0509229940229445
Validation loss: 2.602679984401873

Epoch: 5| Step: 2
Training loss: 0.8041119044604548
Validation loss: 2.6090308425361863

Epoch: 5| Step: 3
Training loss: 0.5182860229842832
Validation loss: 2.586246888473018

Epoch: 5| Step: 4
Training loss: 1.0906950111106486
Validation loss: 2.618918734090555

Epoch: 5| Step: 5
Training loss: 0.6047378558500334
Validation loss: 2.5833267283942356

Epoch: 5| Step: 6
Training loss: 0.4802692743580922
Validation loss: 2.6130765907157207

Epoch: 5| Step: 7
Training loss: 0.661180232501293
Validation loss: 2.5944073275695057

Epoch: 5| Step: 8
Training loss: 0.6199895532173982
Validation loss: 2.5980241264440544

Epoch: 5| Step: 9
Training loss: 0.8157966564676684
Validation loss: 2.5873311080254138

Epoch: 5| Step: 10
Training loss: 0.8671644053090284
Validation loss: 2.610709120660975

Epoch: 321| Step: 0
Training loss: 0.9343044496776733
Validation loss: 2.6228826883746965

Epoch: 5| Step: 1
Training loss: 0.7448289146090253
Validation loss: 2.599695262530381

Epoch: 5| Step: 2
Training loss: 0.7521908867208629
Validation loss: 2.5911464589543276

Epoch: 5| Step: 3
Training loss: 0.7148044763001167
Validation loss: 2.5832454224499872

Epoch: 5| Step: 4
Training loss: 0.6314009476523769
Validation loss: 2.6284827739517347

Epoch: 5| Step: 5
Training loss: 0.7151758641926004
Validation loss: 2.578086295385802

Epoch: 5| Step: 6
Training loss: 0.6597431854352889
Validation loss: 2.6125313538090156

Epoch: 5| Step: 7
Training loss: 0.9041711048304424
Validation loss: 2.5726226908386294

Epoch: 5| Step: 8
Training loss: 1.1798502323506543
Validation loss: 2.5809183817609314

Epoch: 5| Step: 9
Training loss: 0.6054802924255771
Validation loss: 2.562435900679072

Epoch: 5| Step: 10
Training loss: 0.4825857092774115
Validation loss: 2.5706611210113035

Epoch: 322| Step: 0
Training loss: 0.7807059491764087
Validation loss: 2.5655001633492964

Epoch: 5| Step: 1
Training loss: 0.8338500725484617
Validation loss: 2.5698925704722626

Epoch: 5| Step: 2
Training loss: 0.8661378917838491
Validation loss: 2.5817521628771027

Epoch: 5| Step: 3
Training loss: 0.5751777477853205
Validation loss: 2.549886942107888

Epoch: 5| Step: 4
Training loss: 0.7424922919595763
Validation loss: 2.5763297763055366

Epoch: 5| Step: 5
Training loss: 0.833424221486579
Validation loss: 2.5755624624148483

Epoch: 5| Step: 6
Training loss: 0.6231765133868007
Validation loss: 2.5793363358674557

Epoch: 5| Step: 7
Training loss: 0.5445565533881931
Validation loss: 2.536941855861853

Epoch: 5| Step: 8
Training loss: 0.820727034687582
Validation loss: 2.549196100725349

Epoch: 5| Step: 9
Training loss: 0.9513818090102709
Validation loss: 2.526531799553207

Epoch: 5| Step: 10
Training loss: 0.8496683736025502
Validation loss: 2.549637506775855

Epoch: 323| Step: 0
Training loss: 0.9394036991814039
Validation loss: 2.558581586024654

Epoch: 5| Step: 1
Training loss: 0.47036444481698486
Validation loss: 2.5587046138538807

Epoch: 5| Step: 2
Training loss: 0.8083689280338386
Validation loss: 2.5603118786396704

Epoch: 5| Step: 3
Training loss: 0.7878000717060398
Validation loss: 2.5427297315351534

Epoch: 5| Step: 4
Training loss: 1.1456310729486525
Validation loss: 2.5770608932750734

Epoch: 5| Step: 5
Training loss: 0.7674930127350789
Validation loss: 2.5269859552539375

Epoch: 5| Step: 6
Training loss: 0.4661978864820727
Validation loss: 2.5520773838384883

Epoch: 5| Step: 7
Training loss: 0.7073639566355245
Validation loss: 2.5645274443688604

Epoch: 5| Step: 8
Training loss: 0.7488716697867153
Validation loss: 2.538261719692935

Epoch: 5| Step: 9
Training loss: 0.827075581230008
Validation loss: 2.5352878022906458

Epoch: 5| Step: 10
Training loss: 0.6000647291394963
Validation loss: 2.562257730760164

Epoch: 324| Step: 0
Training loss: 0.6695697403908615
Validation loss: 2.5447700116517233

Epoch: 5| Step: 1
Training loss: 0.71883503784
Validation loss: 2.531154459096312

Epoch: 5| Step: 2
Training loss: 0.5699672437759108
Validation loss: 2.5512589948840607

Epoch: 5| Step: 3
Training loss: 0.7681431910795021
Validation loss: 2.611327767647262

Epoch: 5| Step: 4
Training loss: 0.4942927823621544
Validation loss: 2.627595679737152

Epoch: 5| Step: 5
Training loss: 1.1055641807100425
Validation loss: 2.634620769734959

Epoch: 5| Step: 6
Training loss: 0.7679775839032668
Validation loss: 2.601333475543708

Epoch: 5| Step: 7
Training loss: 0.7309547888059499
Validation loss: 2.6146438695232606

Epoch: 5| Step: 8
Training loss: 0.7780177199471278
Validation loss: 2.646175789336445

Epoch: 5| Step: 9
Training loss: 0.8548995262361544
Validation loss: 2.5906842771355114

Epoch: 5| Step: 10
Training loss: 0.7505169517386712
Validation loss: 2.619931091409707

Epoch: 325| Step: 0
Training loss: 0.6520537914088379
Validation loss: 2.586335944626606

Epoch: 5| Step: 1
Training loss: 0.3334705907137929
Validation loss: 2.5996959764892793

Epoch: 5| Step: 2
Training loss: 0.7867542156570799
Validation loss: 2.602607189889716

Epoch: 5| Step: 3
Training loss: 0.8619969684034173
Validation loss: 2.588168881812205

Epoch: 5| Step: 4
Training loss: 0.8977585258684546
Validation loss: 2.5902304800411136

Epoch: 5| Step: 5
Training loss: 0.77526708430681
Validation loss: 2.5832983868709873

Epoch: 5| Step: 6
Training loss: 0.5413942079732397
Validation loss: 2.6137779040169833

Epoch: 5| Step: 7
Training loss: 0.8547535175162966
Validation loss: 2.5778352367634225

Epoch: 5| Step: 8
Training loss: 0.5406761068101281
Validation loss: 2.593892089257007

Epoch: 5| Step: 9
Training loss: 0.9736763381029298
Validation loss: 2.611079623450604

Epoch: 5| Step: 10
Training loss: 0.7139242543425515
Validation loss: 2.585396032150303

Epoch: 326| Step: 0
Training loss: 0.6494923709321482
Validation loss: 2.551889436214874

Epoch: 5| Step: 1
Training loss: 0.8769945164621054
Validation loss: 2.563628911723529

Epoch: 5| Step: 2
Training loss: 0.46406536486733574
Validation loss: 2.564362424141157

Epoch: 5| Step: 3
Training loss: 1.0077560763865523
Validation loss: 2.531252943184338

Epoch: 5| Step: 4
Training loss: 0.5607145105305951
Validation loss: 2.5622295053791673

Epoch: 5| Step: 5
Training loss: 0.7641110535467028
Validation loss: 2.53745988195504

Epoch: 5| Step: 6
Training loss: 0.7282488132366302
Validation loss: 2.548494642977645

Epoch: 5| Step: 7
Training loss: 0.551577837463323
Validation loss: 2.5519112280113503

Epoch: 5| Step: 8
Training loss: 0.5772772579076765
Validation loss: 2.5071435940388684

Epoch: 5| Step: 9
Training loss: 0.7783891175991343
Validation loss: 2.5107751821019892

Epoch: 5| Step: 10
Training loss: 0.9351928295862418
Validation loss: 2.556633872052209

Epoch: 327| Step: 0
Training loss: 0.7738700581896375
Validation loss: 2.5393707709205935

Epoch: 5| Step: 1
Training loss: 0.7108038892010586
Validation loss: 2.521150689186084

Epoch: 5| Step: 2
Training loss: 0.7992123004134772
Validation loss: 2.5630242286452907

Epoch: 5| Step: 3
Training loss: 0.8688539868150217
Validation loss: 2.5619160126526563

Epoch: 5| Step: 4
Training loss: 0.8546425300218576
Validation loss: 2.538793375220884

Epoch: 5| Step: 5
Training loss: 0.5148147806402135
Validation loss: 2.559568050908246

Epoch: 5| Step: 6
Training loss: 0.7864174653270509
Validation loss: 2.5381011056532206

Epoch: 5| Step: 7
Training loss: 0.5106353648054782
Validation loss: 2.579859724035088

Epoch: 5| Step: 8
Training loss: 0.6248896978320531
Validation loss: 2.5745473879072827

Epoch: 5| Step: 9
Training loss: 0.8262313208149431
Validation loss: 2.577274121192777

Epoch: 5| Step: 10
Training loss: 0.7329603326688643
Validation loss: 2.6020329518202137

Epoch: 328| Step: 0
Training loss: 0.631276090479347
Validation loss: 2.5905190151444346

Epoch: 5| Step: 1
Training loss: 0.8521322741517668
Validation loss: 2.575909260226924

Epoch: 5| Step: 2
Training loss: 0.6378432097978207
Validation loss: 2.59559251793493

Epoch: 5| Step: 3
Training loss: 0.6034475244907342
Validation loss: 2.622389690446028

Epoch: 5| Step: 4
Training loss: 0.5726258117580093
Validation loss: 2.6149703617212765

Epoch: 5| Step: 5
Training loss: 0.7117350370216393
Validation loss: 2.600538780656015

Epoch: 5| Step: 6
Training loss: 0.8199679786547366
Validation loss: 2.6050852248711682

Epoch: 5| Step: 7
Training loss: 0.7653465153777873
Validation loss: 2.579754900069681

Epoch: 5| Step: 8
Training loss: 0.9831736060444756
Validation loss: 2.633383217439438

Epoch: 5| Step: 9
Training loss: 0.6611875570556662
Validation loss: 2.5966409879503627

Epoch: 5| Step: 10
Training loss: 0.6530619111687744
Validation loss: 2.602601732829555

Epoch: 329| Step: 0
Training loss: 0.6244505374338924
Validation loss: 2.6063323579940114

Epoch: 5| Step: 1
Training loss: 0.7184773632935464
Validation loss: 2.575230676864083

Epoch: 5| Step: 2
Training loss: 0.42283410086929873
Validation loss: 2.557862709613968

Epoch: 5| Step: 3
Training loss: 0.5949389449618081
Validation loss: 2.547240516337852

Epoch: 5| Step: 4
Training loss: 0.5612557212520992
Validation loss: 2.5490697959645003

Epoch: 5| Step: 5
Training loss: 0.7771606996560652
Validation loss: 2.5349747550004897

Epoch: 5| Step: 6
Training loss: 0.8172925309030704
Validation loss: 2.542289988458407

Epoch: 5| Step: 7
Training loss: 0.7298114695808393
Validation loss: 2.549531271294799

Epoch: 5| Step: 8
Training loss: 0.6636280433770383
Validation loss: 2.543072426901034

Epoch: 5| Step: 9
Training loss: 1.071841185456227
Validation loss: 2.5058259289495908

Epoch: 5| Step: 10
Training loss: 0.9182952949367664
Validation loss: 2.5504183821507684

Epoch: 330| Step: 0
Training loss: 0.828499583332277
Validation loss: 2.5809759471506597

Epoch: 5| Step: 1
Training loss: 0.6014689583319442
Validation loss: 2.589425760221283

Epoch: 5| Step: 2
Training loss: 0.8756320918229614
Validation loss: 2.573232605369853

Epoch: 5| Step: 3
Training loss: 0.5362214117721635
Validation loss: 2.6147744547250285

Epoch: 5| Step: 4
Training loss: 0.7315982511014563
Validation loss: 2.603605915034487

Epoch: 5| Step: 5
Training loss: 0.8570350000096
Validation loss: 2.5907824135241997

Epoch: 5| Step: 6
Training loss: 0.9440109498471914
Validation loss: 2.582622715812427

Epoch: 5| Step: 7
Training loss: 0.5080950317835886
Validation loss: 2.572163265330478

Epoch: 5| Step: 8
Training loss: 0.694654689328011
Validation loss: 2.570637443741757

Epoch: 5| Step: 9
Training loss: 0.6047005486867039
Validation loss: 2.5579777132292834

Epoch: 5| Step: 10
Training loss: 0.5200809925992214
Validation loss: 2.5908573980513387

Epoch: 331| Step: 0
Training loss: 0.8064654069920579
Validation loss: 2.586766511759602

Epoch: 5| Step: 1
Training loss: 0.5563369993689405
Validation loss: 2.599265633266976

Epoch: 5| Step: 2
Training loss: 0.7163825227724839
Validation loss: 2.585260407491774

Epoch: 5| Step: 3
Training loss: 0.5636521302252575
Validation loss: 2.5859586896190234

Epoch: 5| Step: 4
Training loss: 0.5849238465129306
Validation loss: 2.5981942116232646

Epoch: 5| Step: 5
Training loss: 0.9258757595318192
Validation loss: 2.590013791358494

Epoch: 5| Step: 6
Training loss: 0.7659972706589243
Validation loss: 2.5577070610887582

Epoch: 5| Step: 7
Training loss: 0.6899982059151365
Validation loss: 2.566729862466988

Epoch: 5| Step: 8
Training loss: 0.7096499426985304
Validation loss: 2.577650978360625

Epoch: 5| Step: 9
Training loss: 0.5263905705794438
Validation loss: 2.586183645372323

Epoch: 5| Step: 10
Training loss: 0.8616178894502216
Validation loss: 2.579036244341774

Epoch: 332| Step: 0
Training loss: 0.3777166549802517
Validation loss: 2.568268348930214

Epoch: 5| Step: 1
Training loss: 0.752843552547152
Validation loss: 2.6195563297470574

Epoch: 5| Step: 2
Training loss: 0.4599700084528854
Validation loss: 2.6384922829129747

Epoch: 5| Step: 3
Training loss: 0.8615112110101453
Validation loss: 2.6354743172677786

Epoch: 5| Step: 4
Training loss: 0.692892707342429
Validation loss: 2.592689071582603

Epoch: 5| Step: 5
Training loss: 0.5866988766653134
Validation loss: 2.5574674498081547

Epoch: 5| Step: 6
Training loss: 0.6399582207349712
Validation loss: 2.539947342459614

Epoch: 5| Step: 7
Training loss: 0.6669545421337288
Validation loss: 2.5181845121153765

Epoch: 5| Step: 8
Training loss: 0.8273797550597877
Validation loss: 2.553422192850367

Epoch: 5| Step: 9
Training loss: 0.772426869717802
Validation loss: 2.5674280870124715

Epoch: 5| Step: 10
Training loss: 0.9597820064775325
Validation loss: 2.548724176285222

Epoch: 333| Step: 0
Training loss: 0.5279556397873184
Validation loss: 2.544542496849381

Epoch: 5| Step: 1
Training loss: 0.8923317466947832
Validation loss: 2.5547887465894488

Epoch: 5| Step: 2
Training loss: 0.5945779398606923
Validation loss: 2.5619081143270956

Epoch: 5| Step: 3
Training loss: 0.3403898433582646
Validation loss: 2.5300658056486856

Epoch: 5| Step: 4
Training loss: 0.5805938688541198
Validation loss: 2.566169704268777

Epoch: 5| Step: 5
Training loss: 0.7461743136543729
Validation loss: 2.5321810134511598

Epoch: 5| Step: 6
Training loss: 0.7692153979562968
Validation loss: 2.594517930815058

Epoch: 5| Step: 7
Training loss: 0.2731952547854755
Validation loss: 2.553136686951328

Epoch: 5| Step: 8
Training loss: 0.7668871305170052
Validation loss: 2.5873745209809234

Epoch: 5| Step: 9
Training loss: 1.0131357057583503
Validation loss: 2.582386026416196

Epoch: 5| Step: 10
Training loss: 0.7577874877577307
Validation loss: 2.583423112453086

Epoch: 334| Step: 0
Training loss: 0.7787659636402793
Validation loss: 2.5745397155371323

Epoch: 5| Step: 1
Training loss: 0.7630531165331614
Validation loss: 2.5828873814746887

Epoch: 5| Step: 2
Training loss: 0.7007640194342781
Validation loss: 2.5747835871402693

Epoch: 5| Step: 3
Training loss: 0.5852885148999183
Validation loss: 2.59074254505963

Epoch: 5| Step: 4
Training loss: 0.7595737479758263
Validation loss: 2.61073344986101

Epoch: 5| Step: 5
Training loss: 0.2133257994044807
Validation loss: 2.654951332344083

Epoch: 5| Step: 6
Training loss: 0.5251905209119523
Validation loss: 2.5929865646975077

Epoch: 5| Step: 7
Training loss: 0.7469885687891769
Validation loss: 2.5817603669044225

Epoch: 5| Step: 8
Training loss: 0.45335241070160387
Validation loss: 2.6062142559992143

Epoch: 5| Step: 9
Training loss: 0.47602701588907975
Validation loss: 2.5731623851401175

Epoch: 5| Step: 10
Training loss: 1.097621930763533
Validation loss: 2.576402041598625

Epoch: 335| Step: 0
Training loss: 0.810721210896687
Validation loss: 2.6114668527069194

Epoch: 5| Step: 1
Training loss: 0.3090687729340662
Validation loss: 2.5838814080253902

Epoch: 5| Step: 2
Training loss: 0.5395226932999363
Validation loss: 2.564184195125827

Epoch: 5| Step: 3
Training loss: 0.70530356821093
Validation loss: 2.5806012206605153

Epoch: 5| Step: 4
Training loss: 0.5102442690290562
Validation loss: 2.6039314071872366

Epoch: 5| Step: 5
Training loss: 0.5998582603009216
Validation loss: 2.5868861735319406

Epoch: 5| Step: 6
Training loss: 0.8483147590330012
Validation loss: 2.5320713883468455

Epoch: 5| Step: 7
Training loss: 0.44263287817497377
Validation loss: 2.556752295483663

Epoch: 5| Step: 8
Training loss: 0.9154784492152057
Validation loss: 2.577945420321158

Epoch: 5| Step: 9
Training loss: 0.9161762023599783
Validation loss: 2.597290592640134

Epoch: 5| Step: 10
Training loss: 0.45896138884430154
Validation loss: 2.580107399133672

Epoch: 336| Step: 0
Training loss: 0.3537238756380188
Validation loss: 2.5854187195218516

Epoch: 5| Step: 1
Training loss: 0.8342682045015478
Validation loss: 2.5762556123190508

Epoch: 5| Step: 2
Training loss: 0.5517709916152809
Validation loss: 2.591251332598511

Epoch: 5| Step: 3
Training loss: 0.8059072046698412
Validation loss: 2.5876034285617013

Epoch: 5| Step: 4
Training loss: 0.748485705390157
Validation loss: 2.566803765347653

Epoch: 5| Step: 5
Training loss: 0.32649647670425047
Validation loss: 2.554707004040783

Epoch: 5| Step: 6
Training loss: 0.8303787225711319
Validation loss: 2.5252878566161487

Epoch: 5| Step: 7
Training loss: 0.7862793211329019
Validation loss: 2.515530427971471

Epoch: 5| Step: 8
Training loss: 0.5865309189844241
Validation loss: 2.543095082064365

Epoch: 5| Step: 9
Training loss: 0.6801913794312509
Validation loss: 2.538432290595483

Epoch: 5| Step: 10
Training loss: 0.6799333500455397
Validation loss: 2.5855336446587667

Epoch: 337| Step: 0
Training loss: 0.7688946874656521
Validation loss: 2.5648986880689546

Epoch: 5| Step: 1
Training loss: 0.7638538270668043
Validation loss: 2.5810953450032157

Epoch: 5| Step: 2
Training loss: 0.7807359530149939
Validation loss: 2.5857263378533197

Epoch: 5| Step: 3
Training loss: 0.6124197625134611
Validation loss: 2.6078506624125812

Epoch: 5| Step: 4
Training loss: 0.917936608583749
Validation loss: 2.5847460614931577

Epoch: 5| Step: 5
Training loss: 0.6207787056598807
Validation loss: 2.5728143910242385

Epoch: 5| Step: 6
Training loss: 0.5119585829277524
Validation loss: 2.609521891307202

Epoch: 5| Step: 7
Training loss: 0.5348364995520143
Validation loss: 2.6179054447298946

Epoch: 5| Step: 8
Training loss: 0.5765481269926421
Validation loss: 2.6095744329357786

Epoch: 5| Step: 9
Training loss: 0.5117673777996697
Validation loss: 2.5916451370341567

Epoch: 5| Step: 10
Training loss: 0.511879175096935
Validation loss: 2.5569990516263745

Epoch: 338| Step: 0
Training loss: 0.44275466078163406
Validation loss: 2.5923184317345456

Epoch: 5| Step: 1
Training loss: 0.9685370918855686
Validation loss: 2.5779853303178593

Epoch: 5| Step: 2
Training loss: 0.7761163654261792
Validation loss: 2.5580683799030353

Epoch: 5| Step: 3
Training loss: 0.5343086045270782
Validation loss: 2.577794246394965

Epoch: 5| Step: 4
Training loss: 0.5837752564253609
Validation loss: 2.4934962058763195

Epoch: 5| Step: 5
Training loss: 0.7131534039844397
Validation loss: 2.5433249020889983

Epoch: 5| Step: 6
Training loss: 0.8348889057699367
Validation loss: 2.5457917831583172

Epoch: 5| Step: 7
Training loss: 0.5151035677832763
Validation loss: 2.519928795244276

Epoch: 5| Step: 8
Training loss: 0.6047116375819761
Validation loss: 2.5510035936480757

Epoch: 5| Step: 9
Training loss: 0.5462067472150793
Validation loss: 2.5203598864004424

Epoch: 5| Step: 10
Training loss: 0.46472950340841707
Validation loss: 2.5730891740119737

Epoch: 339| Step: 0
Training loss: 0.5108509130341494
Validation loss: 2.579738390788836

Epoch: 5| Step: 1
Training loss: 0.7777423316015927
Validation loss: 2.5847441809740284

Epoch: 5| Step: 2
Training loss: 0.541905934111913
Validation loss: 2.538562091646574

Epoch: 5| Step: 3
Training loss: 0.7561878210310314
Validation loss: 2.584351828741163

Epoch: 5| Step: 4
Training loss: 0.7702206849014198
Validation loss: 2.5653295114512322

Epoch: 5| Step: 5
Training loss: 0.5903267051639517
Validation loss: 2.582764409745873

Epoch: 5| Step: 6
Training loss: 0.4516300665652773
Validation loss: 2.5464451226570435

Epoch: 5| Step: 7
Training loss: 0.7708068963405997
Validation loss: 2.5592220088333146

Epoch: 5| Step: 8
Training loss: 0.6514553485098901
Validation loss: 2.521964423933317

Epoch: 5| Step: 9
Training loss: 0.5988169351168054
Validation loss: 2.565932325456451

Epoch: 5| Step: 10
Training loss: 0.49646078634463137
Validation loss: 2.5914108971051264

Epoch: 340| Step: 0
Training loss: 0.5426236709581965
Validation loss: 2.611692670989036

Epoch: 5| Step: 1
Training loss: 0.6270987558422177
Validation loss: 2.5884091091244956

Epoch: 5| Step: 2
Training loss: 0.7965876491283527
Validation loss: 2.563280075395068

Epoch: 5| Step: 3
Training loss: 0.688971418731915
Validation loss: 2.5936803411802978

Epoch: 5| Step: 4
Training loss: 0.5251208041485894
Validation loss: 2.5526841729384513

Epoch: 5| Step: 5
Training loss: 0.6644055994833633
Validation loss: 2.5213325290630277

Epoch: 5| Step: 6
Training loss: 0.6049982765661867
Validation loss: 2.5445844550787253

Epoch: 5| Step: 7
Training loss: 0.6045502124848157
Validation loss: 2.5602879875069275

Epoch: 5| Step: 8
Training loss: 0.5594397587292158
Validation loss: 2.573382824915922

Epoch: 5| Step: 9
Training loss: 0.7376338804893746
Validation loss: 2.5509787701646442

Epoch: 5| Step: 10
Training loss: 0.6953772825429574
Validation loss: 2.537431730306443

Epoch: 341| Step: 0
Training loss: 0.7885061134241684
Validation loss: 2.560675627643485

Epoch: 5| Step: 1
Training loss: 0.623080787811991
Validation loss: 2.5564854465894586

Epoch: 5| Step: 2
Training loss: 0.4710608741334378
Validation loss: 2.5568227834112185

Epoch: 5| Step: 3
Training loss: 0.5160882775954652
Validation loss: 2.577369900049969

Epoch: 5| Step: 4
Training loss: 0.8985058634083208
Validation loss: 2.5974281839453033

Epoch: 5| Step: 5
Training loss: 0.7438335035234012
Validation loss: 2.551588897993526

Epoch: 5| Step: 6
Training loss: 0.5172986985720994
Validation loss: 2.558354271367517

Epoch: 5| Step: 7
Training loss: 0.6570888108521261
Validation loss: 2.565621808228577

Epoch: 5| Step: 8
Training loss: 0.6356202930137372
Validation loss: 2.594358129531546

Epoch: 5| Step: 9
Training loss: 0.5742228501361643
Validation loss: 2.55098454869841

Epoch: 5| Step: 10
Training loss: 0.4522715950771344
Validation loss: 2.5610067907646648

Epoch: 342| Step: 0
Training loss: 0.7804544976415643
Validation loss: 2.5610961370006886

Epoch: 5| Step: 1
Training loss: 0.6013843718523807
Validation loss: 2.533948719852394

Epoch: 5| Step: 2
Training loss: 0.7378181337095433
Validation loss: 2.5382483407119913

Epoch: 5| Step: 3
Training loss: 0.5590741952405279
Validation loss: 2.572269631517534

Epoch: 5| Step: 4
Training loss: 0.41943293650245905
Validation loss: 2.563326456498721

Epoch: 5| Step: 5
Training loss: 0.5474238502550645
Validation loss: 2.5498145024524312

Epoch: 5| Step: 6
Training loss: 0.41971609706976093
Validation loss: 2.5434981551899267

Epoch: 5| Step: 7
Training loss: 0.6084111244507601
Validation loss: 2.5720773385475586

Epoch: 5| Step: 8
Training loss: 0.583605589229496
Validation loss: 2.5599562421963395

Epoch: 5| Step: 9
Training loss: 0.7740262035596709
Validation loss: 2.5556031021015695

Epoch: 5| Step: 10
Training loss: 0.7022002390719044
Validation loss: 2.553084883173443

Epoch: 343| Step: 0
Training loss: 0.525677627396391
Validation loss: 2.5683989957662656

Epoch: 5| Step: 1
Training loss: 0.5142651167313536
Validation loss: 2.5691583099580035

Epoch: 5| Step: 2
Training loss: 0.630865067494695
Validation loss: 2.5720109571431697

Epoch: 5| Step: 3
Training loss: 0.8548953080914549
Validation loss: 2.5409380663449856

Epoch: 5| Step: 4
Training loss: 0.7848214721555681
Validation loss: 2.592275024931017

Epoch: 5| Step: 5
Training loss: 0.543741184470088
Validation loss: 2.60028293129569

Epoch: 5| Step: 6
Training loss: 0.8212032023759955
Validation loss: 2.5819622550161965

Epoch: 5| Step: 7
Training loss: 0.624584870755384
Validation loss: 2.5937717198138177

Epoch: 5| Step: 8
Training loss: 0.5628518222879983
Validation loss: 2.580169029528825

Epoch: 5| Step: 9
Training loss: 0.4448821514773518
Validation loss: 2.602120550472361

Epoch: 5| Step: 10
Training loss: 0.3071232538961567
Validation loss: 2.5905150566441044

Epoch: 344| Step: 0
Training loss: 0.5405441874263468
Validation loss: 2.596459770262238

Epoch: 5| Step: 1
Training loss: 0.6527340800514674
Validation loss: 2.598718874361977

Epoch: 5| Step: 2
Training loss: 0.667907645124341
Validation loss: 2.556527607916148

Epoch: 5| Step: 3
Training loss: 0.7687177666830317
Validation loss: 2.5514900770291167

Epoch: 5| Step: 4
Training loss: 0.734482818155856
Validation loss: 2.549309098910146

Epoch: 5| Step: 5
Training loss: 0.7439350234622366
Validation loss: 2.549426139531387

Epoch: 5| Step: 6
Training loss: 0.5269338922405383
Validation loss: 2.5499669822664104

Epoch: 5| Step: 7
Training loss: 0.4836538083401257
Validation loss: 2.555507991646714

Epoch: 5| Step: 8
Training loss: 0.4533374387044468
Validation loss: 2.582711119715163

Epoch: 5| Step: 9
Training loss: 0.620983377882274
Validation loss: 2.5737621787514398

Epoch: 5| Step: 10
Training loss: 0.4579759110847797
Validation loss: 2.5716056290025793

Epoch: 345| Step: 0
Training loss: 0.750724720488953
Validation loss: 2.579197078677083

Epoch: 5| Step: 1
Training loss: 0.6000965140124656
Validation loss: 2.5664824446701076

Epoch: 5| Step: 2
Training loss: 0.5872787383588141
Validation loss: 2.6012398444779894

Epoch: 5| Step: 3
Training loss: 0.5494336897364589
Validation loss: 2.5657040473553847

Epoch: 5| Step: 4
Training loss: 0.6078768433784713
Validation loss: 2.5389918708916857

Epoch: 5| Step: 5
Training loss: 0.625415187260426
Validation loss: 2.5712650046618495

Epoch: 5| Step: 6
Training loss: 0.6590996135537484
Validation loss: 2.5836868884407522

Epoch: 5| Step: 7
Training loss: 0.4768813583030132
Validation loss: 2.5969217642934486

Epoch: 5| Step: 8
Training loss: 0.6566695960902534
Validation loss: 2.5633874772507097

Epoch: 5| Step: 9
Training loss: 0.47775544488939103
Validation loss: 2.5284889118175706

Epoch: 5| Step: 10
Training loss: 0.7054025849230361
Validation loss: 2.559309523177114

Epoch: 346| Step: 0
Training loss: 0.6681428648912752
Validation loss: 2.526516439164742

Epoch: 5| Step: 1
Training loss: 0.9184272432744249
Validation loss: 2.57094185884416

Epoch: 5| Step: 2
Training loss: 0.5634069019542157
Validation loss: 2.5576175323101316

Epoch: 5| Step: 3
Training loss: 0.5709910601802944
Validation loss: 2.568739726694229

Epoch: 5| Step: 4
Training loss: 0.4399323795929452
Validation loss: 2.55052343632654

Epoch: 5| Step: 5
Training loss: 0.40214983887541733
Validation loss: 2.576001292144682

Epoch: 5| Step: 6
Training loss: 0.770700022192856
Validation loss: 2.613928956426177

Epoch: 5| Step: 7
Training loss: 0.22748294842399341
Validation loss: 2.568072814439139

Epoch: 5| Step: 8
Training loss: 0.8107933313186781
Validation loss: 2.6199764529935035

Epoch: 5| Step: 9
Training loss: 0.5436477806210902
Validation loss: 2.612222133248617

Epoch: 5| Step: 10
Training loss: 0.6018464050155177
Validation loss: 2.5736171796238345

Epoch: 347| Step: 0
Training loss: 0.6188023843650278
Validation loss: 2.5324494358341965

Epoch: 5| Step: 1
Training loss: 0.6058038092095808
Validation loss: 2.517076245292047

Epoch: 5| Step: 2
Training loss: 0.6053670490127924
Validation loss: 2.5237206852845966

Epoch: 5| Step: 3
Training loss: 0.5420391990274487
Validation loss: 2.531097816704314

Epoch: 5| Step: 4
Training loss: 0.5611835014692784
Validation loss: 2.51121419653492

Epoch: 5| Step: 5
Training loss: 0.7325121200912839
Validation loss: 2.5692557793236737

Epoch: 5| Step: 6
Training loss: 0.4925195391404948
Validation loss: 2.614940913176794

Epoch: 5| Step: 7
Training loss: 0.6539638753678236
Validation loss: 2.634881909203557

Epoch: 5| Step: 8
Training loss: 0.5958232820992447
Validation loss: 2.594446028817058

Epoch: 5| Step: 9
Training loss: 0.5682240223382194
Validation loss: 2.648067272194194

Epoch: 5| Step: 10
Training loss: 0.9312196176168305
Validation loss: 2.600059924054333

Epoch: 348| Step: 0
Training loss: 0.7252685345526988
Validation loss: 2.553919520916574

Epoch: 5| Step: 1
Training loss: 0.6745910306290724
Validation loss: 2.5567536135248172

Epoch: 5| Step: 2
Training loss: 0.6471358183482796
Validation loss: 2.534019538086333

Epoch: 5| Step: 3
Training loss: 0.7685822187482697
Validation loss: 2.5395907530427677

Epoch: 5| Step: 4
Training loss: 0.593243885164701
Validation loss: 2.5604915636544736

Epoch: 5| Step: 5
Training loss: 0.6323393006164697
Validation loss: 2.5953503932175606

Epoch: 5| Step: 6
Training loss: 0.5113439570599445
Validation loss: 2.5602955804254615

Epoch: 5| Step: 7
Training loss: 0.579751099133488
Validation loss: 2.6261686564631703

Epoch: 5| Step: 8
Training loss: 0.5312512341653288
Validation loss: 2.6268034832335934

Epoch: 5| Step: 9
Training loss: 0.5579157095348457
Validation loss: 2.6228540636902338

Epoch: 5| Step: 10
Training loss: 0.45995625617040353
Validation loss: 2.6077609627161316

Epoch: 349| Step: 0
Training loss: 0.4791758750638854
Validation loss: 2.61164733043647

Epoch: 5| Step: 1
Training loss: 0.43233663447638615
Validation loss: 2.6138549942007177

Epoch: 5| Step: 2
Training loss: 0.4608381778584268
Validation loss: 2.6087068480060345

Epoch: 5| Step: 3
Training loss: 0.8146590011522715
Validation loss: 2.6208015903693638

Epoch: 5| Step: 4
Training loss: 0.48902631753767717
Validation loss: 2.607020756819682

Epoch: 5| Step: 5
Training loss: 0.3583782512582511
Validation loss: 2.564576129065686

Epoch: 5| Step: 6
Training loss: 0.6894125994045864
Validation loss: 2.6028902963757004

Epoch: 5| Step: 7
Training loss: 0.5260667102505198
Validation loss: 2.564063631853496

Epoch: 5| Step: 8
Training loss: 0.6162169104043305
Validation loss: 2.60134860603758

Epoch: 5| Step: 9
Training loss: 0.6663273056871456
Validation loss: 2.5976127784330436

Epoch: 5| Step: 10
Training loss: 0.8802425483208359
Validation loss: 2.594320379572906

Epoch: 350| Step: 0
Training loss: 0.5695323572553591
Validation loss: 2.5585851265089468

Epoch: 5| Step: 1
Training loss: 0.6219054861599311
Validation loss: 2.5778437943666153

Epoch: 5| Step: 2
Training loss: 0.7393099767706537
Validation loss: 2.5844721379615345

Epoch: 5| Step: 3
Training loss: 0.6543759426339691
Validation loss: 2.5698357823321905

Epoch: 5| Step: 4
Training loss: 0.5210837779313413
Validation loss: 2.5767059050054657

Epoch: 5| Step: 5
Training loss: 0.6666181864595014
Validation loss: 2.589395008339595

Epoch: 5| Step: 6
Training loss: 0.6923293723936039
Validation loss: 2.6077836137904407

Epoch: 5| Step: 7
Training loss: 0.46733612771101235
Validation loss: 2.564698901325308

Epoch: 5| Step: 8
Training loss: 0.36263689711843666
Validation loss: 2.536973341573306

Epoch: 5| Step: 9
Training loss: 0.7006537560679348
Validation loss: 2.557890473036756

Epoch: 5| Step: 10
Training loss: 0.4596347016355088
Validation loss: 2.558644339092566

Epoch: 351| Step: 0
Training loss: 0.5319510210353899
Validation loss: 2.531764359134735

Epoch: 5| Step: 1
Training loss: 0.40280817134594094
Validation loss: 2.564515859350148

Epoch: 5| Step: 2
Training loss: 0.3618030416926456
Validation loss: 2.5332822613460575

Epoch: 5| Step: 3
Training loss: 0.5531458586730794
Validation loss: 2.5773070170410266

Epoch: 5| Step: 4
Training loss: 0.7911255183237047
Validation loss: 2.5527928189666094

Epoch: 5| Step: 5
Training loss: 0.494032535114797
Validation loss: 2.5718294453559003

Epoch: 5| Step: 6
Training loss: 0.5844321942007484
Validation loss: 2.575931655951543

Epoch: 5| Step: 7
Training loss: 0.7999645255091372
Validation loss: 2.5753085536058924

Epoch: 5| Step: 8
Training loss: 0.5213343943969647
Validation loss: 2.5727600927506638

Epoch: 5| Step: 9
Training loss: 0.6503434035195941
Validation loss: 2.545669236522077

Epoch: 5| Step: 10
Training loss: 0.5412207259439389
Validation loss: 2.5522212195717633

Epoch: 352| Step: 0
Training loss: 0.6977859180066569
Validation loss: 2.575932694969903

Epoch: 5| Step: 1
Training loss: 0.7236002349727665
Validation loss: 2.5243189930684538

Epoch: 5| Step: 2
Training loss: 0.4716988000887242
Validation loss: 2.5755720687241475

Epoch: 5| Step: 3
Training loss: 0.5772746249927521
Validation loss: 2.542955726451694

Epoch: 5| Step: 4
Training loss: 0.6318163389677413
Validation loss: 2.5491934970539436

Epoch: 5| Step: 5
Training loss: 0.4794338524910537
Validation loss: 2.517893304652526

Epoch: 5| Step: 6
Training loss: 0.5588467165215429
Validation loss: 2.5794269127172846

Epoch: 5| Step: 7
Training loss: 0.7107685433302497
Validation loss: 2.5678245696008815

Epoch: 5| Step: 8
Training loss: 0.6293861501060235
Validation loss: 2.562095808300724

Epoch: 5| Step: 9
Training loss: 0.3489838337002722
Validation loss: 2.56391686686842

Epoch: 5| Step: 10
Training loss: 0.34731536397461904
Validation loss: 2.578996239523352

Epoch: 353| Step: 0
Training loss: 0.5450991817221889
Validation loss: 2.5465625868521795

Epoch: 5| Step: 1
Training loss: 0.5085910404443713
Validation loss: 2.577544431427472

Epoch: 5| Step: 2
Training loss: 0.532828706064179
Validation loss: 2.5760997465537883

Epoch: 5| Step: 3
Training loss: 0.9343921328093402
Validation loss: 2.5369594692340547

Epoch: 5| Step: 4
Training loss: 0.1663595787828877
Validation loss: 2.543226059902348

Epoch: 5| Step: 5
Training loss: 0.5971141425988926
Validation loss: 2.562977102881137

Epoch: 5| Step: 6
Training loss: 0.5872027659804504
Validation loss: 2.565162930779244

Epoch: 5| Step: 7
Training loss: 0.5801782489512881
Validation loss: 2.5558329945533247

Epoch: 5| Step: 8
Training loss: 0.7547300512350585
Validation loss: 2.558887800014828

Epoch: 5| Step: 9
Training loss: 0.2860945978782336
Validation loss: 2.560450133428499

Epoch: 5| Step: 10
Training loss: 0.39174955620463636
Validation loss: 2.5468763005046795

Epoch: 354| Step: 0
Training loss: 0.19683094099319307
Validation loss: 2.568260007973185

Epoch: 5| Step: 1
Training loss: 0.480319659043856
Validation loss: 2.550697853320447

Epoch: 5| Step: 2
Training loss: 0.643460210368816
Validation loss: 2.527848669851867

Epoch: 5| Step: 3
Training loss: 0.5782397903715333
Validation loss: 2.576951917430391

Epoch: 5| Step: 4
Training loss: 0.47612947583467075
Validation loss: 2.5409370564011304

Epoch: 5| Step: 5
Training loss: 0.5083145300978128
Validation loss: 2.5825061214658662

Epoch: 5| Step: 6
Training loss: 0.5785497445419548
Validation loss: 2.552036886857779

Epoch: 5| Step: 7
Training loss: 0.6100878824964884
Validation loss: 2.553704258622136

Epoch: 5| Step: 8
Training loss: 0.5122732986915652
Validation loss: 2.563670769573232

Epoch: 5| Step: 9
Training loss: 0.7606379739976059
Validation loss: 2.5329697940979745

Epoch: 5| Step: 10
Training loss: 0.7414026226119772
Validation loss: 2.5400098877432464

Epoch: 355| Step: 0
Training loss: 0.5540700081253609
Validation loss: 2.5712264764567485

Epoch: 5| Step: 1
Training loss: 0.6539762479992365
Validation loss: 2.5557291090622303

Epoch: 5| Step: 2
Training loss: 0.3364907078869983
Validation loss: 2.532645218397753

Epoch: 5| Step: 3
Training loss: 0.6462698174173681
Validation loss: 2.509533871209521

Epoch: 5| Step: 4
Training loss: 0.7027215859997202
Validation loss: 2.5376827184510025

Epoch: 5| Step: 5
Training loss: 0.42785252720321715
Validation loss: 2.5553247021447367

Epoch: 5| Step: 6
Training loss: 0.8588497290526504
Validation loss: 2.5187403499648746

Epoch: 5| Step: 7
Training loss: 0.4951905265830203
Validation loss: 2.5701880179418364

Epoch: 5| Step: 8
Training loss: 0.45133605876101596
Validation loss: 2.5545096617579928

Epoch: 5| Step: 9
Training loss: 0.4996840402556139
Validation loss: 2.5584995633502126

Epoch: 5| Step: 10
Training loss: 0.2281605007035341
Validation loss: 2.5617936233969973

Epoch: 356| Step: 0
Training loss: 0.6285760616930597
Validation loss: 2.5563763628129736

Epoch: 5| Step: 1
Training loss: 0.5562587298018968
Validation loss: 2.5939194082421557

Epoch: 5| Step: 2
Training loss: 0.2783454749796013
Validation loss: 2.59405201313625

Epoch: 5| Step: 3
Training loss: 0.5854373577529476
Validation loss: 2.5798613845292935

Epoch: 5| Step: 4
Training loss: 0.4623703265762207
Validation loss: 2.5985636935016414

Epoch: 5| Step: 5
Training loss: 0.47061123089449886
Validation loss: 2.6267850366531396

Epoch: 5| Step: 6
Training loss: 0.51523928231425
Validation loss: 2.592156923337452

Epoch: 5| Step: 7
Training loss: 0.8350255751547776
Validation loss: 2.627447035646251

Epoch: 5| Step: 8
Training loss: 0.6219730031603533
Validation loss: 2.578714308223067

Epoch: 5| Step: 9
Training loss: 0.34381906942565704
Validation loss: 2.6305353524059214

Epoch: 5| Step: 10
Training loss: 0.6731709246965525
Validation loss: 2.6205729085404634

Epoch: 357| Step: 0
Training loss: 0.6225776699359852
Validation loss: 2.6267801558659607

Epoch: 5| Step: 1
Training loss: 0.6212151126928753
Validation loss: 2.6233125381275113

Epoch: 5| Step: 2
Training loss: 0.6091121693650701
Validation loss: 2.6538460167413915

Epoch: 5| Step: 3
Training loss: 0.19587118352861294
Validation loss: 2.63427794907134

Epoch: 5| Step: 4
Training loss: 0.5552583631360583
Validation loss: 2.5835306047293485

Epoch: 5| Step: 5
Training loss: 0.5137632455533744
Validation loss: 2.573857597750683

Epoch: 5| Step: 6
Training loss: 0.5470550513190243
Validation loss: 2.572596311127726

Epoch: 5| Step: 7
Training loss: 0.6881878186482302
Validation loss: 2.530584340218303

Epoch: 5| Step: 8
Training loss: 0.5159332625494083
Validation loss: 2.5542033173410803

Epoch: 5| Step: 9
Training loss: 0.6320883763999988
Validation loss: 2.5518906085885247

Epoch: 5| Step: 10
Training loss: 0.5265250172843584
Validation loss: 2.5628753315201718

Epoch: 358| Step: 0
Training loss: 0.3854669482278329
Validation loss: 2.5999216881183855

Epoch: 5| Step: 1
Training loss: 0.5808809421334706
Validation loss: 2.57602350295848

Epoch: 5| Step: 2
Training loss: 0.7194777826082613
Validation loss: 2.5950143309561886

Epoch: 5| Step: 3
Training loss: 0.43778406866362846
Validation loss: 2.5533037560359886

Epoch: 5| Step: 4
Training loss: 0.19667461354625143
Validation loss: 2.604642627822972

Epoch: 5| Step: 5
Training loss: 0.6720192776509126
Validation loss: 2.5910651045316793

Epoch: 5| Step: 6
Training loss: 0.5749869106710243
Validation loss: 2.5760613289726444

Epoch: 5| Step: 7
Training loss: 0.5995838271672078
Validation loss: 2.5719903314035193

Epoch: 5| Step: 8
Training loss: 0.7036844994467204
Validation loss: 2.5493638142014987

Epoch: 5| Step: 9
Training loss: 0.6493641999111173
Validation loss: 2.5681809891378395

Epoch: 5| Step: 10
Training loss: 0.5062035821897949
Validation loss: 2.555828994869052

Epoch: 359| Step: 0
Training loss: 0.6942936365303788
Validation loss: 2.551177081959765

Epoch: 5| Step: 1
Training loss: 0.5889676389531425
Validation loss: 2.544896145503571

Epoch: 5| Step: 2
Training loss: 0.5199853733646588
Validation loss: 2.614503987145272

Epoch: 5| Step: 3
Training loss: 0.4637758506397373
Validation loss: 2.5846823849260074

Epoch: 5| Step: 4
Training loss: 0.8555023674477884
Validation loss: 2.628489928969942

Epoch: 5| Step: 5
Training loss: 0.4107230312144889
Validation loss: 2.5919450760373848

Epoch: 5| Step: 6
Training loss: 0.5473492065035741
Validation loss: 2.6093348361922892

Epoch: 5| Step: 7
Training loss: 0.2809979315864893
Validation loss: 2.5690376807478983

Epoch: 5| Step: 8
Training loss: 0.3345086516899375
Validation loss: 2.5212459818010178

Epoch: 5| Step: 9
Training loss: 0.7791348625940807
Validation loss: 2.5173741377193015

Epoch: 5| Step: 10
Training loss: 0.6381212246341345
Validation loss: 2.556000723890875

Epoch: 360| Step: 0
Training loss: 0.624383479262198
Validation loss: 2.5475753562585335

Epoch: 5| Step: 1
Training loss: 0.6275912451040437
Validation loss: 2.529747887304815

Epoch: 5| Step: 2
Training loss: 0.3554235157114765
Validation loss: 2.571648777082392

Epoch: 5| Step: 3
Training loss: 0.5452602798685715
Validation loss: 2.5576447110206355

Epoch: 5| Step: 4
Training loss: 0.6906377540895153
Validation loss: 2.542471532474839

Epoch: 5| Step: 5
Training loss: 0.646091722256893
Validation loss: 2.565301559712906

Epoch: 5| Step: 6
Training loss: 0.48968971057190835
Validation loss: 2.5635362006231572

Epoch: 5| Step: 7
Training loss: 0.3917922509358879
Validation loss: 2.5110038533894006

Epoch: 5| Step: 8
Training loss: 0.6315502245963849
Validation loss: 2.5089478326240573

Epoch: 5| Step: 9
Training loss: 0.5658816835292301
Validation loss: 2.5144766324805103

Epoch: 5| Step: 10
Training loss: 0.7277866838199851
Validation loss: 2.5163532217809657

Epoch: 361| Step: 0
Training loss: 0.5111782918134051
Validation loss: 2.5615048345691624

Epoch: 5| Step: 1
Training loss: 0.5095911129222217
Validation loss: 2.5567041115637106

Epoch: 5| Step: 2
Training loss: 0.7285795209339059
Validation loss: 2.5461705200646527

Epoch: 5| Step: 3
Training loss: 0.43750623289845475
Validation loss: 2.5249960200488455

Epoch: 5| Step: 4
Training loss: 0.6275294379438058
Validation loss: 2.5568016556360775

Epoch: 5| Step: 5
Training loss: 0.3978416999714337
Validation loss: 2.5421712735217388

Epoch: 5| Step: 6
Training loss: 0.5896708759335888
Validation loss: 2.5633508643737613

Epoch: 5| Step: 7
Training loss: 0.4947413987842822
Validation loss: 2.5715082731296643

Epoch: 5| Step: 8
Training loss: 0.5620063894169969
Validation loss: 2.5807263706360546

Epoch: 5| Step: 9
Training loss: 0.6503163429890946
Validation loss: 2.6182613152861927

Epoch: 5| Step: 10
Training loss: 0.6125615993976151
Validation loss: 2.555168774103611

Epoch: 362| Step: 0
Training loss: 0.30112785334282344
Validation loss: 2.5952169888299546

Epoch: 5| Step: 1
Training loss: 0.6921297802766059
Validation loss: 2.5738400257208554

Epoch: 5| Step: 2
Training loss: 0.5206548543936191
Validation loss: 2.554089430569487

Epoch: 5| Step: 3
Training loss: 0.42248522811663
Validation loss: 2.5744627247004352

Epoch: 5| Step: 4
Training loss: 0.7490704259345686
Validation loss: 2.5617947204371414

Epoch: 5| Step: 5
Training loss: 0.398109768736331
Validation loss: 2.571823675778657

Epoch: 5| Step: 6
Training loss: 0.23172180142904678
Validation loss: 2.5667096497439523

Epoch: 5| Step: 7
Training loss: 0.690229416523401
Validation loss: 2.5960840456687158

Epoch: 5| Step: 8
Training loss: 0.5464068725250774
Validation loss: 2.522440628191621

Epoch: 5| Step: 9
Training loss: 0.6525751948236612
Validation loss: 2.5906924162635754

Epoch: 5| Step: 10
Training loss: 0.6983471131349835
Validation loss: 2.5886355919686723

Epoch: 363| Step: 0
Training loss: 0.6910348099222806
Validation loss: 2.5793904619133583

Epoch: 5| Step: 1
Training loss: 0.5045574918356878
Validation loss: 2.585934575434286

Epoch: 5| Step: 2
Training loss: 0.5125962806606168
Validation loss: 2.5516532798457674

Epoch: 5| Step: 3
Training loss: 0.6166247929283303
Validation loss: 2.575975519279637

Epoch: 5| Step: 4
Training loss: 0.4085574460358192
Validation loss: 2.536544955660462

Epoch: 5| Step: 5
Training loss: 0.515677969552643
Validation loss: 2.4959072369638458

Epoch: 5| Step: 6
Training loss: 0.5325535880691672
Validation loss: 2.509252751644047

Epoch: 5| Step: 7
Training loss: 0.582334298726799
Validation loss: 2.5096522386743705

Epoch: 5| Step: 8
Training loss: 0.5727676689139994
Validation loss: 2.516759159328297

Epoch: 5| Step: 9
Training loss: 0.6576509734975506
Validation loss: 2.519035101375316

Epoch: 5| Step: 10
Training loss: 0.33823124029152235
Validation loss: 2.5642828303150806

Epoch: 364| Step: 0
Training loss: 0.3808427855962329
Validation loss: 2.561931093753718

Epoch: 5| Step: 1
Training loss: 0.7301432654485241
Validation loss: 2.5905663741732994

Epoch: 5| Step: 2
Training loss: 0.5254823115445182
Validation loss: 2.5706154028021744

Epoch: 5| Step: 3
Training loss: 0.7671737964905729
Validation loss: 2.6091878793318766

Epoch: 5| Step: 4
Training loss: 0.7234421863774877
Validation loss: 2.6231204011529026

Epoch: 5| Step: 5
Training loss: 0.411873374727368
Validation loss: 2.582879121474026

Epoch: 5| Step: 6
Training loss: 0.4301545812295233
Validation loss: 2.584205623736144

Epoch: 5| Step: 7
Training loss: 0.42210198406701205
Validation loss: 2.5610487835634923

Epoch: 5| Step: 8
Training loss: 0.45089756276590204
Validation loss: 2.554218635685469

Epoch: 5| Step: 9
Training loss: 0.4761756202106099
Validation loss: 2.5503306561937142

Epoch: 5| Step: 10
Training loss: 0.486098959369758
Validation loss: 2.574405898953438

Epoch: 365| Step: 0
Training loss: 0.3075058750816388
Validation loss: 2.555807781642702

Epoch: 5| Step: 1
Training loss: 0.5444377813477546
Validation loss: 2.5689345388102462

Epoch: 5| Step: 2
Training loss: 0.4895041601269215
Validation loss: 2.580438393723343

Epoch: 5| Step: 3
Training loss: 0.7168930779117454
Validation loss: 2.5987286318321563

Epoch: 5| Step: 4
Training loss: 0.6294284808440997
Validation loss: 2.582744938916837

Epoch: 5| Step: 5
Training loss: 0.535341189095033
Validation loss: 2.5690965102235044

Epoch: 5| Step: 6
Training loss: 0.5428065325244817
Validation loss: 2.5933944393206843

Epoch: 5| Step: 7
Training loss: 0.5707494551112564
Validation loss: 2.5857503330232134

Epoch: 5| Step: 8
Training loss: 0.4960056286740486
Validation loss: 2.55578392664603

Epoch: 5| Step: 9
Training loss: 0.49739975120506
Validation loss: 2.576405526747723

Epoch: 5| Step: 10
Training loss: 0.32391354546655526
Validation loss: 2.5393405143040897

Epoch: 366| Step: 0
Training loss: 0.5669254685535018
Validation loss: 2.5525312548378607

Epoch: 5| Step: 1
Training loss: 0.22546264449832587
Validation loss: 2.585233512165178

Epoch: 5| Step: 2
Training loss: 0.7239937853651826
Validation loss: 2.5982188208145245

Epoch: 5| Step: 3
Training loss: 0.6065212085550499
Validation loss: 2.5782967667771675

Epoch: 5| Step: 4
Training loss: 0.6348693997578688
Validation loss: 2.5827839479241166

Epoch: 5| Step: 5
Training loss: 0.43420358678719134
Validation loss: 2.575764031125474

Epoch: 5| Step: 6
Training loss: 0.5160098518089058
Validation loss: 2.55840922810219

Epoch: 5| Step: 7
Training loss: 0.5045978029456523
Validation loss: 2.5652983607834234

Epoch: 5| Step: 8
Training loss: 0.17878102663503295
Validation loss: 2.5400958103076787

Epoch: 5| Step: 9
Training loss: 0.5779798686372712
Validation loss: 2.557411728527078

Epoch: 5| Step: 10
Training loss: 0.5660217032096326
Validation loss: 2.5466761176394543

Epoch: 367| Step: 0
Training loss: 0.5020195586775174
Validation loss: 2.5632336074385056

Epoch: 5| Step: 1
Training loss: 0.6244551429443894
Validation loss: 2.5238613335428512

Epoch: 5| Step: 2
Training loss: 0.5404929931532282
Validation loss: 2.56646968278496

Epoch: 5| Step: 3
Training loss: 0.3986698669825568
Validation loss: 2.5640788432985047

Epoch: 5| Step: 4
Training loss: 0.6193577478972027
Validation loss: 2.525327004987797

Epoch: 5| Step: 5
Training loss: 0.30320272825549816
Validation loss: 2.5496295623695766

Epoch: 5| Step: 6
Training loss: 0.6819657039716771
Validation loss: 2.542322683038653

Epoch: 5| Step: 7
Training loss: 0.3968416680583958
Validation loss: 2.5511887928674883

Epoch: 5| Step: 8
Training loss: 0.2797929985718165
Validation loss: 2.5470598240454705

Epoch: 5| Step: 9
Training loss: 0.8269192897269749
Validation loss: 2.597845221668435

Epoch: 5| Step: 10
Training loss: 0.3127027569086593
Validation loss: 2.58061575744654

Epoch: 368| Step: 0
Training loss: 0.6501426567741371
Validation loss: 2.594193176686644

Epoch: 5| Step: 1
Training loss: 0.43075041651248996
Validation loss: 2.5491699834374946

Epoch: 5| Step: 2
Training loss: 0.6324443923871688
Validation loss: 2.551171982161197

Epoch: 5| Step: 3
Training loss: 0.5287466814284197
Validation loss: 2.5761027300524613

Epoch: 5| Step: 4
Training loss: 0.6154706470995813
Validation loss: 2.614744182352462

Epoch: 5| Step: 5
Training loss: 0.49133326560067
Validation loss: 2.563249097851112

Epoch: 5| Step: 6
Training loss: 0.47487607769945506
Validation loss: 2.5953088092339995

Epoch: 5| Step: 7
Training loss: 0.3319669773500119
Validation loss: 2.596947130859721

Epoch: 5| Step: 8
Training loss: 0.45372986706817825
Validation loss: 2.589980752033817

Epoch: 5| Step: 9
Training loss: 0.5562059813666501
Validation loss: 2.6021734686314613

Epoch: 5| Step: 10
Training loss: 0.5074468323147426
Validation loss: 2.601217079259206

Epoch: 369| Step: 0
Training loss: 0.43812048712459095
Validation loss: 2.5842716254347247

Epoch: 5| Step: 1
Training loss: 0.5203903380586331
Validation loss: 2.5480558273987883

Epoch: 5| Step: 2
Training loss: 0.5996410597590319
Validation loss: 2.6004415334775164

Epoch: 5| Step: 3
Training loss: 0.4292223233024575
Validation loss: 2.528615259133313

Epoch: 5| Step: 4
Training loss: 0.5032392123412076
Validation loss: 2.549686647722766

Epoch: 5| Step: 5
Training loss: 0.49521802970028395
Validation loss: 2.533165412976516

Epoch: 5| Step: 6
Training loss: 0.6498352520573478
Validation loss: 2.5570249786640424

Epoch: 5| Step: 7
Training loss: 0.557987284057414
Validation loss: 2.5489792477207636

Epoch: 5| Step: 8
Training loss: 0.43712790878589114
Validation loss: 2.5476613569972124

Epoch: 5| Step: 9
Training loss: 0.6521397117357737
Validation loss: 2.5302757273020147

Epoch: 5| Step: 10
Training loss: 0.2639708201825215
Validation loss: 2.5437810049318905

Epoch: 370| Step: 0
Training loss: 0.5716783810917635
Validation loss: 2.5582454531690813

Epoch: 5| Step: 1
Training loss: 0.576417411598929
Validation loss: 2.551088319891994

Epoch: 5| Step: 2
Training loss: 0.44476220780076203
Validation loss: 2.5432521646446107

Epoch: 5| Step: 3
Training loss: 0.5233090655912231
Validation loss: 2.5961967982812344

Epoch: 5| Step: 4
Training loss: 0.5784631719513491
Validation loss: 2.5264677100531503

Epoch: 5| Step: 5
Training loss: 0.4689168791946997
Validation loss: 2.5677587327031834

Epoch: 5| Step: 6
Training loss: 0.562679182759548
Validation loss: 2.572310083042007

Epoch: 5| Step: 7
Training loss: 0.2822352213339752
Validation loss: 2.565845972195014

Epoch: 5| Step: 8
Training loss: 0.7174909178394939
Validation loss: 2.60655422961553

Epoch: 5| Step: 9
Training loss: 0.2614459708635974
Validation loss: 2.593836304916057

Epoch: 5| Step: 10
Training loss: 0.5374353148106206
Validation loss: 2.582377597038117

Epoch: 371| Step: 0
Training loss: 0.43532500153915465
Validation loss: 2.5237274343696705

Epoch: 5| Step: 1
Training loss: 0.4785610099600893
Validation loss: 2.5784553055215556

Epoch: 5| Step: 2
Training loss: 0.5702651278534934
Validation loss: 2.5541781947362185

Epoch: 5| Step: 3
Training loss: 0.6803180356867173
Validation loss: 2.5400022644631677

Epoch: 5| Step: 4
Training loss: 0.31265367067446487
Validation loss: 2.579867248420388

Epoch: 5| Step: 5
Training loss: 0.5585020830393906
Validation loss: 2.592374298183851

Epoch: 5| Step: 6
Training loss: 0.4953290196500903
Validation loss: 2.5831077833152647

Epoch: 5| Step: 7
Training loss: 0.4064647767054665
Validation loss: 2.5508386100801324

Epoch: 5| Step: 8
Training loss: 0.5004814333563533
Validation loss: 2.6053458571621966

Epoch: 5| Step: 9
Training loss: 0.4635487155878408
Validation loss: 2.600910801219856

Epoch: 5| Step: 10
Training loss: 0.6781621896416776
Validation loss: 2.6151538424671434

Epoch: 372| Step: 0
Training loss: 0.19178422276239618
Validation loss: 2.62364266525512

Epoch: 5| Step: 1
Training loss: 0.3898261293698618
Validation loss: 2.587185895316011

Epoch: 5| Step: 2
Training loss: 0.22823124495192185
Validation loss: 2.606376130683702

Epoch: 5| Step: 3
Training loss: 0.6621098026060451
Validation loss: 2.583394745193692

Epoch: 5| Step: 4
Training loss: 0.6586783077671072
Validation loss: 2.5974859415769194

Epoch: 5| Step: 5
Training loss: 0.6104154751693328
Validation loss: 2.558885403570845

Epoch: 5| Step: 6
Training loss: 0.41990086702537555
Validation loss: 2.553976256425157

Epoch: 5| Step: 7
Training loss: 0.6818718285840878
Validation loss: 2.5988622959161587

Epoch: 5| Step: 8
Training loss: 0.47725224218746043
Validation loss: 2.5314372743001607

Epoch: 5| Step: 9
Training loss: 0.6014920973762035
Validation loss: 2.540025204885579

Epoch: 5| Step: 10
Training loss: 0.29582233520444934
Validation loss: 2.5811772480528026

Epoch: 373| Step: 0
Training loss: 0.5578852074518588
Validation loss: 2.617889420858526

Epoch: 5| Step: 1
Training loss: 0.5989992846435326
Validation loss: 2.583582889545184

Epoch: 5| Step: 2
Training loss: 0.44882415358045474
Validation loss: 2.6165155979949932

Epoch: 5| Step: 3
Training loss: 0.7426522255597263
Validation loss: 2.5854182911607366

Epoch: 5| Step: 4
Training loss: 0.47107880981440076
Validation loss: 2.5921142189973585

Epoch: 5| Step: 5
Training loss: 0.4059500320414824
Validation loss: 2.5864831234621275

Epoch: 5| Step: 6
Training loss: 0.5002456895870357
Validation loss: 2.569854688574735

Epoch: 5| Step: 7
Training loss: 0.3458259709083917
Validation loss: 2.547199857915421

Epoch: 5| Step: 8
Training loss: 0.5682609446655182
Validation loss: 2.561268355148357

Epoch: 5| Step: 9
Training loss: 0.4113609786285465
Validation loss: 2.5643008117476507

Epoch: 5| Step: 10
Training loss: 0.5071490134857581
Validation loss: 2.5510715070162284

Epoch: 374| Step: 0
Training loss: 0.5072080976777671
Validation loss: 2.5367100714885544

Epoch: 5| Step: 1
Training loss: 0.2236149376801104
Validation loss: 2.573394697022782

Epoch: 5| Step: 2
Training loss: 0.6059126180622758
Validation loss: 2.5374168445817773

Epoch: 5| Step: 3
Training loss: 0.5917265696042887
Validation loss: 2.5267628840995426

Epoch: 5| Step: 4
Training loss: 0.6699461195759837
Validation loss: 2.6040436004764715

Epoch: 5| Step: 5
Training loss: 0.4138965454058315
Validation loss: 2.5545449517080705

Epoch: 5| Step: 6
Training loss: 0.6076723177358142
Validation loss: 2.5684336691746497

Epoch: 5| Step: 7
Training loss: 0.5528452731650544
Validation loss: 2.540818651070195

Epoch: 5| Step: 8
Training loss: 0.2765198680110044
Validation loss: 2.5720860787694018

Epoch: 5| Step: 9
Training loss: 0.24321210149220754
Validation loss: 2.5674754645803852

Epoch: 5| Step: 10
Training loss: 0.6688340143212468
Validation loss: 2.5537490804545895

Epoch: 375| Step: 0
Training loss: 0.507562810694103
Validation loss: 2.5691477147399935

Epoch: 5| Step: 1
Training loss: 0.5716398026472315
Validation loss: 2.590392011562115

Epoch: 5| Step: 2
Training loss: 0.29725749071097735
Validation loss: 2.5464314051104706

Epoch: 5| Step: 3
Training loss: 0.38430200519460506
Validation loss: 2.537236472690554

Epoch: 5| Step: 4
Training loss: 0.6755916572057381
Validation loss: 2.56711267359231

Epoch: 5| Step: 5
Training loss: 0.4659510974703686
Validation loss: 2.5897102064775894

Epoch: 5| Step: 6
Training loss: 0.5252245672496985
Validation loss: 2.5646997049934295

Epoch: 5| Step: 7
Training loss: 0.3109888614234516
Validation loss: 2.5895181205959195

Epoch: 5| Step: 8
Training loss: 0.42749220380868624
Validation loss: 2.579370538237818

Epoch: 5| Step: 9
Training loss: 0.6442379833369356
Validation loss: 2.6059527961525784

Epoch: 5| Step: 10
Training loss: 0.48338974453594696
Validation loss: 2.5439745348357987

Epoch: 376| Step: 0
Training loss: 0.6508777386596921
Validation loss: 2.586914726472194

Epoch: 5| Step: 1
Training loss: 0.6011876511316321
Validation loss: 2.578485690752458

Epoch: 5| Step: 2
Training loss: 0.3906666924161436
Validation loss: 2.539227913515981

Epoch: 5| Step: 3
Training loss: 0.5829447803257416
Validation loss: 2.5505340842860904

Epoch: 5| Step: 4
Training loss: 0.285035303673172
Validation loss: 2.5958099561767245

Epoch: 5| Step: 5
Training loss: 0.6746950184631537
Validation loss: 2.559817208611027

Epoch: 5| Step: 6
Training loss: 0.31604799545722395
Validation loss: 2.5536422957121903

Epoch: 5| Step: 7
Training loss: 0.4624046962077996
Validation loss: 2.534274551911467

Epoch: 5| Step: 8
Training loss: 0.3463918968912775
Validation loss: 2.5488853630780626

Epoch: 5| Step: 9
Training loss: 0.41732613906636346
Validation loss: 2.586272763178583

Epoch: 5| Step: 10
Training loss: 0.375175097435749
Validation loss: 2.5741079328594547

Epoch: 377| Step: 0
Training loss: 0.48491441777799277
Validation loss: 2.572540747627947

Epoch: 5| Step: 1
Training loss: 0.4659751938502307
Validation loss: 2.578518051161556

Epoch: 5| Step: 2
Training loss: 0.4383273306164849
Validation loss: 2.5747405936524226

Epoch: 5| Step: 3
Training loss: 0.4363966380043143
Validation loss: 2.544502957995192

Epoch: 5| Step: 4
Training loss: 0.46642710193430925
Validation loss: 2.5490202247396807

Epoch: 5| Step: 5
Training loss: 0.5580702242398401
Validation loss: 2.556511203347865

Epoch: 5| Step: 6
Training loss: 0.6453996530198547
Validation loss: 2.555387594383029

Epoch: 5| Step: 7
Training loss: 0.39304765929066326
Validation loss: 2.5899798720748017

Epoch: 5| Step: 8
Training loss: 0.5172720525953236
Validation loss: 2.569396967191957

Epoch: 5| Step: 9
Training loss: 0.49402517545697056
Validation loss: 2.5574302113684215

Epoch: 5| Step: 10
Training loss: 0.2741564291320028
Validation loss: 2.5761902252371915

Epoch: 378| Step: 0
Training loss: 0.3004517918332535
Validation loss: 2.582944885116384

Epoch: 5| Step: 1
Training loss: 0.5318406692165509
Validation loss: 2.598241322218589

Epoch: 5| Step: 2
Training loss: 0.3919868381441254
Validation loss: 2.573491522545503

Epoch: 5| Step: 3
Training loss: 0.37765745466590195
Validation loss: 2.5856413466417236

Epoch: 5| Step: 4
Training loss: 0.36419834745876406
Validation loss: 2.5671659878323947

Epoch: 5| Step: 5
Training loss: 0.5286845927444327
Validation loss: 2.565330274948142

Epoch: 5| Step: 6
Training loss: 0.6531975692149578
Validation loss: 2.5648012570297514

Epoch: 5| Step: 7
Training loss: 0.486113136907928
Validation loss: 2.5694665130920966

Epoch: 5| Step: 8
Training loss: 0.6454636043582649
Validation loss: 2.555225963454872

Epoch: 5| Step: 9
Training loss: 0.44775507104154316
Validation loss: 2.5691146435684504

Epoch: 5| Step: 10
Training loss: 0.353701884903225
Validation loss: 2.557488027776826

Epoch: 379| Step: 0
Training loss: 0.7228783343556665
Validation loss: 2.596727965361965

Epoch: 5| Step: 1
Training loss: 0.20047928743029436
Validation loss: 2.596866133759286

Epoch: 5| Step: 2
Training loss: 0.44642865691865374
Validation loss: 2.5849725737020948

Epoch: 5| Step: 3
Training loss: 0.3445483062916469
Validation loss: 2.5773563834010993

Epoch: 5| Step: 4
Training loss: 0.5165136944006892
Validation loss: 2.5786122965011224

Epoch: 5| Step: 5
Training loss: 0.42994021873429694
Validation loss: 2.5486287995647126

Epoch: 5| Step: 6
Training loss: 0.4406845640951134
Validation loss: 2.549432913079407

Epoch: 5| Step: 7
Training loss: 0.377442491932007
Validation loss: 2.5523410480321407

Epoch: 5| Step: 8
Training loss: 0.48698714618639166
Validation loss: 2.5759770210534554

Epoch: 5| Step: 9
Training loss: 0.4731533022166993
Validation loss: 2.6201595675252074

Epoch: 5| Step: 10
Training loss: 0.6214968494863289
Validation loss: 2.5631869496060804

Epoch: 380| Step: 0
Training loss: 0.24750846340177782
Validation loss: 2.5890485890674277

Epoch: 5| Step: 1
Training loss: 0.5048168736974786
Validation loss: 2.5407380623887716

Epoch: 5| Step: 2
Training loss: 0.4124570347344531
Validation loss: 2.550793006946638

Epoch: 5| Step: 3
Training loss: 0.4938534290292388
Validation loss: 2.534313560451121

Epoch: 5| Step: 4
Training loss: 0.47034478694564996
Validation loss: 2.5110059269632714

Epoch: 5| Step: 5
Training loss: 0.4965471313575773
Validation loss: 2.5448131951561543

Epoch: 5| Step: 6
Training loss: 0.5480535342300648
Validation loss: 2.528042647965684

Epoch: 5| Step: 7
Training loss: 0.291028105704969
Validation loss: 2.522507805917847

Epoch: 5| Step: 8
Training loss: 0.6781464788665407
Validation loss: 2.51603860473384

Epoch: 5| Step: 9
Training loss: 0.5719686525298184
Validation loss: 2.533447706694676

Epoch: 5| Step: 10
Training loss: 0.371388348543983
Validation loss: 2.5354875309287146

Epoch: 381| Step: 0
Training loss: 0.5823312792557095
Validation loss: 2.537275656463549

Epoch: 5| Step: 1
Training loss: 0.3669372882962611
Validation loss: 2.566529030606077

Epoch: 5| Step: 2
Training loss: 0.4260393113099942
Validation loss: 2.5747094144613505

Epoch: 5| Step: 3
Training loss: 0.6485494034507149
Validation loss: 2.5567903334069606

Epoch: 5| Step: 4
Training loss: 0.4558140612049427
Validation loss: 2.562950623890983

Epoch: 5| Step: 5
Training loss: 0.5295260169163777
Validation loss: 2.6057654312109024

Epoch: 5| Step: 6
Training loss: 0.6253246894498611
Validation loss: 2.593321297170523

Epoch: 5| Step: 7
Training loss: 0.3582067782715979
Validation loss: 2.5716907725555704

Epoch: 5| Step: 8
Training loss: 0.49320921738377144
Validation loss: 2.5629723681513013

Epoch: 5| Step: 9
Training loss: 0.3614545652466123
Validation loss: 2.588166684831404

Epoch: 5| Step: 10
Training loss: 0.25041478735260364
Validation loss: 2.5667173664943754

Epoch: 382| Step: 0
Training loss: 0.6144294438342782
Validation loss: 2.5573489953359743

Epoch: 5| Step: 1
Training loss: 0.516573265180438
Validation loss: 2.5893380627830633

Epoch: 5| Step: 2
Training loss: 0.5580326276421331
Validation loss: 2.57619163197551

Epoch: 5| Step: 3
Training loss: 0.5302158556281527
Validation loss: 2.5871320492889116

Epoch: 5| Step: 4
Training loss: 0.3849431514260102
Validation loss: 2.601672391114283

Epoch: 5| Step: 5
Training loss: 0.4055272054706454
Validation loss: 2.601770613103831

Epoch: 5| Step: 6
Training loss: 0.3362762827687608
Validation loss: 2.6053766647994556

Epoch: 5| Step: 7
Training loss: 0.4171259216696228
Validation loss: 2.6014676266296077

Epoch: 5| Step: 8
Training loss: 0.29128391264897713
Validation loss: 2.623735771902556

Epoch: 5| Step: 9
Training loss: 0.5008118118744139
Validation loss: 2.5883218932721226

Epoch: 5| Step: 10
Training loss: 0.5288060858359708
Validation loss: 2.6059920964609153

Epoch: 383| Step: 0
Training loss: 0.8287319981732907
Validation loss: 2.564664078463611

Epoch: 5| Step: 1
Training loss: 0.6058956241155001
Validation loss: 2.54475496887971

Epoch: 5| Step: 2
Training loss: 0.28700373775759724
Validation loss: 2.551815089346132

Epoch: 5| Step: 3
Training loss: 0.44358460339303407
Validation loss: 2.5668098248640003

Epoch: 5| Step: 4
Training loss: 0.40836663142825774
Validation loss: 2.546852329640691

Epoch: 5| Step: 5
Training loss: 0.19961835016127977
Validation loss: 2.5773876608725277

Epoch: 5| Step: 6
Training loss: 0.3502422337498083
Validation loss: 2.5464615658966547

Epoch: 5| Step: 7
Training loss: 0.48316425854869155
Validation loss: 2.557267327607713

Epoch: 5| Step: 8
Training loss: 0.45618092262218585
Validation loss: 2.546218331936281

Epoch: 5| Step: 9
Training loss: 0.3154387339897954
Validation loss: 2.5376236496748206

Epoch: 5| Step: 10
Training loss: 0.2970288405102442
Validation loss: 2.553340011967498

Epoch: 384| Step: 0
Training loss: 0.2944340871930139
Validation loss: 2.5452981407417035

Epoch: 5| Step: 1
Training loss: 0.5460305915513732
Validation loss: 2.5618669441735187

Epoch: 5| Step: 2
Training loss: 0.4179704434369444
Validation loss: 2.5387956406770873

Epoch: 5| Step: 3
Training loss: 0.48440837745108273
Validation loss: 2.566122983933347

Epoch: 5| Step: 4
Training loss: 0.47318647925020285
Validation loss: 2.572112655080871

Epoch: 5| Step: 5
Training loss: 0.46523188567116147
Validation loss: 2.5414033212372473

Epoch: 5| Step: 6
Training loss: 0.39558528565219087
Validation loss: 2.5187628590969986

Epoch: 5| Step: 7
Training loss: 0.4901843710394211
Validation loss: 2.563285225114172

Epoch: 5| Step: 8
Training loss: 0.37438899171695134
Validation loss: 2.578302591471234

Epoch: 5| Step: 9
Training loss: 0.5298893839185738
Validation loss: 2.5494837110992723

Epoch: 5| Step: 10
Training loss: 0.6270545093168308
Validation loss: 2.5685362802773524

Epoch: 385| Step: 0
Training loss: 0.3812679349089001
Validation loss: 2.5634027237109533

Epoch: 5| Step: 1
Training loss: 0.6846197004365602
Validation loss: 2.57810076580671

Epoch: 5| Step: 2
Training loss: 0.4245001040796662
Validation loss: 2.588264427376647

Epoch: 5| Step: 3
Training loss: 0.405273989022121
Validation loss: 2.5814569057974635

Epoch: 5| Step: 4
Training loss: 0.4949285535354246
Validation loss: 2.597491186823557

Epoch: 5| Step: 5
Training loss: 0.3999353192605728
Validation loss: 2.5914955695054664

Epoch: 5| Step: 6
Training loss: 0.41954509776186755
Validation loss: 2.5939347087346882

Epoch: 5| Step: 7
Training loss: 0.5260550399691848
Validation loss: 2.626712888696471

Epoch: 5| Step: 8
Training loss: 0.5355060854013062
Validation loss: 2.595947195878929

Epoch: 5| Step: 9
Training loss: 0.41172988196132
Validation loss: 2.5662118223726753

Epoch: 5| Step: 10
Training loss: 0.46869493796885037
Validation loss: 2.5577491762187585

Epoch: 386| Step: 0
Training loss: 0.6680654712275104
Validation loss: 2.5891732515209056

Epoch: 5| Step: 1
Training loss: 0.2429264240257309
Validation loss: 2.603830801357766

Epoch: 5| Step: 2
Training loss: 0.5769359629977017
Validation loss: 2.5780278043054015

Epoch: 5| Step: 3
Training loss: 0.646796044769473
Validation loss: 2.5716709706594076

Epoch: 5| Step: 4
Training loss: 0.13751440812612642
Validation loss: 2.5682405055400466

Epoch: 5| Step: 5
Training loss: 0.5126738625535249
Validation loss: 2.556901742682816

Epoch: 5| Step: 6
Training loss: 0.4536755111598543
Validation loss: 2.5665931545571308

Epoch: 5| Step: 7
Training loss: 0.22022953534229994
Validation loss: 2.5783518482887797

Epoch: 5| Step: 8
Training loss: 0.37151453355056985
Validation loss: 2.589716867730886

Epoch: 5| Step: 9
Training loss: 0.3421984901579406
Validation loss: 2.6200839318993334

Epoch: 5| Step: 10
Training loss: 0.5368353682290637
Validation loss: 2.6010634829881947

Epoch: 387| Step: 0
Training loss: 0.42089337480868
Validation loss: 2.5626080938151214

Epoch: 5| Step: 1
Training loss: 0.5826025085953076
Validation loss: 2.575073715669703

Epoch: 5| Step: 2
Training loss: 0.6132280120095714
Validation loss: 2.584402240974107

Epoch: 5| Step: 3
Training loss: 0.26815669305931716
Validation loss: 2.5899130556858956

Epoch: 5| Step: 4
Training loss: 0.4095667826619117
Validation loss: 2.5437430385383384

Epoch: 5| Step: 5
Training loss: 0.5124566385487358
Validation loss: 2.571651669047021

Epoch: 5| Step: 6
Training loss: 0.3524584691289837
Validation loss: 2.534006723996346

Epoch: 5| Step: 7
Training loss: 0.4026156867559933
Validation loss: 2.5710734586714263

Epoch: 5| Step: 8
Training loss: 0.3353544098472689
Validation loss: 2.5570684033567694

Epoch: 5| Step: 9
Training loss: 0.4149922063968948
Validation loss: 2.5475576786694205

Epoch: 5| Step: 10
Training loss: 0.5561939522012859
Validation loss: 2.556355795451271

Epoch: 388| Step: 0
Training loss: 0.5598962177600576
Validation loss: 2.577623162225406

Epoch: 5| Step: 1
Training loss: 0.5161654789711518
Validation loss: 2.557607118823187

Epoch: 5| Step: 2
Training loss: 0.5818764397493736
Validation loss: 2.518420822767735

Epoch: 5| Step: 3
Training loss: 0.41338303435724855
Validation loss: 2.5378025507517283

Epoch: 5| Step: 4
Training loss: 0.5153367942140311
Validation loss: 2.549072918711202

Epoch: 5| Step: 5
Training loss: 0.48048462880265486
Validation loss: 2.580440675769661

Epoch: 5| Step: 6
Training loss: 0.2580978375106696
Validation loss: 2.5572002138819565

Epoch: 5| Step: 7
Training loss: 0.2649888527298014
Validation loss: 2.5446817675798954

Epoch: 5| Step: 8
Training loss: 0.4104565202497872
Validation loss: 2.5694791313859495

Epoch: 5| Step: 9
Training loss: 0.45677368535797425
Validation loss: 2.5669470275816457

Epoch: 5| Step: 10
Training loss: 0.47003330358748135
Validation loss: 2.5662300630134496

Epoch: 389| Step: 0
Training loss: 0.5348273331543426
Validation loss: 2.5896962523387566

Epoch: 5| Step: 1
Training loss: 0.33980028378739724
Validation loss: 2.5679288103577367

Epoch: 5| Step: 2
Training loss: 0.43181696263054486
Validation loss: 2.54353890604481

Epoch: 5| Step: 3
Training loss: 0.3733217315311571
Validation loss: 2.5714493632432283

Epoch: 5| Step: 4
Training loss: 0.5394050781155941
Validation loss: 2.6269372626915715

Epoch: 5| Step: 5
Training loss: 0.41685513962387405
Validation loss: 2.605583456887232

Epoch: 5| Step: 6
Training loss: 0.42019419157256893
Validation loss: 2.580834951683318

Epoch: 5| Step: 7
Training loss: 0.4154466131481107
Validation loss: 2.587759562892515

Epoch: 5| Step: 8
Training loss: 0.52100739113769
Validation loss: 2.6028314208414853

Epoch: 5| Step: 9
Training loss: 0.4267689509214873
Validation loss: 2.588454002001356

Epoch: 5| Step: 10
Training loss: 0.5683829967925342
Validation loss: 2.5327895027922267

Epoch: 390| Step: 0
Training loss: 0.5375431320716102
Validation loss: 2.554776416987426

Epoch: 5| Step: 1
Training loss: 0.4117602455900348
Validation loss: 2.5573544366842573

Epoch: 5| Step: 2
Training loss: 0.36856868375675494
Validation loss: 2.555496125476168

Epoch: 5| Step: 3
Training loss: 0.46904627655661063
Validation loss: 2.576373563201498

Epoch: 5| Step: 4
Training loss: 0.5969956680472952
Validation loss: 2.5755619358634427

Epoch: 5| Step: 5
Training loss: 0.5034998356346309
Validation loss: 2.601755282081962

Epoch: 5| Step: 6
Training loss: 0.4310936201979582
Validation loss: 2.5701343878488783

Epoch: 5| Step: 7
Training loss: 0.5326919061213798
Validation loss: 2.583316136705506

Epoch: 5| Step: 8
Training loss: 0.38552425360672
Validation loss: 2.600379198533824

Epoch: 5| Step: 9
Training loss: 0.26206537323642803
Validation loss: 2.592633580992122

Epoch: 5| Step: 10
Training loss: 0.4827172614424269
Validation loss: 2.5203239044311245

Epoch: 391| Step: 0
Training loss: 0.3418472688854568
Validation loss: 2.564916910062136

Epoch: 5| Step: 1
Training loss: 0.46049508991895877
Validation loss: 2.568283378755316

Epoch: 5| Step: 2
Training loss: 0.3874619596021531
Validation loss: 2.5850462466145183

Epoch: 5| Step: 3
Training loss: 0.5708537994901844
Validation loss: 2.5919767550821655

Epoch: 5| Step: 4
Training loss: 0.5334000555661333
Validation loss: 2.5765219996594304

Epoch: 5| Step: 5
Training loss: 0.4080532474155354
Validation loss: 2.6027323504324498

Epoch: 5| Step: 6
Training loss: 0.443517278708835
Validation loss: 2.607771807061704

Epoch: 5| Step: 7
Training loss: 0.2260415072081629
Validation loss: 2.6081590762589224

Epoch: 5| Step: 8
Training loss: 0.5883728533548226
Validation loss: 2.586749765765777

Epoch: 5| Step: 9
Training loss: 0.624053118601329
Validation loss: 2.6016887892939042

Epoch: 5| Step: 10
Training loss: 0.39718241387449005
Validation loss: 2.5830968681767397

Epoch: 392| Step: 0
Training loss: 0.3770046297770583
Validation loss: 2.577266947333449

Epoch: 5| Step: 1
Training loss: 0.4629422573475017
Validation loss: 2.54821275961318

Epoch: 5| Step: 2
Training loss: 0.31935611859401813
Validation loss: 2.5349507272162266

Epoch: 5| Step: 3
Training loss: 0.43522443939081723
Validation loss: 2.5351192061413093

Epoch: 5| Step: 4
Training loss: 0.5341332117257827
Validation loss: 2.5467743211056604

Epoch: 5| Step: 5
Training loss: 0.476473362200117
Validation loss: 2.5805144423018134

Epoch: 5| Step: 6
Training loss: 0.4890497644734515
Validation loss: 2.5786840544305485

Epoch: 5| Step: 7
Training loss: 0.24932808286500724
Validation loss: 2.5748688292155095

Epoch: 5| Step: 8
Training loss: 0.3924402972390668
Validation loss: 2.637991226493861

Epoch: 5| Step: 9
Training loss: 0.7572442116401218
Validation loss: 2.5910369901304855

Epoch: 5| Step: 10
Training loss: 0.3607642852178083
Validation loss: 2.6287492618258703

Epoch: 393| Step: 0
Training loss: 0.6142107486130904
Validation loss: 2.6017697223521563

Epoch: 5| Step: 1
Training loss: 0.4412673630418646
Validation loss: 2.5963421325342164

Epoch: 5| Step: 2
Training loss: 0.3952809377743395
Validation loss: 2.594876139412263

Epoch: 5| Step: 3
Training loss: 0.2943447731883993
Validation loss: 2.5688352109973946

Epoch: 5| Step: 4
Training loss: 0.3688864665561512
Validation loss: 2.5405778561625807

Epoch: 5| Step: 5
Training loss: 0.5671049346939181
Validation loss: 2.5805250981432346

Epoch: 5| Step: 6
Training loss: 0.455833397707798
Validation loss: 2.5773923089439332

Epoch: 5| Step: 7
Training loss: 0.4525373693441921
Validation loss: 2.589590384146442

Epoch: 5| Step: 8
Training loss: 0.4754169641750696
Validation loss: 2.5610939998786333

Epoch: 5| Step: 9
Training loss: 0.49210220687788414
Validation loss: 2.58478486177239

Epoch: 5| Step: 10
Training loss: 0.3635162085916445
Validation loss: 2.5812660153026297

Epoch: 394| Step: 0
Training loss: 0.47761759668047066
Validation loss: 2.5954605513017786

Epoch: 5| Step: 1
Training loss: 0.32481252921175685
Validation loss: 2.592517700894335

Epoch: 5| Step: 2
Training loss: 0.40582161104451847
Validation loss: 2.6146443180988785

Epoch: 5| Step: 3
Training loss: 0.6299217034687054
Validation loss: 2.6047704266665175

Epoch: 5| Step: 4
Training loss: 0.5081696941337264
Validation loss: 2.5673421994616445

Epoch: 5| Step: 5
Training loss: 0.5188732713134317
Validation loss: 2.5889920567297446

Epoch: 5| Step: 6
Training loss: 0.3863368412342121
Validation loss: 2.5408868331323484

Epoch: 5| Step: 7
Training loss: 0.4415413303794539
Validation loss: 2.5645002676257307

Epoch: 5| Step: 8
Training loss: 0.4413748535873356
Validation loss: 2.540124509726412

Epoch: 5| Step: 9
Training loss: 0.29923054146503403
Validation loss: 2.524843369431027

Epoch: 5| Step: 10
Training loss: 0.34833150286322834
Validation loss: 2.5358372622138448

Epoch: 395| Step: 0
Training loss: 0.3534378893619892
Validation loss: 2.5663964145914147

Epoch: 5| Step: 1
Training loss: 0.4949718314642763
Validation loss: 2.591920730711732

Epoch: 5| Step: 2
Training loss: 0.4944082447646137
Validation loss: 2.5663510959060623

Epoch: 5| Step: 3
Training loss: 0.39208117863829556
Validation loss: 2.587954032432277

Epoch: 5| Step: 4
Training loss: 0.24969692038190286
Validation loss: 2.5833734998117577

Epoch: 5| Step: 5
Training loss: 0.4936287682824851
Validation loss: 2.577444060818366

Epoch: 5| Step: 6
Training loss: 0.5685461727069538
Validation loss: 2.5879510457559767

Epoch: 5| Step: 7
Training loss: 0.509854451475494
Validation loss: 2.562632932698994

Epoch: 5| Step: 8
Training loss: 0.2824440880108615
Validation loss: 2.5538718702864576

Epoch: 5| Step: 9
Training loss: 0.2992294956996842
Validation loss: 2.5618695539778207

Epoch: 5| Step: 10
Training loss: 0.5047929931079516
Validation loss: 2.5387573554200347

Epoch: 396| Step: 0
Training loss: 0.4229409561636104
Validation loss: 2.5241445667481575

Epoch: 5| Step: 1
Training loss: 0.45567572325736305
Validation loss: 2.56409433360392

Epoch: 5| Step: 2
Training loss: 0.42699656147767256
Validation loss: 2.5825719482106035

Epoch: 5| Step: 3
Training loss: 0.44430852113756714
Validation loss: 2.5760719698958914

Epoch: 5| Step: 4
Training loss: 0.4688031802210333
Validation loss: 2.572811742998591

Epoch: 5| Step: 5
Training loss: 0.40589603262196133
Validation loss: 2.5765725710577048

Epoch: 5| Step: 6
Training loss: 0.33650999302501117
Validation loss: 2.5390467115846875

Epoch: 5| Step: 7
Training loss: 0.299078717843346
Validation loss: 2.569863790496272

Epoch: 5| Step: 8
Training loss: 0.4467274955915488
Validation loss: 2.51654661368028

Epoch: 5| Step: 9
Training loss: 0.36058747960801135
Validation loss: 2.539493883465138

Epoch: 5| Step: 10
Training loss: 0.6279695062189041
Validation loss: 2.5670627966573902

Epoch: 397| Step: 0
Training loss: 0.48866315021242807
Validation loss: 2.5658793827363438

Epoch: 5| Step: 1
Training loss: 0.33988677223879343
Validation loss: 2.5691649117406135

Epoch: 5| Step: 2
Training loss: 0.41657277082414434
Validation loss: 2.561216799923026

Epoch: 5| Step: 3
Training loss: 0.5960204483099075
Validation loss: 2.5589392178247214

Epoch: 5| Step: 4
Training loss: 0.49759348259403396
Validation loss: 2.50448660697988

Epoch: 5| Step: 5
Training loss: 0.33762276235839567
Validation loss: 2.525161864137522

Epoch: 5| Step: 6
Training loss: 0.43717658486691163
Validation loss: 2.54577482553808

Epoch: 5| Step: 7
Training loss: 0.3878945864257134
Validation loss: 2.549073587511528

Epoch: 5| Step: 8
Training loss: 0.3429057743413726
Validation loss: 2.533040834019939

Epoch: 5| Step: 9
Training loss: 0.2393172209805283
Validation loss: 2.5771304681175558

Epoch: 5| Step: 10
Training loss: 0.5525473557972742
Validation loss: 2.5740248380374093

Epoch: 398| Step: 0
Training loss: 0.4459297352992322
Validation loss: 2.590109013008394

Epoch: 5| Step: 1
Training loss: 0.5770872441881145
Validation loss: 2.5782496178900693

Epoch: 5| Step: 2
Training loss: 0.32782510267747866
Validation loss: 2.577819935936786

Epoch: 5| Step: 3
Training loss: 0.4810493806584218
Validation loss: 2.5812921067873327

Epoch: 5| Step: 4
Training loss: 0.5147067476714097
Validation loss: 2.5385487889801306

Epoch: 5| Step: 5
Training loss: 0.38917196870918264
Validation loss: 2.5324570195927474

Epoch: 5| Step: 6
Training loss: 0.40547122035808336
Validation loss: 2.5017993696568217

Epoch: 5| Step: 7
Training loss: 0.3520574370666395
Validation loss: 2.5015303234891677

Epoch: 5| Step: 8
Training loss: 0.3596136296012513
Validation loss: 2.5476286992319954

Epoch: 5| Step: 9
Training loss: 0.4964351380527464
Validation loss: 2.5267835893593213

Epoch: 5| Step: 10
Training loss: 0.3323557446121777
Validation loss: 2.527903200849988

Epoch: 399| Step: 0
Training loss: 0.3071798576459872
Validation loss: 2.565864403023894

Epoch: 5| Step: 1
Training loss: 0.5131420115021824
Validation loss: 2.6051332972675607

Epoch: 5| Step: 2
Training loss: 0.48512809413718366
Validation loss: 2.624152955618627

Epoch: 5| Step: 3
Training loss: 0.48123724660447365
Validation loss: 2.5945600205277874

Epoch: 5| Step: 4
Training loss: 0.4223800391251944
Validation loss: 2.5852103518835747

Epoch: 5| Step: 5
Training loss: 0.3434416515040415
Validation loss: 2.566546656686583

Epoch: 5| Step: 6
Training loss: 0.5303552610098814
Validation loss: 2.5510395240090498

Epoch: 5| Step: 7
Training loss: 0.27976363866591436
Validation loss: 2.531230440802278

Epoch: 5| Step: 8
Training loss: 0.44795571940603274
Validation loss: 2.558800873384353

Epoch: 5| Step: 9
Training loss: 0.5305997009896227
Validation loss: 2.537753324392949

Epoch: 5| Step: 10
Training loss: 0.3004119637280369
Validation loss: 2.535577159131013

Epoch: 400| Step: 0
Training loss: 0.5323687722136751
Validation loss: 2.5538509509880174

Epoch: 5| Step: 1
Training loss: 0.2471085017547953
Validation loss: 2.543334270310953

Epoch: 5| Step: 2
Training loss: 0.34535266331951464
Validation loss: 2.5763454327636373

Epoch: 5| Step: 3
Training loss: 0.48535024232128365
Validation loss: 2.6087924699292966

Epoch: 5| Step: 4
Training loss: 0.3786104168216562
Validation loss: 2.6317875326582856

Epoch: 5| Step: 5
Training loss: 0.3457531865828845
Validation loss: 2.6190345560807367

Epoch: 5| Step: 6
Training loss: 0.3702959419121872
Validation loss: 2.579912998436556

Epoch: 5| Step: 7
Training loss: 0.22175563233973505
Validation loss: 2.6176012682159016

Epoch: 5| Step: 8
Training loss: 0.4949736678700854
Validation loss: 2.589403674761936

Epoch: 5| Step: 9
Training loss: 0.601106669141117
Validation loss: 2.5504108854748924

Epoch: 5| Step: 10
Training loss: 0.3997301003224906
Validation loss: 2.55774178973336

Epoch: 401| Step: 0
Training loss: 0.37306798505721117
Validation loss: 2.5052771727795418

Epoch: 5| Step: 1
Training loss: 0.3899208206715868
Validation loss: 2.531393010900069

Epoch: 5| Step: 2
Training loss: 0.3877056130066633
Validation loss: 2.5051003900754405

Epoch: 5| Step: 3
Training loss: 0.43485713451537933
Validation loss: 2.538810255774633

Epoch: 5| Step: 4
Training loss: 0.6281875152223536
Validation loss: 2.518361030398561

Epoch: 5| Step: 5
Training loss: 0.4090845001867431
Validation loss: 2.556516507091983

Epoch: 5| Step: 6
Training loss: 0.4554078049886766
Validation loss: 2.543360416277456

Epoch: 5| Step: 7
Training loss: 0.2728742929983307
Validation loss: 2.5734506766719387

Epoch: 5| Step: 8
Training loss: 0.3850661329033951
Validation loss: 2.5269055534156095

Epoch: 5| Step: 9
Training loss: 0.5078846220005868
Validation loss: 2.571085698654538

Epoch: 5| Step: 10
Training loss: 0.42702388543521236
Validation loss: 2.5445510404819274

Epoch: 402| Step: 0
Training loss: 0.334286736933922
Validation loss: 2.5546210947293817

Epoch: 5| Step: 1
Training loss: 0.3976832150233388
Validation loss: 2.510462597155472

Epoch: 5| Step: 2
Training loss: 0.4251494663738988
Validation loss: 2.540370634600773

Epoch: 5| Step: 3
Training loss: 0.4368548745798404
Validation loss: 2.485899828966122

Epoch: 5| Step: 4
Training loss: 0.4784500077080883
Validation loss: 2.5391763348299445

Epoch: 5| Step: 5
Training loss: 0.5444833775497313
Validation loss: 2.5289593349302093

Epoch: 5| Step: 6
Training loss: 0.5030536683973591
Validation loss: 2.5357346245258734

Epoch: 5| Step: 7
Training loss: 0.4035824346488374
Validation loss: 2.57918712108149

Epoch: 5| Step: 8
Training loss: 0.5385611040553905
Validation loss: 2.615783595015227

Epoch: 5| Step: 9
Training loss: 0.41142911042687136
Validation loss: 2.5987963569978563

Epoch: 5| Step: 10
Training loss: 0.32974332273575585
Validation loss: 2.5721489548646006

Epoch: 403| Step: 0
Training loss: 0.29933502487845964
Validation loss: 2.570116261199954

Epoch: 5| Step: 1
Training loss: 0.43490938824146796
Validation loss: 2.567101097743797

Epoch: 5| Step: 2
Training loss: 0.36427822516059977
Validation loss: 2.5775216876763514

Epoch: 5| Step: 3
Training loss: 0.42190802409581224
Validation loss: 2.5773557905727253

Epoch: 5| Step: 4
Training loss: 0.33571748404080864
Validation loss: 2.581755612503967

Epoch: 5| Step: 5
Training loss: 0.4321048018634742
Validation loss: 2.54210188750541

Epoch: 5| Step: 6
Training loss: 0.5179324394835977
Validation loss: 2.570088500172587

Epoch: 5| Step: 7
Training loss: 0.49303564533664035
Validation loss: 2.558251651706411

Epoch: 5| Step: 8
Training loss: 0.35018609072558093
Validation loss: 2.5215442061596653

Epoch: 5| Step: 9
Training loss: 0.3525986343731132
Validation loss: 2.518215011216023

Epoch: 5| Step: 10
Training loss: 0.632246235048511
Validation loss: 2.508735338459218

Epoch: 404| Step: 0
Training loss: 0.4020408490158455
Validation loss: 2.5188938365756286

Epoch: 5| Step: 1
Training loss: 0.5040774682903508
Validation loss: 2.540999681241266

Epoch: 5| Step: 2
Training loss: 0.34168568573716546
Validation loss: 2.554375826580936

Epoch: 5| Step: 3
Training loss: 0.2623305216413983
Validation loss: 2.5707958545054663

Epoch: 5| Step: 4
Training loss: 0.5191119229869303
Validation loss: 2.5529895388215107

Epoch: 5| Step: 5
Training loss: 0.3489348014564577
Validation loss: 2.541297075447435

Epoch: 5| Step: 6
Training loss: 0.44658966291502145
Validation loss: 2.540316520337964

Epoch: 5| Step: 7
Training loss: 0.5745002419925244
Validation loss: 2.523641541163461

Epoch: 5| Step: 8
Training loss: 0.5661891652790293
Validation loss: 2.523731448868065

Epoch: 5| Step: 9
Training loss: 0.4910615728058084
Validation loss: 2.5078263863643024

Epoch: 5| Step: 10
Training loss: 0.32857177608298355
Validation loss: 2.512861048694771

Epoch: 405| Step: 0
Training loss: 0.4069628330360932
Validation loss: 2.5236904401413405

Epoch: 5| Step: 1
Training loss: 0.4106307781515498
Validation loss: 2.533046808322691

Epoch: 5| Step: 2
Training loss: 0.5137293388221716
Validation loss: 2.5209746280924863

Epoch: 5| Step: 3
Training loss: 0.22687582843408582
Validation loss: 2.5175672454982045

Epoch: 5| Step: 4
Training loss: 0.575010182456374
Validation loss: 2.5872990763285806

Epoch: 5| Step: 5
Training loss: 0.3294381477799739
Validation loss: 2.5604679545452935

Epoch: 5| Step: 6
Training loss: 0.44638916829467135
Validation loss: 2.5956226857613434

Epoch: 5| Step: 7
Training loss: 0.30259754411122475
Validation loss: 2.5730975924711292

Epoch: 5| Step: 8
Training loss: 0.33594616058186494
Validation loss: 2.562581211847097

Epoch: 5| Step: 9
Training loss: 0.4995092427331259
Validation loss: 2.5805111012900763

Epoch: 5| Step: 10
Training loss: 0.46258964894028276
Validation loss: 2.5848293901276453

Epoch: 406| Step: 0
Training loss: 0.6438135254635766
Validation loss: 2.586464355618213

Epoch: 5| Step: 1
Training loss: 0.5012107138328121
Validation loss: 2.522500297435551

Epoch: 5| Step: 2
Training loss: 0.2506814698744926
Validation loss: 2.520663198128023

Epoch: 5| Step: 3
Training loss: 0.4367116569256934
Validation loss: 2.536528447630323

Epoch: 5| Step: 4
Training loss: 0.16847864095324316
Validation loss: 2.571298408599586

Epoch: 5| Step: 5
Training loss: 0.35459847866545285
Validation loss: 2.570283780581306

Epoch: 5| Step: 6
Training loss: 0.38265016578208155
Validation loss: 2.5469904161980383

Epoch: 5| Step: 7
Training loss: 0.3625468963674335
Validation loss: 2.5415782718090885

Epoch: 5| Step: 8
Training loss: 0.4990052072438711
Validation loss: 2.5606945329389132

Epoch: 5| Step: 9
Training loss: 0.46651431034745
Validation loss: 2.53769010927549

Epoch: 5| Step: 10
Training loss: 0.38026442397083476
Validation loss: 2.55376557253461

Epoch: 407| Step: 0
Training loss: 0.32465832567262853
Validation loss: 2.532030954111715

Epoch: 5| Step: 1
Training loss: 0.3232811849528598
Validation loss: 2.5247008374380773

Epoch: 5| Step: 2
Training loss: 0.2912082930405793
Validation loss: 2.5428600108772548

Epoch: 5| Step: 3
Training loss: 0.3767421705322186
Validation loss: 2.539708764408211

Epoch: 5| Step: 4
Training loss: 0.3797034695881458
Validation loss: 2.557276452275745

Epoch: 5| Step: 5
Training loss: 0.5128967470731942
Validation loss: 2.561756771581704

Epoch: 5| Step: 6
Training loss: 0.41754337305354045
Validation loss: 2.5596034739363343

Epoch: 5| Step: 7
Training loss: 0.4222597910489507
Validation loss: 2.5452436895728434

Epoch: 5| Step: 8
Training loss: 0.22461476526841379
Validation loss: 2.551640427718146

Epoch: 5| Step: 9
Training loss: 0.40010123610902665
Validation loss: 2.5771952713052637

Epoch: 5| Step: 10
Training loss: 0.5347135062835354
Validation loss: 2.565702158874681

Epoch: 408| Step: 0
Training loss: 0.17573087818244668
Validation loss: 2.55805538963485

Epoch: 5| Step: 1
Training loss: 0.45099728992223076
Validation loss: 2.5563737002670623

Epoch: 5| Step: 2
Training loss: 0.5077436253717087
Validation loss: 2.570141228013481

Epoch: 5| Step: 3
Training loss: 0.3386109892466194
Validation loss: 2.572309841857608

Epoch: 5| Step: 4
Training loss: 0.3855531060083435
Validation loss: 2.5027719368692587

Epoch: 5| Step: 5
Training loss: 0.31969944507436165
Validation loss: 2.5604750503169775

Epoch: 5| Step: 6
Training loss: 0.3390048294419645
Validation loss: 2.5203445006030316

Epoch: 5| Step: 7
Training loss: 0.5143767187894005
Validation loss: 2.5187238041231987

Epoch: 5| Step: 8
Training loss: 0.4023131942257085
Validation loss: 2.510029986946411

Epoch: 5| Step: 9
Training loss: 0.21220015625716468
Validation loss: 2.5480617182032237

Epoch: 5| Step: 10
Training loss: 0.5232494642798994
Validation loss: 2.541982650951681

Epoch: 409| Step: 0
Training loss: 0.4869821585768998
Validation loss: 2.552838530985394

Epoch: 5| Step: 1
Training loss: 0.3475527341369606
Validation loss: 2.5621547571450365

Epoch: 5| Step: 2
Training loss: 0.491468115764875
Validation loss: 2.5712612473335397

Epoch: 5| Step: 3
Training loss: 0.3724416446740041
Validation loss: 2.5903055364640837

Epoch: 5| Step: 4
Training loss: 0.49963417677651095
Validation loss: 2.5757850307328227

Epoch: 5| Step: 5
Training loss: 0.1747457042471025
Validation loss: 2.5362651874636155

Epoch: 5| Step: 6
Training loss: 0.5314197549559225
Validation loss: 2.5141381866230823

Epoch: 5| Step: 7
Training loss: 0.3104142439617538
Validation loss: 2.576101971738583

Epoch: 5| Step: 8
Training loss: 0.3652940997081888
Validation loss: 2.5545979133164587

Epoch: 5| Step: 9
Training loss: 0.32282636005230625
Validation loss: 2.5565000392765023

Epoch: 5| Step: 10
Training loss: 0.3591736353768296
Validation loss: 2.5367641065472495

Epoch: 410| Step: 0
Training loss: 0.27869716361641605
Validation loss: 2.549076162139716

Epoch: 5| Step: 1
Training loss: 0.36883594917542495
Validation loss: 2.5647772237975195

Epoch: 5| Step: 2
Training loss: 0.3847153141803157
Validation loss: 2.5926650647400837

Epoch: 5| Step: 3
Training loss: 0.4039786187276206
Validation loss: 2.5581023034137558

Epoch: 5| Step: 4
Training loss: 0.19035624530620765
Validation loss: 2.568560380141878

Epoch: 5| Step: 5
Training loss: 0.5435748114032153
Validation loss: 2.576866397054428

Epoch: 5| Step: 6
Training loss: 0.5198859817874907
Validation loss: 2.6450659992717735

Epoch: 5| Step: 7
Training loss: 0.3639212682302192
Validation loss: 2.6103740486907565

Epoch: 5| Step: 8
Training loss: 0.5005836061087743
Validation loss: 2.5848679094719054

Epoch: 5| Step: 9
Training loss: 0.33260316399195056
Validation loss: 2.579199088480594

Epoch: 5| Step: 10
Training loss: 0.27738863622076776
Validation loss: 2.5781829201017668

Epoch: 411| Step: 0
Training loss: 0.49066305984796715
Validation loss: 2.540280863179596

Epoch: 5| Step: 1
Training loss: 0.46684991064410924
Validation loss: 2.5414624766758385

Epoch: 5| Step: 2
Training loss: 0.52643017223937
Validation loss: 2.5298651346991265

Epoch: 5| Step: 3
Training loss: 0.23733678843953662
Validation loss: 2.491092855395585

Epoch: 5| Step: 4
Training loss: 0.3563910874181421
Validation loss: 2.518287268538633

Epoch: 5| Step: 5
Training loss: 0.1896317809595524
Validation loss: 2.543347254121662

Epoch: 5| Step: 6
Training loss: 0.23911691526304676
Validation loss: 2.524853952570823

Epoch: 5| Step: 7
Training loss: 0.3325778725147969
Validation loss: 2.523225460009728

Epoch: 5| Step: 8
Training loss: 0.3178073567187129
Validation loss: 2.5361460848780477

Epoch: 5| Step: 9
Training loss: 0.36823237668175557
Validation loss: 2.5383552024265037

Epoch: 5| Step: 10
Training loss: 0.4928691322041225
Validation loss: 2.568337641910673

Epoch: 412| Step: 0
Training loss: 0.3091262375976124
Validation loss: 2.5280220965116404

Epoch: 5| Step: 1
Training loss: 0.5565527863380405
Validation loss: 2.532300695835492

Epoch: 5| Step: 2
Training loss: 0.24476532929686
Validation loss: 2.5328682249344574

Epoch: 5| Step: 3
Training loss: 0.3408757686585341
Validation loss: 2.546066475937093

Epoch: 5| Step: 4
Training loss: 0.4287263350448006
Validation loss: 2.5160926298096022

Epoch: 5| Step: 5
Training loss: 0.4345008194469016
Validation loss: 2.51902912640815

Epoch: 5| Step: 6
Training loss: 0.33843727213956676
Validation loss: 2.4878049950303605

Epoch: 5| Step: 7
Training loss: 0.37423604395651405
Validation loss: 2.528344862619463

Epoch: 5| Step: 8
Training loss: 0.24521676734646858
Validation loss: 2.532245663486524

Epoch: 5| Step: 9
Training loss: 0.4399022837527327
Validation loss: 2.571759172857979

Epoch: 5| Step: 10
Training loss: 0.3875372922549494
Validation loss: 2.5503472794448676

Epoch: 413| Step: 0
Training loss: 0.19909324619646804
Validation loss: 2.5500415106942955

Epoch: 5| Step: 1
Training loss: 0.3964941465179044
Validation loss: 2.5614850184835487

Epoch: 5| Step: 2
Training loss: 0.5678586819080359
Validation loss: 2.543229593034667

Epoch: 5| Step: 3
Training loss: 0.28700485402996756
Validation loss: 2.533767590627057

Epoch: 5| Step: 4
Training loss: 0.37748394290929815
Validation loss: 2.5352762909540534

Epoch: 5| Step: 5
Training loss: 0.2812847937148898
Validation loss: 2.5254208010549357

Epoch: 5| Step: 6
Training loss: 0.24202338934262843
Validation loss: 2.546223582110685

Epoch: 5| Step: 7
Training loss: 0.3864749371062749
Validation loss: 2.5368338810955953

Epoch: 5| Step: 8
Training loss: 0.4628241446998633
Validation loss: 2.5507191728655387

Epoch: 5| Step: 9
Training loss: 0.2549501381304199
Validation loss: 2.534604686290075

Epoch: 5| Step: 10
Training loss: 0.43638668435745437
Validation loss: 2.5570069250117413

Epoch: 414| Step: 0
Training loss: 0.5036341205906285
Validation loss: 2.5510646855626344

Epoch: 5| Step: 1
Training loss: 0.3688954745265587
Validation loss: 2.5556513759955153

Epoch: 5| Step: 2
Training loss: 0.25910780369053793
Validation loss: 2.5491564590625235

Epoch: 5| Step: 3
Training loss: 0.4193718257448502
Validation loss: 2.552378209054965

Epoch: 5| Step: 4
Training loss: 0.3533920472529648
Validation loss: 2.529688677839159

Epoch: 5| Step: 5
Training loss: 0.4440310931122582
Validation loss: 2.573135535722323

Epoch: 5| Step: 6
Training loss: 0.3307982044803181
Validation loss: 2.542236424303006

Epoch: 5| Step: 7
Training loss: 0.21115245286633313
Validation loss: 2.553896381067737

Epoch: 5| Step: 8
Training loss: 0.45361572856263427
Validation loss: 2.5720794456125375

Epoch: 5| Step: 9
Training loss: 0.38111770867379197
Validation loss: 2.5772481312758675

Epoch: 5| Step: 10
Training loss: 0.38408255578263983
Validation loss: 2.5948847748086905

Epoch: 415| Step: 0
Training loss: 0.4597227771793459
Validation loss: 2.5660760509484972

Epoch: 5| Step: 1
Training loss: 0.2638738635593014
Validation loss: 2.5421983602178013

Epoch: 5| Step: 2
Training loss: 0.441988485053616
Validation loss: 2.5259559207457762

Epoch: 5| Step: 3
Training loss: 0.5450793076478174
Validation loss: 2.546033672856956

Epoch: 5| Step: 4
Training loss: 0.2153646137386671
Validation loss: 2.5487659248579924

Epoch: 5| Step: 5
Training loss: 0.28893585265917626
Validation loss: 2.542521624114056

Epoch: 5| Step: 6
Training loss: 0.41205600194032654
Validation loss: 2.544187200406899

Epoch: 5| Step: 7
Training loss: 0.41874056705838936
Validation loss: 2.547221321472621

Epoch: 5| Step: 8
Training loss: 0.2679319895895557
Validation loss: 2.554956718068431

Epoch: 5| Step: 9
Training loss: 0.3072601426113403
Validation loss: 2.5533796539411457

Epoch: 5| Step: 10
Training loss: 0.24182547152126313
Validation loss: 2.5618147555348565

Epoch: 416| Step: 0
Training loss: 0.5122550309112427
Validation loss: 2.5402034541636196

Epoch: 5| Step: 1
Training loss: 0.27583080311236097
Validation loss: 2.5535518443512264

Epoch: 5| Step: 2
Training loss: 0.33360962171117986
Validation loss: 2.5339838413870965

Epoch: 5| Step: 3
Training loss: 0.28091258100801203
Validation loss: 2.540191076979698

Epoch: 5| Step: 4
Training loss: 0.2740262097349663
Validation loss: 2.546941847294808

Epoch: 5| Step: 5
Training loss: 0.568434300678429
Validation loss: 2.549578148863637

Epoch: 5| Step: 6
Training loss: 0.35953555459732706
Validation loss: 2.5680703367215716

Epoch: 5| Step: 7
Training loss: 0.2395026530684296
Validation loss: 2.5219143951446004

Epoch: 5| Step: 8
Training loss: 0.2739522176623202
Validation loss: 2.5487073513345866

Epoch: 5| Step: 9
Training loss: 0.30488100998301043
Validation loss: 2.5725258562825224

Epoch: 5| Step: 10
Training loss: 0.32965307688779305
Validation loss: 2.5436580394118278

Epoch: 417| Step: 0
Training loss: 0.46469258006127506
Validation loss: 2.576510732249318

Epoch: 5| Step: 1
Training loss: 0.3296076225854438
Validation loss: 2.551678735748924

Epoch: 5| Step: 2
Training loss: 0.3861043075359276
Validation loss: 2.5239954602410153

Epoch: 5| Step: 3
Training loss: 0.521408332681083
Validation loss: 2.5544134994511185

Epoch: 5| Step: 4
Training loss: 0.21975302642825698
Validation loss: 2.542787371036575

Epoch: 5| Step: 5
Training loss: 0.17578865141651204
Validation loss: 2.537698763867236

Epoch: 5| Step: 6
Training loss: 0.3167315682714062
Validation loss: 2.5322287371465353

Epoch: 5| Step: 7
Training loss: 0.23671780135968676
Validation loss: 2.5366560554915787

Epoch: 5| Step: 8
Training loss: 0.44002412786761985
Validation loss: 2.527922271627812

Epoch: 5| Step: 9
Training loss: 0.22716479156478953
Validation loss: 2.5525023433888316

Epoch: 5| Step: 10
Training loss: 0.4352497233291877
Validation loss: 2.536671053313014

Epoch: 418| Step: 0
Training loss: 0.3431258169973962
Validation loss: 2.5507045842935656

Epoch: 5| Step: 1
Training loss: 0.2845698166151053
Validation loss: 2.547024904962142

Epoch: 5| Step: 2
Training loss: 0.24997910024782635
Validation loss: 2.5678900648741125

Epoch: 5| Step: 3
Training loss: 0.40118782880905995
Validation loss: 2.5540435677909983

Epoch: 5| Step: 4
Training loss: 0.40308739168851365
Validation loss: 2.512191532761313

Epoch: 5| Step: 5
Training loss: 0.4934755757808974
Validation loss: 2.515820094595353

Epoch: 5| Step: 6
Training loss: 0.35237804761869795
Validation loss: 2.523494606917371

Epoch: 5| Step: 7
Training loss: 0.473479586326373
Validation loss: 2.523408479738614

Epoch: 5| Step: 8
Training loss: 0.3131448767591203
Validation loss: 2.4888161240695212

Epoch: 5| Step: 9
Training loss: 0.2725844428045594
Validation loss: 2.531221685601865

Epoch: 5| Step: 10
Training loss: 0.3235902554531935
Validation loss: 2.5462733034289258

Epoch: 419| Step: 0
Training loss: 0.35872691223072983
Validation loss: 2.566757936483643

Epoch: 5| Step: 1
Training loss: 0.41396150616890715
Validation loss: 2.565104537788107

Epoch: 5| Step: 2
Training loss: 0.3269487141410789
Validation loss: 2.5623835215293798

Epoch: 5| Step: 3
Training loss: 0.24759014763715717
Validation loss: 2.5465398029729553

Epoch: 5| Step: 4
Training loss: 0.3669109317463624
Validation loss: 2.5835341244194665

Epoch: 5| Step: 5
Training loss: 0.35706526262472243
Validation loss: 2.5521951563438954

Epoch: 5| Step: 6
Training loss: 0.3030072981621165
Validation loss: 2.536545760163303

Epoch: 5| Step: 7
Training loss: 0.4560889776436924
Validation loss: 2.5308878031935547

Epoch: 5| Step: 8
Training loss: 0.28819849434015216
Validation loss: 2.5634587462978558

Epoch: 5| Step: 9
Training loss: 0.443306033248772
Validation loss: 2.5385226010296242

Epoch: 5| Step: 10
Training loss: 0.3196068760511473
Validation loss: 2.5682564693469225

Epoch: 420| Step: 0
Training loss: 0.2601285851005593
Validation loss: 2.544939653752259

Epoch: 5| Step: 1
Training loss: 0.32309338005421817
Validation loss: 2.5588765531391267

Epoch: 5| Step: 2
Training loss: 0.3165048280847879
Validation loss: 2.5429925024172975

Epoch: 5| Step: 3
Training loss: 0.4099267044786185
Validation loss: 2.564267718056176

Epoch: 5| Step: 4
Training loss: 0.32947893325205635
Validation loss: 2.5553606745796844

Epoch: 5| Step: 5
Training loss: 0.4553753451174052
Validation loss: 2.5214506847798837

Epoch: 5| Step: 6
Training loss: 0.14722006748292557
Validation loss: 2.5482721764927865

Epoch: 5| Step: 7
Training loss: 0.2493197155862441
Validation loss: 2.5482604672718545

Epoch: 5| Step: 8
Training loss: 0.5014755114170074
Validation loss: 2.5523502410350423

Epoch: 5| Step: 9
Training loss: 0.3209373845190269
Validation loss: 2.570176643965051

Epoch: 5| Step: 10
Training loss: 0.3030551195707273
Validation loss: 2.5621112335494365

Epoch: 421| Step: 0
Training loss: 0.3669163940836454
Validation loss: 2.5534750509932795

Epoch: 5| Step: 1
Training loss: 0.36311324141565654
Validation loss: 2.5658910610114716

Epoch: 5| Step: 2
Training loss: 0.35933199915493746
Validation loss: 2.5850152555679093

Epoch: 5| Step: 3
Training loss: 0.3322127799663088
Validation loss: 2.566132424774488

Epoch: 5| Step: 4
Training loss: 0.36619120226770996
Validation loss: 2.549742275905421

Epoch: 5| Step: 5
Training loss: 0.4503982649169248
Validation loss: 2.551292348756617

Epoch: 5| Step: 6
Training loss: 0.38497849206173607
Validation loss: 2.593273216377138

Epoch: 5| Step: 7
Training loss: 0.28007207675080104
Validation loss: 2.5486435981778084

Epoch: 5| Step: 8
Training loss: 0.33380570568290396
Validation loss: 2.5541126499714943

Epoch: 5| Step: 9
Training loss: 0.2147636003978184
Validation loss: 2.5650492127830806

Epoch: 5| Step: 10
Training loss: 0.1934482485815388
Validation loss: 2.560713993228565

Epoch: 422| Step: 0
Training loss: 0.4307790243805961
Validation loss: 2.578793171808603

Epoch: 5| Step: 1
Training loss: 0.21555225416759946
Validation loss: 2.565558569319413

Epoch: 5| Step: 2
Training loss: 0.3114839008558275
Validation loss: 2.5451246676968484

Epoch: 5| Step: 3
Training loss: 0.43732658423412296
Validation loss: 2.5564340797085223

Epoch: 5| Step: 4
Training loss: 0.3327697954852862
Validation loss: 2.5685790437576017

Epoch: 5| Step: 5
Training loss: 0.3165617784264071
Validation loss: 2.573113421530795

Epoch: 5| Step: 6
Training loss: 0.16095762265891403
Validation loss: 2.557853465763539

Epoch: 5| Step: 7
Training loss: 0.429043373742952
Validation loss: 2.5518999453651086

Epoch: 5| Step: 8
Training loss: 0.4390399940668598
Validation loss: 2.555243078574929

Epoch: 5| Step: 9
Training loss: 0.37689775841037004
Validation loss: 2.5417816923497276

Epoch: 5| Step: 10
Training loss: 0.20105805927278275
Validation loss: 2.5353202175858254

Epoch: 423| Step: 0
Training loss: 0.22852055633962384
Validation loss: 2.5308967768241115

Epoch: 5| Step: 1
Training loss: 0.4186371423458779
Validation loss: 2.520181460917159

Epoch: 5| Step: 2
Training loss: 0.36966014815695475
Validation loss: 2.5364627323052265

Epoch: 5| Step: 3
Training loss: 0.2827894675639245
Validation loss: 2.517572159812868

Epoch: 5| Step: 4
Training loss: 0.18234149501618932
Validation loss: 2.504125364128585

Epoch: 5| Step: 5
Training loss: 0.27513616723634726
Validation loss: 2.535322020501921

Epoch: 5| Step: 6
Training loss: 0.2825284353225091
Validation loss: 2.528505657371934

Epoch: 5| Step: 7
Training loss: 0.4323500589972648
Validation loss: 2.5190734900232212

Epoch: 5| Step: 8
Training loss: 0.24848588256436185
Validation loss: 2.572730365325571

Epoch: 5| Step: 9
Training loss: 0.41313813152594486
Validation loss: 2.5679066692972454

Epoch: 5| Step: 10
Training loss: 0.4270044133686361
Validation loss: 2.595066712380017

Epoch: 424| Step: 0
Training loss: 0.2333512358240605
Validation loss: 2.5557006761591614

Epoch: 5| Step: 1
Training loss: 0.4559662792438743
Validation loss: 2.606700321966675

Epoch: 5| Step: 2
Training loss: 0.25244454948194994
Validation loss: 2.614908904493552

Epoch: 5| Step: 3
Training loss: 0.29754809569821716
Validation loss: 2.5935405454388

Epoch: 5| Step: 4
Training loss: 0.4941807606195213
Validation loss: 2.555675582317153

Epoch: 5| Step: 5
Training loss: 0.4249855445759608
Validation loss: 2.562646073830763

Epoch: 5| Step: 6
Training loss: 0.36493736062730736
Validation loss: 2.564875418382455

Epoch: 5| Step: 7
Training loss: 0.3381503435533339
Validation loss: 2.562941713477233

Epoch: 5| Step: 8
Training loss: 0.22325746612463224
Validation loss: 2.5586547591290687

Epoch: 5| Step: 9
Training loss: 0.2062798034202317
Validation loss: 2.5715582936321786

Epoch: 5| Step: 10
Training loss: 0.30028911060863134
Validation loss: 2.517364981458209

Epoch: 425| Step: 0
Training loss: 0.39098747601781136
Validation loss: 2.537631719558957

Epoch: 5| Step: 1
Training loss: 0.48263455540688305
Validation loss: 2.545612320402096

Epoch: 5| Step: 2
Training loss: 0.24731732260422346
Validation loss: 2.5123873720335568

Epoch: 5| Step: 3
Training loss: 0.29102370231734953
Validation loss: 2.4976067244458076

Epoch: 5| Step: 4
Training loss: 0.10173701002293807
Validation loss: 2.5151027024378747

Epoch: 5| Step: 5
Training loss: 0.3180682717802383
Validation loss: 2.5461654253412274

Epoch: 5| Step: 6
Training loss: 0.3140786589076195
Validation loss: 2.5304267280785604

Epoch: 5| Step: 7
Training loss: 0.22196929767986295
Validation loss: 2.538232166963563

Epoch: 5| Step: 8
Training loss: 0.45484414040677484
Validation loss: 2.575524085593267

Epoch: 5| Step: 9
Training loss: 0.4029361844521347
Validation loss: 2.5844035513616186

Epoch: 5| Step: 10
Training loss: 0.4150155632995902
Validation loss: 2.54319827197316

Epoch: 426| Step: 0
Training loss: 0.322909492238649
Validation loss: 2.547298566036097

Epoch: 5| Step: 1
Training loss: 0.4026404462739399
Validation loss: 2.558757799705968

Epoch: 5| Step: 2
Training loss: 0.3475700014262141
Validation loss: 2.5713367577611397

Epoch: 5| Step: 3
Training loss: 0.41427027689425044
Validation loss: 2.5256003404165264

Epoch: 5| Step: 4
Training loss: 0.22438198687053953
Validation loss: 2.5501557762826703

Epoch: 5| Step: 5
Training loss: 0.3397415489776574
Validation loss: 2.549176343328463

Epoch: 5| Step: 6
Training loss: 0.43137914410095324
Validation loss: 2.5483895775982934

Epoch: 5| Step: 7
Training loss: 0.2922933677389104
Validation loss: 2.551855658160722

Epoch: 5| Step: 8
Training loss: 0.27704601693855524
Validation loss: 2.584776703050377

Epoch: 5| Step: 9
Training loss: 0.3862222509076557
Validation loss: 2.5818090870887453

Epoch: 5| Step: 10
Training loss: 0.20421410154730485
Validation loss: 2.5732351204583095

Epoch: 427| Step: 0
Training loss: 0.1557550877322587
Validation loss: 2.5579624935648164

Epoch: 5| Step: 1
Training loss: 0.3095130987877409
Validation loss: 2.5688443165311408

Epoch: 5| Step: 2
Training loss: 0.30337607760919755
Validation loss: 2.609278890750567

Epoch: 5| Step: 3
Training loss: 0.4388170683100983
Validation loss: 2.59918774592597

Epoch: 5| Step: 4
Training loss: 0.4752998509877728
Validation loss: 2.593002302498988

Epoch: 5| Step: 5
Training loss: 0.3524609952172147
Validation loss: 2.609890121674494

Epoch: 5| Step: 6
Training loss: 0.31070448516632393
Validation loss: 2.58513438516957

Epoch: 5| Step: 7
Training loss: 0.3294761631205917
Validation loss: 2.5981542124332173

Epoch: 5| Step: 8
Training loss: 0.12157370450717854
Validation loss: 2.5676081127265347

Epoch: 5| Step: 9
Training loss: 0.3013775846575386
Validation loss: 2.615092049378574

Epoch: 5| Step: 10
Training loss: 0.2699662167995159
Validation loss: 2.5977748821863624

Epoch: 428| Step: 0
Training loss: 0.2239953479933049
Validation loss: 2.6290180990863425

Epoch: 5| Step: 1
Training loss: 0.33029137443684187
Validation loss: 2.5816194152712995

Epoch: 5| Step: 2
Training loss: 0.17404353264447717
Validation loss: 2.579101939227983

Epoch: 5| Step: 3
Training loss: 0.23336823718953706
Validation loss: 2.6213044640793814

Epoch: 5| Step: 4
Training loss: 0.4826435089652529
Validation loss: 2.5808833734615657

Epoch: 5| Step: 5
Training loss: 0.30236781909169863
Validation loss: 2.5687423315119133

Epoch: 5| Step: 6
Training loss: 0.43757582756683006
Validation loss: 2.5604100582408953

Epoch: 5| Step: 7
Training loss: 0.18989446692534015
Validation loss: 2.522951962803554

Epoch: 5| Step: 8
Training loss: 0.31066482031581205
Validation loss: 2.5661648170853963

Epoch: 5| Step: 9
Training loss: 0.3856141276194781
Validation loss: 2.5617705456664397

Epoch: 5| Step: 10
Training loss: 0.31703066730398716
Validation loss: 2.573523809777265

Epoch: 429| Step: 0
Training loss: 0.43874361193861827
Validation loss: 2.5748221930476896

Epoch: 5| Step: 1
Training loss: 0.2768914470136237
Validation loss: 2.5571106513168917

Epoch: 5| Step: 2
Training loss: 0.1646764824129753
Validation loss: 2.5430759098424702

Epoch: 5| Step: 3
Training loss: 0.3067205045613938
Validation loss: 2.539944570842696

Epoch: 5| Step: 4
Training loss: 0.20850745712868024
Validation loss: 2.557776363553353

Epoch: 5| Step: 5
Training loss: 0.4194634352560968
Validation loss: 2.567425612666807

Epoch: 5| Step: 6
Training loss: 0.40587462909659217
Validation loss: 2.5200755813462536

Epoch: 5| Step: 7
Training loss: 0.15885412823306594
Validation loss: 2.5283060033166085

Epoch: 5| Step: 8
Training loss: 0.4465506557017706
Validation loss: 2.549138349683347

Epoch: 5| Step: 9
Training loss: 0.2745847883653849
Validation loss: 2.5706887492031045

Epoch: 5| Step: 10
Training loss: 0.2844932897007689
Validation loss: 2.532389978744595

Epoch: 430| Step: 0
Training loss: 0.2637290610006261
Validation loss: 2.5406682676696923

Epoch: 5| Step: 1
Training loss: 0.27850012073993635
Validation loss: 2.573442541289927

Epoch: 5| Step: 2
Training loss: 0.4530775439963832
Validation loss: 2.565927321924326

Epoch: 5| Step: 3
Training loss: 0.37953835293439336
Validation loss: 2.542711498498504

Epoch: 5| Step: 4
Training loss: 0.2759923920947714
Validation loss: 2.567040067896879

Epoch: 5| Step: 5
Training loss: 0.30873433061753186
Validation loss: 2.545110555733952

Epoch: 5| Step: 6
Training loss: 0.3667009254547916
Validation loss: 2.563816340729147

Epoch: 5| Step: 7
Training loss: 0.44398998164997144
Validation loss: 2.573372626650458

Epoch: 5| Step: 8
Training loss: 0.14632599215523903
Validation loss: 2.544869406860037

Epoch: 5| Step: 9
Training loss: 0.164476949728371
Validation loss: 2.538626666530276

Epoch: 5| Step: 10
Training loss: 0.30458214968117797
Validation loss: 2.5746529337005977

Epoch: 431| Step: 0
Training loss: 0.25391857410745655
Validation loss: 2.5708729501692833

Epoch: 5| Step: 1
Training loss: 0.31948323017235575
Validation loss: 2.5603988981531955

Epoch: 5| Step: 2
Training loss: 0.2798899509241014
Validation loss: 2.5387868312875685

Epoch: 5| Step: 3
Training loss: 0.25106652573350946
Validation loss: 2.5135589565832936

Epoch: 5| Step: 4
Training loss: 0.3558737574998813
Validation loss: 2.5305044696001504

Epoch: 5| Step: 5
Training loss: 0.20640225498280795
Validation loss: 2.546054584391096

Epoch: 5| Step: 6
Training loss: 0.2915982807687619
Validation loss: 2.5421348865385407

Epoch: 5| Step: 7
Training loss: 0.41367867511927175
Validation loss: 2.5556862093124626

Epoch: 5| Step: 8
Training loss: 0.2153606957973067
Validation loss: 2.567583989945336

Epoch: 5| Step: 9
Training loss: 0.477366613286922
Validation loss: 2.5314935830077583

Epoch: 5| Step: 10
Training loss: 0.35620773968253155
Validation loss: 2.5755424513949996

Epoch: 432| Step: 0
Training loss: 0.22113344557307138
Validation loss: 2.554494855981187

Epoch: 5| Step: 1
Training loss: 0.41860984050814126
Validation loss: 2.5768175162632727

Epoch: 5| Step: 2
Training loss: 0.5005488363709536
Validation loss: 2.518946231563072

Epoch: 5| Step: 3
Training loss: 0.20758061127184074
Validation loss: 2.5318014530921884

Epoch: 5| Step: 4
Training loss: 0.2228257889014948
Validation loss: 2.57168599455461

Epoch: 5| Step: 5
Training loss: 0.3017403557428491
Validation loss: 2.5519963892344335

Epoch: 5| Step: 6
Training loss: 0.2697960478869999
Validation loss: 2.5667507102603038

Epoch: 5| Step: 7
Training loss: 0.15954337668961566
Validation loss: 2.532116111183819

Epoch: 5| Step: 8
Training loss: 0.25015459645074456
Validation loss: 2.573712330573056

Epoch: 5| Step: 9
Training loss: 0.47016621275792775
Validation loss: 2.5413968001644167

Epoch: 5| Step: 10
Training loss: 0.20776647796708228
Validation loss: 2.5819246921919623

Epoch: 433| Step: 0
Training loss: 0.34095816024293546
Validation loss: 2.567697370537763

Epoch: 5| Step: 1
Training loss: 0.17223585784185194
Validation loss: 2.5564320118949335

Epoch: 5| Step: 2
Training loss: 0.375846919707941
Validation loss: 2.5755625380630565

Epoch: 5| Step: 3
Training loss: 0.41383699358280224
Validation loss: 2.570424168949925

Epoch: 5| Step: 4
Training loss: 0.35695503055684213
Validation loss: 2.5537175300262236

Epoch: 5| Step: 5
Training loss: 0.16025843500576087
Validation loss: 2.605577989334112

Epoch: 5| Step: 6
Training loss: 0.2660719113171807
Validation loss: 2.600695927052051

Epoch: 5| Step: 7
Training loss: 0.4104927862163101
Validation loss: 2.6009107578503605

Epoch: 5| Step: 8
Training loss: 0.3302664360689386
Validation loss: 2.5457547676779644

Epoch: 5| Step: 9
Training loss: 0.3121584575573872
Validation loss: 2.5869676980210796

Epoch: 5| Step: 10
Training loss: 0.2592929612680694
Validation loss: 2.5535338534879806

Epoch: 434| Step: 0
Training loss: 0.2157936079669975
Validation loss: 2.585624772821745

Epoch: 5| Step: 1
Training loss: 0.2763846294169641
Validation loss: 2.5868869836858286

Epoch: 5| Step: 2
Training loss: 0.4052689701431585
Validation loss: 2.5602150130346093

Epoch: 5| Step: 3
Training loss: 0.1257660015411939
Validation loss: 2.556366522911974

Epoch: 5| Step: 4
Training loss: 0.2585213626145311
Validation loss: 2.5518935063683865

Epoch: 5| Step: 5
Training loss: 0.3017533928507374
Validation loss: 2.5883228748221354

Epoch: 5| Step: 6
Training loss: 0.21476242953934827
Validation loss: 2.5980349665340907

Epoch: 5| Step: 7
Training loss: 0.44242292815966705
Validation loss: 2.516376204096279

Epoch: 5| Step: 8
Training loss: 0.2990202815750791
Validation loss: 2.53175391930476

Epoch: 5| Step: 9
Training loss: 0.36375572639231407
Validation loss: 2.5616721695168145

Epoch: 5| Step: 10
Training loss: 0.48299926305995033
Validation loss: 2.532147096516378

Epoch: 435| Step: 0
Training loss: 0.19769749719919724
Validation loss: 2.5545633895584468

Epoch: 5| Step: 1
Training loss: 0.4072065279855655
Validation loss: 2.54470506023

Epoch: 5| Step: 2
Training loss: 0.2860419093175212
Validation loss: 2.546935891493582

Epoch: 5| Step: 3
Training loss: 0.36007394408738824
Validation loss: 2.5866189684602032

Epoch: 5| Step: 4
Training loss: 0.38408707557933114
Validation loss: 2.546626433379665

Epoch: 5| Step: 5
Training loss: 0.28169739424868384
Validation loss: 2.5682832180463544

Epoch: 5| Step: 6
Training loss: 0.24137594779730814
Validation loss: 2.579928814000613

Epoch: 5| Step: 7
Training loss: 0.28485459872546676
Validation loss: 2.581847122748895

Epoch: 5| Step: 8
Training loss: 0.41955014120578493
Validation loss: 2.5689980009757423

Epoch: 5| Step: 9
Training loss: 0.20458319751077197
Validation loss: 2.542506156143823

Epoch: 5| Step: 10
Training loss: 0.14906748924262817
Validation loss: 2.5619513591874497

Epoch: 436| Step: 0
Training loss: 0.19549023170957883
Validation loss: 2.5755093115340837

Epoch: 5| Step: 1
Training loss: 0.38626119730129055
Validation loss: 2.5783053705754937

Epoch: 5| Step: 2
Training loss: 0.27783242009408887
Validation loss: 2.5573041829666137

Epoch: 5| Step: 3
Training loss: 0.3237809822177875
Validation loss: 2.5538891074106553

Epoch: 5| Step: 4
Training loss: 0.42409542110564463
Validation loss: 2.5884114168277086

Epoch: 5| Step: 5
Training loss: 0.23791002059818664
Validation loss: 2.5833177761227364

Epoch: 5| Step: 6
Training loss: 0.31708489153642466
Validation loss: 2.567936321782451

Epoch: 5| Step: 7
Training loss: 0.16914951794440342
Validation loss: 2.5617408658442

Epoch: 5| Step: 8
Training loss: 0.27566901130228855
Validation loss: 2.563632115736179

Epoch: 5| Step: 9
Training loss: 0.24903793292772655
Validation loss: 2.5602734824967004

Epoch: 5| Step: 10
Training loss: 0.39065772873144167
Validation loss: 2.540716204021393

Epoch: 437| Step: 0
Training loss: 0.4441714810378274
Validation loss: 2.5300021015537726

Epoch: 5| Step: 1
Training loss: 0.3065550617944957
Validation loss: 2.575098192891669

Epoch: 5| Step: 2
Training loss: 0.11939570604991613
Validation loss: 2.5306560235205495

Epoch: 5| Step: 3
Training loss: 0.3463965750905991
Validation loss: 2.571492178472544

Epoch: 5| Step: 4
Training loss: 0.1778292245659093
Validation loss: 2.5569132265941836

Epoch: 5| Step: 5
Training loss: 0.20796523755415536
Validation loss: 2.5725417232407564

Epoch: 5| Step: 6
Training loss: 0.19180449103560973
Validation loss: 2.564833392279946

Epoch: 5| Step: 7
Training loss: 0.3226852690275843
Validation loss: 2.545898848846776

Epoch: 5| Step: 8
Training loss: 0.4077199787113484
Validation loss: 2.5596917965032104

Epoch: 5| Step: 9
Training loss: 0.35465262069277054
Validation loss: 2.547973309429964

Epoch: 5| Step: 10
Training loss: 0.2358633152119919
Validation loss: 2.56568543926505

Epoch: 438| Step: 0
Training loss: 0.36124064443280923
Validation loss: 2.581518441411196

Epoch: 5| Step: 1
Training loss: 0.23327239875072875
Validation loss: 2.5576826975833886

Epoch: 5| Step: 2
Training loss: 0.42605914225408653
Validation loss: 2.5872826870241417

Epoch: 5| Step: 3
Training loss: 0.23453963378468687
Validation loss: 2.5118972601846483

Epoch: 5| Step: 4
Training loss: 0.23867729761484774
Validation loss: 2.577396222945774

Epoch: 5| Step: 5
Training loss: 0.2467488621532831
Validation loss: 2.542489793196577

Epoch: 5| Step: 6
Training loss: 0.20847383867256658
Validation loss: 2.5483037576201433

Epoch: 5| Step: 7
Training loss: 0.2588031117206505
Validation loss: 2.530855019137912

Epoch: 5| Step: 8
Training loss: 0.26387951057623177
Validation loss: 2.5703180405746893

Epoch: 5| Step: 9
Training loss: 0.29534877423122
Validation loss: 2.507683381958312

Epoch: 5| Step: 10
Training loss: 0.4314774597542119
Validation loss: 2.567250702937977

Epoch: 439| Step: 0
Training loss: 0.28255663778733286
Validation loss: 2.5318643595887913

Epoch: 5| Step: 1
Training loss: 0.22305062152234664
Validation loss: 2.5651513646211623

Epoch: 5| Step: 2
Training loss: 0.32867265592844547
Validation loss: 2.541627990701401

Epoch: 5| Step: 3
Training loss: 0.32132006556492093
Validation loss: 2.566018746746074

Epoch: 5| Step: 4
Training loss: 0.3428279692046753
Validation loss: 2.5544938082431705

Epoch: 5| Step: 5
Training loss: 0.25286113148673045
Validation loss: 2.5733573346557157

Epoch: 5| Step: 6
Training loss: 0.24679954679515534
Validation loss: 2.5707620157274618

Epoch: 5| Step: 7
Training loss: 0.36338132074748764
Validation loss: 2.565115062756485

Epoch: 5| Step: 8
Training loss: 0.2483562582563806
Validation loss: 2.6103374839796425

Epoch: 5| Step: 9
Training loss: 0.2619442466507771
Validation loss: 2.6097457599743232

Epoch: 5| Step: 10
Training loss: 0.3507877395981132
Validation loss: 2.606393684012319

Epoch: 440| Step: 0
Training loss: 0.3140314366745031
Validation loss: 2.584052118527002

Epoch: 5| Step: 1
Training loss: 0.1586661450747457
Validation loss: 2.5702637055230717

Epoch: 5| Step: 2
Training loss: 0.4135162781321594
Validation loss: 2.604190466659242

Epoch: 5| Step: 3
Training loss: 0.35559806986581033
Validation loss: 2.6205234005161913

Epoch: 5| Step: 4
Training loss: 0.13688457514310173
Validation loss: 2.5913027928493557

Epoch: 5| Step: 5
Training loss: 0.35255334883297584
Validation loss: 2.5525915012039166

Epoch: 5| Step: 6
Training loss: 0.22182374214388387
Validation loss: 2.557036205611395

Epoch: 5| Step: 7
Training loss: 0.20758011774980917
Validation loss: 2.5477742431358132

Epoch: 5| Step: 8
Training loss: 0.28318282745234497
Validation loss: 2.576747326571077

Epoch: 5| Step: 9
Training loss: 0.3843592904144793
Validation loss: 2.5601855905504625

Epoch: 5| Step: 10
Training loss: 0.3024520172533987
Validation loss: 2.5244419444738058

Epoch: 441| Step: 0
Training loss: 0.24326709877659045
Validation loss: 2.4992909400108823

Epoch: 5| Step: 1
Training loss: 0.2884569656027952
Validation loss: 2.567812510253714

Epoch: 5| Step: 2
Training loss: 0.1835815242998403
Validation loss: 2.54451048618235

Epoch: 5| Step: 3
Training loss: 0.268755986457508
Validation loss: 2.575176238398611

Epoch: 5| Step: 4
Training loss: 0.19057312478423102
Validation loss: 2.5205401910593523

Epoch: 5| Step: 5
Training loss: 0.3746754911151105
Validation loss: 2.5212776411528806

Epoch: 5| Step: 6
Training loss: 0.3474117447937629
Validation loss: 2.5401197429970503

Epoch: 5| Step: 7
Training loss: 0.3304039740599958
Validation loss: 2.5267484098478077

Epoch: 5| Step: 8
Training loss: 0.32642347944994804
Validation loss: 2.4922256263647715

Epoch: 5| Step: 9
Training loss: 0.3440731761880156
Validation loss: 2.5707464698642277

Epoch: 5| Step: 10
Training loss: 0.2881544904449327
Validation loss: 2.5032228134139176

Epoch: 442| Step: 0
Training loss: 0.31766810579405913
Validation loss: 2.5161678864955412

Epoch: 5| Step: 1
Training loss: 0.4439198820229111
Validation loss: 2.5081711696209537

Epoch: 5| Step: 2
Training loss: 0.24509440464358906
Validation loss: 2.522822792429342

Epoch: 5| Step: 3
Training loss: 0.2243099538882337
Validation loss: 2.545980115467903

Epoch: 5| Step: 4
Training loss: 0.3250704688921905
Validation loss: 2.579016363904061

Epoch: 5| Step: 5
Training loss: 0.2910043214996532
Validation loss: 2.5684781815669595

Epoch: 5| Step: 6
Training loss: 0.30717969998986133
Validation loss: 2.5489578794270464

Epoch: 5| Step: 7
Training loss: 0.2283845672388639
Validation loss: 2.5679642638099693

Epoch: 5| Step: 8
Training loss: 0.21538564658957926
Validation loss: 2.547932920279241

Epoch: 5| Step: 9
Training loss: 0.26704215228936895
Validation loss: 2.5929764306813037

Epoch: 5| Step: 10
Training loss: 0.42622955589264855
Validation loss: 2.568791741708484

Epoch: 443| Step: 0
Training loss: 0.41177238679582057
Validation loss: 2.572443615996766

Epoch: 5| Step: 1
Training loss: 0.20680516872340649
Validation loss: 2.592768269967801

Epoch: 5| Step: 2
Training loss: 0.4690216866564833
Validation loss: 2.572734684009464

Epoch: 5| Step: 3
Training loss: 0.26936404252391094
Validation loss: 2.598646129693602

Epoch: 5| Step: 4
Training loss: 0.2103335157638334
Validation loss: 2.55978669892718

Epoch: 5| Step: 5
Training loss: 0.2478315740631165
Validation loss: 2.5477024407447213

Epoch: 5| Step: 6
Training loss: 0.3936196171891304
Validation loss: 2.5459613269680124

Epoch: 5| Step: 7
Training loss: 0.21094204756461835
Validation loss: 2.554547044632821

Epoch: 5| Step: 8
Training loss: 0.16876954102403022
Validation loss: 2.5482679410990383

Epoch: 5| Step: 9
Training loss: 0.21305686689446035
Validation loss: 2.551191467858776

Epoch: 5| Step: 10
Training loss: 0.26480100956382935
Validation loss: 2.5785675275608275

Epoch: 444| Step: 0
Training loss: 0.12838978331170306
Validation loss: 2.585391710818063

Epoch: 5| Step: 1
Training loss: 0.28694665930090035
Validation loss: 2.5778173636625477

Epoch: 5| Step: 2
Training loss: 0.24710707711361335
Validation loss: 2.551380262704291

Epoch: 5| Step: 3
Training loss: 0.5344446839523483
Validation loss: 2.5546453253644184

Epoch: 5| Step: 4
Training loss: 0.24362252001285487
Validation loss: 2.556881486857485

Epoch: 5| Step: 5
Training loss: 0.2862277215300648
Validation loss: 2.5563330517218126

Epoch: 5| Step: 6
Training loss: 0.1889910618141922
Validation loss: 2.5534203595423093

Epoch: 5| Step: 7
Training loss: 0.34359665181182325
Validation loss: 2.5649311169500604

Epoch: 5| Step: 8
Training loss: 0.3241349077398597
Validation loss: 2.5703232879018305

Epoch: 5| Step: 9
Training loss: 0.3075070623036533
Validation loss: 2.6155202076312745

Epoch: 5| Step: 10
Training loss: 0.1657369012953885
Validation loss: 2.5723058568302775

Epoch: 445| Step: 0
Training loss: 0.32069355698320406
Validation loss: 2.5886981700814857

Epoch: 5| Step: 1
Training loss: 0.35430335698196824
Validation loss: 2.5692772921139326

Epoch: 5| Step: 2
Training loss: 0.224789555468705
Validation loss: 2.537235633042479

Epoch: 5| Step: 3
Training loss: 0.17985651111816472
Validation loss: 2.560921622849764

Epoch: 5| Step: 4
Training loss: 0.19515941342431034
Validation loss: 2.5131230550246073

Epoch: 5| Step: 5
Training loss: 0.2976557603967199
Validation loss: 2.518030104144935

Epoch: 5| Step: 6
Training loss: 0.3671800531484409
Validation loss: 2.554725511467624

Epoch: 5| Step: 7
Training loss: 0.3640269757403923
Validation loss: 2.522028127752599

Epoch: 5| Step: 8
Training loss: 0.38381742416301673
Validation loss: 2.544581891521886

Epoch: 5| Step: 9
Training loss: 0.22848960532704313
Validation loss: 2.5504761494409602

Epoch: 5| Step: 10
Training loss: 0.20695619302205728
Validation loss: 2.5327995699213974

Epoch: 446| Step: 0
Training loss: 0.17113212956246762
Validation loss: 2.5611544742385854

Epoch: 5| Step: 1
Training loss: 0.2844475470218377
Validation loss: 2.5437922500189987

Epoch: 5| Step: 2
Training loss: 0.34088950561487924
Validation loss: 2.5326024135126097

Epoch: 5| Step: 3
Training loss: 0.41527624197299895
Validation loss: 2.5498657121230908

Epoch: 5| Step: 4
Training loss: 0.25176936109052156
Validation loss: 2.575455675786016

Epoch: 5| Step: 5
Training loss: 0.2835757993371233
Validation loss: 2.5446669237625765

Epoch: 5| Step: 6
Training loss: 0.19736177159807433
Validation loss: 2.5228554918554096

Epoch: 5| Step: 7
Training loss: 0.31028412553767004
Validation loss: 2.574373483866241

Epoch: 5| Step: 8
Training loss: 0.28012559560280925
Validation loss: 2.5271425819016717

Epoch: 5| Step: 9
Training loss: 0.31356563075211374
Validation loss: 2.5220593158011244

Epoch: 5| Step: 10
Training loss: 0.12074066800432841
Validation loss: 2.52880551035422

Epoch: 447| Step: 0
Training loss: 0.23490804614412725
Validation loss: 2.534169976888819

Epoch: 5| Step: 1
Training loss: 0.1498824799141016
Validation loss: 2.5293576991073916

Epoch: 5| Step: 2
Training loss: 0.34151483070500027
Validation loss: 2.536194390491318

Epoch: 5| Step: 3
Training loss: 0.2403175241121253
Validation loss: 2.537587965285125

Epoch: 5| Step: 4
Training loss: 0.25233638799929436
Validation loss: 2.55470839187666

Epoch: 5| Step: 5
Training loss: 0.358835624119796
Validation loss: 2.5595862968286793

Epoch: 5| Step: 6
Training loss: 0.28101574891135117
Validation loss: 2.561801387979345

Epoch: 5| Step: 7
Training loss: 0.40502524991856276
Validation loss: 2.561798114128477

Epoch: 5| Step: 8
Training loss: 0.29747955354183225
Validation loss: 2.572252375541604

Epoch: 5| Step: 9
Training loss: 0.213548998396701
Validation loss: 2.6054754452521656

Epoch: 5| Step: 10
Training loss: 0.2157944970204638
Validation loss: 2.5840509041951187

Epoch: 448| Step: 0
Training loss: 0.17831323490532897
Validation loss: 2.616739066233841

Epoch: 5| Step: 1
Training loss: 0.3251675659806293
Validation loss: 2.5861302533118358

Epoch: 5| Step: 2
Training loss: 0.34725763206594823
Validation loss: 2.5809120365170735

Epoch: 5| Step: 3
Training loss: 0.25370710339193
Validation loss: 2.5696195996319378

Epoch: 5| Step: 4
Training loss: 0.2519611978346498
Validation loss: 2.5868310567053965

Epoch: 5| Step: 5
Training loss: 0.3312792396236119
Validation loss: 2.574342183715284

Epoch: 5| Step: 6
Training loss: 0.26399507846904874
Validation loss: 2.57352006371609

Epoch: 5| Step: 7
Training loss: 0.3789721756046814
Validation loss: 2.5444272688554808

Epoch: 5| Step: 8
Training loss: 0.22375740511857042
Validation loss: 2.5625037876824477

Epoch: 5| Step: 9
Training loss: 0.1995462269191898
Validation loss: 2.548865620371054

Epoch: 5| Step: 10
Training loss: 0.35193687215148495
Validation loss: 2.568925182114694

Epoch: 449| Step: 0
Training loss: 0.22258257901952827
Validation loss: 2.573867980351534

Epoch: 5| Step: 1
Training loss: 0.38832554171212574
Validation loss: 2.56231769140353

Epoch: 5| Step: 2
Training loss: 0.3181623188343356
Validation loss: 2.56385674664141

Epoch: 5| Step: 3
Training loss: 0.12793738946225042
Validation loss: 2.589767170083831

Epoch: 5| Step: 4
Training loss: 0.3292781571106052
Validation loss: 2.5712647449342763

Epoch: 5| Step: 5
Training loss: 0.24688969670986635
Validation loss: 2.562932049824431

Epoch: 5| Step: 6
Training loss: 0.15721433603834734
Validation loss: 2.5665766984566396

Epoch: 5| Step: 7
Training loss: 0.25511414710215985
Validation loss: 2.5460542913810906

Epoch: 5| Step: 8
Training loss: 0.24759075700741226
Validation loss: 2.5399212996382987

Epoch: 5| Step: 9
Training loss: 0.26841704569326663
Validation loss: 2.535612849576166

Epoch: 5| Step: 10
Training loss: 0.4320590377618131
Validation loss: 2.514057393276203

Epoch: 450| Step: 0
Training loss: 0.25934299708182523
Validation loss: 2.5138454610457326

Epoch: 5| Step: 1
Training loss: 0.2934990724227259
Validation loss: 2.5715866603661963

Epoch: 5| Step: 2
Training loss: 0.35985297055011517
Validation loss: 2.56437459818467

Epoch: 5| Step: 3
Training loss: 0.20995602269297625
Validation loss: 2.5406034401915223

Epoch: 5| Step: 4
Training loss: 0.24182420061603016
Validation loss: 2.523856299424894

Epoch: 5| Step: 5
Training loss: 0.18251194700890547
Validation loss: 2.531092572124323

Epoch: 5| Step: 6
Training loss: 0.3228886217839246
Validation loss: 2.539552668483137

Epoch: 5| Step: 7
Training loss: 0.23359707635405758
Validation loss: 2.552344111030886

Epoch: 5| Step: 8
Training loss: 0.3437077973208574
Validation loss: 2.530856034117981

Epoch: 5| Step: 9
Training loss: 0.3553315201686836
Validation loss: 2.550388261623955

Epoch: 5| Step: 10
Training loss: 0.23220294771366734
Validation loss: 2.5360351476979104

Epoch: 451| Step: 0
Training loss: 0.33198690679308945
Validation loss: 2.5515573098020545

Epoch: 5| Step: 1
Training loss: 0.2514453176676495
Validation loss: 2.5799537156660897

Epoch: 5| Step: 2
Training loss: 0.27082402720724297
Validation loss: 2.5299015117014525

Epoch: 5| Step: 3
Training loss: 0.28032646607954825
Validation loss: 2.5809486972692532

Epoch: 5| Step: 4
Training loss: 0.3519943657696429
Validation loss: 2.5633451147174235

Epoch: 5| Step: 5
Training loss: 0.3067818334752083
Validation loss: 2.5654247449444276

Epoch: 5| Step: 6
Training loss: 0.24612828421108854
Validation loss: 2.5875922203027377

Epoch: 5| Step: 7
Training loss: 0.18527625577014897
Validation loss: 2.548688144381555

Epoch: 5| Step: 8
Training loss: 0.206032467046262
Validation loss: 2.5599062118058673

Epoch: 5| Step: 9
Training loss: 0.4070078493446272
Validation loss: 2.581447697276439

Epoch: 5| Step: 10
Training loss: 0.23251750325132034
Validation loss: 2.561971446344915

Epoch: 452| Step: 0
Training loss: 0.3267701310265853
Validation loss: 2.5770475321834807

Epoch: 5| Step: 1
Training loss: 0.19201071330631714
Validation loss: 2.5763613896354904

Epoch: 5| Step: 2
Training loss: 0.2861410016134626
Validation loss: 2.540059304775983

Epoch: 5| Step: 3
Training loss: 0.39629511708710186
Validation loss: 2.577334556086614

Epoch: 5| Step: 4
Training loss: 0.28170022426463587
Validation loss: 2.5578622054776976

Epoch: 5| Step: 5
Training loss: 0.2894302039910351
Validation loss: 2.5483373654574004

Epoch: 5| Step: 6
Training loss: 0.1938833400831197
Validation loss: 2.5834462031682968

Epoch: 5| Step: 7
Training loss: 0.28206668271903057
Validation loss: 2.5632705230337915

Epoch: 5| Step: 8
Training loss: 0.4124255481635164
Validation loss: 2.5925526074661076

Epoch: 5| Step: 9
Training loss: 0.23573800962676117
Validation loss: 2.561079284218349

Epoch: 5| Step: 10
Training loss: 0.1650688550795299
Validation loss: 2.5514576014028623

Epoch: 453| Step: 0
Training loss: 0.40295345441551905
Validation loss: 2.56359725938338

Epoch: 5| Step: 1
Training loss: 0.32081895425495754
Validation loss: 2.5937302815132193

Epoch: 5| Step: 2
Training loss: 0.19581107400301262
Validation loss: 2.5800194356312987

Epoch: 5| Step: 3
Training loss: 0.3469220241255436
Validation loss: 2.5653424873701134

Epoch: 5| Step: 4
Training loss: 0.22455589652922975
Validation loss: 2.5679628561835712

Epoch: 5| Step: 5
Training loss: 0.152928465135544
Validation loss: 2.5653705890610157

Epoch: 5| Step: 6
Training loss: 0.3057023898826786
Validation loss: 2.6148488821317564

Epoch: 5| Step: 7
Training loss: 0.14657762738143273
Validation loss: 2.5856595206115065

Epoch: 5| Step: 8
Training loss: 0.23228311804506918
Validation loss: 2.5943236622857393

Epoch: 5| Step: 9
Training loss: 0.26386927526905973
Validation loss: 2.57968514408554

Epoch: 5| Step: 10
Training loss: 0.36145837858934515
Validation loss: 2.575740499298923

Epoch: 454| Step: 0
Training loss: 0.23187639032959867
Validation loss: 2.5765034433310907

Epoch: 5| Step: 1
Training loss: 0.25194499276218474
Validation loss: 2.550284500646597

Epoch: 5| Step: 2
Training loss: 0.3503405527764006
Validation loss: 2.5508054568086167

Epoch: 5| Step: 3
Training loss: 0.33594507386297195
Validation loss: 2.5520542157345147

Epoch: 5| Step: 4
Training loss: 0.2841132174749553
Validation loss: 2.557852957616396

Epoch: 5| Step: 5
Training loss: 0.461814950386926
Validation loss: 2.575533913020565

Epoch: 5| Step: 6
Training loss: 0.2584983776583942
Validation loss: 2.5484863695850803

Epoch: 5| Step: 7
Training loss: 0.26260845350806417
Validation loss: 2.5471716352665714

Epoch: 5| Step: 8
Training loss: 0.21461907690147686
Validation loss: 2.533431242233859

Epoch: 5| Step: 9
Training loss: 0.21162356844776672
Validation loss: 2.5857442812089486

Epoch: 5| Step: 10
Training loss: 0.15148116711844314
Validation loss: 2.539079623105452

Epoch: 455| Step: 0
Training loss: 0.3632352656311965
Validation loss: 2.525284850644208

Epoch: 5| Step: 1
Training loss: 0.16756200890751907
Validation loss: 2.5574625013877

Epoch: 5| Step: 2
Training loss: 0.21088172917067807
Validation loss: 2.558245556135773

Epoch: 5| Step: 3
Training loss: 0.22612527884491976
Validation loss: 2.522575338569084

Epoch: 5| Step: 4
Training loss: 0.35057774483716686
Validation loss: 2.511481711252113

Epoch: 5| Step: 5
Training loss: 0.1775522766399441
Validation loss: 2.5471706735885062

Epoch: 5| Step: 6
Training loss: 0.2405532488422959
Validation loss: 2.577110242464806

Epoch: 5| Step: 7
Training loss: 0.30823566086143583
Validation loss: 2.524113467435988

Epoch: 5| Step: 8
Training loss: 0.25762954635995217
Validation loss: 2.5625991541989808

Epoch: 5| Step: 9
Training loss: 0.3077257237376833
Validation loss: 2.551480622702224

Epoch: 5| Step: 10
Training loss: 0.3428898366457085
Validation loss: 2.5288727055315285

Epoch: 456| Step: 0
Training loss: 0.25274713475181426
Validation loss: 2.5527438221728316

Epoch: 5| Step: 1
Training loss: 0.27694828421985285
Validation loss: 2.517917018712511

Epoch: 5| Step: 2
Training loss: 0.2781669461840495
Validation loss: 2.5113319325319763

Epoch: 5| Step: 3
Training loss: 0.30907349778097015
Validation loss: 2.5285625007870247

Epoch: 5| Step: 4
Training loss: 0.268320737719841
Validation loss: 2.5439609767940228

Epoch: 5| Step: 5
Training loss: 0.3056575299134702
Validation loss: 2.5522064979538923

Epoch: 5| Step: 6
Training loss: 0.3332220602077705
Validation loss: 2.560186080210335

Epoch: 5| Step: 7
Training loss: 0.33685369641845303
Validation loss: 2.5688024152400084

Epoch: 5| Step: 8
Training loss: 0.15857098044819395
Validation loss: 2.552413210582558

Epoch: 5| Step: 9
Training loss: 0.29821694897456896
Validation loss: 2.547295165356018

Epoch: 5| Step: 10
Training loss: 0.20436580107923816
Validation loss: 2.543684339274272

Epoch: 457| Step: 0
Training loss: 0.32252079658211574
Validation loss: 2.5584612983287536

Epoch: 5| Step: 1
Training loss: 0.28034889720613443
Validation loss: 2.568922458228116

Epoch: 5| Step: 2
Training loss: 0.2020230849077212
Validation loss: 2.5664503610342257

Epoch: 5| Step: 3
Training loss: 0.3284979358496475
Validation loss: 2.561336128967417

Epoch: 5| Step: 4
Training loss: 0.31114673858722036
Validation loss: 2.5630641009221935

Epoch: 5| Step: 5
Training loss: 0.3099848862393875
Validation loss: 2.5198619526607406

Epoch: 5| Step: 6
Training loss: 0.18528602735871846
Validation loss: 2.5524265660377816

Epoch: 5| Step: 7
Training loss: 0.34824715448710836
Validation loss: 2.5413613992584074

Epoch: 5| Step: 8
Training loss: 0.19170777257567703
Validation loss: 2.525630967692997

Epoch: 5| Step: 9
Training loss: 0.14831291165196278
Validation loss: 2.526291480660424

Epoch: 5| Step: 10
Training loss: 0.24637289715319
Validation loss: 2.534848099648683

Epoch: 458| Step: 0
Training loss: 0.17673916481244906
Validation loss: 2.5259979890413895

Epoch: 5| Step: 1
Training loss: 0.18004670727573094
Validation loss: 2.5369950684871725

Epoch: 5| Step: 2
Training loss: 0.3565550961674422
Validation loss: 2.512008457122313

Epoch: 5| Step: 3
Training loss: 0.24686963522188424
Validation loss: 2.5255270427494487

Epoch: 5| Step: 4
Training loss: 0.2945893920862602
Validation loss: 2.5515676902074826

Epoch: 5| Step: 5
Training loss: 0.3048136278889923
Validation loss: 2.5358587491554694

Epoch: 5| Step: 6
Training loss: 0.2932140976041652
Validation loss: 2.539700830330433

Epoch: 5| Step: 7
Training loss: 0.38476411460928567
Validation loss: 2.5446273858342825

Epoch: 5| Step: 8
Training loss: 0.25825782808144016
Validation loss: 2.5495038939736

Epoch: 5| Step: 9
Training loss: 0.36521177170928903
Validation loss: 2.5278990580961938

Epoch: 5| Step: 10
Training loss: 0.4061611885415683
Validation loss: 2.5524946233357646

Epoch: 459| Step: 0
Training loss: 0.31722010036237835
Validation loss: 2.5087884452942104

Epoch: 5| Step: 1
Training loss: 0.21161516266641098
Validation loss: 2.4989406925578606

Epoch: 5| Step: 2
Training loss: 0.3353390019796714
Validation loss: 2.479088353317604

Epoch: 5| Step: 3
Training loss: 0.42271334743706407
Validation loss: 2.4895867761179753

Epoch: 5| Step: 4
Training loss: 0.4071689994983048
Validation loss: 2.494013258956957

Epoch: 5| Step: 5
Training loss: 0.23440816167833295
Validation loss: 2.538124566265451

Epoch: 5| Step: 6
Training loss: 0.33423932700995834
Validation loss: 2.5448919478079763

Epoch: 5| Step: 7
Training loss: 0.19222619124688506
Validation loss: 2.553120510621371

Epoch: 5| Step: 8
Training loss: 0.4513947733063529
Validation loss: 2.5944618595419446

Epoch: 5| Step: 9
Training loss: 0.27782776733773595
Validation loss: 2.5939494220775803

Epoch: 5| Step: 10
Training loss: 0.26374471152910983
Validation loss: 2.642289658976405

Epoch: 460| Step: 0
Training loss: 0.22680905508146196
Validation loss: 2.583607420603646

Epoch: 5| Step: 1
Training loss: 0.23095229710571896
Validation loss: 2.623288228840931

Epoch: 5| Step: 2
Training loss: 0.264797576885359
Validation loss: 2.5742485966726782

Epoch: 5| Step: 3
Training loss: 0.3627207749672496
Validation loss: 2.569387301377103

Epoch: 5| Step: 4
Training loss: 0.3233646034247516
Validation loss: 2.560121117849229

Epoch: 5| Step: 5
Training loss: 0.2902524529188337
Validation loss: 2.573929021109863

Epoch: 5| Step: 6
Training loss: 0.35879098043411956
Validation loss: 2.523709429997216

Epoch: 5| Step: 7
Training loss: 0.3770867145590468
Validation loss: 2.5645340360801954

Epoch: 5| Step: 8
Training loss: 0.2158508710673749
Validation loss: 2.587841687443052

Epoch: 5| Step: 9
Training loss: 0.48979253729360617
Validation loss: 2.5812575862397322

Epoch: 5| Step: 10
Training loss: 0.41751144918858485
Validation loss: 2.58790182305094

Epoch: 461| Step: 0
Training loss: 0.25973605224236734
Validation loss: 2.54791187222906

Epoch: 5| Step: 1
Training loss: 0.3403573594595132
Validation loss: 2.5449673224376257

Epoch: 5| Step: 2
Training loss: 0.42208630956496085
Validation loss: 2.5567434537111327

Epoch: 5| Step: 3
Training loss: 0.2822989664623679
Validation loss: 2.515086626009151

Epoch: 5| Step: 4
Training loss: 0.34072352130722133
Validation loss: 2.5016682585852688

Epoch: 5| Step: 5
Training loss: 0.1656129666221587
Validation loss: 2.4896561707259153

Epoch: 5| Step: 6
Training loss: 0.33114736379457943
Validation loss: 2.5100528080785316

Epoch: 5| Step: 7
Training loss: 0.38698547489916996
Validation loss: 2.479483183953508

Epoch: 5| Step: 8
Training loss: 0.3069117616904877
Validation loss: 2.4985974181799793

Epoch: 5| Step: 9
Training loss: 0.3485951977695031
Validation loss: 2.466291531398241

Epoch: 5| Step: 10
Training loss: 0.24482614024214333
Validation loss: 2.5187864865990353

Epoch: 462| Step: 0
Training loss: 0.3049737979038431
Validation loss: 2.519727669013873

Epoch: 5| Step: 1
Training loss: 0.3902693655461959
Validation loss: 2.542388739479932

Epoch: 5| Step: 2
Training loss: 0.2726954882787453
Validation loss: 2.563287562437141

Epoch: 5| Step: 3
Training loss: 0.2568243190907858
Validation loss: 2.575653884141706

Epoch: 5| Step: 4
Training loss: 0.42384580935662985
Validation loss: 2.5606050125001922

Epoch: 5| Step: 5
Training loss: 0.3993141217165234
Validation loss: 2.5725563534023626

Epoch: 5| Step: 6
Training loss: 0.33304276940116945
Validation loss: 2.5270358501608414

Epoch: 5| Step: 7
Training loss: 0.4358800289595812
Validation loss: 2.571630193565076

Epoch: 5| Step: 8
Training loss: 0.47869533356192473
Validation loss: 2.5306087295855724

Epoch: 5| Step: 9
Training loss: 0.28078120951792873
Validation loss: 2.5307533478791786

Epoch: 5| Step: 10
Training loss: 0.3882923669585996
Validation loss: 2.5414112671486846

Epoch: 463| Step: 0
Training loss: 0.3405859942369997
Validation loss: 2.5292317476961217

Epoch: 5| Step: 1
Training loss: 0.22612153911314423
Validation loss: 2.54968712029495

Epoch: 5| Step: 2
Training loss: 0.3062815781291772
Validation loss: 2.5630110234361942

Epoch: 5| Step: 3
Training loss: 0.29613731989709136
Validation loss: 2.562252495930996

Epoch: 5| Step: 4
Training loss: 0.43211921637926537
Validation loss: 2.5903880261464964

Epoch: 5| Step: 5
Training loss: 0.42647812186941747
Validation loss: 2.584624868362999

Epoch: 5| Step: 6
Training loss: 0.30076190341309866
Validation loss: 2.5937360764905777

Epoch: 5| Step: 7
Training loss: 0.21509012487422327
Validation loss: 2.5478399076933247

Epoch: 5| Step: 8
Training loss: 0.337253013058685
Validation loss: 2.5578697965767487

Epoch: 5| Step: 9
Training loss: 0.25867561876818956
Validation loss: 2.5647464387612056

Epoch: 5| Step: 10
Training loss: 0.26057973365678294
Validation loss: 2.5635002329056302

Epoch: 464| Step: 0
Training loss: 0.2512854964295153
Validation loss: 2.5477115282256286

Epoch: 5| Step: 1
Training loss: 0.251714785903983
Validation loss: 2.5614157673189184

Epoch: 5| Step: 2
Training loss: 0.41414601905187
Validation loss: 2.5427048343347143

Epoch: 5| Step: 3
Training loss: 0.3538545701312188
Validation loss: 2.5587306248032857

Epoch: 5| Step: 4
Training loss: 0.21612301480058313
Validation loss: 2.5356380337865545

Epoch: 5| Step: 5
Training loss: 0.2699076056676582
Validation loss: 2.559919056484374

Epoch: 5| Step: 6
Training loss: 0.22914649412206292
Validation loss: 2.5504761534616067

Epoch: 5| Step: 7
Training loss: 0.17378498999500594
Validation loss: 2.5382422821965744

Epoch: 5| Step: 8
Training loss: 0.34273523405796524
Validation loss: 2.5637258103354044

Epoch: 5| Step: 9
Training loss: 0.1424005329946692
Validation loss: 2.5704788352171466

Epoch: 5| Step: 10
Training loss: 0.324308382995845
Validation loss: 2.549390776210162

Epoch: 465| Step: 0
Training loss: 0.2997973935112883
Validation loss: 2.5794626543796464

Epoch: 5| Step: 1
Training loss: 0.3136232454791354
Validation loss: 2.558953904716697

Epoch: 5| Step: 2
Training loss: 0.13911559077300012
Validation loss: 2.5675999872885447

Epoch: 5| Step: 3
Training loss: 0.2886769842746137
Validation loss: 2.5435051612266637

Epoch: 5| Step: 4
Training loss: 0.3091913545182033
Validation loss: 2.5726143978806957

Epoch: 5| Step: 5
Training loss: 0.3192010763898904
Validation loss: 2.571723507554777

Epoch: 5| Step: 6
Training loss: 0.28981473062844343
Validation loss: 2.5671462998304593

Epoch: 5| Step: 7
Training loss: 0.15827839438337482
Validation loss: 2.5866155265582265

Epoch: 5| Step: 8
Training loss: 0.13379261262736075
Validation loss: 2.540605159642144

Epoch: 5| Step: 9
Training loss: 0.33373945301692776
Validation loss: 2.5998786468835187

Epoch: 5| Step: 10
Training loss: 0.13984989760115185
Validation loss: 2.5861814843738453

Epoch: 466| Step: 0
Training loss: 0.31750934132778863
Validation loss: 2.5609871354957976

Epoch: 5| Step: 1
Training loss: 0.19583530074172906
Validation loss: 2.5537353574690718

Epoch: 5| Step: 2
Training loss: 0.32528751658460225
Validation loss: 2.557157006972725

Epoch: 5| Step: 3
Training loss: 0.3653486960290568
Validation loss: 2.5478911942797704

Epoch: 5| Step: 4
Training loss: 0.28605058289171614
Validation loss: 2.5338940035478763

Epoch: 5| Step: 5
Training loss: 0.25499947753553537
Validation loss: 2.5298765085219506

Epoch: 5| Step: 6
Training loss: 0.20173818080994516
Validation loss: 2.498846925391924

Epoch: 5| Step: 7
Training loss: 0.1941396402376248
Validation loss: 2.5259744939487656

Epoch: 5| Step: 8
Training loss: 0.17159098763014807
Validation loss: 2.519468940154526

Epoch: 5| Step: 9
Training loss: 0.2999797148601607
Validation loss: 2.517249177493456

Epoch: 5| Step: 10
Training loss: 0.26753412706387447
Validation loss: 2.5446188066926942

Epoch: 467| Step: 0
Training loss: 0.20918488910095395
Validation loss: 2.558559544433358

Epoch: 5| Step: 1
Training loss: 0.22354465729406695
Validation loss: 2.559795041454979

Epoch: 5| Step: 2
Training loss: 0.21834897850822768
Validation loss: 2.5482164188818857

Epoch: 5| Step: 3
Training loss: 0.2434005047375642
Validation loss: 2.5942054345722947

Epoch: 5| Step: 4
Training loss: 0.3580724496549393
Validation loss: 2.5641554010692253

Epoch: 5| Step: 5
Training loss: 0.1614317923440322
Validation loss: 2.6021895163754145

Epoch: 5| Step: 6
Training loss: 0.3811120979862732
Validation loss: 2.571880771894289

Epoch: 5| Step: 7
Training loss: 0.2890293256951507
Validation loss: 2.570817232250231

Epoch: 5| Step: 8
Training loss: 0.1918376226706525
Validation loss: 2.560096969583327

Epoch: 5| Step: 9
Training loss: 0.2777643640908763
Validation loss: 2.559952787228627

Epoch: 5| Step: 10
Training loss: 0.2902630284824639
Validation loss: 2.551171519912941

Epoch: 468| Step: 0
Training loss: 0.2559911810643011
Validation loss: 2.5189653324967964

Epoch: 5| Step: 1
Training loss: 0.33271679509572905
Validation loss: 2.4870099946756974

Epoch: 5| Step: 2
Training loss: 0.1995449947740243
Validation loss: 2.5184502455851643

Epoch: 5| Step: 3
Training loss: 0.2622858848848561
Validation loss: 2.5128940766875254

Epoch: 5| Step: 4
Training loss: 0.26292840195918066
Validation loss: 2.502367988571919

Epoch: 5| Step: 5
Training loss: 0.2092028483044875
Validation loss: 2.541407737540971

Epoch: 5| Step: 6
Training loss: 0.22612211572780339
Validation loss: 2.538191640986714

Epoch: 5| Step: 7
Training loss: 0.26487349340362315
Validation loss: 2.5221153510602687

Epoch: 5| Step: 8
Training loss: 0.23462372933146816
Validation loss: 2.536629530151744

Epoch: 5| Step: 9
Training loss: 0.39431985536064773
Validation loss: 2.5350281403844037

Epoch: 5| Step: 10
Training loss: 0.3545598367503265
Validation loss: 2.5382054742709688

Epoch: 469| Step: 0
Training loss: 0.16191817118512952
Validation loss: 2.5567404847216872

Epoch: 5| Step: 1
Training loss: 0.217452389943297
Validation loss: 2.5483754354277357

Epoch: 5| Step: 2
Training loss: 0.3099534104123758
Validation loss: 2.5146304282732164

Epoch: 5| Step: 3
Training loss: 0.27087014510553015
Validation loss: 2.5172336311202583

Epoch: 5| Step: 4
Training loss: 0.30961490634825684
Validation loss: 2.4946779916302506

Epoch: 5| Step: 5
Training loss: 0.342637668250166
Validation loss: 2.4982336449247544

Epoch: 5| Step: 6
Training loss: 0.20006084112774414
Validation loss: 2.480133774546964

Epoch: 5| Step: 7
Training loss: 0.2781784499167623
Validation loss: 2.5209363619534515

Epoch: 5| Step: 8
Training loss: 0.1991428436329307
Validation loss: 2.5240077898819178

Epoch: 5| Step: 9
Training loss: 0.33473645130997337
Validation loss: 2.5378380808516257

Epoch: 5| Step: 10
Training loss: 0.2583298838036454
Validation loss: 2.553844023524998

Epoch: 470| Step: 0
Training loss: 0.31942505132622956
Validation loss: 2.550641318274548

Epoch: 5| Step: 1
Training loss: 0.3022569275425767
Validation loss: 2.5778088865264186

Epoch: 5| Step: 2
Training loss: 0.22035593389277505
Validation loss: 2.5727180629158872

Epoch: 5| Step: 3
Training loss: 0.3268036691030991
Validation loss: 2.5683368962766875

Epoch: 5| Step: 4
Training loss: 0.2897808453966268
Validation loss: 2.566333456494998

Epoch: 5| Step: 5
Training loss: 0.2745422118359034
Validation loss: 2.5404868367264357

Epoch: 5| Step: 6
Training loss: 0.21780786969094576
Validation loss: 2.5720119369439196

Epoch: 5| Step: 7
Training loss: 0.3444666760885824
Validation loss: 2.5177511194612165

Epoch: 5| Step: 8
Training loss: 0.23926620468680257
Validation loss: 2.54441610843874

Epoch: 5| Step: 9
Training loss: 0.22517273782299158
Validation loss: 2.5329834919393885

Epoch: 5| Step: 10
Training loss: 0.34269638499656635
Validation loss: 2.531159983089808

Epoch: 471| Step: 0
Training loss: 0.2893287360530012
Validation loss: 2.5374173052944218

Epoch: 5| Step: 1
Training loss: 0.20752760029981082
Validation loss: 2.5451437635460454

Epoch: 5| Step: 2
Training loss: 0.20642938038134312
Validation loss: 2.553503812881231

Epoch: 5| Step: 3
Training loss: 0.24369482919903535
Validation loss: 2.5460673529489974

Epoch: 5| Step: 4
Training loss: 0.45181875382703457
Validation loss: 2.575986110299371

Epoch: 5| Step: 5
Training loss: 0.20705449675554918
Validation loss: 2.6017081710669516

Epoch: 5| Step: 6
Training loss: 0.2803609359213879
Validation loss: 2.5641113290398323

Epoch: 5| Step: 7
Training loss: 0.30659059249998605
Validation loss: 2.5572897963674395

Epoch: 5| Step: 8
Training loss: 0.20773493638667545
Validation loss: 2.5387361873076193

Epoch: 5| Step: 9
Training loss: 0.18108782171859492
Validation loss: 2.5287021214052254

Epoch: 5| Step: 10
Training loss: 0.20149481879061812
Validation loss: 2.532562922082227

Epoch: 472| Step: 0
Training loss: 0.16567444805430648
Validation loss: 2.5068664836543304

Epoch: 5| Step: 1
Training loss: 0.2403502533726818
Validation loss: 2.4822410684886833

Epoch: 5| Step: 2
Training loss: 0.31621842637598263
Validation loss: 2.525515772672676

Epoch: 5| Step: 3
Training loss: 0.285910849032749
Validation loss: 2.497534112077856

Epoch: 5| Step: 4
Training loss: 0.2719781762047485
Validation loss: 2.497718394393186

Epoch: 5| Step: 5
Training loss: 0.3000245173687927
Validation loss: 2.500625146618352

Epoch: 5| Step: 6
Training loss: 0.20937204501216122
Validation loss: 2.514330263319802

Epoch: 5| Step: 7
Training loss: 0.18817579157224285
Validation loss: 2.5041374552982454

Epoch: 5| Step: 8
Training loss: 0.29046599437602844
Validation loss: 2.507421426811516

Epoch: 5| Step: 9
Training loss: 0.34772945019181317
Validation loss: 2.5399134550465035

Epoch: 5| Step: 10
Training loss: 0.15989592958089147
Validation loss: 2.5189207166094643

Epoch: 473| Step: 0
Training loss: 0.2642158830285255
Validation loss: 2.57795504857864

Epoch: 5| Step: 1
Training loss: 0.18906498505401492
Validation loss: 2.552587941860895

Epoch: 5| Step: 2
Training loss: 0.3513383998814673
Validation loss: 2.5531780259955887

Epoch: 5| Step: 3
Training loss: 0.2146935197799704
Validation loss: 2.5317547243174294

Epoch: 5| Step: 4
Training loss: 0.15787899108487274
Validation loss: 2.542234167459294

Epoch: 5| Step: 5
Training loss: 0.25426676171957724
Validation loss: 2.564101070402829

Epoch: 5| Step: 6
Training loss: 0.35811048368422754
Validation loss: 2.5851106807991475

Epoch: 5| Step: 7
Training loss: 0.288974194312538
Validation loss: 2.562601222038208

Epoch: 5| Step: 8
Training loss: 0.20441698952475845
Validation loss: 2.578472207791634

Epoch: 5| Step: 9
Training loss: 0.1513173544285046
Validation loss: 2.5541966889318974

Epoch: 5| Step: 10
Training loss: 0.30917564288233135
Validation loss: 2.5329385582082624

Epoch: 474| Step: 0
Training loss: 0.32072444338457706
Validation loss: 2.520475626778604

Epoch: 5| Step: 1
Training loss: 0.26434546720526714
Validation loss: 2.515988997133145

Epoch: 5| Step: 2
Training loss: 0.2539486042789876
Validation loss: 2.5294545869336456

Epoch: 5| Step: 3
Training loss: 0.2351137360450833
Validation loss: 2.551545443343866

Epoch: 5| Step: 4
Training loss: 0.2744258321498387
Validation loss: 2.531130051692144

Epoch: 5| Step: 5
Training loss: 0.24064749575401154
Validation loss: 2.527352337571337

Epoch: 5| Step: 6
Training loss: 0.2734156599859509
Validation loss: 2.522657842823643

Epoch: 5| Step: 7
Training loss: 0.19329296281645467
Validation loss: 2.528275764354976

Epoch: 5| Step: 8
Training loss: 0.31353583325169365
Validation loss: 2.5229541815167718

Epoch: 5| Step: 9
Training loss: 0.18468042147088864
Validation loss: 2.5479618393062706

Epoch: 5| Step: 10
Training loss: 0.12471340151224196
Validation loss: 2.521537196548299

Epoch: 475| Step: 0
Training loss: 0.38013463634255157
Validation loss: 2.5459549912681028

Epoch: 5| Step: 1
Training loss: 0.2176816430378637
Validation loss: 2.5364395140566507

Epoch: 5| Step: 2
Training loss: 0.29485988597048346
Validation loss: 2.519720438653807

Epoch: 5| Step: 3
Training loss: 0.22405956811729125
Validation loss: 2.526485207710397

Epoch: 5| Step: 4
Training loss: 0.1257006262417673
Validation loss: 2.5107650899698273

Epoch: 5| Step: 5
Training loss: 0.20309213225669356
Validation loss: 2.537438966776946

Epoch: 5| Step: 6
Training loss: 0.19525700734491847
Validation loss: 2.527046920199812

Epoch: 5| Step: 7
Training loss: 0.29518682692041337
Validation loss: 2.5200159411610605

Epoch: 5| Step: 8
Training loss: 0.2732153535090968
Validation loss: 2.5300163687191435

Epoch: 5| Step: 9
Training loss: 0.17587541601095227
Validation loss: 2.521809744700641

Epoch: 5| Step: 10
Training loss: 0.2562494144200403
Validation loss: 2.504753983544589

Epoch: 476| Step: 0
Training loss: 0.2383519833749314
Validation loss: 2.535297833208939

Epoch: 5| Step: 1
Training loss: 0.2691155420582441
Validation loss: 2.5183263048325144

Epoch: 5| Step: 2
Training loss: 0.18718910270730799
Validation loss: 2.5276663750330144

Epoch: 5| Step: 3
Training loss: 0.200889741404153
Validation loss: 2.5003752826688834

Epoch: 5| Step: 4
Training loss: 0.17076406373210717
Validation loss: 2.5380604624347147

Epoch: 5| Step: 5
Training loss: 0.3174084814402029
Validation loss: 2.5492488332985563

Epoch: 5| Step: 6
Training loss: 0.36447376466716147
Validation loss: 2.5214289296626204

Epoch: 5| Step: 7
Training loss: 0.17251784227188588
Validation loss: 2.525665981077796

Epoch: 5| Step: 8
Training loss: 0.19367824617826435
Validation loss: 2.5305211476164873

Epoch: 5| Step: 9
Training loss: 0.20892442752556117
Validation loss: 2.5357186106600396

Epoch: 5| Step: 10
Training loss: 0.24591318196880943
Validation loss: 2.5389842809046197

Epoch: 477| Step: 0
Training loss: 0.2945780866098134
Validation loss: 2.5335298148979906

Epoch: 5| Step: 1
Training loss: 0.21044505883019698
Validation loss: 2.566169492477703

Epoch: 5| Step: 2
Training loss: 0.36660584582924294
Validation loss: 2.5212100198498075

Epoch: 5| Step: 3
Training loss: 0.27313469059947315
Validation loss: 2.553589879751207

Epoch: 5| Step: 4
Training loss: 0.2831033728299254
Validation loss: 2.525188081003549

Epoch: 5| Step: 5
Training loss: 0.24614305607787715
Validation loss: 2.51554653621397

Epoch: 5| Step: 6
Training loss: 0.1787373153313944
Validation loss: 2.533449983002572

Epoch: 5| Step: 7
Training loss: 0.1960838915713862
Validation loss: 2.5315989318768644

Epoch: 5| Step: 8
Training loss: 0.18284300239930426
Validation loss: 2.5248863738851246

Epoch: 5| Step: 9
Training loss: 0.13232999697523373
Validation loss: 2.509305419455755

Epoch: 5| Step: 10
Training loss: 0.1572327997617181
Validation loss: 2.53397240708694

Epoch: 478| Step: 0
Training loss: 0.20723575711862594
Validation loss: 2.514578803826959

Epoch: 5| Step: 1
Training loss: 0.34096132875242663
Validation loss: 2.5368057295741377

Epoch: 5| Step: 2
Training loss: 0.17559264449229647
Validation loss: 2.549521366764663

Epoch: 5| Step: 3
Training loss: 0.16426703782092247
Validation loss: 2.521015566086052

Epoch: 5| Step: 4
Training loss: 0.15899467833215836
Validation loss: 2.5052225808668913

Epoch: 5| Step: 5
Training loss: 0.2637278320840636
Validation loss: 2.514366849781406

Epoch: 5| Step: 6
Training loss: 0.2373834408664971
Validation loss: 2.537260141861417

Epoch: 5| Step: 7
Training loss: 0.18625380715376963
Validation loss: 2.5187651573276133

Epoch: 5| Step: 8
Training loss: 0.20151484983380455
Validation loss: 2.5175585441031862

Epoch: 5| Step: 9
Training loss: 0.17362279766538416
Validation loss: 2.5095250306095225

Epoch: 5| Step: 10
Training loss: 0.3862979410412393
Validation loss: 2.533261882946104

Epoch: 479| Step: 0
Training loss: 0.31473065799142563
Validation loss: 2.539547976391955

Epoch: 5| Step: 1
Training loss: 0.1861972353106928
Validation loss: 2.5158487581062268

Epoch: 5| Step: 2
Training loss: 0.3502157057501086
Validation loss: 2.519911127943745

Epoch: 5| Step: 3
Training loss: 0.16791895749368965
Validation loss: 2.5203516015172363

Epoch: 5| Step: 4
Training loss: 0.28403534779387357
Validation loss: 2.5246959867552166

Epoch: 5| Step: 5
Training loss: 0.15412630842207276
Validation loss: 2.5477564227835745

Epoch: 5| Step: 6
Training loss: 0.22320582510036366
Validation loss: 2.5198610044685115

Epoch: 5| Step: 7
Training loss: 0.2805655416016578
Validation loss: 2.5424104775909018

Epoch: 5| Step: 8
Training loss: 0.15884509347320863
Validation loss: 2.514734750013679

Epoch: 5| Step: 9
Training loss: 0.1698914972095384
Validation loss: 2.5299303500703307

Epoch: 5| Step: 10
Training loss: 0.18447868656381017
Validation loss: 2.535673731463112

Epoch: 480| Step: 0
Training loss: 0.08111226093836355
Validation loss: 2.5480551432395764

Epoch: 5| Step: 1
Training loss: 0.25871677468701515
Validation loss: 2.5386439541508574

Epoch: 5| Step: 2
Training loss: 0.34247781770461666
Validation loss: 2.553039828264613

Epoch: 5| Step: 3
Training loss: 0.2216034728797834
Validation loss: 2.5480305561459815

Epoch: 5| Step: 4
Training loss: 0.13600931024764806
Validation loss: 2.5385362396215214

Epoch: 5| Step: 5
Training loss: 0.2275202010691166
Validation loss: 2.5184889851717247

Epoch: 5| Step: 6
Training loss: 0.16351919814578647
Validation loss: 2.5382414206610746

Epoch: 5| Step: 7
Training loss: 0.27044316149278613
Validation loss: 2.4922041520680973

Epoch: 5| Step: 8
Training loss: 0.3270127655652312
Validation loss: 2.5444671040936986

Epoch: 5| Step: 9
Training loss: 0.182917974481129
Validation loss: 2.543798025225675

Epoch: 5| Step: 10
Training loss: 0.2931348202815229
Validation loss: 2.531136262445748

Epoch: 481| Step: 0
Training loss: 0.20964024915318186
Validation loss: 2.5485032784816712

Epoch: 5| Step: 1
Training loss: 0.15859321490794145
Validation loss: 2.519475760154499

Epoch: 5| Step: 2
Training loss: 0.18772579544979406
Validation loss: 2.5442048724450683

Epoch: 5| Step: 3
Training loss: 0.20950596328956533
Validation loss: 2.536935512794767

Epoch: 5| Step: 4
Training loss: 0.2390451537178195
Validation loss: 2.527871735019722

Epoch: 5| Step: 5
Training loss: 0.2601213385953503
Validation loss: 2.578711472395573

Epoch: 5| Step: 6
Training loss: 0.258827552092402
Validation loss: 2.549548833892921

Epoch: 5| Step: 7
Training loss: 0.28313697831707585
Validation loss: 2.5643758663212926

Epoch: 5| Step: 8
Training loss: 0.29100704820526374
Validation loss: 2.5728480623134615

Epoch: 5| Step: 9
Training loss: 0.20026904353363817
Validation loss: 2.5329500204541233

Epoch: 5| Step: 10
Training loss: 0.29463248549409254
Validation loss: 2.5549950476170324

Epoch: 482| Step: 0
Training loss: 0.35805064276573767
Validation loss: 2.552527039567779

Epoch: 5| Step: 1
Training loss: 0.3164125018031991
Validation loss: 2.510996736760587

Epoch: 5| Step: 2
Training loss: 0.2724042990823501
Validation loss: 2.548538345801486

Epoch: 5| Step: 3
Training loss: 0.1197466912703445
Validation loss: 2.5433152112752118

Epoch: 5| Step: 4
Training loss: 0.1570742325292426
Validation loss: 2.511854902914544

Epoch: 5| Step: 5
Training loss: 0.23331940881160387
Validation loss: 2.526946920846671

Epoch: 5| Step: 6
Training loss: 0.22264726520279102
Validation loss: 2.538664749329118

Epoch: 5| Step: 7
Training loss: 0.21855171617494337
Validation loss: 2.5286574208146044

Epoch: 5| Step: 8
Training loss: 0.23201907540180283
Validation loss: 2.5128175221689375

Epoch: 5| Step: 9
Training loss: 0.27478436772445325
Validation loss: 2.5430838565763745

Epoch: 5| Step: 10
Training loss: 0.2067387782231891
Validation loss: 2.530465364349593

Epoch: 483| Step: 0
Training loss: 0.13644079154470043
Validation loss: 2.5206221727919766

Epoch: 5| Step: 1
Training loss: 0.17333451383751125
Validation loss: 2.478733528156157

Epoch: 5| Step: 2
Training loss: 0.2553209799031816
Validation loss: 2.506796156736192

Epoch: 5| Step: 3
Training loss: 0.18021280792134875
Validation loss: 2.5043109620926525

Epoch: 5| Step: 4
Training loss: 0.27162719647291433
Validation loss: 2.522957800448753

Epoch: 5| Step: 5
Training loss: 0.31079709271095446
Validation loss: 2.527002593086026

Epoch: 5| Step: 6
Training loss: 0.31027091858893247
Validation loss: 2.512571724549649

Epoch: 5| Step: 7
Training loss: 0.25738010849127907
Validation loss: 2.5266041457474477

Epoch: 5| Step: 8
Training loss: 0.19185987552714537
Validation loss: 2.4857294754415427

Epoch: 5| Step: 9
Training loss: 0.2914104855104323
Validation loss: 2.4975393840156217

Epoch: 5| Step: 10
Training loss: 0.21582324686256374
Validation loss: 2.457556779353007

Epoch: 484| Step: 0
Training loss: 0.36445972072770016
Validation loss: 2.497959565599575

Epoch: 5| Step: 1
Training loss: 0.17847247447364223
Validation loss: 2.4895577680198726

Epoch: 5| Step: 2
Training loss: 0.18265518772282988
Validation loss: 2.500466113578942

Epoch: 5| Step: 3
Training loss: 0.251789601807116
Validation loss: 2.5072617624900637

Epoch: 5| Step: 4
Training loss: 0.25962929267254775
Validation loss: 2.512517304907532

Epoch: 5| Step: 5
Training loss: 0.31355380951485345
Validation loss: 2.5014045543465224

Epoch: 5| Step: 6
Training loss: 0.25550832762649506
Validation loss: 2.5022350247024994

Epoch: 5| Step: 7
Training loss: 0.23265194925415594
Validation loss: 2.519026708328498

Epoch: 5| Step: 8
Training loss: 0.23074483498933238
Validation loss: 2.517802041466297

Epoch: 5| Step: 9
Training loss: 0.1985088490452289
Validation loss: 2.5221488026840313

Epoch: 5| Step: 10
Training loss: 0.1748317239407797
Validation loss: 2.5071448814093804

Epoch: 485| Step: 0
Training loss: 0.2139432066541626
Validation loss: 2.513222386466677

Epoch: 5| Step: 1
Training loss: 0.27210967688991416
Validation loss: 2.528093800748402

Epoch: 5| Step: 2
Training loss: 0.32439032002104834
Validation loss: 2.516892922983945

Epoch: 5| Step: 3
Training loss: 0.2266740195633799
Validation loss: 2.506832808158696

Epoch: 5| Step: 4
Training loss: 0.14076916272289575
Validation loss: 2.548278995361328

Epoch: 5| Step: 5
Training loss: 0.27299321729317716
Validation loss: 2.526209674538584

Epoch: 5| Step: 6
Training loss: 0.2617891843161911
Validation loss: 2.540987702421577

Epoch: 5| Step: 7
Training loss: 0.16114140111979885
Validation loss: 2.5186002503955396

Epoch: 5| Step: 8
Training loss: 0.2983837438771643
Validation loss: 2.505684012551546

Epoch: 5| Step: 9
Training loss: 0.1230242799267493
Validation loss: 2.531965902196454

Epoch: 5| Step: 10
Training loss: 0.1766097149130601
Validation loss: 2.510352531175167

Epoch: 486| Step: 0
Training loss: 0.2385008378603951
Validation loss: 2.5199183979420203

Epoch: 5| Step: 1
Training loss: 0.1813799310167707
Validation loss: 2.5102527591110615

Epoch: 5| Step: 2
Training loss: 0.2758434171552542
Validation loss: 2.4907933824493016

Epoch: 5| Step: 3
Training loss: 0.26801323146148254
Validation loss: 2.524605695537789

Epoch: 5| Step: 4
Training loss: 0.28897660499969907
Validation loss: 2.515228051635423

Epoch: 5| Step: 5
Training loss: 0.1971143954889197
Validation loss: 2.560160547677609

Epoch: 5| Step: 6
Training loss: 0.24241531332456068
Validation loss: 2.556169796168411

Epoch: 5| Step: 7
Training loss: 0.2066591085088878
Validation loss: 2.5049015785430164

Epoch: 5| Step: 8
Training loss: 0.30555584244040307
Validation loss: 2.543583347126001

Epoch: 5| Step: 9
Training loss: 0.2122526233076268
Validation loss: 2.5502181244786843

Epoch: 5| Step: 10
Training loss: 0.2040069671152886
Validation loss: 2.5646852219356373

Epoch: 487| Step: 0
Training loss: 0.26189145041079015
Validation loss: 2.5444727886019733

Epoch: 5| Step: 1
Training loss: 0.1689945325651256
Validation loss: 2.5596091393518385

Epoch: 5| Step: 2
Training loss: 0.22440532869851879
Validation loss: 2.5841923630760855

Epoch: 5| Step: 3
Training loss: 0.24238543728030465
Validation loss: 2.592904953598675

Epoch: 5| Step: 4
Training loss: 0.32542272869614836
Validation loss: 2.581992993155076

Epoch: 5| Step: 5
Training loss: 0.2515470796206667
Validation loss: 2.5360834594677018

Epoch: 5| Step: 6
Training loss: 0.15023597593441398
Validation loss: 2.532427723574404

Epoch: 5| Step: 7
Training loss: 0.37068880976058194
Validation loss: 2.5639045631646153

Epoch: 5| Step: 8
Training loss: 0.1992709147653714
Validation loss: 2.5239377298245005

Epoch: 5| Step: 9
Training loss: 0.22461582672141078
Validation loss: 2.5442434939559266

Epoch: 5| Step: 10
Training loss: 0.22296754090877516
Validation loss: 2.553920711430629

Epoch: 488| Step: 0
Training loss: 0.2991451501591222
Validation loss: 2.5438960032041664

Epoch: 5| Step: 1
Training loss: 0.20312304679224963
Validation loss: 2.5283205416571817

Epoch: 5| Step: 2
Training loss: 0.16571604120363065
Validation loss: 2.5469742350544

Epoch: 5| Step: 3
Training loss: 0.27478672665678633
Validation loss: 2.5399137447275626

Epoch: 5| Step: 4
Training loss: 0.2693579434484531
Validation loss: 2.5434729470057222

Epoch: 5| Step: 5
Training loss: 0.17559337112255535
Validation loss: 2.529956529175674

Epoch: 5| Step: 6
Training loss: 0.31289190513548987
Validation loss: 2.540106950597414

Epoch: 5| Step: 7
Training loss: 0.2464555019147228
Validation loss: 2.5058096190808383

Epoch: 5| Step: 8
Training loss: 0.20375940399174397
Validation loss: 2.536405725829109

Epoch: 5| Step: 9
Training loss: 0.17885060923538976
Validation loss: 2.4993380028999193

Epoch: 5| Step: 10
Training loss: 0.17830989218074111
Validation loss: 2.53438823258446

Epoch: 489| Step: 0
Training loss: 0.2734455379939526
Validation loss: 2.5362525161233127

Epoch: 5| Step: 1
Training loss: 0.3363427888905595
Validation loss: 2.5273396469037004

Epoch: 5| Step: 2
Training loss: 0.2161080698935501
Validation loss: 2.5312405343880777

Epoch: 5| Step: 3
Training loss: 0.16261458094036077
Validation loss: 2.5352416989921776

Epoch: 5| Step: 4
Training loss: 0.17829456707549918
Validation loss: 2.5439057381623265

Epoch: 5| Step: 5
Training loss: 0.16199589399665015
Validation loss: 2.5583487058851535

Epoch: 5| Step: 6
Training loss: 0.24255839527139514
Validation loss: 2.5477553762993876

Epoch: 5| Step: 7
Training loss: 0.2743845750706431
Validation loss: 2.577806599166751

Epoch: 5| Step: 8
Training loss: 0.23191174856004648
Validation loss: 2.533988480043967

Epoch: 5| Step: 9
Training loss: 0.33151815824416836
Validation loss: 2.519813712419721

Epoch: 5| Step: 10
Training loss: 0.2176319654956076
Validation loss: 2.5545479006691583

Epoch: 490| Step: 0
Training loss: 0.2782202155828625
Validation loss: 2.544829442173167

Epoch: 5| Step: 1
Training loss: 0.23466322977818913
Validation loss: 2.5501723212565515

Epoch: 5| Step: 2
Training loss: 0.2659212171767322
Validation loss: 2.5003247890945577

Epoch: 5| Step: 3
Training loss: 0.2753569670325512
Validation loss: 2.5199960897792644

Epoch: 5| Step: 4
Training loss: 0.25085259132871657
Validation loss: 2.4896023664151543

Epoch: 5| Step: 5
Training loss: 0.1873642012447189
Validation loss: 2.528775889693211

Epoch: 5| Step: 6
Training loss: 0.1759812912215675
Validation loss: 2.4967039769013506

Epoch: 5| Step: 7
Training loss: 0.2584306069761379
Validation loss: 2.5493267867294565

Epoch: 5| Step: 8
Training loss: 0.1976353796393225
Validation loss: 2.5268270706135327

Epoch: 5| Step: 9
Training loss: 0.23637673374631551
Validation loss: 2.5289717427550285

Epoch: 5| Step: 10
Training loss: 0.190775454665132
Validation loss: 2.5758508187398865

Epoch: 491| Step: 0
Training loss: 0.24072748454051088
Validation loss: 2.5256445520649007

Epoch: 5| Step: 1
Training loss: 0.21198979795510456
Validation loss: 2.547563152000429

Epoch: 5| Step: 2
Training loss: 0.13794951950746903
Validation loss: 2.5798876452372013

Epoch: 5| Step: 3
Training loss: 0.2241837324650611
Validation loss: 2.5680715156841774

Epoch: 5| Step: 4
Training loss: 0.28506983139924585
Validation loss: 2.575332711541862

Epoch: 5| Step: 5
Training loss: 0.17181883783019405
Validation loss: 2.545828222601925

Epoch: 5| Step: 6
Training loss: 0.25995815284206286
Validation loss: 2.560314269743282

Epoch: 5| Step: 7
Training loss: 0.12826423000098028
Validation loss: 2.617184396814482

Epoch: 5| Step: 8
Training loss: 0.24239901566120658
Validation loss: 2.576126006796382

Epoch: 5| Step: 9
Training loss: 0.2841447631769543
Validation loss: 2.563815013819747

Epoch: 5| Step: 10
Training loss: 0.3249462422513593
Validation loss: 2.568243494674981

Epoch: 492| Step: 0
Training loss: 0.1535276905686099
Validation loss: 2.5607122882816373

Epoch: 5| Step: 1
Training loss: 0.273130503387349
Validation loss: 2.5614244218151576

Epoch: 5| Step: 2
Training loss: 0.30903281592906723
Validation loss: 2.5817111929924765

Epoch: 5| Step: 3
Training loss: 0.15188513708231693
Validation loss: 2.559204567712909

Epoch: 5| Step: 4
Training loss: 0.23437637487644022
Validation loss: 2.5549205412701324

Epoch: 5| Step: 5
Training loss: 0.23019150852987677
Validation loss: 2.563872581257673

Epoch: 5| Step: 6
Training loss: 0.18734726049078737
Validation loss: 2.563697943109809

Epoch: 5| Step: 7
Training loss: 0.2389575553378073
Validation loss: 2.5305883468781585

Epoch: 5| Step: 8
Training loss: 0.2624929279555488
Validation loss: 2.524248502399087

Epoch: 5| Step: 9
Training loss: 0.27309243363773494
Validation loss: 2.5230013877726285

Epoch: 5| Step: 10
Training loss: 0.22975461848518083
Validation loss: 2.5425035748626166

Epoch: 493| Step: 0
Training loss: 0.3391939506093107
Validation loss: 2.524268227919632

Epoch: 5| Step: 1
Training loss: 0.12890723256979336
Validation loss: 2.4944080344949167

Epoch: 5| Step: 2
Training loss: 0.22636761998554086
Validation loss: 2.477723833498097

Epoch: 5| Step: 3
Training loss: 0.30469481141536847
Validation loss: 2.50537291463668

Epoch: 5| Step: 4
Training loss: 0.1434263447140788
Validation loss: 2.5040104457058505

Epoch: 5| Step: 5
Training loss: 0.22759288756984827
Validation loss: 2.514500326766188

Epoch: 5| Step: 6
Training loss: 0.2127762671083423
Validation loss: 2.5256029095368437

Epoch: 5| Step: 7
Training loss: 0.22460048492087162
Validation loss: 2.528375849048134

Epoch: 5| Step: 8
Training loss: 0.22402494940542733
Validation loss: 2.533712358434166

Epoch: 5| Step: 9
Training loss: 0.26771252451979066
Validation loss: 2.5479313858773285

Epoch: 5| Step: 10
Training loss: 0.2389587869254621
Validation loss: 2.5196265540063854

Epoch: 494| Step: 0
Training loss: 0.18119604812240506
Validation loss: 2.5219017787673055

Epoch: 5| Step: 1
Training loss: 0.29037870563781515
Validation loss: 2.5453735934853077

Epoch: 5| Step: 2
Training loss: 0.3315897980147934
Validation loss: 2.518380081818288

Epoch: 5| Step: 3
Training loss: 0.26096201855713336
Validation loss: 2.558325002596667

Epoch: 5| Step: 4
Training loss: 0.16051057836842278
Validation loss: 2.5183614172308517

Epoch: 5| Step: 5
Training loss: 0.14689668485170787
Validation loss: 2.550727571181634

Epoch: 5| Step: 6
Training loss: 0.2231731521648956
Validation loss: 2.5597545153433887

Epoch: 5| Step: 7
Training loss: 0.18217412474202008
Validation loss: 2.5718312510873766

Epoch: 5| Step: 8
Training loss: 0.25533114935980084
Validation loss: 2.54616555975748

Epoch: 5| Step: 9
Training loss: 0.20012976340892
Validation loss: 2.5273835060715575

Epoch: 5| Step: 10
Training loss: 0.2800356823460064
Validation loss: 2.5208270853308066

Epoch: 495| Step: 0
Training loss: 0.20961727138834801
Validation loss: 2.558959783457202

Epoch: 5| Step: 1
Training loss: 0.2568890186763316
Validation loss: 2.557266999792731

Epoch: 5| Step: 2
Training loss: 0.14656894785559557
Validation loss: 2.5107184914434013

Epoch: 5| Step: 3
Training loss: 0.2228338135881986
Validation loss: 2.5246273176732337

Epoch: 5| Step: 4
Training loss: 0.2871976184826589
Validation loss: 2.5168220659340084

Epoch: 5| Step: 5
Training loss: 0.12080329238637645
Validation loss: 2.519828621251493

Epoch: 5| Step: 6
Training loss: 0.18735869367938646
Validation loss: 2.5139904792216328

Epoch: 5| Step: 7
Training loss: 0.254272768603728
Validation loss: 2.5220458198664435

Epoch: 5| Step: 8
Training loss: 0.16287432435803867
Validation loss: 2.5137470674989486

Epoch: 5| Step: 9
Training loss: 0.11519694124391731
Validation loss: 2.52192373209739

Epoch: 5| Step: 10
Training loss: 0.32387301383519224
Validation loss: 2.520083023299787

Epoch: 496| Step: 0
Training loss: 0.29731805266382955
Validation loss: 2.5372826877651806

Epoch: 5| Step: 1
Training loss: 0.1521961463003453
Validation loss: 2.54729067572674

Epoch: 5| Step: 2
Training loss: 0.167893342900987
Validation loss: 2.5320989394695204

Epoch: 5| Step: 3
Training loss: 0.20418831473690943
Validation loss: 2.523248514352208

Epoch: 5| Step: 4
Training loss: 0.19037907245635854
Validation loss: 2.547608909050483

Epoch: 5| Step: 5
Training loss: 0.23465330766272635
Validation loss: 2.562250502851024

Epoch: 5| Step: 6
Training loss: 0.22415956985544508
Validation loss: 2.517290095618379

Epoch: 5| Step: 7
Training loss: 0.33095688627121117
Validation loss: 2.5126121791039524

Epoch: 5| Step: 8
Training loss: 0.1951085933591134
Validation loss: 2.4973312264011827

Epoch: 5| Step: 9
Training loss: 0.3069107663741202
Validation loss: 2.5413820002075185

Epoch: 5| Step: 10
Training loss: 0.12752211780936765
Validation loss: 2.5084675594718475

Epoch: 497| Step: 0
Training loss: 0.1256017061007168
Validation loss: 2.5055280315188355

Epoch: 5| Step: 1
Training loss: 0.21063179363138584
Validation loss: 2.537522279924554

Epoch: 5| Step: 2
Training loss: 0.1568819736169347
Validation loss: 2.527821631466055

Epoch: 5| Step: 3
Training loss: 0.32728283527040963
Validation loss: 2.5127797766008175

Epoch: 5| Step: 4
Training loss: 0.25763677619457437
Validation loss: 2.5231175007854576

Epoch: 5| Step: 5
Training loss: 0.20483907663701495
Validation loss: 2.5163967115998114

Epoch: 5| Step: 6
Training loss: 0.2852330822838291
Validation loss: 2.5265195847136486

Epoch: 5| Step: 7
Training loss: 0.17498914480601938
Validation loss: 2.5390727038056187

Epoch: 5| Step: 8
Training loss: 0.253493619295848
Validation loss: 2.544247691713768

Epoch: 5| Step: 9
Training loss: 0.11443692213076116
Validation loss: 2.5482293574444643

Epoch: 5| Step: 10
Training loss: 0.2794295842656361
Validation loss: 2.4968325001724025

Epoch: 498| Step: 0
Training loss: 0.15459898453543364
Validation loss: 2.536020054124672

Epoch: 5| Step: 1
Training loss: 0.19097852600174406
Validation loss: 2.5505945929209526

Epoch: 5| Step: 2
Training loss: 0.1446347381631745
Validation loss: 2.548143171892911

Epoch: 5| Step: 3
Training loss: 0.17601462343170568
Validation loss: 2.508364673152031

Epoch: 5| Step: 4
Training loss: 0.26705455372543113
Validation loss: 2.5168984619809796

Epoch: 5| Step: 5
Training loss: 0.33001955630052926
Validation loss: 2.495704864897392

Epoch: 5| Step: 6
Training loss: 0.1401632662625546
Validation loss: 2.532563798708978

Epoch: 5| Step: 7
Training loss: 0.19334069556744102
Validation loss: 2.51673786380716

Epoch: 5| Step: 8
Training loss: 0.15371566265943068
Validation loss: 2.4767518267950384

Epoch: 5| Step: 9
Training loss: 0.36092298321615934
Validation loss: 2.522530514164138

Epoch: 5| Step: 10
Training loss: 0.17349010455903457
Validation loss: 2.5120621754563093

Epoch: 499| Step: 0
Training loss: 0.14790504727820597
Validation loss: 2.5037749758719823

Epoch: 5| Step: 1
Training loss: 0.2699388103996491
Validation loss: 2.482523415909056

Epoch: 5| Step: 2
Training loss: 0.21458146818208418
Validation loss: 2.52634672592206

Epoch: 5| Step: 3
Training loss: 0.2429394508064639
Validation loss: 2.5350570564501758

Epoch: 5| Step: 4
Training loss: 0.0943826005177201
Validation loss: 2.522346430621492

Epoch: 5| Step: 5
Training loss: 0.3224785072720307
Validation loss: 2.5572125749057304

Epoch: 5| Step: 6
Training loss: 0.16230753771027143
Validation loss: 2.5479871137559784

Epoch: 5| Step: 7
Training loss: 0.14684900677752272
Validation loss: 2.544034088993615

Epoch: 5| Step: 8
Training loss: 0.20044908953419713
Validation loss: 2.549992483153294

Epoch: 5| Step: 9
Training loss: 0.252856166567257
Validation loss: 2.5551558799609264

Epoch: 5| Step: 10
Training loss: 0.1417728703254634
Validation loss: 2.549365585565549

Epoch: 500| Step: 0
Training loss: 0.16370149471872608
Validation loss: 2.561808597641677

Epoch: 5| Step: 1
Training loss: 0.22787150054604985
Validation loss: 2.549092006102975

Epoch: 5| Step: 2
Training loss: 0.2189862389133048
Validation loss: 2.5459873674151785

Epoch: 5| Step: 3
Training loss: 0.32833525188526136
Validation loss: 2.5686276989451247

Epoch: 5| Step: 4
Training loss: 0.2753599704427969
Validation loss: 2.5744354865382397

Epoch: 5| Step: 5
Training loss: 0.2888656022942039
Validation loss: 2.5873095833435404

Epoch: 5| Step: 6
Training loss: 0.1780902736677288
Validation loss: 2.530674117256432

Epoch: 5| Step: 7
Training loss: 0.1480409570683763
Validation loss: 2.5581489136840094

Epoch: 5| Step: 8
Training loss: 0.24581336139651205
Validation loss: 2.512314643485567

Epoch: 5| Step: 9
Training loss: 0.12992960581714694
Validation loss: 2.542620161965139

Epoch: 5| Step: 10
Training loss: 0.11986272499411647
Validation loss: 2.5139345361591596

Epoch: 501| Step: 0
Training loss: 0.24387342708682624
Validation loss: 2.533291910087322

Epoch: 5| Step: 1
Training loss: 0.14053694299249725
Validation loss: 2.5285119262803515

Epoch: 5| Step: 2
Training loss: 0.20138588419861472
Validation loss: 2.5278214266037247

Epoch: 5| Step: 3
Training loss: 0.1907066287695954
Validation loss: 2.540001605385979

Epoch: 5| Step: 4
Training loss: 0.1782599423218536
Validation loss: 2.5395675603639947

Epoch: 5| Step: 5
Training loss: 0.23153139276097226
Validation loss: 2.544545106287364

Epoch: 5| Step: 6
Training loss: 0.2042939406525215
Validation loss: 2.536172991303062

Epoch: 5| Step: 7
Training loss: 0.37569008353815264
Validation loss: 2.5272228311384484

Epoch: 5| Step: 8
Training loss: 0.15420597151018117
Validation loss: 2.529875919767765

Epoch: 5| Step: 9
Training loss: 0.13665148579012704
Validation loss: 2.509909023514995

Epoch: 5| Step: 10
Training loss: 0.13270524546740195
Validation loss: 2.5186319491116236

Epoch: 502| Step: 0
Training loss: 0.16290800015658088
Validation loss: 2.4855128292298287

Epoch: 5| Step: 1
Training loss: 0.2172562997923013
Validation loss: 2.4597664745837644

Epoch: 5| Step: 2
Training loss: 0.14100199736582214
Validation loss: 2.4847587835410954

Epoch: 5| Step: 3
Training loss: 0.39867139944458946
Validation loss: 2.483209213796565

Epoch: 5| Step: 4
Training loss: 0.1956695821040293
Validation loss: 2.4583299872151567

Epoch: 5| Step: 5
Training loss: 0.27139463244990186
Validation loss: 2.4847012444482544

Epoch: 5| Step: 6
Training loss: 0.12977712676710998
Validation loss: 2.526149129828188

Epoch: 5| Step: 7
Training loss: 0.23379726730137346
Validation loss: 2.5274533940323747

Epoch: 5| Step: 8
Training loss: 0.21000108556807448
Validation loss: 2.4883594690926265

Epoch: 5| Step: 9
Training loss: 0.1206745961186364
Validation loss: 2.519214894849984

Epoch: 5| Step: 10
Training loss: 0.1266907401355111
Validation loss: 2.532905220743099

Epoch: 503| Step: 0
Training loss: 0.2612463972993149
Validation loss: 2.5780342998441643

Epoch: 5| Step: 1
Training loss: 0.27056005641321096
Validation loss: 2.5300015229617747

Epoch: 5| Step: 2
Training loss: 0.28268667024688426
Validation loss: 2.556638577408241

Epoch: 5| Step: 3
Training loss: 0.25698202931531594
Validation loss: 2.5583241931682132

Epoch: 5| Step: 4
Training loss: 0.2608663713283006
Validation loss: 2.54004706819006

Epoch: 5| Step: 5
Training loss: 0.11600388586332704
Validation loss: 2.596652882806747

Epoch: 5| Step: 6
Training loss: 0.13286526417255606
Validation loss: 2.586382870770979

Epoch: 5| Step: 7
Training loss: 0.17340844099936453
Validation loss: 2.5798432661047435

Epoch: 5| Step: 8
Training loss: 0.27300747708589157
Validation loss: 2.556647916398766

Epoch: 5| Step: 9
Training loss: 0.20706583130123082
Validation loss: 2.571192459886475

Epoch: 5| Step: 10
Training loss: 0.1342336479529654
Validation loss: 2.5419515389242586

Epoch: 504| Step: 0
Training loss: 0.22278482506021602
Validation loss: 2.5563295848372136

Epoch: 5| Step: 1
Training loss: 0.14829278466931434
Validation loss: 2.552646557903726

Epoch: 5| Step: 2
Training loss: 0.18464725646530394
Validation loss: 2.530011344821651

Epoch: 5| Step: 3
Training loss: 0.15885557046384638
Validation loss: 2.5316712395963332

Epoch: 5| Step: 4
Training loss: 0.3858931234074744
Validation loss: 2.4982069784353174

Epoch: 5| Step: 5
Training loss: 0.2136604494321278
Validation loss: 2.5160733144944616

Epoch: 5| Step: 6
Training loss: 0.12880334214385802
Validation loss: 2.5034473190520474

Epoch: 5| Step: 7
Training loss: 0.2091749160464613
Validation loss: 2.4888416713356234

Epoch: 5| Step: 8
Training loss: 0.17207593443191604
Validation loss: 2.4936326716184056

Epoch: 5| Step: 9
Training loss: 0.29151011704772595
Validation loss: 2.4885399047253043

Epoch: 5| Step: 10
Training loss: 0.17248733854128
Validation loss: 2.5233787540704298

Epoch: 505| Step: 0
Training loss: 0.17078072990205662
Validation loss: 2.546560598606433

Epoch: 5| Step: 1
Training loss: 0.19541752852335909
Validation loss: 2.522076041023599

Epoch: 5| Step: 2
Training loss: 0.32776269892628374
Validation loss: 2.53380763493407

Epoch: 5| Step: 3
Training loss: 0.28703943036362306
Validation loss: 2.5173119099275745

Epoch: 5| Step: 4
Training loss: 0.13978722484849446
Validation loss: 2.509922879894862

Epoch: 5| Step: 5
Training loss: 0.139106284974344
Validation loss: 2.537057319748794

Epoch: 5| Step: 6
Training loss: 0.19163665722278544
Validation loss: 2.5219310938816295

Epoch: 5| Step: 7
Training loss: 0.16923241668419048
Validation loss: 2.5406143643339574

Epoch: 5| Step: 8
Training loss: 0.12789444037439715
Validation loss: 2.5093873434900127

Epoch: 5| Step: 9
Training loss: 0.18666423855810252
Validation loss: 2.532200191724908

Epoch: 5| Step: 10
Training loss: 0.2853751713923083
Validation loss: 2.544385478313002

Epoch: 506| Step: 0
Training loss: 0.2227501253027087
Validation loss: 2.516575171120774

Epoch: 5| Step: 1
Training loss: 0.2800618878583256
Validation loss: 2.5321234468787486

Epoch: 5| Step: 2
Training loss: 0.1821373842940507
Validation loss: 2.53914408537714

Epoch: 5| Step: 3
Training loss: 0.19559535525568764
Validation loss: 2.535066239319086

Epoch: 5| Step: 4
Training loss: 0.1856709717809879
Validation loss: 2.565977009123409

Epoch: 5| Step: 5
Training loss: 0.2398440671663952
Validation loss: 2.585236943263634

Epoch: 5| Step: 6
Training loss: 0.19963959578981544
Validation loss: 2.550630399888012

Epoch: 5| Step: 7
Training loss: 0.24364145747693094
Validation loss: 2.5401003277928984

Epoch: 5| Step: 8
Training loss: 0.25145939200704404
Validation loss: 2.5605482686814938

Epoch: 5| Step: 9
Training loss: 0.1598317475814124
Validation loss: 2.554171552209936

Epoch: 5| Step: 10
Training loss: 0.29200222801883713
Validation loss: 2.5530368148019935

Epoch: 507| Step: 0
Training loss: 0.08635550136084978
Validation loss: 2.529555771225436

Epoch: 5| Step: 1
Training loss: 0.21752856904153192
Validation loss: 2.5244750326871332

Epoch: 5| Step: 2
Training loss: 0.16410280481897527
Validation loss: 2.5072578412522923

Epoch: 5| Step: 3
Training loss: 0.19891620551139627
Validation loss: 2.5298824690170196

Epoch: 5| Step: 4
Training loss: 0.24521149572641363
Validation loss: 2.521076696763068

Epoch: 5| Step: 5
Training loss: 0.27160068462992015
Validation loss: 2.491755667196584

Epoch: 5| Step: 6
Training loss: 0.2187922811518317
Validation loss: 2.499954088876477

Epoch: 5| Step: 7
Training loss: 0.23235116411910356
Validation loss: 2.510722899435355

Epoch: 5| Step: 8
Training loss: 0.16979825247432884
Validation loss: 2.510405843271697

Epoch: 5| Step: 9
Training loss: 0.15553500977559648
Validation loss: 2.5005727122200327

Epoch: 5| Step: 10
Training loss: 0.29389798616658425
Validation loss: 2.531939917008096

Epoch: 508| Step: 0
Training loss: 0.13736817206803514
Validation loss: 2.5315127477545656

Epoch: 5| Step: 1
Training loss: 0.26198767609677015
Validation loss: 2.5193199405517

Epoch: 5| Step: 2
Training loss: 0.11788210054979334
Validation loss: 2.5390764259732674

Epoch: 5| Step: 3
Training loss: 0.22117425207856942
Validation loss: 2.554532832179872

Epoch: 5| Step: 4
Training loss: 0.11120016708449376
Validation loss: 2.535619644858666

Epoch: 5| Step: 5
Training loss: 0.12909298434015443
Validation loss: 2.5134711833987193

Epoch: 5| Step: 6
Training loss: 0.19190583911610123
Validation loss: 2.5539451921311795

Epoch: 5| Step: 7
Training loss: 0.21547382902005793
Validation loss: 2.5349513410860194

Epoch: 5| Step: 8
Training loss: 0.2544644894754459
Validation loss: 2.5442179959045372

Epoch: 5| Step: 9
Training loss: 0.31420170465082214
Validation loss: 2.5093265946674395

Epoch: 5| Step: 10
Training loss: 0.23995308573968993
Validation loss: 2.526068357312476

Epoch: 509| Step: 0
Training loss: 0.26974973254504303
Validation loss: 2.541435381127969

Epoch: 5| Step: 1
Training loss: 0.204353013357939
Validation loss: 2.532625390595195

Epoch: 5| Step: 2
Training loss: 0.18667762934014548
Validation loss: 2.5362593693289437

Epoch: 5| Step: 3
Training loss: 0.24143068443018198
Validation loss: 2.5365641413666054

Epoch: 5| Step: 4
Training loss: 0.19831724578127305
Validation loss: 2.5217605617106518

Epoch: 5| Step: 5
Training loss: 0.26272435364567015
Validation loss: 2.536397848633393

Epoch: 5| Step: 6
Training loss: 0.17392954921335668
Validation loss: 2.530928562607993

Epoch: 5| Step: 7
Training loss: 0.14535475367810777
Validation loss: 2.5316922049551502

Epoch: 5| Step: 8
Training loss: 0.2250894971183882
Validation loss: 2.534252238214616

Epoch: 5| Step: 9
Training loss: 0.1347625427999341
Validation loss: 2.51722933637318

Epoch: 5| Step: 10
Training loss: 0.14470214663538217
Validation loss: 2.5592551186868175

Epoch: 510| Step: 0
Training loss: 0.33980886784573927
Validation loss: 2.5274982041611347

Epoch: 5| Step: 1
Training loss: 0.14947971447457697
Validation loss: 2.5619341678017773

Epoch: 5| Step: 2
Training loss: 0.13217359324275388
Validation loss: 2.533616890147273

Epoch: 5| Step: 3
Training loss: 0.2292482256253879
Validation loss: 2.5423299892833158

Epoch: 5| Step: 4
Training loss: 0.16347490968404207
Validation loss: 2.5642564557862593

Epoch: 5| Step: 5
Training loss: 0.12737303028605243
Validation loss: 2.5477790448491584

Epoch: 5| Step: 6
Training loss: 0.14183124461981933
Validation loss: 2.5410696693906814

Epoch: 5| Step: 7
Training loss: 0.20290446230207917
Validation loss: 2.5642749992648066

Epoch: 5| Step: 8
Training loss: 0.13199288245269633
Validation loss: 2.5672485814245722

Epoch: 5| Step: 9
Training loss: 0.285991360328798
Validation loss: 2.566612043733069

Epoch: 5| Step: 10
Training loss: 0.20121128659152343
Validation loss: 2.5946879148384823

Epoch: 511| Step: 0
Training loss: 0.23035775760925573
Validation loss: 2.5388366669464464

Epoch: 5| Step: 1
Training loss: 0.1364585307413474
Validation loss: 2.5497520599292405

Epoch: 5| Step: 2
Training loss: 0.31025170747808123
Validation loss: 2.5640528206145357

Epoch: 5| Step: 3
Training loss: 0.1738563793236609
Validation loss: 2.54437961476599

Epoch: 5| Step: 4
Training loss: 0.2627609057590456
Validation loss: 2.5598005166622273

Epoch: 5| Step: 5
Training loss: 0.1776561984328008
Validation loss: 2.5327110707324376

Epoch: 5| Step: 6
Training loss: 0.14500389271682104
Validation loss: 2.532343742712636

Epoch: 5| Step: 7
Training loss: 0.10320374903031802
Validation loss: 2.535399426377982

Epoch: 5| Step: 8
Training loss: 0.2202316243952922
Validation loss: 2.5285022902225682

Epoch: 5| Step: 9
Training loss: 0.2663735612967353
Validation loss: 2.5427936400223357

Epoch: 5| Step: 10
Training loss: 0.1571190033726588
Validation loss: 2.54911949696589

Epoch: 512| Step: 0
Training loss: 0.25443416879731995
Validation loss: 2.5398710895928316

Epoch: 5| Step: 1
Training loss: 0.1787394724926928
Validation loss: 2.5536297628025166

Epoch: 5| Step: 2
Training loss: 0.26431365850361144
Validation loss: 2.5129179083172897

Epoch: 5| Step: 3
Training loss: 0.1474548932283059
Validation loss: 2.5281959399517517

Epoch: 5| Step: 4
Training loss: 0.08016251559986776
Validation loss: 2.544359067811265

Epoch: 5| Step: 5
Training loss: 0.25271221517729936
Validation loss: 2.535188086535261

Epoch: 5| Step: 6
Training loss: 0.25709406134532187
Validation loss: 2.5371346019510086

Epoch: 5| Step: 7
Training loss: 0.13765996113947865
Validation loss: 2.5391789558403737

Epoch: 5| Step: 8
Training loss: 0.1255494647658032
Validation loss: 2.5417780386941424

Epoch: 5| Step: 9
Training loss: 0.17740462178539254
Validation loss: 2.5317175284143953

Epoch: 5| Step: 10
Training loss: 0.20086245212104498
Validation loss: 2.542537039054426

Epoch: 513| Step: 0
Training loss: 0.2537758565751652
Validation loss: 2.539973990604584

Epoch: 5| Step: 1
Training loss: 0.2522313407928601
Validation loss: 2.5296283304086686

Epoch: 5| Step: 2
Training loss: 0.11813570896177888
Validation loss: 2.5379068662406685

Epoch: 5| Step: 3
Training loss: 0.19392757545952838
Validation loss: 2.5374923195129897

Epoch: 5| Step: 4
Training loss: 0.1298031239812902
Validation loss: 2.5431801630090765

Epoch: 5| Step: 5
Training loss: 0.11766302269114665
Validation loss: 2.553820319834913

Epoch: 5| Step: 6
Training loss: 0.20278645693554176
Validation loss: 2.5168242075443414

Epoch: 5| Step: 7
Training loss: 0.1650294182572273
Validation loss: 2.5570690710684496

Epoch: 5| Step: 8
Training loss: 0.2511291930388348
Validation loss: 2.5487425088873192

Epoch: 5| Step: 9
Training loss: 0.21736494163957373
Validation loss: 2.5400506617596994

Epoch: 5| Step: 10
Training loss: 0.22076176396072222
Validation loss: 2.5275894996270583

Epoch: 514| Step: 0
Training loss: 0.28274928593060544
Validation loss: 2.527112447709934

Epoch: 5| Step: 1
Training loss: 0.20193697977367986
Validation loss: 2.530647502877094

Epoch: 5| Step: 2
Training loss: 0.08673943163429516
Validation loss: 2.533126356394736

Epoch: 5| Step: 3
Training loss: 0.17495083693084468
Validation loss: 2.558210324500111

Epoch: 5| Step: 4
Training loss: 0.13671550065675186
Validation loss: 2.541844838993392

Epoch: 5| Step: 5
Training loss: 0.16238644488256665
Validation loss: 2.5660883512339248

Epoch: 5| Step: 6
Training loss: 0.2750558373810785
Validation loss: 2.5271896881108367

Epoch: 5| Step: 7
Training loss: 0.15809451012806613
Validation loss: 2.526049748517627

Epoch: 5| Step: 8
Training loss: 0.16604592663849593
Validation loss: 2.519031241208232

Epoch: 5| Step: 9
Training loss: 0.14685336369577115
Validation loss: 2.478555823464232

Epoch: 5| Step: 10
Training loss: 0.24277363115028275
Validation loss: 2.5414369956114866

Epoch: 515| Step: 0
Training loss: 0.23259850209968275
Validation loss: 2.5262212068931538

Epoch: 5| Step: 1
Training loss: 0.186253897158922
Validation loss: 2.5474189415503807

Epoch: 5| Step: 2
Training loss: 0.24668532370367727
Validation loss: 2.5156600797858584

Epoch: 5| Step: 3
Training loss: 0.24830075285206327
Validation loss: 2.5651191833832763

Epoch: 5| Step: 4
Training loss: 0.1413113085651407
Validation loss: 2.5378343715151774

Epoch: 5| Step: 5
Training loss: 0.16027856435996868
Validation loss: 2.5701376371163605

Epoch: 5| Step: 6
Training loss: 0.15106146918305352
Validation loss: 2.603292401313564

Epoch: 5| Step: 7
Training loss: 0.15478783975194393
Validation loss: 2.566560033987808

Epoch: 5| Step: 8
Training loss: 0.20445357999361083
Validation loss: 2.575820283492214

Epoch: 5| Step: 9
Training loss: 0.13602192274190902
Validation loss: 2.564574819543207

Epoch: 5| Step: 10
Training loss: 0.24043368778573057
Validation loss: 2.579101881575683

Epoch: 516| Step: 0
Training loss: 0.10885128590849759
Validation loss: 2.5517941667491244

Epoch: 5| Step: 1
Training loss: 0.15217142262025815
Validation loss: 2.5472095168404776

Epoch: 5| Step: 2
Training loss: 0.2654234879129697
Validation loss: 2.5329440358018944

Epoch: 5| Step: 3
Training loss: 0.16932880558187965
Validation loss: 2.5499853169925117

Epoch: 5| Step: 4
Training loss: 0.08581716608974066
Validation loss: 2.567073068924532

Epoch: 5| Step: 5
Training loss: 0.14945171854062286
Validation loss: 2.533991790330003

Epoch: 5| Step: 6
Training loss: 0.26066076600448307
Validation loss: 2.556642796929525

Epoch: 5| Step: 7
Training loss: 0.16500559021590394
Validation loss: 2.530439517746499

Epoch: 5| Step: 8
Training loss: 0.2097394351486644
Validation loss: 2.5424593417819663

Epoch: 5| Step: 9
Training loss: 0.26087835235434087
Validation loss: 2.5262566499828103

Epoch: 5| Step: 10
Training loss: 0.16075277884574674
Validation loss: 2.514755851983454

Epoch: 517| Step: 0
Training loss: 0.23314750621553287
Validation loss: 2.499058739041044

Epoch: 5| Step: 1
Training loss: 0.22716704642510618
Validation loss: 2.5138351522917137

Epoch: 5| Step: 2
Training loss: 0.1484931916617219
Validation loss: 2.4952404471387983

Epoch: 5| Step: 3
Training loss: 0.09268989314856571
Validation loss: 2.479154911635559

Epoch: 5| Step: 4
Training loss: 0.13766864085422373
Validation loss: 2.5191961128040905

Epoch: 5| Step: 5
Training loss: 0.25713037069550543
Validation loss: 2.499314425407988

Epoch: 5| Step: 6
Training loss: 0.2419131786564974
Validation loss: 2.533554071687375

Epoch: 5| Step: 7
Training loss: 0.14126568124873584
Validation loss: 2.5052728462794307

Epoch: 5| Step: 8
Training loss: 0.15240404574177047
Validation loss: 2.514901876289294

Epoch: 5| Step: 9
Training loss: 0.16699313559458223
Validation loss: 2.5286516693238155

Epoch: 5| Step: 10
Training loss: 0.2541735489231388
Validation loss: 2.4984187519368692

Epoch: 518| Step: 0
Training loss: 0.11881198269301507
Validation loss: 2.516638516281754

Epoch: 5| Step: 1
Training loss: 0.10983969965151041
Validation loss: 2.4849006342883357

Epoch: 5| Step: 2
Training loss: 0.22637789703392208
Validation loss: 2.541183732091217

Epoch: 5| Step: 3
Training loss: 0.25048551502150396
Validation loss: 2.522088119830196

Epoch: 5| Step: 4
Training loss: 0.16032655314147207
Validation loss: 2.5274514019116876

Epoch: 5| Step: 5
Training loss: 0.21392217129625588
Validation loss: 2.5326398049412324

Epoch: 5| Step: 6
Training loss: 0.27706357746874244
Validation loss: 2.555282876128375

Epoch: 5| Step: 7
Training loss: 0.12852206924189688
Validation loss: 2.4875837064928783

Epoch: 5| Step: 8
Training loss: 0.25817798948074433
Validation loss: 2.5415093729484566

Epoch: 5| Step: 9
Training loss: 0.12697505761472141
Validation loss: 2.5010330457704897

Epoch: 5| Step: 10
Training loss: 0.2105144125377503
Validation loss: 2.514751631501721

Epoch: 519| Step: 0
Training loss: 0.2756438342512475
Validation loss: 2.508474204472805

Epoch: 5| Step: 1
Training loss: 0.15654916733185573
Validation loss: 2.5011063414529255

Epoch: 5| Step: 2
Training loss: 0.20379573779646892
Validation loss: 2.525821463743964

Epoch: 5| Step: 3
Training loss: 0.18750518553238946
Validation loss: 2.5568482495103324

Epoch: 5| Step: 4
Training loss: 0.128635251682114
Validation loss: 2.5297475022136675

Epoch: 5| Step: 5
Training loss: 0.2638591666312001
Validation loss: 2.5589468458021933

Epoch: 5| Step: 6
Training loss: 0.31391862496439565
Validation loss: 2.5700620757470136

Epoch: 5| Step: 7
Training loss: 0.15089276321134926
Validation loss: 2.5439900377140026

Epoch: 5| Step: 8
Training loss: 0.1724000518739837
Validation loss: 2.5276995670852687

Epoch: 5| Step: 9
Training loss: 0.1472315235268671
Validation loss: 2.5395027267441126

Epoch: 5| Step: 10
Training loss: 0.19342049682653767
Validation loss: 2.5218846427164974

Epoch: 520| Step: 0
Training loss: 0.24655715514748935
Validation loss: 2.538362933668829

Epoch: 5| Step: 1
Training loss: 0.19415591158638612
Validation loss: 2.530177464056202

Epoch: 5| Step: 2
Training loss: 0.2878107211071463
Validation loss: 2.5456015380546138

Epoch: 5| Step: 3
Training loss: 0.2553687888747115
Validation loss: 2.5532054693492237

Epoch: 5| Step: 4
Training loss: 0.13025641666154772
Validation loss: 2.567117609902122

Epoch: 5| Step: 5
Training loss: 0.19708960772326223
Validation loss: 2.5115176063089297

Epoch: 5| Step: 6
Training loss: 0.14426769894134125
Validation loss: 2.5115689619389396

Epoch: 5| Step: 7
Training loss: 0.16892018434495168
Validation loss: 2.510447283965608

Epoch: 5| Step: 8
Training loss: 0.28049081752744187
Validation loss: 2.4972298112592024

Epoch: 5| Step: 9
Training loss: 0.1453614362742541
Validation loss: 2.4824708604409285

Epoch: 5| Step: 10
Training loss: 0.09363272902063652
Validation loss: 2.5217499157747088

Epoch: 521| Step: 0
Training loss: 0.25894743194150055
Validation loss: 2.512198501607991

Epoch: 5| Step: 1
Training loss: 0.08281392566335427
Validation loss: 2.53194694895201

Epoch: 5| Step: 2
Training loss: 0.24011746329742722
Validation loss: 2.491834883718959

Epoch: 5| Step: 3
Training loss: 0.14158230354618637
Validation loss: 2.5068323172812743

Epoch: 5| Step: 4
Training loss: 0.21457919391478897
Validation loss: 2.500279734968553

Epoch: 5| Step: 5
Training loss: 0.16638076121374284
Validation loss: 2.532321510202022

Epoch: 5| Step: 6
Training loss: 0.2004300114107312
Validation loss: 2.5297016992571844

Epoch: 5| Step: 7
Training loss: 0.16462568281961876
Validation loss: 2.5590369421771815

Epoch: 5| Step: 8
Training loss: 0.1445281891885338
Validation loss: 2.5745933439798665

Epoch: 5| Step: 9
Training loss: 0.25740135527867536
Validation loss: 2.5522122425691127

Epoch: 5| Step: 10
Training loss: 0.23478101689410763
Validation loss: 2.527092662726055

Epoch: 522| Step: 0
Training loss: 0.1589190273811781
Validation loss: 2.5185194159475723

Epoch: 5| Step: 1
Training loss: 0.13351256625408925
Validation loss: 2.5532044637558107

Epoch: 5| Step: 2
Training loss: 0.10123234510292804
Validation loss: 2.538172475662895

Epoch: 5| Step: 3
Training loss: 0.10801428521957539
Validation loss: 2.552699673136188

Epoch: 5| Step: 4
Training loss: 0.19020537834929171
Validation loss: 2.538833131739857

Epoch: 5| Step: 5
Training loss: 0.2813244826979641
Validation loss: 2.525502611412854

Epoch: 5| Step: 6
Training loss: 0.14804639866533373
Validation loss: 2.552631617790071

Epoch: 5| Step: 7
Training loss: 0.25313321323962906
Validation loss: 2.554862992876254

Epoch: 5| Step: 8
Training loss: 0.24220434253333203
Validation loss: 2.54810318183713

Epoch: 5| Step: 9
Training loss: 0.233495604268466
Validation loss: 2.5455784107144033

Epoch: 5| Step: 10
Training loss: 0.15105440371072143
Validation loss: 2.5397504471826924

Epoch: 523| Step: 0
Training loss: 0.1402166982364192
Validation loss: 2.5285171021990065

Epoch: 5| Step: 1
Training loss: 0.15173088188263437
Validation loss: 2.5524386207400243

Epoch: 5| Step: 2
Training loss: 0.1346853334934146
Validation loss: 2.514152255241535

Epoch: 5| Step: 3
Training loss: 0.14152208926184878
Validation loss: 2.5014445402502834

Epoch: 5| Step: 4
Training loss: 0.1158301059834468
Validation loss: 2.5279115456640397

Epoch: 5| Step: 5
Training loss: 0.20880534623310798
Validation loss: 2.5175181099705175

Epoch: 5| Step: 6
Training loss: 0.26390796970238506
Validation loss: 2.498696376996262

Epoch: 5| Step: 7
Training loss: 0.2834167464038483
Validation loss: 2.529166723119131

Epoch: 5| Step: 8
Training loss: 0.11866900637074528
Validation loss: 2.5365890826687143

Epoch: 5| Step: 9
Training loss: 0.2548078083161255
Validation loss: 2.5569665993473594

Epoch: 5| Step: 10
Training loss: 0.09299005015981679
Validation loss: 2.5244058488081578

Epoch: 524| Step: 0
Training loss: 0.2859914515099718
Validation loss: 2.513208666606131

Epoch: 5| Step: 1
Training loss: 0.12184486169349494
Validation loss: 2.555855374614756

Epoch: 5| Step: 2
Training loss: 0.10858146577417419
Validation loss: 2.556847551661281

Epoch: 5| Step: 3
Training loss: 0.1552057538575577
Validation loss: 2.551783595879816

Epoch: 5| Step: 4
Training loss: 0.1878325969524498
Validation loss: 2.5487010174315854

Epoch: 5| Step: 5
Training loss: 0.13502592021185017
Validation loss: 2.5755449378503146

Epoch: 5| Step: 6
Training loss: 0.1623691752059316
Validation loss: 2.5392569347111875

Epoch: 5| Step: 7
Training loss: 0.11846825954498745
Validation loss: 2.5432124172278066

Epoch: 5| Step: 8
Training loss: 0.1430063088907711
Validation loss: 2.541055369450365

Epoch: 5| Step: 9
Training loss: 0.2398236027062012
Validation loss: 2.5371520154336213

Epoch: 5| Step: 10
Training loss: 0.28332748313548783
Validation loss: 2.5506073166387666

Epoch: 525| Step: 0
Training loss: 0.13742318554503263
Validation loss: 2.5586397481411196

Epoch: 5| Step: 1
Training loss: 0.13108643717141705
Validation loss: 2.5389272467320043

Epoch: 5| Step: 2
Training loss: 0.22132022634860918
Validation loss: 2.5648732984026714

Epoch: 5| Step: 3
Training loss: 0.12299517650518466
Validation loss: 2.5491126541975078

Epoch: 5| Step: 4
Training loss: 0.21143279383352628
Validation loss: 2.5233280411238868

Epoch: 5| Step: 5
Training loss: 0.2589219669735295
Validation loss: 2.548245376693835

Epoch: 5| Step: 6
Training loss: 0.2138138534722731
Validation loss: 2.5380798467796852

Epoch: 5| Step: 7
Training loss: 0.09658710786535718
Validation loss: 2.513543944268146

Epoch: 5| Step: 8
Training loss: 0.11772037784877738
Validation loss: 2.531557179190238

Epoch: 5| Step: 9
Training loss: 0.2623628973548072
Validation loss: 2.507054989865201

Epoch: 5| Step: 10
Training loss: 0.1516990469289047
Validation loss: 2.513995605497345

Epoch: 526| Step: 0
Training loss: 0.19471069125863327
Validation loss: 2.5121609804317204

Epoch: 5| Step: 1
Training loss: 0.24390524389290394
Validation loss: 2.527559994542719

Epoch: 5| Step: 2
Training loss: 0.15007145565490618
Validation loss: 2.5091461508822577

Epoch: 5| Step: 3
Training loss: 0.1524877784377326
Validation loss: 2.5099180741931275

Epoch: 5| Step: 4
Training loss: 0.13389342476976632
Validation loss: 2.531853239734294

Epoch: 5| Step: 5
Training loss: 0.13853860549365213
Validation loss: 2.508614879774691

Epoch: 5| Step: 6
Training loss: 0.07749886539805409
Validation loss: 2.521675590193161

Epoch: 5| Step: 7
Training loss: 0.25145580682904856
Validation loss: 2.5563231991183173

Epoch: 5| Step: 8
Training loss: 0.1325809128580009
Validation loss: 2.544389064243935

Epoch: 5| Step: 9
Training loss: 0.2307022576682338
Validation loss: 2.5166877545496864

Epoch: 5| Step: 10
Training loss: 0.18348023781070866
Validation loss: 2.5135562180842275

Epoch: 527| Step: 0
Training loss: 0.14839390691803453
Validation loss: 2.5202436087013096

Epoch: 5| Step: 1
Training loss: 0.13394823838200826
Validation loss: 2.5298676356474474

Epoch: 5| Step: 2
Training loss: 0.14427678802288188
Validation loss: 2.5395371950480463

Epoch: 5| Step: 3
Training loss: 0.17390296160904084
Validation loss: 2.518869421051131

Epoch: 5| Step: 4
Training loss: 0.23585193516159955
Validation loss: 2.5492995847051705

Epoch: 5| Step: 5
Training loss: 0.11243648673343676
Validation loss: 2.53487584713364

Epoch: 5| Step: 6
Training loss: 0.09388972836855251
Validation loss: 2.568442366898457

Epoch: 5| Step: 7
Training loss: 0.12256917869787012
Validation loss: 2.5093592421384354

Epoch: 5| Step: 8
Training loss: 0.27857464329555404
Validation loss: 2.5167980115267725

Epoch: 5| Step: 9
Training loss: 0.21292019559942976
Validation loss: 2.523208410166369

Epoch: 5| Step: 10
Training loss: 0.253535204985023
Validation loss: 2.485290785765059

Epoch: 528| Step: 0
Training loss: 0.19075851415866082
Validation loss: 2.5196469551845664

Epoch: 5| Step: 1
Training loss: 0.23177986270303697
Validation loss: 2.522238192881844

Epoch: 5| Step: 2
Training loss: 0.13526977005342922
Validation loss: 2.4912929512970496

Epoch: 5| Step: 3
Training loss: 0.24433630158834066
Validation loss: 2.477954693035437

Epoch: 5| Step: 4
Training loss: 0.20350161813577666
Validation loss: 2.4861280989485195

Epoch: 5| Step: 5
Training loss: 0.11458424862221525
Validation loss: 2.5332208453281013

Epoch: 5| Step: 6
Training loss: 0.2622122453281264
Validation loss: 2.5033436165591283

Epoch: 5| Step: 7
Training loss: 0.12922068019011157
Validation loss: 2.5082715270901557

Epoch: 5| Step: 8
Training loss: 0.1483168048559415
Validation loss: 2.5073067913569482

Epoch: 5| Step: 9
Training loss: 0.1533437334382892
Validation loss: 2.530647953678709

Epoch: 5| Step: 10
Training loss: 0.1648976267323312
Validation loss: 2.5273006260742683

Epoch: 529| Step: 0
Training loss: 0.18760593719713056
Validation loss: 2.539096948533532

Epoch: 5| Step: 1
Training loss: 0.1388984897063505
Validation loss: 2.5523246868659135

Epoch: 5| Step: 2
Training loss: 0.32057750021010034
Validation loss: 2.540272937953056

Epoch: 5| Step: 3
Training loss: 0.19237977233653344
Validation loss: 2.5213592127892843

Epoch: 5| Step: 4
Training loss: 0.17193599723948208
Validation loss: 2.529826449739924

Epoch: 5| Step: 5
Training loss: 0.17482468687763428
Validation loss: 2.51473736183741

Epoch: 5| Step: 6
Training loss: 0.1936581355396005
Validation loss: 2.5228067530021794

Epoch: 5| Step: 7
Training loss: 0.16739635746566606
Validation loss: 2.5163837364551687

Epoch: 5| Step: 8
Training loss: 0.17616723915141363
Validation loss: 2.535553867053165

Epoch: 5| Step: 9
Training loss: 0.09265990086032172
Validation loss: 2.5387181666832

Epoch: 5| Step: 10
Training loss: 0.24836081064918672
Validation loss: 2.5289414610677086

Epoch: 530| Step: 0
Training loss: 0.12828434130792324
Validation loss: 2.5275601984119636

Epoch: 5| Step: 1
Training loss: 0.13101376492949066
Validation loss: 2.534613451550966

Epoch: 5| Step: 2
Training loss: 0.131926399560003
Validation loss: 2.5838655690304524

Epoch: 5| Step: 3
Training loss: 0.15857525609618342
Validation loss: 2.5295334686040944

Epoch: 5| Step: 4
Training loss: 0.10205989778673813
Validation loss: 2.5530156993766693

Epoch: 5| Step: 5
Training loss: 0.10795031098195762
Validation loss: 2.5231398377658967

Epoch: 5| Step: 6
Training loss: 0.269495616160604
Validation loss: 2.530499108803932

Epoch: 5| Step: 7
Training loss: 0.2044091530648971
Validation loss: 2.510150867950433

Epoch: 5| Step: 8
Training loss: 0.20399560870383254
Validation loss: 2.533297595890324

Epoch: 5| Step: 9
Training loss: 0.1113501577158232
Validation loss: 2.4888472390272947

Epoch: 5| Step: 10
Training loss: 0.30659167391037484
Validation loss: 2.512455926177061

Epoch: 531| Step: 0
Training loss: 0.11323066107995851
Validation loss: 2.513929404660046

Epoch: 5| Step: 1
Training loss: 0.10871000447834081
Validation loss: 2.510385491581767

Epoch: 5| Step: 2
Training loss: 0.1370923047973234
Validation loss: 2.5201351524720352

Epoch: 5| Step: 3
Training loss: 0.1028084757852133
Validation loss: 2.520812043076621

Epoch: 5| Step: 4
Training loss: 0.17271786168710151
Validation loss: 2.5012657376113268

Epoch: 5| Step: 5
Training loss: 0.2191165424652567
Validation loss: 2.4825134278533754

Epoch: 5| Step: 6
Training loss: 0.2577987436034585
Validation loss: 2.493032289567961

Epoch: 5| Step: 7
Training loss: 0.24211244035265433
Validation loss: 2.504442013635034

Epoch: 5| Step: 8
Training loss: 0.1409631147917885
Validation loss: 2.5107745572159876

Epoch: 5| Step: 9
Training loss: 0.26059581634364637
Validation loss: 2.530779850730119

Epoch: 5| Step: 10
Training loss: 0.12666908915011238
Validation loss: 2.5714828400558702

Epoch: 532| Step: 0
Training loss: 0.2817279013799228
Validation loss: 2.5220329124117753

Epoch: 5| Step: 1
Training loss: 0.1220757559516288
Validation loss: 2.5306554845863958

Epoch: 5| Step: 2
Training loss: 0.12598231398590243
Validation loss: 2.5080899193215207

Epoch: 5| Step: 3
Training loss: 0.10047975972988787
Validation loss: 2.509023824715828

Epoch: 5| Step: 4
Training loss: 0.08282532266544039
Validation loss: 2.5490414185199417

Epoch: 5| Step: 5
Training loss: 0.0746277968646937
Validation loss: 2.501590375693778

Epoch: 5| Step: 6
Training loss: 0.2133099162920183
Validation loss: 2.519282017653104

Epoch: 5| Step: 7
Training loss: 0.21127282968721522
Validation loss: 2.532928954172653

Epoch: 5| Step: 8
Training loss: 0.22897470446664478
Validation loss: 2.5482504099145564

Epoch: 5| Step: 9
Training loss: 0.176280663262946
Validation loss: 2.5545284736918394

Epoch: 5| Step: 10
Training loss: 0.16720333470020454
Validation loss: 2.5442954626371317

Epoch: 533| Step: 0
Training loss: 0.16568326217724316
Validation loss: 2.583090335744988

Epoch: 5| Step: 1
Training loss: 0.25890219752582505
Validation loss: 2.5290693711546575

Epoch: 5| Step: 2
Training loss: 0.15823482855092105
Validation loss: 2.56012432725328

Epoch: 5| Step: 3
Training loss: 0.17835354114136562
Validation loss: 2.531764683163687

Epoch: 5| Step: 4
Training loss: 0.24027167395110588
Validation loss: 2.5413571654612337

Epoch: 5| Step: 5
Training loss: 0.175957019664905
Validation loss: 2.561724516676621

Epoch: 5| Step: 6
Training loss: 0.19695769722703133
Validation loss: 2.5374001022679495

Epoch: 5| Step: 7
Training loss: 0.22978119204336406
Validation loss: 2.510210059280485

Epoch: 5| Step: 8
Training loss: 0.16050136993282568
Validation loss: 2.513823599828609

Epoch: 5| Step: 9
Training loss: 0.12668580741814953
Validation loss: 2.5434146658561834

Epoch: 5| Step: 10
Training loss: 0.13086204383747638
Validation loss: 2.515018749566344

Epoch: 534| Step: 0
Training loss: 0.12083277729608041
Validation loss: 2.508387758554212

Epoch: 5| Step: 1
Training loss: 0.18963051386167565
Validation loss: 2.527641774204104

Epoch: 5| Step: 2
Training loss: 0.1840271602376337
Validation loss: 2.535962426599884

Epoch: 5| Step: 3
Training loss: 0.1373315497286123
Validation loss: 2.5178600174369152

Epoch: 5| Step: 4
Training loss: 0.22844803454456789
Validation loss: 2.51484490963243

Epoch: 5| Step: 5
Training loss: 0.24879524396972524
Validation loss: 2.5416710051834572

Epoch: 5| Step: 6
Training loss: 0.15064075031479077
Validation loss: 2.541127154863386

Epoch: 5| Step: 7
Training loss: 0.1498095818706058
Validation loss: 2.4874728409880977

Epoch: 5| Step: 8
Training loss: 0.2287429103117452
Validation loss: 2.507908042846261

Epoch: 5| Step: 9
Training loss: 0.21799343270178353
Validation loss: 2.519954352892401

Epoch: 5| Step: 10
Training loss: 0.11103847535606912
Validation loss: 2.545333541786869

Epoch: 535| Step: 0
Training loss: 0.2066713930382361
Validation loss: 2.504031001756442

Epoch: 5| Step: 1
Training loss: 0.1663512035895039
Validation loss: 2.525554267352508

Epoch: 5| Step: 2
Training loss: 0.2567215871625114
Validation loss: 2.5791090980432094

Epoch: 5| Step: 3
Training loss: 0.10578510293606719
Validation loss: 2.514097327327618

Epoch: 5| Step: 4
Training loss: 0.17634274027080876
Validation loss: 2.5313579359580536

Epoch: 5| Step: 5
Training loss: 0.1940226977683478
Validation loss: 2.5089102577244122

Epoch: 5| Step: 6
Training loss: 0.107458468186612
Validation loss: 2.5377655417329543

Epoch: 5| Step: 7
Training loss: 0.1617475573824769
Validation loss: 2.509417835090107

Epoch: 5| Step: 8
Training loss: 0.26156067700588226
Validation loss: 2.533461001740799

Epoch: 5| Step: 9
Training loss: 0.14208861806019688
Validation loss: 2.518290711444774

Epoch: 5| Step: 10
Training loss: 0.11164247736852308
Validation loss: 2.5262507966201615

Epoch: 536| Step: 0
Training loss: 0.15396765703812532
Validation loss: 2.5294158348836717

Epoch: 5| Step: 1
Training loss: 0.13706589631614116
Validation loss: 2.50642776427563

Epoch: 5| Step: 2
Training loss: 0.21463776163586554
Validation loss: 2.544927604830712

Epoch: 5| Step: 3
Training loss: 0.1370151848330819
Validation loss: 2.5402107165471155

Epoch: 5| Step: 4
Training loss: 0.19529065963703057
Validation loss: 2.5250564842806353

Epoch: 5| Step: 5
Training loss: 0.27577593746957935
Validation loss: 2.5631622641186556

Epoch: 5| Step: 6
Training loss: 0.13634048312992805
Validation loss: 2.5223554885066597

Epoch: 5| Step: 7
Training loss: 0.2310793111390112
Validation loss: 2.5270265554297446

Epoch: 5| Step: 8
Training loss: 0.08404107176111195
Validation loss: 2.5403524580489463

Epoch: 5| Step: 9
Training loss: 0.2112277030322858
Validation loss: 2.5024383569554263

Epoch: 5| Step: 10
Training loss: 0.12336489663863662
Validation loss: 2.5381449147140254

Epoch: 537| Step: 0
Training loss: 0.18600384506294118
Validation loss: 2.4905368851052225

Epoch: 5| Step: 1
Training loss: 0.19805452079987132
Validation loss: 2.5061195178462294

Epoch: 5| Step: 2
Training loss: 0.1463294736104511
Validation loss: 2.4925941796135476

Epoch: 5| Step: 3
Training loss: 0.2590452545555269
Validation loss: 2.501038967121083

Epoch: 5| Step: 4
Training loss: 0.20194032801917977
Validation loss: 2.4956976124492556

Epoch: 5| Step: 5
Training loss: 0.1474536995027181
Validation loss: 2.5226721332327093

Epoch: 5| Step: 6
Training loss: 0.15245262559248102
Validation loss: 2.52371139256538

Epoch: 5| Step: 7
Training loss: 0.25646793994889516
Validation loss: 2.538058010972695

Epoch: 5| Step: 8
Training loss: 0.15229530053123766
Validation loss: 2.5355337364267414

Epoch: 5| Step: 9
Training loss: 0.11337972340055225
Validation loss: 2.5343820525598857

Epoch: 5| Step: 10
Training loss: 0.16384064910743848
Validation loss: 2.546320270173975

Epoch: 538| Step: 0
Training loss: 0.1695240340037544
Validation loss: 2.5389473736758963

Epoch: 5| Step: 1
Training loss: 0.10902326515509426
Validation loss: 2.510845384807743

Epoch: 5| Step: 2
Training loss: 0.18475766235355784
Validation loss: 2.5411195541034646

Epoch: 5| Step: 3
Training loss: 0.1593089310357411
Validation loss: 2.501327659458793

Epoch: 5| Step: 4
Training loss: 0.21071045630475987
Validation loss: 2.5084945318118494

Epoch: 5| Step: 5
Training loss: 0.25334085456188293
Validation loss: 2.5397629279588205

Epoch: 5| Step: 6
Training loss: 0.23895869338738193
Validation loss: 2.54621147986095

Epoch: 5| Step: 7
Training loss: 0.0926192105947958
Validation loss: 2.5606617800905407

Epoch: 5| Step: 8
Training loss: 0.29855566132179645
Validation loss: 2.5803785551059275

Epoch: 5| Step: 9
Training loss: 0.21149557076262274
Validation loss: 2.577997646374531

Epoch: 5| Step: 10
Training loss: 0.17334191764343101
Validation loss: 2.5897392143336138

Epoch: 539| Step: 0
Training loss: 0.13880458713823518
Validation loss: 2.5338669808536554

Epoch: 5| Step: 1
Training loss: 0.28011997022032564
Validation loss: 2.545012186833019

Epoch: 5| Step: 2
Training loss: 0.19609783593894473
Validation loss: 2.516017963888704

Epoch: 5| Step: 3
Training loss: 0.09443151595976843
Validation loss: 2.5172523789243217

Epoch: 5| Step: 4
Training loss: 0.14164639782595553
Validation loss: 2.5424847974754377

Epoch: 5| Step: 5
Training loss: 0.19377548065603326
Validation loss: 2.5079655018394584

Epoch: 5| Step: 6
Training loss: 0.15585136225666146
Validation loss: 2.5103745717174557

Epoch: 5| Step: 7
Training loss: 0.17014853389048376
Validation loss: 2.489128876232688

Epoch: 5| Step: 8
Training loss: 0.16069476377093145
Validation loss: 2.483904076174323

Epoch: 5| Step: 9
Training loss: 0.28253940547973455
Validation loss: 2.4841176686124795

Epoch: 5| Step: 10
Training loss: 0.05936719708242438
Validation loss: 2.4948986057179017

Epoch: 540| Step: 0
Training loss: 0.10013682831739068
Validation loss: 2.523131133235581

Epoch: 5| Step: 1
Training loss: 0.19195244184658905
Validation loss: 2.528968350883473

Epoch: 5| Step: 2
Training loss: 0.11201864385773824
Validation loss: 2.495866354490831

Epoch: 5| Step: 3
Training loss: 0.2095467763093695
Validation loss: 2.5271781510459155

Epoch: 5| Step: 4
Training loss: 0.2788812038384746
Validation loss: 2.5422050178939206

Epoch: 5| Step: 5
Training loss: 0.14110650966988905
Validation loss: 2.5013838496259

Epoch: 5| Step: 6
Training loss: 0.0974451788124006
Validation loss: 2.5124568363490596

Epoch: 5| Step: 7
Training loss: 0.2300144016639399
Validation loss: 2.508525664309478

Epoch: 5| Step: 8
Training loss: 0.11910016514154527
Validation loss: 2.4982622839412554

Epoch: 5| Step: 9
Training loss: 0.2198762256816947
Validation loss: 2.488552157124705

Epoch: 5| Step: 10
Training loss: 0.20706392426235554
Validation loss: 2.515254016838877

Epoch: 541| Step: 0
Training loss: 0.18974724777585386
Validation loss: 2.5153083385410238

Epoch: 5| Step: 1
Training loss: 0.15552847089003327
Validation loss: 2.5398601138040924

Epoch: 5| Step: 2
Training loss: 0.1839069981264051
Validation loss: 2.5255443489824456

Epoch: 5| Step: 3
Training loss: 0.09982881497001232
Validation loss: 2.5316488381454008

Epoch: 5| Step: 4
Training loss: 0.11711034619143056
Validation loss: 2.528854467118463

Epoch: 5| Step: 5
Training loss: 0.2314909556004198
Validation loss: 2.5144335397103514

Epoch: 5| Step: 6
Training loss: 0.17635390462947906
Validation loss: 2.541068010787365

Epoch: 5| Step: 7
Training loss: 0.2255169403776804
Validation loss: 2.527668816795863

Epoch: 5| Step: 8
Training loss: 0.22751035222666727
Validation loss: 2.5150575572982037

Epoch: 5| Step: 9
Training loss: 0.1638228903312983
Validation loss: 2.5278804526364427

Epoch: 5| Step: 10
Training loss: 0.10782461962096589
Validation loss: 2.5412117652519997

Epoch: 542| Step: 0
Training loss: 0.15326856237897094
Validation loss: 2.5037957345405064

Epoch: 5| Step: 1
Training loss: 0.15834165324344956
Validation loss: 2.5204141082288767

Epoch: 5| Step: 2
Training loss: 0.1648553017098693
Validation loss: 2.4914523805415363

Epoch: 5| Step: 3
Training loss: 0.09829002717189586
Validation loss: 2.517072363787856

Epoch: 5| Step: 4
Training loss: 0.17346441601338783
Validation loss: 2.515644391111952

Epoch: 5| Step: 5
Training loss: 0.15648774299101464
Validation loss: 2.5140998745524183

Epoch: 5| Step: 6
Training loss: 0.2404381112947916
Validation loss: 2.4924294069554787

Epoch: 5| Step: 7
Training loss: 0.18458207915405997
Validation loss: 2.502523985757997

Epoch: 5| Step: 8
Training loss: 0.2116141504293776
Validation loss: 2.4797234189692117

Epoch: 5| Step: 9
Training loss: 0.16113794492003636
Validation loss: 2.527753635529953

Epoch: 5| Step: 10
Training loss: 0.17973479394897884
Validation loss: 2.4847071905326525

Epoch: 543| Step: 0
Training loss: 0.2523591075274857
Validation loss: 2.5282381867039576

Epoch: 5| Step: 1
Training loss: 0.2267018251523122
Validation loss: 2.4942189563576354

Epoch: 5| Step: 2
Training loss: 0.08380459794827133
Validation loss: 2.5296420985360473

Epoch: 5| Step: 3
Training loss: 0.16886844429820874
Validation loss: 2.5358088539612944

Epoch: 5| Step: 4
Training loss: 0.1593737092620343
Validation loss: 2.493753814941074

Epoch: 5| Step: 5
Training loss: 0.18413510556662385
Validation loss: 2.512473508152039

Epoch: 5| Step: 6
Training loss: 0.17432840557098034
Validation loss: 2.521378195800608

Epoch: 5| Step: 7
Training loss: 0.18796767084663335
Validation loss: 2.524701723902663

Epoch: 5| Step: 8
Training loss: 0.24074454527218267
Validation loss: 2.515942637504961

Epoch: 5| Step: 9
Training loss: 0.11025267364650897
Validation loss: 2.5132570703481645

Epoch: 5| Step: 10
Training loss: 0.12322697628718189
Validation loss: 2.485931767276559

Epoch: 544| Step: 0
Training loss: 0.1314770228097755
Validation loss: 2.4864227091591826

Epoch: 5| Step: 1
Training loss: 0.23062593950943458
Validation loss: 2.5260087703232714

Epoch: 5| Step: 2
Training loss: 0.1259158010105371
Validation loss: 2.5269447233932993

Epoch: 5| Step: 3
Training loss: 0.11680405986975236
Validation loss: 2.5088193707961772

Epoch: 5| Step: 4
Training loss: 0.18514430896867945
Validation loss: 2.504581184539481

Epoch: 5| Step: 5
Training loss: 0.18526629264256325
Validation loss: 2.552932163302764

Epoch: 5| Step: 6
Training loss: 0.19495832756006057
Validation loss: 2.5362004978694146

Epoch: 5| Step: 7
Training loss: 0.196007160811356
Validation loss: 2.5114845107073083

Epoch: 5| Step: 8
Training loss: 0.13433531463469772
Validation loss: 2.5012132018467015

Epoch: 5| Step: 9
Training loss: 0.2865092174535213
Validation loss: 2.4988751270072562

Epoch: 5| Step: 10
Training loss: 0.2262692773757452
Validation loss: 2.480798416122068

Epoch: 545| Step: 0
Training loss: 0.22146505308557674
Validation loss: 2.506989958646738

Epoch: 5| Step: 1
Training loss: 0.16442953787796072
Validation loss: 2.4976035496683506

Epoch: 5| Step: 2
Training loss: 0.2428357462513297
Validation loss: 2.4839132463774796

Epoch: 5| Step: 3
Training loss: 0.10338078119309915
Validation loss: 2.487343078353337

Epoch: 5| Step: 4
Training loss: 0.19702607897538188
Validation loss: 2.513407079101027

Epoch: 5| Step: 5
Training loss: 0.21093907179070245
Validation loss: 2.503211032749622

Epoch: 5| Step: 6
Training loss: 0.12332081576230464
Validation loss: 2.5028465493119314

Epoch: 5| Step: 7
Training loss: 0.2555242484002256
Validation loss: 2.5088469218028737

Epoch: 5| Step: 8
Training loss: 0.19750098549621103
Validation loss: 2.5195389097809087

Epoch: 5| Step: 9
Training loss: 0.2001019795268637
Validation loss: 2.531310436884928

Epoch: 5| Step: 10
Training loss: 0.22204110012983147
Validation loss: 2.4990873229526716

Epoch: 546| Step: 0
Training loss: 0.12121765273630891
Validation loss: 2.4955064217790026

Epoch: 5| Step: 1
Training loss: 0.11255558845920408
Validation loss: 2.4956068170309953

Epoch: 5| Step: 2
Training loss: 0.17190684218652272
Validation loss: 2.5144416595515535

Epoch: 5| Step: 3
Training loss: 0.1612581632455172
Validation loss: 2.5376223939306524

Epoch: 5| Step: 4
Training loss: 0.1617903615357917
Validation loss: 2.5151449856458106

Epoch: 5| Step: 5
Training loss: 0.15075821972416537
Validation loss: 2.5380549504296437

Epoch: 5| Step: 6
Training loss: 0.2469596313324241
Validation loss: 2.5176302948367684

Epoch: 5| Step: 7
Training loss: 0.3173553572297054
Validation loss: 2.5089269009821944

Epoch: 5| Step: 8
Training loss: 0.17326651620614167
Validation loss: 2.5170979799753193

Epoch: 5| Step: 9
Training loss: 0.24576944599313533
Validation loss: 2.5448306623763464

Epoch: 5| Step: 10
Training loss: 0.1445885944016187
Validation loss: 2.512827289789357

Epoch: 547| Step: 0
Training loss: 0.16104618402571383
Validation loss: 2.5384275085692347

Epoch: 5| Step: 1
Training loss: 0.2181512950142703
Validation loss: 2.529442527087701

Epoch: 5| Step: 2
Training loss: 0.19256618880601992
Validation loss: 2.5244682206076465

Epoch: 5| Step: 3
Training loss: 0.1304162265221214
Validation loss: 2.529140453733589

Epoch: 5| Step: 4
Training loss: 0.25477021752189294
Validation loss: 2.4967429150302114

Epoch: 5| Step: 5
Training loss: 0.21865999550015053
Validation loss: 2.506261961179618

Epoch: 5| Step: 6
Training loss: 0.13138778952611221
Validation loss: 2.5190340297292075

Epoch: 5| Step: 7
Training loss: 0.14610308296053368
Validation loss: 2.5272246002692302

Epoch: 5| Step: 8
Training loss: 0.2867669119649353
Validation loss: 2.528311982216755

Epoch: 5| Step: 9
Training loss: 0.09145022438965815
Validation loss: 2.54904684340742

Epoch: 5| Step: 10
Training loss: 0.12892394955817216
Validation loss: 2.541701219936765

Epoch: 548| Step: 0
Training loss: 0.15081028164671859
Validation loss: 2.5409372259022254

Epoch: 5| Step: 1
Training loss: 0.2863822214563959
Validation loss: 2.593233618277396

Epoch: 5| Step: 2
Training loss: 0.18021458567171603
Validation loss: 2.587028707161158

Epoch: 5| Step: 3
Training loss: 0.14655403388283464
Validation loss: 2.5703984089827876

Epoch: 5| Step: 4
Training loss: 0.12854781312972285
Validation loss: 2.5387209446881087

Epoch: 5| Step: 5
Training loss: 0.12381843835867433
Validation loss: 2.529378902568381

Epoch: 5| Step: 6
Training loss: 0.24182594136938546
Validation loss: 2.532809111692896

Epoch: 5| Step: 7
Training loss: 0.22376731925404458
Validation loss: 2.516691147692592

Epoch: 5| Step: 8
Training loss: 0.22659143723473
Validation loss: 2.5548267886610927

Epoch: 5| Step: 9
Training loss: 0.13897176337958514
Validation loss: 2.5253386713146027

Epoch: 5| Step: 10
Training loss: 0.16251790608273253
Validation loss: 2.515798783992184

Epoch: 549| Step: 0
Training loss: 0.16273750843322332
Validation loss: 2.5071933009896306

Epoch: 5| Step: 1
Training loss: 0.22567015888100672
Validation loss: 2.4924871050070885

Epoch: 5| Step: 2
Training loss: 0.07546351027612566
Validation loss: 2.4922136311886223

Epoch: 5| Step: 3
Training loss: 0.2252881367483127
Validation loss: 2.4737539165263756

Epoch: 5| Step: 4
Training loss: 0.18801139590353402
Validation loss: 2.504504106712984

Epoch: 5| Step: 5
Training loss: 0.1189329925508383
Validation loss: 2.489967198863158

Epoch: 5| Step: 6
Training loss: 0.2926444356665035
Validation loss: 2.497944527269962

Epoch: 5| Step: 7
Training loss: 0.1553774671128525
Validation loss: 2.453197958625291

Epoch: 5| Step: 8
Training loss: 0.19266341411886287
Validation loss: 2.471126916322705

Epoch: 5| Step: 9
Training loss: 0.19632576366845833
Validation loss: 2.436462053038681

Epoch: 5| Step: 10
Training loss: 0.13591347323116312
Validation loss: 2.463669101090331

Epoch: 550| Step: 0
Training loss: 0.1897818476219824
Validation loss: 2.458047663729237

Epoch: 5| Step: 1
Training loss: 0.17521662630291288
Validation loss: 2.4785741361805904

Epoch: 5| Step: 2
Training loss: 0.17903779578431847
Validation loss: 2.4719381581302162

Epoch: 5| Step: 3
Training loss: 0.26586625419009663
Validation loss: 2.4931458703175107

Epoch: 5| Step: 4
Training loss: 0.20597194981162223
Validation loss: 2.467531092570304

Epoch: 5| Step: 5
Training loss: 0.21603767530812373
Validation loss: 2.495148196141197

Epoch: 5| Step: 6
Training loss: 0.1339016739765566
Validation loss: 2.4854648011068203

Epoch: 5| Step: 7
Training loss: 0.18999703972794157
Validation loss: 2.4962787342982655

Epoch: 5| Step: 8
Training loss: 0.17508073140952926
Validation loss: 2.4801067944423694

Epoch: 5| Step: 9
Training loss: 0.1292160386535626
Validation loss: 2.5073774357343037

Epoch: 5| Step: 10
Training loss: 0.07554429370864833
Validation loss: 2.4730052037245924

Epoch: 551| Step: 0
Training loss: 0.20049731108355942
Validation loss: 2.4640250452514305

Epoch: 5| Step: 1
Training loss: 0.11982035207066874
Validation loss: 2.475762999009226

Epoch: 5| Step: 2
Training loss: 0.14592023301132567
Validation loss: 2.481087040568043

Epoch: 5| Step: 3
Training loss: 0.206687542973881
Validation loss: 2.4787714074278857

Epoch: 5| Step: 4
Training loss: 0.1347486305578601
Validation loss: 2.5020918339260305

Epoch: 5| Step: 5
Training loss: 0.24138813228580666
Validation loss: 2.512396131133805

Epoch: 5| Step: 6
Training loss: 0.2295898716584598
Validation loss: 2.5137257133149333

Epoch: 5| Step: 7
Training loss: 0.2382759734648272
Validation loss: 2.5383486507988007

Epoch: 5| Step: 8
Training loss: 0.21294099754258025
Validation loss: 2.520888961941613

Epoch: 5| Step: 9
Training loss: 0.2611942729651432
Validation loss: 2.530051054416094

Epoch: 5| Step: 10
Training loss: 0.20892863555267943
Validation loss: 2.5245216545206843

Epoch: 552| Step: 0
Training loss: 0.17849819882937357
Validation loss: 2.5354559352602033

Epoch: 5| Step: 1
Training loss: 0.1461622511051949
Validation loss: 2.5257152164174483

Epoch: 5| Step: 2
Training loss: 0.23991360221867583
Validation loss: 2.5400585357016325

Epoch: 5| Step: 3
Training loss: 0.25584833834773707
Validation loss: 2.513622933599959

Epoch: 5| Step: 4
Training loss: 0.27223163102448633
Validation loss: 2.545499175233414

Epoch: 5| Step: 5
Training loss: 0.16718885764346192
Validation loss: 2.5000085758759445

Epoch: 5| Step: 6
Training loss: 0.2152983364462867
Validation loss: 2.5213143550707686

Epoch: 5| Step: 7
Training loss: 0.1435077940974955
Validation loss: 2.544876383433702

Epoch: 5| Step: 8
Training loss: 0.16607051951570498
Validation loss: 2.4885804032932497

Epoch: 5| Step: 9
Training loss: 0.18916147927770313
Validation loss: 2.479175941599532

Epoch: 5| Step: 10
Training loss: 0.27474704238143166
Validation loss: 2.472321739289257

Epoch: 553| Step: 0
Training loss: 0.18855427340692602
Validation loss: 2.481008235706056

Epoch: 5| Step: 1
Training loss: 0.21476817969408643
Validation loss: 2.4950873765099115

Epoch: 5| Step: 2
Training loss: 0.17499784634320792
Validation loss: 2.48240944311501

Epoch: 5| Step: 3
Training loss: 0.20795479398770364
Validation loss: 2.506423252072643

Epoch: 5| Step: 4
Training loss: 0.3069752853289708
Validation loss: 2.4966375288310454

Epoch: 5| Step: 5
Training loss: 0.18150960647497055
Validation loss: 2.5011702177775836

Epoch: 5| Step: 6
Training loss: 0.20963176384501736
Validation loss: 2.5243559415251515

Epoch: 5| Step: 7
Training loss: 0.21304179432780143
Validation loss: 2.4993380777780523

Epoch: 5| Step: 8
Training loss: 0.23958307072721824
Validation loss: 2.490504712481689

Epoch: 5| Step: 9
Training loss: 0.19272986927494756
Validation loss: 2.503986804708081

Epoch: 5| Step: 10
Training loss: 0.1972762378821537
Validation loss: 2.5294444659507525

Epoch: 554| Step: 0
Training loss: 0.1362516325231619
Validation loss: 2.569268870616381

Epoch: 5| Step: 1
Training loss: 0.199301487440496
Validation loss: 2.536316356352186

Epoch: 5| Step: 2
Training loss: 0.24326039133586455
Validation loss: 2.5394335161589496

Epoch: 5| Step: 3
Training loss: 0.17031723374603872
Validation loss: 2.5659574578668916

Epoch: 5| Step: 4
Training loss: 0.19812332310553574
Validation loss: 2.5291377442695575

Epoch: 5| Step: 5
Training loss: 0.24254881148820723
Validation loss: 2.520196576107299

Epoch: 5| Step: 6
Training loss: 0.18018841376124206
Validation loss: 2.5298715025869862

Epoch: 5| Step: 7
Training loss: 0.26167820858455615
Validation loss: 2.52670405720475

Epoch: 5| Step: 8
Training loss: 0.2262911487011035
Validation loss: 2.5187121570312976

Epoch: 5| Step: 9
Training loss: 0.1499727189567621
Validation loss: 2.541417143092351

Epoch: 5| Step: 10
Training loss: 0.2701571977597629
Validation loss: 2.535191295143976

Epoch: 555| Step: 0
Training loss: 0.20990322118178037
Validation loss: 2.521811882583557

Epoch: 5| Step: 1
Training loss: 0.1656849260151848
Validation loss: 2.559935173330173

Epoch: 5| Step: 2
Training loss: 0.1841896410423806
Validation loss: 2.534227619377379

Epoch: 5| Step: 3
Training loss: 0.24771674407131425
Validation loss: 2.529000890766761

Epoch: 5| Step: 4
Training loss: 0.17367515905778486
Validation loss: 2.52854834404208

Epoch: 5| Step: 5
Training loss: 0.27116843577198435
Validation loss: 2.5302631718665607

Epoch: 5| Step: 6
Training loss: 0.1753959140957134
Validation loss: 2.577749065436518

Epoch: 5| Step: 7
Training loss: 0.17878311033969638
Validation loss: 2.5823736369780743

Epoch: 5| Step: 8
Training loss: 0.15141744087087267
Validation loss: 2.5410679159523495

Epoch: 5| Step: 9
Training loss: 0.14572430193413682
Validation loss: 2.536710659667193

Epoch: 5| Step: 10
Training loss: 0.1385450051438443
Validation loss: 2.532874867661174

Epoch: 556| Step: 0
Training loss: 0.14206434460225728
Validation loss: 2.5546599255520266

Epoch: 5| Step: 1
Training loss: 0.1489253810189294
Validation loss: 2.549828071597137

Epoch: 5| Step: 2
Training loss: 0.1919383904030561
Validation loss: 2.516584886464797

Epoch: 5| Step: 3
Training loss: 0.10358627175831667
Validation loss: 2.5222657955119137

Epoch: 5| Step: 4
Training loss: 0.19503709449439866
Validation loss: 2.532786061881622

Epoch: 5| Step: 5
Training loss: 0.13592329225065491
Validation loss: 2.4916947405787147

Epoch: 5| Step: 6
Training loss: 0.255845863043741
Validation loss: 2.494887111483169

Epoch: 5| Step: 7
Training loss: 0.1580392553969542
Validation loss: 2.498057563454394

Epoch: 5| Step: 8
Training loss: 0.21728853373099213
Validation loss: 2.498422298154148

Epoch: 5| Step: 9
Training loss: 0.12608822597755287
Validation loss: 2.482234431753454

Epoch: 5| Step: 10
Training loss: 0.07712872168759646
Validation loss: 2.4908913720034445

Epoch: 557| Step: 0
Training loss: 0.16193167012077084
Validation loss: 2.4973392827691336

Epoch: 5| Step: 1
Training loss: 0.20596968899968465
Validation loss: 2.4629755485537386

Epoch: 5| Step: 2
Training loss: 0.13779651358821218
Validation loss: 2.5173880823425776

Epoch: 5| Step: 3
Training loss: 0.2651333747217323
Validation loss: 2.493661244220528

Epoch: 5| Step: 4
Training loss: 0.17920963350637545
Validation loss: 2.4947860481020308

Epoch: 5| Step: 5
Training loss: 0.17279698431575707
Validation loss: 2.5212052722685656

Epoch: 5| Step: 6
Training loss: 0.14048199534954398
Validation loss: 2.5086438800704447

Epoch: 5| Step: 7
Training loss: 0.11343544298729241
Validation loss: 2.477722927639358

Epoch: 5| Step: 8
Training loss: 0.08095893316945325
Validation loss: 2.497884567021514

Epoch: 5| Step: 9
Training loss: 0.227295118551036
Validation loss: 2.506762208771616

Epoch: 5| Step: 10
Training loss: 0.1530832109551606
Validation loss: 2.5139735625395923

Epoch: 558| Step: 0
Training loss: 0.22490004928816462
Validation loss: 2.522000023414492

Epoch: 5| Step: 1
Training loss: 0.12592638480212845
Validation loss: 2.5163354560226354

Epoch: 5| Step: 2
Training loss: 0.23016080649812637
Validation loss: 2.502395800647407

Epoch: 5| Step: 3
Training loss: 0.1283133192784111
Validation loss: 2.5292118140718274

Epoch: 5| Step: 4
Training loss: 0.13806687942490717
Validation loss: 2.504212020401345

Epoch: 5| Step: 5
Training loss: 0.14043665564893967
Validation loss: 2.529403765731143

Epoch: 5| Step: 6
Training loss: 0.2316938265195772
Validation loss: 2.5148157290500954

Epoch: 5| Step: 7
Training loss: 0.2105348328807444
Validation loss: 2.500120870683107

Epoch: 5| Step: 8
Training loss: 0.1025388263518021
Validation loss: 2.4866741003407986

Epoch: 5| Step: 9
Training loss: 0.17358352296234056
Validation loss: 2.488266683777877

Epoch: 5| Step: 10
Training loss: 0.16506275593803868
Validation loss: 2.4763301700147258

Epoch: 559| Step: 0
Training loss: 0.14185429742353942
Validation loss: 2.488592192437736

Epoch: 5| Step: 1
Training loss: 0.21382715556015897
Validation loss: 2.4825459560106977

Epoch: 5| Step: 2
Training loss: 0.1604083043298912
Validation loss: 2.4949897449248213

Epoch: 5| Step: 3
Training loss: 0.14691408073670634
Validation loss: 2.5219514713347184

Epoch: 5| Step: 4
Training loss: 0.08775985313860951
Validation loss: 2.5335239520299315

Epoch: 5| Step: 5
Training loss: 0.1694896671171952
Validation loss: 2.491107710997238

Epoch: 5| Step: 6
Training loss: 0.17041036392680195
Validation loss: 2.549619496335889

Epoch: 5| Step: 7
Training loss: 0.305986983376137
Validation loss: 2.538109048266913

Epoch: 5| Step: 8
Training loss: 0.21969152383117302
Validation loss: 2.561168233044646

Epoch: 5| Step: 9
Training loss: 0.1320647761423623
Validation loss: 2.5277484610905905

Epoch: 5| Step: 10
Training loss: 0.17508853477977834
Validation loss: 2.5250426221101394

Epoch: 560| Step: 0
Training loss: 0.183360601062682
Validation loss: 2.5192200176181387

Epoch: 5| Step: 1
Training loss: 0.20585436371525312
Validation loss: 2.5287892189322227

Epoch: 5| Step: 2
Training loss: 0.19288930686231465
Validation loss: 2.5165761439811765

Epoch: 5| Step: 3
Training loss: 0.18154623799204483
Validation loss: 2.529186787856113

Epoch: 5| Step: 4
Training loss: 0.16172842282470562
Validation loss: 2.5139608277893863

Epoch: 5| Step: 5
Training loss: 0.17910060195914876
Validation loss: 2.5304782227134086

Epoch: 5| Step: 6
Training loss: 0.1493924692545008
Validation loss: 2.542864307703313

Epoch: 5| Step: 7
Training loss: 0.09325727981468937
Validation loss: 2.542353792540949

Epoch: 5| Step: 8
Training loss: 0.21299002890239332
Validation loss: 2.546523009899313

Epoch: 5| Step: 9
Training loss: 0.2717214413773375
Validation loss: 2.572629877648613

Epoch: 5| Step: 10
Training loss: 0.17379192446827735
Validation loss: 2.5190227280584936

Epoch: 561| Step: 0
Training loss: 0.18544284514311563
Validation loss: 2.5705552933841354

Epoch: 5| Step: 1
Training loss: 0.15972956364686267
Validation loss: 2.5313646064476583

Epoch: 5| Step: 2
Training loss: 0.1612810031432192
Validation loss: 2.5149165838607033

Epoch: 5| Step: 3
Training loss: 0.19611438171546014
Validation loss: 2.4850409542543495

Epoch: 5| Step: 4
Training loss: 0.16126058309963845
Validation loss: 2.4726755820266115

Epoch: 5| Step: 5
Training loss: 0.261902075940557
Validation loss: 2.5155194514587644

Epoch: 5| Step: 6
Training loss: 0.31384942052531534
Validation loss: 2.503709960828363

Epoch: 5| Step: 7
Training loss: 0.15274896283741915
Validation loss: 2.5472411644840904

Epoch: 5| Step: 8
Training loss: 0.22366450222653975
Validation loss: 2.567380246244709

Epoch: 5| Step: 9
Training loss: 0.14892501205495837
Validation loss: 2.565890268706853

Epoch: 5| Step: 10
Training loss: 0.1271092262103072
Validation loss: 2.565799415821758

Epoch: 562| Step: 0
Training loss: 0.24504646101585037
Validation loss: 2.5706594695333154

Epoch: 5| Step: 1
Training loss: 0.23350862272400813
Validation loss: 2.595652610271043

Epoch: 5| Step: 2
Training loss: 0.21000729426136291
Validation loss: 2.5976433185480965

Epoch: 5| Step: 3
Training loss: 0.2226398110595363
Validation loss: 2.5709163713057217

Epoch: 5| Step: 4
Training loss: 0.22914238100260195
Validation loss: 2.539246468643318

Epoch: 5| Step: 5
Training loss: 0.13761461883018744
Validation loss: 2.540970169940489

Epoch: 5| Step: 6
Training loss: 0.23793922955060007
Validation loss: 2.525540492673918

Epoch: 5| Step: 7
Training loss: 0.2319517269073114
Validation loss: 2.496465014197888

Epoch: 5| Step: 8
Training loss: 0.23586968021933638
Validation loss: 2.4842748272859305

Epoch: 5| Step: 9
Training loss: 0.12740032951777974
Validation loss: 2.4945087776425527

Epoch: 5| Step: 10
Training loss: 0.1781993798510842
Validation loss: 2.491816412280555

Epoch: 563| Step: 0
Training loss: 0.17639607882509833
Validation loss: 2.5031554847827278

Epoch: 5| Step: 1
Training loss: 0.18194472585499413
Validation loss: 2.5055674384932294

Epoch: 5| Step: 2
Training loss: 0.22408037501424377
Validation loss: 2.4864529173649776

Epoch: 5| Step: 3
Training loss: 0.08963852746579708
Validation loss: 2.5242052671953377

Epoch: 5| Step: 4
Training loss: 0.111665749148732
Validation loss: 2.5342707933550637

Epoch: 5| Step: 5
Training loss: 0.16260749626742163
Validation loss: 2.4941692426618802

Epoch: 5| Step: 6
Training loss: 0.11154194426095301
Validation loss: 2.5061480828582035

Epoch: 5| Step: 7
Training loss: 0.200217501643424
Validation loss: 2.533620063307363

Epoch: 5| Step: 8
Training loss: 0.17402666519202972
Validation loss: 2.515191734555193

Epoch: 5| Step: 9
Training loss: 0.1657421440036347
Validation loss: 2.5347095356764817

Epoch: 5| Step: 10
Training loss: 0.22586864245259725
Validation loss: 2.5052838743374566

Epoch: 564| Step: 0
Training loss: 0.12594708386106612
Validation loss: 2.520072464884985

Epoch: 5| Step: 1
Training loss: 0.1106188330978865
Validation loss: 2.4962450520463544

Epoch: 5| Step: 2
Training loss: 0.16431213868508818
Validation loss: 2.528006290863458

Epoch: 5| Step: 3
Training loss: 0.20246012702792923
Validation loss: 2.527594183489484

Epoch: 5| Step: 4
Training loss: 0.10704688598416714
Validation loss: 2.4879432686035914

Epoch: 5| Step: 5
Training loss: 0.18631196141860956
Validation loss: 2.461204934877094

Epoch: 5| Step: 6
Training loss: 0.2303485637804049
Validation loss: 2.516525107522429

Epoch: 5| Step: 7
Training loss: 0.2447380766477532
Validation loss: 2.507199063489334

Epoch: 5| Step: 8
Training loss: 0.14771401874816745
Validation loss: 2.459354012159194

Epoch: 5| Step: 9
Training loss: 0.17294956381713286
Validation loss: 2.4912240674217494

Epoch: 5| Step: 10
Training loss: 0.13317479478373756
Validation loss: 2.518191280619343

Epoch: 565| Step: 0
Training loss: 0.12440560999353288
Validation loss: 2.5148164222521348

Epoch: 5| Step: 1
Training loss: 0.09978743607490219
Validation loss: 2.5012875430580497

Epoch: 5| Step: 2
Training loss: 0.13270855089416317
Validation loss: 2.5110692023032763

Epoch: 5| Step: 3
Training loss: 0.2760517490393048
Validation loss: 2.5284077040393553

Epoch: 5| Step: 4
Training loss: 0.13783369483068142
Validation loss: 2.509246463226958

Epoch: 5| Step: 5
Training loss: 0.19055122996128243
Validation loss: 2.540503598053386

Epoch: 5| Step: 6
Training loss: 0.17346043757240467
Validation loss: 2.5291503620556384

Epoch: 5| Step: 7
Training loss: 0.1077247986814765
Validation loss: 2.54588532874467

Epoch: 5| Step: 8
Training loss: 0.2117072471787744
Validation loss: 2.5445605704268863

Epoch: 5| Step: 9
Training loss: 0.11544778830387949
Validation loss: 2.5016933079968937

Epoch: 5| Step: 10
Training loss: 0.19841956673335473
Validation loss: 2.4957411586653366

Epoch: 566| Step: 0
Training loss: 0.16183833938794037
Validation loss: 2.539111522519994

Epoch: 5| Step: 1
Training loss: 0.14149314412957392
Validation loss: 2.5113757471541818

Epoch: 5| Step: 2
Training loss: 0.18603765931535618
Validation loss: 2.496127030663978

Epoch: 5| Step: 3
Training loss: 0.21682366214257204
Validation loss: 2.5202882347375346

Epoch: 5| Step: 4
Training loss: 0.1443485058382767
Validation loss: 2.5249587012290147

Epoch: 5| Step: 5
Training loss: 0.17088274202479203
Validation loss: 2.5278209813830594

Epoch: 5| Step: 6
Training loss: 0.10981410303395034
Validation loss: 2.509475800953513

Epoch: 5| Step: 7
Training loss: 0.1245386132010299
Validation loss: 2.5328549940851044

Epoch: 5| Step: 8
Training loss: 0.21191539851879398
Validation loss: 2.5358021612946224

Epoch: 5| Step: 9
Training loss: 0.2549276349056746
Validation loss: 2.5743845096822344

Epoch: 5| Step: 10
Training loss: 0.12747967901696808
Validation loss: 2.5558314117323095

Epoch: 567| Step: 0
Training loss: 0.24028582913553498
Validation loss: 2.5473215615189453

Epoch: 5| Step: 1
Training loss: 0.19994722206397178
Validation loss: 2.5525022951793748

Epoch: 5| Step: 2
Training loss: 0.06630570850640226
Validation loss: 2.5391327737654827

Epoch: 5| Step: 3
Training loss: 0.16967963347984547
Validation loss: 2.5641614378499638

Epoch: 5| Step: 4
Training loss: 0.08347275056288743
Validation loss: 2.497527650448924

Epoch: 5| Step: 5
Training loss: 0.14275933207749722
Validation loss: 2.532363925018531

Epoch: 5| Step: 6
Training loss: 0.11782993808621607
Validation loss: 2.5456479295694847

Epoch: 5| Step: 7
Training loss: 0.12983035699053083
Validation loss: 2.524719950682826

Epoch: 5| Step: 8
Training loss: 0.18751388736794203
Validation loss: 2.5219279832711927

Epoch: 5| Step: 9
Training loss: 0.15506707279400228
Validation loss: 2.527234865058084

Epoch: 5| Step: 10
Training loss: 0.22999426927890682
Validation loss: 2.5448703684003493

Epoch: 568| Step: 0
Training loss: 0.16540638265202628
Validation loss: 2.5173342383372694

Epoch: 5| Step: 1
Training loss: 0.17086433070303914
Validation loss: 2.528316642940353

Epoch: 5| Step: 2
Training loss: 0.13391114672206086
Validation loss: 2.564500135669974

Epoch: 5| Step: 3
Training loss: 0.19779732309970652
Validation loss: 2.546960292374182

Epoch: 5| Step: 4
Training loss: 0.19073319335206468
Validation loss: 2.545722050711254

Epoch: 5| Step: 5
Training loss: 0.078963279534075
Validation loss: 2.5695544697016928

Epoch: 5| Step: 6
Training loss: 0.09370569334506618
Validation loss: 2.544929444256753

Epoch: 5| Step: 7
Training loss: 0.21663945299196774
Validation loss: 2.5370395979235334

Epoch: 5| Step: 8
Training loss: 0.19777877086159104
Validation loss: 2.5607967804013674

Epoch: 5| Step: 9
Training loss: 0.1121393645445471
Validation loss: 2.5516798167928267

Epoch: 5| Step: 10
Training loss: 0.17627410671392993
Validation loss: 2.5452589218358597

Epoch: 569| Step: 0
Training loss: 0.1593521330828316
Validation loss: 2.5313243057483352

Epoch: 5| Step: 1
Training loss: 0.11262491017119988
Validation loss: 2.5580503927435614

Epoch: 5| Step: 2
Training loss: 0.1795507615644514
Validation loss: 2.519653594103989

Epoch: 5| Step: 3
Training loss: 0.15845555899476949
Validation loss: 2.5316711241567638

Epoch: 5| Step: 4
Training loss: 0.22654362303919467
Validation loss: 2.5544924514017295

Epoch: 5| Step: 5
Training loss: 0.14324444703753456
Validation loss: 2.538101359178884

Epoch: 5| Step: 6
Training loss: 0.11364692827175703
Validation loss: 2.5250235630878435

Epoch: 5| Step: 7
Training loss: 0.1269598005447056
Validation loss: 2.49210164513764

Epoch: 5| Step: 8
Training loss: 0.19658262211975652
Validation loss: 2.523006655268416

Epoch: 5| Step: 9
Training loss: 0.17321897779157602
Validation loss: 2.5080348852141827

Epoch: 5| Step: 10
Training loss: 0.11205723493747338
Validation loss: 2.5459820392196066

Epoch: 570| Step: 0
Training loss: 0.16811629402210046
Validation loss: 2.50874281251971

Epoch: 5| Step: 1
Training loss: 0.1194367948712904
Validation loss: 2.492243152528977

Epoch: 5| Step: 2
Training loss: 0.12025780704151083
Validation loss: 2.525015696579635

Epoch: 5| Step: 3
Training loss: 0.20968739633230726
Validation loss: 2.5415518109537905

Epoch: 5| Step: 4
Training loss: 0.15076448367099274
Validation loss: 2.5032640181631955

Epoch: 5| Step: 5
Training loss: 0.15846928824038264
Validation loss: 2.535594579770827

Epoch: 5| Step: 6
Training loss: 0.22083449041015463
Validation loss: 2.5424313947256634

Epoch: 5| Step: 7
Training loss: 0.21548778929767035
Validation loss: 2.5234286268352486

Epoch: 5| Step: 8
Training loss: 0.11271307952298666
Validation loss: 2.544683378492557

Epoch: 5| Step: 9
Training loss: 0.10285648986105562
Validation loss: 2.531914906619946

Epoch: 5| Step: 10
Training loss: 0.06241243531558778
Validation loss: 2.534332280533403

Epoch: 571| Step: 0
Training loss: 0.17583360422164004
Validation loss: 2.529533447320939

Epoch: 5| Step: 1
Training loss: 0.1546806560312438
Validation loss: 2.567022321867005

Epoch: 5| Step: 2
Training loss: 0.14208374141422894
Validation loss: 2.5473230409358734

Epoch: 5| Step: 3
Training loss: 0.07230954188966396
Validation loss: 2.5243613620829164

Epoch: 5| Step: 4
Training loss: 0.10932239050584834
Validation loss: 2.511747502161586

Epoch: 5| Step: 5
Training loss: 0.11188212799561831
Validation loss: 2.5358554701188196

Epoch: 5| Step: 6
Training loss: 0.14532757803921972
Validation loss: 2.5023220568633064

Epoch: 5| Step: 7
Training loss: 0.14463379160726275
Validation loss: 2.532965777035563

Epoch: 5| Step: 8
Training loss: 0.18463169066342106
Validation loss: 2.519990187285825

Epoch: 5| Step: 9
Training loss: 0.24008010935436574
Validation loss: 2.500060900079717

Epoch: 5| Step: 10
Training loss: 0.21534871666029662
Validation loss: 2.527878053165132

Epoch: 572| Step: 0
Training loss: 0.12675430428186374
Validation loss: 2.5316494786380606

Epoch: 5| Step: 1
Training loss: 0.15359732029006612
Validation loss: 2.5530799639137443

Epoch: 5| Step: 2
Training loss: 0.12944590430418254
Validation loss: 2.50217447158871

Epoch: 5| Step: 3
Training loss: 0.15116474396005272
Validation loss: 2.558881963187056

Epoch: 5| Step: 4
Training loss: 0.2546587723052243
Validation loss: 2.5326005742437605

Epoch: 5| Step: 5
Training loss: 0.17257039321772494
Validation loss: 2.552495476545145

Epoch: 5| Step: 6
Training loss: 0.12655961598536522
Validation loss: 2.526783116054653

Epoch: 5| Step: 7
Training loss: 0.12897158180947185
Validation loss: 2.5457483091100452

Epoch: 5| Step: 8
Training loss: 0.05496359001976173
Validation loss: 2.5214273720146454

Epoch: 5| Step: 9
Training loss: 0.20056292579239546
Validation loss: 2.5229486045002396

Epoch: 5| Step: 10
Training loss: 0.13994363781679744
Validation loss: 2.53016344553427

Epoch: 573| Step: 0
Training loss: 0.14432068900370681
Validation loss: 2.530601735458349

Epoch: 5| Step: 1
Training loss: 0.13724891186327992
Validation loss: 2.502907168107284

Epoch: 5| Step: 2
Training loss: 0.08552192864237405
Validation loss: 2.5297941819273513

Epoch: 5| Step: 3
Training loss: 0.0770131627295011
Validation loss: 2.487310903584998

Epoch: 5| Step: 4
Training loss: 0.1784823054764982
Validation loss: 2.5245515373328815

Epoch: 5| Step: 5
Training loss: 0.161718995789788
Validation loss: 2.5195020656957494

Epoch: 5| Step: 6
Training loss: 0.09470308642157665
Validation loss: 2.531355507374918

Epoch: 5| Step: 7
Training loss: 0.09746627926760223
Validation loss: 2.524581828010898

Epoch: 5| Step: 8
Training loss: 0.15723111163838097
Validation loss: 2.5501445396528926

Epoch: 5| Step: 9
Training loss: 0.20943600883112412
Validation loss: 2.535095493216778

Epoch: 5| Step: 10
Training loss: 0.23849840899852487
Validation loss: 2.537887185611395

Epoch: 574| Step: 0
Training loss: 0.12763307124021345
Validation loss: 2.564268062971784

Epoch: 5| Step: 1
Training loss: 0.10522856561078386
Validation loss: 2.5474048573927695

Epoch: 5| Step: 2
Training loss: 0.1779618118045611
Validation loss: 2.5595761577739475

Epoch: 5| Step: 3
Training loss: 0.16891830426906546
Validation loss: 2.5501865449424934

Epoch: 5| Step: 4
Training loss: 0.21830130437860115
Validation loss: 2.53779477057611

Epoch: 5| Step: 5
Training loss: 0.15343021292970166
Validation loss: 2.524430906171709

Epoch: 5| Step: 6
Training loss: 0.21158793620487543
Validation loss: 2.5264457627217327

Epoch: 5| Step: 7
Training loss: 0.08740684028865327
Validation loss: 2.522343125379711

Epoch: 5| Step: 8
Training loss: 0.09874514518797381
Validation loss: 2.5024737680875275

Epoch: 5| Step: 9
Training loss: 0.14668207814265943
Validation loss: 2.5298893881188103

Epoch: 5| Step: 10
Training loss: 0.10486934902223101
Validation loss: 2.5301420054704744

Epoch: 575| Step: 0
Training loss: 0.1073603974333773
Validation loss: 2.5249621238698365

Epoch: 5| Step: 1
Training loss: 0.13126952389417826
Validation loss: 2.5448375136363337

Epoch: 5| Step: 2
Training loss: 0.23702004712360472
Validation loss: 2.53070521901331

Epoch: 5| Step: 3
Training loss: 0.17865625180559222
Validation loss: 2.505635830847492

Epoch: 5| Step: 4
Training loss: 0.1150442996557363
Validation loss: 2.5228526191517506

Epoch: 5| Step: 5
Training loss: 0.21028954274343478
Validation loss: 2.5256200234047874

Epoch: 5| Step: 6
Training loss: 0.1660449899620487
Validation loss: 2.557455338114875

Epoch: 5| Step: 7
Training loss: 0.24297322210875627
Validation loss: 2.5677370988633625

Epoch: 5| Step: 8
Training loss: 0.11857200382974571
Validation loss: 2.539647763229656

Epoch: 5| Step: 9
Training loss: 0.22177944375525854
Validation loss: 2.5805352587043546

Epoch: 5| Step: 10
Training loss: 0.1511094452340392
Validation loss: 2.5490052784576505

Epoch: 576| Step: 0
Training loss: 0.11892993072748512
Validation loss: 2.534061454053728

Epoch: 5| Step: 1
Training loss: 0.11292468467960372
Validation loss: 2.5321593034456993

Epoch: 5| Step: 2
Training loss: 0.18454932037947702
Validation loss: 2.507536273768727

Epoch: 5| Step: 3
Training loss: 0.12601531711595151
Validation loss: 2.4673873735927287

Epoch: 5| Step: 4
Training loss: 0.19473924432932288
Validation loss: 2.4986600053415007

Epoch: 5| Step: 5
Training loss: 0.17884434999294976
Validation loss: 2.493843445266013

Epoch: 5| Step: 6
Training loss: 0.141302404419726
Validation loss: 2.479166202712298

Epoch: 5| Step: 7
Training loss: 0.1019621834074144
Validation loss: 2.49673498303399

Epoch: 5| Step: 8
Training loss: 0.19780262476480875
Validation loss: 2.4970107116455993

Epoch: 5| Step: 9
Training loss: 0.16384323545233623
Validation loss: 2.491022546015109

Epoch: 5| Step: 10
Training loss: 0.21088961658235272
Validation loss: 2.5335441613618865

Epoch: 577| Step: 0
Training loss: 0.11155705170858131
Validation loss: 2.572032509683236

Epoch: 5| Step: 1
Training loss: 0.22754914748472826
Validation loss: 2.5460646806293474

Epoch: 5| Step: 2
Training loss: 0.16569604969161936
Validation loss: 2.556742018850403

Epoch: 5| Step: 3
Training loss: 0.1815562205944059
Validation loss: 2.5309435427104408

Epoch: 5| Step: 4
Training loss: 0.07439158418025402
Validation loss: 2.532296781986567

Epoch: 5| Step: 5
Training loss: 0.22793683496037734
Validation loss: 2.5965220324401606

Epoch: 5| Step: 6
Training loss: 0.17376796881637985
Validation loss: 2.5693232646223363

Epoch: 5| Step: 7
Training loss: 0.09625172539192503
Validation loss: 2.553776486551828

Epoch: 5| Step: 8
Training loss: 0.10414410485866106
Validation loss: 2.5559697122855467

Epoch: 5| Step: 9
Training loss: 0.09746452584856372
Validation loss: 2.5524297128006572

Epoch: 5| Step: 10
Training loss: 0.11088018061497035
Validation loss: 2.5443829876044175

Epoch: 578| Step: 0
Training loss: 0.1782190818950754
Validation loss: 2.5222323246032374

Epoch: 5| Step: 1
Training loss: 0.177701475431111
Validation loss: 2.5261122933551023

Epoch: 5| Step: 2
Training loss: 0.18365787847062096
Validation loss: 2.5269828300684396

Epoch: 5| Step: 3
Training loss: 0.20298437606063324
Validation loss: 2.5563915247305964

Epoch: 5| Step: 4
Training loss: 0.07776213658192256
Validation loss: 2.553747726731023

Epoch: 5| Step: 5
Training loss: 0.09452218690097382
Validation loss: 2.5321590817229493

Epoch: 5| Step: 6
Training loss: 0.10609634311973377
Validation loss: 2.5595080503896326

Epoch: 5| Step: 7
Training loss: 0.08451313911991734
Validation loss: 2.514138440525787

Epoch: 5| Step: 8
Training loss: 0.19450253385754093
Validation loss: 2.535328570850338

Epoch: 5| Step: 9
Training loss: 0.09413181477392397
Validation loss: 2.5290672353519934

Epoch: 5| Step: 10
Training loss: 0.14137769300095016
Validation loss: 2.5454101748824987

Epoch: 579| Step: 0
Training loss: 0.1506443793445535
Validation loss: 2.5498739614349226

Epoch: 5| Step: 1
Training loss: 0.21161900032109995
Validation loss: 2.5518597901520295

Epoch: 5| Step: 2
Training loss: 0.10105961311701782
Validation loss: 2.557595515488532

Epoch: 5| Step: 3
Training loss: 0.09926683769944422
Validation loss: 2.5323729890851623

Epoch: 5| Step: 4
Training loss: 0.2007982061328777
Validation loss: 2.5328370788867094

Epoch: 5| Step: 5
Training loss: 0.12126754010790382
Validation loss: 2.525681630339157

Epoch: 5| Step: 6
Training loss: 0.10372820205812032
Validation loss: 2.5000480877958253

Epoch: 5| Step: 7
Training loss: 0.10375159736345813
Validation loss: 2.529527527556372

Epoch: 5| Step: 8
Training loss: 0.2019479835785484
Validation loss: 2.5385134554063367

Epoch: 5| Step: 9
Training loss: 0.13614694366012048
Validation loss: 2.540389128401101

Epoch: 5| Step: 10
Training loss: 0.11219818621535088
Validation loss: 2.558872868288822

Epoch: 580| Step: 0
Training loss: 0.11921158225334333
Validation loss: 2.5419513251153685

Epoch: 5| Step: 1
Training loss: 0.20117408788260221
Validation loss: 2.498203544793695

Epoch: 5| Step: 2
Training loss: 0.135885718502364
Validation loss: 2.530204408115098

Epoch: 5| Step: 3
Training loss: 0.18960964973030572
Validation loss: 2.539122966491258

Epoch: 5| Step: 4
Training loss: 0.1561519195760819
Validation loss: 2.5263760995592923

Epoch: 5| Step: 5
Training loss: 0.177492868438023
Validation loss: 2.541498984244347

Epoch: 5| Step: 6
Training loss: 0.1206080324464203
Validation loss: 2.5226726992783934

Epoch: 5| Step: 7
Training loss: 0.09796108352743951
Validation loss: 2.5113835890140215

Epoch: 5| Step: 8
Training loss: 0.12864840613686968
Validation loss: 2.4621668908930086

Epoch: 5| Step: 9
Training loss: 0.0732467332065124
Validation loss: 2.4523634451205583

Epoch: 5| Step: 10
Training loss: 0.14736552025046454
Validation loss: 2.467477585042762

Epoch: 581| Step: 0
Training loss: 0.14712250000175472
Validation loss: 2.46615202409268

Epoch: 5| Step: 1
Training loss: 0.11910731991382772
Validation loss: 2.4566958545914366

Epoch: 5| Step: 2
Training loss: 0.12508268899590688
Validation loss: 2.478461424721099

Epoch: 5| Step: 3
Training loss: 0.08875579454921492
Validation loss: 2.4847920509454964

Epoch: 5| Step: 4
Training loss: 0.2529568013272752
Validation loss: 2.484934308336391

Epoch: 5| Step: 5
Training loss: 0.1203707987249257
Validation loss: 2.470452975329837

Epoch: 5| Step: 6
Training loss: 0.20138965781017562
Validation loss: 2.488827706600577

Epoch: 5| Step: 7
Training loss: 0.12801464550323832
Validation loss: 2.5079894257893818

Epoch: 5| Step: 8
Training loss: 0.08792598331026036
Validation loss: 2.5337821542900363

Epoch: 5| Step: 9
Training loss: 0.12508080523095463
Validation loss: 2.545742643562429

Epoch: 5| Step: 10
Training loss: 0.12453775694610109
Validation loss: 2.512358941991878

Epoch: 582| Step: 0
Training loss: 0.09364982557839323
Validation loss: 2.5201282340558233

Epoch: 5| Step: 1
Training loss: 0.10215240419756616
Validation loss: 2.535394183618084

Epoch: 5| Step: 2
Training loss: 0.19803200464645138
Validation loss: 2.522427396512509

Epoch: 5| Step: 3
Training loss: 0.1373448409491773
Validation loss: 2.549775804455737

Epoch: 5| Step: 4
Training loss: 0.13155639823436927
Validation loss: 2.5644304760780297

Epoch: 5| Step: 5
Training loss: 0.1328925564651919
Validation loss: 2.5761253499950336

Epoch: 5| Step: 6
Training loss: 0.14298201535912133
Validation loss: 2.548350034049367

Epoch: 5| Step: 7
Training loss: 0.19398802856372319
Validation loss: 2.5670460259894208

Epoch: 5| Step: 8
Training loss: 0.1489377564165099
Validation loss: 2.540170199428232

Epoch: 5| Step: 9
Training loss: 0.17973283527507006
Validation loss: 2.5179696157636453

Epoch: 5| Step: 10
Training loss: 0.18797900684813115
Validation loss: 2.5424079637720984

Epoch: 583| Step: 0
Training loss: 0.15537478780041458
Validation loss: 2.513718061571567

Epoch: 5| Step: 1
Training loss: 0.2417802616999981
Validation loss: 2.548796989914903

Epoch: 5| Step: 2
Training loss: 0.11304279008272092
Validation loss: 2.556706425824435

Epoch: 5| Step: 3
Training loss: 0.06962720713742568
Validation loss: 2.52518059774982

Epoch: 5| Step: 4
Training loss: 0.0672224042848831
Validation loss: 2.540134101695035

Epoch: 5| Step: 5
Training loss: 0.14582375653928806
Validation loss: 2.5394440819039876

Epoch: 5| Step: 6
Training loss: 0.11294810455342641
Validation loss: 2.5375748479483082

Epoch: 5| Step: 7
Training loss: 0.1531763615883594
Validation loss: 2.5414596895628967

Epoch: 5| Step: 8
Training loss: 0.1266109256171593
Validation loss: 2.5190749758529276

Epoch: 5| Step: 9
Training loss: 0.10137863204825491
Validation loss: 2.5229299625331474

Epoch: 5| Step: 10
Training loss: 0.2610438027539324
Validation loss: 2.5060025039524945

Epoch: 584| Step: 0
Training loss: 0.10948627210296102
Validation loss: 2.5022719857455646

Epoch: 5| Step: 1
Training loss: 0.19649986789968288
Validation loss: 2.4984342737829963

Epoch: 5| Step: 2
Training loss: 0.12362081023499036
Validation loss: 2.5029578436256865

Epoch: 5| Step: 3
Training loss: 0.13929930305611266
Validation loss: 2.4692905468212034

Epoch: 5| Step: 4
Training loss: 0.1822049490979072
Validation loss: 2.4824145065493486

Epoch: 5| Step: 5
Training loss: 0.14621524883928658
Validation loss: 2.49746914397482

Epoch: 5| Step: 6
Training loss: 0.13078211168805168
Validation loss: 2.4991957591175895

Epoch: 5| Step: 7
Training loss: 0.12169034568312957
Validation loss: 2.5096983196927662

Epoch: 5| Step: 8
Training loss: 0.08493064746010634
Validation loss: 2.496403162744974

Epoch: 5| Step: 9
Training loss: 0.0939130061348577
Validation loss: 2.509952581072359

Epoch: 5| Step: 10
Training loss: 0.22669282814970726
Validation loss: 2.52845097536582

Epoch: 585| Step: 0
Training loss: 0.07149853045072103
Validation loss: 2.5214056527908815

Epoch: 5| Step: 1
Training loss: 0.10258052986533492
Validation loss: 2.518989143325813

Epoch: 5| Step: 2
Training loss: 0.1981173436974933
Validation loss: 2.5054076478350895

Epoch: 5| Step: 3
Training loss: 0.10177224307692823
Validation loss: 2.537114360591316

Epoch: 5| Step: 4
Training loss: 0.19395885593113082
Validation loss: 2.5186222599856847

Epoch: 5| Step: 5
Training loss: 0.11141147755747872
Validation loss: 2.499010689142798

Epoch: 5| Step: 6
Training loss: 0.0900678483124815
Validation loss: 2.5102213761173933

Epoch: 5| Step: 7
Training loss: 0.1557954913031892
Validation loss: 2.52229116177495

Epoch: 5| Step: 8
Training loss: 0.20854796539350834
Validation loss: 2.5284693596506904

Epoch: 5| Step: 9
Training loss: 0.1348847539934898
Validation loss: 2.4828351176440755

Epoch: 5| Step: 10
Training loss: 0.2486238077934875
Validation loss: 2.5308505803679977

Epoch: 586| Step: 0
Training loss: 0.12341501025049512
Validation loss: 2.5093456814750796

Epoch: 5| Step: 1
Training loss: 0.19935025755203292
Validation loss: 2.5791632517194762

Epoch: 5| Step: 2
Training loss: 0.1616099028155963
Validation loss: 2.5504174538628552

Epoch: 5| Step: 3
Training loss: 0.15138486328287215
Validation loss: 2.5470006023342675

Epoch: 5| Step: 4
Training loss: 0.2100061234932431
Validation loss: 2.554936663056884

Epoch: 5| Step: 5
Training loss: 0.15438738715323894
Validation loss: 2.5549250445839715

Epoch: 5| Step: 6
Training loss: 0.08387651836652556
Validation loss: 2.5227892791171254

Epoch: 5| Step: 7
Training loss: 0.12360312736735367
Validation loss: 2.490166024981767

Epoch: 5| Step: 8
Training loss: 0.1795273149754654
Validation loss: 2.482815036614792

Epoch: 5| Step: 9
Training loss: 0.13698292142075721
Validation loss: 2.4933307309334802

Epoch: 5| Step: 10
Training loss: 0.1524285361742275
Validation loss: 2.4690355743478367

Epoch: 587| Step: 0
Training loss: 0.10586223668808802
Validation loss: 2.478759227172033

Epoch: 5| Step: 1
Training loss: 0.1953188418312439
Validation loss: 2.4940373907525646

Epoch: 5| Step: 2
Training loss: 0.16056761596060654
Validation loss: 2.465814517369827

Epoch: 5| Step: 3
Training loss: 0.1484036532512426
Validation loss: 2.486766283231122

Epoch: 5| Step: 4
Training loss: 0.11471978149662139
Validation loss: 2.494663948836751

Epoch: 5| Step: 5
Training loss: 0.17362023362722906
Validation loss: 2.5022822627364567

Epoch: 5| Step: 6
Training loss: 0.14641945990016927
Validation loss: 2.5050984947964046

Epoch: 5| Step: 7
Training loss: 0.18359835598626148
Validation loss: 2.508788347195263

Epoch: 5| Step: 8
Training loss: 0.09697844362228389
Validation loss: 2.522965688615229

Epoch: 5| Step: 9
Training loss: 0.09530960649256931
Validation loss: 2.509641753850201

Epoch: 5| Step: 10
Training loss: 0.15314431020075878
Validation loss: 2.5429286886527933

Epoch: 588| Step: 0
Training loss: 0.14456466340121438
Validation loss: 2.506164352675711

Epoch: 5| Step: 1
Training loss: 0.11027580800550661
Validation loss: 2.535874861714836

Epoch: 5| Step: 2
Training loss: 0.14691737710083538
Validation loss: 2.5290891873032435

Epoch: 5| Step: 3
Training loss: 0.1867461048821779
Validation loss: 2.5155389019838474

Epoch: 5| Step: 4
Training loss: 0.18704954317608652
Validation loss: 2.563195918177555

Epoch: 5| Step: 5
Training loss: 0.221064196252503
Validation loss: 2.5432119847818497

Epoch: 5| Step: 6
Training loss: 0.10056855690427699
Validation loss: 2.5417236518086512

Epoch: 5| Step: 7
Training loss: 0.19140639597050296
Validation loss: 2.5523509350916065

Epoch: 5| Step: 8
Training loss: 0.10087768132960774
Validation loss: 2.5766953109747113

Epoch: 5| Step: 9
Training loss: 0.10984792814000337
Validation loss: 2.544694441274223

Epoch: 5| Step: 10
Training loss: 0.13507752330683528
Validation loss: 2.5461217653585617

Epoch: 589| Step: 0
Training loss: 0.10049594167829143
Validation loss: 2.541608354520558

Epoch: 5| Step: 1
Training loss: 0.10855148010759237
Validation loss: 2.5510311930461733

Epoch: 5| Step: 2
Training loss: 0.18963797881244673
Validation loss: 2.530402194611511

Epoch: 5| Step: 3
Training loss: 0.13034525983215373
Validation loss: 2.5224829438937224

Epoch: 5| Step: 4
Training loss: 0.2226241741165101
Validation loss: 2.519954085332982

Epoch: 5| Step: 5
Training loss: 0.10847097839224928
Validation loss: 2.5100454686518545

Epoch: 5| Step: 6
Training loss: 0.14019144963267488
Validation loss: 2.53810799376479

Epoch: 5| Step: 7
Training loss: 0.11328730895840665
Validation loss: 2.5230946967231827

Epoch: 5| Step: 8
Training loss: 0.18723117909429318
Validation loss: 2.543710510869748

Epoch: 5| Step: 9
Training loss: 0.11924911859049639
Validation loss: 2.5095319588475666

Epoch: 5| Step: 10
Training loss: 0.132256247598675
Validation loss: 2.523336524508914

Epoch: 590| Step: 0
Training loss: 0.12869509105933105
Validation loss: 2.5432167598278794

Epoch: 5| Step: 1
Training loss: 0.11373747017777536
Validation loss: 2.5323052839197007

Epoch: 5| Step: 2
Training loss: 0.12054335581623603
Validation loss: 2.5365464615763753

Epoch: 5| Step: 3
Training loss: 0.15106014982675178
Validation loss: 2.5429605992636786

Epoch: 5| Step: 4
Training loss: 0.22009451680860245
Validation loss: 2.5269862778666012

Epoch: 5| Step: 5
Training loss: 0.1846322455266133
Validation loss: 2.5119857512208674

Epoch: 5| Step: 6
Training loss: 0.19024014943972012
Validation loss: 2.4993070498313092

Epoch: 5| Step: 7
Training loss: 0.13539500399473137
Validation loss: 2.539175887561716

Epoch: 5| Step: 8
Training loss: 0.08875536957803684
Validation loss: 2.5202605962076667

Epoch: 5| Step: 9
Training loss: 0.10020270998827341
Validation loss: 2.5132080484455948

Epoch: 5| Step: 10
Training loss: 0.1395955085485642
Validation loss: 2.5123448388412175

Epoch: 591| Step: 0
Training loss: 0.1088494763169967
Validation loss: 2.502983858786946

Epoch: 5| Step: 1
Training loss: 0.20615794771891013
Validation loss: 2.503951154918627

Epoch: 5| Step: 2
Training loss: 0.1259019763956915
Validation loss: 2.4859380352636147

Epoch: 5| Step: 3
Training loss: 0.11774109575039954
Validation loss: 2.5089525999509505

Epoch: 5| Step: 4
Training loss: 0.09469066018159639
Validation loss: 2.4715877535681963

Epoch: 5| Step: 5
Training loss: 0.16798470110893085
Validation loss: 2.505060854227019

Epoch: 5| Step: 6
Training loss: 0.15513365229477152
Validation loss: 2.521916089725317

Epoch: 5| Step: 7
Training loss: 0.14265144109193584
Validation loss: 2.514304107083982

Epoch: 5| Step: 8
Training loss: 0.10402103515842008
Validation loss: 2.5416954081937817

Epoch: 5| Step: 9
Training loss: 0.21999438599716967
Validation loss: 2.5224055715603826

Epoch: 5| Step: 10
Training loss: 0.15679429143840362
Validation loss: 2.4986748700749852

Epoch: 592| Step: 0
Training loss: 0.16388938489756266
Validation loss: 2.5417798738435464

Epoch: 5| Step: 1
Training loss: 0.18917537267609663
Validation loss: 2.515362875139

Epoch: 5| Step: 2
Training loss: 0.1426690086308257
Validation loss: 2.4788944332409346

Epoch: 5| Step: 3
Training loss: 0.09074143091248461
Validation loss: 2.5075809552169233

Epoch: 5| Step: 4
Training loss: 0.09913575951832032
Validation loss: 2.4789406785539443

Epoch: 5| Step: 5
Training loss: 0.2460902380314262
Validation loss: 2.4664374107220675

Epoch: 5| Step: 6
Training loss: 0.11051280133450402
Validation loss: 2.4691019634190114

Epoch: 5| Step: 7
Training loss: 0.07470920347658466
Validation loss: 2.483816286666288

Epoch: 5| Step: 8
Training loss: 0.14545341089179378
Validation loss: 2.481623376392029

Epoch: 5| Step: 9
Training loss: 0.12092955671020311
Validation loss: 2.5129898425578094

Epoch: 5| Step: 10
Training loss: 0.11563008867484441
Validation loss: 2.500347057986685

Epoch: 593| Step: 0
Training loss: 0.15893411122976012
Validation loss: 2.5082455335540614

Epoch: 5| Step: 1
Training loss: 0.15830790617226823
Validation loss: 2.5258345540708076

Epoch: 5| Step: 2
Training loss: 0.1124745038731705
Validation loss: 2.5152207996769356

Epoch: 5| Step: 3
Training loss: 0.17125767688877236
Validation loss: 2.5528829306825838

Epoch: 5| Step: 4
Training loss: 0.1918842031402785
Validation loss: 2.5301866311984127

Epoch: 5| Step: 5
Training loss: 0.18993698350322122
Validation loss: 2.52603108985614

Epoch: 5| Step: 6
Training loss: 0.1616239691533275
Validation loss: 2.538357558665229

Epoch: 5| Step: 7
Training loss: 0.1429479779334121
Validation loss: 2.5176202607323903

Epoch: 5| Step: 8
Training loss: 0.15092531126379483
Validation loss: 2.511053205718552

Epoch: 5| Step: 9
Training loss: 0.09809858755577154
Validation loss: 2.509450371552679

Epoch: 5| Step: 10
Training loss: 0.14251284215180227
Validation loss: 2.5081784082324976

Epoch: 594| Step: 0
Training loss: 0.165940598757056
Validation loss: 2.501990291037023

Epoch: 5| Step: 1
Training loss: 0.12698190802957407
Validation loss: 2.504560490725615

Epoch: 5| Step: 2
Training loss: 0.1861535043813329
Validation loss: 2.4979685518126975

Epoch: 5| Step: 3
Training loss: 0.08193478702771982
Validation loss: 2.4957173530495678

Epoch: 5| Step: 4
Training loss: 0.14358712173788013
Validation loss: 2.5207064142483473

Epoch: 5| Step: 5
Training loss: 0.15559113587916545
Validation loss: 2.5445146170036343

Epoch: 5| Step: 6
Training loss: 0.17965415976995952
Validation loss: 2.523963432754963

Epoch: 5| Step: 7
Training loss: 0.14780730816027918
Validation loss: 2.5069650316961565

Epoch: 5| Step: 8
Training loss: 0.22559159341963156
Validation loss: 2.509023191219494

Epoch: 5| Step: 9
Training loss: 0.13735528314879125
Validation loss: 2.520062945081601

Epoch: 5| Step: 10
Training loss: 0.131238998792174
Validation loss: 2.536890895635161

Epoch: 595| Step: 0
Training loss: 0.176371563363946
Validation loss: 2.5186914999268684

Epoch: 5| Step: 1
Training loss: 0.10298327999751167
Validation loss: 2.529078601612822

Epoch: 5| Step: 2
Training loss: 0.21510419664698308
Validation loss: 2.5253993004243176

Epoch: 5| Step: 3
Training loss: 0.12208486851691486
Validation loss: 2.5267460346665174

Epoch: 5| Step: 4
Training loss: 0.09536629393852629
Validation loss: 2.495860526408761

Epoch: 5| Step: 5
Training loss: 0.14089598639555725
Validation loss: 2.534782972369645

Epoch: 5| Step: 6
Training loss: 0.13138382707898086
Validation loss: 2.4854165162503663

Epoch: 5| Step: 7
Training loss: 0.13105938699769942
Validation loss: 2.4866178355208413

Epoch: 5| Step: 8
Training loss: 0.1709800634271937
Validation loss: 2.4502380545498377

Epoch: 5| Step: 9
Training loss: 0.16176392619912797
Validation loss: 2.4491653202351866

Epoch: 5| Step: 10
Training loss: 0.1713090867503097
Validation loss: 2.46530814777274

Epoch: 596| Step: 0
Training loss: 0.17499469574485013
Validation loss: 2.456768059680648

Epoch: 5| Step: 1
Training loss: 0.17700774084691565
Validation loss: 2.471685666984502

Epoch: 5| Step: 2
Training loss: 0.16630981409024984
Validation loss: 2.4785993321057607

Epoch: 5| Step: 3
Training loss: 0.23230531318135125
Validation loss: 2.5175006212712203

Epoch: 5| Step: 4
Training loss: 0.12624651794305672
Validation loss: 2.5364219819752023

Epoch: 5| Step: 5
Training loss: 0.200354145588979
Validation loss: 2.5179398589765505

Epoch: 5| Step: 6
Training loss: 0.16311596120076222
Validation loss: 2.543523341958206

Epoch: 5| Step: 7
Training loss: 0.13286114951685657
Validation loss: 2.5452210223100504

Epoch: 5| Step: 8
Training loss: 0.1577199161528756
Validation loss: 2.502972730462116

Epoch: 5| Step: 9
Training loss: 0.1514216478881613
Validation loss: 2.558950385280208

Epoch: 5| Step: 10
Training loss: 0.09090448396291098
Validation loss: 2.518033971955442

Epoch: 597| Step: 0
Training loss: 0.10376748449000424
Validation loss: 2.5301192480017236

Epoch: 5| Step: 1
Training loss: 0.17538717389693934
Validation loss: 2.503157352856366

Epoch: 5| Step: 2
Training loss: 0.10703556650743776
Validation loss: 2.4933693698455124

Epoch: 5| Step: 3
Training loss: 0.12986796875077106
Validation loss: 2.5021852090079104

Epoch: 5| Step: 4
Training loss: 0.16178720702311541
Validation loss: 2.513303409641561

Epoch: 5| Step: 5
Training loss: 0.13509349744350907
Validation loss: 2.4934308487912324

Epoch: 5| Step: 6
Training loss: 0.1640731263125359
Validation loss: 2.515455290819407

Epoch: 5| Step: 7
Training loss: 0.17464868947802076
Validation loss: 2.51491604766991

Epoch: 5| Step: 8
Training loss: 0.18277829249587177
Validation loss: 2.4974288105911286

Epoch: 5| Step: 9
Training loss: 0.13230927583561947
Validation loss: 2.5048470198950876

Epoch: 5| Step: 10
Training loss: 0.21489821523923305
Validation loss: 2.514378055126325

Epoch: 598| Step: 0
Training loss: 0.17761064771161153
Validation loss: 2.4911465752875914

Epoch: 5| Step: 1
Training loss: 0.17721646694447563
Validation loss: 2.516753765688759

Epoch: 5| Step: 2
Training loss: 0.1347561915869246
Validation loss: 2.5377311079580025

Epoch: 5| Step: 3
Training loss: 0.14562882761161286
Validation loss: 2.5359001777780663

Epoch: 5| Step: 4
Training loss: 0.09672975688601987
Validation loss: 2.5288670305616696

Epoch: 5| Step: 5
Training loss: 0.18756283263596782
Validation loss: 2.5222413630781166

Epoch: 5| Step: 6
Training loss: 0.07627156959476766
Validation loss: 2.528917648653317

Epoch: 5| Step: 7
Training loss: 0.1063254845576543
Validation loss: 2.4878898219103194

Epoch: 5| Step: 8
Training loss: 0.20854249031508904
Validation loss: 2.516380525259546

Epoch: 5| Step: 9
Training loss: 0.14653570547385597
Validation loss: 2.5241953536808914

Epoch: 5| Step: 10
Training loss: 0.13951959201386235
Validation loss: 2.5108887055836213

Epoch: 599| Step: 0
Training loss: 0.1592873636224638
Validation loss: 2.546191645941431

Epoch: 5| Step: 1
Training loss: 0.20655045371775682
Validation loss: 2.5144076476006134

Epoch: 5| Step: 2
Training loss: 0.20128333142985141
Validation loss: 2.539631285967553

Epoch: 5| Step: 3
Training loss: 0.12968210617017029
Validation loss: 2.5159015527708104

Epoch: 5| Step: 4
Training loss: 0.13184010534409457
Validation loss: 2.50526430786656

Epoch: 5| Step: 5
Training loss: 0.11727183803946382
Validation loss: 2.523849580649519

Epoch: 5| Step: 6
Training loss: 0.11396616613802521
Validation loss: 2.5164014229177707

Epoch: 5| Step: 7
Training loss: 0.12081856376993143
Validation loss: 2.5068038881559427

Epoch: 5| Step: 8
Training loss: 0.11940193832862268
Validation loss: 2.504799323601695

Epoch: 5| Step: 9
Training loss: 0.20124557219248745
Validation loss: 2.5329973152068397

Epoch: 5| Step: 10
Training loss: 0.10998057144395995
Validation loss: 2.5277451715331285

Epoch: 600| Step: 0
Training loss: 0.12708744132979619
Validation loss: 2.5433610054380678

Epoch: 5| Step: 1
Training loss: 0.11430622770486627
Validation loss: 2.5580831700077185

Epoch: 5| Step: 2
Training loss: 0.13470793608850648
Validation loss: 2.5258553780784663

Epoch: 5| Step: 3
Training loss: 0.1734660105855755
Validation loss: 2.574330224608955

Epoch: 5| Step: 4
Training loss: 0.07871445962678604
Validation loss: 2.521065395097425

Epoch: 5| Step: 5
Training loss: 0.16789575032877746
Validation loss: 2.5005444415803533

Epoch: 5| Step: 6
Training loss: 0.17879892486647989
Validation loss: 2.5169117818031284

Epoch: 5| Step: 7
Training loss: 0.09368177255863573
Validation loss: 2.505325650968446

Epoch: 5| Step: 8
Training loss: 0.1800468210744806
Validation loss: 2.519489589867258

Epoch: 5| Step: 9
Training loss: 0.15158848736352498
Validation loss: 2.50520720648244

Epoch: 5| Step: 10
Training loss: 0.13986806338481905
Validation loss: 2.5132159355913894

Epoch: 601| Step: 0
Training loss: 0.1374930661794028
Validation loss: 2.5228669338615766

Epoch: 5| Step: 1
Training loss: 0.25110803863756564
Validation loss: 2.51487224885491

Epoch: 5| Step: 2
Training loss: 0.11223406436993484
Validation loss: 2.5222121318675956

Epoch: 5| Step: 3
Training loss: 0.17781633017626697
Validation loss: 2.525184389633297

Epoch: 5| Step: 4
Training loss: 0.1041931436585696
Validation loss: 2.5049429030519748

Epoch: 5| Step: 5
Training loss: 0.13179419527794936
Validation loss: 2.5049944170103915

Epoch: 5| Step: 6
Training loss: 0.15415100856363526
Validation loss: 2.478489620391965

Epoch: 5| Step: 7
Training loss: 0.10738211242652952
Validation loss: 2.4979937604515916

Epoch: 5| Step: 8
Training loss: 0.09721436183759567
Validation loss: 2.510241948711443

Epoch: 5| Step: 9
Training loss: 0.12253352208938673
Validation loss: 2.5078456762613244

Epoch: 5| Step: 10
Training loss: 0.11034030350494026
Validation loss: 2.4928199844227326

Epoch: 602| Step: 0
Training loss: 0.12301674731341129
Validation loss: 2.4844145737830035

Epoch: 5| Step: 1
Training loss: 0.0639846385291312
Validation loss: 2.5125479314700523

Epoch: 5| Step: 2
Training loss: 0.23133546500009428
Validation loss: 2.4856086975566543

Epoch: 5| Step: 3
Training loss: 0.1187667530564821
Validation loss: 2.478869556779703

Epoch: 5| Step: 4
Training loss: 0.17140267235387477
Validation loss: 2.4940181117521947

Epoch: 5| Step: 5
Training loss: 0.09250018887403898
Validation loss: 2.48994492568384

Epoch: 5| Step: 6
Training loss: 0.12815314716432963
Validation loss: 2.492281982655308

Epoch: 5| Step: 7
Training loss: 0.08163635537057386
Validation loss: 2.5178470401603

Epoch: 5| Step: 8
Training loss: 0.08400142297043288
Validation loss: 2.505095945070752

Epoch: 5| Step: 9
Training loss: 0.15320834548280302
Validation loss: 2.5214460581348

Epoch: 5| Step: 10
Training loss: 0.09290292136327094
Validation loss: 2.498201870045083

Epoch: 603| Step: 0
Training loss: 0.21693215144824982
Validation loss: 2.524090060431195

Epoch: 5| Step: 1
Training loss: 0.1368441415429639
Validation loss: 2.491935010493435

Epoch: 5| Step: 2
Training loss: 0.09966693879136734
Validation loss: 2.4942115240858986

Epoch: 5| Step: 3
Training loss: 0.1155592734808125
Validation loss: 2.456601141805196

Epoch: 5| Step: 4
Training loss: 0.1671983327653856
Validation loss: 2.48162139190249

Epoch: 5| Step: 5
Training loss: 0.08889651600559413
Validation loss: 2.4820840501028103

Epoch: 5| Step: 6
Training loss: 0.12499536192753155
Validation loss: 2.4628402966216543

Epoch: 5| Step: 7
Training loss: 0.1504739183902924
Validation loss: 2.4706674681128518

Epoch: 5| Step: 8
Training loss: 0.18438157013323894
Validation loss: 2.515609698362748

Epoch: 5| Step: 9
Training loss: 0.07279569910392983
Validation loss: 2.4707089854471698

Epoch: 5| Step: 10
Training loss: 0.08228517298740133
Validation loss: 2.4719487095366395

Epoch: 604| Step: 0
Training loss: 0.10151913065359583
Validation loss: 2.461295990583983

Epoch: 5| Step: 1
Training loss: 0.09569766554538782
Validation loss: 2.493588258910336

Epoch: 5| Step: 2
Training loss: 0.1329182736554756
Validation loss: 2.4864926617046836

Epoch: 5| Step: 3
Training loss: 0.15533058746215628
Validation loss: 2.4881310483540275

Epoch: 5| Step: 4
Training loss: 0.13269878175168365
Validation loss: 2.4864150355143106

Epoch: 5| Step: 5
Training loss: 0.18728831381726319
Validation loss: 2.458531891187585

Epoch: 5| Step: 6
Training loss: 0.16530078247886673
Validation loss: 2.484824193330917

Epoch: 5| Step: 7
Training loss: 0.08069313947676965
Validation loss: 2.4810292427276055

Epoch: 5| Step: 8
Training loss: 0.24116121775834398
Validation loss: 2.4760884689554605

Epoch: 5| Step: 9
Training loss: 0.10061734366610298
Validation loss: 2.4984400219823666

Epoch: 5| Step: 10
Training loss: 0.2023874151033774
Validation loss: 2.4907632901844994

Epoch: 605| Step: 0
Training loss: 0.1428766652374811
Validation loss: 2.5020919025741586

Epoch: 5| Step: 1
Training loss: 0.1685777204209749
Validation loss: 2.4965265519460247

Epoch: 5| Step: 2
Training loss: 0.11881444791499368
Validation loss: 2.5226270259953956

Epoch: 5| Step: 3
Training loss: 0.14001671042083863
Validation loss: 2.5329528014958465

Epoch: 5| Step: 4
Training loss: 0.1454773813467087
Validation loss: 2.494897970690045

Epoch: 5| Step: 5
Training loss: 0.14479351734332538
Validation loss: 2.519772182098408

Epoch: 5| Step: 6
Training loss: 0.19846398297007073
Validation loss: 2.5021081065534467

Epoch: 5| Step: 7
Training loss: 0.07306083160829507
Validation loss: 2.4697460793896453

Epoch: 5| Step: 8
Training loss: 0.1830141170234079
Validation loss: 2.467864877253737

Epoch: 5| Step: 9
Training loss: 0.13363419918711267
Validation loss: 2.482072231079343

Epoch: 5| Step: 10
Training loss: 0.07673882135447291
Validation loss: 2.5120043248951935

Epoch: 606| Step: 0
Training loss: 0.11857711699224847
Validation loss: 2.502512331906149

Epoch: 5| Step: 1
Training loss: 0.08738514395320468
Validation loss: 2.497951562033865

Epoch: 5| Step: 2
Training loss: 0.0769693825825845
Validation loss: 2.482991073605833

Epoch: 5| Step: 3
Training loss: 0.11603289677915107
Validation loss: 2.4779912403143247

Epoch: 5| Step: 4
Training loss: 0.07476135535191468
Validation loss: 2.458677951468577

Epoch: 5| Step: 5
Training loss: 0.22015205723145476
Validation loss: 2.456743969291793

Epoch: 5| Step: 6
Training loss: 0.10546688678649813
Validation loss: 2.4723069120898726

Epoch: 5| Step: 7
Training loss: 0.10095687172482833
Validation loss: 2.466598259429871

Epoch: 5| Step: 8
Training loss: 0.14444016473252416
Validation loss: 2.4495866352713613

Epoch: 5| Step: 9
Training loss: 0.1361370792021293
Validation loss: 2.4691095501827913

Epoch: 5| Step: 10
Training loss: 0.20252150971767635
Validation loss: 2.457948341347507

Epoch: 607| Step: 0
Training loss: 0.11120867595242266
Validation loss: 2.4561848036633327

Epoch: 5| Step: 1
Training loss: 0.10090229136350541
Validation loss: 2.4807313273173395

Epoch: 5| Step: 2
Training loss: 0.11008456092224482
Validation loss: 2.461774701808555

Epoch: 5| Step: 3
Training loss: 0.073073176249036
Validation loss: 2.4989682806649425

Epoch: 5| Step: 4
Training loss: 0.10510471443645368
Validation loss: 2.483790427867735

Epoch: 5| Step: 5
Training loss: 0.1495707320065218
Validation loss: 2.4932543911160203

Epoch: 5| Step: 6
Training loss: 0.10962535526186534
Validation loss: 2.483416096672989

Epoch: 5| Step: 7
Training loss: 0.1720786513733821
Validation loss: 2.5078811510884176

Epoch: 5| Step: 8
Training loss: 0.08047349080221995
Validation loss: 2.4992413959309916

Epoch: 5| Step: 9
Training loss: 0.16828996971335294
Validation loss: 2.4691730477924296

Epoch: 5| Step: 10
Training loss: 0.20095220627666294
Validation loss: 2.5228232578394794

Epoch: 608| Step: 0
Training loss: 0.13345428682819088
Validation loss: 2.5101682505759535

Epoch: 5| Step: 1
Training loss: 0.145022035827587
Validation loss: 2.5152011586386864

Epoch: 5| Step: 2
Training loss: 0.11163464394705641
Validation loss: 2.525246221403667

Epoch: 5| Step: 3
Training loss: 0.1892557590873189
Validation loss: 2.520922599668951

Epoch: 5| Step: 4
Training loss: 0.16561848317227051
Validation loss: 2.5353158250580137

Epoch: 5| Step: 5
Training loss: 0.11701363540477948
Validation loss: 2.515435076803736

Epoch: 5| Step: 6
Training loss: 0.187998585604359
Validation loss: 2.5047449889229596

Epoch: 5| Step: 7
Training loss: 0.11371540451972958
Validation loss: 2.48333938135684

Epoch: 5| Step: 8
Training loss: 0.12915256116229368
Validation loss: 2.5171477317310242

Epoch: 5| Step: 9
Training loss: 0.11439696014493456
Validation loss: 2.467209941676197

Epoch: 5| Step: 10
Training loss: 0.13547368560916478
Validation loss: 2.48057584317415

Epoch: 609| Step: 0
Training loss: 0.09766670647906907
Validation loss: 2.4871385408702658

Epoch: 5| Step: 1
Training loss: 0.2044642570534851
Validation loss: 2.495694713107661

Epoch: 5| Step: 2
Training loss: 0.067228822005191
Validation loss: 2.4766982141551135

Epoch: 5| Step: 3
Training loss: 0.16718530920857164
Validation loss: 2.494401978954383

Epoch: 5| Step: 4
Training loss: 0.17267779867415237
Validation loss: 2.500344503928414

Epoch: 5| Step: 5
Training loss: 0.14462943221878138
Validation loss: 2.505618937565275

Epoch: 5| Step: 6
Training loss: 0.08708959170927615
Validation loss: 2.505827031821089

Epoch: 5| Step: 7
Training loss: 0.0672498268367619
Validation loss: 2.5082539463232263

Epoch: 5| Step: 8
Training loss: 0.12415800153642753
Validation loss: 2.495520494503011

Epoch: 5| Step: 9
Training loss: 0.14854891886959692
Validation loss: 2.5001763250866276

Epoch: 5| Step: 10
Training loss: 0.09294943428535585
Validation loss: 2.4960528695547763

Epoch: 610| Step: 0
Training loss: 0.11446300242639619
Validation loss: 2.5058697283302362

Epoch: 5| Step: 1
Training loss: 0.1691434833558198
Validation loss: 2.4716397340076766

Epoch: 5| Step: 2
Training loss: 0.08246662768993546
Validation loss: 2.5006071050855323

Epoch: 5| Step: 3
Training loss: 0.09494836637736065
Validation loss: 2.4948002155746725

Epoch: 5| Step: 4
Training loss: 0.10301570012977854
Validation loss: 2.491380220611137

Epoch: 5| Step: 5
Training loss: 0.08535541835603784
Validation loss: 2.4830605183264898

Epoch: 5| Step: 6
Training loss: 0.2404221366979571
Validation loss: 2.5163892195214705

Epoch: 5| Step: 7
Training loss: 0.1081106730847828
Validation loss: 2.484699445040419

Epoch: 5| Step: 8
Training loss: 0.08932827707764467
Validation loss: 2.4865580753722125

Epoch: 5| Step: 9
Training loss: 0.09642050420559102
Validation loss: 2.529707761505516

Epoch: 5| Step: 10
Training loss: 0.09277727219536805
Validation loss: 2.4810387139119063

Epoch: 611| Step: 0
Training loss: 0.13291349497910332
Validation loss: 2.501134911701195

Epoch: 5| Step: 1
Training loss: 0.1970372341436146
Validation loss: 2.507052720780092

Epoch: 5| Step: 2
Training loss: 0.16088953437631875
Validation loss: 2.495371081243349

Epoch: 5| Step: 3
Training loss: 0.09006426018001477
Validation loss: 2.463947272031467

Epoch: 5| Step: 4
Training loss: 0.060308201345129125
Validation loss: 2.4700174418051084

Epoch: 5| Step: 5
Training loss: 0.17288783603388985
Validation loss: 2.443318131604681

Epoch: 5| Step: 6
Training loss: 0.11307373854043992
Validation loss: 2.488482137303098

Epoch: 5| Step: 7
Training loss: 0.07248866612329696
Validation loss: 2.492858052265415

Epoch: 5| Step: 8
Training loss: 0.08886128709928266
Validation loss: 2.4895319837897936

Epoch: 5| Step: 9
Training loss: 0.13595685519620931
Validation loss: 2.456801715497172

Epoch: 5| Step: 10
Training loss: 0.10745875852449442
Validation loss: 2.472825019111899

Epoch: 612| Step: 0
Training loss: 0.13348200290433834
Validation loss: 2.4584613615151807

Epoch: 5| Step: 1
Training loss: 0.09163800655341282
Validation loss: 2.453537605762222

Epoch: 5| Step: 2
Training loss: 0.1084632937263259
Validation loss: 2.4558021876358036

Epoch: 5| Step: 3
Training loss: 0.11155477674715646
Validation loss: 2.476494893754825

Epoch: 5| Step: 4
Training loss: 0.1939691984098625
Validation loss: 2.4207607504586095

Epoch: 5| Step: 5
Training loss: 0.13324927288531585
Validation loss: 2.482947532475821

Epoch: 5| Step: 6
Training loss: 0.09308062441795008
Validation loss: 2.498505445553547

Epoch: 5| Step: 7
Training loss: 0.09411022399780329
Validation loss: 2.502418253441609

Epoch: 5| Step: 8
Training loss: 0.16054870042900124
Validation loss: 2.4878671663814638

Epoch: 5| Step: 9
Training loss: 0.1862761171002055
Validation loss: 2.49585020037798

Epoch: 5| Step: 10
Training loss: 0.1428149946921424
Validation loss: 2.519731436545695

Epoch: 613| Step: 0
Training loss: 0.12731499083904982
Validation loss: 2.5022438828622975

Epoch: 5| Step: 1
Training loss: 0.20357083031320264
Validation loss: 2.4550353951631547

Epoch: 5| Step: 2
Training loss: 0.1080634120607028
Validation loss: 2.51086420634675

Epoch: 5| Step: 3
Training loss: 0.11500715224425903
Validation loss: 2.479308313459734

Epoch: 5| Step: 4
Training loss: 0.14257372235333216
Validation loss: 2.4718139356308133

Epoch: 5| Step: 5
Training loss: 0.15138344831185996
Validation loss: 2.469267592943085

Epoch: 5| Step: 6
Training loss: 0.14423485598826427
Validation loss: 2.4718555913531155

Epoch: 5| Step: 7
Training loss: 0.18957034152093802
Validation loss: 2.4348953967411813

Epoch: 5| Step: 8
Training loss: 0.12087352785715035
Validation loss: 2.4518367900757254

Epoch: 5| Step: 9
Training loss: 0.12900260734048571
Validation loss: 2.4492779935057394

Epoch: 5| Step: 10
Training loss: 0.10437997247221235
Validation loss: 2.4537940329518113

Epoch: 614| Step: 0
Training loss: 0.08862513284881761
Validation loss: 2.438009736238915

Epoch: 5| Step: 1
Training loss: 0.14668155115317624
Validation loss: 2.4688163580698426

Epoch: 5| Step: 2
Training loss: 0.17514953483007406
Validation loss: 2.4808458205232156

Epoch: 5| Step: 3
Training loss: 0.1318814799447828
Validation loss: 2.477127913312068

Epoch: 5| Step: 4
Training loss: 0.08152600357466065
Validation loss: 2.4781183373858067

Epoch: 5| Step: 5
Training loss: 0.21182445969843045
Validation loss: 2.458776441016811

Epoch: 5| Step: 6
Training loss: 0.09607423626860202
Validation loss: 2.484651734463185

Epoch: 5| Step: 7
Training loss: 0.2018129633428288
Validation loss: 2.4831905666963694

Epoch: 5| Step: 8
Training loss: 0.20206020106486564
Validation loss: 2.507523326387201

Epoch: 5| Step: 9
Training loss: 0.10937270945466633
Validation loss: 2.4949646138241515

Epoch: 5| Step: 10
Training loss: 0.12296702049279996
Validation loss: 2.5222352264730348

Epoch: 615| Step: 0
Training loss: 0.13522508637798777
Validation loss: 2.5187608570494

Epoch: 5| Step: 1
Training loss: 0.14246185996967928
Validation loss: 2.4762626588845937

Epoch: 5| Step: 2
Training loss: 0.13349405188069807
Validation loss: 2.5243289650005862

Epoch: 5| Step: 3
Training loss: 0.21081928190015112
Validation loss: 2.491232679682555

Epoch: 5| Step: 4
Training loss: 0.16331269723418246
Validation loss: 2.4788416188116877

Epoch: 5| Step: 5
Training loss: 0.1371647236714618
Validation loss: 2.4720157048348144

Epoch: 5| Step: 6
Training loss: 0.1307273882356122
Validation loss: 2.461767459006508

Epoch: 5| Step: 7
Training loss: 0.1736408575058658
Validation loss: 2.4553803599292987

Epoch: 5| Step: 8
Training loss: 0.17226270815916517
Validation loss: 2.4708161997087355

Epoch: 5| Step: 9
Training loss: 0.1452303166922849
Validation loss: 2.450399457107206

Epoch: 5| Step: 10
Training loss: 0.24337968879281852
Validation loss: 2.426320861749303

Epoch: 616| Step: 0
Training loss: 0.16659048072656849
Validation loss: 2.438509992423995

Epoch: 5| Step: 1
Training loss: 0.1352644685552814
Validation loss: 2.4237820339306646

Epoch: 5| Step: 2
Training loss: 0.23434327228689228
Validation loss: 2.50238774928952

Epoch: 5| Step: 3
Training loss: 0.15542296641223435
Validation loss: 2.531938485810208

Epoch: 5| Step: 4
Training loss: 0.19188112595499082
Validation loss: 2.5471137623337237

Epoch: 5| Step: 5
Training loss: 0.14284769467632322
Validation loss: 2.5566923517177496

Epoch: 5| Step: 6
Training loss: 0.1443811423266659
Validation loss: 2.5735923521211634

Epoch: 5| Step: 7
Training loss: 0.16218310713101813
Validation loss: 2.5684302365899803

Epoch: 5| Step: 8
Training loss: 0.20130868537377414
Validation loss: 2.572828854228177

Epoch: 5| Step: 9
Training loss: 0.18935739910682234
Validation loss: 2.6044119380175546

Epoch: 5| Step: 10
Training loss: 0.10675266933230569
Validation loss: 2.552208119686497

Epoch: 617| Step: 0
Training loss: 0.15580105658510804
Validation loss: 2.567606876639199

Epoch: 5| Step: 1
Training loss: 0.1382228606813996
Validation loss: 2.554325753130142

Epoch: 5| Step: 2
Training loss: 0.19691731134514434
Validation loss: 2.552520648855543

Epoch: 5| Step: 3
Training loss: 0.15023401081796864
Validation loss: 2.5356407373157306

Epoch: 5| Step: 4
Training loss: 0.12976522070117233
Validation loss: 2.5330783687625864

Epoch: 5| Step: 5
Training loss: 0.11255461208351306
Validation loss: 2.5283052266111676

Epoch: 5| Step: 6
Training loss: 0.14601593137967137
Validation loss: 2.5391232234486867

Epoch: 5| Step: 7
Training loss: 0.22450231405490764
Validation loss: 2.544139502017932

Epoch: 5| Step: 8
Training loss: 0.11148138121773475
Validation loss: 2.5407307228093035

Epoch: 5| Step: 9
Training loss: 0.199082131383439
Validation loss: 2.5353355337368755

Epoch: 5| Step: 10
Training loss: 0.1356568445558663
Validation loss: 2.584323613531518

Epoch: 618| Step: 0
Training loss: 0.13084272022447954
Validation loss: 2.582100123005258

Epoch: 5| Step: 1
Training loss: 0.22839504712431194
Validation loss: 2.5490943715256282

Epoch: 5| Step: 2
Training loss: 0.13605197027594215
Validation loss: 2.5184572490282853

Epoch: 5| Step: 3
Training loss: 0.20467655283649996
Validation loss: 2.555420131923545

Epoch: 5| Step: 4
Training loss: 0.11541488216870577
Validation loss: 2.5167655114827214

Epoch: 5| Step: 5
Training loss: 0.15479337507984883
Validation loss: 2.507679784431634

Epoch: 5| Step: 6
Training loss: 0.10445675293664342
Validation loss: 2.51627151231385

Epoch: 5| Step: 7
Training loss: 0.1124611925040743
Validation loss: 2.5221586469926116

Epoch: 5| Step: 8
Training loss: 0.16370842964729096
Validation loss: 2.4736129718296693

Epoch: 5| Step: 9
Training loss: 0.1224137129981013
Validation loss: 2.485822060506429

Epoch: 5| Step: 10
Training loss: 0.13697584366363655
Validation loss: 2.456627416725303

Epoch: 619| Step: 0
Training loss: 0.20587371725540912
Validation loss: 2.467317580212829

Epoch: 5| Step: 1
Training loss: 0.13618194919248947
Validation loss: 2.4435947023202584

Epoch: 5| Step: 2
Training loss: 0.1781536543536099
Validation loss: 2.459902918414253

Epoch: 5| Step: 3
Training loss: 0.14871599398714713
Validation loss: 2.445452803027699

Epoch: 5| Step: 4
Training loss: 0.09380881133760167
Validation loss: 2.47526522993032

Epoch: 5| Step: 5
Training loss: 0.1715402486056254
Validation loss: 2.4891227676814554

Epoch: 5| Step: 6
Training loss: 0.15779613608321283
Validation loss: 2.517671193530268

Epoch: 5| Step: 7
Training loss: 0.12455644739119952
Validation loss: 2.546334893932714

Epoch: 5| Step: 8
Training loss: 0.11387309489294889
Validation loss: 2.5156773998866933

Epoch: 5| Step: 9
Training loss: 0.23174889689299213
Validation loss: 2.531697146532988

Epoch: 5| Step: 10
Training loss: 0.11984352400881511
Validation loss: 2.5148206528192625

Epoch: 620| Step: 0
Training loss: 0.1394567574634345
Validation loss: 2.516667919189863

Epoch: 5| Step: 1
Training loss: 0.15632924812024018
Validation loss: 2.5216038244322023

Epoch: 5| Step: 2
Training loss: 0.14350906607311753
Validation loss: 2.5111332100831647

Epoch: 5| Step: 3
Training loss: 0.16910703999580526
Validation loss: 2.5179921200771247

Epoch: 5| Step: 4
Training loss: 0.15062641881139982
Validation loss: 2.529064580547782

Epoch: 5| Step: 5
Training loss: 0.17703002707049725
Validation loss: 2.5245905250006966

Epoch: 5| Step: 6
Training loss: 0.1685707648202662
Validation loss: 2.516664391042388

Epoch: 5| Step: 7
Training loss: 0.12465933109285639
Validation loss: 2.509126233425922

Epoch: 5| Step: 8
Training loss: 0.09285778929100895
Validation loss: 2.5191795027910047

Epoch: 5| Step: 9
Training loss: 0.14112846002484697
Validation loss: 2.469518028784698

Epoch: 5| Step: 10
Training loss: 0.12622535150996173
Validation loss: 2.4817796626143394

Epoch: 621| Step: 0
Training loss: 0.10442167202286069
Validation loss: 2.4892190196502697

Epoch: 5| Step: 1
Training loss: 0.062440795722437076
Validation loss: 2.4898726644062066

Epoch: 5| Step: 2
Training loss: 0.20287621374583936
Validation loss: 2.5163413507880996

Epoch: 5| Step: 3
Training loss: 0.16998466888011007
Validation loss: 2.484250784346026

Epoch: 5| Step: 4
Training loss: 0.15401871875458753
Validation loss: 2.475693443821384

Epoch: 5| Step: 5
Training loss: 0.132187346724383
Validation loss: 2.465190526525676

Epoch: 5| Step: 6
Training loss: 0.11084211658046449
Validation loss: 2.502855682888995

Epoch: 5| Step: 7
Training loss: 0.15069529400814066
Validation loss: 2.5013436859557783

Epoch: 5| Step: 8
Training loss: 0.1418062572160136
Validation loss: 2.489427816447518

Epoch: 5| Step: 9
Training loss: 0.08310390408182693
Validation loss: 2.521402029597621

Epoch: 5| Step: 10
Training loss: 0.08780773015405592
Validation loss: 2.5144756506513763

Epoch: 622| Step: 0
Training loss: 0.15905697310837674
Validation loss: 2.507623752721924

Epoch: 5| Step: 1
Training loss: 0.11906727111698533
Validation loss: 2.497922257485539

Epoch: 5| Step: 2
Training loss: 0.11627001422824701
Validation loss: 2.5238364574263468

Epoch: 5| Step: 3
Training loss: 0.1788889306026743
Validation loss: 2.5196567126095264

Epoch: 5| Step: 4
Training loss: 0.08185485766798715
Validation loss: 2.5351387216845063

Epoch: 5| Step: 5
Training loss: 0.10439917622751402
Validation loss: 2.5179582741894673

Epoch: 5| Step: 6
Training loss: 0.07819833591728298
Validation loss: 2.498765531953936

Epoch: 5| Step: 7
Training loss: 0.1741161638846754
Validation loss: 2.477091290681695

Epoch: 5| Step: 8
Training loss: 0.12608926005210486
Validation loss: 2.4948643078169335

Epoch: 5| Step: 9
Training loss: 0.11155983169020012
Validation loss: 2.4797753601659838

Epoch: 5| Step: 10
Training loss: 0.09538894288644276
Validation loss: 2.503015887396765

Epoch: 623| Step: 0
Training loss: 0.09272420480327521
Validation loss: 2.499290078383102

Epoch: 5| Step: 1
Training loss: 0.08689317291477373
Validation loss: 2.4947911398518405

Epoch: 5| Step: 2
Training loss: 0.1676788323135369
Validation loss: 2.4925712690892876

Epoch: 5| Step: 3
Training loss: 0.10882297069614798
Validation loss: 2.4880064246527955

Epoch: 5| Step: 4
Training loss: 0.09746102369377285
Validation loss: 2.50622726437073

Epoch: 5| Step: 5
Training loss: 0.2599342917207413
Validation loss: 2.501009673634617

Epoch: 5| Step: 6
Training loss: 0.11721468451224668
Validation loss: 2.520557891583027

Epoch: 5| Step: 7
Training loss: 0.11013479801728103
Validation loss: 2.4877663495585325

Epoch: 5| Step: 8
Training loss: 0.09786925450966064
Validation loss: 2.4887388196335287

Epoch: 5| Step: 9
Training loss: 0.13001607927275804
Validation loss: 2.505381542725732

Epoch: 5| Step: 10
Training loss: 0.1141096972772152
Validation loss: 2.4836734816541606

Epoch: 624| Step: 0
Training loss: 0.0836302755453009
Validation loss: 2.4962162466182325

Epoch: 5| Step: 1
Training loss: 0.09591857830732443
Validation loss: 2.506537081072278

Epoch: 5| Step: 2
Training loss: 0.0852894788551773
Validation loss: 2.513391209085021

Epoch: 5| Step: 3
Training loss: 0.1725971159495407
Validation loss: 2.50789919293726

Epoch: 5| Step: 4
Training loss: 0.09422370323522095
Validation loss: 2.517389865513474

Epoch: 5| Step: 5
Training loss: 0.12856653996333928
Validation loss: 2.504303660093983

Epoch: 5| Step: 6
Training loss: 0.21187352087129105
Validation loss: 2.4893809199486725

Epoch: 5| Step: 7
Training loss: 0.12148555696777183
Validation loss: 2.4877556776884147

Epoch: 5| Step: 8
Training loss: 0.10100298596679999
Validation loss: 2.5052293680177065

Epoch: 5| Step: 9
Training loss: 0.12251082473485607
Validation loss: 2.4878670056301355

Epoch: 5| Step: 10
Training loss: 0.14969134936032114
Validation loss: 2.4947947811402105

Epoch: 625| Step: 0
Training loss: 0.11097793547369458
Validation loss: 2.4793574875975337

Epoch: 5| Step: 1
Training loss: 0.16834834365815912
Validation loss: 2.472962351355761

Epoch: 5| Step: 2
Training loss: 0.07122717744897167
Validation loss: 2.478726816871376

Epoch: 5| Step: 3
Training loss: 0.15954009602275765
Validation loss: 2.4727469369017196

Epoch: 5| Step: 4
Training loss: 0.14923116921875892
Validation loss: 2.466100339126312

Epoch: 5| Step: 5
Training loss: 0.12993063082297232
Validation loss: 2.464160634258789

Epoch: 5| Step: 6
Training loss: 0.09052462794932753
Validation loss: 2.462600337382381

Epoch: 5| Step: 7
Training loss: 0.15070512015849769
Validation loss: 2.457661068743262

Epoch: 5| Step: 8
Training loss: 0.057271400663909657
Validation loss: 2.4638034896749197

Epoch: 5| Step: 9
Training loss: 0.17366303952110712
Validation loss: 2.4751767005626246

Epoch: 5| Step: 10
Training loss: 0.13605444142278014
Validation loss: 2.4714049163970295

Epoch: 626| Step: 0
Training loss: 0.11509002923091123
Validation loss: 2.44945977838731

Epoch: 5| Step: 1
Training loss: 0.08894623395319362
Validation loss: 2.496897932495041

Epoch: 5| Step: 2
Training loss: 0.18130301818197517
Validation loss: 2.4753670084831993

Epoch: 5| Step: 3
Training loss: 0.06902445756776986
Validation loss: 2.525020579137757

Epoch: 5| Step: 4
Training loss: 0.13800013734890143
Validation loss: 2.4833258370716265

Epoch: 5| Step: 5
Training loss: 0.11096872491360904
Validation loss: 2.514809947941529

Epoch: 5| Step: 6
Training loss: 0.09317205522747864
Validation loss: 2.4800463534411845

Epoch: 5| Step: 7
Training loss: 0.11311394570278631
Validation loss: 2.5144056563593966

Epoch: 5| Step: 8
Training loss: 0.14783322788781847
Validation loss: 2.49003639034151

Epoch: 5| Step: 9
Training loss: 0.16242292254294993
Validation loss: 2.4643371663664433

Epoch: 5| Step: 10
Training loss: 0.07586919729795584
Validation loss: 2.469305319458443

Epoch: 627| Step: 0
Training loss: 0.1029256436243056
Validation loss: 2.5002843848880434

Epoch: 5| Step: 1
Training loss: 0.09296653127827696
Validation loss: 2.4465486291147767

Epoch: 5| Step: 2
Training loss: 0.17207303342713837
Validation loss: 2.4857776572745407

Epoch: 5| Step: 3
Training loss: 0.07365143563199573
Validation loss: 2.456633932711728

Epoch: 5| Step: 4
Training loss: 0.154523737033388
Validation loss: 2.5162888842410727

Epoch: 5| Step: 5
Training loss: 0.12363625712967048
Validation loss: 2.5051060278057387

Epoch: 5| Step: 6
Training loss: 0.1808327995203053
Validation loss: 2.54850789272292

Epoch: 5| Step: 7
Training loss: 0.14625796304526598
Validation loss: 2.510043279892987

Epoch: 5| Step: 8
Training loss: 0.08806567244436568
Validation loss: 2.485699511641767

Epoch: 5| Step: 9
Training loss: 0.08818586880948152
Validation loss: 2.4792026235555173

Epoch: 5| Step: 10
Training loss: 0.1412413257070613
Validation loss: 2.4602014157302445

Epoch: 628| Step: 0
Training loss: 0.1505692276051356
Validation loss: 2.480723338957697

Epoch: 5| Step: 1
Training loss: 0.07841777480827092
Validation loss: 2.453549851669192

Epoch: 5| Step: 2
Training loss: 0.11312436470490891
Validation loss: 2.4777083433198097

Epoch: 5| Step: 3
Training loss: 0.08018330899954282
Validation loss: 2.4707950965163716

Epoch: 5| Step: 4
Training loss: 0.06502841913925861
Validation loss: 2.4498682380522596

Epoch: 5| Step: 5
Training loss: 0.12667564732651745
Validation loss: 2.4690905536382686

Epoch: 5| Step: 6
Training loss: 0.11330843467752526
Validation loss: 2.4758858025846133

Epoch: 5| Step: 7
Training loss: 0.1801682344008787
Validation loss: 2.4917766479140164

Epoch: 5| Step: 8
Training loss: 0.22592162879821207
Validation loss: 2.442809910250403

Epoch: 5| Step: 9
Training loss: 0.08115344178780123
Validation loss: 2.4459525368286057

Epoch: 5| Step: 10
Training loss: 0.09603560848102452
Validation loss: 2.4442161438376018

Epoch: 629| Step: 0
Training loss: 0.06939201370813265
Validation loss: 2.4441074690331983

Epoch: 5| Step: 1
Training loss: 0.08640021145261337
Validation loss: 2.4524167085140514

Epoch: 5| Step: 2
Training loss: 0.16825837294162896
Validation loss: 2.4265887626945286

Epoch: 5| Step: 3
Training loss: 0.11772313886409927
Validation loss: 2.471432174972368

Epoch: 5| Step: 4
Training loss: 0.16522137881634127
Validation loss: 2.4416947578187025

Epoch: 5| Step: 5
Training loss: 0.14790115582937857
Validation loss: 2.461879759093775

Epoch: 5| Step: 6
Training loss: 0.1150147478738451
Validation loss: 2.4519051703189256

Epoch: 5| Step: 7
Training loss: 0.09911762193885429
Validation loss: 2.4441941910984393

Epoch: 5| Step: 8
Training loss: 0.1101931219413981
Validation loss: 2.461674071292823

Epoch: 5| Step: 9
Training loss: 0.15323008172232885
Validation loss: 2.4653848434077794

Epoch: 5| Step: 10
Training loss: 0.18210699854756265
Validation loss: 2.4719208530624353

Epoch: 630| Step: 0
Training loss: 0.1437571972102586
Validation loss: 2.4553246695698103

Epoch: 5| Step: 1
Training loss: 0.06951336925419606
Validation loss: 2.4718760518093488

Epoch: 5| Step: 2
Training loss: 0.11576547514573288
Validation loss: 2.4813576999743265

Epoch: 5| Step: 3
Training loss: 0.19742673017285445
Validation loss: 2.478318835607222

Epoch: 5| Step: 4
Training loss: 0.13432743178691595
Validation loss: 2.4485949953404567

Epoch: 5| Step: 5
Training loss: 0.18551506974529078
Validation loss: 2.467799903040809

Epoch: 5| Step: 6
Training loss: 0.10258649455613499
Validation loss: 2.4479574245043647

Epoch: 5| Step: 7
Training loss: 0.18216663000597094
Validation loss: 2.454798424252103

Epoch: 5| Step: 8
Training loss: 0.11625484630778492
Validation loss: 2.4905970325398155

Epoch: 5| Step: 9
Training loss: 0.09771827635301084
Validation loss: 2.4817006545482907

Epoch: 5| Step: 10
Training loss: 0.09190590957265958
Validation loss: 2.5171428423041626

Epoch: 631| Step: 0
Training loss: 0.13410514193390552
Validation loss: 2.508291792703597

Epoch: 5| Step: 1
Training loss: 0.12061677331493204
Validation loss: 2.5277772180401197

Epoch: 5| Step: 2
Training loss: 0.1938280148488554
Validation loss: 2.5197398140186253

Epoch: 5| Step: 3
Training loss: 0.1150935452042787
Validation loss: 2.5272655567207987

Epoch: 5| Step: 4
Training loss: 0.15876710113456366
Validation loss: 2.539780504102489

Epoch: 5| Step: 5
Training loss: 0.10898569338694987
Validation loss: 2.5384877149858305

Epoch: 5| Step: 6
Training loss: 0.0463274099759573
Validation loss: 2.5144786063331437

Epoch: 5| Step: 7
Training loss: 0.17172165011732957
Validation loss: 2.5295944785663758

Epoch: 5| Step: 8
Training loss: 0.09257998122595705
Validation loss: 2.5129885816451836

Epoch: 5| Step: 9
Training loss: 0.0956906972328557
Validation loss: 2.4846005256454795

Epoch: 5| Step: 10
Training loss: 0.10213607436102418
Validation loss: 2.5333280471278132

Epoch: 632| Step: 0
Training loss: 0.135475906075265
Validation loss: 2.4944370833104363

Epoch: 5| Step: 1
Training loss: 0.13205929661425325
Validation loss: 2.5108745232143517

Epoch: 5| Step: 2
Training loss: 0.07967929552421127
Validation loss: 2.510428013548501

Epoch: 5| Step: 3
Training loss: 0.12526545055158853
Validation loss: 2.5095654975012534

Epoch: 5| Step: 4
Training loss: 0.10437534609183306
Validation loss: 2.509537579471337

Epoch: 5| Step: 5
Training loss: 0.1664265931370091
Validation loss: 2.510314177157615

Epoch: 5| Step: 6
Training loss: 0.05362814026823972
Validation loss: 2.4884896969179042

Epoch: 5| Step: 7
Training loss: 0.10669240358231702
Validation loss: 2.4969413540798033

Epoch: 5| Step: 8
Training loss: 0.14956309795539074
Validation loss: 2.503606059810647

Epoch: 5| Step: 9
Training loss: 0.11320618082348825
Validation loss: 2.5115618300692506

Epoch: 5| Step: 10
Training loss: 0.16718561002073046
Validation loss: 2.5135059536023157

Epoch: 633| Step: 0
Training loss: 0.09749066619945543
Validation loss: 2.515158748965613

Epoch: 5| Step: 1
Training loss: 0.1006484115432958
Validation loss: 2.4899675901066107

Epoch: 5| Step: 2
Training loss: 0.13181973110476128
Validation loss: 2.498504772964794

Epoch: 5| Step: 3
Training loss: 0.16460734111287964
Validation loss: 2.4899712152831563

Epoch: 5| Step: 4
Training loss: 0.10120635218449354
Validation loss: 2.4934630340385384

Epoch: 5| Step: 5
Training loss: 0.08609004461861394
Validation loss: 2.485959456438677

Epoch: 5| Step: 6
Training loss: 0.08260652369583528
Validation loss: 2.496049804752565

Epoch: 5| Step: 7
Training loss: 0.15100845774788474
Validation loss: 2.513491727353627

Epoch: 5| Step: 8
Training loss: 0.09062070343092692
Validation loss: 2.484603922884164

Epoch: 5| Step: 9
Training loss: 0.15445519425198007
Validation loss: 2.482115761742718

Epoch: 5| Step: 10
Training loss: 0.0949136518519278
Validation loss: 2.504566915785696

Epoch: 634| Step: 0
Training loss: 0.11871554806647125
Validation loss: 2.4764737540670376

Epoch: 5| Step: 1
Training loss: 0.09097705666492606
Validation loss: 2.4689257252756

Epoch: 5| Step: 2
Training loss: 0.18164401922848827
Validation loss: 2.4989703283198295

Epoch: 5| Step: 3
Training loss: 0.08486319543024252
Validation loss: 2.472985909521099

Epoch: 5| Step: 4
Training loss: 0.08213958512051259
Validation loss: 2.446564323912672

Epoch: 5| Step: 5
Training loss: 0.17732235027378818
Validation loss: 2.4544789115756473

Epoch: 5| Step: 6
Training loss: 0.16155712440630707
Validation loss: 2.4744493516428037

Epoch: 5| Step: 7
Training loss: 0.13105726225323466
Validation loss: 2.465049613235864

Epoch: 5| Step: 8
Training loss: 0.1067170646431074
Validation loss: 2.4270355087512483

Epoch: 5| Step: 9
Training loss: 0.07858431916410293
Validation loss: 2.466648424868769

Epoch: 5| Step: 10
Training loss: 0.12808492574615016
Validation loss: 2.4370105526512478

Epoch: 635| Step: 0
Training loss: 0.05189447982980796
Validation loss: 2.4482213536089046

Epoch: 5| Step: 1
Training loss: 0.16638865915190879
Validation loss: 2.4440503260274298

Epoch: 5| Step: 2
Training loss: 0.16202532071343917
Validation loss: 2.4539823479358724

Epoch: 5| Step: 3
Training loss: 0.08471646157673819
Validation loss: 2.473953033251609

Epoch: 5| Step: 4
Training loss: 0.11446670445159186
Validation loss: 2.4755554646521403

Epoch: 5| Step: 5
Training loss: 0.15408818703007232
Validation loss: 2.471908657718657

Epoch: 5| Step: 6
Training loss: 0.14720846503674126
Validation loss: 2.4776415247139116

Epoch: 5| Step: 7
Training loss: 0.07415333173694799
Validation loss: 2.4506481252191796

Epoch: 5| Step: 8
Training loss: 0.08946643255605415
Validation loss: 2.49291066178396

Epoch: 5| Step: 9
Training loss: 0.08802291662621227
Validation loss: 2.463899049841507

Epoch: 5| Step: 10
Training loss: 0.08197823866531397
Validation loss: 2.5126834252458834

Epoch: 636| Step: 0
Training loss: 0.07052747658289463
Validation loss: 2.4781603919694186

Epoch: 5| Step: 1
Training loss: 0.06224080258968162
Validation loss: 2.4633291056069684

Epoch: 5| Step: 2
Training loss: 0.14197763292314963
Validation loss: 2.475128611702016

Epoch: 5| Step: 3
Training loss: 0.11628504802244297
Validation loss: 2.5099519610885115

Epoch: 5| Step: 4
Training loss: 0.09794802470064168
Validation loss: 2.5046204109104715

Epoch: 5| Step: 5
Training loss: 0.07578915648164064
Validation loss: 2.4877162018822196

Epoch: 5| Step: 6
Training loss: 0.1318575029042508
Validation loss: 2.4866647341278982

Epoch: 5| Step: 7
Training loss: 0.0819892378354191
Validation loss: 2.471109621135512

Epoch: 5| Step: 8
Training loss: 0.1127284059246246
Validation loss: 2.470963094266174

Epoch: 5| Step: 9
Training loss: 0.11629872652568794
Validation loss: 2.493322223598877

Epoch: 5| Step: 10
Training loss: 0.2243045562948901
Validation loss: 2.483659419992875

Epoch: 637| Step: 0
Training loss: 0.12964178968800408
Validation loss: 2.512831010534716

Epoch: 5| Step: 1
Training loss: 0.13338050274906627
Validation loss: 2.486883489134936

Epoch: 5| Step: 2
Training loss: 0.10688859175538384
Validation loss: 2.45678730489953

Epoch: 5| Step: 3
Training loss: 0.10528864317231143
Validation loss: 2.483277744971248

Epoch: 5| Step: 4
Training loss: 0.1489434341224182
Validation loss: 2.4596191776419896

Epoch: 5| Step: 5
Training loss: 0.08121593361808062
Validation loss: 2.4577645933043657

Epoch: 5| Step: 6
Training loss: 0.15877337759518265
Validation loss: 2.454784783064016

Epoch: 5| Step: 7
Training loss: 0.11320100194573757
Validation loss: 2.455151674548259

Epoch: 5| Step: 8
Training loss: 0.08232994138889868
Validation loss: 2.413129768164914

Epoch: 5| Step: 9
Training loss: 0.15908692002907465
Validation loss: 2.4226642403684107

Epoch: 5| Step: 10
Training loss: 0.11726174784000168
Validation loss: 2.4561802221224616

Epoch: 638| Step: 0
Training loss: 0.14466459334988305
Validation loss: 2.4296865123963998

Epoch: 5| Step: 1
Training loss: 0.1441357265456767
Validation loss: 2.4592076334233046

Epoch: 5| Step: 2
Training loss: 0.08287248800427799
Validation loss: 2.4557184446553557

Epoch: 5| Step: 3
Training loss: 0.07142262814587237
Validation loss: 2.4681098131818326

Epoch: 5| Step: 4
Training loss: 0.15636700779077597
Validation loss: 2.4918701790737896

Epoch: 5| Step: 5
Training loss: 0.09096647621872267
Validation loss: 2.4817954837589036

Epoch: 5| Step: 6
Training loss: 0.1203571574202319
Validation loss: 2.5183108373867897

Epoch: 5| Step: 7
Training loss: 0.17907797014272858
Validation loss: 2.492268476682475

Epoch: 5| Step: 8
Training loss: 0.09367938163528602
Validation loss: 2.5195744794307315

Epoch: 5| Step: 9
Training loss: 0.1150151648901541
Validation loss: 2.5369400672337403

Epoch: 5| Step: 10
Training loss: 0.12928734424419033
Validation loss: 2.5156719488981776

Epoch: 639| Step: 0
Training loss: 0.11930791647626135
Validation loss: 2.538285933282483

Epoch: 5| Step: 1
Training loss: 0.07186033355822567
Validation loss: 2.5227379694898975

Epoch: 5| Step: 2
Training loss: 0.07658524710556011
Validation loss: 2.4785023843122667

Epoch: 5| Step: 3
Training loss: 0.09173852506706287
Validation loss: 2.4795994169358715

Epoch: 5| Step: 4
Training loss: 0.07210459681971097
Validation loss: 2.498030933057075

Epoch: 5| Step: 5
Training loss: 0.06152578947324827
Validation loss: 2.4832783561292517

Epoch: 5| Step: 6
Training loss: 0.17101435408592677
Validation loss: 2.4913109573776704

Epoch: 5| Step: 7
Training loss: 0.15427184203649014
Validation loss: 2.452561232640861

Epoch: 5| Step: 8
Training loss: 0.1676673236062472
Validation loss: 2.4871836073104867

Epoch: 5| Step: 9
Training loss: 0.15811606943596654
Validation loss: 2.4819439616700754

Epoch: 5| Step: 10
Training loss: 0.15837068867366388
Validation loss: 2.4653419370928322

Epoch: 640| Step: 0
Training loss: 0.17132225345756041
Validation loss: 2.513755797385109

Epoch: 5| Step: 1
Training loss: 0.1148288915065877
Validation loss: 2.5301474881052117

Epoch: 5| Step: 2
Training loss: 0.16435862678127605
Validation loss: 2.5615235896256294

Epoch: 5| Step: 3
Training loss: 0.15687639918786211
Validation loss: 2.5637621348712085

Epoch: 5| Step: 4
Training loss: 0.1907818496813398
Validation loss: 2.5498560974435796

Epoch: 5| Step: 5
Training loss: 0.09868614718770467
Validation loss: 2.5456894209375602

Epoch: 5| Step: 6
Training loss: 0.0862487094331674
Validation loss: 2.535557445252755

Epoch: 5| Step: 7
Training loss: 0.08632221859797033
Validation loss: 2.5175921041335916

Epoch: 5| Step: 8
Training loss: 0.08167139379298641
Validation loss: 2.5141638276077476

Epoch: 5| Step: 9
Training loss: 0.08533978129943498
Validation loss: 2.5136468470498445

Epoch: 5| Step: 10
Training loss: 0.09921113983765692
Validation loss: 2.519426362179666

Epoch: 641| Step: 0
Training loss: 0.12534946526674687
Validation loss: 2.468813591487643

Epoch: 5| Step: 1
Training loss: 0.12722141087953304
Validation loss: 2.491516315043484

Epoch: 5| Step: 2
Training loss: 0.09594572226178497
Validation loss: 2.4792302348327913

Epoch: 5| Step: 3
Training loss: 0.15183914194928452
Validation loss: 2.486175677046822

Epoch: 5| Step: 4
Training loss: 0.07009649542556574
Validation loss: 2.494854573654221

Epoch: 5| Step: 5
Training loss: 0.16136040653228909
Validation loss: 2.4927120083052974

Epoch: 5| Step: 6
Training loss: 0.1677381240752667
Validation loss: 2.4883843269208725

Epoch: 5| Step: 7
Training loss: 0.1753419791645323
Validation loss: 2.5093262089964723

Epoch: 5| Step: 8
Training loss: 0.09998861747274147
Validation loss: 2.5181740948854494

Epoch: 5| Step: 9
Training loss: 0.20113940115735385
Validation loss: 2.495138121457441

Epoch: 5| Step: 10
Training loss: 0.08903612595438759
Validation loss: 2.472702081151841

Epoch: 642| Step: 0
Training loss: 0.11948742577379588
Validation loss: 2.4446076650427644

Epoch: 5| Step: 1
Training loss: 0.12663744779504196
Validation loss: 2.414722431407708

Epoch: 5| Step: 2
Training loss: 0.23683809790616078
Validation loss: 2.4215571940922787

Epoch: 5| Step: 3
Training loss: 0.21633278946068535
Validation loss: 2.4258256956740927

Epoch: 5| Step: 4
Training loss: 0.12839898088721455
Validation loss: 2.4384719839587827

Epoch: 5| Step: 5
Training loss: 0.14603381482955016
Validation loss: 2.4821726140398046

Epoch: 5| Step: 6
Training loss: 0.13024975276839357
Validation loss: 2.507948321165507

Epoch: 5| Step: 7
Training loss: 0.2922329117679641
Validation loss: 2.5469853553239026

Epoch: 5| Step: 8
Training loss: 0.2244407518417368
Validation loss: 2.485159676456714

Epoch: 5| Step: 9
Training loss: 0.16522187485543818
Validation loss: 2.450734242911702

Epoch: 5| Step: 10
Training loss: 0.15552170417138986
Validation loss: 2.4276767568415387

Epoch: 643| Step: 0
Training loss: 0.18448247282647326
Validation loss: 2.4415517419265744

Epoch: 5| Step: 1
Training loss: 0.24115856080766598
Validation loss: 2.493865053475944

Epoch: 5| Step: 2
Training loss: 0.16016347217558016
Validation loss: 2.492144540277672

Epoch: 5| Step: 3
Training loss: 0.11013229917996668
Validation loss: 2.4975618235000705

Epoch: 5| Step: 4
Training loss: 0.179071604429003
Validation loss: 2.5401085255547087

Epoch: 5| Step: 5
Training loss: 0.1521455318873741
Validation loss: 2.5211710729468213

Epoch: 5| Step: 6
Training loss: 0.13768904245588798
Validation loss: 2.5074685753184047

Epoch: 5| Step: 7
Training loss: 0.14582516797798498
Validation loss: 2.548766875372877

Epoch: 5| Step: 8
Training loss: 0.1982479094633205
Validation loss: 2.512361101692462

Epoch: 5| Step: 9
Training loss: 0.2627186534396353
Validation loss: 2.4564695855722642

Epoch: 5| Step: 10
Training loss: 0.20281522311129685
Validation loss: 2.4722595067623416

Epoch: 644| Step: 0
Training loss: 0.1859321509321135
Validation loss: 2.4218233058677363

Epoch: 5| Step: 1
Training loss: 0.1586117764737323
Validation loss: 2.4545954658957005

Epoch: 5| Step: 2
Training loss: 0.26979784289523506
Validation loss: 2.435992931669377

Epoch: 5| Step: 3
Training loss: 0.22861941336286784
Validation loss: 2.4562710335676416

Epoch: 5| Step: 4
Training loss: 0.178196609893067
Validation loss: 2.4456046693016673

Epoch: 5| Step: 5
Training loss: 0.12063073268174869
Validation loss: 2.5045110329744853

Epoch: 5| Step: 6
Training loss: 0.13107676739318744
Validation loss: 2.5615388366712484

Epoch: 5| Step: 7
Training loss: 0.18568513637875766
Validation loss: 2.5718556355650586

Epoch: 5| Step: 8
Training loss: 0.1484434854404947
Validation loss: 2.5665743012010256

Epoch: 5| Step: 9
Training loss: 0.19762855607174548
Validation loss: 2.596578732080422

Epoch: 5| Step: 10
Training loss: 0.14252206274991278
Validation loss: 2.614938564180803

Epoch: 645| Step: 0
Training loss: 0.17796539132663997
Validation loss: 2.5991836526791348

Epoch: 5| Step: 1
Training loss: 0.20288172238530158
Validation loss: 2.6111203455828966

Epoch: 5| Step: 2
Training loss: 0.19051028771168127
Validation loss: 2.583501285038093

Epoch: 5| Step: 3
Training loss: 0.21350375959393872
Validation loss: 2.5434431655474943

Epoch: 5| Step: 4
Training loss: 0.20868629517140322
Validation loss: 2.5367856594111635

Epoch: 5| Step: 5
Training loss: 0.13361101763931957
Validation loss: 2.5169882856380767

Epoch: 5| Step: 6
Training loss: 0.18923670411867635
Validation loss: 2.52038607743772

Epoch: 5| Step: 7
Training loss: 0.19543162527730581
Validation loss: 2.4901352899227045

Epoch: 5| Step: 8
Training loss: 0.1693505350176686
Validation loss: 2.4896074419934804

Epoch: 5| Step: 9
Training loss: 0.2277895240683507
Validation loss: 2.545772897601718

Epoch: 5| Step: 10
Training loss: 0.1497091421338073
Validation loss: 2.4954569772073145

Epoch: 646| Step: 0
Training loss: 0.2298320931461568
Validation loss: 2.530803081395894

Epoch: 5| Step: 1
Training loss: 0.1678573050170263
Validation loss: 2.5086155583392507

Epoch: 5| Step: 2
Training loss: 0.11961477546534724
Validation loss: 2.495905328027539

Epoch: 5| Step: 3
Training loss: 0.13837944009121994
Validation loss: 2.5111425942689953

Epoch: 5| Step: 4
Training loss: 0.2474444651070243
Validation loss: 2.47818453641113

Epoch: 5| Step: 5
Training loss: 0.31835877822164754
Validation loss: 2.506390938672675

Epoch: 5| Step: 6
Training loss: 0.18410945050657995
Validation loss: 2.4871210854193633

Epoch: 5| Step: 7
Training loss: 0.2854818810260115
Validation loss: 2.4731768644011667

Epoch: 5| Step: 8
Training loss: 0.28140740493376437
Validation loss: 2.498967275302711

Epoch: 5| Step: 9
Training loss: 0.14718234669720906
Validation loss: 2.5538780573548463

Epoch: 5| Step: 10
Training loss: 0.1348274752452798
Validation loss: 2.550645756776785

Epoch: 647| Step: 0
Training loss: 0.2422696481867022
Validation loss: 2.5642387879694213

Epoch: 5| Step: 1
Training loss: 0.2704984201942186
Validation loss: 2.561569991524225

Epoch: 5| Step: 2
Training loss: 0.12962572568342676
Validation loss: 2.503404651376019

Epoch: 5| Step: 3
Training loss: 0.18499950180115504
Validation loss: 2.463211345105128

Epoch: 5| Step: 4
Training loss: 0.24807538597073447
Validation loss: 2.4114289194362883

Epoch: 5| Step: 5
Training loss: 0.18365900422128098
Validation loss: 2.3582505108937695

Epoch: 5| Step: 6
Training loss: 0.3513316244095718
Validation loss: 2.3308991705267217

Epoch: 5| Step: 7
Training loss: 0.23155956426038812
Validation loss: 2.3760985099157925

Epoch: 5| Step: 8
Training loss: 0.3028506025114359
Validation loss: 2.333295026001801

Epoch: 5| Step: 9
Training loss: 0.2575967203589357
Validation loss: 2.3557965575614124

Epoch: 5| Step: 10
Training loss: 0.26392099832776844
Validation loss: 2.384929527892091

Epoch: 648| Step: 0
Training loss: 0.23793266939590924
Validation loss: 2.441990366111857

Epoch: 5| Step: 1
Training loss: 0.31121770511210095
Validation loss: 2.464410982599984

Epoch: 5| Step: 2
Training loss: 0.25271411678953487
Validation loss: 2.4457615297206217

Epoch: 5| Step: 3
Training loss: 0.21636659864878238
Validation loss: 2.4454883044529723

Epoch: 5| Step: 4
Training loss: 0.3780717607329763
Validation loss: 2.4525679873031927

Epoch: 5| Step: 5
Training loss: 0.28731731747498357
Validation loss: 2.479725724434376

Epoch: 5| Step: 6
Training loss: 0.18966030315518953
Validation loss: 2.4537555842161343

Epoch: 5| Step: 7
Training loss: 0.3467899630674805
Validation loss: 2.46167257060379

Epoch: 5| Step: 8
Training loss: 0.4081541698248883
Validation loss: 2.49971593042757

Epoch: 5| Step: 9
Training loss: 0.3542176331518039
Validation loss: 2.4511532184561013

Epoch: 5| Step: 10
Training loss: 0.5954909900605049
Validation loss: 2.436745861673702

Epoch: 649| Step: 0
Training loss: 0.194835738986351
Validation loss: 2.4342325658936357

Epoch: 5| Step: 1
Training loss: 0.20958440862996613
Validation loss: 2.4823926943614145

Epoch: 5| Step: 2
Training loss: 0.3683444727030249
Validation loss: 2.536497411717242

Epoch: 5| Step: 3
Training loss: 0.4267076510840592
Validation loss: 2.5423323312501958

Epoch: 5| Step: 4
Training loss: 0.6486174552039056
Validation loss: 2.6132398532447207

Epoch: 5| Step: 5
Training loss: 0.2845018271704328
Validation loss: 2.530326765032628

Epoch: 5| Step: 6
Training loss: 0.32040894614807636
Validation loss: 2.485557237192737

Epoch: 5| Step: 7
Training loss: 0.4480646816662952
Validation loss: 2.4836483464947023

Epoch: 5| Step: 8
Training loss: 0.43868225302780545
Validation loss: 2.4855557746460546

Epoch: 5| Step: 9
Training loss: 0.6556996581023307
Validation loss: 2.52784000815802

Epoch: 5| Step: 10
Training loss: 0.5263655172402912
Validation loss: 2.563230675971402

Epoch: 650| Step: 0
Training loss: 0.24007971367401912
Validation loss: 2.6218802686251608

Epoch: 5| Step: 1
Training loss: 0.5584732939483159
Validation loss: 2.66686740402986

Epoch: 5| Step: 2
Training loss: 0.5307227210744397
Validation loss: 2.612003159492817

Epoch: 5| Step: 3
Training loss: 0.410583600435092
Validation loss: 2.6515558525310206

Epoch: 5| Step: 4
Training loss: 0.4610245509302515
Validation loss: 2.655315841493529

Epoch: 5| Step: 5
Training loss: 0.6837040839390891
Validation loss: 2.5649304752729862

Epoch: 5| Step: 6
Training loss: 0.5510517024500668
Validation loss: 2.5252545887030347

Epoch: 5| Step: 7
Training loss: 0.4264056326028919
Validation loss: 2.5250949037257784

Epoch: 5| Step: 8
Training loss: 0.4828472964392528
Validation loss: 2.508176763652861

Epoch: 5| Step: 9
Training loss: 0.3912961153878256
Validation loss: 2.516093137220535

Epoch: 5| Step: 10
Training loss: 0.4909319075636792
Validation loss: 2.5059821589568223

Epoch: 651| Step: 0
Training loss: 0.45341571163985306
Validation loss: 2.496634586426918

Epoch: 5| Step: 1
Training loss: 0.3698330596358662
Validation loss: 2.454259139601479

Epoch: 5| Step: 2
Training loss: 0.5114933711505228
Validation loss: 2.4500499749543616

Epoch: 5| Step: 3
Training loss: 0.43780891547685913
Validation loss: 2.4512282746739102

Epoch: 5| Step: 4
Training loss: 0.3082947187579821
Validation loss: 2.472424784779736

Epoch: 5| Step: 5
Training loss: 0.36577834964532774
Validation loss: 2.4935269488586176

Epoch: 5| Step: 6
Training loss: 0.3565909937139537
Validation loss: 2.466926617866864

Epoch: 5| Step: 7
Training loss: 0.32583421372679255
Validation loss: 2.4457176565049608

Epoch: 5| Step: 8
Training loss: 0.47230370039123304
Validation loss: 2.4603896706333344

Epoch: 5| Step: 9
Training loss: 0.3321746852947337
Validation loss: 2.4611711455293412

Epoch: 5| Step: 10
Training loss: 0.26806350178352384
Validation loss: 2.4380447866399724

Epoch: 652| Step: 0
Training loss: 0.2501181085067061
Validation loss: 2.4933132319500757

Epoch: 5| Step: 1
Training loss: 0.35664621204625224
Validation loss: 2.472799140235752

Epoch: 5| Step: 2
Training loss: 0.41930020468370466
Validation loss: 2.471455039247614

Epoch: 5| Step: 3
Training loss: 0.30867177242508104
Validation loss: 2.45672924634363

Epoch: 5| Step: 4
Training loss: 0.2833098900904299
Validation loss: 2.4764214967214944

Epoch: 5| Step: 5
Training loss: 0.28251925803684563
Validation loss: 2.46836898166711

Epoch: 5| Step: 6
Training loss: 0.365859063535497
Validation loss: 2.4706022895127036

Epoch: 5| Step: 7
Training loss: 0.34952783965764955
Validation loss: 2.472810389835773

Epoch: 5| Step: 8
Training loss: 0.34201043133136355
Validation loss: 2.4255407223803407

Epoch: 5| Step: 9
Training loss: 0.30546307278013657
Validation loss: 2.4424357739818876

Epoch: 5| Step: 10
Training loss: 0.284270072275282
Validation loss: 2.4304775007130495

Epoch: 653| Step: 0
Training loss: 0.46637127040638554
Validation loss: 2.4608297834572204

Epoch: 5| Step: 1
Training loss: 0.3448856840231237
Validation loss: 2.3948211133143573

Epoch: 5| Step: 2
Training loss: 0.29005057058398237
Validation loss: 2.4304668705274923

Epoch: 5| Step: 3
Training loss: 0.33081265269379917
Validation loss: 2.4096242948144293

Epoch: 5| Step: 4
Training loss: 0.23546292214880024
Validation loss: 2.408844312510779

Epoch: 5| Step: 5
Training loss: 0.4048631544626856
Validation loss: 2.402610808651238

Epoch: 5| Step: 6
Training loss: 0.3799916481681354
Validation loss: 2.430317909080599

Epoch: 5| Step: 7
Training loss: 0.33186779486742657
Validation loss: 2.4335628756371945

Epoch: 5| Step: 8
Training loss: 0.34492320646934094
Validation loss: 2.435845580592582

Epoch: 5| Step: 9
Training loss: 0.3005743677640445
Validation loss: 2.431344369921657

Epoch: 5| Step: 10
Training loss: 0.26479059884441053
Validation loss: 2.4697373486056677

Epoch: 654| Step: 0
Training loss: 0.34188191037281196
Validation loss: 2.5128382908146065

Epoch: 5| Step: 1
Training loss: 0.28501763305993955
Validation loss: 2.5466196855874794

Epoch: 5| Step: 2
Training loss: 0.19960619145670908
Validation loss: 2.585067899726249

Epoch: 5| Step: 3
Training loss: 0.2787434222852287
Validation loss: 2.5354923468107105

Epoch: 5| Step: 4
Training loss: 0.29058192405590505
Validation loss: 2.557355505304354

Epoch: 5| Step: 5
Training loss: 0.2709481686666251
Validation loss: 2.5597095457814185

Epoch: 5| Step: 6
Training loss: 0.4035448091483399
Validation loss: 2.5171237568219644

Epoch: 5| Step: 7
Training loss: 0.2902882593996271
Validation loss: 2.499947564282725

Epoch: 5| Step: 8
Training loss: 0.24557299238077712
Validation loss: 2.492808370820304

Epoch: 5| Step: 9
Training loss: 0.37788864031119285
Validation loss: 2.449181713707325

Epoch: 5| Step: 10
Training loss: 0.2757155077978301
Validation loss: 2.464192235317546

Epoch: 655| Step: 0
Training loss: 0.18912806595676443
Validation loss: 2.4630276045810278

Epoch: 5| Step: 1
Training loss: 0.3438710303082649
Validation loss: 2.4582363218670893

Epoch: 5| Step: 2
Training loss: 0.2851932188134069
Validation loss: 2.4834125078651685

Epoch: 5| Step: 3
Training loss: 0.23246377679433475
Validation loss: 2.484803820921617

Epoch: 5| Step: 4
Training loss: 0.16660358432200364
Validation loss: 2.456768500038152

Epoch: 5| Step: 5
Training loss: 0.1877039455845846
Validation loss: 2.44577536274129

Epoch: 5| Step: 6
Training loss: 0.24413590235910793
Validation loss: 2.4704980327595556

Epoch: 5| Step: 7
Training loss: 0.289435584068341
Validation loss: 2.4752894362720226

Epoch: 5| Step: 8
Training loss: 0.24133323935698775
Validation loss: 2.461473062462068

Epoch: 5| Step: 9
Training loss: 0.2038090083031672
Validation loss: 2.4725877188942382

Epoch: 5| Step: 10
Training loss: 0.13566560437363956
Validation loss: 2.440168568584505

Epoch: 656| Step: 0
Training loss: 0.21119143953907848
Validation loss: 2.452123740305172

Epoch: 5| Step: 1
Training loss: 0.20465041472544193
Validation loss: 2.4601602004203444

Epoch: 5| Step: 2
Training loss: 0.1695982712669651
Validation loss: 2.429789477407122

Epoch: 5| Step: 3
Training loss: 0.18210518812933132
Validation loss: 2.4271925964506025

Epoch: 5| Step: 4
Training loss: 0.23434676954005546
Validation loss: 2.445363491050504

Epoch: 5| Step: 5
Training loss: 0.23090233669302615
Validation loss: 2.443601353774975

Epoch: 5| Step: 6
Training loss: 0.2765916916694464
Validation loss: 2.4440592209477994

Epoch: 5| Step: 7
Training loss: 0.2182225612529895
Validation loss: 2.4686354525809198

Epoch: 5| Step: 8
Training loss: 0.20232091907440194
Validation loss: 2.4600729938762194

Epoch: 5| Step: 9
Training loss: 0.2736904745182029
Validation loss: 2.453626217939368

Epoch: 5| Step: 10
Training loss: 0.24501254215056203
Validation loss: 2.486773430543318

Epoch: 657| Step: 0
Training loss: 0.16786495594745138
Validation loss: 2.483853810268019

Epoch: 5| Step: 1
Training loss: 0.17172372186004345
Validation loss: 2.5213706371832285

Epoch: 5| Step: 2
Training loss: 0.11585959046717419
Validation loss: 2.490903011268222

Epoch: 5| Step: 3
Training loss: 0.22264763330216444
Validation loss: 2.515668146752813

Epoch: 5| Step: 4
Training loss: 0.15823398689372345
Validation loss: 2.51023323724338

Epoch: 5| Step: 5
Training loss: 0.23874511281848376
Validation loss: 2.4966034871442266

Epoch: 5| Step: 6
Training loss: 0.17255953457656276
Validation loss: 2.4925485599447326

Epoch: 5| Step: 7
Training loss: 0.16795838678904543
Validation loss: 2.4563614570616856

Epoch: 5| Step: 8
Training loss: 0.13878444347216273
Validation loss: 2.4698107657419364

Epoch: 5| Step: 9
Training loss: 0.21528796309471324
Validation loss: 2.440041306110902

Epoch: 5| Step: 10
Training loss: 0.1631770136640562
Validation loss: 2.4482001394239297

Epoch: 658| Step: 0
Training loss: 0.17792134354390474
Validation loss: 2.458673335993859

Epoch: 5| Step: 1
Training loss: 0.11859525084017047
Validation loss: 2.4683719863264213

Epoch: 5| Step: 2
Training loss: 0.24153924136687743
Validation loss: 2.4446731481680493

Epoch: 5| Step: 3
Training loss: 0.20328528242634514
Validation loss: 2.480007021621479

Epoch: 5| Step: 4
Training loss: 0.1731875328028141
Validation loss: 2.476376382465682

Epoch: 5| Step: 5
Training loss: 0.1396562667465968
Validation loss: 2.461378645987775

Epoch: 5| Step: 6
Training loss: 0.14440485866398914
Validation loss: 2.4795382800175916

Epoch: 5| Step: 7
Training loss: 0.11412738626665668
Validation loss: 2.492454971956852

Epoch: 5| Step: 8
Training loss: 0.146806128313283
Validation loss: 2.5122685160653266

Epoch: 5| Step: 9
Training loss: 0.136451855777528
Validation loss: 2.51787974871541

Epoch: 5| Step: 10
Training loss: 0.2324379666952775
Validation loss: 2.4931277432982393

Epoch: 659| Step: 0
Training loss: 0.14569881243625957
Validation loss: 2.5141592930901235

Epoch: 5| Step: 1
Training loss: 0.1887095103824816
Validation loss: 2.5118090737524064

Epoch: 5| Step: 2
Training loss: 0.20574573659361592
Validation loss: 2.507343428158013

Epoch: 5| Step: 3
Training loss: 0.14294780854031094
Validation loss: 2.4934854156185997

Epoch: 5| Step: 4
Training loss: 0.22504508838290013
Validation loss: 2.5337887652790796

Epoch: 5| Step: 5
Training loss: 0.18851642483582273
Validation loss: 2.4702717514855914

Epoch: 5| Step: 6
Training loss: 0.1298399402734307
Validation loss: 2.495628651377242

Epoch: 5| Step: 7
Training loss: 0.14540379922163624
Validation loss: 2.4847905373935046

Epoch: 5| Step: 8
Training loss: 0.09280125050490928
Validation loss: 2.515768878735304

Epoch: 5| Step: 9
Training loss: 0.17363688847120579
Validation loss: 2.4872758877869177

Epoch: 5| Step: 10
Training loss: 0.14960837973918495
Validation loss: 2.465997538761113

Epoch: 660| Step: 0
Training loss: 0.16225874006002658
Validation loss: 2.4679866299553836

Epoch: 5| Step: 1
Training loss: 0.1423993165193152
Validation loss: 2.4617104655856585

Epoch: 5| Step: 2
Training loss: 0.15056847299119072
Validation loss: 2.426834373234527

Epoch: 5| Step: 3
Training loss: 0.16564773862324564
Validation loss: 2.467223272060575

Epoch: 5| Step: 4
Training loss: 0.18924436176951656
Validation loss: 2.443671532862842

Epoch: 5| Step: 5
Training loss: 0.1371555435395402
Validation loss: 2.4673254384566987

Epoch: 5| Step: 6
Training loss: 0.12471616826531139
Validation loss: 2.426810552978382

Epoch: 5| Step: 7
Training loss: 0.1252776430171689
Validation loss: 2.4673350952409514

Epoch: 5| Step: 8
Training loss: 0.1762241822975043
Validation loss: 2.437305384298041

Epoch: 5| Step: 9
Training loss: 0.12935418273618285
Validation loss: 2.4694599819718466

Epoch: 5| Step: 10
Training loss: 0.17567796851880513
Validation loss: 2.4657761281872577

Epoch: 661| Step: 0
Training loss: 0.10398053636494606
Validation loss: 2.453582490578749

Epoch: 5| Step: 1
Training loss: 0.1741982976172907
Validation loss: 2.481821473354373

Epoch: 5| Step: 2
Training loss: 0.12543920752299711
Validation loss: 2.462822936996016

Epoch: 5| Step: 3
Training loss: 0.14155843669962961
Validation loss: 2.462387274104692

Epoch: 5| Step: 4
Training loss: 0.1617794759044082
Validation loss: 2.468404070417578

Epoch: 5| Step: 5
Training loss: 0.09250350129582653
Validation loss: 2.45259713917549

Epoch: 5| Step: 6
Training loss: 0.1724602099842871
Validation loss: 2.471632512334649

Epoch: 5| Step: 7
Training loss: 0.14336044768470022
Validation loss: 2.4336064228286283

Epoch: 5| Step: 8
Training loss: 0.12411847565753786
Validation loss: 2.4542185034795465

Epoch: 5| Step: 9
Training loss: 0.1531518873625858
Validation loss: 2.4436294050893874

Epoch: 5| Step: 10
Training loss: 0.20798341849835564
Validation loss: 2.4183321430642697

Epoch: 662| Step: 0
Training loss: 0.10562406248178816
Validation loss: 2.4355854796106335

Epoch: 5| Step: 1
Training loss: 0.14774686994520936
Validation loss: 2.4655953320957784

Epoch: 5| Step: 2
Training loss: 0.10177567008631165
Validation loss: 2.4543666703016958

Epoch: 5| Step: 3
Training loss: 0.11807908793858492
Validation loss: 2.4506157699561655

Epoch: 5| Step: 4
Training loss: 0.10318459356698376
Validation loss: 2.4563373752093094

Epoch: 5| Step: 5
Training loss: 0.1122751611788707
Validation loss: 2.4425078453906703

Epoch: 5| Step: 6
Training loss: 0.180095230746466
Validation loss: 2.4357396859057894

Epoch: 5| Step: 7
Training loss: 0.17327993190356938
Validation loss: 2.454598094189566

Epoch: 5| Step: 8
Training loss: 0.12584732878877106
Validation loss: 2.4391026104631788

Epoch: 5| Step: 9
Training loss: 0.10250974871924298
Validation loss: 2.45009890028781

Epoch: 5| Step: 10
Training loss: 0.18328955996537605
Validation loss: 2.440838940933693

Epoch: 663| Step: 0
Training loss: 0.08720390339845556
Validation loss: 2.4367693386255245

Epoch: 5| Step: 1
Training loss: 0.12392638757195132
Validation loss: 2.4594285616836817

Epoch: 5| Step: 2
Training loss: 0.19850999379043335
Validation loss: 2.408445326086759

Epoch: 5| Step: 3
Training loss: 0.13171700658583405
Validation loss: 2.440418506086507

Epoch: 5| Step: 4
Training loss: 0.11191879815006696
Validation loss: 2.4468384563323013

Epoch: 5| Step: 5
Training loss: 0.1605213121728441
Validation loss: 2.4309694740694936

Epoch: 5| Step: 6
Training loss: 0.10866698944496317
Validation loss: 2.4207350044203415

Epoch: 5| Step: 7
Training loss: 0.17845415730733502
Validation loss: 2.425779981802562

Epoch: 5| Step: 8
Training loss: 0.13310368957226046
Validation loss: 2.407272250639585

Epoch: 5| Step: 9
Training loss: 0.1316794137377568
Validation loss: 2.4227923425992985

Epoch: 5| Step: 10
Training loss: 0.0836038006328853
Validation loss: 2.4139719523066625

Epoch: 664| Step: 0
Training loss: 0.12603712474374051
Validation loss: 2.444900425030958

Epoch: 5| Step: 1
Training loss: 0.13445427075639857
Validation loss: 2.428951314255455

Epoch: 5| Step: 2
Training loss: 0.11557347302978378
Validation loss: 2.412117654361825

Epoch: 5| Step: 3
Training loss: 0.12460006870448513
Validation loss: 2.4263931730374586

Epoch: 5| Step: 4
Training loss: 0.15638196855793657
Validation loss: 2.4356629601312743

Epoch: 5| Step: 5
Training loss: 0.15428629971732477
Validation loss: 2.4182462904559765

Epoch: 5| Step: 6
Training loss: 0.10035353264780948
Validation loss: 2.4347396441636424

Epoch: 5| Step: 7
Training loss: 0.12111000367263391
Validation loss: 2.412211177823707

Epoch: 5| Step: 8
Training loss: 0.12442015104501918
Validation loss: 2.427555909814726

Epoch: 5| Step: 9
Training loss: 0.16218678797673983
Validation loss: 2.4319898526961485

Epoch: 5| Step: 10
Training loss: 0.2078330151749995
Validation loss: 2.427251687870437

Epoch: 665| Step: 0
Training loss: 0.12180603029025859
Validation loss: 2.447015877698017

Epoch: 5| Step: 1
Training loss: 0.08990866451349312
Validation loss: 2.421964683817245

Epoch: 5| Step: 2
Training loss: 0.14084064321009343
Validation loss: 2.4383440005281947

Epoch: 5| Step: 3
Training loss: 0.10399243913932012
Validation loss: 2.432759585260096

Epoch: 5| Step: 4
Training loss: 0.08242938235745872
Validation loss: 2.4566379900628976

Epoch: 5| Step: 5
Training loss: 0.13927451002859556
Validation loss: 2.447224695711471

Epoch: 5| Step: 6
Training loss: 0.1629881708545894
Validation loss: 2.453000021262202

Epoch: 5| Step: 7
Training loss: 0.1026964070322381
Validation loss: 2.452940787176031

Epoch: 5| Step: 8
Training loss: 0.1087104413963235
Validation loss: 2.461999085860576

Epoch: 5| Step: 9
Training loss: 0.16340083142158643
Validation loss: 2.453869171896205

Epoch: 5| Step: 10
Training loss: 0.13998078765768943
Validation loss: 2.4861381817866937

Epoch: 666| Step: 0
Training loss: 0.13054842086780746
Validation loss: 2.454312776539163

Epoch: 5| Step: 1
Training loss: 0.12925547199084292
Validation loss: 2.439810405431095

Epoch: 5| Step: 2
Training loss: 0.1786516539419704
Validation loss: 2.4261219589307843

Epoch: 5| Step: 3
Training loss: 0.1277499574378441
Validation loss: 2.462543957679542

Epoch: 5| Step: 4
Training loss: 0.1271971631186982
Validation loss: 2.448705496810116

Epoch: 5| Step: 5
Training loss: 0.11835765349517907
Validation loss: 2.4629499018710694

Epoch: 5| Step: 6
Training loss: 0.09527569806841173
Validation loss: 2.4581381994263776

Epoch: 5| Step: 7
Training loss: 0.10348820773098218
Validation loss: 2.447477292801408

Epoch: 5| Step: 8
Training loss: 0.16040172605379566
Validation loss: 2.4440991973411723

Epoch: 5| Step: 9
Training loss: 0.1503071243530359
Validation loss: 2.4413943590100207

Epoch: 5| Step: 10
Training loss: 0.20744513580587126
Validation loss: 2.4565442956831043

Epoch: 667| Step: 0
Training loss: 0.11679965449697077
Validation loss: 2.436636681144174

Epoch: 5| Step: 1
Training loss: 0.1349150685977461
Validation loss: 2.4262820901818656

Epoch: 5| Step: 2
Training loss: 0.18067968146365013
Validation loss: 2.4502408868343077

Epoch: 5| Step: 3
Training loss: 0.09722677205524108
Validation loss: 2.427447891653587

Epoch: 5| Step: 4
Training loss: 0.16434995128597796
Validation loss: 2.4593833535739686

Epoch: 5| Step: 5
Training loss: 0.16825595409682856
Validation loss: 2.451222300193635

Epoch: 5| Step: 6
Training loss: 0.11997578213862631
Validation loss: 2.4431386452682333

Epoch: 5| Step: 7
Training loss: 0.08570907318282404
Validation loss: 2.4672675426761326

Epoch: 5| Step: 8
Training loss: 0.19451446575696046
Validation loss: 2.4734364093858985

Epoch: 5| Step: 9
Training loss: 0.16675979773920685
Validation loss: 2.506047092035114

Epoch: 5| Step: 10
Training loss: 0.10050526411500384
Validation loss: 2.478753486079678

Epoch: 668| Step: 0
Training loss: 0.13566668901391551
Validation loss: 2.4637860171750323

Epoch: 5| Step: 1
Training loss: 0.1407237898008607
Validation loss: 2.4807280699712093

Epoch: 5| Step: 2
Training loss: 0.09778250162659147
Validation loss: 2.483115307365058

Epoch: 5| Step: 3
Training loss: 0.08783707576870207
Validation loss: 2.468536484024807

Epoch: 5| Step: 4
Training loss: 0.11885576902234937
Validation loss: 2.459709123685844

Epoch: 5| Step: 5
Training loss: 0.18348366906947083
Validation loss: 2.449640720921367

Epoch: 5| Step: 6
Training loss: 0.16166208214215824
Validation loss: 2.4795240150022546

Epoch: 5| Step: 7
Training loss: 0.13113995974338
Validation loss: 2.494987077493157

Epoch: 5| Step: 8
Training loss: 0.16405740230451654
Validation loss: 2.446891599018491

Epoch: 5| Step: 9
Training loss: 0.10819875522424582
Validation loss: 2.4456210971241146

Epoch: 5| Step: 10
Training loss: 0.1870340677557403
Validation loss: 2.453721095706907

Epoch: 669| Step: 0
Training loss: 0.16411357039350152
Validation loss: 2.4852458510797795

Epoch: 5| Step: 1
Training loss: 0.10838725917330992
Validation loss: 2.478896518161244

Epoch: 5| Step: 2
Training loss: 0.10636141734420089
Validation loss: 2.4644974052654494

Epoch: 5| Step: 3
Training loss: 0.12205792173441798
Validation loss: 2.4722068979792238

Epoch: 5| Step: 4
Training loss: 0.13954911334440523
Validation loss: 2.432878375851011

Epoch: 5| Step: 5
Training loss: 0.09168549131235684
Validation loss: 2.4559324413955754

Epoch: 5| Step: 6
Training loss: 0.17816936793642196
Validation loss: 2.452863060713118

Epoch: 5| Step: 7
Training loss: 0.17610277334719046
Validation loss: 2.432544765086856

Epoch: 5| Step: 8
Training loss: 0.1355330001149856
Validation loss: 2.4475820828944603

Epoch: 5| Step: 9
Training loss: 0.16939457380852196
Validation loss: 2.434429008441552

Epoch: 5| Step: 10
Training loss: 0.14305251382810993
Validation loss: 2.4416983559711567

Epoch: 670| Step: 0
Training loss: 0.1388661742676416
Validation loss: 2.4325001607864767

Epoch: 5| Step: 1
Training loss: 0.1369476445870141
Validation loss: 2.4598798164908433

Epoch: 5| Step: 2
Training loss: 0.12657692997698772
Validation loss: 2.451172382253527

Epoch: 5| Step: 3
Training loss: 0.14128346723973778
Validation loss: 2.441605343024604

Epoch: 5| Step: 4
Training loss: 0.22180778734559614
Validation loss: 2.4579274822978046

Epoch: 5| Step: 5
Training loss: 0.11542790939200825
Validation loss: 2.437634684436297

Epoch: 5| Step: 6
Training loss: 0.17357631725434777
Validation loss: 2.456184913256984

Epoch: 5| Step: 7
Training loss: 0.17496754609334395
Validation loss: 2.463642288883346

Epoch: 5| Step: 8
Training loss: 0.09792174489298897
Validation loss: 2.4608206131810424

Epoch: 5| Step: 9
Training loss: 0.09851179157818447
Validation loss: 2.475994102461594

Epoch: 5| Step: 10
Training loss: 0.13801814847410088
Validation loss: 2.485282006436655

Epoch: 671| Step: 0
Training loss: 0.14330034365878988
Validation loss: 2.5211296122692546

Epoch: 5| Step: 1
Training loss: 0.14210372542380964
Validation loss: 2.4894389538306827

Epoch: 5| Step: 2
Training loss: 0.13048738300874788
Validation loss: 2.5106595755445964

Epoch: 5| Step: 3
Training loss: 0.15368045131331995
Validation loss: 2.491254271433157

Epoch: 5| Step: 4
Training loss: 0.12062762130349902
Validation loss: 2.4796950553692456

Epoch: 5| Step: 5
Training loss: 0.101517057339435
Validation loss: 2.502915887661486

Epoch: 5| Step: 6
Training loss: 0.10848239276535945
Validation loss: 2.4965232340848984

Epoch: 5| Step: 7
Training loss: 0.1105965494287712
Validation loss: 2.4973334458058547

Epoch: 5| Step: 8
Training loss: 0.11481894757259681
Validation loss: 2.5016380040461668

Epoch: 5| Step: 9
Training loss: 0.0736766170106228
Validation loss: 2.476294401592276

Epoch: 5| Step: 10
Training loss: 0.1076430644444027
Validation loss: 2.491648535464083

Epoch: 672| Step: 0
Training loss: 0.1480903770427314
Validation loss: 2.50504497201562

Epoch: 5| Step: 1
Training loss: 0.08312619967150653
Validation loss: 2.4833438369150045

Epoch: 5| Step: 2
Training loss: 0.13373912798287052
Validation loss: 2.4704824028432846

Epoch: 5| Step: 3
Training loss: 0.09724770442152067
Validation loss: 2.459044516467488

Epoch: 5| Step: 4
Training loss: 0.14560863662845255
Validation loss: 2.4571155700765233

Epoch: 5| Step: 5
Training loss: 0.12920862193932892
Validation loss: 2.423925016301241

Epoch: 5| Step: 6
Training loss: 0.10546744752009024
Validation loss: 2.4521645564595227

Epoch: 5| Step: 7
Training loss: 0.08652704308878523
Validation loss: 2.4197719963598936

Epoch: 5| Step: 8
Training loss: 0.12321714700018464
Validation loss: 2.4361197673816104

Epoch: 5| Step: 9
Training loss: 0.08855787881452652
Validation loss: 2.4469789233080705

Epoch: 5| Step: 10
Training loss: 0.11373575879908723
Validation loss: 2.413870462171311

Epoch: 673| Step: 0
Training loss: 0.1351362329334536
Validation loss: 2.439377656032299

Epoch: 5| Step: 1
Training loss: 0.08854250229646883
Validation loss: 2.473535404723192

Epoch: 5| Step: 2
Training loss: 0.0873585756562448
Validation loss: 2.434412245507824

Epoch: 5| Step: 3
Training loss: 0.11055380088488913
Validation loss: 2.4242448182096528

Epoch: 5| Step: 4
Training loss: 0.18224950484481967
Validation loss: 2.4340719721225432

Epoch: 5| Step: 5
Training loss: 0.11879515589295923
Validation loss: 2.4319045876578773

Epoch: 5| Step: 6
Training loss: 0.10714077583843115
Validation loss: 2.4457061009433216

Epoch: 5| Step: 7
Training loss: 0.12030056779695547
Validation loss: 2.4226503145394966

Epoch: 5| Step: 8
Training loss: 0.13133745969312627
Validation loss: 2.441128558636125

Epoch: 5| Step: 9
Training loss: 0.1663944634216831
Validation loss: 2.4236938273301014

Epoch: 5| Step: 10
Training loss: 0.09153938704789057
Validation loss: 2.430339188640749

Epoch: 674| Step: 0
Training loss: 0.0790544681700593
Validation loss: 2.4596964628779183

Epoch: 5| Step: 1
Training loss: 0.06049992101997647
Validation loss: 2.461278031568379

Epoch: 5| Step: 2
Training loss: 0.14646477886096265
Validation loss: 2.450994711592199

Epoch: 5| Step: 3
Training loss: 0.06979847813693656
Validation loss: 2.4836653716680823

Epoch: 5| Step: 4
Training loss: 0.12981035606457839
Validation loss: 2.474285111318243

Epoch: 5| Step: 5
Training loss: 0.17097994359390198
Validation loss: 2.4795115479092518

Epoch: 5| Step: 6
Training loss: 0.09444741776122381
Validation loss: 2.481945427378022

Epoch: 5| Step: 7
Training loss: 0.10461131106202533
Validation loss: 2.480713984380174

Epoch: 5| Step: 8
Training loss: 0.12408768123863444
Validation loss: 2.4797607320908988

Epoch: 5| Step: 9
Training loss: 0.14166262395316967
Validation loss: 2.494364017410153

Epoch: 5| Step: 10
Training loss: 0.12643633340673574
Validation loss: 2.494559350403082

Epoch: 675| Step: 0
Training loss: 0.15402839335344476
Validation loss: 2.486554682865378

Epoch: 5| Step: 1
Training loss: 0.13623409198058253
Validation loss: 2.4727812015224564

Epoch: 5| Step: 2
Training loss: 0.10105550288640774
Validation loss: 2.4914326035757135

Epoch: 5| Step: 3
Training loss: 0.16528325947206965
Validation loss: 2.483099565351637

Epoch: 5| Step: 4
Training loss: 0.12781171965185964
Validation loss: 2.490231143467556

Epoch: 5| Step: 5
Training loss: 0.13928060839930828
Validation loss: 2.4760057651630847

Epoch: 5| Step: 6
Training loss: 0.09431026851916258
Validation loss: 2.451039165503935

Epoch: 5| Step: 7
Training loss: 0.09316269375737304
Validation loss: 2.4546083598094954

Epoch: 5| Step: 8
Training loss: 0.09304681954113951
Validation loss: 2.4459189832786703

Epoch: 5| Step: 9
Training loss: 0.07572473207806064
Validation loss: 2.4300953565231613

Epoch: 5| Step: 10
Training loss: 0.09331036841646433
Validation loss: 2.4535444956597217

Epoch: 676| Step: 0
Training loss: 0.1902890003584978
Validation loss: 2.473753894763316

Epoch: 5| Step: 1
Training loss: 0.12005030312807706
Validation loss: 2.4658386688540106

Epoch: 5| Step: 2
Training loss: 0.09877122477399086
Validation loss: 2.4754415977232758

Epoch: 5| Step: 3
Training loss: 0.07814936258015819
Validation loss: 2.434501460098236

Epoch: 5| Step: 4
Training loss: 0.1444062710724654
Validation loss: 2.4746034875305636

Epoch: 5| Step: 5
Training loss: 0.08166631632035551
Validation loss: 2.4384416996621487

Epoch: 5| Step: 6
Training loss: 0.0911949950423214
Validation loss: 2.448872450365982

Epoch: 5| Step: 7
Training loss: 0.08326065599701517
Validation loss: 2.4844601679060956

Epoch: 5| Step: 8
Training loss: 0.1782325010324066
Validation loss: 2.4563713030626535

Epoch: 5| Step: 9
Training loss: 0.16246798502556148
Validation loss: 2.4248976698448197

Epoch: 5| Step: 10
Training loss: 0.07192296871233825
Validation loss: 2.4405688163882138

Epoch: 677| Step: 0
Training loss: 0.20910343450816074
Validation loss: 2.4867120957716358

Epoch: 5| Step: 1
Training loss: 0.12394963343795187
Validation loss: 2.464663896547723

Epoch: 5| Step: 2
Training loss: 0.1345605395440481
Validation loss: 2.4830255138293698

Epoch: 5| Step: 3
Training loss: 0.11242663769710391
Validation loss: 2.4891682812290603

Epoch: 5| Step: 4
Training loss: 0.10628730963846159
Validation loss: 2.486583224936267

Epoch: 5| Step: 5
Training loss: 0.07895484905410215
Validation loss: 2.4568280258373427

Epoch: 5| Step: 6
Training loss: 0.07161437236870412
Validation loss: 2.51929175817463

Epoch: 5| Step: 7
Training loss: 0.17844972124353187
Validation loss: 2.480632269839538

Epoch: 5| Step: 8
Training loss: 0.12300425124260088
Validation loss: 2.5068863510590824

Epoch: 5| Step: 9
Training loss: 0.09849085837570541
Validation loss: 2.4950364306822963

Epoch: 5| Step: 10
Training loss: 0.08525788821155253
Validation loss: 2.4789015991129664

Epoch: 678| Step: 0
Training loss: 0.14452697773366938
Validation loss: 2.4560553597099273

Epoch: 5| Step: 1
Training loss: 0.14839200527291918
Validation loss: 2.4438414287456034

Epoch: 5| Step: 2
Training loss: 0.14295685775991887
Validation loss: 2.466416780418652

Epoch: 5| Step: 3
Training loss: 0.10927535524851634
Validation loss: 2.45020437030688

Epoch: 5| Step: 4
Training loss: 0.1459322761196994
Validation loss: 2.470470097665021

Epoch: 5| Step: 5
Training loss: 0.07790124261721809
Validation loss: 2.4646499833508866

Epoch: 5| Step: 6
Training loss: 0.08715504018136064
Validation loss: 2.470784225796229

Epoch: 5| Step: 7
Training loss: 0.10819668509671576
Validation loss: 2.4756415200191433

Epoch: 5| Step: 8
Training loss: 0.1473751829282096
Validation loss: 2.490883764100213

Epoch: 5| Step: 9
Training loss: 0.15960065490159853
Validation loss: 2.4367972497599375

Epoch: 5| Step: 10
Training loss: 0.10477851249345338
Validation loss: 2.438088261139555

Epoch: 679| Step: 0
Training loss: 0.1481392650133435
Validation loss: 2.4750113535770097

Epoch: 5| Step: 1
Training loss: 0.12769964515941806
Validation loss: 2.4602177320170755

Epoch: 5| Step: 2
Training loss: 0.07639281923244656
Validation loss: 2.4502643589912108

Epoch: 5| Step: 3
Training loss: 0.16131435340125513
Validation loss: 2.435620300705586

Epoch: 5| Step: 4
Training loss: 0.09002897615682849
Validation loss: 2.4342132318733993

Epoch: 5| Step: 5
Training loss: 0.10869872110572111
Validation loss: 2.4347964486912224

Epoch: 5| Step: 6
Training loss: 0.08020140880671138
Validation loss: 2.4560070373679106

Epoch: 5| Step: 7
Training loss: 0.13602984432411708
Validation loss: 2.4619796835364807

Epoch: 5| Step: 8
Training loss: 0.10122887669937397
Validation loss: 2.46134414555539

Epoch: 5| Step: 9
Training loss: 0.08283087441091484
Validation loss: 2.4306336339860715

Epoch: 5| Step: 10
Training loss: 0.1316567085696369
Validation loss: 2.438447121961923

Epoch: 680| Step: 0
Training loss: 0.09200831168694355
Validation loss: 2.4491403663369042

Epoch: 5| Step: 1
Training loss: 0.10975910757950157
Validation loss: 2.4502654664688546

Epoch: 5| Step: 2
Training loss: 0.07577642469676178
Validation loss: 2.4392656925736294

Epoch: 5| Step: 3
Training loss: 0.10613026937780112
Validation loss: 2.4388369439978743

Epoch: 5| Step: 4
Training loss: 0.19833068563559944
Validation loss: 2.4652607368120214

Epoch: 5| Step: 5
Training loss: 0.1164372028571252
Validation loss: 2.425280220241038

Epoch: 5| Step: 6
Training loss: 0.18403979153275576
Validation loss: 2.436665939447211

Epoch: 5| Step: 7
Training loss: 0.1064618430294729
Validation loss: 2.4333484466573365

Epoch: 5| Step: 8
Training loss: 0.08340153442725524
Validation loss: 2.428222550145278

Epoch: 5| Step: 9
Training loss: 0.08423506117003307
Validation loss: 2.4399192579689344

Epoch: 5| Step: 10
Training loss: 0.054259972845149856
Validation loss: 2.455306344765995

Epoch: 681| Step: 0
Training loss: 0.16477017252123902
Validation loss: 2.460873946153632

Epoch: 5| Step: 1
Training loss: 0.11198999432031918
Validation loss: 2.427949302965032

Epoch: 5| Step: 2
Training loss: 0.06354148918788909
Validation loss: 2.4822869757029173

Epoch: 5| Step: 3
Training loss: 0.08428567522490894
Validation loss: 2.480744170644221

Epoch: 5| Step: 4
Training loss: 0.07239163855994402
Validation loss: 2.463112307443164

Epoch: 5| Step: 5
Training loss: 0.0992485223240956
Validation loss: 2.4681360642606442

Epoch: 5| Step: 6
Training loss: 0.13927697080680743
Validation loss: 2.4868391522757896

Epoch: 5| Step: 7
Training loss: 0.1495225674451272
Validation loss: 2.477051087597204

Epoch: 5| Step: 8
Training loss: 0.11423481603836536
Validation loss: 2.478325111986853

Epoch: 5| Step: 9
Training loss: 0.13489925283224383
Validation loss: 2.47814200378054

Epoch: 5| Step: 10
Training loss: 0.16225952066244856
Validation loss: 2.487354887791659

Epoch: 682| Step: 0
Training loss: 0.09887922778868667
Validation loss: 2.47319319666962

Epoch: 5| Step: 1
Training loss: 0.09039305610321831
Validation loss: 2.4880677316387367

Epoch: 5| Step: 2
Training loss: 0.08415522496526665
Validation loss: 2.4700468184612507

Epoch: 5| Step: 3
Training loss: 0.08127098064784924
Validation loss: 2.4484807509781334

Epoch: 5| Step: 4
Training loss: 0.15237639762051255
Validation loss: 2.445699463598579

Epoch: 5| Step: 5
Training loss: 0.10399711837467263
Validation loss: 2.4815675928814596

Epoch: 5| Step: 6
Training loss: 0.09889175869332105
Validation loss: 2.4600743308894097

Epoch: 5| Step: 7
Training loss: 0.17055664761442513
Validation loss: 2.439481988015565

Epoch: 5| Step: 8
Training loss: 0.07224243023801583
Validation loss: 2.456745912048598

Epoch: 5| Step: 9
Training loss: 0.10628319565333291
Validation loss: 2.458012839634236

Epoch: 5| Step: 10
Training loss: 0.145634832561884
Validation loss: 2.4526276871728707

Epoch: 683| Step: 0
Training loss: 0.07344417059815843
Validation loss: 2.450000119978379

Epoch: 5| Step: 1
Training loss: 0.15847774500472683
Validation loss: 2.4373344331500193

Epoch: 5| Step: 2
Training loss: 0.09923031619382755
Validation loss: 2.4375250441424443

Epoch: 5| Step: 3
Training loss: 0.16477810244029162
Validation loss: 2.4209727289324823

Epoch: 5| Step: 4
Training loss: 0.09373962821808182
Validation loss: 2.451660369044928

Epoch: 5| Step: 5
Training loss: 0.0617067655866854
Validation loss: 2.4282382261438746

Epoch: 5| Step: 6
Training loss: 0.15657714927497993
Validation loss: 2.4302461323080777

Epoch: 5| Step: 7
Training loss: 0.12757969073323516
Validation loss: 2.4210966009824544

Epoch: 5| Step: 8
Training loss: 0.11346971110344263
Validation loss: 2.4079368601196585

Epoch: 5| Step: 9
Training loss: 0.1231579355058225
Validation loss: 2.428483416504239

Epoch: 5| Step: 10
Training loss: 0.10584790019803933
Validation loss: 2.426246458296152

Epoch: 684| Step: 0
Training loss: 0.057890691428976515
Validation loss: 2.438403033557883

Epoch: 5| Step: 1
Training loss: 0.10203245445580389
Validation loss: 2.4525244125051495

Epoch: 5| Step: 2
Training loss: 0.0846221571096839
Validation loss: 2.455279935111132

Epoch: 5| Step: 3
Training loss: 0.10992319380776329
Validation loss: 2.4251922076665418

Epoch: 5| Step: 4
Training loss: 0.17443735003524724
Validation loss: 2.4351848759540013

Epoch: 5| Step: 5
Training loss: 0.09870936001119864
Validation loss: 2.445812642955632

Epoch: 5| Step: 6
Training loss: 0.11741908555515121
Validation loss: 2.453525496673464

Epoch: 5| Step: 7
Training loss: 0.1397581536442774
Validation loss: 2.425220455525699

Epoch: 5| Step: 8
Training loss: 0.08507787669840047
Validation loss: 2.4070666551701163

Epoch: 5| Step: 9
Training loss: 0.1418319537906855
Validation loss: 2.4181874093988287

Epoch: 5| Step: 10
Training loss: 0.09900568364666915
Validation loss: 2.408726699680391

Epoch: 685| Step: 0
Training loss: 0.1495268153187728
Validation loss: 2.4020598650590967

Epoch: 5| Step: 1
Training loss: 0.06626428477675408
Validation loss: 2.4174886517734984

Epoch: 5| Step: 2
Training loss: 0.11778004566081945
Validation loss: 2.442398615939304

Epoch: 5| Step: 3
Training loss: 0.13149937655750768
Validation loss: 2.416466984404106

Epoch: 5| Step: 4
Training loss: 0.14792979777059784
Validation loss: 2.4457520859688016

Epoch: 5| Step: 5
Training loss: 0.07303984029320874
Validation loss: 2.41141683491002

Epoch: 5| Step: 6
Training loss: 0.07061684491749359
Validation loss: 2.405787946843378

Epoch: 5| Step: 7
Training loss: 0.08384453975413599
Validation loss: 2.422321312593733

Epoch: 5| Step: 8
Training loss: 0.09317585852457497
Validation loss: 2.4247639542348125

Epoch: 5| Step: 9
Training loss: 0.07800731736142072
Validation loss: 2.4219865437840022

Epoch: 5| Step: 10
Training loss: 0.1517084520107784
Validation loss: 2.414304574654853

Epoch: 686| Step: 0
Training loss: 0.08890531581327524
Validation loss: 2.3709539481135615

Epoch: 5| Step: 1
Training loss: 0.14466667918396198
Validation loss: 2.4125210342370127

Epoch: 5| Step: 2
Training loss: 0.09626609787610449
Validation loss: 2.3853691083078528

Epoch: 5| Step: 3
Training loss: 0.08167159049949918
Validation loss: 2.391148234809063

Epoch: 5| Step: 4
Training loss: 0.08627478561308408
Validation loss: 2.4110886802467646

Epoch: 5| Step: 5
Training loss: 0.09150894134901254
Validation loss: 2.399246807184571

Epoch: 5| Step: 6
Training loss: 0.15918804802030806
Validation loss: 2.4050919668481607

Epoch: 5| Step: 7
Training loss: 0.1049232859456283
Validation loss: 2.3803920179971922

Epoch: 5| Step: 8
Training loss: 0.07991457729638084
Validation loss: 2.3998759279516584

Epoch: 5| Step: 9
Training loss: 0.10332445269764365
Validation loss: 2.4143492915963662

Epoch: 5| Step: 10
Training loss: 0.13145497698914949
Validation loss: 2.415476439789047

Epoch: 687| Step: 0
Training loss: 0.12043746644718908
Validation loss: 2.453895950895177

Epoch: 5| Step: 1
Training loss: 0.20310766806385205
Validation loss: 2.4197084398520783

Epoch: 5| Step: 2
Training loss: 0.06928868765777452
Validation loss: 2.440367418014494

Epoch: 5| Step: 3
Training loss: 0.08630390517929211
Validation loss: 2.4143052637984486

Epoch: 5| Step: 4
Training loss: 0.0682221022102057
Validation loss: 2.4242063069001176

Epoch: 5| Step: 5
Training loss: 0.1664172251757965
Validation loss: 2.4250884818978546

Epoch: 5| Step: 6
Training loss: 0.09124559381213217
Validation loss: 2.4061334653947983

Epoch: 5| Step: 7
Training loss: 0.1106717099026013
Validation loss: 2.4254543765934815

Epoch: 5| Step: 8
Training loss: 0.06616067356930581
Validation loss: 2.3991526832454158

Epoch: 5| Step: 9
Training loss: 0.12453399907647172
Validation loss: 2.3930124812312603

Epoch: 5| Step: 10
Training loss: 0.10372887993186374
Validation loss: 2.4091245301413617

Epoch: 688| Step: 0
Training loss: 0.1352000766323651
Validation loss: 2.4092046323195864

Epoch: 5| Step: 1
Training loss: 0.07986072360799366
Validation loss: 2.4201646325982824

Epoch: 5| Step: 2
Training loss: 0.10704274898907828
Validation loss: 2.4058806774258947

Epoch: 5| Step: 3
Training loss: 0.10165237155097863
Validation loss: 2.422931451574001

Epoch: 5| Step: 4
Training loss: 0.11442155597928279
Validation loss: 2.4388433219844203

Epoch: 5| Step: 5
Training loss: 0.15835910925068927
Validation loss: 2.3973409573691793

Epoch: 5| Step: 6
Training loss: 0.09266253417899678
Validation loss: 2.42116972425364

Epoch: 5| Step: 7
Training loss: 0.13716705255692657
Validation loss: 2.423431401300511

Epoch: 5| Step: 8
Training loss: 0.13475337871250645
Validation loss: 2.455355013444369

Epoch: 5| Step: 9
Training loss: 0.07761074627382347
Validation loss: 2.4238916422337167

Epoch: 5| Step: 10
Training loss: 0.11197155595761488
Validation loss: 2.422823395479179

Epoch: 689| Step: 0
Training loss: 0.12874904352129116
Validation loss: 2.410924939992998

Epoch: 5| Step: 1
Training loss: 0.14063407285880064
Validation loss: 2.41189858711788

Epoch: 5| Step: 2
Training loss: 0.1038530267198852
Validation loss: 2.4384730184680437

Epoch: 5| Step: 3
Training loss: 0.09089073916574475
Validation loss: 2.4166146715855747

Epoch: 5| Step: 4
Training loss: 0.14574080892671049
Validation loss: 2.4261925569753164

Epoch: 5| Step: 5
Training loss: 0.10145433332915427
Validation loss: 2.425190354591253

Epoch: 5| Step: 6
Training loss: 0.07618846162524771
Validation loss: 2.4037028226945902

Epoch: 5| Step: 7
Training loss: 0.07721280177481843
Validation loss: 2.416383599056453

Epoch: 5| Step: 8
Training loss: 0.08579754812677864
Validation loss: 2.423654590105465

Epoch: 5| Step: 9
Training loss: 0.15648835003356343
Validation loss: 2.422937683621513

Epoch: 5| Step: 10
Training loss: 0.08739173281315468
Validation loss: 2.4268148101968476

Epoch: 690| Step: 0
Training loss: 0.06577681156665595
Validation loss: 2.4361074343826825

Epoch: 5| Step: 1
Training loss: 0.08214075295625371
Validation loss: 2.4025284234714275

Epoch: 5| Step: 2
Training loss: 0.057213543283253857
Validation loss: 2.416559393782298

Epoch: 5| Step: 3
Training loss: 0.14808853438949832
Validation loss: 2.399721094558486

Epoch: 5| Step: 4
Training loss: 0.18249603577449627
Validation loss: 2.4121808800094495

Epoch: 5| Step: 5
Training loss: 0.10485551183988376
Validation loss: 2.4117969034379736

Epoch: 5| Step: 6
Training loss: 0.13742977267109743
Validation loss: 2.415832393209006

Epoch: 5| Step: 7
Training loss: 0.08800236698240173
Validation loss: 2.4271820596128872

Epoch: 5| Step: 8
Training loss: 0.09939068742404387
Validation loss: 2.4345572603360544

Epoch: 5| Step: 9
Training loss: 0.08979672777061945
Validation loss: 2.4301305115809124

Epoch: 5| Step: 10
Training loss: 0.1134993451502369
Validation loss: 2.4451441584519493

Epoch: 691| Step: 0
Training loss: 0.10999644791898867
Validation loss: 2.423044222702814

Epoch: 5| Step: 1
Training loss: 0.14098663983221726
Validation loss: 2.4584010994151675

Epoch: 5| Step: 2
Training loss: 0.07957069775165523
Validation loss: 2.416148046984448

Epoch: 5| Step: 3
Training loss: 0.157144157660509
Validation loss: 2.428881784856137

Epoch: 5| Step: 4
Training loss: 0.1422677646708587
Validation loss: 2.436805873425738

Epoch: 5| Step: 5
Training loss: 0.08013595841949152
Validation loss: 2.438683283353019

Epoch: 5| Step: 6
Training loss: 0.09298700045316712
Validation loss: 2.453084570825423

Epoch: 5| Step: 7
Training loss: 0.11818675934525699
Validation loss: 2.4204996841036324

Epoch: 5| Step: 8
Training loss: 0.07853629506786056
Validation loss: 2.4082879315500256

Epoch: 5| Step: 9
Training loss: 0.10593210973220257
Validation loss: 2.392115825752464

Epoch: 5| Step: 10
Training loss: 0.11975490785264443
Validation loss: 2.4036409605558107

Epoch: 692| Step: 0
Training loss: 0.15533432876190537
Validation loss: 2.38957825640578

Epoch: 5| Step: 1
Training loss: 0.10524215905924898
Validation loss: 2.39540130943138

Epoch: 5| Step: 2
Training loss: 0.14201328666533933
Validation loss: 2.410492327849809

Epoch: 5| Step: 3
Training loss: 0.11751012102883474
Validation loss: 2.3895087727639273

Epoch: 5| Step: 4
Training loss: 0.08515540426604239
Validation loss: 2.400616376163214

Epoch: 5| Step: 5
Training loss: 0.06600472780723146
Validation loss: 2.4322907742780195

Epoch: 5| Step: 6
Training loss: 0.09811906341799367
Validation loss: 2.416730869983507

Epoch: 5| Step: 7
Training loss: 0.07895965268029666
Validation loss: 2.418408300580962

Epoch: 5| Step: 8
Training loss: 0.083874469746521
Validation loss: 2.4170361180941664

Epoch: 5| Step: 9
Training loss: 0.1254322951291397
Validation loss: 2.4406403883183057

Epoch: 5| Step: 10
Training loss: 0.09088824920375672
Validation loss: 2.4199824925271347

Epoch: 693| Step: 0
Training loss: 0.11795922329311018
Validation loss: 2.4553874106659737

Epoch: 5| Step: 1
Training loss: 0.13417936044622594
Validation loss: 2.4472166566415052

Epoch: 5| Step: 2
Training loss: 0.10549702088841342
Validation loss: 2.445377889293122

Epoch: 5| Step: 3
Training loss: 0.08131233023021753
Validation loss: 2.458288351543921

Epoch: 5| Step: 4
Training loss: 0.08076498816075448
Validation loss: 2.484549265212483

Epoch: 5| Step: 5
Training loss: 0.10403029236964381
Validation loss: 2.4712530510239494

Epoch: 5| Step: 6
Training loss: 0.11416659422669699
Validation loss: 2.4662466247657573

Epoch: 5| Step: 7
Training loss: 0.0929773098346872
Validation loss: 2.460925235642856

Epoch: 5| Step: 8
Training loss: 0.1399988300197964
Validation loss: 2.4352233652389375

Epoch: 5| Step: 9
Training loss: 0.1278794022368226
Validation loss: 2.446305096931741

Epoch: 5| Step: 10
Training loss: 0.08756209271392065
Validation loss: 2.4645233328264133

Epoch: 694| Step: 0
Training loss: 0.09346779429483754
Validation loss: 2.4440564842947325

Epoch: 5| Step: 1
Training loss: 0.12606747621786615
Validation loss: 2.4562460527051986

Epoch: 5| Step: 2
Training loss: 0.11885021727285919
Validation loss: 2.4696886939794696

Epoch: 5| Step: 3
Training loss: 0.1524225300276704
Validation loss: 2.4401317962634694

Epoch: 5| Step: 4
Training loss: 0.1333036876543272
Validation loss: 2.444361039556952

Epoch: 5| Step: 5
Training loss: 0.08356947212085555
Validation loss: 2.431468533348711

Epoch: 5| Step: 6
Training loss: 0.06152462958134659
Validation loss: 2.4258444244162445

Epoch: 5| Step: 7
Training loss: 0.11229207341215441
Validation loss: 2.4378944595257623

Epoch: 5| Step: 8
Training loss: 0.07501230945999192
Validation loss: 2.414188017361249

Epoch: 5| Step: 9
Training loss: 0.09873122319688823
Validation loss: 2.4165944731144395

Epoch: 5| Step: 10
Training loss: 0.06923732326474337
Validation loss: 2.420464575577633

Epoch: 695| Step: 0
Training loss: 0.11323178789982023
Validation loss: 2.415926961878248

Epoch: 5| Step: 1
Training loss: 0.07325281066148479
Validation loss: 2.416844837366212

Epoch: 5| Step: 2
Training loss: 0.06827962173990897
Validation loss: 2.415386451379184

Epoch: 5| Step: 3
Training loss: 0.08177953087155367
Validation loss: 2.4084594540642867

Epoch: 5| Step: 4
Training loss: 0.1000826289364301
Validation loss: 2.413557027901131

Epoch: 5| Step: 5
Training loss: 0.1355101090294617
Validation loss: 2.433553181756527

Epoch: 5| Step: 6
Training loss: 0.07061785382221168
Validation loss: 2.4223698994583165

Epoch: 5| Step: 7
Training loss: 0.06260358898358603
Validation loss: 2.4051911872244056

Epoch: 5| Step: 8
Training loss: 0.07946754783680385
Validation loss: 2.4396377099945634

Epoch: 5| Step: 9
Training loss: 0.13801109006667855
Validation loss: 2.445322762666027

Epoch: 5| Step: 10
Training loss: 0.08533499030886968
Validation loss: 2.404655180536016

Epoch: 696| Step: 0
Training loss: 0.08239479908352344
Validation loss: 2.4468751351978253

Epoch: 5| Step: 1
Training loss: 0.15344609124824254
Validation loss: 2.445516361378964

Epoch: 5| Step: 2
Training loss: 0.08188041375185022
Validation loss: 2.4264952772723083

Epoch: 5| Step: 3
Training loss: 0.08992474471019664
Validation loss: 2.427956076472088

Epoch: 5| Step: 4
Training loss: 0.06208024969012737
Validation loss: 2.4370005021928653

Epoch: 5| Step: 5
Training loss: 0.17363817573563073
Validation loss: 2.439337091495789

Epoch: 5| Step: 6
Training loss: 0.11622011324777126
Validation loss: 2.422522552963318

Epoch: 5| Step: 7
Training loss: 0.10331380261138289
Validation loss: 2.4227390882111077

Epoch: 5| Step: 8
Training loss: 0.08423313183504857
Validation loss: 2.448598378144549

Epoch: 5| Step: 9
Training loss: 0.05946245943860063
Validation loss: 2.442933792640754

Epoch: 5| Step: 10
Training loss: 0.10595137937036271
Validation loss: 2.4433580010357807

Epoch: 697| Step: 0
Training loss: 0.07813500697896417
Validation loss: 2.4329130979158364

Epoch: 5| Step: 1
Training loss: 0.07564471076611119
Validation loss: 2.439578213465704

Epoch: 5| Step: 2
Training loss: 0.07939115542921756
Validation loss: 2.4312992817576595

Epoch: 5| Step: 3
Training loss: 0.058225907596788404
Validation loss: 2.41786195334706

Epoch: 5| Step: 4
Training loss: 0.13730649634915695
Validation loss: 2.4092680828511095

Epoch: 5| Step: 5
Training loss: 0.07889869070668776
Validation loss: 2.429718930063877

Epoch: 5| Step: 6
Training loss: 0.16006656205624742
Validation loss: 2.4417223569927975

Epoch: 5| Step: 7
Training loss: 0.058651111261462406
Validation loss: 2.4645184489997725

Epoch: 5| Step: 8
Training loss: 0.14315586092616456
Validation loss: 2.4324750701787297

Epoch: 5| Step: 9
Training loss: 0.10411559183943604
Validation loss: 2.4432528026059224

Epoch: 5| Step: 10
Training loss: 0.09469437298050185
Validation loss: 2.424870919489216

Epoch: 698| Step: 0
Training loss: 0.07722837797162152
Validation loss: 2.390329959235748

Epoch: 5| Step: 1
Training loss: 0.07134209254303273
Validation loss: 2.4617709242031007

Epoch: 5| Step: 2
Training loss: 0.07945846174916027
Validation loss: 2.435034133820296

Epoch: 5| Step: 3
Training loss: 0.10205048921534171
Validation loss: 2.422279277062887

Epoch: 5| Step: 4
Training loss: 0.09856223895806993
Validation loss: 2.4268136597978547

Epoch: 5| Step: 5
Training loss: 0.12986887233182573
Validation loss: 2.428280339052509

Epoch: 5| Step: 6
Training loss: 0.0692003697819904
Validation loss: 2.4171132927471977

Epoch: 5| Step: 7
Training loss: 0.0993751267891201
Validation loss: 2.429859016705147

Epoch: 5| Step: 8
Training loss: 0.08365946118868073
Validation loss: 2.402425836320712

Epoch: 5| Step: 9
Training loss: 0.10781074709089218
Validation loss: 2.4227340868223783

Epoch: 5| Step: 10
Training loss: 0.17259313370461488
Validation loss: 2.4241305795316994

Epoch: 699| Step: 0
Training loss: 0.07778205703111306
Validation loss: 2.425538212156701

Epoch: 5| Step: 1
Training loss: 0.0693788227916074
Validation loss: 2.4378705801340863

Epoch: 5| Step: 2
Training loss: 0.08923759398401336
Validation loss: 2.42737576967784

Epoch: 5| Step: 3
Training loss: 0.13341344885750048
Validation loss: 2.416294149458021

Epoch: 5| Step: 4
Training loss: 0.12615899619637383
Validation loss: 2.43248596771479

Epoch: 5| Step: 5
Training loss: 0.07419344194481797
Validation loss: 2.42464000230593

Epoch: 5| Step: 6
Training loss: 0.0856370659492149
Validation loss: 2.408668997226286

Epoch: 5| Step: 7
Training loss: 0.10205731986969271
Validation loss: 2.4392788635282345

Epoch: 5| Step: 8
Training loss: 0.11501234696412993
Validation loss: 2.4433243525735273

Epoch: 5| Step: 9
Training loss: 0.07588803458569034
Validation loss: 2.442854204568538

Epoch: 5| Step: 10
Training loss: 0.16531278832848542
Validation loss: 2.4593706092608167

Epoch: 700| Step: 0
Training loss: 0.07916865917519672
Validation loss: 2.4715734717083495

Epoch: 5| Step: 1
Training loss: 0.08088791016622204
Validation loss: 2.461013504732362

Epoch: 5| Step: 2
Training loss: 0.09761179866013679
Validation loss: 2.4649646649353953

Epoch: 5| Step: 3
Training loss: 0.0977514184717154
Validation loss: 2.419772811610727

Epoch: 5| Step: 4
Training loss: 0.09447007012272983
Validation loss: 2.4210573296071813

Epoch: 5| Step: 5
Training loss: 0.13643170605343455
Validation loss: 2.4403449405838127

Epoch: 5| Step: 6
Training loss: 0.15904088199431238
Validation loss: 2.4575402951824166

Epoch: 5| Step: 7
Training loss: 0.07098368991552281
Validation loss: 2.418569709973577

Epoch: 5| Step: 8
Training loss: 0.1014308718368539
Validation loss: 2.446736961092712

Epoch: 5| Step: 9
Training loss: 0.12224357134911637
Validation loss: 2.4265860311659333

Epoch: 5| Step: 10
Training loss: 0.07197327374176601
Validation loss: 2.4407005180624943

Epoch: 701| Step: 0
Training loss: 0.10438756071965294
Validation loss: 2.4546873448460484

Epoch: 5| Step: 1
Training loss: 0.08573513968748742
Validation loss: 2.4321666686376564

Epoch: 5| Step: 2
Training loss: 0.0698265528788939
Validation loss: 2.4356824999922706

Epoch: 5| Step: 3
Training loss: 0.0815623454525459
Validation loss: 2.4253741034241187

Epoch: 5| Step: 4
Training loss: 0.07973326299304202
Validation loss: 2.439009034466182

Epoch: 5| Step: 5
Training loss: 0.08482580839139262
Validation loss: 2.4116591070950633

Epoch: 5| Step: 6
Training loss: 0.11023521197276373
Validation loss: 2.4172998906379775

Epoch: 5| Step: 7
Training loss: 0.10420729669293378
Validation loss: 2.4307358765013416

Epoch: 5| Step: 8
Training loss: 0.14294228360912262
Validation loss: 2.434023355799644

Epoch: 5| Step: 9
Training loss: 0.13541818275581102
Validation loss: 2.4264338092203857

Epoch: 5| Step: 10
Training loss: 0.159130457420813
Validation loss: 2.4235558685752525

Epoch: 702| Step: 0
Training loss: 0.0861044827407254
Validation loss: 2.45925357343357

Epoch: 5| Step: 1
Training loss: 0.07112827851134058
Validation loss: 2.4197491618087836

Epoch: 5| Step: 2
Training loss: 0.0881061401798251
Validation loss: 2.4593400240991787

Epoch: 5| Step: 3
Training loss: 0.1336486107019056
Validation loss: 2.4478217684945385

Epoch: 5| Step: 4
Training loss: 0.1128688284677505
Validation loss: 2.4427429787284707

Epoch: 5| Step: 5
Training loss: 0.10548916371906415
Validation loss: 2.4605040403371015

Epoch: 5| Step: 6
Training loss: 0.0768002790567828
Validation loss: 2.466556071113811

Epoch: 5| Step: 7
Training loss: 0.15684321565949358
Validation loss: 2.4599844378000726

Epoch: 5| Step: 8
Training loss: 0.06471237869803967
Validation loss: 2.466139817893491

Epoch: 5| Step: 9
Training loss: 0.16273551114583548
Validation loss: 2.469962199792354

Epoch: 5| Step: 10
Training loss: 0.06492848016692516
Validation loss: 2.436701448953552

Epoch: 703| Step: 0
Training loss: 0.07957271087282963
Validation loss: 2.4457356941411774

Epoch: 5| Step: 1
Training loss: 0.16301914377728402
Validation loss: 2.43938380192427

Epoch: 5| Step: 2
Training loss: 0.0994732525034467
Validation loss: 2.4524035359882346

Epoch: 5| Step: 3
Training loss: 0.0713930025479184
Validation loss: 2.4479003237194243

Epoch: 5| Step: 4
Training loss: 0.11567169387155997
Validation loss: 2.422314783682679

Epoch: 5| Step: 5
Training loss: 0.10602673202527631
Validation loss: 2.4116429725312627

Epoch: 5| Step: 6
Training loss: 0.08498360342470491
Validation loss: 2.4477896345625316

Epoch: 5| Step: 7
Training loss: 0.14476471165195479
Validation loss: 2.438743173319075

Epoch: 5| Step: 8
Training loss: 0.10391726489230749
Validation loss: 2.417519863976984

Epoch: 5| Step: 9
Training loss: 0.08645064055687161
Validation loss: 2.4174743928384594

Epoch: 5| Step: 10
Training loss: 0.15241945048739966
Validation loss: 2.438838349416367

Epoch: 704| Step: 0
Training loss: 0.12290440743406354
Validation loss: 2.4224458099194583

Epoch: 5| Step: 1
Training loss: 0.06000645242705966
Validation loss: 2.4258329496177886

Epoch: 5| Step: 2
Training loss: 0.07838217011991412
Validation loss: 2.4035143302922166

Epoch: 5| Step: 3
Training loss: 0.11642618040705313
Validation loss: 2.4294352618618063

Epoch: 5| Step: 4
Training loss: 0.11606573602451234
Validation loss: 2.423682355042709

Epoch: 5| Step: 5
Training loss: 0.09975932092397786
Validation loss: 2.4082131849293944

Epoch: 5| Step: 6
Training loss: 0.13706642630224514
Validation loss: 2.416157931654941

Epoch: 5| Step: 7
Training loss: 0.16239123372367875
Validation loss: 2.431553039805236

Epoch: 5| Step: 8
Training loss: 0.09176281033185316
Validation loss: 2.43770192343012

Epoch: 5| Step: 9
Training loss: 0.13812302384106423
Validation loss: 2.4333303314206765

Epoch: 5| Step: 10
Training loss: 0.14172451337726413
Validation loss: 2.4443230911336897

Epoch: 705| Step: 0
Training loss: 0.08675674602706689
Validation loss: 2.4478934446414606

Epoch: 5| Step: 1
Training loss: 0.11326528716250742
Validation loss: 2.425507656977826

Epoch: 5| Step: 2
Training loss: 0.06591183669213907
Validation loss: 2.43536179467559

Epoch: 5| Step: 3
Training loss: 0.10479052459673992
Validation loss: 2.418755399786931

Epoch: 5| Step: 4
Training loss: 0.06747406157619794
Validation loss: 2.41572472794252

Epoch: 5| Step: 5
Training loss: 0.15588822205408182
Validation loss: 2.4087359586589407

Epoch: 5| Step: 6
Training loss: 0.0818542717127289
Validation loss: 2.4151671116799767

Epoch: 5| Step: 7
Training loss: 0.18530978062517647
Validation loss: 2.4077628496139547

Epoch: 5| Step: 8
Training loss: 0.10082532580539635
Validation loss: 2.4317368813638116

Epoch: 5| Step: 9
Training loss: 0.10444018594094752
Validation loss: 2.4462126055138222

Epoch: 5| Step: 10
Training loss: 0.19154279081628656
Validation loss: 2.4485411221681637

Epoch: 706| Step: 0
Training loss: 0.13277557504879917
Validation loss: 2.4367144685904556

Epoch: 5| Step: 1
Training loss: 0.1668817701645137
Validation loss: 2.4590696007806456

Epoch: 5| Step: 2
Training loss: 0.11630092871044836
Validation loss: 2.430183611379865

Epoch: 5| Step: 3
Training loss: 0.08359868456189037
Validation loss: 2.449117994021166

Epoch: 5| Step: 4
Training loss: 0.15189366611520305
Validation loss: 2.4483957639124116

Epoch: 5| Step: 5
Training loss: 0.13990174508143105
Validation loss: 2.4370459698248146

Epoch: 5| Step: 6
Training loss: 0.10697835917138679
Validation loss: 2.4673758660084824

Epoch: 5| Step: 7
Training loss: 0.11663141635205053
Validation loss: 2.4056664179887637

Epoch: 5| Step: 8
Training loss: 0.10047370704862814
Validation loss: 2.4555336444149196

Epoch: 5| Step: 9
Training loss: 0.10337473620377616
Validation loss: 2.4226282256403007

Epoch: 5| Step: 10
Training loss: 0.0784463383389382
Validation loss: 2.4210308634911217

Epoch: 707| Step: 0
Training loss: 0.1253508917819416
Validation loss: 2.4066370746078447

Epoch: 5| Step: 1
Training loss: 0.15291774040511294
Validation loss: 2.4270833991737857

Epoch: 5| Step: 2
Training loss: 0.11689664190262336
Validation loss: 2.438191558993231

Epoch: 5| Step: 3
Training loss: 0.1474502698563887
Validation loss: 2.4247009155492196

Epoch: 5| Step: 4
Training loss: 0.10009547440546784
Validation loss: 2.4144457276508557

Epoch: 5| Step: 5
Training loss: 0.049954234259617855
Validation loss: 2.4548100132496757

Epoch: 5| Step: 6
Training loss: 0.09600549731372075
Validation loss: 2.440632301300633

Epoch: 5| Step: 7
Training loss: 0.10911536906861549
Validation loss: 2.3990573400774635

Epoch: 5| Step: 8
Training loss: 0.09556981942704403
Validation loss: 2.4424407722890464

Epoch: 5| Step: 9
Training loss: 0.08796287586882785
Validation loss: 2.4202924572083586

Epoch: 5| Step: 10
Training loss: 0.1332133289243536
Validation loss: 2.433889437408413

Epoch: 708| Step: 0
Training loss: 0.13034218742716228
Validation loss: 2.4349011201632775

Epoch: 5| Step: 1
Training loss: 0.0765367383092973
Validation loss: 2.434490614232676

Epoch: 5| Step: 2
Training loss: 0.11773842612234499
Validation loss: 2.4052656877527987

Epoch: 5| Step: 3
Training loss: 0.10491287805694118
Validation loss: 2.417539987378975

Epoch: 5| Step: 4
Training loss: 0.14470154163741178
Validation loss: 2.4488654667147665

Epoch: 5| Step: 5
Training loss: 0.12707580361051196
Validation loss: 2.433970310277327

Epoch: 5| Step: 6
Training loss: 0.13148065661489441
Validation loss: 2.41649975764288

Epoch: 5| Step: 7
Training loss: 0.14149193301727458
Validation loss: 2.4107780814444593

Epoch: 5| Step: 8
Training loss: 0.11812070571319465
Validation loss: 2.414573093216947

Epoch: 5| Step: 9
Training loss: 0.06954373531543669
Validation loss: 2.4521195102988362

Epoch: 5| Step: 10
Training loss: 0.07713633756272455
Validation loss: 2.460752768223275

Epoch: 709| Step: 0
Training loss: 0.14116544320422852
Validation loss: 2.439615667718089

Epoch: 5| Step: 1
Training loss: 0.07636189600961207
Validation loss: 2.4422199752790164

Epoch: 5| Step: 2
Training loss: 0.1603064414323973
Validation loss: 2.4554964522778806

Epoch: 5| Step: 3
Training loss: 0.08714893569615804
Validation loss: 2.4324426723799157

Epoch: 5| Step: 4
Training loss: 0.08029165525296923
Validation loss: 2.452949258980656

Epoch: 5| Step: 5
Training loss: 0.13157549670441143
Validation loss: 2.4466613678786655

Epoch: 5| Step: 6
Training loss: 0.1276334141928806
Validation loss: 2.47708867176487

Epoch: 5| Step: 7
Training loss: 0.09457907550617108
Validation loss: 2.4716350426453233

Epoch: 5| Step: 8
Training loss: 0.0882241754525623
Validation loss: 2.4781292685219922

Epoch: 5| Step: 9
Training loss: 0.09195856301911752
Validation loss: 2.4800767514690456

Epoch: 5| Step: 10
Training loss: 0.08268089994125317
Validation loss: 2.455518602044192

Epoch: 710| Step: 0
Training loss: 0.0820939698454139
Validation loss: 2.462898027921028

Epoch: 5| Step: 1
Training loss: 0.16021880812148187
Validation loss: 2.4496150785277373

Epoch: 5| Step: 2
Training loss: 0.07136560602737838
Validation loss: 2.459318872466903

Epoch: 5| Step: 3
Training loss: 0.1062235709937159
Validation loss: 2.498494158248745

Epoch: 5| Step: 4
Training loss: 0.11703311764610895
Validation loss: 2.4778947322319818

Epoch: 5| Step: 5
Training loss: 0.09227450879551988
Validation loss: 2.4798875616987477

Epoch: 5| Step: 6
Training loss: 0.08766437656042746
Validation loss: 2.4775296131188447

Epoch: 5| Step: 7
Training loss: 0.16101578595386143
Validation loss: 2.4610954008736248

Epoch: 5| Step: 8
Training loss: 0.07766000230596537
Validation loss: 2.4410023113835875

Epoch: 5| Step: 9
Training loss: 0.13579275026554302
Validation loss: 2.4395073197199904

Epoch: 5| Step: 10
Training loss: 0.11286031685765839
Validation loss: 2.4303338405509085

Epoch: 711| Step: 0
Training loss: 0.07881146677445625
Validation loss: 2.4520471024572954

Epoch: 5| Step: 1
Training loss: 0.16639110514177222
Validation loss: 2.4257318373669703

Epoch: 5| Step: 2
Training loss: 0.10678971858209928
Validation loss: 2.4035564828137224

Epoch: 5| Step: 3
Training loss: 0.10915022129968235
Validation loss: 2.405218323262116

Epoch: 5| Step: 4
Training loss: 0.08662542355971939
Validation loss: 2.397867523904591

Epoch: 5| Step: 5
Training loss: 0.0804871140052674
Validation loss: 2.4193940739201865

Epoch: 5| Step: 6
Training loss: 0.16407293331940612
Validation loss: 2.4103309396653745

Epoch: 5| Step: 7
Training loss: 0.07683175010596743
Validation loss: 2.3987833388138236

Epoch: 5| Step: 8
Training loss: 0.06575239721590453
Validation loss: 2.436421395766577

Epoch: 5| Step: 9
Training loss: 0.058557107514677104
Validation loss: 2.4289749135116407

Epoch: 5| Step: 10
Training loss: 0.07160095677637263
Validation loss: 2.4282287601670633

Epoch: 712| Step: 0
Training loss: 0.1049763390371981
Validation loss: 2.4086654678751858

Epoch: 5| Step: 1
Training loss: 0.13557021135299938
Validation loss: 2.4136404227416834

Epoch: 5| Step: 2
Training loss: 0.11758330577703126
Validation loss: 2.4388589628286574

Epoch: 5| Step: 3
Training loss: 0.1475851533669128
Validation loss: 2.4160494500636482

Epoch: 5| Step: 4
Training loss: 0.1315060337834484
Validation loss: 2.4184157506209862

Epoch: 5| Step: 5
Training loss: 0.06640505088396696
Validation loss: 2.4524124476523994

Epoch: 5| Step: 6
Training loss: 0.10825841899001877
Validation loss: 2.4312022267029296

Epoch: 5| Step: 7
Training loss: 0.09444480955627557
Validation loss: 2.411219843382722

Epoch: 5| Step: 8
Training loss: 0.07863792483353421
Validation loss: 2.413442357149085

Epoch: 5| Step: 9
Training loss: 0.09331094730756385
Validation loss: 2.4307915364300214

Epoch: 5| Step: 10
Training loss: 0.10417397344314364
Validation loss: 2.4518262969341125

Epoch: 713| Step: 0
Training loss: 0.08018570163699328
Validation loss: 2.420773673678372

Epoch: 5| Step: 1
Training loss: 0.1038596446701091
Validation loss: 2.3917922625264816

Epoch: 5| Step: 2
Training loss: 0.1172425339536644
Validation loss: 2.412096787977381

Epoch: 5| Step: 3
Training loss: 0.1567668294606552
Validation loss: 2.4215119649817156

Epoch: 5| Step: 4
Training loss: 0.17344265427534208
Validation loss: 2.373596211547794

Epoch: 5| Step: 5
Training loss: 0.07349008886403119
Validation loss: 2.400045229287364

Epoch: 5| Step: 6
Training loss: 0.07103127089503057
Validation loss: 2.412469990330204

Epoch: 5| Step: 7
Training loss: 0.11661484992454126
Validation loss: 2.4119772350898323

Epoch: 5| Step: 8
Training loss: 0.07138202432625461
Validation loss: 2.403415532423038

Epoch: 5| Step: 9
Training loss: 0.08574468483036057
Validation loss: 2.408973892460398

Epoch: 5| Step: 10
Training loss: 0.14149302565165428
Validation loss: 2.4020270228763985

Epoch: 714| Step: 0
Training loss: 0.1582372063554576
Validation loss: 2.41956323331158

Epoch: 5| Step: 1
Training loss: 0.08537373342122571
Validation loss: 2.4285819841772316

Epoch: 5| Step: 2
Training loss: 0.08772626980362348
Validation loss: 2.4431655088288466

Epoch: 5| Step: 3
Training loss: 0.0877248100593562
Validation loss: 2.411501835142955

Epoch: 5| Step: 4
Training loss: 0.09435008635949092
Validation loss: 2.41389439418946

Epoch: 5| Step: 5
Training loss: 0.05974690262495418
Validation loss: 2.3960957565793253

Epoch: 5| Step: 6
Training loss: 0.1270296746328719
Validation loss: 2.413338366444711

Epoch: 5| Step: 7
Training loss: 0.08221159705934525
Validation loss: 2.40479052864367

Epoch: 5| Step: 8
Training loss: 0.09798286654935873
Validation loss: 2.3875976553265903

Epoch: 5| Step: 9
Training loss: 0.059463361975370596
Validation loss: 2.3948104436810422

Epoch: 5| Step: 10
Training loss: 0.18023417077220363
Validation loss: 2.4108726314469537

Epoch: 715| Step: 0
Training loss: 0.08363360519960009
Validation loss: 2.4304271625021507

Epoch: 5| Step: 1
Training loss: 0.16427823482929838
Validation loss: 2.407708059616337

Epoch: 5| Step: 2
Training loss: 0.12689247149638974
Validation loss: 2.4221486847645908

Epoch: 5| Step: 3
Training loss: 0.060482673677632375
Validation loss: 2.435261153332537

Epoch: 5| Step: 4
Training loss: 0.10732442597220827
Validation loss: 2.4457887150906474

Epoch: 5| Step: 5
Training loss: 0.0857105645408162
Validation loss: 2.4259382382104557

Epoch: 5| Step: 6
Training loss: 0.09296244391523903
Validation loss: 2.427160578095353

Epoch: 5| Step: 7
Training loss: 0.07109853681232077
Validation loss: 2.4424842881980076

Epoch: 5| Step: 8
Training loss: 0.0840073432121696
Validation loss: 2.425836437082998

Epoch: 5| Step: 9
Training loss: 0.15614866308439426
Validation loss: 2.4432960092117106

Epoch: 5| Step: 10
Training loss: 0.06441368355648247
Validation loss: 2.4718878023901842

Epoch: 716| Step: 0
Training loss: 0.0870434141390329
Validation loss: 2.452851802196185

Epoch: 5| Step: 1
Training loss: 0.1027731086322622
Validation loss: 2.4702344999999717

Epoch: 5| Step: 2
Training loss: 0.06745588100326771
Validation loss: 2.425973039528735

Epoch: 5| Step: 3
Training loss: 0.11081276365352061
Validation loss: 2.421924014989788

Epoch: 5| Step: 4
Training loss: 0.16551403678586518
Validation loss: 2.456653622490096

Epoch: 5| Step: 5
Training loss: 0.11058026220728552
Validation loss: 2.4393794426303983

Epoch: 5| Step: 6
Training loss: 0.0891155085170988
Validation loss: 2.447583002526971

Epoch: 5| Step: 7
Training loss: 0.09296900564847786
Validation loss: 2.4346421018363826

Epoch: 5| Step: 8
Training loss: 0.08968076227047377
Validation loss: 2.4631592778694738

Epoch: 5| Step: 9
Training loss: 0.0609489232293096
Validation loss: 2.448341847613816

Epoch: 5| Step: 10
Training loss: 0.09420424424824353
Validation loss: 2.451348986908983

Epoch: 717| Step: 0
Training loss: 0.13810142527355107
Validation loss: 2.449668533541469

Epoch: 5| Step: 1
Training loss: 0.07120863414309875
Validation loss: 2.4582670876191246

Epoch: 5| Step: 2
Training loss: 0.08845404070926186
Validation loss: 2.426721701117394

Epoch: 5| Step: 3
Training loss: 0.12200088815629623
Validation loss: 2.451831045542399

Epoch: 5| Step: 4
Training loss: 0.08228806191508524
Validation loss: 2.4531766824507883

Epoch: 5| Step: 5
Training loss: 0.0511691291086917
Validation loss: 2.4711177899649424

Epoch: 5| Step: 6
Training loss: 0.04994161566629614
Validation loss: 2.466365910724787

Epoch: 5| Step: 7
Training loss: 0.07940713704952476
Validation loss: 2.436177443146474

Epoch: 5| Step: 8
Training loss: 0.09004490041115064
Validation loss: 2.4722840142148588

Epoch: 5| Step: 9
Training loss: 0.15206477713927957
Validation loss: 2.416355350274023

Epoch: 5| Step: 10
Training loss: 0.08137950102180821
Validation loss: 2.4270163603454655

Epoch: 718| Step: 0
Training loss: 0.051013073506890314
Validation loss: 2.4494861764845846

Epoch: 5| Step: 1
Training loss: 0.09422065886339907
Validation loss: 2.4595770963183616

Epoch: 5| Step: 2
Training loss: 0.07576166863475459
Validation loss: 2.421007869269278

Epoch: 5| Step: 3
Training loss: 0.1119950129881357
Validation loss: 2.4179262677076396

Epoch: 5| Step: 4
Training loss: 0.05642165823556508
Validation loss: 2.4074091490565794

Epoch: 5| Step: 5
Training loss: 0.09156350644635854
Validation loss: 2.423424825660779

Epoch: 5| Step: 6
Training loss: 0.127649203611438
Validation loss: 2.4433508195813607

Epoch: 5| Step: 7
Training loss: 0.14246639027893185
Validation loss: 2.399453779456783

Epoch: 5| Step: 8
Training loss: 0.056166240796881
Validation loss: 2.4306712690448515

Epoch: 5| Step: 9
Training loss: 0.11705702830091587
Validation loss: 2.4389299416419283

Epoch: 5| Step: 10
Training loss: 0.07014221857677862
Validation loss: 2.4387079574003554

Epoch: 719| Step: 0
Training loss: 0.0636307787057932
Validation loss: 2.450903370451119

Epoch: 5| Step: 1
Training loss: 0.0954287790964919
Validation loss: 2.4264549580235264

Epoch: 5| Step: 2
Training loss: 0.09763029707325202
Validation loss: 2.453957960668207

Epoch: 5| Step: 3
Training loss: 0.145819324149771
Validation loss: 2.4438486879591683

Epoch: 5| Step: 4
Training loss: 0.13207696145940875
Validation loss: 2.448429944212015

Epoch: 5| Step: 5
Training loss: 0.07358550036614699
Validation loss: 2.468054726868271

Epoch: 5| Step: 6
Training loss: 0.11881615276831978
Validation loss: 2.453025597964055

Epoch: 5| Step: 7
Training loss: 0.07230968356582476
Validation loss: 2.4506380187567323

Epoch: 5| Step: 8
Training loss: 0.07509610828049372
Validation loss: 2.4690895329955618

Epoch: 5| Step: 9
Training loss: 0.05888463968747291
Validation loss: 2.4278389021669238

Epoch: 5| Step: 10
Training loss: 0.08751542485467424
Validation loss: 2.424696965466488

Epoch: 720| Step: 0
Training loss: 0.08440717739233417
Validation loss: 2.418302889807468

Epoch: 5| Step: 1
Training loss: 0.07008474603630345
Validation loss: 2.433234193405871

Epoch: 5| Step: 2
Training loss: 0.12638185053424672
Validation loss: 2.415156787747528

Epoch: 5| Step: 3
Training loss: 0.0882967651498476
Validation loss: 2.452439778296149

Epoch: 5| Step: 4
Training loss: 0.06261258862194614
Validation loss: 2.424724272290724

Epoch: 5| Step: 5
Training loss: 0.09192104261216937
Validation loss: 2.4452197513907272

Epoch: 5| Step: 6
Training loss: 0.13586440861805843
Validation loss: 2.41018343331254

Epoch: 5| Step: 7
Training loss: 0.0682211636746673
Validation loss: 2.454356508123534

Epoch: 5| Step: 8
Training loss: 0.08175009274112913
Validation loss: 2.448548945918343

Epoch: 5| Step: 9
Training loss: 0.12674869069574363
Validation loss: 2.444770289224413

Epoch: 5| Step: 10
Training loss: 0.07257695729391127
Validation loss: 2.4421188770097153

Epoch: 721| Step: 0
Training loss: 0.08955945250649806
Validation loss: 2.4407308562598864

Epoch: 5| Step: 1
Training loss: 0.10096446818927851
Validation loss: 2.4481076981347427

Epoch: 5| Step: 2
Training loss: 0.07326111231130597
Validation loss: 2.438992043912721

Epoch: 5| Step: 3
Training loss: 0.04744266464367352
Validation loss: 2.4447594716128678

Epoch: 5| Step: 4
Training loss: 0.11479914230318486
Validation loss: 2.4269106780324545

Epoch: 5| Step: 5
Training loss: 0.05954972286541228
Validation loss: 2.467724853233716

Epoch: 5| Step: 6
Training loss: 0.07779101567806039
Validation loss: 2.4545327212676096

Epoch: 5| Step: 7
Training loss: 0.1338641032811749
Validation loss: 2.4582652584332845

Epoch: 5| Step: 8
Training loss: 0.08674786514955446
Validation loss: 2.455408550225573

Epoch: 5| Step: 9
Training loss: 0.0693169151324018
Validation loss: 2.4240170556956855

Epoch: 5| Step: 10
Training loss: 0.14022435628014168
Validation loss: 2.4308421510547333

Epoch: 722| Step: 0
Training loss: 0.051782462709887504
Validation loss: 2.4208089333948264

Epoch: 5| Step: 1
Training loss: 0.10630298863943928
Validation loss: 2.4443794154752436

Epoch: 5| Step: 2
Training loss: 0.07661444218216494
Validation loss: 2.4145702923541617

Epoch: 5| Step: 3
Training loss: 0.07155821561481782
Validation loss: 2.4419113199842255

Epoch: 5| Step: 4
Training loss: 0.08078356577673153
Validation loss: 2.4234829690997945

Epoch: 5| Step: 5
Training loss: 0.0701326580300871
Validation loss: 2.4418500027242604

Epoch: 5| Step: 6
Training loss: 0.10211954127504248
Validation loss: 2.4186337187965075

Epoch: 5| Step: 7
Training loss: 0.12049360918028604
Validation loss: 2.473869970499848

Epoch: 5| Step: 8
Training loss: 0.12610996191752902
Validation loss: 2.449937578385095

Epoch: 5| Step: 9
Training loss: 0.05324163885806465
Validation loss: 2.42924700636352

Epoch: 5| Step: 10
Training loss: 0.06832560658867824
Validation loss: 2.441891173279332

Epoch: 723| Step: 0
Training loss: 0.13562918151175365
Validation loss: 2.4204098845713102

Epoch: 5| Step: 1
Training loss: 0.06604093103282399
Validation loss: 2.4423902707578247

Epoch: 5| Step: 2
Training loss: 0.06518179993450961
Validation loss: 2.466729660014158

Epoch: 5| Step: 3
Training loss: 0.13304104494860944
Validation loss: 2.458308463981508

Epoch: 5| Step: 4
Training loss: 0.07299802454817313
Validation loss: 2.4630723929613856

Epoch: 5| Step: 5
Training loss: 0.06667220628467016
Validation loss: 2.442277667062141

Epoch: 5| Step: 6
Training loss: 0.07760352198708488
Validation loss: 2.4724934914842516

Epoch: 5| Step: 7
Training loss: 0.07876610857495966
Validation loss: 2.4674583816447093

Epoch: 5| Step: 8
Training loss: 0.07130705593292976
Validation loss: 2.465483959272149

Epoch: 5| Step: 9
Training loss: 0.05299745607863937
Validation loss: 2.4406748915055685

Epoch: 5| Step: 10
Training loss: 0.1086027779702895
Validation loss: 2.464392817424581

Epoch: 724| Step: 0
Training loss: 0.08296988125477073
Validation loss: 2.434096137603408

Epoch: 5| Step: 1
Training loss: 0.10995399121150227
Validation loss: 2.4528058488925355

Epoch: 5| Step: 2
Training loss: 0.07683117129811279
Validation loss: 2.4670929036488403

Epoch: 5| Step: 3
Training loss: 0.08506328896090772
Validation loss: 2.4650135771265522

Epoch: 5| Step: 4
Training loss: 0.07206680036014503
Validation loss: 2.4470884930776275

Epoch: 5| Step: 5
Training loss: 0.12083075405182446
Validation loss: 2.4594931952244217

Epoch: 5| Step: 6
Training loss: 0.09002380883185711
Validation loss: 2.4518340077324514

Epoch: 5| Step: 7
Training loss: 0.1403397541403149
Validation loss: 2.4616870661176824

Epoch: 5| Step: 8
Training loss: 0.12319702115779944
Validation loss: 2.4589829800532983

Epoch: 5| Step: 9
Training loss: 0.06356671606933166
Validation loss: 2.460953563996503

Epoch: 5| Step: 10
Training loss: 0.07365743228022568
Validation loss: 2.4569007018097127

Epoch: 725| Step: 0
Training loss: 0.06265065914405353
Validation loss: 2.4470097019964845

Epoch: 5| Step: 1
Training loss: 0.07485089443666341
Validation loss: 2.4301000236384867

Epoch: 5| Step: 2
Training loss: 0.05842579970869918
Validation loss: 2.4468069056559667

Epoch: 5| Step: 3
Training loss: 0.13658525216281356
Validation loss: 2.442611771840107

Epoch: 5| Step: 4
Training loss: 0.10659154419250874
Validation loss: 2.3967326769285076

Epoch: 5| Step: 5
Training loss: 0.08502040897199371
Validation loss: 2.4401616041484235

Epoch: 5| Step: 6
Training loss: 0.08792579000385616
Validation loss: 2.4296154281509317

Epoch: 5| Step: 7
Training loss: 0.08782526340922905
Validation loss: 2.4113291859963115

Epoch: 5| Step: 8
Training loss: 0.06434900731831417
Validation loss: 2.443703653805467

Epoch: 5| Step: 9
Training loss: 0.12372629358823997
Validation loss: 2.4202415544302425

Epoch: 5| Step: 10
Training loss: 0.0565576912188595
Validation loss: 2.402288745697634

Epoch: 726| Step: 0
Training loss: 0.06759794418683653
Validation loss: 2.423123237873106

Epoch: 5| Step: 1
Training loss: 0.07998870881686324
Validation loss: 2.4254010189349375

Epoch: 5| Step: 2
Training loss: 0.09361525130193664
Validation loss: 2.4068883244444064

Epoch: 5| Step: 3
Training loss: 0.05710170783096047
Validation loss: 2.413714277729245

Epoch: 5| Step: 4
Training loss: 0.12003800255443725
Validation loss: 2.4457863000697158

Epoch: 5| Step: 5
Training loss: 0.07300888414856763
Validation loss: 2.42841102705139

Epoch: 5| Step: 6
Training loss: 0.07741255758017898
Validation loss: 2.42380467606514

Epoch: 5| Step: 7
Training loss: 0.06141694631552231
Validation loss: 2.4118144820543344

Epoch: 5| Step: 8
Training loss: 0.09312730359902176
Validation loss: 2.431622553972093

Epoch: 5| Step: 9
Training loss: 0.08590710167342966
Validation loss: 2.4208294705265563

Epoch: 5| Step: 10
Training loss: 0.13712462397491657
Validation loss: 2.4202460032757527

Epoch: 727| Step: 0
Training loss: 0.09131431561661763
Validation loss: 2.409513978974613

Epoch: 5| Step: 1
Training loss: 0.12821233988252892
Validation loss: 2.4288947957460327

Epoch: 5| Step: 2
Training loss: 0.06557154933858754
Validation loss: 2.4051530295512853

Epoch: 5| Step: 3
Training loss: 0.05876881553351008
Validation loss: 2.4206739079788147

Epoch: 5| Step: 4
Training loss: 0.07804807810004058
Validation loss: 2.4470346045487212

Epoch: 5| Step: 5
Training loss: 0.09785135330056006
Validation loss: 2.4338540469807994

Epoch: 5| Step: 6
Training loss: 0.0841340876362304
Validation loss: 2.4453866163649103

Epoch: 5| Step: 7
Training loss: 0.09975298645393758
Validation loss: 2.4315429288331916

Epoch: 5| Step: 8
Training loss: 0.05187095789715977
Validation loss: 2.433278744214905

Epoch: 5| Step: 9
Training loss: 0.1190132883325051
Validation loss: 2.443573438526215

Epoch: 5| Step: 10
Training loss: 0.07942419131543157
Validation loss: 2.413226402741754

Epoch: 728| Step: 0
Training loss: 0.0829089473550862
Validation loss: 2.390621671353277

Epoch: 5| Step: 1
Training loss: 0.07669157247020626
Validation loss: 2.4151257636722048

Epoch: 5| Step: 2
Training loss: 0.07440814835783471
Validation loss: 2.41130602164746

Epoch: 5| Step: 3
Training loss: 0.06372729446404177
Validation loss: 2.391332400636623

Epoch: 5| Step: 4
Training loss: 0.08234530175554734
Validation loss: 2.4377261220729767

Epoch: 5| Step: 5
Training loss: 0.0821339384571665
Validation loss: 2.4083571608021432

Epoch: 5| Step: 6
Training loss: 0.12869014832586287
Validation loss: 2.4159179676251856

Epoch: 5| Step: 7
Training loss: 0.06244920551523966
Validation loss: 2.4230273714848294

Epoch: 5| Step: 8
Training loss: 0.09427754172365002
Validation loss: 2.423271624918914

Epoch: 5| Step: 9
Training loss: 0.15010693036865627
Validation loss: 2.4178704399124764

Epoch: 5| Step: 10
Training loss: 0.06669719505870449
Validation loss: 2.423100722679088

Epoch: 729| Step: 0
Training loss: 0.09294918880313872
Validation loss: 2.4169498662391247

Epoch: 5| Step: 1
Training loss: 0.07886836327389134
Validation loss: 2.4381481252399535

Epoch: 5| Step: 2
Training loss: 0.13178189194178933
Validation loss: 2.4133706457256014

Epoch: 5| Step: 3
Training loss: 0.05513012524677972
Validation loss: 2.397702340287845

Epoch: 5| Step: 4
Training loss: 0.0851438406118087
Validation loss: 2.439011924461935

Epoch: 5| Step: 5
Training loss: 0.08027801338203484
Validation loss: 2.412707176028611

Epoch: 5| Step: 6
Training loss: 0.10523284472745521
Validation loss: 2.3906413546978693

Epoch: 5| Step: 7
Training loss: 0.12012300632307973
Validation loss: 2.4069088642569816

Epoch: 5| Step: 8
Training loss: 0.056180625510498024
Validation loss: 2.429776164275898

Epoch: 5| Step: 9
Training loss: 0.04664373220144748
Validation loss: 2.411802835803493

Epoch: 5| Step: 10
Training loss: 0.07766162125051017
Validation loss: 2.4439950918332256

Epoch: 730| Step: 0
Training loss: 0.07753998950432947
Validation loss: 2.4163929172840293

Epoch: 5| Step: 1
Training loss: 0.06299453896480642
Validation loss: 2.424453373760309

Epoch: 5| Step: 2
Training loss: 0.15307168178270078
Validation loss: 2.400716703614729

Epoch: 5| Step: 3
Training loss: 0.061121703774755405
Validation loss: 2.4462659766321426

Epoch: 5| Step: 4
Training loss: 0.08491069031330835
Validation loss: 2.448104462307003

Epoch: 5| Step: 5
Training loss: 0.08524389393884715
Validation loss: 2.460352157513003

Epoch: 5| Step: 6
Training loss: 0.1146582287339264
Validation loss: 2.4210302138530837

Epoch: 5| Step: 7
Training loss: 0.08212674917139362
Validation loss: 2.4286785106002573

Epoch: 5| Step: 8
Training loss: 0.09008275252579039
Validation loss: 2.3901517859334103

Epoch: 5| Step: 9
Training loss: 0.05150159811837655
Validation loss: 2.41243264224722

Epoch: 5| Step: 10
Training loss: 0.10256584362702814
Validation loss: 2.435208597451969

Epoch: 731| Step: 0
Training loss: 0.15367652430286483
Validation loss: 2.4325575168889686

Epoch: 5| Step: 1
Training loss: 0.11646568601906017
Validation loss: 2.429308342554423

Epoch: 5| Step: 2
Training loss: 0.09256897027990928
Validation loss: 2.419879446065157

Epoch: 5| Step: 3
Training loss: 0.07208741613128186
Validation loss: 2.4114045929797063

Epoch: 5| Step: 4
Training loss: 0.12267267761045647
Validation loss: 2.401762264137818

Epoch: 5| Step: 5
Training loss: 0.07287598295227739
Validation loss: 2.3921837236816903

Epoch: 5| Step: 6
Training loss: 0.06990481773298167
Validation loss: 2.3989023549976314

Epoch: 5| Step: 7
Training loss: 0.09143967832329025
Validation loss: 2.4158422839463336

Epoch: 5| Step: 8
Training loss: 0.0716290856618299
Validation loss: 2.443254593190645

Epoch: 5| Step: 9
Training loss: 0.07833282722696867
Validation loss: 2.433081687762018

Epoch: 5| Step: 10
Training loss: 0.07784075586390744
Validation loss: 2.4508048469417187

Epoch: 732| Step: 0
Training loss: 0.08657941256228181
Validation loss: 2.4490997018084113

Epoch: 5| Step: 1
Training loss: 0.07547072345807114
Validation loss: 2.4582464137770033

Epoch: 5| Step: 2
Training loss: 0.09070679533150597
Validation loss: 2.4558995894512283

Epoch: 5| Step: 3
Training loss: 0.06280858259534876
Validation loss: 2.432291887304439

Epoch: 5| Step: 4
Training loss: 0.08341860940410781
Validation loss: 2.447549179095721

Epoch: 5| Step: 5
Training loss: 0.07677157317518489
Validation loss: 2.4202981304248787

Epoch: 5| Step: 6
Training loss: 0.12927975872646744
Validation loss: 2.424971497815072

Epoch: 5| Step: 7
Training loss: 0.06957983050385969
Validation loss: 2.426116972440906

Epoch: 5| Step: 8
Training loss: 0.11031480193775678
Validation loss: 2.406279045007459

Epoch: 5| Step: 9
Training loss: 0.128519170648426
Validation loss: 2.421418804453589

Epoch: 5| Step: 10
Training loss: 0.09749310216895704
Validation loss: 2.4252991498051166

Epoch: 733| Step: 0
Training loss: 0.043766190468612395
Validation loss: 2.400066674442461

Epoch: 5| Step: 1
Training loss: 0.07491733209582227
Validation loss: 2.4247576581581254

Epoch: 5| Step: 2
Training loss: 0.10040450630995024
Validation loss: 2.4038756884392574

Epoch: 5| Step: 3
Training loss: 0.11333629487559094
Validation loss: 2.4483312572963363

Epoch: 5| Step: 4
Training loss: 0.1647025859843124
Validation loss: 2.439730103384502

Epoch: 5| Step: 5
Training loss: 0.07116124046468414
Validation loss: 2.4430934809560423

Epoch: 5| Step: 6
Training loss: 0.053200682207287575
Validation loss: 2.447309051451281

Epoch: 5| Step: 7
Training loss: 0.12420267010023722
Validation loss: 2.4610108541223195

Epoch: 5| Step: 8
Training loss: 0.08664219909868494
Validation loss: 2.4274390161282406

Epoch: 5| Step: 9
Training loss: 0.06502034473569189
Validation loss: 2.423057212037233

Epoch: 5| Step: 10
Training loss: 0.08780549748167017
Validation loss: 2.425934851284176

Epoch: 734| Step: 0
Training loss: 0.14825551899106232
Validation loss: 2.438866559578736

Epoch: 5| Step: 1
Training loss: 0.10302643978933632
Validation loss: 2.4525026841374893

Epoch: 5| Step: 2
Training loss: 0.06951981327209523
Validation loss: 2.420953649586148

Epoch: 5| Step: 3
Training loss: 0.1383054418469468
Validation loss: 2.4450079489649466

Epoch: 5| Step: 4
Training loss: 0.1030828091622656
Validation loss: 2.451708539694681

Epoch: 5| Step: 5
Training loss: 0.08821317244254233
Validation loss: 2.438400378608332

Epoch: 5| Step: 6
Training loss: 0.1061780882554895
Validation loss: 2.453587290642983

Epoch: 5| Step: 7
Training loss: 0.10020587002937884
Validation loss: 2.409166979823038

Epoch: 5| Step: 8
Training loss: 0.14768728353958313
Validation loss: 2.4478914966916876

Epoch: 5| Step: 9
Training loss: 0.09786176989952133
Validation loss: 2.4127041254234687

Epoch: 5| Step: 10
Training loss: 0.09922255411139436
Validation loss: 2.424611154251692

Epoch: 735| Step: 0
Training loss: 0.05725771492220933
Validation loss: 2.3947887820489036

Epoch: 5| Step: 1
Training loss: 0.06955262696694213
Validation loss: 2.397668970098529

Epoch: 5| Step: 2
Training loss: 0.13286281081567136
Validation loss: 2.4083710670886007

Epoch: 5| Step: 3
Training loss: 0.07632282473435524
Validation loss: 2.4146531436447027

Epoch: 5| Step: 4
Training loss: 0.0774299729795854
Validation loss: 2.448712984492819

Epoch: 5| Step: 5
Training loss: 0.06404414248285269
Validation loss: 2.436822894476711

Epoch: 5| Step: 6
Training loss: 0.09930591546599576
Validation loss: 2.4351796795749494

Epoch: 5| Step: 7
Training loss: 0.12458992540207618
Validation loss: 2.4147023715827958

Epoch: 5| Step: 8
Training loss: 0.09044022138306552
Validation loss: 2.420744422391239

Epoch: 5| Step: 9
Training loss: 0.10898113006628514
Validation loss: 2.4303287487786984

Epoch: 5| Step: 10
Training loss: 0.12293110426943056
Validation loss: 2.4479439504582636

Epoch: 736| Step: 0
Training loss: 0.07641542452745065
Validation loss: 2.4169099265931164

Epoch: 5| Step: 1
Training loss: 0.08230173838020524
Validation loss: 2.4264783205963445

Epoch: 5| Step: 2
Training loss: 0.08284359564059916
Validation loss: 2.4320390306634003

Epoch: 5| Step: 3
Training loss: 0.1364065351952961
Validation loss: 2.4332652004759625

Epoch: 5| Step: 4
Training loss: 0.09570427816046578
Validation loss: 2.404762514668977

Epoch: 5| Step: 5
Training loss: 0.08805754229263861
Validation loss: 2.4092443985653533

Epoch: 5| Step: 6
Training loss: 0.08046252460379355
Validation loss: 2.4308600456980627

Epoch: 5| Step: 7
Training loss: 0.09238639203610965
Validation loss: 2.432770487844446

Epoch: 5| Step: 8
Training loss: 0.07169409225163689
Validation loss: 2.419553569165336

Epoch: 5| Step: 9
Training loss: 0.11861405323844552
Validation loss: 2.445727818938984

Epoch: 5| Step: 10
Training loss: 0.10543813967666191
Validation loss: 2.420179773950288

Epoch: 737| Step: 0
Training loss: 0.08705875054697611
Validation loss: 2.4317225720867715

Epoch: 5| Step: 1
Training loss: 0.10891263593480026
Validation loss: 2.428013664773232

Epoch: 5| Step: 2
Training loss: 0.09033519120746475
Validation loss: 2.4373813207955837

Epoch: 5| Step: 3
Training loss: 0.11865126840865511
Validation loss: 2.4254943837617646

Epoch: 5| Step: 4
Training loss: 0.08890676141266649
Validation loss: 2.434968567299768

Epoch: 5| Step: 5
Training loss: 0.04779629532461579
Validation loss: 2.4368647233174827

Epoch: 5| Step: 6
Training loss: 0.15130519828172445
Validation loss: 2.441421793045281

Epoch: 5| Step: 7
Training loss: 0.07098696005835536
Validation loss: 2.4272240271348418

Epoch: 5| Step: 8
Training loss: 0.11259913613107014
Validation loss: 2.435281390152282

Epoch: 5| Step: 9
Training loss: 0.09183725524047805
Validation loss: 2.457989720989514

Epoch: 5| Step: 10
Training loss: 0.0779320898139884
Validation loss: 2.462936867910064

Epoch: 738| Step: 0
Training loss: 0.07961599528812809
Validation loss: 2.461676085922151

Epoch: 5| Step: 1
Training loss: 0.08675065645713631
Validation loss: 2.4563303553790017

Epoch: 5| Step: 2
Training loss: 0.1269606147904262
Validation loss: 2.4658487306896704

Epoch: 5| Step: 3
Training loss: 0.07682373732058462
Validation loss: 2.4403534324788216

Epoch: 5| Step: 4
Training loss: 0.09168443489542127
Validation loss: 2.427938681772272

Epoch: 5| Step: 5
Training loss: 0.07182718998481118
Validation loss: 2.4248673206835525

Epoch: 5| Step: 6
Training loss: 0.09054076332945696
Validation loss: 2.3942315434770434

Epoch: 5| Step: 7
Training loss: 0.11359820338155126
Validation loss: 2.4132323751485707

Epoch: 5| Step: 8
Training loss: 0.11136772890203532
Validation loss: 2.421821838705789

Epoch: 5| Step: 9
Training loss: 0.06487712331629461
Validation loss: 2.4074028171759885

Epoch: 5| Step: 10
Training loss: 0.05337159726141925
Validation loss: 2.38232707635585

Epoch: 739| Step: 0
Training loss: 0.0811680781951494
Validation loss: 2.3595085233933424

Epoch: 5| Step: 1
Training loss: 0.14648670194684993
Validation loss: 2.3696125834151447

Epoch: 5| Step: 2
Training loss: 0.08470347736758932
Validation loss: 2.407285348506015

Epoch: 5| Step: 3
Training loss: 0.09753146782495974
Validation loss: 2.4227862096428465

Epoch: 5| Step: 4
Training loss: 0.06369162221109835
Validation loss: 2.4230014199355447

Epoch: 5| Step: 5
Training loss: 0.1506319092119586
Validation loss: 2.4053305019856035

Epoch: 5| Step: 6
Training loss: 0.07995491900620275
Validation loss: 2.418453240044367

Epoch: 5| Step: 7
Training loss: 0.10002297197177124
Validation loss: 2.4087731043715777

Epoch: 5| Step: 8
Training loss: 0.07815544608044733
Validation loss: 2.4308825243536223

Epoch: 5| Step: 9
Training loss: 0.08065646080331697
Validation loss: 2.4291917215751955

Epoch: 5| Step: 10
Training loss: 0.08925718624471253
Validation loss: 2.407749181511944

Epoch: 740| Step: 0
Training loss: 0.11304536051945108
Validation loss: 2.42609840324997

Epoch: 5| Step: 1
Training loss: 0.09041718773519583
Validation loss: 2.431826702229533

Epoch: 5| Step: 2
Training loss: 0.0792521291775441
Validation loss: 2.4205038001710766

Epoch: 5| Step: 3
Training loss: 0.05934343753951396
Validation loss: 2.4345268330956364

Epoch: 5| Step: 4
Training loss: 0.09062156670742647
Validation loss: 2.3990943898713413

Epoch: 5| Step: 5
Training loss: 0.10570769264180903
Validation loss: 2.385130268648939

Epoch: 5| Step: 6
Training loss: 0.10183701187960063
Validation loss: 2.4044562116606203

Epoch: 5| Step: 7
Training loss: 0.14312809209940042
Validation loss: 2.3785696426830416

Epoch: 5| Step: 8
Training loss: 0.13741724872880312
Validation loss: 2.415996096918054

Epoch: 5| Step: 9
Training loss: 0.09234505178047116
Validation loss: 2.410471417616422

Epoch: 5| Step: 10
Training loss: 0.0717666189783929
Validation loss: 2.4039116844414345

Epoch: 741| Step: 0
Training loss: 0.06708862173086377
Validation loss: 2.434551020123871

Epoch: 5| Step: 1
Training loss: 0.06350373273512408
Validation loss: 2.4384274817724148

Epoch: 5| Step: 2
Training loss: 0.1448138155451435
Validation loss: 2.447171781300982

Epoch: 5| Step: 3
Training loss: 0.0802292444581558
Validation loss: 2.439143373341925

Epoch: 5| Step: 4
Training loss: 0.06908921550336335
Validation loss: 2.4420273361533775

Epoch: 5| Step: 5
Training loss: 0.09703893576542252
Validation loss: 2.46545509339281

Epoch: 5| Step: 6
Training loss: 0.0529804844644241
Validation loss: 2.4393816138707978

Epoch: 5| Step: 7
Training loss: 0.10526127629996311
Validation loss: 2.458819444696035

Epoch: 5| Step: 8
Training loss: 0.09141881175818574
Validation loss: 2.458017839119467

Epoch: 5| Step: 9
Training loss: 0.09123131342672229
Validation loss: 2.471564689812019

Epoch: 5| Step: 10
Training loss: 0.14762733872763178
Validation loss: 2.4487121521802266

Epoch: 742| Step: 0
Training loss: 0.06270086896641568
Validation loss: 2.484029581682629

Epoch: 5| Step: 1
Training loss: 0.12503544483713425
Validation loss: 2.4351863255901827

Epoch: 5| Step: 2
Training loss: 0.07910876182478248
Validation loss: 2.3876728465393158

Epoch: 5| Step: 3
Training loss: 0.06485322831292278
Validation loss: 2.400960855260981

Epoch: 5| Step: 4
Training loss: 0.10233115053152825
Validation loss: 2.3943428321804565

Epoch: 5| Step: 5
Training loss: 0.11674447558727047
Validation loss: 2.4056062693618485

Epoch: 5| Step: 6
Training loss: 0.13487647514800472
Validation loss: 2.3931281512690763

Epoch: 5| Step: 7
Training loss: 0.07986011135931392
Validation loss: 2.3810826104156964

Epoch: 5| Step: 8
Training loss: 0.06986490478100892
Validation loss: 2.4173429894952743

Epoch: 5| Step: 9
Training loss: 0.07124075493939389
Validation loss: 2.4285711419606972

Epoch: 5| Step: 10
Training loss: 0.070947534464821
Validation loss: 2.43855130242157

Epoch: 743| Step: 0
Training loss: 0.08167720926375464
Validation loss: 2.4224889024154592

Epoch: 5| Step: 1
Training loss: 0.06983214780163266
Validation loss: 2.4266152178467992

Epoch: 5| Step: 2
Training loss: 0.08014311130658595
Validation loss: 2.419415340419091

Epoch: 5| Step: 3
Training loss: 0.07668727346548496
Validation loss: 2.4470894663246856

Epoch: 5| Step: 4
Training loss: 0.09562079138314312
Validation loss: 2.43129806388798

Epoch: 5| Step: 5
Training loss: 0.09034563426101666
Validation loss: 2.420824725175805

Epoch: 5| Step: 6
Training loss: 0.12669973762303638
Validation loss: 2.431127310411239

Epoch: 5| Step: 7
Training loss: 0.105640042689738
Validation loss: 2.4255716734885584

Epoch: 5| Step: 8
Training loss: 0.06953799330233641
Validation loss: 2.4244568399469912

Epoch: 5| Step: 9
Training loss: 0.05791352328182346
Validation loss: 2.4179727715080714

Epoch: 5| Step: 10
Training loss: 0.06028064523989774
Validation loss: 2.4172356847585696

Epoch: 744| Step: 0
Training loss: 0.06411827410035983
Validation loss: 2.427660379192983

Epoch: 5| Step: 1
Training loss: 0.055514844610713245
Validation loss: 2.4187147551668255

Epoch: 5| Step: 2
Training loss: 0.1221026987983014
Validation loss: 2.4095748710998324

Epoch: 5| Step: 3
Training loss: 0.07230769685431447
Validation loss: 2.418812116265335

Epoch: 5| Step: 4
Training loss: 0.07581644703318892
Validation loss: 2.4066325649196525

Epoch: 5| Step: 5
Training loss: 0.07270370582018165
Validation loss: 2.4054884294714562

Epoch: 5| Step: 6
Training loss: 0.11306254881293158
Validation loss: 2.401177891173314

Epoch: 5| Step: 7
Training loss: 0.11300398339154158
Validation loss: 2.383702682045356

Epoch: 5| Step: 8
Training loss: 0.10601037963338523
Validation loss: 2.414803244447444

Epoch: 5| Step: 9
Training loss: 0.07120289886393497
Validation loss: 2.4173863670262015

Epoch: 5| Step: 10
Training loss: 0.057091586647222144
Validation loss: 2.43301184227813

Epoch: 745| Step: 0
Training loss: 0.040766550096723114
Validation loss: 2.4305835532017874

Epoch: 5| Step: 1
Training loss: 0.05916138710675969
Validation loss: 2.4218547247263893

Epoch: 5| Step: 2
Training loss: 0.07371603274967016
Validation loss: 2.4367912730377

Epoch: 5| Step: 3
Training loss: 0.1444057744737996
Validation loss: 2.4268929198509155

Epoch: 5| Step: 4
Training loss: 0.07112303107252448
Validation loss: 2.4588168506294883

Epoch: 5| Step: 5
Training loss: 0.08627395710507554
Validation loss: 2.478555132532776

Epoch: 5| Step: 6
Training loss: 0.06010541796345882
Validation loss: 2.4394209333758643

Epoch: 5| Step: 7
Training loss: 0.07324462250794411
Validation loss: 2.4673336582589873

Epoch: 5| Step: 8
Training loss: 0.08784509115101155
Validation loss: 2.4420590588079167

Epoch: 5| Step: 9
Training loss: 0.12620439553196863
Validation loss: 2.434098822261699

Epoch: 5| Step: 10
Training loss: 0.07482085563691165
Validation loss: 2.460737014419617

Epoch: 746| Step: 0
Training loss: 0.08915357763916337
Validation loss: 2.406168492692938

Epoch: 5| Step: 1
Training loss: 0.0734313429625453
Validation loss: 2.434970854074604

Epoch: 5| Step: 2
Training loss: 0.06505689176121421
Validation loss: 2.428871720815864

Epoch: 5| Step: 3
Training loss: 0.06758727276358018
Validation loss: 2.4117956608388678

Epoch: 5| Step: 4
Training loss: 0.12312232837586266
Validation loss: 2.4043263701064554

Epoch: 5| Step: 5
Training loss: 0.06806667196476435
Validation loss: 2.4143511821928842

Epoch: 5| Step: 6
Training loss: 0.06818318481344536
Validation loss: 2.412861727536783

Epoch: 5| Step: 7
Training loss: 0.1208757584150106
Validation loss: 2.3983602473617536

Epoch: 5| Step: 8
Training loss: 0.07806600190726734
Validation loss: 2.4082032655199384

Epoch: 5| Step: 9
Training loss: 0.12323199833072314
Validation loss: 2.4318104463546018

Epoch: 5| Step: 10
Training loss: 0.0973914992248697
Validation loss: 2.4512064725876237

Epoch: 747| Step: 0
Training loss: 0.06740539973849702
Validation loss: 2.4487492856098028

Epoch: 5| Step: 1
Training loss: 0.07202084751170851
Validation loss: 2.4528303395906073

Epoch: 5| Step: 2
Training loss: 0.06258774722102667
Validation loss: 2.4504919385301154

Epoch: 5| Step: 3
Training loss: 0.06073612967945519
Validation loss: 2.4663658733049285

Epoch: 5| Step: 4
Training loss: 0.05503433377113464
Validation loss: 2.4588259324569983

Epoch: 5| Step: 5
Training loss: 0.11004083061896709
Validation loss: 2.458041354346324

Epoch: 5| Step: 6
Training loss: 0.05885090624624282
Validation loss: 2.47358647728063

Epoch: 5| Step: 7
Training loss: 0.07922381208543522
Validation loss: 2.4401608634733307

Epoch: 5| Step: 8
Training loss: 0.06079607678222478
Validation loss: 2.4750721134250737

Epoch: 5| Step: 9
Training loss: 0.11802098384136604
Validation loss: 2.4512164982664677

Epoch: 5| Step: 10
Training loss: 0.13711742448136952
Validation loss: 2.428528987646903

Epoch: 748| Step: 0
Training loss: 0.05841667120285488
Validation loss: 2.4284637200135704

Epoch: 5| Step: 1
Training loss: 0.07210244945753932
Validation loss: 2.435402143313631

Epoch: 5| Step: 2
Training loss: 0.1334325816523346
Validation loss: 2.4264563801225734

Epoch: 5| Step: 3
Training loss: 0.09525656641862601
Validation loss: 2.4183643774218706

Epoch: 5| Step: 4
Training loss: 0.1146834588053459
Validation loss: 2.400978000159708

Epoch: 5| Step: 5
Training loss: 0.05825884395365111
Validation loss: 2.4253113226587093

Epoch: 5| Step: 6
Training loss: 0.06784081298127845
Validation loss: 2.4668372945657033

Epoch: 5| Step: 7
Training loss: 0.09604282328373973
Validation loss: 2.4388876058270967

Epoch: 5| Step: 8
Training loss: 0.11523260907258638
Validation loss: 2.468180362128276

Epoch: 5| Step: 9
Training loss: 0.07234680603423306
Validation loss: 2.470339734556604

Epoch: 5| Step: 10
Training loss: 0.08601435021123638
Validation loss: 2.477735421838809

Epoch: 749| Step: 0
Training loss: 0.059501598547425726
Validation loss: 2.46903398935703

Epoch: 5| Step: 1
Training loss: 0.06791610734485959
Validation loss: 2.504580021751684

Epoch: 5| Step: 2
Training loss: 0.07294150621939202
Validation loss: 2.5013479751811736

Epoch: 5| Step: 3
Training loss: 0.05884295160837812
Validation loss: 2.47154120937917

Epoch: 5| Step: 4
Training loss: 0.1015917341633084
Validation loss: 2.507824967472537

Epoch: 5| Step: 5
Training loss: 0.07029217187758893
Validation loss: 2.4806244320469193

Epoch: 5| Step: 6
Training loss: 0.05884242732812236
Validation loss: 2.4633797258018193

Epoch: 5| Step: 7
Training loss: 0.05880881220150817
Validation loss: 2.461640768486519

Epoch: 5| Step: 8
Training loss: 0.1280059732602424
Validation loss: 2.442102804069405

Epoch: 5| Step: 9
Training loss: 0.12413042440091378
Validation loss: 2.436035210447695

Epoch: 5| Step: 10
Training loss: 0.06762028740488109
Validation loss: 2.411311181230931

Epoch: 750| Step: 0
Training loss: 0.06826759034800794
Validation loss: 2.448734478998387

Epoch: 5| Step: 1
Training loss: 0.08142640582764933
Validation loss: 2.4211297398625895

Epoch: 5| Step: 2
Training loss: 0.08671675209372978
Validation loss: 2.398556384243009

Epoch: 5| Step: 3
Training loss: 0.12051489359424625
Validation loss: 2.436545594027705

Epoch: 5| Step: 4
Training loss: 0.08171067153248374
Validation loss: 2.4272647201723774

Epoch: 5| Step: 5
Training loss: 0.07933004958459396
Validation loss: 2.4458218087082075

Epoch: 5| Step: 6
Training loss: 0.0549031438026231
Validation loss: 2.427147606495921

Epoch: 5| Step: 7
Training loss: 0.10304735992670377
Validation loss: 2.4332685405870795

Epoch: 5| Step: 8
Training loss: 0.08795528152920398
Validation loss: 2.4234195554038274

Epoch: 5| Step: 9
Training loss: 0.11296837449176264
Validation loss: 2.4297609360660797

Epoch: 5| Step: 10
Training loss: 0.10212810908531895
Validation loss: 2.4225623397571954

Epoch: 751| Step: 0
Training loss: 0.08758301150023201
Validation loss: 2.4603611482311565

Epoch: 5| Step: 1
Training loss: 0.08881108116289022
Validation loss: 2.4662944377598377

Epoch: 5| Step: 2
Training loss: 0.07825380079153478
Validation loss: 2.44705229304073

Epoch: 5| Step: 3
Training loss: 0.09197489744037075
Validation loss: 2.451762256481097

Epoch: 5| Step: 4
Training loss: 0.052336011588583295
Validation loss: 2.4581607691469527

Epoch: 5| Step: 5
Training loss: 0.08281745119858405
Validation loss: 2.449661154478915

Epoch: 5| Step: 6
Training loss: 0.08455788992458763
Validation loss: 2.4753468575485282

Epoch: 5| Step: 7
Training loss: 0.07263379454977181
Validation loss: 2.454625234958241

Epoch: 5| Step: 8
Training loss: 0.12168240521183514
Validation loss: 2.464247022010086

Epoch: 5| Step: 9
Training loss: 0.12399109095680491
Validation loss: 2.450666031370614

Epoch: 5| Step: 10
Training loss: 0.09840738861543386
Validation loss: 2.4400132277303475

Epoch: 752| Step: 0
Training loss: 0.06377520368037715
Validation loss: 2.4461142473114696

Epoch: 5| Step: 1
Training loss: 0.05444621177009503
Validation loss: 2.447602633142178

Epoch: 5| Step: 2
Training loss: 0.062081041036053684
Validation loss: 2.4152995844309553

Epoch: 5| Step: 3
Training loss: 0.08886044864465406
Validation loss: 2.407020663311465

Epoch: 5| Step: 4
Training loss: 0.05431428928495252
Validation loss: 2.4070392332325965

Epoch: 5| Step: 5
Training loss: 0.05874332370704338
Validation loss: 2.4124101707400727

Epoch: 5| Step: 6
Training loss: 0.06588610479437791
Validation loss: 2.3937484135249387

Epoch: 5| Step: 7
Training loss: 0.09273372603320325
Validation loss: 2.4148146357685385

Epoch: 5| Step: 8
Training loss: 0.09041549332285147
Validation loss: 2.431990444855261

Epoch: 5| Step: 9
Training loss: 0.09510840310768486
Validation loss: 2.416902181275962

Epoch: 5| Step: 10
Training loss: 0.1606359856370367
Validation loss: 2.3958804321653093

Epoch: 753| Step: 0
Training loss: 0.13404775238283556
Validation loss: 2.447708518648537

Epoch: 5| Step: 1
Training loss: 0.04978915046990592
Validation loss: 2.429798868723287

Epoch: 5| Step: 2
Training loss: 0.1010561433929805
Validation loss: 2.450605900830719

Epoch: 5| Step: 3
Training loss: 0.08483096298611031
Validation loss: 2.4517243865409273

Epoch: 5| Step: 4
Training loss: 0.07848847296939172
Validation loss: 2.4314367705775615

Epoch: 5| Step: 5
Training loss: 0.1286462850086556
Validation loss: 2.4624858016479325

Epoch: 5| Step: 6
Training loss: 0.06799958094343271
Validation loss: 2.453295741799187

Epoch: 5| Step: 7
Training loss: 0.055880556392204954
Validation loss: 2.427023501404464

Epoch: 5| Step: 8
Training loss: 0.0756395796492992
Validation loss: 2.451748317123651

Epoch: 5| Step: 9
Training loss: 0.117808856351246
Validation loss: 2.4530985349867405

Epoch: 5| Step: 10
Training loss: 0.11326460469386666
Validation loss: 2.458462219725079

Epoch: 754| Step: 0
Training loss: 0.05566814892810435
Validation loss: 2.4484501250655013

Epoch: 5| Step: 1
Training loss: 0.05897950111235608
Validation loss: 2.4434980212768633

Epoch: 5| Step: 2
Training loss: 0.06683809447472708
Validation loss: 2.434586782662041

Epoch: 5| Step: 3
Training loss: 0.09019724610454577
Validation loss: 2.4512430735426505

Epoch: 5| Step: 4
Training loss: 0.11259580695030655
Validation loss: 2.4399826063826904

Epoch: 5| Step: 5
Training loss: 0.1131345604839943
Validation loss: 2.423544907613023

Epoch: 5| Step: 6
Training loss: 0.09134210899626462
Validation loss: 2.4135870790117893

Epoch: 5| Step: 7
Training loss: 0.0667999043809469
Validation loss: 2.4372035872568665

Epoch: 5| Step: 8
Training loss: 0.06439587188750608
Validation loss: 2.4543270773658623

Epoch: 5| Step: 9
Training loss: 0.11553393237947038
Validation loss: 2.4801963666287903

Epoch: 5| Step: 10
Training loss: 0.0681446688643269
Validation loss: 2.4643637530734854

Epoch: 755| Step: 0
Training loss: 0.06849505039461416
Validation loss: 2.460989025674937

Epoch: 5| Step: 1
Training loss: 0.06072708583048292
Validation loss: 2.418594406900761

Epoch: 5| Step: 2
Training loss: 0.051252514422043996
Validation loss: 2.453967218226407

Epoch: 5| Step: 3
Training loss: 0.05913069195018852
Validation loss: 2.4575030379624527

Epoch: 5| Step: 4
Training loss: 0.061741201325063104
Validation loss: 2.432062056568922

Epoch: 5| Step: 5
Training loss: 0.1287548736927562
Validation loss: 2.4546764330788333

Epoch: 5| Step: 6
Training loss: 0.06855730625052353
Validation loss: 2.473416950636755

Epoch: 5| Step: 7
Training loss: 0.14249856897940621
Validation loss: 2.4334620066122166

Epoch: 5| Step: 8
Training loss: 0.15493936408238385
Validation loss: 2.456959045341482

Epoch: 5| Step: 9
Training loss: 0.06914653900952887
Validation loss: 2.442669104878075

Epoch: 5| Step: 10
Training loss: 0.09001906021766311
Validation loss: 2.4345368042584656

Epoch: 756| Step: 0
Training loss: 0.0742017481805286
Validation loss: 2.4196538631338464

Epoch: 5| Step: 1
Training loss: 0.07195705182546479
Validation loss: 2.3833843597341278

Epoch: 5| Step: 2
Training loss: 0.11286385690724941
Validation loss: 2.397698647243289

Epoch: 5| Step: 3
Training loss: 0.0637100437354214
Validation loss: 2.405538429509943

Epoch: 5| Step: 4
Training loss: 0.07701113712014725
Validation loss: 2.386206894764483

Epoch: 5| Step: 5
Training loss: 0.12164635852391767
Validation loss: 2.393084427765028

Epoch: 5| Step: 6
Training loss: 0.11194731616079244
Validation loss: 2.4017454210431217

Epoch: 5| Step: 7
Training loss: 0.13714773451174866
Validation loss: 2.411043854983543

Epoch: 5| Step: 8
Training loss: 0.11129499661955719
Validation loss: 2.4106926436070513

Epoch: 5| Step: 9
Training loss: 0.09267290088772002
Validation loss: 2.4314183253109873

Epoch: 5| Step: 10
Training loss: 0.13373212229153658
Validation loss: 2.4322398338021975

Epoch: 757| Step: 0
Training loss: 0.07887912309917453
Validation loss: 2.4592699846163355

Epoch: 5| Step: 1
Training loss: 0.07465243994035103
Validation loss: 2.421045753231888

Epoch: 5| Step: 2
Training loss: 0.08795855863732203
Validation loss: 2.450798411693349

Epoch: 5| Step: 3
Training loss: 0.08319086479246884
Validation loss: 2.4692896041268964

Epoch: 5| Step: 4
Training loss: 0.07950016832240148
Validation loss: 2.457299497060752

Epoch: 5| Step: 5
Training loss: 0.061433715338231
Validation loss: 2.4420007839390254

Epoch: 5| Step: 6
Training loss: 0.0749865581964086
Validation loss: 2.4655739263532466

Epoch: 5| Step: 7
Training loss: 0.09459683294978034
Validation loss: 2.4593499790945343

Epoch: 5| Step: 8
Training loss: 0.11234724648171694
Validation loss: 2.445156171699569

Epoch: 5| Step: 9
Training loss: 0.14381001271919844
Validation loss: 2.460222533724

Epoch: 5| Step: 10
Training loss: 0.09570976156462517
Validation loss: 2.4524019909480335

Epoch: 758| Step: 0
Training loss: 0.1250865904583899
Validation loss: 2.469951496665191

Epoch: 5| Step: 1
Training loss: 0.06554289532357281
Validation loss: 2.443512449396562

Epoch: 5| Step: 2
Training loss: 0.09260979324035273
Validation loss: 2.4549866496610884

Epoch: 5| Step: 3
Training loss: 0.09008653117655735
Validation loss: 2.445370839050212

Epoch: 5| Step: 4
Training loss: 0.053696903649483284
Validation loss: 2.479452250297868

Epoch: 5| Step: 5
Training loss: 0.06767189171583224
Validation loss: 2.442395517398424

Epoch: 5| Step: 6
Training loss: 0.12952761733571724
Validation loss: 2.4474304634482933

Epoch: 5| Step: 7
Training loss: 0.10486897158801388
Validation loss: 2.447220074349419

Epoch: 5| Step: 8
Training loss: 0.0783387865125008
Validation loss: 2.4410109112666216

Epoch: 5| Step: 9
Training loss: 0.08950629299232842
Validation loss: 2.4193057359477486

Epoch: 5| Step: 10
Training loss: 0.13470797757035788
Validation loss: 2.41762897043638

Epoch: 759| Step: 0
Training loss: 0.11130094614713906
Validation loss: 2.416307097627636

Epoch: 5| Step: 1
Training loss: 0.0600199749691541
Validation loss: 2.3962473343540314

Epoch: 5| Step: 2
Training loss: 0.12724770334884244
Validation loss: 2.402475942780829

Epoch: 5| Step: 3
Training loss: 0.12263647393841465
Validation loss: 2.4203452273534443

Epoch: 5| Step: 4
Training loss: 0.0648489487528797
Validation loss: 2.3678648334408714

Epoch: 5| Step: 5
Training loss: 0.13129763732120484
Validation loss: 2.402656666721698

Epoch: 5| Step: 6
Training loss: 0.11222444238197019
Validation loss: 2.423014096055727

Epoch: 5| Step: 7
Training loss: 0.09387770537885823
Validation loss: 2.409500144186695

Epoch: 5| Step: 8
Training loss: 0.1172207705634536
Validation loss: 2.4423629772335707

Epoch: 5| Step: 9
Training loss: 0.08658823273778124
Validation loss: 2.4180542774365947

Epoch: 5| Step: 10
Training loss: 0.06479844872104634
Validation loss: 2.4707655751937745

Epoch: 760| Step: 0
Training loss: 0.08778817510618896
Validation loss: 2.4419124086784483

Epoch: 5| Step: 1
Training loss: 0.06466141913268526
Validation loss: 2.4549932169939064

Epoch: 5| Step: 2
Training loss: 0.11088944052291667
Validation loss: 2.46377121768757

Epoch: 5| Step: 3
Training loss: 0.06973724684078722
Validation loss: 2.475177039249729

Epoch: 5| Step: 4
Training loss: 0.12093907137153033
Validation loss: 2.4205602109048763

Epoch: 5| Step: 5
Training loss: 0.14132293385871825
Validation loss: 2.426159758282989

Epoch: 5| Step: 6
Training loss: 0.07750751732892205
Validation loss: 2.4507160579557925

Epoch: 5| Step: 7
Training loss: 0.11758656107145564
Validation loss: 2.3917149222646197

Epoch: 5| Step: 8
Training loss: 0.09301158555319151
Validation loss: 2.421876938177703

Epoch: 5| Step: 9
Training loss: 0.0700809055486944
Validation loss: 2.441396994690118

Epoch: 5| Step: 10
Training loss: 0.13949664075414703
Validation loss: 2.438259733116259

Epoch: 761| Step: 0
Training loss: 0.06350782064934536
Validation loss: 2.4319492208022035

Epoch: 5| Step: 1
Training loss: 0.06709155076366483
Validation loss: 2.438013158967006

Epoch: 5| Step: 2
Training loss: 0.07739293913651753
Validation loss: 2.444192550666057

Epoch: 5| Step: 3
Training loss: 0.11725433351158213
Validation loss: 2.420154601162071

Epoch: 5| Step: 4
Training loss: 0.06397203230322096
Validation loss: 2.4479310680446655

Epoch: 5| Step: 5
Training loss: 0.12227662771278734
Validation loss: 2.445935177878981

Epoch: 5| Step: 6
Training loss: 0.10405718643065666
Validation loss: 2.4607758960703645

Epoch: 5| Step: 7
Training loss: 0.07040825588608784
Validation loss: 2.427727103506036

Epoch: 5| Step: 8
Training loss: 0.10552828044712156
Validation loss: 2.4521713927147424

Epoch: 5| Step: 9
Training loss: 0.08461892688722025
Validation loss: 2.419618973840702

Epoch: 5| Step: 10
Training loss: 0.09176773258012336
Validation loss: 2.448238791638108

Epoch: 762| Step: 0
Training loss: 0.13740068392642382
Validation loss: 2.4166954982580853

Epoch: 5| Step: 1
Training loss: 0.10490037391019118
Validation loss: 2.421886382405357

Epoch: 5| Step: 2
Training loss: 0.09760986180044406
Validation loss: 2.4263943310317595

Epoch: 5| Step: 3
Training loss: 0.08221548825894612
Validation loss: 2.445895824740555

Epoch: 5| Step: 4
Training loss: 0.141533387971743
Validation loss: 2.4006088457887342

Epoch: 5| Step: 5
Training loss: 0.08545899199044489
Validation loss: 2.4252796029241983

Epoch: 5| Step: 6
Training loss: 0.0813927608981607
Validation loss: 2.423738508018859

Epoch: 5| Step: 7
Training loss: 0.07906329441990752
Validation loss: 2.4034615906016885

Epoch: 5| Step: 8
Training loss: 0.08754193491055269
Validation loss: 2.423849608552105

Epoch: 5| Step: 9
Training loss: 0.10146864350650793
Validation loss: 2.4174615771166907

Epoch: 5| Step: 10
Training loss: 0.09556178925551173
Validation loss: 2.3906943487909857

Epoch: 763| Step: 0
Training loss: 0.11837153702749109
Validation loss: 2.421785879198967

Epoch: 5| Step: 1
Training loss: 0.1112582213131305
Validation loss: 2.4178576443149367

Epoch: 5| Step: 2
Training loss: 0.08469680858142595
Validation loss: 2.4399303176874403

Epoch: 5| Step: 3
Training loss: 0.08269112144340798
Validation loss: 2.4341365446099017

Epoch: 5| Step: 4
Training loss: 0.08123137852131092
Validation loss: 2.4512004902101725

Epoch: 5| Step: 5
Training loss: 0.07894503742511737
Validation loss: 2.4610716528461523

Epoch: 5| Step: 6
Training loss: 0.11173915693329686
Validation loss: 2.461145484731063

Epoch: 5| Step: 7
Training loss: 0.09813197610743296
Validation loss: 2.493942263775334

Epoch: 5| Step: 8
Training loss: 0.09666408547789855
Validation loss: 2.48012335719575

Epoch: 5| Step: 9
Training loss: 0.08608787558119041
Validation loss: 2.491760040315948

Epoch: 5| Step: 10
Training loss: 0.09778813992648959
Validation loss: 2.490001284174006

Epoch: 764| Step: 0
Training loss: 0.08413415128585124
Validation loss: 2.47131198727033

Epoch: 5| Step: 1
Training loss: 0.07948412338799676
Validation loss: 2.4363196917436567

Epoch: 5| Step: 2
Training loss: 0.10928459347973625
Validation loss: 2.4505238100098117

Epoch: 5| Step: 3
Training loss: 0.0778920814297646
Validation loss: 2.4348598261503547

Epoch: 5| Step: 4
Training loss: 0.09141993746206344
Validation loss: 2.4152855949111265

Epoch: 5| Step: 5
Training loss: 0.07766190006533069
Validation loss: 2.4120013187512797

Epoch: 5| Step: 6
Training loss: 0.06922716689117722
Validation loss: 2.4427183722014623

Epoch: 5| Step: 7
Training loss: 0.11091156458246869
Validation loss: 2.438651180909982

Epoch: 5| Step: 8
Training loss: 0.12823817499851176
Validation loss: 2.458886086140624

Epoch: 5| Step: 9
Training loss: 0.08259240718966701
Validation loss: 2.4319966961176256

Epoch: 5| Step: 10
Training loss: 0.14250183023774837
Validation loss: 2.428467652357116

Epoch: 765| Step: 0
Training loss: 0.14374281435090205
Validation loss: 2.430683970030451

Epoch: 5| Step: 1
Training loss: 0.09598576401853197
Validation loss: 2.443615837936912

Epoch: 5| Step: 2
Training loss: 0.07501617061116225
Validation loss: 2.4440588580188987

Epoch: 5| Step: 3
Training loss: 0.11658433822110591
Validation loss: 2.4400069074366537

Epoch: 5| Step: 4
Training loss: 0.12123573347103193
Validation loss: 2.440784949611132

Epoch: 5| Step: 5
Training loss: 0.07799055034088812
Validation loss: 2.433416086428524

Epoch: 5| Step: 6
Training loss: 0.07926399719150468
Validation loss: 2.446724859210475

Epoch: 5| Step: 7
Training loss: 0.09111792500428113
Validation loss: 2.4118858225505706

Epoch: 5| Step: 8
Training loss: 0.09278695861263274
Validation loss: 2.4092365828489313

Epoch: 5| Step: 9
Training loss: 0.11006158098636472
Validation loss: 2.429882308567286

Epoch: 5| Step: 10
Training loss: 0.06963759270477664
Validation loss: 2.4243815026691484

Epoch: 766| Step: 0
Training loss: 0.0759392971789639
Validation loss: 2.4229141572936754

Epoch: 5| Step: 1
Training loss: 0.08318458135573459
Validation loss: 2.4246720531529804

Epoch: 5| Step: 2
Training loss: 0.05968364113297034
Validation loss: 2.426721370985697

Epoch: 5| Step: 3
Training loss: 0.07449967148207552
Validation loss: 2.4926633526811797

Epoch: 5| Step: 4
Training loss: 0.12096785338169778
Validation loss: 2.476477930052181

Epoch: 5| Step: 5
Training loss: 0.07521014253103674
Validation loss: 2.47494156802566

Epoch: 5| Step: 6
Training loss: 0.08952314767907958
Validation loss: 2.454236895424467

Epoch: 5| Step: 7
Training loss: 0.05327403362269024
Validation loss: 2.4809831159106217

Epoch: 5| Step: 8
Training loss: 0.1276031359481704
Validation loss: 2.4673331512109216

Epoch: 5| Step: 9
Training loss: 0.0865074111657353
Validation loss: 2.4600541516044814

Epoch: 5| Step: 10
Training loss: 0.08155487453323407
Validation loss: 2.45095856924916

Epoch: 767| Step: 0
Training loss: 0.05419350069830279
Validation loss: 2.431833773817473

Epoch: 5| Step: 1
Training loss: 0.06884919496264201
Validation loss: 2.4710286098673904

Epoch: 5| Step: 2
Training loss: 0.0636048597629844
Validation loss: 2.4466628007608735

Epoch: 5| Step: 3
Training loss: 0.054196291062609175
Validation loss: 2.468223486556021

Epoch: 5| Step: 4
Training loss: 0.07035523678781234
Validation loss: 2.454723976405071

Epoch: 5| Step: 5
Training loss: 0.07542674256931649
Validation loss: 2.4644101327032844

Epoch: 5| Step: 6
Training loss: 0.0889949404311033
Validation loss: 2.452093317761484

Epoch: 5| Step: 7
Training loss: 0.10983803353011283
Validation loss: 2.416278297298469

Epoch: 5| Step: 8
Training loss: 0.08353680460304515
Validation loss: 2.4486085296697224

Epoch: 5| Step: 9
Training loss: 0.10757684799688579
Validation loss: 2.4388166021300934

Epoch: 5| Step: 10
Training loss: 0.11842251720624275
Validation loss: 2.415536846234557

Epoch: 768| Step: 0
Training loss: 0.07580056841397009
Validation loss: 2.4201833924376244

Epoch: 5| Step: 1
Training loss: 0.10838881441308539
Validation loss: 2.4659487677219896

Epoch: 5| Step: 2
Training loss: 0.08680870067011544
Validation loss: 2.460031728998424

Epoch: 5| Step: 3
Training loss: 0.08661839202486496
Validation loss: 2.4466839706463603

Epoch: 5| Step: 4
Training loss: 0.10375368437056261
Validation loss: 2.469453656587952

Epoch: 5| Step: 5
Training loss: 0.05465329326573417
Validation loss: 2.4691491043902483

Epoch: 5| Step: 6
Training loss: 0.07967113368880314
Validation loss: 2.44390044175055

Epoch: 5| Step: 7
Training loss: 0.06409137891929274
Validation loss: 2.451019874628132

Epoch: 5| Step: 8
Training loss: 0.10797881190619954
Validation loss: 2.4393916629263153

Epoch: 5| Step: 9
Training loss: 0.07702328695434783
Validation loss: 2.4419602236079254

Epoch: 5| Step: 10
Training loss: 0.06789861436723614
Validation loss: 2.4627377671947475

Epoch: 769| Step: 0
Training loss: 0.07023084057707848
Validation loss: 2.4551970399337035

Epoch: 5| Step: 1
Training loss: 0.06979768755845224
Validation loss: 2.4499169760434985

Epoch: 5| Step: 2
Training loss: 0.1209779308563189
Validation loss: 2.453019374425514

Epoch: 5| Step: 3
Training loss: 0.049741045175577425
Validation loss: 2.4471379972331175

Epoch: 5| Step: 4
Training loss: 0.0649398323097805
Validation loss: 2.4531925908748065

Epoch: 5| Step: 5
Training loss: 0.04718399772610062
Validation loss: 2.4259267205282766

Epoch: 5| Step: 6
Training loss: 0.048804561174399276
Validation loss: 2.445288156268119

Epoch: 5| Step: 7
Training loss: 0.11776745656074576
Validation loss: 2.432400866566991

Epoch: 5| Step: 8
Training loss: 0.11810407613441379
Validation loss: 2.4325265516488286

Epoch: 5| Step: 9
Training loss: 0.08556650015018887
Validation loss: 2.4352318744670227

Epoch: 5| Step: 10
Training loss: 0.09377884421079931
Validation loss: 2.416067170132042

Epoch: 770| Step: 0
Training loss: 0.08283522278408027
Validation loss: 2.4373696089609123

Epoch: 5| Step: 1
Training loss: 0.05562504438200262
Validation loss: 2.4376630536600277

Epoch: 5| Step: 2
Training loss: 0.05181039532314167
Validation loss: 2.41111208963876

Epoch: 5| Step: 3
Training loss: 0.06001512186963768
Validation loss: 2.4309496912088386

Epoch: 5| Step: 4
Training loss: 0.057236810001049424
Validation loss: 2.4365044162685194

Epoch: 5| Step: 5
Training loss: 0.11210577390782037
Validation loss: 2.4332170745524184

Epoch: 5| Step: 6
Training loss: 0.05575358152725931
Validation loss: 2.435615151831465

Epoch: 5| Step: 7
Training loss: 0.11070701858118251
Validation loss: 2.4403775533544865

Epoch: 5| Step: 8
Training loss: 0.07635673990517124
Validation loss: 2.439272683740324

Epoch: 5| Step: 9
Training loss: 0.05398491858472291
Validation loss: 2.418073564929759

Epoch: 5| Step: 10
Training loss: 0.11519682401698353
Validation loss: 2.42727292354756

Epoch: 771| Step: 0
Training loss: 0.06464725576859248
Validation loss: 2.408864661107682

Epoch: 5| Step: 1
Training loss: 0.05052910156200456
Validation loss: 2.434531297957629

Epoch: 5| Step: 2
Training loss: 0.0816277160659991
Validation loss: 2.4113595051432957

Epoch: 5| Step: 3
Training loss: 0.06699882160291869
Validation loss: 2.4396301902548143

Epoch: 5| Step: 4
Training loss: 0.06340040994162466
Validation loss: 2.4038930748966094

Epoch: 5| Step: 5
Training loss: 0.11528471073649688
Validation loss: 2.4079852176800274

Epoch: 5| Step: 6
Training loss: 0.11139991185802897
Validation loss: 2.3944271617531814

Epoch: 5| Step: 7
Training loss: 0.06517540927880272
Validation loss: 2.412110399027871

Epoch: 5| Step: 8
Training loss: 0.0376599062780847
Validation loss: 2.4160038393038747

Epoch: 5| Step: 9
Training loss: 0.09715377761496224
Validation loss: 2.394688949741144

Epoch: 5| Step: 10
Training loss: 0.10144377609957905
Validation loss: 2.416178383117766

Epoch: 772| Step: 0
Training loss: 0.08888966936223709
Validation loss: 2.4120078383788948

Epoch: 5| Step: 1
Training loss: 0.061506787575141164
Validation loss: 2.413085799389174

Epoch: 5| Step: 2
Training loss: 0.039996282762885034
Validation loss: 2.3990366251126964

Epoch: 5| Step: 3
Training loss: 0.11279089624391686
Validation loss: 2.4536236319652414

Epoch: 5| Step: 4
Training loss: 0.0743921318929166
Validation loss: 2.4441189036625537

Epoch: 5| Step: 5
Training loss: 0.08616126254522838
Validation loss: 2.4346954496635904

Epoch: 5| Step: 6
Training loss: 0.060195683042486126
Validation loss: 2.4402119569203333

Epoch: 5| Step: 7
Training loss: 0.07927411297673628
Validation loss: 2.419067527569641

Epoch: 5| Step: 8
Training loss: 0.07417740736977951
Validation loss: 2.41315956325606

Epoch: 5| Step: 9
Training loss: 0.07510664282159007
Validation loss: 2.428708801053522

Epoch: 5| Step: 10
Training loss: 0.13716942214032884
Validation loss: 2.4154801863146913

Epoch: 773| Step: 0
Training loss: 0.04605354822932056
Validation loss: 2.4227023518629163

Epoch: 5| Step: 1
Training loss: 0.07669518818378428
Validation loss: 2.423209135632812

Epoch: 5| Step: 2
Training loss: 0.07809910046904883
Validation loss: 2.4448621772208177

Epoch: 5| Step: 3
Training loss: 0.13124737226035552
Validation loss: 2.4432264289719337

Epoch: 5| Step: 4
Training loss: 0.07168904212279906
Validation loss: 2.43193790025298

Epoch: 5| Step: 5
Training loss: 0.10512250562190824
Validation loss: 2.4170285662211497

Epoch: 5| Step: 6
Training loss: 0.10449173740040463
Validation loss: 2.439719600204213

Epoch: 5| Step: 7
Training loss: 0.07646555406963987
Validation loss: 2.4657631694678996

Epoch: 5| Step: 8
Training loss: 0.07178074316162213
Validation loss: 2.4556641050313543

Epoch: 5| Step: 9
Training loss: 0.07160998315197084
Validation loss: 2.4569219413007715

Epoch: 5| Step: 10
Training loss: 0.05954686469451086
Validation loss: 2.4404262988879193

Epoch: 774| Step: 0
Training loss: 0.06429968255357336
Validation loss: 2.4482460995940776

Epoch: 5| Step: 1
Training loss: 0.11510297589815292
Validation loss: 2.4873630725817755

Epoch: 5| Step: 2
Training loss: 0.11696922318864524
Validation loss: 2.4875746992543837

Epoch: 5| Step: 3
Training loss: 0.06530566702809863
Validation loss: 2.476535945910555

Epoch: 5| Step: 4
Training loss: 0.09464600175375414
Validation loss: 2.4820385982491895

Epoch: 5| Step: 5
Training loss: 0.07084014061633419
Validation loss: 2.5049825372190195

Epoch: 5| Step: 6
Training loss: 0.06483416917409415
Validation loss: 2.4849969641672986

Epoch: 5| Step: 7
Training loss: 0.06901218828890245
Validation loss: 2.4710746579499334

Epoch: 5| Step: 8
Training loss: 0.1231602116523281
Validation loss: 2.435398036899182

Epoch: 5| Step: 9
Training loss: 0.04152118940090262
Validation loss: 2.4565446129363715

Epoch: 5| Step: 10
Training loss: 0.10522448546364695
Validation loss: 2.445088397463751

Epoch: 775| Step: 0
Training loss: 0.08322844355151295
Validation loss: 2.4382489223682935

Epoch: 5| Step: 1
Training loss: 0.05647771731787105
Validation loss: 2.4384463839200836

Epoch: 5| Step: 2
Training loss: 0.055070914564198215
Validation loss: 2.4528903685684718

Epoch: 5| Step: 3
Training loss: 0.11806188453238241
Validation loss: 2.4529192720469872

Epoch: 5| Step: 4
Training loss: 0.07170954570942782
Validation loss: 2.444476438159459

Epoch: 5| Step: 5
Training loss: 0.13127773934101336
Validation loss: 2.4352860199584487

Epoch: 5| Step: 6
Training loss: 0.12548344970189076
Validation loss: 2.4287064767158415

Epoch: 5| Step: 7
Training loss: 0.08822052816881928
Validation loss: 2.4457847319819317

Epoch: 5| Step: 8
Training loss: 0.0661374288886623
Validation loss: 2.4172028806653527

Epoch: 5| Step: 9
Training loss: 0.1450148238114826
Validation loss: 2.4291274210588094

Epoch: 5| Step: 10
Training loss: 0.0549557378684376
Validation loss: 2.430755006153117

Epoch: 776| Step: 0
Training loss: 0.12096344951575486
Validation loss: 2.439565319452488

Epoch: 5| Step: 1
Training loss: 0.06469098186566785
Validation loss: 2.4394627176687305

Epoch: 5| Step: 2
Training loss: 0.06228959347663548
Validation loss: 2.461088395656434

Epoch: 5| Step: 3
Training loss: 0.07202255765470812
Validation loss: 2.4055928554316237

Epoch: 5| Step: 4
Training loss: 0.06848969639320374
Validation loss: 2.438578007310978

Epoch: 5| Step: 5
Training loss: 0.08448407751940756
Validation loss: 2.438320141835686

Epoch: 5| Step: 6
Training loss: 0.06029746190855788
Validation loss: 2.436506235486648

Epoch: 5| Step: 7
Training loss: 0.07891622364633752
Validation loss: 2.422395708551774

Epoch: 5| Step: 8
Training loss: 0.1158347653124937
Validation loss: 2.429576073412699

Epoch: 5| Step: 9
Training loss: 0.10370783235459705
Validation loss: 2.4173675616192503

Epoch: 5| Step: 10
Training loss: 0.08537747504795805
Validation loss: 2.449582460537934

Epoch: 777| Step: 0
Training loss: 0.08293018076781863
Validation loss: 2.429711682446232

Epoch: 5| Step: 1
Training loss: 0.10332209111433287
Validation loss: 2.4196682670910543

Epoch: 5| Step: 2
Training loss: 0.10106983267440299
Validation loss: 2.4471311741545843

Epoch: 5| Step: 3
Training loss: 0.05970003706958972
Validation loss: 2.4268785365898964

Epoch: 5| Step: 4
Training loss: 0.08222843211080454
Validation loss: 2.438665718651563

Epoch: 5| Step: 5
Training loss: 0.07697590718231898
Validation loss: 2.431914545326442

Epoch: 5| Step: 6
Training loss: 0.07459871380714468
Validation loss: 2.4392948258059213

Epoch: 5| Step: 7
Training loss: 0.060628088581786435
Validation loss: 2.437412271953431

Epoch: 5| Step: 8
Training loss: 0.08386200206540963
Validation loss: 2.4608132305760213

Epoch: 5| Step: 9
Training loss: 0.09329117813982685
Validation loss: 2.442486889114682

Epoch: 5| Step: 10
Training loss: 0.15010187990677915
Validation loss: 2.448001587982435

Epoch: 778| Step: 0
Training loss: 0.05281653450193563
Validation loss: 2.442334424327696

Epoch: 5| Step: 1
Training loss: 0.060765339511441994
Validation loss: 2.4304319734891022

Epoch: 5| Step: 2
Training loss: 0.08647027998371319
Validation loss: 2.4382333990513416

Epoch: 5| Step: 3
Training loss: 0.08625581969187764
Validation loss: 2.4203006376094955

Epoch: 5| Step: 4
Training loss: 0.07978487108102587
Validation loss: 2.429189226205504

Epoch: 5| Step: 5
Training loss: 0.10425269230446664
Validation loss: 2.4407920566891677

Epoch: 5| Step: 6
Training loss: 0.08476573069517516
Validation loss: 2.434832265534196

Epoch: 5| Step: 7
Training loss: 0.09919196446875024
Validation loss: 2.4381705183026736

Epoch: 5| Step: 8
Training loss: 0.08355890666444231
Validation loss: 2.434784516996941

Epoch: 5| Step: 9
Training loss: 0.11492303233079329
Validation loss: 2.4408822669391537

Epoch: 5| Step: 10
Training loss: 0.0653711277540225
Validation loss: 2.4575982271336914

Epoch: 779| Step: 0
Training loss: 0.07641326728729175
Validation loss: 2.4468224322060808

Epoch: 5| Step: 1
Training loss: 0.15358628449870632
Validation loss: 2.4640274351133744

Epoch: 5| Step: 2
Training loss: 0.08979323252281013
Validation loss: 2.441882768096302

Epoch: 5| Step: 3
Training loss: 0.07156841205763322
Validation loss: 2.4316829214656464

Epoch: 5| Step: 4
Training loss: 0.09923432839863577
Validation loss: 2.4476138540073635

Epoch: 5| Step: 5
Training loss: 0.04738445398643234
Validation loss: 2.443471261043978

Epoch: 5| Step: 6
Training loss: 0.08364433936977704
Validation loss: 2.4319689960592523

Epoch: 5| Step: 7
Training loss: 0.07804959353541815
Validation loss: 2.406607327393834

Epoch: 5| Step: 8
Training loss: 0.07302549732748037
Validation loss: 2.4143656007963163

Epoch: 5| Step: 9
Training loss: 0.05911209586801522
Validation loss: 2.4201000090819305

Epoch: 5| Step: 10
Training loss: 0.08481860570673959
Validation loss: 2.400867367121962

Epoch: 780| Step: 0
Training loss: 0.0943502393586959
Validation loss: 2.4338709854499134

Epoch: 5| Step: 1
Training loss: 0.082278461002823
Validation loss: 2.400174571852786

Epoch: 5| Step: 2
Training loss: 0.051491994952346964
Validation loss: 2.4073514065023756

Epoch: 5| Step: 3
Training loss: 0.08445236756217128
Validation loss: 2.406046976666609

Epoch: 5| Step: 4
Training loss: 0.08796545922423886
Validation loss: 2.4224351122111845

Epoch: 5| Step: 5
Training loss: 0.12219624699018872
Validation loss: 2.394588482689405

Epoch: 5| Step: 6
Training loss: 0.07579976671656037
Validation loss: 2.412915640847256

Epoch: 5| Step: 7
Training loss: 0.08532137162241316
Validation loss: 2.4223478027104277

Epoch: 5| Step: 8
Training loss: 0.08826727429468222
Validation loss: 2.402078419167618

Epoch: 5| Step: 9
Training loss: 0.06043953378893569
Validation loss: 2.407083151636324

Epoch: 5| Step: 10
Training loss: 0.11018739574517236
Validation loss: 2.414140042628227

Epoch: 781| Step: 0
Training loss: 0.055593636365622125
Validation loss: 2.405878651771445

Epoch: 5| Step: 1
Training loss: 0.05778050310468121
Validation loss: 2.427025561697219

Epoch: 5| Step: 2
Training loss: 0.10982002254354725
Validation loss: 2.4372899680444826

Epoch: 5| Step: 3
Training loss: 0.06469309811394956
Validation loss: 2.417409000132378

Epoch: 5| Step: 4
Training loss: 0.08403053789273292
Validation loss: 2.441864679951909

Epoch: 5| Step: 5
Training loss: 0.08863929725653139
Validation loss: 2.445754854266997

Epoch: 5| Step: 6
Training loss: 0.07833350491420406
Validation loss: 2.4628071053521086

Epoch: 5| Step: 7
Training loss: 0.07886794111639028
Validation loss: 2.444057793357218

Epoch: 5| Step: 8
Training loss: 0.07606791162850024
Validation loss: 2.4553336040432336

Epoch: 5| Step: 9
Training loss: 0.10466518075215626
Validation loss: 2.465785686030898

Epoch: 5| Step: 10
Training loss: 0.06693389875811677
Validation loss: 2.4701685435304075

Epoch: 782| Step: 0
Training loss: 0.08496352991994094
Validation loss: 2.447910378124474

Epoch: 5| Step: 1
Training loss: 0.08151064877532883
Validation loss: 2.440008113079512

Epoch: 5| Step: 2
Training loss: 0.09192404156624331
Validation loss: 2.427276263191007

Epoch: 5| Step: 3
Training loss: 0.14347205086668396
Validation loss: 2.4441351830882043

Epoch: 5| Step: 4
Training loss: 0.06423480816363109
Validation loss: 2.464930786719973

Epoch: 5| Step: 5
Training loss: 0.11061876574423021
Validation loss: 2.42301050216298

Epoch: 5| Step: 6
Training loss: 0.06364272084965725
Validation loss: 2.431593170144443

Epoch: 5| Step: 7
Training loss: 0.07458909081046308
Validation loss: 2.448685386112749

Epoch: 5| Step: 8
Training loss: 0.09661683534514985
Validation loss: 2.3815322467978106

Epoch: 5| Step: 9
Training loss: 0.07726817556902225
Validation loss: 2.4066005350781605

Epoch: 5| Step: 10
Training loss: 0.11992704647481901
Validation loss: 2.4212374321347756

Epoch: 783| Step: 0
Training loss: 0.09488778306639682
Validation loss: 2.4092922361562183

Epoch: 5| Step: 1
Training loss: 0.12525000753659665
Validation loss: 2.4570567836954496

Epoch: 5| Step: 2
Training loss: 0.10563903325296045
Validation loss: 2.4581547007064555

Epoch: 5| Step: 3
Training loss: 0.10724263843728639
Validation loss: 2.4727295275969294

Epoch: 5| Step: 4
Training loss: 0.09237511604783147
Validation loss: 2.4617210337534794

Epoch: 5| Step: 5
Training loss: 0.0899894093368555
Validation loss: 2.476598377381327

Epoch: 5| Step: 6
Training loss: 0.1373215601227917
Validation loss: 2.46719257850615

Epoch: 5| Step: 7
Training loss: 0.11623342681105217
Validation loss: 2.476331120381394

Epoch: 5| Step: 8
Training loss: 0.1433884508026919
Validation loss: 2.4876375008758633

Epoch: 5| Step: 9
Training loss: 0.06905182534786003
Validation loss: 2.4262520911750034

Epoch: 5| Step: 10
Training loss: 0.12377099756109984
Validation loss: 2.471062737508009

Epoch: 784| Step: 0
Training loss: 0.11652416203446544
Validation loss: 2.4555928587599256

Epoch: 5| Step: 1
Training loss: 0.09831483971963674
Validation loss: 2.442922930692113

Epoch: 5| Step: 2
Training loss: 0.06651851686813869
Validation loss: 2.4558896147283424

Epoch: 5| Step: 3
Training loss: 0.06729966368498205
Validation loss: 2.442126059462461

Epoch: 5| Step: 4
Training loss: 0.1098562874157346
Validation loss: 2.4739727592803264

Epoch: 5| Step: 5
Training loss: 0.10614218992295128
Validation loss: 2.4746164838701716

Epoch: 5| Step: 6
Training loss: 0.13388367947857946
Validation loss: 2.4512884919156734

Epoch: 5| Step: 7
Training loss: 0.09305280984389025
Validation loss: 2.4614281970699614

Epoch: 5| Step: 8
Training loss: 0.10669888906412237
Validation loss: 2.4621578213888387

Epoch: 5| Step: 9
Training loss: 0.11565460344831346
Validation loss: 2.4635450542688293

Epoch: 5| Step: 10
Training loss: 0.19175054763705796
Validation loss: 2.4529505016349558

Epoch: 785| Step: 0
Training loss: 0.1261387232284237
Validation loss: 2.419761858409431

Epoch: 5| Step: 1
Training loss: 0.12498181180952182
Validation loss: 2.4062388605894203

Epoch: 5| Step: 2
Training loss: 0.09455819750759656
Validation loss: 2.364679344808016

Epoch: 5| Step: 3
Training loss: 0.0938717429126839
Validation loss: 2.382301713437225

Epoch: 5| Step: 4
Training loss: 0.12895222768699016
Validation loss: 2.3755970697143747

Epoch: 5| Step: 5
Training loss: 0.11627585337012389
Validation loss: 2.4132797395718466

Epoch: 5| Step: 6
Training loss: 0.13398151060996263
Validation loss: 2.3894172999644008

Epoch: 5| Step: 7
Training loss: 0.04055192500659298
Validation loss: 2.392562818614291

Epoch: 5| Step: 8
Training loss: 0.11769471866927574
Validation loss: 2.4082287101390167

Epoch: 5| Step: 9
Training loss: 0.08055127030580218
Validation loss: 2.4015421076356414

Epoch: 5| Step: 10
Training loss: 0.13064087232865837
Validation loss: 2.4102508924688717

Epoch: 786| Step: 0
Training loss: 0.15160826282197468
Validation loss: 2.39346008532882

Epoch: 5| Step: 1
Training loss: 0.11426143966525437
Validation loss: 2.380787129021785

Epoch: 5| Step: 2
Training loss: 0.09523614009476321
Validation loss: 2.398997372515541

Epoch: 5| Step: 3
Training loss: 0.14634308040505625
Validation loss: 2.397540053732646

Epoch: 5| Step: 4
Training loss: 0.09957471412785979
Validation loss: 2.3712177945934374

Epoch: 5| Step: 5
Training loss: 0.12089033115060846
Validation loss: 2.391245800583454

Epoch: 5| Step: 6
Training loss: 0.1236121386377112
Validation loss: 2.4039329012796804

Epoch: 5| Step: 7
Training loss: 0.11224044952884416
Validation loss: 2.380028082892691

Epoch: 5| Step: 8
Training loss: 0.10494204416796436
Validation loss: 2.384837700467824

Epoch: 5| Step: 9
Training loss: 0.12224253521768194
Validation loss: 2.414687272326034

Epoch: 5| Step: 10
Training loss: 0.07927996626635227
Validation loss: 2.442848930053293

Epoch: 787| Step: 0
Training loss: 0.12081527222147978
Validation loss: 2.4279419529229807

Epoch: 5| Step: 1
Training loss: 0.11861684841255021
Validation loss: 2.458024664831867

Epoch: 5| Step: 2
Training loss: 0.09773904151966895
Validation loss: 2.453909646125938

Epoch: 5| Step: 3
Training loss: 0.09120367008965864
Validation loss: 2.453314669416805

Epoch: 5| Step: 4
Training loss: 0.16430266717014452
Validation loss: 2.4454261553916123

Epoch: 5| Step: 5
Training loss: 0.1180081639541903
Validation loss: 2.449124106049671

Epoch: 5| Step: 6
Training loss: 0.11730080531121101
Validation loss: 2.4184318357600394

Epoch: 5| Step: 7
Training loss: 0.11263055378708386
Validation loss: 2.4166781185106534

Epoch: 5| Step: 8
Training loss: 0.07481082861171816
Validation loss: 2.3844704946381374

Epoch: 5| Step: 9
Training loss: 0.09077086692136298
Validation loss: 2.3592188321053924

Epoch: 5| Step: 10
Training loss: 0.12681897484948035
Validation loss: 2.3726177357412013

Epoch: 788| Step: 0
Training loss: 0.1344058029222359
Validation loss: 2.332029167893454

Epoch: 5| Step: 1
Training loss: 0.10153745379094085
Validation loss: 2.3794334268392405

Epoch: 5| Step: 2
Training loss: 0.10813443365315663
Validation loss: 2.4126557859397524

Epoch: 5| Step: 3
Training loss: 0.09139805251638046
Validation loss: 2.3991661139491725

Epoch: 5| Step: 4
Training loss: 0.09507434945614933
Validation loss: 2.4026009514739175

Epoch: 5| Step: 5
Training loss: 0.09121676024122218
Validation loss: 2.4264780416731164

Epoch: 5| Step: 6
Training loss: 0.13735554080342113
Validation loss: 2.406488488530698

Epoch: 5| Step: 7
Training loss: 0.09227676959001059
Validation loss: 2.4285462356088625

Epoch: 5| Step: 8
Training loss: 0.0832836560604942
Validation loss: 2.4206522670354644

Epoch: 5| Step: 9
Training loss: 0.0846414670860072
Validation loss: 2.439063650549821

Epoch: 5| Step: 10
Training loss: 0.09011016094889622
Validation loss: 2.4212592266686945

Epoch: 789| Step: 0
Training loss: 0.10370544807001263
Validation loss: 2.443298554178469

Epoch: 5| Step: 1
Training loss: 0.08254340351313923
Validation loss: 2.3896527426858345

Epoch: 5| Step: 2
Training loss: 0.12478936598312243
Validation loss: 2.3950364558972344

Epoch: 5| Step: 3
Training loss: 0.0835395387646484
Validation loss: 2.4127426492573107

Epoch: 5| Step: 4
Training loss: 0.12257380220195392
Validation loss: 2.4132411823501165

Epoch: 5| Step: 5
Training loss: 0.0638577533018522
Validation loss: 2.3989684060550567

Epoch: 5| Step: 6
Training loss: 0.05147043103719496
Validation loss: 2.376547039159923

Epoch: 5| Step: 7
Training loss: 0.10796178471639785
Validation loss: 2.394919240774546

Epoch: 5| Step: 8
Training loss: 0.11669771041853026
Validation loss: 2.3574359833327576

Epoch: 5| Step: 9
Training loss: 0.07853710440624542
Validation loss: 2.3788553162381167

Epoch: 5| Step: 10
Training loss: 0.11717180703310351
Validation loss: 2.38779032639148

Epoch: 790| Step: 0
Training loss: 0.06821507823824931
Validation loss: 2.3939817881145418

Epoch: 5| Step: 1
Training loss: 0.13070554374194285
Validation loss: 2.4170543061319396

Epoch: 5| Step: 2
Training loss: 0.0935808682691691
Validation loss: 2.3819314716799473

Epoch: 5| Step: 3
Training loss: 0.1068800221554283
Validation loss: 2.3959511690913433

Epoch: 5| Step: 4
Training loss: 0.10183219223100462
Validation loss: 2.422745370751272

Epoch: 5| Step: 5
Training loss: 0.09034037164898484
Validation loss: 2.4114082948014026

Epoch: 5| Step: 6
Training loss: 0.08247412047186041
Validation loss: 2.4376648962020844

Epoch: 5| Step: 7
Training loss: 0.11139464482430297
Validation loss: 2.4128856653100716

Epoch: 5| Step: 8
Training loss: 0.07085635536304119
Validation loss: 2.4037740642506904

Epoch: 5| Step: 9
Training loss: 0.11286538346779618
Validation loss: 2.4414949265649515

Epoch: 5| Step: 10
Training loss: 0.06161116597143225
Validation loss: 2.4515578980460413

Epoch: 791| Step: 0
Training loss: 0.09491814578544666
Validation loss: 2.41976009652699

Epoch: 5| Step: 1
Training loss: 0.13362938338772198
Validation loss: 2.4297731952414403

Epoch: 5| Step: 2
Training loss: 0.12124204399979896
Validation loss: 2.4426915771894806

Epoch: 5| Step: 3
Training loss: 0.10011186266315315
Validation loss: 2.4394172640796437

Epoch: 5| Step: 4
Training loss: 0.11453056791266368
Validation loss: 2.4729035912856148

Epoch: 5| Step: 5
Training loss: 0.09054724856144072
Validation loss: 2.4260398173821933

Epoch: 5| Step: 6
Training loss: 0.09539050990292215
Validation loss: 2.445978554059966

Epoch: 5| Step: 7
Training loss: 0.07572447995244674
Validation loss: 2.4400408059992587

Epoch: 5| Step: 8
Training loss: 0.09733964141392365
Validation loss: 2.42220524055695

Epoch: 5| Step: 9
Training loss: 0.11560825535953473
Validation loss: 2.428556606600889

Epoch: 5| Step: 10
Training loss: 0.14465509727448914
Validation loss: 2.431632508051306

Epoch: 792| Step: 0
Training loss: 0.04131889902356165
Validation loss: 2.4215053925992978

Epoch: 5| Step: 1
Training loss: 0.1149859498475074
Validation loss: 2.4161824564130874

Epoch: 5| Step: 2
Training loss: 0.09206735047021253
Validation loss: 2.438040853444986

Epoch: 5| Step: 3
Training loss: 0.10863128346228179
Validation loss: 2.416088847402514

Epoch: 5| Step: 4
Training loss: 0.06984168947837205
Validation loss: 2.4063448413812982

Epoch: 5| Step: 5
Training loss: 0.08326994514138782
Validation loss: 2.4102537674876205

Epoch: 5| Step: 6
Training loss: 0.07029394726232481
Validation loss: 2.3911017947051616

Epoch: 5| Step: 7
Training loss: 0.13122196636087302
Validation loss: 2.3994984211169608

Epoch: 5| Step: 8
Training loss: 0.08944098231929079
Validation loss: 2.3940713132220846

Epoch: 5| Step: 9
Training loss: 0.06333986014155088
Validation loss: 2.409393774432166

Epoch: 5| Step: 10
Training loss: 0.09268966205059816
Validation loss: 2.3994950524276852

Epoch: 793| Step: 0
Training loss: 0.08918687935969424
Validation loss: 2.3642622257275225

Epoch: 5| Step: 1
Training loss: 0.09690782813700383
Validation loss: 2.407269675572984

Epoch: 5| Step: 2
Training loss: 0.11925395671959996
Validation loss: 2.407328985537516

Epoch: 5| Step: 3
Training loss: 0.11786911148136416
Validation loss: 2.4038474398436787

Epoch: 5| Step: 4
Training loss: 0.11417875244509468
Validation loss: 2.384174325050134

Epoch: 5| Step: 5
Training loss: 0.08579227520403955
Validation loss: 2.412246772593054

Epoch: 5| Step: 6
Training loss: 0.07816707550944553
Validation loss: 2.4046603895716725

Epoch: 5| Step: 7
Training loss: 0.08318770773970605
Validation loss: 2.3894427579457025

Epoch: 5| Step: 8
Training loss: 0.07074551892032566
Validation loss: 2.4156824815808235

Epoch: 5| Step: 9
Training loss: 0.07659015375057958
Validation loss: 2.3998610452022353

Epoch: 5| Step: 10
Training loss: 0.10728438855765834
Validation loss: 2.4158151977360016

Epoch: 794| Step: 0
Training loss: 0.07646778595526756
Validation loss: 2.438598185593005

Epoch: 5| Step: 1
Training loss: 0.10918148411209196
Validation loss: 2.419705104596413

Epoch: 5| Step: 2
Training loss: 0.07585619042702145
Validation loss: 2.4057201819143335

Epoch: 5| Step: 3
Training loss: 0.06809728652599027
Validation loss: 2.437817852834862

Epoch: 5| Step: 4
Training loss: 0.0718631426214826
Validation loss: 2.4187264576992225

Epoch: 5| Step: 5
Training loss: 0.0977968348429741
Validation loss: 2.408961135276276

Epoch: 5| Step: 6
Training loss: 0.06873569448062647
Validation loss: 2.4208987387748095

Epoch: 5| Step: 7
Training loss: 0.12644074552842383
Validation loss: 2.4296953037425353

Epoch: 5| Step: 8
Training loss: 0.14270257743889952
Validation loss: 2.3986460453538037

Epoch: 5| Step: 9
Training loss: 0.06929031402295484
Validation loss: 2.4034489294904753

Epoch: 5| Step: 10
Training loss: 0.10676589427162045
Validation loss: 2.3873846908983127

Epoch: 795| Step: 0
Training loss: 0.10664889789113338
Validation loss: 2.364383177484833

Epoch: 5| Step: 1
Training loss: 0.08440053760861016
Validation loss: 2.3863690764960874

Epoch: 5| Step: 2
Training loss: 0.09940582870830639
Validation loss: 2.3897846827323526

Epoch: 5| Step: 3
Training loss: 0.10748215631223876
Validation loss: 2.373974749906985

Epoch: 5| Step: 4
Training loss: 0.07197787694228709
Validation loss: 2.3646700244483547

Epoch: 5| Step: 5
Training loss: 0.0823878925560547
Validation loss: 2.368993330749411

Epoch: 5| Step: 6
Training loss: 0.10704914799589056
Validation loss: 2.3523770974620626

Epoch: 5| Step: 7
Training loss: 0.05856601137979587
Validation loss: 2.3959032395388844

Epoch: 5| Step: 8
Training loss: 0.09071196995141781
Validation loss: 2.386233207797269

Epoch: 5| Step: 9
Training loss: 0.062438185492132946
Validation loss: 2.389023136577666

Epoch: 5| Step: 10
Training loss: 0.08837890098108096
Validation loss: 2.4065701559753463

Epoch: 796| Step: 0
Training loss: 0.09819155842681673
Validation loss: 2.400490988585813

Epoch: 5| Step: 1
Training loss: 0.06682313115818171
Validation loss: 2.406086416854153

Epoch: 5| Step: 2
Training loss: 0.07453892062559221
Validation loss: 2.4002276604016126

Epoch: 5| Step: 3
Training loss: 0.06861374055951386
Validation loss: 2.3979105711117397

Epoch: 5| Step: 4
Training loss: 0.09703333551435414
Validation loss: 2.4292795723627334

Epoch: 5| Step: 5
Training loss: 0.07405689748969047
Validation loss: 2.389685191715121

Epoch: 5| Step: 6
Training loss: 0.0780544349752997
Validation loss: 2.3924822755172634

Epoch: 5| Step: 7
Training loss: 0.12565903975836754
Validation loss: 2.4292492441752573

Epoch: 5| Step: 8
Training loss: 0.07547884903146986
Validation loss: 2.394938211744606

Epoch: 5| Step: 9
Training loss: 0.11871234726641437
Validation loss: 2.376557059954413

Epoch: 5| Step: 10
Training loss: 0.05740805430398356
Validation loss: 2.408334040252256

Epoch: 797| Step: 0
Training loss: 0.06774244534286475
Validation loss: 2.420725009236967

Epoch: 5| Step: 1
Training loss: 0.1107816837662785
Validation loss: 2.423338004597746

Epoch: 5| Step: 2
Training loss: 0.0993153824279887
Validation loss: 2.429683243594441

Epoch: 5| Step: 3
Training loss: 0.09202614519925682
Validation loss: 2.4373957220152795

Epoch: 5| Step: 4
Training loss: 0.07295666992352107
Validation loss: 2.4097420622465444

Epoch: 5| Step: 5
Training loss: 0.09181082396344027
Validation loss: 2.4116923931946617

Epoch: 5| Step: 6
Training loss: 0.13399827568079925
Validation loss: 2.4076640993724423

Epoch: 5| Step: 7
Training loss: 0.09813161072208867
Validation loss: 2.425385199872204

Epoch: 5| Step: 8
Training loss: 0.08701043465177351
Validation loss: 2.4204997878990504

Epoch: 5| Step: 9
Training loss: 0.08508608906884511
Validation loss: 2.4243058310032923

Epoch: 5| Step: 10
Training loss: 0.10313262802869251
Validation loss: 2.3731351389612416

Epoch: 798| Step: 0
Training loss: 0.08189265145515046
Validation loss: 2.411777293895129

Epoch: 5| Step: 1
Training loss: 0.0687543053525216
Validation loss: 2.3925207906436814

Epoch: 5| Step: 2
Training loss: 0.09717354207373144
Validation loss: 2.426131165788004

Epoch: 5| Step: 3
Training loss: 0.07234705062138176
Validation loss: 2.410577820644321

Epoch: 5| Step: 4
Training loss: 0.10934057289946963
Validation loss: 2.4467353915186365

Epoch: 5| Step: 5
Training loss: 0.07571157122913505
Validation loss: 2.4380969159897314

Epoch: 5| Step: 6
Training loss: 0.057293152473791305
Validation loss: 2.4156467490624722

Epoch: 5| Step: 7
Training loss: 0.0693672203629282
Validation loss: 2.4474636275677413

Epoch: 5| Step: 8
Training loss: 0.1077195767411593
Validation loss: 2.4572627818311448

Epoch: 5| Step: 9
Training loss: 0.08613908759979651
Validation loss: 2.4433435190177053

Epoch: 5| Step: 10
Training loss: 0.09275943750856731
Validation loss: 2.4597552976916

Epoch: 799| Step: 0
Training loss: 0.07698981359335809
Validation loss: 2.4403220075397565

Epoch: 5| Step: 1
Training loss: 0.1092249232363502
Validation loss: 2.4390811837440185

Epoch: 5| Step: 2
Training loss: 0.054052687509683554
Validation loss: 2.4410304154076012

Epoch: 5| Step: 3
Training loss: 0.06946288160444437
Validation loss: 2.413987510571225

Epoch: 5| Step: 4
Training loss: 0.12278601075620443
Validation loss: 2.421204464670621

Epoch: 5| Step: 5
Training loss: 0.08435812390620841
Validation loss: 2.4053642721403734

Epoch: 5| Step: 6
Training loss: 0.06941261551357236
Validation loss: 2.3900328504738626

Epoch: 5| Step: 7
Training loss: 0.06352462049716746
Validation loss: 2.394821793612933

Epoch: 5| Step: 8
Training loss: 0.10359533407976568
Validation loss: 2.3980831669996236

Epoch: 5| Step: 9
Training loss: 0.08487551055605061
Validation loss: 2.395038825755758

Epoch: 5| Step: 10
Training loss: 0.07855763746609667
Validation loss: 2.3863735831176394

Epoch: 800| Step: 0
Training loss: 0.09134173174412101
Validation loss: 2.4306858938011784

Epoch: 5| Step: 1
Training loss: 0.061907534300265056
Validation loss: 2.3949865063552145

Epoch: 5| Step: 2
Training loss: 0.09905634489402099
Validation loss: 2.4127965705411487

Epoch: 5| Step: 3
Training loss: 0.056244544337531566
Validation loss: 2.411994903267451

Epoch: 5| Step: 4
Training loss: 0.10460810159131807
Validation loss: 2.4218029423002854

Epoch: 5| Step: 5
Training loss: 0.07871472583864335
Validation loss: 2.4158965896920592

Epoch: 5| Step: 6
Training loss: 0.0769500233175194
Validation loss: 2.4425974643468336

Epoch: 5| Step: 7
Training loss: 0.06608942128158092
Validation loss: 2.4136241760883843

Epoch: 5| Step: 8
Training loss: 0.06946202352007538
Validation loss: 2.394560828994227

Epoch: 5| Step: 9
Training loss: 0.07693665141750171
Validation loss: 2.396299320789029

Epoch: 5| Step: 10
Training loss: 0.1151471413965757
Validation loss: 2.400660578125473

Testing loss: 2.4234639687550974
