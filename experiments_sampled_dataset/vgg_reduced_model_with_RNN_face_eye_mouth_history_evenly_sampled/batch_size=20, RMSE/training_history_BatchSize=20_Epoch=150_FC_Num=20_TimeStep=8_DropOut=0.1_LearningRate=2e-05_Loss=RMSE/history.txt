Epoch: 1| Step: 0
Training loss: 4.957884802953811
Validation loss: 5.7711794921052295

Epoch: 5| Step: 1
Training loss: 5.059817133075662
Validation loss: 5.754704292069744

Epoch: 5| Step: 2
Training loss: 6.082862870649395
Validation loss: 5.739930819305719

Epoch: 5| Step: 3
Training loss: 6.228324229283357
Validation loss: 5.723718615121696

Epoch: 5| Step: 4
Training loss: 6.669344205401829
Validation loss: 5.70539409624686

Epoch: 5| Step: 5
Training loss: 6.611811628368824
Validation loss: 5.68520747420329

Epoch: 5| Step: 6
Training loss: 4.8479432690388755
Validation loss: 5.662670939320392

Epoch: 5| Step: 7
Training loss: 5.437656268801094
Validation loss: 5.637324194384582

Epoch: 5| Step: 8
Training loss: 6.133990482010747
Validation loss: 5.609084746895313

Epoch: 5| Step: 9
Training loss: 4.990969322714119
Validation loss: 5.577743844937627

Epoch: 5| Step: 10
Training loss: 5.345048713140939
Validation loss: 5.543000429526819

Epoch: 2| Step: 0
Training loss: 5.981649310934561
Validation loss: 5.505091643751107

Epoch: 5| Step: 1
Training loss: 5.451345596087575
Validation loss: 5.4643414209983785

Epoch: 5| Step: 2
Training loss: 4.526145006177261
Validation loss: 5.419882674241288

Epoch: 5| Step: 3
Training loss: 5.204409329101983
Validation loss: 5.374740716433011

Epoch: 5| Step: 4
Training loss: 5.8786411770598015
Validation loss: 5.328289107041001

Epoch: 5| Step: 5
Training loss: 4.283375901383024
Validation loss: 5.279352217874524

Epoch: 5| Step: 6
Training loss: 5.616219342961237
Validation loss: 5.23074078404818

Epoch: 5| Step: 7
Training loss: 5.41671621837937
Validation loss: 5.180934744147641

Epoch: 5| Step: 8
Training loss: 5.646777234817081
Validation loss: 5.129598046080317

Epoch: 5| Step: 9
Training loss: 5.488955940235153
Validation loss: 5.080303959116808

Epoch: 5| Step: 10
Training loss: 4.7841508829059896
Validation loss: 5.032220321799811

Epoch: 3| Step: 0
Training loss: 5.409146806210992
Validation loss: 4.986824149114447

Epoch: 5| Step: 1
Training loss: 4.340319040059939
Validation loss: 4.940737639843417

Epoch: 5| Step: 2
Training loss: 4.892849644723821
Validation loss: 4.895559669374246

Epoch: 5| Step: 3
Training loss: 4.186401223030983
Validation loss: 4.856977292426852

Epoch: 5| Step: 4
Training loss: 4.818478920284347
Validation loss: 4.824454319598597

Epoch: 5| Step: 5
Training loss: 5.7475720130686625
Validation loss: 4.794740353225906

Epoch: 5| Step: 6
Training loss: 4.449853598940302
Validation loss: 4.768737047978024

Epoch: 5| Step: 7
Training loss: 4.284146185509822
Validation loss: 4.746504271791731

Epoch: 5| Step: 8
Training loss: 4.992254552256562
Validation loss: 4.727118892222557

Epoch: 5| Step: 9
Training loss: 5.409959171162254
Validation loss: 4.709378386326158

Epoch: 5| Step: 10
Training loss: 5.091076857415849
Validation loss: 4.691688859075794

Epoch: 4| Step: 0
Training loss: 4.8031465866209375
Validation loss: 4.6722238138601195

Epoch: 5| Step: 1
Training loss: 3.898494009093823
Validation loss: 4.65134069984863

Epoch: 5| Step: 2
Training loss: 5.683240699945378
Validation loss: 4.63159346481327

Epoch: 5| Step: 3
Training loss: 4.232750838046391
Validation loss: 4.611824205035276

Epoch: 5| Step: 4
Training loss: 4.314644542918719
Validation loss: 4.594438553851259

Epoch: 5| Step: 5
Training loss: 4.944956496985598
Validation loss: 4.5737782094526

Epoch: 5| Step: 6
Training loss: 5.067603658736643
Validation loss: 4.54574900969139

Epoch: 5| Step: 7
Training loss: 4.243232949491161
Validation loss: 4.526089765289191

Epoch: 5| Step: 8
Training loss: 4.70174390215328
Validation loss: 4.483092852039946

Epoch: 5| Step: 9
Training loss: 4.769681211171369
Validation loss: 4.475449097881119

Epoch: 5| Step: 10
Training loss: 4.386947449236573
Validation loss: 4.465880809784518

Epoch: 5| Step: 0
Training loss: 4.694487792848867
Validation loss: 4.452246285689963

Epoch: 5| Step: 1
Training loss: 4.019640625409974
Validation loss: 4.431389589814424

Epoch: 5| Step: 2
Training loss: 4.287502873811787
Validation loss: 4.414696894794924

Epoch: 5| Step: 3
Training loss: 4.098030938690298
Validation loss: 4.41102735933894

Epoch: 5| Step: 4
Training loss: 4.784573067141357
Validation loss: 4.396159264318777

Epoch: 5| Step: 5
Training loss: 3.467032754959549
Validation loss: 4.3818148518564195

Epoch: 5| Step: 6
Training loss: 5.430200697981736
Validation loss: 4.377112415094094

Epoch: 5| Step: 7
Training loss: 4.843969327821653
Validation loss: 4.36970774887667

Epoch: 5| Step: 8
Training loss: 4.316712464392798
Validation loss: 4.358472733297729

Epoch: 5| Step: 9
Training loss: 4.802339603539571
Validation loss: 4.346925486160453

Epoch: 5| Step: 10
Training loss: 4.498631587185882
Validation loss: 4.328936271470772

Epoch: 6| Step: 0
Training loss: 4.845522254849441
Validation loss: 4.313858657591282

Epoch: 5| Step: 1
Training loss: 4.248098958014053
Validation loss: 4.296003102789506

Epoch: 5| Step: 2
Training loss: 4.766720305098781
Validation loss: 4.280860228640642

Epoch: 5| Step: 3
Training loss: 4.474028131238807
Validation loss: 4.281894059041362

Epoch: 5| Step: 4
Training loss: 3.5875090436123624
Validation loss: 4.252774990859596

Epoch: 5| Step: 5
Training loss: 4.411031955379257
Validation loss: 4.237002999640009

Epoch: 5| Step: 6
Training loss: 4.198473089682729
Validation loss: 4.222369919701305

Epoch: 5| Step: 7
Training loss: 3.9057734084261404
Validation loss: 4.203861770803007

Epoch: 5| Step: 8
Training loss: 4.290966507670071
Validation loss: 4.189250783912427

Epoch: 5| Step: 9
Training loss: 4.906456815406135
Validation loss: 4.168000595109973

Epoch: 5| Step: 10
Training loss: 4.173630248731313
Validation loss: 4.149255124654895

Epoch: 7| Step: 0
Training loss: 4.3674008448699215
Validation loss: 4.131223090599867

Epoch: 5| Step: 1
Training loss: 4.1966146085831655
Validation loss: 4.112696017780866

Epoch: 5| Step: 2
Training loss: 4.7937029064108305
Validation loss: 4.102893824151648

Epoch: 5| Step: 3
Training loss: 4.398798709219202
Validation loss: 4.080062110061375

Epoch: 5| Step: 4
Training loss: 3.204946307180384
Validation loss: 4.0691240802337

Epoch: 5| Step: 5
Training loss: 3.8381495419978466
Validation loss: 4.055309938234136

Epoch: 5| Step: 6
Training loss: 4.446032206059616
Validation loss: 4.042052467605733

Epoch: 5| Step: 7
Training loss: 4.03090364609495
Validation loss: 4.024469104653837

Epoch: 5| Step: 8
Training loss: 4.125552053790518
Validation loss: 4.008082947146304

Epoch: 5| Step: 9
Training loss: 4.062497887244042
Validation loss: 3.9982787782069407

Epoch: 5| Step: 10
Training loss: 4.606727382813686
Validation loss: 3.98390948933884

Epoch: 8| Step: 0
Training loss: 4.859950580424151
Validation loss: 3.971347743176598

Epoch: 5| Step: 1
Training loss: 4.091199240365254
Validation loss: 3.9576731655374457

Epoch: 5| Step: 2
Training loss: 4.50004365687916
Validation loss: 3.945881805882783

Epoch: 5| Step: 3
Training loss: 4.094920216809022
Validation loss: 3.9319202521779544

Epoch: 5| Step: 4
Training loss: 3.7210504164526212
Validation loss: 3.921843763252456

Epoch: 5| Step: 5
Training loss: 4.465334140282785
Validation loss: 3.9111675104469152

Epoch: 5| Step: 6
Training loss: 3.6253005593761447
Validation loss: 3.9061770353988585

Epoch: 5| Step: 7
Training loss: 4.10726700589217
Validation loss: 3.8893123447922378

Epoch: 5| Step: 8
Training loss: 4.342795287674119
Validation loss: 3.8824063462509892

Epoch: 5| Step: 9
Training loss: 3.4763101207550604
Validation loss: 3.8733202349667737

Epoch: 5| Step: 10
Training loss: 3.129619388534306
Validation loss: 3.8665323086295937

Epoch: 9| Step: 0
Training loss: 3.6855056024533908
Validation loss: 3.854468117287953

Epoch: 5| Step: 1
Training loss: 3.800947101420625
Validation loss: 3.844188471423609

Epoch: 5| Step: 2
Training loss: 3.789130204372565
Validation loss: 3.834280166397965

Epoch: 5| Step: 3
Training loss: 4.661531665871618
Validation loss: 3.8248641637491483

Epoch: 5| Step: 4
Training loss: 4.16957194448007
Validation loss: 3.8195912945143005

Epoch: 5| Step: 5
Training loss: 4.530347010645568
Validation loss: 3.814720178442612

Epoch: 5| Step: 6
Training loss: 3.7369301964434416
Validation loss: 3.8025810011513874

Epoch: 5| Step: 7
Training loss: 3.3093319984646468
Validation loss: 3.792143743810591

Epoch: 5| Step: 8
Training loss: 3.722850942574118
Validation loss: 3.779317419088444

Epoch: 5| Step: 9
Training loss: 4.204630188709075
Validation loss: 3.7809028761080663

Epoch: 5| Step: 10
Training loss: 4.015822825030523
Validation loss: 3.7638776119812825

Epoch: 10| Step: 0
Training loss: 4.456780897192072
Validation loss: 3.7635363365110095

Epoch: 5| Step: 1
Training loss: 3.5148558728987704
Validation loss: 3.75879650080969

Epoch: 5| Step: 2
Training loss: 3.523071540723334
Validation loss: 3.750904022139108

Epoch: 5| Step: 3
Training loss: 3.750777481862237
Validation loss: 3.740172387621006

Epoch: 5| Step: 4
Training loss: 3.4917615933742354
Validation loss: 3.7296130243837267

Epoch: 5| Step: 5
Training loss: 4.081568407896033
Validation loss: 3.7226005783922234

Epoch: 5| Step: 6
Training loss: 3.218464810968254
Validation loss: 3.713695702016499

Epoch: 5| Step: 7
Training loss: 3.9049323949688737
Validation loss: 3.708563323365006

Epoch: 5| Step: 8
Training loss: 4.191629679360581
Validation loss: 3.696764274058711

Epoch: 5| Step: 9
Training loss: 4.275846984123803
Validation loss: 3.689825461071133

Epoch: 5| Step: 10
Training loss: 4.442628717398551
Validation loss: 3.6901465780778326

Epoch: 11| Step: 0
Training loss: 4.044990955243649
Validation loss: 3.686454136585594

Epoch: 5| Step: 1
Training loss: 3.849787243005287
Validation loss: 3.676854137124204

Epoch: 5| Step: 2
Training loss: 4.168875197971243
Validation loss: 3.6659066292570355

Epoch: 5| Step: 3
Training loss: 3.6648234734170475
Validation loss: 3.653001828757028

Epoch: 5| Step: 4
Training loss: 3.384224048745794
Validation loss: 3.653481208388477

Epoch: 5| Step: 5
Training loss: 4.3514397704865315
Validation loss: 3.6535320376381586

Epoch: 5| Step: 6
Training loss: 3.6994458685723557
Validation loss: 3.63868775842954

Epoch: 5| Step: 7
Training loss: 3.9667855755162797
Validation loss: 3.6521909325442654

Epoch: 5| Step: 8
Training loss: 3.790001318334989
Validation loss: 3.6578126563214064

Epoch: 5| Step: 9
Training loss: 3.8748440864944635
Validation loss: 3.6545830393794527

Epoch: 5| Step: 10
Training loss: 3.3641335075457093
Validation loss: 3.6392797021059176

Epoch: 12| Step: 0
Training loss: 3.8044034941965967
Validation loss: 3.633620167357425

Epoch: 5| Step: 1
Training loss: 4.4301835039765844
Validation loss: 3.630486065108195

Epoch: 5| Step: 2
Training loss: 2.746160948624372
Validation loss: 3.6248826972219756

Epoch: 5| Step: 3
Training loss: 4.017931086752921
Validation loss: 3.6152583063551593

Epoch: 5| Step: 4
Training loss: 3.845109776590359
Validation loss: 3.6056525412063407

Epoch: 5| Step: 5
Training loss: 3.8980425250423543
Validation loss: 3.5934227807379715

Epoch: 5| Step: 6
Training loss: 4.385752951201721
Validation loss: 3.587436910975438

Epoch: 5| Step: 7
Training loss: 3.6394676366248335
Validation loss: 3.58061332137875

Epoch: 5| Step: 8
Training loss: 3.3010578829622905
Validation loss: 3.5794501635374427

Epoch: 5| Step: 9
Training loss: 3.340336278102201
Validation loss: 3.577213149491981

Epoch: 5| Step: 10
Training loss: 4.124635622519241
Validation loss: 3.5639027034421753

Epoch: 13| Step: 0
Training loss: 4.096540359110155
Validation loss: 3.5583493387530387

Epoch: 5| Step: 1
Training loss: 3.7921305082775145
Validation loss: 3.554309775950617

Epoch: 5| Step: 2
Training loss: 3.812438338984909
Validation loss: 3.5509512551606517

Epoch: 5| Step: 3
Training loss: 2.961242499030014
Validation loss: 3.550898699056283

Epoch: 5| Step: 4
Training loss: 3.8113734347484827
Validation loss: 3.5554486840497335

Epoch: 5| Step: 5
Training loss: 3.9937080727347927
Validation loss: 3.54097843806185

Epoch: 5| Step: 6
Training loss: 3.6146847200420087
Validation loss: 3.5375286884826607

Epoch: 5| Step: 7
Training loss: 4.298633784225945
Validation loss: 3.5349535543867527

Epoch: 5| Step: 8
Training loss: 3.41825710279209
Validation loss: 3.5294726697119234

Epoch: 5| Step: 9
Training loss: 3.946096572769234
Validation loss: 3.525584538864423

Epoch: 5| Step: 10
Training loss: 3.182487585818163
Validation loss: 3.522066330883751

Epoch: 14| Step: 0
Training loss: 2.9182102660048694
Validation loss: 3.5158904659260872

Epoch: 5| Step: 1
Training loss: 3.6595388113570557
Validation loss: 3.5129253826596885

Epoch: 5| Step: 2
Training loss: 3.2416343125115525
Validation loss: 3.5081111074599076

Epoch: 5| Step: 3
Training loss: 3.7745870099041183
Validation loss: 3.5036194642663134

Epoch: 5| Step: 4
Training loss: 4.03374457246352
Validation loss: 3.4977844289702777

Epoch: 5| Step: 5
Training loss: 4.0309457590196125
Validation loss: 3.4911520289671585

Epoch: 5| Step: 6
Training loss: 4.3497271134294975
Validation loss: 3.487098406856124

Epoch: 5| Step: 7
Training loss: 3.8114622611107003
Validation loss: 3.4842968856610113

Epoch: 5| Step: 8
Training loss: 3.571253012020669
Validation loss: 3.481144071563068

Epoch: 5| Step: 9
Training loss: 3.506909770395485
Validation loss: 3.479276799170872

Epoch: 5| Step: 10
Training loss: 3.687401721743853
Validation loss: 3.4754140928074473

Epoch: 15| Step: 0
Training loss: 3.5449518712143435
Validation loss: 3.472666653209279

Epoch: 5| Step: 1
Training loss: 3.2010491320275447
Validation loss: 3.4682538668905716

Epoch: 5| Step: 2
Training loss: 4.210231969608686
Validation loss: 3.4654520385963203

Epoch: 5| Step: 3
Training loss: 3.5619472944932182
Validation loss: 3.460561662792576

Epoch: 5| Step: 4
Training loss: 2.8338874574227346
Validation loss: 3.4572830270729216

Epoch: 5| Step: 5
Training loss: 4.014621713187931
Validation loss: 3.452611683592841

Epoch: 5| Step: 6
Training loss: 3.4806305476298744
Validation loss: 3.4522102483283086

Epoch: 5| Step: 7
Training loss: 3.814362993166767
Validation loss: 3.4477352496981846

Epoch: 5| Step: 8
Training loss: 3.762266695513675
Validation loss: 3.444418057314065

Epoch: 5| Step: 9
Training loss: 4.106172307177982
Validation loss: 3.4427518995278517

Epoch: 5| Step: 10
Training loss: 3.6734936332226895
Validation loss: 3.439064736222582

Epoch: 16| Step: 0
Training loss: 3.3057715259028
Validation loss: 3.4371292704878096

Epoch: 5| Step: 1
Training loss: 3.9547068932644427
Validation loss: 3.4326224288698532

Epoch: 5| Step: 2
Training loss: 3.9397661257813885
Validation loss: 3.427160952947312

Epoch: 5| Step: 3
Training loss: 3.3351432337164018
Validation loss: 3.4245002787417387

Epoch: 5| Step: 4
Training loss: 3.5098707791530646
Validation loss: 3.419607862903851

Epoch: 5| Step: 5
Training loss: 3.538021246044656
Validation loss: 3.416411055380771

Epoch: 5| Step: 6
Training loss: 3.4504753061805866
Validation loss: 3.4099665349869293

Epoch: 5| Step: 7
Training loss: 3.8329413807937467
Validation loss: 3.408997999375159

Epoch: 5| Step: 8
Training loss: 3.0413784430521473
Validation loss: 3.4049675446349297

Epoch: 5| Step: 9
Training loss: 3.285948087536438
Validation loss: 3.402554139710168

Epoch: 5| Step: 10
Training loss: 4.767090618958313
Validation loss: 3.394600713530725

Epoch: 17| Step: 0
Training loss: 3.4791560068176577
Validation loss: 3.393078141097159

Epoch: 5| Step: 1
Training loss: 3.881168132416131
Validation loss: 3.391799932625497

Epoch: 5| Step: 2
Training loss: 2.9840947364106962
Validation loss: 3.38696034918968

Epoch: 5| Step: 3
Training loss: 3.3332138199043966
Validation loss: 3.381178132107852

Epoch: 5| Step: 4
Training loss: 3.75195935242358
Validation loss: 3.380429285674146

Epoch: 5| Step: 5
Training loss: 3.7534720559737202
Validation loss: 3.3800985851692915

Epoch: 5| Step: 6
Training loss: 3.8020827759346054
Validation loss: 3.3815538987016436

Epoch: 5| Step: 7
Training loss: 4.422468058037868
Validation loss: 3.390142064741825

Epoch: 5| Step: 8
Training loss: 3.180217127075099
Validation loss: 3.3753004285998833

Epoch: 5| Step: 9
Training loss: 3.359175991107551
Validation loss: 3.3889303753449176

Epoch: 5| Step: 10
Training loss: 3.6536432086321575
Validation loss: 3.4025254543950516

Epoch: 18| Step: 0
Training loss: 3.391049547468487
Validation loss: 3.3909478077134225

Epoch: 5| Step: 1
Training loss: 4.190889723094916
Validation loss: 3.375238347116332

Epoch: 5| Step: 2
Training loss: 3.434225291216358
Validation loss: 3.3646251300356864

Epoch: 5| Step: 3
Training loss: 3.7944551770896413
Validation loss: 3.3628812204268907

Epoch: 5| Step: 4
Training loss: 4.163461036973504
Validation loss: 3.378498300060799

Epoch: 5| Step: 5
Training loss: 2.6959792929456903
Validation loss: 3.3624039803643213

Epoch: 5| Step: 6
Training loss: 3.38958161644559
Validation loss: 3.357095756484611

Epoch: 5| Step: 7
Training loss: 3.1874868355273493
Validation loss: 3.3550485524085722

Epoch: 5| Step: 8
Training loss: 4.235950810190957
Validation loss: 3.3545853089795474

Epoch: 5| Step: 9
Training loss: 3.2936922593095495
Validation loss: 3.3531401376803336

Epoch: 5| Step: 10
Training loss: 3.46919563798783
Validation loss: 3.3506880519955513

Epoch: 19| Step: 0
Training loss: 3.29686661127117
Validation loss: 3.3481264176565815

Epoch: 5| Step: 1
Training loss: 3.9500741154924297
Validation loss: 3.346376936857292

Epoch: 5| Step: 2
Training loss: 3.0273802921181656
Validation loss: 3.3449483492685586

Epoch: 5| Step: 3
Training loss: 3.2405336872946116
Validation loss: 3.34237038817477

Epoch: 5| Step: 4
Training loss: 4.199747877273827
Validation loss: 3.3408664141531905

Epoch: 5| Step: 5
Training loss: 4.1393324651985
Validation loss: 3.338033450131555

Epoch: 5| Step: 6
Training loss: 3.7446517953584744
Validation loss: 3.335831603222236

Epoch: 5| Step: 7
Training loss: 3.6145057046929407
Validation loss: 3.33326263557853

Epoch: 5| Step: 8
Training loss: 3.8320073584882133
Validation loss: 3.331944995341669

Epoch: 5| Step: 9
Training loss: 2.6008107241848006
Validation loss: 3.3305515838895583

Epoch: 5| Step: 10
Training loss: 3.322951760101759
Validation loss: 3.3283090894372354

Epoch: 20| Step: 0
Training loss: 3.3176863752962937
Validation loss: 3.32627150348964

Epoch: 5| Step: 1
Training loss: 3.3747345148855
Validation loss: 3.324523215443792

Epoch: 5| Step: 2
Training loss: 3.9712346026656724
Validation loss: 3.322437251921688

Epoch: 5| Step: 3
Training loss: 3.4434529863551617
Validation loss: 3.32077062352572

Epoch: 5| Step: 4
Training loss: 2.9575515752891963
Validation loss: 3.319702577301792

Epoch: 5| Step: 5
Training loss: 3.959369296315939
Validation loss: 3.3182948406661006

Epoch: 5| Step: 6
Training loss: 3.9543586585194217
Validation loss: 3.3162591894037217

Epoch: 5| Step: 7
Training loss: 3.167792638735428
Validation loss: 3.3154870185085787

Epoch: 5| Step: 8
Training loss: 3.164708653158297
Validation loss: 3.313267452333329

Epoch: 5| Step: 9
Training loss: 3.21380368508746
Validation loss: 3.3119593229543827

Epoch: 5| Step: 10
Training loss: 4.480079214894365
Validation loss: 3.3118068722930167

Epoch: 21| Step: 0
Training loss: 3.421190585316335
Validation loss: 3.309417437279249

Epoch: 5| Step: 1
Training loss: 3.664767264643678
Validation loss: 3.309020820535786

Epoch: 5| Step: 2
Training loss: 2.8641883901512735
Validation loss: 3.3075181752526666

Epoch: 5| Step: 3
Training loss: 4.344711965620849
Validation loss: 3.3059698877939887

Epoch: 5| Step: 4
Training loss: 2.7127203012474936
Validation loss: 3.303993697044055

Epoch: 5| Step: 5
Training loss: 3.731580127316313
Validation loss: 3.3037810550478035

Epoch: 5| Step: 6
Training loss: 3.8443477755050677
Validation loss: 3.302569135868002

Epoch: 5| Step: 7
Training loss: 3.899126316901807
Validation loss: 3.3016917268638584

Epoch: 5| Step: 8
Training loss: 3.220003050808616
Validation loss: 3.299529362004285

Epoch: 5| Step: 9
Training loss: 3.698861287135835
Validation loss: 3.2994210698092563

Epoch: 5| Step: 10
Training loss: 3.261303245896391
Validation loss: 3.297675087718977

Epoch: 22| Step: 0
Training loss: 3.4890917683256557
Validation loss: 3.2966986051414353

Epoch: 5| Step: 1
Training loss: 3.5900708812633653
Validation loss: 3.296011687246876

Epoch: 5| Step: 2
Training loss: 2.954778137914811
Validation loss: 3.2949486883289514

Epoch: 5| Step: 3
Training loss: 3.089063543494149
Validation loss: 3.2928378206459077

Epoch: 5| Step: 4
Training loss: 4.076736623101942
Validation loss: 3.2919584705447194

Epoch: 5| Step: 5
Training loss: 3.830620026562649
Validation loss: 3.290774776885988

Epoch: 5| Step: 6
Training loss: 4.336597729153807
Validation loss: 3.28935687821778

Epoch: 5| Step: 7
Training loss: 3.7925523554910385
Validation loss: 3.2876482826522198

Epoch: 5| Step: 8
Training loss: 3.230873903563105
Validation loss: 3.2851666429644064

Epoch: 5| Step: 9
Training loss: 2.545069704131728
Validation loss: 3.2815208764685004

Epoch: 5| Step: 10
Training loss: 3.6006095105344422
Validation loss: 3.281561137974756

Epoch: 23| Step: 0
Training loss: 4.099494921580041
Validation loss: 3.2737090526559522

Epoch: 5| Step: 1
Training loss: 3.679120386566286
Validation loss: 3.268985580387488

Epoch: 5| Step: 2
Training loss: 3.169713378367353
Validation loss: 3.269137758487171

Epoch: 5| Step: 3
Training loss: 3.083033796315115
Validation loss: 3.269051750013426

Epoch: 5| Step: 4
Training loss: 3.545918474322004
Validation loss: 3.264346319531502

Epoch: 5| Step: 5
Training loss: 4.110977614586564
Validation loss: 3.258702341906361

Epoch: 5| Step: 6
Training loss: 3.709992298416411
Validation loss: 3.2579457670445007

Epoch: 5| Step: 7
Training loss: 3.527691288552832
Validation loss: 3.2586731659975943

Epoch: 5| Step: 8
Training loss: 3.097945633945003
Validation loss: 3.260660953301769

Epoch: 5| Step: 9
Training loss: 3.373454976533514
Validation loss: 3.2573841098866154

Epoch: 5| Step: 10
Training loss: 2.984418778822385
Validation loss: 3.252356179197735

Epoch: 24| Step: 0
Training loss: 3.268375826074215
Validation loss: 3.2476622201204064

Epoch: 5| Step: 1
Training loss: 3.7368560593516293
Validation loss: 3.245384265827124

Epoch: 5| Step: 2
Training loss: 3.717833462133645
Validation loss: 3.243228891881926

Epoch: 5| Step: 3
Training loss: 3.3378269106887153
Validation loss: 3.243703741389901

Epoch: 5| Step: 4
Training loss: 2.4996526476832384
Validation loss: 3.243956744233827

Epoch: 5| Step: 5
Training loss: 3.7800505446026746
Validation loss: 3.2435703191546383

Epoch: 5| Step: 6
Training loss: 3.8653836445564482
Validation loss: 3.240561843019146

Epoch: 5| Step: 7
Training loss: 3.2189163609446774
Validation loss: 3.2365345434418624

Epoch: 5| Step: 8
Training loss: 3.4676161278914073
Validation loss: 3.236237318578376

Epoch: 5| Step: 9
Training loss: 3.1021884699712645
Validation loss: 3.233944663374515

Epoch: 5| Step: 10
Training loss: 4.252079174607277
Validation loss: 3.233926669176488

Epoch: 25| Step: 0
Training loss: 3.2115740736748832
Validation loss: 3.231852362439781

Epoch: 5| Step: 1
Training loss: 3.5900395353472705
Validation loss: 3.2332807269783967

Epoch: 5| Step: 2
Training loss: 3.5601357093404316
Validation loss: 3.239599389234711

Epoch: 5| Step: 3
Training loss: 3.78175501958247
Validation loss: 3.2254262982194075

Epoch: 5| Step: 4
Training loss: 4.169176236027994
Validation loss: 3.2268804014019623

Epoch: 5| Step: 5
Training loss: 3.329745618938603
Validation loss: 3.226885457367537

Epoch: 5| Step: 6
Training loss: 2.7715596463692727
Validation loss: 3.225548774030987

Epoch: 5| Step: 7
Training loss: 2.972313920108852
Validation loss: 3.2248401938983133

Epoch: 5| Step: 8
Training loss: 3.953679464303792
Validation loss: 3.223415293967067

Epoch: 5| Step: 9
Training loss: 3.267983055220229
Validation loss: 3.221755511709082

Epoch: 5| Step: 10
Training loss: 3.4611408526954324
Validation loss: 3.2187094243318906

Epoch: 26| Step: 0
Training loss: 3.8811783297151887
Validation loss: 3.21718940053693

Epoch: 5| Step: 1
Training loss: 4.138741003433998
Validation loss: 3.2182767069865914

Epoch: 5| Step: 2
Training loss: 3.7773272130341864
Validation loss: 3.2157188293811325

Epoch: 5| Step: 3
Training loss: 2.8950435375570063
Validation loss: 3.2154541409036437

Epoch: 5| Step: 4
Training loss: 3.108274025304371
Validation loss: 3.213618020600706

Epoch: 5| Step: 5
Training loss: 3.8737558397936556
Validation loss: 3.215066871968908

Epoch: 5| Step: 6
Training loss: 2.4773673786346553
Validation loss: 3.210811420797046

Epoch: 5| Step: 7
Training loss: 3.211978493006853
Validation loss: 3.2081404362831956

Epoch: 5| Step: 8
Training loss: 3.4162878121085076
Validation loss: 3.2103810750534874

Epoch: 5| Step: 9
Training loss: 3.689795216199375
Validation loss: 3.2120405645326184

Epoch: 5| Step: 10
Training loss: 3.336395160808651
Validation loss: 3.206916858102381

Epoch: 27| Step: 0
Training loss: 2.880095403203716
Validation loss: 3.205039756684074

Epoch: 5| Step: 1
Training loss: 3.553771586371041
Validation loss: 3.2043425312204286

Epoch: 5| Step: 2
Training loss: 3.658595449547838
Validation loss: 3.2013803007887542

Epoch: 5| Step: 3
Training loss: 3.0702980565321054
Validation loss: 3.203583364758082

Epoch: 5| Step: 4
Training loss: 3.8572358291764224
Validation loss: 3.201234791922765

Epoch: 5| Step: 5
Training loss: 4.125930681142826
Validation loss: 3.1980341055057395

Epoch: 5| Step: 6
Training loss: 3.629953354464878
Validation loss: 3.2016014831873254

Epoch: 5| Step: 7
Training loss: 3.366301878123197
Validation loss: 3.199272168036919

Epoch: 5| Step: 8
Training loss: 3.253280158103414
Validation loss: 3.1973953300442415

Epoch: 5| Step: 9
Training loss: 3.4886894030008393
Validation loss: 3.1958885986317376

Epoch: 5| Step: 10
Training loss: 2.8703565831918603
Validation loss: 3.193767816993846

Epoch: 28| Step: 0
Training loss: 3.6590760875296175
Validation loss: 3.1948372932074234

Epoch: 5| Step: 1
Training loss: 3.170192779792321
Validation loss: 3.193756540630225

Epoch: 5| Step: 2
Training loss: 3.7882537293255614
Validation loss: 3.1958431907683935

Epoch: 5| Step: 3
Training loss: 3.1739420051684704
Validation loss: 3.195264951370857

Epoch: 5| Step: 4
Training loss: 3.418597179951445
Validation loss: 3.1961186979503573

Epoch: 5| Step: 5
Training loss: 3.41761396038083
Validation loss: 3.197910504570509

Epoch: 5| Step: 6
Training loss: 2.726487472944725
Validation loss: 3.1952825976560004

Epoch: 5| Step: 7
Training loss: 3.858880756561334
Validation loss: 3.1972299340620944

Epoch: 5| Step: 8
Training loss: 3.1948798523282513
Validation loss: 3.1924178662105267

Epoch: 5| Step: 9
Training loss: 3.6615778260066136
Validation loss: 3.1898285774829582

Epoch: 5| Step: 10
Training loss: 3.7330365835053185
Validation loss: 3.190193987400776

Epoch: 29| Step: 0
Training loss: 3.4486256280631826
Validation loss: 3.1870309032929853

Epoch: 5| Step: 1
Training loss: 3.1883035282776535
Validation loss: 3.1895053096336907

Epoch: 5| Step: 2
Training loss: 3.6948998121995653
Validation loss: 3.18627767432323

Epoch: 5| Step: 3
Training loss: 3.41723569147903
Validation loss: 3.181345175937885

Epoch: 5| Step: 4
Training loss: 3.2467373830729755
Validation loss: 3.1839696196600427

Epoch: 5| Step: 5
Training loss: 3.400596196130282
Validation loss: 3.18406831762619

Epoch: 5| Step: 6
Training loss: 3.7934681870994575
Validation loss: 3.1800502523717413

Epoch: 5| Step: 7
Training loss: 3.6085617668549776
Validation loss: 3.1834703808184464

Epoch: 5| Step: 8
Training loss: 3.6942525557270183
Validation loss: 3.1802410945820676

Epoch: 5| Step: 9
Training loss: 3.13552822451084
Validation loss: 3.191174555249976

Epoch: 5| Step: 10
Training loss: 3.0930179539038223
Validation loss: 3.2001773520386143

Epoch: 30| Step: 0
Training loss: 3.4027570261073805
Validation loss: 3.198762851802708

Epoch: 5| Step: 1
Training loss: 3.7475147913258535
Validation loss: 3.1795293216303855

Epoch: 5| Step: 2
Training loss: 2.956417125792585
Validation loss: 3.1785143478717988

Epoch: 5| Step: 3
Training loss: 3.6006295077628927
Validation loss: 3.173174744703111

Epoch: 5| Step: 4
Training loss: 4.166657460520429
Validation loss: 3.175392625474921

Epoch: 5| Step: 5
Training loss: 3.1320171155108696
Validation loss: 3.17669690285343

Epoch: 5| Step: 6
Training loss: 3.3878114338973337
Validation loss: 3.1792653004486944

Epoch: 5| Step: 7
Training loss: 3.411882136376404
Validation loss: 3.1866316122163405

Epoch: 5| Step: 8
Training loss: 3.6057583743200947
Validation loss: 3.1787391456317806

Epoch: 5| Step: 9
Training loss: 2.9621453954233794
Validation loss: 3.173787883746388

Epoch: 5| Step: 10
Training loss: 3.2080182172586214
Validation loss: 3.1698588978392936

Epoch: 31| Step: 0
Training loss: 3.608550270613116
Validation loss: 3.17407910698598

Epoch: 5| Step: 1
Training loss: 4.060507417737585
Validation loss: 3.170575691150001

Epoch: 5| Step: 2
Training loss: 3.3543255849275733
Validation loss: 3.1721914600173102

Epoch: 5| Step: 3
Training loss: 2.5472846140604894
Validation loss: 3.1701209350945407

Epoch: 5| Step: 4
Training loss: 4.060142889655958
Validation loss: 3.1724431137179416

Epoch: 5| Step: 5
Training loss: 4.094988453607734
Validation loss: 3.172156260380468

Epoch: 5| Step: 6
Training loss: 3.2260815721523013
Validation loss: 3.1717370366615025

Epoch: 5| Step: 7
Training loss: 3.576037601802363
Validation loss: 3.172462116861722

Epoch: 5| Step: 8
Training loss: 2.976788689937701
Validation loss: 3.1737483366599233

Epoch: 5| Step: 9
Training loss: 2.918040978126321
Validation loss: 3.1726685743673846

Epoch: 5| Step: 10
Training loss: 2.714657125301993
Validation loss: 3.172593572896686

Epoch: 32| Step: 0
Training loss: 3.2233724642103936
Validation loss: 3.1730443679199305

Epoch: 5| Step: 1
Training loss: 2.789161231593465
Validation loss: 3.170810967344757

Epoch: 5| Step: 2
Training loss: 2.535720644814329
Validation loss: 3.169510821118709

Epoch: 5| Step: 3
Training loss: 3.3635917281017464
Validation loss: 3.1673388566486

Epoch: 5| Step: 4
Training loss: 3.75544889669803
Validation loss: 3.1632543295622773

Epoch: 5| Step: 5
Training loss: 4.216200672882361
Validation loss: 3.164326501484839

Epoch: 5| Step: 6
Training loss: 3.8268051674885397
Validation loss: 3.162613569745799

Epoch: 5| Step: 7
Training loss: 2.9055444004419297
Validation loss: 3.1616124268320873

Epoch: 5| Step: 8
Training loss: 3.8332256357295305
Validation loss: 3.159839359458946

Epoch: 5| Step: 9
Training loss: 3.651241425814645
Validation loss: 3.161079765332761

Epoch: 5| Step: 10
Training loss: 3.0131180378568962
Validation loss: 3.1575782342286036

Epoch: 33| Step: 0
Training loss: 3.1184642347395313
Validation loss: 3.1572955566505274

Epoch: 5| Step: 1
Training loss: 3.412171143276776
Validation loss: 3.1598032733652186

Epoch: 5| Step: 2
Training loss: 3.362303978407201
Validation loss: 3.1584625806236475

Epoch: 5| Step: 3
Training loss: 3.4193655070175013
Validation loss: 3.1561141560034986

Epoch: 5| Step: 4
Training loss: 3.5441260082843633
Validation loss: 3.1550017944484767

Epoch: 5| Step: 5
Training loss: 3.3318878536516685
Validation loss: 3.1524957978859764

Epoch: 5| Step: 6
Training loss: 3.6490700150994164
Validation loss: 3.150848790103802

Epoch: 5| Step: 7
Training loss: 3.6273719656687176
Validation loss: 3.1524797271919547

Epoch: 5| Step: 8
Training loss: 2.5597921811627966
Validation loss: 3.152450157779178

Epoch: 5| Step: 9
Training loss: 3.8506207349667227
Validation loss: 3.1516782663513783

Epoch: 5| Step: 10
Training loss: 3.4862167896263223
Validation loss: 3.1527282925146545

Epoch: 34| Step: 0
Training loss: 3.41372699965862
Validation loss: 3.1504087765278843

Epoch: 5| Step: 1
Training loss: 3.2224011499412324
Validation loss: 3.149658438659599

Epoch: 5| Step: 2
Training loss: 3.323037283849815
Validation loss: 3.148044527560143

Epoch: 5| Step: 3
Training loss: 3.802120149338377
Validation loss: 3.144227778978647

Epoch: 5| Step: 4
Training loss: 3.542297097737243
Validation loss: 3.142065702310347

Epoch: 5| Step: 5
Training loss: 3.164414826545029
Validation loss: 3.1409043818539453

Epoch: 5| Step: 6
Training loss: 3.82541158618402
Validation loss: 3.1391587430117776

Epoch: 5| Step: 7
Training loss: 3.291126319540451
Validation loss: 3.138738573488497

Epoch: 5| Step: 8
Training loss: 3.3608088782193444
Validation loss: 3.1649902053243664

Epoch: 5| Step: 9
Training loss: 3.093975791012841
Validation loss: 3.1358113126196403

Epoch: 5| Step: 10
Training loss: 3.2721606110790566
Validation loss: 3.145474264613662

Epoch: 35| Step: 0
Training loss: 3.6244159096377384
Validation loss: 3.1957023890800627

Epoch: 5| Step: 1
Training loss: 3.8569543328206346
Validation loss: 3.214852727551701

Epoch: 5| Step: 2
Training loss: 4.212071083939836
Validation loss: 3.1557994583101

Epoch: 5| Step: 3
Training loss: 3.4809502847568408
Validation loss: 3.1394367266885728

Epoch: 5| Step: 4
Training loss: 2.9833864502111878
Validation loss: 3.144339849860511

Epoch: 5| Step: 5
Training loss: 2.8007889964317125
Validation loss: 3.161032117009726

Epoch: 5| Step: 6
Training loss: 3.3534307363582516
Validation loss: 3.237158332064989

Epoch: 5| Step: 7
Training loss: 2.636323212519964
Validation loss: 3.1630654499384434

Epoch: 5| Step: 8
Training loss: 3.692872998324
Validation loss: 3.152579529739431

Epoch: 5| Step: 9
Training loss: 3.240609320342371
Validation loss: 3.1383185519322674

Epoch: 5| Step: 10
Training loss: 3.5335905707187085
Validation loss: 3.140524329397079

Epoch: 36| Step: 0
Training loss: 3.3204924411259706
Validation loss: 3.1470732798361554

Epoch: 5| Step: 1
Training loss: 3.280700346913042
Validation loss: 3.155767852530536

Epoch: 5| Step: 2
Training loss: 3.1851311651556213
Validation loss: 3.146147005714044

Epoch: 5| Step: 3
Training loss: 3.3068772584499735
Validation loss: 3.1382712997675015

Epoch: 5| Step: 4
Training loss: 3.1639674042904735
Validation loss: 3.131374479678579

Epoch: 5| Step: 5
Training loss: 3.6579648422462148
Validation loss: 3.1257404934924256

Epoch: 5| Step: 6
Training loss: 3.3210781516115104
Validation loss: 3.1223800045591554

Epoch: 5| Step: 7
Training loss: 3.7538602669367602
Validation loss: 3.1232648433515795

Epoch: 5| Step: 8
Training loss: 3.7328979891172707
Validation loss: 3.1223557899591756

Epoch: 5| Step: 9
Training loss: 2.5489144613909738
Validation loss: 3.122393477194892

Epoch: 5| Step: 10
Training loss: 3.9397363518353172
Validation loss: 3.1207007123024093

Epoch: 37| Step: 0
Training loss: 2.9262786157277016
Validation loss: 3.1180380658666706

Epoch: 5| Step: 1
Training loss: 3.707368760978979
Validation loss: 3.1170587522594055

Epoch: 5| Step: 2
Training loss: 2.475997715999801
Validation loss: 3.11444382261288

Epoch: 5| Step: 3
Training loss: 3.8075872568312588
Validation loss: 3.116128425015932

Epoch: 5| Step: 4
Training loss: 3.659720184177617
Validation loss: 3.116376048049215

Epoch: 5| Step: 5
Training loss: 3.749727366391539
Validation loss: 3.1147945139165145

Epoch: 5| Step: 6
Training loss: 3.0569861463557912
Validation loss: 3.113556951250516

Epoch: 5| Step: 7
Training loss: 3.7143135855750393
Validation loss: 3.11315339806946

Epoch: 5| Step: 8
Training loss: 3.000507629679785
Validation loss: 3.111144413845504

Epoch: 5| Step: 9
Training loss: 3.576280809927755
Validation loss: 3.1109229707620942

Epoch: 5| Step: 10
Training loss: 3.1598707525162197
Validation loss: 3.11058054537498

Epoch: 38| Step: 0
Training loss: 3.1272632795316158
Validation loss: 3.110884108687605

Epoch: 5| Step: 1
Training loss: 3.5690742198423338
Validation loss: 3.108188433460111

Epoch: 5| Step: 2
Training loss: 3.355866911494127
Validation loss: 3.1094242132658687

Epoch: 5| Step: 3
Training loss: 4.106908253668778
Validation loss: 3.1068405975451725

Epoch: 5| Step: 4
Training loss: 2.8400650462908565
Validation loss: 3.1063848216360155

Epoch: 5| Step: 5
Training loss: 3.001087309571791
Validation loss: 3.104394769859587

Epoch: 5| Step: 6
Training loss: 3.5931413217977726
Validation loss: 3.10468437952318

Epoch: 5| Step: 7
Training loss: 2.999978065410535
Validation loss: 3.102661301862491

Epoch: 5| Step: 8
Training loss: 3.045008474003067
Validation loss: 3.101527689878458

Epoch: 5| Step: 9
Training loss: 3.2425382493350603
Validation loss: 3.1020615393376194

Epoch: 5| Step: 10
Training loss: 3.9892015133343737
Validation loss: 3.1017114664415772

Epoch: 39| Step: 0
Training loss: 3.0531932561579267
Validation loss: 3.1001961561656732

Epoch: 5| Step: 1
Training loss: 3.018096859489317
Validation loss: 3.097470575869059

Epoch: 5| Step: 2
Training loss: 3.284969437920062
Validation loss: 3.096986202709806

Epoch: 5| Step: 3
Training loss: 3.5324713021291783
Validation loss: 3.0986604523429735

Epoch: 5| Step: 4
Training loss: 3.3191178629820755
Validation loss: 3.099184725399092

Epoch: 5| Step: 5
Training loss: 4.119341581750495
Validation loss: 3.10173530662372

Epoch: 5| Step: 6
Training loss: 3.263214535861175
Validation loss: 3.0973775508845267

Epoch: 5| Step: 7
Training loss: 3.200963030386233
Validation loss: 3.096454302291

Epoch: 5| Step: 8
Training loss: 3.0980806192309447
Validation loss: 3.0926639013161217

Epoch: 5| Step: 9
Training loss: 3.786548779582306
Validation loss: 3.0917307144198625

Epoch: 5| Step: 10
Training loss: 3.0616534873195587
Validation loss: 3.092424022571456

Epoch: 40| Step: 0
Training loss: 3.520568491588721
Validation loss: 3.090440108385733

Epoch: 5| Step: 1
Training loss: 2.8529836797237413
Validation loss: 3.08826775608895

Epoch: 5| Step: 2
Training loss: 3.3998226456105685
Validation loss: 3.0910641656441045

Epoch: 5| Step: 3
Training loss: 3.2609694299747707
Validation loss: 3.0867719256056363

Epoch: 5| Step: 4
Training loss: 3.617774207235517
Validation loss: 3.087644420585827

Epoch: 5| Step: 5
Training loss: 3.449867058003179
Validation loss: 3.0868690348513823

Epoch: 5| Step: 6
Training loss: 3.4177006033209563
Validation loss: 3.0854379083638492

Epoch: 5| Step: 7
Training loss: 3.3924191557908436
Validation loss: 3.083722640129149

Epoch: 5| Step: 8
Training loss: 3.556988384374786
Validation loss: 3.081997122626914

Epoch: 5| Step: 9
Training loss: 3.4036649641663406
Validation loss: 3.0827263520386246

Epoch: 5| Step: 10
Training loss: 2.7725433197627294
Validation loss: 3.0825119842465862

Epoch: 41| Step: 0
Training loss: 3.202054175047856
Validation loss: 3.0808189974745797

Epoch: 5| Step: 1
Training loss: 3.7955419138912143
Validation loss: 3.0807509385082854

Epoch: 5| Step: 2
Training loss: 3.6519587186337388
Validation loss: 3.0809441572074636

Epoch: 5| Step: 3
Training loss: 3.147383975071304
Validation loss: 3.078949788579894

Epoch: 5| Step: 4
Training loss: 3.2154466288542642
Validation loss: 3.077554206235141

Epoch: 5| Step: 5
Training loss: 3.756184881728089
Validation loss: 3.0776700477492454

Epoch: 5| Step: 6
Training loss: 2.500330521669152
Validation loss: 3.0781367399421677

Epoch: 5| Step: 7
Training loss: 3.5335371324556464
Validation loss: 3.079442529050567

Epoch: 5| Step: 8
Training loss: 3.0334964568603304
Validation loss: 3.0785904957066172

Epoch: 5| Step: 9
Training loss: 3.4097168804333173
Validation loss: 3.0790397800954943

Epoch: 5| Step: 10
Training loss: 3.302670126842195
Validation loss: 3.079710445527827

Epoch: 42| Step: 0
Training loss: 3.369462733696506
Validation loss: 3.0762194643442973

Epoch: 5| Step: 1
Training loss: 3.3034760980585793
Validation loss: 3.0787544879015707

Epoch: 5| Step: 2
Training loss: 3.5159618979202483
Validation loss: 3.0767800188115544

Epoch: 5| Step: 3
Training loss: 3.7556630924887586
Validation loss: 3.0747667791932494

Epoch: 5| Step: 4
Training loss: 3.5630142108506435
Validation loss: 3.0736205254146833

Epoch: 5| Step: 5
Training loss: 3.619031794353296
Validation loss: 3.073032266991473

Epoch: 5| Step: 6
Training loss: 2.526037241089605
Validation loss: 3.072135500359612

Epoch: 5| Step: 7
Training loss: 3.328669543781969
Validation loss: 3.0716473949761403

Epoch: 5| Step: 8
Training loss: 2.882218627960126
Validation loss: 3.068573037187401

Epoch: 5| Step: 9
Training loss: 3.6276474854492853
Validation loss: 3.0698786970793166

Epoch: 5| Step: 10
Training loss: 2.901950896874986
Validation loss: 3.0674107857482262

Epoch: 43| Step: 0
Training loss: 2.972417393235165
Validation loss: 3.0666807349802117

Epoch: 5| Step: 1
Training loss: 3.627872512798129
Validation loss: 3.0681253802241986

Epoch: 5| Step: 2
Training loss: 3.1994092276743733
Validation loss: 3.065287029423017

Epoch: 5| Step: 3
Training loss: 3.773907807858045
Validation loss: 3.0678570996464316

Epoch: 5| Step: 4
Training loss: 3.7404633374762417
Validation loss: 3.0651849792908323

Epoch: 5| Step: 5
Training loss: 3.1577595037649977
Validation loss: 3.0657504271120546

Epoch: 5| Step: 6
Training loss: 3.5852421105004555
Validation loss: 3.0637487745545116

Epoch: 5| Step: 7
Training loss: 3.394832549424972
Validation loss: 3.06262747955697

Epoch: 5| Step: 8
Training loss: 2.981567020474805
Validation loss: 3.0590099750915005

Epoch: 5| Step: 9
Training loss: 3.0168844962815213
Validation loss: 3.0572524711364757

Epoch: 5| Step: 10
Training loss: 2.926898249049756
Validation loss: 3.056792790376206

Epoch: 44| Step: 0
Training loss: 3.4252231887158957
Validation loss: 3.0568741184860597

Epoch: 5| Step: 1
Training loss: 3.63731659626769
Validation loss: 3.055565373382258

Epoch: 5| Step: 2
Training loss: 3.962090379018226
Validation loss: 3.055697067789804

Epoch: 5| Step: 3
Training loss: 3.139281331813611
Validation loss: 3.053618716901976

Epoch: 5| Step: 4
Training loss: 3.496037147106385
Validation loss: 3.053029009437668

Epoch: 5| Step: 5
Training loss: 2.680938517655565
Validation loss: 3.051915839322488

Epoch: 5| Step: 6
Training loss: 3.1048343802247307
Validation loss: 3.0538051457458906

Epoch: 5| Step: 7
Training loss: 2.7849250258758773
Validation loss: 3.052046503482264

Epoch: 5| Step: 8
Training loss: 2.929778318904829
Validation loss: 3.0506542527533664

Epoch: 5| Step: 9
Training loss: 3.372412784882388
Validation loss: 3.0510878153977523

Epoch: 5| Step: 10
Training loss: 3.8432640450797337
Validation loss: 3.051014116371976

Epoch: 45| Step: 0
Training loss: 3.523428568014593
Validation loss: 3.0503391779965865

Epoch: 5| Step: 1
Training loss: 3.656830700788725
Validation loss: 3.0512080217126574

Epoch: 5| Step: 2
Training loss: 3.03284498901889
Validation loss: 3.0491975000047566

Epoch: 5| Step: 3
Training loss: 3.663524596335685
Validation loss: 3.048021105282371

Epoch: 5| Step: 4
Training loss: 3.0785076077844153
Validation loss: 3.0487629003970422

Epoch: 5| Step: 5
Training loss: 3.745112603892241
Validation loss: 3.0472683139704206

Epoch: 5| Step: 6
Training loss: 3.20954170425545
Validation loss: 3.0440987676833204

Epoch: 5| Step: 7
Training loss: 3.3182367994853075
Validation loss: 3.0467752369339327

Epoch: 5| Step: 8
Training loss: 2.5524242770239836
Validation loss: 3.0463938562195945

Epoch: 5| Step: 9
Training loss: 3.2230752568514633
Validation loss: 3.044055655146319

Epoch: 5| Step: 10
Training loss: 3.3022170335595686
Validation loss: 3.0443304087938023

Epoch: 46| Step: 0
Training loss: 3.6564273628188366
Validation loss: 3.041482712232652

Epoch: 5| Step: 1
Training loss: 3.113588784606745
Validation loss: 3.0414200872608013

Epoch: 5| Step: 2
Training loss: 3.5289607096403817
Validation loss: 3.0405391407523985

Epoch: 5| Step: 3
Training loss: 3.070676204503704
Validation loss: 3.041827691626111

Epoch: 5| Step: 4
Training loss: 3.109798230068678
Validation loss: 3.0425988484216036

Epoch: 5| Step: 5
Training loss: 3.055287333959639
Validation loss: 3.0409060370138308

Epoch: 5| Step: 6
Training loss: 3.099761363042726
Validation loss: 3.0417159938029372

Epoch: 5| Step: 7
Training loss: 3.647766835817329
Validation loss: 3.0428361053561024

Epoch: 5| Step: 8
Training loss: 3.931373553009897
Validation loss: 3.0396171527852296

Epoch: 5| Step: 9
Training loss: 3.1669577080010995
Validation loss: 3.0389716334110233

Epoch: 5| Step: 10
Training loss: 2.759958442706837
Validation loss: 3.0394999183523725

Epoch: 47| Step: 0
Training loss: 3.434482151404405
Validation loss: 3.0393814394903615

Epoch: 5| Step: 1
Training loss: 3.3321533180765344
Validation loss: 3.0390177047882094

Epoch: 5| Step: 2
Training loss: 3.037084254317332
Validation loss: 3.0396787421076263

Epoch: 5| Step: 3
Training loss: 2.761529940311452
Validation loss: 3.0432677921543303

Epoch: 5| Step: 4
Training loss: 3.4299513730530915
Validation loss: 3.0419796633580685

Epoch: 5| Step: 5
Training loss: 3.2956045875951685
Validation loss: 3.0429520856978707

Epoch: 5| Step: 6
Training loss: 3.0696975829937383
Validation loss: 3.0396173653243044

Epoch: 5| Step: 7
Training loss: 3.357258116416088
Validation loss: 3.037755020045594

Epoch: 5| Step: 8
Training loss: 3.266792052321413
Validation loss: 3.0318150942403665

Epoch: 5| Step: 9
Training loss: 3.4413741042057104
Validation loss: 3.031889150878046

Epoch: 5| Step: 10
Training loss: 3.867130903350056
Validation loss: 3.0289687907828258

Epoch: 48| Step: 0
Training loss: 3.7430959088743943
Validation loss: 3.0286597723113675

Epoch: 5| Step: 1
Training loss: 3.228966212460034
Validation loss: 3.0282349319607804

Epoch: 5| Step: 2
Training loss: 3.1709764833423404
Validation loss: 3.0294290343472805

Epoch: 5| Step: 3
Training loss: 3.462097937861905
Validation loss: 3.0278466446923296

Epoch: 5| Step: 4
Training loss: 2.9349279303207356
Validation loss: 3.026391848222735

Epoch: 5| Step: 5
Training loss: 3.4177653399294754
Validation loss: 3.0264435663034823

Epoch: 5| Step: 6
Training loss: 3.5771773636815034
Validation loss: 3.02567342067518

Epoch: 5| Step: 7
Training loss: 3.012268095468843
Validation loss: 3.0253757552254807

Epoch: 5| Step: 8
Training loss: 2.3539357930180183
Validation loss: 3.0240742346084546

Epoch: 5| Step: 9
Training loss: 3.4651803559543612
Validation loss: 3.023411607728157

Epoch: 5| Step: 10
Training loss: 3.6838654532201907
Validation loss: 3.024791493522918

Epoch: 49| Step: 0
Training loss: 3.062072412652442
Validation loss: 3.024792919937328

Epoch: 5| Step: 1
Training loss: 3.4107074095514753
Validation loss: 3.0326979248732617

Epoch: 5| Step: 2
Training loss: 3.654267123910159
Validation loss: 3.0447760256590413

Epoch: 5| Step: 3
Training loss: 3.54696561050629
Validation loss: 3.0313973796416023

Epoch: 5| Step: 4
Training loss: 3.3379686233755477
Validation loss: 3.0184304943699676

Epoch: 5| Step: 5
Training loss: 3.2659260734231923
Validation loss: 3.0180652556948315

Epoch: 5| Step: 6
Training loss: 3.442696267865267
Validation loss: 3.02469736055056

Epoch: 5| Step: 7
Training loss: 2.766452902460033
Validation loss: 3.0343373210689033

Epoch: 5| Step: 8
Training loss: 3.8294580746507476
Validation loss: 3.0256730690473677

Epoch: 5| Step: 9
Training loss: 2.970568611866694
Validation loss: 3.0164696196390834

Epoch: 5| Step: 10
Training loss: 2.7776129440568544
Validation loss: 3.0145536595362734

Epoch: 50| Step: 0
Training loss: 3.7985500832133536
Validation loss: 3.0125794335684617

Epoch: 5| Step: 1
Training loss: 2.8843999694206333
Validation loss: 3.0122995728520396

Epoch: 5| Step: 2
Training loss: 3.5215167373634277
Validation loss: 3.0121795032439334

Epoch: 5| Step: 3
Training loss: 3.920760767741864
Validation loss: 3.010677016551747

Epoch: 5| Step: 4
Training loss: 3.4943450475591797
Validation loss: 3.0114228328912658

Epoch: 5| Step: 5
Training loss: 3.3720160114546234
Validation loss: 3.009902398085954

Epoch: 5| Step: 6
Training loss: 3.0600775655253005
Validation loss: 3.009809099239969

Epoch: 5| Step: 7
Training loss: 2.3564873006710383
Validation loss: 3.0116077503350906

Epoch: 5| Step: 8
Training loss: 3.318439556767449
Validation loss: 3.0111192599481216

Epoch: 5| Step: 9
Training loss: 2.920431667976386
Validation loss: 3.013498248225574

Epoch: 5| Step: 10
Training loss: 3.1420485273725896
Validation loss: 3.017809667829217

Epoch: 51| Step: 0
Training loss: 3.2668113196387876
Validation loss: 3.0289136583206964

Epoch: 5| Step: 1
Training loss: 3.270251341793315
Validation loss: 3.0440692175714195

Epoch: 5| Step: 2
Training loss: 3.442244844309636
Validation loss: 3.0305779687594248

Epoch: 5| Step: 3
Training loss: 3.7214864712210036
Validation loss: 3.013669180075834

Epoch: 5| Step: 4
Training loss: 2.9830168984241743
Validation loss: 3.0079950970531435

Epoch: 5| Step: 5
Training loss: 3.5131596716198223
Validation loss: 3.0023415094527635

Epoch: 5| Step: 6
Training loss: 3.4449080664516596
Validation loss: 3.001828733525025

Epoch: 5| Step: 7
Training loss: 2.8519012667992714
Validation loss: 3.000855366647144

Epoch: 5| Step: 8
Training loss: 3.629025033376195
Validation loss: 3.0014748742068154

Epoch: 5| Step: 9
Training loss: 2.7711902378987343
Validation loss: 2.999473445239951

Epoch: 5| Step: 10
Training loss: 3.058873890876452
Validation loss: 2.998559529046913

Epoch: 52| Step: 0
Training loss: 3.571784786443459
Validation loss: 2.9979289462001035

Epoch: 5| Step: 1
Training loss: 3.500694614692826
Validation loss: 2.9976751538183426

Epoch: 5| Step: 2
Training loss: 3.022664446904675
Validation loss: 2.9984582225792242

Epoch: 5| Step: 3
Training loss: 2.7786515345182745
Validation loss: 2.9958028513470545

Epoch: 5| Step: 4
Training loss: 3.2872728566651537
Validation loss: 2.997418896406139

Epoch: 5| Step: 5
Training loss: 3.6766435542090603
Validation loss: 2.997345161574526

Epoch: 5| Step: 6
Training loss: 2.946502849749021
Validation loss: 2.997991267098057

Epoch: 5| Step: 7
Training loss: 2.5882557046437373
Validation loss: 2.999425202340536

Epoch: 5| Step: 8
Training loss: 3.3559220421958402
Validation loss: 2.999992967925495

Epoch: 5| Step: 9
Training loss: 3.2389653016010507
Validation loss: 2.999322718219786

Epoch: 5| Step: 10
Training loss: 3.9516852248544554
Validation loss: 2.99616867416477

Epoch: 53| Step: 0
Training loss: 4.046993769372018
Validation loss: 2.9968353503251484

Epoch: 5| Step: 1
Training loss: 3.6069073849752593
Validation loss: 2.992604468261713

Epoch: 5| Step: 2
Training loss: 3.0526915758955973
Validation loss: 2.9925126364673624

Epoch: 5| Step: 3
Training loss: 2.927613360834991
Validation loss: 2.99042725861422

Epoch: 5| Step: 4
Training loss: 3.5642255652960655
Validation loss: 2.9904912223413116

Epoch: 5| Step: 5
Training loss: 2.647158423588202
Validation loss: 2.99068806940789

Epoch: 5| Step: 6
Training loss: 2.325396891527337
Validation loss: 2.9904109573450923

Epoch: 5| Step: 7
Training loss: 3.1438865616792726
Validation loss: 2.9891404829399915

Epoch: 5| Step: 8
Training loss: 3.50877832654738
Validation loss: 2.9881763375225185

Epoch: 5| Step: 9
Training loss: 3.312080644657722
Validation loss: 2.9865083822411123

Epoch: 5| Step: 10
Training loss: 3.4664835355756405
Validation loss: 2.9840412980929742

Epoch: 54| Step: 0
Training loss: 3.2168103642230075
Validation loss: 2.98534674925873

Epoch: 5| Step: 1
Training loss: 3.209946973843982
Validation loss: 2.9917543013544914

Epoch: 5| Step: 2
Training loss: 2.9148879122245024
Validation loss: 3.003672713622494

Epoch: 5| Step: 3
Training loss: 2.5392668187023
Validation loss: 2.996536335354452

Epoch: 5| Step: 4
Training loss: 3.7243602331297336
Validation loss: 2.996939385694143

Epoch: 5| Step: 5
Training loss: 3.230756716826241
Validation loss: 2.9855221342947265

Epoch: 5| Step: 6
Training loss: 3.4921036609937537
Validation loss: 2.983073173912495

Epoch: 5| Step: 7
Training loss: 3.309095540553157
Validation loss: 2.9812825648386947

Epoch: 5| Step: 8
Training loss: 3.083298416627324
Validation loss: 2.980601409207805

Epoch: 5| Step: 9
Training loss: 3.3810019636580035
Validation loss: 2.978643262237441

Epoch: 5| Step: 10
Training loss: 3.6869519359827665
Validation loss: 2.977785439262805

Epoch: 55| Step: 0
Training loss: 3.5424019592545077
Validation loss: 2.9766768571153523

Epoch: 5| Step: 1
Training loss: 3.54039545619795
Validation loss: 2.974959030965391

Epoch: 5| Step: 2
Training loss: 3.369627455769232
Validation loss: 2.9763054756530236

Epoch: 5| Step: 3
Training loss: 2.979153684218781
Validation loss: 2.975614128414204

Epoch: 5| Step: 4
Training loss: 2.8878964304752786
Validation loss: 2.9729006436129715

Epoch: 5| Step: 5
Training loss: 4.199802148790971
Validation loss: 2.975282189971741

Epoch: 5| Step: 6
Training loss: 2.9682395094605254
Validation loss: 2.974199284456862

Epoch: 5| Step: 7
Training loss: 3.6205387945331737
Validation loss: 2.9756163796437507

Epoch: 5| Step: 8
Training loss: 2.8245622312578442
Validation loss: 2.9745329493962416

Epoch: 5| Step: 9
Training loss: 2.9736786737021794
Validation loss: 2.9801135294936567

Epoch: 5| Step: 10
Training loss: 2.3804349450570848
Validation loss: 2.974869667204722

Epoch: 56| Step: 0
Training loss: 3.4291455094776744
Validation loss: 2.971195954668267

Epoch: 5| Step: 1
Training loss: 2.104458200131586
Validation loss: 2.972530128871866

Epoch: 5| Step: 2
Training loss: 2.927224224858365
Validation loss: 2.9714155301980725

Epoch: 5| Step: 3
Training loss: 2.9824378632102557
Validation loss: 2.9737856683543447

Epoch: 5| Step: 4
Training loss: 3.7346603731426726
Validation loss: 2.973533713989294

Epoch: 5| Step: 5
Training loss: 3.46894574686987
Validation loss: 2.977508612461759

Epoch: 5| Step: 6
Training loss: 3.4211126723793033
Validation loss: 2.9699572817209097

Epoch: 5| Step: 7
Training loss: 3.010035419192352
Validation loss: 2.9672420348413966

Epoch: 5| Step: 8
Training loss: 3.3557940182223365
Validation loss: 2.9652572992576114

Epoch: 5| Step: 9
Training loss: 4.001460047329721
Validation loss: 2.964797198730388

Epoch: 5| Step: 10
Training loss: 2.8071477189016725
Validation loss: 2.9630260568662568

Epoch: 57| Step: 0
Training loss: 3.5852080623418163
Validation loss: 2.963822079245122

Epoch: 5| Step: 1
Training loss: 2.8591808816024047
Validation loss: 2.9672908856509728

Epoch: 5| Step: 2
Training loss: 2.4288982323740904
Validation loss: 2.964469200642655

Epoch: 5| Step: 3
Training loss: 2.8814219193875195
Validation loss: 2.9655288967542774

Epoch: 5| Step: 4
Training loss: 3.7790194150815086
Validation loss: 2.9672120683743026

Epoch: 5| Step: 5
Training loss: 3.055727886388023
Validation loss: 2.9620796858038765

Epoch: 5| Step: 6
Training loss: 3.8030652733456516
Validation loss: 2.9640931984962413

Epoch: 5| Step: 7
Training loss: 3.507294410558718
Validation loss: 2.9610938968340337

Epoch: 5| Step: 8
Training loss: 2.6881650944486664
Validation loss: 2.958826591264618

Epoch: 5| Step: 9
Training loss: 3.6183705712406398
Validation loss: 2.958979166246214

Epoch: 5| Step: 10
Training loss: 3.1411715359343337
Validation loss: 2.9577907502019816

Epoch: 58| Step: 0
Training loss: 3.4557065677933982
Validation loss: 2.9591772033356145

Epoch: 5| Step: 1
Training loss: 3.3069339268361504
Validation loss: 2.9575448262847397

Epoch: 5| Step: 2
Training loss: 3.7033467286763537
Validation loss: 2.960050851819662

Epoch: 5| Step: 3
Training loss: 2.761743353878425
Validation loss: 2.9612387192442786

Epoch: 5| Step: 4
Training loss: 3.387847043661735
Validation loss: 2.959679152878349

Epoch: 5| Step: 5
Training loss: 2.824815953428798
Validation loss: 2.964031579870918

Epoch: 5| Step: 6
Training loss: 3.0867381155863978
Validation loss: 2.959043930192438

Epoch: 5| Step: 7
Training loss: 3.544296470099044
Validation loss: 2.957536466720749

Epoch: 5| Step: 8
Training loss: 3.2111315889009893
Validation loss: 2.9558316100491724

Epoch: 5| Step: 9
Training loss: 3.3335250958278624
Validation loss: 2.9548714755837437

Epoch: 5| Step: 10
Training loss: 2.7749150168662964
Validation loss: 2.952417700765264

Epoch: 59| Step: 0
Training loss: 3.0173625782644913
Validation loss: 2.95611518195685

Epoch: 5| Step: 1
Training loss: 3.1518973373598875
Validation loss: 2.9517361192533214

Epoch: 5| Step: 2
Training loss: 2.8944899006514335
Validation loss: 2.9527554115538526

Epoch: 5| Step: 3
Training loss: 3.4975629223609435
Validation loss: 2.948866470530089

Epoch: 5| Step: 4
Training loss: 2.8806021468848653
Validation loss: 2.9503935360050724

Epoch: 5| Step: 5
Training loss: 3.466117478542964
Validation loss: 2.948997050574974

Epoch: 5| Step: 6
Training loss: 3.419180309824106
Validation loss: 2.9486921012286893

Epoch: 5| Step: 7
Training loss: 3.059828235068923
Validation loss: 2.947782033288649

Epoch: 5| Step: 8
Training loss: 3.1578857413381316
Validation loss: 2.9467923382713366

Epoch: 5| Step: 9
Training loss: 3.3763196272663327
Validation loss: 2.9455412758997634

Epoch: 5| Step: 10
Training loss: 3.5923755173429432
Validation loss: 2.9459029008217863

Epoch: 60| Step: 0
Training loss: 3.6969931008829424
Validation loss: 2.9455346847606703

Epoch: 5| Step: 1
Training loss: 3.28627312687992
Validation loss: 2.944484172609008

Epoch: 5| Step: 2
Training loss: 3.7334057176475577
Validation loss: 2.944065632918031

Epoch: 5| Step: 3
Training loss: 2.8050651614802367
Validation loss: 2.9465552513868616

Epoch: 5| Step: 4
Training loss: 3.563711127822158
Validation loss: 2.9459139989633547

Epoch: 5| Step: 5
Training loss: 2.358070973157301
Validation loss: 2.943801108679226

Epoch: 5| Step: 6
Training loss: 2.9051437733670094
Validation loss: 2.939891383751576

Epoch: 5| Step: 7
Training loss: 2.7842066618684096
Validation loss: 2.941483484008736

Epoch: 5| Step: 8
Training loss: 3.232185249080721
Validation loss: 2.938554152682733

Epoch: 5| Step: 9
Training loss: 2.8979755043695214
Validation loss: 2.939245497402695

Epoch: 5| Step: 10
Training loss: 3.973115457496627
Validation loss: 2.938511251329903

Epoch: 61| Step: 0
Training loss: 3.2460358725849594
Validation loss: 2.9375105530168106

Epoch: 5| Step: 1
Training loss: 2.986489231112557
Validation loss: 2.9376841216637426

Epoch: 5| Step: 2
Training loss: 3.038555348107983
Validation loss: 2.936814759079476

Epoch: 5| Step: 3
Training loss: 3.4658699795240184
Validation loss: 2.936904269072428

Epoch: 5| Step: 4
Training loss: 3.2559451965481245
Validation loss: 2.9364760339339337

Epoch: 5| Step: 5
Training loss: 2.9686770781545695
Validation loss: 2.934324728021318

Epoch: 5| Step: 6
Training loss: 3.068180188265281
Validation loss: 2.9337968893735438

Epoch: 5| Step: 7
Training loss: 3.4191719422441866
Validation loss: 2.9343802721377927

Epoch: 5| Step: 8
Training loss: 3.81944892343586
Validation loss: 2.933048241102348

Epoch: 5| Step: 9
Training loss: 2.870805915365706
Validation loss: 2.935284791887433

Epoch: 5| Step: 10
Training loss: 3.176031236557408
Validation loss: 2.932585945823642

Epoch: 62| Step: 0
Training loss: 2.493943889987064
Validation loss: 2.9324863597754516

Epoch: 5| Step: 1
Training loss: 3.718613565971509
Validation loss: 2.9314024158669207

Epoch: 5| Step: 2
Training loss: 3.496067835535939
Validation loss: 2.9308004613411662

Epoch: 5| Step: 3
Training loss: 3.681252828962861
Validation loss: 2.9288393779656383

Epoch: 5| Step: 4
Training loss: 2.9539885696365613
Validation loss: 2.9322010841484296

Epoch: 5| Step: 5
Training loss: 2.6296120952962845
Validation loss: 2.9347675778546005

Epoch: 5| Step: 6
Training loss: 3.299679399580306
Validation loss: 2.929925372567569

Epoch: 5| Step: 7
Training loss: 3.507130172058375
Validation loss: 2.93167410750632

Epoch: 5| Step: 8
Training loss: 2.8711952243441035
Validation loss: 2.9317889948320297

Epoch: 5| Step: 9
Training loss: 3.195452176424552
Validation loss: 2.933453822760992

Epoch: 5| Step: 10
Training loss: 3.229290342526204
Validation loss: 2.934030582486264

Epoch: 63| Step: 0
Training loss: 3.585617948767538
Validation loss: 2.9259030268717328

Epoch: 5| Step: 1
Training loss: 3.0021586599083494
Validation loss: 2.9235780289094966

Epoch: 5| Step: 2
Training loss: 3.20478680929668
Validation loss: 2.9231062900556304

Epoch: 5| Step: 3
Training loss: 3.1852819167669018
Validation loss: 2.9235784936583133

Epoch: 5| Step: 4
Training loss: 3.339898145801547
Validation loss: 2.9218435609872233

Epoch: 5| Step: 5
Training loss: 3.2002291358927404
Validation loss: 2.920545855541671

Epoch: 5| Step: 6
Training loss: 3.148501412095566
Validation loss: 2.9205764974498165

Epoch: 5| Step: 7
Training loss: 2.7222169716021014
Validation loss: 2.9204812614023092

Epoch: 5| Step: 8
Training loss: 3.3872934313639163
Validation loss: 2.9207613813807027

Epoch: 5| Step: 9
Training loss: 3.26440143934568
Validation loss: 2.9216800151063484

Epoch: 5| Step: 10
Training loss: 3.143053321165185
Validation loss: 2.9181894103979675

Epoch: 64| Step: 0
Training loss: 2.906313331488216
Validation loss: 2.9176157560082663

Epoch: 5| Step: 1
Training loss: 3.483889695656139
Validation loss: 2.916860133374671

Epoch: 5| Step: 2
Training loss: 2.862280698146656
Validation loss: 2.9249469067922793

Epoch: 5| Step: 3
Training loss: 3.3956323731916545
Validation loss: 2.921576220073262

Epoch: 5| Step: 4
Training loss: 3.4534398276307647
Validation loss: 2.9250767474346815

Epoch: 5| Step: 5
Training loss: 3.0298131309773177
Validation loss: 2.919850337856397

Epoch: 5| Step: 6
Training loss: 3.2727545342128757
Validation loss: 2.932441519772459

Epoch: 5| Step: 7
Training loss: 2.87588371295366
Validation loss: 2.9316324661553557

Epoch: 5| Step: 8
Training loss: 3.9266560505031043
Validation loss: 2.941447167299269

Epoch: 5| Step: 9
Training loss: 3.0493426380602084
Validation loss: 2.9248082163547697

Epoch: 5| Step: 10
Training loss: 2.7693588138590277
Validation loss: 2.9126605570608644

Epoch: 65| Step: 0
Training loss: 3.159683324180834
Validation loss: 2.9099203946436516

Epoch: 5| Step: 1
Training loss: 3.1459031423608264
Validation loss: 2.9107222199488016

Epoch: 5| Step: 2
Training loss: 3.759503339065589
Validation loss: 2.9111603568195545

Epoch: 5| Step: 3
Training loss: 2.9140009732948413
Validation loss: 2.9113326002158875

Epoch: 5| Step: 4
Training loss: 2.706980783231553
Validation loss: 2.914659928405759

Epoch: 5| Step: 5
Training loss: 3.0659630327577836
Validation loss: 2.9100509621204913

Epoch: 5| Step: 6
Training loss: 3.0690110726801554
Validation loss: 2.909046742922852

Epoch: 5| Step: 7
Training loss: 2.796903642049571
Validation loss: 2.907893598751506

Epoch: 5| Step: 8
Training loss: 2.7882091595198206
Validation loss: 2.905404168808025

Epoch: 5| Step: 9
Training loss: 3.617076501317305
Validation loss: 2.9065004351779025

Epoch: 5| Step: 10
Training loss: 4.032105820765809
Validation loss: 2.9066837184310255

Epoch: 66| Step: 0
Training loss: 2.444188063595387
Validation loss: 2.9091127718234926

Epoch: 5| Step: 1
Training loss: 3.5215268928554972
Validation loss: 2.914411243786896

Epoch: 5| Step: 2
Training loss: 3.4005762845998344
Validation loss: 2.9171751472717844

Epoch: 5| Step: 3
Training loss: 3.5674834614445885
Validation loss: 2.920259801488919

Epoch: 5| Step: 4
Training loss: 2.6200594957890955
Validation loss: 2.926928824454933

Epoch: 5| Step: 5
Training loss: 3.628201616449187
Validation loss: 2.9487889769439133

Epoch: 5| Step: 6
Training loss: 3.2762750604130257
Validation loss: 2.9097911913245786

Epoch: 5| Step: 7
Training loss: 2.594544346519895
Validation loss: 2.9035322731723383

Epoch: 5| Step: 8
Training loss: 3.2275977148131383
Validation loss: 2.903047423482668

Epoch: 5| Step: 9
Training loss: 3.541201587134669
Validation loss: 2.9052193700071993

Epoch: 5| Step: 10
Training loss: 3.0371702917926178
Validation loss: 2.9146674539770085

Epoch: 67| Step: 0
Training loss: 2.711692858731463
Validation loss: 2.916684343720996

Epoch: 5| Step: 1
Training loss: 2.9177491132198656
Validation loss: 2.917158149292872

Epoch: 5| Step: 2
Training loss: 3.4303711924432223
Validation loss: 2.912480618935541

Epoch: 5| Step: 3
Training loss: 3.604997498700548
Validation loss: 2.8996287524451154

Epoch: 5| Step: 4
Training loss: 2.9731433684844375
Validation loss: 2.8973205676846363

Epoch: 5| Step: 5
Training loss: 3.371482146024492
Validation loss: 2.8951503107216525

Epoch: 5| Step: 6
Training loss: 2.5806910835687087
Validation loss: 2.895931665098594

Epoch: 5| Step: 7
Training loss: 3.749757504569944
Validation loss: 2.8919664529026714

Epoch: 5| Step: 8
Training loss: 2.8719389832584485
Validation loss: 2.886177467049413

Epoch: 5| Step: 9
Training loss: 3.737392977710054
Validation loss: 2.8846935555063187

Epoch: 5| Step: 10
Training loss: 2.733424430197511
Validation loss: 2.883019104523997

Epoch: 68| Step: 0
Training loss: 3.168893700224922
Validation loss: 2.8813880033006325

Epoch: 5| Step: 1
Training loss: 3.202154393959846
Validation loss: 2.8836847144063587

Epoch: 5| Step: 2
Training loss: 2.567003526091522
Validation loss: 2.8785286765690463

Epoch: 5| Step: 3
Training loss: 3.8001023379147947
Validation loss: 2.878198917197699

Epoch: 5| Step: 4
Training loss: 3.392329055875895
Validation loss: 2.872547151064741

Epoch: 5| Step: 5
Training loss: 3.0288361051995936
Validation loss: 2.8756264801641716

Epoch: 5| Step: 6
Training loss: 3.2107411716704854
Validation loss: 2.8721927903556073

Epoch: 5| Step: 7
Training loss: 2.651153072472048
Validation loss: 2.872795970437715

Epoch: 5| Step: 8
Training loss: 3.326864370945046
Validation loss: 2.8692709359884083

Epoch: 5| Step: 9
Training loss: 2.698208963670772
Validation loss: 2.869626257853145

Epoch: 5| Step: 10
Training loss: 3.67825671845746
Validation loss: 2.8668888635391228

Epoch: 69| Step: 0
Training loss: 3.053164519539362
Validation loss: 2.8689163600516476

Epoch: 5| Step: 1
Training loss: 2.7220478445328666
Validation loss: 2.8667375345000727

Epoch: 5| Step: 2
Training loss: 3.0398858139276794
Validation loss: 2.864944824201141

Epoch: 5| Step: 3
Training loss: 3.514136240767674
Validation loss: 2.86580888203803

Epoch: 5| Step: 4
Training loss: 2.992046462437746
Validation loss: 2.8618850364830033

Epoch: 5| Step: 5
Training loss: 2.8251055199825093
Validation loss: 2.860710896659646

Epoch: 5| Step: 6
Training loss: 2.9336044778640398
Validation loss: 2.8617266998835

Epoch: 5| Step: 7
Training loss: 3.5183202287968105
Validation loss: 2.861325261504723

Epoch: 5| Step: 8
Training loss: 3.924577853103852
Validation loss: 2.859434156222266

Epoch: 5| Step: 9
Training loss: 2.8624103049005876
Validation loss: 2.8584254612661177

Epoch: 5| Step: 10
Training loss: 3.1761445873412733
Validation loss: 2.8552717442760076

Epoch: 70| Step: 0
Training loss: 2.411841101921005
Validation loss: 2.8533729055465917

Epoch: 5| Step: 1
Training loss: 3.674480666230795
Validation loss: 2.850759655555219

Epoch: 5| Step: 2
Training loss: 2.748393022742289
Validation loss: 2.8464323273891066

Epoch: 5| Step: 3
Training loss: 3.1189194077099125
Validation loss: 2.842612140653579

Epoch: 5| Step: 4
Training loss: 2.807534985209671
Validation loss: 2.8436065478982138

Epoch: 5| Step: 5
Training loss: 3.1418724808873493
Validation loss: 2.8383913040790048

Epoch: 5| Step: 6
Training loss: 3.0131628233286922
Validation loss: 2.8380497178271025

Epoch: 5| Step: 7
Training loss: 3.6027345550017573
Validation loss: 2.8408702994464146

Epoch: 5| Step: 8
Training loss: 3.1082982638292336
Validation loss: 2.8393970255552414

Epoch: 5| Step: 9
Training loss: 3.374890360994038
Validation loss: 2.8417985385080393

Epoch: 5| Step: 10
Training loss: 3.378726173850336
Validation loss: 2.8396334588538146

Epoch: 71| Step: 0
Training loss: 3.8020412634346648
Validation loss: 2.8452509583900683

Epoch: 5| Step: 1
Training loss: 3.2733699090575508
Validation loss: 2.847973182689306

Epoch: 5| Step: 2
Training loss: 2.884802320243084
Validation loss: 2.84906597098714

Epoch: 5| Step: 3
Training loss: 3.2377213568110808
Validation loss: 2.848911330380191

Epoch: 5| Step: 4
Training loss: 3.0482184162729653
Validation loss: 2.851489428591028

Epoch: 5| Step: 5
Training loss: 2.72885097007556
Validation loss: 2.8426533094019506

Epoch: 5| Step: 6
Training loss: 2.959363534133758
Validation loss: 2.847124317062264

Epoch: 5| Step: 7
Training loss: 3.3015687623801826
Validation loss: 2.856037841207006

Epoch: 5| Step: 8
Training loss: 3.1324987848984294
Validation loss: 2.840176102279522

Epoch: 5| Step: 9
Training loss: 3.0287543966440116
Validation loss: 2.8300525426311682

Epoch: 5| Step: 10
Training loss: 2.9435489140407682
Validation loss: 2.8303625184055567

Epoch: 72| Step: 0
Training loss: 3.039508227927531
Validation loss: 2.827323405201142

Epoch: 5| Step: 1
Training loss: 2.928051300912668
Validation loss: 2.828081782297521

Epoch: 5| Step: 2
Training loss: 3.297417907849836
Validation loss: 2.852776795214116

Epoch: 5| Step: 3
Training loss: 3.14903431576844
Validation loss: 2.8900201494482682

Epoch: 5| Step: 4
Training loss: 2.5265369572053102
Validation loss: 2.8508232431702925

Epoch: 5| Step: 5
Training loss: 2.756756631735459
Validation loss: 2.8344580570222404

Epoch: 5| Step: 6
Training loss: 3.4673306422277843
Validation loss: 2.8304960212558625

Epoch: 5| Step: 7
Training loss: 3.4983378959675684
Validation loss: 2.830324218819071

Epoch: 5| Step: 8
Training loss: 3.2176323589141362
Validation loss: 2.8327676587202597

Epoch: 5| Step: 9
Training loss: 3.2971132020639087
Validation loss: 2.832551657132677

Epoch: 5| Step: 10
Training loss: 3.2827046394331396
Validation loss: 2.835265984962901

Epoch: 73| Step: 0
Training loss: 3.693209866503932
Validation loss: 2.8383258825995106

Epoch: 5| Step: 1
Training loss: 3.456400840737455
Validation loss: 2.844557849222871

Epoch: 5| Step: 2
Training loss: 2.873665209527755
Validation loss: 2.8446906083754486

Epoch: 5| Step: 3
Training loss: 3.749230623792799
Validation loss: 2.8487524175754024

Epoch: 5| Step: 4
Training loss: 2.5189246105317404
Validation loss: 2.8499282206124654

Epoch: 5| Step: 5
Training loss: 2.7859028675539044
Validation loss: 2.8577609286186387

Epoch: 5| Step: 6
Training loss: 3.1508723610195655
Validation loss: 2.8455712509445825

Epoch: 5| Step: 7
Training loss: 2.8189307550300082
Validation loss: 2.8385184964538923

Epoch: 5| Step: 8
Training loss: 2.8233212301932387
Validation loss: 2.8241120728489437

Epoch: 5| Step: 9
Training loss: 3.0917015615243697
Validation loss: 2.821493683700297

Epoch: 5| Step: 10
Training loss: 3.2648036964371276
Validation loss: 2.8195210916944133

Epoch: 74| Step: 0
Training loss: 3.1978293209179656
Validation loss: 2.819029972887965

Epoch: 5| Step: 1
Training loss: 3.3477982587750894
Validation loss: 2.8166800606468545

Epoch: 5| Step: 2
Training loss: 3.2620231075251933
Validation loss: 2.81712242929784

Epoch: 5| Step: 3
Training loss: 2.8565009009014135
Validation loss: 2.8166388918104355

Epoch: 5| Step: 4
Training loss: 2.716527446931851
Validation loss: 2.8149890873670027

Epoch: 5| Step: 5
Training loss: 2.9518307064690075
Validation loss: 2.815243668669507

Epoch: 5| Step: 6
Training loss: 3.7837538822936754
Validation loss: 2.8156285248904234

Epoch: 5| Step: 7
Training loss: 2.636863874044407
Validation loss: 2.815095548343461

Epoch: 5| Step: 8
Training loss: 3.070700584520241
Validation loss: 2.8128181159115284

Epoch: 5| Step: 9
Training loss: 3.0673809470505313
Validation loss: 2.8137301891336857

Epoch: 5| Step: 10
Training loss: 3.3828860796883795
Validation loss: 2.812250721958216

Epoch: 75| Step: 0
Training loss: 2.940784647030442
Validation loss: 2.8124933067251248

Epoch: 5| Step: 1
Training loss: 3.4067740780892155
Validation loss: 2.812462304887004

Epoch: 5| Step: 2
Training loss: 3.6773700260141813
Validation loss: 2.812757961060445

Epoch: 5| Step: 3
Training loss: 3.3613206064249876
Validation loss: 2.8160457615053165

Epoch: 5| Step: 4
Training loss: 2.9262880668135844
Validation loss: 2.8322264905934595

Epoch: 5| Step: 5
Training loss: 2.4647212897347597
Validation loss: 2.855075114657304

Epoch: 5| Step: 6
Training loss: 2.8849056264161637
Validation loss: 2.9107082634308545

Epoch: 5| Step: 7
Training loss: 3.4026749074182403
Validation loss: 2.934960574340381

Epoch: 5| Step: 8
Training loss: 3.263078052275817
Validation loss: 2.921353173183856

Epoch: 5| Step: 9
Training loss: 2.7567670964217443
Validation loss: 2.867323165044021

Epoch: 5| Step: 10
Training loss: 3.3968204553571297
Validation loss: 2.878105072240737

Epoch: 76| Step: 0
Training loss: 2.9690283393882133
Validation loss: 2.858477566340939

Epoch: 5| Step: 1
Training loss: 2.3182499513456403
Validation loss: 2.8150377580573016

Epoch: 5| Step: 2
Training loss: 3.369179970331854
Validation loss: 2.8122684515614695

Epoch: 5| Step: 3
Training loss: 3.136714189461971
Validation loss: 2.8111691880138094

Epoch: 5| Step: 4
Training loss: 3.121152722084454
Validation loss: 2.8136067235381526

Epoch: 5| Step: 5
Training loss: 3.8519985114676034
Validation loss: 2.8100709139945477

Epoch: 5| Step: 6
Training loss: 2.7046745136903447
Validation loss: 2.8129663388427364

Epoch: 5| Step: 7
Training loss: 2.8848585192600797
Validation loss: 2.816420102187428

Epoch: 5| Step: 8
Training loss: 2.942979450170935
Validation loss: 2.8275938984041677

Epoch: 5| Step: 9
Training loss: 3.5039913035332746
Validation loss: 2.867241576520458

Epoch: 5| Step: 10
Training loss: 3.4783550998632426
Validation loss: 2.8478680398871083

Epoch: 77| Step: 0
Training loss: 2.945380010261187
Validation loss: 2.835589656561882

Epoch: 5| Step: 1
Training loss: 3.175787856504506
Validation loss: 2.830312846774615

Epoch: 5| Step: 2
Training loss: 2.89742308599307
Validation loss: 2.8238108445944

Epoch: 5| Step: 3
Training loss: 2.890226099482172
Validation loss: 2.820264180314626

Epoch: 5| Step: 4
Training loss: 3.1752339134256333
Validation loss: 2.820195403077149

Epoch: 5| Step: 5
Training loss: 3.0492478740922735
Validation loss: 2.806906139873

Epoch: 5| Step: 6
Training loss: 3.53579999426244
Validation loss: 2.8081072996568786

Epoch: 5| Step: 7
Training loss: 3.1597228631285597
Validation loss: 2.8079634235289084

Epoch: 5| Step: 8
Training loss: 3.269539708863759
Validation loss: 2.8079687535555387

Epoch: 5| Step: 9
Training loss: 3.2407449845382112
Validation loss: 2.803072720440241

Epoch: 5| Step: 10
Training loss: 3.002303828327155
Validation loss: 2.8070715177280703

Epoch: 78| Step: 0
Training loss: 2.892826046515827
Validation loss: 2.8140130552330747

Epoch: 5| Step: 1
Training loss: 2.9778646189171583
Validation loss: 2.8150150370376084

Epoch: 5| Step: 2
Training loss: 3.2797042838980675
Validation loss: 2.825484589753081

Epoch: 5| Step: 3
Training loss: 3.5420685184858347
Validation loss: 2.829132346663775

Epoch: 5| Step: 4
Training loss: 3.0656703187351746
Validation loss: 2.831832698867536

Epoch: 5| Step: 5
Training loss: 3.312802282971994
Validation loss: 2.821250021828906

Epoch: 5| Step: 6
Training loss: 3.3455517629399703
Validation loss: 2.809833517747098

Epoch: 5| Step: 7
Training loss: 2.9384887329944873
Validation loss: 2.808036499156733

Epoch: 5| Step: 8
Training loss: 2.841234708678571
Validation loss: 2.8031869668156895

Epoch: 5| Step: 9
Training loss: 3.048967317950886
Validation loss: 2.8038594644929673

Epoch: 5| Step: 10
Training loss: 2.989214423586609
Validation loss: 2.797283977507322

Epoch: 79| Step: 0
Training loss: 3.5943796684275946
Validation loss: 2.795279317107105

Epoch: 5| Step: 1
Training loss: 3.3677781155726367
Validation loss: 2.7943573316474697

Epoch: 5| Step: 2
Training loss: 2.978455589815045
Validation loss: 2.7921870592523255

Epoch: 5| Step: 3
Training loss: 3.447021337396081
Validation loss: 2.7908564276262045

Epoch: 5| Step: 4
Training loss: 3.6755616206552553
Validation loss: 2.7927749728345694

Epoch: 5| Step: 5
Training loss: 2.272843955252533
Validation loss: 2.7915446738885534

Epoch: 5| Step: 6
Training loss: 3.140446140643121
Validation loss: 2.7911291625849293

Epoch: 5| Step: 7
Training loss: 2.9228341063524006
Validation loss: 2.790441754610732

Epoch: 5| Step: 8
Training loss: 2.8820013957288277
Validation loss: 2.789367812572771

Epoch: 5| Step: 9
Training loss: 2.699299304604779
Validation loss: 2.788613829500538

Epoch: 5| Step: 10
Training loss: 2.9126832372302167
Validation loss: 2.7875019359871605

Epoch: 80| Step: 0
Training loss: 3.136053449447724
Validation loss: 2.7868319009812232

Epoch: 5| Step: 1
Training loss: 2.9983040466348463
Validation loss: 2.7859976135272073

Epoch: 5| Step: 2
Training loss: 3.1046293455762295
Validation loss: 2.7846634627372966

Epoch: 5| Step: 3
Training loss: 3.5539992787580985
Validation loss: 2.78404847480936

Epoch: 5| Step: 4
Training loss: 2.947349430861997
Validation loss: 2.7874069220031976

Epoch: 5| Step: 5
Training loss: 2.713466904404103
Validation loss: 2.783913246440412

Epoch: 5| Step: 6
Training loss: 3.229155083092043
Validation loss: 2.785954160086471

Epoch: 5| Step: 7
Training loss: 3.601659678308667
Validation loss: 2.7815351608480854

Epoch: 5| Step: 8
Training loss: 2.7099907620825037
Validation loss: 2.7844836876420813

Epoch: 5| Step: 9
Training loss: 3.092836033073533
Validation loss: 2.782597107610119

Epoch: 5| Step: 10
Training loss: 2.884055761192386
Validation loss: 2.782132834406769

Epoch: 81| Step: 0
Training loss: 3.2265357508254855
Validation loss: 2.7823600070296295

Epoch: 5| Step: 1
Training loss: 3.0479529405800743
Validation loss: 2.7817981737880597

Epoch: 5| Step: 2
Training loss: 3.452181173598321
Validation loss: 2.7820372389667805

Epoch: 5| Step: 3
Training loss: 3.382394108436383
Validation loss: 2.7781823258136593

Epoch: 5| Step: 4
Training loss: 2.8255439909705293
Validation loss: 2.782302406615166

Epoch: 5| Step: 5
Training loss: 2.9549225679893034
Validation loss: 2.7774678251853415

Epoch: 5| Step: 6
Training loss: 3.3389771525105996
Validation loss: 2.778247401077375

Epoch: 5| Step: 7
Training loss: 2.9417978864441894
Validation loss: 2.777323151031442

Epoch: 5| Step: 8
Training loss: 3.1478907107973146
Validation loss: 2.7767925115497394

Epoch: 5| Step: 9
Training loss: 2.888346996183341
Validation loss: 2.779467557334469

Epoch: 5| Step: 10
Training loss: 2.7119654924284715
Validation loss: 2.777607731143397

Epoch: 82| Step: 0
Training loss: 3.5880105004300487
Validation loss: 2.7779108982250884

Epoch: 5| Step: 1
Training loss: 3.1480938366545437
Validation loss: 2.777275027715735

Epoch: 5| Step: 2
Training loss: 3.14313676135187
Validation loss: 2.7778968124794843

Epoch: 5| Step: 3
Training loss: 3.310533911755593
Validation loss: 2.774299140410176

Epoch: 5| Step: 4
Training loss: 3.8452456906004775
Validation loss: 2.7728031693049355

Epoch: 5| Step: 5
Training loss: 2.104970558123706
Validation loss: 2.7748873498104127

Epoch: 5| Step: 6
Training loss: 2.8183462627737685
Validation loss: 2.7735421202155246

Epoch: 5| Step: 7
Training loss: 2.7920336885359966
Validation loss: 2.771584609650138

Epoch: 5| Step: 8
Training loss: 2.832714424602759
Validation loss: 2.773092768133563

Epoch: 5| Step: 9
Training loss: 2.9250502035935178
Validation loss: 2.7760995367348387

Epoch: 5| Step: 10
Training loss: 3.1876151868165694
Validation loss: 2.7772509075907825

Epoch: 83| Step: 0
Training loss: 2.7318671360744866
Validation loss: 2.778737925505825

Epoch: 5| Step: 1
Training loss: 2.9625603649572483
Validation loss: 2.783715243557588

Epoch: 5| Step: 2
Training loss: 3.0164659345522145
Validation loss: 2.7940568152268015

Epoch: 5| Step: 3
Training loss: 2.778055134807668
Validation loss: 2.7895019815552446

Epoch: 5| Step: 4
Training loss: 3.0164567660093544
Validation loss: 2.7863790760531457

Epoch: 5| Step: 5
Training loss: 3.346501724413706
Validation loss: 2.7761413196787683

Epoch: 5| Step: 6
Training loss: 2.973271029408326
Validation loss: 2.7722160463149734

Epoch: 5| Step: 7
Training loss: 3.4100348766702404
Validation loss: 2.767113101427151

Epoch: 5| Step: 8
Training loss: 3.452635303141504
Validation loss: 2.7682101625335744

Epoch: 5| Step: 9
Training loss: 3.2674704270020576
Validation loss: 2.7657861390933953

Epoch: 5| Step: 10
Training loss: 2.7946745671780615
Validation loss: 2.767831837618914

Epoch: 84| Step: 0
Training loss: 2.9589481162691835
Validation loss: 2.764497117599038

Epoch: 5| Step: 1
Training loss: 3.2729745323525985
Validation loss: 2.7668846473214432

Epoch: 5| Step: 2
Training loss: 3.339676131119094
Validation loss: 2.7644181062721787

Epoch: 5| Step: 3
Training loss: 2.801332129619666
Validation loss: 2.765577822584639

Epoch: 5| Step: 4
Training loss: 3.329470367011049
Validation loss: 2.765688552066002

Epoch: 5| Step: 5
Training loss: 3.2949152179282186
Validation loss: 2.763947450099835

Epoch: 5| Step: 6
Training loss: 3.1923136547552646
Validation loss: 2.7618483688060067

Epoch: 5| Step: 7
Training loss: 3.0807172829320053
Validation loss: 2.7634254265964686

Epoch: 5| Step: 8
Training loss: 3.2503676573330766
Validation loss: 2.7630327424404935

Epoch: 5| Step: 9
Training loss: 2.6393247032567233
Validation loss: 2.761366518734367

Epoch: 5| Step: 10
Training loss: 2.508677110739297
Validation loss: 2.7674498556145366

Epoch: 85| Step: 0
Training loss: 3.0807482390190923
Validation loss: 2.780140275499141

Epoch: 5| Step: 1
Training loss: 3.3695683039240456
Validation loss: 2.7726406248435396

Epoch: 5| Step: 2
Training loss: 3.307582011456739
Validation loss: 2.7775786686023687

Epoch: 5| Step: 3
Training loss: 2.248551008104411
Validation loss: 2.7851619173011914

Epoch: 5| Step: 4
Training loss: 2.9659945901832967
Validation loss: 2.79945169689593

Epoch: 5| Step: 5
Training loss: 2.6607895600011444
Validation loss: 2.767953808841504

Epoch: 5| Step: 6
Training loss: 2.5614446001795197
Validation loss: 2.76404169839611

Epoch: 5| Step: 7
Training loss: 3.102035524825245
Validation loss: 2.7565254955309557

Epoch: 5| Step: 8
Training loss: 3.971571392517916
Validation loss: 2.7569442228563403

Epoch: 5| Step: 9
Training loss: 3.391483602496255
Validation loss: 2.7583543115728997

Epoch: 5| Step: 10
Training loss: 2.810901441867636
Validation loss: 2.757456311232422

Epoch: 86| Step: 0
Training loss: 3.123038324722504
Validation loss: 2.7578022186925213

Epoch: 5| Step: 1
Training loss: 3.049334975736593
Validation loss: 2.755950885981669

Epoch: 5| Step: 2
Training loss: 3.0267019859079327
Validation loss: 2.755039979366081

Epoch: 5| Step: 3
Training loss: 3.4841619178382564
Validation loss: 2.75355750599894

Epoch: 5| Step: 4
Training loss: 3.302832838290553
Validation loss: 2.751245360235263

Epoch: 5| Step: 5
Training loss: 2.526651797724768
Validation loss: 2.7495325983368013

Epoch: 5| Step: 6
Training loss: 3.174441947854434
Validation loss: 2.7481874643569157

Epoch: 5| Step: 7
Training loss: 2.723222233137554
Validation loss: 2.7451643551348734

Epoch: 5| Step: 8
Training loss: 3.3259432093026406
Validation loss: 2.7458724941298356

Epoch: 5| Step: 9
Training loss: 3.0983356437927574
Validation loss: 2.746017514510873

Epoch: 5| Step: 10
Training loss: 2.8939855887496444
Validation loss: 2.7464748817025058

Epoch: 87| Step: 0
Training loss: 3.0408980212688546
Validation loss: 2.7491284310246504

Epoch: 5| Step: 1
Training loss: 3.4798891760181334
Validation loss: 2.7478524172421817

Epoch: 5| Step: 2
Training loss: 2.5682427789599034
Validation loss: 2.746220638279812

Epoch: 5| Step: 3
Training loss: 2.734616078239765
Validation loss: 2.749157411992881

Epoch: 5| Step: 4
Training loss: 3.0771895018185895
Validation loss: 2.754972920081187

Epoch: 5| Step: 5
Training loss: 3.071546622000559
Validation loss: 2.753417698272488

Epoch: 5| Step: 6
Training loss: 3.333497202342078
Validation loss: 2.753225650669965

Epoch: 5| Step: 7
Training loss: 3.315219842171664
Validation loss: 2.7512015358840225

Epoch: 5| Step: 8
Training loss: 3.2548759270385466
Validation loss: 2.739330707906675

Epoch: 5| Step: 9
Training loss: 2.3879041958733254
Validation loss: 2.7377820312303993

Epoch: 5| Step: 10
Training loss: 3.3698554212306435
Validation loss: 2.7404173513342074

Epoch: 88| Step: 0
Training loss: 3.4777478886769906
Validation loss: 2.738585114125735

Epoch: 5| Step: 1
Training loss: 2.768727259833164
Validation loss: 2.740813036212289

Epoch: 5| Step: 2
Training loss: 3.1374056433361313
Validation loss: 2.7390272690603

Epoch: 5| Step: 3
Training loss: 3.1808974754602906
Validation loss: 2.739186260996969

Epoch: 5| Step: 4
Training loss: 3.178164855647109
Validation loss: 2.7377584490010296

Epoch: 5| Step: 5
Training loss: 2.7211505333065555
Validation loss: 2.7361489982647687

Epoch: 5| Step: 6
Training loss: 3.2326130513707603
Validation loss: 2.7370006343871944

Epoch: 5| Step: 7
Training loss: 2.6681639123805865
Validation loss: 2.7361455994688013

Epoch: 5| Step: 8
Training loss: 3.1489287719617716
Validation loss: 2.735438423159876

Epoch: 5| Step: 9
Training loss: 3.611295511151069
Validation loss: 2.7357636650271417

Epoch: 5| Step: 10
Training loss: 2.263965920019937
Validation loss: 2.7361277242154465

Epoch: 89| Step: 0
Training loss: 2.0417850486014397
Validation loss: 2.7358900939612805

Epoch: 5| Step: 1
Training loss: 3.468593147099409
Validation loss: 2.7355857463284146

Epoch: 5| Step: 2
Training loss: 3.5152347602424365
Validation loss: 2.7341461807821057

Epoch: 5| Step: 3
Training loss: 3.092534915168798
Validation loss: 2.742861652456778

Epoch: 5| Step: 4
Training loss: 2.824152817754557
Validation loss: 2.746105428798713

Epoch: 5| Step: 5
Training loss: 3.0677641176463606
Validation loss: 2.757573193096457

Epoch: 5| Step: 6
Training loss: 2.8589183672058005
Validation loss: 2.751616890118693

Epoch: 5| Step: 7
Training loss: 3.27809165450338
Validation loss: 2.7557218172283666

Epoch: 5| Step: 8
Training loss: 2.787125628182725
Validation loss: 2.7563520467179274

Epoch: 5| Step: 9
Training loss: 3.125403111207248
Validation loss: 2.747838755852324

Epoch: 5| Step: 10
Training loss: 3.381281764080454
Validation loss: 2.738333662045032

Epoch: 90| Step: 0
Training loss: 2.8772085248672625
Validation loss: 2.731527350349405

Epoch: 5| Step: 1
Training loss: 3.299430832763498
Validation loss: 2.729240467833708

Epoch: 5| Step: 2
Training loss: 2.804551995279473
Validation loss: 2.7279629758632473

Epoch: 5| Step: 3
Training loss: 3.5408456785783304
Validation loss: 2.7305772266226147

Epoch: 5| Step: 4
Training loss: 2.602681328926972
Validation loss: 2.7285254303701265

Epoch: 5| Step: 5
Training loss: 3.225030789487078
Validation loss: 2.7294437036444488

Epoch: 5| Step: 6
Training loss: 3.023796750196518
Validation loss: 2.7330018808107837

Epoch: 5| Step: 7
Training loss: 2.9120651640884447
Validation loss: 2.746347147307927

Epoch: 5| Step: 8
Training loss: 3.0457420394581765
Validation loss: 2.732519302836637

Epoch: 5| Step: 9
Training loss: 3.1309332407556774
Validation loss: 2.7278710597842912

Epoch: 5| Step: 10
Training loss: 3.0751284812819777
Validation loss: 2.728040956342212

Epoch: 91| Step: 0
Training loss: 2.891182180781042
Validation loss: 2.7261686935382614

Epoch: 5| Step: 1
Training loss: 3.0764153859471075
Validation loss: 2.722174203693466

Epoch: 5| Step: 2
Training loss: 2.9245037146897057
Validation loss: 2.7228870327874115

Epoch: 5| Step: 3
Training loss: 2.8082620692809215
Validation loss: 2.7244789029077783

Epoch: 5| Step: 4
Training loss: 3.1312845742149973
Validation loss: 2.7255404119471347

Epoch: 5| Step: 5
Training loss: 2.9948923818266233
Validation loss: 2.7261942859209247

Epoch: 5| Step: 6
Training loss: 3.142132753021403
Validation loss: 2.7233993291419964

Epoch: 5| Step: 7
Training loss: 3.810088473717017
Validation loss: 2.717605738517884

Epoch: 5| Step: 8
Training loss: 2.6768415369066014
Validation loss: 2.716117708589929

Epoch: 5| Step: 9
Training loss: 3.1042192356514193
Validation loss: 2.7152110371523115

Epoch: 5| Step: 10
Training loss: 2.8187064461398776
Validation loss: 2.7139182280700345

Epoch: 92| Step: 0
Training loss: 3.0981101705270495
Validation loss: 2.720513071651231

Epoch: 5| Step: 1
Training loss: 3.0684645821098533
Validation loss: 2.722055500462009

Epoch: 5| Step: 2
Training loss: 3.2877446884937327
Validation loss: 2.730851038210694

Epoch: 5| Step: 3
Training loss: 2.848962052718855
Validation loss: 2.734471865108756

Epoch: 5| Step: 4
Training loss: 2.204994112210187
Validation loss: 2.7597119580923755

Epoch: 5| Step: 5
Training loss: 3.3666799211398533
Validation loss: 2.7955253269909233

Epoch: 5| Step: 6
Training loss: 2.9279851825109886
Validation loss: 2.8149882731915343

Epoch: 5| Step: 7
Training loss: 3.443704588879713
Validation loss: 2.759389711753129

Epoch: 5| Step: 8
Training loss: 2.7482294104710627
Validation loss: 2.7307074261158033

Epoch: 5| Step: 9
Training loss: 3.039838912360019
Validation loss: 2.7100463321604322

Epoch: 5| Step: 10
Training loss: 3.337152550145758
Validation loss: 2.726384027865987

Epoch: 93| Step: 0
Training loss: 2.6156933519189884
Validation loss: 2.810514714227487

Epoch: 5| Step: 1
Training loss: 3.3557319227048734
Validation loss: 2.8435685583209347

Epoch: 5| Step: 2
Training loss: 3.2098162473094467
Validation loss: 2.8226193682919343

Epoch: 5| Step: 3
Training loss: 2.4749790267826346
Validation loss: 2.7928286864315006

Epoch: 5| Step: 4
Training loss: 3.624306053299163
Validation loss: 2.790693484148815

Epoch: 5| Step: 5
Training loss: 2.975913790602665
Validation loss: 2.7830773664788695

Epoch: 5| Step: 6
Training loss: 2.7323125417893332
Validation loss: 2.773571923831601

Epoch: 5| Step: 7
Training loss: 2.8828186200498216
Validation loss: 2.7636419664752663

Epoch: 5| Step: 8
Training loss: 3.1316265801068055
Validation loss: 2.731238330292283

Epoch: 5| Step: 9
Training loss: 3.481841119681172
Validation loss: 2.7379527538081785

Epoch: 5| Step: 10
Training loss: 3.3569470525298386
Validation loss: 2.7663239284808876

Epoch: 94| Step: 0
Training loss: 3.1608113481028726
Validation loss: 2.7773035589777075

Epoch: 5| Step: 1
Training loss: 3.135078504878385
Validation loss: 2.76768651341547

Epoch: 5| Step: 2
Training loss: 2.727742112110653
Validation loss: 2.724266464137529

Epoch: 5| Step: 3
Training loss: 2.8657359260879725
Validation loss: 2.7074018326335145

Epoch: 5| Step: 4
Training loss: 2.7466557715795528
Validation loss: 2.707926573076406

Epoch: 5| Step: 5
Training loss: 3.3330317042891857
Validation loss: 2.7069382803323667

Epoch: 5| Step: 6
Training loss: 3.4458530546928627
Validation loss: 2.7051368390411192

Epoch: 5| Step: 7
Training loss: 3.1903371712844852
Validation loss: 2.70767941843485

Epoch: 5| Step: 8
Training loss: 2.6856447070248524
Validation loss: 2.7078339664575526

Epoch: 5| Step: 9
Training loss: 3.0861989357216766
Validation loss: 2.7069976775674385

Epoch: 5| Step: 10
Training loss: 3.1504563137331725
Validation loss: 2.70736130876875

Epoch: 95| Step: 0
Training loss: 2.8456686066240366
Validation loss: 2.707135326630024

Epoch: 5| Step: 1
Training loss: 2.2411980655608033
Validation loss: 2.708736482121216

Epoch: 5| Step: 2
Training loss: 3.3252747558424796
Validation loss: 2.710100847302288

Epoch: 5| Step: 3
Training loss: 3.1852148503968265
Validation loss: 2.750011774077059

Epoch: 5| Step: 4
Training loss: 3.4203440407265457
Validation loss: 2.7773020737605547

Epoch: 5| Step: 5
Training loss: 3.435121025163383
Validation loss: 2.709856002536433

Epoch: 5| Step: 6
Training loss: 3.093187685639808
Validation loss: 2.698438559643463

Epoch: 5| Step: 7
Training loss: 2.9328261182547104
Validation loss: 2.700714861593471

Epoch: 5| Step: 8
Training loss: 2.7042379568741137
Validation loss: 2.7014773547727944

Epoch: 5| Step: 9
Training loss: 2.9256629257824374
Validation loss: 2.6967639659595015

Epoch: 5| Step: 10
Training loss: 3.260353615895612
Validation loss: 2.6977306464484374

Epoch: 96| Step: 0
Training loss: 2.880855402539634
Validation loss: 2.6991538237994437

Epoch: 5| Step: 1
Training loss: 2.875205157050431
Validation loss: 2.70683308044285

Epoch: 5| Step: 2
Training loss: 3.2891207800841618
Validation loss: 2.720813251678732

Epoch: 5| Step: 3
Training loss: 3.0436265109662908
Validation loss: 2.729297954786583

Epoch: 5| Step: 4
Training loss: 3.3929976498758423
Validation loss: 2.7361584450683245

Epoch: 5| Step: 5
Training loss: 3.207847872249646
Validation loss: 2.73684758538723

Epoch: 5| Step: 6
Training loss: 2.5080648039821702
Validation loss: 2.7382953438578927

Epoch: 5| Step: 7
Training loss: 3.4073480358648727
Validation loss: 2.7270698229348693

Epoch: 5| Step: 8
Training loss: 2.896713690191334
Validation loss: 2.704455462046906

Epoch: 5| Step: 9
Training loss: 3.0179734646974885
Validation loss: 2.6994236933792055

Epoch: 5| Step: 10
Training loss: 2.774532478058557
Validation loss: 2.691888630924865

Epoch: 97| Step: 0
Training loss: 3.257378345715123
Validation loss: 2.6933106890202363

Epoch: 5| Step: 1
Training loss: 2.990533516021718
Validation loss: 2.694878010136521

Epoch: 5| Step: 2
Training loss: 3.2569826381877665
Validation loss: 2.6999595364843216

Epoch: 5| Step: 3
Training loss: 3.066603422203834
Validation loss: 2.6987207123408123

Epoch: 5| Step: 4
Training loss: 2.969220415289635
Validation loss: 2.699777271741627

Epoch: 5| Step: 5
Training loss: 2.6859640123480175
Validation loss: 2.702699342154365

Epoch: 5| Step: 6
Training loss: 2.811895263083342
Validation loss: 2.701786207396221

Epoch: 5| Step: 7
Training loss: 3.5220154051392343
Validation loss: 2.69974472296781

Epoch: 5| Step: 8
Training loss: 2.53373586777753
Validation loss: 2.695689039782298

Epoch: 5| Step: 9
Training loss: 3.170417337954383
Validation loss: 2.7011762237021486

Epoch: 5| Step: 10
Training loss: 2.972001553798182
Validation loss: 2.7009826626629714

Epoch: 98| Step: 0
Training loss: 2.5920953643410063
Validation loss: 2.706672850118889

Epoch: 5| Step: 1
Training loss: 3.25447332196679
Validation loss: 2.700749296193045

Epoch: 5| Step: 2
Training loss: 3.1248637360428133
Validation loss: 2.7026097597763545

Epoch: 5| Step: 3
Training loss: 2.6523085129746966
Validation loss: 2.7005358650364375

Epoch: 5| Step: 4
Training loss: 3.307357106600165
Validation loss: 2.700126605329927

Epoch: 5| Step: 5
Training loss: 2.6115854916822063
Validation loss: 2.700358707887313

Epoch: 5| Step: 6
Training loss: 3.262407826257947
Validation loss: 2.706847116423121

Epoch: 5| Step: 7
Training loss: 3.355062724406891
Validation loss: 2.7024267137500306

Epoch: 5| Step: 8
Training loss: 2.6925665537083168
Validation loss: 2.707924739284588

Epoch: 5| Step: 9
Training loss: 3.3764292198613313
Validation loss: 2.7033039265920205

Epoch: 5| Step: 10
Training loss: 2.960461580784535
Validation loss: 2.702255132771514

Epoch: 99| Step: 0
Training loss: 3.0381722605061876
Validation loss: 2.6996180822173637

Epoch: 5| Step: 1
Training loss: 3.201427921949972
Validation loss: 2.6999018416949983

Epoch: 5| Step: 2
Training loss: 2.803795292726997
Validation loss: 2.7008488024661554

Epoch: 5| Step: 3
Training loss: 2.9544376100184784
Validation loss: 2.7043844989053234

Epoch: 5| Step: 4
Training loss: 2.8035921385870517
Validation loss: 2.705885422817138

Epoch: 5| Step: 5
Training loss: 2.6926359736289482
Validation loss: 2.6987061971173296

Epoch: 5| Step: 6
Training loss: 3.0401058808509727
Validation loss: 2.6920416390172184

Epoch: 5| Step: 7
Training loss: 3.3405712383858046
Validation loss: 2.677338161687873

Epoch: 5| Step: 8
Training loss: 2.9749238717733064
Validation loss: 2.675455574256517

Epoch: 5| Step: 9
Training loss: 3.019182231911036
Validation loss: 2.6777239470694205

Epoch: 5| Step: 10
Training loss: 3.289647428642308
Validation loss: 2.6780650003395503

Epoch: 100| Step: 0
Training loss: 3.0647128148908744
Validation loss: 2.6698643376874402

Epoch: 5| Step: 1
Training loss: 3.257713261471876
Validation loss: 2.6749185267007256

Epoch: 5| Step: 2
Training loss: 3.565738477581177
Validation loss: 2.675154243302788

Epoch: 5| Step: 3
Training loss: 3.2573367716015995
Validation loss: 2.676534197458886

Epoch: 5| Step: 4
Training loss: 2.4330722011165116
Validation loss: 2.6760148423912637

Epoch: 5| Step: 5
Training loss: 2.7835455004599985
Validation loss: 2.6773471232276953

Epoch: 5| Step: 6
Training loss: 2.8649840658387205
Validation loss: 2.6719215905690343

Epoch: 5| Step: 7
Training loss: 3.182895401262187
Validation loss: 2.6762360782294428

Epoch: 5| Step: 8
Training loss: 3.0044889244602966
Validation loss: 2.676418568726949

Epoch: 5| Step: 9
Training loss: 2.879143093102794
Validation loss: 2.6802351474590385

Epoch: 5| Step: 10
Training loss: 2.528141892120926
Validation loss: 2.6818537732883243

Epoch: 101| Step: 0
Training loss: 3.2592436576559756
Validation loss: 2.691579299779291

Epoch: 5| Step: 1
Training loss: 3.505268627326476
Validation loss: 2.682403067690649

Epoch: 5| Step: 2
Training loss: 2.929451487889407
Validation loss: 2.6674130808979477

Epoch: 5| Step: 3
Training loss: 2.9533206935408294
Validation loss: 2.6647778007460095

Epoch: 5| Step: 4
Training loss: 2.8753968669801324
Validation loss: 2.6586775861147185

Epoch: 5| Step: 5
Training loss: 1.875092440551669
Validation loss: 2.656208290385487

Epoch: 5| Step: 6
Training loss: 3.3414895090785826
Validation loss: 2.6590676879350146

Epoch: 5| Step: 7
Training loss: 3.055936358063782
Validation loss: 2.6572270439254755

Epoch: 5| Step: 8
Training loss: 3.1245426606263083
Validation loss: 2.6569016739969404

Epoch: 5| Step: 9
Training loss: 2.7555553503788426
Validation loss: 2.655595711142037

Epoch: 5| Step: 10
Training loss: 3.153105273908115
Validation loss: 2.655657132294538

Epoch: 102| Step: 0
Training loss: 3.3547624015530553
Validation loss: 2.654224446225212

Epoch: 5| Step: 1
Training loss: 3.085016890716065
Validation loss: 2.655155110170436

Epoch: 5| Step: 2
Training loss: 3.311184747959502
Validation loss: 2.6666150036801306

Epoch: 5| Step: 3
Training loss: 3.731393813232357
Validation loss: 2.6765217629979063

Epoch: 5| Step: 4
Training loss: 2.5223210466194104
Validation loss: 2.658360545067684

Epoch: 5| Step: 5
Training loss: 2.7352012040018723
Validation loss: 2.652696585454715

Epoch: 5| Step: 6
Training loss: 2.8486498863903815
Validation loss: 2.647651513383974

Epoch: 5| Step: 7
Training loss: 2.902920199788539
Validation loss: 2.6457952581108852

Epoch: 5| Step: 8
Training loss: 3.1058965040503312
Validation loss: 2.6481666630944827

Epoch: 5| Step: 9
Training loss: 2.610133078094634
Validation loss: 2.6453652016610887

Epoch: 5| Step: 10
Training loss: 2.5038315022420883
Validation loss: 2.644863436974643

Epoch: 103| Step: 0
Training loss: 2.7177123797264597
Validation loss: 2.6427334884695863

Epoch: 5| Step: 1
Training loss: 2.9986510422897314
Validation loss: 2.644237370929183

Epoch: 5| Step: 2
Training loss: 2.9082059123664448
Validation loss: 2.643464685472001

Epoch: 5| Step: 3
Training loss: 2.744256697945502
Validation loss: 2.6469050930255578

Epoch: 5| Step: 4
Training loss: 2.7979683896583945
Validation loss: 2.658908832143127

Epoch: 5| Step: 5
Training loss: 3.2217627194040226
Validation loss: 2.673651864758194

Epoch: 5| Step: 6
Training loss: 2.669720232589979
Validation loss: 2.686892784987267

Epoch: 5| Step: 7
Training loss: 3.5462487293842178
Validation loss: 2.6936208834835544

Epoch: 5| Step: 8
Training loss: 3.5153202179084673
Validation loss: 2.6474595043573563

Epoch: 5| Step: 9
Training loss: 2.8904882450230964
Validation loss: 2.6386353040770323

Epoch: 5| Step: 10
Training loss: 2.767251177786927
Validation loss: 2.6528695173019994

Epoch: 104| Step: 0
Training loss: 2.684511874420795
Validation loss: 2.6598247334573735

Epoch: 5| Step: 1
Training loss: 2.9574757976299475
Validation loss: 2.6465452452621414

Epoch: 5| Step: 2
Training loss: 3.0903816767643857
Validation loss: 2.646912215679074

Epoch: 5| Step: 3
Training loss: 2.887249269374894
Validation loss: 2.6460787021717453

Epoch: 5| Step: 4
Training loss: 2.9645635701153186
Validation loss: 2.6467041554018236

Epoch: 5| Step: 5
Training loss: 2.999371144824244
Validation loss: 2.6434043746596747

Epoch: 5| Step: 6
Training loss: 2.7709476954060808
Validation loss: 2.6426850426511206

Epoch: 5| Step: 7
Training loss: 2.87561078425216
Validation loss: 2.6406260815223983

Epoch: 5| Step: 8
Training loss: 3.114906949142919
Validation loss: 2.6427767562178155

Epoch: 5| Step: 9
Training loss: 3.057920652259495
Validation loss: 2.6491663010470687

Epoch: 5| Step: 10
Training loss: 3.4869349360301967
Validation loss: 2.650972897590401

Epoch: 105| Step: 0
Training loss: 2.900755579942976
Validation loss: 2.6603358106358383

Epoch: 5| Step: 1
Training loss: 3.0728465099192555
Validation loss: 2.6727303166963527

Epoch: 5| Step: 2
Training loss: 2.9581646580136303
Validation loss: 2.6733249754283164

Epoch: 5| Step: 3
Training loss: 3.1672341356951335
Validation loss: 2.6691099927671837

Epoch: 5| Step: 4
Training loss: 2.653669472621237
Validation loss: 2.6578248038453887

Epoch: 5| Step: 5
Training loss: 3.2786658874496313
Validation loss: 2.6463401340705337

Epoch: 5| Step: 6
Training loss: 3.4031363438889217
Validation loss: 2.6437183786769887

Epoch: 5| Step: 7
Training loss: 3.081565521984593
Validation loss: 2.6435094395734016

Epoch: 5| Step: 8
Training loss: 2.64120973512114
Validation loss: 2.6453104582061777

Epoch: 5| Step: 9
Training loss: 2.7365370567875353
Validation loss: 2.6422362441155474

Epoch: 5| Step: 10
Training loss: 2.8006969742485426
Validation loss: 2.6420030322724966

Epoch: 106| Step: 0
Training loss: 3.37719062071531
Validation loss: 2.640897757762073

Epoch: 5| Step: 1
Training loss: 3.18717042303686
Validation loss: 2.6416516896318205

Epoch: 5| Step: 2
Training loss: 3.321627008865226
Validation loss: 2.6354060317316197

Epoch: 5| Step: 3
Training loss: 2.8779308473127116
Validation loss: 2.6314350735259673

Epoch: 5| Step: 4
Training loss: 2.454879716307768
Validation loss: 2.6340357563910275

Epoch: 5| Step: 5
Training loss: 2.4801740336112528
Validation loss: 2.6392421957250285

Epoch: 5| Step: 6
Training loss: 3.3556192384309096
Validation loss: 2.6566101457406193

Epoch: 5| Step: 7
Training loss: 2.832897564157375
Validation loss: 2.659905345733666

Epoch: 5| Step: 8
Training loss: 2.428500557113813
Validation loss: 2.6590096795400786

Epoch: 5| Step: 9
Training loss: 2.5645782602871
Validation loss: 2.651037709893413

Epoch: 5| Step: 10
Training loss: 3.716931451394776
Validation loss: 2.642787712004094

Epoch: 107| Step: 0
Training loss: 2.700948026019348
Validation loss: 2.6329547552382553

Epoch: 5| Step: 1
Training loss: 2.717377941264591
Validation loss: 2.6275937118297077

Epoch: 5| Step: 2
Training loss: 3.2889781225259163
Validation loss: 2.6273928477549005

Epoch: 5| Step: 3
Training loss: 3.237140597274236
Validation loss: 2.62403159924896

Epoch: 5| Step: 4
Training loss: 2.2755921106808916
Validation loss: 2.6275766259992124

Epoch: 5| Step: 5
Training loss: 3.1265169657947394
Validation loss: 2.624484900873393

Epoch: 5| Step: 6
Training loss: 3.03734330138105
Validation loss: 2.624434957714822

Epoch: 5| Step: 7
Training loss: 2.8046058919185732
Validation loss: 2.625148958432207

Epoch: 5| Step: 8
Training loss: 2.9181207211304367
Validation loss: 2.6220261780190666

Epoch: 5| Step: 9
Training loss: 2.9880557704454715
Validation loss: 2.6241203256115226

Epoch: 5| Step: 10
Training loss: 3.579900043093729
Validation loss: 2.626521726654661

Epoch: 108| Step: 0
Training loss: 2.682257662560679
Validation loss: 2.6282614191210585

Epoch: 5| Step: 1
Training loss: 3.2542598390286157
Validation loss: 2.6277094963324044

Epoch: 5| Step: 2
Training loss: 2.571829861028122
Validation loss: 2.625316761904153

Epoch: 5| Step: 3
Training loss: 2.610425634792436
Validation loss: 2.624049246477408

Epoch: 5| Step: 4
Training loss: 3.2202586369866184
Validation loss: 2.6238314248853123

Epoch: 5| Step: 5
Training loss: 3.0826727872686552
Validation loss: 2.6225967256144123

Epoch: 5| Step: 6
Training loss: 3.2879166951822256
Validation loss: 2.62508225202244

Epoch: 5| Step: 7
Training loss: 3.265600761068088
Validation loss: 2.63215930034435

Epoch: 5| Step: 8
Training loss: 2.760746332792254
Validation loss: 2.6275790056507193

Epoch: 5| Step: 9
Training loss: 3.1192094177800525
Validation loss: 2.6295649442250184

Epoch: 5| Step: 10
Training loss: 2.679488461056205
Validation loss: 2.6233931280312492

Epoch: 109| Step: 0
Training loss: 3.3346104718394574
Validation loss: 2.628148487266998

Epoch: 5| Step: 1
Training loss: 2.654410589279106
Validation loss: 2.6244463026551488

Epoch: 5| Step: 2
Training loss: 3.2284798824964933
Validation loss: 2.621309307140107

Epoch: 5| Step: 3
Training loss: 2.3477039808349813
Validation loss: 2.6204833009429627

Epoch: 5| Step: 4
Training loss: 2.6780776813114797
Validation loss: 2.6228992545017693

Epoch: 5| Step: 5
Training loss: 3.0836581153617733
Validation loss: 2.616205035519872

Epoch: 5| Step: 6
Training loss: 3.010576043755476
Validation loss: 2.618070947182547

Epoch: 5| Step: 7
Training loss: 3.02937715228496
Validation loss: 2.6191127718388802

Epoch: 5| Step: 8
Training loss: 2.9117150554628424
Validation loss: 2.618597343871181

Epoch: 5| Step: 9
Training loss: 2.9589166916764063
Validation loss: 2.618516570143336

Epoch: 5| Step: 10
Training loss: 3.3450263608797566
Validation loss: 2.6165356748325865

Epoch: 110| Step: 0
Training loss: 3.0876829208983434
Validation loss: 2.624643871997113

Epoch: 5| Step: 1
Training loss: 3.2893854920460757
Validation loss: 2.6279793993808505

Epoch: 5| Step: 2
Training loss: 2.757938890019419
Validation loss: 2.6325620221295067

Epoch: 5| Step: 3
Training loss: 2.7391910538043787
Validation loss: 2.624003125831159

Epoch: 5| Step: 4
Training loss: 2.7093009296222887
Validation loss: 2.6258851359423265

Epoch: 5| Step: 5
Training loss: 2.7689503651059124
Validation loss: 2.64234031831593

Epoch: 5| Step: 6
Training loss: 2.7255969592329103
Validation loss: 2.6380421928628897

Epoch: 5| Step: 7
Training loss: 3.0112280538668967
Validation loss: 2.6387690908948125

Epoch: 5| Step: 8
Training loss: 3.466227120875262
Validation loss: 2.6421751309819905

Epoch: 5| Step: 9
Training loss: 2.916973715469216
Validation loss: 2.6263586201495857

Epoch: 5| Step: 10
Training loss: 3.045011136139549
Validation loss: 2.6145200847144303

Epoch: 111| Step: 0
Training loss: 3.5405352561734955
Validation loss: 2.6085996614958518

Epoch: 5| Step: 1
Training loss: 2.5323948096282844
Validation loss: 2.612288486973682

Epoch: 5| Step: 2
Training loss: 2.6949453794928213
Validation loss: 2.6100837403751944

Epoch: 5| Step: 3
Training loss: 3.640888777578662
Validation loss: 2.612997310293592

Epoch: 5| Step: 4
Training loss: 3.2582596213612063
Validation loss: 2.6135810140449145

Epoch: 5| Step: 5
Training loss: 2.8283012714565614
Validation loss: 2.6142802395955855

Epoch: 5| Step: 6
Training loss: 2.6586137912655117
Validation loss: 2.617765621566192

Epoch: 5| Step: 7
Training loss: 3.342297818011535
Validation loss: 2.623495256617495

Epoch: 5| Step: 8
Training loss: 1.7786132303119673
Validation loss: 2.6139003209785896

Epoch: 5| Step: 9
Training loss: 2.879367661993614
Validation loss: 2.6239425523551714

Epoch: 5| Step: 10
Training loss: 2.9332772603599917
Validation loss: 2.6300243669517513

Epoch: 112| Step: 0
Training loss: 2.8891548335916197
Validation loss: 2.621949699632611

Epoch: 5| Step: 1
Training loss: 2.6485777511144977
Validation loss: 2.6127529139032175

Epoch: 5| Step: 2
Training loss: 2.8107708171727417
Validation loss: 2.613157246128588

Epoch: 5| Step: 3
Training loss: 2.837007683212101
Validation loss: 2.6165587868629134

Epoch: 5| Step: 4
Training loss: 2.724975298848321
Validation loss: 2.612869202497268

Epoch: 5| Step: 5
Training loss: 3.428270468672516
Validation loss: 2.6098877214743013

Epoch: 5| Step: 6
Training loss: 2.8904959984939556
Validation loss: 2.6125447924872356

Epoch: 5| Step: 7
Training loss: 3.0378795370964236
Validation loss: 2.6209820625664895

Epoch: 5| Step: 8
Training loss: 2.767871440024301
Validation loss: 2.645709560936702

Epoch: 5| Step: 9
Training loss: 3.2851594432765396
Validation loss: 2.6722356177144575

Epoch: 5| Step: 10
Training loss: 3.2619092326022563
Validation loss: 2.687695174917614

Epoch: 113| Step: 0
Training loss: 3.1539580833441176
Validation loss: 2.6273225275034213

Epoch: 5| Step: 1
Training loss: 2.951757366640028
Validation loss: 2.6044958924588917

Epoch: 5| Step: 2
Training loss: 2.8933900547473947
Validation loss: 2.603073866078183

Epoch: 5| Step: 3
Training loss: 3.117762309451653
Validation loss: 2.6100436179225674

Epoch: 5| Step: 4
Training loss: 2.9724884587377463
Validation loss: 2.609592336586237

Epoch: 5| Step: 5
Training loss: 3.318363685896994
Validation loss: 2.6160365868257447

Epoch: 5| Step: 6
Training loss: 2.8012324652065557
Validation loss: 2.612514384373825

Epoch: 5| Step: 7
Training loss: 2.9502882477190098
Validation loss: 2.611720227333886

Epoch: 5| Step: 8
Training loss: 2.9312294119496203
Validation loss: 2.607352605039911

Epoch: 5| Step: 9
Training loss: 2.833612671340104
Validation loss: 2.6047284753692805

Epoch: 5| Step: 10
Training loss: 2.7266144405981243
Validation loss: 2.606507581056155

Epoch: 114| Step: 0
Training loss: 3.082707436071995
Validation loss: 2.6129743100051157

Epoch: 5| Step: 1
Training loss: 3.2593674276525473
Validation loss: 2.6254937771557776

Epoch: 5| Step: 2
Training loss: 2.210442908943529
Validation loss: 2.6110823156316223

Epoch: 5| Step: 3
Training loss: 3.1183000075576097
Validation loss: 2.6206498027523573

Epoch: 5| Step: 4
Training loss: 2.3295422023234535
Validation loss: 2.612169724862227

Epoch: 5| Step: 5
Training loss: 2.8896822655062016
Validation loss: 2.60747815130902

Epoch: 5| Step: 6
Training loss: 2.895160313253986
Validation loss: 2.6038250829980503

Epoch: 5| Step: 7
Training loss: 3.0341447988419
Validation loss: 2.604107952481484

Epoch: 5| Step: 8
Training loss: 2.841980268191107
Validation loss: 2.6024565156640813

Epoch: 5| Step: 9
Training loss: 3.287070497950431
Validation loss: 2.602038094795395

Epoch: 5| Step: 10
Training loss: 3.428582571783577
Validation loss: 2.60657900280948

Epoch: 115| Step: 0
Training loss: 3.034695741337618
Validation loss: 2.610786587203533

Epoch: 5| Step: 1
Training loss: 2.655313034856688
Validation loss: 2.609410433632724

Epoch: 5| Step: 2
Training loss: 3.193076846255622
Validation loss: 2.6196167276929643

Epoch: 5| Step: 3
Training loss: 2.6897245559630605
Validation loss: 2.6059165702941374

Epoch: 5| Step: 4
Training loss: 2.9305028162384428
Validation loss: 2.5992457233627215

Epoch: 5| Step: 5
Training loss: 2.9802477993441427
Validation loss: 2.598733812914564

Epoch: 5| Step: 6
Training loss: 3.437393325537635
Validation loss: 2.598052205692033

Epoch: 5| Step: 7
Training loss: 2.9065169345133346
Validation loss: 2.598129702289264

Epoch: 5| Step: 8
Training loss: 2.746444658022899
Validation loss: 2.599025546826671

Epoch: 5| Step: 9
Training loss: 2.966999381049554
Validation loss: 2.5968339374552007

Epoch: 5| Step: 10
Training loss: 2.9058076255222005
Validation loss: 2.5948989918750534

Epoch: 116| Step: 0
Training loss: 2.629316323480014
Validation loss: 2.594413176370369

Epoch: 5| Step: 1
Training loss: 3.0699091444954103
Validation loss: 2.592864971686052

Epoch: 5| Step: 2
Training loss: 2.8988015493766484
Validation loss: 2.597007825602804

Epoch: 5| Step: 3
Training loss: 2.961022207210996
Validation loss: 2.596640941547679

Epoch: 5| Step: 4
Training loss: 2.965759216422898
Validation loss: 2.5953620114844975

Epoch: 5| Step: 5
Training loss: 3.2604589165010815
Validation loss: 2.6035641704619232

Epoch: 5| Step: 6
Training loss: 2.6132224037832144
Validation loss: 2.6237894305120335

Epoch: 5| Step: 7
Training loss: 3.0290988486008055
Validation loss: 2.6485621131743384

Epoch: 5| Step: 8
Training loss: 3.0720730070637936
Validation loss: 2.6616983397990914

Epoch: 5| Step: 9
Training loss: 2.8904181329060727
Validation loss: 2.6761953966472425

Epoch: 5| Step: 10
Training loss: 3.090055629636866
Validation loss: 2.649437201227798

Epoch: 117| Step: 0
Training loss: 2.9597779270584543
Validation loss: 2.618689516315531

Epoch: 5| Step: 1
Training loss: 3.0190849418504935
Validation loss: 2.600524904338488

Epoch: 5| Step: 2
Training loss: 3.047497807940852
Validation loss: 2.596990872204532

Epoch: 5| Step: 3
Training loss: 2.8268619477845527
Validation loss: 2.5935707055025756

Epoch: 5| Step: 4
Training loss: 2.8941513409379493
Validation loss: 2.5959103509279235

Epoch: 5| Step: 5
Training loss: 2.718890307083595
Validation loss: 2.5957957963196923

Epoch: 5| Step: 6
Training loss: 2.6165412674355273
Validation loss: 2.6014274047946846

Epoch: 5| Step: 7
Training loss: 3.4807216496747695
Validation loss: 2.6020451570098855

Epoch: 5| Step: 8
Training loss: 3.1322969312066475
Validation loss: 2.6042108895433427

Epoch: 5| Step: 9
Training loss: 3.01256995535388
Validation loss: 2.6002056615530726

Epoch: 5| Step: 10
Training loss: 2.6915786311473284
Validation loss: 2.6012638837966127

Epoch: 118| Step: 0
Training loss: 3.06762764289748
Validation loss: 2.599988683119031

Epoch: 5| Step: 1
Training loss: 2.940741191518418
Validation loss: 2.6080031983891123

Epoch: 5| Step: 2
Training loss: 2.8301918528197145
Validation loss: 2.6013158506198466

Epoch: 5| Step: 3
Training loss: 3.352572486770828
Validation loss: 2.5993593951140586

Epoch: 5| Step: 4
Training loss: 2.659958617813485
Validation loss: 2.6101747873447523

Epoch: 5| Step: 5
Training loss: 3.0295868076316257
Validation loss: 2.6214149045686344

Epoch: 5| Step: 6
Training loss: 2.931303265378416
Validation loss: 2.6193511330895425

Epoch: 5| Step: 7
Training loss: 2.7522993878425734
Validation loss: 2.6128108591768546

Epoch: 5| Step: 8
Training loss: 3.2466833357281883
Validation loss: 2.60231011807831

Epoch: 5| Step: 9
Training loss: 2.942256566481402
Validation loss: 2.5974467018217338

Epoch: 5| Step: 10
Training loss: 2.585794496759918
Validation loss: 2.5987078945746545

Epoch: 119| Step: 0
Training loss: 2.9577635811913163
Validation loss: 2.5990232870169296

Epoch: 5| Step: 1
Training loss: 2.8714116134630827
Validation loss: 2.5949997641821962

Epoch: 5| Step: 2
Training loss: 3.1866738239777233
Validation loss: 2.594515085088308

Epoch: 5| Step: 3
Training loss: 2.6926192386332333
Validation loss: 2.5972084751861715

Epoch: 5| Step: 4
Training loss: 3.078690994818601
Validation loss: 2.6016124171302524

Epoch: 5| Step: 5
Training loss: 2.661576439513166
Validation loss: 2.5970071671725505

Epoch: 5| Step: 6
Training loss: 3.1389287666630885
Validation loss: 2.5971320250700463

Epoch: 5| Step: 7
Training loss: 3.07087729503232
Validation loss: 2.590160772097767

Epoch: 5| Step: 8
Training loss: 3.006353960995602
Validation loss: 2.59402013707028

Epoch: 5| Step: 9
Training loss: 2.585259847216642
Validation loss: 2.59417572165003

Epoch: 5| Step: 10
Training loss: 3.0095526875518215
Validation loss: 2.6007951184046747

Epoch: 120| Step: 0
Training loss: 2.430943498683736
Validation loss: 2.6057242092239474

Epoch: 5| Step: 1
Training loss: 3.212927134575997
Validation loss: 2.612836654300668

Epoch: 5| Step: 2
Training loss: 2.267790292413249
Validation loss: 2.596045955425763

Epoch: 5| Step: 3
Training loss: 3.0571145174778183
Validation loss: 2.610632302885723

Epoch: 5| Step: 4
Training loss: 2.81905744952405
Validation loss: 2.611706977787204

Epoch: 5| Step: 5
Training loss: 3.3008992732690383
Validation loss: 2.6030068480553967

Epoch: 5| Step: 6
Training loss: 3.474566831966224
Validation loss: 2.600070758121792

Epoch: 5| Step: 7
Training loss: 2.861132805833589
Validation loss: 2.6273377200688066

Epoch: 5| Step: 8
Training loss: 2.804447599474057
Validation loss: 2.609763840741731

Epoch: 5| Step: 9
Training loss: 3.2111624757236443
Validation loss: 2.604228720305071

Epoch: 5| Step: 10
Training loss: 2.5395853765999448
Validation loss: 2.597168260435318

Epoch: 121| Step: 0
Training loss: 3.354342785746858
Validation loss: 2.5916577887985617

Epoch: 5| Step: 1
Training loss: 3.176807045518435
Validation loss: 2.5899220168355646

Epoch: 5| Step: 2
Training loss: 3.137398956009178
Validation loss: 2.5854675908945395

Epoch: 5| Step: 3
Training loss: 3.1907623650014534
Validation loss: 2.5893952885248344

Epoch: 5| Step: 4
Training loss: 2.972779440614299
Validation loss: 2.5868564647410928

Epoch: 5| Step: 5
Training loss: 2.0565568086330632
Validation loss: 2.5843797678736755

Epoch: 5| Step: 6
Training loss: 3.0691832195839948
Validation loss: 2.5882835550834895

Epoch: 5| Step: 7
Training loss: 2.4387413189771134
Validation loss: 2.581899334916344

Epoch: 5| Step: 8
Training loss: 3.0915494857201056
Validation loss: 2.5823393870201334

Epoch: 5| Step: 9
Training loss: 3.1011618252096578
Validation loss: 2.5822780476848166

Epoch: 5| Step: 10
Training loss: 2.417033814351135
Validation loss: 2.6055650898185774

Epoch: 122| Step: 0
Training loss: 2.4426596391998774
Validation loss: 2.627315328323905

Epoch: 5| Step: 1
Training loss: 3.2647876304737995
Validation loss: 2.6060526427681703

Epoch: 5| Step: 2
Training loss: 2.3796290409875196
Validation loss: 2.5959617247474456

Epoch: 5| Step: 3
Training loss: 3.0446396673063547
Validation loss: 2.5885201756553795

Epoch: 5| Step: 4
Training loss: 2.971485203030399
Validation loss: 2.584730778268268

Epoch: 5| Step: 5
Training loss: 3.17222706010683
Validation loss: 2.5816650061377366

Epoch: 5| Step: 6
Training loss: 2.304935144600166
Validation loss: 2.5841781926359273

Epoch: 5| Step: 7
Training loss: 2.604171040849191
Validation loss: 2.5839988104073566

Epoch: 5| Step: 8
Training loss: 3.5300026099868074
Validation loss: 2.582752905537039

Epoch: 5| Step: 9
Training loss: 3.519039953830487
Validation loss: 2.5805684552213806

Epoch: 5| Step: 10
Training loss: 2.7407366182918684
Validation loss: 2.580105448661195

Epoch: 123| Step: 0
Training loss: 3.3405800883286854
Validation loss: 2.583997858962715

Epoch: 5| Step: 1
Training loss: 3.1331063986499452
Validation loss: 2.5816652673015406

Epoch: 5| Step: 2
Training loss: 3.174126488379661
Validation loss: 2.580852840639823

Epoch: 5| Step: 3
Training loss: 2.6605955592993786
Validation loss: 2.5828433010333103

Epoch: 5| Step: 4
Training loss: 3.413449299998057
Validation loss: 2.594276683127069

Epoch: 5| Step: 5
Training loss: 2.5727616442312224
Validation loss: 2.596738184943751

Epoch: 5| Step: 6
Training loss: 3.445228350729727
Validation loss: 2.587953866010604

Epoch: 5| Step: 7
Training loss: 2.374818292994993
Validation loss: 2.58649668657652

Epoch: 5| Step: 8
Training loss: 2.5907371211436296
Validation loss: 2.5908382977574997

Epoch: 5| Step: 9
Training loss: 2.7979511769188594
Validation loss: 2.589734332032159

Epoch: 5| Step: 10
Training loss: 2.3446453164612473
Validation loss: 2.594962696337866

Epoch: 124| Step: 0
Training loss: 2.8829253053175066
Validation loss: 2.6070229516788808

Epoch: 5| Step: 1
Training loss: 2.9404596880215657
Validation loss: 2.6257028122293615

Epoch: 5| Step: 2
Training loss: 3.1449937184184646
Validation loss: 2.637397688546452

Epoch: 5| Step: 3
Training loss: 3.4672053566567835
Validation loss: 2.618077096612646

Epoch: 5| Step: 4
Training loss: 2.669164520875765
Validation loss: 2.59171702474477

Epoch: 5| Step: 5
Training loss: 2.7321088719324567
Validation loss: 2.5747442557936013

Epoch: 5| Step: 6
Training loss: 2.9043492490128835
Validation loss: 2.5701905185542047

Epoch: 5| Step: 7
Training loss: 2.6873107666106564
Validation loss: 2.5719333324137668

Epoch: 5| Step: 8
Training loss: 2.7152523474276165
Validation loss: 2.572726857759714

Epoch: 5| Step: 9
Training loss: 3.3943500360685253
Validation loss: 2.5747933825454923

Epoch: 5| Step: 10
Training loss: 2.6979646322535196
Validation loss: 2.574724631714152

Epoch: 125| Step: 0
Training loss: 3.0312378873288117
Validation loss: 2.572804396768296

Epoch: 5| Step: 1
Training loss: 3.3747872179560434
Validation loss: 2.5750351931792057

Epoch: 5| Step: 2
Training loss: 2.9788842945505327
Validation loss: 2.5767951366945474

Epoch: 5| Step: 3
Training loss: 2.925299448188555
Validation loss: 2.580985353527579

Epoch: 5| Step: 4
Training loss: 2.9770603514510148
Validation loss: 2.5941426266256

Epoch: 5| Step: 5
Training loss: 2.7976310177037753
Validation loss: 2.6019679593048743

Epoch: 5| Step: 6
Training loss: 2.517506245488865
Validation loss: 2.610523446910371

Epoch: 5| Step: 7
Training loss: 3.26763620456079
Validation loss: 2.631788276875341

Epoch: 5| Step: 8
Training loss: 2.7160870017498002
Validation loss: 2.655779984817606

Epoch: 5| Step: 9
Training loss: 2.941971318046125
Validation loss: 2.635444802604179

Epoch: 5| Step: 10
Training loss: 2.6234995777267196
Validation loss: 2.593956849258554

Epoch: 126| Step: 0
Training loss: 2.9542147124507965
Validation loss: 2.5768160473131227

Epoch: 5| Step: 1
Training loss: 2.9504036449426407
Validation loss: 2.5669337097234313

Epoch: 5| Step: 2
Training loss: 2.875198854949927
Validation loss: 2.566459376137908

Epoch: 5| Step: 3
Training loss: 2.9969406423052454
Validation loss: 2.567062343262579

Epoch: 5| Step: 4
Training loss: 3.1635018311120384
Validation loss: 2.5630424899710404

Epoch: 5| Step: 5
Training loss: 3.0141868522150244
Validation loss: 2.566116845869426

Epoch: 5| Step: 6
Training loss: 2.752341400760511
Validation loss: 2.5657352340642694

Epoch: 5| Step: 7
Training loss: 3.029380300370434
Validation loss: 2.5645271299775945

Epoch: 5| Step: 8
Training loss: 2.854650878671352
Validation loss: 2.565991160187781

Epoch: 5| Step: 9
Training loss: 2.977518403759507
Validation loss: 2.567209192056694

Epoch: 5| Step: 10
Training loss: 2.588610509395774
Validation loss: 2.560426292647315

Epoch: 127| Step: 0
Training loss: 2.290686230016767
Validation loss: 2.563764194772755

Epoch: 5| Step: 1
Training loss: 3.2335221645102274
Validation loss: 2.57243651138261

Epoch: 5| Step: 2
Training loss: 3.1259872402972895
Validation loss: 2.567098472286357

Epoch: 5| Step: 3
Training loss: 2.508237428405337
Validation loss: 2.5748887538723775

Epoch: 5| Step: 4
Training loss: 3.2293169212249766
Validation loss: 2.5763337804831057

Epoch: 5| Step: 5
Training loss: 2.344942018650205
Validation loss: 2.571982884646554

Epoch: 5| Step: 6
Training loss: 3.1486748163410043
Validation loss: 2.573974643611991

Epoch: 5| Step: 7
Training loss: 2.740456580942981
Validation loss: 2.5844755522158844

Epoch: 5| Step: 8
Training loss: 3.2997327233940332
Validation loss: 2.6020768214661474

Epoch: 5| Step: 9
Training loss: 3.0088066538860136
Validation loss: 2.5877163783126265

Epoch: 5| Step: 10
Training loss: 2.8740045233832263
Validation loss: 2.5754926650469097

Epoch: 128| Step: 0
Training loss: 2.748538235655696
Validation loss: 2.576407452657501

Epoch: 5| Step: 1
Training loss: 3.6102263532352423
Validation loss: 2.578562539598569

Epoch: 5| Step: 2
Training loss: 3.3705634167416068
Validation loss: 2.5809674197983465

Epoch: 5| Step: 3
Training loss: 2.6819865426644034
Validation loss: 2.5715204277990025

Epoch: 5| Step: 4
Training loss: 3.2244950660671368
Validation loss: 2.575881541727441

Epoch: 5| Step: 5
Training loss: 2.9416648072262976
Validation loss: 2.5672777227468337

Epoch: 5| Step: 6
Training loss: 2.5191150410223
Validation loss: 2.5693691724508683

Epoch: 5| Step: 7
Training loss: 2.492533883923367
Validation loss: 2.570999169981997

Epoch: 5| Step: 8
Training loss: 2.9987629883243594
Validation loss: 2.5850907665005938

Epoch: 5| Step: 9
Training loss: 2.614170989289468
Validation loss: 2.5864848748563

Epoch: 5| Step: 10
Training loss: 2.6878137627128416
Validation loss: 2.590691871017011

Epoch: 129| Step: 0
Training loss: 2.508403862841355
Validation loss: 2.5927221636550217

Epoch: 5| Step: 1
Training loss: 2.8221813994514795
Validation loss: 2.6099888997605487

Epoch: 5| Step: 2
Training loss: 3.306234804634121
Validation loss: 2.617746242631635

Epoch: 5| Step: 3
Training loss: 3.3456703447204705
Validation loss: 2.6164775955126616

Epoch: 5| Step: 4
Training loss: 2.4900189474832684
Validation loss: 2.595268451448519

Epoch: 5| Step: 5
Training loss: 2.9141737684018443
Validation loss: 2.576215395897657

Epoch: 5| Step: 6
Training loss: 2.426670568728541
Validation loss: 2.561408353874405

Epoch: 5| Step: 7
Training loss: 3.074774143019063
Validation loss: 2.557367334277477

Epoch: 5| Step: 8
Training loss: 3.2427789723101443
Validation loss: 2.557104528714377

Epoch: 5| Step: 9
Training loss: 2.4770108848951713
Validation loss: 2.5567271066791957

Epoch: 5| Step: 10
Training loss: 3.4324807716492307
Validation loss: 2.5579149237623375

Epoch: 130| Step: 0
Training loss: 2.8529963820548505
Validation loss: 2.5602023310571584

Epoch: 5| Step: 1
Training loss: 3.230345053651299
Validation loss: 2.555422028002762

Epoch: 5| Step: 2
Training loss: 2.460048648229147
Validation loss: 2.55620828002739

Epoch: 5| Step: 3
Training loss: 2.8801674221966356
Validation loss: 2.5524892188327586

Epoch: 5| Step: 4
Training loss: 2.254469987789211
Validation loss: 2.5590799523024224

Epoch: 5| Step: 5
Training loss: 2.97351703387087
Validation loss: 2.5691907199976316

Epoch: 5| Step: 6
Training loss: 3.068718960171908
Validation loss: 2.5682647773748597

Epoch: 5| Step: 7
Training loss: 2.701583334476758
Validation loss: 2.565103737245112

Epoch: 5| Step: 8
Training loss: 3.2040548324083953
Validation loss: 2.563256534976176

Epoch: 5| Step: 9
Training loss: 2.860488591374606
Validation loss: 2.562223972327584

Epoch: 5| Step: 10
Training loss: 3.5331206641583077
Validation loss: 2.561567067160558

Epoch: 131| Step: 0
Training loss: 3.4866526733127357
Validation loss: 2.5652802824096876

Epoch: 5| Step: 1
Training loss: 2.9295076442188406
Validation loss: 2.566889247451006

Epoch: 5| Step: 2
Training loss: 3.066632032889907
Validation loss: 2.576160645864142

Epoch: 5| Step: 3
Training loss: 2.458388397979421
Validation loss: 2.5543035453428757

Epoch: 5| Step: 4
Training loss: 3.1236838048521034
Validation loss: 2.549508881974192

Epoch: 5| Step: 5
Training loss: 2.8333472831233073
Validation loss: 2.548685480845035

Epoch: 5| Step: 6
Training loss: 2.6987233569909237
Validation loss: 2.5503446146254802

Epoch: 5| Step: 7
Training loss: 2.3712016400044544
Validation loss: 2.549184185563065

Epoch: 5| Step: 8
Training loss: 3.10674139852508
Validation loss: 2.554022878757482

Epoch: 5| Step: 9
Training loss: 3.021990447023593
Validation loss: 2.5568219757631985

Epoch: 5| Step: 10
Training loss: 2.805338834401214
Validation loss: 2.558376465035982

Epoch: 132| Step: 0
Training loss: 2.824730622268061
Validation loss: 2.561566862995414

Epoch: 5| Step: 1
Training loss: 2.3766351391527816
Validation loss: 2.5626413449918535

Epoch: 5| Step: 2
Training loss: 2.674552334555654
Validation loss: 2.5610259984263637

Epoch: 5| Step: 3
Training loss: 2.77379921716911
Validation loss: 2.5798240405413777

Epoch: 5| Step: 4
Training loss: 3.132961050873289
Validation loss: 2.587980814294984

Epoch: 5| Step: 5
Training loss: 2.896807353558039
Validation loss: 2.598069086052552

Epoch: 5| Step: 6
Training loss: 3.031240246943878
Validation loss: 2.638141128655509

Epoch: 5| Step: 7
Training loss: 2.116076751665499
Validation loss: 2.5966502595848855

Epoch: 5| Step: 8
Training loss: 3.6138559245284685
Validation loss: 2.5791356984042833

Epoch: 5| Step: 9
Training loss: 3.316304163715146
Validation loss: 2.5691545710025587

Epoch: 5| Step: 10
Training loss: 3.0033266378900354
Validation loss: 2.5476110942144747

Epoch: 133| Step: 0
Training loss: 2.867398204908962
Validation loss: 2.548633034358775

Epoch: 5| Step: 1
Training loss: 3.014089559114216
Validation loss: 2.550849513505266

Epoch: 5| Step: 2
Training loss: 3.004502414630663
Validation loss: 2.555339313499387

Epoch: 5| Step: 3
Training loss: 2.9001232910256443
Validation loss: 2.563878265737067

Epoch: 5| Step: 4
Training loss: 3.308065360976883
Validation loss: 2.571777159833723

Epoch: 5| Step: 5
Training loss: 2.7479005949539976
Validation loss: 2.559016351117807

Epoch: 5| Step: 6
Training loss: 3.320209384887807
Validation loss: 2.5528595745678406

Epoch: 5| Step: 7
Training loss: 2.988587128187183
Validation loss: 2.5459612192249956

Epoch: 5| Step: 8
Training loss: 2.374721410373433
Validation loss: 2.5484115391531716

Epoch: 5| Step: 9
Training loss: 2.7094083755355824
Validation loss: 2.5449197333616502

Epoch: 5| Step: 10
Training loss: 2.773356777682002
Validation loss: 2.5479758952314184

Epoch: 134| Step: 0
Training loss: 3.4641426349020747
Validation loss: 2.5652837092156893

Epoch: 5| Step: 1
Training loss: 2.7845828200339846
Validation loss: 2.5642209180765705

Epoch: 5| Step: 2
Training loss: 2.39614669298526
Validation loss: 2.586204247130905

Epoch: 5| Step: 3
Training loss: 2.7380244723745664
Validation loss: 2.6005295928780408

Epoch: 5| Step: 4
Training loss: 2.824126478194213
Validation loss: 2.637287990266549

Epoch: 5| Step: 5
Training loss: 3.108349808418309
Validation loss: 2.6366625027447173

Epoch: 5| Step: 6
Training loss: 3.2698348803346815
Validation loss: 2.610189064158146

Epoch: 5| Step: 7
Training loss: 3.0223834741184024
Validation loss: 2.5784559676949272

Epoch: 5| Step: 8
Training loss: 2.6908018543634538
Validation loss: 2.560583137504545

Epoch: 5| Step: 9
Training loss: 2.4668434603800904
Validation loss: 2.5442884335864417

Epoch: 5| Step: 10
Training loss: 3.026186302173319
Validation loss: 2.545263517785434

Epoch: 135| Step: 0
Training loss: 2.3362202042689537
Validation loss: 2.551684834196916

Epoch: 5| Step: 1
Training loss: 3.119207124711828
Validation loss: 2.5532212515412382

Epoch: 5| Step: 2
Training loss: 3.0287950150454326
Validation loss: 2.5623203487734654

Epoch: 5| Step: 3
Training loss: 3.002689110027792
Validation loss: 2.5574973892267394

Epoch: 5| Step: 4
Training loss: 2.856967266681686
Validation loss: 2.556168198512099

Epoch: 5| Step: 5
Training loss: 3.379449948354048
Validation loss: 2.555994846368519

Epoch: 5| Step: 6
Training loss: 2.659210350596715
Validation loss: 2.5644923912547117

Epoch: 5| Step: 7
Training loss: 2.5098241420707335
Validation loss: 2.575528741009414

Epoch: 5| Step: 8
Training loss: 2.4922509260088836
Validation loss: 2.576984422447372

Epoch: 5| Step: 9
Training loss: 3.2322364408196984
Validation loss: 2.5878186200975732

Epoch: 5| Step: 10
Training loss: 3.3746234542459366
Validation loss: 2.5947721651307676

Epoch: 136| Step: 0
Training loss: 2.5363178148975147
Validation loss: 2.5988955162887892

Epoch: 5| Step: 1
Training loss: 2.9263506387500944
Validation loss: 2.5964810142140573

Epoch: 5| Step: 2
Training loss: 2.850780139357313
Validation loss: 2.602144133879983

Epoch: 5| Step: 3
Training loss: 2.515837855840937
Validation loss: 2.6009899463870156

Epoch: 5| Step: 4
Training loss: 2.681254382007637
Validation loss: 2.583891254267216

Epoch: 5| Step: 5
Training loss: 3.388473179513341
Validation loss: 2.5732449979724534

Epoch: 5| Step: 6
Training loss: 3.1579834360916768
Validation loss: 2.556395329486339

Epoch: 5| Step: 7
Training loss: 3.2448761971343383
Validation loss: 2.555934531777072

Epoch: 5| Step: 8
Training loss: 3.1463116078034035
Validation loss: 2.5510900262462224

Epoch: 5| Step: 9
Training loss: 2.151402982672879
Validation loss: 2.5474491037271534

Epoch: 5| Step: 10
Training loss: 3.0488731679087833
Validation loss: 2.5459879826516323

Epoch: 137| Step: 0
Training loss: 2.9371985422838605
Validation loss: 2.548705449254205

Epoch: 5| Step: 1
Training loss: 3.0243492624536126
Validation loss: 2.5455542362785435

Epoch: 5| Step: 2
Training loss: 2.9827930991339664
Validation loss: 2.54572791620143

Epoch: 5| Step: 3
Training loss: 2.4739391982024515
Validation loss: 2.5463301166796293

Epoch: 5| Step: 4
Training loss: 3.213245314293495
Validation loss: 2.550187999576057

Epoch: 5| Step: 5
Training loss: 2.628416018526933
Validation loss: 2.5452359671442797

Epoch: 5| Step: 6
Training loss: 3.0176176296969133
Validation loss: 2.548532170918094

Epoch: 5| Step: 7
Training loss: 2.950437261212079
Validation loss: 2.549882443971861

Epoch: 5| Step: 8
Training loss: 2.598839053141479
Validation loss: 2.549401978452753

Epoch: 5| Step: 9
Training loss: 3.075582005696985
Validation loss: 2.5423046469965085

Epoch: 5| Step: 10
Training loss: 2.8457522208037496
Validation loss: 2.5397137115858928

Epoch: 138| Step: 0
Training loss: 2.6144733988433075
Validation loss: 2.54230051359278

Epoch: 5| Step: 1
Training loss: 3.4570180084492166
Validation loss: 2.552621590711272

Epoch: 5| Step: 2
Training loss: 2.66283453330657
Validation loss: 2.554827495089711

Epoch: 5| Step: 3
Training loss: 2.5121488069510094
Validation loss: 2.552369115087785

Epoch: 5| Step: 4
Training loss: 3.299280382936111
Validation loss: 2.5561345512169797

Epoch: 5| Step: 5
Training loss: 2.4243909011874
Validation loss: 2.562955744264033

Epoch: 5| Step: 6
Training loss: 2.7216972950015763
Validation loss: 2.5980301753096677

Epoch: 5| Step: 7
Training loss: 2.898630634464093
Validation loss: 2.605562114966052

Epoch: 5| Step: 8
Training loss: 3.3611374600921584
Validation loss: 2.6013098596559407

Epoch: 5| Step: 9
Training loss: 3.217907100789885
Validation loss: 2.536087433178979

Epoch: 5| Step: 10
Training loss: 2.4327368536466447
Validation loss: 2.5224267724804563

Epoch: 139| Step: 0
Training loss: 2.9964919242221746
Validation loss: 2.5288600579749794

Epoch: 5| Step: 1
Training loss: 2.637645417313166
Validation loss: 2.5454343275220266

Epoch: 5| Step: 2
Training loss: 2.7635294415869396
Validation loss: 2.5815776696926354

Epoch: 5| Step: 3
Training loss: 2.847133258783987
Validation loss: 2.614713928258284

Epoch: 5| Step: 4
Training loss: 2.931311073561684
Validation loss: 2.598973652577111

Epoch: 5| Step: 5
Training loss: 2.590253656551717
Validation loss: 2.583935278137431

Epoch: 5| Step: 6
Training loss: 3.3731202436197676
Validation loss: 2.551075265942901

Epoch: 5| Step: 7
Training loss: 3.0959759035478815
Validation loss: 2.5390016297016325

Epoch: 5| Step: 8
Training loss: 3.00704621301121
Validation loss: 2.5381186665383235

Epoch: 5| Step: 9
Training loss: 3.199398943958083
Validation loss: 2.5417446956293515

Epoch: 5| Step: 10
Training loss: 2.7786329150532696
Validation loss: 2.5549148559254147

Epoch: 140| Step: 0
Training loss: 2.8285899754806545
Validation loss: 2.5670594281517394

Epoch: 5| Step: 1
Training loss: 3.0261656603903853
Validation loss: 2.6114643062120084

Epoch: 5| Step: 2
Training loss: 3.1292468396382906
Validation loss: 2.6122206444610048

Epoch: 5| Step: 3
Training loss: 3.4880711405699922
Validation loss: 2.630168107849221

Epoch: 5| Step: 4
Training loss: 2.667922727486703
Validation loss: 2.6064317076222587

Epoch: 5| Step: 5
Training loss: 2.3609052331462737
Validation loss: 2.582897162027714

Epoch: 5| Step: 6
Training loss: 3.159634578919253
Validation loss: 2.5725195720550755

Epoch: 5| Step: 7
Training loss: 3.359255056679626
Validation loss: 2.5610256170373598

Epoch: 5| Step: 8
Training loss: 2.2657784245600143
Validation loss: 2.5501061608231175

Epoch: 5| Step: 9
Training loss: 2.565910953472213
Validation loss: 2.5489082436673196

Epoch: 5| Step: 10
Training loss: 2.809156931729472
Validation loss: 2.547742416965841

Epoch: 141| Step: 0
Training loss: 2.926642297572331
Validation loss: 2.54422880477183

Epoch: 5| Step: 1
Training loss: 3.1548408913128267
Validation loss: 2.549402132810061

Epoch: 5| Step: 2
Training loss: 2.4861355667284806
Validation loss: 2.542518707586338

Epoch: 5| Step: 3
Training loss: 2.6911085874946594
Validation loss: 2.542928368062689

Epoch: 5| Step: 4
Training loss: 3.0331507750130724
Validation loss: 2.544801672507643

Epoch: 5| Step: 5
Training loss: 2.4978233398446643
Validation loss: 2.553067054702987

Epoch: 5| Step: 6
Training loss: 2.559375626001526
Validation loss: 2.5718062752613724

Epoch: 5| Step: 7
Training loss: 3.1099903513767915
Validation loss: 2.600986563667142

Epoch: 5| Step: 8
Training loss: 3.1870736229648418
Validation loss: 2.6216634131288576

Epoch: 5| Step: 9
Training loss: 3.366836423339554
Validation loss: 2.6134392379592106

Epoch: 5| Step: 10
Training loss: 2.6122346843716264
Validation loss: 2.5788935008452114

Epoch: 142| Step: 0
Training loss: 2.787539795732604
Validation loss: 2.55588747991105

Epoch: 5| Step: 1
Training loss: 2.6955167388934056
Validation loss: 2.5459694721254853

Epoch: 5| Step: 2
Training loss: 2.925218270789839
Validation loss: 2.544771437144191

Epoch: 5| Step: 3
Training loss: 3.338856190799747
Validation loss: 2.5353944626929437

Epoch: 5| Step: 4
Training loss: 2.7471011228220212
Validation loss: 2.535762181342126

Epoch: 5| Step: 5
Training loss: 2.7760629181946053
Validation loss: 2.5315480575180844

Epoch: 5| Step: 6
Training loss: 2.6775487255289656
Validation loss: 2.52663495262417

Epoch: 5| Step: 7
Training loss: 3.307768988019052
Validation loss: 2.5367830086421184

Epoch: 5| Step: 8
Training loss: 2.472060868597154
Validation loss: 2.5338195586623695

Epoch: 5| Step: 9
Training loss: 3.0145954489491946
Validation loss: 2.5349353794117726

Epoch: 5| Step: 10
Training loss: 2.7714036818216767
Validation loss: 2.5430183303108045

Epoch: 143| Step: 0
Training loss: 2.6324406482928855
Validation loss: 2.5548632106217832

Epoch: 5| Step: 1
Training loss: 3.0176950574026953
Validation loss: 2.581605091682435

Epoch: 5| Step: 2
Training loss: 2.6942649685402373
Validation loss: 2.62429298356672

Epoch: 5| Step: 3
Training loss: 3.173088405383838
Validation loss: 2.6205915866760945

Epoch: 5| Step: 4
Training loss: 2.9224063165821446
Validation loss: 2.5880806841473607

Epoch: 5| Step: 5
Training loss: 2.5706676481285964
Validation loss: 2.5496677186211048

Epoch: 5| Step: 6
Training loss: 3.175621488524554
Validation loss: 2.535143478060287

Epoch: 5| Step: 7
Training loss: 2.3097673715152265
Validation loss: 2.5202055501681455

Epoch: 5| Step: 8
Training loss: 3.488016321389045
Validation loss: 2.518300512808808

Epoch: 5| Step: 9
Training loss: 2.6913420250126823
Validation loss: 2.518373225766929

Epoch: 5| Step: 10
Training loss: 2.875317431631089
Validation loss: 2.5205393600887724

Epoch: 144| Step: 0
Training loss: 2.718128177082225
Validation loss: 2.523997682607628

Epoch: 5| Step: 1
Training loss: 2.3816521492745415
Validation loss: 2.5297166744637685

Epoch: 5| Step: 2
Training loss: 3.037295889570323
Validation loss: 2.532907370515761

Epoch: 5| Step: 3
Training loss: 2.6827682713643672
Validation loss: 2.5415154645282905

Epoch: 5| Step: 4
Training loss: 2.9457041027278414
Validation loss: 2.549183761169863

Epoch: 5| Step: 5
Training loss: 2.6817228633887074
Validation loss: 2.546649754046668

Epoch: 5| Step: 6
Training loss: 2.989915109405315
Validation loss: 2.5500011703871364

Epoch: 5| Step: 7
Training loss: 3.22870998639852
Validation loss: 2.5519888268744784

Epoch: 5| Step: 8
Training loss: 3.1250531001347976
Validation loss: 2.5302985157850615

Epoch: 5| Step: 9
Training loss: 3.0815126009263647
Validation loss: 2.5284808593929573

Epoch: 5| Step: 10
Training loss: 2.538397505314921
Validation loss: 2.5299342037408126

Epoch: 145| Step: 0
Training loss: 3.0752046160346724
Validation loss: 2.5181700287690574

Epoch: 5| Step: 1
Training loss: 2.6041592305395134
Validation loss: 2.5185376660933243

Epoch: 5| Step: 2
Training loss: 2.8859992879336636
Validation loss: 2.539725736791115

Epoch: 5| Step: 3
Training loss: 2.433375365621471
Validation loss: 2.553183155926489

Epoch: 5| Step: 4
Training loss: 2.9240060470560274
Validation loss: 2.5791934049669134

Epoch: 5| Step: 5
Training loss: 2.3378200536288958
Validation loss: 2.6012675263371534

Epoch: 5| Step: 6
Training loss: 3.1072848401882895
Validation loss: 2.6196714502629725

Epoch: 5| Step: 7
Training loss: 3.3278509036099733
Validation loss: 2.6427646450447475

Epoch: 5| Step: 8
Training loss: 2.7844313524839426
Validation loss: 2.602148282074601

Epoch: 5| Step: 9
Training loss: 3.471788742133848
Validation loss: 2.611630464217543

Epoch: 5| Step: 10
Training loss: 2.6062850474098282
Validation loss: 2.615424681973602

Epoch: 146| Step: 0
Training loss: 2.5806825840836143
Validation loss: 2.593116502015416

Epoch: 5| Step: 1
Training loss: 2.3533516094625573
Validation loss: 2.56762807874947

Epoch: 5| Step: 2
Training loss: 2.6849137215275873
Validation loss: 2.551629799948331

Epoch: 5| Step: 3
Training loss: 3.398136941181227
Validation loss: 2.5466673828232014

Epoch: 5| Step: 4
Training loss: 3.1012846776644842
Validation loss: 2.55812846680203

Epoch: 5| Step: 5
Training loss: 2.8333331463383633
Validation loss: 2.553588243335114

Epoch: 5| Step: 6
Training loss: 2.9316237091450676
Validation loss: 2.5543623779432725

Epoch: 5| Step: 7
Training loss: 2.579842752351696
Validation loss: 2.5528775099299605

Epoch: 5| Step: 8
Training loss: 2.396419906681762
Validation loss: 2.56376745661347

Epoch: 5| Step: 9
Training loss: 3.542771709308595
Validation loss: 2.5805373832028375

Epoch: 5| Step: 10
Training loss: 2.9187482944132297
Validation loss: 2.57669224060792

Epoch: 147| Step: 0
Training loss: 2.3518903636810706
Validation loss: 2.5704010859249533

Epoch: 5| Step: 1
Training loss: 2.8640861680904557
Validation loss: 2.561967703905477

Epoch: 5| Step: 2
Training loss: 3.4013095689833377
Validation loss: 2.5593632593979567

Epoch: 5| Step: 3
Training loss: 2.902097791721086
Validation loss: 2.5512760753207155

Epoch: 5| Step: 4
Training loss: 3.197413269250611
Validation loss: 2.5461392165534837

Epoch: 5| Step: 5
Training loss: 2.645814750385857
Validation loss: 2.5531924307430973

Epoch: 5| Step: 6
Training loss: 3.0550181022145186
Validation loss: 2.5567432150690825

Epoch: 5| Step: 7
Training loss: 2.6587168290365097
Validation loss: 2.5691207984189313

Epoch: 5| Step: 8
Training loss: 3.0869432572864137
Validation loss: 2.5731871052068627

Epoch: 5| Step: 9
Training loss: 2.923512046104107
Validation loss: 2.5627323088351672

Epoch: 5| Step: 10
Training loss: 2.528887175734658
Validation loss: 2.5545341398251886

Epoch: 148| Step: 0
Training loss: 2.408507044070133
Validation loss: 2.550547889829427

Epoch: 5| Step: 1
Training loss: 3.3222687826079937
Validation loss: 2.5460328743728806

Epoch: 5| Step: 2
Training loss: 2.377196551030273
Validation loss: 2.5430384551187513

Epoch: 5| Step: 3
Training loss: 2.841022734709841
Validation loss: 2.536300031301467

Epoch: 5| Step: 4
Training loss: 2.856109922884895
Validation loss: 2.544286815370474

Epoch: 5| Step: 5
Training loss: 2.919103930168803
Validation loss: 2.544722189190792

Epoch: 5| Step: 6
Training loss: 2.7495702060879963
Validation loss: 2.5409695368418723

Epoch: 5| Step: 7
Training loss: 2.5556822540370416
Validation loss: 2.554481030621984

Epoch: 5| Step: 8
Training loss: 3.262789722893259
Validation loss: 2.5570421699697876

Epoch: 5| Step: 9
Training loss: 3.1499876839533227
Validation loss: 2.543306235093241

Epoch: 5| Step: 10
Training loss: 2.8643373880865584
Validation loss: 2.5566285479953406

Epoch: 149| Step: 0
Training loss: 2.485205841289184
Validation loss: 2.5650030707203184

Epoch: 5| Step: 1
Training loss: 2.855370891684152
Validation loss: 2.55585678088493

Epoch: 5| Step: 2
Training loss: 3.0340885361066974
Validation loss: 2.559258202961106

Epoch: 5| Step: 3
Training loss: 2.613195306707582
Validation loss: 2.571120848834006

Epoch: 5| Step: 4
Training loss: 3.0358314106890023
Validation loss: 2.593883474893682

Epoch: 5| Step: 5
Training loss: 3.2456668430733284
Validation loss: 2.587868781528705

Epoch: 5| Step: 6
Training loss: 2.707665131130751
Validation loss: 2.5619321004248103

Epoch: 5| Step: 7
Training loss: 3.1177858624482266
Validation loss: 2.544995483404745

Epoch: 5| Step: 8
Training loss: 3.0797557867754315
Validation loss: 2.5233330488644374

Epoch: 5| Step: 9
Training loss: 2.380672506958524
Validation loss: 2.517609192521042

Epoch: 5| Step: 10
Training loss: 2.5146351637999187
Validation loss: 2.5127958035135967

Epoch: 150| Step: 0
Training loss: 3.1555850395502727
Validation loss: 2.5138571515917687

Epoch: 5| Step: 1
Training loss: 2.8357414409027704
Validation loss: 2.5112102457381

Epoch: 5| Step: 2
Training loss: 3.0551008252177363
Validation loss: 2.5118476452999126

Epoch: 5| Step: 3
Training loss: 3.0633227741722235
Validation loss: 2.513890279694237

Epoch: 5| Step: 4
Training loss: 2.7255183190678545
Validation loss: 2.525154109229078

Epoch: 5| Step: 5
Training loss: 2.4132760257485337
Validation loss: 2.5304268830868053

Epoch: 5| Step: 6
Training loss: 2.762342498570143
Validation loss: 2.552543417515231

Epoch: 5| Step: 7
Training loss: 2.336681234810438
Validation loss: 2.5870334647532713

Epoch: 5| Step: 8
Training loss: 3.134291302218587
Validation loss: 2.596077747367305

Epoch: 5| Step: 9
Training loss: 2.940024407214105
Validation loss: 2.559250733180958

Epoch: 5| Step: 10
Training loss: 2.790665964336401
Validation loss: 2.538411829317552

Testing loss: 2.7370164785796947
