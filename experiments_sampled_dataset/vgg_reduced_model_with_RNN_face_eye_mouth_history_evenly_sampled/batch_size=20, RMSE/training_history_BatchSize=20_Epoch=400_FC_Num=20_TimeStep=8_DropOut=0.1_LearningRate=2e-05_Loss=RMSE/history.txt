Epoch: 1| Step: 0
Training loss: 5.985157728674272
Validation loss: 5.796399619896167

Epoch: 5| Step: 1
Training loss: 5.940667843250296
Validation loss: 5.779002618024635

Epoch: 5| Step: 2
Training loss: 6.0916303029086105
Validation loss: 5.763182777708137

Epoch: 5| Step: 3
Training loss: 5.2531790417961215
Validation loss: 5.74772681502498

Epoch: 5| Step: 4
Training loss: 5.446692928000321
Validation loss: 5.730304595016251

Epoch: 5| Step: 5
Training loss: 5.150954608033683
Validation loss: 5.71103940301352

Epoch: 5| Step: 6
Training loss: 5.805911688500607
Validation loss: 5.6884715717492185

Epoch: 5| Step: 7
Training loss: 5.9834044144994225
Validation loss: 5.662919104008413

Epoch: 5| Step: 8
Training loss: 5.855638457034549
Validation loss: 5.633080522913206

Epoch: 5| Step: 9
Training loss: 5.262191060256048
Validation loss: 5.598408347664131

Epoch: 5| Step: 10
Training loss: 6.271254144111771
Validation loss: 5.5592797306708315

Epoch: 2| Step: 0
Training loss: 4.385348261332154
Validation loss: 5.515200697407163

Epoch: 5| Step: 1
Training loss: 6.1015875079513116
Validation loss: 5.466615957694741

Epoch: 5| Step: 2
Training loss: 4.96505388705081
Validation loss: 5.414115745570149

Epoch: 5| Step: 3
Training loss: 5.707991021280906
Validation loss: 5.356036294271781

Epoch: 5| Step: 4
Training loss: 4.28998782211745
Validation loss: 5.29550871810688

Epoch: 5| Step: 5
Training loss: 5.24246346988057
Validation loss: 5.232138153181413

Epoch: 5| Step: 6
Training loss: 5.9636150860882635
Validation loss: 5.165238520790401

Epoch: 5| Step: 7
Training loss: 5.166007317750882
Validation loss: 5.09613746161668

Epoch: 5| Step: 8
Training loss: 5.513774269550454
Validation loss: 5.027800304527281

Epoch: 5| Step: 9
Training loss: 5.059228098800101
Validation loss: 4.956851680290729

Epoch: 5| Step: 10
Training loss: 5.338299386334075
Validation loss: 4.885982382107483

Epoch: 3| Step: 0
Training loss: 3.8402136685609873
Validation loss: 4.820292494221067

Epoch: 5| Step: 1
Training loss: 4.595476513749987
Validation loss: 4.762759105216432

Epoch: 5| Step: 2
Training loss: 4.1605878865719985
Validation loss: 4.7122404327589935

Epoch: 5| Step: 3
Training loss: 4.687411498187963
Validation loss: 4.663337200267306

Epoch: 5| Step: 4
Training loss: 5.052851395050025
Validation loss: 4.604066079909559

Epoch: 5| Step: 5
Training loss: 4.67848885649487
Validation loss: 4.561612730555359

Epoch: 5| Step: 6
Training loss: 5.376337816398821
Validation loss: 4.5334221204777

Epoch: 5| Step: 7
Training loss: 4.768427790684337
Validation loss: 4.5037427921885325

Epoch: 5| Step: 8
Training loss: 5.399690562671848
Validation loss: 4.469605153856692

Epoch: 5| Step: 9
Training loss: 4.11276604160016
Validation loss: 4.43420817367861

Epoch: 5| Step: 10
Training loss: 4.577076450088643
Validation loss: 4.402812884687993

Epoch: 4| Step: 0
Training loss: 3.9298453631080568
Validation loss: 4.374086700133543

Epoch: 5| Step: 1
Training loss: 4.340668827327221
Validation loss: 4.348863979134209

Epoch: 5| Step: 2
Training loss: 4.097186560753983
Validation loss: 4.325778513319562

Epoch: 5| Step: 3
Training loss: 5.07868330013896
Validation loss: 4.30538510212199

Epoch: 5| Step: 4
Training loss: 4.422786551292736
Validation loss: 4.280222789366136

Epoch: 5| Step: 5
Training loss: 5.058066793559606
Validation loss: 4.257295416473758

Epoch: 5| Step: 6
Training loss: 4.343572160112851
Validation loss: 4.2271562581961275

Epoch: 5| Step: 7
Training loss: 3.772721690646969
Validation loss: 4.201499533472504

Epoch: 5| Step: 8
Training loss: 3.7922216714860535
Validation loss: 4.178950037514118

Epoch: 5| Step: 9
Training loss: 4.708886150663151
Validation loss: 4.164540089424669

Epoch: 5| Step: 10
Training loss: 4.4508464136855785
Validation loss: 4.139040858807542

Epoch: 5| Step: 0
Training loss: 4.7944604220418165
Validation loss: 4.112995926972266

Epoch: 5| Step: 1
Training loss: 3.934523895815498
Validation loss: 4.086197816267498

Epoch: 5| Step: 2
Training loss: 3.668391356736519
Validation loss: 4.061532213719425

Epoch: 5| Step: 3
Training loss: 3.710846781374686
Validation loss: 4.0422902152176015

Epoch: 5| Step: 4
Training loss: 4.388242027375007
Validation loss: 4.02624993762679

Epoch: 5| Step: 5
Training loss: 4.106427081744609
Validation loss: 4.008332257239436

Epoch: 5| Step: 6
Training loss: 3.622762318255946
Validation loss: 3.9889130298194275

Epoch: 5| Step: 7
Training loss: 3.7999498765550914
Validation loss: 3.974768558904477

Epoch: 5| Step: 8
Training loss: 4.226251333349875
Validation loss: 3.955209267144962

Epoch: 5| Step: 9
Training loss: 4.9134138737516695
Validation loss: 3.944243423128503

Epoch: 5| Step: 10
Training loss: 4.396542074671351
Validation loss: 3.926259385440812

Epoch: 6| Step: 0
Training loss: 3.7776772510642047
Validation loss: 3.9097944977023857

Epoch: 5| Step: 1
Training loss: 4.268637016443236
Validation loss: 3.8953557393203666

Epoch: 5| Step: 2
Training loss: 3.482113912832393
Validation loss: 3.8849474845695697

Epoch: 5| Step: 3
Training loss: 4.7636950978318735
Validation loss: 3.871078168497159

Epoch: 5| Step: 4
Training loss: 3.8683342976851756
Validation loss: 3.8611272260364475

Epoch: 5| Step: 5
Training loss: 4.250779921831716
Validation loss: 3.8557498189141257

Epoch: 5| Step: 6
Training loss: 3.3406714412076783
Validation loss: 3.8488528513762024

Epoch: 5| Step: 7
Training loss: 3.8990805789265135
Validation loss: 3.8411883256695187

Epoch: 5| Step: 8
Training loss: 3.108866127584648
Validation loss: 3.8179227087232817

Epoch: 5| Step: 9
Training loss: 4.41392206289315
Validation loss: 3.8057910357907643

Epoch: 5| Step: 10
Training loss: 4.8035734544325335
Validation loss: 3.8000976465758787

Epoch: 7| Step: 0
Training loss: 3.6250372259925197
Validation loss: 3.784744628908161

Epoch: 5| Step: 1
Training loss: 3.537069201438756
Validation loss: 3.7704332287061915

Epoch: 5| Step: 2
Training loss: 4.605670021842387
Validation loss: 3.7594033043545596

Epoch: 5| Step: 3
Training loss: 3.3433503954963246
Validation loss: 3.749832204257258

Epoch: 5| Step: 4
Training loss: 4.586457569065358
Validation loss: 3.73960885276774

Epoch: 5| Step: 5
Training loss: 3.8010374259280404
Validation loss: 3.7294226415522798

Epoch: 5| Step: 6
Training loss: 3.5577920959182423
Validation loss: 3.7215369682037616

Epoch: 5| Step: 7
Training loss: 3.0143230572804143
Validation loss: 3.7116373742593667

Epoch: 5| Step: 8
Training loss: 3.8055925174103096
Validation loss: 3.708684764735578

Epoch: 5| Step: 9
Training loss: 4.536251280913983
Validation loss: 3.705037636025127

Epoch: 5| Step: 10
Training loss: 4.341757337876665
Validation loss: 3.6931374159975654

Epoch: 8| Step: 0
Training loss: 4.172275023980613
Validation loss: 3.682492619743983

Epoch: 5| Step: 1
Training loss: 4.281745826243851
Validation loss: 3.6692916911561517

Epoch: 5| Step: 2
Training loss: 4.033169548135053
Validation loss: 3.660692299751836

Epoch: 5| Step: 3
Training loss: 3.2808903088288237
Validation loss: 3.650064138662849

Epoch: 5| Step: 4
Training loss: 3.8260012593962713
Validation loss: 3.6450582235243063

Epoch: 5| Step: 5
Training loss: 4.249914953839449
Validation loss: 3.6334356868386526

Epoch: 5| Step: 6
Training loss: 2.933386011806611
Validation loss: 3.6254340390394226

Epoch: 5| Step: 7
Training loss: 4.218942369384361
Validation loss: 3.6199270529256125

Epoch: 5| Step: 8
Training loss: 4.411259394111695
Validation loss: 3.6150304542533735

Epoch: 5| Step: 9
Training loss: 3.085176089066768
Validation loss: 3.6071190057347624

Epoch: 5| Step: 10
Training loss: 3.2073244432437007
Validation loss: 3.599219370421681

Epoch: 9| Step: 0
Training loss: 3.931900887514002
Validation loss: 3.5901114771599185

Epoch: 5| Step: 1
Training loss: 3.6679277996665767
Validation loss: 3.580595185608165

Epoch: 5| Step: 2
Training loss: 3.878823270803336
Validation loss: 3.5764007576658123

Epoch: 5| Step: 3
Training loss: 4.112094457973798
Validation loss: 3.5671520302737103

Epoch: 5| Step: 4
Training loss: 2.9226494237131253
Validation loss: 3.5616843126849247

Epoch: 5| Step: 5
Training loss: 3.3858565450654
Validation loss: 3.554039571120491

Epoch: 5| Step: 6
Training loss: 3.9522821183686103
Validation loss: 3.5465660320231276

Epoch: 5| Step: 7
Training loss: 3.902275565986532
Validation loss: 3.537521186399049

Epoch: 5| Step: 8
Training loss: 3.694113409816017
Validation loss: 3.531486219468824

Epoch: 5| Step: 9
Training loss: 3.8825167691076805
Validation loss: 3.5247834447981314

Epoch: 5| Step: 10
Training loss: 3.880303230234634
Validation loss: 3.518585376257816

Epoch: 10| Step: 0
Training loss: 2.7684468673890335
Validation loss: 3.5180197508207733

Epoch: 5| Step: 1
Training loss: 3.905759368602009
Validation loss: 3.51229570664905

Epoch: 5| Step: 2
Training loss: 4.310230929744323
Validation loss: 3.500377584854233

Epoch: 5| Step: 3
Training loss: 3.6154455353057395
Validation loss: 3.497310442983853

Epoch: 5| Step: 4
Training loss: 3.9235340272126242
Validation loss: 3.4929780588533252

Epoch: 5| Step: 5
Training loss: 3.353536384709332
Validation loss: 3.4884363548828534

Epoch: 5| Step: 6
Training loss: 3.9233135609437784
Validation loss: 3.4833048457280866

Epoch: 5| Step: 7
Training loss: 3.7000834532940376
Validation loss: 3.4747079081553127

Epoch: 5| Step: 8
Training loss: 3.577535788985509
Validation loss: 3.467860685720545

Epoch: 5| Step: 9
Training loss: 3.5708323962026025
Validation loss: 3.462017875415526

Epoch: 5| Step: 10
Training loss: 3.9017036531616194
Validation loss: 3.4555240379226237

Epoch: 11| Step: 0
Training loss: 3.530861892302593
Validation loss: 3.4504530775770514

Epoch: 5| Step: 1
Training loss: 3.838836506769728
Validation loss: 3.445006222737973

Epoch: 5| Step: 2
Training loss: 3.457042284586909
Validation loss: 3.44306244869731

Epoch: 5| Step: 3
Training loss: 3.898906182685949
Validation loss: 3.441906959158005

Epoch: 5| Step: 4
Training loss: 3.0500471768091915
Validation loss: 3.4295850900091396

Epoch: 5| Step: 5
Training loss: 3.6901394724138408
Validation loss: 3.4269917295044885

Epoch: 5| Step: 6
Training loss: 3.664621273940992
Validation loss: 3.42764320192682

Epoch: 5| Step: 7
Training loss: 3.9880443954751508
Validation loss: 3.42899654029563

Epoch: 5| Step: 8
Training loss: 3.6095497782612176
Validation loss: 3.42755148939964

Epoch: 5| Step: 9
Training loss: 3.214365222492512
Validation loss: 3.427374507651662

Epoch: 5| Step: 10
Training loss: 4.223325381694274
Validation loss: 3.423054331811121

Epoch: 12| Step: 0
Training loss: 3.549860164413473
Validation loss: 3.4179204885705667

Epoch: 5| Step: 1
Training loss: 4.150514933800172
Validation loss: 3.416935108563155

Epoch: 5| Step: 2
Training loss: 3.62072422812857
Validation loss: 3.4085038446619946

Epoch: 5| Step: 3
Training loss: 4.092587604458932
Validation loss: 3.4031279112474024

Epoch: 5| Step: 4
Training loss: 3.977274233334739
Validation loss: 3.3956248731941874

Epoch: 5| Step: 5
Training loss: 3.3717931417546496
Validation loss: 3.3909183029612473

Epoch: 5| Step: 6
Training loss: 2.3508279356499546
Validation loss: 3.3862667715817536

Epoch: 5| Step: 7
Training loss: 3.091244386142642
Validation loss: 3.3839455795035374

Epoch: 5| Step: 8
Training loss: 4.1146769967665415
Validation loss: 3.382960515617198

Epoch: 5| Step: 9
Training loss: 3.7332225601474325
Validation loss: 3.3752533343970836

Epoch: 5| Step: 10
Training loss: 3.3836110782465836
Validation loss: 3.3672291765683284

Epoch: 13| Step: 0
Training loss: 3.6825389788002654
Validation loss: 3.363326162635526

Epoch: 5| Step: 1
Training loss: 3.513184238457637
Validation loss: 3.3642083492465185

Epoch: 5| Step: 2
Training loss: 4.023831661138749
Validation loss: 3.3541566536127885

Epoch: 5| Step: 3
Training loss: 3.84657580701953
Validation loss: 3.349615251391343

Epoch: 5| Step: 4
Training loss: 3.997043828552622
Validation loss: 3.3457146095156496

Epoch: 5| Step: 5
Training loss: 3.932726312662143
Validation loss: 3.3439840135789334

Epoch: 5| Step: 6
Training loss: 3.4606382356858707
Validation loss: 3.350389023454306

Epoch: 5| Step: 7
Training loss: 3.4446183454715955
Validation loss: 3.339555101071442

Epoch: 5| Step: 8
Training loss: 3.8018236602873756
Validation loss: 3.3335993435042175

Epoch: 5| Step: 9
Training loss: 3.1053898255497536
Validation loss: 3.3302834252862854

Epoch: 5| Step: 10
Training loss: 1.9476291083852042
Validation loss: 3.334192791754431

Epoch: 14| Step: 0
Training loss: 3.6869485733753926
Validation loss: 3.3465212529069746

Epoch: 5| Step: 1
Training loss: 3.4152310464426763
Validation loss: 3.328139088679956

Epoch: 5| Step: 2
Training loss: 3.192897340906129
Validation loss: 3.3168543195228084

Epoch: 5| Step: 3
Training loss: 3.56143359904344
Validation loss: 3.318169359311901

Epoch: 5| Step: 4
Training loss: 3.717232915625712
Validation loss: 3.320590299099816

Epoch: 5| Step: 5
Training loss: 3.3737228237554313
Validation loss: 3.322276872614389

Epoch: 5| Step: 6
Training loss: 4.037638961243025
Validation loss: 3.3125110238298716

Epoch: 5| Step: 7
Training loss: 3.4986556059712903
Validation loss: 3.3047469939636054

Epoch: 5| Step: 8
Training loss: 3.5223301672080276
Validation loss: 3.303592634431915

Epoch: 5| Step: 9
Training loss: 3.449528681308353
Validation loss: 3.3016536784169848

Epoch: 5| Step: 10
Training loss: 3.6486077932604
Validation loss: 3.2989129919065

Epoch: 15| Step: 0
Training loss: 3.6716485136267045
Validation loss: 3.292279694310612

Epoch: 5| Step: 1
Training loss: 3.021924332666733
Validation loss: 3.288245121589465

Epoch: 5| Step: 2
Training loss: 3.1528750968025356
Validation loss: 3.287170952784921

Epoch: 5| Step: 3
Training loss: 3.0196389478893586
Validation loss: 3.288889711392466

Epoch: 5| Step: 4
Training loss: 3.738530484524076
Validation loss: 3.2876450403275848

Epoch: 5| Step: 5
Training loss: 3.7091975258822147
Validation loss: 3.28571303029445

Epoch: 5| Step: 6
Training loss: 3.311173947340414
Validation loss: 3.274380159841578

Epoch: 5| Step: 7
Training loss: 3.9434660263716563
Validation loss: 3.2715630272226623

Epoch: 5| Step: 8
Training loss: 3.2932929516323015
Validation loss: 3.2712540056533412

Epoch: 5| Step: 9
Training loss: 3.827897170157565
Validation loss: 3.272028217590443

Epoch: 5| Step: 10
Training loss: 3.986985013705434
Validation loss: 3.2692747936459288

Epoch: 16| Step: 0
Training loss: 3.9252772676733034
Validation loss: 3.2653112930556074

Epoch: 5| Step: 1
Training loss: 2.7982969452167903
Validation loss: 3.2605517232071244

Epoch: 5| Step: 2
Training loss: 3.241422190595972
Validation loss: 3.2590751877453217

Epoch: 5| Step: 3
Training loss: 3.5321382738827816
Validation loss: 3.2566430295610647

Epoch: 5| Step: 4
Training loss: 3.6811700575848008
Validation loss: 3.256410701791156

Epoch: 5| Step: 5
Training loss: 3.6252468945841323
Validation loss: 3.257462900303195

Epoch: 5| Step: 6
Training loss: 2.9214976673968898
Validation loss: 3.256459552458375

Epoch: 5| Step: 7
Training loss: 4.039331895709523
Validation loss: 3.252752184731636

Epoch: 5| Step: 8
Training loss: 3.3085378306593833
Validation loss: 3.251194856540987

Epoch: 5| Step: 9
Training loss: 3.910611212878183
Validation loss: 3.250323143063862

Epoch: 5| Step: 10
Training loss: 3.3354623353410116
Validation loss: 3.248567879339103

Epoch: 17| Step: 0
Training loss: 3.1449427744112115
Validation loss: 3.246061056858538

Epoch: 5| Step: 1
Training loss: 2.9609023924988263
Validation loss: 3.2451529442559095

Epoch: 5| Step: 2
Training loss: 3.9843393361608537
Validation loss: 3.243116513489531

Epoch: 5| Step: 3
Training loss: 3.3005243867326586
Validation loss: 3.2417189495618572

Epoch: 5| Step: 4
Training loss: 4.250175472451797
Validation loss: 3.2411796678727733

Epoch: 5| Step: 5
Training loss: 3.636402218787377
Validation loss: 3.240260207246501

Epoch: 5| Step: 6
Training loss: 3.259194353168598
Validation loss: 3.238078857154927

Epoch: 5| Step: 7
Training loss: 3.944929349820253
Validation loss: 3.237427552534233

Epoch: 5| Step: 8
Training loss: 3.4928343854336097
Validation loss: 3.2362321330485795

Epoch: 5| Step: 9
Training loss: 3.2123181421482077
Validation loss: 3.233487975817436

Epoch: 5| Step: 10
Training loss: 2.8936573516317274
Validation loss: 3.232478240276096

Epoch: 18| Step: 0
Training loss: 3.4259317119270776
Validation loss: 3.23152176515137

Epoch: 5| Step: 1
Training loss: 3.485920789841869
Validation loss: 3.2297469433789274

Epoch: 5| Step: 2
Training loss: 3.3737199969828544
Validation loss: 3.2279170454971613

Epoch: 5| Step: 3
Training loss: 3.1390243170976038
Validation loss: 3.2270754570994207

Epoch: 5| Step: 4
Training loss: 4.02424118755575
Validation loss: 3.2269409501208535

Epoch: 5| Step: 5
Training loss: 3.6270212260535732
Validation loss: 3.2255141519071584

Epoch: 5| Step: 6
Training loss: 3.234394312999027
Validation loss: 3.224970430666418

Epoch: 5| Step: 7
Training loss: 3.3897191960437287
Validation loss: 3.2225494198013753

Epoch: 5| Step: 8
Training loss: 4.074114116959992
Validation loss: 3.222228674044696

Epoch: 5| Step: 9
Training loss: 2.5578416490612477
Validation loss: 3.220717175747315

Epoch: 5| Step: 10
Training loss: 3.7676164734877657
Validation loss: 3.2198841292385776

Epoch: 19| Step: 0
Training loss: 3.391259762461327
Validation loss: 3.2186079494704605

Epoch: 5| Step: 1
Training loss: 3.6457190504781813
Validation loss: 3.217328833187328

Epoch: 5| Step: 2
Training loss: 3.763561268929708
Validation loss: 3.216415171733017

Epoch: 5| Step: 3
Training loss: 3.2109640821113037
Validation loss: 3.2146013865018017

Epoch: 5| Step: 4
Training loss: 3.4449876558611416
Validation loss: 3.2142031946314673

Epoch: 5| Step: 5
Training loss: 3.127676771063936
Validation loss: 3.2131940513689607

Epoch: 5| Step: 6
Training loss: 3.4889231194870725
Validation loss: 3.2125983419361184

Epoch: 5| Step: 7
Training loss: 3.581311668410945
Validation loss: 3.2111839042403347

Epoch: 5| Step: 8
Training loss: 3.209894386764482
Validation loss: 3.210296035843385

Epoch: 5| Step: 9
Training loss: 3.581559444459804
Validation loss: 3.209455645132184

Epoch: 5| Step: 10
Training loss: 3.7300859025160436
Validation loss: 3.2085230248804337

Epoch: 20| Step: 0
Training loss: 3.791976594659545
Validation loss: 3.207842180500682

Epoch: 5| Step: 1
Training loss: 3.43449325843868
Validation loss: 3.2069010889066867

Epoch: 5| Step: 2
Training loss: 3.4643562601853395
Validation loss: 3.205493375363355

Epoch: 5| Step: 3
Training loss: 3.2140186683288277
Validation loss: 3.2053776761062913

Epoch: 5| Step: 4
Training loss: 3.7692886195391955
Validation loss: 3.203740509145769

Epoch: 5| Step: 5
Training loss: 3.028334326344147
Validation loss: 3.202790238369833

Epoch: 5| Step: 6
Training loss: 3.7938594695484724
Validation loss: 3.2009637559985347

Epoch: 5| Step: 7
Training loss: 3.7474305569027684
Validation loss: 3.2002099563698327

Epoch: 5| Step: 8
Training loss: 3.353516478141272
Validation loss: 3.1990739521999396

Epoch: 5| Step: 9
Training loss: 3.4646737832201895
Validation loss: 3.1965820749266105

Epoch: 5| Step: 10
Training loss: 2.786996113347744
Validation loss: 3.197286566940611

Epoch: 21| Step: 0
Training loss: 3.55447058382632
Validation loss: 3.2040492091331583

Epoch: 5| Step: 1
Training loss: 3.7018528294257647
Validation loss: 3.1896918198785977

Epoch: 5| Step: 2
Training loss: 3.8319860799851173
Validation loss: 3.18584898837924

Epoch: 5| Step: 3
Training loss: 3.3810999810578184
Validation loss: 3.1810497058823786

Epoch: 5| Step: 4
Training loss: 3.0385236483041744
Validation loss: 3.181152033887483

Epoch: 5| Step: 5
Training loss: 3.111355711389003
Validation loss: 3.1719383751901646

Epoch: 5| Step: 6
Training loss: 3.5605045552545334
Validation loss: 3.172075650083898

Epoch: 5| Step: 7
Training loss: 3.788179841417946
Validation loss: 3.173234833272424

Epoch: 5| Step: 8
Training loss: 3.3298812315784563
Validation loss: 3.169736344758022

Epoch: 5| Step: 9
Training loss: 2.997090677370531
Validation loss: 3.1693289318996953

Epoch: 5| Step: 10
Training loss: 3.4902552778560554
Validation loss: 3.174273779389357

Epoch: 22| Step: 0
Training loss: 3.466970313663322
Validation loss: 3.1730455604443417

Epoch: 5| Step: 1
Training loss: 2.8774811363099038
Validation loss: 3.164720948401317

Epoch: 5| Step: 2
Training loss: 2.5563605660028297
Validation loss: 3.165055717409786

Epoch: 5| Step: 3
Training loss: 4.020184848388189
Validation loss: 3.164122046190491

Epoch: 5| Step: 4
Training loss: 3.7674223223438887
Validation loss: 3.155131094283482

Epoch: 5| Step: 5
Training loss: 3.878857323221767
Validation loss: 3.156975596857123

Epoch: 5| Step: 6
Training loss: 3.1906271162035402
Validation loss: 3.153483949959772

Epoch: 5| Step: 7
Training loss: 3.5297743152953767
Validation loss: 3.151835444612442

Epoch: 5| Step: 8
Training loss: 2.910815682680303
Validation loss: 3.1516336889498144

Epoch: 5| Step: 9
Training loss: 3.938022518304751
Validation loss: 3.151300409742183

Epoch: 5| Step: 10
Training loss: 3.170169616156624
Validation loss: 3.1519119664954616

Epoch: 23| Step: 0
Training loss: 3.827792904520497
Validation loss: 3.1530273109506446

Epoch: 5| Step: 1
Training loss: 3.407821712630114
Validation loss: 3.1482121199565793

Epoch: 5| Step: 2
Training loss: 3.1206524934480098
Validation loss: 3.147058146770492

Epoch: 5| Step: 3
Training loss: 3.6049333466228957
Validation loss: 3.1421659090611613

Epoch: 5| Step: 4
Training loss: 3.030408919536189
Validation loss: 3.13962167618645

Epoch: 5| Step: 5
Training loss: 3.0529029101650194
Validation loss: 3.1408415052281584

Epoch: 5| Step: 6
Training loss: 3.4288917261330165
Validation loss: 3.139691326654936

Epoch: 5| Step: 7
Training loss: 3.2457075382743947
Validation loss: 3.1376309220974457

Epoch: 5| Step: 8
Training loss: 3.297070971987672
Validation loss: 3.137057486266831

Epoch: 5| Step: 9
Training loss: 4.1572140600954235
Validation loss: 3.1327106306958052

Epoch: 5| Step: 10
Training loss: 3.156668455881366
Validation loss: 3.1301013073132133

Epoch: 24| Step: 0
Training loss: 3.7173950547859675
Validation loss: 3.1269223197068374

Epoch: 5| Step: 1
Training loss: 3.6895607831119723
Validation loss: 3.1232753334233294

Epoch: 5| Step: 2
Training loss: 3.144989321497996
Validation loss: 3.116728366080743

Epoch: 5| Step: 3
Training loss: 2.9443445208726464
Validation loss: 3.108325106776972

Epoch: 5| Step: 4
Training loss: 3.1833663765622013
Validation loss: 3.1047249343134378

Epoch: 5| Step: 5
Training loss: 3.2722885555444328
Validation loss: 3.1049479357339775

Epoch: 5| Step: 6
Training loss: 3.4465812717043796
Validation loss: 3.1074074637677103

Epoch: 5| Step: 7
Training loss: 3.507430363763881
Validation loss: 3.0988520976913736

Epoch: 5| Step: 8
Training loss: 2.9783902701592675
Validation loss: 3.1043424956385053

Epoch: 5| Step: 9
Training loss: 3.7005835717305864
Validation loss: 3.103889762407803

Epoch: 5| Step: 10
Training loss: 3.6111280799532244
Validation loss: 3.100959148610664

Epoch: 25| Step: 0
Training loss: 3.162675266158757
Validation loss: 3.097024453619176

Epoch: 5| Step: 1
Training loss: 3.6245670717790155
Validation loss: 3.095176082212089

Epoch: 5| Step: 2
Training loss: 3.24306040583558
Validation loss: 3.0927043451576592

Epoch: 5| Step: 3
Training loss: 3.3650578182972426
Validation loss: 3.0914012619113858

Epoch: 5| Step: 4
Training loss: 3.511775507484187
Validation loss: 3.0901517471718796

Epoch: 5| Step: 5
Training loss: 3.10817077934384
Validation loss: 3.0884264208029206

Epoch: 5| Step: 6
Training loss: 4.063260520760429
Validation loss: 3.087663749679161

Epoch: 5| Step: 7
Training loss: 2.8328479089223
Validation loss: 3.0872833594433846

Epoch: 5| Step: 8
Training loss: 3.3253623707575968
Validation loss: 3.0849860073786823

Epoch: 5| Step: 9
Training loss: 3.255648326383771
Validation loss: 3.084551005112599

Epoch: 5| Step: 10
Training loss: 3.4593771006673415
Validation loss: 3.0836812853739515

Epoch: 26| Step: 0
Training loss: 3.581895732084124
Validation loss: 3.08243287453747

Epoch: 5| Step: 1
Training loss: 3.7642295436127213
Validation loss: 3.080631420602227

Epoch: 5| Step: 2
Training loss: 3.3945413639809052
Validation loss: 3.0808530979562723

Epoch: 5| Step: 3
Training loss: 3.154328620680035
Validation loss: 3.0780519075253845

Epoch: 5| Step: 4
Training loss: 3.076190941161152
Validation loss: 3.0786723171942545

Epoch: 5| Step: 5
Training loss: 2.903630542572314
Validation loss: 3.0770906299409546

Epoch: 5| Step: 6
Training loss: 3.7671519622328984
Validation loss: 3.0770975558080096

Epoch: 5| Step: 7
Training loss: 3.2969946093805897
Validation loss: 3.076840426809648

Epoch: 5| Step: 8
Training loss: 3.106810465855932
Validation loss: 3.0832604552361214

Epoch: 5| Step: 9
Training loss: 3.465691119871258
Validation loss: 3.0773192961195948

Epoch: 5| Step: 10
Training loss: 3.3635439532002347
Validation loss: 3.0726975207280223

Epoch: 27| Step: 0
Training loss: 2.799559088460666
Validation loss: 3.072278014833448

Epoch: 5| Step: 1
Training loss: 2.8863107189005204
Validation loss: 3.071807933836338

Epoch: 5| Step: 2
Training loss: 3.002568417038823
Validation loss: 3.071942450321011

Epoch: 5| Step: 3
Training loss: 3.4358502677471163
Validation loss: 3.0703557131008696

Epoch: 5| Step: 4
Training loss: 4.012671427169421
Validation loss: 3.0697184431587834

Epoch: 5| Step: 5
Training loss: 3.469594216929606
Validation loss: 3.0691171228235983

Epoch: 5| Step: 6
Training loss: 3.394558361019829
Validation loss: 3.0684708365063846

Epoch: 5| Step: 7
Training loss: 3.569824185356398
Validation loss: 3.068303599281183

Epoch: 5| Step: 8
Training loss: 3.1221607279877763
Validation loss: 3.066932826866553

Epoch: 5| Step: 9
Training loss: 3.54621107970896
Validation loss: 3.066304841594289

Epoch: 5| Step: 10
Training loss: 3.5025448402948913
Validation loss: 3.0656311673323136

Epoch: 28| Step: 0
Training loss: 3.3416561808306655
Validation loss: 3.0638268446591654

Epoch: 5| Step: 1
Training loss: 3.517474963567435
Validation loss: 3.0640495637578544

Epoch: 5| Step: 2
Training loss: 3.8513904092037263
Validation loss: 3.062969137509217

Epoch: 5| Step: 3
Training loss: 3.8547580299682225
Validation loss: 3.0613143196065735

Epoch: 5| Step: 4
Training loss: 2.898735257300836
Validation loss: 3.0608828512596964

Epoch: 5| Step: 5
Training loss: 3.426377352240808
Validation loss: 3.059553323015681

Epoch: 5| Step: 6
Training loss: 2.872127922800731
Validation loss: 3.0593973414657505

Epoch: 5| Step: 7
Training loss: 2.529907906857757
Validation loss: 3.058161020958557

Epoch: 5| Step: 8
Training loss: 3.490865640704001
Validation loss: 3.057881259111082

Epoch: 5| Step: 9
Training loss: 2.7930818548175744
Validation loss: 3.0573000396889456

Epoch: 5| Step: 10
Training loss: 4.006250504658826
Validation loss: 3.056048671971999

Epoch: 29| Step: 0
Training loss: 3.5368125112688915
Validation loss: 3.055574771923845

Epoch: 5| Step: 1
Training loss: 3.844851080263934
Validation loss: 3.05509958497663

Epoch: 5| Step: 2
Training loss: 3.3465762449362164
Validation loss: 3.054169735725588

Epoch: 5| Step: 3
Training loss: 3.3558904984515894
Validation loss: 3.0535302959161696

Epoch: 5| Step: 4
Training loss: 3.938707317967265
Validation loss: 3.052708212224995

Epoch: 5| Step: 5
Training loss: 2.9005736013937056
Validation loss: 3.051912538080358

Epoch: 5| Step: 6
Training loss: 3.2201465428811455
Validation loss: 3.0508286808038934

Epoch: 5| Step: 7
Training loss: 2.948965544283634
Validation loss: 3.05037278046154

Epoch: 5| Step: 8
Training loss: 3.5209761521003897
Validation loss: 3.0495743011817495

Epoch: 5| Step: 9
Training loss: 2.9294169796979026
Validation loss: 3.0485938672640502

Epoch: 5| Step: 10
Training loss: 2.9643546242509298
Validation loss: 3.048540229193538

Epoch: 30| Step: 0
Training loss: 2.183005920884425
Validation loss: 3.0473261841739556

Epoch: 5| Step: 1
Training loss: 2.918833735896517
Validation loss: 3.0468051680478676

Epoch: 5| Step: 2
Training loss: 3.3920629590057563
Validation loss: 3.045856306586645

Epoch: 5| Step: 3
Training loss: 3.4056570954472236
Validation loss: 3.045740116985103

Epoch: 5| Step: 4
Training loss: 3.047313326093209
Validation loss: 3.0446776656461596

Epoch: 5| Step: 5
Training loss: 3.652206532557752
Validation loss: 3.044339021814009

Epoch: 5| Step: 6
Training loss: 3.336327130257579
Validation loss: 3.0435529117585487

Epoch: 5| Step: 7
Training loss: 3.549794747235051
Validation loss: 3.0426883799239652

Epoch: 5| Step: 8
Training loss: 3.1616970686455454
Validation loss: 3.0428429516401767

Epoch: 5| Step: 9
Training loss: 3.3672665190662894
Validation loss: 3.0412315116936623

Epoch: 5| Step: 10
Training loss: 4.423126367145891
Validation loss: 3.040668673322294

Epoch: 31| Step: 0
Training loss: 4.022087626257167
Validation loss: 3.0403664673264514

Epoch: 5| Step: 1
Training loss: 3.6804425220206807
Validation loss: 3.040020506646097

Epoch: 5| Step: 2
Training loss: 3.4088181080184796
Validation loss: 3.038804627882492

Epoch: 5| Step: 3
Training loss: 3.4653706628399195
Validation loss: 3.0387956271319347

Epoch: 5| Step: 4
Training loss: 3.2687300380585946
Validation loss: 3.0367867795856283

Epoch: 5| Step: 5
Training loss: 3.394484051023992
Validation loss: 3.037567556340534

Epoch: 5| Step: 6
Training loss: 3.7514991306861663
Validation loss: 3.036269200804761

Epoch: 5| Step: 7
Training loss: 2.7333747124059684
Validation loss: 3.0343691651461913

Epoch: 5| Step: 8
Training loss: 3.072362162242831
Validation loss: 3.0345015479649162

Epoch: 5| Step: 9
Training loss: 2.7480288290096886
Validation loss: 3.033194569103911

Epoch: 5| Step: 10
Training loss: 2.7109436562767812
Validation loss: 3.0330204226793835

Epoch: 32| Step: 0
Training loss: 3.083801457378187
Validation loss: 3.032358401405079

Epoch: 5| Step: 1
Training loss: 3.1169259097827777
Validation loss: 3.0317909156442595

Epoch: 5| Step: 2
Training loss: 2.991932193232555
Validation loss: 3.031725655979394

Epoch: 5| Step: 3
Training loss: 3.173313059167717
Validation loss: 3.030318262144907

Epoch: 5| Step: 4
Training loss: 4.026433151707712
Validation loss: 3.0290931637449563

Epoch: 5| Step: 5
Training loss: 3.5239924566857166
Validation loss: 3.0294573546662296

Epoch: 5| Step: 6
Training loss: 2.977046096244981
Validation loss: 3.028771420076357

Epoch: 5| Step: 7
Training loss: 3.3732512853341934
Validation loss: 3.0279734631597703

Epoch: 5| Step: 8
Training loss: 3.811250325494129
Validation loss: 3.0279081525452205

Epoch: 5| Step: 9
Training loss: 3.410974428446169
Validation loss: 3.0262813071162773

Epoch: 5| Step: 10
Training loss: 2.779010514005063
Validation loss: 3.025966481892269

Epoch: 33| Step: 0
Training loss: 3.7249638549279935
Validation loss: 3.025472739615536

Epoch: 5| Step: 1
Training loss: 3.4408579291027177
Validation loss: 3.024497254684715

Epoch: 5| Step: 2
Training loss: 2.6278714414880118
Validation loss: 3.02498442966946

Epoch: 5| Step: 3
Training loss: 3.2906130943553915
Validation loss: 3.0236483005954913

Epoch: 5| Step: 4
Training loss: 3.0388814288723274
Validation loss: 3.0238781043810654

Epoch: 5| Step: 5
Training loss: 3.830465667742042
Validation loss: 3.022819913633091

Epoch: 5| Step: 6
Training loss: 3.2351985748993464
Validation loss: 3.0220977315284885

Epoch: 5| Step: 7
Training loss: 3.4000369462642483
Validation loss: 3.020939215705806

Epoch: 5| Step: 8
Training loss: 2.9419366325436624
Validation loss: 3.0206936904036956

Epoch: 5| Step: 9
Training loss: 3.5168044082881242
Validation loss: 3.0191776645042516

Epoch: 5| Step: 10
Training loss: 3.24826619777782
Validation loss: 3.0176429056351237

Epoch: 34| Step: 0
Training loss: 3.1558020245496796
Validation loss: 3.018064880245948

Epoch: 5| Step: 1
Training loss: 3.4396178223983194
Validation loss: 3.018093065964189

Epoch: 5| Step: 2
Training loss: 3.6712461541804795
Validation loss: 3.016486513529053

Epoch: 5| Step: 3
Training loss: 2.866181490745243
Validation loss: 3.015980605987043

Epoch: 5| Step: 4
Training loss: 3.2710798782116455
Validation loss: 3.012867564548293

Epoch: 5| Step: 5
Training loss: 3.7200683052190864
Validation loss: 3.0131451739946833

Epoch: 5| Step: 6
Training loss: 3.264416046498024
Validation loss: 3.011724226756039

Epoch: 5| Step: 7
Training loss: 3.4150347340103395
Validation loss: 3.009638037597196

Epoch: 5| Step: 8
Training loss: 3.1678054334733474
Validation loss: 3.0125763700439365

Epoch: 5| Step: 9
Training loss: 3.1235589328688027
Validation loss: 3.0191432486724032

Epoch: 5| Step: 10
Training loss: 3.22320426211744
Validation loss: 3.031320795827323

Epoch: 35| Step: 0
Training loss: 3.2149618134077302
Validation loss: 3.0512824562577006

Epoch: 5| Step: 1
Training loss: 3.0774879377238733
Validation loss: 3.054723130908903

Epoch: 5| Step: 2
Training loss: 3.4925603816848114
Validation loss: 3.0581630596909535

Epoch: 5| Step: 3
Training loss: 2.6652419536180356
Validation loss: 3.06580325817577

Epoch: 5| Step: 4
Training loss: 3.5882579468000118
Validation loss: 3.0573364032048596

Epoch: 5| Step: 5
Training loss: 3.1260807457353725
Validation loss: 3.052880860227341

Epoch: 5| Step: 6
Training loss: 3.436441293153646
Validation loss: 3.052999179647462

Epoch: 5| Step: 7
Training loss: 3.0041929190057837
Validation loss: 3.0496342191364567

Epoch: 5| Step: 8
Training loss: 3.661233749483823
Validation loss: 3.0499589540384826

Epoch: 5| Step: 9
Training loss: 3.424696782187696
Validation loss: 3.0456986757797186

Epoch: 5| Step: 10
Training loss: 3.9101418600665534
Validation loss: 3.0424960212824073

Epoch: 36| Step: 0
Training loss: 3.857454014897751
Validation loss: 3.046196565908872

Epoch: 5| Step: 1
Training loss: 2.7782109834047066
Validation loss: 3.0489969786647433

Epoch: 5| Step: 2
Training loss: 3.0395215626733187
Validation loss: 3.0615945171809584

Epoch: 5| Step: 3
Training loss: 3.158277559081493
Validation loss: 3.0429521530966475

Epoch: 5| Step: 4
Training loss: 3.654109099807155
Validation loss: 3.0520428882307216

Epoch: 5| Step: 5
Training loss: 3.227891403564873
Validation loss: 3.0421044684566465

Epoch: 5| Step: 6
Training loss: 3.4759119003685255
Validation loss: 3.036842791416504

Epoch: 5| Step: 7
Training loss: 2.9259385192732426
Validation loss: 3.012716221869372

Epoch: 5| Step: 8
Training loss: 3.57400768886736
Validation loss: 2.99764624588331

Epoch: 5| Step: 9
Training loss: 3.566186035309984
Validation loss: 2.999521357455738

Epoch: 5| Step: 10
Training loss: 3.113682968661629
Validation loss: 3.007552716474056

Epoch: 37| Step: 0
Training loss: 3.3113201127310314
Validation loss: 3.024853607611184

Epoch: 5| Step: 1
Training loss: 3.218046241043946
Validation loss: 3.016921008731495

Epoch: 5| Step: 2
Training loss: 2.556293507697729
Validation loss: 3.0111374847743853

Epoch: 5| Step: 3
Training loss: 3.631010925511864
Validation loss: 3.0046696262795223

Epoch: 5| Step: 4
Training loss: 3.5599310463217444
Validation loss: 3.003840500599182

Epoch: 5| Step: 5
Training loss: 3.8803936736968083
Validation loss: 2.9989960299710643

Epoch: 5| Step: 6
Training loss: 2.9573408440969504
Validation loss: 2.9873129637619242

Epoch: 5| Step: 7
Training loss: 3.330061514804616
Validation loss: 2.9885723729568556

Epoch: 5| Step: 8
Training loss: 3.0510561693410563
Validation loss: 2.9919087993901328

Epoch: 5| Step: 9
Training loss: 3.370504847216491
Validation loss: 2.9995587034621494

Epoch: 5| Step: 10
Training loss: 3.2059098210112746
Validation loss: 2.9980828130781383

Epoch: 38| Step: 0
Training loss: 3.0401476023628904
Validation loss: 2.988505882159574

Epoch: 5| Step: 1
Training loss: 3.727793748053578
Validation loss: 2.991180360092939

Epoch: 5| Step: 2
Training loss: 3.106616459496733
Validation loss: 2.9895063723868045

Epoch: 5| Step: 3
Training loss: 2.9677727948131913
Validation loss: 2.9889280334135404

Epoch: 5| Step: 4
Training loss: 3.5722124983235126
Validation loss: 3.003672201521257

Epoch: 5| Step: 5
Training loss: 3.486922218288857
Validation loss: 2.9910072336388542

Epoch: 5| Step: 6
Training loss: 2.7639564610266434
Validation loss: 2.980016264677345

Epoch: 5| Step: 7
Training loss: 3.1501405714852133
Validation loss: 2.9809248010646394

Epoch: 5| Step: 8
Training loss: 3.752044120610499
Validation loss: 2.978566077719728

Epoch: 5| Step: 9
Training loss: 3.031009625214762
Validation loss: 2.980238840237669

Epoch: 5| Step: 10
Training loss: 3.4434457855720377
Validation loss: 2.991109619554499

Epoch: 39| Step: 0
Training loss: 3.879439610194744
Validation loss: 2.9902520275309588

Epoch: 5| Step: 1
Training loss: 2.911217494732357
Validation loss: 2.9842984430713573

Epoch: 5| Step: 2
Training loss: 3.2997061338493743
Validation loss: 2.980650431549274

Epoch: 5| Step: 3
Training loss: 2.44871347864557
Validation loss: 2.9786634862850505

Epoch: 5| Step: 4
Training loss: 3.801525642915633
Validation loss: 2.978884867712942

Epoch: 5| Step: 5
Training loss: 3.2489760326324535
Validation loss: 2.9769273139854535

Epoch: 5| Step: 6
Training loss: 2.556114148398372
Validation loss: 2.9817263495868924

Epoch: 5| Step: 7
Training loss: 2.8251321879830043
Validation loss: 2.987605721347671

Epoch: 5| Step: 8
Training loss: 3.585229209478394
Validation loss: 2.9969917176686938

Epoch: 5| Step: 9
Training loss: 3.6251599506737286
Validation loss: 2.9901565071476583

Epoch: 5| Step: 10
Training loss: 3.638320389877644
Validation loss: 2.973169977896153

Epoch: 40| Step: 0
Training loss: 2.92109547380599
Validation loss: 2.9736328418122207

Epoch: 5| Step: 1
Training loss: 3.0784942870168384
Validation loss: 2.971363459999975

Epoch: 5| Step: 2
Training loss: 3.7897876792759377
Validation loss: 2.971079492604464

Epoch: 5| Step: 3
Training loss: 2.733871500797639
Validation loss: 2.968605035373955

Epoch: 5| Step: 4
Training loss: 3.186792631758777
Validation loss: 2.968226063494429

Epoch: 5| Step: 5
Training loss: 3.228854272970005
Validation loss: 2.971157209842468

Epoch: 5| Step: 6
Training loss: 3.6231951989096385
Validation loss: 2.966269815767843

Epoch: 5| Step: 7
Training loss: 3.5892461003203096
Validation loss: 2.9653949926837764

Epoch: 5| Step: 8
Training loss: 3.423787179322335
Validation loss: 2.967883530115115

Epoch: 5| Step: 9
Training loss: 3.4760595064940976
Validation loss: 2.9661156166658897

Epoch: 5| Step: 10
Training loss: 2.580439043465948
Validation loss: 2.965546111095997

Epoch: 41| Step: 0
Training loss: 3.431733722324968
Validation loss: 2.9765092778601225

Epoch: 5| Step: 1
Training loss: 3.210968537192225
Validation loss: 2.979195171632596

Epoch: 5| Step: 2
Training loss: 3.580569036428957
Validation loss: 2.985327497074794

Epoch: 5| Step: 3
Training loss: 3.0586002978258455
Validation loss: 2.9637105711148095

Epoch: 5| Step: 4
Training loss: 3.3902667862782
Validation loss: 2.958477726182259

Epoch: 5| Step: 5
Training loss: 2.3935327735124954
Validation loss: 2.959334678170333

Epoch: 5| Step: 6
Training loss: 3.3585469489553668
Validation loss: 2.956929262024536

Epoch: 5| Step: 7
Training loss: 2.745391017809253
Validation loss: 2.9595966307967196

Epoch: 5| Step: 8
Training loss: 3.0161728435438424
Validation loss: 2.9553333122376095

Epoch: 5| Step: 9
Training loss: 3.904246556547935
Validation loss: 2.956392951441404

Epoch: 5| Step: 10
Training loss: 3.533762080492732
Validation loss: 2.955290750754152

Epoch: 42| Step: 0
Training loss: 3.2949059558929314
Validation loss: 2.9551289709264483

Epoch: 5| Step: 1
Training loss: 3.112316637881042
Validation loss: 2.957123663486349

Epoch: 5| Step: 2
Training loss: 3.467652568252253
Validation loss: 2.9569825227349598

Epoch: 5| Step: 3
Training loss: 3.185124727738303
Validation loss: 2.961570889104873

Epoch: 5| Step: 4
Training loss: 3.370845356759852
Validation loss: 2.9557984610381856

Epoch: 5| Step: 5
Training loss: 3.1095120960472027
Validation loss: 2.9579261772284915

Epoch: 5| Step: 6
Training loss: 3.347066927552703
Validation loss: 2.9549410960341196

Epoch: 5| Step: 7
Training loss: 3.459062399864626
Validation loss: 2.950200031889627

Epoch: 5| Step: 8
Training loss: 3.549389321899
Validation loss: 2.9503332240117373

Epoch: 5| Step: 9
Training loss: 2.9567874218330537
Validation loss: 2.9504875284984213

Epoch: 5| Step: 10
Training loss: 2.8125079684674446
Validation loss: 2.950596726474206

Epoch: 43| Step: 0
Training loss: 3.3858240127028334
Validation loss: 2.954539552113754

Epoch: 5| Step: 1
Training loss: 3.059454512999704
Validation loss: 2.95886694708538

Epoch: 5| Step: 2
Training loss: 3.4590941055788003
Validation loss: 2.9608265308912363

Epoch: 5| Step: 3
Training loss: 3.1861416783557606
Validation loss: 2.9603045079682353

Epoch: 5| Step: 4
Training loss: 3.0958358976850677
Validation loss: 2.9517497271868445

Epoch: 5| Step: 5
Training loss: 3.188226056152831
Validation loss: 2.9475508324861788

Epoch: 5| Step: 6
Training loss: 3.6974129060568792
Validation loss: 2.947789947407876

Epoch: 5| Step: 7
Training loss: 3.3026890404746387
Validation loss: 2.9485651498222656

Epoch: 5| Step: 8
Training loss: 2.8028006409576975
Validation loss: 2.946930755271172

Epoch: 5| Step: 9
Training loss: 3.3724028873247094
Validation loss: 2.947209606966018

Epoch: 5| Step: 10
Training loss: 3.0128499441171313
Validation loss: 2.9457177872631215

Epoch: 44| Step: 0
Training loss: 3.0491873549678448
Validation loss: 2.945780822856324

Epoch: 5| Step: 1
Training loss: 3.133850534513166
Validation loss: 2.9461738765425234

Epoch: 5| Step: 2
Training loss: 3.133512880037411
Validation loss: 2.9475231576914203

Epoch: 5| Step: 3
Training loss: 2.897989819442316
Validation loss: 2.9458512151126994

Epoch: 5| Step: 4
Training loss: 3.135669955713929
Validation loss: 2.950698836019087

Epoch: 5| Step: 5
Training loss: 3.2618295616468678
Validation loss: 2.9435910931348026

Epoch: 5| Step: 6
Training loss: 3.975933152555982
Validation loss: 2.940370018595572

Epoch: 5| Step: 7
Training loss: 2.8375315324148787
Validation loss: 2.941311385949853

Epoch: 5| Step: 8
Training loss: 3.4295103683437302
Validation loss: 2.940071444893054

Epoch: 5| Step: 9
Training loss: 3.4264774115383028
Validation loss: 2.9396215094423948

Epoch: 5| Step: 10
Training loss: 3.1506642685713047
Validation loss: 2.940445059209139

Epoch: 45| Step: 0
Training loss: 3.5163901619584483
Validation loss: 2.945602002809037

Epoch: 5| Step: 1
Training loss: 2.902139032673283
Validation loss: 2.9505708066788405

Epoch: 5| Step: 2
Training loss: 3.5731702590379375
Validation loss: 2.9579351891825167

Epoch: 5| Step: 3
Training loss: 2.0294049613298752
Validation loss: 2.965901722709224

Epoch: 5| Step: 4
Training loss: 4.007799650472823
Validation loss: 2.9646670975623297

Epoch: 5| Step: 5
Training loss: 3.4070295089370837
Validation loss: 2.934686264884887

Epoch: 5| Step: 6
Training loss: 3.254066417548495
Validation loss: 2.9506260814622585

Epoch: 5| Step: 7
Training loss: 2.776747842161577
Validation loss: 2.962452303733208

Epoch: 5| Step: 8
Training loss: 3.661229581818279
Validation loss: 2.9490052639582287

Epoch: 5| Step: 9
Training loss: 2.983336582572773
Validation loss: 2.9374412874608704

Epoch: 5| Step: 10
Training loss: 3.192113940287201
Validation loss: 2.9328317108662345

Epoch: 46| Step: 0
Training loss: 3.1050503046994837
Validation loss: 2.9308131465568703

Epoch: 5| Step: 1
Training loss: 2.6452273378222535
Validation loss: 2.9318353566786786

Epoch: 5| Step: 2
Training loss: 3.3692136540998194
Validation loss: 2.932899394780861

Epoch: 5| Step: 3
Training loss: 3.602435157292911
Validation loss: 2.9362831676146888

Epoch: 5| Step: 4
Training loss: 3.5067963689549226
Validation loss: 2.945666860696825

Epoch: 5| Step: 5
Training loss: 3.1445412582332968
Validation loss: 2.956631834229119

Epoch: 5| Step: 6
Training loss: 3.7185661206344407
Validation loss: 2.953921363736075

Epoch: 5| Step: 7
Training loss: 3.1182145264864185
Validation loss: 2.9420872906952322

Epoch: 5| Step: 8
Training loss: 2.9994827460371254
Validation loss: 2.9253814979261326

Epoch: 5| Step: 9
Training loss: 2.783084136025539
Validation loss: 2.924738354581009

Epoch: 5| Step: 10
Training loss: 3.367064577766457
Validation loss: 2.9240849260002015

Epoch: 47| Step: 0
Training loss: 3.2459577217474767
Validation loss: 2.9248247193478347

Epoch: 5| Step: 1
Training loss: 2.6598973981530136
Validation loss: 2.921706901936698

Epoch: 5| Step: 2
Training loss: 3.0587755249105797
Validation loss: 2.9236974388659407

Epoch: 5| Step: 3
Training loss: 2.98517218522883
Validation loss: 2.9247644629879455

Epoch: 5| Step: 4
Training loss: 3.6942924398129846
Validation loss: 2.9233687949960254

Epoch: 5| Step: 5
Training loss: 3.6603476231069725
Validation loss: 2.920610476341246

Epoch: 5| Step: 6
Training loss: 2.779087812076154
Validation loss: 2.917043010028713

Epoch: 5| Step: 7
Training loss: 3.2674269381864867
Validation loss: 2.91635660085004

Epoch: 5| Step: 8
Training loss: 2.6400063596995653
Validation loss: 2.9147362413362856

Epoch: 5| Step: 9
Training loss: 2.7947928920709515
Validation loss: 2.9141697058779017

Epoch: 5| Step: 10
Training loss: 4.389454315611768
Validation loss: 2.917485475237668

Epoch: 48| Step: 0
Training loss: 3.4418212086214908
Validation loss: 2.924183377908987

Epoch: 5| Step: 1
Training loss: 3.274787424191839
Validation loss: 2.9182191950405385

Epoch: 5| Step: 2
Training loss: 2.898994824070963
Validation loss: 2.929113842876126

Epoch: 5| Step: 3
Training loss: 3.1084851088980967
Validation loss: 2.942160498635939

Epoch: 5| Step: 4
Training loss: 3.6106713019002727
Validation loss: 2.94570963607786

Epoch: 5| Step: 5
Training loss: 2.928633111044961
Validation loss: 2.9147461564261383

Epoch: 5| Step: 6
Training loss: 3.099274298110246
Validation loss: 2.912865450244633

Epoch: 5| Step: 7
Training loss: 3.193276948477494
Validation loss: 2.9133978344127898

Epoch: 5| Step: 8
Training loss: 2.5766784308766626
Validation loss: 2.9223169292316857

Epoch: 5| Step: 9
Training loss: 3.5687707957181285
Validation loss: 2.9298328834475016

Epoch: 5| Step: 10
Training loss: 3.6420624477891907
Validation loss: 2.922341057374753

Epoch: 49| Step: 0
Training loss: 3.063696491298689
Validation loss: 2.9133821748036484

Epoch: 5| Step: 1
Training loss: 3.1995517059073157
Validation loss: 2.9095784706867294

Epoch: 5| Step: 2
Training loss: 3.549523797131295
Validation loss: 2.9115869056116312

Epoch: 5| Step: 3
Training loss: 2.634121532622728
Validation loss: 2.911385952759395

Epoch: 5| Step: 4
Training loss: 2.305109638411778
Validation loss: 2.910543730715736

Epoch: 5| Step: 5
Training loss: 3.254312148772073
Validation loss: 2.9114555740292007

Epoch: 5| Step: 6
Training loss: 3.687376505190083
Validation loss: 2.912207157785543

Epoch: 5| Step: 7
Training loss: 3.740402146204607
Validation loss: 2.915364709374224

Epoch: 5| Step: 8
Training loss: 3.439848357783863
Validation loss: 2.911731577196297

Epoch: 5| Step: 9
Training loss: 3.2156623919716174
Validation loss: 2.913880120774396

Epoch: 5| Step: 10
Training loss: 2.800881356082333
Validation loss: 2.910290667830828

Epoch: 50| Step: 0
Training loss: 3.6504966920451816
Validation loss: 2.9106061848718863

Epoch: 5| Step: 1
Training loss: 3.4121096544969833
Validation loss: 2.905743744829413

Epoch: 5| Step: 2
Training loss: 2.683640658705743
Validation loss: 2.902701940551841

Epoch: 5| Step: 3
Training loss: 3.3893863507417867
Validation loss: 2.90326065796838

Epoch: 5| Step: 4
Training loss: 2.9733537815514173
Validation loss: 2.9018350429008977

Epoch: 5| Step: 5
Training loss: 3.2323283478727705
Validation loss: 2.9022314097142594

Epoch: 5| Step: 6
Training loss: 3.2513816537567886
Validation loss: 2.905884960517987

Epoch: 5| Step: 7
Training loss: 2.8724390316594337
Validation loss: 2.926486970573012

Epoch: 5| Step: 8
Training loss: 3.3430913829129523
Validation loss: 2.9408062455270207

Epoch: 5| Step: 9
Training loss: 2.916445660165176
Validation loss: 2.9332773075551875

Epoch: 5| Step: 10
Training loss: 3.618454910923005
Validation loss: 2.940257922736003

Epoch: 51| Step: 0
Training loss: 3.2914044883391913
Validation loss: 2.9304660791300337

Epoch: 5| Step: 1
Training loss: 2.313306203989067
Validation loss: 2.9108322967102542

Epoch: 5| Step: 2
Training loss: 3.5747671571679054
Validation loss: 2.912829685894309

Epoch: 5| Step: 3
Training loss: 3.4450939567609247
Validation loss: 2.89672605208133

Epoch: 5| Step: 4
Training loss: 2.980378675787093
Validation loss: 2.9038225353141924

Epoch: 5| Step: 5
Training loss: 3.404802067139005
Validation loss: 2.9347727029168333

Epoch: 5| Step: 6
Training loss: 3.4257681660418617
Validation loss: 2.9635815969793584

Epoch: 5| Step: 7
Training loss: 3.392678478384067
Validation loss: 2.9582784264296142

Epoch: 5| Step: 8
Training loss: 3.6454459429604595
Validation loss: 2.903273631286487

Epoch: 5| Step: 9
Training loss: 2.4339611088475355
Validation loss: 2.8941208249506696

Epoch: 5| Step: 10
Training loss: 2.9409565170171
Validation loss: 2.8939628860657858

Epoch: 52| Step: 0
Training loss: 3.0902116366010235
Validation loss: 2.89429819938764

Epoch: 5| Step: 1
Training loss: 3.177166213325127
Validation loss: 2.9115161410488395

Epoch: 5| Step: 2
Training loss: 3.292166000028055
Validation loss: 2.921652436588152

Epoch: 5| Step: 3
Training loss: 3.026397281483562
Validation loss: 2.925483183615675

Epoch: 5| Step: 4
Training loss: 3.0349548351566007
Validation loss: 2.923154855851885

Epoch: 5| Step: 5
Training loss: 3.5209608487544863
Validation loss: 2.9211014285185763

Epoch: 5| Step: 6
Training loss: 3.4202265143532324
Validation loss: 2.915961999340138

Epoch: 5| Step: 7
Training loss: 2.4611445264171974
Validation loss: 2.9001734986843535

Epoch: 5| Step: 8
Training loss: 2.988480225963378
Validation loss: 2.896857734619256

Epoch: 5| Step: 9
Training loss: 3.8557863423523733
Validation loss: 2.8875527349247623

Epoch: 5| Step: 10
Training loss: 3.222615855570701
Validation loss: 2.8902497486724528

Epoch: 53| Step: 0
Training loss: 3.7214741706407937
Validation loss: 2.8898895968933376

Epoch: 5| Step: 1
Training loss: 3.44638051889664
Validation loss: 2.893797594386578

Epoch: 5| Step: 2
Training loss: 3.0615777943240707
Validation loss: 2.9300824824046834

Epoch: 5| Step: 3
Training loss: 3.30804546907074
Validation loss: 2.970081323573222

Epoch: 5| Step: 4
Training loss: 2.9168489853324364
Validation loss: 2.9747884446788717

Epoch: 5| Step: 5
Training loss: 3.162163058338316
Validation loss: 2.9044486929543534

Epoch: 5| Step: 6
Training loss: 2.7611811221137654
Validation loss: 2.885735582374282

Epoch: 5| Step: 7
Training loss: 3.255114565706784
Validation loss: 2.885355138931576

Epoch: 5| Step: 8
Training loss: 3.195613781592055
Validation loss: 2.883215323985183

Epoch: 5| Step: 9
Training loss: 3.262108766914085
Validation loss: 2.8821502697708374

Epoch: 5| Step: 10
Training loss: 2.7603164846606814
Validation loss: 2.8803072385783266

Epoch: 54| Step: 0
Training loss: 3.1638209121214573
Validation loss: 2.8842774784081833

Epoch: 5| Step: 1
Training loss: 3.4236674034403345
Validation loss: 2.8819517023263916

Epoch: 5| Step: 2
Training loss: 3.2281295259338734
Validation loss: 2.8827596920207927

Epoch: 5| Step: 3
Training loss: 3.0532073120141576
Validation loss: 2.88429889475673

Epoch: 5| Step: 4
Training loss: 2.7669582278424882
Validation loss: 2.880180486183119

Epoch: 5| Step: 5
Training loss: 3.2709438685957157
Validation loss: 2.882084946745694

Epoch: 5| Step: 6
Training loss: 2.656619057541847
Validation loss: 2.879945881715655

Epoch: 5| Step: 7
Training loss: 2.936371931627465
Validation loss: 2.878447427036762

Epoch: 5| Step: 8
Training loss: 3.9360267668410933
Validation loss: 2.879790083556792

Epoch: 5| Step: 9
Training loss: 3.168786560690372
Validation loss: 2.88094228017241

Epoch: 5| Step: 10
Training loss: 3.181327827865599
Validation loss: 2.893141554197464

Epoch: 55| Step: 0
Training loss: 3.2457056284027233
Validation loss: 2.9081153295233775

Epoch: 5| Step: 1
Training loss: 3.295846932467936
Validation loss: 2.905537881801823

Epoch: 5| Step: 2
Training loss: 3.3013596248083084
Validation loss: 2.8787885478121433

Epoch: 5| Step: 3
Training loss: 3.115715884123752
Validation loss: 2.8762299651779037

Epoch: 5| Step: 4
Training loss: 3.3912996948065675
Validation loss: 2.875241804899928

Epoch: 5| Step: 5
Training loss: 3.77652262113047
Validation loss: 2.878042935393938

Epoch: 5| Step: 6
Training loss: 3.4529953323805542
Validation loss: 2.879736187481299

Epoch: 5| Step: 7
Training loss: 2.524777838876354
Validation loss: 2.8845066361954323

Epoch: 5| Step: 8
Training loss: 3.2797246384755585
Validation loss: 2.889469854905615

Epoch: 5| Step: 9
Training loss: 2.9648099754128623
Validation loss: 2.8764858107046614

Epoch: 5| Step: 10
Training loss: 2.351331325586751
Validation loss: 2.871046564449552

Epoch: 56| Step: 0
Training loss: 3.0059307603000063
Validation loss: 2.870028555671792

Epoch: 5| Step: 1
Training loss: 3.0529036911218843
Validation loss: 2.8706150169510916

Epoch: 5| Step: 2
Training loss: 2.8133294471906725
Validation loss: 2.8712138748180314

Epoch: 5| Step: 3
Training loss: 3.387457708678941
Validation loss: 2.8708478228358776

Epoch: 5| Step: 4
Training loss: 3.5283454495022095
Validation loss: 2.882198534812694

Epoch: 5| Step: 5
Training loss: 3.0144478669713277
Validation loss: 2.8747913557747693

Epoch: 5| Step: 6
Training loss: 3.4145817481815617
Validation loss: 2.8669859361632

Epoch: 5| Step: 7
Training loss: 3.047293922773125
Validation loss: 2.866635333584191

Epoch: 5| Step: 8
Training loss: 3.6837685018695474
Validation loss: 2.8690820486654594

Epoch: 5| Step: 9
Training loss: 3.0114023955322513
Validation loss: 2.8707752092653003

Epoch: 5| Step: 10
Training loss: 2.700937168518985
Validation loss: 2.8761797504575966

Epoch: 57| Step: 0
Training loss: 3.4976871205378375
Validation loss: 2.891802872454817

Epoch: 5| Step: 1
Training loss: 2.8947855931607602
Validation loss: 2.8794887147904054

Epoch: 5| Step: 2
Training loss: 2.8684410244639222
Validation loss: 2.8680200277042167

Epoch: 5| Step: 3
Training loss: 2.950040144566379
Validation loss: 2.870461982027096

Epoch: 5| Step: 4
Training loss: 2.615035444788931
Validation loss: 2.8638250146343402

Epoch: 5| Step: 5
Training loss: 3.5509814718972166
Validation loss: 2.864650035689382

Epoch: 5| Step: 6
Training loss: 3.106765955974186
Validation loss: 2.8596495118847787

Epoch: 5| Step: 7
Training loss: 3.1491020012547453
Validation loss: 2.858674831816796

Epoch: 5| Step: 8
Training loss: 3.624855564791594
Validation loss: 2.858288349627692

Epoch: 5| Step: 9
Training loss: 2.8140568980447696
Validation loss: 2.864478892699885

Epoch: 5| Step: 10
Training loss: 3.6598654583659007
Validation loss: 2.86285208523968

Epoch: 58| Step: 0
Training loss: 3.0953127834545238
Validation loss: 2.862794402898223

Epoch: 5| Step: 1
Training loss: 3.4931992808191086
Validation loss: 2.8633897733917433

Epoch: 5| Step: 2
Training loss: 2.2898370779793407
Validation loss: 2.8625508963536346

Epoch: 5| Step: 3
Training loss: 3.1866174111756056
Validation loss: 2.8628600622075027

Epoch: 5| Step: 4
Training loss: 3.1701679616047405
Validation loss: 2.8674656559623073

Epoch: 5| Step: 5
Training loss: 3.249020942524215
Validation loss: 2.8675419455151414

Epoch: 5| Step: 6
Training loss: 3.3631505287277634
Validation loss: 2.8613598042411925

Epoch: 5| Step: 7
Training loss: 2.5098236671000023
Validation loss: 2.8579192481167524

Epoch: 5| Step: 8
Training loss: 3.360462811021758
Validation loss: 2.8572671473917532

Epoch: 5| Step: 9
Training loss: 3.503517835303545
Validation loss: 2.8601701951940623

Epoch: 5| Step: 10
Training loss: 3.290369059724811
Validation loss: 2.855046930477831

Epoch: 59| Step: 0
Training loss: 3.715351763946235
Validation loss: 2.854884296724385

Epoch: 5| Step: 1
Training loss: 2.696454853734577
Validation loss: 2.8551058719823463

Epoch: 5| Step: 2
Training loss: 2.931734148397894
Validation loss: 2.852890709087041

Epoch: 5| Step: 3
Training loss: 2.349891246145953
Validation loss: 2.854733852590268

Epoch: 5| Step: 4
Training loss: 2.5565968882037686
Validation loss: 2.857321991263704

Epoch: 5| Step: 5
Training loss: 3.4482489634155318
Validation loss: 2.8565101870691616

Epoch: 5| Step: 6
Training loss: 3.62822211872397
Validation loss: 2.856521332764032

Epoch: 5| Step: 7
Training loss: 3.211733679897949
Validation loss: 2.860500509346331

Epoch: 5| Step: 8
Training loss: 3.303320491495073
Validation loss: 2.8627622111796613

Epoch: 5| Step: 9
Training loss: 3.5216881581445185
Validation loss: 2.850442895080321

Epoch: 5| Step: 10
Training loss: 2.960622483861014
Validation loss: 2.8481591305311325

Epoch: 60| Step: 0
Training loss: 3.4944195537425276
Validation loss: 2.8472116328243526

Epoch: 5| Step: 1
Training loss: 3.9148097134040993
Validation loss: 2.848112830583409

Epoch: 5| Step: 2
Training loss: 3.3792588948474727
Validation loss: 2.8476866643355483

Epoch: 5| Step: 3
Training loss: 2.843598749519102
Validation loss: 2.8450910923416735

Epoch: 5| Step: 4
Training loss: 3.63400518056094
Validation loss: 2.846347513221005

Epoch: 5| Step: 5
Training loss: 3.2605373047436523
Validation loss: 2.8460494324160326

Epoch: 5| Step: 6
Training loss: 3.017360839921778
Validation loss: 2.8430336409743293

Epoch: 5| Step: 7
Training loss: 2.556900698938975
Validation loss: 2.842649316918933

Epoch: 5| Step: 8
Training loss: 1.8145276270949877
Validation loss: 2.84331317707745

Epoch: 5| Step: 9
Training loss: 3.031828520321646
Validation loss: 2.844386423847607

Epoch: 5| Step: 10
Training loss: 3.199643061519577
Validation loss: 2.8462380459475285

Epoch: 61| Step: 0
Training loss: 3.1280501167106975
Validation loss: 2.8430604455893675

Epoch: 5| Step: 1
Training loss: 2.707285331042515
Validation loss: 2.8552470412858053

Epoch: 5| Step: 2
Training loss: 2.9930025190909326
Validation loss: 2.8586128681041525

Epoch: 5| Step: 3
Training loss: 3.4496747900231677
Validation loss: 2.8441259078684014

Epoch: 5| Step: 4
Training loss: 2.9998825368137627
Validation loss: 2.842718127169954

Epoch: 5| Step: 5
Training loss: 2.795190229135259
Validation loss: 2.839629899986846

Epoch: 5| Step: 6
Training loss: 3.395948880029905
Validation loss: 2.840256553846266

Epoch: 5| Step: 7
Training loss: 3.046453828312445
Validation loss: 2.8379987878103745

Epoch: 5| Step: 8
Training loss: 3.4630944137723376
Validation loss: 2.8397704167722035

Epoch: 5| Step: 9
Training loss: 3.1573206530307765
Validation loss: 2.838994715243375

Epoch: 5| Step: 10
Training loss: 3.382986579627092
Validation loss: 2.8366892678218982

Epoch: 62| Step: 0
Training loss: 3.443907159171991
Validation loss: 2.8371507984970052

Epoch: 5| Step: 1
Training loss: 2.770424509123899
Validation loss: 2.8346880407278356

Epoch: 5| Step: 2
Training loss: 3.568854570610435
Validation loss: 2.837944663559972

Epoch: 5| Step: 3
Training loss: 2.5980022458132113
Validation loss: 2.83577587942102

Epoch: 5| Step: 4
Training loss: 2.9397939288002886
Validation loss: 2.8343421713169086

Epoch: 5| Step: 5
Training loss: 2.8161464364980273
Validation loss: 2.8350379199814526

Epoch: 5| Step: 6
Training loss: 3.189491547389894
Validation loss: 2.8343207094426437

Epoch: 5| Step: 7
Training loss: 3.8038584845821406
Validation loss: 2.833126316313257

Epoch: 5| Step: 8
Training loss: 2.6373236972406513
Validation loss: 2.8352935158370802

Epoch: 5| Step: 9
Training loss: 3.2156431147562836
Validation loss: 2.8328718054431428

Epoch: 5| Step: 10
Training loss: 3.372956116233375
Validation loss: 2.8312299607119695

Epoch: 63| Step: 0
Training loss: 3.7199769119858805
Validation loss: 2.827744102900715

Epoch: 5| Step: 1
Training loss: 3.323465300005673
Validation loss: 2.8267471164936246

Epoch: 5| Step: 2
Training loss: 3.0323974954336874
Validation loss: 2.8233592343324254

Epoch: 5| Step: 3
Training loss: 3.3575022600724487
Validation loss: 2.8240784016904086

Epoch: 5| Step: 4
Training loss: 3.187733510757747
Validation loss: 2.827055164966138

Epoch: 5| Step: 5
Training loss: 3.151872526398943
Validation loss: 2.821119912647674

Epoch: 5| Step: 6
Training loss: 2.7804662050094597
Validation loss: 2.8225452487677423

Epoch: 5| Step: 7
Training loss: 3.0408643073604598
Validation loss: 2.820182116671621

Epoch: 5| Step: 8
Training loss: 3.330483187653802
Validation loss: 2.819972297521043

Epoch: 5| Step: 9
Training loss: 2.526452120963119
Validation loss: 2.819182006794299

Epoch: 5| Step: 10
Training loss: 2.737519031615271
Validation loss: 2.8175167210942935

Epoch: 64| Step: 0
Training loss: 2.9027966727372405
Validation loss: 2.8201710391649755

Epoch: 5| Step: 1
Training loss: 3.3109659925515706
Validation loss: 2.8205742420114257

Epoch: 5| Step: 2
Training loss: 2.756387661287965
Validation loss: 2.82576843208188

Epoch: 5| Step: 3
Training loss: 2.705202748426671
Validation loss: 2.8232340786158763

Epoch: 5| Step: 4
Training loss: 2.8637651604426364
Validation loss: 2.82750459641071

Epoch: 5| Step: 5
Training loss: 3.4347309403635142
Validation loss: 2.824632955161922

Epoch: 5| Step: 6
Training loss: 3.4596603482627883
Validation loss: 2.8186052450064794

Epoch: 5| Step: 7
Training loss: 3.185261707183495
Validation loss: 2.8182541571025443

Epoch: 5| Step: 8
Training loss: 3.4948872961992303
Validation loss: 2.8176189730897208

Epoch: 5| Step: 9
Training loss: 2.8498018028543246
Validation loss: 2.8159546475752433

Epoch: 5| Step: 10
Training loss: 3.2337918700348687
Validation loss: 2.8175858830832308

Epoch: 65| Step: 0
Training loss: 3.118583500456001
Validation loss: 2.8150926150537567

Epoch: 5| Step: 1
Training loss: 3.205991179075142
Validation loss: 2.8113289048174117

Epoch: 5| Step: 2
Training loss: 2.6745158746732827
Validation loss: 2.810593652404717

Epoch: 5| Step: 3
Training loss: 3.5063336149911204
Validation loss: 2.8124791389521153

Epoch: 5| Step: 4
Training loss: 3.1406072359863755
Validation loss: 2.8139376412659063

Epoch: 5| Step: 5
Training loss: 3.3478159204282356
Validation loss: 2.8161786176165653

Epoch: 5| Step: 6
Training loss: 3.210009958364661
Validation loss: 2.8167817477882187

Epoch: 5| Step: 7
Training loss: 2.932392956535342
Validation loss: 2.8169755098527234

Epoch: 5| Step: 8
Training loss: 2.850380681362846
Validation loss: 2.818949378424508

Epoch: 5| Step: 9
Training loss: 2.612596270963987
Validation loss: 2.817934208523392

Epoch: 5| Step: 10
Training loss: 3.713977219272935
Validation loss: 2.8121013545697133

Epoch: 66| Step: 0
Training loss: 3.8684584253529315
Validation loss: 2.81587418450374

Epoch: 5| Step: 1
Training loss: 3.352898035962768
Validation loss: 2.8150719945145948

Epoch: 5| Step: 2
Training loss: 3.0843741404368896
Validation loss: 2.8163877308534073

Epoch: 5| Step: 3
Training loss: 3.4270169020748837
Validation loss: 2.8112611026805756

Epoch: 5| Step: 4
Training loss: 2.71655842813125
Validation loss: 2.8116243063352435

Epoch: 5| Step: 5
Training loss: 3.1879388843646823
Validation loss: 2.8154160526193275

Epoch: 5| Step: 6
Training loss: 3.242992181769118
Validation loss: 2.8153319964104533

Epoch: 5| Step: 7
Training loss: 2.9503003694882723
Validation loss: 2.81203055890551

Epoch: 5| Step: 8
Training loss: 3.241274785639587
Validation loss: 2.812529801879645

Epoch: 5| Step: 9
Training loss: 2.018358491425259
Validation loss: 2.814891905573897

Epoch: 5| Step: 10
Training loss: 2.82422415283024
Validation loss: 2.814038204919924

Epoch: 67| Step: 0
Training loss: 3.3459384209711858
Validation loss: 2.816139220252064

Epoch: 5| Step: 1
Training loss: 2.702010614087698
Validation loss: 2.8240788701046204

Epoch: 5| Step: 2
Training loss: 3.162236645253789
Validation loss: 2.8296636242788815

Epoch: 5| Step: 3
Training loss: 2.437682511759316
Validation loss: 2.8323695134745845

Epoch: 5| Step: 4
Training loss: 3.150362472266491
Validation loss: 2.8297385086130893

Epoch: 5| Step: 5
Training loss: 2.9525349345389382
Validation loss: 2.815603119897156

Epoch: 5| Step: 6
Training loss: 3.1230690140025956
Validation loss: 2.809807496500994

Epoch: 5| Step: 7
Training loss: 2.8753892386285034
Validation loss: 2.8057352837839056

Epoch: 5| Step: 8
Training loss: 3.5890328671365936
Validation loss: 2.8068541734714807

Epoch: 5| Step: 9
Training loss: 3.543185966587591
Validation loss: 2.803688647714219

Epoch: 5| Step: 10
Training loss: 3.1894443042303777
Validation loss: 2.8027829886653075

Epoch: 68| Step: 0
Training loss: 3.0299695643542504
Validation loss: 2.8027887438059595

Epoch: 5| Step: 1
Training loss: 3.332986209597072
Validation loss: 2.8022360911970563

Epoch: 5| Step: 2
Training loss: 3.212195825091894
Validation loss: 2.7984736544934603

Epoch: 5| Step: 3
Training loss: 3.3450819553433764
Validation loss: 2.7996141576403257

Epoch: 5| Step: 4
Training loss: 3.4754044221970983
Validation loss: 2.800541007532806

Epoch: 5| Step: 5
Training loss: 2.589499794514573
Validation loss: 2.7989899372907567

Epoch: 5| Step: 6
Training loss: 2.774585497029848
Validation loss: 2.7968715196336804

Epoch: 5| Step: 7
Training loss: 3.342103356599165
Validation loss: 2.79622644964417

Epoch: 5| Step: 8
Training loss: 3.0361866815842675
Validation loss: 2.7941053174599353

Epoch: 5| Step: 9
Training loss: 3.1479446366130177
Validation loss: 2.795964860888773

Epoch: 5| Step: 10
Training loss: 2.6710976702429003
Validation loss: 2.80026378414511

Epoch: 69| Step: 0
Training loss: 4.026322065938356
Validation loss: 2.8072495741685635

Epoch: 5| Step: 1
Training loss: 2.7819379320056257
Validation loss: 2.813204536018886

Epoch: 5| Step: 2
Training loss: 3.010150743682918
Validation loss: 2.8269698170581194

Epoch: 5| Step: 3
Training loss: 2.9814651443616538
Validation loss: 2.82592410778528

Epoch: 5| Step: 4
Training loss: 3.3886178399870523
Validation loss: 2.8221623876985165

Epoch: 5| Step: 5
Training loss: 2.8769546166938595
Validation loss: 2.810072571651526

Epoch: 5| Step: 6
Training loss: 3.2020212644386796
Validation loss: 2.7982180577648372

Epoch: 5| Step: 7
Training loss: 2.8674527495132187
Validation loss: 2.7942979491322

Epoch: 5| Step: 8
Training loss: 2.789834906639626
Validation loss: 2.795410201645918

Epoch: 5| Step: 9
Training loss: 2.947215469772876
Validation loss: 2.797805783410298

Epoch: 5| Step: 10
Training loss: 3.037099640760124
Validation loss: 2.7929295007087833

Epoch: 70| Step: 0
Training loss: 3.0746592263062515
Validation loss: 2.788877728378102

Epoch: 5| Step: 1
Training loss: 3.1774753683052404
Validation loss: 2.793819877853792

Epoch: 5| Step: 2
Training loss: 2.97159063059744
Validation loss: 2.7880485063067453

Epoch: 5| Step: 3
Training loss: 2.915629193301932
Validation loss: 2.790553770316177

Epoch: 5| Step: 4
Training loss: 3.047487481007824
Validation loss: 2.7884253221034996

Epoch: 5| Step: 5
Training loss: 3.4977123413632523
Validation loss: 2.7864042755087626

Epoch: 5| Step: 6
Training loss: 3.5341922351860013
Validation loss: 2.786565821156451

Epoch: 5| Step: 7
Training loss: 2.791760419343621
Validation loss: 2.784594797732294

Epoch: 5| Step: 8
Training loss: 3.446133262807295
Validation loss: 2.785857427691372

Epoch: 5| Step: 9
Training loss: 2.8347281407388913
Validation loss: 2.7850144827170418

Epoch: 5| Step: 10
Training loss: 2.540086557310189
Validation loss: 2.7853319705524346

Epoch: 71| Step: 0
Training loss: 3.1375466818205315
Validation loss: 2.782720065061017

Epoch: 5| Step: 1
Training loss: 3.377804191664544
Validation loss: 2.781840327312695

Epoch: 5| Step: 2
Training loss: 3.3011156623775
Validation loss: 2.7789433901594403

Epoch: 5| Step: 3
Training loss: 3.7035954816336445
Validation loss: 2.7794832058727903

Epoch: 5| Step: 4
Training loss: 3.0439714731090306
Validation loss: 2.7810753692264023

Epoch: 5| Step: 5
Training loss: 3.1475263843839447
Validation loss: 2.779648826313626

Epoch: 5| Step: 6
Training loss: 2.6454929423204727
Validation loss: 2.778712745095593

Epoch: 5| Step: 7
Training loss: 2.726360062131378
Validation loss: 2.7778705336011407

Epoch: 5| Step: 8
Training loss: 2.785505660772178
Validation loss: 2.7792622310524764

Epoch: 5| Step: 9
Training loss: 3.0932155879674825
Validation loss: 2.781747852475372

Epoch: 5| Step: 10
Training loss: 2.8578228515971453
Validation loss: 2.793397025257563

Epoch: 72| Step: 0
Training loss: 2.9878561278486377
Validation loss: 2.8075306606290464

Epoch: 5| Step: 1
Training loss: 3.549090932584555
Validation loss: 2.80317646964848

Epoch: 5| Step: 2
Training loss: 2.914905415958531
Validation loss: 2.7793168837630042

Epoch: 5| Step: 3
Training loss: 3.3030519879806213
Validation loss: 2.7768669050790904

Epoch: 5| Step: 4
Training loss: 2.9510547304161645
Validation loss: 2.7760657542025062

Epoch: 5| Step: 5
Training loss: 2.8015539148968256
Validation loss: 2.774192874268767

Epoch: 5| Step: 6
Training loss: 2.745108936559327
Validation loss: 2.7772065132747437

Epoch: 5| Step: 7
Training loss: 2.6769779842641337
Validation loss: 2.7778029761316563

Epoch: 5| Step: 8
Training loss: 3.194832390342312
Validation loss: 2.777794766903952

Epoch: 5| Step: 9
Training loss: 2.986643303654891
Validation loss: 2.7795446517743074

Epoch: 5| Step: 10
Training loss: 3.811036376170929
Validation loss: 2.7829441719074106

Epoch: 73| Step: 0
Training loss: 2.7634567123067906
Validation loss: 2.779211675646562

Epoch: 5| Step: 1
Training loss: 3.201900043259303
Validation loss: 2.77979975303117

Epoch: 5| Step: 2
Training loss: 3.4428497300805936
Validation loss: 2.7745994018568187

Epoch: 5| Step: 3
Training loss: 2.883316946993738
Validation loss: 2.77190793356551

Epoch: 5| Step: 4
Training loss: 3.3408382965023113
Validation loss: 2.7717057405282906

Epoch: 5| Step: 5
Training loss: 2.787533466497445
Validation loss: 2.767790397911812

Epoch: 5| Step: 6
Training loss: 2.7801797071869565
Validation loss: 2.7700375010752594

Epoch: 5| Step: 7
Training loss: 3.1921181229172486
Validation loss: 2.767597231970232

Epoch: 5| Step: 8
Training loss: 2.8152368580720024
Validation loss: 2.771343398597308

Epoch: 5| Step: 9
Training loss: 3.435835417948024
Validation loss: 2.776030928637489

Epoch: 5| Step: 10
Training loss: 3.155152384951577
Validation loss: 2.8008838649125694

Epoch: 74| Step: 0
Training loss: 2.7772010734383508
Validation loss: 2.860843020922901

Epoch: 5| Step: 1
Training loss: 3.248956806312554
Validation loss: 2.812819243329904

Epoch: 5| Step: 2
Training loss: 2.9032311295901483
Validation loss: 2.784213443401743

Epoch: 5| Step: 3
Training loss: 3.336555370134905
Validation loss: 2.7618025535969633

Epoch: 5| Step: 4
Training loss: 3.056394446456331
Validation loss: 2.7642732448389986

Epoch: 5| Step: 5
Training loss: 3.3190560869636783
Validation loss: 2.7666816118234276

Epoch: 5| Step: 6
Training loss: 3.0918095215510464
Validation loss: 2.7691689688557966

Epoch: 5| Step: 7
Training loss: 2.3699212230997744
Validation loss: 2.7677054825495846

Epoch: 5| Step: 8
Training loss: 3.3072223005254386
Validation loss: 2.764180726713609

Epoch: 5| Step: 9
Training loss: 3.5879553475977066
Validation loss: 2.766091651912673

Epoch: 5| Step: 10
Training loss: 2.7685944730937595
Validation loss: 2.763913478224228

Epoch: 75| Step: 0
Training loss: 2.7555830375606702
Validation loss: 2.7641490930529384

Epoch: 5| Step: 1
Training loss: 2.9703270186902695
Validation loss: 2.761380802992733

Epoch: 5| Step: 2
Training loss: 3.065454264794753
Validation loss: 2.7645705660010162

Epoch: 5| Step: 3
Training loss: 3.1039742190381694
Validation loss: 2.7648484511904936

Epoch: 5| Step: 4
Training loss: 3.001313716620395
Validation loss: 2.7666575225840075

Epoch: 5| Step: 5
Training loss: 3.0931810568730285
Validation loss: 2.773671584856919

Epoch: 5| Step: 6
Training loss: 3.2039024339982
Validation loss: 2.776430185277248

Epoch: 5| Step: 7
Training loss: 2.982940328985248
Validation loss: 2.774340730544121

Epoch: 5| Step: 8
Training loss: 3.2709820626495043
Validation loss: 2.774482816840387

Epoch: 5| Step: 9
Training loss: 2.929295058350967
Validation loss: 2.7688145160114424

Epoch: 5| Step: 10
Training loss: 3.4630296983670905
Validation loss: 2.7613803332269296

Epoch: 76| Step: 0
Training loss: 2.9545575255034024
Validation loss: 2.7550346995476347

Epoch: 5| Step: 1
Training loss: 3.2835839100086024
Validation loss: 2.755802969590316

Epoch: 5| Step: 2
Training loss: 2.99447440858034
Validation loss: 2.754315510279031

Epoch: 5| Step: 3
Training loss: 3.36804669740611
Validation loss: 2.755635699189651

Epoch: 5| Step: 4
Training loss: 3.098226064296051
Validation loss: 2.7591992997600254

Epoch: 5| Step: 5
Training loss: 2.8594160233353305
Validation loss: 2.758626679231464

Epoch: 5| Step: 6
Training loss: 2.907794664954456
Validation loss: 2.779730052998459

Epoch: 5| Step: 7
Training loss: 2.9931965613039933
Validation loss: 2.786872731904547

Epoch: 5| Step: 8
Training loss: 3.050869714526441
Validation loss: 2.8084963450847917

Epoch: 5| Step: 9
Training loss: 3.205764501745163
Validation loss: 2.840211448319824

Epoch: 5| Step: 10
Training loss: 3.3089841501980946
Validation loss: 2.819249599339669

Epoch: 77| Step: 0
Training loss: 2.9185007777197494
Validation loss: 2.8217489119333545

Epoch: 5| Step: 1
Training loss: 2.807727324606077
Validation loss: 2.824631776641345

Epoch: 5| Step: 2
Training loss: 3.1885410179645155
Validation loss: 2.835087711380617

Epoch: 5| Step: 3
Training loss: 2.686546156415206
Validation loss: 2.847447356027028

Epoch: 5| Step: 4
Training loss: 3.2049910901402545
Validation loss: 2.872797082349472

Epoch: 5| Step: 5
Training loss: 3.310221770310886
Validation loss: 2.8953516227434632

Epoch: 5| Step: 6
Training loss: 2.975098257285451
Validation loss: 2.8669729381347535

Epoch: 5| Step: 7
Training loss: 3.2911736968250915
Validation loss: 2.8330347255475563

Epoch: 5| Step: 8
Training loss: 3.2617971079659687
Validation loss: 2.8111552041655776

Epoch: 5| Step: 9
Training loss: 2.7901477572238202
Validation loss: 2.8021172517137996

Epoch: 5| Step: 10
Training loss: 3.7924423402490604
Validation loss: 2.7994910388111953

Epoch: 78| Step: 0
Training loss: 3.3261886479777476
Validation loss: 2.8054215058622303

Epoch: 5| Step: 1
Training loss: 3.292349217466303
Validation loss: 2.8090675382591646

Epoch: 5| Step: 2
Training loss: 3.0452839144935315
Validation loss: 2.804659935600436

Epoch: 5| Step: 3
Training loss: 3.6942573315140503
Validation loss: 2.7957926897348955

Epoch: 5| Step: 4
Training loss: 2.7035894270580543
Validation loss: 2.791399149657245

Epoch: 5| Step: 5
Training loss: 3.0446998069880142
Validation loss: 2.7869938192209793

Epoch: 5| Step: 6
Training loss: 3.331270978621795
Validation loss: 2.7818256854839714

Epoch: 5| Step: 7
Training loss: 3.301769366014243
Validation loss: 2.779467063877419

Epoch: 5| Step: 8
Training loss: 2.5372584110503604
Validation loss: 2.771963460979175

Epoch: 5| Step: 9
Training loss: 2.9308418949607016
Validation loss: 2.7695285368930858

Epoch: 5| Step: 10
Training loss: 2.667199399504797
Validation loss: 2.7633158839280823

Epoch: 79| Step: 0
Training loss: 2.850451443705429
Validation loss: 2.751895905430843

Epoch: 5| Step: 1
Training loss: 2.9191362733934847
Validation loss: 2.748656183204625

Epoch: 5| Step: 2
Training loss: 3.340374535216442
Validation loss: 2.784695571313489

Epoch: 5| Step: 3
Training loss: 3.27937277728195
Validation loss: 2.8284511664753405

Epoch: 5| Step: 4
Training loss: 2.8290004323700795
Validation loss: 2.8059926324247306

Epoch: 5| Step: 5
Training loss: 3.4566254285990685
Validation loss: 2.7594143763473076

Epoch: 5| Step: 6
Training loss: 3.575263865943408
Validation loss: 2.7391314383955407

Epoch: 5| Step: 7
Training loss: 2.440150946810257
Validation loss: 2.745135767201469

Epoch: 5| Step: 8
Training loss: 3.125158687377181
Validation loss: 2.752204606095425

Epoch: 5| Step: 9
Training loss: 2.9416425997548346
Validation loss: 2.7612370518557796

Epoch: 5| Step: 10
Training loss: 2.859061302112258
Validation loss: 2.7574228079218526

Epoch: 80| Step: 0
Training loss: 3.2356150733127893
Validation loss: 2.7576079449742994

Epoch: 5| Step: 1
Training loss: 3.2323473780595937
Validation loss: 2.7568348987776408

Epoch: 5| Step: 2
Training loss: 3.4567727547247906
Validation loss: 2.752416568797947

Epoch: 5| Step: 3
Training loss: 3.129671039052364
Validation loss: 2.7511221776569146

Epoch: 5| Step: 4
Training loss: 2.861519264893552
Validation loss: 2.7480548904266717

Epoch: 5| Step: 5
Training loss: 3.3708314937276893
Validation loss: 2.7510870335396276

Epoch: 5| Step: 6
Training loss: 2.7435996394569706
Validation loss: 2.750261611278181

Epoch: 5| Step: 7
Training loss: 2.9982455209536223
Validation loss: 2.7533832570970413

Epoch: 5| Step: 8
Training loss: 2.9802613992421034
Validation loss: 2.7560646653528234

Epoch: 5| Step: 9
Training loss: 2.7851558219834436
Validation loss: 2.7651594940631505

Epoch: 5| Step: 10
Training loss: 2.9110908799604935
Validation loss: 2.7656633761305116

Epoch: 81| Step: 0
Training loss: 2.4825194524980563
Validation loss: 2.7664492374038088

Epoch: 5| Step: 1
Training loss: 3.2326465355745904
Validation loss: 2.764923588892747

Epoch: 5| Step: 2
Training loss: 3.1892462042492675
Validation loss: 2.754169579928943

Epoch: 5| Step: 3
Training loss: 3.1856640783064387
Validation loss: 2.7475451916911107

Epoch: 5| Step: 4
Training loss: 3.1364738397247685
Validation loss: 2.7458000720988216

Epoch: 5| Step: 5
Training loss: 2.922271538412176
Validation loss: 2.7364313679495855

Epoch: 5| Step: 6
Training loss: 2.58876109328534
Validation loss: 2.7354198282003606

Epoch: 5| Step: 7
Training loss: 2.912435041366283
Validation loss: 2.7338335054810847

Epoch: 5| Step: 8
Training loss: 3.571882507903718
Validation loss: 2.735031832839907

Epoch: 5| Step: 9
Training loss: 2.970360409482196
Validation loss: 2.735510387582841

Epoch: 5| Step: 10
Training loss: 3.356290030640289
Validation loss: 2.732969033579966

Epoch: 82| Step: 0
Training loss: 2.987140113509786
Validation loss: 2.7345730805030493

Epoch: 5| Step: 1
Training loss: 3.264220889545784
Validation loss: 2.7373843479679323

Epoch: 5| Step: 2
Training loss: 2.8905398794477364
Validation loss: 2.7367013212419975

Epoch: 5| Step: 3
Training loss: 3.1801402076665553
Validation loss: 2.7305018779921997

Epoch: 5| Step: 4
Training loss: 2.8580062174852894
Validation loss: 2.730172433574205

Epoch: 5| Step: 5
Training loss: 2.6650515870903937
Validation loss: 2.728950850473452

Epoch: 5| Step: 6
Training loss: 3.3521471914053356
Validation loss: 2.7302651604429506

Epoch: 5| Step: 7
Training loss: 2.4051593439050922
Validation loss: 2.729922930902877

Epoch: 5| Step: 8
Training loss: 3.3998867408737374
Validation loss: 2.7425331627309477

Epoch: 5| Step: 9
Training loss: 3.069411283825037
Validation loss: 2.7349672590802365

Epoch: 5| Step: 10
Training loss: 3.4231836612251767
Validation loss: 2.740918433099877

Epoch: 83| Step: 0
Training loss: 3.176271295217131
Validation loss: 2.7356625349159085

Epoch: 5| Step: 1
Training loss: 2.629512269227382
Validation loss: 2.7323020153436017

Epoch: 5| Step: 2
Training loss: 3.1050034660283155
Validation loss: 2.73692495116494

Epoch: 5| Step: 3
Training loss: 3.3106167316099464
Validation loss: 2.733767785596458

Epoch: 5| Step: 4
Training loss: 3.5033165340825363
Validation loss: 2.7344366157492352

Epoch: 5| Step: 5
Training loss: 3.4146923470604555
Validation loss: 2.733416576328464

Epoch: 5| Step: 6
Training loss: 3.2084872881789264
Validation loss: 2.7271524050861395

Epoch: 5| Step: 7
Training loss: 2.7422347974909647
Validation loss: 2.720571037963413

Epoch: 5| Step: 8
Training loss: 2.9136425871424847
Validation loss: 2.718496458616775

Epoch: 5| Step: 9
Training loss: 2.693890979025053
Validation loss: 2.717774814698823

Epoch: 5| Step: 10
Training loss: 2.4495344186713552
Validation loss: 2.7149567346912584

Epoch: 84| Step: 0
Training loss: 2.888161924382467
Validation loss: 2.716920190931259

Epoch: 5| Step: 1
Training loss: 2.382284737596219
Validation loss: 2.7154612628213917

Epoch: 5| Step: 2
Training loss: 3.591146703788683
Validation loss: 2.712896291123454

Epoch: 5| Step: 3
Training loss: 2.9670483982933176
Validation loss: 2.7160246285033773

Epoch: 5| Step: 4
Training loss: 3.122477925133232
Validation loss: 2.713654808860224

Epoch: 5| Step: 5
Training loss: 2.9495584254410576
Validation loss: 2.723158770760465

Epoch: 5| Step: 6
Training loss: 3.1274884806298116
Validation loss: 2.7336135924543363

Epoch: 5| Step: 7
Training loss: 3.1031858870419176
Validation loss: 2.7660965602926066

Epoch: 5| Step: 8
Training loss: 2.6168327432723335
Validation loss: 2.7648589381018422

Epoch: 5| Step: 9
Training loss: 3.395272862027025
Validation loss: 2.7552649410386114

Epoch: 5| Step: 10
Training loss: 3.2235859217753697
Validation loss: 2.7356024565107284

Epoch: 85| Step: 0
Training loss: 3.3522636907188277
Validation loss: 2.7238200260077

Epoch: 5| Step: 1
Training loss: 3.3557043559055026
Validation loss: 2.7285116064417143

Epoch: 5| Step: 2
Training loss: 2.9911368096532294
Validation loss: 2.711717318069171

Epoch: 5| Step: 3
Training loss: 2.9444384504853023
Validation loss: 2.7065730947887827

Epoch: 5| Step: 4
Training loss: 2.626390815311422
Validation loss: 2.707623710778059

Epoch: 5| Step: 5
Training loss: 2.7361651854703832
Validation loss: 2.707432391786685

Epoch: 5| Step: 6
Training loss: 2.83566862991329
Validation loss: 2.706101092228304

Epoch: 5| Step: 7
Training loss: 2.7528376244195147
Validation loss: 2.7032092990139214

Epoch: 5| Step: 8
Training loss: 3.405315585979118
Validation loss: 2.705451821706904

Epoch: 5| Step: 9
Training loss: 2.919843814278475
Validation loss: 2.7034888685604814

Epoch: 5| Step: 10
Training loss: 3.296865164936456
Validation loss: 2.703209601543702

Epoch: 86| Step: 0
Training loss: 3.3944603108147806
Validation loss: 2.7031334777240064

Epoch: 5| Step: 1
Training loss: 2.8917715737022966
Validation loss: 2.701478895911459

Epoch: 5| Step: 2
Training loss: 3.146262655372917
Validation loss: 2.701062580002354

Epoch: 5| Step: 3
Training loss: 3.156827817091115
Validation loss: 2.7017286019061526

Epoch: 5| Step: 4
Training loss: 3.1737941704914494
Validation loss: 2.7028774717418784

Epoch: 5| Step: 5
Training loss: 2.7417434376303897
Validation loss: 2.7021182578611285

Epoch: 5| Step: 6
Training loss: 3.2000816215596055
Validation loss: 2.707388649850157

Epoch: 5| Step: 7
Training loss: 3.4504867763158105
Validation loss: 2.7037983476013263

Epoch: 5| Step: 8
Training loss: 2.8990550244502153
Validation loss: 2.711875180996828

Epoch: 5| Step: 9
Training loss: 2.4848332012542453
Validation loss: 2.69990194424435

Epoch: 5| Step: 10
Training loss: 2.572900367922002
Validation loss: 2.704820774266996

Epoch: 87| Step: 0
Training loss: 3.228048725833453
Validation loss: 2.709546335468343

Epoch: 5| Step: 1
Training loss: 3.6916412117269206
Validation loss: 2.711774952441973

Epoch: 5| Step: 2
Training loss: 2.472831249824015
Validation loss: 2.7131410448315805

Epoch: 5| Step: 3
Training loss: 3.2643476844621975
Validation loss: 2.7148960479422954

Epoch: 5| Step: 4
Training loss: 3.001634470420833
Validation loss: 2.7158425730028113

Epoch: 5| Step: 5
Training loss: 2.5614420870254997
Validation loss: 2.710261296835611

Epoch: 5| Step: 6
Training loss: 3.1266487349895447
Validation loss: 2.7116253419864713

Epoch: 5| Step: 7
Training loss: 2.9435573377148674
Validation loss: 2.7083127531369313

Epoch: 5| Step: 8
Training loss: 3.365218221721969
Validation loss: 2.7022065824009363

Epoch: 5| Step: 9
Training loss: 2.805393310824343
Validation loss: 2.7010029478438704

Epoch: 5| Step: 10
Training loss: 2.7648088360835095
Validation loss: 2.6991586905405156

Epoch: 88| Step: 0
Training loss: 2.532748120458687
Validation loss: 2.7032381036803583

Epoch: 5| Step: 1
Training loss: 3.707883200310986
Validation loss: 2.7226999387350337

Epoch: 5| Step: 2
Training loss: 3.1295116662744915
Validation loss: 2.742743402444933

Epoch: 5| Step: 3
Training loss: 3.1950053694654548
Validation loss: 2.764494997689163

Epoch: 5| Step: 4
Training loss: 2.991215560466147
Validation loss: 2.751781840033017

Epoch: 5| Step: 5
Training loss: 2.7352109666596123
Validation loss: 2.715335758221268

Epoch: 5| Step: 6
Training loss: 2.7319192376326327
Validation loss: 2.6954775780644527

Epoch: 5| Step: 7
Training loss: 2.9889242440377575
Validation loss: 2.6945937739415857

Epoch: 5| Step: 8
Training loss: 3.1818861049982075
Validation loss: 2.701121779951983

Epoch: 5| Step: 9
Training loss: 3.1000700850409055
Validation loss: 2.6953230634270997

Epoch: 5| Step: 10
Training loss: 2.9981941510039434
Validation loss: 2.7000870033961317

Epoch: 89| Step: 0
Training loss: 3.1609418385316093
Validation loss: 2.702917857961334

Epoch: 5| Step: 1
Training loss: 3.1165180300052264
Validation loss: 2.701756591140924

Epoch: 5| Step: 2
Training loss: 3.368075862093576
Validation loss: 2.6989488798750143

Epoch: 5| Step: 3
Training loss: 2.6346411085291965
Validation loss: 2.6996208855262007

Epoch: 5| Step: 4
Training loss: 3.1735141070617168
Validation loss: 2.7212782860066524

Epoch: 5| Step: 5
Training loss: 2.9158767902209983
Validation loss: 2.7865721939893624

Epoch: 5| Step: 6
Training loss: 2.6316577405176225
Validation loss: 2.736387437039704

Epoch: 5| Step: 7
Training loss: 2.682736633330047
Validation loss: 2.715947881719192

Epoch: 5| Step: 8
Training loss: 3.697444631330916
Validation loss: 2.698059493184314

Epoch: 5| Step: 9
Training loss: 2.9075914793965763
Validation loss: 2.689228617056654

Epoch: 5| Step: 10
Training loss: 2.9836907526086125
Validation loss: 2.691886029082604

Epoch: 90| Step: 0
Training loss: 3.3102492837299384
Validation loss: 2.6928502908196785

Epoch: 5| Step: 1
Training loss: 2.51406679407942
Validation loss: 2.6933885581817116

Epoch: 5| Step: 2
Training loss: 3.5342872183748413
Validation loss: 2.694488642021768

Epoch: 5| Step: 3
Training loss: 2.773792598718727
Validation loss: 2.6945688413977793

Epoch: 5| Step: 4
Training loss: 2.1010462470722593
Validation loss: 2.691325729672769

Epoch: 5| Step: 5
Training loss: 3.0642648399574433
Validation loss: 2.6911337959686237

Epoch: 5| Step: 6
Training loss: 2.975561098671763
Validation loss: 2.6870571724603294

Epoch: 5| Step: 7
Training loss: 3.049968850649003
Validation loss: 2.6896225364165587

Epoch: 5| Step: 8
Training loss: 3.2516696749122063
Validation loss: 2.697391233798341

Epoch: 5| Step: 9
Training loss: 3.292662329122597
Validation loss: 2.6997882374098863

Epoch: 5| Step: 10
Training loss: 3.141070130341044
Validation loss: 2.7071049203791855

Epoch: 91| Step: 0
Training loss: 3.0170479219175443
Validation loss: 2.7116000659091424

Epoch: 5| Step: 1
Training loss: 3.2590875486054527
Validation loss: 2.7145267093999577

Epoch: 5| Step: 2
Training loss: 3.248499156959428
Validation loss: 2.7050046780568744

Epoch: 5| Step: 3
Training loss: 3.1443143971228613
Validation loss: 2.714210309936467

Epoch: 5| Step: 4
Training loss: 2.827353187749774
Validation loss: 2.703802043536852

Epoch: 5| Step: 5
Training loss: 2.6700335844120815
Validation loss: 2.699442223847214

Epoch: 5| Step: 6
Training loss: 2.4218740155617957
Validation loss: 2.684718162016448

Epoch: 5| Step: 7
Training loss: 3.428810094292148
Validation loss: 2.6826496545252256

Epoch: 5| Step: 8
Training loss: 2.564606335865016
Validation loss: 2.6837745270423423

Epoch: 5| Step: 9
Training loss: 3.126121319818792
Validation loss: 2.6843155779462076

Epoch: 5| Step: 10
Training loss: 3.3104330847885
Validation loss: 2.684867329675581

Epoch: 92| Step: 0
Training loss: 2.9557604458984152
Validation loss: 2.6844424860250555

Epoch: 5| Step: 1
Training loss: 2.9869742533414163
Validation loss: 2.6856279800115455

Epoch: 5| Step: 2
Training loss: 3.0214875313089524
Validation loss: 2.6859520061902735

Epoch: 5| Step: 3
Training loss: 3.179089089209956
Validation loss: 2.687093286629337

Epoch: 5| Step: 4
Training loss: 2.880622010878148
Validation loss: 2.686719038318088

Epoch: 5| Step: 5
Training loss: 2.9813191211932644
Validation loss: 2.6838597968259386

Epoch: 5| Step: 6
Training loss: 2.8131824089384416
Validation loss: 2.6912101115597933

Epoch: 5| Step: 7
Training loss: 3.0559391667168097
Validation loss: 2.6861797828406804

Epoch: 5| Step: 8
Training loss: 3.2911122655970253
Validation loss: 2.68722830045507

Epoch: 5| Step: 9
Training loss: 2.797847983472842
Validation loss: 2.6865184219071447

Epoch: 5| Step: 10
Training loss: 3.1463801096163593
Validation loss: 2.6938315573602587

Epoch: 93| Step: 0
Training loss: 3.1208526556404057
Validation loss: 2.7169835763464985

Epoch: 5| Step: 1
Training loss: 3.359550152138147
Validation loss: 2.733497610590432

Epoch: 5| Step: 2
Training loss: 2.732999270269113
Validation loss: 2.762494829245681

Epoch: 5| Step: 3
Training loss: 2.7909379738749722
Validation loss: 2.731433045419933

Epoch: 5| Step: 4
Training loss: 3.2302439379623755
Validation loss: 2.7104774135036678

Epoch: 5| Step: 5
Training loss: 2.531779857798077
Validation loss: 2.6846786651018486

Epoch: 5| Step: 6
Training loss: 3.1208521972683716
Validation loss: 2.6829981337783706

Epoch: 5| Step: 7
Training loss: 2.872660804809246
Validation loss: 2.67390567755132

Epoch: 5| Step: 8
Training loss: 3.200015014374795
Validation loss: 2.679359981665345

Epoch: 5| Step: 9
Training loss: 3.1624640300650184
Validation loss: 2.6747676061457897

Epoch: 5| Step: 10
Training loss: 2.972626253595782
Validation loss: 2.676538023951007

Epoch: 94| Step: 0
Training loss: 2.8460913441114077
Validation loss: 2.6756626769649623

Epoch: 5| Step: 1
Training loss: 3.0615955496391605
Validation loss: 2.6757849836761314

Epoch: 5| Step: 2
Training loss: 3.2827517024950845
Validation loss: 2.678230314454792

Epoch: 5| Step: 3
Training loss: 3.063749564461461
Validation loss: 2.6787917834155714

Epoch: 5| Step: 4
Training loss: 2.9284448862150576
Validation loss: 2.677041434379146

Epoch: 5| Step: 5
Training loss: 3.1096662068704184
Validation loss: 2.6724369748827574

Epoch: 5| Step: 6
Training loss: 2.9480827114039405
Validation loss: 2.6699163884508317

Epoch: 5| Step: 7
Training loss: 2.592345075548905
Validation loss: 2.6689147036147

Epoch: 5| Step: 8
Training loss: 2.810108948628437
Validation loss: 2.6675764718624966

Epoch: 5| Step: 9
Training loss: 3.425097198220912
Validation loss: 2.6664754974639973

Epoch: 5| Step: 10
Training loss: 2.94284836877581
Validation loss: 2.663595002010966

Epoch: 95| Step: 0
Training loss: 2.789207988972768
Validation loss: 2.6638476750333986

Epoch: 5| Step: 1
Training loss: 3.197177780892748
Validation loss: 2.6649552020210017

Epoch: 5| Step: 2
Training loss: 3.0162907789487714
Validation loss: 2.6631407795541455

Epoch: 5| Step: 3
Training loss: 2.8524001471973466
Validation loss: 2.663285417287317

Epoch: 5| Step: 4
Training loss: 2.8605797736185146
Validation loss: 2.6691350670759424

Epoch: 5| Step: 5
Training loss: 3.1495347300042478
Validation loss: 2.6629600689343116

Epoch: 5| Step: 6
Training loss: 3.4062918564210856
Validation loss: 2.6716303377238626

Epoch: 5| Step: 7
Training loss: 3.134398251691626
Validation loss: 2.682163050421623

Epoch: 5| Step: 8
Training loss: 3.135619620580319
Validation loss: 2.7046673659025133

Epoch: 5| Step: 9
Training loss: 2.783385582012801
Validation loss: 2.7182532613292136

Epoch: 5| Step: 10
Training loss: 2.516828639984386
Validation loss: 2.7165581535119174

Epoch: 96| Step: 0
Training loss: 3.8352880607950874
Validation loss: 2.691596885121263

Epoch: 5| Step: 1
Training loss: 3.433122934604359
Validation loss: 2.6660850708478026

Epoch: 5| Step: 2
Training loss: 2.1563626688394066
Validation loss: 2.6627132299768146

Epoch: 5| Step: 3
Training loss: 2.8708461109720425
Validation loss: 2.6555033648428017

Epoch: 5| Step: 4
Training loss: 2.7757989850109803
Validation loss: 2.6585541838028073

Epoch: 5| Step: 5
Training loss: 2.5843342308509647
Validation loss: 2.6554818052937397

Epoch: 5| Step: 6
Training loss: 2.9894817658471373
Validation loss: 2.6614914989907406

Epoch: 5| Step: 7
Training loss: 3.1088244080084517
Validation loss: 2.6582008200204754

Epoch: 5| Step: 8
Training loss: 3.1101407588984027
Validation loss: 2.663716906163938

Epoch: 5| Step: 9
Training loss: 2.977543546548772
Validation loss: 2.658872268629761

Epoch: 5| Step: 10
Training loss: 2.8377269637297227
Validation loss: 2.6604168362387415

Epoch: 97| Step: 0
Training loss: 2.992433861533019
Validation loss: 2.66468820383248

Epoch: 5| Step: 1
Training loss: 2.919527630679955
Validation loss: 2.6909492205006025

Epoch: 5| Step: 2
Training loss: 3.3584962627054455
Validation loss: 2.704592650910509

Epoch: 5| Step: 3
Training loss: 2.9155518353963137
Validation loss: 2.674674514720143

Epoch: 5| Step: 4
Training loss: 3.6538341398466336
Validation loss: 2.67084113143523

Epoch: 5| Step: 5
Training loss: 2.779294129917829
Validation loss: 2.6603815847240972

Epoch: 5| Step: 6
Training loss: 2.2745242323508066
Validation loss: 2.6599813101444436

Epoch: 5| Step: 7
Training loss: 3.3512648514756824
Validation loss: 2.657375649722767

Epoch: 5| Step: 8
Training loss: 2.8285872782363612
Validation loss: 2.6493842130200944

Epoch: 5| Step: 9
Training loss: 2.877071463643053
Validation loss: 2.648513954010845

Epoch: 5| Step: 10
Training loss: 2.8067378038586672
Validation loss: 2.6513401171900894

Epoch: 98| Step: 0
Training loss: 3.318116375050964
Validation loss: 2.6578516764469735

Epoch: 5| Step: 1
Training loss: 3.253452960952166
Validation loss: 2.659208206524483

Epoch: 5| Step: 2
Training loss: 2.805808010849994
Validation loss: 2.6629681460033456

Epoch: 5| Step: 3
Training loss: 3.373780348062852
Validation loss: 2.665304101828376

Epoch: 5| Step: 4
Training loss: 3.353697481373331
Validation loss: 2.6618054544892105

Epoch: 5| Step: 5
Training loss: 3.048014579307551
Validation loss: 2.6611259321425065

Epoch: 5| Step: 6
Training loss: 2.898713543437706
Validation loss: 2.6633653612418704

Epoch: 5| Step: 7
Training loss: 2.360060333353597
Validation loss: 2.6605609518914326

Epoch: 5| Step: 8
Training loss: 3.04812189655408
Validation loss: 2.6547384884931686

Epoch: 5| Step: 9
Training loss: 2.639642024623407
Validation loss: 2.6492191262018

Epoch: 5| Step: 10
Training loss: 2.6267599836061555
Validation loss: 2.6480677165601527

Epoch: 99| Step: 0
Training loss: 3.032882408189328
Validation loss: 2.6512657612511688

Epoch: 5| Step: 1
Training loss: 2.9955353894232513
Validation loss: 2.6536075233797582

Epoch: 5| Step: 2
Training loss: 2.9127439732343934
Validation loss: 2.6766739887396946

Epoch: 5| Step: 3
Training loss: 2.995504507836656
Validation loss: 2.701358235569247

Epoch: 5| Step: 4
Training loss: 3.069359085330706
Validation loss: 2.7177741987325863

Epoch: 5| Step: 5
Training loss: 3.2059444765267324
Validation loss: 2.6670917074831055

Epoch: 5| Step: 6
Training loss: 2.4634968361730682
Validation loss: 2.6564937993603746

Epoch: 5| Step: 7
Training loss: 2.9722370749446103
Validation loss: 2.6524453669925965

Epoch: 5| Step: 8
Training loss: 2.685156931917283
Validation loss: 2.6407344625771954

Epoch: 5| Step: 9
Training loss: 3.3889606099973015
Validation loss: 2.6435149644431903

Epoch: 5| Step: 10
Training loss: 3.0789731788668835
Validation loss: 2.642272780722811

Epoch: 100| Step: 0
Training loss: 2.7712384169237114
Validation loss: 2.644863682205093

Epoch: 5| Step: 1
Training loss: 3.2869611175159226
Validation loss: 2.6512600968537683

Epoch: 5| Step: 2
Training loss: 2.600563292739609
Validation loss: 2.646133447172007

Epoch: 5| Step: 3
Training loss: 3.1158721366670528
Validation loss: 2.6510221976735773

Epoch: 5| Step: 4
Training loss: 3.1955232061105447
Validation loss: 2.6451000078779825

Epoch: 5| Step: 5
Training loss: 3.1416782112482853
Validation loss: 2.6430705309565417

Epoch: 5| Step: 6
Training loss: 3.147242922900466
Validation loss: 2.6416453544036744

Epoch: 5| Step: 7
Training loss: 2.8343402158039073
Validation loss: 2.6428100289186043

Epoch: 5| Step: 8
Training loss: 2.554314449032247
Validation loss: 2.6420773514914693

Epoch: 5| Step: 9
Training loss: 3.302643705326982
Validation loss: 2.647600959542297

Epoch: 5| Step: 10
Training loss: 2.7420019538032143
Validation loss: 2.6438015717138397

Epoch: 101| Step: 0
Training loss: 3.160819796201235
Validation loss: 2.6511437216545026

Epoch: 5| Step: 1
Training loss: 2.9216945000857044
Validation loss: 2.6504965639850164

Epoch: 5| Step: 2
Training loss: 2.8644855459457514
Validation loss: 2.646761489113493

Epoch: 5| Step: 3
Training loss: 3.342400964997382
Validation loss: 2.643667326821719

Epoch: 5| Step: 4
Training loss: 2.5355391720149516
Validation loss: 2.6416393103023657

Epoch: 5| Step: 5
Training loss: 3.2546686238782168
Validation loss: 2.6469225819435196

Epoch: 5| Step: 6
Training loss: 2.605635195881675
Validation loss: 2.6411232553165407

Epoch: 5| Step: 7
Training loss: 3.1479046467707903
Validation loss: 2.6416011781870212

Epoch: 5| Step: 8
Training loss: 2.7619991349005537
Validation loss: 2.6445218970953634

Epoch: 5| Step: 9
Training loss: 2.7366308879333308
Validation loss: 2.6423033227538024

Epoch: 5| Step: 10
Training loss: 3.335193845957429
Validation loss: 2.6409640569324284

Epoch: 102| Step: 0
Training loss: 2.696804971327227
Validation loss: 2.6404706134725013

Epoch: 5| Step: 1
Training loss: 3.1237992077722465
Validation loss: 2.6425441314749656

Epoch: 5| Step: 2
Training loss: 3.266597913161265
Validation loss: 2.6499065274721674

Epoch: 5| Step: 3
Training loss: 2.8213713710843207
Validation loss: 2.64946356479105

Epoch: 5| Step: 4
Training loss: 2.9677480512652306
Validation loss: 2.6448298702364403

Epoch: 5| Step: 5
Training loss: 2.6964827056618765
Validation loss: 2.6469282987229272

Epoch: 5| Step: 6
Training loss: 3.413623353836136
Validation loss: 2.6494096114189114

Epoch: 5| Step: 7
Training loss: 2.6272553337435784
Validation loss: 2.6327848070582798

Epoch: 5| Step: 8
Training loss: 3.6393575795205626
Validation loss: 2.6324745346657723

Epoch: 5| Step: 9
Training loss: 3.0952282080998947
Validation loss: 2.63268482571407

Epoch: 5| Step: 10
Training loss: 1.9415111858783474
Validation loss: 2.6406559173857462

Epoch: 103| Step: 0
Training loss: 3.037164011767392
Validation loss: 2.641217153645159

Epoch: 5| Step: 1
Training loss: 2.7429654574720788
Validation loss: 2.6430282855093354

Epoch: 5| Step: 2
Training loss: 3.09556295276107
Validation loss: 2.6482343165922066

Epoch: 5| Step: 3
Training loss: 3.251615856196659
Validation loss: 2.6473514141160153

Epoch: 5| Step: 4
Training loss: 3.3550227871389606
Validation loss: 2.6428897846900195

Epoch: 5| Step: 5
Training loss: 2.948743041621751
Validation loss: 2.642970186004535

Epoch: 5| Step: 6
Training loss: 2.7169072713574134
Validation loss: 2.6444324146490152

Epoch: 5| Step: 7
Training loss: 3.428395786214181
Validation loss: 2.6378345165975894

Epoch: 5| Step: 8
Training loss: 2.681994365524074
Validation loss: 2.634372319594662

Epoch: 5| Step: 9
Training loss: 2.98826912272866
Validation loss: 2.638000518005032

Epoch: 5| Step: 10
Training loss: 2.503954620608255
Validation loss: 2.639070484718526

Epoch: 104| Step: 0
Training loss: 3.0947626171377194
Validation loss: 2.6585444752246623

Epoch: 5| Step: 1
Training loss: 3.214739328498551
Validation loss: 2.6501369775254204

Epoch: 5| Step: 2
Training loss: 2.956439867434868
Validation loss: 2.6485831018319206

Epoch: 5| Step: 3
Training loss: 2.784218992921213
Validation loss: 2.63855355518944

Epoch: 5| Step: 4
Training loss: 2.8885030020047293
Validation loss: 2.633784961705992

Epoch: 5| Step: 5
Training loss: 3.2170029130091833
Validation loss: 2.635953184593045

Epoch: 5| Step: 6
Training loss: 2.8226087526600745
Validation loss: 2.6316783642569446

Epoch: 5| Step: 7
Training loss: 2.9027600406995124
Validation loss: 2.6273620279906953

Epoch: 5| Step: 8
Training loss: 3.211369023713987
Validation loss: 2.6277124636728204

Epoch: 5| Step: 9
Training loss: 3.0084378471782447
Validation loss: 2.626850522842539

Epoch: 5| Step: 10
Training loss: 2.426058791741521
Validation loss: 2.627753977794369

Epoch: 105| Step: 0
Training loss: 2.866775857339242
Validation loss: 2.6300136026630896

Epoch: 5| Step: 1
Training loss: 3.150061555291265
Validation loss: 2.624776691054131

Epoch: 5| Step: 2
Training loss: 2.8846879353325083
Validation loss: 2.6230188424343908

Epoch: 5| Step: 3
Training loss: 3.1218280716157363
Validation loss: 2.6214863827383654

Epoch: 5| Step: 4
Training loss: 3.0479463698807816
Validation loss: 2.6197360153189715

Epoch: 5| Step: 5
Training loss: 2.8863125361709394
Validation loss: 2.6200527463179824

Epoch: 5| Step: 6
Training loss: 3.115038137921911
Validation loss: 2.6228014171478087

Epoch: 5| Step: 7
Training loss: 3.1517232026493325
Validation loss: 2.619581277489216

Epoch: 5| Step: 8
Training loss: 2.766016442134862
Validation loss: 2.6209576133109516

Epoch: 5| Step: 9
Training loss: 2.8504532838374748
Validation loss: 2.617304407483109

Epoch: 5| Step: 10
Training loss: 2.760679316471059
Validation loss: 2.6197371240582523

Epoch: 106| Step: 0
Training loss: 3.081990714344491
Validation loss: 2.6244416529352357

Epoch: 5| Step: 1
Training loss: 2.644012355186924
Validation loss: 2.626237621457131

Epoch: 5| Step: 2
Training loss: 3.2020794906708976
Validation loss: 2.6276597788575233

Epoch: 5| Step: 3
Training loss: 2.386746420442353
Validation loss: 2.624561378156094

Epoch: 5| Step: 4
Training loss: 3.5598785392529053
Validation loss: 2.6408601313834628

Epoch: 5| Step: 5
Training loss: 2.674845600128648
Validation loss: 2.648234290454679

Epoch: 5| Step: 6
Training loss: 2.4300605512068496
Validation loss: 2.6485251483793877

Epoch: 5| Step: 7
Training loss: 3.569748581439929
Validation loss: 2.6520285264946706

Epoch: 5| Step: 8
Training loss: 2.8381354271672614
Validation loss: 2.6430583784517228

Epoch: 5| Step: 9
Training loss: 2.774330446728151
Validation loss: 2.620215686687976

Epoch: 5| Step: 10
Training loss: 3.2059312390564627
Validation loss: 2.621804692661863

Epoch: 107| Step: 0
Training loss: 2.734880411577644
Validation loss: 2.6221407794708838

Epoch: 5| Step: 1
Training loss: 3.249663408896091
Validation loss: 2.631780809368488

Epoch: 5| Step: 2
Training loss: 3.0773227633796636
Validation loss: 2.6209259353597534

Epoch: 5| Step: 3
Training loss: 3.195440984628362
Validation loss: 2.619708643108025

Epoch: 5| Step: 4
Training loss: 2.8011296479884837
Validation loss: 2.6217322101260216

Epoch: 5| Step: 5
Training loss: 2.991764526750143
Validation loss: 2.6257194874902394

Epoch: 5| Step: 6
Training loss: 3.577733047540083
Validation loss: 2.621864645741198

Epoch: 5| Step: 7
Training loss: 2.615027786311486
Validation loss: 2.6270366625684205

Epoch: 5| Step: 8
Training loss: 2.828260976989426
Validation loss: 2.6381186361972926

Epoch: 5| Step: 9
Training loss: 2.308062755366227
Validation loss: 2.6460555970506663

Epoch: 5| Step: 10
Training loss: 3.0481871298269048
Validation loss: 2.6735880561271044

Epoch: 108| Step: 0
Training loss: 3.1825716402271644
Validation loss: 2.66667587204339

Epoch: 5| Step: 1
Training loss: 3.0702245956921725
Validation loss: 2.642479259284498

Epoch: 5| Step: 2
Training loss: 2.919542003404567
Validation loss: 2.6252699389444207

Epoch: 5| Step: 3
Training loss: 2.8435028304113956
Validation loss: 2.6210247132362396

Epoch: 5| Step: 4
Training loss: 2.605874826336574
Validation loss: 2.6218888870707104

Epoch: 5| Step: 5
Training loss: 2.900282773668169
Validation loss: 2.616196203592811

Epoch: 5| Step: 6
Training loss: 2.795016219854634
Validation loss: 2.6237872272056277

Epoch: 5| Step: 7
Training loss: 3.051888434704536
Validation loss: 2.613268355645194

Epoch: 5| Step: 8
Training loss: 3.0277409643643622
Validation loss: 2.620610200113377

Epoch: 5| Step: 9
Training loss: 2.949200479817167
Validation loss: 2.616166860959572

Epoch: 5| Step: 10
Training loss: 3.223515510447212
Validation loss: 2.614162071055809

Epoch: 109| Step: 0
Training loss: 2.849830916893634
Validation loss: 2.6256356629408897

Epoch: 5| Step: 1
Training loss: 2.7617104623284416
Validation loss: 2.6224298214787503

Epoch: 5| Step: 2
Training loss: 3.0150889182066227
Validation loss: 2.61559786884983

Epoch: 5| Step: 3
Training loss: 3.1786869358732868
Validation loss: 2.6131658666098625

Epoch: 5| Step: 4
Training loss: 3.0083416361883524
Validation loss: 2.612362749682913

Epoch: 5| Step: 5
Training loss: 2.8696669166621844
Validation loss: 2.6120567519230855

Epoch: 5| Step: 6
Training loss: 3.2269411026550956
Validation loss: 2.610233681643151

Epoch: 5| Step: 7
Training loss: 2.69240052304204
Validation loss: 2.6070052688494223

Epoch: 5| Step: 8
Training loss: 3.3554860870659504
Validation loss: 2.607760832949417

Epoch: 5| Step: 9
Training loss: 2.8852122173567354
Validation loss: 2.6056154787882004

Epoch: 5| Step: 10
Training loss: 2.395938528211698
Validation loss: 2.6170844415152157

Epoch: 110| Step: 0
Training loss: 3.3570751745711873
Validation loss: 2.609100390225229

Epoch: 5| Step: 1
Training loss: 2.1367526705488533
Validation loss: 2.6168566667799835

Epoch: 5| Step: 2
Training loss: 3.068087560316849
Validation loss: 2.6191334806571795

Epoch: 5| Step: 3
Training loss: 2.5410719212153485
Validation loss: 2.626341487239077

Epoch: 5| Step: 4
Training loss: 3.5516193940841365
Validation loss: 2.6198267023787185

Epoch: 5| Step: 5
Training loss: 3.393667236218169
Validation loss: 2.61353838609395

Epoch: 5| Step: 6
Training loss: 2.769255932465367
Validation loss: 2.613896108558815

Epoch: 5| Step: 7
Training loss: 2.831130143548592
Validation loss: 2.5994284569571686

Epoch: 5| Step: 8
Training loss: 2.7358599309202565
Validation loss: 2.6030760406289066

Epoch: 5| Step: 9
Training loss: 2.931273333816542
Validation loss: 2.5994242911080594

Epoch: 5| Step: 10
Training loss: 2.7632416191419193
Validation loss: 2.59715295653602

Epoch: 111| Step: 0
Training loss: 3.591027331408364
Validation loss: 2.5904510003404773

Epoch: 5| Step: 1
Training loss: 3.3433686511328555
Validation loss: 2.595601196751981

Epoch: 5| Step: 2
Training loss: 3.083100765495704
Validation loss: 2.5914275249326963

Epoch: 5| Step: 3
Training loss: 2.427967407139778
Validation loss: 2.5913726085741056

Epoch: 5| Step: 4
Training loss: 2.7405415782172065
Validation loss: 2.5959345985967714

Epoch: 5| Step: 5
Training loss: 3.2246957324899155
Validation loss: 2.5987740601619067

Epoch: 5| Step: 6
Training loss: 3.233875475654716
Validation loss: 2.600658593406976

Epoch: 5| Step: 7
Training loss: 2.773558278207531
Validation loss: 2.6032978638193045

Epoch: 5| Step: 8
Training loss: 2.772271053399733
Validation loss: 2.616699648358538

Epoch: 5| Step: 9
Training loss: 2.248484843102271
Validation loss: 2.627324980567132

Epoch: 5| Step: 10
Training loss: 2.619118413752763
Validation loss: 2.6399983813463272

Epoch: 112| Step: 0
Training loss: 2.899314891523506
Validation loss: 2.6075603946523476

Epoch: 5| Step: 1
Training loss: 2.635035088900861
Validation loss: 2.5997233385204614

Epoch: 5| Step: 2
Training loss: 3.0031423006541855
Validation loss: 2.5856976012573436

Epoch: 5| Step: 3
Training loss: 2.6883343133453583
Validation loss: 2.587888438679907

Epoch: 5| Step: 4
Training loss: 2.6168058658029136
Validation loss: 2.5877535440115422

Epoch: 5| Step: 5
Training loss: 3.362093513055124
Validation loss: 2.586757271100319

Epoch: 5| Step: 6
Training loss: 2.8882391904121643
Validation loss: 2.590098428268973

Epoch: 5| Step: 7
Training loss: 3.2235712775291683
Validation loss: 2.585838591334673

Epoch: 5| Step: 8
Training loss: 3.008588735318221
Validation loss: 2.5836238277648005

Epoch: 5| Step: 9
Training loss: 3.0633213732309184
Validation loss: 2.584093996754162

Epoch: 5| Step: 10
Training loss: 2.791766909797037
Validation loss: 2.5852443706837116

Epoch: 113| Step: 0
Training loss: 2.9690659204336254
Validation loss: 2.5815756200326794

Epoch: 5| Step: 1
Training loss: 2.8442727750724885
Validation loss: 2.5838140618605747

Epoch: 5| Step: 2
Training loss: 3.1342149292376633
Validation loss: 2.5835181612417695

Epoch: 5| Step: 3
Training loss: 2.402057413544199
Validation loss: 2.594057952671194

Epoch: 5| Step: 4
Training loss: 3.2289774357304735
Validation loss: 2.6238949017491735

Epoch: 5| Step: 5
Training loss: 2.8388881833481414
Validation loss: 2.6063102480898572

Epoch: 5| Step: 6
Training loss: 3.267266695877045
Validation loss: 2.5940215799712942

Epoch: 5| Step: 7
Training loss: 2.7433001660010246
Validation loss: 2.580718714649

Epoch: 5| Step: 8
Training loss: 3.1493881721319537
Validation loss: 2.5820187834004855

Epoch: 5| Step: 9
Training loss: 2.521187077022201
Validation loss: 2.5784432332558858

Epoch: 5| Step: 10
Training loss: 3.072760385106093
Validation loss: 2.582232861783604

Epoch: 114| Step: 0
Training loss: 3.12235208861967
Validation loss: 2.5811509498113328

Epoch: 5| Step: 1
Training loss: 3.053935941452779
Validation loss: 2.5790136849698757

Epoch: 5| Step: 2
Training loss: 3.263792555088538
Validation loss: 2.576668013833003

Epoch: 5| Step: 3
Training loss: 2.3337224454228718
Validation loss: 2.580931154645805

Epoch: 5| Step: 4
Training loss: 2.7256559159997282
Validation loss: 2.5764851425878996

Epoch: 5| Step: 5
Training loss: 2.7858872918842708
Validation loss: 2.5888901613316175

Epoch: 5| Step: 6
Training loss: 2.5601369615514433
Validation loss: 2.58721867455192

Epoch: 5| Step: 7
Training loss: 2.5357028742174617
Validation loss: 2.60664711902734

Epoch: 5| Step: 8
Training loss: 3.54757051748631
Validation loss: 2.6124557495294813

Epoch: 5| Step: 9
Training loss: 3.1953769668007777
Validation loss: 2.623820817900912

Epoch: 5| Step: 10
Training loss: 2.9517791749293147
Validation loss: 2.6338588236882785

Epoch: 115| Step: 0
Training loss: 2.8164457828958724
Validation loss: 2.6086675401962705

Epoch: 5| Step: 1
Training loss: 2.38934152095249
Validation loss: 2.5915367230264397

Epoch: 5| Step: 2
Training loss: 2.80707076883885
Validation loss: 2.579455485613094

Epoch: 5| Step: 3
Training loss: 2.8140231776309848
Validation loss: 2.577070276140072

Epoch: 5| Step: 4
Training loss: 2.6690385720534064
Validation loss: 2.572119986841243

Epoch: 5| Step: 5
Training loss: 3.187506283024598
Validation loss: 2.5769529242026934

Epoch: 5| Step: 6
Training loss: 2.867462061902936
Validation loss: 2.578446665435997

Epoch: 5| Step: 7
Training loss: 2.793903925194815
Validation loss: 2.576043368925145

Epoch: 5| Step: 8
Training loss: 3.3937238604415323
Validation loss: 2.5747249164829276

Epoch: 5| Step: 9
Training loss: 2.9494615871671908
Validation loss: 2.5745472007037145

Epoch: 5| Step: 10
Training loss: 3.4942558017979217
Validation loss: 2.571831258563491

Epoch: 116| Step: 0
Training loss: 3.090234010841291
Validation loss: 2.5754205673497244

Epoch: 5| Step: 1
Training loss: 2.808900946315943
Validation loss: 2.5754602034155494

Epoch: 5| Step: 2
Training loss: 2.7864617368493136
Validation loss: 2.580549470507894

Epoch: 5| Step: 3
Training loss: 2.449268687346025
Validation loss: 2.5750379449470064

Epoch: 5| Step: 4
Training loss: 3.1884728237439797
Validation loss: 2.574431135854193

Epoch: 5| Step: 5
Training loss: 2.8851431339398594
Validation loss: 2.5755547442951903

Epoch: 5| Step: 6
Training loss: 2.5944626530024877
Validation loss: 2.5803201815601793

Epoch: 5| Step: 7
Training loss: 3.016382152003666
Validation loss: 2.596837271781113

Epoch: 5| Step: 8
Training loss: 2.798013466083442
Validation loss: 2.5807426083660494

Epoch: 5| Step: 9
Training loss: 3.3654855910023787
Validation loss: 2.5793764251105764

Epoch: 5| Step: 10
Training loss: 3.093830146136748
Validation loss: 2.581080507979099

Epoch: 117| Step: 0
Training loss: 3.2247760251360837
Validation loss: 2.5761849940894836

Epoch: 5| Step: 1
Training loss: 2.8129771357697746
Validation loss: 2.5750711894347202

Epoch: 5| Step: 2
Training loss: 2.8371317216953464
Validation loss: 2.5742139856542545

Epoch: 5| Step: 3
Training loss: 2.844723545312509
Validation loss: 2.568817382061271

Epoch: 5| Step: 4
Training loss: 2.330787314146055
Validation loss: 2.5752929097581307

Epoch: 5| Step: 5
Training loss: 2.8312642078169485
Validation loss: 2.58207832487

Epoch: 5| Step: 6
Training loss: 3.600017224376587
Validation loss: 2.5734496232029325

Epoch: 5| Step: 7
Training loss: 3.1337901276194047
Validation loss: 2.590914936551037

Epoch: 5| Step: 8
Training loss: 2.8049017099169307
Validation loss: 2.5896908334084445

Epoch: 5| Step: 9
Training loss: 2.8283734291515015
Validation loss: 2.5976110680970304

Epoch: 5| Step: 10
Training loss: 2.680486087415012
Validation loss: 2.6134578895843923

Epoch: 118| Step: 0
Training loss: 2.7361097663923424
Validation loss: 2.6368913569253185

Epoch: 5| Step: 1
Training loss: 3.355311717576615
Validation loss: 2.6867399216408665

Epoch: 5| Step: 2
Training loss: 2.548552914081162
Validation loss: 2.654972848886441

Epoch: 5| Step: 3
Training loss: 3.251312577680467
Validation loss: 2.6249655161212315

Epoch: 5| Step: 4
Training loss: 3.007301029463383
Validation loss: 2.5691415839026077

Epoch: 5| Step: 5
Training loss: 3.1148330095085393
Validation loss: 2.5707632173891577

Epoch: 5| Step: 6
Training loss: 3.027032179027209
Validation loss: 2.5862681409797434

Epoch: 5| Step: 7
Training loss: 2.583201548588709
Validation loss: 2.5949001892749304

Epoch: 5| Step: 8
Training loss: 2.9645558495140034
Validation loss: 2.604862420118221

Epoch: 5| Step: 9
Training loss: 2.830615722479328
Validation loss: 2.602787120682362

Epoch: 5| Step: 10
Training loss: 3.021441133235338
Validation loss: 2.5939020477258135

Epoch: 119| Step: 0
Training loss: 3.330023425595479
Validation loss: 2.582648117602954

Epoch: 5| Step: 1
Training loss: 2.762374519501733
Validation loss: 2.580560741146116

Epoch: 5| Step: 2
Training loss: 2.9099524100171212
Validation loss: 2.564771534313635

Epoch: 5| Step: 3
Training loss: 3.247269143348494
Validation loss: 2.561272341834361

Epoch: 5| Step: 4
Training loss: 2.6037421732476767
Validation loss: 2.5759914286826335

Epoch: 5| Step: 5
Training loss: 3.4043232079087686
Validation loss: 2.627888102987855

Epoch: 5| Step: 6
Training loss: 2.3461396305909092
Validation loss: 2.674872651555857

Epoch: 5| Step: 7
Training loss: 2.7170659253571334
Validation loss: 2.7133985635237834

Epoch: 5| Step: 8
Training loss: 3.1095628537887117
Validation loss: 2.705716729304556

Epoch: 5| Step: 9
Training loss: 2.399114258558032
Validation loss: 2.6178718692061245

Epoch: 5| Step: 10
Training loss: 3.3393408681162935
Validation loss: 2.5779539089416943

Epoch: 120| Step: 0
Training loss: 3.2096660537753476
Validation loss: 2.5650219796015454

Epoch: 5| Step: 1
Training loss: 2.668869380380248
Validation loss: 2.5639526387644387

Epoch: 5| Step: 2
Training loss: 3.472345499181502
Validation loss: 2.571600805484265

Epoch: 5| Step: 3
Training loss: 2.410896274216653
Validation loss: 2.5780826936782546

Epoch: 5| Step: 4
Training loss: 3.1967249502279156
Validation loss: 2.5854697961182143

Epoch: 5| Step: 5
Training loss: 3.053029578756919
Validation loss: 2.5849042284885146

Epoch: 5| Step: 6
Training loss: 3.511020883844121
Validation loss: 2.5874417328601393

Epoch: 5| Step: 7
Training loss: 2.559816769956778
Validation loss: 2.583790773015967

Epoch: 5| Step: 8
Training loss: 2.375923077741364
Validation loss: 2.5882404441238274

Epoch: 5| Step: 9
Training loss: 2.893606267206072
Validation loss: 2.5877188847726544

Epoch: 5| Step: 10
Training loss: 2.8456169958439825
Validation loss: 2.584213589821499

Epoch: 121| Step: 0
Training loss: 3.187410689954011
Validation loss: 2.5796344026479523

Epoch: 5| Step: 1
Training loss: 3.1214234293770313
Validation loss: 2.574034967736355

Epoch: 5| Step: 2
Training loss: 3.1106972494811655
Validation loss: 2.575200090958385

Epoch: 5| Step: 3
Training loss: 2.7645947105175526
Validation loss: 2.568671676143855

Epoch: 5| Step: 4
Training loss: 2.6550755316556227
Validation loss: 2.564296945740291

Epoch: 5| Step: 5
Training loss: 2.718736933534289
Validation loss: 2.560281836455398

Epoch: 5| Step: 6
Training loss: 2.6751576386109392
Validation loss: 2.575625734397176

Epoch: 5| Step: 7
Training loss: 2.4736212463951865
Validation loss: 2.588177476565436

Epoch: 5| Step: 8
Training loss: 3.2539751244774098
Validation loss: 2.6183422848772406

Epoch: 5| Step: 9
Training loss: 3.0464841934362523
Validation loss: 2.63529477771227

Epoch: 5| Step: 10
Training loss: 3.048069177037787
Validation loss: 2.6395077235786006

Epoch: 122| Step: 0
Training loss: 3.03915256082413
Validation loss: 2.6087020812955575

Epoch: 5| Step: 1
Training loss: 3.059113479050746
Validation loss: 2.598799976362227

Epoch: 5| Step: 2
Training loss: 3.0208760927177583
Validation loss: 2.5773127146615398

Epoch: 5| Step: 3
Training loss: 2.590638281922753
Validation loss: 2.574386985306032

Epoch: 5| Step: 4
Training loss: 3.1885423638884016
Validation loss: 2.5617966025416345

Epoch: 5| Step: 5
Training loss: 2.2722387135515283
Validation loss: 2.556687041319376

Epoch: 5| Step: 6
Training loss: 2.9570730148450024
Validation loss: 2.554867430064893

Epoch: 5| Step: 7
Training loss: 2.7764462766006055
Validation loss: 2.5530287544498096

Epoch: 5| Step: 8
Training loss: 2.9247197465232673
Validation loss: 2.5548807576394306

Epoch: 5| Step: 9
Training loss: 2.9927557263780407
Validation loss: 2.5570118296984816

Epoch: 5| Step: 10
Training loss: 3.1705620213921284
Validation loss: 2.554725272637074

Epoch: 123| Step: 0
Training loss: 3.128778233570299
Validation loss: 2.557704260605479

Epoch: 5| Step: 1
Training loss: 2.816308304225058
Validation loss: 2.556020286113666

Epoch: 5| Step: 2
Training loss: 2.8886180612169667
Validation loss: 2.5555268378633436

Epoch: 5| Step: 3
Training loss: 2.7998206115205946
Validation loss: 2.5607918369127725

Epoch: 5| Step: 4
Training loss: 3.108532355297378
Validation loss: 2.5609804335501787

Epoch: 5| Step: 5
Training loss: 2.5258813132026274
Validation loss: 2.570169037346859

Epoch: 5| Step: 6
Training loss: 3.2862840093374244
Validation loss: 2.5823798436174865

Epoch: 5| Step: 7
Training loss: 2.630920273515658
Validation loss: 2.584428571600702

Epoch: 5| Step: 8
Training loss: 3.041977766318144
Validation loss: 2.5800703995223917

Epoch: 5| Step: 9
Training loss: 3.194722389255314
Validation loss: 2.570969216783044

Epoch: 5| Step: 10
Training loss: 2.3966970683554023
Validation loss: 2.547592892339952

Epoch: 124| Step: 0
Training loss: 3.052533495170158
Validation loss: 2.5530874296572876

Epoch: 5| Step: 1
Training loss: 3.1662050881195585
Validation loss: 2.553516215893646

Epoch: 5| Step: 2
Training loss: 2.6758584115813315
Validation loss: 2.5491433519759887

Epoch: 5| Step: 3
Training loss: 2.6281452409506856
Validation loss: 2.5543388165623

Epoch: 5| Step: 4
Training loss: 2.6880225627213354
Validation loss: 2.548012076053576

Epoch: 5| Step: 5
Training loss: 3.3804176081612174
Validation loss: 2.553564870580742

Epoch: 5| Step: 6
Training loss: 2.5763730656725454
Validation loss: 2.5477895940970745

Epoch: 5| Step: 7
Training loss: 3.068581750922919
Validation loss: 2.5521277344494986

Epoch: 5| Step: 8
Training loss: 2.972820021821219
Validation loss: 2.5537964924506906

Epoch: 5| Step: 9
Training loss: 2.769572743265072
Validation loss: 2.5511589577820777

Epoch: 5| Step: 10
Training loss: 2.8911670073568407
Validation loss: 2.557775680991918

Epoch: 125| Step: 0
Training loss: 3.1134488049916142
Validation loss: 2.5504552570719548

Epoch: 5| Step: 1
Training loss: 2.7825951912801035
Validation loss: 2.5742993481682324

Epoch: 5| Step: 2
Training loss: 3.072698156486651
Validation loss: 2.583477568660332

Epoch: 5| Step: 3
Training loss: 2.585092642800794
Validation loss: 2.5881968025220776

Epoch: 5| Step: 4
Training loss: 2.6930666204938585
Validation loss: 2.5957928305173605

Epoch: 5| Step: 5
Training loss: 2.745280116785298
Validation loss: 2.5778062829142545

Epoch: 5| Step: 6
Training loss: 2.8378455938873937
Validation loss: 2.562874561290125

Epoch: 5| Step: 7
Training loss: 3.3636569390382305
Validation loss: 2.547945097863752

Epoch: 5| Step: 8
Training loss: 2.879409228502956
Validation loss: 2.5459175627891257

Epoch: 5| Step: 9
Training loss: 2.812989171191384
Validation loss: 2.5429442039557566

Epoch: 5| Step: 10
Training loss: 2.9725415562322812
Validation loss: 2.5400327291859655

Epoch: 126| Step: 0
Training loss: 2.797960720629107
Validation loss: 2.5455738677024193

Epoch: 5| Step: 1
Training loss: 3.5093084259376424
Validation loss: 2.5461944147856084

Epoch: 5| Step: 2
Training loss: 3.023319212499558
Validation loss: 2.5473886346009684

Epoch: 5| Step: 3
Training loss: 2.8706305097696925
Validation loss: 2.545748100655175

Epoch: 5| Step: 4
Training loss: 2.6257102550384928
Validation loss: 2.5430901177747005

Epoch: 5| Step: 5
Training loss: 2.436589193125737
Validation loss: 2.5365192033492967

Epoch: 5| Step: 6
Training loss: 2.48259791508603
Validation loss: 2.5364608837070306

Epoch: 5| Step: 7
Training loss: 3.1324246516074488
Validation loss: 2.5397728205794428

Epoch: 5| Step: 8
Training loss: 2.950326875583539
Validation loss: 2.5480972347869524

Epoch: 5| Step: 9
Training loss: 3.2584119652303407
Validation loss: 2.5596616558997134

Epoch: 5| Step: 10
Training loss: 2.6661995736963435
Validation loss: 2.558574522075031

Epoch: 127| Step: 0
Training loss: 2.9323207566945335
Validation loss: 2.55420555156477

Epoch: 5| Step: 1
Training loss: 3.084892617556246
Validation loss: 2.5547215396524616

Epoch: 5| Step: 2
Training loss: 3.521460813929084
Validation loss: 2.557076475036883

Epoch: 5| Step: 3
Training loss: 2.7109000343570133
Validation loss: 2.5559036908862507

Epoch: 5| Step: 4
Training loss: 3.0678494501390157
Validation loss: 2.5520862658854035

Epoch: 5| Step: 5
Training loss: 3.076210627236067
Validation loss: 2.544559232468695

Epoch: 5| Step: 6
Training loss: 2.543764238997214
Validation loss: 2.5497374849274386

Epoch: 5| Step: 7
Training loss: 3.091266598654985
Validation loss: 2.5494199471895254

Epoch: 5| Step: 8
Training loss: 2.354354873380819
Validation loss: 2.548411402340443

Epoch: 5| Step: 9
Training loss: 2.512572527545575
Validation loss: 2.548824688139793

Epoch: 5| Step: 10
Training loss: 2.9311832119423475
Validation loss: 2.5497146640636266

Epoch: 128| Step: 0
Training loss: 3.361677932934723
Validation loss: 2.547959067351964

Epoch: 5| Step: 1
Training loss: 2.7265725559169414
Validation loss: 2.5450749732959714

Epoch: 5| Step: 2
Training loss: 3.0146708980374823
Validation loss: 2.550428072109464

Epoch: 5| Step: 3
Training loss: 2.4991064382098562
Validation loss: 2.554776487230302

Epoch: 5| Step: 4
Training loss: 2.99350130007811
Validation loss: 2.555554342767476

Epoch: 5| Step: 5
Training loss: 2.939553050627114
Validation loss: 2.563602437465762

Epoch: 5| Step: 6
Training loss: 3.0085132921941833
Validation loss: 2.5748337008295983

Epoch: 5| Step: 7
Training loss: 3.1998457335003954
Validation loss: 2.5670007067882317

Epoch: 5| Step: 8
Training loss: 2.511792218926958
Validation loss: 2.574867254113632

Epoch: 5| Step: 9
Training loss: 2.9549458052414534
Validation loss: 2.55487089391643

Epoch: 5| Step: 10
Training loss: 2.5201801262920713
Validation loss: 2.554603671370359

Epoch: 129| Step: 0
Training loss: 2.9049740523264473
Validation loss: 2.5563647358406882

Epoch: 5| Step: 1
Training loss: 3.221351239083064
Validation loss: 2.552397081896489

Epoch: 5| Step: 2
Training loss: 2.7683907165949324
Validation loss: 2.5560008041299946

Epoch: 5| Step: 3
Training loss: 2.5512223848066014
Validation loss: 2.5580492823219494

Epoch: 5| Step: 4
Training loss: 3.0426540775200226
Validation loss: 2.5755520159731775

Epoch: 5| Step: 5
Training loss: 2.6349507599777504
Validation loss: 2.563817035681423

Epoch: 5| Step: 6
Training loss: 2.429770514244522
Validation loss: 2.5549529944525813

Epoch: 5| Step: 7
Training loss: 3.215719333225169
Validation loss: 2.5540081083020767

Epoch: 5| Step: 8
Training loss: 3.1033728862608823
Validation loss: 2.546612016659183

Epoch: 5| Step: 9
Training loss: 2.9990493539766714
Validation loss: 2.544745088071351

Epoch: 5| Step: 10
Training loss: 2.8704934666899296
Validation loss: 2.544162351729573

Epoch: 130| Step: 0
Training loss: 2.2532253459960163
Validation loss: 2.539152723402164

Epoch: 5| Step: 1
Training loss: 2.7584717910759693
Validation loss: 2.546011613257763

Epoch: 5| Step: 2
Training loss: 3.5322099579285555
Validation loss: 2.538062879551726

Epoch: 5| Step: 3
Training loss: 2.5839727492297992
Validation loss: 2.5419801014115517

Epoch: 5| Step: 4
Training loss: 3.3374740313830533
Validation loss: 2.5462660543096636

Epoch: 5| Step: 5
Training loss: 2.7630808707188295
Validation loss: 2.5419279794968457

Epoch: 5| Step: 6
Training loss: 3.0201816425897037
Validation loss: 2.5458606497033505

Epoch: 5| Step: 7
Training loss: 3.1968235462929155
Validation loss: 2.552124918803335

Epoch: 5| Step: 8
Training loss: 3.099385071338276
Validation loss: 2.55193653065349

Epoch: 5| Step: 9
Training loss: 2.3067263103594544
Validation loss: 2.5635272572432317

Epoch: 5| Step: 10
Training loss: 2.6591761908086173
Validation loss: 2.5648490159632793

Epoch: 131| Step: 0
Training loss: 2.5407614320578324
Validation loss: 2.5614091445627722

Epoch: 5| Step: 1
Training loss: 2.8137139137831593
Validation loss: 2.597773685124666

Epoch: 5| Step: 2
Training loss: 3.2169981698365087
Validation loss: 2.6070267887446006

Epoch: 5| Step: 3
Training loss: 2.968387943074628
Validation loss: 2.5780792202432115

Epoch: 5| Step: 4
Training loss: 2.731129491316705
Validation loss: 2.5848787258877737

Epoch: 5| Step: 5
Training loss: 2.981926038053818
Validation loss: 2.5795721910124114

Epoch: 5| Step: 6
Training loss: 2.8856800569665233
Validation loss: 2.568876720552626

Epoch: 5| Step: 7
Training loss: 3.2414864758879154
Validation loss: 2.550265938373085

Epoch: 5| Step: 8
Training loss: 3.183646771510161
Validation loss: 2.536809638487707

Epoch: 5| Step: 9
Training loss: 2.4986597283198138
Validation loss: 2.53244394907221

Epoch: 5| Step: 10
Training loss: 2.550596081495689
Validation loss: 2.5368553929443745

Epoch: 132| Step: 0
Training loss: 2.5845817400197477
Validation loss: 2.5462163902399277

Epoch: 5| Step: 1
Training loss: 3.202058344693654
Validation loss: 2.5384152328090774

Epoch: 5| Step: 2
Training loss: 3.078277739012673
Validation loss: 2.5428455954869573

Epoch: 5| Step: 3
Training loss: 3.036290490739124
Validation loss: 2.5441764236076674

Epoch: 5| Step: 4
Training loss: 2.8255018008011543
Validation loss: 2.565317182543628

Epoch: 5| Step: 5
Training loss: 2.3336809671384557
Validation loss: 2.5655527716502617

Epoch: 5| Step: 6
Training loss: 2.9787948127350017
Validation loss: 2.5902560506970995

Epoch: 5| Step: 7
Training loss: 2.9018454040424695
Validation loss: 2.6077087989257244

Epoch: 5| Step: 8
Training loss: 2.809543496787219
Validation loss: 2.564863702998426

Epoch: 5| Step: 9
Training loss: 3.391574709033845
Validation loss: 2.548488566571025

Epoch: 5| Step: 10
Training loss: 2.601052632357747
Validation loss: 2.5281606122705735

Epoch: 133| Step: 0
Training loss: 2.856862783328691
Validation loss: 2.533269092366505

Epoch: 5| Step: 1
Training loss: 2.461473097873295
Validation loss: 2.536579858316696

Epoch: 5| Step: 2
Training loss: 2.686618216703255
Validation loss: 2.5365154162821146

Epoch: 5| Step: 3
Training loss: 2.875577785649061
Validation loss: 2.5466750123249584

Epoch: 5| Step: 4
Training loss: 2.3186893630003707
Validation loss: 2.5378207230903023

Epoch: 5| Step: 5
Training loss: 2.9608687339990514
Validation loss: 2.5375761542295754

Epoch: 5| Step: 6
Training loss: 3.0703314472419505
Validation loss: 2.5411716118924077

Epoch: 5| Step: 7
Training loss: 3.4687350161117108
Validation loss: 2.5399026348801326

Epoch: 5| Step: 8
Training loss: 3.079720485438998
Validation loss: 2.540811083692889

Epoch: 5| Step: 9
Training loss: 3.277835777186244
Validation loss: 2.535590210972748

Epoch: 5| Step: 10
Training loss: 2.6023970631406663
Validation loss: 2.5354236561803427

Epoch: 134| Step: 0
Training loss: 2.9553532343127764
Validation loss: 2.5334814766938263

Epoch: 5| Step: 1
Training loss: 2.9915786801064717
Validation loss: 2.533988885736345

Epoch: 5| Step: 2
Training loss: 2.901272027796163
Validation loss: 2.5320481956417513

Epoch: 5| Step: 3
Training loss: 3.1301312852327725
Validation loss: 2.556403494549261

Epoch: 5| Step: 4
Training loss: 2.9063546766893174
Validation loss: 2.5803856666649447

Epoch: 5| Step: 5
Training loss: 2.469020587240472
Validation loss: 2.5986943873009523

Epoch: 5| Step: 6
Training loss: 2.36132681241563
Validation loss: 2.6144508410283103

Epoch: 5| Step: 7
Training loss: 3.119745032333966
Validation loss: 2.6044587461686994

Epoch: 5| Step: 8
Training loss: 2.5922460217161625
Validation loss: 2.586393681842413

Epoch: 5| Step: 9
Training loss: 3.023874808137011
Validation loss: 2.5543922940402353

Epoch: 5| Step: 10
Training loss: 3.2247300382481754
Validation loss: 2.5369718015533733

Epoch: 135| Step: 0
Training loss: 3.167109926889413
Validation loss: 2.5296610214180375

Epoch: 5| Step: 1
Training loss: 2.6282200817639407
Validation loss: 2.530238360716331

Epoch: 5| Step: 2
Training loss: 2.753928153309394
Validation loss: 2.5325753937394575

Epoch: 5| Step: 3
Training loss: 2.583531115764439
Validation loss: 2.5294756497185404

Epoch: 5| Step: 4
Training loss: 2.7360060704481812
Validation loss: 2.5319753245963934

Epoch: 5| Step: 5
Training loss: 3.408774044454255
Validation loss: 2.5317409094544496

Epoch: 5| Step: 6
Training loss: 2.615320889421559
Validation loss: 2.529442094314616

Epoch: 5| Step: 7
Training loss: 2.431090903286322
Validation loss: 2.533615578789137

Epoch: 5| Step: 8
Training loss: 3.2903145697108305
Validation loss: 2.5366348795082083

Epoch: 5| Step: 9
Training loss: 3.051655779544307
Validation loss: 2.541542041761926

Epoch: 5| Step: 10
Training loss: 2.8456354283728857
Validation loss: 2.546087249257305

Epoch: 136| Step: 0
Training loss: 3.11759422153743
Validation loss: 2.5571065097643797

Epoch: 5| Step: 1
Training loss: 2.944514725604088
Validation loss: 2.56267174866272

Epoch: 5| Step: 2
Training loss: 2.9018817189862043
Validation loss: 2.5787970290075193

Epoch: 5| Step: 3
Training loss: 2.9761377867621412
Validation loss: 2.5821219507417754

Epoch: 5| Step: 4
Training loss: 1.9052054873598707
Validation loss: 2.545682168645045

Epoch: 5| Step: 5
Training loss: 2.8734046822147135
Validation loss: 2.5439790595415532

Epoch: 5| Step: 6
Training loss: 2.8256800077872746
Validation loss: 2.551829089889525

Epoch: 5| Step: 7
Training loss: 3.248855682802895
Validation loss: 2.5398088588469165

Epoch: 5| Step: 8
Training loss: 2.734595938339682
Validation loss: 2.568903266197274

Epoch: 5| Step: 9
Training loss: 2.9940259579314903
Validation loss: 2.5584144106725906

Epoch: 5| Step: 10
Training loss: 3.033290058567881
Validation loss: 2.5369189876006333

Epoch: 137| Step: 0
Training loss: 2.5973851112606945
Validation loss: 2.5304267594854606

Epoch: 5| Step: 1
Training loss: 3.0183662249582555
Validation loss: 2.520969326859965

Epoch: 5| Step: 2
Training loss: 3.296689864470117
Validation loss: 2.5217842211054142

Epoch: 5| Step: 3
Training loss: 3.073605079911188
Validation loss: 2.5219890094943174

Epoch: 5| Step: 4
Training loss: 3.253439330526542
Validation loss: 2.523087212849062

Epoch: 5| Step: 5
Training loss: 2.343166940007975
Validation loss: 2.525322688473826

Epoch: 5| Step: 6
Training loss: 3.083384711035118
Validation loss: 2.5231774832182707

Epoch: 5| Step: 7
Training loss: 2.5966561823165186
Validation loss: 2.5268640361678494

Epoch: 5| Step: 8
Training loss: 2.0790991543477717
Validation loss: 2.5257470704547527

Epoch: 5| Step: 9
Training loss: 2.971535430024291
Validation loss: 2.5224580369061904

Epoch: 5| Step: 10
Training loss: 3.162380195127581
Validation loss: 2.5285178190198145

Epoch: 138| Step: 0
Training loss: 3.00046948891847
Validation loss: 2.5204569360067155

Epoch: 5| Step: 1
Training loss: 2.7275773485162014
Validation loss: 2.5253221727656427

Epoch: 5| Step: 2
Training loss: 2.6618464137824343
Validation loss: 2.5263602582443583

Epoch: 5| Step: 3
Training loss: 2.7800345175816275
Validation loss: 2.5199040736040694

Epoch: 5| Step: 4
Training loss: 3.1934211934956815
Validation loss: 2.51522478698263

Epoch: 5| Step: 5
Training loss: 3.107642069459184
Validation loss: 2.5203557800719243

Epoch: 5| Step: 6
Training loss: 2.638137096819225
Validation loss: 2.5280972211729176

Epoch: 5| Step: 7
Training loss: 2.8680711262926573
Validation loss: 2.5239538676997424

Epoch: 5| Step: 8
Training loss: 2.870336149779662
Validation loss: 2.5452397855542364

Epoch: 5| Step: 9
Training loss: 3.0280963971152186
Validation loss: 2.5471416338599653

Epoch: 5| Step: 10
Training loss: 2.701230835288368
Validation loss: 2.5656248318901187

Epoch: 139| Step: 0
Training loss: 2.9013804997485746
Validation loss: 2.554565054452904

Epoch: 5| Step: 1
Training loss: 2.8895047053113796
Validation loss: 2.547197237106681

Epoch: 5| Step: 2
Training loss: 3.0262696557271305
Validation loss: 2.5442386916157305

Epoch: 5| Step: 3
Training loss: 2.7404273489272684
Validation loss: 2.5409899608768254

Epoch: 5| Step: 4
Training loss: 2.6370095325770713
Validation loss: 2.533361504510914

Epoch: 5| Step: 5
Training loss: 2.797576901467197
Validation loss: 2.5223133261731587

Epoch: 5| Step: 6
Training loss: 2.7754285945348722
Validation loss: 2.516776086826764

Epoch: 5| Step: 7
Training loss: 2.9526432996789773
Validation loss: 2.523059326065149

Epoch: 5| Step: 8
Training loss: 3.101488703467155
Validation loss: 2.518439286379128

Epoch: 5| Step: 9
Training loss: 2.8310723726918297
Validation loss: 2.517023345914546

Epoch: 5| Step: 10
Training loss: 2.925156652706158
Validation loss: 2.522855282525151

Epoch: 140| Step: 0
Training loss: 3.0886595490695625
Validation loss: 2.5155490819713133

Epoch: 5| Step: 1
Training loss: 3.0503576475479233
Validation loss: 2.5232564788262226

Epoch: 5| Step: 2
Training loss: 2.7294344491601117
Validation loss: 2.5231046872109264

Epoch: 5| Step: 3
Training loss: 2.930102509668064
Validation loss: 2.5362792890060155

Epoch: 5| Step: 4
Training loss: 2.8458882771033713
Validation loss: 2.5559094552764234

Epoch: 5| Step: 5
Training loss: 2.5573352776335376
Validation loss: 2.554942333302008

Epoch: 5| Step: 6
Training loss: 3.0286339551583943
Validation loss: 2.542259525070619

Epoch: 5| Step: 7
Training loss: 2.9281384250980427
Validation loss: 2.5307130455498714

Epoch: 5| Step: 8
Training loss: 3.020155591682924
Validation loss: 2.5384534455251715

Epoch: 5| Step: 9
Training loss: 2.471594029407664
Validation loss: 2.5202943430243363

Epoch: 5| Step: 10
Training loss: 2.96297849500965
Validation loss: 2.548370895390058

Epoch: 141| Step: 0
Training loss: 2.2761937373590753
Validation loss: 2.557379930068792

Epoch: 5| Step: 1
Training loss: 2.964862245444204
Validation loss: 2.566127450604421

Epoch: 5| Step: 2
Training loss: 3.373715332802925
Validation loss: 2.5401468596434715

Epoch: 5| Step: 3
Training loss: 2.3919927137767854
Validation loss: 2.555232486356782

Epoch: 5| Step: 4
Training loss: 2.655999654304528
Validation loss: 2.5361930855200097

Epoch: 5| Step: 5
Training loss: 3.0102106219642546
Validation loss: 2.542485464479645

Epoch: 5| Step: 6
Training loss: 3.0082720516933823
Validation loss: 2.5459946656606185

Epoch: 5| Step: 7
Training loss: 2.5439821441971437
Validation loss: 2.5615387090666286

Epoch: 5| Step: 8
Training loss: 2.864672979628286
Validation loss: 2.5661069094477207

Epoch: 5| Step: 9
Training loss: 2.840684013467122
Validation loss: 2.569765702724701

Epoch: 5| Step: 10
Training loss: 3.5088219496440964
Validation loss: 2.5833563547236627

Epoch: 142| Step: 0
Training loss: 3.182483090867448
Validation loss: 2.525853093403845

Epoch: 5| Step: 1
Training loss: 2.530900153955986
Validation loss: 2.512908543003441

Epoch: 5| Step: 2
Training loss: 3.0672788119606498
Validation loss: 2.5145451546427777

Epoch: 5| Step: 3
Training loss: 2.29733427477371
Validation loss: 2.5183268413152047

Epoch: 5| Step: 4
Training loss: 3.1549036156974464
Validation loss: 2.526851892938908

Epoch: 5| Step: 5
Training loss: 2.547783999499461
Validation loss: 2.5390746585374986

Epoch: 5| Step: 6
Training loss: 2.894806348157845
Validation loss: 2.567800603602048

Epoch: 5| Step: 7
Training loss: 3.0376571112294477
Validation loss: 2.5903170981824393

Epoch: 5| Step: 8
Training loss: 3.1225848211002725
Validation loss: 2.610393144515823

Epoch: 5| Step: 9
Training loss: 3.26171217135377
Validation loss: 2.615474383548966

Epoch: 5| Step: 10
Training loss: 2.690090793651467
Validation loss: 2.6203559172110635

Epoch: 143| Step: 0
Training loss: 3.3700127664205373
Validation loss: 2.6280068025079997

Epoch: 5| Step: 1
Training loss: 2.9782882853813604
Validation loss: 2.6060769524812066

Epoch: 5| Step: 2
Training loss: 3.2804814483113365
Validation loss: 2.590119630367198

Epoch: 5| Step: 3
Training loss: 2.4060274491872855
Validation loss: 2.5784742539530465

Epoch: 5| Step: 4
Training loss: 2.8268546101629477
Validation loss: 2.5814399664630545

Epoch: 5| Step: 5
Training loss: 2.549461876430985
Validation loss: 2.5688884126455522

Epoch: 5| Step: 6
Training loss: 3.248207625071669
Validation loss: 2.584676706526663

Epoch: 5| Step: 7
Training loss: 3.019619998392576
Validation loss: 2.581472330555204

Epoch: 5| Step: 8
Training loss: 2.863599647627882
Validation loss: 2.5815837114133853

Epoch: 5| Step: 9
Training loss: 2.6138563221888984
Validation loss: 2.566363641611167

Epoch: 5| Step: 10
Training loss: 2.6396459988022865
Validation loss: 2.5707051440769164

Epoch: 144| Step: 0
Training loss: 2.9995290068609917
Validation loss: 2.5721095852239366

Epoch: 5| Step: 1
Training loss: 2.726391806082434
Validation loss: 2.554444212811634

Epoch: 5| Step: 2
Training loss: 3.11050317894792
Validation loss: 2.5601343159343686

Epoch: 5| Step: 3
Training loss: 2.9479330936329156
Validation loss: 2.536600767945197

Epoch: 5| Step: 4
Training loss: 3.15456443573036
Validation loss: 2.5305977744072723

Epoch: 5| Step: 5
Training loss: 2.2324703608443137
Validation loss: 2.5430247227243568

Epoch: 5| Step: 6
Training loss: 2.1194578715585557
Validation loss: 2.5292224083271813

Epoch: 5| Step: 7
Training loss: 3.132076643141215
Validation loss: 2.571347940166851

Epoch: 5| Step: 8
Training loss: 2.699490523837295
Validation loss: 2.641062796879294

Epoch: 5| Step: 9
Training loss: 3.0488672247853166
Validation loss: 2.5903519398934574

Epoch: 5| Step: 10
Training loss: 3.3606962222894743
Validation loss: 2.5463835448871768

Epoch: 145| Step: 0
Training loss: 2.725673672758247
Validation loss: 2.508280785024861

Epoch: 5| Step: 1
Training loss: 2.890358247562985
Validation loss: 2.5028565309978577

Epoch: 5| Step: 2
Training loss: 3.2438422335115322
Validation loss: 2.5158940368004212

Epoch: 5| Step: 3
Training loss: 3.304348542706567
Validation loss: 2.5358835305893166

Epoch: 5| Step: 4
Training loss: 2.7380353569606797
Validation loss: 2.5550449755070077

Epoch: 5| Step: 5
Training loss: 2.7800617894503032
Validation loss: 2.566567698747947

Epoch: 5| Step: 6
Training loss: 2.623463680643356
Validation loss: 2.544655214071463

Epoch: 5| Step: 7
Training loss: 2.851302628890619
Validation loss: 2.5421544899114505

Epoch: 5| Step: 8
Training loss: 3.141996928562579
Validation loss: 2.550931804771559

Epoch: 5| Step: 9
Training loss: 2.8306687859509165
Validation loss: 2.55884201271905

Epoch: 5| Step: 10
Training loss: 2.363857634064187
Validation loss: 2.5563996697490214

Epoch: 146| Step: 0
Training loss: 3.037295575582355
Validation loss: 2.5547348368800167

Epoch: 5| Step: 1
Training loss: 3.0831895399501166
Validation loss: 2.544064337150986

Epoch: 5| Step: 2
Training loss: 2.6999138076587967
Validation loss: 2.5616796257311516

Epoch: 5| Step: 3
Training loss: 2.829532504879029
Validation loss: 2.5424312535577642

Epoch: 5| Step: 4
Training loss: 3.058472300879408
Validation loss: 2.553377213170791

Epoch: 5| Step: 5
Training loss: 2.432212572356978
Validation loss: 2.5338830868552265

Epoch: 5| Step: 6
Training loss: 2.8053367097142914
Validation loss: 2.5231352370794

Epoch: 5| Step: 7
Training loss: 2.920190825563055
Validation loss: 2.525907925024417

Epoch: 5| Step: 8
Training loss: 2.922877012397554
Validation loss: 2.519619978098927

Epoch: 5| Step: 9
Training loss: 3.3128562591716992
Validation loss: 2.5212189872529116

Epoch: 5| Step: 10
Training loss: 2.1188409971428004
Validation loss: 2.5121806523824524

Epoch: 147| Step: 0
Training loss: 2.2446471224550426
Validation loss: 2.5130039512700137

Epoch: 5| Step: 1
Training loss: 3.0198015928461674
Validation loss: 2.513949201460866

Epoch: 5| Step: 2
Training loss: 2.8189839538788726
Validation loss: 2.509812740705479

Epoch: 5| Step: 3
Training loss: 2.7640325412021585
Validation loss: 2.509345929732882

Epoch: 5| Step: 4
Training loss: 3.053748257137243
Validation loss: 2.5148487782641262

Epoch: 5| Step: 5
Training loss: 3.345477504660866
Validation loss: 2.5106681619803886

Epoch: 5| Step: 6
Training loss: 2.9604917004441065
Validation loss: 2.5166080123370045

Epoch: 5| Step: 7
Training loss: 2.5969603560061763
Validation loss: 2.5127354829630026

Epoch: 5| Step: 8
Training loss: 2.9966796938648734
Validation loss: 2.5132503798502013

Epoch: 5| Step: 9
Training loss: 2.6586931549150585
Validation loss: 2.518212625949941

Epoch: 5| Step: 10
Training loss: 2.9562103462382465
Validation loss: 2.5240732794882152

Epoch: 148| Step: 0
Training loss: 3.3805331332249273
Validation loss: 2.541174508276121

Epoch: 5| Step: 1
Training loss: 2.892734891673175
Validation loss: 2.5197750725576804

Epoch: 5| Step: 2
Training loss: 2.891582598458162
Validation loss: 2.5064671637525855

Epoch: 5| Step: 3
Training loss: 2.3573539110957022
Validation loss: 2.506811118443577

Epoch: 5| Step: 4
Training loss: 2.5385326595613593
Validation loss: 2.5033056533812688

Epoch: 5| Step: 5
Training loss: 3.038035869032543
Validation loss: 2.5031344442780976

Epoch: 5| Step: 6
Training loss: 3.143886106665534
Validation loss: 2.506151483110467

Epoch: 5| Step: 7
Training loss: 2.3594007680130016
Validation loss: 2.5028985048574848

Epoch: 5| Step: 8
Training loss: 2.9435054993381256
Validation loss: 2.5014699398400397

Epoch: 5| Step: 9
Training loss: 2.692740808484178
Validation loss: 2.5014567130436713

Epoch: 5| Step: 10
Training loss: 3.144029432736528
Validation loss: 2.503600683401864

Epoch: 149| Step: 0
Training loss: 3.14043338627612
Validation loss: 2.523535628985408

Epoch: 5| Step: 1
Training loss: 2.6127326058686693
Validation loss: 2.568786080078109

Epoch: 5| Step: 2
Training loss: 3.024790064565206
Validation loss: 2.6375340235053875

Epoch: 5| Step: 3
Training loss: 2.738105278510093
Validation loss: 2.651383423848532

Epoch: 5| Step: 4
Training loss: 2.615741660593997
Validation loss: 2.635488084471241

Epoch: 5| Step: 5
Training loss: 2.9766060733359248
Validation loss: 2.5325757394283634

Epoch: 5| Step: 6
Training loss: 2.9678934568216766
Validation loss: 2.498348748002751

Epoch: 5| Step: 7
Training loss: 2.781265944531631
Validation loss: 2.5016380255666477

Epoch: 5| Step: 8
Training loss: 2.8549598835333
Validation loss: 2.514180357063567

Epoch: 5| Step: 9
Training loss: 3.3193629444142574
Validation loss: 2.518853800456734

Epoch: 5| Step: 10
Training loss: 2.8023556337085984
Validation loss: 2.5199821422931863

Epoch: 150| Step: 0
Training loss: 3.0498461199855345
Validation loss: 2.5197032455444384

Epoch: 5| Step: 1
Training loss: 2.4522193160119308
Validation loss: 2.5158725841654466

Epoch: 5| Step: 2
Training loss: 2.5727708185740146
Validation loss: 2.504715733662027

Epoch: 5| Step: 3
Training loss: 2.8326551710353245
Validation loss: 2.5054248218853843

Epoch: 5| Step: 4
Training loss: 2.931170035046249
Validation loss: 2.5026581220291115

Epoch: 5| Step: 5
Training loss: 2.7482504914959205
Validation loss: 2.5154064574993136

Epoch: 5| Step: 6
Training loss: 3.372383233516923
Validation loss: 2.53892391359857

Epoch: 5| Step: 7
Training loss: 2.7013898804266994
Validation loss: 2.5797833838709403

Epoch: 5| Step: 8
Training loss: 3.3880422573404267
Validation loss: 2.602771147540561

Epoch: 5| Step: 9
Training loss: 2.965292433008393
Validation loss: 2.618242928957601

Epoch: 5| Step: 10
Training loss: 2.6307639463657324
Validation loss: 2.5838489481014966

Epoch: 151| Step: 0
Training loss: 3.0226127031768
Validation loss: 2.5792491978824232

Epoch: 5| Step: 1
Training loss: 2.583925784276453
Validation loss: 2.5321327866845453

Epoch: 5| Step: 2
Training loss: 3.095713599154205
Validation loss: 2.514756706273339

Epoch: 5| Step: 3
Training loss: 3.451874795775897
Validation loss: 2.507277622223868

Epoch: 5| Step: 4
Training loss: 3.1443083310930953
Validation loss: 2.50137909413671

Epoch: 5| Step: 5
Training loss: 2.9077162786651582
Validation loss: 2.5003876252280244

Epoch: 5| Step: 6
Training loss: 2.591411501557414
Validation loss: 2.500614527575302

Epoch: 5| Step: 7
Training loss: 2.6154801450517944
Validation loss: 2.496369529411502

Epoch: 5| Step: 8
Training loss: 2.3999030888382618
Validation loss: 2.5033096217738517

Epoch: 5| Step: 9
Training loss: 2.565947655706595
Validation loss: 2.497809965443831

Epoch: 5| Step: 10
Training loss: 2.9828321053613482
Validation loss: 2.5029856645104602

Epoch: 152| Step: 0
Training loss: 3.1404406744921776
Validation loss: 2.501830845743587

Epoch: 5| Step: 1
Training loss: 2.4257043896967017
Validation loss: 2.511537909015951

Epoch: 5| Step: 2
Training loss: 3.5304977831118403
Validation loss: 2.506531753395954

Epoch: 5| Step: 3
Training loss: 3.1606803996907464
Validation loss: 2.5156770320039366

Epoch: 5| Step: 4
Training loss: 2.487471276505606
Validation loss: 2.531463880376289

Epoch: 5| Step: 5
Training loss: 2.5766104208501797
Validation loss: 2.5231767211907163

Epoch: 5| Step: 6
Training loss: 2.488979942164327
Validation loss: 2.5279948690763328

Epoch: 5| Step: 7
Training loss: 2.7804127836798167
Validation loss: 2.5454797627888324

Epoch: 5| Step: 8
Training loss: 3.262574591825315
Validation loss: 2.5407271811569663

Epoch: 5| Step: 9
Training loss: 2.7459584795653016
Validation loss: 2.528546934750664

Epoch: 5| Step: 10
Training loss: 2.4453605671506287
Validation loss: 2.5192844110651427

Epoch: 153| Step: 0
Training loss: 2.9424419631355345
Validation loss: 2.5010793796378166

Epoch: 5| Step: 1
Training loss: 2.361065694584089
Validation loss: 2.50072848155699

Epoch: 5| Step: 2
Training loss: 2.9046158657095336
Validation loss: 2.490529053263598

Epoch: 5| Step: 3
Training loss: 3.0284917808094947
Validation loss: 2.4995746691682386

Epoch: 5| Step: 4
Training loss: 3.6158525215642627
Validation loss: 2.504382177216746

Epoch: 5| Step: 5
Training loss: 2.2787045425844528
Validation loss: 2.5017392661080575

Epoch: 5| Step: 6
Training loss: 2.9218188601725736
Validation loss: 2.4974416532497012

Epoch: 5| Step: 7
Training loss: 2.7767001880516684
Validation loss: 2.5092049041074223

Epoch: 5| Step: 8
Training loss: 2.850125052402272
Validation loss: 2.512342927598516

Epoch: 5| Step: 9
Training loss: 2.3268279488453443
Validation loss: 2.523086546305127

Epoch: 5| Step: 10
Training loss: 3.0669232558284065
Validation loss: 2.5315914959277506

Epoch: 154| Step: 0
Training loss: 3.1055375385463164
Validation loss: 2.5355959366142438

Epoch: 5| Step: 1
Training loss: 3.057539367172813
Validation loss: 2.520772618134047

Epoch: 5| Step: 2
Training loss: 2.628768849289413
Validation loss: 2.537345239120823

Epoch: 5| Step: 3
Training loss: 2.769334708101277
Validation loss: 2.532224710809276

Epoch: 5| Step: 4
Training loss: 3.061981468677818
Validation loss: 2.5270701577906673

Epoch: 5| Step: 5
Training loss: 2.6573316279244903
Validation loss: 2.5258863879423763

Epoch: 5| Step: 6
Training loss: 2.2325615626408704
Validation loss: 2.5162597305925343

Epoch: 5| Step: 7
Training loss: 2.864212696488782
Validation loss: 2.502552780046019

Epoch: 5| Step: 8
Training loss: 3.0425244693822187
Validation loss: 2.494069968537535

Epoch: 5| Step: 9
Training loss: 3.009414206751515
Validation loss: 2.4949850584222237

Epoch: 5| Step: 10
Training loss: 2.8370394496817086
Validation loss: 2.491774300098978

Epoch: 155| Step: 0
Training loss: 2.9586087130039007
Validation loss: 2.4939718067990597

Epoch: 5| Step: 1
Training loss: 2.387725168365232
Validation loss: 2.4912047208556487

Epoch: 5| Step: 2
Training loss: 2.6295516198287485
Validation loss: 2.489279742700621

Epoch: 5| Step: 3
Training loss: 2.793531155815514
Validation loss: 2.5006549900091883

Epoch: 5| Step: 4
Training loss: 3.1214413025650325
Validation loss: 2.5049645987091553

Epoch: 5| Step: 5
Training loss: 2.478445017525105
Validation loss: 2.506718285896827

Epoch: 5| Step: 6
Training loss: 3.044181689721259
Validation loss: 2.531888279969854

Epoch: 5| Step: 7
Training loss: 3.0503451417845797
Validation loss: 2.578630957453247

Epoch: 5| Step: 8
Training loss: 3.1985256017078045
Validation loss: 2.6161315825336504

Epoch: 5| Step: 9
Training loss: 3.0589825418403715
Validation loss: 2.6469729501951935

Epoch: 5| Step: 10
Training loss: 2.3004122115897405
Validation loss: 2.597289306521213

Epoch: 156| Step: 0
Training loss: 2.744368422206501
Validation loss: 2.584793095846711

Epoch: 5| Step: 1
Training loss: 3.0008197300277843
Validation loss: 2.5740059890671656

Epoch: 5| Step: 2
Training loss: 3.0541062838703352
Validation loss: 2.549356962032864

Epoch: 5| Step: 3
Training loss: 2.5563372496845473
Validation loss: 2.537966460756461

Epoch: 5| Step: 4
Training loss: 3.200725419551753
Validation loss: 2.5101140024962123

Epoch: 5| Step: 5
Training loss: 2.701774303810907
Validation loss: 2.4936001847606253

Epoch: 5| Step: 6
Training loss: 2.6989002177848445
Validation loss: 2.491506349662539

Epoch: 5| Step: 7
Training loss: 2.660862676225922
Validation loss: 2.4878830302194883

Epoch: 5| Step: 8
Training loss: 2.7921604934351203
Validation loss: 2.4890396554952723

Epoch: 5| Step: 9
Training loss: 2.76346206138193
Validation loss: 2.490846754489489

Epoch: 5| Step: 10
Training loss: 3.187961021443513
Validation loss: 2.4877457085787382

Epoch: 157| Step: 0
Training loss: 1.8883749443423363
Validation loss: 2.488516087396439

Epoch: 5| Step: 1
Training loss: 2.8750729758910847
Validation loss: 2.488719510403586

Epoch: 5| Step: 2
Training loss: 2.6938604451702726
Validation loss: 2.495208232419326

Epoch: 5| Step: 3
Training loss: 2.7882385746583176
Validation loss: 2.514151449691106

Epoch: 5| Step: 4
Training loss: 2.788963508452029
Validation loss: 2.535311742952946

Epoch: 5| Step: 5
Training loss: 2.801611528536716
Validation loss: 2.5536436073272255

Epoch: 5| Step: 6
Training loss: 3.5720184057088304
Validation loss: 2.5447741349998343

Epoch: 5| Step: 7
Training loss: 2.838739025476055
Validation loss: 2.530483366243261

Epoch: 5| Step: 8
Training loss: 2.839001222326023
Validation loss: 2.5246599185845113

Epoch: 5| Step: 9
Training loss: 3.3163662785613868
Validation loss: 2.5004876481543343

Epoch: 5| Step: 10
Training loss: 2.5253721208477145
Validation loss: 2.4926832546113142

Epoch: 158| Step: 0
Training loss: 2.7130971435860287
Validation loss: 2.4966879830007036

Epoch: 5| Step: 1
Training loss: 2.849439358361996
Validation loss: 2.496776553601719

Epoch: 5| Step: 2
Training loss: 2.844752711324207
Validation loss: 2.4995584672268163

Epoch: 5| Step: 3
Training loss: 2.794420667875378
Validation loss: 2.5193035888075648

Epoch: 5| Step: 4
Training loss: 1.8686286759304325
Validation loss: 2.520186367082426

Epoch: 5| Step: 5
Training loss: 3.1857496953654403
Validation loss: 2.5366614512813492

Epoch: 5| Step: 6
Training loss: 3.017688104791934
Validation loss: 2.538293727354912

Epoch: 5| Step: 7
Training loss: 2.189976516493213
Validation loss: 2.526239557171941

Epoch: 5| Step: 8
Training loss: 3.240399780098635
Validation loss: 2.512474319342274

Epoch: 5| Step: 9
Training loss: 2.9702070977033017
Validation loss: 2.510711081465895

Epoch: 5| Step: 10
Training loss: 3.2309636356216505
Validation loss: 2.5031375454695075

Epoch: 159| Step: 0
Training loss: 2.975431452647958
Validation loss: 2.5124780783637948

Epoch: 5| Step: 1
Training loss: 2.6780561369296176
Validation loss: 2.5025409695927627

Epoch: 5| Step: 2
Training loss: 2.83984375
Validation loss: 2.5116488779156363

Epoch: 5| Step: 3
Training loss: 3.3448517312345656
Validation loss: 2.544929660333821

Epoch: 5| Step: 4
Training loss: 2.638335459939851
Validation loss: 2.4966896002363055

Epoch: 5| Step: 5
Training loss: 2.821541980512895
Validation loss: 2.4914044370775748

Epoch: 5| Step: 6
Training loss: 2.653796869583693
Validation loss: 2.496080844944709

Epoch: 5| Step: 7
Training loss: 3.1587523559030157
Validation loss: 2.484903890291587

Epoch: 5| Step: 8
Training loss: 2.779617344709126
Validation loss: 2.477937165648212

Epoch: 5| Step: 9
Training loss: 2.5981936709111007
Validation loss: 2.4902191098585993

Epoch: 5| Step: 10
Training loss: 2.6538096269115976
Validation loss: 2.490614742060763

Epoch: 160| Step: 0
Training loss: 2.8566725003135818
Validation loss: 2.4993546011731276

Epoch: 5| Step: 1
Training loss: 3.4083212058699535
Validation loss: 2.517296181646344

Epoch: 5| Step: 2
Training loss: 2.2845469648810712
Validation loss: 2.5411687588856475

Epoch: 5| Step: 3
Training loss: 2.57611653092798
Validation loss: 2.5668866846972134

Epoch: 5| Step: 4
Training loss: 3.1091448061285396
Validation loss: 2.5856502442684226

Epoch: 5| Step: 5
Training loss: 2.5111752599870143
Validation loss: 2.594814710133173

Epoch: 5| Step: 6
Training loss: 2.2029518438159004
Validation loss: 2.5672520480434735

Epoch: 5| Step: 7
Training loss: 3.04585789063065
Validation loss: 2.5496194913083925

Epoch: 5| Step: 8
Training loss: 3.2781750030631382
Validation loss: 2.508283360642042

Epoch: 5| Step: 9
Training loss: 2.9610879099948675
Validation loss: 2.4939569330508125

Epoch: 5| Step: 10
Training loss: 2.536645860156406
Validation loss: 2.4876676227077

Epoch: 161| Step: 0
Training loss: 3.0850068439426277
Validation loss: 2.4814626420609804

Epoch: 5| Step: 1
Training loss: 2.952430280077045
Validation loss: 2.4891806834775774

Epoch: 5| Step: 2
Training loss: 2.760856526196127
Validation loss: 2.486056981708433

Epoch: 5| Step: 3
Training loss: 2.4051586500091564
Validation loss: 2.4910449639305035

Epoch: 5| Step: 4
Training loss: 2.6449796445816864
Validation loss: 2.495460714606009

Epoch: 5| Step: 5
Training loss: 3.299520868139729
Validation loss: 2.4856309533814933

Epoch: 5| Step: 6
Training loss: 3.5277691454710856
Validation loss: 2.487618471654213

Epoch: 5| Step: 7
Training loss: 2.7248200803383043
Validation loss: 2.506901752983061

Epoch: 5| Step: 8
Training loss: 2.338417395424129
Validation loss: 2.522563240753476

Epoch: 5| Step: 9
Training loss: 2.445165660215274
Validation loss: 2.5229492639677185

Epoch: 5| Step: 10
Training loss: 2.7366441303243683
Validation loss: 2.5361024404282433

Epoch: 162| Step: 0
Training loss: 3.311946318794902
Validation loss: 2.5425256669150524

Epoch: 5| Step: 1
Training loss: 2.5708906920560604
Validation loss: 2.5697806968567725

Epoch: 5| Step: 2
Training loss: 2.9078928908151216
Validation loss: 2.5747313297462098

Epoch: 5| Step: 3
Training loss: 2.8390902394528337
Validation loss: 2.570044140359067

Epoch: 5| Step: 4
Training loss: 3.1671234771776646
Validation loss: 2.550474067750479

Epoch: 5| Step: 5
Training loss: 2.797946149415549
Validation loss: 2.541321792753407

Epoch: 5| Step: 6
Training loss: 2.7446039317796087
Validation loss: 2.5455825488665673

Epoch: 5| Step: 7
Training loss: 2.657361056265353
Validation loss: 2.5294893401306204

Epoch: 5| Step: 8
Training loss: 2.8737591263210076
Validation loss: 2.5202762307156252

Epoch: 5| Step: 9
Training loss: 2.5760701631563045
Validation loss: 2.5074617405523885

Epoch: 5| Step: 10
Training loss: 2.3676422991581085
Validation loss: 2.5081107833322545

Epoch: 163| Step: 0
Training loss: 2.067148922468716
Validation loss: 2.5164158441109477

Epoch: 5| Step: 1
Training loss: 2.466637685536772
Validation loss: 2.5006325567522074

Epoch: 5| Step: 2
Training loss: 2.7296776232570763
Validation loss: 2.5051520614609526

Epoch: 5| Step: 3
Training loss: 2.881426387526393
Validation loss: 2.50891572033826

Epoch: 5| Step: 4
Training loss: 2.734308034894295
Validation loss: 2.4965031840874756

Epoch: 5| Step: 5
Training loss: 3.0628601173892758
Validation loss: 2.502736364013661

Epoch: 5| Step: 6
Training loss: 2.9509147971355616
Validation loss: 2.526998817119353

Epoch: 5| Step: 7
Training loss: 3.390541462374565
Validation loss: 2.560097872831709

Epoch: 5| Step: 8
Training loss: 2.8839987198381056
Validation loss: 2.548850664130211

Epoch: 5| Step: 9
Training loss: 2.760022539516686
Validation loss: 2.5379716941622776

Epoch: 5| Step: 10
Training loss: 2.9402274597824554
Validation loss: 2.5126189886365013

Epoch: 164| Step: 0
Training loss: 2.8421940162252644
Validation loss: 2.4981500312998306

Epoch: 5| Step: 1
Training loss: 3.0876370542431557
Validation loss: 2.4931667853519768

Epoch: 5| Step: 2
Training loss: 2.8192740348676995
Validation loss: 2.4932159247098857

Epoch: 5| Step: 3
Training loss: 2.6014886335820764
Validation loss: 2.487720709371447

Epoch: 5| Step: 4
Training loss: 2.841443981793828
Validation loss: 2.4904500947572794

Epoch: 5| Step: 5
Training loss: 2.097443354936373
Validation loss: 2.487034950517661

Epoch: 5| Step: 6
Training loss: 2.838279408696588
Validation loss: 2.4916296449103696

Epoch: 5| Step: 7
Training loss: 2.8158623835576138
Validation loss: 2.5078918671414305

Epoch: 5| Step: 8
Training loss: 2.538712603595528
Validation loss: 2.531923666004677

Epoch: 5| Step: 9
Training loss: 2.9358902436615626
Validation loss: 2.5330704918463667

Epoch: 5| Step: 10
Training loss: 3.477263030720347
Validation loss: 2.518123878804111

Epoch: 165| Step: 0
Training loss: 2.69669322155993
Validation loss: 2.51108007933054

Epoch: 5| Step: 1
Training loss: 2.2804464727909957
Validation loss: 2.520576581606302

Epoch: 5| Step: 2
Training loss: 2.784707481322008
Validation loss: 2.5042047068530926

Epoch: 5| Step: 3
Training loss: 2.9523488795974555
Validation loss: 2.488994598971405

Epoch: 5| Step: 4
Training loss: 3.1650093828155623
Validation loss: 2.484133251953263

Epoch: 5| Step: 5
Training loss: 2.6610477874891734
Validation loss: 2.485216263124914

Epoch: 5| Step: 6
Training loss: 2.834101647567122
Validation loss: 2.4888174384312194

Epoch: 5| Step: 7
Training loss: 2.936547307487371
Validation loss: 2.501712740486242

Epoch: 5| Step: 8
Training loss: 2.8655480627216963
Validation loss: 2.502995437723121

Epoch: 5| Step: 9
Training loss: 2.7438408630202282
Validation loss: 2.498157638624794

Epoch: 5| Step: 10
Training loss: 2.932293437372264
Validation loss: 2.4822845776012916

Epoch: 166| Step: 0
Training loss: 2.4279977497549172
Validation loss: 2.478766160730805

Epoch: 5| Step: 1
Training loss: 2.4206660052548723
Validation loss: 2.472816031722624

Epoch: 5| Step: 2
Training loss: 2.827038804005532
Validation loss: 2.4739649190421065

Epoch: 5| Step: 3
Training loss: 2.991038288510356
Validation loss: 2.474354064758517

Epoch: 5| Step: 4
Training loss: 2.990301030547911
Validation loss: 2.4849353678647508

Epoch: 5| Step: 5
Training loss: 2.4866882686682357
Validation loss: 2.4895774733802707

Epoch: 5| Step: 6
Training loss: 3.3647014175967587
Validation loss: 2.4737372148764347

Epoch: 5| Step: 7
Training loss: 3.0387182359435787
Validation loss: 2.4912348263114525

Epoch: 5| Step: 8
Training loss: 2.864096823329009
Validation loss: 2.4997367689541865

Epoch: 5| Step: 9
Training loss: 2.613148866958216
Validation loss: 2.506685669483757

Epoch: 5| Step: 10
Training loss: 2.663766883714246
Validation loss: 2.5327098419067244

Epoch: 167| Step: 0
Training loss: 2.434318716160011
Validation loss: 2.5249349456792376

Epoch: 5| Step: 1
Training loss: 3.1187299769796555
Validation loss: 2.512406049880016

Epoch: 5| Step: 2
Training loss: 2.9051669163770466
Validation loss: 2.4879842318088694

Epoch: 5| Step: 3
Training loss: 2.347650867525808
Validation loss: 2.4690508209417916

Epoch: 5| Step: 4
Training loss: 2.4019766178120614
Validation loss: 2.46649801487827

Epoch: 5| Step: 5
Training loss: 3.006027207079495
Validation loss: 2.4701456497035914

Epoch: 5| Step: 6
Training loss: 2.9054626710955835
Validation loss: 2.4715148471748956

Epoch: 5| Step: 7
Training loss: 3.4212510746378215
Validation loss: 2.4743167871827056

Epoch: 5| Step: 8
Training loss: 2.9386881596505625
Validation loss: 2.467697229576264

Epoch: 5| Step: 9
Training loss: 2.7429159126201506
Validation loss: 2.4824970763528946

Epoch: 5| Step: 10
Training loss: 2.461381369630707
Validation loss: 2.491077574160459

Epoch: 168| Step: 0
Training loss: 2.971516815646337
Validation loss: 2.50394025511431

Epoch: 5| Step: 1
Training loss: 2.9260289656482383
Validation loss: 2.5205937407889505

Epoch: 5| Step: 2
Training loss: 2.734847458485629
Validation loss: 2.526742213673905

Epoch: 5| Step: 3
Training loss: 2.7276141480389553
Validation loss: 2.515392088102888

Epoch: 5| Step: 4
Training loss: 2.984620728287538
Validation loss: 2.5068809908891843

Epoch: 5| Step: 5
Training loss: 2.859047959599581
Validation loss: 2.4918446533404977

Epoch: 5| Step: 6
Training loss: 2.4671965914770744
Validation loss: 2.5092668369259705

Epoch: 5| Step: 7
Training loss: 2.3903859336845144
Validation loss: 2.483200776832149

Epoch: 5| Step: 8
Training loss: 2.9978642808809792
Validation loss: 2.493137149498358

Epoch: 5| Step: 9
Training loss: 2.4799113931516383
Validation loss: 2.49361301115457

Epoch: 5| Step: 10
Training loss: 3.1847938569098537
Validation loss: 2.4951395110891266

Epoch: 169| Step: 0
Training loss: 2.7197283157534744
Validation loss: 2.490157727150321

Epoch: 5| Step: 1
Training loss: 3.0311203761750014
Validation loss: 2.501491905432199

Epoch: 5| Step: 2
Training loss: 2.7423145232165447
Validation loss: 2.493398033887634

Epoch: 5| Step: 3
Training loss: 2.8185378643995898
Validation loss: 2.5014395804156937

Epoch: 5| Step: 4
Training loss: 2.681836481575622
Validation loss: 2.5080492681416935

Epoch: 5| Step: 5
Training loss: 2.7453745175490476
Validation loss: 2.5375947370938214

Epoch: 5| Step: 6
Training loss: 2.3912143354852113
Validation loss: 2.542776497566113

Epoch: 5| Step: 7
Training loss: 2.8170419258678363
Validation loss: 2.5255596538709058

Epoch: 5| Step: 8
Training loss: 2.6512553210746894
Validation loss: 2.5461581054341917

Epoch: 5| Step: 9
Training loss: 2.780680051547151
Validation loss: 2.5544000048453923

Epoch: 5| Step: 10
Training loss: 3.3572312723129305
Validation loss: 2.57323062477955

Epoch: 170| Step: 0
Training loss: 2.8775200786934034
Validation loss: 2.5364236011659425

Epoch: 5| Step: 1
Training loss: 2.6445534281173977
Validation loss: 2.510527911142732

Epoch: 5| Step: 2
Training loss: 2.7349918214721023
Validation loss: 2.469374456593152

Epoch: 5| Step: 3
Training loss: 2.9532903392868435
Validation loss: 2.4781493332100135

Epoch: 5| Step: 4
Training loss: 2.6091270100509933
Validation loss: 2.4758221411273853

Epoch: 5| Step: 5
Training loss: 2.9419453849987476
Validation loss: 2.4717131869475852

Epoch: 5| Step: 6
Training loss: 3.0726831034891595
Validation loss: 2.474384881354855

Epoch: 5| Step: 7
Training loss: 2.9262033318501732
Validation loss: 2.482085988776722

Epoch: 5| Step: 8
Training loss: 2.9588701182045503
Validation loss: 2.4952763528842428

Epoch: 5| Step: 9
Training loss: 2.588723148812698
Validation loss: 2.49903442030069

Epoch: 5| Step: 10
Training loss: 2.5837130011210347
Validation loss: 2.5041774866297857

Epoch: 171| Step: 0
Training loss: 3.156963909727087
Validation loss: 2.4998250387352696

Epoch: 5| Step: 1
Training loss: 2.2089552333538647
Validation loss: 2.4959435152068226

Epoch: 5| Step: 2
Training loss: 3.1845800451687367
Validation loss: 2.4978432642950334

Epoch: 5| Step: 3
Training loss: 2.789633299817152
Validation loss: 2.5074607631333174

Epoch: 5| Step: 4
Training loss: 2.5149059334183597
Validation loss: 2.509741195496612

Epoch: 5| Step: 5
Training loss: 2.8986972579336143
Validation loss: 2.510967006584385

Epoch: 5| Step: 6
Training loss: 3.0164837973229224
Validation loss: 2.5108424764109842

Epoch: 5| Step: 7
Training loss: 2.9908935298762582
Validation loss: 2.538520762010627

Epoch: 5| Step: 8
Training loss: 2.768197108191063
Validation loss: 2.5410435513071636

Epoch: 5| Step: 9
Training loss: 2.3760578409726185
Validation loss: 2.5410283472466357

Epoch: 5| Step: 10
Training loss: 2.6210963878817295
Validation loss: 2.54705264963362

Epoch: 172| Step: 0
Training loss: 3.132669421802886
Validation loss: 2.5367979976283426

Epoch: 5| Step: 1
Training loss: 2.719205007077237
Validation loss: 2.4980872461248316

Epoch: 5| Step: 2
Training loss: 2.848981133090232
Validation loss: 2.4899842384881627

Epoch: 5| Step: 3
Training loss: 3.0729450461591186
Validation loss: 2.4861494524911287

Epoch: 5| Step: 4
Training loss: 2.745732029930814
Validation loss: 2.4796177477921164

Epoch: 5| Step: 5
Training loss: 2.2643790140308555
Validation loss: 2.4762799781273888

Epoch: 5| Step: 6
Training loss: 2.791909354369797
Validation loss: 2.4661003505613888

Epoch: 5| Step: 7
Training loss: 3.1371393551187774
Validation loss: 2.466638775789487

Epoch: 5| Step: 8
Training loss: 2.5258424241185455
Validation loss: 2.4789123277156713

Epoch: 5| Step: 9
Training loss: 2.869730723172986
Validation loss: 2.4744601337386056

Epoch: 5| Step: 10
Training loss: 2.3561194993365273
Validation loss: 2.472627402013894

Epoch: 173| Step: 0
Training loss: 3.038500422495426
Validation loss: 2.497136229321527

Epoch: 5| Step: 1
Training loss: 2.6110096454069645
Validation loss: 2.5173575706772926

Epoch: 5| Step: 2
Training loss: 2.0637016263915178
Validation loss: 2.54048812334636

Epoch: 5| Step: 3
Training loss: 3.1742834709417562
Validation loss: 2.564858399523134

Epoch: 5| Step: 4
Training loss: 2.779936834070537
Validation loss: 2.5974742888897686

Epoch: 5| Step: 5
Training loss: 2.8160748121391763
Validation loss: 2.551175843940636

Epoch: 5| Step: 6
Training loss: 2.4847295736004273
Validation loss: 2.5206236437241247

Epoch: 5| Step: 7
Training loss: 3.0223770055995747
Validation loss: 2.49971884920602

Epoch: 5| Step: 8
Training loss: 2.8408097378090393
Validation loss: 2.4790668220989214

Epoch: 5| Step: 9
Training loss: 2.961121404970689
Validation loss: 2.459938540619274

Epoch: 5| Step: 10
Training loss: 2.811467553418421
Validation loss: 2.465115001049021

Epoch: 174| Step: 0
Training loss: 2.751623021531931
Validation loss: 2.4714145655397015

Epoch: 5| Step: 1
Training loss: 3.19984737270673
Validation loss: 2.478743404747246

Epoch: 5| Step: 2
Training loss: 2.799629857938578
Validation loss: 2.4731357813655466

Epoch: 5| Step: 3
Training loss: 2.916453344627539
Validation loss: 2.468942849895552

Epoch: 5| Step: 4
Training loss: 2.5692316350931037
Validation loss: 2.464914288420014

Epoch: 5| Step: 5
Training loss: 2.8520644490796663
Validation loss: 2.477356621609883

Epoch: 5| Step: 6
Training loss: 2.539831802025592
Validation loss: 2.5035431723596493

Epoch: 5| Step: 7
Training loss: 2.9528945752219955
Validation loss: 2.55754393534254

Epoch: 5| Step: 8
Training loss: 3.0684359885108208
Validation loss: 2.5989262179000487

Epoch: 5| Step: 9
Training loss: 2.4886773241851934
Validation loss: 2.576991929362777

Epoch: 5| Step: 10
Training loss: 2.7664745340697157
Validation loss: 2.5919508522572463

Epoch: 175| Step: 0
Training loss: 3.140146399322759
Validation loss: 2.5195113658001156

Epoch: 5| Step: 1
Training loss: 2.2786649924789777
Validation loss: 2.483814316830548

Epoch: 5| Step: 2
Training loss: 3.148218189864879
Validation loss: 2.463457888457984

Epoch: 5| Step: 3
Training loss: 2.7141647258123434
Validation loss: 2.4607156393425336

Epoch: 5| Step: 4
Training loss: 2.980783108473057
Validation loss: 2.4661812295335745

Epoch: 5| Step: 5
Training loss: 2.7796088530815175
Validation loss: 2.467326459829147

Epoch: 5| Step: 6
Training loss: 2.7063148508384787
Validation loss: 2.4714233261858976

Epoch: 5| Step: 7
Training loss: 2.6138813145260102
Validation loss: 2.469647587173459

Epoch: 5| Step: 8
Training loss: 2.5999283340554062
Validation loss: 2.471787059829207

Epoch: 5| Step: 9
Training loss: 3.126634856782756
Validation loss: 2.4781856924460013

Epoch: 5| Step: 10
Training loss: 2.7695630156466815
Validation loss: 2.486248171572778

Epoch: 176| Step: 0
Training loss: 2.4847160441155554
Validation loss: 2.5064229442013057

Epoch: 5| Step: 1
Training loss: 2.9565293807104145
Validation loss: 2.5335792986234003

Epoch: 5| Step: 2
Training loss: 2.412996025679754
Validation loss: 2.5642645198364855

Epoch: 5| Step: 3
Training loss: 3.1797276899717444
Validation loss: 2.593417204999442

Epoch: 5| Step: 4
Training loss: 2.9801205972936837
Validation loss: 2.5727984639682893

Epoch: 5| Step: 5
Training loss: 3.1570140555899306
Validation loss: 2.542266679731477

Epoch: 5| Step: 6
Training loss: 2.346858290449003
Validation loss: 2.513252894271787

Epoch: 5| Step: 7
Training loss: 2.582994890090549
Validation loss: 2.491028507885046

Epoch: 5| Step: 8
Training loss: 3.3353173709141504
Validation loss: 2.479082163150165

Epoch: 5| Step: 9
Training loss: 2.2925322082985935
Validation loss: 2.4743309951868233

Epoch: 5| Step: 10
Training loss: 2.8269058887751637
Validation loss: 2.470946424590643

Epoch: 177| Step: 0
Training loss: 2.8914293974202643
Validation loss: 2.477188981908058

Epoch: 5| Step: 1
Training loss: 3.128948616188675
Validation loss: 2.4807236567357545

Epoch: 5| Step: 2
Training loss: 2.5711805738720552
Validation loss: 2.4767208693763427

Epoch: 5| Step: 3
Training loss: 2.616178130043456
Validation loss: 2.481665430461696

Epoch: 5| Step: 4
Training loss: 2.54599236482253
Validation loss: 2.501054965742291

Epoch: 5| Step: 5
Training loss: 2.9008833033257577
Validation loss: 2.520240411578777

Epoch: 5| Step: 6
Training loss: 2.666485889585604
Validation loss: 2.532715388825312

Epoch: 5| Step: 7
Training loss: 2.899990436932811
Validation loss: 2.548280523517768

Epoch: 5| Step: 8
Training loss: 2.9360295937525263
Validation loss: 2.525037846199884

Epoch: 5| Step: 9
Training loss: 2.962939227415312
Validation loss: 2.521221184612612

Epoch: 5| Step: 10
Training loss: 2.881853145598403
Validation loss: 2.5017658109185454

Epoch: 178| Step: 0
Training loss: 2.7123538667894613
Validation loss: 2.477966567908206

Epoch: 5| Step: 1
Training loss: 3.2951107276291074
Validation loss: 2.463819014207593

Epoch: 5| Step: 2
Training loss: 2.8436584457918364
Validation loss: 2.4543375801842005

Epoch: 5| Step: 3
Training loss: 2.3351968975492166
Validation loss: 2.4515321287805314

Epoch: 5| Step: 4
Training loss: 2.669834272263228
Validation loss: 2.4601180559265496

Epoch: 5| Step: 5
Training loss: 3.1629160369911284
Validation loss: 2.4778367305994298

Epoch: 5| Step: 6
Training loss: 2.5444498509993254
Validation loss: 2.4670678250563505

Epoch: 5| Step: 7
Training loss: 2.89891356802474
Validation loss: 2.498376916248844

Epoch: 5| Step: 8
Training loss: 2.991681805698977
Validation loss: 2.497531402198973

Epoch: 5| Step: 9
Training loss: 2.251011091451548
Validation loss: 2.522603209361739

Epoch: 5| Step: 10
Training loss: 2.976105261899724
Validation loss: 2.5613880120811525

Epoch: 179| Step: 0
Training loss: 2.6626505312207067
Validation loss: 2.5839247514486328

Epoch: 5| Step: 1
Training loss: 2.8013677900641216
Validation loss: 2.6028558295849127

Epoch: 5| Step: 2
Training loss: 3.1649980833701647
Validation loss: 2.644942650073894

Epoch: 5| Step: 3
Training loss: 3.0633942213292493
Validation loss: 2.5929503687757793

Epoch: 5| Step: 4
Training loss: 2.9830559017251725
Validation loss: 2.5262685515077603

Epoch: 5| Step: 5
Training loss: 2.4602603041157187
Validation loss: 2.4873265504050313

Epoch: 5| Step: 6
Training loss: 2.725641745498606
Validation loss: 2.4632911210448913

Epoch: 5| Step: 7
Training loss: 3.1801447059287997
Validation loss: 2.4500367384318524

Epoch: 5| Step: 8
Training loss: 2.157228330833363
Validation loss: 2.447163859388016

Epoch: 5| Step: 9
Training loss: 2.7213487153553855
Validation loss: 2.4506714229617703

Epoch: 5| Step: 10
Training loss: 2.69852704737285
Validation loss: 2.4642531402083536

Epoch: 180| Step: 0
Training loss: 2.8243788044636498
Validation loss: 2.4692148134757828

Epoch: 5| Step: 1
Training loss: 2.686835894480876
Validation loss: 2.501675122501522

Epoch: 5| Step: 2
Training loss: 2.6908364101032785
Validation loss: 2.5218498070850135

Epoch: 5| Step: 3
Training loss: 2.239951051790307
Validation loss: 2.5341542677543254

Epoch: 5| Step: 4
Training loss: 2.888823406585885
Validation loss: 2.583894597853498

Epoch: 5| Step: 5
Training loss: 2.813818474185953
Validation loss: 2.609030275574392

Epoch: 5| Step: 6
Training loss: 3.0659081315661783
Validation loss: 2.647631286153474

Epoch: 5| Step: 7
Training loss: 3.0458846610180594
Validation loss: 2.629736470177601

Epoch: 5| Step: 8
Training loss: 2.6180201785808572
Validation loss: 2.550552013888052

Epoch: 5| Step: 9
Training loss: 3.3033316064926956
Validation loss: 2.493717942273514

Epoch: 5| Step: 10
Training loss: 2.339018763844875
Validation loss: 2.4740100726085896

Epoch: 181| Step: 0
Training loss: 3.313687957217399
Validation loss: 2.4964063246719554

Epoch: 5| Step: 1
Training loss: 2.6437824941671817
Validation loss: 2.532223839127171

Epoch: 5| Step: 2
Training loss: 2.959824002936143
Validation loss: 2.5774999035358954

Epoch: 5| Step: 3
Training loss: 2.833748469139867
Validation loss: 2.633448249450737

Epoch: 5| Step: 4
Training loss: 3.578614713647977
Validation loss: 2.6261876140123457

Epoch: 5| Step: 5
Training loss: 2.52870728679643
Validation loss: 2.619667032806889

Epoch: 5| Step: 6
Training loss: 3.0401817947540257
Validation loss: 2.618322853911585

Epoch: 5| Step: 7
Training loss: 2.6976539945441087
Validation loss: 2.650159089383666

Epoch: 5| Step: 8
Training loss: 3.044011261867789
Validation loss: 2.691828748869078

Epoch: 5| Step: 9
Training loss: 3.0417791546091966
Validation loss: 2.6743903619188303

Epoch: 5| Step: 10
Training loss: 2.4829787643391024
Validation loss: 2.654059169783894

Epoch: 182| Step: 0
Training loss: 3.004114825841519
Validation loss: 2.6469173663703414

Epoch: 5| Step: 1
Training loss: 3.1271771285806738
Validation loss: 2.6430022826032715

Epoch: 5| Step: 2
Training loss: 2.597830997411741
Validation loss: 2.6365891308449756

Epoch: 5| Step: 3
Training loss: 1.8014397399843949
Validation loss: 2.6548915412610214

Epoch: 5| Step: 4
Training loss: 2.857677184958549
Validation loss: 2.6593496479591914

Epoch: 5| Step: 5
Training loss: 3.053069718015618
Validation loss: 2.643384752110057

Epoch: 5| Step: 6
Training loss: 2.9894683674007894
Validation loss: 2.6123312825246567

Epoch: 5| Step: 7
Training loss: 2.854671925469368
Validation loss: 2.5651106912669333

Epoch: 5| Step: 8
Training loss: 2.8509420477611225
Validation loss: 2.557051564131883

Epoch: 5| Step: 9
Training loss: 2.884377486371491
Validation loss: 2.5324016540392935

Epoch: 5| Step: 10
Training loss: 3.0354534774429838
Validation loss: 2.5252026240970435

Epoch: 183| Step: 0
Training loss: 2.725551297477834
Validation loss: 2.5123498562290467

Epoch: 5| Step: 1
Training loss: 2.742259315354572
Validation loss: 2.502224159428975

Epoch: 5| Step: 2
Training loss: 2.653500738597743
Validation loss: 2.496917423866007

Epoch: 5| Step: 3
Training loss: 2.762589939086021
Validation loss: 2.507591448657772

Epoch: 5| Step: 4
Training loss: 2.5456175713228197
Validation loss: 2.4980193711336995

Epoch: 5| Step: 5
Training loss: 2.656052346449075
Validation loss: 2.5262744109180177

Epoch: 5| Step: 6
Training loss: 3.3073967543999956
Validation loss: 2.5514093496448687

Epoch: 5| Step: 7
Training loss: 2.907616570875531
Validation loss: 2.565618611696853

Epoch: 5| Step: 8
Training loss: 2.819292724193634
Validation loss: 2.523183759268456

Epoch: 5| Step: 9
Training loss: 2.9437271020083764
Validation loss: 2.524238347847177

Epoch: 5| Step: 10
Training loss: 2.8220333861789695
Validation loss: 2.5202072153808635

Epoch: 184| Step: 0
Training loss: 2.404327417175018
Validation loss: 2.5319172536641625

Epoch: 5| Step: 1
Training loss: 2.608630502447044
Validation loss: 2.5287371191320074

Epoch: 5| Step: 2
Training loss: 2.811369944414194
Validation loss: 2.5402224522767822

Epoch: 5| Step: 3
Training loss: 2.687865032866421
Validation loss: 2.5583639843778636

Epoch: 5| Step: 4
Training loss: 3.3560419625533506
Validation loss: 2.5701847851960347

Epoch: 5| Step: 5
Training loss: 2.4592949123502583
Validation loss: 2.5595655669610586

Epoch: 5| Step: 6
Training loss: 3.100449523327884
Validation loss: 2.5381964567881514

Epoch: 5| Step: 7
Training loss: 2.4207404647934037
Validation loss: 2.5277978815235413

Epoch: 5| Step: 8
Training loss: 3.1257149450720356
Validation loss: 2.5379823841757907

Epoch: 5| Step: 9
Training loss: 2.4892567589309755
Validation loss: 2.5025806971175286

Epoch: 5| Step: 10
Training loss: 2.989580019285556
Validation loss: 2.500143566931489

Epoch: 185| Step: 0
Training loss: 3.1802823496773733
Validation loss: 2.4981032826351126

Epoch: 5| Step: 1
Training loss: 2.77583540292703
Validation loss: 2.484699691633657

Epoch: 5| Step: 2
Training loss: 2.0743762170248434
Validation loss: 2.4847450385791157

Epoch: 5| Step: 3
Training loss: 3.2509567613076005
Validation loss: 2.4768327502350433

Epoch: 5| Step: 4
Training loss: 2.9106926545284675
Validation loss: 2.4830810846838522

Epoch: 5| Step: 5
Training loss: 2.7402241952044966
Validation loss: 2.4808779944023605

Epoch: 5| Step: 6
Training loss: 2.7505180564499883
Validation loss: 2.484760506556788

Epoch: 5| Step: 7
Training loss: 2.729789420170153
Validation loss: 2.486768318253302

Epoch: 5| Step: 8
Training loss: 2.648821597533572
Validation loss: 2.50183677673386

Epoch: 5| Step: 9
Training loss: 2.8792522331216546
Validation loss: 2.527568080329209

Epoch: 5| Step: 10
Training loss: 2.6361369981779856
Validation loss: 2.536158673356136

Epoch: 186| Step: 0
Training loss: 2.432651980475541
Validation loss: 2.523554236001782

Epoch: 5| Step: 1
Training loss: 2.7125083923210016
Validation loss: 2.515427006031825

Epoch: 5| Step: 2
Training loss: 2.7762525429471396
Validation loss: 2.5197050250420423

Epoch: 5| Step: 3
Training loss: 2.773661515765853
Validation loss: 2.5165186966938538

Epoch: 5| Step: 4
Training loss: 3.056568863973924
Validation loss: 2.5134007031589554

Epoch: 5| Step: 5
Training loss: 2.420231415268918
Validation loss: 2.503384080965643

Epoch: 5| Step: 6
Training loss: 2.512412727320562
Validation loss: 2.4799153917436896

Epoch: 5| Step: 7
Training loss: 3.010445212962532
Validation loss: 2.4628886670527392

Epoch: 5| Step: 8
Training loss: 2.7941664895196894
Validation loss: 2.4752679937033224

Epoch: 5| Step: 9
Training loss: 3.067140605488351
Validation loss: 2.464959683700003

Epoch: 5| Step: 10
Training loss: 2.7480899072679073
Validation loss: 2.4628991749970703

Epoch: 187| Step: 0
Training loss: 2.4531924487517878
Validation loss: 2.4617999405421807

Epoch: 5| Step: 1
Training loss: 2.78867745613323
Validation loss: 2.448285960502522

Epoch: 5| Step: 2
Training loss: 2.748775816584111
Validation loss: 2.452637941180111

Epoch: 5| Step: 3
Training loss: 2.9451148171702775
Validation loss: 2.4466225712916088

Epoch: 5| Step: 4
Training loss: 2.5755167396340592
Validation loss: 2.462169403859753

Epoch: 5| Step: 5
Training loss: 2.4098367092799187
Validation loss: 2.4675504979960956

Epoch: 5| Step: 6
Training loss: 2.7051907622645945
Validation loss: 2.481939737038381

Epoch: 5| Step: 7
Training loss: 3.3060467316820294
Validation loss: 2.4804269712361506

Epoch: 5| Step: 8
Training loss: 2.882392832078155
Validation loss: 2.488422636213452

Epoch: 5| Step: 9
Training loss: 2.5225089523111204
Validation loss: 2.4954293543905135

Epoch: 5| Step: 10
Training loss: 2.989621329426082
Validation loss: 2.4967660213819873

Epoch: 188| Step: 0
Training loss: 2.682279706514724
Validation loss: 2.4933918525133025

Epoch: 5| Step: 1
Training loss: 2.7874465663561208
Validation loss: 2.4931130619458526

Epoch: 5| Step: 2
Training loss: 2.816367393786444
Validation loss: 2.4920820656939253

Epoch: 5| Step: 3
Training loss: 2.6898833950820586
Validation loss: 2.502529807541472

Epoch: 5| Step: 4
Training loss: 2.510706102667568
Validation loss: 2.482285499868901

Epoch: 5| Step: 5
Training loss: 2.7885815288519358
Validation loss: 2.4676558849332353

Epoch: 5| Step: 6
Training loss: 3.076413215979229
Validation loss: 2.4677094353440445

Epoch: 5| Step: 7
Training loss: 2.8821749512027925
Validation loss: 2.467112876766642

Epoch: 5| Step: 8
Training loss: 2.697151772805319
Validation loss: 2.473706216622039

Epoch: 5| Step: 9
Training loss: 2.537173463453925
Validation loss: 2.4617756661253796

Epoch: 5| Step: 10
Training loss: 2.847735284825717
Validation loss: 2.4600835784572395

Epoch: 189| Step: 0
Training loss: 2.6048500893596755
Validation loss: 2.45225305202963

Epoch: 5| Step: 1
Training loss: 2.4729601536188808
Validation loss: 2.459895112537573

Epoch: 5| Step: 2
Training loss: 2.6673136363403036
Validation loss: 2.464285858422822

Epoch: 5| Step: 3
Training loss: 2.6712521725022333
Validation loss: 2.468823184819467

Epoch: 5| Step: 4
Training loss: 2.760748405436047
Validation loss: 2.4717961577869696

Epoch: 5| Step: 5
Training loss: 2.981632270536409
Validation loss: 2.4787139362008586

Epoch: 5| Step: 6
Training loss: 2.864850580869447
Validation loss: 2.4841285449690433

Epoch: 5| Step: 7
Training loss: 2.8599934560527496
Validation loss: 2.4765145074059154

Epoch: 5| Step: 8
Training loss: 2.5477390812776592
Validation loss: 2.4941661950743317

Epoch: 5| Step: 9
Training loss: 3.034050974649645
Validation loss: 2.498802203701363

Epoch: 5| Step: 10
Training loss: 2.7470756066925968
Validation loss: 2.496205900491643

Epoch: 190| Step: 0
Training loss: 2.817302926185444
Validation loss: 2.489682170937833

Epoch: 5| Step: 1
Training loss: 3.2957420391133323
Validation loss: 2.4766479386355655

Epoch: 5| Step: 2
Training loss: 2.8432925348906406
Validation loss: 2.4786004564007214

Epoch: 5| Step: 3
Training loss: 2.659457345980859
Validation loss: 2.4760103488465104

Epoch: 5| Step: 4
Training loss: 2.594883223094597
Validation loss: 2.467350594435739

Epoch: 5| Step: 5
Training loss: 2.406948731273021
Validation loss: 2.473440594644953

Epoch: 5| Step: 6
Training loss: 2.9329550463056715
Validation loss: 2.491991375156554

Epoch: 5| Step: 7
Training loss: 2.4197215689332707
Validation loss: 2.5043901228678638

Epoch: 5| Step: 8
Training loss: 2.994391603147131
Validation loss: 2.520550670215628

Epoch: 5| Step: 9
Training loss: 2.7149556308443814
Validation loss: 2.5393190608624097

Epoch: 5| Step: 10
Training loss: 2.534806943084324
Validation loss: 2.549782051232308

Epoch: 191| Step: 0
Training loss: 3.0936582917771864
Validation loss: 2.5668233541033665

Epoch: 5| Step: 1
Training loss: 2.6174024806761396
Validation loss: 2.5764811724761194

Epoch: 5| Step: 2
Training loss: 3.0152707855441854
Validation loss: 2.5941924641779655

Epoch: 5| Step: 3
Training loss: 2.873058492817265
Validation loss: 2.578143075809398

Epoch: 5| Step: 4
Training loss: 3.024859584355267
Validation loss: 2.5178743890398034

Epoch: 5| Step: 5
Training loss: 3.0486349647030972
Validation loss: 2.477916586083013

Epoch: 5| Step: 6
Training loss: 3.156513769628836
Validation loss: 2.4593803869255857

Epoch: 5| Step: 7
Training loss: 2.5919343039464025
Validation loss: 2.46172094106872

Epoch: 5| Step: 8
Training loss: 2.6707152588007785
Validation loss: 2.462126949110575

Epoch: 5| Step: 9
Training loss: 2.303763407990573
Validation loss: 2.463595769925016

Epoch: 5| Step: 10
Training loss: 1.8785468568702328
Validation loss: 2.463796292376819

Epoch: 192| Step: 0
Training loss: 3.1657466221122372
Validation loss: 2.464704250199199

Epoch: 5| Step: 1
Training loss: 3.147306101722076
Validation loss: 2.474630751275761

Epoch: 5| Step: 2
Training loss: 3.2432921216907205
Validation loss: 2.5016013328776205

Epoch: 5| Step: 3
Training loss: 2.570168256335613
Validation loss: 2.511100232436563

Epoch: 5| Step: 4
Training loss: 2.460507019175591
Validation loss: 2.543889884068541

Epoch: 5| Step: 5
Training loss: 2.602430685624542
Validation loss: 2.591710324119683

Epoch: 5| Step: 6
Training loss: 2.561280029925099
Validation loss: 2.62154133618496

Epoch: 5| Step: 7
Training loss: 2.6570072665389755
Validation loss: 2.6831135630456355

Epoch: 5| Step: 8
Training loss: 2.211416778916734
Validation loss: 2.674288378588172

Epoch: 5| Step: 9
Training loss: 3.027299489343787
Validation loss: 2.629726865292939

Epoch: 5| Step: 10
Training loss: 2.630443650599783
Validation loss: 2.569451296626382

Epoch: 193| Step: 0
Training loss: 2.0153209841433246
Validation loss: 2.5432500851053237

Epoch: 5| Step: 1
Training loss: 3.191878210349604
Validation loss: 2.527683960236892

Epoch: 5| Step: 2
Training loss: 2.9377530577397546
Validation loss: 2.518018302144696

Epoch: 5| Step: 3
Training loss: 2.7815693875493137
Validation loss: 2.5094880343935686

Epoch: 5| Step: 4
Training loss: 2.4082958887306605
Validation loss: 2.494094724224193

Epoch: 5| Step: 5
Training loss: 2.9621935271431092
Validation loss: 2.503904883151228

Epoch: 5| Step: 6
Training loss: 2.785078178691898
Validation loss: 2.5130582032742446

Epoch: 5| Step: 7
Training loss: 2.8004466858556376
Validation loss: 2.5112589743499725

Epoch: 5| Step: 8
Training loss: 2.8541747786877667
Validation loss: 2.484581458202477

Epoch: 5| Step: 9
Training loss: 2.7539782791998717
Validation loss: 2.4687034620200623

Epoch: 5| Step: 10
Training loss: 2.783978270621289
Validation loss: 2.4932875585321637

Epoch: 194| Step: 0
Training loss: 3.2559096087062858
Validation loss: 2.500121736126193

Epoch: 5| Step: 1
Training loss: 3.01644000963488
Validation loss: 2.527335488010666

Epoch: 5| Step: 2
Training loss: 2.842975720645738
Validation loss: 2.5615293243549355

Epoch: 5| Step: 3
Training loss: 2.2661697259016185
Validation loss: 2.5512475807316055

Epoch: 5| Step: 4
Training loss: 2.6543540920353
Validation loss: 2.5301653889110347

Epoch: 5| Step: 5
Training loss: 2.790464759318427
Validation loss: 2.533880678903714

Epoch: 5| Step: 6
Training loss: 2.8262753840052692
Validation loss: 2.516979538953662

Epoch: 5| Step: 7
Training loss: 2.986198786747079
Validation loss: 2.5200827313392056

Epoch: 5| Step: 8
Training loss: 2.468834984197854
Validation loss: 2.520990008010344

Epoch: 5| Step: 9
Training loss: 2.7708397102760607
Validation loss: 2.539016775219615

Epoch: 5| Step: 10
Training loss: 1.9391154660868601
Validation loss: 2.499814874706348

Epoch: 195| Step: 0
Training loss: 2.742382770769532
Validation loss: 2.49015769729455

Epoch: 5| Step: 1
Training loss: 2.8994870817472593
Validation loss: 2.486739553565337

Epoch: 5| Step: 2
Training loss: 2.6051217324191698
Validation loss: 2.473045204611375

Epoch: 5| Step: 3
Training loss: 3.213154493818724
Validation loss: 2.475434320343255

Epoch: 5| Step: 4
Training loss: 2.7141532184414845
Validation loss: 2.4681245876927

Epoch: 5| Step: 5
Training loss: 2.7570975352161677
Validation loss: 2.502269102730071

Epoch: 5| Step: 6
Training loss: 2.993138095064765
Validation loss: 2.506415044884922

Epoch: 5| Step: 7
Training loss: 2.7867258579258682
Validation loss: 2.521490728467944

Epoch: 5| Step: 8
Training loss: 2.2879534954533445
Validation loss: 2.524462480898497

Epoch: 5| Step: 9
Training loss: 2.8422928315075247
Validation loss: 2.5135289135044734

Epoch: 5| Step: 10
Training loss: 1.9407055701393998
Validation loss: 2.5041052030060658

Epoch: 196| Step: 0
Training loss: 2.9051326121331518
Validation loss: 2.4932262451989966

Epoch: 5| Step: 1
Training loss: 2.4733375707454663
Validation loss: 2.4670786622733876

Epoch: 5| Step: 2
Training loss: 3.3365255011829213
Validation loss: 2.466937284236267

Epoch: 5| Step: 3
Training loss: 2.84034508395069
Validation loss: 2.4525309900898553

Epoch: 5| Step: 4
Training loss: 2.6724622649909002
Validation loss: 2.4547635880037926

Epoch: 5| Step: 5
Training loss: 2.7757464186858223
Validation loss: 2.4544655929229173

Epoch: 5| Step: 6
Training loss: 2.5211073566231534
Validation loss: 2.461643138793085

Epoch: 5| Step: 7
Training loss: 2.6295823564095926
Validation loss: 2.4680810855209656

Epoch: 5| Step: 8
Training loss: 2.4802303650214066
Validation loss: 2.4857671717875394

Epoch: 5| Step: 9
Training loss: 2.8319253415002916
Validation loss: 2.4986269677237263

Epoch: 5| Step: 10
Training loss: 2.2793539868728474
Validation loss: 2.4986379266167233

Epoch: 197| Step: 0
Training loss: 2.578472137200031
Validation loss: 2.5043465699078387

Epoch: 5| Step: 1
Training loss: 2.465193492421665
Validation loss: 2.518598368328981

Epoch: 5| Step: 2
Training loss: 2.1683637379482317
Validation loss: 2.5368749128161574

Epoch: 5| Step: 3
Training loss: 3.16707680371851
Validation loss: 2.5459581379741767

Epoch: 5| Step: 4
Training loss: 2.7812988619852015
Validation loss: 2.543011409630485

Epoch: 5| Step: 5
Training loss: 2.755492966677723
Validation loss: 2.510010958964148

Epoch: 5| Step: 6
Training loss: 3.124986267059669
Validation loss: 2.4914623049795366

Epoch: 5| Step: 7
Training loss: 2.5756661451571308
Validation loss: 2.4880939184595565

Epoch: 5| Step: 8
Training loss: 2.817508391915308
Validation loss: 2.4772882464055153

Epoch: 5| Step: 9
Training loss: 2.451681599298155
Validation loss: 2.4735600954173003

Epoch: 5| Step: 10
Training loss: 2.9734206551472084
Validation loss: 2.4935875844812365

Epoch: 198| Step: 0
Training loss: 2.898099565984639
Validation loss: 2.5075918688443273

Epoch: 5| Step: 1
Training loss: 3.193323238996613
Validation loss: 2.5150433000725196

Epoch: 5| Step: 2
Training loss: 2.7730666221542104
Validation loss: 2.5291655016940333

Epoch: 5| Step: 3
Training loss: 2.110786700280156
Validation loss: 2.527127344930595

Epoch: 5| Step: 4
Training loss: 2.4022390451331352
Validation loss: 2.552959472730332

Epoch: 5| Step: 5
Training loss: 2.6489814492278483
Validation loss: 2.5271091172535622

Epoch: 5| Step: 6
Training loss: 3.0380493671959203
Validation loss: 2.527165581235552

Epoch: 5| Step: 7
Training loss: 2.8376279894493477
Validation loss: 2.499779336686587

Epoch: 5| Step: 8
Training loss: 2.9664783017940057
Validation loss: 2.497916665120357

Epoch: 5| Step: 9
Training loss: 2.5264518378563183
Validation loss: 2.5008348434895336

Epoch: 5| Step: 10
Training loss: 2.192668802685778
Validation loss: 2.501469037968652

Epoch: 199| Step: 0
Training loss: 2.7995722035170085
Validation loss: 2.4998270364630644

Epoch: 5| Step: 1
Training loss: 2.5950404254800135
Validation loss: 2.501267686016439

Epoch: 5| Step: 2
Training loss: 2.710917272134999
Validation loss: 2.5037966888166814

Epoch: 5| Step: 3
Training loss: 3.0371348094795114
Validation loss: 2.5164334483377413

Epoch: 5| Step: 4
Training loss: 2.479100896994071
Validation loss: 2.537540102438266

Epoch: 5| Step: 5
Training loss: 2.3275725458068224
Validation loss: 2.5432351936189503

Epoch: 5| Step: 6
Training loss: 3.2841666201791773
Validation loss: 2.5701043532511707

Epoch: 5| Step: 7
Training loss: 2.370549499291012
Validation loss: 2.566457664019822

Epoch: 5| Step: 8
Training loss: 2.994979153721372
Validation loss: 2.5396487161477497

Epoch: 5| Step: 9
Training loss: 2.8581410231183884
Validation loss: 2.510017351687752

Epoch: 5| Step: 10
Training loss: 2.294113887018543
Validation loss: 2.50644315111824

Epoch: 200| Step: 0
Training loss: 2.354858116848716
Validation loss: 2.5029418095398643

Epoch: 5| Step: 1
Training loss: 3.140692107589162
Validation loss: 2.505922738347731

Epoch: 5| Step: 2
Training loss: 2.7170701372839843
Validation loss: 2.506220349501177

Epoch: 5| Step: 3
Training loss: 2.8292264532215157
Validation loss: 2.518942380419503

Epoch: 5| Step: 4
Training loss: 2.712950560949238
Validation loss: 2.505839569532987

Epoch: 5| Step: 5
Training loss: 2.8110374886677185
Validation loss: 2.5170177430253813

Epoch: 5| Step: 6
Training loss: 2.7070335399183136
Validation loss: 2.537338393899894

Epoch: 5| Step: 7
Training loss: 2.481234310686681
Validation loss: 2.5248351083980514

Epoch: 5| Step: 8
Training loss: 2.52166799383471
Validation loss: 2.5583751122578358

Epoch: 5| Step: 9
Training loss: 2.4489492849174432
Validation loss: 2.5135709172107243

Epoch: 5| Step: 10
Training loss: 2.8804268412054177
Validation loss: 2.464909867152237

Epoch: 201| Step: 0
Training loss: 2.6272776576953185
Validation loss: 2.4571363113389753

Epoch: 5| Step: 1
Training loss: 2.6226438211255054
Validation loss: 2.4572014438893794

Epoch: 5| Step: 2
Training loss: 3.0001560806362577
Validation loss: 2.4482331758376628

Epoch: 5| Step: 3
Training loss: 2.689021190124299
Validation loss: 2.455294450615558

Epoch: 5| Step: 4
Training loss: 2.3228390485400325
Validation loss: 2.473901440797955

Epoch: 5| Step: 5
Training loss: 2.5209528261557934
Validation loss: 2.4727228591123187

Epoch: 5| Step: 6
Training loss: 3.0458322158860134
Validation loss: 2.478765477097665

Epoch: 5| Step: 7
Training loss: 2.824873936633905
Validation loss: 2.4715792963812513

Epoch: 5| Step: 8
Training loss: 2.5259182195223757
Validation loss: 2.46626184494284

Epoch: 5| Step: 9
Training loss: 3.062375124506833
Validation loss: 2.47079486409907

Epoch: 5| Step: 10
Training loss: 2.557684770399806
Validation loss: 2.484864332039174

Epoch: 202| Step: 0
Training loss: 2.6057147091552086
Validation loss: 2.511160031283576

Epoch: 5| Step: 1
Training loss: 2.446374437132982
Validation loss: 2.57546652575883

Epoch: 5| Step: 2
Training loss: 3.071379265120145
Validation loss: 2.608967269335016

Epoch: 5| Step: 3
Training loss: 2.348773100345007
Validation loss: 2.5727949455344126

Epoch: 5| Step: 4
Training loss: 2.8030363445232496
Validation loss: 2.5169247725597064

Epoch: 5| Step: 5
Training loss: 2.765886887042133
Validation loss: 2.4757143426839043

Epoch: 5| Step: 6
Training loss: 2.994694946496354
Validation loss: 2.452910476144685

Epoch: 5| Step: 7
Training loss: 2.7699618199881195
Validation loss: 2.440905459390643

Epoch: 5| Step: 8
Training loss: 2.569060324976652
Validation loss: 2.439131191741825

Epoch: 5| Step: 9
Training loss: 2.7962629618235586
Validation loss: 2.4403982209975807

Epoch: 5| Step: 10
Training loss: 2.7248161428879425
Validation loss: 2.4310831208960595

Epoch: 203| Step: 0
Training loss: 2.820563561421035
Validation loss: 2.44628229469223

Epoch: 5| Step: 1
Training loss: 3.440315064928164
Validation loss: 2.4573337642525592

Epoch: 5| Step: 2
Training loss: 1.7973412613684427
Validation loss: 2.4488054793560106

Epoch: 5| Step: 3
Training loss: 2.256757126558258
Validation loss: 2.4662705277404826

Epoch: 5| Step: 4
Training loss: 2.9082221446238368
Validation loss: 2.4793792189530888

Epoch: 5| Step: 5
Training loss: 2.1224835024710367
Validation loss: 2.4669280187138005

Epoch: 5| Step: 6
Training loss: 2.7147402956345013
Validation loss: 2.5036052529148742

Epoch: 5| Step: 7
Training loss: 2.433762839919724
Validation loss: 2.4873772676469037

Epoch: 5| Step: 8
Training loss: 2.7491421662027404
Validation loss: 2.530972633575041

Epoch: 5| Step: 9
Training loss: 2.84597406295356
Validation loss: 2.55776076883334

Epoch: 5| Step: 10
Training loss: 3.144048694049085
Validation loss: 2.5707785218230526

Epoch: 204| Step: 0
Training loss: 2.8739857750569144
Validation loss: 2.5876645752834806

Epoch: 5| Step: 1
Training loss: 2.623077142445671
Validation loss: 2.5312685968973536

Epoch: 5| Step: 2
Training loss: 2.418524313163512
Validation loss: 2.4965989523078793

Epoch: 5| Step: 3
Training loss: 3.2850350483457347
Validation loss: 2.505842966111621

Epoch: 5| Step: 4
Training loss: 3.1667619657398074
Validation loss: 2.5142026097884598

Epoch: 5| Step: 5
Training loss: 2.4842759598478055
Validation loss: 2.5218115582923515

Epoch: 5| Step: 6
Training loss: 2.999894776088411
Validation loss: 2.538515479241891

Epoch: 5| Step: 7
Training loss: 2.4091411907582456
Validation loss: 2.5462298788824302

Epoch: 5| Step: 8
Training loss: 2.2136772084344387
Validation loss: 2.5572137904533006

Epoch: 5| Step: 9
Training loss: 2.7440611261004437
Validation loss: 2.5618561006483387

Epoch: 5| Step: 10
Training loss: 2.6375930805866443
Validation loss: 2.5865170202120438

Epoch: 205| Step: 0
Training loss: 2.3549834553325715
Validation loss: 2.600714003705343

Epoch: 5| Step: 1
Training loss: 2.753441651024794
Validation loss: 2.608781090326032

Epoch: 5| Step: 2
Training loss: 2.61651065102131
Validation loss: 2.63250860368428

Epoch: 5| Step: 3
Training loss: 2.5083417957792604
Validation loss: 2.6275341119276265

Epoch: 5| Step: 4
Training loss: 2.6877851113186977
Validation loss: 2.631495125765472

Epoch: 5| Step: 5
Training loss: 2.892614721134973
Validation loss: 2.574895542079746

Epoch: 5| Step: 6
Training loss: 3.085716992962371
Validation loss: 2.514222363651864

Epoch: 5| Step: 7
Training loss: 2.7753877042450323
Validation loss: 2.4580449838470275

Epoch: 5| Step: 8
Training loss: 2.4830016172774814
Validation loss: 2.4520820839387216

Epoch: 5| Step: 9
Training loss: 2.8103173157531818
Validation loss: 2.4473762509136567

Epoch: 5| Step: 10
Training loss: 2.8552022201619236
Validation loss: 2.455483487856124

Epoch: 206| Step: 0
Training loss: 3.02640200826007
Validation loss: 2.4559488768585642

Epoch: 5| Step: 1
Training loss: 2.11457252186484
Validation loss: 2.444747371476702

Epoch: 5| Step: 2
Training loss: 2.4460701545642154
Validation loss: 2.441800250675636

Epoch: 5| Step: 3
Training loss: 3.004174030804614
Validation loss: 2.4529032960061867

Epoch: 5| Step: 4
Training loss: 2.9562338959656507
Validation loss: 2.463004396654146

Epoch: 5| Step: 5
Training loss: 2.6485465148274883
Validation loss: 2.49661081551477

Epoch: 5| Step: 6
Training loss: 3.087742994375731
Validation loss: 2.5552118536030872

Epoch: 5| Step: 7
Training loss: 2.70055509795054
Validation loss: 2.599116514620477

Epoch: 5| Step: 8
Training loss: 2.5797362869982123
Validation loss: 2.6055164807847637

Epoch: 5| Step: 9
Training loss: 2.5476263143353455
Validation loss: 2.5993583792674713

Epoch: 5| Step: 10
Training loss: 2.6280089798400836
Validation loss: 2.5833080636520918

Epoch: 207| Step: 0
Training loss: 2.6449403432309184
Validation loss: 2.5535471036907444

Epoch: 5| Step: 1
Training loss: 2.675488443434153
Validation loss: 2.5476759569577996

Epoch: 5| Step: 2
Training loss: 2.5343736754389266
Validation loss: 2.5327154596800328

Epoch: 5| Step: 3
Training loss: 3.1197590940342765
Validation loss: 2.517832404180102

Epoch: 5| Step: 4
Training loss: 2.4776418361616233
Validation loss: 2.4811629932486015

Epoch: 5| Step: 5
Training loss: 2.2175079952814065
Validation loss: 2.482767939314341

Epoch: 5| Step: 6
Training loss: 2.5850386887095604
Validation loss: 2.4745176395281376

Epoch: 5| Step: 7
Training loss: 2.3242568069035006
Validation loss: 2.4724657085448785

Epoch: 5| Step: 8
Training loss: 3.029180075621453
Validation loss: 2.475359813737

Epoch: 5| Step: 9
Training loss: 2.676718265167543
Validation loss: 2.477381384945634

Epoch: 5| Step: 10
Training loss: 3.1357473577114026
Validation loss: 2.470538907501377

Epoch: 208| Step: 0
Training loss: 3.1524632465540376
Validation loss: 2.489560361462636

Epoch: 5| Step: 1
Training loss: 2.9631979977141634
Validation loss: 2.487159692987412

Epoch: 5| Step: 2
Training loss: 2.5501241728524815
Validation loss: 2.4811417683104064

Epoch: 5| Step: 3
Training loss: 2.7427475403560924
Validation loss: 2.5166122709623275

Epoch: 5| Step: 4
Training loss: 2.5371244105597586
Validation loss: 2.53512287495557

Epoch: 5| Step: 5
Training loss: 2.1888429061892163
Validation loss: 2.5284309524441886

Epoch: 5| Step: 6
Training loss: 2.702504522300416
Validation loss: 2.528010530794564

Epoch: 5| Step: 7
Training loss: 2.418776468137087
Validation loss: 2.5391438617401954

Epoch: 5| Step: 8
Training loss: 2.26572738942264
Validation loss: 2.535764582957502

Epoch: 5| Step: 9
Training loss: 2.128772528412129
Validation loss: 2.5365108044816975

Epoch: 5| Step: 10
Training loss: 3.3898923583368896
Validation loss: 2.543389313713847

Epoch: 209| Step: 0
Training loss: 2.7747526247579395
Validation loss: 2.562624715455833

Epoch: 5| Step: 1
Training loss: 2.521056761705247
Validation loss: 2.554671773027637

Epoch: 5| Step: 2
Training loss: 2.828001999683024
Validation loss: 2.566748336139364

Epoch: 5| Step: 3
Training loss: 2.5421680414525447
Validation loss: 2.543534884508439

Epoch: 5| Step: 4
Training loss: 2.646737512397799
Validation loss: 2.5239617659575693

Epoch: 5| Step: 5
Training loss: 2.1912698142270557
Validation loss: 2.5222439513742345

Epoch: 5| Step: 6
Training loss: 2.497528762117173
Validation loss: 2.4996895956308043

Epoch: 5| Step: 7
Training loss: 2.989748605729898
Validation loss: 2.5112131052172466

Epoch: 5| Step: 8
Training loss: 2.560277393630703
Validation loss: 2.537884878433241

Epoch: 5| Step: 9
Training loss: 2.8344551184454208
Validation loss: 2.536445611748032

Epoch: 5| Step: 10
Training loss: 2.650789729789754
Validation loss: 2.5314091306167215

Epoch: 210| Step: 0
Training loss: 2.6583635784888022
Validation loss: 2.5191531658958413

Epoch: 5| Step: 1
Training loss: 2.610750486843433
Validation loss: 2.5180576561838106

Epoch: 5| Step: 2
Training loss: 3.0807315227706984
Validation loss: 2.512557549129512

Epoch: 5| Step: 3
Training loss: 2.5853864653178698
Validation loss: 2.4951710413929002

Epoch: 5| Step: 4
Training loss: 2.200896089297773
Validation loss: 2.4970847421557627

Epoch: 5| Step: 5
Training loss: 2.7871504354894134
Validation loss: 2.4937298150738476

Epoch: 5| Step: 6
Training loss: 2.494880011048878
Validation loss: 2.4930495457843347

Epoch: 5| Step: 7
Training loss: 2.6240412459853455
Validation loss: 2.5145284690478626

Epoch: 5| Step: 8
Training loss: 2.710651833381854
Validation loss: 2.5479700243515686

Epoch: 5| Step: 9
Training loss: 2.84480970151854
Validation loss: 2.5162282811548202

Epoch: 5| Step: 10
Training loss: 2.223967421883111
Validation loss: 2.5207379949472712

Epoch: 211| Step: 0
Training loss: 2.3703006630930754
Validation loss: 2.499701636978761

Epoch: 5| Step: 1
Training loss: 2.8830096583156646
Validation loss: 2.4804764115513422

Epoch: 5| Step: 2
Training loss: 2.5506351540103283
Validation loss: 2.477455550328022

Epoch: 5| Step: 3
Training loss: 2.370141732207066
Validation loss: 2.478570583803462

Epoch: 5| Step: 4
Training loss: 2.899538555922351
Validation loss: 2.4738042415347627

Epoch: 5| Step: 5
Training loss: 2.8925085580974503
Validation loss: 2.489136287633008

Epoch: 5| Step: 6
Training loss: 2.311674022080707
Validation loss: 2.513429031659003

Epoch: 5| Step: 7
Training loss: 2.4258794350034396
Validation loss: 2.521785320047544

Epoch: 5| Step: 8
Training loss: 2.6883522279299665
Validation loss: 2.5020489489699695

Epoch: 5| Step: 9
Training loss: 2.8259557339494368
Validation loss: 2.488385115056674

Epoch: 5| Step: 10
Training loss: 2.429587898788738
Validation loss: 2.496520477925785

Epoch: 212| Step: 0
Training loss: 3.049339197835661
Validation loss: 2.480842310150532

Epoch: 5| Step: 1
Training loss: 2.875623220813369
Validation loss: 2.46976563453142

Epoch: 5| Step: 2
Training loss: 2.932967727447164
Validation loss: 2.4789523129144273

Epoch: 5| Step: 3
Training loss: 2.8486798491467185
Validation loss: 2.4730811413116105

Epoch: 5| Step: 4
Training loss: 2.4720092698389458
Validation loss: 2.482645231430504

Epoch: 5| Step: 5
Training loss: 2.2536352249176765
Validation loss: 2.4789434904546064

Epoch: 5| Step: 6
Training loss: 2.149678485694526
Validation loss: 2.4780272594342576

Epoch: 5| Step: 7
Training loss: 2.3379699642578755
Validation loss: 2.4970841405367756

Epoch: 5| Step: 8
Training loss: 2.216641673566226
Validation loss: 2.5042779519345615

Epoch: 5| Step: 9
Training loss: 2.635715231487298
Validation loss: 2.528600726542665

Epoch: 5| Step: 10
Training loss: 2.485063853220625
Validation loss: 2.548858520442244

Epoch: 213| Step: 0
Training loss: 2.3721779570766364
Validation loss: 2.5333569274471794

Epoch: 5| Step: 1
Training loss: 2.421873621786402
Validation loss: 2.5797262559578242

Epoch: 5| Step: 2
Training loss: 2.9822822942840763
Validation loss: 2.539624704319778

Epoch: 5| Step: 3
Training loss: 2.9429131810729667
Validation loss: 2.5058372666091318

Epoch: 5| Step: 4
Training loss: 3.04011952667164
Validation loss: 2.4773591579746217

Epoch: 5| Step: 5
Training loss: 1.8731353388829695
Validation loss: 2.471759384075578

Epoch: 5| Step: 6
Training loss: 2.6605181342849153
Validation loss: 2.4680491249950682

Epoch: 5| Step: 7
Training loss: 2.112239446880261
Validation loss: 2.461237747776098

Epoch: 5| Step: 8
Training loss: 2.9182233380194744
Validation loss: 2.467532433853975

Epoch: 5| Step: 9
Training loss: 2.6438436360832887
Validation loss: 2.4746199782111393

Epoch: 5| Step: 10
Training loss: 2.42800815846111
Validation loss: 2.513731278668141

Epoch: 214| Step: 0
Training loss: 2.6033136013258455
Validation loss: 2.527463544288908

Epoch: 5| Step: 1
Training loss: 2.015196998753874
Validation loss: 2.5686474755223654

Epoch: 5| Step: 2
Training loss: 2.7920685284355877
Validation loss: 2.6019159720060503

Epoch: 5| Step: 3
Training loss: 2.983368868767137
Validation loss: 2.585989146294188

Epoch: 5| Step: 4
Training loss: 3.014852948754268
Validation loss: 2.5203304128935478

Epoch: 5| Step: 5
Training loss: 2.522542316395622
Validation loss: 2.486138504544082

Epoch: 5| Step: 6
Training loss: 2.6804651850179404
Validation loss: 2.484618419780638

Epoch: 5| Step: 7
Training loss: 1.8004433403814262
Validation loss: 2.480910919107281

Epoch: 5| Step: 8
Training loss: 2.705562925448379
Validation loss: 2.499138543183209

Epoch: 5| Step: 9
Training loss: 2.941999195817102
Validation loss: 2.5073633873822256

Epoch: 5| Step: 10
Training loss: 2.1182587225635476
Validation loss: 2.512802875768275

Epoch: 215| Step: 0
Training loss: 2.6355584650504293
Validation loss: 2.528307978033348

Epoch: 5| Step: 1
Training loss: 2.48819443867159
Validation loss: 2.5369099382604894

Epoch: 5| Step: 2
Training loss: 2.1734244767874564
Validation loss: 2.528590211805391

Epoch: 5| Step: 3
Training loss: 2.3758964854338815
Validation loss: 2.510968031645513

Epoch: 5| Step: 4
Training loss: 2.864195382406485
Validation loss: 2.5129062863452556

Epoch: 5| Step: 5
Training loss: 2.9045873008054843
Validation loss: 2.514203613137145

Epoch: 5| Step: 6
Training loss: 2.3937909473871106
Validation loss: 2.5474554815001835

Epoch: 5| Step: 7
Training loss: 1.911101748877272
Validation loss: 2.5560759088472538

Epoch: 5| Step: 8
Training loss: 2.6374848785690084
Validation loss: 2.5669847526491028

Epoch: 5| Step: 9
Training loss: 2.9045917333090085
Validation loss: 2.568950153518409

Epoch: 5| Step: 10
Training loss: 2.644962067214881
Validation loss: 2.5608242367117167

Epoch: 216| Step: 0
Training loss: 2.8609124724763775
Validation loss: 2.527815664083263

Epoch: 5| Step: 1
Training loss: 2.361764468382436
Validation loss: 2.5050531371279052

Epoch: 5| Step: 2
Training loss: 2.2596973616593625
Validation loss: 2.4995276938129765

Epoch: 5| Step: 3
Training loss: 2.689680944474427
Validation loss: 2.485790596224093

Epoch: 5| Step: 4
Training loss: 2.357594810027593
Validation loss: 2.4572054324879615

Epoch: 5| Step: 5
Training loss: 3.195811934484453
Validation loss: 2.462020372740513

Epoch: 5| Step: 6
Training loss: 2.172850245786118
Validation loss: 2.4713111407842825

Epoch: 5| Step: 7
Training loss: 1.7696203078875803
Validation loss: 2.472103553038673

Epoch: 5| Step: 8
Training loss: 2.9015612773245607
Validation loss: 2.4936093943566724

Epoch: 5| Step: 9
Training loss: 2.917871026747987
Validation loss: 2.4955001244051362

Epoch: 5| Step: 10
Training loss: 2.1898149502752453
Validation loss: 2.513936258553871

Epoch: 217| Step: 0
Training loss: 2.8942997848896046
Validation loss: 2.4910263476994

Epoch: 5| Step: 1
Training loss: 1.974658757921377
Validation loss: 2.477519260355345

Epoch: 5| Step: 2
Training loss: 2.1409689077073333
Validation loss: 2.464484226574337

Epoch: 5| Step: 3
Training loss: 2.463226416473869
Validation loss: 2.4434970392551487

Epoch: 5| Step: 4
Training loss: 2.40239277611306
Validation loss: 2.4438620167422664

Epoch: 5| Step: 5
Training loss: 3.086614220697512
Validation loss: 2.4496361224317074

Epoch: 5| Step: 6
Training loss: 2.5038189329731875
Validation loss: 2.4612601099192193

Epoch: 5| Step: 7
Training loss: 2.8569298801062217
Validation loss: 2.4820691500470238

Epoch: 5| Step: 8
Training loss: 2.2979993079626837
Validation loss: 2.5487352848962446

Epoch: 5| Step: 9
Training loss: 2.6474187911621274
Validation loss: 2.5975647247669404

Epoch: 5| Step: 10
Training loss: 2.7544599260568177
Validation loss: 2.606515656020973

Epoch: 218| Step: 0
Training loss: 3.010467071287226
Validation loss: 2.5938599651266703

Epoch: 5| Step: 1
Training loss: 2.4399391099492647
Validation loss: 2.532079011205103

Epoch: 5| Step: 2
Training loss: 2.729977892412373
Validation loss: 2.5033938515988257

Epoch: 5| Step: 3
Training loss: 2.0747208786715747
Validation loss: 2.4812974763209255

Epoch: 5| Step: 4
Training loss: 2.1934300289850195
Validation loss: 2.4978314223367364

Epoch: 5| Step: 5
Training loss: 2.447910671362062
Validation loss: 2.512296153230224

Epoch: 5| Step: 6
Training loss: 2.4291495067934745
Validation loss: 2.5210213624543965

Epoch: 5| Step: 7
Training loss: 2.6858708966459477
Validation loss: 2.5417298006184597

Epoch: 5| Step: 8
Training loss: 2.4929532874574334
Validation loss: 2.5567435900780087

Epoch: 5| Step: 9
Training loss: 2.660379946541647
Validation loss: 2.5383943148981953

Epoch: 5| Step: 10
Training loss: 3.195528130378992
Validation loss: 2.5296322093686294

Epoch: 219| Step: 0
Training loss: 2.510457103187258
Validation loss: 2.51395646422585

Epoch: 5| Step: 1
Training loss: 2.7945390035187376
Validation loss: 2.503788984971596

Epoch: 5| Step: 2
Training loss: 2.766228216734495
Validation loss: 2.494566334593443

Epoch: 5| Step: 3
Training loss: 2.8457153571395475
Validation loss: 2.4624797883720873

Epoch: 5| Step: 4
Training loss: 2.771198755323029
Validation loss: 2.461048212928737

Epoch: 5| Step: 5
Training loss: 2.5142714371523565
Validation loss: 2.4725427368714885

Epoch: 5| Step: 6
Training loss: 2.2327494009724256
Validation loss: 2.475032968758329

Epoch: 5| Step: 7
Training loss: 2.2053572796479024
Validation loss: 2.5178753858344396

Epoch: 5| Step: 8
Training loss: 2.925151110275217
Validation loss: 2.524265026754115

Epoch: 5| Step: 9
Training loss: 1.9356984407302276
Validation loss: 2.51919079663488

Epoch: 5| Step: 10
Training loss: 2.186678595956191
Validation loss: 2.5267302788687425

Epoch: 220| Step: 0
Training loss: 2.5967877535159287
Validation loss: 2.5188834919963745

Epoch: 5| Step: 1
Training loss: 2.5085035661318855
Validation loss: 2.4844802201605316

Epoch: 5| Step: 2
Training loss: 2.147828060755925
Validation loss: 2.471308957139401

Epoch: 5| Step: 3
Training loss: 2.34148266794558
Validation loss: 2.4649969311781827

Epoch: 5| Step: 4
Training loss: 2.1264966294445573
Validation loss: 2.455581545942405

Epoch: 5| Step: 5
Training loss: 2.763280532142259
Validation loss: 2.4439018264242556

Epoch: 5| Step: 6
Training loss: 2.3842899932307033
Validation loss: 2.444016949333286

Epoch: 5| Step: 7
Training loss: 2.4918195399036827
Validation loss: 2.458023298543638

Epoch: 5| Step: 8
Training loss: 3.233077816518429
Validation loss: 2.463571889907381

Epoch: 5| Step: 9
Training loss: 2.6718435899104036
Validation loss: 2.483333159459993

Epoch: 5| Step: 10
Training loss: 2.113144395948526
Validation loss: 2.5149391425066567

Epoch: 221| Step: 0
Training loss: 2.445880567970787
Validation loss: 2.5531736230226016

Epoch: 5| Step: 1
Training loss: 1.5200196881023047
Validation loss: 2.567768670220818

Epoch: 5| Step: 2
Training loss: 2.575879685589482
Validation loss: 2.581490829814747

Epoch: 5| Step: 3
Training loss: 2.3050560608043633
Validation loss: 2.541895771510218

Epoch: 5| Step: 4
Training loss: 3.029281606334425
Validation loss: 2.5103555831112145

Epoch: 5| Step: 5
Training loss: 2.7283240806066935
Validation loss: 2.4686799149114127

Epoch: 5| Step: 6
Training loss: 2.367387114817475
Validation loss: 2.4429402417851303

Epoch: 5| Step: 7
Training loss: 2.762717232426738
Validation loss: 2.4580713038245428

Epoch: 5| Step: 8
Training loss: 2.353023949387337
Validation loss: 2.448121533606275

Epoch: 5| Step: 9
Training loss: 2.729004474120423
Validation loss: 2.4670521858779444

Epoch: 5| Step: 10
Training loss: 2.434025954171618
Validation loss: 2.4796332673975816

Epoch: 222| Step: 0
Training loss: 2.590872213718736
Validation loss: 2.508396316229261

Epoch: 5| Step: 1
Training loss: 2.1450140293258313
Validation loss: 2.539119639167863

Epoch: 5| Step: 2
Training loss: 2.2320482637252987
Validation loss: 2.6128799697160563

Epoch: 5| Step: 3
Training loss: 2.6701618971299785
Validation loss: 2.625184038530541

Epoch: 5| Step: 4
Training loss: 2.4580033506490095
Validation loss: 2.6417989095335375

Epoch: 5| Step: 5
Training loss: 3.0246064048258856
Validation loss: 2.598481163927953

Epoch: 5| Step: 6
Training loss: 2.111487679888414
Validation loss: 2.5718536788345125

Epoch: 5| Step: 7
Training loss: 2.58292769251923
Validation loss: 2.56075440604515

Epoch: 5| Step: 8
Training loss: 1.960803388287758
Validation loss: 2.5071787955618903

Epoch: 5| Step: 9
Training loss: 2.2169657235393028
Validation loss: 2.4800702707155953

Epoch: 5| Step: 10
Training loss: 3.0233479173582607
Validation loss: 2.4578693119511175

Epoch: 223| Step: 0
Training loss: 2.477017815068061
Validation loss: 2.4624423810107094

Epoch: 5| Step: 1
Training loss: 2.4762280355651116
Validation loss: 2.4649195063586316

Epoch: 5| Step: 2
Training loss: 2.1042297907762206
Validation loss: 2.47585540383854

Epoch: 5| Step: 3
Training loss: 2.7159533092603554
Validation loss: 2.475096059604589

Epoch: 5| Step: 4
Training loss: 2.561599480172509
Validation loss: 2.448376872087283

Epoch: 5| Step: 5
Training loss: 2.6929608244484657
Validation loss: 2.4477306378189936

Epoch: 5| Step: 6
Training loss: 2.3084316035353276
Validation loss: 2.4785973389891534

Epoch: 5| Step: 7
Training loss: 2.278404970063725
Validation loss: 2.5515134120207805

Epoch: 5| Step: 8
Training loss: 2.4943050369165958
Validation loss: 2.5602673884854226

Epoch: 5| Step: 9
Training loss: 2.3125060828876394
Validation loss: 2.569748458865849

Epoch: 5| Step: 10
Training loss: 2.8820849485247124
Validation loss: 2.6136251086906666

Epoch: 224| Step: 0
Training loss: 2.3571988611049934
Validation loss: 2.612877912232899

Epoch: 5| Step: 1
Training loss: 2.50205089369133
Validation loss: 2.6047256004445045

Epoch: 5| Step: 2
Training loss: 2.787857436455196
Validation loss: 2.5360444549017322

Epoch: 5| Step: 3
Training loss: 2.342181787362999
Validation loss: 2.475412197059464

Epoch: 5| Step: 4
Training loss: 1.9395159416359813
Validation loss: 2.4470218682105203

Epoch: 5| Step: 5
Training loss: 2.428666860244133
Validation loss: 2.4405130601092844

Epoch: 5| Step: 6
Training loss: 2.633361125348706
Validation loss: 2.4424010479552556

Epoch: 5| Step: 7
Training loss: 2.760061929809597
Validation loss: 2.4515491882371476

Epoch: 5| Step: 8
Training loss: 2.1602916709572293
Validation loss: 2.437246499290638

Epoch: 5| Step: 9
Training loss: 2.7426020208419892
Validation loss: 2.4414651622596404

Epoch: 5| Step: 10
Training loss: 2.221774551546117
Validation loss: 2.4569752809057532

Epoch: 225| Step: 0
Training loss: 2.387982672189181
Validation loss: 2.4928137070010816

Epoch: 5| Step: 1
Training loss: 2.6672971893978787
Validation loss: 2.532655067457819

Epoch: 5| Step: 2
Training loss: 2.563630203729112
Validation loss: 2.549465635216994

Epoch: 5| Step: 3
Training loss: 1.9260672768897744
Validation loss: 2.5580365084300025

Epoch: 5| Step: 4
Training loss: 2.363655602937038
Validation loss: 2.553878436799779

Epoch: 5| Step: 5
Training loss: 2.3889929492474344
Validation loss: 2.5687193720987938

Epoch: 5| Step: 6
Training loss: 2.7301629458694467
Validation loss: 2.5368031627041434

Epoch: 5| Step: 7
Training loss: 2.1444428639359434
Validation loss: 2.51141618626658

Epoch: 5| Step: 8
Training loss: 2.4352952816497804
Validation loss: 2.5078066373223757

Epoch: 5| Step: 9
Training loss: 2.479977440423801
Validation loss: 2.522290918856864

Epoch: 5| Step: 10
Training loss: 2.5264774117093234
Validation loss: 2.513672330885779

Epoch: 226| Step: 0
Training loss: 2.5715677738355813
Validation loss: 2.499144056904428

Epoch: 5| Step: 1
Training loss: 1.7049879332084654
Validation loss: 2.5045019509850346

Epoch: 5| Step: 2
Training loss: 2.792731940627261
Validation loss: 2.5166292809432274

Epoch: 5| Step: 3
Training loss: 2.0128927712380005
Validation loss: 2.530565712965655

Epoch: 5| Step: 4
Training loss: 2.5146237862869385
Validation loss: 2.5440675839418536

Epoch: 5| Step: 5
Training loss: 2.330954042522514
Validation loss: 2.546838543322275

Epoch: 5| Step: 6
Training loss: 2.9731480195439586
Validation loss: 2.5719244939884907

Epoch: 5| Step: 7
Training loss: 2.493338770409978
Validation loss: 2.6000635308138746

Epoch: 5| Step: 8
Training loss: 2.26050995196215
Validation loss: 2.5476000330289175

Epoch: 5| Step: 9
Training loss: 2.2843407373950817
Validation loss: 2.498864230709854

Epoch: 5| Step: 10
Training loss: 2.1010515804431984
Validation loss: 2.4682725107375707

Epoch: 227| Step: 0
Training loss: 2.8645319893599384
Validation loss: 2.4577131679686777

Epoch: 5| Step: 1
Training loss: 2.053292384647595
Validation loss: 2.4488428678556193

Epoch: 5| Step: 2
Training loss: 2.2756619926029518
Validation loss: 2.4613954700330023

Epoch: 5| Step: 3
Training loss: 2.098939755139038
Validation loss: 2.4548674968765942

Epoch: 5| Step: 4
Training loss: 2.3457956160860927
Validation loss: 2.458449346545149

Epoch: 5| Step: 5
Training loss: 3.154919183243116
Validation loss: 2.462218212276733

Epoch: 5| Step: 6
Training loss: 2.302501611698676
Validation loss: 2.476173708599871

Epoch: 5| Step: 7
Training loss: 2.4114792715087776
Validation loss: 2.488844820465383

Epoch: 5| Step: 8
Training loss: 2.120670283357154
Validation loss: 2.4844908596664443

Epoch: 5| Step: 9
Training loss: 1.906475804197141
Validation loss: 2.4640584063492224

Epoch: 5| Step: 10
Training loss: 2.3839062791234147
Validation loss: 2.497965852668023

Epoch: 228| Step: 0
Training loss: 2.1576279369979803
Validation loss: 2.5027200237672385

Epoch: 5| Step: 1
Training loss: 1.9550723934184842
Validation loss: 2.516815912550255

Epoch: 5| Step: 2
Training loss: 2.2015450947319213
Validation loss: 2.517444819858583

Epoch: 5| Step: 3
Training loss: 2.8293661692359118
Validation loss: 2.523139713807581

Epoch: 5| Step: 4
Training loss: 2.084515604884462
Validation loss: 2.5005744458688044

Epoch: 5| Step: 5
Training loss: 2.431008130278461
Validation loss: 2.48137598684689

Epoch: 5| Step: 6
Training loss: 2.8056418832605337
Validation loss: 2.4699438626666943

Epoch: 5| Step: 7
Training loss: 2.0051310999144767
Validation loss: 2.4585776279787286

Epoch: 5| Step: 8
Training loss: 1.9978990248404076
Validation loss: 2.4699268726538737

Epoch: 5| Step: 9
Training loss: 2.743019781939038
Validation loss: 2.461578846543155

Epoch: 5| Step: 10
Training loss: 2.4212426129072364
Validation loss: 2.470177996162412

Epoch: 229| Step: 0
Training loss: 2.5534067472390105
Validation loss: 2.501703654999016

Epoch: 5| Step: 1
Training loss: 2.909399971204346
Validation loss: 2.5403808765457896

Epoch: 5| Step: 2
Training loss: 2.15051125059043
Validation loss: 2.5432456588965557

Epoch: 5| Step: 3
Training loss: 2.225150855447399
Validation loss: 2.5378709575384066

Epoch: 5| Step: 4
Training loss: 2.133531945142515
Validation loss: 2.546904888288485

Epoch: 5| Step: 5
Training loss: 2.1820665727454482
Validation loss: 2.5367758243669862

Epoch: 5| Step: 6
Training loss: 2.111026936520491
Validation loss: 2.5206987030952677

Epoch: 5| Step: 7
Training loss: 2.2083921844509953
Validation loss: 2.5104943434783418

Epoch: 5| Step: 8
Training loss: 2.373174367234954
Validation loss: 2.5023720255552173

Epoch: 5| Step: 9
Training loss: 2.1609960099889096
Validation loss: 2.5232511041552295

Epoch: 5| Step: 10
Training loss: 2.5092530673415814
Validation loss: 2.5165728556096334

Epoch: 230| Step: 0
Training loss: 2.398141650116489
Validation loss: 2.521601903940586

Epoch: 5| Step: 1
Training loss: 2.885762181349941
Validation loss: 2.5415247849500497

Epoch: 5| Step: 2
Training loss: 1.8534037774349341
Validation loss: 2.5528841417643124

Epoch: 5| Step: 3
Training loss: 2.412247354985749
Validation loss: 2.5683133053836342

Epoch: 5| Step: 4
Training loss: 2.440555613529073
Validation loss: 2.591126231894781

Epoch: 5| Step: 5
Training loss: 2.870561407652688
Validation loss: 2.603517630800892

Epoch: 5| Step: 6
Training loss: 1.7931221291754083
Validation loss: 2.5719085713895296

Epoch: 5| Step: 7
Training loss: 2.076344580657785
Validation loss: 2.5683109516725913

Epoch: 5| Step: 8
Training loss: 2.27581945479566
Validation loss: 2.5262811795651836

Epoch: 5| Step: 9
Training loss: 2.004862120494171
Validation loss: 2.5007761119725895

Epoch: 5| Step: 10
Training loss: 2.34772611948858
Validation loss: 2.4854042406569805

Epoch: 231| Step: 0
Training loss: 2.726149475818972
Validation loss: 2.498403977003471

Epoch: 5| Step: 1
Training loss: 2.342943179813682
Validation loss: 2.5038050335982107

Epoch: 5| Step: 2
Training loss: 2.5485926727635033
Validation loss: 2.5335319692000873

Epoch: 5| Step: 3
Training loss: 1.845283710923786
Validation loss: 2.613020511505611

Epoch: 5| Step: 4
Training loss: 2.2837412569560382
Validation loss: 2.6494204517235436

Epoch: 5| Step: 5
Training loss: 1.9315583584723626
Validation loss: 2.5325679510408055

Epoch: 5| Step: 6
Training loss: 2.1791428189647317
Validation loss: 2.46221087498941

Epoch: 5| Step: 7
Training loss: 2.885426563746329
Validation loss: 2.439030726431073

Epoch: 5| Step: 8
Training loss: 2.524367311734654
Validation loss: 2.42746560036302

Epoch: 5| Step: 9
Training loss: 2.109880287968805
Validation loss: 2.4403424839324828

Epoch: 5| Step: 10
Training loss: 1.7133877423227915
Validation loss: 2.4494031731465915

Epoch: 232| Step: 0
Training loss: 2.366491435732035
Validation loss: 2.440349639047343

Epoch: 5| Step: 1
Training loss: 2.372392628594644
Validation loss: 2.452220176406374

Epoch: 5| Step: 2
Training loss: 2.119773608481481
Validation loss: 2.4927686405320286

Epoch: 5| Step: 3
Training loss: 2.330069734569449
Validation loss: 2.534445994020192

Epoch: 5| Step: 4
Training loss: 2.344246976932034
Validation loss: 2.5860003912418112

Epoch: 5| Step: 5
Training loss: 2.0618523245469706
Validation loss: 2.645479129791773

Epoch: 5| Step: 6
Training loss: 2.182992596525044
Validation loss: 2.6708991045901422

Epoch: 5| Step: 7
Training loss: 2.66159229476428
Validation loss: 2.6606520695039317

Epoch: 5| Step: 8
Training loss: 1.8253758291717925
Validation loss: 2.6107561409367173

Epoch: 5| Step: 9
Training loss: 2.12138137131844
Validation loss: 2.541334500353222

Epoch: 5| Step: 10
Training loss: 2.98242027617426
Validation loss: 2.5391710928009696

Epoch: 233| Step: 0
Training loss: 2.3523314983412478
Validation loss: 2.5242535941320723

Epoch: 5| Step: 1
Training loss: 2.5585020558474034
Validation loss: 2.519857269686422

Epoch: 5| Step: 2
Training loss: 2.7821267278453115
Validation loss: 2.538842687186955

Epoch: 5| Step: 3
Training loss: 1.9112057913138787
Validation loss: 2.516997663781516

Epoch: 5| Step: 4
Training loss: 2.2703374852107188
Validation loss: 2.5580624961074343

Epoch: 5| Step: 5
Training loss: 2.3846441514478474
Validation loss: 2.57973142452234

Epoch: 5| Step: 6
Training loss: 2.071377807615285
Validation loss: 2.5939385861628947

Epoch: 5| Step: 7
Training loss: 2.2163735140889673
Validation loss: 2.5949019251085894

Epoch: 5| Step: 8
Training loss: 1.7895673680805317
Validation loss: 2.591267013663722

Epoch: 5| Step: 9
Training loss: 2.3471268804424503
Validation loss: 2.5739262415134143

Epoch: 5| Step: 10
Training loss: 2.3964082663839053
Validation loss: 2.5468040912922896

Epoch: 234| Step: 0
Training loss: 2.016282321886073
Validation loss: 2.522714060919221

Epoch: 5| Step: 1
Training loss: 3.0503515509946983
Validation loss: 2.5086898620919578

Epoch: 5| Step: 2
Training loss: 1.968478895625087
Validation loss: 2.4884341798822307

Epoch: 5| Step: 3
Training loss: 2.093590573746098
Validation loss: 2.5018161042821885

Epoch: 5| Step: 4
Training loss: 2.262026751008447
Validation loss: 2.5155823875369165

Epoch: 5| Step: 5
Training loss: 2.4328168238097314
Validation loss: 2.530098876549858

Epoch: 5| Step: 6
Training loss: 1.9110648835613924
Validation loss: 2.5345178321030115

Epoch: 5| Step: 7
Training loss: 2.4451523018424277
Validation loss: 2.5267404188402764

Epoch: 5| Step: 8
Training loss: 2.1345339803843664
Validation loss: 2.5401320407974244

Epoch: 5| Step: 9
Training loss: 2.294137685998937
Validation loss: 2.5181640792368967

Epoch: 5| Step: 10
Training loss: 1.4889005238677817
Validation loss: 2.507817243289739

Epoch: 235| Step: 0
Training loss: 2.099157609464463
Validation loss: 2.5303614312774476

Epoch: 5| Step: 1
Training loss: 1.6117067204376414
Validation loss: 2.5324176610410074

Epoch: 5| Step: 2
Training loss: 2.1689337704766625
Validation loss: 2.538245298073523

Epoch: 5| Step: 3
Training loss: 2.0075836644963
Validation loss: 2.546919044663881

Epoch: 5| Step: 4
Training loss: 2.3915581969896995
Validation loss: 2.5299137345324616

Epoch: 5| Step: 5
Training loss: 1.694176922022973
Validation loss: 2.5221892184842893

Epoch: 5| Step: 6
Training loss: 2.2745988638895573
Validation loss: 2.511600773893641

Epoch: 5| Step: 7
Training loss: 2.351643101524341
Validation loss: 2.5195550361484136

Epoch: 5| Step: 8
Training loss: 2.3456049381641275
Validation loss: 2.50268783054733

Epoch: 5| Step: 9
Training loss: 2.627700415752349
Validation loss: 2.4982632562366964

Epoch: 5| Step: 10
Training loss: 2.5057048556704498
Validation loss: 2.5406014785633357

Epoch: 236| Step: 0
Training loss: 2.3941413101391986
Validation loss: 2.5902284985917583

Epoch: 5| Step: 1
Training loss: 2.048067750011331
Validation loss: 2.6248965831411746

Epoch: 5| Step: 2
Training loss: 2.2488417293209313
Validation loss: 2.6100894332365723

Epoch: 5| Step: 3
Training loss: 1.4381843264866656
Validation loss: 2.603173427714587

Epoch: 5| Step: 4
Training loss: 1.9747960939051534
Validation loss: 2.5859197522964505

Epoch: 5| Step: 5
Training loss: 2.262865372129507
Validation loss: 2.574430824166086

Epoch: 5| Step: 6
Training loss: 2.1115108273314602
Validation loss: 2.5688053273748963

Epoch: 5| Step: 7
Training loss: 2.378380527879062
Validation loss: 2.575494646883865

Epoch: 5| Step: 8
Training loss: 2.479222839317476
Validation loss: 2.571483118204994

Epoch: 5| Step: 9
Training loss: 2.0386699430182813
Validation loss: 2.5563026839795766

Epoch: 5| Step: 10
Training loss: 2.5466325328529935
Validation loss: 2.5358233189575565

Epoch: 237| Step: 0
Training loss: 2.0726855227419527
Validation loss: 2.5216909780354424

Epoch: 5| Step: 1
Training loss: 2.1970989520118662
Validation loss: 2.4853361539022374

Epoch: 5| Step: 2
Training loss: 2.1149744383076654
Validation loss: 2.469348297581477

Epoch: 5| Step: 3
Training loss: 1.5970490661230456
Validation loss: 2.451252752895748

Epoch: 5| Step: 4
Training loss: 2.4020057998765076
Validation loss: 2.4571436486510194

Epoch: 5| Step: 5
Training loss: 2.047836776629085
Validation loss: 2.4589717704080245

Epoch: 5| Step: 6
Training loss: 1.7749651408466316
Validation loss: 2.498357143817167

Epoch: 5| Step: 7
Training loss: 2.202708536379753
Validation loss: 2.5206898253747823

Epoch: 5| Step: 8
Training loss: 2.59212700495569
Validation loss: 2.5848449990706017

Epoch: 5| Step: 9
Training loss: 2.5851206800377593
Validation loss: 2.6487109941187956

Epoch: 5| Step: 10
Training loss: 2.4735443304225275
Validation loss: 2.689389592133418

Epoch: 238| Step: 0
Training loss: 2.513395375751665
Validation loss: 2.635655041958604

Epoch: 5| Step: 1
Training loss: 2.326132721975808
Validation loss: 2.556425880647332

Epoch: 5| Step: 2
Training loss: 2.2416807658757776
Validation loss: 2.4761529119709764

Epoch: 5| Step: 3
Training loss: 2.1319685723026343
Validation loss: 2.461782099754312

Epoch: 5| Step: 4
Training loss: 1.9686421561600829
Validation loss: 2.4633837595538486

Epoch: 5| Step: 5
Training loss: 2.3548862629049117
Validation loss: 2.467012068074333

Epoch: 5| Step: 6
Training loss: 2.313533242828775
Validation loss: 2.476428242204706

Epoch: 5| Step: 7
Training loss: 2.5029220670240995
Validation loss: 2.503271591512904

Epoch: 5| Step: 8
Training loss: 2.1450955008207915
Validation loss: 2.5654076987506804

Epoch: 5| Step: 9
Training loss: 1.9358797374171541
Validation loss: 2.614334548261049

Epoch: 5| Step: 10
Training loss: 1.5765185347174377
Validation loss: 2.683178574502951

Epoch: 239| Step: 0
Training loss: 2.33104036835778
Validation loss: 2.661752962915973

Epoch: 5| Step: 1
Training loss: 1.9562673695923538
Validation loss: 2.649405094531588

Epoch: 5| Step: 2
Training loss: 1.9324481691661672
Validation loss: 2.645940045165357

Epoch: 5| Step: 3
Training loss: 2.2488277348499315
Validation loss: 2.5823093022765264

Epoch: 5| Step: 4
Training loss: 1.9145563228169928
Validation loss: 2.5444943970732816

Epoch: 5| Step: 5
Training loss: 2.688530746451578
Validation loss: 2.5065503117433843

Epoch: 5| Step: 6
Training loss: 2.1798490512278406
Validation loss: 2.491465701608076

Epoch: 5| Step: 7
Training loss: 2.4209177401912996
Validation loss: 2.506838701236906

Epoch: 5| Step: 8
Training loss: 2.1872054855450904
Validation loss: 2.4877830270977968

Epoch: 5| Step: 9
Training loss: 1.7999520533851654
Validation loss: 2.5007512409757644

Epoch: 5| Step: 10
Training loss: 2.164048728485908
Validation loss: 2.4863648678008037

Epoch: 240| Step: 0
Training loss: 2.4769644907383928
Validation loss: 2.5152383225744424

Epoch: 5| Step: 1
Training loss: 1.6389848048848137
Validation loss: 2.5253775762773443

Epoch: 5| Step: 2
Training loss: 2.259329949189675
Validation loss: 2.5990067945877775

Epoch: 5| Step: 3
Training loss: 1.8378368536028478
Validation loss: 2.6353915967765817

Epoch: 5| Step: 4
Training loss: 2.174898745931339
Validation loss: 2.6774503535223064

Epoch: 5| Step: 5
Training loss: 2.2562290433718792
Validation loss: 2.701296707111448

Epoch: 5| Step: 6
Training loss: 2.016846515843295
Validation loss: 2.6434505864347964

Epoch: 5| Step: 7
Training loss: 1.9082349854604144
Validation loss: 2.614733987555023

Epoch: 5| Step: 8
Training loss: 1.9940365456854532
Validation loss: 2.5533713687663133

Epoch: 5| Step: 9
Training loss: 2.792872628645357
Validation loss: 2.534306757620295

Epoch: 5| Step: 10
Training loss: 1.9334658185464326
Validation loss: 2.5169039714273196

Epoch: 241| Step: 0
Training loss: 2.3798806085212405
Validation loss: 2.5076571461686346

Epoch: 5| Step: 1
Training loss: 2.4835598166020443
Validation loss: 2.510884293798705

Epoch: 5| Step: 2
Training loss: 2.2499664092205576
Validation loss: 2.495668251644835

Epoch: 5| Step: 3
Training loss: 1.8836297125529877
Validation loss: 2.4901017263601335

Epoch: 5| Step: 4
Training loss: 2.4674354626719563
Validation loss: 2.5161186625075285

Epoch: 5| Step: 5
Training loss: 1.4367415873883773
Validation loss: 2.525095679388167

Epoch: 5| Step: 6
Training loss: 2.1989760053157346
Validation loss: 2.558026366239077

Epoch: 5| Step: 7
Training loss: 2.2781726512974982
Validation loss: 2.5786664118960667

Epoch: 5| Step: 8
Training loss: 1.3408644989134477
Validation loss: 2.6312971316323392

Epoch: 5| Step: 9
Training loss: 2.0047508081086547
Validation loss: 2.643493060792915

Epoch: 5| Step: 10
Training loss: 2.0156375381907754
Validation loss: 2.6667140138047802

Epoch: 242| Step: 0
Training loss: 1.8396413898343145
Validation loss: 2.6704921745704815

Epoch: 5| Step: 1
Training loss: 1.9667575987575356
Validation loss: 2.664112918530512

Epoch: 5| Step: 2
Training loss: 2.3748251198078587
Validation loss: 2.630108553613096

Epoch: 5| Step: 3
Training loss: 2.0884108149632974
Validation loss: 2.6075598853770945

Epoch: 5| Step: 4
Training loss: 1.9114149818043218
Validation loss: 2.5768784677535588

Epoch: 5| Step: 5
Training loss: 2.069137873403813
Validation loss: 2.557956728790083

Epoch: 5| Step: 6
Training loss: 1.5193353443313777
Validation loss: 2.541214978613154

Epoch: 5| Step: 7
Training loss: 2.5690177276759933
Validation loss: 2.5414929662611665

Epoch: 5| Step: 8
Training loss: 1.7978949927492993
Validation loss: 2.538525513564399

Epoch: 5| Step: 9
Training loss: 2.300078772149611
Validation loss: 2.5159306636974725

Epoch: 5| Step: 10
Training loss: 2.2127950568576304
Validation loss: 2.541961160305706

Epoch: 243| Step: 0
Training loss: 2.014216796078621
Validation loss: 2.52718476612317

Epoch: 5| Step: 1
Training loss: 2.203741109205845
Validation loss: 2.5424911897179374

Epoch: 5| Step: 2
Training loss: 1.7210129838816113
Validation loss: 2.5604644922581383

Epoch: 5| Step: 3
Training loss: 1.9614265105721198
Validation loss: 2.5761937708780414

Epoch: 5| Step: 4
Training loss: 1.9411351956859955
Validation loss: 2.6071296036790796

Epoch: 5| Step: 5
Training loss: 2.00026474630944
Validation loss: 2.631855360749342

Epoch: 5| Step: 6
Training loss: 2.120162618985823
Validation loss: 2.6457203979909916

Epoch: 5| Step: 7
Training loss: 1.9638323446452235
Validation loss: 2.640918874312922

Epoch: 5| Step: 8
Training loss: 2.1037316454915715
Validation loss: 2.6434045628057903

Epoch: 5| Step: 9
Training loss: 2.113175310169511
Validation loss: 2.606313470454323

Epoch: 5| Step: 10
Training loss: 2.314842584090208
Validation loss: 2.5935063193909857

Epoch: 244| Step: 0
Training loss: 1.9004685326158743
Validation loss: 2.573765282993661

Epoch: 5| Step: 1
Training loss: 1.8169026670655657
Validation loss: 2.531117732436991

Epoch: 5| Step: 2
Training loss: 1.8529034358276286
Validation loss: 2.528454439919468

Epoch: 5| Step: 3
Training loss: 2.5032152481097465
Validation loss: 2.5354273296096963

Epoch: 5| Step: 4
Training loss: 1.9134972185244752
Validation loss: 2.5389829410176237

Epoch: 5| Step: 5
Training loss: 2.311393885654523
Validation loss: 2.5640534785086744

Epoch: 5| Step: 6
Training loss: 1.9094553404542698
Validation loss: 2.5755209063283986

Epoch: 5| Step: 7
Training loss: 1.8139428282437577
Validation loss: 2.596768601079743

Epoch: 5| Step: 8
Training loss: 1.8513629660954154
Validation loss: 2.603646195770862

Epoch: 5| Step: 9
Training loss: 2.1791331909214806
Validation loss: 2.6507269521028105

Epoch: 5| Step: 10
Training loss: 2.0980781116763296
Validation loss: 2.62692050537712

Epoch: 245| Step: 0
Training loss: 2.3066030009897247
Validation loss: 2.5987346711659836

Epoch: 5| Step: 1
Training loss: 2.3718379202496283
Validation loss: 2.56855056994932

Epoch: 5| Step: 2
Training loss: 1.6759128474425216
Validation loss: 2.5512587919037166

Epoch: 5| Step: 3
Training loss: 2.410239936946092
Validation loss: 2.5281672227491057

Epoch: 5| Step: 4
Training loss: 2.2973518136171016
Validation loss: 2.512379583816781

Epoch: 5| Step: 5
Training loss: 1.5697936154433392
Validation loss: 2.5301206422318754

Epoch: 5| Step: 6
Training loss: 1.7572998655708707
Validation loss: 2.5369364111526913

Epoch: 5| Step: 7
Training loss: 1.8695118375058075
Validation loss: 2.568439610060567

Epoch: 5| Step: 8
Training loss: 2.2906454296163803
Validation loss: 2.5774657230905462

Epoch: 5| Step: 9
Training loss: 1.4745975721278473
Validation loss: 2.588486378426895

Epoch: 5| Step: 10
Training loss: 1.7850218874660642
Validation loss: 2.6011047167451626

Epoch: 246| Step: 0
Training loss: 1.7300373168184056
Validation loss: 2.625565203843921

Epoch: 5| Step: 1
Training loss: 2.151677466418847
Validation loss: 2.6211732285929568

Epoch: 5| Step: 2
Training loss: 1.8278884734683893
Validation loss: 2.6406386694785215

Epoch: 5| Step: 3
Training loss: 2.17514319112938
Validation loss: 2.6165044303037535

Epoch: 5| Step: 4
Training loss: 1.4386801643557434
Validation loss: 2.5923436188586853

Epoch: 5| Step: 5
Training loss: 2.0105130925220647
Validation loss: 2.582699721479351

Epoch: 5| Step: 6
Training loss: 2.069986569642068
Validation loss: 2.5791843081382586

Epoch: 5| Step: 7
Training loss: 2.001211395558484
Validation loss: 2.557338011355759

Epoch: 5| Step: 8
Training loss: 1.8903986897859943
Validation loss: 2.557422893630745

Epoch: 5| Step: 9
Training loss: 2.0691122930631223
Validation loss: 2.5478390695272397

Epoch: 5| Step: 10
Training loss: 2.2224787153462766
Validation loss: 2.538975255080968

Epoch: 247| Step: 0
Training loss: 1.9588604143349548
Validation loss: 2.5340290621121846

Epoch: 5| Step: 1
Training loss: 1.8299813911659184
Validation loss: 2.5410873056038756

Epoch: 5| Step: 2
Training loss: 1.8346672046326986
Validation loss: 2.5538800961178314

Epoch: 5| Step: 3
Training loss: 2.1224427262881065
Validation loss: 2.5447450286332565

Epoch: 5| Step: 4
Training loss: 1.7715983664313248
Validation loss: 2.5603810985837527

Epoch: 5| Step: 5
Training loss: 1.8633914810939096
Validation loss: 2.5549876697253113

Epoch: 5| Step: 6
Training loss: 2.2327971322429723
Validation loss: 2.5596118971872355

Epoch: 5| Step: 7
Training loss: 1.9178765735113807
Validation loss: 2.5386015513533065

Epoch: 5| Step: 8
Training loss: 1.6733204662669248
Validation loss: 2.5503084216594325

Epoch: 5| Step: 9
Training loss: 2.139647880355644
Validation loss: 2.568438788598162

Epoch: 5| Step: 10
Training loss: 2.0629196895956556
Validation loss: 2.5725393086232913

Epoch: 248| Step: 0
Training loss: 1.4995586222719834
Validation loss: 2.565056752629269

Epoch: 5| Step: 1
Training loss: 1.8068187069115114
Validation loss: 2.5809824452026637

Epoch: 5| Step: 2
Training loss: 2.1262978349134367
Validation loss: 2.5842146542791142

Epoch: 5| Step: 3
Training loss: 1.9037312611529922
Validation loss: 2.5886439088671724

Epoch: 5| Step: 4
Training loss: 1.663395134434539
Validation loss: 2.5758737190672503

Epoch: 5| Step: 5
Training loss: 1.8460633587363664
Validation loss: 2.570847806977719

Epoch: 5| Step: 6
Training loss: 1.626546124202734
Validation loss: 2.5451196716075826

Epoch: 5| Step: 7
Training loss: 2.4948550689434765
Validation loss: 2.558765540938612

Epoch: 5| Step: 8
Training loss: 1.9917708615723209
Validation loss: 2.558194667287145

Epoch: 5| Step: 9
Training loss: 2.18844355260831
Validation loss: 2.5904274376490837

Epoch: 5| Step: 10
Training loss: 1.9216566504520423
Validation loss: 2.5878642612444773

Epoch: 249| Step: 0
Training loss: 2.142614400829531
Validation loss: 2.6009652569647623

Epoch: 5| Step: 1
Training loss: 1.8474706189577108
Validation loss: 2.617522453922231

Epoch: 5| Step: 2
Training loss: 1.6305502227329185
Validation loss: 2.6098072326971997

Epoch: 5| Step: 3
Training loss: 1.9577255388021888
Validation loss: 2.5944768631183948

Epoch: 5| Step: 4
Training loss: 2.128076009984714
Validation loss: 2.6093276630362237

Epoch: 5| Step: 5
Training loss: 2.0452112322887763
Validation loss: 2.601996966473457

Epoch: 5| Step: 6
Training loss: 1.989099540275669
Validation loss: 2.5800601919201687

Epoch: 5| Step: 7
Training loss: 1.9866830214311548
Validation loss: 2.57547361106503

Epoch: 5| Step: 8
Training loss: 2.0383614105802783
Validation loss: 2.5963455617887576

Epoch: 5| Step: 9
Training loss: 1.4273515806520967
Validation loss: 2.573887224506995

Epoch: 5| Step: 10
Training loss: 1.7096145601494221
Validation loss: 2.5801695660695643

Epoch: 250| Step: 0
Training loss: 2.2559692884478553
Validation loss: 2.5451073686959544

Epoch: 5| Step: 1
Training loss: 1.4651667938064579
Validation loss: 2.5590360525795197

Epoch: 5| Step: 2
Training loss: 2.254752861233461
Validation loss: 2.546949308886526

Epoch: 5| Step: 3
Training loss: 1.9270237131604695
Validation loss: 2.5762776502815212

Epoch: 5| Step: 4
Training loss: 2.001216875858889
Validation loss: 2.578711885964299

Epoch: 5| Step: 5
Training loss: 1.6291838850719627
Validation loss: 2.566609366834352

Epoch: 5| Step: 6
Training loss: 1.5714787190349995
Validation loss: 2.5760118183706138

Epoch: 5| Step: 7
Training loss: 1.9243206807195294
Validation loss: 2.5646869762202322

Epoch: 5| Step: 8
Training loss: 1.8136153242507904
Validation loss: 2.5546302198175264

Epoch: 5| Step: 9
Training loss: 2.041914542066056
Validation loss: 2.5795636938036064

Epoch: 5| Step: 10
Training loss: 1.7576544118365147
Validation loss: 2.580081755718078

Epoch: 251| Step: 0
Training loss: 1.849615691193347
Validation loss: 2.5675126636661436

Epoch: 5| Step: 1
Training loss: 2.2546374954526236
Validation loss: 2.5717044106939144

Epoch: 5| Step: 2
Training loss: 1.7802133722682267
Validation loss: 2.5408017455182272

Epoch: 5| Step: 3
Training loss: 1.7424172562118618
Validation loss: 2.5453245636578523

Epoch: 5| Step: 4
Training loss: 1.9703052977415947
Validation loss: 2.5599655505571586

Epoch: 5| Step: 5
Training loss: 1.952070210784915
Validation loss: 2.566030927417974

Epoch: 5| Step: 6
Training loss: 2.1043200924776686
Validation loss: 2.573837293589128

Epoch: 5| Step: 7
Training loss: 1.5290877197979964
Validation loss: 2.566159085722137

Epoch: 5| Step: 8
Training loss: 1.4302742176296008
Validation loss: 2.559870102952249

Epoch: 5| Step: 9
Training loss: 2.14784371233334
Validation loss: 2.5896266458409394

Epoch: 5| Step: 10
Training loss: 1.8179285376953391
Validation loss: 2.6035744794002627

Epoch: 252| Step: 0
Training loss: 1.6809790325547769
Validation loss: 2.5727714473346612

Epoch: 5| Step: 1
Training loss: 1.5243040310275893
Validation loss: 2.595446273478409

Epoch: 5| Step: 2
Training loss: 1.6628901690643094
Validation loss: 2.5751691333592808

Epoch: 5| Step: 3
Training loss: 2.1708773510278205
Validation loss: 2.5787227958038104

Epoch: 5| Step: 4
Training loss: 1.826097325726009
Validation loss: 2.5646616674249993

Epoch: 5| Step: 5
Training loss: 1.6624260678021754
Validation loss: 2.5694217454357915

Epoch: 5| Step: 6
Training loss: 2.423045509260507
Validation loss: 2.585665739193111

Epoch: 5| Step: 7
Training loss: 2.0481393418146063
Validation loss: 2.5789464234260424

Epoch: 5| Step: 8
Training loss: 1.810291259893886
Validation loss: 2.5938458662803385

Epoch: 5| Step: 9
Training loss: 1.7137334961656456
Validation loss: 2.5726793845777096

Epoch: 5| Step: 10
Training loss: 1.8647210338473892
Validation loss: 2.5822953965019413

Epoch: 253| Step: 0
Training loss: 1.5652135555823867
Validation loss: 2.5433737819747786

Epoch: 5| Step: 1
Training loss: 1.8866663702413013
Validation loss: 2.572330018548717

Epoch: 5| Step: 2
Training loss: 2.02781715819326
Validation loss: 2.542113783422851

Epoch: 5| Step: 3
Training loss: 1.401965799643724
Validation loss: 2.537301574882595

Epoch: 5| Step: 4
Training loss: 2.203606951869511
Validation loss: 2.5536439752619766

Epoch: 5| Step: 5
Training loss: 1.772257677093637
Validation loss: 2.5531102565222654

Epoch: 5| Step: 6
Training loss: 2.054188714931102
Validation loss: 2.558211242444339

Epoch: 5| Step: 7
Training loss: 2.290566845164744
Validation loss: 2.5791827953102766

Epoch: 5| Step: 8
Training loss: 1.4718842848304714
Validation loss: 2.5749012480231377

Epoch: 5| Step: 9
Training loss: 1.753766162604791
Validation loss: 2.602637566987144

Epoch: 5| Step: 10
Training loss: 1.6026905088211603
Validation loss: 2.6025039224434607

Epoch: 254| Step: 0
Training loss: 1.8153896973767574
Validation loss: 2.60902715679102

Epoch: 5| Step: 1
Training loss: 1.6138190973146345
Validation loss: 2.615977351793105

Epoch: 5| Step: 2
Training loss: 1.6823584323857776
Validation loss: 2.6069636603304445

Epoch: 5| Step: 3
Training loss: 1.970261916646459
Validation loss: 2.6085461936141217

Epoch: 5| Step: 4
Training loss: 1.9906341480661742
Validation loss: 2.6171073155615856

Epoch: 5| Step: 5
Training loss: 1.3723610349389883
Validation loss: 2.6006521159309868

Epoch: 5| Step: 6
Training loss: 1.7586128277889834
Validation loss: 2.597326586931849

Epoch: 5| Step: 7
Training loss: 1.9392397053396015
Validation loss: 2.564756288993473

Epoch: 5| Step: 8
Training loss: 1.6309712080387613
Validation loss: 2.5146694142890085

Epoch: 5| Step: 9
Training loss: 2.119671479988102
Validation loss: 2.514156394135173

Epoch: 5| Step: 10
Training loss: 2.0913003284078147
Validation loss: 2.4850239209674223

Epoch: 255| Step: 0
Training loss: 1.5848103543974963
Validation loss: 2.5013492153142662

Epoch: 5| Step: 1
Training loss: 1.4533834740245772
Validation loss: 2.499587458750935

Epoch: 5| Step: 2
Training loss: 1.972996869281464
Validation loss: 2.532131115140261

Epoch: 5| Step: 3
Training loss: 1.5709275896174493
Validation loss: 2.5783162025904813

Epoch: 5| Step: 4
Training loss: 2.3268337893467703
Validation loss: 2.5993033937595422

Epoch: 5| Step: 5
Training loss: 1.6794931698541289
Validation loss: 2.6109242616416273

Epoch: 5| Step: 6
Training loss: 2.0592368929085656
Validation loss: 2.5867673819100734

Epoch: 5| Step: 7
Training loss: 1.7860971721515937
Validation loss: 2.5883363678780773

Epoch: 5| Step: 8
Training loss: 1.8623640254008613
Validation loss: 2.5672279219165373

Epoch: 5| Step: 9
Training loss: 1.6621382068683968
Validation loss: 2.5630247077604453

Epoch: 5| Step: 10
Training loss: 1.8288682910054888
Validation loss: 2.553211520472867

Epoch: 256| Step: 0
Training loss: 1.6289837496317547
Validation loss: 2.5845559396403797

Epoch: 5| Step: 1
Training loss: 1.269996440461945
Validation loss: 2.5852433502824046

Epoch: 5| Step: 2
Training loss: 1.9592181567337132
Validation loss: 2.5887230933552896

Epoch: 5| Step: 3
Training loss: 1.819197677625249
Validation loss: 2.610271782886599

Epoch: 5| Step: 4
Training loss: 1.975807437745803
Validation loss: 2.5903175593832826

Epoch: 5| Step: 5
Training loss: 1.2980451704961724
Validation loss: 2.5884119051097128

Epoch: 5| Step: 6
Training loss: 2.153131745747268
Validation loss: 2.619218913935575

Epoch: 5| Step: 7
Training loss: 1.792528418364895
Validation loss: 2.6068486886613798

Epoch: 5| Step: 8
Training loss: 2.070026190771739
Validation loss: 2.5989961375820823

Epoch: 5| Step: 9
Training loss: 1.8840658361266518
Validation loss: 2.5692084156268846

Epoch: 5| Step: 10
Training loss: 1.6775959566190397
Validation loss: 2.5401759268571293

Epoch: 257| Step: 0
Training loss: 1.7845057798651682
Validation loss: 2.528687212171746

Epoch: 5| Step: 1
Training loss: 1.6297466936635283
Validation loss: 2.5056798044140733

Epoch: 5| Step: 2
Training loss: 1.8244644424348162
Validation loss: 2.514785449186902

Epoch: 5| Step: 3
Training loss: 1.8277985370981173
Validation loss: 2.517961986334725

Epoch: 5| Step: 4
Training loss: 2.135669066856722
Validation loss: 2.541929344053543

Epoch: 5| Step: 5
Training loss: 1.5320777991039893
Validation loss: 2.5630314423696237

Epoch: 5| Step: 6
Training loss: 1.65270328442897
Validation loss: 2.582726844691526

Epoch: 5| Step: 7
Training loss: 2.036980395380513
Validation loss: 2.603695217321859

Epoch: 5| Step: 8
Training loss: 1.848566391643856
Validation loss: 2.623738072961647

Epoch: 5| Step: 9
Training loss: 1.543763856400918
Validation loss: 2.579684455892494

Epoch: 5| Step: 10
Training loss: 1.7183770208543208
Validation loss: 2.5661050072769416

Epoch: 258| Step: 0
Training loss: 2.1552328391976596
Validation loss: 2.548932913316911

Epoch: 5| Step: 1
Training loss: 1.8952693799075533
Validation loss: 2.5310001024588225

Epoch: 5| Step: 2
Training loss: 1.8980434306997265
Validation loss: 2.5160922956111813

Epoch: 5| Step: 3
Training loss: 1.2846263964315903
Validation loss: 2.5340207844873333

Epoch: 5| Step: 4
Training loss: 1.475464266110036
Validation loss: 2.5101759246297886

Epoch: 5| Step: 5
Training loss: 1.9449756744354176
Validation loss: 2.5375861690302854

Epoch: 5| Step: 6
Training loss: 1.6961188442318966
Validation loss: 2.5489205171696843

Epoch: 5| Step: 7
Training loss: 1.841639652600673
Validation loss: 2.5722432461925098

Epoch: 5| Step: 8
Training loss: 1.708524770787658
Validation loss: 2.5753273380433135

Epoch: 5| Step: 9
Training loss: 1.6843143346049565
Validation loss: 2.592141043920681

Epoch: 5| Step: 10
Training loss: 1.6623340638605755
Validation loss: 2.569441283302687

Epoch: 259| Step: 0
Training loss: 1.8931573349567417
Validation loss: 2.5501361067446027

Epoch: 5| Step: 1
Training loss: 1.62038382186554
Validation loss: 2.544566502570394

Epoch: 5| Step: 2
Training loss: 1.8956928899816106
Validation loss: 2.5471945146431345

Epoch: 5| Step: 3
Training loss: 1.9194193092033973
Validation loss: 2.5461204030487323

Epoch: 5| Step: 4
Training loss: 1.6354884802081098
Validation loss: 2.556662789424058

Epoch: 5| Step: 5
Training loss: 1.8285602149342808
Validation loss: 2.5605227167323625

Epoch: 5| Step: 6
Training loss: 1.5473946363234108
Validation loss: 2.5507045380602733

Epoch: 5| Step: 7
Training loss: 1.4346716879386905
Validation loss: 2.573109887586468

Epoch: 5| Step: 8
Training loss: 1.8984515656629137
Validation loss: 2.5744023140048804

Epoch: 5| Step: 9
Training loss: 1.4561480998131604
Validation loss: 2.5897193603755815

Epoch: 5| Step: 10
Training loss: 1.9681788630306172
Validation loss: 2.584079413064973

Epoch: 260| Step: 0
Training loss: 1.814595688063574
Validation loss: 2.5215866736481036

Epoch: 5| Step: 1
Training loss: 1.6457589611520516
Validation loss: 2.496631628616726

Epoch: 5| Step: 2
Training loss: 1.6394633222166939
Validation loss: 2.4534887333270006

Epoch: 5| Step: 3
Training loss: 2.0047704309330303
Validation loss: 2.4768818161966353

Epoch: 5| Step: 4
Training loss: 1.6969932276107895
Validation loss: 2.4899690284405667

Epoch: 5| Step: 5
Training loss: 1.3510964532752117
Validation loss: 2.490222758347088

Epoch: 5| Step: 6
Training loss: 1.5678692689669387
Validation loss: 2.518394818957117

Epoch: 5| Step: 7
Training loss: 1.6534769127142073
Validation loss: 2.5395467569313817

Epoch: 5| Step: 8
Training loss: 2.102445168885835
Validation loss: 2.577688037563547

Epoch: 5| Step: 9
Training loss: 1.4354008814474808
Validation loss: 2.6269362653166954

Epoch: 5| Step: 10
Training loss: 1.812166446379961
Validation loss: 2.589660051016079

Epoch: 261| Step: 0
Training loss: 2.1763081486189773
Validation loss: 2.6312181079126162

Epoch: 5| Step: 1
Training loss: 1.7663613868357797
Validation loss: 2.5995933478166684

Epoch: 5| Step: 2
Training loss: 1.4551852807649548
Validation loss: 2.6106854275572715

Epoch: 5| Step: 3
Training loss: 1.7367043189557319
Validation loss: 2.6147765626793626

Epoch: 5| Step: 4
Training loss: 1.4929860160464021
Validation loss: 2.590307705898477

Epoch: 5| Step: 5
Training loss: 2.043420336905456
Validation loss: 2.55500726579233

Epoch: 5| Step: 6
Training loss: 1.8341526527106282
Validation loss: 2.537179560391809

Epoch: 5| Step: 7
Training loss: 1.3730324192290018
Validation loss: 2.5380337568253095

Epoch: 5| Step: 8
Training loss: 1.741465739778146
Validation loss: 2.515081068751583

Epoch: 5| Step: 9
Training loss: 1.5507832486310327
Validation loss: 2.496799723815356

Epoch: 5| Step: 10
Training loss: 1.3368528921930753
Validation loss: 2.5167780792483883

Epoch: 262| Step: 0
Training loss: 1.3338097923054342
Validation loss: 2.53437319394203

Epoch: 5| Step: 1
Training loss: 2.068799196332523
Validation loss: 2.55135170698016

Epoch: 5| Step: 2
Training loss: 1.8320340479847703
Validation loss: 2.5983444384164764

Epoch: 5| Step: 3
Training loss: 1.8968437003706615
Validation loss: 2.6122310159051287

Epoch: 5| Step: 4
Training loss: 1.585233560315363
Validation loss: 2.6070445648464697

Epoch: 5| Step: 5
Training loss: 1.651673381623682
Validation loss: 2.5794715126934933

Epoch: 5| Step: 6
Training loss: 1.7934973774771956
Validation loss: 2.5391311532734093

Epoch: 5| Step: 7
Training loss: 1.7688858168794697
Validation loss: 2.538525113646507

Epoch: 5| Step: 8
Training loss: 1.6394729202235212
Validation loss: 2.504962517064081

Epoch: 5| Step: 9
Training loss: 1.6348160128649951
Validation loss: 2.5541452669878804

Epoch: 5| Step: 10
Training loss: 1.3821829963212249
Validation loss: 2.5387670120689823

Epoch: 263| Step: 0
Training loss: 1.7210005850560968
Validation loss: 2.5402598011771054

Epoch: 5| Step: 1
Training loss: 1.5323740667528092
Validation loss: 2.5587533191682

Epoch: 5| Step: 2
Training loss: 1.4765713807499965
Validation loss: 2.565669496931359

Epoch: 5| Step: 3
Training loss: 1.6746411835959893
Validation loss: 2.569127286541395

Epoch: 5| Step: 4
Training loss: 1.9683721270548429
Validation loss: 2.572884639683309

Epoch: 5| Step: 5
Training loss: 1.8130876312034263
Validation loss: 2.54741717839322

Epoch: 5| Step: 6
Training loss: 1.904787597028845
Validation loss: 2.559548164239267

Epoch: 5| Step: 7
Training loss: 1.7642991480804031
Validation loss: 2.551544247702582

Epoch: 5| Step: 8
Training loss: 1.0422067894930591
Validation loss: 2.5139993081976493

Epoch: 5| Step: 9
Training loss: 1.8303458263299925
Validation loss: 2.5062735075819025

Epoch: 5| Step: 10
Training loss: 1.5179129566220935
Validation loss: 2.5009730260548455

Epoch: 264| Step: 0
Training loss: 1.7938122728550392
Validation loss: 2.477416249812641

Epoch: 5| Step: 1
Training loss: 1.455374340654509
Validation loss: 2.484455013708647

Epoch: 5| Step: 2
Training loss: 1.4674309834200292
Validation loss: 2.5121489100212173

Epoch: 5| Step: 3
Training loss: 1.195476695233638
Validation loss: 2.5355008587561283

Epoch: 5| Step: 4
Training loss: 1.6601170434249126
Validation loss: 2.5553845897084217

Epoch: 5| Step: 5
Training loss: 1.7492706958985214
Validation loss: 2.583046028510018

Epoch: 5| Step: 6
Training loss: 1.6604269368018802
Validation loss: 2.570016954121162

Epoch: 5| Step: 7
Training loss: 1.8088738572659633
Validation loss: 2.5759230382534204

Epoch: 5| Step: 8
Training loss: 1.697210488779175
Validation loss: 2.5869532179868218

Epoch: 5| Step: 9
Training loss: 1.551657249116164
Validation loss: 2.559313676190009

Epoch: 5| Step: 10
Training loss: 2.1149828929524914
Validation loss: 2.560656008377527

Epoch: 265| Step: 0
Training loss: 1.404071476744418
Validation loss: 2.536834843155208

Epoch: 5| Step: 1
Training loss: 2.000390253139611
Validation loss: 2.518602735046966

Epoch: 5| Step: 2
Training loss: 1.5785835279828324
Validation loss: 2.5359635092888486

Epoch: 5| Step: 3
Training loss: 1.3284829947489114
Validation loss: 2.5157505799707782

Epoch: 5| Step: 4
Training loss: 1.3069453090908547
Validation loss: 2.5368670860891673

Epoch: 5| Step: 5
Training loss: 1.8675968886523742
Validation loss: 2.529784848688317

Epoch: 5| Step: 6
Training loss: 1.6195792971751204
Validation loss: 2.5254084224800417

Epoch: 5| Step: 7
Training loss: 1.537567109294852
Validation loss: 2.499491836830995

Epoch: 5| Step: 8
Training loss: 1.6679016385658916
Validation loss: 2.4910279552317265

Epoch: 5| Step: 9
Training loss: 1.9923921966107367
Validation loss: 2.4755706483086013

Epoch: 5| Step: 10
Training loss: 1.7826158741101563
Validation loss: 2.485559227822593

Epoch: 266| Step: 0
Training loss: 1.6301283974189067
Validation loss: 2.514708907390631

Epoch: 5| Step: 1
Training loss: 1.9255799967934086
Validation loss: 2.5577399780641334

Epoch: 5| Step: 2
Training loss: 1.4674655898574833
Validation loss: 2.551043519143296

Epoch: 5| Step: 3
Training loss: 1.587811044573328
Validation loss: 2.550919964045746

Epoch: 5| Step: 4
Training loss: 1.7594021539303517
Validation loss: 2.5554361211443037

Epoch: 5| Step: 5
Training loss: 1.6397070360192236
Validation loss: 2.5553678958926693

Epoch: 5| Step: 6
Training loss: 1.3991010146711513
Validation loss: 2.5381944165378187

Epoch: 5| Step: 7
Training loss: 1.5283574401440752
Validation loss: 2.52670110973634

Epoch: 5| Step: 8
Training loss: 1.462882639069908
Validation loss: 2.5124003744497565

Epoch: 5| Step: 9
Training loss: 1.6843693267783344
Validation loss: 2.544963505633549

Epoch: 5| Step: 10
Training loss: 1.9080785517407393
Validation loss: 2.5450617646057596

Epoch: 267| Step: 0
Training loss: 1.4950910350423365
Validation loss: 2.5415045034063035

Epoch: 5| Step: 1
Training loss: 2.048810436947003
Validation loss: 2.525389690050199

Epoch: 5| Step: 2
Training loss: 1.054217481079514
Validation loss: 2.524290971108779

Epoch: 5| Step: 3
Training loss: 1.9406150879046251
Validation loss: 2.52676187559205

Epoch: 5| Step: 4
Training loss: 1.7382580702018404
Validation loss: 2.5009202847635144

Epoch: 5| Step: 5
Training loss: 1.606376447042167
Validation loss: 2.527403534755559

Epoch: 5| Step: 6
Training loss: 1.7198500840701276
Validation loss: 2.507690564728449

Epoch: 5| Step: 7
Training loss: 1.8027360942993562
Validation loss: 2.535094982530433

Epoch: 5| Step: 8
Training loss: 1.3628546804344162
Validation loss: 2.5701655522194904

Epoch: 5| Step: 9
Training loss: 1.2505592049025231
Validation loss: 2.561078413348109

Epoch: 5| Step: 10
Training loss: 1.562795382236037
Validation loss: 2.5628432517429287

Epoch: 268| Step: 0
Training loss: 1.4661135446935336
Validation loss: 2.535767785781794

Epoch: 5| Step: 1
Training loss: 1.6776680095012122
Validation loss: 2.564355134183267

Epoch: 5| Step: 2
Training loss: 1.198154834899202
Validation loss: 2.535213794728577

Epoch: 5| Step: 3
Training loss: 1.7743886002103018
Validation loss: 2.485686390698511

Epoch: 5| Step: 4
Training loss: 1.4824954531054702
Validation loss: 2.5110746469483995

Epoch: 5| Step: 5
Training loss: 1.29354149617158
Validation loss: 2.4960317476092517

Epoch: 5| Step: 6
Training loss: 1.8518957168187629
Validation loss: 2.511184045774715

Epoch: 5| Step: 7
Training loss: 1.7245562189881087
Validation loss: 2.4774206456568026

Epoch: 5| Step: 8
Training loss: 1.8020078904194035
Validation loss: 2.519094061562883

Epoch: 5| Step: 9
Training loss: 1.6741268643625389
Validation loss: 2.50420740029699

Epoch: 5| Step: 10
Training loss: 1.4148602843305855
Validation loss: 2.492008762030225

Epoch: 269| Step: 0
Training loss: 1.5294557296466527
Validation loss: 2.4732576223534357

Epoch: 5| Step: 1
Training loss: 1.5006682179116888
Validation loss: 2.465531134066706

Epoch: 5| Step: 2
Training loss: 1.4086544250182638
Validation loss: 2.4512583209903585

Epoch: 5| Step: 3
Training loss: 1.9870467334890078
Validation loss: 2.47602911628586

Epoch: 5| Step: 4
Training loss: 1.583823613335519
Validation loss: 2.4763454234592173

Epoch: 5| Step: 5
Training loss: 1.768405244475472
Validation loss: 2.49394068895993

Epoch: 5| Step: 6
Training loss: 1.5023976872244553
Validation loss: 2.5038918791092284

Epoch: 5| Step: 7
Training loss: 1.6117890409673337
Validation loss: 2.5546761081904807

Epoch: 5| Step: 8
Training loss: 1.5074783508365772
Validation loss: 2.572910987542507

Epoch: 5| Step: 9
Training loss: 1.4383050903134755
Validation loss: 2.5581327329713126

Epoch: 5| Step: 10
Training loss: 1.4779268450512428
Validation loss: 2.5829490775439186

Epoch: 270| Step: 0
Training loss: 1.5571757584966868
Validation loss: 2.552874273339496

Epoch: 5| Step: 1
Training loss: 1.7825654509781328
Validation loss: 2.5512921065901626

Epoch: 5| Step: 2
Training loss: 1.4421336915133762
Validation loss: 2.522073649244296

Epoch: 5| Step: 3
Training loss: 1.2885013167967043
Validation loss: 2.535273329183049

Epoch: 5| Step: 4
Training loss: 1.8649177322447152
Validation loss: 2.4955416426055925

Epoch: 5| Step: 5
Training loss: 1.2300769969441974
Validation loss: 2.5000715430082625

Epoch: 5| Step: 6
Training loss: 1.7087044274058067
Validation loss: 2.5057256648532458

Epoch: 5| Step: 7
Training loss: 1.5097020618239427
Validation loss: 2.4946105485043324

Epoch: 5| Step: 8
Training loss: 1.6833392523985684
Validation loss: 2.5290928496600147

Epoch: 5| Step: 9
Training loss: 1.4561140430819872
Validation loss: 2.536585129956623

Epoch: 5| Step: 10
Training loss: 1.578443816056621
Validation loss: 2.5192627766543176

Epoch: 271| Step: 0
Training loss: 1.744038304385106
Validation loss: 2.5420143747624633

Epoch: 5| Step: 1
Training loss: 1.490259252818026
Validation loss: 2.5204995433597683

Epoch: 5| Step: 2
Training loss: 1.4807098916975505
Validation loss: 2.5067206013064807

Epoch: 5| Step: 3
Training loss: 1.5385708870907675
Validation loss: 2.50661905365168

Epoch: 5| Step: 4
Training loss: 1.2036778554559213
Validation loss: 2.4965795200622045

Epoch: 5| Step: 5
Training loss: 1.5972219310520663
Validation loss: 2.482789304202827

Epoch: 5| Step: 6
Training loss: 1.492378741886462
Validation loss: 2.521006545079965

Epoch: 5| Step: 7
Training loss: 1.3880792954987644
Validation loss: 2.534436494826135

Epoch: 5| Step: 8
Training loss: 1.837387551221015
Validation loss: 2.5385870102894628

Epoch: 5| Step: 9
Training loss: 1.850064472415355
Validation loss: 2.5471224563662966

Epoch: 5| Step: 10
Training loss: 1.334988932117202
Validation loss: 2.544382448555111

Epoch: 272| Step: 0
Training loss: 1.556116875159605
Validation loss: 2.508518503348031

Epoch: 5| Step: 1
Training loss: 1.5001285815759215
Validation loss: 2.4980022097992207

Epoch: 5| Step: 2
Training loss: 1.421271898407937
Validation loss: 2.4802021684670037

Epoch: 5| Step: 3
Training loss: 1.2560810943470855
Validation loss: 2.452293983117081

Epoch: 5| Step: 4
Training loss: 1.328592509843718
Validation loss: 2.4454946310222687

Epoch: 5| Step: 5
Training loss: 1.3553413968901058
Validation loss: 2.4427369399406906

Epoch: 5| Step: 6
Training loss: 1.5649756845894838
Validation loss: 2.4637954859701274

Epoch: 5| Step: 7
Training loss: 1.9104892307867503
Validation loss: 2.474569249178471

Epoch: 5| Step: 8
Training loss: 1.9049738380057424
Validation loss: 2.508340389443605

Epoch: 5| Step: 9
Training loss: 1.300573154792806
Validation loss: 2.541450723975816

Epoch: 5| Step: 10
Training loss: 1.756356072531614
Validation loss: 2.5508228151565304

Epoch: 273| Step: 0
Training loss: 1.1471031897438575
Validation loss: 2.529096150135307

Epoch: 5| Step: 1
Training loss: 1.5227669046904413
Validation loss: 2.5555525410839324

Epoch: 5| Step: 2
Training loss: 1.0389857443087616
Validation loss: 2.50621396857356

Epoch: 5| Step: 3
Training loss: 1.6661937837496885
Validation loss: 2.5369583900016845

Epoch: 5| Step: 4
Training loss: 1.6258176800423851
Validation loss: 2.532155071473881

Epoch: 5| Step: 5
Training loss: 1.3764269100617241
Validation loss: 2.5317866522298793

Epoch: 5| Step: 6
Training loss: 1.4119263420884953
Validation loss: 2.4991251696659695

Epoch: 5| Step: 7
Training loss: 1.4010728267716739
Validation loss: 2.507696551376823

Epoch: 5| Step: 8
Training loss: 1.708376566021967
Validation loss: 2.4844710087117168

Epoch: 5| Step: 9
Training loss: 1.5472759151140645
Validation loss: 2.4531147156319477

Epoch: 5| Step: 10
Training loss: 2.1089979046611766
Validation loss: 2.471019641881436

Epoch: 274| Step: 0
Training loss: 1.4832247644332275
Validation loss: 2.4269942805503564

Epoch: 5| Step: 1
Training loss: 1.4080530263875073
Validation loss: 2.4588309313316117

Epoch: 5| Step: 2
Training loss: 1.5132523675229195
Validation loss: 2.5019429624437124

Epoch: 5| Step: 3
Training loss: 1.7651878423397032
Validation loss: 2.5280980364765067

Epoch: 5| Step: 4
Training loss: 1.5342471316135018
Validation loss: 2.571461995734137

Epoch: 5| Step: 5
Training loss: 1.7980178515743603
Validation loss: 2.587918982602924

Epoch: 5| Step: 6
Training loss: 1.0607203557720144
Validation loss: 2.547790771375943

Epoch: 5| Step: 7
Training loss: 1.6111020201210975
Validation loss: 2.5561235078593434

Epoch: 5| Step: 8
Training loss: 1.3859556005558173
Validation loss: 2.4984373100077675

Epoch: 5| Step: 9
Training loss: 1.4387683248802892
Validation loss: 2.503097082198502

Epoch: 5| Step: 10
Training loss: 1.4376234747889596
Validation loss: 2.487353615945262

Epoch: 275| Step: 0
Training loss: 1.584036152436731
Validation loss: 2.475068677726435

Epoch: 5| Step: 1
Training loss: 1.5672099270646904
Validation loss: 2.4934730974978963

Epoch: 5| Step: 2
Training loss: 1.8760139267003932
Validation loss: 2.475628994023224

Epoch: 5| Step: 3
Training loss: 1.225546349117837
Validation loss: 2.4556108113301423

Epoch: 5| Step: 4
Training loss: 1.7822946530229202
Validation loss: 2.4496608101709576

Epoch: 5| Step: 5
Training loss: 1.1431999926946812
Validation loss: 2.456945740133103

Epoch: 5| Step: 6
Training loss: 1.682983996083444
Validation loss: 2.4683157332628345

Epoch: 5| Step: 7
Training loss: 1.5364275223395953
Validation loss: 2.50616280599908

Epoch: 5| Step: 8
Training loss: 1.3746098051425513
Validation loss: 2.477969428504615

Epoch: 5| Step: 9
Training loss: 1.1583786006471002
Validation loss: 2.515911894326229

Epoch: 5| Step: 10
Training loss: 1.1270317698098966
Validation loss: 2.506221647575037

Epoch: 276| Step: 0
Training loss: 1.472701499506869
Validation loss: 2.5062405406622106

Epoch: 5| Step: 1
Training loss: 1.810139006234966
Validation loss: 2.501058060286952

Epoch: 5| Step: 2
Training loss: 0.9022201519492418
Validation loss: 2.484890876569897

Epoch: 5| Step: 3
Training loss: 1.4780231497194376
Validation loss: 2.512570303236028

Epoch: 5| Step: 4
Training loss: 1.3173623164726718
Validation loss: 2.488277398789004

Epoch: 5| Step: 5
Training loss: 1.1324706515452523
Validation loss: 2.4874586590935475

Epoch: 5| Step: 6
Training loss: 1.4671116883472795
Validation loss: 2.494916358688533

Epoch: 5| Step: 7
Training loss: 1.6802621257737778
Validation loss: 2.49198085203208

Epoch: 5| Step: 8
Training loss: 1.59871148141327
Validation loss: 2.506432425802883

Epoch: 5| Step: 9
Training loss: 1.9791222082130537
Validation loss: 2.5140888994417376

Epoch: 5| Step: 10
Training loss: 0.8398804767473792
Validation loss: 2.507668648321026

Epoch: 277| Step: 0
Training loss: 1.6707969826464433
Validation loss: 2.503594644464032

Epoch: 5| Step: 1
Training loss: 1.2344514847249561
Validation loss: 2.5006702878126457

Epoch: 5| Step: 2
Training loss: 1.2172896610426072
Validation loss: 2.5002281484789326

Epoch: 5| Step: 3
Training loss: 1.6152152598863265
Validation loss: 2.5050380651398174

Epoch: 5| Step: 4
Training loss: 1.2221347074291882
Validation loss: 2.4905119931760877

Epoch: 5| Step: 5
Training loss: 1.487064374719308
Validation loss: 2.4972273166350285

Epoch: 5| Step: 6
Training loss: 1.6555753809462255
Validation loss: 2.4969204947903205

Epoch: 5| Step: 7
Training loss: 1.569920581096677
Validation loss: 2.541958445345154

Epoch: 5| Step: 8
Training loss: 1.111590148393175
Validation loss: 2.518870074716609

Epoch: 5| Step: 9
Training loss: 1.6637929062215318
Validation loss: 2.485295009858087

Epoch: 5| Step: 10
Training loss: 1.4584110057672919
Validation loss: 2.501520083377577

Epoch: 278| Step: 0
Training loss: 1.3387878528019967
Validation loss: 2.5438174268208464

Epoch: 5| Step: 1
Training loss: 0.9180754903865934
Validation loss: 2.52175514827004

Epoch: 5| Step: 2
Training loss: 1.5014395958243067
Validation loss: 2.5277357440139965

Epoch: 5| Step: 3
Training loss: 1.3943992573651314
Validation loss: 2.5391744246003003

Epoch: 5| Step: 4
Training loss: 1.372293322484811
Validation loss: 2.5827660336317937

Epoch: 5| Step: 5
Training loss: 1.6196434059448561
Validation loss: 2.5539862018981805

Epoch: 5| Step: 6
Training loss: 1.457634113350995
Validation loss: 2.5336775235302587

Epoch: 5| Step: 7
Training loss: 1.5593412896375056
Validation loss: 2.513531507202416

Epoch: 5| Step: 8
Training loss: 1.2694041496622535
Validation loss: 2.4966620660155114

Epoch: 5| Step: 9
Training loss: 1.3112797287006481
Validation loss: 2.4464339695783166

Epoch: 5| Step: 10
Training loss: 2.0675860031672597
Validation loss: 2.4597959246801584

Epoch: 279| Step: 0
Training loss: 1.3924817751474297
Validation loss: 2.459320396482959

Epoch: 5| Step: 1
Training loss: 1.309196037498839
Validation loss: 2.510128912766599

Epoch: 5| Step: 2
Training loss: 1.60758198233894
Validation loss: 2.488742184955847

Epoch: 5| Step: 3
Training loss: 1.7096264139961541
Validation loss: 2.510530341492832

Epoch: 5| Step: 4
Training loss: 1.159385450783897
Validation loss: 2.5304055526473466

Epoch: 5| Step: 5
Training loss: 1.2009769436594777
Validation loss: 2.5422286050066303

Epoch: 5| Step: 6
Training loss: 1.4697134226468274
Validation loss: 2.5505022553639036

Epoch: 5| Step: 7
Training loss: 1.8193992321165842
Validation loss: 2.570763604314132

Epoch: 5| Step: 8
Training loss: 1.394786052773279
Validation loss: 2.518825678002853

Epoch: 5| Step: 9
Training loss: 1.6268890111776377
Validation loss: 2.530636414145121

Epoch: 5| Step: 10
Training loss: 0.9374408703276798
Validation loss: 2.509699483173645

Epoch: 280| Step: 0
Training loss: 1.3300042713068014
Validation loss: 2.474595314667932

Epoch: 5| Step: 1
Training loss: 1.1955954023686948
Validation loss: 2.482986864178002

Epoch: 5| Step: 2
Training loss: 1.2552155880962412
Validation loss: 2.497272705059465

Epoch: 5| Step: 3
Training loss: 1.5968299725001498
Validation loss: 2.5145790607437064

Epoch: 5| Step: 4
Training loss: 1.3730490889334703
Validation loss: 2.5255702639538686

Epoch: 5| Step: 5
Training loss: 0.9642552731770101
Validation loss: 2.5213809715583637

Epoch: 5| Step: 6
Training loss: 1.592068851381454
Validation loss: 2.531493837195156

Epoch: 5| Step: 7
Training loss: 1.2735671931027412
Validation loss: 2.535285234389406

Epoch: 5| Step: 8
Training loss: 1.525479947843892
Validation loss: 2.526674460610284

Epoch: 5| Step: 9
Training loss: 1.701010274821292
Validation loss: 2.5390434856349655

Epoch: 5| Step: 10
Training loss: 1.7781289849798134
Validation loss: 2.506335444816279

Epoch: 281| Step: 0
Training loss: 1.2985236477878004
Validation loss: 2.4924066754324725

Epoch: 5| Step: 1
Training loss: 1.5801979274151479
Validation loss: 2.5116448471671178

Epoch: 5| Step: 2
Training loss: 1.5096233345282193
Validation loss: 2.4872764319975995

Epoch: 5| Step: 3
Training loss: 1.4599245200830075
Validation loss: 2.505190092851881

Epoch: 5| Step: 4
Training loss: 1.3847579202585596
Validation loss: 2.5030234369160156

Epoch: 5| Step: 5
Training loss: 1.536513565708683
Validation loss: 2.505933537456508

Epoch: 5| Step: 6
Training loss: 1.0933533085378437
Validation loss: 2.5098330939754048

Epoch: 5| Step: 7
Training loss: 1.2361034894320129
Validation loss: 2.5314461426857013

Epoch: 5| Step: 8
Training loss: 1.6365120331589598
Validation loss: 2.5099117802931135

Epoch: 5| Step: 9
Training loss: 1.1518872924910475
Validation loss: 2.5199609085979624

Epoch: 5| Step: 10
Training loss: 1.5534253388417845
Validation loss: 2.5074221414837803

Epoch: 282| Step: 0
Training loss: 1.4726795629786011
Validation loss: 2.498901876646498

Epoch: 5| Step: 1
Training loss: 1.4640880212014862
Validation loss: 2.4976036707882887

Epoch: 5| Step: 2
Training loss: 1.5873994149609632
Validation loss: 2.4815738163640586

Epoch: 5| Step: 3
Training loss: 1.4830244646427386
Validation loss: 2.480897019524462

Epoch: 5| Step: 4
Training loss: 1.2372564172399119
Validation loss: 2.490377867696676

Epoch: 5| Step: 5
Training loss: 1.3265125584272093
Validation loss: 2.496320876269056

Epoch: 5| Step: 6
Training loss: 0.9081777261443431
Validation loss: 2.498932214580687

Epoch: 5| Step: 7
Training loss: 1.7572037384460613
Validation loss: 2.5035613299498203

Epoch: 5| Step: 8
Training loss: 1.6132807327528302
Validation loss: 2.5262408403925884

Epoch: 5| Step: 9
Training loss: 1.0703204634989727
Validation loss: 2.5460620324725944

Epoch: 5| Step: 10
Training loss: 1.1765226643620983
Validation loss: 2.5528766784389143

Epoch: 283| Step: 0
Training loss: 1.1458049886260966
Validation loss: 2.572243135563736

Epoch: 5| Step: 1
Training loss: 1.1209204669442059
Validation loss: 2.5901674391206337

Epoch: 5| Step: 2
Training loss: 1.3043317024125873
Validation loss: 2.5642803599327237

Epoch: 5| Step: 3
Training loss: 1.5097528336194062
Validation loss: 2.533162528687976

Epoch: 5| Step: 4
Training loss: 1.7835492469826433
Validation loss: 2.502587141089814

Epoch: 5| Step: 5
Training loss: 1.496876643743389
Validation loss: 2.4904295995483263

Epoch: 5| Step: 6
Training loss: 1.1749649509315856
Validation loss: 2.4677889557573987

Epoch: 5| Step: 7
Training loss: 0.9481239441555835
Validation loss: 2.492611401322833

Epoch: 5| Step: 8
Training loss: 1.4256639406203284
Validation loss: 2.525133168776055

Epoch: 5| Step: 9
Training loss: 1.3336524829769736
Validation loss: 2.5082345205618637

Epoch: 5| Step: 10
Training loss: 1.8907335738855997
Validation loss: 2.5164183747261286

Epoch: 284| Step: 0
Training loss: 1.2630196115809034
Validation loss: 2.5367600944826885

Epoch: 5| Step: 1
Training loss: 1.3212015894138525
Validation loss: 2.5203023676936898

Epoch: 5| Step: 2
Training loss: 1.3510638954531973
Validation loss: 2.5022867204231996

Epoch: 5| Step: 3
Training loss: 1.7537269415668428
Validation loss: 2.5002642133003734

Epoch: 5| Step: 4
Training loss: 1.723222081684179
Validation loss: 2.4880859537385773

Epoch: 5| Step: 5
Training loss: 1.5320950725826008
Validation loss: 2.4646070678834073

Epoch: 5| Step: 6
Training loss: 1.3403955329902548
Validation loss: 2.5038180063505893

Epoch: 5| Step: 7
Training loss: 1.1035889187668844
Validation loss: 2.496363741528257

Epoch: 5| Step: 8
Training loss: 0.8499265933596172
Validation loss: 2.480807433496226

Epoch: 5| Step: 9
Training loss: 1.313454417215731
Validation loss: 2.5185676697824806

Epoch: 5| Step: 10
Training loss: 1.3372822735839818
Validation loss: 2.559019245086302

Epoch: 285| Step: 0
Training loss: 1.4929571912828083
Validation loss: 2.5558981200677344

Epoch: 5| Step: 1
Training loss: 1.7338397600609219
Validation loss: 2.5789120683073414

Epoch: 5| Step: 2
Training loss: 1.1162715438182007
Validation loss: 2.568543498482977

Epoch: 5| Step: 3
Training loss: 1.274525183733035
Validation loss: 2.5670321733530272

Epoch: 5| Step: 4
Training loss: 1.5835476613124702
Validation loss: 2.5174031766253573

Epoch: 5| Step: 5
Training loss: 1.3424009604124378
Validation loss: 2.5421878149959394

Epoch: 5| Step: 6
Training loss: 1.5800265950970538
Validation loss: 2.510714742040402

Epoch: 5| Step: 7
Training loss: 1.6463648344291868
Validation loss: 2.470514914037264

Epoch: 5| Step: 8
Training loss: 0.8231154012735892
Validation loss: 2.489884769703844

Epoch: 5| Step: 9
Training loss: 1.3341512059100809
Validation loss: 2.488870248209581

Epoch: 5| Step: 10
Training loss: 0.6582534725504726
Validation loss: 2.4806794913959314

Epoch: 286| Step: 0
Training loss: 1.3501774741889494
Validation loss: 2.499853303153387

Epoch: 5| Step: 1
Training loss: 1.4573590520949264
Validation loss: 2.4907837610334447

Epoch: 5| Step: 2
Training loss: 1.1522947139328412
Validation loss: 2.5350084050446076

Epoch: 5| Step: 3
Training loss: 1.4407120353572542
Validation loss: 2.537555889114474

Epoch: 5| Step: 4
Training loss: 1.3662733236906466
Validation loss: 2.534966556312041

Epoch: 5| Step: 5
Training loss: 1.4230115770417244
Validation loss: 2.5270789248381007

Epoch: 5| Step: 6
Training loss: 1.4168897995346246
Validation loss: 2.5129737551627396

Epoch: 5| Step: 7
Training loss: 1.2831801785488768
Validation loss: 2.502422373325371

Epoch: 5| Step: 8
Training loss: 1.2795966110277626
Validation loss: 2.5047943299820425

Epoch: 5| Step: 9
Training loss: 1.110200064732064
Validation loss: 2.511742466219253

Epoch: 5| Step: 10
Training loss: 1.6704306379599698
Validation loss: 2.4915116168626583

Epoch: 287| Step: 0
Training loss: 1.1643326209111895
Validation loss: 2.539460660323412

Epoch: 5| Step: 1
Training loss: 1.0150072419796112
Validation loss: 2.523580254711637

Epoch: 5| Step: 2
Training loss: 1.1599911145165924
Validation loss: 2.5148363262438855

Epoch: 5| Step: 3
Training loss: 1.4790152709564603
Validation loss: 2.535810682815322

Epoch: 5| Step: 4
Training loss: 1.6231704830103009
Validation loss: 2.52881823421635

Epoch: 5| Step: 5
Training loss: 1.6880714720424341
Validation loss: 2.5080693321417873

Epoch: 5| Step: 6
Training loss: 1.2158435987823986
Validation loss: 2.4956658622924164

Epoch: 5| Step: 7
Training loss: 1.4456234983971594
Validation loss: 2.474025133631102

Epoch: 5| Step: 8
Training loss: 1.0535051288018218
Validation loss: 2.4525423159333455

Epoch: 5| Step: 9
Training loss: 1.1381823369121118
Validation loss: 2.4805604431500807

Epoch: 5| Step: 10
Training loss: 1.6720890371626336
Validation loss: 2.46745928659638

Epoch: 288| Step: 0
Training loss: 1.2411174363785538
Validation loss: 2.5156392671769923

Epoch: 5| Step: 1
Training loss: 1.3085665116393248
Validation loss: 2.5188485263119307

Epoch: 5| Step: 2
Training loss: 1.3232019171974196
Validation loss: 2.5344486472335115

Epoch: 5| Step: 3
Training loss: 1.2549058489039495
Validation loss: 2.529273234187323

Epoch: 5| Step: 4
Training loss: 1.4981969487145044
Validation loss: 2.560289044889521

Epoch: 5| Step: 5
Training loss: 1.383177412774976
Validation loss: 2.5405615584952566

Epoch: 5| Step: 6
Training loss: 1.296512920896359
Validation loss: 2.5793338630061737

Epoch: 5| Step: 7
Training loss: 1.019847893780273
Validation loss: 2.531945985035151

Epoch: 5| Step: 8
Training loss: 1.1983736023660478
Validation loss: 2.566363970262065

Epoch: 5| Step: 9
Training loss: 1.5092505678179287
Validation loss: 2.573106215148625

Epoch: 5| Step: 10
Training loss: 1.6646718087234693
Validation loss: 2.538823631794421

Epoch: 289| Step: 0
Training loss: 1.252086376412873
Validation loss: 2.4920997826642077

Epoch: 5| Step: 1
Training loss: 1.1711038722643556
Validation loss: 2.490462402095526

Epoch: 5| Step: 2
Training loss: 1.3130994517742893
Validation loss: 2.4575042157227807

Epoch: 5| Step: 3
Training loss: 1.3856826565128637
Validation loss: 2.480891388781402

Epoch: 5| Step: 4
Training loss: 1.2311896256104562
Validation loss: 2.5345973329956712

Epoch: 5| Step: 5
Training loss: 1.319827605824247
Validation loss: 2.5410157430417564

Epoch: 5| Step: 6
Training loss: 1.2817178197771544
Validation loss: 2.566976805004015

Epoch: 5| Step: 7
Training loss: 1.6760892429399672
Validation loss: 2.5542063595382642

Epoch: 5| Step: 8
Training loss: 1.4731710733128476
Validation loss: 2.5320844663590707

Epoch: 5| Step: 9
Training loss: 1.0961702544416707
Validation loss: 2.5215030805235923

Epoch: 5| Step: 10
Training loss: 1.4170439255231937
Validation loss: 2.4692923449992144

Epoch: 290| Step: 0
Training loss: 1.1652928960761881
Validation loss: 2.457626519252528

Epoch: 5| Step: 1
Training loss: 1.4923397605666135
Validation loss: 2.4242465408777103

Epoch: 5| Step: 2
Training loss: 0.9512683106714079
Validation loss: 2.4327880882597834

Epoch: 5| Step: 3
Training loss: 1.429439919302276
Validation loss: 2.4472010320248456

Epoch: 5| Step: 4
Training loss: 1.2390254819711155
Validation loss: 2.514344537843535

Epoch: 5| Step: 5
Training loss: 1.3765887704998927
Validation loss: 2.51470502325186

Epoch: 5| Step: 6
Training loss: 0.9899443854499477
Validation loss: 2.5533969501107854

Epoch: 5| Step: 7
Training loss: 1.6244151456773548
Validation loss: 2.5934996372275796

Epoch: 5| Step: 8
Training loss: 1.4972514561142707
Validation loss: 2.645747287918512

Epoch: 5| Step: 9
Training loss: 1.5502096126704745
Validation loss: 2.6030281272130797

Epoch: 5| Step: 10
Training loss: 1.1980266796955947
Validation loss: 2.5739496133863726

Epoch: 291| Step: 0
Training loss: 1.423565624513156
Validation loss: 2.5342520035242226

Epoch: 5| Step: 1
Training loss: 1.2228545981690728
Validation loss: 2.494037715057473

Epoch: 5| Step: 2
Training loss: 1.2668700510840163
Validation loss: 2.475709469543051

Epoch: 5| Step: 3
Training loss: 1.2076940599332562
Validation loss: 2.4442438314880426

Epoch: 5| Step: 4
Training loss: 0.9663223797632533
Validation loss: 2.4566244060498885

Epoch: 5| Step: 5
Training loss: 1.1421579484991395
Validation loss: 2.4692850131589474

Epoch: 5| Step: 6
Training loss: 1.4892345189008234
Validation loss: 2.4954515477987447

Epoch: 5| Step: 7
Training loss: 1.6270737986787955
Validation loss: 2.4943931052793284

Epoch: 5| Step: 8
Training loss: 1.280652441845011
Validation loss: 2.54971523416039

Epoch: 5| Step: 9
Training loss: 1.378497184614946
Validation loss: 2.5674131600217365

Epoch: 5| Step: 10
Training loss: 1.451096297872144
Validation loss: 2.581524084055439

Epoch: 292| Step: 0
Training loss: 1.7174126710858972
Validation loss: 2.56880818162316

Epoch: 5| Step: 1
Training loss: 1.4291226464583069
Validation loss: 2.5699755288199913

Epoch: 5| Step: 2
Training loss: 1.5367182193943305
Validation loss: 2.5448516522979086

Epoch: 5| Step: 3
Training loss: 1.174033351736389
Validation loss: 2.5035408929235623

Epoch: 5| Step: 4
Training loss: 1.464895751030123
Validation loss: 2.467703901252882

Epoch: 5| Step: 5
Training loss: 1.4087081194172109
Validation loss: 2.473197744621216

Epoch: 5| Step: 6
Training loss: 1.173493450268418
Validation loss: 2.4297842673791963

Epoch: 5| Step: 7
Training loss: 1.2196004296865985
Validation loss: 2.4505649101634295

Epoch: 5| Step: 8
Training loss: 0.7122174154361756
Validation loss: 2.460729610206448

Epoch: 5| Step: 9
Training loss: 1.0910217044604942
Validation loss: 2.4934248093843894

Epoch: 5| Step: 10
Training loss: 1.206260212672193
Validation loss: 2.5115108897412677

Epoch: 293| Step: 0
Training loss: 1.38292133312505
Validation loss: 2.5537378014106973

Epoch: 5| Step: 1
Training loss: 1.2998659504955934
Validation loss: 2.592589086803515

Epoch: 5| Step: 2
Training loss: 1.2937870720605906
Validation loss: 2.612189020527395

Epoch: 5| Step: 3
Training loss: 1.3811633518710582
Validation loss: 2.6018698767963953

Epoch: 5| Step: 4
Training loss: 0.8463762524975394
Validation loss: 2.525038839151357

Epoch: 5| Step: 5
Training loss: 1.3571010292749237
Validation loss: 2.5233728798086354

Epoch: 5| Step: 6
Training loss: 1.194577558379534
Validation loss: 2.5000708323873133

Epoch: 5| Step: 7
Training loss: 1.574460827410117
Validation loss: 2.499711612762404

Epoch: 5| Step: 8
Training loss: 1.043834198622203
Validation loss: 2.492329988441577

Epoch: 5| Step: 9
Training loss: 1.3842376434177008
Validation loss: 2.482761591043716

Epoch: 5| Step: 10
Training loss: 1.4555028513150214
Validation loss: 2.4809973591035153

Epoch: 294| Step: 0
Training loss: 1.233069876721135
Validation loss: 2.501998987146013

Epoch: 5| Step: 1
Training loss: 1.111496629326326
Validation loss: 2.507319598756783

Epoch: 5| Step: 2
Training loss: 1.3551269012232339
Validation loss: 2.516998431753919

Epoch: 5| Step: 3
Training loss: 1.122924054934814
Validation loss: 2.523638271648914

Epoch: 5| Step: 4
Training loss: 0.9371924213663078
Validation loss: 2.484159666008613

Epoch: 5| Step: 5
Training loss: 1.1952305185964038
Validation loss: 2.5367910529040967

Epoch: 5| Step: 6
Training loss: 1.5690382156969616
Validation loss: 2.5130756249571005

Epoch: 5| Step: 7
Training loss: 1.6545743563173236
Validation loss: 2.5003625627356625

Epoch: 5| Step: 8
Training loss: 1.0719597385375685
Validation loss: 2.500386204165588

Epoch: 5| Step: 9
Training loss: 1.018881404335693
Validation loss: 2.5136512162502958

Epoch: 5| Step: 10
Training loss: 1.628150892875508
Validation loss: 2.514812979686596

Epoch: 295| Step: 0
Training loss: 1.2204433805685724
Validation loss: 2.460517414345526

Epoch: 5| Step: 1
Training loss: 1.19699208057942
Validation loss: 2.478150685298587

Epoch: 5| Step: 2
Training loss: 1.49378889344469
Validation loss: 2.448495722460086

Epoch: 5| Step: 3
Training loss: 1.487028140070514
Validation loss: 2.4820780812086283

Epoch: 5| Step: 4
Training loss: 1.106153188661172
Validation loss: 2.469118677733721

Epoch: 5| Step: 5
Training loss: 1.0007335237532815
Validation loss: 2.5124622871704316

Epoch: 5| Step: 6
Training loss: 1.2208087356658552
Validation loss: 2.468214430478308

Epoch: 5| Step: 7
Training loss: 1.3249472805547358
Validation loss: 2.5029894009098292

Epoch: 5| Step: 8
Training loss: 0.8664244998148394
Validation loss: 2.4956671175758727

Epoch: 5| Step: 9
Training loss: 0.8816580186310371
Validation loss: 2.563341812334618

Epoch: 5| Step: 10
Training loss: 1.9414779066527834
Validation loss: 2.571203105505124

Epoch: 296| Step: 0
Training loss: 1.2008839331896493
Validation loss: 2.543436280293237

Epoch: 5| Step: 1
Training loss: 1.339839612770922
Validation loss: 2.506752237524315

Epoch: 5| Step: 2
Training loss: 1.0918407124298282
Validation loss: 2.5300164619418344

Epoch: 5| Step: 3
Training loss: 1.0651824972112114
Validation loss: 2.525019886706508

Epoch: 5| Step: 4
Training loss: 1.4511364692486448
Validation loss: 2.506413033997092

Epoch: 5| Step: 5
Training loss: 1.3898131325894378
Validation loss: 2.4890629095747903

Epoch: 5| Step: 6
Training loss: 1.0396084032622495
Validation loss: 2.4872267434223194

Epoch: 5| Step: 7
Training loss: 1.4320330947056619
Validation loss: 2.5021180983573554

Epoch: 5| Step: 8
Training loss: 1.0108734487911062
Validation loss: 2.4827144947945894

Epoch: 5| Step: 9
Training loss: 1.3151428317690406
Validation loss: 2.491677204383755

Epoch: 5| Step: 10
Training loss: 1.4385049044114757
Validation loss: 2.5255990761566354

Epoch: 297| Step: 0
Training loss: 0.9289820904006307
Validation loss: 2.553005668785545

Epoch: 5| Step: 1
Training loss: 1.6570921142565447
Validation loss: 2.5649390989196825

Epoch: 5| Step: 2
Training loss: 1.0276919742944555
Validation loss: 2.5780914433726414

Epoch: 5| Step: 3
Training loss: 1.0910408801069345
Validation loss: 2.5681200243850033

Epoch: 5| Step: 4
Training loss: 1.3746446236949943
Validation loss: 2.5413656875218362

Epoch: 5| Step: 5
Training loss: 1.3260027366051836
Validation loss: 2.499746629734889

Epoch: 5| Step: 6
Training loss: 1.120600841238403
Validation loss: 2.4974208284210846

Epoch: 5| Step: 7
Training loss: 1.0154308426944525
Validation loss: 2.529353549613876

Epoch: 5| Step: 8
Training loss: 1.1710828010805616
Validation loss: 2.493373173606564

Epoch: 5| Step: 9
Training loss: 1.499601311151476
Validation loss: 2.5133148553531925

Epoch: 5| Step: 10
Training loss: 1.359661335221038
Validation loss: 2.4623773147306443

Epoch: 298| Step: 0
Training loss: 1.4730101951821222
Validation loss: 2.4802956389337467

Epoch: 5| Step: 1
Training loss: 1.563665489395296
Validation loss: 2.480836507742639

Epoch: 5| Step: 2
Training loss: 0.8298482060371154
Validation loss: 2.480553038165203

Epoch: 5| Step: 3
Training loss: 1.4578423990697735
Validation loss: 2.5036261455948976

Epoch: 5| Step: 4
Training loss: 0.9514897185555432
Validation loss: 2.5315006587247213

Epoch: 5| Step: 5
Training loss: 1.0570659239862445
Validation loss: 2.503743418761989

Epoch: 5| Step: 6
Training loss: 1.3988368140885272
Validation loss: 2.4787347671924147

Epoch: 5| Step: 7
Training loss: 0.9910667878365089
Validation loss: 2.5001339809858085

Epoch: 5| Step: 8
Training loss: 1.3922594302312374
Validation loss: 2.4700854931100156

Epoch: 5| Step: 9
Training loss: 1.1294646680455394
Validation loss: 2.4673577948732124

Epoch: 5| Step: 10
Training loss: 1.2073515433120041
Validation loss: 2.448630603019238

Epoch: 299| Step: 0
Training loss: 0.9508518879211494
Validation loss: 2.498390986400221

Epoch: 5| Step: 1
Training loss: 1.1152421246207593
Validation loss: 2.514107309211807

Epoch: 5| Step: 2
Training loss: 1.2303464798501829
Validation loss: 2.500023460278107

Epoch: 5| Step: 3
Training loss: 1.4546272961935298
Validation loss: 2.509854486896221

Epoch: 5| Step: 4
Training loss: 0.795152897736823
Validation loss: 2.5373088910389647

Epoch: 5| Step: 5
Training loss: 1.216843409742946
Validation loss: 2.517063832809303

Epoch: 5| Step: 6
Training loss: 1.0885626807610478
Validation loss: 2.5072326040805977

Epoch: 5| Step: 7
Training loss: 1.0608100353858045
Validation loss: 2.4663693824536406

Epoch: 5| Step: 8
Training loss: 1.7241535210726726
Validation loss: 2.4692510384849635

Epoch: 5| Step: 9
Training loss: 1.4086840016188624
Validation loss: 2.462476371542255

Epoch: 5| Step: 10
Training loss: 1.2920741187173734
Validation loss: 2.479574838074273

Epoch: 300| Step: 0
Training loss: 1.3811183400645635
Validation loss: 2.5175015662791553

Epoch: 5| Step: 1
Training loss: 1.1856903542386787
Validation loss: 2.542859459407031

Epoch: 5| Step: 2
Training loss: 1.2835742059706858
Validation loss: 2.5358415299955346

Epoch: 5| Step: 3
Training loss: 1.4733661589842293
Validation loss: 2.548809381633811

Epoch: 5| Step: 4
Training loss: 1.1429173675063975
Validation loss: 2.5441392888967505

Epoch: 5| Step: 5
Training loss: 0.9565921320994225
Validation loss: 2.5543822979598563

Epoch: 5| Step: 6
Training loss: 1.3889619977570944
Validation loss: 2.5660471222670385

Epoch: 5| Step: 7
Training loss: 0.9056397060255954
Validation loss: 2.5519134029614623

Epoch: 5| Step: 8
Training loss: 0.9799111897262279
Validation loss: 2.553727794737378

Epoch: 5| Step: 9
Training loss: 1.3411264757654378
Validation loss: 2.5247240509286684

Epoch: 5| Step: 10
Training loss: 1.2258440574178633
Validation loss: 2.5266630977392524

Epoch: 301| Step: 0
Training loss: 1.4378776054342137
Validation loss: 2.5256482904696043

Epoch: 5| Step: 1
Training loss: 0.5844574355053285
Validation loss: 2.497803409077214

Epoch: 5| Step: 2
Training loss: 1.161145132398897
Validation loss: 2.5111479254346643

Epoch: 5| Step: 3
Training loss: 1.7006568873737515
Validation loss: 2.480025991919053

Epoch: 5| Step: 4
Training loss: 1.0884797232250167
Validation loss: 2.4841414749641495

Epoch: 5| Step: 5
Training loss: 1.2728522424372657
Validation loss: 2.504800962210935

Epoch: 5| Step: 6
Training loss: 1.0323358079163953
Validation loss: 2.4847825992263792

Epoch: 5| Step: 7
Training loss: 0.9241549859256127
Validation loss: 2.5461997994237735

Epoch: 5| Step: 8
Training loss: 1.3466286099756517
Validation loss: 2.529178446742804

Epoch: 5| Step: 9
Training loss: 1.1111728982170397
Validation loss: 2.534430192018905

Epoch: 5| Step: 10
Training loss: 1.3350495181383153
Validation loss: 2.5161865581844305

Epoch: 302| Step: 0
Training loss: 1.3869417682819425
Validation loss: 2.5345958663800676

Epoch: 5| Step: 1
Training loss: 1.1935405187900372
Validation loss: 2.5106291117893806

Epoch: 5| Step: 2
Training loss: 1.0614284834378556
Validation loss: 2.534689885849698

Epoch: 5| Step: 3
Training loss: 0.9003286609304799
Validation loss: 2.5216319464026355

Epoch: 5| Step: 4
Training loss: 0.9014783400156628
Validation loss: 2.5271515637588937

Epoch: 5| Step: 5
Training loss: 1.0805589043882158
Validation loss: 2.5065430817262153

Epoch: 5| Step: 6
Training loss: 1.6774595877132943
Validation loss: 2.4987779501775544

Epoch: 5| Step: 7
Training loss: 0.9558126047631104
Validation loss: 2.4955750836963078

Epoch: 5| Step: 8
Training loss: 1.393529366448303
Validation loss: 2.506667622480077

Epoch: 5| Step: 9
Training loss: 1.1667797964740747
Validation loss: 2.5201704441355512

Epoch: 5| Step: 10
Training loss: 1.296257239590976
Validation loss: 2.5065438835851386

Epoch: 303| Step: 0
Training loss: 1.1879801532359124
Validation loss: 2.496283648416308

Epoch: 5| Step: 1
Training loss: 1.052730808004306
Validation loss: 2.5075118838888777

Epoch: 5| Step: 2
Training loss: 0.8716328069177797
Validation loss: 2.528666576232281

Epoch: 5| Step: 3
Training loss: 1.2297920424968998
Validation loss: 2.5230247337505616

Epoch: 5| Step: 4
Training loss: 1.2135812755664104
Validation loss: 2.5222105127013124

Epoch: 5| Step: 5
Training loss: 1.2236955509405114
Validation loss: 2.5491876179159125

Epoch: 5| Step: 6
Training loss: 0.8926775520089305
Validation loss: 2.4964651939068334

Epoch: 5| Step: 7
Training loss: 1.2856522272664166
Validation loss: 2.494049482517356

Epoch: 5| Step: 8
Training loss: 1.1928209254442228
Validation loss: 2.499916596200695

Epoch: 5| Step: 9
Training loss: 1.068492929873462
Validation loss: 2.5027503656106047

Epoch: 5| Step: 10
Training loss: 1.7772197973604398
Validation loss: 2.497963788795355

Epoch: 304| Step: 0
Training loss: 1.343391060018729
Validation loss: 2.472470914694365

Epoch: 5| Step: 1
Training loss: 0.9854724458280701
Validation loss: 2.4897691322084827

Epoch: 5| Step: 2
Training loss: 1.1166852342191143
Validation loss: 2.4693667813600086

Epoch: 5| Step: 3
Training loss: 0.5809945724548947
Validation loss: 2.4648471365060107

Epoch: 5| Step: 4
Training loss: 1.4220285856697517
Validation loss: 2.4744148500709993

Epoch: 5| Step: 5
Training loss: 1.3042127465018187
Validation loss: 2.4809528664208136

Epoch: 5| Step: 6
Training loss: 1.6548990462015791
Validation loss: 2.451304023022997

Epoch: 5| Step: 7
Training loss: 0.974549377674031
Validation loss: 2.4402313621272307

Epoch: 5| Step: 8
Training loss: 1.0531930578862883
Validation loss: 2.4545943645493913

Epoch: 5| Step: 9
Training loss: 1.102973629343135
Validation loss: 2.5040706129886567

Epoch: 5| Step: 10
Training loss: 1.1837140516323186
Validation loss: 2.5252561439902763

Epoch: 305| Step: 0
Training loss: 1.1049942777666746
Validation loss: 2.581658744156645

Epoch: 5| Step: 1
Training loss: 1.2715521587814755
Validation loss: 2.606240044605758

Epoch: 5| Step: 2
Training loss: 1.0875027579787788
Validation loss: 2.5733354863718825

Epoch: 5| Step: 3
Training loss: 1.2682340127067748
Validation loss: 2.5475736457891562

Epoch: 5| Step: 4
Training loss: 1.194324409136026
Validation loss: 2.507255398527671

Epoch: 5| Step: 5
Training loss: 1.2818018027414497
Validation loss: 2.4611619780875342

Epoch: 5| Step: 6
Training loss: 1.1198757347073014
Validation loss: 2.4528047017996024

Epoch: 5| Step: 7
Training loss: 1.5103718279617644
Validation loss: 2.463824919123128

Epoch: 5| Step: 8
Training loss: 1.1631458436798623
Validation loss: 2.4736223905714065

Epoch: 5| Step: 9
Training loss: 1.044059839916066
Validation loss: 2.516113250173879

Epoch: 5| Step: 10
Training loss: 0.8016569234397373
Validation loss: 2.506596920255759

Epoch: 306| Step: 0
Training loss: 0.9198679655116866
Validation loss: 2.570846869612765

Epoch: 5| Step: 1
Training loss: 1.2558275755657669
Validation loss: 2.579019972259993

Epoch: 5| Step: 2
Training loss: 1.3652858042273535
Validation loss: 2.5803913187408303

Epoch: 5| Step: 3
Training loss: 1.1592095619472031
Validation loss: 2.5536103790367193

Epoch: 5| Step: 4
Training loss: 1.113939432031728
Validation loss: 2.595891749011255

Epoch: 5| Step: 5
Training loss: 0.9808885200086934
Validation loss: 2.5458057574132797

Epoch: 5| Step: 6
Training loss: 0.7698423657134834
Validation loss: 2.508709057466481

Epoch: 5| Step: 7
Training loss: 1.1456821110668223
Validation loss: 2.4649090975117764

Epoch: 5| Step: 8
Training loss: 1.2948317920772043
Validation loss: 2.4243557707609393

Epoch: 5| Step: 9
Training loss: 1.6204395858675302
Validation loss: 2.404081150511079

Epoch: 5| Step: 10
Training loss: 1.0607183328361423
Validation loss: 2.4447765222273987

Epoch: 307| Step: 0
Training loss: 1.156475045237976
Validation loss: 2.4551670219798165

Epoch: 5| Step: 1
Training loss: 1.1837634477989463
Validation loss: 2.4790429525374

Epoch: 5| Step: 2
Training loss: 1.114282204898436
Validation loss: 2.538337051336306

Epoch: 5| Step: 3
Training loss: 1.6289807492424788
Validation loss: 2.6293548131573856

Epoch: 5| Step: 4
Training loss: 1.1588308553458415
Validation loss: 2.590773650782133

Epoch: 5| Step: 5
Training loss: 1.2983332329302362
Validation loss: 2.5915545712500343

Epoch: 5| Step: 6
Training loss: 0.918339625981459
Validation loss: 2.560326633755976

Epoch: 5| Step: 7
Training loss: 0.9858072548515538
Validation loss: 2.525061158120138

Epoch: 5| Step: 8
Training loss: 1.21588928762367
Validation loss: 2.533054686324633

Epoch: 5| Step: 9
Training loss: 0.7879429040982052
Validation loss: 2.5129920991409613

Epoch: 5| Step: 10
Training loss: 1.2719081283866258
Validation loss: 2.5168659520296055

Epoch: 308| Step: 0
Training loss: 1.179713368921663
Validation loss: 2.5240027337105713

Epoch: 5| Step: 1
Training loss: 0.9196983762429153
Validation loss: 2.5230388757642683

Epoch: 5| Step: 2
Training loss: 1.089645969396963
Validation loss: 2.5212132920049024

Epoch: 5| Step: 3
Training loss: 1.324617533994727
Validation loss: 2.520423911506962

Epoch: 5| Step: 4
Training loss: 1.2179714063379319
Validation loss: 2.5325911167164175

Epoch: 5| Step: 5
Training loss: 1.3711352654499787
Validation loss: 2.5504525280344503

Epoch: 5| Step: 6
Training loss: 1.0234690071672405
Validation loss: 2.5324713361971063

Epoch: 5| Step: 7
Training loss: 1.3998006644709438
Validation loss: 2.516981882100456

Epoch: 5| Step: 8
Training loss: 0.7530488984846277
Validation loss: 2.512306161659062

Epoch: 5| Step: 9
Training loss: 1.2690713372165894
Validation loss: 2.499796154571567

Epoch: 5| Step: 10
Training loss: 0.9676879167541699
Validation loss: 2.541140295730695

Epoch: 309| Step: 0
Training loss: 1.2805730845855323
Validation loss: 2.522427843701507

Epoch: 5| Step: 1
Training loss: 1.1397518839953382
Validation loss: 2.518677275485705

Epoch: 5| Step: 2
Training loss: 1.449071172310268
Validation loss: 2.532229046942398

Epoch: 5| Step: 3
Training loss: 1.0563034676105325
Validation loss: 2.5668798922886764

Epoch: 5| Step: 4
Training loss: 1.0801560441067584
Validation loss: 2.558213014196022

Epoch: 5| Step: 5
Training loss: 0.9160950063052372
Validation loss: 2.5181361364052504

Epoch: 5| Step: 6
Training loss: 1.6478464956410264
Validation loss: 2.5897737940690186

Epoch: 5| Step: 7
Training loss: 0.9250099735753321
Validation loss: 2.5472683220658325

Epoch: 5| Step: 8
Training loss: 0.7938401268681635
Validation loss: 2.551907299032108

Epoch: 5| Step: 9
Training loss: 0.6464323040140142
Validation loss: 2.5266195806869867

Epoch: 5| Step: 10
Training loss: 1.3312690769315165
Validation loss: 2.532797749014913

Epoch: 310| Step: 0
Training loss: 0.9411158766814145
Validation loss: 2.538757538130962

Epoch: 5| Step: 1
Training loss: 1.5199085541874027
Validation loss: 2.5318189705912437

Epoch: 5| Step: 2
Training loss: 1.0919962856138727
Validation loss: 2.5179986472932665

Epoch: 5| Step: 3
Training loss: 1.2232279553012566
Validation loss: 2.4991783791607936

Epoch: 5| Step: 4
Training loss: 1.1108049123113504
Validation loss: 2.4919942145099294

Epoch: 5| Step: 5
Training loss: 1.261994511847797
Validation loss: 2.519255821243356

Epoch: 5| Step: 6
Training loss: 1.3980440833081715
Validation loss: 2.4779738254365986

Epoch: 5| Step: 7
Training loss: 0.7392684955908446
Validation loss: 2.4913600273514733

Epoch: 5| Step: 8
Training loss: 0.852982098974062
Validation loss: 2.4767634145082145

Epoch: 5| Step: 9
Training loss: 1.1567063848526868
Validation loss: 2.4974792713580904

Epoch: 5| Step: 10
Training loss: 0.949898809765838
Validation loss: 2.492958828227276

Epoch: 311| Step: 0
Training loss: 0.9934220330641367
Validation loss: 2.526924367944917

Epoch: 5| Step: 1
Training loss: 0.8019047369018232
Validation loss: 2.531275632731783

Epoch: 5| Step: 2
Training loss: 1.024973582881014
Validation loss: 2.549521067114319

Epoch: 5| Step: 3
Training loss: 1.1435998765990065
Validation loss: 2.542866174834288

Epoch: 5| Step: 4
Training loss: 1.0429382319753853
Validation loss: 2.5739009396523835

Epoch: 5| Step: 5
Training loss: 0.9594629961842747
Validation loss: 2.556724043416475

Epoch: 5| Step: 6
Training loss: 1.109947486700624
Validation loss: 2.542439901085468

Epoch: 5| Step: 7
Training loss: 1.3619004829196926
Validation loss: 2.55963357966937

Epoch: 5| Step: 8
Training loss: 1.088055747083575
Validation loss: 2.5019466102303114

Epoch: 5| Step: 9
Training loss: 1.3276100506757522
Validation loss: 2.5149092372213895

Epoch: 5| Step: 10
Training loss: 1.4702056813532582
Validation loss: 2.5099243486707294

Epoch: 312| Step: 0
Training loss: 1.1776196374879409
Validation loss: 2.5013061833613754

Epoch: 5| Step: 1
Training loss: 1.21251241343328
Validation loss: 2.4649277263836367

Epoch: 5| Step: 2
Training loss: 1.1201907252655994
Validation loss: 2.5141916402245847

Epoch: 5| Step: 3
Training loss: 1.2267231441191222
Validation loss: 2.4847393082219615

Epoch: 5| Step: 4
Training loss: 1.1629388493593475
Validation loss: 2.502804972012117

Epoch: 5| Step: 5
Training loss: 1.1133330751369277
Validation loss: 2.4875068934887143

Epoch: 5| Step: 6
Training loss: 0.9852754319632109
Validation loss: 2.5271369050755155

Epoch: 5| Step: 7
Training loss: 1.2723726372225141
Validation loss: 2.5432108688894965

Epoch: 5| Step: 8
Training loss: 0.9619253709777058
Validation loss: 2.5217339447532887

Epoch: 5| Step: 9
Training loss: 1.251155033528209
Validation loss: 2.5539186335516053

Epoch: 5| Step: 10
Training loss: 0.6526755671145931
Validation loss: 2.510786544381115

Epoch: 313| Step: 0
Training loss: 1.0624404217340835
Validation loss: 2.5133271568085136

Epoch: 5| Step: 1
Training loss: 1.2124635985897776
Validation loss: 2.515088872556597

Epoch: 5| Step: 2
Training loss: 1.1611216731455527
Validation loss: 2.49537908589409

Epoch: 5| Step: 3
Training loss: 0.8717970126148767
Validation loss: 2.519805238539826

Epoch: 5| Step: 4
Training loss: 0.8265545547190017
Validation loss: 2.508963232111023

Epoch: 5| Step: 5
Training loss: 1.12678883642585
Validation loss: 2.5151292081387133

Epoch: 5| Step: 6
Training loss: 1.380026991345253
Validation loss: 2.504394130488308

Epoch: 5| Step: 7
Training loss: 1.293829593882197
Validation loss: 2.533952045871974

Epoch: 5| Step: 8
Training loss: 0.7368077100034569
Validation loss: 2.5637729363365365

Epoch: 5| Step: 9
Training loss: 1.388412730399357
Validation loss: 2.5407782268882353

Epoch: 5| Step: 10
Training loss: 1.017764786423815
Validation loss: 2.5512284928868065

Epoch: 314| Step: 0
Training loss: 0.9502297500062478
Validation loss: 2.550574945864284

Epoch: 5| Step: 1
Training loss: 1.1355002777858514
Validation loss: 2.552695138780709

Epoch: 5| Step: 2
Training loss: 1.0239872511502224
Validation loss: 2.528188549764953

Epoch: 5| Step: 3
Training loss: 1.0792463800945284
Validation loss: 2.496607934176706

Epoch: 5| Step: 4
Training loss: 0.9633335541743605
Validation loss: 2.4639432017453196

Epoch: 5| Step: 5
Training loss: 1.4935888929754004
Validation loss: 2.469071297372208

Epoch: 5| Step: 6
Training loss: 1.0925245231651994
Validation loss: 2.453513081373463

Epoch: 5| Step: 7
Training loss: 1.3113769085820846
Validation loss: 2.4732239157821923

Epoch: 5| Step: 8
Training loss: 0.4845816878829052
Validation loss: 2.4617761795250037

Epoch: 5| Step: 9
Training loss: 1.4117816634480376
Validation loss: 2.520909734259897

Epoch: 5| Step: 10
Training loss: 0.9736186096318642
Validation loss: 2.4913953849994357

Epoch: 315| Step: 0
Training loss: 1.0810326330180335
Validation loss: 2.5291871983731924

Epoch: 5| Step: 1
Training loss: 1.0641044395572845
Validation loss: 2.572534626869887

Epoch: 5| Step: 2
Training loss: 1.2470187876310093
Validation loss: 2.577456350616874

Epoch: 5| Step: 3
Training loss: 1.4092271443899573
Validation loss: 2.5782693811921265

Epoch: 5| Step: 4
Training loss: 0.7063818842198522
Validation loss: 2.5501198892642396

Epoch: 5| Step: 5
Training loss: 0.8934778732885919
Validation loss: 2.5571077589479545

Epoch: 5| Step: 6
Training loss: 1.556195931472039
Validation loss: 2.5214193061889487

Epoch: 5| Step: 7
Training loss: 0.7860312828701232
Validation loss: 2.52771496288105

Epoch: 5| Step: 8
Training loss: 1.0965230936974844
Validation loss: 2.5045705628213875

Epoch: 5| Step: 9
Training loss: 0.9133341242851768
Validation loss: 2.5213484472129792

Epoch: 5| Step: 10
Training loss: 1.1639600875146658
Validation loss: 2.5016003495819845

Epoch: 316| Step: 0
Training loss: 0.6753028102110736
Validation loss: 2.528252119064232

Epoch: 5| Step: 1
Training loss: 1.3929261017591181
Validation loss: 2.5071735991095134

Epoch: 5| Step: 2
Training loss: 1.0513549713269765
Validation loss: 2.5380622230011567

Epoch: 5| Step: 3
Training loss: 0.7292913648155065
Validation loss: 2.536104242788257

Epoch: 5| Step: 4
Training loss: 1.18524281657741
Validation loss: 2.5426056897599962

Epoch: 5| Step: 5
Training loss: 1.016344021322374
Validation loss: 2.548623756026451

Epoch: 5| Step: 6
Training loss: 0.987174216987434
Validation loss: 2.5031277379897454

Epoch: 5| Step: 7
Training loss: 1.3514848808094897
Validation loss: 2.519565934539227

Epoch: 5| Step: 8
Training loss: 1.0430845274939096
Validation loss: 2.503914606702632

Epoch: 5| Step: 9
Training loss: 1.188941983545634
Validation loss: 2.5197895471871665

Epoch: 5| Step: 10
Training loss: 1.1513192487965864
Validation loss: 2.4941805356629385

Epoch: 317| Step: 0
Training loss: 1.149094478026303
Validation loss: 2.4749279777825937

Epoch: 5| Step: 1
Training loss: 1.1795836143982898
Validation loss: 2.458527383363762

Epoch: 5| Step: 2
Training loss: 0.8211730076714269
Validation loss: 2.4424686910366815

Epoch: 5| Step: 3
Training loss: 1.00028230735358
Validation loss: 2.485454157518406

Epoch: 5| Step: 4
Training loss: 1.1981059823195923
Validation loss: 2.495713383884037

Epoch: 5| Step: 5
Training loss: 1.4292466781655009
Validation loss: 2.5172899774824833

Epoch: 5| Step: 6
Training loss: 0.8753214313850854
Validation loss: 2.5696173259336854

Epoch: 5| Step: 7
Training loss: 1.335985194018549
Validation loss: 2.5662099642356084

Epoch: 5| Step: 8
Training loss: 0.9093627745340761
Validation loss: 2.573791782202743

Epoch: 5| Step: 9
Training loss: 1.1278000001539679
Validation loss: 2.5554101418702344

Epoch: 5| Step: 10
Training loss: 0.514234198793434
Validation loss: 2.5621902274581405

Epoch: 318| Step: 0
Training loss: 1.3928337986006414
Validation loss: 2.5534796913896076

Epoch: 5| Step: 1
Training loss: 0.7870899131773168
Validation loss: 2.529209893782273

Epoch: 5| Step: 2
Training loss: 1.1983314238432703
Validation loss: 2.521174360405122

Epoch: 5| Step: 3
Training loss: 1.130025658442769
Validation loss: 2.5062235266610657

Epoch: 5| Step: 4
Training loss: 1.0230468703390487
Validation loss: 2.5037059403374933

Epoch: 5| Step: 5
Training loss: 1.3261433796356412
Validation loss: 2.52461395630599

Epoch: 5| Step: 6
Training loss: 1.0378268933353434
Validation loss: 2.4945935137602557

Epoch: 5| Step: 7
Training loss: 0.6567797339307954
Validation loss: 2.5276083384787467

Epoch: 5| Step: 8
Training loss: 1.0421555452723898
Validation loss: 2.533570911259163

Epoch: 5| Step: 9
Training loss: 1.2447748648601569
Validation loss: 2.5155333620314226

Epoch: 5| Step: 10
Training loss: 0.56251239762949
Validation loss: 2.502307498609583

Epoch: 319| Step: 0
Training loss: 0.817221056976744
Validation loss: 2.51746650604355

Epoch: 5| Step: 1
Training loss: 1.220580364921063
Validation loss: 2.527987866703297

Epoch: 5| Step: 2
Training loss: 1.1204324825632235
Validation loss: 2.488960241343254

Epoch: 5| Step: 3
Training loss: 0.970271392541215
Validation loss: 2.5427137168578624

Epoch: 5| Step: 4
Training loss: 0.9777914020704158
Validation loss: 2.5357524863955527

Epoch: 5| Step: 5
Training loss: 0.9092099095616373
Validation loss: 2.536213656682073

Epoch: 5| Step: 6
Training loss: 0.9610410494953663
Validation loss: 2.562288190009851

Epoch: 5| Step: 7
Training loss: 1.4664862211082788
Validation loss: 2.524386245721217

Epoch: 5| Step: 8
Training loss: 1.0474030600509827
Validation loss: 2.5130945787294867

Epoch: 5| Step: 9
Training loss: 1.2111218712024432
Validation loss: 2.546405456289663

Epoch: 5| Step: 10
Training loss: 0.8166106848764897
Validation loss: 2.5667308233089785

Epoch: 320| Step: 0
Training loss: 1.0232705132921147
Validation loss: 2.559115081305778

Epoch: 5| Step: 1
Training loss: 0.7538315731083979
Validation loss: 2.5326254989055452

Epoch: 5| Step: 2
Training loss: 1.0886497930580588
Validation loss: 2.5336367309332926

Epoch: 5| Step: 3
Training loss: 1.2694170621723875
Validation loss: 2.5135819547580853

Epoch: 5| Step: 4
Training loss: 0.9989977224551215
Validation loss: 2.501451823436203

Epoch: 5| Step: 5
Training loss: 0.702711916485663
Validation loss: 2.4990536129008722

Epoch: 5| Step: 6
Training loss: 0.9975921729771164
Validation loss: 2.465801297892925

Epoch: 5| Step: 7
Training loss: 1.0314759671568425
Validation loss: 2.5214695166272874

Epoch: 5| Step: 8
Training loss: 1.3654412588994158
Validation loss: 2.537538147534564

Epoch: 5| Step: 9
Training loss: 1.3067506934821487
Validation loss: 2.5470956203144293

Epoch: 5| Step: 10
Training loss: 0.941902125017989
Validation loss: 2.5834517185529116

Epoch: 321| Step: 0
Training loss: 1.000495430291076
Validation loss: 2.587976810307239

Epoch: 5| Step: 1
Training loss: 1.124672047179519
Validation loss: 2.5787365657567864

Epoch: 5| Step: 2
Training loss: 0.9313545667582533
Validation loss: 2.5946716339583484

Epoch: 5| Step: 3
Training loss: 1.1685020734599647
Validation loss: 2.5870127338359055

Epoch: 5| Step: 4
Training loss: 1.0478523019750712
Validation loss: 2.55491585733368

Epoch: 5| Step: 5
Training loss: 0.9238186406299949
Validation loss: 2.5295196821493864

Epoch: 5| Step: 6
Training loss: 1.03911974756388
Validation loss: 2.489472111322392

Epoch: 5| Step: 7
Training loss: 0.7391414575962191
Validation loss: 2.509904467010696

Epoch: 5| Step: 8
Training loss: 1.1272500636984206
Validation loss: 2.523786196562039

Epoch: 5| Step: 9
Training loss: 1.35448915114059
Validation loss: 2.545508700621597

Epoch: 5| Step: 10
Training loss: 1.0374432904474684
Validation loss: 2.5476167696949714

Epoch: 322| Step: 0
Training loss: 0.7872499099106312
Validation loss: 2.5331434690243433

Epoch: 5| Step: 1
Training loss: 1.2061920211377557
Validation loss: 2.5569052777227324

Epoch: 5| Step: 2
Training loss: 0.8556303455194162
Validation loss: 2.6122069469863156

Epoch: 5| Step: 3
Training loss: 1.032637327635274
Validation loss: 2.5914022824080956

Epoch: 5| Step: 4
Training loss: 1.171805163527814
Validation loss: 2.59180963779557

Epoch: 5| Step: 5
Training loss: 1.0434438359198723
Validation loss: 2.5555613187618222

Epoch: 5| Step: 6
Training loss: 1.0343395538249571
Validation loss: 2.4975334941436116

Epoch: 5| Step: 7
Training loss: 0.9265565161166026
Validation loss: 2.5090984535517284

Epoch: 5| Step: 8
Training loss: 0.7473791344313431
Validation loss: 2.533826597531048

Epoch: 5| Step: 9
Training loss: 1.1520514683286076
Validation loss: 2.490988642432696

Epoch: 5| Step: 10
Training loss: 1.4368030683076887
Validation loss: 2.5350828686156657

Epoch: 323| Step: 0
Training loss: 1.1277054468824224
Validation loss: 2.527106986895373

Epoch: 5| Step: 1
Training loss: 0.7789718217711501
Validation loss: 2.5234497114718035

Epoch: 5| Step: 2
Training loss: 1.1558868765903063
Validation loss: 2.513065206442105

Epoch: 5| Step: 3
Training loss: 0.6882857903840626
Validation loss: 2.535288238110602

Epoch: 5| Step: 4
Training loss: 0.865371142184695
Validation loss: 2.5239695910590054

Epoch: 5| Step: 5
Training loss: 1.44964428846522
Validation loss: 2.5195991330812606

Epoch: 5| Step: 6
Training loss: 1.154345980921287
Validation loss: 2.4906887110163685

Epoch: 5| Step: 7
Training loss: 1.0603082715126402
Validation loss: 2.4815682326118718

Epoch: 5| Step: 8
Training loss: 1.0633928810733675
Validation loss: 2.503626078524795

Epoch: 5| Step: 9
Training loss: 1.0269680714236011
Validation loss: 2.531843770302306

Epoch: 5| Step: 10
Training loss: 0.8867688942061327
Validation loss: 2.597307191709535

Epoch: 324| Step: 0
Training loss: 0.7233769714871771
Validation loss: 2.623894071268164

Epoch: 5| Step: 1
Training loss: 1.0191084763473957
Validation loss: 2.60902739261598

Epoch: 5| Step: 2
Training loss: 0.8039240502406293
Validation loss: 2.606077107908393

Epoch: 5| Step: 3
Training loss: 0.663897392840523
Validation loss: 2.591267099736184

Epoch: 5| Step: 4
Training loss: 1.2832704755738809
Validation loss: 2.5514926065165557

Epoch: 5| Step: 5
Training loss: 1.1228446446655376
Validation loss: 2.518225881811067

Epoch: 5| Step: 6
Training loss: 1.1943363367487068
Validation loss: 2.497956670422838

Epoch: 5| Step: 7
Training loss: 0.9913121965673742
Validation loss: 2.4849531022597136

Epoch: 5| Step: 8
Training loss: 1.324865087802294
Validation loss: 2.4962647374814453

Epoch: 5| Step: 9
Training loss: 1.1697442583830628
Validation loss: 2.4935001713742597

Epoch: 5| Step: 10
Training loss: 0.8709547333916614
Validation loss: 2.4658857651272683

Epoch: 325| Step: 0
Training loss: 1.050494300205867
Validation loss: 2.4926225918474794

Epoch: 5| Step: 1
Training loss: 1.1332446096322806
Validation loss: 2.5453473543861627

Epoch: 5| Step: 2
Training loss: 0.6787365147004474
Validation loss: 2.512137106413973

Epoch: 5| Step: 3
Training loss: 0.6217223291516971
Validation loss: 2.5355971468532505

Epoch: 5| Step: 4
Training loss: 0.9839942740820391
Validation loss: 2.560932188033491

Epoch: 5| Step: 5
Training loss: 1.4489160103265022
Validation loss: 2.5451510480942936

Epoch: 5| Step: 6
Training loss: 0.7748451908911269
Validation loss: 2.5276343296563173

Epoch: 5| Step: 7
Training loss: 1.1262263924922005
Validation loss: 2.5180906689570173

Epoch: 5| Step: 8
Training loss: 1.118258623014447
Validation loss: 2.5147636211174196

Epoch: 5| Step: 9
Training loss: 0.9154492805261029
Validation loss: 2.527010654279178

Epoch: 5| Step: 10
Training loss: 1.1937640763496404
Validation loss: 2.52177860337896

Epoch: 326| Step: 0
Training loss: 1.1812981227377068
Validation loss: 2.5300320868269393

Epoch: 5| Step: 1
Training loss: 1.226422392988841
Validation loss: 2.5156959213382235

Epoch: 5| Step: 2
Training loss: 1.2101497918406698
Validation loss: 2.5403152452367195

Epoch: 5| Step: 3
Training loss: 1.1375050659905273
Validation loss: 2.5581791643071297

Epoch: 5| Step: 4
Training loss: 0.7121258958165066
Validation loss: 2.5460969697959306

Epoch: 5| Step: 5
Training loss: 1.1116755634640059
Validation loss: 2.5446066479477985

Epoch: 5| Step: 6
Training loss: 0.6146727162897474
Validation loss: 2.605796161084792

Epoch: 5| Step: 7
Training loss: 0.9365965940922244
Validation loss: 2.5440753240246607

Epoch: 5| Step: 8
Training loss: 1.0817752907222966
Validation loss: 2.5469403606105603

Epoch: 5| Step: 9
Training loss: 0.9769578362389059
Validation loss: 2.589583195897442

Epoch: 5| Step: 10
Training loss: 0.7816778156024964
Validation loss: 2.5282786461064988

Epoch: 327| Step: 0
Training loss: 0.8094989666946913
Validation loss: 2.5418441773682408

Epoch: 5| Step: 1
Training loss: 0.8643974234540387
Validation loss: 2.5110512582702076

Epoch: 5| Step: 2
Training loss: 1.3565300296394018
Validation loss: 2.4861087859404813

Epoch: 5| Step: 3
Training loss: 1.428911342371923
Validation loss: 2.516068380949777

Epoch: 5| Step: 4
Training loss: 0.4882395459485228
Validation loss: 2.5376937551786574

Epoch: 5| Step: 5
Training loss: 1.0854879313166585
Validation loss: 2.5602852539305854

Epoch: 5| Step: 6
Training loss: 0.8520988734972612
Validation loss: 2.5873269449924092

Epoch: 5| Step: 7
Training loss: 1.0558753212456018
Validation loss: 2.5894224277372766

Epoch: 5| Step: 8
Training loss: 1.0769601140229614
Validation loss: 2.6082695288351743

Epoch: 5| Step: 9
Training loss: 0.9904668410969296
Validation loss: 2.6468701032203

Epoch: 5| Step: 10
Training loss: 0.921901896456154
Validation loss: 2.6527094911047455

Epoch: 328| Step: 0
Training loss: 1.3234789196680332
Validation loss: 2.6130434986331976

Epoch: 5| Step: 1
Training loss: 0.9359278530330577
Validation loss: 2.5614188810192675

Epoch: 5| Step: 2
Training loss: 0.7399160057804172
Validation loss: 2.5385854843767603

Epoch: 5| Step: 3
Training loss: 1.0984753576404815
Validation loss: 2.552597536207309

Epoch: 5| Step: 4
Training loss: 1.1894972218324305
Validation loss: 2.4938824036433362

Epoch: 5| Step: 5
Training loss: 0.5596004298228944
Validation loss: 2.542870950529685

Epoch: 5| Step: 6
Training loss: 0.9570803882673692
Validation loss: 2.609398381280315

Epoch: 5| Step: 7
Training loss: 0.652055939554993
Validation loss: 2.63416087762814

Epoch: 5| Step: 8
Training loss: 0.8703536237934782
Validation loss: 2.6270658506138442

Epoch: 5| Step: 9
Training loss: 1.2959523883274355
Validation loss: 2.620619001512404

Epoch: 5| Step: 10
Training loss: 1.1746636335338816
Validation loss: 2.6520190617962327

Epoch: 329| Step: 0
Training loss: 1.0007261977289517
Validation loss: 2.586940910129338

Epoch: 5| Step: 1
Training loss: 1.0400384893997834
Validation loss: 2.5791656372740457

Epoch: 5| Step: 2
Training loss: 1.0809409918264128
Validation loss: 2.589001189401982

Epoch: 5| Step: 3
Training loss: 0.7765722231956602
Validation loss: 2.545755026483572

Epoch: 5| Step: 4
Training loss: 0.8899818239606276
Validation loss: 2.4962742550994848

Epoch: 5| Step: 5
Training loss: 1.0044176750873275
Validation loss: 2.516890929634659

Epoch: 5| Step: 6
Training loss: 0.8124395494714731
Validation loss: 2.488185057575151

Epoch: 5| Step: 7
Training loss: 1.2665745975679952
Validation loss: 2.5561997954152633

Epoch: 5| Step: 8
Training loss: 0.43054986594484557
Validation loss: 2.530020004401546

Epoch: 5| Step: 9
Training loss: 1.2392147648927272
Validation loss: 2.5517835376103144

Epoch: 5| Step: 10
Training loss: 1.140734575834882
Validation loss: 2.59038736207491

Epoch: 330| Step: 0
Training loss: 0.9089123325626374
Validation loss: 2.544322274821041

Epoch: 5| Step: 1
Training loss: 0.8783180472607929
Validation loss: 2.52778777926197

Epoch: 5| Step: 2
Training loss: 1.1410792765612932
Validation loss: 2.521884659997974

Epoch: 5| Step: 3
Training loss: 0.8630934290874798
Validation loss: 2.5061814120873653

Epoch: 5| Step: 4
Training loss: 0.9639651356007688
Validation loss: 2.520953951900599

Epoch: 5| Step: 5
Training loss: 0.5330518011754192
Validation loss: 2.539466089525295

Epoch: 5| Step: 6
Training loss: 1.1014747314117554
Validation loss: 2.5201427554853844

Epoch: 5| Step: 7
Training loss: 1.0497889034060504
Validation loss: 2.5632380691430057

Epoch: 5| Step: 8
Training loss: 0.7569018525983787
Validation loss: 2.5274826062124296

Epoch: 5| Step: 9
Training loss: 1.0440085153743983
Validation loss: 2.559935560389596

Epoch: 5| Step: 10
Training loss: 1.4858697693287355
Validation loss: 2.55736198919233

Epoch: 331| Step: 0
Training loss: 1.152127003086398
Validation loss: 2.5434902198296565

Epoch: 5| Step: 1
Training loss: 0.991689902655805
Validation loss: 2.5643797212128434

Epoch: 5| Step: 2
Training loss: 0.941087154268411
Validation loss: 2.557560387415106

Epoch: 5| Step: 3
Training loss: 0.9649061113351205
Validation loss: 2.512916253577011

Epoch: 5| Step: 4
Training loss: 0.923709498848083
Validation loss: 2.513733919580475

Epoch: 5| Step: 5
Training loss: 0.997024579918841
Validation loss: 2.510169741676885

Epoch: 5| Step: 6
Training loss: 1.0277445196378179
Validation loss: 2.5144720832336747

Epoch: 5| Step: 7
Training loss: 0.6549831605886938
Validation loss: 2.5469766386794013

Epoch: 5| Step: 8
Training loss: 1.2245426920329099
Validation loss: 2.5384384410658396

Epoch: 5| Step: 9
Training loss: 0.7209968278579664
Validation loss: 2.527714670787774

Epoch: 5| Step: 10
Training loss: 1.1543823313828794
Validation loss: 2.537789023630668

Epoch: 332| Step: 0
Training loss: 0.6373977551091272
Validation loss: 2.540681429325368

Epoch: 5| Step: 1
Training loss: 0.83112188800442
Validation loss: 2.5608130443914754

Epoch: 5| Step: 2
Training loss: 1.1532226314410616
Validation loss: 2.5616887276773603

Epoch: 5| Step: 3
Training loss: 1.0288482209383
Validation loss: 2.54157167200351

Epoch: 5| Step: 4
Training loss: 0.5395582379822682
Validation loss: 2.541019784707475

Epoch: 5| Step: 5
Training loss: 0.8520764191276248
Validation loss: 2.5298361235685882

Epoch: 5| Step: 6
Training loss: 1.3400665186982819
Validation loss: 2.5770390276449797

Epoch: 5| Step: 7
Training loss: 1.2621436097612155
Validation loss: 2.5692243838968576

Epoch: 5| Step: 8
Training loss: 1.0651532871450788
Validation loss: 2.5829643842137546

Epoch: 5| Step: 9
Training loss: 0.8188688381232843
Validation loss: 2.6313626019822327

Epoch: 5| Step: 10
Training loss: 1.0698834415481158
Validation loss: 2.6335285613108526

Epoch: 333| Step: 0
Training loss: 1.0424738363372157
Validation loss: 2.621135351345032

Epoch: 5| Step: 1
Training loss: 1.0725618658473488
Validation loss: 2.6011502459935385

Epoch: 5| Step: 2
Training loss: 0.7834783817149746
Validation loss: 2.556529878214268

Epoch: 5| Step: 3
Training loss: 1.1792952535946022
Validation loss: 2.519842275564115

Epoch: 5| Step: 4
Training loss: 0.7749173427925753
Validation loss: 2.475374825638755

Epoch: 5| Step: 5
Training loss: 0.881494770822145
Validation loss: 2.484916558847929

Epoch: 5| Step: 6
Training loss: 0.9539180333115032
Validation loss: 2.480713261496804

Epoch: 5| Step: 7
Training loss: 0.7408591580332786
Validation loss: 2.50828591070486

Epoch: 5| Step: 8
Training loss: 1.1503697961757737
Validation loss: 2.5020527467081424

Epoch: 5| Step: 9
Training loss: 1.2034131980627463
Validation loss: 2.5132035377052

Epoch: 5| Step: 10
Training loss: 0.7381140302574547
Validation loss: 2.5279629419514853

Epoch: 334| Step: 0
Training loss: 0.6709356839031485
Validation loss: 2.5210598286474797

Epoch: 5| Step: 1
Training loss: 0.7292075463597657
Validation loss: 2.5211913152024157

Epoch: 5| Step: 2
Training loss: 0.9871036917338311
Validation loss: 2.553301277039204

Epoch: 5| Step: 3
Training loss: 0.7191646457951671
Validation loss: 2.548839728015035

Epoch: 5| Step: 4
Training loss: 1.172921539937946
Validation loss: 2.536011266431286

Epoch: 5| Step: 5
Training loss: 0.7151914907669299
Validation loss: 2.5443658548487185

Epoch: 5| Step: 6
Training loss: 0.9976209115959223
Validation loss: 2.528342591347973

Epoch: 5| Step: 7
Training loss: 0.9721115915993179
Validation loss: 2.535225239609194

Epoch: 5| Step: 8
Training loss: 1.075526159733598
Validation loss: 2.5291465467227208

Epoch: 5| Step: 9
Training loss: 0.8631702541611415
Validation loss: 2.571072383787637

Epoch: 5| Step: 10
Training loss: 1.5339499045924525
Validation loss: 2.5467553356290007

Epoch: 335| Step: 0
Training loss: 1.2685417662117382
Validation loss: 2.5852990413920884

Epoch: 5| Step: 1
Training loss: 0.8840989386289068
Validation loss: 2.5759918576161343

Epoch: 5| Step: 2
Training loss: 0.7907594242336368
Validation loss: 2.569756264756584

Epoch: 5| Step: 3
Training loss: 0.9196509349007936
Validation loss: 2.530556036607432

Epoch: 5| Step: 4
Training loss: 0.8419786863189187
Validation loss: 2.5277397125925773

Epoch: 5| Step: 5
Training loss: 0.5783459782340278
Validation loss: 2.5017603183465265

Epoch: 5| Step: 6
Training loss: 0.759693093257699
Validation loss: 2.486949305888494

Epoch: 5| Step: 7
Training loss: 1.0491284840740818
Validation loss: 2.4673215831095843

Epoch: 5| Step: 8
Training loss: 0.8800895354931901
Validation loss: 2.471905594094479

Epoch: 5| Step: 9
Training loss: 1.3295462240796356
Validation loss: 2.4715099076662703

Epoch: 5| Step: 10
Training loss: 0.9825156984215601
Validation loss: 2.4419622161825356

Epoch: 336| Step: 0
Training loss: 0.49027809768782793
Validation loss: 2.4758573473896766

Epoch: 5| Step: 1
Training loss: 1.102240712130811
Validation loss: 2.463485951979411

Epoch: 5| Step: 2
Training loss: 1.2551556123712668
Validation loss: 2.5075884347628494

Epoch: 5| Step: 3
Training loss: 0.8979321924683208
Validation loss: 2.5281125445773798

Epoch: 5| Step: 4
Training loss: 0.7228212735195704
Validation loss: 2.6228799389094157

Epoch: 5| Step: 5
Training loss: 1.1944811055128948
Validation loss: 2.6178891770183763

Epoch: 5| Step: 6
Training loss: 0.804000042336496
Validation loss: 2.6521944060186695

Epoch: 5| Step: 7
Training loss: 1.1849282172951288
Validation loss: 2.6213625068690223

Epoch: 5| Step: 8
Training loss: 0.6322591033753809
Validation loss: 2.5791143960705645

Epoch: 5| Step: 9
Training loss: 0.9116258340149421
Validation loss: 2.5192448273808807

Epoch: 5| Step: 10
Training loss: 1.0256702441476595
Validation loss: 2.5100034988935214

Epoch: 337| Step: 0
Training loss: 0.9097501315299974
Validation loss: 2.4857229790011117

Epoch: 5| Step: 1
Training loss: 0.6867556009831445
Validation loss: 2.491330338105628

Epoch: 5| Step: 2
Training loss: 0.9200175047328679
Validation loss: 2.4799524921265714

Epoch: 5| Step: 3
Training loss: 1.4089274454949787
Validation loss: 2.542955013196648

Epoch: 5| Step: 4
Training loss: 1.0606333098482221
Validation loss: 2.5538653097792183

Epoch: 5| Step: 5
Training loss: 0.9169975499980483
Validation loss: 2.5544851212340256

Epoch: 5| Step: 6
Training loss: 0.6893928220490869
Validation loss: 2.5717486362038033

Epoch: 5| Step: 7
Training loss: 0.9221030131114666
Validation loss: 2.551071798947505

Epoch: 5| Step: 8
Training loss: 0.41513699442033897
Validation loss: 2.5403835704863367

Epoch: 5| Step: 9
Training loss: 1.178007483249723
Validation loss: 2.5418292120874937

Epoch: 5| Step: 10
Training loss: 0.8253735953513589
Validation loss: 2.50659516929442

Epoch: 338| Step: 0
Training loss: 0.8127042807020269
Validation loss: 2.498660806652208

Epoch: 5| Step: 1
Training loss: 0.8702459272197836
Validation loss: 2.5285731738030193

Epoch: 5| Step: 2
Training loss: 0.7339006880739685
Validation loss: 2.4785923060264365

Epoch: 5| Step: 3
Training loss: 1.0929205883177306
Validation loss: 2.533900815580729

Epoch: 5| Step: 4
Training loss: 0.7166586178689875
Validation loss: 2.5384533970489027

Epoch: 5| Step: 5
Training loss: 1.038818043799526
Validation loss: 2.5926477190616635

Epoch: 5| Step: 6
Training loss: 0.684376404817437
Validation loss: 2.5997579688716503

Epoch: 5| Step: 7
Training loss: 0.9727645874968868
Validation loss: 2.6301492155423265

Epoch: 5| Step: 8
Training loss: 0.8273881837261586
Validation loss: 2.56586543337993

Epoch: 5| Step: 9
Training loss: 1.19397985432433
Validation loss: 2.5742134887038035

Epoch: 5| Step: 10
Training loss: 1.1464329046754047
Validation loss: 2.5699032394317354

Epoch: 339| Step: 0
Training loss: 0.6575862132868145
Validation loss: 2.5496101512082077

Epoch: 5| Step: 1
Training loss: 0.7646934135529495
Validation loss: 2.5066978367686263

Epoch: 5| Step: 2
Training loss: 0.7849492042046144
Validation loss: 2.5323148386897456

Epoch: 5| Step: 3
Training loss: 1.2218347294017673
Validation loss: 2.522467867812069

Epoch: 5| Step: 4
Training loss: 1.2349270901799436
Validation loss: 2.539709247921819

Epoch: 5| Step: 5
Training loss: 0.5950675450381495
Validation loss: 2.5248412270074208

Epoch: 5| Step: 6
Training loss: 0.6738275942593018
Validation loss: 2.551929609044069

Epoch: 5| Step: 7
Training loss: 1.052684379338825
Validation loss: 2.56280178450977

Epoch: 5| Step: 8
Training loss: 0.9415777532973342
Validation loss: 2.5595403567639043

Epoch: 5| Step: 9
Training loss: 0.9394172772648316
Validation loss: 2.570646590760965

Epoch: 5| Step: 10
Training loss: 0.9767274030693601
Validation loss: 2.598418429734032

Epoch: 340| Step: 0
Training loss: 0.9610916262203015
Validation loss: 2.5685871276725987

Epoch: 5| Step: 1
Training loss: 1.0351469219435254
Validation loss: 2.522875593576327

Epoch: 5| Step: 2
Training loss: 1.1387188281787313
Validation loss: 2.5370234735620327

Epoch: 5| Step: 3
Training loss: 0.7409234777416454
Validation loss: 2.507162263402906

Epoch: 5| Step: 4
Training loss: 0.7977535416378926
Validation loss: 2.5308308823462373

Epoch: 5| Step: 5
Training loss: 1.0662473902608902
Validation loss: 2.51585059943191

Epoch: 5| Step: 6
Training loss: 0.8020806168018925
Validation loss: 2.5485450749336644

Epoch: 5| Step: 7
Training loss: 0.6974109957592037
Validation loss: 2.5728611452919923

Epoch: 5| Step: 8
Training loss: 0.9967893976271484
Validation loss: 2.555323179204172

Epoch: 5| Step: 9
Training loss: 0.9204539969043403
Validation loss: 2.5752038808668862

Epoch: 5| Step: 10
Training loss: 0.7185240265924439
Validation loss: 2.6307016311945466

Epoch: 341| Step: 0
Training loss: 1.1015251640323338
Validation loss: 2.573945703107505

Epoch: 5| Step: 1
Training loss: 0.5268158142043523
Validation loss: 2.600164653125403

Epoch: 5| Step: 2
Training loss: 0.7226035846386899
Validation loss: 2.638331655776023

Epoch: 5| Step: 3
Training loss: 1.1611858897995426
Validation loss: 2.5877694325193117

Epoch: 5| Step: 4
Training loss: 0.8463996327243469
Validation loss: 2.5645697363904554

Epoch: 5| Step: 5
Training loss: 0.8655914534255272
Validation loss: 2.5454684053070857

Epoch: 5| Step: 6
Training loss: 0.6940315319711519
Validation loss: 2.5583621516048765

Epoch: 5| Step: 7
Training loss: 1.253879154661253
Validation loss: 2.536400448257241

Epoch: 5| Step: 8
Training loss: 0.8582546907958448
Validation loss: 2.5406131912976364

Epoch: 5| Step: 9
Training loss: 0.7579806819582899
Validation loss: 2.5453085542276077

Epoch: 5| Step: 10
Training loss: 0.8460580904588513
Validation loss: 2.565677854303724

Epoch: 342| Step: 0
Training loss: 1.0627092828517657
Validation loss: 2.5713791421715633

Epoch: 5| Step: 1
Training loss: 0.574955811046504
Validation loss: 2.5235418370961527

Epoch: 5| Step: 2
Training loss: 0.9879565402870263
Validation loss: 2.553547051485201

Epoch: 5| Step: 3
Training loss: 0.8161445453749676
Validation loss: 2.530049479784317

Epoch: 5| Step: 4
Training loss: 0.4966156684638258
Validation loss: 2.522162227424691

Epoch: 5| Step: 5
Training loss: 1.3348520788472984
Validation loss: 2.5516410109481353

Epoch: 5| Step: 6
Training loss: 0.5417777522204617
Validation loss: 2.5183001432732364

Epoch: 5| Step: 7
Training loss: 1.033848811343117
Validation loss: 2.5232343247448092

Epoch: 5| Step: 8
Training loss: 1.089977789398826
Validation loss: 2.545123783309181

Epoch: 5| Step: 9
Training loss: 0.6759988511628766
Validation loss: 2.538445984208564

Epoch: 5| Step: 10
Training loss: 0.7893647096737905
Validation loss: 2.5366817174781957

Epoch: 343| Step: 0
Training loss: 1.0461050020144071
Validation loss: 2.5264884943421935

Epoch: 5| Step: 1
Training loss: 1.0438197518072747
Validation loss: 2.536843222001933

Epoch: 5| Step: 2
Training loss: 1.1186353464887482
Validation loss: 2.5491195341766613

Epoch: 5| Step: 3
Training loss: 0.8480865159998466
Validation loss: 2.552254625155102

Epoch: 5| Step: 4
Training loss: 0.6538141092262925
Validation loss: 2.536755164788628

Epoch: 5| Step: 5
Training loss: 0.7922719515416313
Validation loss: 2.5613785307325343

Epoch: 5| Step: 6
Training loss: 0.670093325371028
Validation loss: 2.5807897236285413

Epoch: 5| Step: 7
Training loss: 1.0245189631221152
Validation loss: 2.569890123438661

Epoch: 5| Step: 8
Training loss: 0.9007432623576027
Validation loss: 2.6006198958917426

Epoch: 5| Step: 9
Training loss: 0.6737369420373289
Validation loss: 2.5591321042996813

Epoch: 5| Step: 10
Training loss: 0.8689563341528547
Validation loss: 2.5743716395867735

Epoch: 344| Step: 0
Training loss: 0.6432961623376972
Validation loss: 2.575011481460508

Epoch: 5| Step: 1
Training loss: 0.9819219086803957
Validation loss: 2.5507694728982524

Epoch: 5| Step: 2
Training loss: 0.7481368287186299
Validation loss: 2.5844382253030105

Epoch: 5| Step: 3
Training loss: 0.8782565958376426
Validation loss: 2.5929305651117214

Epoch: 5| Step: 4
Training loss: 0.9823530108544868
Validation loss: 2.5830872709946506

Epoch: 5| Step: 5
Training loss: 0.955563349809081
Validation loss: 2.5184636477966458

Epoch: 5| Step: 6
Training loss: 0.7270306955282531
Validation loss: 2.554122958262398

Epoch: 5| Step: 7
Training loss: 0.8870582098842688
Validation loss: 2.5514891310453844

Epoch: 5| Step: 8
Training loss: 0.9765204153529534
Validation loss: 2.5830390820813687

Epoch: 5| Step: 9
Training loss: 0.9860877320080741
Validation loss: 2.5806905511099685

Epoch: 5| Step: 10
Training loss: 0.8256780713312328
Validation loss: 2.589878616391562

Epoch: 345| Step: 0
Training loss: 0.726747058685303
Validation loss: 2.618515150530426

Epoch: 5| Step: 1
Training loss: 0.4857741575069954
Validation loss: 2.605017787201924

Epoch: 5| Step: 2
Training loss: 0.9123364968329225
Validation loss: 2.602322773160154

Epoch: 5| Step: 3
Training loss: 1.0052999477770852
Validation loss: 2.5760737537452174

Epoch: 5| Step: 4
Training loss: 0.7159960272188628
Validation loss: 2.574815822824099

Epoch: 5| Step: 5
Training loss: 0.8369543005796972
Validation loss: 2.55289975171283

Epoch: 5| Step: 6
Training loss: 1.1876825894974574
Validation loss: 2.5498537880249375

Epoch: 5| Step: 7
Training loss: 0.8469517676549569
Validation loss: 2.564722363532793

Epoch: 5| Step: 8
Training loss: 0.5438743558725108
Validation loss: 2.5639225532494083

Epoch: 5| Step: 9
Training loss: 0.9578172219986134
Validation loss: 2.5460260917792636

Epoch: 5| Step: 10
Training loss: 1.1597331396161366
Validation loss: 2.527197185703882

Epoch: 346| Step: 0
Training loss: 0.9314129949183734
Validation loss: 2.551994874353283

Epoch: 5| Step: 1
Training loss: 1.0734756951567865
Validation loss: 2.5532049216196606

Epoch: 5| Step: 2
Training loss: 1.021599553399821
Validation loss: 2.5306357040026737

Epoch: 5| Step: 3
Training loss: 0.8502949020768584
Validation loss: 2.5704300862855023

Epoch: 5| Step: 4
Training loss: 0.7190477749519997
Validation loss: 2.5340706339546153

Epoch: 5| Step: 5
Training loss: 0.7229952043055065
Validation loss: 2.535825925236201

Epoch: 5| Step: 6
Training loss: 0.9836203997988355
Validation loss: 2.5379676011772156

Epoch: 5| Step: 7
Training loss: 0.6958718139797518
Validation loss: 2.504289188601914

Epoch: 5| Step: 8
Training loss: 0.4044937538989732
Validation loss: 2.5773218230695663

Epoch: 5| Step: 9
Training loss: 1.079677514390272
Validation loss: 2.569401926052665

Epoch: 5| Step: 10
Training loss: 0.8919297081381979
Validation loss: 2.5784062634549207

Epoch: 347| Step: 0
Training loss: 0.42338700785247757
Validation loss: 2.6302371190527634

Epoch: 5| Step: 1
Training loss: 0.9008288196400059
Validation loss: 2.6497722416411382

Epoch: 5| Step: 2
Training loss: 0.5393736673738675
Validation loss: 2.657964114021164

Epoch: 5| Step: 3
Training loss: 0.7129054237815428
Validation loss: 2.6420205012417655

Epoch: 5| Step: 4
Training loss: 1.2578001317902925
Validation loss: 2.586525504489424

Epoch: 5| Step: 5
Training loss: 0.7752864969514135
Validation loss: 2.5437184072451875

Epoch: 5| Step: 6
Training loss: 1.1556660492096484
Validation loss: 2.50628208449495

Epoch: 5| Step: 7
Training loss: 0.7731152643502022
Validation loss: 2.465529266598775

Epoch: 5| Step: 8
Training loss: 0.7787428490324186
Validation loss: 2.495560918568086

Epoch: 5| Step: 9
Training loss: 0.8193912964807181
Validation loss: 2.5288240350029363

Epoch: 5| Step: 10
Training loss: 1.1356925395895539
Validation loss: 2.5192565101707993

Epoch: 348| Step: 0
Training loss: 0.7594860121347373
Validation loss: 2.5397645313926764

Epoch: 5| Step: 1
Training loss: 1.1188661994472908
Validation loss: 2.545336446024539

Epoch: 5| Step: 2
Training loss: 0.9816394519001956
Validation loss: 2.5772605712159815

Epoch: 5| Step: 3
Training loss: 1.0054060720071798
Validation loss: 2.5652050744078685

Epoch: 5| Step: 4
Training loss: 0.6567992681952244
Validation loss: 2.586936100835272

Epoch: 5| Step: 5
Training loss: 0.6313434550535731
Validation loss: 2.6055170868843445

Epoch: 5| Step: 6
Training loss: 0.8998116971755774
Validation loss: 2.574981518185384

Epoch: 5| Step: 7
Training loss: 0.9532824839577897
Validation loss: 2.5380957139341054

Epoch: 5| Step: 8
Training loss: 0.570683084562953
Validation loss: 2.555059564380699

Epoch: 5| Step: 9
Training loss: 0.5728739086725876
Validation loss: 2.561077174109256

Epoch: 5| Step: 10
Training loss: 1.117054271089924
Validation loss: 2.5363152121566497

Epoch: 349| Step: 0
Training loss: 0.8357660706047895
Validation loss: 2.5203837888224556

Epoch: 5| Step: 1
Training loss: 0.7592186613803144
Validation loss: 2.542206887525975

Epoch: 5| Step: 2
Training loss: 0.5085910990421804
Validation loss: 2.5588912013183838

Epoch: 5| Step: 3
Training loss: 1.0994913095405752
Validation loss: 2.5557422887013943

Epoch: 5| Step: 4
Training loss: 0.9235503281085983
Validation loss: 2.620983917085448

Epoch: 5| Step: 5
Training loss: 0.9160991703805456
Validation loss: 2.6313140452138053

Epoch: 5| Step: 6
Training loss: 0.9166722658737723
Validation loss: 2.6273460003214693

Epoch: 5| Step: 7
Training loss: 0.5835991548954347
Validation loss: 2.618679900771422

Epoch: 5| Step: 8
Training loss: 0.7846923140693759
Validation loss: 2.6286613100237757

Epoch: 5| Step: 9
Training loss: 0.9881436700764202
Validation loss: 2.564455421271219

Epoch: 5| Step: 10
Training loss: 0.9612398059736006
Validation loss: 2.5686546395209273

Epoch: 350| Step: 0
Training loss: 1.2217627237155801
Validation loss: 2.576918693723735

Epoch: 5| Step: 1
Training loss: 0.8584089224286777
Validation loss: 2.569059205343379

Epoch: 5| Step: 2
Training loss: 1.030548088021541
Validation loss: 2.559289036484256

Epoch: 5| Step: 3
Training loss: 0.7727280647992854
Validation loss: 2.52918508192887

Epoch: 5| Step: 4
Training loss: 0.6789968204114849
Validation loss: 2.564058353219027

Epoch: 5| Step: 5
Training loss: 0.851105418593618
Validation loss: 2.5314101079035245

Epoch: 5| Step: 6
Training loss: 0.541508859486194
Validation loss: 2.5335261275866277

Epoch: 5| Step: 7
Training loss: 0.7309937655813188
Validation loss: 2.54978035405712

Epoch: 5| Step: 8
Training loss: 0.7152311182286499
Validation loss: 2.5788280196019957

Epoch: 5| Step: 9
Training loss: 0.8826257963999478
Validation loss: 2.5565330439932183

Epoch: 5| Step: 10
Training loss: 0.8326325012702969
Validation loss: 2.5464378810742

Epoch: 351| Step: 0
Training loss: 0.2848422921876332
Validation loss: 2.5768416839297394

Epoch: 5| Step: 1
Training loss: 1.0724110322344254
Validation loss: 2.546718126281329

Epoch: 5| Step: 2
Training loss: 0.914490623959989
Validation loss: 2.570802868918376

Epoch: 5| Step: 3
Training loss: 0.7914814648750296
Validation loss: 2.5311458074489757

Epoch: 5| Step: 4
Training loss: 0.4530825101727886
Validation loss: 2.50841010226988

Epoch: 5| Step: 5
Training loss: 0.9551590649216826
Validation loss: 2.5721650254783945

Epoch: 5| Step: 6
Training loss: 0.3462684663950613
Validation loss: 2.543221587282442

Epoch: 5| Step: 7
Training loss: 1.2135703229454096
Validation loss: 2.523821665721353

Epoch: 5| Step: 8
Training loss: 0.9764722553517069
Validation loss: 2.5194067987000732

Epoch: 5| Step: 9
Training loss: 0.7035356382142403
Validation loss: 2.552022396228217

Epoch: 5| Step: 10
Training loss: 0.9815504938197142
Validation loss: 2.581808218246062

Epoch: 352| Step: 0
Training loss: 1.063846856447002
Validation loss: 2.569191903435307

Epoch: 5| Step: 1
Training loss: 0.805133510796324
Validation loss: 2.5788232607894837

Epoch: 5| Step: 2
Training loss: 0.8517103854216355
Validation loss: 2.5802001447329626

Epoch: 5| Step: 3
Training loss: 0.8379738861899635
Validation loss: 2.5860833890021127

Epoch: 5| Step: 4
Training loss: 0.7596701829286853
Validation loss: 2.6224224632074336

Epoch: 5| Step: 5
Training loss: 0.9081132741802482
Validation loss: 2.5706096923320017

Epoch: 5| Step: 6
Training loss: 1.0278036154400416
Validation loss: 2.569835999806645

Epoch: 5| Step: 7
Training loss: 0.6099870737848099
Validation loss: 2.5566215388141984

Epoch: 5| Step: 8
Training loss: 0.7191733896229308
Validation loss: 2.5615259385642988

Epoch: 5| Step: 9
Training loss: 0.6871506930664405
Validation loss: 2.5452200659383957

Epoch: 5| Step: 10
Training loss: 0.8465252551746274
Validation loss: 2.5771500072286315

Epoch: 353| Step: 0
Training loss: 0.5380000272594856
Validation loss: 2.5308238017178026

Epoch: 5| Step: 1
Training loss: 0.5468574793597548
Validation loss: 2.545098176224557

Epoch: 5| Step: 2
Training loss: 1.004003141603456
Validation loss: 2.57674581131741

Epoch: 5| Step: 3
Training loss: 1.0040021323641135
Validation loss: 2.6091870127283507

Epoch: 5| Step: 4
Training loss: 1.1053437610505539
Validation loss: 2.5720923206989124

Epoch: 5| Step: 5
Training loss: 0.710082241856026
Validation loss: 2.585262519678348

Epoch: 5| Step: 6
Training loss: 0.782875125534776
Validation loss: 2.5631925055832974

Epoch: 5| Step: 7
Training loss: 1.060224002705601
Validation loss: 2.5761705594302517

Epoch: 5| Step: 8
Training loss: 0.8066091831535808
Validation loss: 2.5463689103332277

Epoch: 5| Step: 9
Training loss: 0.7034660783654014
Validation loss: 2.521366984961815

Epoch: 5| Step: 10
Training loss: 0.5679122371971969
Validation loss: 2.5413077121299987

Epoch: 354| Step: 0
Training loss: 0.9553800390425828
Validation loss: 2.519952680391231

Epoch: 5| Step: 1
Training loss: 0.6343020345508795
Validation loss: 2.5570318142947603

Epoch: 5| Step: 2
Training loss: 0.5771923016243616
Validation loss: 2.551223705202245

Epoch: 5| Step: 3
Training loss: 1.0871895906143723
Validation loss: 2.5721615734544336

Epoch: 5| Step: 4
Training loss: 0.6222937405754636
Validation loss: 2.563586209172598

Epoch: 5| Step: 5
Training loss: 1.2063402586853498
Validation loss: 2.60004134097966

Epoch: 5| Step: 6
Training loss: 0.7583025891146753
Validation loss: 2.597183508967684

Epoch: 5| Step: 7
Training loss: 0.6478014204639196
Validation loss: 2.5946147399870254

Epoch: 5| Step: 8
Training loss: 0.7407359736231772
Validation loss: 2.5605276757587707

Epoch: 5| Step: 9
Training loss: 0.7292252426234418
Validation loss: 2.521496903994975

Epoch: 5| Step: 10
Training loss: 0.8269211638143584
Validation loss: 2.5039573117615745

Epoch: 355| Step: 0
Training loss: 0.5868020101461454
Validation loss: 2.521276926340837

Epoch: 5| Step: 1
Training loss: 0.8864915195324098
Validation loss: 2.4746950923992266

Epoch: 5| Step: 2
Training loss: 1.217089622391634
Validation loss: 2.5142828815161513

Epoch: 5| Step: 3
Training loss: 0.6208776661919491
Validation loss: 2.4966744628700845

Epoch: 5| Step: 4
Training loss: 0.6511181265119794
Validation loss: 2.5290322300292742

Epoch: 5| Step: 5
Training loss: 0.7087791292908865
Validation loss: 2.560866144408706

Epoch: 5| Step: 6
Training loss: 0.7236835497985452
Validation loss: 2.6109472996269645

Epoch: 5| Step: 7
Training loss: 0.7754100729859955
Validation loss: 2.60337307821648

Epoch: 5| Step: 8
Training loss: 1.1236109105002454
Validation loss: 2.5934843383693984

Epoch: 5| Step: 9
Training loss: 0.8206176916699108
Validation loss: 2.5708146260446583

Epoch: 5| Step: 10
Training loss: 0.7069258426895296
Validation loss: 2.5376467863720955

Epoch: 356| Step: 0
Training loss: 0.8287242664467286
Validation loss: 2.515609257095371

Epoch: 5| Step: 1
Training loss: 0.9083769601150096
Validation loss: 2.4728518857060364

Epoch: 5| Step: 2
Training loss: 0.6939486296574734
Validation loss: 2.464807345806624

Epoch: 5| Step: 3
Training loss: 0.49142979018164795
Validation loss: 2.4722339257997215

Epoch: 5| Step: 4
Training loss: 0.9726470272745324
Validation loss: 2.4985544291259627

Epoch: 5| Step: 5
Training loss: 0.9075449537802627
Validation loss: 2.523943619023306

Epoch: 5| Step: 6
Training loss: 0.6728055409498125
Validation loss: 2.5743531419483

Epoch: 5| Step: 7
Training loss: 0.6994847265966057
Validation loss: 2.609269476329988

Epoch: 5| Step: 8
Training loss: 0.7322577534216599
Validation loss: 2.6181167444226707

Epoch: 5| Step: 9
Training loss: 1.2128296865981834
Validation loss: 2.638210036245403

Epoch: 5| Step: 10
Training loss: 0.7428812900092702
Validation loss: 2.5992827034979036

Epoch: 357| Step: 0
Training loss: 0.4735904949986314
Validation loss: 2.6058461574757534

Epoch: 5| Step: 1
Training loss: 0.7268938109045848
Validation loss: 2.5638817154149867

Epoch: 5| Step: 2
Training loss: 0.9185463893806751
Validation loss: 2.541212958945147

Epoch: 5| Step: 3
Training loss: 0.8492688428322922
Validation loss: 2.5293203230136134

Epoch: 5| Step: 4
Training loss: 0.5819385377917471
Validation loss: 2.508174708182328

Epoch: 5| Step: 5
Training loss: 0.7550158463640371
Validation loss: 2.5132317169491247

Epoch: 5| Step: 6
Training loss: 0.9215509847424102
Validation loss: 2.524035382808896

Epoch: 5| Step: 7
Training loss: 0.7022441432704583
Validation loss: 2.4977028270422883

Epoch: 5| Step: 8
Training loss: 1.0557303465184358
Validation loss: 2.528541397951388

Epoch: 5| Step: 9
Training loss: 0.9252464584699218
Validation loss: 2.5434788322974726

Epoch: 5| Step: 10
Training loss: 0.771633046950998
Validation loss: 2.6067798597913785

Epoch: 358| Step: 0
Training loss: 1.01342235279791
Validation loss: 2.65384568540009

Epoch: 5| Step: 1
Training loss: 0.6144352642938664
Validation loss: 2.6458003460571247

Epoch: 5| Step: 2
Training loss: 0.8370492262954559
Validation loss: 2.648640451977615

Epoch: 5| Step: 3
Training loss: 0.8905250091639264
Validation loss: 2.623713188195136

Epoch: 5| Step: 4
Training loss: 0.9633397724229004
Validation loss: 2.6404314799693136

Epoch: 5| Step: 5
Training loss: 0.5047325929036871
Validation loss: 2.538014553945771

Epoch: 5| Step: 6
Training loss: 0.7419131926529101
Validation loss: 2.5582188465373505

Epoch: 5| Step: 7
Training loss: 0.6482276347090796
Validation loss: 2.5344584275829787

Epoch: 5| Step: 8
Training loss: 1.1138286650135192
Validation loss: 2.4695311608887907

Epoch: 5| Step: 9
Training loss: 0.72541924226564
Validation loss: 2.499844702132291

Epoch: 5| Step: 10
Training loss: 0.7121929778775111
Validation loss: 2.533062604784937

Epoch: 359| Step: 0
Training loss: 0.6620193015076637
Validation loss: 2.5665564415762234

Epoch: 5| Step: 1
Training loss: 0.682811005544882
Validation loss: 2.648440936334953

Epoch: 5| Step: 2
Training loss: 0.699220071290542
Validation loss: 2.7114140764642864

Epoch: 5| Step: 3
Training loss: 0.9867633727940754
Validation loss: 2.680583458588619

Epoch: 5| Step: 4
Training loss: 0.6931774491742365
Validation loss: 2.682587201931369

Epoch: 5| Step: 5
Training loss: 1.1262008827329308
Validation loss: 2.629823538404284

Epoch: 5| Step: 6
Training loss: 0.8845592535990715
Validation loss: 2.5794634623927055

Epoch: 5| Step: 7
Training loss: 0.726334730973576
Validation loss: 2.5233761583026793

Epoch: 5| Step: 8
Training loss: 0.7797201054240099
Validation loss: 2.4783653533658616

Epoch: 5| Step: 9
Training loss: 0.875423907728598
Validation loss: 2.462835483363605

Epoch: 5| Step: 10
Training loss: 0.7856101626601235
Validation loss: 2.4720595225111848

Epoch: 360| Step: 0
Training loss: 0.8501072619584022
Validation loss: 2.4840425524425687

Epoch: 5| Step: 1
Training loss: 0.8888298481135478
Validation loss: 2.5686731462583934

Epoch: 5| Step: 2
Training loss: 0.33650181192176654
Validation loss: 2.582734810374934

Epoch: 5| Step: 3
Training loss: 0.6277899460565045
Validation loss: 2.651754430967439

Epoch: 5| Step: 4
Training loss: 0.750578458551712
Validation loss: 2.681325054736479

Epoch: 5| Step: 5
Training loss: 1.1118359201735035
Validation loss: 2.6802596853567193

Epoch: 5| Step: 6
Training loss: 0.6332478379801134
Validation loss: 2.653077497986732

Epoch: 5| Step: 7
Training loss: 0.780500662975042
Validation loss: 2.658080217617435

Epoch: 5| Step: 8
Training loss: 0.8787759981067303
Validation loss: 2.6342308401547996

Epoch: 5| Step: 9
Training loss: 1.013542034675764
Validation loss: 2.5702466844399003

Epoch: 5| Step: 10
Training loss: 0.7328864086758947
Validation loss: 2.592452520265849

Epoch: 361| Step: 0
Training loss: 0.7759829548040297
Validation loss: 2.523351716300677

Epoch: 5| Step: 1
Training loss: 0.583109452223312
Validation loss: 2.542442016579255

Epoch: 5| Step: 2
Training loss: 0.8020896828800563
Validation loss: 2.518641710468801

Epoch: 5| Step: 3
Training loss: 0.9306188134064002
Validation loss: 2.550666670702408

Epoch: 5| Step: 4
Training loss: 0.9205546541394389
Validation loss: 2.5618297171471798

Epoch: 5| Step: 5
Training loss: 0.5276739993737583
Validation loss: 2.553784413038406

Epoch: 5| Step: 6
Training loss: 0.5497607252524136
Validation loss: 2.557718405320007

Epoch: 5| Step: 7
Training loss: 0.7951321335514373
Validation loss: 2.5406842410043904

Epoch: 5| Step: 8
Training loss: 0.9345096899319073
Validation loss: 2.559498300654534

Epoch: 5| Step: 9
Training loss: 0.8544040830694997
Validation loss: 2.5467665263114863

Epoch: 5| Step: 10
Training loss: 0.8200199513799425
Validation loss: 2.547349078533178

Epoch: 362| Step: 0
Training loss: 0.71262795821832
Validation loss: 2.565758684796811

Epoch: 5| Step: 1
Training loss: 0.774517807619727
Validation loss: 2.589455039562162

Epoch: 5| Step: 2
Training loss: 1.0018352119412532
Validation loss: 2.5495865036791767

Epoch: 5| Step: 3
Training loss: 0.6978841864206561
Validation loss: 2.5651295963565754

Epoch: 5| Step: 4
Training loss: 1.1345356430769318
Validation loss: 2.5386031045226445

Epoch: 5| Step: 5
Training loss: 0.7747337191490685
Validation loss: 2.5729714621476902

Epoch: 5| Step: 6
Training loss: 0.3047874849053882
Validation loss: 2.563362015609945

Epoch: 5| Step: 7
Training loss: 0.6577347806926346
Validation loss: 2.557284051128473

Epoch: 5| Step: 8
Training loss: 0.8316812629858579
Validation loss: 2.584473055505637

Epoch: 5| Step: 9
Training loss: 0.7596477034582846
Validation loss: 2.5722243385696335

Epoch: 5| Step: 10
Training loss: 0.5673397395843995
Validation loss: 2.595313187150675

Epoch: 363| Step: 0
Training loss: 0.3133292282732614
Validation loss: 2.587452793151425

Epoch: 5| Step: 1
Training loss: 0.8504395386309849
Validation loss: 2.595384923380264

Epoch: 5| Step: 2
Training loss: 0.48593445436559696
Validation loss: 2.5995172577805534

Epoch: 5| Step: 3
Training loss: 1.0130699296182633
Validation loss: 2.5835066613816586

Epoch: 5| Step: 4
Training loss: 0.6835959516217337
Validation loss: 2.583852276859859

Epoch: 5| Step: 5
Training loss: 1.101951854966063
Validation loss: 2.5740135216004387

Epoch: 5| Step: 6
Training loss: 0.5704820198097603
Validation loss: 2.5334177987838697

Epoch: 5| Step: 7
Training loss: 0.8862484260189999
Validation loss: 2.5780964551173864

Epoch: 5| Step: 8
Training loss: 0.9545594349576344
Validation loss: 2.547007963100833

Epoch: 5| Step: 9
Training loss: 0.6458869547784989
Validation loss: 2.5543507448145792

Epoch: 5| Step: 10
Training loss: 0.5444412025638433
Validation loss: 2.545631127591089

Epoch: 364| Step: 0
Training loss: 0.8819149822577194
Validation loss: 2.53940785775161

Epoch: 5| Step: 1
Training loss: 0.5538714948115819
Validation loss: 2.5403632324007943

Epoch: 5| Step: 2
Training loss: 0.7012933184933828
Validation loss: 2.587988374504335

Epoch: 5| Step: 3
Training loss: 0.9389279934083751
Validation loss: 2.569543156773518

Epoch: 5| Step: 4
Training loss: 0.6919274386250813
Validation loss: 2.5387789316909397

Epoch: 5| Step: 5
Training loss: 0.6962761148797827
Validation loss: 2.5870086094337754

Epoch: 5| Step: 6
Training loss: 1.0839401648501368
Validation loss: 2.5444561335210425

Epoch: 5| Step: 7
Training loss: 0.2504923710479887
Validation loss: 2.5651884425033895

Epoch: 5| Step: 8
Training loss: 0.6953213508985584
Validation loss: 2.551491431950506

Epoch: 5| Step: 9
Training loss: 0.8905222649465535
Validation loss: 2.5601073048487115

Epoch: 5| Step: 10
Training loss: 0.6894320087603221
Validation loss: 2.5807492758785946

Epoch: 365| Step: 0
Training loss: 0.6744291196148152
Validation loss: 2.5688887419714006

Epoch: 5| Step: 1
Training loss: 0.6237596124279143
Validation loss: 2.5419740946526255

Epoch: 5| Step: 2
Training loss: 0.7394097800631855
Validation loss: 2.5757362403965405

Epoch: 5| Step: 3
Training loss: 0.9119275256919903
Validation loss: 2.5376833892429596

Epoch: 5| Step: 4
Training loss: 0.6215286651500805
Validation loss: 2.5931219973263135

Epoch: 5| Step: 5
Training loss: 0.6565004052671531
Validation loss: 2.6290904772897994

Epoch: 5| Step: 6
Training loss: 0.649510839608228
Validation loss: 2.5987264353933988

Epoch: 5| Step: 7
Training loss: 0.9406902708808997
Validation loss: 2.578778723167361

Epoch: 5| Step: 8
Training loss: 0.5137732228137607
Validation loss: 2.586929486430961

Epoch: 5| Step: 9
Training loss: 1.1664402889694003
Validation loss: 2.58690985370513

Epoch: 5| Step: 10
Training loss: 0.5835741318107971
Validation loss: 2.539534181714809

Epoch: 366| Step: 0
Training loss: 0.5788285382166749
Validation loss: 2.5546719225507375

Epoch: 5| Step: 1
Training loss: 0.9483708177531882
Validation loss: 2.5008160561559634

Epoch: 5| Step: 2
Training loss: 0.6355609782036876
Validation loss: 2.5188822248740945

Epoch: 5| Step: 3
Training loss: 0.9414615535716183
Validation loss: 2.5335879181821475

Epoch: 5| Step: 4
Training loss: 0.7576600147483407
Validation loss: 2.4954630332697296

Epoch: 5| Step: 5
Training loss: 0.6564828822772556
Validation loss: 2.533727005382723

Epoch: 5| Step: 6
Training loss: 0.6782851605762864
Validation loss: 2.543023374885145

Epoch: 5| Step: 7
Training loss: 0.8742432728073051
Validation loss: 2.5475468310943894

Epoch: 5| Step: 8
Training loss: 0.7513078174779936
Validation loss: 2.558598268892089

Epoch: 5| Step: 9
Training loss: 0.7956040288374375
Validation loss: 2.5713376779983963

Epoch: 5| Step: 10
Training loss: 0.5696624290821342
Validation loss: 2.6016399388402256

Epoch: 367| Step: 0
Training loss: 0.6140889479981436
Validation loss: 2.6389079255340513

Epoch: 5| Step: 1
Training loss: 0.7058166271410969
Validation loss: 2.6520525133750565

Epoch: 5| Step: 2
Training loss: 1.05285609856199
Validation loss: 2.599582528524503

Epoch: 5| Step: 3
Training loss: 0.6977389783176692
Validation loss: 2.6338039169961203

Epoch: 5| Step: 4
Training loss: 0.7831049831477832
Validation loss: 2.5923926880020955

Epoch: 5| Step: 5
Training loss: 0.8089933651839498
Validation loss: 2.6200233578339387

Epoch: 5| Step: 6
Training loss: 0.7388961895205168
Validation loss: 2.6253731184574316

Epoch: 5| Step: 7
Training loss: 0.6642248740549919
Validation loss: 2.6217419738631342

Epoch: 5| Step: 8
Training loss: 0.7549376868749818
Validation loss: 2.605481661307828

Epoch: 5| Step: 9
Training loss: 0.5853561823767289
Validation loss: 2.5925123323603354

Epoch: 5| Step: 10
Training loss: 0.7597080002925239
Validation loss: 2.5637295382088383

Epoch: 368| Step: 0
Training loss: 0.6427699211532122
Validation loss: 2.559871232613475

Epoch: 5| Step: 1
Training loss: 0.9889993282832689
Validation loss: 2.583416395277747

Epoch: 5| Step: 2
Training loss: 0.9108851383399368
Validation loss: 2.563392258718418

Epoch: 5| Step: 3
Training loss: 0.5878281164046872
Validation loss: 2.5644257545283597

Epoch: 5| Step: 4
Training loss: 0.49571112648087573
Validation loss: 2.5858458028814577

Epoch: 5| Step: 5
Training loss: 0.6906776900063802
Validation loss: 2.5591953307127646

Epoch: 5| Step: 6
Training loss: 0.552562349866336
Validation loss: 2.5799061836832253

Epoch: 5| Step: 7
Training loss: 1.0796975539715106
Validation loss: 2.605181054863465

Epoch: 5| Step: 8
Training loss: 0.7627471241954602
Validation loss: 2.600409834320911

Epoch: 5| Step: 9
Training loss: 0.5282307829243191
Validation loss: 2.5917899431228255

Epoch: 5| Step: 10
Training loss: 0.7109975684643466
Validation loss: 2.5411283069808377

Epoch: 369| Step: 0
Training loss: 0.396981421041915
Validation loss: 2.5602322059507077

Epoch: 5| Step: 1
Training loss: 0.6989898520089123
Validation loss: 2.5916949721645923

Epoch: 5| Step: 2
Training loss: 0.7158804708184866
Validation loss: 2.572975713669992

Epoch: 5| Step: 3
Training loss: 0.8405943244527377
Validation loss: 2.587686818742974

Epoch: 5| Step: 4
Training loss: 0.7927401734690146
Validation loss: 2.579151844762211

Epoch: 5| Step: 5
Training loss: 0.43067496149713186
Validation loss: 2.5535894159327643

Epoch: 5| Step: 6
Training loss: 0.85547690191696
Validation loss: 2.5652628984691255

Epoch: 5| Step: 7
Training loss: 0.49780982865109513
Validation loss: 2.6000369591921846

Epoch: 5| Step: 8
Training loss: 1.0586664941997372
Validation loss: 2.5577216944159913

Epoch: 5| Step: 9
Training loss: 0.7631216579304713
Validation loss: 2.556516483025103

Epoch: 5| Step: 10
Training loss: 0.8053097957496106
Validation loss: 2.558309921532168

Epoch: 370| Step: 0
Training loss: 1.0258191766286289
Validation loss: 2.567094682894685

Epoch: 5| Step: 1
Training loss: 0.5717041072966821
Validation loss: 2.561674061468833

Epoch: 5| Step: 2
Training loss: 0.6646105580349073
Validation loss: 2.540743961078597

Epoch: 5| Step: 3
Training loss: 0.5909301907850375
Validation loss: 2.5600122540831816

Epoch: 5| Step: 4
Training loss: 0.4644781325708675
Validation loss: 2.545600635201515

Epoch: 5| Step: 5
Training loss: 0.22600829644292963
Validation loss: 2.508668040255367

Epoch: 5| Step: 6
Training loss: 0.8827836023512909
Validation loss: 2.522696360280874

Epoch: 5| Step: 7
Training loss: 0.8559319970691129
Validation loss: 2.5399403336744966

Epoch: 5| Step: 8
Training loss: 0.7928358445811067
Validation loss: 2.5899674368064938

Epoch: 5| Step: 9
Training loss: 0.7540239627632557
Validation loss: 2.6040225068255367

Epoch: 5| Step: 10
Training loss: 0.9347970781083936
Validation loss: 2.596533734324437

Epoch: 371| Step: 0
Training loss: 0.7831879802200395
Validation loss: 2.6350142686368074

Epoch: 5| Step: 1
Training loss: 0.62071005047343
Validation loss: 2.6229143172809906

Epoch: 5| Step: 2
Training loss: 0.7633879931493318
Validation loss: 2.5803881842196983

Epoch: 5| Step: 3
Training loss: 0.6039918175168343
Validation loss: 2.6123531667883766

Epoch: 5| Step: 4
Training loss: 0.6038114939741372
Validation loss: 2.564781979684589

Epoch: 5| Step: 5
Training loss: 0.8035715012323256
Validation loss: 2.5503499935168255

Epoch: 5| Step: 6
Training loss: 0.5000730997532431
Validation loss: 2.559378163221325

Epoch: 5| Step: 7
Training loss: 0.6641493123474329
Validation loss: 2.560002570359288

Epoch: 5| Step: 8
Training loss: 0.8659819393807522
Validation loss: 2.5429469339940733

Epoch: 5| Step: 9
Training loss: 1.0314631386335933
Validation loss: 2.5616506834288972

Epoch: 5| Step: 10
Training loss: 0.609959664222837
Validation loss: 2.579179638446926

Epoch: 372| Step: 0
Training loss: 0.4689669266072579
Validation loss: 2.571259920277967

Epoch: 5| Step: 1
Training loss: 0.6053769441959748
Validation loss: 2.575445164209128

Epoch: 5| Step: 2
Training loss: 1.1347125725483058
Validation loss: 2.5557925701208446

Epoch: 5| Step: 3
Training loss: 0.6457753052842827
Validation loss: 2.5858316533992216

Epoch: 5| Step: 4
Training loss: 0.7817437709637037
Validation loss: 2.551516030405633

Epoch: 5| Step: 5
Training loss: 0.551528261759209
Validation loss: 2.5406775753070243

Epoch: 5| Step: 6
Training loss: 0.4946180156024729
Validation loss: 2.545770408250545

Epoch: 5| Step: 7
Training loss: 0.7059518995163159
Validation loss: 2.5435021505785125

Epoch: 5| Step: 8
Training loss: 0.6178178586134115
Validation loss: 2.573441654679668

Epoch: 5| Step: 9
Training loss: 1.0616074908685762
Validation loss: 2.576427461436582

Epoch: 5| Step: 10
Training loss: 0.4667342395338497
Validation loss: 2.544523073076143

Epoch: 373| Step: 0
Training loss: 0.6988104795101411
Validation loss: 2.6195717082790013

Epoch: 5| Step: 1
Training loss: 0.15900530361043688
Validation loss: 2.5604415397190516

Epoch: 5| Step: 2
Training loss: 0.7637792643483047
Validation loss: 2.603190932717749

Epoch: 5| Step: 3
Training loss: 0.7911819094849042
Validation loss: 2.6110327872058825

Epoch: 5| Step: 4
Training loss: 0.44356978880800974
Validation loss: 2.5808897287090593

Epoch: 5| Step: 5
Training loss: 0.5979419349576912
Validation loss: 2.59336477543038

Epoch: 5| Step: 6
Training loss: 0.8191239966076824
Validation loss: 2.5887090110963236

Epoch: 5| Step: 7
Training loss: 0.7750304031561247
Validation loss: 2.617970026899897

Epoch: 5| Step: 8
Training loss: 0.8187775556280721
Validation loss: 2.5863580607424246

Epoch: 5| Step: 9
Training loss: 0.6458133314993609
Validation loss: 2.5398078590525657

Epoch: 5| Step: 10
Training loss: 1.0307060888070403
Validation loss: 2.5574375832161373

Epoch: 374| Step: 0
Training loss: 0.9866671442232609
Validation loss: 2.5417405623236404

Epoch: 5| Step: 1
Training loss: 0.6285662946553318
Validation loss: 2.5311031007747857

Epoch: 5| Step: 2
Training loss: 0.8372716862924618
Validation loss: 2.546250043751189

Epoch: 5| Step: 3
Training loss: 0.7108771329968164
Validation loss: 2.5580356305107177

Epoch: 5| Step: 4
Training loss: 0.8815225950646053
Validation loss: 2.558057049250014

Epoch: 5| Step: 5
Training loss: 0.42877462691710705
Validation loss: 2.592364749192571

Epoch: 5| Step: 6
Training loss: 0.8512527182335383
Validation loss: 2.59601727084844

Epoch: 5| Step: 7
Training loss: 0.4685361533337439
Validation loss: 2.6534106488196234

Epoch: 5| Step: 8
Training loss: 0.6344611743594416
Validation loss: 2.6151625191060677

Epoch: 5| Step: 9
Training loss: 0.6120909297965981
Validation loss: 2.603973381170747

Epoch: 5| Step: 10
Training loss: 0.5631729974307141
Validation loss: 2.6227191292731127

Epoch: 375| Step: 0
Training loss: 0.8020389263856625
Validation loss: 2.593901106832024

Epoch: 5| Step: 1
Training loss: 0.7757480671865005
Validation loss: 2.5924277623916256

Epoch: 5| Step: 2
Training loss: 0.7402341334360176
Validation loss: 2.565231245803419

Epoch: 5| Step: 3
Training loss: 0.48407523816305814
Validation loss: 2.553616101419182

Epoch: 5| Step: 4
Training loss: 0.83341864308157
Validation loss: 2.5470105347843974

Epoch: 5| Step: 5
Training loss: 0.7582554260170444
Validation loss: 2.534636079661082

Epoch: 5| Step: 6
Training loss: 0.6401618120409484
Validation loss: 2.481898269675831

Epoch: 5| Step: 7
Training loss: 0.678158608056438
Validation loss: 2.496903002483862

Epoch: 5| Step: 8
Training loss: 0.4268660768104083
Validation loss: 2.5218593750378

Epoch: 5| Step: 9
Training loss: 0.9571100630713737
Validation loss: 2.5608187727031697

Epoch: 5| Step: 10
Training loss: 0.4276614540683824
Validation loss: 2.5374106254580635

Epoch: 376| Step: 0
Training loss: 0.871590203425886
Validation loss: 2.579618279186577

Epoch: 5| Step: 1
Training loss: 0.8317455105558634
Validation loss: 2.598804970859758

Epoch: 5| Step: 2
Training loss: 0.5249305611056538
Validation loss: 2.628949194355356

Epoch: 5| Step: 3
Training loss: 0.574568557586158
Validation loss: 2.6458906658905916

Epoch: 5| Step: 4
Training loss: 0.6135331869483878
Validation loss: 2.6163475857341654

Epoch: 5| Step: 5
Training loss: 0.8343276449759666
Validation loss: 2.583878102124417

Epoch: 5| Step: 6
Training loss: 0.4685937780092135
Validation loss: 2.598265856963118

Epoch: 5| Step: 7
Training loss: 0.5160259652960704
Validation loss: 2.5886763710568177

Epoch: 5| Step: 8
Training loss: 1.09750696436382
Validation loss: 2.536292441345193

Epoch: 5| Step: 9
Training loss: 0.6367344766558561
Validation loss: 2.545142915426656

Epoch: 5| Step: 10
Training loss: 0.6276228705398365
Validation loss: 2.55093223289387

Epoch: 377| Step: 0
Training loss: 0.756326181342062
Validation loss: 2.5761648921232387

Epoch: 5| Step: 1
Training loss: 0.3582679864530338
Validation loss: 2.578463404705502

Epoch: 5| Step: 2
Training loss: 0.9505508557459911
Validation loss: 2.583643584686446

Epoch: 5| Step: 3
Training loss: 0.7754855542242459
Validation loss: 2.6022911717906094

Epoch: 5| Step: 4
Training loss: 0.6773859057128422
Validation loss: 2.581829217347117

Epoch: 5| Step: 5
Training loss: 0.5962160747401475
Validation loss: 2.5710840479478203

Epoch: 5| Step: 6
Training loss: 0.7980068994070867
Validation loss: 2.544261811989271

Epoch: 5| Step: 7
Training loss: 0.5143444748879223
Validation loss: 2.5325630951806053

Epoch: 5| Step: 8
Training loss: 0.8076825743916679
Validation loss: 2.5070716035141105

Epoch: 5| Step: 9
Training loss: 0.6974525094357632
Validation loss: 2.5277708859511043

Epoch: 5| Step: 10
Training loss: 0.5152626787557149
Validation loss: 2.5327625928133544

Epoch: 378| Step: 0
Training loss: 0.6502478961301895
Validation loss: 2.5402306047343766

Epoch: 5| Step: 1
Training loss: 0.31530374191566973
Validation loss: 2.544723861531323

Epoch: 5| Step: 2
Training loss: 0.4109911459365871
Validation loss: 2.5570477262649214

Epoch: 5| Step: 3
Training loss: 1.0115263767056097
Validation loss: 2.5879043253688625

Epoch: 5| Step: 4
Training loss: 0.8014879783209511
Validation loss: 2.6208643624842454

Epoch: 5| Step: 5
Training loss: 0.4265181088667144
Validation loss: 2.622460625889586

Epoch: 5| Step: 6
Training loss: 0.7573998497706189
Validation loss: 2.6219318740079207

Epoch: 5| Step: 7
Training loss: 0.814094336357607
Validation loss: 2.6432970855504117

Epoch: 5| Step: 8
Training loss: 0.6231050852785245
Validation loss: 2.6467297170610418

Epoch: 5| Step: 9
Training loss: 0.5508971396737066
Validation loss: 2.642156712157576

Epoch: 5| Step: 10
Training loss: 0.9331177651290301
Validation loss: 2.619618495101676

Epoch: 379| Step: 0
Training loss: 0.6982894134556453
Validation loss: 2.6038340671577753

Epoch: 5| Step: 1
Training loss: 0.7659929909248492
Validation loss: 2.6117479296434785

Epoch: 5| Step: 2
Training loss: 0.4743574753390305
Validation loss: 2.545962245804301

Epoch: 5| Step: 3
Training loss: 0.4956391421750117
Validation loss: 2.5827540271748397

Epoch: 5| Step: 4
Training loss: 0.6497820048476662
Validation loss: 2.572581781842329

Epoch: 5| Step: 5
Training loss: 0.8702089409022775
Validation loss: 2.565867676432366

Epoch: 5| Step: 6
Training loss: 0.5053134756367831
Validation loss: 2.5230420591797604

Epoch: 5| Step: 7
Training loss: 0.8327570154197468
Validation loss: 2.5689290491405052

Epoch: 5| Step: 8
Training loss: 0.8652565223494308
Validation loss: 2.571587830738351

Epoch: 5| Step: 9
Training loss: 0.47535700056137997
Validation loss: 2.574857443059136

Epoch: 5| Step: 10
Training loss: 0.7532122486275326
Validation loss: 2.537941378441085

Epoch: 380| Step: 0
Training loss: 0.7724745564761241
Validation loss: 2.54034747124383

Epoch: 5| Step: 1
Training loss: 0.6581675579298136
Validation loss: 2.5955186465649307

Epoch: 5| Step: 2
Training loss: 0.6958634411890143
Validation loss: 2.531163709803582

Epoch: 5| Step: 3
Training loss: 0.48637846414258373
Validation loss: 2.5303031591716736

Epoch: 5| Step: 4
Training loss: 0.679356505380003
Validation loss: 2.5678316879736127

Epoch: 5| Step: 5
Training loss: 0.6433105700382468
Validation loss: 2.5394756062481556

Epoch: 5| Step: 6
Training loss: 0.5649671754754433
Validation loss: 2.594894444319167

Epoch: 5| Step: 7
Training loss: 0.5396589213956864
Validation loss: 2.61137199164061

Epoch: 5| Step: 8
Training loss: 0.8299996731654063
Validation loss: 2.58074640304902

Epoch: 5| Step: 9
Training loss: 0.728143796555369
Validation loss: 2.5957343848541736

Epoch: 5| Step: 10
Training loss: 0.8069288648595817
Validation loss: 2.6291149640255718

Epoch: 381| Step: 0
Training loss: 0.6672664765331434
Validation loss: 2.640184599108147

Epoch: 5| Step: 1
Training loss: 0.7553948051612357
Validation loss: 2.5976962588314265

Epoch: 5| Step: 2
Training loss: 0.7370290480987802
Validation loss: 2.554338246493821

Epoch: 5| Step: 3
Training loss: 0.7027888448151236
Validation loss: 2.555002424484068

Epoch: 5| Step: 4
Training loss: 0.5137653338332091
Validation loss: 2.503621040582138

Epoch: 5| Step: 5
Training loss: 0.5527473690810581
Validation loss: 2.4882288068739955

Epoch: 5| Step: 6
Training loss: 0.8194177016152745
Validation loss: 2.493288685457733

Epoch: 5| Step: 7
Training loss: 0.4219641591271322
Validation loss: 2.464824133967633

Epoch: 5| Step: 8
Training loss: 0.8128275577803288
Validation loss: 2.500212785935379

Epoch: 5| Step: 9
Training loss: 0.7021955068460259
Validation loss: 2.5243349467191587

Epoch: 5| Step: 10
Training loss: 0.686021949939614
Validation loss: 2.5225304603003873

Epoch: 382| Step: 0
Training loss: 0.922344120729305
Validation loss: 2.540262079958967

Epoch: 5| Step: 1
Training loss: 0.41158637537311227
Validation loss: 2.563951364919153

Epoch: 5| Step: 2
Training loss: 0.5552442738230456
Validation loss: 2.566844859314794

Epoch: 5| Step: 3
Training loss: 0.6944074848724231
Validation loss: 2.5965460502735898

Epoch: 5| Step: 4
Training loss: 0.5951839498461887
Validation loss: 2.63594007435956

Epoch: 5| Step: 5
Training loss: 0.6254630757478757
Validation loss: 2.5855545138548126

Epoch: 5| Step: 6
Training loss: 0.8605528649023405
Validation loss: 2.596063384062418

Epoch: 5| Step: 7
Training loss: 0.7163268166936891
Validation loss: 2.581989448527583

Epoch: 5| Step: 8
Training loss: 0.6889066394468242
Validation loss: 2.577594459613595

Epoch: 5| Step: 9
Training loss: 0.5644259594778829
Validation loss: 2.5744914403202044

Epoch: 5| Step: 10
Training loss: 0.5812315855903526
Validation loss: 2.5816125394819043

Epoch: 383| Step: 0
Training loss: 0.86855877891831
Validation loss: 2.5765288109262374

Epoch: 5| Step: 1
Training loss: 0.6398212927299548
Validation loss: 2.5965457461767834

Epoch: 5| Step: 2
Training loss: 0.6752382864502811
Validation loss: 2.576509416852591

Epoch: 5| Step: 3
Training loss: 0.7050131981879068
Validation loss: 2.590210053818637

Epoch: 5| Step: 4
Training loss: 0.6237472854432874
Validation loss: 2.578733297002675

Epoch: 5| Step: 5
Training loss: 0.7916883080853971
Validation loss: 2.5823774391917684

Epoch: 5| Step: 6
Training loss: 0.3966206095741335
Validation loss: 2.5897364227511837

Epoch: 5| Step: 7
Training loss: 0.6434204934138995
Validation loss: 2.560738373945565

Epoch: 5| Step: 8
Training loss: 0.5385683254773755
Validation loss: 2.605855944826742

Epoch: 5| Step: 9
Training loss: 0.5762058054098278
Validation loss: 2.625403856110284

Epoch: 5| Step: 10
Training loss: 0.7379187041918129
Validation loss: 2.605007567133425

Epoch: 384| Step: 0
Training loss: 0.4786428165721224
Validation loss: 2.6217212915162436

Epoch: 5| Step: 1
Training loss: 0.5750301622689661
Validation loss: 2.628484939185581

Epoch: 5| Step: 2
Training loss: 0.5328802172007001
Validation loss: 2.6035803090846104

Epoch: 5| Step: 3
Training loss: 0.7735530882496535
Validation loss: 2.601755978724609

Epoch: 5| Step: 4
Training loss: 0.6598326888931196
Validation loss: 2.5737973013428803

Epoch: 5| Step: 5
Training loss: 0.6562829236445682
Validation loss: 2.5626264661489997

Epoch: 5| Step: 6
Training loss: 0.8440113369329454
Validation loss: 2.56975507908476

Epoch: 5| Step: 7
Training loss: 0.5809106471938635
Validation loss: 2.58097945939847

Epoch: 5| Step: 8
Training loss: 0.4483592892274643
Validation loss: 2.612785266414265

Epoch: 5| Step: 9
Training loss: 0.8915260842872398
Validation loss: 2.601431466917821

Epoch: 5| Step: 10
Training loss: 0.7202058642845951
Validation loss: 2.5950773074793863

Epoch: 385| Step: 0
Training loss: 0.5693690975733309
Validation loss: 2.6109800613677363

Epoch: 5| Step: 1
Training loss: 0.6044770024723392
Validation loss: 2.6029778097906053

Epoch: 5| Step: 2
Training loss: 0.4279420949233212
Validation loss: 2.5866807261718026

Epoch: 5| Step: 3
Training loss: 0.8375234799865665
Validation loss: 2.582067086670437

Epoch: 5| Step: 4
Training loss: 0.8438452207735222
Validation loss: 2.567773899794701

Epoch: 5| Step: 5
Training loss: 0.4040479953637779
Validation loss: 2.572298475269659

Epoch: 5| Step: 6
Training loss: 0.39679568617061134
Validation loss: 2.5209602558588355

Epoch: 5| Step: 7
Training loss: 0.6186005315483589
Validation loss: 2.524773094957853

Epoch: 5| Step: 8
Training loss: 0.8524980218366566
Validation loss: 2.527002186272048

Epoch: 5| Step: 9
Training loss: 0.9751296250666771
Validation loss: 2.5431830656736634

Epoch: 5| Step: 10
Training loss: 0.29423853041432263
Validation loss: 2.534928762311113

Epoch: 386| Step: 0
Training loss: 0.46243384313394187
Validation loss: 2.5627429235741133

Epoch: 5| Step: 1
Training loss: 0.9389377060418752
Validation loss: 2.5471986139374154

Epoch: 5| Step: 2
Training loss: 0.666562323053822
Validation loss: 2.550256013575493

Epoch: 5| Step: 3
Training loss: 0.6694048563035956
Validation loss: 2.5754367001686402

Epoch: 5| Step: 4
Training loss: 0.7774905732248798
Validation loss: 2.5697325736628174

Epoch: 5| Step: 5
Training loss: 0.6525512639366176
Validation loss: 2.5584866208629453

Epoch: 5| Step: 6
Training loss: 0.7738421758986876
Validation loss: 2.5353304799329526

Epoch: 5| Step: 7
Training loss: 0.6403197514955113
Validation loss: 2.5368762235000344

Epoch: 5| Step: 8
Training loss: 0.5396595288633826
Validation loss: 2.5542436585283532

Epoch: 5| Step: 9
Training loss: 0.369940360714137
Validation loss: 2.5361846875940848

Epoch: 5| Step: 10
Training loss: 0.48883780232233676
Validation loss: 2.578803063325178

Epoch: 387| Step: 0
Training loss: 0.38514903373225634
Validation loss: 2.608097704268588

Epoch: 5| Step: 1
Training loss: 0.5463751006744858
Validation loss: 2.6467624906408034

Epoch: 5| Step: 2
Training loss: 0.4678552352966225
Validation loss: 2.613451821493743

Epoch: 5| Step: 3
Training loss: 0.8278097596344568
Validation loss: 2.605365902979133

Epoch: 5| Step: 4
Training loss: 1.0273967772748325
Validation loss: 2.5512431945242153

Epoch: 5| Step: 5
Training loss: 0.5627793042498104
Validation loss: 2.5687696689640815

Epoch: 5| Step: 6
Training loss: 0.5120570396840862
Validation loss: 2.5435607351155185

Epoch: 5| Step: 7
Training loss: 0.6997431062288597
Validation loss: 2.5098571242270613

Epoch: 5| Step: 8
Training loss: 0.6505567092307952
Validation loss: 2.521419849130755

Epoch: 5| Step: 9
Training loss: 0.7138148339482809
Validation loss: 2.5229452858215287

Epoch: 5| Step: 10
Training loss: 0.40941252718429144
Validation loss: 2.550857878226866

Epoch: 388| Step: 0
Training loss: 0.8722580454557262
Validation loss: 2.505978943128058

Epoch: 5| Step: 1
Training loss: 0.5017431391392809
Validation loss: 2.502691205794572

Epoch: 5| Step: 2
Training loss: 0.713402300587488
Validation loss: 2.5272293162545814

Epoch: 5| Step: 3
Training loss: 0.6570923938944951
Validation loss: 2.5540947543986356

Epoch: 5| Step: 4
Training loss: 0.6403160745978006
Validation loss: 2.5533085704436864

Epoch: 5| Step: 5
Training loss: 0.2617155758110116
Validation loss: 2.537210404569959

Epoch: 5| Step: 6
Training loss: 0.7448932916271311
Validation loss: 2.5404497474826098

Epoch: 5| Step: 7
Training loss: 0.6233582391285112
Validation loss: 2.5173252357092526

Epoch: 5| Step: 8
Training loss: 0.5380061206363108
Validation loss: 2.5572867678632174

Epoch: 5| Step: 9
Training loss: 0.6171572231157761
Validation loss: 2.5326006521874866

Epoch: 5| Step: 10
Training loss: 0.6390167145311578
Validation loss: 2.5332190965770773

Epoch: 389| Step: 0
Training loss: 0.597842791996767
Validation loss: 2.5130202532119417

Epoch: 5| Step: 1
Training loss: 0.6515233483203814
Validation loss: 2.553417997625141

Epoch: 5| Step: 2
Training loss: 0.8066927174888366
Validation loss: 2.55214755639004

Epoch: 5| Step: 3
Training loss: 0.6450767058589849
Validation loss: 2.5634417860384304

Epoch: 5| Step: 4
Training loss: 0.6660843083828585
Validation loss: 2.576885568079879

Epoch: 5| Step: 5
Training loss: 0.8805852154637962
Validation loss: 2.563095747843905

Epoch: 5| Step: 6
Training loss: 0.45263110571943627
Validation loss: 2.6017208665205493

Epoch: 5| Step: 7
Training loss: 0.5979569121405847
Validation loss: 2.5817324004181263

Epoch: 5| Step: 8
Training loss: 0.39472835640402915
Validation loss: 2.5488898961646567

Epoch: 5| Step: 9
Training loss: 0.7306670873314745
Validation loss: 2.4932506977087145

Epoch: 5| Step: 10
Training loss: 0.2896255602454577
Validation loss: 2.4567726062115542

Epoch: 390| Step: 0
Training loss: 0.6077741233262322
Validation loss: 2.458042429638614

Epoch: 5| Step: 1
Training loss: 0.6451135259345949
Validation loss: 2.4973835964344278

Epoch: 5| Step: 2
Training loss: 0.7165892089710515
Validation loss: 2.475754417845854

Epoch: 5| Step: 3
Training loss: 0.6149844433980154
Validation loss: 2.512906037419002

Epoch: 5| Step: 4
Training loss: 0.6167684653602383
Validation loss: 2.6091885769376804

Epoch: 5| Step: 5
Training loss: 0.7420237310321388
Validation loss: 2.6097864307193377

Epoch: 5| Step: 6
Training loss: 0.7174947392207686
Validation loss: 2.619837560386051

Epoch: 5| Step: 7
Training loss: 0.5442498277568413
Validation loss: 2.6405369350182304

Epoch: 5| Step: 8
Training loss: 0.48196825329910126
Validation loss: 2.6236630495788185

Epoch: 5| Step: 9
Training loss: 0.5073012492732407
Validation loss: 2.5880547106300638

Epoch: 5| Step: 10
Training loss: 0.7603431997125917
Validation loss: 2.5805902680973065

Epoch: 391| Step: 0
Training loss: 0.658434184916533
Validation loss: 2.569638304938878

Epoch: 5| Step: 1
Training loss: 0.6995252864362762
Validation loss: 2.563323063080605

Epoch: 5| Step: 2
Training loss: 0.6841005027395541
Validation loss: 2.561068703625371

Epoch: 5| Step: 3
Training loss: 0.5666582533501643
Validation loss: 2.531777901484377

Epoch: 5| Step: 4
Training loss: 0.8024468196943022
Validation loss: 2.4858613426022056

Epoch: 5| Step: 5
Training loss: 0.33661151514903354
Validation loss: 2.532772601342614

Epoch: 5| Step: 6
Training loss: 0.7501988544693339
Validation loss: 2.5493674594994387

Epoch: 5| Step: 7
Training loss: 0.5309882079950556
Validation loss: 2.5368093191454593

Epoch: 5| Step: 8
Training loss: 0.39313405088670567
Validation loss: 2.5497501847698403

Epoch: 5| Step: 9
Training loss: 0.7106709242502947
Validation loss: 2.534975323355608

Epoch: 5| Step: 10
Training loss: 0.5476482102352234
Validation loss: 2.56487606806945

Epoch: 392| Step: 0
Training loss: 0.669597536097429
Validation loss: 2.5449990795567468

Epoch: 5| Step: 1
Training loss: 0.9845994057771515
Validation loss: 2.5277514443559728

Epoch: 5| Step: 2
Training loss: 0.34699445592123096
Validation loss: 2.521609782115257

Epoch: 5| Step: 3
Training loss: 0.5143361021516597
Validation loss: 2.5250638841417903

Epoch: 5| Step: 4
Training loss: 0.5404398639742395
Validation loss: 2.5385771488983315

Epoch: 5| Step: 5
Training loss: 0.7673628022149862
Validation loss: 2.522114229899713

Epoch: 5| Step: 6
Training loss: 0.7914249820883591
Validation loss: 2.524358308799679

Epoch: 5| Step: 7
Training loss: 0.47116066629812353
Validation loss: 2.512761327517365

Epoch: 5| Step: 8
Training loss: 0.4572563758069789
Validation loss: 2.514902960909364

Epoch: 5| Step: 9
Training loss: 0.3945008067858899
Validation loss: 2.495515336696433

Epoch: 5| Step: 10
Training loss: 0.490719725946436
Validation loss: 2.510741092913955

Epoch: 393| Step: 0
Training loss: 0.8298521923683693
Validation loss: 2.5667419249031864

Epoch: 5| Step: 1
Training loss: 0.6011867836137829
Validation loss: 2.571559698792037

Epoch: 5| Step: 2
Training loss: 0.6959642506028726
Validation loss: 2.599170583835853

Epoch: 5| Step: 3
Training loss: 0.4658452952981091
Validation loss: 2.606929195520432

Epoch: 5| Step: 4
Training loss: 0.7803357305952965
Validation loss: 2.6368641783526727

Epoch: 5| Step: 5
Training loss: 0.5209415768359134
Validation loss: 2.651612587291698

Epoch: 5| Step: 6
Training loss: 0.3771977791890719
Validation loss: 2.6111713897157776

Epoch: 5| Step: 7
Training loss: 0.7276297493553378
Validation loss: 2.6116490394332526

Epoch: 5| Step: 8
Training loss: 0.4867533467887472
Validation loss: 2.5925936028051613

Epoch: 5| Step: 9
Training loss: 0.5107641270084663
Validation loss: 2.557962902470458

Epoch: 5| Step: 10
Training loss: 0.4897687303934789
Validation loss: 2.535032519252704

Epoch: 394| Step: 0
Training loss: 0.7813596267078844
Validation loss: 2.5078527512308804

Epoch: 5| Step: 1
Training loss: 0.5154318303175339
Validation loss: 2.5132026395344202

Epoch: 5| Step: 2
Training loss: 0.6879751557505271
Validation loss: 2.545523325014247

Epoch: 5| Step: 3
Training loss: 0.5182987307020539
Validation loss: 2.5391951381976967

Epoch: 5| Step: 4
Training loss: 0.6481301601943888
Validation loss: 2.528332628148127

Epoch: 5| Step: 5
Training loss: 0.6731336912906346
Validation loss: 2.591867233295551

Epoch: 5| Step: 6
Training loss: 0.3713458760724018
Validation loss: 2.5480170201894294

Epoch: 5| Step: 7
Training loss: 0.3837442347624682
Validation loss: 2.5571460081322854

Epoch: 5| Step: 8
Training loss: 0.5166024566815719
Validation loss: 2.569405866194923

Epoch: 5| Step: 9
Training loss: 0.6278782374066736
Validation loss: 2.5909041819455862

Epoch: 5| Step: 10
Training loss: 0.7716311544509379
Validation loss: 2.588902555233015

Epoch: 395| Step: 0
Training loss: 0.5263672724283182
Validation loss: 2.598082468793895

Epoch: 5| Step: 1
Training loss: 0.3300088437296972
Validation loss: 2.5929284655980798

Epoch: 5| Step: 2
Training loss: 0.7355435590623693
Validation loss: 2.5895574542587005

Epoch: 5| Step: 3
Training loss: 0.5703543294956152
Validation loss: 2.5873476079969193

Epoch: 5| Step: 4
Training loss: 0.7204498011211582
Validation loss: 2.538084226443398

Epoch: 5| Step: 5
Training loss: 0.571975374011812
Validation loss: 2.590560968938406

Epoch: 5| Step: 6
Training loss: 0.7105156621636215
Validation loss: 2.565828934794591

Epoch: 5| Step: 7
Training loss: 0.6647324044107132
Validation loss: 2.5659639509906804

Epoch: 5| Step: 8
Training loss: 0.5582131109285453
Validation loss: 2.5222536250629926

Epoch: 5| Step: 9
Training loss: 0.5303802663634691
Validation loss: 2.4779715592071003

Epoch: 5| Step: 10
Training loss: 0.6002445894638564
Validation loss: 2.484636233306747

Epoch: 396| Step: 0
Training loss: 0.5503068057387884
Validation loss: 2.4933867280888986

Epoch: 5| Step: 1
Training loss: 0.5123762318563067
Validation loss: 2.5179582507721867

Epoch: 5| Step: 2
Training loss: 0.4082457962730747
Validation loss: 2.552820470823846

Epoch: 5| Step: 3
Training loss: 0.669918360575808
Validation loss: 2.5744207146962226

Epoch: 5| Step: 4
Training loss: 0.8133734263312109
Validation loss: 2.6142006377356237

Epoch: 5| Step: 5
Training loss: 0.5440056320522981
Validation loss: 2.6501047728961167

Epoch: 5| Step: 6
Training loss: 0.6444558995446477
Validation loss: 2.6247454489064377

Epoch: 5| Step: 7
Training loss: 0.740508016369049
Validation loss: 2.667260410238323

Epoch: 5| Step: 8
Training loss: 0.41741082575412597
Validation loss: 2.5939852453051544

Epoch: 5| Step: 9
Training loss: 0.38543623367678054
Validation loss: 2.5798375591671756

Epoch: 5| Step: 10
Training loss: 0.7708635367241234
Validation loss: 2.5335539366020265

Epoch: 397| Step: 0
Training loss: 0.7386439406399804
Validation loss: 2.4918601739557698

Epoch: 5| Step: 1
Training loss: 0.5857891403566325
Validation loss: 2.4327670724934403

Epoch: 5| Step: 2
Training loss: 0.7027848798617464
Validation loss: 2.436347162928561

Epoch: 5| Step: 3
Training loss: 0.7029395600664612
Validation loss: 2.4279839907241354

Epoch: 5| Step: 4
Training loss: 0.3561832875814116
Validation loss: 2.445878160377581

Epoch: 5| Step: 5
Training loss: 0.36401852272531837
Validation loss: 2.487584821574368

Epoch: 5| Step: 6
Training loss: 0.6439951429909531
Validation loss: 2.539217279227025

Epoch: 5| Step: 7
Training loss: 0.48752896149511854
Validation loss: 2.57048149312612

Epoch: 5| Step: 8
Training loss: 0.3814331427770173
Validation loss: 2.61414996093036

Epoch: 5| Step: 9
Training loss: 0.6559488650096603
Validation loss: 2.544473634929663

Epoch: 5| Step: 10
Training loss: 0.7892159039029356
Validation loss: 2.5513725859795757

Epoch: 398| Step: 0
Training loss: 0.47886668192709736
Validation loss: 2.536923169183198

Epoch: 5| Step: 1
Training loss: 0.6066515536530566
Validation loss: 2.487014007624967

Epoch: 5| Step: 2
Training loss: 0.38797213955034965
Validation loss: 2.490360741204964

Epoch: 5| Step: 3
Training loss: 0.8051427275730455
Validation loss: 2.4858495379284267

Epoch: 5| Step: 4
Training loss: 0.609940339985664
Validation loss: 2.493543541604317

Epoch: 5| Step: 5
Training loss: 0.5625104108482779
Validation loss: 2.516862346747202

Epoch: 5| Step: 6
Training loss: 0.6035484626009052
Validation loss: 2.5415016825476324

Epoch: 5| Step: 7
Training loss: 0.6896702583899187
Validation loss: 2.553634771355743

Epoch: 5| Step: 8
Training loss: 0.5711051710163532
Validation loss: 2.611462102323699

Epoch: 5| Step: 9
Training loss: 0.6031707963702848
Validation loss: 2.576109367777273

Epoch: 5| Step: 10
Training loss: 0.4762640002588302
Validation loss: 2.6331436885159643

Epoch: 399| Step: 0
Training loss: 0.5358578892514957
Validation loss: 2.620348753679473

Epoch: 5| Step: 1
Training loss: 0.3852900498989756
Validation loss: 2.5912068057707542

Epoch: 5| Step: 2
Training loss: 0.3397385335696759
Validation loss: 2.564440562950488

Epoch: 5| Step: 3
Training loss: 0.9035747767644331
Validation loss: 2.558063536370697

Epoch: 5| Step: 4
Training loss: 0.41963981204102047
Validation loss: 2.518708053105633

Epoch: 5| Step: 5
Training loss: 0.5742916138799409
Validation loss: 2.48013997656104

Epoch: 5| Step: 6
Training loss: 0.4712266187407405
Validation loss: 2.4653944599601085

Epoch: 5| Step: 7
Training loss: 0.4181376499206889
Validation loss: 2.4756298379973276

Epoch: 5| Step: 8
Training loss: 0.8008599219405461
Validation loss: 2.4971236848703118

Epoch: 5| Step: 9
Training loss: 0.800009974775118
Validation loss: 2.4902390601483835

Epoch: 5| Step: 10
Training loss: 0.5381405451320337
Validation loss: 2.5357211391985

Epoch: 400| Step: 0
Training loss: 0.3654218590293904
Validation loss: 2.5712933058368153

Epoch: 5| Step: 1
Training loss: 0.5307252760854667
Validation loss: 2.5588519232504274

Epoch: 5| Step: 2
Training loss: 0.6714352565906511
Validation loss: 2.588064678682875

Epoch: 5| Step: 3
Training loss: 0.6929784023640534
Validation loss: 2.5528084596008456

Epoch: 5| Step: 4
Training loss: 0.6198810277893079
Validation loss: 2.5615359277847496

Epoch: 5| Step: 5
Training loss: 0.6494389120524731
Validation loss: 2.5711991272375077

Epoch: 5| Step: 6
Training loss: 0.6910707122944063
Validation loss: 2.5523012588472347

Epoch: 5| Step: 7
Training loss: 0.6019868716237343
Validation loss: 2.519167425811919

Epoch: 5| Step: 8
Training loss: 0.32323927172126554
Validation loss: 2.5431489859950642

Epoch: 5| Step: 9
Training loss: 0.5775801178650006
Validation loss: 2.540490208678368

Epoch: 5| Step: 10
Training loss: 0.5520167730502449
Validation loss: 2.5437018172696644

Testing loss: 2.404886241838693
