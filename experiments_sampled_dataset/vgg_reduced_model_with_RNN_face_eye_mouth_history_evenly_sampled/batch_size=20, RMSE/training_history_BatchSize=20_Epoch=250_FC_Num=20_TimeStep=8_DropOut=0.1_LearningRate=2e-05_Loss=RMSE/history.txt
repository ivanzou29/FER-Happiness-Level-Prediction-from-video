Epoch: 1| Step: 0
Training loss: 5.835715252628903
Validation loss: 5.757650609988796

Epoch: 5| Step: 1
Training loss: 5.167095084527555
Validation loss: 5.742342947130405

Epoch: 5| Step: 2
Training loss: 6.05552728551085
Validation loss: 5.726990869853195

Epoch: 5| Step: 3
Training loss: 5.697945529044054
Validation loss: 5.710061901637629

Epoch: 5| Step: 4
Training loss: 4.982899988697675
Validation loss: 5.691436175395238

Epoch: 5| Step: 5
Training loss: 7.182299515514958
Validation loss: 5.669672598830526

Epoch: 5| Step: 6
Training loss: 5.532668109723691
Validation loss: 5.6449864811940085

Epoch: 5| Step: 7
Training loss: 5.108406185026863
Validation loss: 5.617251113412051

Epoch: 5| Step: 8
Training loss: 5.481097075918255
Validation loss: 5.585252694880312

Epoch: 5| Step: 9
Training loss: 6.134181089829536
Validation loss: 5.548669581437365

Epoch: 5| Step: 10
Training loss: 5.002597324963057
Validation loss: 5.507515626457244

Epoch: 2| Step: 0
Training loss: 6.1491490961704285
Validation loss: 5.464112583351855

Epoch: 5| Step: 1
Training loss: 5.702332323979853
Validation loss: 5.4169578922003305

Epoch: 5| Step: 2
Training loss: 4.684610518934453
Validation loss: 5.367483142329373

Epoch: 5| Step: 3
Training loss: 5.58850499615425
Validation loss: 5.319007419411574

Epoch: 5| Step: 4
Training loss: 4.640545468660349
Validation loss: 5.2689197255109885

Epoch: 5| Step: 5
Training loss: 5.225667241033787
Validation loss: 5.217017113199906

Epoch: 5| Step: 6
Training loss: 5.322558585687084
Validation loss: 5.1625762225888865

Epoch: 5| Step: 7
Training loss: 5.011688874557779
Validation loss: 5.105953441067259

Epoch: 5| Step: 8
Training loss: 4.596862983817571
Validation loss: 5.045623696306213

Epoch: 5| Step: 9
Training loss: 6.136149942806602
Validation loss: 4.984324924051446

Epoch: 5| Step: 10
Training loss: 4.4315827367170035
Validation loss: 4.92323072922765

Epoch: 3| Step: 0
Training loss: 5.416544555852662
Validation loss: 4.864515818406044

Epoch: 5| Step: 1
Training loss: 5.031049831033653
Validation loss: 4.8017610938254185

Epoch: 5| Step: 2
Training loss: 4.861816185574528
Validation loss: 4.7441520205283085

Epoch: 5| Step: 3
Training loss: 5.325833809632278
Validation loss: 4.683683530323356

Epoch: 5| Step: 4
Training loss: 3.5051214350017728
Validation loss: 4.62328612730922

Epoch: 5| Step: 5
Training loss: 5.231301569712957
Validation loss: 4.570568067544566

Epoch: 5| Step: 6
Training loss: 4.005671771569999
Validation loss: 4.526382958870243

Epoch: 5| Step: 7
Training loss: 4.284539733880545
Validation loss: 4.488007895199886

Epoch: 5| Step: 8
Training loss: 4.574732021133648
Validation loss: 4.446724904362178

Epoch: 5| Step: 9
Training loss: 4.9155218871421615
Validation loss: 4.40609844979578

Epoch: 5| Step: 10
Training loss: 4.0882354168078665
Validation loss: 4.371188933004509

Epoch: 4| Step: 0
Training loss: 4.4993548460597905
Validation loss: 4.342900809704893

Epoch: 5| Step: 1
Training loss: 3.986232548959883
Validation loss: 4.316429242134246

Epoch: 5| Step: 2
Training loss: 4.755522880164655
Validation loss: 4.294879338472221

Epoch: 5| Step: 3
Training loss: 4.651819566332078
Validation loss: 4.272228233870162

Epoch: 5| Step: 4
Training loss: 4.089181928453923
Validation loss: 4.259246736943727

Epoch: 5| Step: 5
Training loss: 3.7004275255387906
Validation loss: 4.2471121664900275

Epoch: 5| Step: 6
Training loss: 3.366892649050381
Validation loss: 4.2368139989124645

Epoch: 5| Step: 7
Training loss: 4.7963489157006265
Validation loss: 4.230004333984153

Epoch: 5| Step: 8
Training loss: 5.452275338422189
Validation loss: 4.214516357667005

Epoch: 5| Step: 9
Training loss: 4.79861368981878
Validation loss: 4.19645504534658

Epoch: 5| Step: 10
Training loss: 3.522480972271136
Validation loss: 4.181575551961452

Epoch: 5| Step: 0
Training loss: 3.9737034920523477
Validation loss: 4.163859778409536

Epoch: 5| Step: 1
Training loss: 4.318841224954581
Validation loss: 4.147828403946567

Epoch: 5| Step: 2
Training loss: 5.220518988756088
Validation loss: 4.1295986625842485

Epoch: 5| Step: 3
Training loss: 4.181526136189599
Validation loss: 4.109120636554706

Epoch: 5| Step: 4
Training loss: 4.828170430485087
Validation loss: 4.0900898000727

Epoch: 5| Step: 5
Training loss: 3.8462277001846212
Validation loss: 4.071857081778605

Epoch: 5| Step: 6
Training loss: 3.898169621072603
Validation loss: 4.058718313447588

Epoch: 5| Step: 7
Training loss: 4.186522640213068
Validation loss: 4.043764130642038

Epoch: 5| Step: 8
Training loss: 3.9398015879520125
Validation loss: 4.028835218548055

Epoch: 5| Step: 9
Training loss: 3.236479880551077
Validation loss: 4.0132177182338395

Epoch: 5| Step: 10
Training loss: 4.580305289875547
Validation loss: 4.001199314331664

Epoch: 6| Step: 0
Training loss: 4.471684486068347
Validation loss: 3.9852076780526984

Epoch: 5| Step: 1
Training loss: 4.2249680647687065
Validation loss: 3.96924712814353

Epoch: 5| Step: 2
Training loss: 4.089819032727363
Validation loss: 3.959267074909264

Epoch: 5| Step: 3
Training loss: 3.928228209724555
Validation loss: 3.9441648695493403

Epoch: 5| Step: 4
Training loss: 3.914358040317448
Validation loss: 3.934642462584194

Epoch: 5| Step: 5
Training loss: 4.226879735524064
Validation loss: 3.92116392551603

Epoch: 5| Step: 6
Training loss: 4.099560058064491
Validation loss: 3.9060095718389416

Epoch: 5| Step: 7
Training loss: 4.555562218348482
Validation loss: 3.890906404671053

Epoch: 5| Step: 8
Training loss: 3.0755127021925395
Validation loss: 3.878681112177256

Epoch: 5| Step: 9
Training loss: 4.318676271375116
Validation loss: 3.864903153879764

Epoch: 5| Step: 10
Training loss: 3.7304420350401415
Validation loss: 3.8506448891478136

Epoch: 7| Step: 0
Training loss: 4.171899459710015
Validation loss: 3.836110217196311

Epoch: 5| Step: 1
Training loss: 5.579144211093116
Validation loss: 3.8227479252615675

Epoch: 5| Step: 2
Training loss: 3.9901780896131207
Validation loss: 3.809476991041995

Epoch: 5| Step: 3
Training loss: 3.9301295249890833
Validation loss: 3.7952660171655412

Epoch: 5| Step: 4
Training loss: 3.745269079995105
Validation loss: 3.7844996599352907

Epoch: 5| Step: 5
Training loss: 3.9131674590257353
Validation loss: 3.7766565653757804

Epoch: 5| Step: 6
Training loss: 3.6101884461985403
Validation loss: 3.7681744522891716

Epoch: 5| Step: 7
Training loss: 3.3977103321352504
Validation loss: 3.759035326429578

Epoch: 5| Step: 8
Training loss: 3.5470153511947657
Validation loss: 3.7545608595628157

Epoch: 5| Step: 9
Training loss: 3.610114348019177
Validation loss: 3.742351831087251

Epoch: 5| Step: 10
Training loss: 3.5915298902013153
Validation loss: 3.73594610166984

Epoch: 8| Step: 0
Training loss: 3.9854899921973552
Validation loss: 3.7226720092386154

Epoch: 5| Step: 1
Training loss: 4.294537050390048
Validation loss: 3.711645626774678

Epoch: 5| Step: 2
Training loss: 3.1829481347856348
Validation loss: 3.698373618252803

Epoch: 5| Step: 3
Training loss: 3.859377594611033
Validation loss: 3.6891991211759754

Epoch: 5| Step: 4
Training loss: 3.7337316493581785
Validation loss: 3.677773196052903

Epoch: 5| Step: 5
Training loss: 4.351999038359592
Validation loss: 3.6683279820381953

Epoch: 5| Step: 6
Training loss: 3.1245267891226063
Validation loss: 3.6590273138872105

Epoch: 5| Step: 7
Training loss: 4.09274279601838
Validation loss: 3.6514459220325244

Epoch: 5| Step: 8
Training loss: 3.6283364562087024
Validation loss: 3.6418559534439776

Epoch: 5| Step: 9
Training loss: 4.279470700486026
Validation loss: 3.637220634239739

Epoch: 5| Step: 10
Training loss: 3.6997274917050875
Validation loss: 3.628444821247282

Epoch: 9| Step: 0
Training loss: 3.4935085861517665
Validation loss: 3.6249139441041054

Epoch: 5| Step: 1
Training loss: 4.4995960478142765
Validation loss: 3.6217219828818066

Epoch: 5| Step: 2
Training loss: 4.218068611784392
Validation loss: 3.610128777776404

Epoch: 5| Step: 3
Training loss: 3.1852173953518235
Validation loss: 3.601849477514169

Epoch: 5| Step: 4
Training loss: 3.5564279843593867
Validation loss: 3.5982285381393915

Epoch: 5| Step: 5
Training loss: 4.182392934647585
Validation loss: 3.5909780290162314

Epoch: 5| Step: 6
Training loss: 4.521972840785616
Validation loss: 3.582320089856351

Epoch: 5| Step: 7
Training loss: 4.183756507250737
Validation loss: 3.5779301132245847

Epoch: 5| Step: 8
Training loss: 2.4684875928270658
Validation loss: 3.570110610542572

Epoch: 5| Step: 9
Training loss: 3.424646657273251
Validation loss: 3.565493237426514

Epoch: 5| Step: 10
Training loss: 3.4395153726710297
Validation loss: 3.562521867697553

Epoch: 10| Step: 0
Training loss: 3.6127695742016064
Validation loss: 3.5632634132020966

Epoch: 5| Step: 1
Training loss: 3.871084265211324
Validation loss: 3.552559885798716

Epoch: 5| Step: 2
Training loss: 2.9550239068886066
Validation loss: 3.5455145406634356

Epoch: 5| Step: 3
Training loss: 3.155837683609619
Validation loss: 3.5463500316294567

Epoch: 5| Step: 4
Training loss: 3.2315728031854083
Validation loss: 3.543798904817942

Epoch: 5| Step: 5
Training loss: 4.037251108723927
Validation loss: 3.532759924146426

Epoch: 5| Step: 6
Training loss: 3.9922792308443618
Validation loss: 3.525650069316013

Epoch: 5| Step: 7
Training loss: 4.114309387101082
Validation loss: 3.5244080643969693

Epoch: 5| Step: 8
Training loss: 3.669351692833916
Validation loss: 3.517763197391331

Epoch: 5| Step: 9
Training loss: 4.106526943488579
Validation loss: 3.513292671709756

Epoch: 5| Step: 10
Training loss: 4.244587087869536
Validation loss: 3.51197896050357

Epoch: 11| Step: 0
Training loss: 4.018193592335168
Validation loss: 3.5093663094091108

Epoch: 5| Step: 1
Training loss: 3.6094148972192923
Validation loss: 3.499907233067984

Epoch: 5| Step: 2
Training loss: 4.1117407657382525
Validation loss: 3.4940048032988775

Epoch: 5| Step: 3
Training loss: 3.603097187341838
Validation loss: 3.4904075642161176

Epoch: 5| Step: 4
Training loss: 3.4692257391684795
Validation loss: 3.4889350657514835

Epoch: 5| Step: 5
Training loss: 3.9049209164708576
Validation loss: 3.4835599945560256

Epoch: 5| Step: 6
Training loss: 3.1937840170644365
Validation loss: 3.479885588278496

Epoch: 5| Step: 7
Training loss: 3.826378747119298
Validation loss: 3.481650038657739

Epoch: 5| Step: 8
Training loss: 3.336764731120492
Validation loss: 3.4722133361265173

Epoch: 5| Step: 9
Training loss: 3.986666031925657
Validation loss: 3.4680703962694897

Epoch: 5| Step: 10
Training loss: 3.5043309527398474
Validation loss: 3.465799041842641

Epoch: 12| Step: 0
Training loss: 3.82467433565313
Validation loss: 3.4599177149464433

Epoch: 5| Step: 1
Training loss: 4.142412368501341
Validation loss: 3.4549004029359764

Epoch: 5| Step: 2
Training loss: 4.203524772606439
Validation loss: 3.4548521899256226

Epoch: 5| Step: 3
Training loss: 3.3757607344410308
Validation loss: 3.4483851970857424

Epoch: 5| Step: 4
Training loss: 3.8592119066627246
Validation loss: 3.4445584421438595

Epoch: 5| Step: 5
Training loss: 3.2151832447660453
Validation loss: 3.438570681052653

Epoch: 5| Step: 6
Training loss: 3.1350383509186863
Validation loss: 3.4287660065178405

Epoch: 5| Step: 7
Training loss: 3.4312662648856023
Validation loss: 3.4254492264873626

Epoch: 5| Step: 8
Training loss: 4.007044787429608
Validation loss: 3.4170362726321066

Epoch: 5| Step: 9
Training loss: 2.9828314659191104
Validation loss: 3.3800320167478968

Epoch: 5| Step: 10
Training loss: 3.746884132355035
Validation loss: 3.36075948472977

Epoch: 13| Step: 0
Training loss: 3.5640531132569016
Validation loss: 3.354173314164324

Epoch: 5| Step: 1
Training loss: 4.188328447522492
Validation loss: 3.370068058237

Epoch: 5| Step: 2
Training loss: 4.094148805717664
Validation loss: 3.3720409466786543

Epoch: 5| Step: 3
Training loss: 3.4876779545054415
Validation loss: 3.3577858900176687

Epoch: 5| Step: 4
Training loss: 3.4559615554613954
Validation loss: 3.3569790827349277

Epoch: 5| Step: 5
Training loss: 3.327822102835444
Validation loss: 3.3584499549774653

Epoch: 5| Step: 6
Training loss: 3.8548816052178023
Validation loss: 3.3533055652280996

Epoch: 5| Step: 7
Training loss: 3.3609964405462045
Validation loss: 3.33815959634273

Epoch: 5| Step: 8
Training loss: 3.0065100289740077
Validation loss: 3.3317456114755584

Epoch: 5| Step: 9
Training loss: 3.3197474817966963
Validation loss: 3.328829043658963

Epoch: 5| Step: 10
Training loss: 3.6273705196604684
Validation loss: 3.3246525222294285

Epoch: 14| Step: 0
Training loss: 4.033747882399167
Validation loss: 3.3187303342322103

Epoch: 5| Step: 1
Training loss: 3.859371293409784
Validation loss: 3.3137178478933302

Epoch: 5| Step: 2
Training loss: 2.9326656412497316
Validation loss: 3.308027942271079

Epoch: 5| Step: 3
Training loss: 4.075914507327763
Validation loss: 3.30493701807474

Epoch: 5| Step: 4
Training loss: 3.358771265471545
Validation loss: 3.302319667892766

Epoch: 5| Step: 5
Training loss: 3.565199515175527
Validation loss: 3.300036638851377

Epoch: 5| Step: 6
Training loss: 3.741173720367612
Validation loss: 3.298711560196371

Epoch: 5| Step: 7
Training loss: 3.4884435054211695
Validation loss: 3.2946763184958248

Epoch: 5| Step: 8
Training loss: 2.330122020784402
Validation loss: 3.291968627097388

Epoch: 5| Step: 9
Training loss: 3.111246283940096
Validation loss: 3.2910979607677926

Epoch: 5| Step: 10
Training loss: 4.1731686533001175
Validation loss: 3.290139839668184

Epoch: 15| Step: 0
Training loss: 3.463262255113359
Validation loss: 3.288896823407134

Epoch: 5| Step: 1
Training loss: 4.019899935259826
Validation loss: 3.286249792273215

Epoch: 5| Step: 2
Training loss: 3.700577000140947
Validation loss: 3.284592772259879

Epoch: 5| Step: 3
Training loss: 3.080944957683501
Validation loss: 3.284189964903494

Epoch: 5| Step: 4
Training loss: 3.746756867876209
Validation loss: 3.2818860446896574

Epoch: 5| Step: 5
Training loss: 2.6236490678933264
Validation loss: 3.281399324909232

Epoch: 5| Step: 6
Training loss: 4.154414639330479
Validation loss: 3.278746420659528

Epoch: 5| Step: 7
Training loss: 2.7803242889459643
Validation loss: 3.277263007097732

Epoch: 5| Step: 8
Training loss: 2.977661250413955
Validation loss: 3.2766872295358294

Epoch: 5| Step: 9
Training loss: 4.30285760717764
Validation loss: 3.2756248717769947

Epoch: 5| Step: 10
Training loss: 3.5161384716172535
Validation loss: 3.2760180739797766

Epoch: 16| Step: 0
Training loss: 3.782969942720192
Validation loss: 3.2767979199147157

Epoch: 5| Step: 1
Training loss: 4.071378425537909
Validation loss: 3.2761642490768113

Epoch: 5| Step: 2
Training loss: 3.611317033683617
Validation loss: 3.2728364426754237

Epoch: 5| Step: 3
Training loss: 3.220042737594269
Validation loss: 3.2716931405063394

Epoch: 5| Step: 4
Training loss: 3.413366041573134
Validation loss: 3.2728124169486366

Epoch: 5| Step: 5
Training loss: 3.4737925949862
Validation loss: 3.2698187559842977

Epoch: 5| Step: 6
Training loss: 3.4597383578827
Validation loss: 3.2672271527275805

Epoch: 5| Step: 7
Training loss: 3.108758759894643
Validation loss: 3.265645194262294

Epoch: 5| Step: 8
Training loss: 4.133488561935353
Validation loss: 3.26589678464379

Epoch: 5| Step: 9
Training loss: 3.4507913428261108
Validation loss: 3.263171434992433

Epoch: 5| Step: 10
Training loss: 2.5905538882813457
Validation loss: 3.2618258771030066

Epoch: 17| Step: 0
Training loss: 3.5452594859033515
Validation loss: 3.261214974365513

Epoch: 5| Step: 1
Training loss: 4.298105514502168
Validation loss: 3.259377217769119

Epoch: 5| Step: 2
Training loss: 3.6686860217051134
Validation loss: 3.25808462160905

Epoch: 5| Step: 3
Training loss: 2.8448105396011147
Validation loss: 3.257301685356895

Epoch: 5| Step: 4
Training loss: 3.061739145859758
Validation loss: 3.2566646586912924

Epoch: 5| Step: 5
Training loss: 4.045265378416047
Validation loss: 3.255256303725003

Epoch: 5| Step: 6
Training loss: 3.682064252608767
Validation loss: 3.253982519218532

Epoch: 5| Step: 7
Training loss: 3.902005139877868
Validation loss: 3.2529406247622052

Epoch: 5| Step: 8
Training loss: 3.200875883633153
Validation loss: 3.251304579186944

Epoch: 5| Step: 9
Training loss: 3.1759725327733337
Validation loss: 3.250750492897767

Epoch: 5| Step: 10
Training loss: 2.6834028195532036
Validation loss: 3.2492045587866696

Epoch: 18| Step: 0
Training loss: 3.8380090282705726
Validation loss: 3.2489484122199457

Epoch: 5| Step: 1
Training loss: 3.8315597384083286
Validation loss: 3.2475108371286563

Epoch: 5| Step: 2
Training loss: 3.225064943827758
Validation loss: 3.2466607178222966

Epoch: 5| Step: 3
Training loss: 3.256324336691599
Validation loss: 3.2456456509097054

Epoch: 5| Step: 4
Training loss: 3.7838122301431603
Validation loss: 3.2448277986059018

Epoch: 5| Step: 5
Training loss: 4.004094174324619
Validation loss: 3.2437711380343264

Epoch: 5| Step: 6
Training loss: 3.0033380692840166
Validation loss: 3.2432495828801415

Epoch: 5| Step: 7
Training loss: 3.6664285726983326
Validation loss: 3.241524733897377

Epoch: 5| Step: 8
Training loss: 3.4687644339596226
Validation loss: 3.240869364499738

Epoch: 5| Step: 9
Training loss: 2.731834583005312
Validation loss: 3.2396445272365315

Epoch: 5| Step: 10
Training loss: 3.445659455629282
Validation loss: 3.2392176923715414

Epoch: 19| Step: 0
Training loss: 3.0339296432515037
Validation loss: 3.2382549111294

Epoch: 5| Step: 1
Training loss: 3.090990936246262
Validation loss: 3.2383291692533196

Epoch: 5| Step: 2
Training loss: 3.4819686175339393
Validation loss: 3.236098790150075

Epoch: 5| Step: 3
Training loss: 3.521665004640167
Validation loss: 3.235321144322115

Epoch: 5| Step: 4
Training loss: 3.403995152560771
Validation loss: 3.234693090994355

Epoch: 5| Step: 5
Training loss: 4.161137969186842
Validation loss: 3.2335340030596313

Epoch: 5| Step: 6
Training loss: 3.625530598711364
Validation loss: 3.233177492449653

Epoch: 5| Step: 7
Training loss: 3.9672445009936133
Validation loss: 3.2317675264872476

Epoch: 5| Step: 8
Training loss: 3.6180497989295533
Validation loss: 3.2307829025794685

Epoch: 5| Step: 9
Training loss: 3.171485162841308
Validation loss: 3.2300986785175416

Epoch: 5| Step: 10
Training loss: 3.0591973382722775
Validation loss: 3.2290801376409344

Epoch: 20| Step: 0
Training loss: 2.8238923661141815
Validation loss: 3.2281038555111965

Epoch: 5| Step: 1
Training loss: 3.601099344456837
Validation loss: 3.227203045743848

Epoch: 5| Step: 2
Training loss: 3.599102247409024
Validation loss: 3.226280789058799

Epoch: 5| Step: 3
Training loss: 3.1774621622997623
Validation loss: 3.225424190350072

Epoch: 5| Step: 4
Training loss: 2.7627122271044593
Validation loss: 3.224220868071619

Epoch: 5| Step: 5
Training loss: 3.543500059217967
Validation loss: 3.223323816767959

Epoch: 5| Step: 6
Training loss: 3.451343473821751
Validation loss: 3.2227041661195246

Epoch: 5| Step: 7
Training loss: 3.3856450087005525
Validation loss: 3.2219226706996142

Epoch: 5| Step: 8
Training loss: 4.067397232304871
Validation loss: 3.220727928682653

Epoch: 5| Step: 9
Training loss: 3.1454436879815058
Validation loss: 3.2198314353384085

Epoch: 5| Step: 10
Training loss: 4.5389450504517574
Validation loss: 3.2190140383813315

Epoch: 21| Step: 0
Training loss: 3.56819808085965
Validation loss: 3.217999686363278

Epoch: 5| Step: 1
Training loss: 2.8373871768249987
Validation loss: 3.217086824251538

Epoch: 5| Step: 2
Training loss: 3.4385493670846037
Validation loss: 3.2157511214787013

Epoch: 5| Step: 3
Training loss: 3.44202638336479
Validation loss: 3.2153193997220115

Epoch: 5| Step: 4
Training loss: 3.2436323140869803
Validation loss: 3.214815901727114

Epoch: 5| Step: 5
Training loss: 3.370986388652869
Validation loss: 3.2145575365306343

Epoch: 5| Step: 6
Training loss: 3.7546573963141148
Validation loss: 3.2145442085218394

Epoch: 5| Step: 7
Training loss: 3.745742797323213
Validation loss: 3.2164836853390675

Epoch: 5| Step: 8
Training loss: 3.774071555247194
Validation loss: 3.215386509502908

Epoch: 5| Step: 9
Training loss: 3.6379168346980113
Validation loss: 3.2147660003870735

Epoch: 5| Step: 10
Training loss: 3.261875317864623
Validation loss: 3.211469941804445

Epoch: 22| Step: 0
Training loss: 3.5576389007366482
Validation loss: 3.2096039730702457

Epoch: 5| Step: 1
Training loss: 2.675130188527977
Validation loss: 3.2084000421649077

Epoch: 5| Step: 2
Training loss: 3.325817328936835
Validation loss: 3.207731730440243

Epoch: 5| Step: 3
Training loss: 3.021038513231053
Validation loss: 3.2069431393899563

Epoch: 5| Step: 4
Training loss: 3.016555089274588
Validation loss: 3.207282942894955

Epoch: 5| Step: 5
Training loss: 3.294983814066609
Validation loss: 3.204948764476157

Epoch: 5| Step: 6
Training loss: 3.6711386084225937
Validation loss: 3.205211855403374

Epoch: 5| Step: 7
Training loss: 3.4691113807829566
Validation loss: 3.2030590051574945

Epoch: 5| Step: 8
Training loss: 3.830088831815096
Validation loss: 3.201619405231779

Epoch: 5| Step: 9
Training loss: 3.7078663535533463
Validation loss: 3.2003339218939786

Epoch: 5| Step: 10
Training loss: 4.39567302875594
Validation loss: 3.199291152051692

Epoch: 23| Step: 0
Training loss: 3.499418482836481
Validation loss: 3.198307874540908

Epoch: 5| Step: 1
Training loss: 3.084110849310537
Validation loss: 3.1970344013983913

Epoch: 5| Step: 2
Training loss: 3.518485977810599
Validation loss: 3.1970073875224805

Epoch: 5| Step: 3
Training loss: 3.218169372928343
Validation loss: 3.196546276908142

Epoch: 5| Step: 4
Training loss: 3.778747991876198
Validation loss: 3.206607522768474

Epoch: 5| Step: 5
Training loss: 3.512899605497667
Validation loss: 3.1933662237107905

Epoch: 5| Step: 6
Training loss: 3.5271239354785346
Validation loss: 3.1922555587789656

Epoch: 5| Step: 7
Training loss: 3.203112644078684
Validation loss: 3.191214749976252

Epoch: 5| Step: 8
Training loss: 3.45713249101402
Validation loss: 3.19044007083818

Epoch: 5| Step: 9
Training loss: 3.2691243236352743
Validation loss: 3.189187398057646

Epoch: 5| Step: 10
Training loss: 3.937833015043949
Validation loss: 3.1885913602767744

Epoch: 24| Step: 0
Training loss: 4.0371918173881385
Validation loss: 3.1878852732040284

Epoch: 5| Step: 1
Training loss: 3.6823228603626297
Validation loss: 3.1860688141458726

Epoch: 5| Step: 2
Training loss: 3.6380451541088603
Validation loss: 3.184924167259538

Epoch: 5| Step: 3
Training loss: 3.1441398424395692
Validation loss: 3.183642574529541

Epoch: 5| Step: 4
Training loss: 2.9348346711730016
Validation loss: 3.1822969637228327

Epoch: 5| Step: 5
Training loss: 3.070353811049211
Validation loss: 3.1835563822051216

Epoch: 5| Step: 6
Training loss: 4.148498189880925
Validation loss: 3.185655243826334

Epoch: 5| Step: 7
Training loss: 3.137342113154564
Validation loss: 3.179909961500494

Epoch: 5| Step: 8
Training loss: 3.580522159025749
Validation loss: 3.179096903287049

Epoch: 5| Step: 9
Training loss: 2.9352617867742175
Validation loss: 3.1795358655190813

Epoch: 5| Step: 10
Training loss: 3.343170400993363
Validation loss: 3.1794126646368337

Epoch: 25| Step: 0
Training loss: 3.4695681045385536
Validation loss: 3.18081830612036

Epoch: 5| Step: 1
Training loss: 3.4340751926674584
Validation loss: 3.1787032789361103

Epoch: 5| Step: 2
Training loss: 3.2671017752757208
Validation loss: 3.178319743232274

Epoch: 5| Step: 3
Training loss: 3.8661844204934925
Validation loss: 3.1759765179104047

Epoch: 5| Step: 4
Training loss: 4.256729408186126
Validation loss: 3.173748873823144

Epoch: 5| Step: 5
Training loss: 2.9290625961142527
Validation loss: 3.1726311877885407

Epoch: 5| Step: 6
Training loss: 3.402520193787014
Validation loss: 3.171689904089745

Epoch: 5| Step: 7
Training loss: 4.1821090386002835
Validation loss: 3.170702074997305

Epoch: 5| Step: 8
Training loss: 2.8357217669860173
Validation loss: 3.170347222346907

Epoch: 5| Step: 9
Training loss: 2.9889280728683105
Validation loss: 3.170333756188415

Epoch: 5| Step: 10
Training loss: 2.7215225289327076
Validation loss: 3.171212214848039

Epoch: 26| Step: 0
Training loss: 4.1161630937685105
Validation loss: 3.1717407773631208

Epoch: 5| Step: 1
Training loss: 3.769169575630149
Validation loss: 3.167285114532872

Epoch: 5| Step: 2
Training loss: 3.2184791821370555
Validation loss: 3.1650000014437385

Epoch: 5| Step: 3
Training loss: 3.4239013803308422
Validation loss: 3.1645279485653153

Epoch: 5| Step: 4
Training loss: 3.699883051905603
Validation loss: 3.162971729688136

Epoch: 5| Step: 5
Training loss: 2.7981637723927717
Validation loss: 3.1620131016997832

Epoch: 5| Step: 6
Training loss: 2.8588356384874145
Validation loss: 3.161210705311444

Epoch: 5| Step: 7
Training loss: 3.3157659301145044
Validation loss: 3.1604250992505576

Epoch: 5| Step: 8
Training loss: 3.345574567454949
Validation loss: 3.1601402831621397

Epoch: 5| Step: 9
Training loss: 4.212424049485126
Validation loss: 3.1587100664361305

Epoch: 5| Step: 10
Training loss: 2.41705433158746
Validation loss: 3.1582974802786876

Epoch: 27| Step: 0
Training loss: 3.2400193651821545
Validation loss: 3.157590261705748

Epoch: 5| Step: 1
Training loss: 3.5015650383643466
Validation loss: 3.157501792832834

Epoch: 5| Step: 2
Training loss: 3.71013971687725
Validation loss: 3.1569357733849857

Epoch: 5| Step: 3
Training loss: 4.157490480633434
Validation loss: 3.155940575643159

Epoch: 5| Step: 4
Training loss: 2.3437594604301255
Validation loss: 3.15490078463537

Epoch: 5| Step: 5
Training loss: 3.8927961672185867
Validation loss: 3.153315642640533

Epoch: 5| Step: 6
Training loss: 3.9242375161696046
Validation loss: 3.1525956438366394

Epoch: 5| Step: 7
Training loss: 3.20123324472138
Validation loss: 3.1513005268888197

Epoch: 5| Step: 8
Training loss: 3.4420567221436937
Validation loss: 3.150427204624094

Epoch: 5| Step: 9
Training loss: 2.7563152625559946
Validation loss: 3.1495002938151124

Epoch: 5| Step: 10
Training loss: 3.0003350388679904
Validation loss: 3.1485376488924914

Epoch: 28| Step: 0
Training loss: 3.5084011883792035
Validation loss: 3.1478508522044146

Epoch: 5| Step: 1
Training loss: 3.387788350688044
Validation loss: 3.147170168181738

Epoch: 5| Step: 2
Training loss: 3.051569369181897
Validation loss: 3.1458244809848748

Epoch: 5| Step: 3
Training loss: 3.2624183498410932
Validation loss: 3.145141288024807

Epoch: 5| Step: 4
Training loss: 3.4362198266529047
Validation loss: 3.1445936680492177

Epoch: 5| Step: 5
Training loss: 3.7487434825223644
Validation loss: 3.1438788199132506

Epoch: 5| Step: 6
Training loss: 4.162795570120897
Validation loss: 3.1427783941382805

Epoch: 5| Step: 7
Training loss: 2.7659541219794335
Validation loss: 3.142042090622325

Epoch: 5| Step: 8
Training loss: 3.227709106952106
Validation loss: 3.1416406615106793

Epoch: 5| Step: 9
Training loss: 3.350436930844017
Validation loss: 3.14051826584239

Epoch: 5| Step: 10
Training loss: 3.492404871241015
Validation loss: 3.1377220591958364

Epoch: 29| Step: 0
Training loss: 3.547980585752611
Validation loss: 3.1381430739160034

Epoch: 5| Step: 1
Training loss: 3.681828938734993
Validation loss: 3.136586145155116

Epoch: 5| Step: 2
Training loss: 3.33105382860587
Validation loss: 3.1482906011605465

Epoch: 5| Step: 3
Training loss: 4.006223843350772
Validation loss: 3.1333247423108768

Epoch: 5| Step: 4
Training loss: 3.1198379606570654
Validation loss: 3.134239506994301

Epoch: 5| Step: 5
Training loss: 3.605834148898531
Validation loss: 3.1339288256515623

Epoch: 5| Step: 6
Training loss: 3.142713165700955
Validation loss: 3.1350374644903463

Epoch: 5| Step: 7
Training loss: 3.4462422956588794
Validation loss: 3.1373301453324367

Epoch: 5| Step: 8
Training loss: 3.1444153947989806
Validation loss: 3.1382155314297004

Epoch: 5| Step: 9
Training loss: 2.9833902861488477
Validation loss: 3.1346563277819564

Epoch: 5| Step: 10
Training loss: 3.3769336388788576
Validation loss: 3.134240462355817

Epoch: 30| Step: 0
Training loss: 3.5922729110353515
Validation loss: 3.1304911256283448

Epoch: 5| Step: 1
Training loss: 3.413397892351372
Validation loss: 3.1283709927632715

Epoch: 5| Step: 2
Training loss: 2.6070366164058774
Validation loss: 3.126022161852431

Epoch: 5| Step: 3
Training loss: 3.3068469772348354
Validation loss: 3.124766287319114

Epoch: 5| Step: 4
Training loss: 4.012804993063271
Validation loss: 3.1244448047613553

Epoch: 5| Step: 5
Training loss: 2.640037245487695
Validation loss: 3.122185770131778

Epoch: 5| Step: 6
Training loss: 3.6313736229763576
Validation loss: 3.122377935503969

Epoch: 5| Step: 7
Training loss: 3.714636057794911
Validation loss: 3.2124563162561093

Epoch: 5| Step: 8
Training loss: 3.411077875174915
Validation loss: 3.1997206690348525

Epoch: 5| Step: 9
Training loss: 3.829900586703044
Validation loss: 3.178527438201834

Epoch: 5| Step: 10
Training loss: 3.1466827424764823
Validation loss: 3.18231463680386

Epoch: 31| Step: 0
Training loss: 3.321468089347644
Validation loss: 3.1842335631629632

Epoch: 5| Step: 1
Training loss: 2.7900749527355577
Validation loss: 3.1802182572569038

Epoch: 5| Step: 2
Training loss: 3.498347300925199
Validation loss: 3.1878169588013856

Epoch: 5| Step: 3
Training loss: 3.5333928720988035
Validation loss: 3.1980612325557662

Epoch: 5| Step: 4
Training loss: 3.9395990982964055
Validation loss: 3.181662228173906

Epoch: 5| Step: 5
Training loss: 3.2096730362220205
Validation loss: 3.1863616786349906

Epoch: 5| Step: 6
Training loss: 3.312377063701201
Validation loss: 3.174555040437485

Epoch: 5| Step: 7
Training loss: 3.602808672608205
Validation loss: 3.1695607895055353

Epoch: 5| Step: 8
Training loss: 3.2912619297667622
Validation loss: 3.1736695447355405

Epoch: 5| Step: 9
Training loss: 3.849443762094318
Validation loss: 3.2021784646698004

Epoch: 5| Step: 10
Training loss: 3.427052104463687
Validation loss: 3.174949461689999

Epoch: 32| Step: 0
Training loss: 3.208193458051155
Validation loss: 3.1592024935140577

Epoch: 5| Step: 1
Training loss: 3.488850546043696
Validation loss: 3.1629717685929255

Epoch: 5| Step: 2
Training loss: 3.484865436336818
Validation loss: 3.161547151531472

Epoch: 5| Step: 3
Training loss: 4.001807043072586
Validation loss: 3.1456434006057434

Epoch: 5| Step: 4
Training loss: 2.689865579330942
Validation loss: 3.1099110058529456

Epoch: 5| Step: 5
Training loss: 2.989999952539552
Validation loss: 3.1542649583221847

Epoch: 5| Step: 6
Training loss: 3.63163387088285
Validation loss: 3.188790086217921

Epoch: 5| Step: 7
Training loss: 3.7283186703153306
Validation loss: 3.0995168310700425

Epoch: 5| Step: 8
Training loss: 3.2555345214175815
Validation loss: 3.1192152548228154

Epoch: 5| Step: 9
Training loss: 3.2229842695277826
Validation loss: 3.1362687874676216

Epoch: 5| Step: 10
Training loss: 3.7986945670609473
Validation loss: 3.1678470835886565

Epoch: 33| Step: 0
Training loss: 3.443160234687517
Validation loss: 3.1215355256395823

Epoch: 5| Step: 1
Training loss: 3.33089092101464
Validation loss: 3.133707401449739

Epoch: 5| Step: 2
Training loss: 3.2689253634208613
Validation loss: 3.147860208130485

Epoch: 5| Step: 3
Training loss: 3.4797126813644588
Validation loss: 3.1583770290694915

Epoch: 5| Step: 4
Training loss: 3.3540129695452774
Validation loss: 3.149424532222428

Epoch: 5| Step: 5
Training loss: 3.1797858745531613
Validation loss: 3.1514884131004934

Epoch: 5| Step: 6
Training loss: 3.5779686772876946
Validation loss: 3.1391894878432067

Epoch: 5| Step: 7
Training loss: 3.6946416975884917
Validation loss: 3.119045409837207

Epoch: 5| Step: 8
Training loss: 2.8678682854705193
Validation loss: 3.0953335488462335

Epoch: 5| Step: 9
Training loss: 3.7890043588483864
Validation loss: 3.0858066674927267

Epoch: 5| Step: 10
Training loss: 3.3401649722170874
Validation loss: 3.091396184219047

Epoch: 34| Step: 0
Training loss: 3.081900358140231
Validation loss: 3.1015753117191838

Epoch: 5| Step: 1
Training loss: 3.4160092039140624
Validation loss: 3.117600147124774

Epoch: 5| Step: 2
Training loss: 3.087626243821166
Validation loss: 3.0997528312397598

Epoch: 5| Step: 3
Training loss: 3.755972239146966
Validation loss: 3.09171458492078

Epoch: 5| Step: 4
Training loss: 3.1243892835857925
Validation loss: 3.0793227031081782

Epoch: 5| Step: 5
Training loss: 3.5048878463237045
Validation loss: 3.072006897373066

Epoch: 5| Step: 6
Training loss: 3.8063127935331793
Validation loss: 3.071058115825463

Epoch: 5| Step: 7
Training loss: 3.4687840915413672
Validation loss: 3.0670640432057477

Epoch: 5| Step: 8
Training loss: 2.421457759232759
Validation loss: 3.0692875773981645

Epoch: 5| Step: 9
Training loss: 3.9103000244780586
Validation loss: 3.0698317184454105

Epoch: 5| Step: 10
Training loss: 3.0986498938329223
Validation loss: 3.073185720426488

Epoch: 35| Step: 0
Training loss: 3.4481192507202385
Validation loss: 3.0786821581430424

Epoch: 5| Step: 1
Training loss: 3.2840241830100347
Validation loss: 3.075272389267937

Epoch: 5| Step: 2
Training loss: 3.1279612434503314
Validation loss: 3.0578615740838453

Epoch: 5| Step: 3
Training loss: 3.079703453947768
Validation loss: 3.0545679753062887

Epoch: 5| Step: 4
Training loss: 3.1639506755895352
Validation loss: 3.0566087034612752

Epoch: 5| Step: 5
Training loss: 3.1117789785354106
Validation loss: 3.051587013869625

Epoch: 5| Step: 6
Training loss: 3.0467258514676807
Validation loss: 3.0607175262664685

Epoch: 5| Step: 7
Training loss: 3.61128217503893
Validation loss: 3.0921005702990496

Epoch: 5| Step: 8
Training loss: 3.7566124155707508
Validation loss: 3.048951142162748

Epoch: 5| Step: 9
Training loss: 3.7974634538691325
Validation loss: 3.0463052112210507

Epoch: 5| Step: 10
Training loss: 3.2302458569757175
Validation loss: 3.0422743711242073

Epoch: 36| Step: 0
Training loss: 3.0574913327959035
Validation loss: 3.0491717352527634

Epoch: 5| Step: 1
Training loss: 2.867738759112332
Validation loss: 3.059380232030453

Epoch: 5| Step: 2
Training loss: 3.592825331109666
Validation loss: 3.0777321974991643

Epoch: 5| Step: 3
Training loss: 3.1024877287616626
Validation loss: 3.0601022880128625

Epoch: 5| Step: 4
Training loss: 3.5984842712304537
Validation loss: 3.0489695957384653

Epoch: 5| Step: 5
Training loss: 3.202639808193833
Validation loss: 3.0380042211905387

Epoch: 5| Step: 6
Training loss: 3.7134872511006303
Validation loss: 3.035425194486845

Epoch: 5| Step: 7
Training loss: 3.2766968153390876
Validation loss: 3.0363061817853567

Epoch: 5| Step: 8
Training loss: 3.369651512442736
Validation loss: 3.0370300871382727

Epoch: 5| Step: 9
Training loss: 3.204478057162422
Validation loss: 3.0341384872065844

Epoch: 5| Step: 10
Training loss: 3.568511575460668
Validation loss: 3.036642515872762

Epoch: 37| Step: 0
Training loss: 3.410416321161183
Validation loss: 3.034591363141871

Epoch: 5| Step: 1
Training loss: 2.765881025457325
Validation loss: 3.0393393785016247

Epoch: 5| Step: 2
Training loss: 3.181028491029621
Validation loss: 3.0308027801258914

Epoch: 5| Step: 3
Training loss: 3.431943807306406
Validation loss: 3.024021767280263

Epoch: 5| Step: 4
Training loss: 3.2847339844084233
Validation loss: 3.023678391964594

Epoch: 5| Step: 5
Training loss: 2.866092815922049
Validation loss: 3.025907867683354

Epoch: 5| Step: 6
Training loss: 3.1414432503533196
Validation loss: 3.03324718287644

Epoch: 5| Step: 7
Training loss: 3.51254829563592
Validation loss: 3.0410265387328463

Epoch: 5| Step: 8
Training loss: 3.201096352878588
Validation loss: 3.042305782418304

Epoch: 5| Step: 9
Training loss: 3.6820931315913117
Validation loss: 3.0452097727761727

Epoch: 5| Step: 10
Training loss: 3.9188925052509926
Validation loss: 3.0356399468088524

Epoch: 38| Step: 0
Training loss: 2.60816863721208
Validation loss: 3.024827783398266

Epoch: 5| Step: 1
Training loss: 3.0191571200040244
Validation loss: 3.01464074822257

Epoch: 5| Step: 2
Training loss: 3.746033414448286
Validation loss: 3.011907524648245

Epoch: 5| Step: 3
Training loss: 3.3112717276609507
Validation loss: 3.0111306890027714

Epoch: 5| Step: 4
Training loss: 3.145641666325
Validation loss: 3.0079163593994447

Epoch: 5| Step: 5
Training loss: 3.3345229569189843
Validation loss: 3.0095427466274605

Epoch: 5| Step: 6
Training loss: 3.1420210586997963
Validation loss: 3.004996809346283

Epoch: 5| Step: 7
Training loss: 3.244883985517475
Validation loss: 3.006114828472421

Epoch: 5| Step: 8
Training loss: 3.560609951914881
Validation loss: 3.003920377740266

Epoch: 5| Step: 9
Training loss: 3.0834191971928946
Validation loss: 3.002837700204002

Epoch: 5| Step: 10
Training loss: 3.9599963392375632
Validation loss: 3.0019774995091657

Epoch: 39| Step: 0
Training loss: 3.2044838604888914
Validation loss: 3.0071172939192627

Epoch: 5| Step: 1
Training loss: 3.516396942160254
Validation loss: 3.0236996900054605

Epoch: 5| Step: 2
Training loss: 3.0933103923385397
Validation loss: 3.023363935894093

Epoch: 5| Step: 3
Training loss: 2.993232564468982
Validation loss: 3.0008760783048167

Epoch: 5| Step: 4
Training loss: 3.2789253356101824
Validation loss: 2.99954613291121

Epoch: 5| Step: 5
Training loss: 2.9569412681363842
Validation loss: 3.0015997910930476

Epoch: 5| Step: 6
Training loss: 2.8303161900064446
Validation loss: 3.0003363444695275

Epoch: 5| Step: 7
Training loss: 3.3785329623554317
Validation loss: 3.002980397634381

Epoch: 5| Step: 8
Training loss: 3.4995152273968215
Validation loss: 3.006347534734181

Epoch: 5| Step: 9
Training loss: 3.4578227543323297
Validation loss: 3.0043015319645705

Epoch: 5| Step: 10
Training loss: 3.956789994110771
Validation loss: 3.0018102164700453

Epoch: 40| Step: 0
Training loss: 3.3253233673488842
Validation loss: 2.996809573816661

Epoch: 5| Step: 1
Training loss: 3.308907774307787
Validation loss: 2.9945150296641234

Epoch: 5| Step: 2
Training loss: 3.680713291906779
Validation loss: 2.9945158686538913

Epoch: 5| Step: 3
Training loss: 3.3960443598857073
Validation loss: 2.9936181401545294

Epoch: 5| Step: 4
Training loss: 3.343619085583395
Validation loss: 2.996665304426087

Epoch: 5| Step: 5
Training loss: 2.8148775012395943
Validation loss: 3.001715128799165

Epoch: 5| Step: 6
Training loss: 3.074836174547382
Validation loss: 3.0076825598999783

Epoch: 5| Step: 7
Training loss: 3.1943741518846855
Validation loss: 2.996584350995904

Epoch: 5| Step: 8
Training loss: 3.289240961375397
Validation loss: 2.9876581932140533

Epoch: 5| Step: 9
Training loss: 3.9190324307380093
Validation loss: 2.986614153317204

Epoch: 5| Step: 10
Training loss: 2.3578786589161282
Validation loss: 2.984704235977723

Epoch: 41| Step: 0
Training loss: 3.541725487314091
Validation loss: 2.9851535940515546

Epoch: 5| Step: 1
Training loss: 3.6542261505215126
Validation loss: 2.9852817031881256

Epoch: 5| Step: 2
Training loss: 3.9950240895257583
Validation loss: 2.9838157851025704

Epoch: 5| Step: 3
Training loss: 2.8169894520674164
Validation loss: 2.9827988249610526

Epoch: 5| Step: 4
Training loss: 3.074658295789023
Validation loss: 2.9791893184072356

Epoch: 5| Step: 5
Training loss: 3.549393083513223
Validation loss: 2.977296390311176

Epoch: 5| Step: 6
Training loss: 2.8445282594266414
Validation loss: 2.9799552738268615

Epoch: 5| Step: 7
Training loss: 2.621037899053336
Validation loss: 2.977183504495464

Epoch: 5| Step: 8
Training loss: 3.315727964307171
Validation loss: 2.976103323731279

Epoch: 5| Step: 9
Training loss: 3.136456052200128
Validation loss: 2.981742614076637

Epoch: 5| Step: 10
Training loss: 3.0958801026403324
Validation loss: 2.9873378215878676

Epoch: 42| Step: 0
Training loss: 3.713507282513429
Validation loss: 3.002254280884972

Epoch: 5| Step: 1
Training loss: 2.9136543704017352
Validation loss: 3.0019367180820926

Epoch: 5| Step: 2
Training loss: 3.301058894110751
Validation loss: 2.994062980325426

Epoch: 5| Step: 3
Training loss: 3.351271681183654
Validation loss: 2.9865800618251774

Epoch: 5| Step: 4
Training loss: 3.7317347430524697
Validation loss: 2.9824486560633017

Epoch: 5| Step: 5
Training loss: 2.9190010175242516
Validation loss: 2.9739445540427876

Epoch: 5| Step: 6
Training loss: 3.360294943534562
Validation loss: 2.967723187437088

Epoch: 5| Step: 7
Training loss: 3.1365883159952768
Validation loss: 2.9694353712524806

Epoch: 5| Step: 8
Training loss: 3.3208462633928617
Validation loss: 2.9695899781088455

Epoch: 5| Step: 9
Training loss: 3.097313880039344
Validation loss: 2.969577489615926

Epoch: 5| Step: 10
Training loss: 2.799684700924564
Validation loss: 2.971105956557487

Epoch: 43| Step: 0
Training loss: 3.5715790553405595
Validation loss: 2.9736974995571197

Epoch: 5| Step: 1
Training loss: 2.897062813638495
Validation loss: 2.972008575332237

Epoch: 5| Step: 2
Training loss: 3.2508059749382667
Validation loss: 2.9681078489965005

Epoch: 5| Step: 3
Training loss: 3.6352717125676226
Validation loss: 2.963905953236567

Epoch: 5| Step: 4
Training loss: 3.55511632994559
Validation loss: 2.96660437947729

Epoch: 5| Step: 5
Training loss: 2.9705384338594465
Validation loss: 2.965143759704563

Epoch: 5| Step: 6
Training loss: 3.2900461642380314
Validation loss: 2.9634493887289652

Epoch: 5| Step: 7
Training loss: 3.5156180826754864
Validation loss: 2.9662231555083878

Epoch: 5| Step: 8
Training loss: 3.0797065505895427
Validation loss: 2.9646050628144094

Epoch: 5| Step: 9
Training loss: 3.2300412542111983
Validation loss: 2.966864243754132

Epoch: 5| Step: 10
Training loss: 2.4711700360139752
Validation loss: 2.96392747838959

Epoch: 44| Step: 0
Training loss: 3.590761351756214
Validation loss: 2.9664074915790697

Epoch: 5| Step: 1
Training loss: 3.0958334332787425
Validation loss: 2.9675047736441336

Epoch: 5| Step: 2
Training loss: 3.4124836009543293
Validation loss: 2.9734526110246122

Epoch: 5| Step: 3
Training loss: 2.771409789809688
Validation loss: 2.967023373938057

Epoch: 5| Step: 4
Training loss: 2.7888691298184636
Validation loss: 2.9644665042290326

Epoch: 5| Step: 5
Training loss: 3.417218946775315
Validation loss: 2.9660049285879255

Epoch: 5| Step: 6
Training loss: 3.078274486029524
Validation loss: 2.9675838233057785

Epoch: 5| Step: 7
Training loss: 2.5735445890860644
Validation loss: 2.9655146077287355

Epoch: 5| Step: 8
Training loss: 3.493908895247003
Validation loss: 2.966811305611968

Epoch: 5| Step: 9
Training loss: 3.884558547970395
Validation loss: 2.965790933724999

Epoch: 5| Step: 10
Training loss: 3.295845919720472
Validation loss: 2.9563136927302294

Epoch: 45| Step: 0
Training loss: 2.7036664122889142
Validation loss: 2.9549654271470875

Epoch: 5| Step: 1
Training loss: 3.496424347148388
Validation loss: 2.9520516824513083

Epoch: 5| Step: 2
Training loss: 3.0633605993452835
Validation loss: 2.950120579859011

Epoch: 5| Step: 3
Training loss: 3.056685708782935
Validation loss: 2.95131609414118

Epoch: 5| Step: 4
Training loss: 2.6829399634037663
Validation loss: 2.9488545245645197

Epoch: 5| Step: 5
Training loss: 2.974145583867832
Validation loss: 2.9510322157107876

Epoch: 5| Step: 6
Training loss: 3.3114933427654187
Validation loss: 2.9492160231271995

Epoch: 5| Step: 7
Training loss: 2.9188165824533057
Validation loss: 2.948923031729271

Epoch: 5| Step: 8
Training loss: 3.8003191613131966
Validation loss: 2.9499903667439358

Epoch: 5| Step: 9
Training loss: 3.723295623214945
Validation loss: 2.948268828617629

Epoch: 5| Step: 10
Training loss: 3.6932958539950085
Validation loss: 2.9465249379342997

Epoch: 46| Step: 0
Training loss: 3.26774754515398
Validation loss: 2.9478466971080746

Epoch: 5| Step: 1
Training loss: 3.158445444524505
Validation loss: 2.9494121855068824

Epoch: 5| Step: 2
Training loss: 3.2905732443308646
Validation loss: 2.945280325848687

Epoch: 5| Step: 3
Training loss: 3.5847880197843707
Validation loss: 2.944467687076516

Epoch: 5| Step: 4
Training loss: 2.8446633685158216
Validation loss: 2.9452136994136335

Epoch: 5| Step: 5
Training loss: 2.6497769639786264
Validation loss: 2.942303519682506

Epoch: 5| Step: 6
Training loss: 3.176504880848862
Validation loss: 2.944241793900158

Epoch: 5| Step: 7
Training loss: 3.464064449160057
Validation loss: 2.9431834939402712

Epoch: 5| Step: 8
Training loss: 3.4541990241056353
Validation loss: 2.9440993450669177

Epoch: 5| Step: 9
Training loss: 2.987909431014323
Validation loss: 2.9420217160390987

Epoch: 5| Step: 10
Training loss: 3.504482804475958
Validation loss: 2.951032136656652

Epoch: 47| Step: 0
Training loss: 3.2476437169930468
Validation loss: 2.949926815373092

Epoch: 5| Step: 1
Training loss: 3.1919094328687834
Validation loss: 2.963570929186965

Epoch: 5| Step: 2
Training loss: 3.2992686761777104
Validation loss: 2.964181967784618

Epoch: 5| Step: 3
Training loss: 3.608549742049391
Validation loss: 2.9921716349983924

Epoch: 5| Step: 4
Training loss: 3.122361098926946
Validation loss: 2.9374828106847004

Epoch: 5| Step: 5
Training loss: 2.5275539210573807
Validation loss: 2.9356868011545503

Epoch: 5| Step: 6
Training loss: 3.52717787647261
Validation loss: 2.9390592728279734

Epoch: 5| Step: 7
Training loss: 3.605515567562366
Validation loss: 2.9500956109141456

Epoch: 5| Step: 8
Training loss: 2.583419911154091
Validation loss: 2.94005643397001

Epoch: 5| Step: 9
Training loss: 3.0844079971480904
Validation loss: 2.938635622089004

Epoch: 5| Step: 10
Training loss: 3.613951188949009
Validation loss: 2.9354084225049926

Epoch: 48| Step: 0
Training loss: 2.594542324889087
Validation loss: 2.934079566850105

Epoch: 5| Step: 1
Training loss: 3.3379276244566536
Validation loss: 2.9329270860654897

Epoch: 5| Step: 2
Training loss: 3.361736088875806
Validation loss: 2.932400843996215

Epoch: 5| Step: 3
Training loss: 3.198561380779836
Validation loss: 2.9304006520986268

Epoch: 5| Step: 4
Training loss: 3.0853093147705724
Validation loss: 2.927076958418842

Epoch: 5| Step: 5
Training loss: 2.8959876552234376
Validation loss: 2.9298968417940596

Epoch: 5| Step: 6
Training loss: 2.9954885893687004
Validation loss: 2.926798839112445

Epoch: 5| Step: 7
Training loss: 3.1488442737963585
Validation loss: 2.9268636652083444

Epoch: 5| Step: 8
Training loss: 3.4194472248786747
Validation loss: 2.925804522424921

Epoch: 5| Step: 9
Training loss: 3.2630076163293937
Validation loss: 2.927096755758571

Epoch: 5| Step: 10
Training loss: 4.088219320949712
Validation loss: 2.9319510123870804

Epoch: 49| Step: 0
Training loss: 3.536775435256125
Validation loss: 2.932524701101606

Epoch: 5| Step: 1
Training loss: 3.693023811641627
Validation loss: 2.9439805301208146

Epoch: 5| Step: 2
Training loss: 2.7271601068478852
Validation loss: 2.929299529607617

Epoch: 5| Step: 3
Training loss: 3.445775284253213
Validation loss: 2.926675874051968

Epoch: 5| Step: 4
Training loss: 3.2703127274602015
Validation loss: 2.922918519743737

Epoch: 5| Step: 5
Training loss: 2.403849605851262
Validation loss: 2.930930459894961

Epoch: 5| Step: 6
Training loss: 3.4365790780786196
Validation loss: 2.939553245981807

Epoch: 5| Step: 7
Training loss: 3.3507531529336103
Validation loss: 2.9244081103598507

Epoch: 5| Step: 8
Training loss: 3.1462344657020376
Validation loss: 2.9169283847610803

Epoch: 5| Step: 9
Training loss: 2.927260550748808
Validation loss: 2.914310233542478

Epoch: 5| Step: 10
Training loss: 3.1149453725663094
Validation loss: 2.915244059366947

Epoch: 50| Step: 0
Training loss: 3.1689680336723973
Validation loss: 2.914283283749436

Epoch: 5| Step: 1
Training loss: 2.6844896711696804
Validation loss: 2.9169654189247916

Epoch: 5| Step: 2
Training loss: 3.7517682039362312
Validation loss: 2.928433918841154

Epoch: 5| Step: 3
Training loss: 3.5276045085043775
Validation loss: 2.9216936270228935

Epoch: 5| Step: 4
Training loss: 3.2852420319414914
Validation loss: 2.9138678826881854

Epoch: 5| Step: 5
Training loss: 2.7935286807610145
Validation loss: 2.911379839927821

Epoch: 5| Step: 6
Training loss: 3.278386346892286
Validation loss: 2.912639494482159

Epoch: 5| Step: 7
Training loss: 2.8186786177365892
Validation loss: 2.910660018422928

Epoch: 5| Step: 8
Training loss: 3.3620547939376246
Validation loss: 2.908018282791589

Epoch: 5| Step: 9
Training loss: 3.0928815142842714
Validation loss: 2.910647052484751

Epoch: 5| Step: 10
Training loss: 3.4509987477355826
Validation loss: 2.9117386921222836

Epoch: 51| Step: 0
Training loss: 3.4437462669947725
Validation loss: 2.915732230232656

Epoch: 5| Step: 1
Training loss: 2.4166252088827345
Validation loss: 2.912003044070596

Epoch: 5| Step: 2
Training loss: 3.368381226690036
Validation loss: 2.910085539623927

Epoch: 5| Step: 3
Training loss: 3.7087942258475564
Validation loss: 2.9102557914972222

Epoch: 5| Step: 4
Training loss: 3.439157537163671
Validation loss: 2.9082400393176404

Epoch: 5| Step: 5
Training loss: 3.6418955145422243
Validation loss: 2.9057503344711284

Epoch: 5| Step: 6
Training loss: 3.215795549887579
Validation loss: 2.9076932881973527

Epoch: 5| Step: 7
Training loss: 3.3415985316102774
Validation loss: 2.904726706951489

Epoch: 5| Step: 8
Training loss: 2.4079288719419316
Validation loss: 2.89959967335586

Epoch: 5| Step: 9
Training loss: 3.128477221922573
Validation loss: 2.9159731929736386

Epoch: 5| Step: 10
Training loss: 2.666406757881123
Validation loss: 2.977426567319321

Epoch: 52| Step: 0
Training loss: 3.176946935175099
Validation loss: 2.917611929369249

Epoch: 5| Step: 1
Training loss: 3.244374027388002
Validation loss: 2.898800542952614

Epoch: 5| Step: 2
Training loss: 3.1654396356838337
Validation loss: 2.896755315778189

Epoch: 5| Step: 3
Training loss: 2.380436647735162
Validation loss: 2.8977217136888562

Epoch: 5| Step: 4
Training loss: 3.1808511540192947
Validation loss: 2.8969915938572175

Epoch: 5| Step: 5
Training loss: 2.3336531783187593
Validation loss: 2.89386778940164

Epoch: 5| Step: 6
Training loss: 4.048079028025351
Validation loss: 2.8961612860679438

Epoch: 5| Step: 7
Training loss: 2.9287408952494154
Validation loss: 2.894336697609955

Epoch: 5| Step: 8
Training loss: 3.8262375518785765
Validation loss: 2.892822847309355

Epoch: 5| Step: 9
Training loss: 3.2948554483986525
Validation loss: 2.8954887837322834

Epoch: 5| Step: 10
Training loss: 3.1314050266774935
Validation loss: 2.893108034247632

Epoch: 53| Step: 0
Training loss: 3.360788447197533
Validation loss: 2.8908427459377495

Epoch: 5| Step: 1
Training loss: 2.950136963849094
Validation loss: 2.8892142061657915

Epoch: 5| Step: 2
Training loss: 3.3722552688741856
Validation loss: 2.8883849293520916

Epoch: 5| Step: 3
Training loss: 2.837002977038204
Validation loss: 2.8887992434269347

Epoch: 5| Step: 4
Training loss: 3.383512288013331
Validation loss: 2.8868324931985145

Epoch: 5| Step: 5
Training loss: 3.1414991082823605
Validation loss: 2.885302453901256

Epoch: 5| Step: 6
Training loss: 2.8439173387192134
Validation loss: 2.8875001912054126

Epoch: 5| Step: 7
Training loss: 3.2185224434125046
Validation loss: 2.8831350912664595

Epoch: 5| Step: 8
Training loss: 4.071948054164069
Validation loss: 2.883178372913338

Epoch: 5| Step: 9
Training loss: 2.8516027996403186
Validation loss: 2.8823908664724707

Epoch: 5| Step: 10
Training loss: 2.6872256826524334
Validation loss: 2.8864208491060266

Epoch: 54| Step: 0
Training loss: 2.999321383970591
Validation loss: 2.8830896250977194

Epoch: 5| Step: 1
Training loss: 3.0002306213744814
Validation loss: 2.8866869476372474

Epoch: 5| Step: 2
Training loss: 2.824006934025062
Validation loss: 2.8868691000070137

Epoch: 5| Step: 3
Training loss: 3.122763634601622
Validation loss: 2.8851559710270145

Epoch: 5| Step: 4
Training loss: 3.030416000312289
Validation loss: 2.882030510946439

Epoch: 5| Step: 5
Training loss: 2.9062165289151207
Validation loss: 2.877071872639139

Epoch: 5| Step: 6
Training loss: 3.504036074883778
Validation loss: 2.8799603042094373

Epoch: 5| Step: 7
Training loss: 3.012300863055181
Validation loss: 2.8801910614087407

Epoch: 5| Step: 8
Training loss: 3.4785174070479012
Validation loss: 2.88097416819543

Epoch: 5| Step: 9
Training loss: 3.7532865745202075
Validation loss: 2.891147441928112

Epoch: 5| Step: 10
Training loss: 3.1758693856447078
Validation loss: 2.88104655585665

Epoch: 55| Step: 0
Training loss: 3.038174614735635
Validation loss: 2.8853569399223367

Epoch: 5| Step: 1
Training loss: 3.4788048531322877
Validation loss: 2.8906371129964756

Epoch: 5| Step: 2
Training loss: 2.9392907386105143
Validation loss: 2.907235613451468

Epoch: 5| Step: 3
Training loss: 2.952238403928099
Validation loss: 2.8770969406913074

Epoch: 5| Step: 4
Training loss: 3.124243835516397
Validation loss: 2.873400272977887

Epoch: 5| Step: 5
Training loss: 3.2461035919958348
Validation loss: 2.87204394108899

Epoch: 5| Step: 6
Training loss: 3.61935050343448
Validation loss: 2.8708092489470136

Epoch: 5| Step: 7
Training loss: 2.734711718944061
Validation loss: 2.8710696822873674

Epoch: 5| Step: 8
Training loss: 3.1683305752451405
Validation loss: 2.870999788877644

Epoch: 5| Step: 9
Training loss: 3.677490744925963
Validation loss: 2.8731076922357324

Epoch: 5| Step: 10
Training loss: 2.6918682703944206
Validation loss: 2.87164545373385

Epoch: 56| Step: 0
Training loss: 2.746877110885139
Validation loss: 2.873587150165024

Epoch: 5| Step: 1
Training loss: 3.7843005273044885
Validation loss: 2.870427451476024

Epoch: 5| Step: 2
Training loss: 3.6127438367237104
Validation loss: 2.8695161638566624

Epoch: 5| Step: 3
Training loss: 3.0900434388499285
Validation loss: 2.869724039207338

Epoch: 5| Step: 4
Training loss: 3.1952923538580214
Validation loss: 2.8672956234099387

Epoch: 5| Step: 5
Training loss: 3.414568481661276
Validation loss: 2.8652018778483788

Epoch: 5| Step: 6
Training loss: 2.89659895255511
Validation loss: 2.8678381280760354

Epoch: 5| Step: 7
Training loss: 2.7110472555231655
Validation loss: 2.8677979010365187

Epoch: 5| Step: 8
Training loss: 3.15146977482542
Validation loss: 2.8678128226522106

Epoch: 5| Step: 9
Training loss: 3.1043737628305306
Validation loss: 2.867165962096543

Epoch: 5| Step: 10
Training loss: 2.939733265045776
Validation loss: 2.8686541806967636

Epoch: 57| Step: 0
Training loss: 2.897444480383833
Validation loss: 2.8645040118887235

Epoch: 5| Step: 1
Training loss: 3.3426005446634037
Validation loss: 2.8612264136111514

Epoch: 5| Step: 2
Training loss: 3.461800151290595
Validation loss: 2.862166500550836

Epoch: 5| Step: 3
Training loss: 2.7099539871814025
Validation loss: 2.8595267204648827

Epoch: 5| Step: 4
Training loss: 3.3282737161425637
Validation loss: 2.860442910435007

Epoch: 5| Step: 5
Training loss: 1.9810001179609884
Validation loss: 2.8575897982773126

Epoch: 5| Step: 6
Training loss: 3.653946631899477
Validation loss: 2.856202860540358

Epoch: 5| Step: 7
Training loss: 3.283525531649204
Validation loss: 2.858880493216692

Epoch: 5| Step: 8
Training loss: 3.0000333784153876
Validation loss: 2.856339138859989

Epoch: 5| Step: 9
Training loss: 3.459641052325732
Validation loss: 2.8558969075822227

Epoch: 5| Step: 10
Training loss: 3.262562314896306
Validation loss: 2.855410288238683

Epoch: 58| Step: 0
Training loss: 2.712924372090317
Validation loss: 2.8688558650243325

Epoch: 5| Step: 1
Training loss: 3.134702041313876
Validation loss: 2.8648935946844767

Epoch: 5| Step: 2
Training loss: 3.374014533951711
Validation loss: 2.854930884656073

Epoch: 5| Step: 3
Training loss: 3.3191004796140797
Validation loss: 2.8580117116244215

Epoch: 5| Step: 4
Training loss: 3.2971847894849238
Validation loss: 2.8527175036355112

Epoch: 5| Step: 5
Training loss: 3.1493855982240837
Validation loss: 2.855498869244854

Epoch: 5| Step: 6
Training loss: 3.5585365332684105
Validation loss: 2.855954131400602

Epoch: 5| Step: 7
Training loss: 3.440667929455159
Validation loss: 2.8591761482641944

Epoch: 5| Step: 8
Training loss: 2.4746605341680494
Validation loss: 2.860762792530279

Epoch: 5| Step: 9
Training loss: 3.0277157659528435
Validation loss: 2.8598048568825147

Epoch: 5| Step: 10
Training loss: 2.9750343064325633
Validation loss: 2.8672006490573034

Epoch: 59| Step: 0
Training loss: 3.1266801513619678
Validation loss: 2.862579312936102

Epoch: 5| Step: 1
Training loss: 2.8881487163072688
Validation loss: 2.8670876989603764

Epoch: 5| Step: 2
Training loss: 3.381296289377436
Validation loss: 2.873638558352373

Epoch: 5| Step: 3
Training loss: 3.1155487571578044
Validation loss: 2.865248001862212

Epoch: 5| Step: 4
Training loss: 3.3275978494726406
Validation loss: 2.8511514967323004

Epoch: 5| Step: 5
Training loss: 2.625723421231232
Validation loss: 2.845942099847264

Epoch: 5| Step: 6
Training loss: 2.698047345112933
Validation loss: 2.8428821630080425

Epoch: 5| Step: 7
Training loss: 3.6983146489138274
Validation loss: 2.842971079357729

Epoch: 5| Step: 8
Training loss: 3.0427672254554183
Validation loss: 2.8410492063780857

Epoch: 5| Step: 9
Training loss: 3.381163726100852
Validation loss: 2.8429411799752993

Epoch: 5| Step: 10
Training loss: 3.3048867600701852
Validation loss: 2.841291886732855

Epoch: 60| Step: 0
Training loss: 3.184085587966212
Validation loss: 2.8429803754523304

Epoch: 5| Step: 1
Training loss: 3.3432511287280247
Validation loss: 2.841994178845565

Epoch: 5| Step: 2
Training loss: 3.2674037341856623
Validation loss: 2.842019894569099

Epoch: 5| Step: 3
Training loss: 3.4256151913768846
Validation loss: 2.838110776456058

Epoch: 5| Step: 4
Training loss: 2.5155926814876155
Validation loss: 2.838761473528781

Epoch: 5| Step: 5
Training loss: 3.299140621762444
Validation loss: 2.838104798468259

Epoch: 5| Step: 6
Training loss: 3.5021391189976274
Validation loss: 2.836472699921748

Epoch: 5| Step: 7
Training loss: 2.6542765747821027
Validation loss: 2.8359334944463948

Epoch: 5| Step: 8
Training loss: 2.7089338566058294
Validation loss: 2.8337934251354207

Epoch: 5| Step: 9
Training loss: 3.034444011056687
Validation loss: 2.837183086540918

Epoch: 5| Step: 10
Training loss: 3.488716329031451
Validation loss: 2.838143260430149

Epoch: 61| Step: 0
Training loss: 2.5013884503481085
Validation loss: 2.8393949787208737

Epoch: 5| Step: 1
Training loss: 2.712762224030104
Validation loss: 2.855099360299795

Epoch: 5| Step: 2
Training loss: 3.5183477412340967
Validation loss: 2.8762647282215554

Epoch: 5| Step: 3
Training loss: 2.91664332425904
Validation loss: 2.860837794783007

Epoch: 5| Step: 4
Training loss: 3.3123170334289935
Validation loss: 2.8367351044386786

Epoch: 5| Step: 5
Training loss: 3.8308895171745494
Validation loss: 2.8333011736362685

Epoch: 5| Step: 6
Training loss: 3.362820441991104
Validation loss: 2.8306502704535106

Epoch: 5| Step: 7
Training loss: 2.7775008402633428
Validation loss: 2.832057045326535

Epoch: 5| Step: 8
Training loss: 3.0270049268558306
Validation loss: 2.8264494951056927

Epoch: 5| Step: 9
Training loss: 3.187228471747158
Validation loss: 2.827103061174794

Epoch: 5| Step: 10
Training loss: 3.1403516963638753
Validation loss: 2.828660161839622

Epoch: 62| Step: 0
Training loss: 3.233625684544985
Validation loss: 2.8276460947230526

Epoch: 5| Step: 1
Training loss: 2.76515780021045
Validation loss: 2.8268975872604485

Epoch: 5| Step: 2
Training loss: 2.8730126851509175
Validation loss: 2.825969409602103

Epoch: 5| Step: 3
Training loss: 3.5245622078953605
Validation loss: 2.823105828930663

Epoch: 5| Step: 4
Training loss: 3.059190479983596
Validation loss: 2.8249620921308307

Epoch: 5| Step: 5
Training loss: 3.4505489631321935
Validation loss: 2.8198716500230785

Epoch: 5| Step: 6
Training loss: 3.5236889396321764
Validation loss: 2.82288452088965

Epoch: 5| Step: 7
Training loss: 3.223626008210026
Validation loss: 2.824075589387946

Epoch: 5| Step: 8
Training loss: 2.86426563697576
Validation loss: 2.8228206099774575

Epoch: 5| Step: 9
Training loss: 2.96095489255281
Validation loss: 2.8231321889105763

Epoch: 5| Step: 10
Training loss: 2.7416442159025296
Validation loss: 2.822498273423972

Epoch: 63| Step: 0
Training loss: 3.303290177675102
Validation loss: 2.8238144551734545

Epoch: 5| Step: 1
Training loss: 2.471782029594226
Validation loss: 2.8315210017260557

Epoch: 5| Step: 2
Training loss: 3.5941509520725727
Validation loss: 2.863010823436072

Epoch: 5| Step: 3
Training loss: 2.767943191948668
Validation loss: 2.8283801573584655

Epoch: 5| Step: 4
Training loss: 2.995314276609655
Validation loss: 2.8218760413455235

Epoch: 5| Step: 5
Training loss: 3.0364709311867917
Validation loss: 2.820176067954774

Epoch: 5| Step: 6
Training loss: 2.612078425510859
Validation loss: 2.8189876443031743

Epoch: 5| Step: 7
Training loss: 3.1423933070847663
Validation loss: 2.822200308429019

Epoch: 5| Step: 8
Training loss: 3.8317034753262353
Validation loss: 2.820678601730645

Epoch: 5| Step: 9
Training loss: 3.0281231670551243
Validation loss: 2.823258728461743

Epoch: 5| Step: 10
Training loss: 3.3640368384885453
Validation loss: 2.8224482617485194

Epoch: 64| Step: 0
Training loss: 3.0025661937014134
Validation loss: 2.819511678246192

Epoch: 5| Step: 1
Training loss: 3.4706483062725497
Validation loss: 2.820505851358294

Epoch: 5| Step: 2
Training loss: 3.2344065494196474
Validation loss: 2.8176699430224215

Epoch: 5| Step: 3
Training loss: 3.135278506524829
Validation loss: 2.819990756763631

Epoch: 5| Step: 4
Training loss: 3.1031361006339404
Validation loss: 2.8174900301468924

Epoch: 5| Step: 5
Training loss: 2.5661223325639786
Validation loss: 2.817926691175839

Epoch: 5| Step: 6
Training loss: 2.874778075567686
Validation loss: 2.8155977642600445

Epoch: 5| Step: 7
Training loss: 3.5128112383567784
Validation loss: 2.814798953697924

Epoch: 5| Step: 8
Training loss: 2.7298475003529235
Validation loss: 2.8142149478749663

Epoch: 5| Step: 9
Training loss: 3.4640403598874534
Validation loss: 2.814092497449858

Epoch: 5| Step: 10
Training loss: 3.112967864265578
Validation loss: 2.8110799998905187

Epoch: 65| Step: 0
Training loss: 2.5485843468790157
Validation loss: 2.8098344356029217

Epoch: 5| Step: 1
Training loss: 2.9978154493842504
Validation loss: 2.8094909121359106

Epoch: 5| Step: 2
Training loss: 2.839086880366647
Validation loss: 2.8145290953531448

Epoch: 5| Step: 3
Training loss: 3.754158511701583
Validation loss: 2.811305200883125

Epoch: 5| Step: 4
Training loss: 3.433472510791493
Validation loss: 2.8163081394636333

Epoch: 5| Step: 5
Training loss: 3.1118157550039527
Validation loss: 2.8144437237493785

Epoch: 5| Step: 6
Training loss: 2.92549732903525
Validation loss: 2.824150216125708

Epoch: 5| Step: 7
Training loss: 3.255116030592401
Validation loss: 2.840429430669276

Epoch: 5| Step: 8
Training loss: 3.242562366553459
Validation loss: 2.812033720571267

Epoch: 5| Step: 9
Training loss: 3.1906520741478785
Validation loss: 2.8070207252338353

Epoch: 5| Step: 10
Training loss: 2.7851555651734783
Validation loss: 2.80380520971246

Epoch: 66| Step: 0
Training loss: 3.021197452743186
Validation loss: 2.803830022138037

Epoch: 5| Step: 1
Training loss: 2.1730637624613447
Validation loss: 2.801172877915771

Epoch: 5| Step: 2
Training loss: 3.5513319337571283
Validation loss: 2.802133287932288

Epoch: 5| Step: 3
Training loss: 2.8743432995001394
Validation loss: 2.7990912761044187

Epoch: 5| Step: 4
Training loss: 3.512050320223534
Validation loss: 2.7995831995314195

Epoch: 5| Step: 5
Training loss: 3.3111426973507556
Validation loss: 2.7996117918970453

Epoch: 5| Step: 6
Training loss: 3.44014665845473
Validation loss: 2.799741475817314

Epoch: 5| Step: 7
Training loss: 2.8077452416449717
Validation loss: 2.7983690557489056

Epoch: 5| Step: 8
Training loss: 2.9759926237917314
Validation loss: 2.797939233491368

Epoch: 5| Step: 9
Training loss: 3.2285512194139643
Validation loss: 2.7998013581953045

Epoch: 5| Step: 10
Training loss: 3.056571360037895
Validation loss: 2.796347289612799

Epoch: 67| Step: 0
Training loss: 2.8314393575978976
Validation loss: 2.8006733478412036

Epoch: 5| Step: 1
Training loss: 3.137637563174599
Validation loss: 2.8192144806265094

Epoch: 5| Step: 2
Training loss: 2.9315344113316795
Validation loss: 2.834284724620546

Epoch: 5| Step: 3
Training loss: 2.907394019939956
Validation loss: 2.8629499493139465

Epoch: 5| Step: 4
Training loss: 3.2218331690384296
Validation loss: 2.8319263934170995

Epoch: 5| Step: 5
Training loss: 2.9003529761340143
Validation loss: 2.796540731241238

Epoch: 5| Step: 6
Training loss: 3.138844151210891
Validation loss: 2.791303966165424

Epoch: 5| Step: 7
Training loss: 3.345410799081604
Validation loss: 2.788287861237641

Epoch: 5| Step: 8
Training loss: 3.5892526100437756
Validation loss: 2.79018652835772

Epoch: 5| Step: 9
Training loss: 3.297786930028115
Validation loss: 2.791250120360365

Epoch: 5| Step: 10
Training loss: 2.6701225199788112
Validation loss: 2.795116851590004

Epoch: 68| Step: 0
Training loss: 2.850861094708622
Validation loss: 2.79361355726805

Epoch: 5| Step: 1
Training loss: 3.346400841215513
Validation loss: 2.7932334186475187

Epoch: 5| Step: 2
Training loss: 3.327995333585769
Validation loss: 2.7924070140314585

Epoch: 5| Step: 3
Training loss: 3.192093027054754
Validation loss: 2.7898382873515675

Epoch: 5| Step: 4
Training loss: 3.0915514908250135
Validation loss: 2.7903706446106127

Epoch: 5| Step: 5
Training loss: 2.683778092939566
Validation loss: 2.789103057447869

Epoch: 5| Step: 6
Training loss: 3.6083356673752163
Validation loss: 2.789615544904813

Epoch: 5| Step: 7
Training loss: 2.623503485480833
Validation loss: 2.786892500457746

Epoch: 5| Step: 8
Training loss: 3.1761504424374496
Validation loss: 2.794716764986683

Epoch: 5| Step: 9
Training loss: 3.153820046680029
Validation loss: 2.795063459877981

Epoch: 5| Step: 10
Training loss: 2.977180957372577
Validation loss: 2.793707051598213

Epoch: 69| Step: 0
Training loss: 2.958929583857406
Validation loss: 2.7884013186570873

Epoch: 5| Step: 1
Training loss: 2.918983211635026
Validation loss: 2.7874085912988873

Epoch: 5| Step: 2
Training loss: 3.0986028045249623
Validation loss: 2.786176542873557

Epoch: 5| Step: 3
Training loss: 3.118320039455418
Validation loss: 2.7822358588411067

Epoch: 5| Step: 4
Training loss: 2.9348410076897657
Validation loss: 2.78028294691742

Epoch: 5| Step: 5
Training loss: 2.70472105678675
Validation loss: 2.774993226289635

Epoch: 5| Step: 6
Training loss: 3.286821848034629
Validation loss: 2.793335886824456

Epoch: 5| Step: 7
Training loss: 2.578494883504292
Validation loss: 2.815755366146897

Epoch: 5| Step: 8
Training loss: 3.7262765066898997
Validation loss: 2.801283229953605

Epoch: 5| Step: 9
Training loss: 3.4431087166814374
Validation loss: 2.769862479002153

Epoch: 5| Step: 10
Training loss: 3.017189845316848
Validation loss: 2.757820971359539

Epoch: 70| Step: 0
Training loss: 3.191272821520359
Validation loss: 2.756106933410713

Epoch: 5| Step: 1
Training loss: 3.151798848796726
Validation loss: 2.7571865690202926

Epoch: 5| Step: 2
Training loss: 2.9382120446329387
Validation loss: 2.757008098695631

Epoch: 5| Step: 3
Training loss: 3.016359546124935
Validation loss: 2.755799434562315

Epoch: 5| Step: 4
Training loss: 3.2555389155055563
Validation loss: 2.7539622874577883

Epoch: 5| Step: 5
Training loss: 2.9543228545730633
Validation loss: 2.757703190820346

Epoch: 5| Step: 6
Training loss: 2.6374538724942496
Validation loss: 2.756586554787777

Epoch: 5| Step: 7
Training loss: 2.946881511272466
Validation loss: 2.7559526431666903

Epoch: 5| Step: 8
Training loss: 2.508071173045877
Validation loss: 2.7513464020988936

Epoch: 5| Step: 9
Training loss: 3.4583751415498494
Validation loss: 2.7517014569498914

Epoch: 5| Step: 10
Training loss: 3.777158304611188
Validation loss: 2.750057925549267

Epoch: 71| Step: 0
Training loss: 2.9222036574643875
Validation loss: 2.749764302762887

Epoch: 5| Step: 1
Training loss: 3.011363442684318
Validation loss: 2.74670028727275

Epoch: 5| Step: 2
Training loss: 3.3039531207418875
Validation loss: 2.7487414585447834

Epoch: 5| Step: 3
Training loss: 2.824021708472567
Validation loss: 2.7446064808439616

Epoch: 5| Step: 4
Training loss: 2.998509990696486
Validation loss: 2.7456069006170085

Epoch: 5| Step: 5
Training loss: 3.3936099084985547
Validation loss: 2.7481970759374352

Epoch: 5| Step: 6
Training loss: 2.85866283448992
Validation loss: 2.7574613260951986

Epoch: 5| Step: 7
Training loss: 3.7193877370542863
Validation loss: 2.7725283847264484

Epoch: 5| Step: 8
Training loss: 2.7784356440253792
Validation loss: 2.7558576484538078

Epoch: 5| Step: 9
Training loss: 3.1145548399235343
Validation loss: 2.749942286716409

Epoch: 5| Step: 10
Training loss: 2.7019075507577597
Validation loss: 2.74037363073056

Epoch: 72| Step: 0
Training loss: 2.7677501552314014
Validation loss: 2.7412532148174065

Epoch: 5| Step: 1
Training loss: 2.6225496390329575
Validation loss: 2.7404153802502194

Epoch: 5| Step: 2
Training loss: 3.7562856764535204
Validation loss: 2.7429057586656356

Epoch: 5| Step: 3
Training loss: 3.1722252563117626
Validation loss: 2.738719306256687

Epoch: 5| Step: 4
Training loss: 3.6560079380341546
Validation loss: 2.742976411240444

Epoch: 5| Step: 5
Training loss: 3.16328748465442
Validation loss: 2.7414470100874238

Epoch: 5| Step: 6
Training loss: 2.7648778218597676
Validation loss: 2.738079185122865

Epoch: 5| Step: 7
Training loss: 2.8575043109050284
Validation loss: 2.735994825475144

Epoch: 5| Step: 8
Training loss: 2.318829303218195
Validation loss: 2.740678187049109

Epoch: 5| Step: 9
Training loss: 3.0507234184459415
Validation loss: 2.7336520578558847

Epoch: 5| Step: 10
Training loss: 3.309119028596941
Validation loss: 2.7386558650603634

Epoch: 73| Step: 0
Training loss: 2.99283427526593
Validation loss: 2.744067944252538

Epoch: 5| Step: 1
Training loss: 2.7759011944603236
Validation loss: 2.7410804251053165

Epoch: 5| Step: 2
Training loss: 2.869895550093213
Validation loss: 2.740703339940346

Epoch: 5| Step: 3
Training loss: 3.6209961714451735
Validation loss: 2.732009350966376

Epoch: 5| Step: 4
Training loss: 3.2300569024993644
Validation loss: 2.7321694174988584

Epoch: 5| Step: 5
Training loss: 3.4820131242779717
Validation loss: 2.7339542422635836

Epoch: 5| Step: 6
Training loss: 2.3429562050946875
Validation loss: 2.733057380730643

Epoch: 5| Step: 7
Training loss: 3.38742983699644
Validation loss: 2.736186584778305

Epoch: 5| Step: 8
Training loss: 3.326157825774058
Validation loss: 2.732052144140518

Epoch: 5| Step: 9
Training loss: 2.590819116183054
Validation loss: 2.7322630899420903

Epoch: 5| Step: 10
Training loss: 2.683433472401666
Validation loss: 2.7315570839916172

Epoch: 74| Step: 0
Training loss: 3.087376821431457
Validation loss: 2.7303298397760742

Epoch: 5| Step: 1
Training loss: 3.149103818294728
Validation loss: 2.735818093141575

Epoch: 5| Step: 2
Training loss: 2.79023713666215
Validation loss: 2.7323993996038847

Epoch: 5| Step: 3
Training loss: 3.2468136059240864
Validation loss: 2.735490588839504

Epoch: 5| Step: 4
Training loss: 3.016271017975977
Validation loss: 2.7383659056786422

Epoch: 5| Step: 5
Training loss: 3.175587403034135
Validation loss: 2.7687689382928133

Epoch: 5| Step: 6
Training loss: 2.9999132143819165
Validation loss: 2.8082645788205527

Epoch: 5| Step: 7
Training loss: 3.040954628432502
Validation loss: 2.7432411127625027

Epoch: 5| Step: 8
Training loss: 3.070115100057341
Validation loss: 2.7229689989608783

Epoch: 5| Step: 9
Training loss: 2.8565314490217832
Validation loss: 2.725091917187354

Epoch: 5| Step: 10
Training loss: 3.216757741109864
Validation loss: 2.729294856020747

Epoch: 75| Step: 0
Training loss: 2.813346226860018
Validation loss: 2.7280044097310223

Epoch: 5| Step: 1
Training loss: 2.5353493168792056
Validation loss: 2.7286050220630162

Epoch: 5| Step: 2
Training loss: 3.2068272478127744
Validation loss: 2.733012089383681

Epoch: 5| Step: 3
Training loss: 3.549702059640955
Validation loss: 2.757149626765605

Epoch: 5| Step: 4
Training loss: 3.374423790240001
Validation loss: 2.758221750431652

Epoch: 5| Step: 5
Training loss: 3.0838713477249415
Validation loss: 2.743704600400865

Epoch: 5| Step: 6
Training loss: 3.2423879538465954
Validation loss: 2.732422287821243

Epoch: 5| Step: 7
Training loss: 2.944066439262454
Validation loss: 2.7244139482264282

Epoch: 5| Step: 8
Training loss: 3.224793621231618
Validation loss: 2.72507243410606

Epoch: 5| Step: 9
Training loss: 3.0820895770878964
Validation loss: 2.723846036696236

Epoch: 5| Step: 10
Training loss: 2.3393178103542445
Validation loss: 2.720054801807178

Epoch: 76| Step: 0
Training loss: 2.9553443602185494
Validation loss: 2.7175090250355067

Epoch: 5| Step: 1
Training loss: 2.9273499789348594
Validation loss: 2.718670051897567

Epoch: 5| Step: 2
Training loss: 3.0875548940867468
Validation loss: 2.7198785502966656

Epoch: 5| Step: 3
Training loss: 3.116571427656373
Validation loss: 2.7400028471052056

Epoch: 5| Step: 4
Training loss: 3.196694968068125
Validation loss: 2.790968428525818

Epoch: 5| Step: 5
Training loss: 3.5606320486589875
Validation loss: 2.755803883115236

Epoch: 5| Step: 6
Training loss: 3.0491789103433593
Validation loss: 2.7171145998877235

Epoch: 5| Step: 7
Training loss: 2.544742744798977
Validation loss: 2.7152800490269273

Epoch: 5| Step: 8
Training loss: 2.8145034436103002
Validation loss: 2.7227136245703534

Epoch: 5| Step: 9
Training loss: 3.164052854923571
Validation loss: 2.720732813924045

Epoch: 5| Step: 10
Training loss: 3.0875201452424292
Validation loss: 2.7294503310119005

Epoch: 77| Step: 0
Training loss: 3.059806573526343
Validation loss: 2.7328349784152173

Epoch: 5| Step: 1
Training loss: 2.4564231520329027
Validation loss: 2.7296483518825325

Epoch: 5| Step: 2
Training loss: 3.1114079715998133
Validation loss: 2.723200699475324

Epoch: 5| Step: 3
Training loss: 2.776984125775362
Validation loss: 2.721144819364387

Epoch: 5| Step: 4
Training loss: 3.3146059071850895
Validation loss: 2.719438065270875

Epoch: 5| Step: 5
Training loss: 2.7625227948797497
Validation loss: 2.7187203705177003

Epoch: 5| Step: 6
Training loss: 3.34075165839462
Validation loss: 2.7137098636775545

Epoch: 5| Step: 7
Training loss: 3.276776561375327
Validation loss: 2.7128472517370223

Epoch: 5| Step: 8
Training loss: 2.700078051816443
Validation loss: 2.7130609040423996

Epoch: 5| Step: 9
Training loss: 3.1431737777435607
Validation loss: 2.7171427976554874

Epoch: 5| Step: 10
Training loss: 3.528179758219674
Validation loss: 2.7204682970736687

Epoch: 78| Step: 0
Training loss: 3.003324573883707
Validation loss: 2.7257094003715423

Epoch: 5| Step: 1
Training loss: 2.7387021077372244
Validation loss: 2.7165284510494923

Epoch: 5| Step: 2
Training loss: 2.9530121312446096
Validation loss: 2.710433341426317

Epoch: 5| Step: 3
Training loss: 2.9982262772056036
Validation loss: 2.7081544506231388

Epoch: 5| Step: 4
Training loss: 2.8200996297457106
Validation loss: 2.706780426873364

Epoch: 5| Step: 5
Training loss: 3.1709400922637414
Validation loss: 2.7109660617909768

Epoch: 5| Step: 6
Training loss: 3.316243341800866
Validation loss: 2.7103573003692576

Epoch: 5| Step: 7
Training loss: 2.9760664879539664
Validation loss: 2.7122039744536077

Epoch: 5| Step: 8
Training loss: 3.2127514098828285
Validation loss: 2.7142469893888235

Epoch: 5| Step: 9
Training loss: 3.11602639202062
Validation loss: 2.715866142581513

Epoch: 5| Step: 10
Training loss: 3.047359017294425
Validation loss: 2.715207709869455

Epoch: 79| Step: 0
Training loss: 3.1705423195659588
Validation loss: 2.716203951678641

Epoch: 5| Step: 1
Training loss: 2.3952035380225847
Validation loss: 2.7037480831351366

Epoch: 5| Step: 2
Training loss: 3.110635779793065
Validation loss: 2.704615155483506

Epoch: 5| Step: 3
Training loss: 3.105189127299074
Validation loss: 2.705945548036454

Epoch: 5| Step: 4
Training loss: 2.741103868394607
Validation loss: 2.7054553931455447

Epoch: 5| Step: 5
Training loss: 3.372236745413088
Validation loss: 2.7046995227423025

Epoch: 5| Step: 6
Training loss: 2.974934290312518
Validation loss: 2.7053498162451204

Epoch: 5| Step: 7
Training loss: 2.8418312726118398
Validation loss: 2.704135083668366

Epoch: 5| Step: 8
Training loss: 3.186196154038046
Validation loss: 2.7046997615996715

Epoch: 5| Step: 9
Training loss: 3.243849583385288
Validation loss: 2.7048502640877885

Epoch: 5| Step: 10
Training loss: 3.1453827457381878
Validation loss: 2.7136774432828585

Epoch: 80| Step: 0
Training loss: 2.717608508178311
Validation loss: 2.7283322554566953

Epoch: 5| Step: 1
Training loss: 3.0459305301992368
Validation loss: 2.7435569413647567

Epoch: 5| Step: 2
Training loss: 3.0444319883340794
Validation loss: 2.7526098612512233

Epoch: 5| Step: 3
Training loss: 2.5077589748291564
Validation loss: 2.7451191122489766

Epoch: 5| Step: 4
Training loss: 2.9945943131587676
Validation loss: 2.734023634313892

Epoch: 5| Step: 5
Training loss: 3.010905946527631
Validation loss: 2.720126021523784

Epoch: 5| Step: 6
Training loss: 3.328781421382722
Validation loss: 2.7124687585061262

Epoch: 5| Step: 7
Training loss: 3.2055382546483764
Validation loss: 2.6979204251393885

Epoch: 5| Step: 8
Training loss: 3.3124640120944555
Validation loss: 2.695191440892421

Epoch: 5| Step: 9
Training loss: 3.4004834560669974
Validation loss: 2.696179151197362

Epoch: 5| Step: 10
Training loss: 2.563164880605553
Validation loss: 2.6965650133424095

Epoch: 81| Step: 0
Training loss: 2.331066449586737
Validation loss: 2.694346675072298

Epoch: 5| Step: 1
Training loss: 2.727628220884354
Validation loss: 2.693821776070773

Epoch: 5| Step: 2
Training loss: 2.6905658002093813
Validation loss: 2.693252548151277

Epoch: 5| Step: 3
Training loss: 3.7710011200783056
Validation loss: 2.6997273787181038

Epoch: 5| Step: 4
Training loss: 2.2079430241213456
Validation loss: 2.695863040424955

Epoch: 5| Step: 5
Training loss: 3.1916100426440948
Validation loss: 2.6951983712578755

Epoch: 5| Step: 6
Training loss: 3.1205574501102324
Validation loss: 2.696763786289311

Epoch: 5| Step: 7
Training loss: 2.6567834655026665
Validation loss: 2.6932615350291633

Epoch: 5| Step: 8
Training loss: 3.7677237965536565
Validation loss: 2.6913509399230677

Epoch: 5| Step: 9
Training loss: 3.1013815416255768
Validation loss: 2.6870018243814813

Epoch: 5| Step: 10
Training loss: 3.250738060115862
Validation loss: 2.6870518248926607

Epoch: 82| Step: 0
Training loss: 3.0425771282516183
Validation loss: 2.6878605996782383

Epoch: 5| Step: 1
Training loss: 3.003580817364572
Validation loss: 2.6925819322716573

Epoch: 5| Step: 2
Training loss: 3.0320161460808905
Validation loss: 2.7068919287863684

Epoch: 5| Step: 3
Training loss: 3.040699339033366
Validation loss: 2.6974506739878277

Epoch: 5| Step: 4
Training loss: 2.6010709647617856
Validation loss: 2.6953531298756204

Epoch: 5| Step: 5
Training loss: 3.168932221419416
Validation loss: 2.696831234968588

Epoch: 5| Step: 6
Training loss: 3.6353850413406983
Validation loss: 2.6951044493077454

Epoch: 5| Step: 7
Training loss: 3.0628963914585112
Validation loss: 2.694702996429067

Epoch: 5| Step: 8
Training loss: 2.952118232716387
Validation loss: 2.6890635843878923

Epoch: 5| Step: 9
Training loss: 2.7161735516185646
Validation loss: 2.6906329754986125

Epoch: 5| Step: 10
Training loss: 2.7003980343205347
Validation loss: 2.6845983612566404

Epoch: 83| Step: 0
Training loss: 2.8251787719875296
Validation loss: 2.6884431140469895

Epoch: 5| Step: 1
Training loss: 2.6437216213858554
Validation loss: 2.6887508056219587

Epoch: 5| Step: 2
Training loss: 2.8869551173422043
Validation loss: 2.68604334670444

Epoch: 5| Step: 3
Training loss: 3.419552925290425
Validation loss: 2.686392620599428

Epoch: 5| Step: 4
Training loss: 3.4665810617245523
Validation loss: 2.6821125229149496

Epoch: 5| Step: 5
Training loss: 2.8445847512284437
Validation loss: 2.6860384323393296

Epoch: 5| Step: 6
Training loss: 2.8193326394432128
Validation loss: 2.6818084890111846

Epoch: 5| Step: 7
Training loss: 2.877864902933446
Validation loss: 2.689540598674789

Epoch: 5| Step: 8
Training loss: 3.2008992719690497
Validation loss: 2.7060199357745205

Epoch: 5| Step: 9
Training loss: 3.151572056208786
Validation loss: 2.729672386421131

Epoch: 5| Step: 10
Training loss: 2.84499340331481
Validation loss: 2.7623191037424437

Epoch: 84| Step: 0
Training loss: 2.6971526567694415
Validation loss: 2.7784725883716783

Epoch: 5| Step: 1
Training loss: 2.866913244450989
Validation loss: 2.859598331391794

Epoch: 5| Step: 2
Training loss: 3.3352719073996147
Validation loss: 2.8906485980355794

Epoch: 5| Step: 3
Training loss: 2.828388855148842
Validation loss: 2.940651989239623

Epoch: 5| Step: 4
Training loss: 2.945405265500751
Validation loss: 2.78131941030899

Epoch: 5| Step: 5
Training loss: 3.390554541633637
Validation loss: 2.6910279077402115

Epoch: 5| Step: 6
Training loss: 2.76518616723897
Validation loss: 2.6744819678881733

Epoch: 5| Step: 7
Training loss: 3.2371124624774104
Validation loss: 2.6841966913831166

Epoch: 5| Step: 8
Training loss: 2.8288057466914633
Validation loss: 2.702820018506845

Epoch: 5| Step: 9
Training loss: 3.222528702494878
Validation loss: 2.7174808989918615

Epoch: 5| Step: 10
Training loss: 3.3913709813102924
Validation loss: 2.711887012830543

Epoch: 85| Step: 0
Training loss: 3.1993074323312265
Validation loss: 2.6906168449878254

Epoch: 5| Step: 1
Training loss: 2.4798221736649766
Validation loss: 2.681484919145425

Epoch: 5| Step: 2
Training loss: 3.211720317820707
Validation loss: 2.6815052304060396

Epoch: 5| Step: 3
Training loss: 3.3540139647291487
Validation loss: 2.681686531587356

Epoch: 5| Step: 4
Training loss: 2.843555821087675
Validation loss: 2.6777716316383855

Epoch: 5| Step: 5
Training loss: 3.0378406098211785
Validation loss: 2.679054669856174

Epoch: 5| Step: 6
Training loss: 3.2337914276713433
Validation loss: 2.6785978298966344

Epoch: 5| Step: 7
Training loss: 3.2912149883976762
Validation loss: 2.6733576329800117

Epoch: 5| Step: 8
Training loss: 2.6066011773132463
Validation loss: 2.6758414154917363

Epoch: 5| Step: 9
Training loss: 2.9117599267404723
Validation loss: 2.6898334500653487

Epoch: 5| Step: 10
Training loss: 2.7743166967196644
Validation loss: 2.7380462789556392

Epoch: 86| Step: 0
Training loss: 3.277869963202705
Validation loss: 2.890924235927234

Epoch: 5| Step: 1
Training loss: 3.3985994146953216
Validation loss: 2.7301344036799766

Epoch: 5| Step: 2
Training loss: 3.0231884599972667
Validation loss: 2.677369719886727

Epoch: 5| Step: 3
Training loss: 2.1774824467158433
Validation loss: 2.677340222298895

Epoch: 5| Step: 4
Training loss: 3.1067679512583988
Validation loss: 2.6776573153489416

Epoch: 5| Step: 5
Training loss: 3.3403663984788294
Validation loss: 2.676091549860914

Epoch: 5| Step: 6
Training loss: 3.331963702788375
Validation loss: 2.694415279394516

Epoch: 5| Step: 7
Training loss: 2.926352757047448
Validation loss: 2.6981807381064344

Epoch: 5| Step: 8
Training loss: 2.44395950473008
Validation loss: 2.694775323779276

Epoch: 5| Step: 9
Training loss: 3.0613385547744048
Validation loss: 2.696695356743325

Epoch: 5| Step: 10
Training loss: 3.285154217913313
Validation loss: 2.7044644711803008

Epoch: 87| Step: 0
Training loss: 2.3764349969071628
Validation loss: 2.6906581712782556

Epoch: 5| Step: 1
Training loss: 3.1438454585058366
Validation loss: 2.6833183439935824

Epoch: 5| Step: 2
Training loss: 3.15649307372519
Validation loss: 2.675266683880612

Epoch: 5| Step: 3
Training loss: 2.9623443562629594
Validation loss: 2.6730873453240904

Epoch: 5| Step: 4
Training loss: 3.2825229173893113
Validation loss: 2.6740558817030413

Epoch: 5| Step: 5
Training loss: 3.1853489817249185
Validation loss: 2.6745272516055616

Epoch: 5| Step: 6
Training loss: 3.2470042286508445
Validation loss: 2.6876818325212906

Epoch: 5| Step: 7
Training loss: 2.9892228780934005
Validation loss: 2.693433562101953

Epoch: 5| Step: 8
Training loss: 2.678278071370071
Validation loss: 2.6963852744746073

Epoch: 5| Step: 9
Training loss: 3.158549915493588
Validation loss: 2.705005513963263

Epoch: 5| Step: 10
Training loss: 2.974415723341926
Validation loss: 2.69987233770495

Epoch: 88| Step: 0
Training loss: 3.2800370653895956
Validation loss: 2.6805782482573712

Epoch: 5| Step: 1
Training loss: 3.6143374986993666
Validation loss: 2.6710663815427007

Epoch: 5| Step: 2
Training loss: 2.8191475192494853
Validation loss: 2.664839640389049

Epoch: 5| Step: 3
Training loss: 2.258741352717066
Validation loss: 2.6634554357909535

Epoch: 5| Step: 4
Training loss: 2.9688910199853757
Validation loss: 2.6676842596345094

Epoch: 5| Step: 5
Training loss: 2.64472002851641
Validation loss: 2.6661796698752798

Epoch: 5| Step: 6
Training loss: 3.5771251097638896
Validation loss: 2.6595156945253935

Epoch: 5| Step: 7
Training loss: 3.0705397038926483
Validation loss: 2.6623180291593354

Epoch: 5| Step: 8
Training loss: 2.863579998590086
Validation loss: 2.6581641908307425

Epoch: 5| Step: 9
Training loss: 3.047273580450053
Validation loss: 2.6728708852780705

Epoch: 5| Step: 10
Training loss: 2.3972151931398353
Validation loss: 2.6678978964279656

Epoch: 89| Step: 0
Training loss: 3.157127636044878
Validation loss: 2.664767984003607

Epoch: 5| Step: 1
Training loss: 3.308225068467636
Validation loss: 2.667735451534696

Epoch: 5| Step: 2
Training loss: 2.602480248221456
Validation loss: 2.6602671938013716

Epoch: 5| Step: 3
Training loss: 3.371991688827825
Validation loss: 2.663845022705649

Epoch: 5| Step: 4
Training loss: 3.1180204650520493
Validation loss: 2.662382737640901

Epoch: 5| Step: 5
Training loss: 3.0499183518784565
Validation loss: 2.6586778078931412

Epoch: 5| Step: 6
Training loss: 2.3175725204165967
Validation loss: 2.679058876472602

Epoch: 5| Step: 7
Training loss: 2.7057666549557737
Validation loss: 2.653069109615282

Epoch: 5| Step: 8
Training loss: 2.6345269934269906
Validation loss: 2.658659938278486

Epoch: 5| Step: 9
Training loss: 3.0910583500854223
Validation loss: 2.6590893360309886

Epoch: 5| Step: 10
Training loss: 3.339853315730088
Validation loss: 2.6683740895430152

Epoch: 90| Step: 0
Training loss: 2.9687846934650453
Validation loss: 2.659825381156553

Epoch: 5| Step: 1
Training loss: 2.6297857165340437
Validation loss: 2.6570623980803956

Epoch: 5| Step: 2
Training loss: 2.2140814867194893
Validation loss: 2.649751590386007

Epoch: 5| Step: 3
Training loss: 2.8962461511210162
Validation loss: 2.6562088057757793

Epoch: 5| Step: 4
Training loss: 3.336160049340693
Validation loss: 2.6527680305923673

Epoch: 5| Step: 5
Training loss: 2.796336628335535
Validation loss: 2.649563343558188

Epoch: 5| Step: 6
Training loss: 3.222831878500279
Validation loss: 2.6522527471250545

Epoch: 5| Step: 7
Training loss: 2.7310510977592086
Validation loss: 2.655746543507632

Epoch: 5| Step: 8
Training loss: 3.159708677456136
Validation loss: 2.6536023016236596

Epoch: 5| Step: 9
Training loss: 3.257042077902741
Validation loss: 2.6544212275899715

Epoch: 5| Step: 10
Training loss: 3.4618599310383584
Validation loss: 2.650740941836422

Epoch: 91| Step: 0
Training loss: 3.1103051102791057
Validation loss: 2.649864132695679

Epoch: 5| Step: 1
Training loss: 2.750796116120011
Validation loss: 2.6513096091566775

Epoch: 5| Step: 2
Training loss: 3.3408080376491833
Validation loss: 2.6541332055058637

Epoch: 5| Step: 3
Training loss: 3.010869046092793
Validation loss: 2.6690510183246023

Epoch: 5| Step: 4
Training loss: 2.382085470381343
Validation loss: 2.6918404154841045

Epoch: 5| Step: 5
Training loss: 3.0457988697055667
Validation loss: 2.71265915336229

Epoch: 5| Step: 6
Training loss: 3.3711325067478075
Validation loss: 2.702037070018385

Epoch: 5| Step: 7
Training loss: 3.200464697713605
Validation loss: 2.651798989091976

Epoch: 5| Step: 8
Training loss: 3.074864398478535
Validation loss: 2.64802709694365

Epoch: 5| Step: 9
Training loss: 2.8551292374148862
Validation loss: 2.653769956888366

Epoch: 5| Step: 10
Training loss: 2.6046864308776674
Validation loss: 2.6561816771935662

Epoch: 92| Step: 0
Training loss: 2.8223115805082015
Validation loss: 2.6556899318148184

Epoch: 5| Step: 1
Training loss: 3.1110474962209556
Validation loss: 2.6560833989110146

Epoch: 5| Step: 2
Training loss: 2.796010144740571
Validation loss: 2.6554202642334186

Epoch: 5| Step: 3
Training loss: 2.8794933533072657
Validation loss: 2.655029292409197

Epoch: 5| Step: 4
Training loss: 3.0282006410770785
Validation loss: 2.657546062225214

Epoch: 5| Step: 5
Training loss: 3.221219643097115
Validation loss: 2.6575274190515694

Epoch: 5| Step: 6
Training loss: 2.7253811525932297
Validation loss: 2.651275091332418

Epoch: 5| Step: 7
Training loss: 3.5329831351669405
Validation loss: 2.652325449152211

Epoch: 5| Step: 8
Training loss: 2.6850010986610027
Validation loss: 2.6499067915848262

Epoch: 5| Step: 9
Training loss: 3.2087277421822042
Validation loss: 2.650579680651974

Epoch: 5| Step: 10
Training loss: 3.0168196925626964
Validation loss: 2.6500368614519823

Epoch: 93| Step: 0
Training loss: 3.2821964896997056
Validation loss: 2.6490642892355005

Epoch: 5| Step: 1
Training loss: 3.1398490592492125
Validation loss: 2.644241856893752

Epoch: 5| Step: 2
Training loss: 3.1165440404366893
Validation loss: 2.6464566982223507

Epoch: 5| Step: 3
Training loss: 3.0764656047761374
Validation loss: 2.6482886453058856

Epoch: 5| Step: 4
Training loss: 2.896558620455633
Validation loss: 2.647881029822748

Epoch: 5| Step: 5
Training loss: 2.9259838242934384
Validation loss: 2.6495583973306545

Epoch: 5| Step: 6
Training loss: 2.5436012430770196
Validation loss: 2.6491034345661553

Epoch: 5| Step: 7
Training loss: 3.0127185789721525
Validation loss: 2.646520705719721

Epoch: 5| Step: 8
Training loss: 2.657185199139427
Validation loss: 2.6458146244234135

Epoch: 5| Step: 9
Training loss: 3.3591481686682685
Validation loss: 2.6485477508897244

Epoch: 5| Step: 10
Training loss: 2.7989437188544355
Validation loss: 2.645723868862192

Epoch: 94| Step: 0
Training loss: 3.001386639885798
Validation loss: 2.643035310944722

Epoch: 5| Step: 1
Training loss: 2.6079455817694326
Validation loss: 2.645381902220841

Epoch: 5| Step: 2
Training loss: 3.2022610127169355
Validation loss: 2.644739432751802

Epoch: 5| Step: 3
Training loss: 3.2630076163293937
Validation loss: 2.641275058765274

Epoch: 5| Step: 4
Training loss: 2.7939459951720593
Validation loss: 2.641191816237347

Epoch: 5| Step: 5
Training loss: 2.8098392192144543
Validation loss: 2.650049112553254

Epoch: 5| Step: 6
Training loss: 3.225003731895476
Validation loss: 2.6531910384256174

Epoch: 5| Step: 7
Training loss: 3.244123133842447
Validation loss: 2.6525633889840097

Epoch: 5| Step: 8
Training loss: 2.6284714405815097
Validation loss: 2.6511003206650035

Epoch: 5| Step: 9
Training loss: 2.8638432511957483
Validation loss: 2.6457787442617615

Epoch: 5| Step: 10
Training loss: 3.0458472450310894
Validation loss: 2.637906759801589

Epoch: 95| Step: 0
Training loss: 2.363377693667435
Validation loss: 2.64885115042237

Epoch: 5| Step: 1
Training loss: 2.893895788619242
Validation loss: 2.65202186515237

Epoch: 5| Step: 2
Training loss: 2.8250619729595337
Validation loss: 2.64682644037756

Epoch: 5| Step: 3
Training loss: 3.3175031198287126
Validation loss: 2.6470746503672222

Epoch: 5| Step: 4
Training loss: 3.125183100104646
Validation loss: 2.6541506960566665

Epoch: 5| Step: 5
Training loss: 3.023848315970973
Validation loss: 2.664539591189285

Epoch: 5| Step: 6
Training loss: 3.3478587922793266
Validation loss: 2.664959602125956

Epoch: 5| Step: 7
Training loss: 2.461123020505925
Validation loss: 2.647216222959899

Epoch: 5| Step: 8
Training loss: 2.9551371828822637
Validation loss: 2.636689729094075

Epoch: 5| Step: 9
Training loss: 3.0324658973581444
Validation loss: 2.629199189556548

Epoch: 5| Step: 10
Training loss: 3.1899534768565636
Validation loss: 2.630250435103035

Epoch: 96| Step: 0
Training loss: 3.0301086794055405
Validation loss: 2.635186421008532

Epoch: 5| Step: 1
Training loss: 3.2423679531389524
Validation loss: 2.631248196599374

Epoch: 5| Step: 2
Training loss: 3.025584954065911
Validation loss: 2.636195062537234

Epoch: 5| Step: 3
Training loss: 3.1877737488722477
Validation loss: 2.635779222631562

Epoch: 5| Step: 4
Training loss: 2.9486511896969057
Validation loss: 2.6332049878911516

Epoch: 5| Step: 5
Training loss: 2.84897812040851
Validation loss: 2.632338932018367

Epoch: 5| Step: 6
Training loss: 2.553729236311112
Validation loss: 2.630743405111166

Epoch: 5| Step: 7
Training loss: 2.9659855871589906
Validation loss: 2.6348340185933425

Epoch: 5| Step: 8
Training loss: 2.866056713003656
Validation loss: 2.6454275522699744

Epoch: 5| Step: 9
Training loss: 2.830396888319756
Validation loss: 2.6618946457011514

Epoch: 5| Step: 10
Training loss: 3.154427634915478
Validation loss: 2.657287109511046

Epoch: 97| Step: 0
Training loss: 2.4551144447765942
Validation loss: 2.647317407317391

Epoch: 5| Step: 1
Training loss: 2.6079907428951614
Validation loss: 2.643548455749161

Epoch: 5| Step: 2
Training loss: 2.796393923169849
Validation loss: 2.638632187252209

Epoch: 5| Step: 3
Training loss: 3.461632927803794
Validation loss: 2.640313021516341

Epoch: 5| Step: 4
Training loss: 2.5950350967415283
Validation loss: 2.63900238160781

Epoch: 5| Step: 5
Training loss: 3.243985112072593
Validation loss: 2.641668255482877

Epoch: 5| Step: 6
Training loss: 3.536836239713093
Validation loss: 2.644051241773457

Epoch: 5| Step: 7
Training loss: 2.6098835158388884
Validation loss: 2.6429861392947016

Epoch: 5| Step: 8
Training loss: 3.116935547706614
Validation loss: 2.631247025483425

Epoch: 5| Step: 9
Training loss: 2.8101248991009924
Validation loss: 2.6278839139656323

Epoch: 5| Step: 10
Training loss: 3.157137453312555
Validation loss: 2.6247697925558073

Epoch: 98| Step: 0
Training loss: 3.096447625873926
Validation loss: 2.630220195622084

Epoch: 5| Step: 1
Training loss: 2.8258067371673374
Validation loss: 2.6257718382754573

Epoch: 5| Step: 2
Training loss: 3.156094991069085
Validation loss: 2.6272962276673084

Epoch: 5| Step: 3
Training loss: 3.0844008857236016
Validation loss: 2.6271878611346615

Epoch: 5| Step: 4
Training loss: 2.7760824137280324
Validation loss: 2.6242175168975703

Epoch: 5| Step: 5
Training loss: 2.4470791513528614
Validation loss: 2.627006377310809

Epoch: 5| Step: 6
Training loss: 2.7825787402696767
Validation loss: 2.635834236985849

Epoch: 5| Step: 7
Training loss: 3.3675621868641805
Validation loss: 2.6494075542428206

Epoch: 5| Step: 8
Training loss: 3.020800482911136
Validation loss: 2.6492964179137046

Epoch: 5| Step: 9
Training loss: 3.12007867493837
Validation loss: 2.6557854214160304

Epoch: 5| Step: 10
Training loss: 2.900152886405537
Validation loss: 2.6607363344268276

Epoch: 99| Step: 0
Training loss: 3.4019084174529604
Validation loss: 2.660467415400758

Epoch: 5| Step: 1
Training loss: 3.5366168803582694
Validation loss: 2.657057090489113

Epoch: 5| Step: 2
Training loss: 3.0322860048521427
Validation loss: 2.6489008509887686

Epoch: 5| Step: 3
Training loss: 2.9579697685528097
Validation loss: 2.623680327004923

Epoch: 5| Step: 4
Training loss: 2.5456827567647937
Validation loss: 2.6200024632872325

Epoch: 5| Step: 5
Training loss: 2.7664853929016475
Validation loss: 2.6202052773819653

Epoch: 5| Step: 6
Training loss: 3.164505689688486
Validation loss: 2.622473438877279

Epoch: 5| Step: 7
Training loss: 2.2379208685731857
Validation loss: 2.6232235508713915

Epoch: 5| Step: 8
Training loss: 2.7284215147681556
Validation loss: 2.6207668062084863

Epoch: 5| Step: 9
Training loss: 2.9103184597200533
Validation loss: 2.6206978469161664

Epoch: 5| Step: 10
Training loss: 3.119377571522213
Validation loss: 2.6223106094665902

Epoch: 100| Step: 0
Training loss: 2.8126939494758347
Validation loss: 2.620993091848756

Epoch: 5| Step: 1
Training loss: 3.013511272707448
Validation loss: 2.621768194475447

Epoch: 5| Step: 2
Training loss: 3.466176771125703
Validation loss: 2.6206803972227743

Epoch: 5| Step: 3
Training loss: 3.1739708501562522
Validation loss: 2.6229134708510733

Epoch: 5| Step: 4
Training loss: 2.8878691862495516
Validation loss: 2.622112545589077

Epoch: 5| Step: 5
Training loss: 3.0458297110212906
Validation loss: 2.6243536808311507

Epoch: 5| Step: 6
Training loss: 3.530704827549971
Validation loss: 2.620994397636019

Epoch: 5| Step: 7
Training loss: 2.4967860543804865
Validation loss: 2.6225874518661945

Epoch: 5| Step: 8
Training loss: 2.614879718005444
Validation loss: 2.6328517116945713

Epoch: 5| Step: 9
Training loss: 2.3322097479975477
Validation loss: 2.6407269427038726

Epoch: 5| Step: 10
Training loss: 2.989853708267075
Validation loss: 2.635978868012796

Epoch: 101| Step: 0
Training loss: 2.8914884360258797
Validation loss: 2.636143551840705

Epoch: 5| Step: 1
Training loss: 2.673364859686038
Validation loss: 2.641415234022433

Epoch: 5| Step: 2
Training loss: 2.6881178212286168
Validation loss: 2.6331491377749057

Epoch: 5| Step: 3
Training loss: 2.9774333651090417
Validation loss: 2.627228913211863

Epoch: 5| Step: 4
Training loss: 2.480622342378092
Validation loss: 2.621251455842725

Epoch: 5| Step: 5
Training loss: 2.3320903419151677
Validation loss: 2.618187283530696

Epoch: 5| Step: 6
Training loss: 3.140340611881197
Validation loss: 2.6179000930047502

Epoch: 5| Step: 7
Training loss: 3.4287486257630313
Validation loss: 2.6179165545434113

Epoch: 5| Step: 8
Training loss: 3.1183097941497153
Validation loss: 2.615899939986159

Epoch: 5| Step: 9
Training loss: 3.263430939780749
Validation loss: 2.618384199188519

Epoch: 5| Step: 10
Training loss: 3.3199528757450714
Validation loss: 2.6202451072587776

Epoch: 102| Step: 0
Training loss: 3.2315097962646644
Validation loss: 2.6177341028136163

Epoch: 5| Step: 1
Training loss: 2.802530378301236
Validation loss: 2.617408102769628

Epoch: 5| Step: 2
Training loss: 3.171240230991833
Validation loss: 2.6279203603814967

Epoch: 5| Step: 3
Training loss: 3.0471375963562806
Validation loss: 2.6305818019474865

Epoch: 5| Step: 4
Training loss: 2.9665252380377685
Validation loss: 2.6427195038807705

Epoch: 5| Step: 5
Training loss: 2.869320774849751
Validation loss: 2.6810905299164056

Epoch: 5| Step: 6
Training loss: 2.9369691409657936
Validation loss: 2.678539757294739

Epoch: 5| Step: 7
Training loss: 2.9538190722370303
Validation loss: 2.697095882872565

Epoch: 5| Step: 8
Training loss: 2.585266671656973
Validation loss: 2.6588568329721145

Epoch: 5| Step: 9
Training loss: 3.2048589711694726
Validation loss: 2.622641187732712

Epoch: 5| Step: 10
Training loss: 2.5424348472867018
Validation loss: 2.6111318386997437

Epoch: 103| Step: 0
Training loss: 2.8829974190141052
Validation loss: 2.60700375151507

Epoch: 5| Step: 1
Training loss: 3.1245925637713463
Validation loss: 2.611140692665565

Epoch: 5| Step: 2
Training loss: 2.5384256826104785
Validation loss: 2.610747843418058

Epoch: 5| Step: 3
Training loss: 3.5447086658937166
Validation loss: 2.6137328546541703

Epoch: 5| Step: 4
Training loss: 3.2214384240140856
Validation loss: 2.614005854835283

Epoch: 5| Step: 5
Training loss: 2.569027472218843
Validation loss: 2.6102670607747465

Epoch: 5| Step: 6
Training loss: 2.4152350186182527
Validation loss: 2.6129225578799438

Epoch: 5| Step: 7
Training loss: 3.211933955928056
Validation loss: 2.6111006679455526

Epoch: 5| Step: 8
Training loss: 2.9637376734985255
Validation loss: 2.6096076058485136

Epoch: 5| Step: 9
Training loss: 2.822808764508125
Validation loss: 2.607747447281514

Epoch: 5| Step: 10
Training loss: 3.150408939277594
Validation loss: 2.612158496389869

Epoch: 104| Step: 0
Training loss: 2.7042012800715978
Validation loss: 2.611890806544823

Epoch: 5| Step: 1
Training loss: 2.5288061895835985
Validation loss: 2.6197696716589567

Epoch: 5| Step: 2
Training loss: 2.852937215451833
Validation loss: 2.6232435196878923

Epoch: 5| Step: 3
Training loss: 3.2055699391283845
Validation loss: 2.6299622569944945

Epoch: 5| Step: 4
Training loss: 3.3848746623918795
Validation loss: 2.6123546260598904

Epoch: 5| Step: 5
Training loss: 2.792832335228478
Validation loss: 2.6023823702221405

Epoch: 5| Step: 6
Training loss: 2.625755110624458
Validation loss: 2.6035735700648246

Epoch: 5| Step: 7
Training loss: 3.1592512308359675
Validation loss: 2.60576949149067

Epoch: 5| Step: 8
Training loss: 3.467642392491912
Validation loss: 2.609164103635526

Epoch: 5| Step: 9
Training loss: 3.0224254402701463
Validation loss: 2.6031503425962623

Epoch: 5| Step: 10
Training loss: 2.485753570600115
Validation loss: 2.608662350343806

Epoch: 105| Step: 0
Training loss: 2.7356520803992375
Validation loss: 2.620056800112301

Epoch: 5| Step: 1
Training loss: 3.130364962619269
Validation loss: 2.6231090592740163

Epoch: 5| Step: 2
Training loss: 3.302153497345594
Validation loss: 2.6263224370918135

Epoch: 5| Step: 3
Training loss: 3.0923733200980914
Validation loss: 2.647029902308039

Epoch: 5| Step: 4
Training loss: 2.938363780186503
Validation loss: 2.642518554551576

Epoch: 5| Step: 5
Training loss: 2.6833765200186233
Validation loss: 2.6367009337995753

Epoch: 5| Step: 6
Training loss: 3.0307726926683274
Validation loss: 2.6404711164001675

Epoch: 5| Step: 7
Training loss: 2.794882549486397
Validation loss: 2.62338924552059

Epoch: 5| Step: 8
Training loss: 3.0965258542975236
Validation loss: 2.6034835895802972

Epoch: 5| Step: 9
Training loss: 2.871387368064516
Validation loss: 2.59780364604132

Epoch: 5| Step: 10
Training loss: 2.614766381734434
Validation loss: 2.5973770918059635

Epoch: 106| Step: 0
Training loss: 2.8478126430605624
Validation loss: 2.598077754623196

Epoch: 5| Step: 1
Training loss: 2.980771750550826
Validation loss: 2.604473293505721

Epoch: 5| Step: 2
Training loss: 2.9552417414841634
Validation loss: 2.602801744339167

Epoch: 5| Step: 3
Training loss: 3.0691207630689252
Validation loss: 2.5998370988437953

Epoch: 5| Step: 4
Training loss: 3.180901672839088
Validation loss: 2.6034187529226918

Epoch: 5| Step: 5
Training loss: 2.523528011812789
Validation loss: 2.599708767562227

Epoch: 5| Step: 6
Training loss: 3.1950059664436234
Validation loss: 2.5966996383053282

Epoch: 5| Step: 7
Training loss: 2.8534415964580337
Validation loss: 2.604301660463865

Epoch: 5| Step: 8
Training loss: 2.656535234283327
Validation loss: 2.6284234585299435

Epoch: 5| Step: 9
Training loss: 3.1216189595446893
Validation loss: 2.6752746595898493

Epoch: 5| Step: 10
Training loss: 3.0223233636905023
Validation loss: 2.7175572105150225

Epoch: 107| Step: 0
Training loss: 3.239248538528705
Validation loss: 2.6833696107113356

Epoch: 5| Step: 1
Training loss: 2.6404586829904364
Validation loss: 2.620726133211226

Epoch: 5| Step: 2
Training loss: 2.8487484777361964
Validation loss: 2.5955120120542596

Epoch: 5| Step: 3
Training loss: 3.054070217661863
Validation loss: 2.5925957920792397

Epoch: 5| Step: 4
Training loss: 2.760041630057797
Validation loss: 2.60141202346163

Epoch: 5| Step: 5
Training loss: 3.0039329180383203
Validation loss: 2.601183895434808

Epoch: 5| Step: 6
Training loss: 3.3948394319432484
Validation loss: 2.6066695171880148

Epoch: 5| Step: 7
Training loss: 3.0644081554918277
Validation loss: 2.609666149472471

Epoch: 5| Step: 8
Training loss: 3.369584153324117
Validation loss: 2.61036306980482

Epoch: 5| Step: 9
Training loss: 2.545711509008271
Validation loss: 2.612645742766281

Epoch: 5| Step: 10
Training loss: 2.572861911535969
Validation loss: 2.6201337270825538

Epoch: 108| Step: 0
Training loss: 2.5392193085593155
Validation loss: 2.6179184964301707

Epoch: 5| Step: 1
Training loss: 2.7074006944586584
Validation loss: 2.6153473165428416

Epoch: 5| Step: 2
Training loss: 3.260168307821654
Validation loss: 2.634847220925021

Epoch: 5| Step: 3
Training loss: 3.022112888886083
Validation loss: 2.6280711149867986

Epoch: 5| Step: 4
Training loss: 3.3561022052865286
Validation loss: 2.618148385862298

Epoch: 5| Step: 5
Training loss: 2.6413835869228426
Validation loss: 2.6041961733879435

Epoch: 5| Step: 6
Training loss: 3.2279565492090416
Validation loss: 2.603552550394711

Epoch: 5| Step: 7
Training loss: 2.4260715673320306
Validation loss: 2.602469532543493

Epoch: 5| Step: 8
Training loss: 2.8888177944466693
Validation loss: 2.602024160461896

Epoch: 5| Step: 9
Training loss: 3.4412938769695995
Validation loss: 2.599073130605115

Epoch: 5| Step: 10
Training loss: 3.0707330391463663
Validation loss: 2.6002703841028936

Epoch: 109| Step: 0
Training loss: 2.685678707701686
Validation loss: 2.5972135398651917

Epoch: 5| Step: 1
Training loss: 3.17803027106549
Validation loss: 2.593297281105081

Epoch: 5| Step: 2
Training loss: 2.6360761297343767
Validation loss: 2.590306757760859

Epoch: 5| Step: 3
Training loss: 3.2658765778075827
Validation loss: 2.589762378412163

Epoch: 5| Step: 4
Training loss: 2.7254693318336694
Validation loss: 2.588780806049228

Epoch: 5| Step: 5
Training loss: 3.1169886322450586
Validation loss: 2.590718566193648

Epoch: 5| Step: 6
Training loss: 2.935728147471999
Validation loss: 2.5930555046170545

Epoch: 5| Step: 7
Training loss: 3.0589192535128675
Validation loss: 2.5973868479011992

Epoch: 5| Step: 8
Training loss: 2.950092191387094
Validation loss: 2.6089457556195494

Epoch: 5| Step: 9
Training loss: 2.697850632810643
Validation loss: 2.6136378816192214

Epoch: 5| Step: 10
Training loss: 2.9450333764042074
Validation loss: 2.6067103583725095

Epoch: 110| Step: 0
Training loss: 2.5501787721387186
Validation loss: 2.602654720990876

Epoch: 5| Step: 1
Training loss: 2.70763096627364
Validation loss: 2.6003804515766356

Epoch: 5| Step: 2
Training loss: 2.840513630478918
Validation loss: 2.602292580058576

Epoch: 5| Step: 3
Training loss: 3.286568971797835
Validation loss: 2.597147545267281

Epoch: 5| Step: 4
Training loss: 3.105687240495863
Validation loss: 2.6013050562312556

Epoch: 5| Step: 5
Training loss: 2.4964007217222814
Validation loss: 2.59177637803443

Epoch: 5| Step: 6
Training loss: 2.927185455025074
Validation loss: 2.5948322408977376

Epoch: 5| Step: 7
Training loss: 3.2903916670189424
Validation loss: 2.5904670237190897

Epoch: 5| Step: 8
Training loss: 3.2861275886845553
Validation loss: 2.5923902315508083

Epoch: 5| Step: 9
Training loss: 2.843989267868202
Validation loss: 2.5936583645988085

Epoch: 5| Step: 10
Training loss: 2.6825729272035876
Validation loss: 2.593800745503597

Epoch: 111| Step: 0
Training loss: 3.084470144116537
Validation loss: 2.593847992231159

Epoch: 5| Step: 1
Training loss: 3.3019611484453124
Validation loss: 2.5939077039530303

Epoch: 5| Step: 2
Training loss: 2.736813662116711
Validation loss: 2.588591338548255

Epoch: 5| Step: 3
Training loss: 2.537218944600437
Validation loss: 2.58386770517719

Epoch: 5| Step: 4
Training loss: 2.8652921227458523
Validation loss: 2.593279689546962

Epoch: 5| Step: 5
Training loss: 2.8314418837174005
Validation loss: 2.591255891494635

Epoch: 5| Step: 6
Training loss: 3.1323902482932326
Validation loss: 2.5876554567175702

Epoch: 5| Step: 7
Training loss: 3.2020427084939143
Validation loss: 2.5880561519041105

Epoch: 5| Step: 8
Training loss: 2.948955519088827
Validation loss: 2.579881037107545

Epoch: 5| Step: 9
Training loss: 2.7624514200073076
Validation loss: 2.5804924320779703

Epoch: 5| Step: 10
Training loss: 2.5823816474316774
Validation loss: 2.5764626352566884

Epoch: 112| Step: 0
Training loss: 2.617826287045557
Validation loss: 2.5808856302814736

Epoch: 5| Step: 1
Training loss: 3.0512488638107267
Validation loss: 2.5793878847449974

Epoch: 5| Step: 2
Training loss: 3.281493404988037
Validation loss: 2.5833915359207067

Epoch: 5| Step: 3
Training loss: 3.392561539701112
Validation loss: 2.5882493714448

Epoch: 5| Step: 4
Training loss: 2.759711975742468
Validation loss: 2.6157424123165827

Epoch: 5| Step: 5
Training loss: 2.6510257283289356
Validation loss: 2.6380187296995894

Epoch: 5| Step: 6
Training loss: 3.20184657938889
Validation loss: 2.6582655824332972

Epoch: 5| Step: 7
Training loss: 2.594021610608225
Validation loss: 2.6250455923657507

Epoch: 5| Step: 8
Training loss: 2.9337876582156617
Validation loss: 2.582021350992724

Epoch: 5| Step: 9
Training loss: 2.9453147665566544
Validation loss: 2.5797166839994214

Epoch: 5| Step: 10
Training loss: 2.597974989990185
Validation loss: 2.5754237049306163

Epoch: 113| Step: 0
Training loss: 3.2250006269114277
Validation loss: 2.5807496945842976

Epoch: 5| Step: 1
Training loss: 3.4209047100195846
Validation loss: 2.581179927721101

Epoch: 5| Step: 2
Training loss: 2.771020055994961
Validation loss: 2.582165890602252

Epoch: 5| Step: 3
Training loss: 2.835122403793993
Validation loss: 2.5763808549748113

Epoch: 5| Step: 4
Training loss: 3.21838421270873
Validation loss: 2.578172929752685

Epoch: 5| Step: 5
Training loss: 2.8843416123198824
Validation loss: 2.5728283968673407

Epoch: 5| Step: 6
Training loss: 2.4119146476940743
Validation loss: 2.583923864466487

Epoch: 5| Step: 7
Training loss: 2.2852178059951753
Validation loss: 2.5955662343846835

Epoch: 5| Step: 8
Training loss: 2.6161259106598873
Validation loss: 2.6462259683564042

Epoch: 5| Step: 9
Training loss: 3.2768053742468988
Validation loss: 2.7083394040275546

Epoch: 5| Step: 10
Training loss: 3.249769642809047
Validation loss: 2.626123601961087

Epoch: 114| Step: 0
Training loss: 2.884677356152102
Validation loss: 2.5825663763501874

Epoch: 5| Step: 1
Training loss: 2.7363397133777188
Validation loss: 2.5820839454407247

Epoch: 5| Step: 2
Training loss: 2.9907809704136277
Validation loss: 2.573441070911398

Epoch: 5| Step: 3
Training loss: 2.723048965831978
Validation loss: 2.5754673897730487

Epoch: 5| Step: 4
Training loss: 2.697726111635664
Validation loss: 2.578324699933339

Epoch: 5| Step: 5
Training loss: 3.327990605322709
Validation loss: 2.5745531543679676

Epoch: 5| Step: 6
Training loss: 2.8032719432203654
Validation loss: 2.5740299689989627

Epoch: 5| Step: 7
Training loss: 3.120363992830629
Validation loss: 2.5735327229004996

Epoch: 5| Step: 8
Training loss: 2.382378410446998
Validation loss: 2.5720309996258446

Epoch: 5| Step: 9
Training loss: 3.195270118339041
Validation loss: 2.5733125011912814

Epoch: 5| Step: 10
Training loss: 3.284120593757303
Validation loss: 2.573730627624705

Epoch: 115| Step: 0
Training loss: 2.585318868807456
Validation loss: 2.5657777249953204

Epoch: 5| Step: 1
Training loss: 3.1570533258902436
Validation loss: 2.567909392763806

Epoch: 5| Step: 2
Training loss: 2.9145811708527276
Validation loss: 2.573390890253834

Epoch: 5| Step: 3
Training loss: 2.5413248634851033
Validation loss: 2.5767908944587123

Epoch: 5| Step: 4
Training loss: 2.757921254550476
Validation loss: 2.590745663837111

Epoch: 5| Step: 5
Training loss: 3.1446292080044924
Validation loss: 2.5908063890780864

Epoch: 5| Step: 6
Training loss: 2.5623680639029334
Validation loss: 2.6030359194816826

Epoch: 5| Step: 7
Training loss: 3.006137609462742
Validation loss: 2.613771436494537

Epoch: 5| Step: 8
Training loss: 3.259951979862701
Validation loss: 2.598404666407398

Epoch: 5| Step: 9
Training loss: 2.8086953602371034
Validation loss: 2.6098782871485318

Epoch: 5| Step: 10
Training loss: 3.3413208310846527
Validation loss: 2.615356909051298

Epoch: 116| Step: 0
Training loss: 2.867997307194891
Validation loss: 2.605143592616117

Epoch: 5| Step: 1
Training loss: 3.1771938283914856
Validation loss: 2.5896655432671407

Epoch: 5| Step: 2
Training loss: 3.1032866867061597
Validation loss: 2.5759293042254896

Epoch: 5| Step: 3
Training loss: 3.3412928599681617
Validation loss: 2.5739477075494643

Epoch: 5| Step: 4
Training loss: 2.667304965953947
Validation loss: 2.5688853788539343

Epoch: 5| Step: 5
Training loss: 2.6396954948924725
Validation loss: 2.5724558160753386

Epoch: 5| Step: 6
Training loss: 2.7455548860631533
Validation loss: 2.5668437906502657

Epoch: 5| Step: 7
Training loss: 3.053037387992566
Validation loss: 2.5693258269413564

Epoch: 5| Step: 8
Training loss: 2.7165113857177428
Validation loss: 2.5757825863112918

Epoch: 5| Step: 9
Training loss: 2.6232066613538834
Validation loss: 2.574518958698872

Epoch: 5| Step: 10
Training loss: 3.087682766466304
Validation loss: 2.578622624166754

Epoch: 117| Step: 0
Training loss: 2.9565469604767642
Validation loss: 2.5734044486515364

Epoch: 5| Step: 1
Training loss: 2.5468119045937354
Validation loss: 2.5661315376366085

Epoch: 5| Step: 2
Training loss: 2.903365149281688
Validation loss: 2.5765418866573455

Epoch: 5| Step: 3
Training loss: 2.736358969144951
Validation loss: 2.5780679795269865

Epoch: 5| Step: 4
Training loss: 2.828309111108352
Validation loss: 2.573515757307954

Epoch: 5| Step: 5
Training loss: 2.6714603927791982
Validation loss: 2.572265072857542

Epoch: 5| Step: 6
Training loss: 3.3889962076867732
Validation loss: 2.5727581506583954

Epoch: 5| Step: 7
Training loss: 2.9792791669896257
Validation loss: 2.560280765051455

Epoch: 5| Step: 8
Training loss: 2.4036209805003805
Validation loss: 2.5632178708917226

Epoch: 5| Step: 9
Training loss: 3.1467742691661926
Validation loss: 2.5641131327080378

Epoch: 5| Step: 10
Training loss: 3.3899963077311255
Validation loss: 2.566867735620263

Epoch: 118| Step: 0
Training loss: 3.0031159431567063
Validation loss: 2.5620750817272886

Epoch: 5| Step: 1
Training loss: 3.2826077513140093
Validation loss: 2.564541214568521

Epoch: 5| Step: 2
Training loss: 2.720207963454434
Validation loss: 2.561669697117215

Epoch: 5| Step: 3
Training loss: 2.9112360032868336
Validation loss: 2.566902438701288

Epoch: 5| Step: 4
Training loss: 2.393301568719293
Validation loss: 2.5674468192695175

Epoch: 5| Step: 5
Training loss: 2.9445858167701986
Validation loss: 2.5613650718213337

Epoch: 5| Step: 6
Training loss: 2.6670948121961566
Validation loss: 2.5580606029875597

Epoch: 5| Step: 7
Training loss: 2.842282430060645
Validation loss: 2.559399440510004

Epoch: 5| Step: 8
Training loss: 2.881283569140382
Validation loss: 2.561292288183221

Epoch: 5| Step: 9
Training loss: 2.9585469844840073
Validation loss: 2.56862797153983

Epoch: 5| Step: 10
Training loss: 3.321098970504674
Validation loss: 2.5698716583851517

Epoch: 119| Step: 0
Training loss: 3.424193411195248
Validation loss: 2.5704557631552456

Epoch: 5| Step: 1
Training loss: 3.078864768735411
Validation loss: 2.5729964122160625

Epoch: 5| Step: 2
Training loss: 2.8555719484814426
Validation loss: 2.583344211085742

Epoch: 5| Step: 3
Training loss: 2.8200237094612923
Validation loss: 2.595690583817183

Epoch: 5| Step: 4
Training loss: 2.5315777601745806
Validation loss: 2.5959420437993765

Epoch: 5| Step: 5
Training loss: 2.736905393081074
Validation loss: 2.61859333285217

Epoch: 5| Step: 6
Training loss: 2.732739291729099
Validation loss: 2.586298193550077

Epoch: 5| Step: 7
Training loss: 2.420468223295425
Validation loss: 2.5687503445532784

Epoch: 5| Step: 8
Training loss: 3.2289725624731007
Validation loss: 2.5638319446122106

Epoch: 5| Step: 9
Training loss: 2.8570522191793546
Validation loss: 2.557523381379913

Epoch: 5| Step: 10
Training loss: 3.2478282714977613
Validation loss: 2.5583089044170246

Epoch: 120| Step: 0
Training loss: 3.0183437919189755
Validation loss: 2.5595247557642447

Epoch: 5| Step: 1
Training loss: 2.590217574859982
Validation loss: 2.5576490140811594

Epoch: 5| Step: 2
Training loss: 2.648005897665227
Validation loss: 2.5567237867239165

Epoch: 5| Step: 3
Training loss: 2.8985031408398534
Validation loss: 2.557014604872748

Epoch: 5| Step: 4
Training loss: 1.9486436014449309
Validation loss: 2.5596730836109844

Epoch: 5| Step: 5
Training loss: 3.5612632880292687
Validation loss: 2.5590305136249594

Epoch: 5| Step: 6
Training loss: 3.117047070086332
Validation loss: 2.5652627095886413

Epoch: 5| Step: 7
Training loss: 2.963993156559054
Validation loss: 2.5800104132583077

Epoch: 5| Step: 8
Training loss: 3.125572152212539
Validation loss: 2.5850157768466406

Epoch: 5| Step: 9
Training loss: 2.634206250126741
Validation loss: 2.5991679049614467

Epoch: 5| Step: 10
Training loss: 3.169803187039831
Validation loss: 2.630719414936827

Epoch: 121| Step: 0
Training loss: 3.1420576329569836
Validation loss: 2.6564739106380104

Epoch: 5| Step: 1
Training loss: 2.300237257786282
Validation loss: 2.6353407056092255

Epoch: 5| Step: 2
Training loss: 2.8395075749912375
Validation loss: 2.6157982450011743

Epoch: 5| Step: 3
Training loss: 2.6628856576630087
Validation loss: 2.5918041510771594

Epoch: 5| Step: 4
Training loss: 2.4196473736436808
Validation loss: 2.592804377713656

Epoch: 5| Step: 5
Training loss: 3.0281686754098422
Validation loss: 2.5876931305325037

Epoch: 5| Step: 6
Training loss: 2.8377111684054404
Validation loss: 2.5720542165356792

Epoch: 5| Step: 7
Training loss: 3.1035572622973926
Validation loss: 2.5636312207330487

Epoch: 5| Step: 8
Training loss: 3.4382575847536803
Validation loss: 2.5593535852385885

Epoch: 5| Step: 9
Training loss: 3.18309045101391
Validation loss: 2.5556868312421015

Epoch: 5| Step: 10
Training loss: 2.8018413755946536
Validation loss: 2.5565568318336953

Epoch: 122| Step: 0
Training loss: 3.1618032419175908
Validation loss: 2.5588892366779126

Epoch: 5| Step: 1
Training loss: 2.616795388070558
Validation loss: 2.568831386743435

Epoch: 5| Step: 2
Training loss: 3.1382619593670555
Validation loss: 2.5605788353700416

Epoch: 5| Step: 3
Training loss: 2.642343086340492
Validation loss: 2.564575263381435

Epoch: 5| Step: 4
Training loss: 3.532992582864585
Validation loss: 2.565327109532444

Epoch: 5| Step: 5
Training loss: 3.0366736587069845
Validation loss: 2.569314179744005

Epoch: 5| Step: 6
Training loss: 2.8036747115932927
Validation loss: 2.5700853820132363

Epoch: 5| Step: 7
Training loss: 2.7669387541880086
Validation loss: 2.5813758994789393

Epoch: 5| Step: 8
Training loss: 2.6571531667670487
Validation loss: 2.584646275052902

Epoch: 5| Step: 9
Training loss: 2.785062255985377
Validation loss: 2.6147309304806847

Epoch: 5| Step: 10
Training loss: 2.548046848800638
Validation loss: 2.6223572574830776

Epoch: 123| Step: 0
Training loss: 2.822627419906004
Validation loss: 2.623931701564348

Epoch: 5| Step: 1
Training loss: 3.477483254563076
Validation loss: 2.5872822465858527

Epoch: 5| Step: 2
Training loss: 3.511403172520956
Validation loss: 2.5580892732310336

Epoch: 5| Step: 3
Training loss: 2.9623058851039317
Validation loss: 2.545134816980248

Epoch: 5| Step: 4
Training loss: 2.761845651864731
Validation loss: 2.5468815689510524

Epoch: 5| Step: 5
Training loss: 3.2223992262561856
Validation loss: 2.5491214610904582

Epoch: 5| Step: 6
Training loss: 2.7673226011737926
Validation loss: 2.5531682279897048

Epoch: 5| Step: 7
Training loss: 2.8319622162922364
Validation loss: 2.558624486324504

Epoch: 5| Step: 8
Training loss: 2.370473161456546
Validation loss: 2.5594003029366266

Epoch: 5| Step: 9
Training loss: 2.8286218364842357
Validation loss: 2.554799751564452

Epoch: 5| Step: 10
Training loss: 2.265573540464895
Validation loss: 2.5566648751001075

Epoch: 124| Step: 0
Training loss: 2.678695628601898
Validation loss: 2.556097774273962

Epoch: 5| Step: 1
Training loss: 2.8191336495449417
Validation loss: 2.5602404428887073

Epoch: 5| Step: 2
Training loss: 3.068515397250609
Validation loss: 2.5697689749046986

Epoch: 5| Step: 3
Training loss: 2.5292257055925877
Validation loss: 2.5663144803571014

Epoch: 5| Step: 4
Training loss: 2.835311946761629
Validation loss: 2.5807787271641507

Epoch: 5| Step: 5
Training loss: 2.749347435946822
Validation loss: 2.590587017277109

Epoch: 5| Step: 6
Training loss: 2.588577720549632
Validation loss: 2.601093395169418

Epoch: 5| Step: 7
Training loss: 3.3069892965350616
Validation loss: 2.6013630190002797

Epoch: 5| Step: 8
Training loss: 2.885854878298816
Validation loss: 2.6041394973486103

Epoch: 5| Step: 9
Training loss: 3.241399977303975
Validation loss: 2.6122844476215716

Epoch: 5| Step: 10
Training loss: 3.2152657029154277
Validation loss: 2.601882250252438

Epoch: 125| Step: 0
Training loss: 3.313575713914022
Validation loss: 2.565850914938322

Epoch: 5| Step: 1
Training loss: 2.307646632965173
Validation loss: 2.5567603511159804

Epoch: 5| Step: 2
Training loss: 3.058150024186938
Validation loss: 2.547987143940283

Epoch: 5| Step: 3
Training loss: 3.096000238354499
Validation loss: 2.546114925609393

Epoch: 5| Step: 4
Training loss: 2.6258534451893527
Validation loss: 2.5417933628318083

Epoch: 5| Step: 5
Training loss: 3.185378172504432
Validation loss: 2.5425015642847364

Epoch: 5| Step: 6
Training loss: 2.7725213055355296
Validation loss: 2.544461603952104

Epoch: 5| Step: 7
Training loss: 2.981666334339491
Validation loss: 2.5384395156292463

Epoch: 5| Step: 8
Training loss: 3.1396993155383823
Validation loss: 2.5397378669181996

Epoch: 5| Step: 9
Training loss: 2.7343361116096245
Validation loss: 2.5385200601331737

Epoch: 5| Step: 10
Training loss: 2.3088858947249036
Validation loss: 2.5348380548143417

Epoch: 126| Step: 0
Training loss: 2.7361076750844
Validation loss: 2.5407985056529587

Epoch: 5| Step: 1
Training loss: 3.460002971052537
Validation loss: 2.5364388985255775

Epoch: 5| Step: 2
Training loss: 2.7231986820390337
Validation loss: 2.533743478039644

Epoch: 5| Step: 3
Training loss: 3.3230200644801995
Validation loss: 2.5388953470216613

Epoch: 5| Step: 4
Training loss: 3.0455277031712735
Validation loss: 2.5371917986823007

Epoch: 5| Step: 5
Training loss: 2.575623194271085
Validation loss: 2.54148142553314

Epoch: 5| Step: 6
Training loss: 2.5608540342739525
Validation loss: 2.5367655436126597

Epoch: 5| Step: 7
Training loss: 2.921589556944234
Validation loss: 2.5540058598528517

Epoch: 5| Step: 8
Training loss: 2.9017887123846977
Validation loss: 2.5408410645005564

Epoch: 5| Step: 9
Training loss: 2.7058141485140528
Validation loss: 2.5397252229981504

Epoch: 5| Step: 10
Training loss: 2.720039938605432
Validation loss: 2.546212574301374

Epoch: 127| Step: 0
Training loss: 2.758438774083527
Validation loss: 2.5418485313830317

Epoch: 5| Step: 1
Training loss: 2.6666804452381205
Validation loss: 2.5410590539071958

Epoch: 5| Step: 2
Training loss: 2.7487196109023437
Validation loss: 2.5551716822121593

Epoch: 5| Step: 3
Training loss: 3.1519878049411227
Validation loss: 2.5555394758307433

Epoch: 5| Step: 4
Training loss: 2.9472310018054118
Validation loss: 2.5599080645040004

Epoch: 5| Step: 5
Training loss: 2.8754771292792958
Validation loss: 2.5644061934443454

Epoch: 5| Step: 6
Training loss: 2.1910591598595404
Validation loss: 2.5538968096968966

Epoch: 5| Step: 7
Training loss: 2.508675400062435
Validation loss: 2.536518402880804

Epoch: 5| Step: 8
Training loss: 3.0779685353436332
Validation loss: 2.5345636289433053

Epoch: 5| Step: 9
Training loss: 3.2258487678644086
Validation loss: 2.5340921687547047

Epoch: 5| Step: 10
Training loss: 3.506290640909951
Validation loss: 2.531696876164122

Epoch: 128| Step: 0
Training loss: 2.5349072068064227
Validation loss: 2.53380887638044

Epoch: 5| Step: 1
Training loss: 3.252202094917615
Validation loss: 2.5490487140555977

Epoch: 5| Step: 2
Training loss: 2.891972737966019
Validation loss: 2.5432012592921764

Epoch: 5| Step: 3
Training loss: 2.7392492827964348
Validation loss: 2.5479661476517688

Epoch: 5| Step: 4
Training loss: 2.821432467176842
Validation loss: 2.563972152315312

Epoch: 5| Step: 5
Training loss: 2.4006080373786967
Validation loss: 2.56932686164656

Epoch: 5| Step: 6
Training loss: 3.1773514097753135
Validation loss: 2.5810197932885734

Epoch: 5| Step: 7
Training loss: 3.2319041964145914
Validation loss: 2.5712641816095076

Epoch: 5| Step: 8
Training loss: 2.603364429247459
Validation loss: 2.564356551787782

Epoch: 5| Step: 9
Training loss: 3.1295883063957946
Validation loss: 2.543929096871175

Epoch: 5| Step: 10
Training loss: 2.7881284373129014
Validation loss: 2.5358650575106463

Epoch: 129| Step: 0
Training loss: 2.5933599523470985
Validation loss: 2.5333611968774403

Epoch: 5| Step: 1
Training loss: 3.1263159460702816
Validation loss: 2.5292577951699746

Epoch: 5| Step: 2
Training loss: 3.6272071170153164
Validation loss: 2.527260342735104

Epoch: 5| Step: 3
Training loss: 2.7210061369423317
Validation loss: 2.5286249920899766

Epoch: 5| Step: 4
Training loss: 2.67427802637297
Validation loss: 2.5292487123374428

Epoch: 5| Step: 5
Training loss: 2.8752897365362613
Validation loss: 2.525013337028513

Epoch: 5| Step: 6
Training loss: 2.5490543893523947
Validation loss: 2.5257846323882727

Epoch: 5| Step: 7
Training loss: 3.0103419381516656
Validation loss: 2.521626993233534

Epoch: 5| Step: 8
Training loss: 3.264513036331741
Validation loss: 2.5255943809811843

Epoch: 5| Step: 9
Training loss: 2.528581507788175
Validation loss: 2.540717730672465

Epoch: 5| Step: 10
Training loss: 2.5299423042322804
Validation loss: 2.5530362163264884

Epoch: 130| Step: 0
Training loss: 3.0481545915823514
Validation loss: 2.5730569685061035

Epoch: 5| Step: 1
Training loss: 2.6496360564881436
Validation loss: 2.6147265135019877

Epoch: 5| Step: 2
Training loss: 2.862321346654864
Validation loss: 2.643423854500355

Epoch: 5| Step: 3
Training loss: 3.31004933807389
Validation loss: 2.632701000054323

Epoch: 5| Step: 4
Training loss: 2.8172981870956093
Validation loss: 2.6151161956570905

Epoch: 5| Step: 5
Training loss: 3.222065671501325
Validation loss: 2.566577754247256

Epoch: 5| Step: 6
Training loss: 2.7177562432082754
Validation loss: 2.550252173523926

Epoch: 5| Step: 7
Training loss: 2.699746021051987
Validation loss: 2.5347872636711597

Epoch: 5| Step: 8
Training loss: 3.0834077533985447
Validation loss: 2.5252767199848494

Epoch: 5| Step: 9
Training loss: 2.8503900495280012
Validation loss: 2.527831131177748

Epoch: 5| Step: 10
Training loss: 2.3241052936462645
Validation loss: 2.5231298804391464

Epoch: 131| Step: 0
Training loss: 2.9443995834227987
Validation loss: 2.5255902628620532

Epoch: 5| Step: 1
Training loss: 3.128520203585971
Validation loss: 2.5242067093794223

Epoch: 5| Step: 2
Training loss: 3.033305935858217
Validation loss: 2.5252774955913915

Epoch: 5| Step: 3
Training loss: 2.5169055593760596
Validation loss: 2.5264461148303163

Epoch: 5| Step: 4
Training loss: 3.2980529705579995
Validation loss: 2.524205350476413

Epoch: 5| Step: 5
Training loss: 2.6393330138956976
Validation loss: 2.5277881129283166

Epoch: 5| Step: 6
Training loss: 3.038539027458216
Validation loss: 2.542547496618569

Epoch: 5| Step: 7
Training loss: 2.81292204339379
Validation loss: 2.5550257640206118

Epoch: 5| Step: 8
Training loss: 3.252377154224324
Validation loss: 2.5692075564926307

Epoch: 5| Step: 9
Training loss: 2.5406232057309355
Validation loss: 2.580344968173811

Epoch: 5| Step: 10
Training loss: 2.4893217920377357
Validation loss: 2.566915343249933

Epoch: 132| Step: 0
Training loss: 3.1849333957672696
Validation loss: 2.5450676734205158

Epoch: 5| Step: 1
Training loss: 2.9507774427741356
Validation loss: 2.535349438218252

Epoch: 5| Step: 2
Training loss: 2.75858302604516
Validation loss: 2.5227581331195803

Epoch: 5| Step: 3
Training loss: 3.052825438251114
Validation loss: 2.523883258654991

Epoch: 5| Step: 4
Training loss: 2.8996679773669407
Validation loss: 2.523360760417631

Epoch: 5| Step: 5
Training loss: 3.012873209395164
Validation loss: 2.524350810899379

Epoch: 5| Step: 6
Training loss: 2.4104296561649203
Validation loss: 2.526413908361205

Epoch: 5| Step: 7
Training loss: 2.677350418086969
Validation loss: 2.5255329272271037

Epoch: 5| Step: 8
Training loss: 3.0245996257551453
Validation loss: 2.523484486412594

Epoch: 5| Step: 9
Training loss: 3.0634220837122776
Validation loss: 2.527401300168664

Epoch: 5| Step: 10
Training loss: 2.4051507197556687
Validation loss: 2.539701716606509

Epoch: 133| Step: 0
Training loss: 2.465730583144636
Validation loss: 2.5527765771895297

Epoch: 5| Step: 1
Training loss: 2.683129060761271
Validation loss: 2.5808777403430527

Epoch: 5| Step: 2
Training loss: 3.3808410397213677
Validation loss: 2.583114181720633

Epoch: 5| Step: 3
Training loss: 3.2107125085122297
Validation loss: 2.5452051436737713

Epoch: 5| Step: 4
Training loss: 2.1080861993425795
Validation loss: 2.5295709165451807

Epoch: 5| Step: 5
Training loss: 3.1016561268240137
Validation loss: 2.5290637300772674

Epoch: 5| Step: 6
Training loss: 3.60194934414114
Validation loss: 2.5222748130306463

Epoch: 5| Step: 7
Training loss: 3.172579682343741
Validation loss: 2.5181462560077397

Epoch: 5| Step: 8
Training loss: 2.9750732541081355
Validation loss: 2.526524801242735

Epoch: 5| Step: 9
Training loss: 2.5628349271401643
Validation loss: 2.519658763800624

Epoch: 5| Step: 10
Training loss: 1.727076734369952
Validation loss: 2.516713078225792

Epoch: 134| Step: 0
Training loss: 3.0658131019676147
Validation loss: 2.518239953043565

Epoch: 5| Step: 1
Training loss: 2.6850484267543693
Validation loss: 2.522440546884949

Epoch: 5| Step: 2
Training loss: 2.644544412644957
Validation loss: 2.5392101755416134

Epoch: 5| Step: 3
Training loss: 3.710713012330041
Validation loss: 2.5612910520506005

Epoch: 5| Step: 4
Training loss: 2.6427508944065226
Validation loss: 2.564242009215812

Epoch: 5| Step: 5
Training loss: 2.535090323650454
Validation loss: 2.6003530944881157

Epoch: 5| Step: 6
Training loss: 2.621056091674798
Validation loss: 2.5961549878983416

Epoch: 5| Step: 7
Training loss: 3.159607564967461
Validation loss: 2.60485044563271

Epoch: 5| Step: 8
Training loss: 3.0158906335403746
Validation loss: 2.5767550769353873

Epoch: 5| Step: 9
Training loss: 2.8711326129385073
Validation loss: 2.5652619300817348

Epoch: 5| Step: 10
Training loss: 2.311316006647873
Validation loss: 2.5413985236176533

Epoch: 135| Step: 0
Training loss: 2.239896980028353
Validation loss: 2.540523455188527

Epoch: 5| Step: 1
Training loss: 2.921731710745392
Validation loss: 2.5290121387237456

Epoch: 5| Step: 2
Training loss: 2.6307034973773233
Validation loss: 2.5255952803279738

Epoch: 5| Step: 3
Training loss: 3.1123238387295147
Validation loss: 2.521325668330251

Epoch: 5| Step: 4
Training loss: 2.57128164461995
Validation loss: 2.5274470819256374

Epoch: 5| Step: 5
Training loss: 2.9212084331174997
Validation loss: 2.5122853947370194

Epoch: 5| Step: 6
Training loss: 2.964544268574331
Validation loss: 2.5270797729331846

Epoch: 5| Step: 7
Training loss: 2.877163114737528
Validation loss: 2.51442544635183

Epoch: 5| Step: 8
Training loss: 3.3507043411205357
Validation loss: 2.5255088542772843

Epoch: 5| Step: 9
Training loss: 2.4069367456750217
Validation loss: 2.5266192270805985

Epoch: 5| Step: 10
Training loss: 3.385162735243254
Validation loss: 2.5363231093190395

Epoch: 136| Step: 0
Training loss: 2.4832044998988447
Validation loss: 2.529295040422462

Epoch: 5| Step: 1
Training loss: 3.010875380963547
Validation loss: 2.5298210829467953

Epoch: 5| Step: 2
Training loss: 3.1272474218356834
Validation loss: 2.5225311569720197

Epoch: 5| Step: 3
Training loss: 2.9540181096166895
Validation loss: 2.521287803053522

Epoch: 5| Step: 4
Training loss: 2.6421098315318843
Validation loss: 2.5241920701570733

Epoch: 5| Step: 5
Training loss: 3.421137342678347
Validation loss: 2.5244724045346136

Epoch: 5| Step: 6
Training loss: 2.777423841391995
Validation loss: 2.52637989421479

Epoch: 5| Step: 7
Training loss: 2.2130113991272697
Validation loss: 2.522279383778224

Epoch: 5| Step: 8
Training loss: 2.5510695850926175
Validation loss: 2.523726480519037

Epoch: 5| Step: 9
Training loss: 3.199565714930724
Validation loss: 2.5242497521013325

Epoch: 5| Step: 10
Training loss: 2.8964687354706733
Validation loss: 2.5315928918787356

Epoch: 137| Step: 0
Training loss: 2.90379016101273
Validation loss: 2.541703303769176

Epoch: 5| Step: 1
Training loss: 3.3274383552968763
Validation loss: 2.5696048160677796

Epoch: 5| Step: 2
Training loss: 2.6016140952736087
Validation loss: 2.606607537720011

Epoch: 5| Step: 3
Training loss: 2.7999511510130106
Validation loss: 2.6405284504970674

Epoch: 5| Step: 4
Training loss: 2.799233406575762
Validation loss: 2.599842696799231

Epoch: 5| Step: 5
Training loss: 3.078399800848211
Validation loss: 2.5883656565707143

Epoch: 5| Step: 6
Training loss: 2.499724659062327
Validation loss: 2.560129609492997

Epoch: 5| Step: 7
Training loss: 3.1133250540950677
Validation loss: 2.520187524704105

Epoch: 5| Step: 8
Training loss: 2.800150567502325
Validation loss: 2.512866272663775

Epoch: 5| Step: 9
Training loss: 2.5815591770137343
Validation loss: 2.51593914757036

Epoch: 5| Step: 10
Training loss: 2.97337045999906
Validation loss: 2.517042234311937

Epoch: 138| Step: 0
Training loss: 2.5571110513357698
Validation loss: 2.520373847053626

Epoch: 5| Step: 1
Training loss: 2.6945674142819036
Validation loss: 2.5312556007573455

Epoch: 5| Step: 2
Training loss: 2.745292970070064
Validation loss: 2.5297398449680566

Epoch: 5| Step: 3
Training loss: 2.8961873741442115
Validation loss: 2.5278384635880045

Epoch: 5| Step: 4
Training loss: 3.5959956574885847
Validation loss: 2.539932952425827

Epoch: 5| Step: 5
Training loss: 2.8426144187532034
Validation loss: 2.5303353364010936

Epoch: 5| Step: 6
Training loss: 2.764124748947953
Validation loss: 2.5333257196060472

Epoch: 5| Step: 7
Training loss: 3.100676518115864
Validation loss: 2.529219745576973

Epoch: 5| Step: 8
Training loss: 2.065433381350125
Validation loss: 2.5350503729227767

Epoch: 5| Step: 9
Training loss: 3.506688131066059
Validation loss: 2.5434443014967423

Epoch: 5| Step: 10
Training loss: 2.608769786341106
Validation loss: 2.568994503282657

Epoch: 139| Step: 0
Training loss: 2.9439681245695315
Validation loss: 2.6030963353632184

Epoch: 5| Step: 1
Training loss: 2.7649876781554674
Validation loss: 2.625857481241807

Epoch: 5| Step: 2
Training loss: 2.9877313245014565
Validation loss: 2.6385954680970523

Epoch: 5| Step: 3
Training loss: 3.048371871640673
Validation loss: 2.601400307058431

Epoch: 5| Step: 4
Training loss: 2.5932474223945743
Validation loss: 2.5828469040428357

Epoch: 5| Step: 5
Training loss: 2.7124300758736446
Validation loss: 2.6004776852659948

Epoch: 5| Step: 6
Training loss: 3.2850649500076923
Validation loss: 2.611698046231625

Epoch: 5| Step: 7
Training loss: 2.847662613054448
Validation loss: 2.615620855869486

Epoch: 5| Step: 8
Training loss: 3.005775455446067
Validation loss: 2.6288408832840124

Epoch: 5| Step: 9
Training loss: 2.6010649150827367
Validation loss: 2.64042210089142

Epoch: 5| Step: 10
Training loss: 3.006981831573413
Validation loss: 2.6401681589187933

Epoch: 140| Step: 0
Training loss: 2.587465140434999
Validation loss: 2.6540779570944584

Epoch: 5| Step: 1
Training loss: 2.4968349448799927
Validation loss: 2.688193248747175

Epoch: 5| Step: 2
Training loss: 2.75700016323085
Validation loss: 2.691282359412032

Epoch: 5| Step: 3
Training loss: 2.751803240406838
Validation loss: 2.6416493081002277

Epoch: 5| Step: 4
Training loss: 3.1110924046574673
Validation loss: 2.6035619529935636

Epoch: 5| Step: 5
Training loss: 2.8341817333610217
Validation loss: 2.5782446939445904

Epoch: 5| Step: 6
Training loss: 2.9864675166229815
Validation loss: 2.5654592237178266

Epoch: 5| Step: 7
Training loss: 2.8797589595909305
Validation loss: 2.561157925583299

Epoch: 5| Step: 8
Training loss: 3.1281670353186852
Validation loss: 2.562323628460421

Epoch: 5| Step: 9
Training loss: 3.164897893189669
Validation loss: 2.5622688587387787

Epoch: 5| Step: 10
Training loss: 3.132413539073816
Validation loss: 2.547767998479983

Epoch: 141| Step: 0
Training loss: 3.035632711003708
Validation loss: 2.546170904182221

Epoch: 5| Step: 1
Training loss: 3.109232530253255
Validation loss: 2.5623242337713132

Epoch: 5| Step: 2
Training loss: 2.4872364383795182
Validation loss: 2.548069843567148

Epoch: 5| Step: 3
Training loss: 3.2310688609958578
Validation loss: 2.5322495470425626

Epoch: 5| Step: 4
Training loss: 2.1810169609211396
Validation loss: 2.5242105992098516

Epoch: 5| Step: 5
Training loss: 2.7014615447650256
Validation loss: 2.5181667903276446

Epoch: 5| Step: 6
Training loss: 3.0848763874829417
Validation loss: 2.525069150380872

Epoch: 5| Step: 7
Training loss: 2.8244605165363272
Validation loss: 2.5243608253593552

Epoch: 5| Step: 8
Training loss: 2.776440007948455
Validation loss: 2.530086937313348

Epoch: 5| Step: 9
Training loss: 3.3200123370757164
Validation loss: 2.5343591667643603

Epoch: 5| Step: 10
Training loss: 2.9048392861010695
Validation loss: 2.5539009765307155

Epoch: 142| Step: 0
Training loss: 2.9516925869935697
Validation loss: 2.596326003227014

Epoch: 5| Step: 1
Training loss: 2.9019791591008985
Validation loss: 2.6292504063074955

Epoch: 5| Step: 2
Training loss: 3.0099395761096357
Validation loss: 2.6428018407689113

Epoch: 5| Step: 3
Training loss: 3.1317729033647237
Validation loss: 2.694477995402243

Epoch: 5| Step: 4
Training loss: 2.3589106222752605
Validation loss: 2.6488533880470264

Epoch: 5| Step: 5
Training loss: 2.965173594907558
Validation loss: 2.595526600646259

Epoch: 5| Step: 6
Training loss: 2.523459608612999
Validation loss: 2.5482909187801464

Epoch: 5| Step: 7
Training loss: 2.645572248978782
Validation loss: 2.5461939053185056

Epoch: 5| Step: 8
Training loss: 3.2293530974356894
Validation loss: 2.555447319959829

Epoch: 5| Step: 9
Training loss: 3.09095005528441
Validation loss: 2.5422079060412406

Epoch: 5| Step: 10
Training loss: 2.9407334083738323
Validation loss: 2.557732382570554

Epoch: 143| Step: 0
Training loss: 2.961056025002419
Validation loss: 2.549050841161938

Epoch: 5| Step: 1
Training loss: 2.994663260098176
Validation loss: 2.5444079923137495

Epoch: 5| Step: 2
Training loss: 2.4941472208029953
Validation loss: 2.56108666758449

Epoch: 5| Step: 3
Training loss: 2.9768518021933303
Validation loss: 2.5675712724756177

Epoch: 5| Step: 4
Training loss: 3.177216040335906
Validation loss: 2.568237398113733

Epoch: 5| Step: 5
Training loss: 2.811761208033751
Validation loss: 2.559496331972779

Epoch: 5| Step: 6
Training loss: 2.6805402549961426
Validation loss: 2.546707052157476

Epoch: 5| Step: 7
Training loss: 2.659220840522316
Validation loss: 2.5350797974019303

Epoch: 5| Step: 8
Training loss: 3.129910540048788
Validation loss: 2.5360824961121855

Epoch: 5| Step: 9
Training loss: 2.7958727697859076
Validation loss: 2.5399856239734317

Epoch: 5| Step: 10
Training loss: 2.9493663624586284
Validation loss: 2.5362541798973557

Epoch: 144| Step: 0
Training loss: 2.204352719892234
Validation loss: 2.532115706710062

Epoch: 5| Step: 1
Training loss: 2.6182186998914787
Validation loss: 2.527701674631232

Epoch: 5| Step: 2
Training loss: 2.838068222086166
Validation loss: 2.5378855097759825

Epoch: 5| Step: 3
Training loss: 2.7892441463356037
Validation loss: 2.5495193868595574

Epoch: 5| Step: 4
Training loss: 2.849007242865041
Validation loss: 2.5326155657137246

Epoch: 5| Step: 5
Training loss: 3.3110871090826204
Validation loss: 2.52110804504464

Epoch: 5| Step: 6
Training loss: 3.195002981551664
Validation loss: 2.5189260394551853

Epoch: 5| Step: 7
Training loss: 3.173621687997842
Validation loss: 2.5119598792960063

Epoch: 5| Step: 8
Training loss: 2.8369323834929063
Validation loss: 2.502552483991449

Epoch: 5| Step: 9
Training loss: 2.2479187558517673
Validation loss: 2.492884378502424

Epoch: 5| Step: 10
Training loss: 3.1283985730947252
Validation loss: 2.491395928310271

Epoch: 145| Step: 0
Training loss: 3.0863454042121665
Validation loss: 2.487711851024103

Epoch: 5| Step: 1
Training loss: 2.50323029676459
Validation loss: 2.4872031129654

Epoch: 5| Step: 2
Training loss: 3.0540794294179463
Validation loss: 2.4818671641800916

Epoch: 5| Step: 3
Training loss: 2.5384970636927493
Validation loss: 2.4865999707231743

Epoch: 5| Step: 4
Training loss: 2.530324225024599
Validation loss: 2.4905366514421696

Epoch: 5| Step: 5
Training loss: 3.083243514806159
Validation loss: 2.4934788571342317

Epoch: 5| Step: 6
Training loss: 3.010762459893637
Validation loss: 2.5011658493240283

Epoch: 5| Step: 7
Training loss: 2.8066655146610797
Validation loss: 2.515836786908934

Epoch: 5| Step: 8
Training loss: 3.3411765489878484
Validation loss: 2.52993593246934

Epoch: 5| Step: 9
Training loss: 2.480670205893995
Validation loss: 2.5329196699333107

Epoch: 5| Step: 10
Training loss: 2.6662216609945695
Validation loss: 2.5372543320706558

Epoch: 146| Step: 0
Training loss: 3.2833958466544413
Validation loss: 2.53422560982066

Epoch: 5| Step: 1
Training loss: 2.6973127378952486
Validation loss: 2.5497943647675125

Epoch: 5| Step: 2
Training loss: 2.7252964698434665
Validation loss: 2.558372351586139

Epoch: 5| Step: 3
Training loss: 3.2282522732219965
Validation loss: 2.5814464861883772

Epoch: 5| Step: 4
Training loss: 3.1193413428002446
Validation loss: 2.533057701293457

Epoch: 5| Step: 5
Training loss: 2.613570079038332
Validation loss: 2.5416610720401587

Epoch: 5| Step: 6
Training loss: 2.8574188712176625
Validation loss: 2.550224564187123

Epoch: 5| Step: 7
Training loss: 2.6209654002025355
Validation loss: 2.53417890450179

Epoch: 5| Step: 8
Training loss: 3.0129373066808505
Validation loss: 2.5504943990893105

Epoch: 5| Step: 9
Training loss: 2.4850983916055904
Validation loss: 2.5559053739651496

Epoch: 5| Step: 10
Training loss: 2.4502488301872494
Validation loss: 2.552623560175671

Epoch: 147| Step: 0
Training loss: 3.0441519281918343
Validation loss: 2.54454926324752

Epoch: 5| Step: 1
Training loss: 2.479861784436719
Validation loss: 2.55858767503338

Epoch: 5| Step: 2
Training loss: 2.8417723769347836
Validation loss: 2.5538871750596868

Epoch: 5| Step: 3
Training loss: 2.705157271236107
Validation loss: 2.5573288478111165

Epoch: 5| Step: 4
Training loss: 2.7338580705572797
Validation loss: 2.5670229115890377

Epoch: 5| Step: 5
Training loss: 3.0701143234786086
Validation loss: 2.56871200468353

Epoch: 5| Step: 6
Training loss: 2.9277780235655566
Validation loss: 2.565639910175545

Epoch: 5| Step: 7
Training loss: 3.0373236773769743
Validation loss: 2.5787919629533227

Epoch: 5| Step: 8
Training loss: 2.3200656746743715
Validation loss: 2.566119345453869

Epoch: 5| Step: 9
Training loss: 3.3392214903691495
Validation loss: 2.5683739920535955

Epoch: 5| Step: 10
Training loss: 2.8041357491212
Validation loss: 2.5787876673371692

Epoch: 148| Step: 0
Training loss: 2.8502890055503376
Validation loss: 2.589095529417169

Epoch: 5| Step: 1
Training loss: 3.379187070610136
Validation loss: 2.573434288829367

Epoch: 5| Step: 2
Training loss: 2.47003024742973
Validation loss: 2.5566969983072783

Epoch: 5| Step: 3
Training loss: 2.858363571970912
Validation loss: 2.5411037693892444

Epoch: 5| Step: 4
Training loss: 3.156503950421396
Validation loss: 2.5664145590228937

Epoch: 5| Step: 5
Training loss: 2.5268380604019907
Validation loss: 2.5861234043851113

Epoch: 5| Step: 6
Training loss: 3.3263327200723656
Validation loss: 2.6457077566946334

Epoch: 5| Step: 7
Training loss: 2.7740412525060743
Validation loss: 2.6707666940095933

Epoch: 5| Step: 8
Training loss: 2.5065143588476846
Validation loss: 2.635934685334438

Epoch: 5| Step: 9
Training loss: 2.495626343139929
Validation loss: 2.582947477593683

Epoch: 5| Step: 10
Training loss: 2.80951880234433
Validation loss: 2.5569588842507067

Epoch: 149| Step: 0
Training loss: 3.130163580669235
Validation loss: 2.531419433124838

Epoch: 5| Step: 1
Training loss: 2.8192318354362516
Validation loss: 2.5110887541701175

Epoch: 5| Step: 2
Training loss: 2.9452487119045796
Validation loss: 2.5088631281360714

Epoch: 5| Step: 3
Training loss: 3.3473955762898773
Validation loss: 2.5183656784899977

Epoch: 5| Step: 4
Training loss: 2.5578083725734584
Validation loss: 2.5084251412217773

Epoch: 5| Step: 5
Training loss: 2.517202605303403
Validation loss: 2.5082392283025428

Epoch: 5| Step: 6
Training loss: 3.0292675968725367
Validation loss: 2.5107297600402827

Epoch: 5| Step: 7
Training loss: 2.303776033847396
Validation loss: 2.5275267372645525

Epoch: 5| Step: 8
Training loss: 2.704051746420648
Validation loss: 2.561664786337082

Epoch: 5| Step: 9
Training loss: 2.937546262985517
Validation loss: 2.609762958612228

Epoch: 5| Step: 10
Training loss: 3.2873224652874704
Validation loss: 2.5823893987553674

Epoch: 150| Step: 0
Training loss: 3.3044424845451603
Validation loss: 2.5798778661930033

Epoch: 5| Step: 1
Training loss: 2.5994071394558516
Validation loss: 2.5841183463712367

Epoch: 5| Step: 2
Training loss: 2.3925090670837346
Validation loss: 2.6057236528569576

Epoch: 5| Step: 3
Training loss: 3.1332505221955786
Validation loss: 2.643407949433585

Epoch: 5| Step: 4
Training loss: 2.7192228059607455
Validation loss: 2.6240560462414475

Epoch: 5| Step: 5
Training loss: 2.860234199218211
Validation loss: 2.591308363732442

Epoch: 5| Step: 6
Training loss: 3.232684002069916
Validation loss: 2.5743281144069767

Epoch: 5| Step: 7
Training loss: 3.0355083011016673
Validation loss: 2.601446186887315

Epoch: 5| Step: 8
Training loss: 2.8550407203669814
Validation loss: 2.560240581071978

Epoch: 5| Step: 9
Training loss: 2.308679466140844
Validation loss: 2.5363399406139404

Epoch: 5| Step: 10
Training loss: 2.9552175384331507
Validation loss: 2.5174288057403307

Epoch: 151| Step: 0
Training loss: 2.13229352624536
Validation loss: 2.5198547842372516

Epoch: 5| Step: 1
Training loss: 2.4366432053479756
Validation loss: 2.5202954039625665

Epoch: 5| Step: 2
Training loss: 2.7408241295324114
Validation loss: 2.511628205078063

Epoch: 5| Step: 3
Training loss: 2.9492239238365214
Validation loss: 2.516828129665937

Epoch: 5| Step: 4
Training loss: 2.4702906569613634
Validation loss: 2.5205133822032715

Epoch: 5| Step: 5
Training loss: 2.8828743615271524
Validation loss: 2.5322735245282812

Epoch: 5| Step: 6
Training loss: 3.09780802601453
Validation loss: 2.5148835681581336

Epoch: 5| Step: 7
Training loss: 3.030214113029108
Validation loss: 2.5037591646013717

Epoch: 5| Step: 8
Training loss: 3.1750882414322517
Validation loss: 2.493272899199403

Epoch: 5| Step: 9
Training loss: 3.22940876371121
Validation loss: 2.4968570765107225

Epoch: 5| Step: 10
Training loss: 3.0398478535173727
Validation loss: 2.504104702379976

Epoch: 152| Step: 0
Training loss: 2.9806434510152466
Validation loss: 2.5127357313960226

Epoch: 5| Step: 1
Training loss: 3.205348885006026
Validation loss: 2.5067996409914044

Epoch: 5| Step: 2
Training loss: 2.922527220038793
Validation loss: 2.510973858354554

Epoch: 5| Step: 3
Training loss: 2.844210409265259
Validation loss: 2.519741128528488

Epoch: 5| Step: 4
Training loss: 2.533905331969661
Validation loss: 2.5382283905322374

Epoch: 5| Step: 5
Training loss: 2.727561090136616
Validation loss: 2.5410171282664025

Epoch: 5| Step: 6
Training loss: 2.8449758046601317
Validation loss: 2.5277451527704176

Epoch: 5| Step: 7
Training loss: 2.639007705110589
Validation loss: 2.5438040090334377

Epoch: 5| Step: 8
Training loss: 2.847596302631184
Validation loss: 2.54620160269104

Epoch: 5| Step: 9
Training loss: 3.109179466655404
Validation loss: 2.556443355767328

Epoch: 5| Step: 10
Training loss: 2.4164308454838634
Validation loss: 2.526090365770194

Epoch: 153| Step: 0
Training loss: 2.5025676892679
Validation loss: 2.522324211629646

Epoch: 5| Step: 1
Training loss: 3.0633774103833935
Validation loss: 2.5049826354670084

Epoch: 5| Step: 2
Training loss: 2.5185593260729386
Validation loss: 2.501015395414028

Epoch: 5| Step: 3
Training loss: 2.6160742370501118
Validation loss: 2.4947886612859254

Epoch: 5| Step: 4
Training loss: 2.586252982726481
Validation loss: 2.489091879667135

Epoch: 5| Step: 5
Training loss: 3.485735024830499
Validation loss: 2.4899811744530145

Epoch: 5| Step: 6
Training loss: 2.935649857329526
Validation loss: 2.486274081627518

Epoch: 5| Step: 7
Training loss: 2.2338754589026335
Validation loss: 2.482807713730916

Epoch: 5| Step: 8
Training loss: 2.889176619294083
Validation loss: 2.483012023585572

Epoch: 5| Step: 9
Training loss: 2.7570069084703563
Validation loss: 2.4916621260794205

Epoch: 5| Step: 10
Training loss: 3.3845220391199367
Validation loss: 2.4994462815165943

Epoch: 154| Step: 0
Training loss: 2.7386020793517156
Validation loss: 2.5038952025642263

Epoch: 5| Step: 1
Training loss: 2.9423687134058985
Validation loss: 2.537701527834756

Epoch: 5| Step: 2
Training loss: 2.2903192084442296
Validation loss: 2.5548853944791703

Epoch: 5| Step: 3
Training loss: 2.6490522813256776
Validation loss: 2.5762117219160516

Epoch: 5| Step: 4
Training loss: 2.982471598052682
Validation loss: 2.564041864352684

Epoch: 5| Step: 5
Training loss: 2.9675070318895562
Validation loss: 2.5809796818936457

Epoch: 5| Step: 6
Training loss: 3.1064202920145316
Validation loss: 2.548776967907999

Epoch: 5| Step: 7
Training loss: 2.696652640395433
Validation loss: 2.5255456716370546

Epoch: 5| Step: 8
Training loss: 3.188248340798593
Validation loss: 2.5288991196216486

Epoch: 5| Step: 9
Training loss: 2.7675247994873664
Validation loss: 2.5076445602937616

Epoch: 5| Step: 10
Training loss: 2.677309276580384
Validation loss: 2.497194386335764

Epoch: 155| Step: 0
Training loss: 2.319238381994371
Validation loss: 2.4928847281527178

Epoch: 5| Step: 1
Training loss: 3.185970612672379
Validation loss: 2.4921583977030455

Epoch: 5| Step: 2
Training loss: 2.9873556062287605
Validation loss: 2.4913284961506035

Epoch: 5| Step: 3
Training loss: 2.9433707152858846
Validation loss: 2.489614959061461

Epoch: 5| Step: 4
Training loss: 2.8077649417643
Validation loss: 2.49813584485453

Epoch: 5| Step: 5
Training loss: 2.545758148764716
Validation loss: 2.494897364433526

Epoch: 5| Step: 6
Training loss: 3.166653248273294
Validation loss: 2.5081097284834377

Epoch: 5| Step: 7
Training loss: 3.1793463146669674
Validation loss: 2.517457934648494

Epoch: 5| Step: 8
Training loss: 2.575228919807014
Validation loss: 2.528007501693588

Epoch: 5| Step: 9
Training loss: 2.372631096227692
Validation loss: 2.5250024012315904

Epoch: 5| Step: 10
Training loss: 2.645827906645569
Validation loss: 2.5314440271172782

Epoch: 156| Step: 0
Training loss: 2.9540978499460144
Validation loss: 2.507626499744322

Epoch: 5| Step: 1
Training loss: 2.2227992328584127
Validation loss: 2.4885483351778617

Epoch: 5| Step: 2
Training loss: 2.7493091062162214
Validation loss: 2.4857814607922863

Epoch: 5| Step: 3
Training loss: 2.816164892597915
Validation loss: 2.480591975839595

Epoch: 5| Step: 4
Training loss: 2.9932564601358536
Validation loss: 2.480724655540345

Epoch: 5| Step: 5
Training loss: 2.7526246463780084
Validation loss: 2.475213853847419

Epoch: 5| Step: 6
Training loss: 2.8478027640956665
Validation loss: 2.4870475870874453

Epoch: 5| Step: 7
Training loss: 2.9075471997878455
Validation loss: 2.472418378844776

Epoch: 5| Step: 8
Training loss: 3.0864768800275866
Validation loss: 2.472257848658595

Epoch: 5| Step: 9
Training loss: 2.691043115044348
Validation loss: 2.4819904280125265

Epoch: 5| Step: 10
Training loss: 3.042306614969922
Validation loss: 2.4851841402523442

Epoch: 157| Step: 0
Training loss: 2.937827558719284
Validation loss: 2.520558847649836

Epoch: 5| Step: 1
Training loss: 3.2935424160192874
Validation loss: 2.535585108134265

Epoch: 5| Step: 2
Training loss: 3.1196533240382043
Validation loss: 2.569329976735314

Epoch: 5| Step: 3
Training loss: 2.9836114835449354
Validation loss: 2.6184510958160403

Epoch: 5| Step: 4
Training loss: 2.7218958752047335
Validation loss: 2.612033334078234

Epoch: 5| Step: 5
Training loss: 3.3245869487534505
Validation loss: 2.5591660527781914

Epoch: 5| Step: 6
Training loss: 2.811923243407036
Validation loss: 2.5045610127559645

Epoch: 5| Step: 7
Training loss: 2.4644202399013544
Validation loss: 2.4823424102435663

Epoch: 5| Step: 8
Training loss: 2.2872503092252017
Validation loss: 2.466720686791893

Epoch: 5| Step: 9
Training loss: 2.50433888618053
Validation loss: 2.4714718476017765

Epoch: 5| Step: 10
Training loss: 2.5629535366733123
Validation loss: 2.4735929392655374

Epoch: 158| Step: 0
Training loss: 2.8388542539802564
Validation loss: 2.47425055772208

Epoch: 5| Step: 1
Training loss: 2.5694884860643157
Validation loss: 2.4712202523261406

Epoch: 5| Step: 2
Training loss: 3.3942014053281575
Validation loss: 2.4792837068956315

Epoch: 5| Step: 3
Training loss: 2.9910668249033816
Validation loss: 2.4739502996153426

Epoch: 5| Step: 4
Training loss: 2.51645405062801
Validation loss: 2.478303067264672

Epoch: 5| Step: 5
Training loss: 2.699516754703208
Validation loss: 2.4724535490687916

Epoch: 5| Step: 6
Training loss: 2.3490850128276444
Validation loss: 2.470470264736919

Epoch: 5| Step: 7
Training loss: 2.6540403263158865
Validation loss: 2.4743615805062396

Epoch: 5| Step: 8
Training loss: 3.027470227952727
Validation loss: 2.4843879122020267

Epoch: 5| Step: 9
Training loss: 3.046162526874874
Validation loss: 2.484961649594517

Epoch: 5| Step: 10
Training loss: 2.9588056554422844
Validation loss: 2.5116672167700624

Epoch: 159| Step: 0
Training loss: 2.603698220399706
Validation loss: 2.551310085126026

Epoch: 5| Step: 1
Training loss: 2.858970571798128
Validation loss: 2.520273905381154

Epoch: 5| Step: 2
Training loss: 2.6808017382678457
Validation loss: 2.505222934423411

Epoch: 5| Step: 3
Training loss: 3.129115027464241
Validation loss: 2.500637861115115

Epoch: 5| Step: 4
Training loss: 2.6755732768743816
Validation loss: 2.4905741597428914

Epoch: 5| Step: 5
Training loss: 3.1783054356850102
Validation loss: 2.4827840319217835

Epoch: 5| Step: 6
Training loss: 2.764331579831181
Validation loss: 2.4707064889481805

Epoch: 5| Step: 7
Training loss: 2.2473274889500043
Validation loss: 2.4716253082734085

Epoch: 5| Step: 8
Training loss: 2.511093227872307
Validation loss: 2.4726199826025033

Epoch: 5| Step: 9
Training loss: 3.0553597493481863
Validation loss: 2.4742590176939037

Epoch: 5| Step: 10
Training loss: 3.2682951455719746
Validation loss: 2.4779556520902637

Epoch: 160| Step: 0
Training loss: 3.079723427232489
Validation loss: 2.472682058833432

Epoch: 5| Step: 1
Training loss: 2.8518086366374584
Validation loss: 2.4750915156590123

Epoch: 5| Step: 2
Training loss: 2.74793512677019
Validation loss: 2.4740942456012713

Epoch: 5| Step: 3
Training loss: 2.5379168464018846
Validation loss: 2.4831189430616614

Epoch: 5| Step: 4
Training loss: 2.937920235950114
Validation loss: 2.4887812571788412

Epoch: 5| Step: 5
Training loss: 2.5183974442904056
Validation loss: 2.4837818630844777

Epoch: 5| Step: 6
Training loss: 2.978132019354923
Validation loss: 2.488946447482687

Epoch: 5| Step: 7
Training loss: 2.8904227521096435
Validation loss: 2.4880368552558383

Epoch: 5| Step: 8
Training loss: 2.872178725161869
Validation loss: 2.511160274257514

Epoch: 5| Step: 9
Training loss: 2.718688262589263
Validation loss: 2.5162998976405264

Epoch: 5| Step: 10
Training loss: 2.691441063731888
Validation loss: 2.50229674122483

Epoch: 161| Step: 0
Training loss: 2.710875848514341
Validation loss: 2.5033032262580592

Epoch: 5| Step: 1
Training loss: 2.8046137978053394
Validation loss: 2.497328167274026

Epoch: 5| Step: 2
Training loss: 2.2101209231129175
Validation loss: 2.498380217282576

Epoch: 5| Step: 3
Training loss: 3.213145441310455
Validation loss: 2.490973634060768

Epoch: 5| Step: 4
Training loss: 2.766905235054672
Validation loss: 2.4869216658886835

Epoch: 5| Step: 5
Training loss: 3.0031213416991247
Validation loss: 2.4876063357474782

Epoch: 5| Step: 6
Training loss: 2.4377416833245316
Validation loss: 2.503419019943445

Epoch: 5| Step: 7
Training loss: 2.565435449472498
Validation loss: 2.5305112456748975

Epoch: 5| Step: 8
Training loss: 2.6681011831722237
Validation loss: 2.5429633181949507

Epoch: 5| Step: 9
Training loss: 3.548939242851402
Validation loss: 2.5640610192832343

Epoch: 5| Step: 10
Training loss: 2.913202644693268
Validation loss: 2.5516956707112097

Epoch: 162| Step: 0
Training loss: 3.3302506656638906
Validation loss: 2.474730269632417

Epoch: 5| Step: 1
Training loss: 2.7352365934703933
Validation loss: 2.4699242227867355

Epoch: 5| Step: 2
Training loss: 2.421242514437722
Validation loss: 2.47339068357015

Epoch: 5| Step: 3
Training loss: 3.143086545795835
Validation loss: 2.479561878062398

Epoch: 5| Step: 4
Training loss: 3.2196824287997377
Validation loss: 2.4846101849347337

Epoch: 5| Step: 5
Training loss: 2.5286613696976743
Validation loss: 2.4822026214471786

Epoch: 5| Step: 6
Training loss: 2.8271674120962995
Validation loss: 2.4874024888036432

Epoch: 5| Step: 7
Training loss: 2.923942935705101
Validation loss: 2.487364999668848

Epoch: 5| Step: 8
Training loss: 2.7388702063947474
Validation loss: 2.4867762036907943

Epoch: 5| Step: 9
Training loss: 2.916322051988272
Validation loss: 2.4858954213026823

Epoch: 5| Step: 10
Training loss: 2.4559609124120643
Validation loss: 2.4832671312387515

Epoch: 163| Step: 0
Training loss: 2.7754605503924332
Validation loss: 2.4881586666765814

Epoch: 5| Step: 1
Training loss: 2.7325535402348926
Validation loss: 2.4849228216581674

Epoch: 5| Step: 2
Training loss: 3.2476165541479616
Validation loss: 2.49389030102373

Epoch: 5| Step: 3
Training loss: 2.7043459565886683
Validation loss: 2.5003958470734093

Epoch: 5| Step: 4
Training loss: 2.5359549417794947
Validation loss: 2.507362032642511

Epoch: 5| Step: 5
Training loss: 2.223906850702841
Validation loss: 2.512384118485338

Epoch: 5| Step: 6
Training loss: 2.8118361643330627
Validation loss: 2.5217508388580234

Epoch: 5| Step: 7
Training loss: 3.1747375499956747
Validation loss: 2.5220285160554243

Epoch: 5| Step: 8
Training loss: 2.9571133278424777
Validation loss: 2.531537639075088

Epoch: 5| Step: 9
Training loss: 2.7392191675081503
Validation loss: 2.524910966531382

Epoch: 5| Step: 10
Training loss: 3.1362179633123906
Validation loss: 2.5111615554852436

Epoch: 164| Step: 0
Training loss: 2.41992837752607
Validation loss: 2.5187370338840056

Epoch: 5| Step: 1
Training loss: 2.9484202535556476
Validation loss: 2.5277425452593456

Epoch: 5| Step: 2
Training loss: 2.588602680635984
Validation loss: 2.520795931869582

Epoch: 5| Step: 3
Training loss: 2.8777460998238307
Validation loss: 2.513635433446728

Epoch: 5| Step: 4
Training loss: 2.7089721415380317
Validation loss: 2.4993578301409194

Epoch: 5| Step: 5
Training loss: 2.8685469146184777
Validation loss: 2.481448377776929

Epoch: 5| Step: 6
Training loss: 2.864905673300037
Validation loss: 2.470075617707129

Epoch: 5| Step: 7
Training loss: 2.412130131805934
Validation loss: 2.4746510613637946

Epoch: 5| Step: 8
Training loss: 2.9795312369409284
Validation loss: 2.470623898649465

Epoch: 5| Step: 9
Training loss: 2.911124458800074
Validation loss: 2.467278752037044

Epoch: 5| Step: 10
Training loss: 3.237267421778346
Validation loss: 2.4683639205787085

Epoch: 165| Step: 0
Training loss: 3.198534695593214
Validation loss: 2.4756214717677025

Epoch: 5| Step: 1
Training loss: 2.594404574606806
Validation loss: 2.4751781257410768

Epoch: 5| Step: 2
Training loss: 2.715524974951879
Validation loss: 2.4875576740417378

Epoch: 5| Step: 3
Training loss: 3.1395365029132885
Validation loss: 2.498364188193586

Epoch: 5| Step: 4
Training loss: 3.066028819576415
Validation loss: 2.502215862651803

Epoch: 5| Step: 5
Training loss: 2.656071645695321
Validation loss: 2.5087088234522055

Epoch: 5| Step: 6
Training loss: 3.2287215059317536
Validation loss: 2.526078327413178

Epoch: 5| Step: 7
Training loss: 2.2975172325708377
Validation loss: 2.515600493896492

Epoch: 5| Step: 8
Training loss: 2.363340367610275
Validation loss: 2.5065021415779474

Epoch: 5| Step: 9
Training loss: 2.236913985759734
Validation loss: 2.487232748404516

Epoch: 5| Step: 10
Training loss: 2.9763263598711527
Validation loss: 2.477673858157912

Epoch: 166| Step: 0
Training loss: 3.2672766200370638
Validation loss: 2.4626669634370866

Epoch: 5| Step: 1
Training loss: 3.112563755347594
Validation loss: 2.4629660916991125

Epoch: 5| Step: 2
Training loss: 2.645383351025529
Validation loss: 2.45912259903435

Epoch: 5| Step: 3
Training loss: 2.886188793962469
Validation loss: 2.46068078059729

Epoch: 5| Step: 4
Training loss: 1.8579553906903055
Validation loss: 2.4597498103233995

Epoch: 5| Step: 5
Training loss: 2.75966195399759
Validation loss: 2.46162820040812

Epoch: 5| Step: 6
Training loss: 2.8429247318894966
Validation loss: 2.4594197431967384

Epoch: 5| Step: 7
Training loss: 3.0569242205700187
Validation loss: 2.4799001747302145

Epoch: 5| Step: 8
Training loss: 2.4605559522549463
Validation loss: 2.4858455349592257

Epoch: 5| Step: 9
Training loss: 2.869294517549982
Validation loss: 2.49551461142317

Epoch: 5| Step: 10
Training loss: 2.792376859676849
Validation loss: 2.5043323919487115

Epoch: 167| Step: 0
Training loss: 2.7062389981440447
Validation loss: 2.5128063272090535

Epoch: 5| Step: 1
Training loss: 2.8191925107481914
Validation loss: 2.518661125685591

Epoch: 5| Step: 2
Training loss: 2.655108038074469
Validation loss: 2.5237288341625987

Epoch: 5| Step: 3
Training loss: 2.2386205925273712
Validation loss: 2.5262175972028262

Epoch: 5| Step: 4
Training loss: 2.9101151226645046
Validation loss: 2.5101393802362004

Epoch: 5| Step: 5
Training loss: 3.305476822614448
Validation loss: 2.489280840544414

Epoch: 5| Step: 6
Training loss: 3.0981017053408273
Validation loss: 2.479445946269701

Epoch: 5| Step: 7
Training loss: 2.4082988586950225
Validation loss: 2.474015537155444

Epoch: 5| Step: 8
Training loss: 2.57147385353
Validation loss: 2.468852709638733

Epoch: 5| Step: 9
Training loss: 2.7751505115003607
Validation loss: 2.4828540585894907

Epoch: 5| Step: 10
Training loss: 2.9108364871932917
Validation loss: 2.471272962509786

Epoch: 168| Step: 0
Training loss: 3.2884048203052845
Validation loss: 2.468059286885466

Epoch: 5| Step: 1
Training loss: 3.048979829365542
Validation loss: 2.467262466859599

Epoch: 5| Step: 2
Training loss: 2.850958104291741
Validation loss: 2.476667249855577

Epoch: 5| Step: 3
Training loss: 2.4966715590153608
Validation loss: 2.4809785662141746

Epoch: 5| Step: 4
Training loss: 2.591321704717044
Validation loss: 2.478414032639532

Epoch: 5| Step: 5
Training loss: 1.9686527530933338
Validation loss: 2.4822737282796736

Epoch: 5| Step: 6
Training loss: 2.411954978294947
Validation loss: 2.499257461450172

Epoch: 5| Step: 7
Training loss: 2.6685699187724037
Validation loss: 2.501364120436051

Epoch: 5| Step: 8
Training loss: 2.5251465669905055
Validation loss: 2.4988433295066375

Epoch: 5| Step: 9
Training loss: 3.368957479170665
Validation loss: 2.5056884171225855

Epoch: 5| Step: 10
Training loss: 2.9269542914530406
Validation loss: 2.4806344132400118

Epoch: 169| Step: 0
Training loss: 2.8615959172361287
Validation loss: 2.4673408701752133

Epoch: 5| Step: 1
Training loss: 2.5900764648461636
Validation loss: 2.4643751192011334

Epoch: 5| Step: 2
Training loss: 2.3222889301487775
Validation loss: 2.462721618545834

Epoch: 5| Step: 3
Training loss: 2.7727763502777623
Validation loss: 2.4573134863036072

Epoch: 5| Step: 4
Training loss: 2.6149880348063115
Validation loss: 2.459020397295764

Epoch: 5| Step: 5
Training loss: 2.7047351605972345
Validation loss: 2.466750280425901

Epoch: 5| Step: 6
Training loss: 3.2518186615875617
Validation loss: 2.469957807281077

Epoch: 5| Step: 7
Training loss: 2.438227813829411
Validation loss: 2.484813265337945

Epoch: 5| Step: 8
Training loss: 2.8083490044885737
Validation loss: 2.521081722195023

Epoch: 5| Step: 9
Training loss: 3.441312721531638
Validation loss: 2.504325035757208

Epoch: 5| Step: 10
Training loss: 2.4078155973044444
Validation loss: 2.5105457205507524

Epoch: 170| Step: 0
Training loss: 2.8531539865381323
Validation loss: 2.5095582526751476

Epoch: 5| Step: 1
Training loss: 3.392221944907311
Validation loss: 2.4880185524256335

Epoch: 5| Step: 2
Training loss: 2.7610425323559427
Validation loss: 2.4769660618571008

Epoch: 5| Step: 3
Training loss: 2.5946540635748043
Validation loss: 2.483956370132707

Epoch: 5| Step: 4
Training loss: 2.332811388039755
Validation loss: 2.4734445321816145

Epoch: 5| Step: 5
Training loss: 2.176444207760872
Validation loss: 2.4662251591876694

Epoch: 5| Step: 6
Training loss: 2.5514723584895984
Validation loss: 2.4639329635725216

Epoch: 5| Step: 7
Training loss: 2.943790275152432
Validation loss: 2.4727365796657232

Epoch: 5| Step: 8
Training loss: 2.6502796169526466
Validation loss: 2.474345670385231

Epoch: 5| Step: 9
Training loss: 3.095187999333918
Validation loss: 2.4768585372851786

Epoch: 5| Step: 10
Training loss: 2.8091060081080634
Validation loss: 2.4674402555279173

Epoch: 171| Step: 0
Training loss: 2.7932471930150795
Validation loss: 2.475236136850603

Epoch: 5| Step: 1
Training loss: 3.4188719509767096
Validation loss: 2.5105808146352864

Epoch: 5| Step: 2
Training loss: 2.5598239416438653
Validation loss: 2.5247937875969346

Epoch: 5| Step: 3
Training loss: 2.3191963362592145
Validation loss: 2.525863927066947

Epoch: 5| Step: 4
Training loss: 2.897469166023031
Validation loss: 2.5436533367520844

Epoch: 5| Step: 5
Training loss: 3.407071075871479
Validation loss: 2.5217016110039983

Epoch: 5| Step: 6
Training loss: 2.352324504893928
Validation loss: 2.5023257630062092

Epoch: 5| Step: 7
Training loss: 2.364714889115688
Validation loss: 2.4692714322741187

Epoch: 5| Step: 8
Training loss: 2.5302165241090555
Validation loss: 2.467730049646493

Epoch: 5| Step: 9
Training loss: 3.150565438762277
Validation loss: 2.455796227936679

Epoch: 5| Step: 10
Training loss: 2.165003162408153
Validation loss: 2.450487983989695

Epoch: 172| Step: 0
Training loss: 2.4715590129137492
Validation loss: 2.455512775293236

Epoch: 5| Step: 1
Training loss: 3.105635958794451
Validation loss: 2.4536326238295985

Epoch: 5| Step: 2
Training loss: 3.359071371861903
Validation loss: 2.4540942416862874

Epoch: 5| Step: 3
Training loss: 2.7595415179596885
Validation loss: 2.4604521512885844

Epoch: 5| Step: 4
Training loss: 2.8535440327341943
Validation loss: 2.4992942429146217

Epoch: 5| Step: 5
Training loss: 2.7829370418312354
Validation loss: 2.511636384513514

Epoch: 5| Step: 6
Training loss: 2.5224512966206585
Validation loss: 2.55162952264915

Epoch: 5| Step: 7
Training loss: 2.888774217465288
Validation loss: 2.573988653101609

Epoch: 5| Step: 8
Training loss: 2.458103255372871
Validation loss: 2.5315544525656195

Epoch: 5| Step: 9
Training loss: 2.509236914610942
Validation loss: 2.5149742022979384

Epoch: 5| Step: 10
Training loss: 2.7028958438474815
Validation loss: 2.469557607592582

Epoch: 173| Step: 0
Training loss: 2.964766228709028
Validation loss: 2.4500323708869165

Epoch: 5| Step: 1
Training loss: 2.6471846326214217
Validation loss: 2.454561259175086

Epoch: 5| Step: 2
Training loss: 2.1571623489127214
Validation loss: 2.453385663662613

Epoch: 5| Step: 3
Training loss: 3.035731826859773
Validation loss: 2.4582761188131856

Epoch: 5| Step: 4
Training loss: 3.1757175866158827
Validation loss: 2.4582570395945917

Epoch: 5| Step: 5
Training loss: 2.254839143788659
Validation loss: 2.4602989387908236

Epoch: 5| Step: 6
Training loss: 3.2917175449994382
Validation loss: 2.4592413715653256

Epoch: 5| Step: 7
Training loss: 2.758060346926589
Validation loss: 2.4662078732844055

Epoch: 5| Step: 8
Training loss: 2.4667225492006812
Validation loss: 2.491393608948416

Epoch: 5| Step: 9
Training loss: 2.587137733199223
Validation loss: 2.515867944714844

Epoch: 5| Step: 10
Training loss: 2.7471076320007692
Validation loss: 2.527977322036025

Epoch: 174| Step: 0
Training loss: 2.896737558999395
Validation loss: 2.5294069370818892

Epoch: 5| Step: 1
Training loss: 2.816659775749972
Validation loss: 2.5080914085916093

Epoch: 5| Step: 2
Training loss: 2.491160501039075
Validation loss: 2.5061136330506812

Epoch: 5| Step: 3
Training loss: 2.1572576186438703
Validation loss: 2.4778844275513627

Epoch: 5| Step: 4
Training loss: 3.1623702433507486
Validation loss: 2.4695172429324597

Epoch: 5| Step: 5
Training loss: 2.784427927458211
Validation loss: 2.46537999664287

Epoch: 5| Step: 6
Training loss: 2.602801511889954
Validation loss: 2.4699703091032603

Epoch: 5| Step: 7
Training loss: 2.848683866475563
Validation loss: 2.4724466506884566

Epoch: 5| Step: 8
Training loss: 2.5389931067740883
Validation loss: 2.4782082921728663

Epoch: 5| Step: 9
Training loss: 2.765556981171637
Validation loss: 2.470656218094219

Epoch: 5| Step: 10
Training loss: 2.9327181590072544
Validation loss: 2.4878067015095437

Epoch: 175| Step: 0
Training loss: 2.4630053355089108
Validation loss: 2.508556803574445

Epoch: 5| Step: 1
Training loss: 2.6818592401955796
Validation loss: 2.536502324730361

Epoch: 5| Step: 2
Training loss: 2.8815331243397986
Validation loss: 2.5320125632869357

Epoch: 5| Step: 3
Training loss: 2.4245690896922114
Validation loss: 2.540879135802512

Epoch: 5| Step: 4
Training loss: 2.9007577169312895
Validation loss: 2.5351836088356303

Epoch: 5| Step: 5
Training loss: 2.8823427060461873
Validation loss: 2.5134675579474823

Epoch: 5| Step: 6
Training loss: 2.9502223044217892
Validation loss: 2.5068635082597877

Epoch: 5| Step: 7
Training loss: 2.551515155266559
Validation loss: 2.499137280411112

Epoch: 5| Step: 8
Training loss: 2.7406178734228894
Validation loss: 2.5118890137286067

Epoch: 5| Step: 9
Training loss: 3.035577575426242
Validation loss: 2.501177192732777

Epoch: 5| Step: 10
Training loss: 2.4782367426151017
Validation loss: 2.4994084365885607

Epoch: 176| Step: 0
Training loss: 2.66934316149467
Validation loss: 2.4770360646375744

Epoch: 5| Step: 1
Training loss: 2.7200127661629825
Validation loss: 2.4769276115972096

Epoch: 5| Step: 2
Training loss: 2.601368023359352
Validation loss: 2.4698457416293182

Epoch: 5| Step: 3
Training loss: 2.6876694381884407
Validation loss: 2.47836036492887

Epoch: 5| Step: 4
Training loss: 2.502416110771543
Validation loss: 2.463008203073076

Epoch: 5| Step: 5
Training loss: 3.0128787487205964
Validation loss: 2.4807136288807303

Epoch: 5| Step: 6
Training loss: 2.3250275558971665
Validation loss: 2.493433553873211

Epoch: 5| Step: 7
Training loss: 3.435309249527992
Validation loss: 2.509058553353182

Epoch: 5| Step: 8
Training loss: 2.1088886971982213
Validation loss: 2.5131674902537595

Epoch: 5| Step: 9
Training loss: 2.950662544979636
Validation loss: 2.5100490392968484

Epoch: 5| Step: 10
Training loss: 2.667372451206811
Validation loss: 2.5320478250751313

Epoch: 177| Step: 0
Training loss: 2.831165007606051
Validation loss: 2.5855676817623467

Epoch: 5| Step: 1
Training loss: 2.032074511521055
Validation loss: 2.6529563998367287

Epoch: 5| Step: 2
Training loss: 2.881616028810917
Validation loss: 2.6795169667594076

Epoch: 5| Step: 3
Training loss: 3.024247723822231
Validation loss: 2.6535927671825457

Epoch: 5| Step: 4
Training loss: 2.9253687243075426
Validation loss: 2.5231465467466507

Epoch: 5| Step: 5
Training loss: 2.8084468882739033
Validation loss: 2.4656085984264062

Epoch: 5| Step: 6
Training loss: 3.210990664002548
Validation loss: 2.4582348274224284

Epoch: 5| Step: 7
Training loss: 2.920995896223895
Validation loss: 2.4735302661092673

Epoch: 5| Step: 8
Training loss: 2.7740144371311604
Validation loss: 2.482349610570368

Epoch: 5| Step: 9
Training loss: 2.786164987875026
Validation loss: 2.485375665448314

Epoch: 5| Step: 10
Training loss: 2.767722072909394
Validation loss: 2.480635555214917

Epoch: 178| Step: 0
Training loss: 3.0155626992228726
Validation loss: 2.4814128659964316

Epoch: 5| Step: 1
Training loss: 2.7741131886256705
Validation loss: 2.4678976551008325

Epoch: 5| Step: 2
Training loss: 2.723535732263892
Validation loss: 2.4637097493859073

Epoch: 5| Step: 3
Training loss: 2.5681204216907694
Validation loss: 2.46025687482525

Epoch: 5| Step: 4
Training loss: 3.2553593389454227
Validation loss: 2.4801562123267797

Epoch: 5| Step: 5
Training loss: 2.6327313600256486
Validation loss: 2.5057707438319894

Epoch: 5| Step: 6
Training loss: 2.7409994915610687
Validation loss: 2.5704931380262437

Epoch: 5| Step: 7
Training loss: 2.5923649410429905
Validation loss: 2.688200497558698

Epoch: 5| Step: 8
Training loss: 2.9411815542289332
Validation loss: 2.878358862897316

Epoch: 5| Step: 9
Training loss: 2.2406757854414967
Validation loss: 2.90246328277963

Epoch: 5| Step: 10
Training loss: 3.1083422915523053
Validation loss: 2.7592300982186653

Epoch: 179| Step: 0
Training loss: 2.4275683026275736
Validation loss: 2.545776514809926

Epoch: 5| Step: 1
Training loss: 3.429010902349629
Validation loss: 2.4812977656128554

Epoch: 5| Step: 2
Training loss: 2.787578968246716
Validation loss: 2.4667311888051997

Epoch: 5| Step: 3
Training loss: 2.9209678179970444
Validation loss: 2.501614408264556

Epoch: 5| Step: 4
Training loss: 2.7904497217578035
Validation loss: 2.5404495285016826

Epoch: 5| Step: 5
Training loss: 2.649067131525338
Validation loss: 2.5406043705516863

Epoch: 5| Step: 6
Training loss: 2.8708897939887064
Validation loss: 2.5427360278849966

Epoch: 5| Step: 7
Training loss: 2.6429759738968857
Validation loss: 2.5335499958506276

Epoch: 5| Step: 8
Training loss: 3.0376867794176268
Validation loss: 2.5279259488588277

Epoch: 5| Step: 9
Training loss: 3.1056764929040277
Validation loss: 2.532992376165482

Epoch: 5| Step: 10
Training loss: 2.5116690101266657
Validation loss: 2.5146848817042797

Epoch: 180| Step: 0
Training loss: 2.730962749538645
Validation loss: 2.5087576011611517

Epoch: 5| Step: 1
Training loss: 2.706361277629295
Validation loss: 2.5105475652552998

Epoch: 5| Step: 2
Training loss: 2.5248016355042666
Validation loss: 2.514947557349658

Epoch: 5| Step: 3
Training loss: 2.5787725386787987
Validation loss: 2.522772014956324

Epoch: 5| Step: 4
Training loss: 2.9192172932316187
Validation loss: 2.5295148092890822

Epoch: 5| Step: 5
Training loss: 2.990754822849976
Validation loss: 2.5248168946337395

Epoch: 5| Step: 6
Training loss: 2.8947409529405816
Validation loss: 2.5102419844559742

Epoch: 5| Step: 7
Training loss: 2.948602028336274
Validation loss: 2.504395449981861

Epoch: 5| Step: 8
Training loss: 2.9543806363530765
Validation loss: 2.493461024014971

Epoch: 5| Step: 9
Training loss: 2.7918255793952067
Validation loss: 2.495188606459708

Epoch: 5| Step: 10
Training loss: 3.06871088006904
Validation loss: 2.500633067812788

Epoch: 181| Step: 0
Training loss: 3.0800480910671073
Validation loss: 2.5091322871478265

Epoch: 5| Step: 1
Training loss: 2.9464538143777563
Validation loss: 2.540018143831704

Epoch: 5| Step: 2
Training loss: 2.5898446705904283
Validation loss: 2.5929511162301324

Epoch: 5| Step: 3
Training loss: 2.852776757470922
Validation loss: 2.606173043078707

Epoch: 5| Step: 4
Training loss: 2.7523271077779308
Validation loss: 2.5907083451311577

Epoch: 5| Step: 5
Training loss: 2.925034227741527
Validation loss: 2.5679681412676314

Epoch: 5| Step: 6
Training loss: 2.7985257013969687
Validation loss: 2.5450148627761062

Epoch: 5| Step: 7
Training loss: 2.665695361229526
Validation loss: 2.5497741444776088

Epoch: 5| Step: 8
Training loss: 2.2302955787362073
Validation loss: 2.526879407632468

Epoch: 5| Step: 9
Training loss: 2.978976975028344
Validation loss: 2.508011119624825

Epoch: 5| Step: 10
Training loss: 2.2464566410311506
Validation loss: 2.5007734578888847

Epoch: 182| Step: 0
Training loss: 2.997349840082531
Validation loss: 2.4796608831844

Epoch: 5| Step: 1
Training loss: 2.6802926228317587
Validation loss: 2.4624258670794883

Epoch: 5| Step: 2
Training loss: 2.6238117253283826
Validation loss: 2.4503872529980364

Epoch: 5| Step: 3
Training loss: 2.806043036970315
Validation loss: 2.472329256030472

Epoch: 5| Step: 4
Training loss: 2.5086069720313926
Validation loss: 2.488039866044601

Epoch: 5| Step: 5
Training loss: 3.029191409451171
Validation loss: 2.5005597708169196

Epoch: 5| Step: 6
Training loss: 2.7786367762429025
Validation loss: 2.511630363365577

Epoch: 5| Step: 7
Training loss: 2.446589322422452
Validation loss: 2.5091992653696127

Epoch: 5| Step: 8
Training loss: 2.3276478323202014
Validation loss: 2.5123331744217157

Epoch: 5| Step: 9
Training loss: 2.8812413676829745
Validation loss: 2.48856636420772

Epoch: 5| Step: 10
Training loss: 2.798542995796654
Validation loss: 2.4758751468094053

Epoch: 183| Step: 0
Training loss: 2.8663431946168227
Validation loss: 2.484401390847201

Epoch: 5| Step: 1
Training loss: 3.092911886110191
Validation loss: 2.4961643389069597

Epoch: 5| Step: 2
Training loss: 2.4999603268336457
Validation loss: 2.4998443944762845

Epoch: 5| Step: 3
Training loss: 1.953356919824328
Validation loss: 2.5064436236611187

Epoch: 5| Step: 4
Training loss: 3.0045533593159983
Validation loss: 2.5214563764415

Epoch: 5| Step: 5
Training loss: 2.3277357147207822
Validation loss: 2.5212694396130497

Epoch: 5| Step: 6
Training loss: 2.606609958152157
Validation loss: 2.5363228667341025

Epoch: 5| Step: 7
Training loss: 2.6278762500082964
Validation loss: 2.5300245885153907

Epoch: 5| Step: 8
Training loss: 2.886761697287088
Validation loss: 2.505347933736435

Epoch: 5| Step: 9
Training loss: 2.8419505703712713
Validation loss: 2.4909644744119896

Epoch: 5| Step: 10
Training loss: 2.8241198932657423
Validation loss: 2.4934138697337946

Epoch: 184| Step: 0
Training loss: 2.420010741343975
Validation loss: 2.5220700813925014

Epoch: 5| Step: 1
Training loss: 2.379450292656047
Validation loss: 2.525114937871783

Epoch: 5| Step: 2
Training loss: 2.435338847339541
Validation loss: 2.5393098312836444

Epoch: 5| Step: 3
Training loss: 2.9973659077511257
Validation loss: 2.5426029502808127

Epoch: 5| Step: 4
Training loss: 2.4927536850430396
Validation loss: 2.5511783189734083

Epoch: 5| Step: 5
Training loss: 2.9363349064957607
Validation loss: 2.5610101051676883

Epoch: 5| Step: 6
Training loss: 3.1748366786972473
Validation loss: 2.551399973895452

Epoch: 5| Step: 7
Training loss: 2.4546607003306096
Validation loss: 2.535214204269727

Epoch: 5| Step: 8
Training loss: 2.6523092321023416
Validation loss: 2.525597566250878

Epoch: 5| Step: 9
Training loss: 2.3075790628132404
Validation loss: 2.5093972307101966

Epoch: 5| Step: 10
Training loss: 3.350197111565278
Validation loss: 2.510078479561479

Epoch: 185| Step: 0
Training loss: 2.6454658152928023
Validation loss: 2.5206534588379146

Epoch: 5| Step: 1
Training loss: 2.1937992405595454
Validation loss: 2.503688688452052

Epoch: 5| Step: 2
Training loss: 2.4768841170615565
Validation loss: 2.501491247481837

Epoch: 5| Step: 3
Training loss: 2.7938144923879964
Validation loss: 2.5185368965544597

Epoch: 5| Step: 4
Training loss: 3.079262770072298
Validation loss: 2.5030850090476418

Epoch: 5| Step: 5
Training loss: 2.255607822148803
Validation loss: 2.509675940712388

Epoch: 5| Step: 6
Training loss: 2.77811057534351
Validation loss: 2.542152962106297

Epoch: 5| Step: 7
Training loss: 2.8180285898765853
Validation loss: 2.571121277582962

Epoch: 5| Step: 8
Training loss: 3.0044017923714668
Validation loss: 2.626199021666254

Epoch: 5| Step: 9
Training loss: 2.686994371976875
Validation loss: 2.5313316401932116

Epoch: 5| Step: 10
Training loss: 2.7603457651689456
Validation loss: 2.482536538079526

Epoch: 186| Step: 0
Training loss: 2.243405532959866
Validation loss: 2.471333869248985

Epoch: 5| Step: 1
Training loss: 3.131237671117819
Validation loss: 2.4611361776126777

Epoch: 5| Step: 2
Training loss: 2.4006575955077687
Validation loss: 2.462791956469018

Epoch: 5| Step: 3
Training loss: 2.460649358441335
Validation loss: 2.4635077421722134

Epoch: 5| Step: 4
Training loss: 3.1646150836435876
Validation loss: 2.466465705389016

Epoch: 5| Step: 5
Training loss: 2.833300496827378
Validation loss: 2.4689435331334426

Epoch: 5| Step: 6
Training loss: 2.751995143204107
Validation loss: 2.4816106109623055

Epoch: 5| Step: 7
Training loss: 2.3359470941352933
Validation loss: 2.5206361790315452

Epoch: 5| Step: 8
Training loss: 2.7456697703739894
Validation loss: 2.537595348303474

Epoch: 5| Step: 9
Training loss: 3.019292469132488
Validation loss: 2.5585741733859484

Epoch: 5| Step: 10
Training loss: 2.720331630825761
Validation loss: 2.5792442012989336

Epoch: 187| Step: 0
Training loss: 2.923777567720043
Validation loss: 2.578453808173934

Epoch: 5| Step: 1
Training loss: 2.404220121198206
Validation loss: 2.5368606144944743

Epoch: 5| Step: 2
Training loss: 2.829301115351734
Validation loss: 2.521805900979817

Epoch: 5| Step: 3
Training loss: 2.557810702873815
Validation loss: 2.510299406877493

Epoch: 5| Step: 4
Training loss: 3.228854716009937
Validation loss: 2.501455250569331

Epoch: 5| Step: 5
Training loss: 2.3168579484565766
Validation loss: 2.498724521829902

Epoch: 5| Step: 6
Training loss: 2.53281024836276
Validation loss: 2.500429071501837

Epoch: 5| Step: 7
Training loss: 2.9558261043208165
Validation loss: 2.4914087495884

Epoch: 5| Step: 8
Training loss: 2.5361564085769372
Validation loss: 2.493323303211475

Epoch: 5| Step: 9
Training loss: 2.5934155719665246
Validation loss: 2.5234258929514315

Epoch: 5| Step: 10
Training loss: 2.4354893143007716
Validation loss: 2.5318107373817837

Epoch: 188| Step: 0
Training loss: 2.6694227420411174
Validation loss: 2.5422284608022028

Epoch: 5| Step: 1
Training loss: 2.760255331446983
Validation loss: 2.5445443909590715

Epoch: 5| Step: 2
Training loss: 2.925291949969047
Validation loss: 2.5572774146646746

Epoch: 5| Step: 3
Training loss: 2.81628434635625
Validation loss: 2.5697749984983234

Epoch: 5| Step: 4
Training loss: 2.8961730501623717
Validation loss: 2.5654189179929445

Epoch: 5| Step: 5
Training loss: 2.6360943994594215
Validation loss: 2.540550161872261

Epoch: 5| Step: 6
Training loss: 2.0095349949667694
Validation loss: 2.551320006828042

Epoch: 5| Step: 7
Training loss: 2.4489464616075356
Validation loss: 2.5256788156615833

Epoch: 5| Step: 8
Training loss: 2.6440142488196665
Validation loss: 2.5194956431091056

Epoch: 5| Step: 9
Training loss: 2.221685160535841
Validation loss: 2.496992662991175

Epoch: 5| Step: 10
Training loss: 2.9336390993394774
Validation loss: 2.519022986557427

Epoch: 189| Step: 0
Training loss: 3.1839798582005443
Validation loss: 2.4987866584918708

Epoch: 5| Step: 1
Training loss: 2.848541247832052
Validation loss: 2.488209366957404

Epoch: 5| Step: 2
Training loss: 2.544542332625974
Validation loss: 2.4890277757722683

Epoch: 5| Step: 3
Training loss: 2.5605481785727995
Validation loss: 2.4832744125057027

Epoch: 5| Step: 4
Training loss: 2.771976397701478
Validation loss: 2.5062632438885224

Epoch: 5| Step: 5
Training loss: 2.92804120411048
Validation loss: 2.5117666568179815

Epoch: 5| Step: 6
Training loss: 2.156151479045951
Validation loss: 2.5322865255679434

Epoch: 5| Step: 7
Training loss: 2.666982175123095
Validation loss: 2.551957914189203

Epoch: 5| Step: 8
Training loss: 2.630086965247192
Validation loss: 2.5668621216809195

Epoch: 5| Step: 9
Training loss: 2.529572295875537
Validation loss: 2.5203039056930616

Epoch: 5| Step: 10
Training loss: 2.1175213652594684
Validation loss: 2.502427067413188

Epoch: 190| Step: 0
Training loss: 2.3175763267614276
Validation loss: 2.4844566652199247

Epoch: 5| Step: 1
Training loss: 3.0182580077027894
Validation loss: 2.476739485484488

Epoch: 5| Step: 2
Training loss: 2.561928289882447
Validation loss: 2.486187643609865

Epoch: 5| Step: 3
Training loss: 2.2063318815517112
Validation loss: 2.4967009804112408

Epoch: 5| Step: 4
Training loss: 2.6400704789146205
Validation loss: 2.508886099872006

Epoch: 5| Step: 5
Training loss: 2.9853081168125892
Validation loss: 2.5151372747697986

Epoch: 5| Step: 6
Training loss: 2.88954579595503
Validation loss: 2.519665776094085

Epoch: 5| Step: 7
Training loss: 2.990870253054363
Validation loss: 2.5207563271723306

Epoch: 5| Step: 8
Training loss: 2.483561256582522
Validation loss: 2.542086468917849

Epoch: 5| Step: 9
Training loss: 2.3141148058371535
Validation loss: 2.5464421909913413

Epoch: 5| Step: 10
Training loss: 2.599682836261303
Validation loss: 2.554479685816791

Epoch: 191| Step: 0
Training loss: 2.2461956498624374
Validation loss: 2.558446949800189

Epoch: 5| Step: 1
Training loss: 2.696853595175729
Validation loss: 2.576757392091039

Epoch: 5| Step: 2
Training loss: 2.5538420138444833
Validation loss: 2.56796159830401

Epoch: 5| Step: 3
Training loss: 2.9428496650357414
Validation loss: 2.5328889820059097

Epoch: 5| Step: 4
Training loss: 3.027617017656465
Validation loss: 2.529617340074266

Epoch: 5| Step: 5
Training loss: 2.485945103488038
Validation loss: 2.5254810678290047

Epoch: 5| Step: 6
Training loss: 2.523719889899059
Validation loss: 2.509356682439218

Epoch: 5| Step: 7
Training loss: 1.9398991896795525
Validation loss: 2.487174841363276

Epoch: 5| Step: 8
Training loss: 2.774052941178121
Validation loss: 2.4943895132510896

Epoch: 5| Step: 9
Training loss: 2.4461295131041507
Validation loss: 2.503038278809128

Epoch: 5| Step: 10
Training loss: 3.1782605767753336
Validation loss: 2.523394540954249

Epoch: 192| Step: 0
Training loss: 2.4421279206821542
Validation loss: 2.5183187085511123

Epoch: 5| Step: 1
Training loss: 2.7872834502127395
Validation loss: 2.542242843893066

Epoch: 5| Step: 2
Training loss: 2.4368024952921425
Validation loss: 2.5468446241689118

Epoch: 5| Step: 3
Training loss: 2.856976947054522
Validation loss: 2.548659257736811

Epoch: 5| Step: 4
Training loss: 2.3973437869162644
Validation loss: 2.5210102700241657

Epoch: 5| Step: 5
Training loss: 2.420832649620428
Validation loss: 2.509626396323103

Epoch: 5| Step: 6
Training loss: 3.003535095223178
Validation loss: 2.48190752011176

Epoch: 5| Step: 7
Training loss: 2.782817698778526
Validation loss: 2.4933586566670676

Epoch: 5| Step: 8
Training loss: 2.6433044021998695
Validation loss: 2.4874472928040046

Epoch: 5| Step: 9
Training loss: 2.666334866703529
Validation loss: 2.49568063700031

Epoch: 5| Step: 10
Training loss: 2.2772814576935656
Validation loss: 2.4879157808162917

Epoch: 193| Step: 0
Training loss: 2.870323358057341
Validation loss: 2.500602676698719

Epoch: 5| Step: 1
Training loss: 2.4490737993827376
Validation loss: 2.5162671935104433

Epoch: 5| Step: 2
Training loss: 2.9354641941429325
Validation loss: 2.531584187045956

Epoch: 5| Step: 3
Training loss: 2.913593489715995
Validation loss: 2.534940879996285

Epoch: 5| Step: 4
Training loss: 2.338960458572123
Validation loss: 2.536277397820988

Epoch: 5| Step: 5
Training loss: 2.810738499347217
Validation loss: 2.5567451903828613

Epoch: 5| Step: 6
Training loss: 2.506871982935001
Validation loss: 2.5751867928849075

Epoch: 5| Step: 7
Training loss: 2.656068503967116
Validation loss: 2.570533112364879

Epoch: 5| Step: 8
Training loss: 2.5970135115902506
Validation loss: 2.583358765184839

Epoch: 5| Step: 9
Training loss: 2.12311459093796
Validation loss: 2.5936310542310848

Epoch: 5| Step: 10
Training loss: 2.481012431958074
Validation loss: 2.6427824979712202

Epoch: 194| Step: 0
Training loss: 2.2892231022345113
Validation loss: 2.5831526988531635

Epoch: 5| Step: 1
Training loss: 2.6477047066800394
Validation loss: 2.524788175551464

Epoch: 5| Step: 2
Training loss: 2.517038173496699
Validation loss: 2.491675555086129

Epoch: 5| Step: 3
Training loss: 2.446259531539569
Validation loss: 2.482706563413347

Epoch: 5| Step: 4
Training loss: 2.5832068094423106
Validation loss: 2.472764184350797

Epoch: 5| Step: 5
Training loss: 2.5496861208549517
Validation loss: 2.4773062808037327

Epoch: 5| Step: 6
Training loss: 2.7660537645985666
Validation loss: 2.4979569947320615

Epoch: 5| Step: 7
Training loss: 2.427781513520642
Validation loss: 2.5016745102016062

Epoch: 5| Step: 8
Training loss: 2.8599629449111132
Validation loss: 2.50757477097737

Epoch: 5| Step: 9
Training loss: 2.834326588680936
Validation loss: 2.5073613752100687

Epoch: 5| Step: 10
Training loss: 2.4186648844250076
Validation loss: 2.5090096537733158

Epoch: 195| Step: 0
Training loss: 2.2234330521067927
Validation loss: 2.504336922762283

Epoch: 5| Step: 1
Training loss: 2.6074016670272635
Validation loss: 2.5100645137353674

Epoch: 5| Step: 2
Training loss: 2.2901437959126127
Validation loss: 2.504731479530127

Epoch: 5| Step: 3
Training loss: 2.581468575669987
Validation loss: 2.5339528587859057

Epoch: 5| Step: 4
Training loss: 2.5656876624908027
Validation loss: 2.5509696470893855

Epoch: 5| Step: 5
Training loss: 2.1204726291536966
Validation loss: 2.574174180515538

Epoch: 5| Step: 6
Training loss: 2.6178039735707808
Validation loss: 2.5673626049176086

Epoch: 5| Step: 7
Training loss: 2.386723145326354
Validation loss: 2.55284346376531

Epoch: 5| Step: 8
Training loss: 2.702813279364283
Validation loss: 2.555705514138506

Epoch: 5| Step: 9
Training loss: 2.8883433642014182
Validation loss: 2.520348040382274

Epoch: 5| Step: 10
Training loss: 3.3161505970182494
Validation loss: 2.4970866568636905

Epoch: 196| Step: 0
Training loss: 2.4922625969840015
Validation loss: 2.4902369322211726

Epoch: 5| Step: 1
Training loss: 2.8679855026134082
Validation loss: 2.4799971402423364

Epoch: 5| Step: 2
Training loss: 2.8552696899665024
Validation loss: 2.465668835133255

Epoch: 5| Step: 3
Training loss: 2.1417563017655263
Validation loss: 2.487087614150366

Epoch: 5| Step: 4
Training loss: 3.151086190069401
Validation loss: 2.491399934195027

Epoch: 5| Step: 5
Training loss: 2.319079344358905
Validation loss: 2.548471496624467

Epoch: 5| Step: 6
Training loss: 2.2686093373475495
Validation loss: 2.567840369765875

Epoch: 5| Step: 7
Training loss: 2.572151245262109
Validation loss: 2.5653062007019143

Epoch: 5| Step: 8
Training loss: 2.4656804957266534
Validation loss: 2.5308230278110044

Epoch: 5| Step: 9
Training loss: 2.5555564032659186
Validation loss: 2.5411774520719983

Epoch: 5| Step: 10
Training loss: 2.738985545181176
Validation loss: 2.5265430260325172

Epoch: 197| Step: 0
Training loss: 2.7142567830228943
Validation loss: 2.5252008601486313

Epoch: 5| Step: 1
Training loss: 2.7121060625902462
Validation loss: 2.5223933590990737

Epoch: 5| Step: 2
Training loss: 2.6558143707291064
Validation loss: 2.530081231629293

Epoch: 5| Step: 3
Training loss: 1.9305740976091161
Validation loss: 2.525878603287426

Epoch: 5| Step: 4
Training loss: 2.122958043686951
Validation loss: 2.5376146836680458

Epoch: 5| Step: 5
Training loss: 2.502905206638715
Validation loss: 2.5481493683435854

Epoch: 5| Step: 6
Training loss: 2.374402422765437
Validation loss: 2.564769457229058

Epoch: 5| Step: 7
Training loss: 3.305218737313653
Validation loss: 2.5636172801439496

Epoch: 5| Step: 8
Training loss: 2.1173784796244064
Validation loss: 2.545493021680756

Epoch: 5| Step: 9
Training loss: 2.807562924068011
Validation loss: 2.5343166265239967

Epoch: 5| Step: 10
Training loss: 2.3846889424160334
Validation loss: 2.529421096116133

Epoch: 198| Step: 0
Training loss: 2.713988156966792
Validation loss: 2.5259051400322514

Epoch: 5| Step: 1
Training loss: 2.421637935726158
Validation loss: 2.527996186392423

Epoch: 5| Step: 2
Training loss: 2.1755278900399775
Validation loss: 2.5525539350207285

Epoch: 5| Step: 3
Training loss: 2.4402429845861704
Validation loss: 2.559832981085658

Epoch: 5| Step: 4
Training loss: 2.6886747587167177
Validation loss: 2.5648047074653344

Epoch: 5| Step: 5
Training loss: 2.674180045977541
Validation loss: 2.5602427849940046

Epoch: 5| Step: 6
Training loss: 2.434561694604683
Validation loss: 2.571843673867543

Epoch: 5| Step: 7
Training loss: 2.386996039283001
Validation loss: 2.571875194814253

Epoch: 5| Step: 8
Training loss: 2.8048013223062846
Validation loss: 2.5772243145813833

Epoch: 5| Step: 9
Training loss: 2.8305010009073825
Validation loss: 2.560574927700066

Epoch: 5| Step: 10
Training loss: 1.896582368151713
Validation loss: 2.534927035976188

Epoch: 199| Step: 0
Training loss: 2.6322014436303793
Validation loss: 2.5291198736952145

Epoch: 5| Step: 1
Training loss: 2.483741727526269
Validation loss: 2.52437052191047

Epoch: 5| Step: 2
Training loss: 2.6409165260963547
Validation loss: 2.520043061007813

Epoch: 5| Step: 3
Training loss: 2.801592040451394
Validation loss: 2.514003264808857

Epoch: 5| Step: 4
Training loss: 2.0572635181931784
Validation loss: 2.531199097358918

Epoch: 5| Step: 5
Training loss: 2.0778442422614063
Validation loss: 2.53843003238949

Epoch: 5| Step: 6
Training loss: 3.0531442163305833
Validation loss: 2.558780668160352

Epoch: 5| Step: 7
Training loss: 2.592032357896939
Validation loss: 2.552670402047565

Epoch: 5| Step: 8
Training loss: 2.3067115301205128
Validation loss: 2.538687720519597

Epoch: 5| Step: 9
Training loss: 2.1629441880050453
Validation loss: 2.5262921270778658

Epoch: 5| Step: 10
Training loss: 2.3546689828247107
Validation loss: 2.502021340526072

Epoch: 200| Step: 0
Training loss: 2.817271868076634
Validation loss: 2.5005523973756407

Epoch: 5| Step: 1
Training loss: 2.1312540809390916
Validation loss: 2.5007856959694372

Epoch: 5| Step: 2
Training loss: 2.9933114194457247
Validation loss: 2.4992768872349993

Epoch: 5| Step: 3
Training loss: 2.620882983765873
Validation loss: 2.4937545422684764

Epoch: 5| Step: 4
Training loss: 2.3458736716597146
Validation loss: 2.4966285460418476

Epoch: 5| Step: 5
Training loss: 2.680322599637712
Validation loss: 2.5241627518477094

Epoch: 5| Step: 6
Training loss: 1.8003363401042596
Validation loss: 2.572370012677851

Epoch: 5| Step: 7
Training loss: 2.624739861086981
Validation loss: 2.6342012478132824

Epoch: 5| Step: 8
Training loss: 2.8107237399017215
Validation loss: 2.641038903354396

Epoch: 5| Step: 9
Training loss: 2.2379171398188147
Validation loss: 2.60754040896509

Epoch: 5| Step: 10
Training loss: 1.858505366221417
Validation loss: 2.5661130205614224

Epoch: 201| Step: 0
Training loss: 2.4399423345411733
Validation loss: 2.5597493625272625

Epoch: 5| Step: 1
Training loss: 2.015648420330868
Validation loss: 2.5460513532239126

Epoch: 5| Step: 2
Training loss: 2.335845945471435
Validation loss: 2.540614014188979

Epoch: 5| Step: 3
Training loss: 2.407169216006836
Validation loss: 2.550306636374436

Epoch: 5| Step: 4
Training loss: 2.541019565775672
Validation loss: 2.5440104803274606

Epoch: 5| Step: 5
Training loss: 2.346106603322371
Validation loss: 2.547869457651058

Epoch: 5| Step: 6
Training loss: 2.4501802300315485
Validation loss: 2.5616535756722865

Epoch: 5| Step: 7
Training loss: 3.018268118676381
Validation loss: 2.5436016290944

Epoch: 5| Step: 8
Training loss: 2.401942174579141
Validation loss: 2.5098548832110246

Epoch: 5| Step: 9
Training loss: 2.6686683731639067
Validation loss: 2.4613236902493973

Epoch: 5| Step: 10
Training loss: 2.4730827843507286
Validation loss: 2.4650298563611712

Epoch: 202| Step: 0
Training loss: 1.817329680636218
Validation loss: 2.4771139816352763

Epoch: 5| Step: 1
Training loss: 2.231012869236521
Validation loss: 2.5186849836669056

Epoch: 5| Step: 2
Training loss: 2.321861084271262
Validation loss: 2.5981973118357256

Epoch: 5| Step: 3
Training loss: 3.0723491252360735
Validation loss: 2.6585585279653965

Epoch: 5| Step: 4
Training loss: 3.113261798333603
Validation loss: 2.6234568578455697

Epoch: 5| Step: 5
Training loss: 2.0253329438959837
Validation loss: 2.504867352106101

Epoch: 5| Step: 6
Training loss: 2.519450720158053
Validation loss: 2.4681764421605177

Epoch: 5| Step: 7
Training loss: 2.2538331547194757
Validation loss: 2.4516565131143118

Epoch: 5| Step: 8
Training loss: 2.5915032272892855
Validation loss: 2.4435310027085766

Epoch: 5| Step: 9
Training loss: 2.5970653808436763
Validation loss: 2.4726548337359677

Epoch: 5| Step: 10
Training loss: 2.7185982848181722
Validation loss: 2.4560699040330856

Epoch: 203| Step: 0
Training loss: 2.8363295775371573
Validation loss: 2.4587412106995785

Epoch: 5| Step: 1
Training loss: 2.7042838021777498
Validation loss: 2.4663376907929866

Epoch: 5| Step: 2
Training loss: 2.0038052360550784
Validation loss: 2.505630695142136

Epoch: 5| Step: 3
Training loss: 2.372368408669926
Validation loss: 2.5606863585319584

Epoch: 5| Step: 4
Training loss: 2.3065918377037837
Validation loss: 2.676455440427069

Epoch: 5| Step: 5
Training loss: 3.084981649582259
Validation loss: 2.829506659356266

Epoch: 5| Step: 6
Training loss: 2.6029121632478764
Validation loss: 2.843239618653625

Epoch: 5| Step: 7
Training loss: 2.252329891610754
Validation loss: 2.687291888234786

Epoch: 5| Step: 8
Training loss: 2.043309958211712
Validation loss: 2.590147919026926

Epoch: 5| Step: 9
Training loss: 2.5872038998932423
Validation loss: 2.5371231626521076

Epoch: 5| Step: 10
Training loss: 3.166290628960945
Validation loss: 2.4986925110582168

Epoch: 204| Step: 0
Training loss: 3.1874937169630173
Validation loss: 2.525028192823087

Epoch: 5| Step: 1
Training loss: 2.2705324889452063
Validation loss: 2.5342876367629046

Epoch: 5| Step: 2
Training loss: 2.727251725404966
Validation loss: 2.5618477888490707

Epoch: 5| Step: 3
Training loss: 2.5794011512208948
Validation loss: 2.5773284506918674

Epoch: 5| Step: 4
Training loss: 3.108690196015397
Validation loss: 2.5886784423285705

Epoch: 5| Step: 5
Training loss: 2.8888300090886507
Validation loss: 2.5733184088964323

Epoch: 5| Step: 6
Training loss: 2.5015543873814425
Validation loss: 2.560241773653374

Epoch: 5| Step: 7
Training loss: 1.9330424437976823
Validation loss: 2.5488529845157624

Epoch: 5| Step: 8
Training loss: 2.838790425357526
Validation loss: 2.5544715467195056

Epoch: 5| Step: 9
Training loss: 2.4868601718948504
Validation loss: 2.591121939906938

Epoch: 5| Step: 10
Training loss: 1.9513791635737805
Validation loss: 2.6324659257998646

Epoch: 205| Step: 0
Training loss: 2.992266860586773
Validation loss: 2.649445184056517

Epoch: 5| Step: 1
Training loss: 2.2976792153744867
Validation loss: 2.62197301033331

Epoch: 5| Step: 2
Training loss: 2.630518335385456
Validation loss: 2.587207024175037

Epoch: 5| Step: 3
Training loss: 2.346821006428091
Validation loss: 2.552917891147435

Epoch: 5| Step: 4
Training loss: 2.3678292893208073
Validation loss: 2.5252420560172926

Epoch: 5| Step: 5
Training loss: 2.3567013781238035
Validation loss: 2.530128945788703

Epoch: 5| Step: 6
Training loss: 2.0086973148028893
Validation loss: 2.573611662089675

Epoch: 5| Step: 7
Training loss: 2.6431453798040123
Validation loss: 2.5672235759940762

Epoch: 5| Step: 8
Training loss: 2.974349994333879
Validation loss: 2.5667286329482826

Epoch: 5| Step: 9
Training loss: 1.7421764151045196
Validation loss: 2.5224917116395575

Epoch: 5| Step: 10
Training loss: 2.423907700553386
Validation loss: 2.4972780196386144

Epoch: 206| Step: 0
Training loss: 2.5352482242681456
Validation loss: 2.4626310912962834

Epoch: 5| Step: 1
Training loss: 2.4149557393127012
Validation loss: 2.4589854259010284

Epoch: 5| Step: 2
Training loss: 2.5827242430592614
Validation loss: 2.464356269251865

Epoch: 5| Step: 3
Training loss: 2.4204866429153236
Validation loss: 2.470176528661309

Epoch: 5| Step: 4
Training loss: 1.918786397085507
Validation loss: 2.4916197118787577

Epoch: 5| Step: 5
Training loss: 2.4000536912634405
Validation loss: 2.5167686468089663

Epoch: 5| Step: 6
Training loss: 2.7171589372218388
Validation loss: 2.5524372899245837

Epoch: 5| Step: 7
Training loss: 2.498957034947221
Validation loss: 2.586700199089778

Epoch: 5| Step: 8
Training loss: 2.414572553854692
Validation loss: 2.6082533435441757

Epoch: 5| Step: 9
Training loss: 2.4219743277577543
Validation loss: 2.612933303784463

Epoch: 5| Step: 10
Training loss: 2.448278998214988
Validation loss: 2.631921410413592

Epoch: 207| Step: 0
Training loss: 2.895348231532079
Validation loss: 2.5737296036546478

Epoch: 5| Step: 1
Training loss: 2.4119830511582596
Validation loss: 2.547925574258821

Epoch: 5| Step: 2
Training loss: 2.3970344739081253
Validation loss: 2.5298414850096687

Epoch: 5| Step: 3
Training loss: 2.3279048124300235
Validation loss: 2.5221248610838907

Epoch: 5| Step: 4
Training loss: 2.0001503172653035
Validation loss: 2.5114433760102397

Epoch: 5| Step: 5
Training loss: 2.715937859145977
Validation loss: 2.513367171822579

Epoch: 5| Step: 6
Training loss: 2.0304585015161956
Validation loss: 2.486077187106319

Epoch: 5| Step: 7
Training loss: 2.632959559830187
Validation loss: 2.4681099502910295

Epoch: 5| Step: 8
Training loss: 2.041354123021925
Validation loss: 2.452444903607283

Epoch: 5| Step: 9
Training loss: 2.345839421031183
Validation loss: 2.4395458543024637

Epoch: 5| Step: 10
Training loss: 2.5941648955747065
Validation loss: 2.4397774367496483

Epoch: 208| Step: 0
Training loss: 2.3631268915886663
Validation loss: 2.4544039813979515

Epoch: 5| Step: 1
Training loss: 2.2106479414724713
Validation loss: 2.4574473811018445

Epoch: 5| Step: 2
Training loss: 1.8695535393042568
Validation loss: 2.463971406442792

Epoch: 5| Step: 3
Training loss: 2.693742643200239
Validation loss: 2.51477607043937

Epoch: 5| Step: 4
Training loss: 1.9012479347955145
Validation loss: 2.5371001131316757

Epoch: 5| Step: 5
Training loss: 2.9458062443618536
Validation loss: 2.5657541365504835

Epoch: 5| Step: 6
Training loss: 2.4479675504116987
Validation loss: 2.5696703268232883

Epoch: 5| Step: 7
Training loss: 2.9687128968178973
Validation loss: 2.5912634935943784

Epoch: 5| Step: 8
Training loss: 2.2872144510448424
Validation loss: 2.5790903938322094

Epoch: 5| Step: 9
Training loss: 2.294819333646631
Validation loss: 2.572559140707279

Epoch: 5| Step: 10
Training loss: 1.8252551383821467
Validation loss: 2.582303541222578

Epoch: 209| Step: 0
Training loss: 2.00337637575259
Validation loss: 2.5676011754532375

Epoch: 5| Step: 1
Training loss: 2.5133081038074714
Validation loss: 2.5452372362550566

Epoch: 5| Step: 2
Training loss: 2.085386281994152
Validation loss: 2.5588559457610573

Epoch: 5| Step: 3
Training loss: 2.445944999818817
Validation loss: 2.5522609452168807

Epoch: 5| Step: 4
Training loss: 2.5330452851450285
Validation loss: 2.52828380526499

Epoch: 5| Step: 5
Training loss: 2.7651534890864173
Validation loss: 2.539548680004288

Epoch: 5| Step: 6
Training loss: 2.7373073004915285
Validation loss: 2.550803174882862

Epoch: 5| Step: 7
Training loss: 2.2172491880925715
Validation loss: 2.5766671860393795

Epoch: 5| Step: 8
Training loss: 1.9047086769284889
Validation loss: 2.552357136393253

Epoch: 5| Step: 9
Training loss: 2.4251422132497886
Validation loss: 2.563447699490289

Epoch: 5| Step: 10
Training loss: 2.1693194606378854
Validation loss: 2.5422651691366824

Epoch: 210| Step: 0
Training loss: 2.2117877309398026
Validation loss: 2.5303925725908027

Epoch: 5| Step: 1
Training loss: 1.8021948969123482
Validation loss: 2.516468786821268

Epoch: 5| Step: 2
Training loss: 2.615547782460023
Validation loss: 2.543046291078887

Epoch: 5| Step: 3
Training loss: 2.3992585507131503
Validation loss: 2.545318458028577

Epoch: 5| Step: 4
Training loss: 2.169223621552258
Validation loss: 2.5310419975287846

Epoch: 5| Step: 5
Training loss: 1.9950211661035815
Validation loss: 2.52132504097517

Epoch: 5| Step: 6
Training loss: 2.220685624965402
Validation loss: 2.5065515268015153

Epoch: 5| Step: 7
Training loss: 2.7732607503098197
Validation loss: 2.496530729302509

Epoch: 5| Step: 8
Training loss: 2.5342642650565907
Validation loss: 2.4955520788052192

Epoch: 5| Step: 9
Training loss: 1.995238537115817
Validation loss: 2.4718066506818537

Epoch: 5| Step: 10
Training loss: 2.7765295710459887
Validation loss: 2.4667953795059727

Epoch: 211| Step: 0
Training loss: 2.1757407056225766
Validation loss: 2.456733350495609

Epoch: 5| Step: 1
Training loss: 2.6638816257501987
Validation loss: 2.470249494790669

Epoch: 5| Step: 2
Training loss: 2.20109063771176
Validation loss: 2.4884801974309463

Epoch: 5| Step: 3
Training loss: 2.4618462716271527
Validation loss: 2.51732102462729

Epoch: 5| Step: 4
Training loss: 2.4606081787650624
Validation loss: 2.548779751042755

Epoch: 5| Step: 5
Training loss: 2.5134995289535187
Validation loss: 2.5683506969584626

Epoch: 5| Step: 6
Training loss: 2.2523512740576828
Validation loss: 2.5767408994220165

Epoch: 5| Step: 7
Training loss: 2.2530336062536223
Validation loss: 2.5389301446663324

Epoch: 5| Step: 8
Training loss: 2.4695088632613404
Validation loss: 2.522656111140072

Epoch: 5| Step: 9
Training loss: 1.7592953679169672
Validation loss: 2.4837086927452052

Epoch: 5| Step: 10
Training loss: 2.289171964872784
Validation loss: 2.4827936234172814

Epoch: 212| Step: 0
Training loss: 2.283815587296791
Validation loss: 2.452793046364316

Epoch: 5| Step: 1
Training loss: 2.424899077527526
Validation loss: 2.4251855374345475

Epoch: 5| Step: 2
Training loss: 2.6997903530532614
Validation loss: 2.438058273333911

Epoch: 5| Step: 3
Training loss: 2.5115237716531
Validation loss: 2.43814837338696

Epoch: 5| Step: 4
Training loss: 2.052702550523405
Validation loss: 2.4541409376150116

Epoch: 5| Step: 5
Training loss: 2.0888735792036384
Validation loss: 2.4745550321823155

Epoch: 5| Step: 6
Training loss: 2.0529577131937873
Validation loss: 2.525926848477694

Epoch: 5| Step: 7
Training loss: 2.3577179805752286
Validation loss: 2.569875832237053

Epoch: 5| Step: 8
Training loss: 2.96944218647269
Validation loss: 2.5898367604312456

Epoch: 5| Step: 9
Training loss: 1.8171759830546141
Validation loss: 2.554311786344357

Epoch: 5| Step: 10
Training loss: 1.9014945200646294
Validation loss: 2.5304726607597705

Epoch: 213| Step: 0
Training loss: 2.1597562285018963
Validation loss: 2.513471487346848

Epoch: 5| Step: 1
Training loss: 2.3070228253555327
Validation loss: 2.480836810522229

Epoch: 5| Step: 2
Training loss: 2.2436741808138896
Validation loss: 2.4522502084786493

Epoch: 5| Step: 3
Training loss: 2.491447314895579
Validation loss: 2.4422418407931503

Epoch: 5| Step: 4
Training loss: 2.5881325432327325
Validation loss: 2.4373909920885715

Epoch: 5| Step: 5
Training loss: 2.010412529132387
Validation loss: 2.46298790210414

Epoch: 5| Step: 6
Training loss: 2.354116681223749
Validation loss: 2.4990090657153186

Epoch: 5| Step: 7
Training loss: 2.187208319699943
Validation loss: 2.5500173644943045

Epoch: 5| Step: 8
Training loss: 2.3459338377251577
Validation loss: 2.567169263326056

Epoch: 5| Step: 9
Training loss: 2.025567895825303
Validation loss: 2.6025527872164913

Epoch: 5| Step: 10
Training loss: 2.4599667526727615
Validation loss: 2.6204172124471374

Epoch: 214| Step: 0
Training loss: 2.4684767752967502
Validation loss: 2.5587096866159342

Epoch: 5| Step: 1
Training loss: 2.178320233695529
Validation loss: 2.536347612299697

Epoch: 5| Step: 2
Training loss: 2.127064095116526
Validation loss: 2.5198378041689415

Epoch: 5| Step: 3
Training loss: 2.521537136054795
Validation loss: 2.482831659646238

Epoch: 5| Step: 4
Training loss: 2.1920980901559206
Validation loss: 2.4643919701223

Epoch: 5| Step: 5
Training loss: 2.3289549711468007
Validation loss: 2.468993861183338

Epoch: 5| Step: 6
Training loss: 2.2894731485258886
Validation loss: 2.4663064997475437

Epoch: 5| Step: 7
Training loss: 2.361517533372303
Validation loss: 2.4893533589547876

Epoch: 5| Step: 8
Training loss: 2.0314618513697362
Validation loss: 2.503212641674356

Epoch: 5| Step: 9
Training loss: 2.145710049640087
Validation loss: 2.5142963926095274

Epoch: 5| Step: 10
Training loss: 2.2202946833325887
Validation loss: 2.5289392004692486

Epoch: 215| Step: 0
Training loss: 2.067177987166911
Validation loss: 2.5441810094209427

Epoch: 5| Step: 1
Training loss: 2.572162090236719
Validation loss: 2.5391259313442527

Epoch: 5| Step: 2
Training loss: 2.329502389514006
Validation loss: 2.5396222927270826

Epoch: 5| Step: 3
Training loss: 2.0051425146885262
Validation loss: 2.522024162384461

Epoch: 5| Step: 4
Training loss: 1.7259137760253755
Validation loss: 2.5382129867954752

Epoch: 5| Step: 5
Training loss: 1.876289242328345
Validation loss: 2.554364273804018

Epoch: 5| Step: 6
Training loss: 2.6690678713170217
Validation loss: 2.552694749117005

Epoch: 5| Step: 7
Training loss: 2.5507199337002446
Validation loss: 2.5972426406028206

Epoch: 5| Step: 8
Training loss: 2.266047997285357
Validation loss: 2.581243355988373

Epoch: 5| Step: 9
Training loss: 1.4580299697694734
Validation loss: 2.5498699006252794

Epoch: 5| Step: 10
Training loss: 2.900588396824087
Validation loss: 2.527218312951347

Epoch: 216| Step: 0
Training loss: 2.623980914709419
Validation loss: 2.4874265821850563

Epoch: 5| Step: 1
Training loss: 2.234213976626516
Validation loss: 2.4412324030845745

Epoch: 5| Step: 2
Training loss: 2.2341452527137506
Validation loss: 2.4249118359693465

Epoch: 5| Step: 3
Training loss: 1.8773050762230008
Validation loss: 2.4008228587659697

Epoch: 5| Step: 4
Training loss: 2.3387895097356686
Validation loss: 2.422877144262164

Epoch: 5| Step: 5
Training loss: 1.9091997930926634
Validation loss: 2.4586922759116927

Epoch: 5| Step: 6
Training loss: 2.143462479330831
Validation loss: 2.501132172411396

Epoch: 5| Step: 7
Training loss: 1.7127427980145995
Validation loss: 2.58239783206587

Epoch: 5| Step: 8
Training loss: 2.2078195969993306
Validation loss: 2.686203743438981

Epoch: 5| Step: 9
Training loss: 2.8302455981546943
Validation loss: 2.737254628094642

Epoch: 5| Step: 10
Training loss: 2.6708480021232126
Validation loss: 2.7155612646890255

Epoch: 217| Step: 0
Training loss: 2.2226751289839695
Validation loss: 2.6173273550276672

Epoch: 5| Step: 1
Training loss: 2.0671240095450014
Validation loss: 2.522545079693199

Epoch: 5| Step: 2
Training loss: 2.043993486838219
Validation loss: 2.458745202013648

Epoch: 5| Step: 3
Training loss: 2.542705000693265
Validation loss: 2.4110958365815076

Epoch: 5| Step: 4
Training loss: 2.1205904593607383
Validation loss: 2.4395744671681543

Epoch: 5| Step: 5
Training loss: 2.6352546752679764
Validation loss: 2.4104321066098056

Epoch: 5| Step: 6
Training loss: 2.359602456149789
Validation loss: 2.425755755933697

Epoch: 5| Step: 7
Training loss: 2.2889612585599775
Validation loss: 2.458964966612172

Epoch: 5| Step: 8
Training loss: 2.5201233633817606
Validation loss: 2.501703721095901

Epoch: 5| Step: 9
Training loss: 1.370940588414383
Validation loss: 2.564807991971835

Epoch: 5| Step: 10
Training loss: 2.579996620294294
Validation loss: 2.6084478778594558

Epoch: 218| Step: 0
Training loss: 2.309918586650431
Validation loss: 2.617813619752844

Epoch: 5| Step: 1
Training loss: 2.3577643953930916
Validation loss: 2.6169279491109356

Epoch: 5| Step: 2
Training loss: 2.6199114388502167
Validation loss: 2.593172064573938

Epoch: 5| Step: 3
Training loss: 2.221781633993402
Validation loss: 2.5381374262291874

Epoch: 5| Step: 4
Training loss: 2.294420864526964
Validation loss: 2.528463153499317

Epoch: 5| Step: 5
Training loss: 2.3494565538284884
Validation loss: 2.488643176960161

Epoch: 5| Step: 6
Training loss: 1.929812655077562
Validation loss: 2.486844961295684

Epoch: 5| Step: 7
Training loss: 2.5339640442932483
Validation loss: 2.488699455222426

Epoch: 5| Step: 8
Training loss: 2.1105239564737497
Validation loss: 2.4903237032325913

Epoch: 5| Step: 9
Training loss: 1.282489967455672
Validation loss: 2.479144675271981

Epoch: 5| Step: 10
Training loss: 2.054755264151096
Validation loss: 2.475268593892705

Epoch: 219| Step: 0
Training loss: 2.304625636418124
Validation loss: 2.481515358349748

Epoch: 5| Step: 1
Training loss: 1.9809288679212573
Validation loss: 2.477349810873032

Epoch: 5| Step: 2
Training loss: 2.0970932188912066
Validation loss: 2.4676452133587623

Epoch: 5| Step: 3
Training loss: 2.0756001443359655
Validation loss: 2.4742042402883087

Epoch: 5| Step: 4
Training loss: 1.9582624693149324
Validation loss: 2.4703118568254516

Epoch: 5| Step: 5
Training loss: 2.088460132659469
Validation loss: 2.4817917908590856

Epoch: 5| Step: 6
Training loss: 2.292213952575615
Validation loss: 2.5024062646078633

Epoch: 5| Step: 7
Training loss: 2.573109875630629
Validation loss: 2.494444202477105

Epoch: 5| Step: 8
Training loss: 2.124292592501016
Validation loss: 2.5240932927964845

Epoch: 5| Step: 9
Training loss: 2.23885999723503
Validation loss: 2.541996858943355

Epoch: 5| Step: 10
Training loss: 2.433904294303818
Validation loss: 2.5533524027232017

Epoch: 220| Step: 0
Training loss: 2.1067704686815647
Validation loss: 2.5487423268293163

Epoch: 5| Step: 1
Training loss: 2.5841569100443533
Validation loss: 2.5276787126305353

Epoch: 5| Step: 2
Training loss: 2.1420835551858057
Validation loss: 2.517009611124065

Epoch: 5| Step: 3
Training loss: 1.9953463773308493
Validation loss: 2.4949180104677375

Epoch: 5| Step: 4
Training loss: 2.137339946264617
Validation loss: 2.504762304666696

Epoch: 5| Step: 5
Training loss: 2.334573813350979
Validation loss: 2.48799521697193

Epoch: 5| Step: 6
Training loss: 2.245129506001438
Validation loss: 2.494866120444748

Epoch: 5| Step: 7
Training loss: 2.156451893075957
Validation loss: 2.4836798296583873

Epoch: 5| Step: 8
Training loss: 2.3380885602104473
Validation loss: 2.4966883362255845

Epoch: 5| Step: 9
Training loss: 1.9104855493449777
Validation loss: 2.5300406460210816

Epoch: 5| Step: 10
Training loss: 1.7506825614598884
Validation loss: 2.544332737642472

Epoch: 221| Step: 0
Training loss: 2.064882001114793
Validation loss: 2.545752491798724

Epoch: 5| Step: 1
Training loss: 2.272276381935547
Validation loss: 2.5792102367984397

Epoch: 5| Step: 2
Training loss: 2.4237453006976226
Validation loss: 2.5977768351819606

Epoch: 5| Step: 3
Training loss: 2.245415679748322
Validation loss: 2.6016140331931634

Epoch: 5| Step: 4
Training loss: 2.0544811768884537
Validation loss: 2.564805416143447

Epoch: 5| Step: 5
Training loss: 2.351283465587864
Validation loss: 2.483813763604196

Epoch: 5| Step: 6
Training loss: 1.8179374557706522
Validation loss: 2.4466848513238784

Epoch: 5| Step: 7
Training loss: 1.9375298405472015
Validation loss: 2.4105882492666533

Epoch: 5| Step: 8
Training loss: 2.1593492873520015
Validation loss: 2.4050935486760094

Epoch: 5| Step: 9
Training loss: 2.487419805719669
Validation loss: 2.3969704695893985

Epoch: 5| Step: 10
Training loss: 1.8500080263118355
Validation loss: 2.406533526478428

Epoch: 222| Step: 0
Training loss: 1.5277436262224688
Validation loss: 2.3947895067827343

Epoch: 5| Step: 1
Training loss: 1.723996495249963
Validation loss: 2.4056296356592757

Epoch: 5| Step: 2
Training loss: 2.4280456687113907
Validation loss: 2.446852104102836

Epoch: 5| Step: 3
Training loss: 2.2162916506808585
Validation loss: 2.4979966791897503

Epoch: 5| Step: 4
Training loss: 2.207859660277342
Validation loss: 2.5550023943826408

Epoch: 5| Step: 5
Training loss: 2.0878433493390722
Validation loss: 2.5796765841435247

Epoch: 5| Step: 6
Training loss: 2.155580499620517
Validation loss: 2.5897799087302866

Epoch: 5| Step: 7
Training loss: 2.4481063336422078
Validation loss: 2.5679045098897046

Epoch: 5| Step: 8
Training loss: 2.1943428912050478
Validation loss: 2.529655333015147

Epoch: 5| Step: 9
Training loss: 2.546128239592651
Validation loss: 2.518206497342989

Epoch: 5| Step: 10
Training loss: 1.9513596147518772
Validation loss: 2.477540900220401

Epoch: 223| Step: 0
Training loss: 2.3587053371743463
Validation loss: 2.4633616217085255

Epoch: 5| Step: 1
Training loss: 2.588961029366485
Validation loss: 2.479036002172604

Epoch: 5| Step: 2
Training loss: 2.232914373851391
Validation loss: 2.485045514050917

Epoch: 5| Step: 3
Training loss: 1.9282890534434305
Validation loss: 2.489441073171739

Epoch: 5| Step: 4
Training loss: 1.9913200135263924
Validation loss: 2.5211746349529456

Epoch: 5| Step: 5
Training loss: 2.0093923802313807
Validation loss: 2.5114989550299143

Epoch: 5| Step: 6
Training loss: 2.2885649989979906
Validation loss: 2.534168296571971

Epoch: 5| Step: 7
Training loss: 2.2374773162885386
Validation loss: 2.5231017751643754

Epoch: 5| Step: 8
Training loss: 2.0790819531793088
Validation loss: 2.5052128516472774

Epoch: 5| Step: 9
Training loss: 1.677114672002745
Validation loss: 2.496301602066908

Epoch: 5| Step: 10
Training loss: 2.1109758871952042
Validation loss: 2.5125680875972907

Epoch: 224| Step: 0
Training loss: 2.042300404913217
Validation loss: 2.51465232784306

Epoch: 5| Step: 1
Training loss: 1.8168657931582373
Validation loss: 2.523992962107654

Epoch: 5| Step: 2
Training loss: 2.066664796746341
Validation loss: 2.5386954840735423

Epoch: 5| Step: 3
Training loss: 1.947679909854286
Validation loss: 2.533714958789739

Epoch: 5| Step: 4
Training loss: 2.6406125401310145
Validation loss: 2.557145960010375

Epoch: 5| Step: 5
Training loss: 1.7848727545810588
Validation loss: 2.544234580499003

Epoch: 5| Step: 6
Training loss: 2.396968826785111
Validation loss: 2.5570743987196654

Epoch: 5| Step: 7
Training loss: 2.264811507880788
Validation loss: 2.5589668914255115

Epoch: 5| Step: 8
Training loss: 1.9777561850327514
Validation loss: 2.555566485038143

Epoch: 5| Step: 9
Training loss: 2.0439867215033187
Validation loss: 2.5424060741208683

Epoch: 5| Step: 10
Training loss: 2.106251304014804
Validation loss: 2.5403981855307474

Epoch: 225| Step: 0
Training loss: 2.355187748837742
Validation loss: 2.5359256452279126

Epoch: 5| Step: 1
Training loss: 2.1483766859290654
Validation loss: 2.537507644780014

Epoch: 5| Step: 2
Training loss: 2.059121804308931
Validation loss: 2.508233716177151

Epoch: 5| Step: 3
Training loss: 1.7581630781045896
Validation loss: 2.5077925627510784

Epoch: 5| Step: 4
Training loss: 2.1865295437330996
Validation loss: 2.5176273306357504

Epoch: 5| Step: 5
Training loss: 2.0566975439877075
Validation loss: 2.5313183425717454

Epoch: 5| Step: 6
Training loss: 2.210637479989003
Validation loss: 2.5769870069934693

Epoch: 5| Step: 7
Training loss: 2.4182913569622255
Validation loss: 2.592749183009415

Epoch: 5| Step: 8
Training loss: 2.2499900393795365
Validation loss: 2.575128640134448

Epoch: 5| Step: 9
Training loss: 1.8438119392982515
Validation loss: 2.5649860327184704

Epoch: 5| Step: 10
Training loss: 1.7515318160895759
Validation loss: 2.5640048778745355

Epoch: 226| Step: 0
Training loss: 1.8451334402112138
Validation loss: 2.5387784823331128

Epoch: 5| Step: 1
Training loss: 2.109844805356937
Validation loss: 2.5211824707386

Epoch: 5| Step: 2
Training loss: 2.269951523754755
Validation loss: 2.5006397454222298

Epoch: 5| Step: 3
Training loss: 1.9044233857215496
Validation loss: 2.4913489366299526

Epoch: 5| Step: 4
Training loss: 1.9508800574759142
Validation loss: 2.4964158330212998

Epoch: 5| Step: 5
Training loss: 1.9228670614614696
Validation loss: 2.52040440306807

Epoch: 5| Step: 6
Training loss: 2.1320837543490363
Validation loss: 2.5315766999139204

Epoch: 5| Step: 7
Training loss: 2.0863850431350808
Validation loss: 2.5325762172179305

Epoch: 5| Step: 8
Training loss: 2.0958548825965524
Validation loss: 2.547282664622337

Epoch: 5| Step: 9
Training loss: 2.309853250540385
Validation loss: 2.561201693595997

Epoch: 5| Step: 10
Training loss: 2.4038962209329306
Validation loss: 2.586837966193588

Epoch: 227| Step: 0
Training loss: 1.9881843588253416
Validation loss: 2.5963728366917427

Epoch: 5| Step: 1
Training loss: 2.0951825834843096
Validation loss: 2.6012823507149494

Epoch: 5| Step: 2
Training loss: 2.281714300694523
Validation loss: 2.569875295542327

Epoch: 5| Step: 3
Training loss: 2.0380997412835127
Validation loss: 2.520819664388148

Epoch: 5| Step: 4
Training loss: 1.961916067636015
Validation loss: 2.461985683455749

Epoch: 5| Step: 5
Training loss: 1.977309074685621
Validation loss: 2.4358706901576235

Epoch: 5| Step: 6
Training loss: 1.6941823400525178
Validation loss: 2.44506480641787

Epoch: 5| Step: 7
Training loss: 1.7160862481554937
Validation loss: 2.430827418610895

Epoch: 5| Step: 8
Training loss: 1.9134706788937754
Validation loss: 2.441172277515087

Epoch: 5| Step: 9
Training loss: 2.8014861726761744
Validation loss: 2.4736806226383092

Epoch: 5| Step: 10
Training loss: 2.470660761895958
Validation loss: 2.515420140912367

Epoch: 228| Step: 0
Training loss: 1.7947895719398264
Validation loss: 2.5691881994531767

Epoch: 5| Step: 1
Training loss: 1.733911675778745
Validation loss: 2.5915591676979663

Epoch: 5| Step: 2
Training loss: 1.8803968960228226
Validation loss: 2.6127247071123003

Epoch: 5| Step: 3
Training loss: 2.19911196298659
Validation loss: 2.594183891329356

Epoch: 5| Step: 4
Training loss: 1.9314758415636966
Validation loss: 2.5692901408313595

Epoch: 5| Step: 5
Training loss: 1.7842237846048923
Validation loss: 2.5424478266155774

Epoch: 5| Step: 6
Training loss: 1.9057550256696139
Validation loss: 2.532777180474489

Epoch: 5| Step: 7
Training loss: 2.7673215673140312
Validation loss: 2.522799272846725

Epoch: 5| Step: 8
Training loss: 1.9096382546508903
Validation loss: 2.4865025224256896

Epoch: 5| Step: 9
Training loss: 2.215978584000151
Validation loss: 2.479717081513568

Epoch: 5| Step: 10
Training loss: 2.517474708771025
Validation loss: 2.474233811762365

Epoch: 229| Step: 0
Training loss: 1.9486465990432043
Validation loss: 2.4861614676451143

Epoch: 5| Step: 1
Training loss: 1.8324169411772737
Validation loss: 2.5086287003817236

Epoch: 5| Step: 2
Training loss: 2.124054530124436
Validation loss: 2.5380383244448264

Epoch: 5| Step: 3
Training loss: 1.6983021335649726
Validation loss: 2.5860367171543435

Epoch: 5| Step: 4
Training loss: 2.0647731161286575
Validation loss: 2.6034998404648246

Epoch: 5| Step: 5
Training loss: 1.8855927386888953
Validation loss: 2.607711935998526

Epoch: 5| Step: 6
Training loss: 1.992858893261369
Validation loss: 2.598795496793863

Epoch: 5| Step: 7
Training loss: 2.024577405185137
Validation loss: 2.5830369760165848

Epoch: 5| Step: 8
Training loss: 2.85175011422622
Validation loss: 2.5473433199316493

Epoch: 5| Step: 9
Training loss: 2.1196389733009324
Validation loss: 2.487069347112202

Epoch: 5| Step: 10
Training loss: 1.9256017264668641
Validation loss: 2.4784162431247547

Epoch: 230| Step: 0
Training loss: 2.7490667146626797
Validation loss: 2.4727446041946948

Epoch: 5| Step: 1
Training loss: 2.029121809926413
Validation loss: 2.486840828491264

Epoch: 5| Step: 2
Training loss: 1.8975409129158651
Validation loss: 2.4918580288943892

Epoch: 5| Step: 3
Training loss: 1.982821419577831
Validation loss: 2.5414803260291783

Epoch: 5| Step: 4
Training loss: 1.9962148013800773
Validation loss: 2.572229091650736

Epoch: 5| Step: 5
Training loss: 2.1635145464541035
Validation loss: 2.59367171622948

Epoch: 5| Step: 6
Training loss: 1.6728360275019327
Validation loss: 2.6155210858587177

Epoch: 5| Step: 7
Training loss: 1.9136428061475483
Validation loss: 2.608349995771357

Epoch: 5| Step: 8
Training loss: 1.6759902361401045
Validation loss: 2.5578428497770003

Epoch: 5| Step: 9
Training loss: 1.6306534505798778
Validation loss: 2.4885779350241912

Epoch: 5| Step: 10
Training loss: 2.623470133066702
Validation loss: 2.4633347296618893

Epoch: 231| Step: 0
Training loss: 1.9647309591329578
Validation loss: 2.448340846593084

Epoch: 5| Step: 1
Training loss: 2.3573330765302583
Validation loss: 2.4907743536653606

Epoch: 5| Step: 2
Training loss: 2.0544523967650674
Validation loss: 2.5241699349513276

Epoch: 5| Step: 3
Training loss: 1.8356771081549317
Validation loss: 2.5747427572834987

Epoch: 5| Step: 4
Training loss: 2.1840186618384902
Validation loss: 2.5965598096294977

Epoch: 5| Step: 5
Training loss: 1.6205247730785028
Validation loss: 2.6041277252895325

Epoch: 5| Step: 6
Training loss: 2.0561984348498576
Validation loss: 2.6094160650857434

Epoch: 5| Step: 7
Training loss: 1.481402824662643
Validation loss: 2.5915761220062743

Epoch: 5| Step: 8
Training loss: 2.2203820901551468
Validation loss: 2.5794106040899822

Epoch: 5| Step: 9
Training loss: 2.0151636349706212
Validation loss: 2.5427172617926033

Epoch: 5| Step: 10
Training loss: 2.4511205173902577
Validation loss: 2.5097222347857167

Epoch: 232| Step: 0
Training loss: 1.9360904488478825
Validation loss: 2.4724867420058194

Epoch: 5| Step: 1
Training loss: 1.9184427394320036
Validation loss: 2.4665277348692247

Epoch: 5| Step: 2
Training loss: 2.243652503145397
Validation loss: 2.4732776016605715

Epoch: 5| Step: 3
Training loss: 2.2765791641704145
Validation loss: 2.4568133127842446

Epoch: 5| Step: 4
Training loss: 1.844964936396183
Validation loss: 2.480701224605153

Epoch: 5| Step: 5
Training loss: 1.6125521363102422
Validation loss: 2.512362682818643

Epoch: 5| Step: 6
Training loss: 1.6681253328462384
Validation loss: 2.5226606837373966

Epoch: 5| Step: 7
Training loss: 2.2345275826807844
Validation loss: 2.536216766955286

Epoch: 5| Step: 8
Training loss: 1.7560861205617422
Validation loss: 2.5463684985589947

Epoch: 5| Step: 9
Training loss: 2.129823147770159
Validation loss: 2.559051101564997

Epoch: 5| Step: 10
Training loss: 2.474913713126309
Validation loss: 2.5682368615757216

Epoch: 233| Step: 0
Training loss: 2.1113254148340608
Validation loss: 2.5594208348147025

Epoch: 5| Step: 1
Training loss: 1.858061125908813
Validation loss: 2.569085550524231

Epoch: 5| Step: 2
Training loss: 1.8704431473841796
Validation loss: 2.5458115748779413

Epoch: 5| Step: 3
Training loss: 2.3846322537055054
Validation loss: 2.5112794052229614

Epoch: 5| Step: 4
Training loss: 1.9280834867438308
Validation loss: 2.474141726645223

Epoch: 5| Step: 5
Training loss: 2.0982233342958265
Validation loss: 2.4679796463760693

Epoch: 5| Step: 6
Training loss: 1.8990107169348591
Validation loss: 2.4564252205419854

Epoch: 5| Step: 7
Training loss: 2.122923004270708
Validation loss: 2.475832374142836

Epoch: 5| Step: 8
Training loss: 1.8828404847910545
Validation loss: 2.5031123876090677

Epoch: 5| Step: 9
Training loss: 1.9292319682901105
Validation loss: 2.5494382798163002

Epoch: 5| Step: 10
Training loss: 1.8229262942105326
Validation loss: 2.5603541071234117

Epoch: 234| Step: 0
Training loss: 1.9881653517723719
Validation loss: 2.579135694428315

Epoch: 5| Step: 1
Training loss: 1.5535005418612613
Validation loss: 2.589514965442218

Epoch: 5| Step: 2
Training loss: 1.9221737016986662
Validation loss: 2.5787655946565247

Epoch: 5| Step: 3
Training loss: 2.1124291808768336
Validation loss: 2.5729080601266316

Epoch: 5| Step: 4
Training loss: 2.080791168498621
Validation loss: 2.5496989466366933

Epoch: 5| Step: 5
Training loss: 1.5660883326409643
Validation loss: 2.555576798499501

Epoch: 5| Step: 6
Training loss: 1.7144841053810822
Validation loss: 2.538143737001257

Epoch: 5| Step: 7
Training loss: 2.393054002419522
Validation loss: 2.5225585429763577

Epoch: 5| Step: 8
Training loss: 2.0226034559047026
Validation loss: 2.523672069803501

Epoch: 5| Step: 9
Training loss: 1.825949197340304
Validation loss: 2.5028865710742356

Epoch: 5| Step: 10
Training loss: 2.4241003825738985
Validation loss: 2.5069193084635017

Epoch: 235| Step: 0
Training loss: 1.7633672812402368
Validation loss: 2.5023762105697283

Epoch: 5| Step: 1
Training loss: 1.9780221608022692
Validation loss: 2.508240519199062

Epoch: 5| Step: 2
Training loss: 1.9608469178452939
Validation loss: 2.5134882584948586

Epoch: 5| Step: 3
Training loss: 2.1645716539887205
Validation loss: 2.5090634649198953

Epoch: 5| Step: 4
Training loss: 2.1559041063714175
Validation loss: 2.5309918068245416

Epoch: 5| Step: 5
Training loss: 2.1010914100831957
Validation loss: 2.5259421667798883

Epoch: 5| Step: 6
Training loss: 1.7501454974044188
Validation loss: 2.540729389897422

Epoch: 5| Step: 7
Training loss: 2.2035852046287743
Validation loss: 2.513796244102225

Epoch: 5| Step: 8
Training loss: 1.7148007884976546
Validation loss: 2.521424802706777

Epoch: 5| Step: 9
Training loss: 1.6167398468968177
Validation loss: 2.5426811346835394

Epoch: 5| Step: 10
Training loss: 1.9916529517985093
Validation loss: 2.5660489615398556

Epoch: 236| Step: 0
Training loss: 1.6012552850592867
Validation loss: 2.573403055955344

Epoch: 5| Step: 1
Training loss: 1.7461037176816305
Validation loss: 2.598150421467131

Epoch: 5| Step: 2
Training loss: 2.047427619707391
Validation loss: 2.586894336997589

Epoch: 5| Step: 3
Training loss: 2.043788533911984
Validation loss: 2.592816756859731

Epoch: 5| Step: 4
Training loss: 2.0027052941023635
Validation loss: 2.569625511836581

Epoch: 5| Step: 5
Training loss: 1.761344717712824
Validation loss: 2.5391968596115957

Epoch: 5| Step: 6
Training loss: 1.7992047009932055
Validation loss: 2.5358417650442995

Epoch: 5| Step: 7
Training loss: 2.2258310287655987
Validation loss: 2.5359336730019537

Epoch: 5| Step: 8
Training loss: 2.038777766316384
Validation loss: 2.5508469979528425

Epoch: 5| Step: 9
Training loss: 2.0871072411102345
Validation loss: 2.5507917325597593

Epoch: 5| Step: 10
Training loss: 1.8954247324295264
Validation loss: 2.527611854900087

Epoch: 237| Step: 0
Training loss: 2.180456210530553
Validation loss: 2.539818751793327

Epoch: 5| Step: 1
Training loss: 1.980001300368219
Validation loss: 2.5427970578128227

Epoch: 5| Step: 2
Training loss: 1.828361691533472
Validation loss: 2.5541435054628314

Epoch: 5| Step: 3
Training loss: 1.725287056963148
Validation loss: 2.531213757837729

Epoch: 5| Step: 4
Training loss: 1.4780629925292912
Validation loss: 2.5161806212829885

Epoch: 5| Step: 5
Training loss: 2.0868073553527866
Validation loss: 2.5168551061185305

Epoch: 5| Step: 6
Training loss: 1.6606423059149673
Validation loss: 2.5116962792982633

Epoch: 5| Step: 7
Training loss: 1.8027673720360073
Validation loss: 2.5116790526958432

Epoch: 5| Step: 8
Training loss: 2.3127414474221957
Validation loss: 2.5278875617920855

Epoch: 5| Step: 9
Training loss: 2.1955876839732764
Validation loss: 2.5253780747166426

Epoch: 5| Step: 10
Training loss: 1.6478454105035838
Validation loss: 2.518807588720604

Epoch: 238| Step: 0
Training loss: 1.8861754841681688
Validation loss: 2.5392454918485

Epoch: 5| Step: 1
Training loss: 1.7083709138908039
Validation loss: 2.560442187527352

Epoch: 5| Step: 2
Training loss: 1.9584368076448022
Validation loss: 2.5550549629746477

Epoch: 5| Step: 3
Training loss: 1.4683776545826557
Validation loss: 2.551704290861234

Epoch: 5| Step: 4
Training loss: 2.3911959894983243
Validation loss: 2.5517756511223775

Epoch: 5| Step: 5
Training loss: 1.8791918626718715
Validation loss: 2.5694423628597884

Epoch: 5| Step: 6
Training loss: 1.7939655799115402
Validation loss: 2.5829932584084454

Epoch: 5| Step: 7
Training loss: 1.5068137067735934
Validation loss: 2.5772138519969725

Epoch: 5| Step: 8
Training loss: 1.9191160169778934
Validation loss: 2.5714925024802002

Epoch: 5| Step: 9
Training loss: 2.0291985349352464
Validation loss: 2.5748374444817723

Epoch: 5| Step: 10
Training loss: 2.283751592358899
Validation loss: 2.573363566030016

Epoch: 239| Step: 0
Training loss: 2.2519314211538135
Validation loss: 2.567786897805531

Epoch: 5| Step: 1
Training loss: 1.7476278303595607
Validation loss: 2.5560770331646148

Epoch: 5| Step: 2
Training loss: 1.812958757944541
Validation loss: 2.583266499184404

Epoch: 5| Step: 3
Training loss: 1.404385411385624
Validation loss: 2.5481142016009146

Epoch: 5| Step: 4
Training loss: 2.2581262073571686
Validation loss: 2.5356223848052437

Epoch: 5| Step: 5
Training loss: 2.1288598851745895
Validation loss: 2.5127292180556724

Epoch: 5| Step: 6
Training loss: 2.0131572432069147
Validation loss: 2.518947591267746

Epoch: 5| Step: 7
Training loss: 1.5622108954951581
Validation loss: 2.511638601484505

Epoch: 5| Step: 8
Training loss: 1.5750052709339892
Validation loss: 2.5147080581818004

Epoch: 5| Step: 9
Training loss: 1.8122828123258816
Validation loss: 2.5036005733238564

Epoch: 5| Step: 10
Training loss: 2.0677824863874688
Validation loss: 2.4845156344425416

Epoch: 240| Step: 0
Training loss: 1.9114195969595136
Validation loss: 2.4944765879028434

Epoch: 5| Step: 1
Training loss: 1.9367476202262142
Validation loss: 2.495742208469788

Epoch: 5| Step: 2
Training loss: 1.531550942256511
Validation loss: 2.5099287386507787

Epoch: 5| Step: 3
Training loss: 1.7785819969804344
Validation loss: 2.501625211624632

Epoch: 5| Step: 4
Training loss: 1.9055703624425635
Validation loss: 2.5208184948529144

Epoch: 5| Step: 5
Training loss: 2.3499067693843907
Validation loss: 2.5122253088838953

Epoch: 5| Step: 6
Training loss: 1.7704914510973537
Validation loss: 2.531579568793937

Epoch: 5| Step: 7
Training loss: 1.3757184925745027
Validation loss: 2.557494671212126

Epoch: 5| Step: 8
Training loss: 2.3604585294274347
Validation loss: 2.579521072176988

Epoch: 5| Step: 9
Training loss: 1.754244153749516
Validation loss: 2.5206757688353143

Epoch: 5| Step: 10
Training loss: 1.7084110366393341
Validation loss: 2.492398378889221

Epoch: 241| Step: 0
Training loss: 1.7974864416977276
Validation loss: 2.4694974138356938

Epoch: 5| Step: 1
Training loss: 2.1238191352893936
Validation loss: 2.4572239147534085

Epoch: 5| Step: 2
Training loss: 1.7792730905595084
Validation loss: 2.480124167596541

Epoch: 5| Step: 3
Training loss: 2.55681938787875
Validation loss: 2.49045766486865

Epoch: 5| Step: 4
Training loss: 1.9125932932519805
Validation loss: 2.5040599537839414

Epoch: 5| Step: 5
Training loss: 1.8391800187384877
Validation loss: 2.5086307396403864

Epoch: 5| Step: 6
Training loss: 1.7519306704507922
Validation loss: 2.5688535028682433

Epoch: 5| Step: 7
Training loss: 1.5794710518507908
Validation loss: 2.6394294167552905

Epoch: 5| Step: 8
Training loss: 1.9612227760501797
Validation loss: 2.6987340001615054

Epoch: 5| Step: 9
Training loss: 1.8189674614485867
Validation loss: 2.697975484612539

Epoch: 5| Step: 10
Training loss: 1.2833744207633362
Validation loss: 2.6440948913001017

Epoch: 242| Step: 0
Training loss: 1.8473580182226332
Validation loss: 2.588569147923085

Epoch: 5| Step: 1
Training loss: 2.0288920875381113
Validation loss: 2.5024418646939326

Epoch: 5| Step: 2
Training loss: 1.8658584269780885
Validation loss: 2.4570621664801044

Epoch: 5| Step: 3
Training loss: 1.6972042375531902
Validation loss: 2.441368078708653

Epoch: 5| Step: 4
Training loss: 2.0211348816616335
Validation loss: 2.4291190783041854

Epoch: 5| Step: 5
Training loss: 1.8416152492382352
Validation loss: 2.4146899456509074

Epoch: 5| Step: 6
Training loss: 2.116570977678813
Validation loss: 2.420633056485216

Epoch: 5| Step: 7
Training loss: 1.9894180495493659
Validation loss: 2.42718532122111

Epoch: 5| Step: 8
Training loss: 1.5607334068451382
Validation loss: 2.5016831997225357

Epoch: 5| Step: 9
Training loss: 1.9926934291709633
Validation loss: 2.54067065228675

Epoch: 5| Step: 10
Training loss: 1.4625899817018386
Validation loss: 2.6055270166645497

Epoch: 243| Step: 0
Training loss: 1.8123443799791048
Validation loss: 2.626090902722832

Epoch: 5| Step: 1
Training loss: 1.9625424204329702
Validation loss: 2.64804376909797

Epoch: 5| Step: 2
Training loss: 1.8643180473751786
Validation loss: 2.6506797752559885

Epoch: 5| Step: 3
Training loss: 2.1164827757525866
Validation loss: 2.599699189301895

Epoch: 5| Step: 4
Training loss: 1.9074583132527103
Validation loss: 2.545597813342916

Epoch: 5| Step: 5
Training loss: 1.8226516167638618
Validation loss: 2.525953229432907

Epoch: 5| Step: 6
Training loss: 1.4896604700279004
Validation loss: 2.4606082964966816

Epoch: 5| Step: 7
Training loss: 1.660239901959568
Validation loss: 2.472926412929263

Epoch: 5| Step: 8
Training loss: 1.7849769418760497
Validation loss: 2.472867537967315

Epoch: 5| Step: 9
Training loss: 1.8716549599140722
Validation loss: 2.5086496079417744

Epoch: 5| Step: 10
Training loss: 2.064809719675592
Validation loss: 2.5236403226513886

Epoch: 244| Step: 0
Training loss: 1.5051938576535722
Validation loss: 2.552887607302636

Epoch: 5| Step: 1
Training loss: 1.542607132268734
Validation loss: 2.6223082739155754

Epoch: 5| Step: 2
Training loss: 1.9889825509688293
Validation loss: 2.659994023355127

Epoch: 5| Step: 3
Training loss: 1.8576217206912278
Validation loss: 2.6395116863046226

Epoch: 5| Step: 4
Training loss: 1.8290532029862467
Validation loss: 2.6276271953252732

Epoch: 5| Step: 5
Training loss: 1.8233294065155388
Validation loss: 2.546671481959326

Epoch: 5| Step: 6
Training loss: 1.8312389881206546
Validation loss: 2.513733967513595

Epoch: 5| Step: 7
Training loss: 2.146440611402703
Validation loss: 2.4710088105361727

Epoch: 5| Step: 8
Training loss: 1.8306719000927458
Validation loss: 2.4539325368090004

Epoch: 5| Step: 9
Training loss: 1.516855428637792
Validation loss: 2.4871837474911778

Epoch: 5| Step: 10
Training loss: 2.250858566931756
Validation loss: 2.4887743103181936

Epoch: 245| Step: 0
Training loss: 1.9573078987892636
Validation loss: 2.482456671141243

Epoch: 5| Step: 1
Training loss: 2.125368983826886
Validation loss: 2.534788655333725

Epoch: 5| Step: 2
Training loss: 1.7526749194649682
Validation loss: 2.55066203523926

Epoch: 5| Step: 3
Training loss: 1.5455404362295901
Validation loss: 2.574214322265928

Epoch: 5| Step: 4
Training loss: 1.4509213052832175
Validation loss: 2.6091198559749422

Epoch: 5| Step: 5
Training loss: 2.221423083567116
Validation loss: 2.6046858176951035

Epoch: 5| Step: 6
Training loss: 1.9730418819771385
Validation loss: 2.618748441345188

Epoch: 5| Step: 7
Training loss: 1.2452179991357755
Validation loss: 2.6185884240692623

Epoch: 5| Step: 8
Training loss: 2.1232898787159558
Validation loss: 2.624328612388325

Epoch: 5| Step: 9
Training loss: 1.5043670344726245
Validation loss: 2.5771777588384226

Epoch: 5| Step: 10
Training loss: 1.770251197123894
Validation loss: 2.563158155348673

Epoch: 246| Step: 0
Training loss: 1.875263259208173
Validation loss: 2.52072768641276

Epoch: 5| Step: 1
Training loss: 1.781366913288133
Validation loss: 2.52827159381995

Epoch: 5| Step: 2
Training loss: 1.4329311908245768
Validation loss: 2.5169121525611065

Epoch: 5| Step: 3
Training loss: 1.8059338646076695
Validation loss: 2.4994744835490836

Epoch: 5| Step: 4
Training loss: 2.079588754603935
Validation loss: 2.523682717789336

Epoch: 5| Step: 5
Training loss: 1.9082492912588025
Validation loss: 2.5541055565985653

Epoch: 5| Step: 6
Training loss: 1.4375515804158825
Validation loss: 2.570610131139101

Epoch: 5| Step: 7
Training loss: 1.6874901806580993
Validation loss: 2.5943776110305685

Epoch: 5| Step: 8
Training loss: 1.5165130530454967
Validation loss: 2.614203340431751

Epoch: 5| Step: 9
Training loss: 1.8704558939767213
Validation loss: 2.5880010342394053

Epoch: 5| Step: 10
Training loss: 2.176396883806698
Validation loss: 2.572758164608781

Epoch: 247| Step: 0
Training loss: 1.96764003405587
Validation loss: 2.530506890388749

Epoch: 5| Step: 1
Training loss: 1.5664396591619123
Validation loss: 2.5003370447509226

Epoch: 5| Step: 2
Training loss: 2.10941546365993
Validation loss: 2.4900542284256137

Epoch: 5| Step: 3
Training loss: 1.6574186844247734
Validation loss: 2.474057562003311

Epoch: 5| Step: 4
Training loss: 1.6882705342148212
Validation loss: 2.5004360746690284

Epoch: 5| Step: 5
Training loss: 1.6392496793070903
Validation loss: 2.5265071262876306

Epoch: 5| Step: 6
Training loss: 1.9020317808799345
Validation loss: 2.571604405304204

Epoch: 5| Step: 7
Training loss: 1.6758897297211093
Validation loss: 2.58878235287987

Epoch: 5| Step: 8
Training loss: 1.7932348116267782
Validation loss: 2.6150102634895553

Epoch: 5| Step: 9
Training loss: 1.591996593466905
Validation loss: 2.622171483643373

Epoch: 5| Step: 10
Training loss: 1.863768315983197
Validation loss: 2.610788608039097

Epoch: 248| Step: 0
Training loss: 2.0799013734322997
Validation loss: 2.5963862227455525

Epoch: 5| Step: 1
Training loss: 1.5388880596931387
Validation loss: 2.570659238665384

Epoch: 5| Step: 2
Training loss: 1.826434405218584
Validation loss: 2.5530499129455357

Epoch: 5| Step: 3
Training loss: 2.3032865760057946
Validation loss: 2.5419800711559177

Epoch: 5| Step: 4
Training loss: 1.6917526207620743
Validation loss: 2.5620063528349246

Epoch: 5| Step: 5
Training loss: 1.4994257781512796
Validation loss: 2.5471254788390643

Epoch: 5| Step: 6
Training loss: 1.2863238749591714
Validation loss: 2.5427064011293603

Epoch: 5| Step: 7
Training loss: 1.3437193490014647
Validation loss: 2.556151456658688

Epoch: 5| Step: 8
Training loss: 1.8792315734796219
Validation loss: 2.5588177852556018

Epoch: 5| Step: 9
Training loss: 1.5839031683146827
Validation loss: 2.54862505563878

Epoch: 5| Step: 10
Training loss: 1.9821537832501495
Validation loss: 2.5414487730889284

Epoch: 249| Step: 0
Training loss: 1.6625329810291414
Validation loss: 2.533056243907162

Epoch: 5| Step: 1
Training loss: 1.962280664518089
Validation loss: 2.5288877150456583

Epoch: 5| Step: 2
Training loss: 1.3842782049159579
Validation loss: 2.509825514888858

Epoch: 5| Step: 3
Training loss: 1.9043435741469488
Validation loss: 2.509610407396979

Epoch: 5| Step: 4
Training loss: 1.3132628539985138
Validation loss: 2.520411171713483

Epoch: 5| Step: 5
Training loss: 2.0613171046376104
Validation loss: 2.5100822779177405

Epoch: 5| Step: 6
Training loss: 1.7594674013309923
Validation loss: 2.5137371851496426

Epoch: 5| Step: 7
Training loss: 1.6627026943462795
Validation loss: 2.5060831866660007

Epoch: 5| Step: 8
Training loss: 1.3387255214586782
Validation loss: 2.5347778547580577

Epoch: 5| Step: 9
Training loss: 2.1198909152054513
Validation loss: 2.5507537820719635

Epoch: 5| Step: 10
Training loss: 1.81313727126494
Validation loss: 2.557623402094079

Epoch: 250| Step: 0
Training loss: 1.8635150115010073
Validation loss: 2.56549584647689

Epoch: 5| Step: 1
Training loss: 1.4563109225516748
Validation loss: 2.537085124919869

Epoch: 5| Step: 2
Training loss: 1.6704267842776228
Validation loss: 2.5323621007617394

Epoch: 5| Step: 3
Training loss: 1.4357345354594753
Validation loss: 2.5037864784522945

Epoch: 5| Step: 4
Training loss: 1.8625641728553006
Validation loss: 2.5062548500095736

Epoch: 5| Step: 5
Training loss: 1.7092566747352351
Validation loss: 2.4927677653370632

Epoch: 5| Step: 6
Training loss: 1.7444930622928305
Validation loss: 2.519692989244587

Epoch: 5| Step: 7
Training loss: 1.8692212381388607
Validation loss: 2.505101929221076

Epoch: 5| Step: 8
Training loss: 1.4162094930594877
Validation loss: 2.5128239557030123

Epoch: 5| Step: 9
Training loss: 1.8719207910913638
Validation loss: 2.494036443535292

Epoch: 5| Step: 10
Training loss: 2.0702581434491636
Validation loss: 2.4883339815249026

Testing loss: 2.5680032783809557
