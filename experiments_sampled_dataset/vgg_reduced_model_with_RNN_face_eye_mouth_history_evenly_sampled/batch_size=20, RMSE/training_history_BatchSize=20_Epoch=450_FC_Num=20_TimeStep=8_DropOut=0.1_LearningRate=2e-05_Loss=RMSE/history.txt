Epoch: 1| Step: 0
Training loss: 6.540659573860484
Validation loss: 5.835714511087296

Epoch: 5| Step: 1
Training loss: 6.213229235212304
Validation loss: 5.820474604510022

Epoch: 5| Step: 2
Training loss: 5.90699981289578
Validation loss: 5.803897305976082

Epoch: 5| Step: 3
Training loss: 6.544000035330252
Validation loss: 5.78695115396995

Epoch: 5| Step: 4
Training loss: 6.013540565714847
Validation loss: 5.7678650639275375

Epoch: 5| Step: 5
Training loss: 5.822873938260978
Validation loss: 5.746169898998497

Epoch: 5| Step: 6
Training loss: 5.599821918925783
Validation loss: 5.721975420110875

Epoch: 5| Step: 7
Training loss: 5.513720305091944
Validation loss: 5.693339121094827

Epoch: 5| Step: 8
Training loss: 4.567417995341026
Validation loss: 5.661214526774303

Epoch: 5| Step: 9
Training loss: 4.188696163768406
Validation loss: 5.625963259385

Epoch: 5| Step: 10
Training loss: 6.178140670918574
Validation loss: 5.586662337127009

Epoch: 2| Step: 0
Training loss: 6.172976933868635
Validation loss: 5.544330804349502

Epoch: 5| Step: 1
Training loss: 5.2724315446775165
Validation loss: 5.498802761383876

Epoch: 5| Step: 2
Training loss: 5.193376085613863
Validation loss: 5.451474313053811

Epoch: 5| Step: 3
Training loss: 5.317609237459945
Validation loss: 5.403563548555104

Epoch: 5| Step: 4
Training loss: 5.057715333058869
Validation loss: 5.354516121816169

Epoch: 5| Step: 5
Training loss: 4.9647436724645075
Validation loss: 5.305219835324665

Epoch: 5| Step: 6
Training loss: 3.9749346025953267
Validation loss: 5.253386238012482

Epoch: 5| Step: 7
Training loss: 6.160325303839165
Validation loss: 5.205208264722778

Epoch: 5| Step: 8
Training loss: 5.618032590831989
Validation loss: 5.157115095299604

Epoch: 5| Step: 9
Training loss: 4.950831318415949
Validation loss: 5.1121182344880385

Epoch: 5| Step: 10
Training loss: 5.9300731588807345
Validation loss: 5.067231370066911

Epoch: 3| Step: 0
Training loss: 6.134712148565078
Validation loss: 5.021850996807959

Epoch: 5| Step: 1
Training loss: 4.2621407723845826
Validation loss: 4.976988169066708

Epoch: 5| Step: 2
Training loss: 5.525873016842371
Validation loss: 4.925571377815151

Epoch: 5| Step: 3
Training loss: 4.5574835804085305
Validation loss: 4.872106332260819

Epoch: 5| Step: 4
Training loss: 5.159638742028572
Validation loss: 4.824000131257582

Epoch: 5| Step: 5
Training loss: 3.9902728541493904
Validation loss: 4.778681305873833

Epoch: 5| Step: 6
Training loss: 5.619101250079285
Validation loss: 4.73877801482245

Epoch: 5| Step: 7
Training loss: 4.4713003710393515
Validation loss: 4.699583941851381

Epoch: 5| Step: 8
Training loss: 4.9397962035485605
Validation loss: 4.654894753590038

Epoch: 5| Step: 9
Training loss: 3.9305655558308756
Validation loss: 4.607609487787102

Epoch: 5| Step: 10
Training loss: 4.489143414934915
Validation loss: 4.575091763719304

Epoch: 4| Step: 0
Training loss: 4.0082029632071645
Validation loss: 4.543891347571721

Epoch: 5| Step: 1
Training loss: 4.054399601411988
Validation loss: 4.509035621408826

Epoch: 5| Step: 2
Training loss: 4.988763581259604
Validation loss: 4.47717036609093

Epoch: 5| Step: 3
Training loss: 4.819050875719558
Validation loss: 4.437214295801574

Epoch: 5| Step: 4
Training loss: 4.439938157484309
Validation loss: 4.407934579695837

Epoch: 5| Step: 5
Training loss: 4.606400076130703
Validation loss: 4.3834859933654045

Epoch: 5| Step: 6
Training loss: 4.503851196270202
Validation loss: 4.363205202896909

Epoch: 5| Step: 7
Training loss: 5.400238045991041
Validation loss: 4.35831511952951

Epoch: 5| Step: 8
Training loss: 4.8705866472459025
Validation loss: 4.333935870046985

Epoch: 5| Step: 9
Training loss: 3.853613379002764
Validation loss: 4.318450137656952

Epoch: 5| Step: 10
Training loss: 3.741640309762765
Validation loss: 4.30510366906426

Epoch: 5| Step: 0
Training loss: 4.797143189329526
Validation loss: 4.293204767375648

Epoch: 5| Step: 1
Training loss: 3.7667647413690823
Validation loss: 4.2899328425727745

Epoch: 5| Step: 2
Training loss: 5.440116515875265
Validation loss: 4.284672585154074

Epoch: 5| Step: 3
Training loss: 3.7443149707142096
Validation loss: 4.272745513036089

Epoch: 5| Step: 4
Training loss: 4.6900269881328045
Validation loss: 4.274805008128632

Epoch: 5| Step: 5
Training loss: 3.8436574537099375
Validation loss: 4.260900577915696

Epoch: 5| Step: 6
Training loss: 4.354011983116387
Validation loss: 4.239177259412777

Epoch: 5| Step: 7
Training loss: 4.529659228781105
Validation loss: 4.224746631554846

Epoch: 5| Step: 8
Training loss: 4.0059984053762365
Validation loss: 4.227752399773115

Epoch: 5| Step: 9
Training loss: 3.620653769749042
Validation loss: 4.212060470438584

Epoch: 5| Step: 10
Training loss: 5.110249389116907
Validation loss: 4.19133838653329

Epoch: 6| Step: 0
Training loss: 3.3774571834083753
Validation loss: 4.175947465994581

Epoch: 5| Step: 1
Training loss: 3.772868680236314
Validation loss: 4.172555068329798

Epoch: 5| Step: 2
Training loss: 4.49347552865932
Validation loss: 4.167722235251172

Epoch: 5| Step: 3
Training loss: 4.114603060260595
Validation loss: 4.1579672551642926

Epoch: 5| Step: 4
Training loss: 5.033151587095469
Validation loss: 4.141473377294883

Epoch: 5| Step: 5
Training loss: 4.42198110931654
Validation loss: 4.117230112682228

Epoch: 5| Step: 6
Training loss: 4.5378307043366775
Validation loss: 4.10324330694908

Epoch: 5| Step: 7
Training loss: 4.080486213285913
Validation loss: 4.090740005008488

Epoch: 5| Step: 8
Training loss: 3.9024358820611815
Validation loss: 4.089758076355992

Epoch: 5| Step: 9
Training loss: 4.378715898934753
Validation loss: 4.088691582748626

Epoch: 5| Step: 10
Training loss: 4.603513553377769
Validation loss: 4.058004957147076

Epoch: 7| Step: 0
Training loss: 4.318755326219468
Validation loss: 4.050463954248733

Epoch: 5| Step: 1
Training loss: 3.808015030150043
Validation loss: 4.050059104942895

Epoch: 5| Step: 2
Training loss: 3.9007660480235895
Validation loss: 4.045550963882529

Epoch: 5| Step: 3
Training loss: 3.1440888845968726
Validation loss: 4.033635887107724

Epoch: 5| Step: 4
Training loss: 4.851667270972685
Validation loss: 4.014659353228769

Epoch: 5| Step: 5
Training loss: 4.050676246981648
Validation loss: 3.998171290894981

Epoch: 5| Step: 6
Training loss: 4.635191128276621
Validation loss: 3.9927485799593194

Epoch: 5| Step: 7
Training loss: 4.2258726674659455
Validation loss: 3.9765098054631127

Epoch: 5| Step: 8
Training loss: 3.7904817734946716
Validation loss: 3.9642253156400216

Epoch: 5| Step: 9
Training loss: 4.529833552521528
Validation loss: 3.9579461694738187

Epoch: 5| Step: 10
Training loss: 4.170054292028092
Validation loss: 3.9483201716862526

Epoch: 8| Step: 0
Training loss: 3.8365294083326114
Validation loss: 3.9377794506772803

Epoch: 5| Step: 1
Training loss: 4.544882006566648
Validation loss: 3.927954790244606

Epoch: 5| Step: 2
Training loss: 4.253141027864615
Validation loss: 3.914214824898716

Epoch: 5| Step: 3
Training loss: 4.293168234247155
Validation loss: 3.9036076412425817

Epoch: 5| Step: 4
Training loss: 3.1725652535583784
Validation loss: 3.8934103209943633

Epoch: 5| Step: 5
Training loss: 4.298406598483753
Validation loss: 3.8852415207291537

Epoch: 5| Step: 6
Training loss: 3.656442229605492
Validation loss: 3.878524971210827

Epoch: 5| Step: 7
Training loss: 4.367549546849979
Validation loss: 3.867312514313714

Epoch: 5| Step: 8
Training loss: 3.659676405354268
Validation loss: 3.852722551052662

Epoch: 5| Step: 9
Training loss: 4.485993096708989
Validation loss: 3.848479785676635

Epoch: 5| Step: 10
Training loss: 3.73822104346763
Validation loss: 3.8367158221160187

Epoch: 9| Step: 0
Training loss: 4.6174622016685625
Validation loss: 3.827364265908985

Epoch: 5| Step: 1
Training loss: 4.032738462564401
Validation loss: 3.8184570635702957

Epoch: 5| Step: 2
Training loss: 4.200478099677362
Validation loss: 3.812686730674777

Epoch: 5| Step: 3
Training loss: 3.616019074668199
Validation loss: 3.804352188739684

Epoch: 5| Step: 4
Training loss: 3.9771593766347006
Validation loss: 3.7979013897385476

Epoch: 5| Step: 5
Training loss: 4.349202856929377
Validation loss: 3.789900239233301

Epoch: 5| Step: 6
Training loss: 3.5272368185705627
Validation loss: 3.779971375811416

Epoch: 5| Step: 7
Training loss: 3.916041682815423
Validation loss: 3.7702895969986323

Epoch: 5| Step: 8
Training loss: 3.642469470983374
Validation loss: 3.7608313030928207

Epoch: 5| Step: 9
Training loss: 4.041738188330339
Validation loss: 3.750568605199305

Epoch: 5| Step: 10
Training loss: 3.46766989447818
Validation loss: 3.740381810577193

Epoch: 10| Step: 0
Training loss: 4.199504214497589
Validation loss: 3.734404141722606

Epoch: 5| Step: 1
Training loss: 3.7282145614929836
Validation loss: 3.725810325837888

Epoch: 5| Step: 2
Training loss: 2.7157686044104374
Validation loss: 3.718701639513291

Epoch: 5| Step: 3
Training loss: 3.6839036376312206
Validation loss: 3.7087298922423946

Epoch: 5| Step: 4
Training loss: 3.8752601290113264
Validation loss: 3.704979521436424

Epoch: 5| Step: 5
Training loss: 4.393854114498135
Validation loss: 3.7002266314740164

Epoch: 5| Step: 6
Training loss: 4.45530288711306
Validation loss: 3.69393480143059

Epoch: 5| Step: 7
Training loss: 3.376882240164799
Validation loss: 3.685605257049906

Epoch: 5| Step: 8
Training loss: 3.691596003100808
Validation loss: 3.6780560938799276

Epoch: 5| Step: 9
Training loss: 3.846886448413166
Validation loss: 3.6705338639418197

Epoch: 5| Step: 10
Training loss: 4.507500437706341
Validation loss: 3.664947553302836

Epoch: 11| Step: 0
Training loss: 3.8517146515728697
Validation loss: 3.658731411377562

Epoch: 5| Step: 1
Training loss: 3.9043524443816198
Validation loss: 3.650998443356557

Epoch: 5| Step: 2
Training loss: 3.7544445402139037
Validation loss: 3.643880642656262

Epoch: 5| Step: 3
Training loss: 4.715697254716902
Validation loss: 3.6369395534814384

Epoch: 5| Step: 4
Training loss: 3.2893544699499158
Validation loss: 3.626949016899537

Epoch: 5| Step: 5
Training loss: 3.1359412344856623
Validation loss: 3.6207587126546072

Epoch: 5| Step: 6
Training loss: 3.0916460377569615
Validation loss: 3.6145164599640442

Epoch: 5| Step: 7
Training loss: 4.374309376293731
Validation loss: 3.6088318220948508

Epoch: 5| Step: 8
Training loss: 4.125022656927597
Validation loss: 3.602258099502158

Epoch: 5| Step: 9
Training loss: 3.286857826549278
Validation loss: 3.5947928878526274

Epoch: 5| Step: 10
Training loss: 4.181191318254135
Validation loss: 3.5862034185159084

Epoch: 12| Step: 0
Training loss: 4.013824415440751
Validation loss: 3.5776795233864407

Epoch: 5| Step: 1
Training loss: 3.525470967315124
Validation loss: 3.572346675604621

Epoch: 5| Step: 2
Training loss: 3.9386343154697787
Validation loss: 3.5704845764780173

Epoch: 5| Step: 3
Training loss: 3.375899866020245
Validation loss: 3.5573651451483466

Epoch: 5| Step: 4
Training loss: 3.425211077123797
Validation loss: 3.548864946510639

Epoch: 5| Step: 5
Training loss: 3.096592223713574
Validation loss: 3.5432086032218155

Epoch: 5| Step: 6
Training loss: 4.319133135394157
Validation loss: 3.539378465141272

Epoch: 5| Step: 7
Training loss: 4.094829853701094
Validation loss: 3.528493528647837

Epoch: 5| Step: 8
Training loss: 3.846663448612271
Validation loss: 3.520630183253641

Epoch: 5| Step: 9
Training loss: 3.6037010083158156
Validation loss: 3.5189882222610835

Epoch: 5| Step: 10
Training loss: 3.850874090671757
Validation loss: 3.5120356626854323

Epoch: 13| Step: 0
Training loss: 3.4346438940440454
Validation loss: 3.5001365734590686

Epoch: 5| Step: 1
Training loss: 3.423826175216929
Validation loss: 3.4933340535879

Epoch: 5| Step: 2
Training loss: 4.553933658671163
Validation loss: 3.489957456533063

Epoch: 5| Step: 3
Training loss: 3.292835237414231
Validation loss: 3.4786438755800346

Epoch: 5| Step: 4
Training loss: 3.6150594758645513
Validation loss: 3.4692095831123626

Epoch: 5| Step: 5
Training loss: 4.105446914338934
Validation loss: 3.464502338514427

Epoch: 5| Step: 6
Training loss: 3.414679499899827
Validation loss: 3.456475567024688

Epoch: 5| Step: 7
Training loss: 3.6069676681774325
Validation loss: 3.4491114077962752

Epoch: 5| Step: 8
Training loss: 2.973033184360312
Validation loss: 3.442053529933412

Epoch: 5| Step: 9
Training loss: 4.114611636036295
Validation loss: 3.441125855138861

Epoch: 5| Step: 10
Training loss: 3.740856977390738
Validation loss: 3.4416928387731605

Epoch: 14| Step: 0
Training loss: 3.5076360509456443
Validation loss: 3.4323560364574295

Epoch: 5| Step: 1
Training loss: 4.127570305172949
Validation loss: 3.4191453248062977

Epoch: 5| Step: 2
Training loss: 3.0805507338447624
Validation loss: 3.412778456761537

Epoch: 5| Step: 3
Training loss: 3.9121338743070244
Validation loss: 3.4117243927539973

Epoch: 5| Step: 4
Training loss: 3.5387880332571107
Validation loss: 3.397611849239489

Epoch: 5| Step: 5
Training loss: 3.228928112119386
Validation loss: 3.38923282092337

Epoch: 5| Step: 6
Training loss: 2.964986724823797
Validation loss: 3.3858282271022953

Epoch: 5| Step: 7
Training loss: 4.116973929321972
Validation loss: 3.3868872001472163

Epoch: 5| Step: 8
Training loss: 3.9834672679224283
Validation loss: 3.371166338307996

Epoch: 5| Step: 9
Training loss: 3.9235929700643988
Validation loss: 3.3856056850980147

Epoch: 5| Step: 10
Training loss: 3.2191831426933715
Validation loss: 3.360478172402839

Epoch: 15| Step: 0
Training loss: 3.870650896441267
Validation loss: 3.3581956789440683

Epoch: 5| Step: 1
Training loss: 3.639448900948096
Validation loss: 3.3558681780864816

Epoch: 5| Step: 2
Training loss: 3.224041487320362
Validation loss: 3.3493694183953577

Epoch: 5| Step: 3
Training loss: 4.114925682537017
Validation loss: 3.3430378872165614

Epoch: 5| Step: 4
Training loss: 3.429726845900092
Validation loss: 3.33716272279356

Epoch: 5| Step: 5
Training loss: 4.246333167266982
Validation loss: 3.334333770091401

Epoch: 5| Step: 6
Training loss: 3.4345404629336254
Validation loss: 3.3271516998879975

Epoch: 5| Step: 7
Training loss: 2.7024571470238423
Validation loss: 3.3174984291595266

Epoch: 5| Step: 8
Training loss: 4.016424077307377
Validation loss: 3.30950053295507

Epoch: 5| Step: 9
Training loss: 2.6290453665712477
Validation loss: 3.3044043172616733

Epoch: 5| Step: 10
Training loss: 3.5844461502157325
Validation loss: 3.3000746841904136

Epoch: 16| Step: 0
Training loss: 3.4709925919928772
Validation loss: 3.2914715017580467

Epoch: 5| Step: 1
Training loss: 3.801760697284097
Validation loss: 3.2896613041491034

Epoch: 5| Step: 2
Training loss: 2.558328163398547
Validation loss: 3.2854828159064917

Epoch: 5| Step: 3
Training loss: 2.8578809159538032
Validation loss: 3.28660362079432

Epoch: 5| Step: 4
Training loss: 3.4648774671150466
Validation loss: 3.2735011362107707

Epoch: 5| Step: 5
Training loss: 3.9248883954357194
Validation loss: 3.2672937000673095

Epoch: 5| Step: 6
Training loss: 3.6645028636628147
Validation loss: 3.2645022540669246

Epoch: 5| Step: 7
Training loss: 4.1961198594654086
Validation loss: 3.2624920312600825

Epoch: 5| Step: 8
Training loss: 3.6093468603052834
Validation loss: 3.2550251686329488

Epoch: 5| Step: 9
Training loss: 2.833751834554125
Validation loss: 3.249314583756598

Epoch: 5| Step: 10
Training loss: 3.974017154896555
Validation loss: 3.2469018568231207

Epoch: 17| Step: 0
Training loss: 3.7562454350550074
Validation loss: 3.245685415920248

Epoch: 5| Step: 1
Training loss: 3.8993243047833954
Validation loss: 3.2402206937157696

Epoch: 5| Step: 2
Training loss: 3.642025657668172
Validation loss: 3.2330398851602022

Epoch: 5| Step: 3
Training loss: 3.409015477819826
Validation loss: 3.2278216929496413

Epoch: 5| Step: 4
Training loss: 3.2145165315132647
Validation loss: 3.2259995096640877

Epoch: 5| Step: 5
Training loss: 3.3748156179289395
Validation loss: 3.2223269806292976

Epoch: 5| Step: 6
Training loss: 3.7431606230009633
Validation loss: 3.217661898989972

Epoch: 5| Step: 7
Training loss: 3.5269032960574935
Validation loss: 3.215257217675897

Epoch: 5| Step: 8
Training loss: 3.421367868965218
Validation loss: 3.2109320085398365

Epoch: 5| Step: 9
Training loss: 3.0397915394734865
Validation loss: 3.2147486939085237

Epoch: 5| Step: 10
Training loss: 3.1027786599429965
Validation loss: 3.2033171613364684

Epoch: 18| Step: 0
Training loss: 3.841873082858157
Validation loss: 3.2048115529787813

Epoch: 5| Step: 1
Training loss: 3.151033831289759
Validation loss: 3.2038543423071904

Epoch: 5| Step: 2
Training loss: 3.143381759281319
Validation loss: 3.202195206620137

Epoch: 5| Step: 3
Training loss: 3.4257375438168363
Validation loss: 3.198486725176377

Epoch: 5| Step: 4
Training loss: 3.4177600382705657
Validation loss: 3.1934790483067244

Epoch: 5| Step: 5
Training loss: 3.272160756804528
Validation loss: 3.189487499565267

Epoch: 5| Step: 6
Training loss: 3.2806404637535325
Validation loss: 3.1887277598767256

Epoch: 5| Step: 7
Training loss: 3.3195729587706118
Validation loss: 3.187995902631554

Epoch: 5| Step: 8
Training loss: 3.682543122349204
Validation loss: 3.1829211382818943

Epoch: 5| Step: 9
Training loss: 3.060437188924732
Validation loss: 3.1774344237004457

Epoch: 5| Step: 10
Training loss: 4.350518531148691
Validation loss: 3.1747030988978597

Epoch: 19| Step: 0
Training loss: 3.3579209130466974
Validation loss: 3.170857773411027

Epoch: 5| Step: 1
Training loss: 3.2380742097754176
Validation loss: 3.16715092078577

Epoch: 5| Step: 2
Training loss: 3.451315150932631
Validation loss: 3.165566741271547

Epoch: 5| Step: 3
Training loss: 3.728148820517991
Validation loss: 3.159734192797396

Epoch: 5| Step: 4
Training loss: 3.6318203135167426
Validation loss: 3.157727584739968

Epoch: 5| Step: 5
Training loss: 3.9080052208919263
Validation loss: 3.1546434561605325

Epoch: 5| Step: 6
Training loss: 3.1786467327425214
Validation loss: 3.150352109822858

Epoch: 5| Step: 7
Training loss: 3.6288126922143253
Validation loss: 3.1479261239461787

Epoch: 5| Step: 8
Training loss: 3.1353498348240114
Validation loss: 3.146859142263797

Epoch: 5| Step: 9
Training loss: 3.19517759304146
Validation loss: 3.1740834716864184

Epoch: 5| Step: 10
Training loss: 3.1048290049573444
Validation loss: 3.1396871819645504

Epoch: 20| Step: 0
Training loss: 2.8780736663912556
Validation loss: 3.1473335079782467

Epoch: 5| Step: 1
Training loss: 3.5983803814534263
Validation loss: 3.1677925497143002

Epoch: 5| Step: 2
Training loss: 3.3603312705995143
Validation loss: 3.1706092143928433

Epoch: 5| Step: 3
Training loss: 2.4921163231901007
Validation loss: 3.1535264038115205

Epoch: 5| Step: 4
Training loss: 3.011309129539015
Validation loss: 3.143932400306484

Epoch: 5| Step: 5
Training loss: 3.569970179200843
Validation loss: 3.1377033914380243

Epoch: 5| Step: 6
Training loss: 3.1237811954279353
Validation loss: 3.1337786567061277

Epoch: 5| Step: 7
Training loss: 4.306270799738864
Validation loss: 3.131207617004412

Epoch: 5| Step: 8
Training loss: 2.9359474137297696
Validation loss: 3.1244253996212112

Epoch: 5| Step: 9
Training loss: 3.9184052822225413
Validation loss: 3.116045367350141

Epoch: 5| Step: 10
Training loss: 3.9700974707564964
Validation loss: 3.112722136175564

Epoch: 21| Step: 0
Training loss: 3.870378014291465
Validation loss: 3.104222988342554

Epoch: 5| Step: 1
Training loss: 2.626834500835843
Validation loss: 3.095941274062925

Epoch: 5| Step: 2
Training loss: 3.3936838161133984
Validation loss: 3.0923800169178106

Epoch: 5| Step: 3
Training loss: 3.2027054674761097
Validation loss: 3.085159338642569

Epoch: 5| Step: 4
Training loss: 3.7749802494163975
Validation loss: 3.0811221514991023

Epoch: 5| Step: 5
Training loss: 3.260009463945939
Validation loss: 3.076768175372016

Epoch: 5| Step: 6
Training loss: 3.361159307661494
Validation loss: 3.073691888338189

Epoch: 5| Step: 7
Training loss: 3.6560327188208896
Validation loss: 3.069001478051244

Epoch: 5| Step: 8
Training loss: 2.9471436330576206
Validation loss: 3.066538884999293

Epoch: 5| Step: 9
Training loss: 3.5925934630615415
Validation loss: 3.0633719322446082

Epoch: 5| Step: 10
Training loss: 3.059335280132305
Validation loss: 3.062653494816562

Epoch: 22| Step: 0
Training loss: 2.700431054639125
Validation loss: 3.060624055976679

Epoch: 5| Step: 1
Training loss: 4.366926755269508
Validation loss: 3.0611990316091515

Epoch: 5| Step: 2
Training loss: 3.729008477690091
Validation loss: 3.054937364148855

Epoch: 5| Step: 3
Training loss: 3.329409212739038
Validation loss: 3.0513050638620953

Epoch: 5| Step: 4
Training loss: 3.457594244852356
Validation loss: 3.051030045951597

Epoch: 5| Step: 5
Training loss: 3.935756721297479
Validation loss: 3.049195187495894

Epoch: 5| Step: 6
Training loss: 3.0207457080277975
Validation loss: 3.044113995715511

Epoch: 5| Step: 7
Training loss: 2.9355077277724906
Validation loss: 3.0408319099572285

Epoch: 5| Step: 8
Training loss: 2.6148130662962474
Validation loss: 3.0367663618133736

Epoch: 5| Step: 9
Training loss: 3.1723996184259726
Validation loss: 3.035476651399496

Epoch: 5| Step: 10
Training loss: 2.976181686751693
Validation loss: 3.0356464563162966

Epoch: 23| Step: 0
Training loss: 3.115268661645174
Validation loss: 3.0346831355516426

Epoch: 5| Step: 1
Training loss: 3.254013517702204
Validation loss: 3.029932627026865

Epoch: 5| Step: 2
Training loss: 2.8504420757420497
Validation loss: 3.0297707526952267

Epoch: 5| Step: 3
Training loss: 2.6674396666091624
Validation loss: 3.027772859190107

Epoch: 5| Step: 4
Training loss: 3.5608309131854834
Validation loss: 3.0246035009647354

Epoch: 5| Step: 5
Training loss: 3.0461899207275454
Validation loss: 3.0200196038294216

Epoch: 5| Step: 6
Training loss: 4.17622634328372
Validation loss: 3.0195802541535874

Epoch: 5| Step: 7
Training loss: 3.516286016416066
Validation loss: 3.0170672801362732

Epoch: 5| Step: 8
Training loss: 3.5037817279033736
Validation loss: 3.0137200795385426

Epoch: 5| Step: 9
Training loss: 3.356835545443117
Validation loss: 3.0116092485402923

Epoch: 5| Step: 10
Training loss: 3.165331626018566
Validation loss: 3.009140015321928

Epoch: 24| Step: 0
Training loss: 3.8477855060379955
Validation loss: 3.0052208139453245

Epoch: 5| Step: 1
Training loss: 3.157514564317472
Validation loss: 3.0004029499009635

Epoch: 5| Step: 2
Training loss: 3.536725280903996
Validation loss: 2.9978583307019275

Epoch: 5| Step: 3
Training loss: 3.705480928700601
Validation loss: 2.994209400872084

Epoch: 5| Step: 4
Training loss: 2.9385314104635265
Validation loss: 2.9925753725643878

Epoch: 5| Step: 5
Training loss: 3.179003142771408
Validation loss: 2.9892585114584054

Epoch: 5| Step: 6
Training loss: 2.931596545981497
Validation loss: 2.98429219438616

Epoch: 5| Step: 7
Training loss: 2.9502108288444995
Validation loss: 2.985936669452224

Epoch: 5| Step: 8
Training loss: 2.993427706832947
Validation loss: 2.983797708718975

Epoch: 5| Step: 9
Training loss: 3.329169883933361
Validation loss: 2.981722069579022

Epoch: 5| Step: 10
Training loss: 3.513039820991859
Validation loss: 2.9769517056659427

Epoch: 25| Step: 0
Training loss: 3.4607207701874105
Validation loss: 2.979815076855039

Epoch: 5| Step: 1
Training loss: 3.4457105203412306
Validation loss: 2.9931358407402135

Epoch: 5| Step: 2
Training loss: 3.633258751153299
Validation loss: 2.9740555750238107

Epoch: 5| Step: 3
Training loss: 3.3194910806087012
Validation loss: 2.9693866463753533

Epoch: 5| Step: 4
Training loss: 3.7463809033581827
Validation loss: 2.9671312686863396

Epoch: 5| Step: 5
Training loss: 3.480543553226036
Validation loss: 2.9719776062743413

Epoch: 5| Step: 6
Training loss: 2.6299992141432367
Validation loss: 2.9761875992979334

Epoch: 5| Step: 7
Training loss: 3.1729582642107568
Validation loss: 2.9774999077196123

Epoch: 5| Step: 8
Training loss: 3.054298785909525
Validation loss: 2.9775956722592385

Epoch: 5| Step: 9
Training loss: 3.2901461666764447
Validation loss: 2.977399454359286

Epoch: 5| Step: 10
Training loss: 2.4987797620183065
Validation loss: 2.9771915832866345

Epoch: 26| Step: 0
Training loss: 2.734734909349362
Validation loss: 2.9784218421936837

Epoch: 5| Step: 1
Training loss: 3.127985329420414
Validation loss: 2.9800872005866808

Epoch: 5| Step: 2
Training loss: 2.669430869662617
Validation loss: 2.9724110488500584

Epoch: 5| Step: 3
Training loss: 3.7688422803825863
Validation loss: 2.9661117255438967

Epoch: 5| Step: 4
Training loss: 3.8795470354798494
Validation loss: 2.9599578229803254

Epoch: 5| Step: 5
Training loss: 2.797629142828045
Validation loss: 2.9573918114897104

Epoch: 5| Step: 6
Training loss: 3.4847748531257423
Validation loss: 2.956147094224506

Epoch: 5| Step: 7
Training loss: 3.6825984123841864
Validation loss: 2.953663834288374

Epoch: 5| Step: 8
Training loss: 3.4629430879856287
Validation loss: 2.949447480190108

Epoch: 5| Step: 9
Training loss: 3.2939972815441596
Validation loss: 2.9480102114327833

Epoch: 5| Step: 10
Training loss: 2.597359317644995
Validation loss: 2.945082038485919

Epoch: 27| Step: 0
Training loss: 3.3016310100244364
Validation loss: 2.9444592211674947

Epoch: 5| Step: 1
Training loss: 3.870117680339989
Validation loss: 2.950804154832141

Epoch: 5| Step: 2
Training loss: 3.172707885231826
Validation loss: 2.949562731260644

Epoch: 5| Step: 3
Training loss: 2.93093381693371
Validation loss: 2.953682710464376

Epoch: 5| Step: 4
Training loss: 3.7223545844866694
Validation loss: 2.9617137120413948

Epoch: 5| Step: 5
Training loss: 3.039977889482501
Validation loss: 2.9572080152770104

Epoch: 5| Step: 6
Training loss: 2.491517745280741
Validation loss: 2.946791330838161

Epoch: 5| Step: 7
Training loss: 3.718384412217748
Validation loss: 2.9520692923563323

Epoch: 5| Step: 8
Training loss: 2.6745145375043338
Validation loss: 2.9488705435012466

Epoch: 5| Step: 9
Training loss: 3.4088430071775098
Validation loss: 2.95039344911359

Epoch: 5| Step: 10
Training loss: 3.132426934999888
Validation loss: 2.9481627340108774

Epoch: 28| Step: 0
Training loss: 3.404518597331734
Validation loss: 2.944088062446507

Epoch: 5| Step: 1
Training loss: 3.7326202739083834
Validation loss: 2.94511639968835

Epoch: 5| Step: 2
Training loss: 3.0292187993645867
Validation loss: 2.9420945474387525

Epoch: 5| Step: 3
Training loss: 3.3903635513128676
Validation loss: 2.936747154054807

Epoch: 5| Step: 4
Training loss: 2.9804997873752557
Validation loss: 2.9349791707524395

Epoch: 5| Step: 5
Training loss: 3.69120576505835
Validation loss: 2.9354297339283772

Epoch: 5| Step: 6
Training loss: 3.311690033547207
Validation loss: 2.9350196710416387

Epoch: 5| Step: 7
Training loss: 2.664153961669996
Validation loss: 2.9352910147657774

Epoch: 5| Step: 8
Training loss: 2.9516045425514497
Validation loss: 2.9346106655539193

Epoch: 5| Step: 9
Training loss: 3.3330317042891857
Validation loss: 2.9339806221712124

Epoch: 5| Step: 10
Training loss: 2.9053280916602913
Validation loss: 2.933787048280125

Epoch: 29| Step: 0
Training loss: 3.7472466851571684
Validation loss: 2.9339840665925476

Epoch: 5| Step: 1
Training loss: 3.01461095017387
Validation loss: 2.934190871257085

Epoch: 5| Step: 2
Training loss: 3.118257802527312
Validation loss: 2.9406535732875816

Epoch: 5| Step: 3
Training loss: 3.3091884830639176
Validation loss: 2.941787662531684

Epoch: 5| Step: 4
Training loss: 2.983607967529623
Validation loss: 2.948444375024594

Epoch: 5| Step: 5
Training loss: 3.188948208799535
Validation loss: 2.9567014834608685

Epoch: 5| Step: 6
Training loss: 3.305403827921364
Validation loss: 2.940684320387377

Epoch: 5| Step: 7
Training loss: 3.8131335623194365
Validation loss: 2.9266088740033704

Epoch: 5| Step: 8
Training loss: 2.8083193755062386
Validation loss: 2.9225718375947998

Epoch: 5| Step: 9
Training loss: 2.254189511487162
Validation loss: 2.9219957122425946

Epoch: 5| Step: 10
Training loss: 3.726918201544791
Validation loss: 2.932016136393859

Epoch: 30| Step: 0
Training loss: 2.7879963180649034
Validation loss: 2.9359197893532842

Epoch: 5| Step: 1
Training loss: 3.333167040173684
Validation loss: 2.923466769424485

Epoch: 5| Step: 2
Training loss: 3.173190741287202
Validation loss: 2.921926520222785

Epoch: 5| Step: 3
Training loss: 3.3287950297972437
Validation loss: 2.922255214879641

Epoch: 5| Step: 4
Training loss: 3.2709470757471553
Validation loss: 2.923493930956472

Epoch: 5| Step: 5
Training loss: 3.1636831550665523
Validation loss: 2.918980905310364

Epoch: 5| Step: 6
Training loss: 3.3472291903249585
Validation loss: 2.9193282088490204

Epoch: 5| Step: 7
Training loss: 2.9383454425091275
Validation loss: 2.9202273416580264

Epoch: 5| Step: 8
Training loss: 3.02969635150122
Validation loss: 2.9216304314991266

Epoch: 5| Step: 9
Training loss: 3.641527710685172
Validation loss: 2.920301353935326

Epoch: 5| Step: 10
Training loss: 3.4021295946522367
Validation loss: 2.916492427655013

Epoch: 31| Step: 0
Training loss: 2.7012660519724485
Validation loss: 2.9136412074985003

Epoch: 5| Step: 1
Training loss: 2.2355027987147595
Validation loss: 2.9149185502862474

Epoch: 5| Step: 2
Training loss: 3.1979219186016947
Validation loss: 2.915734700907795

Epoch: 5| Step: 3
Training loss: 2.726019775240532
Validation loss: 2.9172125843075443

Epoch: 5| Step: 4
Training loss: 3.218959023808854
Validation loss: 2.9117906857585356

Epoch: 5| Step: 5
Training loss: 3.7834210429058555
Validation loss: 2.9130581614531454

Epoch: 5| Step: 6
Training loss: 3.8572647564916207
Validation loss: 2.909471652512745

Epoch: 5| Step: 7
Training loss: 3.307688259265585
Validation loss: 2.9058756953897245

Epoch: 5| Step: 8
Training loss: 3.1984061861578543
Validation loss: 2.904943529126276

Epoch: 5| Step: 9
Training loss: 3.5317128646106895
Validation loss: 2.903829017193959

Epoch: 5| Step: 10
Training loss: 3.207174876408552
Validation loss: 2.90269752724236

Epoch: 32| Step: 0
Training loss: 3.2074299981438665
Validation loss: 2.902821984058895

Epoch: 5| Step: 1
Training loss: 3.204789785076132
Validation loss: 2.902063489183751

Epoch: 5| Step: 2
Training loss: 3.8901447781095913
Validation loss: 2.9019662064982703

Epoch: 5| Step: 3
Training loss: 3.1653665751559874
Validation loss: 2.9011238875781404

Epoch: 5| Step: 4
Training loss: 3.5731374303532473
Validation loss: 2.8993108798014116

Epoch: 5| Step: 5
Training loss: 2.0241724984388756
Validation loss: 2.900565739633416

Epoch: 5| Step: 6
Training loss: 3.370893169637448
Validation loss: 2.897200319236752

Epoch: 5| Step: 7
Training loss: 3.234318239755201
Validation loss: 2.8976737567530453

Epoch: 5| Step: 8
Training loss: 2.389999008497727
Validation loss: 2.8982354576221594

Epoch: 5| Step: 9
Training loss: 3.451242201152806
Validation loss: 2.8985408349601878

Epoch: 5| Step: 10
Training loss: 3.3513728446030115
Validation loss: 2.8972292003082774

Epoch: 33| Step: 0
Training loss: 3.6602219094297452
Validation loss: 2.894825279568128

Epoch: 5| Step: 1
Training loss: 2.6519170988194993
Validation loss: 2.896650023144291

Epoch: 5| Step: 2
Training loss: 3.190701541113316
Validation loss: 2.895456262241081

Epoch: 5| Step: 3
Training loss: 3.636719143352221
Validation loss: 2.8931721115271984

Epoch: 5| Step: 4
Training loss: 2.9886445666087527
Validation loss: 2.894749949055099

Epoch: 5| Step: 5
Training loss: 3.2082881346322023
Validation loss: 2.8971505166527063

Epoch: 5| Step: 6
Training loss: 2.5746677221331944
Validation loss: 2.8972882569957603

Epoch: 5| Step: 7
Training loss: 3.206386189979615
Validation loss: 2.8960026794573714

Epoch: 5| Step: 8
Training loss: 3.161374304134948
Validation loss: 2.8980072376996464

Epoch: 5| Step: 9
Training loss: 3.0009725901474686
Validation loss: 2.887988075358988

Epoch: 5| Step: 10
Training loss: 3.737426022208918
Validation loss: 2.888854949374228

Epoch: 34| Step: 0
Training loss: 2.714761988005537
Validation loss: 2.89129512416927

Epoch: 5| Step: 1
Training loss: 3.61639197810899
Validation loss: 2.8901743494612946

Epoch: 5| Step: 2
Training loss: 2.888144588771382
Validation loss: 2.886356665469496

Epoch: 5| Step: 3
Training loss: 2.8770343383182455
Validation loss: 2.88434478715856

Epoch: 5| Step: 4
Training loss: 2.678803056057102
Validation loss: 2.8832051644215646

Epoch: 5| Step: 5
Training loss: 3.0801134222375084
Validation loss: 2.8809052785890885

Epoch: 5| Step: 6
Training loss: 3.407118240432032
Validation loss: 2.881527574514412

Epoch: 5| Step: 7
Training loss: 3.3932425946867526
Validation loss: 2.882729208405189

Epoch: 5| Step: 8
Training loss: 3.4821647168266328
Validation loss: 2.8838203669919014

Epoch: 5| Step: 9
Training loss: 3.5040300872590966
Validation loss: 2.889932945040705

Epoch: 5| Step: 10
Training loss: 3.2561093642311056
Validation loss: 2.893913681541883

Epoch: 35| Step: 0
Training loss: 3.086815972174133
Validation loss: 2.8831860749083766

Epoch: 5| Step: 1
Training loss: 2.4859202635507396
Validation loss: 2.8785179643162238

Epoch: 5| Step: 2
Training loss: 3.0129550321092906
Validation loss: 2.8792582236201785

Epoch: 5| Step: 3
Training loss: 3.3941620690714
Validation loss: 2.8776165726375282

Epoch: 5| Step: 4
Training loss: 3.3119461748199934
Validation loss: 2.8812110797706563

Epoch: 5| Step: 5
Training loss: 2.8674984797080416
Validation loss: 2.8795332264378763

Epoch: 5| Step: 6
Training loss: 3.911725044893015
Validation loss: 2.8804132167303576

Epoch: 5| Step: 7
Training loss: 3.223207516770677
Validation loss: 2.87766832398857

Epoch: 5| Step: 8
Training loss: 3.1297065387666665
Validation loss: 2.878486082036229

Epoch: 5| Step: 9
Training loss: 3.450220880486568
Validation loss: 2.882690414652396

Epoch: 5| Step: 10
Training loss: 2.897844197299311
Validation loss: 2.879112732362529

Epoch: 36| Step: 0
Training loss: 3.1548254745261644
Validation loss: 2.8750999222877853

Epoch: 5| Step: 1
Training loss: 3.2448612081179573
Validation loss: 2.8728029685140086

Epoch: 5| Step: 2
Training loss: 3.621536836808894
Validation loss: 2.87176328264547

Epoch: 5| Step: 3
Training loss: 2.8630077861183025
Validation loss: 2.8725689315296825

Epoch: 5| Step: 4
Training loss: 3.427736322559988
Validation loss: 2.869505504619535

Epoch: 5| Step: 5
Training loss: 3.0134255091598616
Validation loss: 2.8755784195210783

Epoch: 5| Step: 6
Training loss: 2.7765506948070913
Validation loss: 2.880746107897261

Epoch: 5| Step: 7
Training loss: 3.118202598708788
Validation loss: 2.889665647869242

Epoch: 5| Step: 8
Training loss: 3.5316522419808796
Validation loss: 2.8747924776159364

Epoch: 5| Step: 9
Training loss: 3.317588352846518
Validation loss: 2.8701629100773864

Epoch: 5| Step: 10
Training loss: 2.598314979036538
Validation loss: 2.8662275176017604

Epoch: 37| Step: 0
Training loss: 3.9217232602617598
Validation loss: 2.8643896192157485

Epoch: 5| Step: 1
Training loss: 3.1474957820751963
Validation loss: 2.869346712051312

Epoch: 5| Step: 2
Training loss: 2.8366219191228748
Validation loss: 2.864980149215635

Epoch: 5| Step: 3
Training loss: 2.569448586767025
Validation loss: 2.868513672097979

Epoch: 5| Step: 4
Training loss: 3.1730682684151232
Validation loss: 2.872474119929326

Epoch: 5| Step: 5
Training loss: 2.795606527968915
Validation loss: 2.873457956538201

Epoch: 5| Step: 6
Training loss: 3.744705531686433
Validation loss: 2.9059290378451235

Epoch: 5| Step: 7
Training loss: 3.3403288550292785
Validation loss: 2.881023348116192

Epoch: 5| Step: 8
Training loss: 2.947805144196586
Validation loss: 2.8610826639503557

Epoch: 5| Step: 9
Training loss: 3.220413074653456
Validation loss: 2.859377175983722

Epoch: 5| Step: 10
Training loss: 2.8455739302883725
Validation loss: 2.8596977815132787

Epoch: 38| Step: 0
Training loss: 2.9734795090819404
Validation loss: 2.8782960278922705

Epoch: 5| Step: 1
Training loss: 2.540214582375221
Validation loss: 2.9229937426320993

Epoch: 5| Step: 2
Training loss: 3.226115271952446
Validation loss: 2.889138300767407

Epoch: 5| Step: 3
Training loss: 3.3512346867656477
Validation loss: 2.8578472946032143

Epoch: 5| Step: 4
Training loss: 2.581779802460848
Validation loss: 2.857502992975621

Epoch: 5| Step: 5
Training loss: 3.7221957359194024
Validation loss: 2.8531991026533667

Epoch: 5| Step: 6
Training loss: 2.9831991225871737
Validation loss: 2.8535016366474633

Epoch: 5| Step: 7
Training loss: 3.223919023429234
Validation loss: 2.865513064099472

Epoch: 5| Step: 8
Training loss: 3.5383326975863354
Validation loss: 2.8542369321601098

Epoch: 5| Step: 9
Training loss: 3.019458449104193
Validation loss: 2.8536319206276604

Epoch: 5| Step: 10
Training loss: 3.5215044153270587
Validation loss: 2.85363956671406

Epoch: 39| Step: 0
Training loss: 3.6870745397264515
Validation loss: 2.8537118805552035

Epoch: 5| Step: 1
Training loss: 3.0928301744282702
Validation loss: 2.850357302188125

Epoch: 5| Step: 2
Training loss: 2.5384482242217277
Validation loss: 2.8509861562437107

Epoch: 5| Step: 3
Training loss: 2.8478312288168883
Validation loss: 2.8472303854759184

Epoch: 5| Step: 4
Training loss: 3.311398160967138
Validation loss: 2.8522100230645053

Epoch: 5| Step: 5
Training loss: 2.974066541387825
Validation loss: 2.852954724559369

Epoch: 5| Step: 6
Training loss: 3.2594357478477995
Validation loss: 2.852056129109078

Epoch: 5| Step: 7
Training loss: 3.181272819152411
Validation loss: 2.8524774472270593

Epoch: 5| Step: 8
Training loss: 3.643246079633537
Validation loss: 2.853911632685262

Epoch: 5| Step: 9
Training loss: 3.126921558876041
Validation loss: 2.8554753165036777

Epoch: 5| Step: 10
Training loss: 2.88357145248635
Validation loss: 2.8573802398550066

Epoch: 40| Step: 0
Training loss: 2.5473772735533147
Validation loss: 2.8713074003676704

Epoch: 5| Step: 1
Training loss: 3.457732703817605
Validation loss: 2.865543474992084

Epoch: 5| Step: 2
Training loss: 3.4218897710333307
Validation loss: 2.851290460281771

Epoch: 5| Step: 3
Training loss: 3.2603234875966547
Validation loss: 2.8430506420872694

Epoch: 5| Step: 4
Training loss: 3.233624947234518
Validation loss: 2.842724409291549

Epoch: 5| Step: 5
Training loss: 3.2994552567279802
Validation loss: 2.8418795277992306

Epoch: 5| Step: 6
Training loss: 3.028621359693725
Validation loss: 2.8428300327092315

Epoch: 5| Step: 7
Training loss: 3.1658363926942936
Validation loss: 2.8459060737001116

Epoch: 5| Step: 8
Training loss: 3.1615298083467347
Validation loss: 2.84898922808185

Epoch: 5| Step: 9
Training loss: 3.562408981499014
Validation loss: 2.845033154427339

Epoch: 5| Step: 10
Training loss: 2.250706032075772
Validation loss: 2.8421855952011215

Epoch: 41| Step: 0
Training loss: 3.2474089344110144
Validation loss: 2.84454798959665

Epoch: 5| Step: 1
Training loss: 2.8600849875247163
Validation loss: 2.844578754401398

Epoch: 5| Step: 2
Training loss: 3.2834293938799304
Validation loss: 2.8473450461553416

Epoch: 5| Step: 3
Training loss: 3.023985978088971
Validation loss: 2.8462177573384255

Epoch: 5| Step: 4
Training loss: 2.8377167135824903
Validation loss: 2.844206553269923

Epoch: 5| Step: 5
Training loss: 3.548877839583674
Validation loss: 2.8455753753671638

Epoch: 5| Step: 6
Training loss: 3.660775929108091
Validation loss: 2.8417304800267007

Epoch: 5| Step: 7
Training loss: 3.070592348191862
Validation loss: 2.841733396645986

Epoch: 5| Step: 8
Training loss: 3.0807935891250398
Validation loss: 2.8410331931056554

Epoch: 5| Step: 9
Training loss: 2.7325577282893474
Validation loss: 2.8419625678876383

Epoch: 5| Step: 10
Training loss: 3.081838778250243
Validation loss: 2.8356169076433444

Epoch: 42| Step: 0
Training loss: 2.868639004290794
Validation loss: 2.8400613976976254

Epoch: 5| Step: 1
Training loss: 3.396303124881032
Validation loss: 2.83439433742956

Epoch: 5| Step: 2
Training loss: 3.2308060125206453
Validation loss: 2.8335781884361047

Epoch: 5| Step: 3
Training loss: 2.697549173863223
Validation loss: 2.829778436873687

Epoch: 5| Step: 4
Training loss: 2.513271012313525
Validation loss: 2.8303499300687087

Epoch: 5| Step: 5
Training loss: 2.8474120989085407
Validation loss: 2.8297905938041885

Epoch: 5| Step: 6
Training loss: 3.079535766146116
Validation loss: 2.8273576896512966

Epoch: 5| Step: 7
Training loss: 4.007357982420285
Validation loss: 2.835655612191173

Epoch: 5| Step: 8
Training loss: 3.5015606806561816
Validation loss: 2.882968651471187

Epoch: 5| Step: 9
Training loss: 3.294184884418963
Validation loss: 2.856291201556792

Epoch: 5| Step: 10
Training loss: 2.8363391602289285
Validation loss: 2.8294137146366762

Epoch: 43| Step: 0
Training loss: 3.2161196729494415
Validation loss: 2.8278259434682234

Epoch: 5| Step: 1
Training loss: 3.090946969906855
Validation loss: 2.824058955169822

Epoch: 5| Step: 2
Training loss: 2.756806706196869
Validation loss: 2.8291534056950707

Epoch: 5| Step: 3
Training loss: 3.8518362199501452
Validation loss: 2.824673239667425

Epoch: 5| Step: 4
Training loss: 3.847915996943183
Validation loss: 2.8228263932875217

Epoch: 5| Step: 5
Training loss: 2.783888176382283
Validation loss: 2.823461363722369

Epoch: 5| Step: 6
Training loss: 3.0864818237797786
Validation loss: 2.821744983451349

Epoch: 5| Step: 7
Training loss: 2.8392066293346137
Validation loss: 2.8204881771711183

Epoch: 5| Step: 8
Training loss: 2.94279295312977
Validation loss: 2.8223451592031488

Epoch: 5| Step: 9
Training loss: 2.955453429055088
Validation loss: 2.8188357781696114

Epoch: 5| Step: 10
Training loss: 2.816049328328621
Validation loss: 2.8198081317654573

Epoch: 44| Step: 0
Training loss: 2.6745149832273913
Validation loss: 2.8177097484246993

Epoch: 5| Step: 1
Training loss: 2.8843751719300124
Validation loss: 2.817240973422326

Epoch: 5| Step: 2
Training loss: 3.533010533420507
Validation loss: 2.821126908054376

Epoch: 5| Step: 3
Training loss: 3.5315338290766927
Validation loss: 2.830302483727208

Epoch: 5| Step: 4
Training loss: 2.941839867554903
Validation loss: 2.8458709983715593

Epoch: 5| Step: 5
Training loss: 2.85569601550501
Validation loss: 2.8538440054594245

Epoch: 5| Step: 6
Training loss: 3.1425374599217935
Validation loss: 2.8466521577748

Epoch: 5| Step: 7
Training loss: 3.0865063879310632
Validation loss: 2.8291044794525266

Epoch: 5| Step: 8
Training loss: 3.3303928439076036
Validation loss: 2.8089653993628967

Epoch: 5| Step: 9
Training loss: 3.3740142512989997
Validation loss: 2.8103566460423073

Epoch: 5| Step: 10
Training loss: 2.9212004346972313
Validation loss: 2.8143714393709667

Epoch: 45| Step: 0
Training loss: 3.5670112021580196
Validation loss: 2.818645862143337

Epoch: 5| Step: 1
Training loss: 2.7047310176105333
Validation loss: 2.813571784962801

Epoch: 5| Step: 2
Training loss: 3.1079805400636844
Validation loss: 2.812567112348685

Epoch: 5| Step: 3
Training loss: 2.881880612157959
Validation loss: 2.808633866589044

Epoch: 5| Step: 4
Training loss: 2.924693008354079
Validation loss: 2.8079219123363526

Epoch: 5| Step: 5
Training loss: 2.955606376797396
Validation loss: 2.8074236972758366

Epoch: 5| Step: 6
Training loss: 3.528878014540019
Validation loss: 2.806404382819582

Epoch: 5| Step: 7
Training loss: 2.954533962414139
Validation loss: 2.8041451209343324

Epoch: 5| Step: 8
Training loss: 3.4068901090509107
Validation loss: 2.8039493110923828

Epoch: 5| Step: 9
Training loss: 2.7889087965897703
Validation loss: 2.802014229080905

Epoch: 5| Step: 10
Training loss: 3.469561370258458
Validation loss: 2.8021704523026445

Epoch: 46| Step: 0
Training loss: 3.4139745076797094
Validation loss: 2.800165468738153

Epoch: 5| Step: 1
Training loss: 2.9935290165455872
Validation loss: 2.8001773404143178

Epoch: 5| Step: 2
Training loss: 3.6271703076803505
Validation loss: 2.799679427466335

Epoch: 5| Step: 3
Training loss: 2.7428732337933805
Validation loss: 2.79922317299797

Epoch: 5| Step: 4
Training loss: 2.7488026179628706
Validation loss: 2.8006907022078806

Epoch: 5| Step: 5
Training loss: 2.8886083218055365
Validation loss: 2.8001248005186308

Epoch: 5| Step: 6
Training loss: 2.8390455632814673
Validation loss: 2.803967036499796

Epoch: 5| Step: 7
Training loss: 3.4272992067070716
Validation loss: 2.8010914127194115

Epoch: 5| Step: 8
Training loss: 3.022521833998807
Validation loss: 2.800732603420243

Epoch: 5| Step: 9
Training loss: 3.1491235028273454
Validation loss: 2.798599837821166

Epoch: 5| Step: 10
Training loss: 3.2961728763056657
Validation loss: 2.7976906062080475

Epoch: 47| Step: 0
Training loss: 3.121625069665081
Validation loss: 2.7968193759498217

Epoch: 5| Step: 1
Training loss: 3.069791560350478
Validation loss: 2.8031877578970064

Epoch: 5| Step: 2
Training loss: 3.544259472374946
Validation loss: 2.7925053473733983

Epoch: 5| Step: 3
Training loss: 3.5535833299688115
Validation loss: 2.79190165584166

Epoch: 5| Step: 4
Training loss: 3.3064277702090172
Validation loss: 2.7909859828562817

Epoch: 5| Step: 5
Training loss: 3.601706148208034
Validation loss: 2.7892559284665945

Epoch: 5| Step: 6
Training loss: 2.932632309058167
Validation loss: 2.7891601258630896

Epoch: 5| Step: 7
Training loss: 3.348139368581498
Validation loss: 2.790745074453564

Epoch: 5| Step: 8
Training loss: 2.5926317309145115
Validation loss: 2.789776945033198

Epoch: 5| Step: 9
Training loss: 2.6160807988349126
Validation loss: 2.7874104270631306

Epoch: 5| Step: 10
Training loss: 2.106083994133244
Validation loss: 2.788011356904531

Epoch: 48| Step: 0
Training loss: 3.244482051146593
Validation loss: 2.7885797710828375

Epoch: 5| Step: 1
Training loss: 2.8257792318061115
Validation loss: 2.788183255515135

Epoch: 5| Step: 2
Training loss: 3.245774529985025
Validation loss: 2.786887011455664

Epoch: 5| Step: 3
Training loss: 3.0279734098206763
Validation loss: 2.7859818920766117

Epoch: 5| Step: 4
Training loss: 3.9321197809037445
Validation loss: 2.783861945772698

Epoch: 5| Step: 5
Training loss: 2.8435367043119966
Validation loss: 2.7832090072123514

Epoch: 5| Step: 6
Training loss: 3.3341226755787052
Validation loss: 2.7819977598865346

Epoch: 5| Step: 7
Training loss: 2.5384626883168493
Validation loss: 2.7830688476409935

Epoch: 5| Step: 8
Training loss: 2.7995689673399844
Validation loss: 2.786062716963941

Epoch: 5| Step: 9
Training loss: 3.1654771444543695
Validation loss: 2.7889344704854038

Epoch: 5| Step: 10
Training loss: 2.9838133278412093
Validation loss: 2.7945041302022195

Epoch: 49| Step: 0
Training loss: 3.418999007674255
Validation loss: 2.789015624363419

Epoch: 5| Step: 1
Training loss: 2.801820953072514
Validation loss: 2.7904438217347938

Epoch: 5| Step: 2
Training loss: 2.6968686241879025
Validation loss: 2.790795122384486

Epoch: 5| Step: 3
Training loss: 2.584061602002854
Validation loss: 2.7894889321941876

Epoch: 5| Step: 4
Training loss: 3.204403505803058
Validation loss: 2.7864781014530258

Epoch: 5| Step: 5
Training loss: 2.955831750554393
Validation loss: 2.788156090669442

Epoch: 5| Step: 6
Training loss: 3.1046510015606743
Validation loss: 2.7878334198430115

Epoch: 5| Step: 7
Training loss: 3.238401109343177
Validation loss: 2.786264748682474

Epoch: 5| Step: 8
Training loss: 2.7441123879496945
Validation loss: 2.7813066995484017

Epoch: 5| Step: 9
Training loss: 3.6583377713558125
Validation loss: 2.7822151053549478

Epoch: 5| Step: 10
Training loss: 3.525782039818907
Validation loss: 2.781618752667393

Epoch: 50| Step: 0
Training loss: 3.3581131805376634
Validation loss: 2.7824629650071295

Epoch: 5| Step: 1
Training loss: 2.8050139085829415
Validation loss: 2.78153848067959

Epoch: 5| Step: 2
Training loss: 2.8130772316179598
Validation loss: 2.780413642095185

Epoch: 5| Step: 3
Training loss: 2.539888687698427
Validation loss: 2.7790278251480993

Epoch: 5| Step: 4
Training loss: 3.747811887052879
Validation loss: 2.781987863765787

Epoch: 5| Step: 5
Training loss: 3.137506863407972
Validation loss: 2.779852459430909

Epoch: 5| Step: 6
Training loss: 2.739610901513774
Validation loss: 2.786269566318978

Epoch: 5| Step: 7
Training loss: 2.84999990630568
Validation loss: 2.796068900426203

Epoch: 5| Step: 8
Training loss: 3.152123047619878
Validation loss: 2.811666281672797

Epoch: 5| Step: 9
Training loss: 3.1403140393318947
Validation loss: 2.805033452407734

Epoch: 5| Step: 10
Training loss: 3.5864673630269004
Validation loss: 2.7818112555398553

Epoch: 51| Step: 0
Training loss: 3.4041443362178696
Validation loss: 2.771734683364014

Epoch: 5| Step: 1
Training loss: 3.129107408093675
Validation loss: 2.7700754134933825

Epoch: 5| Step: 2
Training loss: 3.0091955398812504
Validation loss: 2.771795216126248

Epoch: 5| Step: 3
Training loss: 2.677990968570765
Validation loss: 2.774299022129489

Epoch: 5| Step: 4
Training loss: 2.9087897247762458
Validation loss: 2.7727911563877186

Epoch: 5| Step: 5
Training loss: 3.175196069385405
Validation loss: 2.771432718464196

Epoch: 5| Step: 6
Training loss: 2.769248614396364
Validation loss: 2.7710384879230894

Epoch: 5| Step: 7
Training loss: 3.6207302861682176
Validation loss: 2.7695767846273633

Epoch: 5| Step: 8
Training loss: 3.1970040244040456
Validation loss: 2.7700654905129496

Epoch: 5| Step: 9
Training loss: 2.861485270588753
Validation loss: 2.7708317195885477

Epoch: 5| Step: 10
Training loss: 3.1385223789848418
Validation loss: 2.7720974051076714

Epoch: 52| Step: 0
Training loss: 2.5021094006131546
Validation loss: 2.7716485125157337

Epoch: 5| Step: 1
Training loss: 2.5740717612921156
Validation loss: 2.776724792132768

Epoch: 5| Step: 2
Training loss: 3.7002646428909918
Validation loss: 2.7913953446942776

Epoch: 5| Step: 3
Training loss: 3.3234988731955117
Validation loss: 2.775329434448706

Epoch: 5| Step: 4
Training loss: 3.034126411414715
Validation loss: 2.777036790528764

Epoch: 5| Step: 5
Training loss: 2.906665567199546
Validation loss: 2.7801368378099416

Epoch: 5| Step: 6
Training loss: 3.2063046932203125
Validation loss: 2.7900348146312735

Epoch: 5| Step: 7
Training loss: 2.481434935781137
Validation loss: 2.7700724963888526

Epoch: 5| Step: 8
Training loss: 3.611873009993544
Validation loss: 2.761535674665997

Epoch: 5| Step: 9
Training loss: 2.8500885799094173
Validation loss: 2.761893860235076

Epoch: 5| Step: 10
Training loss: 3.4964611691533856
Validation loss: 2.7586309847570667

Epoch: 53| Step: 0
Training loss: 2.6074733543314657
Validation loss: 2.7589160851832677

Epoch: 5| Step: 1
Training loss: 3.308058009634199
Validation loss: 2.7607303523963522

Epoch: 5| Step: 2
Training loss: 3.4952959056011843
Validation loss: 2.758345724745385

Epoch: 5| Step: 3
Training loss: 3.1074735875745017
Validation loss: 2.7580875051732847

Epoch: 5| Step: 4
Training loss: 3.324150900590992
Validation loss: 2.7556642740168247

Epoch: 5| Step: 5
Training loss: 2.9941430138505636
Validation loss: 2.755129558867629

Epoch: 5| Step: 6
Training loss: 3.1632900472505945
Validation loss: 2.754900400418123

Epoch: 5| Step: 7
Training loss: 2.6768465246609408
Validation loss: 2.7559236062149095

Epoch: 5| Step: 8
Training loss: 3.0276363895857683
Validation loss: 2.752674038836161

Epoch: 5| Step: 9
Training loss: 3.162493733637335
Validation loss: 2.7523286698103337

Epoch: 5| Step: 10
Training loss: 2.8940119515615774
Validation loss: 2.754285279558971

Epoch: 54| Step: 0
Training loss: 2.9937911952614855
Validation loss: 2.7519261754410085

Epoch: 5| Step: 1
Training loss: 2.8202193395386663
Validation loss: 2.7504464399572814

Epoch: 5| Step: 2
Training loss: 2.812815754437945
Validation loss: 2.749927512338733

Epoch: 5| Step: 3
Training loss: 3.355046948532236
Validation loss: 2.7505556162415767

Epoch: 5| Step: 4
Training loss: 3.337171411233487
Validation loss: 2.747287801813248

Epoch: 5| Step: 5
Training loss: 3.6191978058927243
Validation loss: 2.7538280170202367

Epoch: 5| Step: 6
Training loss: 3.155213138496482
Validation loss: 2.7498973405904517

Epoch: 5| Step: 7
Training loss: 2.449716715102571
Validation loss: 2.7538773906879697

Epoch: 5| Step: 8
Training loss: 2.680618613714223
Validation loss: 2.7485884626400097

Epoch: 5| Step: 9
Training loss: 3.478444068168407
Validation loss: 2.753569411035196

Epoch: 5| Step: 10
Training loss: 2.8790697235112863
Validation loss: 2.7717136385153953

Epoch: 55| Step: 0
Training loss: 2.779856986614209
Validation loss: 2.797526446102575

Epoch: 5| Step: 1
Training loss: 2.300537200056542
Validation loss: 2.8235968689146165

Epoch: 5| Step: 2
Training loss: 3.1594118201037404
Validation loss: 2.8879868867406735

Epoch: 5| Step: 3
Training loss: 2.8565272758005618
Validation loss: 2.8425910965543295

Epoch: 5| Step: 4
Training loss: 3.105546137007472
Validation loss: 2.8015312144624125

Epoch: 5| Step: 5
Training loss: 2.6800680084993895
Validation loss: 2.762470317438526

Epoch: 5| Step: 6
Training loss: 3.5547510833083975
Validation loss: 2.7496765241055905

Epoch: 5| Step: 7
Training loss: 2.975929653546341
Validation loss: 2.747750914749207

Epoch: 5| Step: 8
Training loss: 3.1692995035112324
Validation loss: 2.7520964509695256

Epoch: 5| Step: 9
Training loss: 3.514794688190802
Validation loss: 2.7507128532713456

Epoch: 5| Step: 10
Training loss: 3.613345913695034
Validation loss: 2.7441239939030093

Epoch: 56| Step: 0
Training loss: 3.049474614653324
Validation loss: 2.741852792154071

Epoch: 5| Step: 1
Training loss: 3.3214268867500123
Validation loss: 2.7425165443206683

Epoch: 5| Step: 2
Training loss: 2.700322456884508
Validation loss: 2.7452627296429597

Epoch: 5| Step: 3
Training loss: 3.2280107623822545
Validation loss: 2.7499604851576986

Epoch: 5| Step: 4
Training loss: 3.476950771638275
Validation loss: 2.7472224429797536

Epoch: 5| Step: 5
Training loss: 2.514637723733245
Validation loss: 2.7397206527548654

Epoch: 5| Step: 6
Training loss: 3.347122488123267
Validation loss: 2.7365508148806836

Epoch: 5| Step: 7
Training loss: 2.8431855364627503
Validation loss: 2.7422494927166294

Epoch: 5| Step: 8
Training loss: 3.1553632038066572
Validation loss: 2.7510935211733676

Epoch: 5| Step: 9
Training loss: 2.843712942699399
Validation loss: 2.769199427768786

Epoch: 5| Step: 10
Training loss: 3.17501810624374
Validation loss: 2.7718543731909384

Epoch: 57| Step: 0
Training loss: 3.0936519722869225
Validation loss: 2.772829233633728

Epoch: 5| Step: 1
Training loss: 3.2068330468879718
Validation loss: 2.7772003026478425

Epoch: 5| Step: 2
Training loss: 3.504087785762102
Validation loss: 2.7902822846950395

Epoch: 5| Step: 3
Training loss: 2.949330793867116
Validation loss: 2.784919061677449

Epoch: 5| Step: 4
Training loss: 2.9324119818731313
Validation loss: 2.7764988730724176

Epoch: 5| Step: 5
Training loss: 2.9499963404745904
Validation loss: 2.7442720745706812

Epoch: 5| Step: 6
Training loss: 3.2290422641212744
Validation loss: 2.734553449348197

Epoch: 5| Step: 7
Training loss: 2.593400219232087
Validation loss: 2.7345390905785525

Epoch: 5| Step: 8
Training loss: 3.3813579154289313
Validation loss: 2.762424958003788

Epoch: 5| Step: 9
Training loss: 3.2597243738964212
Validation loss: 2.7638869819861958

Epoch: 5| Step: 10
Training loss: 2.3765129490488937
Validation loss: 2.7588121657402827

Epoch: 58| Step: 0
Training loss: 2.9777573317526467
Validation loss: 2.7530556256345307

Epoch: 5| Step: 1
Training loss: 3.3864883995696666
Validation loss: 2.7359487628621193

Epoch: 5| Step: 2
Training loss: 2.691361779896126
Validation loss: 2.7326175959386605

Epoch: 5| Step: 3
Training loss: 2.924577901005178
Validation loss: 2.7329788820686263

Epoch: 5| Step: 4
Training loss: 3.299282695377302
Validation loss: 2.7305526207642474

Epoch: 5| Step: 5
Training loss: 3.069976865948422
Validation loss: 2.7297158426513417

Epoch: 5| Step: 6
Training loss: 3.336368148844126
Validation loss: 2.7300069865274414

Epoch: 5| Step: 7
Training loss: 3.143829836125547
Validation loss: 2.7290434976673725

Epoch: 5| Step: 8
Training loss: 2.9727650044782528
Validation loss: 2.7276612893885828

Epoch: 5| Step: 9
Training loss: 2.9195410234483186
Validation loss: 2.7305598125177624

Epoch: 5| Step: 10
Training loss: 2.935662851688555
Validation loss: 2.7482683382728195

Epoch: 59| Step: 0
Training loss: 2.88234336778166
Validation loss: 2.7357501653602707

Epoch: 5| Step: 1
Training loss: 2.8367508491668816
Validation loss: 2.734839776497937

Epoch: 5| Step: 2
Training loss: 3.1553857205435527
Validation loss: 2.752178216964604

Epoch: 5| Step: 3
Training loss: 2.88633500414705
Validation loss: 2.735075335141372

Epoch: 5| Step: 4
Training loss: 3.3203064682849623
Validation loss: 2.7405758557107793

Epoch: 5| Step: 5
Training loss: 2.8334632357569474
Validation loss: 2.7373820665816173

Epoch: 5| Step: 6
Training loss: 3.6639320984757906
Validation loss: 2.733369398241798

Epoch: 5| Step: 7
Training loss: 2.4662011424666397
Validation loss: 2.7338773691224207

Epoch: 5| Step: 8
Training loss: 2.907019400527617
Validation loss: 2.7358068511441727

Epoch: 5| Step: 9
Training loss: 3.536959732909279
Validation loss: 2.7252049783992622

Epoch: 5| Step: 10
Training loss: 2.9071973671694953
Validation loss: 2.7262890043282653

Epoch: 60| Step: 0
Training loss: 2.899641172637351
Validation loss: 2.7250882952827338

Epoch: 5| Step: 1
Training loss: 3.1009640825018914
Validation loss: 2.7242805345143806

Epoch: 5| Step: 2
Training loss: 3.1863707991905277
Validation loss: 2.722836523772731

Epoch: 5| Step: 3
Training loss: 2.9551621933782863
Validation loss: 2.72051055937913

Epoch: 5| Step: 4
Training loss: 2.756224783092199
Validation loss: 2.718042778842934

Epoch: 5| Step: 5
Training loss: 3.2326077410686853
Validation loss: 2.718004951799177

Epoch: 5| Step: 6
Training loss: 3.0352706200298525
Validation loss: 2.7190133894710704

Epoch: 5| Step: 7
Training loss: 3.129185124802955
Validation loss: 2.716069455097824

Epoch: 5| Step: 8
Training loss: 2.972562730799402
Validation loss: 2.714618702393964

Epoch: 5| Step: 9
Training loss: 3.193237227690666
Validation loss: 2.7139098057619715

Epoch: 5| Step: 10
Training loss: 3.1128509875107704
Validation loss: 2.714436546459943

Epoch: 61| Step: 0
Training loss: 3.212271976913242
Validation loss: 2.7131084125945106

Epoch: 5| Step: 1
Training loss: 2.6420297892563807
Validation loss: 2.7147294262475348

Epoch: 5| Step: 2
Training loss: 3.248257977110848
Validation loss: 2.7151273137716525

Epoch: 5| Step: 3
Training loss: 3.3581914191792466
Validation loss: 2.7216286304703816

Epoch: 5| Step: 4
Training loss: 3.1530800187651957
Validation loss: 2.7471572710972048

Epoch: 5| Step: 5
Training loss: 2.831290312557929
Validation loss: 2.744151716078876

Epoch: 5| Step: 6
Training loss: 3.0399168720926233
Validation loss: 2.7167364728172676

Epoch: 5| Step: 7
Training loss: 3.1233394025365704
Validation loss: 2.7116558866321054

Epoch: 5| Step: 8
Training loss: 3.230721737089854
Validation loss: 2.7103403087406157

Epoch: 5| Step: 9
Training loss: 2.8143828976914484
Validation loss: 2.7108069732394044

Epoch: 5| Step: 10
Training loss: 2.7673748967428167
Validation loss: 2.716152016817676

Epoch: 62| Step: 0
Training loss: 2.957601716460147
Validation loss: 2.722096590084571

Epoch: 5| Step: 1
Training loss: 2.6484802602731246
Validation loss: 2.71876513239188

Epoch: 5| Step: 2
Training loss: 3.2494391911163216
Validation loss: 2.71591056731606

Epoch: 5| Step: 3
Training loss: 3.0682766986394925
Validation loss: 2.7107298408786886

Epoch: 5| Step: 4
Training loss: 2.766694201673273
Validation loss: 2.707953742776734

Epoch: 5| Step: 5
Training loss: 2.6505734093198323
Validation loss: 2.7056666899786563

Epoch: 5| Step: 6
Training loss: 3.2425954539087916
Validation loss: 2.7028370166269733

Epoch: 5| Step: 7
Training loss: 2.9962385756840177
Validation loss: 2.7037877983229825

Epoch: 5| Step: 8
Training loss: 3.243099075304924
Validation loss: 2.7026090521358386

Epoch: 5| Step: 9
Training loss: 3.033703155470267
Validation loss: 2.699979028920381

Epoch: 5| Step: 10
Training loss: 3.6640023753229296
Validation loss: 2.7016858882776584

Epoch: 63| Step: 0
Training loss: 3.362807538458074
Validation loss: 2.699433843745621

Epoch: 5| Step: 1
Training loss: 2.969650132093587
Validation loss: 2.700174175305

Epoch: 5| Step: 2
Training loss: 2.940357198489992
Validation loss: 2.699198607174057

Epoch: 5| Step: 3
Training loss: 3.012918473298872
Validation loss: 2.698430128922498

Epoch: 5| Step: 4
Training loss: 3.187364163963808
Validation loss: 2.6953153382236303

Epoch: 5| Step: 5
Training loss: 3.2043880298543783
Validation loss: 2.69793673576074

Epoch: 5| Step: 6
Training loss: 2.6303871824184273
Validation loss: 2.6957092050283316

Epoch: 5| Step: 7
Training loss: 2.609418674491815
Validation loss: 2.699793363189317

Epoch: 5| Step: 8
Training loss: 3.0120751235631213
Validation loss: 2.70926700586918

Epoch: 5| Step: 9
Training loss: 3.149130316675353
Validation loss: 2.7331223963834805

Epoch: 5| Step: 10
Training loss: 3.3196849992985586
Validation loss: 2.7288418234979965

Epoch: 64| Step: 0
Training loss: 2.6389131132207475
Validation loss: 2.7234507389175246

Epoch: 5| Step: 1
Training loss: 3.0977075098710376
Validation loss: 2.7225844147383014

Epoch: 5| Step: 2
Training loss: 3.041773197625197
Validation loss: 2.715033214417821

Epoch: 5| Step: 3
Training loss: 2.970254938249133
Validation loss: 2.7130977341565603

Epoch: 5| Step: 4
Training loss: 3.1161377939159536
Validation loss: 2.7089072929517792

Epoch: 5| Step: 5
Training loss: 2.814481164605944
Validation loss: 2.6981487848188506

Epoch: 5| Step: 6
Training loss: 2.818262089288088
Validation loss: 2.703937210042432

Epoch: 5| Step: 7
Training loss: 3.2367665759877773
Validation loss: 2.706048881997717

Epoch: 5| Step: 8
Training loss: 3.7088834518835667
Validation loss: 2.6957631066637955

Epoch: 5| Step: 9
Training loss: 2.848431433306588
Validation loss: 2.693258428830594

Epoch: 5| Step: 10
Training loss: 2.9405068774117766
Validation loss: 2.6928668149369455

Epoch: 65| Step: 0
Training loss: 2.771308016928978
Validation loss: 2.6916460326044636

Epoch: 5| Step: 1
Training loss: 2.8197344665775916
Validation loss: 2.6954142404608694

Epoch: 5| Step: 2
Training loss: 2.913840114095187
Validation loss: 2.7025999040157607

Epoch: 5| Step: 3
Training loss: 3.367632984687563
Validation loss: 2.7120795545835463

Epoch: 5| Step: 4
Training loss: 3.3673781055572203
Validation loss: 2.723361295977066

Epoch: 5| Step: 5
Training loss: 3.3490215352898898
Validation loss: 2.7148226768069437

Epoch: 5| Step: 6
Training loss: 2.678308693852187
Validation loss: 2.6899193874381035

Epoch: 5| Step: 7
Training loss: 3.236163395871765
Validation loss: 2.6868278977497826

Epoch: 5| Step: 8
Training loss: 2.8476277835297004
Validation loss: 2.6856848541044984

Epoch: 5| Step: 9
Training loss: 2.887087745466773
Validation loss: 2.6862074778983858

Epoch: 5| Step: 10
Training loss: 2.9975898916273103
Validation loss: 2.6883618765426496

Epoch: 66| Step: 0
Training loss: 3.011241038789317
Validation loss: 2.6883030040178446

Epoch: 5| Step: 1
Training loss: 3.1495807550363137
Validation loss: 2.683732212576897

Epoch: 5| Step: 2
Training loss: 2.847818503447272
Validation loss: 2.685338770346013

Epoch: 5| Step: 3
Training loss: 3.318447316190515
Validation loss: 2.6863299152822964

Epoch: 5| Step: 4
Training loss: 3.119971387438522
Validation loss: 2.687113702421312

Epoch: 5| Step: 5
Training loss: 3.177325747054127
Validation loss: 2.69017121276193

Epoch: 5| Step: 6
Training loss: 2.3550824659936773
Validation loss: 2.6920593613267454

Epoch: 5| Step: 7
Training loss: 2.74802952308843
Validation loss: 2.69654549622756

Epoch: 5| Step: 8
Training loss: 3.299095382389247
Validation loss: 2.7003424603133515

Epoch: 5| Step: 9
Training loss: 3.0393089841701393
Validation loss: 2.6923487679405222

Epoch: 5| Step: 10
Training loss: 3.116422401552765
Validation loss: 2.6919202080610867

Epoch: 67| Step: 0
Training loss: 3.4140773048341755
Validation loss: 2.6820421997499455

Epoch: 5| Step: 1
Training loss: 3.1309177062466165
Validation loss: 2.677976214144553

Epoch: 5| Step: 2
Training loss: 2.9426234590336686
Validation loss: 2.675972280681045

Epoch: 5| Step: 3
Training loss: 3.188890041863576
Validation loss: 2.6760350677561258

Epoch: 5| Step: 4
Training loss: 2.7864472766312227
Validation loss: 2.6751081278256534

Epoch: 5| Step: 5
Training loss: 3.4479743207431093
Validation loss: 2.6796596811109152

Epoch: 5| Step: 6
Training loss: 3.0722536740370705
Validation loss: 2.672995938045626

Epoch: 5| Step: 7
Training loss: 2.813918370649669
Validation loss: 2.6722798055512658

Epoch: 5| Step: 8
Training loss: 2.283636856324784
Validation loss: 2.669679926095303

Epoch: 5| Step: 9
Training loss: 3.077883638320338
Validation loss: 2.6690066233487038

Epoch: 5| Step: 10
Training loss: 2.8050771458534705
Validation loss: 2.667609666847222

Epoch: 68| Step: 0
Training loss: 3.136106210379483
Validation loss: 2.6692999325218345

Epoch: 5| Step: 1
Training loss: 3.284633672021128
Validation loss: 2.6710541164641826

Epoch: 5| Step: 2
Training loss: 2.9700314617096097
Validation loss: 2.675093283228079

Epoch: 5| Step: 3
Training loss: 2.4600655115910186
Validation loss: 2.6840570674432738

Epoch: 5| Step: 4
Training loss: 2.670919861088668
Validation loss: 2.6914068481877096

Epoch: 5| Step: 5
Training loss: 3.0708325748796357
Validation loss: 2.6817985482012845

Epoch: 5| Step: 6
Training loss: 3.7231918862254836
Validation loss: 2.6814343759921986

Epoch: 5| Step: 7
Training loss: 2.5962772236821503
Validation loss: 2.6690541053904475

Epoch: 5| Step: 8
Training loss: 3.200015312396607
Validation loss: 2.6667329378763487

Epoch: 5| Step: 9
Training loss: 2.921908291713747
Validation loss: 2.667399064233814

Epoch: 5| Step: 10
Training loss: 2.95599871287234
Validation loss: 2.665219187765344

Epoch: 69| Step: 0
Training loss: 3.107908123342324
Validation loss: 2.6658811755052465

Epoch: 5| Step: 1
Training loss: 2.9304300816709503
Validation loss: 2.6682587634142894

Epoch: 5| Step: 2
Training loss: 3.1918649145429745
Validation loss: 2.6709772393699445

Epoch: 5| Step: 3
Training loss: 3.036272116306082
Validation loss: 2.6674826700843757

Epoch: 5| Step: 4
Training loss: 2.689469436451988
Validation loss: 2.6719519750347773

Epoch: 5| Step: 5
Training loss: 3.02343655371836
Validation loss: 2.67170831678142

Epoch: 5| Step: 6
Training loss: 2.7163534015016095
Validation loss: 2.6659234684708286

Epoch: 5| Step: 7
Training loss: 2.6663854768638515
Validation loss: 2.6623395410522757

Epoch: 5| Step: 8
Training loss: 3.273083506086788
Validation loss: 2.6626643369933163

Epoch: 5| Step: 9
Training loss: 3.0388415729466303
Validation loss: 2.6623018546820227

Epoch: 5| Step: 10
Training loss: 3.3836653341376457
Validation loss: 2.6610609787450996

Epoch: 70| Step: 0
Training loss: 3.0578543791244646
Validation loss: 2.6603177623172236

Epoch: 5| Step: 1
Training loss: 3.1996847891532947
Validation loss: 2.66042867336557

Epoch: 5| Step: 2
Training loss: 2.5834496277095
Validation loss: 2.6604461745632313

Epoch: 5| Step: 3
Training loss: 3.07604615938552
Validation loss: 2.661600157338739

Epoch: 5| Step: 4
Training loss: 3.2497284115507763
Validation loss: 2.6631850114423865

Epoch: 5| Step: 5
Training loss: 3.6006769179666933
Validation loss: 2.6684761384657576

Epoch: 5| Step: 6
Training loss: 2.8738629953836266
Validation loss: 2.665965210719927

Epoch: 5| Step: 7
Training loss: 2.768671631403598
Validation loss: 2.6628825817380104

Epoch: 5| Step: 8
Training loss: 2.7975369314801917
Validation loss: 2.66095064946953

Epoch: 5| Step: 9
Training loss: 2.955450040882578
Validation loss: 2.6603159660552036

Epoch: 5| Step: 10
Training loss: 2.6600529990975392
Validation loss: 2.6595834169470716

Epoch: 71| Step: 0
Training loss: 2.939993591301609
Validation loss: 2.65705590276818

Epoch: 5| Step: 1
Training loss: 2.918701079977649
Validation loss: 2.6568023860083234

Epoch: 5| Step: 2
Training loss: 2.880785552549907
Validation loss: 2.6558551839945377

Epoch: 5| Step: 3
Training loss: 2.808990068553236
Validation loss: 2.657383273945139

Epoch: 5| Step: 4
Training loss: 3.3602579065523175
Validation loss: 2.657458898524961

Epoch: 5| Step: 5
Training loss: 3.073561795721957
Validation loss: 2.6569405147402203

Epoch: 5| Step: 6
Training loss: 2.8428849801523763
Validation loss: 2.653515732974669

Epoch: 5| Step: 7
Training loss: 3.3751538559494687
Validation loss: 2.6543220708914137

Epoch: 5| Step: 8
Training loss: 2.468373040500875
Validation loss: 2.654284351817982

Epoch: 5| Step: 9
Training loss: 3.327584379460452
Validation loss: 2.6554110105048703

Epoch: 5| Step: 10
Training loss: 2.808874209093345
Validation loss: 2.654205965169187

Epoch: 72| Step: 0
Training loss: 2.75301733077054
Validation loss: 2.6541538922134515

Epoch: 5| Step: 1
Training loss: 2.7480996241383706
Validation loss: 2.6519950804133856

Epoch: 5| Step: 2
Training loss: 3.2044664504779528
Validation loss: 2.6524265188254366

Epoch: 5| Step: 3
Training loss: 3.3090338656322884
Validation loss: 2.6524165355539795

Epoch: 5| Step: 4
Training loss: 2.897478381941083
Validation loss: 2.6502064786399284

Epoch: 5| Step: 5
Training loss: 2.646461312168882
Validation loss: 2.65205341140469

Epoch: 5| Step: 6
Training loss: 3.2754363373561763
Validation loss: 2.6517356658660334

Epoch: 5| Step: 7
Training loss: 2.9672727422939476
Validation loss: 2.6536936011715633

Epoch: 5| Step: 8
Training loss: 2.9657022994713
Validation loss: 2.655507806675132

Epoch: 5| Step: 9
Training loss: 3.28978657850577
Validation loss: 2.6556148650404263

Epoch: 5| Step: 10
Training loss: 2.67956213477134
Validation loss: 2.657422847581544

Epoch: 73| Step: 0
Training loss: 3.1700689877485253
Validation loss: 2.6580756730273505

Epoch: 5| Step: 1
Training loss: 2.722060982693032
Validation loss: 2.658355640764352

Epoch: 5| Step: 2
Training loss: 3.3005204859552757
Validation loss: 2.653287318464447

Epoch: 5| Step: 3
Training loss: 2.74713453644264
Validation loss: 2.6518446292153

Epoch: 5| Step: 4
Training loss: 2.7480220617327693
Validation loss: 2.6538436490508923

Epoch: 5| Step: 5
Training loss: 3.061383413614075
Validation loss: 2.6526520385418437

Epoch: 5| Step: 6
Training loss: 3.1717427042915323
Validation loss: 2.6464025740817996

Epoch: 5| Step: 7
Training loss: 2.52058651138761
Validation loss: 2.647120091090313

Epoch: 5| Step: 8
Training loss: 2.7807645909911636
Validation loss: 2.643320173079674

Epoch: 5| Step: 9
Training loss: 2.998729595768448
Validation loss: 2.645600991241202

Epoch: 5| Step: 10
Training loss: 3.561269848903133
Validation loss: 2.644655703107302

Epoch: 74| Step: 0
Training loss: 2.262963777502542
Validation loss: 2.644820832442972

Epoch: 5| Step: 1
Training loss: 2.8176577428952245
Validation loss: 2.6462230290420368

Epoch: 5| Step: 2
Training loss: 3.75667511982772
Validation loss: 2.6449121259199004

Epoch: 5| Step: 3
Training loss: 3.2376748174062513
Validation loss: 2.6427958119231323

Epoch: 5| Step: 4
Training loss: 3.163527455244068
Validation loss: 2.6408317884452717

Epoch: 5| Step: 5
Training loss: 3.020145329142799
Validation loss: 2.638911578288293

Epoch: 5| Step: 6
Training loss: 2.9033612076143545
Validation loss: 2.6383474223717682

Epoch: 5| Step: 7
Training loss: 2.986731592420647
Validation loss: 2.637355682727933

Epoch: 5| Step: 8
Training loss: 3.0296352844302956
Validation loss: 2.636979937391616

Epoch: 5| Step: 9
Training loss: 2.685643197846452
Validation loss: 2.638729004333206

Epoch: 5| Step: 10
Training loss: 2.726837931277653
Validation loss: 2.6395779911524646

Epoch: 75| Step: 0
Training loss: 2.7309069629746787
Validation loss: 2.632417227720063

Epoch: 5| Step: 1
Training loss: 2.24998198607969
Validation loss: 2.632243976790571

Epoch: 5| Step: 2
Training loss: 3.234446649172432
Validation loss: 2.6459952154642656

Epoch: 5| Step: 3
Training loss: 3.6089831383095348
Validation loss: 2.6711920898320303

Epoch: 5| Step: 4
Training loss: 2.7248961157639244
Validation loss: 2.6551030963829088

Epoch: 5| Step: 5
Training loss: 2.9582147887929473
Validation loss: 2.6359316966138966

Epoch: 5| Step: 6
Training loss: 3.1185942035664973
Validation loss: 2.6352697666531384

Epoch: 5| Step: 7
Training loss: 3.3339191557768553
Validation loss: 2.64162301309259

Epoch: 5| Step: 8
Training loss: 2.625825570483543
Validation loss: 2.6453005682511024

Epoch: 5| Step: 9
Training loss: 2.952864378070608
Validation loss: 2.6502164218699638

Epoch: 5| Step: 10
Training loss: 3.185032506564273
Validation loss: 2.647162970457154

Epoch: 76| Step: 0
Training loss: 3.0665115241184515
Validation loss: 2.6669981289666422

Epoch: 5| Step: 1
Training loss: 2.868524639777178
Validation loss: 2.680745529454192

Epoch: 5| Step: 2
Training loss: 3.345600222348498
Validation loss: 2.6833382759387563

Epoch: 5| Step: 3
Training loss: 2.772057848278582
Validation loss: 2.645557055503359

Epoch: 5| Step: 4
Training loss: 2.530880182825116
Validation loss: 2.6442789794854824

Epoch: 5| Step: 5
Training loss: 3.045690844360502
Validation loss: 2.6450655534323158

Epoch: 5| Step: 6
Training loss: 2.7717852761800534
Validation loss: 2.6408124850959447

Epoch: 5| Step: 7
Training loss: 2.751346865191904
Validation loss: 2.643729998688587

Epoch: 5| Step: 8
Training loss: 3.1511446008604915
Validation loss: 2.6574193987434236

Epoch: 5| Step: 9
Training loss: 3.7111140480207547
Validation loss: 2.6520722825232776

Epoch: 5| Step: 10
Training loss: 2.8024425819905754
Validation loss: 2.6352314304939215

Epoch: 77| Step: 0
Training loss: 3.3579764360302
Validation loss: 2.632461442166697

Epoch: 5| Step: 1
Training loss: 2.7597921468725155
Validation loss: 2.637648313701304

Epoch: 5| Step: 2
Training loss: 2.8041225703845383
Validation loss: 2.6507594499519422

Epoch: 5| Step: 3
Training loss: 2.5558439198032064
Validation loss: 2.6696900099780967

Epoch: 5| Step: 4
Training loss: 3.0304507745503235
Validation loss: 2.686620357985279

Epoch: 5| Step: 5
Training loss: 3.4348978076820202
Validation loss: 2.694397317586773

Epoch: 5| Step: 6
Training loss: 3.1656438949337384
Validation loss: 2.6594863555758512

Epoch: 5| Step: 7
Training loss: 3.0583497555436474
Validation loss: 2.651925047115367

Epoch: 5| Step: 8
Training loss: 2.915326946107032
Validation loss: 2.6416065284785897

Epoch: 5| Step: 9
Training loss: 3.087262682732453
Validation loss: 2.62621091589374

Epoch: 5| Step: 10
Training loss: 2.5557854302536485
Validation loss: 2.622547179547437

Epoch: 78| Step: 0
Training loss: 2.8795809530996177
Validation loss: 2.6316156109305155

Epoch: 5| Step: 1
Training loss: 2.328983737356457
Validation loss: 2.6490936778038683

Epoch: 5| Step: 2
Training loss: 3.0282365430005247
Validation loss: 2.65748710705831

Epoch: 5| Step: 3
Training loss: 2.630562655815184
Validation loss: 2.684061738056262

Epoch: 5| Step: 4
Training loss: 2.76411310454732
Validation loss: 2.678201443755529

Epoch: 5| Step: 5
Training loss: 3.2406471362043043
Validation loss: 2.646664981365197

Epoch: 5| Step: 6
Training loss: 2.7962095012298462
Validation loss: 2.622603471470952

Epoch: 5| Step: 7
Training loss: 2.947254299700739
Validation loss: 2.6186102560407662

Epoch: 5| Step: 8
Training loss: 3.5303643390354216
Validation loss: 2.619269347077521

Epoch: 5| Step: 9
Training loss: 3.313091872977425
Validation loss: 2.6192705764019837

Epoch: 5| Step: 10
Training loss: 3.161208082639934
Validation loss: 2.6184874659667323

Epoch: 79| Step: 0
Training loss: 3.241088680985557
Validation loss: 2.6201454585381234

Epoch: 5| Step: 1
Training loss: 2.763121252844754
Validation loss: 2.6253474377211017

Epoch: 5| Step: 2
Training loss: 3.0692694447737203
Validation loss: 2.6355574641290875

Epoch: 5| Step: 3
Training loss: 2.88208015050892
Validation loss: 2.649350742265158

Epoch: 5| Step: 4
Training loss: 2.8460469453844275
Validation loss: 2.6706498421970735

Epoch: 5| Step: 5
Training loss: 3.235076385964087
Validation loss: 2.6893565754212383

Epoch: 5| Step: 6
Training loss: 2.9691458990238155
Validation loss: 2.6653775376146855

Epoch: 5| Step: 7
Training loss: 3.280918358891297
Validation loss: 2.6457453809916442

Epoch: 5| Step: 8
Training loss: 2.5416108005408264
Validation loss: 2.628371275652515

Epoch: 5| Step: 9
Training loss: 2.7448736440346955
Validation loss: 2.6218800087782332

Epoch: 5| Step: 10
Training loss: 3.0813284533187053
Validation loss: 2.619441453739626

Epoch: 80| Step: 0
Training loss: 2.8480602757472586
Validation loss: 2.618710641606555

Epoch: 5| Step: 1
Training loss: 2.668794339457119
Validation loss: 2.6237312518544926

Epoch: 5| Step: 2
Training loss: 2.638728979073069
Validation loss: 2.6229913451695896

Epoch: 5| Step: 3
Training loss: 3.405048823517741
Validation loss: 2.6436276539445975

Epoch: 5| Step: 4
Training loss: 2.9855858708038125
Validation loss: 2.6488900192037113

Epoch: 5| Step: 5
Training loss: 2.8207322756659994
Validation loss: 2.6171458143509088

Epoch: 5| Step: 6
Training loss: 3.2266504308066146
Validation loss: 2.6195667739272457

Epoch: 5| Step: 7
Training loss: 2.9304730392176523
Validation loss: 2.622846250150758

Epoch: 5| Step: 8
Training loss: 3.1162496508779074
Validation loss: 2.6196421015393665

Epoch: 5| Step: 9
Training loss: 3.1576379424806538
Validation loss: 2.6209452364975268

Epoch: 5| Step: 10
Training loss: 2.875359720033701
Validation loss: 2.6207446146126707

Epoch: 81| Step: 0
Training loss: 2.6813999409754476
Validation loss: 2.6237605040294043

Epoch: 5| Step: 1
Training loss: 3.053784639440783
Validation loss: 2.6269449196293286

Epoch: 5| Step: 2
Training loss: 2.652874406138763
Validation loss: 2.6243078996290135

Epoch: 5| Step: 3
Training loss: 3.642237228518839
Validation loss: 2.6158798455289203

Epoch: 5| Step: 4
Training loss: 3.0722423438604545
Validation loss: 2.6106401333411062

Epoch: 5| Step: 5
Training loss: 3.1511265935040718
Validation loss: 2.6065261554049313

Epoch: 5| Step: 6
Training loss: 2.9114205910153355
Validation loss: 2.6039522426476336

Epoch: 5| Step: 7
Training loss: 2.9161694965786675
Validation loss: 2.603999132899628

Epoch: 5| Step: 8
Training loss: 2.866536827991308
Validation loss: 2.6044714892426772

Epoch: 5| Step: 9
Training loss: 2.7074372398591033
Validation loss: 2.607549158129499

Epoch: 5| Step: 10
Training loss: 2.779800551690307
Validation loss: 2.6183403619078547

Epoch: 82| Step: 0
Training loss: 3.2071093086286715
Validation loss: 2.6204369023031417

Epoch: 5| Step: 1
Training loss: 2.8255315027460326
Validation loss: 2.631295159673138

Epoch: 5| Step: 2
Training loss: 2.7539656395967596
Validation loss: 2.6662289243497757

Epoch: 5| Step: 3
Training loss: 3.2222265338503466
Validation loss: 2.6774954874586205

Epoch: 5| Step: 4
Training loss: 2.910220151878112
Validation loss: 2.6378753806329134

Epoch: 5| Step: 5
Training loss: 2.5594847081557175
Validation loss: 2.6068850525205582

Epoch: 5| Step: 6
Training loss: 2.9401856178284316
Validation loss: 2.6013873794358244

Epoch: 5| Step: 7
Training loss: 3.071078061859733
Validation loss: 2.598499897268642

Epoch: 5| Step: 8
Training loss: 3.231634480901554
Validation loss: 2.5996473834469622

Epoch: 5| Step: 9
Training loss: 3.1493501689255248
Validation loss: 2.598613809805108

Epoch: 5| Step: 10
Training loss: 2.5220645913634
Validation loss: 2.5974680324514936

Epoch: 83| Step: 0
Training loss: 2.6334006900462255
Validation loss: 2.59917951010951

Epoch: 5| Step: 1
Training loss: 2.1576803135142955
Validation loss: 2.6020694263293875

Epoch: 5| Step: 2
Training loss: 3.438694694293392
Validation loss: 2.5969205342614035

Epoch: 5| Step: 3
Training loss: 2.718323860533967
Validation loss: 2.599249161608388

Epoch: 5| Step: 4
Training loss: 3.57938812482588
Validation loss: 2.6032177606916194

Epoch: 5| Step: 5
Training loss: 3.0358632956726175
Validation loss: 2.601594009708696

Epoch: 5| Step: 6
Training loss: 2.932676697697892
Validation loss: 2.5976944217349165

Epoch: 5| Step: 7
Training loss: 2.677548280310926
Validation loss: 2.597402537820592

Epoch: 5| Step: 8
Training loss: 3.2091891315723586
Validation loss: 2.6027282479853966

Epoch: 5| Step: 9
Training loss: 2.808283209046829
Validation loss: 2.6031773935559963

Epoch: 5| Step: 10
Training loss: 3.081903452574595
Validation loss: 2.6008338369695805

Epoch: 84| Step: 0
Training loss: 2.82930060974574
Validation loss: 2.595966506951368

Epoch: 5| Step: 1
Training loss: 2.7833670798747634
Validation loss: 2.5984107716110336

Epoch: 5| Step: 2
Training loss: 3.097162849606068
Validation loss: 2.597288628421418

Epoch: 5| Step: 3
Training loss: 3.05241102384192
Validation loss: 2.600025411115648

Epoch: 5| Step: 4
Training loss: 2.742802129914724
Validation loss: 2.602453225478411

Epoch: 5| Step: 5
Training loss: 3.1066112408039177
Validation loss: 2.600055865704372

Epoch: 5| Step: 6
Training loss: 2.6953162151808634
Validation loss: 2.5958799889284827

Epoch: 5| Step: 7
Training loss: 2.8455677301352553
Validation loss: 2.5899498503468474

Epoch: 5| Step: 8
Training loss: 2.553156496038133
Validation loss: 2.590441956900159

Epoch: 5| Step: 9
Training loss: 3.09443518247042
Validation loss: 2.594241524044445

Epoch: 5| Step: 10
Training loss: 3.5741960701978526
Validation loss: 2.5959684529132923

Epoch: 85| Step: 0
Training loss: 3.075301371126803
Validation loss: 2.6000091725322516

Epoch: 5| Step: 1
Training loss: 2.9025671810027713
Validation loss: 2.6032108301746026

Epoch: 5| Step: 2
Training loss: 2.8460660452990374
Validation loss: 2.5981895563641233

Epoch: 5| Step: 3
Training loss: 2.77969196698761
Validation loss: 2.585763889075427

Epoch: 5| Step: 4
Training loss: 2.8557920259891345
Validation loss: 2.586517676356918

Epoch: 5| Step: 5
Training loss: 3.2121711829853137
Validation loss: 2.583975916111453

Epoch: 5| Step: 6
Training loss: 2.8217007504015896
Validation loss: 2.583683157611064

Epoch: 5| Step: 7
Training loss: 2.7274162464237293
Validation loss: 2.5870390200559634

Epoch: 5| Step: 8
Training loss: 3.3475363141256063
Validation loss: 2.596766189244904

Epoch: 5| Step: 9
Training loss: 2.7227400516436493
Validation loss: 2.5990497506368566

Epoch: 5| Step: 10
Training loss: 3.0785254203486625
Validation loss: 2.62256961004818

Epoch: 86| Step: 0
Training loss: 2.526479015964536
Validation loss: 2.6511809970853597

Epoch: 5| Step: 1
Training loss: 2.581612095593658
Validation loss: 2.6770025271185824

Epoch: 5| Step: 2
Training loss: 3.2961171802412226
Validation loss: 2.680608351934897

Epoch: 5| Step: 3
Training loss: 2.9140425366901646
Validation loss: 2.6490164895346067

Epoch: 5| Step: 4
Training loss: 3.1832050484045147
Validation loss: 2.5980733502824656

Epoch: 5| Step: 5
Training loss: 3.089698682000664
Validation loss: 2.5799682561004698

Epoch: 5| Step: 6
Training loss: 2.9796664656810337
Validation loss: 2.5825042194617525

Epoch: 5| Step: 7
Training loss: 3.0607134220499153
Validation loss: 2.5872590761562897

Epoch: 5| Step: 8
Training loss: 2.948565156777894
Validation loss: 2.594576634102073

Epoch: 5| Step: 9
Training loss: 2.881324942518188
Validation loss: 2.5949392714317745

Epoch: 5| Step: 10
Training loss: 3.042264766329069
Validation loss: 2.591530789583939

Epoch: 87| Step: 0
Training loss: 2.301619424005938
Validation loss: 2.5891277859329263

Epoch: 5| Step: 1
Training loss: 3.328272569993464
Validation loss: 2.5840868338912535

Epoch: 5| Step: 2
Training loss: 3.147750741729031
Validation loss: 2.579106963919172

Epoch: 5| Step: 3
Training loss: 3.115767459042103
Validation loss: 2.5805507629828766

Epoch: 5| Step: 4
Training loss: 2.755930401530901
Validation loss: 2.5783975913881707

Epoch: 5| Step: 5
Training loss: 2.7606206758554666
Validation loss: 2.5841421352414056

Epoch: 5| Step: 6
Training loss: 3.333256307347761
Validation loss: 2.5912894804579607

Epoch: 5| Step: 7
Training loss: 2.4506687575045283
Validation loss: 2.61162124183841

Epoch: 5| Step: 8
Training loss: 3.015498025227164
Validation loss: 2.6494104638982816

Epoch: 5| Step: 9
Training loss: 2.896297518258444
Validation loss: 2.605441726766065

Epoch: 5| Step: 10
Training loss: 3.352582300642382
Validation loss: 2.5823874420645563

Epoch: 88| Step: 0
Training loss: 2.9478522160003084
Validation loss: 2.582138272029468

Epoch: 5| Step: 1
Training loss: 2.74027387572875
Validation loss: 2.5831189832435215

Epoch: 5| Step: 2
Training loss: 3.2929561519721204
Validation loss: 2.5769173277980135

Epoch: 5| Step: 3
Training loss: 2.2119218232479745
Validation loss: 2.5877995800952824

Epoch: 5| Step: 4
Training loss: 3.3530543281665923
Validation loss: 2.5886644544035367

Epoch: 5| Step: 5
Training loss: 3.054548723819767
Validation loss: 2.601265766170743

Epoch: 5| Step: 6
Training loss: 2.8920583109800684
Validation loss: 2.5982602891573574

Epoch: 5| Step: 7
Training loss: 2.7906680147587264
Validation loss: 2.5895623299637065

Epoch: 5| Step: 8
Training loss: 2.3138450628584772
Validation loss: 2.5829198832588043

Epoch: 5| Step: 9
Training loss: 3.531735682212942
Validation loss: 2.5804082371411323

Epoch: 5| Step: 10
Training loss: 2.964321326667265
Validation loss: 2.5787492182218577

Epoch: 89| Step: 0
Training loss: 3.3232909722212653
Validation loss: 2.5789274625586143

Epoch: 5| Step: 1
Training loss: 3.019705428100158
Validation loss: 2.5761515651951763

Epoch: 5| Step: 2
Training loss: 2.992587468678306
Validation loss: 2.576295689795447

Epoch: 5| Step: 3
Training loss: 3.3598459312901294
Validation loss: 2.5731224312236773

Epoch: 5| Step: 4
Training loss: 3.0604008857072618
Validation loss: 2.571419210908491

Epoch: 5| Step: 5
Training loss: 2.778731330812299
Validation loss: 2.569728229980959

Epoch: 5| Step: 6
Training loss: 2.7715247207081406
Validation loss: 2.5714872944260336

Epoch: 5| Step: 7
Training loss: 2.742003345011668
Validation loss: 2.576430988342792

Epoch: 5| Step: 8
Training loss: 2.9583687220502903
Validation loss: 2.580834967576721

Epoch: 5| Step: 9
Training loss: 2.7271097502996544
Validation loss: 2.590416295050926

Epoch: 5| Step: 10
Training loss: 2.4584578358648126
Validation loss: 2.5983671646721964

Epoch: 90| Step: 0
Training loss: 3.395370327017772
Validation loss: 2.5881019750852765

Epoch: 5| Step: 1
Training loss: 2.6614348129955134
Validation loss: 2.5780421258925528

Epoch: 5| Step: 2
Training loss: 2.819130351251501
Validation loss: 2.578668284917401

Epoch: 5| Step: 3
Training loss: 3.043162740025626
Validation loss: 2.57508611832751

Epoch: 5| Step: 4
Training loss: 3.1525107413947655
Validation loss: 2.577511882747231

Epoch: 5| Step: 5
Training loss: 2.816229995947718
Validation loss: 2.580688564322656

Epoch: 5| Step: 6
Training loss: 3.156920409056302
Validation loss: 2.5789923269557256

Epoch: 5| Step: 7
Training loss: 3.0511851025110155
Validation loss: 2.5847486769597356

Epoch: 5| Step: 8
Training loss: 2.3398939837379507
Validation loss: 2.579423858522456

Epoch: 5| Step: 9
Training loss: 2.627966340091852
Validation loss: 2.5786025563650132

Epoch: 5| Step: 10
Training loss: 3.068038447719815
Validation loss: 2.5814913978594856

Epoch: 91| Step: 0
Training loss: 3.158965802506613
Validation loss: 2.572362754382583

Epoch: 5| Step: 1
Training loss: 2.803450202577188
Validation loss: 2.5732363294334064

Epoch: 5| Step: 2
Training loss: 2.5454931898713453
Validation loss: 2.5738835940151

Epoch: 5| Step: 3
Training loss: 2.9334175473464525
Validation loss: 2.5749684788349354

Epoch: 5| Step: 4
Training loss: 3.052972726919367
Validation loss: 2.577011885355437

Epoch: 5| Step: 5
Training loss: 3.312931824373876
Validation loss: 2.5795244880153487

Epoch: 5| Step: 6
Training loss: 3.1522139625349967
Validation loss: 2.5775927001894874

Epoch: 5| Step: 7
Training loss: 2.802751558364137
Validation loss: 2.5792498946401636

Epoch: 5| Step: 8
Training loss: 3.099036122262043
Validation loss: 2.5763900761329364

Epoch: 5| Step: 9
Training loss: 2.684699262545073
Validation loss: 2.5749314123509737

Epoch: 5| Step: 10
Training loss: 2.8455456105600105
Validation loss: 2.570310443351594

Epoch: 92| Step: 0
Training loss: 2.9066524432064704
Validation loss: 2.571526092381671

Epoch: 5| Step: 1
Training loss: 3.1053116668703127
Validation loss: 2.5719605691654204

Epoch: 5| Step: 2
Training loss: 2.6818893772896457
Validation loss: 2.5725417730677544

Epoch: 5| Step: 3
Training loss: 2.9500639051854
Validation loss: 2.5825687716659638

Epoch: 5| Step: 4
Training loss: 2.9916696922124015
Validation loss: 2.5895283423963034

Epoch: 5| Step: 5
Training loss: 2.2495913664303497
Validation loss: 2.589344087386549

Epoch: 5| Step: 6
Training loss: 3.179515637151302
Validation loss: 2.5987299695231196

Epoch: 5| Step: 7
Training loss: 2.867688210653827
Validation loss: 2.6176228087311912

Epoch: 5| Step: 8
Training loss: 3.291826043113475
Validation loss: 2.614248801401597

Epoch: 5| Step: 9
Training loss: 3.0125250027833825
Validation loss: 2.609721527659525

Epoch: 5| Step: 10
Training loss: 2.899020647884025
Validation loss: 2.592833537825046

Epoch: 93| Step: 0
Training loss: 3.260736776771866
Validation loss: 2.5802770200142815

Epoch: 5| Step: 1
Training loss: 2.682273839996258
Validation loss: 2.56706267681736

Epoch: 5| Step: 2
Training loss: 2.712824711503535
Validation loss: 2.5625069570859624

Epoch: 5| Step: 3
Training loss: 3.2793793204998667
Validation loss: 2.560413596697447

Epoch: 5| Step: 4
Training loss: 3.2554138281491776
Validation loss: 2.5638703114620283

Epoch: 5| Step: 5
Training loss: 2.82327191321691
Validation loss: 2.560716155696318

Epoch: 5| Step: 6
Training loss: 3.283935319995369
Validation loss: 2.5586155868959843

Epoch: 5| Step: 7
Training loss: 2.5548214191951404
Validation loss: 2.557221760922248

Epoch: 5| Step: 8
Training loss: 2.777553459222982
Validation loss: 2.5580212209659736

Epoch: 5| Step: 9
Training loss: 2.623534565550487
Validation loss: 2.5560951264821403

Epoch: 5| Step: 10
Training loss: 2.7690405148579544
Validation loss: 2.557198301075859

Epoch: 94| Step: 0
Training loss: 2.372601954818958
Validation loss: 2.5610325000490737

Epoch: 5| Step: 1
Training loss: 3.056091142204042
Validation loss: 2.565494102738176

Epoch: 5| Step: 2
Training loss: 2.9176927305760203
Validation loss: 2.564079678155665

Epoch: 5| Step: 3
Training loss: 2.4930291264466367
Validation loss: 2.5513810203274416

Epoch: 5| Step: 4
Training loss: 2.4117560865393233
Validation loss: 2.5459386112156217

Epoch: 5| Step: 5
Training loss: 3.063144538161711
Validation loss: 2.5468083301270585

Epoch: 5| Step: 6
Training loss: 3.0342590498451814
Validation loss: 2.545609346486878

Epoch: 5| Step: 7
Training loss: 2.7663347443477706
Validation loss: 2.5461915744548684

Epoch: 5| Step: 8
Training loss: 3.14259329840184
Validation loss: 2.5441959941203325

Epoch: 5| Step: 9
Training loss: 3.2549327682841325
Validation loss: 2.5481486691182935

Epoch: 5| Step: 10
Training loss: 3.495626987434203
Validation loss: 2.549761154181407

Epoch: 95| Step: 0
Training loss: 3.2399092793420463
Validation loss: 2.5586771368024452

Epoch: 5| Step: 1
Training loss: 2.5148064839593354
Validation loss: 2.57514897293989

Epoch: 5| Step: 2
Training loss: 3.0776919917221486
Validation loss: 2.5901708795194267

Epoch: 5| Step: 3
Training loss: 2.9344463303156405
Validation loss: 2.5863980907086686

Epoch: 5| Step: 4
Training loss: 2.579608467319319
Validation loss: 2.5844092869030737

Epoch: 5| Step: 5
Training loss: 3.2545969803520376
Validation loss: 2.560758231348947

Epoch: 5| Step: 6
Training loss: 2.9111939084393157
Validation loss: 2.549035197083048

Epoch: 5| Step: 7
Training loss: 2.351778749173633
Validation loss: 2.5400192197454117

Epoch: 5| Step: 8
Training loss: 3.043005417883215
Validation loss: 2.5365417800952503

Epoch: 5| Step: 9
Training loss: 3.283895098526663
Validation loss: 2.537569995607596

Epoch: 5| Step: 10
Training loss: 2.7164482809023593
Validation loss: 2.534110133755976

Epoch: 96| Step: 0
Training loss: 2.689141770058369
Validation loss: 2.5330705080394615

Epoch: 5| Step: 1
Training loss: 3.562963756692783
Validation loss: 2.5328725366865275

Epoch: 5| Step: 2
Training loss: 3.0585086269883734
Validation loss: 2.5322954496972447

Epoch: 5| Step: 3
Training loss: 2.863376173499024
Validation loss: 2.5337142768290413

Epoch: 5| Step: 4
Training loss: 2.5112777014230327
Validation loss: 2.5339882342004247

Epoch: 5| Step: 5
Training loss: 2.902923649271709
Validation loss: 2.5410640418380517

Epoch: 5| Step: 6
Training loss: 2.802417910051626
Validation loss: 2.5372807235696464

Epoch: 5| Step: 7
Training loss: 2.8610813073475243
Validation loss: 2.5555890038619635

Epoch: 5| Step: 8
Training loss: 3.4340599186268195
Validation loss: 2.5808585532789725

Epoch: 5| Step: 9
Training loss: 2.146060919189404
Validation loss: 2.604242145716055

Epoch: 5| Step: 10
Training loss: 2.8840600599153996
Validation loss: 2.5831516825878347

Epoch: 97| Step: 0
Training loss: 2.3740348862717564
Validation loss: 2.5711135939919827

Epoch: 5| Step: 1
Training loss: 3.036197989259012
Validation loss: 2.5540411873787465

Epoch: 5| Step: 2
Training loss: 2.6077947342840595
Validation loss: 2.544644898658386

Epoch: 5| Step: 3
Training loss: 3.1254433889551536
Validation loss: 2.5390741698546697

Epoch: 5| Step: 4
Training loss: 3.491897878221978
Validation loss: 2.537541388531715

Epoch: 5| Step: 5
Training loss: 3.0443185890091593
Validation loss: 2.5363378250843924

Epoch: 5| Step: 6
Training loss: 2.7511411379985113
Validation loss: 2.531292283892373

Epoch: 5| Step: 7
Training loss: 3.025480147158399
Validation loss: 2.5328914566892995

Epoch: 5| Step: 8
Training loss: 3.007544408963433
Validation loss: 2.5303218815685797

Epoch: 5| Step: 9
Training loss: 2.7766207627176662
Validation loss: 2.5310071076399288

Epoch: 5| Step: 10
Training loss: 2.3983943574982804
Validation loss: 2.5316903386969125

Epoch: 98| Step: 0
Training loss: 3.348121423795954
Validation loss: 2.5301815215149532

Epoch: 5| Step: 1
Training loss: 2.7633194445946265
Validation loss: 2.528623837317181

Epoch: 5| Step: 2
Training loss: 3.154455902531469
Validation loss: 2.5334004016292604

Epoch: 5| Step: 3
Training loss: 2.5828232928244987
Validation loss: 2.53451354034531

Epoch: 5| Step: 4
Training loss: 2.9287537574499742
Validation loss: 2.5360330753822113

Epoch: 5| Step: 5
Training loss: 2.6775310948380158
Validation loss: 2.53238727883136

Epoch: 5| Step: 6
Training loss: 2.9554629481856383
Validation loss: 2.5304823632709565

Epoch: 5| Step: 7
Training loss: 2.9849565348823286
Validation loss: 2.5367044534661267

Epoch: 5| Step: 8
Training loss: 2.8371438227204453
Validation loss: 2.533312810929121

Epoch: 5| Step: 9
Training loss: 2.966203742038336
Validation loss: 2.52814338478948

Epoch: 5| Step: 10
Training loss: 2.4651434908068404
Validation loss: 2.533682938816889

Epoch: 99| Step: 0
Training loss: 2.753779068844061
Validation loss: 2.5386439410228534

Epoch: 5| Step: 1
Training loss: 2.918525612025167
Validation loss: 2.555228779195469

Epoch: 5| Step: 2
Training loss: 2.8039139129712525
Validation loss: 2.5636629656530845

Epoch: 5| Step: 3
Training loss: 3.1506960508526363
Validation loss: 2.556125323181603

Epoch: 5| Step: 4
Training loss: 2.8370772664436696
Validation loss: 2.5460291729478435

Epoch: 5| Step: 5
Training loss: 3.1591064821985886
Validation loss: 2.5412001105100877

Epoch: 5| Step: 6
Training loss: 3.147764072384636
Validation loss: 2.531756564200771

Epoch: 5| Step: 7
Training loss: 3.0178519609266536
Validation loss: 2.526256615479672

Epoch: 5| Step: 8
Training loss: 2.584606738696117
Validation loss: 2.527992420022654

Epoch: 5| Step: 9
Training loss: 2.8740768609118996
Validation loss: 2.5273109869199497

Epoch: 5| Step: 10
Training loss: 2.517523008087998
Validation loss: 2.5262555885036977

Epoch: 100| Step: 0
Training loss: 2.951224709725181
Validation loss: 2.523095137189456

Epoch: 5| Step: 1
Training loss: 2.7581059891360864
Validation loss: 2.5295032473566903

Epoch: 5| Step: 2
Training loss: 2.877861589105669
Validation loss: 2.528307856863354

Epoch: 5| Step: 3
Training loss: 3.0371335534608312
Validation loss: 2.5345211922721287

Epoch: 5| Step: 4
Training loss: 3.105124016587136
Validation loss: 2.5346465136885046

Epoch: 5| Step: 5
Training loss: 2.6873540616887004
Validation loss: 2.545610633538997

Epoch: 5| Step: 6
Training loss: 2.4688720672946927
Validation loss: 2.5507784137717286

Epoch: 5| Step: 7
Training loss: 3.109180386841117
Validation loss: 2.5527596042061482

Epoch: 5| Step: 8
Training loss: 3.283212274814362
Validation loss: 2.544426833593344

Epoch: 5| Step: 9
Training loss: 2.7086525557752354
Validation loss: 2.5436582208258742

Epoch: 5| Step: 10
Training loss: 2.7063532609158534
Validation loss: 2.5398319473754696

Epoch: 101| Step: 0
Training loss: 2.773768789357535
Validation loss: 2.542119245280167

Epoch: 5| Step: 1
Training loss: 2.840510273075983
Validation loss: 2.557299148518217

Epoch: 5| Step: 2
Training loss: 2.8067645614326486
Validation loss: 2.543913628893002

Epoch: 5| Step: 3
Training loss: 3.3290113244956987
Validation loss: 2.547270169362656

Epoch: 5| Step: 4
Training loss: 3.073902622822448
Validation loss: 2.5394630831743292

Epoch: 5| Step: 5
Training loss: 3.326691224638884
Validation loss: 2.5345073773159417

Epoch: 5| Step: 6
Training loss: 3.339299743249856
Validation loss: 2.535573969209829

Epoch: 5| Step: 7
Training loss: 2.389977660453809
Validation loss: 2.5337751183332546

Epoch: 5| Step: 8
Training loss: 2.642839124242563
Validation loss: 2.537625633809954

Epoch: 5| Step: 9
Training loss: 2.687635285277052
Validation loss: 2.546002484466854

Epoch: 5| Step: 10
Training loss: 2.3334516994789647
Validation loss: 2.5558380639874194

Epoch: 102| Step: 0
Training loss: 2.6567999775303877
Validation loss: 2.561251987950625

Epoch: 5| Step: 1
Training loss: 2.9292608738849037
Validation loss: 2.562585342550781

Epoch: 5| Step: 2
Training loss: 2.5872565187163286
Validation loss: 2.566995904078471

Epoch: 5| Step: 3
Training loss: 2.5921056659788877
Validation loss: 2.5799611702200784

Epoch: 5| Step: 4
Training loss: 3.2208165321717925
Validation loss: 2.586133328334261

Epoch: 5| Step: 5
Training loss: 3.238586632257008
Validation loss: 2.570947004185116

Epoch: 5| Step: 6
Training loss: 2.2349163546687207
Validation loss: 2.57372986263544

Epoch: 5| Step: 7
Training loss: 3.1095582534233226
Validation loss: 2.5569200798189975

Epoch: 5| Step: 8
Training loss: 2.897246493949747
Validation loss: 2.540414414615323

Epoch: 5| Step: 9
Training loss: 2.838410447380338
Validation loss: 2.5402414436879868

Epoch: 5| Step: 10
Training loss: 3.3229101454014103
Validation loss: 2.5236729241226636

Epoch: 103| Step: 0
Training loss: 3.086728846814194
Validation loss: 2.5266237174214576

Epoch: 5| Step: 1
Training loss: 3.0085614745757265
Validation loss: 2.5243706925239398

Epoch: 5| Step: 2
Training loss: 2.7518067060387623
Validation loss: 2.53038923100128

Epoch: 5| Step: 3
Training loss: 3.2479238481097608
Validation loss: 2.5457301754865553

Epoch: 5| Step: 4
Training loss: 3.1983686162987994
Validation loss: 2.5370093155262308

Epoch: 5| Step: 5
Training loss: 2.825975728955964
Validation loss: 2.5252632828682513

Epoch: 5| Step: 6
Training loss: 2.6831115555976224
Validation loss: 2.52419845946596

Epoch: 5| Step: 7
Training loss: 2.801729560462298
Validation loss: 2.5295298960719523

Epoch: 5| Step: 8
Training loss: 2.517874996891125
Validation loss: 2.531769145645686

Epoch: 5| Step: 9
Training loss: 2.6515907263616216
Validation loss: 2.5387295917264616

Epoch: 5| Step: 10
Training loss: 2.850893375850158
Validation loss: 2.5425854102845205

Epoch: 104| Step: 0
Training loss: 3.046705974878981
Validation loss: 2.5889398534281147

Epoch: 5| Step: 1
Training loss: 2.7893164596551734
Validation loss: 2.6147478521952827

Epoch: 5| Step: 2
Training loss: 2.712361689965928
Validation loss: 2.6009828211831816

Epoch: 5| Step: 3
Training loss: 2.964998625679405
Validation loss: 2.5586117423573365

Epoch: 5| Step: 4
Training loss: 2.5985883144853728
Validation loss: 2.5435198445107976

Epoch: 5| Step: 5
Training loss: 2.9876497686026626
Validation loss: 2.5378997982829183

Epoch: 5| Step: 6
Training loss: 2.0591347723600286
Validation loss: 2.5324228229029226

Epoch: 5| Step: 7
Training loss: 3.4103977253332927
Validation loss: 2.526839387452237

Epoch: 5| Step: 8
Training loss: 3.11264188512024
Validation loss: 2.522307396577937

Epoch: 5| Step: 9
Training loss: 3.1272547407822597
Validation loss: 2.516316602053375

Epoch: 5| Step: 10
Training loss: 2.7367029362209934
Validation loss: 2.516016989793544

Epoch: 105| Step: 0
Training loss: 3.028602151509251
Validation loss: 2.513227419443583

Epoch: 5| Step: 1
Training loss: 2.7914757639580863
Validation loss: 2.5188023755471236

Epoch: 5| Step: 2
Training loss: 2.9522532634692844
Validation loss: 2.5316014240237914

Epoch: 5| Step: 3
Training loss: 2.941627686614211
Validation loss: 2.523407036082379

Epoch: 5| Step: 4
Training loss: 3.595186692697151
Validation loss: 2.5264026995734508

Epoch: 5| Step: 5
Training loss: 3.1154930461768595
Validation loss: 2.5266333033161805

Epoch: 5| Step: 6
Training loss: 2.609462256885714
Validation loss: 2.5178554580122134

Epoch: 5| Step: 7
Training loss: 3.030332131390565
Validation loss: 2.5198509365169994

Epoch: 5| Step: 8
Training loss: 2.414834599645748
Validation loss: 2.522097190840725

Epoch: 5| Step: 9
Training loss: 2.412039492440379
Validation loss: 2.5094803868404516

Epoch: 5| Step: 10
Training loss: 2.6458355660817094
Validation loss: 2.5129371040410335

Epoch: 106| Step: 0
Training loss: 2.8070665220852216
Validation loss: 2.509322954033314

Epoch: 5| Step: 1
Training loss: 3.2473989495346833
Validation loss: 2.5145077500461595

Epoch: 5| Step: 2
Training loss: 3.234500458721294
Validation loss: 2.5163586376736293

Epoch: 5| Step: 3
Training loss: 2.8694136705827633
Validation loss: 2.5273820398343974

Epoch: 5| Step: 4
Training loss: 2.929817868193122
Validation loss: 2.5215108573362137

Epoch: 5| Step: 5
Training loss: 2.6785887308924297
Validation loss: 2.521514989234744

Epoch: 5| Step: 6
Training loss: 2.7739406935135387
Validation loss: 2.5212145030469326

Epoch: 5| Step: 7
Training loss: 3.166144846703577
Validation loss: 2.5247632984130117

Epoch: 5| Step: 8
Training loss: 2.7415132481590425
Validation loss: 2.526364979394825

Epoch: 5| Step: 9
Training loss: 2.5829136620364737
Validation loss: 2.5311100550282166

Epoch: 5| Step: 10
Training loss: 2.357554560785408
Validation loss: 2.536333857830005

Epoch: 107| Step: 0
Training loss: 2.684709652878234
Validation loss: 2.554799527792751

Epoch: 5| Step: 1
Training loss: 2.6311154655078277
Validation loss: 2.5709164760085677

Epoch: 5| Step: 2
Training loss: 3.055598676743304
Validation loss: 2.5958611477980194

Epoch: 5| Step: 3
Training loss: 3.3140307074662565
Validation loss: 2.6011499651033354

Epoch: 5| Step: 4
Training loss: 2.6190312054767944
Validation loss: 2.5898480243084903

Epoch: 5| Step: 5
Training loss: 2.9222506521346467
Validation loss: 2.5636295887265357

Epoch: 5| Step: 6
Training loss: 2.855080469871369
Validation loss: 2.556529317659398

Epoch: 5| Step: 7
Training loss: 2.779335563213466
Validation loss: 2.549046193708861

Epoch: 5| Step: 8
Training loss: 3.18713466570199
Validation loss: 2.571982792944955

Epoch: 5| Step: 9
Training loss: 3.0565414071357115
Validation loss: 2.5730699428182144

Epoch: 5| Step: 10
Training loss: 2.5489268082847967
Validation loss: 2.565897340491502

Epoch: 108| Step: 0
Training loss: 2.508263568182563
Validation loss: 2.5553813603062983

Epoch: 5| Step: 1
Training loss: 3.07217700051966
Validation loss: 2.556712153309906

Epoch: 5| Step: 2
Training loss: 2.3986213936653122
Validation loss: 2.550751948856138

Epoch: 5| Step: 3
Training loss: 2.4215645868044042
Validation loss: 2.535691758052844

Epoch: 5| Step: 4
Training loss: 3.1072598264629225
Validation loss: 2.540129107901076

Epoch: 5| Step: 5
Training loss: 2.9445020941922655
Validation loss: 2.5298999025231486

Epoch: 5| Step: 6
Training loss: 3.141595643013929
Validation loss: 2.5236668280767427

Epoch: 5| Step: 7
Training loss: 3.1344479979270647
Validation loss: 2.5314194523666798

Epoch: 5| Step: 8
Training loss: 3.026887251368164
Validation loss: 2.5376727403997066

Epoch: 5| Step: 9
Training loss: 2.9528695455194844
Validation loss: 2.5589033798515666

Epoch: 5| Step: 10
Training loss: 2.728085679932135
Validation loss: 2.547035015471475

Epoch: 109| Step: 0
Training loss: 2.7516656512931124
Validation loss: 2.530285891566297

Epoch: 5| Step: 1
Training loss: 2.3755554754274835
Validation loss: 2.5304340904531313

Epoch: 5| Step: 2
Training loss: 3.0680709305065195
Validation loss: 2.527444124166197

Epoch: 5| Step: 3
Training loss: 2.8054029991881744
Validation loss: 2.5343847387153104

Epoch: 5| Step: 4
Training loss: 2.809525591216242
Validation loss: 2.530929648463284

Epoch: 5| Step: 5
Training loss: 3.5690576530966727
Validation loss: 2.537182061203161

Epoch: 5| Step: 6
Training loss: 2.8284970876494304
Validation loss: 2.5322533050556655

Epoch: 5| Step: 7
Training loss: 2.9326843396303475
Validation loss: 2.5337866870789956

Epoch: 5| Step: 8
Training loss: 2.2936459634662665
Validation loss: 2.52761703266186

Epoch: 5| Step: 9
Training loss: 2.853395473867169
Validation loss: 2.520606704432787

Epoch: 5| Step: 10
Training loss: 3.0657305124772916
Validation loss: 2.5216814673921557

Epoch: 110| Step: 0
Training loss: 2.48397267280818
Validation loss: 2.523520996029031

Epoch: 5| Step: 1
Training loss: 3.154458169976323
Validation loss: 2.5199191528160942

Epoch: 5| Step: 2
Training loss: 2.74339776352426
Validation loss: 2.523744158695363

Epoch: 5| Step: 3
Training loss: 3.0778514140195634
Validation loss: 2.5365968617417414

Epoch: 5| Step: 4
Training loss: 2.8359881099672277
Validation loss: 2.5792326366608704

Epoch: 5| Step: 5
Training loss: 2.4638419314438313
Validation loss: 2.5748509146150074

Epoch: 5| Step: 6
Training loss: 2.748243030740179
Validation loss: 2.573850122531026

Epoch: 5| Step: 7
Training loss: 2.811572536557863
Validation loss: 2.5475623197811568

Epoch: 5| Step: 8
Training loss: 3.0876775157723726
Validation loss: 2.520825869017733

Epoch: 5| Step: 9
Training loss: 3.1666770399492585
Validation loss: 2.517425299535573

Epoch: 5| Step: 10
Training loss: 2.8887347665250553
Validation loss: 2.5018437037192114

Epoch: 111| Step: 0
Training loss: 2.885722854472041
Validation loss: 2.505297159209741

Epoch: 5| Step: 1
Training loss: 2.433565828460158
Validation loss: 2.5127705821732396

Epoch: 5| Step: 2
Training loss: 3.189331127106447
Validation loss: 2.509702471039103

Epoch: 5| Step: 3
Training loss: 3.1614819965178738
Validation loss: 2.5039598698135133

Epoch: 5| Step: 4
Training loss: 3.360895424920415
Validation loss: 2.502513495654694

Epoch: 5| Step: 5
Training loss: 3.027745374064817
Validation loss: 2.5043569376815817

Epoch: 5| Step: 6
Training loss: 2.841945201240775
Validation loss: 2.517436616524542

Epoch: 5| Step: 7
Training loss: 2.4672771841011367
Validation loss: 2.530232044411939

Epoch: 5| Step: 8
Training loss: 2.5499657909118225
Validation loss: 2.5597278708155544

Epoch: 5| Step: 9
Training loss: 2.994923110509886
Validation loss: 2.625707695995519

Epoch: 5| Step: 10
Training loss: 2.4236433894774847
Validation loss: 2.6994406815457914

Epoch: 112| Step: 0
Training loss: 3.2763165397538363
Validation loss: 2.8488294107309065

Epoch: 5| Step: 1
Training loss: 2.7846454938516363
Validation loss: 2.7078857702048342

Epoch: 5| Step: 2
Training loss: 3.163111414251753
Validation loss: 2.5732971889142915

Epoch: 5| Step: 3
Training loss: 2.519371039449673
Validation loss: 2.5084818060379797

Epoch: 5| Step: 4
Training loss: 2.451343059261484
Validation loss: 2.5015006073731194

Epoch: 5| Step: 5
Training loss: 2.409321892495674
Validation loss: 2.5063689341871656

Epoch: 5| Step: 6
Training loss: 2.896540018114386
Validation loss: 2.533592258559289

Epoch: 5| Step: 7
Training loss: 2.978483606385279
Validation loss: 2.5965033944246305

Epoch: 5| Step: 8
Training loss: 3.2744960484535466
Validation loss: 2.663390027610092

Epoch: 5| Step: 9
Training loss: 3.554001425464282
Validation loss: 2.5962677858141494

Epoch: 5| Step: 10
Training loss: 2.9593611172085605
Validation loss: 2.5246177195922894

Epoch: 113| Step: 0
Training loss: 2.637798986618376
Validation loss: 2.51305323779708

Epoch: 5| Step: 1
Training loss: 3.2481019272901395
Validation loss: 2.5195563161597865

Epoch: 5| Step: 2
Training loss: 3.2192213583683253
Validation loss: 2.516532811089842

Epoch: 5| Step: 3
Training loss: 3.655353925401245
Validation loss: 2.524391604773262

Epoch: 5| Step: 4
Training loss: 2.727268947251908
Validation loss: 2.509175997140842

Epoch: 5| Step: 5
Training loss: 2.848463909384566
Validation loss: 2.5044572146050283

Epoch: 5| Step: 6
Training loss: 2.7268446636938766
Validation loss: 2.511882328772219

Epoch: 5| Step: 7
Training loss: 2.641815639430901
Validation loss: 2.538531117457725

Epoch: 5| Step: 8
Training loss: 2.5185815721713585
Validation loss: 2.5671994955357955

Epoch: 5| Step: 9
Training loss: 2.5078950196947183
Validation loss: 2.5959641768316315

Epoch: 5| Step: 10
Training loss: 2.576904655395078
Validation loss: 2.661044573600883

Epoch: 114| Step: 0
Training loss: 3.1713330035987006
Validation loss: 2.692641032095832

Epoch: 5| Step: 1
Training loss: 2.8471150034330255
Validation loss: 2.6989766785195224

Epoch: 5| Step: 2
Training loss: 2.7184857645649596
Validation loss: 2.65154672744247

Epoch: 5| Step: 3
Training loss: 3.127443807632275
Validation loss: 2.610379044613636

Epoch: 5| Step: 4
Training loss: 2.995866152637097
Validation loss: 2.537815143892897

Epoch: 5| Step: 5
Training loss: 2.5067076343712458
Validation loss: 2.500849137637327

Epoch: 5| Step: 6
Training loss: 3.2164923889174473
Validation loss: 2.500230472975048

Epoch: 5| Step: 7
Training loss: 2.608524023851
Validation loss: 2.4959742054491203

Epoch: 5| Step: 8
Training loss: 2.7586649584917793
Validation loss: 2.499972983183545

Epoch: 5| Step: 9
Training loss: 2.8504291947421323
Validation loss: 2.4960986644822243

Epoch: 5| Step: 10
Training loss: 2.816886786788951
Validation loss: 2.4957620314067652

Epoch: 115| Step: 0
Training loss: 2.111854170092264
Validation loss: 2.493564836785594

Epoch: 5| Step: 1
Training loss: 3.3184198707423382
Validation loss: 2.4938413913455437

Epoch: 5| Step: 2
Training loss: 2.655715978459641
Validation loss: 2.501059931977227

Epoch: 5| Step: 3
Training loss: 3.1297124807395913
Validation loss: 2.496830810129553

Epoch: 5| Step: 4
Training loss: 3.0384611893071436
Validation loss: 2.5014230646439155

Epoch: 5| Step: 5
Training loss: 3.2798490894305603
Validation loss: 2.4981441295267084

Epoch: 5| Step: 6
Training loss: 2.841201814309182
Validation loss: 2.5012796562215898

Epoch: 5| Step: 7
Training loss: 2.4239258973154003
Validation loss: 2.5065058942140594

Epoch: 5| Step: 8
Training loss: 2.933462899409903
Validation loss: 2.5120791682824666

Epoch: 5| Step: 9
Training loss: 2.7968945209525202
Validation loss: 2.514371773409996

Epoch: 5| Step: 10
Training loss: 2.6405865367367922
Validation loss: 2.5629814540036207

Epoch: 116| Step: 0
Training loss: 2.627256785713687
Validation loss: 2.600613452821774

Epoch: 5| Step: 1
Training loss: 2.9274656288220653
Validation loss: 2.645995890770587

Epoch: 5| Step: 2
Training loss: 3.1056969132967147
Validation loss: 2.665520646413342

Epoch: 5| Step: 3
Training loss: 3.1087314572335383
Validation loss: 2.6619415602272363

Epoch: 5| Step: 4
Training loss: 2.8075887396656607
Validation loss: 2.6543433288634795

Epoch: 5| Step: 5
Training loss: 2.8902919268095006
Validation loss: 2.6422111056816378

Epoch: 5| Step: 6
Training loss: 3.3380611905111444
Validation loss: 2.672027049127658

Epoch: 5| Step: 7
Training loss: 3.226454171863026
Validation loss: 2.5309691704426416

Epoch: 5| Step: 8
Training loss: 2.755793191505735
Validation loss: 2.4992210261566727

Epoch: 5| Step: 9
Training loss: 2.1134637834899217
Validation loss: 2.5029904722557688

Epoch: 5| Step: 10
Training loss: 2.5984889481268914
Validation loss: 2.508442731008912

Epoch: 117| Step: 0
Training loss: 3.296387550513245
Validation loss: 2.5094583798189922

Epoch: 5| Step: 1
Training loss: 3.109614684101801
Validation loss: 2.5149495012712273

Epoch: 5| Step: 2
Training loss: 2.9018122108004314
Validation loss: 2.517023709526446

Epoch: 5| Step: 3
Training loss: 2.5233245918831364
Validation loss: 2.5153286458134434

Epoch: 5| Step: 4
Training loss: 2.7065061029562365
Validation loss: 2.5131423185477852

Epoch: 5| Step: 5
Training loss: 2.644074213155075
Validation loss: 2.512418172115304

Epoch: 5| Step: 6
Training loss: 3.0295924737909843
Validation loss: 2.5103217261740913

Epoch: 5| Step: 7
Training loss: 2.8097352744194417
Validation loss: 2.503010628018045

Epoch: 5| Step: 8
Training loss: 2.96622255051391
Validation loss: 2.509467432122422

Epoch: 5| Step: 9
Training loss: 2.9165686091333813
Validation loss: 2.510835958669871

Epoch: 5| Step: 10
Training loss: 2.9171538536448436
Validation loss: 2.542175630001639

Epoch: 118| Step: 0
Training loss: 3.0446185241672947
Validation loss: 2.5888485013064355

Epoch: 5| Step: 1
Training loss: 2.9774338455602165
Validation loss: 2.62714789646279

Epoch: 5| Step: 2
Training loss: 2.109477853033533
Validation loss: 2.6050743339145312

Epoch: 5| Step: 3
Training loss: 2.890486100442378
Validation loss: 2.6207238285293606

Epoch: 5| Step: 4
Training loss: 2.9620135523597444
Validation loss: 2.549974695394206

Epoch: 5| Step: 5
Training loss: 2.162649195821979
Validation loss: 2.512308827029187

Epoch: 5| Step: 6
Training loss: 2.658482948166747
Validation loss: 2.502133263241093

Epoch: 5| Step: 7
Training loss: 3.049432395274506
Validation loss: 2.4974813089424037

Epoch: 5| Step: 8
Training loss: 3.0280875787302537
Validation loss: 2.4991810575058717

Epoch: 5| Step: 9
Training loss: 3.595491070480197
Validation loss: 2.5100874458791163

Epoch: 5| Step: 10
Training loss: 2.807312738248671
Validation loss: 2.5151949686730517

Epoch: 119| Step: 0
Training loss: 2.8140426643515504
Validation loss: 2.511760989128878

Epoch: 5| Step: 1
Training loss: 3.054632083946269
Validation loss: 2.516744593928431

Epoch: 5| Step: 2
Training loss: 2.678829934498016
Validation loss: 2.5117612657262844

Epoch: 5| Step: 3
Training loss: 2.6318843122293547
Validation loss: 2.5445747690618474

Epoch: 5| Step: 4
Training loss: 2.663951345681028
Validation loss: 2.598465813498241

Epoch: 5| Step: 5
Training loss: 3.0268782719262237
Validation loss: 2.6543680810027968

Epoch: 5| Step: 6
Training loss: 2.743369953363798
Validation loss: 2.6148094200753023

Epoch: 5| Step: 7
Training loss: 2.7454498100354754
Validation loss: 2.554127320453596

Epoch: 5| Step: 8
Training loss: 2.8447642770736308
Validation loss: 2.5094608898673525

Epoch: 5| Step: 9
Training loss: 3.0734670027697155
Validation loss: 2.4966967550794026

Epoch: 5| Step: 10
Training loss: 2.9743033418882936
Validation loss: 2.484137582247027

Epoch: 120| Step: 0
Training loss: 3.092967232985388
Validation loss: 2.4920094142542357

Epoch: 5| Step: 1
Training loss: 2.5212349269645222
Validation loss: 2.4871633335948578

Epoch: 5| Step: 2
Training loss: 2.9331273750768636
Validation loss: 2.4963829033139517

Epoch: 5| Step: 3
Training loss: 2.6905821049158596
Validation loss: 2.500700157319164

Epoch: 5| Step: 4
Training loss: 3.4305343798877455
Validation loss: 2.4936218413420663

Epoch: 5| Step: 5
Training loss: 2.5349249829811615
Validation loss: 2.4951992455120493

Epoch: 5| Step: 6
Training loss: 2.947917888807351
Validation loss: 2.5040955375263882

Epoch: 5| Step: 7
Training loss: 2.9922608050338453
Validation loss: 2.502813860932419

Epoch: 5| Step: 8
Training loss: 2.574098899725659
Validation loss: 2.552659934232719

Epoch: 5| Step: 9
Training loss: 2.6993838313586016
Validation loss: 2.522908781591807

Epoch: 5| Step: 10
Training loss: 3.004676987842376
Validation loss: 2.541705356332345

Epoch: 121| Step: 0
Training loss: 2.754833655069222
Validation loss: 2.5393487402627377

Epoch: 5| Step: 1
Training loss: 2.8952423334240067
Validation loss: 2.5504677804519162

Epoch: 5| Step: 2
Training loss: 2.964741781740437
Validation loss: 2.5203967911810086

Epoch: 5| Step: 3
Training loss: 2.902517731946721
Validation loss: 2.501803034048263

Epoch: 5| Step: 4
Training loss: 3.1535708699135623
Validation loss: 2.489660409036409

Epoch: 5| Step: 5
Training loss: 2.7276367869286133
Validation loss: 2.4900043275929535

Epoch: 5| Step: 6
Training loss: 2.3342489308091987
Validation loss: 2.489466495855527

Epoch: 5| Step: 7
Training loss: 2.425311597487974
Validation loss: 2.4884431283779156

Epoch: 5| Step: 8
Training loss: 2.7343831089444492
Validation loss: 2.497469683911352

Epoch: 5| Step: 9
Training loss: 3.15129773489279
Validation loss: 2.4909566567794923

Epoch: 5| Step: 10
Training loss: 3.2966755449608134
Validation loss: 2.5051741073351534

Epoch: 122| Step: 0
Training loss: 3.025134337413698
Validation loss: 2.5283142448969773

Epoch: 5| Step: 1
Training loss: 2.9666872588168065
Validation loss: 2.574652071404506

Epoch: 5| Step: 2
Training loss: 3.1253909057266154
Validation loss: 2.6243171917195327

Epoch: 5| Step: 3
Training loss: 2.8971283210353183
Validation loss: 2.590102664545412

Epoch: 5| Step: 4
Training loss: 2.7059170630489784
Validation loss: 2.574666276351583

Epoch: 5| Step: 5
Training loss: 2.845362447167234
Validation loss: 2.5545415641870575

Epoch: 5| Step: 6
Training loss: 2.594543335704688
Validation loss: 2.5502159249616803

Epoch: 5| Step: 7
Training loss: 3.041196569058842
Validation loss: 2.504101344394619

Epoch: 5| Step: 8
Training loss: 2.363310909873281
Validation loss: 2.4926392944901368

Epoch: 5| Step: 9
Training loss: 2.7391989744126546
Validation loss: 2.487838201091399

Epoch: 5| Step: 10
Training loss: 2.9987186238474868
Validation loss: 2.4842910953654638

Epoch: 123| Step: 0
Training loss: 2.8488552672289558
Validation loss: 2.4797859924619634

Epoch: 5| Step: 1
Training loss: 2.737723082767408
Validation loss: 2.4825105435779573

Epoch: 5| Step: 2
Training loss: 2.755533113909504
Validation loss: 2.4756869666086287

Epoch: 5| Step: 3
Training loss: 3.025426087439434
Validation loss: 2.478460805651907

Epoch: 5| Step: 4
Training loss: 3.179504539230953
Validation loss: 2.505352932392247

Epoch: 5| Step: 5
Training loss: 2.57171833585535
Validation loss: 2.5262061348542533

Epoch: 5| Step: 6
Training loss: 3.043380846514072
Validation loss: 2.5911981943526614

Epoch: 5| Step: 7
Training loss: 2.8182900909980546
Validation loss: 2.6486745753590406

Epoch: 5| Step: 8
Training loss: 2.752642402395394
Validation loss: 2.6626186031115466

Epoch: 5| Step: 9
Training loss: 2.5884963913660832
Validation loss: 2.603033281025297

Epoch: 5| Step: 10
Training loss: 2.9743015783794338
Validation loss: 2.561688973864791

Epoch: 124| Step: 0
Training loss: 2.8847805015061576
Validation loss: 2.538688752564687

Epoch: 5| Step: 1
Training loss: 3.1848597343854816
Validation loss: 2.5039521726135088

Epoch: 5| Step: 2
Training loss: 3.3290674728747445
Validation loss: 2.499069038478404

Epoch: 5| Step: 3
Training loss: 3.0946350373023184
Validation loss: 2.496435530459677

Epoch: 5| Step: 4
Training loss: 2.5200222276282562
Validation loss: 2.5038520177827404

Epoch: 5| Step: 5
Training loss: 2.9043295473006725
Validation loss: 2.5012276465502254

Epoch: 5| Step: 6
Training loss: 2.5227104533241693
Validation loss: 2.4913919733545407

Epoch: 5| Step: 7
Training loss: 2.7094169111871116
Validation loss: 2.485584794381835

Epoch: 5| Step: 8
Training loss: 2.6696587009388093
Validation loss: 2.4920552248483614

Epoch: 5| Step: 9
Training loss: 2.565034868624265
Validation loss: 2.524605161404827

Epoch: 5| Step: 10
Training loss: 2.5696151390311424
Validation loss: 2.5562869970305657

Epoch: 125| Step: 0
Training loss: 3.1524050114574758
Validation loss: 2.6424852587774508

Epoch: 5| Step: 1
Training loss: 3.2892790879362854
Validation loss: 2.7302254660815324

Epoch: 5| Step: 2
Training loss: 2.652091057809357
Validation loss: 2.574265744161589

Epoch: 5| Step: 3
Training loss: 3.082339891419795
Validation loss: 2.5052993188582318

Epoch: 5| Step: 4
Training loss: 3.1048505059710543
Validation loss: 2.4780319211076893

Epoch: 5| Step: 5
Training loss: 2.4329271704783535
Validation loss: 2.489966618175393

Epoch: 5| Step: 6
Training loss: 3.063378655641806
Validation loss: 2.4970116895617998

Epoch: 5| Step: 7
Training loss: 2.7855851751317564
Validation loss: 2.5018991445285375

Epoch: 5| Step: 8
Training loss: 2.8601465070319407
Validation loss: 2.4973038922486053

Epoch: 5| Step: 9
Training loss: 2.870765220893414
Validation loss: 2.4975259680617774

Epoch: 5| Step: 10
Training loss: 1.9278573071396894
Validation loss: 2.521977572653759

Epoch: 126| Step: 0
Training loss: 3.275611610669097
Validation loss: 2.5606491323631513

Epoch: 5| Step: 1
Training loss: 2.9261280460357293
Validation loss: 2.541369887006861

Epoch: 5| Step: 2
Training loss: 2.3090254997936923
Validation loss: 2.5363827026381998

Epoch: 5| Step: 3
Training loss: 2.3816674655016907
Validation loss: 2.5303857508601495

Epoch: 5| Step: 4
Training loss: 2.255437743842937
Validation loss: 2.5390724362414785

Epoch: 5| Step: 5
Training loss: 2.8541455418902504
Validation loss: 2.5291684037180104

Epoch: 5| Step: 6
Training loss: 2.9094868344489107
Validation loss: 2.538502196024287

Epoch: 5| Step: 7
Training loss: 2.8223134389872757
Validation loss: 2.5295133792527977

Epoch: 5| Step: 8
Training loss: 3.447017464067017
Validation loss: 2.531159180926484

Epoch: 5| Step: 9
Training loss: 3.1961688174372305
Validation loss: 2.504992440801588

Epoch: 5| Step: 10
Training loss: 2.6733211596807127
Validation loss: 2.499649856001877

Epoch: 127| Step: 0
Training loss: 2.850568038816281
Validation loss: 2.4880580749536088

Epoch: 5| Step: 1
Training loss: 2.4547337402029017
Validation loss: 2.4877347470462055

Epoch: 5| Step: 2
Training loss: 2.99847834461376
Validation loss: 2.494698035744112

Epoch: 5| Step: 3
Training loss: 3.4142651530511445
Validation loss: 2.4989114752693387

Epoch: 5| Step: 4
Training loss: 2.6441504064765895
Validation loss: 2.515242399545654

Epoch: 5| Step: 5
Training loss: 2.6612781281998252
Validation loss: 2.5708129477406088

Epoch: 5| Step: 6
Training loss: 3.1921160316029096
Validation loss: 2.596354451367043

Epoch: 5| Step: 7
Training loss: 2.3181427852044005
Validation loss: 2.59999241027166

Epoch: 5| Step: 8
Training loss: 2.6923665186984294
Validation loss: 2.6013793762611375

Epoch: 5| Step: 9
Training loss: 2.272405436009756
Validation loss: 2.5949766103020093

Epoch: 5| Step: 10
Training loss: 3.2698324012386233
Validation loss: 2.6251621313463227

Epoch: 128| Step: 0
Training loss: 2.9645817456181973
Validation loss: 2.547662188177861

Epoch: 5| Step: 1
Training loss: 3.078363244765574
Validation loss: 2.5146436377707615

Epoch: 5| Step: 2
Training loss: 2.7864758547413246
Validation loss: 2.5007659292560502

Epoch: 5| Step: 3
Training loss: 2.709947916635385
Validation loss: 2.4981648708470314

Epoch: 5| Step: 4
Training loss: 3.027077073687815
Validation loss: 2.509279991393242

Epoch: 5| Step: 5
Training loss: 3.0192289805652304
Validation loss: 2.5004991279224207

Epoch: 5| Step: 6
Training loss: 3.146495740930356
Validation loss: 2.5014155902349073

Epoch: 5| Step: 7
Training loss: 2.3917740198514017
Validation loss: 2.5013499101984906

Epoch: 5| Step: 8
Training loss: 3.200058823283276
Validation loss: 2.4924786410778004

Epoch: 5| Step: 9
Training loss: 2.01348846517877
Validation loss: 2.502967824355657

Epoch: 5| Step: 10
Training loss: 2.5308768856892976
Validation loss: 2.509591322091955

Epoch: 129| Step: 0
Training loss: 2.5965463662182864
Validation loss: 2.5293466624937118

Epoch: 5| Step: 1
Training loss: 3.071749363112211
Validation loss: 2.579666733740319

Epoch: 5| Step: 2
Training loss: 3.111659605252863
Validation loss: 2.5669380611302244

Epoch: 5| Step: 3
Training loss: 2.770262714418431
Validation loss: 2.583277813542751

Epoch: 5| Step: 4
Training loss: 2.6555114616961197
Validation loss: 2.5835249664675217

Epoch: 5| Step: 5
Training loss: 2.407840945937887
Validation loss: 2.580366373609548

Epoch: 5| Step: 6
Training loss: 3.1320547200534636
Validation loss: 2.570850327889432

Epoch: 5| Step: 7
Training loss: 2.6167241383779127
Validation loss: 2.5574458782736564

Epoch: 5| Step: 8
Training loss: 2.6244952306894875
Validation loss: 2.5576368075235014

Epoch: 5| Step: 9
Training loss: 3.2116107466903325
Validation loss: 2.5490347284129227

Epoch: 5| Step: 10
Training loss: 2.4750474212419125
Validation loss: 2.525315190391331

Epoch: 130| Step: 0
Training loss: 2.6799328750061213
Validation loss: 2.5092660149929666

Epoch: 5| Step: 1
Training loss: 2.841187548775493
Validation loss: 2.5182266290482236

Epoch: 5| Step: 2
Training loss: 2.683842232429201
Validation loss: 2.5255200345490985

Epoch: 5| Step: 3
Training loss: 3.0927057526833464
Validation loss: 2.5369738165136475

Epoch: 5| Step: 4
Training loss: 2.8088679279311193
Validation loss: 2.5519556860343493

Epoch: 5| Step: 5
Training loss: 2.780895424861149
Validation loss: 2.5589688730374

Epoch: 5| Step: 6
Training loss: 2.866369978019431
Validation loss: 2.595364216203316

Epoch: 5| Step: 7
Training loss: 2.9964233376307727
Validation loss: 2.5739525406136594

Epoch: 5| Step: 8
Training loss: 2.6787311415513577
Validation loss: 2.5553108080374027

Epoch: 5| Step: 9
Training loss: 2.9926770160938267
Validation loss: 2.51625927110021

Epoch: 5| Step: 10
Training loss: 2.2728867535556025
Validation loss: 2.4904155966222397

Epoch: 131| Step: 0
Training loss: 3.082191840219715
Validation loss: 2.4879127410250925

Epoch: 5| Step: 1
Training loss: 2.443004262170185
Validation loss: 2.486434300777356

Epoch: 5| Step: 2
Training loss: 3.1875421857847193
Validation loss: 2.4914080601634057

Epoch: 5| Step: 3
Training loss: 2.8440209563565655
Validation loss: 2.5016826135561434

Epoch: 5| Step: 4
Training loss: 2.8000999909666837
Validation loss: 2.5063753530770536

Epoch: 5| Step: 5
Training loss: 2.8552533236752216
Validation loss: 2.5131534518257195

Epoch: 5| Step: 6
Training loss: 2.670912987706026
Validation loss: 2.5269944649100355

Epoch: 5| Step: 7
Training loss: 2.2660265336532808
Validation loss: 2.5424835456446946

Epoch: 5| Step: 8
Training loss: 2.5770470417482296
Validation loss: 2.551369265085614

Epoch: 5| Step: 9
Training loss: 2.5721763647489824
Validation loss: 2.571233793794223

Epoch: 5| Step: 10
Training loss: 3.4121096544969833
Validation loss: 2.611838555428376

Epoch: 132| Step: 0
Training loss: 2.8961511524440042
Validation loss: 2.5995520585286265

Epoch: 5| Step: 1
Training loss: 2.74979070387186
Validation loss: 2.592579891618413

Epoch: 5| Step: 2
Training loss: 2.3342478072765
Validation loss: 2.5266159888149176

Epoch: 5| Step: 3
Training loss: 2.73409125899488
Validation loss: 2.505062298989775

Epoch: 5| Step: 4
Training loss: 2.3341786579049693
Validation loss: 2.496975853944685

Epoch: 5| Step: 5
Training loss: 3.2056688581423947
Validation loss: 2.4897995175854

Epoch: 5| Step: 6
Training loss: 2.6537192462104047
Validation loss: 2.4826099319388963

Epoch: 5| Step: 7
Training loss: 2.7599838397340775
Validation loss: 2.485716624869828

Epoch: 5| Step: 8
Training loss: 3.2798662446825193
Validation loss: 2.485082689491935

Epoch: 5| Step: 9
Training loss: 3.278455870652065
Validation loss: 2.494980101673217

Epoch: 5| Step: 10
Training loss: 2.45843533665305
Validation loss: 2.5110867817365885

Epoch: 133| Step: 0
Training loss: 3.4658669527451367
Validation loss: 2.5175094929265733

Epoch: 5| Step: 1
Training loss: 2.623163943543566
Validation loss: 2.5335484466666682

Epoch: 5| Step: 2
Training loss: 2.9908820509182377
Validation loss: 2.525067492435571

Epoch: 5| Step: 3
Training loss: 2.729802084375503
Validation loss: 2.510777894023749

Epoch: 5| Step: 4
Training loss: 2.204999951040393
Validation loss: 2.512536859790393

Epoch: 5| Step: 5
Training loss: 3.1868575701598827
Validation loss: 2.5205509031304767

Epoch: 5| Step: 6
Training loss: 2.6050044022008563
Validation loss: 2.513797247613105

Epoch: 5| Step: 7
Training loss: 2.317798009844887
Validation loss: 2.512706294717923

Epoch: 5| Step: 8
Training loss: 2.525903211646664
Validation loss: 2.525938499347481

Epoch: 5| Step: 9
Training loss: 2.9622711157605144
Validation loss: 2.5389218517186234

Epoch: 5| Step: 10
Training loss: 2.7792343379241045
Validation loss: 2.541046500299213

Epoch: 134| Step: 0
Training loss: 2.6744211123120127
Validation loss: 2.570076251949084

Epoch: 5| Step: 1
Training loss: 2.9784146051004194
Validation loss: 2.6031218840292802

Epoch: 5| Step: 2
Training loss: 2.7611663568070974
Validation loss: 2.674520846635402

Epoch: 5| Step: 3
Training loss: 2.2127865449514252
Validation loss: 2.679851215936198

Epoch: 5| Step: 4
Training loss: 2.579934242504679
Validation loss: 2.6699127569904912

Epoch: 5| Step: 5
Training loss: 3.2660139664434853
Validation loss: 2.6074244264260877

Epoch: 5| Step: 6
Training loss: 3.1235738933451693
Validation loss: 2.5101424850290153

Epoch: 5| Step: 7
Training loss: 3.0876080204527043
Validation loss: 2.4897432369024517

Epoch: 5| Step: 8
Training loss: 2.817575156589617
Validation loss: 2.498637309981478

Epoch: 5| Step: 9
Training loss: 2.621557976308083
Validation loss: 2.5018792400821304

Epoch: 5| Step: 10
Training loss: 2.6739303090066344
Validation loss: 2.5143896131986643

Epoch: 135| Step: 0
Training loss: 2.2502022758265556
Validation loss: 2.5742889304602175

Epoch: 5| Step: 1
Training loss: 3.160298234652198
Validation loss: 2.678133631183179

Epoch: 5| Step: 2
Training loss: 2.7812468282274314
Validation loss: 2.7428802577179536

Epoch: 5| Step: 3
Training loss: 3.2927807882113664
Validation loss: 2.676377755815874

Epoch: 5| Step: 4
Training loss: 3.230029887010937
Validation loss: 2.5254716323655897

Epoch: 5| Step: 5
Training loss: 2.6964013595435024
Validation loss: 2.5001521402641913

Epoch: 5| Step: 6
Training loss: 3.0500218500073832
Validation loss: 2.5136626246823353

Epoch: 5| Step: 7
Training loss: 2.87416827568908
Validation loss: 2.5327050996865843

Epoch: 5| Step: 8
Training loss: 3.0210781305154475
Validation loss: 2.5230194226002083

Epoch: 5| Step: 9
Training loss: 2.29382776029823
Validation loss: 2.5109633719021116

Epoch: 5| Step: 10
Training loss: 3.4175143392132283
Validation loss: 2.492669244804489

Epoch: 136| Step: 0
Training loss: 3.353823310542737
Validation loss: 2.49158544086656

Epoch: 5| Step: 1
Training loss: 3.0932360906224248
Validation loss: 2.497813952831205

Epoch: 5| Step: 2
Training loss: 2.4275004365490442
Validation loss: 2.5214455106233324

Epoch: 5| Step: 3
Training loss: 2.7726054058212397
Validation loss: 2.5851076164606193

Epoch: 5| Step: 4
Training loss: 2.9449263504223024
Validation loss: 2.661281479559482

Epoch: 5| Step: 5
Training loss: 3.12187572704532
Validation loss: 2.7181344151617424

Epoch: 5| Step: 6
Training loss: 3.1357707756210065
Validation loss: 2.6782909073555903

Epoch: 5| Step: 7
Training loss: 2.1641516271202526
Validation loss: 2.692980560793091

Epoch: 5| Step: 8
Training loss: 2.498027977413372
Validation loss: 2.760076147442076

Epoch: 5| Step: 9
Training loss: 2.731032415666266
Validation loss: 2.6611723245978434

Epoch: 5| Step: 10
Training loss: 2.522877067005237
Validation loss: 2.597875653460988

Epoch: 137| Step: 0
Training loss: 2.5284909882885573
Validation loss: 2.5499168664746827

Epoch: 5| Step: 1
Training loss: 3.160172847897543
Validation loss: 2.524010140216054

Epoch: 5| Step: 2
Training loss: 3.0199413341861905
Validation loss: 2.5184470675628354

Epoch: 5| Step: 3
Training loss: 2.495673154638142
Validation loss: 2.5205501911636223

Epoch: 5| Step: 4
Training loss: 2.8276597794264493
Validation loss: 2.5175345425569433

Epoch: 5| Step: 5
Training loss: 1.8298533168226998
Validation loss: 2.5232558184230314

Epoch: 5| Step: 6
Training loss: 3.157413683607771
Validation loss: 2.5144325894710686

Epoch: 5| Step: 7
Training loss: 2.8786223438497003
Validation loss: 2.5299375112250755

Epoch: 5| Step: 8
Training loss: 2.8838492496047365
Validation loss: 2.538998295656141

Epoch: 5| Step: 9
Training loss: 2.966892665298552
Validation loss: 2.5377654003055086

Epoch: 5| Step: 10
Training loss: 2.669126111581078
Validation loss: 2.547917474595265

Epoch: 138| Step: 0
Training loss: 2.559501847883699
Validation loss: 2.5578805998725582

Epoch: 5| Step: 1
Training loss: 2.6757088087536625
Validation loss: 2.5796846347730145

Epoch: 5| Step: 2
Training loss: 2.620035654364108
Validation loss: 2.607997596324022

Epoch: 5| Step: 3
Training loss: 2.878140103013695
Validation loss: 2.6386281124451254

Epoch: 5| Step: 4
Training loss: 3.147072621630367
Validation loss: 2.6582142698853555

Epoch: 5| Step: 5
Training loss: 2.745806444313322
Validation loss: 2.6334466509764924

Epoch: 5| Step: 6
Training loss: 3.0690904665403855
Validation loss: 2.578734573487438

Epoch: 5| Step: 7
Training loss: 2.5666167522712757
Validation loss: 2.54574546425346

Epoch: 5| Step: 8
Training loss: 2.5946107837831343
Validation loss: 2.5037451778611968

Epoch: 5| Step: 9
Training loss: 2.999833420261266
Validation loss: 2.488153831302795

Epoch: 5| Step: 10
Training loss: 2.5968145627403776
Validation loss: 2.4920791878638098

Epoch: 139| Step: 0
Training loss: 2.663915546201208
Validation loss: 2.4843900760960165

Epoch: 5| Step: 1
Training loss: 2.8995027049960305
Validation loss: 2.4778766400398986

Epoch: 5| Step: 2
Training loss: 2.707398052603362
Validation loss: 2.4746201802259566

Epoch: 5| Step: 3
Training loss: 3.0507329529127576
Validation loss: 2.483181974034086

Epoch: 5| Step: 4
Training loss: 3.15234344747133
Validation loss: 2.548077500058972

Epoch: 5| Step: 5
Training loss: 2.4345880378478784
Validation loss: 2.6091550651196966

Epoch: 5| Step: 6
Training loss: 2.8356230590356275
Validation loss: 2.685157344367169

Epoch: 5| Step: 7
Training loss: 2.791253177898971
Validation loss: 2.7024269281435447

Epoch: 5| Step: 8
Training loss: 2.647953495596883
Validation loss: 2.6739975033756997

Epoch: 5| Step: 9
Training loss: 2.919886600957505
Validation loss: 2.60339033077067

Epoch: 5| Step: 10
Training loss: 2.5953255889029707
Validation loss: 2.5298014985141135

Epoch: 140| Step: 0
Training loss: 2.9504112409600958
Validation loss: 2.506843214226089

Epoch: 5| Step: 1
Training loss: 2.781382782584601
Validation loss: 2.488557804529754

Epoch: 5| Step: 2
Training loss: 2.6941752370298238
Validation loss: 2.487769662610482

Epoch: 5| Step: 3
Training loss: 2.539634663597963
Validation loss: 2.486167946441176

Epoch: 5| Step: 4
Training loss: 2.838569029696572
Validation loss: 2.4971358433077637

Epoch: 5| Step: 5
Training loss: 2.7254068718330684
Validation loss: 2.499477216963088

Epoch: 5| Step: 6
Training loss: 2.7921357306413266
Validation loss: 2.5097164409228467

Epoch: 5| Step: 7
Training loss: 2.8643075891195573
Validation loss: 2.520671113816145

Epoch: 5| Step: 8
Training loss: 2.880978711776177
Validation loss: 2.5304964443578557

Epoch: 5| Step: 9
Training loss: 2.719208777293814
Validation loss: 2.5688085878043854

Epoch: 5| Step: 10
Training loss: 3.0156471370220514
Validation loss: 2.6400354635877763

Epoch: 141| Step: 0
Training loss: 2.586003420816447
Validation loss: 2.659214521120754

Epoch: 5| Step: 1
Training loss: 2.9732150581453776
Validation loss: 2.6512266623517022

Epoch: 5| Step: 2
Training loss: 3.1875463744137256
Validation loss: 2.6033347627601366

Epoch: 5| Step: 3
Training loss: 2.6708896894852168
Validation loss: 2.5472740315220763

Epoch: 5| Step: 4
Training loss: 2.657661511742708
Validation loss: 2.510672408727349

Epoch: 5| Step: 5
Training loss: 3.3750228881059843
Validation loss: 2.5097877896961607

Epoch: 5| Step: 6
Training loss: 3.027798132482893
Validation loss: 2.514436807429608

Epoch: 5| Step: 7
Training loss: 2.531346166220362
Validation loss: 2.5076968435015896

Epoch: 5| Step: 8
Training loss: 2.595757959617617
Validation loss: 2.5169371225777852

Epoch: 5| Step: 9
Training loss: 2.5567389134921727
Validation loss: 2.5299368464859384

Epoch: 5| Step: 10
Training loss: 2.8409154829473544
Validation loss: 2.5406586678795566

Epoch: 142| Step: 0
Training loss: 2.8343553569748123
Validation loss: 2.556344426118971

Epoch: 5| Step: 1
Training loss: 2.5777182518272284
Validation loss: 2.5644885495282264

Epoch: 5| Step: 2
Training loss: 2.3874117130912245
Validation loss: 2.5685026452876136

Epoch: 5| Step: 3
Training loss: 2.719461106883683
Validation loss: 2.555423583990529

Epoch: 5| Step: 4
Training loss: 3.193977506115269
Validation loss: 2.578942818943469

Epoch: 5| Step: 5
Training loss: 2.9510401880054333
Validation loss: 2.535944260405171

Epoch: 5| Step: 6
Training loss: 2.9677877372454935
Validation loss: 2.5335343967088035

Epoch: 5| Step: 7
Training loss: 3.2904383303015385
Validation loss: 2.5127647147396535

Epoch: 5| Step: 8
Training loss: 2.7942031800019147
Validation loss: 2.523761305483706

Epoch: 5| Step: 9
Training loss: 1.9959040661769885
Validation loss: 2.508368991253174

Epoch: 5| Step: 10
Training loss: 2.9046270289290255
Validation loss: 2.5396163258171045

Epoch: 143| Step: 0
Training loss: 2.9630637875815875
Validation loss: 2.5288611518147266

Epoch: 5| Step: 1
Training loss: 2.4632183827932446
Validation loss: 2.5357709117667535

Epoch: 5| Step: 2
Training loss: 2.6021555548226054
Validation loss: 2.5299537202674163

Epoch: 5| Step: 3
Training loss: 2.455346334854713
Validation loss: 2.5146277205062546

Epoch: 5| Step: 4
Training loss: 2.586772311435805
Validation loss: 2.5144606417701336

Epoch: 5| Step: 5
Training loss: 3.140668270894775
Validation loss: 2.5243331735320753

Epoch: 5| Step: 6
Training loss: 2.6390027361845148
Validation loss: 2.5294858364543353

Epoch: 5| Step: 7
Training loss: 2.860650950425175
Validation loss: 2.5402264790572002

Epoch: 5| Step: 8
Training loss: 2.5686932596961527
Validation loss: 2.5330799050771957

Epoch: 5| Step: 9
Training loss: 2.8947350228226343
Validation loss: 2.5319108524452596

Epoch: 5| Step: 10
Training loss: 2.980217719349397
Validation loss: 2.523832032722692

Epoch: 144| Step: 0
Training loss: 2.7822524418000505
Validation loss: 2.516481738096365

Epoch: 5| Step: 1
Training loss: 2.758011937697193
Validation loss: 2.5076407347314285

Epoch: 5| Step: 2
Training loss: 2.7473067186315023
Validation loss: 2.4999697037368533

Epoch: 5| Step: 3
Training loss: 2.754553319786464
Validation loss: 2.504548668244451

Epoch: 5| Step: 4
Training loss: 2.760519541616838
Validation loss: 2.4982864239497515

Epoch: 5| Step: 5
Training loss: 2.125782878500789
Validation loss: 2.5097931247610865

Epoch: 5| Step: 6
Training loss: 2.8304998216600334
Validation loss: 2.5261165095715232

Epoch: 5| Step: 7
Training loss: 3.03331332427192
Validation loss: 2.5499108603152685

Epoch: 5| Step: 8
Training loss: 3.0592863387605376
Validation loss: 2.5878271922384126

Epoch: 5| Step: 9
Training loss: 2.2856025455614226
Validation loss: 2.6100174455205427

Epoch: 5| Step: 10
Training loss: 2.8594893969389106
Validation loss: 2.6284584685917585

Epoch: 145| Step: 0
Training loss: 2.814631184458953
Validation loss: 2.6438759373411993

Epoch: 5| Step: 1
Training loss: 2.122341849609818
Validation loss: 2.6529283151376477

Epoch: 5| Step: 2
Training loss: 2.9706077786104346
Validation loss: 2.6652126777037735

Epoch: 5| Step: 3
Training loss: 1.8143145587353204
Validation loss: 2.708819367660674

Epoch: 5| Step: 4
Training loss: 2.963068615389599
Validation loss: 2.707800276164624

Epoch: 5| Step: 5
Training loss: 3.410363889055525
Validation loss: 2.684020705153781

Epoch: 5| Step: 6
Training loss: 2.8967866128978264
Validation loss: 2.628637610984258

Epoch: 5| Step: 7
Training loss: 2.8610976403010833
Validation loss: 2.574781558457207

Epoch: 5| Step: 8
Training loss: 2.952749077015588
Validation loss: 2.528208274458001

Epoch: 5| Step: 9
Training loss: 2.5778490323416774
Validation loss: 2.530952807862972

Epoch: 5| Step: 10
Training loss: 2.870556590375777
Validation loss: 2.5248011237511876

Epoch: 146| Step: 0
Training loss: 2.845295915550068
Validation loss: 2.540582619005187

Epoch: 5| Step: 1
Training loss: 2.521112085068273
Validation loss: 2.540661082524705

Epoch: 5| Step: 2
Training loss: 2.9311685709430257
Validation loss: 2.543906386150455

Epoch: 5| Step: 3
Training loss: 2.9043249502152597
Validation loss: 2.558473053550942

Epoch: 5| Step: 4
Training loss: 2.4962208794589134
Validation loss: 2.5496685059120496

Epoch: 5| Step: 5
Training loss: 3.087973702728881
Validation loss: 2.5785388980970754

Epoch: 5| Step: 6
Training loss: 3.1588732704953983
Validation loss: 2.6078036565977287

Epoch: 5| Step: 7
Training loss: 3.111607349268302
Validation loss: 2.5677171965881254

Epoch: 5| Step: 8
Training loss: 2.7470040040433106
Validation loss: 2.5307687210454928

Epoch: 5| Step: 9
Training loss: 2.6557171455425945
Validation loss: 2.5058119670455272

Epoch: 5| Step: 10
Training loss: 2.585922563861227
Validation loss: 2.499405669251233

Epoch: 147| Step: 0
Training loss: 2.7228361094981484
Validation loss: 2.4983654010762035

Epoch: 5| Step: 1
Training loss: 2.357006981471537
Validation loss: 2.4970825502497105

Epoch: 5| Step: 2
Training loss: 2.3654815267495866
Validation loss: 2.4944495379847553

Epoch: 5| Step: 3
Training loss: 2.6868404200037483
Validation loss: 2.4969633045809494

Epoch: 5| Step: 4
Training loss: 2.3358417606190396
Validation loss: 2.511719165413411

Epoch: 5| Step: 5
Training loss: 3.2511574078097856
Validation loss: 2.5269841027665874

Epoch: 5| Step: 6
Training loss: 2.488371411760598
Validation loss: 2.5424099895492587

Epoch: 5| Step: 7
Training loss: 2.829936927658701
Validation loss: 2.5405065587723743

Epoch: 5| Step: 8
Training loss: 3.07921708770752
Validation loss: 2.5512038569910884

Epoch: 5| Step: 9
Training loss: 3.0718806875026825
Validation loss: 2.54980888213498

Epoch: 5| Step: 10
Training loss: 2.8378496265534734
Validation loss: 2.533522687170528

Epoch: 148| Step: 0
Training loss: 2.5295475073396876
Validation loss: 2.548978370704985

Epoch: 5| Step: 1
Training loss: 2.8004806548780063
Validation loss: 2.533747026924253

Epoch: 5| Step: 2
Training loss: 2.339092560742509
Validation loss: 2.5472474647789958

Epoch: 5| Step: 3
Training loss: 3.0307764686310366
Validation loss: 2.5476886550014695

Epoch: 5| Step: 4
Training loss: 3.1753040438474587
Validation loss: 2.560824763290158

Epoch: 5| Step: 5
Training loss: 2.9203849705928917
Validation loss: 2.557397111971397

Epoch: 5| Step: 6
Training loss: 2.618704103053991
Validation loss: 2.582377037626644

Epoch: 5| Step: 7
Training loss: 2.9167631587461385
Validation loss: 2.626759220397

Epoch: 5| Step: 8
Training loss: 2.7406048242224323
Validation loss: 2.6126498453405054

Epoch: 5| Step: 9
Training loss: 2.18317093961112
Validation loss: 2.585412647099783

Epoch: 5| Step: 10
Training loss: 2.417903868462612
Validation loss: 2.590072032547448

Epoch: 149| Step: 0
Training loss: 2.7114471044514286
Validation loss: 2.591848829857908

Epoch: 5| Step: 1
Training loss: 2.9901791996664957
Validation loss: 2.597442128129748

Epoch: 5| Step: 2
Training loss: 2.824405310498334
Validation loss: 2.589226575881584

Epoch: 5| Step: 3
Training loss: 2.4705079977913202
Validation loss: 2.581837900228886

Epoch: 5| Step: 4
Training loss: 2.6053270018307693
Validation loss: 2.58087971407157

Epoch: 5| Step: 5
Training loss: 3.211501023343603
Validation loss: 2.573232017569067

Epoch: 5| Step: 6
Training loss: 2.2100669845510095
Validation loss: 2.563561006513662

Epoch: 5| Step: 7
Training loss: 2.3596484297401377
Validation loss: 2.540727410204147

Epoch: 5| Step: 8
Training loss: 2.907494883381088
Validation loss: 2.5285467441414053

Epoch: 5| Step: 9
Training loss: 2.343365345225715
Validation loss: 2.523070826587591

Epoch: 5| Step: 10
Training loss: 2.669433906350014
Validation loss: 2.5256219824581927

Epoch: 150| Step: 0
Training loss: 2.3977649255152196
Validation loss: 2.5374637156026623

Epoch: 5| Step: 1
Training loss: 2.4968358042747427
Validation loss: 2.5554188136962126

Epoch: 5| Step: 2
Training loss: 2.792884494604354
Validation loss: 2.595032668477017

Epoch: 5| Step: 3
Training loss: 2.804077252062551
Validation loss: 2.6141733066130715

Epoch: 5| Step: 4
Training loss: 2.7504637933985583
Validation loss: 2.69706803632686

Epoch: 5| Step: 5
Training loss: 2.412490283373304
Validation loss: 2.7301228819259817

Epoch: 5| Step: 6
Training loss: 2.738882306314347
Validation loss: 2.7214114276984835

Epoch: 5| Step: 7
Training loss: 2.7991294938170936
Validation loss: 2.6402893561809346

Epoch: 5| Step: 8
Training loss: 2.8734511474152526
Validation loss: 2.5628584074120844

Epoch: 5| Step: 9
Training loss: 2.727220166306757
Validation loss: 2.528332832969036

Epoch: 5| Step: 10
Training loss: 2.70503246943647
Validation loss: 2.5009645037140062

Epoch: 151| Step: 0
Training loss: 2.8617823738192496
Validation loss: 2.493076608835751

Epoch: 5| Step: 1
Training loss: 3.084461950682407
Validation loss: 2.494183110423019

Epoch: 5| Step: 2
Training loss: 2.4528898867538484
Validation loss: 2.497630927757199

Epoch: 5| Step: 3
Training loss: 3.2317860142148653
Validation loss: 2.490996644184927

Epoch: 5| Step: 4
Training loss: 3.0131248427594564
Validation loss: 2.491057646023196

Epoch: 5| Step: 5
Training loss: 2.7883625594768056
Validation loss: 2.4896444288382416

Epoch: 5| Step: 6
Training loss: 2.0281058993858125
Validation loss: 2.502039106484517

Epoch: 5| Step: 7
Training loss: 2.2229840350347843
Validation loss: 2.516114944586061

Epoch: 5| Step: 8
Training loss: 2.803514835803498
Validation loss: 2.547988181273993

Epoch: 5| Step: 9
Training loss: 2.128756848613768
Validation loss: 2.605070708506016

Epoch: 5| Step: 10
Training loss: 2.4967249399098064
Validation loss: 2.674815972152413

Epoch: 152| Step: 0
Training loss: 2.490239545031398
Validation loss: 2.741498693931084

Epoch: 5| Step: 1
Training loss: 3.0909563802987687
Validation loss: 2.7892526692909443

Epoch: 5| Step: 2
Training loss: 2.66006608493716
Validation loss: 2.8028814116512457

Epoch: 5| Step: 3
Training loss: 2.7694084021866128
Validation loss: 2.7678335881874285

Epoch: 5| Step: 4
Training loss: 2.883022062960174
Validation loss: 2.70522725981114

Epoch: 5| Step: 5
Training loss: 2.5546399033338467
Validation loss: 2.6396163360549845

Epoch: 5| Step: 6
Training loss: 2.7593676799188898
Validation loss: 2.55638614752002

Epoch: 5| Step: 7
Training loss: 2.5822268136392736
Validation loss: 2.518498353146343

Epoch: 5| Step: 8
Training loss: 2.7860468955820403
Validation loss: 2.507421622093943

Epoch: 5| Step: 9
Training loss: 2.233482129088897
Validation loss: 2.496095039474799

Epoch: 5| Step: 10
Training loss: 2.5579512626651844
Validation loss: 2.4912514821747855

Epoch: 153| Step: 0
Training loss: 2.640913366339059
Validation loss: 2.491680928932083

Epoch: 5| Step: 1
Training loss: 2.883417660430063
Validation loss: 2.502038163833452

Epoch: 5| Step: 2
Training loss: 2.316692058049018
Validation loss: 2.4959161833179353

Epoch: 5| Step: 3
Training loss: 3.1655985553386286
Validation loss: 2.5042719294736835

Epoch: 5| Step: 4
Training loss: 2.3305394498591636
Validation loss: 2.518378509050918

Epoch: 5| Step: 5
Training loss: 2.3167368249309654
Validation loss: 2.5805450695313463

Epoch: 5| Step: 6
Training loss: 2.2857171829239333
Validation loss: 2.6427768076307667

Epoch: 5| Step: 7
Training loss: 2.971310765949378
Validation loss: 2.659142815347289

Epoch: 5| Step: 8
Training loss: 2.505087158910159
Validation loss: 2.629614616417752

Epoch: 5| Step: 9
Training loss: 3.1975796964136785
Validation loss: 2.587317553744006

Epoch: 5| Step: 10
Training loss: 2.9425735487776374
Validation loss: 2.5770936356646943

Epoch: 154| Step: 0
Training loss: 2.733742428225343
Validation loss: 2.5474075303192714

Epoch: 5| Step: 1
Training loss: 2.600069826362213
Validation loss: 2.5174369383242587

Epoch: 5| Step: 2
Training loss: 2.6870232092618433
Validation loss: 2.510038242574147

Epoch: 5| Step: 3
Training loss: 2.548325014701657
Validation loss: 2.495720722315562

Epoch: 5| Step: 4
Training loss: 2.704867115811196
Validation loss: 2.486596869526387

Epoch: 5| Step: 5
Training loss: 2.2781475343361555
Validation loss: 2.483483708058555

Epoch: 5| Step: 6
Training loss: 3.035896279786029
Validation loss: 2.477918099695345

Epoch: 5| Step: 7
Training loss: 2.5503192851319074
Validation loss: 2.4931366548960985

Epoch: 5| Step: 8
Training loss: 2.526678784961208
Validation loss: 2.4990013363395014

Epoch: 5| Step: 9
Training loss: 2.4983983631420608
Validation loss: 2.514944769394496

Epoch: 5| Step: 10
Training loss: 2.8185021674239383
Validation loss: 2.5403322287052545

Epoch: 155| Step: 0
Training loss: 2.25171108880638
Validation loss: 2.577478544913524

Epoch: 5| Step: 1
Training loss: 2.1768010761108316
Validation loss: 2.6204587893131768

Epoch: 5| Step: 2
Training loss: 3.6000176217389623
Validation loss: 2.63706061707942

Epoch: 5| Step: 3
Training loss: 2.3667244536996677
Validation loss: 2.65138349346582

Epoch: 5| Step: 4
Training loss: 2.184756711426368
Validation loss: 2.632275208827154

Epoch: 5| Step: 5
Training loss: 2.0344416266106484
Validation loss: 2.606335841973725

Epoch: 5| Step: 6
Training loss: 2.5839777317091475
Validation loss: 2.5729674318136406

Epoch: 5| Step: 7
Training loss: 2.8751449548418493
Validation loss: 2.5390543942759884

Epoch: 5| Step: 8
Training loss: 2.3442607068906263
Validation loss: 2.53448736683842

Epoch: 5| Step: 9
Training loss: 3.1347151232302743
Validation loss: 2.529841042171229

Epoch: 5| Step: 10
Training loss: 2.778254492437609
Validation loss: 2.503375742973493

Epoch: 156| Step: 0
Training loss: 3.083614663013784
Validation loss: 2.4942254758940448

Epoch: 5| Step: 1
Training loss: 2.836214246461479
Validation loss: 2.4814375082692495

Epoch: 5| Step: 2
Training loss: 2.478104842153296
Validation loss: 2.4812807913517863

Epoch: 5| Step: 3
Training loss: 2.4290168057296535
Validation loss: 2.5011206386615674

Epoch: 5| Step: 4
Training loss: 2.5125595275507573
Validation loss: 2.511032948608616

Epoch: 5| Step: 5
Training loss: 2.7682752249550355
Validation loss: 2.5401995989154726

Epoch: 5| Step: 6
Training loss: 2.888591484101538
Validation loss: 2.594181809135798

Epoch: 5| Step: 7
Training loss: 2.1463989574038846
Validation loss: 2.612482713949397

Epoch: 5| Step: 8
Training loss: 1.9972685400741794
Validation loss: 2.5861937306688625

Epoch: 5| Step: 9
Training loss: 2.667737110185803
Validation loss: 2.5769201123756114

Epoch: 5| Step: 10
Training loss: 2.7258820217460387
Validation loss: 2.601715375084276

Epoch: 157| Step: 0
Training loss: 2.2350140704708408
Validation loss: 2.6337132780556645

Epoch: 5| Step: 1
Training loss: 2.9074048444768574
Validation loss: 2.667181437039175

Epoch: 5| Step: 2
Training loss: 2.333930643013825
Validation loss: 2.633755313738997

Epoch: 5| Step: 3
Training loss: 2.85186364660902
Validation loss: 2.591346268371775

Epoch: 5| Step: 4
Training loss: 2.3317590807074016
Validation loss: 2.5738893320823824

Epoch: 5| Step: 5
Training loss: 2.8358450209826747
Validation loss: 2.542447847790625

Epoch: 5| Step: 6
Training loss: 2.6703385067784366
Validation loss: 2.535238939421323

Epoch: 5| Step: 7
Training loss: 2.730071948993229
Validation loss: 2.526933896392922

Epoch: 5| Step: 8
Training loss: 2.506519590418818
Validation loss: 2.520076245126065

Epoch: 5| Step: 9
Training loss: 2.4588111046789325
Validation loss: 2.511544433611737

Epoch: 5| Step: 10
Training loss: 2.627578921743405
Validation loss: 2.527598455553925

Epoch: 158| Step: 0
Training loss: 2.4733239789444847
Validation loss: 2.5195519114120373

Epoch: 5| Step: 1
Training loss: 2.6442655489041447
Validation loss: 2.532353152570797

Epoch: 5| Step: 2
Training loss: 2.257842172605894
Validation loss: 2.5356029685295574

Epoch: 5| Step: 3
Training loss: 2.81210053044171
Validation loss: 2.5602564180269836

Epoch: 5| Step: 4
Training loss: 2.471470167186422
Validation loss: 2.591842973292055

Epoch: 5| Step: 5
Training loss: 2.882061289265974
Validation loss: 2.6198119927209444

Epoch: 5| Step: 6
Training loss: 2.5411512029369177
Validation loss: 2.6001390675142293

Epoch: 5| Step: 7
Training loss: 2.4809936929151326
Validation loss: 2.5437502767068834

Epoch: 5| Step: 8
Training loss: 2.5395126178545904
Validation loss: 2.5133914151235337

Epoch: 5| Step: 9
Training loss: 2.5149146552043122
Validation loss: 2.4979506686420128

Epoch: 5| Step: 10
Training loss: 2.736809044997348
Validation loss: 2.5010663024788107

Epoch: 159| Step: 0
Training loss: 3.053033639561948
Validation loss: 2.5031427216238895

Epoch: 5| Step: 1
Training loss: 2.2733178385805934
Validation loss: 2.5134403263526006

Epoch: 5| Step: 2
Training loss: 2.7619952504519785
Validation loss: 2.5213825322852834

Epoch: 5| Step: 3
Training loss: 2.5819815718911414
Validation loss: 2.550584566880095

Epoch: 5| Step: 4
Training loss: 3.036752798852803
Validation loss: 2.5672240892766616

Epoch: 5| Step: 5
Training loss: 2.5898564541190106
Validation loss: 2.571387642498711

Epoch: 5| Step: 6
Training loss: 2.374289155288362
Validation loss: 2.5510865215863454

Epoch: 5| Step: 7
Training loss: 2.2336742662806137
Validation loss: 2.5433724000496007

Epoch: 5| Step: 8
Training loss: 2.329985419297336
Validation loss: 2.5549151730046273

Epoch: 5| Step: 9
Training loss: 2.557495906673672
Validation loss: 2.523771271492995

Epoch: 5| Step: 10
Training loss: 2.0781357843793247
Validation loss: 2.526814585295495

Epoch: 160| Step: 0
Training loss: 2.4788122698512365
Validation loss: 2.5329083431759565

Epoch: 5| Step: 1
Training loss: 1.8766899122805207
Validation loss: 2.5270289059996576

Epoch: 5| Step: 2
Training loss: 2.4439669188400486
Validation loss: 2.5361204579056307

Epoch: 5| Step: 3
Training loss: 2.5772203187505363
Validation loss: 2.55210062455997

Epoch: 5| Step: 4
Training loss: 2.6933581357072023
Validation loss: 2.544108343813972

Epoch: 5| Step: 5
Training loss: 3.112560844592681
Validation loss: 2.513277619113384

Epoch: 5| Step: 6
Training loss: 2.8232647351605245
Validation loss: 2.5187273543227957

Epoch: 5| Step: 7
Training loss: 2.21398596998144
Validation loss: 2.540837597666146

Epoch: 5| Step: 8
Training loss: 2.2984810747882323
Validation loss: 2.5386536850127923

Epoch: 5| Step: 9
Training loss: 2.4865124222863
Validation loss: 2.513227341919086

Epoch: 5| Step: 10
Training loss: 2.782532728333456
Validation loss: 2.5503310241038135

Epoch: 161| Step: 0
Training loss: 2.825636385241013
Validation loss: 2.5530942728179697

Epoch: 5| Step: 1
Training loss: 2.7795983886158537
Validation loss: 2.58501114149115

Epoch: 5| Step: 2
Training loss: 2.0135439990313486
Validation loss: 2.5865828747202513

Epoch: 5| Step: 3
Training loss: 2.4450260274863025
Validation loss: 2.564756269002173

Epoch: 5| Step: 4
Training loss: 2.3484273396346453
Validation loss: 2.5760829391813274

Epoch: 5| Step: 5
Training loss: 2.6835904628061655
Validation loss: 2.6181977165263493

Epoch: 5| Step: 6
Training loss: 2.478004108188478
Validation loss: 2.568233242062415

Epoch: 5| Step: 7
Training loss: 2.509258198187201
Validation loss: 2.5512152723440344

Epoch: 5| Step: 8
Training loss: 2.4288553364479832
Validation loss: 2.5188747676684513

Epoch: 5| Step: 9
Training loss: 2.5145312472692902
Validation loss: 2.5192253525518513

Epoch: 5| Step: 10
Training loss: 2.592127188911623
Validation loss: 2.522256229100847

Epoch: 162| Step: 0
Training loss: 2.509963779568074
Validation loss: 2.534070690608077

Epoch: 5| Step: 1
Training loss: 2.400440684231882
Validation loss: 2.54699013940029

Epoch: 5| Step: 2
Training loss: 2.5636353187448226
Validation loss: 2.59367727609391

Epoch: 5| Step: 3
Training loss: 2.650146383165158
Validation loss: 2.6374748163848802

Epoch: 5| Step: 4
Training loss: 2.9488560737784173
Validation loss: 2.6329438963121423

Epoch: 5| Step: 5
Training loss: 1.9037292573516411
Validation loss: 2.5975047319368283

Epoch: 5| Step: 6
Training loss: 2.506135468945862
Validation loss: 2.5658015360355

Epoch: 5| Step: 7
Training loss: 2.38997995487889
Validation loss: 2.5116263091110294

Epoch: 5| Step: 8
Training loss: 2.82091678475283
Validation loss: 2.4740850358953685

Epoch: 5| Step: 9
Training loss: 2.5257703078245624
Validation loss: 2.4875216506986213

Epoch: 5| Step: 10
Training loss: 2.520979117809757
Validation loss: 2.4876079001450297

Epoch: 163| Step: 0
Training loss: 2.7009826284935317
Validation loss: 2.49423295643209

Epoch: 5| Step: 1
Training loss: 2.301766202552857
Validation loss: 2.503429455049763

Epoch: 5| Step: 2
Training loss: 2.481646112681836
Validation loss: 2.5213853029544717

Epoch: 5| Step: 3
Training loss: 2.7161853137610854
Validation loss: 2.5374063774912714

Epoch: 5| Step: 4
Training loss: 2.508019839833467
Validation loss: 2.525547897714967

Epoch: 5| Step: 5
Training loss: 2.785942063084501
Validation loss: 2.484477889183265

Epoch: 5| Step: 6
Training loss: 2.76931266836771
Validation loss: 2.467996929218579

Epoch: 5| Step: 7
Training loss: 2.15052677177434
Validation loss: 2.4695297988904104

Epoch: 5| Step: 8
Training loss: 2.2609929582164763
Validation loss: 2.468906667091164

Epoch: 5| Step: 9
Training loss: 2.7199509697590263
Validation loss: 2.4899529060799197

Epoch: 5| Step: 10
Training loss: 2.4155193981859666
Validation loss: 2.52455745150233

Epoch: 164| Step: 0
Training loss: 2.283644060121642
Validation loss: 2.5902864231935006

Epoch: 5| Step: 1
Training loss: 2.949554707168703
Validation loss: 2.635587574283634

Epoch: 5| Step: 2
Training loss: 2.4645385553242884
Validation loss: 2.5703494695204077

Epoch: 5| Step: 3
Training loss: 2.4114722518574148
Validation loss: 2.5346825287567647

Epoch: 5| Step: 4
Training loss: 3.055422955342706
Validation loss: 2.5228214297323537

Epoch: 5| Step: 5
Training loss: 2.353863980799698
Validation loss: 2.4877570802031204

Epoch: 5| Step: 6
Training loss: 2.4748006143115697
Validation loss: 2.481539511988837

Epoch: 5| Step: 7
Training loss: 2.748200000869932
Validation loss: 2.470472248844559

Epoch: 5| Step: 8
Training loss: 2.300628812497106
Validation loss: 2.47835877814349

Epoch: 5| Step: 9
Training loss: 2.4062827962646796
Validation loss: 2.4869891835179403

Epoch: 5| Step: 10
Training loss: 1.8228172129794595
Validation loss: 2.519091962080805

Epoch: 165| Step: 0
Training loss: 1.8008070672888343
Validation loss: 2.5614992424041607

Epoch: 5| Step: 1
Training loss: 2.6158883129741204
Validation loss: 2.6014005691973927

Epoch: 5| Step: 2
Training loss: 2.470606431840621
Validation loss: 2.5905702286867167

Epoch: 5| Step: 3
Training loss: 2.6045086648803863
Validation loss: 2.550026712151019

Epoch: 5| Step: 4
Training loss: 2.5914044172886004
Validation loss: 2.540807676347775

Epoch: 5| Step: 5
Training loss: 2.3506126132873026
Validation loss: 2.513899454729796

Epoch: 5| Step: 6
Training loss: 2.292086013804398
Validation loss: 2.495319035233782

Epoch: 5| Step: 7
Training loss: 2.969694449123476
Validation loss: 2.479180079942877

Epoch: 5| Step: 8
Training loss: 2.3149608200086345
Validation loss: 2.482705998581559

Epoch: 5| Step: 9
Training loss: 2.442587019152106
Validation loss: 2.485533308253121

Epoch: 5| Step: 10
Training loss: 2.531839655260086
Validation loss: 2.492508609779198

Epoch: 166| Step: 0
Training loss: 1.6746695861598604
Validation loss: 2.5191385878785697

Epoch: 5| Step: 1
Training loss: 2.6489369869434642
Validation loss: 2.5623724500764444

Epoch: 5| Step: 2
Training loss: 2.5247056921733044
Validation loss: 2.6172015935879256

Epoch: 5| Step: 3
Training loss: 2.6283536106247443
Validation loss: 2.637827781507813

Epoch: 5| Step: 4
Training loss: 2.758395730395232
Validation loss: 2.5638325970634392

Epoch: 5| Step: 5
Training loss: 2.444474439244283
Validation loss: 2.5171926845792676

Epoch: 5| Step: 6
Training loss: 2.5212907192287726
Validation loss: 2.471706277166193

Epoch: 5| Step: 7
Training loss: 2.880951567645598
Validation loss: 2.4559033510349653

Epoch: 5| Step: 8
Training loss: 2.249404828508984
Validation loss: 2.433597279015433

Epoch: 5| Step: 9
Training loss: 2.332675966124174
Validation loss: 2.441686219666245

Epoch: 5| Step: 10
Training loss: 2.3125349506108295
Validation loss: 2.447122248495724

Epoch: 167| Step: 0
Training loss: 1.7561368966930675
Validation loss: 2.4899542785283773

Epoch: 5| Step: 1
Training loss: 2.399016667621778
Validation loss: 2.561399179869756

Epoch: 5| Step: 2
Training loss: 2.342432287452781
Validation loss: 2.640309532851621

Epoch: 5| Step: 3
Training loss: 2.400612407274893
Validation loss: 2.7249294366324603

Epoch: 5| Step: 4
Training loss: 3.0088974618374835
Validation loss: 2.7183438522116132

Epoch: 5| Step: 5
Training loss: 2.583564060941498
Validation loss: 2.582014961793853

Epoch: 5| Step: 6
Training loss: 2.5434964477742223
Validation loss: 2.494921310426462

Epoch: 5| Step: 7
Training loss: 2.3574131773477704
Validation loss: 2.455278888888896

Epoch: 5| Step: 8
Training loss: 2.7596089074951653
Validation loss: 2.4491412037377267

Epoch: 5| Step: 9
Training loss: 2.735698183617733
Validation loss: 2.4649397581377497

Epoch: 5| Step: 10
Training loss: 2.5187267823012953
Validation loss: 2.4547796877026107

Epoch: 168| Step: 0
Training loss: 2.7831366494254284
Validation loss: 2.4525421560025555

Epoch: 5| Step: 1
Training loss: 2.56697668416127
Validation loss: 2.446335352000651

Epoch: 5| Step: 2
Training loss: 2.9090434769534923
Validation loss: 2.4377155455813972

Epoch: 5| Step: 3
Training loss: 2.2159520089499316
Validation loss: 2.4330086106082653

Epoch: 5| Step: 4
Training loss: 2.093725175852722
Validation loss: 2.4415736984746843

Epoch: 5| Step: 5
Training loss: 2.1258697973593557
Validation loss: 2.4662843559135808

Epoch: 5| Step: 6
Training loss: 2.73321150957942
Validation loss: 2.4834067558517114

Epoch: 5| Step: 7
Training loss: 2.5819379873356327
Validation loss: 2.532044486935676

Epoch: 5| Step: 8
Training loss: 2.2399316797736737
Validation loss: 2.569995150259275

Epoch: 5| Step: 9
Training loss: 2.3466429086407308
Validation loss: 2.606595214233398

Epoch: 5| Step: 10
Training loss: 1.8454238922581743
Validation loss: 2.658265642226314

Epoch: 169| Step: 0
Training loss: 2.5630569783105024
Validation loss: 2.688965184588026

Epoch: 5| Step: 1
Training loss: 1.6723804601079355
Validation loss: 2.7214037643052453

Epoch: 5| Step: 2
Training loss: 2.7138175506829443
Validation loss: 2.6806433728446586

Epoch: 5| Step: 3
Training loss: 2.3415522125437653
Validation loss: 2.5990643785537046

Epoch: 5| Step: 4
Training loss: 2.5305933159380167
Validation loss: 2.5574493436450054

Epoch: 5| Step: 5
Training loss: 2.598498582150702
Validation loss: 2.5303280375685997

Epoch: 5| Step: 6
Training loss: 2.662022948174043
Validation loss: 2.4822887107620804

Epoch: 5| Step: 7
Training loss: 2.261907856205327
Validation loss: 2.4945217673949784

Epoch: 5| Step: 8
Training loss: 2.1905236192173043
Validation loss: 2.4742420469508764

Epoch: 5| Step: 9
Training loss: 2.4610289541538504
Validation loss: 2.4648611328360763

Epoch: 5| Step: 10
Training loss: 2.451174987547825
Validation loss: 2.484158482825934

Epoch: 170| Step: 0
Training loss: 2.1425920345164386
Validation loss: 2.5197053953890127

Epoch: 5| Step: 1
Training loss: 2.601203779170145
Validation loss: 2.538893461824286

Epoch: 5| Step: 2
Training loss: 2.20584231059812
Validation loss: 2.601878714985287

Epoch: 5| Step: 3
Training loss: 2.348335155254422
Validation loss: 2.6396652703771326

Epoch: 5| Step: 4
Training loss: 2.2455262105665366
Validation loss: 2.657095140695936

Epoch: 5| Step: 5
Training loss: 2.7472089996208253
Validation loss: 2.6865795798194987

Epoch: 5| Step: 6
Training loss: 2.4968862215823595
Validation loss: 2.638046259828846

Epoch: 5| Step: 7
Training loss: 2.7339255699290024
Validation loss: 2.5320532215727374

Epoch: 5| Step: 8
Training loss: 2.8286901088549086
Validation loss: 2.499741756268102

Epoch: 5| Step: 9
Training loss: 2.139270994671165
Validation loss: 2.4378240336816863

Epoch: 5| Step: 10
Training loss: 2.21732639256758
Validation loss: 2.423571437245309

Epoch: 171| Step: 0
Training loss: 2.402187534618613
Validation loss: 2.43158045624821

Epoch: 5| Step: 1
Training loss: 2.6093375380333867
Validation loss: 2.431186264016273

Epoch: 5| Step: 2
Training loss: 2.1740538282003503
Validation loss: 2.4350794060267384

Epoch: 5| Step: 3
Training loss: 2.977073485400652
Validation loss: 2.455428168392619

Epoch: 5| Step: 4
Training loss: 2.458250680169778
Validation loss: 2.5176524096416717

Epoch: 5| Step: 5
Training loss: 2.026923281188384
Validation loss: 2.5314334715285436

Epoch: 5| Step: 6
Training loss: 2.125936189757906
Validation loss: 2.5828196004503408

Epoch: 5| Step: 7
Training loss: 2.481301860123235
Validation loss: 2.5920590046518557

Epoch: 5| Step: 8
Training loss: 2.2069239767555353
Validation loss: 2.566956694096273

Epoch: 5| Step: 9
Training loss: 2.5084158388511595
Validation loss: 2.5349120379495957

Epoch: 5| Step: 10
Training loss: 2.4508182832925307
Validation loss: 2.5465093415985813

Epoch: 172| Step: 0
Training loss: 2.423422239195281
Validation loss: 2.530216219132833

Epoch: 5| Step: 1
Training loss: 2.908698250540147
Validation loss: 2.510654548652219

Epoch: 5| Step: 2
Training loss: 2.2609161903204904
Validation loss: 2.5143830276733095

Epoch: 5| Step: 3
Training loss: 1.9170629533948678
Validation loss: 2.515047397746289

Epoch: 5| Step: 4
Training loss: 2.3066555090544343
Validation loss: 2.5046736172771826

Epoch: 5| Step: 5
Training loss: 2.7116886384523613
Validation loss: 2.537716221463886

Epoch: 5| Step: 6
Training loss: 2.072951912380623
Validation loss: 2.5470553923790327

Epoch: 5| Step: 7
Training loss: 2.386986650331305
Validation loss: 2.571842744840041

Epoch: 5| Step: 8
Training loss: 2.17154894240612
Validation loss: 2.603694129320669

Epoch: 5| Step: 9
Training loss: 2.474145040326559
Validation loss: 2.611657519613843

Epoch: 5| Step: 10
Training loss: 2.2084420615246687
Validation loss: 2.6110284970119735

Epoch: 173| Step: 0
Training loss: 2.535850112546963
Validation loss: 2.604832330760246

Epoch: 5| Step: 1
Training loss: 2.2798294451985517
Validation loss: 2.586231609160876

Epoch: 5| Step: 2
Training loss: 2.3146392618650404
Validation loss: 2.54297750054498

Epoch: 5| Step: 3
Training loss: 2.287196521743846
Validation loss: 2.515004240344069

Epoch: 5| Step: 4
Training loss: 1.920220073465263
Validation loss: 2.4670686740374843

Epoch: 5| Step: 5
Training loss: 2.23814319764052
Validation loss: 2.4498975005315518

Epoch: 5| Step: 6
Training loss: 1.8984234342328719
Validation loss: 2.4391631517585664

Epoch: 5| Step: 7
Training loss: 2.544263753162061
Validation loss: 2.422100838602097

Epoch: 5| Step: 8
Training loss: 2.579342733689281
Validation loss: 2.419605623291176

Epoch: 5| Step: 9
Training loss: 2.548166988757604
Validation loss: 2.4446737962422938

Epoch: 5| Step: 10
Training loss: 2.82266069966717
Validation loss: 2.4838979981223086

Epoch: 174| Step: 0
Training loss: 2.2483718067192533
Validation loss: 2.5532938480668266

Epoch: 5| Step: 1
Training loss: 2.0187161422110553
Validation loss: 2.6194771779098436

Epoch: 5| Step: 2
Training loss: 1.9603565464942683
Validation loss: 2.663300468717128

Epoch: 5| Step: 3
Training loss: 2.2367543176720397
Validation loss: 2.723366533652581

Epoch: 5| Step: 4
Training loss: 2.2120651766123562
Validation loss: 2.717109425641988

Epoch: 5| Step: 5
Training loss: 2.5635558023467335
Validation loss: 2.636842271956728

Epoch: 5| Step: 6
Training loss: 2.4954839925770416
Validation loss: 2.521152453426106

Epoch: 5| Step: 7
Training loss: 2.744842113825107
Validation loss: 2.4932170897129375

Epoch: 5| Step: 8
Training loss: 2.360624980123579
Validation loss: 2.47201996768627

Epoch: 5| Step: 9
Training loss: 2.5131089796244885
Validation loss: 2.4550389100649026

Epoch: 5| Step: 10
Training loss: 2.638366817118105
Validation loss: 2.4545192692163256

Epoch: 175| Step: 0
Training loss: 2.54072004940446
Validation loss: 2.4400160986754047

Epoch: 5| Step: 1
Training loss: 2.5154621711302294
Validation loss: 2.4509490215735714

Epoch: 5| Step: 2
Training loss: 2.3630750329708525
Validation loss: 2.4464824328024393

Epoch: 5| Step: 3
Training loss: 2.3337328659597363
Validation loss: 2.463657668750177

Epoch: 5| Step: 4
Training loss: 2.435710739337719
Validation loss: 2.5166754552596324

Epoch: 5| Step: 5
Training loss: 2.5164371861637953
Validation loss: 2.531979722919371

Epoch: 5| Step: 6
Training loss: 2.411082480837318
Validation loss: 2.5296947502528857

Epoch: 5| Step: 7
Training loss: 1.7707449348675632
Validation loss: 2.5128750958977655

Epoch: 5| Step: 8
Training loss: 2.0893081691778876
Validation loss: 2.4930733136334227

Epoch: 5| Step: 9
Training loss: 2.226928466703183
Validation loss: 2.505957295127402

Epoch: 5| Step: 10
Training loss: 2.693379380647692
Validation loss: 2.4815110079836935

Epoch: 176| Step: 0
Training loss: 1.8343962997941547
Validation loss: 2.5336620526644413

Epoch: 5| Step: 1
Training loss: 2.421942236182369
Validation loss: 2.5044807191151865

Epoch: 5| Step: 2
Training loss: 2.288205347596355
Validation loss: 2.475147803235318

Epoch: 5| Step: 3
Training loss: 2.4972858000306877
Validation loss: 2.428930347618238

Epoch: 5| Step: 4
Training loss: 2.6224522715571887
Validation loss: 2.452306496584196

Epoch: 5| Step: 5
Training loss: 2.2893339132901795
Validation loss: 2.468728980913011

Epoch: 5| Step: 6
Training loss: 1.8890160894885029
Validation loss: 2.5222744298477404

Epoch: 5| Step: 7
Training loss: 2.3664547632835666
Validation loss: 2.57632943001951

Epoch: 5| Step: 8
Training loss: 2.640909755183235
Validation loss: 2.617267999343144

Epoch: 5| Step: 9
Training loss: 2.1366072770353743
Validation loss: 2.5420110275237713

Epoch: 5| Step: 10
Training loss: 2.660954247879482
Validation loss: 2.499725213895206

Epoch: 177| Step: 0
Training loss: 1.7012704673954144
Validation loss: 2.4688807876396304

Epoch: 5| Step: 1
Training loss: 2.409763495842693
Validation loss: 2.4366749497007114

Epoch: 5| Step: 2
Training loss: 2.8485161381767043
Validation loss: 2.4336337276515745

Epoch: 5| Step: 3
Training loss: 2.402829600261039
Validation loss: 2.4117924570773996

Epoch: 5| Step: 4
Training loss: 2.4269116604276166
Validation loss: 2.438269376742445

Epoch: 5| Step: 5
Training loss: 2.702763439539895
Validation loss: 2.4572423363684477

Epoch: 5| Step: 6
Training loss: 1.7067883491102367
Validation loss: 2.4866407581116605

Epoch: 5| Step: 7
Training loss: 1.9905861795373954
Validation loss: 2.5032971400058392

Epoch: 5| Step: 8
Training loss: 2.259514929103977
Validation loss: 2.533755656536252

Epoch: 5| Step: 9
Training loss: 2.179535891274787
Validation loss: 2.5707163411970657

Epoch: 5| Step: 10
Training loss: 2.3975050912431075
Validation loss: 2.615169856632167

Epoch: 178| Step: 0
Training loss: 2.33169200480802
Validation loss: 2.607278384480965

Epoch: 5| Step: 1
Training loss: 2.653159643874871
Validation loss: 2.588930808670108

Epoch: 5| Step: 2
Training loss: 1.4921521886671907
Validation loss: 2.5668945926720395

Epoch: 5| Step: 3
Training loss: 1.9552012279979576
Validation loss: 2.5086660679623844

Epoch: 5| Step: 4
Training loss: 1.8608231875320551
Validation loss: 2.4989380878193868

Epoch: 5| Step: 5
Training loss: 2.6799562725371437
Validation loss: 2.462012266400117

Epoch: 5| Step: 6
Training loss: 2.45461699192081
Validation loss: 2.46691568333547

Epoch: 5| Step: 7
Training loss: 1.6885681304018831
Validation loss: 2.4542105781978822

Epoch: 5| Step: 8
Training loss: 2.6678395274914495
Validation loss: 2.4395365845783594

Epoch: 5| Step: 9
Training loss: 2.2370020221672076
Validation loss: 2.4451251686351987

Epoch: 5| Step: 10
Training loss: 2.759377702687928
Validation loss: 2.509389845436475

Epoch: 179| Step: 0
Training loss: 2.545192607493728
Validation loss: 2.5376543217655994

Epoch: 5| Step: 1
Training loss: 2.6315665990138206
Validation loss: 2.547988692394618

Epoch: 5| Step: 2
Training loss: 1.7034327377731442
Validation loss: 2.5283308689183484

Epoch: 5| Step: 3
Training loss: 2.211865664998944
Validation loss: 2.510967779464179

Epoch: 5| Step: 4
Training loss: 2.3516842629981713
Validation loss: 2.4793247521670483

Epoch: 5| Step: 5
Training loss: 2.446053292187526
Validation loss: 2.480441303406539

Epoch: 5| Step: 6
Training loss: 2.0740509252669246
Validation loss: 2.4899097492427473

Epoch: 5| Step: 7
Training loss: 2.1853656710725757
Validation loss: 2.4970029555502133

Epoch: 5| Step: 8
Training loss: 2.388659298630527
Validation loss: 2.5187656072024485

Epoch: 5| Step: 9
Training loss: 2.136452276431134
Validation loss: 2.53444686797258

Epoch: 5| Step: 10
Training loss: 2.0913531120312707
Validation loss: 2.566584232816685

Epoch: 180| Step: 0
Training loss: 2.2092656260912626
Validation loss: 2.572523188527202

Epoch: 5| Step: 1
Training loss: 2.2643109950665234
Validation loss: 2.579781762082515

Epoch: 5| Step: 2
Training loss: 2.294321937872288
Validation loss: 2.5412669900599467

Epoch: 5| Step: 3
Training loss: 1.8998877241189314
Validation loss: 2.4791479988115714

Epoch: 5| Step: 4
Training loss: 2.0426839772247067
Validation loss: 2.4601568970800707

Epoch: 5| Step: 5
Training loss: 2.383013307208494
Validation loss: 2.4265903875590453

Epoch: 5| Step: 6
Training loss: 2.1767633984829065
Validation loss: 2.423656885439778

Epoch: 5| Step: 7
Training loss: 2.3550611051500296
Validation loss: 2.4407904349768854

Epoch: 5| Step: 8
Training loss: 2.417373904516693
Validation loss: 2.4576539348206983

Epoch: 5| Step: 9
Training loss: 2.338547897047368
Validation loss: 2.458225641730055

Epoch: 5| Step: 10
Training loss: 2.607565886560239
Validation loss: 2.481918570389114

Epoch: 181| Step: 0
Training loss: 2.1139948234242096
Validation loss: 2.5644476417319373

Epoch: 5| Step: 1
Training loss: 2.0810496465800044
Validation loss: 2.6432394080350337

Epoch: 5| Step: 2
Training loss: 2.185700902888968
Validation loss: 2.7070046515761264

Epoch: 5| Step: 3
Training loss: 2.3626003829378357
Validation loss: 2.7131084040903297

Epoch: 5| Step: 4
Training loss: 2.498339387590717
Validation loss: 2.6500536979951015

Epoch: 5| Step: 5
Training loss: 2.0661361315875846
Validation loss: 2.588770686763357

Epoch: 5| Step: 6
Training loss: 2.101448141056729
Validation loss: 2.503119445231731

Epoch: 5| Step: 7
Training loss: 2.4867191411772196
Validation loss: 2.4466224298347696

Epoch: 5| Step: 8
Training loss: 2.4492588557073223
Validation loss: 2.4131575075914373

Epoch: 5| Step: 9
Training loss: 2.711431364867405
Validation loss: 2.41582812194304

Epoch: 5| Step: 10
Training loss: 2.3546980424124793
Validation loss: 2.4050482551182193

Epoch: 182| Step: 0
Training loss: 2.2837585869989425
Validation loss: 2.391865989877542

Epoch: 5| Step: 1
Training loss: 2.370148572489976
Validation loss: 2.38855839764642

Epoch: 5| Step: 2
Training loss: 2.2277479797086994
Validation loss: 2.4382809612399132

Epoch: 5| Step: 3
Training loss: 2.318631471961639
Validation loss: 2.5161703664168

Epoch: 5| Step: 4
Training loss: 2.3075289521720643
Validation loss: 2.6295821477760364

Epoch: 5| Step: 5
Training loss: 2.668956568136255
Validation loss: 2.6652660062592526

Epoch: 5| Step: 6
Training loss: 1.7613253608862973
Validation loss: 2.694635753255634

Epoch: 5| Step: 7
Training loss: 1.9140895919439507
Validation loss: 2.667761411324349

Epoch: 5| Step: 8
Training loss: 2.378938521243036
Validation loss: 2.649067333785547

Epoch: 5| Step: 9
Training loss: 2.175720433150537
Validation loss: 2.5984291177208356

Epoch: 5| Step: 10
Training loss: 2.199153269035155
Validation loss: 2.518279704715885

Epoch: 183| Step: 0
Training loss: 2.2648207716945663
Validation loss: 2.481476953786134

Epoch: 5| Step: 1
Training loss: 2.3847451298963187
Validation loss: 2.4888627319824983

Epoch: 5| Step: 2
Training loss: 2.627028816579142
Validation loss: 2.4573546544232934

Epoch: 5| Step: 3
Training loss: 2.1350660330859106
Validation loss: 2.4563592142051935

Epoch: 5| Step: 4
Training loss: 1.9366783122480191
Validation loss: 2.446893579195644

Epoch: 5| Step: 5
Training loss: 2.07145653550764
Validation loss: 2.4355594934573332

Epoch: 5| Step: 6
Training loss: 2.626013242352603
Validation loss: 2.4427335311779794

Epoch: 5| Step: 7
Training loss: 1.9593539588199993
Validation loss: 2.4381999758494826

Epoch: 5| Step: 8
Training loss: 1.9597821118438958
Validation loss: 2.42792593184486

Epoch: 5| Step: 9
Training loss: 2.214075133422904
Validation loss: 2.466727435938483

Epoch: 5| Step: 10
Training loss: 2.256705570458468
Validation loss: 2.494045398655887

Epoch: 184| Step: 0
Training loss: 2.5734621362948706
Validation loss: 2.5333185832085894

Epoch: 5| Step: 1
Training loss: 2.1048925173902884
Validation loss: 2.5189807114521505

Epoch: 5| Step: 2
Training loss: 2.4281678184946256
Validation loss: 2.517421878868137

Epoch: 5| Step: 3
Training loss: 2.091104914802094
Validation loss: 2.5274014036311967

Epoch: 5| Step: 4
Training loss: 1.9313270923819597
Validation loss: 2.521659651233739

Epoch: 5| Step: 5
Training loss: 2.522368024354667
Validation loss: 2.531348568480781

Epoch: 5| Step: 6
Training loss: 2.2102134786176726
Validation loss: 2.5186412035713093

Epoch: 5| Step: 7
Training loss: 1.988693584262951
Validation loss: 2.535938705385315

Epoch: 5| Step: 8
Training loss: 2.2777162119704353
Validation loss: 2.553129503508702

Epoch: 5| Step: 9
Training loss: 1.904851056181068
Validation loss: 2.563419393203726

Epoch: 5| Step: 10
Training loss: 1.92833034961352
Validation loss: 2.566045432852334

Epoch: 185| Step: 0
Training loss: 1.9537647267748801
Validation loss: 2.5288992595174613

Epoch: 5| Step: 1
Training loss: 1.8527816428633979
Validation loss: 2.5110143560081157

Epoch: 5| Step: 2
Training loss: 1.941357924782885
Validation loss: 2.5074615186905613

Epoch: 5| Step: 3
Training loss: 2.299197002882255
Validation loss: 2.5126664589525465

Epoch: 5| Step: 4
Training loss: 2.2876414812871175
Validation loss: 2.5291581619810866

Epoch: 5| Step: 5
Training loss: 2.3346661326140716
Validation loss: 2.5242777105361736

Epoch: 5| Step: 6
Training loss: 1.9257558701024724
Validation loss: 2.532352210068021

Epoch: 5| Step: 7
Training loss: 2.491635061040197
Validation loss: 2.537074473565526

Epoch: 5| Step: 8
Training loss: 1.937374110900411
Validation loss: 2.5184647756720437

Epoch: 5| Step: 9
Training loss: 2.530836283464652
Validation loss: 2.5016650530950857

Epoch: 5| Step: 10
Training loss: 2.1665823137540214
Validation loss: 2.495536538005

Epoch: 186| Step: 0
Training loss: 2.0502244175213913
Validation loss: 2.499879402410294

Epoch: 5| Step: 1
Training loss: 1.780556928753468
Validation loss: 2.50257563146039

Epoch: 5| Step: 2
Training loss: 1.8805108148476337
Validation loss: 2.494421803292294

Epoch: 5| Step: 3
Training loss: 2.2729304951061517
Validation loss: 2.493716018810801

Epoch: 5| Step: 4
Training loss: 2.1515302003251957
Validation loss: 2.52281760381182

Epoch: 5| Step: 5
Training loss: 2.1728095369882516
Validation loss: 2.5568117796236747

Epoch: 5| Step: 6
Training loss: 2.2496672490222287
Validation loss: 2.589652632300857

Epoch: 5| Step: 7
Training loss: 2.064923452108486
Validation loss: 2.605434089778544

Epoch: 5| Step: 8
Training loss: 2.1353952050099743
Validation loss: 2.5344406248709035

Epoch: 5| Step: 9
Training loss: 2.6299781824519646
Validation loss: 2.483065622763607

Epoch: 5| Step: 10
Training loss: 2.082681464890394
Validation loss: 2.4672550417056907

Epoch: 187| Step: 0
Training loss: 2.18167636060006
Validation loss: 2.449263088560762

Epoch: 5| Step: 1
Training loss: 1.9883543349588089
Validation loss: 2.440650537230222

Epoch: 5| Step: 2
Training loss: 1.6872718798131146
Validation loss: 2.450938944593415

Epoch: 5| Step: 3
Training loss: 2.547927732487809
Validation loss: 2.449099595038013

Epoch: 5| Step: 4
Training loss: 2.476330959916459
Validation loss: 2.495384187221033

Epoch: 5| Step: 5
Training loss: 1.7456082003912192
Validation loss: 2.5048641056773597

Epoch: 5| Step: 6
Training loss: 2.059871964410804
Validation loss: 2.5372984563405336

Epoch: 5| Step: 7
Training loss: 2.020465450294496
Validation loss: 2.5414385868930505

Epoch: 5| Step: 8
Training loss: 2.079681616587811
Validation loss: 2.554619740464375

Epoch: 5| Step: 9
Training loss: 2.4865093539729584
Validation loss: 2.537591167828563

Epoch: 5| Step: 10
Training loss: 1.7301134558502618
Validation loss: 2.5392078897579995

Epoch: 188| Step: 0
Training loss: 1.7829118973407516
Validation loss: 2.5459574029039858

Epoch: 5| Step: 1
Training loss: 2.2330205052993586
Validation loss: 2.5548594035843744

Epoch: 5| Step: 2
Training loss: 1.9817782855969408
Validation loss: 2.508884885944514

Epoch: 5| Step: 3
Training loss: 2.266309016659131
Validation loss: 2.514406480180839

Epoch: 5| Step: 4
Training loss: 1.9912373389962867
Validation loss: 2.511392911016019

Epoch: 5| Step: 5
Training loss: 2.204603848671601
Validation loss: 2.5325738292814615

Epoch: 5| Step: 6
Training loss: 1.9898599828410681
Validation loss: 2.5579394393990755

Epoch: 5| Step: 7
Training loss: 2.307218758584322
Validation loss: 2.577131944349225

Epoch: 5| Step: 8
Training loss: 2.343691100334129
Validation loss: 2.5296574211966

Epoch: 5| Step: 9
Training loss: 2.110432451596465
Validation loss: 2.489339555944228

Epoch: 5| Step: 10
Training loss: 1.8593912204066987
Validation loss: 2.47324786949062

Epoch: 189| Step: 0
Training loss: 2.2368677279537206
Validation loss: 2.494568221431392

Epoch: 5| Step: 1
Training loss: 2.1307030610846227
Validation loss: 2.5039741573839462

Epoch: 5| Step: 2
Training loss: 1.9575250120745173
Validation loss: 2.4977001378744625

Epoch: 5| Step: 3
Training loss: 2.130380438557461
Validation loss: 2.5252359932003765

Epoch: 5| Step: 4
Training loss: 1.949200158040091
Validation loss: 2.5618894116194904

Epoch: 5| Step: 5
Training loss: 2.3034075787507593
Validation loss: 2.552387471730441

Epoch: 5| Step: 6
Training loss: 2.0174795682456304
Validation loss: 2.5447117561789065

Epoch: 5| Step: 7
Training loss: 1.8443517834331
Validation loss: 2.5238026025576747

Epoch: 5| Step: 8
Training loss: 2.358181784335638
Validation loss: 2.511066419230536

Epoch: 5| Step: 9
Training loss: 1.4790813618450052
Validation loss: 2.529416825102985

Epoch: 5| Step: 10
Training loss: 2.3460633114908553
Validation loss: 2.4906867131639485

Epoch: 190| Step: 0
Training loss: 1.8907769512559207
Validation loss: 2.47546975943928

Epoch: 5| Step: 1
Training loss: 1.9184937545201477
Validation loss: 2.465259683386524

Epoch: 5| Step: 2
Training loss: 2.3772764840138625
Validation loss: 2.4574807125689113

Epoch: 5| Step: 3
Training loss: 2.0244138269566916
Validation loss: 2.5040699756797524

Epoch: 5| Step: 4
Training loss: 1.8154798544877278
Validation loss: 2.504242845789708

Epoch: 5| Step: 5
Training loss: 2.4496926757197226
Validation loss: 2.5023061554757846

Epoch: 5| Step: 6
Training loss: 2.00036105234835
Validation loss: 2.5187172238231548

Epoch: 5| Step: 7
Training loss: 1.9431342373122573
Validation loss: 2.5067149048221746

Epoch: 5| Step: 8
Training loss: 1.7787727396323099
Validation loss: 2.515341010293123

Epoch: 5| Step: 9
Training loss: 2.3827504634598573
Validation loss: 2.5096996844077726

Epoch: 5| Step: 10
Training loss: 1.9585219623813583
Validation loss: 2.5230817382421358

Epoch: 191| Step: 0
Training loss: 1.5634119805573696
Validation loss: 2.6019489425416022

Epoch: 5| Step: 1
Training loss: 2.018761257459118
Validation loss: 2.6653232311659845

Epoch: 5| Step: 2
Training loss: 1.7301527987789989
Validation loss: 2.7370890340496747

Epoch: 5| Step: 3
Training loss: 1.9941205388924743
Validation loss: 2.7898567998700603

Epoch: 5| Step: 4
Training loss: 2.3466207597678284
Validation loss: 2.745143462401641

Epoch: 5| Step: 5
Training loss: 1.8916267074308035
Validation loss: 2.655810138878558

Epoch: 5| Step: 6
Training loss: 1.8639340966407243
Validation loss: 2.586063438575526

Epoch: 5| Step: 7
Training loss: 2.3975568018003006
Validation loss: 2.502296223844683

Epoch: 5| Step: 8
Training loss: 2.297848242268107
Validation loss: 2.4461184667416567

Epoch: 5| Step: 9
Training loss: 2.459227727918102
Validation loss: 2.4533710652859346

Epoch: 5| Step: 10
Training loss: 2.0926961951301735
Validation loss: 2.4559572579106845

Epoch: 192| Step: 0
Training loss: 2.0483595727782
Validation loss: 2.4333586560079525

Epoch: 5| Step: 1
Training loss: 2.2981366695204257
Validation loss: 2.4487071928476336

Epoch: 5| Step: 2
Training loss: 1.54290330965361
Validation loss: 2.4775777826495253

Epoch: 5| Step: 3
Training loss: 2.065487403153418
Validation loss: 2.479611167102689

Epoch: 5| Step: 4
Training loss: 2.2735521215534438
Validation loss: 2.5214490783421617

Epoch: 5| Step: 5
Training loss: 2.3061622168729214
Validation loss: 2.546754158878116

Epoch: 5| Step: 6
Training loss: 1.845220335129266
Validation loss: 2.57015181115609

Epoch: 5| Step: 7
Training loss: 1.5348398596019073
Validation loss: 2.573198052418329

Epoch: 5| Step: 8
Training loss: 2.025284090247518
Validation loss: 2.5782589954347013

Epoch: 5| Step: 9
Training loss: 2.0639501155547078
Validation loss: 2.58125288057205

Epoch: 5| Step: 10
Training loss: 2.338171257697405
Validation loss: 2.5463159640776847

Epoch: 193| Step: 0
Training loss: 1.9972483660502285
Validation loss: 2.517514369676054

Epoch: 5| Step: 1
Training loss: 2.483620775045144
Validation loss: 2.474288041445976

Epoch: 5| Step: 2
Training loss: 1.864506796290726
Validation loss: 2.4649599785494813

Epoch: 5| Step: 3
Training loss: 2.148017204095008
Validation loss: 2.449952200883092

Epoch: 5| Step: 4
Training loss: 1.9039217378896616
Validation loss: 2.4735803396748426

Epoch: 5| Step: 5
Training loss: 1.9932167535944736
Validation loss: 2.4901128380795265

Epoch: 5| Step: 6
Training loss: 2.07044481538413
Validation loss: 2.486430311637738

Epoch: 5| Step: 7
Training loss: 2.0009302121812684
Validation loss: 2.5222592275017597

Epoch: 5| Step: 8
Training loss: 1.975357532733215
Validation loss: 2.547482929642905

Epoch: 5| Step: 9
Training loss: 1.6389693852859306
Validation loss: 2.608384964682318

Epoch: 5| Step: 10
Training loss: 1.980504203042663
Validation loss: 2.6716057675880203

Epoch: 194| Step: 0
Training loss: 2.4027882234594986
Validation loss: 2.648182239476849

Epoch: 5| Step: 1
Training loss: 2.0416519268308275
Validation loss: 2.624192421753931

Epoch: 5| Step: 2
Training loss: 1.861484388935084
Validation loss: 2.583727485671401

Epoch: 5| Step: 3
Training loss: 1.80960661043179
Validation loss: 2.534516013948238

Epoch: 5| Step: 4
Training loss: 1.8593963493596088
Validation loss: 2.498235067211624

Epoch: 5| Step: 5
Training loss: 2.4142578441014075
Validation loss: 2.4750386884426363

Epoch: 5| Step: 6
Training loss: 2.0419028658055725
Validation loss: 2.4788253382380896

Epoch: 5| Step: 7
Training loss: 1.7603891434483596
Validation loss: 2.4657193501102133

Epoch: 5| Step: 8
Training loss: 2.3441089609553774
Validation loss: 2.473295691216198

Epoch: 5| Step: 9
Training loss: 1.4586542412218773
Validation loss: 2.527809683502113

Epoch: 5| Step: 10
Training loss: 1.749937669461436
Validation loss: 2.5719543941979683

Epoch: 195| Step: 0
Training loss: 1.901250944419491
Validation loss: 2.5777382380000584

Epoch: 5| Step: 1
Training loss: 1.9199920362068954
Validation loss: 2.616179413736019

Epoch: 5| Step: 2
Training loss: 1.8437596337018245
Validation loss: 2.6566555439874753

Epoch: 5| Step: 3
Training loss: 2.1298438571059277
Validation loss: 2.613978381429903

Epoch: 5| Step: 4
Training loss: 2.1247534889401707
Validation loss: 2.56054839082883

Epoch: 5| Step: 5
Training loss: 2.2750133807449044
Validation loss: 2.516346477368614

Epoch: 5| Step: 6
Training loss: 1.8993142697515812
Validation loss: 2.5141701669455276

Epoch: 5| Step: 7
Training loss: 1.8248886414088643
Validation loss: 2.4916664597508498

Epoch: 5| Step: 8
Training loss: 1.9911092794902832
Validation loss: 2.504542188886945

Epoch: 5| Step: 9
Training loss: 2.049817714495289
Validation loss: 2.500627010431065

Epoch: 5| Step: 10
Training loss: 1.8734246311588871
Validation loss: 2.5064918256351723

Epoch: 196| Step: 0
Training loss: 1.6379149806556508
Validation loss: 2.5152368202088846

Epoch: 5| Step: 1
Training loss: 1.8824088902608425
Validation loss: 2.5196864526821185

Epoch: 5| Step: 2
Training loss: 1.7940061804963716
Validation loss: 2.5269585817237687

Epoch: 5| Step: 3
Training loss: 2.0297168521065547
Validation loss: 2.5297530130650783

Epoch: 5| Step: 4
Training loss: 2.0699904857177276
Validation loss: 2.5318675825351225

Epoch: 5| Step: 5
Training loss: 1.8945711426615028
Validation loss: 2.503855755960918

Epoch: 5| Step: 6
Training loss: 2.19203196141686
Validation loss: 2.5259033136481492

Epoch: 5| Step: 7
Training loss: 1.7326696448780594
Validation loss: 2.5221246252650125

Epoch: 5| Step: 8
Training loss: 2.298506903102982
Validation loss: 2.5319641829539976

Epoch: 5| Step: 9
Training loss: 2.0346240850686654
Validation loss: 2.5619330110315213

Epoch: 5| Step: 10
Training loss: 2.093358700754463
Validation loss: 2.536078780164501

Epoch: 197| Step: 0
Training loss: 1.7997134801860961
Validation loss: 2.527495312391075

Epoch: 5| Step: 1
Training loss: 1.7421139415043196
Validation loss: 2.5485714249558575

Epoch: 5| Step: 2
Training loss: 2.0377141360226374
Validation loss: 2.5473062963014477

Epoch: 5| Step: 3
Training loss: 2.0088372491334034
Validation loss: 2.5352307688897837

Epoch: 5| Step: 4
Training loss: 2.103000191645448
Validation loss: 2.551582301977005

Epoch: 5| Step: 5
Training loss: 1.716037968751252
Validation loss: 2.582827184700256

Epoch: 5| Step: 6
Training loss: 1.9555214789822029
Validation loss: 2.5624507826293703

Epoch: 5| Step: 7
Training loss: 1.6970659320681254
Validation loss: 2.5411006318049414

Epoch: 5| Step: 8
Training loss: 1.9511518353262696
Validation loss: 2.5017817505811926

Epoch: 5| Step: 9
Training loss: 1.7664785431920025
Validation loss: 2.5083451041398988

Epoch: 5| Step: 10
Training loss: 2.417466612213495
Validation loss: 2.48146693259116

Epoch: 198| Step: 0
Training loss: 1.9658345024404031
Validation loss: 2.4569099738440627

Epoch: 5| Step: 1
Training loss: 1.7856197631887327
Validation loss: 2.472265653868967

Epoch: 5| Step: 2
Training loss: 2.256878511166753
Validation loss: 2.4730491707666187

Epoch: 5| Step: 3
Training loss: 2.2727232135389666
Validation loss: 2.474465998238269

Epoch: 5| Step: 4
Training loss: 1.7379169896827507
Validation loss: 2.499258236925308

Epoch: 5| Step: 5
Training loss: 1.7383450271393557
Validation loss: 2.5097572203624283

Epoch: 5| Step: 6
Training loss: 1.758605439101916
Validation loss: 2.5184933429180285

Epoch: 5| Step: 7
Training loss: 2.0905317938630694
Validation loss: 2.562813379277483

Epoch: 5| Step: 8
Training loss: 1.9744982890983582
Validation loss: 2.6005402426138304

Epoch: 5| Step: 9
Training loss: 1.5421678999840882
Validation loss: 2.6241901201163165

Epoch: 5| Step: 10
Training loss: 1.7999658952237139
Validation loss: 2.5769200636281195

Epoch: 199| Step: 0
Training loss: 2.563033443844449
Validation loss: 2.5508409206171963

Epoch: 5| Step: 1
Training loss: 2.193053906196982
Validation loss: 2.5369439628035213

Epoch: 5| Step: 2
Training loss: 1.463446110584604
Validation loss: 2.569817417146662

Epoch: 5| Step: 3
Training loss: 1.6927953218458538
Validation loss: 2.519785156073379

Epoch: 5| Step: 4
Training loss: 1.6933209371989117
Validation loss: 2.5119239405503757

Epoch: 5| Step: 5
Training loss: 1.4349693745658032
Validation loss: 2.5231869049079405

Epoch: 5| Step: 6
Training loss: 1.8114859276355775
Validation loss: 2.5690697400553244

Epoch: 5| Step: 7
Training loss: 2.1350117617423843
Validation loss: 2.566385614178541

Epoch: 5| Step: 8
Training loss: 1.6301542116713854
Validation loss: 2.5951455369073244

Epoch: 5| Step: 9
Training loss: 1.8659515759562135
Validation loss: 2.6257075739502937

Epoch: 5| Step: 10
Training loss: 2.0150315941541592
Validation loss: 2.6013350503885073

Epoch: 200| Step: 0
Training loss: 1.897468853520222
Validation loss: 2.557706963863728

Epoch: 5| Step: 1
Training loss: 1.6564587155674586
Validation loss: 2.5321005892672392

Epoch: 5| Step: 2
Training loss: 1.360390032068898
Validation loss: 2.5222848723234104

Epoch: 5| Step: 3
Training loss: 2.107166066168924
Validation loss: 2.504544844094876

Epoch: 5| Step: 4
Training loss: 2.399702105313154
Validation loss: 2.525076925348048

Epoch: 5| Step: 5
Training loss: 1.69525195598166
Validation loss: 2.544302254882258

Epoch: 5| Step: 6
Training loss: 1.6022816601817196
Validation loss: 2.528910746153776

Epoch: 5| Step: 7
Training loss: 2.333439949415471
Validation loss: 2.552331849973974

Epoch: 5| Step: 8
Training loss: 1.852558367140455
Validation loss: 2.5555124011311405

Epoch: 5| Step: 9
Training loss: 1.64450624134321
Validation loss: 2.561598290224804

Epoch: 5| Step: 10
Training loss: 1.8220987355962224
Validation loss: 2.5980941749974225

Epoch: 201| Step: 0
Training loss: 1.958570655348795
Validation loss: 2.5928032357047903

Epoch: 5| Step: 1
Training loss: 1.721917164696495
Validation loss: 2.6220241580226085

Epoch: 5| Step: 2
Training loss: 1.4814596357765886
Validation loss: 2.6474707419178873

Epoch: 5| Step: 3
Training loss: 2.131532501559922
Validation loss: 2.6733597513198295

Epoch: 5| Step: 4
Training loss: 2.3327341218570896
Validation loss: 2.6009528830889455

Epoch: 5| Step: 5
Training loss: 1.7772629268839895
Validation loss: 2.5188367342531315

Epoch: 5| Step: 6
Training loss: 1.6879468255639443
Validation loss: 2.468908095888996

Epoch: 5| Step: 7
Training loss: 1.6680330715239893
Validation loss: 2.4779540060746856

Epoch: 5| Step: 8
Training loss: 1.8593493547995115
Validation loss: 2.4345287590948916

Epoch: 5| Step: 9
Training loss: 2.0501511541326067
Validation loss: 2.4395244742996285

Epoch: 5| Step: 10
Training loss: 1.7621781454363978
Validation loss: 2.4689906989346677

Epoch: 202| Step: 0
Training loss: 2.125502358689454
Validation loss: 2.4970881290831577

Epoch: 5| Step: 1
Training loss: 1.4822170432691508
Validation loss: 2.548590565392871

Epoch: 5| Step: 2
Training loss: 2.0082392257654047
Validation loss: 2.6036047905639124

Epoch: 5| Step: 3
Training loss: 1.9123228302715352
Validation loss: 2.5563074275527975

Epoch: 5| Step: 4
Training loss: 1.6668784801674248
Validation loss: 2.5407113047063543

Epoch: 5| Step: 5
Training loss: 1.8924265703395726
Validation loss: 2.555104233508972

Epoch: 5| Step: 6
Training loss: 1.5966098781805271
Validation loss: 2.527684354770443

Epoch: 5| Step: 7
Training loss: 1.9069549007673965
Validation loss: 2.5214285443176827

Epoch: 5| Step: 8
Training loss: 1.914108711774737
Validation loss: 2.505847826689483

Epoch: 5| Step: 9
Training loss: 1.9422481561151914
Validation loss: 2.5203975164142403

Epoch: 5| Step: 10
Training loss: 1.9648010370605913
Validation loss: 2.50467530816931

Epoch: 203| Step: 0
Training loss: 1.6301289824489857
Validation loss: 2.510086517485258

Epoch: 5| Step: 1
Training loss: 1.6929029929888642
Validation loss: 2.524500040619782

Epoch: 5| Step: 2
Training loss: 1.661706537184787
Validation loss: 2.5379537181106047

Epoch: 5| Step: 3
Training loss: 1.6458171248140843
Validation loss: 2.541322236617613

Epoch: 5| Step: 4
Training loss: 1.7072292186898381
Validation loss: 2.5811395377333133

Epoch: 5| Step: 5
Training loss: 1.957353637699572
Validation loss: 2.603220516151731

Epoch: 5| Step: 6
Training loss: 1.910521552293018
Validation loss: 2.6007752877311363

Epoch: 5| Step: 7
Training loss: 2.1071137918125658
Validation loss: 2.614277931192443

Epoch: 5| Step: 8
Training loss: 2.111232024907349
Validation loss: 2.5812057807160187

Epoch: 5| Step: 9
Training loss: 1.6871180631957494
Validation loss: 2.564187949327088

Epoch: 5| Step: 10
Training loss: 1.9078634344326615
Validation loss: 2.5734722834004615

Epoch: 204| Step: 0
Training loss: 2.1495845437630297
Validation loss: 2.504245035523396

Epoch: 5| Step: 1
Training loss: 2.0680454725582327
Validation loss: 2.4702166272446027

Epoch: 5| Step: 2
Training loss: 1.9473136199576728
Validation loss: 2.441982490904197

Epoch: 5| Step: 3
Training loss: 1.5317885561162818
Validation loss: 2.4437746870291313

Epoch: 5| Step: 4
Training loss: 1.2866068251106337
Validation loss: 2.4816549286327527

Epoch: 5| Step: 5
Training loss: 1.5107395835415098
Validation loss: 2.502179323412033

Epoch: 5| Step: 6
Training loss: 1.8759596594029615
Validation loss: 2.538463731562529

Epoch: 5| Step: 7
Training loss: 1.7765738695731998
Validation loss: 2.528001401902739

Epoch: 5| Step: 8
Training loss: 1.9651372550027533
Validation loss: 2.5581651183457312

Epoch: 5| Step: 9
Training loss: 1.914019276656417
Validation loss: 2.5927145816528268

Epoch: 5| Step: 10
Training loss: 1.8123887126563551
Validation loss: 2.5999924940832315

Epoch: 205| Step: 0
Training loss: 1.4950048403199088
Validation loss: 2.6041177803291147

Epoch: 5| Step: 1
Training loss: 1.8341627267844027
Validation loss: 2.6147445823783255

Epoch: 5| Step: 2
Training loss: 1.7778355180118925
Validation loss: 2.552281898138738

Epoch: 5| Step: 3
Training loss: 2.1385870372371154
Validation loss: 2.533385211403141

Epoch: 5| Step: 4
Training loss: 1.7128966101930068
Validation loss: 2.5257003331981727

Epoch: 5| Step: 5
Training loss: 1.9379511892354593
Validation loss: 2.4716703256622523

Epoch: 5| Step: 6
Training loss: 1.3487051599807331
Validation loss: 2.458653819316575

Epoch: 5| Step: 7
Training loss: 1.6540908414948419
Validation loss: 2.4465793029305303

Epoch: 5| Step: 8
Training loss: 1.8068853429064828
Validation loss: 2.456858367839834

Epoch: 5| Step: 9
Training loss: 1.6752956015672622
Validation loss: 2.483056425683649

Epoch: 5| Step: 10
Training loss: 2.2499993642170324
Validation loss: 2.550448839054619

Epoch: 206| Step: 0
Training loss: 1.466419156098515
Validation loss: 2.5836584040149755

Epoch: 5| Step: 1
Training loss: 1.6748138694400272
Validation loss: 2.635350768159411

Epoch: 5| Step: 2
Training loss: 1.8887767111746967
Validation loss: 2.676073124021282

Epoch: 5| Step: 3
Training loss: 1.8546424712424965
Validation loss: 2.6735215016017824

Epoch: 5| Step: 4
Training loss: 2.2073158823304895
Validation loss: 2.5895389492659278

Epoch: 5| Step: 5
Training loss: 1.5696112741944253
Validation loss: 2.534515551190973

Epoch: 5| Step: 6
Training loss: 1.7741840152540294
Validation loss: 2.4707681753919144

Epoch: 5| Step: 7
Training loss: 1.8310396483757392
Validation loss: 2.4352980839413534

Epoch: 5| Step: 8
Training loss: 1.6266718114057594
Validation loss: 2.4592672388286645

Epoch: 5| Step: 9
Training loss: 1.98515514747562
Validation loss: 2.492070563097636

Epoch: 5| Step: 10
Training loss: 1.7649790839882193
Validation loss: 2.533649237778287

Epoch: 207| Step: 0
Training loss: 1.8536245074916224
Validation loss: 2.5984714035553202

Epoch: 5| Step: 1
Training loss: 1.3339944730183777
Validation loss: 2.6143714365594946

Epoch: 5| Step: 2
Training loss: 1.544269872689766
Validation loss: 2.656548530456412

Epoch: 5| Step: 3
Training loss: 1.2131684456562537
Validation loss: 2.6074804962108034

Epoch: 5| Step: 4
Training loss: 2.3491055145730284
Validation loss: 2.5727867368330997

Epoch: 5| Step: 5
Training loss: 1.9342472705977116
Validation loss: 2.5192122617186765

Epoch: 5| Step: 6
Training loss: 2.0960562231662174
Validation loss: 2.5042117439938343

Epoch: 5| Step: 7
Training loss: 1.6032588255945837
Validation loss: 2.4936816383351115

Epoch: 5| Step: 8
Training loss: 1.7240637048824623
Validation loss: 2.4889789296775593

Epoch: 5| Step: 9
Training loss: 1.6915206341907107
Validation loss: 2.499826985186704

Epoch: 5| Step: 10
Training loss: 1.8053810141228903
Validation loss: 2.524315545181746

Epoch: 208| Step: 0
Training loss: 1.748317181876568
Validation loss: 2.5440651130759337

Epoch: 5| Step: 1
Training loss: 1.1576676827699124
Validation loss: 2.6209224844686028

Epoch: 5| Step: 2
Training loss: 2.192251766510812
Validation loss: 2.6824302655850376

Epoch: 5| Step: 3
Training loss: 2.1672826282660256
Validation loss: 2.7204760959734062

Epoch: 5| Step: 4
Training loss: 1.5635297052619277
Validation loss: 2.7579449497457613

Epoch: 5| Step: 5
Training loss: 1.634225480368243
Validation loss: 2.7613179446472764

Epoch: 5| Step: 6
Training loss: 1.8778311018673919
Validation loss: 2.6665542762155092

Epoch: 5| Step: 7
Training loss: 1.4722533952463663
Validation loss: 2.604315621986919

Epoch: 5| Step: 8
Training loss: 1.5980124974102274
Validation loss: 2.5151051039042036

Epoch: 5| Step: 9
Training loss: 1.6934919294418969
Validation loss: 2.480864785956839

Epoch: 5| Step: 10
Training loss: 1.8305494745732696
Validation loss: 2.430707185960154

Epoch: 209| Step: 0
Training loss: 1.8236452953462539
Validation loss: 2.4059357008369022

Epoch: 5| Step: 1
Training loss: 1.6599818239021247
Validation loss: 2.412697584301008

Epoch: 5| Step: 2
Training loss: 1.4937094870464287
Validation loss: 2.446036508300553

Epoch: 5| Step: 3
Training loss: 1.4268716065696034
Validation loss: 2.485426046529128

Epoch: 5| Step: 4
Training loss: 1.8365692350411098
Validation loss: 2.563233091856595

Epoch: 5| Step: 5
Training loss: 1.929084158410753
Validation loss: 2.629473049657221

Epoch: 5| Step: 6
Training loss: 1.5105539018395036
Validation loss: 2.6013523046331635

Epoch: 5| Step: 7
Training loss: 2.1961631348680846
Validation loss: 2.596218061171546

Epoch: 5| Step: 8
Training loss: 2.1467970255055513
Validation loss: 2.6099477837701195

Epoch: 5| Step: 9
Training loss: 1.5181111660135032
Validation loss: 2.550166670563907

Epoch: 5| Step: 10
Training loss: 1.7851269341864284
Validation loss: 2.5439694820702403

Epoch: 210| Step: 0
Training loss: 1.9695392419334394
Validation loss: 2.523924026566574

Epoch: 5| Step: 1
Training loss: 1.8419097509817681
Validation loss: 2.497087078817894

Epoch: 5| Step: 2
Training loss: 1.392479420891674
Validation loss: 2.4610784435262314

Epoch: 5| Step: 3
Training loss: 1.8583020873358107
Validation loss: 2.4677901628904815

Epoch: 5| Step: 4
Training loss: 1.4434086813138247
Validation loss: 2.4834347384667343

Epoch: 5| Step: 5
Training loss: 1.8263614331765567
Validation loss: 2.506380633523505

Epoch: 5| Step: 6
Training loss: 1.7258886342726105
Validation loss: 2.571470068093627

Epoch: 5| Step: 7
Training loss: 1.0800110725435697
Validation loss: 2.652568410792042

Epoch: 5| Step: 8
Training loss: 1.8561076459662318
Validation loss: 2.683107072514582

Epoch: 5| Step: 9
Training loss: 1.8359467201813027
Validation loss: 2.756307298123632

Epoch: 5| Step: 10
Training loss: 2.349179299076898
Validation loss: 2.7258014768106174

Epoch: 211| Step: 0
Training loss: 1.79191155940888
Validation loss: 2.6459521040170686

Epoch: 5| Step: 1
Training loss: 1.786195148028916
Validation loss: 2.5603574494059624

Epoch: 5| Step: 2
Training loss: 1.7985681932091926
Validation loss: 2.487281961707343

Epoch: 5| Step: 3
Training loss: 1.3658264797163646
Validation loss: 2.449083119891082

Epoch: 5| Step: 4
Training loss: 1.5507070682184723
Validation loss: 2.4704065929219743

Epoch: 5| Step: 5
Training loss: 1.6430879543302856
Validation loss: 2.5288296918215

Epoch: 5| Step: 6
Training loss: 1.7626357303598734
Validation loss: 2.548906775228267

Epoch: 5| Step: 7
Training loss: 1.986716383476213
Validation loss: 2.5684497171208607

Epoch: 5| Step: 8
Training loss: 1.8458193787792858
Validation loss: 2.63332333092317

Epoch: 5| Step: 9
Training loss: 1.5234371869991665
Validation loss: 2.643331031568136

Epoch: 5| Step: 10
Training loss: 1.9248282219673607
Validation loss: 2.6664394299789134

Epoch: 212| Step: 0
Training loss: 1.580878546588871
Validation loss: 2.605135858807617

Epoch: 5| Step: 1
Training loss: 1.6813408100320917
Validation loss: 2.5426428554389693

Epoch: 5| Step: 2
Training loss: 1.5443960035093065
Validation loss: 2.4674892412444356

Epoch: 5| Step: 3
Training loss: 1.5799351499020833
Validation loss: 2.454318630163496

Epoch: 5| Step: 4
Training loss: 1.6511346528095079
Validation loss: 2.456058565230203

Epoch: 5| Step: 5
Training loss: 1.2919066524088372
Validation loss: 2.4844252759990764

Epoch: 5| Step: 6
Training loss: 1.918257308975866
Validation loss: 2.527671066359715

Epoch: 5| Step: 7
Training loss: 2.297469808153888
Validation loss: 2.5951149278827366

Epoch: 5| Step: 8
Training loss: 1.4957464626805366
Validation loss: 2.6591325179317127

Epoch: 5| Step: 9
Training loss: 1.879274899170481
Validation loss: 2.618108322373265

Epoch: 5| Step: 10
Training loss: 1.5990895601614177
Validation loss: 2.6632963045913787

Epoch: 213| Step: 0
Training loss: 1.8790767854001302
Validation loss: 2.6301309128052637

Epoch: 5| Step: 1
Training loss: 2.046047596740467
Validation loss: 2.5947417502924575

Epoch: 5| Step: 2
Training loss: 1.764774961849201
Validation loss: 2.5785410948301073

Epoch: 5| Step: 3
Training loss: 1.3810868352429269
Validation loss: 2.568388786694943

Epoch: 5| Step: 4
Training loss: 1.6355142098593505
Validation loss: 2.5668017787979736

Epoch: 5| Step: 5
Training loss: 1.7434787498253397
Validation loss: 2.578772081377979

Epoch: 5| Step: 6
Training loss: 1.4990595412488552
Validation loss: 2.62169626146335

Epoch: 5| Step: 7
Training loss: 1.4200832270020476
Validation loss: 2.6404428668629976

Epoch: 5| Step: 8
Training loss: 1.0908538621952906
Validation loss: 2.6085236729936723

Epoch: 5| Step: 9
Training loss: 1.8274289623809807
Validation loss: 2.6564182129305487

Epoch: 5| Step: 10
Training loss: 1.858386121379315
Validation loss: 2.5913375396890443

Epoch: 214| Step: 0
Training loss: 1.5517644960080659
Validation loss: 2.563963487421168

Epoch: 5| Step: 1
Training loss: 1.452250966375643
Validation loss: 2.5405377712410506

Epoch: 5| Step: 2
Training loss: 1.6802949738399917
Validation loss: 2.5328387246610675

Epoch: 5| Step: 3
Training loss: 1.9000652226747614
Validation loss: 2.5029566590867205

Epoch: 5| Step: 4
Training loss: 1.4633430626762276
Validation loss: 2.5282916920242693

Epoch: 5| Step: 5
Training loss: 1.6987892046426192
Validation loss: 2.5147588165108328

Epoch: 5| Step: 6
Training loss: 1.9720708299416847
Validation loss: 2.544727328108405

Epoch: 5| Step: 7
Training loss: 1.9899232450855453
Validation loss: 2.575086827162787

Epoch: 5| Step: 8
Training loss: 0.9467319833750122
Validation loss: 2.5919554821255506

Epoch: 5| Step: 9
Training loss: 1.7749072467048856
Validation loss: 2.6711433290126827

Epoch: 5| Step: 10
Training loss: 1.472182382288479
Validation loss: 2.698902393966939

Epoch: 215| Step: 0
Training loss: 1.6468002360273577
Validation loss: 2.698110737774768

Epoch: 5| Step: 1
Training loss: 1.9241980802081762
Validation loss: 2.6697469700928593

Epoch: 5| Step: 2
Training loss: 1.561240489677252
Validation loss: 2.6301070096433796

Epoch: 5| Step: 3
Training loss: 1.4739173730701254
Validation loss: 2.591556010083046

Epoch: 5| Step: 4
Training loss: 1.9033152392786095
Validation loss: 2.5614268599216903

Epoch: 5| Step: 5
Training loss: 1.9324359548598267
Validation loss: 2.5558016308423928

Epoch: 5| Step: 6
Training loss: 1.6474722978870686
Validation loss: 2.530809966578635

Epoch: 5| Step: 7
Training loss: 1.2639253765936307
Validation loss: 2.537537814139984

Epoch: 5| Step: 8
Training loss: 1.5690034942685296
Validation loss: 2.539117827842052

Epoch: 5| Step: 9
Training loss: 1.4695897238260487
Validation loss: 2.5368840875890735

Epoch: 5| Step: 10
Training loss: 1.338604723957845
Validation loss: 2.5925989949028017

Epoch: 216| Step: 0
Training loss: 1.8808961985500021
Validation loss: 2.567342375207884

Epoch: 5| Step: 1
Training loss: 1.7514527966244797
Validation loss: 2.587162694296288

Epoch: 5| Step: 2
Training loss: 1.7787882206577617
Validation loss: 2.6033124540795067

Epoch: 5| Step: 3
Training loss: 1.6196619535886456
Validation loss: 2.583694604096974

Epoch: 5| Step: 4
Training loss: 1.3191040196647645
Validation loss: 2.60887971583593

Epoch: 5| Step: 5
Training loss: 1.6227896402748114
Validation loss: 2.576714190764754

Epoch: 5| Step: 6
Training loss: 1.7966764920920872
Validation loss: 2.584201199224829

Epoch: 5| Step: 7
Training loss: 1.3665216622922958
Validation loss: 2.587303401411105

Epoch: 5| Step: 8
Training loss: 1.3224558841291585
Validation loss: 2.560403791335982

Epoch: 5| Step: 9
Training loss: 1.6683367785489043
Validation loss: 2.5443681853697258

Epoch: 5| Step: 10
Training loss: 1.3276299395428472
Validation loss: 2.5544601810439618

Epoch: 217| Step: 0
Training loss: 1.780871033091708
Validation loss: 2.525387449620766

Epoch: 5| Step: 1
Training loss: 1.6460286117143514
Validation loss: 2.5412645860785674

Epoch: 5| Step: 2
Training loss: 1.2897484081574222
Validation loss: 2.5222282208149447

Epoch: 5| Step: 3
Training loss: 1.8303021891249611
Validation loss: 2.531216276190535

Epoch: 5| Step: 4
Training loss: 1.3122081432095087
Validation loss: 2.5586680817548557

Epoch: 5| Step: 5
Training loss: 1.85586177478106
Validation loss: 2.577510094422804

Epoch: 5| Step: 6
Training loss: 1.2481955856054479
Validation loss: 2.566431292861846

Epoch: 5| Step: 7
Training loss: 1.9856430567759982
Validation loss: 2.5620065569650468

Epoch: 5| Step: 8
Training loss: 1.2406926787627046
Validation loss: 2.5743999220447606

Epoch: 5| Step: 9
Training loss: 1.7096034732419167
Validation loss: 2.5734281721889394

Epoch: 5| Step: 10
Training loss: 1.237475304405329
Validation loss: 2.5082853383462966

Epoch: 218| Step: 0
Training loss: 1.9204511252542609
Validation loss: 2.522293333807173

Epoch: 5| Step: 1
Training loss: 1.4111686306007867
Validation loss: 2.503563504919644

Epoch: 5| Step: 2
Training loss: 1.5785124652456157
Validation loss: 2.4953722729788987

Epoch: 5| Step: 3
Training loss: 1.5572559093167861
Validation loss: 2.5055804798817785

Epoch: 5| Step: 4
Training loss: 1.2795470480875852
Validation loss: 2.5489417942518533

Epoch: 5| Step: 5
Training loss: 1.5605594028165792
Validation loss: 2.558469017412039

Epoch: 5| Step: 6
Training loss: 1.58732701958612
Validation loss: 2.587565557271484

Epoch: 5| Step: 7
Training loss: 1.8246517606862052
Validation loss: 2.6049521763217363

Epoch: 5| Step: 8
Training loss: 1.68432247384292
Validation loss: 2.6017715023771846

Epoch: 5| Step: 9
Training loss: 1.4980091552760189
Validation loss: 2.5329205484608504

Epoch: 5| Step: 10
Training loss: 1.299158269468864
Validation loss: 2.467920976465892

Epoch: 219| Step: 0
Training loss: 1.1921598958710629
Validation loss: 2.447897270368411

Epoch: 5| Step: 1
Training loss: 1.7888014823707825
Validation loss: 2.4427884738082297

Epoch: 5| Step: 2
Training loss: 1.6146935292037816
Validation loss: 2.4306084196921294

Epoch: 5| Step: 3
Training loss: 1.614820286580795
Validation loss: 2.4793427396980006

Epoch: 5| Step: 4
Training loss: 1.4350526127491048
Validation loss: 2.545844449295141

Epoch: 5| Step: 5
Training loss: 1.695350330124074
Validation loss: 2.627989128201685

Epoch: 5| Step: 6
Training loss: 1.947358491724402
Validation loss: 2.6927188073271098

Epoch: 5| Step: 7
Training loss: 1.4995035303576085
Validation loss: 2.6779944282505697

Epoch: 5| Step: 8
Training loss: 1.2648851092187445
Validation loss: 2.6060933086824476

Epoch: 5| Step: 9
Training loss: 1.5757909453911265
Validation loss: 2.5629242186479466

Epoch: 5| Step: 10
Training loss: 1.7048379525732942
Validation loss: 2.4821401346972873

Epoch: 220| Step: 0
Training loss: 1.4901529392374848
Validation loss: 2.4305488708997958

Epoch: 5| Step: 1
Training loss: 1.9189697885287014
Validation loss: 2.468142205017956

Epoch: 5| Step: 2
Training loss: 1.648382972430135
Validation loss: 2.4466532441803452

Epoch: 5| Step: 3
Training loss: 1.6916651714800661
Validation loss: 2.4365901053336794

Epoch: 5| Step: 4
Training loss: 1.564638276877273
Validation loss: 2.4709668272122713

Epoch: 5| Step: 5
Training loss: 1.283615812366268
Validation loss: 2.5176537669903003

Epoch: 5| Step: 6
Training loss: 1.234683469062391
Validation loss: 2.6204063607550196

Epoch: 5| Step: 7
Training loss: 1.6886724002156972
Validation loss: 2.6373379660917324

Epoch: 5| Step: 8
Training loss: 1.0574947719580017
Validation loss: 2.677661123959975

Epoch: 5| Step: 9
Training loss: 1.6865780042381326
Validation loss: 2.628701348236656

Epoch: 5| Step: 10
Training loss: 1.776053830400654
Validation loss: 2.611863303039589

Epoch: 221| Step: 0
Training loss: 1.8300555216595389
Validation loss: 2.552741931134231

Epoch: 5| Step: 1
Training loss: 1.5595911797337925
Validation loss: 2.4450040495145866

Epoch: 5| Step: 2
Training loss: 1.1786865636396155
Validation loss: 2.4439646483499327

Epoch: 5| Step: 3
Training loss: 1.5631304422716212
Validation loss: 2.4211348149795837

Epoch: 5| Step: 4
Training loss: 1.3138991573022993
Validation loss: 2.4122783640054206

Epoch: 5| Step: 5
Training loss: 1.9025516592222986
Validation loss: 2.4694059795107077

Epoch: 5| Step: 6
Training loss: 1.6856976526746752
Validation loss: 2.485575694292881

Epoch: 5| Step: 7
Training loss: 1.3757661072365022
Validation loss: 2.5540231578043393

Epoch: 5| Step: 8
Training loss: 1.6754031877498075
Validation loss: 2.5653459365780646

Epoch: 5| Step: 9
Training loss: 1.208325528525216
Validation loss: 2.6049934075731325

Epoch: 5| Step: 10
Training loss: 1.5401261425374768
Validation loss: 2.61739478798719

Epoch: 222| Step: 0
Training loss: 1.6757882213669824
Validation loss: 2.5685480717327356

Epoch: 5| Step: 1
Training loss: 1.6691496552647795
Validation loss: 2.5091653325490193

Epoch: 5| Step: 2
Training loss: 1.4940807854132467
Validation loss: 2.528277740616314

Epoch: 5| Step: 3
Training loss: 1.5560388873813433
Validation loss: 2.4941311665654506

Epoch: 5| Step: 4
Training loss: 1.5313720654472025
Validation loss: 2.4901703406667957

Epoch: 5| Step: 5
Training loss: 1.4824560510769396
Validation loss: 2.5086250142808013

Epoch: 5| Step: 6
Training loss: 1.468091776647715
Validation loss: 2.4912459154828595

Epoch: 5| Step: 7
Training loss: 1.3248999989757988
Validation loss: 2.509755472627381

Epoch: 5| Step: 8
Training loss: 1.4854801280343377
Validation loss: 2.5273984894349075

Epoch: 5| Step: 9
Training loss: 1.2826232993658628
Validation loss: 2.529297184648177

Epoch: 5| Step: 10
Training loss: 1.8212057386058647
Validation loss: 2.540700994974867

Epoch: 223| Step: 0
Training loss: 1.471876509679842
Validation loss: 2.5165584093391358

Epoch: 5| Step: 1
Training loss: 1.609321222980848
Validation loss: 2.5497590306839695

Epoch: 5| Step: 2
Training loss: 1.1862678158289477
Validation loss: 2.5222535132580286

Epoch: 5| Step: 3
Training loss: 1.4379140837977884
Validation loss: 2.531748613302899

Epoch: 5| Step: 4
Training loss: 1.8716014579403655
Validation loss: 2.548509228608079

Epoch: 5| Step: 5
Training loss: 1.8633452270528572
Validation loss: 2.511564164490541

Epoch: 5| Step: 6
Training loss: 1.394854553529512
Validation loss: 2.5126680128489927

Epoch: 5| Step: 7
Training loss: 0.9419680616629819
Validation loss: 2.5242192299401416

Epoch: 5| Step: 8
Training loss: 1.393359763421041
Validation loss: 2.4961280186833266

Epoch: 5| Step: 9
Training loss: 1.7886155415561544
Validation loss: 2.5420437766209245

Epoch: 5| Step: 10
Training loss: 1.2243635061599842
Validation loss: 2.5613084289176533

Epoch: 224| Step: 0
Training loss: 1.3769621287382934
Validation loss: 2.534956587795744

Epoch: 5| Step: 1
Training loss: 1.7606915441794786
Validation loss: 2.6011097156876213

Epoch: 5| Step: 2
Training loss: 1.2549133534555648
Validation loss: 2.5575101497730497

Epoch: 5| Step: 3
Training loss: 1.3614992666281056
Validation loss: 2.5730221810455194

Epoch: 5| Step: 4
Training loss: 1.5351293818716694
Validation loss: 2.555204576667525

Epoch: 5| Step: 5
Training loss: 1.2451321230721863
Validation loss: 2.539840328194956

Epoch: 5| Step: 6
Training loss: 1.4707093662975552
Validation loss: 2.5370001947627285

Epoch: 5| Step: 7
Training loss: 1.4414380904818689
Validation loss: 2.5093340281444827

Epoch: 5| Step: 8
Training loss: 1.3262620313783602
Validation loss: 2.5134342054886893

Epoch: 5| Step: 9
Training loss: 1.9964213541018874
Validation loss: 2.518296599597414

Epoch: 5| Step: 10
Training loss: 1.2773651214584953
Validation loss: 2.4801105830115664

Epoch: 225| Step: 0
Training loss: 1.3050754906754223
Validation loss: 2.520818421629821

Epoch: 5| Step: 1
Training loss: 1.5637345586634888
Validation loss: 2.511709999764946

Epoch: 5| Step: 2
Training loss: 1.5164915144393982
Validation loss: 2.510202216818409

Epoch: 5| Step: 3
Training loss: 1.464980625115606
Validation loss: 2.542260063561651

Epoch: 5| Step: 4
Training loss: 1.2819829565572705
Validation loss: 2.5333900049711096

Epoch: 5| Step: 5
Training loss: 1.5459656788124108
Validation loss: 2.544084829551761

Epoch: 5| Step: 6
Training loss: 1.5834497944347214
Validation loss: 2.558924934591149

Epoch: 5| Step: 7
Training loss: 1.1085405031821953
Validation loss: 2.4907260811629777

Epoch: 5| Step: 8
Training loss: 1.378124631505385
Validation loss: 2.469837595580135

Epoch: 5| Step: 9
Training loss: 1.4438448490841835
Validation loss: 2.4441098028494332

Epoch: 5| Step: 10
Training loss: 1.9894028293821517
Validation loss: 2.446531498638261

Epoch: 226| Step: 0
Training loss: 1.6532084049176414
Validation loss: 2.4981846114489485

Epoch: 5| Step: 1
Training loss: 1.9681508196981168
Validation loss: 2.5054928088494246

Epoch: 5| Step: 2
Training loss: 1.015325355342731
Validation loss: 2.5166229335383608

Epoch: 5| Step: 3
Training loss: 1.215552071391623
Validation loss: 2.526336220576698

Epoch: 5| Step: 4
Training loss: 1.8082231508548257
Validation loss: 2.5339863079193314

Epoch: 5| Step: 5
Training loss: 1.2454827224623428
Validation loss: 2.4603777526054875

Epoch: 5| Step: 6
Training loss: 0.9366963756902077
Validation loss: 2.5183493149508855

Epoch: 5| Step: 7
Training loss: 1.1238340587810687
Validation loss: 2.516786688610401

Epoch: 5| Step: 8
Training loss: 1.5192191384454372
Validation loss: 2.537832943136352

Epoch: 5| Step: 9
Training loss: 1.5700782866913745
Validation loss: 2.552321627861597

Epoch: 5| Step: 10
Training loss: 1.6258497217324455
Validation loss: 2.5730997759157392

Epoch: 227| Step: 0
Training loss: 1.0175464354283144
Validation loss: 2.5146680033362943

Epoch: 5| Step: 1
Training loss: 1.4260965077137502
Validation loss: 2.5311252746075135

Epoch: 5| Step: 2
Training loss: 1.4691441595495986
Validation loss: 2.516450980109958

Epoch: 5| Step: 3
Training loss: 1.5364203841700717
Validation loss: 2.4889692023676235

Epoch: 5| Step: 4
Training loss: 2.1444015046774565
Validation loss: 2.5070921958191024

Epoch: 5| Step: 5
Training loss: 1.4922041168086566
Validation loss: 2.5211986465865897

Epoch: 5| Step: 6
Training loss: 1.2020330056024324
Validation loss: 2.4927326174178446

Epoch: 5| Step: 7
Training loss: 0.9323334746691975
Validation loss: 2.53535691875926

Epoch: 5| Step: 8
Training loss: 1.0904372592002423
Validation loss: 2.53000768278117

Epoch: 5| Step: 9
Training loss: 1.5239219482138995
Validation loss: 2.5619976242557265

Epoch: 5| Step: 10
Training loss: 1.7415294002972241
Validation loss: 2.5811772028619306

Epoch: 228| Step: 0
Training loss: 1.8643863367905482
Validation loss: 2.624262896217079

Epoch: 5| Step: 1
Training loss: 1.705046523457868
Validation loss: 2.583140484786257

Epoch: 5| Step: 2
Training loss: 1.4260989318599704
Validation loss: 2.5660385942580874

Epoch: 5| Step: 3
Training loss: 1.0813431187040736
Validation loss: 2.5686776015087194

Epoch: 5| Step: 4
Training loss: 1.4970734180037506
Validation loss: 2.521497284245898

Epoch: 5| Step: 5
Training loss: 0.8882335881553796
Validation loss: 2.5335335831546617

Epoch: 5| Step: 6
Training loss: 1.2278694430511625
Validation loss: 2.4895406482435587

Epoch: 5| Step: 7
Training loss: 2.027731915249965
Validation loss: 2.50653754848354

Epoch: 5| Step: 8
Training loss: 1.2798997230291644
Validation loss: 2.4824813319681605

Epoch: 5| Step: 9
Training loss: 1.0896644581534791
Validation loss: 2.5449816437124193

Epoch: 5| Step: 10
Training loss: 1.332531116472975
Validation loss: 2.572088408094809

Epoch: 229| Step: 0
Training loss: 1.1874994478726357
Validation loss: 2.6073008706279097

Epoch: 5| Step: 1
Training loss: 1.3283270289527942
Validation loss: 2.6206143410887255

Epoch: 5| Step: 2
Training loss: 1.3608589403710323
Validation loss: 2.61276645839241

Epoch: 5| Step: 3
Training loss: 1.2563618415657345
Validation loss: 2.571042192132567

Epoch: 5| Step: 4
Training loss: 1.6849293378734638
Validation loss: 2.5224203878309477

Epoch: 5| Step: 5
Training loss: 0.8820216594813245
Validation loss: 2.5012899526635537

Epoch: 5| Step: 6
Training loss: 1.3765184514492261
Validation loss: 2.495796661077403

Epoch: 5| Step: 7
Training loss: 1.852389509069447
Validation loss: 2.478611385927825

Epoch: 5| Step: 8
Training loss: 1.5528994298574872
Validation loss: 2.508567625068341

Epoch: 5| Step: 9
Training loss: 1.495378368047046
Validation loss: 2.489437486355862

Epoch: 5| Step: 10
Training loss: 1.4506504770233377
Validation loss: 2.5227741281431033

Epoch: 230| Step: 0
Training loss: 1.9827969501628127
Validation loss: 2.5137756954971384

Epoch: 5| Step: 1
Training loss: 1.0178765794623956
Validation loss: 2.4980736704531457

Epoch: 5| Step: 2
Training loss: 1.5731303425676562
Validation loss: 2.490262576351092

Epoch: 5| Step: 3
Training loss: 1.240831462678509
Validation loss: 2.4897075685064443

Epoch: 5| Step: 4
Training loss: 1.117852766523757
Validation loss: 2.504189076426686

Epoch: 5| Step: 5
Training loss: 1.2422326517596118
Validation loss: 2.5698740056788933

Epoch: 5| Step: 6
Training loss: 1.358231205796702
Validation loss: 2.5717719084951285

Epoch: 5| Step: 7
Training loss: 1.7068506490115078
Validation loss: 2.591468768567792

Epoch: 5| Step: 8
Training loss: 1.3135812483694376
Validation loss: 2.55468450303178

Epoch: 5| Step: 9
Training loss: 1.6825068742631482
Validation loss: 2.5615122752572943

Epoch: 5| Step: 10
Training loss: 0.6896251431455147
Validation loss: 2.54034248493351

Epoch: 231| Step: 0
Training loss: 1.471619663647161
Validation loss: 2.4955168838083837

Epoch: 5| Step: 1
Training loss: 1.4846234565399876
Validation loss: 2.5144994774869147

Epoch: 5| Step: 2
Training loss: 1.5275938799988964
Validation loss: 2.4922520266584396

Epoch: 5| Step: 3
Training loss: 1.8519893106024379
Validation loss: 2.525123573633122

Epoch: 5| Step: 4
Training loss: 1.3472221670554938
Validation loss: 2.518214306733062

Epoch: 5| Step: 5
Training loss: 1.3288356001977466
Validation loss: 2.5328444119874725

Epoch: 5| Step: 6
Training loss: 1.574219128629956
Validation loss: 2.527393370057237

Epoch: 5| Step: 7
Training loss: 1.151877202131761
Validation loss: 2.5397164471156293

Epoch: 5| Step: 8
Training loss: 1.1243738975328657
Validation loss: 2.491270219694983

Epoch: 5| Step: 9
Training loss: 1.2380134942855352
Validation loss: 2.5050750308775642

Epoch: 5| Step: 10
Training loss: 1.1010205714653918
Validation loss: 2.459529279904095

Epoch: 232| Step: 0
Training loss: 1.7348430105195922
Validation loss: 2.463705289536807

Epoch: 5| Step: 1
Training loss: 1.331472553759596
Validation loss: 2.473897887410618

Epoch: 5| Step: 2
Training loss: 1.3629001642244847
Validation loss: 2.4882120287760308

Epoch: 5| Step: 3
Training loss: 1.2791428334918313
Validation loss: 2.5291752274650774

Epoch: 5| Step: 4
Training loss: 0.9142498248264144
Validation loss: 2.567524793317271

Epoch: 5| Step: 5
Training loss: 1.5706188605264817
Validation loss: 2.5680933648280013

Epoch: 5| Step: 6
Training loss: 1.53326112673927
Validation loss: 2.5786810838601064

Epoch: 5| Step: 7
Training loss: 1.3563849351269646
Validation loss: 2.529886449428212

Epoch: 5| Step: 8
Training loss: 1.3854001075309534
Validation loss: 2.4785980930018

Epoch: 5| Step: 9
Training loss: 1.1601958605236902
Validation loss: 2.4361159384180646

Epoch: 5| Step: 10
Training loss: 1.5793202472309404
Validation loss: 2.4036582847175563

Epoch: 233| Step: 0
Training loss: 1.4094298544483477
Validation loss: 2.4174093718344665

Epoch: 5| Step: 1
Training loss: 1.223016216682099
Validation loss: 2.4750182546491595

Epoch: 5| Step: 2
Training loss: 1.726936541471001
Validation loss: 2.500479283074448

Epoch: 5| Step: 3
Training loss: 1.0661391597974388
Validation loss: 2.576792380833883

Epoch: 5| Step: 4
Training loss: 1.4429689119232534
Validation loss: 2.6087578828569327

Epoch: 5| Step: 5
Training loss: 1.5803411050372207
Validation loss: 2.712796809058399

Epoch: 5| Step: 6
Training loss: 1.207468885569786
Validation loss: 2.6722874035598747

Epoch: 5| Step: 7
Training loss: 1.516315499547535
Validation loss: 2.651200176109539

Epoch: 5| Step: 8
Training loss: 1.747389208292637
Validation loss: 2.596175199477588

Epoch: 5| Step: 9
Training loss: 1.262078012627542
Validation loss: 2.5267838780091774

Epoch: 5| Step: 10
Training loss: 0.8752024280179671
Validation loss: 2.4679703016657704

Epoch: 234| Step: 0
Training loss: 1.174943390963839
Validation loss: 2.4173004177257673

Epoch: 5| Step: 1
Training loss: 1.5342843489274234
Validation loss: 2.4031569577089518

Epoch: 5| Step: 2
Training loss: 1.5179702860873034
Validation loss: 2.423080746498193

Epoch: 5| Step: 3
Training loss: 1.2848910721947213
Validation loss: 2.4255354651763605

Epoch: 5| Step: 4
Training loss: 1.9688844786234119
Validation loss: 2.447325170858905

Epoch: 5| Step: 5
Training loss: 1.4518931920672624
Validation loss: 2.506936426140144

Epoch: 5| Step: 6
Training loss: 1.5314696796640228
Validation loss: 2.491357961093496

Epoch: 5| Step: 7
Training loss: 0.7684660379354875
Validation loss: 2.5661926994805357

Epoch: 5| Step: 8
Training loss: 1.3296753753934125
Validation loss: 2.5418521763644297

Epoch: 5| Step: 9
Training loss: 0.9448385705769641
Validation loss: 2.5698056469784376

Epoch: 5| Step: 10
Training loss: 1.2442380187331712
Validation loss: 2.5752944169073846

Epoch: 235| Step: 0
Training loss: 1.5719432808396363
Validation loss: 2.5506370305293196

Epoch: 5| Step: 1
Training loss: 1.2074334422026098
Validation loss: 2.5324115789591803

Epoch: 5| Step: 2
Training loss: 1.160049484940352
Validation loss: 2.573574108874144

Epoch: 5| Step: 3
Training loss: 1.3391550145634357
Validation loss: 2.5226226581134705

Epoch: 5| Step: 4
Training loss: 1.398659459406124
Validation loss: 2.54586308861714

Epoch: 5| Step: 5
Training loss: 1.138517287476994
Validation loss: 2.498480354433104

Epoch: 5| Step: 6
Training loss: 1.1632247572914045
Validation loss: 2.5031538563621356

Epoch: 5| Step: 7
Training loss: 1.6344343827438779
Validation loss: 2.475964028093461

Epoch: 5| Step: 8
Training loss: 1.5033589742099271
Validation loss: 2.4811224805508907

Epoch: 5| Step: 9
Training loss: 1.5513111045292909
Validation loss: 2.495325340769987

Epoch: 5| Step: 10
Training loss: 1.0589312476407142
Validation loss: 2.491806364764695

Epoch: 236| Step: 0
Training loss: 1.8779945620213305
Validation loss: 2.530352174091085

Epoch: 5| Step: 1
Training loss: 1.3960313182121447
Validation loss: 2.5594382754630125

Epoch: 5| Step: 2
Training loss: 1.3027789381374966
Validation loss: 2.585644883288407

Epoch: 5| Step: 3
Training loss: 1.066312960502123
Validation loss: 2.588906403311455

Epoch: 5| Step: 4
Training loss: 1.0650853510580511
Validation loss: 2.5946977852822797

Epoch: 5| Step: 5
Training loss: 1.4267174560353844
Validation loss: 2.557751529626004

Epoch: 5| Step: 6
Training loss: 1.380226000786712
Validation loss: 2.506454930910574

Epoch: 5| Step: 7
Training loss: 0.9081374277943428
Validation loss: 2.4738127444853646

Epoch: 5| Step: 8
Training loss: 1.3123058902163245
Validation loss: 2.453787074800226

Epoch: 5| Step: 9
Training loss: 1.462894617948698
Validation loss: 2.471930719019376

Epoch: 5| Step: 10
Training loss: 1.32885385597279
Validation loss: 2.5006920502684453

Epoch: 237| Step: 0
Training loss: 1.098131938775622
Validation loss: 2.538277011024797

Epoch: 5| Step: 1
Training loss: 1.7119136446894099
Validation loss: 2.5835063597192667

Epoch: 5| Step: 2
Training loss: 1.6667710589458449
Validation loss: 2.587023997126438

Epoch: 5| Step: 3
Training loss: 1.1684496855833666
Validation loss: 2.5088594434014135

Epoch: 5| Step: 4
Training loss: 1.5499603635580732
Validation loss: 2.532186213761301

Epoch: 5| Step: 5
Training loss: 1.6268926016184744
Validation loss: 2.4603115938934015

Epoch: 5| Step: 6
Training loss: 0.8914740681238396
Validation loss: 2.486708210171401

Epoch: 5| Step: 7
Training loss: 0.8674374469334064
Validation loss: 2.484725802520575

Epoch: 5| Step: 8
Training loss: 1.2762598227516146
Validation loss: 2.4337603571371127

Epoch: 5| Step: 9
Training loss: 1.281165887816442
Validation loss: 2.4849771678066546

Epoch: 5| Step: 10
Training loss: 1.2028543737649515
Validation loss: 2.460133828803861

Epoch: 238| Step: 0
Training loss: 1.0481592528285772
Validation loss: 2.4721601637497144

Epoch: 5| Step: 1
Training loss: 1.0568825379592919
Validation loss: 2.534027752990719

Epoch: 5| Step: 2
Training loss: 1.709937582940348
Validation loss: 2.533771743009693

Epoch: 5| Step: 3
Training loss: 1.5471495567728217
Validation loss: 2.5531795582484893

Epoch: 5| Step: 4
Training loss: 1.3417593382980777
Validation loss: 2.5803883521228284

Epoch: 5| Step: 5
Training loss: 1.2199537739047646
Validation loss: 2.577852127187329

Epoch: 5| Step: 6
Training loss: 1.1936714026655342
Validation loss: 2.531573940398659

Epoch: 5| Step: 7
Training loss: 1.0030553157762327
Validation loss: 2.557481650463665

Epoch: 5| Step: 8
Training loss: 1.6555856775932953
Validation loss: 2.5614987019526683

Epoch: 5| Step: 9
Training loss: 1.2092165130937615
Validation loss: 2.5582732951112694

Epoch: 5| Step: 10
Training loss: 1.3026083180349832
Validation loss: 2.5342466349755366

Epoch: 239| Step: 0
Training loss: 1.2604798177656664
Validation loss: 2.51727760780877

Epoch: 5| Step: 1
Training loss: 1.0846892393510918
Validation loss: 2.5442319908951054

Epoch: 5| Step: 2
Training loss: 1.563854164782991
Validation loss: 2.5109303858989636

Epoch: 5| Step: 3
Training loss: 1.378785125340327
Validation loss: 2.533522086109118

Epoch: 5| Step: 4
Training loss: 0.9342842900059928
Validation loss: 2.5247966367688552

Epoch: 5| Step: 5
Training loss: 1.9103211251776622
Validation loss: 2.526928487947979

Epoch: 5| Step: 6
Training loss: 1.0085915799638376
Validation loss: 2.540498101440172

Epoch: 5| Step: 7
Training loss: 1.3185452704587064
Validation loss: 2.5603833684687896

Epoch: 5| Step: 8
Training loss: 1.1723548923813516
Validation loss: 2.5365941743915505

Epoch: 5| Step: 9
Training loss: 1.0925269782185592
Validation loss: 2.553816026384771

Epoch: 5| Step: 10
Training loss: 1.2604274696748858
Validation loss: 2.5255503481240433

Epoch: 240| Step: 0
Training loss: 1.4383530780649636
Validation loss: 2.5210658465955667

Epoch: 5| Step: 1
Training loss: 1.0978396659549905
Validation loss: 2.5114193047928213

Epoch: 5| Step: 2
Training loss: 1.0533526415101468
Validation loss: 2.495365895132364

Epoch: 5| Step: 3
Training loss: 1.0384440481718173
Validation loss: 2.491169011639589

Epoch: 5| Step: 4
Training loss: 1.518464800268729
Validation loss: 2.462915621219154

Epoch: 5| Step: 5
Training loss: 1.4882904613139731
Validation loss: 2.4762506743821806

Epoch: 5| Step: 6
Training loss: 1.0624241521353548
Validation loss: 2.5243553748413445

Epoch: 5| Step: 7
Training loss: 1.0824522996396553
Validation loss: 2.5783315894621217

Epoch: 5| Step: 8
Training loss: 1.4189920227385717
Validation loss: 2.5946247786791163

Epoch: 5| Step: 9
Training loss: 1.4288550282720207
Validation loss: 2.5953838605406583

Epoch: 5| Step: 10
Training loss: 1.476787570168704
Validation loss: 2.571644438132463

Epoch: 241| Step: 0
Training loss: 1.5478735889107076
Validation loss: 2.5603587670931507

Epoch: 5| Step: 1
Training loss: 1.6833677206524338
Validation loss: 2.5202545000456538

Epoch: 5| Step: 2
Training loss: 1.2772113603118347
Validation loss: 2.5443954511985956

Epoch: 5| Step: 3
Training loss: 1.2131257988653446
Validation loss: 2.5330719866709734

Epoch: 5| Step: 4
Training loss: 1.1756613027026472
Validation loss: 2.5266263595706144

Epoch: 5| Step: 5
Training loss: 1.1176880468759585
Validation loss: 2.5314380510573358

Epoch: 5| Step: 6
Training loss: 1.0244058585042977
Validation loss: 2.4946071520470885

Epoch: 5| Step: 7
Training loss: 0.9993037243607524
Validation loss: 2.5140266810894065

Epoch: 5| Step: 8
Training loss: 1.2423648827537421
Validation loss: 2.5246598211022704

Epoch: 5| Step: 9
Training loss: 1.2408341526945101
Validation loss: 2.505841675514589

Epoch: 5| Step: 10
Training loss: 1.4980434532076712
Validation loss: 2.532741229410561

Epoch: 242| Step: 0
Training loss: 1.3682678314000567
Validation loss: 2.528064336028237

Epoch: 5| Step: 1
Training loss: 1.5734297902771641
Validation loss: 2.548004046088434

Epoch: 5| Step: 2
Training loss: 1.3095456433230614
Validation loss: 2.5140860075435927

Epoch: 5| Step: 3
Training loss: 0.9391852807945149
Validation loss: 2.5071312479278123

Epoch: 5| Step: 4
Training loss: 1.2490522129302344
Validation loss: 2.491032481427929

Epoch: 5| Step: 5
Training loss: 1.4638982137149419
Validation loss: 2.5161691539658735

Epoch: 5| Step: 6
Training loss: 1.3230232085731826
Validation loss: 2.5140973161108495

Epoch: 5| Step: 7
Training loss: 1.3498852857665364
Validation loss: 2.592768950485785

Epoch: 5| Step: 8
Training loss: 1.04386885874233
Validation loss: 2.5776084215809787

Epoch: 5| Step: 9
Training loss: 1.0534654106758696
Validation loss: 2.594048547248261

Epoch: 5| Step: 10
Training loss: 1.2703352040494185
Validation loss: 2.5938080189246637

Epoch: 243| Step: 0
Training loss: 1.63004692993006
Validation loss: 2.5718444493859516

Epoch: 5| Step: 1
Training loss: 1.151282698076851
Validation loss: 2.5607397715273668

Epoch: 5| Step: 2
Training loss: 1.4376240552363946
Validation loss: 2.50909911972466

Epoch: 5| Step: 3
Training loss: 1.0361451230050374
Validation loss: 2.5580472218271395

Epoch: 5| Step: 4
Training loss: 0.8721880689104522
Validation loss: 2.516341206118943

Epoch: 5| Step: 5
Training loss: 1.1990254895680028
Validation loss: 2.5276931668488944

Epoch: 5| Step: 6
Training loss: 1.4094670690672753
Validation loss: 2.547474251432575

Epoch: 5| Step: 7
Training loss: 1.5459442421060754
Validation loss: 2.5829563825150306

Epoch: 5| Step: 8
Training loss: 1.4311561753616397
Validation loss: 2.57465446810898

Epoch: 5| Step: 9
Training loss: 1.1458421302226536
Validation loss: 2.526680745730276

Epoch: 5| Step: 10
Training loss: 0.7332988727304453
Validation loss: 2.534501276984406

Epoch: 244| Step: 0
Training loss: 1.1556530519818093
Validation loss: 2.562763542711413

Epoch: 5| Step: 1
Training loss: 0.8729215527733836
Validation loss: 2.4952630829831133

Epoch: 5| Step: 2
Training loss: 1.2392331865658033
Validation loss: 2.4764189480089667

Epoch: 5| Step: 3
Training loss: 1.0566901514429934
Validation loss: 2.487792633326155

Epoch: 5| Step: 4
Training loss: 1.1719551567638293
Validation loss: 2.5340175996887546

Epoch: 5| Step: 5
Training loss: 1.7572284321543419
Validation loss: 2.5224474213548547

Epoch: 5| Step: 6
Training loss: 1.2431448839840364
Validation loss: 2.566563880105078

Epoch: 5| Step: 7
Training loss: 1.4510336973140792
Validation loss: 2.572096211369388

Epoch: 5| Step: 8
Training loss: 1.5884150803788892
Validation loss: 2.5421781864047714

Epoch: 5| Step: 9
Training loss: 1.0984114360294566
Validation loss: 2.5522229221551425

Epoch: 5| Step: 10
Training loss: 0.9227879416520807
Validation loss: 2.5442167444227626

Epoch: 245| Step: 0
Training loss: 0.9117199150019167
Validation loss: 2.591844398611867

Epoch: 5| Step: 1
Training loss: 1.2629774210701938
Validation loss: 2.5589321167924224

Epoch: 5| Step: 2
Training loss: 1.1752991052141681
Validation loss: 2.5536839397881463

Epoch: 5| Step: 3
Training loss: 1.2626371554665838
Validation loss: 2.5658405538503453

Epoch: 5| Step: 4
Training loss: 1.1288132150718622
Validation loss: 2.508731322445409

Epoch: 5| Step: 5
Training loss: 1.3418152653795676
Validation loss: 2.5487936898049286

Epoch: 5| Step: 6
Training loss: 1.412833844457974
Validation loss: 2.507442385334561

Epoch: 5| Step: 7
Training loss: 1.0216120973754996
Validation loss: 2.542757976768068

Epoch: 5| Step: 8
Training loss: 1.2042988586904377
Validation loss: 2.5790974025844435

Epoch: 5| Step: 9
Training loss: 1.7289615034469712
Validation loss: 2.5374415026940116

Epoch: 5| Step: 10
Training loss: 0.917031576754859
Validation loss: 2.5439554674962555

Epoch: 246| Step: 0
Training loss: 0.570428078841227
Validation loss: 2.5818965338643984

Epoch: 5| Step: 1
Training loss: 0.8509515443021857
Validation loss: 2.624633659000629

Epoch: 5| Step: 2
Training loss: 1.5424873470238774
Validation loss: 2.601859999074844

Epoch: 5| Step: 3
Training loss: 1.6586254287547828
Validation loss: 2.6040811149736824

Epoch: 5| Step: 4
Training loss: 1.0975417216545347
Validation loss: 2.5375258755542864

Epoch: 5| Step: 5
Training loss: 1.5617750393377834
Validation loss: 2.5248871455501805

Epoch: 5| Step: 6
Training loss: 1.04561698823859
Validation loss: 2.4921845909171365

Epoch: 5| Step: 7
Training loss: 1.2243738754134883
Validation loss: 2.4909634627318624

Epoch: 5| Step: 8
Training loss: 0.8827517328194006
Validation loss: 2.498915122095162

Epoch: 5| Step: 9
Training loss: 1.1901002824025724
Validation loss: 2.5320426624487395

Epoch: 5| Step: 10
Training loss: 1.467067810311606
Validation loss: 2.4979024917181323

Epoch: 247| Step: 0
Training loss: 0.9862825893050831
Validation loss: 2.5437340265765074

Epoch: 5| Step: 1
Training loss: 1.2244322921021418
Validation loss: 2.588258359154792

Epoch: 5| Step: 2
Training loss: 1.043359690344451
Validation loss: 2.575276710336654

Epoch: 5| Step: 3
Training loss: 1.1204844025016099
Validation loss: 2.6050272253528246

Epoch: 5| Step: 4
Training loss: 1.4035572125468245
Validation loss: 2.604028710105409

Epoch: 5| Step: 5
Training loss: 1.2506570043095704
Validation loss: 2.5862739893534705

Epoch: 5| Step: 6
Training loss: 0.9228587962679453
Validation loss: 2.576557885096966

Epoch: 5| Step: 7
Training loss: 1.4231936868837431
Validation loss: 2.613712747459556

Epoch: 5| Step: 8
Training loss: 1.4363094043315714
Validation loss: 2.559735681725081

Epoch: 5| Step: 9
Training loss: 1.3400620263248595
Validation loss: 2.485008958070926

Epoch: 5| Step: 10
Training loss: 1.2088088985164815
Validation loss: 2.504918314447455

Epoch: 248| Step: 0
Training loss: 0.854770218439628
Validation loss: 2.5006384229217375

Epoch: 5| Step: 1
Training loss: 1.1990664009466236
Validation loss: 2.504150393056422

Epoch: 5| Step: 2
Training loss: 1.31840001926642
Validation loss: 2.5528038636775263

Epoch: 5| Step: 3
Training loss: 1.106152434276228
Validation loss: 2.5935967295442115

Epoch: 5| Step: 4
Training loss: 1.3281390918657274
Validation loss: 2.610398685460927

Epoch: 5| Step: 5
Training loss: 1.5474002601391585
Validation loss: 2.5838770246299685

Epoch: 5| Step: 6
Training loss: 1.1095464869383553
Validation loss: 2.629765391855185

Epoch: 5| Step: 7
Training loss: 1.2037807510583696
Validation loss: 2.6007876121803384

Epoch: 5| Step: 8
Training loss: 1.3007676865612305
Validation loss: 2.527186895908581

Epoch: 5| Step: 9
Training loss: 1.2123093248650127
Validation loss: 2.4992279614177426

Epoch: 5| Step: 10
Training loss: 1.2114040337439822
Validation loss: 2.498958863072266

Epoch: 249| Step: 0
Training loss: 1.235405214373475
Validation loss: 2.4849043751839752

Epoch: 5| Step: 1
Training loss: 1.1007989712785196
Validation loss: 2.4801329476105813

Epoch: 5| Step: 2
Training loss: 1.3110419758027942
Validation loss: 2.5143517403296056

Epoch: 5| Step: 3
Training loss: 1.1346403962204727
Validation loss: 2.5569040266856238

Epoch: 5| Step: 4
Training loss: 1.2509700825603054
Validation loss: 2.591634930507119

Epoch: 5| Step: 5
Training loss: 1.1445559346007559
Validation loss: 2.6057995710110022

Epoch: 5| Step: 6
Training loss: 1.3406713837822462
Validation loss: 2.598880150550543

Epoch: 5| Step: 7
Training loss: 1.5307170173895794
Validation loss: 2.638065381773267

Epoch: 5| Step: 8
Training loss: 0.9313617024857951
Validation loss: 2.6060165919276543

Epoch: 5| Step: 9
Training loss: 1.2158430105028608
Validation loss: 2.5368660270285797

Epoch: 5| Step: 10
Training loss: 0.984545617228046
Validation loss: 2.4820092173719672

Epoch: 250| Step: 0
Training loss: 1.2163758751244025
Validation loss: 2.429249715904231

Epoch: 5| Step: 1
Training loss: 1.3608365149537687
Validation loss: 2.4077820329522712

Epoch: 5| Step: 2
Training loss: 1.597515221226252
Validation loss: 2.412002281710103

Epoch: 5| Step: 3
Training loss: 0.7806084860039159
Validation loss: 2.429050896714481

Epoch: 5| Step: 4
Training loss: 1.4876622792688614
Validation loss: 2.4476690714780265

Epoch: 5| Step: 5
Training loss: 0.7098052262053351
Validation loss: 2.5272730221354798

Epoch: 5| Step: 6
Training loss: 1.000600872713906
Validation loss: 2.571785953409448

Epoch: 5| Step: 7
Training loss: 1.5205488156551914
Validation loss: 2.6103160041459526

Epoch: 5| Step: 8
Training loss: 0.9646394335675471
Validation loss: 2.660638894046213

Epoch: 5| Step: 9
Training loss: 1.3757843034873927
Validation loss: 2.6103085763702807

Epoch: 5| Step: 10
Training loss: 1.0551810910975261
Validation loss: 2.5401119969166017

Epoch: 251| Step: 0
Training loss: 0.759918432877954
Validation loss: 2.5040295684283747

Epoch: 5| Step: 1
Training loss: 1.099171797041721
Validation loss: 2.450293160571085

Epoch: 5| Step: 2
Training loss: 1.411037729617242
Validation loss: 2.472080439650268

Epoch: 5| Step: 3
Training loss: 1.2287041984862037
Validation loss: 2.4930975326776266

Epoch: 5| Step: 4
Training loss: 0.7929098924864314
Validation loss: 2.499862833259408

Epoch: 5| Step: 5
Training loss: 1.303776177191974
Validation loss: 2.566853194882846

Epoch: 5| Step: 6
Training loss: 1.2939306639795833
Validation loss: 2.576364977828409

Epoch: 5| Step: 7
Training loss: 1.5380402864009002
Validation loss: 2.589731923545509

Epoch: 5| Step: 8
Training loss: 1.0700749043067155
Validation loss: 2.575214808554499

Epoch: 5| Step: 9
Training loss: 1.3996130408521976
Validation loss: 2.5430464019696974

Epoch: 5| Step: 10
Training loss: 1.0571258051520622
Validation loss: 2.5295550202406134

Epoch: 252| Step: 0
Training loss: 1.088132108942306
Validation loss: 2.503070825991145

Epoch: 5| Step: 1
Training loss: 1.1106820801432087
Validation loss: 2.4749718101920477

Epoch: 5| Step: 2
Training loss: 1.3258279570768836
Validation loss: 2.4654487249793706

Epoch: 5| Step: 3
Training loss: 1.0926696891727348
Validation loss: 2.4586035345497836

Epoch: 5| Step: 4
Training loss: 0.92915941514976
Validation loss: 2.473932335052584

Epoch: 5| Step: 5
Training loss: 1.1909307312604127
Validation loss: 2.5365701164670726

Epoch: 5| Step: 6
Training loss: 1.052449430215828
Validation loss: 2.5246609198081402

Epoch: 5| Step: 7
Training loss: 1.0552798832808241
Validation loss: 2.575161894899866

Epoch: 5| Step: 8
Training loss: 1.1770452251285783
Validation loss: 2.575261854721568

Epoch: 5| Step: 9
Training loss: 1.3674444338651799
Validation loss: 2.605194834544847

Epoch: 5| Step: 10
Training loss: 1.5938513480480803
Validation loss: 2.593971581994928

Epoch: 253| Step: 0
Training loss: 1.083973982477631
Validation loss: 2.5467262619718505

Epoch: 5| Step: 1
Training loss: 1.299863887043479
Validation loss: 2.518617867854652

Epoch: 5| Step: 2
Training loss: 0.9640906788867121
Validation loss: 2.4972901968294745

Epoch: 5| Step: 3
Training loss: 1.1861482757108155
Validation loss: 2.4989304151612117

Epoch: 5| Step: 4
Training loss: 1.0593284506684264
Validation loss: 2.460770864944119

Epoch: 5| Step: 5
Training loss: 0.5970724657972626
Validation loss: 2.486398704516952

Epoch: 5| Step: 6
Training loss: 1.244793252132582
Validation loss: 2.5268373004929345

Epoch: 5| Step: 7
Training loss: 1.4418461652963823
Validation loss: 2.5405451769688514

Epoch: 5| Step: 8
Training loss: 1.6499961246098176
Validation loss: 2.557016154878452

Epoch: 5| Step: 9
Training loss: 0.9183873946678904
Validation loss: 2.5622580899538994

Epoch: 5| Step: 10
Training loss: 1.1495108745968197
Validation loss: 2.5637934261972415

Epoch: 254| Step: 0
Training loss: 1.3813837288724058
Validation loss: 2.5627173755006254

Epoch: 5| Step: 1
Training loss: 1.3043768050250297
Validation loss: 2.5429475035918014

Epoch: 5| Step: 2
Training loss: 0.9734901316024535
Validation loss: 2.521901448388356

Epoch: 5| Step: 3
Training loss: 1.1911688396109696
Validation loss: 2.493474212001931

Epoch: 5| Step: 4
Training loss: 1.0578454106900927
Validation loss: 2.496029045343077

Epoch: 5| Step: 5
Training loss: 0.8992961926424952
Validation loss: 2.4794498551412767

Epoch: 5| Step: 6
Training loss: 0.961694093910321
Validation loss: 2.5063380295926136

Epoch: 5| Step: 7
Training loss: 1.0450407441879668
Validation loss: 2.5103590205559057

Epoch: 5| Step: 8
Training loss: 1.453988833698071
Validation loss: 2.5247866930839593

Epoch: 5| Step: 9
Training loss: 1.0856532541308739
Validation loss: 2.585550674173352

Epoch: 5| Step: 10
Training loss: 1.310946680702917
Validation loss: 2.5765695582536137

Epoch: 255| Step: 0
Training loss: 1.0367379825650755
Validation loss: 2.55718890043516

Epoch: 5| Step: 1
Training loss: 1.4994248241114394
Validation loss: 2.512815308278521

Epoch: 5| Step: 2
Training loss: 1.1358469867981857
Validation loss: 2.5038435400531274

Epoch: 5| Step: 3
Training loss: 1.2666379383660764
Validation loss: 2.4851122233307645

Epoch: 5| Step: 4
Training loss: 0.9888958433498436
Validation loss: 2.4697162476130887

Epoch: 5| Step: 5
Training loss: 1.1051615365655791
Validation loss: 2.4967154122015414

Epoch: 5| Step: 6
Training loss: 1.0859073662178955
Validation loss: 2.5137049463920365

Epoch: 5| Step: 7
Training loss: 1.1078476936550128
Validation loss: 2.5265239884755384

Epoch: 5| Step: 8
Training loss: 1.1338238640963205
Validation loss: 2.554890769831218

Epoch: 5| Step: 9
Training loss: 1.26708231723439
Validation loss: 2.5833643586567923

Epoch: 5| Step: 10
Training loss: 0.8376074892783154
Validation loss: 2.533134430991631

Epoch: 256| Step: 0
Training loss: 1.1528325482778912
Validation loss: 2.536212542764642

Epoch: 5| Step: 1
Training loss: 1.2354868939120243
Validation loss: 2.504892472383233

Epoch: 5| Step: 2
Training loss: 1.2141655994760558
Validation loss: 2.487840398050759

Epoch: 5| Step: 3
Training loss: 0.950576815415414
Validation loss: 2.4454588214807065

Epoch: 5| Step: 4
Training loss: 1.2960177426301063
Validation loss: 2.491683866382707

Epoch: 5| Step: 5
Training loss: 1.0796383726478347
Validation loss: 2.478184382790348

Epoch: 5| Step: 6
Training loss: 0.9451308903545285
Validation loss: 2.481568550798273

Epoch: 5| Step: 7
Training loss: 1.1195467067378229
Validation loss: 2.4682411592625195

Epoch: 5| Step: 8
Training loss: 0.8959436385679894
Validation loss: 2.4616264164189707

Epoch: 5| Step: 9
Training loss: 1.526517132150352
Validation loss: 2.512398165803933

Epoch: 5| Step: 10
Training loss: 0.7492624470972283
Validation loss: 2.49352769835673

Epoch: 257| Step: 0
Training loss: 1.0978120849330606
Validation loss: 2.5061204448965477

Epoch: 5| Step: 1
Training loss: 0.7292933263217299
Validation loss: 2.515217930484495

Epoch: 5| Step: 2
Training loss: 1.323000502245311
Validation loss: 2.49914811781644

Epoch: 5| Step: 3
Training loss: 0.8267593639709782
Validation loss: 2.5439519877745065

Epoch: 5| Step: 4
Training loss: 1.3880074114505434
Validation loss: 2.5063082968322554

Epoch: 5| Step: 5
Training loss: 1.4246211937136142
Validation loss: 2.4962213313427135

Epoch: 5| Step: 6
Training loss: 1.0757833842337388
Validation loss: 2.4603676881934198

Epoch: 5| Step: 7
Training loss: 0.9845928980335442
Validation loss: 2.4799724133631336

Epoch: 5| Step: 8
Training loss: 0.748845722148928
Validation loss: 2.494903391027799

Epoch: 5| Step: 9
Training loss: 1.5553231018330502
Validation loss: 2.5022427241110465

Epoch: 5| Step: 10
Training loss: 0.8332116435528043
Validation loss: 2.5444886864175835

Epoch: 258| Step: 0
Training loss: 0.6596203948513133
Validation loss: 2.507880788195427

Epoch: 5| Step: 1
Training loss: 1.2596835797229238
Validation loss: 2.537272530311689

Epoch: 5| Step: 2
Training loss: 1.2562072177263581
Validation loss: 2.512436645146567

Epoch: 5| Step: 3
Training loss: 1.3900109982226954
Validation loss: 2.5062879180065165

Epoch: 5| Step: 4
Training loss: 1.011341982172289
Validation loss: 2.521932037229396

Epoch: 5| Step: 5
Training loss: 1.2519584572331843
Validation loss: 2.5209553654367256

Epoch: 5| Step: 6
Training loss: 1.4621303808571964
Validation loss: 2.5199732946028104

Epoch: 5| Step: 7
Training loss: 0.9709477874240332
Validation loss: 2.501645092472679

Epoch: 5| Step: 8
Training loss: 0.7539238804154119
Validation loss: 2.549483743276964

Epoch: 5| Step: 9
Training loss: 1.1702333268198395
Validation loss: 2.5528920152878607

Epoch: 5| Step: 10
Training loss: 0.705834128725789
Validation loss: 2.559348715089852

Epoch: 259| Step: 0
Training loss: 0.918740325669197
Validation loss: 2.5617107423443914

Epoch: 5| Step: 1
Training loss: 1.711453851967546
Validation loss: 2.5153202755617925

Epoch: 5| Step: 2
Training loss: 0.7151619458362405
Validation loss: 2.461350006413453

Epoch: 5| Step: 3
Training loss: 0.8760627695657299
Validation loss: 2.4191743806821386

Epoch: 5| Step: 4
Training loss: 0.7627910793223903
Validation loss: 2.459044614465801

Epoch: 5| Step: 5
Training loss: 1.3332244361674102
Validation loss: 2.427851250242131

Epoch: 5| Step: 6
Training loss: 1.2869684492421667
Validation loss: 2.4439823690260867

Epoch: 5| Step: 7
Training loss: 0.7684626251494121
Validation loss: 2.4692755000066513

Epoch: 5| Step: 8
Training loss: 1.1868517762815245
Validation loss: 2.550268197156324

Epoch: 5| Step: 9
Training loss: 1.12726915182738
Validation loss: 2.572670405220927

Epoch: 5| Step: 10
Training loss: 1.035935766986761
Validation loss: 2.580539508196297

Epoch: 260| Step: 0
Training loss: 1.590651848047453
Validation loss: 2.6063928263157186

Epoch: 5| Step: 1
Training loss: 1.293321267560016
Validation loss: 2.5858558696674643

Epoch: 5| Step: 2
Training loss: 1.2751370188073077
Validation loss: 2.5945606084371025

Epoch: 5| Step: 3
Training loss: 0.7943831734345598
Validation loss: 2.5138276862329523

Epoch: 5| Step: 4
Training loss: 0.8922832511120832
Validation loss: 2.4438854725385144

Epoch: 5| Step: 5
Training loss: 0.9389682081363607
Validation loss: 2.453506778615066

Epoch: 5| Step: 6
Training loss: 0.7651729416930252
Validation loss: 2.4520237937386664

Epoch: 5| Step: 7
Training loss: 1.0998444924106143
Validation loss: 2.4921738999055756

Epoch: 5| Step: 8
Training loss: 0.9757735460525482
Validation loss: 2.506957230213251

Epoch: 5| Step: 9
Training loss: 1.279234021222529
Validation loss: 2.5539237128084564

Epoch: 5| Step: 10
Training loss: 0.9633741731522574
Validation loss: 2.5761889275891385

Epoch: 261| Step: 0
Training loss: 1.0497437073495584
Validation loss: 2.5319426335986788

Epoch: 5| Step: 1
Training loss: 0.5691083188074506
Validation loss: 2.490115490141979

Epoch: 5| Step: 2
Training loss: 1.239157285588526
Validation loss: 2.505858128914485

Epoch: 5| Step: 3
Training loss: 0.9946873328867636
Validation loss: 2.4353089972677724

Epoch: 5| Step: 4
Training loss: 0.6156830135836823
Validation loss: 2.449396840449759

Epoch: 5| Step: 5
Training loss: 1.343974870895294
Validation loss: 2.4334904207931363

Epoch: 5| Step: 6
Training loss: 1.1393658206672468
Validation loss: 2.4639768469532006

Epoch: 5| Step: 7
Training loss: 1.2141063942455173
Validation loss: 2.4765790438860464

Epoch: 5| Step: 8
Training loss: 0.5758060651838027
Validation loss: 2.482878775356012

Epoch: 5| Step: 9
Training loss: 1.5736108557504596
Validation loss: 2.5019134008308423

Epoch: 5| Step: 10
Training loss: 1.1468209547566621
Validation loss: 2.492422526834489

Epoch: 262| Step: 0
Training loss: 0.8061375931442181
Validation loss: 2.4788085663017236

Epoch: 5| Step: 1
Training loss: 0.894035835175152
Validation loss: 2.4656851661869372

Epoch: 5| Step: 2
Training loss: 1.07239902687925
Validation loss: 2.467788176626438

Epoch: 5| Step: 3
Training loss: 1.062724145919836
Validation loss: 2.5019008649620558

Epoch: 5| Step: 4
Training loss: 1.1542327914707817
Validation loss: 2.4800504706917197

Epoch: 5| Step: 5
Training loss: 1.3368845923152308
Validation loss: 2.4541489143077024

Epoch: 5| Step: 6
Training loss: 1.0310464715964511
Validation loss: 2.4548869387034054

Epoch: 5| Step: 7
Training loss: 1.1180260452314414
Validation loss: 2.4708449422594057

Epoch: 5| Step: 8
Training loss: 1.2962942086813531
Validation loss: 2.472469895447081

Epoch: 5| Step: 9
Training loss: 0.8595085387080399
Validation loss: 2.467166431689845

Epoch: 5| Step: 10
Training loss: 0.8972726983541804
Validation loss: 2.4735582941232646

Epoch: 263| Step: 0
Training loss: 1.0632519585514932
Validation loss: 2.4598513835375075

Epoch: 5| Step: 1
Training loss: 0.8291164437296359
Validation loss: 2.47666942774101

Epoch: 5| Step: 2
Training loss: 0.8060034944302366
Validation loss: 2.4653502118622725

Epoch: 5| Step: 3
Training loss: 1.1616041607963508
Validation loss: 2.471221769521249

Epoch: 5| Step: 4
Training loss: 1.3385341461009952
Validation loss: 2.461920806079831

Epoch: 5| Step: 5
Training loss: 0.6976917578193006
Validation loss: 2.4805620982877814

Epoch: 5| Step: 6
Training loss: 0.8496185653014073
Validation loss: 2.4853375980110517

Epoch: 5| Step: 7
Training loss: 1.0339129196627521
Validation loss: 2.4910338460775585

Epoch: 5| Step: 8
Training loss: 1.108190952324262
Validation loss: 2.542585873085471

Epoch: 5| Step: 9
Training loss: 1.3433414104177825
Validation loss: 2.5373630638884315

Epoch: 5| Step: 10
Training loss: 1.1845240697931176
Validation loss: 2.5254617857443393

Epoch: 264| Step: 0
Training loss: 1.1794116474516403
Validation loss: 2.517975886977059

Epoch: 5| Step: 1
Training loss: 1.0251054058307147
Validation loss: 2.4803075992402617

Epoch: 5| Step: 2
Training loss: 1.018047144133575
Validation loss: 2.434806260812871

Epoch: 5| Step: 3
Training loss: 0.912886262164221
Validation loss: 2.4247461496700726

Epoch: 5| Step: 4
Training loss: 1.0443357731262728
Validation loss: 2.3636722516167854

Epoch: 5| Step: 5
Training loss: 1.295008177492105
Validation loss: 2.36259548156863

Epoch: 5| Step: 6
Training loss: 1.0314179486005828
Validation loss: 2.3943633125843875

Epoch: 5| Step: 7
Training loss: 0.6734211452825987
Validation loss: 2.446404745312319

Epoch: 5| Step: 8
Training loss: 0.806610845796597
Validation loss: 2.4658483480953066

Epoch: 5| Step: 9
Training loss: 1.2992429142652866
Validation loss: 2.5011632161534765

Epoch: 5| Step: 10
Training loss: 1.1429138733628856
Validation loss: 2.5045009007579258

Epoch: 265| Step: 0
Training loss: 1.454509608683184
Validation loss: 2.502656579331788

Epoch: 5| Step: 1
Training loss: 0.8658316727023557
Validation loss: 2.491757879735643

Epoch: 5| Step: 2
Training loss: 1.2921400843342548
Validation loss: 2.487772803565146

Epoch: 5| Step: 3
Training loss: 1.0641392796357172
Validation loss: 2.486023266150196

Epoch: 5| Step: 4
Training loss: 0.8126892089614555
Validation loss: 2.4550297249456277

Epoch: 5| Step: 5
Training loss: 0.8546924291046666
Validation loss: 2.4540822366745227

Epoch: 5| Step: 6
Training loss: 0.8421214245865682
Validation loss: 2.4487335535167682

Epoch: 5| Step: 7
Training loss: 0.8618859109056509
Validation loss: 2.5213037057255785

Epoch: 5| Step: 8
Training loss: 1.0309182991860013
Validation loss: 2.492719397739216

Epoch: 5| Step: 9
Training loss: 1.1437308471410152
Validation loss: 2.5416156572710005

Epoch: 5| Step: 10
Training loss: 0.9760631657976927
Validation loss: 2.5144618081452035

Epoch: 266| Step: 0
Training loss: 1.3230046921327503
Validation loss: 2.5593888639907734

Epoch: 5| Step: 1
Training loss: 1.0927126733762205
Validation loss: 2.511596006106937

Epoch: 5| Step: 2
Training loss: 0.9490018055097732
Validation loss: 2.455701045124096

Epoch: 5| Step: 3
Training loss: 0.8202162186567608
Validation loss: 2.446780415262749

Epoch: 5| Step: 4
Training loss: 0.518903453374837
Validation loss: 2.4670312271451267

Epoch: 5| Step: 5
Training loss: 1.0787730826055462
Validation loss: 2.4256848598206737

Epoch: 5| Step: 6
Training loss: 1.2820963041641003
Validation loss: 2.385146835146966

Epoch: 5| Step: 7
Training loss: 1.0839343910034127
Validation loss: 2.4440721625795514

Epoch: 5| Step: 8
Training loss: 1.0421119628251825
Validation loss: 2.430139902634081

Epoch: 5| Step: 9
Training loss: 1.1491326544257854
Validation loss: 2.4939477591743002

Epoch: 5| Step: 10
Training loss: 0.8968719442494935
Validation loss: 2.4888667821161787

Epoch: 267| Step: 0
Training loss: 1.2552166802641893
Validation loss: 2.5392819131685207

Epoch: 5| Step: 1
Training loss: 0.8321717192943843
Validation loss: 2.5531759816514925

Epoch: 5| Step: 2
Training loss: 0.8890124328675045
Validation loss: 2.550629452077789

Epoch: 5| Step: 3
Training loss: 0.5924748229459967
Validation loss: 2.5093298440068357

Epoch: 5| Step: 4
Training loss: 0.9286158499991584
Validation loss: 2.452353273595957

Epoch: 5| Step: 5
Training loss: 1.2640168133414167
Validation loss: 2.464496116421902

Epoch: 5| Step: 6
Training loss: 0.8976007296637427
Validation loss: 2.455971403024203

Epoch: 5| Step: 7
Training loss: 0.8053473572594168
Validation loss: 2.4644094128395104

Epoch: 5| Step: 8
Training loss: 0.9974637352893165
Validation loss: 2.4533737100432007

Epoch: 5| Step: 9
Training loss: 1.5296161264790475
Validation loss: 2.4348290183811563

Epoch: 5| Step: 10
Training loss: 0.9762394790473248
Validation loss: 2.462858964562476

Epoch: 268| Step: 0
Training loss: 1.1662573891228796
Validation loss: 2.485093687481037

Epoch: 5| Step: 1
Training loss: 0.5665113680406808
Validation loss: 2.4908357932238903

Epoch: 5| Step: 2
Training loss: 0.8309788742180317
Validation loss: 2.548212535263041

Epoch: 5| Step: 3
Training loss: 0.9987514270968023
Validation loss: 2.5441290373941436

Epoch: 5| Step: 4
Training loss: 1.3541478473627204
Validation loss: 2.5362304644439604

Epoch: 5| Step: 5
Training loss: 1.011111279605204
Validation loss: 2.5236709726988016

Epoch: 5| Step: 6
Training loss: 0.7411907127948292
Validation loss: 2.5260287292237122

Epoch: 5| Step: 7
Training loss: 1.1832288425052302
Validation loss: 2.4866440046196514

Epoch: 5| Step: 8
Training loss: 1.4254771287114256
Validation loss: 2.4727500098510817

Epoch: 5| Step: 9
Training loss: 0.621256848878929
Validation loss: 2.482524698491458

Epoch: 5| Step: 10
Training loss: 0.8217781778604464
Validation loss: 2.489979719652748

Epoch: 269| Step: 0
Training loss: 0.8316121366610639
Validation loss: 2.4956551533223696

Epoch: 5| Step: 1
Training loss: 0.8433860771047674
Validation loss: 2.497688992679919

Epoch: 5| Step: 2
Training loss: 0.8254442189442055
Validation loss: 2.471943340500489

Epoch: 5| Step: 3
Training loss: 1.09915384780161
Validation loss: 2.51784799267462

Epoch: 5| Step: 4
Training loss: 0.9347837198485163
Validation loss: 2.505902268404983

Epoch: 5| Step: 5
Training loss: 0.7844583246723408
Validation loss: 2.5048849515248732

Epoch: 5| Step: 6
Training loss: 1.051806775496791
Validation loss: 2.454742644451887

Epoch: 5| Step: 7
Training loss: 1.4626508651257735
Validation loss: 2.503134358247634

Epoch: 5| Step: 8
Training loss: 0.9377039369656496
Validation loss: 2.4702042532837454

Epoch: 5| Step: 9
Training loss: 0.8809564710335557
Validation loss: 2.495419846391723

Epoch: 5| Step: 10
Training loss: 1.1423531596104475
Validation loss: 2.4763915020805536

Epoch: 270| Step: 0
Training loss: 1.1428601039269097
Validation loss: 2.505424572215811

Epoch: 5| Step: 1
Training loss: 1.1252700693425246
Validation loss: 2.485339865260198

Epoch: 5| Step: 2
Training loss: 0.7888914621636535
Validation loss: 2.4569351582073122

Epoch: 5| Step: 3
Training loss: 0.8424695153197007
Validation loss: 2.4459732108184182

Epoch: 5| Step: 4
Training loss: 1.0523441985879125
Validation loss: 2.464751581373716

Epoch: 5| Step: 5
Training loss: 0.6247014047698177
Validation loss: 2.4930842234152015

Epoch: 5| Step: 6
Training loss: 1.1643362555453978
Validation loss: 2.481935038289207

Epoch: 5| Step: 7
Training loss: 0.8543500858405295
Validation loss: 2.4809802060898267

Epoch: 5| Step: 8
Training loss: 0.9718412178767319
Validation loss: 2.4545967280828735

Epoch: 5| Step: 9
Training loss: 0.43573161770232094
Validation loss: 2.468159119027603

Epoch: 5| Step: 10
Training loss: 1.5952628939666023
Validation loss: 2.4931620769138476

Epoch: 271| Step: 0
Training loss: 1.6153257406426014
Validation loss: 2.4709686241704163

Epoch: 5| Step: 1
Training loss: 0.8902568390821104
Validation loss: 2.5264940752138076

Epoch: 5| Step: 2
Training loss: 0.9721247741514525
Validation loss: 2.5051972356975183

Epoch: 5| Step: 3
Training loss: 0.828651584690802
Validation loss: 2.4914279690340666

Epoch: 5| Step: 4
Training loss: 1.0760866328713488
Validation loss: 2.4735064654193804

Epoch: 5| Step: 5
Training loss: 1.10244493783829
Validation loss: 2.457740269643767

Epoch: 5| Step: 6
Training loss: 1.0618641577622348
Validation loss: 2.453210522344622

Epoch: 5| Step: 7
Training loss: 0.5680273338023797
Validation loss: 2.4599014864702395

Epoch: 5| Step: 8
Training loss: 0.9283308500899335
Validation loss: 2.4543090161735543

Epoch: 5| Step: 9
Training loss: 0.7958614036509488
Validation loss: 2.4536077796230713

Epoch: 5| Step: 10
Training loss: 0.6599983613398468
Validation loss: 2.4983272514287567

Epoch: 272| Step: 0
Training loss: 0.9296104976276351
Validation loss: 2.4716794842076446

Epoch: 5| Step: 1
Training loss: 0.8976942222007285
Validation loss: 2.4703029858647105

Epoch: 5| Step: 2
Training loss: 1.0951243349144488
Validation loss: 2.483343961827433

Epoch: 5| Step: 3
Training loss: 0.8113285569771584
Validation loss: 2.4625617086231513

Epoch: 5| Step: 4
Training loss: 0.9354723938539184
Validation loss: 2.465701576151219

Epoch: 5| Step: 5
Training loss: 1.313627485375463
Validation loss: 2.4552035419654508

Epoch: 5| Step: 6
Training loss: 0.7951835557773391
Validation loss: 2.5229728736028028

Epoch: 5| Step: 7
Training loss: 1.1676853818563357
Validation loss: 2.4866028141708187

Epoch: 5| Step: 8
Training loss: 0.9643513894296631
Validation loss: 2.490877910980275

Epoch: 5| Step: 9
Training loss: 0.9916325015639408
Validation loss: 2.4655811766894367

Epoch: 5| Step: 10
Training loss: 0.7249091420297465
Validation loss: 2.5202634342290033

Epoch: 273| Step: 0
Training loss: 1.3910438249788466
Validation loss: 2.51924523697397

Epoch: 5| Step: 1
Training loss: 0.503141843620453
Validation loss: 2.509674324694668

Epoch: 5| Step: 2
Training loss: 1.2584710144778886
Validation loss: 2.532813422533427

Epoch: 5| Step: 3
Training loss: 0.5749215735978856
Validation loss: 2.5319068509158265

Epoch: 5| Step: 4
Training loss: 0.9558043420037263
Validation loss: 2.5285988488780067

Epoch: 5| Step: 5
Training loss: 0.7197195645410088
Validation loss: 2.4730533354301047

Epoch: 5| Step: 6
Training loss: 0.9966391472754303
Validation loss: 2.4961947111393066

Epoch: 5| Step: 7
Training loss: 1.0355086392567678
Validation loss: 2.437362886331871

Epoch: 5| Step: 8
Training loss: 1.1771610819477842
Validation loss: 2.4304232127601844

Epoch: 5| Step: 9
Training loss: 0.38099736379352184
Validation loss: 2.488875817639894

Epoch: 5| Step: 10
Training loss: 1.199001677807039
Validation loss: 2.5040836759938285

Epoch: 274| Step: 0
Training loss: 1.0662042894661021
Validation loss: 2.5143720017992433

Epoch: 5| Step: 1
Training loss: 0.853487132140259
Validation loss: 2.58702692442443

Epoch: 5| Step: 2
Training loss: 0.7581928124726337
Validation loss: 2.5763387259920396

Epoch: 5| Step: 3
Training loss: 0.8529681582081076
Validation loss: 2.5608484772275855

Epoch: 5| Step: 4
Training loss: 1.4056170416607103
Validation loss: 2.5743382899662213

Epoch: 5| Step: 5
Training loss: 0.9397044331452422
Validation loss: 2.5272389399211974

Epoch: 5| Step: 6
Training loss: 1.1900532027781383
Validation loss: 2.5110239070536826

Epoch: 5| Step: 7
Training loss: 0.7745351227737948
Validation loss: 2.445167305237069

Epoch: 5| Step: 8
Training loss: 0.9513664594885167
Validation loss: 2.455221403408075

Epoch: 5| Step: 9
Training loss: 0.8090617718919857
Validation loss: 2.439590851003725

Epoch: 5| Step: 10
Training loss: 0.8704670246677559
Validation loss: 2.4567798950437525

Epoch: 275| Step: 0
Training loss: 0.8345762203051195
Validation loss: 2.465115266240838

Epoch: 5| Step: 1
Training loss: 0.8769687574730711
Validation loss: 2.477090880327987

Epoch: 5| Step: 2
Training loss: 0.9317312136578846
Validation loss: 2.5006778321110965

Epoch: 5| Step: 3
Training loss: 0.7311056695640272
Validation loss: 2.514067984090728

Epoch: 5| Step: 4
Training loss: 1.5231499816323508
Validation loss: 2.5183147923139972

Epoch: 5| Step: 5
Training loss: 1.1571564600832887
Validation loss: 2.540621865699224

Epoch: 5| Step: 6
Training loss: 0.9607306156907868
Validation loss: 2.485131922677572

Epoch: 5| Step: 7
Training loss: 1.0626576811527442
Validation loss: 2.519556055171829

Epoch: 5| Step: 8
Training loss: 0.6169291329715465
Validation loss: 2.502845654082331

Epoch: 5| Step: 9
Training loss: 0.8079782253249045
Validation loss: 2.4560201686466443

Epoch: 5| Step: 10
Training loss: 0.7495623742298054
Validation loss: 2.4259655685774937

Epoch: 276| Step: 0
Training loss: 1.1854685925651658
Validation loss: 2.444017785867197

Epoch: 5| Step: 1
Training loss: 0.8004942589052992
Validation loss: 2.4329064319922193

Epoch: 5| Step: 2
Training loss: 0.8739216153809317
Validation loss: 2.477085402901554

Epoch: 5| Step: 3
Training loss: 0.7771136072583729
Validation loss: 2.500720043471117

Epoch: 5| Step: 4
Training loss: 0.735388725729767
Validation loss: 2.5208207017145967

Epoch: 5| Step: 5
Training loss: 1.104972970813188
Validation loss: 2.5061869450934053

Epoch: 5| Step: 6
Training loss: 0.8275984763703442
Validation loss: 2.54872490351649

Epoch: 5| Step: 7
Training loss: 0.9375491447283298
Validation loss: 2.5002315593455617

Epoch: 5| Step: 8
Training loss: 1.4462267484254772
Validation loss: 2.4950349551972106

Epoch: 5| Step: 9
Training loss: 0.8399630439666959
Validation loss: 2.505390993477982

Epoch: 5| Step: 10
Training loss: 0.5933573579031918
Validation loss: 2.4966222607399726

Epoch: 277| Step: 0
Training loss: 0.7404036517082565
Validation loss: 2.4802689852739013

Epoch: 5| Step: 1
Training loss: 0.8766043464341398
Validation loss: 2.511603748269372

Epoch: 5| Step: 2
Training loss: 0.7151930325704245
Validation loss: 2.506511045513652

Epoch: 5| Step: 3
Training loss: 1.5173858167245649
Validation loss: 2.497157816738273

Epoch: 5| Step: 4
Training loss: 0.7090037529769374
Validation loss: 2.4825202915479427

Epoch: 5| Step: 5
Training loss: 0.9174490573575308
Validation loss: 2.4776909719800284

Epoch: 5| Step: 6
Training loss: 0.9156688041754641
Validation loss: 2.5158537420123093

Epoch: 5| Step: 7
Training loss: 1.0232573488979542
Validation loss: 2.5183544949598224

Epoch: 5| Step: 8
Training loss: 0.8033815545597737
Validation loss: 2.5413865920719565

Epoch: 5| Step: 9
Training loss: 0.8703265040039728
Validation loss: 2.5524612686014683

Epoch: 5| Step: 10
Training loss: 1.106807154639156
Validation loss: 2.568015638650561

Epoch: 278| Step: 0
Training loss: 1.2504449529265083
Validation loss: 2.5768751588376224

Epoch: 5| Step: 1
Training loss: 1.0164717445705886
Validation loss: 2.5169814731575846

Epoch: 5| Step: 2
Training loss: 0.8243987623583015
Validation loss: 2.5086989662197032

Epoch: 5| Step: 3
Training loss: 0.822436643380714
Validation loss: 2.524709149681407

Epoch: 5| Step: 4
Training loss: 0.6492839711614157
Validation loss: 2.4540625304436583

Epoch: 5| Step: 5
Training loss: 1.0992507485271557
Validation loss: 2.4595965316661355

Epoch: 5| Step: 6
Training loss: 0.8706983686807548
Validation loss: 2.4381672272282615

Epoch: 5| Step: 7
Training loss: 0.6508431907750679
Validation loss: 2.447968750563003

Epoch: 5| Step: 8
Training loss: 0.9410876609558392
Validation loss: 2.474052878334338

Epoch: 5| Step: 9
Training loss: 1.2117527832131507
Validation loss: 2.486551091370421

Epoch: 5| Step: 10
Training loss: 0.8815182676580814
Validation loss: 2.4938385952148585

Epoch: 279| Step: 0
Training loss: 1.5786295924478222
Validation loss: 2.5378598579413922

Epoch: 5| Step: 1
Training loss: 1.0528768750848505
Validation loss: 2.5231930092255705

Epoch: 5| Step: 2
Training loss: 0.8930202866414685
Validation loss: 2.5169772105735095

Epoch: 5| Step: 3
Training loss: 0.8216983895500403
Validation loss: 2.507609316236554

Epoch: 5| Step: 4
Training loss: 0.6746549978550732
Validation loss: 2.4690054318327963

Epoch: 5| Step: 5
Training loss: 0.45420537602826333
Validation loss: 2.5108021664099116

Epoch: 5| Step: 6
Training loss: 0.9356864235795166
Validation loss: 2.509394167903232

Epoch: 5| Step: 7
Training loss: 0.7701050608659985
Validation loss: 2.518694978922863

Epoch: 5| Step: 8
Training loss: 0.7778905354425345
Validation loss: 2.4929303334428687

Epoch: 5| Step: 9
Training loss: 0.9566002322820963
Validation loss: 2.4849139213546336

Epoch: 5| Step: 10
Training loss: 0.9384759273784922
Validation loss: 2.507105382658718

Epoch: 280| Step: 0
Training loss: 0.6028905056899801
Validation loss: 2.4976302451818686

Epoch: 5| Step: 1
Training loss: 1.3042349573035295
Validation loss: 2.4848331837150837

Epoch: 5| Step: 2
Training loss: 0.9027443198989583
Validation loss: 2.4571293955175824

Epoch: 5| Step: 3
Training loss: 0.9387469264461423
Validation loss: 2.4511269214617806

Epoch: 5| Step: 4
Training loss: 0.8936344298754836
Validation loss: 2.4454995979180625

Epoch: 5| Step: 5
Training loss: 1.0626695161116755
Validation loss: 2.4396826409023165

Epoch: 5| Step: 6
Training loss: 1.1130149656696564
Validation loss: 2.489517360009971

Epoch: 5| Step: 7
Training loss: 0.7154634218336201
Validation loss: 2.476463245750016

Epoch: 5| Step: 8
Training loss: 0.4530539950281478
Validation loss: 2.4921689838559047

Epoch: 5| Step: 9
Training loss: 0.8733436370258775
Validation loss: 2.5204120881670438

Epoch: 5| Step: 10
Training loss: 0.994047958761744
Validation loss: 2.515455595546947

Epoch: 281| Step: 0
Training loss: 0.6842314225526208
Validation loss: 2.5299035809330066

Epoch: 5| Step: 1
Training loss: 0.7056163730550116
Validation loss: 2.5676910280663185

Epoch: 5| Step: 2
Training loss: 0.6305350778095514
Validation loss: 2.5028856692011696

Epoch: 5| Step: 3
Training loss: 1.0138885913192335
Validation loss: 2.5006240055706095

Epoch: 5| Step: 4
Training loss: 1.1550578595816416
Validation loss: 2.514424564420913

Epoch: 5| Step: 5
Training loss: 1.0403013373269079
Validation loss: 2.5045393002959373

Epoch: 5| Step: 6
Training loss: 0.9629993802877712
Validation loss: 2.488435828237526

Epoch: 5| Step: 7
Training loss: 1.2702250770807126
Validation loss: 2.4852566441020123

Epoch: 5| Step: 8
Training loss: 0.8421991719019217
Validation loss: 2.4765816980194097

Epoch: 5| Step: 9
Training loss: 0.6959165242617938
Validation loss: 2.467369921796275

Epoch: 5| Step: 10
Training loss: 0.6791336170494515
Validation loss: 2.489924598260873

Epoch: 282| Step: 0
Training loss: 0.8362821777493695
Validation loss: 2.4605045441038498

Epoch: 5| Step: 1
Training loss: 1.1494447093109257
Validation loss: 2.4809035776861514

Epoch: 5| Step: 2
Training loss: 1.3140921245778172
Validation loss: 2.5187391794641454

Epoch: 5| Step: 3
Training loss: 0.9960550637305992
Validation loss: 2.540845641199041

Epoch: 5| Step: 4
Training loss: 0.6960826851493052
Validation loss: 2.501919600088828

Epoch: 5| Step: 5
Training loss: 0.6770850157105501
Validation loss: 2.519361567874618

Epoch: 5| Step: 6
Training loss: 0.8889975820750942
Validation loss: 2.517543474173073

Epoch: 5| Step: 7
Training loss: 0.5116729133402748
Validation loss: 2.5113791229747426

Epoch: 5| Step: 8
Training loss: 0.9314489267366711
Validation loss: 2.505604574451295

Epoch: 5| Step: 9
Training loss: 0.8490868024608854
Validation loss: 2.529722945438202

Epoch: 5| Step: 10
Training loss: 0.7754794821764218
Validation loss: 2.5085645121946265

Epoch: 283| Step: 0
Training loss: 0.43244891198464985
Validation loss: 2.5064210790729766

Epoch: 5| Step: 1
Training loss: 1.0174096493358846
Validation loss: 2.541092917971886

Epoch: 5| Step: 2
Training loss: 0.7190234866411411
Validation loss: 2.5087624346327155

Epoch: 5| Step: 3
Training loss: 0.9290436510726768
Validation loss: 2.5162127916426655

Epoch: 5| Step: 4
Training loss: 0.276510437413139
Validation loss: 2.495226655118458

Epoch: 5| Step: 5
Training loss: 1.3468187023885496
Validation loss: 2.5262015356927767

Epoch: 5| Step: 6
Training loss: 1.076162459372093
Validation loss: 2.550154968031105

Epoch: 5| Step: 7
Training loss: 1.002498783006191
Validation loss: 2.534609672762312

Epoch: 5| Step: 8
Training loss: 0.9851441179174354
Validation loss: 2.5213318473119064

Epoch: 5| Step: 9
Training loss: 0.7641458430793115
Validation loss: 2.5117945715056678

Epoch: 5| Step: 10
Training loss: 0.8437418054253398
Validation loss: 2.4944348484819465

Epoch: 284| Step: 0
Training loss: 0.878455627210946
Validation loss: 2.4836079899472896

Epoch: 5| Step: 1
Training loss: 1.0656320745059913
Validation loss: 2.5232284628469737

Epoch: 5| Step: 2
Training loss: 0.5024268738597764
Validation loss: 2.5186402187852286

Epoch: 5| Step: 3
Training loss: 0.9469518082691937
Validation loss: 2.5044217557679755

Epoch: 5| Step: 4
Training loss: 1.1116419451327242
Validation loss: 2.508538563595049

Epoch: 5| Step: 5
Training loss: 0.6774121708615357
Validation loss: 2.4705445141059097

Epoch: 5| Step: 6
Training loss: 0.7893999718878939
Validation loss: 2.47645717221023

Epoch: 5| Step: 7
Training loss: 1.0462234519224558
Validation loss: 2.5011449878543783

Epoch: 5| Step: 8
Training loss: 1.0039602183519345
Validation loss: 2.4615706611595733

Epoch: 5| Step: 9
Training loss: 0.8680943738946877
Validation loss: 2.475436359503127

Epoch: 5| Step: 10
Training loss: 0.7724425727214068
Validation loss: 2.5187511348312137

Epoch: 285| Step: 0
Training loss: 0.5680940146227115
Validation loss: 2.521250211747709

Epoch: 5| Step: 1
Training loss: 0.7282458258318353
Validation loss: 2.5424156806736686

Epoch: 5| Step: 2
Training loss: 0.8250929187697797
Validation loss: 2.5700580775087345

Epoch: 5| Step: 3
Training loss: 1.1081577661514184
Validation loss: 2.570170455734492

Epoch: 5| Step: 4
Training loss: 1.1726671720297286
Validation loss: 2.5460228484928837

Epoch: 5| Step: 5
Training loss: 0.6027181844458945
Validation loss: 2.5360463331190197

Epoch: 5| Step: 6
Training loss: 1.0356162146942145
Validation loss: 2.5169167951797324

Epoch: 5| Step: 7
Training loss: 0.5698363001310034
Validation loss: 2.5201747196290905

Epoch: 5| Step: 8
Training loss: 0.9020396459159987
Validation loss: 2.4947265761057404

Epoch: 5| Step: 9
Training loss: 1.2743042880313862
Validation loss: 2.4324423324853015

Epoch: 5| Step: 10
Training loss: 0.690189022869132
Validation loss: 2.508016588285765

Epoch: 286| Step: 0
Training loss: 0.7594861690952018
Validation loss: 2.5000694593399144

Epoch: 5| Step: 1
Training loss: 0.707522774656666
Validation loss: 2.509295170207027

Epoch: 5| Step: 2
Training loss: 0.8005085922890415
Validation loss: 2.5443471325161418

Epoch: 5| Step: 3
Training loss: 0.8446216672476199
Validation loss: 2.6271667249683617

Epoch: 5| Step: 4
Training loss: 0.9781275605969535
Validation loss: 2.573349435582578

Epoch: 5| Step: 5
Training loss: 0.8560906505580828
Validation loss: 2.531076300234247

Epoch: 5| Step: 6
Training loss: 0.8795006331636146
Validation loss: 2.491873410538287

Epoch: 5| Step: 7
Training loss: 0.8057009786760159
Validation loss: 2.5100869454248236

Epoch: 5| Step: 8
Training loss: 0.6511958181353565
Validation loss: 2.4904471054113415

Epoch: 5| Step: 9
Training loss: 1.3734230188294183
Validation loss: 2.4316874674564044

Epoch: 5| Step: 10
Training loss: 0.9237746047793981
Validation loss: 2.4501705579508912

Epoch: 287| Step: 0
Training loss: 0.9737015281923824
Validation loss: 2.5020326923517775

Epoch: 5| Step: 1
Training loss: 1.311209634717789
Validation loss: 2.4556863033956007

Epoch: 5| Step: 2
Training loss: 0.9533556987288625
Validation loss: 2.442365067097514

Epoch: 5| Step: 3
Training loss: 0.8417000770232528
Validation loss: 2.479187423882502

Epoch: 5| Step: 4
Training loss: 0.6730845010771009
Validation loss: 2.4593720665314427

Epoch: 5| Step: 5
Training loss: 0.8988896766220883
Validation loss: 2.442119609742635

Epoch: 5| Step: 6
Training loss: 0.9890459441958319
Validation loss: 2.518182351300886

Epoch: 5| Step: 7
Training loss: 0.8878129434231997
Validation loss: 2.465868983154421

Epoch: 5| Step: 8
Training loss: 0.7406353833078311
Validation loss: 2.4616975208720833

Epoch: 5| Step: 9
Training loss: 0.5836876463007088
Validation loss: 2.488144854977769

Epoch: 5| Step: 10
Training loss: 0.4773044594984964
Validation loss: 2.4760379015025036

Epoch: 288| Step: 0
Training loss: 0.9607871333382744
Validation loss: 2.5059392976100767

Epoch: 5| Step: 1
Training loss: 0.8530222429145933
Validation loss: 2.5242078570323656

Epoch: 5| Step: 2
Training loss: 0.9369320102520897
Validation loss: 2.484414256477046

Epoch: 5| Step: 3
Training loss: 0.5016833816269937
Validation loss: 2.4714253577634375

Epoch: 5| Step: 4
Training loss: 0.6794223926090328
Validation loss: 2.5226169375791474

Epoch: 5| Step: 5
Training loss: 0.8927026907981025
Validation loss: 2.5019409766520306

Epoch: 5| Step: 6
Training loss: 0.5215820621046933
Validation loss: 2.503321675407718

Epoch: 5| Step: 7
Training loss: 0.967119814179051
Validation loss: 2.5055090164139324

Epoch: 5| Step: 8
Training loss: 0.942053544626471
Validation loss: 2.50290095593132

Epoch: 5| Step: 9
Training loss: 0.8017624217190136
Validation loss: 2.504216716253163

Epoch: 5| Step: 10
Training loss: 1.3626177903101764
Validation loss: 2.516246025255471

Epoch: 289| Step: 0
Training loss: 0.7592189361578318
Validation loss: 2.51901910296436

Epoch: 5| Step: 1
Training loss: 0.8181983953299367
Validation loss: 2.48754639580478

Epoch: 5| Step: 2
Training loss: 0.8289466236863261
Validation loss: 2.5092879102971826

Epoch: 5| Step: 3
Training loss: 1.232960965459863
Validation loss: 2.5467320335450063

Epoch: 5| Step: 4
Training loss: 0.6101709449551737
Validation loss: 2.49240902573756

Epoch: 5| Step: 5
Training loss: 0.9699365978068393
Validation loss: 2.542402189945413

Epoch: 5| Step: 6
Training loss: 1.0287937621290904
Validation loss: 2.51616305909867

Epoch: 5| Step: 7
Training loss: 0.8128477599442623
Validation loss: 2.502817406043821

Epoch: 5| Step: 8
Training loss: 0.5959400643832118
Validation loss: 2.489071364004904

Epoch: 5| Step: 9
Training loss: 0.8635475127816419
Validation loss: 2.493746787868013

Epoch: 5| Step: 10
Training loss: 0.8608264110640145
Validation loss: 2.492605079664696

Epoch: 290| Step: 0
Training loss: 0.45450483893870497
Validation loss: 2.4847840900850198

Epoch: 5| Step: 1
Training loss: 0.8833198102479722
Validation loss: 2.4795362028743444

Epoch: 5| Step: 2
Training loss: 0.9970161804389934
Validation loss: 2.4943657564019013

Epoch: 5| Step: 3
Training loss: 1.1835831745543939
Validation loss: 2.52105356561393

Epoch: 5| Step: 4
Training loss: 0.6662308018120956
Validation loss: 2.5058647092211377

Epoch: 5| Step: 5
Training loss: 0.8756178990252448
Validation loss: 2.55489097252301

Epoch: 5| Step: 6
Training loss: 0.5963985448813772
Validation loss: 2.5081263714315827

Epoch: 5| Step: 7
Training loss: 0.8094234540420352
Validation loss: 2.5280457814747885

Epoch: 5| Step: 8
Training loss: 1.238422710629756
Validation loss: 2.551445102976883

Epoch: 5| Step: 9
Training loss: 0.7503665584614913
Validation loss: 2.5197501784829632

Epoch: 5| Step: 10
Training loss: 0.6261492653118436
Validation loss: 2.513578495203085

Epoch: 291| Step: 0
Training loss: 0.9081330959434387
Validation loss: 2.5331643088510103

Epoch: 5| Step: 1
Training loss: 0.9768646993356375
Validation loss: 2.483300363911328

Epoch: 5| Step: 2
Training loss: 0.6233217117514758
Validation loss: 2.521695573223836

Epoch: 5| Step: 3
Training loss: 1.2905368580866174
Validation loss: 2.49792174125195

Epoch: 5| Step: 4
Training loss: 0.7169153598908141
Validation loss: 2.5121131617540375

Epoch: 5| Step: 5
Training loss: 0.8384134222178359
Validation loss: 2.5400835738976175

Epoch: 5| Step: 6
Training loss: 0.8188091489669286
Validation loss: 2.5063499050048343

Epoch: 5| Step: 7
Training loss: 0.7166931742563869
Validation loss: 2.4994028670369994

Epoch: 5| Step: 8
Training loss: 0.6177549288856803
Validation loss: 2.5078850825961574

Epoch: 5| Step: 9
Training loss: 1.0509164148915755
Validation loss: 2.486171696772674

Epoch: 5| Step: 10
Training loss: 0.5014351276035857
Validation loss: 2.492865955976119

Epoch: 292| Step: 0
Training loss: 0.5837122560670137
Validation loss: 2.5031957023385294

Epoch: 5| Step: 1
Training loss: 0.6041608651200536
Validation loss: 2.511261614799677

Epoch: 5| Step: 2
Training loss: 0.8939151557968154
Validation loss: 2.5097329133547692

Epoch: 5| Step: 3
Training loss: 1.1905044895169177
Validation loss: 2.531785768245969

Epoch: 5| Step: 4
Training loss: 0.7805235727967127
Validation loss: 2.506028463466787

Epoch: 5| Step: 5
Training loss: 0.9414248326157248
Validation loss: 2.5321383267677056

Epoch: 5| Step: 6
Training loss: 0.6996631169298014
Validation loss: 2.5423551215760676

Epoch: 5| Step: 7
Training loss: 0.9685879541043074
Validation loss: 2.5256067363133483

Epoch: 5| Step: 8
Training loss: 0.6661517096512062
Validation loss: 2.5320051356400275

Epoch: 5| Step: 9
Training loss: 0.9923935923960305
Validation loss: 2.522611017335838

Epoch: 5| Step: 10
Training loss: 0.8023667062003006
Validation loss: 2.537532757650148

Epoch: 293| Step: 0
Training loss: 1.1354387030373336
Validation loss: 2.519584388741711

Epoch: 5| Step: 1
Training loss: 0.5686443964412509
Validation loss: 2.4938059398771117

Epoch: 5| Step: 2
Training loss: 0.7173761838486763
Validation loss: 2.4886087882114643

Epoch: 5| Step: 3
Training loss: 0.9388633986655139
Validation loss: 2.5121673156391857

Epoch: 5| Step: 4
Training loss: 0.6888085829506868
Validation loss: 2.4690332661689443

Epoch: 5| Step: 5
Training loss: 1.0909489322741923
Validation loss: 2.500136913119108

Epoch: 5| Step: 6
Training loss: 0.8386941538153846
Validation loss: 2.5050880042167982

Epoch: 5| Step: 7
Training loss: 0.769678789121252
Validation loss: 2.5127703240513406

Epoch: 5| Step: 8
Training loss: 0.7811746179452606
Validation loss: 2.5102942025874446

Epoch: 5| Step: 9
Training loss: 0.9673054908182516
Validation loss: 2.4910947461508655

Epoch: 5| Step: 10
Training loss: 0.31018776193039316
Validation loss: 2.51462972074704

Epoch: 294| Step: 0
Training loss: 0.7191945649928231
Validation loss: 2.504333270267934

Epoch: 5| Step: 1
Training loss: 0.6471428413400134
Validation loss: 2.46856653568416

Epoch: 5| Step: 2
Training loss: 1.305197381990749
Validation loss: 2.4681801897079914

Epoch: 5| Step: 3
Training loss: 0.8901013960031624
Validation loss: 2.499272016955256

Epoch: 5| Step: 4
Training loss: 0.541279697352338
Validation loss: 2.501674049567512

Epoch: 5| Step: 5
Training loss: 0.6659592859149638
Validation loss: 2.4818629435494732

Epoch: 5| Step: 6
Training loss: 0.9664270791944571
Validation loss: 2.5064974520534045

Epoch: 5| Step: 7
Training loss: 0.8030505520643376
Validation loss: 2.4439375276570776

Epoch: 5| Step: 8
Training loss: 0.5438538616564127
Validation loss: 2.5163702019306284

Epoch: 5| Step: 9
Training loss: 1.0021432915486486
Validation loss: 2.502714434952352

Epoch: 5| Step: 10
Training loss: 0.7595082217180201
Validation loss: 2.476776971908548

Epoch: 295| Step: 0
Training loss: 0.7358528849883257
Validation loss: 2.5085119238709273

Epoch: 5| Step: 1
Training loss: 0.6172297258056404
Validation loss: 2.484221439436031

Epoch: 5| Step: 2
Training loss: 0.7813235820450908
Validation loss: 2.472044147212202

Epoch: 5| Step: 3
Training loss: 0.8679111657324662
Validation loss: 2.50934763688772

Epoch: 5| Step: 4
Training loss: 0.5156289880771731
Validation loss: 2.5177383905809276

Epoch: 5| Step: 5
Training loss: 0.8954893420195936
Validation loss: 2.5121537185988716

Epoch: 5| Step: 6
Training loss: 0.9839375447286147
Validation loss: 2.4991288287461804

Epoch: 5| Step: 7
Training loss: 0.6877303387845114
Validation loss: 2.497138252812911

Epoch: 5| Step: 8
Training loss: 0.6636000425410012
Validation loss: 2.518303316390963

Epoch: 5| Step: 9
Training loss: 0.8948363737425435
Validation loss: 2.5200357018464863

Epoch: 5| Step: 10
Training loss: 1.2814305341112902
Validation loss: 2.545714058839552

Epoch: 296| Step: 0
Training loss: 0.6974576370473095
Validation loss: 2.4929468376073913

Epoch: 5| Step: 1
Training loss: 0.6812815991343866
Validation loss: 2.51815149904535

Epoch: 5| Step: 2
Training loss: 0.9179691720515153
Validation loss: 2.52691860134969

Epoch: 5| Step: 3
Training loss: 0.7570157139052982
Validation loss: 2.544843357491657

Epoch: 5| Step: 4
Training loss: 0.6159165248850902
Validation loss: 2.533554503758065

Epoch: 5| Step: 5
Training loss: 0.8872731026215726
Validation loss: 2.4798758045713227

Epoch: 5| Step: 6
Training loss: 0.6303056111146064
Validation loss: 2.5168538552910693

Epoch: 5| Step: 7
Training loss: 0.7506756123703696
Validation loss: 2.494611055146424

Epoch: 5| Step: 8
Training loss: 0.9194856488143517
Validation loss: 2.504744152200427

Epoch: 5| Step: 9
Training loss: 1.303647569123577
Validation loss: 2.4715183635347433

Epoch: 5| Step: 10
Training loss: 0.6567658712838446
Validation loss: 2.479507590023194

Epoch: 297| Step: 0
Training loss: 0.5476800170617097
Validation loss: 2.503283336048311

Epoch: 5| Step: 1
Training loss: 0.774097854305852
Validation loss: 2.545944306535671

Epoch: 5| Step: 2
Training loss: 0.6222821747709709
Validation loss: 2.513891221980192

Epoch: 5| Step: 3
Training loss: 1.2904352450406282
Validation loss: 2.4931267988202133

Epoch: 5| Step: 4
Training loss: 0.4441305503272929
Validation loss: 2.5373758600180985

Epoch: 5| Step: 5
Training loss: 0.43213425110350995
Validation loss: 2.55302331794027

Epoch: 5| Step: 6
Training loss: 0.6851944846399494
Validation loss: 2.569775866421382

Epoch: 5| Step: 7
Training loss: 1.0502964872747318
Validation loss: 2.5337930289227963

Epoch: 5| Step: 8
Training loss: 1.0234987080448943
Validation loss: 2.526448133111711

Epoch: 5| Step: 9
Training loss: 0.8945497069474496
Validation loss: 2.48367065859341

Epoch: 5| Step: 10
Training loss: 0.8216079655223071
Validation loss: 2.4779310998594375

Epoch: 298| Step: 0
Training loss: 0.6233236003267151
Validation loss: 2.4402703401670554

Epoch: 5| Step: 1
Training loss: 1.274351201754288
Validation loss: 2.4327897047686142

Epoch: 5| Step: 2
Training loss: 0.9442669469490738
Validation loss: 2.4354499986897227

Epoch: 5| Step: 3
Training loss: 0.8434472423893951
Validation loss: 2.4534258412738112

Epoch: 5| Step: 4
Training loss: 0.5768664037243766
Validation loss: 2.462064195456509

Epoch: 5| Step: 5
Training loss: 0.8356621190616753
Validation loss: 2.501889284034159

Epoch: 5| Step: 6
Training loss: 0.6627337906940677
Validation loss: 2.5097779561090947

Epoch: 5| Step: 7
Training loss: 0.6078746861906691
Validation loss: 2.507155656848471

Epoch: 5| Step: 8
Training loss: 0.8855628323053267
Validation loss: 2.5180937619097707

Epoch: 5| Step: 9
Training loss: 0.846601225177411
Validation loss: 2.511183035094218

Epoch: 5| Step: 10
Training loss: 0.757697932441431
Validation loss: 2.5012141837570976

Epoch: 299| Step: 0
Training loss: 0.7330570975855958
Validation loss: 2.5022907898099094

Epoch: 5| Step: 1
Training loss: 0.7774856284551993
Validation loss: 2.4849084255792473

Epoch: 5| Step: 2
Training loss: 0.862608565532842
Validation loss: 2.4730455156013

Epoch: 5| Step: 3
Training loss: 0.8610765431414902
Validation loss: 2.4820366187395875

Epoch: 5| Step: 4
Training loss: 1.1403316486368127
Validation loss: 2.4795253906384245

Epoch: 5| Step: 5
Training loss: 0.6792607557226517
Validation loss: 2.4907682090085994

Epoch: 5| Step: 6
Training loss: 0.7485116655081565
Validation loss: 2.498793336418753

Epoch: 5| Step: 7
Training loss: 0.9249936387126863
Validation loss: 2.48946989932632

Epoch: 5| Step: 8
Training loss: 0.9077095577420555
Validation loss: 2.487446359052018

Epoch: 5| Step: 9
Training loss: 0.5532959959299971
Validation loss: 2.505426862728566

Epoch: 5| Step: 10
Training loss: 0.59961770017728
Validation loss: 2.529453209566133

Epoch: 300| Step: 0
Training loss: 1.2047311045155749
Validation loss: 2.5541497144568295

Epoch: 5| Step: 1
Training loss: 0.8803184184619227
Validation loss: 2.5303877183815744

Epoch: 5| Step: 2
Training loss: 0.27176339061912747
Validation loss: 2.54704807402314

Epoch: 5| Step: 3
Training loss: 1.0192873725205498
Validation loss: 2.518313726469361

Epoch: 5| Step: 4
Training loss: 0.6266185307361898
Validation loss: 2.5236515899292087

Epoch: 5| Step: 5
Training loss: 0.8500597932765587
Validation loss: 2.541389955264416

Epoch: 5| Step: 6
Training loss: 0.7454842279634785
Validation loss: 2.490599131852873

Epoch: 5| Step: 7
Training loss: 0.6022701065029357
Validation loss: 2.548180459026191

Epoch: 5| Step: 8
Training loss: 0.7915581996965068
Validation loss: 2.500307433391076

Epoch: 5| Step: 9
Training loss: 0.6984501668988977
Validation loss: 2.4993444936974254

Epoch: 5| Step: 10
Training loss: 0.8452376566981068
Validation loss: 2.486484881048572

Epoch: 301| Step: 0
Training loss: 1.0556181580958142
Validation loss: 2.506808133267943

Epoch: 5| Step: 1
Training loss: 0.9254559939457098
Validation loss: 2.507687946587604

Epoch: 5| Step: 2
Training loss: 0.700996950904756
Validation loss: 2.5315824862785408

Epoch: 5| Step: 3
Training loss: 0.8873426284420223
Validation loss: 2.5456547413684993

Epoch: 5| Step: 4
Training loss: 0.8510095743566387
Validation loss: 2.5698670216507122

Epoch: 5| Step: 5
Training loss: 0.8488825352693403
Validation loss: 2.5561812374846182

Epoch: 5| Step: 6
Training loss: 0.8519469277122825
Validation loss: 2.5552274237475947

Epoch: 5| Step: 7
Training loss: 0.5103814800616256
Validation loss: 2.4890911720912587

Epoch: 5| Step: 8
Training loss: 0.8058583897978936
Validation loss: 2.51094953759983

Epoch: 5| Step: 9
Training loss: 0.7323726790118418
Validation loss: 2.5212230840409258

Epoch: 5| Step: 10
Training loss: 0.41127531794036676
Validation loss: 2.5012232494982385

Epoch: 302| Step: 0
Training loss: 0.7460917128290455
Validation loss: 2.4799072891091423

Epoch: 5| Step: 1
Training loss: 0.58423007147104
Validation loss: 2.486331592570253

Epoch: 5| Step: 2
Training loss: 1.239541264095269
Validation loss: 2.4539652244303594

Epoch: 5| Step: 3
Training loss: 0.5169031312199336
Validation loss: 2.491088582731034

Epoch: 5| Step: 4
Training loss: 0.6595758448609637
Validation loss: 2.4711522898477725

Epoch: 5| Step: 5
Training loss: 0.7244742953924923
Validation loss: 2.5034585399909086

Epoch: 5| Step: 6
Training loss: 0.7143125384266739
Validation loss: 2.4936474424377653

Epoch: 5| Step: 7
Training loss: 0.8702192492839611
Validation loss: 2.4927655099859893

Epoch: 5| Step: 8
Training loss: 1.1057297900511531
Validation loss: 2.5607213716411144

Epoch: 5| Step: 9
Training loss: 0.6671460534115762
Validation loss: 2.534694612219415

Epoch: 5| Step: 10
Training loss: 0.6139077794887785
Validation loss: 2.5228225078990842

Epoch: 303| Step: 0
Training loss: 1.2134310736082001
Validation loss: 2.5251217187642316

Epoch: 5| Step: 1
Training loss: 0.7460652291004406
Validation loss: 2.515901373685958

Epoch: 5| Step: 2
Training loss: 0.9340742462838812
Validation loss: 2.435756414180846

Epoch: 5| Step: 3
Training loss: 0.745308867631614
Validation loss: 2.4740481946564983

Epoch: 5| Step: 4
Training loss: 0.6619484629940167
Validation loss: 2.4339970333030965

Epoch: 5| Step: 5
Training loss: 0.9348321147375064
Validation loss: 2.4728837012230938

Epoch: 5| Step: 6
Training loss: 0.8412694141477396
Validation loss: 2.519224425490266

Epoch: 5| Step: 7
Training loss: 0.6516184858241314
Validation loss: 2.5353884130306734

Epoch: 5| Step: 8
Training loss: 0.32198798039316573
Validation loss: 2.5449861278454438

Epoch: 5| Step: 9
Training loss: 0.8238401583013866
Validation loss: 2.5089234298992946

Epoch: 5| Step: 10
Training loss: 0.6138853268882015
Validation loss: 2.5067672700593016

Epoch: 304| Step: 0
Training loss: 0.4327280148012765
Validation loss: 2.453202414063502

Epoch: 5| Step: 1
Training loss: 0.6446914704903669
Validation loss: 2.433226135506595

Epoch: 5| Step: 2
Training loss: 0.5781890988256162
Validation loss: 2.4741790058224513

Epoch: 5| Step: 3
Training loss: 0.6506890193799455
Validation loss: 2.5265965692802914

Epoch: 5| Step: 4
Training loss: 1.0624385703785146
Validation loss: 2.520823676398369

Epoch: 5| Step: 5
Training loss: 0.645906218651157
Validation loss: 2.539668275116422

Epoch: 5| Step: 6
Training loss: 0.7845366961015318
Validation loss: 2.5735519436630345

Epoch: 5| Step: 7
Training loss: 0.674290418296736
Validation loss: 2.548682495427682

Epoch: 5| Step: 8
Training loss: 1.246899383230024
Validation loss: 2.5368978168436334

Epoch: 5| Step: 9
Training loss: 0.8698552997330087
Validation loss: 2.49793312402389

Epoch: 5| Step: 10
Training loss: 1.017205871322374
Validation loss: 2.4936657497021613

Epoch: 305| Step: 0
Training loss: 0.35365674063370517
Validation loss: 2.4444489733833326

Epoch: 5| Step: 1
Training loss: 0.6577088625493628
Validation loss: 2.4405972901607464

Epoch: 5| Step: 2
Training loss: 0.574313357078684
Validation loss: 2.4573514725020402

Epoch: 5| Step: 3
Training loss: 0.8026095476574557
Validation loss: 2.4729995705625356

Epoch: 5| Step: 4
Training loss: 0.7877165390699737
Validation loss: 2.540764544835922

Epoch: 5| Step: 5
Training loss: 0.8000499083925229
Validation loss: 2.5763746517945125

Epoch: 5| Step: 6
Training loss: 0.7725221631349081
Validation loss: 2.5987220074895463

Epoch: 5| Step: 7
Training loss: 0.9449526204236001
Validation loss: 2.5857820968842327

Epoch: 5| Step: 8
Training loss: 0.659757888956378
Validation loss: 2.5396034501244795

Epoch: 5| Step: 9
Training loss: 1.2416786255143248
Validation loss: 2.4935643073126688

Epoch: 5| Step: 10
Training loss: 0.8619651255467613
Validation loss: 2.435559438722758

Epoch: 306| Step: 0
Training loss: 0.7466474545581487
Validation loss: 2.40372194991273

Epoch: 5| Step: 1
Training loss: 1.1287477375400718
Validation loss: 2.388674916586838

Epoch: 5| Step: 2
Training loss: 0.8028406226020129
Validation loss: 2.3936815356630454

Epoch: 5| Step: 3
Training loss: 0.6783614541847518
Validation loss: 2.4627253900086092

Epoch: 5| Step: 4
Training loss: 0.5671752707684151
Validation loss: 2.516531068060454

Epoch: 5| Step: 5
Training loss: 0.939303824443376
Validation loss: 2.613535237377466

Epoch: 5| Step: 6
Training loss: 0.5320261166586799
Validation loss: 2.6029215002013006

Epoch: 5| Step: 7
Training loss: 0.8798418278944983
Validation loss: 2.586029520018746

Epoch: 5| Step: 8
Training loss: 0.9975472410865878
Validation loss: 2.5565770185337287

Epoch: 5| Step: 9
Training loss: 0.6949077027941215
Validation loss: 2.5553870757132406

Epoch: 5| Step: 10
Training loss: 0.59810693739481
Validation loss: 2.5519747327777256

Epoch: 307| Step: 0
Training loss: 1.0567481361735513
Validation loss: 2.5051147212858424

Epoch: 5| Step: 1
Training loss: 0.8145352694940756
Validation loss: 2.464779006099635

Epoch: 5| Step: 2
Training loss: 0.5287410168076303
Validation loss: 2.476933190285662

Epoch: 5| Step: 3
Training loss: 1.1604762807950724
Validation loss: 2.5025750198930004

Epoch: 5| Step: 4
Training loss: 0.39345623138414604
Validation loss: 2.476163092370752

Epoch: 5| Step: 5
Training loss: 0.5458260421654222
Validation loss: 2.4860263732186265

Epoch: 5| Step: 6
Training loss: 0.793230361252952
Validation loss: 2.513045114999981

Epoch: 5| Step: 7
Training loss: 0.6950617563130335
Validation loss: 2.491547791391773

Epoch: 5| Step: 8
Training loss: 0.5927284889839
Validation loss: 2.523137871705004

Epoch: 5| Step: 9
Training loss: 0.7924868618089713
Validation loss: 2.5486184489339294

Epoch: 5| Step: 10
Training loss: 0.8165341509786076
Validation loss: 2.513337236612844

Epoch: 308| Step: 0
Training loss: 0.904794609568043
Validation loss: 2.5132666791736624

Epoch: 5| Step: 1
Training loss: 0.4710209829835903
Validation loss: 2.4601610965939127

Epoch: 5| Step: 2
Training loss: 0.5233781695546673
Validation loss: 2.4618649252373532

Epoch: 5| Step: 3
Training loss: 0.6702839398468623
Validation loss: 2.4367040044901938

Epoch: 5| Step: 4
Training loss: 0.7361529316408566
Validation loss: 2.443559362229209

Epoch: 5| Step: 5
Training loss: 0.6822794240964584
Validation loss: 2.5036487470933735

Epoch: 5| Step: 6
Training loss: 0.8190651629192519
Validation loss: 2.4509649831575815

Epoch: 5| Step: 7
Training loss: 0.30568192889858403
Validation loss: 2.5187516783481705

Epoch: 5| Step: 8
Training loss: 1.2453705892571865
Validation loss: 2.544616475897484

Epoch: 5| Step: 9
Training loss: 0.9209519307041791
Validation loss: 2.544179313547649

Epoch: 5| Step: 10
Training loss: 0.7489812607808386
Validation loss: 2.570535307462309

Epoch: 309| Step: 0
Training loss: 0.7655892266460202
Validation loss: 2.5025511491844226

Epoch: 5| Step: 1
Training loss: 0.8339551433648661
Validation loss: 2.449910347490885

Epoch: 5| Step: 2
Training loss: 0.8877415073238851
Validation loss: 2.4324724712040218

Epoch: 5| Step: 3
Training loss: 0.5223990715689683
Validation loss: 2.430764011950402

Epoch: 5| Step: 4
Training loss: 0.6890474806552197
Validation loss: 2.374459631023404

Epoch: 5| Step: 5
Training loss: 0.5640033130818989
Validation loss: 2.417412266972884

Epoch: 5| Step: 6
Training loss: 0.4828137184794337
Validation loss: 2.424275009138402

Epoch: 5| Step: 7
Training loss: 0.6930127204096377
Validation loss: 2.487606877824738

Epoch: 5| Step: 8
Training loss: 0.793943886092853
Validation loss: 2.531829804040553

Epoch: 5| Step: 9
Training loss: 0.8176506815873266
Validation loss: 2.561622531422142

Epoch: 5| Step: 10
Training loss: 1.1276146915405656
Validation loss: 2.608002947726692

Epoch: 310| Step: 0
Training loss: 0.5982438234710991
Validation loss: 2.5563037490278613

Epoch: 5| Step: 1
Training loss: 0.9876710115912871
Validation loss: 2.516955003259465

Epoch: 5| Step: 2
Training loss: 0.5414022723515585
Validation loss: 2.5016593112812693

Epoch: 5| Step: 3
Training loss: 0.5137913496079226
Validation loss: 2.4490397871818947

Epoch: 5| Step: 4
Training loss: 0.7795746195999547
Validation loss: 2.4170143788183776

Epoch: 5| Step: 5
Training loss: 0.9247599896079356
Validation loss: 2.4255265504163055

Epoch: 5| Step: 6
Training loss: 0.7704552848906484
Validation loss: 2.4115273523288487

Epoch: 5| Step: 7
Training loss: 0.5719576583076132
Validation loss: 2.434197620682688

Epoch: 5| Step: 8
Training loss: 0.41507096111908426
Validation loss: 2.463644424172356

Epoch: 5| Step: 9
Training loss: 0.849604534266921
Validation loss: 2.513510869737788

Epoch: 5| Step: 10
Training loss: 0.825158654476535
Validation loss: 2.575962403352993

Epoch: 311| Step: 0
Training loss: 0.5061288947786747
Validation loss: 2.5659219547060967

Epoch: 5| Step: 1
Training loss: 1.0041250739974312
Validation loss: 2.577979816166029

Epoch: 5| Step: 2
Training loss: 0.4304856257237551
Validation loss: 2.5705808874739335

Epoch: 5| Step: 3
Training loss: 0.7768574252484595
Validation loss: 2.526289087798188

Epoch: 5| Step: 4
Training loss: 0.6413094887829596
Validation loss: 2.5280095420525956

Epoch: 5| Step: 5
Training loss: 0.7763574371685295
Validation loss: 2.4874092117225683

Epoch: 5| Step: 6
Training loss: 0.6404552700078745
Validation loss: 2.4883435165988916

Epoch: 5| Step: 7
Training loss: 0.8941763961122824
Validation loss: 2.456938247802544

Epoch: 5| Step: 8
Training loss: 0.6973050103697815
Validation loss: 2.4749010518931214

Epoch: 5| Step: 9
Training loss: 0.7495650381202574
Validation loss: 2.4889726178484204

Epoch: 5| Step: 10
Training loss: 0.7111957206864445
Validation loss: 2.5594565563641742

Epoch: 312| Step: 0
Training loss: 0.49029215437991625
Validation loss: 2.5678799725829875

Epoch: 5| Step: 1
Training loss: 0.49829325846008904
Validation loss: 2.551566751788015

Epoch: 5| Step: 2
Training loss: 0.820075700277876
Validation loss: 2.579651834834622

Epoch: 5| Step: 3
Training loss: 0.6926795743168563
Validation loss: 2.551662211091923

Epoch: 5| Step: 4
Training loss: 0.6732022018222648
Validation loss: 2.543241645968671

Epoch: 5| Step: 5
Training loss: 0.7290189093791679
Validation loss: 2.53622711513128

Epoch: 5| Step: 6
Training loss: 0.6607915090295371
Validation loss: 2.4669568699564093

Epoch: 5| Step: 7
Training loss: 0.8500339893950306
Validation loss: 2.482241553901239

Epoch: 5| Step: 8
Training loss: 0.7117179945974184
Validation loss: 2.5281160329180077

Epoch: 5| Step: 9
Training loss: 0.4479389868948843
Validation loss: 2.5311390659903275

Epoch: 5| Step: 10
Training loss: 1.058397056633597
Validation loss: 2.5439206327777595

Epoch: 313| Step: 0
Training loss: 0.9676878551592635
Validation loss: 2.4783603949267587

Epoch: 5| Step: 1
Training loss: 0.6485404426946302
Validation loss: 2.49161413109036

Epoch: 5| Step: 2
Training loss: 0.6686042751652554
Validation loss: 2.4327911376542106

Epoch: 5| Step: 3
Training loss: 0.6220665037796104
Validation loss: 2.4971861385505734

Epoch: 5| Step: 4
Training loss: 0.7713455268398319
Validation loss: 2.471295550243695

Epoch: 5| Step: 5
Training loss: 0.8396415289563353
Validation loss: 2.4956432650277467

Epoch: 5| Step: 6
Training loss: 0.734145351783188
Validation loss: 2.5522712122705293

Epoch: 5| Step: 7
Training loss: 0.743633467897444
Validation loss: 2.558579305523333

Epoch: 5| Step: 8
Training loss: 0.8462558552301376
Validation loss: 2.5109693854606645

Epoch: 5| Step: 9
Training loss: 0.785665204787914
Validation loss: 2.4831019729905193

Epoch: 5| Step: 10
Training loss: 0.7464149542627017
Validation loss: 2.509709468248563

Epoch: 314| Step: 0
Training loss: 0.6060800235430109
Validation loss: 2.4513177954838477

Epoch: 5| Step: 1
Training loss: 0.6460927139882796
Validation loss: 2.464235395206816

Epoch: 5| Step: 2
Training loss: 0.897500951495503
Validation loss: 2.4134463543324833

Epoch: 5| Step: 3
Training loss: 0.6044746852430132
Validation loss: 2.4733073282904896

Epoch: 5| Step: 4
Training loss: 0.8476871889155013
Validation loss: 2.4802612558967017

Epoch: 5| Step: 5
Training loss: 0.736155603571679
Validation loss: 2.5152801723696867

Epoch: 5| Step: 6
Training loss: 0.7705110228342301
Validation loss: 2.5406323094517558

Epoch: 5| Step: 7
Training loss: 0.982129002138975
Validation loss: 2.5048686171068297

Epoch: 5| Step: 8
Training loss: 0.5660273369735109
Validation loss: 2.5026114667947943

Epoch: 5| Step: 9
Training loss: 0.9133853197153013
Validation loss: 2.44230920172169

Epoch: 5| Step: 10
Training loss: 0.5474714840905028
Validation loss: 2.434004860619436

Epoch: 315| Step: 0
Training loss: 0.6596900603056303
Validation loss: 2.4169088913398915

Epoch: 5| Step: 1
Training loss: 0.6513220272394193
Validation loss: 2.3891374696045125

Epoch: 5| Step: 2
Training loss: 0.586591863816846
Validation loss: 2.418093502696262

Epoch: 5| Step: 3
Training loss: 0.8398057086224547
Validation loss: 2.4195279692158813

Epoch: 5| Step: 4
Training loss: 0.7217487720258392
Validation loss: 2.435067294637212

Epoch: 5| Step: 5
Training loss: 0.7713367562365052
Validation loss: 2.5137364223000107

Epoch: 5| Step: 6
Training loss: 0.6502977367890272
Validation loss: 2.5108105859283905

Epoch: 5| Step: 7
Training loss: 0.8401867188399886
Validation loss: 2.499356818781062

Epoch: 5| Step: 8
Training loss: 0.692585666570251
Validation loss: 2.508811591429259

Epoch: 5| Step: 9
Training loss: 0.7006954604150846
Validation loss: 2.4865675626133745

Epoch: 5| Step: 10
Training loss: 0.8197616180639007
Validation loss: 2.43515400281472

Epoch: 316| Step: 0
Training loss: 0.5560358610406336
Validation loss: 2.3776030327117037

Epoch: 5| Step: 1
Training loss: 0.8371879992851998
Validation loss: 2.3920273999459716

Epoch: 5| Step: 2
Training loss: 0.7259357579473513
Validation loss: 2.3574517782361752

Epoch: 5| Step: 3
Training loss: 0.6436634579606023
Validation loss: 2.3662208476780893

Epoch: 5| Step: 4
Training loss: 0.6124898822104455
Validation loss: 2.390653468104673

Epoch: 5| Step: 5
Training loss: 0.8127366968319939
Validation loss: 2.438686673073013

Epoch: 5| Step: 6
Training loss: 0.6278385790377979
Validation loss: 2.45434256469847

Epoch: 5| Step: 7
Training loss: 0.7512525986231388
Validation loss: 2.511816714215533

Epoch: 5| Step: 8
Training loss: 0.9028439477161958
Validation loss: 2.498711931488293

Epoch: 5| Step: 9
Training loss: 0.6426953147999938
Validation loss: 2.4659582812327767

Epoch: 5| Step: 10
Training loss: 0.7405927288895536
Validation loss: 2.452858884239973

Epoch: 317| Step: 0
Training loss: 0.7878699780824159
Validation loss: 2.370306025499664

Epoch: 5| Step: 1
Training loss: 0.880493866393839
Validation loss: 2.4171930782210453

Epoch: 5| Step: 2
Training loss: 0.5826361412369517
Validation loss: 2.4086140447707804

Epoch: 5| Step: 3
Training loss: 0.7720183251014512
Validation loss: 2.458030443388302

Epoch: 5| Step: 4
Training loss: 0.5670622611165687
Validation loss: 2.4691726345653944

Epoch: 5| Step: 5
Training loss: 0.6922394855688532
Validation loss: 2.487962635378878

Epoch: 5| Step: 6
Training loss: 0.7845995243513507
Validation loss: 2.558198456333455

Epoch: 5| Step: 7
Training loss: 0.7506557617744912
Validation loss: 2.533654611640135

Epoch: 5| Step: 8
Training loss: 0.8596871589374316
Validation loss: 2.515276502641383

Epoch: 5| Step: 9
Training loss: 0.34192853299269665
Validation loss: 2.5070987207365487

Epoch: 5| Step: 10
Training loss: 0.21576712457827893
Validation loss: 2.4803703021788777

Epoch: 318| Step: 0
Training loss: 0.7607624016991043
Validation loss: 2.4952328586602817

Epoch: 5| Step: 1
Training loss: 0.8943645538530423
Validation loss: 2.502313864910548

Epoch: 5| Step: 2
Training loss: 0.664296254921859
Validation loss: 2.5066382689750357

Epoch: 5| Step: 3
Training loss: 0.6098881785897556
Validation loss: 2.4990466956212107

Epoch: 5| Step: 4
Training loss: 0.18343807275607943
Validation loss: 2.4761893264044272

Epoch: 5| Step: 5
Training loss: 0.6255697276254044
Validation loss: 2.5261391478287827

Epoch: 5| Step: 6
Training loss: 0.5207261706415675
Validation loss: 2.4642402603481983

Epoch: 5| Step: 7
Training loss: 0.6489411431898892
Validation loss: 2.4807475623131054

Epoch: 5| Step: 8
Training loss: 0.7695681567951168
Validation loss: 2.5091885038150834

Epoch: 5| Step: 9
Training loss: 0.7830271154485516
Validation loss: 2.4635211841659928

Epoch: 5| Step: 10
Training loss: 0.5770213960353151
Validation loss: 2.4780257303703563

Epoch: 319| Step: 0
Training loss: 0.7970320229002169
Validation loss: 2.4900146912508188

Epoch: 5| Step: 1
Training loss: 0.6115930976289194
Validation loss: 2.497914542707244

Epoch: 5| Step: 2
Training loss: 0.9795751260802782
Validation loss: 2.4868539773625082

Epoch: 5| Step: 3
Training loss: 0.6100527833161471
Validation loss: 2.4898276713500236

Epoch: 5| Step: 4
Training loss: 0.6103352536883614
Validation loss: 2.489609229616087

Epoch: 5| Step: 5
Training loss: 0.568998154799783
Validation loss: 2.5009538820116046

Epoch: 5| Step: 6
Training loss: 0.6134807237971605
Validation loss: 2.506320678706136

Epoch: 5| Step: 7
Training loss: 0.8373801715017487
Validation loss: 2.4874859865185193

Epoch: 5| Step: 8
Training loss: 0.3661744163104325
Validation loss: 2.476961699878494

Epoch: 5| Step: 9
Training loss: 0.5030127595606525
Validation loss: 2.5187933415255155

Epoch: 5| Step: 10
Training loss: 0.5661894021440754
Validation loss: 2.4985990731688723

Epoch: 320| Step: 0
Training loss: 0.8425242032273222
Validation loss: 2.538638425235414

Epoch: 5| Step: 1
Training loss: 0.7320801611715628
Validation loss: 2.4852700726481984

Epoch: 5| Step: 2
Training loss: 0.8565529350072376
Validation loss: 2.503764607736237

Epoch: 5| Step: 3
Training loss: 0.3687236792659002
Validation loss: 2.4886499969654263

Epoch: 5| Step: 4
Training loss: 0.5581846272825298
Validation loss: 2.4506071499039126

Epoch: 5| Step: 5
Training loss: 0.6039649253854782
Validation loss: 2.438252556097136

Epoch: 5| Step: 6
Training loss: 0.7553255625973482
Validation loss: 2.445344500840273

Epoch: 5| Step: 7
Training loss: 0.3523415622516387
Validation loss: 2.423217846799645

Epoch: 5| Step: 8
Training loss: 0.6265604803951753
Validation loss: 2.482894691716538

Epoch: 5| Step: 9
Training loss: 0.5929188683478555
Validation loss: 2.498165842154177

Epoch: 5| Step: 10
Training loss: 0.7342984179884285
Validation loss: 2.5322015832906684

Epoch: 321| Step: 0
Training loss: 0.6161693432004891
Validation loss: 2.512125516037153

Epoch: 5| Step: 1
Training loss: 0.8297049727099715
Validation loss: 2.513687826873571

Epoch: 5| Step: 2
Training loss: 0.591940229823452
Validation loss: 2.487820137931255

Epoch: 5| Step: 3
Training loss: 0.47124310936177777
Validation loss: 2.450247040005503

Epoch: 5| Step: 4
Training loss: 0.5782075256007011
Validation loss: 2.488244827072704

Epoch: 5| Step: 5
Training loss: 0.7778311500137232
Validation loss: 2.4995588303024276

Epoch: 5| Step: 6
Training loss: 0.561315375218441
Validation loss: 2.4805282723866546

Epoch: 5| Step: 7
Training loss: 0.6187802779370813
Validation loss: 2.4907841706751426

Epoch: 5| Step: 8
Training loss: 0.3129352875835699
Validation loss: 2.475678844957242

Epoch: 5| Step: 9
Training loss: 0.7574937287628131
Validation loss: 2.5362222632444964

Epoch: 5| Step: 10
Training loss: 0.9039093901135394
Validation loss: 2.559839955434843

Epoch: 322| Step: 0
Training loss: 0.3671861405043088
Validation loss: 2.544208069682332

Epoch: 5| Step: 1
Training loss: 0.8046896851148844
Validation loss: 2.490156344518895

Epoch: 5| Step: 2
Training loss: 0.6066412125564353
Validation loss: 2.531866580617436

Epoch: 5| Step: 3
Training loss: 0.6774618166900387
Validation loss: 2.526955903399354

Epoch: 5| Step: 4
Training loss: 0.5686023101204213
Validation loss: 2.499173024513616

Epoch: 5| Step: 5
Training loss: 0.5332507437098557
Validation loss: 2.529452473246842

Epoch: 5| Step: 6
Training loss: 0.764725877292223
Validation loss: 2.4862623856345696

Epoch: 5| Step: 7
Training loss: 0.5159437754738648
Validation loss: 2.533452645354311

Epoch: 5| Step: 8
Training loss: 0.6724518583927405
Validation loss: 2.491075451066044

Epoch: 5| Step: 9
Training loss: 0.6193466325147426
Validation loss: 2.494459228507747

Epoch: 5| Step: 10
Training loss: 0.8216653839382453
Validation loss: 2.494634514720665

Epoch: 323| Step: 0
Training loss: 0.6640112913245988
Validation loss: 2.4922283214397125

Epoch: 5| Step: 1
Training loss: 0.7787001387797226
Validation loss: 2.4701878991774775

Epoch: 5| Step: 2
Training loss: 0.6702074159713347
Validation loss: 2.485164346414288

Epoch: 5| Step: 3
Training loss: 0.8090822890931054
Validation loss: 2.502455852571893

Epoch: 5| Step: 4
Training loss: 0.7156150700575693
Validation loss: 2.4947142579477264

Epoch: 5| Step: 5
Training loss: 0.4266808132655138
Validation loss: 2.4779496608366047

Epoch: 5| Step: 6
Training loss: 0.7507072928340047
Validation loss: 2.471819700101121

Epoch: 5| Step: 7
Training loss: 0.5963422005020607
Validation loss: 2.487709122201582

Epoch: 5| Step: 8
Training loss: 0.34975439931694435
Validation loss: 2.459510168713163

Epoch: 5| Step: 9
Training loss: 0.5066405932353649
Validation loss: 2.4717528924049437

Epoch: 5| Step: 10
Training loss: 0.43268527836265774
Validation loss: 2.4894360940561446

Epoch: 324| Step: 0
Training loss: 0.5600701408226865
Validation loss: 2.5241275992871937

Epoch: 5| Step: 1
Training loss: 0.5229155372009643
Validation loss: 2.5076219881648254

Epoch: 5| Step: 2
Training loss: 0.3785938469496606
Validation loss: 2.516422270992393

Epoch: 5| Step: 3
Training loss: 0.6090241914056581
Validation loss: 2.46675008296297

Epoch: 5| Step: 4
Training loss: 0.6245632075841417
Validation loss: 2.4984283326633587

Epoch: 5| Step: 5
Training loss: 0.6523498260763297
Validation loss: 2.483387305028399

Epoch: 5| Step: 6
Training loss: 0.6849885715798195
Validation loss: 2.473447409408968

Epoch: 5| Step: 7
Training loss: 0.531308367271671
Validation loss: 2.4835383726649476

Epoch: 5| Step: 8
Training loss: 0.6008576809565732
Validation loss: 2.5203332770287346

Epoch: 5| Step: 9
Training loss: 0.9674796419687879
Validation loss: 2.479458480382452

Epoch: 5| Step: 10
Training loss: 0.5102870510597871
Validation loss: 2.4831831396150332

Epoch: 325| Step: 0
Training loss: 0.6638166309038158
Validation loss: 2.443951457017628

Epoch: 5| Step: 1
Training loss: 0.3906055254850104
Validation loss: 2.4828941702934344

Epoch: 5| Step: 2
Training loss: 0.7961542946925153
Validation loss: 2.4811446903407153

Epoch: 5| Step: 3
Training loss: 0.7474754680958572
Validation loss: 2.4592321781655704

Epoch: 5| Step: 4
Training loss: 0.6636129765142587
Validation loss: 2.538904264077152

Epoch: 5| Step: 5
Training loss: 0.6921750121357165
Validation loss: 2.4829956165172424

Epoch: 5| Step: 6
Training loss: 0.5679621930904832
Validation loss: 2.505411295693441

Epoch: 5| Step: 7
Training loss: 0.5627172898115613
Validation loss: 2.5200101440060796

Epoch: 5| Step: 8
Training loss: 0.4871953562555134
Validation loss: 2.5110541893963423

Epoch: 5| Step: 9
Training loss: 0.4344501629299526
Validation loss: 2.4778457939289935

Epoch: 5| Step: 10
Training loss: 0.5448290291174006
Validation loss: 2.4696590774250757

Epoch: 326| Step: 0
Training loss: 0.7434601162729076
Validation loss: 2.4781572936596694

Epoch: 5| Step: 1
Training loss: 0.47404669542314565
Validation loss: 2.5209380612593613

Epoch: 5| Step: 2
Training loss: 0.683850703311778
Validation loss: 2.500333400768014

Epoch: 5| Step: 3
Training loss: 0.547039470463745
Validation loss: 2.4757744919434774

Epoch: 5| Step: 4
Training loss: 0.6294698618339443
Validation loss: 2.4572065916112633

Epoch: 5| Step: 5
Training loss: 0.26102763349579994
Validation loss: 2.4334287570218613

Epoch: 5| Step: 6
Training loss: 0.5957636067689088
Validation loss: 2.474985890655391

Epoch: 5| Step: 7
Training loss: 0.6278542670582876
Validation loss: 2.4729710785289005

Epoch: 5| Step: 8
Training loss: 0.8022359521170253
Validation loss: 2.4619617468197523

Epoch: 5| Step: 9
Training loss: 0.5072100072956511
Validation loss: 2.3877390262472447

Epoch: 5| Step: 10
Training loss: 0.6075086623622113
Validation loss: 2.365227525924576

Epoch: 327| Step: 0
Training loss: 0.3000071832671073
Validation loss: 2.421902125878511

Epoch: 5| Step: 1
Training loss: 0.6737279181674728
Validation loss: 2.408005743877791

Epoch: 5| Step: 2
Training loss: 0.6771797967322117
Validation loss: 2.4149447563013373

Epoch: 5| Step: 3
Training loss: 0.3268806272317745
Validation loss: 2.420952469399082

Epoch: 5| Step: 4
Training loss: 0.5263464928913223
Validation loss: 2.4511487974681936

Epoch: 5| Step: 5
Training loss: 0.8456669330561419
Validation loss: 2.494273037262041

Epoch: 5| Step: 6
Training loss: 0.3938415277157017
Validation loss: 2.4837905161164326

Epoch: 5| Step: 7
Training loss: 0.7219349328465129
Validation loss: 2.49784415002774

Epoch: 5| Step: 8
Training loss: 0.8058086473601725
Validation loss: 2.5104945528181117

Epoch: 5| Step: 9
Training loss: 0.49611016494146476
Validation loss: 2.461301482837674

Epoch: 5| Step: 10
Training loss: 0.5321490030034375
Validation loss: 2.443063770754928

Epoch: 328| Step: 0
Training loss: 0.6638002214272208
Validation loss: 2.491771682725004

Epoch: 5| Step: 1
Training loss: 0.5640541435320127
Validation loss: 2.4764773047935744

Epoch: 5| Step: 2
Training loss: 0.366729653793266
Validation loss: 2.4886571110541675

Epoch: 5| Step: 3
Training loss: 0.8153979997702517
Validation loss: 2.4716137815243013

Epoch: 5| Step: 4
Training loss: 0.5288622715301226
Validation loss: 2.456330196738537

Epoch: 5| Step: 5
Training loss: 0.5333884060508988
Validation loss: 2.462269620569605

Epoch: 5| Step: 6
Training loss: 0.5428093875319213
Validation loss: 2.5051648501997037

Epoch: 5| Step: 7
Training loss: 0.8529034127673323
Validation loss: 2.501270361099365

Epoch: 5| Step: 8
Training loss: 0.337378737069598
Validation loss: 2.4859135943560466

Epoch: 5| Step: 9
Training loss: 0.6819361835656174
Validation loss: 2.5065673276174656

Epoch: 5| Step: 10
Training loss: 0.539254969638072
Validation loss: 2.5203976801765537

Epoch: 329| Step: 0
Training loss: 0.4960464394906004
Validation loss: 2.4534134630869238

Epoch: 5| Step: 1
Training loss: 0.4387317755845737
Validation loss: 2.4767469774322537

Epoch: 5| Step: 2
Training loss: 0.47987797711008573
Validation loss: 2.457517529904131

Epoch: 5| Step: 3
Training loss: 0.6565622313552009
Validation loss: 2.44331843063964

Epoch: 5| Step: 4
Training loss: 0.42551068800088815
Validation loss: 2.4569688644274126

Epoch: 5| Step: 5
Training loss: 0.6344258734312568
Validation loss: 2.462269234295599

Epoch: 5| Step: 6
Training loss: 0.2687165483459289
Validation loss: 2.4509841400590746

Epoch: 5| Step: 7
Training loss: 0.5369656734701435
Validation loss: 2.482417285598968

Epoch: 5| Step: 8
Training loss: 0.700278454131313
Validation loss: 2.4631477562563715

Epoch: 5| Step: 9
Training loss: 0.625654140521634
Validation loss: 2.47168431343377

Epoch: 5| Step: 10
Training loss: 0.9842336038430607
Validation loss: 2.447960551611876

Epoch: 330| Step: 0
Training loss: 0.6368751333833654
Validation loss: 2.45491648388663

Epoch: 5| Step: 1
Training loss: 0.4666774229813909
Validation loss: 2.463958299851176

Epoch: 5| Step: 2
Training loss: 0.5616654456980912
Validation loss: 2.4693474109712334

Epoch: 5| Step: 3
Training loss: 0.571749666164686
Validation loss: 2.5042249746657723

Epoch: 5| Step: 4
Training loss: 0.5615472672423226
Validation loss: 2.489853562689003

Epoch: 5| Step: 5
Training loss: 0.6506722330323655
Validation loss: 2.4587288571869674

Epoch: 5| Step: 6
Training loss: 0.5416105008961133
Validation loss: 2.4720840101685213

Epoch: 5| Step: 7
Training loss: 0.21795758557183775
Validation loss: 2.522500003722132

Epoch: 5| Step: 8
Training loss: 0.6748774664534019
Validation loss: 2.491597055281852

Epoch: 5| Step: 9
Training loss: 0.6738388502953608
Validation loss: 2.492448063106658

Epoch: 5| Step: 10
Training loss: 0.7442642469673068
Validation loss: 2.500957209370828

Epoch: 331| Step: 0
Training loss: 0.57316544651095
Validation loss: 2.4749053429220975

Epoch: 5| Step: 1
Training loss: 0.5780265569641255
Validation loss: 2.43877219505876

Epoch: 5| Step: 2
Training loss: 0.5216082879339017
Validation loss: 2.4703222750785145

Epoch: 5| Step: 3
Training loss: 0.5751299472837321
Validation loss: 2.4972331651388875

Epoch: 5| Step: 4
Training loss: 0.6349369463440826
Validation loss: 2.48735588960214

Epoch: 5| Step: 5
Training loss: 0.2830412434905586
Validation loss: 2.4849064055408614

Epoch: 5| Step: 6
Training loss: 0.6554578814327244
Validation loss: 2.492706454645345

Epoch: 5| Step: 7
Training loss: 0.40195607517001314
Validation loss: 2.5176500075502948

Epoch: 5| Step: 8
Training loss: 0.835488671285917
Validation loss: 2.500594211020193

Epoch: 5| Step: 9
Training loss: 0.6665886122984969
Validation loss: 2.51185701865172

Epoch: 5| Step: 10
Training loss: 0.6080186371738842
Validation loss: 2.5103589960465125

Epoch: 332| Step: 0
Training loss: 0.37125457491126973
Validation loss: 2.4777901905007087

Epoch: 5| Step: 1
Training loss: 0.6824238384635641
Validation loss: 2.443831977049384

Epoch: 5| Step: 2
Training loss: 0.6891998820121009
Validation loss: 2.45744500466187

Epoch: 5| Step: 3
Training loss: 0.7584747095336378
Validation loss: 2.439541626656898

Epoch: 5| Step: 4
Training loss: 0.4441808576654834
Validation loss: 2.4769145228476708

Epoch: 5| Step: 5
Training loss: 0.6031524651949555
Validation loss: 2.5279276343391

Epoch: 5| Step: 6
Training loss: 0.4168077369139799
Validation loss: 2.533013996545413

Epoch: 5| Step: 7
Training loss: 0.8025374344980749
Validation loss: 2.4992041623443884

Epoch: 5| Step: 8
Training loss: 0.3827560928203629
Validation loss: 2.5386278480584172

Epoch: 5| Step: 9
Training loss: 0.5459590325479029
Validation loss: 2.530837975110397

Epoch: 5| Step: 10
Training loss: 0.6467324095133933
Validation loss: 2.4825390030612353

Epoch: 333| Step: 0
Training loss: 0.434083232727791
Validation loss: 2.462583269637674

Epoch: 5| Step: 1
Training loss: 0.5914471540327272
Validation loss: 2.478533191221567

Epoch: 5| Step: 2
Training loss: 0.37588319486102617
Validation loss: 2.436637256655194

Epoch: 5| Step: 3
Training loss: 0.4793382696729641
Validation loss: 2.491241073752528

Epoch: 5| Step: 4
Training loss: 0.7223929260532778
Validation loss: 2.443661416430463

Epoch: 5| Step: 5
Training loss: 0.6410198855447371
Validation loss: 2.4679031498027775

Epoch: 5| Step: 6
Training loss: 0.4651448853180476
Validation loss: 2.4876224393078896

Epoch: 5| Step: 7
Training loss: 0.5717864911319291
Validation loss: 2.472291561142299

Epoch: 5| Step: 8
Training loss: 0.5955840445144582
Validation loss: 2.4628580058744154

Epoch: 5| Step: 9
Training loss: 0.6569584700727277
Validation loss: 2.4826976345126206

Epoch: 5| Step: 10
Training loss: 0.7539958208863784
Validation loss: 2.4384548840038045

Epoch: 334| Step: 0
Training loss: 0.37813158581255474
Validation loss: 2.4396769160878122

Epoch: 5| Step: 1
Training loss: 0.5301073351621869
Validation loss: 2.4869393551940813

Epoch: 5| Step: 2
Training loss: 0.5465341323112578
Validation loss: 2.477271803239398

Epoch: 5| Step: 3
Training loss: 0.6177422891025195
Validation loss: 2.4765394789500257

Epoch: 5| Step: 4
Training loss: 0.4785829302106184
Validation loss: 2.473442371149503

Epoch: 5| Step: 5
Training loss: 0.48036915436919514
Validation loss: 2.487952061210386

Epoch: 5| Step: 6
Training loss: 0.7909935088656906
Validation loss: 2.505922928631786

Epoch: 5| Step: 7
Training loss: 0.44522023499996843
Validation loss: 2.5187141143327754

Epoch: 5| Step: 8
Training loss: 0.797924323248586
Validation loss: 2.4956635386809487

Epoch: 5| Step: 9
Training loss: 0.5966532649856292
Validation loss: 2.5217869303374596

Epoch: 5| Step: 10
Training loss: 0.4289326366097157
Validation loss: 2.55452152699119

Epoch: 335| Step: 0
Training loss: 0.6039828371584243
Validation loss: 2.532622572499978

Epoch: 5| Step: 1
Training loss: 0.2357807440780763
Validation loss: 2.4883065933541846

Epoch: 5| Step: 2
Training loss: 0.7488502590706996
Validation loss: 2.4941171875049997

Epoch: 5| Step: 3
Training loss: 0.5990439367626966
Validation loss: 2.497955648232731

Epoch: 5| Step: 4
Training loss: 0.675431883364223
Validation loss: 2.4839564423782767

Epoch: 5| Step: 5
Training loss: 0.4851964629825852
Validation loss: 2.4491835402566644

Epoch: 5| Step: 6
Training loss: 0.5742343199818304
Validation loss: 2.453333073362325

Epoch: 5| Step: 7
Training loss: 0.290898779639264
Validation loss: 2.448218444640765

Epoch: 5| Step: 8
Training loss: 0.5951448670107669
Validation loss: 2.4392869424212327

Epoch: 5| Step: 9
Training loss: 0.6688574071889918
Validation loss: 2.470408329579862

Epoch: 5| Step: 10
Training loss: 0.5365497239668565
Validation loss: 2.482037651617218

Epoch: 336| Step: 0
Training loss: 0.7666505056903137
Validation loss: 2.50680582816586

Epoch: 5| Step: 1
Training loss: 0.34903761926154486
Validation loss: 2.5175373398639094

Epoch: 5| Step: 2
Training loss: 0.5795456982763393
Validation loss: 2.5551913932515435

Epoch: 5| Step: 3
Training loss: 0.32917025384075055
Validation loss: 2.509160462050208

Epoch: 5| Step: 4
Training loss: 0.6530421738376067
Validation loss: 2.525550910479395

Epoch: 5| Step: 5
Training loss: 0.6461425522958697
Validation loss: 2.531581808806713

Epoch: 5| Step: 6
Training loss: 0.5861337460259717
Validation loss: 2.5514421177741937

Epoch: 5| Step: 7
Training loss: 0.4520747081385002
Validation loss: 2.504078921536728

Epoch: 5| Step: 8
Training loss: 0.515469643278987
Validation loss: 2.473607097534644

Epoch: 5| Step: 9
Training loss: 0.6248026774768509
Validation loss: 2.480707730062755

Epoch: 5| Step: 10
Training loss: 0.46215517231491016
Validation loss: 2.5198795958892566

Epoch: 337| Step: 0
Training loss: 0.4938085593735156
Validation loss: 2.4782319727082793

Epoch: 5| Step: 1
Training loss: 0.4996206215195852
Validation loss: 2.5047654980051095

Epoch: 5| Step: 2
Training loss: 0.5214516847343856
Validation loss: 2.5134938386531505

Epoch: 5| Step: 3
Training loss: 0.49934088954515665
Validation loss: 2.5160019055354135

Epoch: 5| Step: 4
Training loss: 0.743605614118842
Validation loss: 2.5173831391540604

Epoch: 5| Step: 5
Training loss: 0.3783700826556621
Validation loss: 2.5322918982721307

Epoch: 5| Step: 6
Training loss: 0.7471085283066594
Validation loss: 2.5256889425990163

Epoch: 5| Step: 7
Training loss: 0.5362294705780581
Validation loss: 2.54759657740488

Epoch: 5| Step: 8
Training loss: 0.3915683608594522
Validation loss: 2.530590313229006

Epoch: 5| Step: 9
Training loss: 0.6936443334302503
Validation loss: 2.509840463644756

Epoch: 5| Step: 10
Training loss: 0.273553414979835
Validation loss: 2.4685725587977454

Epoch: 338| Step: 0
Training loss: 0.6654610212476898
Validation loss: 2.5053825352815093

Epoch: 5| Step: 1
Training loss: 0.6862827709412691
Validation loss: 2.5190663081613875

Epoch: 5| Step: 2
Training loss: 0.5184688748551576
Validation loss: 2.5244328430445755

Epoch: 5| Step: 3
Training loss: 0.6659103265568
Validation loss: 2.550321564977571

Epoch: 5| Step: 4
Training loss: 0.2147768436636491
Validation loss: 2.5805821716148025

Epoch: 5| Step: 5
Training loss: 0.6405669860623204
Validation loss: 2.6221625016957764

Epoch: 5| Step: 6
Training loss: 0.560681423295076
Validation loss: 2.574368154173805

Epoch: 5| Step: 7
Training loss: 0.3501758248757169
Validation loss: 2.602069086424515

Epoch: 5| Step: 8
Training loss: 0.4430719191553171
Validation loss: 2.567490100645207

Epoch: 5| Step: 9
Training loss: 0.5680873259085619
Validation loss: 2.4784696427594666

Epoch: 5| Step: 10
Training loss: 0.49716470417965763
Validation loss: 2.491088902788776

Epoch: 339| Step: 0
Training loss: 0.5318115296018182
Validation loss: 2.4601197701480952

Epoch: 5| Step: 1
Training loss: 0.29541074894617064
Validation loss: 2.4557534229044222

Epoch: 5| Step: 2
Training loss: 0.4999536701433927
Validation loss: 2.475979149190978

Epoch: 5| Step: 3
Training loss: 0.5243154536050493
Validation loss: 2.4553061766622646

Epoch: 5| Step: 4
Training loss: 0.6369623993491182
Validation loss: 2.477984910326144

Epoch: 5| Step: 5
Training loss: 0.3855051592025184
Validation loss: 2.4795957486805715

Epoch: 5| Step: 6
Training loss: 0.6519581003153523
Validation loss: 2.4858425452325643

Epoch: 5| Step: 7
Training loss: 0.6531773797162731
Validation loss: 2.513821179801143

Epoch: 5| Step: 8
Training loss: 0.27481381225619655
Validation loss: 2.5358265115979783

Epoch: 5| Step: 9
Training loss: 0.7017572238918589
Validation loss: 2.521175389450885

Epoch: 5| Step: 10
Training loss: 0.6372103519280093
Validation loss: 2.5300741919667438

Epoch: 340| Step: 0
Training loss: 0.33448163319813506
Validation loss: 2.4770028400330593

Epoch: 5| Step: 1
Training loss: 0.735017941444078
Validation loss: 2.4949896699161886

Epoch: 5| Step: 2
Training loss: 0.6016557546887087
Validation loss: 2.4948883743513486

Epoch: 5| Step: 3
Training loss: 0.5463091511420259
Validation loss: 2.450120362754648

Epoch: 5| Step: 4
Training loss: 0.43341880568252955
Validation loss: 2.4484465389293097

Epoch: 5| Step: 5
Training loss: 0.5094356418857003
Validation loss: 2.453070303513097

Epoch: 5| Step: 6
Training loss: 0.6327748228559902
Validation loss: 2.4756456466664525

Epoch: 5| Step: 7
Training loss: 0.5642262567164972
Validation loss: 2.461245932704448

Epoch: 5| Step: 8
Training loss: 0.5429077388598312
Validation loss: 2.4710665169894246

Epoch: 5| Step: 9
Training loss: 0.4792640283050768
Validation loss: 2.50136055071718

Epoch: 5| Step: 10
Training loss: 0.3312356504895039
Validation loss: 2.5164299458399326

Epoch: 341| Step: 0
Training loss: 0.4952972054752525
Validation loss: 2.536643090996041

Epoch: 5| Step: 1
Training loss: 0.6433983759127044
Validation loss: 2.550634860521427

Epoch: 5| Step: 2
Training loss: 0.5317137601328509
Validation loss: 2.5635598554776515

Epoch: 5| Step: 3
Training loss: 0.5921209474070181
Validation loss: 2.5435100334900076

Epoch: 5| Step: 4
Training loss: 0.2905841932053384
Validation loss: 2.5438391849722093

Epoch: 5| Step: 5
Training loss: 0.64684852416917
Validation loss: 2.4962541769138813

Epoch: 5| Step: 6
Training loss: 0.6074909771928154
Validation loss: 2.4819535037334863

Epoch: 5| Step: 7
Training loss: 0.6466131859921861
Validation loss: 2.4687444692798706

Epoch: 5| Step: 8
Training loss: 0.4804597248997544
Validation loss: 2.4160576071624673

Epoch: 5| Step: 9
Training loss: 0.3870383204159676
Validation loss: 2.4380527876043905

Epoch: 5| Step: 10
Training loss: 0.3831076165653712
Validation loss: 2.4559567151108155

Epoch: 342| Step: 0
Training loss: 0.5506129988575967
Validation loss: 2.439557476874688

Epoch: 5| Step: 1
Training loss: 0.48559376988090847
Validation loss: 2.509709878887111

Epoch: 5| Step: 2
Training loss: 0.6260224562081459
Validation loss: 2.5253533272389257

Epoch: 5| Step: 3
Training loss: 0.46600892988641224
Validation loss: 2.498026871098614

Epoch: 5| Step: 4
Training loss: 0.4464938238684327
Validation loss: 2.539777772679329

Epoch: 5| Step: 5
Training loss: 0.5177436995627177
Validation loss: 2.5406931648988267

Epoch: 5| Step: 6
Training loss: 0.4614423153453044
Validation loss: 2.5082250978993423

Epoch: 5| Step: 7
Training loss: 0.5351578371344651
Validation loss: 2.5390958101345174

Epoch: 5| Step: 8
Training loss: 0.6865178809341277
Validation loss: 2.5034994326295354

Epoch: 5| Step: 9
Training loss: 0.37034129099246393
Validation loss: 2.4914079341118

Epoch: 5| Step: 10
Training loss: 0.6722527706107588
Validation loss: 2.488538480502937

Epoch: 343| Step: 0
Training loss: 0.5008520376845855
Validation loss: 2.3773208595117348

Epoch: 5| Step: 1
Training loss: 0.8113635625249073
Validation loss: 2.408071365852494

Epoch: 5| Step: 2
Training loss: 0.5709321561833661
Validation loss: 2.412274549804849

Epoch: 5| Step: 3
Training loss: 0.6525458291281532
Validation loss: 2.462086948890969

Epoch: 5| Step: 4
Training loss: 0.4645157626611622
Validation loss: 2.481346657530877

Epoch: 5| Step: 5
Training loss: 0.6356100950115806
Validation loss: 2.479455745061375

Epoch: 5| Step: 6
Training loss: 0.4942175311526701
Validation loss: 2.5126720582807347

Epoch: 5| Step: 7
Training loss: 0.4081579484535501
Validation loss: 2.490810294457496

Epoch: 5| Step: 8
Training loss: 0.31391507669422064
Validation loss: 2.5317771420454216

Epoch: 5| Step: 9
Training loss: 0.5163471482429497
Validation loss: 2.559031961227734

Epoch: 5| Step: 10
Training loss: 0.24675572387043263
Validation loss: 2.5406106489602847

Epoch: 344| Step: 0
Training loss: 0.5113349815008035
Validation loss: 2.4997409229986824

Epoch: 5| Step: 1
Training loss: 0.5994249986115183
Validation loss: 2.473311280550616

Epoch: 5| Step: 2
Training loss: 0.4623611899152048
Validation loss: 2.4714954417574657

Epoch: 5| Step: 3
Training loss: 0.5845665214968799
Validation loss: 2.464162911629298

Epoch: 5| Step: 4
Training loss: 0.447291427600988
Validation loss: 2.441826121069516

Epoch: 5| Step: 5
Training loss: 0.28511743411988866
Validation loss: 2.474891993317479

Epoch: 5| Step: 6
Training loss: 0.2674411228038857
Validation loss: 2.5317000507180856

Epoch: 5| Step: 7
Training loss: 0.5591533765288893
Validation loss: 2.5034102990695106

Epoch: 5| Step: 8
Training loss: 0.6747370684650589
Validation loss: 2.5638704394505587

Epoch: 5| Step: 9
Training loss: 0.6081964638209884
Validation loss: 2.5651142622167744

Epoch: 5| Step: 10
Training loss: 0.7181971538473496
Validation loss: 2.5758454587629394

Epoch: 345| Step: 0
Training loss: 0.586474820769725
Validation loss: 2.55027036446048

Epoch: 5| Step: 1
Training loss: 0.5827272081733509
Validation loss: 2.562589016060307

Epoch: 5| Step: 2
Training loss: 0.5481254450623326
Validation loss: 2.525509920130645

Epoch: 5| Step: 3
Training loss: 0.38760838146561394
Validation loss: 2.538676774958815

Epoch: 5| Step: 4
Training loss: 0.4428088092852057
Validation loss: 2.4870298696893447

Epoch: 5| Step: 5
Training loss: 0.5875532379783789
Validation loss: 2.4906781247476575

Epoch: 5| Step: 6
Training loss: 0.5362090454379426
Validation loss: 2.5104890139882703

Epoch: 5| Step: 7
Training loss: 0.6657196908856503
Validation loss: 2.4823682887734297

Epoch: 5| Step: 8
Training loss: 0.35468948800626354
Validation loss: 2.474054661652707

Epoch: 5| Step: 9
Training loss: 0.2782034779315821
Validation loss: 2.4817472308120663

Epoch: 5| Step: 10
Training loss: 0.6058106226339545
Validation loss: 2.4651397552822454

Epoch: 346| Step: 0
Training loss: 0.4370647717884208
Validation loss: 2.5259417339145442

Epoch: 5| Step: 1
Training loss: 0.531062064868434
Validation loss: 2.5143439179230445

Epoch: 5| Step: 2
Training loss: 0.5033836316035776
Validation loss: 2.5187539318048633

Epoch: 5| Step: 3
Training loss: 0.668954868666061
Validation loss: 2.5012378519858514

Epoch: 5| Step: 4
Training loss: 0.4917778550788521
Validation loss: 2.5111331059503574

Epoch: 5| Step: 5
Training loss: 0.6281910259029081
Validation loss: 2.478640777604317

Epoch: 5| Step: 6
Training loss: 0.5295104830967616
Validation loss: 2.4780284083006614

Epoch: 5| Step: 7
Training loss: 0.5428664570785559
Validation loss: 2.488710869873832

Epoch: 5| Step: 8
Training loss: 0.5745831585368149
Validation loss: 2.466541521065049

Epoch: 5| Step: 9
Training loss: 0.43073925996676177
Validation loss: 2.5326720420660553

Epoch: 5| Step: 10
Training loss: 0.18965800503798555
Validation loss: 2.5112041429188046

Epoch: 347| Step: 0
Training loss: 0.35662768153490465
Validation loss: 2.4784481144407975

Epoch: 5| Step: 1
Training loss: 0.547141936413283
Validation loss: 2.479637385334015

Epoch: 5| Step: 2
Training loss: 0.6886897845868649
Validation loss: 2.5005679500621345

Epoch: 5| Step: 3
Training loss: 0.6266962160801849
Validation loss: 2.5078121902546897

Epoch: 5| Step: 4
Training loss: 0.6246732811504655
Validation loss: 2.5123400938953693

Epoch: 5| Step: 5
Training loss: 0.4283876699216383
Validation loss: 2.5037977147655543

Epoch: 5| Step: 6
Training loss: 0.41833293058305077
Validation loss: 2.5572226882439195

Epoch: 5| Step: 7
Training loss: 0.43215640567845975
Validation loss: 2.550177107396496

Epoch: 5| Step: 8
Training loss: 0.5547951070077449
Validation loss: 2.5130525844038227

Epoch: 5| Step: 9
Training loss: 0.3656371440663887
Validation loss: 2.54049216686058

Epoch: 5| Step: 10
Training loss: 0.49792667509206034
Validation loss: 2.523286759650894

Epoch: 348| Step: 0
Training loss: 0.44277763011345717
Validation loss: 2.5196311448200484

Epoch: 5| Step: 1
Training loss: 0.5161125594524725
Validation loss: 2.5135256619438535

Epoch: 5| Step: 2
Training loss: 0.60683628815247
Validation loss: 2.4523754240490296

Epoch: 5| Step: 3
Training loss: 0.5910285015430563
Validation loss: 2.486657578255613

Epoch: 5| Step: 4
Training loss: 0.3953566462477606
Validation loss: 2.450177565086264

Epoch: 5| Step: 5
Training loss: 0.3546792369669851
Validation loss: 2.4565158930009243

Epoch: 5| Step: 6
Training loss: 0.5831338053014989
Validation loss: 2.4712391500269955

Epoch: 5| Step: 7
Training loss: 0.5373068429174978
Validation loss: 2.458019173600141

Epoch: 5| Step: 8
Training loss: 0.43997192276973635
Validation loss: 2.485505942340316

Epoch: 5| Step: 9
Training loss: 0.6651171667809532
Validation loss: 2.494493094169616

Epoch: 5| Step: 10
Training loss: 0.2881530683503355
Validation loss: 2.5134142424541808

Epoch: 349| Step: 0
Training loss: 0.35023774519181033
Validation loss: 2.497354125594075

Epoch: 5| Step: 1
Training loss: 0.3749626061551114
Validation loss: 2.514515621900348

Epoch: 5| Step: 2
Training loss: 0.462276824382268
Validation loss: 2.4550596297132263

Epoch: 5| Step: 3
Training loss: 0.2808681783768756
Validation loss: 2.4932493836276244

Epoch: 5| Step: 4
Training loss: 0.6411777995549205
Validation loss: 2.4860000625269922

Epoch: 5| Step: 5
Training loss: 0.3108760840178864
Validation loss: 2.4419072077182546

Epoch: 5| Step: 6
Training loss: 0.6090851852631356
Validation loss: 2.4857835089965574

Epoch: 5| Step: 7
Training loss: 0.466155565327188
Validation loss: 2.464124463423617

Epoch: 5| Step: 8
Training loss: 0.5143234993331763
Validation loss: 2.4812704273764514

Epoch: 5| Step: 9
Training loss: 0.4602452106330243
Validation loss: 2.5044112173130166

Epoch: 5| Step: 10
Training loss: 0.8324382305999856
Validation loss: 2.5130965404061616

Epoch: 350| Step: 0
Training loss: 0.5583918813592093
Validation loss: 2.5155470712512553

Epoch: 5| Step: 1
Training loss: 0.5197680514468354
Validation loss: 2.5107041707767968

Epoch: 5| Step: 2
Training loss: 0.3613183303742678
Validation loss: 2.5433979020424355

Epoch: 5| Step: 3
Training loss: 0.48264900451536946
Validation loss: 2.5096928654220516

Epoch: 5| Step: 4
Training loss: 0.3816557554215085
Validation loss: 2.4861000631225973

Epoch: 5| Step: 5
Training loss: 0.5013355656791422
Validation loss: 2.4338106711750847

Epoch: 5| Step: 6
Training loss: 0.49449859439005944
Validation loss: 2.437813676876568

Epoch: 5| Step: 7
Training loss: 0.5115371556607352
Validation loss: 2.4013732449154155

Epoch: 5| Step: 8
Training loss: 0.590203939444626
Validation loss: 2.4002642558258427

Epoch: 5| Step: 9
Training loss: 0.5634122444877903
Validation loss: 2.362861326832363

Epoch: 5| Step: 10
Training loss: 0.3885871373109754
Validation loss: 2.372981704039159

Epoch: 351| Step: 0
Training loss: 0.3860930380357317
Validation loss: 2.4207642198145556

Epoch: 5| Step: 1
Training loss: 0.6399628077816558
Validation loss: 2.399709117196292

Epoch: 5| Step: 2
Training loss: 0.3566848368153428
Validation loss: 2.394801594925309

Epoch: 5| Step: 3
Training loss: 0.5003817412327072
Validation loss: 2.445223804615995

Epoch: 5| Step: 4
Training loss: 0.5410292861260331
Validation loss: 2.4199930416438677

Epoch: 5| Step: 5
Training loss: 0.5841821954253098
Validation loss: 2.4246603312087402

Epoch: 5| Step: 6
Training loss: 0.4158630091157051
Validation loss: 2.4179335347474766

Epoch: 5| Step: 7
Training loss: 0.28343304476028097
Validation loss: 2.4567711307030202

Epoch: 5| Step: 8
Training loss: 0.7087224471238299
Validation loss: 2.4594388186074423

Epoch: 5| Step: 9
Training loss: 0.42044942674637453
Validation loss: 2.4704194286991834

Epoch: 5| Step: 10
Training loss: 0.45655308676538775
Validation loss: 2.474009933235804

Epoch: 352| Step: 0
Training loss: 0.17808609002088613
Validation loss: 2.474331723043074

Epoch: 5| Step: 1
Training loss: 0.5094547419938444
Validation loss: 2.4796425257662826

Epoch: 5| Step: 2
Training loss: 0.7434582322297743
Validation loss: 2.499848765239065

Epoch: 5| Step: 3
Training loss: 0.6660795880252202
Validation loss: 2.5128510914461644

Epoch: 5| Step: 4
Training loss: 0.5581725072772509
Validation loss: 2.508518470644863

Epoch: 5| Step: 5
Training loss: 0.3663593042552309
Validation loss: 2.4390329894266425

Epoch: 5| Step: 6
Training loss: 0.25681271466181
Validation loss: 2.402519827758727

Epoch: 5| Step: 7
Training loss: 0.48858052047029527
Validation loss: 2.3902433829259344

Epoch: 5| Step: 8
Training loss: 0.5683636222759312
Validation loss: 2.3963752493946453

Epoch: 5| Step: 9
Training loss: 0.34291335725210964
Validation loss: 2.41266494961531

Epoch: 5| Step: 10
Training loss: 0.3937839569102897
Validation loss: 2.43742080614518

Epoch: 353| Step: 0
Training loss: 0.5771702537996124
Validation loss: 2.4303938376384724

Epoch: 5| Step: 1
Training loss: 0.5261381142709048
Validation loss: 2.4383672702168084

Epoch: 5| Step: 2
Training loss: 0.6111466988643613
Validation loss: 2.4455136483708855

Epoch: 5| Step: 3
Training loss: 0.5468713760255902
Validation loss: 2.466514818555679

Epoch: 5| Step: 4
Training loss: 0.3468180635480021
Validation loss: 2.495506357058928

Epoch: 5| Step: 5
Training loss: 0.4259123644055772
Validation loss: 2.474109326317037

Epoch: 5| Step: 6
Training loss: 0.33953358757804847
Validation loss: 2.4865605250262988

Epoch: 5| Step: 7
Training loss: 0.5147305736108991
Validation loss: 2.4618506973555307

Epoch: 5| Step: 8
Training loss: 0.5414774607056089
Validation loss: 2.4667242250556014

Epoch: 5| Step: 9
Training loss: 0.46481781574639636
Validation loss: 2.4218186418563326

Epoch: 5| Step: 10
Training loss: 0.3816085684831471
Validation loss: 2.454894375158839

Epoch: 354| Step: 0
Training loss: 0.4928462146747958
Validation loss: 2.435178652088637

Epoch: 5| Step: 1
Training loss: 0.17940298651308645
Validation loss: 2.4043039070705574

Epoch: 5| Step: 2
Training loss: 0.4496156680464612
Validation loss: 2.4065265770910007

Epoch: 5| Step: 3
Training loss: 0.6432324819955574
Validation loss: 2.40417896986383

Epoch: 5| Step: 4
Training loss: 0.7924858840503516
Validation loss: 2.460302213806322

Epoch: 5| Step: 5
Training loss: 0.4737618811232251
Validation loss: 2.449036012439114

Epoch: 5| Step: 6
Training loss: 0.4748866366331046
Validation loss: 2.4566700541718265

Epoch: 5| Step: 7
Training loss: 0.22019045709545737
Validation loss: 2.493952216338979

Epoch: 5| Step: 8
Training loss: 0.38991497360049976
Validation loss: 2.4825375222136987

Epoch: 5| Step: 9
Training loss: 0.3909615783228784
Validation loss: 2.4719985486112037

Epoch: 5| Step: 10
Training loss: 0.4840771466890474
Validation loss: 2.4737243051160385

Epoch: 355| Step: 0
Training loss: 0.44387580606059196
Validation loss: 2.470531998586417

Epoch: 5| Step: 1
Training loss: 0.3939577409923719
Validation loss: 2.449162611792536

Epoch: 5| Step: 2
Training loss: 0.364493470243356
Validation loss: 2.4677985686549526

Epoch: 5| Step: 3
Training loss: 0.5130375473733646
Validation loss: 2.5091443700265623

Epoch: 5| Step: 4
Training loss: 0.24794064146743708
Validation loss: 2.4948578814036275

Epoch: 5| Step: 5
Training loss: 0.5258518732714931
Validation loss: 2.5171249504804427

Epoch: 5| Step: 6
Training loss: 0.6686486470435206
Validation loss: 2.493487074000455

Epoch: 5| Step: 7
Training loss: 0.500112699682052
Validation loss: 2.5104709871774102

Epoch: 5| Step: 8
Training loss: 0.5334138558616692
Validation loss: 2.519908998621779

Epoch: 5| Step: 9
Training loss: 0.5242722530890218
Validation loss: 2.5189211277818866

Epoch: 5| Step: 10
Training loss: 0.4602119263157164
Validation loss: 2.5066495088686276

Epoch: 356| Step: 0
Training loss: 0.4793439430063835
Validation loss: 2.4480482116277833

Epoch: 5| Step: 1
Training loss: 0.5654713775076198
Validation loss: 2.465672713339409

Epoch: 5| Step: 2
Training loss: 0.5792560339207156
Validation loss: 2.4139473891604855

Epoch: 5| Step: 3
Training loss: 0.46379226882662894
Validation loss: 2.4568667369200243

Epoch: 5| Step: 4
Training loss: 0.5208844795545381
Validation loss: 2.4618557301800394

Epoch: 5| Step: 5
Training loss: 0.46402551458661223
Validation loss: 2.4505961572010557

Epoch: 5| Step: 6
Training loss: 0.44164757334926646
Validation loss: 2.4547540029098123

Epoch: 5| Step: 7
Training loss: 0.5037702036703631
Validation loss: 2.4785975996355263

Epoch: 5| Step: 8
Training loss: 0.3689375020821539
Validation loss: 2.497073956111448

Epoch: 5| Step: 9
Training loss: 0.5449630010802446
Validation loss: 2.5055304759275248

Epoch: 5| Step: 10
Training loss: 0.3946045722435033
Validation loss: 2.5224101502017837

Epoch: 357| Step: 0
Training loss: 0.5111162263878025
Validation loss: 2.4908590526633034

Epoch: 5| Step: 1
Training loss: 0.6258799319140571
Validation loss: 2.5514960257164447

Epoch: 5| Step: 2
Training loss: 0.40277056600793687
Validation loss: 2.561405174103658

Epoch: 5| Step: 3
Training loss: 0.5138074746665118
Validation loss: 2.5220806344939355

Epoch: 5| Step: 4
Training loss: 0.4818596749398338
Validation loss: 2.4758848831103366

Epoch: 5| Step: 5
Training loss: 0.2989816458293193
Validation loss: 2.4526539231303808

Epoch: 5| Step: 6
Training loss: 0.45727307695331987
Validation loss: 2.463526706840484

Epoch: 5| Step: 7
Training loss: 0.6956804566328828
Validation loss: 2.4576840371419957

Epoch: 5| Step: 8
Training loss: 0.4746148065954787
Validation loss: 2.4856283914216775

Epoch: 5| Step: 9
Training loss: 0.16067993214604798
Validation loss: 2.500045392434454

Epoch: 5| Step: 10
Training loss: 0.48234786110656147
Validation loss: 2.452253356770284

Epoch: 358| Step: 0
Training loss: 0.5191406272962813
Validation loss: 2.4659085685492665

Epoch: 5| Step: 1
Training loss: 0.4008235172938816
Validation loss: 2.4352091617203535

Epoch: 5| Step: 2
Training loss: 0.4554015716949049
Validation loss: 2.492692067523156

Epoch: 5| Step: 3
Training loss: 0.4869031608820926
Validation loss: 2.4675904153643757

Epoch: 5| Step: 4
Training loss: 0.48503821099565936
Validation loss: 2.4690091807178205

Epoch: 5| Step: 5
Training loss: 0.593501716702878
Validation loss: 2.477823009317545

Epoch: 5| Step: 6
Training loss: 0.35492478134574157
Validation loss: 2.478915245651782

Epoch: 5| Step: 7
Training loss: 0.3991254402597868
Validation loss: 2.5021056772439847

Epoch: 5| Step: 8
Training loss: 0.45693817168989814
Validation loss: 2.471982073629505

Epoch: 5| Step: 9
Training loss: 0.39024353474815565
Validation loss: 2.498870024086585

Epoch: 5| Step: 10
Training loss: 0.6233268037197328
Validation loss: 2.51580901285967

Epoch: 359| Step: 0
Training loss: 0.40419716457776755
Validation loss: 2.4917368294123405

Epoch: 5| Step: 1
Training loss: 0.48527091755167046
Validation loss: 2.4987070370226783

Epoch: 5| Step: 2
Training loss: 0.4837477837740972
Validation loss: 2.472091056819533

Epoch: 5| Step: 3
Training loss: 0.4630068057767067
Validation loss: 2.4988169270349334

Epoch: 5| Step: 4
Training loss: 0.5784329805450047
Validation loss: 2.40989082749528

Epoch: 5| Step: 5
Training loss: 0.3580451284087545
Validation loss: 2.4211846486114936

Epoch: 5| Step: 6
Training loss: 0.5064669167897401
Validation loss: 2.4416513065856096

Epoch: 5| Step: 7
Training loss: 0.36553021041801864
Validation loss: 2.4173141924933876

Epoch: 5| Step: 8
Training loss: 0.4624408033221797
Validation loss: 2.427688435181135

Epoch: 5| Step: 9
Training loss: 0.6107668996995378
Validation loss: 2.455222523790037

Epoch: 5| Step: 10
Training loss: 0.25098941636474104
Validation loss: 2.4152955616562393

Epoch: 360| Step: 0
Training loss: 0.4264582230543408
Validation loss: 2.4425309541839417

Epoch: 5| Step: 1
Training loss: 0.37584999232929683
Validation loss: 2.4254250824002064

Epoch: 5| Step: 2
Training loss: 0.2874572359290747
Validation loss: 2.467853859619212

Epoch: 5| Step: 3
Training loss: 0.5340602538997411
Validation loss: 2.4705956609434603

Epoch: 5| Step: 4
Training loss: 0.43620780440174034
Validation loss: 2.4759811661586593

Epoch: 5| Step: 5
Training loss: 0.22793274904367092
Validation loss: 2.4963791580533994

Epoch: 5| Step: 6
Training loss: 0.4293906486913502
Validation loss: 2.501317759814576

Epoch: 5| Step: 7
Training loss: 0.6492536074097849
Validation loss: 2.486354761651428

Epoch: 5| Step: 8
Training loss: 0.45970418773989996
Validation loss: 2.470824800097646

Epoch: 5| Step: 9
Training loss: 0.5099373889805621
Validation loss: 2.491307146866379

Epoch: 5| Step: 10
Training loss: 0.608444652975755
Validation loss: 2.4743205958848784

Epoch: 361| Step: 0
Training loss: 0.39870457019731603
Validation loss: 2.4808170509763716

Epoch: 5| Step: 1
Training loss: 0.2915653055471055
Validation loss: 2.4544862275863837

Epoch: 5| Step: 2
Training loss: 0.3444766795046778
Validation loss: 2.45118758726001

Epoch: 5| Step: 3
Training loss: 0.41115713160844275
Validation loss: 2.4320894303807132

Epoch: 5| Step: 4
Training loss: 0.3323363417107762
Validation loss: 2.45743729634273

Epoch: 5| Step: 5
Training loss: 0.509038823597568
Validation loss: 2.457552919112746

Epoch: 5| Step: 6
Training loss: 0.2754418751529483
Validation loss: 2.4517241104898466

Epoch: 5| Step: 7
Training loss: 0.4873487188899864
Validation loss: 2.5008248291314974

Epoch: 5| Step: 8
Training loss: 0.7532445741439665
Validation loss: 2.5247002535694802

Epoch: 5| Step: 9
Training loss: 0.4107592192350644
Validation loss: 2.518564075588188

Epoch: 5| Step: 10
Training loss: 0.5711742840093758
Validation loss: 2.555863009789877

Epoch: 362| Step: 0
Training loss: 0.5533012745036426
Validation loss: 2.5010091995525214

Epoch: 5| Step: 1
Training loss: 0.2670094649801762
Validation loss: 2.5103281170850678

Epoch: 5| Step: 2
Training loss: 0.581727146863724
Validation loss: 2.4680798915141557

Epoch: 5| Step: 3
Training loss: 0.3961290166981643
Validation loss: 2.45075587398373

Epoch: 5| Step: 4
Training loss: 0.25433347412285046
Validation loss: 2.4339463544676327

Epoch: 5| Step: 5
Training loss: 0.5168544100035684
Validation loss: 2.443334453613676

Epoch: 5| Step: 6
Training loss: 0.5750135772594812
Validation loss: 2.4784936895451692

Epoch: 5| Step: 7
Training loss: 0.5316011446406611
Validation loss: 2.4387122674356285

Epoch: 5| Step: 8
Training loss: 0.2191307041826085
Validation loss: 2.550088559840134

Epoch: 5| Step: 9
Training loss: 0.3086654121149087
Validation loss: 2.53860138169626

Epoch: 5| Step: 10
Training loss: 0.5946599111807649
Validation loss: 2.584374243557886

Epoch: 363| Step: 0
Training loss: 0.4311439280050419
Validation loss: 2.557115285115697

Epoch: 5| Step: 1
Training loss: 0.4918973763985491
Validation loss: 2.5882706708999454

Epoch: 5| Step: 2
Training loss: 0.36528124992950856
Validation loss: 2.559434542340902

Epoch: 5| Step: 3
Training loss: 0.5015528526447879
Validation loss: 2.486570531879415

Epoch: 5| Step: 4
Training loss: 0.45375078660986107
Validation loss: 2.4814080959961013

Epoch: 5| Step: 5
Training loss: 0.3933795132070535
Validation loss: 2.4814486680843895

Epoch: 5| Step: 6
Training loss: 0.32196345178731733
Validation loss: 2.460841997243165

Epoch: 5| Step: 7
Training loss: 0.49005395677356883
Validation loss: 2.4956707509091256

Epoch: 5| Step: 8
Training loss: 0.5443479735785846
Validation loss: 2.4807021185252784

Epoch: 5| Step: 9
Training loss: 0.40630971029603413
Validation loss: 2.5028415251645497

Epoch: 5| Step: 10
Training loss: 0.45534928065279084
Validation loss: 2.4756110209309337

Epoch: 364| Step: 0
Training loss: 0.3832179860879911
Validation loss: 2.4757732949163245

Epoch: 5| Step: 1
Training loss: 0.5879263629379595
Validation loss: 2.513335344485079

Epoch: 5| Step: 2
Training loss: 0.5034291870169636
Validation loss: 2.518537865603362

Epoch: 5| Step: 3
Training loss: 0.5615537950353714
Validation loss: 2.4716239017909296

Epoch: 5| Step: 4
Training loss: 0.40194747446312845
Validation loss: 2.450304449676887

Epoch: 5| Step: 5
Training loss: 0.22635748235980743
Validation loss: 2.435937078545994

Epoch: 5| Step: 6
Training loss: 0.3666485828939821
Validation loss: 2.4358402782714164

Epoch: 5| Step: 7
Training loss: 0.3044867465528378
Validation loss: 2.5033924496520203

Epoch: 5| Step: 8
Training loss: 0.4594114710803881
Validation loss: 2.4705240446974917

Epoch: 5| Step: 9
Training loss: 0.49656939795224064
Validation loss: 2.4980078892061854

Epoch: 5| Step: 10
Training loss: 0.3962907553270487
Validation loss: 2.4617624030910843

Epoch: 365| Step: 0
Training loss: 0.23153581740953116
Validation loss: 2.488748623040653

Epoch: 5| Step: 1
Training loss: 0.3614433311112087
Validation loss: 2.4967328719379345

Epoch: 5| Step: 2
Training loss: 0.6088484910407285
Validation loss: 2.469862314936712

Epoch: 5| Step: 3
Training loss: 0.3281592623669817
Validation loss: 2.4737964919584714

Epoch: 5| Step: 4
Training loss: 0.3468517145297053
Validation loss: 2.46899537040156

Epoch: 5| Step: 5
Training loss: 0.42260012298046007
Validation loss: 2.4502774310666964

Epoch: 5| Step: 6
Training loss: 0.5482777452506334
Validation loss: 2.4515081934731184

Epoch: 5| Step: 7
Training loss: 0.3055397731625748
Validation loss: 2.439888208324069

Epoch: 5| Step: 8
Training loss: 0.4833394486626894
Validation loss: 2.4563452560564523

Epoch: 5| Step: 9
Training loss: 0.4687165566276149
Validation loss: 2.4440968928843247

Epoch: 5| Step: 10
Training loss: 0.5740481012788592
Validation loss: 2.4084136303750996

Epoch: 366| Step: 0
Training loss: 0.25046823283788794
Validation loss: 2.4562737279098297

Epoch: 5| Step: 1
Training loss: 0.27518842592415
Validation loss: 2.45048047348385

Epoch: 5| Step: 2
Training loss: 0.4998893317295084
Validation loss: 2.494156456131316

Epoch: 5| Step: 3
Training loss: 0.5589375005084557
Validation loss: 2.477461343063031

Epoch: 5| Step: 4
Training loss: 0.5163667718568365
Validation loss: 2.4817947400144873

Epoch: 5| Step: 5
Training loss: 0.36987365118298404
Validation loss: 2.502542027813287

Epoch: 5| Step: 6
Training loss: 0.43443894704600505
Validation loss: 2.4773167079313274

Epoch: 5| Step: 7
Training loss: 0.3751422095858939
Validation loss: 2.4690295417209907

Epoch: 5| Step: 8
Training loss: 0.45447339657182173
Validation loss: 2.5004885760110853

Epoch: 5| Step: 9
Training loss: 0.36355164422203917
Validation loss: 2.464262801229661

Epoch: 5| Step: 10
Training loss: 0.646486656899473
Validation loss: 2.4695668134206676

Epoch: 367| Step: 0
Training loss: 0.36603077843889
Validation loss: 2.4671722392310245

Epoch: 5| Step: 1
Training loss: 0.6667385708258784
Validation loss: 2.5129548387354186

Epoch: 5| Step: 2
Training loss: 0.33730204260340807
Validation loss: 2.4956993921143065

Epoch: 5| Step: 3
Training loss: 0.38970619863450723
Validation loss: 2.5203967708378574

Epoch: 5| Step: 4
Training loss: 0.38513485382880586
Validation loss: 2.5091959428097104

Epoch: 5| Step: 5
Training loss: 0.41891262398195683
Validation loss: 2.5098327068501103

Epoch: 5| Step: 6
Training loss: 0.39881604108148533
Validation loss: 2.4571611381270846

Epoch: 5| Step: 7
Training loss: 0.41680475172127546
Validation loss: 2.429666420484717

Epoch: 5| Step: 8
Training loss: 0.6142095355786441
Validation loss: 2.4323870491799586

Epoch: 5| Step: 9
Training loss: 0.36913121933030035
Validation loss: 2.4802813906775665

Epoch: 5| Step: 10
Training loss: 0.36340254122670096
Validation loss: 2.4581846029161123

Epoch: 368| Step: 0
Training loss: 0.37724802607733415
Validation loss: 2.4603943271718065

Epoch: 5| Step: 1
Training loss: 0.5823372158280673
Validation loss: 2.5107106781386705

Epoch: 5| Step: 2
Training loss: 0.4150968264605268
Validation loss: 2.5285256279937265

Epoch: 5| Step: 3
Training loss: 0.24743037317326796
Validation loss: 2.5063155950362814

Epoch: 5| Step: 4
Training loss: 0.4050529523659248
Validation loss: 2.4864398065837356

Epoch: 5| Step: 5
Training loss: 0.1421300496900284
Validation loss: 2.4543281877106913

Epoch: 5| Step: 6
Training loss: 0.48789156813641077
Validation loss: 2.4726176316314903

Epoch: 5| Step: 7
Training loss: 0.406293426540114
Validation loss: 2.4829876240850504

Epoch: 5| Step: 8
Training loss: 0.43464214288509795
Validation loss: 2.415592447782237

Epoch: 5| Step: 9
Training loss: 0.6014523095610071
Validation loss: 2.405826059814478

Epoch: 5| Step: 10
Training loss: 0.4513306606671176
Validation loss: 2.3905854891791365

Epoch: 369| Step: 0
Training loss: 0.2686348119330983
Validation loss: 2.3658882961144716

Epoch: 5| Step: 1
Training loss: 0.27850338452849144
Validation loss: 2.4073422715871176

Epoch: 5| Step: 2
Training loss: 0.6792574870539684
Validation loss: 2.4092216472582333

Epoch: 5| Step: 3
Training loss: 0.16098556726638616
Validation loss: 2.42825905200757

Epoch: 5| Step: 4
Training loss: 0.34558462277870877
Validation loss: 2.4493817206184954

Epoch: 5| Step: 5
Training loss: 0.3675390346388026
Validation loss: 2.505848015956163

Epoch: 5| Step: 6
Training loss: 0.48011763854715955
Validation loss: 2.4716910728824124

Epoch: 5| Step: 7
Training loss: 0.5605007777383055
Validation loss: 2.490160849907565

Epoch: 5| Step: 8
Training loss: 0.4801585584014609
Validation loss: 2.5003230880830416

Epoch: 5| Step: 9
Training loss: 0.23163961953882523
Validation loss: 2.480322645795521

Epoch: 5| Step: 10
Training loss: 0.5640706809340892
Validation loss: 2.4485321419693613

Epoch: 370| Step: 0
Training loss: 0.5922362204366116
Validation loss: 2.4364359120899466

Epoch: 5| Step: 1
Training loss: 0.2443944984350043
Validation loss: 2.4541298970189285

Epoch: 5| Step: 2
Training loss: 0.3192460169749083
Validation loss: 2.478952467004702

Epoch: 5| Step: 3
Training loss: 0.3435247506896077
Validation loss: 2.4852845605013187

Epoch: 5| Step: 4
Training loss: 0.36507779605262086
Validation loss: 2.468446206378116

Epoch: 5| Step: 5
Training loss: 0.30778099421648264
Validation loss: 2.4297125993465

Epoch: 5| Step: 6
Training loss: 0.5097133565831009
Validation loss: 2.4543133322371475

Epoch: 5| Step: 7
Training loss: 0.42938513087241253
Validation loss: 2.4265915623628813

Epoch: 5| Step: 8
Training loss: 0.673159945261828
Validation loss: 2.4405915748446287

Epoch: 5| Step: 9
Training loss: 0.43263160216554847
Validation loss: 2.4505379132557445

Epoch: 5| Step: 10
Training loss: 0.1925462909254078
Validation loss: 2.4555485353106716

Epoch: 371| Step: 0
Training loss: 0.3320544627434143
Validation loss: 2.441426024785506

Epoch: 5| Step: 1
Training loss: 0.366646916587263
Validation loss: 2.4384543972341945

Epoch: 5| Step: 2
Training loss: 0.16769066790625003
Validation loss: 2.4241047080056837

Epoch: 5| Step: 3
Training loss: 0.3646249838153259
Validation loss: 2.402946466325558

Epoch: 5| Step: 4
Training loss: 0.48558631301017174
Validation loss: 2.395841752760237

Epoch: 5| Step: 5
Training loss: 0.4991235651243523
Validation loss: 2.4637542059191277

Epoch: 5| Step: 6
Training loss: 0.565923998506825
Validation loss: 2.4619874869690617

Epoch: 5| Step: 7
Training loss: 0.4460947126922642
Validation loss: 2.422994597662164

Epoch: 5| Step: 8
Training loss: 0.2412386967056734
Validation loss: 2.453970118812839

Epoch: 5| Step: 9
Training loss: 0.5121363617444662
Validation loss: 2.4749555942798254

Epoch: 5| Step: 10
Training loss: 0.46432843214843156
Validation loss: 2.5118190208429008

Epoch: 372| Step: 0
Training loss: 0.49065867144460495
Validation loss: 2.4640686325563017

Epoch: 5| Step: 1
Training loss: 0.4678546301473703
Validation loss: 2.503331918390643

Epoch: 5| Step: 2
Training loss: 0.47414732054154735
Validation loss: 2.4590234821859465

Epoch: 5| Step: 3
Training loss: 0.5522680303532289
Validation loss: 2.467846382226182

Epoch: 5| Step: 4
Training loss: 0.4044713367225299
Validation loss: 2.464315681034981

Epoch: 5| Step: 5
Training loss: 0.36569364506512225
Validation loss: 2.4596478097492764

Epoch: 5| Step: 6
Training loss: 0.5171242505262448
Validation loss: 2.4663736025725527

Epoch: 5| Step: 7
Training loss: 0.38058451980660357
Validation loss: 2.457351271154098

Epoch: 5| Step: 8
Training loss: 0.2141267342499997
Validation loss: 2.433084070612741

Epoch: 5| Step: 9
Training loss: 0.38191356991719244
Validation loss: 2.474692405164165

Epoch: 5| Step: 10
Training loss: 0.27271136188695355
Validation loss: 2.466207367564141

Epoch: 373| Step: 0
Training loss: 0.23954174555001248
Validation loss: 2.444711695702813

Epoch: 5| Step: 1
Training loss: 0.37135953921604414
Validation loss: 2.484644375720777

Epoch: 5| Step: 2
Training loss: 0.4021290326543253
Validation loss: 2.4820332846076623

Epoch: 5| Step: 3
Training loss: 0.4594071409438555
Validation loss: 2.4844096759159573

Epoch: 5| Step: 4
Training loss: 0.29360206815539486
Validation loss: 2.468736076601288

Epoch: 5| Step: 5
Training loss: 0.49250471398474494
Validation loss: 2.4846183310454437

Epoch: 5| Step: 6
Training loss: 0.45016154992195545
Validation loss: 2.43068522617697

Epoch: 5| Step: 7
Training loss: 0.4747735669612826
Validation loss: 2.4454186286843824

Epoch: 5| Step: 8
Training loss: 0.4473362496267238
Validation loss: 2.4450015949232573

Epoch: 5| Step: 9
Training loss: 0.4297472132026008
Validation loss: 2.464139985934097

Epoch: 5| Step: 10
Training loss: 0.42693695219214467
Validation loss: 2.4803012090132386

Epoch: 374| Step: 0
Training loss: 0.5109004692633985
Validation loss: 2.50092795592976

Epoch: 5| Step: 1
Training loss: 0.1502252263711959
Validation loss: 2.471896800932701

Epoch: 5| Step: 2
Training loss: 0.3067713659224666
Validation loss: 2.4832150436966773

Epoch: 5| Step: 3
Training loss: 0.3792793953479267
Validation loss: 2.4748859034913857

Epoch: 5| Step: 4
Training loss: 0.509586638967294
Validation loss: 2.4959288796903167

Epoch: 5| Step: 5
Training loss: 0.625603241670727
Validation loss: 2.4847267125327077

Epoch: 5| Step: 6
Training loss: 0.3142208165309942
Validation loss: 2.5032119667658885

Epoch: 5| Step: 7
Training loss: 0.4403982891385613
Validation loss: 2.462672772220039

Epoch: 5| Step: 8
Training loss: 0.3539047628544094
Validation loss: 2.446036631973927

Epoch: 5| Step: 9
Training loss: 0.39394550465327105
Validation loss: 2.4557699691776778

Epoch: 5| Step: 10
Training loss: 0.32320735778323684
Validation loss: 2.411839924715469

Epoch: 375| Step: 0
Training loss: 0.28628715544690175
Validation loss: 2.4047422102499834

Epoch: 5| Step: 1
Training loss: 0.3902327284525213
Validation loss: 2.3675482544190025

Epoch: 5| Step: 2
Training loss: 0.24724117598105375
Validation loss: 2.389759763701265

Epoch: 5| Step: 3
Training loss: 0.27165415826964395
Validation loss: 2.377491675340612

Epoch: 5| Step: 4
Training loss: 0.5489454042286268
Validation loss: 2.4086777812010083

Epoch: 5| Step: 5
Training loss: 0.43134288962254275
Validation loss: 2.424092350364084

Epoch: 5| Step: 6
Training loss: 0.4350191006358394
Validation loss: 2.425807810129332

Epoch: 5| Step: 7
Training loss: 0.4317634545843444
Validation loss: 2.4391170383067515

Epoch: 5| Step: 8
Training loss: 0.5212247966829817
Validation loss: 2.444941251674593

Epoch: 5| Step: 9
Training loss: 0.42460143389816846
Validation loss: 2.4656787479408218

Epoch: 5| Step: 10
Training loss: 0.36580880020202416
Validation loss: 2.4946399202159606

Epoch: 376| Step: 0
Training loss: 0.4310074213798502
Validation loss: 2.4977719859015073

Epoch: 5| Step: 1
Training loss: 0.2545514345918032
Validation loss: 2.504912030500727

Epoch: 5| Step: 2
Training loss: 0.4913909460938407
Validation loss: 2.486443930775285

Epoch: 5| Step: 3
Training loss: 0.3561047324763035
Validation loss: 2.4777173822867247

Epoch: 5| Step: 4
Training loss: 0.15237461902188998
Validation loss: 2.4452069122887914

Epoch: 5| Step: 5
Training loss: 0.386233921734871
Validation loss: 2.467293427099927

Epoch: 5| Step: 6
Training loss: 0.6392575066714629
Validation loss: 2.446428403602331

Epoch: 5| Step: 7
Training loss: 0.41107436464624014
Validation loss: 2.4659922009508017

Epoch: 5| Step: 8
Training loss: 0.517615752381896
Validation loss: 2.446951450998658

Epoch: 5| Step: 9
Training loss: 0.3524219815172234
Validation loss: 2.456021599722143

Epoch: 5| Step: 10
Training loss: 0.23353623667747248
Validation loss: 2.4183595482585383

Epoch: 377| Step: 0
Training loss: 0.5259209264545358
Validation loss: 2.4369147002661484

Epoch: 5| Step: 1
Training loss: 0.5062129725349026
Validation loss: 2.499007731580288

Epoch: 5| Step: 2
Training loss: 0.41934693477088447
Validation loss: 2.4495013663163765

Epoch: 5| Step: 3
Training loss: 0.2874201824473311
Validation loss: 2.4381920258377368

Epoch: 5| Step: 4
Training loss: 0.30108078990574316
Validation loss: 2.4401089988481433

Epoch: 5| Step: 5
Training loss: 0.47869690555845773
Validation loss: 2.4699389615338085

Epoch: 5| Step: 6
Training loss: 0.29043554570768
Validation loss: 2.4909728971734157

Epoch: 5| Step: 7
Training loss: 0.5264386922928552
Validation loss: 2.487163793308783

Epoch: 5| Step: 8
Training loss: 0.21237323605386949
Validation loss: 2.5131841563223705

Epoch: 5| Step: 9
Training loss: 0.4080549454844962
Validation loss: 2.4791197609921456

Epoch: 5| Step: 10
Training loss: 0.3501057324615183
Validation loss: 2.471476807932289

Epoch: 378| Step: 0
Training loss: 0.5603310305695396
Validation loss: 2.4719286385948562

Epoch: 5| Step: 1
Training loss: 0.4191001303701032
Validation loss: 2.5045616985603756

Epoch: 5| Step: 2
Training loss: 0.48753791686080006
Validation loss: 2.4596497098241796

Epoch: 5| Step: 3
Training loss: 0.17991582213476418
Validation loss: 2.4608996160338497

Epoch: 5| Step: 4
Training loss: 0.47374887519139247
Validation loss: 2.456289686725555

Epoch: 5| Step: 5
Training loss: 0.5317390098601815
Validation loss: 2.39737263185159

Epoch: 5| Step: 6
Training loss: 0.4464846460002834
Validation loss: 2.4165625233287913

Epoch: 5| Step: 7
Training loss: 0.3032457524101993
Validation loss: 2.3969366651349238

Epoch: 5| Step: 8
Training loss: 0.19165334517029914
Validation loss: 2.435778160898228

Epoch: 5| Step: 9
Training loss: 0.2711585305506991
Validation loss: 2.3860212502863467

Epoch: 5| Step: 10
Training loss: 0.33149793091440405
Validation loss: 2.400501175349451

Epoch: 379| Step: 0
Training loss: 0.49866596713862765
Validation loss: 2.414726400992093

Epoch: 5| Step: 1
Training loss: 0.43928762074410166
Validation loss: 2.436185098769578

Epoch: 5| Step: 2
Training loss: 0.30005843765601364
Validation loss: 2.461174257931089

Epoch: 5| Step: 3
Training loss: 0.35039472545661304
Validation loss: 2.479256855196351

Epoch: 5| Step: 4
Training loss: 0.4298112517662278
Validation loss: 2.47069224142375

Epoch: 5| Step: 5
Training loss: 0.4038205681239718
Validation loss: 2.476870395677577

Epoch: 5| Step: 6
Training loss: 0.35503383901662905
Validation loss: 2.5094149046066483

Epoch: 5| Step: 7
Training loss: 0.24997917475985035
Validation loss: 2.5069202503017864

Epoch: 5| Step: 8
Training loss: 0.41064340634367696
Validation loss: 2.54713106079233

Epoch: 5| Step: 9
Training loss: 0.50612197599405
Validation loss: 2.50128160461586

Epoch: 5| Step: 10
Training loss: 0.36885166463979185
Validation loss: 2.49698227131359

Epoch: 380| Step: 0
Training loss: 0.49112146977189625
Validation loss: 2.4416172608114404

Epoch: 5| Step: 1
Training loss: 0.4579092541940191
Validation loss: 2.4313392349258773

Epoch: 5| Step: 2
Training loss: 0.3184047970811179
Validation loss: 2.458803652960762

Epoch: 5| Step: 3
Training loss: 0.5355816006966551
Validation loss: 2.483605714923787

Epoch: 5| Step: 4
Training loss: 0.23463979703573332
Validation loss: 2.466915040065102

Epoch: 5| Step: 5
Training loss: 0.48680979457333157
Validation loss: 2.4781414679089107

Epoch: 5| Step: 6
Training loss: 0.3718469104255845
Validation loss: 2.504361936268062

Epoch: 5| Step: 7
Training loss: 0.1112161499868011
Validation loss: 2.4387579932871057

Epoch: 5| Step: 8
Training loss: 0.31772477727556986
Validation loss: 2.4810125373551033

Epoch: 5| Step: 9
Training loss: 0.5563057410782403
Validation loss: 2.458652998710803

Epoch: 5| Step: 10
Training loss: 0.1766421535042823
Validation loss: 2.4511748500142927

Epoch: 381| Step: 0
Training loss: 0.6524320531230922
Validation loss: 2.4354949068554084

Epoch: 5| Step: 1
Training loss: 0.2569134091343865
Validation loss: 2.4555097517667748

Epoch: 5| Step: 2
Training loss: 0.4190459941825029
Validation loss: 2.4351534922244915

Epoch: 5| Step: 3
Training loss: 0.336701732568359
Validation loss: 2.4448519849739294

Epoch: 5| Step: 4
Training loss: 0.4754083916910454
Validation loss: 2.4878805736239737

Epoch: 5| Step: 5
Training loss: 0.45524381314535156
Validation loss: 2.4536058424790608

Epoch: 5| Step: 6
Training loss: 0.3279819176562616
Validation loss: 2.450211184827515

Epoch: 5| Step: 7
Training loss: 0.3431595369408588
Validation loss: 2.456952374747252

Epoch: 5| Step: 8
Training loss: 0.36416354762181224
Validation loss: 2.4282631926654585

Epoch: 5| Step: 9
Training loss: 0.3066992126670846
Validation loss: 2.472702123659698

Epoch: 5| Step: 10
Training loss: 0.1466312498633044
Validation loss: 2.4090868439361555

Epoch: 382| Step: 0
Training loss: 0.3712741212683028
Validation loss: 2.4254917355572743

Epoch: 5| Step: 1
Training loss: 0.39241058418424285
Validation loss: 2.4646234860660616

Epoch: 5| Step: 2
Training loss: 0.400758546331162
Validation loss: 2.4229264860278965

Epoch: 5| Step: 3
Training loss: 0.3863590378538632
Validation loss: 2.4553618136700983

Epoch: 5| Step: 4
Training loss: 0.3084740104632525
Validation loss: 2.4233100601022994

Epoch: 5| Step: 5
Training loss: 0.36363783122844834
Validation loss: 2.4056018094275102

Epoch: 5| Step: 6
Training loss: 0.47139952811916297
Validation loss: 2.4386574137841306

Epoch: 5| Step: 7
Training loss: 0.2773453484072764
Validation loss: 2.456149698477692

Epoch: 5| Step: 8
Training loss: 0.5147704643917088
Validation loss: 2.4317879862915452

Epoch: 5| Step: 9
Training loss: 0.4397129392822164
Validation loss: 2.4669376339269617

Epoch: 5| Step: 10
Training loss: 0.3143444347311561
Validation loss: 2.4583211460162517

Epoch: 383| Step: 0
Training loss: 0.3926471251016827
Validation loss: 2.4532282331869077

Epoch: 5| Step: 1
Training loss: 0.3756389340499533
Validation loss: 2.433867026023533

Epoch: 5| Step: 2
Training loss: 0.2951484214265522
Validation loss: 2.3932292505777752

Epoch: 5| Step: 3
Training loss: 0.31991465214551046
Validation loss: 2.3812589237027733

Epoch: 5| Step: 4
Training loss: 0.5043616787310591
Validation loss: 2.4060619458154244

Epoch: 5| Step: 5
Training loss: 0.2997498850484187
Validation loss: 2.415427547096642

Epoch: 5| Step: 6
Training loss: 0.20692230453049115
Validation loss: 2.4399281879127503

Epoch: 5| Step: 7
Training loss: 0.45239137586587247
Validation loss: 2.4535544302852634

Epoch: 5| Step: 8
Training loss: 0.5055487721230286
Validation loss: 2.4600986450196647

Epoch: 5| Step: 9
Training loss: 0.15228758290064776
Validation loss: 2.540601313076115

Epoch: 5| Step: 10
Training loss: 0.535750455997645
Validation loss: 2.475662739300977

Epoch: 384| Step: 0
Training loss: 0.4376660270375132
Validation loss: 2.484767622495768

Epoch: 5| Step: 1
Training loss: 0.2828236372214252
Validation loss: 2.4894162732670666

Epoch: 5| Step: 2
Training loss: 0.34941590139673845
Validation loss: 2.4283881375497347

Epoch: 5| Step: 3
Training loss: 0.25405107915904734
Validation loss: 2.468336328999848

Epoch: 5| Step: 4
Training loss: 0.5530440470621443
Validation loss: 2.4429037525527106

Epoch: 5| Step: 5
Training loss: 0.5726168859673457
Validation loss: 2.463458598193137

Epoch: 5| Step: 6
Training loss: 0.21609472720021078
Validation loss: 2.4291597401236964

Epoch: 5| Step: 7
Training loss: 0.29737192526595124
Validation loss: 2.3704568666058616

Epoch: 5| Step: 8
Training loss: 0.28633006721035625
Validation loss: 2.4537133600171344

Epoch: 5| Step: 9
Training loss: 0.4264916259797706
Validation loss: 2.441124016574616

Epoch: 5| Step: 10
Training loss: 0.3990752034865058
Validation loss: 2.434666207693452

Epoch: 385| Step: 0
Training loss: 0.6034009015814671
Validation loss: 2.4456566726280964

Epoch: 5| Step: 1
Training loss: 0.3920126300949611
Validation loss: 2.4724649951740094

Epoch: 5| Step: 2
Training loss: 0.3928291505123715
Validation loss: 2.476498913391019

Epoch: 5| Step: 3
Training loss: 0.34952232939481126
Validation loss: 2.4715483576734503

Epoch: 5| Step: 4
Training loss: 0.18739683571533797
Validation loss: 2.502318537687287

Epoch: 5| Step: 5
Training loss: 0.36109516779028256
Validation loss: 2.4786100713255723

Epoch: 5| Step: 6
Training loss: 0.3856782111701556
Validation loss: 2.4884594881970354

Epoch: 5| Step: 7
Training loss: 0.1784814497206966
Validation loss: 2.4497379737116107

Epoch: 5| Step: 8
Training loss: 0.4186073487263265
Validation loss: 2.479422743130798

Epoch: 5| Step: 9
Training loss: 0.2975344861903012
Validation loss: 2.4746963676435256

Epoch: 5| Step: 10
Training loss: 0.4762294731322162
Validation loss: 2.491565560006297

Epoch: 386| Step: 0
Training loss: 0.3295456242037728
Validation loss: 2.4824588232935163

Epoch: 5| Step: 1
Training loss: 0.3003453402867584
Validation loss: 2.423987054568519

Epoch: 5| Step: 2
Training loss: 0.38389182231715896
Validation loss: 2.436984314492828

Epoch: 5| Step: 3
Training loss: 0.5642605885470069
Validation loss: 2.4456730534547653

Epoch: 5| Step: 4
Training loss: 0.1797003430462218
Validation loss: 2.4565970447373586

Epoch: 5| Step: 5
Training loss: 0.25005497923937176
Validation loss: 2.458465867374499

Epoch: 5| Step: 6
Training loss: 0.26928567064580533
Validation loss: 2.467173629547496

Epoch: 5| Step: 7
Training loss: 0.4959513542485239
Validation loss: 2.4581697540615677

Epoch: 5| Step: 8
Training loss: 0.32288023399618054
Validation loss: 2.493181055597806

Epoch: 5| Step: 9
Training loss: 0.49534730999525095
Validation loss: 2.4677265642488875

Epoch: 5| Step: 10
Training loss: 0.4522684321182125
Validation loss: 2.4844498223530214

Epoch: 387| Step: 0
Training loss: 0.18328298483350294
Validation loss: 2.4514402351051587

Epoch: 5| Step: 1
Training loss: 0.4852518328436031
Validation loss: 2.492618296349888

Epoch: 5| Step: 2
Training loss: 0.575964680287507
Validation loss: 2.4167957448239616

Epoch: 5| Step: 3
Training loss: 0.427051521682708
Validation loss: 2.4264314964385556

Epoch: 5| Step: 4
Training loss: 0.364511723524759
Validation loss: 2.4082223005730388

Epoch: 5| Step: 5
Training loss: 0.3818086775393091
Validation loss: 2.4172930830290107

Epoch: 5| Step: 6
Training loss: 0.27450443286651716
Validation loss: 2.4168785293718678

Epoch: 5| Step: 7
Training loss: 0.29617285514715647
Validation loss: 2.4321910256490145

Epoch: 5| Step: 8
Training loss: 0.43461651502878385
Validation loss: 2.4787232786755515

Epoch: 5| Step: 9
Training loss: 0.22003915380079508
Validation loss: 2.44615255938674

Epoch: 5| Step: 10
Training loss: 0.36419736549837556
Validation loss: 2.499675779956051

Epoch: 388| Step: 0
Training loss: 0.46359606398675773
Validation loss: 2.4499405794888394

Epoch: 5| Step: 1
Training loss: 0.4116062148042045
Validation loss: 2.4435939238680655

Epoch: 5| Step: 2
Training loss: 0.30974664088760795
Validation loss: 2.4381877611467684

Epoch: 5| Step: 3
Training loss: 0.3936427848410521
Validation loss: 2.439636327103973

Epoch: 5| Step: 4
Training loss: 0.2712594342239168
Validation loss: 2.4307304839330928

Epoch: 5| Step: 5
Training loss: 0.13538425925863842
Validation loss: 2.445122344055112

Epoch: 5| Step: 6
Training loss: 0.4623419169305507
Validation loss: 2.413655486061679

Epoch: 5| Step: 7
Training loss: 0.5255202236367335
Validation loss: 2.4615746364297366

Epoch: 5| Step: 8
Training loss: 0.39138576811844394
Validation loss: 2.4208402849354242

Epoch: 5| Step: 9
Training loss: 0.40265201129688105
Validation loss: 2.4307340018126804

Epoch: 5| Step: 10
Training loss: 0.2481921138728424
Validation loss: 2.425616444301268

Epoch: 389| Step: 0
Training loss: 0.18575126032125755
Validation loss: 2.444192136362308

Epoch: 5| Step: 1
Training loss: 0.3524208398971629
Validation loss: 2.4325593466995072

Epoch: 5| Step: 2
Training loss: 0.3666525047811288
Validation loss: 2.47420306011598

Epoch: 5| Step: 3
Training loss: 0.22824889698576797
Validation loss: 2.4425519095570793

Epoch: 5| Step: 4
Training loss: 0.4501731519561491
Validation loss: 2.482032529572828

Epoch: 5| Step: 5
Training loss: 0.40533735391712594
Validation loss: 2.487266526932266

Epoch: 5| Step: 6
Training loss: 0.5046846159389041
Validation loss: 2.488682508782551

Epoch: 5| Step: 7
Training loss: 0.5320009085676136
Validation loss: 2.5203935220345093

Epoch: 5| Step: 8
Training loss: 0.2758381096036459
Validation loss: 2.440045487712648

Epoch: 5| Step: 9
Training loss: 0.2779749149241413
Validation loss: 2.4881175950649435

Epoch: 5| Step: 10
Training loss: 0.5061781184651457
Validation loss: 2.4752933418683005

Epoch: 390| Step: 0
Training loss: 0.2632057024953248
Validation loss: 2.4453311549765986

Epoch: 5| Step: 1
Training loss: 0.39579705858491754
Validation loss: 2.410750864427135

Epoch: 5| Step: 2
Training loss: 0.4076720072463261
Validation loss: 2.3764827063680976

Epoch: 5| Step: 3
Training loss: 0.4263998490045667
Validation loss: 2.393829327403069

Epoch: 5| Step: 4
Training loss: 0.38702415197991785
Validation loss: 2.40718129842706

Epoch: 5| Step: 5
Training loss: 0.5207324089177775
Validation loss: 2.3856158198697

Epoch: 5| Step: 6
Training loss: 0.18639219370154753
Validation loss: 2.4059999024605085

Epoch: 5| Step: 7
Training loss: 0.24401072288719242
Validation loss: 2.4454166846601826

Epoch: 5| Step: 8
Training loss: 0.40827733145642536
Validation loss: 2.438468550310061

Epoch: 5| Step: 9
Training loss: 0.4725622603858933
Validation loss: 2.4408302716491166

Epoch: 5| Step: 10
Training loss: 0.22866119736484072
Validation loss: 2.4503763158047493

Epoch: 391| Step: 0
Training loss: 0.3830764794545968
Validation loss: 2.4307761648196444

Epoch: 5| Step: 1
Training loss: 0.2519678510753707
Validation loss: 2.4656217518723236

Epoch: 5| Step: 2
Training loss: 0.4021470413072609
Validation loss: 2.426157649704981

Epoch: 5| Step: 3
Training loss: 0.3075749201725116
Validation loss: 2.4592137235028266

Epoch: 5| Step: 4
Training loss: 0.26186107921700186
Validation loss: 2.4773870598849985

Epoch: 5| Step: 5
Training loss: 0.3338257931789213
Validation loss: 2.4551718346088567

Epoch: 5| Step: 6
Training loss: 0.405912240544163
Validation loss: 2.4909924637228524

Epoch: 5| Step: 7
Training loss: 0.489622182183999
Validation loss: 2.508863841375821

Epoch: 5| Step: 8
Training loss: 0.378239152559906
Validation loss: 2.4638196020984964

Epoch: 5| Step: 9
Training loss: 0.20602927571025842
Validation loss: 2.4911953294843405

Epoch: 5| Step: 10
Training loss: 0.5312752998162005
Validation loss: 2.4871447924162324

Epoch: 392| Step: 0
Training loss: 0.4218658693526448
Validation loss: 2.482009844335662

Epoch: 5| Step: 1
Training loss: 0.2706767356967706
Validation loss: 2.4856901469133637

Epoch: 5| Step: 2
Training loss: 0.2323539939294738
Validation loss: 2.4191705174801

Epoch: 5| Step: 3
Training loss: 0.4722349953638045
Validation loss: 2.483377520717365

Epoch: 5| Step: 4
Training loss: 0.38022568632614834
Validation loss: 2.454253247186146

Epoch: 5| Step: 5
Training loss: 0.25059622953810134
Validation loss: 2.4289763161928297

Epoch: 5| Step: 6
Training loss: 0.3784499813198267
Validation loss: 2.4620616214688056

Epoch: 5| Step: 7
Training loss: 0.46552415946317927
Validation loss: 2.461780934454365

Epoch: 5| Step: 8
Training loss: 0.326739029421438
Validation loss: 2.477487664757459

Epoch: 5| Step: 9
Training loss: 0.4529513815701157
Validation loss: 2.420236090813068

Epoch: 5| Step: 10
Training loss: 0.2008036419149228
Validation loss: 2.4265616966021035

Epoch: 393| Step: 0
Training loss: 0.22424396977827574
Validation loss: 2.4524114765177827

Epoch: 5| Step: 1
Training loss: 0.44773916305513867
Validation loss: 2.460246938087863

Epoch: 5| Step: 2
Training loss: 0.3944469966249924
Validation loss: 2.465236448636436

Epoch: 5| Step: 3
Training loss: 0.3268922628362865
Validation loss: 2.493416401074507

Epoch: 5| Step: 4
Training loss: 0.44678191302521725
Validation loss: 2.475726171867235

Epoch: 5| Step: 5
Training loss: 0.2586043652433051
Validation loss: 2.435574635940871

Epoch: 5| Step: 6
Training loss: 0.29042687482055507
Validation loss: 2.4598521245368334

Epoch: 5| Step: 7
Training loss: 0.2841698818546947
Validation loss: 2.45450100263416

Epoch: 5| Step: 8
Training loss: 0.5061853603021549
Validation loss: 2.432501231560635

Epoch: 5| Step: 9
Training loss: 0.3999449319484275
Validation loss: 2.438055338570046

Epoch: 5| Step: 10
Training loss: 0.2707552827951962
Validation loss: 2.4319266476444037

Epoch: 394| Step: 0
Training loss: 0.34313221166498226
Validation loss: 2.467550755653576

Epoch: 5| Step: 1
Training loss: 0.4817858066465836
Validation loss: 2.46691737204929

Epoch: 5| Step: 2
Training loss: 0.2158709591778369
Validation loss: 2.4512472339435116

Epoch: 5| Step: 3
Training loss: 0.35227138258238294
Validation loss: 2.427799821161459

Epoch: 5| Step: 4
Training loss: 0.3600544104916375
Validation loss: 2.428246337546575

Epoch: 5| Step: 5
Training loss: 0.3824053954644618
Validation loss: 2.44865168051091

Epoch: 5| Step: 6
Training loss: 0.4140450275981234
Validation loss: 2.4494345988011994

Epoch: 5| Step: 7
Training loss: 0.30202584569193897
Validation loss: 2.4755508666638684

Epoch: 5| Step: 8
Training loss: 0.4802348955659541
Validation loss: 2.439518890982705

Epoch: 5| Step: 9
Training loss: 0.40489760287661786
Validation loss: 2.4576504189648567

Epoch: 5| Step: 10
Training loss: 0.11901528769679812
Validation loss: 2.448101037979786

Epoch: 395| Step: 0
Training loss: 0.4818804092202579
Validation loss: 2.4707837645910953

Epoch: 5| Step: 1
Training loss: 0.19059082451880155
Validation loss: 2.4684292143656132

Epoch: 5| Step: 2
Training loss: 0.43164148805281716
Validation loss: 2.4561619318831958

Epoch: 5| Step: 3
Training loss: 0.3856035587031817
Validation loss: 2.4262641271700067

Epoch: 5| Step: 4
Training loss: 0.17700405777304765
Validation loss: 2.4604099784530176

Epoch: 5| Step: 5
Training loss: 0.4165199339310647
Validation loss: 2.4342506391353793

Epoch: 5| Step: 6
Training loss: 0.21193308239503283
Validation loss: 2.4657862526592123

Epoch: 5| Step: 7
Training loss: 0.5315713191211887
Validation loss: 2.4489446149915084

Epoch: 5| Step: 8
Training loss: 0.24564411321924282
Validation loss: 2.4448962014015234

Epoch: 5| Step: 9
Training loss: 0.32075407248458987
Validation loss: 2.486713911764464

Epoch: 5| Step: 10
Training loss: 0.409958528363481
Validation loss: 2.4719314149137275

Epoch: 396| Step: 0
Training loss: 0.23581655162209086
Validation loss: 2.4600966171145062

Epoch: 5| Step: 1
Training loss: 0.4331884809930647
Validation loss: 2.483512819103496

Epoch: 5| Step: 2
Training loss: 0.16469032641669115
Validation loss: 2.48243689376589

Epoch: 5| Step: 3
Training loss: 0.24213466529431482
Validation loss: 2.477919437425776

Epoch: 5| Step: 4
Training loss: 0.2956388234783747
Validation loss: 2.471330304908413

Epoch: 5| Step: 5
Training loss: 0.13596872595890072
Validation loss: 2.4673250914185583

Epoch: 5| Step: 6
Training loss: 0.35619071333279645
Validation loss: 2.432462376700899

Epoch: 5| Step: 7
Training loss: 0.4488991803131387
Validation loss: 2.4333676526960004

Epoch: 5| Step: 8
Training loss: 0.44863698024914683
Validation loss: 2.4567267492043268

Epoch: 5| Step: 9
Training loss: 0.603723138484133
Validation loss: 2.4348009504373174

Epoch: 5| Step: 10
Training loss: 0.2904934005783791
Validation loss: 2.4077906444827573

Epoch: 397| Step: 0
Training loss: 0.21105383384767767
Validation loss: 2.4321739226423964

Epoch: 5| Step: 1
Training loss: 0.36927028175316395
Validation loss: 2.39333958649856

Epoch: 5| Step: 2
Training loss: 0.287918844095177
Validation loss: 2.409237340479734

Epoch: 5| Step: 3
Training loss: 0.34448017252100493
Validation loss: 2.4157781470395707

Epoch: 5| Step: 4
Training loss: 0.23550819787964994
Validation loss: 2.4057412677144736

Epoch: 5| Step: 5
Training loss: 0.3214679208579597
Validation loss: 2.439229962900714

Epoch: 5| Step: 6
Training loss: 0.40916941773266036
Validation loss: 2.4312648469162803

Epoch: 5| Step: 7
Training loss: 0.2207173874559275
Validation loss: 2.4090570538105496

Epoch: 5| Step: 8
Training loss: 0.3783134266822919
Validation loss: 2.4266490615540572

Epoch: 5| Step: 9
Training loss: 0.579764747099783
Validation loss: 2.4415479220067393

Epoch: 5| Step: 10
Training loss: 0.3768095622654445
Validation loss: 2.435762457644873

Epoch: 398| Step: 0
Training loss: 0.4254161599362027
Validation loss: 2.4477598965273053

Epoch: 5| Step: 1
Training loss: 0.40850647236705384
Validation loss: 2.4355735844117947

Epoch: 5| Step: 2
Training loss: 0.4108293006510767
Validation loss: 2.416981463001962

Epoch: 5| Step: 3
Training loss: 0.12441025882338112
Validation loss: 2.429361157460448

Epoch: 5| Step: 4
Training loss: 0.3883164280512078
Validation loss: 2.3921993507780854

Epoch: 5| Step: 5
Training loss: 0.1680434138670049
Validation loss: 2.398264415444311

Epoch: 5| Step: 6
Training loss: 0.3916830991111542
Validation loss: 2.3684987591364566

Epoch: 5| Step: 7
Training loss: 0.34150938750164267
Validation loss: 2.4011997559417027

Epoch: 5| Step: 8
Training loss: 0.384068627490957
Validation loss: 2.43429745874954

Epoch: 5| Step: 9
Training loss: 0.387332871758656
Validation loss: 2.454460746530152

Epoch: 5| Step: 10
Training loss: 0.3344815552356028
Validation loss: 2.4357985639251525

Epoch: 399| Step: 0
Training loss: 0.44265815974132267
Validation loss: 2.433302786668085

Epoch: 5| Step: 1
Training loss: 0.4395207162375233
Validation loss: 2.4584622009549992

Epoch: 5| Step: 2
Training loss: 0.30530696643277594
Validation loss: 2.4310371810863844

Epoch: 5| Step: 3
Training loss: 0.3194327251500653
Validation loss: 2.4216735840772525

Epoch: 5| Step: 4
Training loss: 0.30560740960485466
Validation loss: 2.430082360500865

Epoch: 5| Step: 5
Training loss: 0.3731943008948017
Validation loss: 2.454904957004981

Epoch: 5| Step: 6
Training loss: 0.18204394038418928
Validation loss: 2.4721623787898337

Epoch: 5| Step: 7
Training loss: 0.4719722148720343
Validation loss: 2.4212530665351464

Epoch: 5| Step: 8
Training loss: 0.18827918197952345
Validation loss: 2.4235828275501583

Epoch: 5| Step: 9
Training loss: 0.2784563367960323
Validation loss: 2.432409494225907

Epoch: 5| Step: 10
Training loss: 0.3704369605433599
Validation loss: 2.4292399425476554

Epoch: 400| Step: 0
Training loss: 0.25117300932110453
Validation loss: 2.4520266961012824

Epoch: 5| Step: 1
Training loss: 0.3536714663460007
Validation loss: 2.420678761649197

Epoch: 5| Step: 2
Training loss: 0.2934676055780275
Validation loss: 2.4587279109645657

Epoch: 5| Step: 3
Training loss: 0.3447469970006631
Validation loss: 2.4400157167584804

Epoch: 5| Step: 4
Training loss: 0.3573664012446872
Validation loss: 2.420324067134795

Epoch: 5| Step: 5
Training loss: 0.3994324173941928
Validation loss: 2.450259265738502

Epoch: 5| Step: 6
Training loss: 0.2738938202461313
Validation loss: 2.424923420847016

Epoch: 5| Step: 7
Training loss: 0.22787237517340783
Validation loss: 2.484205899991433

Epoch: 5| Step: 8
Training loss: 0.3709547083525916
Validation loss: 2.4680052641631973

Epoch: 5| Step: 9
Training loss: 0.5199164203268818
Validation loss: 2.4493445276971664

Epoch: 5| Step: 10
Training loss: 0.3610800226392704
Validation loss: 2.4678901118767906

Epoch: 401| Step: 0
Training loss: 0.345303633304182
Validation loss: 2.4341508623400214

Epoch: 5| Step: 1
Training loss: 0.3227054830864045
Validation loss: 2.417972479941009

Epoch: 5| Step: 2
Training loss: 0.30512047838754414
Validation loss: 2.4336878339078782

Epoch: 5| Step: 3
Training loss: 0.3536475762542937
Validation loss: 2.4408890171605

Epoch: 5| Step: 4
Training loss: 0.22077920328259307
Validation loss: 2.3938216385978186

Epoch: 5| Step: 5
Training loss: 0.3405180084988101
Validation loss: 2.3894423057169867

Epoch: 5| Step: 6
Training loss: 0.31685693456102276
Validation loss: 2.369384249923469

Epoch: 5| Step: 7
Training loss: 0.2969812529303413
Validation loss: 2.3992737801906063

Epoch: 5| Step: 8
Training loss: 0.49522296445248065
Validation loss: 2.416792261285093

Epoch: 5| Step: 9
Training loss: 0.38886478563196347
Validation loss: 2.4095250048276906

Epoch: 5| Step: 10
Training loss: 0.3005718022146647
Validation loss: 2.4516854975387314

Epoch: 402| Step: 0
Training loss: 0.5153695832161443
Validation loss: 2.46725556539486

Epoch: 5| Step: 1
Training loss: 0.40217609060327764
Validation loss: 2.4260073695735382

Epoch: 5| Step: 2
Training loss: 0.3283165531521892
Validation loss: 2.4097589489191327

Epoch: 5| Step: 3
Training loss: 0.3438245844122387
Validation loss: 2.4496045083665274

Epoch: 5| Step: 4
Training loss: 0.3119979879256317
Validation loss: 2.4309233697044226

Epoch: 5| Step: 5
Training loss: 0.46938125702691397
Validation loss: 2.3793319212735726

Epoch: 5| Step: 6
Training loss: 0.2216478484559613
Validation loss: 2.4398558080906265

Epoch: 5| Step: 7
Training loss: 0.15221299159655177
Validation loss: 2.390181781653583

Epoch: 5| Step: 8
Training loss: 0.34139593313939715
Validation loss: 2.4163573331952772

Epoch: 5| Step: 9
Training loss: 0.11037321637808845
Validation loss: 2.4230197642223934

Epoch: 5| Step: 10
Training loss: 0.35985429563652355
Validation loss: 2.4222911814536334

Epoch: 403| Step: 0
Training loss: 0.46210982063897543
Validation loss: 2.436210120650721

Epoch: 5| Step: 1
Training loss: 0.4804673543770222
Validation loss: 2.445133572108628

Epoch: 5| Step: 2
Training loss: 0.21578214489131825
Validation loss: 2.4458335487245577

Epoch: 5| Step: 3
Training loss: 0.41400810100281976
Validation loss: 2.4548537056909705

Epoch: 5| Step: 4
Training loss: 0.3516313909213613
Validation loss: 2.48613442212406

Epoch: 5| Step: 5
Training loss: 0.3311949126304369
Validation loss: 2.45298645890745

Epoch: 5| Step: 6
Training loss: 0.13525451219333468
Validation loss: 2.447704360611789

Epoch: 5| Step: 7
Training loss: 0.27764174074078346
Validation loss: 2.418512619193056

Epoch: 5| Step: 8
Training loss: 0.27031916020297353
Validation loss: 2.413331596525949

Epoch: 5| Step: 9
Training loss: 0.37250395407914255
Validation loss: 2.400703407594463

Epoch: 5| Step: 10
Training loss: 0.22183630364077647
Validation loss: 2.378131032057525

Epoch: 404| Step: 0
Training loss: 0.2890815084238881
Validation loss: 2.3983567939656445

Epoch: 5| Step: 1
Training loss: 0.1600761038586061
Validation loss: 2.418170457545848

Epoch: 5| Step: 2
Training loss: 0.3767825911992319
Validation loss: 2.422830879558391

Epoch: 5| Step: 3
Training loss: 0.5045883825423825
Validation loss: 2.4046834825428895

Epoch: 5| Step: 4
Training loss: 0.20779047612673462
Validation loss: 2.4212302618342263

Epoch: 5| Step: 5
Training loss: 0.284095423944317
Validation loss: 2.450600593831735

Epoch: 5| Step: 6
Training loss: 0.31220865974085077
Validation loss: 2.4560912976218985

Epoch: 5| Step: 7
Training loss: 0.3666153772562937
Validation loss: 2.455859912142637

Epoch: 5| Step: 8
Training loss: 0.5235887565135621
Validation loss: 2.4986740718467892

Epoch: 5| Step: 9
Training loss: 0.27497143326117873
Validation loss: 2.492819464047292

Epoch: 5| Step: 10
Training loss: 0.23693111826866264
Validation loss: 2.505648970101934

Epoch: 405| Step: 0
Training loss: 0.2921303769744294
Validation loss: 2.474922181189753

Epoch: 5| Step: 1
Training loss: 0.37703692043449477
Validation loss: 2.47415530773689

Epoch: 5| Step: 2
Training loss: 0.3075162934041671
Validation loss: 2.5027657417711255

Epoch: 5| Step: 3
Training loss: 0.3481677075733118
Validation loss: 2.4810883962220527

Epoch: 5| Step: 4
Training loss: 0.47835843365414804
Validation loss: 2.442810262870223

Epoch: 5| Step: 5
Training loss: 0.21291748367409122
Validation loss: 2.470648885113157

Epoch: 5| Step: 6
Training loss: 0.16037016631733858
Validation loss: 2.447813813076312

Epoch: 5| Step: 7
Training loss: 0.22925684610365604
Validation loss: 2.451828003882882

Epoch: 5| Step: 8
Training loss: 0.3748537811679851
Validation loss: 2.448788917431291

Epoch: 5| Step: 9
Training loss: 0.23828516628611615
Validation loss: 2.4404551343740897

Epoch: 5| Step: 10
Training loss: 0.5432886512302673
Validation loss: 2.443631011279146

Epoch: 406| Step: 0
Training loss: 0.5517391505503441
Validation loss: 2.4213977058922564

Epoch: 5| Step: 1
Training loss: 0.28192810592357853
Validation loss: 2.4675366592564028

Epoch: 5| Step: 2
Training loss: 0.4363580172689027
Validation loss: 2.44366189272097

Epoch: 5| Step: 3
Training loss: 0.22270982499302572
Validation loss: 2.4139331284237797

Epoch: 5| Step: 4
Training loss: 0.2964274018723368
Validation loss: 2.403977685843177

Epoch: 5| Step: 5
Training loss: 0.20128129557321947
Validation loss: 2.3905302154004624

Epoch: 5| Step: 6
Training loss: 0.15945220507777402
Validation loss: 2.367838623229488

Epoch: 5| Step: 7
Training loss: 0.31594164610725917
Validation loss: 2.42466717469951

Epoch: 5| Step: 8
Training loss: 0.4216287035243632
Validation loss: 2.376937565381979

Epoch: 5| Step: 9
Training loss: 0.19153862871348945
Validation loss: 2.381039107159786

Epoch: 5| Step: 10
Training loss: 0.3854578829541288
Validation loss: 2.408940739604444

Epoch: 407| Step: 0
Training loss: 0.2286409702667297
Validation loss: 2.430327838176298

Epoch: 5| Step: 1
Training loss: 0.3780943046280103
Validation loss: 2.425650112760885

Epoch: 5| Step: 2
Training loss: 0.4540027469875398
Validation loss: 2.4455763633748178

Epoch: 5| Step: 3
Training loss: 0.3917446493405386
Validation loss: 2.445224477837609

Epoch: 5| Step: 4
Training loss: 0.338608909922408
Validation loss: 2.444527173980703

Epoch: 5| Step: 5
Training loss: 0.16638390700016148
Validation loss: 2.467715140317278

Epoch: 5| Step: 6
Training loss: 0.2941357195522397
Validation loss: 2.4293123315719867

Epoch: 5| Step: 7
Training loss: 0.3912001381201003
Validation loss: 2.437376469883551

Epoch: 5| Step: 8
Training loss: 0.29719082446399947
Validation loss: 2.4270805282467416

Epoch: 5| Step: 9
Training loss: 0.40183592664218554
Validation loss: 2.3986222006073166

Epoch: 5| Step: 10
Training loss: 0.13415788365081832
Validation loss: 2.4267829336960505

Epoch: 408| Step: 0
Training loss: 0.3548852512105771
Validation loss: 2.389844624548088

Epoch: 5| Step: 1
Training loss: 0.17431872497213202
Validation loss: 2.4089563303631363

Epoch: 5| Step: 2
Training loss: 0.22669410993627354
Validation loss: 2.406698194510091

Epoch: 5| Step: 3
Training loss: 0.49690408681508175
Validation loss: 2.440790322591344

Epoch: 5| Step: 4
Training loss: 0.31339355510592026
Validation loss: 2.4392296696705587

Epoch: 5| Step: 5
Training loss: 0.2864514552359922
Validation loss: 2.4148741532203775

Epoch: 5| Step: 6
Training loss: 0.38990358493582344
Validation loss: 2.4465456154673384

Epoch: 5| Step: 7
Training loss: 0.4062253871210881
Validation loss: 2.43402453228215

Epoch: 5| Step: 8
Training loss: 0.22282273777290904
Validation loss: 2.4234207566045085

Epoch: 5| Step: 9
Training loss: 0.2882658574406652
Validation loss: 2.427154911941096

Epoch: 5| Step: 10
Training loss: 0.34333225355780966
Validation loss: 2.430814940113399

Epoch: 409| Step: 0
Training loss: 0.2866425254386561
Validation loss: 2.432171205818831

Epoch: 5| Step: 1
Training loss: 0.39493770246927656
Validation loss: 2.4444155756508703

Epoch: 5| Step: 2
Training loss: 0.40476597647328627
Validation loss: 2.4667220347519656

Epoch: 5| Step: 3
Training loss: 0.4515211396596565
Validation loss: 2.4253522454503273

Epoch: 5| Step: 4
Training loss: 0.1448847468646343
Validation loss: 2.423024191038377

Epoch: 5| Step: 5
Training loss: 0.2766981670364767
Validation loss: 2.4475759691100922

Epoch: 5| Step: 6
Training loss: 0.47742830642016293
Validation loss: 2.4833238363927475

Epoch: 5| Step: 7
Training loss: 0.22164882327418614
Validation loss: 2.452812844318738

Epoch: 5| Step: 8
Training loss: 0.19388991118763968
Validation loss: 2.4787530827237436

Epoch: 5| Step: 9
Training loss: 0.20169744077630064
Validation loss: 2.5011741424094307

Epoch: 5| Step: 10
Training loss: 0.3255952660975374
Validation loss: 2.46526802446592

Epoch: 410| Step: 0
Training loss: 0.37882910267520237
Validation loss: 2.4239356466199813

Epoch: 5| Step: 1
Training loss: 0.46906147780742236
Validation loss: 2.442643900421454

Epoch: 5| Step: 2
Training loss: 0.17554655832212004
Validation loss: 2.432868801741607

Epoch: 5| Step: 3
Training loss: 0.1848471346825012
Validation loss: 2.4673960243764452

Epoch: 5| Step: 4
Training loss: 0.361276901325853
Validation loss: 2.4500968965426457

Epoch: 5| Step: 5
Training loss: 0.3060493721953822
Validation loss: 2.4847123952793893

Epoch: 5| Step: 6
Training loss: 0.45063209446098734
Validation loss: 2.45319276434848

Epoch: 5| Step: 7
Training loss: 0.3251688834783174
Validation loss: 2.506073058248333

Epoch: 5| Step: 8
Training loss: 0.18932715878637943
Validation loss: 2.483080743977512

Epoch: 5| Step: 9
Training loss: 0.21247297844464264
Validation loss: 2.4833252135372055

Epoch: 5| Step: 10
Training loss: 0.24586070849187622
Validation loss: 2.469000044974609

Epoch: 411| Step: 0
Training loss: 0.3608332363654191
Validation loss: 2.461940497310526

Epoch: 5| Step: 1
Training loss: 0.2722008533684081
Validation loss: 2.4401217828252326

Epoch: 5| Step: 2
Training loss: 0.289910156169406
Validation loss: 2.4533695866866947

Epoch: 5| Step: 3
Training loss: 0.33735550418675697
Validation loss: 2.369245613703727

Epoch: 5| Step: 4
Training loss: 0.2060076130975226
Validation loss: 2.436940220137943

Epoch: 5| Step: 5
Training loss: 0.241667674154341
Validation loss: 2.3943237799368307

Epoch: 5| Step: 6
Training loss: 0.44924533599466143
Validation loss: 2.4433241679067765

Epoch: 5| Step: 7
Training loss: 0.35112710058413027
Validation loss: 2.4259755004279304

Epoch: 5| Step: 8
Training loss: 0.37569746086561223
Validation loss: 2.4729688180815343

Epoch: 5| Step: 9
Training loss: 0.31264208901214263
Validation loss: 2.4356364016886367

Epoch: 5| Step: 10
Training loss: 0.30444315135615263
Validation loss: 2.466367392966506

Epoch: 412| Step: 0
Training loss: 0.26469038176966353
Validation loss: 2.4911524637947253

Epoch: 5| Step: 1
Training loss: 0.38389591738777457
Validation loss: 2.4548614022807187

Epoch: 5| Step: 2
Training loss: 0.14458617249398262
Validation loss: 2.45376231678465

Epoch: 5| Step: 3
Training loss: 0.44799819655246986
Validation loss: 2.4397948363588386

Epoch: 5| Step: 4
Training loss: 0.345341013253331
Validation loss: 2.4430622848681134

Epoch: 5| Step: 5
Training loss: 0.21556644266537284
Validation loss: 2.4947782003131023

Epoch: 5| Step: 6
Training loss: 0.3311784451051862
Validation loss: 2.4272079875872397

Epoch: 5| Step: 7
Training loss: 0.36954121324201183
Validation loss: 2.450373825792185

Epoch: 5| Step: 8
Training loss: 0.2880303410046722
Validation loss: 2.443031787786043

Epoch: 5| Step: 9
Training loss: 0.30904237513885063
Validation loss: 2.4627891989937765

Epoch: 5| Step: 10
Training loss: 0.33707399856757003
Validation loss: 2.4822870867260844

Epoch: 413| Step: 0
Training loss: 0.4583649371550735
Validation loss: 2.4394731720373133

Epoch: 5| Step: 1
Training loss: 0.29303897016130687
Validation loss: 2.4408333217619576

Epoch: 5| Step: 2
Training loss: 0.33848979503654125
Validation loss: 2.472435869144013

Epoch: 5| Step: 3
Training loss: 0.3887306245654885
Validation loss: 2.446375005113518

Epoch: 5| Step: 4
Training loss: 0.31086329768050625
Validation loss: 2.4354315690811923

Epoch: 5| Step: 5
Training loss: 0.44434126966022813
Validation loss: 2.475379893105977

Epoch: 5| Step: 6
Training loss: 0.16936892393868963
Validation loss: 2.4423304618272486

Epoch: 5| Step: 7
Training loss: 0.28712874626153656
Validation loss: 2.445612406529943

Epoch: 5| Step: 8
Training loss: 0.1896799244067087
Validation loss: 2.4499636673551044

Epoch: 5| Step: 9
Training loss: 0.16248500346713274
Validation loss: 2.4401085176616357

Epoch: 5| Step: 10
Training loss: 0.27191771084081007
Validation loss: 2.4252213461114738

Epoch: 414| Step: 0
Training loss: 0.2487225528651104
Validation loss: 2.407281016281962

Epoch: 5| Step: 1
Training loss: 0.22417875557928613
Validation loss: 2.376909343395038

Epoch: 5| Step: 2
Training loss: 0.1941458380937567
Validation loss: 2.398832265631481

Epoch: 5| Step: 3
Training loss: 0.3195717200693658
Validation loss: 2.387951744897063

Epoch: 5| Step: 4
Training loss: 0.43943098224379495
Validation loss: 2.3972193724470996

Epoch: 5| Step: 5
Training loss: 0.09144560586131874
Validation loss: 2.393421364399189

Epoch: 5| Step: 6
Training loss: 0.2911027355517005
Validation loss: 2.4440037666748817

Epoch: 5| Step: 7
Training loss: 0.4324254112478117
Validation loss: 2.430201963691815

Epoch: 5| Step: 8
Training loss: 0.33860987807495213
Validation loss: 2.4230051421293304

Epoch: 5| Step: 9
Training loss: 0.33519698742398146
Validation loss: 2.4225375335399004

Epoch: 5| Step: 10
Training loss: 0.37055253164697693
Validation loss: 2.450100836019181

Epoch: 415| Step: 0
Training loss: 0.395225179021972
Validation loss: 2.477857697258385

Epoch: 5| Step: 1
Training loss: 0.3364588772421929
Validation loss: 2.4599426477541244

Epoch: 5| Step: 2
Training loss: 0.3569267679336752
Validation loss: 2.513612003322367

Epoch: 5| Step: 3
Training loss: 0.16708328037982523
Validation loss: 2.482082511143753

Epoch: 5| Step: 4
Training loss: 0.362131185193712
Validation loss: 2.44820862239739

Epoch: 5| Step: 5
Training loss: 0.40671366128218456
Validation loss: 2.468298036163232

Epoch: 5| Step: 6
Training loss: 0.30507238238567663
Validation loss: 2.4476770085139044

Epoch: 5| Step: 7
Training loss: 0.17954947519382358
Validation loss: 2.487334299569326

Epoch: 5| Step: 8
Training loss: 0.28813478734569536
Validation loss: 2.472605888147888

Epoch: 5| Step: 9
Training loss: 0.3568504434945471
Validation loss: 2.483804164694516

Epoch: 5| Step: 10
Training loss: 0.23775778006811424
Validation loss: 2.4648873935518347

Epoch: 416| Step: 0
Training loss: 0.1703525926925765
Validation loss: 2.447128548840933

Epoch: 5| Step: 1
Training loss: 0.419885536218373
Validation loss: 2.4441732036549215

Epoch: 5| Step: 2
Training loss: 0.13578799730311852
Validation loss: 2.4436214454646024

Epoch: 5| Step: 3
Training loss: 0.3982902890687811
Validation loss: 2.421366504501379

Epoch: 5| Step: 4
Training loss: 0.42459452023179756
Validation loss: 2.4261897711113516

Epoch: 5| Step: 5
Training loss: 0.27751538513252266
Validation loss: 2.4228117698744023

Epoch: 5| Step: 6
Training loss: 0.20602306466815465
Validation loss: 2.4062350943478856

Epoch: 5| Step: 7
Training loss: 0.43080140430235725
Validation loss: 2.3846042894232613

Epoch: 5| Step: 8
Training loss: 0.26286398425310165
Validation loss: 2.4204072588719927

Epoch: 5| Step: 9
Training loss: 0.24058960802957619
Validation loss: 2.3991720401471635

Epoch: 5| Step: 10
Training loss: 0.3155530682357643
Validation loss: 2.428526640968763

Epoch: 417| Step: 0
Training loss: 0.2851702934883018
Validation loss: 2.408535062389656

Epoch: 5| Step: 1
Training loss: 0.3899996520309852
Validation loss: 2.4759221256871227

Epoch: 5| Step: 2
Training loss: 0.37971231905348346
Validation loss: 2.446833828478196

Epoch: 5| Step: 3
Training loss: 0.4463817074564713
Validation loss: 2.447737257087739

Epoch: 5| Step: 4
Training loss: 0.19122157627391653
Validation loss: 2.4997460708045214

Epoch: 5| Step: 5
Training loss: 0.3679153857239443
Validation loss: 2.458253656524469

Epoch: 5| Step: 6
Training loss: 0.18421636683416556
Validation loss: 2.460017253431057

Epoch: 5| Step: 7
Training loss: 0.15319070987497907
Validation loss: 2.4784538696873373

Epoch: 5| Step: 8
Training loss: 0.25479181353350877
Validation loss: 2.490985060932695

Epoch: 5| Step: 9
Training loss: 0.23034537779455805
Validation loss: 2.51883329209333

Epoch: 5| Step: 10
Training loss: 0.3909081005382291
Validation loss: 2.513870983150281

Epoch: 418| Step: 0
Training loss: 0.370092647815942
Validation loss: 2.4988779175022913

Epoch: 5| Step: 1
Training loss: 0.43858193403689194
Validation loss: 2.490318924564167

Epoch: 5| Step: 2
Training loss: 0.3836384834575002
Validation loss: 2.498351129658668

Epoch: 5| Step: 3
Training loss: 0.3796962485855722
Validation loss: 2.485567064493964

Epoch: 5| Step: 4
Training loss: 0.13758558947336283
Validation loss: 2.466054984075647

Epoch: 5| Step: 5
Training loss: 0.236991856657935
Validation loss: 2.4436506343005897

Epoch: 5| Step: 6
Training loss: 0.27589702715480163
Validation loss: 2.4116012696370777

Epoch: 5| Step: 7
Training loss: 0.25091118461991196
Validation loss: 2.3999372526224594

Epoch: 5| Step: 8
Training loss: 0.34191641760657515
Validation loss: 2.413160740880198

Epoch: 5| Step: 9
Training loss: 0.22311022137870679
Validation loss: 2.4446742324863484

Epoch: 5| Step: 10
Training loss: 0.22787929850702351
Validation loss: 2.4120259941841216

Epoch: 419| Step: 0
Training loss: 0.42480449457273817
Validation loss: 2.4231442124380145

Epoch: 5| Step: 1
Training loss: 0.35151598940590184
Validation loss: 2.441872040579856

Epoch: 5| Step: 2
Training loss: 0.16195251160177468
Validation loss: 2.4127019014863245

Epoch: 5| Step: 3
Training loss: 0.3102534245195212
Validation loss: 2.3939752643723358

Epoch: 5| Step: 4
Training loss: 0.26663171506849964
Validation loss: 2.4150258134859213

Epoch: 5| Step: 5
Training loss: 0.23744087079229317
Validation loss: 2.439264943218584

Epoch: 5| Step: 6
Training loss: 0.28166373603799133
Validation loss: 2.4445268237059987

Epoch: 5| Step: 7
Training loss: 0.3070879667860769
Validation loss: 2.446342723279919

Epoch: 5| Step: 8
Training loss: 0.424199851020803
Validation loss: 2.4212467306234458

Epoch: 5| Step: 9
Training loss: 0.18613287094131306
Validation loss: 2.4543438620075224

Epoch: 5| Step: 10
Training loss: 0.26518459836157704
Validation loss: 2.462036855029708

Epoch: 420| Step: 0
Training loss: 0.24028271289597913
Validation loss: 2.4404910225875036

Epoch: 5| Step: 1
Training loss: 0.2584439405540536
Validation loss: 2.4601379199816042

Epoch: 5| Step: 2
Training loss: 0.14926499054737077
Validation loss: 2.4312293370899343

Epoch: 5| Step: 3
Training loss: 0.41318882231355775
Validation loss: 2.4271043511345507

Epoch: 5| Step: 4
Training loss: 0.17220721865766342
Validation loss: 2.4331629810075803

Epoch: 5| Step: 5
Training loss: 0.3900273901540032
Validation loss: 2.4252126833671173

Epoch: 5| Step: 6
Training loss: 0.3183426530811063
Validation loss: 2.4390926274848153

Epoch: 5| Step: 7
Training loss: 0.3474195081468495
Validation loss: 2.408229769349822

Epoch: 5| Step: 8
Training loss: 0.24552063586022504
Validation loss: 2.4156391806413695

Epoch: 5| Step: 9
Training loss: 0.33594341051091947
Validation loss: 2.3874870293497983

Epoch: 5| Step: 10
Training loss: 0.32243377460236056
Validation loss: 2.4062121851378464

Epoch: 421| Step: 0
Training loss: 0.12728445392699944
Validation loss: 2.4382872634021147

Epoch: 5| Step: 1
Training loss: 0.324631279161586
Validation loss: 2.4524340487647405

Epoch: 5| Step: 2
Training loss: 0.2666727047971744
Validation loss: 2.483344396956215

Epoch: 5| Step: 3
Training loss: 0.1766516435131557
Validation loss: 2.4797506295245517

Epoch: 5| Step: 4
Training loss: 0.25117228257307855
Validation loss: 2.45216055547978

Epoch: 5| Step: 5
Training loss: 0.13654321573655537
Validation loss: 2.4421162079914542

Epoch: 5| Step: 6
Training loss: 0.5037699374567498
Validation loss: 2.4711844249842096

Epoch: 5| Step: 7
Training loss: 0.2698196443880328
Validation loss: 2.4453669296948624

Epoch: 5| Step: 8
Training loss: 0.441943946730936
Validation loss: 2.4018651192516813

Epoch: 5| Step: 9
Training loss: 0.32010497371887564
Validation loss: 2.398977070061997

Epoch: 5| Step: 10
Training loss: 0.1825343265323157
Validation loss: 2.443601768178889

Epoch: 422| Step: 0
Training loss: 0.23481662786519408
Validation loss: 2.3806545363236418

Epoch: 5| Step: 1
Training loss: 0.13287754429528176
Validation loss: 2.3598935484337313

Epoch: 5| Step: 2
Training loss: 0.3697257274168874
Validation loss: 2.36631912921882

Epoch: 5| Step: 3
Training loss: 0.18671020424412058
Validation loss: 2.434969491696116

Epoch: 5| Step: 4
Training loss: 0.34060931300867014
Validation loss: 2.4234925863708416

Epoch: 5| Step: 5
Training loss: 0.3312090398547607
Validation loss: 2.4184668089607944

Epoch: 5| Step: 6
Training loss: 0.16520022812748483
Validation loss: 2.4501744062800705

Epoch: 5| Step: 7
Training loss: 0.3291398430812049
Validation loss: 2.403364272195032

Epoch: 5| Step: 8
Training loss: 0.3906255531307119
Validation loss: 2.423772107371141

Epoch: 5| Step: 9
Training loss: 0.16344543055773567
Validation loss: 2.4222348372267737

Epoch: 5| Step: 10
Training loss: 0.4095255043648451
Validation loss: 2.4260291793758935

Epoch: 423| Step: 0
Training loss: 0.22374137175828973
Validation loss: 2.4445501095235254

Epoch: 5| Step: 1
Training loss: 0.1439028753719556
Validation loss: 2.446497471003079

Epoch: 5| Step: 2
Training loss: 0.3506262817121392
Validation loss: 2.3825075263351576

Epoch: 5| Step: 3
Training loss: 0.2614862491072074
Validation loss: 2.3862481615755007

Epoch: 5| Step: 4
Training loss: 0.30684608816624886
Validation loss: 2.4208102402025

Epoch: 5| Step: 5
Training loss: 0.33114454012163586
Validation loss: 2.4093093207039065

Epoch: 5| Step: 6
Training loss: 0.37752939558209203
Validation loss: 2.4173342348866567

Epoch: 5| Step: 7
Training loss: 0.20325723342000726
Validation loss: 2.4514145205520146

Epoch: 5| Step: 8
Training loss: 0.23357908687690787
Validation loss: 2.4492953591176114

Epoch: 5| Step: 9
Training loss: 0.39280123088273805
Validation loss: 2.4340963545668792

Epoch: 5| Step: 10
Training loss: 0.3887085250367147
Validation loss: 2.4579612254953296

Epoch: 424| Step: 0
Training loss: 0.2821339121869918
Validation loss: 2.440438193281649

Epoch: 5| Step: 1
Training loss: 0.392196735714075
Validation loss: 2.441684319261795

Epoch: 5| Step: 2
Training loss: 0.3039765744861631
Validation loss: 2.422219819851423

Epoch: 5| Step: 3
Training loss: 0.4370049332246422
Validation loss: 2.419280416307913

Epoch: 5| Step: 4
Training loss: 0.09195656278985223
Validation loss: 2.4415973453018114

Epoch: 5| Step: 5
Training loss: 0.2998283202955785
Validation loss: 2.419563402309299

Epoch: 5| Step: 6
Training loss: 0.2721691688645276
Validation loss: 2.3990777075702616

Epoch: 5| Step: 7
Training loss: 0.37699522267610835
Validation loss: 2.448454961367568

Epoch: 5| Step: 8
Training loss: 0.30904326715595387
Validation loss: 2.3979430698299544

Epoch: 5| Step: 9
Training loss: 0.24184210821014177
Validation loss: 2.3911195249281505

Epoch: 5| Step: 10
Training loss: 0.13449333159408536
Validation loss: 2.3576431203897994

Epoch: 425| Step: 0
Training loss: 0.15801402552476113
Validation loss: 2.3888074633333747

Epoch: 5| Step: 1
Training loss: 0.30986588865013276
Validation loss: 2.3709496933135217

Epoch: 5| Step: 2
Training loss: 0.12024782024433257
Validation loss: 2.410380955183213

Epoch: 5| Step: 3
Training loss: 0.23806066152013458
Validation loss: 2.4326761545295437

Epoch: 5| Step: 4
Training loss: 0.3257859396654142
Validation loss: 2.4191409744571857

Epoch: 5| Step: 5
Training loss: 0.32154300474898767
Validation loss: 2.398715901294398

Epoch: 5| Step: 6
Training loss: 0.42883698645922447
Validation loss: 2.3902441776807315

Epoch: 5| Step: 7
Training loss: 0.3634433179735716
Validation loss: 2.422946978759368

Epoch: 5| Step: 8
Training loss: 0.34287867873148314
Validation loss: 2.4482149607856045

Epoch: 5| Step: 9
Training loss: 0.2438983019817392
Validation loss: 2.4510959343021423

Epoch: 5| Step: 10
Training loss: 0.15468025864885318
Validation loss: 2.4649903988178523

Epoch: 426| Step: 0
Training loss: 0.23955062542741934
Validation loss: 2.4569260719992947

Epoch: 5| Step: 1
Training loss: 0.408190914135686
Validation loss: 2.495367608769278

Epoch: 5| Step: 2
Training loss: 0.2883228685477368
Validation loss: 2.5035562580848825

Epoch: 5| Step: 3
Training loss: 0.23599343994588218
Validation loss: 2.4786621977183687

Epoch: 5| Step: 4
Training loss: 0.2826958684532325
Validation loss: 2.4651344707324245

Epoch: 5| Step: 5
Training loss: 0.13897900753796494
Validation loss: 2.455275006794906

Epoch: 5| Step: 6
Training loss: 0.19926479218939414
Validation loss: 2.414200966207755

Epoch: 5| Step: 7
Training loss: 0.34803602285196
Validation loss: 2.432699055322287

Epoch: 5| Step: 8
Training loss: 0.28795193934104657
Validation loss: 2.4342924173934044

Epoch: 5| Step: 9
Training loss: 0.32993269430852934
Validation loss: 2.4138688393650054

Epoch: 5| Step: 10
Training loss: 0.38741047963397246
Validation loss: 2.4065291263206037

Epoch: 427| Step: 0
Training loss: 0.21072928430689422
Validation loss: 2.376208520323679

Epoch: 5| Step: 1
Training loss: 0.32959541598660574
Validation loss: 2.347433208231917

Epoch: 5| Step: 2
Training loss: 0.15166622279917913
Validation loss: 2.3663353881013123

Epoch: 5| Step: 3
Training loss: 0.21706513827549662
Validation loss: 2.379727773881943

Epoch: 5| Step: 4
Training loss: 0.29044154847789466
Validation loss: 2.4104615888613234

Epoch: 5| Step: 5
Training loss: 0.24835319828153662
Validation loss: 2.399471422323064

Epoch: 5| Step: 6
Training loss: 0.24617959599082995
Validation loss: 2.4261262231692964

Epoch: 5| Step: 7
Training loss: 0.24672887225703757
Validation loss: 2.4445697435195903

Epoch: 5| Step: 8
Training loss: 0.42208350292037966
Validation loss: 2.437443894802069

Epoch: 5| Step: 9
Training loss: 0.3294517623442597
Validation loss: 2.428731095371112

Epoch: 5| Step: 10
Training loss: 0.3808446636782152
Validation loss: 2.457556205611425

Epoch: 428| Step: 0
Training loss: 0.21615479730302958
Validation loss: 2.425287556151732

Epoch: 5| Step: 1
Training loss: 0.24920681951779827
Validation loss: 2.4134150129654146

Epoch: 5| Step: 2
Training loss: 0.3090236180748217
Validation loss: 2.4276325615422483

Epoch: 5| Step: 3
Training loss: 0.3884602838157867
Validation loss: 2.4134342745967086

Epoch: 5| Step: 4
Training loss: 0.35203971263400236
Validation loss: 2.4189808447412093

Epoch: 5| Step: 5
Training loss: 0.1487064560098952
Validation loss: 2.4508805163288083

Epoch: 5| Step: 6
Training loss: 0.2534037532751612
Validation loss: 2.460988486068307

Epoch: 5| Step: 7
Training loss: 0.4012335487510819
Validation loss: 2.4664714241526675

Epoch: 5| Step: 8
Training loss: 0.22428649417262816
Validation loss: 2.432556473804131

Epoch: 5| Step: 9
Training loss: 0.33357383078932223
Validation loss: 2.4599802994708337

Epoch: 5| Step: 10
Training loss: 0.15762967505733225
Validation loss: 2.4625339812411933

Epoch: 429| Step: 0
Training loss: 0.351586404623496
Validation loss: 2.4628686451050474

Epoch: 5| Step: 1
Training loss: 0.18885034843101609
Validation loss: 2.4345825464050614

Epoch: 5| Step: 2
Training loss: 0.28244346810467974
Validation loss: 2.3898781742521487

Epoch: 5| Step: 3
Training loss: 0.3749463917243357
Validation loss: 2.4273304393393365

Epoch: 5| Step: 4
Training loss: 0.290279045107284
Validation loss: 2.4136679481210317

Epoch: 5| Step: 5
Training loss: 0.15423180016683352
Validation loss: 2.4000629810303895

Epoch: 5| Step: 6
Training loss: 0.18716852372135084
Validation loss: 2.4022957100122135

Epoch: 5| Step: 7
Training loss: 0.1894149741860648
Validation loss: 2.3391087417261756

Epoch: 5| Step: 8
Training loss: 0.42297120196812316
Validation loss: 2.3584396049928302

Epoch: 5| Step: 9
Training loss: 0.19296772141896762
Validation loss: 2.387307332683371

Epoch: 5| Step: 10
Training loss: 0.40685401543033595
Validation loss: 2.4237131416060866

Epoch: 430| Step: 0
Training loss: 0.1335704576810918
Validation loss: 2.4481617515334304

Epoch: 5| Step: 1
Training loss: 0.19208929258654384
Validation loss: 2.4253592629817344

Epoch: 5| Step: 2
Training loss: 0.37848705030358065
Validation loss: 2.3948722727267606

Epoch: 5| Step: 3
Training loss: 0.22907644721188836
Validation loss: 2.4492784948713426

Epoch: 5| Step: 4
Training loss: 0.4232697038283238
Validation loss: 2.4029332317195835

Epoch: 5| Step: 5
Training loss: 0.25448903911103987
Validation loss: 2.3808940596989383

Epoch: 5| Step: 6
Training loss: 0.2383035352322819
Validation loss: 2.4700657100903696

Epoch: 5| Step: 7
Training loss: 0.3726862017672732
Validation loss: 2.4413321036287785

Epoch: 5| Step: 8
Training loss: 0.35763622589519023
Validation loss: 2.439154778165358

Epoch: 5| Step: 9
Training loss: 0.19085037517838033
Validation loss: 2.47210600457168

Epoch: 5| Step: 10
Training loss: 0.24852842610358256
Validation loss: 2.439082662333741

Epoch: 431| Step: 0
Training loss: 0.20641310196042986
Validation loss: 2.41355702152803

Epoch: 5| Step: 1
Training loss: 0.17696411780765536
Validation loss: 2.432781489436191

Epoch: 5| Step: 2
Training loss: 0.34499404947014295
Validation loss: 2.383451950313462

Epoch: 5| Step: 3
Training loss: 0.14180126577467772
Validation loss: 2.4335681365686557

Epoch: 5| Step: 4
Training loss: 0.3347334798471387
Validation loss: 2.4211667531360166

Epoch: 5| Step: 5
Training loss: 0.33079367731866094
Validation loss: 2.422114409840592

Epoch: 5| Step: 6
Training loss: 0.3034571111334871
Validation loss: 2.421121919100239

Epoch: 5| Step: 7
Training loss: 0.34450223285853904
Validation loss: 2.4442000920308846

Epoch: 5| Step: 8
Training loss: 0.16275130564302157
Validation loss: 2.3777602131199638

Epoch: 5| Step: 9
Training loss: 0.3152746285945516
Validation loss: 2.4030275644360772

Epoch: 5| Step: 10
Training loss: 0.3455858193206844
Validation loss: 2.4401632000135685

Epoch: 432| Step: 0
Training loss: 0.2550212586414435
Validation loss: 2.423952367781166

Epoch: 5| Step: 1
Training loss: 0.30199141857921213
Validation loss: 2.4363675301494085

Epoch: 5| Step: 2
Training loss: 0.14205318646628423
Validation loss: 2.4405887786310583

Epoch: 5| Step: 3
Training loss: 0.2757848393582191
Validation loss: 2.4430072098777726

Epoch: 5| Step: 4
Training loss: 0.16197585156678043
Validation loss: 2.4528307294414113

Epoch: 5| Step: 5
Training loss: 0.3799957264484225
Validation loss: 2.452994314986609

Epoch: 5| Step: 6
Training loss: 0.219264625716666
Validation loss: 2.4043559874696485

Epoch: 5| Step: 7
Training loss: 0.36904524524609406
Validation loss: 2.3961914058862406

Epoch: 5| Step: 8
Training loss: 0.2040128925950077
Validation loss: 2.419353994485578

Epoch: 5| Step: 9
Training loss: 0.3171846915811317
Validation loss: 2.4331001272674238

Epoch: 5| Step: 10
Training loss: 0.36593977998305033
Validation loss: 2.443019447705843

Epoch: 433| Step: 0
Training loss: 0.2396030970728302
Validation loss: 2.426167598732372

Epoch: 5| Step: 1
Training loss: 0.1803337273259216
Validation loss: 2.456154197618296

Epoch: 5| Step: 2
Training loss: 0.16507506683196027
Validation loss: 2.458054580095916

Epoch: 5| Step: 3
Training loss: 0.37828892630312705
Validation loss: 2.4398230302081982

Epoch: 5| Step: 4
Training loss: 0.23340388016360172
Validation loss: 2.4163246948895036

Epoch: 5| Step: 5
Training loss: 0.3353982189784023
Validation loss: 2.474240999421499

Epoch: 5| Step: 6
Training loss: 0.3592486366692081
Validation loss: 2.482148373606575

Epoch: 5| Step: 7
Training loss: 0.1752650150973045
Validation loss: 2.4727544741222647

Epoch: 5| Step: 8
Training loss: 0.37561778996255296
Validation loss: 2.501486783253316

Epoch: 5| Step: 9
Training loss: 0.28504711832417634
Validation loss: 2.4804942202001206

Epoch: 5| Step: 10
Training loss: 0.24123875847503085
Validation loss: 2.508800515522929

Epoch: 434| Step: 0
Training loss: 0.2693192159373495
Validation loss: 2.5195323641698977

Epoch: 5| Step: 1
Training loss: 0.33059635900031725
Validation loss: 2.517859006381636

Epoch: 5| Step: 2
Training loss: 0.2632358902476459
Validation loss: 2.5392799333563465

Epoch: 5| Step: 3
Training loss: 0.3304251928460083
Validation loss: 2.5125323213161406

Epoch: 5| Step: 4
Training loss: 0.2910307041844276
Validation loss: 2.4922997578646666

Epoch: 5| Step: 5
Training loss: 0.1917167985874341
Validation loss: 2.4680568645721417

Epoch: 5| Step: 6
Training loss: 0.23704714201910324
Validation loss: 2.438018642682641

Epoch: 5| Step: 7
Training loss: 0.3243479413854133
Validation loss: 2.450308699556624

Epoch: 5| Step: 8
Training loss: 0.3938072094909287
Validation loss: 2.4397911150868286

Epoch: 5| Step: 9
Training loss: 0.18773142122952446
Validation loss: 2.448498726378126

Epoch: 5| Step: 10
Training loss: 0.1742165116307453
Validation loss: 2.451953289109589

Epoch: 435| Step: 0
Training loss: 0.22705163442800053
Validation loss: 2.4606371072340774

Epoch: 5| Step: 1
Training loss: 0.2761424738275389
Validation loss: 2.4753319884003777

Epoch: 5| Step: 2
Training loss: 0.5279325800571943
Validation loss: 2.4637724195054136

Epoch: 5| Step: 3
Training loss: 0.21131532880643544
Validation loss: 2.4901258234810437

Epoch: 5| Step: 4
Training loss: 0.17694962352799948
Validation loss: 2.457467669421202

Epoch: 5| Step: 5
Training loss: 0.38955163350732874
Validation loss: 2.466114459326739

Epoch: 5| Step: 6
Training loss: 0.21459087748984657
Validation loss: 2.4450991276445997

Epoch: 5| Step: 7
Training loss: 0.16732324165565676
Validation loss: 2.485997884565907

Epoch: 5| Step: 8
Training loss: 0.15978219382404416
Validation loss: 2.4284020558112998

Epoch: 5| Step: 9
Training loss: 0.2498900872251398
Validation loss: 2.427541509360652

Epoch: 5| Step: 10
Training loss: 0.1329792672669926
Validation loss: 2.3635172711922787

Epoch: 436| Step: 0
Training loss: 0.20170611211190295
Validation loss: 2.4460112788015524

Epoch: 5| Step: 1
Training loss: 0.3994125328874095
Validation loss: 2.3826751104534476

Epoch: 5| Step: 2
Training loss: 0.2043364601369222
Validation loss: 2.455100003391044

Epoch: 5| Step: 3
Training loss: 0.21487673592934192
Validation loss: 2.424643085737797

Epoch: 5| Step: 4
Training loss: 0.38712743876757266
Validation loss: 2.4832711739808433

Epoch: 5| Step: 5
Training loss: 0.15627702240926725
Validation loss: 2.451799887435951

Epoch: 5| Step: 6
Training loss: 0.14268441353649952
Validation loss: 2.4565384938024017

Epoch: 5| Step: 7
Training loss: 0.30555106319872366
Validation loss: 2.4721553784888988

Epoch: 5| Step: 8
Training loss: 0.26690865739943276
Validation loss: 2.483156652194961

Epoch: 5| Step: 9
Training loss: 0.3089312024185609
Validation loss: 2.4906387168768105

Epoch: 5| Step: 10
Training loss: 0.25580966262679117
Validation loss: 2.4297427017603708

Epoch: 437| Step: 0
Training loss: 0.2753708473841375
Validation loss: 2.432720934751805

Epoch: 5| Step: 1
Training loss: 0.22057353916253017
Validation loss: 2.4424576743006665

Epoch: 5| Step: 2
Training loss: 0.17538887311914342
Validation loss: 2.4232370855238696

Epoch: 5| Step: 3
Training loss: 0.30808820237809303
Validation loss: 2.4356932189832654

Epoch: 5| Step: 4
Training loss: 0.3462564490678274
Validation loss: 2.416562109592369

Epoch: 5| Step: 5
Training loss: 0.2820225542582436
Validation loss: 2.4442873320782197

Epoch: 5| Step: 6
Training loss: 0.13071353101377542
Validation loss: 2.4419831150217606

Epoch: 5| Step: 7
Training loss: 0.2761471414888801
Validation loss: 2.443379680621665

Epoch: 5| Step: 8
Training loss: 0.2309118472654911
Validation loss: 2.4648215170980663

Epoch: 5| Step: 9
Training loss: 0.3339168413380895
Validation loss: 2.4205469211503563

Epoch: 5| Step: 10
Training loss: 0.3416087586575697
Validation loss: 2.4651443342109696

Epoch: 438| Step: 0
Training loss: 0.18529050080497536
Validation loss: 2.4022631591917145

Epoch: 5| Step: 1
Training loss: 0.3399146543177331
Validation loss: 2.431578255901348

Epoch: 5| Step: 2
Training loss: 0.28768200762633894
Validation loss: 2.412504157334217

Epoch: 5| Step: 3
Training loss: 0.37443565580996024
Validation loss: 2.438325036080283

Epoch: 5| Step: 4
Training loss: 0.11088480016684218
Validation loss: 2.478408635199384

Epoch: 5| Step: 5
Training loss: 0.24823151122034626
Validation loss: 2.426922988577075

Epoch: 5| Step: 6
Training loss: 0.31352609023292527
Validation loss: 2.4714226348163923

Epoch: 5| Step: 7
Training loss: 0.24466481963578077
Validation loss: 2.438192986864208

Epoch: 5| Step: 8
Training loss: 0.29556533898990417
Validation loss: 2.4694834043338756

Epoch: 5| Step: 9
Training loss: 0.2294639894733775
Validation loss: 2.487771766885666

Epoch: 5| Step: 10
Training loss: 0.15869802021035337
Validation loss: 2.435714606302735

Epoch: 439| Step: 0
Training loss: 0.17426367103598295
Validation loss: 2.456070965575332

Epoch: 5| Step: 1
Training loss: 0.25088062753528634
Validation loss: 2.433796727489765

Epoch: 5| Step: 2
Training loss: 0.3225777703780084
Validation loss: 2.4591676941370624

Epoch: 5| Step: 3
Training loss: 0.08551152273975261
Validation loss: 2.438114084698916

Epoch: 5| Step: 4
Training loss: 0.2357060070449588
Validation loss: 2.4160320953795353

Epoch: 5| Step: 5
Training loss: 0.2986629628042442
Validation loss: 2.466383502153211

Epoch: 5| Step: 6
Training loss: 0.24101045129994514
Validation loss: 2.4314945568973134

Epoch: 5| Step: 7
Training loss: 0.22542168884153316
Validation loss: 2.447570001949649

Epoch: 5| Step: 8
Training loss: 0.349172254961872
Validation loss: 2.4829476563756883

Epoch: 5| Step: 9
Training loss: 0.312772941603255
Validation loss: 2.433660475441406

Epoch: 5| Step: 10
Training loss: 0.3190352397784683
Validation loss: 2.4237313482905987

Epoch: 440| Step: 0
Training loss: 0.3628954941471158
Validation loss: 2.4411778581006485

Epoch: 5| Step: 1
Training loss: 0.3006619179554876
Validation loss: 2.4412269066352503

Epoch: 5| Step: 2
Training loss: 0.33218430749932715
Validation loss: 2.4407443470178856

Epoch: 5| Step: 3
Training loss: 0.1570752227004326
Validation loss: 2.404746131278412

Epoch: 5| Step: 4
Training loss: 0.22153072982191052
Validation loss: 2.4405647386251963

Epoch: 5| Step: 5
Training loss: 0.25194496318993187
Validation loss: 2.4391511100453087

Epoch: 5| Step: 6
Training loss: 0.3577442070700579
Validation loss: 2.4327465202198266

Epoch: 5| Step: 7
Training loss: 0.27665571376843795
Validation loss: 2.4725102336780465

Epoch: 5| Step: 8
Training loss: 0.19998566419661434
Validation loss: 2.477658270405095

Epoch: 5| Step: 9
Training loss: 0.26185639875259215
Validation loss: 2.474316861781934

Epoch: 5| Step: 10
Training loss: 0.14446983450165463
Validation loss: 2.4499677022680633

Epoch: 441| Step: 0
Training loss: 0.1663205767988744
Validation loss: 2.4596760345178046

Epoch: 5| Step: 1
Training loss: 0.2522995511489093
Validation loss: 2.4329489540755933

Epoch: 5| Step: 2
Training loss: 0.3915920874764541
Validation loss: 2.402230200262869

Epoch: 5| Step: 3
Training loss: 0.2713508277487514
Validation loss: 2.3898518005159763

Epoch: 5| Step: 4
Training loss: 0.15855614399528817
Validation loss: 2.375614584357183

Epoch: 5| Step: 5
Training loss: 0.3400963907487187
Validation loss: 2.4183072987554657

Epoch: 5| Step: 6
Training loss: 0.2697148043578488
Validation loss: 2.4045291314395234

Epoch: 5| Step: 7
Training loss: 0.26251164648922587
Validation loss: 2.460333908186998

Epoch: 5| Step: 8
Training loss: 0.258918384412681
Validation loss: 2.43776325248306

Epoch: 5| Step: 9
Training loss: 0.28025889608162907
Validation loss: 2.5173024550466505

Epoch: 5| Step: 10
Training loss: 0.27703524610861363
Validation loss: 2.466320553281703

Epoch: 442| Step: 0
Training loss: 0.193242721819057
Validation loss: 2.437306242068505

Epoch: 5| Step: 1
Training loss: 0.23198275396459372
Validation loss: 2.4370910063705926

Epoch: 5| Step: 2
Training loss: 0.244690862488815
Validation loss: 2.4117779981109275

Epoch: 5| Step: 3
Training loss: 0.41180462891615766
Validation loss: 2.3620049674121235

Epoch: 5| Step: 4
Training loss: 0.2641116959831453
Validation loss: 2.3643443026678383

Epoch: 5| Step: 5
Training loss: 0.34466766200038723
Validation loss: 2.407394566591322

Epoch: 5| Step: 6
Training loss: 0.3450429399346555
Validation loss: 2.399008109017433

Epoch: 5| Step: 7
Training loss: 0.2911653837396984
Validation loss: 2.41291010220606

Epoch: 5| Step: 8
Training loss: 0.17848920355330544
Validation loss: 2.434594442233998

Epoch: 5| Step: 9
Training loss: 0.20052057220805286
Validation loss: 2.4465107057168

Epoch: 5| Step: 10
Training loss: 0.27588514472862086
Validation loss: 2.46680901559273

Epoch: 443| Step: 0
Training loss: 0.2901717502190503
Validation loss: 2.5066779499720733

Epoch: 5| Step: 1
Training loss: 0.14452548273281754
Validation loss: 2.474778419064707

Epoch: 5| Step: 2
Training loss: 0.23501440091597703
Validation loss: 2.4224242308414077

Epoch: 5| Step: 3
Training loss: 0.29209836732498856
Validation loss: 2.431516982768966

Epoch: 5| Step: 4
Training loss: 0.32257838244807846
Validation loss: 2.4364035722210935

Epoch: 5| Step: 5
Training loss: 0.32917041228171234
Validation loss: 2.390198219826434

Epoch: 5| Step: 6
Training loss: 0.3135926456555516
Validation loss: 2.3634357523587464

Epoch: 5| Step: 7
Training loss: 0.24643854177585167
Validation loss: 2.405854088044769

Epoch: 5| Step: 8
Training loss: 0.15219048591128512
Validation loss: 2.3859212348625825

Epoch: 5| Step: 9
Training loss: 0.21924697247038424
Validation loss: 2.3866874266205826

Epoch: 5| Step: 10
Training loss: 0.3555180232513244
Validation loss: 2.4072529141437

Epoch: 444| Step: 0
Training loss: 0.42813855936338624
Validation loss: 2.38870027086361

Epoch: 5| Step: 1
Training loss: 0.15405053985048262
Validation loss: 2.4809625781447564

Epoch: 5| Step: 2
Training loss: 0.27114678394553027
Validation loss: 2.4473787287871964

Epoch: 5| Step: 3
Training loss: 0.2921047822887606
Validation loss: 2.417328726519448

Epoch: 5| Step: 4
Training loss: 0.27571004915609104
Validation loss: 2.3930804836117927

Epoch: 5| Step: 5
Training loss: 0.16535780109304227
Validation loss: 2.448236491077745

Epoch: 5| Step: 6
Training loss: 0.32993727844759796
Validation loss: 2.4186617777376873

Epoch: 5| Step: 7
Training loss: 0.14299533497805508
Validation loss: 2.414125726747098

Epoch: 5| Step: 8
Training loss: 0.23457427295450992
Validation loss: 2.475170856908094

Epoch: 5| Step: 9
Training loss: 0.22069931026976664
Validation loss: 2.449616193101484

Epoch: 5| Step: 10
Training loss: 0.2885708364943631
Validation loss: 2.483196971684454

Epoch: 445| Step: 0
Training loss: 0.2069907418693861
Validation loss: 2.4582437919910185

Epoch: 5| Step: 1
Training loss: 0.1782376322267645
Validation loss: 2.4508088585029832

Epoch: 5| Step: 2
Training loss: 0.3358666323054966
Validation loss: 2.4715297942628696

Epoch: 5| Step: 3
Training loss: 0.3326989696624609
Validation loss: 2.4151617427311014

Epoch: 5| Step: 4
Training loss: 0.21679861050847607
Validation loss: 2.458451077572051

Epoch: 5| Step: 5
Training loss: 0.23502890443335214
Validation loss: 2.4317394020565843

Epoch: 5| Step: 6
Training loss: 0.25361656389546683
Validation loss: 2.44934552098106

Epoch: 5| Step: 7
Training loss: 0.30592618921352244
Validation loss: 2.461226824427052

Epoch: 5| Step: 8
Training loss: 0.28017796076461704
Validation loss: 2.4654787820410915

Epoch: 5| Step: 9
Training loss: 0.2062682541080854
Validation loss: 2.4660652976435613

Epoch: 5| Step: 10
Training loss: 0.2748919767928604
Validation loss: 2.429401429532121

Epoch: 446| Step: 0
Training loss: 0.22008398020480865
Validation loss: 2.486906816980378

Epoch: 5| Step: 1
Training loss: 0.20472270502664416
Validation loss: 2.4628034349860464

Epoch: 5| Step: 2
Training loss: 0.11341364703674171
Validation loss: 2.4575597033466603

Epoch: 5| Step: 3
Training loss: 0.19689156220419426
Validation loss: 2.424696038211124

Epoch: 5| Step: 4
Training loss: 0.2107892928628549
Validation loss: 2.4231249422947165

Epoch: 5| Step: 5
Training loss: 0.37958389328595316
Validation loss: 2.394127952973371

Epoch: 5| Step: 6
Training loss: 0.192433365119848
Validation loss: 2.400187993634073

Epoch: 5| Step: 7
Training loss: 0.38068963205219286
Validation loss: 2.406536586503548

Epoch: 5| Step: 8
Training loss: 0.4448080384444897
Validation loss: 2.4236586275653385

Epoch: 5| Step: 9
Training loss: 0.21314257840129106
Validation loss: 2.435198100562341

Epoch: 5| Step: 10
Training loss: 0.2522455041917623
Validation loss: 2.4693715818873607

Epoch: 447| Step: 0
Training loss: 0.19098319771082425
Validation loss: 2.418221533256325

Epoch: 5| Step: 1
Training loss: 0.3249827884738238
Validation loss: 2.390276293704771

Epoch: 5| Step: 2
Training loss: 0.15533198446443136
Validation loss: 2.415039521612437

Epoch: 5| Step: 3
Training loss: 0.4048569711037656
Validation loss: 2.388933361121557

Epoch: 5| Step: 4
Training loss: 0.20653850469432022
Validation loss: 2.369949810093218

Epoch: 5| Step: 5
Training loss: 0.3083746651491868
Validation loss: 2.3602269924383337

Epoch: 5| Step: 6
Training loss: 0.34803214807318295
Validation loss: 2.3426265635547843

Epoch: 5| Step: 7
Training loss: 0.2434582749636052
Validation loss: 2.3800090111168686

Epoch: 5| Step: 8
Training loss: 0.2495985383978256
Validation loss: 2.4353795047888562

Epoch: 5| Step: 9
Training loss: 0.292150154889105
Validation loss: 2.4099391123385536

Epoch: 5| Step: 10
Training loss: 0.1454033316502411
Validation loss: 2.431089764401498

Epoch: 448| Step: 0
Training loss: 0.19792771413153262
Validation loss: 2.465816745387937

Epoch: 5| Step: 1
Training loss: 0.1522015005286797
Validation loss: 2.4349519438982563

Epoch: 5| Step: 2
Training loss: 0.18235193459742627
Validation loss: 2.470537339559169

Epoch: 5| Step: 3
Training loss: 0.2573994882947553
Validation loss: 2.4790044476229776

Epoch: 5| Step: 4
Training loss: 0.3589121284053283
Validation loss: 2.5014470506535664

Epoch: 5| Step: 5
Training loss: 0.23935260062831953
Validation loss: 2.4952558305351977

Epoch: 5| Step: 6
Training loss: 0.35272149731014013
Validation loss: 2.437345021813547

Epoch: 5| Step: 7
Training loss: 0.16360744878950015
Validation loss: 2.4234668757016546

Epoch: 5| Step: 8
Training loss: 0.14589064116374206
Validation loss: 2.430661244846161

Epoch: 5| Step: 9
Training loss: 0.3678999947946335
Validation loss: 2.408939603018226

Epoch: 5| Step: 10
Training loss: 0.33370959260551886
Validation loss: 2.4292875890044474

Epoch: 449| Step: 0
Training loss: 0.3405743670672105
Validation loss: 2.3700536461168817

Epoch: 5| Step: 1
Training loss: 0.181611161252174
Validation loss: 2.4330576931733714

Epoch: 5| Step: 2
Training loss: 0.18747951475135777
Validation loss: 2.438588265203411

Epoch: 5| Step: 3
Training loss: 0.2533377812699881
Validation loss: 2.441248253876199

Epoch: 5| Step: 4
Training loss: 0.3952214652624458
Validation loss: 2.4419885047873233

Epoch: 5| Step: 5
Training loss: 0.24384662473656726
Validation loss: 2.4446346996501056

Epoch: 5| Step: 6
Training loss: 0.13667053326098275
Validation loss: 2.414908079730302

Epoch: 5| Step: 7
Training loss: 0.20646209576396213
Validation loss: 2.408076624454574

Epoch: 5| Step: 8
Training loss: 0.2541089056128313
Validation loss: 2.3947828364398913

Epoch: 5| Step: 9
Training loss: 0.35388036216384217
Validation loss: 2.398701770168528

Epoch: 5| Step: 10
Training loss: 0.23949287700662705
Validation loss: 2.4136881742685894

Epoch: 450| Step: 0
Training loss: 0.3351959871863908
Validation loss: 2.4204831482716296

Epoch: 5| Step: 1
Training loss: 0.3016403364621284
Validation loss: 2.414853361081062

Epoch: 5| Step: 2
Training loss: 0.30630274094682525
Validation loss: 2.4175843401377204

Epoch: 5| Step: 3
Training loss: 0.22059238660169214
Validation loss: 2.4327214179264667

Epoch: 5| Step: 4
Training loss: 0.1809519973441739
Validation loss: 2.4255800997864445

Epoch: 5| Step: 5
Training loss: 0.21262999863778725
Validation loss: 2.4264023260375507

Epoch: 5| Step: 6
Training loss: 0.29888130163635546
Validation loss: 2.4182623099348377

Epoch: 5| Step: 7
Training loss: 0.20622234845479434
Validation loss: 2.439684234979148

Epoch: 5| Step: 8
Training loss: 0.3029190484643738
Validation loss: 2.401919609196224

Epoch: 5| Step: 9
Training loss: 0.28519452504424325
Validation loss: 2.4162166510268035

Epoch: 5| Step: 10
Training loss: 0.1434335067396784
Validation loss: 2.419683621328955

Testing loss: 2.284125618949109
