Epoch: 1| Step: 0
Training loss: 4.631277412199576
Validation loss: 5.731856689161962

Epoch: 5| Step: 1
Training loss: 7.373434902868927
Validation loss: 5.713798283042135

Epoch: 5| Step: 2
Training loss: 4.516506016725882
Validation loss: 5.696590834963939

Epoch: 5| Step: 3
Training loss: 5.782960710788163
Validation loss: 5.677854555310304

Epoch: 5| Step: 4
Training loss: 5.654780075694171
Validation loss: 5.656933765987703

Epoch: 5| Step: 5
Training loss: 6.3287286917870045
Validation loss: 5.63296706238321

Epoch: 5| Step: 6
Training loss: 6.632517741812605
Validation loss: 5.605483663129726

Epoch: 5| Step: 7
Training loss: 5.801591378614497
Validation loss: 5.574186375899925

Epoch: 5| Step: 8
Training loss: 5.3907682980274325
Validation loss: 5.538435934337313

Epoch: 5| Step: 9
Training loss: 5.162588766226208
Validation loss: 5.498850921488801

Epoch: 5| Step: 10
Training loss: 3.948285302873355
Validation loss: 5.455261415606401

Epoch: 2| Step: 0
Training loss: 5.833898389787337
Validation loss: 5.407188352587079

Epoch: 5| Step: 1
Training loss: 5.6957180470108355
Validation loss: 5.3579747070511194

Epoch: 5| Step: 2
Training loss: 5.385387585362829
Validation loss: 5.303232922699068

Epoch: 5| Step: 3
Training loss: 4.480330820130641
Validation loss: 5.248666987654882

Epoch: 5| Step: 4
Training loss: 4.629244532074768
Validation loss: 5.1936959147813235

Epoch: 5| Step: 5
Training loss: 5.673681554690323
Validation loss: 5.139721980584295

Epoch: 5| Step: 6
Training loss: 4.902210103071197
Validation loss: 5.085117893605797

Epoch: 5| Step: 7
Training loss: 5.1013166710128965
Validation loss: 5.032575842915587

Epoch: 5| Step: 8
Training loss: 5.247832804644962
Validation loss: 4.979985232350464

Epoch: 5| Step: 9
Training loss: 5.551281019956062
Validation loss: 4.926346357341563

Epoch: 5| Step: 10
Training loss: 4.376552851161378
Validation loss: 4.866437375230901

Epoch: 3| Step: 0
Training loss: 4.467513333446413
Validation loss: 4.809101843511292

Epoch: 5| Step: 1
Training loss: 5.134492410535122
Validation loss: 4.75416535586557

Epoch: 5| Step: 2
Training loss: 5.592662343246845
Validation loss: 4.698579169285641

Epoch: 5| Step: 3
Training loss: 4.4211934241724045
Validation loss: 4.646618357053115

Epoch: 5| Step: 4
Training loss: 4.006539958869324
Validation loss: 4.605780194834985

Epoch: 5| Step: 5
Training loss: 4.2690123358749545
Validation loss: 4.5733268076037135

Epoch: 5| Step: 6
Training loss: 4.7118115476218625
Validation loss: 4.545842264760917

Epoch: 5| Step: 7
Training loss: 4.050113987201616
Validation loss: 4.517463201786348

Epoch: 5| Step: 8
Training loss: 4.2234753176922055
Validation loss: 4.493265054733602

Epoch: 5| Step: 9
Training loss: 5.648496086692619
Validation loss: 4.468043115309458

Epoch: 5| Step: 10
Training loss: 4.770761791953307
Validation loss: 4.43847573884985

Epoch: 4| Step: 0
Training loss: 4.381299742063943
Validation loss: 4.410590974068103

Epoch: 5| Step: 1
Training loss: 5.3208335587698885
Validation loss: 4.382564898951482

Epoch: 5| Step: 2
Training loss: 3.623761458758751
Validation loss: 4.356435359094383

Epoch: 5| Step: 3
Training loss: 4.560930792191667
Validation loss: 4.336080654433991

Epoch: 5| Step: 4
Training loss: 4.850681783989881
Validation loss: 4.319371780420731

Epoch: 5| Step: 5
Training loss: 4.922515536817032
Validation loss: 4.297901965907446

Epoch: 5| Step: 6
Training loss: 4.244594502306866
Validation loss: 4.274342772730249

Epoch: 5| Step: 7
Training loss: 3.231018093501215
Validation loss: 4.256659708533807

Epoch: 5| Step: 8
Training loss: 4.392780250115599
Validation loss: 4.239823566487746

Epoch: 5| Step: 9
Training loss: 4.439501458780552
Validation loss: 4.218612511877216

Epoch: 5| Step: 10
Training loss: 4.331200123509383
Validation loss: 4.196388366842751

Epoch: 5| Step: 0
Training loss: 5.944731474667986
Validation loss: 4.177201520276684

Epoch: 5| Step: 1
Training loss: 3.6015374768229815
Validation loss: 4.159488257495677

Epoch: 5| Step: 2
Training loss: 3.386526416918278
Validation loss: 4.146170013125226

Epoch: 5| Step: 3
Training loss: 3.8523941225507894
Validation loss: 4.125013593177113

Epoch: 5| Step: 4
Training loss: 4.53752953385759
Validation loss: 4.114309135367256

Epoch: 5| Step: 5
Training loss: 4.437487320143085
Validation loss: 4.097871440557788

Epoch: 5| Step: 6
Training loss: 4.377229830750373
Validation loss: 4.088240982744382

Epoch: 5| Step: 7
Training loss: 3.995726448249825
Validation loss: 4.075506216656801

Epoch: 5| Step: 8
Training loss: 4.00198791697297
Validation loss: 4.064102182536271

Epoch: 5| Step: 9
Training loss: 3.3115351009360365
Validation loss: 4.04094169837455

Epoch: 5| Step: 10
Training loss: 4.7073884314039995
Validation loss: 4.027340373691327

Epoch: 6| Step: 0
Training loss: 4.215657775163316
Validation loss: 4.010234993680623

Epoch: 5| Step: 1
Training loss: 4.595249891324813
Validation loss: 3.993965274048457

Epoch: 5| Step: 2
Training loss: 4.959189183504506
Validation loss: 3.979470687476966

Epoch: 5| Step: 3
Training loss: 3.407843960525416
Validation loss: 3.9642997856321704

Epoch: 5| Step: 4
Training loss: 4.078299449244143
Validation loss: 3.9562049925240736

Epoch: 5| Step: 5
Training loss: 4.666989633192699
Validation loss: 3.934747843870479

Epoch: 5| Step: 6
Training loss: 3.783562323632521
Validation loss: 3.92034219457646

Epoch: 5| Step: 7
Training loss: 3.2232660999669713
Validation loss: 3.9049428151364367

Epoch: 5| Step: 8
Training loss: 4.259550247449474
Validation loss: 3.8955359482239045

Epoch: 5| Step: 9
Training loss: 3.116418576353631
Validation loss: 3.888051954988749

Epoch: 5| Step: 10
Training loss: 4.359556132829691
Validation loss: 3.8785375549924463

Epoch: 7| Step: 0
Training loss: 4.005523682454409
Validation loss: 3.8563644120702167

Epoch: 5| Step: 1
Training loss: 3.7765188332220276
Validation loss: 3.8404256519779474

Epoch: 5| Step: 2
Training loss: 4.361831027879402
Validation loss: 3.8255584772353552

Epoch: 5| Step: 3
Training loss: 3.953871223069943
Validation loss: 3.810382057709649

Epoch: 5| Step: 4
Training loss: 3.278459070454891
Validation loss: 3.7951680207664693

Epoch: 5| Step: 5
Training loss: 4.5253746088408855
Validation loss: 3.7794902954141936

Epoch: 5| Step: 6
Training loss: 3.0236688569730017
Validation loss: 3.7584070235071407

Epoch: 5| Step: 7
Training loss: 3.4559238880129826
Validation loss: 3.7415231118402517

Epoch: 5| Step: 8
Training loss: 4.384127659254644
Validation loss: 3.725525739124292

Epoch: 5| Step: 9
Training loss: 4.409315841786223
Validation loss: 3.710263939583935

Epoch: 5| Step: 10
Training loss: 3.95967120934562
Validation loss: 3.6952938976130505

Epoch: 8| Step: 0
Training loss: 3.662009634058398
Validation loss: 3.6813235425783875

Epoch: 5| Step: 1
Training loss: 4.2571738787843865
Validation loss: 3.670214507394876

Epoch: 5| Step: 2
Training loss: 3.8896594707036587
Validation loss: 3.660464751674309

Epoch: 5| Step: 3
Training loss: 3.899951587278703
Validation loss: 3.6508841246322734

Epoch: 5| Step: 4
Training loss: 2.9771950517696584
Validation loss: 3.6403351468161187

Epoch: 5| Step: 5
Training loss: 4.120115682959254
Validation loss: 3.632880451697303

Epoch: 5| Step: 6
Training loss: 4.0093213191493575
Validation loss: 3.6244542110938553

Epoch: 5| Step: 7
Training loss: 3.9188918968684017
Validation loss: 3.6176678894385708

Epoch: 5| Step: 8
Training loss: 3.726643111598639
Validation loss: 3.606252866129542

Epoch: 5| Step: 9
Training loss: 3.5396975859010595
Validation loss: 3.603620876337307

Epoch: 5| Step: 10
Training loss: 3.996794608398539
Validation loss: 3.593602765006716

Epoch: 9| Step: 0
Training loss: 3.730787141803822
Validation loss: 3.5855695694041025

Epoch: 5| Step: 1
Training loss: 3.159405179355967
Validation loss: 3.580456747869833

Epoch: 5| Step: 2
Training loss: 3.8466113845405228
Validation loss: 3.5725575722284724

Epoch: 5| Step: 3
Training loss: 3.2311945956588017
Validation loss: 3.567612162743633

Epoch: 5| Step: 4
Training loss: 3.7900050927684052
Validation loss: 3.561984662683312

Epoch: 5| Step: 5
Training loss: 3.9722724961757736
Validation loss: 3.554734317111089

Epoch: 5| Step: 6
Training loss: 4.224725179368065
Validation loss: 3.5499240046167193

Epoch: 5| Step: 7
Training loss: 4.506929995463518
Validation loss: 3.5441363275687165

Epoch: 5| Step: 8
Training loss: 3.24705327768088
Validation loss: 3.53989941094584

Epoch: 5| Step: 9
Training loss: 3.4962735092578336
Validation loss: 3.535387750330509

Epoch: 5| Step: 10
Training loss: 3.9734140459179246
Validation loss: 3.5304761200687165

Epoch: 10| Step: 0
Training loss: 3.667865528283355
Validation loss: 3.525324992280011

Epoch: 5| Step: 1
Training loss: 3.7778736519958334
Validation loss: 3.5204377944585312

Epoch: 5| Step: 2
Training loss: 4.073671679099419
Validation loss: 3.5190818251745166

Epoch: 5| Step: 3
Training loss: 3.7670452557815715
Validation loss: 3.5145030545997638

Epoch: 5| Step: 4
Training loss: 3.2968115054701106
Validation loss: 3.5074286607267537

Epoch: 5| Step: 5
Training loss: 3.9788855941059533
Validation loss: 3.50891331776532

Epoch: 5| Step: 6
Training loss: 3.314147971137856
Validation loss: 3.5007009888300282

Epoch: 5| Step: 7
Training loss: 3.4997969977226613
Validation loss: 3.4956329058466906

Epoch: 5| Step: 8
Training loss: 3.644095015508743
Validation loss: 3.4888155189671135

Epoch: 5| Step: 9
Training loss: 4.44820541885874
Validation loss: 3.4861246001517507

Epoch: 5| Step: 10
Training loss: 3.1721326601205253
Validation loss: 3.475005957851465

Epoch: 11| Step: 0
Training loss: 3.143625372962667
Validation loss: 3.470836929169535

Epoch: 5| Step: 1
Training loss: 3.4013314389002107
Validation loss: 3.467407361379038

Epoch: 5| Step: 2
Training loss: 3.5107817115734155
Validation loss: 3.4542159205553062

Epoch: 5| Step: 3
Training loss: 3.38257342544336
Validation loss: 3.4480192558735516

Epoch: 5| Step: 4
Training loss: 2.721567382247458
Validation loss: 3.4415967198877047

Epoch: 5| Step: 5
Training loss: 3.983314043793732
Validation loss: 3.4403141975430502

Epoch: 5| Step: 6
Training loss: 3.1542917351931807
Validation loss: 3.440536200757863

Epoch: 5| Step: 7
Training loss: 4.350317292315958
Validation loss: 3.438098126054578

Epoch: 5| Step: 8
Training loss: 3.8194490482803496
Validation loss: 3.436236651851811

Epoch: 5| Step: 9
Training loss: 4.578917763459121
Validation loss: 3.4340832783258897

Epoch: 5| Step: 10
Training loss: 3.8732544443716486
Validation loss: 3.4263408522484284

Epoch: 12| Step: 0
Training loss: 3.851826563946402
Validation loss: 3.4214926181195255

Epoch: 5| Step: 1
Training loss: 4.695274721015858
Validation loss: 3.418069749971834

Epoch: 5| Step: 2
Training loss: 3.5623792661319205
Validation loss: 3.4186227562904627

Epoch: 5| Step: 3
Training loss: 3.946265016901192
Validation loss: 3.4120153875816768

Epoch: 5| Step: 4
Training loss: 3.1205635623090795
Validation loss: 3.40753166875396

Epoch: 5| Step: 5
Training loss: 3.716211301908126
Validation loss: 3.4097349717175756

Epoch: 5| Step: 6
Training loss: 3.0541756047373494
Validation loss: 3.4092381941798386

Epoch: 5| Step: 7
Training loss: 3.5105149494000076
Validation loss: 3.4071225699497667

Epoch: 5| Step: 8
Training loss: 4.010978890514914
Validation loss: 3.4024355979939482

Epoch: 5| Step: 9
Training loss: 3.123572977399696
Validation loss: 3.3973365253483654

Epoch: 5| Step: 10
Training loss: 2.954736502012605
Validation loss: 3.3949843285952053

Epoch: 13| Step: 0
Training loss: 2.720088673015754
Validation loss: 3.395029450089072

Epoch: 5| Step: 1
Training loss: 3.2528559534104327
Validation loss: 3.3938931186161425

Epoch: 5| Step: 2
Training loss: 3.9870914548895566
Validation loss: 3.3907417106020556

Epoch: 5| Step: 3
Training loss: 3.7051081115764
Validation loss: 3.3886085102658114

Epoch: 5| Step: 4
Training loss: 3.832757505760236
Validation loss: 3.386954175786415

Epoch: 5| Step: 5
Training loss: 4.348535988528814
Validation loss: 3.38644785331696

Epoch: 5| Step: 6
Training loss: 3.6525760026004863
Validation loss: 3.3846488075521117

Epoch: 5| Step: 7
Training loss: 3.593846195426203
Validation loss: 3.3821186266394876

Epoch: 5| Step: 8
Training loss: 3.7884118219499885
Validation loss: 3.37974538621873

Epoch: 5| Step: 9
Training loss: 3.7789226336830852
Validation loss: 3.3792826326066208

Epoch: 5| Step: 10
Training loss: 2.6319459117213184
Validation loss: 3.376968399981516

Epoch: 14| Step: 0
Training loss: 3.9575852875185644
Validation loss: 3.375318740809229

Epoch: 5| Step: 1
Training loss: 4.037306147312094
Validation loss: 3.3752116232290312

Epoch: 5| Step: 2
Training loss: 2.6902723872176098
Validation loss: 3.3740459599227086

Epoch: 5| Step: 3
Training loss: 3.2498142482787276
Validation loss: 3.372318297750063

Epoch: 5| Step: 4
Training loss: 3.783224803919559
Validation loss: 3.370582302313773

Epoch: 5| Step: 5
Training loss: 3.6080026370798017
Validation loss: 3.369503338255714

Epoch: 5| Step: 6
Training loss: 3.534153377691169
Validation loss: 3.368530116921545

Epoch: 5| Step: 7
Training loss: 3.5633768709078604
Validation loss: 3.3672503603098938

Epoch: 5| Step: 8
Training loss: 3.8975342218194706
Validation loss: 3.3659053424960965

Epoch: 5| Step: 9
Training loss: 3.378044450701187
Validation loss: 3.36487158251712

Epoch: 5| Step: 10
Training loss: 3.7640893107813707
Validation loss: 3.363114412013843

Epoch: 15| Step: 0
Training loss: 3.011273500850401
Validation loss: 3.361771514242775

Epoch: 5| Step: 1
Training loss: 3.2016750124164437
Validation loss: 3.3614625351858516

Epoch: 5| Step: 2
Training loss: 4.2173455055037845
Validation loss: 3.3602965151521027

Epoch: 5| Step: 3
Training loss: 3.638304400559801
Validation loss: 3.359240336865834

Epoch: 5| Step: 4
Training loss: 3.426683783309084
Validation loss: 3.3575132552593003

Epoch: 5| Step: 5
Training loss: 3.5977944876654746
Validation loss: 3.3557002686903314

Epoch: 5| Step: 6
Training loss: 3.586146263411883
Validation loss: 3.354808978734076

Epoch: 5| Step: 7
Training loss: 3.7666563782227924
Validation loss: 3.3539277158928287

Epoch: 5| Step: 8
Training loss: 3.7600579482543828
Validation loss: 3.352741773175912

Epoch: 5| Step: 9
Training loss: 3.4726437545912003
Validation loss: 3.3518128759907673

Epoch: 5| Step: 10
Training loss: 3.7230000292142487
Validation loss: 3.3504001797164515

Epoch: 16| Step: 0
Training loss: 3.6570209440278836
Validation loss: 3.349477752765818

Epoch: 5| Step: 1
Training loss: 3.3929436837539004
Validation loss: 3.3476804308651498

Epoch: 5| Step: 2
Training loss: 4.005765098232396
Validation loss: 3.3469215925473375

Epoch: 5| Step: 3
Training loss: 3.441888677965746
Validation loss: 3.345857733555787

Epoch: 5| Step: 4
Training loss: 4.21622419686993
Validation loss: 3.3445756299460276

Epoch: 5| Step: 5
Training loss: 3.5353797462587164
Validation loss: 3.3440826882268366

Epoch: 5| Step: 6
Training loss: 3.023484655993289
Validation loss: 3.342367707464204

Epoch: 5| Step: 7
Training loss: 3.5985393952003073
Validation loss: 3.3410688140470333

Epoch: 5| Step: 8
Training loss: 3.6116567558102126
Validation loss: 3.3400316008188664

Epoch: 5| Step: 9
Training loss: 3.4992320716912637
Validation loss: 3.3393845489133827

Epoch: 5| Step: 10
Training loss: 3.218849106531351
Validation loss: 3.3381062750482364

Epoch: 17| Step: 0
Training loss: 3.327882999701851
Validation loss: 3.33684809845164

Epoch: 5| Step: 1
Training loss: 4.145146503137218
Validation loss: 3.336484648961138

Epoch: 5| Step: 2
Training loss: 2.8166272715535383
Validation loss: 3.334796458788772

Epoch: 5| Step: 3
Training loss: 4.448271237727589
Validation loss: 3.3339673444289386

Epoch: 5| Step: 4
Training loss: 3.8677339418225967
Validation loss: 3.3326468919675345

Epoch: 5| Step: 5
Training loss: 3.216993130207879
Validation loss: 3.3319563818600515

Epoch: 5| Step: 6
Training loss: 3.2528410011645854
Validation loss: 3.330914940356727

Epoch: 5| Step: 7
Training loss: 3.7051535414207777
Validation loss: 3.3290307653784597

Epoch: 5| Step: 8
Training loss: 3.454472067614699
Validation loss: 3.3291411084305715

Epoch: 5| Step: 9
Training loss: 3.0760060099132547
Validation loss: 3.3272959706745864

Epoch: 5| Step: 10
Training loss: 3.6743915131962375
Validation loss: 3.326920301268545

Epoch: 18| Step: 0
Training loss: 3.777428201009483
Validation loss: 3.3255667364535633

Epoch: 5| Step: 1
Training loss: 3.6573092238655684
Validation loss: 3.32654795645728

Epoch: 5| Step: 2
Training loss: 3.381837206495214
Validation loss: 3.323626266805194

Epoch: 5| Step: 3
Training loss: 3.707372105065128
Validation loss: 3.3231935116068922

Epoch: 5| Step: 4
Training loss: 4.177736657754168
Validation loss: 3.321207976932365

Epoch: 5| Step: 5
Training loss: 3.7929727729123877
Validation loss: 3.3195531883373306

Epoch: 5| Step: 6
Training loss: 3.523917899189692
Validation loss: 3.319349875035294

Epoch: 5| Step: 7
Training loss: 2.639062362679929
Validation loss: 3.317694807199705

Epoch: 5| Step: 8
Training loss: 3.033672033690459
Validation loss: 3.317433638516316

Epoch: 5| Step: 9
Training loss: 3.6607177043194374
Validation loss: 3.3156454561441855

Epoch: 5| Step: 10
Training loss: 3.612491863729957
Validation loss: 3.316245280623857

Epoch: 19| Step: 0
Training loss: 3.790843678682044
Validation loss: 3.313999909883423

Epoch: 5| Step: 1
Training loss: 3.6309698210155217
Validation loss: 3.313368504087637

Epoch: 5| Step: 2
Training loss: 3.0028056694411203
Validation loss: 3.3114913361303895

Epoch: 5| Step: 3
Training loss: 3.5190045876154654
Validation loss: 3.3106219585999703

Epoch: 5| Step: 4
Training loss: 2.9472598005658153
Validation loss: 3.3093746468789393

Epoch: 5| Step: 5
Training loss: 3.9272781175358062
Validation loss: 3.308537853905065

Epoch: 5| Step: 6
Training loss: 3.210234999091133
Validation loss: 3.3080915438996152

Epoch: 5| Step: 7
Training loss: 3.7997666638662304
Validation loss: 3.3061716340842677

Epoch: 5| Step: 8
Training loss: 3.393933909791586
Validation loss: 3.3055862682011052

Epoch: 5| Step: 9
Training loss: 4.1287471051253615
Validation loss: 3.3049967666259423

Epoch: 5| Step: 10
Training loss: 3.523001024231449
Validation loss: 3.304071786439956

Epoch: 20| Step: 0
Training loss: 3.9510345359688954
Validation loss: 3.303912640158052

Epoch: 5| Step: 1
Training loss: 3.638808947616098
Validation loss: 3.301778905397482

Epoch: 5| Step: 2
Training loss: 3.861429138869032
Validation loss: 3.300926194925607

Epoch: 5| Step: 3
Training loss: 2.652779230202837
Validation loss: 3.2999812884466806

Epoch: 5| Step: 4
Training loss: 4.136612239687593
Validation loss: 3.2979612518091717

Epoch: 5| Step: 5
Training loss: 3.0677137563729833
Validation loss: 3.2961343643780285

Epoch: 5| Step: 6
Training loss: 3.4003782847277515
Validation loss: 3.2953854731991283

Epoch: 5| Step: 7
Training loss: 3.43554978969639
Validation loss: 3.2941898464235115

Epoch: 5| Step: 8
Training loss: 3.574363897326042
Validation loss: 3.2931300506345367

Epoch: 5| Step: 9
Training loss: 3.0073187881125873
Validation loss: 3.293214184720282

Epoch: 5| Step: 10
Training loss: 4.015152840371456
Validation loss: 3.292368732337584

Epoch: 21| Step: 0
Training loss: 4.299583219689684
Validation loss: 3.2909990980847588

Epoch: 5| Step: 1
Training loss: 3.58644808456518
Validation loss: 3.2892231254940945

Epoch: 5| Step: 2
Training loss: 3.2353576052143236
Validation loss: 3.2876101855256983

Epoch: 5| Step: 3
Training loss: 3.2723866234847634
Validation loss: 3.285451348862898

Epoch: 5| Step: 4
Training loss: 3.8660316049909076
Validation loss: 3.282627488101429

Epoch: 5| Step: 5
Training loss: 3.125764371849739
Validation loss: 3.2791364833187298

Epoch: 5| Step: 6
Training loss: 3.0364301013888197
Validation loss: 3.278414376151926

Epoch: 5| Step: 7
Training loss: 4.217517135757159
Validation loss: 3.277206161242925

Epoch: 5| Step: 8
Training loss: 3.4416577250539224
Validation loss: 3.275241314187801

Epoch: 5| Step: 9
Training loss: 2.9359035617882774
Validation loss: 3.2733855491418087

Epoch: 5| Step: 10
Training loss: 3.5152884767321724
Validation loss: 3.2750770002448473

Epoch: 22| Step: 0
Training loss: 3.916377131264244
Validation loss: 3.2755982868956686

Epoch: 5| Step: 1
Training loss: 3.658301666284913
Validation loss: 3.2705337928591995

Epoch: 5| Step: 2
Training loss: 2.6989499522738747
Validation loss: 3.27425912851189

Epoch: 5| Step: 3
Training loss: 3.4955658753890724
Validation loss: 3.289742661524362

Epoch: 5| Step: 4
Training loss: 3.0495440408053667
Validation loss: 3.2669106286467287

Epoch: 5| Step: 5
Training loss: 3.529841319291829
Validation loss: 3.268593784778864

Epoch: 5| Step: 6
Training loss: 3.8445212978210193
Validation loss: 3.2737237145991367

Epoch: 5| Step: 7
Training loss: 3.786460754029953
Validation loss: 3.268251931291337

Epoch: 5| Step: 8
Training loss: 3.1401782880572453
Validation loss: 3.2672170377459633

Epoch: 5| Step: 9
Training loss: 3.8293819932856645
Validation loss: 3.266510319960259

Epoch: 5| Step: 10
Training loss: 3.5891763525422427
Validation loss: 3.2657561034714373

Epoch: 23| Step: 0
Training loss: 3.576960878196113
Validation loss: 3.2644858261617746

Epoch: 5| Step: 1
Training loss: 3.64779206474709
Validation loss: 3.2639189660658796

Epoch: 5| Step: 2
Training loss: 3.644199826461648
Validation loss: 3.2613557853935418

Epoch: 5| Step: 3
Training loss: 3.094782801388258
Validation loss: 3.2593508881327606

Epoch: 5| Step: 4
Training loss: 3.4274587841046085
Validation loss: 3.258453360404755

Epoch: 5| Step: 5
Training loss: 3.4617900960703105
Validation loss: 3.257421598789122

Epoch: 5| Step: 6
Training loss: 3.6325722891853407
Validation loss: 3.256384898467783

Epoch: 5| Step: 7
Training loss: 3.7995849483093473
Validation loss: 3.256315761621157

Epoch: 5| Step: 8
Training loss: 3.6898948522126944
Validation loss: 3.2561209143779877

Epoch: 5| Step: 9
Training loss: 2.403009982884848
Validation loss: 3.254417640130048

Epoch: 5| Step: 10
Training loss: 4.058411874082923
Validation loss: 3.252607657780939

Epoch: 24| Step: 0
Training loss: 3.184353041643348
Validation loss: 3.252165455531598

Epoch: 5| Step: 1
Training loss: 3.544862150839865
Validation loss: 3.2511842808586167

Epoch: 5| Step: 2
Training loss: 4.007367977602026
Validation loss: 3.2522211711987365

Epoch: 5| Step: 3
Training loss: 3.0794197883546435
Validation loss: 3.2485674003187963

Epoch: 5| Step: 4
Training loss: 3.759344284426812
Validation loss: 3.2480521284889203

Epoch: 5| Step: 5
Training loss: 3.6598792688854345
Validation loss: 3.2499404441103286

Epoch: 5| Step: 6
Training loss: 3.667619682496675
Validation loss: 3.247380498589763

Epoch: 5| Step: 7
Training loss: 2.7688780365352454
Validation loss: 3.245351420189039

Epoch: 5| Step: 8
Training loss: 3.83699471691604
Validation loss: 3.2436978256623306

Epoch: 5| Step: 9
Training loss: 3.270306603526173
Validation loss: 3.2422009088876718

Epoch: 5| Step: 10
Training loss: 3.5419196244204203
Validation loss: 3.2428328080332527

Epoch: 25| Step: 0
Training loss: 3.2191070062367513
Validation loss: 3.241861143562322

Epoch: 5| Step: 1
Training loss: 3.835096713839743
Validation loss: 3.239806422200074

Epoch: 5| Step: 2
Training loss: 3.618993320750903
Validation loss: 3.2389897825997074

Epoch: 5| Step: 3
Training loss: 2.931590202451957
Validation loss: 3.2382562126403904

Epoch: 5| Step: 4
Training loss: 3.2732980921519275
Validation loss: 3.236940371287377

Epoch: 5| Step: 5
Training loss: 3.2405456062383755
Validation loss: 3.2354819529897836

Epoch: 5| Step: 6
Training loss: 3.9939879297294714
Validation loss: 3.2343723621489424

Epoch: 5| Step: 7
Training loss: 3.3928275974679494
Validation loss: 3.2328639611306875

Epoch: 5| Step: 8
Training loss: 3.978603596152472
Validation loss: 3.2346455648769186

Epoch: 5| Step: 9
Training loss: 3.5650760639310026
Validation loss: 3.232385300095801

Epoch: 5| Step: 10
Training loss: 3.120097625623341
Validation loss: 3.231756044782524

Epoch: 26| Step: 0
Training loss: 4.142254433222419
Validation loss: 3.2286957846345197

Epoch: 5| Step: 1
Training loss: 3.164362989685786
Validation loss: 3.2296265802871513

Epoch: 5| Step: 2
Training loss: 3.9037781485777323
Validation loss: 3.2283127342699993

Epoch: 5| Step: 3
Training loss: 3.473078733132269
Validation loss: 3.226456965566606

Epoch: 5| Step: 4
Training loss: 3.364093252733333
Validation loss: 3.225840606098459

Epoch: 5| Step: 5
Training loss: 3.412697525735418
Validation loss: 3.226338072111584

Epoch: 5| Step: 6
Training loss: 3.9305740478823483
Validation loss: 3.2240965026344153

Epoch: 5| Step: 7
Training loss: 3.3787645607936923
Validation loss: 3.2212719919706982

Epoch: 5| Step: 8
Training loss: 3.0481395738138692
Validation loss: 3.2208588546707344

Epoch: 5| Step: 9
Training loss: 3.2620353864835523
Validation loss: 3.217374638213958

Epoch: 5| Step: 10
Training loss: 2.937101458845646
Validation loss: 3.221669980968435

Epoch: 27| Step: 0
Training loss: 3.5230138824301984
Validation loss: 3.222707262179245

Epoch: 5| Step: 1
Training loss: 2.9902351723239464
Validation loss: 3.2227032958493758

Epoch: 5| Step: 2
Training loss: 3.8074942072663354
Validation loss: 3.2273398025227253

Epoch: 5| Step: 3
Training loss: 3.883146152705809
Validation loss: 3.228336865643531

Epoch: 5| Step: 4
Training loss: 2.6597183920287955
Validation loss: 3.229922883202021

Epoch: 5| Step: 5
Training loss: 3.509083948609128
Validation loss: 3.2261733907250556

Epoch: 5| Step: 6
Training loss: 3.8335361150650207
Validation loss: 3.2190389769280223

Epoch: 5| Step: 7
Training loss: 3.5870394208372764
Validation loss: 3.2145246343043916

Epoch: 5| Step: 8
Training loss: 3.4120715029470214
Validation loss: 3.2207156180054635

Epoch: 5| Step: 9
Training loss: 3.647422894505421
Validation loss: 3.2169776622282003

Epoch: 5| Step: 10
Training loss: 3.0561195392496665
Validation loss: 3.212611132190591

Epoch: 28| Step: 0
Training loss: 3.78856713901138
Validation loss: 3.2198028594727006

Epoch: 5| Step: 1
Training loss: 2.3409403936072612
Validation loss: 3.221502730878759

Epoch: 5| Step: 2
Training loss: 2.9829956382133878
Validation loss: 3.2247354362520824

Epoch: 5| Step: 3
Training loss: 3.586778463183574
Validation loss: 3.2251565958007813

Epoch: 5| Step: 4
Training loss: 3.853837213955395
Validation loss: 3.214822737423103

Epoch: 5| Step: 5
Training loss: 2.6029807683913524
Validation loss: 3.211089671507468

Epoch: 5| Step: 6
Training loss: 3.300567728393392
Validation loss: 3.212112505981418

Epoch: 5| Step: 7
Training loss: 3.605822511719476
Validation loss: 3.21271361677454

Epoch: 5| Step: 8
Training loss: 3.3037470207532884
Validation loss: 3.2132896736316456

Epoch: 5| Step: 9
Training loss: 3.7728915560030845
Validation loss: 3.2318550110733244

Epoch: 5| Step: 10
Training loss: 4.608412199167575
Validation loss: 3.2135590094285527

Epoch: 29| Step: 0
Training loss: 3.776472367902647
Validation loss: 3.209469058174256

Epoch: 5| Step: 1
Training loss: 3.14929838692605
Validation loss: 3.204106028722988

Epoch: 5| Step: 2
Training loss: 3.334287284405213
Validation loss: 3.2059258005946085

Epoch: 5| Step: 3
Training loss: 3.1921819073464226
Validation loss: 3.2065363708449297

Epoch: 5| Step: 4
Training loss: 3.8961796462138767
Validation loss: 3.2194117084843525

Epoch: 5| Step: 5
Training loss: 4.185992296863363
Validation loss: 3.2247242856673504

Epoch: 5| Step: 6
Training loss: 3.7533676285021027
Validation loss: 3.2053142998328035

Epoch: 5| Step: 7
Training loss: 3.1917869312811695
Validation loss: 3.1982128704511803

Epoch: 5| Step: 8
Training loss: 3.1570607267767516
Validation loss: 3.197390083124061

Epoch: 5| Step: 9
Training loss: 3.421177344423564
Validation loss: 3.1974658627610295

Epoch: 5| Step: 10
Training loss: 2.610251913227264
Validation loss: 3.205245313926606

Epoch: 30| Step: 0
Training loss: 2.9380396895042193
Validation loss: 3.215603239732701

Epoch: 5| Step: 1
Training loss: 4.099917592406751
Validation loss: 3.199554692965725

Epoch: 5| Step: 2
Training loss: 3.927097445326863
Validation loss: 3.1944969346518053

Epoch: 5| Step: 3
Training loss: 4.087333951137954
Validation loss: 3.194097834474802

Epoch: 5| Step: 4
Training loss: 3.7345523552697033
Validation loss: 3.1935097365880143

Epoch: 5| Step: 5
Training loss: 2.8621642469704183
Validation loss: 3.194313353431225

Epoch: 5| Step: 6
Training loss: 4.0689463015782055
Validation loss: 3.218575311673953

Epoch: 5| Step: 7
Training loss: 2.676310822367223
Validation loss: 3.1906550518613805

Epoch: 5| Step: 8
Training loss: 3.2852144542350565
Validation loss: 3.1892314730608353

Epoch: 5| Step: 9
Training loss: 3.295826677459542
Validation loss: 3.194480973335509

Epoch: 5| Step: 10
Training loss: 2.2603040629054996
Validation loss: 3.194147801071851

Epoch: 31| Step: 0
Training loss: 2.7840635662824
Validation loss: 3.196925739886503

Epoch: 5| Step: 1
Training loss: 2.9555431335430375
Validation loss: 3.1911767949982126

Epoch: 5| Step: 2
Training loss: 3.4114551495641554
Validation loss: 3.186512077574047

Epoch: 5| Step: 3
Training loss: 3.771635332054642
Validation loss: 3.184190217654158

Epoch: 5| Step: 4
Training loss: 3.811082920554701
Validation loss: 3.1828544683886797

Epoch: 5| Step: 5
Training loss: 3.993623061095497
Validation loss: 3.181038006461437

Epoch: 5| Step: 6
Training loss: 3.634925277130839
Validation loss: 3.184738495915891

Epoch: 5| Step: 7
Training loss: 3.6195865856595315
Validation loss: 3.1810705369828973

Epoch: 5| Step: 8
Training loss: 2.5729308546243956
Validation loss: 3.1838443220888943

Epoch: 5| Step: 9
Training loss: 3.1830225894376882
Validation loss: 3.187736513715677

Epoch: 5| Step: 10
Training loss: 3.8065931494361824
Validation loss: 3.184832314581216

Epoch: 32| Step: 0
Training loss: 3.0291111272436684
Validation loss: 3.1842292783941573

Epoch: 5| Step: 1
Training loss: 3.358606862807692
Validation loss: 3.183386606231214

Epoch: 5| Step: 2
Training loss: 3.2219678478756024
Validation loss: 3.1794957182756405

Epoch: 5| Step: 3
Training loss: 2.9234474561186357
Validation loss: 3.179663037306816

Epoch: 5| Step: 4
Training loss: 3.079220959120649
Validation loss: 3.1786736973985046

Epoch: 5| Step: 5
Training loss: 3.5325667365398647
Validation loss: 3.1747664345906776

Epoch: 5| Step: 6
Training loss: 3.3687090699605786
Validation loss: 3.1769090711927306

Epoch: 5| Step: 7
Training loss: 3.0510902394840924
Validation loss: 3.1760506048711625

Epoch: 5| Step: 8
Training loss: 3.6270128120930196
Validation loss: 3.174809203011866

Epoch: 5| Step: 9
Training loss: 4.638745476389771
Validation loss: 3.170909570391916

Epoch: 5| Step: 10
Training loss: 3.52224934711568
Validation loss: 3.1718157537368517

Epoch: 33| Step: 0
Training loss: 3.4465212269490024
Validation loss: 3.168448101458791

Epoch: 5| Step: 1
Training loss: 3.408528956711777
Validation loss: 3.1706949954099035

Epoch: 5| Step: 2
Training loss: 3.238300686951619
Validation loss: 3.1677600794956478

Epoch: 5| Step: 3
Training loss: 3.2866921480234357
Validation loss: 3.1684455883448885

Epoch: 5| Step: 4
Training loss: 3.415986311248582
Validation loss: 3.177669551889642

Epoch: 5| Step: 5
Training loss: 3.606049826634797
Validation loss: 3.181878628108003

Epoch: 5| Step: 6
Training loss: 3.8791855387872256
Validation loss: 3.166200435644591

Epoch: 5| Step: 7
Training loss: 3.096982403999279
Validation loss: 3.165180742262723

Epoch: 5| Step: 8
Training loss: 3.120046580773872
Validation loss: 3.1705159257514293

Epoch: 5| Step: 9
Training loss: 3.423378949206559
Validation loss: 3.1806662774091747

Epoch: 5| Step: 10
Training loss: 3.6916565825336813
Validation loss: 3.1885279824130355

Epoch: 34| Step: 0
Training loss: 3.8491914271628964
Validation loss: 3.1595884350163526

Epoch: 5| Step: 1
Training loss: 3.643310211494511
Validation loss: 3.1603486407276997

Epoch: 5| Step: 2
Training loss: 4.0922478402296525
Validation loss: 3.157351988311328

Epoch: 5| Step: 3
Training loss: 3.3384694266674013
Validation loss: 3.1594333359008244

Epoch: 5| Step: 4
Training loss: 2.9181986645428624
Validation loss: 3.1676732575364395

Epoch: 5| Step: 5
Training loss: 3.7060568747934917
Validation loss: 3.195273486491754

Epoch: 5| Step: 6
Training loss: 3.39275043864715
Validation loss: 3.192599652525668

Epoch: 5| Step: 7
Training loss: 2.630980264425112
Validation loss: 3.1544124095354316

Epoch: 5| Step: 8
Training loss: 3.8247909039958707
Validation loss: 3.1523092924484124

Epoch: 5| Step: 9
Training loss: 3.03680916924655
Validation loss: 3.151638190480939

Epoch: 5| Step: 10
Training loss: 2.7039982261764757
Validation loss: 3.1521476760564178

Epoch: 35| Step: 0
Training loss: 2.560594734309118
Validation loss: 3.1506392932991587

Epoch: 5| Step: 1
Training loss: 3.030795348374018
Validation loss: 3.1501655393179866

Epoch: 5| Step: 2
Training loss: 3.509377451188411
Validation loss: 3.1520740195253736

Epoch: 5| Step: 3
Training loss: 2.834099123818348
Validation loss: 3.1530469238308956

Epoch: 5| Step: 4
Training loss: 3.902111821733396
Validation loss: 3.1500519853525524

Epoch: 5| Step: 5
Training loss: 4.008196539074601
Validation loss: 3.153075463191353

Epoch: 5| Step: 6
Training loss: 3.6911910382866844
Validation loss: 3.154203539549749

Epoch: 5| Step: 7
Training loss: 3.6697723212026836
Validation loss: 3.149476154233924

Epoch: 5| Step: 8
Training loss: 3.813393159899432
Validation loss: 3.147712459759754

Epoch: 5| Step: 9
Training loss: 2.885563558610562
Validation loss: 3.1484996077357983

Epoch: 5| Step: 10
Training loss: 3.1814159597339824
Validation loss: 3.203088706846641

Epoch: 36| Step: 0
Training loss: 3.756512264293126
Validation loss: 3.143639921529268

Epoch: 5| Step: 1
Training loss: 3.1745024824446686
Validation loss: 3.1472875673790868

Epoch: 5| Step: 2
Training loss: 3.526964811499425
Validation loss: 3.1674483122008765

Epoch: 5| Step: 3
Training loss: 3.9086957675354337
Validation loss: 3.1680979842880657

Epoch: 5| Step: 4
Training loss: 3.0306386429441643
Validation loss: 3.1685811560994095

Epoch: 5| Step: 5
Training loss: 3.941195615616434
Validation loss: 3.159130882531206

Epoch: 5| Step: 6
Training loss: 2.4996833600747848
Validation loss: 3.1503008724334043

Epoch: 5| Step: 7
Training loss: 3.1845766013047383
Validation loss: 3.1489564034478166

Epoch: 5| Step: 8
Training loss: 3.7863351975908874
Validation loss: 3.152817012423538

Epoch: 5| Step: 9
Training loss: 3.1273288441516494
Validation loss: 3.158632412261278

Epoch: 5| Step: 10
Training loss: 3.289608291682692
Validation loss: 3.175568851306089

Epoch: 37| Step: 0
Training loss: 4.433532015332859
Validation loss: 3.1486442887020574

Epoch: 5| Step: 1
Training loss: 3.000063100786984
Validation loss: 3.1377538067115

Epoch: 5| Step: 2
Training loss: 3.8994596742808834
Validation loss: 3.1383273660928297

Epoch: 5| Step: 3
Training loss: 3.070890027734462
Validation loss: 3.1409279065986384

Epoch: 5| Step: 4
Training loss: 3.6104964458604982
Validation loss: 3.138998677518335

Epoch: 5| Step: 5
Training loss: 3.6365517025779326
Validation loss: 3.1382378926360612

Epoch: 5| Step: 6
Training loss: 3.1817764056547175
Validation loss: 3.133541409956606

Epoch: 5| Step: 7
Training loss: 3.313741775093822
Validation loss: 3.1289170620028766

Epoch: 5| Step: 8
Training loss: 3.502147016035139
Validation loss: 3.124459911969265

Epoch: 5| Step: 9
Training loss: 2.1959684756227618
Validation loss: 3.125199022415878

Epoch: 5| Step: 10
Training loss: 3.0057231036869645
Validation loss: 3.12374185317859

Epoch: 38| Step: 0
Training loss: 3.3224767475448305
Validation loss: 3.1236979768518434

Epoch: 5| Step: 1
Training loss: 2.940123015963622
Validation loss: 3.121507359048111

Epoch: 5| Step: 2
Training loss: 3.1680092391544057
Validation loss: 3.1221876455337827

Epoch: 5| Step: 3
Training loss: 3.287198007151412
Validation loss: 3.1192365736616146

Epoch: 5| Step: 4
Training loss: 3.578609383792137
Validation loss: 3.12490413395672

Epoch: 5| Step: 5
Training loss: 3.625611089302605
Validation loss: 3.1353165126725755

Epoch: 5| Step: 6
Training loss: 4.11683355036918
Validation loss: 3.120188413780766

Epoch: 5| Step: 7
Training loss: 3.034511895435983
Validation loss: 3.1194887485493776

Epoch: 5| Step: 8
Training loss: 3.363005907083587
Validation loss: 3.112915302469753

Epoch: 5| Step: 9
Training loss: 3.4927217557023273
Validation loss: 3.1116475468911515

Epoch: 5| Step: 10
Training loss: 3.068345233148903
Validation loss: 3.110280608798065

Epoch: 39| Step: 0
Training loss: 3.2378525766573287
Validation loss: 3.112697157908392

Epoch: 5| Step: 1
Training loss: 2.6291599916432844
Validation loss: 3.110700247690052

Epoch: 5| Step: 2
Training loss: 3.305853455385076
Validation loss: 3.111911753214651

Epoch: 5| Step: 3
Training loss: 3.919784414240913
Validation loss: 3.1112496623036

Epoch: 5| Step: 4
Training loss: 3.703268828999108
Validation loss: 3.1106686089410034

Epoch: 5| Step: 5
Training loss: 3.527831862294546
Validation loss: 3.111828608540838

Epoch: 5| Step: 6
Training loss: 3.327797600487748
Validation loss: 3.1073624558742443

Epoch: 5| Step: 7
Training loss: 2.957505786467669
Validation loss: 3.108655566319163

Epoch: 5| Step: 8
Training loss: 3.4699489136818733
Validation loss: 3.108628774056687

Epoch: 5| Step: 9
Training loss: 3.708003183019891
Validation loss: 3.1082428369366277

Epoch: 5| Step: 10
Training loss: 3.1502775584658465
Validation loss: 3.104066884452984

Epoch: 40| Step: 0
Training loss: 2.574085839969122
Validation loss: 3.102839531770539

Epoch: 5| Step: 1
Training loss: 2.9310616894323975
Validation loss: 3.101426239545814

Epoch: 5| Step: 2
Training loss: 3.2513138976192457
Validation loss: 3.1005053227100565

Epoch: 5| Step: 3
Training loss: 3.526000991353779
Validation loss: 3.0990404354782966

Epoch: 5| Step: 4
Training loss: 4.22855238689274
Validation loss: 3.0968935613524113

Epoch: 5| Step: 5
Training loss: 3.312824305367682
Validation loss: 3.0996982142425304

Epoch: 5| Step: 6
Training loss: 3.7667475250027387
Validation loss: 3.100423573015257

Epoch: 5| Step: 7
Training loss: 3.0900162794554666
Validation loss: 3.101242823859246

Epoch: 5| Step: 8
Training loss: 3.5350662810115767
Validation loss: 3.101908723474465

Epoch: 5| Step: 9
Training loss: 3.295528191009638
Validation loss: 3.1042505635460573

Epoch: 5| Step: 10
Training loss: 3.1738736475100717
Validation loss: 3.1040916852256384

Epoch: 41| Step: 0
Training loss: 3.602327145645966
Validation loss: 3.10949624593461

Epoch: 5| Step: 1
Training loss: 3.4653042011022293
Validation loss: 3.1123598526063394

Epoch: 5| Step: 2
Training loss: 3.219841040721521
Validation loss: 3.1011010841343154

Epoch: 5| Step: 3
Training loss: 3.700583829439746
Validation loss: 3.094190222944684

Epoch: 5| Step: 4
Training loss: 3.701630367173782
Validation loss: 3.090670346657631

Epoch: 5| Step: 5
Training loss: 3.0908645891872077
Validation loss: 3.089083575764817

Epoch: 5| Step: 6
Training loss: 4.0361605757952095
Validation loss: 3.0861528343543894

Epoch: 5| Step: 7
Training loss: 2.98667475582912
Validation loss: 3.0871175216798155

Epoch: 5| Step: 8
Training loss: 2.856110256791603
Validation loss: 3.0871625988510027

Epoch: 5| Step: 9
Training loss: 2.8055752595098356
Validation loss: 3.0886419924952695

Epoch: 5| Step: 10
Training loss: 3.170827307342404
Validation loss: 3.0891691351198536

Epoch: 42| Step: 0
Training loss: 3.909194446910371
Validation loss: 3.08646765864607

Epoch: 5| Step: 1
Training loss: 3.152139990365254
Validation loss: 3.0853159380149497

Epoch: 5| Step: 2
Training loss: 3.09717131735837
Validation loss: 3.0843191314237774

Epoch: 5| Step: 3
Training loss: 3.396681198024145
Validation loss: 3.0833997832911644

Epoch: 5| Step: 4
Training loss: 4.091209496922039
Validation loss: 3.0827388461929726

Epoch: 5| Step: 5
Training loss: 3.1104927545955805
Validation loss: 3.0804213436815124

Epoch: 5| Step: 6
Training loss: 2.9989757378777497
Validation loss: 3.0802072349484595

Epoch: 5| Step: 7
Training loss: 3.3710862532053807
Validation loss: 3.0794386279458985

Epoch: 5| Step: 8
Training loss: 3.158875836672545
Validation loss: 3.076910183657097

Epoch: 5| Step: 9
Training loss: 3.5993544953509544
Validation loss: 3.0764074593903583

Epoch: 5| Step: 10
Training loss: 2.613572815736952
Validation loss: 3.076976609582751

Epoch: 43| Step: 0
Training loss: 3.4022686289783866
Validation loss: 3.0751848501581205

Epoch: 5| Step: 1
Training loss: 3.8725121418003474
Validation loss: 3.0785837722215925

Epoch: 5| Step: 2
Training loss: 2.7500030344166055
Validation loss: 3.087948789939486

Epoch: 5| Step: 3
Training loss: 2.739450768187306
Validation loss: 3.100225249028543

Epoch: 5| Step: 4
Training loss: 3.7157856642602742
Validation loss: 3.1207527897341785

Epoch: 5| Step: 5
Training loss: 3.6216681065024754
Validation loss: 3.081563400567468

Epoch: 5| Step: 6
Training loss: 3.386057788101135
Validation loss: 3.073252325286531

Epoch: 5| Step: 7
Training loss: 2.8112831026251106
Validation loss: 3.0710674769710966

Epoch: 5| Step: 8
Training loss: 3.136905422332989
Validation loss: 3.08500495923409

Epoch: 5| Step: 9
Training loss: 3.881711254876559
Validation loss: 3.091776853675924

Epoch: 5| Step: 10
Training loss: 3.269653609708225
Validation loss: 3.0797795655036

Epoch: 44| Step: 0
Training loss: 3.8850368828906756
Validation loss: 3.0935964205447815

Epoch: 5| Step: 1
Training loss: 3.575991465061252
Validation loss: 3.0765219333205933

Epoch: 5| Step: 2
Training loss: 2.8661034637005396
Validation loss: 3.0700873451785067

Epoch: 5| Step: 3
Training loss: 3.140638360901306
Validation loss: 3.0693224466292093

Epoch: 5| Step: 4
Training loss: 3.0752728410955954
Validation loss: 3.0685358109617424

Epoch: 5| Step: 5
Training loss: 3.4586240041136382
Validation loss: 3.0668926082438217

Epoch: 5| Step: 6
Training loss: 3.3842499742459324
Validation loss: 3.069730431551251

Epoch: 5| Step: 7
Training loss: 3.782938052350628
Validation loss: 3.071076886504814

Epoch: 5| Step: 8
Training loss: 3.385476840535935
Validation loss: 3.0667685126553113

Epoch: 5| Step: 9
Training loss: 2.5942942955938673
Validation loss: 3.067159122645046

Epoch: 5| Step: 10
Training loss: 3.4111281994761966
Validation loss: 3.0664715365645896

Epoch: 45| Step: 0
Training loss: 2.5501017344507226
Validation loss: 3.067847118681685

Epoch: 5| Step: 1
Training loss: 2.9209097017398147
Validation loss: 3.0680945457795823

Epoch: 5| Step: 2
Training loss: 3.4892716149933416
Validation loss: 3.0892891758040837

Epoch: 5| Step: 3
Training loss: 3.135987459021424
Validation loss: 3.0883839992792645

Epoch: 5| Step: 4
Training loss: 3.2391649243823064
Validation loss: 3.070430633627732

Epoch: 5| Step: 5
Training loss: 3.1685262206023372
Validation loss: 3.0628734241250477

Epoch: 5| Step: 6
Training loss: 3.733665366961631
Validation loss: 3.0613569278180104

Epoch: 5| Step: 7
Training loss: 3.237834462449491
Validation loss: 3.060252374609804

Epoch: 5| Step: 8
Training loss: 3.489718321661302
Validation loss: 3.059101409663481

Epoch: 5| Step: 9
Training loss: 3.050264322052633
Validation loss: 3.0622624214508223

Epoch: 5| Step: 10
Training loss: 4.449644207393182
Validation loss: 3.060489192797351

Epoch: 46| Step: 0
Training loss: 2.5694495146646967
Validation loss: 3.055700185403733

Epoch: 5| Step: 1
Training loss: 2.9758338336700243
Validation loss: 3.0556575587211325

Epoch: 5| Step: 2
Training loss: 2.505512454368683
Validation loss: 3.055536459387369

Epoch: 5| Step: 3
Training loss: 3.484497205019621
Validation loss: 3.0538018003741194

Epoch: 5| Step: 4
Training loss: 3.3306442540221233
Validation loss: 3.051554590007703

Epoch: 5| Step: 5
Training loss: 3.7857091163332623
Validation loss: 3.049261316738284

Epoch: 5| Step: 6
Training loss: 3.745601235831023
Validation loss: 3.058719856045985

Epoch: 5| Step: 7
Training loss: 3.53101665434776
Validation loss: 3.069890919506764

Epoch: 5| Step: 8
Training loss: 3.7773979049003827
Validation loss: 3.0600990140330997

Epoch: 5| Step: 9
Training loss: 3.091911925863964
Validation loss: 3.0458254116720656

Epoch: 5| Step: 10
Training loss: 3.5557736257065784
Validation loss: 3.0428830264417392

Epoch: 47| Step: 0
Training loss: 3.481788941447785
Validation loss: 3.044074567065746

Epoch: 5| Step: 1
Training loss: 3.5960951078098673
Validation loss: 3.04476078915014

Epoch: 5| Step: 2
Training loss: 3.2048920014227766
Validation loss: 3.0452552615056274

Epoch: 5| Step: 3
Training loss: 4.313326991301114
Validation loss: 3.046148790300929

Epoch: 5| Step: 4
Training loss: 3.2465449821755223
Validation loss: 3.044530832883207

Epoch: 5| Step: 5
Training loss: 2.823295389556228
Validation loss: 3.04209379539596

Epoch: 5| Step: 6
Training loss: 3.0068679713704456
Validation loss: 3.04296647193294

Epoch: 5| Step: 7
Training loss: 3.1996028236431067
Validation loss: 3.0412070286255233

Epoch: 5| Step: 8
Training loss: 2.7658820598555467
Validation loss: 3.0400308876163145

Epoch: 5| Step: 9
Training loss: 3.6081596409059697
Validation loss: 3.0393255115578763

Epoch: 5| Step: 10
Training loss: 2.908765463072786
Validation loss: 3.0416234069952988

Epoch: 48| Step: 0
Training loss: 3.4391393740431977
Validation loss: 3.041242392619366

Epoch: 5| Step: 1
Training loss: 3.3597931357690958
Validation loss: 3.044860101256979

Epoch: 5| Step: 2
Training loss: 3.3040362498717095
Validation loss: 3.0462198087809007

Epoch: 5| Step: 3
Training loss: 3.0492894705200446
Validation loss: 3.055647791281095

Epoch: 5| Step: 4
Training loss: 2.935608437426249
Validation loss: 3.0468679423285967

Epoch: 5| Step: 5
Training loss: 3.661556338449692
Validation loss: 3.043116263006156

Epoch: 5| Step: 6
Training loss: 3.744204939009773
Validation loss: 3.0399309758422763

Epoch: 5| Step: 7
Training loss: 3.069824490578265
Validation loss: 3.0342396086705707

Epoch: 5| Step: 8
Training loss: 3.254059676895668
Validation loss: 3.03096943571651

Epoch: 5| Step: 9
Training loss: 2.8941605674210007
Validation loss: 3.0288433640128742

Epoch: 5| Step: 10
Training loss: 3.602329395921643
Validation loss: 3.0321407449237903

Epoch: 49| Step: 0
Training loss: 3.000390345291941
Validation loss: 3.0307929275103223

Epoch: 5| Step: 1
Training loss: 3.275641161640943
Validation loss: 3.0313129661658476

Epoch: 5| Step: 2
Training loss: 3.642628261844969
Validation loss: 3.031841486352272

Epoch: 5| Step: 3
Training loss: 3.366141101366168
Validation loss: 3.029587133419152

Epoch: 5| Step: 4
Training loss: 3.0564120758704734
Validation loss: 3.03053297030903

Epoch: 5| Step: 5
Training loss: 3.459507907426698
Validation loss: 3.027379716281756

Epoch: 5| Step: 6
Training loss: 3.3840969545620254
Validation loss: 3.027910472421616

Epoch: 5| Step: 7
Training loss: 3.7558027512144823
Validation loss: 3.030471385453679

Epoch: 5| Step: 8
Training loss: 2.996100434416435
Validation loss: 3.03194040483871

Epoch: 5| Step: 9
Training loss: 3.216567846041945
Validation loss: 3.028186096647198

Epoch: 5| Step: 10
Training loss: 3.0107673695934385
Validation loss: 3.0305938044276726

Epoch: 50| Step: 0
Training loss: 3.0099032975184765
Validation loss: 3.0254816622198395

Epoch: 5| Step: 1
Training loss: 3.208932960920291
Validation loss: 3.025778567420077

Epoch: 5| Step: 2
Training loss: 4.296631296356039
Validation loss: 3.028339327765633

Epoch: 5| Step: 3
Training loss: 3.320726938749014
Validation loss: 3.029311876164713

Epoch: 5| Step: 4
Training loss: 2.9951569884460167
Validation loss: 3.0233457008223996

Epoch: 5| Step: 5
Training loss: 3.648860669968473
Validation loss: 3.0247494991744674

Epoch: 5| Step: 6
Training loss: 2.8079648222282083
Validation loss: 3.0221193087692693

Epoch: 5| Step: 7
Training loss: 3.1714205110906537
Validation loss: 3.0222680616516677

Epoch: 5| Step: 8
Training loss: 3.0505466346546215
Validation loss: 3.0214940492461992

Epoch: 5| Step: 9
Training loss: 2.9694282158587675
Validation loss: 3.019368643122615

Epoch: 5| Step: 10
Training loss: 3.469870996193462
Validation loss: 3.0204536807619866

Epoch: 51| Step: 0
Training loss: 3.6059308153773673
Validation loss: 3.01977751841323

Epoch: 5| Step: 1
Training loss: 3.433958413958146
Validation loss: 3.02287582552263

Epoch: 5| Step: 2
Training loss: 3.69967658201679
Validation loss: 3.0188215408912793

Epoch: 5| Step: 3
Training loss: 2.71811765135164
Validation loss: 3.0208664114007044

Epoch: 5| Step: 4
Training loss: 3.57378954368828
Validation loss: 3.0183484005071377

Epoch: 5| Step: 5
Training loss: 2.6386586830605654
Validation loss: 3.017092900567328

Epoch: 5| Step: 6
Training loss: 3.7922874333779024
Validation loss: 3.0217678594831963

Epoch: 5| Step: 7
Training loss: 2.8459678636721617
Validation loss: 3.018645494356083

Epoch: 5| Step: 8
Training loss: 3.295495201027475
Validation loss: 3.023490805024985

Epoch: 5| Step: 9
Training loss: 3.3179215023879483
Validation loss: 3.023400279365532

Epoch: 5| Step: 10
Training loss: 2.8765037584497413
Validation loss: 3.0225118950167222

Epoch: 52| Step: 0
Training loss: 3.182126021665583
Validation loss: 3.0197412968880726

Epoch: 5| Step: 1
Training loss: 3.3440600099974085
Validation loss: 3.0201877881602397

Epoch: 5| Step: 2
Training loss: 2.9909193573707267
Validation loss: 3.025127200207712

Epoch: 5| Step: 3
Training loss: 3.123747460164674
Validation loss: 3.016846392611267

Epoch: 5| Step: 4
Training loss: 3.6063993003258963
Validation loss: 3.00961903790881

Epoch: 5| Step: 5
Training loss: 3.346358663157647
Validation loss: 3.0052357757680865

Epoch: 5| Step: 6
Training loss: 3.5379077635926244
Validation loss: 3.007404892887152

Epoch: 5| Step: 7
Training loss: 3.2105047300928
Validation loss: 3.002701566675123

Epoch: 5| Step: 8
Training loss: 3.722133988114355
Validation loss: 3.0030703488179076

Epoch: 5| Step: 9
Training loss: 2.9052637539229376
Validation loss: 3.0000978158228855

Epoch: 5| Step: 10
Training loss: 2.94488149874082
Validation loss: 3.001433752836352

Epoch: 53| Step: 0
Training loss: 3.488195266603712
Validation loss: 3.000879334884744

Epoch: 5| Step: 1
Training loss: 3.410314392408113
Validation loss: 2.9996811909289174

Epoch: 5| Step: 2
Training loss: 3.133976061487945
Validation loss: 3.00285078885309

Epoch: 5| Step: 3
Training loss: 2.6309617779462626
Validation loss: 3.0002171504482584

Epoch: 5| Step: 4
Training loss: 3.134072980088218
Validation loss: 2.9984194204859067

Epoch: 5| Step: 5
Training loss: 2.8355226659943447
Validation loss: 2.9981398506814894

Epoch: 5| Step: 6
Training loss: 2.9933278273919095
Validation loss: 2.99963609648633

Epoch: 5| Step: 7
Training loss: 3.414310961309051
Validation loss: 3.0056577343526167

Epoch: 5| Step: 8
Training loss: 3.606230716224032
Validation loss: 3.003297553878469

Epoch: 5| Step: 9
Training loss: 3.510655939265676
Validation loss: 2.9977024827724517

Epoch: 5| Step: 10
Training loss: 3.7699743455170798
Validation loss: 2.9973319137450583

Epoch: 54| Step: 0
Training loss: 3.600431517064284
Validation loss: 3.0041367012120004

Epoch: 5| Step: 1
Training loss: 3.3593199259657056
Validation loss: 3.0063463579491523

Epoch: 5| Step: 2
Training loss: 3.1956367607952254
Validation loss: 3.000218227953685

Epoch: 5| Step: 3
Training loss: 2.805895956768308
Validation loss: 2.995210999623742

Epoch: 5| Step: 4
Training loss: 3.3757216070653993
Validation loss: 2.991325132271318

Epoch: 5| Step: 5
Training loss: 3.396127340932981
Validation loss: 2.9948533666103545

Epoch: 5| Step: 6
Training loss: 3.0364852214863776
Validation loss: 2.9933002161189703

Epoch: 5| Step: 7
Training loss: 3.491374149375534
Validation loss: 2.9942074983961584

Epoch: 5| Step: 8
Training loss: 3.572409783859959
Validation loss: 2.992541049146608

Epoch: 5| Step: 9
Training loss: 3.077204687729685
Validation loss: 3.0025359001382648

Epoch: 5| Step: 10
Training loss: 2.9741585703624067
Validation loss: 3.0101296172018266

Epoch: 55| Step: 0
Training loss: 3.7253346849665263
Validation loss: 3.02535552143611

Epoch: 5| Step: 1
Training loss: 2.7367994622719243
Validation loss: 3.010892107001789

Epoch: 5| Step: 2
Training loss: 3.8465469232848606
Validation loss: 2.996531421159449

Epoch: 5| Step: 3
Training loss: 2.7402519502844256
Validation loss: 2.9924790336669482

Epoch: 5| Step: 4
Training loss: 3.5862132778793954
Validation loss: 2.991190302905475

Epoch: 5| Step: 5
Training loss: 2.914372404663056
Validation loss: 2.991038019378664

Epoch: 5| Step: 6
Training loss: 3.328313114777881
Validation loss: 2.9898988653642644

Epoch: 5| Step: 7
Training loss: 2.6412533345451914
Validation loss: 2.9908909875720004

Epoch: 5| Step: 8
Training loss: 3.2854519052173905
Validation loss: 2.989251752566656

Epoch: 5| Step: 9
Training loss: 3.8515132258669866
Validation loss: 2.989414719845373

Epoch: 5| Step: 10
Training loss: 2.832338850482519
Validation loss: 2.9850580049915822

Epoch: 56| Step: 0
Training loss: 3.0338945945480105
Validation loss: 2.984152192574204

Epoch: 5| Step: 1
Training loss: 3.8657773924558123
Validation loss: 2.985205713980068

Epoch: 5| Step: 2
Training loss: 2.5537284894234293
Validation loss: 2.9823794104131767

Epoch: 5| Step: 3
Training loss: 4.138064186376438
Validation loss: 2.981787234569895

Epoch: 5| Step: 4
Training loss: 2.6671620345953153
Validation loss: 2.978648672428921

Epoch: 5| Step: 5
Training loss: 3.4966835930932496
Validation loss: 2.977865317967054

Epoch: 5| Step: 6
Training loss: 3.3746911366737455
Validation loss: 2.9789763382009067

Epoch: 5| Step: 7
Training loss: 3.0930776154393276
Validation loss: 2.977183978098195

Epoch: 5| Step: 8
Training loss: 3.4838541094851774
Validation loss: 2.975159805257908

Epoch: 5| Step: 9
Training loss: 2.830888104414725
Validation loss: 2.975847522658819

Epoch: 5| Step: 10
Training loss: 2.8253045112084267
Validation loss: 2.97684460089802

Epoch: 57| Step: 0
Training loss: 2.859595952069844
Validation loss: 2.97448128714066

Epoch: 5| Step: 1
Training loss: 2.951026776607573
Validation loss: 2.975048657449651

Epoch: 5| Step: 2
Training loss: 3.575689428049402
Validation loss: 2.9765018974484425

Epoch: 5| Step: 3
Training loss: 2.985780554718491
Validation loss: 2.97360066371698

Epoch: 5| Step: 4
Training loss: 3.259249802376613
Validation loss: 2.9718019765764927

Epoch: 5| Step: 5
Training loss: 3.3677237453200464
Validation loss: 2.9773631185243996

Epoch: 5| Step: 6
Training loss: 3.47954015192874
Validation loss: 2.972146730560321

Epoch: 5| Step: 7
Training loss: 3.7350973922920976
Validation loss: 2.9684436029027355

Epoch: 5| Step: 8
Training loss: 2.7382539102928143
Validation loss: 2.968070828479684

Epoch: 5| Step: 9
Training loss: 2.867215107049482
Validation loss: 2.9673771635712543

Epoch: 5| Step: 10
Training loss: 3.7974834190142275
Validation loss: 2.9693072397837055

Epoch: 58| Step: 0
Training loss: 3.019259461561399
Validation loss: 2.9730236852701215

Epoch: 5| Step: 1
Training loss: 3.3256583228948293
Validation loss: 2.9706098247876165

Epoch: 5| Step: 2
Training loss: 3.3397286735474543
Validation loss: 2.971326849321167

Epoch: 5| Step: 3
Training loss: 2.841660287202925
Validation loss: 2.97346101205948

Epoch: 5| Step: 4
Training loss: 3.7678576929793217
Validation loss: 2.96903680906659

Epoch: 5| Step: 5
Training loss: 3.0515670252862632
Validation loss: 2.9621334545439093

Epoch: 5| Step: 6
Training loss: 2.7579568711657636
Validation loss: 2.959466321796404

Epoch: 5| Step: 7
Training loss: 3.132658157922663
Validation loss: 2.960126029201202

Epoch: 5| Step: 8
Training loss: 3.482834137429633
Validation loss: 2.959298447988001

Epoch: 5| Step: 9
Training loss: 3.679449831015496
Validation loss: 2.9571338049008253

Epoch: 5| Step: 10
Training loss: 3.098341645928515
Validation loss: 2.955082514735713

Epoch: 59| Step: 0
Training loss: 3.882928059813623
Validation loss: 2.961022040978195

Epoch: 5| Step: 1
Training loss: 3.7626475359103444
Validation loss: 2.9662766244329353

Epoch: 5| Step: 2
Training loss: 2.631086015461687
Validation loss: 2.9600975123742232

Epoch: 5| Step: 3
Training loss: 3.007783488344257
Validation loss: 2.9581184808916863

Epoch: 5| Step: 4
Training loss: 3.503712728508308
Validation loss: 2.9547441910074563

Epoch: 5| Step: 5
Training loss: 2.904109699962118
Validation loss: 2.9570254812136785

Epoch: 5| Step: 6
Training loss: 3.6829139510995383
Validation loss: 2.956722287650045

Epoch: 5| Step: 7
Training loss: 3.2604659364205286
Validation loss: 2.9571819054906436

Epoch: 5| Step: 8
Training loss: 2.800284071544824
Validation loss: 2.958904272502156

Epoch: 5| Step: 9
Training loss: 3.170552696878972
Validation loss: 2.9536509833520617

Epoch: 5| Step: 10
Training loss: 2.5991403112107743
Validation loss: 2.957840911586808

Epoch: 60| Step: 0
Training loss: 3.4974109065151655
Validation loss: 2.954399859382613

Epoch: 5| Step: 1
Training loss: 2.862733296711481
Validation loss: 2.9533974145929536

Epoch: 5| Step: 2
Training loss: 3.0778737231868023
Validation loss: 2.9532948783822395

Epoch: 5| Step: 3
Training loss: 4.010647668832397
Validation loss: 2.9521044649570336

Epoch: 5| Step: 4
Training loss: 3.854297463886838
Validation loss: 2.9541071165692476

Epoch: 5| Step: 5
Training loss: 3.049415194619258
Validation loss: 2.949014975159065

Epoch: 5| Step: 6
Training loss: 2.6264086985220643
Validation loss: 2.9506606474420956

Epoch: 5| Step: 7
Training loss: 2.9513033945503757
Validation loss: 2.9483682554766766

Epoch: 5| Step: 8
Training loss: 2.970629930064747
Validation loss: 2.9490333777578113

Epoch: 5| Step: 9
Training loss: 3.350211202312125
Validation loss: 2.949676295200404

Epoch: 5| Step: 10
Training loss: 2.930296648911601
Validation loss: 2.95359856525664

Epoch: 61| Step: 0
Training loss: 3.223265952030948
Validation loss: 2.9523415733813283

Epoch: 5| Step: 1
Training loss: 3.3430058016576925
Validation loss: 2.949314334121523

Epoch: 5| Step: 2
Training loss: 3.3086959300651055
Validation loss: 2.9488071549136654

Epoch: 5| Step: 3
Training loss: 2.1754744089068465
Validation loss: 2.967371100422767

Epoch: 5| Step: 4
Training loss: 3.9069358528754843
Validation loss: 2.9750542870209133

Epoch: 5| Step: 5
Training loss: 3.628766832250228
Validation loss: 2.994749429127588

Epoch: 5| Step: 6
Training loss: 3.0587011637528545
Validation loss: 2.959589229864867

Epoch: 5| Step: 7
Training loss: 3.514327695753088
Validation loss: 2.9440921899209016

Epoch: 5| Step: 8
Training loss: 2.639449992396071
Validation loss: 2.9403978696986983

Epoch: 5| Step: 9
Training loss: 3.1295898300372302
Validation loss: 2.9368959013859497

Epoch: 5| Step: 10
Training loss: 3.1983994772868183
Validation loss: 2.9404448412454736

Epoch: 62| Step: 0
Training loss: 3.0410454172232053
Validation loss: 2.9427772478329857

Epoch: 5| Step: 1
Training loss: 3.1761331773792514
Validation loss: 2.9419011344660255

Epoch: 5| Step: 2
Training loss: 3.166773710616679
Validation loss: 2.945478096792055

Epoch: 5| Step: 3
Training loss: 3.2901077603023667
Validation loss: 2.9356614823932183

Epoch: 5| Step: 4
Training loss: 2.934060538345414
Validation loss: 2.935039904817652

Epoch: 5| Step: 5
Training loss: 3.0890536642454722
Validation loss: 2.9353872489172725

Epoch: 5| Step: 6
Training loss: 2.9828604005431463
Validation loss: 2.933456625461183

Epoch: 5| Step: 7
Training loss: 3.6428412375650536
Validation loss: 2.9341424164828274

Epoch: 5| Step: 8
Training loss: 3.534381659355602
Validation loss: 2.936130281140534

Epoch: 5| Step: 9
Training loss: 3.4172732272250745
Validation loss: 2.933093993942061

Epoch: 5| Step: 10
Training loss: 3.124305037470427
Validation loss: 2.9318828134165957

Epoch: 63| Step: 0
Training loss: 3.5779600147040895
Validation loss: 2.9282331249478077

Epoch: 5| Step: 1
Training loss: 2.8803730389280813
Validation loss: 2.9295302097113582

Epoch: 5| Step: 2
Training loss: 2.92506683142843
Validation loss: 2.9315995769489955

Epoch: 5| Step: 3
Training loss: 3.206373103048388
Validation loss: 2.9314955848146704

Epoch: 5| Step: 4
Training loss: 3.8023225613237446
Validation loss: 2.9394936063818444

Epoch: 5| Step: 5
Training loss: 3.617534052353078
Validation loss: 2.944599020693985

Epoch: 5| Step: 6
Training loss: 3.019268305730669
Validation loss: 2.9297500325847663

Epoch: 5| Step: 7
Training loss: 2.856000065458922
Validation loss: 2.92636862320356

Epoch: 5| Step: 8
Training loss: 3.8227618581971994
Validation loss: 2.922468824256893

Epoch: 5| Step: 9
Training loss: 2.769479597764107
Validation loss: 2.9209565803114947

Epoch: 5| Step: 10
Training loss: 2.4625626299489114
Validation loss: 2.922407011353139

Epoch: 64| Step: 0
Training loss: 3.129573374670466
Validation loss: 2.923585373685924

Epoch: 5| Step: 1
Training loss: 3.5729364481712933
Validation loss: 2.921653461464246

Epoch: 5| Step: 2
Training loss: 3.1146471576253876
Validation loss: 2.9201185891578265

Epoch: 5| Step: 3
Training loss: 3.5141137159659808
Validation loss: 2.921414132606358

Epoch: 5| Step: 4
Training loss: 3.333945758508784
Validation loss: 2.923167198886691

Epoch: 5| Step: 5
Training loss: 3.010102428328365
Validation loss: 2.917391296471089

Epoch: 5| Step: 6
Training loss: 3.191165387368855
Validation loss: 2.916704510444735

Epoch: 5| Step: 7
Training loss: 2.488670713885157
Validation loss: 2.915683284056021

Epoch: 5| Step: 8
Training loss: 3.764167598588845
Validation loss: 2.915550929718619

Epoch: 5| Step: 9
Training loss: 3.0561672831382145
Validation loss: 2.915394735676618

Epoch: 5| Step: 10
Training loss: 2.8611624712073778
Validation loss: 2.9150182774273166

Epoch: 65| Step: 0
Training loss: 3.551747340684315
Validation loss: 2.9154956722954455

Epoch: 5| Step: 1
Training loss: 3.3869972334502156
Validation loss: 2.912492430661843

Epoch: 5| Step: 2
Training loss: 2.541959172494977
Validation loss: 2.9113816441918896

Epoch: 5| Step: 3
Training loss: 3.2962875927664554
Validation loss: 2.9083110211061225

Epoch: 5| Step: 4
Training loss: 2.987216256046452
Validation loss: 2.91160682676557

Epoch: 5| Step: 5
Training loss: 3.3827183382174892
Validation loss: 2.9085957594550664

Epoch: 5| Step: 6
Training loss: 2.9998278568470114
Validation loss: 2.910725010187453

Epoch: 5| Step: 7
Training loss: 2.680099589077437
Validation loss: 2.913930650944996

Epoch: 5| Step: 8
Training loss: 2.8970601801443356
Validation loss: 2.908594298972431

Epoch: 5| Step: 9
Training loss: 3.5754211071060773
Validation loss: 2.905132950112321

Epoch: 5| Step: 10
Training loss: 3.7896608489785417
Validation loss: 2.909261844669547

Epoch: 66| Step: 0
Training loss: 2.8469813506008332
Validation loss: 2.9080610468725236

Epoch: 5| Step: 1
Training loss: 2.3709823355980055
Validation loss: 2.906269312915812

Epoch: 5| Step: 2
Training loss: 3.9718726181395296
Validation loss: 2.9069042900530397

Epoch: 5| Step: 3
Training loss: 3.4411414539249052
Validation loss: 2.9121770616439613

Epoch: 5| Step: 4
Training loss: 3.158792812236923
Validation loss: 2.9038839015910556

Epoch: 5| Step: 5
Training loss: 3.7427841698366713
Validation loss: 2.9041302188331577

Epoch: 5| Step: 6
Training loss: 2.2065569612752016
Validation loss: 2.909302420107518

Epoch: 5| Step: 7
Training loss: 3.132882210200882
Validation loss: 2.905609001951149

Epoch: 5| Step: 8
Training loss: 3.3609911912134716
Validation loss: 2.9038110529403136

Epoch: 5| Step: 9
Training loss: 3.308408405467524
Validation loss: 2.9030760529907176

Epoch: 5| Step: 10
Training loss: 3.154315317767291
Validation loss: 2.9089725905909374

Epoch: 67| Step: 0
Training loss: 3.5752994758709495
Validation loss: 2.9012200055911292

Epoch: 5| Step: 1
Training loss: 3.3058514360208346
Validation loss: 2.9045945223758594

Epoch: 5| Step: 2
Training loss: 3.312748305892828
Validation loss: 2.913000512241946

Epoch: 5| Step: 3
Training loss: 2.555229479493201
Validation loss: 2.91967863910184

Epoch: 5| Step: 4
Training loss: 3.1386261457756923
Validation loss: 2.9250416740349445

Epoch: 5| Step: 5
Training loss: 2.3421348601489624
Validation loss: 2.9357289735715484

Epoch: 5| Step: 6
Training loss: 3.5548064830275785
Validation loss: 2.9261796271728957

Epoch: 5| Step: 7
Training loss: 3.3497098768632596
Validation loss: 2.8968314092103182

Epoch: 5| Step: 8
Training loss: 3.265031240410188
Validation loss: 2.895877642737765

Epoch: 5| Step: 9
Training loss: 3.79246748687145
Validation loss: 2.8933491055314966

Epoch: 5| Step: 10
Training loss: 2.481066726334643
Validation loss: 2.8959958613754826

Epoch: 68| Step: 0
Training loss: 3.1018628952647966
Validation loss: 2.8971518891066608

Epoch: 5| Step: 1
Training loss: 3.2897475881480003
Validation loss: 2.8972584589230985

Epoch: 5| Step: 2
Training loss: 3.620428952256879
Validation loss: 2.8962709939091424

Epoch: 5| Step: 3
Training loss: 3.0071034574176663
Validation loss: 2.895775430920362

Epoch: 5| Step: 4
Training loss: 3.3926052516276606
Validation loss: 2.895770841502466

Epoch: 5| Step: 5
Training loss: 2.5154568633761833
Validation loss: 2.896456476923739

Epoch: 5| Step: 6
Training loss: 2.944299336422589
Validation loss: 2.8960029406014507

Epoch: 5| Step: 7
Training loss: 2.9342677412651352
Validation loss: 2.895498253862353

Epoch: 5| Step: 8
Training loss: 4.000718767437663
Validation loss: 2.8936027685189476

Epoch: 5| Step: 9
Training loss: 2.82329986523905
Validation loss: 2.8930833397525446

Epoch: 5| Step: 10
Training loss: 3.194750748106853
Validation loss: 2.890868447475032

Epoch: 69| Step: 0
Training loss: 3.3849822875873774
Validation loss: 2.892039383618278

Epoch: 5| Step: 1
Training loss: 3.4278014260714036
Validation loss: 2.8871338767956374

Epoch: 5| Step: 2
Training loss: 3.347143857327908
Validation loss: 2.8851187551349358

Epoch: 5| Step: 3
Training loss: 3.291185142611144
Validation loss: 2.894268733694191

Epoch: 5| Step: 4
Training loss: 3.3005902658320485
Validation loss: 2.8991612395747537

Epoch: 5| Step: 5
Training loss: 2.5431867233589798
Validation loss: 2.88792645830328

Epoch: 5| Step: 6
Training loss: 3.003788780822467
Validation loss: 2.8848335817479027

Epoch: 5| Step: 7
Training loss: 3.0449116959319116
Validation loss: 2.8808107698267253

Epoch: 5| Step: 8
Training loss: 3.313226871993201
Validation loss: 2.881675351204995

Epoch: 5| Step: 9
Training loss: 3.0674205876076557
Validation loss: 2.880356270568737

Epoch: 5| Step: 10
Training loss: 3.137958666342628
Validation loss: 2.8790283836181727

Epoch: 70| Step: 0
Training loss: 3.3679716608844124
Validation loss: 2.877371163772622

Epoch: 5| Step: 1
Training loss: 3.0766539180845545
Validation loss: 2.881671690352668

Epoch: 5| Step: 2
Training loss: 2.576037862558689
Validation loss: 2.8788946023517497

Epoch: 5| Step: 3
Training loss: 3.2189785774326327
Validation loss: 2.8794535009922404

Epoch: 5| Step: 4
Training loss: 2.7488523169154035
Validation loss: 2.87697997537114

Epoch: 5| Step: 5
Training loss: 3.3248155643106174
Validation loss: 2.880104554549005

Epoch: 5| Step: 6
Training loss: 3.314920225032216
Validation loss: 2.875219870814218

Epoch: 5| Step: 7
Training loss: 3.3968830631444664
Validation loss: 2.8757051296038108

Epoch: 5| Step: 8
Training loss: 3.3937627802655594
Validation loss: 2.872870835227042

Epoch: 5| Step: 9
Training loss: 2.981694960427061
Validation loss: 2.870920164893448

Epoch: 5| Step: 10
Training loss: 3.4077935877244157
Validation loss: 2.8704174770771425

Epoch: 71| Step: 0
Training loss: 3.4859919196257882
Validation loss: 2.867616335977204

Epoch: 5| Step: 1
Training loss: 3.178234621331084
Validation loss: 2.8657173741512425

Epoch: 5| Step: 2
Training loss: 3.037764951351273
Validation loss: 2.8670560847973117

Epoch: 5| Step: 3
Training loss: 3.2697214233073675
Validation loss: 2.867820192249723

Epoch: 5| Step: 4
Training loss: 3.0242445703940044
Validation loss: 2.8644657973771657

Epoch: 5| Step: 5
Training loss: 2.938420090745996
Validation loss: 2.8655603112438497

Epoch: 5| Step: 6
Training loss: 2.8830433988238804
Validation loss: 2.866306336396198

Epoch: 5| Step: 7
Training loss: 3.123914911711001
Validation loss: 2.864789527489936

Epoch: 5| Step: 8
Training loss: 3.126828993573795
Validation loss: 2.8633162866460036

Epoch: 5| Step: 9
Training loss: 3.774754896480488
Validation loss: 2.8693622135048975

Epoch: 5| Step: 10
Training loss: 2.7011075291447924
Validation loss: 2.865436373394844

Epoch: 72| Step: 0
Training loss: 2.514885076851041
Validation loss: 2.8700956608629404

Epoch: 5| Step: 1
Training loss: 3.3951383164198288
Validation loss: 2.8606339589181204

Epoch: 5| Step: 2
Training loss: 3.005805438315629
Validation loss: 2.8638402917459542

Epoch: 5| Step: 3
Training loss: 2.7995429074623335
Validation loss: 2.8691964106181826

Epoch: 5| Step: 4
Training loss: 2.8574630932497915
Validation loss: 2.863864536585747

Epoch: 5| Step: 5
Training loss: 3.369613021682691
Validation loss: 2.8648672073228845

Epoch: 5| Step: 6
Training loss: 3.3879842714667454
Validation loss: 2.864959461804641

Epoch: 5| Step: 7
Training loss: 3.614556362846665
Validation loss: 2.86955251271003

Epoch: 5| Step: 8
Training loss: 3.2013780249362807
Validation loss: 2.856152973190666

Epoch: 5| Step: 9
Training loss: 3.1007411070916593
Validation loss: 2.857035391115189

Epoch: 5| Step: 10
Training loss: 3.302670126842195
Validation loss: 2.8547681751440086

Epoch: 73| Step: 0
Training loss: 2.8451812831194916
Validation loss: 2.8557740755505905

Epoch: 5| Step: 1
Training loss: 2.5631060000024455
Validation loss: 2.8565436644091173

Epoch: 5| Step: 2
Training loss: 3.156264956599386
Validation loss: 2.863031348527883

Epoch: 5| Step: 3
Training loss: 3.1566908122518544
Validation loss: 2.863643631870184

Epoch: 5| Step: 4
Training loss: 3.3590448261619015
Validation loss: 2.8753413211331935

Epoch: 5| Step: 5
Training loss: 3.3515071553104536
Validation loss: 2.8869291509693644

Epoch: 5| Step: 6
Training loss: 3.410604930257301
Validation loss: 2.863794845098368

Epoch: 5| Step: 7
Training loss: 2.8104142826448193
Validation loss: 2.8570411159343205

Epoch: 5| Step: 8
Training loss: 3.5297941734672658
Validation loss: 2.8539205059813164

Epoch: 5| Step: 9
Training loss: 3.30960762856102
Validation loss: 2.8524360418931125

Epoch: 5| Step: 10
Training loss: 2.97341472157961
Validation loss: 2.8553310582341025

Epoch: 74| Step: 0
Training loss: 2.838700726920082
Validation loss: 2.8578336907613147

Epoch: 5| Step: 1
Training loss: 2.9915737389146484
Validation loss: 2.857982111320449

Epoch: 5| Step: 2
Training loss: 3.384121049280608
Validation loss: 2.859439855618156

Epoch: 5| Step: 3
Training loss: 3.641461845125778
Validation loss: 2.8559188715815864

Epoch: 5| Step: 4
Training loss: 2.9060588486679664
Validation loss: 2.850175179280917

Epoch: 5| Step: 5
Training loss: 2.9056661696213877
Validation loss: 2.8512153093848664

Epoch: 5| Step: 6
Training loss: 2.649290054518144
Validation loss: 2.8497828017441527

Epoch: 5| Step: 7
Training loss: 3.7186076673949873
Validation loss: 2.8468238042248872

Epoch: 5| Step: 8
Training loss: 3.2028866562906084
Validation loss: 2.8455545820181065

Epoch: 5| Step: 9
Training loss: 3.1304001498149443
Validation loss: 2.8471819355459944

Epoch: 5| Step: 10
Training loss: 3.0891063017530285
Validation loss: 2.84634331110789

Epoch: 75| Step: 0
Training loss: 3.3262451307167216
Validation loss: 2.8453943960624124

Epoch: 5| Step: 1
Training loss: 3.6410780203238504
Validation loss: 2.8482406122187425

Epoch: 5| Step: 2
Training loss: 3.0573770141819514
Validation loss: 2.8395713604088932

Epoch: 5| Step: 3
Training loss: 2.263226732750267
Validation loss: 2.8394706943583654

Epoch: 5| Step: 4
Training loss: 3.0854944611263058
Validation loss: 2.8363987327166673

Epoch: 5| Step: 5
Training loss: 3.821915054423311
Validation loss: 2.838552745937835

Epoch: 5| Step: 6
Training loss: 2.7849703990246653
Validation loss: 2.8377626573696624

Epoch: 5| Step: 7
Training loss: 3.4200495898126015
Validation loss: 2.838101089544144

Epoch: 5| Step: 8
Training loss: 2.83975190193844
Validation loss: 2.8366920865977368

Epoch: 5| Step: 9
Training loss: 2.5697425279891855
Validation loss: 2.832740908751038

Epoch: 5| Step: 10
Training loss: 3.3929698237014043
Validation loss: 2.8334667842738823

Testing loss: 3.038354428877759
