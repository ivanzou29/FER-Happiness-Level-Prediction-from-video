Epoch: 1| Step: 0
Training loss: 5.130331104442572
Validation loss: 5.791724230035453

Epoch: 5| Step: 1
Training loss: 5.023158420149221
Validation loss: 5.777061158573271

Epoch: 5| Step: 2
Training loss: 6.445524972823623
Validation loss: 5.765780779206998

Epoch: 5| Step: 3
Training loss: 6.150714690077119
Validation loss: 5.755337471144896

Epoch: 5| Step: 4
Training loss: 5.974312152933055
Validation loss: 5.743108949330676

Epoch: 5| Step: 5
Training loss: 5.577204096667852
Validation loss: 5.729017832622956

Epoch: 5| Step: 6
Training loss: 5.482506066774281
Validation loss: 5.712860332724578

Epoch: 5| Step: 7
Training loss: 6.3147920280999195
Validation loss: 5.693826363781097

Epoch: 5| Step: 8
Training loss: 4.489418091650157
Validation loss: 5.672173306702103

Epoch: 5| Step: 9
Training loss: 6.144713770731616
Validation loss: 5.647711723315219

Epoch: 5| Step: 10
Training loss: 6.30405336804722
Validation loss: 5.61969365142964

Epoch: 2| Step: 0
Training loss: 5.104654260298879
Validation loss: 5.588095815595419

Epoch: 5| Step: 1
Training loss: 5.13066662388945
Validation loss: 5.551994820630937

Epoch: 5| Step: 2
Training loss: 5.419404008198424
Validation loss: 5.512726636780689

Epoch: 5| Step: 3
Training loss: 5.825445382441465
Validation loss: 5.4679558102581325

Epoch: 5| Step: 4
Training loss: 5.939741173445147
Validation loss: 5.420887973705465

Epoch: 5| Step: 5
Training loss: 5.5332403535193055
Validation loss: 5.368864135835436

Epoch: 5| Step: 6
Training loss: 5.637970952495378
Validation loss: 5.3157021742092105

Epoch: 5| Step: 7
Training loss: 5.7607195902728945
Validation loss: 5.260279333498153

Epoch: 5| Step: 8
Training loss: 4.276542135572746
Validation loss: 5.2018346724120095

Epoch: 5| Step: 9
Training loss: 5.665312362099397
Validation loss: 5.143714233636127

Epoch: 5| Step: 10
Training loss: 4.880591682460072
Validation loss: 5.084447765118949

Epoch: 3| Step: 0
Training loss: 5.412998816077954
Validation loss: 5.022264833672168

Epoch: 5| Step: 1
Training loss: 4.714701551617578
Validation loss: 4.95885707081135

Epoch: 5| Step: 2
Training loss: 5.103595416222308
Validation loss: 4.8923350713718134

Epoch: 5| Step: 3
Training loss: 4.126976695537281
Validation loss: 4.824572567160203

Epoch: 5| Step: 4
Training loss: 4.042139294443426
Validation loss: 4.761211785626025

Epoch: 5| Step: 5
Training loss: 5.039431536268772
Validation loss: 4.699532330367752

Epoch: 5| Step: 6
Training loss: 4.081160895176682
Validation loss: 4.647884633211323

Epoch: 5| Step: 7
Training loss: 4.790979197846129
Validation loss: 4.596679148746559

Epoch: 5| Step: 8
Training loss: 5.52549832543498
Validation loss: 4.541841982057818

Epoch: 5| Step: 9
Training loss: 4.854150643820234
Validation loss: 4.487178080059463

Epoch: 5| Step: 10
Training loss: 4.8654897799656505
Validation loss: 4.446432140791496

Epoch: 4| Step: 0
Training loss: 4.635538415345782
Validation loss: 4.4084013492245315

Epoch: 5| Step: 1
Training loss: 3.9825340655558725
Validation loss: 4.375038481981116

Epoch: 5| Step: 2
Training loss: 4.568340169369634
Validation loss: 4.348339902742142

Epoch: 5| Step: 3
Training loss: 4.6355943738613075
Validation loss: 4.32191060419276

Epoch: 5| Step: 4
Training loss: 4.757954011262721
Validation loss: 4.301393056609509

Epoch: 5| Step: 5
Training loss: 4.125744607940037
Validation loss: 4.280431762808856

Epoch: 5| Step: 6
Training loss: 4.665340893751198
Validation loss: 4.258901913733002

Epoch: 5| Step: 7
Training loss: 4.078678254347875
Validation loss: 4.234643388284285

Epoch: 5| Step: 8
Training loss: 4.137179110435188
Validation loss: 4.218272187502276

Epoch: 5| Step: 9
Training loss: 4.6667630094846615
Validation loss: 4.211359936042937

Epoch: 5| Step: 10
Training loss: 4.169471076701245
Validation loss: 4.1909284152723885

Epoch: 5| Step: 0
Training loss: 3.412626125813515
Validation loss: 4.1679797131989424

Epoch: 5| Step: 1
Training loss: 3.903850092855174
Validation loss: 4.154229330988492

Epoch: 5| Step: 2
Training loss: 4.288782551841202
Validation loss: 4.135946278584248

Epoch: 5| Step: 3
Training loss: 4.155857842093076
Validation loss: 4.122497403530515

Epoch: 5| Step: 4
Training loss: 4.622207623442394
Validation loss: 4.108793304445865

Epoch: 5| Step: 5
Training loss: 4.158996592332013
Validation loss: 4.092170634238071

Epoch: 5| Step: 6
Training loss: 4.9130970987562055
Validation loss: 4.080333475860803

Epoch: 5| Step: 7
Training loss: 4.221345456314592
Validation loss: 4.0702584141254405

Epoch: 5| Step: 8
Training loss: 4.356987849924492
Validation loss: 4.052770416182533

Epoch: 5| Step: 9
Training loss: 3.81556478416923
Validation loss: 4.045822258753923

Epoch: 5| Step: 10
Training loss: 4.629247210214245
Validation loss: 4.0304315894789235

Epoch: 6| Step: 0
Training loss: 4.672846154157006
Validation loss: 4.010878482986842

Epoch: 5| Step: 1
Training loss: 4.473820510653937
Validation loss: 4.006758412717071

Epoch: 5| Step: 2
Training loss: 3.9364072706361806
Validation loss: 3.989814205210442

Epoch: 5| Step: 3
Training loss: 3.7563191894658545
Validation loss: 3.9963105783760615

Epoch: 5| Step: 4
Training loss: 4.0368766846795765
Validation loss: 3.998036619262087

Epoch: 5| Step: 5
Training loss: 4.70356155346472
Validation loss: 3.976947497838415

Epoch: 5| Step: 6
Training loss: 4.280511945606447
Validation loss: 3.959927934695434

Epoch: 5| Step: 7
Training loss: 3.9429970773700096
Validation loss: 3.9430570556163254

Epoch: 5| Step: 8
Training loss: 3.880729868954537
Validation loss: 3.928747380379216

Epoch: 5| Step: 9
Training loss: 4.169030523512804
Validation loss: 3.920408051602968

Epoch: 5| Step: 10
Training loss: 3.2334718779412652
Validation loss: 3.9083059761812318

Epoch: 7| Step: 0
Training loss: 4.103023595784391
Validation loss: 3.9150089158424306

Epoch: 5| Step: 1
Training loss: 3.3468650497160386
Validation loss: 3.8825513226525743

Epoch: 5| Step: 2
Training loss: 3.418620752545015
Validation loss: 3.872917989417853

Epoch: 5| Step: 3
Training loss: 4.468132563264576
Validation loss: 3.86520957709792

Epoch: 5| Step: 4
Training loss: 3.5620772796935203
Validation loss: 3.8579944713659255

Epoch: 5| Step: 5
Training loss: 4.270456337765752
Validation loss: 3.856279316409777

Epoch: 5| Step: 6
Training loss: 3.8443212317296083
Validation loss: 3.8445150562908084

Epoch: 5| Step: 7
Training loss: 4.743220862428849
Validation loss: 3.826812508428543

Epoch: 5| Step: 8
Training loss: 4.304229545810983
Validation loss: 3.8139319189395744

Epoch: 5| Step: 9
Training loss: 4.275167557851397
Validation loss: 3.807257377724072

Epoch: 5| Step: 10
Training loss: 3.4936989877760647
Validation loss: 3.8018346503170086

Epoch: 8| Step: 0
Training loss: 4.93634888956373
Validation loss: 3.7961098268643982

Epoch: 5| Step: 1
Training loss: 4.053755989458457
Validation loss: 3.7823260220504142

Epoch: 5| Step: 2
Training loss: 4.363907184288633
Validation loss: 3.7742319930283164

Epoch: 5| Step: 3
Training loss: 3.586474409611185
Validation loss: 3.7679965227926737

Epoch: 5| Step: 4
Training loss: 3.8272048778611296
Validation loss: 3.7552428918181078

Epoch: 5| Step: 5
Training loss: 4.691299322912385
Validation loss: 3.744401954984388

Epoch: 5| Step: 6
Training loss: 3.0179590867431205
Validation loss: 3.7368806374156245

Epoch: 5| Step: 7
Training loss: 3.473296751121346
Validation loss: 3.7306219769478277

Epoch: 5| Step: 8
Training loss: 3.526424114873857
Validation loss: 3.7318206026512977

Epoch: 5| Step: 9
Training loss: 4.146535893756726
Validation loss: 3.7195737261999655

Epoch: 5| Step: 10
Training loss: 3.040245943661338
Validation loss: 3.7088404427746036

Epoch: 9| Step: 0
Training loss: 4.714477423696081
Validation loss: 3.703234193471954

Epoch: 5| Step: 1
Training loss: 3.65645527059665
Validation loss: 3.6966474093462263

Epoch: 5| Step: 2
Training loss: 4.060214529523882
Validation loss: 3.6910692172116684

Epoch: 5| Step: 3
Training loss: 3.987455964517944
Validation loss: 3.6866805979171327

Epoch: 5| Step: 4
Training loss: 3.4315396045976745
Validation loss: 3.6832809464190683

Epoch: 5| Step: 5
Training loss: 3.1001180749371864
Validation loss: 3.680960962669092

Epoch: 5| Step: 6
Training loss: 4.926343457705852
Validation loss: 3.6704659052872293

Epoch: 5| Step: 7
Training loss: 3.811527565932622
Validation loss: 3.6652442955085176

Epoch: 5| Step: 8
Training loss: 3.1908130257824463
Validation loss: 3.6557321924155874

Epoch: 5| Step: 9
Training loss: 3.4333522394888107
Validation loss: 3.6541381337740333

Epoch: 5| Step: 10
Training loss: 3.7845125861637112
Validation loss: 3.644084797781534

Epoch: 10| Step: 0
Training loss: 4.134118146118872
Validation loss: 3.63700120682705

Epoch: 5| Step: 1
Training loss: 4.1374338196593
Validation loss: 3.631598079183399

Epoch: 5| Step: 2
Training loss: 3.066098337446563
Validation loss: 3.6288996319708424

Epoch: 5| Step: 3
Training loss: 3.664015259265359
Validation loss: 3.625730536388375

Epoch: 5| Step: 4
Training loss: 3.7639037191013585
Validation loss: 3.619426143614255

Epoch: 5| Step: 5
Training loss: 3.64355036874074
Validation loss: 3.6086067014497316

Epoch: 5| Step: 6
Training loss: 4.459635369145377
Validation loss: 3.6046279241246393

Epoch: 5| Step: 7
Training loss: 4.488087463179437
Validation loss: 3.6018361932619105

Epoch: 5| Step: 8
Training loss: 3.170093355458829
Validation loss: 3.5957700012817817

Epoch: 5| Step: 9
Training loss: 3.246003260998078
Validation loss: 3.5918163817011726

Epoch: 5| Step: 10
Training loss: 3.81967176435229
Validation loss: 3.589180063886726

Epoch: 11| Step: 0
Training loss: 3.6920613671324416
Validation loss: 3.58823784061535

Epoch: 5| Step: 1
Training loss: 4.280091066193815
Validation loss: 3.579291903249784

Epoch: 5| Step: 2
Training loss: 3.567265050966588
Validation loss: 3.575964877880892

Epoch: 5| Step: 3
Training loss: 3.353982403039691
Validation loss: 3.5731146001914578

Epoch: 5| Step: 4
Training loss: 3.9233622979386227
Validation loss: 3.5717906777124577

Epoch: 5| Step: 5
Training loss: 3.6939967194084633
Validation loss: 3.5702243935066234

Epoch: 5| Step: 6
Training loss: 4.548148380002948
Validation loss: 3.563576002390467

Epoch: 5| Step: 7
Training loss: 2.7346524343072196
Validation loss: 3.5582844306744117

Epoch: 5| Step: 8
Training loss: 4.607410904700272
Validation loss: 3.5592563458444877

Epoch: 5| Step: 9
Training loss: 3.693586079273096
Validation loss: 3.5560722689162385

Epoch: 5| Step: 10
Training loss: 2.7377186413549532
Validation loss: 3.5537202969077826

Epoch: 12| Step: 0
Training loss: 4.445584092785265
Validation loss: 3.5508100400921934

Epoch: 5| Step: 1
Training loss: 3.371494309197796
Validation loss: 3.5462094140919733

Epoch: 5| Step: 2
Training loss: 4.206685539924695
Validation loss: 3.540272634640105

Epoch: 5| Step: 3
Training loss: 3.4706248122671535
Validation loss: 3.5397577969812475

Epoch: 5| Step: 4
Training loss: 3.8485071780750033
Validation loss: 3.5411453693438344

Epoch: 5| Step: 5
Training loss: 4.400190583349749
Validation loss: 3.537641578715923

Epoch: 5| Step: 6
Training loss: 4.123182879092723
Validation loss: 3.5297580725030717

Epoch: 5| Step: 7
Training loss: 2.199067186787251
Validation loss: 3.528902455970551

Epoch: 5| Step: 8
Training loss: 4.221561653486711
Validation loss: 3.531104194171169

Epoch: 5| Step: 9
Training loss: 2.7973228394402745
Validation loss: 3.5297136608236994

Epoch: 5| Step: 10
Training loss: 3.4001562924085085
Validation loss: 3.522225836288358

Epoch: 13| Step: 0
Training loss: 2.9387668556239483
Validation loss: 3.524000019579161

Epoch: 5| Step: 1
Training loss: 3.839446597356212
Validation loss: 3.5280519349930337

Epoch: 5| Step: 2
Training loss: 3.694752301907224
Validation loss: 3.524367277607566

Epoch: 5| Step: 3
Training loss: 3.717476121714185
Validation loss: 3.5187019954679535

Epoch: 5| Step: 4
Training loss: 3.5900983751254802
Validation loss: 3.5137056933926907

Epoch: 5| Step: 5
Training loss: 3.8896839888219645
Validation loss: 3.514957316994594

Epoch: 5| Step: 6
Training loss: 3.5708412096136257
Validation loss: 3.515074895299117

Epoch: 5| Step: 7
Training loss: 5.216780056599621
Validation loss: 3.5140864388477286

Epoch: 5| Step: 8
Training loss: 2.837729652286802
Validation loss: 3.5078491323035372

Epoch: 5| Step: 9
Training loss: 3.412280562615051
Validation loss: 3.5033289976578965

Epoch: 5| Step: 10
Training loss: 3.7791313351988234
Validation loss: 3.4992271117860483

Epoch: 14| Step: 0
Training loss: 4.076309209099388
Validation loss: 3.496395414253525

Epoch: 5| Step: 1
Training loss: 3.0122535319827217
Validation loss: 3.4938611266077575

Epoch: 5| Step: 2
Training loss: 4.016273060318975
Validation loss: 3.495240272631911

Epoch: 5| Step: 3
Training loss: 3.876291367483229
Validation loss: 3.495541636504787

Epoch: 5| Step: 4
Training loss: 3.5268942376490413
Validation loss: 3.4887700437915123

Epoch: 5| Step: 5
Training loss: 3.273852337974237
Validation loss: 3.483374552584185

Epoch: 5| Step: 6
Training loss: 4.651020569733904
Validation loss: 3.48183751333674

Epoch: 5| Step: 7
Training loss: 2.263689885302328
Validation loss: 3.4780520139027793

Epoch: 5| Step: 8
Training loss: 4.177156798112279
Validation loss: 3.491065956190053

Epoch: 5| Step: 9
Training loss: 3.9246784540147015
Validation loss: 3.478194730945431

Epoch: 5| Step: 10
Training loss: 3.2741321200008393
Validation loss: 3.480431095871313

Epoch: 15| Step: 0
Training loss: 2.421275599969128
Validation loss: 3.48059255791034

Epoch: 5| Step: 1
Training loss: 3.592730568300574
Validation loss: 3.4835376856389435

Epoch: 5| Step: 2
Training loss: 4.412231065373069
Validation loss: 3.475056718216022

Epoch: 5| Step: 3
Training loss: 3.8245845693742866
Validation loss: 3.4677492024793173

Epoch: 5| Step: 4
Training loss: 4.168901276596018
Validation loss: 3.4660651789893335

Epoch: 5| Step: 5
Training loss: 3.4915466403285174
Validation loss: 3.4694229695582752

Epoch: 5| Step: 6
Training loss: 3.3650495995412975
Validation loss: 3.4748283600869634

Epoch: 5| Step: 7
Training loss: 4.032318683291668
Validation loss: 3.469678072286075

Epoch: 5| Step: 8
Training loss: 3.559723022701633
Validation loss: 3.4608907585086777

Epoch: 5| Step: 9
Training loss: 3.62592593239127
Validation loss: 3.455637058046528

Epoch: 5| Step: 10
Training loss: 3.7019088615274116
Validation loss: 3.4523382404695386

Epoch: 16| Step: 0
Training loss: 3.986727031539936
Validation loss: 3.4510822645362618

Epoch: 5| Step: 1
Training loss: 3.721472889328017
Validation loss: 3.450497243393888

Epoch: 5| Step: 2
Training loss: 3.773236697838804
Validation loss: 3.448594643829687

Epoch: 5| Step: 3
Training loss: 3.4813571057374246
Validation loss: 3.4466423805471145

Epoch: 5| Step: 4
Training loss: 3.713325968608938
Validation loss: 3.44458152895378

Epoch: 5| Step: 5
Training loss: 4.141379694267929
Validation loss: 3.4413518168151

Epoch: 5| Step: 6
Training loss: 3.4900045719499344
Validation loss: 3.437895885354227

Epoch: 5| Step: 7
Training loss: 3.4404047397442055
Validation loss: 3.43672452291804

Epoch: 5| Step: 8
Training loss: 3.4459875574313497
Validation loss: 3.4354669609117754

Epoch: 5| Step: 9
Training loss: 2.9620172549922916
Validation loss: 3.4333727434618186

Epoch: 5| Step: 10
Training loss: 4.0548575481412135
Validation loss: 3.4325469009876612

Epoch: 17| Step: 0
Training loss: 3.8631353553246837
Validation loss: 3.4291165083262825

Epoch: 5| Step: 1
Training loss: 4.327093228638155
Validation loss: 3.426527921167553

Epoch: 5| Step: 2
Training loss: 4.017497891305062
Validation loss: 3.423965514522013

Epoch: 5| Step: 3
Training loss: 3.850517208483446
Validation loss: 3.422691344858898

Epoch: 5| Step: 4
Training loss: 3.083113757038941
Validation loss: 3.42100941818091

Epoch: 5| Step: 5
Training loss: 3.730626862855083
Validation loss: 3.4201463697211563

Epoch: 5| Step: 6
Training loss: 3.3247887451062152
Validation loss: 3.417426380258963

Epoch: 5| Step: 7
Training loss: 3.625477989516116
Validation loss: 3.41584756208257

Epoch: 5| Step: 8
Training loss: 3.8871073926296322
Validation loss: 3.4117493263075125

Epoch: 5| Step: 9
Training loss: 2.822310482315446
Validation loss: 3.409237700888293

Epoch: 5| Step: 10
Training loss: 3.2363284196778683
Validation loss: 3.4071011961944007

Epoch: 18| Step: 0
Training loss: 3.5335992071298095
Validation loss: 3.4063191778935376

Epoch: 5| Step: 1
Training loss: 2.892149652020133
Validation loss: 3.406283485780112

Epoch: 5| Step: 2
Training loss: 3.684723795007654
Validation loss: 3.4011825419028914

Epoch: 5| Step: 3
Training loss: 3.057189697090146
Validation loss: 3.4008608760281738

Epoch: 5| Step: 4
Training loss: 3.2881020346446634
Validation loss: 3.40060697810148

Epoch: 5| Step: 5
Training loss: 3.4168081176754272
Validation loss: 3.4015836623818148

Epoch: 5| Step: 6
Training loss: 4.369687151502033
Validation loss: 3.4018955265357405

Epoch: 5| Step: 7
Training loss: 3.7053356412962977
Validation loss: 3.397659920766402

Epoch: 5| Step: 8
Training loss: 3.7499849954940707
Validation loss: 3.3985045542765464

Epoch: 5| Step: 9
Training loss: 4.244980035202472
Validation loss: 3.4004994071463215

Epoch: 5| Step: 10
Training loss: 3.715166432899811
Validation loss: 3.398944374599292

Epoch: 19| Step: 0
Training loss: 3.517390236080719
Validation loss: 3.395954116091568

Epoch: 5| Step: 1
Training loss: 3.54836910556472
Validation loss: 3.3910815337671854

Epoch: 5| Step: 2
Training loss: 4.274212252668248
Validation loss: 3.3896921325386384

Epoch: 5| Step: 3
Training loss: 4.0007170988071
Validation loss: 3.3866808211058506

Epoch: 5| Step: 4
Training loss: 3.9338251555336163
Validation loss: 3.3855929956195947

Epoch: 5| Step: 5
Training loss: 3.4048229342900034
Validation loss: 3.3851512845937584

Epoch: 5| Step: 6
Training loss: 3.3123368996826867
Validation loss: 3.3851119158747442

Epoch: 5| Step: 7
Training loss: 3.134426699941265
Validation loss: 3.3819006890028733

Epoch: 5| Step: 8
Training loss: 3.5569295331159214
Validation loss: 3.3801343125939534

Epoch: 5| Step: 9
Training loss: 3.065580881405985
Validation loss: 3.3784808215700903

Epoch: 5| Step: 10
Training loss: 3.8621436933102165
Validation loss: 3.3771055209909946

Epoch: 20| Step: 0
Training loss: 3.138139490862592
Validation loss: 3.3767836341909483

Epoch: 5| Step: 1
Training loss: 3.265170563102691
Validation loss: 3.3740199590556155

Epoch: 5| Step: 2
Training loss: 3.608642768072711
Validation loss: 3.375071960435583

Epoch: 5| Step: 3
Training loss: 4.152706844499445
Validation loss: 3.372016546684248

Epoch: 5| Step: 4
Training loss: 3.5433204081010414
Validation loss: 3.370299457928322

Epoch: 5| Step: 5
Training loss: 4.103641586149809
Validation loss: 3.3695324553371857

Epoch: 5| Step: 6
Training loss: 3.370751567991577
Validation loss: 3.366869666080291

Epoch: 5| Step: 7
Training loss: 3.1983997754591633
Validation loss: 3.365545655555338

Epoch: 5| Step: 8
Training loss: 3.72555125209116
Validation loss: 3.3645707362622477

Epoch: 5| Step: 9
Training loss: 3.7592750288687022
Validation loss: 3.3637229032329703

Epoch: 5| Step: 10
Training loss: 3.615118436020806
Validation loss: 3.3667086255571688

Epoch: 21| Step: 0
Training loss: 3.286979831402733
Validation loss: 3.36295539171402

Epoch: 5| Step: 1
Training loss: 4.203809037260485
Validation loss: 3.363768730628916

Epoch: 5| Step: 2
Training loss: 3.8178226025364874
Validation loss: 3.362186520077025

Epoch: 5| Step: 3
Training loss: 3.691779934169482
Validation loss: 3.360395635432712

Epoch: 5| Step: 4
Training loss: 3.494677311049164
Validation loss: 3.357030463915738

Epoch: 5| Step: 5
Training loss: 3.841957232450221
Validation loss: 3.356904586950069

Epoch: 5| Step: 6
Training loss: 3.632150109722293
Validation loss: 3.3571736416036595

Epoch: 5| Step: 7
Training loss: 3.233679802674214
Validation loss: 3.3538378324584257

Epoch: 5| Step: 8
Training loss: 2.938330350352515
Validation loss: 3.3527955498793167

Epoch: 5| Step: 9
Training loss: 4.006603512215997
Validation loss: 3.349986001911282

Epoch: 5| Step: 10
Training loss: 3.0452087541252686
Validation loss: 3.3486872875468348

Epoch: 22| Step: 0
Training loss: 3.4353259060547003
Validation loss: 3.345596125854501

Epoch: 5| Step: 1
Training loss: 3.388427303404059
Validation loss: 3.344594753474522

Epoch: 5| Step: 2
Training loss: 4.803179744688933
Validation loss: 3.340527711244339

Epoch: 5| Step: 3
Training loss: 2.666917451351237
Validation loss: 3.334444376662412

Epoch: 5| Step: 4
Training loss: 3.9763203905069604
Validation loss: 3.3292993244166853

Epoch: 5| Step: 5
Training loss: 3.332443086634666
Validation loss: 3.329312074450919

Epoch: 5| Step: 6
Training loss: 3.937225574436779
Validation loss: 3.3244049481682163

Epoch: 5| Step: 7
Training loss: 3.440133906353085
Validation loss: 3.3201001001279553

Epoch: 5| Step: 8
Training loss: 2.99899497681668
Validation loss: 3.3112166122903557

Epoch: 5| Step: 9
Training loss: 3.1612091385209333
Validation loss: 3.308949691393497

Epoch: 5| Step: 10
Training loss: 3.654711277278093
Validation loss: 3.310691741610898

Epoch: 23| Step: 0
Training loss: 2.9679655946140935
Validation loss: 3.3053940709753227

Epoch: 5| Step: 1
Training loss: 3.1042834437036415
Validation loss: 3.301200948848432

Epoch: 5| Step: 2
Training loss: 3.0054381672171084
Validation loss: 3.301384724066508

Epoch: 5| Step: 3
Training loss: 4.017260504125643
Validation loss: 3.300835893429521

Epoch: 5| Step: 4
Training loss: 3.325920843663148
Validation loss: 3.2985134426496883

Epoch: 5| Step: 5
Training loss: 3.5145644559204396
Validation loss: 3.295962565647039

Epoch: 5| Step: 6
Training loss: 3.5601875429366565
Validation loss: 3.2945126999640397

Epoch: 5| Step: 7
Training loss: 3.809960692195422
Validation loss: 3.293315400293189

Epoch: 5| Step: 8
Training loss: 3.2486538666801064
Validation loss: 3.29027700679157

Epoch: 5| Step: 9
Training loss: 4.592271631799928
Validation loss: 3.289112935887537

Epoch: 5| Step: 10
Training loss: 3.442158680646705
Validation loss: 3.2855509043854183

Epoch: 24| Step: 0
Training loss: 3.9995310031601528
Validation loss: 3.282362223317915

Epoch: 5| Step: 1
Training loss: 3.646465806142464
Validation loss: 3.2831420662413464

Epoch: 5| Step: 2
Training loss: 2.974741140692073
Validation loss: 3.2801987737146545

Epoch: 5| Step: 3
Training loss: 3.071201651925837
Validation loss: 3.2790285840499216

Epoch: 5| Step: 4
Training loss: 3.4754920940372362
Validation loss: 3.278407034955094

Epoch: 5| Step: 5
Training loss: 3.607760510043197
Validation loss: 3.2749684513654387

Epoch: 5| Step: 6
Training loss: 3.0700543710075205
Validation loss: 3.2757714932884205

Epoch: 5| Step: 7
Training loss: 3.9319401800780125
Validation loss: 3.273606781367711

Epoch: 5| Step: 8
Training loss: 3.896979967308093
Validation loss: 3.27240602237877

Epoch: 5| Step: 9
Training loss: 3.670920130165022
Validation loss: 3.270751632841554

Epoch: 5| Step: 10
Training loss: 3.1452190144608023
Validation loss: 3.2688328619011493

Epoch: 25| Step: 0
Training loss: 3.5615806062470243
Validation loss: 3.2693676857096627

Epoch: 5| Step: 1
Training loss: 3.422957297091923
Validation loss: 3.2680921028294208

Epoch: 5| Step: 2
Training loss: 3.396915910714861
Validation loss: 3.266125524031075

Epoch: 5| Step: 3
Training loss: 3.586814623502528
Validation loss: 3.263881368780422

Epoch: 5| Step: 4
Training loss: 3.333401790551721
Validation loss: 3.2626619056713424

Epoch: 5| Step: 5
Training loss: 3.5584531854699386
Validation loss: 3.261160270789641

Epoch: 5| Step: 6
Training loss: 3.4952783070487516
Validation loss: 3.2618123995594175

Epoch: 5| Step: 7
Training loss: 3.889072951244934
Validation loss: 3.2599032365797305

Epoch: 5| Step: 8
Training loss: 3.4767711105336665
Validation loss: 3.2551738457934523

Epoch: 5| Step: 9
Training loss: 3.7608374081119096
Validation loss: 3.2492193226261623

Epoch: 5| Step: 10
Training loss: 2.9846319117984685
Validation loss: 3.240742747405004

Epoch: 26| Step: 0
Training loss: 3.5671619897265257
Validation loss: 3.236547461682383

Epoch: 5| Step: 1
Training loss: 3.7774063625886214
Validation loss: 3.2322985246464415

Epoch: 5| Step: 2
Training loss: 3.8372042364902943
Validation loss: 3.230257748801379

Epoch: 5| Step: 3
Training loss: 3.2942006622600974
Validation loss: 3.2310997619376365

Epoch: 5| Step: 4
Training loss: 3.2043802918520097
Validation loss: 3.2276565249150755

Epoch: 5| Step: 5
Training loss: 3.7819069536000587
Validation loss: 3.224802596523031

Epoch: 5| Step: 6
Training loss: 3.6627417422769075
Validation loss: 3.2178262607051047

Epoch: 5| Step: 7
Training loss: 3.086650833545171
Validation loss: 3.2188115443092307

Epoch: 5| Step: 8
Training loss: 3.2350327564685966
Validation loss: 3.219068155276153

Epoch: 5| Step: 9
Training loss: 3.4083957737905757
Validation loss: 3.2174584529115546

Epoch: 5| Step: 10
Training loss: 3.2796692446509117
Validation loss: 3.2104545245794855

Epoch: 27| Step: 0
Training loss: 2.9460898266556015
Validation loss: 3.2095834581540545

Epoch: 5| Step: 1
Training loss: 3.99877028636312
Validation loss: 3.2140145827969637

Epoch: 5| Step: 2
Training loss: 3.6694694268563937
Validation loss: 3.2079157297144363

Epoch: 5| Step: 3
Training loss: 3.2118512637806584
Validation loss: 3.207670887856882

Epoch: 5| Step: 4
Training loss: 3.4501568910611895
Validation loss: 3.207702565657392

Epoch: 5| Step: 5
Training loss: 2.6656603006974837
Validation loss: 3.20456219236765

Epoch: 5| Step: 6
Training loss: 3.6951799752019254
Validation loss: 3.2036013653417656

Epoch: 5| Step: 7
Training loss: 3.513486220081299
Validation loss: 3.2043364252177833

Epoch: 5| Step: 8
Training loss: 3.6134155908303245
Validation loss: 3.206442592378971

Epoch: 5| Step: 9
Training loss: 3.6569893896310424
Validation loss: 3.202634161621609

Epoch: 5| Step: 10
Training loss: 3.46260530056911
Validation loss: 3.1995710247864695

Epoch: 28| Step: 0
Training loss: 3.126354229275169
Validation loss: 3.196654927259552

Epoch: 5| Step: 1
Training loss: 3.0535621228630005
Validation loss: 3.1978863969253233

Epoch: 5| Step: 2
Training loss: 3.0838684098882747
Validation loss: 3.1990053814732646

Epoch: 5| Step: 3
Training loss: 3.0602982060353665
Validation loss: 3.1969253437438785

Epoch: 5| Step: 4
Training loss: 3.163560615577425
Validation loss: 3.1947970012227316

Epoch: 5| Step: 5
Training loss: 3.5428772297302946
Validation loss: 3.1928490850588354

Epoch: 5| Step: 6
Training loss: 3.537792390527477
Validation loss: 3.1904980729160766

Epoch: 5| Step: 7
Training loss: 3.0645660904728382
Validation loss: 3.1910349309972372

Epoch: 5| Step: 8
Training loss: 3.5866526968824566
Validation loss: 3.192190431436266

Epoch: 5| Step: 9
Training loss: 4.702672385301422
Validation loss: 3.189626636973262

Epoch: 5| Step: 10
Training loss: 3.694577166118116
Validation loss: 3.185287243190114

Epoch: 29| Step: 0
Training loss: 4.257939720003054
Validation loss: 3.1839892673870134

Epoch: 5| Step: 1
Training loss: 3.221882601265585
Validation loss: 3.1843563472765015

Epoch: 5| Step: 2
Training loss: 4.037642740377828
Validation loss: 3.1895785277590525

Epoch: 5| Step: 3
Training loss: 3.0353311024381218
Validation loss: 3.187133774458124

Epoch: 5| Step: 4
Training loss: 3.777337943134756
Validation loss: 3.18211548551852

Epoch: 5| Step: 5
Training loss: 2.9264097875536743
Validation loss: 3.178246982014729

Epoch: 5| Step: 6
Training loss: 2.820366433597447
Validation loss: 3.1770018283523536

Epoch: 5| Step: 7
Training loss: 2.9142163110798194
Validation loss: 3.176949292278215

Epoch: 5| Step: 8
Training loss: 3.5516720232542025
Validation loss: 3.1793822208758455

Epoch: 5| Step: 9
Training loss: 2.6241019393030456
Validation loss: 3.1796326660884917

Epoch: 5| Step: 10
Training loss: 4.282873138365872
Validation loss: 3.18027790320059

Epoch: 30| Step: 0
Training loss: 2.725605356713784
Validation loss: 3.176077289282176

Epoch: 5| Step: 1
Training loss: 4.139043772371751
Validation loss: 3.1763552074264196

Epoch: 5| Step: 2
Training loss: 3.125038757083881
Validation loss: 3.1781250524646403

Epoch: 5| Step: 3
Training loss: 3.5652409767147435
Validation loss: 3.1745881873329793

Epoch: 5| Step: 4
Training loss: 3.3918207406954335
Validation loss: 3.175185053255143

Epoch: 5| Step: 5
Training loss: 3.389246787956411
Validation loss: 3.1723562744639837

Epoch: 5| Step: 6
Training loss: 3.7890769722259057
Validation loss: 3.169224812207727

Epoch: 5| Step: 7
Training loss: 3.040018201070809
Validation loss: 3.166369117094896

Epoch: 5| Step: 8
Training loss: 3.6350012307774953
Validation loss: 3.1648780135385084

Epoch: 5| Step: 9
Training loss: 3.245736480038323
Validation loss: 3.1651777454433896

Epoch: 5| Step: 10
Training loss: 3.467446159489361
Validation loss: 3.165071280785688

Epoch: 31| Step: 0
Training loss: 2.71296119460838
Validation loss: 3.1660592824900085

Epoch: 5| Step: 1
Training loss: 2.948899571408117
Validation loss: 3.16598730026595

Epoch: 5| Step: 2
Training loss: 2.8222002384834766
Validation loss: 3.1673777763563313

Epoch: 5| Step: 3
Training loss: 3.335559260703524
Validation loss: 3.168814530322028

Epoch: 5| Step: 4
Training loss: 4.074334381598566
Validation loss: 3.168257608894408

Epoch: 5| Step: 5
Training loss: 3.427979480641935
Validation loss: 3.1668879642675067

Epoch: 5| Step: 6
Training loss: 3.304410882289262
Validation loss: 3.1658570550510534

Epoch: 5| Step: 7
Training loss: 3.31627209934617
Validation loss: 3.1617909710045398

Epoch: 5| Step: 8
Training loss: 3.814282985316852
Validation loss: 3.160148243065176

Epoch: 5| Step: 9
Training loss: 4.2596523404526145
Validation loss: 3.1596905128221824

Epoch: 5| Step: 10
Training loss: 3.197269651751817
Validation loss: 3.1598567054313547

Epoch: 32| Step: 0
Training loss: 3.355347956480463
Validation loss: 3.1581061026899797

Epoch: 5| Step: 1
Training loss: 3.287815464679421
Validation loss: 3.160888765449961

Epoch: 5| Step: 2
Training loss: 3.0516818740551925
Validation loss: 3.1580979249567562

Epoch: 5| Step: 3
Training loss: 4.011156260012358
Validation loss: 3.158047812540011

Epoch: 5| Step: 4
Training loss: 2.3505424238740904
Validation loss: 3.154483974846803

Epoch: 5| Step: 5
Training loss: 3.6216825893266837
Validation loss: 3.1522757697769115

Epoch: 5| Step: 6
Training loss: 3.82125636885452
Validation loss: 3.154220098873378

Epoch: 5| Step: 7
Training loss: 3.4816892391317382
Validation loss: 3.1535970836299376

Epoch: 5| Step: 8
Training loss: 3.794114730371136
Validation loss: 3.1530525583850775

Epoch: 5| Step: 9
Training loss: 3.457902598079885
Validation loss: 3.155891809939247

Epoch: 5| Step: 10
Training loss: 2.8790746921656702
Validation loss: 3.1524586356032045

Epoch: 33| Step: 0
Training loss: 3.0636723668298567
Validation loss: 3.156663206236977

Epoch: 5| Step: 1
Training loss: 3.2817351936197534
Validation loss: 3.1492924444614125

Epoch: 5| Step: 2
Training loss: 3.081444514017533
Validation loss: 3.1492396341810136

Epoch: 5| Step: 3
Training loss: 3.0010491761777103
Validation loss: 3.1497897378595185

Epoch: 5| Step: 4
Training loss: 3.29327948609886
Validation loss: 3.1556299640853362

Epoch: 5| Step: 5
Training loss: 2.9548223552460833
Validation loss: 3.153508000329634

Epoch: 5| Step: 6
Training loss: 3.3086934800863643
Validation loss: 3.1520162701178243

Epoch: 5| Step: 7
Training loss: 3.378690326825612
Validation loss: 3.1485021742255546

Epoch: 5| Step: 8
Training loss: 3.837663250659686
Validation loss: 3.1437309757595573

Epoch: 5| Step: 9
Training loss: 3.9315799835425183
Validation loss: 3.144197687591925

Epoch: 5| Step: 10
Training loss: 4.199263262845471
Validation loss: 3.1423393985881454

Epoch: 34| Step: 0
Training loss: 2.5351903880778837
Validation loss: 3.141848288411588

Epoch: 5| Step: 1
Training loss: 3.2779696097696274
Validation loss: 3.143238157364881

Epoch: 5| Step: 2
Training loss: 3.7544963583233217
Validation loss: 3.150767059415043

Epoch: 5| Step: 3
Training loss: 3.1049368156847463
Validation loss: 3.1597371744959553

Epoch: 5| Step: 4
Training loss: 3.6920492268232468
Validation loss: 3.1474602533109315

Epoch: 5| Step: 5
Training loss: 3.864720029375549
Validation loss: 3.1382820084362377

Epoch: 5| Step: 6
Training loss: 3.2903997824199744
Validation loss: 3.13609178708628

Epoch: 5| Step: 7
Training loss: 3.298390840013337
Validation loss: 3.1370206346980143

Epoch: 5| Step: 8
Training loss: 3.312732328508701
Validation loss: 3.1607867174199304

Epoch: 5| Step: 9
Training loss: 3.40827909455983
Validation loss: 3.162175525623288

Epoch: 5| Step: 10
Training loss: 3.7165982729060145
Validation loss: 3.1345426577076165

Epoch: 35| Step: 0
Training loss: 3.3125377149054316
Validation loss: 3.132188333586986

Epoch: 5| Step: 1
Training loss: 3.8698272634985154
Validation loss: 3.1366018428457125

Epoch: 5| Step: 2
Training loss: 3.676629806661189
Validation loss: 3.1929485764161463

Epoch: 5| Step: 3
Training loss: 2.3024174259385246
Validation loss: 3.153734682963268

Epoch: 5| Step: 4
Training loss: 3.1094775925776785
Validation loss: 3.16031429519661

Epoch: 5| Step: 5
Training loss: 3.2419948290831306
Validation loss: 3.1576022030762374

Epoch: 5| Step: 6
Training loss: 3.4338998148216877
Validation loss: 3.1387449279852118

Epoch: 5| Step: 7
Training loss: 3.214434350830762
Validation loss: 3.1331656355698985

Epoch: 5| Step: 8
Training loss: 3.624116329481809
Validation loss: 3.135306583742784

Epoch: 5| Step: 9
Training loss: 4.020461439152951
Validation loss: 3.132935035176378

Epoch: 5| Step: 10
Training loss: 3.2580535579936942
Validation loss: 3.133925389933277

Epoch: 36| Step: 0
Training loss: 2.8104964007205444
Validation loss: 3.134386181023411

Epoch: 5| Step: 1
Training loss: 3.8574873906619853
Validation loss: 3.1714906126698357

Epoch: 5| Step: 2
Training loss: 3.3519652509231053
Validation loss: 3.1272457314582667

Epoch: 5| Step: 3
Training loss: 3.5198340418013645
Validation loss: 3.1222022217372323

Epoch: 5| Step: 4
Training loss: 2.8611338057950184
Validation loss: 3.1312518277595944

Epoch: 5| Step: 5
Training loss: 3.6124203207871095
Validation loss: 3.180704022512918

Epoch: 5| Step: 6
Training loss: 3.2224840152838254
Validation loss: 3.158513275725371

Epoch: 5| Step: 7
Training loss: 3.6114588415194846
Validation loss: 3.1376498746224746

Epoch: 5| Step: 8
Training loss: 2.9347875530551413
Validation loss: 3.116345100359302

Epoch: 5| Step: 9
Training loss: 3.1235596961601475
Validation loss: 3.117607090721258

Epoch: 5| Step: 10
Training loss: 4.285721274778934
Validation loss: 3.123948183144996

Epoch: 37| Step: 0
Training loss: 3.115031555652752
Validation loss: 3.160205522624106

Epoch: 5| Step: 1
Training loss: 4.2941586318046685
Validation loss: 3.1853783350770897

Epoch: 5| Step: 2
Training loss: 3.2462372639097397
Validation loss: 3.1172701637339557

Epoch: 5| Step: 3
Training loss: 2.4340681712713472
Validation loss: 3.116251351333372

Epoch: 5| Step: 4
Training loss: 3.760082043300528
Validation loss: 3.1729567840177166

Epoch: 5| Step: 5
Training loss: 3.3599300901769467
Validation loss: 3.3806834720347534

Epoch: 5| Step: 6
Training loss: 3.057640424047366
Validation loss: 3.36116231584802

Epoch: 5| Step: 7
Training loss: 3.4875015805695484
Validation loss: 3.2467088150321044

Epoch: 5| Step: 8
Training loss: 3.5534420304793284
Validation loss: 3.1223293500814577

Epoch: 5| Step: 9
Training loss: 4.14724421176303
Validation loss: 3.147320711470931

Epoch: 5| Step: 10
Training loss: 2.9627420769143655
Validation loss: 3.165305122341451

Epoch: 38| Step: 0
Training loss: 3.30189211960643
Validation loss: 3.1429694986589363

Epoch: 5| Step: 1
Training loss: 3.0040818102347027
Validation loss: 3.1472296063288505

Epoch: 5| Step: 2
Training loss: 3.052573484743773
Validation loss: 3.1514859523534007

Epoch: 5| Step: 3
Training loss: 3.683905838076744
Validation loss: 3.1526594602521443

Epoch: 5| Step: 4
Training loss: 2.88373267728698
Validation loss: 3.1259281412659687

Epoch: 5| Step: 5
Training loss: 4.012519793595309
Validation loss: 3.122550263397302

Epoch: 5| Step: 6
Training loss: 2.7459627340001056
Validation loss: 3.110837637223602

Epoch: 5| Step: 7
Training loss: 3.502447362554621
Validation loss: 3.110591233165944

Epoch: 5| Step: 8
Training loss: 3.666723915577949
Validation loss: 3.1117726118123126

Epoch: 5| Step: 9
Training loss: 3.6115329121137414
Validation loss: 3.108475281477655

Epoch: 5| Step: 10
Training loss: 3.5246500098528317
Validation loss: 3.111618099443846

Epoch: 39| Step: 0
Training loss: 3.2780877270320516
Validation loss: 3.11428905587626

Epoch: 5| Step: 1
Training loss: 3.4506177819025723
Validation loss: 3.110164077817807

Epoch: 5| Step: 2
Training loss: 3.265773496035018
Validation loss: 3.095705095945702

Epoch: 5| Step: 3
Training loss: 3.2358168184846443
Validation loss: 3.090457510406141

Epoch: 5| Step: 4
Training loss: 3.847817850350073
Validation loss: 3.087335012417702

Epoch: 5| Step: 5
Training loss: 3.5708243839918863
Validation loss: 3.0882838255590315

Epoch: 5| Step: 6
Training loss: 2.8636411099855574
Validation loss: 3.0867087029188447

Epoch: 5| Step: 7
Training loss: 3.159912854453695
Validation loss: 3.087818665334156

Epoch: 5| Step: 8
Training loss: 3.4863292191875033
Validation loss: 3.087474531912529

Epoch: 5| Step: 9
Training loss: 3.4988431381034664
Validation loss: 3.0860417473161936

Epoch: 5| Step: 10
Training loss: 3.0676158293079503
Validation loss: 3.0838480311671908

Epoch: 40| Step: 0
Training loss: 3.165296827140584
Validation loss: 3.0830048937974093

Epoch: 5| Step: 1
Training loss: 2.8802536770572242
Validation loss: 3.0821296057235705

Epoch: 5| Step: 2
Training loss: 3.6572097431605903
Validation loss: 3.0834779619543107

Epoch: 5| Step: 3
Training loss: 3.069018530507854
Validation loss: 3.0815028089501086

Epoch: 5| Step: 4
Training loss: 3.6828515446842416
Validation loss: 3.0808860048128857

Epoch: 5| Step: 5
Training loss: 3.426236791129469
Validation loss: 3.078983416849163

Epoch: 5| Step: 6
Training loss: 3.068570407188349
Validation loss: 3.078898508675552

Epoch: 5| Step: 7
Training loss: 3.35781057436725
Validation loss: 3.0800008338902587

Epoch: 5| Step: 8
Training loss: 3.4228962806904124
Validation loss: 3.076701856600851

Epoch: 5| Step: 9
Training loss: 3.486447115879042
Validation loss: 3.0752760647422943

Epoch: 5| Step: 10
Training loss: 3.4439132513270447
Validation loss: 3.0758569153864186

Epoch: 41| Step: 0
Training loss: 3.0272223072919693
Validation loss: 3.076025201283027

Epoch: 5| Step: 1
Training loss: 3.430269856639223
Validation loss: 3.073160926339415

Epoch: 5| Step: 2
Training loss: 3.122219221747945
Validation loss: 3.0719468449742795

Epoch: 5| Step: 3
Training loss: 3.3402937379606863
Validation loss: 3.074263048974053

Epoch: 5| Step: 4
Training loss: 3.6666657852402986
Validation loss: 3.069823468403652

Epoch: 5| Step: 5
Training loss: 2.3628838323191856
Validation loss: 3.074550623205266

Epoch: 5| Step: 6
Training loss: 4.261844510776197
Validation loss: 3.0721566927819555

Epoch: 5| Step: 7
Training loss: 2.949229097663966
Validation loss: 3.0726621716738154

Epoch: 5| Step: 8
Training loss: 3.6199351476687585
Validation loss: 3.072684313271641

Epoch: 5| Step: 9
Training loss: 3.182112535262189
Validation loss: 3.068901978159936

Epoch: 5| Step: 10
Training loss: 3.3503913878504146
Validation loss: 3.0708611545116993

Epoch: 42| Step: 0
Training loss: 4.095587165293351
Validation loss: 3.0709916787530065

Epoch: 5| Step: 1
Training loss: 3.8685609786735085
Validation loss: 3.070862747362961

Epoch: 5| Step: 2
Training loss: 3.201976439942718
Validation loss: 3.0690906077076994

Epoch: 5| Step: 3
Training loss: 3.0604829958035284
Validation loss: 3.0683059287206103

Epoch: 5| Step: 4
Training loss: 2.753511267940144
Validation loss: 3.066875331644781

Epoch: 5| Step: 5
Training loss: 3.7206267421621573
Validation loss: 3.0677538672922386

Epoch: 5| Step: 6
Training loss: 3.0643124569371567
Validation loss: 3.06705647697846

Epoch: 5| Step: 7
Training loss: 3.037273596343907
Validation loss: 3.0630650320321804

Epoch: 5| Step: 8
Training loss: 3.3190918597284154
Validation loss: 3.064131555999953

Epoch: 5| Step: 9
Training loss: 3.322232613464004
Validation loss: 3.0624146473659652

Epoch: 5| Step: 10
Training loss: 2.750013178013525
Validation loss: 3.062468502844543

Epoch: 43| Step: 0
Training loss: 3.3067372415558487
Validation loss: 3.0603471463037812

Epoch: 5| Step: 1
Training loss: 3.5355993172365356
Validation loss: 3.0594963158863755

Epoch: 5| Step: 2
Training loss: 3.6306315120218997
Validation loss: 3.0580936950814386

Epoch: 5| Step: 3
Training loss: 3.1535530276179036
Validation loss: 3.0567199812052936

Epoch: 5| Step: 4
Training loss: 3.0728579930452957
Validation loss: 3.05632270481407

Epoch: 5| Step: 5
Training loss: 3.017851486910166
Validation loss: 3.056938790962688

Epoch: 5| Step: 6
Training loss: 2.445082681112106
Validation loss: 3.05644898508251

Epoch: 5| Step: 7
Training loss: 3.5844880542702406
Validation loss: 3.0551748175274698

Epoch: 5| Step: 8
Training loss: 3.37280527032625
Validation loss: 3.0541035121445232

Epoch: 5| Step: 9
Training loss: 3.4783660668034844
Validation loss: 3.0517067494047865

Epoch: 5| Step: 10
Training loss: 3.7243553679118944
Validation loss: 3.0504270367941864

Epoch: 44| Step: 0
Training loss: 2.9739623239538315
Validation loss: 3.0503293783985477

Epoch: 5| Step: 1
Training loss: 2.8982540596958466
Validation loss: 3.048761395223298

Epoch: 5| Step: 2
Training loss: 3.382405104564182
Validation loss: 3.0455114990128056

Epoch: 5| Step: 3
Training loss: 3.4131775850535253
Validation loss: 3.046772602423122

Epoch: 5| Step: 4
Training loss: 3.925880969854452
Validation loss: 3.0452085453438844

Epoch: 5| Step: 5
Training loss: 3.3806019667949596
Validation loss: 3.0483270374614038

Epoch: 5| Step: 6
Training loss: 3.1576273717130254
Validation loss: 3.0535478083760084

Epoch: 5| Step: 7
Training loss: 3.3853507793568443
Validation loss: 3.044245356016093

Epoch: 5| Step: 8
Training loss: 3.2420265985112
Validation loss: 3.0415628786089193

Epoch: 5| Step: 9
Training loss: 3.1902014560526104
Validation loss: 3.041051572897457

Epoch: 5| Step: 10
Training loss: 3.3256917305660445
Validation loss: 3.0383901447293105

Epoch: 45| Step: 0
Training loss: 3.0060313313793614
Validation loss: 3.0361568551947493

Epoch: 5| Step: 1
Training loss: 3.5475983407259597
Validation loss: 3.0368791694287403

Epoch: 5| Step: 2
Training loss: 2.9256961743930963
Validation loss: 3.038351577531571

Epoch: 5| Step: 3
Training loss: 3.556574662176617
Validation loss: 3.033959260011371

Epoch: 5| Step: 4
Training loss: 3.200824041362194
Validation loss: 3.034882324838333

Epoch: 5| Step: 5
Training loss: 3.446373324230244
Validation loss: 3.0334938522277084

Epoch: 5| Step: 6
Training loss: 3.5975529990358144
Validation loss: 3.03285982555374

Epoch: 5| Step: 7
Training loss: 3.174168401230104
Validation loss: 3.030952292681437

Epoch: 5| Step: 8
Training loss: 3.283439850087939
Validation loss: 3.03224866624954

Epoch: 5| Step: 9
Training loss: 3.628537917974701
Validation loss: 3.0304228763476067

Epoch: 5| Step: 10
Training loss: 2.7084924406608453
Validation loss: 3.029268458396226

Epoch: 46| Step: 0
Training loss: 3.0867161794471705
Validation loss: 3.02953206975257

Epoch: 5| Step: 1
Training loss: 3.251739329965418
Validation loss: 3.028757988907688

Epoch: 5| Step: 2
Training loss: 3.8690550947291773
Validation loss: 3.0272841970545086

Epoch: 5| Step: 3
Training loss: 2.9548835160845055
Validation loss: 3.027669063664923

Epoch: 5| Step: 4
Training loss: 3.6529244190817085
Validation loss: 3.0278370889594064

Epoch: 5| Step: 5
Training loss: 3.1012064155243606
Validation loss: 3.024162756431537

Epoch: 5| Step: 6
Training loss: 2.4749028273493443
Validation loss: 3.027846712427348

Epoch: 5| Step: 7
Training loss: 3.1919451367149687
Validation loss: 3.0230321845390433

Epoch: 5| Step: 8
Training loss: 3.5204277632629446
Validation loss: 3.0253624742213594

Epoch: 5| Step: 9
Training loss: 3.8698397086213228
Validation loss: 3.0229965956436473

Epoch: 5| Step: 10
Training loss: 2.850957602526528
Validation loss: 3.025540025401731

Epoch: 47| Step: 0
Training loss: 3.2994562683675803
Validation loss: 3.032922509788596

Epoch: 5| Step: 1
Training loss: 3.669557270090178
Validation loss: 3.0336692483651766

Epoch: 5| Step: 2
Training loss: 3.637671324375605
Validation loss: 3.0242818823598507

Epoch: 5| Step: 3
Training loss: 3.9722022713350604
Validation loss: 3.0200590477282985

Epoch: 5| Step: 4
Training loss: 3.1766392298417876
Validation loss: 3.015823229374603

Epoch: 5| Step: 5
Training loss: 3.5440193141212912
Validation loss: 3.0171237328260125

Epoch: 5| Step: 6
Training loss: 2.968731689396657
Validation loss: 3.0143227511053103

Epoch: 5| Step: 7
Training loss: 2.3921305584250674
Validation loss: 3.0144274356638165

Epoch: 5| Step: 8
Training loss: 2.657522098883599
Validation loss: 3.0123681034908283

Epoch: 5| Step: 9
Training loss: 3.6763378536722193
Validation loss: 3.011877343766411

Epoch: 5| Step: 10
Training loss: 2.623817631693557
Validation loss: 3.0115779852697595

Epoch: 48| Step: 0
Training loss: 3.604798689682913
Validation loss: 3.0114290465632516

Epoch: 5| Step: 1
Training loss: 3.3041834525747875
Validation loss: 3.00989618552102

Epoch: 5| Step: 2
Training loss: 3.102746694195297
Validation loss: 3.0091757203875154

Epoch: 5| Step: 3
Training loss: 3.434688319873478
Validation loss: 3.00675386470964

Epoch: 5| Step: 4
Training loss: 3.376332761618039
Validation loss: 3.0071809435641357

Epoch: 5| Step: 5
Training loss: 3.1783896006934684
Validation loss: 3.0074571164891726

Epoch: 5| Step: 6
Training loss: 3.1420127118179497
Validation loss: 3.0065851540095103

Epoch: 5| Step: 7
Training loss: 2.813931927148381
Validation loss: 3.0055712511340995

Epoch: 5| Step: 8
Training loss: 3.602836201616542
Validation loss: 3.0040742628815695

Epoch: 5| Step: 9
Training loss: 3.629175740758776
Validation loss: 3.0035636861531736

Epoch: 5| Step: 10
Training loss: 2.5722774890576816
Validation loss: 3.0041793677105746

Epoch: 49| Step: 0
Training loss: 2.8872694179401512
Validation loss: 3.0025184257020983

Epoch: 5| Step: 1
Training loss: 3.4879275972481167
Validation loss: 3.0008620643775226

Epoch: 5| Step: 2
Training loss: 3.482431322941825
Validation loss: 3.001236450568179

Epoch: 5| Step: 3
Training loss: 2.762706445082952
Validation loss: 2.9989236264555177

Epoch: 5| Step: 4
Training loss: 3.0399564002072683
Validation loss: 2.9982381983227504

Epoch: 5| Step: 5
Training loss: 2.8536735349980287
Validation loss: 2.999039415848987

Epoch: 5| Step: 6
Training loss: 3.263944348524667
Validation loss: 2.998716638741089

Epoch: 5| Step: 7
Training loss: 3.5105608600165135
Validation loss: 3.002424087092764

Epoch: 5| Step: 8
Training loss: 2.7234101968732785
Validation loss: 2.9991336788530636

Epoch: 5| Step: 9
Training loss: 3.613172110893957
Validation loss: 2.998548788197957

Epoch: 5| Step: 10
Training loss: 4.173018052457681
Validation loss: 2.9988883532791464

Epoch: 50| Step: 0
Training loss: 3.5394917410948032
Validation loss: 2.9970024474176475

Epoch: 5| Step: 1
Training loss: 3.945168792826746
Validation loss: 2.994463845706983

Epoch: 5| Step: 2
Training loss: 3.0116177355181875
Validation loss: 2.993739444880958

Epoch: 5| Step: 3
Training loss: 3.1557928075237376
Validation loss: 2.9942920461020517

Epoch: 5| Step: 4
Training loss: 3.1738013820988695
Validation loss: 2.9992040754185214

Epoch: 5| Step: 5
Training loss: 2.996095659834789
Validation loss: 2.991143712559772

Epoch: 5| Step: 6
Training loss: 2.9665935514491215
Validation loss: 2.9891888609508532

Epoch: 5| Step: 7
Training loss: 3.484525531887096
Validation loss: 2.987468255275502

Epoch: 5| Step: 8
Training loss: 3.5135757916615376
Validation loss: 2.987042859927495

Epoch: 5| Step: 9
Training loss: 2.734705877720743
Validation loss: 2.9840571960108817

Epoch: 5| Step: 10
Training loss: 3.2332356238267153
Validation loss: 2.9829773927099605

Epoch: 51| Step: 0
Training loss: 3.447998383966408
Validation loss: 2.982613843043362

Epoch: 5| Step: 1
Training loss: 2.7618849298316364
Validation loss: 2.9830497002825367

Epoch: 5| Step: 2
Training loss: 3.4249880491173514
Validation loss: 2.983140874628675

Epoch: 5| Step: 3
Training loss: 3.328103508678409
Validation loss: 2.983490881509635

Epoch: 5| Step: 4
Training loss: 3.6901518774436743
Validation loss: 2.9825621952671635

Epoch: 5| Step: 5
Training loss: 3.1318106630957083
Validation loss: 2.9795522551439886

Epoch: 5| Step: 6
Training loss: 3.0028472740215464
Validation loss: 2.983897706975971

Epoch: 5| Step: 7
Training loss: 3.368360133780936
Validation loss: 2.9861968422523066

Epoch: 5| Step: 8
Training loss: 3.3186269273944515
Validation loss: 2.9840788773525677

Epoch: 5| Step: 9
Training loss: 2.948146599922363
Validation loss: 2.9784881096693114

Epoch: 5| Step: 10
Training loss: 3.2907043853197298
Validation loss: 2.9775823968291846

Epoch: 52| Step: 0
Training loss: 3.402581855859993
Validation loss: 2.976944626897739

Epoch: 5| Step: 1
Training loss: 2.91352802519366
Validation loss: 2.9763645378345247

Epoch: 5| Step: 2
Training loss: 3.378168243780729
Validation loss: 2.974695151084936

Epoch: 5| Step: 3
Training loss: 3.150202632623323
Validation loss: 2.97325792004905

Epoch: 5| Step: 4
Training loss: 3.3450755406447295
Validation loss: 2.9758822798297633

Epoch: 5| Step: 5
Training loss: 3.33379600810689
Validation loss: 2.9835555498833255

Epoch: 5| Step: 6
Training loss: 3.473875228749506
Validation loss: 2.984338482796174

Epoch: 5| Step: 7
Training loss: 3.178834393003909
Validation loss: 2.9917369241857155

Epoch: 5| Step: 8
Training loss: 2.9936859123999717
Validation loss: 2.9973135442483754

Epoch: 5| Step: 9
Training loss: 3.0708505872416842
Validation loss: 2.9873069925665434

Epoch: 5| Step: 10
Training loss: 3.5341021067317318
Validation loss: 2.977216863165385

Epoch: 53| Step: 0
Training loss: 3.8210190195759854
Validation loss: 2.969753656596459

Epoch: 5| Step: 1
Training loss: 3.3225437700475573
Validation loss: 2.966239770337066

Epoch: 5| Step: 2
Training loss: 2.9846846334998602
Validation loss: 2.967005109706295

Epoch: 5| Step: 3
Training loss: 3.7948778967633165
Validation loss: 2.9640153877197424

Epoch: 5| Step: 4
Training loss: 2.9750033723186964
Validation loss: 2.964769561270416

Epoch: 5| Step: 5
Training loss: 2.985239912197012
Validation loss: 2.9631434973184883

Epoch: 5| Step: 6
Training loss: 2.68996990172838
Validation loss: 2.9631200440346905

Epoch: 5| Step: 7
Training loss: 3.1569475970457863
Validation loss: 2.9625203095371604

Epoch: 5| Step: 8
Training loss: 3.303338535303459
Validation loss: 2.962752880080537

Epoch: 5| Step: 9
Training loss: 3.233111148423308
Validation loss: 2.9603788302441254

Epoch: 5| Step: 10
Training loss: 3.1950608879579727
Validation loss: 2.960101989933495

Epoch: 54| Step: 0
Training loss: 3.615488794608274
Validation loss: 2.9599137516559897

Epoch: 5| Step: 1
Training loss: 3.6375865126346967
Validation loss: 2.960025377701057

Epoch: 5| Step: 2
Training loss: 3.061949077020804
Validation loss: 2.9585629908012865

Epoch: 5| Step: 3
Training loss: 3.4417505514222455
Validation loss: 2.9584331596709736

Epoch: 5| Step: 4
Training loss: 2.5184145796381663
Validation loss: 2.957465630082829

Epoch: 5| Step: 5
Training loss: 3.09618751755443
Validation loss: 2.9563899432912573

Epoch: 5| Step: 6
Training loss: 3.7253087011855026
Validation loss: 2.957690239391146

Epoch: 5| Step: 7
Training loss: 2.7295777008910034
Validation loss: 2.956601057012652

Epoch: 5| Step: 8
Training loss: 3.471710316540344
Validation loss: 2.9563855372866286

Epoch: 5| Step: 9
Training loss: 3.287522052647414
Validation loss: 2.955702364967516

Epoch: 5| Step: 10
Training loss: 2.681311112709991
Validation loss: 2.953900835768271

Epoch: 55| Step: 0
Training loss: 3.6516226153471214
Validation loss: 2.951398765230554

Epoch: 5| Step: 1
Training loss: 3.124283975586634
Validation loss: 2.951151287947159

Epoch: 5| Step: 2
Training loss: 3.4981195302773616
Validation loss: 2.9629985179599436

Epoch: 5| Step: 3
Training loss: 2.645057434294952
Validation loss: 2.9836363601800686

Epoch: 5| Step: 4
Training loss: 3.1625459026880365
Validation loss: 3.026345074677764

Epoch: 5| Step: 5
Training loss: 2.9335115017389928
Validation loss: 3.115295528470365

Epoch: 5| Step: 6
Training loss: 3.5169764654973603
Validation loss: 3.0559551192801373

Epoch: 5| Step: 7
Training loss: 3.269701589798085
Validation loss: 2.9700982374794624

Epoch: 5| Step: 8
Training loss: 3.2985313557581097
Validation loss: 2.945286015800336

Epoch: 5| Step: 9
Training loss: 2.9972001361789364
Validation loss: 2.948966477949886

Epoch: 5| Step: 10
Training loss: 3.5110362305147613
Validation loss: 2.9562153257256334

Epoch: 56| Step: 0
Training loss: 3.3615901297419377
Validation loss: 2.993380668281037

Epoch: 5| Step: 1
Training loss: 3.1242963380138975
Validation loss: 3.025944901161173

Epoch: 5| Step: 2
Training loss: 3.481770315957251
Validation loss: 2.96462199456054

Epoch: 5| Step: 3
Training loss: 3.6794432216803976
Validation loss: 2.9491688313993305

Epoch: 5| Step: 4
Training loss: 2.8225911833746586
Validation loss: 2.942508898020841

Epoch: 5| Step: 5
Training loss: 2.997699332207271
Validation loss: 2.9421865901135598

Epoch: 5| Step: 6
Training loss: 2.7832253117262606
Validation loss: 2.940993069040389

Epoch: 5| Step: 7
Training loss: 3.336587668317975
Validation loss: 2.941331248725844

Epoch: 5| Step: 8
Training loss: 3.6238731737576
Validation loss: 2.946624553270717

Epoch: 5| Step: 9
Training loss: 3.541569577550586
Validation loss: 2.9520789839250914

Epoch: 5| Step: 10
Training loss: 2.685237286842936
Validation loss: 2.9597417126959744

Epoch: 57| Step: 0
Training loss: 3.1027124228595993
Validation loss: 2.976370169223558

Epoch: 5| Step: 1
Training loss: 3.693412953860115
Validation loss: 2.962510409825156

Epoch: 5| Step: 2
Training loss: 3.619156171968091
Validation loss: 2.953253333550039

Epoch: 5| Step: 3
Training loss: 2.834505923106353
Validation loss: 2.9393592445274486

Epoch: 5| Step: 4
Training loss: 3.4844374030987098
Validation loss: 2.9343254601593

Epoch: 5| Step: 5
Training loss: 2.613441086059285
Validation loss: 2.933818042981345

Epoch: 5| Step: 6
Training loss: 2.7356068479420736
Validation loss: 2.9329688663697198

Epoch: 5| Step: 7
Training loss: 3.048962156977383
Validation loss: 2.933772893895194

Epoch: 5| Step: 8
Training loss: 3.370308617743041
Validation loss: 2.932744930655768

Epoch: 5| Step: 9
Training loss: 2.557461413766404
Validation loss: 2.9316858488979682

Epoch: 5| Step: 10
Training loss: 4.159739470760111
Validation loss: 2.929992343151035

Epoch: 58| Step: 0
Training loss: 2.729499524811247
Validation loss: 2.929697160602352

Epoch: 5| Step: 1
Training loss: 3.6428274933492624
Validation loss: 2.928838516661063

Epoch: 5| Step: 2
Training loss: 2.9240667109465743
Validation loss: 2.9305507870666943

Epoch: 5| Step: 3
Training loss: 3.1732745911533367
Validation loss: 2.9262816495751527

Epoch: 5| Step: 4
Training loss: 2.974872099106528
Validation loss: 2.926930269657826

Epoch: 5| Step: 5
Training loss: 3.5581808845209393
Validation loss: 2.9295237689462974

Epoch: 5| Step: 6
Training loss: 2.8102155096419783
Validation loss: 2.929415093777467

Epoch: 5| Step: 7
Training loss: 3.365108689115849
Validation loss: 2.9281076206777996

Epoch: 5| Step: 8
Training loss: 3.3988332934483316
Validation loss: 2.9286288173468233

Epoch: 5| Step: 9
Training loss: 2.9807128806266125
Validation loss: 2.9263622902426127

Epoch: 5| Step: 10
Training loss: 3.6278169144652783
Validation loss: 2.9253569829752863

Epoch: 59| Step: 0
Training loss: 3.8358386739831367
Validation loss: 2.9229416605963885

Epoch: 5| Step: 1
Training loss: 3.3120057798970968
Validation loss: 2.923980132656118

Epoch: 5| Step: 2
Training loss: 2.357007891849323
Validation loss: 2.9229874207774156

Epoch: 5| Step: 3
Training loss: 3.035194897497671
Validation loss: 2.919928523076772

Epoch: 5| Step: 4
Training loss: 3.462949008955091
Validation loss: 2.922431463327093

Epoch: 5| Step: 5
Training loss: 2.9321093505410527
Validation loss: 2.919720578255769

Epoch: 5| Step: 6
Training loss: 2.847554774105025
Validation loss: 2.921778011066772

Epoch: 5| Step: 7
Training loss: 3.1237663885925415
Validation loss: 2.9218525666599713

Epoch: 5| Step: 8
Training loss: 3.644326485363432
Validation loss: 2.9202079226495825

Epoch: 5| Step: 9
Training loss: 3.19000056299665
Validation loss: 2.9158511684444237

Epoch: 5| Step: 10
Training loss: 3.2528899621842577
Validation loss: 2.9171207502268475

Epoch: 60| Step: 0
Training loss: 4.190046987702557
Validation loss: 2.916602986310056

Epoch: 5| Step: 1
Training loss: 2.7776944010195437
Validation loss: 2.9159356608991596

Epoch: 5| Step: 2
Training loss: 2.912405734521821
Validation loss: 2.914531413699691

Epoch: 5| Step: 3
Training loss: 3.029130017366269
Validation loss: 2.914559976140438

Epoch: 5| Step: 4
Training loss: 2.9131985526547863
Validation loss: 2.915204080199726

Epoch: 5| Step: 5
Training loss: 3.334424571390098
Validation loss: 2.9144392840230107

Epoch: 5| Step: 6
Training loss: 3.4717417693992036
Validation loss: 2.912674509505106

Epoch: 5| Step: 7
Training loss: 3.3934306126148854
Validation loss: 2.909883988842013

Epoch: 5| Step: 8
Training loss: 3.1354588772962435
Validation loss: 2.9101845030133373

Epoch: 5| Step: 9
Training loss: 3.36297357904206
Validation loss: 2.908348482332678

Epoch: 5| Step: 10
Training loss: 2.1758296831037782
Validation loss: 2.9080315081724564

Epoch: 61| Step: 0
Training loss: 3.247715367083578
Validation loss: 2.907234327766587

Epoch: 5| Step: 1
Training loss: 3.811278726050999
Validation loss: 2.909140407530586

Epoch: 5| Step: 2
Training loss: 3.082281104960668
Validation loss: 2.908066528429544

Epoch: 5| Step: 3
Training loss: 2.8784391316678555
Validation loss: 2.9086355606298206

Epoch: 5| Step: 4
Training loss: 3.038814583597744
Validation loss: 2.9117214722282228

Epoch: 5| Step: 5
Training loss: 3.833735873330342
Validation loss: 2.9101399862458917

Epoch: 5| Step: 6
Training loss: 2.577564155379582
Validation loss: 2.911996540768836

Epoch: 5| Step: 7
Training loss: 2.987369971857333
Validation loss: 2.906756632673133

Epoch: 5| Step: 8
Training loss: 2.707601644029314
Validation loss: 2.905437297189938

Epoch: 5| Step: 9
Training loss: 3.1464610368276316
Validation loss: 2.901922946224004

Epoch: 5| Step: 10
Training loss: 3.5388140391191505
Validation loss: 2.9010124085032114

Epoch: 62| Step: 0
Training loss: 2.7795807190188344
Validation loss: 2.901178105622984

Epoch: 5| Step: 1
Training loss: 3.6288320084154204
Validation loss: 2.9023891512719984

Epoch: 5| Step: 2
Training loss: 2.9659084172581913
Validation loss: 2.900256151407839

Epoch: 5| Step: 3
Training loss: 2.712959349100278
Validation loss: 2.9056987982924505

Epoch: 5| Step: 4
Training loss: 3.5285180250531525
Validation loss: 2.9185857793513788

Epoch: 5| Step: 5
Training loss: 2.8491647332910044
Validation loss: 2.91979966428672

Epoch: 5| Step: 6
Training loss: 3.082922126224525
Validation loss: 2.897828059073958

Epoch: 5| Step: 7
Training loss: 3.2860325428145907
Validation loss: 2.895018406177777

Epoch: 5| Step: 8
Training loss: 3.4126216545358257
Validation loss: 2.897648377457963

Epoch: 5| Step: 9
Training loss: 3.6863974523174567
Validation loss: 2.8998825176743486

Epoch: 5| Step: 10
Training loss: 2.8984523063343177
Validation loss: 2.900442708926357

Epoch: 63| Step: 0
Training loss: 2.974418288346939
Validation loss: 2.9003362048449826

Epoch: 5| Step: 1
Training loss: 3.613832569848181
Validation loss: 2.90029804966856

Epoch: 5| Step: 2
Training loss: 3.989423478047276
Validation loss: 2.901038594346553

Epoch: 5| Step: 3
Training loss: 2.506067542381398
Validation loss: 2.9005061795886826

Epoch: 5| Step: 4
Training loss: 3.443509761233153
Validation loss: 2.9008290285127427

Epoch: 5| Step: 5
Training loss: 3.5774383552406426
Validation loss: 2.9002482507776826

Epoch: 5| Step: 6
Training loss: 2.7370921558368213
Validation loss: 2.89843209929555

Epoch: 5| Step: 7
Training loss: 2.926733373896967
Validation loss: 2.8983359374754314

Epoch: 5| Step: 8
Training loss: 2.5083529166368583
Validation loss: 2.8963752948254657

Epoch: 5| Step: 9
Training loss: 3.7409269563161316
Validation loss: 2.8952912001471063

Epoch: 5| Step: 10
Training loss: 2.547861200842971
Validation loss: 2.8953462747216143

Epoch: 64| Step: 0
Training loss: 3.3756738625775533
Validation loss: 2.8937594079234783

Epoch: 5| Step: 1
Training loss: 3.469815064924618
Validation loss: 2.8929244367820575

Epoch: 5| Step: 2
Training loss: 3.095213572785766
Validation loss: 2.8920093905168054

Epoch: 5| Step: 3
Training loss: 3.0508148543183657
Validation loss: 2.8918039992213207

Epoch: 5| Step: 4
Training loss: 3.322197592171583
Validation loss: 2.8918560330152374

Epoch: 5| Step: 5
Training loss: 3.611616223212873
Validation loss: 2.889642374499998

Epoch: 5| Step: 6
Training loss: 3.02372263271126
Validation loss: 2.886483318955686

Epoch: 5| Step: 7
Training loss: 2.7353031000258876
Validation loss: 2.8878874005831263

Epoch: 5| Step: 8
Training loss: 3.286444630218972
Validation loss: 2.8830204534716777

Epoch: 5| Step: 9
Training loss: 3.0748228378743976
Validation loss: 2.8822102936348766

Epoch: 5| Step: 10
Training loss: 2.8116696297524997
Validation loss: 2.881038478861636

Epoch: 65| Step: 0
Training loss: 3.415324311837647
Validation loss: 2.8804208522472803

Epoch: 5| Step: 1
Training loss: 3.112350037420619
Validation loss: 2.8781832139370835

Epoch: 5| Step: 2
Training loss: 3.4455198195311874
Validation loss: 2.8810290412865

Epoch: 5| Step: 3
Training loss: 3.4087457875196714
Validation loss: 2.880131583826857

Epoch: 5| Step: 4
Training loss: 3.3399252719856967
Validation loss: 2.8857941289355065

Epoch: 5| Step: 5
Training loss: 2.815843840804585
Validation loss: 2.8866446564350663

Epoch: 5| Step: 6
Training loss: 3.0176937932928394
Validation loss: 2.8844918604850247

Epoch: 5| Step: 7
Training loss: 3.0883220489455
Validation loss: 2.883327227084596

Epoch: 5| Step: 8
Training loss: 2.846394744797863
Validation loss: 2.8827169385655456

Epoch: 5| Step: 9
Training loss: 2.7627811789357994
Validation loss: 2.880332299833728

Epoch: 5| Step: 10
Training loss: 3.5782786507078814
Validation loss: 2.874787995599242

Epoch: 66| Step: 0
Training loss: 3.0399306756196336
Validation loss: 2.873212850067159

Epoch: 5| Step: 1
Training loss: 3.3240186404682173
Validation loss: 2.8721739659374266

Epoch: 5| Step: 2
Training loss: 3.339521354596736
Validation loss: 2.872702414818466

Epoch: 5| Step: 3
Training loss: 2.8604869243961093
Validation loss: 2.874260912179523

Epoch: 5| Step: 4
Training loss: 3.2557947876673454
Validation loss: 2.87207778185646

Epoch: 5| Step: 5
Training loss: 3.052327603057496
Validation loss: 2.872811121313859

Epoch: 5| Step: 6
Training loss: 2.9198085392929327
Validation loss: 2.8710530863953005

Epoch: 5| Step: 7
Training loss: 3.2459970912015415
Validation loss: 2.8692006404665746

Epoch: 5| Step: 8
Training loss: 3.493287188562501
Validation loss: 2.8698705129335296

Epoch: 5| Step: 9
Training loss: 2.6425346376572363
Validation loss: 2.875025526613798

Epoch: 5| Step: 10
Training loss: 3.610689394526696
Validation loss: 2.891006044628381

Epoch: 67| Step: 0
Training loss: 3.551295009329151
Validation loss: 2.917866458904524

Epoch: 5| Step: 1
Training loss: 3.207225129264417
Validation loss: 2.898168957107169

Epoch: 5| Step: 2
Training loss: 3.275141670715457
Validation loss: 2.8791050737869597

Epoch: 5| Step: 3
Training loss: 3.0785551593566844
Validation loss: 2.868488052680038

Epoch: 5| Step: 4
Training loss: 2.908962829436291
Validation loss: 2.8647061575383685

Epoch: 5| Step: 5
Training loss: 3.01624256194771
Validation loss: 2.862951395472159

Epoch: 5| Step: 6
Training loss: 2.335685690891855
Validation loss: 2.863805855914751

Epoch: 5| Step: 7
Training loss: 2.9297635081286018
Validation loss: 2.864075902181744

Epoch: 5| Step: 8
Training loss: 3.575775174483109
Validation loss: 2.863401588861638

Epoch: 5| Step: 9
Training loss: 3.4619883024920517
Validation loss: 2.86196938975036

Epoch: 5| Step: 10
Training loss: 3.334969802330824
Validation loss: 2.86110386056204

Epoch: 68| Step: 0
Training loss: 3.1725751733553644
Validation loss: 2.8611547798158488

Epoch: 5| Step: 1
Training loss: 3.032126073968954
Validation loss: 2.8595287797848314

Epoch: 5| Step: 2
Training loss: 3.1464478521991888
Validation loss: 2.8609851365458794

Epoch: 5| Step: 3
Training loss: 3.6836292188277797
Validation loss: 2.86058948119895

Epoch: 5| Step: 4
Training loss: 2.9368775702556786
Validation loss: 2.8584812990500863

Epoch: 5| Step: 5
Training loss: 3.0039749832127542
Validation loss: 2.858136610067541

Epoch: 5| Step: 6
Training loss: 2.8625523991348993
Validation loss: 2.8573461514470457

Epoch: 5| Step: 7
Training loss: 2.8563913923863837
Validation loss: 2.8562089981141536

Epoch: 5| Step: 8
Training loss: 2.9795493211397748
Validation loss: 2.8575188412831656

Epoch: 5| Step: 9
Training loss: 3.6408709659903096
Validation loss: 2.8588418771211437

Epoch: 5| Step: 10
Training loss: 3.249097698843237
Validation loss: 2.859594524834326

Epoch: 69| Step: 0
Training loss: 3.2579584249111755
Validation loss: 2.8590794489055744

Epoch: 5| Step: 1
Training loss: 3.4198061467605
Validation loss: 2.8588931550001067

Epoch: 5| Step: 2
Training loss: 3.236050673881394
Validation loss: 2.8561556399150483

Epoch: 5| Step: 3
Training loss: 3.4110343999724497
Validation loss: 2.855145194076262

Epoch: 5| Step: 4
Training loss: 3.188935947477123
Validation loss: 2.853663502039249

Epoch: 5| Step: 5
Training loss: 2.6275587780563754
Validation loss: 2.8538197114222195

Epoch: 5| Step: 6
Training loss: 3.0253512218019893
Validation loss: 2.8547586893366286

Epoch: 5| Step: 7
Training loss: 3.288282723312066
Validation loss: 2.853675586863119

Epoch: 5| Step: 8
Training loss: 3.3220316666041727
Validation loss: 2.8511727509909885

Epoch: 5| Step: 9
Training loss: 2.9713142965162134
Validation loss: 2.851409152800815

Epoch: 5| Step: 10
Training loss: 2.7048588302356755
Validation loss: 2.8534133125881502

Epoch: 70| Step: 0
Training loss: 2.9372797132640667
Validation loss: 2.85299317412852

Epoch: 5| Step: 1
Training loss: 2.380291515096077
Validation loss: 2.847293690857378

Epoch: 5| Step: 2
Training loss: 3.4494413172281937
Validation loss: 2.846682960177553

Epoch: 5| Step: 3
Training loss: 2.918865265295862
Validation loss: 2.8464567511239784

Epoch: 5| Step: 4
Training loss: 3.3766337078729096
Validation loss: 2.8439250109239294

Epoch: 5| Step: 5
Training loss: 3.2913055382782788
Validation loss: 2.8455044440158983

Epoch: 5| Step: 6
Training loss: 3.431669666078383
Validation loss: 2.845502461487565

Epoch: 5| Step: 7
Training loss: 3.8275626878943134
Validation loss: 2.8494110788507707

Epoch: 5| Step: 8
Training loss: 2.9827459392844493
Validation loss: 2.8491839202787563

Epoch: 5| Step: 9
Training loss: 2.3761447356224883
Validation loss: 2.849018814738612

Epoch: 5| Step: 10
Training loss: 3.2986683962125363
Validation loss: 2.846758726023884

Epoch: 71| Step: 0
Training loss: 2.758896741537956
Validation loss: 2.8464553479222285

Epoch: 5| Step: 1
Training loss: 3.263433277624552
Validation loss: 2.840522409346817

Epoch: 5| Step: 2
Training loss: 3.0821910666837984
Validation loss: 2.840275680062905

Epoch: 5| Step: 3
Training loss: 3.144209301502181
Validation loss: 2.844811772393099

Epoch: 5| Step: 4
Training loss: 3.0361544858907994
Validation loss: 2.848564164924299

Epoch: 5| Step: 5
Training loss: 2.904831899221009
Validation loss: 2.842611503939739

Epoch: 5| Step: 6
Training loss: 2.912734641909085
Validation loss: 2.8387187708711825

Epoch: 5| Step: 7
Training loss: 3.043424403264959
Validation loss: 2.837143804648463

Epoch: 5| Step: 8
Training loss: 3.6289966518610552
Validation loss: 2.8338123498103482

Epoch: 5| Step: 9
Training loss: 3.3761791006282595
Validation loss: 2.835908912282504

Epoch: 5| Step: 10
Training loss: 3.323992675552837
Validation loss: 2.834955815569223

Epoch: 72| Step: 0
Training loss: 3.072873976243893
Validation loss: 2.836480355206737

Epoch: 5| Step: 1
Training loss: 2.9422084327475777
Validation loss: 2.8349687433625808

Epoch: 5| Step: 2
Training loss: 2.976174797380111
Validation loss: 2.836190770396428

Epoch: 5| Step: 3
Training loss: 3.2674511635712693
Validation loss: 2.833835581419763

Epoch: 5| Step: 4
Training loss: 3.539382347491353
Validation loss: 2.8333937257293744

Epoch: 5| Step: 5
Training loss: 2.913430643995255
Validation loss: 2.831915076690897

Epoch: 5| Step: 6
Training loss: 2.5152058696479354
Validation loss: 2.831106779264625

Epoch: 5| Step: 7
Training loss: 3.0759826020640433
Validation loss: 2.8306307368528447

Epoch: 5| Step: 8
Training loss: 3.4631167196530397
Validation loss: 2.8326466284351897

Epoch: 5| Step: 9
Training loss: 3.6322551340742555
Validation loss: 2.8398626921309016

Epoch: 5| Step: 10
Training loss: 2.87408167228845
Validation loss: 2.839985740235282

Epoch: 73| Step: 0
Training loss: 2.433967867730846
Validation loss: 2.8533105023440264

Epoch: 5| Step: 1
Training loss: 2.8954819573571617
Validation loss: 2.865971517544434

Epoch: 5| Step: 2
Training loss: 3.4169278548977546
Validation loss: 2.851530037634904

Epoch: 5| Step: 3
Training loss: 3.1907327751466465
Validation loss: 2.82933242559705

Epoch: 5| Step: 4
Training loss: 2.924007514745655
Validation loss: 2.825232779651201

Epoch: 5| Step: 5
Training loss: 3.366507547854777
Validation loss: 2.8261263451125926

Epoch: 5| Step: 6
Training loss: 3.4342265408529657
Validation loss: 2.8238314803033533

Epoch: 5| Step: 7
Training loss: 2.708006051658281
Validation loss: 2.8249513927375838

Epoch: 5| Step: 8
Training loss: 3.5306980748244174
Validation loss: 2.825875851393578

Epoch: 5| Step: 9
Training loss: 3.158649552215848
Validation loss: 2.8246908186922344

Epoch: 5| Step: 10
Training loss: 3.169526983403509
Validation loss: 2.822355342551284

Epoch: 74| Step: 0
Training loss: 2.8913941056110635
Validation loss: 2.82187905025631

Epoch: 5| Step: 1
Training loss: 2.6288107504652127
Validation loss: 2.822648481148621

Epoch: 5| Step: 2
Training loss: 3.26076236797439
Validation loss: 2.8244208371353965

Epoch: 5| Step: 3
Training loss: 3.1325035037959568
Validation loss: 2.8245515603016327

Epoch: 5| Step: 4
Training loss: 2.872919739815385
Validation loss: 2.821049202451854

Epoch: 5| Step: 5
Training loss: 3.6354636086363508
Validation loss: 2.820998945164303

Epoch: 5| Step: 6
Training loss: 3.3809225604292004
Validation loss: 2.820001562250898

Epoch: 5| Step: 7
Training loss: 3.573722696536927
Validation loss: 2.818726586249004

Epoch: 5| Step: 8
Training loss: 2.893234147629226
Validation loss: 2.8192721180067526

Epoch: 5| Step: 9
Training loss: 3.3985143893959964
Validation loss: 2.818849900351676

Epoch: 5| Step: 10
Training loss: 2.381315667956544
Validation loss: 2.81764220082656

Epoch: 75| Step: 0
Training loss: 3.19496193900444
Validation loss: 2.8179482105873412

Epoch: 5| Step: 1
Training loss: 3.187223534655717
Validation loss: 2.818631944493595

Epoch: 5| Step: 2
Training loss: 3.4466756256351085
Validation loss: 2.820394178992841

Epoch: 5| Step: 3
Training loss: 3.4425663459495808
Validation loss: 2.8182008671552063

Epoch: 5| Step: 4
Training loss: 3.1074970651061853
Validation loss: 2.8251228540299773

Epoch: 5| Step: 5
Training loss: 3.017244684753111
Validation loss: 2.823245507323108

Epoch: 5| Step: 6
Training loss: 3.3588811467032027
Validation loss: 2.8207884188037076

Epoch: 5| Step: 7
Training loss: 2.8459311703516996
Validation loss: 2.819415618907007

Epoch: 5| Step: 8
Training loss: 2.6595919062265954
Validation loss: 2.813534776661319

Epoch: 5| Step: 9
Training loss: 3.0685977563948907
Validation loss: 2.8119538828640875

Epoch: 5| Step: 10
Training loss: 2.787255735771401
Validation loss: 2.8124926312895835

Epoch: 76| Step: 0
Training loss: 3.0400149071478504
Validation loss: 2.810982106562198

Epoch: 5| Step: 1
Training loss: 2.855131742574422
Validation loss: 2.8123431509529024

Epoch: 5| Step: 2
Training loss: 2.7686259050308797
Validation loss: 2.8132408287562467

Epoch: 5| Step: 3
Training loss: 3.41818665600034
Validation loss: 2.8128253087783235

Epoch: 5| Step: 4
Training loss: 3.0742247992217324
Validation loss: 2.8135390683225716

Epoch: 5| Step: 5
Training loss: 3.315501742359498
Validation loss: 2.8108533699131875

Epoch: 5| Step: 6
Training loss: 2.7625832937810446
Validation loss: 2.8124852151607453

Epoch: 5| Step: 7
Training loss: 3.520337282407636
Validation loss: 2.811848080643313

Epoch: 5| Step: 8
Training loss: 3.0245266315424746
Validation loss: 2.8089875687883192

Epoch: 5| Step: 9
Training loss: 3.203219528664234
Validation loss: 2.810464577788063

Epoch: 5| Step: 10
Training loss: 3.219963807797061
Validation loss: 2.8084267547756445

Epoch: 77| Step: 0
Training loss: 2.459227727918102
Validation loss: 2.808284943528482

Epoch: 5| Step: 1
Training loss: 3.5168300343634162
Validation loss: 2.8114845493653653

Epoch: 5| Step: 2
Training loss: 3.409834349515779
Validation loss: 2.8121196603595546

Epoch: 5| Step: 3
Training loss: 2.9688201895999478
Validation loss: 2.808177274005526

Epoch: 5| Step: 4
Training loss: 2.729299838090563
Validation loss: 2.8051335986639856

Epoch: 5| Step: 5
Training loss: 3.210525671915248
Validation loss: 2.8053364721147935

Epoch: 5| Step: 6
Training loss: 2.4932052782225314
Validation loss: 2.802049578922244

Epoch: 5| Step: 7
Training loss: 3.3162265185212476
Validation loss: 2.8028683331161286

Epoch: 5| Step: 8
Training loss: 3.3794404947048524
Validation loss: 2.8023284342581207

Epoch: 5| Step: 9
Training loss: 3.4968271860734976
Validation loss: 2.801580567334809

Epoch: 5| Step: 10
Training loss: 2.946192278614198
Validation loss: 2.801493539223325

Epoch: 78| Step: 0
Training loss: 3.212024810913716
Validation loss: 2.801763452625246

Epoch: 5| Step: 1
Training loss: 2.795988144736199
Validation loss: 2.8006331712321395

Epoch: 5| Step: 2
Training loss: 3.3076742756920168
Validation loss: 2.8027638974656686

Epoch: 5| Step: 3
Training loss: 3.0130816392799282
Validation loss: 2.804308834170728

Epoch: 5| Step: 4
Training loss: 3.088805592128115
Validation loss: 2.8104217434626264

Epoch: 5| Step: 5
Training loss: 3.211165445594782
Validation loss: 2.812059984686674

Epoch: 5| Step: 6
Training loss: 3.383919691066255
Validation loss: 2.81093286312354

Epoch: 5| Step: 7
Training loss: 3.1626273208741726
Validation loss: 2.8108976532714873

Epoch: 5| Step: 8
Training loss: 2.816640561075014
Validation loss: 2.797467994121597

Epoch: 5| Step: 9
Training loss: 3.013925973065391
Validation loss: 2.795143697480546

Epoch: 5| Step: 10
Training loss: 3.118006242580661
Validation loss: 2.794128543402393

Epoch: 79| Step: 0
Training loss: 2.70753172724654
Validation loss: 2.795515848330768

Epoch: 5| Step: 1
Training loss: 3.203055627583379
Validation loss: 2.7948599503429987

Epoch: 5| Step: 2
Training loss: 2.457393164733039
Validation loss: 2.796663020649323

Epoch: 5| Step: 3
Training loss: 3.295415184479513
Validation loss: 2.7973795110555586

Epoch: 5| Step: 4
Training loss: 2.9888272453610134
Validation loss: 2.794213063137216

Epoch: 5| Step: 5
Training loss: 3.2373325260398063
Validation loss: 2.7955221118065894

Epoch: 5| Step: 6
Training loss: 2.9068094350884004
Validation loss: 2.794190332424256

Epoch: 5| Step: 7
Training loss: 3.4796970595120147
Validation loss: 2.7925819698825363

Epoch: 5| Step: 8
Training loss: 2.680914506174433
Validation loss: 2.793021906392703

Epoch: 5| Step: 9
Training loss: 3.6314156420643573
Validation loss: 2.7906094880213743

Epoch: 5| Step: 10
Training loss: 3.3958444107592682
Validation loss: 2.7901496481525805

Epoch: 80| Step: 0
Training loss: 3.340030776470264
Validation loss: 2.793939612090037

Epoch: 5| Step: 1
Training loss: 3.536743077691001
Validation loss: 2.79968149509535

Epoch: 5| Step: 2
Training loss: 2.818384837923134
Validation loss: 2.8096666897342035

Epoch: 5| Step: 3
Training loss: 3.3841364078128664
Validation loss: 2.8071787072865435

Epoch: 5| Step: 4
Training loss: 3.247886263786821
Validation loss: 2.7938084884393635

Epoch: 5| Step: 5
Training loss: 2.3716569762613893
Validation loss: 2.7877928117383353

Epoch: 5| Step: 6
Training loss: 2.890259755746614
Validation loss: 2.785650177771299

Epoch: 5| Step: 7
Training loss: 3.1962468429746766
Validation loss: 2.7865035143779253

Epoch: 5| Step: 8
Training loss: 3.2930559212401844
Validation loss: 2.7866913146145595

Epoch: 5| Step: 9
Training loss: 2.874749214180881
Validation loss: 2.7863896723834554

Epoch: 5| Step: 10
Training loss: 2.925793147349392
Validation loss: 2.790216375616951

Epoch: 81| Step: 0
Training loss: 3.3405112865424624
Validation loss: 2.79045775319231

Epoch: 5| Step: 1
Training loss: 2.567110426634468
Validation loss: 2.7920271179011045

Epoch: 5| Step: 2
Training loss: 2.5969473194100914
Validation loss: 2.788023920319309

Epoch: 5| Step: 3
Training loss: 3.5917355406162055
Validation loss: 2.788211222782341

Epoch: 5| Step: 4
Training loss: 2.7486273200677465
Validation loss: 2.7888321062541435

Epoch: 5| Step: 5
Training loss: 3.2410823547107053
Validation loss: 2.7845673419358508

Epoch: 5| Step: 6
Training loss: 3.1946468639280114
Validation loss: 2.7817436850266124

Epoch: 5| Step: 7
Training loss: 3.405201881910584
Validation loss: 2.7793101419365356

Epoch: 5| Step: 8
Training loss: 3.0093357737233695
Validation loss: 2.7799491425645257

Epoch: 5| Step: 9
Training loss: 3.0881074253825957
Validation loss: 2.7771772397583834

Epoch: 5| Step: 10
Training loss: 3.1627948246614532
Validation loss: 2.7824799989959326

Epoch: 82| Step: 0
Training loss: 3.073042493065231
Validation loss: 2.7823163106539353

Epoch: 5| Step: 1
Training loss: 3.7376526051882233
Validation loss: 2.8021040744626085

Epoch: 5| Step: 2
Training loss: 3.3426861362942715
Validation loss: 2.7851289875151886

Epoch: 5| Step: 3
Training loss: 3.311845966765448
Validation loss: 2.777474894537671

Epoch: 5| Step: 4
Training loss: 2.5401572347018315
Validation loss: 2.7749583918836964

Epoch: 5| Step: 5
Training loss: 3.1505698279007426
Validation loss: 2.771845780090848

Epoch: 5| Step: 6
Training loss: 3.6113269366463028
Validation loss: 2.77149432990042

Epoch: 5| Step: 7
Training loss: 2.923080929857666
Validation loss: 2.7744849642310627

Epoch: 5| Step: 8
Training loss: 2.749451756014039
Validation loss: 2.7713109512342737

Epoch: 5| Step: 9
Training loss: 2.6065708100173066
Validation loss: 2.770744987249466

Epoch: 5| Step: 10
Training loss: 2.523415958088198
Validation loss: 2.771639053944868

Epoch: 83| Step: 0
Training loss: 3.0557484845221112
Validation loss: 2.7735623488864

Epoch: 5| Step: 1
Training loss: 3.162758640976155
Validation loss: 2.7695544885636156

Epoch: 5| Step: 2
Training loss: 2.8655861688643256
Validation loss: 2.7678671599871705

Epoch: 5| Step: 3
Training loss: 2.9554418124474546
Validation loss: 2.7660742574931145

Epoch: 5| Step: 4
Training loss: 3.0430301762895144
Validation loss: 2.765996990581943

Epoch: 5| Step: 5
Training loss: 3.369967770974195
Validation loss: 2.768620831683886

Epoch: 5| Step: 6
Training loss: 2.897890270633083
Validation loss: 2.783879785266263

Epoch: 5| Step: 7
Training loss: 3.5548350544581244
Validation loss: 2.8041686970632203

Epoch: 5| Step: 8
Training loss: 2.9213551757578617
Validation loss: 2.819187547496178

Epoch: 5| Step: 9
Training loss: 2.7627291416053597
Validation loss: 2.8060988143872887

Epoch: 5| Step: 10
Training loss: 3.308944665523966
Validation loss: 2.798252456950784

Epoch: 84| Step: 0
Training loss: 3.0498695720863673
Validation loss: 2.7786073554110486

Epoch: 5| Step: 1
Training loss: 3.0395488594998943
Validation loss: 2.764892113939624

Epoch: 5| Step: 2
Training loss: 3.2260363429198753
Validation loss: 2.766597698413078

Epoch: 5| Step: 3
Training loss: 3.0372670025413573
Validation loss: 2.765058503583708

Epoch: 5| Step: 4
Training loss: 2.826374502767639
Validation loss: 2.7673010558641367

Epoch: 5| Step: 5
Training loss: 2.8458510800911827
Validation loss: 2.7687444005494894

Epoch: 5| Step: 6
Training loss: 2.9313943595557648
Validation loss: 2.7678252864074464

Epoch: 5| Step: 7
Training loss: 2.5525451449923704
Validation loss: 2.7657683451045916

Epoch: 5| Step: 8
Training loss: 3.142258556137315
Validation loss: 2.768772257690847

Epoch: 5| Step: 9
Training loss: 3.637776975803161
Validation loss: 2.7662577117672598

Epoch: 5| Step: 10
Training loss: 3.53206699338908
Validation loss: 2.764589896839051

Epoch: 85| Step: 0
Training loss: 3.074641391343675
Validation loss: 2.7647298044561532

Epoch: 5| Step: 1
Training loss: 2.8678707795021663
Validation loss: 2.7653501149337805

Epoch: 5| Step: 2
Training loss: 2.548619334120713
Validation loss: 2.7648255782736237

Epoch: 5| Step: 3
Training loss: 2.824453257088361
Validation loss: 2.76312031761609

Epoch: 5| Step: 4
Training loss: 2.9216365614923308
Validation loss: 2.7613574937856056

Epoch: 5| Step: 5
Training loss: 2.883509275180378
Validation loss: 2.7601252542302297

Epoch: 5| Step: 6
Training loss: 3.3472006987481637
Validation loss: 2.7595161893249855

Epoch: 5| Step: 7
Training loss: 3.4643835129788965
Validation loss: 2.758697517423224

Epoch: 5| Step: 8
Training loss: 3.2966053929306156
Validation loss: 2.7583756665317667

Epoch: 5| Step: 9
Training loss: 3.5397365172440773
Validation loss: 2.758011722976944

Epoch: 5| Step: 10
Training loss: 2.8327415259634052
Validation loss: 2.758136445670112

Epoch: 86| Step: 0
Training loss: 3.248253279577523
Validation loss: 2.7589479934921814

Epoch: 5| Step: 1
Training loss: 2.74364595672141
Validation loss: 2.7628937491448777

Epoch: 5| Step: 2
Training loss: 3.2226600970620978
Validation loss: 2.770503514327681

Epoch: 5| Step: 3
Training loss: 3.1093489295978363
Validation loss: 2.7942494575825045

Epoch: 5| Step: 4
Training loss: 2.8119195975018454
Validation loss: 2.788139690859903

Epoch: 5| Step: 5
Training loss: 3.4007371159535
Validation loss: 2.791143808881799

Epoch: 5| Step: 6
Training loss: 3.188019055758282
Validation loss: 2.7877928117383353

Epoch: 5| Step: 7
Training loss: 3.3280407532250793
Validation loss: 2.773922085864933

Epoch: 5| Step: 8
Training loss: 3.192988438892073
Validation loss: 2.76374118042173

Epoch: 5| Step: 9
Training loss: 2.905996003895773
Validation loss: 2.755583895337869

Epoch: 5| Step: 10
Training loss: 2.453969142026507
Validation loss: 2.757688588170628

Epoch: 87| Step: 0
Training loss: 2.9774573875728283
Validation loss: 2.7518565566214956

Epoch: 5| Step: 1
Training loss: 3.5087269565979384
Validation loss: 2.750345345456514

Epoch: 5| Step: 2
Training loss: 3.1406108798947976
Validation loss: 2.750506601441015

Epoch: 5| Step: 3
Training loss: 2.981499849802129
Validation loss: 2.7533842333420746

Epoch: 5| Step: 4
Training loss: 2.686442144807869
Validation loss: 2.758492033607353

Epoch: 5| Step: 5
Training loss: 2.6246288582143538
Validation loss: 2.7602851810047206

Epoch: 5| Step: 6
Training loss: 3.3150212032048536
Validation loss: 2.770336739167353

Epoch: 5| Step: 7
Training loss: 3.2369199314155144
Validation loss: 2.7718933780018977

Epoch: 5| Step: 8
Training loss: 3.2659669541919776
Validation loss: 2.7752455312565645

Epoch: 5| Step: 9
Training loss: 3.1277654999544127
Validation loss: 2.775458074925806

Epoch: 5| Step: 10
Training loss: 2.6971469109974664
Validation loss: 2.769208004085043

Epoch: 88| Step: 0
Training loss: 3.1581280852151186
Validation loss: 2.766309031225452

Epoch: 5| Step: 1
Training loss: 3.358127096073612
Validation loss: 2.766573920723451

Epoch: 5| Step: 2
Training loss: 3.25649727085678
Validation loss: 2.7577550338785786

Epoch: 5| Step: 3
Training loss: 2.7099693834327847
Validation loss: 2.7494834795174463

Epoch: 5| Step: 4
Training loss: 2.758607225755194
Validation loss: 2.7427901211275674

Epoch: 5| Step: 5
Training loss: 2.708903140257532
Validation loss: 2.7420406521347807

Epoch: 5| Step: 6
Training loss: 2.8483897495504786
Validation loss: 2.7426413061324335

Epoch: 5| Step: 7
Training loss: 2.506243824178264
Validation loss: 2.742559566147251

Epoch: 5| Step: 8
Training loss: 3.2723810862945024
Validation loss: 2.743807686787873

Epoch: 5| Step: 9
Training loss: 3.398306447275573
Validation loss: 2.742653816586474

Epoch: 5| Step: 10
Training loss: 3.6455895623954007
Validation loss: 2.7393962568995502

Epoch: 89| Step: 0
Training loss: 3.203172190248801
Validation loss: 2.7378024857283143

Epoch: 5| Step: 1
Training loss: 2.6403237797408927
Validation loss: 2.738185246185048

Epoch: 5| Step: 2
Training loss: 3.2670168306205
Validation loss: 2.737320931088614

Epoch: 5| Step: 3
Training loss: 2.866349183473912
Validation loss: 2.73783695950789

Epoch: 5| Step: 4
Training loss: 3.0469247667209665
Validation loss: 2.7391033303429233

Epoch: 5| Step: 5
Training loss: 3.258869246747255
Validation loss: 2.7460468102504656

Epoch: 5| Step: 6
Training loss: 3.2911457341677037
Validation loss: 2.775080000915855

Epoch: 5| Step: 7
Training loss: 2.3017478686940493
Validation loss: 2.7717030332496297

Epoch: 5| Step: 8
Training loss: 2.9940844068331973
Validation loss: 2.760964763431142

Epoch: 5| Step: 9
Training loss: 3.2310008264680476
Validation loss: 2.7550279559932154

Epoch: 5| Step: 10
Training loss: 3.4630204728810456
Validation loss: 2.7356437371864635

Epoch: 90| Step: 0
Training loss: 3.4768383131023715
Validation loss: 2.7345344911813165

Epoch: 5| Step: 1
Training loss: 3.085255376054571
Validation loss: 2.741676217693478

Epoch: 5| Step: 2
Training loss: 3.1809730274312478
Validation loss: 2.743445993766692

Epoch: 5| Step: 3
Training loss: 2.498173523317826
Validation loss: 2.7599636555163625

Epoch: 5| Step: 4
Training loss: 3.144071291816536
Validation loss: 2.745712399196111

Epoch: 5| Step: 5
Training loss: 3.1303198736865023
Validation loss: 2.7441621905303357

Epoch: 5| Step: 6
Training loss: 2.3355016397426747
Validation loss: 2.7441317442571207

Epoch: 5| Step: 7
Training loss: 2.148033187275959
Validation loss: 2.7429308733717916

Epoch: 5| Step: 8
Training loss: 3.244270703339259
Validation loss: 2.742772928505617

Epoch: 5| Step: 9
Training loss: 3.6385769957101277
Validation loss: 2.7440050228467205

Epoch: 5| Step: 10
Training loss: 3.5590045578775484
Validation loss: 2.7420928015991266

Epoch: 91| Step: 0
Training loss: 3.1024987947890454
Validation loss: 2.73826411894632

Epoch: 5| Step: 1
Training loss: 2.9691817120315322
Validation loss: 2.7395679185379755

Epoch: 5| Step: 2
Training loss: 3.2975006233081707
Validation loss: 2.7445954168226727

Epoch: 5| Step: 3
Training loss: 3.090259316683334
Validation loss: 2.7531163446793334

Epoch: 5| Step: 4
Training loss: 3.2576143126729775
Validation loss: 2.7685277449038437

Epoch: 5| Step: 5
Training loss: 2.701329158415711
Validation loss: 2.771433987596267

Epoch: 5| Step: 6
Training loss: 3.1324406353195697
Validation loss: 2.7539805291511263

Epoch: 5| Step: 7
Training loss: 3.1648121640360225
Validation loss: 2.739093884804445

Epoch: 5| Step: 8
Training loss: 3.2221735552331667
Validation loss: 2.736095127203179

Epoch: 5| Step: 9
Training loss: 2.719976039107755
Validation loss: 2.731120119577979

Epoch: 5| Step: 10
Training loss: 2.8583438869388997
Validation loss: 2.732050685933134

Epoch: 92| Step: 0
Training loss: 3.1545825746194653
Validation loss: 2.7295977735660504

Epoch: 5| Step: 1
Training loss: 2.9357999386721203
Validation loss: 2.7326876945765597

Epoch: 5| Step: 2
Training loss: 2.9074458461451353
Validation loss: 2.72531917313821

Epoch: 5| Step: 3
Training loss: 3.1320474123234456
Validation loss: 2.727240356914783

Epoch: 5| Step: 4
Training loss: 3.3592969308697582
Validation loss: 2.725863355012427

Epoch: 5| Step: 5
Training loss: 3.1330920924664007
Validation loss: 2.728242707566094

Epoch: 5| Step: 6
Training loss: 3.2107805274035486
Validation loss: 2.727309280596777

Epoch: 5| Step: 7
Training loss: 3.307271321552006
Validation loss: 2.7239329687214533

Epoch: 5| Step: 8
Training loss: 2.4643409083091004
Validation loss: 2.725298160250673

Epoch: 5| Step: 9
Training loss: 2.9055576935519767
Validation loss: 2.727739729615687

Epoch: 5| Step: 10
Training loss: 2.8906890037255417
Validation loss: 2.7294441169161323

Epoch: 93| Step: 0
Training loss: 3.5501218210729064
Validation loss: 2.737855229985612

Epoch: 5| Step: 1
Training loss: 3.236307792162289
Validation loss: 2.7526661895980107

Epoch: 5| Step: 2
Training loss: 3.059651198110916
Validation loss: 2.7582641578451397

Epoch: 5| Step: 3
Training loss: 2.7338188259703644
Validation loss: 2.7620861581110776

Epoch: 5| Step: 4
Training loss: 2.4726335907149455
Validation loss: 2.7418828046516857

Epoch: 5| Step: 5
Training loss: 3.3130081074964055
Validation loss: 2.72612604781029

Epoch: 5| Step: 6
Training loss: 3.193731462458432
Validation loss: 2.720503077204666

Epoch: 5| Step: 7
Training loss: 2.6138565958289197
Validation loss: 2.718357212922989

Epoch: 5| Step: 8
Training loss: 3.548383081271677
Validation loss: 2.7212038565742347

Epoch: 5| Step: 9
Training loss: 2.686976448339182
Validation loss: 2.7198347050181204

Epoch: 5| Step: 10
Training loss: 2.7952949706754557
Validation loss: 2.7236172158135585

Epoch: 94| Step: 0
Training loss: 3.219564094181535
Validation loss: 2.7261397484191066

Epoch: 5| Step: 1
Training loss: 3.3078642742445963
Validation loss: 2.7220484124417466

Epoch: 5| Step: 2
Training loss: 2.6244820583353063
Validation loss: 2.720157156826583

Epoch: 5| Step: 3
Training loss: 2.635128824751205
Validation loss: 2.715857428025244

Epoch: 5| Step: 4
Training loss: 2.957845477501219
Validation loss: 2.715752785089592

Epoch: 5| Step: 5
Training loss: 3.099256450942073
Validation loss: 2.7152114676971277

Epoch: 5| Step: 6
Training loss: 3.0024653477380343
Validation loss: 2.722766502940935

Epoch: 5| Step: 7
Training loss: 2.853006075901069
Validation loss: 2.729565390197157

Epoch: 5| Step: 8
Training loss: 3.1946131306951036
Validation loss: 2.7288398553263633

Epoch: 5| Step: 9
Training loss: 3.287163047782991
Validation loss: 2.7208293807792123

Epoch: 5| Step: 10
Training loss: 3.159874374210313
Validation loss: 2.7198552332210273

Epoch: 95| Step: 0
Training loss: 3.2936039466976954
Validation loss: 2.7190544741516938

Epoch: 5| Step: 1
Training loss: 2.864380670950143
Validation loss: 2.717809661369967

Epoch: 5| Step: 2
Training loss: 3.0532021582077196
Validation loss: 2.7133587830366808

Epoch: 5| Step: 3
Training loss: 3.1059609844756517
Validation loss: 2.712968084305209

Epoch: 5| Step: 4
Training loss: 2.7195771811534395
Validation loss: 2.712069072492084

Epoch: 5| Step: 5
Training loss: 3.598216854988379
Validation loss: 2.713401569901133

Epoch: 5| Step: 6
Training loss: 2.680414840703155
Validation loss: 2.7061944776385585

Epoch: 5| Step: 7
Training loss: 2.6385347117500393
Validation loss: 2.711045507057493

Epoch: 5| Step: 8
Training loss: 2.845937369713027
Validation loss: 2.709124627642064

Epoch: 5| Step: 9
Training loss: 3.079920520995536
Validation loss: 2.7062913610096047

Epoch: 5| Step: 10
Training loss: 3.350270553595276
Validation loss: 2.708843289838351

Epoch: 96| Step: 0
Training loss: 2.989610802571882
Validation loss: 2.70721459643466

Epoch: 5| Step: 1
Training loss: 3.3658822842355267
Validation loss: 2.7101357302121842

Epoch: 5| Step: 2
Training loss: 3.094248105419251
Validation loss: 2.7071397680277625

Epoch: 5| Step: 3
Training loss: 2.9569514275161746
Validation loss: 2.703280501641138

Epoch: 5| Step: 4
Training loss: 2.549114529825883
Validation loss: 2.703822068630719

Epoch: 5| Step: 5
Training loss: 2.9668442883699013
Validation loss: 2.704273419744473

Epoch: 5| Step: 6
Training loss: 2.9716105282270298
Validation loss: 2.7033717602204015

Epoch: 5| Step: 7
Training loss: 2.937767665923865
Validation loss: 2.704996073513401

Epoch: 5| Step: 8
Training loss: 3.3638848838568807
Validation loss: 2.7038631196094984

Epoch: 5| Step: 9
Training loss: 3.2957265580182846
Validation loss: 2.7031871592425976

Epoch: 5| Step: 10
Training loss: 2.636279350685328
Validation loss: 2.7066841619758537

Epoch: 97| Step: 0
Training loss: 3.27967389718661
Validation loss: 2.7074725263684067

Epoch: 5| Step: 1
Training loss: 2.7598377604414974
Validation loss: 2.7191273011743236

Epoch: 5| Step: 2
Training loss: 3.5736914740857424
Validation loss: 2.7098203601273743

Epoch: 5| Step: 3
Training loss: 3.4372575154176217
Validation loss: 2.7059100388660866

Epoch: 5| Step: 4
Training loss: 3.2321997067721555
Validation loss: 2.706477108578539

Epoch: 5| Step: 5
Training loss: 2.69240052304204
Validation loss: 2.6983651846967573

Epoch: 5| Step: 6
Training loss: 2.8203501183703508
Validation loss: 2.696987021547063

Epoch: 5| Step: 7
Training loss: 3.003942601017456
Validation loss: 2.6976089146808166

Epoch: 5| Step: 8
Training loss: 2.869633517376017
Validation loss: 2.698015594537451

Epoch: 5| Step: 9
Training loss: 2.6088045147627175
Validation loss: 2.6998423785571277

Epoch: 5| Step: 10
Training loss: 2.776685676998107
Validation loss: 2.697257264748875

Epoch: 98| Step: 0
Training loss: 2.887091379028273
Validation loss: 2.6970592078016344

Epoch: 5| Step: 1
Training loss: 3.0618445804452987
Validation loss: 2.700872822767246

Epoch: 5| Step: 2
Training loss: 3.2757685334686397
Validation loss: 2.7011943501789712

Epoch: 5| Step: 3
Training loss: 2.6308280189644955
Validation loss: 2.699984578765011

Epoch: 5| Step: 4
Training loss: 2.6937684874995487
Validation loss: 2.7103894852335775

Epoch: 5| Step: 5
Training loss: 2.9169650515560708
Validation loss: 2.702941121970899

Epoch: 5| Step: 6
Training loss: 2.975661093723905
Validation loss: 2.7031092034226347

Epoch: 5| Step: 7
Training loss: 2.7927993829766375
Validation loss: 2.699447601002055

Epoch: 5| Step: 8
Training loss: 3.4224616118368765
Validation loss: 2.694723052988479

Epoch: 5| Step: 9
Training loss: 3.1684831796602677
Validation loss: 2.695278631315277

Epoch: 5| Step: 10
Training loss: 3.340913799709571
Validation loss: 2.6946389080521076

Epoch: 99| Step: 0
Training loss: 3.2553380996270267
Validation loss: 2.694008537558315

Epoch: 5| Step: 1
Training loss: 3.0136405463577383
Validation loss: 2.693427462412008

Epoch: 5| Step: 2
Training loss: 2.663336243737277
Validation loss: 2.6934851726261377

Epoch: 5| Step: 3
Training loss: 2.8166403071357005
Validation loss: 2.69143756228085

Epoch: 5| Step: 4
Training loss: 3.142800863183189
Validation loss: 2.6909528007075516

Epoch: 5| Step: 5
Training loss: 2.506299569645735
Validation loss: 2.6955648486314763

Epoch: 5| Step: 6
Training loss: 3.5619345768398807
Validation loss: 2.6931075507916544

Epoch: 5| Step: 7
Training loss: 3.05855165649914
Validation loss: 2.691003839574115

Epoch: 5| Step: 8
Training loss: 2.843582986810981
Validation loss: 2.6911820040644767

Epoch: 5| Step: 9
Training loss: 2.9425988281040247
Validation loss: 2.6944335350830935

Epoch: 5| Step: 10
Training loss: 3.2476537011168434
Validation loss: 2.688824328520943

Epoch: 100| Step: 0
Training loss: 2.7719919655258196
Validation loss: 2.688565601231961

Epoch: 5| Step: 1
Training loss: 2.4547528739591473
Validation loss: 2.687607698412218

Epoch: 5| Step: 2
Training loss: 2.7772491481888553
Validation loss: 2.6870015343382114

Epoch: 5| Step: 3
Training loss: 2.7225124589338967
Validation loss: 2.6850982182658414

Epoch: 5| Step: 4
Training loss: 2.3547504905168
Validation loss: 2.6862922543609793

Epoch: 5| Step: 5
Training loss: 3.19134259948384
Validation loss: 2.684991061778432

Epoch: 5| Step: 6
Training loss: 2.9592065910268017
Validation loss: 2.6844876265513866

Epoch: 5| Step: 7
Training loss: 3.556245366044872
Validation loss: 2.6881913232932293

Epoch: 5| Step: 8
Training loss: 3.4726522679515273
Validation loss: 2.68720634765872

Epoch: 5| Step: 9
Training loss: 3.3251887160360414
Validation loss: 2.6841133778748616

Epoch: 5| Step: 10
Training loss: 3.3204400251245647
Validation loss: 2.6859787415080625

Epoch: 101| Step: 0
Training loss: 2.9023674082144777
Validation loss: 2.684981892778427

Epoch: 5| Step: 1
Training loss: 2.929073177779301
Validation loss: 2.6834593548458785

Epoch: 5| Step: 2
Training loss: 3.0624556246286776
Validation loss: 2.6834806065037498

Epoch: 5| Step: 3
Training loss: 3.1058647239196646
Validation loss: 2.6837595288248375

Epoch: 5| Step: 4
Training loss: 3.1244442254806932
Validation loss: 2.685915738276951

Epoch: 5| Step: 5
Training loss: 2.701722768130091
Validation loss: 2.683068558968313

Epoch: 5| Step: 6
Training loss: 3.021620566733057
Validation loss: 2.68152570977551

Epoch: 5| Step: 7
Training loss: 3.102452839778048
Validation loss: 2.6851324082206283

Epoch: 5| Step: 8
Training loss: 3.434521858886608
Validation loss: 2.6811788701981034

Epoch: 5| Step: 9
Training loss: 2.7269000962033925
Validation loss: 2.683221878929883

Epoch: 5| Step: 10
Training loss: 2.881431186630799
Validation loss: 2.6818232677603686

Epoch: 102| Step: 0
Training loss: 2.735025906065269
Validation loss: 2.682223619473434

Epoch: 5| Step: 1
Training loss: 2.802226397373169
Validation loss: 2.6811393852085894

Epoch: 5| Step: 2
Training loss: 2.0861732835418114
Validation loss: 2.6795175857796716

Epoch: 5| Step: 3
Training loss: 2.492117949564634
Validation loss: 2.6781447773668843

Epoch: 5| Step: 4
Training loss: 3.2186276310742516
Validation loss: 2.6799850946779307

Epoch: 5| Step: 5
Training loss: 3.0465122104727516
Validation loss: 2.6816053236190776

Epoch: 5| Step: 6
Training loss: 3.829414617558588
Validation loss: 2.6789957880159134

Epoch: 5| Step: 7
Training loss: 3.4710692479318226
Validation loss: 2.682857478520827

Epoch: 5| Step: 8
Training loss: 3.2485314499194438
Validation loss: 2.6789373422130236

Epoch: 5| Step: 9
Training loss: 2.9628730828728393
Validation loss: 2.677136095370647

Epoch: 5| Step: 10
Training loss: 2.7081249059047194
Validation loss: 2.679393504279714

Epoch: 103| Step: 0
Training loss: 2.91217929236783
Validation loss: 2.6779763026952854

Epoch: 5| Step: 1
Training loss: 3.3255919366980597
Validation loss: 2.6779475283396996

Epoch: 5| Step: 2
Training loss: 2.6138618861970357
Validation loss: 2.6758134224860752

Epoch: 5| Step: 3
Training loss: 2.9549341866382206
Validation loss: 2.6751306696064265

Epoch: 5| Step: 4
Training loss: 3.0531877899741393
Validation loss: 2.6741552212532333

Epoch: 5| Step: 5
Training loss: 2.827993653340212
Validation loss: 2.677307952297117

Epoch: 5| Step: 6
Training loss: 2.9395657033051417
Validation loss: 2.6779318374142824

Epoch: 5| Step: 7
Training loss: 3.04293960341866
Validation loss: 2.684621808844994

Epoch: 5| Step: 8
Training loss: 3.5912979385145296
Validation loss: 2.6850328274519675

Epoch: 5| Step: 9
Training loss: 3.074698617943964
Validation loss: 2.6789918655123004

Epoch: 5| Step: 10
Training loss: 2.5454161977046805
Validation loss: 2.672571985229223

Epoch: 104| Step: 0
Training loss: 3.605125534898263
Validation loss: 2.672936558276377

Epoch: 5| Step: 1
Training loss: 2.4561071067964755
Validation loss: 2.671640868124155

Epoch: 5| Step: 2
Training loss: 3.1158973873220397
Validation loss: 2.6710893067900323

Epoch: 5| Step: 3
Training loss: 3.1794238531859835
Validation loss: 2.670467285803731

Epoch: 5| Step: 4
Training loss: 3.1953360782863265
Validation loss: 2.6678217999635794

Epoch: 5| Step: 5
Training loss: 3.050977869084206
Validation loss: 2.67081932806623

Epoch: 5| Step: 6
Training loss: 3.300017536001141
Validation loss: 2.671866354970014

Epoch: 5| Step: 7
Training loss: 2.573469825824171
Validation loss: 2.6684770540254177

Epoch: 5| Step: 8
Training loss: 3.3196239520438753
Validation loss: 2.667726787324198

Epoch: 5| Step: 9
Training loss: 2.2931089082217224
Validation loss: 2.666645904301243

Epoch: 5| Step: 10
Training loss: 2.5096628368421254
Validation loss: 2.6688829224869735

Epoch: 105| Step: 0
Training loss: 2.556187460584353
Validation loss: 2.66818921848961

Epoch: 5| Step: 1
Training loss: 3.2525544031682
Validation loss: 2.667555895973382

Epoch: 5| Step: 2
Training loss: 2.685063433048808
Validation loss: 2.667322758429035

Epoch: 5| Step: 3
Training loss: 3.4900422814548784
Validation loss: 2.666445885127378

Epoch: 5| Step: 4
Training loss: 3.4721883967129528
Validation loss: 2.666500871513673

Epoch: 5| Step: 5
Training loss: 3.0489544936975808
Validation loss: 2.6702749041113294

Epoch: 5| Step: 6
Training loss: 3.05939902743294
Validation loss: 2.6689888094409087

Epoch: 5| Step: 7
Training loss: 2.9320156764799234
Validation loss: 2.6686250785025933

Epoch: 5| Step: 8
Training loss: 2.9733504137765983
Validation loss: 2.674589814762136

Epoch: 5| Step: 9
Training loss: 2.9912908022210325
Validation loss: 2.6868389983243923

Epoch: 5| Step: 10
Training loss: 2.2019146780379866
Validation loss: 2.665850241016796

Epoch: 106| Step: 0
Training loss: 3.309216581448632
Validation loss: 2.6627024495660736

Epoch: 5| Step: 1
Training loss: 3.4254191956539555
Validation loss: 2.66492842606174

Epoch: 5| Step: 2
Training loss: 2.898741343733285
Validation loss: 2.6677463951534337

Epoch: 5| Step: 3
Training loss: 2.656286800353995
Validation loss: 2.673497559671277

Epoch: 5| Step: 4
Training loss: 2.9330277182579327
Validation loss: 2.676919766388062

Epoch: 5| Step: 5
Training loss: 3.2906978646205522
Validation loss: 2.6800613785873253

Epoch: 5| Step: 6
Training loss: 3.25468342121984
Validation loss: 2.678022023201268

Epoch: 5| Step: 7
Training loss: 3.1897326859070723
Validation loss: 2.675585326730131

Epoch: 5| Step: 8
Training loss: 3.045170546893551
Validation loss: 2.673363362754507

Epoch: 5| Step: 9
Training loss: 2.3796135112559056
Validation loss: 2.6699676278105096

Epoch: 5| Step: 10
Training loss: 2.529507166541482
Validation loss: 2.673067611234089

Epoch: 107| Step: 0
Training loss: 3.3222696437732897
Validation loss: 2.683756082308392

Epoch: 5| Step: 1
Training loss: 3.3071186330791456
Validation loss: 2.683018866427748

Epoch: 5| Step: 2
Training loss: 3.0356086776699844
Validation loss: 2.6805131067854577

Epoch: 5| Step: 3
Training loss: 2.828755176790619
Validation loss: 2.682123690796449

Epoch: 5| Step: 4
Training loss: 2.5267406846664793
Validation loss: 2.675106678827891

Epoch: 5| Step: 5
Training loss: 2.831700883209202
Validation loss: 2.680065644843399

Epoch: 5| Step: 6
Training loss: 3.0979430172964006
Validation loss: 2.6919466050703744

Epoch: 5| Step: 7
Training loss: 3.107718021420087
Validation loss: 2.673721594557077

Epoch: 5| Step: 8
Training loss: 2.752307443977565
Validation loss: 2.6689538459633457

Epoch: 5| Step: 9
Training loss: 2.695291712584015
Validation loss: 2.6624378657154772

Epoch: 5| Step: 10
Training loss: 3.3411206041049035
Validation loss: 2.6610742971025365

Epoch: 108| Step: 0
Training loss: 3.454874691491883
Validation loss: 2.6576344182467

Epoch: 5| Step: 1
Training loss: 3.4535805242088715
Validation loss: 2.656751126256248

Epoch: 5| Step: 2
Training loss: 2.696494995785934
Validation loss: 2.6561366733260776

Epoch: 5| Step: 3
Training loss: 3.0943313206606504
Validation loss: 2.6595855867427924

Epoch: 5| Step: 4
Training loss: 2.83133797414154
Validation loss: 2.6634785906566387

Epoch: 5| Step: 5
Training loss: 2.8763242242645073
Validation loss: 2.661454081880619

Epoch: 5| Step: 6
Training loss: 3.0175526837014086
Validation loss: 2.6558045005836264

Epoch: 5| Step: 7
Training loss: 2.4657228477025006
Validation loss: 2.6555868036296038

Epoch: 5| Step: 8
Training loss: 2.8280115262866343
Validation loss: 2.6559004426347785

Epoch: 5| Step: 9
Training loss: 3.2149929600663776
Validation loss: 2.688496966834155

Epoch: 5| Step: 10
Training loss: 2.721082454179334
Validation loss: 2.740612633170788

Epoch: 109| Step: 0
Training loss: 2.825910259547077
Validation loss: 2.783303419348713

Epoch: 5| Step: 1
Training loss: 2.6146926147804828
Validation loss: 2.751081218698339

Epoch: 5| Step: 2
Training loss: 3.2260512715928433
Validation loss: 2.7190291087364824

Epoch: 5| Step: 3
Training loss: 2.488522121203122
Validation loss: 2.67611654678021

Epoch: 5| Step: 4
Training loss: 3.1098963621479063
Validation loss: 2.6507776600629063

Epoch: 5| Step: 5
Training loss: 3.553846456779851
Validation loss: 2.646896780978958

Epoch: 5| Step: 6
Training loss: 2.946512883288773
Validation loss: 2.64958293873348

Epoch: 5| Step: 7
Training loss: 3.1094346543920297
Validation loss: 2.64981792634768

Epoch: 5| Step: 8
Training loss: 3.0696200689260733
Validation loss: 2.6530780603670974

Epoch: 5| Step: 9
Training loss: 3.2362562227981284
Validation loss: 2.653104807116903

Epoch: 5| Step: 10
Training loss: 2.516556087700313
Validation loss: 2.6549829683506267

Epoch: 110| Step: 0
Training loss: 2.802456704450983
Validation loss: 2.6507495310030347

Epoch: 5| Step: 1
Training loss: 2.8254265319744998
Validation loss: 2.6489062949312063

Epoch: 5| Step: 2
Training loss: 2.77780546704373
Validation loss: 2.649502643264201

Epoch: 5| Step: 3
Training loss: 3.071084427801213
Validation loss: 2.658081369195268

Epoch: 5| Step: 4
Training loss: 3.2077766695172256
Validation loss: 2.67053852239243

Epoch: 5| Step: 5
Training loss: 3.022952176355866
Validation loss: 2.6643585597745707

Epoch: 5| Step: 6
Training loss: 3.198006312866851
Validation loss: 2.6493068338767385

Epoch: 5| Step: 7
Training loss: 2.9813589464030263
Validation loss: 2.644727856918247

Epoch: 5| Step: 8
Training loss: 3.068005964589196
Validation loss: 2.6458196711524598

Epoch: 5| Step: 9
Training loss: 2.820956254438045
Validation loss: 2.6413987781991257

Epoch: 5| Step: 10
Training loss: 3.0722348938585395
Validation loss: 2.644534275533484

Epoch: 111| Step: 0
Training loss: 2.981877585197868
Validation loss: 2.6453018513791595

Epoch: 5| Step: 1
Training loss: 3.3658353918651214
Validation loss: 2.6504382335515855

Epoch: 5| Step: 2
Training loss: 2.8665684335718526
Validation loss: 2.6430916864048997

Epoch: 5| Step: 3
Training loss: 3.1373319299675555
Validation loss: 2.642953962960685

Epoch: 5| Step: 4
Training loss: 2.590696260693897
Validation loss: 2.6386889769134574

Epoch: 5| Step: 5
Training loss: 3.2051284107306
Validation loss: 2.637584226968581

Epoch: 5| Step: 6
Training loss: 2.728222448262489
Validation loss: 2.6357479591672544

Epoch: 5| Step: 7
Training loss: 2.8676639337747987
Validation loss: 2.6459751083091407

Epoch: 5| Step: 8
Training loss: 2.994153843282548
Validation loss: 2.6444296105181824

Epoch: 5| Step: 9
Training loss: 2.974123137941035
Validation loss: 2.6444349449079927

Epoch: 5| Step: 10
Training loss: 3.0193753812959843
Validation loss: 2.635686168406581

Epoch: 112| Step: 0
Training loss: 3.1268440909023645
Validation loss: 2.6358049787477786

Epoch: 5| Step: 1
Training loss: 3.3318132908361893
Validation loss: 2.63913925147593

Epoch: 5| Step: 2
Training loss: 3.1403902639850094
Validation loss: 2.636640530500484

Epoch: 5| Step: 3
Training loss: 3.1458710085063317
Validation loss: 2.6362715954130596

Epoch: 5| Step: 4
Training loss: 3.598759220134005
Validation loss: 2.6373728733697477

Epoch: 5| Step: 5
Training loss: 2.15479583357243
Validation loss: 2.6340060148916464

Epoch: 5| Step: 6
Training loss: 2.3575292782467256
Validation loss: 2.6322224682709954

Epoch: 5| Step: 7
Training loss: 2.5224579129143696
Validation loss: 2.6315037144262448

Epoch: 5| Step: 8
Training loss: 2.9602193238220362
Validation loss: 2.6336040843495927

Epoch: 5| Step: 9
Training loss: 3.0499055316240624
Validation loss: 2.6305995114598004

Epoch: 5| Step: 10
Training loss: 3.035732926383609
Validation loss: 2.6330519728847146

Epoch: 113| Step: 0
Training loss: 2.5403880253969233
Validation loss: 2.631059763963193

Epoch: 5| Step: 1
Training loss: 2.583806199716157
Validation loss: 2.6338820611093556

Epoch: 5| Step: 2
Training loss: 3.257858898097729
Validation loss: 2.632127997779836

Epoch: 5| Step: 3
Training loss: 3.4982756045229193
Validation loss: 2.6333989825099784

Epoch: 5| Step: 4
Training loss: 3.2024563719541943
Validation loss: 2.65014529101761

Epoch: 5| Step: 5
Training loss: 3.4245249620670473
Validation loss: 2.6488417895430185

Epoch: 5| Step: 6
Training loss: 3.2182369378810947
Validation loss: 2.64299007255598

Epoch: 5| Step: 7
Training loss: 2.653555367187758
Validation loss: 2.641381175061907

Epoch: 5| Step: 8
Training loss: 2.59619999271255
Validation loss: 2.6288517791498074

Epoch: 5| Step: 9
Training loss: 2.804442158543776
Validation loss: 2.6288242892607636

Epoch: 5| Step: 10
Training loss: 2.6282818578478206
Validation loss: 2.629888310432456

Epoch: 114| Step: 0
Training loss: 3.3317153977733835
Validation loss: 2.628284315868585

Epoch: 5| Step: 1
Training loss: 3.0111134040733076
Validation loss: 2.627370538442308

Epoch: 5| Step: 2
Training loss: 2.6751417746363084
Validation loss: 2.631822701554684

Epoch: 5| Step: 3
Training loss: 3.106543090010627
Validation loss: 2.634352838023562

Epoch: 5| Step: 4
Training loss: 3.645065023211177
Validation loss: 2.635551848651771

Epoch: 5| Step: 5
Training loss: 2.6974989716224727
Validation loss: 2.6369945590607893

Epoch: 5| Step: 6
Training loss: 2.611744609936381
Validation loss: 2.638395197710397

Epoch: 5| Step: 7
Training loss: 2.6613834815999016
Validation loss: 2.64082901446815

Epoch: 5| Step: 8
Training loss: 3.205174381314725
Validation loss: 2.639952341232487

Epoch: 5| Step: 9
Training loss: 3.0562881997808433
Validation loss: 2.635926567249625

Epoch: 5| Step: 10
Training loss: 2.545416759699736
Validation loss: 2.6297660342847258

Epoch: 115| Step: 0
Training loss: 2.7356388332059898
Validation loss: 2.631226610763676

Epoch: 5| Step: 1
Training loss: 3.2750776092418965
Validation loss: 2.6574519594557713

Epoch: 5| Step: 2
Training loss: 2.5023467493530553
Validation loss: 2.6903487091387195

Epoch: 5| Step: 3
Training loss: 3.0965738991213705
Validation loss: 2.7147254052243697

Epoch: 5| Step: 4
Training loss: 3.195981578215215
Validation loss: 2.680960951127009

Epoch: 5| Step: 5
Training loss: 2.921845951037919
Validation loss: 2.6669615225544985

Epoch: 5| Step: 6
Training loss: 3.2339745609979125
Validation loss: 2.641062040715395

Epoch: 5| Step: 7
Training loss: 2.621770143287664
Validation loss: 2.6327325694315857

Epoch: 5| Step: 8
Training loss: 3.0624156083916025
Validation loss: 2.626336044353959

Epoch: 5| Step: 9
Training loss: 2.993097311398834
Validation loss: 2.6202674312539784

Epoch: 5| Step: 10
Training loss: 3.0169760094062745
Validation loss: 2.622688779985641

Epoch: 116| Step: 0
Training loss: 3.3612976250159683
Validation loss: 2.6267825050082125

Epoch: 5| Step: 1
Training loss: 3.0639299440865986
Validation loss: 2.6355418617686497

Epoch: 5| Step: 2
Training loss: 2.54501911718237
Validation loss: 2.638389803011615

Epoch: 5| Step: 3
Training loss: 2.5846365338506456
Validation loss: 2.627803118380779

Epoch: 5| Step: 4
Training loss: 2.793378978559638
Validation loss: 2.6223208735482975

Epoch: 5| Step: 5
Training loss: 3.4226920489311343
Validation loss: 2.618939015691493

Epoch: 5| Step: 6
Training loss: 3.0051652628667718
Validation loss: 2.618557338160581

Epoch: 5| Step: 7
Training loss: 2.6764512163088736
Validation loss: 2.625649060910587

Epoch: 5| Step: 8
Training loss: 2.727044617621168
Validation loss: 2.6487231690829613

Epoch: 5| Step: 9
Training loss: 3.0049902419758565
Validation loss: 2.6618903021676017

Epoch: 5| Step: 10
Training loss: 3.370231367822727
Validation loss: 2.691265344514422

Epoch: 117| Step: 0
Training loss: 2.9436877395946306
Validation loss: 2.6823479829382446

Epoch: 5| Step: 1
Training loss: 3.188620875131935
Validation loss: 2.705511544372685

Epoch: 5| Step: 2
Training loss: 2.8862730515832866
Validation loss: 2.6815371057249617

Epoch: 5| Step: 3
Training loss: 3.3754831604026867
Validation loss: 2.659503872614097

Epoch: 5| Step: 4
Training loss: 2.785310074890649
Validation loss: 2.6371998400976815

Epoch: 5| Step: 5
Training loss: 3.1323689363161296
Validation loss: 2.6266818530661498

Epoch: 5| Step: 6
Training loss: 2.9829977162857855
Validation loss: 2.6241613748761656

Epoch: 5| Step: 7
Training loss: 3.3285258593500973
Validation loss: 2.621486016991028

Epoch: 5| Step: 8
Training loss: 2.67920602638043
Validation loss: 2.6242270730745547

Epoch: 5| Step: 9
Training loss: 2.4626838421817303
Validation loss: 2.623270568674825

Epoch: 5| Step: 10
Training loss: 2.772000824524948
Validation loss: 2.6252690649547725

Epoch: 118| Step: 0
Training loss: 2.6734607296441104
Validation loss: 2.6180755435891467

Epoch: 5| Step: 1
Training loss: 2.8429696825512862
Validation loss: 2.618508723100963

Epoch: 5| Step: 2
Training loss: 3.408350585545633
Validation loss: 2.620060059385781

Epoch: 5| Step: 3
Training loss: 3.364646572467484
Validation loss: 2.6162531005529943

Epoch: 5| Step: 4
Training loss: 3.2668711643696393
Validation loss: 2.6147379162530693

Epoch: 5| Step: 5
Training loss: 2.37322510101042
Validation loss: 2.6184240185824357

Epoch: 5| Step: 6
Training loss: 2.9986375257954068
Validation loss: 2.6169624526942705

Epoch: 5| Step: 7
Training loss: 3.134062481985835
Validation loss: 2.625783867707511

Epoch: 5| Step: 8
Training loss: 3.133507706139175
Validation loss: 2.624122527661296

Epoch: 5| Step: 9
Training loss: 2.4220959962489443
Validation loss: 2.630837759663685

Epoch: 5| Step: 10
Training loss: 2.7316967736245923
Validation loss: 2.6333474054372035

Epoch: 119| Step: 0
Training loss: 3.2810440725466723
Validation loss: 2.636264461514875

Epoch: 5| Step: 1
Training loss: 2.227565178222622
Validation loss: 2.6326436902479586

Epoch: 5| Step: 2
Training loss: 3.3321116751907316
Validation loss: 2.631138842130291

Epoch: 5| Step: 3
Training loss: 2.634034911588362
Validation loss: 2.622092395105221

Epoch: 5| Step: 4
Training loss: 2.797860424833259
Validation loss: 2.6187762230024623

Epoch: 5| Step: 5
Training loss: 2.655263919679981
Validation loss: 2.6134473484014116

Epoch: 5| Step: 6
Training loss: 3.1435458896273283
Validation loss: 2.6117082656405937

Epoch: 5| Step: 7
Training loss: 2.8658009848433306
Validation loss: 2.6107185534573216

Epoch: 5| Step: 8
Training loss: 2.9382216196214235
Validation loss: 2.615595313635024

Epoch: 5| Step: 9
Training loss: 3.4984523893842794
Validation loss: 2.6169175639536704

Epoch: 5| Step: 10
Training loss: 3.0341589429408327
Validation loss: 2.6234803124822603

Epoch: 120| Step: 0
Training loss: 2.7457997583894183
Validation loss: 2.620334572333759

Epoch: 5| Step: 1
Training loss: 3.0384250943265014
Validation loss: 2.61793126897572

Epoch: 5| Step: 2
Training loss: 3.0887060180644954
Validation loss: 2.6178666770359924

Epoch: 5| Step: 3
Training loss: 3.079730394626917
Validation loss: 2.612021911668511

Epoch: 5| Step: 4
Training loss: 2.824523318423546
Validation loss: 2.6074785209875966

Epoch: 5| Step: 5
Training loss: 3.491693995208738
Validation loss: 2.607010964499722

Epoch: 5| Step: 6
Training loss: 2.377266655510864
Validation loss: 2.6065974242037204

Epoch: 5| Step: 7
Training loss: 3.008590478729395
Validation loss: 2.6071212857685704

Epoch: 5| Step: 8
Training loss: 2.8977889083318296
Validation loss: 2.610917685915472

Epoch: 5| Step: 9
Training loss: 2.930988968733739
Validation loss: 2.6088590769552176

Epoch: 5| Step: 10
Training loss: 2.813614179535236
Validation loss: 2.6127588590045914

Epoch: 121| Step: 0
Training loss: 3.0759526831629933
Validation loss: 2.6278504864216647

Epoch: 5| Step: 1
Training loss: 2.810751647063854
Validation loss: 2.617375634033757

Epoch: 5| Step: 2
Training loss: 3.481153701189965
Validation loss: 2.6088739132246808

Epoch: 5| Step: 3
Training loss: 3.087263300544618
Validation loss: 2.6125192712056458

Epoch: 5| Step: 4
Training loss: 2.882115887262319
Validation loss: 2.60386036964553

Epoch: 5| Step: 5
Training loss: 2.6417405520274078
Validation loss: 2.6008583176873663

Epoch: 5| Step: 6
Training loss: 3.1499403024496484
Validation loss: 2.6051246629991205

Epoch: 5| Step: 7
Training loss: 2.5471183800986417
Validation loss: 2.6081713373124797

Epoch: 5| Step: 8
Training loss: 2.856973942804393
Validation loss: 2.6092086688873293

Epoch: 5| Step: 9
Training loss: 3.199506101640313
Validation loss: 2.6090485352196207

Epoch: 5| Step: 10
Training loss: 2.620483327357287
Validation loss: 2.6039965928849327

Epoch: 122| Step: 0
Training loss: 2.877337459212425
Validation loss: 2.605685019249429

Epoch: 5| Step: 1
Training loss: 2.7869759242315126
Validation loss: 2.6020361489391224

Epoch: 5| Step: 2
Training loss: 2.9008920152692568
Validation loss: 2.602183431859673

Epoch: 5| Step: 3
Training loss: 2.7806246622419333
Validation loss: 2.603569530977101

Epoch: 5| Step: 4
Training loss: 2.8970996823053685
Validation loss: 2.6057683590992506

Epoch: 5| Step: 5
Training loss: 3.247336396522568
Validation loss: 2.60278790569519

Epoch: 5| Step: 6
Training loss: 3.121615293466713
Validation loss: 2.6037769204814514

Epoch: 5| Step: 7
Training loss: 3.0994656871429256
Validation loss: 2.6038963646838607

Epoch: 5| Step: 8
Training loss: 2.5821898811308115
Validation loss: 2.5996893181246494

Epoch: 5| Step: 9
Training loss: 2.982561609058739
Validation loss: 2.6062900128089943

Epoch: 5| Step: 10
Training loss: 3.0733821365497627
Validation loss: 2.608043261798125

Epoch: 123| Step: 0
Training loss: 2.637403520744938
Validation loss: 2.6208533561363345

Epoch: 5| Step: 1
Training loss: 2.8116273161873027
Validation loss: 2.624437935107042

Epoch: 5| Step: 2
Training loss: 3.1055198809175133
Validation loss: 2.614510423439308

Epoch: 5| Step: 3
Training loss: 3.3902089791039534
Validation loss: 2.6055652506878

Epoch: 5| Step: 4
Training loss: 2.7388473121560097
Validation loss: 2.6054869244037513

Epoch: 5| Step: 5
Training loss: 2.9402709228871386
Validation loss: 2.59689952589541

Epoch: 5| Step: 6
Training loss: 2.9999136912328312
Validation loss: 2.600511390729339

Epoch: 5| Step: 7
Training loss: 3.1789338439508787
Validation loss: 2.610941942476455

Epoch: 5| Step: 8
Training loss: 2.986268406552177
Validation loss: 2.6082708557356113

Epoch: 5| Step: 9
Training loss: 2.2475468719992238
Validation loss: 2.607771507223184

Epoch: 5| Step: 10
Training loss: 3.303280361711868
Validation loss: 2.6071290510536222

Epoch: 124| Step: 0
Training loss: 2.4043272188504576
Validation loss: 2.5983506562387615

Epoch: 5| Step: 1
Training loss: 3.006264503745386
Validation loss: 2.5998870855854475

Epoch: 5| Step: 2
Training loss: 2.395715616623739
Validation loss: 2.5981927853466837

Epoch: 5| Step: 3
Training loss: 3.495638991460383
Validation loss: 2.6050902004299528

Epoch: 5| Step: 4
Training loss: 2.4758328587409504
Validation loss: 2.6184830944869595

Epoch: 5| Step: 5
Training loss: 3.056133737673531
Validation loss: 2.639219705850993

Epoch: 5| Step: 6
Training loss: 3.1381562052081047
Validation loss: 2.669892648481618

Epoch: 5| Step: 7
Training loss: 3.144306814583825
Validation loss: 2.650535972524139

Epoch: 5| Step: 8
Training loss: 3.1201780119266975
Validation loss: 2.6007487825253097

Epoch: 5| Step: 9
Training loss: 2.9473025128158765
Validation loss: 2.594986247486353

Epoch: 5| Step: 10
Training loss: 3.1261316920563504
Validation loss: 2.5997515266238627

Epoch: 125| Step: 0
Training loss: 3.151733490632049
Validation loss: 2.6119549966224933

Epoch: 5| Step: 1
Training loss: 2.875189235927788
Validation loss: 2.616023108266494

Epoch: 5| Step: 2
Training loss: 2.808132595355088
Validation loss: 2.622175078564687

Epoch: 5| Step: 3
Training loss: 3.0003865310885365
Validation loss: 2.6330169873887668

Epoch: 5| Step: 4
Training loss: 2.7353600171961894
Validation loss: 2.644375986336429

Epoch: 5| Step: 5
Training loss: 3.227206777760883
Validation loss: 2.6313698651068766

Epoch: 5| Step: 6
Training loss: 2.869789045070736
Validation loss: 2.6188018110587414

Epoch: 5| Step: 7
Training loss: 3.3824655826280887
Validation loss: 2.6137089555195674

Epoch: 5| Step: 8
Training loss: 3.092363759819804
Validation loss: 2.6037610686089088

Epoch: 5| Step: 9
Training loss: 2.5137518312057736
Validation loss: 2.5989063147666647

Epoch: 5| Step: 10
Training loss: 2.866631643687556
Validation loss: 2.5965977787942074

Epoch: 126| Step: 0
Training loss: 3.327916671608372
Validation loss: 2.600416572666848

Epoch: 5| Step: 1
Training loss: 3.523067615658194
Validation loss: 2.6182763724357994

Epoch: 5| Step: 2
Training loss: 2.6328583212467587
Validation loss: 2.6373515379050216

Epoch: 5| Step: 3
Training loss: 3.015357761697652
Validation loss: 2.6811676859509834

Epoch: 5| Step: 4
Training loss: 2.1743831285904243
Validation loss: 2.606530941339595

Epoch: 5| Step: 5
Training loss: 3.0766605824596
Validation loss: 2.5898984216154

Epoch: 5| Step: 6
Training loss: 2.9962470103707672
Validation loss: 2.592508940556554

Epoch: 5| Step: 7
Training loss: 3.10641046796514
Validation loss: 2.5930259050674436

Epoch: 5| Step: 8
Training loss: 2.74315250295157
Validation loss: 2.5960340014997256

Epoch: 5| Step: 9
Training loss: 2.897925976962928
Validation loss: 2.596729637282966

Epoch: 5| Step: 10
Training loss: 2.6160568300134663
Validation loss: 2.594963313793835

Epoch: 127| Step: 0
Training loss: 3.243024382531053
Validation loss: 2.5913380254410603

Epoch: 5| Step: 1
Training loss: 3.015511466147297
Validation loss: 2.5906337654813254

Epoch: 5| Step: 2
Training loss: 2.4423190676345103
Validation loss: 2.5850004495964787

Epoch: 5| Step: 3
Training loss: 2.6051603532226992
Validation loss: 2.586451336492539

Epoch: 5| Step: 4
Training loss: 2.4651731824102954
Validation loss: 2.5884998102163697

Epoch: 5| Step: 5
Training loss: 3.287497249935726
Validation loss: 2.601744481633694

Epoch: 5| Step: 6
Training loss: 3.259868311650297
Validation loss: 2.6248515038744324

Epoch: 5| Step: 7
Training loss: 2.8470927283966985
Validation loss: 2.6518509014080935

Epoch: 5| Step: 8
Training loss: 3.2525598275079513
Validation loss: 2.6430594318197445

Epoch: 5| Step: 9
Training loss: 2.74010325286005
Validation loss: 2.6127752243986264

Epoch: 5| Step: 10
Training loss: 3.2406097617752114
Validation loss: 2.6200503989695756

Epoch: 128| Step: 0
Training loss: 2.719844641596311
Validation loss: 2.591407614659635

Epoch: 5| Step: 1
Training loss: 2.9360611008982778
Validation loss: 2.5849730110627984

Epoch: 5| Step: 2
Training loss: 3.392980926091294
Validation loss: 2.5871737428987256

Epoch: 5| Step: 3
Training loss: 2.993555458453528
Validation loss: 2.602930800679732

Epoch: 5| Step: 4
Training loss: 3.0928801267318007
Validation loss: 2.6106577237931203

Epoch: 5| Step: 5
Training loss: 2.980796385989248
Validation loss: 2.609781067747768

Epoch: 5| Step: 6
Training loss: 2.8064200063070635
Validation loss: 2.60960813044231

Epoch: 5| Step: 7
Training loss: 3.565820719022133
Validation loss: 2.58902924174357

Epoch: 5| Step: 8
Training loss: 2.3054403853343963
Validation loss: 2.590806843265228

Epoch: 5| Step: 9
Training loss: 2.7502138748230633
Validation loss: 2.58770073814535

Epoch: 5| Step: 10
Training loss: 2.767875833052716
Validation loss: 2.587360092517351

Epoch: 129| Step: 0
Training loss: 2.359999012057857
Validation loss: 2.584898579338014

Epoch: 5| Step: 1
Training loss: 3.4797066518858615
Validation loss: 2.5820090173921435

Epoch: 5| Step: 2
Training loss: 2.6184899576579843
Validation loss: 2.5828748058563487

Epoch: 5| Step: 3
Training loss: 2.728550402147284
Validation loss: 2.589729610089515

Epoch: 5| Step: 4
Training loss: 3.201943677455716
Validation loss: 2.5932121900413176

Epoch: 5| Step: 5
Training loss: 2.8087637774236094
Validation loss: 2.6044068794621746

Epoch: 5| Step: 6
Training loss: 2.862002140377585
Validation loss: 2.6180415540780495

Epoch: 5| Step: 7
Training loss: 2.7901883457557592
Validation loss: 2.6237280577215825

Epoch: 5| Step: 8
Training loss: 3.0029273056392993
Validation loss: 2.622982304454762

Epoch: 5| Step: 9
Training loss: 2.7916119033983855
Validation loss: 2.6092551060583364

Epoch: 5| Step: 10
Training loss: 3.47060736339999
Validation loss: 2.587796894898329

Epoch: 130| Step: 0
Training loss: 2.6518300700916133
Validation loss: 2.5822482650287637

Epoch: 5| Step: 1
Training loss: 3.1264995791668153
Validation loss: 2.5899303919635432

Epoch: 5| Step: 2
Training loss: 2.8722959324101414
Validation loss: 2.587911989816899

Epoch: 5| Step: 3
Training loss: 3.0678157215503674
Validation loss: 2.588754216658423

Epoch: 5| Step: 4
Training loss: 3.086794036588189
Validation loss: 2.591899422676894

Epoch: 5| Step: 5
Training loss: 2.978248739323781
Validation loss: 2.5993768685994727

Epoch: 5| Step: 6
Training loss: 2.4933664050773325
Validation loss: 2.5931316063069234

Epoch: 5| Step: 7
Training loss: 2.8940000883259263
Validation loss: 2.592630790548528

Epoch: 5| Step: 8
Training loss: 3.1252667122511446
Validation loss: 2.5908513314499313

Epoch: 5| Step: 9
Training loss: 3.1471377735605226
Validation loss: 2.591170250578737

Epoch: 5| Step: 10
Training loss: 2.8653452097044725
Validation loss: 2.5812361633649785

Epoch: 131| Step: 0
Training loss: 2.772789849969432
Validation loss: 2.5793693057994767

Epoch: 5| Step: 1
Training loss: 3.2874810047833773
Validation loss: 2.5817652712360695

Epoch: 5| Step: 2
Training loss: 3.221659410221501
Validation loss: 2.588949621018309

Epoch: 5| Step: 3
Training loss: 3.181306843727551
Validation loss: 2.5898360348454177

Epoch: 5| Step: 4
Training loss: 3.0432285496645113
Validation loss: 2.601803014974039

Epoch: 5| Step: 5
Training loss: 2.6182303557207636
Validation loss: 2.637256459866743

Epoch: 5| Step: 6
Training loss: 2.095737709407086
Validation loss: 2.6655258025032684

Epoch: 5| Step: 7
Training loss: 3.045816717002482
Validation loss: 2.6295943723095947

Epoch: 5| Step: 8
Training loss: 2.827424189110296
Validation loss: 2.598198626119459

Epoch: 5| Step: 9
Training loss: 2.952755052110844
Validation loss: 2.587225348660838

Epoch: 5| Step: 10
Training loss: 3.1394563085168006
Validation loss: 2.5787931260788906

Epoch: 132| Step: 0
Training loss: 3.3634136674535124
Validation loss: 2.575020478538818

Epoch: 5| Step: 1
Training loss: 2.958531189512189
Validation loss: 2.573379323220458

Epoch: 5| Step: 2
Training loss: 2.64504012785905
Validation loss: 2.577049872941111

Epoch: 5| Step: 3
Training loss: 2.6008933183262646
Validation loss: 2.5764367684982914

Epoch: 5| Step: 4
Training loss: 3.1064075514444958
Validation loss: 2.5777232424177425

Epoch: 5| Step: 5
Training loss: 3.1690361962121596
Validation loss: 2.5752156437835203

Epoch: 5| Step: 6
Training loss: 2.929588865527125
Validation loss: 2.570230461193009

Epoch: 5| Step: 7
Training loss: 2.716028978437573
Validation loss: 2.5701164816431166

Epoch: 5| Step: 8
Training loss: 3.005016424353172
Validation loss: 2.5725258991340048

Epoch: 5| Step: 9
Training loss: 2.8419748991167166
Validation loss: 2.5756547127586638

Epoch: 5| Step: 10
Training loss: 2.7320867936965354
Validation loss: 2.5733941956802258

Epoch: 133| Step: 0
Training loss: 3.0957725926255413
Validation loss: 2.5873021202362105

Epoch: 5| Step: 1
Training loss: 2.4836275907780685
Validation loss: 2.5813653285865708

Epoch: 5| Step: 2
Training loss: 3.2490937363243115
Validation loss: 2.5775964398345437

Epoch: 5| Step: 3
Training loss: 2.794829489022753
Validation loss: 2.5764732262640897

Epoch: 5| Step: 4
Training loss: 2.9982083056599684
Validation loss: 2.568069230632539

Epoch: 5| Step: 5
Training loss: 2.7061816446952878
Validation loss: 2.5681167530987574

Epoch: 5| Step: 6
Training loss: 3.0700142984958148
Validation loss: 2.568783006245709

Epoch: 5| Step: 7
Training loss: 2.742793089680717
Validation loss: 2.5740503383697364

Epoch: 5| Step: 8
Training loss: 3.1474695729306763
Validation loss: 2.5698881243112335

Epoch: 5| Step: 9
Training loss: 2.9606749888784667
Validation loss: 2.5728626090270366

Epoch: 5| Step: 10
Training loss: 2.8573654701157096
Validation loss: 2.5702230312807957

Epoch: 134| Step: 0
Training loss: 2.184174325699848
Validation loss: 2.571236589013636

Epoch: 5| Step: 1
Training loss: 2.5861518517478963
Validation loss: 2.5689863223545286

Epoch: 5| Step: 2
Training loss: 3.536419890264558
Validation loss: 2.572249121470561

Epoch: 5| Step: 3
Training loss: 2.864267801188686
Validation loss: 2.574356503399833

Epoch: 5| Step: 4
Training loss: 2.6788059041165955
Validation loss: 2.581022292346013

Epoch: 5| Step: 5
Training loss: 2.954316075630948
Validation loss: 2.5840448622902565

Epoch: 5| Step: 6
Training loss: 2.9012947086306355
Validation loss: 2.588586411001008

Epoch: 5| Step: 7
Training loss: 3.174947819318533
Validation loss: 2.613848541580891

Epoch: 5| Step: 8
Training loss: 2.6018452075477714
Validation loss: 2.609895938725104

Epoch: 5| Step: 9
Training loss: 2.932008520699437
Validation loss: 2.592355069628229

Epoch: 5| Step: 10
Training loss: 3.5571748519789224
Validation loss: 2.585635544428725

Epoch: 135| Step: 0
Training loss: 3.144876667266832
Validation loss: 2.5727438733953205

Epoch: 5| Step: 1
Training loss: 3.460522628959324
Validation loss: 2.563633752741097

Epoch: 5| Step: 2
Training loss: 2.2616940828075185
Validation loss: 2.561727139635734

Epoch: 5| Step: 3
Training loss: 2.559827015217895
Validation loss: 2.56464217611379

Epoch: 5| Step: 4
Training loss: 2.3868989517436554
Validation loss: 2.5611595901948205

Epoch: 5| Step: 5
Training loss: 2.9355561338114966
Validation loss: 2.563098034328865

Epoch: 5| Step: 6
Training loss: 2.5787247393688815
Validation loss: 2.5588335127948

Epoch: 5| Step: 7
Training loss: 2.9187907704154474
Validation loss: 2.558902701598158

Epoch: 5| Step: 8
Training loss: 3.15743059796364
Validation loss: 2.559982107238383

Epoch: 5| Step: 9
Training loss: 3.049912410791657
Validation loss: 2.5605749747563373

Epoch: 5| Step: 10
Training loss: 3.4663384104863715
Validation loss: 2.5652322701676478

Epoch: 136| Step: 0
Training loss: 2.947594039749868
Validation loss: 2.566815021434699

Epoch: 5| Step: 1
Training loss: 2.2549377936941357
Validation loss: 2.571709903411024

Epoch: 5| Step: 2
Training loss: 3.0885854442425127
Validation loss: 2.5800648828713624

Epoch: 5| Step: 3
Training loss: 3.46982729567222
Validation loss: 2.591974017341168

Epoch: 5| Step: 4
Training loss: 2.9516925869935697
Validation loss: 2.589798564940819

Epoch: 5| Step: 5
Training loss: 2.7877464288143545
Validation loss: 2.581265312136894

Epoch: 5| Step: 6
Training loss: 2.5421388739851456
Validation loss: 2.5768062297500838

Epoch: 5| Step: 7
Training loss: 2.900895631540006
Validation loss: 2.564279987525626

Epoch: 5| Step: 8
Training loss: 3.346794382472548
Validation loss: 2.556755192265496

Epoch: 5| Step: 9
Training loss: 2.9883185889211346
Validation loss: 2.5550990612812883

Epoch: 5| Step: 10
Training loss: 2.4316544497912727
Validation loss: 2.5540557247722075

Epoch: 137| Step: 0
Training loss: 2.165369403502665
Validation loss: 2.5621689193142694

Epoch: 5| Step: 1
Training loss: 2.752320437693992
Validation loss: 2.5691204711185636

Epoch: 5| Step: 2
Training loss: 2.911281045737513
Validation loss: 2.5714431700997693

Epoch: 5| Step: 3
Training loss: 3.0086299429484438
Validation loss: 2.5667077060700483

Epoch: 5| Step: 4
Training loss: 2.9801005964773255
Validation loss: 2.5684241689189147

Epoch: 5| Step: 5
Training loss: 3.328199215630113
Validation loss: 2.5598803099440945

Epoch: 5| Step: 6
Training loss: 3.265550968480906
Validation loss: 2.55771132796093

Epoch: 5| Step: 7
Training loss: 3.4355465974097386
Validation loss: 2.555208528669156

Epoch: 5| Step: 8
Training loss: 2.4521767308142226
Validation loss: 2.5583449561420997

Epoch: 5| Step: 9
Training loss: 2.617255457664817
Validation loss: 2.5609486093297487

Epoch: 5| Step: 10
Training loss: 2.8506975090040325
Validation loss: 2.564084921252384

Epoch: 138| Step: 0
Training loss: 2.362234946424287
Validation loss: 2.5769627491655065

Epoch: 5| Step: 1
Training loss: 3.0495240262209813
Validation loss: 2.6038745826254734

Epoch: 5| Step: 2
Training loss: 2.7768003036683493
Validation loss: 2.6529368286122224

Epoch: 5| Step: 3
Training loss: 2.9164513826390737
Validation loss: 2.680920975238603

Epoch: 5| Step: 4
Training loss: 3.186818667129193
Validation loss: 2.7300968634292757

Epoch: 5| Step: 5
Training loss: 3.1586708378354325
Validation loss: 2.718334502409546

Epoch: 5| Step: 6
Training loss: 2.9960959781404686
Validation loss: 2.564704841366389

Epoch: 5| Step: 7
Training loss: 3.0050895751195483
Validation loss: 2.5534892783695065

Epoch: 5| Step: 8
Training loss: 3.3107529837665393
Validation loss: 2.5593627795973752

Epoch: 5| Step: 9
Training loss: 2.765087528050561
Validation loss: 2.601234192367497

Epoch: 5| Step: 10
Training loss: 2.612235231991384
Validation loss: 2.6043848742874176

Epoch: 139| Step: 0
Training loss: 3.137157290765701
Validation loss: 2.5923763096383827

Epoch: 5| Step: 1
Training loss: 3.1441521267959582
Validation loss: 2.5894859738844835

Epoch: 5| Step: 2
Training loss: 2.8653598542096264
Validation loss: 2.5796073403385575

Epoch: 5| Step: 3
Training loss: 2.8037388294284864
Validation loss: 2.5808659654864057

Epoch: 5| Step: 4
Training loss: 3.332932130192971
Validation loss: 2.5816659207074433

Epoch: 5| Step: 5
Training loss: 2.9167603795573216
Validation loss: 2.5766651085945957

Epoch: 5| Step: 6
Training loss: 2.5249822748147484
Validation loss: 2.564352895806136

Epoch: 5| Step: 7
Training loss: 2.7834714954219337
Validation loss: 2.561486783967434

Epoch: 5| Step: 8
Training loss: 3.1411773044175786
Validation loss: 2.568334102393201

Epoch: 5| Step: 9
Training loss: 2.622410086953231
Validation loss: 2.570679127637232

Epoch: 5| Step: 10
Training loss: 3.0532736860165666
Validation loss: 2.5868309209335703

Epoch: 140| Step: 0
Training loss: 3.1452823855402934
Validation loss: 2.582066879161919

Epoch: 5| Step: 1
Training loss: 3.07731036719882
Validation loss: 2.5591410309829983

Epoch: 5| Step: 2
Training loss: 3.0129513920744584
Validation loss: 2.5501383565951876

Epoch: 5| Step: 3
Training loss: 2.5877628395632515
Validation loss: 2.5520180485210266

Epoch: 5| Step: 4
Training loss: 3.177061003726388
Validation loss: 2.5578658837658974

Epoch: 5| Step: 5
Training loss: 2.603909919797988
Validation loss: 2.5575851861108267

Epoch: 5| Step: 6
Training loss: 2.93990389893914
Validation loss: 2.553587714260484

Epoch: 5| Step: 7
Training loss: 2.4857253717228516
Validation loss: 2.552882591258248

Epoch: 5| Step: 8
Training loss: 2.7019835250487763
Validation loss: 2.553983932350268

Epoch: 5| Step: 9
Training loss: 3.018225462776569
Validation loss: 2.5601244063617847

Epoch: 5| Step: 10
Training loss: 3.303730422505723
Validation loss: 2.5676253410062477

Epoch: 141| Step: 0
Training loss: 2.893787530445576
Validation loss: 2.5809611829435624

Epoch: 5| Step: 1
Training loss: 2.6549526861253034
Validation loss: 2.56225894241348

Epoch: 5| Step: 2
Training loss: 3.0120260475217853
Validation loss: 2.5715081016559

Epoch: 5| Step: 3
Training loss: 2.9598130478973528
Validation loss: 2.567402132225967

Epoch: 5| Step: 4
Training loss: 3.2015692677759118
Validation loss: 2.5643617203392144

Epoch: 5| Step: 5
Training loss: 2.9444771550918696
Validation loss: 2.56748345561452

Epoch: 5| Step: 6
Training loss: 2.9575681816232393
Validation loss: 2.566276011191328

Epoch: 5| Step: 7
Training loss: 2.6099845494072436
Validation loss: 2.5638106591122547

Epoch: 5| Step: 8
Training loss: 2.699541218951132
Validation loss: 2.5593620463737663

Epoch: 5| Step: 9
Training loss: 3.0816606847589125
Validation loss: 2.557386910105342

Epoch: 5| Step: 10
Training loss: 2.8004454939526333
Validation loss: 2.552687936018304

Epoch: 142| Step: 0
Training loss: 3.1812744679287595
Validation loss: 2.5485755894314757

Epoch: 5| Step: 1
Training loss: 2.9990250274743424
Validation loss: 2.5502641178747685

Epoch: 5| Step: 2
Training loss: 2.9143984194474566
Validation loss: 2.552956213147521

Epoch: 5| Step: 3
Training loss: 2.9975728707129665
Validation loss: 2.5511165750817524

Epoch: 5| Step: 4
Training loss: 2.8424788767651306
Validation loss: 2.5541073562916234

Epoch: 5| Step: 5
Training loss: 3.093377909777626
Validation loss: 2.5499895947746944

Epoch: 5| Step: 6
Training loss: 2.8904569009927448
Validation loss: 2.5446624556901174

Epoch: 5| Step: 7
Training loss: 2.483643718071626
Validation loss: 2.5455484736166794

Epoch: 5| Step: 8
Training loss: 2.8021603730872084
Validation loss: 2.5440123153780427

Epoch: 5| Step: 9
Training loss: 2.5863997400667746
Validation loss: 2.55083243624247

Epoch: 5| Step: 10
Training loss: 3.1607906803384735
Validation loss: 2.555491989332588

Epoch: 143| Step: 0
Training loss: 3.0274462873260104
Validation loss: 2.5752666380339098

Epoch: 5| Step: 1
Training loss: 2.9238323652482614
Validation loss: 2.5828869864404114

Epoch: 5| Step: 2
Training loss: 2.988138751453321
Validation loss: 2.6064498802293214

Epoch: 5| Step: 3
Training loss: 2.7123518450660313
Validation loss: 2.5975815619094687

Epoch: 5| Step: 4
Training loss: 3.066925277033535
Validation loss: 2.5810099003347378

Epoch: 5| Step: 5
Training loss: 3.048003159028266
Validation loss: 2.5646253526310394

Epoch: 5| Step: 6
Training loss: 2.4833692518192594
Validation loss: 2.5527994429870025

Epoch: 5| Step: 7
Training loss: 3.101225327774551
Validation loss: 2.545561389735967

Epoch: 5| Step: 8
Training loss: 2.6580591660308936
Validation loss: 2.547902618437358

Epoch: 5| Step: 9
Training loss: 2.962393289567608
Validation loss: 2.54953577910019

Epoch: 5| Step: 10
Training loss: 2.9311936232751505
Validation loss: 2.5553291927072834

Epoch: 144| Step: 0
Training loss: 2.803351038704146
Validation loss: 2.5497723497695737

Epoch: 5| Step: 1
Training loss: 2.617253271386717
Validation loss: 2.5443525185447764

Epoch: 5| Step: 2
Training loss: 2.991601473240516
Validation loss: 2.5474580919797187

Epoch: 5| Step: 3
Training loss: 2.504553653141582
Validation loss: 2.549595743315126

Epoch: 5| Step: 4
Training loss: 2.6396578309812515
Validation loss: 2.5504345927072114

Epoch: 5| Step: 5
Training loss: 2.7197782830023858
Validation loss: 2.558319695837767

Epoch: 5| Step: 6
Training loss: 2.998138167889346
Validation loss: 2.580860429676032

Epoch: 5| Step: 7
Training loss: 3.0720202329187876
Validation loss: 2.590784319840933

Epoch: 5| Step: 8
Training loss: 3.3874485589094654
Validation loss: 2.5787678583004854

Epoch: 5| Step: 9
Training loss: 2.9007956893072486
Validation loss: 2.5840757254619553

Epoch: 5| Step: 10
Training loss: 3.282027379546486
Validation loss: 2.5682895485743735

Epoch: 145| Step: 0
Training loss: 2.927330757806604
Validation loss: 2.5689495807046914

Epoch: 5| Step: 1
Training loss: 2.8953161166519
Validation loss: 2.5587342026532633

Epoch: 5| Step: 2
Training loss: 3.04645836744813
Validation loss: 2.540730168858879

Epoch: 5| Step: 3
Training loss: 2.8981438254081637
Validation loss: 2.5368871778399553

Epoch: 5| Step: 4
Training loss: 2.42280865792322
Validation loss: 2.5414359540906846

Epoch: 5| Step: 5
Training loss: 3.165865914007356
Validation loss: 2.5423553847612403

Epoch: 5| Step: 6
Training loss: 2.98549611069543
Validation loss: 2.552760277061907

Epoch: 5| Step: 7
Training loss: 3.053417517432983
Validation loss: 2.550819704602337

Epoch: 5| Step: 8
Training loss: 2.569959529305722
Validation loss: 2.5517925070793273

Epoch: 5| Step: 9
Training loss: 2.935096731590205
Validation loss: 2.545699088111156

Epoch: 5| Step: 10
Training loss: 3.0068113568234476
Validation loss: 2.542932511535451

Epoch: 146| Step: 0
Training loss: 3.6348473541237962
Validation loss: 2.5358190870347035

Epoch: 5| Step: 1
Training loss: 2.6637076312114236
Validation loss: 2.532522392441603

Epoch: 5| Step: 2
Training loss: 3.082870775185314
Validation loss: 2.540883874874381

Epoch: 5| Step: 3
Training loss: 2.053276360679189
Validation loss: 2.5426317343261524

Epoch: 5| Step: 4
Training loss: 2.3074117820135402
Validation loss: 2.5634764914954546

Epoch: 5| Step: 5
Training loss: 3.151498674191791
Validation loss: 2.5865672148142598

Epoch: 5| Step: 6
Training loss: 2.884437165256845
Validation loss: 2.609013388506825

Epoch: 5| Step: 7
Training loss: 2.543690475029847
Validation loss: 2.6453685169723786

Epoch: 5| Step: 8
Training loss: 2.955162354735638
Validation loss: 2.617752740486251

Epoch: 5| Step: 9
Training loss: 2.833762603852891
Validation loss: 2.586835864212688

Epoch: 5| Step: 10
Training loss: 3.383278054849075
Validation loss: 2.554750364775148

Epoch: 147| Step: 0
Training loss: 2.7868091017842604
Validation loss: 2.540407805731251

Epoch: 5| Step: 1
Training loss: 2.8682882498331406
Validation loss: 2.5341291037000238

Epoch: 5| Step: 2
Training loss: 3.003546525823778
Validation loss: 2.5292373468410827

Epoch: 5| Step: 3
Training loss: 2.68614366593391
Validation loss: 2.533853897876968

Epoch: 5| Step: 4
Training loss: 3.3783571006517246
Validation loss: 2.541130867464162

Epoch: 5| Step: 5
Training loss: 2.645760863105124
Validation loss: 2.5399401075843318

Epoch: 5| Step: 6
Training loss: 2.586880146177251
Validation loss: 2.5398497072510082

Epoch: 5| Step: 7
Training loss: 2.8763374866375004
Validation loss: 2.543139727977315

Epoch: 5| Step: 8
Training loss: 2.274307346747731
Validation loss: 2.5413200546207793

Epoch: 5| Step: 9
Training loss: 3.520396474487703
Validation loss: 2.5399479692523874

Epoch: 5| Step: 10
Training loss: 3.2408553362572166
Validation loss: 2.5398316304319764

Epoch: 148| Step: 0
Training loss: 2.6520196775681626
Validation loss: 2.53914778926652

Epoch: 5| Step: 1
Training loss: 2.845961496828561
Validation loss: 2.5472497861217445

Epoch: 5| Step: 2
Training loss: 2.550341254194799
Validation loss: 2.5624541711998554

Epoch: 5| Step: 3
Training loss: 3.149884594211055
Validation loss: 2.5801121754500116

Epoch: 5| Step: 4
Training loss: 2.8174153926030003
Validation loss: 2.5831766355573436

Epoch: 5| Step: 5
Training loss: 2.8751257164047344
Validation loss: 2.584144511239388

Epoch: 5| Step: 6
Training loss: 3.0492671086012075
Validation loss: 2.5704970969411756

Epoch: 5| Step: 7
Training loss: 2.9712059703962073
Validation loss: 2.5561964025654396

Epoch: 5| Step: 8
Training loss: 2.6832703419117507
Validation loss: 2.5401975113264363

Epoch: 5| Step: 9
Training loss: 2.9159482525288034
Validation loss: 2.5403800752757895

Epoch: 5| Step: 10
Training loss: 3.2602949678338486
Validation loss: 2.5369255722258357

Epoch: 149| Step: 0
Training loss: 2.7332546881859954
Validation loss: 2.533458557971143

Epoch: 5| Step: 1
Training loss: 2.5458430908648797
Validation loss: 2.5400270710756407

Epoch: 5| Step: 2
Training loss: 3.1413546042097265
Validation loss: 2.535595533201113

Epoch: 5| Step: 3
Training loss: 2.8324811065124513
Validation loss: 2.538692322306454

Epoch: 5| Step: 4
Training loss: 2.8241676758597123
Validation loss: 2.54459721993128

Epoch: 5| Step: 5
Training loss: 3.089598828047733
Validation loss: 2.554826061159826

Epoch: 5| Step: 6
Training loss: 2.8320878227108133
Validation loss: 2.549270677836667

Epoch: 5| Step: 7
Training loss: 2.5786827640024432
Validation loss: 2.5537357133440604

Epoch: 5| Step: 8
Training loss: 2.8923418874560984
Validation loss: 2.5530515376569087

Epoch: 5| Step: 9
Training loss: 3.385342328160183
Validation loss: 2.545448844577269

Epoch: 5| Step: 10
Training loss: 2.775456255271691
Validation loss: 2.5411054582352683

Epoch: 150| Step: 0
Training loss: 2.8845781744488805
Validation loss: 2.5365457975585293

Epoch: 5| Step: 1
Training loss: 2.9454344058927036
Validation loss: 2.5276399749380243

Epoch: 5| Step: 2
Training loss: 2.3617917245486497
Validation loss: 2.5263293155905755

Epoch: 5| Step: 3
Training loss: 3.3317282786038738
Validation loss: 2.526908227735245

Epoch: 5| Step: 4
Training loss: 3.2608520087170327
Validation loss: 2.5263725991760753

Epoch: 5| Step: 5
Training loss: 2.9679279996359327
Validation loss: 2.5244765701753993

Epoch: 5| Step: 6
Training loss: 3.041767867682256
Validation loss: 2.524055046006924

Epoch: 5| Step: 7
Training loss: 3.018333365238329
Validation loss: 2.520455492694175

Epoch: 5| Step: 8
Training loss: 2.0447705348576815
Validation loss: 2.5234239464162207

Epoch: 5| Step: 9
Training loss: 2.330083650388985
Validation loss: 2.542810822690658

Epoch: 5| Step: 10
Training loss: 3.1412635267993365
Validation loss: 2.567602169916709

Epoch: 151| Step: 0
Training loss: 3.0927720498990414
Validation loss: 2.6103048020739488

Epoch: 5| Step: 1
Training loss: 2.7327192252431773
Validation loss: 2.6042824057834406

Epoch: 5| Step: 2
Training loss: 2.957249420462647
Validation loss: 2.5896010471905297

Epoch: 5| Step: 3
Training loss: 3.1615365954562633
Validation loss: 2.5495664044142257

Epoch: 5| Step: 4
Training loss: 3.2092559940965337
Validation loss: 2.5287569338290474

Epoch: 5| Step: 5
Training loss: 3.093403498193651
Validation loss: 2.521772500720568

Epoch: 5| Step: 6
Training loss: 2.4525314876545443
Validation loss: 2.524313062091053

Epoch: 5| Step: 7
Training loss: 2.437150294331358
Validation loss: 2.520248540176028

Epoch: 5| Step: 8
Training loss: 2.7843946188632613
Validation loss: 2.525844628620686

Epoch: 5| Step: 9
Training loss: 2.6653532330163086
Validation loss: 2.5240379032454574

Epoch: 5| Step: 10
Training loss: 2.9840503136532504
Validation loss: 2.5258037658511796

Epoch: 152| Step: 0
Training loss: 2.5816760951494504
Validation loss: 2.5256493714897537

Epoch: 5| Step: 1
Training loss: 2.7892311536728873
Validation loss: 2.5328068393638126

Epoch: 5| Step: 2
Training loss: 2.390318109099542
Validation loss: 2.535153763370068

Epoch: 5| Step: 3
Training loss: 2.804447004372822
Validation loss: 2.5361397327447754

Epoch: 5| Step: 4
Training loss: 2.853947057883888
Validation loss: 2.5370357853604997

Epoch: 5| Step: 5
Training loss: 3.205450786007502
Validation loss: 2.5345486004448863

Epoch: 5| Step: 6
Training loss: 3.0820744152454917
Validation loss: 2.5229723736722125

Epoch: 5| Step: 7
Training loss: 2.7714674279069156
Validation loss: 2.5226186022163395

Epoch: 5| Step: 8
Training loss: 2.553999035195069
Validation loss: 2.5276575902455245

Epoch: 5| Step: 9
Training loss: 3.0793496421232884
Validation loss: 2.524599366156476

Epoch: 5| Step: 10
Training loss: 3.387473615142431
Validation loss: 2.524206360005325

Epoch: 153| Step: 0
Training loss: 3.1277263192942186
Validation loss: 2.522780484460062

Epoch: 5| Step: 1
Training loss: 2.329118145577757
Validation loss: 2.522952544028364

Epoch: 5| Step: 2
Training loss: 2.9805713000972447
Validation loss: 2.5245009941781356

Epoch: 5| Step: 3
Training loss: 2.8430667936815976
Validation loss: 2.535135853292842

Epoch: 5| Step: 4
Training loss: 2.746111548245354
Validation loss: 2.5375489141353813

Epoch: 5| Step: 5
Training loss: 3.2135650947166075
Validation loss: 2.5598897718052083

Epoch: 5| Step: 6
Training loss: 2.7552499942237847
Validation loss: 2.5800926468480334

Epoch: 5| Step: 7
Training loss: 2.6191224190735625
Validation loss: 2.5690564890830903

Epoch: 5| Step: 8
Training loss: 2.535329098679467
Validation loss: 2.561375002616969

Epoch: 5| Step: 9
Training loss: 3.381817889516525
Validation loss: 2.5441450068865246

Epoch: 5| Step: 10
Training loss: 2.8949471817073777
Validation loss: 2.5356100823208063

Epoch: 154| Step: 0
Training loss: 3.0446058382133816
Validation loss: 2.530618513632037

Epoch: 5| Step: 1
Training loss: 2.6334664186415577
Validation loss: 2.5250567051041366

Epoch: 5| Step: 2
Training loss: 2.72724709209763
Validation loss: 2.528212793917974

Epoch: 5| Step: 3
Training loss: 3.120406627811219
Validation loss: 2.530336508629725

Epoch: 5| Step: 4
Training loss: 2.664572479567942
Validation loss: 2.527997323198136

Epoch: 5| Step: 5
Training loss: 3.1292357158196205
Validation loss: 2.53206061060465

Epoch: 5| Step: 6
Training loss: 2.460694897516169
Validation loss: 2.5357925023907644

Epoch: 5| Step: 7
Training loss: 3.0250498491703937
Validation loss: 2.5441054185246217

Epoch: 5| Step: 8
Training loss: 2.4723509589500416
Validation loss: 2.570519306445613

Epoch: 5| Step: 9
Training loss: 2.920478038065891
Validation loss: 2.6427880224206106

Epoch: 5| Step: 10
Training loss: 3.4129418949844488
Validation loss: 2.6135020981325474

Epoch: 155| Step: 0
Training loss: 3.058396217330282
Validation loss: 2.589221073788302

Epoch: 5| Step: 1
Training loss: 2.334424399551564
Validation loss: 2.5778505797649673

Epoch: 5| Step: 2
Training loss: 3.00623135313092
Validation loss: 2.5676214450588173

Epoch: 5| Step: 3
Training loss: 2.972845845937198
Validation loss: 2.5579401459702984

Epoch: 5| Step: 4
Training loss: 3.022790489656925
Validation loss: 2.564675679805935

Epoch: 5| Step: 5
Training loss: 2.5103923326845674
Validation loss: 2.5543414681819674

Epoch: 5| Step: 6
Training loss: 3.439202875221401
Validation loss: 2.559264701061091

Epoch: 5| Step: 7
Training loss: 2.9531337192951637
Validation loss: 2.5560462280942144

Epoch: 5| Step: 8
Training loss: 2.805372744186712
Validation loss: 2.568427210242262

Epoch: 5| Step: 9
Training loss: 2.730227305552439
Validation loss: 2.5540322187805073

Epoch: 5| Step: 10
Training loss: 2.4647142282543077
Validation loss: 2.5423611753323274

Epoch: 156| Step: 0
Training loss: 2.8705200452531585
Validation loss: 2.533021251203218

Epoch: 5| Step: 1
Training loss: 3.33536226195252
Validation loss: 2.5266783019979338

Epoch: 5| Step: 2
Training loss: 2.2134211847764176
Validation loss: 2.524154170690836

Epoch: 5| Step: 3
Training loss: 2.8961735440939593
Validation loss: 2.5253422599276116

Epoch: 5| Step: 4
Training loss: 2.786950174341385
Validation loss: 2.5224611041773284

Epoch: 5| Step: 5
Training loss: 3.2090399488302537
Validation loss: 2.5273061848649747

Epoch: 5| Step: 6
Training loss: 2.961266169763541
Validation loss: 2.5237524192361382

Epoch: 5| Step: 7
Training loss: 1.9107577697124776
Validation loss: 2.5225067733504107

Epoch: 5| Step: 8
Training loss: 3.1311290907977183
Validation loss: 2.521887919079048

Epoch: 5| Step: 9
Training loss: 2.5654091487508155
Validation loss: 2.5183465831879266

Epoch: 5| Step: 10
Training loss: 3.150127856369422
Validation loss: 2.5288521902221315

Epoch: 157| Step: 0
Training loss: 2.704101386161515
Validation loss: 2.5461391088179948

Epoch: 5| Step: 1
Training loss: 3.0597810158256635
Validation loss: 2.5858152989124155

Epoch: 5| Step: 2
Training loss: 2.8863285611423746
Validation loss: 2.6163665654520227

Epoch: 5| Step: 3
Training loss: 2.6089687373787425
Validation loss: 2.5978032473541837

Epoch: 5| Step: 4
Training loss: 2.8874314271124875
Validation loss: 2.604650688884436

Epoch: 5| Step: 5
Training loss: 3.453244444563502
Validation loss: 2.572428923405803

Epoch: 5| Step: 6
Training loss: 2.4284388041146086
Validation loss: 2.538758056663871

Epoch: 5| Step: 7
Training loss: 2.947863700759313
Validation loss: 2.5197458025618733

Epoch: 5| Step: 8
Training loss: 3.004286564635799
Validation loss: 2.524850491199559

Epoch: 5| Step: 9
Training loss: 2.968973251782475
Validation loss: 2.5240755850716674

Epoch: 5| Step: 10
Training loss: 2.546274313269874
Validation loss: 2.528316881223609

Epoch: 158| Step: 0
Training loss: 2.987821975021093
Validation loss: 2.5297005855125563

Epoch: 5| Step: 1
Training loss: 2.966309678819246
Validation loss: 2.5275750159092043

Epoch: 5| Step: 2
Training loss: 2.511742575430108
Validation loss: 2.5312069882012778

Epoch: 5| Step: 3
Training loss: 2.7350928535948547
Validation loss: 2.521594654046134

Epoch: 5| Step: 4
Training loss: 2.803848183520368
Validation loss: 2.5216929482743233

Epoch: 5| Step: 5
Training loss: 2.9889928431752284
Validation loss: 2.524695334851974

Epoch: 5| Step: 6
Training loss: 3.453234364430482
Validation loss: 2.5391436880807934

Epoch: 5| Step: 7
Training loss: 2.5167156248404225
Validation loss: 2.5572290040474406

Epoch: 5| Step: 8
Training loss: 3.3581246821582442
Validation loss: 2.5665277280732797

Epoch: 5| Step: 9
Training loss: 2.422024728392059
Validation loss: 2.576958981740391

Epoch: 5| Step: 10
Training loss: 2.504716524847179
Validation loss: 2.5657545801847066

Epoch: 159| Step: 0
Training loss: 2.5889878275479408
Validation loss: 2.5542118979136728

Epoch: 5| Step: 1
Training loss: 3.0871313948427006
Validation loss: 2.534473985634813

Epoch: 5| Step: 2
Training loss: 3.246994536239872
Validation loss: 2.526686886757834

Epoch: 5| Step: 3
Training loss: 2.5317376691326405
Validation loss: 2.5238276273110025

Epoch: 5| Step: 4
Training loss: 2.6913817118064545
Validation loss: 2.527439442054327

Epoch: 5| Step: 5
Training loss: 3.151205734311242
Validation loss: 2.5193740880925986

Epoch: 5| Step: 6
Training loss: 2.2383010623714115
Validation loss: 2.5302446212790253

Epoch: 5| Step: 7
Training loss: 3.189958110761501
Validation loss: 2.5241905731206704

Epoch: 5| Step: 8
Training loss: 3.038894609457145
Validation loss: 2.524779331502977

Epoch: 5| Step: 9
Training loss: 2.4980832381356994
Validation loss: 2.521078344113376

Epoch: 5| Step: 10
Training loss: 2.750305158849991
Validation loss: 2.521554722827733

Epoch: 160| Step: 0
Training loss: 3.18119322720515
Validation loss: 2.522800927201723

Epoch: 5| Step: 1
Training loss: 3.1704678726289073
Validation loss: 2.5182214727001164

Epoch: 5| Step: 2
Training loss: 2.873866977509388
Validation loss: 2.5195727140857906

Epoch: 5| Step: 3
Training loss: 2.9395170388607936
Validation loss: 2.5234761955331737

Epoch: 5| Step: 4
Training loss: 2.276701481647439
Validation loss: 2.5328352306788053

Epoch: 5| Step: 5
Training loss: 3.0355310785483662
Validation loss: 2.5556738068001303

Epoch: 5| Step: 6
Training loss: 3.3214673715367287
Validation loss: 2.5720043417340355

Epoch: 5| Step: 7
Training loss: 2.4809640945487184
Validation loss: 2.588923639879805

Epoch: 5| Step: 8
Training loss: 2.3719486913680115
Validation loss: 2.602199925829686

Epoch: 5| Step: 9
Training loss: 3.15925530604051
Validation loss: 2.5781187473195195

Epoch: 5| Step: 10
Training loss: 2.275760473227872
Validation loss: 2.542747392530146

Epoch: 161| Step: 0
Training loss: 2.6979375025903214
Validation loss: 2.525086963071422

Epoch: 5| Step: 1
Training loss: 3.1006780559642566
Validation loss: 2.5167578310374044

Epoch: 5| Step: 2
Training loss: 2.7623038312900814
Validation loss: 2.519065044184152

Epoch: 5| Step: 3
Training loss: 3.2965131081925567
Validation loss: 2.520169168505096

Epoch: 5| Step: 4
Training loss: 2.7578899599603317
Validation loss: 2.5219004186223057

Epoch: 5| Step: 5
Training loss: 2.6971112869380116
Validation loss: 2.525510530204604

Epoch: 5| Step: 6
Training loss: 2.8220103217678973
Validation loss: 2.523217831740558

Epoch: 5| Step: 7
Training loss: 2.847391835771546
Validation loss: 2.524692259125526

Epoch: 5| Step: 8
Training loss: 2.6426435351118043
Validation loss: 2.5197854887646125

Epoch: 5| Step: 9
Training loss: 2.576344100366337
Validation loss: 2.520477067028239

Epoch: 5| Step: 10
Training loss: 2.963846916116838
Validation loss: 2.527832683865568

Epoch: 162| Step: 0
Training loss: 2.853264454904519
Validation loss: 2.5339633118139964

Epoch: 5| Step: 1
Training loss: 2.59692482653763
Validation loss: 2.544569321542709

Epoch: 5| Step: 2
Training loss: 2.824116938485156
Validation loss: 2.5369327186873782

Epoch: 5| Step: 3
Training loss: 3.0197689066504334
Validation loss: 2.543640385747498

Epoch: 5| Step: 4
Training loss: 2.9720952510946868
Validation loss: 2.5551463694668706

Epoch: 5| Step: 5
Training loss: 3.0343038375791505
Validation loss: 2.557281256196876

Epoch: 5| Step: 6
Training loss: 2.5896625714341086
Validation loss: 2.5571010177606524

Epoch: 5| Step: 7
Training loss: 2.4850772848718186
Validation loss: 2.5428844478444947

Epoch: 5| Step: 8
Training loss: 2.493840354104784
Validation loss: 2.5356381632001335

Epoch: 5| Step: 9
Training loss: 3.134534557537214
Validation loss: 2.544457491180461

Epoch: 5| Step: 10
Training loss: 3.0236950353110914
Validation loss: 2.5325983158991696

Epoch: 163| Step: 0
Training loss: 2.518594162429349
Validation loss: 2.5317804825625374

Epoch: 5| Step: 1
Training loss: 2.9057961386409783
Validation loss: 2.527536198527509

Epoch: 5| Step: 2
Training loss: 2.5291764985531833
Validation loss: 2.527879728535873

Epoch: 5| Step: 3
Training loss: 2.9989447327164425
Validation loss: 2.5217379476842927

Epoch: 5| Step: 4
Training loss: 3.146718201807934
Validation loss: 2.5215222647758373

Epoch: 5| Step: 5
Training loss: 3.18393223373145
Validation loss: 2.5152119760078913

Epoch: 5| Step: 6
Training loss: 2.4590974256057048
Validation loss: 2.509484757165538

Epoch: 5| Step: 7
Training loss: 3.08002006945326
Validation loss: 2.516178674491809

Epoch: 5| Step: 8
Training loss: 2.9811249456828306
Validation loss: 2.5275056643243174

Epoch: 5| Step: 9
Training loss: 2.31805381914514
Validation loss: 2.526598690936904

Epoch: 5| Step: 10
Training loss: 2.7818453719430343
Validation loss: 2.5469634786034216

Epoch: 164| Step: 0
Training loss: 3.020548383931774
Validation loss: 2.5752501716553624

Epoch: 5| Step: 1
Training loss: 2.1453522324963448
Validation loss: 2.5892344423595883

Epoch: 5| Step: 2
Training loss: 2.921603266682214
Validation loss: 2.616478093254099

Epoch: 5| Step: 3
Training loss: 3.231273398692783
Validation loss: 2.6780534737846238

Epoch: 5| Step: 4
Training loss: 2.4879192286563225
Validation loss: 2.668322813818276

Epoch: 5| Step: 5
Training loss: 2.750339400414859
Validation loss: 2.6363202582749845

Epoch: 5| Step: 6
Training loss: 2.765744481496125
Validation loss: 2.5986080582611932

Epoch: 5| Step: 7
Training loss: 2.6076725871390196
Validation loss: 2.5317769243395456

Epoch: 5| Step: 8
Training loss: 3.0819065470058526
Validation loss: 2.5121513265571482

Epoch: 5| Step: 9
Training loss: 2.666167828473557
Validation loss: 2.513479759209667

Epoch: 5| Step: 10
Training loss: 3.209203692862944
Validation loss: 2.527254717907735

Epoch: 165| Step: 0
Training loss: 2.765561808925636
Validation loss: 2.544110540549888

Epoch: 5| Step: 1
Training loss: 2.6309875139892034
Validation loss: 2.566014462716491

Epoch: 5| Step: 2
Training loss: 2.6173973796442813
Validation loss: 2.5468890085746665

Epoch: 5| Step: 3
Training loss: 2.461629328288509
Validation loss: 2.5261402022529094

Epoch: 5| Step: 4
Training loss: 3.108847108435526
Validation loss: 2.519025033175997

Epoch: 5| Step: 5
Training loss: 2.829920751857195
Validation loss: 2.5092845561831343

Epoch: 5| Step: 6
Training loss: 3.0428831898874797
Validation loss: 2.513332858706437

Epoch: 5| Step: 7
Training loss: 2.629934577418276
Validation loss: 2.529550536623482

Epoch: 5| Step: 8
Training loss: 2.96399991336879
Validation loss: 2.5642834031715154

Epoch: 5| Step: 9
Training loss: 3.3280401801104635
Validation loss: 2.60757068730018

Epoch: 5| Step: 10
Training loss: 3.070789406892295
Validation loss: 2.6396526117372137

Epoch: 166| Step: 0
Training loss: 2.9236483980541053
Validation loss: 2.5602957816880623

Epoch: 5| Step: 1
Training loss: 2.9821930743216036
Validation loss: 2.5193014376025094

Epoch: 5| Step: 2
Training loss: 2.7012262456115126
Validation loss: 2.5107030833217716

Epoch: 5| Step: 3
Training loss: 2.4717773032383397
Validation loss: 2.511122910102537

Epoch: 5| Step: 4
Training loss: 3.2139314304863698
Validation loss: 2.5079716099840685

Epoch: 5| Step: 5
Training loss: 3.2021527559344927
Validation loss: 2.504436795125879

Epoch: 5| Step: 6
Training loss: 2.709727608198345
Validation loss: 2.507665555800126

Epoch: 5| Step: 7
Training loss: 3.0949203897569166
Validation loss: 2.509767537183908

Epoch: 5| Step: 8
Training loss: 2.286912657163662
Validation loss: 2.531284088468345

Epoch: 5| Step: 9
Training loss: 2.7716844633000925
Validation loss: 2.5562041029139464

Epoch: 5| Step: 10
Training loss: 2.7127959727177244
Validation loss: 2.5551764007955953

Epoch: 167| Step: 0
Training loss: 2.472755080623882
Validation loss: 2.507483868359388

Epoch: 5| Step: 1
Training loss: 2.5291892246034298
Validation loss: 2.502462421335999

Epoch: 5| Step: 2
Training loss: 2.920495671568675
Validation loss: 2.501609283774512

Epoch: 5| Step: 3
Training loss: 3.0833209956841596
Validation loss: 2.5020681399634053

Epoch: 5| Step: 4
Training loss: 2.4624485765693738
Validation loss: 2.5168183296981588

Epoch: 5| Step: 5
Training loss: 3.082179154206168
Validation loss: 2.5307966682420826

Epoch: 5| Step: 6
Training loss: 2.9776601294467073
Validation loss: 2.5512982612283994

Epoch: 5| Step: 7
Training loss: 2.6288153758787516
Validation loss: 2.5772059766808026

Epoch: 5| Step: 8
Training loss: 2.836664616292294
Validation loss: 2.585636744135488

Epoch: 5| Step: 9
Training loss: 2.932458812947972
Validation loss: 2.6027443661819443

Epoch: 5| Step: 10
Training loss: 3.0747908916550384
Validation loss: 2.6122160681757745

Epoch: 168| Step: 0
Training loss: 2.773826034624617
Validation loss: 2.608419099682143

Epoch: 5| Step: 1
Training loss: 3.3473518437938226
Validation loss: 2.6189420531704997

Epoch: 5| Step: 2
Training loss: 2.593773991117632
Validation loss: 2.5796089045956725

Epoch: 5| Step: 3
Training loss: 2.9178321326368395
Validation loss: 2.5368027150174965

Epoch: 5| Step: 4
Training loss: 2.508771671340315
Validation loss: 2.5143084221220193

Epoch: 5| Step: 5
Training loss: 2.6871179708373014
Validation loss: 2.5166431818160175

Epoch: 5| Step: 6
Training loss: 2.189590980620479
Validation loss: 2.5030816517427126

Epoch: 5| Step: 7
Training loss: 3.244538192686483
Validation loss: 2.5057001787217

Epoch: 5| Step: 8
Training loss: 2.9308602795859424
Validation loss: 2.5025456644825383

Epoch: 5| Step: 9
Training loss: 2.862668501379701
Validation loss: 2.503336194992587

Epoch: 5| Step: 10
Training loss: 3.114400205469994
Validation loss: 2.4964699967519715

Epoch: 169| Step: 0
Training loss: 3.0769747216218724
Validation loss: 2.51254711010023

Epoch: 5| Step: 1
Training loss: 2.8271127649141925
Validation loss: 2.510667981245867

Epoch: 5| Step: 2
Training loss: 3.0605901874527772
Validation loss: 2.5270960449416284

Epoch: 5| Step: 3
Training loss: 3.007424069379151
Validation loss: 2.5389673681872043

Epoch: 5| Step: 4
Training loss: 2.9465742166035183
Validation loss: 2.541741645577178

Epoch: 5| Step: 5
Training loss: 2.5670420702409538
Validation loss: 2.5306023757095013

Epoch: 5| Step: 6
Training loss: 2.2656904539979426
Validation loss: 2.517634808846936

Epoch: 5| Step: 7
Training loss: 3.0080227072447117
Validation loss: 2.5134053354339456

Epoch: 5| Step: 8
Training loss: 2.7196464376101295
Validation loss: 2.5099624711728947

Epoch: 5| Step: 9
Training loss: 2.7218475235297834
Validation loss: 2.513976522890685

Epoch: 5| Step: 10
Training loss: 2.6493202021304914
Validation loss: 2.5324670642543397

Epoch: 170| Step: 0
Training loss: 2.8401254884101497
Validation loss: 2.543294967697241

Epoch: 5| Step: 1
Training loss: 2.4995075694528706
Validation loss: 2.548079102788186

Epoch: 5| Step: 2
Training loss: 3.2096604083818256
Validation loss: 2.54230621101261

Epoch: 5| Step: 3
Training loss: 2.574244405013709
Validation loss: 2.537919878827711

Epoch: 5| Step: 4
Training loss: 2.758506104128405
Validation loss: 2.5621168303822532

Epoch: 5| Step: 5
Training loss: 2.8326452392081323
Validation loss: 2.582950867065247

Epoch: 5| Step: 6
Training loss: 2.6395732884465564
Validation loss: 2.567987856911196

Epoch: 5| Step: 7
Training loss: 2.5989876683681263
Validation loss: 2.548921284575924

Epoch: 5| Step: 8
Training loss: 3.056908309964063
Validation loss: 2.5173907525157735

Epoch: 5| Step: 9
Training loss: 2.9779100946980406
Validation loss: 2.5044431007377694

Epoch: 5| Step: 10
Training loss: 2.9858557737335683
Validation loss: 2.491401727734458

Epoch: 171| Step: 0
Training loss: 2.666858268848018
Validation loss: 2.4922909183642012

Epoch: 5| Step: 1
Training loss: 3.010791759596356
Validation loss: 2.4955681773203167

Epoch: 5| Step: 2
Training loss: 3.4528267157651515
Validation loss: 2.492924795694794

Epoch: 5| Step: 3
Training loss: 3.0515048332644867
Validation loss: 2.501412914282416

Epoch: 5| Step: 4
Training loss: 3.0941510181423415
Validation loss: 2.497117550704149

Epoch: 5| Step: 5
Training loss: 1.9137510708059036
Validation loss: 2.496565292859776

Epoch: 5| Step: 6
Training loss: 2.2951505246799653
Validation loss: 2.4976432972215794

Epoch: 5| Step: 7
Training loss: 2.580920559085849
Validation loss: 2.5007193837799333

Epoch: 5| Step: 8
Training loss: 2.7832853606271923
Validation loss: 2.531637312287748

Epoch: 5| Step: 9
Training loss: 2.6435950916980646
Validation loss: 2.562694640212011

Epoch: 5| Step: 10
Training loss: 3.2057655429506426
Validation loss: 2.592041366117173

Epoch: 172| Step: 0
Training loss: 3.094145470205934
Validation loss: 2.6389527258269565

Epoch: 5| Step: 1
Training loss: 3.142335492352238
Validation loss: 2.640851146986993

Epoch: 5| Step: 2
Training loss: 3.1283328784690965
Validation loss: 2.593996674991844

Epoch: 5| Step: 3
Training loss: 2.881557118893075
Validation loss: 2.5568742181830086

Epoch: 5| Step: 4
Training loss: 2.5772723088303118
Validation loss: 2.531251572872166

Epoch: 5| Step: 5
Training loss: 3.4150759242541606
Validation loss: 2.5139427014621685

Epoch: 5| Step: 6
Training loss: 2.67970600622254
Validation loss: 2.4995949468314898

Epoch: 5| Step: 7
Training loss: 2.2514489065155137
Validation loss: 2.4928250184838836

Epoch: 5| Step: 8
Training loss: 2.8969660311555168
Validation loss: 2.5009770760529237

Epoch: 5| Step: 9
Training loss: 2.532280606164999
Validation loss: 2.51940750844615

Epoch: 5| Step: 10
Training loss: 2.2225000631634906
Validation loss: 2.5277036493129827

Epoch: 173| Step: 0
Training loss: 2.7200064551052465
Validation loss: 2.544499515292974

Epoch: 5| Step: 1
Training loss: 2.643375747199279
Validation loss: 2.540180354377896

Epoch: 5| Step: 2
Training loss: 2.8201217798221663
Validation loss: 2.5458527337907615

Epoch: 5| Step: 3
Training loss: 2.3950763225141123
Validation loss: 2.5425092607359905

Epoch: 5| Step: 4
Training loss: 2.3502267484639767
Validation loss: 2.551489995141001

Epoch: 5| Step: 5
Training loss: 3.367595745218011
Validation loss: 2.5448348803208263

Epoch: 5| Step: 6
Training loss: 2.8024807805296432
Validation loss: 2.532280819778036

Epoch: 5| Step: 7
Training loss: 3.357179856024005
Validation loss: 2.536378796604282

Epoch: 5| Step: 8
Training loss: 2.6596839698406822
Validation loss: 2.535176180367083

Epoch: 5| Step: 9
Training loss: 2.957946877467449
Validation loss: 2.5289842174234156

Epoch: 5| Step: 10
Training loss: 2.7118936660873247
Validation loss: 2.540299768373119

Epoch: 174| Step: 0
Training loss: 3.147087470328468
Validation loss: 2.5486468572409247

Epoch: 5| Step: 1
Training loss: 2.774620641948386
Validation loss: 2.542692874638754

Epoch: 5| Step: 2
Training loss: 2.5972149237418574
Validation loss: 2.5310985059535414

Epoch: 5| Step: 3
Training loss: 2.4141037823255194
Validation loss: 2.528454260456314

Epoch: 5| Step: 4
Training loss: 3.1104208562728624
Validation loss: 2.521030564415997

Epoch: 5| Step: 5
Training loss: 2.0310483392234184
Validation loss: 2.5106802629949367

Epoch: 5| Step: 6
Training loss: 3.0927535484934374
Validation loss: 2.4981094472202217

Epoch: 5| Step: 7
Training loss: 2.5728236399112516
Validation loss: 2.5101082789878433

Epoch: 5| Step: 8
Training loss: 2.7615573949228143
Validation loss: 2.51072219080803

Epoch: 5| Step: 9
Training loss: 2.9312577172281475
Validation loss: 2.5203540051024858

Epoch: 5| Step: 10
Training loss: 3.1673756525189622
Validation loss: 2.5373973793961357

Epoch: 175| Step: 0
Training loss: 2.506140415906643
Validation loss: 2.5578526850009244

Epoch: 5| Step: 1
Training loss: 2.1526442523961706
Validation loss: 2.590021456492854

Epoch: 5| Step: 2
Training loss: 2.2680371302100037
Validation loss: 2.5717406883281506

Epoch: 5| Step: 3
Training loss: 2.8690925942095262
Validation loss: 2.5501183451198934

Epoch: 5| Step: 4
Training loss: 3.2015390331028226
Validation loss: 2.530213828969072

Epoch: 5| Step: 5
Training loss: 3.0453772360358946
Validation loss: 2.5135637104474

Epoch: 5| Step: 6
Training loss: 3.1635615199452842
Validation loss: 2.5004279580471978

Epoch: 5| Step: 7
Training loss: 2.813306650408842
Validation loss: 2.49678605335371

Epoch: 5| Step: 8
Training loss: 3.011514817592972
Validation loss: 2.5020647946139576

Epoch: 5| Step: 9
Training loss: 2.950478311329368
Validation loss: 2.5021595774415357

Epoch: 5| Step: 10
Training loss: 2.8798771829378684
Validation loss: 2.502018934698828

Epoch: 176| Step: 0
Training loss: 2.7040332304757895
Validation loss: 2.5096955565512036

Epoch: 5| Step: 1
Training loss: 2.996906274785488
Validation loss: 2.501307100665288

Epoch: 5| Step: 2
Training loss: 2.8877443548739636
Validation loss: 2.5197308901877973

Epoch: 5| Step: 3
Training loss: 3.009307410569514
Validation loss: 2.5326518303300722

Epoch: 5| Step: 4
Training loss: 2.401131673078843
Validation loss: 2.550277567014166

Epoch: 5| Step: 5
Training loss: 2.6667130784128474
Validation loss: 2.567089021516129

Epoch: 5| Step: 6
Training loss: 2.782822496587928
Validation loss: 2.5777198246897495

Epoch: 5| Step: 7
Training loss: 2.913756653636142
Validation loss: 2.5908899705402146

Epoch: 5| Step: 8
Training loss: 2.7648913601163154
Validation loss: 2.6053088617356437

Epoch: 5| Step: 9
Training loss: 3.0507743727915444
Validation loss: 2.5879231194228205

Epoch: 5| Step: 10
Training loss: 2.280633712505196
Validation loss: 2.5677901814926107

Epoch: 177| Step: 0
Training loss: 2.9347319851991887
Validation loss: 2.5585854736935727

Epoch: 5| Step: 1
Training loss: 2.71877876354217
Validation loss: 2.556764607034458

Epoch: 5| Step: 2
Training loss: 2.7637531389885464
Validation loss: 2.5487376476324206

Epoch: 5| Step: 3
Training loss: 2.9601355601534305
Validation loss: 2.548587269039228

Epoch: 5| Step: 4
Training loss: 3.1042207717447297
Validation loss: 2.5419592319982125

Epoch: 5| Step: 5
Training loss: 1.878343969899987
Validation loss: 2.5586113706281175

Epoch: 5| Step: 6
Training loss: 3.0843741404368896
Validation loss: 2.553081466101422

Epoch: 5| Step: 7
Training loss: 2.8291907225659636
Validation loss: 2.5458370982554244

Epoch: 5| Step: 8
Training loss: 2.911105621937761
Validation loss: 2.5385868810262116

Epoch: 5| Step: 9
Training loss: 2.721822033442337
Validation loss: 2.534654777132632

Epoch: 5| Step: 10
Training loss: 2.4608686165024674
Validation loss: 2.5156146317878956

Epoch: 178| Step: 0
Training loss: 2.4451303627505685
Validation loss: 2.5144485497729314

Epoch: 5| Step: 1
Training loss: 2.3550835795868474
Validation loss: 2.5252351414404375

Epoch: 5| Step: 2
Training loss: 2.935944165460269
Validation loss: 2.5346693852580993

Epoch: 5| Step: 3
Training loss: 3.190542227841782
Validation loss: 2.5207801876976257

Epoch: 5| Step: 4
Training loss: 2.683576514398345
Validation loss: 2.5322992501620463

Epoch: 5| Step: 5
Training loss: 2.728237828808774
Validation loss: 2.537209456293386

Epoch: 5| Step: 6
Training loss: 2.940796645827347
Validation loss: 2.5204311047575176

Epoch: 5| Step: 7
Training loss: 2.5055290117382616
Validation loss: 2.5319610310064626

Epoch: 5| Step: 8
Training loss: 2.8674159985371834
Validation loss: 2.5044614708600936

Epoch: 5| Step: 9
Training loss: 2.483893005831069
Validation loss: 2.5086143320176233

Epoch: 5| Step: 10
Training loss: 3.2050561061477048
Validation loss: 2.5070385039283605

Epoch: 179| Step: 0
Training loss: 3.4108312753658265
Validation loss: 2.5032947886582626

Epoch: 5| Step: 1
Training loss: 2.4392504153543055
Validation loss: 2.5155932042858886

Epoch: 5| Step: 2
Training loss: 2.443482222849712
Validation loss: 2.5384026550167755

Epoch: 5| Step: 3
Training loss: 2.8613217923351426
Validation loss: 2.5458043898993172

Epoch: 5| Step: 4
Training loss: 2.942092552010342
Validation loss: 2.51784774321874

Epoch: 5| Step: 5
Training loss: 2.6918861614604372
Validation loss: 2.508456459562486

Epoch: 5| Step: 6
Training loss: 2.7955685766382143
Validation loss: 2.5018484767698506

Epoch: 5| Step: 7
Training loss: 2.4750521413531863
Validation loss: 2.4901611955648684

Epoch: 5| Step: 8
Training loss: 2.6418842270209217
Validation loss: 2.4967857925525276

Epoch: 5| Step: 9
Training loss: 2.5646184212840613
Validation loss: 2.5074289226807878

Epoch: 5| Step: 10
Training loss: 3.0401361525312867
Validation loss: 2.5290669591267902

Epoch: 180| Step: 0
Training loss: 2.6906572470687555
Validation loss: 2.54878743658269

Epoch: 5| Step: 1
Training loss: 2.315824129960957
Validation loss: 2.5816690288517985

Epoch: 5| Step: 2
Training loss: 2.8357669999753883
Validation loss: 2.56934721142941

Epoch: 5| Step: 3
Training loss: 2.348536778506992
Validation loss: 2.515338353232057

Epoch: 5| Step: 4
Training loss: 2.7097707210832143
Validation loss: 2.499420654684716

Epoch: 5| Step: 5
Training loss: 3.156867844946016
Validation loss: 2.495624349240291

Epoch: 5| Step: 6
Training loss: 3.2096641224576286
Validation loss: 2.4989935182020875

Epoch: 5| Step: 7
Training loss: 2.580718060009894
Validation loss: 2.4996757225230515

Epoch: 5| Step: 8
Training loss: 2.8577127263008806
Validation loss: 2.5157379245297395

Epoch: 5| Step: 9
Training loss: 2.839917461377877
Validation loss: 2.525108016855278

Epoch: 5| Step: 10
Training loss: 2.8549500292999532
Validation loss: 2.52550751130141

Epoch: 181| Step: 0
Training loss: 2.7171778024475186
Validation loss: 2.5341344633929075

Epoch: 5| Step: 1
Training loss: 2.7249547377160814
Validation loss: 2.5409690636573057

Epoch: 5| Step: 2
Training loss: 3.1527082759536444
Validation loss: 2.5490480633517905

Epoch: 5| Step: 3
Training loss: 2.153271815993003
Validation loss: 2.5519448998487486

Epoch: 5| Step: 4
Training loss: 2.5236063330892082
Validation loss: 2.539531618612133

Epoch: 5| Step: 5
Training loss: 2.5812788659206665
Validation loss: 2.5343970643439753

Epoch: 5| Step: 6
Training loss: 2.8574270481732906
Validation loss: 2.5345685123263553

Epoch: 5| Step: 7
Training loss: 2.6384697419514054
Validation loss: 2.5116421892579974

Epoch: 5| Step: 8
Training loss: 2.9642836854701233
Validation loss: 2.495560419309797

Epoch: 5| Step: 9
Training loss: 2.935386546738261
Validation loss: 2.4933266654305726

Epoch: 5| Step: 10
Training loss: 3.017019157118726
Validation loss: 2.4837143573562788

Epoch: 182| Step: 0
Training loss: 2.5426894355351926
Validation loss: 2.4981897896560277

Epoch: 5| Step: 1
Training loss: 2.6314115787287022
Validation loss: 2.499919916736619

Epoch: 5| Step: 2
Training loss: 2.6445269225407726
Validation loss: 2.507390615961621

Epoch: 5| Step: 3
Training loss: 3.0868729730735747
Validation loss: 2.530118448294875

Epoch: 5| Step: 4
Training loss: 2.8904273713058326
Validation loss: 2.578929315508919

Epoch: 5| Step: 5
Training loss: 2.4755029186646866
Validation loss: 2.5714714040133413

Epoch: 5| Step: 6
Training loss: 2.4658468052413447
Validation loss: 2.537384539930041

Epoch: 5| Step: 7
Training loss: 2.6696170836624806
Validation loss: 2.524622998947506

Epoch: 5| Step: 8
Training loss: 3.249409255111173
Validation loss: 2.518180039303682

Epoch: 5| Step: 9
Training loss: 2.9010754531363085
Validation loss: 2.5152541208010764

Epoch: 5| Step: 10
Training loss: 2.6589603732894616
Validation loss: 2.5245063062735107

Epoch: 183| Step: 0
Training loss: 2.687532114236269
Validation loss: 2.533228099393533

Epoch: 5| Step: 1
Training loss: 3.0962659065537177
Validation loss: 2.540223768297952

Epoch: 5| Step: 2
Training loss: 2.6649234756447475
Validation loss: 2.534027303802054

Epoch: 5| Step: 3
Training loss: 2.722141474436651
Validation loss: 2.516271889279118

Epoch: 5| Step: 4
Training loss: 2.632842926845695
Validation loss: 2.4978459738355814

Epoch: 5| Step: 5
Training loss: 2.4740081032548584
Validation loss: 2.5040334609359727

Epoch: 5| Step: 6
Training loss: 2.521077094364383
Validation loss: 2.493739682130813

Epoch: 5| Step: 7
Training loss: 2.7653651573400166
Validation loss: 2.4857645336497844

Epoch: 5| Step: 8
Training loss: 3.128916917799386
Validation loss: 2.4875519573779217

Epoch: 5| Step: 9
Training loss: 2.5466480739107857
Validation loss: 2.4952231207982334

Epoch: 5| Step: 10
Training loss: 3.048168201371128
Validation loss: 2.499553807751787

Epoch: 184| Step: 0
Training loss: 2.597351974220017
Validation loss: 2.5323127896511877

Epoch: 5| Step: 1
Training loss: 2.666072858817889
Validation loss: 2.554530997661754

Epoch: 5| Step: 2
Training loss: 2.650991193269644
Validation loss: 2.589210486409094

Epoch: 5| Step: 3
Training loss: 2.7392943680715898
Validation loss: 2.6270707220875393

Epoch: 5| Step: 4
Training loss: 3.220560842208496
Validation loss: 2.6517480783042373

Epoch: 5| Step: 5
Training loss: 2.287518706531851
Validation loss: 2.6262304134466006

Epoch: 5| Step: 6
Training loss: 2.6701276095752458
Validation loss: 2.5961223654376093

Epoch: 5| Step: 7
Training loss: 3.234470974147856
Validation loss: 2.5395783769106144

Epoch: 5| Step: 8
Training loss: 2.8595374222781524
Validation loss: 2.516371455036071

Epoch: 5| Step: 9
Training loss: 2.147405091965138
Validation loss: 2.495146549137904

Epoch: 5| Step: 10
Training loss: 3.2232172807106685
Validation loss: 2.4861946719409396

Epoch: 185| Step: 0
Training loss: 2.4109010210324544
Validation loss: 2.492669655164801

Epoch: 5| Step: 1
Training loss: 2.499230361725477
Validation loss: 2.522171721516715

Epoch: 5| Step: 2
Training loss: 2.9232711312415907
Validation loss: 2.5748274640522935

Epoch: 5| Step: 3
Training loss: 3.361514523539616
Validation loss: 2.639382641153367

Epoch: 5| Step: 4
Training loss: 2.9054758004628427
Validation loss: 2.607335600916405

Epoch: 5| Step: 5
Training loss: 2.6045388731403527
Validation loss: 2.6197946203052025

Epoch: 5| Step: 6
Training loss: 2.3521871655918662
Validation loss: 2.629717634237005

Epoch: 5| Step: 7
Training loss: 2.4951283673000515
Validation loss: 2.6814865496926426

Epoch: 5| Step: 8
Training loss: 3.047126798740101
Validation loss: 2.6562531347575984

Epoch: 5| Step: 9
Training loss: 2.8606442828838055
Validation loss: 2.5999359670015796

Epoch: 5| Step: 10
Training loss: 2.9428679746462856
Validation loss: 2.5418698010969796

Epoch: 186| Step: 0
Training loss: 2.7622882951769148
Validation loss: 2.527107212104752

Epoch: 5| Step: 1
Training loss: 2.563797784933759
Validation loss: 2.5300712762893287

Epoch: 5| Step: 2
Training loss: 3.2120786991763057
Validation loss: 2.5608141375970033

Epoch: 5| Step: 3
Training loss: 2.4499853172640793
Validation loss: 2.5564112584549603

Epoch: 5| Step: 4
Training loss: 2.4402714159361576
Validation loss: 2.5843643932043276

Epoch: 5| Step: 5
Training loss: 2.986293954697411
Validation loss: 2.5957150162529916

Epoch: 5| Step: 6
Training loss: 2.9490130826466494
Validation loss: 2.5695925874877883

Epoch: 5| Step: 7
Training loss: 2.349554579707069
Validation loss: 2.5238823505721255

Epoch: 5| Step: 8
Training loss: 2.5803469244263897
Validation loss: 2.5020397151090377

Epoch: 5| Step: 9
Training loss: 3.114234232820736
Validation loss: 2.5122953511663995

Epoch: 5| Step: 10
Training loss: 2.4595551983400656
Validation loss: 2.522884974222994

Epoch: 187| Step: 0
Training loss: 2.5440908555115347
Validation loss: 2.57269564021291

Epoch: 5| Step: 1
Training loss: 2.3935238086415977
Validation loss: 2.615047310875072

Epoch: 5| Step: 2
Training loss: 2.7019466411650104
Validation loss: 2.7195561521799645

Epoch: 5| Step: 3
Training loss: 2.390798325582055
Validation loss: 2.718955632270255

Epoch: 5| Step: 4
Training loss: 2.834556558633861
Validation loss: 2.6373005844348345

Epoch: 5| Step: 5
Training loss: 3.185617526806947
Validation loss: 2.532687586292056

Epoch: 5| Step: 6
Training loss: 2.828879408562853
Validation loss: 2.5023507264377822

Epoch: 5| Step: 7
Training loss: 2.8005785582764644
Validation loss: 2.4958561948838915

Epoch: 5| Step: 8
Training loss: 2.928617154738031
Validation loss: 2.492831782312656

Epoch: 5| Step: 9
Training loss: 2.771864926084428
Validation loss: 2.4998929646867

Epoch: 5| Step: 10
Training loss: 2.8108818485503817
Validation loss: 2.509348125229824

Epoch: 188| Step: 0
Training loss: 2.3599767864831334
Validation loss: 2.5058803701177825

Epoch: 5| Step: 1
Training loss: 2.8311303119750226
Validation loss: 2.50250514554201

Epoch: 5| Step: 2
Training loss: 2.9444980456513683
Validation loss: 2.5059267097571083

Epoch: 5| Step: 3
Training loss: 2.661508896876788
Validation loss: 2.5075563030235895

Epoch: 5| Step: 4
Training loss: 2.138083403984751
Validation loss: 2.5269551932371015

Epoch: 5| Step: 5
Training loss: 2.650483637887522
Validation loss: 2.5381143606682146

Epoch: 5| Step: 6
Training loss: 3.264688896090535
Validation loss: 2.563677720982098

Epoch: 5| Step: 7
Training loss: 2.839857854375222
Validation loss: 2.5695620631737426

Epoch: 5| Step: 8
Training loss: 2.54788188104805
Validation loss: 2.579591703678132

Epoch: 5| Step: 9
Training loss: 2.64594423757488
Validation loss: 2.563557581404987

Epoch: 5| Step: 10
Training loss: 3.0864683829350046
Validation loss: 2.5539121780625593

Epoch: 189| Step: 0
Training loss: 2.2883797626642712
Validation loss: 2.5361624978514774

Epoch: 5| Step: 1
Training loss: 3.2658983326100817
Validation loss: 2.562380990286903

Epoch: 5| Step: 2
Training loss: 2.445405415972578
Validation loss: 2.5692463579420206

Epoch: 5| Step: 3
Training loss: 3.432146099208697
Validation loss: 2.582818908625886

Epoch: 5| Step: 4
Training loss: 2.422965118194907
Validation loss: 2.5772002201347366

Epoch: 5| Step: 5
Training loss: 2.6398260047679694
Validation loss: 2.584859784732914

Epoch: 5| Step: 6
Training loss: 2.70711949852774
Validation loss: 2.5855258264131926

Epoch: 5| Step: 7
Training loss: 2.373468507585522
Validation loss: 2.5676018933440754

Epoch: 5| Step: 8
Training loss: 2.302453772197807
Validation loss: 2.562344213953061

Epoch: 5| Step: 9
Training loss: 2.6528070014378056
Validation loss: 2.540498916800475

Epoch: 5| Step: 10
Training loss: 2.802196448405308
Validation loss: 2.5404798455755646

Epoch: 190| Step: 0
Training loss: 2.5239035350242025
Validation loss: 2.5405194187878135

Epoch: 5| Step: 1
Training loss: 3.0699840107852436
Validation loss: 2.5286091293790873

Epoch: 5| Step: 2
Training loss: 1.9300230406339531
Validation loss: 2.537413575136137

Epoch: 5| Step: 3
Training loss: 2.7574013897996412
Validation loss: 2.5289069010610468

Epoch: 5| Step: 4
Training loss: 2.792794431568409
Validation loss: 2.5221215098109537

Epoch: 5| Step: 5
Training loss: 2.6853461395148983
Validation loss: 2.5277348454287654

Epoch: 5| Step: 6
Training loss: 2.6981072573313702
Validation loss: 2.5342715859349765

Epoch: 5| Step: 7
Training loss: 3.2585211333051514
Validation loss: 2.5348655151853765

Epoch: 5| Step: 8
Training loss: 2.465486711653867
Validation loss: 2.5361900116074034

Epoch: 5| Step: 9
Training loss: 2.5457469103473285
Validation loss: 2.5304564205956717

Epoch: 5| Step: 10
Training loss: 2.358879896346349
Validation loss: 2.527677456002657

Epoch: 191| Step: 0
Training loss: 2.639145114795828
Validation loss: 2.5489352899506645

Epoch: 5| Step: 1
Training loss: 2.7192059715517427
Validation loss: 2.5513550781377416

Epoch: 5| Step: 2
Training loss: 2.5655337727505234
Validation loss: 2.582056043024082

Epoch: 5| Step: 3
Training loss: 2.967999333291609
Validation loss: 2.58838955596174

Epoch: 5| Step: 4
Training loss: 2.6261945458812
Validation loss: 2.588152756048597

Epoch: 5| Step: 5
Training loss: 2.9474170562488773
Validation loss: 2.585539314235379

Epoch: 5| Step: 6
Training loss: 2.1935183976121198
Validation loss: 2.5748607366464458

Epoch: 5| Step: 7
Training loss: 3.136052080996762
Validation loss: 2.5595971109080886

Epoch: 5| Step: 8
Training loss: 2.3243229690394354
Validation loss: 2.547029803204453

Epoch: 5| Step: 9
Training loss: 2.822756228984622
Validation loss: 2.552269491136941

Epoch: 5| Step: 10
Training loss: 2.104239648239454
Validation loss: 2.5686525026992624

Epoch: 192| Step: 0
Training loss: 3.0126965787071893
Validation loss: 2.5854061819972545

Epoch: 5| Step: 1
Training loss: 2.862174742764263
Validation loss: 2.573399746555501

Epoch: 5| Step: 2
Training loss: 3.054620220097071
Validation loss: 2.5844867243943344

Epoch: 5| Step: 3
Training loss: 2.653794533728279
Validation loss: 2.5533331865340454

Epoch: 5| Step: 4
Training loss: 2.503959095794471
Validation loss: 2.5490715268013897

Epoch: 5| Step: 5
Training loss: 2.35427790916276
Validation loss: 2.5479478336115324

Epoch: 5| Step: 6
Training loss: 2.5488990276895893
Validation loss: 2.5531568334178427

Epoch: 5| Step: 7
Training loss: 2.470657866896501
Validation loss: 2.5766633555005205

Epoch: 5| Step: 8
Training loss: 2.3626603248732096
Validation loss: 2.6035487436568974

Epoch: 5| Step: 9
Training loss: 2.856234634324694
Validation loss: 2.639756157512592

Epoch: 5| Step: 10
Training loss: 2.687985398570775
Validation loss: 2.637859599553388

Epoch: 193| Step: 0
Training loss: 2.525005314132084
Validation loss: 2.6563412500448074

Epoch: 5| Step: 1
Training loss: 2.5118100637683085
Validation loss: 2.66000748535597

Epoch: 5| Step: 2
Training loss: 2.0420043302783393
Validation loss: 2.6525749567180696

Epoch: 5| Step: 3
Training loss: 3.3416531842372788
Validation loss: 2.6558270517609572

Epoch: 5| Step: 4
Training loss: 2.246280350604791
Validation loss: 2.654414064722892

Epoch: 5| Step: 5
Training loss: 2.772563098020913
Validation loss: 2.6011963544483887

Epoch: 5| Step: 6
Training loss: 2.445195984425829
Validation loss: 2.584596640263768

Epoch: 5| Step: 7
Training loss: 2.682006366457626
Validation loss: 2.571891931002038

Epoch: 5| Step: 8
Training loss: 2.3101088043284226
Validation loss: 2.544081499144792

Epoch: 5| Step: 9
Training loss: 3.154864016351564
Validation loss: 2.5447562906162546

Epoch: 5| Step: 10
Training loss: 2.8755467765663614
Validation loss: 2.536135477089619

Epoch: 194| Step: 0
Training loss: 2.4446928073923457
Validation loss: 2.5262070268795274

Epoch: 5| Step: 1
Training loss: 1.7576255190266403
Validation loss: 2.5253356339329316

Epoch: 5| Step: 2
Training loss: 2.401533582584014
Validation loss: 2.5154514435036406

Epoch: 5| Step: 3
Training loss: 2.758044181796266
Validation loss: 2.5314281613104708

Epoch: 5| Step: 4
Training loss: 2.7484558278351563
Validation loss: 2.546403411542151

Epoch: 5| Step: 5
Training loss: 2.666955356071199
Validation loss: 2.5385237412005357

Epoch: 5| Step: 6
Training loss: 2.84812875184479
Validation loss: 2.557714719803498

Epoch: 5| Step: 7
Training loss: 2.8738590132523476
Validation loss: 2.577879379967222

Epoch: 5| Step: 8
Training loss: 2.825355142871354
Validation loss: 2.601687252600212

Epoch: 5| Step: 9
Training loss: 2.608902208816662
Validation loss: 2.620925158714012

Epoch: 5| Step: 10
Training loss: 2.734420165642608
Validation loss: 2.6084009004981015

Epoch: 195| Step: 0
Training loss: 2.4049628642302183
Validation loss: 2.6196341697922034

Epoch: 5| Step: 1
Training loss: 2.517981710705377
Validation loss: 2.61950390172126

Epoch: 5| Step: 2
Training loss: 2.7241475688101136
Validation loss: 2.630800540955428

Epoch: 5| Step: 3
Training loss: 2.821883590871042
Validation loss: 2.6567452226657013

Epoch: 5| Step: 4
Training loss: 2.6223889034802204
Validation loss: 2.6372855892412246

Epoch: 5| Step: 5
Training loss: 2.5284527994027046
Validation loss: 2.647235084013527

Epoch: 5| Step: 6
Training loss: 2.4100793860248957
Validation loss: 2.6578562185264074

Epoch: 5| Step: 7
Training loss: 1.5961960366252814
Validation loss: 2.6387611447473454

Epoch: 5| Step: 8
Training loss: 3.1429982494285045
Validation loss: 2.6322322067317843

Epoch: 5| Step: 9
Training loss: 2.576789741373234
Validation loss: 2.6080413017457658

Epoch: 5| Step: 10
Training loss: 3.109205538478499
Validation loss: 2.5973034429368864

Epoch: 196| Step: 0
Training loss: 2.8970414164291576
Validation loss: 2.545180400623696

Epoch: 5| Step: 1
Training loss: 2.58558149854891
Validation loss: 2.54716717410388

Epoch: 5| Step: 2
Training loss: 2.654265436543488
Validation loss: 2.526994477084058

Epoch: 5| Step: 3
Training loss: 2.8311394069873836
Validation loss: 2.5106802272566453

Epoch: 5| Step: 4
Training loss: 2.3920373671429354
Validation loss: 2.5102145774425897

Epoch: 5| Step: 5
Training loss: 2.73275394889526
Validation loss: 2.5055838358847966

Epoch: 5| Step: 6
Training loss: 2.7406705045673974
Validation loss: 2.509353609366423

Epoch: 5| Step: 7
Training loss: 3.3145604473085575
Validation loss: 2.508405459237158

Epoch: 5| Step: 8
Training loss: 2.347836200336045
Validation loss: 2.5307282629582257

Epoch: 5| Step: 9
Training loss: 1.9199664556036677
Validation loss: 2.544737425582828

Epoch: 5| Step: 10
Training loss: 1.8427534481353234
Validation loss: 2.5610332478097035

Epoch: 197| Step: 0
Training loss: 2.2087242452245754
Validation loss: 2.5828824951544886

Epoch: 5| Step: 1
Training loss: 2.7830138024972384
Validation loss: 2.600949266720463

Epoch: 5| Step: 2
Training loss: 2.4640585832195803
Validation loss: 2.6560549833936173

Epoch: 5| Step: 3
Training loss: 2.4684759060288637
Validation loss: 2.683661950004799

Epoch: 5| Step: 4
Training loss: 2.4624762674340195
Validation loss: 2.7177357359395207

Epoch: 5| Step: 5
Training loss: 2.9761993106529268
Validation loss: 2.7325440711176783

Epoch: 5| Step: 6
Training loss: 2.2543749131936908
Validation loss: 2.6879626498552414

Epoch: 5| Step: 7
Training loss: 2.3297642818618596
Validation loss: 2.62733475962333

Epoch: 5| Step: 8
Training loss: 3.1124225039964912
Validation loss: 2.6041149805333674

Epoch: 5| Step: 9
Training loss: 2.597667447403028
Validation loss: 2.584646828517929

Epoch: 5| Step: 10
Training loss: 2.6543186122293325
Validation loss: 2.5940163954067876

Epoch: 198| Step: 0
Training loss: 2.484771408988267
Validation loss: 2.5720737792583774

Epoch: 5| Step: 1
Training loss: 2.7635209867986017
Validation loss: 2.557341378631883

Epoch: 5| Step: 2
Training loss: 2.6538592181952683
Validation loss: 2.5768190100847304

Epoch: 5| Step: 3
Training loss: 2.441484178443782
Validation loss: 2.5719480966129873

Epoch: 5| Step: 4
Training loss: 2.5712571654639502
Validation loss: 2.5764603855077777

Epoch: 5| Step: 5
Training loss: 2.5603146422265577
Validation loss: 2.6123509400974547

Epoch: 5| Step: 6
Training loss: 2.477056700678542
Validation loss: 2.5914492978471126

Epoch: 5| Step: 7
Training loss: 2.7007006760358556
Validation loss: 2.602826019408369

Epoch: 5| Step: 8
Training loss: 2.127385091222316
Validation loss: 2.608484866112919

Epoch: 5| Step: 9
Training loss: 2.643941388067746
Validation loss: 2.6109118210646587

Epoch: 5| Step: 10
Training loss: 2.851110636822661
Validation loss: 2.622909453726148

Epoch: 199| Step: 0
Training loss: 2.2868594872760934
Validation loss: 2.6146955777741314

Epoch: 5| Step: 1
Training loss: 2.4533622286829506
Validation loss: 2.6320069876942536

Epoch: 5| Step: 2
Training loss: 2.797007467020574
Validation loss: 2.6043293649035517

Epoch: 5| Step: 3
Training loss: 2.4788426633626894
Validation loss: 2.60703757714284

Epoch: 5| Step: 4
Training loss: 2.5817593937822347
Validation loss: 2.610800242542287

Epoch: 5| Step: 5
Training loss: 2.561747929068628
Validation loss: 2.642928248868428

Epoch: 5| Step: 6
Training loss: 2.772015790148483
Validation loss: 2.659056053962941

Epoch: 5| Step: 7
Training loss: 2.600059647976305
Validation loss: 2.663183250806061

Epoch: 5| Step: 8
Training loss: 2.5020019145320944
Validation loss: 2.6700382056242535

Epoch: 5| Step: 9
Training loss: 2.268598827863725
Validation loss: 2.6415584521341002

Epoch: 5| Step: 10
Training loss: 2.6372981134318754
Validation loss: 2.620646862142717

Epoch: 200| Step: 0
Training loss: 2.145096612279546
Validation loss: 2.625343313976278

Epoch: 5| Step: 1
Training loss: 2.478114174510117
Validation loss: 2.6219955132102672

Epoch: 5| Step: 2
Training loss: 2.876917489861195
Validation loss: 2.617526186469962

Epoch: 5| Step: 3
Training loss: 2.8184696844750143
Validation loss: 2.629077040301404

Epoch: 5| Step: 4
Training loss: 2.341533579274201
Validation loss: 2.6259413084730854

Epoch: 5| Step: 5
Training loss: 2.413610125874036
Validation loss: 2.6220914829035253

Epoch: 5| Step: 6
Training loss: 2.7237979022326586
Validation loss: 2.6315663096799646

Epoch: 5| Step: 7
Training loss: 2.4228950567312273
Validation loss: 2.642488616023344

Epoch: 5| Step: 8
Training loss: 2.6683855080333543
Validation loss: 2.619359336801479

Epoch: 5| Step: 9
Training loss: 2.3387142760557253
Validation loss: 2.623084229135131

Epoch: 5| Step: 10
Training loss: 2.489062894640339
Validation loss: 2.5928253757558473

Epoch: 201| Step: 0
Training loss: 2.604124623277148
Validation loss: 2.5936097335595485

Epoch: 5| Step: 1
Training loss: 2.2561884652408883
Validation loss: 2.590418918647719

Epoch: 5| Step: 2
Training loss: 2.7775825580238265
Validation loss: 2.590219115883918

Epoch: 5| Step: 3
Training loss: 2.9827374664189104
Validation loss: 2.5812487400143924

Epoch: 5| Step: 4
Training loss: 2.931564014915479
Validation loss: 2.579275823634962

Epoch: 5| Step: 5
Training loss: 2.1115353294703167
Validation loss: 2.592819646966554

Epoch: 5| Step: 6
Training loss: 2.1926738044635736
Validation loss: 2.6341706527178035

Epoch: 5| Step: 7
Training loss: 2.3147393802078264
Validation loss: 2.674534756002597

Epoch: 5| Step: 8
Training loss: 2.7827204556800975
Validation loss: 2.7118350491801784

Epoch: 5| Step: 9
Training loss: 2.123361741399441
Validation loss: 2.7194668205927446

Epoch: 5| Step: 10
Training loss: 2.494379209908202
Validation loss: 2.679383374631094

Epoch: 202| Step: 0
Training loss: 2.6067090149420826
Validation loss: 2.624483161162304

Epoch: 5| Step: 1
Training loss: 2.736176600266858
Validation loss: 2.580489615590281

Epoch: 5| Step: 2
Training loss: 2.258214894903973
Validation loss: 2.5641649881262687

Epoch: 5| Step: 3
Training loss: 2.142552531253815
Validation loss: 2.5820531249835903

Epoch: 5| Step: 4
Training loss: 2.618286539732481
Validation loss: 2.5992360615327086

Epoch: 5| Step: 5
Training loss: 2.7866608352995583
Validation loss: 2.618829075766279

Epoch: 5| Step: 6
Training loss: 2.1338364375461647
Validation loss: 2.6239918942607656

Epoch: 5| Step: 7
Training loss: 2.7398310695558163
Validation loss: 2.640892518641326

Epoch: 5| Step: 8
Training loss: 1.9628533962382166
Validation loss: 2.6092199297045533

Epoch: 5| Step: 9
Training loss: 2.628412118076458
Validation loss: 2.6182197005871917

Epoch: 5| Step: 10
Training loss: 3.1440367126165625
Validation loss: 2.631924726100448

Epoch: 203| Step: 0
Training loss: 2.5311146452706685
Validation loss: 2.6408515469413274

Epoch: 5| Step: 1
Training loss: 2.3179896380412597
Validation loss: 2.6451894851858166

Epoch: 5| Step: 2
Training loss: 1.6525980435833136
Validation loss: 2.634852715309462

Epoch: 5| Step: 3
Training loss: 2.986904649988439
Validation loss: 2.6137186334889777

Epoch: 5| Step: 4
Training loss: 2.797907462901422
Validation loss: 2.5908351402535135

Epoch: 5| Step: 5
Training loss: 2.4767305816508327
Validation loss: 2.557401963782971

Epoch: 5| Step: 6
Training loss: 2.5914848272021853
Validation loss: 2.5758097276205687

Epoch: 5| Step: 7
Training loss: 2.8893499088043684
Validation loss: 2.5690495836619305

Epoch: 5| Step: 8
Training loss: 2.6108900229099956
Validation loss: 2.55208177564388

Epoch: 5| Step: 9
Training loss: 1.9800079832975723
Validation loss: 2.5747046171696564

Epoch: 5| Step: 10
Training loss: 2.596434158016348
Validation loss: 2.5820308240555336

Epoch: 204| Step: 0
Training loss: 1.96357592106764
Validation loss: 2.597613648897911

Epoch: 5| Step: 1
Training loss: 2.445153959454703
Validation loss: 2.602705172708349

Epoch: 5| Step: 2
Training loss: 1.8646254579129609
Validation loss: 2.647555490276902

Epoch: 5| Step: 3
Training loss: 2.24779762987585
Validation loss: 2.6687369747621625

Epoch: 5| Step: 4
Training loss: 3.1517829632563763
Validation loss: 2.691135881263374

Epoch: 5| Step: 5
Training loss: 2.3662374371388086
Validation loss: 2.707134034930039

Epoch: 5| Step: 6
Training loss: 2.2778912208447233
Validation loss: 2.7006521480315437

Epoch: 5| Step: 7
Training loss: 2.50544384479188
Validation loss: 2.6632098777792894

Epoch: 5| Step: 8
Training loss: 2.43530477805757
Validation loss: 2.6377907061343024

Epoch: 5| Step: 9
Training loss: 2.5367543219494473
Validation loss: 2.6069679301707547

Epoch: 5| Step: 10
Training loss: 3.1723946582568847
Validation loss: 2.5763879536873566

Epoch: 205| Step: 0
Training loss: 2.52383344159956
Validation loss: 2.5583397844537936

Epoch: 5| Step: 1
Training loss: 2.4482512441558155
Validation loss: 2.5384315654651552

Epoch: 5| Step: 2
Training loss: 2.0612656338609496
Validation loss: 2.536524830878237

Epoch: 5| Step: 3
Training loss: 2.1576430754888154
Validation loss: 2.554723786468316

Epoch: 5| Step: 4
Training loss: 2.66965450351761
Validation loss: 2.5519729667407276

Epoch: 5| Step: 5
Training loss: 2.5255346884058647
Validation loss: 2.55724752931195

Epoch: 5| Step: 6
Training loss: 2.373558108672581
Validation loss: 2.5577893251700012

Epoch: 5| Step: 7
Training loss: 2.411392167064521
Validation loss: 2.56754503956235

Epoch: 5| Step: 8
Training loss: 2.744266862782528
Validation loss: 2.610000215163501

Epoch: 5| Step: 9
Training loss: 2.673344258343958
Validation loss: 2.6409445249725594

Epoch: 5| Step: 10
Training loss: 1.8331802116374794
Validation loss: 2.6504995256425965

Epoch: 206| Step: 0
Training loss: 2.3491974657450028
Validation loss: 2.6356793723849496

Epoch: 5| Step: 1
Training loss: 2.235957299017534
Validation loss: 2.6550928557165285

Epoch: 5| Step: 2
Training loss: 3.0461096169077324
Validation loss: 2.6188961656203116

Epoch: 5| Step: 3
Training loss: 2.3533549526975803
Validation loss: 2.595594438003476

Epoch: 5| Step: 4
Training loss: 2.3476387823029445
Validation loss: 2.5939720464992426

Epoch: 5| Step: 5
Training loss: 2.3063654594155834
Validation loss: 2.588545472035054

Epoch: 5| Step: 6
Training loss: 2.168632227093649
Validation loss: 2.5890515442769755

Epoch: 5| Step: 7
Training loss: 2.1997888073555045
Validation loss: 2.6074660354579504

Epoch: 5| Step: 8
Training loss: 2.48735750259862
Validation loss: 2.608151617767171

Epoch: 5| Step: 9
Training loss: 2.6940336427690696
Validation loss: 2.5971663898977684

Epoch: 5| Step: 10
Training loss: 1.9857624640113838
Validation loss: 2.612985575688068

Epoch: 207| Step: 0
Training loss: 2.108729171785743
Validation loss: 2.628322441232018

Epoch: 5| Step: 1
Training loss: 2.205293926967852
Validation loss: 2.613438694515522

Epoch: 5| Step: 2
Training loss: 2.5174223361115375
Validation loss: 2.6265270422675613

Epoch: 5| Step: 3
Training loss: 2.264961513840729
Validation loss: 2.639412192885832

Epoch: 5| Step: 4
Training loss: 2.3002873199788687
Validation loss: 2.6562922339848867

Epoch: 5| Step: 5
Training loss: 2.2901227663274026
Validation loss: 2.668941574058341

Epoch: 5| Step: 6
Training loss: 1.8598492442327668
Validation loss: 2.6687382331733405

Epoch: 5| Step: 7
Training loss: 2.513444796889177
Validation loss: 2.6799611377898236

Epoch: 5| Step: 8
Training loss: 2.0910065170252206
Validation loss: 2.6718534036840706

Epoch: 5| Step: 9
Training loss: 3.0332691507221474
Validation loss: 2.6511092645258056

Epoch: 5| Step: 10
Training loss: 2.784793867636057
Validation loss: 2.6325179486307086

Epoch: 208| Step: 0
Training loss: 2.2150923977905554
Validation loss: 2.6281981462374624

Epoch: 5| Step: 1
Training loss: 2.540996296345107
Validation loss: 2.605204587441038

Epoch: 5| Step: 2
Training loss: 2.1971397533391284
Validation loss: 2.6289628465308272

Epoch: 5| Step: 3
Training loss: 2.025032033784652
Validation loss: 2.628992336938179

Epoch: 5| Step: 4
Training loss: 2.468805433206272
Validation loss: 2.675881780549232

Epoch: 5| Step: 5
Training loss: 2.3277354074454415
Validation loss: 2.694353779829664

Epoch: 5| Step: 6
Training loss: 2.6410894041979716
Validation loss: 2.7092402552837243

Epoch: 5| Step: 7
Training loss: 2.2695045666595117
Validation loss: 2.7224875824388395

Epoch: 5| Step: 8
Training loss: 2.710270956366058
Validation loss: 2.6832031313441242

Epoch: 5| Step: 9
Training loss: 2.229509404534102
Validation loss: 2.6368452236723825

Epoch: 5| Step: 10
Training loss: 2.1174334281175797
Validation loss: 2.6425772062880495

Epoch: 209| Step: 0
Training loss: 2.463085678084843
Validation loss: 2.639392825247097

Epoch: 5| Step: 1
Training loss: 2.5048191352469087
Validation loss: 2.61025095367338

Epoch: 5| Step: 2
Training loss: 2.5141171503380226
Validation loss: 2.6207597611846296

Epoch: 5| Step: 3
Training loss: 2.6992778412772553
Validation loss: 2.5791689472273553

Epoch: 5| Step: 4
Training loss: 2.60108828876486
Validation loss: 2.5340028876479432

Epoch: 5| Step: 5
Training loss: 2.5882480590423937
Validation loss: 2.5094604659073863

Epoch: 5| Step: 6
Training loss: 2.1103187992742503
Validation loss: 2.5119648770413154

Epoch: 5| Step: 7
Training loss: 2.145585264909741
Validation loss: 2.517954249468472

Epoch: 5| Step: 8
Training loss: 2.1610221575898945
Validation loss: 2.5516124536208893

Epoch: 5| Step: 9
Training loss: 1.680871023128432
Validation loss: 2.610939695926196

Epoch: 5| Step: 10
Training loss: 2.4265040305241916
Validation loss: 2.715960770931849

Epoch: 210| Step: 0
Training loss: 2.707886487827182
Validation loss: 2.7160398237460455

Epoch: 5| Step: 1
Training loss: 2.4319823978565074
Validation loss: 2.6607953312921113

Epoch: 5| Step: 2
Training loss: 2.062504739466915
Validation loss: 2.6311650314565997

Epoch: 5| Step: 3
Training loss: 2.1057058565326354
Validation loss: 2.6073223349879857

Epoch: 5| Step: 4
Training loss: 2.6890855592030456
Validation loss: 2.618569885351811

Epoch: 5| Step: 5
Training loss: 2.1945987504985274
Validation loss: 2.670925615289413

Epoch: 5| Step: 6
Training loss: 2.742346517185347
Validation loss: 2.6784232388555007

Epoch: 5| Step: 7
Training loss: 2.2089066630892837
Validation loss: 2.70084683762531

Epoch: 5| Step: 8
Training loss: 2.042545077738135
Validation loss: 2.7160145321173808

Epoch: 5| Step: 9
Training loss: 2.2427954298211987
Validation loss: 2.6948741012371307

Epoch: 5| Step: 10
Training loss: 2.342956510373843
Validation loss: 2.678408655747615

Epoch: 211| Step: 0
Training loss: 2.796001702898896
Validation loss: 2.662298157947479

Epoch: 5| Step: 1
Training loss: 2.6475381139906107
Validation loss: 2.634815062930038

Epoch: 5| Step: 2
Training loss: 2.3447761832265077
Validation loss: 2.6159898790192124

Epoch: 5| Step: 3
Training loss: 2.3380605178584357
Validation loss: 2.569877040298564

Epoch: 5| Step: 4
Training loss: 2.3155051628949805
Validation loss: 2.554806780795583

Epoch: 5| Step: 5
Training loss: 2.308584248737851
Validation loss: 2.5492635478611483

Epoch: 5| Step: 6
Training loss: 2.187361140612233
Validation loss: 2.5264605187690625

Epoch: 5| Step: 7
Training loss: 2.255404656889934
Validation loss: 2.522457792987848

Epoch: 5| Step: 8
Training loss: 2.032522184619208
Validation loss: 2.54859740654531

Epoch: 5| Step: 9
Training loss: 1.9448517403078736
Validation loss: 2.5997364460019075

Epoch: 5| Step: 10
Training loss: 2.062318967330285
Validation loss: 2.6151969018795684

Epoch: 212| Step: 0
Training loss: 2.364814702168447
Validation loss: 2.6809933550175513

Epoch: 5| Step: 1
Training loss: 2.623094321110823
Validation loss: 2.725374877483287

Epoch: 5| Step: 2
Training loss: 2.3468970977108587
Validation loss: 2.7150848704172135

Epoch: 5| Step: 3
Training loss: 1.8324865495258391
Validation loss: 2.7280094768553345

Epoch: 5| Step: 4
Training loss: 2.4184343077779884
Validation loss: 2.6945836890665107

Epoch: 5| Step: 5
Training loss: 2.062521963291557
Validation loss: 2.6882982110799576

Epoch: 5| Step: 6
Training loss: 2.346341036055246
Validation loss: 2.6736239849864325

Epoch: 5| Step: 7
Training loss: 2.3130999637414598
Validation loss: 2.656000204483444

Epoch: 5| Step: 8
Training loss: 2.498718410061354
Validation loss: 2.6454928609194552

Epoch: 5| Step: 9
Training loss: 2.1219700922606637
Validation loss: 2.6435972523122295

Epoch: 5| Step: 10
Training loss: 2.1577452851474783
Validation loss: 2.634652792901838

Epoch: 213| Step: 0
Training loss: 2.155727157229322
Validation loss: 2.640342657988729

Epoch: 5| Step: 1
Training loss: 1.8404560082776094
Validation loss: 2.642416940977254

Epoch: 5| Step: 2
Training loss: 2.279977626523451
Validation loss: 2.654372157724066

Epoch: 5| Step: 3
Training loss: 2.3753947883548143
Validation loss: 2.6683867781392303

Epoch: 5| Step: 4
Training loss: 2.031331926307571
Validation loss: 2.6785286510389787

Epoch: 5| Step: 5
Training loss: 2.5625466133157966
Validation loss: 2.6980616016316485

Epoch: 5| Step: 6
Training loss: 2.010806215590581
Validation loss: 2.6911424705555347

Epoch: 5| Step: 7
Training loss: 2.052984772281501
Validation loss: 2.6754191841764605

Epoch: 5| Step: 8
Training loss: 2.2332839969860188
Validation loss: 2.6794135902827785

Epoch: 5| Step: 9
Training loss: 2.8096751119607632
Validation loss: 2.6485010995457183

Epoch: 5| Step: 10
Training loss: 2.3796668128794467
Validation loss: 2.6278260561934066

Epoch: 214| Step: 0
Training loss: 1.987692155485972
Validation loss: 2.627479540429294

Epoch: 5| Step: 1
Training loss: 2.5167079513734016
Validation loss: 2.599799480704486

Epoch: 5| Step: 2
Training loss: 2.224156736387703
Validation loss: 2.607420559466036

Epoch: 5| Step: 3
Training loss: 2.3704641093763796
Validation loss: 2.620399301065339

Epoch: 5| Step: 4
Training loss: 2.3202935934099247
Validation loss: 2.5977923327766375

Epoch: 5| Step: 5
Training loss: 2.2752234925542054
Validation loss: 2.592284344816325

Epoch: 5| Step: 6
Training loss: 2.5550488324360483
Validation loss: 2.6014539720688106

Epoch: 5| Step: 7
Training loss: 2.0895945748064495
Validation loss: 2.595067378217838

Epoch: 5| Step: 8
Training loss: 1.8660098396197211
Validation loss: 2.5928690551333595

Epoch: 5| Step: 9
Training loss: 1.8235142918019607
Validation loss: 2.6012980629651796

Epoch: 5| Step: 10
Training loss: 2.216560250311667
Validation loss: 2.5905413805576654

Epoch: 215| Step: 0
Training loss: 2.184445237325268
Validation loss: 2.611712034963939

Epoch: 5| Step: 1
Training loss: 1.9674081013604128
Validation loss: 2.609432008358913

Epoch: 5| Step: 2
Training loss: 2.2662815589622105
Validation loss: 2.6240323046323444

Epoch: 5| Step: 3
Training loss: 2.490192727133348
Validation loss: 2.6422808472918136

Epoch: 5| Step: 4
Training loss: 2.3013856155575843
Validation loss: 2.6396447410899206

Epoch: 5| Step: 5
Training loss: 2.0738147981624677
Validation loss: 2.665122637535141

Epoch: 5| Step: 6
Training loss: 2.179125969861126
Validation loss: 2.670035718831247

Epoch: 5| Step: 7
Training loss: 1.72642440588867
Validation loss: 2.6937697722848033

Epoch: 5| Step: 8
Training loss: 2.1415397749936
Validation loss: 2.7105192168090504

Epoch: 5| Step: 9
Training loss: 2.5924338253039982
Validation loss: 2.681639293295722

Epoch: 5| Step: 10
Training loss: 2.091103888661453
Validation loss: 2.6605802935913054

Epoch: 216| Step: 0
Training loss: 2.1150752154744423
Validation loss: 2.6243766712605723

Epoch: 5| Step: 1
Training loss: 2.298680743967985
Validation loss: 2.601750518893717

Epoch: 5| Step: 2
Training loss: 2.525560271545936
Validation loss: 2.5824526106860195

Epoch: 5| Step: 3
Training loss: 2.2420147021761854
Validation loss: 2.569310324273574

Epoch: 5| Step: 4
Training loss: 1.8861996902218021
Validation loss: 2.6038084698512827

Epoch: 5| Step: 5
Training loss: 2.08651416822569
Validation loss: 2.581538358440421

Epoch: 5| Step: 6
Training loss: 2.437574532176309
Validation loss: 2.5925964511354147

Epoch: 5| Step: 7
Training loss: 1.8541005440683762
Validation loss: 2.5952039474276924

Epoch: 5| Step: 8
Training loss: 2.372655916386676
Validation loss: 2.57857164657441

Epoch: 5| Step: 9
Training loss: 2.450561836594197
Validation loss: 2.6044515684419256

Epoch: 5| Step: 10
Training loss: 1.9173591717228915
Validation loss: 2.63995172361693

Epoch: 217| Step: 0
Training loss: 2.3731800936757925
Validation loss: 2.666853555608739

Epoch: 5| Step: 1
Training loss: 2.0157695393155253
Validation loss: 2.6364688688344424

Epoch: 5| Step: 2
Training loss: 1.4836652966483503
Validation loss: 2.648490801409255

Epoch: 5| Step: 3
Training loss: 2.6509838185372314
Validation loss: 2.654880490578146

Epoch: 5| Step: 4
Training loss: 2.179602180369815
Validation loss: 2.6856186852721957

Epoch: 5| Step: 5
Training loss: 2.458858714025088
Validation loss: 2.68266576843652

Epoch: 5| Step: 6
Training loss: 2.256050240505097
Validation loss: 2.693289709107464

Epoch: 5| Step: 7
Training loss: 2.019444122500994
Validation loss: 2.6555316047682775

Epoch: 5| Step: 8
Training loss: 2.044693694550583
Validation loss: 2.6577918242522007

Epoch: 5| Step: 9
Training loss: 1.6314609902687085
Validation loss: 2.636536051422537

Epoch: 5| Step: 10
Training loss: 2.4758262141470007
Validation loss: 2.6088805304605915

Epoch: 218| Step: 0
Training loss: 1.8920101419705275
Validation loss: 2.587783074089562

Epoch: 5| Step: 1
Training loss: 2.238518560854486
Validation loss: 2.5838645788420016

Epoch: 5| Step: 2
Training loss: 1.9708023273160837
Validation loss: 2.5739267771144685

Epoch: 5| Step: 3
Training loss: 2.281105454973576
Validation loss: 2.5680404551795837

Epoch: 5| Step: 4
Training loss: 1.9504690804298253
Validation loss: 2.575172151783877

Epoch: 5| Step: 5
Training loss: 2.074558381114895
Validation loss: 2.614032516894496

Epoch: 5| Step: 6
Training loss: 2.2677886102918055
Validation loss: 2.6454821896120277

Epoch: 5| Step: 7
Training loss: 2.092815361368457
Validation loss: 2.68988584827687

Epoch: 5| Step: 8
Training loss: 2.4656949999098767
Validation loss: 2.734078078314403

Epoch: 5| Step: 9
Training loss: 2.3625978600957573
Validation loss: 2.734146945894988

Epoch: 5| Step: 10
Training loss: 2.2998387943662535
Validation loss: 2.6992722785825065

Epoch: 219| Step: 0
Training loss: 1.9107733667709985
Validation loss: 2.6639797597321513

Epoch: 5| Step: 1
Training loss: 2.327785697636248
Validation loss: 2.6271851835060103

Epoch: 5| Step: 2
Training loss: 2.505421862685399
Validation loss: 2.5924716462441424

Epoch: 5| Step: 3
Training loss: 1.5626737879427022
Validation loss: 2.5944905385893113

Epoch: 5| Step: 4
Training loss: 1.6564792978160088
Validation loss: 2.585033850091701

Epoch: 5| Step: 5
Training loss: 2.2625367261740474
Validation loss: 2.593798824107264

Epoch: 5| Step: 6
Training loss: 2.1860466625122967
Validation loss: 2.5984376775500673

Epoch: 5| Step: 7
Training loss: 1.9624575616414988
Validation loss: 2.601936679754268

Epoch: 5| Step: 8
Training loss: 2.4222513214117174
Validation loss: 2.6337345213200916

Epoch: 5| Step: 9
Training loss: 2.3809257667053125
Validation loss: 2.6447213681479864

Epoch: 5| Step: 10
Training loss: 2.189658816337402
Validation loss: 2.661851154186654

Epoch: 220| Step: 0
Training loss: 2.577967136058167
Validation loss: 2.660015126129118

Epoch: 5| Step: 1
Training loss: 2.6961178668260866
Validation loss: 2.66337714483705

Epoch: 5| Step: 2
Training loss: 2.112895824660823
Validation loss: 2.637260699617338

Epoch: 5| Step: 3
Training loss: 1.8256905150811569
Validation loss: 2.6065264445676943

Epoch: 5| Step: 4
Training loss: 2.290291934499433
Validation loss: 2.5617361293298604

Epoch: 5| Step: 5
Training loss: 2.0429066635821616
Validation loss: 2.551423813612538

Epoch: 5| Step: 6
Training loss: 1.7765664213836794
Validation loss: 2.527387876376302

Epoch: 5| Step: 7
Training loss: 1.9254872560002596
Validation loss: 2.502855393015972

Epoch: 5| Step: 8
Training loss: 2.026326006735167
Validation loss: 2.5306224817419842

Epoch: 5| Step: 9
Training loss: 1.0508687149573204
Validation loss: 2.5504337563990136

Epoch: 5| Step: 10
Training loss: 2.519776419606205
Validation loss: 2.589391959961832

Epoch: 221| Step: 0
Training loss: 1.6588168137525416
Validation loss: 2.6182152072450293

Epoch: 5| Step: 1
Training loss: 1.8591838065189035
Validation loss: 2.6431588054081523

Epoch: 5| Step: 2
Training loss: 2.097615900486288
Validation loss: 2.6803800540062617

Epoch: 5| Step: 3
Training loss: 2.0976786408037404
Validation loss: 2.6726821460327743

Epoch: 5| Step: 4
Training loss: 1.9938937192196833
Validation loss: 2.681745046529148

Epoch: 5| Step: 5
Training loss: 2.2248928301429123
Validation loss: 2.705564903920082

Epoch: 5| Step: 6
Training loss: 1.8488163924917915
Validation loss: 2.69670237735891

Epoch: 5| Step: 7
Training loss: 2.1686599316981505
Validation loss: 2.6821278094428243

Epoch: 5| Step: 8
Training loss: 2.084071664313838
Validation loss: 2.688875836830233

Epoch: 5| Step: 9
Training loss: 2.3175774583762525
Validation loss: 2.702370547755222

Epoch: 5| Step: 10
Training loss: 2.483436935192412
Validation loss: 2.676353097075245

Epoch: 222| Step: 0
Training loss: 1.7889165693843907
Validation loss: 2.6724802984420495

Epoch: 5| Step: 1
Training loss: 1.870076263218997
Validation loss: 2.646765429356082

Epoch: 5| Step: 2
Training loss: 2.3616528157662797
Validation loss: 2.6344729959249404

Epoch: 5| Step: 3
Training loss: 1.982464990006061
Validation loss: 2.628273586395985

Epoch: 5| Step: 4
Training loss: 1.688753721965808
Validation loss: 2.604699662987587

Epoch: 5| Step: 5
Training loss: 2.511358588279129
Validation loss: 2.588239715119002

Epoch: 5| Step: 6
Training loss: 2.1823887647879348
Validation loss: 2.5929836164443905

Epoch: 5| Step: 7
Training loss: 2.2251877137627543
Validation loss: 2.5784691047420014

Epoch: 5| Step: 8
Training loss: 2.372690483300997
Validation loss: 2.5945128440762955

Epoch: 5| Step: 9
Training loss: 1.7552933337479522
Validation loss: 2.625321263598336

Epoch: 5| Step: 10
Training loss: 1.9024590490598239
Validation loss: 2.667945198333843

Epoch: 223| Step: 0
Training loss: 1.8263456374132976
Validation loss: 2.6933564585681147

Epoch: 5| Step: 1
Training loss: 2.496784717517444
Validation loss: 2.726366823937056

Epoch: 5| Step: 2
Training loss: 1.8101014018238435
Validation loss: 2.686790487120729

Epoch: 5| Step: 3
Training loss: 1.9065697823876067
Validation loss: 2.6297098849603633

Epoch: 5| Step: 4
Training loss: 1.6935162147126401
Validation loss: 2.5909308541559093

Epoch: 5| Step: 5
Training loss: 2.103664552309854
Validation loss: 2.562040439337953

Epoch: 5| Step: 6
Training loss: 2.233517568969628
Validation loss: 2.5649014077328944

Epoch: 5| Step: 7
Training loss: 2.1993910076646097
Validation loss: 2.5699964535285207

Epoch: 5| Step: 8
Training loss: 2.38469064205674
Validation loss: 2.578553652312424

Epoch: 5| Step: 9
Training loss: 2.2069908475975595
Validation loss: 2.568165446617414

Epoch: 5| Step: 10
Training loss: 1.71848704320592
Validation loss: 2.601550263968526

Epoch: 224| Step: 0
Training loss: 2.46245612865425
Validation loss: 2.639817957889636

Epoch: 5| Step: 1
Training loss: 1.9267740843482635
Validation loss: 2.630479777943588

Epoch: 5| Step: 2
Training loss: 2.2119332487440517
Validation loss: 2.655502958406567

Epoch: 5| Step: 3
Training loss: 2.0390767648716785
Validation loss: 2.6911638692110404

Epoch: 5| Step: 4
Training loss: 2.0426326205318803
Validation loss: 2.6993662207680593

Epoch: 5| Step: 5
Training loss: 2.158196165323903
Validation loss: 2.6843243051280035

Epoch: 5| Step: 6
Training loss: 2.2578298178671914
Validation loss: 2.677194338227589

Epoch: 5| Step: 7
Training loss: 1.9230138614291836
Validation loss: 2.6783831868043837

Epoch: 5| Step: 8
Training loss: 1.7073720770708292
Validation loss: 2.6624309492518705

Epoch: 5| Step: 9
Training loss: 1.8786527656982148
Validation loss: 2.69646159735955

Epoch: 5| Step: 10
Training loss: 1.9569669244667962
Validation loss: 2.6804062729511906

Epoch: 225| Step: 0
Training loss: 1.8519714161456984
Validation loss: 2.6761126828035153

Epoch: 5| Step: 1
Training loss: 1.9736117928587509
Validation loss: 2.6853921832356757

Epoch: 5| Step: 2
Training loss: 1.602870797569527
Validation loss: 2.703848292556351

Epoch: 5| Step: 3
Training loss: 1.8034469502184414
Validation loss: 2.696377625523858

Epoch: 5| Step: 4
Training loss: 1.6804888565797225
Validation loss: 2.686830124738258

Epoch: 5| Step: 5
Training loss: 2.362221220007694
Validation loss: 2.6862118393739194

Epoch: 5| Step: 6
Training loss: 2.623046420531187
Validation loss: 2.6620344305023216

Epoch: 5| Step: 7
Training loss: 1.8475249487775776
Validation loss: 2.6106475552634665

Epoch: 5| Step: 8
Training loss: 1.7861994193345556
Validation loss: 2.611473805980107

Epoch: 5| Step: 9
Training loss: 2.062571437638893
Validation loss: 2.5620193560913296

Epoch: 5| Step: 10
Training loss: 2.397114739992784
Validation loss: 2.5741926351224054

Epoch: 226| Step: 0
Training loss: 2.1110646580164065
Validation loss: 2.5558916485146663

Epoch: 5| Step: 1
Training loss: 2.186164448254525
Validation loss: 2.5673699252792392

Epoch: 5| Step: 2
Training loss: 1.7567836887293768
Validation loss: 2.560663687305945

Epoch: 5| Step: 3
Training loss: 1.689396534231033
Validation loss: 2.5909472327517493

Epoch: 5| Step: 4
Training loss: 1.9039196090636548
Validation loss: 2.606659685192206

Epoch: 5| Step: 5
Training loss: 2.045352165472842
Validation loss: 2.627501222420065

Epoch: 5| Step: 6
Training loss: 1.7296695973642315
Validation loss: 2.6551901993492164

Epoch: 5| Step: 7
Training loss: 2.1132855371230774
Validation loss: 2.645471063768828

Epoch: 5| Step: 8
Training loss: 2.080595569992593
Validation loss: 2.6556449176832597

Epoch: 5| Step: 9
Training loss: 2.4079704574470986
Validation loss: 2.6530733574334677

Epoch: 5| Step: 10
Training loss: 2.120885231067583
Validation loss: 2.645787421239871

Epoch: 227| Step: 0
Training loss: 2.242034800576715
Validation loss: 2.656422556725893

Epoch: 5| Step: 1
Training loss: 2.209664777127203
Validation loss: 2.6486247205200075

Epoch: 5| Step: 2
Training loss: 2.4099773915603504
Validation loss: 2.6456454446665254

Epoch: 5| Step: 3
Training loss: 1.5193992890864843
Validation loss: 2.6216443162760488

Epoch: 5| Step: 4
Training loss: 1.6681554899720095
Validation loss: 2.6421677888889494

Epoch: 5| Step: 5
Training loss: 2.147971140790183
Validation loss: 2.6517332469854953

Epoch: 5| Step: 6
Training loss: 1.5031558059422403
Validation loss: 2.654597195388452

Epoch: 5| Step: 7
Training loss: 1.939637819775245
Validation loss: 2.66090368760578

Epoch: 5| Step: 8
Training loss: 1.9339997452949742
Validation loss: 2.671451199410802

Epoch: 5| Step: 9
Training loss: 2.25851186724626
Validation loss: 2.673833350402366

Epoch: 5| Step: 10
Training loss: 1.764628171144692
Validation loss: 2.685694418753674

Epoch: 228| Step: 0
Training loss: 1.9028608492733745
Validation loss: 2.653897295897703

Epoch: 5| Step: 1
Training loss: 1.9885907185257816
Validation loss: 2.6566089221146836

Epoch: 5| Step: 2
Training loss: 2.4919837222600947
Validation loss: 2.633637411609983

Epoch: 5| Step: 3
Training loss: 1.5931737269316177
Validation loss: 2.6357315603627236

Epoch: 5| Step: 4
Training loss: 1.7579277170356418
Validation loss: 2.6164094011011616

Epoch: 5| Step: 5
Training loss: 2.0880438638661785
Validation loss: 2.599994294552345

Epoch: 5| Step: 6
Training loss: 2.299549854843793
Validation loss: 2.595618695537269

Epoch: 5| Step: 7
Training loss: 1.752343447953503
Validation loss: 2.6151824573270153

Epoch: 5| Step: 8
Training loss: 1.4874523187256046
Validation loss: 2.6116275595888205

Epoch: 5| Step: 9
Training loss: 2.0840601098439726
Validation loss: 2.614226143583588

Epoch: 5| Step: 10
Training loss: 1.9327153223844842
Validation loss: 2.6400364812615553

Epoch: 229| Step: 0
Training loss: 2.4718250486629327
Validation loss: 2.6537468086027842

Epoch: 5| Step: 1
Training loss: 1.9970899510991917
Validation loss: 2.6810598741859315

Epoch: 5| Step: 2
Training loss: 2.137646349977475
Validation loss: 2.685393236227147

Epoch: 5| Step: 3
Training loss: 1.9393525035068473
Validation loss: 2.6745662475931957

Epoch: 5| Step: 4
Training loss: 1.7490388410561937
Validation loss: 2.665102929600203

Epoch: 5| Step: 5
Training loss: 1.5412391722856462
Validation loss: 2.6154410767561287

Epoch: 5| Step: 6
Training loss: 1.8234999749759204
Validation loss: 2.6211487664496564

Epoch: 5| Step: 7
Training loss: 2.013604030705731
Validation loss: 2.6166921368120843

Epoch: 5| Step: 8
Training loss: 1.3461508040865386
Validation loss: 2.5726245861972883

Epoch: 5| Step: 9
Training loss: 2.224906760844576
Validation loss: 2.5922635451281013

Epoch: 5| Step: 10
Training loss: 1.9189668066941887
Validation loss: 2.6020587158562454

Epoch: 230| Step: 0
Training loss: 1.5267962867287905
Validation loss: 2.6284856609298

Epoch: 5| Step: 1
Training loss: 2.0630433493944604
Validation loss: 2.6213867782693248

Epoch: 5| Step: 2
Training loss: 1.7041275153602173
Validation loss: 2.6509351550397082

Epoch: 5| Step: 3
Training loss: 1.5027831801205545
Validation loss: 2.6758826849525463

Epoch: 5| Step: 4
Training loss: 2.3604461057554924
Validation loss: 2.666142769528706

Epoch: 5| Step: 5
Training loss: 2.020196270236107
Validation loss: 2.6805485067123094

Epoch: 5| Step: 6
Training loss: 2.2241143939422963
Validation loss: 2.668099645814411

Epoch: 5| Step: 7
Training loss: 1.8469436271297086
Validation loss: 2.708763503627068

Epoch: 5| Step: 8
Training loss: 1.8336600604945843
Validation loss: 2.690019683151367

Epoch: 5| Step: 9
Training loss: 2.0027096988831126
Validation loss: 2.692491138254878

Epoch: 5| Step: 10
Training loss: 1.8701166775456224
Validation loss: 2.675202109754162

Epoch: 231| Step: 0
Training loss: 2.147365122102166
Validation loss: 2.6985698100502575

Epoch: 5| Step: 1
Training loss: 1.9053292474046644
Validation loss: 2.675134628437952

Epoch: 5| Step: 2
Training loss: 1.9370429822833082
Validation loss: 2.6920261621364854

Epoch: 5| Step: 3
Training loss: 1.880914958635627
Validation loss: 2.6694047916552637

Epoch: 5| Step: 4
Training loss: 2.0729044110368773
Validation loss: 2.65538739380077

Epoch: 5| Step: 5
Training loss: 1.910824960933443
Validation loss: 2.6362566031185892

Epoch: 5| Step: 6
Training loss: 1.9289766925295562
Validation loss: 2.6539802712868377

Epoch: 5| Step: 7
Training loss: 2.1910952859108885
Validation loss: 2.646700261561662

Epoch: 5| Step: 8
Training loss: 1.8453460509426118
Validation loss: 2.636200924625661

Epoch: 5| Step: 9
Training loss: 1.3486914155838632
Validation loss: 2.6336791525886203

Epoch: 5| Step: 10
Training loss: 1.630744464046726
Validation loss: 2.6380097463159164

Epoch: 232| Step: 0
Training loss: 1.8317786329282504
Validation loss: 2.633968694956779

Epoch: 5| Step: 1
Training loss: 2.2458082996263626
Validation loss: 2.6636734703886926

Epoch: 5| Step: 2
Training loss: 2.0600681417731743
Validation loss: 2.653722559779428

Epoch: 5| Step: 3
Training loss: 1.434261322503416
Validation loss: 2.629131206156763

Epoch: 5| Step: 4
Training loss: 1.821958068210211
Validation loss: 2.6395031042757577

Epoch: 5| Step: 5
Training loss: 2.2592814066009232
Validation loss: 2.672792114300234

Epoch: 5| Step: 6
Training loss: 2.373333697783339
Validation loss: 2.654335821467347

Epoch: 5| Step: 7
Training loss: 1.5486831885852468
Validation loss: 2.6637294311964275

Epoch: 5| Step: 8
Training loss: 1.4672345398663456
Validation loss: 2.6693210299154257

Epoch: 5| Step: 9
Training loss: 1.9286964744315316
Validation loss: 2.6619867288707324

Epoch: 5| Step: 10
Training loss: 1.1482267121441585
Validation loss: 2.6725366858863846

Epoch: 233| Step: 0
Training loss: 2.3277193266460108
Validation loss: 2.663344242660335

Epoch: 5| Step: 1
Training loss: 1.7010482585504387
Validation loss: 2.6874304149764336

Epoch: 5| Step: 2
Training loss: 1.953167785175905
Validation loss: 2.6874418736491834

Epoch: 5| Step: 3
Training loss: 2.0051608257528346
Validation loss: 2.6844230603144594

Epoch: 5| Step: 4
Training loss: 1.5115133929679823
Validation loss: 2.6537560874553017

Epoch: 5| Step: 5
Training loss: 1.733899437941767
Validation loss: 2.627471591361935

Epoch: 5| Step: 6
Training loss: 2.2510997415795035
Validation loss: 2.610470351350424

Epoch: 5| Step: 7
Training loss: 1.7569084046511885
Validation loss: 2.5956954213352637

Epoch: 5| Step: 8
Training loss: 1.9065964806027524
Validation loss: 2.5817140962762033

Epoch: 5| Step: 9
Training loss: 1.790366751004843
Validation loss: 2.6030972079337764

Epoch: 5| Step: 10
Training loss: 1.4870628515991928
Validation loss: 2.5878302850574793

Epoch: 234| Step: 0
Training loss: 1.2885414226329246
Validation loss: 2.598151441732884

Epoch: 5| Step: 1
Training loss: 2.0905319079099227
Validation loss: 2.619743548473886

Epoch: 5| Step: 2
Training loss: 1.7340967453451948
Validation loss: 2.655010218292324

Epoch: 5| Step: 3
Training loss: 1.94341102416447
Validation loss: 2.6688418521719464

Epoch: 5| Step: 4
Training loss: 2.131225330735789
Validation loss: 2.7053990389138245

Epoch: 5| Step: 5
Training loss: 2.045988400468359
Validation loss: 2.735571864363596

Epoch: 5| Step: 6
Training loss: 1.8512238784379254
Validation loss: 2.7313706110416183

Epoch: 5| Step: 7
Training loss: 2.0369829703711395
Validation loss: 2.7284567178113446

Epoch: 5| Step: 8
Training loss: 1.3718133760484494
Validation loss: 2.706607928920292

Epoch: 5| Step: 9
Training loss: 2.01305941749959
Validation loss: 2.6639628456806506

Epoch: 5| Step: 10
Training loss: 1.6983683244783596
Validation loss: 2.6671449350293677

Epoch: 235| Step: 0
Training loss: 1.6155119245792158
Validation loss: 2.6561440935924643

Epoch: 5| Step: 1
Training loss: 2.2903002624559536
Validation loss: 2.643106669997216

Epoch: 5| Step: 2
Training loss: 2.0393480122937775
Validation loss: 2.5833700940245334

Epoch: 5| Step: 3
Training loss: 1.9146015264610423
Validation loss: 2.6251116004733897

Epoch: 5| Step: 4
Training loss: 1.8391735370728326
Validation loss: 2.614936992626798

Epoch: 5| Step: 5
Training loss: 1.1087098612610602
Validation loss: 2.634269770895788

Epoch: 5| Step: 6
Training loss: 2.134617192167811
Validation loss: 2.6473887564999665

Epoch: 5| Step: 7
Training loss: 1.7286132095291211
Validation loss: 2.649575507832789

Epoch: 5| Step: 8
Training loss: 1.8056198288000733
Validation loss: 2.643043491096441

Epoch: 5| Step: 9
Training loss: 1.32007510968573
Validation loss: 2.6438913382853375

Epoch: 5| Step: 10
Training loss: 2.1062268536028808
Validation loss: 2.606220740308019

Epoch: 236| Step: 0
Training loss: 1.6993977770273296
Validation loss: 2.62804231367161

Epoch: 5| Step: 1
Training loss: 1.7866704683239665
Validation loss: 2.6333545550260613

Epoch: 5| Step: 2
Training loss: 1.993501596312868
Validation loss: 2.668680693396569

Epoch: 5| Step: 3
Training loss: 1.8660311130697842
Validation loss: 2.671701540423008

Epoch: 5| Step: 4
Training loss: 1.7999282769642728
Validation loss: 2.7004457029922646

Epoch: 5| Step: 5
Training loss: 1.5319357134625085
Validation loss: 2.722000669068096

Epoch: 5| Step: 6
Training loss: 1.748591605614561
Validation loss: 2.7333908011485173

Epoch: 5| Step: 7
Training loss: 1.8744219842703422
Validation loss: 2.715381260375037

Epoch: 5| Step: 8
Training loss: 2.2826627772304042
Validation loss: 2.6535593379189732

Epoch: 5| Step: 9
Training loss: 1.9622210067413086
Validation loss: 2.6351482461050804

Epoch: 5| Step: 10
Training loss: 1.1875639948416157
Validation loss: 2.6266115352523243

Epoch: 237| Step: 0
Training loss: 1.829336759208626
Validation loss: 2.642851813211158

Epoch: 5| Step: 1
Training loss: 1.6234952855771585
Validation loss: 2.6460404397762542

Epoch: 5| Step: 2
Training loss: 1.4295238964088892
Validation loss: 2.655264871656617

Epoch: 5| Step: 3
Training loss: 1.7825017847210054
Validation loss: 2.6776389117730397

Epoch: 5| Step: 4
Training loss: 2.0147091462996216
Validation loss: 2.6853440840925753

Epoch: 5| Step: 5
Training loss: 1.8360646305302357
Validation loss: 2.6840549642320717

Epoch: 5| Step: 6
Training loss: 1.7041738937460966
Validation loss: 2.668830526889709

Epoch: 5| Step: 7
Training loss: 1.9189609672548464
Validation loss: 2.6781874510079726

Epoch: 5| Step: 8
Training loss: 1.9780885135606214
Validation loss: 2.6416952118891026

Epoch: 5| Step: 9
Training loss: 1.4204531256928719
Validation loss: 2.61775468249453

Epoch: 5| Step: 10
Training loss: 2.0570064556222665
Validation loss: 2.6233796384074717

Epoch: 238| Step: 0
Training loss: 1.7864484054541658
Validation loss: 2.642429361292071

Epoch: 5| Step: 1
Training loss: 1.837261096189458
Validation loss: 2.6178040499569306

Epoch: 5| Step: 2
Training loss: 1.4354992086580407
Validation loss: 2.632216532067851

Epoch: 5| Step: 3
Training loss: 1.8237264160764877
Validation loss: 2.666890714318925

Epoch: 5| Step: 4
Training loss: 1.664533163499462
Validation loss: 2.6829587223837263

Epoch: 5| Step: 5
Training loss: 1.4282450251987595
Validation loss: 2.676638292377716

Epoch: 5| Step: 6
Training loss: 1.9009652597061366
Validation loss: 2.6888481397000765

Epoch: 5| Step: 7
Training loss: 1.7280500399178853
Validation loss: 2.7011888037690084

Epoch: 5| Step: 8
Training loss: 2.1876911624759763
Validation loss: 2.6931516817458956

Epoch: 5| Step: 9
Training loss: 2.015117374343031
Validation loss: 2.6889410255003936

Epoch: 5| Step: 10
Training loss: 1.1856733125888792
Validation loss: 2.6623346233756924

Epoch: 239| Step: 0
Training loss: 1.8236374510875326
Validation loss: 2.6870521841007062

Epoch: 5| Step: 1
Training loss: 1.4278407442100873
Validation loss: 2.676751788302492

Epoch: 5| Step: 2
Training loss: 1.673970914111746
Validation loss: 2.668715959207786

Epoch: 5| Step: 3
Training loss: 2.2896305980669127
Validation loss: 2.692764909679529

Epoch: 5| Step: 4
Training loss: 1.444760933869814
Validation loss: 2.691338177656296

Epoch: 5| Step: 5
Training loss: 1.5943173165468236
Validation loss: 2.6823837313854875

Epoch: 5| Step: 6
Training loss: 2.029815401976513
Validation loss: 2.655592241588888

Epoch: 5| Step: 7
Training loss: 1.7139026605570404
Validation loss: 2.6538259758312908

Epoch: 5| Step: 8
Training loss: 1.7377448122191042
Validation loss: 2.6134034979579774

Epoch: 5| Step: 9
Training loss: 1.5367861726648162
Validation loss: 2.6102608585703475

Epoch: 5| Step: 10
Training loss: 1.83925157480923
Validation loss: 2.57831964935714

Epoch: 240| Step: 0
Training loss: 2.103298108712255
Validation loss: 2.5677181091368775

Epoch: 5| Step: 1
Training loss: 2.1232538341728797
Validation loss: 2.5701926296596413

Epoch: 5| Step: 2
Training loss: 1.175852725875919
Validation loss: 2.578860254435444

Epoch: 5| Step: 3
Training loss: 1.438617437836164
Validation loss: 2.584773399286302

Epoch: 5| Step: 4
Training loss: 1.803708690400265
Validation loss: 2.610774181320608

Epoch: 5| Step: 5
Training loss: 1.9816845654940418
Validation loss: 2.606750534096759

Epoch: 5| Step: 6
Training loss: 1.6865665538513648
Validation loss: 2.6151859746098682

Epoch: 5| Step: 7
Training loss: 1.3133586617914252
Validation loss: 2.628356403133032

Epoch: 5| Step: 8
Training loss: 1.6981619519259263
Validation loss: 2.6558483198883067

Epoch: 5| Step: 9
Training loss: 1.9762408330271646
Validation loss: 2.649910023818566

Epoch: 5| Step: 10
Training loss: 1.6483053000714558
Validation loss: 2.6393551327339124

Epoch: 241| Step: 0
Training loss: 1.6591016583789233
Validation loss: 2.6977754496468362

Epoch: 5| Step: 1
Training loss: 2.0273615077422553
Validation loss: 2.7052313916135957

Epoch: 5| Step: 2
Training loss: 2.0219374586596284
Validation loss: 2.716137532453823

Epoch: 5| Step: 3
Training loss: 1.82706714247428
Validation loss: 2.694294851737412

Epoch: 5| Step: 4
Training loss: 1.429269197899219
Validation loss: 2.69735534874684

Epoch: 5| Step: 5
Training loss: 1.4355771016163008
Validation loss: 2.6962971909054674

Epoch: 5| Step: 6
Training loss: 1.5333281447834188
Validation loss: 2.7126945581208495

Epoch: 5| Step: 7
Training loss: 2.1526204396932718
Validation loss: 2.6742387040783875

Epoch: 5| Step: 8
Training loss: 1.5190667469661367
Validation loss: 2.6287180249564512

Epoch: 5| Step: 9
Training loss: 1.878191837892375
Validation loss: 2.5802670715541085

Epoch: 5| Step: 10
Training loss: 1.9683748523598004
Validation loss: 2.5743777221190167

Epoch: 242| Step: 0
Training loss: 2.036448238832345
Validation loss: 2.641622194978355

Epoch: 5| Step: 1
Training loss: 1.4910608002452737
Validation loss: 2.6257361677710613

Epoch: 5| Step: 2
Training loss: 2.1800133246268327
Validation loss: 2.6621796680975507

Epoch: 5| Step: 3
Training loss: 1.8611640337477935
Validation loss: 2.6687170447160877

Epoch: 5| Step: 4
Training loss: 1.202542845345378
Validation loss: 2.707466213539052

Epoch: 5| Step: 5
Training loss: 1.844349521214075
Validation loss: 2.7038878706895355

Epoch: 5| Step: 6
Training loss: 1.567424642890023
Validation loss: 2.7671689057139

Epoch: 5| Step: 7
Training loss: 2.1003334961341045
Validation loss: 2.8058577626939267

Epoch: 5| Step: 8
Training loss: 1.6258368904678377
Validation loss: 2.7474464939432797

Epoch: 5| Step: 9
Training loss: 1.5816687651373418
Validation loss: 2.697838346961736

Epoch: 5| Step: 10
Training loss: 1.7374238031818239
Validation loss: 2.6599280414105007

Epoch: 243| Step: 0
Training loss: 1.4112829636676385
Validation loss: 2.5870942801011716

Epoch: 5| Step: 1
Training loss: 1.6826283813741845
Validation loss: 2.53971728594353

Epoch: 5| Step: 2
Training loss: 1.491712564511699
Validation loss: 2.5323523345877423

Epoch: 5| Step: 3
Training loss: 1.8671179084099185
Validation loss: 2.5389389848601978

Epoch: 5| Step: 4
Training loss: 1.5178103079101617
Validation loss: 2.535581361125661

Epoch: 5| Step: 5
Training loss: 1.8143254000053277
Validation loss: 2.530296816686413

Epoch: 5| Step: 6
Training loss: 1.589692354609173
Validation loss: 2.563968558777491

Epoch: 5| Step: 7
Training loss: 1.5680163092592199
Validation loss: 2.585377235591502

Epoch: 5| Step: 8
Training loss: 1.9806000254083567
Validation loss: 2.592527704196772

Epoch: 5| Step: 9
Training loss: 1.9095605338650874
Validation loss: 2.61786098933573

Epoch: 5| Step: 10
Training loss: 2.0914537734345395
Validation loss: 2.630310476377373

Epoch: 244| Step: 0
Training loss: 1.699353092188478
Validation loss: 2.652862734376376

Epoch: 5| Step: 1
Training loss: 2.140582787313315
Validation loss: 2.669172861545784

Epoch: 5| Step: 2
Training loss: 1.5020983641882517
Validation loss: 2.6821328475834565

Epoch: 5| Step: 3
Training loss: 1.8732389445073456
Validation loss: 2.671579224294563

Epoch: 5| Step: 4
Training loss: 1.5197268950909706
Validation loss: 2.6931178268193805

Epoch: 5| Step: 5
Training loss: 1.200094443816775
Validation loss: 2.658801208806258

Epoch: 5| Step: 6
Training loss: 1.7790810614307262
Validation loss: 2.651728285469828

Epoch: 5| Step: 7
Training loss: 1.4858052641135149
Validation loss: 2.640094721068433

Epoch: 5| Step: 8
Training loss: 1.6501096226660779
Validation loss: 2.6504187665742913

Epoch: 5| Step: 9
Training loss: 2.0740478215309586
Validation loss: 2.6349703898780814

Epoch: 5| Step: 10
Training loss: 1.2138807398806013
Validation loss: 2.670173499995632

Epoch: 245| Step: 0
Training loss: 1.5435338011791937
Validation loss: 2.6429068811350995

Epoch: 5| Step: 1
Training loss: 1.8807599921822453
Validation loss: 2.6764351794457064

Epoch: 5| Step: 2
Training loss: 1.5912576522703084
Validation loss: 2.6542876105940016

Epoch: 5| Step: 3
Training loss: 1.8459717893087717
Validation loss: 2.6560406674172476

Epoch: 5| Step: 4
Training loss: 1.4559212309416973
Validation loss: 2.6654550224919196

Epoch: 5| Step: 5
Training loss: 1.7236519701706232
Validation loss: 2.651244061844125

Epoch: 5| Step: 6
Training loss: 1.3279487044067797
Validation loss: 2.650923927329837

Epoch: 5| Step: 7
Training loss: 1.5482532256844437
Validation loss: 2.658106251449046

Epoch: 5| Step: 8
Training loss: 1.6793295545430744
Validation loss: 2.653351423988542

Epoch: 5| Step: 9
Training loss: 1.7212616342055793
Validation loss: 2.658622042572621

Epoch: 5| Step: 10
Training loss: 1.828280841673142
Validation loss: 2.6571916661565824

Epoch: 246| Step: 0
Training loss: 1.5209662322760886
Validation loss: 2.7007925580944634

Epoch: 5| Step: 1
Training loss: 1.8568321599547735
Validation loss: 2.7045903086876417

Epoch: 5| Step: 2
Training loss: 1.5152153956067165
Validation loss: 2.7110086244763596

Epoch: 5| Step: 3
Training loss: 1.6967299200881714
Validation loss: 2.715519546554599

Epoch: 5| Step: 4
Training loss: 1.1754628000510667
Validation loss: 2.662587308167102

Epoch: 5| Step: 5
Training loss: 1.4537780278817694
Validation loss: 2.6559310171429287

Epoch: 5| Step: 6
Training loss: 1.3330248932914357
Validation loss: 2.6684065040932796

Epoch: 5| Step: 7
Training loss: 1.9379884042737425
Validation loss: 2.6441836323212935

Epoch: 5| Step: 8
Training loss: 1.4310821234852091
Validation loss: 2.631967527697203

Epoch: 5| Step: 9
Training loss: 1.979401972652862
Validation loss: 2.653854715643265

Epoch: 5| Step: 10
Training loss: 2.0208250878024905
Validation loss: 2.627852756561923

Epoch: 247| Step: 0
Training loss: 1.228631140004013
Validation loss: 2.634353354770227

Epoch: 5| Step: 1
Training loss: 1.964396067405311
Validation loss: 2.6445803900130302

Epoch: 5| Step: 2
Training loss: 1.5754893738519347
Validation loss: 2.6473747393684257

Epoch: 5| Step: 3
Training loss: 1.5049257464166739
Validation loss: 2.6748811598799946

Epoch: 5| Step: 4
Training loss: 1.8252490644464314
Validation loss: 2.6644227934183258

Epoch: 5| Step: 5
Training loss: 1.754450656195906
Validation loss: 2.6921462094319617

Epoch: 5| Step: 6
Training loss: 0.9491339123650463
Validation loss: 2.709346005136683

Epoch: 5| Step: 7
Training loss: 1.9617804429088923
Validation loss: 2.6946204415944712

Epoch: 5| Step: 8
Training loss: 1.383306813656102
Validation loss: 2.704077694128196

Epoch: 5| Step: 9
Training loss: 1.5430397500229074
Validation loss: 2.666183400651123

Epoch: 5| Step: 10
Training loss: 1.8716437501033751
Validation loss: 2.6442432578471964

Epoch: 248| Step: 0
Training loss: 1.4916292914000604
Validation loss: 2.6500768427466252

Epoch: 5| Step: 1
Training loss: 1.7376975461781052
Validation loss: 2.6453587096086193

Epoch: 5| Step: 2
Training loss: 1.9329013393896572
Validation loss: 2.632445180654614

Epoch: 5| Step: 3
Training loss: 1.8970275792403006
Validation loss: 2.641060528144277

Epoch: 5| Step: 4
Training loss: 1.7650209592055661
Validation loss: 2.675787927882556

Epoch: 5| Step: 5
Training loss: 1.393415501573391
Validation loss: 2.6997032570638715

Epoch: 5| Step: 6
Training loss: 1.7363559990995887
Validation loss: 2.7461436277392357

Epoch: 5| Step: 7
Training loss: 1.217369177680894
Validation loss: 2.7166820257182906

Epoch: 5| Step: 8
Training loss: 1.8108906671558982
Validation loss: 2.710454253903639

Epoch: 5| Step: 9
Training loss: 1.7081162694714196
Validation loss: 2.6724285806071117

Epoch: 5| Step: 10
Training loss: 1.5350484640317612
Validation loss: 2.641493972092448

Epoch: 249| Step: 0
Training loss: 1.5572032414298491
Validation loss: 2.6020393411278886

Epoch: 5| Step: 1
Training loss: 1.4203951334232634
Validation loss: 2.619551470722872

Epoch: 5| Step: 2
Training loss: 1.8021080441700905
Validation loss: 2.5886893908761563

Epoch: 5| Step: 3
Training loss: 1.7323524435380353
Validation loss: 2.5874493283317657

Epoch: 5| Step: 4
Training loss: 1.7320342893664131
Validation loss: 2.5917316960263643

Epoch: 5| Step: 5
Training loss: 1.6732668208142105
Validation loss: 2.6053368841196547

Epoch: 5| Step: 6
Training loss: 1.6379414727697061
Validation loss: 2.608398319559091

Epoch: 5| Step: 7
Training loss: 1.726993627791585
Validation loss: 2.619512664754535

Epoch: 5| Step: 8
Training loss: 1.600109129402718
Validation loss: 2.6338406961382863

Epoch: 5| Step: 9
Training loss: 1.5275820963223674
Validation loss: 2.635399210668306

Epoch: 5| Step: 10
Training loss: 1.2341620346040794
Validation loss: 2.6489556402507644

Epoch: 250| Step: 0
Training loss: 1.7606633105729306
Validation loss: 2.652992761750699

Epoch: 5| Step: 1
Training loss: 0.7191112688445492
Validation loss: 2.6329621682978464

Epoch: 5| Step: 2
Training loss: 1.9128578599207893
Validation loss: 2.6358940654826926

Epoch: 5| Step: 3
Training loss: 1.885300887401042
Validation loss: 2.5943392743842297

Epoch: 5| Step: 4
Training loss: 1.1225733015599395
Validation loss: 2.5918359129523783

Epoch: 5| Step: 5
Training loss: 1.8120367839439593
Validation loss: 2.589448204874472

Epoch: 5| Step: 6
Training loss: 1.5717276653913343
Validation loss: 2.6057382644609577

Epoch: 5| Step: 7
Training loss: 1.8519430936305517
Validation loss: 2.624706902379711

Epoch: 5| Step: 8
Training loss: 1.385330493895332
Validation loss: 2.6200476230488

Epoch: 5| Step: 9
Training loss: 1.582954871806182
Validation loss: 2.6203693343493364

Epoch: 5| Step: 10
Training loss: 1.4915534464882843
Validation loss: 2.674778709807674

Epoch: 251| Step: 0
Training loss: 1.351429839045772
Validation loss: 2.6777597725662767

Epoch: 5| Step: 1
Training loss: 1.4394915509626893
Validation loss: 2.6593855474630237

Epoch: 5| Step: 2
Training loss: 1.6744181462189935
Validation loss: 2.692888406475076

Epoch: 5| Step: 3
Training loss: 1.2641320076258502
Validation loss: 2.6646928275802746

Epoch: 5| Step: 4
Training loss: 1.7116194110774379
Validation loss: 2.6548239289789612

Epoch: 5| Step: 5
Training loss: 1.6305606774085966
Validation loss: 2.6685608826049516

Epoch: 5| Step: 6
Training loss: 1.4977197799779365
Validation loss: 2.6375797763352122

Epoch: 5| Step: 7
Training loss: 1.6954932753694778
Validation loss: 2.6550379599153024

Epoch: 5| Step: 8
Training loss: 1.2326986301373968
Validation loss: 2.658745915171567

Epoch: 5| Step: 9
Training loss: 1.7833366887188775
Validation loss: 2.6573195850171496

Epoch: 5| Step: 10
Training loss: 1.7728425763162898
Validation loss: 2.645120666858137

Epoch: 252| Step: 0
Training loss: 1.6713970606375559
Validation loss: 2.6560586009838474

Epoch: 5| Step: 1
Training loss: 1.2195124564228708
Validation loss: 2.6250991592586006

Epoch: 5| Step: 2
Training loss: 1.5226882265744721
Validation loss: 2.6454611976718834

Epoch: 5| Step: 3
Training loss: 1.4039514193647875
Validation loss: 2.643485164727842

Epoch: 5| Step: 4
Training loss: 1.361685225773887
Validation loss: 2.609550937308865

Epoch: 5| Step: 5
Training loss: 1.6398565036519446
Validation loss: 2.6310706798712444

Epoch: 5| Step: 6
Training loss: 1.220040787108844
Validation loss: 2.614737668197191

Epoch: 5| Step: 7
Training loss: 1.9836391977134658
Validation loss: 2.634376933296954

Epoch: 5| Step: 8
Training loss: 1.2153886266138878
Validation loss: 2.618914332984926

Epoch: 5| Step: 9
Training loss: 1.8227204862116717
Validation loss: 2.640910421111804

Epoch: 5| Step: 10
Training loss: 1.5928529196810899
Validation loss: 2.622566877850231

Epoch: 253| Step: 0
Training loss: 1.6138857247078466
Validation loss: 2.613851655592296

Epoch: 5| Step: 1
Training loss: 1.5763138301791269
Validation loss: 2.600063247834288

Epoch: 5| Step: 2
Training loss: 1.5408728162301777
Validation loss: 2.5997598720582835

Epoch: 5| Step: 3
Training loss: 1.6049502387012737
Validation loss: 2.622985461378183

Epoch: 5| Step: 4
Training loss: 1.828986788039253
Validation loss: 2.6049127060576707

Epoch: 5| Step: 5
Training loss: 1.466911626357722
Validation loss: 2.6319057514317943

Epoch: 5| Step: 6
Training loss: 1.3864536945466994
Validation loss: 2.6221679190252054

Epoch: 5| Step: 7
Training loss: 1.4908138163557618
Validation loss: 2.6166157151290848

Epoch: 5| Step: 8
Training loss: 1.1375535344531915
Validation loss: 2.626660466874204

Epoch: 5| Step: 9
Training loss: 1.5054110046302764
Validation loss: 2.665086222759495

Epoch: 5| Step: 10
Training loss: 1.5356682852892538
Validation loss: 2.653534131886873

Epoch: 254| Step: 0
Training loss: 1.484145939871616
Validation loss: 2.6520927494442152

Epoch: 5| Step: 1
Training loss: 1.4905558348150028
Validation loss: 2.6857379899769693

Epoch: 5| Step: 2
Training loss: 1.0957286920131528
Validation loss: 2.652162123910248

Epoch: 5| Step: 3
Training loss: 1.6070180132983287
Validation loss: 2.6695608160502835

Epoch: 5| Step: 4
Training loss: 1.5270523612857145
Validation loss: 2.661078648711695

Epoch: 5| Step: 5
Training loss: 1.9683002382037686
Validation loss: 2.6598890794799175

Epoch: 5| Step: 6
Training loss: 1.5696800818354397
Validation loss: 2.6717156352675824

Epoch: 5| Step: 7
Training loss: 1.1804531215034593
Validation loss: 2.67886623805252

Epoch: 5| Step: 8
Training loss: 1.6519630660946154
Validation loss: 2.6685661490630594

Epoch: 5| Step: 9
Training loss: 1.3280960079843438
Validation loss: 2.68533062118066

Epoch: 5| Step: 10
Training loss: 1.5124468959597044
Validation loss: 2.6646106014081403

Epoch: 255| Step: 0
Training loss: 1.4734783761593366
Validation loss: 2.6416159897240585

Epoch: 5| Step: 1
Training loss: 1.3899859556682421
Validation loss: 2.6561251297903343

Epoch: 5| Step: 2
Training loss: 1.0098358661120164
Validation loss: 2.6214960437304415

Epoch: 5| Step: 3
Training loss: 1.39846273218333
Validation loss: 2.630880949232164

Epoch: 5| Step: 4
Training loss: 1.438300283162062
Validation loss: 2.6354120716458773

Epoch: 5| Step: 5
Training loss: 1.7935411790257858
Validation loss: 2.619820449414278

Epoch: 5| Step: 6
Training loss: 1.7509455850970428
Validation loss: 2.6273977596031255

Epoch: 5| Step: 7
Training loss: 1.6123418035457562
Validation loss: 2.615134214786128

Epoch: 5| Step: 8
Training loss: 1.3572203562055674
Validation loss: 2.6251903265705563

Epoch: 5| Step: 9
Training loss: 1.5541852590285734
Validation loss: 2.6427397900470195

Epoch: 5| Step: 10
Training loss: 1.5589014958942617
Validation loss: 2.634024859583778

Epoch: 256| Step: 0
Training loss: 1.1937330694146406
Validation loss: 2.6000019746335896

Epoch: 5| Step: 1
Training loss: 1.3062835342264238
Validation loss: 2.636757722761807

Epoch: 5| Step: 2
Training loss: 1.561948068412442
Validation loss: 2.6312500214736874

Epoch: 5| Step: 3
Training loss: 1.5085322584345184
Validation loss: 2.6340628512489515

Epoch: 5| Step: 4
Training loss: 1.5262411288816686
Validation loss: 2.620234574791097

Epoch: 5| Step: 5
Training loss: 1.373549563335391
Validation loss: 2.6141792072961882

Epoch: 5| Step: 6
Training loss: 1.3251886107599287
Validation loss: 2.6157294624682312

Epoch: 5| Step: 7
Training loss: 1.4418297949138175
Validation loss: 2.6384312035442696

Epoch: 5| Step: 8
Training loss: 1.7244765164619835
Validation loss: 2.648195319114108

Epoch: 5| Step: 9
Training loss: 1.7442356267432282
Validation loss: 2.6249173781776514

Epoch: 5| Step: 10
Training loss: 1.503986703281266
Validation loss: 2.628849142223751

Epoch: 257| Step: 0
Training loss: 1.5646881041345635
Validation loss: 2.6129185680745164

Epoch: 5| Step: 1
Training loss: 1.1923706154039355
Validation loss: 2.6451848496374097

Epoch: 5| Step: 2
Training loss: 1.6350720117325186
Validation loss: 2.632719857982639

Epoch: 5| Step: 3
Training loss: 1.5718264138086255
Validation loss: 2.6171933850715208

Epoch: 5| Step: 4
Training loss: 1.5922970600262265
Validation loss: 2.6475566580522085

Epoch: 5| Step: 5
Training loss: 1.4502401942234129
Validation loss: 2.627353887320803

Epoch: 5| Step: 6
Training loss: 1.3725915970663074
Validation loss: 2.6489366607949183

Epoch: 5| Step: 7
Training loss: 1.467703263666816
Validation loss: 2.6438295933684417

Epoch: 5| Step: 8
Training loss: 1.4298913528943915
Validation loss: 2.642398432640086

Epoch: 5| Step: 9
Training loss: 1.3696998401027647
Validation loss: 2.6308060506125646

Epoch: 5| Step: 10
Training loss: 1.4309889909386095
Validation loss: 2.652304708554235

Epoch: 258| Step: 0
Training loss: 1.4526304818668632
Validation loss: 2.6545420107163205

Epoch: 5| Step: 1
Training loss: 1.429176697913611
Validation loss: 2.6874827741875498

Epoch: 5| Step: 2
Training loss: 1.0769544134454003
Validation loss: 2.69104929587484

Epoch: 5| Step: 3
Training loss: 1.3101548633329256
Validation loss: 2.706579973278292

Epoch: 5| Step: 4
Training loss: 1.729126213550383
Validation loss: 2.6806076184026617

Epoch: 5| Step: 5
Training loss: 1.465307950537305
Validation loss: 2.6598783353320044

Epoch: 5| Step: 6
Training loss: 1.3733910770838011
Validation loss: 2.663079564215947

Epoch: 5| Step: 7
Training loss: 1.5093295515022032
Validation loss: 2.6500092053306714

Epoch: 5| Step: 8
Training loss: 1.4219569088326067
Validation loss: 2.643478509011341

Epoch: 5| Step: 9
Training loss: 1.3331734243505349
Validation loss: 2.6502667284896084

Epoch: 5| Step: 10
Training loss: 1.7763848369407356
Validation loss: 2.6164636018849197

Epoch: 259| Step: 0
Training loss: 1.8087638626674638
Validation loss: 2.6343682284669496

Epoch: 5| Step: 1
Training loss: 1.096398661504163
Validation loss: 2.6231580308199773

Epoch: 5| Step: 2
Training loss: 1.5184711592783244
Validation loss: 2.6332814265886113

Epoch: 5| Step: 3
Training loss: 1.5645049392558832
Validation loss: 2.617125010459922

Epoch: 5| Step: 4
Training loss: 1.3125008628479073
Validation loss: 2.6364538509212667

Epoch: 5| Step: 5
Training loss: 1.343716155224783
Validation loss: 2.6324999238392754

Epoch: 5| Step: 6
Training loss: 1.1833139220960422
Validation loss: 2.6261296378429555

Epoch: 5| Step: 7
Training loss: 1.128339579032918
Validation loss: 2.6670787599256283

Epoch: 5| Step: 8
Training loss: 1.2910044059323655
Validation loss: 2.653352881485201

Epoch: 5| Step: 9
Training loss: 1.682115582993318
Validation loss: 2.6627099776613727

Epoch: 5| Step: 10
Training loss: 1.7266906414552268
Validation loss: 2.6351420752220513

Epoch: 260| Step: 0
Training loss: 1.362389827788632
Validation loss: 2.643515273804524

Epoch: 5| Step: 1
Training loss: 1.4126727614626091
Validation loss: 2.640210023861861

Epoch: 5| Step: 2
Training loss: 1.2158213910324032
Validation loss: 2.640452247808948

Epoch: 5| Step: 3
Training loss: 1.0244059748734904
Validation loss: 2.6526283325218976

Epoch: 5| Step: 4
Training loss: 1.6838198906001536
Validation loss: 2.654377123956016

Epoch: 5| Step: 5
Training loss: 1.4416098515481957
Validation loss: 2.694517951881402

Epoch: 5| Step: 6
Training loss: 1.8229523210217617
Validation loss: 2.678966928436862

Epoch: 5| Step: 7
Training loss: 1.3036803052639592
Validation loss: 2.681779694114714

Epoch: 5| Step: 8
Training loss: 1.759793466565793
Validation loss: 2.6692546984257177

Epoch: 5| Step: 9
Training loss: 1.0318286890442865
Validation loss: 2.6893136271604816

Epoch: 5| Step: 10
Training loss: 1.3251082771972607
Validation loss: 2.6967439949266003

Epoch: 261| Step: 0
Training loss: 1.302123331091398
Validation loss: 2.69377719071805

Epoch: 5| Step: 1
Training loss: 0.8674924846840325
Validation loss: 2.669313021050591

Epoch: 5| Step: 2
Training loss: 1.8362711501802376
Validation loss: 2.665336307722495

Epoch: 5| Step: 3
Training loss: 1.7268418996526214
Validation loss: 2.6412259436421994

Epoch: 5| Step: 4
Training loss: 1.1516175648995708
Validation loss: 2.62556780501157

Epoch: 5| Step: 5
Training loss: 1.534347437593545
Validation loss: 2.6147485796922325

Epoch: 5| Step: 6
Training loss: 1.350939303804385
Validation loss: 2.5958554415098054

Epoch: 5| Step: 7
Training loss: 1.3131989479940327
Validation loss: 2.6036190128162056

Epoch: 5| Step: 8
Training loss: 1.5191478098363218
Validation loss: 2.6003013075763577

Epoch: 5| Step: 9
Training loss: 1.3692244260557784
Validation loss: 2.6172750498478856

Epoch: 5| Step: 10
Training loss: 1.3804272268167517
Validation loss: 2.59601650650139

Epoch: 262| Step: 0
Training loss: 1.3022717250594371
Validation loss: 2.6387605637712035

Epoch: 5| Step: 1
Training loss: 1.3461137430274903
Validation loss: 2.619110491186689

Epoch: 5| Step: 2
Training loss: 1.5077127216115886
Validation loss: 2.61564511390037

Epoch: 5| Step: 3
Training loss: 1.2796457994161905
Validation loss: 2.619724610836679

Epoch: 5| Step: 4
Training loss: 1.7619450121471096
Validation loss: 2.6314317971658885

Epoch: 5| Step: 5
Training loss: 0.8923455066693675
Validation loss: 2.62375012930578

Epoch: 5| Step: 6
Training loss: 1.442980229983181
Validation loss: 2.623482976302831

Epoch: 5| Step: 7
Training loss: 1.6534777057714678
Validation loss: 2.6520871225791773

Epoch: 5| Step: 8
Training loss: 1.5560756601016987
Validation loss: 2.6724022584511764

Epoch: 5| Step: 9
Training loss: 1.1748797233381885
Validation loss: 2.664538401993019

Epoch: 5| Step: 10
Training loss: 1.2373996809553762
Validation loss: 2.639507597315174

Epoch: 263| Step: 0
Training loss: 1.4484266393885994
Validation loss: 2.659991533918383

Epoch: 5| Step: 1
Training loss: 1.415607598810424
Validation loss: 2.668831268461823

Epoch: 5| Step: 2
Training loss: 0.9887865305251675
Validation loss: 2.6356448531489396

Epoch: 5| Step: 3
Training loss: 1.0878228486622794
Validation loss: 2.6349424676241133

Epoch: 5| Step: 4
Training loss: 1.5108251172848963
Validation loss: 2.661803688124776

Epoch: 5| Step: 5
Training loss: 1.27958259012757
Validation loss: 2.6441215980287116

Epoch: 5| Step: 6
Training loss: 1.3378509738364697
Validation loss: 2.6357768756718642

Epoch: 5| Step: 7
Training loss: 1.354173112511577
Validation loss: 2.655913855886172

Epoch: 5| Step: 8
Training loss: 1.8798240275914346
Validation loss: 2.6541675876389106

Epoch: 5| Step: 9
Training loss: 1.4097968406952477
Validation loss: 2.6698193762569336

Epoch: 5| Step: 10
Training loss: 1.417920240512992
Validation loss: 2.662540714095705

Epoch: 264| Step: 0
Training loss: 1.2001223064718582
Validation loss: 2.6331535413754206

Epoch: 5| Step: 1
Training loss: 1.1764535597662762
Validation loss: 2.6673222317304184

Epoch: 5| Step: 2
Training loss: 1.6526719797645795
Validation loss: 2.6289775381427467

Epoch: 5| Step: 3
Training loss: 1.3965498475419027
Validation loss: 2.622605909398318

Epoch: 5| Step: 4
Training loss: 1.3781805533286422
Validation loss: 2.6485583295068333

Epoch: 5| Step: 5
Training loss: 1.3767161063875788
Validation loss: 2.635340332056739

Epoch: 5| Step: 6
Training loss: 1.5865426999371164
Validation loss: 2.6478134350730307

Epoch: 5| Step: 7
Training loss: 1.4492567525235505
Validation loss: 2.635460087450385

Epoch: 5| Step: 8
Training loss: 1.0765405705271143
Validation loss: 2.6299901448806033

Epoch: 5| Step: 9
Training loss: 1.286470987152179
Validation loss: 2.617466156055501

Epoch: 5| Step: 10
Training loss: 1.65489782162013
Validation loss: 2.6201606751068303

Epoch: 265| Step: 0
Training loss: 1.5641364873712584
Validation loss: 2.643691276108132

Epoch: 5| Step: 1
Training loss: 1.2204547110519182
Validation loss: 2.63488339102465

Epoch: 5| Step: 2
Training loss: 1.4121479963030892
Validation loss: 2.6089615720597727

Epoch: 5| Step: 3
Training loss: 1.46103998324536
Validation loss: 2.6344316781845465

Epoch: 5| Step: 4
Training loss: 1.2403749881841646
Validation loss: 2.6178177945310757

Epoch: 5| Step: 5
Training loss: 1.4069188540659583
Validation loss: 2.617431277616713

Epoch: 5| Step: 6
Training loss: 0.9922833734283635
Validation loss: 2.6127530993505514

Epoch: 5| Step: 7
Training loss: 1.4597487075311264
Validation loss: 2.6299424761504544

Epoch: 5| Step: 8
Training loss: 1.4356626295274015
Validation loss: 2.638767634572474

Epoch: 5| Step: 9
Training loss: 1.6627385420071092
Validation loss: 2.6285155575469528

Epoch: 5| Step: 10
Training loss: 0.9802695144115747
Validation loss: 2.6583849073291965

Epoch: 266| Step: 0
Training loss: 1.2494586726113028
Validation loss: 2.667358945642789

Epoch: 5| Step: 1
Training loss: 1.2635660731554774
Validation loss: 2.6636454553767672

Epoch: 5| Step: 2
Training loss: 1.2463900414147369
Validation loss: 2.6565788919573743

Epoch: 5| Step: 3
Training loss: 1.270080166036211
Validation loss: 2.6408104561707493

Epoch: 5| Step: 4
Training loss: 1.290270799705343
Validation loss: 2.664086249581274

Epoch: 5| Step: 5
Training loss: 1.5855912455393124
Validation loss: 2.6216089042467496

Epoch: 5| Step: 6
Training loss: 1.659437028260771
Validation loss: 2.6309873142366973

Epoch: 5| Step: 7
Training loss: 1.5205659849079975
Validation loss: 2.6207992011403856

Epoch: 5| Step: 8
Training loss: 1.311759830851692
Validation loss: 2.62717329027405

Epoch: 5| Step: 9
Training loss: 1.183021180302677
Validation loss: 2.615028009831115

Epoch: 5| Step: 10
Training loss: 1.2465030870793412
Validation loss: 2.6332362338422945

Epoch: 267| Step: 0
Training loss: 1.19074738842159
Validation loss: 2.6246239919760486

Epoch: 5| Step: 1
Training loss: 1.8789321358338986
Validation loss: 2.6139654905139564

Epoch: 5| Step: 2
Training loss: 1.3824839228545458
Validation loss: 2.6523025347353166

Epoch: 5| Step: 3
Training loss: 1.4153263071658122
Validation loss: 2.668404122421686

Epoch: 5| Step: 4
Training loss: 1.4449592777308768
Validation loss: 2.646832894930115

Epoch: 5| Step: 5
Training loss: 1.3773229224176833
Validation loss: 2.6506048964029207

Epoch: 5| Step: 6
Training loss: 1.3277377742175016
Validation loss: 2.6579094477622283

Epoch: 5| Step: 7
Training loss: 0.736647559374137
Validation loss: 2.635463756169928

Epoch: 5| Step: 8
Training loss: 0.7948451649537193
Validation loss: 2.656928338835218

Epoch: 5| Step: 9
Training loss: 1.6060463267826282
Validation loss: 2.6373370358338164

Epoch: 5| Step: 10
Training loss: 1.2474106195113694
Validation loss: 2.6307366499180644

Epoch: 268| Step: 0
Training loss: 1.1213415848870265
Validation loss: 2.638548871061483

Epoch: 5| Step: 1
Training loss: 1.5941112333325616
Validation loss: 2.6577971265179343

Epoch: 5| Step: 2
Training loss: 1.1792197405370077
Validation loss: 2.6468151700556795

Epoch: 5| Step: 3
Training loss: 1.0298004945107415
Validation loss: 2.640909501819697

Epoch: 5| Step: 4
Training loss: 1.3575441154491537
Validation loss: 2.6226709232170764

Epoch: 5| Step: 5
Training loss: 1.1878915442400773
Validation loss: 2.631994728099899

Epoch: 5| Step: 6
Training loss: 1.4055393542653118
Validation loss: 2.6102464927744387

Epoch: 5| Step: 7
Training loss: 1.329894648373357
Validation loss: 2.6002510517540047

Epoch: 5| Step: 8
Training loss: 1.2069397925631231
Validation loss: 2.588790439560741

Epoch: 5| Step: 9
Training loss: 1.8122686041088722
Validation loss: 2.616871604656152

Epoch: 5| Step: 10
Training loss: 1.4077061213905548
Validation loss: 2.62596149287944

Epoch: 269| Step: 0
Training loss: 1.5393123520723244
Validation loss: 2.635799062284454

Epoch: 5| Step: 1
Training loss: 1.3667732265069534
Validation loss: 2.5771369072269867

Epoch: 5| Step: 2
Training loss: 1.364430465095085
Validation loss: 2.6124712375698884

Epoch: 5| Step: 3
Training loss: 1.0109939040614326
Validation loss: 2.5927733831179878

Epoch: 5| Step: 4
Training loss: 1.03324062228891
Validation loss: 2.584581623967716

Epoch: 5| Step: 5
Training loss: 1.5556203832439057
Validation loss: 2.5889584953926157

Epoch: 5| Step: 6
Training loss: 1.2046920677326058
Validation loss: 2.5956398920508894

Epoch: 5| Step: 7
Training loss: 1.5065391579548453
Validation loss: 2.584968501582782

Epoch: 5| Step: 8
Training loss: 1.2184059439929287
Validation loss: 2.5759107481060592

Epoch: 5| Step: 9
Training loss: 1.5823581687441324
Validation loss: 2.5685815154950373

Epoch: 5| Step: 10
Training loss: 1.1144167279418147
Validation loss: 2.5925154561780266

Epoch: 270| Step: 0
Training loss: 0.9277538417982296
Validation loss: 2.5588107099353885

Epoch: 5| Step: 1
Training loss: 1.0739158064484873
Validation loss: 2.584940794934821

Epoch: 5| Step: 2
Training loss: 1.256468439801042
Validation loss: 2.60207094457061

Epoch: 5| Step: 3
Training loss: 1.0608911113681996
Validation loss: 2.627608072544315

Epoch: 5| Step: 4
Training loss: 1.4558106901740349
Validation loss: 2.613038676552985

Epoch: 5| Step: 5
Training loss: 1.1937612802661575
Validation loss: 2.645010709759694

Epoch: 5| Step: 6
Training loss: 1.2628022729072017
Validation loss: 2.649518463848933

Epoch: 5| Step: 7
Training loss: 1.1932696169797787
Validation loss: 2.648775670131797

Epoch: 5| Step: 8
Training loss: 1.4546838418195478
Validation loss: 2.6608187313881655

Epoch: 5| Step: 9
Training loss: 1.220123983712013
Validation loss: 2.671110905444732

Epoch: 5| Step: 10
Training loss: 2.2284946557679093
Validation loss: 2.6486855715988473

Epoch: 271| Step: 0
Training loss: 1.1565441066842963
Validation loss: 2.6030635881499085

Epoch: 5| Step: 1
Training loss: 1.6959579575069017
Validation loss: 2.5970625754192636

Epoch: 5| Step: 2
Training loss: 1.570471153025923
Validation loss: 2.570150388768299

Epoch: 5| Step: 3
Training loss: 0.895583520848502
Validation loss: 2.563440262919837

Epoch: 5| Step: 4
Training loss: 1.1773603107829227
Validation loss: 2.5418873833478925

Epoch: 5| Step: 5
Training loss: 1.3403517313414497
Validation loss: 2.53987942385282

Epoch: 5| Step: 6
Training loss: 1.0724268168487479
Validation loss: 2.5747845310374142

Epoch: 5| Step: 7
Training loss: 1.42257740152087
Validation loss: 2.571806018080525

Epoch: 5| Step: 8
Training loss: 1.6004054658446998
Validation loss: 2.605094691808321

Epoch: 5| Step: 9
Training loss: 1.2019092808445186
Validation loss: 2.61700392868894

Epoch: 5| Step: 10
Training loss: 1.211673143956337
Validation loss: 2.5687594114655683

Epoch: 272| Step: 0
Training loss: 1.3966705411585658
Validation loss: 2.5599897180884006

Epoch: 5| Step: 1
Training loss: 1.5469916713912069
Validation loss: 2.5848583515945416

Epoch: 5| Step: 2
Training loss: 0.5703648843614387
Validation loss: 2.6118040037863035

Epoch: 5| Step: 3
Training loss: 1.347451014716508
Validation loss: 2.634873062042949

Epoch: 5| Step: 4
Training loss: 1.6204178101795597
Validation loss: 2.6663801734086943

Epoch: 5| Step: 5
Training loss: 1.0330947790323932
Validation loss: 2.665262198211387

Epoch: 5| Step: 6
Training loss: 1.0697277170077186
Validation loss: 2.6524467868096195

Epoch: 5| Step: 7
Training loss: 1.1985953136320013
Validation loss: 2.6393970707933065

Epoch: 5| Step: 8
Training loss: 1.189018984586107
Validation loss: 2.693043415879133

Epoch: 5| Step: 9
Training loss: 1.5255496519767433
Validation loss: 2.677192543713051

Epoch: 5| Step: 10
Training loss: 1.593842971184371
Validation loss: 2.6577729136840347

Epoch: 273| Step: 0
Training loss: 1.191424010097519
Validation loss: 2.6494366719412135

Epoch: 5| Step: 1
Training loss: 1.519131880107496
Validation loss: 2.613460147703116

Epoch: 5| Step: 2
Training loss: 1.1403364051577503
Validation loss: 2.622509196039387

Epoch: 5| Step: 3
Training loss: 1.0312851986513412
Validation loss: 2.5942451418578734

Epoch: 5| Step: 4
Training loss: 1.557064137587595
Validation loss: 2.5872740828578533

Epoch: 5| Step: 5
Training loss: 1.1470469665489893
Validation loss: 2.6192001966474625

Epoch: 5| Step: 6
Training loss: 1.1000399517260142
Validation loss: 2.5917324942793925

Epoch: 5| Step: 7
Training loss: 0.9269928548716507
Validation loss: 2.611867295929309

Epoch: 5| Step: 8
Training loss: 1.4915569630921106
Validation loss: 2.634307597481939

Epoch: 5| Step: 9
Training loss: 1.274119188826707
Validation loss: 2.6132477229755398

Epoch: 5| Step: 10
Training loss: 1.6310428356296887
Validation loss: 2.589367245099198

Epoch: 274| Step: 0
Training loss: 1.180635589180547
Validation loss: 2.578880240704635

Epoch: 5| Step: 1
Training loss: 0.616377117401676
Validation loss: 2.5556844618899905

Epoch: 5| Step: 2
Training loss: 1.361287974308705
Validation loss: 2.5998152517139217

Epoch: 5| Step: 3
Training loss: 1.1879042389129402
Validation loss: 2.5759197067126682

Epoch: 5| Step: 4
Training loss: 1.3787040670288289
Validation loss: 2.5818938519610524

Epoch: 5| Step: 5
Training loss: 1.781282859633006
Validation loss: 2.5421729374559154

Epoch: 5| Step: 6
Training loss: 1.0912380255427792
Validation loss: 2.571553106148179

Epoch: 5| Step: 7
Training loss: 1.162152662993667
Validation loss: 2.5742956933610253

Epoch: 5| Step: 8
Training loss: 1.4589681969170811
Validation loss: 2.573547529723994

Epoch: 5| Step: 9
Training loss: 0.7806471978628553
Validation loss: 2.5951598707172643

Epoch: 5| Step: 10
Training loss: 1.6489939541402254
Validation loss: 2.5617535432073346

Epoch: 275| Step: 0
Training loss: 0.9087413874536805
Validation loss: 2.5766270725530096

Epoch: 5| Step: 1
Training loss: 1.2082618933419285
Validation loss: 2.5336913308693796

Epoch: 5| Step: 2
Training loss: 1.4553251939989515
Validation loss: 2.5628090578793774

Epoch: 5| Step: 3
Training loss: 0.8494106016353888
Validation loss: 2.5616731507700723

Epoch: 5| Step: 4
Training loss: 1.427985674115723
Validation loss: 2.5236391645818457

Epoch: 5| Step: 5
Training loss: 1.098683863831233
Validation loss: 2.584896049315941

Epoch: 5| Step: 6
Training loss: 1.383994981605053
Validation loss: 2.5633494922182973

Epoch: 5| Step: 7
Training loss: 1.3504296555091104
Validation loss: 2.538402401521204

Epoch: 5| Step: 8
Training loss: 1.2011956933614105
Validation loss: 2.5466695099052212

Epoch: 5| Step: 9
Training loss: 1.4935164201138393
Validation loss: 2.602314789609538

Epoch: 5| Step: 10
Training loss: 1.3366539355850544
Validation loss: 2.592317961000303

Epoch: 276| Step: 0
Training loss: 1.2061793706900559
Validation loss: 2.6267143097348233

Epoch: 5| Step: 1
Training loss: 1.0379762636458563
Validation loss: 2.628325032843193

Epoch: 5| Step: 2
Training loss: 1.3735247413953706
Validation loss: 2.614307705906302

Epoch: 5| Step: 3
Training loss: 1.4916964217189408
Validation loss: 2.5965972910642234

Epoch: 5| Step: 4
Training loss: 1.567294736865345
Validation loss: 2.575135975752103

Epoch: 5| Step: 5
Training loss: 1.2153799462135872
Validation loss: 2.5623520398986614

Epoch: 5| Step: 6
Training loss: 0.9937610013820675
Validation loss: 2.571594886854929

Epoch: 5| Step: 7
Training loss: 0.8113187125426348
Validation loss: 2.5734690876542636

Epoch: 5| Step: 8
Training loss: 1.3272015222033693
Validation loss: 2.586402890099947

Epoch: 5| Step: 9
Training loss: 1.090725996265255
Validation loss: 2.569758750325991

Epoch: 5| Step: 10
Training loss: 1.4015985490634673
Validation loss: 2.599048130020369

Epoch: 277| Step: 0
Training loss: 0.9124717564327041
Validation loss: 2.6182971838236746

Epoch: 5| Step: 1
Training loss: 1.7450203892738112
Validation loss: 2.603070797279778

Epoch: 5| Step: 2
Training loss: 1.2405526301033485
Validation loss: 2.6059713513373732

Epoch: 5| Step: 3
Training loss: 1.4911730448586893
Validation loss: 2.6348504794164858

Epoch: 5| Step: 4
Training loss: 1.2990213121423468
Validation loss: 2.579712505200381

Epoch: 5| Step: 5
Training loss: 1.1598090991425518
Validation loss: 2.6105044448420025

Epoch: 5| Step: 6
Training loss: 1.3093289715454055
Validation loss: 2.5526782144662663

Epoch: 5| Step: 7
Training loss: 0.36503201759034953
Validation loss: 2.576512542659979

Epoch: 5| Step: 8
Training loss: 1.2026416253420769
Validation loss: 2.5380023004306858

Epoch: 5| Step: 9
Training loss: 1.4496571168307952
Validation loss: 2.5561635639993456

Epoch: 5| Step: 10
Training loss: 0.9209841934032289
Validation loss: 2.5332732081227136

Epoch: 278| Step: 0
Training loss: 0.8771663483018663
Validation loss: 2.5488985368671844

Epoch: 5| Step: 1
Training loss: 1.4055504224371043
Validation loss: 2.5721682547387115

Epoch: 5| Step: 2
Training loss: 1.5774997945746092
Validation loss: 2.6048924441738257

Epoch: 5| Step: 3
Training loss: 1.2330765957426661
Validation loss: 2.6189638880673676

Epoch: 5| Step: 4
Training loss: 0.9694209697751073
Validation loss: 2.6142042161596137

Epoch: 5| Step: 5
Training loss: 0.6860802686527001
Validation loss: 2.6027047560572094

Epoch: 5| Step: 6
Training loss: 1.3447245678855713
Validation loss: 2.5935798368790404

Epoch: 5| Step: 7
Training loss: 1.455210020500776
Validation loss: 2.589692539075895

Epoch: 5| Step: 8
Training loss: 1.3754532673813828
Validation loss: 2.558546945431397

Epoch: 5| Step: 9
Training loss: 1.1991511521562965
Validation loss: 2.560535454192112

Epoch: 5| Step: 10
Training loss: 0.9379096090039089
Validation loss: 2.544400374150341

Epoch: 279| Step: 0
Training loss: 0.925194405411736
Validation loss: 2.5409646879570387

Epoch: 5| Step: 1
Training loss: 1.1273110811254519
Validation loss: 2.5566745584305175

Epoch: 5| Step: 2
Training loss: 1.5785118610853572
Validation loss: 2.5462656908463353

Epoch: 5| Step: 3
Training loss: 1.446708046691965
Validation loss: 2.5892398751165375

Epoch: 5| Step: 4
Training loss: 0.9941322910881344
Validation loss: 2.608845161365762

Epoch: 5| Step: 5
Training loss: 1.2362190668538695
Validation loss: 2.6211212730402287

Epoch: 5| Step: 6
Training loss: 0.7653034858593321
Validation loss: 2.6176220379610595

Epoch: 5| Step: 7
Training loss: 1.4504409119682635
Validation loss: 2.613860127646123

Epoch: 5| Step: 8
Training loss: 1.522680319394725
Validation loss: 2.599916958054641

Epoch: 5| Step: 9
Training loss: 1.0635698205781456
Validation loss: 2.566315107702711

Epoch: 5| Step: 10
Training loss: 0.9069118713623213
Validation loss: 2.5827539775448587

Epoch: 280| Step: 0
Training loss: 1.099932011757357
Validation loss: 2.5659910013334253

Epoch: 5| Step: 1
Training loss: 1.0923339396306173
Validation loss: 2.5900773467519485

Epoch: 5| Step: 2
Training loss: 1.31072396504595
Validation loss: 2.5780312996869132

Epoch: 5| Step: 3
Training loss: 1.0461441449539755
Validation loss: 2.603904474328821

Epoch: 5| Step: 4
Training loss: 1.3145306636619007
Validation loss: 2.5768029724757695

Epoch: 5| Step: 5
Training loss: 1.1081557760251888
Validation loss: 2.5859794418740036

Epoch: 5| Step: 6
Training loss: 1.5696104387630316
Validation loss: 2.596589296821046

Epoch: 5| Step: 7
Training loss: 0.996643453272405
Validation loss: 2.5740555322745435

Epoch: 5| Step: 8
Training loss: 1.4594953630301197
Validation loss: 2.582579559989798

Epoch: 5| Step: 9
Training loss: 1.0862680384956627
Validation loss: 2.57720186941087

Epoch: 5| Step: 10
Training loss: 1.0515884645609268
Validation loss: 2.548493407176231

Epoch: 281| Step: 0
Training loss: 1.028579317026694
Validation loss: 2.5922329624001947

Epoch: 5| Step: 1
Training loss: 1.0448909576690666
Validation loss: 2.6024794414441494

Epoch: 5| Step: 2
Training loss: 1.296669817400114
Validation loss: 2.5937858665053217

Epoch: 5| Step: 3
Training loss: 1.1892585783210603
Validation loss: 2.5778578285754556

Epoch: 5| Step: 4
Training loss: 1.1877908350517556
Validation loss: 2.583063367206693

Epoch: 5| Step: 5
Training loss: 1.166732133436348
Validation loss: 2.5591427199468466

Epoch: 5| Step: 6
Training loss: 1.2406040872113249
Validation loss: 2.560854986308609

Epoch: 5| Step: 7
Training loss: 1.5121314301159738
Validation loss: 2.5578747096314878

Epoch: 5| Step: 8
Training loss: 0.9390964901781873
Validation loss: 2.551286644273489

Epoch: 5| Step: 9
Training loss: 1.377468407713461
Validation loss: 2.547932613398933

Epoch: 5| Step: 10
Training loss: 1.1498300323103496
Validation loss: 2.528689038065868

Epoch: 282| Step: 0
Training loss: 0.9145350090821641
Validation loss: 2.5379937640462065

Epoch: 5| Step: 1
Training loss: 1.1552000175614765
Validation loss: 2.532850567929513

Epoch: 5| Step: 2
Training loss: 1.2722174293635087
Validation loss: 2.6064160666462888

Epoch: 5| Step: 3
Training loss: 1.246851197591576
Validation loss: 2.5909298439098833

Epoch: 5| Step: 4
Training loss: 0.8457308229487436
Validation loss: 2.613650046348465

Epoch: 5| Step: 5
Training loss: 1.8343703053818892
Validation loss: 2.593063738133568

Epoch: 5| Step: 6
Training loss: 1.0571355594839709
Validation loss: 2.582021672189794

Epoch: 5| Step: 7
Training loss: 0.8012911034097187
Validation loss: 2.593999446176777

Epoch: 5| Step: 8
Training loss: 1.3264383714021741
Validation loss: 2.5812935776594936

Epoch: 5| Step: 9
Training loss: 1.1940836854486432
Validation loss: 2.574146972165443

Epoch: 5| Step: 10
Training loss: 0.9789073411306768
Validation loss: 2.564472129906369

Epoch: 283| Step: 0
Training loss: 1.259633375219689
Validation loss: 2.5676685095452805

Epoch: 5| Step: 1
Training loss: 1.424037169716097
Validation loss: 2.5434770956388983

Epoch: 5| Step: 2
Training loss: 1.3894048760171105
Validation loss: 2.553136709041839

Epoch: 5| Step: 3
Training loss: 1.0723179316313367
Validation loss: 2.5059361328776664

Epoch: 5| Step: 4
Training loss: 0.8659518261828831
Validation loss: 2.531810111612217

Epoch: 5| Step: 5
Training loss: 0.9171772892918117
Validation loss: 2.529068631175771

Epoch: 5| Step: 6
Training loss: 1.0100646175827093
Validation loss: 2.525725077275867

Epoch: 5| Step: 7
Training loss: 1.2075686446713176
Validation loss: 2.5412614527280435

Epoch: 5| Step: 8
Training loss: 1.427013961702306
Validation loss: 2.5683837819593918

Epoch: 5| Step: 9
Training loss: 1.0555852954143878
Validation loss: 2.565250014589625

Epoch: 5| Step: 10
Training loss: 1.0371196049474867
Validation loss: 2.5509278391093675

Epoch: 284| Step: 0
Training loss: 0.9679215488209445
Validation loss: 2.5469924458795203

Epoch: 5| Step: 1
Training loss: 1.3208923872172171
Validation loss: 2.518898824634328

Epoch: 5| Step: 2
Training loss: 1.093502670661585
Validation loss: 2.5118815133083827

Epoch: 5| Step: 3
Training loss: 0.8697288665638166
Validation loss: 2.507130737680569

Epoch: 5| Step: 4
Training loss: 1.073496627844963
Validation loss: 2.4828175766963705

Epoch: 5| Step: 5
Training loss: 1.2484676505447736
Validation loss: 2.568706797978097

Epoch: 5| Step: 6
Training loss: 1.0132097135187392
Validation loss: 2.554508183492396

Epoch: 5| Step: 7
Training loss: 1.2199382857832153
Validation loss: 2.5513517120042435

Epoch: 5| Step: 8
Training loss: 0.9649987656086355
Validation loss: 2.5494718938146823

Epoch: 5| Step: 9
Training loss: 1.2386120856660225
Validation loss: 2.5873477021264653

Epoch: 5| Step: 10
Training loss: 1.6495972662049292
Validation loss: 2.5833387401284735

Epoch: 285| Step: 0
Training loss: 1.0440153093129008
Validation loss: 2.575522613416942

Epoch: 5| Step: 1
Training loss: 1.0702504049512902
Validation loss: 2.57809693938665

Epoch: 5| Step: 2
Training loss: 0.9902031647167204
Validation loss: 2.619969903900973

Epoch: 5| Step: 3
Training loss: 1.4363781241563134
Validation loss: 2.5492831597711847

Epoch: 5| Step: 4
Training loss: 1.1900992807278272
Validation loss: 2.570980652067929

Epoch: 5| Step: 5
Training loss: 1.389311781185849
Validation loss: 2.5597124205630006

Epoch: 5| Step: 6
Training loss: 1.076796999169316
Validation loss: 2.5607050229724617

Epoch: 5| Step: 7
Training loss: 0.788594399775628
Validation loss: 2.5611627232249963

Epoch: 5| Step: 8
Training loss: 1.0890017849650961
Validation loss: 2.51700820453877

Epoch: 5| Step: 9
Training loss: 0.9378384297188767
Validation loss: 2.5399467055734015

Epoch: 5| Step: 10
Training loss: 1.5824726760457883
Validation loss: 2.5612442917682285

Epoch: 286| Step: 0
Training loss: 0.9302869835411346
Validation loss: 2.527984786616416

Epoch: 5| Step: 1
Training loss: 1.2448190608927376
Validation loss: 2.527957123470198

Epoch: 5| Step: 2
Training loss: 1.168392551044199
Validation loss: 2.548721975478958

Epoch: 5| Step: 3
Training loss: 1.4874702707092657
Validation loss: 2.4989933350844176

Epoch: 5| Step: 4
Training loss: 1.4816398719164148
Validation loss: 2.522330523343404

Epoch: 5| Step: 5
Training loss: 1.140686974082902
Validation loss: 2.5146759888696475

Epoch: 5| Step: 6
Training loss: 0.7918369503258462
Validation loss: 2.4942943560214643

Epoch: 5| Step: 7
Training loss: 1.2124424104680094
Validation loss: 2.5210216009187385

Epoch: 5| Step: 8
Training loss: 1.0182888602135856
Validation loss: 2.5207740724520704

Epoch: 5| Step: 9
Training loss: 0.9057211483817446
Validation loss: 2.4945435721859206

Epoch: 5| Step: 10
Training loss: 1.1231794461494402
Validation loss: 2.5289854784704926

Epoch: 287| Step: 0
Training loss: 1.0006344689821238
Validation loss: 2.534661931008099

Epoch: 5| Step: 1
Training loss: 0.8243681785758226
Validation loss: 2.523760242955065

Epoch: 5| Step: 2
Training loss: 1.2260637180329903
Validation loss: 2.530839986850512

Epoch: 5| Step: 3
Training loss: 1.0382153492286181
Validation loss: 2.5453751747520257

Epoch: 5| Step: 4
Training loss: 1.1951827433848092
Validation loss: 2.533625266228986

Epoch: 5| Step: 5
Training loss: 1.2561382262954945
Validation loss: 2.5484966563719915

Epoch: 5| Step: 6
Training loss: 1.1052307304008901
Validation loss: 2.5342096405405674

Epoch: 5| Step: 7
Training loss: 1.09054324218005
Validation loss: 2.5391328171805205

Epoch: 5| Step: 8
Training loss: 1.1489584642942232
Validation loss: 2.547543176650227

Epoch: 5| Step: 9
Training loss: 1.536539245888791
Validation loss: 2.5564781762875444

Epoch: 5| Step: 10
Training loss: 1.091017115366922
Validation loss: 2.525499362071944

Epoch: 288| Step: 0
Training loss: 1.1912759178040084
Validation loss: 2.537177026233792

Epoch: 5| Step: 1
Training loss: 1.3465561951909957
Validation loss: 2.520495014137759

Epoch: 5| Step: 2
Training loss: 1.2287780772481296
Validation loss: 2.467367898308779

Epoch: 5| Step: 3
Training loss: 0.9579908892490979
Validation loss: 2.508470764445285

Epoch: 5| Step: 4
Training loss: 1.276386147017515
Validation loss: 2.49759875002946

Epoch: 5| Step: 5
Training loss: 0.8605390814152518
Validation loss: 2.5001380195255685

Epoch: 5| Step: 6
Training loss: 1.2438804558047891
Validation loss: 2.4865780117335348

Epoch: 5| Step: 7
Training loss: 0.9436382568596466
Validation loss: 2.5520610199773825

Epoch: 5| Step: 8
Training loss: 0.9054308181466642
Validation loss: 2.530966332270936

Epoch: 5| Step: 9
Training loss: 1.0207776748638997
Validation loss: 2.560309407429739

Epoch: 5| Step: 10
Training loss: 1.4446270116132036
Validation loss: 2.587265941894073

Epoch: 289| Step: 0
Training loss: 0.6743656612806714
Validation loss: 2.5750264739186854

Epoch: 5| Step: 1
Training loss: 1.3536537177030068
Validation loss: 2.613737149727058

Epoch: 5| Step: 2
Training loss: 1.5568038873959158
Validation loss: 2.5485718937111823

Epoch: 5| Step: 3
Training loss: 1.2439255940304013
Validation loss: 2.558703729150324

Epoch: 5| Step: 4
Training loss: 1.0868031187236686
Validation loss: 2.558949260221636

Epoch: 5| Step: 5
Training loss: 1.257543736525775
Validation loss: 2.4930875633341376

Epoch: 5| Step: 6
Training loss: 0.9288428179849139
Validation loss: 2.4809413494253034

Epoch: 5| Step: 7
Training loss: 0.7877640569093105
Validation loss: 2.496118264799511

Epoch: 5| Step: 8
Training loss: 1.2134198249042423
Validation loss: 2.503008603128686

Epoch: 5| Step: 9
Training loss: 1.3129016170932521
Validation loss: 2.498238041081552

Epoch: 5| Step: 10
Training loss: 0.6998231502634567
Validation loss: 2.5331188601582237

Epoch: 290| Step: 0
Training loss: 1.1355560753774065
Validation loss: 2.5142400036299546

Epoch: 5| Step: 1
Training loss: 1.134637139247345
Validation loss: 2.6001062421374344

Epoch: 5| Step: 2
Training loss: 0.7796638408733085
Validation loss: 2.558730365306271

Epoch: 5| Step: 3
Training loss: 1.0104179120138037
Validation loss: 2.5268356335621225

Epoch: 5| Step: 4
Training loss: 1.0194883374065797
Validation loss: 2.5492738998952253

Epoch: 5| Step: 5
Training loss: 1.2743526984747446
Validation loss: 2.5354914272135427

Epoch: 5| Step: 6
Training loss: 1.2539037781688058
Validation loss: 2.518686819865577

Epoch: 5| Step: 7
Training loss: 1.0530981450944132
Validation loss: 2.5689416770598634

Epoch: 5| Step: 8
Training loss: 1.3473705928853217
Validation loss: 2.540572427318382

Epoch: 5| Step: 9
Training loss: 0.849812871305723
Validation loss: 2.573226456369224

Epoch: 5| Step: 10
Training loss: 1.4816117114648508
Validation loss: 2.5457504238686326

Epoch: 291| Step: 0
Training loss: 1.1717341020440364
Validation loss: 2.5777131095595975

Epoch: 5| Step: 1
Training loss: 0.6613362167052637
Validation loss: 2.6056730190281425

Epoch: 5| Step: 2
Training loss: 1.3319317285494034
Validation loss: 2.5711154864747368

Epoch: 5| Step: 3
Training loss: 1.0187650410296565
Validation loss: 2.593191119997359

Epoch: 5| Step: 4
Training loss: 1.0757844369435252
Validation loss: 2.6053660003936336

Epoch: 5| Step: 5
Training loss: 0.6190997570521057
Validation loss: 2.612816302763932

Epoch: 5| Step: 6
Training loss: 1.164067108349991
Validation loss: 2.588950896426798

Epoch: 5| Step: 7
Training loss: 1.0842460247808672
Validation loss: 2.556029996960492

Epoch: 5| Step: 8
Training loss: 1.15920344314722
Validation loss: 2.56033462006739

Epoch: 5| Step: 9
Training loss: 1.0267695573755813
Validation loss: 2.5508783803721413

Epoch: 5| Step: 10
Training loss: 1.6988167122716067
Validation loss: 2.5495168297731357

Epoch: 292| Step: 0
Training loss: 0.823569344781549
Validation loss: 2.526570269113526

Epoch: 5| Step: 1
Training loss: 1.149658177202232
Validation loss: 2.518718582633621

Epoch: 5| Step: 2
Training loss: 0.9735132448170223
Validation loss: 2.5148246050800025

Epoch: 5| Step: 3
Training loss: 1.2245488737453394
Validation loss: 2.530875113033856

Epoch: 5| Step: 4
Training loss: 1.017625101070495
Validation loss: 2.508457892916033

Epoch: 5| Step: 5
Training loss: 1.382512119233195
Validation loss: 2.509300368906652

Epoch: 5| Step: 6
Training loss: 0.9948098978232773
Validation loss: 2.514921334139164

Epoch: 5| Step: 7
Training loss: 1.204599443079658
Validation loss: 2.5304806845578374

Epoch: 5| Step: 8
Training loss: 0.9222027793970625
Validation loss: 2.5327945596419235

Epoch: 5| Step: 9
Training loss: 1.444715716899013
Validation loss: 2.489784293023718

Epoch: 5| Step: 10
Training loss: 0.8011383004967539
Validation loss: 2.519040892123703

Epoch: 293| Step: 0
Training loss: 0.8403305417213338
Validation loss: 2.4978700603928803

Epoch: 5| Step: 1
Training loss: 1.4448501259716822
Validation loss: 2.51676841150684

Epoch: 5| Step: 2
Training loss: 0.9026065460250026
Validation loss: 2.5309633046816926

Epoch: 5| Step: 3
Training loss: 1.3250512850930831
Validation loss: 2.523546819015248

Epoch: 5| Step: 4
Training loss: 0.8390052335437231
Validation loss: 2.4858211808031374

Epoch: 5| Step: 5
Training loss: 1.3130803414639327
Validation loss: 2.492990245743064

Epoch: 5| Step: 6
Training loss: 0.6763012159065576
Validation loss: 2.516210306159546

Epoch: 5| Step: 7
Training loss: 1.1827817340916258
Validation loss: 2.485256119564072

Epoch: 5| Step: 8
Training loss: 1.1755773931554991
Validation loss: 2.486559733219181

Epoch: 5| Step: 9
Training loss: 0.9954907256230382
Validation loss: 2.5063665836756894

Epoch: 5| Step: 10
Training loss: 1.0175839824837412
Validation loss: 2.486770192451588

Epoch: 294| Step: 0
Training loss: 0.9924626907427437
Validation loss: 2.4754231748394524

Epoch: 5| Step: 1
Training loss: 1.098495705420356
Validation loss: 2.4907282282284866

Epoch: 5| Step: 2
Training loss: 1.4496679715129996
Validation loss: 2.470505532220193

Epoch: 5| Step: 3
Training loss: 0.6962036893705207
Validation loss: 2.4970328093782226

Epoch: 5| Step: 4
Training loss: 0.8501108377783327
Validation loss: 2.508562558215456

Epoch: 5| Step: 5
Training loss: 1.3185365910984153
Validation loss: 2.5266807898665866

Epoch: 5| Step: 6
Training loss: 0.868482533454401
Validation loss: 2.537939947597168

Epoch: 5| Step: 7
Training loss: 1.0909105774117949
Validation loss: 2.5468704562810696

Epoch: 5| Step: 8
Training loss: 0.871294383392129
Validation loss: 2.5026225076048387

Epoch: 5| Step: 9
Training loss: 1.143938555574579
Validation loss: 2.502738447510332

Epoch: 5| Step: 10
Training loss: 1.2620677170155188
Validation loss: 2.495630319634656

Epoch: 295| Step: 0
Training loss: 1.2131919302305039
Validation loss: 2.503436115471721

Epoch: 5| Step: 1
Training loss: 1.167431098407835
Validation loss: 2.542697431872309

Epoch: 5| Step: 2
Training loss: 1.196769823278722
Validation loss: 2.4733079605696124

Epoch: 5| Step: 3
Training loss: 0.9548844841302451
Validation loss: 2.493537253666836

Epoch: 5| Step: 4
Training loss: 1.1532110538782514
Validation loss: 2.486824382768715

Epoch: 5| Step: 5
Training loss: 0.8873278840492619
Validation loss: 2.524783357528891

Epoch: 5| Step: 6
Training loss: 1.125726677063592
Validation loss: 2.489632710578898

Epoch: 5| Step: 7
Training loss: 1.401540116861795
Validation loss: 2.5155453846095215

Epoch: 5| Step: 8
Training loss: 1.0546264630775843
Validation loss: 2.505012510864188

Epoch: 5| Step: 9
Training loss: 0.7026046947103052
Validation loss: 2.5122657929970322

Epoch: 5| Step: 10
Training loss: 0.684732915746648
Validation loss: 2.5069324665565356

Epoch: 296| Step: 0
Training loss: 1.3821400445928504
Validation loss: 2.501936232468412

Epoch: 5| Step: 1
Training loss: 0.9468328686899761
Validation loss: 2.534904167742623

Epoch: 5| Step: 2
Training loss: 0.8868297557836315
Validation loss: 2.5865594968244476

Epoch: 5| Step: 3
Training loss: 1.1129146574671833
Validation loss: 2.5502041341912474

Epoch: 5| Step: 4
Training loss: 1.0747896654041753
Validation loss: 2.5178720416326947

Epoch: 5| Step: 5
Training loss: 1.3510108659929896
Validation loss: 2.4876349121270502

Epoch: 5| Step: 6
Training loss: 1.1480478676775119
Validation loss: 2.5095819842039724

Epoch: 5| Step: 7
Training loss: 0.8721487046364068
Validation loss: 2.4923333694870613

Epoch: 5| Step: 8
Training loss: 1.0134308809669441
Validation loss: 2.4880839589480632

Epoch: 5| Step: 9
Training loss: 1.050401016132883
Validation loss: 2.4836228745777698

Epoch: 5| Step: 10
Training loss: 0.772711480522449
Validation loss: 2.467833090527597

Epoch: 297| Step: 0
Training loss: 0.6292076099623071
Validation loss: 2.46749005059983

Epoch: 5| Step: 1
Training loss: 1.141783557022002
Validation loss: 2.464044895497175

Epoch: 5| Step: 2
Training loss: 0.989400870249427
Validation loss: 2.4533306584532006

Epoch: 5| Step: 3
Training loss: 1.1787653976033463
Validation loss: 2.4628170109412117

Epoch: 5| Step: 4
Training loss: 1.2699955487361005
Validation loss: 2.4993176318614876

Epoch: 5| Step: 5
Training loss: 0.9935860876539885
Validation loss: 2.467672616314915

Epoch: 5| Step: 6
Training loss: 0.9437847876295052
Validation loss: 2.5225604053195503

Epoch: 5| Step: 7
Training loss: 1.2146982185552322
Validation loss: 2.5301069511827565

Epoch: 5| Step: 8
Training loss: 1.4028305016524902
Validation loss: 2.529492153608556

Epoch: 5| Step: 9
Training loss: 0.6705320154450503
Validation loss: 2.5153935378879018

Epoch: 5| Step: 10
Training loss: 0.9212433218746295
Validation loss: 2.513215022634109

Epoch: 298| Step: 0
Training loss: 0.8916502957014728
Validation loss: 2.4985995543774644

Epoch: 5| Step: 1
Training loss: 0.8711869741600109
Validation loss: 2.4766949504695326

Epoch: 5| Step: 2
Training loss: 0.9548633544587264
Validation loss: 2.471286997137364

Epoch: 5| Step: 3
Training loss: 1.424348210295844
Validation loss: 2.4764760718742376

Epoch: 5| Step: 4
Training loss: 1.158971830530938
Validation loss: 2.4866024100261743

Epoch: 5| Step: 5
Training loss: 0.7945022412671213
Validation loss: 2.5005512101593426

Epoch: 5| Step: 6
Training loss: 1.1713040804921928
Validation loss: 2.4993306391887233

Epoch: 5| Step: 7
Training loss: 1.026428975750754
Validation loss: 2.4733300363383623

Epoch: 5| Step: 8
Training loss: 1.1605868070416263
Validation loss: 2.4876368031918346

Epoch: 5| Step: 9
Training loss: 0.5456102460109591
Validation loss: 2.504326364500328

Epoch: 5| Step: 10
Training loss: 1.2265179376950555
Validation loss: 2.471531673793141

Epoch: 299| Step: 0
Training loss: 1.1112857535653333
Validation loss: 2.460196546249043

Epoch: 5| Step: 1
Training loss: 1.0696105883020746
Validation loss: 2.4905132304699804

Epoch: 5| Step: 2
Training loss: 1.276366160128938
Validation loss: 2.4561282328553364

Epoch: 5| Step: 3
Training loss: 0.9031343175810002
Validation loss: 2.5029431021442843

Epoch: 5| Step: 4
Training loss: 0.8773477936377208
Validation loss: 2.4734184597473097

Epoch: 5| Step: 5
Training loss: 1.0910557942656103
Validation loss: 2.510949594774963

Epoch: 5| Step: 6
Training loss: 0.848908549684288
Validation loss: 2.4944224733848452

Epoch: 5| Step: 7
Training loss: 1.0518216792898447
Validation loss: 2.4984389384241967

Epoch: 5| Step: 8
Training loss: 1.2182352984359577
Validation loss: 2.4798598574631954

Epoch: 5| Step: 9
Training loss: 1.0219943522243131
Validation loss: 2.5018554211426354

Epoch: 5| Step: 10
Training loss: 0.8564682786704797
Validation loss: 2.5046298031210683

Epoch: 300| Step: 0
Training loss: 1.0751958668609494
Validation loss: 2.4864726617658897

Epoch: 5| Step: 1
Training loss: 0.8500873843322367
Validation loss: 2.5045085113118524

Epoch: 5| Step: 2
Training loss: 1.4798507809806758
Validation loss: 2.4699358830112286

Epoch: 5| Step: 3
Training loss: 0.9271411484824963
Validation loss: 2.458645116919173

Epoch: 5| Step: 4
Training loss: 0.950811925062536
Validation loss: 2.4902790055446764

Epoch: 5| Step: 5
Training loss: 1.1448378949583766
Validation loss: 2.485980529385943

Epoch: 5| Step: 6
Training loss: 1.1149867863577763
Validation loss: 2.4892841510657537

Epoch: 5| Step: 7
Training loss: 1.1049421694022672
Validation loss: 2.4643145772708226

Epoch: 5| Step: 8
Training loss: 0.7463077418034527
Validation loss: 2.46911740480008

Epoch: 5| Step: 9
Training loss: 0.7895780710801548
Validation loss: 2.464435552497926

Epoch: 5| Step: 10
Training loss: 0.8373452214368508
Validation loss: 2.461332605029907

Epoch: 301| Step: 0
Training loss: 1.0355138197105156
Validation loss: 2.4994258252025525

Epoch: 5| Step: 1
Training loss: 1.1582384795635512
Validation loss: 2.434325722587103

Epoch: 5| Step: 2
Training loss: 1.0919902268625643
Validation loss: 2.4405127155611637

Epoch: 5| Step: 3
Training loss: 0.7704765593907167
Validation loss: 2.4586552248770333

Epoch: 5| Step: 4
Training loss: 1.0775612725628736
Validation loss: 2.469830226953124

Epoch: 5| Step: 5
Training loss: 0.9683690091015879
Validation loss: 2.4768530308813466

Epoch: 5| Step: 6
Training loss: 0.898274216119257
Validation loss: 2.4701626921794704

Epoch: 5| Step: 7
Training loss: 1.3111085327755276
Validation loss: 2.472525537646523

Epoch: 5| Step: 8
Training loss: 0.971646562327959
Validation loss: 2.4641835129456386

Epoch: 5| Step: 9
Training loss: 1.0755476066945422
Validation loss: 2.461671949916039

Epoch: 5| Step: 10
Training loss: 0.5628213229591874
Validation loss: 2.4191663093328266

Epoch: 302| Step: 0
Training loss: 0.8386245038992983
Validation loss: 2.461889451296718

Epoch: 5| Step: 1
Training loss: 0.7773332451345395
Validation loss: 2.431906945834818

Epoch: 5| Step: 2
Training loss: 1.1115217258116432
Validation loss: 2.439989563974945

Epoch: 5| Step: 3
Training loss: 1.0365527827233207
Validation loss: 2.4315480718334017

Epoch: 5| Step: 4
Training loss: 1.2333016859753987
Validation loss: 2.444721797302631

Epoch: 5| Step: 5
Training loss: 0.9903685650012798
Validation loss: 2.439845405797052

Epoch: 5| Step: 6
Training loss: 1.0041961251418663
Validation loss: 2.4444491396118084

Epoch: 5| Step: 7
Training loss: 1.0682155365851635
Validation loss: 2.4467076293797954

Epoch: 5| Step: 8
Training loss: 1.0920405516867586
Validation loss: 2.450332747543257

Epoch: 5| Step: 9
Training loss: 0.8877923322815272
Validation loss: 2.4847585348902292

Epoch: 5| Step: 10
Training loss: 0.9418201407268748
Validation loss: 2.4761991753544264

Epoch: 303| Step: 0
Training loss: 1.274815755509397
Validation loss: 2.4503097332534858

Epoch: 5| Step: 1
Training loss: 1.1113657215912278
Validation loss: 2.4750682716984245

Epoch: 5| Step: 2
Training loss: 0.6638523891378688
Validation loss: 2.4621020073589523

Epoch: 5| Step: 3
Training loss: 0.9428062317879757
Validation loss: 2.4805381407982297

Epoch: 5| Step: 4
Training loss: 1.2067205529185283
Validation loss: 2.5043262518950065

Epoch: 5| Step: 5
Training loss: 0.8937152989193264
Validation loss: 2.4821627464459164

Epoch: 5| Step: 6
Training loss: 0.977153629683387
Validation loss: 2.4938058699728893

Epoch: 5| Step: 7
Training loss: 1.1058347924995904
Validation loss: 2.4873115235435432

Epoch: 5| Step: 8
Training loss: 1.038922178502321
Validation loss: 2.4562580027832546

Epoch: 5| Step: 9
Training loss: 0.7282944003319263
Validation loss: 2.452858674684514

Epoch: 5| Step: 10
Training loss: 0.8989701392207821
Validation loss: 2.4315666742632165

Epoch: 304| Step: 0
Training loss: 0.7468136415057023
Validation loss: 2.468356994151352

Epoch: 5| Step: 1
Training loss: 1.016006280782014
Validation loss: 2.475130678043502

Epoch: 5| Step: 2
Training loss: 0.858805866784115
Validation loss: 2.4619828042877065

Epoch: 5| Step: 3
Training loss: 0.5471617083350502
Validation loss: 2.4439777410085783

Epoch: 5| Step: 4
Training loss: 1.0105660842585638
Validation loss: 2.453768194707235

Epoch: 5| Step: 5
Training loss: 0.9891508596282634
Validation loss: 2.4444467133041967

Epoch: 5| Step: 6
Training loss: 1.3064261176281355
Validation loss: 2.472943356417264

Epoch: 5| Step: 7
Training loss: 0.8632867735258815
Validation loss: 2.4625737212265464

Epoch: 5| Step: 8
Training loss: 1.3319125304356079
Validation loss: 2.4576822461173933

Epoch: 5| Step: 9
Training loss: 0.9489897463498832
Validation loss: 2.420986329791111

Epoch: 5| Step: 10
Training loss: 1.0314553952135126
Validation loss: 2.43824008248016

Epoch: 305| Step: 0
Training loss: 1.1291305160835368
Validation loss: 2.442915894352571

Epoch: 5| Step: 1
Training loss: 1.2003853556662891
Validation loss: 2.415032439594348

Epoch: 5| Step: 2
Training loss: 0.9062923553039994
Validation loss: 2.4191596235456374

Epoch: 5| Step: 3
Training loss: 0.8395899544416153
Validation loss: 2.4459199548948245

Epoch: 5| Step: 4
Training loss: 0.790155503565153
Validation loss: 2.4122994721860866

Epoch: 5| Step: 5
Training loss: 1.1674150666377427
Validation loss: 2.395657101035205

Epoch: 5| Step: 6
Training loss: 0.7184420630868872
Validation loss: 2.424188901156811

Epoch: 5| Step: 7
Training loss: 0.825615228657218
Validation loss: 2.417439756828717

Epoch: 5| Step: 8
Training loss: 1.1326620067734834
Validation loss: 2.441888621071555

Epoch: 5| Step: 9
Training loss: 1.2824689137816496
Validation loss: 2.4545257270874843

Epoch: 5| Step: 10
Training loss: 0.7662621785576017
Validation loss: 2.445566386905443

Epoch: 306| Step: 0
Training loss: 0.6629062684460653
Validation loss: 2.49380136525841

Epoch: 5| Step: 1
Training loss: 1.0037851817234944
Validation loss: 2.47813823612466

Epoch: 5| Step: 2
Training loss: 1.0696232936533907
Validation loss: 2.4916917542693233

Epoch: 5| Step: 3
Training loss: 1.258451642965108
Validation loss: 2.488079357322935

Epoch: 5| Step: 4
Training loss: 0.9371912765808434
Validation loss: 2.459139933699266

Epoch: 5| Step: 5
Training loss: 0.7625230504288396
Validation loss: 2.421957560126728

Epoch: 5| Step: 6
Training loss: 1.1660257463638921
Validation loss: 2.413317627466756

Epoch: 5| Step: 7
Training loss: 0.6806262756980241
Validation loss: 2.428984126441977

Epoch: 5| Step: 8
Training loss: 1.1562349473128077
Validation loss: 2.446391262714491

Epoch: 5| Step: 9
Training loss: 0.6132757587551483
Validation loss: 2.4038932561937294

Epoch: 5| Step: 10
Training loss: 1.2100457630488548
Validation loss: 2.4486772063123334

Epoch: 307| Step: 0
Training loss: 0.8704294999270542
Validation loss: 2.4343334366895037

Epoch: 5| Step: 1
Training loss: 0.8549168169258398
Validation loss: 2.416587104449485

Epoch: 5| Step: 2
Training loss: 0.9605307609878796
Validation loss: 2.425897425698161

Epoch: 5| Step: 3
Training loss: 1.1464356082247018
Validation loss: 2.4332578433125844

Epoch: 5| Step: 4
Training loss: 1.0299093027829798
Validation loss: 2.412074575861931

Epoch: 5| Step: 5
Training loss: 0.9721076674562483
Validation loss: 2.4340693719565367

Epoch: 5| Step: 6
Training loss: 0.6723001598684225
Validation loss: 2.458298541268295

Epoch: 5| Step: 7
Training loss: 1.0482079858746098
Validation loss: 2.432473292210525

Epoch: 5| Step: 8
Training loss: 1.003878878802906
Validation loss: 2.4374716194126615

Epoch: 5| Step: 9
Training loss: 0.8224434196003447
Validation loss: 2.427800857578352

Epoch: 5| Step: 10
Training loss: 1.1963413772043319
Validation loss: 2.4817734863906145

Epoch: 308| Step: 0
Training loss: 1.1758486199325895
Validation loss: 2.469392884114896

Epoch: 5| Step: 1
Training loss: 0.9754684423311437
Validation loss: 2.4504657526582307

Epoch: 5| Step: 2
Training loss: 0.9562273970282503
Validation loss: 2.487858224057807

Epoch: 5| Step: 3
Training loss: 0.644768018294006
Validation loss: 2.514454197640076

Epoch: 5| Step: 4
Training loss: 0.942599098803767
Validation loss: 2.456417953617676

Epoch: 5| Step: 5
Training loss: 0.9902002452860055
Validation loss: 2.4856270887816763

Epoch: 5| Step: 6
Training loss: 0.8326292083180312
Validation loss: 2.4855719141826653

Epoch: 5| Step: 7
Training loss: 1.1355927648677293
Validation loss: 2.5082563073310062

Epoch: 5| Step: 8
Training loss: 0.5620070257579228
Validation loss: 2.486834906064376

Epoch: 5| Step: 9
Training loss: 1.0790372112988573
Validation loss: 2.470484564389184

Epoch: 5| Step: 10
Training loss: 1.0878995556011075
Validation loss: 2.4385881248574415

Epoch: 309| Step: 0
Training loss: 0.9422180031667223
Validation loss: 2.444603636488916

Epoch: 5| Step: 1
Training loss: 1.173525449095712
Validation loss: 2.420592002014749

Epoch: 5| Step: 2
Training loss: 0.601290059014179
Validation loss: 2.434552788150513

Epoch: 5| Step: 3
Training loss: 0.8722755387148998
Validation loss: 2.433067618727375

Epoch: 5| Step: 4
Training loss: 0.8882148657479201
Validation loss: 2.4657476332626476

Epoch: 5| Step: 5
Training loss: 1.320859175147483
Validation loss: 2.440867029246235

Epoch: 5| Step: 6
Training loss: 1.018509919599076
Validation loss: 2.433769073725912

Epoch: 5| Step: 7
Training loss: 0.8489559072136098
Validation loss: 2.4580458515889307

Epoch: 5| Step: 8
Training loss: 0.7115266056916967
Validation loss: 2.4618881204759466

Epoch: 5| Step: 9
Training loss: 0.8669121451144599
Validation loss: 2.4822965794467176

Epoch: 5| Step: 10
Training loss: 1.0061733311416678
Validation loss: 2.493772009370691

Epoch: 310| Step: 0
Training loss: 0.9516227953619845
Validation loss: 2.5004061994445914

Epoch: 5| Step: 1
Training loss: 0.8251852001044587
Validation loss: 2.4650062793602703

Epoch: 5| Step: 2
Training loss: 1.0299512603486864
Validation loss: 2.524922282459443

Epoch: 5| Step: 3
Training loss: 0.9493677783663775
Validation loss: 2.4962297332854737

Epoch: 5| Step: 4
Training loss: 0.898123578499855
Validation loss: 2.4734301066087143

Epoch: 5| Step: 5
Training loss: 1.2403478855843466
Validation loss: 2.444086154107739

Epoch: 5| Step: 6
Training loss: 1.069847451414355
Validation loss: 2.4616703794503594

Epoch: 5| Step: 7
Training loss: 0.8024249443416669
Validation loss: 2.4608260340919705

Epoch: 5| Step: 8
Training loss: 1.008249469033349
Validation loss: 2.475860200068523

Epoch: 5| Step: 9
Training loss: 1.015560969755189
Validation loss: 2.419371880057693

Epoch: 5| Step: 10
Training loss: 0.6053354424189209
Validation loss: 2.4774107151564215

Epoch: 311| Step: 0
Training loss: 0.9107014737977761
Validation loss: 2.437141946431364

Epoch: 5| Step: 1
Training loss: 1.032912676825184
Validation loss: 2.460760699261309

Epoch: 5| Step: 2
Training loss: 1.227567516109422
Validation loss: 2.442572063406912

Epoch: 5| Step: 3
Training loss: 0.9248133883525163
Validation loss: 2.445774754266122

Epoch: 5| Step: 4
Training loss: 0.9873635173593056
Validation loss: 2.426014466578082

Epoch: 5| Step: 5
Training loss: 1.137401729572766
Validation loss: 2.4005188810026654

Epoch: 5| Step: 6
Training loss: 0.8786932454020734
Validation loss: 2.410120750404204

Epoch: 5| Step: 7
Training loss: 0.8439575575805605
Validation loss: 2.3816668239637573

Epoch: 5| Step: 8
Training loss: 0.8259319200446332
Validation loss: 2.3712175243060787

Epoch: 5| Step: 9
Training loss: 0.5667137363696922
Validation loss: 2.3363235192542793

Epoch: 5| Step: 10
Training loss: 0.9393127082683859
Validation loss: 2.3456616826081826

Epoch: 312| Step: 0
Training loss: 0.8973282642280367
Validation loss: 2.373811969772541

Epoch: 5| Step: 1
Training loss: 0.9525747117705896
Validation loss: 2.349447558261482

Epoch: 5| Step: 2
Training loss: 0.8050861297165055
Validation loss: 2.3954695465982048

Epoch: 5| Step: 3
Training loss: 0.8734027043544655
Validation loss: 2.386135517644175

Epoch: 5| Step: 4
Training loss: 1.0962014110762812
Validation loss: 2.4174636540423697

Epoch: 5| Step: 5
Training loss: 1.2806293100607538
Validation loss: 2.436434353767408

Epoch: 5| Step: 6
Training loss: 0.8803513578127016
Validation loss: 2.4067455431919407

Epoch: 5| Step: 7
Training loss: 0.9822731588055467
Validation loss: 2.4581449077371555

Epoch: 5| Step: 8
Training loss: 0.7856775327855486
Validation loss: 2.483784978117525

Epoch: 5| Step: 9
Training loss: 0.9766088856171178
Validation loss: 2.5037532197343846

Epoch: 5| Step: 10
Training loss: 0.6813935977187153
Validation loss: 2.497657675325409

Epoch: 313| Step: 0
Training loss: 1.1865992392357028
Validation loss: 2.4808595447203508

Epoch: 5| Step: 1
Training loss: 0.6888794714295076
Validation loss: 2.4740167495402345

Epoch: 5| Step: 2
Training loss: 0.8536525590285252
Validation loss: 2.4911226352034315

Epoch: 5| Step: 3
Training loss: 0.7715861965540652
Validation loss: 2.458030778701646

Epoch: 5| Step: 4
Training loss: 0.7873487085003447
Validation loss: 2.45685233557322

Epoch: 5| Step: 5
Training loss: 0.9005644127865625
Validation loss: 2.4693370041780187

Epoch: 5| Step: 6
Training loss: 0.43308534113100666
Validation loss: 2.443341929426722

Epoch: 5| Step: 7
Training loss: 1.2982502734622707
Validation loss: 2.4787060592458707

Epoch: 5| Step: 8
Training loss: 0.8344664777121874
Validation loss: 2.4538939492057987

Epoch: 5| Step: 9
Training loss: 1.3213380521163314
Validation loss: 2.451493815549131

Epoch: 5| Step: 10
Training loss: 0.7539825400852986
Validation loss: 2.4826252769117896

Epoch: 314| Step: 0
Training loss: 0.7985955904866839
Validation loss: 2.4754304191119423

Epoch: 5| Step: 1
Training loss: 0.7458330268077824
Validation loss: 2.4727850395451094

Epoch: 5| Step: 2
Training loss: 0.8213947241781596
Validation loss: 2.4725261514622527

Epoch: 5| Step: 3
Training loss: 1.1235243868487828
Validation loss: 2.4555394251793254

Epoch: 5| Step: 4
Training loss: 0.8537598354393022
Validation loss: 2.4174838489629606

Epoch: 5| Step: 5
Training loss: 1.1532614981232958
Validation loss: 2.444362555069395

Epoch: 5| Step: 6
Training loss: 1.0943566955743622
Validation loss: 2.4951410471321225

Epoch: 5| Step: 7
Training loss: 0.9042695537748945
Validation loss: 2.463048798263931

Epoch: 5| Step: 8
Training loss: 0.8367828301860982
Validation loss: 2.4616075464627487

Epoch: 5| Step: 9
Training loss: 0.8598888248286612
Validation loss: 2.4803726628555958

Epoch: 5| Step: 10
Training loss: 0.7723637458239412
Validation loss: 2.4554000221730528

Epoch: 315| Step: 0
Training loss: 1.0157579775099588
Validation loss: 2.447304729320165

Epoch: 5| Step: 1
Training loss: 0.8831191079063966
Validation loss: 2.474636803399

Epoch: 5| Step: 2
Training loss: 0.8315533980624414
Validation loss: 2.4228025038454626

Epoch: 5| Step: 3
Training loss: 0.9832333196005438
Validation loss: 2.4472261884991164

Epoch: 5| Step: 4
Training loss: 0.7716958058034533
Validation loss: 2.406970686075268

Epoch: 5| Step: 5
Training loss: 0.8537197959997104
Validation loss: 2.401869443633014

Epoch: 5| Step: 6
Training loss: 1.1599560702983422
Validation loss: 2.3835025535239107

Epoch: 5| Step: 7
Training loss: 1.0489417783509805
Validation loss: 2.3960796049504247

Epoch: 5| Step: 8
Training loss: 0.7273282353665124
Validation loss: 2.385980284697466

Epoch: 5| Step: 9
Training loss: 0.6464083531792469
Validation loss: 2.3710295211726993

Epoch: 5| Step: 10
Training loss: 1.0212797758694605
Validation loss: 2.3839505978857414

Epoch: 316| Step: 0
Training loss: 0.8104884115069584
Validation loss: 2.421828500206678

Epoch: 5| Step: 1
Training loss: 0.8817780772476986
Validation loss: 2.4337871409293466

Epoch: 5| Step: 2
Training loss: 1.1749227437532892
Validation loss: 2.4166508332166274

Epoch: 5| Step: 3
Training loss: 0.6344039590924897
Validation loss: 2.444020585500234

Epoch: 5| Step: 4
Training loss: 1.0078049888626655
Validation loss: 2.446794465694901

Epoch: 5| Step: 5
Training loss: 0.8142928370544281
Validation loss: 2.478730065987706

Epoch: 5| Step: 6
Training loss: 1.0962723122286744
Validation loss: 2.4501733202106206

Epoch: 5| Step: 7
Training loss: 1.0302997025310268
Validation loss: 2.4570499912909285

Epoch: 5| Step: 8
Training loss: 0.7615230211020517
Validation loss: 2.412346586058865

Epoch: 5| Step: 9
Training loss: 0.860117470181512
Validation loss: 2.4077317473024076

Epoch: 5| Step: 10
Training loss: 0.7010846522068048
Validation loss: 2.4368165338209793

Epoch: 317| Step: 0
Training loss: 0.9887815573632075
Validation loss: 2.3891621225767525

Epoch: 5| Step: 1
Training loss: 0.8440412089470619
Validation loss: 2.42307773170038

Epoch: 5| Step: 2
Training loss: 0.8889920842018901
Validation loss: 2.4418805623346334

Epoch: 5| Step: 3
Training loss: 1.233718890848212
Validation loss: 2.45461387799329

Epoch: 5| Step: 4
Training loss: 0.9616119375032185
Validation loss: 2.4255277738262437

Epoch: 5| Step: 5
Training loss: 0.7130620880861352
Validation loss: 2.474365017186695

Epoch: 5| Step: 6
Training loss: 0.5171479362729131
Validation loss: 2.4707614813806633

Epoch: 5| Step: 7
Training loss: 0.9333862968017648
Validation loss: 2.4654828300356932

Epoch: 5| Step: 8
Training loss: 0.9664580705174586
Validation loss: 2.453154571106249

Epoch: 5| Step: 9
Training loss: 0.9287999508595679
Validation loss: 2.4664978641674637

Epoch: 5| Step: 10
Training loss: 0.7202368574495875
Validation loss: 2.4359257886326007

Epoch: 318| Step: 0
Training loss: 0.7012650791797692
Validation loss: 2.4296711058337714

Epoch: 5| Step: 1
Training loss: 1.1279674176928103
Validation loss: 2.436533593038611

Epoch: 5| Step: 2
Training loss: 0.8130898535343445
Validation loss: 2.448093831169058

Epoch: 5| Step: 3
Training loss: 0.6119833655247134
Validation loss: 2.4542114587859976

Epoch: 5| Step: 4
Training loss: 1.1240563143405395
Validation loss: 2.459670709566876

Epoch: 5| Step: 5
Training loss: 0.6719627766602928
Validation loss: 2.4660083879588104

Epoch: 5| Step: 6
Training loss: 1.0275520142618328
Validation loss: 2.4794345572065524

Epoch: 5| Step: 7
Training loss: 1.0811637403004477
Validation loss: 2.4641901369157697

Epoch: 5| Step: 8
Training loss: 0.623747834907092
Validation loss: 2.477271764690695

Epoch: 5| Step: 9
Training loss: 1.0357598038710532
Validation loss: 2.468558390606284

Epoch: 5| Step: 10
Training loss: 0.8265774139616415
Validation loss: 2.3992500143420012

Epoch: 319| Step: 0
Training loss: 0.9675479322087981
Validation loss: 2.416952392807378

Epoch: 5| Step: 1
Training loss: 0.36980547901559246
Validation loss: 2.3761230074028044

Epoch: 5| Step: 2
Training loss: 0.7023501046882986
Validation loss: 2.397539924349813

Epoch: 5| Step: 3
Training loss: 1.2313043572679545
Validation loss: 2.3518958607164837

Epoch: 5| Step: 4
Training loss: 0.8493405322336718
Validation loss: 2.3304564958542366

Epoch: 5| Step: 5
Training loss: 1.0218866260112192
Validation loss: 2.3836255146224268

Epoch: 5| Step: 6
Training loss: 0.8619073835987653
Validation loss: 2.4170874967207467

Epoch: 5| Step: 7
Training loss: 0.890797916156745
Validation loss: 2.4428584789534584

Epoch: 5| Step: 8
Training loss: 0.7563943078938935
Validation loss: 2.490207189435272

Epoch: 5| Step: 9
Training loss: 0.9934039131047544
Validation loss: 2.4520703921353504

Epoch: 5| Step: 10
Training loss: 0.94842574663751
Validation loss: 2.4527748892148464

Epoch: 320| Step: 0
Training loss: 0.8806748968842448
Validation loss: 2.4556271643829217

Epoch: 5| Step: 1
Training loss: 0.7258894068814092
Validation loss: 2.415026849546368

Epoch: 5| Step: 2
Training loss: 0.9826434209844154
Validation loss: 2.4095276493013067

Epoch: 5| Step: 3
Training loss: 0.7802196192890678
Validation loss: 2.4276786555391503

Epoch: 5| Step: 4
Training loss: 0.963672065502901
Validation loss: 2.3903324828384864

Epoch: 5| Step: 5
Training loss: 0.6790940116175089
Validation loss: 2.4008975140649516

Epoch: 5| Step: 6
Training loss: 1.1614230140595976
Validation loss: 2.398514256076374

Epoch: 5| Step: 7
Training loss: 0.925289296970782
Validation loss: 2.401385134443683

Epoch: 5| Step: 8
Training loss: 0.812702153806671
Validation loss: 2.4334522944202375

Epoch: 5| Step: 9
Training loss: 0.7963604107036678
Validation loss: 2.4220533587792255

Epoch: 5| Step: 10
Training loss: 0.7680609739854782
Validation loss: 2.432060278298782

Epoch: 321| Step: 0
Training loss: 0.557686609332673
Validation loss: 2.4511996200449633

Epoch: 5| Step: 1
Training loss: 0.7700147707253169
Validation loss: 2.476869034609849

Epoch: 5| Step: 2
Training loss: 1.063716192369438
Validation loss: 2.3909249302226505

Epoch: 5| Step: 3
Training loss: 0.904984577268835
Validation loss: 2.407058080456377

Epoch: 5| Step: 4
Training loss: 0.8867438560662316
Validation loss: 2.411981832038353

Epoch: 5| Step: 5
Training loss: 1.0144879945822072
Validation loss: 2.428986582443512

Epoch: 5| Step: 6
Training loss: 0.8866733421765148
Validation loss: 2.410130973584054

Epoch: 5| Step: 7
Training loss: 0.9609554258085701
Validation loss: 2.4210710888235996

Epoch: 5| Step: 8
Training loss: 0.40832944676761856
Validation loss: 2.3935738465442418

Epoch: 5| Step: 9
Training loss: 1.09885056435801
Validation loss: 2.418778919134955

Epoch: 5| Step: 10
Training loss: 0.5537759517332055
Validation loss: 2.4299741107141037

Epoch: 322| Step: 0
Training loss: 0.7939488785066557
Validation loss: 2.421851991563335

Epoch: 5| Step: 1
Training loss: 1.0172172389685907
Validation loss: 2.3734579212651963

Epoch: 5| Step: 2
Training loss: 0.9228113559259802
Validation loss: 2.3863694567929667

Epoch: 5| Step: 3
Training loss: 1.0955948665672726
Validation loss: 2.422456826123168

Epoch: 5| Step: 4
Training loss: 0.986615975555553
Validation loss: 2.3893998929350078

Epoch: 5| Step: 5
Training loss: 0.8420269291098479
Validation loss: 2.416988643785756

Epoch: 5| Step: 6
Training loss: 0.7616202266261172
Validation loss: 2.410229577017576

Epoch: 5| Step: 7
Training loss: 0.46942454123611976
Validation loss: 2.386371133751082

Epoch: 5| Step: 8
Training loss: 0.6083393833652107
Validation loss: 2.4014466330150426

Epoch: 5| Step: 9
Training loss: 0.7134672576272483
Validation loss: 2.3735989991965787

Epoch: 5| Step: 10
Training loss: 0.9587941340368487
Validation loss: 2.4060591968435494

Epoch: 323| Step: 0
Training loss: 0.5606356294659822
Validation loss: 2.4125326531115476

Epoch: 5| Step: 1
Training loss: 0.8574831165175265
Validation loss: 2.407097294265326

Epoch: 5| Step: 2
Training loss: 0.9656886675440413
Validation loss: 2.4436692049226085

Epoch: 5| Step: 3
Training loss: 0.9002528550670281
Validation loss: 2.4315745275898593

Epoch: 5| Step: 4
Training loss: 0.8169572057126868
Validation loss: 2.429635715687854

Epoch: 5| Step: 5
Training loss: 0.7688697256503649
Validation loss: 2.4349818720457255

Epoch: 5| Step: 6
Training loss: 0.605654460359719
Validation loss: 2.404496850745758

Epoch: 5| Step: 7
Training loss: 0.8885656943134012
Validation loss: 2.401950437755445

Epoch: 5| Step: 8
Training loss: 0.9285305100637252
Validation loss: 2.3911104271754993

Epoch: 5| Step: 9
Training loss: 1.084449736908165
Validation loss: 2.3876181828517664

Epoch: 5| Step: 10
Training loss: 0.7678734985143136
Validation loss: 2.384800923680938

Epoch: 324| Step: 0
Training loss: 0.49270852077499383
Validation loss: 2.4051792653482047

Epoch: 5| Step: 1
Training loss: 0.9024256549340258
Validation loss: 2.3883103010385756

Epoch: 5| Step: 2
Training loss: 0.817270505930871
Validation loss: 2.379474237945684

Epoch: 5| Step: 3
Training loss: 1.0018466350040658
Validation loss: 2.353636511426919

Epoch: 5| Step: 4
Training loss: 0.8082047784639963
Validation loss: 2.3900765407754094

Epoch: 5| Step: 5
Training loss: 0.8395725965799375
Validation loss: 2.4106215326053912

Epoch: 5| Step: 6
Training loss: 1.0285499946597576
Validation loss: 2.4117084062460914

Epoch: 5| Step: 7
Training loss: 0.9564690008768537
Validation loss: 2.427262781015907

Epoch: 5| Step: 8
Training loss: 0.9314984227063211
Validation loss: 2.406533369349096

Epoch: 5| Step: 9
Training loss: 0.5840148662657432
Validation loss: 2.4035063930134375

Epoch: 5| Step: 10
Training loss: 0.6707017546402579
Validation loss: 2.368845455921613

Epoch: 325| Step: 0
Training loss: 1.1118785922853915
Validation loss: 2.381565931361834

Epoch: 5| Step: 1
Training loss: 0.9384838663664468
Validation loss: 2.3728700120286725

Epoch: 5| Step: 2
Training loss: 0.8553611652883805
Validation loss: 2.3720814805155537

Epoch: 5| Step: 3
Training loss: 1.229354596184433
Validation loss: 2.3929018066794154

Epoch: 5| Step: 4
Training loss: 0.7182707225201515
Validation loss: 2.3596354911685915

Epoch: 5| Step: 5
Training loss: 0.6788966082732215
Validation loss: 2.357008138749809

Epoch: 5| Step: 6
Training loss: 0.5655589112509296
Validation loss: 2.3930407805949834

Epoch: 5| Step: 7
Training loss: 0.5722635418850738
Validation loss: 2.3863974052248516

Epoch: 5| Step: 8
Training loss: 0.5952952004469727
Validation loss: 2.3696802709217453

Epoch: 5| Step: 9
Training loss: 0.8958694909065961
Validation loss: 2.3450113152566967

Epoch: 5| Step: 10
Training loss: 0.7168044419889673
Validation loss: 2.399913813810694

Epoch: 326| Step: 0
Training loss: 0.8987800276916984
Validation loss: 2.3702390648490557

Epoch: 5| Step: 1
Training loss: 0.9602691683317228
Validation loss: 2.3823031597410025

Epoch: 5| Step: 2
Training loss: 0.2587875798020984
Validation loss: 2.39337708417135

Epoch: 5| Step: 3
Training loss: 0.8617669888341517
Validation loss: 2.393556662533788

Epoch: 5| Step: 4
Training loss: 0.8300178775240823
Validation loss: 2.3921268096238415

Epoch: 5| Step: 5
Training loss: 0.8603636863105408
Validation loss: 2.3858726944321176

Epoch: 5| Step: 6
Training loss: 0.7845580066098531
Validation loss: 2.403986114781673

Epoch: 5| Step: 7
Training loss: 0.8104512721292068
Validation loss: 2.4113849095477335

Epoch: 5| Step: 8
Training loss: 0.9399112845214121
Validation loss: 2.409138531494642

Epoch: 5| Step: 9
Training loss: 0.7404212011335461
Validation loss: 2.400589242035552

Epoch: 5| Step: 10
Training loss: 0.9892271136899043
Validation loss: 2.3837333041827167

Epoch: 327| Step: 0
Training loss: 0.5942390335316469
Validation loss: 2.3763322110808094

Epoch: 5| Step: 1
Training loss: 0.7463179645866979
Validation loss: 2.3429605178429336

Epoch: 5| Step: 2
Training loss: 0.9241295095070803
Validation loss: 2.3577238706876553

Epoch: 5| Step: 3
Training loss: 0.9364721703841942
Validation loss: 2.333012893057171

Epoch: 5| Step: 4
Training loss: 0.756588960773363
Validation loss: 2.3990612191043748

Epoch: 5| Step: 5
Training loss: 0.786231713559927
Validation loss: 2.3912601741065322

Epoch: 5| Step: 6
Training loss: 1.0035397940606265
Validation loss: 2.3863816960892654

Epoch: 5| Step: 7
Training loss: 0.8180680951523056
Validation loss: 2.395479447033192

Epoch: 5| Step: 8
Training loss: 0.9579982932081528
Validation loss: 2.4126593753335133

Epoch: 5| Step: 9
Training loss: 0.7554550074971431
Validation loss: 2.365415480813656

Epoch: 5| Step: 10
Training loss: 0.5501445038572677
Validation loss: 2.4007905314416758

Epoch: 328| Step: 0
Training loss: 0.8302910026894388
Validation loss: 2.4003707214874384

Epoch: 5| Step: 1
Training loss: 0.5472962528129058
Validation loss: 2.3925957799933566

Epoch: 5| Step: 2
Training loss: 0.5505993048813517
Validation loss: 2.3972267220428276

Epoch: 5| Step: 3
Training loss: 1.0659886475221574
Validation loss: 2.3819072034488036

Epoch: 5| Step: 4
Training loss: 0.6631187913983321
Validation loss: 2.3924052884104037

Epoch: 5| Step: 5
Training loss: 0.44101471541845627
Validation loss: 2.3717853776562956

Epoch: 5| Step: 6
Training loss: 1.0491693889854286
Validation loss: 2.374512095007857

Epoch: 5| Step: 7
Training loss: 0.340774839149422
Validation loss: 2.400513766037729

Epoch: 5| Step: 8
Training loss: 0.8795835809663622
Validation loss: 2.377249112060428

Epoch: 5| Step: 9
Training loss: 1.1495223338714806
Validation loss: 2.4026593769064832

Epoch: 5| Step: 10
Training loss: 0.95450604551468
Validation loss: 2.386619330969278

Epoch: 329| Step: 0
Training loss: 0.665062723285045
Validation loss: 2.403948062752765

Epoch: 5| Step: 1
Training loss: 0.7940797961684662
Validation loss: 2.372074725242288

Epoch: 5| Step: 2
Training loss: 0.9407874325135868
Validation loss: 2.380583260335418

Epoch: 5| Step: 3
Training loss: 0.5881737822389321
Validation loss: 2.3844567037719475

Epoch: 5| Step: 4
Training loss: 0.541151642485185
Validation loss: 2.393746251764359

Epoch: 5| Step: 5
Training loss: 0.8480120496658518
Validation loss: 2.4037271929665778

Epoch: 5| Step: 6
Training loss: 1.244553956939965
Validation loss: 2.3893473223785175

Epoch: 5| Step: 7
Training loss: 0.6462984076914
Validation loss: 2.374394932879574

Epoch: 5| Step: 8
Training loss: 0.6838755653405507
Validation loss: 2.398652795800165

Epoch: 5| Step: 9
Training loss: 0.9927667443835774
Validation loss: 2.3525877643656448

Epoch: 5| Step: 10
Training loss: 0.559712017551075
Validation loss: 2.3799158110747793

Epoch: 330| Step: 0
Training loss: 1.0623585101893582
Validation loss: 2.368870774065603

Epoch: 5| Step: 1
Training loss: 0.9677922528975546
Validation loss: 2.3832159079117563

Epoch: 5| Step: 2
Training loss: 0.5626891665799981
Validation loss: 2.3898637977807833

Epoch: 5| Step: 3
Training loss: 0.7832873292021604
Validation loss: 2.3772042143431715

Epoch: 5| Step: 4
Training loss: 1.0100882215966709
Validation loss: 2.3611134008130676

Epoch: 5| Step: 5
Training loss: 0.7795636478129053
Validation loss: 2.3612769629828265

Epoch: 5| Step: 6
Training loss: 0.6236412537598145
Validation loss: 2.38124197164908

Epoch: 5| Step: 7
Training loss: 0.891104652676547
Validation loss: 2.3939627918958206

Epoch: 5| Step: 8
Training loss: 0.5798995131557504
Validation loss: 2.3746859845358665

Epoch: 5| Step: 9
Training loss: 0.6176379045174034
Validation loss: 2.4030825635625237

Epoch: 5| Step: 10
Training loss: 0.7368705633545958
Validation loss: 2.391530826628821

Epoch: 331| Step: 0
Training loss: 0.5974178212605594
Validation loss: 2.3970699662421753

Epoch: 5| Step: 1
Training loss: 0.8360284773616966
Validation loss: 2.3885526200634875

Epoch: 5| Step: 2
Training loss: 1.095263387800677
Validation loss: 2.4405227378998813

Epoch: 5| Step: 3
Training loss: 0.8366160980713095
Validation loss: 2.4410241457957027

Epoch: 5| Step: 4
Training loss: 0.8572380546656473
Validation loss: 2.4174145067259407

Epoch: 5| Step: 5
Training loss: 0.5198331830321193
Validation loss: 2.4005712416188287

Epoch: 5| Step: 6
Training loss: 0.5179349712790213
Validation loss: 2.402133980313253

Epoch: 5| Step: 7
Training loss: 0.7065670955732902
Validation loss: 2.437354551255848

Epoch: 5| Step: 8
Training loss: 0.8401739136859357
Validation loss: 2.3970822182800706

Epoch: 5| Step: 9
Training loss: 0.9678996260795103
Validation loss: 2.425062981605802

Epoch: 5| Step: 10
Training loss: 0.7040152318252226
Validation loss: 2.4069659192598296

Epoch: 332| Step: 0
Training loss: 0.8398462339852437
Validation loss: 2.381074834152645

Epoch: 5| Step: 1
Training loss: 0.6840388565543287
Validation loss: 2.3867850334977376

Epoch: 5| Step: 2
Training loss: 0.746220483052385
Validation loss: 2.399731788829356

Epoch: 5| Step: 3
Training loss: 0.7947442233489778
Validation loss: 2.411722101870354

Epoch: 5| Step: 4
Training loss: 0.7417690502892258
Validation loss: 2.368146563119512

Epoch: 5| Step: 5
Training loss: 0.735548542687323
Validation loss: 2.4064179622742308

Epoch: 5| Step: 6
Training loss: 0.6891202690492149
Validation loss: 2.357200830710243

Epoch: 5| Step: 7
Training loss: 0.8416268515533201
Validation loss: 2.4012901724402345

Epoch: 5| Step: 8
Training loss: 0.8414769815026818
Validation loss: 2.409256613697238

Epoch: 5| Step: 9
Training loss: 0.6555203741429546
Validation loss: 2.3895025071744844

Epoch: 5| Step: 10
Training loss: 0.9922286498179703
Validation loss: 2.359564752030799

Epoch: 333| Step: 0
Training loss: 0.9384747206464431
Validation loss: 2.3889643476046767

Epoch: 5| Step: 1
Training loss: 0.77855511310151
Validation loss: 2.3902231750434493

Epoch: 5| Step: 2
Training loss: 0.7602083147180844
Validation loss: 2.3920025750145433

Epoch: 5| Step: 3
Training loss: 0.5322009159173434
Validation loss: 2.373020732287813

Epoch: 5| Step: 4
Training loss: 0.4382293276026728
Validation loss: 2.4132308029048795

Epoch: 5| Step: 5
Training loss: 0.8103258681895609
Validation loss: 2.394356250248241

Epoch: 5| Step: 6
Training loss: 1.0160551480735172
Validation loss: 2.3798572802611977

Epoch: 5| Step: 7
Training loss: 0.6560535363893896
Validation loss: 2.3894119418230293

Epoch: 5| Step: 8
Training loss: 0.727027129229852
Validation loss: 2.3919833380073263

Epoch: 5| Step: 9
Training loss: 0.8303764256056401
Validation loss: 2.3775361104403454

Epoch: 5| Step: 10
Training loss: 0.858888384289886
Validation loss: 2.3895610179135045

Epoch: 334| Step: 0
Training loss: 0.8653776855272794
Validation loss: 2.394515475386266

Epoch: 5| Step: 1
Training loss: 0.7944437224452273
Validation loss: 2.378549077484642

Epoch: 5| Step: 2
Training loss: 0.625999462167064
Validation loss: 2.4079505409968975

Epoch: 5| Step: 3
Training loss: 0.7426355715970202
Validation loss: 2.3959520903514218

Epoch: 5| Step: 4
Training loss: 0.868583243303594
Validation loss: 2.397417541101791

Epoch: 5| Step: 5
Training loss: 0.45495883868127945
Validation loss: 2.380174893800226

Epoch: 5| Step: 6
Training loss: 0.7944068458710657
Validation loss: 2.413736403860055

Epoch: 5| Step: 7
Training loss: 0.9740046151872364
Validation loss: 2.396173306634104

Epoch: 5| Step: 8
Training loss: 0.6711166671019617
Validation loss: 2.372935934751199

Epoch: 5| Step: 9
Training loss: 0.8907378610409615
Validation loss: 2.4111419362440585

Epoch: 5| Step: 10
Training loss: 0.5620658841781514
Validation loss: 2.3954412422157203

Epoch: 335| Step: 0
Training loss: 0.6487606805866688
Validation loss: 2.3987922541043774

Epoch: 5| Step: 1
Training loss: 0.9257002847412074
Validation loss: 2.3765065585819074

Epoch: 5| Step: 2
Training loss: 0.5842519548993098
Validation loss: 2.4046345041992825

Epoch: 5| Step: 3
Training loss: 0.9972993623112402
Validation loss: 2.409446362994889

Epoch: 5| Step: 4
Training loss: 1.010368890058833
Validation loss: 2.3708290776392014

Epoch: 5| Step: 5
Training loss: 0.6567252118820388
Validation loss: 2.370871312529824

Epoch: 5| Step: 6
Training loss: 0.624412069356277
Validation loss: 2.392229824501257

Epoch: 5| Step: 7
Training loss: 0.5415221229289062
Validation loss: 2.376523728877709

Epoch: 5| Step: 8
Training loss: 0.9634867712655831
Validation loss: 2.3961770170079806

Epoch: 5| Step: 9
Training loss: 0.4782133743790661
Validation loss: 2.377137111526319

Epoch: 5| Step: 10
Training loss: 0.5233298233647493
Validation loss: 2.3959710333488946

Epoch: 336| Step: 0
Training loss: 1.1543081318521011
Validation loss: 2.399365010782412

Epoch: 5| Step: 1
Training loss: 0.6714457981818693
Validation loss: 2.3490594208630933

Epoch: 5| Step: 2
Training loss: 0.6015416178856432
Validation loss: 2.3847743884440225

Epoch: 5| Step: 3
Training loss: 0.6970786263313994
Validation loss: 2.366703030033767

Epoch: 5| Step: 4
Training loss: 0.947616260562234
Validation loss: 2.4193578558051874

Epoch: 5| Step: 5
Training loss: 0.647160340922279
Validation loss: 2.3672915319093475

Epoch: 5| Step: 6
Training loss: 0.7835705435179441
Validation loss: 2.3863734622607957

Epoch: 5| Step: 7
Training loss: 0.6617083389922453
Validation loss: 2.3858026375944146

Epoch: 5| Step: 8
Training loss: 0.5225783741956526
Validation loss: 2.3697130821492767

Epoch: 5| Step: 9
Training loss: 0.6731278913713871
Validation loss: 2.3924163770382147

Epoch: 5| Step: 10
Training loss: 0.49960016118337935
Validation loss: 2.3644610531415577

Epoch: 337| Step: 0
Training loss: 0.699279313687877
Validation loss: 2.381596481940867

Epoch: 5| Step: 1
Training loss: 0.5240480932576822
Validation loss: 2.383186873343102

Epoch: 5| Step: 2
Training loss: 1.1393666053751497
Validation loss: 2.389807228604986

Epoch: 5| Step: 3
Training loss: 0.8327550471028932
Validation loss: 2.393095391121716

Epoch: 5| Step: 4
Training loss: 0.7670322641850487
Validation loss: 2.4030391235958177

Epoch: 5| Step: 5
Training loss: 0.7912406695450056
Validation loss: 2.4302664725983933

Epoch: 5| Step: 6
Training loss: 0.6831645599176713
Validation loss: 2.3442780365425553

Epoch: 5| Step: 7
Training loss: 0.5012740057145997
Validation loss: 2.3943571881825005

Epoch: 5| Step: 8
Training loss: 0.6902926469523691
Validation loss: 2.3857417732542547

Epoch: 5| Step: 9
Training loss: 0.34927070453086606
Validation loss: 2.4123626574676784

Epoch: 5| Step: 10
Training loss: 0.7955939149140551
Validation loss: 2.3909436214029185

Epoch: 338| Step: 0
Training loss: 0.6038173180717518
Validation loss: 2.367792988392149

Epoch: 5| Step: 1
Training loss: 1.0611119459780283
Validation loss: 2.3961331544150455

Epoch: 5| Step: 2
Training loss: 0.5865761137791419
Validation loss: 2.404900545206814

Epoch: 5| Step: 3
Training loss: 0.9230823369585733
Validation loss: 2.372884681608032

Epoch: 5| Step: 4
Training loss: 0.8238219983093292
Validation loss: 2.3968441671691743

Epoch: 5| Step: 5
Training loss: 0.465522030831475
Validation loss: 2.3725773923421105

Epoch: 5| Step: 6
Training loss: 0.7426535097051973
Validation loss: 2.315613708782983

Epoch: 5| Step: 7
Training loss: 0.6560524007218513
Validation loss: 2.341161188252766

Epoch: 5| Step: 8
Training loss: 0.5063191684518737
Validation loss: 2.3296320347864894

Epoch: 5| Step: 9
Training loss: 0.7138964520468971
Validation loss: 2.362918148352736

Epoch: 5| Step: 10
Training loss: 0.8486564114958122
Validation loss: 2.350880609680589

Epoch: 339| Step: 0
Training loss: 0.6349804324041276
Validation loss: 2.365218530724808

Epoch: 5| Step: 1
Training loss: 0.7845733908416473
Validation loss: 2.3645999996943603

Epoch: 5| Step: 2
Training loss: 0.8956700368393571
Validation loss: 2.380687319061885

Epoch: 5| Step: 3
Training loss: 0.6894334568752033
Validation loss: 2.3532234714169817

Epoch: 5| Step: 4
Training loss: 0.72239003819729
Validation loss: 2.3901018238718255

Epoch: 5| Step: 5
Training loss: 0.492708112489464
Validation loss: 2.3781109287689266

Epoch: 5| Step: 6
Training loss: 0.7193835410266464
Validation loss: 2.414621548265877

Epoch: 5| Step: 7
Training loss: 0.8352512858659791
Validation loss: 2.3958271263723416

Epoch: 5| Step: 8
Training loss: 0.7476724828155713
Validation loss: 2.3781039901115144

Epoch: 5| Step: 9
Training loss: 0.44502123291815354
Validation loss: 2.3550007128831463

Epoch: 5| Step: 10
Training loss: 0.8406882365099232
Validation loss: 2.359015722314604

Epoch: 340| Step: 0
Training loss: 0.5109126898665184
Validation loss: 2.343058886613594

Epoch: 5| Step: 1
Training loss: 0.6859400998980839
Validation loss: 2.353560894007521

Epoch: 5| Step: 2
Training loss: 0.9292241392336947
Validation loss: 2.3108060719476393

Epoch: 5| Step: 3
Training loss: 0.6232014287987931
Validation loss: 2.3949260525716647

Epoch: 5| Step: 4
Training loss: 0.6126734886867129
Validation loss: 2.4023076515343553

Epoch: 5| Step: 5
Training loss: 0.6698629058597482
Validation loss: 2.3827383378495925

Epoch: 5| Step: 6
Training loss: 0.8046575003652062
Validation loss: 2.4136575025340967

Epoch: 5| Step: 7
Training loss: 0.6612805831052778
Validation loss: 2.3585026951290486

Epoch: 5| Step: 8
Training loss: 0.8488707038884151
Validation loss: 2.3479180773446475

Epoch: 5| Step: 9
Training loss: 0.7679486727103195
Validation loss: 2.411447198668849

Epoch: 5| Step: 10
Training loss: 0.7195929269937109
Validation loss: 2.33649299281371

Epoch: 341| Step: 0
Training loss: 0.46546058440177035
Validation loss: 2.325451078662811

Epoch: 5| Step: 1
Training loss: 0.9348418699255504
Validation loss: 2.361793728857656

Epoch: 5| Step: 2
Training loss: 0.9168433575413025
Validation loss: 2.3532699585415577

Epoch: 5| Step: 3
Training loss: 0.8699019965515835
Validation loss: 2.3458788789878917

Epoch: 5| Step: 4
Training loss: 0.6410372268412257
Validation loss: 2.3788150603041327

Epoch: 5| Step: 5
Training loss: 0.4929386039016337
Validation loss: 2.3899275225860666

Epoch: 5| Step: 6
Training loss: 0.8128816735188599
Validation loss: 2.3782562769410407

Epoch: 5| Step: 7
Training loss: 0.6195328971003877
Validation loss: 2.4079644634720907

Epoch: 5| Step: 8
Training loss: 0.6431894843541937
Validation loss: 2.386783408387161

Epoch: 5| Step: 9
Training loss: 0.6359652407732448
Validation loss: 2.4134363926975566

Epoch: 5| Step: 10
Training loss: 0.7267524716991678
Validation loss: 2.39918602371518

Epoch: 342| Step: 0
Training loss: 0.5810316578123936
Validation loss: 2.4202615074384455

Epoch: 5| Step: 1
Training loss: 0.8119733277201253
Validation loss: 2.3585033869904692

Epoch: 5| Step: 2
Training loss: 0.7294707799423311
Validation loss: 2.3442881479758992

Epoch: 5| Step: 3
Training loss: 0.4036155156060561
Validation loss: 2.375133249444827

Epoch: 5| Step: 4
Training loss: 0.945841680537514
Validation loss: 2.356201531336119

Epoch: 5| Step: 5
Training loss: 0.785052164494875
Validation loss: 2.379811853269293

Epoch: 5| Step: 6
Training loss: 0.6669198439588853
Validation loss: 2.386856026012395

Epoch: 5| Step: 7
Training loss: 0.4890336000721338
Validation loss: 2.3680558154179843

Epoch: 5| Step: 8
Training loss: 0.6817091330829841
Validation loss: 2.379164561775796

Epoch: 5| Step: 9
Training loss: 0.7980537671927282
Validation loss: 2.4009185418487933

Epoch: 5| Step: 10
Training loss: 0.8254879043381481
Validation loss: 2.401066175346451

Epoch: 343| Step: 0
Training loss: 0.7184245990061117
Validation loss: 2.3996044517472552

Epoch: 5| Step: 1
Training loss: 0.5325148895134126
Validation loss: 2.403633642838455

Epoch: 5| Step: 2
Training loss: 1.0016738472637259
Validation loss: 2.4029617225725137

Epoch: 5| Step: 3
Training loss: 0.7017806446789496
Validation loss: 2.366942492216455

Epoch: 5| Step: 4
Training loss: 0.6063613710650987
Validation loss: 2.364782137362751

Epoch: 5| Step: 5
Training loss: 0.7330625046599866
Validation loss: 2.3826485719849244

Epoch: 5| Step: 6
Training loss: 0.7737682290464288
Validation loss: 2.372692906812639

Epoch: 5| Step: 7
Training loss: 0.44873108308602705
Validation loss: 2.369734965965311

Epoch: 5| Step: 8
Training loss: 0.5590202463984031
Validation loss: 2.3548268884198307

Epoch: 5| Step: 9
Training loss: 0.6715037628801229
Validation loss: 2.36957224997888

Epoch: 5| Step: 10
Training loss: 0.9443091750667439
Validation loss: 2.3541863840206516

Epoch: 344| Step: 0
Training loss: 0.7523726841006338
Validation loss: 2.390086036649317

Epoch: 5| Step: 1
Training loss: 1.0816819491332978
Validation loss: 2.3787359377452306

Epoch: 5| Step: 2
Training loss: 0.5243837145330162
Validation loss: 2.4145592014152615

Epoch: 5| Step: 3
Training loss: 0.8159502937310288
Validation loss: 2.3867192322832724

Epoch: 5| Step: 4
Training loss: 0.5774600612569479
Validation loss: 2.4035082052090737

Epoch: 5| Step: 5
Training loss: 0.5870003279826403
Validation loss: 2.377321601972011

Epoch: 5| Step: 6
Training loss: 0.747458602626514
Validation loss: 2.352158937102291

Epoch: 5| Step: 7
Training loss: 0.5412155222758794
Validation loss: 2.3785714372321567

Epoch: 5| Step: 8
Training loss: 0.641946754902133
Validation loss: 2.335638408147625

Epoch: 5| Step: 9
Training loss: 0.732222751252397
Validation loss: 2.371961315267951

Epoch: 5| Step: 10
Training loss: 0.4631278802161804
Validation loss: 2.358396920011088

Epoch: 345| Step: 0
Training loss: 0.7176590808934664
Validation loss: 2.3563733852801327

Epoch: 5| Step: 1
Training loss: 0.8004558739565728
Validation loss: 2.3697764925700238

Epoch: 5| Step: 2
Training loss: 0.9274022200420661
Validation loss: 2.392748647694278

Epoch: 5| Step: 3
Training loss: 0.858074591504297
Validation loss: 2.3474788096736345

Epoch: 5| Step: 4
Training loss: 0.5025441886678954
Validation loss: 2.3638895880177873

Epoch: 5| Step: 5
Training loss: 0.654319785556793
Validation loss: 2.3574440855132055

Epoch: 5| Step: 6
Training loss: 0.4000844761933367
Validation loss: 2.384898699943845

Epoch: 5| Step: 7
Training loss: 0.7879713842622899
Validation loss: 2.344067642399613

Epoch: 5| Step: 8
Training loss: 0.60694753887087
Validation loss: 2.3774110788691702

Epoch: 5| Step: 9
Training loss: 0.4902811522032999
Validation loss: 2.396995656975113

Epoch: 5| Step: 10
Training loss: 0.6823693345298169
Validation loss: 2.3822588931929465

Epoch: 346| Step: 0
Training loss: 0.8103410942190348
Validation loss: 2.417516675224499

Epoch: 5| Step: 1
Training loss: 0.748526078559193
Validation loss: 2.395675158172445

Epoch: 5| Step: 2
Training loss: 0.5317534697634217
Validation loss: 2.3832448108921014

Epoch: 5| Step: 3
Training loss: 0.6352306364636983
Validation loss: 2.4143128443650146

Epoch: 5| Step: 4
Training loss: 0.6875829429878098
Validation loss: 2.421241062276625

Epoch: 5| Step: 5
Training loss: 0.6789979177030115
Validation loss: 2.441864449505418

Epoch: 5| Step: 6
Training loss: 0.6181492615384717
Validation loss: 2.3935931339602656

Epoch: 5| Step: 7
Training loss: 0.6415024075466657
Validation loss: 2.376849162190473

Epoch: 5| Step: 8
Training loss: 0.823708217933121
Validation loss: 2.429845195941975

Epoch: 5| Step: 9
Training loss: 0.5127821494541002
Validation loss: 2.414146043039617

Epoch: 5| Step: 10
Training loss: 0.8970110640507959
Validation loss: 2.3745055803942456

Epoch: 347| Step: 0
Training loss: 0.7345386890845328
Validation loss: 2.3706824949567027

Epoch: 5| Step: 1
Training loss: 0.8873132401729494
Validation loss: 2.351471237664576

Epoch: 5| Step: 2
Training loss: 0.574348694507161
Validation loss: 2.3521837520334494

Epoch: 5| Step: 3
Training loss: 0.6692906511591123
Validation loss: 2.3681847346606335

Epoch: 5| Step: 4
Training loss: 0.6236510023552014
Validation loss: 2.33735524654396

Epoch: 5| Step: 5
Training loss: 0.6742869929390727
Validation loss: 2.3890564601314845

Epoch: 5| Step: 6
Training loss: 0.7620222220747437
Validation loss: 2.371952155921897

Epoch: 5| Step: 7
Training loss: 0.550233880080315
Validation loss: 2.3537427749458857

Epoch: 5| Step: 8
Training loss: 0.5053910845797046
Validation loss: 2.36852464111748

Epoch: 5| Step: 9
Training loss: 0.7153209490129173
Validation loss: 2.3687745048036186

Epoch: 5| Step: 10
Training loss: 0.7610951928015612
Validation loss: 2.381468267742908

Epoch: 348| Step: 0
Training loss: 0.543700020784171
Validation loss: 2.3724592042876758

Epoch: 5| Step: 1
Training loss: 0.5426384998673044
Validation loss: 2.3650560118455237

Epoch: 5| Step: 2
Training loss: 0.7083446885115058
Validation loss: 2.3846623704562715

Epoch: 5| Step: 3
Training loss: 1.0313805584191973
Validation loss: 2.4008324237220697

Epoch: 5| Step: 4
Training loss: 0.659014487581958
Validation loss: 2.3818120729994976

Epoch: 5| Step: 5
Training loss: 0.6628134705618696
Validation loss: 2.3771294674093886

Epoch: 5| Step: 6
Training loss: 0.7108524397383754
Validation loss: 2.373871965548926

Epoch: 5| Step: 7
Training loss: 0.7120818266193245
Validation loss: 2.37987105145972

Epoch: 5| Step: 8
Training loss: 0.8047494957013667
Validation loss: 2.376366193746293

Epoch: 5| Step: 9
Training loss: 0.46290942447650063
Validation loss: 2.3937533132227675

Epoch: 5| Step: 10
Training loss: 0.46556527375547085
Validation loss: 2.361247485475263

Epoch: 349| Step: 0
Training loss: 0.7637899946488895
Validation loss: 2.350032968667311

Epoch: 5| Step: 1
Training loss: 0.8361275002431763
Validation loss: 2.3816192840150325

Epoch: 5| Step: 2
Training loss: 0.4875323083148544
Validation loss: 2.36404276014631

Epoch: 5| Step: 3
Training loss: 0.5024802264313324
Validation loss: 2.367839041148677

Epoch: 5| Step: 4
Training loss: 0.29208650628532773
Validation loss: 2.376047665401053

Epoch: 5| Step: 5
Training loss: 0.6387955665385564
Validation loss: 2.3748764908372677

Epoch: 5| Step: 6
Training loss: 0.8402451376622487
Validation loss: 2.378106522915164

Epoch: 5| Step: 7
Training loss: 0.7061239712438047
Validation loss: 2.3777702983436617

Epoch: 5| Step: 8
Training loss: 0.5273422241188862
Validation loss: 2.375433585393198

Epoch: 5| Step: 9
Training loss: 0.7671708829676742
Validation loss: 2.3321360262584823

Epoch: 5| Step: 10
Training loss: 0.9117897012621374
Validation loss: 2.3827667452492363

Epoch: 350| Step: 0
Training loss: 0.6012231439314593
Validation loss: 2.363197518674514

Epoch: 5| Step: 1
Training loss: 0.892060311198698
Validation loss: 2.3656239776754338

Epoch: 5| Step: 2
Training loss: 0.6915191730591235
Validation loss: 2.409365863989415

Epoch: 5| Step: 3
Training loss: 0.41696776200167224
Validation loss: 2.4050334550085544

Epoch: 5| Step: 4
Training loss: 0.8457792745581587
Validation loss: 2.3880541400991215

Epoch: 5| Step: 5
Training loss: 0.6887020093672237
Validation loss: 2.3752717713762066

Epoch: 5| Step: 6
Training loss: 0.6531178113550894
Validation loss: 2.3416560531630846

Epoch: 5| Step: 7
Training loss: 0.6633843493452399
Validation loss: 2.385727519610724

Epoch: 5| Step: 8
Training loss: 0.4903483315352804
Validation loss: 2.39852951379418

Epoch: 5| Step: 9
Training loss: 0.5340095821031677
Validation loss: 2.390930465108952

Epoch: 5| Step: 10
Training loss: 0.7827457985852043
Validation loss: 2.3964014111944456

Epoch: 351| Step: 0
Training loss: 0.325220823003328
Validation loss: 2.427702534861254

Epoch: 5| Step: 1
Training loss: 0.5939647888382262
Validation loss: 2.4132809559114774

Epoch: 5| Step: 2
Training loss: 0.6821341053594591
Validation loss: 2.4221081407465004

Epoch: 5| Step: 3
Training loss: 0.6475221999055901
Validation loss: 2.4381426744111985

Epoch: 5| Step: 4
Training loss: 0.3654714009032673
Validation loss: 2.45590661416635

Epoch: 5| Step: 5
Training loss: 0.8297209206726891
Validation loss: 2.4865386564169927

Epoch: 5| Step: 6
Training loss: 0.35939017554044783
Validation loss: 2.4732204692236346

Epoch: 5| Step: 7
Training loss: 0.699462890625
Validation loss: 2.455424238507315

Epoch: 5| Step: 8
Training loss: 0.8690760899276445
Validation loss: 2.4234003562114736

Epoch: 5| Step: 9
Training loss: 1.0350078548372907
Validation loss: 2.4092271167001686

Epoch: 5| Step: 10
Training loss: 0.7464945650228628
Validation loss: 2.3844376370450373

Epoch: 352| Step: 0
Training loss: 0.5156321091595318
Validation loss: 2.3696045861316692

Epoch: 5| Step: 1
Training loss: 0.8575283323339601
Validation loss: 2.355795774038082

Epoch: 5| Step: 2
Training loss: 0.5498306512207373
Validation loss: 2.379807146780838

Epoch: 5| Step: 3
Training loss: 0.600476510848696
Validation loss: 2.3526767146987733

Epoch: 5| Step: 4
Training loss: 0.8885778691801356
Validation loss: 2.346376566439509

Epoch: 5| Step: 5
Training loss: 0.45419015327876516
Validation loss: 2.3921065426324604

Epoch: 5| Step: 6
Training loss: 0.6570883346235048
Validation loss: 2.370011771734344

Epoch: 5| Step: 7
Training loss: 0.7848038523104084
Validation loss: 2.3893626305864344

Epoch: 5| Step: 8
Training loss: 0.5305700157712583
Validation loss: 2.372393866437633

Epoch: 5| Step: 9
Training loss: 0.8265164786148214
Validation loss: 2.389699930790458

Epoch: 5| Step: 10
Training loss: 0.544491259339221
Validation loss: 2.370841783193151

Epoch: 353| Step: 0
Training loss: 0.6180169531617189
Validation loss: 2.3641487511150587

Epoch: 5| Step: 1
Training loss: 0.7742999499070079
Validation loss: 2.3307840886774245

Epoch: 5| Step: 2
Training loss: 0.5477771946551658
Validation loss: 2.332904785841718

Epoch: 5| Step: 3
Training loss: 0.9503630659605182
Validation loss: 2.3421515764280865

Epoch: 5| Step: 4
Training loss: 0.7920245482657352
Validation loss: 2.3316483546314495

Epoch: 5| Step: 5
Training loss: 0.6106066361538686
Validation loss: 2.3402056358285055

Epoch: 5| Step: 6
Training loss: 0.6366940827067312
Validation loss: 2.338339374909151

Epoch: 5| Step: 7
Training loss: 0.43833720620091887
Validation loss: 2.3431038209797306

Epoch: 5| Step: 8
Training loss: 0.5841842360400749
Validation loss: 2.3571478389461302

Epoch: 5| Step: 9
Training loss: 0.6886469204125234
Validation loss: 2.384157082431743

Epoch: 5| Step: 10
Training loss: 0.31047221551889465
Validation loss: 2.327702337112817

Epoch: 354| Step: 0
Training loss: 0.5313861335910732
Validation loss: 2.3736685046665453

Epoch: 5| Step: 1
Training loss: 0.5266247121129674
Validation loss: 2.3824771047268385

Epoch: 5| Step: 2
Training loss: 0.6320090432621609
Validation loss: 2.368432823316936

Epoch: 5| Step: 3
Training loss: 0.5653070768198467
Validation loss: 2.399086025493457

Epoch: 5| Step: 4
Training loss: 0.9243423933838608
Validation loss: 2.3720314274880505

Epoch: 5| Step: 5
Training loss: 0.4265499700026434
Validation loss: 2.363729668054858

Epoch: 5| Step: 6
Training loss: 0.5348888759538196
Validation loss: 2.3787312549936277

Epoch: 5| Step: 7
Training loss: 0.73041566870085
Validation loss: 2.3046832543986295

Epoch: 5| Step: 8
Training loss: 0.6835848126508397
Validation loss: 2.346623324913857

Epoch: 5| Step: 9
Training loss: 0.6613721766392674
Validation loss: 2.3521993467889204

Epoch: 5| Step: 10
Training loss: 0.7159120258942699
Validation loss: 2.368948235440645

Epoch: 355| Step: 0
Training loss: 0.5477890550173894
Validation loss: 2.3650264356444675

Epoch: 5| Step: 1
Training loss: 0.8533321855644117
Validation loss: 2.2952853616068034

Epoch: 5| Step: 2
Training loss: 0.7656594093531284
Validation loss: 2.3650086929982583

Epoch: 5| Step: 3
Training loss: 0.8642143971373729
Validation loss: 2.3354510799126964

Epoch: 5| Step: 4
Training loss: 0.5523707403470652
Validation loss: 2.4088049925108774

Epoch: 5| Step: 5
Training loss: 0.6363621748870317
Validation loss: 2.360598051493954

Epoch: 5| Step: 6
Training loss: 0.6179417938256092
Validation loss: 2.370315586517215

Epoch: 5| Step: 7
Training loss: 0.5165197527599016
Validation loss: 2.3589189188160495

Epoch: 5| Step: 8
Training loss: 0.5928978828632363
Validation loss: 2.392986347731484

Epoch: 5| Step: 9
Training loss: 0.36926110133307827
Validation loss: 2.3841322691006117

Epoch: 5| Step: 10
Training loss: 0.48511459429756054
Validation loss: 2.37045956169343

Epoch: 356| Step: 0
Training loss: 0.6064072994782376
Validation loss: 2.358439793045054

Epoch: 5| Step: 1
Training loss: 0.4525502934089192
Validation loss: 2.4039805710303472

Epoch: 5| Step: 2
Training loss: 0.49071415376651517
Validation loss: 2.344892468123486

Epoch: 5| Step: 3
Training loss: 0.3847232156221224
Validation loss: 2.383797710159847

Epoch: 5| Step: 4
Training loss: 0.7007231697841727
Validation loss: 2.3722061580826086

Epoch: 5| Step: 5
Training loss: 0.9162200179145097
Validation loss: 2.3673449745190136

Epoch: 5| Step: 6
Training loss: 0.6154847135311198
Validation loss: 2.3523558471894797

Epoch: 5| Step: 7
Training loss: 0.5818416107300673
Validation loss: 2.3540305090001503

Epoch: 5| Step: 8
Training loss: 0.7142070164923623
Validation loss: 2.338821168235673

Epoch: 5| Step: 9
Training loss: 0.7840649056426234
Validation loss: 2.3465766733403215

Epoch: 5| Step: 10
Training loss: 0.6228622115030198
Validation loss: 2.358009933899207

Epoch: 357| Step: 0
Training loss: 0.6412320865858067
Validation loss: 2.350797465045901

Epoch: 5| Step: 1
Training loss: 0.6484452212689767
Validation loss: 2.3527763416389713

Epoch: 5| Step: 2
Training loss: 0.5132049062497334
Validation loss: 2.3386336065819466

Epoch: 5| Step: 3
Training loss: 0.44401651156391636
Validation loss: 2.4087888026439

Epoch: 5| Step: 4
Training loss: 0.7692483682178128
Validation loss: 2.3619447201301638

Epoch: 5| Step: 5
Training loss: 0.3959893203701698
Validation loss: 2.362741367007424

Epoch: 5| Step: 6
Training loss: 0.6462393812196271
Validation loss: 2.3809602598566815

Epoch: 5| Step: 7
Training loss: 0.7335722980064305
Validation loss: 2.4068608280456916

Epoch: 5| Step: 8
Training loss: 0.6979100431061532
Validation loss: 2.3957820867235764

Epoch: 5| Step: 9
Training loss: 0.49893248862094025
Validation loss: 2.3756071759919877

Epoch: 5| Step: 10
Training loss: 0.9126689754435519
Validation loss: 2.395057313568849

Epoch: 358| Step: 0
Training loss: 0.6358881722704379
Validation loss: 2.3457421021915463

Epoch: 5| Step: 1
Training loss: 0.451484126249193
Validation loss: 2.4001076161661152

Epoch: 5| Step: 2
Training loss: 0.6945508578679024
Validation loss: 2.3521653182419384

Epoch: 5| Step: 3
Training loss: 0.5126132572450426
Validation loss: 2.3710812566325044

Epoch: 5| Step: 4
Training loss: 0.7636686749403462
Validation loss: 2.3761169007220486

Epoch: 5| Step: 5
Training loss: 0.569590411887546
Validation loss: 2.3689959376824117

Epoch: 5| Step: 6
Training loss: 0.5196393409660606
Validation loss: 2.402468186143799

Epoch: 5| Step: 7
Training loss: 0.6215174926910813
Validation loss: 2.3751642923788108

Epoch: 5| Step: 8
Training loss: 0.8486070354660012
Validation loss: 2.398143411846542

Epoch: 5| Step: 9
Training loss: 0.5638247625592412
Validation loss: 2.3886136676833205

Epoch: 5| Step: 10
Training loss: 0.7241023261222675
Validation loss: 2.4322798948395494

Epoch: 359| Step: 0
Training loss: 0.8286505776746454
Validation loss: 2.396963119742715

Epoch: 5| Step: 1
Training loss: 0.889708030203868
Validation loss: 2.3829779960334516

Epoch: 5| Step: 2
Training loss: 0.6338688075794296
Validation loss: 2.397807665576998

Epoch: 5| Step: 3
Training loss: 0.5569995459138674
Validation loss: 2.4280610671105864

Epoch: 5| Step: 4
Training loss: 0.6921618368588217
Validation loss: 2.3956477888326533

Epoch: 5| Step: 5
Training loss: 0.6370803180853588
Validation loss: 2.3852886936372677

Epoch: 5| Step: 6
Training loss: 0.4047268594284743
Validation loss: 2.3946519971897193

Epoch: 5| Step: 7
Training loss: 0.4761954911143901
Validation loss: 2.390410311026138

Epoch: 5| Step: 8
Training loss: 0.5324023035360725
Validation loss: 2.4037607926073146

Epoch: 5| Step: 9
Training loss: 0.61457193223971
Validation loss: 2.3629679512287476

Epoch: 5| Step: 10
Training loss: 0.5748841977645464
Validation loss: 2.394881921930352

Epoch: 360| Step: 0
Training loss: 0.4804615547447772
Validation loss: 2.3873333790845006

Epoch: 5| Step: 1
Training loss: 0.5980229717438559
Validation loss: 2.4011687421138257

Epoch: 5| Step: 2
Training loss: 0.8694390288303807
Validation loss: 2.3710219254830838

Epoch: 5| Step: 3
Training loss: 0.4723186232848976
Validation loss: 2.380488543830972

Epoch: 5| Step: 4
Training loss: 0.6152026455886814
Validation loss: 2.3688429786909992

Epoch: 5| Step: 5
Training loss: 0.5078750278417499
Validation loss: 2.369061630581317

Epoch: 5| Step: 6
Training loss: 0.7928994810921757
Validation loss: 2.3823382075884356

Epoch: 5| Step: 7
Training loss: 0.3610622149257185
Validation loss: 2.3794577698612276

Epoch: 5| Step: 8
Training loss: 0.5750472650590118
Validation loss: 2.3629787852549495

Epoch: 5| Step: 9
Training loss: 0.5278218115735619
Validation loss: 2.3553022587251986

Epoch: 5| Step: 10
Training loss: 0.8148385652137601
Validation loss: 2.348798856966626

Epoch: 361| Step: 0
Training loss: 0.7021705507236966
Validation loss: 2.3394695810504147

Epoch: 5| Step: 1
Training loss: 0.534742599225651
Validation loss: 2.351193069069093

Epoch: 5| Step: 2
Training loss: 0.278460912159013
Validation loss: 2.382678998935623

Epoch: 5| Step: 3
Training loss: 0.723040050966941
Validation loss: 2.3497344233945423

Epoch: 5| Step: 4
Training loss: 0.5766566419373228
Validation loss: 2.374691251753878

Epoch: 5| Step: 5
Training loss: 0.3563401785703919
Validation loss: 2.411134967709874

Epoch: 5| Step: 6
Training loss: 0.6416360738405451
Validation loss: 2.4179643478564206

Epoch: 5| Step: 7
Training loss: 0.49881595247214083
Validation loss: 2.3575836011165547

Epoch: 5| Step: 8
Training loss: 0.8154933516268212
Validation loss: 2.364550238782436

Epoch: 5| Step: 9
Training loss: 0.80142264382293
Validation loss: 2.3819125612514553

Epoch: 5| Step: 10
Training loss: 0.589551082533285
Validation loss: 2.363514441281745

Epoch: 362| Step: 0
Training loss: 0.7656768080640787
Validation loss: 2.3861064745513176

Epoch: 5| Step: 1
Training loss: 0.48634103964697656
Validation loss: 2.3570730106844304

Epoch: 5| Step: 2
Training loss: 0.48381684046046175
Validation loss: 2.375681372451292

Epoch: 5| Step: 3
Training loss: 0.3254504992476968
Validation loss: 2.367310979311077

Epoch: 5| Step: 4
Training loss: 0.6527262953709626
Validation loss: 2.377114078804294

Epoch: 5| Step: 5
Training loss: 0.6943200776210922
Validation loss: 2.353330701335997

Epoch: 5| Step: 6
Training loss: 0.5067449057971788
Validation loss: 2.382855782602418

Epoch: 5| Step: 7
Training loss: 0.68341312746982
Validation loss: 2.4115940664335014

Epoch: 5| Step: 8
Training loss: 0.7753197087449022
Validation loss: 2.3771605284914124

Epoch: 5| Step: 9
Training loss: 0.5651352928015749
Validation loss: 2.3772254085697795

Epoch: 5| Step: 10
Training loss: 0.7194786110509445
Validation loss: 2.3512851490342803

Epoch: 363| Step: 0
Training loss: 0.7092798211192193
Validation loss: 2.354910313178848

Epoch: 5| Step: 1
Training loss: 0.37729980655162715
Validation loss: 2.391809651340889

Epoch: 5| Step: 2
Training loss: 0.5773379664976676
Validation loss: 2.363585244429929

Epoch: 5| Step: 3
Training loss: 0.2286002499639925
Validation loss: 2.3678163039639615

Epoch: 5| Step: 4
Training loss: 0.5979054498672615
Validation loss: 2.3472772975977056

Epoch: 5| Step: 5
Training loss: 0.4766951360764863
Validation loss: 2.3802887395932752

Epoch: 5| Step: 6
Training loss: 0.6350327619226093
Validation loss: 2.342950384540607

Epoch: 5| Step: 7
Training loss: 0.8879018276865585
Validation loss: 2.369205216670565

Epoch: 5| Step: 8
Training loss: 0.5242149500702032
Validation loss: 2.3710643821025146

Epoch: 5| Step: 9
Training loss: 0.7767035373509455
Validation loss: 2.4142264378749365

Epoch: 5| Step: 10
Training loss: 0.6056807362248964
Validation loss: 2.409457358301647

Epoch: 364| Step: 0
Training loss: 0.7445908833786072
Validation loss: 2.3885389311181053

Epoch: 5| Step: 1
Training loss: 0.5431216182537613
Validation loss: 2.377418507493064

Epoch: 5| Step: 2
Training loss: 0.4410080928514056
Validation loss: 2.365135571996037

Epoch: 5| Step: 3
Training loss: 0.6089831584064304
Validation loss: 2.3218636083151623

Epoch: 5| Step: 4
Training loss: 0.7172671654031008
Validation loss: 2.3709130887425243

Epoch: 5| Step: 5
Training loss: 0.6036071214174907
Validation loss: 2.34739491766966

Epoch: 5| Step: 6
Training loss: 0.520790037898768
Validation loss: 2.352201943452528

Epoch: 5| Step: 7
Training loss: 0.5806836394067832
Validation loss: 2.3278256846275887

Epoch: 5| Step: 8
Training loss: 0.8012370231398828
Validation loss: 2.395839533501334

Epoch: 5| Step: 9
Training loss: 0.6513230338852234
Validation loss: 2.3757296220268596

Epoch: 5| Step: 10
Training loss: 0.5873465570990117
Validation loss: 2.4254310998146953

Epoch: 365| Step: 0
Training loss: 0.49207481729253755
Validation loss: 2.384020145667545

Epoch: 5| Step: 1
Training loss: 0.5347352982720887
Validation loss: 2.38258754691139

Epoch: 5| Step: 2
Training loss: 0.5258882286215977
Validation loss: 2.400327569409078

Epoch: 5| Step: 3
Training loss: 0.7801742777163507
Validation loss: 2.4252204983372483

Epoch: 5| Step: 4
Training loss: 0.8212271541164126
Validation loss: 2.378078967009179

Epoch: 5| Step: 5
Training loss: 0.35432205110745413
Validation loss: 2.413070704890636

Epoch: 5| Step: 6
Training loss: 0.49563724810557874
Validation loss: 2.423526713279463

Epoch: 5| Step: 7
Training loss: 0.5719449443463971
Validation loss: 2.337620116161445

Epoch: 5| Step: 8
Training loss: 0.7363985468127465
Validation loss: 2.3824496795378125

Epoch: 5| Step: 9
Training loss: 0.7313857824651815
Validation loss: 2.3810819676435138

Epoch: 5| Step: 10
Training loss: 0.540831579309371
Validation loss: 2.3936340752912906

Epoch: 366| Step: 0
Training loss: 0.5756179474472107
Validation loss: 2.3749506696447225

Epoch: 5| Step: 1
Training loss: 0.48540969285607855
Validation loss: 2.313146745194345

Epoch: 5| Step: 2
Training loss: 0.6493297550861977
Validation loss: 2.3577492283397956

Epoch: 5| Step: 3
Training loss: 0.590620804827288
Validation loss: 2.3839691652364565

Epoch: 5| Step: 4
Training loss: 0.7649072279807171
Validation loss: 2.385505595799519

Epoch: 5| Step: 5
Training loss: 0.8076348262461276
Validation loss: 2.3509515978527795

Epoch: 5| Step: 6
Training loss: 0.48790442612906393
Validation loss: 2.3193770533459457

Epoch: 5| Step: 7
Training loss: 0.5555812458880075
Validation loss: 2.322608850840812

Epoch: 5| Step: 8
Training loss: 0.7441381819877672
Validation loss: 2.3068385816256716

Epoch: 5| Step: 9
Training loss: 0.2187290607376077
Validation loss: 2.3000873820486167

Epoch: 5| Step: 10
Training loss: 0.5069005553815383
Validation loss: 2.3290330209413512

Epoch: 367| Step: 0
Training loss: 0.1903039174579736
Validation loss: 2.3152869657483404

Epoch: 5| Step: 1
Training loss: 0.7060929495124644
Validation loss: 2.3316122562125323

Epoch: 5| Step: 2
Training loss: 0.6150496917125939
Validation loss: 2.288433324048624

Epoch: 5| Step: 3
Training loss: 0.6352577062752648
Validation loss: 2.312261157241254

Epoch: 5| Step: 4
Training loss: 0.5582195709347194
Validation loss: 2.3538420469072863

Epoch: 5| Step: 5
Training loss: 0.6663194114570639
Validation loss: 2.334030343545819

Epoch: 5| Step: 6
Training loss: 0.652292900616301
Validation loss: 2.317841301468568

Epoch: 5| Step: 7
Training loss: 0.6359216814627824
Validation loss: 2.329507288979299

Epoch: 5| Step: 8
Training loss: 0.4432450369725406
Validation loss: 2.3153611951781783

Epoch: 5| Step: 9
Training loss: 0.37407160117694466
Validation loss: 2.3665962933527496

Epoch: 5| Step: 10
Training loss: 0.8125345149412015
Validation loss: 2.333944446841582

Epoch: 368| Step: 0
Training loss: 0.6649584392237818
Validation loss: 2.313968454945803

Epoch: 5| Step: 1
Training loss: 0.5827170562318559
Validation loss: 2.3024130623000905

Epoch: 5| Step: 2
Training loss: 0.5490485458033777
Validation loss: 2.3111071816843

Epoch: 5| Step: 3
Training loss: 0.646101039859187
Validation loss: 2.288236450025198

Epoch: 5| Step: 4
Training loss: 0.47222515024262257
Validation loss: 2.3363974813834165

Epoch: 5| Step: 5
Training loss: 0.6075797412483425
Validation loss: 2.3108895538440866

Epoch: 5| Step: 6
Training loss: 0.5597794493134801
Validation loss: 2.3449618932851224

Epoch: 5| Step: 7
Training loss: 0.8163967953367196
Validation loss: 2.3216474680044237

Epoch: 5| Step: 8
Training loss: 0.5102779401019691
Validation loss: 2.345192527802745

Epoch: 5| Step: 9
Training loss: 0.42818910995846676
Validation loss: 2.337679882716484

Epoch: 5| Step: 10
Training loss: 0.49417352378402024
Validation loss: 2.3486484111856045

Epoch: 369| Step: 0
Training loss: 0.39034299207562945
Validation loss: 2.373351757335921

Epoch: 5| Step: 1
Training loss: 0.35484382696583433
Validation loss: 2.3320673171990087

Epoch: 5| Step: 2
Training loss: 0.6337392167296947
Validation loss: 2.396677157701846

Epoch: 5| Step: 3
Training loss: 0.7997236758088577
Validation loss: 2.3652686688537212

Epoch: 5| Step: 4
Training loss: 0.6425463543954198
Validation loss: 2.40464483279479

Epoch: 5| Step: 5
Training loss: 0.4484544970119017
Validation loss: 2.406788891762814

Epoch: 5| Step: 6
Training loss: 0.4467909513808889
Validation loss: 2.414018636357357

Epoch: 5| Step: 7
Training loss: 0.5861015344528395
Validation loss: 2.3885463873849737

Epoch: 5| Step: 8
Training loss: 0.7828775999369261
Validation loss: 2.3792545043420783

Epoch: 5| Step: 9
Training loss: 0.6216411936998133
Validation loss: 2.381594861901327

Epoch: 5| Step: 10
Training loss: 0.4712401527924092
Validation loss: 2.38389443684545

Epoch: 370| Step: 0
Training loss: 0.647634422569446
Validation loss: 2.4306884989049444

Epoch: 5| Step: 1
Training loss: 0.4971891609610118
Validation loss: 2.4026108523991745

Epoch: 5| Step: 2
Training loss: 0.6459200144607877
Validation loss: 2.4234782416388136

Epoch: 5| Step: 3
Training loss: 0.683589957090482
Validation loss: 2.381727798896299

Epoch: 5| Step: 4
Training loss: 0.645767044439087
Validation loss: 2.3920329129899414

Epoch: 5| Step: 5
Training loss: 0.3917845491122975
Validation loss: 2.3476669029818735

Epoch: 5| Step: 6
Training loss: 0.7249236132402256
Validation loss: 2.3795875915148743

Epoch: 5| Step: 7
Training loss: 0.453371967230856
Validation loss: 2.3873826758591354

Epoch: 5| Step: 8
Training loss: 0.2570485442584283
Validation loss: 2.364224020132981

Epoch: 5| Step: 9
Training loss: 0.3207684504969722
Validation loss: 2.356863522422156

Epoch: 5| Step: 10
Training loss: 0.7850397507510348
Validation loss: 2.3687966559493967

Epoch: 371| Step: 0
Training loss: 0.33911707346630837
Validation loss: 2.3942924730687998

Epoch: 5| Step: 1
Training loss: 0.9250578166316569
Validation loss: 2.3778302675599368

Epoch: 5| Step: 2
Training loss: 0.549935008674057
Validation loss: 2.407101444699531

Epoch: 5| Step: 3
Training loss: 0.42882107165084077
Validation loss: 2.3699912107003613

Epoch: 5| Step: 4
Training loss: 0.5268773594958416
Validation loss: 2.4001795428125248

Epoch: 5| Step: 5
Training loss: 0.6223175659341283
Validation loss: 2.353891630129949

Epoch: 5| Step: 6
Training loss: 0.3598123874157227
Validation loss: 2.3614198010790846

Epoch: 5| Step: 7
Training loss: 0.37640340776269043
Validation loss: 2.3364805495129835

Epoch: 5| Step: 8
Training loss: 0.6012097104505998
Validation loss: 2.3700400223127707

Epoch: 5| Step: 9
Training loss: 0.8350577671946741
Validation loss: 2.3808927374428888

Epoch: 5| Step: 10
Training loss: 0.4798507748048932
Validation loss: 2.3625883372920935

Epoch: 372| Step: 0
Training loss: 0.41673104464370286
Validation loss: 2.356181477592413

Epoch: 5| Step: 1
Training loss: 0.687801533377198
Validation loss: 2.375339887441845

Epoch: 5| Step: 2
Training loss: 0.4729157830816857
Validation loss: 2.373393814745685

Epoch: 5| Step: 3
Training loss: 0.6097581588024097
Validation loss: 2.37233300929174

Epoch: 5| Step: 4
Training loss: 0.6676684591336248
Validation loss: 2.377086123140708

Epoch: 5| Step: 5
Training loss: 0.5677040753219462
Validation loss: 2.407391301331635

Epoch: 5| Step: 6
Training loss: 0.49803523629744995
Validation loss: 2.4118626157160055

Epoch: 5| Step: 7
Training loss: 0.5663908068426083
Validation loss: 2.3851093230909206

Epoch: 5| Step: 8
Training loss: 0.6446803527376673
Validation loss: 2.337208463185312

Epoch: 5| Step: 9
Training loss: 0.5808720662334541
Validation loss: 2.340149292595062

Epoch: 5| Step: 10
Training loss: 0.6978071658267553
Validation loss: 2.338276634286992

Epoch: 373| Step: 0
Training loss: 0.4301652852920193
Validation loss: 2.3371501686930385

Epoch: 5| Step: 1
Training loss: 0.7532994096074841
Validation loss: 2.335750919048437

Epoch: 5| Step: 2
Training loss: 0.3516893475892282
Validation loss: 2.3162495690962692

Epoch: 5| Step: 3
Training loss: 0.7380403801898867
Validation loss: 2.323472719663248

Epoch: 5| Step: 4
Training loss: 0.5704842661510913
Validation loss: 2.3769383031085174

Epoch: 5| Step: 5
Training loss: 0.6706425207858767
Validation loss: 2.372437895082324

Epoch: 5| Step: 6
Training loss: 0.5899418376686756
Validation loss: 2.397446818224854

Epoch: 5| Step: 7
Training loss: 0.5834683335855283
Validation loss: 2.439951030095897

Epoch: 5| Step: 8
Training loss: 0.24461702786234177
Validation loss: 2.4481851629929077

Epoch: 5| Step: 9
Training loss: 0.7030181379705087
Validation loss: 2.467093506346609

Epoch: 5| Step: 10
Training loss: 0.42414620764517685
Validation loss: 2.45133664111323

Epoch: 374| Step: 0
Training loss: 0.43559254633505057
Validation loss: 2.469470403818817

Epoch: 5| Step: 1
Training loss: 0.29811620993221366
Validation loss: 2.443371410662704

Epoch: 5| Step: 2
Training loss: 0.6771090038030497
Validation loss: 2.4254673107418676

Epoch: 5| Step: 3
Training loss: 0.6298204494624609
Validation loss: 2.449347242741966

Epoch: 5| Step: 4
Training loss: 0.7472452594636064
Validation loss: 2.427230909342051

Epoch: 5| Step: 5
Training loss: 0.5690100704049483
Validation loss: 2.3985234182005932

Epoch: 5| Step: 6
Training loss: 0.34628734685017776
Validation loss: 2.395901596002826

Epoch: 5| Step: 7
Training loss: 0.6370244140857046
Validation loss: 2.416663292559629

Epoch: 5| Step: 8
Training loss: 0.5942301063946993
Validation loss: 2.4042471317100893

Epoch: 5| Step: 9
Training loss: 0.6530866675558481
Validation loss: 2.403129468755513

Epoch: 5| Step: 10
Training loss: 0.46223188761004563
Validation loss: 2.4053678836057437

Epoch: 375| Step: 0
Training loss: 0.3715888485176619
Validation loss: 2.3991149584764977

Epoch: 5| Step: 1
Training loss: 0.49238518877375265
Validation loss: 2.406237281112606

Epoch: 5| Step: 2
Training loss: 0.5488101779813466
Validation loss: 2.3799041692285403

Epoch: 5| Step: 3
Training loss: 0.4768469540009436
Validation loss: 2.413921722853624

Epoch: 5| Step: 4
Training loss: 0.6140699235695515
Validation loss: 2.3913830086168697

Epoch: 5| Step: 5
Training loss: 0.5550676842820996
Validation loss: 2.415950909603501

Epoch: 5| Step: 6
Training loss: 0.43987237217197606
Validation loss: 2.413694661724643

Epoch: 5| Step: 7
Training loss: 0.6302465054219564
Validation loss: 2.406536707945718

Epoch: 5| Step: 8
Training loss: 0.686888053950494
Validation loss: 2.4063969154292213

Epoch: 5| Step: 9
Training loss: 0.6217770925922464
Validation loss: 2.411526278088726

Epoch: 5| Step: 10
Training loss: 0.6277033752497122
Validation loss: 2.4231809992175406

Epoch: 376| Step: 0
Training loss: 0.4646542747999984
Validation loss: 2.4106610112082842

Epoch: 5| Step: 1
Training loss: 0.593032277640802
Validation loss: 2.381180864232185

Epoch: 5| Step: 2
Training loss: 0.7059221367517298
Validation loss: 2.3752818261522113

Epoch: 5| Step: 3
Training loss: 0.49645034109137115
Validation loss: 2.3835610733392247

Epoch: 5| Step: 4
Training loss: 0.6876448782076121
Validation loss: 2.4047398702095792

Epoch: 5| Step: 5
Training loss: 0.5485620362696101
Validation loss: 2.3794959441829193

Epoch: 5| Step: 6
Training loss: 0.6943821630099861
Validation loss: 2.389630588007361

Epoch: 5| Step: 7
Training loss: 0.44547083198224074
Validation loss: 2.383198732045568

Epoch: 5| Step: 8
Training loss: 0.28138160275677626
Validation loss: 2.3738676630618096

Epoch: 5| Step: 9
Training loss: 0.4848862380387179
Validation loss: 2.3416382597522505

Epoch: 5| Step: 10
Training loss: 0.581836437418487
Validation loss: 2.399252640756587

Epoch: 377| Step: 0
Training loss: 0.45084521205128536
Validation loss: 2.3564426933141327

Epoch: 5| Step: 1
Training loss: 0.6933229678629331
Validation loss: 2.3561664494132524

Epoch: 5| Step: 2
Training loss: 0.4230252233091312
Validation loss: 2.405176745598544

Epoch: 5| Step: 3
Training loss: 0.5099776839067429
Validation loss: 2.386323577941684

Epoch: 5| Step: 4
Training loss: 0.5720071045927841
Validation loss: 2.372724884400951

Epoch: 5| Step: 5
Training loss: 0.6542519852910952
Validation loss: 2.374116272251674

Epoch: 5| Step: 6
Training loss: 0.5762461986126745
Validation loss: 2.3982579728340783

Epoch: 5| Step: 7
Training loss: 0.4025837636057132
Validation loss: 2.382265826743546

Epoch: 5| Step: 8
Training loss: 0.5707509693767454
Validation loss: 2.4007614072186807

Epoch: 5| Step: 9
Training loss: 0.44442756462659727
Validation loss: 2.409545341292439

Epoch: 5| Step: 10
Training loss: 0.694060258823093
Validation loss: 2.426193441921004

Epoch: 378| Step: 0
Training loss: 0.43252903576224805
Validation loss: 2.3949532460446705

Epoch: 5| Step: 1
Training loss: 0.6095617203869308
Validation loss: 2.403594771424447

Epoch: 5| Step: 2
Training loss: 0.562193522142744
Validation loss: 2.448825472862804

Epoch: 5| Step: 3
Training loss: 0.41496750158579915
Validation loss: 2.416356478067317

Epoch: 5| Step: 4
Training loss: 0.5454796018589136
Validation loss: 2.406490324047947

Epoch: 5| Step: 5
Training loss: 0.6769033608522639
Validation loss: 2.399566199892518

Epoch: 5| Step: 6
Training loss: 0.7879538726763758
Validation loss: 2.4215052062686087

Epoch: 5| Step: 7
Training loss: 0.3516372283351126
Validation loss: 2.4051065081132377

Epoch: 5| Step: 8
Training loss: 0.49315043515554874
Validation loss: 2.4032840590936857

Epoch: 5| Step: 9
Training loss: 0.6053836147381456
Validation loss: 2.4002148166778148

Epoch: 5| Step: 10
Training loss: 0.5171785935848017
Validation loss: 2.392741933090794

Epoch: 379| Step: 0
Training loss: 0.5597898575195487
Validation loss: 2.378907402013105

Epoch: 5| Step: 1
Training loss: 0.48926990364651807
Validation loss: 2.3521063914280034

Epoch: 5| Step: 2
Training loss: 0.4831738036749156
Validation loss: 2.4100550395641194

Epoch: 5| Step: 3
Training loss: 0.6614057014331485
Validation loss: 2.3988771496933237

Epoch: 5| Step: 4
Training loss: 0.3489087612849263
Validation loss: 2.3886682517073075

Epoch: 5| Step: 5
Training loss: 0.6100452112031024
Validation loss: 2.420936617032525

Epoch: 5| Step: 6
Training loss: 0.6408051493349715
Validation loss: 2.4200218539097427

Epoch: 5| Step: 7
Training loss: 0.3815055647227957
Validation loss: 2.3926885659479886

Epoch: 5| Step: 8
Training loss: 0.6716753197184381
Validation loss: 2.401289410700606

Epoch: 5| Step: 9
Training loss: 0.6413859987953304
Validation loss: 2.4293812782783935

Epoch: 5| Step: 10
Training loss: 0.41236300144159865
Validation loss: 2.415540251985545

Epoch: 380| Step: 0
Training loss: 0.444029264152597
Validation loss: 2.4388648861303563

Epoch: 5| Step: 1
Training loss: 0.5422818346435335
Validation loss: 2.4040050259318306

Epoch: 5| Step: 2
Training loss: 0.4187934440167964
Validation loss: 2.401321113704672

Epoch: 5| Step: 3
Training loss: 0.3935944227127317
Validation loss: 2.4198330890873523

Epoch: 5| Step: 4
Training loss: 0.5978053287249462
Validation loss: 2.377010826225927

Epoch: 5| Step: 5
Training loss: 0.3605011006866244
Validation loss: 2.4065449031474633

Epoch: 5| Step: 6
Training loss: 0.6113139629247056
Validation loss: 2.3768573055148154

Epoch: 5| Step: 7
Training loss: 0.5186915100398626
Validation loss: 2.3952233035896966

Epoch: 5| Step: 8
Training loss: 0.867867658412363
Validation loss: 2.4157403826327513

Epoch: 5| Step: 9
Training loss: 0.4152739993089714
Validation loss: 2.4438222305394497

Epoch: 5| Step: 10
Training loss: 0.633195737481485
Validation loss: 2.3980034983353185

Epoch: 381| Step: 0
Training loss: 0.5958588193453455
Validation loss: 2.4053788224172297

Epoch: 5| Step: 1
Training loss: 0.5757830584845746
Validation loss: 2.38861423007964

Epoch: 5| Step: 2
Training loss: 0.6600138267961654
Validation loss: 2.402708805232446

Epoch: 5| Step: 3
Training loss: 0.5173186893551449
Validation loss: 2.401698264659741

Epoch: 5| Step: 4
Training loss: 0.3499161530435882
Validation loss: 2.402640198548897

Epoch: 5| Step: 5
Training loss: 0.5511730234632957
Validation loss: 2.407024552404052

Epoch: 5| Step: 6
Training loss: 0.6018092404941939
Validation loss: 2.3818567428612227

Epoch: 5| Step: 7
Training loss: 0.2642007962200431
Validation loss: 2.3912107031796745

Epoch: 5| Step: 8
Training loss: 0.43986356429736323
Validation loss: 2.3863090984077124

Epoch: 5| Step: 9
Training loss: 0.4452386426746227
Validation loss: 2.4034395013458854

Epoch: 5| Step: 10
Training loss: 0.7573588871845005
Validation loss: 2.4026482149801445

Epoch: 382| Step: 0
Training loss: 0.5867017974639375
Validation loss: 2.3659981706889037

Epoch: 5| Step: 1
Training loss: 0.4384476582063424
Validation loss: 2.3949695765380765

Epoch: 5| Step: 2
Training loss: 0.5815299262466792
Validation loss: 2.3967493033517226

Epoch: 5| Step: 3
Training loss: 0.7541546980468401
Validation loss: 2.3922272761087005

Epoch: 5| Step: 4
Training loss: 0.14962381089087762
Validation loss: 2.4500569290702603

Epoch: 5| Step: 5
Training loss: 0.5926816262751922
Validation loss: 2.3925370557691097

Epoch: 5| Step: 6
Training loss: 0.45852682154899765
Validation loss: 2.4091436866750553

Epoch: 5| Step: 7
Training loss: 0.6823328869625148
Validation loss: 2.39861876655953

Epoch: 5| Step: 8
Training loss: 0.4367498540293947
Validation loss: 2.4054697021028053

Epoch: 5| Step: 9
Training loss: 0.4895790553075139
Validation loss: 2.4175988041434153

Epoch: 5| Step: 10
Training loss: 0.3587783753740352
Validation loss: 2.4014006002437163

Epoch: 383| Step: 0
Training loss: 0.40359410190308487
Validation loss: 2.397685453169663

Epoch: 5| Step: 1
Training loss: 0.6663222963281927
Validation loss: 2.4156767508293866

Epoch: 5| Step: 2
Training loss: 0.3863038621463515
Validation loss: 2.4087791378417016

Epoch: 5| Step: 3
Training loss: 0.7042500925209599
Validation loss: 2.397181571267512

Epoch: 5| Step: 4
Training loss: 0.300810081784491
Validation loss: 2.4366088554976404

Epoch: 5| Step: 5
Training loss: 0.6295355734223389
Validation loss: 2.377131255496505

Epoch: 5| Step: 6
Training loss: 0.6047046639226784
Validation loss: 2.3925365591216052

Epoch: 5| Step: 7
Training loss: 0.4583792410603092
Validation loss: 2.4011205638411366

Epoch: 5| Step: 8
Training loss: 0.45140094639087797
Validation loss: 2.3853582572171517

Epoch: 5| Step: 9
Training loss: 0.5021173824409578
Validation loss: 2.4206446618405453

Epoch: 5| Step: 10
Training loss: 0.5032932485898819
Validation loss: 2.4155563095750883

Epoch: 384| Step: 0
Training loss: 0.35061451999961385
Validation loss: 2.394178432796057

Epoch: 5| Step: 1
Training loss: 0.5333677324238424
Validation loss: 2.41542955996697

Epoch: 5| Step: 2
Training loss: 0.41621421050096497
Validation loss: 2.409185985979588

Epoch: 5| Step: 3
Training loss: 0.5872892935295463
Validation loss: 2.3987848414412376

Epoch: 5| Step: 4
Training loss: 0.44533250997994506
Validation loss: 2.4031247396594457

Epoch: 5| Step: 5
Training loss: 0.5209903734602792
Validation loss: 2.3664781061232465

Epoch: 5| Step: 6
Training loss: 0.6507717081494686
Validation loss: 2.40308587601579

Epoch: 5| Step: 7
Training loss: 0.49164918192253537
Validation loss: 2.387096909113794

Epoch: 5| Step: 8
Training loss: 0.5212419496458897
Validation loss: 2.3885018887862732

Epoch: 5| Step: 9
Training loss: 0.4263942750092881
Validation loss: 2.3899463138170445

Epoch: 5| Step: 10
Training loss: 0.661783751590769
Validation loss: 2.3925160673664085

Epoch: 385| Step: 0
Training loss: 0.480828220526466
Validation loss: 2.390482580929367

Epoch: 5| Step: 1
Training loss: 0.45238874076619773
Validation loss: 2.4254086980030944

Epoch: 5| Step: 2
Training loss: 0.46306188449311564
Validation loss: 2.419590297695528

Epoch: 5| Step: 3
Training loss: 0.2014531511694192
Validation loss: 2.40914831190907

Epoch: 5| Step: 4
Training loss: 0.7129712620945268
Validation loss: 2.3909135499972423

Epoch: 5| Step: 5
Training loss: 0.32316706035029996
Validation loss: 2.376739755270735

Epoch: 5| Step: 6
Training loss: 0.32610674453382893
Validation loss: 2.3677561920993955

Epoch: 5| Step: 7
Training loss: 0.6992357347865635
Validation loss: 2.405614353704424

Epoch: 5| Step: 8
Training loss: 0.5158907465600852
Validation loss: 2.394955841311765

Epoch: 5| Step: 9
Training loss: 0.43196890934795845
Validation loss: 2.387188036427369

Epoch: 5| Step: 10
Training loss: 0.7253203900855992
Validation loss: 2.3833980707552023

Epoch: 386| Step: 0
Training loss: 0.2015001710732446
Validation loss: 2.412673081498157

Epoch: 5| Step: 1
Training loss: 0.6876150598478455
Validation loss: 2.399884931051567

Epoch: 5| Step: 2
Training loss: 0.5165980146030255
Validation loss: 2.3785939185605094

Epoch: 5| Step: 3
Training loss: 0.4899678360590916
Validation loss: 2.4101761748152004

Epoch: 5| Step: 4
Training loss: 0.33197924262745065
Validation loss: 2.409937861866982

Epoch: 5| Step: 5
Training loss: 0.6388205492284922
Validation loss: 2.363533244015872

Epoch: 5| Step: 6
Training loss: 0.45736403453846486
Validation loss: 2.390520663380323

Epoch: 5| Step: 7
Training loss: 0.6021461380361873
Validation loss: 2.388924463231703

Epoch: 5| Step: 8
Training loss: 0.4687728876248275
Validation loss: 2.4215490931021373

Epoch: 5| Step: 9
Training loss: 0.6360013465792118
Validation loss: 2.4283541544445604

Epoch: 5| Step: 10
Training loss: 0.3927704638838537
Validation loss: 2.3928563787718553

Epoch: 387| Step: 0
Training loss: 0.6759273613651291
Validation loss: 2.4343895767156507

Epoch: 5| Step: 1
Training loss: 0.4906361669739559
Validation loss: 2.393282884171242

Epoch: 5| Step: 2
Training loss: 0.6606693192686007
Validation loss: 2.431769690226735

Epoch: 5| Step: 3
Training loss: 0.4513384028673128
Validation loss: 2.406120542120952

Epoch: 5| Step: 4
Training loss: 0.34570824355307056
Validation loss: 2.423070607579115

Epoch: 5| Step: 5
Training loss: 0.46722963455704514
Validation loss: 2.4488466638336552

Epoch: 5| Step: 6
Training loss: 0.435495655828679
Validation loss: 2.3930696366881934

Epoch: 5| Step: 7
Training loss: 0.5698646720641504
Validation loss: 2.433521443034185

Epoch: 5| Step: 8
Training loss: 0.3685808327138897
Validation loss: 2.392872570370392

Epoch: 5| Step: 9
Training loss: 0.6526596309619043
Validation loss: 2.3908959774760814

Epoch: 5| Step: 10
Training loss: 0.3002599682546787
Validation loss: 2.3807989549901842

Epoch: 388| Step: 0
Training loss: 0.5456463226486672
Validation loss: 2.3887714704671867

Epoch: 5| Step: 1
Training loss: 0.35075571948559003
Validation loss: 2.3845081747871086

Epoch: 5| Step: 2
Training loss: 0.4378143611653295
Validation loss: 2.3960365023791645

Epoch: 5| Step: 3
Training loss: 0.757135226231805
Validation loss: 2.4147668417564456

Epoch: 5| Step: 4
Training loss: 0.4633656249640236
Validation loss: 2.4275756802021804

Epoch: 5| Step: 5
Training loss: 0.49358153849461167
Validation loss: 2.3998826503691535

Epoch: 5| Step: 6
Training loss: 0.36451260243909495
Validation loss: 2.438699673701417

Epoch: 5| Step: 7
Training loss: 0.5831981201365933
Validation loss: 2.4073061032441254

Epoch: 5| Step: 8
Training loss: 0.5530642276719256
Validation loss: 2.4056049681488854

Epoch: 5| Step: 9
Training loss: 0.5130660977864201
Validation loss: 2.4209279378972828

Epoch: 5| Step: 10
Training loss: 0.29866967332384203
Validation loss: 2.4051575670621035

Epoch: 389| Step: 0
Training loss: 0.40100365206727306
Validation loss: 2.3666270653379335

Epoch: 5| Step: 1
Training loss: 0.5040597016646486
Validation loss: 2.3782222846323386

Epoch: 5| Step: 2
Training loss: 0.5659903479197943
Validation loss: 2.39344648121967

Epoch: 5| Step: 3
Training loss: 0.41385541091733186
Validation loss: 2.3727209282836306

Epoch: 5| Step: 4
Training loss: 0.4637250983809272
Validation loss: 2.3842690505056496

Epoch: 5| Step: 5
Training loss: 0.5645014072346611
Validation loss: 2.388257471415496

Epoch: 5| Step: 6
Training loss: 0.2485584630324225
Validation loss: 2.3876332192217653

Epoch: 5| Step: 7
Training loss: 0.4697741129514541
Validation loss: 2.348929713061456

Epoch: 5| Step: 8
Training loss: 0.6040127136032413
Validation loss: 2.375798697203087

Epoch: 5| Step: 9
Training loss: 0.6682888401787589
Validation loss: 2.3953149817072013

Epoch: 5| Step: 10
Training loss: 0.5944626195848476
Validation loss: 2.4330175607796147

Epoch: 390| Step: 0
Training loss: 0.296607788193423
Validation loss: 2.3991777435379165

Epoch: 5| Step: 1
Training loss: 0.5817536069481951
Validation loss: 2.432220591452851

Epoch: 5| Step: 2
Training loss: 0.6469247937042288
Validation loss: 2.4356913270595224

Epoch: 5| Step: 3
Training loss: 0.5261764605463234
Validation loss: 2.4186293698010797

Epoch: 5| Step: 4
Training loss: 0.5871786324164912
Validation loss: 2.432860415440978

Epoch: 5| Step: 5
Training loss: 0.18713455548412544
Validation loss: 2.4009116354705924

Epoch: 5| Step: 6
Training loss: 0.367698030444533
Validation loss: 2.4189473897414584

Epoch: 5| Step: 7
Training loss: 0.6202833058287952
Validation loss: 2.4030563091417876

Epoch: 5| Step: 8
Training loss: 0.4830549618930811
Validation loss: 2.3908327845997266

Epoch: 5| Step: 9
Training loss: 0.5164950861387826
Validation loss: 2.3602763731018714

Epoch: 5| Step: 10
Training loss: 0.4982337301950364
Validation loss: 2.3976390210006464

Epoch: 391| Step: 0
Training loss: 0.3554601563473367
Validation loss: 2.357984719301655

Epoch: 5| Step: 1
Training loss: 0.6110930554535483
Validation loss: 2.3872515266008274

Epoch: 5| Step: 2
Training loss: 0.4837246189309731
Validation loss: 2.3908084297946948

Epoch: 5| Step: 3
Training loss: 0.5337327834664843
Validation loss: 2.3731047921975055

Epoch: 5| Step: 4
Training loss: 0.47877405156010794
Validation loss: 2.383436287376522

Epoch: 5| Step: 5
Training loss: 0.40171794925403653
Validation loss: 2.351167193656525

Epoch: 5| Step: 6
Training loss: 0.6319906290059744
Validation loss: 2.3881562136972043

Epoch: 5| Step: 7
Training loss: 0.5703919237825064
Validation loss: 2.347574929535237

Epoch: 5| Step: 8
Training loss: 0.5101404675412743
Validation loss: 2.3877153023459843

Epoch: 5| Step: 9
Training loss: 0.21320023902010535
Validation loss: 2.361013061020526

Epoch: 5| Step: 10
Training loss: 0.5886728146247477
Validation loss: 2.340318296317519

Epoch: 392| Step: 0
Training loss: 0.267708920442306
Validation loss: 2.372405818532192

Epoch: 5| Step: 1
Training loss: 0.5059730372633355
Validation loss: 2.3831720001297008

Epoch: 5| Step: 2
Training loss: 0.4046428876758257
Validation loss: 2.3643611037193875

Epoch: 5| Step: 3
Training loss: 0.5050804887496501
Validation loss: 2.39312559312061

Epoch: 5| Step: 4
Training loss: 0.6939799365900475
Validation loss: 2.3700003630218704

Epoch: 5| Step: 5
Training loss: 0.3663518812433493
Validation loss: 2.3661075347156832

Epoch: 5| Step: 6
Training loss: 0.4308614127282991
Validation loss: 2.408661660725574

Epoch: 5| Step: 7
Training loss: 0.7020383491216605
Validation loss: 2.3809791789253447

Epoch: 5| Step: 8
Training loss: 0.48809730116616407
Validation loss: 2.3759941854799047

Epoch: 5| Step: 9
Training loss: 0.43994006835192134
Validation loss: 2.35633442727657

Epoch: 5| Step: 10
Training loss: 0.5034212247371366
Validation loss: 2.3815429748427754

Epoch: 393| Step: 0
Training loss: 0.454625670171647
Validation loss: 2.3906897891908083

Epoch: 5| Step: 1
Training loss: 0.5791520455342155
Validation loss: 2.4037785979654958

Epoch: 5| Step: 2
Training loss: 0.48373909708792134
Validation loss: 2.3958723652688865

Epoch: 5| Step: 3
Training loss: 0.6105911150992162
Validation loss: 2.3520278369407834

Epoch: 5| Step: 4
Training loss: 0.4843280677208348
Validation loss: 2.3616248730206073

Epoch: 5| Step: 5
Training loss: 0.5844275282644585
Validation loss: 2.3899922523805452

Epoch: 5| Step: 6
Training loss: 0.34279393409244013
Validation loss: 2.34807898793093

Epoch: 5| Step: 7
Training loss: 0.4321857479664009
Validation loss: 2.3763884375650313

Epoch: 5| Step: 8
Training loss: 0.4671645532031276
Validation loss: 2.365386512792167

Epoch: 5| Step: 9
Training loss: 0.4980259311236657
Validation loss: 2.3725871948884367

Epoch: 5| Step: 10
Training loss: 0.4344143362552949
Validation loss: 2.399490581134425

Epoch: 394| Step: 0
Training loss: 0.45097503661851235
Validation loss: 2.397391434233802

Epoch: 5| Step: 1
Training loss: 0.6630339342267851
Validation loss: 2.391504563844366

Epoch: 5| Step: 2
Training loss: 0.5158481981798957
Validation loss: 2.3624415623341677

Epoch: 5| Step: 3
Training loss: 0.3804615388222106
Validation loss: 2.369299944941866

Epoch: 5| Step: 4
Training loss: 0.46216655387125016
Validation loss: 2.37704421572173

Epoch: 5| Step: 5
Training loss: 0.685026270021566
Validation loss: 2.3682236682193274

Epoch: 5| Step: 6
Training loss: 0.5561835570782364
Validation loss: 2.3517292674781345

Epoch: 5| Step: 7
Training loss: 0.318016850912726
Validation loss: 2.3693557280593085

Epoch: 5| Step: 8
Training loss: 0.19696478045429466
Validation loss: 2.394197050391893

Epoch: 5| Step: 9
Training loss: 0.5517304000121451
Validation loss: 2.4170083256001775

Epoch: 5| Step: 10
Training loss: 0.42842589615147514
Validation loss: 2.381007062500883

Epoch: 395| Step: 0
Training loss: 0.5529820726292883
Validation loss: 2.402187097062119

Epoch: 5| Step: 1
Training loss: 0.8058724428671503
Validation loss: 2.400346397240027

Epoch: 5| Step: 2
Training loss: 0.3883543970298926
Validation loss: 2.389544007815565

Epoch: 5| Step: 3
Training loss: 0.2628857372674127
Validation loss: 2.404313889483236

Epoch: 5| Step: 4
Training loss: 0.4289395150936728
Validation loss: 2.403252739874794

Epoch: 5| Step: 5
Training loss: 0.46359988893482074
Validation loss: 2.4249150297981465

Epoch: 5| Step: 6
Training loss: 0.5708815466110968
Validation loss: 2.389237678730635

Epoch: 5| Step: 7
Training loss: 0.35616236913956634
Validation loss: 2.4152487526241013

Epoch: 5| Step: 8
Training loss: 0.42486519218228674
Validation loss: 2.400580663941543

Epoch: 5| Step: 9
Training loss: 0.38794460017136984
Validation loss: 2.3974856610016766

Epoch: 5| Step: 10
Training loss: 0.5904499500973358
Validation loss: 2.3887088712298845

Epoch: 396| Step: 0
Training loss: 0.6224588950117371
Validation loss: 2.3789269947717036

Epoch: 5| Step: 1
Training loss: 0.38638433774526787
Validation loss: 2.360212119274888

Epoch: 5| Step: 2
Training loss: 0.5465459651201678
Validation loss: 2.3747251418498307

Epoch: 5| Step: 3
Training loss: 0.154351309336888
Validation loss: 2.3634889751885195

Epoch: 5| Step: 4
Training loss: 0.42288385844952714
Validation loss: 2.4119204394666247

Epoch: 5| Step: 5
Training loss: 0.49068387765583515
Validation loss: 2.3923129104707055

Epoch: 5| Step: 6
Training loss: 0.4531649867862956
Validation loss: 2.3779911566046827

Epoch: 5| Step: 7
Training loss: 0.6518824196719661
Validation loss: 2.402678463349606

Epoch: 5| Step: 8
Training loss: 0.5170034997478508
Validation loss: 2.396116349320306

Epoch: 5| Step: 9
Training loss: 0.42839269622214093
Validation loss: 2.361143009743228

Epoch: 5| Step: 10
Training loss: 0.49841635967135267
Validation loss: 2.394484872296433

Epoch: 397| Step: 0
Training loss: 0.36132637229700537
Validation loss: 2.3627738715113615

Epoch: 5| Step: 1
Training loss: 0.4247541726431117
Validation loss: 2.3676150258861854

Epoch: 5| Step: 2
Training loss: 0.4787216054598514
Validation loss: 2.379532491061687

Epoch: 5| Step: 3
Training loss: 0.5395845290456752
Validation loss: 2.331870075274423

Epoch: 5| Step: 4
Training loss: 0.38359929020565386
Validation loss: 2.3875244310320167

Epoch: 5| Step: 5
Training loss: 0.49671377649304266
Validation loss: 2.4068348044360626

Epoch: 5| Step: 6
Training loss: 0.5672613069627125
Validation loss: 2.400370921740922

Epoch: 5| Step: 7
Training loss: 0.5098123930893216
Validation loss: 2.3723674425909707

Epoch: 5| Step: 8
Training loss: 0.27059300317208557
Validation loss: 2.3949182506083484

Epoch: 5| Step: 9
Training loss: 0.5825872645684956
Validation loss: 2.372472113985464

Epoch: 5| Step: 10
Training loss: 0.5653040191199804
Validation loss: 2.398634527013481

Epoch: 398| Step: 0
Training loss: 0.5560759239844578
Validation loss: 2.375770513483154

Epoch: 5| Step: 1
Training loss: 0.4943250681308782
Validation loss: 2.3943971549758607

Epoch: 5| Step: 2
Training loss: 0.30530269577777275
Validation loss: 2.3973742920235033

Epoch: 5| Step: 3
Training loss: 0.6071868638110399
Validation loss: 2.363819788502563

Epoch: 5| Step: 4
Training loss: 0.3690870740689023
Validation loss: 2.3506672486823637

Epoch: 5| Step: 5
Training loss: 0.44525057378814414
Validation loss: 2.3997670334884993

Epoch: 5| Step: 6
Training loss: 0.49629431147165964
Validation loss: 2.3319186541776076

Epoch: 5| Step: 7
Training loss: 0.559359951988994
Validation loss: 2.3739147669875122

Epoch: 5| Step: 8
Training loss: 0.5765451547551581
Validation loss: 2.3758708855383777

Epoch: 5| Step: 9
Training loss: 0.2713608769607909
Validation loss: 2.386982614209171

Epoch: 5| Step: 10
Training loss: 0.44640582537605833
Validation loss: 2.3824142583204515

Epoch: 399| Step: 0
Training loss: 0.47315602637972787
Validation loss: 2.3709596269351616

Epoch: 5| Step: 1
Training loss: 0.43650273352899893
Validation loss: 2.3756363193853205

Epoch: 5| Step: 2
Training loss: 0.3765250626627991
Validation loss: 2.407603038597191

Epoch: 5| Step: 3
Training loss: 0.2800212084026922
Validation loss: 2.385298536913001

Epoch: 5| Step: 4
Training loss: 0.6197750559485624
Validation loss: 2.4025027872315916

Epoch: 5| Step: 5
Training loss: 0.5094307570569888
Validation loss: 2.3799221412206144

Epoch: 5| Step: 6
Training loss: 0.4748692213270693
Validation loss: 2.3357711877105705

Epoch: 5| Step: 7
Training loss: 0.6157997319066975
Validation loss: 2.4184279909826762

Epoch: 5| Step: 8
Training loss: 0.5631975511224023
Validation loss: 2.3900340754264215

Epoch: 5| Step: 9
Training loss: 0.33711384917259435
Validation loss: 2.3586682197713484

Epoch: 5| Step: 10
Training loss: 0.21971338868385468
Validation loss: 2.372562786775505

Epoch: 400| Step: 0
Training loss: 0.5526255577997492
Validation loss: 2.3810495779455394

Epoch: 5| Step: 1
Training loss: 0.4606359271147047
Validation loss: 2.3489892325144677

Epoch: 5| Step: 2
Training loss: 0.5868602861341332
Validation loss: 2.3454038312884378

Epoch: 5| Step: 3
Training loss: 0.49891468811545486
Validation loss: 2.362645576620189

Epoch: 5| Step: 4
Training loss: 0.6132310494450762
Validation loss: 2.3932276681387425

Epoch: 5| Step: 5
Training loss: 0.3677975882178882
Validation loss: 2.3312934407373818

Epoch: 5| Step: 6
Training loss: 0.2507195399762959
Validation loss: 2.3634841515901615

Epoch: 5| Step: 7
Training loss: 0.4653566560103843
Validation loss: 2.3486605337831303

Epoch: 5| Step: 8
Training loss: 0.3658662318113153
Validation loss: 2.364282474420625

Epoch: 5| Step: 9
Training loss: 0.41349198966241674
Validation loss: 2.3951201316766695

Epoch: 5| Step: 10
Training loss: 0.5201721254070681
Validation loss: 2.401370471359813

Epoch: 401| Step: 0
Training loss: 0.35121077851393806
Validation loss: 2.3811975486429917

Epoch: 5| Step: 1
Training loss: 0.4227561754997189
Validation loss: 2.3658274574627116

Epoch: 5| Step: 2
Training loss: 0.5669662338240531
Validation loss: 2.3679209194061546

Epoch: 5| Step: 3
Training loss: 0.5726833966782721
Validation loss: 2.3593413995660435

Epoch: 5| Step: 4
Training loss: 0.39838308074914014
Validation loss: 2.365275267437055

Epoch: 5| Step: 5
Training loss: 0.3353903995124846
Validation loss: 2.316789116599729

Epoch: 5| Step: 6
Training loss: 0.5061963111759613
Validation loss: 2.3436939191774244

Epoch: 5| Step: 7
Training loss: 0.49294779350606444
Validation loss: 2.357933563021177

Epoch: 5| Step: 8
Training loss: 0.48771724934217836
Validation loss: 2.3642773802760755

Epoch: 5| Step: 9
Training loss: 0.524766913397228
Validation loss: 2.3988715711585167

Epoch: 5| Step: 10
Training loss: 0.4133988946722726
Validation loss: 2.35540509969953

Epoch: 402| Step: 0
Training loss: 0.3611404550175912
Validation loss: 2.3696789548498103

Epoch: 5| Step: 1
Training loss: 0.5910547973398751
Validation loss: 2.3608449958062714

Epoch: 5| Step: 2
Training loss: 0.2991444776899141
Validation loss: 2.339656261009163

Epoch: 5| Step: 3
Training loss: 0.2262005792695756
Validation loss: 2.324889879885974

Epoch: 5| Step: 4
Training loss: 0.4511956543043547
Validation loss: 2.3446470877723415

Epoch: 5| Step: 5
Training loss: 0.5981432856332694
Validation loss: 2.316645682940645

Epoch: 5| Step: 6
Training loss: 0.5122139551151128
Validation loss: 2.353410883912074

Epoch: 5| Step: 7
Training loss: 0.5380333738044156
Validation loss: 2.316736869193923

Epoch: 5| Step: 8
Training loss: 0.3493437370548029
Validation loss: 2.320986493548056

Epoch: 5| Step: 9
Training loss: 0.4332688807122662
Validation loss: 2.345487848065869

Epoch: 5| Step: 10
Training loss: 0.6698568551677114
Validation loss: 2.3648924790599066

Epoch: 403| Step: 0
Training loss: 0.4628628106754178
Validation loss: 2.3212516295332417

Epoch: 5| Step: 1
Training loss: 0.3761736464731053
Validation loss: 2.388805335199683

Epoch: 5| Step: 2
Training loss: 0.32774400162681816
Validation loss: 2.350036375531814

Epoch: 5| Step: 3
Training loss: 0.33847397959010367
Validation loss: 2.3636907147028015

Epoch: 5| Step: 4
Training loss: 0.5790899832019778
Validation loss: 2.3711443996322714

Epoch: 5| Step: 5
Training loss: 0.3087748828892041
Validation loss: 2.3566917923326494

Epoch: 5| Step: 6
Training loss: 0.4408586531881115
Validation loss: 2.3372800665103055

Epoch: 5| Step: 7
Training loss: 0.3548940267349867
Validation loss: 2.358520901940934

Epoch: 5| Step: 8
Training loss: 0.4678512062618584
Validation loss: 2.338499738148036

Epoch: 5| Step: 9
Training loss: 0.7462639739295307
Validation loss: 2.3331224028297575

Epoch: 5| Step: 10
Training loss: 0.5759266218212681
Validation loss: 2.307111924545122

Epoch: 404| Step: 0
Training loss: 0.5257697456994448
Validation loss: 2.364884851734453

Epoch: 5| Step: 1
Training loss: 0.4807892947411879
Validation loss: 2.3440991322797156

Epoch: 5| Step: 2
Training loss: 0.4410637564871633
Validation loss: 2.3354645893517594

Epoch: 5| Step: 3
Training loss: 0.523228019815877
Validation loss: 2.3381066310392242

Epoch: 5| Step: 4
Training loss: 0.3196653248021546
Validation loss: 2.3249005032095424

Epoch: 5| Step: 5
Training loss: 0.5967781747304393
Validation loss: 2.3621950204327913

Epoch: 5| Step: 6
Training loss: 0.5114557595068453
Validation loss: 2.3471571021566997

Epoch: 5| Step: 7
Training loss: 0.5229544047179543
Validation loss: 2.3552682916077816

Epoch: 5| Step: 8
Training loss: 0.3051273032784799
Validation loss: 2.3817647248514477

Epoch: 5| Step: 9
Training loss: 0.5088530223863504
Validation loss: 2.3632946068604848

Epoch: 5| Step: 10
Training loss: 0.20941801625656975
Validation loss: 2.364023919171585

Epoch: 405| Step: 0
Training loss: 0.41913708830209656
Validation loss: 2.3995494524950005

Epoch: 5| Step: 1
Training loss: 0.49376819733995964
Validation loss: 2.38733671500069

Epoch: 5| Step: 2
Training loss: 0.4402111043931599
Validation loss: 2.3499162224834307

Epoch: 5| Step: 3
Training loss: 0.3379764117229128
Validation loss: 2.404014411868533

Epoch: 5| Step: 4
Training loss: 0.5719538806232389
Validation loss: 2.40508819561288

Epoch: 5| Step: 5
Training loss: 0.32474998247412323
Validation loss: 2.398575548225673

Epoch: 5| Step: 6
Training loss: 0.4470714830722375
Validation loss: 2.3993034326771414

Epoch: 5| Step: 7
Training loss: 0.4377046855585081
Validation loss: 2.429082967196758

Epoch: 5| Step: 8
Training loss: 0.5250657222119025
Validation loss: 2.457144967434679

Epoch: 5| Step: 9
Training loss: 0.3802550779200474
Validation loss: 2.4360084303249945

Epoch: 5| Step: 10
Training loss: 0.67170677740515
Validation loss: 2.3906675513642277

Epoch: 406| Step: 0
Training loss: 0.30567776097811705
Validation loss: 2.4364991816685833

Epoch: 5| Step: 1
Training loss: 0.45578529193957334
Validation loss: 2.4197340527248246

Epoch: 5| Step: 2
Training loss: 0.3232619749161198
Validation loss: 2.418499331967103

Epoch: 5| Step: 3
Training loss: 0.5193659870912678
Validation loss: 2.4273158801793753

Epoch: 5| Step: 4
Training loss: 0.24453101417115755
Validation loss: 2.428919893784788

Epoch: 5| Step: 5
Training loss: 0.28665263637642513
Validation loss: 2.402633435831273

Epoch: 5| Step: 6
Training loss: 0.4857226359777574
Validation loss: 2.41866392305887

Epoch: 5| Step: 7
Training loss: 0.5335618932550079
Validation loss: 2.430870686819686

Epoch: 5| Step: 8
Training loss: 0.6595472427233027
Validation loss: 2.4387251638566525

Epoch: 5| Step: 9
Training loss: 0.5026113447029239
Validation loss: 2.450923673193053

Epoch: 5| Step: 10
Training loss: 0.5314803185196703
Validation loss: 2.4631679986643698

Epoch: 407| Step: 0
Training loss: 0.3656073109512955
Validation loss: 2.4536000273808827

Epoch: 5| Step: 1
Training loss: 0.5993314216849901
Validation loss: 2.4089692264516516

Epoch: 5| Step: 2
Training loss: 0.5282229406067246
Validation loss: 2.399358923722227

Epoch: 5| Step: 3
Training loss: 0.5572804571670286
Validation loss: 2.427086502475211

Epoch: 5| Step: 4
Training loss: 0.3433388288337424
Validation loss: 2.369322347612626

Epoch: 5| Step: 5
Training loss: 0.5330166333378302
Validation loss: 2.3592501371424923

Epoch: 5| Step: 6
Training loss: 0.33799920514961324
Validation loss: 2.390592018954617

Epoch: 5| Step: 7
Training loss: 0.5531640690944346
Validation loss: 2.3735726821927217

Epoch: 5| Step: 8
Training loss: 0.4227807952655098
Validation loss: 2.38177479150418

Epoch: 5| Step: 9
Training loss: 0.3209418417795707
Validation loss: 2.382182041670929

Epoch: 5| Step: 10
Training loss: 0.4861860718907808
Validation loss: 2.379450290501229

Epoch: 408| Step: 0
Training loss: 0.4039953093043986
Validation loss: 2.364990785451549

Epoch: 5| Step: 1
Training loss: 0.7033239083276306
Validation loss: 2.39806403222255

Epoch: 5| Step: 2
Training loss: 0.4086317522454371
Validation loss: 2.422960585993906

Epoch: 5| Step: 3
Training loss: 0.3005782346376752
Validation loss: 2.395606422825179

Epoch: 5| Step: 4
Training loss: 0.3835151995938013
Validation loss: 2.403015918806455

Epoch: 5| Step: 5
Training loss: 0.38343546256695366
Validation loss: 2.365959148497536

Epoch: 5| Step: 6
Training loss: 0.3475147452244887
Validation loss: 2.363997835007251

Epoch: 5| Step: 7
Training loss: 0.4072213298360794
Validation loss: 2.358111713134416

Epoch: 5| Step: 8
Training loss: 0.5280633326083796
Validation loss: 2.373624504248845

Epoch: 5| Step: 9
Training loss: 0.43065805928377754
Validation loss: 2.352920586493195

Epoch: 5| Step: 10
Training loss: 0.5543131034900263
Validation loss: 2.350901253888372

Epoch: 409| Step: 0
Training loss: 0.2414314250719959
Validation loss: 2.367038136873659

Epoch: 5| Step: 1
Training loss: 0.5632276596840289
Validation loss: 2.3508800033612505

Epoch: 5| Step: 2
Training loss: 0.4464244678853674
Validation loss: 2.335962364335249

Epoch: 5| Step: 3
Training loss: 0.5902927281474788
Validation loss: 2.3393638549166433

Epoch: 5| Step: 4
Training loss: 0.4993964665445636
Validation loss: 2.375067502127374

Epoch: 5| Step: 5
Training loss: 0.592366212234307
Validation loss: 2.334430390168234

Epoch: 5| Step: 6
Training loss: 0.45312647983704
Validation loss: 2.3634201571711495

Epoch: 5| Step: 7
Training loss: 0.31033071756429986
Validation loss: 2.327051900259406

Epoch: 5| Step: 8
Training loss: 0.4352160167913674
Validation loss: 2.3361126323089216

Epoch: 5| Step: 9
Training loss: 0.2972898721518263
Validation loss: 2.3702519996180254

Epoch: 5| Step: 10
Training loss: 0.23129323799991366
Validation loss: 2.358352040595982

Epoch: 410| Step: 0
Training loss: 0.4863778820398531
Validation loss: 2.402407132031362

Epoch: 5| Step: 1
Training loss: 0.3238011048643584
Validation loss: 2.391192541569228

Epoch: 5| Step: 2
Training loss: 0.20053173733248233
Validation loss: 2.4011102638609407

Epoch: 5| Step: 3
Training loss: 0.30112422858139803
Validation loss: 2.3848067141154274

Epoch: 5| Step: 4
Training loss: 0.5667134997237984
Validation loss: 2.4227285552839426

Epoch: 5| Step: 5
Training loss: 0.5166371555001322
Validation loss: 2.387697162464307

Epoch: 5| Step: 6
Training loss: 0.43006855800704374
Validation loss: 2.3405108047716396

Epoch: 5| Step: 7
Training loss: 0.24817734388409146
Validation loss: 2.3679013622514784

Epoch: 5| Step: 8
Training loss: 0.5553175611807374
Validation loss: 2.3603488504403027

Epoch: 5| Step: 9
Training loss: 0.5135851014386554
Validation loss: 2.337486351455466

Epoch: 5| Step: 10
Training loss: 0.5285053880916714
Validation loss: 2.381034120465531

Epoch: 411| Step: 0
Training loss: 0.2874549680147818
Validation loss: 2.382513082928225

Epoch: 5| Step: 1
Training loss: 0.4591522072276754
Validation loss: 2.314166917468512

Epoch: 5| Step: 2
Training loss: 0.3986391417446195
Validation loss: 2.3321657013373334

Epoch: 5| Step: 3
Training loss: 0.5038841597572193
Validation loss: 2.3901624795806127

Epoch: 5| Step: 4
Training loss: 0.47332967908997836
Validation loss: 2.3759702396454943

Epoch: 5| Step: 5
Training loss: 0.28143737432336
Validation loss: 2.3219644242905964

Epoch: 5| Step: 6
Training loss: 0.6211239549501762
Validation loss: 2.3826911990879545

Epoch: 5| Step: 7
Training loss: 0.27812810585345166
Validation loss: 2.387655305463298

Epoch: 5| Step: 8
Training loss: 0.4963855786172553
Validation loss: 2.343205904956571

Epoch: 5| Step: 9
Training loss: 0.3349763071521087
Validation loss: 2.3652906246797163

Epoch: 5| Step: 10
Training loss: 0.5205076979874992
Validation loss: 2.369226485969947

Epoch: 412| Step: 0
Training loss: 0.6346506337400016
Validation loss: 2.356029616979468

Epoch: 5| Step: 1
Training loss: 0.13724817222583735
Validation loss: 2.3598434911046757

Epoch: 5| Step: 2
Training loss: 0.3219753692207201
Validation loss: 2.373554459068076

Epoch: 5| Step: 3
Training loss: 0.4067445275970793
Validation loss: 2.3466956372805687

Epoch: 5| Step: 4
Training loss: 0.4592818898927636
Validation loss: 2.373286256642421

Epoch: 5| Step: 5
Training loss: 0.3655194888339786
Validation loss: 2.371727399054141

Epoch: 5| Step: 6
Training loss: 0.6297123641413032
Validation loss: 2.3586911706772167

Epoch: 5| Step: 7
Training loss: 0.5027340406581238
Validation loss: 2.3627342871888533

Epoch: 5| Step: 8
Training loss: 0.4937011664421406
Validation loss: 2.3619958329515254

Epoch: 5| Step: 9
Training loss: 0.3605905376211565
Validation loss: 2.34155983321159

Epoch: 5| Step: 10
Training loss: 0.3224869863708539
Validation loss: 2.342714727218074

Epoch: 413| Step: 0
Training loss: 0.3374360836399945
Validation loss: 2.3674188987664166

Epoch: 5| Step: 1
Training loss: 0.34997601171440357
Validation loss: 2.379366355644614

Epoch: 5| Step: 2
Training loss: 0.23218725688351705
Validation loss: 2.381675203770301

Epoch: 5| Step: 3
Training loss: 0.37532001986501823
Validation loss: 2.3671542942075408

Epoch: 5| Step: 4
Training loss: 0.35658223905764674
Validation loss: 2.368736716153733

Epoch: 5| Step: 5
Training loss: 0.4876584926359317
Validation loss: 2.411142528472843

Epoch: 5| Step: 6
Training loss: 0.35375039329776536
Validation loss: 2.4099778625406114

Epoch: 5| Step: 7
Training loss: 0.726776009639112
Validation loss: 2.400616324369611

Epoch: 5| Step: 8
Training loss: 0.479555378341345
Validation loss: 2.3571281010475236

Epoch: 5| Step: 9
Training loss: 0.27262624559113546
Validation loss: 2.366212817262563

Epoch: 5| Step: 10
Training loss: 0.5979734339554275
Validation loss: 2.3656880422489857

Epoch: 414| Step: 0
Training loss: 0.4774962485999895
Validation loss: 2.3539719035953826

Epoch: 5| Step: 1
Training loss: 0.3707808932540984
Validation loss: 2.347690242622043

Epoch: 5| Step: 2
Training loss: 0.39604536660138506
Validation loss: 2.3335240816414404

Epoch: 5| Step: 3
Training loss: 0.37004130851348277
Validation loss: 2.3370655675205674

Epoch: 5| Step: 4
Training loss: 0.4129760271312365
Validation loss: 2.324065869746803

Epoch: 5| Step: 5
Training loss: 0.3563572395940806
Validation loss: 2.3217856211577446

Epoch: 5| Step: 6
Training loss: 0.652920291158633
Validation loss: 2.3240946457294895

Epoch: 5| Step: 7
Training loss: 0.3160534292650289
Validation loss: 2.3239231041882324

Epoch: 5| Step: 8
Training loss: 0.4607745383605913
Validation loss: 2.3123889005092435

Epoch: 5| Step: 9
Training loss: 0.46533451299816136
Validation loss: 2.3369464770116686

Epoch: 5| Step: 10
Training loss: 0.36277333510656096
Validation loss: 2.3376735259166255

Epoch: 415| Step: 0
Training loss: 0.4433929161794689
Validation loss: 2.3463940413479376

Epoch: 5| Step: 1
Training loss: 0.5346568206600342
Validation loss: 2.329645371086587

Epoch: 5| Step: 2
Training loss: 0.41222255291665605
Validation loss: 2.360578276196828

Epoch: 5| Step: 3
Training loss: 0.42108527194460843
Validation loss: 2.379633818931732

Epoch: 5| Step: 4
Training loss: 0.509585790958337
Validation loss: 2.39896320496426

Epoch: 5| Step: 5
Training loss: 0.4932032201347821
Validation loss: 2.388289898611945

Epoch: 5| Step: 6
Training loss: 0.4257132624670324
Validation loss: 2.3701573056118557

Epoch: 5| Step: 7
Training loss: 0.28951889814615933
Validation loss: 2.3295141704435864

Epoch: 5| Step: 8
Training loss: 0.3761053285928228
Validation loss: 2.340998085588016

Epoch: 5| Step: 9
Training loss: 0.2985961362622625
Validation loss: 2.3145823605175777

Epoch: 5| Step: 10
Training loss: 0.41085938628668733
Validation loss: 2.3300670059676376

Epoch: 416| Step: 0
Training loss: 0.4431530140306097
Validation loss: 2.331320687515305

Epoch: 5| Step: 1
Training loss: 0.47333496796410784
Validation loss: 2.351860738548415

Epoch: 5| Step: 2
Training loss: 0.46421126604547663
Validation loss: 2.33962751754143

Epoch: 5| Step: 3
Training loss: 0.4168390354616562
Validation loss: 2.365497234876485

Epoch: 5| Step: 4
Training loss: 0.3339918369998883
Validation loss: 2.3714232613736344

Epoch: 5| Step: 5
Training loss: 0.4443135853269991
Validation loss: 2.422421990428822

Epoch: 5| Step: 6
Training loss: 0.4882796325656805
Validation loss: 2.3988361225796084

Epoch: 5| Step: 7
Training loss: 0.487173670584078
Validation loss: 2.3623265460735596

Epoch: 5| Step: 8
Training loss: 0.3393612319127593
Validation loss: 2.3609561122114693

Epoch: 5| Step: 9
Training loss: 0.40337225554117473
Validation loss: 2.390882677237514

Epoch: 5| Step: 10
Training loss: 0.1821455040289924
Validation loss: 2.4055025015457696

Epoch: 417| Step: 0
Training loss: 0.3388043875863926
Validation loss: 2.374600147423667

Epoch: 5| Step: 1
Training loss: 0.24820269548897086
Validation loss: 2.392594170615976

Epoch: 5| Step: 2
Training loss: 0.471322566144585
Validation loss: 2.3862254875328173

Epoch: 5| Step: 3
Training loss: 0.3829215925824799
Validation loss: 2.371776179259038

Epoch: 5| Step: 4
Training loss: 0.6830133862768422
Validation loss: 2.377897201497775

Epoch: 5| Step: 5
Training loss: 0.5081541232763709
Validation loss: 2.3607162817038696

Epoch: 5| Step: 6
Training loss: 0.1603736158346175
Validation loss: 2.3441254285701176

Epoch: 5| Step: 7
Training loss: 0.4644079168726292
Validation loss: 2.3512575230246373

Epoch: 5| Step: 8
Training loss: 0.3060790587205591
Validation loss: 2.3263296971274885

Epoch: 5| Step: 9
Training loss: 0.46340133564472136
Validation loss: 2.3621927543691648

Epoch: 5| Step: 10
Training loss: 0.33776791499786957
Validation loss: 2.3653207362482647

Epoch: 418| Step: 0
Training loss: 0.45215344683712666
Validation loss: 2.343349726142073

Epoch: 5| Step: 1
Training loss: 0.4616009415080586
Validation loss: 2.4049517129948867

Epoch: 5| Step: 2
Training loss: 0.6323271408897249
Validation loss: 2.369442059731301

Epoch: 5| Step: 3
Training loss: 0.4327865338024644
Validation loss: 2.3955529418486523

Epoch: 5| Step: 4
Training loss: 0.3520445380007808
Validation loss: 2.3588557496065086

Epoch: 5| Step: 5
Training loss: 0.1909136564348241
Validation loss: 2.357286345446263

Epoch: 5| Step: 6
Training loss: 0.2339578492504104
Validation loss: 2.383431166944136

Epoch: 5| Step: 7
Training loss: 0.4708895175742467
Validation loss: 2.357626138803551

Epoch: 5| Step: 8
Training loss: 0.2278167765285307
Validation loss: 2.342319328606783

Epoch: 5| Step: 9
Training loss: 0.46239141916584453
Validation loss: 2.3725424493710343

Epoch: 5| Step: 10
Training loss: 0.425732496077615
Validation loss: 2.368891989281184

Epoch: 419| Step: 0
Training loss: 0.5019700459400208
Validation loss: 2.3779263820500143

Epoch: 5| Step: 1
Training loss: 0.3798564911576318
Validation loss: 2.363247042294555

Epoch: 5| Step: 2
Training loss: 0.42162502795031875
Validation loss: 2.3785988257637447

Epoch: 5| Step: 3
Training loss: 0.48436515551991965
Validation loss: 2.4138084485289477

Epoch: 5| Step: 4
Training loss: 0.47142742353460587
Validation loss: 2.389790150530964

Epoch: 5| Step: 5
Training loss: 0.36265701067054584
Validation loss: 2.406055898073154

Epoch: 5| Step: 6
Training loss: 0.5764102248822321
Validation loss: 2.4055632660853434

Epoch: 5| Step: 7
Training loss: 0.4647595786174112
Validation loss: 2.3712896975047264

Epoch: 5| Step: 8
Training loss: 0.2196484744868891
Validation loss: 2.379907358825388

Epoch: 5| Step: 9
Training loss: 0.18895397105714057
Validation loss: 2.394423623187174

Epoch: 5| Step: 10
Training loss: 0.17418657270854698
Validation loss: 2.3951601595927894

Epoch: 420| Step: 0
Training loss: 0.48712284770036873
Validation loss: 2.3419922349636324

Epoch: 5| Step: 1
Training loss: 0.4161801080191932
Validation loss: 2.381287489782646

Epoch: 5| Step: 2
Training loss: 0.45532707641350967
Validation loss: 2.3793082703180457

Epoch: 5| Step: 3
Training loss: 0.3199506436968178
Validation loss: 2.3922097330635634

Epoch: 5| Step: 4
Training loss: 0.3400554874316194
Validation loss: 2.3816464658086707

Epoch: 5| Step: 5
Training loss: 0.6728446085311687
Validation loss: 2.329843391689451

Epoch: 5| Step: 6
Training loss: 0.24632954276149047
Validation loss: 2.3512295205229776

Epoch: 5| Step: 7
Training loss: 0.3972143209482224
Validation loss: 2.350038527864735

Epoch: 5| Step: 8
Training loss: 0.2748048382442145
Validation loss: 2.3840872187389333

Epoch: 5| Step: 9
Training loss: 0.40222523619681433
Validation loss: 2.356366445715302

Epoch: 5| Step: 10
Training loss: 0.2737250859319566
Validation loss: 2.3021078409577465

Epoch: 421| Step: 0
Training loss: 0.32426305261368316
Validation loss: 2.316902064833706

Epoch: 5| Step: 1
Training loss: 0.42195859716575473
Validation loss: 2.332131857283907

Epoch: 5| Step: 2
Training loss: 0.47665144918844315
Validation loss: 2.3774029633217473

Epoch: 5| Step: 3
Training loss: 0.40334887091735283
Validation loss: 2.3345196106496675

Epoch: 5| Step: 4
Training loss: 0.5003511268815745
Validation loss: 2.351776778297668

Epoch: 5| Step: 5
Training loss: 0.402408594628101
Validation loss: 2.342492471319659

Epoch: 5| Step: 6
Training loss: 0.29304146182237817
Validation loss: 2.3639754317629516

Epoch: 5| Step: 7
Training loss: 0.5932117582406597
Validation loss: 2.341951488788613

Epoch: 5| Step: 8
Training loss: 0.24981253270885567
Validation loss: 2.3698565016600237

Epoch: 5| Step: 9
Training loss: 0.39108525817528006
Validation loss: 2.3608387725074644

Epoch: 5| Step: 10
Training loss: 0.1638541374420735
Validation loss: 2.3693093114686086

Epoch: 422| Step: 0
Training loss: 0.44948478782147655
Validation loss: 2.3552769329611856

Epoch: 5| Step: 1
Training loss: 0.3546990455731289
Validation loss: 2.4078952016359323

Epoch: 5| Step: 2
Training loss: 0.413119321515738
Validation loss: 2.379525443963868

Epoch: 5| Step: 3
Training loss: 0.47833826320325235
Validation loss: 2.3341963185863097

Epoch: 5| Step: 4
Training loss: 0.4445402409292924
Validation loss: 2.401719266219226

Epoch: 5| Step: 5
Training loss: 0.1559155759612267
Validation loss: 2.3464430280865916

Epoch: 5| Step: 6
Training loss: 0.3990490464980006
Validation loss: 2.375276347081664

Epoch: 5| Step: 7
Training loss: 0.3923198742516057
Validation loss: 2.3087163784018037

Epoch: 5| Step: 8
Training loss: 0.5148775868157521
Validation loss: 2.340834490773735

Epoch: 5| Step: 9
Training loss: 0.279389492764154
Validation loss: 2.3767739165535975

Epoch: 5| Step: 10
Training loss: 0.3390421237184568
Validation loss: 2.29873212983536

Epoch: 423| Step: 0
Training loss: 0.3229384017623144
Validation loss: 2.3250947049766717

Epoch: 5| Step: 1
Training loss: 0.33641703335443834
Validation loss: 2.361385255911949

Epoch: 5| Step: 2
Training loss: 0.3823962186442344
Validation loss: 2.357388960122255

Epoch: 5| Step: 3
Training loss: 0.487315940344774
Validation loss: 2.333632767672513

Epoch: 5| Step: 4
Training loss: 0.5582361210226571
Validation loss: 2.3747677627426897

Epoch: 5| Step: 5
Training loss: 0.31719063442541884
Validation loss: 2.364778748489737

Epoch: 5| Step: 6
Training loss: 0.4546518908317982
Validation loss: 2.374076121694072

Epoch: 5| Step: 7
Training loss: 0.4316308205988452
Validation loss: 2.3713311601257554

Epoch: 5| Step: 8
Training loss: 0.23725739938032434
Validation loss: 2.340558622176329

Epoch: 5| Step: 9
Training loss: 0.40831559744418694
Validation loss: 2.3742188862253975

Epoch: 5| Step: 10
Training loss: 0.3828627689598634
Validation loss: 2.3019741308811557

Epoch: 424| Step: 0
Training loss: 0.4995711096455168
Validation loss: 2.3627094810732445

Epoch: 5| Step: 1
Training loss: 0.1723807869037327
Validation loss: 2.3430854593581354

Epoch: 5| Step: 2
Training loss: 0.44317049885123827
Validation loss: 2.362692508774631

Epoch: 5| Step: 3
Training loss: 0.49366040322264626
Validation loss: 2.3330728880678944

Epoch: 5| Step: 4
Training loss: 0.3504911948205437
Validation loss: 2.392363924203365

Epoch: 5| Step: 5
Training loss: 0.39627735013466464
Validation loss: 2.348889425300305

Epoch: 5| Step: 6
Training loss: 0.31044966897754833
Validation loss: 2.3600042555683576

Epoch: 5| Step: 7
Training loss: 0.42135135506665206
Validation loss: 2.390525706963244

Epoch: 5| Step: 8
Training loss: 0.39585640697823354
Validation loss: 2.3324779029788427

Epoch: 5| Step: 9
Training loss: 0.4480334026303316
Validation loss: 2.377013583985896

Epoch: 5| Step: 10
Training loss: 0.33399629850463725
Validation loss: 2.367263375236617

Epoch: 425| Step: 0
Training loss: 0.4702632637485575
Validation loss: 2.378857842314595

Epoch: 5| Step: 1
Training loss: 0.34978624483753123
Validation loss: 2.335444498053182

Epoch: 5| Step: 2
Training loss: 0.4439020238968561
Validation loss: 2.3677899784476435

Epoch: 5| Step: 3
Training loss: 0.357237679802298
Validation loss: 2.352705441486877

Epoch: 5| Step: 4
Training loss: 0.24824032036223947
Validation loss: 2.3717001938367868

Epoch: 5| Step: 5
Training loss: 0.31631434247833834
Validation loss: 2.352723377163512

Epoch: 5| Step: 6
Training loss: 0.6525296386111331
Validation loss: 2.3529675491914688

Epoch: 5| Step: 7
Training loss: 0.360957393675988
Validation loss: 2.382513265852254

Epoch: 5| Step: 8
Training loss: 0.2615107806036769
Validation loss: 2.3976515213996965

Epoch: 5| Step: 9
Training loss: 0.5785211546103658
Validation loss: 2.319388053407823

Epoch: 5| Step: 10
Training loss: 0.3684421167254272
Validation loss: 2.324451365747664

Epoch: 426| Step: 0
Training loss: 0.465951369301112
Validation loss: 2.339161881585227

Epoch: 5| Step: 1
Training loss: 0.36535775043880236
Validation loss: 2.283372045730267

Epoch: 5| Step: 2
Training loss: 0.513472079449364
Validation loss: 2.3130600552334855

Epoch: 5| Step: 3
Training loss: 0.28681221979376514
Validation loss: 2.366826584445187

Epoch: 5| Step: 4
Training loss: 0.4352363368907528
Validation loss: 2.362926866969652

Epoch: 5| Step: 5
Training loss: 0.44721608116574935
Validation loss: 2.3964487450862553

Epoch: 5| Step: 6
Training loss: 0.40988050001548726
Validation loss: 2.341001469462564

Epoch: 5| Step: 7
Training loss: 0.4711310945958239
Validation loss: 2.39673912631294

Epoch: 5| Step: 8
Training loss: 0.4081792139962564
Validation loss: 2.393114929854206

Epoch: 5| Step: 9
Training loss: 0.3692438294186322
Validation loss: 2.4171358902283417

Epoch: 5| Step: 10
Training loss: 0.09276981848634883
Validation loss: 2.415396613001065

Epoch: 427| Step: 0
Training loss: 0.471949956005857
Validation loss: 2.376198647484662

Epoch: 5| Step: 1
Training loss: 0.463165877387651
Validation loss: 2.4208986492924884

Epoch: 5| Step: 2
Training loss: 0.3996952997420404
Validation loss: 2.354741875538042

Epoch: 5| Step: 3
Training loss: 0.3611324708482066
Validation loss: 2.397374369551632

Epoch: 5| Step: 4
Training loss: 0.5463743643092618
Validation loss: 2.383063498029472

Epoch: 5| Step: 5
Training loss: 0.24304557885781114
Validation loss: 2.391328406155143

Epoch: 5| Step: 6
Training loss: 0.1573809996609632
Validation loss: 2.359957623003082

Epoch: 5| Step: 7
Training loss: 0.45541356375644404
Validation loss: 2.4193312132102287

Epoch: 5| Step: 8
Training loss: 0.34929252630336777
Validation loss: 2.3676522260833384

Epoch: 5| Step: 9
Training loss: 0.3809957797975675
Validation loss: 2.3659146389982917

Epoch: 5| Step: 10
Training loss: 0.44791972543721814
Validation loss: 2.3769240581509985

Epoch: 428| Step: 0
Training loss: 0.36801812393453703
Validation loss: 2.3576082523863278

Epoch: 5| Step: 1
Training loss: 0.38554920246074925
Validation loss: 2.366095161291323

Epoch: 5| Step: 2
Training loss: 0.5266227880087828
Validation loss: 2.329213524050148

Epoch: 5| Step: 3
Training loss: 0.369897379562654
Validation loss: 2.338236275080351

Epoch: 5| Step: 4
Training loss: 0.34999569268641584
Validation loss: 2.3437538141472523

Epoch: 5| Step: 5
Training loss: 0.2587581400120713
Validation loss: 2.35606565847006

Epoch: 5| Step: 6
Training loss: 0.4680018812879424
Validation loss: 2.346061953212834

Epoch: 5| Step: 7
Training loss: 0.22831850434591566
Validation loss: 2.393454286373868

Epoch: 5| Step: 8
Training loss: 0.2116833938834493
Validation loss: 2.3367799831066414

Epoch: 5| Step: 9
Training loss: 0.5563573819355447
Validation loss: 2.3679307412289274

Epoch: 5| Step: 10
Training loss: 0.4310098069009016
Validation loss: 2.3630249182737795

Epoch: 429| Step: 0
Training loss: 0.3472116821066838
Validation loss: 2.393110656607026

Epoch: 5| Step: 1
Training loss: 0.3328788485231151
Validation loss: 2.393268433887572

Epoch: 5| Step: 2
Training loss: 0.437652510218796
Validation loss: 2.4388696468357045

Epoch: 5| Step: 3
Training loss: 0.3571077644613932
Validation loss: 2.428252177993123

Epoch: 5| Step: 4
Training loss: 0.5254994106053497
Validation loss: 2.385913888585701

Epoch: 5| Step: 5
Training loss: 0.3834238814443646
Validation loss: 2.4027255194055437

Epoch: 5| Step: 6
Training loss: 0.43990609453852575
Validation loss: 2.402347672275263

Epoch: 5| Step: 7
Training loss: 0.3077727998992478
Validation loss: 2.350996191355625

Epoch: 5| Step: 8
Training loss: 0.527921797805976
Validation loss: 2.3329989765787156

Epoch: 5| Step: 9
Training loss: 0.4330572985296685
Validation loss: 2.341610765306279

Epoch: 5| Step: 10
Training loss: 0.3207440144611472
Validation loss: 2.320486974304007

Epoch: 430| Step: 0
Training loss: 0.42222233002470266
Validation loss: 2.309951401064201

Epoch: 5| Step: 1
Training loss: 0.26933794415053536
Validation loss: 2.269185558289243

Epoch: 5| Step: 2
Training loss: 0.6016009925317947
Validation loss: 2.361663731269466

Epoch: 5| Step: 3
Training loss: 0.29972034224667055
Validation loss: 2.322150150062587

Epoch: 5| Step: 4
Training loss: 0.14237132163441277
Validation loss: 2.3581266642310394

Epoch: 5| Step: 5
Training loss: 0.33966661638218026
Validation loss: 2.3648256383094086

Epoch: 5| Step: 6
Training loss: 0.6006708348754454
Validation loss: 2.388188181214616

Epoch: 5| Step: 7
Training loss: 0.3606113644803753
Validation loss: 2.391991031113962

Epoch: 5| Step: 8
Training loss: 0.33492753777100254
Validation loss: 2.4119394271145165

Epoch: 5| Step: 9
Training loss: 0.4482507476321707
Validation loss: 2.3747672078625617

Epoch: 5| Step: 10
Training loss: 0.40689391676704806
Validation loss: 2.365562665136511

Epoch: 431| Step: 0
Training loss: 0.31890342890581763
Validation loss: 2.3325912598267853

Epoch: 5| Step: 1
Training loss: 0.3617521530118933
Validation loss: 2.3725602145570264

Epoch: 5| Step: 2
Training loss: 0.36411869777747885
Validation loss: 2.319260624351995

Epoch: 5| Step: 3
Training loss: 0.2590261129403042
Validation loss: 2.326102040294724

Epoch: 5| Step: 4
Training loss: 0.4412567087911609
Validation loss: 2.3134857322856637

Epoch: 5| Step: 5
Training loss: 0.393993540030738
Validation loss: 2.3257164045361565

Epoch: 5| Step: 6
Training loss: 0.3911685594982375
Validation loss: 2.3069338116268217

Epoch: 5| Step: 7
Training loss: 0.5874044746493456
Validation loss: 2.33089730957892

Epoch: 5| Step: 8
Training loss: 0.17343872903268104
Validation loss: 2.3150138704950205

Epoch: 5| Step: 9
Training loss: 0.5245084482281728
Validation loss: 2.335279741347927

Epoch: 5| Step: 10
Training loss: 0.5400600325805397
Validation loss: 2.3227815832032994

Epoch: 432| Step: 0
Training loss: 0.44392406112349053
Validation loss: 2.2969256823720343

Epoch: 5| Step: 1
Training loss: 0.26269002292228383
Validation loss: 2.3942939977877487

Epoch: 5| Step: 2
Training loss: 0.39025806358921467
Validation loss: 2.3643558308368773

Epoch: 5| Step: 3
Training loss: 0.4082495010534112
Validation loss: 2.3972054319479295

Epoch: 5| Step: 4
Training loss: 0.38562220385386287
Validation loss: 2.4024174947464014

Epoch: 5| Step: 5
Training loss: 0.454171091314805
Validation loss: 2.3411742135927907

Epoch: 5| Step: 6
Training loss: 0.22819272074738803
Validation loss: 2.4000053405275024

Epoch: 5| Step: 7
Training loss: 0.5279471442144544
Validation loss: 2.4146258471472897

Epoch: 5| Step: 8
Training loss: 0.34283938955319754
Validation loss: 2.389632271259475

Epoch: 5| Step: 9
Training loss: 0.48877840291297603
Validation loss: 2.4087755000941926

Epoch: 5| Step: 10
Training loss: 0.279621349269106
Validation loss: 2.388445332971744

Epoch: 433| Step: 0
Training loss: 0.40873032615864385
Validation loss: 2.3700292941203642

Epoch: 5| Step: 1
Training loss: 0.2561501459630237
Validation loss: 2.392188168980507

Epoch: 5| Step: 2
Training loss: 0.4808166763846263
Validation loss: 2.392939138727264

Epoch: 5| Step: 3
Training loss: 0.4759270543275285
Validation loss: 2.3824936428660357

Epoch: 5| Step: 4
Training loss: 0.21576539803851508
Validation loss: 2.3765500897921825

Epoch: 5| Step: 5
Training loss: 0.512915573036315
Validation loss: 2.3677638502362224

Epoch: 5| Step: 6
Training loss: 0.23168214519138128
Validation loss: 2.3978251110012825

Epoch: 5| Step: 7
Training loss: 0.5319856430873535
Validation loss: 2.388755886411717

Epoch: 5| Step: 8
Training loss: 0.3599143127945309
Validation loss: 2.4068896601127183

Epoch: 5| Step: 9
Training loss: 0.17437794344478943
Validation loss: 2.3415400383646037

Epoch: 5| Step: 10
Training loss: 0.4169528236838373
Validation loss: 2.366250925740772

Epoch: 434| Step: 0
Training loss: 0.32789765156617207
Validation loss: 2.427802285224738

Epoch: 5| Step: 1
Training loss: 0.33167154237663393
Validation loss: 2.376787425177137

Epoch: 5| Step: 2
Training loss: 0.4579565674310988
Validation loss: 2.3522952939213555

Epoch: 5| Step: 3
Training loss: 0.4067323095792304
Validation loss: 2.3564479055727356

Epoch: 5| Step: 4
Training loss: 0.2921391503216796
Validation loss: 2.37229778229048

Epoch: 5| Step: 5
Training loss: 0.44297294749267707
Validation loss: 2.361280260797151

Epoch: 5| Step: 6
Training loss: 0.42046307132193456
Validation loss: 2.371765159510537

Epoch: 5| Step: 7
Training loss: 0.38464396145919266
Validation loss: 2.3377317031778677

Epoch: 5| Step: 8
Training loss: 0.32525615867513336
Validation loss: 2.3719606149026595

Epoch: 5| Step: 9
Training loss: 0.33353121169075844
Validation loss: 2.3521042807699413

Epoch: 5| Step: 10
Training loss: 0.44550866273684314
Validation loss: 2.3765097365576784

Epoch: 435| Step: 0
Training loss: 0.32799930662788396
Validation loss: 2.3459495434195325

Epoch: 5| Step: 1
Training loss: 0.3536564456918594
Validation loss: 2.352284355652199

Epoch: 5| Step: 2
Training loss: 0.4642747233211224
Validation loss: 2.3793282007930645

Epoch: 5| Step: 3
Training loss: 0.5303856606222334
Validation loss: 2.3669103563558407

Epoch: 5| Step: 4
Training loss: 0.2672027126242376
Validation loss: 2.3244500681838196

Epoch: 5| Step: 5
Training loss: 0.4973259888454826
Validation loss: 2.388867754300986

Epoch: 5| Step: 6
Training loss: 0.4482411569487915
Validation loss: 2.393820180511831

Epoch: 5| Step: 7
Training loss: 0.29663491579900675
Validation loss: 2.375898986601715

Epoch: 5| Step: 8
Training loss: 0.15720497599199146
Validation loss: 2.3634954225463507

Epoch: 5| Step: 9
Training loss: 0.2991548634346254
Validation loss: 2.3774076740305308

Epoch: 5| Step: 10
Training loss: 0.33191363551581626
Validation loss: 2.3612871978634753

Epoch: 436| Step: 0
Training loss: 0.45644830548501236
Validation loss: 2.3649104242081287

Epoch: 5| Step: 1
Training loss: 0.26682252774547494
Validation loss: 2.3565096946003

Epoch: 5| Step: 2
Training loss: 0.17556706200834846
Validation loss: 2.3455648515112015

Epoch: 5| Step: 3
Training loss: 0.5134042543129478
Validation loss: 2.3296935193475328

Epoch: 5| Step: 4
Training loss: 0.4521112282522031
Validation loss: 2.3792569140291935

Epoch: 5| Step: 5
Training loss: 0.3169319001487147
Validation loss: 2.3699188519226104

Epoch: 5| Step: 6
Training loss: 0.24028750351621697
Validation loss: 2.3825311821167787

Epoch: 5| Step: 7
Training loss: 0.45012460678833427
Validation loss: 2.415611129572554

Epoch: 5| Step: 8
Training loss: 0.40928298993631723
Validation loss: 2.399623190702811

Epoch: 5| Step: 9
Training loss: 0.3593716828566338
Validation loss: 2.3382752638111097

Epoch: 5| Step: 10
Training loss: 0.28523369612726623
Validation loss: 2.372478478580015

Epoch: 437| Step: 0
Training loss: 0.34686243318011817
Validation loss: 2.3523042568013453

Epoch: 5| Step: 1
Training loss: 0.2836704607534074
Validation loss: 2.36477955722315

Epoch: 5| Step: 2
Training loss: 0.5221684002308216
Validation loss: 2.334570539854956

Epoch: 5| Step: 3
Training loss: 0.3981084399769116
Validation loss: 2.332561558838532

Epoch: 5| Step: 4
Training loss: 0.23991673101626593
Validation loss: 2.380952486962581

Epoch: 5| Step: 5
Training loss: 0.437342853933645
Validation loss: 2.333162237375279

Epoch: 5| Step: 6
Training loss: 0.2186601403138234
Validation loss: 2.347106919556559

Epoch: 5| Step: 7
Training loss: 0.2649745550625367
Validation loss: 2.3371962943506963

Epoch: 5| Step: 8
Training loss: 0.3335420903535368
Validation loss: 2.352517995677578

Epoch: 5| Step: 9
Training loss: 0.49184834435930697
Validation loss: 2.369444697547391

Epoch: 5| Step: 10
Training loss: 0.35573488270908543
Validation loss: 2.3589934983432026

Epoch: 438| Step: 0
Training loss: 0.3768359382592224
Validation loss: 2.3520161753189583

Epoch: 5| Step: 1
Training loss: 0.3687982939760857
Validation loss: 2.3544644341603926

Epoch: 5| Step: 2
Training loss: 0.30621709549526294
Validation loss: 2.3548706189908604

Epoch: 5| Step: 3
Training loss: 0.11139856586198764
Validation loss: 2.3641364791307518

Epoch: 5| Step: 4
Training loss: 0.19087635376992887
Validation loss: 2.305748322071011

Epoch: 5| Step: 5
Training loss: 0.4994247524891202
Validation loss: 2.340967814477137

Epoch: 5| Step: 6
Training loss: 0.4543079522472421
Validation loss: 2.337031924415516

Epoch: 5| Step: 7
Training loss: 0.3149865169894169
Validation loss: 2.290468819831366

Epoch: 5| Step: 8
Training loss: 0.29665770860516544
Validation loss: 2.363329000455889

Epoch: 5| Step: 9
Training loss: 0.3617951545188423
Validation loss: 2.360898536021873

Epoch: 5| Step: 10
Training loss: 0.497713643212441
Validation loss: 2.353361778590507

Epoch: 439| Step: 0
Training loss: 0.23194132741783527
Validation loss: 2.376688848428588

Epoch: 5| Step: 1
Training loss: 0.3184580503726434
Validation loss: 2.37434376629671

Epoch: 5| Step: 2
Training loss: 0.47653282573428674
Validation loss: 2.3830665058950613

Epoch: 5| Step: 3
Training loss: 0.24345308768103976
Validation loss: 2.373637275303024

Epoch: 5| Step: 4
Training loss: 0.41078640803613414
Validation loss: 2.3962856177909595

Epoch: 5| Step: 5
Training loss: 0.2564632336876315
Validation loss: 2.3910851697542808

Epoch: 5| Step: 6
Training loss: 0.571219415576321
Validation loss: 2.3868168008038797

Epoch: 5| Step: 7
Training loss: 0.41225510321211967
Validation loss: 2.403012581719333

Epoch: 5| Step: 8
Training loss: 0.32689609189665814
Validation loss: 2.3497629477652575

Epoch: 5| Step: 9
Training loss: 0.3325644307344852
Validation loss: 2.350532044047906

Epoch: 5| Step: 10
Training loss: 0.35228768894439677
Validation loss: 2.3603683889849614

Epoch: 440| Step: 0
Training loss: 0.410228559387051
Validation loss: 2.364735351432942

Epoch: 5| Step: 1
Training loss: 0.3378333555871448
Validation loss: 2.3042559197899797

Epoch: 5| Step: 2
Training loss: 0.28886695639992443
Validation loss: 2.3299589870768562

Epoch: 5| Step: 3
Training loss: 0.39977460784391916
Validation loss: 2.335416980498339

Epoch: 5| Step: 4
Training loss: 0.39034511075642725
Validation loss: 2.31268775618951

Epoch: 5| Step: 5
Training loss: 0.3309512131383031
Validation loss: 2.3169670428435816

Epoch: 5| Step: 6
Training loss: 0.48781239697139417
Validation loss: 2.3136384695291454

Epoch: 5| Step: 7
Training loss: 0.49223663448130844
Validation loss: 2.2712958257119245

Epoch: 5| Step: 8
Training loss: 0.2720547454608697
Validation loss: 2.3272804407096612

Epoch: 5| Step: 9
Training loss: 0.29810677522659057
Validation loss: 2.3277066599508323

Epoch: 5| Step: 10
Training loss: 0.336389924506814
Validation loss: 2.2711629774112607

Epoch: 441| Step: 0
Training loss: 0.46117214114339633
Validation loss: 2.3162600023865094

Epoch: 5| Step: 1
Training loss: 0.3261654105088364
Validation loss: 2.321425818460034

Epoch: 5| Step: 2
Training loss: 0.3355053628416145
Validation loss: 2.3273492172870904

Epoch: 5| Step: 3
Training loss: 0.6708384879923163
Validation loss: 2.3425812025336104

Epoch: 5| Step: 4
Training loss: 0.23788258549928318
Validation loss: 2.347910582680512

Epoch: 5| Step: 5
Training loss: 0.3689639965716244
Validation loss: 2.3343508493397294

Epoch: 5| Step: 6
Training loss: 0.21801987632915665
Validation loss: 2.365891558244313

Epoch: 5| Step: 7
Training loss: 0.3343563239505976
Validation loss: 2.3603154800121713

Epoch: 5| Step: 8
Training loss: 0.3117036925768715
Validation loss: 2.3655406511457997

Epoch: 5| Step: 9
Training loss: 0.29103469786132036
Validation loss: 2.3349402434866473

Epoch: 5| Step: 10
Training loss: 0.39776687657117815
Validation loss: 2.352805882239034

Epoch: 442| Step: 0
Training loss: 0.32160651110610283
Validation loss: 2.346517688394679

Epoch: 5| Step: 1
Training loss: 0.4727289285820441
Validation loss: 2.359739237850838

Epoch: 5| Step: 2
Training loss: 0.3569950828347179
Validation loss: 2.355762729792602

Epoch: 5| Step: 3
Training loss: 0.2891795205045324
Validation loss: 2.37443484267501

Epoch: 5| Step: 4
Training loss: 0.39400165251443414
Validation loss: 2.3692890305353944

Epoch: 5| Step: 5
Training loss: 0.23269116805098236
Validation loss: 2.3717871254558305

Epoch: 5| Step: 6
Training loss: 0.4181066624222586
Validation loss: 2.345172811717044

Epoch: 5| Step: 7
Training loss: 0.48193169219502796
Validation loss: 2.3992676458845406

Epoch: 5| Step: 8
Training loss: 0.15915580289483164
Validation loss: 2.387315634702562

Epoch: 5| Step: 9
Training loss: 0.44762897308491056
Validation loss: 2.3700787561132546

Epoch: 5| Step: 10
Training loss: 0.30048625897014347
Validation loss: 2.3567605036009063

Epoch: 443| Step: 0
Training loss: 0.4745702688173341
Validation loss: 2.394281349229615

Epoch: 5| Step: 1
Training loss: 0.3649278262058785
Validation loss: 2.395578181593853

Epoch: 5| Step: 2
Training loss: 0.3779825178574363
Validation loss: 2.41751349919315

Epoch: 5| Step: 3
Training loss: 0.19831331038948144
Validation loss: 2.3819373977059257

Epoch: 5| Step: 4
Training loss: 0.3378138261957806
Validation loss: 2.3860843449642304

Epoch: 5| Step: 5
Training loss: 0.20099826840110302
Validation loss: 2.365862087303344

Epoch: 5| Step: 6
Training loss: 0.32529469709758896
Validation loss: 2.3774631979021636

Epoch: 5| Step: 7
Training loss: 0.377936764830727
Validation loss: 2.368491063327261

Epoch: 5| Step: 8
Training loss: 0.3917930496348549
Validation loss: 2.3822217166204522

Epoch: 5| Step: 9
Training loss: 0.5277278207955006
Validation loss: 2.3588756404171685

Epoch: 5| Step: 10
Training loss: 0.3031560115091699
Validation loss: 2.393957970533219

Epoch: 444| Step: 0
Training loss: 0.347230629289363
Validation loss: 2.358541926014168

Epoch: 5| Step: 1
Training loss: 0.26468151491102315
Validation loss: 2.3839274815148177

Epoch: 5| Step: 2
Training loss: 0.3938625068995547
Validation loss: 2.375231496801109

Epoch: 5| Step: 3
Training loss: 0.15307594068105174
Validation loss: 2.350465994690589

Epoch: 5| Step: 4
Training loss: 0.3980388142646507
Validation loss: 2.3834036532382457

Epoch: 5| Step: 5
Training loss: 0.2205881646450715
Validation loss: 2.3943666595848128

Epoch: 5| Step: 6
Training loss: 0.46919491633992977
Validation loss: 2.4118015496262193

Epoch: 5| Step: 7
Training loss: 0.48596695813740404
Validation loss: 2.3664946926972408

Epoch: 5| Step: 8
Training loss: 0.3770986286068088
Validation loss: 2.355792707412319

Epoch: 5| Step: 9
Training loss: 0.36337670743585077
Validation loss: 2.3837265007312674

Epoch: 5| Step: 10
Training loss: 0.38018388756674587
Validation loss: 2.390852917632121

Epoch: 445| Step: 0
Training loss: 0.18398510027699963
Validation loss: 2.3781399072682188

Epoch: 5| Step: 1
Training loss: 0.42752655415297935
Validation loss: 2.3702477403131517

Epoch: 5| Step: 2
Training loss: 0.44882936601990125
Validation loss: 2.3976557389732274

Epoch: 5| Step: 3
Training loss: 0.523068027196838
Validation loss: 2.380399732410607

Epoch: 5| Step: 4
Training loss: 0.2695228464779184
Validation loss: 2.3896171557417416

Epoch: 5| Step: 5
Training loss: 0.44264792609879977
Validation loss: 2.371078087058486

Epoch: 5| Step: 6
Training loss: 0.2504070960949012
Validation loss: 2.396846243242532

Epoch: 5| Step: 7
Training loss: 0.2733221900856914
Validation loss: 2.381855396922375

Epoch: 5| Step: 8
Training loss: 0.3507084645667655
Validation loss: 2.368708828834448

Epoch: 5| Step: 9
Training loss: 0.3461041360678778
Validation loss: 2.3315774596290195

Epoch: 5| Step: 10
Training loss: 0.2978566528885906
Validation loss: 2.327989397974571

Epoch: 446| Step: 0
Training loss: 0.3000172163076413
Validation loss: 2.3565383991408195

Epoch: 5| Step: 1
Training loss: 0.3779744755034129
Validation loss: 2.412518915332514

Epoch: 5| Step: 2
Training loss: 0.2237754932990085
Validation loss: 2.381604736052122

Epoch: 5| Step: 3
Training loss: 0.20841655956296318
Validation loss: 2.4186971424361583

Epoch: 5| Step: 4
Training loss: 0.3200819884074753
Validation loss: 2.3496998924536503

Epoch: 5| Step: 5
Training loss: 0.33432781118239246
Validation loss: 2.352915151777578

Epoch: 5| Step: 6
Training loss: 0.3491887593885891
Validation loss: 2.3706871838742725

Epoch: 5| Step: 7
Training loss: 0.29987130683033575
Validation loss: 2.3887899681508107

Epoch: 5| Step: 8
Training loss: 0.2630594983653565
Validation loss: 2.346471448797934

Epoch: 5| Step: 9
Training loss: 0.6534040594095702
Validation loss: 2.348163202130537

Epoch: 5| Step: 10
Training loss: 0.5249561654819288
Validation loss: 2.3382749491497337

Epoch: 447| Step: 0
Training loss: 0.38988065372928454
Validation loss: 2.313772867259648

Epoch: 5| Step: 1
Training loss: 0.35291670546856113
Validation loss: 2.318594482038572

Epoch: 5| Step: 2
Training loss: 0.3089193003111471
Validation loss: 2.3040778242008484

Epoch: 5| Step: 3
Training loss: 0.2485663538689909
Validation loss: 2.314431809257578

Epoch: 5| Step: 4
Training loss: 0.2806217541326384
Validation loss: 2.325019113058742

Epoch: 5| Step: 5
Training loss: 0.3165531288484619
Validation loss: 2.308273868217618

Epoch: 5| Step: 6
Training loss: 0.5464484049566185
Validation loss: 2.2877042120555067

Epoch: 5| Step: 7
Training loss: 0.3997772170088317
Validation loss: 2.337454356814556

Epoch: 5| Step: 8
Training loss: 0.30224566236227923
Validation loss: 2.3192703438482156

Epoch: 5| Step: 9
Training loss: 0.39884350230493154
Validation loss: 2.351047571644364

Epoch: 5| Step: 10
Training loss: 0.39215938573731585
Validation loss: 2.329978895717197

Epoch: 448| Step: 0
Training loss: 0.31124303269918463
Validation loss: 2.338586244766442

Epoch: 5| Step: 1
Training loss: 0.5342700052010116
Validation loss: 2.3296854092402532

Epoch: 5| Step: 2
Training loss: 0.2921963491476762
Validation loss: 2.337803546533464

Epoch: 5| Step: 3
Training loss: 0.4777203861162889
Validation loss: 2.335319562147944

Epoch: 5| Step: 4
Training loss: 0.3588601861604821
Validation loss: 2.3800128263998404

Epoch: 5| Step: 5
Training loss: 0.3956279619235611
Validation loss: 2.3746645517285185

Epoch: 5| Step: 6
Training loss: 0.3439889965660947
Validation loss: 2.3513189441841855

Epoch: 5| Step: 7
Training loss: 0.23016233603205885
Validation loss: 2.3024220768397896

Epoch: 5| Step: 8
Training loss: 0.3698118253595034
Validation loss: 2.311288196280023

Epoch: 5| Step: 9
Training loss: 0.2913018297771458
Validation loss: 2.3111903265909746

Epoch: 5| Step: 10
Training loss: 0.26492780459986554
Validation loss: 2.328465499253215

Epoch: 449| Step: 0
Training loss: 0.30698722640219156
Validation loss: 2.3194668738684174

Epoch: 5| Step: 1
Training loss: 0.35170773579159903
Validation loss: 2.3106824272215833

Epoch: 5| Step: 2
Training loss: 0.4641284247173651
Validation loss: 2.3231037369352237

Epoch: 5| Step: 3
Training loss: 0.3752534724944672
Validation loss: 2.290838287254096

Epoch: 5| Step: 4
Training loss: 0.48995091119419315
Validation loss: 2.340570309120219

Epoch: 5| Step: 5
Training loss: 0.20685013460275256
Validation loss: 2.3499760166812895

Epoch: 5| Step: 6
Training loss: 0.2901463165801427
Validation loss: 2.354627745052567

Epoch: 5| Step: 7
Training loss: 0.37957751403993084
Validation loss: 2.3323324487905284

Epoch: 5| Step: 8
Training loss: 0.4289602019905542
Validation loss: 2.3086413356769144

Epoch: 5| Step: 9
Training loss: 0.3428014868755488
Validation loss: 2.3312066316055318

Epoch: 5| Step: 10
Training loss: 0.3152087710546231
Validation loss: 2.3981312475445105

Epoch: 450| Step: 0
Training loss: 0.32441742106977994
Validation loss: 2.3392227408516697

Epoch: 5| Step: 1
Training loss: 0.27275212086203504
Validation loss: 2.340099780811948

Epoch: 5| Step: 2
Training loss: 0.47365788658862545
Validation loss: 2.3378808842247203

Epoch: 5| Step: 3
Training loss: 0.4166514592574446
Validation loss: 2.341796797274007

Epoch: 5| Step: 4
Training loss: 0.2801594519019988
Validation loss: 2.3723547473692146

Epoch: 5| Step: 5
Training loss: 0.4687465190758205
Validation loss: 2.308435868063214

Epoch: 5| Step: 6
Training loss: 0.192337805426034
Validation loss: 2.3345240757022667

Epoch: 5| Step: 7
Training loss: 0.36520528422488385
Validation loss: 2.3411803112228626

Epoch: 5| Step: 8
Training loss: 0.25439560024161345
Validation loss: 2.3487867831078897

Epoch: 5| Step: 9
Training loss: 0.3688840630470506
Validation loss: 2.354159986127311

Epoch: 5| Step: 10
Training loss: 0.429523297926977
Validation loss: 2.3458738880400034

Epoch: 451| Step: 0
Training loss: 0.5041568340046781
Validation loss: 2.3241014593870233

Epoch: 5| Step: 1
Training loss: 0.40320949556062907
Validation loss: 2.343532284704879

Epoch: 5| Step: 2
Training loss: 0.4106271130000869
Validation loss: 2.3080873757345914

Epoch: 5| Step: 3
Training loss: 0.18483885146717774
Validation loss: 2.335637819275062

Epoch: 5| Step: 4
Training loss: 0.31913864387261487
Validation loss: 2.3148454812546855

Epoch: 5| Step: 5
Training loss: 0.2957826016249609
Validation loss: 2.3370563783646783

Epoch: 5| Step: 6
Training loss: 0.38063484811805187
Validation loss: 2.308899168761428

Epoch: 5| Step: 7
Training loss: 0.3566167131912561
Validation loss: 2.320063955315152

Epoch: 5| Step: 8
Training loss: 0.2793205758022247
Validation loss: 2.331906785352473

Epoch: 5| Step: 9
Training loss: 0.3067157313217263
Validation loss: 2.3598693197261924

Epoch: 5| Step: 10
Training loss: 0.4244834123488833
Validation loss: 2.372912054208569

Epoch: 452| Step: 0
Training loss: 0.33598144376908023
Validation loss: 2.332035437293122

Epoch: 5| Step: 1
Training loss: 0.4640948730633939
Validation loss: 2.3187114668923847

Epoch: 5| Step: 2
Training loss: 0.30437219640000673
Validation loss: 2.3572489381609234

Epoch: 5| Step: 3
Training loss: 0.36377786716408494
Validation loss: 2.2995749821879428

Epoch: 5| Step: 4
Training loss: 0.3856804713843712
Validation loss: 2.3095432864314542

Epoch: 5| Step: 5
Training loss: 0.4117013438995309
Validation loss: 2.3183002946973725

Epoch: 5| Step: 6
Training loss: 0.4648322576817217
Validation loss: 2.3200210747912586

Epoch: 5| Step: 7
Training loss: 0.22967950197165188
Validation loss: 2.3431960656549964

Epoch: 5| Step: 8
Training loss: 0.37799333928436174
Validation loss: 2.3275715666420664

Epoch: 5| Step: 9
Training loss: 0.22837392375015947
Validation loss: 2.327726950749584

Epoch: 5| Step: 10
Training loss: 0.24149653095316667
Validation loss: 2.326056536122414

Epoch: 453| Step: 0
Training loss: 0.257340504892777
Validation loss: 2.3385388299195022

Epoch: 5| Step: 1
Training loss: 0.29166941840145316
Validation loss: 2.326424113299639

Epoch: 5| Step: 2
Training loss: 0.34799531411299195
Validation loss: 2.3294833792269887

Epoch: 5| Step: 3
Training loss: 0.33793807385640906
Validation loss: 2.3178433537372416

Epoch: 5| Step: 4
Training loss: 0.2753876219240765
Validation loss: 2.355065934570376

Epoch: 5| Step: 5
Training loss: 0.3617515557327509
Validation loss: 2.3688132549683054

Epoch: 5| Step: 6
Training loss: 0.3168843154553701
Validation loss: 2.3705335575215236

Epoch: 5| Step: 7
Training loss: 0.35330385641109047
Validation loss: 2.3461753541531887

Epoch: 5| Step: 8
Training loss: 0.5277868034472214
Validation loss: 2.368408307444374

Epoch: 5| Step: 9
Training loss: 0.26847427551458797
Validation loss: 2.3453968171843687

Epoch: 5| Step: 10
Training loss: 0.32620368162848506
Validation loss: 2.347869398724759

Epoch: 454| Step: 0
Training loss: 0.42963204459485105
Validation loss: 2.364814735774826

Epoch: 5| Step: 1
Training loss: 0.20102484431735756
Validation loss: 2.3831364570631584

Epoch: 5| Step: 2
Training loss: 0.32017808512990475
Validation loss: 2.3710048883438692

Epoch: 5| Step: 3
Training loss: 0.3416325855508663
Validation loss: 2.3507580154906496

Epoch: 5| Step: 4
Training loss: 0.2885549574360528
Validation loss: 2.3820749266610597

Epoch: 5| Step: 5
Training loss: 0.3016146471465609
Validation loss: 2.3675345815471958

Epoch: 5| Step: 6
Training loss: 0.3269582394800351
Validation loss: 2.356866696427891

Epoch: 5| Step: 7
Training loss: 0.36030214379176
Validation loss: 2.35882434152063

Epoch: 5| Step: 8
Training loss: 0.42174939652327964
Validation loss: 2.3296911666490336

Epoch: 5| Step: 9
Training loss: 0.40868548134869503
Validation loss: 2.348131475247117

Epoch: 5| Step: 10
Training loss: 0.21312439184297843
Validation loss: 2.3535045360899143

Epoch: 455| Step: 0
Training loss: 0.3304769037020891
Validation loss: 2.337008238641894

Epoch: 5| Step: 1
Training loss: 0.2142862803516972
Validation loss: 2.3140664996110605

Epoch: 5| Step: 2
Training loss: 0.32581500557763493
Validation loss: 2.3125809248201157

Epoch: 5| Step: 3
Training loss: 0.4345173664200098
Validation loss: 2.364188252656931

Epoch: 5| Step: 4
Training loss: 0.2227713638682731
Validation loss: 2.3418934174498753

Epoch: 5| Step: 5
Training loss: 0.2830471924946642
Validation loss: 2.373132514429555

Epoch: 5| Step: 6
Training loss: 0.39172639070171855
Validation loss: 2.3816839258420592

Epoch: 5| Step: 7
Training loss: 0.27354424981415365
Validation loss: 2.353217934450766

Epoch: 5| Step: 8
Training loss: 0.38157106075946506
Validation loss: 2.3781967960108363

Epoch: 5| Step: 9
Training loss: 0.39816660180110625
Validation loss: 2.3227356028464965

Epoch: 5| Step: 10
Training loss: 0.3418316087785447
Validation loss: 2.325765168740115

Epoch: 456| Step: 0
Training loss: 0.3035993217628427
Validation loss: 2.3380188818835563

Epoch: 5| Step: 1
Training loss: 0.2196284774565762
Validation loss: 2.335176209469336

Epoch: 5| Step: 2
Training loss: 0.42491625493676743
Validation loss: 2.347446533498137

Epoch: 5| Step: 3
Training loss: 0.36294464185627184
Validation loss: 2.3464093287814576

Epoch: 5| Step: 4
Training loss: 0.41833551304972505
Validation loss: 2.284574578971943

Epoch: 5| Step: 5
Training loss: 0.3743365100504722
Validation loss: 2.3364734101451026

Epoch: 5| Step: 6
Training loss: 0.23069181800155858
Validation loss: 2.329964267383307

Epoch: 5| Step: 7
Training loss: 0.3978869430398598
Validation loss: 2.3155970876709016

Epoch: 5| Step: 8
Training loss: 0.1765319371567134
Validation loss: 2.324666910109839

Epoch: 5| Step: 9
Training loss: 0.3091003147400396
Validation loss: 2.356851265803341

Epoch: 5| Step: 10
Training loss: 0.33845114108955715
Validation loss: 2.328468890330906

Epoch: 457| Step: 0
Training loss: 0.38516864872720535
Validation loss: 2.33040757239785

Epoch: 5| Step: 1
Training loss: 0.28988527787063234
Validation loss: 2.3665182956758524

Epoch: 5| Step: 2
Training loss: 0.31926229485217344
Validation loss: 2.3577795732219355

Epoch: 5| Step: 3
Training loss: 0.3804717805964969
Validation loss: 2.3295162669035587

Epoch: 5| Step: 4
Training loss: 0.316127300923799
Validation loss: 2.374699174690059

Epoch: 5| Step: 5
Training loss: 0.33494085134889245
Validation loss: 2.392244086018914

Epoch: 5| Step: 6
Training loss: 0.2907272804925287
Validation loss: 2.334513822321105

Epoch: 5| Step: 7
Training loss: 0.42655987371956694
Validation loss: 2.3757291002838246

Epoch: 5| Step: 8
Training loss: 0.3457609333046001
Validation loss: 2.3643919844889085

Epoch: 5| Step: 9
Training loss: 0.18669090941297597
Validation loss: 2.3755482471007703

Epoch: 5| Step: 10
Training loss: 0.2773956465186305
Validation loss: 2.3751403257648493

Epoch: 458| Step: 0
Training loss: 0.3166805655896746
Validation loss: 2.358247370819858

Epoch: 5| Step: 1
Training loss: 0.3809652132526151
Validation loss: 2.3727275747514445

Epoch: 5| Step: 2
Training loss: 0.22309966022257405
Validation loss: 2.351458090564007

Epoch: 5| Step: 3
Training loss: 0.36472254093629486
Validation loss: 2.3842021481398743

Epoch: 5| Step: 4
Training loss: 0.3182543481872853
Validation loss: 2.3213876803579763

Epoch: 5| Step: 5
Training loss: 0.19695448179280783
Validation loss: 2.3591498517629037

Epoch: 5| Step: 6
Training loss: 0.42904804505450844
Validation loss: 2.3385510981045465

Epoch: 5| Step: 7
Training loss: 0.23385720275799823
Validation loss: 2.3824707786793495

Epoch: 5| Step: 8
Training loss: 0.3481893523952201
Validation loss: 2.3492327248530764

Epoch: 5| Step: 9
Training loss: 0.3277835886291119
Validation loss: 2.3421402213677696

Epoch: 5| Step: 10
Training loss: 0.3179985529173908
Validation loss: 2.369869977641349

Epoch: 459| Step: 0
Training loss: 0.16185836432191417
Validation loss: 2.3721398476314217

Epoch: 5| Step: 1
Training loss: 0.5055480057667322
Validation loss: 2.371289901835753

Epoch: 5| Step: 2
Training loss: 0.30749259726599953
Validation loss: 2.408234176513397

Epoch: 5| Step: 3
Training loss: 0.36918522802467196
Validation loss: 2.358586144217761

Epoch: 5| Step: 4
Training loss: 0.36382732572297777
Validation loss: 2.382497898032831

Epoch: 5| Step: 5
Training loss: 0.15838969967374153
Validation loss: 2.3829933155728544

Epoch: 5| Step: 6
Training loss: 0.17503427101801378
Validation loss: 2.402197715788685

Epoch: 5| Step: 7
Training loss: 0.38812708413367697
Validation loss: 2.3767098428465823

Epoch: 5| Step: 8
Training loss: 0.31610199934961586
Validation loss: 2.3319287518661413

Epoch: 5| Step: 9
Training loss: 0.39570834880367034
Validation loss: 2.3552559050502335

Epoch: 5| Step: 10
Training loss: 0.35425465089306457
Validation loss: 2.3523644828944614

Epoch: 460| Step: 0
Training loss: 0.3892736903511013
Validation loss: 2.339011894998972

Epoch: 5| Step: 1
Training loss: 0.3398940169768806
Validation loss: 2.3279601415403315

Epoch: 5| Step: 2
Training loss: 0.22285292121011635
Validation loss: 2.359393760749448

Epoch: 5| Step: 3
Training loss: 0.32467720066804273
Validation loss: 2.316462421495322

Epoch: 5| Step: 4
Training loss: 0.2809389831877224
Validation loss: 2.3128469340504716

Epoch: 5| Step: 5
Training loss: 0.4029658794559684
Validation loss: 2.3381207972608284

Epoch: 5| Step: 6
Training loss: 0.33814345806530793
Validation loss: 2.3342843970429077

Epoch: 5| Step: 7
Training loss: 0.20706199921473434
Validation loss: 2.328841511056841

Epoch: 5| Step: 8
Training loss: 0.32498022074299904
Validation loss: 2.3397266805744854

Epoch: 5| Step: 9
Training loss: 0.2345677933887203
Validation loss: 2.3154923413633983

Epoch: 5| Step: 10
Training loss: 0.36330319410107026
Validation loss: 2.3371901660340275

Epoch: 461| Step: 0
Training loss: 0.20928972877813043
Validation loss: 2.3095185578150454

Epoch: 5| Step: 1
Training loss: 0.31997231119660796
Validation loss: 2.3250001747245075

Epoch: 5| Step: 2
Training loss: 0.32306569516252615
Validation loss: 2.3317093984618564

Epoch: 5| Step: 3
Training loss: 0.2923378190540457
Validation loss: 2.3114484742625585

Epoch: 5| Step: 4
Training loss: 0.24970696829331446
Validation loss: 2.279531177760644

Epoch: 5| Step: 5
Training loss: 0.4610731604130858
Validation loss: 2.3266833804693463

Epoch: 5| Step: 6
Training loss: 0.25827275720884796
Validation loss: 2.298811758625073

Epoch: 5| Step: 7
Training loss: 0.23534743119408721
Validation loss: 2.2976941474376362

Epoch: 5| Step: 8
Training loss: 0.2305453787315261
Validation loss: 2.3173863514406046

Epoch: 5| Step: 9
Training loss: 0.42104650313770464
Validation loss: 2.299256809313731

Epoch: 5| Step: 10
Training loss: 0.3982621349298681
Validation loss: 2.3560046717188996

Epoch: 462| Step: 0
Training loss: 0.2905752062440961
Validation loss: 2.3398118511425525

Epoch: 5| Step: 1
Training loss: 0.34354796758155204
Validation loss: 2.337947233200789

Epoch: 5| Step: 2
Training loss: 0.47102715193892297
Validation loss: 2.34738425963101

Epoch: 5| Step: 3
Training loss: 0.3541481303057824
Validation loss: 2.332267452590373

Epoch: 5| Step: 4
Training loss: 0.19498330984765427
Validation loss: 2.3438127636452983

Epoch: 5| Step: 5
Training loss: 0.44774315674502785
Validation loss: 2.341650060230528

Epoch: 5| Step: 6
Training loss: 0.2726468508174233
Validation loss: 2.3600126655830382

Epoch: 5| Step: 7
Training loss: 0.2136177629089809
Validation loss: 2.3537806627245987

Epoch: 5| Step: 8
Training loss: 0.2509145400302311
Validation loss: 2.3352688853032646

Epoch: 5| Step: 9
Training loss: 0.17481865107850705
Validation loss: 2.326978660160427

Epoch: 5| Step: 10
Training loss: 0.37645932204653776
Validation loss: 2.2832126791094387

Epoch: 463| Step: 0
Training loss: 0.37770132809830426
Validation loss: 2.317243869132841

Epoch: 5| Step: 1
Training loss: 0.22768839245939887
Validation loss: 2.2953410955902696

Epoch: 5| Step: 2
Training loss: 0.18056090219133375
Validation loss: 2.331144557905036

Epoch: 5| Step: 3
Training loss: 0.2634016559692153
Validation loss: 2.315962769966384

Epoch: 5| Step: 4
Training loss: 0.1730989905127246
Validation loss: 2.3154392005313005

Epoch: 5| Step: 5
Training loss: 0.3469201556876458
Validation loss: 2.3083891110825947

Epoch: 5| Step: 6
Training loss: 0.31519227201702216
Validation loss: 2.319538874005005

Epoch: 5| Step: 7
Training loss: 0.3462847434525969
Validation loss: 2.3123348457585156

Epoch: 5| Step: 8
Training loss: 0.45516623106625664
Validation loss: 2.3249401114366877

Epoch: 5| Step: 9
Training loss: 0.39957568342638144
Validation loss: 2.3571666272099576

Epoch: 5| Step: 10
Training loss: 0.2175687674902071
Validation loss: 2.30307061577008

Epoch: 464| Step: 0
Training loss: 0.3591704823246285
Validation loss: 2.3281998744458314

Epoch: 5| Step: 1
Training loss: 0.3892523298628703
Validation loss: 2.3407522279910586

Epoch: 5| Step: 2
Training loss: 0.22517198506316133
Validation loss: 2.389564852276474

Epoch: 5| Step: 3
Training loss: 0.38646533639257297
Validation loss: 2.3249220027756983

Epoch: 5| Step: 4
Training loss: 0.18895151648234632
Validation loss: 2.367128549948673

Epoch: 5| Step: 5
Training loss: 0.3157798193814706
Validation loss: 2.361363669539914

Epoch: 5| Step: 6
Training loss: 0.41731801581011874
Validation loss: 2.3769860439906285

Epoch: 5| Step: 7
Training loss: 0.3344624761438345
Validation loss: 2.3744712839086004

Epoch: 5| Step: 8
Training loss: 0.365278659522552
Validation loss: 2.3794666137269673

Epoch: 5| Step: 9
Training loss: 0.17456828813793931
Validation loss: 2.398314003829483

Epoch: 5| Step: 10
Training loss: 0.24976737405106697
Validation loss: 2.3556866174411737

Epoch: 465| Step: 0
Training loss: 0.21997735863375004
Validation loss: 2.36832488836316

Epoch: 5| Step: 1
Training loss: 0.4058507094132776
Validation loss: 2.362720801296442

Epoch: 5| Step: 2
Training loss: 0.25609947179578224
Validation loss: 2.35466425765459

Epoch: 5| Step: 3
Training loss: 0.3790189044661272
Validation loss: 2.3763764423912974

Epoch: 5| Step: 4
Training loss: 0.18825466553984505
Validation loss: 2.3967843720620174

Epoch: 5| Step: 5
Training loss: 0.42290612765117125
Validation loss: 2.3804334405391363

Epoch: 5| Step: 6
Training loss: 0.2863460696479373
Validation loss: 2.347042633973886

Epoch: 5| Step: 7
Training loss: 0.24530559305320151
Validation loss: 2.369202800411974

Epoch: 5| Step: 8
Training loss: 0.2409936567214678
Validation loss: 2.4041269869332664

Epoch: 5| Step: 9
Training loss: 0.33776602900932173
Validation loss: 2.396147889134696

Epoch: 5| Step: 10
Training loss: 0.4547153058021574
Validation loss: 2.3669846061048863

Epoch: 466| Step: 0
Training loss: 0.3274401829961493
Validation loss: 2.337900848219655

Epoch: 5| Step: 1
Training loss: 0.28671759519422424
Validation loss: 2.3902413837035215

Epoch: 5| Step: 2
Training loss: 0.29924966338703596
Validation loss: 2.348820405736008

Epoch: 5| Step: 3
Training loss: 0.335729168455854
Validation loss: 2.3547941887572184

Epoch: 5| Step: 4
Training loss: 0.17907438165546466
Validation loss: 2.351723499705703

Epoch: 5| Step: 5
Training loss: 0.30354045486513764
Validation loss: 2.3796708560232513

Epoch: 5| Step: 6
Training loss: 0.32798997053434725
Validation loss: 2.3673089011605586

Epoch: 5| Step: 7
Training loss: 0.4748263863705533
Validation loss: 2.3453710488889055

Epoch: 5| Step: 8
Training loss: 0.2546965696908118
Validation loss: 2.3690349634187013

Epoch: 5| Step: 9
Training loss: 0.3715628419751004
Validation loss: 2.3148984125644874

Epoch: 5| Step: 10
Training loss: 0.16273390299691523
Validation loss: 2.342080068402107

Epoch: 467| Step: 0
Training loss: 0.2247553309687789
Validation loss: 2.3122046303348633

Epoch: 5| Step: 1
Training loss: 0.38634260746392673
Validation loss: 2.3654123204466306

Epoch: 5| Step: 2
Training loss: 0.3670824387583114
Validation loss: 2.3083618040880856

Epoch: 5| Step: 3
Training loss: 0.2342949571623224
Validation loss: 2.36791342958932

Epoch: 5| Step: 4
Training loss: 0.17517199366423183
Validation loss: 2.3534893595573134

Epoch: 5| Step: 5
Training loss: 0.27307274877288523
Validation loss: 2.3530512490545523

Epoch: 5| Step: 6
Training loss: 0.36473657475603877
Validation loss: 2.340152800393128

Epoch: 5| Step: 7
Training loss: 0.2734611228547946
Validation loss: 2.333199678129441

Epoch: 5| Step: 8
Training loss: 0.4155893604515161
Validation loss: 2.336386093968576

Epoch: 5| Step: 9
Training loss: 0.3122840612111846
Validation loss: 2.3467501650471903

Epoch: 5| Step: 10
Training loss: 0.27698980500123666
Validation loss: 2.3530534520150446

Epoch: 468| Step: 0
Training loss: 0.17067279087866166
Validation loss: 2.3767303039604797

Epoch: 5| Step: 1
Training loss: 0.2595194173247879
Validation loss: 2.3324319175759713

Epoch: 5| Step: 2
Training loss: 0.15171949548469413
Validation loss: 2.3388991211629264

Epoch: 5| Step: 3
Training loss: 0.42758148108401917
Validation loss: 2.3442125811462673

Epoch: 5| Step: 4
Training loss: 0.40274729444351576
Validation loss: 2.371335566675839

Epoch: 5| Step: 5
Training loss: 0.3574319223127826
Validation loss: 2.3654852362243832

Epoch: 5| Step: 6
Training loss: 0.4143607127343069
Validation loss: 2.3579192157531796

Epoch: 5| Step: 7
Training loss: 0.2881545163011331
Validation loss: 2.3724811367927185

Epoch: 5| Step: 8
Training loss: 0.3761904219732395
Validation loss: 2.3539114213052037

Epoch: 5| Step: 9
Training loss: 0.18643414022530358
Validation loss: 2.3607318000042077

Epoch: 5| Step: 10
Training loss: 0.19945629767327477
Validation loss: 2.3938065350757527

Epoch: 469| Step: 0
Training loss: 0.2835473040964659
Validation loss: 2.344378901503115

Epoch: 5| Step: 1
Training loss: 0.3354785134574196
Validation loss: 2.368955493645423

Epoch: 5| Step: 2
Training loss: 0.3109528868428821
Validation loss: 2.380395495571265

Epoch: 5| Step: 3
Training loss: 0.31668564740608957
Validation loss: 2.381658521629238

Epoch: 5| Step: 4
Training loss: 0.2706744923387169
Validation loss: 2.389207675449594

Epoch: 5| Step: 5
Training loss: 0.10896207571060836
Validation loss: 2.3830021360972475

Epoch: 5| Step: 6
Training loss: 0.38610581268399896
Validation loss: 2.3802537358847347

Epoch: 5| Step: 7
Training loss: 0.3684910301296916
Validation loss: 2.4004492473403505

Epoch: 5| Step: 8
Training loss: 0.4172400780738631
Validation loss: 2.3687255588843863

Epoch: 5| Step: 9
Training loss: 0.27628704027697615
Validation loss: 2.382968655799654

Epoch: 5| Step: 10
Training loss: 0.2297295337284424
Validation loss: 2.3951903623143322

Epoch: 470| Step: 0
Training loss: 0.4595708792732009
Validation loss: 2.34838303603998

Epoch: 5| Step: 1
Training loss: 0.31382689107548334
Validation loss: 2.3493789293752894

Epoch: 5| Step: 2
Training loss: 0.1876812495938476
Validation loss: 2.3904734442896323

Epoch: 5| Step: 3
Training loss: 0.18178790284669363
Validation loss: 2.3662016042129883

Epoch: 5| Step: 4
Training loss: 0.3906703922600756
Validation loss: 2.355287533515037

Epoch: 5| Step: 5
Training loss: 0.2639081955561906
Validation loss: 2.3906579561942443

Epoch: 5| Step: 6
Training loss: 0.42193650750964673
Validation loss: 2.353062669127083

Epoch: 5| Step: 7
Training loss: 0.38633419915371875
Validation loss: 2.321019046553931

Epoch: 5| Step: 8
Training loss: 0.30115017002527794
Validation loss: 2.3307729119678773

Epoch: 5| Step: 9
Training loss: 0.23144934445502796
Validation loss: 2.3311784195912337

Epoch: 5| Step: 10
Training loss: 0.16304991090047413
Validation loss: 2.3377143822971314

Epoch: 471| Step: 0
Training loss: 0.3812646519081158
Validation loss: 2.341109424539601

Epoch: 5| Step: 1
Training loss: 0.3762111575966002
Validation loss: 2.3420132585436066

Epoch: 5| Step: 2
Training loss: 0.30226147540121406
Validation loss: 2.3528954584552135

Epoch: 5| Step: 3
Training loss: 0.2323456967957854
Validation loss: 2.366442388966434

Epoch: 5| Step: 4
Training loss: 0.4132323670637961
Validation loss: 2.34812303359671

Epoch: 5| Step: 5
Training loss: 0.4525382913279147
Validation loss: 2.385580842205548

Epoch: 5| Step: 6
Training loss: 0.29495960272172633
Validation loss: 2.3773459466684908

Epoch: 5| Step: 7
Training loss: 0.12434669479253904
Validation loss: 2.3805124463691243

Epoch: 5| Step: 8
Training loss: 0.3134891947164861
Validation loss: 2.402942404733557

Epoch: 5| Step: 9
Training loss: 0.16838053196426545
Validation loss: 2.3238586753518726

Epoch: 5| Step: 10
Training loss: 0.30222675464984433
Validation loss: 2.357864678812068

Epoch: 472| Step: 0
Training loss: 0.3493518733489356
Validation loss: 2.3492830939336016

Epoch: 5| Step: 1
Training loss: 0.30628379177972825
Validation loss: 2.3357227037505934

Epoch: 5| Step: 2
Training loss: 0.21601996529549128
Validation loss: 2.3373136331042854

Epoch: 5| Step: 3
Training loss: 0.23231136676120914
Validation loss: 2.296869954470652

Epoch: 5| Step: 4
Training loss: 0.22689387324414195
Validation loss: 2.304540262303946

Epoch: 5| Step: 5
Training loss: 0.4278254477336794
Validation loss: 2.356786417678725

Epoch: 5| Step: 6
Training loss: 0.4010997911748007
Validation loss: 2.3570780437208794

Epoch: 5| Step: 7
Training loss: 0.1995157944407204
Validation loss: 2.3093224067443465

Epoch: 5| Step: 8
Training loss: 0.3839755005844214
Validation loss: 2.391499550733298

Epoch: 5| Step: 9
Training loss: 0.31182337465513327
Validation loss: 2.3381741448693836

Epoch: 5| Step: 10
Training loss: 0.26759889619496985
Validation loss: 2.353655478032129

Epoch: 473| Step: 0
Training loss: 0.4478448174389171
Validation loss: 2.3591612768156383

Epoch: 5| Step: 1
Training loss: 0.2867040822697477
Validation loss: 2.369708467573841

Epoch: 5| Step: 2
Training loss: 0.3377331824439351
Validation loss: 2.336878658116804

Epoch: 5| Step: 3
Training loss: 0.18462321618199184
Validation loss: 2.37765501761122

Epoch: 5| Step: 4
Training loss: 0.2418527828160751
Validation loss: 2.3327390073913663

Epoch: 5| Step: 5
Training loss: 0.28206260168748676
Validation loss: 2.36835912231187

Epoch: 5| Step: 6
Training loss: 0.3053377499871744
Validation loss: 2.4158969955837954

Epoch: 5| Step: 7
Training loss: 0.1564980623941096
Validation loss: 2.3683045627368005

Epoch: 5| Step: 8
Training loss: 0.5029034357719304
Validation loss: 2.3968473454538546

Epoch: 5| Step: 9
Training loss: 0.25401091252468183
Validation loss: 2.389153734693052

Epoch: 5| Step: 10
Training loss: 0.32009494185176923
Validation loss: 2.387726263513402

Epoch: 474| Step: 0
Training loss: 0.29492104132326036
Validation loss: 2.3993446382491386

Epoch: 5| Step: 1
Training loss: 0.1878869712617089
Validation loss: 2.389717107132212

Epoch: 5| Step: 2
Training loss: 0.16571339416697167
Validation loss: 2.381993024784617

Epoch: 5| Step: 3
Training loss: 0.42377847829001913
Validation loss: 2.38259814216244

Epoch: 5| Step: 4
Training loss: 0.3883704737303441
Validation loss: 2.3870810343581805

Epoch: 5| Step: 5
Training loss: 0.14853284935598796
Validation loss: 2.3672461096158455

Epoch: 5| Step: 6
Training loss: 0.359030081212574
Validation loss: 2.383951483994494

Epoch: 5| Step: 7
Training loss: 0.25936877978576195
Validation loss: 2.3715816188548247

Epoch: 5| Step: 8
Training loss: 0.300901636579341
Validation loss: 2.3778891124061214

Epoch: 5| Step: 9
Training loss: 0.4335620627981893
Validation loss: 2.386666902100097

Epoch: 5| Step: 10
Training loss: 0.30311457232600203
Validation loss: 2.36312614602468

Epoch: 475| Step: 0
Training loss: 0.214726285901307
Validation loss: 2.365334907476878

Epoch: 5| Step: 1
Training loss: 0.19038419913811075
Validation loss: 2.350850980547267

Epoch: 5| Step: 2
Training loss: 0.38415176297872733
Validation loss: 2.3707391863329823

Epoch: 5| Step: 3
Training loss: 0.3857287827106199
Validation loss: 2.3760879919570694

Epoch: 5| Step: 4
Training loss: 0.309288209243095
Validation loss: 2.3766938890042586

Epoch: 5| Step: 5
Training loss: 0.34234360700540767
Validation loss: 2.388389451508479

Epoch: 5| Step: 6
Training loss: 0.26724877240511913
Validation loss: 2.4227295213861617

Epoch: 5| Step: 7
Training loss: 0.41224256053756375
Validation loss: 2.4000943514862345

Epoch: 5| Step: 8
Training loss: 0.3767902635171863
Validation loss: 2.34697390308705

Epoch: 5| Step: 9
Training loss: 0.32518944720686593
Validation loss: 2.366327951227028

Epoch: 5| Step: 10
Training loss: 0.19338289753569077
Validation loss: 2.347534753119624

Epoch: 476| Step: 0
Training loss: 0.1350156289564074
Validation loss: 2.3560978845776677

Epoch: 5| Step: 1
Training loss: 0.33484531998544415
Validation loss: 2.3167794154645045

Epoch: 5| Step: 2
Training loss: 0.4544366728054131
Validation loss: 2.3989711770445834

Epoch: 5| Step: 3
Training loss: 0.4335580244038167
Validation loss: 2.317608729664104

Epoch: 5| Step: 4
Training loss: 0.40410782821613533
Validation loss: 2.352710543252797

Epoch: 5| Step: 5
Training loss: 0.42686731605260453
Validation loss: 2.3381303824373187

Epoch: 5| Step: 6
Training loss: 0.2596441429429235
Validation loss: 2.398022596178162

Epoch: 5| Step: 7
Training loss: 0.25627338605094735
Validation loss: 2.38970282007412

Epoch: 5| Step: 8
Training loss: 0.2657741520565724
Validation loss: 2.3662546364471035

Epoch: 5| Step: 9
Training loss: 0.3174295479036996
Validation loss: 2.33074011241831

Epoch: 5| Step: 10
Training loss: 0.20432801893639457
Validation loss: 2.332576365967075

Epoch: 477| Step: 0
Training loss: 0.371232438523024
Validation loss: 2.2889822047370325

Epoch: 5| Step: 1
Training loss: 0.33599462688781995
Validation loss: 2.3211159418413767

Epoch: 5| Step: 2
Training loss: 0.28247494970507403
Validation loss: 2.3054872855153588

Epoch: 5| Step: 3
Training loss: 0.31028675485400165
Validation loss: 2.33213891128346

Epoch: 5| Step: 4
Training loss: 0.4209703884006503
Validation loss: 2.338012771074083

Epoch: 5| Step: 5
Training loss: 0.4126053126601006
Validation loss: 2.2688053043117358

Epoch: 5| Step: 6
Training loss: 0.40566686813860936
Validation loss: 2.2958805514493874

Epoch: 5| Step: 7
Training loss: 0.273546592203688
Validation loss: 2.3482308381352204

Epoch: 5| Step: 8
Training loss: 0.19176765304745017
Validation loss: 2.312027442538127

Epoch: 5| Step: 9
Training loss: 0.3284388358309482
Validation loss: 2.356473660445052

Epoch: 5| Step: 10
Training loss: 0.42369402684554114
Validation loss: 2.346203237232298

Epoch: 478| Step: 0
Training loss: 0.26830013348657483
Validation loss: 2.3905720327880653

Epoch: 5| Step: 1
Training loss: 0.23893812191508323
Validation loss: 2.356510780865547

Epoch: 5| Step: 2
Training loss: 0.28404721715205544
Validation loss: 2.315468965039142

Epoch: 5| Step: 3
Training loss: 0.32816498376557846
Validation loss: 2.355851262080799

Epoch: 5| Step: 4
Training loss: 0.24109575865348243
Validation loss: 2.3766224483900693

Epoch: 5| Step: 5
Training loss: 0.39774689006728514
Validation loss: 2.330826825637048

Epoch: 5| Step: 6
Training loss: 0.23706069616279654
Validation loss: 2.3830722053381157

Epoch: 5| Step: 7
Training loss: 0.42974939767463555
Validation loss: 2.338194630174554

Epoch: 5| Step: 8
Training loss: 0.4439038869492106
Validation loss: 2.3779281301872963

Epoch: 5| Step: 9
Training loss: 0.28492530197287547
Validation loss: 2.3672504896568203

Epoch: 5| Step: 10
Training loss: 0.3656493496733998
Validation loss: 2.3468509027302913

Epoch: 479| Step: 0
Training loss: 0.20493455129923635
Validation loss: 2.3544900185505657

Epoch: 5| Step: 1
Training loss: 0.2684260806007303
Validation loss: 2.3634350331964007

Epoch: 5| Step: 2
Training loss: 0.37384650525037016
Validation loss: 2.340267508627372

Epoch: 5| Step: 3
Training loss: 0.23446427075676843
Validation loss: 2.3539902652472247

Epoch: 5| Step: 4
Training loss: 0.32507580918356066
Validation loss: 2.3958306425346114

Epoch: 5| Step: 5
Training loss: 0.23035345588101308
Validation loss: 2.3706859402738836

Epoch: 5| Step: 6
Training loss: 0.4171027722562211
Validation loss: 2.3603586147095283

Epoch: 5| Step: 7
Training loss: 0.46181891915179546
Validation loss: 2.3213462809595597

Epoch: 5| Step: 8
Training loss: 0.32366025459557574
Validation loss: 2.3226741879607036

Epoch: 5| Step: 9
Training loss: 0.27907863173041814
Validation loss: 2.341371601314294

Epoch: 5| Step: 10
Training loss: 0.27722296972743105
Validation loss: 2.333757537378446

Epoch: 480| Step: 0
Training loss: 0.42645396014966797
Validation loss: 2.344779492768281

Epoch: 5| Step: 1
Training loss: 0.3614198722861379
Validation loss: 2.339120927737265

Epoch: 5| Step: 2
Training loss: 0.3431684603379444
Validation loss: 2.3174764028832096

Epoch: 5| Step: 3
Training loss: 0.3157977858738774
Validation loss: 2.316545131833249

Epoch: 5| Step: 4
Training loss: 0.30954073214076433
Validation loss: 2.3232596107597216

Epoch: 5| Step: 5
Training loss: 0.3617066127973618
Validation loss: 2.3288019972560847

Epoch: 5| Step: 6
Training loss: 0.15940047672879798
Validation loss: 2.309237351705026

Epoch: 5| Step: 7
Training loss: 0.22971572540361548
Validation loss: 2.3186982949130774

Epoch: 5| Step: 8
Training loss: 0.2530586473600843
Validation loss: 2.338832064790115

Epoch: 5| Step: 9
Training loss: 0.21625460430987703
Validation loss: 2.308416101243756

Epoch: 5| Step: 10
Training loss: 0.3757208412770255
Validation loss: 2.311662031014493

Epoch: 481| Step: 0
Training loss: 0.41707572725558795
Validation loss: 2.3076857263638444

Epoch: 5| Step: 1
Training loss: 0.41949100123723576
Validation loss: 2.323551072770192

Epoch: 5| Step: 2
Training loss: 0.329198330651972
Validation loss: 2.31329737537742

Epoch: 5| Step: 3
Training loss: 0.24652372369581887
Validation loss: 2.316560898996664

Epoch: 5| Step: 4
Training loss: 0.16385607562395055
Validation loss: 2.2862219263021

Epoch: 5| Step: 5
Training loss: 0.2349354321849778
Validation loss: 2.3075646935412393

Epoch: 5| Step: 6
Training loss: 0.2078587441152728
Validation loss: 2.309660527716991

Epoch: 5| Step: 7
Training loss: 0.26886268293826854
Validation loss: 2.3384838278434485

Epoch: 5| Step: 8
Training loss: 0.48716987778637105
Validation loss: 2.310694320190841

Epoch: 5| Step: 9
Training loss: 0.2136372239994326
Validation loss: 2.37477439106727

Epoch: 5| Step: 10
Training loss: 0.23505960455543612
Validation loss: 2.3732117325254714

Epoch: 482| Step: 0
Training loss: 0.38152380476061293
Validation loss: 2.373584903229529

Epoch: 5| Step: 1
Training loss: 0.20808260652007535
Validation loss: 2.3603818695822882

Epoch: 5| Step: 2
Training loss: 0.3510097290569527
Validation loss: 2.3274013520296384

Epoch: 5| Step: 3
Training loss: 0.28517619807872113
Validation loss: 2.358048117323491

Epoch: 5| Step: 4
Training loss: 0.35597565946252
Validation loss: 2.3742195222173614

Epoch: 5| Step: 5
Training loss: 0.4318374944319796
Validation loss: 2.3534635589549606

Epoch: 5| Step: 6
Training loss: 0.21002827828610324
Validation loss: 2.377786517199865

Epoch: 5| Step: 7
Training loss: 0.3089137048357222
Validation loss: 2.3682077243248756

Epoch: 5| Step: 8
Training loss: 0.2463950931004362
Validation loss: 2.3750342586272266

Epoch: 5| Step: 9
Training loss: 0.26232457145943844
Validation loss: 2.362903642568636

Epoch: 5| Step: 10
Training loss: 0.15641202870229892
Validation loss: 2.3693429999293527

Epoch: 483| Step: 0
Training loss: 0.15100521985246518
Validation loss: 2.3692207994774575

Epoch: 5| Step: 1
Training loss: 0.19411053836955672
Validation loss: 2.3622707858001477

Epoch: 5| Step: 2
Training loss: 0.28644283281639615
Validation loss: 2.3662431153620664

Epoch: 5| Step: 3
Training loss: 0.23880874374208977
Validation loss: 2.3362193686402364

Epoch: 5| Step: 4
Training loss: 0.22345185767240436
Validation loss: 2.3566528855535678

Epoch: 5| Step: 5
Training loss: 0.3233814918934013
Validation loss: 2.356070922703463

Epoch: 5| Step: 6
Training loss: 0.37069439732012244
Validation loss: 2.3473614793991646

Epoch: 5| Step: 7
Training loss: 0.3057204977471224
Validation loss: 2.3263516193266223

Epoch: 5| Step: 8
Training loss: 0.24127655063554193
Validation loss: 2.3461797707990617

Epoch: 5| Step: 9
Training loss: 0.2802573009989601
Validation loss: 2.342712953898782

Epoch: 5| Step: 10
Training loss: 0.4837275762067575
Validation loss: 2.3538386722347107

Epoch: 484| Step: 0
Training loss: 0.401722066621506
Validation loss: 2.338152559108894

Epoch: 5| Step: 1
Training loss: 0.17593647143468139
Validation loss: 2.3716716014585395

Epoch: 5| Step: 2
Training loss: 0.2864416493267827
Validation loss: 2.361711271819763

Epoch: 5| Step: 3
Training loss: 0.13060858165875605
Validation loss: 2.3728855545629073

Epoch: 5| Step: 4
Training loss: 0.2560655476633408
Validation loss: 2.3446097532809853

Epoch: 5| Step: 5
Training loss: 0.519536240632603
Validation loss: 2.3614320774108655

Epoch: 5| Step: 6
Training loss: 0.2805483330582771
Validation loss: 2.393193328766554

Epoch: 5| Step: 7
Training loss: 0.3708850876272305
Validation loss: 2.393343982519737

Epoch: 5| Step: 8
Training loss: 0.2648202542485749
Validation loss: 2.3459004431047723

Epoch: 5| Step: 9
Training loss: 0.170868091613825
Validation loss: 2.3372463392921627

Epoch: 5| Step: 10
Training loss: 0.2613412212289168
Validation loss: 2.3797595519068055

Epoch: 485| Step: 0
Training loss: 0.1981895076117098
Validation loss: 2.37778740991838

Epoch: 5| Step: 1
Training loss: 0.31244427660991003
Validation loss: 2.336546348786708

Epoch: 5| Step: 2
Training loss: 0.3022069705422414
Validation loss: 2.360345256440492

Epoch: 5| Step: 3
Training loss: 0.4430115801845504
Validation loss: 2.3572164645974563

Epoch: 5| Step: 4
Training loss: 0.20557771411520392
Validation loss: 2.3244907831090242

Epoch: 5| Step: 5
Training loss: 0.24183302749265667
Validation loss: 2.3548185448015655

Epoch: 5| Step: 6
Training loss: 0.29041503530661666
Validation loss: 2.378385235034812

Epoch: 5| Step: 7
Training loss: 0.20632600323164954
Validation loss: 2.361665309076827

Epoch: 5| Step: 8
Training loss: 0.29001992416175393
Validation loss: 2.3628161795914275

Epoch: 5| Step: 9
Training loss: 0.25774366731477005
Validation loss: 2.3723699842206676

Epoch: 5| Step: 10
Training loss: 0.3665450542880695
Validation loss: 2.3599102421216025

Epoch: 486| Step: 0
Training loss: 0.2660212366349676
Validation loss: 2.4053586521629673

Epoch: 5| Step: 1
Training loss: 0.2512868751443725
Validation loss: 2.381199130194613

Epoch: 5| Step: 2
Training loss: 0.1626028627129111
Validation loss: 2.3671785783107153

Epoch: 5| Step: 3
Training loss: 0.3383070524035388
Validation loss: 2.400324438454153

Epoch: 5| Step: 4
Training loss: 0.3214835531935727
Validation loss: 2.412010862230194

Epoch: 5| Step: 5
Training loss: 0.18708308877447521
Validation loss: 2.3754934643998085

Epoch: 5| Step: 6
Training loss: 0.3447310039461083
Validation loss: 2.392627230138846

Epoch: 5| Step: 7
Training loss: 0.16935651823503273
Validation loss: 2.351001774446111

Epoch: 5| Step: 8
Training loss: 0.3208192909974116
Validation loss: 2.368531732852143

Epoch: 5| Step: 9
Training loss: 0.3310389557197886
Validation loss: 2.380703253142448

Epoch: 5| Step: 10
Training loss: 0.39394781199822143
Validation loss: 2.366793692041221

Epoch: 487| Step: 0
Training loss: 0.34500824871775515
Validation loss: 2.356922376799708

Epoch: 5| Step: 1
Training loss: 0.33804039034035716
Validation loss: 2.3523452279752286

Epoch: 5| Step: 2
Training loss: 0.31876158319258174
Validation loss: 2.3367408805618166

Epoch: 5| Step: 3
Training loss: 0.2181572290646373
Validation loss: 2.347928410311544

Epoch: 5| Step: 4
Training loss: 0.32063814218070225
Validation loss: 2.3226857005471513

Epoch: 5| Step: 5
Training loss: 0.24706888763861234
Validation loss: 2.32875034027135

Epoch: 5| Step: 6
Training loss: 0.33562590320117547
Validation loss: 2.344843374646601

Epoch: 5| Step: 7
Training loss: 0.25051716123071954
Validation loss: 2.3565472653794863

Epoch: 5| Step: 8
Training loss: 0.22224084685843826
Validation loss: 2.336425235368605

Epoch: 5| Step: 9
Training loss: 0.22521581465469093
Validation loss: 2.327550029318947

Epoch: 5| Step: 10
Training loss: 0.11020764950856797
Validation loss: 2.3534540928717314

Epoch: 488| Step: 0
Training loss: 0.18573238736040057
Validation loss: 2.339997856311642

Epoch: 5| Step: 1
Training loss: 0.15213186861837621
Validation loss: 2.353846968681853

Epoch: 5| Step: 2
Training loss: 0.17085273131477868
Validation loss: 2.3752011439017395

Epoch: 5| Step: 3
Training loss: 0.27228578796598013
Validation loss: 2.350706875344711

Epoch: 5| Step: 4
Training loss: 0.34961806984430555
Validation loss: 2.3804838860658153

Epoch: 5| Step: 5
Training loss: 0.3092730445671414
Validation loss: 2.333093640399277

Epoch: 5| Step: 6
Training loss: 0.22583018534889768
Validation loss: 2.3182488747987664

Epoch: 5| Step: 7
Training loss: 0.2503993004591832
Validation loss: 2.336766588512643

Epoch: 5| Step: 8
Training loss: 0.35346237329507135
Validation loss: 2.3262891097127336

Epoch: 5| Step: 9
Training loss: 0.17707217171965964
Validation loss: 2.335004811210056

Epoch: 5| Step: 10
Training loss: 0.42490668113772473
Validation loss: 2.33074384886246

Epoch: 489| Step: 0
Training loss: 0.3639715670534505
Validation loss: 2.3059781006034483

Epoch: 5| Step: 1
Training loss: 0.1609422076564498
Validation loss: 2.312229465489706

Epoch: 5| Step: 2
Training loss: 0.29107985331791
Validation loss: 2.30917850207747

Epoch: 5| Step: 3
Training loss: 0.2781489061946781
Validation loss: 2.3594490397679135

Epoch: 5| Step: 4
Training loss: 0.18814270810654002
Validation loss: 2.349352317056116

Epoch: 5| Step: 5
Training loss: 0.3817020386368835
Validation loss: 2.3186454077810468

Epoch: 5| Step: 6
Training loss: 0.2860999755765364
Validation loss: 2.3508720459506844

Epoch: 5| Step: 7
Training loss: 0.1439717973647832
Validation loss: 2.3400456480449185

Epoch: 5| Step: 8
Training loss: 0.3068003511826881
Validation loss: 2.323445393541964

Epoch: 5| Step: 9
Training loss: 0.3474156908291655
Validation loss: 2.3377284653579724

Epoch: 5| Step: 10
Training loss: 0.15915126195686508
Validation loss: 2.32174035922724

Epoch: 490| Step: 0
Training loss: 0.25963011053562624
Validation loss: 2.327639519037666

Epoch: 5| Step: 1
Training loss: 0.24783993897413747
Validation loss: 2.3121298671418784

Epoch: 5| Step: 2
Training loss: 0.17505745753428456
Validation loss: 2.3287529091393044

Epoch: 5| Step: 3
Training loss: 0.3209247436699821
Validation loss: 2.3485158051376405

Epoch: 5| Step: 4
Training loss: 0.16428974285780304
Validation loss: 2.309616812470924

Epoch: 5| Step: 5
Training loss: 0.43355692457925765
Validation loss: 2.311006250379203

Epoch: 5| Step: 6
Training loss: 0.2898790194087579
Validation loss: 2.330364877804142

Epoch: 5| Step: 7
Training loss: 0.34253044971100766
Validation loss: 2.3534726176014877

Epoch: 5| Step: 8
Training loss: 0.1758942135128535
Validation loss: 2.3830604740234373

Epoch: 5| Step: 9
Training loss: 0.26043694735075446
Validation loss: 2.3719841710569454

Epoch: 5| Step: 10
Training loss: 0.34932094802442015
Validation loss: 2.366109195154965

Epoch: 491| Step: 0
Training loss: 0.38339399431387294
Validation loss: 2.389618931802599

Epoch: 5| Step: 1
Training loss: 0.23687046653113314
Validation loss: 2.374364626510891

Epoch: 5| Step: 2
Training loss: 0.3304456323965321
Validation loss: 2.3858068325953274

Epoch: 5| Step: 3
Training loss: 0.16215589154671223
Validation loss: 2.3955251077250588

Epoch: 5| Step: 4
Training loss: 0.3363003545410154
Validation loss: 2.395316922111125

Epoch: 5| Step: 5
Training loss: 0.16731608361569847
Validation loss: 2.360620689873489

Epoch: 5| Step: 6
Training loss: 0.2338491660534293
Validation loss: 2.338390994928325

Epoch: 5| Step: 7
Training loss: 0.3144375696540441
Validation loss: 2.3560524483261585

Epoch: 5| Step: 8
Training loss: 0.27860648183351094
Validation loss: 2.3485839533034985

Epoch: 5| Step: 9
Training loss: 0.3568447018002742
Validation loss: 2.3551549801658505

Epoch: 5| Step: 10
Training loss: 0.24966352141139905
Validation loss: 2.3286858264645502

Epoch: 492| Step: 0
Training loss: 0.12550533490506305
Validation loss: 2.3405495872086477

Epoch: 5| Step: 1
Training loss: 0.3418531426027667
Validation loss: 2.3203596917765097

Epoch: 5| Step: 2
Training loss: 0.24948871006295906
Validation loss: 2.3401064865182493

Epoch: 5| Step: 3
Training loss: 0.3787115717740426
Validation loss: 2.313841379452785

Epoch: 5| Step: 4
Training loss: 0.16751165071933538
Validation loss: 2.315260914379641

Epoch: 5| Step: 5
Training loss: 0.21885914293653938
Validation loss: 2.31557897846094

Epoch: 5| Step: 6
Training loss: 0.31838792544166483
Validation loss: 2.3092777225992247

Epoch: 5| Step: 7
Training loss: 0.3731191275564213
Validation loss: 2.3298795576767093

Epoch: 5| Step: 8
Training loss: 0.23886169028019405
Validation loss: 2.308359718401483

Epoch: 5| Step: 9
Training loss: 0.24130446439364622
Validation loss: 2.3471019055519524

Epoch: 5| Step: 10
Training loss: 0.2753431265701304
Validation loss: 2.360798199042176

Epoch: 493| Step: 0
Training loss: 0.1396614415443017
Validation loss: 2.340455795913206

Epoch: 5| Step: 1
Training loss: 0.2226940675040578
Validation loss: 2.3682037828533464

Epoch: 5| Step: 2
Training loss: 0.2155522023199754
Validation loss: 2.338134889934665

Epoch: 5| Step: 3
Training loss: 0.27743010452598815
Validation loss: 2.3334750258439056

Epoch: 5| Step: 4
Training loss: 0.3088828073037449
Validation loss: 2.33389995949353

Epoch: 5| Step: 5
Training loss: 0.24247334900388434
Validation loss: 2.3378333136121023

Epoch: 5| Step: 6
Training loss: 0.25469241576336155
Validation loss: 2.3102010570197202

Epoch: 5| Step: 7
Training loss: 0.32388319322638354
Validation loss: 2.284420626831789

Epoch: 5| Step: 8
Training loss: 0.34604847355684926
Validation loss: 2.3092259691279176

Epoch: 5| Step: 9
Training loss: 0.4165294143003243
Validation loss: 2.3266733569787017

Epoch: 5| Step: 10
Training loss: 0.31810961328255183
Validation loss: 2.3137822796281697

Epoch: 494| Step: 0
Training loss: 0.16317295562567494
Validation loss: 2.3322064832748857

Epoch: 5| Step: 1
Training loss: 0.23784307151770837
Validation loss: 2.3184091652993826

Epoch: 5| Step: 2
Training loss: 0.33302779151743667
Validation loss: 2.3424442583557483

Epoch: 5| Step: 3
Training loss: 0.2705115170001376
Validation loss: 2.329072976061088

Epoch: 5| Step: 4
Training loss: 0.22826609069653467
Validation loss: 2.3297566308635393

Epoch: 5| Step: 5
Training loss: 0.21958740914330369
Validation loss: 2.3532203763824797

Epoch: 5| Step: 6
Training loss: 0.20853022668965573
Validation loss: 2.38643015311703

Epoch: 5| Step: 7
Training loss: 0.21881007323326307
Validation loss: 2.3924158262513826

Epoch: 5| Step: 8
Training loss: 0.4135571941308054
Validation loss: 2.3867873019912857

Epoch: 5| Step: 9
Training loss: 0.3514519199667313
Validation loss: 2.365937698397645

Epoch: 5| Step: 10
Training loss: 0.22579447697633226
Validation loss: 2.35826901479642

Epoch: 495| Step: 0
Training loss: 0.18502310057702298
Validation loss: 2.3243223083649167

Epoch: 5| Step: 1
Training loss: 0.4221048964948228
Validation loss: 2.34856713544496

Epoch: 5| Step: 2
Training loss: 0.11420317916827079
Validation loss: 2.3218111134890362

Epoch: 5| Step: 3
Training loss: 0.4244762159217671
Validation loss: 2.3621720992292308

Epoch: 5| Step: 4
Training loss: 0.27473608650525305
Validation loss: 2.335045771375826

Epoch: 5| Step: 5
Training loss: 0.2301082944276706
Validation loss: 2.299762203974675

Epoch: 5| Step: 6
Training loss: 0.29197095710861704
Validation loss: 2.3384634138640696

Epoch: 5| Step: 7
Training loss: 0.15263387368663098
Validation loss: 2.349694903075598

Epoch: 5| Step: 8
Training loss: 0.3345620697128462
Validation loss: 2.3257807780517092

Epoch: 5| Step: 9
Training loss: 0.15906161627495874
Validation loss: 2.344601000446291

Epoch: 5| Step: 10
Training loss: 0.12131761807538649
Validation loss: 2.3686598220306583

Epoch: 496| Step: 0
Training loss: 0.33869936522392524
Validation loss: 2.3725851046112045

Epoch: 5| Step: 1
Training loss: 0.29473571712566693
Validation loss: 2.3853111702306267

Epoch: 5| Step: 2
Training loss: 0.34345759613277005
Validation loss: 2.366967556151908

Epoch: 5| Step: 3
Training loss: 0.17281963570781594
Validation loss: 2.3565900502235517

Epoch: 5| Step: 4
Training loss: 0.2734526085085531
Validation loss: 2.369470378773218

Epoch: 5| Step: 5
Training loss: 0.2537292156727372
Validation loss: 2.361186536476562

Epoch: 5| Step: 6
Training loss: 0.23457685361408512
Validation loss: 2.3987513345500933

Epoch: 5| Step: 7
Training loss: 0.25050461029904125
Validation loss: 2.3615512645946217

Epoch: 5| Step: 8
Training loss: 0.3132788964846671
Validation loss: 2.359088395956203

Epoch: 5| Step: 9
Training loss: 0.13269082273760208
Validation loss: 2.3717979905357387

Epoch: 5| Step: 10
Training loss: 0.21164107428608994
Validation loss: 2.3736114728317266

Epoch: 497| Step: 0
Training loss: 0.3776946606119014
Validation loss: 2.3504633453918427

Epoch: 5| Step: 1
Training loss: 0.33224724868341354
Validation loss: 2.3592304526914374

Epoch: 5| Step: 2
Training loss: 0.268525361280533
Validation loss: 2.369896941138167

Epoch: 5| Step: 3
Training loss: 0.27119225627915683
Validation loss: 2.3725016676035064

Epoch: 5| Step: 4
Training loss: 0.20615515587287808
Validation loss: 2.3262802471697346

Epoch: 5| Step: 5
Training loss: 0.3342234999152846
Validation loss: 2.340896696305099

Epoch: 5| Step: 6
Training loss: 0.1397531090447704
Validation loss: 2.3843681734782165

Epoch: 5| Step: 7
Training loss: 0.0895880813874373
Validation loss: 2.3703722039312867

Epoch: 5| Step: 8
Training loss: 0.2760205740637469
Validation loss: 2.3837578140847318

Epoch: 5| Step: 9
Training loss: 0.1852601395655774
Validation loss: 2.367113892350215

Epoch: 5| Step: 10
Training loss: 0.2790581943782129
Validation loss: 2.375027948375907

Epoch: 498| Step: 0
Training loss: 0.15697034845747712
Validation loss: 2.329551158103421

Epoch: 5| Step: 1
Training loss: 0.21492301172408607
Validation loss: 2.381174128851963

Epoch: 5| Step: 2
Training loss: 0.42539943409215375
Validation loss: 2.3679058931943486

Epoch: 5| Step: 3
Training loss: 0.2809642293602656
Validation loss: 2.348265070805341

Epoch: 5| Step: 4
Training loss: 0.3620387744080473
Validation loss: 2.3881808129273905

Epoch: 5| Step: 5
Training loss: 0.21838704720332777
Validation loss: 2.3638208545982904

Epoch: 5| Step: 6
Training loss: 0.15171107329719005
Validation loss: 2.35628652909074

Epoch: 5| Step: 7
Training loss: 0.18877662728239364
Validation loss: 2.354162102565176

Epoch: 5| Step: 8
Training loss: 0.3434126889583868
Validation loss: 2.3333944696849316

Epoch: 5| Step: 9
Training loss: 0.15547647936215772
Validation loss: 2.338768985521035

Epoch: 5| Step: 10
Training loss: 0.20012317381197756
Validation loss: 2.339871117435593

Epoch: 499| Step: 0
Training loss: 0.26196664485747667
Validation loss: 2.33842858876724

Epoch: 5| Step: 1
Training loss: 0.2958865021668537
Validation loss: 2.3099766494333616

Epoch: 5| Step: 2
Training loss: 0.18585153964869677
Validation loss: 2.318676802871807

Epoch: 5| Step: 3
Training loss: 0.16481913635937973
Validation loss: 2.3271198402884576

Epoch: 5| Step: 4
Training loss: 0.28844393453312533
Validation loss: 2.274793069563568

Epoch: 5| Step: 5
Training loss: 0.14564136162514188
Validation loss: 2.2839407746154046

Epoch: 5| Step: 6
Training loss: 0.3179317480953907
Validation loss: 2.3235360828978235

Epoch: 5| Step: 7
Training loss: 0.2605254883689026
Validation loss: 2.293616965864929

Epoch: 5| Step: 8
Training loss: 0.2734875769400217
Validation loss: 2.3256403555136593

Epoch: 5| Step: 9
Training loss: 0.22733868629348247
Validation loss: 2.3429963341909676

Epoch: 5| Step: 10
Training loss: 0.35696882708072036
Validation loss: 2.3610269649341555

Epoch: 500| Step: 0
Training loss: 0.19587723150363695
Validation loss: 2.3616616931988865

Epoch: 5| Step: 1
Training loss: 0.21470403463222176
Validation loss: 2.386517432799282

Epoch: 5| Step: 2
Training loss: 0.28490446026495053
Validation loss: 2.3700629680204535

Epoch: 5| Step: 3
Training loss: 0.30877227689323533
Validation loss: 2.333237767643038

Epoch: 5| Step: 4
Training loss: 0.3573407982761453
Validation loss: 2.3563930326728233

Epoch: 5| Step: 5
Training loss: 0.1376043113685596
Validation loss: 2.3400494594656553

Epoch: 5| Step: 6
Training loss: 0.29734342411682907
Validation loss: 2.3292100460047163

Epoch: 5| Step: 7
Training loss: 0.18442131769977937
Validation loss: 2.3688619923706606

Epoch: 5| Step: 8
Training loss: 0.37482980998786086
Validation loss: 2.3753836440113854

Epoch: 5| Step: 9
Training loss: 0.27345867075025726
Validation loss: 2.337236161471857

Epoch: 5| Step: 10
Training loss: 0.15189603895292839
Validation loss: 2.3506989511562684

Testing loss: 2.54864743998243
