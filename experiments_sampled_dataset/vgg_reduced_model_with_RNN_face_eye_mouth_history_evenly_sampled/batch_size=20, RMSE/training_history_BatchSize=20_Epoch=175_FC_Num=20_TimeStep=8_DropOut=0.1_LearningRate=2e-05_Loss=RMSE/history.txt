Epoch: 1| Step: 0
Training loss: 5.980616731513383
Validation loss: 5.7949509243091

Epoch: 5| Step: 1
Training loss: 5.79103637485743
Validation loss: 5.774917745144256

Epoch: 5| Step: 2
Training loss: 5.052220020870254
Validation loss: 5.755865792271736

Epoch: 5| Step: 3
Training loss: 5.269542470683939
Validation loss: 5.73706142690221

Epoch: 5| Step: 4
Training loss: 5.5404607086867745
Validation loss: 5.718114867732

Epoch: 5| Step: 5
Training loss: 5.449298554523153
Validation loss: 5.6965340588106725

Epoch: 5| Step: 6
Training loss: 5.87136533595067
Validation loss: 5.671539547124168

Epoch: 5| Step: 7
Training loss: 5.816111765337263
Validation loss: 5.643412781280145

Epoch: 5| Step: 8
Training loss: 5.782781614578256
Validation loss: 5.611918861787109

Epoch: 5| Step: 9
Training loss: 6.193189990982377
Validation loss: 5.575503760519066

Epoch: 5| Step: 10
Training loss: 6.088548210495129
Validation loss: 5.535722575553145

Epoch: 2| Step: 0
Training loss: 5.13189047975892
Validation loss: 5.492138381505209

Epoch: 5| Step: 1
Training loss: 4.847998349570317
Validation loss: 5.446070352476115

Epoch: 5| Step: 2
Training loss: 5.7196927987147985
Validation loss: 5.398173637572847

Epoch: 5| Step: 3
Training loss: 5.155154025036555
Validation loss: 5.350026832308571

Epoch: 5| Step: 4
Training loss: 5.381829824013267
Validation loss: 5.299966572806845

Epoch: 5| Step: 5
Training loss: 5.807916618442222
Validation loss: 5.249270570615443

Epoch: 5| Step: 6
Training loss: 6.140101597346124
Validation loss: 5.196415162772835

Epoch: 5| Step: 7
Training loss: 4.706504849325932
Validation loss: 5.146696225185101

Epoch: 5| Step: 8
Training loss: 4.959662422259547
Validation loss: 5.102317535714756

Epoch: 5| Step: 9
Training loss: 4.5824487468311075
Validation loss: 5.060656940380316

Epoch: 5| Step: 10
Training loss: 5.73922914864907
Validation loss: 5.018125568865931

Epoch: 3| Step: 0
Training loss: 5.755487560098046
Validation loss: 4.974950779422841

Epoch: 5| Step: 1
Training loss: 4.915733938592415
Validation loss: 4.9221799246536255

Epoch: 5| Step: 2
Training loss: 4.5865542567325175
Validation loss: 4.852634832375358

Epoch: 5| Step: 3
Training loss: 4.367265895078456
Validation loss: 4.797238798576562

Epoch: 5| Step: 4
Training loss: 5.430701906140621
Validation loss: 4.758744347700302

Epoch: 5| Step: 5
Training loss: 4.854637265075926
Validation loss: 4.719732045312023

Epoch: 5| Step: 6
Training loss: 5.110314705670406
Validation loss: 4.678906916351665

Epoch: 5| Step: 7
Training loss: 4.287184785427311
Validation loss: 4.63693096576026

Epoch: 5| Step: 8
Training loss: 4.493706647003261
Validation loss: 4.596808804689539

Epoch: 5| Step: 9
Training loss: 4.767088618420474
Validation loss: 4.553347282882561

Epoch: 5| Step: 10
Training loss: 4.198419255286931
Validation loss: 4.512679954587694

Epoch: 4| Step: 0
Training loss: 5.020887234769128
Validation loss: 4.480462048607076

Epoch: 5| Step: 1
Training loss: 4.470272845106033
Validation loss: 4.448858008711397

Epoch: 5| Step: 2
Training loss: 4.455814446220847
Validation loss: 4.41723797369718

Epoch: 5| Step: 3
Training loss: 3.6113817325489808
Validation loss: 4.389684150152026

Epoch: 5| Step: 4
Training loss: 5.047976724936728
Validation loss: 4.368255120195571

Epoch: 5| Step: 5
Training loss: 4.179329715995138
Validation loss: 4.347968265849068

Epoch: 5| Step: 6
Training loss: 4.556457698991105
Validation loss: 4.319596424894941

Epoch: 5| Step: 7
Training loss: 4.280254164662576
Validation loss: 4.279763453707897

Epoch: 5| Step: 8
Training loss: 3.783745816861409
Validation loss: 4.233721520071093

Epoch: 5| Step: 9
Training loss: 4.962714794516593
Validation loss: 4.174631927605901

Epoch: 5| Step: 10
Training loss: 4.2919538580839705
Validation loss: 4.145493219137514

Epoch: 5| Step: 0
Training loss: 4.011331006471723
Validation loss: 4.118881097369998

Epoch: 5| Step: 1
Training loss: 4.446924008000876
Validation loss: 4.09404985684993

Epoch: 5| Step: 2
Training loss: 4.905671103760573
Validation loss: 4.077544386669718

Epoch: 5| Step: 3
Training loss: 4.1124080009953285
Validation loss: 4.073756429920671

Epoch: 5| Step: 4
Training loss: 3.354122722329968
Validation loss: 4.043246050810513

Epoch: 5| Step: 5
Training loss: 5.374550024315262
Validation loss: 4.025619042527099

Epoch: 5| Step: 6
Training loss: 3.50272508528307
Validation loss: 4.00346718770615

Epoch: 5| Step: 7
Training loss: 3.4652742034615067
Validation loss: 3.9837132843232648

Epoch: 5| Step: 8
Training loss: 4.84220792772847
Validation loss: 3.9689521935062424

Epoch: 5| Step: 9
Training loss: 3.840576102036285
Validation loss: 3.948346347442397

Epoch: 5| Step: 10
Training loss: 3.4597876987483143
Validation loss: 3.931730233104293

Epoch: 6| Step: 0
Training loss: 3.8739344454660762
Validation loss: 3.917849003342886

Epoch: 5| Step: 1
Training loss: 3.9026514185989982
Validation loss: 3.9033387444592464

Epoch: 5| Step: 2
Training loss: 3.7777652288365595
Validation loss: 3.8936167231431518

Epoch: 5| Step: 3
Training loss: 4.309760730235483
Validation loss: 3.8855753831590745

Epoch: 5| Step: 4
Training loss: 3.536925219961072
Validation loss: 3.8701984827272327

Epoch: 5| Step: 5
Training loss: 4.117863348080749
Validation loss: 3.858691933542461

Epoch: 5| Step: 6
Training loss: 3.754486705984593
Validation loss: 3.8431126502745054

Epoch: 5| Step: 7
Training loss: 3.2294484825625998
Validation loss: 3.8367220656429617

Epoch: 5| Step: 8
Training loss: 3.955592293931844
Validation loss: 3.8258163150506026

Epoch: 5| Step: 9
Training loss: 4.182963404820718
Validation loss: 3.8148726596943003

Epoch: 5| Step: 10
Training loss: 5.483593485650549
Validation loss: 3.8047799268923237

Epoch: 7| Step: 0
Training loss: 3.7492526263300103
Validation loss: 3.7934741179499407

Epoch: 5| Step: 1
Training loss: 3.530843795774071
Validation loss: 3.78184295130033

Epoch: 5| Step: 2
Training loss: 3.642293523147832
Validation loss: 3.7765954867157516

Epoch: 5| Step: 3
Training loss: 4.031587098687285
Validation loss: 3.763040809082986

Epoch: 5| Step: 4
Training loss: 4.086147558235726
Validation loss: 3.7509297739364658

Epoch: 5| Step: 5
Training loss: 3.9536101152902754
Validation loss: 3.7462229558586277

Epoch: 5| Step: 6
Training loss: 3.9956370639962002
Validation loss: 3.7410371735186776

Epoch: 5| Step: 7
Training loss: 3.7656936322680967
Validation loss: 3.7240535123562766

Epoch: 5| Step: 8
Training loss: 4.381064217583311
Validation loss: 3.7219371214044754

Epoch: 5| Step: 9
Training loss: 3.772680866210913
Validation loss: 3.7045601875715857

Epoch: 5| Step: 10
Training loss: 4.241288400707223
Validation loss: 3.700987258052697

Epoch: 8| Step: 0
Training loss: 3.2291971676934432
Validation loss: 3.6958653714721943

Epoch: 5| Step: 1
Training loss: 4.17483038643406
Validation loss: 3.6811246172889227

Epoch: 5| Step: 2
Training loss: 4.019120057244607
Validation loss: 3.672215478279962

Epoch: 5| Step: 3
Training loss: 3.3948221553913305
Validation loss: 3.66614103371825

Epoch: 5| Step: 4
Training loss: 3.602432642352663
Validation loss: 3.6594046295304006

Epoch: 5| Step: 5
Training loss: 3.6410873185028003
Validation loss: 3.6521185485644425

Epoch: 5| Step: 6
Training loss: 4.432644834093944
Validation loss: 3.6449548129869727

Epoch: 5| Step: 7
Training loss: 3.2052389473001153
Validation loss: 3.631907078221044

Epoch: 5| Step: 8
Training loss: 4.8533144135857444
Validation loss: 3.622645121353918

Epoch: 5| Step: 9
Training loss: 3.446339564441179
Validation loss: 3.6167844178631148

Epoch: 5| Step: 10
Training loss: 3.9324162680314156
Validation loss: 3.6155607802645475

Epoch: 9| Step: 0
Training loss: 4.270475989798252
Validation loss: 3.6055668412111825

Epoch: 5| Step: 1
Training loss: 3.451715518293197
Validation loss: 3.5933234619285694

Epoch: 5| Step: 2
Training loss: 4.048714827090028
Validation loss: 3.5883417339784924

Epoch: 5| Step: 3
Training loss: 3.207416915471595
Validation loss: 3.5880573328717142

Epoch: 5| Step: 4
Training loss: 3.541168058115897
Validation loss: 3.582415762083113

Epoch: 5| Step: 5
Training loss: 4.153063707207961
Validation loss: 3.5699385174750646

Epoch: 5| Step: 6
Training loss: 3.2484535059091906
Validation loss: 3.564391419352384

Epoch: 5| Step: 7
Training loss: 4.173225784215961
Validation loss: 3.560716966848071

Epoch: 5| Step: 8
Training loss: 3.865633935694439
Validation loss: 3.5575774790000363

Epoch: 5| Step: 9
Training loss: 3.889260661807511
Validation loss: 3.545275747341653

Epoch: 5| Step: 10
Training loss: 3.4117543953513447
Validation loss: 3.5361670533408893

Epoch: 10| Step: 0
Training loss: 3.6067378991708603
Validation loss: 3.5314726081019483

Epoch: 5| Step: 1
Training loss: 3.2900057276064287
Validation loss: 3.5274092724802673

Epoch: 5| Step: 2
Training loss: 3.476962565859346
Validation loss: 3.5208861906556295

Epoch: 5| Step: 3
Training loss: 3.541093323618386
Validation loss: 3.5193838339683126

Epoch: 5| Step: 4
Training loss: 3.494092315118103
Validation loss: 3.5047661255333247

Epoch: 5| Step: 5
Training loss: 3.4111979533216195
Validation loss: 3.5045450558166995

Epoch: 5| Step: 6
Training loss: 4.457490621525884
Validation loss: 3.5048330941423385

Epoch: 5| Step: 7
Training loss: 4.003861708974815
Validation loss: 3.4926757911590642

Epoch: 5| Step: 8
Training loss: 3.1966955647307636
Validation loss: 3.4977968462942823

Epoch: 5| Step: 9
Training loss: 4.363515985880332
Validation loss: 3.499997339672478

Epoch: 5| Step: 10
Training loss: 3.8509927138599145
Validation loss: 3.490431478859781

Epoch: 11| Step: 0
Training loss: 3.542736983788623
Validation loss: 3.4741960111417685

Epoch: 5| Step: 1
Training loss: 3.05847697808502
Validation loss: 3.466931789741918

Epoch: 5| Step: 2
Training loss: 3.6314152481376647
Validation loss: 3.476037043236887

Epoch: 5| Step: 3
Training loss: 4.0827951400977565
Validation loss: 3.459999564227299

Epoch: 5| Step: 4
Training loss: 3.9131114055432135
Validation loss: 3.4508668547339147

Epoch: 5| Step: 5
Training loss: 3.5600252088447157
Validation loss: 3.4430366086436384

Epoch: 5| Step: 6
Training loss: 3.031540532297466
Validation loss: 3.44082782711532

Epoch: 5| Step: 7
Training loss: 3.974926805122215
Validation loss: 3.438336302153865

Epoch: 5| Step: 8
Training loss: 4.324741183789233
Validation loss: 3.4335142414312303

Epoch: 5| Step: 9
Training loss: 3.4676109024497794
Validation loss: 3.425126517827143

Epoch: 5| Step: 10
Training loss: 3.525675602011983
Validation loss: 3.4161425703027706

Epoch: 12| Step: 0
Training loss: 4.0812158089530195
Validation loss: 3.4111671672311252

Epoch: 5| Step: 1
Training loss: 3.658326952906253
Validation loss: 3.4059403395302574

Epoch: 5| Step: 2
Training loss: 3.3339796552306225
Validation loss: 3.405331412038949

Epoch: 5| Step: 3
Training loss: 3.6411300112450067
Validation loss: 3.401128550376709

Epoch: 5| Step: 4
Training loss: 3.246644415207996
Validation loss: 3.401525747569889

Epoch: 5| Step: 5
Training loss: 3.490051298884825
Validation loss: 3.393676512750541

Epoch: 5| Step: 6
Training loss: 3.6287078310427927
Validation loss: 3.3847228191911563

Epoch: 5| Step: 7
Training loss: 4.012296610873619
Validation loss: 3.379070762087734

Epoch: 5| Step: 8
Training loss: 3.4814966741039512
Validation loss: 3.3730050088586787

Epoch: 5| Step: 9
Training loss: 3.3861879066922307
Validation loss: 3.371411891358089

Epoch: 5| Step: 10
Training loss: 3.77564612410644
Validation loss: 3.3669323252186047

Epoch: 13| Step: 0
Training loss: 3.51795061967902
Validation loss: 3.368661349369403

Epoch: 5| Step: 1
Training loss: 3.122677664913591
Validation loss: 3.359926823754551

Epoch: 5| Step: 2
Training loss: 3.449992696781998
Validation loss: 3.359460011632612

Epoch: 5| Step: 3
Training loss: 4.257033642568492
Validation loss: 3.356484456834019

Epoch: 5| Step: 4
Training loss: 3.188082473492191
Validation loss: 3.352136698666634

Epoch: 5| Step: 5
Training loss: 3.7208824134542895
Validation loss: 3.352148099958716

Epoch: 5| Step: 6
Training loss: 3.4782749030617937
Validation loss: 3.351261880303578

Epoch: 5| Step: 7
Training loss: 3.7805434898939456
Validation loss: 3.350684755905579

Epoch: 5| Step: 8
Training loss: 4.247717300433763
Validation loss: 3.344738925677155

Epoch: 5| Step: 9
Training loss: 3.649376301191111
Validation loss: 3.335803395484281

Epoch: 5| Step: 10
Training loss: 2.579502916577312
Validation loss: 3.331477512045436

Epoch: 14| Step: 0
Training loss: 3.5955502189022406
Validation loss: 3.332615840252981

Epoch: 5| Step: 1
Training loss: 4.251026478392615
Validation loss: 3.327703304131827

Epoch: 5| Step: 2
Training loss: 3.0037922732156237
Validation loss: 3.318797790814817

Epoch: 5| Step: 3
Training loss: 3.732269459661111
Validation loss: 3.318331405022599

Epoch: 5| Step: 4
Training loss: 3.16388466417676
Validation loss: 3.3211283915388714

Epoch: 5| Step: 5
Training loss: 3.743796367071551
Validation loss: 3.3107819454160885

Epoch: 5| Step: 6
Training loss: 3.510878550463681
Validation loss: 3.3096383740640767

Epoch: 5| Step: 7
Training loss: 3.1362833407330046
Validation loss: 3.309636329123632

Epoch: 5| Step: 8
Training loss: 3.4569482136037397
Validation loss: 3.3076139461483614

Epoch: 5| Step: 9
Training loss: 3.5703484264210634
Validation loss: 3.3066215820105285

Epoch: 5| Step: 10
Training loss: 3.841520081300393
Validation loss: 3.3006452572821665

Epoch: 15| Step: 0
Training loss: 3.281350997097065
Validation loss: 3.293327422462006

Epoch: 5| Step: 1
Training loss: 3.723673278284582
Validation loss: 3.2945928971705594

Epoch: 5| Step: 2
Training loss: 3.460146570353643
Validation loss: 3.296146617373519

Epoch: 5| Step: 3
Training loss: 2.9684878584922028
Validation loss: 3.288017774426929

Epoch: 5| Step: 4
Training loss: 4.074792896460856
Validation loss: 3.2806585002398543

Epoch: 5| Step: 5
Training loss: 4.078355570738892
Validation loss: 3.2740870518612963

Epoch: 5| Step: 6
Training loss: 3.861942317664237
Validation loss: 3.271043686966987

Epoch: 5| Step: 7
Training loss: 2.8397478719737417
Validation loss: 3.2712696229391116

Epoch: 5| Step: 8
Training loss: 3.4689069832685533
Validation loss: 3.274717406068521

Epoch: 5| Step: 9
Training loss: 3.2944449920253573
Validation loss: 3.2668100216567377

Epoch: 5| Step: 10
Training loss: 3.50024985375277
Validation loss: 3.2656672316462765

Epoch: 16| Step: 0
Training loss: 3.5172188769736863
Validation loss: 3.259359412744509

Epoch: 5| Step: 1
Training loss: 3.5430318706908293
Validation loss: 3.2565341480570282

Epoch: 5| Step: 2
Training loss: 3.6868602391678396
Validation loss: 3.250666711668431

Epoch: 5| Step: 3
Training loss: 3.724737908276442
Validation loss: 3.2495947443967377

Epoch: 5| Step: 4
Training loss: 4.116707529542154
Validation loss: 3.251550949618686

Epoch: 5| Step: 5
Training loss: 3.284134242038008
Validation loss: 3.2479852121700383

Epoch: 5| Step: 6
Training loss: 3.0504206445511106
Validation loss: 3.24753842398198

Epoch: 5| Step: 7
Training loss: 3.01835453452197
Validation loss: 3.2532075462386256

Epoch: 5| Step: 8
Training loss: 3.1620445315502494
Validation loss: 3.256389732276534

Epoch: 5| Step: 9
Training loss: 3.4633616618177947
Validation loss: 3.239213788204524

Epoch: 5| Step: 10
Training loss: 3.837932619442639
Validation loss: 3.2443224914156343

Epoch: 17| Step: 0
Training loss: 3.0787939903471226
Validation loss: 3.2482609904107385

Epoch: 5| Step: 1
Training loss: 3.615592192795262
Validation loss: 3.2535416463656137

Epoch: 5| Step: 2
Training loss: 3.390491676346227
Validation loss: 3.2446708150385004

Epoch: 5| Step: 3
Training loss: 3.681857301523477
Validation loss: 3.239122377274756

Epoch: 5| Step: 4
Training loss: 3.52398136111471
Validation loss: 3.2347547805430614

Epoch: 5| Step: 5
Training loss: 3.6050224978608676
Validation loss: 3.2316181167634577

Epoch: 5| Step: 6
Training loss: 3.147287920896187
Validation loss: 3.2280471930723267

Epoch: 5| Step: 7
Training loss: 3.053297892646611
Validation loss: 3.2263941447909654

Epoch: 5| Step: 8
Training loss: 3.9237343077696725
Validation loss: 3.2277119368996874

Epoch: 5| Step: 9
Training loss: 3.268180905577228
Validation loss: 3.2300815982424

Epoch: 5| Step: 10
Training loss: 4.040567674694865
Validation loss: 3.231635145682996

Epoch: 18| Step: 0
Training loss: 3.327735555724494
Validation loss: 3.216125090187871

Epoch: 5| Step: 1
Training loss: 3.714705375396678
Validation loss: 3.222221612193562

Epoch: 5| Step: 2
Training loss: 3.0425691354461817
Validation loss: 3.2263452123581247

Epoch: 5| Step: 3
Training loss: 3.3266389063082675
Validation loss: 3.2353405594378257

Epoch: 5| Step: 4
Training loss: 4.057771013743332
Validation loss: 3.2277634688342447

Epoch: 5| Step: 5
Training loss: 3.1587045020331597
Validation loss: 3.21582849172549

Epoch: 5| Step: 6
Training loss: 3.467699871394768
Validation loss: 3.210579965425187

Epoch: 5| Step: 7
Training loss: 3.8898966770130174
Validation loss: 3.208610638280746

Epoch: 5| Step: 8
Training loss: 3.0329978072614128
Validation loss: 3.2082511998948693

Epoch: 5| Step: 9
Training loss: 3.1535894681312437
Validation loss: 3.2152210917691377

Epoch: 5| Step: 10
Training loss: 3.9552113451714743
Validation loss: 3.2120303324310506

Epoch: 19| Step: 0
Training loss: 4.1147437470790305
Validation loss: 3.208816329489277

Epoch: 5| Step: 1
Training loss: 3.4126138297857724
Validation loss: 3.2018129876658774

Epoch: 5| Step: 2
Training loss: 3.7191352965199855
Validation loss: 3.1978300376211544

Epoch: 5| Step: 3
Training loss: 2.512046590858935
Validation loss: 3.1956043921926693

Epoch: 5| Step: 4
Training loss: 3.508511412050873
Validation loss: 3.1927510551944427

Epoch: 5| Step: 5
Training loss: 3.4472765525234026
Validation loss: 3.1933814038568062

Epoch: 5| Step: 6
Training loss: 3.6632162389764784
Validation loss: 3.191279667479098

Epoch: 5| Step: 7
Training loss: 2.819796020895268
Validation loss: 3.1897723715711352

Epoch: 5| Step: 8
Training loss: 3.439372159751178
Validation loss: 3.190084748936268

Epoch: 5| Step: 9
Training loss: 3.2057842845914473
Validation loss: 3.186992275072311

Epoch: 5| Step: 10
Training loss: 3.9482080088722835
Validation loss: 3.186613100650041

Epoch: 20| Step: 0
Training loss: 3.6057205525560354
Validation loss: 3.183701863212463

Epoch: 5| Step: 1
Training loss: 3.4545312840111775
Validation loss: 3.1803370353518914

Epoch: 5| Step: 2
Training loss: 2.8690934251988955
Validation loss: 3.1808282267760957

Epoch: 5| Step: 3
Training loss: 2.946095977110667
Validation loss: 3.1780964436193275

Epoch: 5| Step: 4
Training loss: 3.455332883043485
Validation loss: 3.1781621663021937

Epoch: 5| Step: 5
Training loss: 3.7148061403442516
Validation loss: 3.1749765211313874

Epoch: 5| Step: 6
Training loss: 3.6796920355183698
Validation loss: 3.173120022849216

Epoch: 5| Step: 7
Training loss: 3.8242271041389215
Validation loss: 3.173044495575004

Epoch: 5| Step: 8
Training loss: 3.338401724054041
Validation loss: 3.171622488875006

Epoch: 5| Step: 9
Training loss: 3.1117636548785708
Validation loss: 3.169332889799322

Epoch: 5| Step: 10
Training loss: 3.7591086073659348
Validation loss: 3.175232297037676

Epoch: 21| Step: 0
Training loss: 3.5312872690580313
Validation loss: 3.178215020305054

Epoch: 5| Step: 1
Training loss: 3.7133271243205
Validation loss: 3.170676948697145

Epoch: 5| Step: 2
Training loss: 4.141172207355854
Validation loss: 3.1629015973532626

Epoch: 5| Step: 3
Training loss: 2.7426813012478943
Validation loss: 3.1619037490706354

Epoch: 5| Step: 4
Training loss: 3.0324276868181457
Validation loss: 3.1605178080820746

Epoch: 5| Step: 5
Training loss: 3.618616468637527
Validation loss: 3.1576996021509305

Epoch: 5| Step: 6
Training loss: 3.5244114918856653
Validation loss: 3.1582023554701366

Epoch: 5| Step: 7
Training loss: 3.099507686530999
Validation loss: 3.1558054656957735

Epoch: 5| Step: 8
Training loss: 3.2738651551643385
Validation loss: 3.1546597043672087

Epoch: 5| Step: 9
Training loss: 3.308752711417107
Validation loss: 3.1561461254609138

Epoch: 5| Step: 10
Training loss: 3.5366690586476293
Validation loss: 3.1536543456079613

Epoch: 22| Step: 0
Training loss: 4.0593761464646665
Validation loss: 3.1523630694858005

Epoch: 5| Step: 1
Training loss: 3.58841275821944
Validation loss: 3.1506234181861568

Epoch: 5| Step: 2
Training loss: 3.3683066223182716
Validation loss: 3.1499886923224203

Epoch: 5| Step: 3
Training loss: 3.286295327055001
Validation loss: 3.1483264837262865

Epoch: 5| Step: 4
Training loss: 3.7524188823433473
Validation loss: 3.1510997702111987

Epoch: 5| Step: 5
Training loss: 2.936407007637387
Validation loss: 3.1466285766882773

Epoch: 5| Step: 6
Training loss: 3.152084472279533
Validation loss: 3.1551482946973675

Epoch: 5| Step: 7
Training loss: 3.6786545520549345
Validation loss: 3.1888785971122364

Epoch: 5| Step: 8
Training loss: 3.3090590833206255
Validation loss: 3.1664446060437337

Epoch: 5| Step: 9
Training loss: 2.4359117860152586
Validation loss: 3.140880680630158

Epoch: 5| Step: 10
Training loss: 3.866930650600703
Validation loss: 3.1472658088953436

Epoch: 23| Step: 0
Training loss: 3.48334655637528
Validation loss: 3.153597117772824

Epoch: 5| Step: 1
Training loss: 3.077571296268888
Validation loss: 3.149328759257522

Epoch: 5| Step: 2
Training loss: 3.0339222563387027
Validation loss: 3.142582009724158

Epoch: 5| Step: 3
Training loss: 3.522919678118092
Validation loss: 3.1426563651273134

Epoch: 5| Step: 4
Training loss: 3.7586762829355687
Validation loss: 3.143466810423986

Epoch: 5| Step: 5
Training loss: 3.745260040463268
Validation loss: 3.143924360207089

Epoch: 5| Step: 6
Training loss: 3.458160181574975
Validation loss: 3.1448401502504892

Epoch: 5| Step: 7
Training loss: 3.248987773840559
Validation loss: 3.147392014478303

Epoch: 5| Step: 8
Training loss: 3.1629371431408435
Validation loss: 3.147508462211973

Epoch: 5| Step: 9
Training loss: 3.4671376923141977
Validation loss: 3.1420056573392285

Epoch: 5| Step: 10
Training loss: 3.539766692108126
Validation loss: 3.139460237933173

Epoch: 24| Step: 0
Training loss: 4.031635827814823
Validation loss: 3.1425543091375667

Epoch: 5| Step: 1
Training loss: 3.475048086807928
Validation loss: 3.1372023696836053

Epoch: 5| Step: 2
Training loss: 3.0122611303320914
Validation loss: 3.1378682518090377

Epoch: 5| Step: 3
Training loss: 2.7841156330320156
Validation loss: 3.1625054100593784

Epoch: 5| Step: 4
Training loss: 3.0569335797113095
Validation loss: 3.176198148881006

Epoch: 5| Step: 5
Training loss: 2.495736683124183
Validation loss: 3.1385695963304405

Epoch: 5| Step: 6
Training loss: 3.3877411985217556
Validation loss: 3.1326572135356314

Epoch: 5| Step: 7
Training loss: 3.9335805368059487
Validation loss: 3.132305006062405

Epoch: 5| Step: 8
Training loss: 3.3296138674731828
Validation loss: 3.1302555936447556

Epoch: 5| Step: 9
Training loss: 3.5713207065097246
Validation loss: 3.131543520897273

Epoch: 5| Step: 10
Training loss: 4.060666418769999
Validation loss: 3.1349855932767023

Epoch: 25| Step: 0
Training loss: 2.926419727042456
Validation loss: 3.1431450481546723

Epoch: 5| Step: 1
Training loss: 3.0496922697320588
Validation loss: 3.1466311447041044

Epoch: 5| Step: 2
Training loss: 4.45889369021889
Validation loss: 3.154853047865673

Epoch: 5| Step: 3
Training loss: 3.5625256989204654
Validation loss: 3.123267126874111

Epoch: 5| Step: 4
Training loss: 3.547363919745727
Validation loss: 3.1367664464555305

Epoch: 5| Step: 5
Training loss: 2.986153596876454
Validation loss: 3.1536463563075117

Epoch: 5| Step: 6
Training loss: 3.13179147877315
Validation loss: 3.1722530525829025

Epoch: 5| Step: 7
Training loss: 3.366403156455268
Validation loss: 3.1419816927177515

Epoch: 5| Step: 8
Training loss: 3.0340563181488935
Validation loss: 3.1283255513914945

Epoch: 5| Step: 9
Training loss: 3.6381072805733665
Validation loss: 3.1201766151506036

Epoch: 5| Step: 10
Training loss: 3.5404652221936863
Validation loss: 3.1198472806182376

Epoch: 26| Step: 0
Training loss: 3.8386978814659143
Validation loss: 3.117062535550227

Epoch: 5| Step: 1
Training loss: 2.690551976576492
Validation loss: 3.1231417145266067

Epoch: 5| Step: 2
Training loss: 3.135562745469133
Validation loss: 3.135950592425871

Epoch: 5| Step: 3
Training loss: 4.052582828491863
Validation loss: 3.149848095372148

Epoch: 5| Step: 4
Training loss: 3.288464707078321
Validation loss: 3.1277959838439124

Epoch: 5| Step: 5
Training loss: 4.108858141286911
Validation loss: 3.1186392877555718

Epoch: 5| Step: 6
Training loss: 3.1632395486492437
Validation loss: 3.1130950114864837

Epoch: 5| Step: 7
Training loss: 3.0446993371513553
Validation loss: 3.109977719405485

Epoch: 5| Step: 8
Training loss: 3.1948217933875287
Validation loss: 3.1120959158033714

Epoch: 5| Step: 9
Training loss: 3.2322239011315257
Validation loss: 3.1129259558911575

Epoch: 5| Step: 10
Training loss: 3.1242868754196427
Validation loss: 3.113502991395639

Epoch: 27| Step: 0
Training loss: 3.084058590383136
Validation loss: 3.116552990212371

Epoch: 5| Step: 1
Training loss: 4.207653003252094
Validation loss: 3.133434771591298

Epoch: 5| Step: 2
Training loss: 3.5292378321967046
Validation loss: 3.111232142565045

Epoch: 5| Step: 3
Training loss: 3.2248169839663965
Validation loss: 3.107769955093021

Epoch: 5| Step: 4
Training loss: 2.8460670505541503
Validation loss: 3.107644453555688

Epoch: 5| Step: 5
Training loss: 3.0047299926101863
Validation loss: 3.1073300909397825

Epoch: 5| Step: 6
Training loss: 3.406478174249138
Validation loss: 3.107107820725362

Epoch: 5| Step: 7
Training loss: 3.4978901089418746
Validation loss: 3.09974026837353

Epoch: 5| Step: 8
Training loss: 3.238958823959586
Validation loss: 3.1007023720570897

Epoch: 5| Step: 9
Training loss: 3.544098695960854
Validation loss: 3.103765972335343

Epoch: 5| Step: 10
Training loss: 3.344761633027816
Validation loss: 3.1035020819781485

Epoch: 28| Step: 0
Training loss: 3.6153882950671963
Validation loss: 3.102626475975482

Epoch: 5| Step: 1
Training loss: 4.014557336559101
Validation loss: 3.0930295179644958

Epoch: 5| Step: 2
Training loss: 3.022931039269052
Validation loss: 3.0917129920328223

Epoch: 5| Step: 3
Training loss: 2.5738106434492263
Validation loss: 3.092497430254967

Epoch: 5| Step: 4
Training loss: 3.1510052303172738
Validation loss: 3.103312960038229

Epoch: 5| Step: 5
Training loss: 3.5238718919622936
Validation loss: 3.1018486251559865

Epoch: 5| Step: 6
Training loss: 3.4265639695191785
Validation loss: 3.102619781441352

Epoch: 5| Step: 7
Training loss: 2.7986298069567397
Validation loss: 3.0941023772488516

Epoch: 5| Step: 8
Training loss: 3.841166550747449
Validation loss: 3.096688266679568

Epoch: 5| Step: 9
Training loss: 2.939298038890541
Validation loss: 3.096195934982356

Epoch: 5| Step: 10
Training loss: 3.9692646804252654
Validation loss: 3.1346425308268273

Epoch: 29| Step: 0
Training loss: 2.8188274838102254
Validation loss: 3.093906705634526

Epoch: 5| Step: 1
Training loss: 3.18335888704226
Validation loss: 3.090215982044568

Epoch: 5| Step: 2
Training loss: 4.044584237175847
Validation loss: 3.089583054176884

Epoch: 5| Step: 3
Training loss: 3.6404925801175745
Validation loss: 3.0841236021898055

Epoch: 5| Step: 4
Training loss: 3.3427466197251747
Validation loss: 3.0824371344707093

Epoch: 5| Step: 5
Training loss: 3.4220898704477207
Validation loss: 3.087941582893048

Epoch: 5| Step: 6
Training loss: 3.3926812893604903
Validation loss: 3.0880884195122564

Epoch: 5| Step: 7
Training loss: 3.6252322944664903
Validation loss: 3.091219177932371

Epoch: 5| Step: 8
Training loss: 2.9878942700310325
Validation loss: 3.0876594886540345

Epoch: 5| Step: 9
Training loss: 3.1652181893059264
Validation loss: 3.0901675911456863

Epoch: 5| Step: 10
Training loss: 3.057007359938517
Validation loss: 3.0920099407550383

Epoch: 30| Step: 0
Training loss: 3.658741941348664
Validation loss: 3.0806358835816923

Epoch: 5| Step: 1
Training loss: 3.383731849263793
Validation loss: 3.077335559384932

Epoch: 5| Step: 2
Training loss: 3.5612185666486913
Validation loss: 3.0792054126616364

Epoch: 5| Step: 3
Training loss: 3.7245928599447047
Validation loss: 3.0884335403898526

Epoch: 5| Step: 4
Training loss: 2.6339600549621998
Validation loss: 3.0795970632657403

Epoch: 5| Step: 5
Training loss: 3.877413090630224
Validation loss: 3.07593511907064

Epoch: 5| Step: 6
Training loss: 2.92093859676505
Validation loss: 3.0731516307992566

Epoch: 5| Step: 7
Training loss: 2.8518969196026465
Validation loss: 3.0719535687983033

Epoch: 5| Step: 8
Training loss: 3.1196274923816056
Validation loss: 3.0746861286382328

Epoch: 5| Step: 9
Training loss: 2.7216914258470406
Validation loss: 3.0763389944897126

Epoch: 5| Step: 10
Training loss: 4.1517403595727975
Validation loss: 3.078514927686545

Epoch: 31| Step: 0
Training loss: 4.1202598849059315
Validation loss: 3.0737360147512516

Epoch: 5| Step: 1
Training loss: 2.7346503418847914
Validation loss: 3.070391719935533

Epoch: 5| Step: 2
Training loss: 3.0090243982027616
Validation loss: 3.0668914864548316

Epoch: 5| Step: 3
Training loss: 3.3634272775173035
Validation loss: 3.064869057907015

Epoch: 5| Step: 4
Training loss: 3.050684655060897
Validation loss: 3.0655676098380416

Epoch: 5| Step: 5
Training loss: 3.499034612213526
Validation loss: 3.0671672402691756

Epoch: 5| Step: 6
Training loss: 3.0867863127532145
Validation loss: 3.0665436234697445

Epoch: 5| Step: 7
Training loss: 3.596293204654311
Validation loss: 3.0636225792835177

Epoch: 5| Step: 8
Training loss: 3.2428679338231245
Validation loss: 3.06320365337586

Epoch: 5| Step: 9
Training loss: 3.100873356511052
Validation loss: 3.0618603297608065

Epoch: 5| Step: 10
Training loss: 3.780731922314541
Validation loss: 3.0590549351221092

Epoch: 32| Step: 0
Training loss: 3.4668521672527315
Validation loss: 3.061629527619194

Epoch: 5| Step: 1
Training loss: 2.5901007661401447
Validation loss: 3.0593743344568223

Epoch: 5| Step: 2
Training loss: 3.435609748616335
Validation loss: 3.060497974782246

Epoch: 5| Step: 3
Training loss: 3.7612867255809213
Validation loss: 3.059716796384847

Epoch: 5| Step: 4
Training loss: 3.3085211123224822
Validation loss: 3.056507119291038

Epoch: 5| Step: 5
Training loss: 3.5885683602206275
Validation loss: 3.0581960807631154

Epoch: 5| Step: 6
Training loss: 3.298817428472149
Validation loss: 3.0593551383541215

Epoch: 5| Step: 7
Training loss: 3.220608961441847
Validation loss: 3.059972946392705

Epoch: 5| Step: 8
Training loss: 3.820822090845128
Validation loss: 3.06158555412286

Epoch: 5| Step: 9
Training loss: 3.0031953325083927
Validation loss: 3.06764326558106

Epoch: 5| Step: 10
Training loss: 2.7829043150999557
Validation loss: 3.0607239171070018

Epoch: 33| Step: 0
Training loss: 3.5680934428992668
Validation loss: 3.0539995462669887

Epoch: 5| Step: 1
Training loss: 2.806957123497232
Validation loss: 3.0539191523142275

Epoch: 5| Step: 2
Training loss: 3.718136776924559
Validation loss: 3.0542318902705574

Epoch: 5| Step: 3
Training loss: 3.148140791549897
Validation loss: 3.0507183780908766

Epoch: 5| Step: 4
Training loss: 3.0102270962030975
Validation loss: 3.049365934297819

Epoch: 5| Step: 5
Training loss: 3.6647662237323373
Validation loss: 3.0462060101879893

Epoch: 5| Step: 6
Training loss: 3.751356769530817
Validation loss: 3.044610641132192

Epoch: 5| Step: 7
Training loss: 3.068168532217525
Validation loss: 3.0455005929342844

Epoch: 5| Step: 8
Training loss: 3.0828471101112505
Validation loss: 3.043702808735355

Epoch: 5| Step: 9
Training loss: 3.442207996447644
Validation loss: 3.0435838128947013

Epoch: 5| Step: 10
Training loss: 3.141710843316147
Validation loss: 3.043057084441958

Epoch: 34| Step: 0
Training loss: 3.6472858841443605
Validation loss: 3.045181208328658

Epoch: 5| Step: 1
Training loss: 3.502487797086207
Validation loss: 3.047174046651913

Epoch: 5| Step: 2
Training loss: 3.2849498416317005
Validation loss: 3.041604607106739

Epoch: 5| Step: 3
Training loss: 3.018706807524527
Validation loss: 3.0431241347484903

Epoch: 5| Step: 4
Training loss: 3.1521475540614663
Validation loss: 3.0401471773588646

Epoch: 5| Step: 5
Training loss: 3.6315581094157077
Validation loss: 3.042593602498249

Epoch: 5| Step: 6
Training loss: 3.1092967881377347
Validation loss: 3.04260029766321

Epoch: 5| Step: 7
Training loss: 3.478959874995487
Validation loss: 3.0431183455153126

Epoch: 5| Step: 8
Training loss: 3.369687880146607
Validation loss: 3.039361251705457

Epoch: 5| Step: 9
Training loss: 3.2233357770792845
Validation loss: 3.038216796480258

Epoch: 5| Step: 10
Training loss: 2.8619076711502203
Validation loss: 3.03825634418175

Epoch: 35| Step: 0
Training loss: 3.2994753449419627
Validation loss: 3.035982117023605

Epoch: 5| Step: 1
Training loss: 3.4472271709080444
Validation loss: 3.0356510048558967

Epoch: 5| Step: 2
Training loss: 3.202523523939632
Validation loss: 3.037579419274194

Epoch: 5| Step: 3
Training loss: 2.860420244459641
Validation loss: 3.0357660183178603

Epoch: 5| Step: 4
Training loss: 3.223350718259692
Validation loss: 3.031709252900349

Epoch: 5| Step: 5
Training loss: 2.8451598309235595
Validation loss: 3.0330943231040988

Epoch: 5| Step: 6
Training loss: 4.304216916485524
Validation loss: 3.0323723019000526

Epoch: 5| Step: 7
Training loss: 2.926978728211538
Validation loss: 3.0322083494439207

Epoch: 5| Step: 8
Training loss: 3.5067429303142656
Validation loss: 3.0333757354502433

Epoch: 5| Step: 9
Training loss: 3.272054084023058
Validation loss: 3.0301503236716676

Epoch: 5| Step: 10
Training loss: 3.1909195751837003
Validation loss: 3.0339224963164773

Epoch: 36| Step: 0
Training loss: 3.268821356671027
Validation loss: 3.034442911065815

Epoch: 5| Step: 1
Training loss: 2.8490579553977717
Validation loss: 3.0318973959109616

Epoch: 5| Step: 2
Training loss: 3.307871193561037
Validation loss: 3.0297655793294815

Epoch: 5| Step: 3
Training loss: 3.4819043898758646
Validation loss: 3.027829251982801

Epoch: 5| Step: 4
Training loss: 3.685102297477113
Validation loss: 3.022480795410038

Epoch: 5| Step: 5
Training loss: 3.542757307680769
Validation loss: 3.0249056418406357

Epoch: 5| Step: 6
Training loss: 3.165520376903582
Validation loss: 3.024769150513761

Epoch: 5| Step: 7
Training loss: 3.057123252133507
Validation loss: 3.0298583186510313

Epoch: 5| Step: 8
Training loss: 3.591842277700397
Validation loss: 3.0306268661939546

Epoch: 5| Step: 9
Training loss: 2.6017135255525288
Validation loss: 3.028217959693884

Epoch: 5| Step: 10
Training loss: 3.584703154038795
Validation loss: 3.028867798052691

Epoch: 37| Step: 0
Training loss: 3.50605563408711
Validation loss: 3.024780989057643

Epoch: 5| Step: 1
Training loss: 3.1648005625486113
Validation loss: 3.018331477967911

Epoch: 5| Step: 2
Training loss: 3.7308208838629953
Validation loss: 3.0204712245827645

Epoch: 5| Step: 3
Training loss: 3.0387296911178447
Validation loss: 3.016867725287379

Epoch: 5| Step: 4
Training loss: 4.47455907599403
Validation loss: 3.0169965135263377

Epoch: 5| Step: 5
Training loss: 2.496434243728053
Validation loss: 3.0149629284693726

Epoch: 5| Step: 6
Training loss: 3.0885466928853935
Validation loss: 3.0157539288682695

Epoch: 5| Step: 7
Training loss: 3.6061860235876284
Validation loss: 3.0140632207983775

Epoch: 5| Step: 8
Training loss: 2.5702863419427877
Validation loss: 3.0164611531112966

Epoch: 5| Step: 9
Training loss: 3.239653624398618
Validation loss: 3.011186161530502

Epoch: 5| Step: 10
Training loss: 2.6484647766329052
Validation loss: 3.012459181084091

Epoch: 38| Step: 0
Training loss: 2.9694160115905177
Validation loss: 3.013074580729856

Epoch: 5| Step: 1
Training loss: 3.7418082727994797
Validation loss: 3.0121454364083142

Epoch: 5| Step: 2
Training loss: 3.535936334856746
Validation loss: 3.0102667723135745

Epoch: 5| Step: 3
Training loss: 3.3025787334889616
Validation loss: 3.0089862853092426

Epoch: 5| Step: 4
Training loss: 3.961216783176643
Validation loss: 3.0039470354120765

Epoch: 5| Step: 5
Training loss: 3.1109892522319074
Validation loss: 3.0071245514500675

Epoch: 5| Step: 6
Training loss: 3.849810281017638
Validation loss: 3.004073144943209

Epoch: 5| Step: 7
Training loss: 2.582381370456438
Validation loss: 3.0051283823685813

Epoch: 5| Step: 8
Training loss: 2.7733987295100393
Validation loss: 3.0045829021619253

Epoch: 5| Step: 9
Training loss: 3.120599929644689
Validation loss: 3.0036089725641246

Epoch: 5| Step: 10
Training loss: 2.777578867042371
Validation loss: 3.002774877992257

Epoch: 39| Step: 0
Training loss: 2.632860313456789
Validation loss: 3.0034619142787498

Epoch: 5| Step: 1
Training loss: 3.048771820428205
Validation loss: 3.0038998782427973

Epoch: 5| Step: 2
Training loss: 3.1570998454600865
Validation loss: 3.003061684022559

Epoch: 5| Step: 3
Training loss: 3.746168849856576
Validation loss: 3.006537432809839

Epoch: 5| Step: 4
Training loss: 2.8966480088008018
Validation loss: 3.0050285847059026

Epoch: 5| Step: 5
Training loss: 3.3563651862526473
Validation loss: 3.0116368238954236

Epoch: 5| Step: 6
Training loss: 3.9952923967782876
Validation loss: 3.008430261328422

Epoch: 5| Step: 7
Training loss: 3.4328773627840303
Validation loss: 3.0085995536539434

Epoch: 5| Step: 8
Training loss: 2.2879343214611882
Validation loss: 3.003578670740627

Epoch: 5| Step: 9
Training loss: 3.2493027159143604
Validation loss: 2.997813536369247

Epoch: 5| Step: 10
Training loss: 3.897105752067533
Validation loss: 2.9934745185535534

Epoch: 40| Step: 0
Training loss: 3.812583297069682
Validation loss: 2.993304653432747

Epoch: 5| Step: 1
Training loss: 3.1088800851119935
Validation loss: 2.99571298060868

Epoch: 5| Step: 2
Training loss: 3.1073472968934035
Validation loss: 2.994737874208261

Epoch: 5| Step: 3
Training loss: 4.485521548767002
Validation loss: 2.99244577317087

Epoch: 5| Step: 4
Training loss: 3.3222036204531404
Validation loss: 2.990410596427216

Epoch: 5| Step: 5
Training loss: 3.124881131772458
Validation loss: 2.9913176967125565

Epoch: 5| Step: 6
Training loss: 2.9288289757702692
Validation loss: 2.9888816668370106

Epoch: 5| Step: 7
Training loss: 2.5932940346584905
Validation loss: 2.9889245733997183

Epoch: 5| Step: 8
Training loss: 2.7356788360478728
Validation loss: 2.9870735556430694

Epoch: 5| Step: 9
Training loss: 3.291094299643805
Validation loss: 2.987341506563172

Epoch: 5| Step: 10
Training loss: 3.0321395984409416
Validation loss: 2.9872311595781698

Epoch: 41| Step: 0
Training loss: 3.425500908302072
Validation loss: 2.986115392968199

Epoch: 5| Step: 1
Training loss: 2.5793663042133113
Validation loss: 2.9852995876711512

Epoch: 5| Step: 2
Training loss: 3.1390636605487994
Validation loss: 2.9853879608294034

Epoch: 5| Step: 3
Training loss: 3.1238628607332393
Validation loss: 2.9825382070429827

Epoch: 5| Step: 4
Training loss: 3.462290893189788
Validation loss: 2.98520915597594

Epoch: 5| Step: 5
Training loss: 3.6757210575571087
Validation loss: 2.9849414121500106

Epoch: 5| Step: 6
Training loss: 3.9821898208967035
Validation loss: 2.9823770989593363

Epoch: 5| Step: 7
Training loss: 3.442341671961608
Validation loss: 2.9810502488420525

Epoch: 5| Step: 8
Training loss: 2.6235383823757616
Validation loss: 2.981704756893099

Epoch: 5| Step: 9
Training loss: 2.983129590996215
Validation loss: 2.9863650574001928

Epoch: 5| Step: 10
Training loss: 3.162415930795338
Validation loss: 2.997413393511962

Epoch: 42| Step: 0
Training loss: 3.2213607126024
Validation loss: 2.996152771204528

Epoch: 5| Step: 1
Training loss: 3.2167111948782225
Validation loss: 2.9833722355443557

Epoch: 5| Step: 2
Training loss: 3.807613806222851
Validation loss: 2.976204465150552

Epoch: 5| Step: 3
Training loss: 3.1131504466914786
Validation loss: 2.9766278563196673

Epoch: 5| Step: 4
Training loss: 3.156100883360623
Validation loss: 2.9766287726966376

Epoch: 5| Step: 5
Training loss: 3.2296294998401587
Validation loss: 2.9749837386666735

Epoch: 5| Step: 6
Training loss: 2.9786251260609418
Validation loss: 2.973817344446817

Epoch: 5| Step: 7
Training loss: 3.124655742756662
Validation loss: 2.972097471349414

Epoch: 5| Step: 8
Training loss: 3.254368413776014
Validation loss: 2.9716388086167322

Epoch: 5| Step: 9
Training loss: 3.525792318267997
Validation loss: 2.9707241072845503

Epoch: 5| Step: 10
Training loss: 3.082966516343237
Validation loss: 2.974383924336006

Epoch: 43| Step: 0
Training loss: 3.154997322093474
Validation loss: 2.980529616806118

Epoch: 5| Step: 1
Training loss: 3.9073849669527396
Validation loss: 2.9878181104518564

Epoch: 5| Step: 2
Training loss: 3.1498730891259887
Validation loss: 2.9906364102010423

Epoch: 5| Step: 3
Training loss: 3.220700460031493
Validation loss: 2.9695029512308433

Epoch: 5| Step: 4
Training loss: 3.052737967598254
Validation loss: 2.9669345773340527

Epoch: 5| Step: 5
Training loss: 2.9435819606240172
Validation loss: 2.9703316033869918

Epoch: 5| Step: 6
Training loss: 3.1533008053844593
Validation loss: 2.967955994655066

Epoch: 5| Step: 7
Training loss: 3.9566758684427867
Validation loss: 2.965902057220939

Epoch: 5| Step: 8
Training loss: 2.8146264408706085
Validation loss: 2.96447813908926

Epoch: 5| Step: 9
Training loss: 2.438729685156681
Validation loss: 2.9623174609477068

Epoch: 5| Step: 10
Training loss: 3.659829759234321
Validation loss: 2.9648303820194526

Epoch: 44| Step: 0
Training loss: 3.3687229417269795
Validation loss: 2.962489514747494

Epoch: 5| Step: 1
Training loss: 2.688932524958426
Validation loss: 2.960984891176228

Epoch: 5| Step: 2
Training loss: 3.406600514147246
Validation loss: 2.9593407179347446

Epoch: 5| Step: 3
Training loss: 3.2042628802540416
Validation loss: 2.960045476922735

Epoch: 5| Step: 4
Training loss: 3.03948861790098
Validation loss: 2.9620619718341845

Epoch: 5| Step: 5
Training loss: 3.237074310713088
Validation loss: 2.9606300753080017

Epoch: 5| Step: 6
Training loss: 3.286882924231555
Validation loss: 2.96120833880312

Epoch: 5| Step: 7
Training loss: 3.7372583725817803
Validation loss: 2.958639995297002

Epoch: 5| Step: 8
Training loss: 2.5666673780002682
Validation loss: 2.958231573392617

Epoch: 5| Step: 9
Training loss: 2.991504880166349
Validation loss: 2.9617868728457832

Epoch: 5| Step: 10
Training loss: 3.938229205713324
Validation loss: 2.969497774740737

Epoch: 45| Step: 0
Training loss: 3.2906271504307285
Validation loss: 2.986063164429966

Epoch: 5| Step: 1
Training loss: 3.260648010301406
Validation loss: 2.959926202971585

Epoch: 5| Step: 2
Training loss: 2.9460852947331264
Validation loss: 2.951282333261742

Epoch: 5| Step: 3
Training loss: 3.035514898724501
Validation loss: 2.9529168960160335

Epoch: 5| Step: 4
Training loss: 3.0977877075471576
Validation loss: 2.9502021061245873

Epoch: 5| Step: 5
Training loss: 2.927538111281452
Validation loss: 2.952784516741885

Epoch: 5| Step: 6
Training loss: 3.1870243989257667
Validation loss: 2.950450438080448

Epoch: 5| Step: 7
Training loss: 3.831924483652188
Validation loss: 2.9486753388370106

Epoch: 5| Step: 8
Training loss: 3.3108110260582007
Validation loss: 2.9492415697496686

Epoch: 5| Step: 9
Training loss: 3.854397672311564
Validation loss: 2.9492112082825224

Epoch: 5| Step: 10
Training loss: 2.5164872107617575
Validation loss: 2.9506340696245825

Epoch: 46| Step: 0
Training loss: 3.181371144684237
Validation loss: 2.9533424816056106

Epoch: 5| Step: 1
Training loss: 3.2448504806421563
Validation loss: 2.9482157113574043

Epoch: 5| Step: 2
Training loss: 2.958267981295426
Validation loss: 2.962950650234287

Epoch: 5| Step: 3
Training loss: 3.5907273559323762
Validation loss: 2.9936747507232586

Epoch: 5| Step: 4
Training loss: 3.055598520689705
Validation loss: 2.9950795378860846

Epoch: 5| Step: 5
Training loss: 3.85277286105372
Validation loss: 2.982615005125229

Epoch: 5| Step: 6
Training loss: 2.782734763908675
Validation loss: 2.947733387079209

Epoch: 5| Step: 7
Training loss: 3.6381055766971393
Validation loss: 2.9420851384155546

Epoch: 5| Step: 8
Training loss: 2.7017854226816094
Validation loss: 2.941313007992976

Epoch: 5| Step: 9
Training loss: 2.7175786794662184
Validation loss: 2.941616594088913

Epoch: 5| Step: 10
Training loss: 3.6209592989720294
Validation loss: 2.940291704699498

Epoch: 47| Step: 0
Training loss: 3.4002303382041985
Validation loss: 2.944889820232269

Epoch: 5| Step: 1
Training loss: 3.392087981153674
Validation loss: 2.941635591145919

Epoch: 5| Step: 2
Training loss: 2.6916238062923297
Validation loss: 2.9453552735642043

Epoch: 5| Step: 3
Training loss: 3.6568828589329354
Validation loss: 2.945451924804397

Epoch: 5| Step: 4
Training loss: 2.881917840510573
Validation loss: 2.939306544522489

Epoch: 5| Step: 5
Training loss: 3.1150978369372937
Validation loss: 2.9376893428678126

Epoch: 5| Step: 6
Training loss: 3.4457370902985307
Validation loss: 2.9360228773534938

Epoch: 5| Step: 7
Training loss: 3.1606069274108046
Validation loss: 2.9355462069182447

Epoch: 5| Step: 8
Training loss: 3.581799881346618
Validation loss: 2.9351928271246885

Epoch: 5| Step: 9
Training loss: 2.72315569419276
Validation loss: 2.9334001191172288

Epoch: 5| Step: 10
Training loss: 3.2011203354415683
Validation loss: 2.9372565649256392

Epoch: 48| Step: 0
Training loss: 3.3907643654303903
Validation loss: 2.939603877294294

Epoch: 5| Step: 1
Training loss: 3.5680399868182784
Validation loss: 2.9489132724113483

Epoch: 5| Step: 2
Training loss: 2.8307738992244285
Validation loss: 2.9494018515233655

Epoch: 5| Step: 3
Training loss: 3.1031410178455863
Validation loss: 2.9650090704479326

Epoch: 5| Step: 4
Training loss: 2.670485285687187
Validation loss: 2.9878985566416922

Epoch: 5| Step: 5
Training loss: 3.2451114568392825
Validation loss: 2.970892512494551

Epoch: 5| Step: 6
Training loss: 3.7526736582830234
Validation loss: 2.9656141116530876

Epoch: 5| Step: 7
Training loss: 2.5573610087910286
Validation loss: 2.935786590385227

Epoch: 5| Step: 8
Training loss: 3.559974176548941
Validation loss: 2.930732630981324

Epoch: 5| Step: 9
Training loss: 3.5332674998022284
Validation loss: 2.9301408034443934

Epoch: 5| Step: 10
Training loss: 2.8878974211695527
Validation loss: 2.929213244263998

Epoch: 49| Step: 0
Training loss: 3.0301931839598444
Validation loss: 2.9270660840135196

Epoch: 5| Step: 1
Training loss: 3.5387566373244725
Validation loss: 2.930044355856431

Epoch: 5| Step: 2
Training loss: 2.679572189118856
Validation loss: 2.9337160012822903

Epoch: 5| Step: 3
Training loss: 3.358180485758137
Validation loss: 2.928893954748782

Epoch: 5| Step: 4
Training loss: 3.4828617932753416
Validation loss: 2.923960195850632

Epoch: 5| Step: 5
Training loss: 2.6209553029638406
Validation loss: 2.922386919070737

Epoch: 5| Step: 6
Training loss: 3.4759795310907
Validation loss: 2.9212714122330246

Epoch: 5| Step: 7
Training loss: 3.491095796833839
Validation loss: 2.928171960783289

Epoch: 5| Step: 8
Training loss: 3.3022056260111907
Validation loss: 2.92467809468866

Epoch: 5| Step: 9
Training loss: 2.9699934112270236
Validation loss: 2.9240319305400715

Epoch: 5| Step: 10
Training loss: 3.246270313808969
Validation loss: 2.9391666022920866

Epoch: 50| Step: 0
Training loss: 2.815944850760905
Validation loss: 2.951105152238929

Epoch: 5| Step: 1
Training loss: 4.190038338715676
Validation loss: 2.9489756989749165

Epoch: 5| Step: 2
Training loss: 2.862648679378567
Validation loss: 2.9266669681890987

Epoch: 5| Step: 3
Training loss: 2.8604309133539303
Validation loss: 2.921516615388308

Epoch: 5| Step: 4
Training loss: 2.592136386691621
Validation loss: 2.917488753285185

Epoch: 5| Step: 5
Training loss: 3.3121917869121913
Validation loss: 2.9175932064440424

Epoch: 5| Step: 6
Training loss: 3.313504048893143
Validation loss: 2.9185514510031756

Epoch: 5| Step: 7
Training loss: 3.4641540597835068
Validation loss: 2.92399381452696

Epoch: 5| Step: 8
Training loss: 2.8521492132394686
Validation loss: 2.924085227596207

Epoch: 5| Step: 9
Training loss: 3.3698114142018625
Validation loss: 2.925750473335722

Epoch: 5| Step: 10
Training loss: 3.3567344046017564
Validation loss: 2.9194200332043714

Epoch: 51| Step: 0
Training loss: 2.813262412260548
Validation loss: 2.915321518652402

Epoch: 5| Step: 1
Training loss: 2.8764575083322907
Validation loss: 2.9168532533044433

Epoch: 5| Step: 2
Training loss: 3.659068268544886
Validation loss: 2.9131007802659643

Epoch: 5| Step: 3
Training loss: 2.897593249317228
Validation loss: 2.9121214391273984

Epoch: 5| Step: 4
Training loss: 3.07562929242677
Validation loss: 2.9109357517897636

Epoch: 5| Step: 5
Training loss: 2.534479318299219
Validation loss: 2.9100308417886995

Epoch: 5| Step: 6
Training loss: 3.682241019512608
Validation loss: 2.9146263111356294

Epoch: 5| Step: 7
Training loss: 3.732563680832482
Validation loss: 2.9158140128636805

Epoch: 5| Step: 8
Training loss: 3.4334893151068817
Validation loss: 2.915837540683467

Epoch: 5| Step: 9
Training loss: 3.4010308554196627
Validation loss: 2.921765272585019

Epoch: 5| Step: 10
Training loss: 2.7981582340382514
Validation loss: 2.911548526298862

Epoch: 52| Step: 0
Training loss: 3.0193616417234193
Validation loss: 2.9103681514850255

Epoch: 5| Step: 1
Training loss: 3.4011639061419654
Validation loss: 2.9093121924593714

Epoch: 5| Step: 2
Training loss: 3.1514460196504253
Validation loss: 2.9109004128893785

Epoch: 5| Step: 3
Training loss: 3.554681865981112
Validation loss: 2.9084606498082604

Epoch: 5| Step: 4
Training loss: 3.0251890328353377
Validation loss: 2.9052897090840535

Epoch: 5| Step: 5
Training loss: 2.660258331804875
Validation loss: 2.9057608589863957

Epoch: 5| Step: 6
Training loss: 3.331235909208517
Validation loss: 2.9039318407199692

Epoch: 5| Step: 7
Training loss: 2.633346910884315
Validation loss: 2.9030461747987477

Epoch: 5| Step: 8
Training loss: 3.241124137320715
Validation loss: 2.901691409001512

Epoch: 5| Step: 9
Training loss: 3.8644889278482757
Validation loss: 2.9024798969234245

Epoch: 5| Step: 10
Training loss: 2.9583153701738323
Validation loss: 2.9035737427349875

Epoch: 53| Step: 0
Training loss: 2.6436608373878876
Validation loss: 2.903824272763089

Epoch: 5| Step: 1
Training loss: 3.5508598092330623
Validation loss: 2.9007147170298335

Epoch: 5| Step: 2
Training loss: 3.3741232121644136
Validation loss: 2.904039003908308

Epoch: 5| Step: 3
Training loss: 3.1224168400804166
Validation loss: 2.900054298496505

Epoch: 5| Step: 4
Training loss: 2.9624267697840243
Validation loss: 2.901693158328443

Epoch: 5| Step: 5
Training loss: 3.3958911695801333
Validation loss: 2.899722595723537

Epoch: 5| Step: 6
Training loss: 3.620915973336293
Validation loss: 2.8964045222361725

Epoch: 5| Step: 7
Training loss: 3.113279412052469
Validation loss: 2.8947987957508

Epoch: 5| Step: 8
Training loss: 3.2509877097848836
Validation loss: 2.898031757545421

Epoch: 5| Step: 9
Training loss: 3.0662712699192847
Validation loss: 2.9076229675897807

Epoch: 5| Step: 10
Training loss: 2.8092945057642473
Validation loss: 2.908334257031272

Epoch: 54| Step: 0
Training loss: 3.481133291592761
Validation loss: 2.9221857070344033

Epoch: 5| Step: 1
Training loss: 3.068970986545778
Validation loss: 2.9093526103465175

Epoch: 5| Step: 2
Training loss: 3.7891597774642376
Validation loss: 2.898246733872044

Epoch: 5| Step: 3
Training loss: 3.0017640967039267
Validation loss: 2.890437246498117

Epoch: 5| Step: 4
Training loss: 3.4515857977229785
Validation loss: 2.890149680460268

Epoch: 5| Step: 5
Training loss: 3.2875616495712205
Validation loss: 2.8885655599515134

Epoch: 5| Step: 6
Training loss: 3.157500368723844
Validation loss: 2.889949754525924

Epoch: 5| Step: 7
Training loss: 3.38221449995503
Validation loss: 2.8884295541965415

Epoch: 5| Step: 8
Training loss: 2.22327080729734
Validation loss: 2.89147241659909

Epoch: 5| Step: 9
Training loss: 2.9924676430338377
Validation loss: 2.894411034470904

Epoch: 5| Step: 10
Training loss: 2.8966384610060154
Validation loss: 2.897933059435707

Epoch: 55| Step: 0
Training loss: 3.1024182577991777
Validation loss: 2.9033818262544875

Epoch: 5| Step: 1
Training loss: 2.8877607021468674
Validation loss: 2.900834985058259

Epoch: 5| Step: 2
Training loss: 3.550104359986742
Validation loss: 2.888833651107912

Epoch: 5| Step: 3
Training loss: 3.389200078160008
Validation loss: 2.8895830027386387

Epoch: 5| Step: 4
Training loss: 3.379218679106989
Validation loss: 2.9087948065939053

Epoch: 5| Step: 5
Training loss: 3.5283947769698956
Validation loss: 2.8928963014387006

Epoch: 5| Step: 6
Training loss: 2.856083878041435
Validation loss: 2.881606283526769

Epoch: 5| Step: 7
Training loss: 2.9978968877893206
Validation loss: 2.8824254164665164

Epoch: 5| Step: 8
Training loss: 3.266588424861474
Validation loss: 2.884047400175551

Epoch: 5| Step: 9
Training loss: 2.8349049267309683
Validation loss: 2.8963826935367925

Epoch: 5| Step: 10
Training loss: 3.0160873137769357
Validation loss: 2.9387847065190935

Epoch: 56| Step: 0
Training loss: 3.4639592810477486
Validation loss: 3.0106450470530213

Epoch: 5| Step: 1
Training loss: 2.7083858387087982
Validation loss: 2.884129908821982

Epoch: 5| Step: 2
Training loss: 2.917259119806591
Validation loss: 2.883936617525371

Epoch: 5| Step: 3
Training loss: 3.6954273423783954
Validation loss: 2.9042878554948266

Epoch: 5| Step: 4
Training loss: 3.76722752831868
Validation loss: 2.9350409704389415

Epoch: 5| Step: 5
Training loss: 3.1873137475742914
Validation loss: 2.9148564189587054

Epoch: 5| Step: 6
Training loss: 2.9884596428573875
Validation loss: 2.882603910760918

Epoch: 5| Step: 7
Training loss: 3.3112194537103523
Validation loss: 2.874344514274244

Epoch: 5| Step: 8
Training loss: 3.292782815591441
Validation loss: 2.872337619107282

Epoch: 5| Step: 9
Training loss: 2.2939453125
Validation loss: 2.8688448691221473

Epoch: 5| Step: 10
Training loss: 3.3700313021057906
Validation loss: 2.879515107050369

Epoch: 57| Step: 0
Training loss: 3.3338892632065225
Validation loss: 2.904606510037129

Epoch: 5| Step: 1
Training loss: 2.8888678081264967
Validation loss: 2.9156370434609413

Epoch: 5| Step: 2
Training loss: 3.3041091304610526
Validation loss: 2.88699105482185

Epoch: 5| Step: 3
Training loss: 3.092656876849154
Validation loss: 2.87289430782002

Epoch: 5| Step: 4
Training loss: 3.52147652132721
Validation loss: 2.8676647785878937

Epoch: 5| Step: 5
Training loss: 2.3578919050371763
Validation loss: 2.8701988246873276

Epoch: 5| Step: 6
Training loss: 3.2871153225677774
Validation loss: 2.867460842425051

Epoch: 5| Step: 7
Training loss: 2.7968958848567747
Validation loss: 2.8755129837564453

Epoch: 5| Step: 8
Training loss: 3.6394443152782583
Validation loss: 2.8730678138062755

Epoch: 5| Step: 9
Training loss: 3.7360421134568265
Validation loss: 2.86644870435487

Epoch: 5| Step: 10
Training loss: 2.4972242204231225
Validation loss: 2.8646902523428626

Epoch: 58| Step: 0
Training loss: 2.9706771217427024
Validation loss: 2.864854254268029

Epoch: 5| Step: 1
Training loss: 2.7253088924776443
Validation loss: 2.8659642505346956

Epoch: 5| Step: 2
Training loss: 3.528600188050408
Validation loss: 2.8725374080350154

Epoch: 5| Step: 3
Training loss: 3.5059291482001895
Validation loss: 2.875639011156812

Epoch: 5| Step: 4
Training loss: 2.905988455868269
Validation loss: 2.892234455733825

Epoch: 5| Step: 5
Training loss: 3.606090157336524
Validation loss: 2.9284928977569926

Epoch: 5| Step: 6
Training loss: 2.4751162954423687
Validation loss: 2.8940056709268966

Epoch: 5| Step: 7
Training loss: 3.0814098510133108
Validation loss: 2.8604333081137123

Epoch: 5| Step: 8
Training loss: 3.388683554329657
Validation loss: 2.858209267570821

Epoch: 5| Step: 9
Training loss: 2.874195317978775
Validation loss: 2.8601380510240237

Epoch: 5| Step: 10
Training loss: 3.6306057698296588
Validation loss: 2.860701729874528

Epoch: 59| Step: 0
Training loss: 3.309979037307788
Validation loss: 2.8645925564584824

Epoch: 5| Step: 1
Training loss: 3.4665744591945717
Validation loss: 2.865278501014469

Epoch: 5| Step: 2
Training loss: 3.1254632225039236
Validation loss: 2.861052393812697

Epoch: 5| Step: 3
Training loss: 3.156407116293629
Validation loss: 2.85675983787852

Epoch: 5| Step: 4
Training loss: 2.4418889171319935
Validation loss: 2.85554690962685

Epoch: 5| Step: 5
Training loss: 2.9403129257994864
Validation loss: 2.8577058581310637

Epoch: 5| Step: 6
Training loss: 3.7181901269884747
Validation loss: 2.885386016838105

Epoch: 5| Step: 7
Training loss: 2.3769625535839087
Validation loss: 2.861468996290559

Epoch: 5| Step: 8
Training loss: 3.74441786780832
Validation loss: 2.852466757572394

Epoch: 5| Step: 9
Training loss: 3.0504526896738584
Validation loss: 2.851927164663345

Epoch: 5| Step: 10
Training loss: 3.137062291468985
Validation loss: 2.852088928852366

Epoch: 60| Step: 0
Training loss: 2.8821273030762704
Validation loss: 2.850640903617423

Epoch: 5| Step: 1
Training loss: 2.994532052549299
Validation loss: 2.8486098023639745

Epoch: 5| Step: 2
Training loss: 3.2578543607734742
Validation loss: 2.852928151290158

Epoch: 5| Step: 3
Training loss: 3.285238403309134
Validation loss: 2.8534715646018007

Epoch: 5| Step: 4
Training loss: 3.3510962386465994
Validation loss: 2.853666088440217

Epoch: 5| Step: 5
Training loss: 3.558614385316817
Validation loss: 2.853138181824449

Epoch: 5| Step: 6
Training loss: 3.3424312094298227
Validation loss: 2.854201532565159

Epoch: 5| Step: 7
Training loss: 3.0841906275037907
Validation loss: 2.8509691628868645

Epoch: 5| Step: 8
Training loss: 2.7755691288369375
Validation loss: 2.8501422270896666

Epoch: 5| Step: 9
Training loss: 3.0332485571392276
Validation loss: 2.85001391454386

Epoch: 5| Step: 10
Training loss: 3.035153893429346
Validation loss: 2.848838358349431

Epoch: 61| Step: 0
Training loss: 2.799961624563726
Validation loss: 2.8487343008393737

Epoch: 5| Step: 1
Training loss: 3.184314557251517
Validation loss: 2.847783729842511

Epoch: 5| Step: 2
Training loss: 3.5034372617609018
Validation loss: 2.846056498060063

Epoch: 5| Step: 3
Training loss: 2.443855021920094
Validation loss: 2.8604703818224397

Epoch: 5| Step: 4
Training loss: 3.1412617052241933
Validation loss: 2.864874792103501

Epoch: 5| Step: 5
Training loss: 2.731733954040986
Validation loss: 2.873696071197941

Epoch: 5| Step: 6
Training loss: 3.7377641055078437
Validation loss: 2.8558235045163722

Epoch: 5| Step: 7
Training loss: 3.3116020569036633
Validation loss: 2.843464287675033

Epoch: 5| Step: 8
Training loss: 2.429220369333174
Validation loss: 2.841824936193463

Epoch: 5| Step: 9
Training loss: 3.772948555238472
Validation loss: 2.8426481400056565

Epoch: 5| Step: 10
Training loss: 3.278488741205084
Validation loss: 2.8424958036329357

Epoch: 62| Step: 0
Training loss: 3.00989125736538
Validation loss: 2.842710526559836

Epoch: 5| Step: 1
Training loss: 3.148686325804478
Validation loss: 2.8420910517978863

Epoch: 5| Step: 2
Training loss: 3.248569320345397
Validation loss: 2.84087523023128

Epoch: 5| Step: 3
Training loss: 3.1976232404424043
Validation loss: 2.84110196489723

Epoch: 5| Step: 4
Training loss: 2.813120625154983
Validation loss: 2.843961050898469

Epoch: 5| Step: 5
Training loss: 3.108427123699317
Validation loss: 2.842537517902657

Epoch: 5| Step: 6
Training loss: 3.5411124450273586
Validation loss: 2.8412896238138976

Epoch: 5| Step: 7
Training loss: 3.1144854850240966
Validation loss: 2.842184193498665

Epoch: 5| Step: 8
Training loss: 3.4921154040376714
Validation loss: 2.8406963845401254

Epoch: 5| Step: 9
Training loss: 2.6409086718355246
Validation loss: 2.8374478223545205

Epoch: 5| Step: 10
Training loss: 3.2127110393389007
Validation loss: 2.838489428955204

Epoch: 63| Step: 0
Training loss: 2.5973043332462047
Validation loss: 2.8590385471726374

Epoch: 5| Step: 1
Training loss: 3.552753702187671
Validation loss: 2.8843162677027316

Epoch: 5| Step: 2
Training loss: 2.94292889783999
Validation loss: 2.8691799968888874

Epoch: 5| Step: 3
Training loss: 2.9616798134681748
Validation loss: 2.851653579289009

Epoch: 5| Step: 4
Training loss: 3.224219702426334
Validation loss: 2.8429382745144314

Epoch: 5| Step: 5
Training loss: 3.1803124865659083
Validation loss: 2.8550562429249875

Epoch: 5| Step: 6
Training loss: 3.4055200197053983
Validation loss: 2.8683305980735136

Epoch: 5| Step: 7
Training loss: 3.2267113159442804
Validation loss: 2.835291573638877

Epoch: 5| Step: 8
Training loss: 3.0198271731003925
Validation loss: 2.8352048071989677

Epoch: 5| Step: 9
Training loss: 3.1339182436271784
Validation loss: 2.8589179349881846

Epoch: 5| Step: 10
Training loss: 3.1836954486728
Validation loss: 2.846146379916454

Epoch: 64| Step: 0
Training loss: 2.2862991474556638
Validation loss: 2.831497973854807

Epoch: 5| Step: 1
Training loss: 2.897422921420221
Validation loss: 2.8361819030965933

Epoch: 5| Step: 2
Training loss: 3.7121416888736785
Validation loss: 2.8327068876525354

Epoch: 5| Step: 3
Training loss: 3.5001626658105174
Validation loss: 2.834067337959941

Epoch: 5| Step: 4
Training loss: 3.2574024994458384
Validation loss: 2.8330226911277454

Epoch: 5| Step: 5
Training loss: 3.267496257333283
Validation loss: 2.8219074966601245

Epoch: 5| Step: 6
Training loss: 3.1247851488642384
Validation loss: 2.8205957975755673

Epoch: 5| Step: 7
Training loss: 2.41653799394085
Validation loss: 2.8216283221233325

Epoch: 5| Step: 8
Training loss: 3.093342147299388
Validation loss: 2.8203252767583025

Epoch: 5| Step: 9
Training loss: 2.8894476064990564
Validation loss: 2.823866853897271

Epoch: 5| Step: 10
Training loss: 3.6960297547748655
Validation loss: 2.8338530520435588

Epoch: 65| Step: 0
Training loss: 3.3765793389955667
Validation loss: 2.8180368738512045

Epoch: 5| Step: 1
Training loss: 3.4152732116522526
Validation loss: 2.824805473108145

Epoch: 5| Step: 2
Training loss: 3.2492900953373227
Validation loss: 2.8338465865140527

Epoch: 5| Step: 3
Training loss: 3.260617007274458
Validation loss: 2.840186844511133

Epoch: 5| Step: 4
Training loss: 3.060883075722931
Validation loss: 2.851608233296521

Epoch: 5| Step: 5
Training loss: 2.7336621908520167
Validation loss: 2.836668256602042

Epoch: 5| Step: 6
Training loss: 3.1516873457411947
Validation loss: 2.8298849248816262

Epoch: 5| Step: 7
Training loss: 3.0489824880345426
Validation loss: 2.8224154990383314

Epoch: 5| Step: 8
Training loss: 3.0261112977692703
Validation loss: 2.817701863815277

Epoch: 5| Step: 9
Training loss: 3.060465545644829
Validation loss: 2.81734941852711

Epoch: 5| Step: 10
Training loss: 3.1249697874516085
Validation loss: 2.815654754563399

Epoch: 66| Step: 0
Training loss: 3.233378528659261
Validation loss: 2.8168856974024523

Epoch: 5| Step: 1
Training loss: 3.414114595971592
Validation loss: 2.809450647183699

Epoch: 5| Step: 2
Training loss: 2.5282060192880556
Validation loss: 2.8117645031186256

Epoch: 5| Step: 3
Training loss: 3.416007947613228
Validation loss: 2.815523107511801

Epoch: 5| Step: 4
Training loss: 3.0820784377823784
Validation loss: 2.827509708265472

Epoch: 5| Step: 5
Training loss: 2.84662641995617
Validation loss: 2.8542058196652196

Epoch: 5| Step: 6
Training loss: 3.5593325269943135
Validation loss: 2.882447351753395

Epoch: 5| Step: 7
Training loss: 2.8541268301826666
Validation loss: 2.896896991751793

Epoch: 5| Step: 8
Training loss: 3.3767849475997767
Validation loss: 2.8605318571928047

Epoch: 5| Step: 9
Training loss: 3.059011691442409
Validation loss: 2.8196549823861536

Epoch: 5| Step: 10
Training loss: 2.8507139014507934
Validation loss: 2.8087744882800147

Epoch: 67| Step: 0
Training loss: 2.800677224412738
Validation loss: 2.8114435369735675

Epoch: 5| Step: 1
Training loss: 3.4279704390311743
Validation loss: 2.8099093027972497

Epoch: 5| Step: 2
Training loss: 2.8876888725304415
Validation loss: 2.809717878288171

Epoch: 5| Step: 3
Training loss: 3.2024693259944814
Validation loss: 2.808485595742016

Epoch: 5| Step: 4
Training loss: 3.1358045335985167
Validation loss: 2.809319557160175

Epoch: 5| Step: 5
Training loss: 3.3853841613774027
Validation loss: 2.8097274541117185

Epoch: 5| Step: 6
Training loss: 3.503101745582732
Validation loss: 2.811002176157909

Epoch: 5| Step: 7
Training loss: 2.624561636516565
Validation loss: 2.8089760528655696

Epoch: 5| Step: 8
Training loss: 3.033688223343031
Validation loss: 2.806014104488126

Epoch: 5| Step: 9
Training loss: 3.3272226749129055
Validation loss: 2.808564701398188

Epoch: 5| Step: 10
Training loss: 2.961109810598858
Validation loss: 2.862078683049271

Epoch: 68| Step: 0
Training loss: 3.6448214334669884
Validation loss: 2.861760014971433

Epoch: 5| Step: 1
Training loss: 3.325203486361099
Validation loss: 2.864568615350734

Epoch: 5| Step: 2
Training loss: 3.6304522322493833
Validation loss: 2.86856546344858

Epoch: 5| Step: 3
Training loss: 3.1491107836049514
Validation loss: 2.8814504416890188

Epoch: 5| Step: 4
Training loss: 2.5452610823260096
Validation loss: 2.884436127157337

Epoch: 5| Step: 5
Training loss: 2.9053533668101643
Validation loss: 2.8865073043329437

Epoch: 5| Step: 6
Training loss: 3.5607871237685496
Validation loss: 2.876590155249173

Epoch: 5| Step: 7
Training loss: 3.118281351781328
Validation loss: 2.867391912471951

Epoch: 5| Step: 8
Training loss: 2.861002641203967
Validation loss: 2.8651425212789894

Epoch: 5| Step: 9
Training loss: 2.840691735015651
Validation loss: 2.8641223835666128

Epoch: 5| Step: 10
Training loss: 3.017081585866774
Validation loss: 2.863229385450397

Epoch: 69| Step: 0
Training loss: 2.9272864509963017
Validation loss: 2.86260331769823

Epoch: 5| Step: 1
Training loss: 3.1215566356335382
Validation loss: 2.8610211018489218

Epoch: 5| Step: 2
Training loss: 3.17015412350063
Validation loss: 2.8642103165247206

Epoch: 5| Step: 3
Training loss: 3.3084833516299725
Validation loss: 2.8662140483447653

Epoch: 5| Step: 4
Training loss: 3.0112402470273576
Validation loss: 2.8624565106162096

Epoch: 5| Step: 5
Training loss: 3.4497188840582824
Validation loss: 2.870986594713987

Epoch: 5| Step: 6
Training loss: 3.813753891164269
Validation loss: 2.8741041716554316

Epoch: 5| Step: 7
Training loss: 2.3895781973994525
Validation loss: 2.867415644489583

Epoch: 5| Step: 8
Training loss: 2.810760892840658
Validation loss: 2.8640760749364635

Epoch: 5| Step: 9
Training loss: 3.9019979298877945
Validation loss: 2.862185191943558

Epoch: 5| Step: 10
Training loss: 2.252850845736572
Validation loss: 2.859302431294424

Epoch: 70| Step: 0
Training loss: 3.412207896268332
Validation loss: 2.8615230679947223

Epoch: 5| Step: 1
Training loss: 3.3082579315074323
Validation loss: 2.8604979515304447

Epoch: 5| Step: 2
Training loss: 3.289014947325486
Validation loss: 2.860876300600065

Epoch: 5| Step: 3
Training loss: 3.415089607682852
Validation loss: 2.8590503573110855

Epoch: 5| Step: 4
Training loss: 2.7033813884178266
Validation loss: 2.857334735319324

Epoch: 5| Step: 5
Training loss: 2.739012790540041
Validation loss: 2.860196480685723

Epoch: 5| Step: 6
Training loss: 3.0091616292478376
Validation loss: 2.8607725442964584

Epoch: 5| Step: 7
Training loss: 2.7657259475474527
Validation loss: 2.8620970095613205

Epoch: 5| Step: 8
Training loss: 3.000077882391562
Validation loss: 2.8701337392303694

Epoch: 5| Step: 9
Training loss: 2.635032917374463
Validation loss: 2.875746708044391

Epoch: 5| Step: 10
Training loss: 4.203824690541769
Validation loss: 2.8707625775634336

Epoch: 71| Step: 0
Training loss: 3.473275883492989
Validation loss: 2.8588753630263013

Epoch: 5| Step: 1
Training loss: 3.2999856023763368
Validation loss: 2.852842091090314

Epoch: 5| Step: 2
Training loss: 2.9133661578473005
Validation loss: 2.8527805569499245

Epoch: 5| Step: 3
Training loss: 2.6527081381115822
Validation loss: 2.8512114853415196

Epoch: 5| Step: 4
Training loss: 3.1392034093618593
Validation loss: 2.850421039083826

Epoch: 5| Step: 5
Training loss: 2.7039982261764757
Validation loss: 2.8540679654692425

Epoch: 5| Step: 6
Training loss: 3.562152778703244
Validation loss: 2.8570728220720834

Epoch: 5| Step: 7
Training loss: 3.2803631265183566
Validation loss: 2.849588960152199

Epoch: 5| Step: 8
Training loss: 3.0107830489037095
Validation loss: 2.846636577682149

Epoch: 5| Step: 9
Training loss: 3.502726855014162
Validation loss: 2.8436226765011448

Epoch: 5| Step: 10
Training loss: 2.9408514505204644
Validation loss: 2.8412247915030155

Epoch: 72| Step: 0
Training loss: 3.2737046453677734
Validation loss: 2.8231144907556778

Epoch: 5| Step: 1
Training loss: 3.833059066138219
Validation loss: 2.7910229659080303

Epoch: 5| Step: 2
Training loss: 2.33563005854646
Validation loss: 2.797525328099846

Epoch: 5| Step: 3
Training loss: 3.110102276116931
Validation loss: 2.7904315806631463

Epoch: 5| Step: 4
Training loss: 3.2034669274911804
Validation loss: 2.792478573432218

Epoch: 5| Step: 5
Training loss: 2.832675034585242
Validation loss: 2.7956254415423083

Epoch: 5| Step: 6
Training loss: 3.4239019373995965
Validation loss: 2.8162309080775882

Epoch: 5| Step: 7
Training loss: 3.4186843558918576
Validation loss: 2.783175713505423

Epoch: 5| Step: 8
Training loss: 3.1010663382757886
Validation loss: 2.775750286661452

Epoch: 5| Step: 9
Training loss: 2.4507273236690423
Validation loss: 2.780357082006066

Epoch: 5| Step: 10
Training loss: 2.7386733793320643
Validation loss: 2.7818417584993966

Epoch: 73| Step: 0
Training loss: 3.485443772421304
Validation loss: 2.7829873904639837

Epoch: 5| Step: 1
Training loss: 2.392450470924917
Validation loss: 2.7879878850610025

Epoch: 5| Step: 2
Training loss: 3.1842239598625124
Validation loss: 2.783391889364285

Epoch: 5| Step: 3
Training loss: 3.5738237006322353
Validation loss: 2.7729658780466626

Epoch: 5| Step: 4
Training loss: 3.0435787270235566
Validation loss: 2.7673262030047825

Epoch: 5| Step: 5
Training loss: 2.9589664874149926
Validation loss: 2.765970279809495

Epoch: 5| Step: 6
Training loss: 3.0043422744647836
Validation loss: 2.7698089031389115

Epoch: 5| Step: 7
Training loss: 2.8604552516200976
Validation loss: 2.801149478833764

Epoch: 5| Step: 8
Training loss: 3.2927980209022114
Validation loss: 2.8315115847128767

Epoch: 5| Step: 9
Training loss: 3.206964192403754
Validation loss: 2.840550602262489

Epoch: 5| Step: 10
Training loss: 2.9540481335560886
Validation loss: 2.835981322972298

Epoch: 74| Step: 0
Training loss: 3.2478381082374375
Validation loss: 2.8328041162102022

Epoch: 5| Step: 1
Training loss: 3.5956654626965654
Validation loss: 2.828648403360048

Epoch: 5| Step: 2
Training loss: 3.371777444158284
Validation loss: 2.825692170555988

Epoch: 5| Step: 3
Training loss: 2.3207160778547795
Validation loss: 2.8297159083500314

Epoch: 5| Step: 4
Training loss: 3.288420915888985
Validation loss: 2.8274254213225967

Epoch: 5| Step: 5
Training loss: 3.656965919241943
Validation loss: 2.8255935150744107

Epoch: 5| Step: 6
Training loss: 2.8727584061290905
Validation loss: 2.8164455016318053

Epoch: 5| Step: 7
Training loss: 2.7478363021501675
Validation loss: 2.788707149474601

Epoch: 5| Step: 8
Training loss: 2.829636817785782
Validation loss: 2.775069001114215

Epoch: 5| Step: 9
Training loss: 3.053449999594625
Validation loss: 2.7603623003877376

Epoch: 5| Step: 10
Training loss: 3.0413494380149366
Validation loss: 2.760260492613608

Epoch: 75| Step: 0
Training loss: 2.776724229866997
Validation loss: 2.7634038388416373

Epoch: 5| Step: 1
Training loss: 3.4217360655567144
Validation loss: 2.7644456884606474

Epoch: 5| Step: 2
Training loss: 2.684915586313179
Validation loss: 2.7690948767831114

Epoch: 5| Step: 3
Training loss: 2.8554953014219566
Validation loss: 2.7684723069279977

Epoch: 5| Step: 4
Training loss: 2.766745992082502
Validation loss: 2.763139714268009

Epoch: 5| Step: 5
Training loss: 3.251717627077283
Validation loss: 2.761686182129579

Epoch: 5| Step: 6
Training loss: 3.3938527016177824
Validation loss: 2.757991226876225

Epoch: 5| Step: 7
Training loss: 2.7702311289240673
Validation loss: 2.7552069509636783

Epoch: 5| Step: 8
Training loss: 3.338258315672009
Validation loss: 2.7546323948940667

Epoch: 5| Step: 9
Training loss: 3.3548363121795606
Validation loss: 2.754959027862042

Epoch: 5| Step: 10
Training loss: 3.146812303481071
Validation loss: 2.7602409874953935

Epoch: 76| Step: 0
Training loss: 3.3819973780679944
Validation loss: 2.758451268653633

Epoch: 5| Step: 1
Training loss: 3.598307232770188
Validation loss: 2.756652547187574

Epoch: 5| Step: 2
Training loss: 2.6878805556439245
Validation loss: 2.7621658343208724

Epoch: 5| Step: 3
Training loss: 3.4653977700564065
Validation loss: 2.7650728067826247

Epoch: 5| Step: 4
Training loss: 2.834153131551557
Validation loss: 2.762469649260675

Epoch: 5| Step: 5
Training loss: 2.7610034151094145
Validation loss: 2.762181626820363

Epoch: 5| Step: 6
Training loss: 3.1330137116844123
Validation loss: 2.7638823776290717

Epoch: 5| Step: 7
Training loss: 3.2337442418811375
Validation loss: 2.7728893902528795

Epoch: 5| Step: 8
Training loss: 2.9019793234153606
Validation loss: 2.792862311177359

Epoch: 5| Step: 9
Training loss: 3.1641465917644847
Validation loss: 2.795815155257268

Epoch: 5| Step: 10
Training loss: 2.526316037303511
Validation loss: 2.7997386821052697

Epoch: 77| Step: 0
Training loss: 2.7749218903966892
Validation loss: 2.8003693740579876

Epoch: 5| Step: 1
Training loss: 2.937232309684109
Validation loss: 2.803021515254518

Epoch: 5| Step: 2
Training loss: 3.36641519633406
Validation loss: 2.8069414454600863

Epoch: 5| Step: 3
Training loss: 3.217966225019494
Validation loss: 2.8077035254373404

Epoch: 5| Step: 4
Training loss: 3.1829076858542287
Validation loss: 2.808403218043906

Epoch: 5| Step: 5
Training loss: 3.394754874322781
Validation loss: 2.817668308941777

Epoch: 5| Step: 6
Training loss: 2.651816134441181
Validation loss: 2.8263137556919857

Epoch: 5| Step: 7
Training loss: 3.3817111506449637
Validation loss: 2.820887086929016

Epoch: 5| Step: 8
Training loss: 3.3424986877667084
Validation loss: 2.833073114272146

Epoch: 5| Step: 9
Training loss: 3.0152729995137553
Validation loss: 2.7913235793476847

Epoch: 5| Step: 10
Training loss: 2.8301372640366003
Validation loss: 2.7929084393264043

Epoch: 78| Step: 0
Training loss: 3.5225751883155634
Validation loss: 2.7974134513395237

Epoch: 5| Step: 1
Training loss: 3.2546574892005578
Validation loss: 2.8043362685524946

Epoch: 5| Step: 2
Training loss: 3.4926940414055907
Validation loss: 2.8051362398636606

Epoch: 5| Step: 3
Training loss: 2.7974741203467834
Validation loss: 2.799941224955057

Epoch: 5| Step: 4
Training loss: 2.87491673888013
Validation loss: 2.8002257128315633

Epoch: 5| Step: 5
Training loss: 2.9552218949969618
Validation loss: 2.788987867386793

Epoch: 5| Step: 6
Training loss: 3.302833127034889
Validation loss: 2.786863805193153

Epoch: 5| Step: 7
Training loss: 3.371855789992487
Validation loss: 2.7844532808351423

Epoch: 5| Step: 8
Training loss: 2.747847841994958
Validation loss: 2.7838250048019266

Epoch: 5| Step: 9
Training loss: 2.8074036943285674
Validation loss: 2.7808127202953257

Epoch: 5| Step: 10
Training loss: 2.918592271484314
Validation loss: 2.7662282575121093

Epoch: 79| Step: 0
Training loss: 3.1925224677410258
Validation loss: 2.756368885848467

Epoch: 5| Step: 1
Training loss: 3.067808882528649
Validation loss: 2.745575846629487

Epoch: 5| Step: 2
Training loss: 3.2974388761256317
Validation loss: 2.745841550515186

Epoch: 5| Step: 3
Training loss: 3.459166200534094
Validation loss: 2.744405250663303

Epoch: 5| Step: 4
Training loss: 3.069229206653298
Validation loss: 2.7429340268302385

Epoch: 5| Step: 5
Training loss: 3.0926467007108136
Validation loss: 2.7423870634702845

Epoch: 5| Step: 6
Training loss: 3.0772101112512
Validation loss: 2.7405265726167274

Epoch: 5| Step: 7
Training loss: 2.64387799397313
Validation loss: 2.7412453048207444

Epoch: 5| Step: 8
Training loss: 2.791566638198291
Validation loss: 2.735152738863651

Epoch: 5| Step: 9
Training loss: 3.2460535003333457
Validation loss: 2.733831830666738

Epoch: 5| Step: 10
Training loss: 2.687232248142416
Validation loss: 2.7339967565080596

Epoch: 80| Step: 0
Training loss: 3.0075796061925693
Validation loss: 2.735010923631624

Epoch: 5| Step: 1
Training loss: 2.6629971250546474
Validation loss: 2.7348284807965513

Epoch: 5| Step: 2
Training loss: 3.047697455101479
Validation loss: 2.731725396152126

Epoch: 5| Step: 3
Training loss: 2.9599177635213247
Validation loss: 2.7334838915261908

Epoch: 5| Step: 4
Training loss: 2.8138531290861417
Validation loss: 2.731196495871143

Epoch: 5| Step: 5
Training loss: 3.369247903636244
Validation loss: 2.730543877969974

Epoch: 5| Step: 6
Training loss: 3.1217448256104445
Validation loss: 2.7292086302057887

Epoch: 5| Step: 7
Training loss: 3.5825505103884945
Validation loss: 2.729669408294917

Epoch: 5| Step: 8
Training loss: 3.0714041053076335
Validation loss: 2.7295423949026985

Epoch: 5| Step: 9
Training loss: 2.867238389896639
Validation loss: 2.7281293127296506

Epoch: 5| Step: 10
Training loss: 2.9546782430405956
Validation loss: 2.7281217640575184

Epoch: 81| Step: 0
Training loss: 3.123849580726148
Validation loss: 2.731574003707668

Epoch: 5| Step: 1
Training loss: 2.7491262088083164
Validation loss: 2.73104727724311

Epoch: 5| Step: 2
Training loss: 2.8269269734609788
Validation loss: 2.738395758857434

Epoch: 5| Step: 3
Training loss: 3.387103524179369
Validation loss: 2.7371971649500217

Epoch: 5| Step: 4
Training loss: 3.0335087177031252
Validation loss: 2.738916221747458

Epoch: 5| Step: 5
Training loss: 3.445686164367055
Validation loss: 2.7725720532073526

Epoch: 5| Step: 6
Training loss: 2.4865056144609547
Validation loss: 2.7270687700545793

Epoch: 5| Step: 7
Training loss: 3.3593307137342525
Validation loss: 2.722090871535734

Epoch: 5| Step: 8
Training loss: 3.0338233957108156
Validation loss: 2.721142608211576

Epoch: 5| Step: 9
Training loss: 2.8014623433648906
Validation loss: 2.7219415097479014

Epoch: 5| Step: 10
Training loss: 3.1752893270993456
Validation loss: 2.724353687634079

Epoch: 82| Step: 0
Training loss: 2.8243184474374345
Validation loss: 2.7223884819364037

Epoch: 5| Step: 1
Training loss: 3.364305435530133
Validation loss: 2.7191388459493426

Epoch: 5| Step: 2
Training loss: 3.347683170882493
Validation loss: 2.718223916916603

Epoch: 5| Step: 3
Training loss: 2.728244645159512
Validation loss: 2.719642038317502

Epoch: 5| Step: 4
Training loss: 3.3448350518445378
Validation loss: 2.71977080823935

Epoch: 5| Step: 5
Training loss: 3.200633051958405
Validation loss: 2.717373082624622

Epoch: 5| Step: 6
Training loss: 2.4169249122581653
Validation loss: 2.718140491003475

Epoch: 5| Step: 7
Training loss: 2.6335182036521574
Validation loss: 2.718013687766119

Epoch: 5| Step: 8
Training loss: 2.93696573146925
Validation loss: 2.7215489157630888

Epoch: 5| Step: 9
Training loss: 3.4563518654020546
Validation loss: 2.7204595859513954

Epoch: 5| Step: 10
Training loss: 3.067410794105896
Validation loss: 2.7240599180374714

Epoch: 83| Step: 0
Training loss: 3.2119617174463366
Validation loss: 2.719292524910533

Epoch: 5| Step: 1
Training loss: 3.4050143739282093
Validation loss: 2.723653513504178

Epoch: 5| Step: 2
Training loss: 3.17151748822241
Validation loss: 2.7269164854407384

Epoch: 5| Step: 3
Training loss: 3.10393781053046
Validation loss: 2.743934274364782

Epoch: 5| Step: 4
Training loss: 2.8715653843065554
Validation loss: 2.714632343032435

Epoch: 5| Step: 5
Training loss: 3.1114398483648493
Validation loss: 2.714218517849965

Epoch: 5| Step: 6
Training loss: 2.910754906440288
Validation loss: 2.713400411567577

Epoch: 5| Step: 7
Training loss: 3.0531948179229254
Validation loss: 2.7154001634421276

Epoch: 5| Step: 8
Training loss: 2.686427589961426
Validation loss: 2.7125547414591797

Epoch: 5| Step: 9
Training loss: 3.0038816453498995
Validation loss: 2.7135329213411947

Epoch: 5| Step: 10
Training loss: 2.8560424729295844
Validation loss: 2.7135052094639946

Epoch: 84| Step: 0
Training loss: 3.0440563760517074
Validation loss: 2.7125777413614687

Epoch: 5| Step: 1
Training loss: 3.0021478593515645
Validation loss: 2.714164512346005

Epoch: 5| Step: 2
Training loss: 3.039867618087677
Validation loss: 2.7140929255569306

Epoch: 5| Step: 3
Training loss: 3.0209259720552066
Validation loss: 2.7126083565600068

Epoch: 5| Step: 4
Training loss: 2.9026509631948074
Validation loss: 2.7120458603145305

Epoch: 5| Step: 5
Training loss: 2.872461110143124
Validation loss: 2.7114466402167925

Epoch: 5| Step: 6
Training loss: 3.3108664749398113
Validation loss: 2.709436675266262

Epoch: 5| Step: 7
Training loss: 3.257934568025597
Validation loss: 2.710684711769798

Epoch: 5| Step: 8
Training loss: 3.3077042610143548
Validation loss: 2.710234385800034

Epoch: 5| Step: 9
Training loss: 2.7303176859923957
Validation loss: 2.7095183841241264

Epoch: 5| Step: 10
Training loss: 2.9363167185407693
Validation loss: 2.7083637431467085

Epoch: 85| Step: 0
Training loss: 2.9472187056197376
Validation loss: 2.7076883628737365

Epoch: 5| Step: 1
Training loss: 3.4652276928445604
Validation loss: 2.7114661181479653

Epoch: 5| Step: 2
Training loss: 3.0342958229805843
Validation loss: 2.7105011129679215

Epoch: 5| Step: 3
Training loss: 3.543983658987566
Validation loss: 2.726233289510122

Epoch: 5| Step: 4
Training loss: 3.323075596627082
Validation loss: 2.7391775934909193

Epoch: 5| Step: 5
Training loss: 2.5132329716194257
Validation loss: 2.728474830298223

Epoch: 5| Step: 6
Training loss: 1.9870739702145586
Validation loss: 2.713405706262766

Epoch: 5| Step: 7
Training loss: 3.260377893836866
Validation loss: 2.707455107582296

Epoch: 5| Step: 8
Training loss: 2.58148399936491
Validation loss: 2.703667650649493

Epoch: 5| Step: 9
Training loss: 3.1183752411949177
Validation loss: 2.7000868590773055

Epoch: 5| Step: 10
Training loss: 3.341646192175593
Validation loss: 2.70137142690291

Epoch: 86| Step: 0
Training loss: 3.1846890490264914
Validation loss: 2.7028174708188946

Epoch: 5| Step: 1
Training loss: 3.198762332464656
Validation loss: 2.705208593651531

Epoch: 5| Step: 2
Training loss: 3.535343194728993
Validation loss: 2.705583810190933

Epoch: 5| Step: 3
Training loss: 2.7980711526228887
Validation loss: 2.7077463746111623

Epoch: 5| Step: 4
Training loss: 3.0055089279039664
Validation loss: 2.7071201974132326

Epoch: 5| Step: 5
Training loss: 2.8989782111779103
Validation loss: 2.7086170148931554

Epoch: 5| Step: 6
Training loss: 3.078651964033839
Validation loss: 2.7045059323344174

Epoch: 5| Step: 7
Training loss: 2.6309514472103293
Validation loss: 2.7024103382092974

Epoch: 5| Step: 8
Training loss: 3.1711184346323056
Validation loss: 2.7019468745728648

Epoch: 5| Step: 9
Training loss: 2.8969726151003914
Validation loss: 2.698061889535776

Epoch: 5| Step: 10
Training loss: 2.83119751332118
Validation loss: 2.7034342570704464

Epoch: 87| Step: 0
Training loss: 2.88524130461635
Validation loss: 2.703636962655581

Epoch: 5| Step: 1
Training loss: 2.9974316093017714
Validation loss: 2.7008339123540286

Epoch: 5| Step: 2
Training loss: 2.5559853339811744
Validation loss: 2.70965203174685

Epoch: 5| Step: 3
Training loss: 3.6048674738170585
Validation loss: 2.7167071441054715

Epoch: 5| Step: 4
Training loss: 2.97789792519093
Validation loss: 2.6978180398863953

Epoch: 5| Step: 5
Training loss: 2.9205168969400774
Validation loss: 2.702132278484731

Epoch: 5| Step: 6
Training loss: 3.3550530599159045
Validation loss: 2.7058887625105292

Epoch: 5| Step: 7
Training loss: 3.22097804906993
Validation loss: 2.7060346827173896

Epoch: 5| Step: 8
Training loss: 2.988924722641845
Validation loss: 2.718649560480177

Epoch: 5| Step: 9
Training loss: 2.4059242919844728
Validation loss: 2.7145121370323158

Epoch: 5| Step: 10
Training loss: 3.1954174071161163
Validation loss: 2.7233093375773767

Epoch: 88| Step: 0
Training loss: 2.9401599933920544
Validation loss: 2.71611430218938

Epoch: 5| Step: 1
Training loss: 2.8207198506625275
Validation loss: 2.6945070104337323

Epoch: 5| Step: 2
Training loss: 3.0193384264414997
Validation loss: 2.693020027336671

Epoch: 5| Step: 3
Training loss: 2.981965375437008
Validation loss: 2.6973740863594435

Epoch: 5| Step: 4
Training loss: 3.154622933273524
Validation loss: 2.694250697640927

Epoch: 5| Step: 5
Training loss: 3.039976634638488
Validation loss: 2.6926594930867047

Epoch: 5| Step: 6
Training loss: 3.1620294514876353
Validation loss: 2.693017842593303

Epoch: 5| Step: 7
Training loss: 3.1093685590974434
Validation loss: 2.693728333368868

Epoch: 5| Step: 8
Training loss: 2.91185064976605
Validation loss: 2.6917659216111605

Epoch: 5| Step: 9
Training loss: 3.285293558088437
Validation loss: 2.6895283196654782

Epoch: 5| Step: 10
Training loss: 2.9089108663353183
Validation loss: 2.687826170687126

Epoch: 89| Step: 0
Training loss: 3.184614783066913
Validation loss: 2.6881774292758593

Epoch: 5| Step: 1
Training loss: 2.7022606675058065
Validation loss: 2.686830230648975

Epoch: 5| Step: 2
Training loss: 3.353943590284655
Validation loss: 2.6954731973422907

Epoch: 5| Step: 3
Training loss: 3.040585016377817
Validation loss: 2.703816750427782

Epoch: 5| Step: 4
Training loss: 2.833640100664298
Validation loss: 2.6916038123600523

Epoch: 5| Step: 5
Training loss: 2.6067539231053245
Validation loss: 2.6867565444055015

Epoch: 5| Step: 6
Training loss: 3.5312680944468657
Validation loss: 2.6845648119604464

Epoch: 5| Step: 7
Training loss: 3.1121448850467197
Validation loss: 2.6860311929639766

Epoch: 5| Step: 8
Training loss: 2.877218468595639
Validation loss: 2.6838996654211753

Epoch: 5| Step: 9
Training loss: 2.4754340552212795
Validation loss: 2.68570675347351

Epoch: 5| Step: 10
Training loss: 3.3289835364271814
Validation loss: 2.6834036669656265

Epoch: 90| Step: 0
Training loss: 3.006998640653191
Validation loss: 2.6861065464136735

Epoch: 5| Step: 1
Training loss: 3.1521731192203193
Validation loss: 2.686733194644717

Epoch: 5| Step: 2
Training loss: 3.164279506447222
Validation loss: 2.6861385942769576

Epoch: 5| Step: 3
Training loss: 3.207705465204289
Validation loss: 2.690238719998326

Epoch: 5| Step: 4
Training loss: 2.9884941075129543
Validation loss: 2.696870110924339

Epoch: 5| Step: 5
Training loss: 2.775712920018111
Validation loss: 2.6930067617761178

Epoch: 5| Step: 6
Training loss: 2.8192812230846442
Validation loss: 2.7014130380209083

Epoch: 5| Step: 7
Training loss: 3.220145358246249
Validation loss: 2.702880557164105

Epoch: 5| Step: 8
Training loss: 3.0446095970200515
Validation loss: 2.6937364609360497

Epoch: 5| Step: 9
Training loss: 3.087012149709031
Validation loss: 2.6840765521553434

Epoch: 5| Step: 10
Training loss: 2.563193901826984
Validation loss: 2.6799370611119615

Epoch: 91| Step: 0
Training loss: 2.6957594348933753
Validation loss: 2.6772476215465955

Epoch: 5| Step: 1
Training loss: 3.2263168721767523
Validation loss: 2.678373572117235

Epoch: 5| Step: 2
Training loss: 3.660822560373895
Validation loss: 2.6763634738320325

Epoch: 5| Step: 3
Training loss: 3.1852217367409494
Validation loss: 2.678391880672466

Epoch: 5| Step: 4
Training loss: 3.0299547712016004
Validation loss: 2.675991497577735

Epoch: 5| Step: 5
Training loss: 3.1106897382876655
Validation loss: 2.677023868340064

Epoch: 5| Step: 6
Training loss: 2.7089799744804743
Validation loss: 2.6745991037372603

Epoch: 5| Step: 7
Training loss: 2.6367896402507336
Validation loss: 2.672640850172181

Epoch: 5| Step: 8
Training loss: 2.7965109817341096
Validation loss: 2.6696785644177057

Epoch: 5| Step: 9
Training loss: 3.336415455368278
Validation loss: 2.6749037577233303

Epoch: 5| Step: 10
Training loss: 2.494364872517358
Validation loss: 2.672611045237489

Epoch: 92| Step: 0
Training loss: 2.982615006844285
Validation loss: 2.6740259554435433

Epoch: 5| Step: 1
Training loss: 3.135673453291377
Validation loss: 2.672437173935314

Epoch: 5| Step: 2
Training loss: 2.992812447485675
Validation loss: 2.6699152246941162

Epoch: 5| Step: 3
Training loss: 3.463619252342167
Validation loss: 2.6803926398587308

Epoch: 5| Step: 4
Training loss: 2.670373505888213
Validation loss: 2.6914376270520206

Epoch: 5| Step: 5
Training loss: 3.0999787176078453
Validation loss: 2.682155664860756

Epoch: 5| Step: 6
Training loss: 2.568654647505311
Validation loss: 2.67409993592229

Epoch: 5| Step: 7
Training loss: 2.762740878136964
Validation loss: 2.667947254668752

Epoch: 5| Step: 8
Training loss: 3.337149120845627
Validation loss: 2.6675269693300905

Epoch: 5| Step: 9
Training loss: 2.8568452577914214
Validation loss: 2.6695308826147413

Epoch: 5| Step: 10
Training loss: 3.1215105029174928
Validation loss: 2.673467263731464

Epoch: 93| Step: 0
Training loss: 3.2178890224877805
Validation loss: 2.673338332899454

Epoch: 5| Step: 1
Training loss: 2.7040868381968655
Validation loss: 2.6806932557394707

Epoch: 5| Step: 2
Training loss: 2.909318514069677
Validation loss: 2.68700887795702

Epoch: 5| Step: 3
Training loss: 3.4961248471033186
Validation loss: 2.690099349618826

Epoch: 5| Step: 4
Training loss: 3.109984218397914
Validation loss: 2.687480787173728

Epoch: 5| Step: 5
Training loss: 2.7676739188167447
Validation loss: 2.6883613758989413

Epoch: 5| Step: 6
Training loss: 3.411540271658314
Validation loss: 2.6921821610611687

Epoch: 5| Step: 7
Training loss: 2.8027631273024327
Validation loss: 2.68644548481527

Epoch: 5| Step: 8
Training loss: 2.906063278926997
Validation loss: 2.68901854641922

Epoch: 5| Step: 9
Training loss: 3.0871950315523957
Validation loss: 2.6896362504477755

Epoch: 5| Step: 10
Training loss: 2.4376776214830578
Validation loss: 2.6894664729072018

Epoch: 94| Step: 0
Training loss: 2.8477093308345856
Validation loss: 2.6941529516524003

Epoch: 5| Step: 1
Training loss: 3.2990060580990925
Validation loss: 2.6987805298169274

Epoch: 5| Step: 2
Training loss: 3.234361436603505
Validation loss: 2.6858939036077847

Epoch: 5| Step: 3
Training loss: 2.402955512331509
Validation loss: 2.664526014981424

Epoch: 5| Step: 4
Training loss: 3.2057729801228048
Validation loss: 2.662533715093521

Epoch: 5| Step: 5
Training loss: 3.339476947831084
Validation loss: 2.660293919345626

Epoch: 5| Step: 6
Training loss: 2.90736843451071
Validation loss: 2.659499792191712

Epoch: 5| Step: 7
Training loss: 2.7564778759236472
Validation loss: 2.661980411219956

Epoch: 5| Step: 8
Training loss: 3.0522854231413694
Validation loss: 2.6669829806517367

Epoch: 5| Step: 9
Training loss: 2.979284928826679
Validation loss: 2.6608900991095057

Epoch: 5| Step: 10
Training loss: 2.868517325612461
Validation loss: 2.6592842621880775

Epoch: 95| Step: 0
Training loss: 2.721267148806254
Validation loss: 2.656909980795775

Epoch: 5| Step: 1
Training loss: 2.547412932520598
Validation loss: 2.658197632587338

Epoch: 5| Step: 2
Training loss: 2.964445828760457
Validation loss: 2.6574963352286645

Epoch: 5| Step: 3
Training loss: 2.9772040208966963
Validation loss: 2.659795983936707

Epoch: 5| Step: 4
Training loss: 2.6999320869381824
Validation loss: 2.668074698216687

Epoch: 5| Step: 5
Training loss: 2.47706661448653
Validation loss: 2.6733180458962122

Epoch: 5| Step: 6
Training loss: 3.124654521918808
Validation loss: 2.6758795684004304

Epoch: 5| Step: 7
Training loss: 3.0766131565927854
Validation loss: 2.685395144594138

Epoch: 5| Step: 8
Training loss: 3.594824058248974
Validation loss: 2.6672435785047997

Epoch: 5| Step: 9
Training loss: 3.618883563329177
Validation loss: 2.657732198354468

Epoch: 5| Step: 10
Training loss: 3.024860687831116
Validation loss: 2.658022226251724

Epoch: 96| Step: 0
Training loss: 2.769329714739509
Validation loss: 2.6616746353695975

Epoch: 5| Step: 1
Training loss: 2.751110892897546
Validation loss: 2.6657538665519622

Epoch: 5| Step: 2
Training loss: 2.977776867912242
Validation loss: 2.6694595182986594

Epoch: 5| Step: 3
Training loss: 2.820576747867853
Validation loss: 2.6666594788495477

Epoch: 5| Step: 4
Training loss: 3.0160171174795556
Validation loss: 2.667064644421084

Epoch: 5| Step: 5
Training loss: 3.1520598140695504
Validation loss: 2.663335304271332

Epoch: 5| Step: 6
Training loss: 3.3068768258631382
Validation loss: 2.6618545163820917

Epoch: 5| Step: 7
Training loss: 2.9136510972789456
Validation loss: 2.6606473558695405

Epoch: 5| Step: 8
Training loss: 3.2845619562222748
Validation loss: 2.6600109443312956

Epoch: 5| Step: 9
Training loss: 2.751474332073813
Validation loss: 2.6591709877001906

Epoch: 5| Step: 10
Training loss: 3.262857825288947
Validation loss: 2.6520350399198533

Epoch: 97| Step: 0
Training loss: 2.9417631988968433
Validation loss: 2.6519769898313776

Epoch: 5| Step: 1
Training loss: 3.323791117792205
Validation loss: 2.652518001884731

Epoch: 5| Step: 2
Training loss: 3.5923759155505888
Validation loss: 2.6523924688432756

Epoch: 5| Step: 3
Training loss: 3.0823250402096494
Validation loss: 2.6559694744033244

Epoch: 5| Step: 4
Training loss: 3.136924727388321
Validation loss: 2.653026544091641

Epoch: 5| Step: 5
Training loss: 2.487060151437616
Validation loss: 2.6528673690714126

Epoch: 5| Step: 6
Training loss: 2.7143409318255047
Validation loss: 2.6532760630256194

Epoch: 5| Step: 7
Training loss: 2.945255997416833
Validation loss: 2.6565453651664885

Epoch: 5| Step: 8
Training loss: 3.1578493504023313
Validation loss: 2.660279397789984

Epoch: 5| Step: 9
Training loss: 2.4627979814740164
Validation loss: 2.6595603279361004

Epoch: 5| Step: 10
Training loss: 2.819319700875484
Validation loss: 2.6572170999150333

Epoch: 98| Step: 0
Training loss: 2.7355366882195558
Validation loss: 2.661524876785972

Epoch: 5| Step: 1
Training loss: 3.0425772849730834
Validation loss: 2.656549447231752

Epoch: 5| Step: 2
Training loss: 3.1959836670001063
Validation loss: 2.642721169501953

Epoch: 5| Step: 3
Training loss: 3.1329015400473965
Validation loss: 2.652236666887247

Epoch: 5| Step: 4
Training loss: 2.9874946306890657
Validation loss: 2.649752077039596

Epoch: 5| Step: 5
Training loss: 2.6538429573873366
Validation loss: 2.651617770425946

Epoch: 5| Step: 6
Training loss: 2.9121548951631766
Validation loss: 2.6544729263728963

Epoch: 5| Step: 7
Training loss: 2.8214308616256387
Validation loss: 2.6570463083563802

Epoch: 5| Step: 8
Training loss: 2.8807822420818177
Validation loss: 2.657348750118399

Epoch: 5| Step: 9
Training loss: 3.3787944797265292
Validation loss: 2.6526186911691516

Epoch: 5| Step: 10
Training loss: 3.0089321678175702
Validation loss: 2.6482679737692374

Epoch: 99| Step: 0
Training loss: 2.598553357778642
Validation loss: 2.65057542496861

Epoch: 5| Step: 1
Training loss: 3.061835080579773
Validation loss: 2.65346778883307

Epoch: 5| Step: 2
Training loss: 3.309364706425062
Validation loss: 2.6553411986036353

Epoch: 5| Step: 3
Training loss: 3.392531179960891
Validation loss: 2.6530464460954875

Epoch: 5| Step: 4
Training loss: 2.8787162645610187
Validation loss: 2.64503042007751

Epoch: 5| Step: 5
Training loss: 3.399859111335161
Validation loss: 2.6469341384935654

Epoch: 5| Step: 6
Training loss: 2.6305892114613387
Validation loss: 2.643410883149745

Epoch: 5| Step: 7
Training loss: 2.578075154140532
Validation loss: 2.639919002410031

Epoch: 5| Step: 8
Training loss: 3.2934955071534024
Validation loss: 2.643641495056808

Epoch: 5| Step: 9
Training loss: 2.7022541385293906
Validation loss: 2.644513425359348

Epoch: 5| Step: 10
Training loss: 2.7658280120304966
Validation loss: 2.639049796347778

Epoch: 100| Step: 0
Training loss: 2.336209182505151
Validation loss: 2.651778517003453

Epoch: 5| Step: 1
Training loss: 3.0035096937327634
Validation loss: 2.6892054231767273

Epoch: 5| Step: 2
Training loss: 3.1570512113480547
Validation loss: 2.732717041280138

Epoch: 5| Step: 3
Training loss: 2.771682312814758
Validation loss: 2.7610864205615937

Epoch: 5| Step: 4
Training loss: 3.0803247327659387
Validation loss: 2.682866748426157

Epoch: 5| Step: 5
Training loss: 3.15263567663546
Validation loss: 2.638149708312647

Epoch: 5| Step: 6
Training loss: 3.1823245648787095
Validation loss: 2.645981596911483

Epoch: 5| Step: 7
Training loss: 2.8847282681018904
Validation loss: 2.661768574405762

Epoch: 5| Step: 8
Training loss: 2.6987725646792615
Validation loss: 2.688525798491241

Epoch: 5| Step: 9
Training loss: 3.5247654072501704
Validation loss: 2.719494137065605

Epoch: 5| Step: 10
Training loss: 2.998427614769238
Validation loss: 2.6577174747043286

Epoch: 101| Step: 0
Training loss: 2.945237702651871
Validation loss: 2.649479169350149

Epoch: 5| Step: 1
Training loss: 2.913534244386513
Validation loss: 2.6429642826710755

Epoch: 5| Step: 2
Training loss: 3.00763351106032
Validation loss: 2.6369457783676844

Epoch: 5| Step: 3
Training loss: 2.550426978472815
Validation loss: 2.646882192702627

Epoch: 5| Step: 4
Training loss: 2.989352723552466
Validation loss: 2.677454364458518

Epoch: 5| Step: 5
Training loss: 3.192815201149513
Validation loss: 2.7156983362047864

Epoch: 5| Step: 6
Training loss: 2.5678626911020777
Validation loss: 2.6633216550258525

Epoch: 5| Step: 7
Training loss: 3.169371721118938
Validation loss: 2.6516030437624605

Epoch: 5| Step: 8
Training loss: 3.357782314585559
Validation loss: 2.6423404803419834

Epoch: 5| Step: 9
Training loss: 2.9943116618834473
Validation loss: 2.6358850738853405

Epoch: 5| Step: 10
Training loss: 3.09156244175964
Validation loss: 2.638263418931073

Epoch: 102| Step: 0
Training loss: 3.6958929981001565
Validation loss: 2.641621555432175

Epoch: 5| Step: 1
Training loss: 3.293776950327806
Validation loss: 2.6471567123364586

Epoch: 5| Step: 2
Training loss: 3.089379045382318
Validation loss: 2.6574959233091366

Epoch: 5| Step: 3
Training loss: 2.2184084777180306
Validation loss: 2.654239035679178

Epoch: 5| Step: 4
Training loss: 3.2434735424737995
Validation loss: 2.654984736356108

Epoch: 5| Step: 5
Training loss: 3.1871867306421575
Validation loss: 2.642067925859195

Epoch: 5| Step: 6
Training loss: 2.711777614612917
Validation loss: 2.63633503335648

Epoch: 5| Step: 7
Training loss: 2.558907013563592
Validation loss: 2.632676577833433

Epoch: 5| Step: 8
Training loss: 2.9125488277157046
Validation loss: 2.634920664923908

Epoch: 5| Step: 9
Training loss: 2.9746246036933717
Validation loss: 2.6297221732416274

Epoch: 5| Step: 10
Training loss: 2.6566344936565405
Validation loss: 2.6309397960949177

Epoch: 103| Step: 0
Training loss: 2.992216503510706
Validation loss: 2.632054601502224

Epoch: 5| Step: 1
Training loss: 3.177766486757696
Validation loss: 2.660872679835248

Epoch: 5| Step: 2
Training loss: 2.747423785942789
Validation loss: 2.7264284608168143

Epoch: 5| Step: 3
Training loss: 3.0875048556270333
Validation loss: 2.754886190505685

Epoch: 5| Step: 4
Training loss: 2.6936438661276023
Validation loss: 2.7912507522580743

Epoch: 5| Step: 5
Training loss: 3.7935030057087458
Validation loss: 2.8656039442215486

Epoch: 5| Step: 6
Training loss: 3.036013606084961
Validation loss: 2.6702651978245755

Epoch: 5| Step: 7
Training loss: 3.2166197310533398
Validation loss: 2.6337504254279405

Epoch: 5| Step: 8
Training loss: 2.562185593832428
Validation loss: 2.6852775717627635

Epoch: 5| Step: 9
Training loss: 2.622119049244455
Validation loss: 2.7875888877428134

Epoch: 5| Step: 10
Training loss: 3.5677697540713593
Validation loss: 2.9166797924771855

Epoch: 104| Step: 0
Training loss: 3.459189496670709
Validation loss: 2.9844985469892733

Epoch: 5| Step: 1
Training loss: 3.515430088997977
Validation loss: 3.0771003568098427

Epoch: 5| Step: 2
Training loss: 3.2044305885334006
Validation loss: 3.035629822757343

Epoch: 5| Step: 3
Training loss: 3.3214086540785215
Validation loss: 2.9693928979365376

Epoch: 5| Step: 4
Training loss: 2.6204108131631636
Validation loss: 2.894951982307696

Epoch: 5| Step: 5
Training loss: 3.6423000689784564
Validation loss: 2.8345569005060667

Epoch: 5| Step: 6
Training loss: 3.033093393358819
Validation loss: 2.7601274062894623

Epoch: 5| Step: 7
Training loss: 3.2819041735359153
Validation loss: 2.694685761482457

Epoch: 5| Step: 8
Training loss: 3.3035287832210307
Validation loss: 2.6556475656512584

Epoch: 5| Step: 9
Training loss: 2.685305919588102
Validation loss: 2.668586420314573

Epoch: 5| Step: 10
Training loss: 2.7471450377823268
Validation loss: 2.7323831323869996

Epoch: 105| Step: 0
Training loss: 3.315039183326089
Validation loss: 2.8548935998242477

Epoch: 5| Step: 1
Training loss: 2.874801463030667
Validation loss: 2.9189316464879997

Epoch: 5| Step: 2
Training loss: 3.0881694979029763
Validation loss: 2.925850221183034

Epoch: 5| Step: 3
Training loss: 3.2920446219125847
Validation loss: 2.8969827529303385

Epoch: 5| Step: 4
Training loss: 2.974660991939716
Validation loss: 2.784843136011386

Epoch: 5| Step: 5
Training loss: 2.8711987119419358
Validation loss: 2.705409754372239

Epoch: 5| Step: 6
Training loss: 2.8414058875145836
Validation loss: 2.672149031995128

Epoch: 5| Step: 7
Training loss: 3.3196424817998422
Validation loss: 2.648358931582841

Epoch: 5| Step: 8
Training loss: 3.232357261910869
Validation loss: 2.6401566397528256

Epoch: 5| Step: 9
Training loss: 3.0445099870753203
Validation loss: 2.6556456272192386

Epoch: 5| Step: 10
Training loss: 2.477445042036213
Validation loss: 2.6544753953919513

Epoch: 106| Step: 0
Training loss: 2.9205149376814874
Validation loss: 2.651543739399391

Epoch: 5| Step: 1
Training loss: 3.3957611419555604
Validation loss: 2.6509227310585484

Epoch: 5| Step: 2
Training loss: 3.2176525133765423
Validation loss: 2.6387799933704703

Epoch: 5| Step: 3
Training loss: 2.118293726581079
Validation loss: 2.6304283239342303

Epoch: 5| Step: 4
Training loss: 2.639830520565123
Validation loss: 2.628184507647685

Epoch: 5| Step: 5
Training loss: 2.861912169755567
Validation loss: 2.62495890622805

Epoch: 5| Step: 6
Training loss: 2.624819340619909
Validation loss: 2.625758876381135

Epoch: 5| Step: 7
Training loss: 2.2375618142907734
Validation loss: 2.631651898507957

Epoch: 5| Step: 8
Training loss: 3.3192974379019136
Validation loss: 2.6346951541564705

Epoch: 5| Step: 9
Training loss: 3.5783022374396802
Validation loss: 2.6538158210426324

Epoch: 5| Step: 10
Training loss: 3.3887173256588126
Validation loss: 2.6512907964276806

Epoch: 107| Step: 0
Training loss: 3.1296465089716063
Validation loss: 2.6446645853976007

Epoch: 5| Step: 1
Training loss: 3.5065305274625596
Validation loss: 2.6567955947896964

Epoch: 5| Step: 2
Training loss: 2.8702532517616013
Validation loss: 2.6376119783789838

Epoch: 5| Step: 3
Training loss: 2.5228322723494636
Validation loss: 2.6394629463036474

Epoch: 5| Step: 4
Training loss: 2.5513943319505463
Validation loss: 2.638855881980193

Epoch: 5| Step: 5
Training loss: 3.2415053052057092
Validation loss: 2.6382395787629243

Epoch: 5| Step: 6
Training loss: 3.0781984272055913
Validation loss: 2.628592374483696

Epoch: 5| Step: 7
Training loss: 2.7063110626591125
Validation loss: 2.6157805528885096

Epoch: 5| Step: 8
Training loss: 2.4866495336738375
Validation loss: 2.6126856604123194

Epoch: 5| Step: 9
Training loss: 2.9815196813010227
Validation loss: 2.612382432533821

Epoch: 5| Step: 10
Training loss: 3.395802425563707
Validation loss: 2.610837031033405

Epoch: 108| Step: 0
Training loss: 2.6920307027417785
Validation loss: 2.6044847962684425

Epoch: 5| Step: 1
Training loss: 2.732066286084369
Validation loss: 2.6027689569756403

Epoch: 5| Step: 2
Training loss: 2.928225709532863
Validation loss: 2.605611345460417

Epoch: 5| Step: 3
Training loss: 2.9244401249214333
Validation loss: 2.604807135465756

Epoch: 5| Step: 4
Training loss: 2.816648263889967
Validation loss: 2.6077061150591287

Epoch: 5| Step: 5
Training loss: 3.3974289373133675
Validation loss: 2.610106390444787

Epoch: 5| Step: 6
Training loss: 3.1957994010811572
Validation loss: 2.609013298106774

Epoch: 5| Step: 7
Training loss: 2.720653525268005
Validation loss: 2.6077033250146626

Epoch: 5| Step: 8
Training loss: 2.7272146587258743
Validation loss: 2.6058618992684104

Epoch: 5| Step: 9
Training loss: 3.2435351409019932
Validation loss: 2.6070509113879696

Epoch: 5| Step: 10
Training loss: 3.0634195932302535
Validation loss: 2.6107403491158174

Epoch: 109| Step: 0
Training loss: 2.77351469550358
Validation loss: 2.609758676645293

Epoch: 5| Step: 1
Training loss: 2.4528609212644246
Validation loss: 2.6152415103890525

Epoch: 5| Step: 2
Training loss: 2.763964051886502
Validation loss: 2.6185955160534187

Epoch: 5| Step: 3
Training loss: 3.4360534398604963
Validation loss: 2.628869930374153

Epoch: 5| Step: 4
Training loss: 2.9826210819808736
Validation loss: 2.632540833676223

Epoch: 5| Step: 5
Training loss: 3.0033487067921105
Validation loss: 2.6233914999768877

Epoch: 5| Step: 6
Training loss: 3.3512916010857383
Validation loss: 2.6200599272928184

Epoch: 5| Step: 7
Training loss: 2.9892860468590636
Validation loss: 2.6083527693983775

Epoch: 5| Step: 8
Training loss: 2.3882502310812757
Validation loss: 2.6063389325018034

Epoch: 5| Step: 9
Training loss: 3.0104209785474545
Validation loss: 2.6056096443102765

Epoch: 5| Step: 10
Training loss: 3.248261647054031
Validation loss: 2.605981993590885

Epoch: 110| Step: 0
Training loss: 3.145825383932078
Validation loss: 2.605998652398149

Epoch: 5| Step: 1
Training loss: 2.668427233865541
Validation loss: 2.603419798695987

Epoch: 5| Step: 2
Training loss: 3.083240267062169
Validation loss: 2.6060526329309144

Epoch: 5| Step: 3
Training loss: 2.9913572748239368
Validation loss: 2.6038660918659593

Epoch: 5| Step: 4
Training loss: 3.294510269007771
Validation loss: 2.604716617391386

Epoch: 5| Step: 5
Training loss: 2.805323451631545
Validation loss: 2.604274917485586

Epoch: 5| Step: 6
Training loss: 2.6793609509145355
Validation loss: 2.603141287139012

Epoch: 5| Step: 7
Training loss: 3.150917004517947
Validation loss: 2.603849283546082

Epoch: 5| Step: 8
Training loss: 2.3644929664137755
Validation loss: 2.6067287045864607

Epoch: 5| Step: 9
Training loss: 2.7546123492223957
Validation loss: 2.6088279596253376

Epoch: 5| Step: 10
Training loss: 3.4092573136840527
Validation loss: 2.6042883101734815

Epoch: 111| Step: 0
Training loss: 2.3923977530862564
Validation loss: 2.6222052602620263

Epoch: 5| Step: 1
Training loss: 2.4009233446956384
Validation loss: 2.6325274844151276

Epoch: 5| Step: 2
Training loss: 3.0233665280550865
Validation loss: 2.6257812994611016

Epoch: 5| Step: 3
Training loss: 3.1422879954637426
Validation loss: 2.6236319153345593

Epoch: 5| Step: 4
Training loss: 3.1748027349751764
Validation loss: 2.617563324589206

Epoch: 5| Step: 5
Training loss: 3.0560888017764243
Validation loss: 2.5985368702595033

Epoch: 5| Step: 6
Training loss: 2.967885905548266
Validation loss: 2.597767333681738

Epoch: 5| Step: 7
Training loss: 3.088642721254452
Validation loss: 2.5992415167823046

Epoch: 5| Step: 8
Training loss: 3.5330651943260825
Validation loss: 2.6121663998026348

Epoch: 5| Step: 9
Training loss: 2.71578853277208
Validation loss: 2.6123687869374894

Epoch: 5| Step: 10
Training loss: 2.8752190879604242
Validation loss: 2.612009110226609

Epoch: 112| Step: 0
Training loss: 3.313049990501651
Validation loss: 2.61367839420487

Epoch: 5| Step: 1
Training loss: 2.752689953312022
Validation loss: 2.6105472887889816

Epoch: 5| Step: 2
Training loss: 2.9593092334049875
Validation loss: 2.6053860677030882

Epoch: 5| Step: 3
Training loss: 3.087267316320677
Validation loss: 2.603565689800832

Epoch: 5| Step: 4
Training loss: 3.5012730599256514
Validation loss: 2.5963538480655144

Epoch: 5| Step: 5
Training loss: 3.20882032257165
Validation loss: 2.592256548238449

Epoch: 5| Step: 6
Training loss: 2.4111458649403694
Validation loss: 2.593800250329061

Epoch: 5| Step: 7
Training loss: 2.8627532846926496
Validation loss: 2.5920855700326926

Epoch: 5| Step: 8
Training loss: 2.8148422660474335
Validation loss: 2.6103416736609546

Epoch: 5| Step: 9
Training loss: 2.6410253999955455
Validation loss: 2.642809878561861

Epoch: 5| Step: 10
Training loss: 2.9568654748363676
Validation loss: 2.660882541779081

Epoch: 113| Step: 0
Training loss: 3.4529181370978117
Validation loss: 2.6075825342654926

Epoch: 5| Step: 1
Training loss: 3.297180161658234
Validation loss: 2.5893517936111836

Epoch: 5| Step: 2
Training loss: 2.915704259582186
Validation loss: 2.58961297636338

Epoch: 5| Step: 3
Training loss: 2.943571755101139
Validation loss: 2.592574386753311

Epoch: 5| Step: 4
Training loss: 2.9615590593077115
Validation loss: 2.5925700744195295

Epoch: 5| Step: 5
Training loss: 3.1880818752175766
Validation loss: 2.595580915515195

Epoch: 5| Step: 6
Training loss: 2.7284203787845267
Validation loss: 2.594909740791459

Epoch: 5| Step: 7
Training loss: 2.541577030122996
Validation loss: 2.595832543149214

Epoch: 5| Step: 8
Training loss: 2.8835153937513454
Validation loss: 2.5966594206104827

Epoch: 5| Step: 9
Training loss: 2.541975680051088
Validation loss: 2.5924498265383207

Epoch: 5| Step: 10
Training loss: 2.8321053330827546
Validation loss: 2.5911729594877286

Epoch: 114| Step: 0
Training loss: 2.5978650460905346
Validation loss: 2.5909669071149364

Epoch: 5| Step: 1
Training loss: 3.2815263904240974
Validation loss: 2.5903661720648907

Epoch: 5| Step: 2
Training loss: 2.8342000720164013
Validation loss: 2.5917912329598223

Epoch: 5| Step: 3
Training loss: 2.7625794101538523
Validation loss: 2.5840301255389173

Epoch: 5| Step: 4
Training loss: 3.088440162744776
Validation loss: 2.5879992908053886

Epoch: 5| Step: 5
Training loss: 3.040741836482949
Validation loss: 2.5874618846893287

Epoch: 5| Step: 6
Training loss: 2.726538453091712
Validation loss: 2.590326429071077

Epoch: 5| Step: 7
Training loss: 3.1320405613110687
Validation loss: 2.6075440073439373

Epoch: 5| Step: 8
Training loss: 2.833022960791972
Validation loss: 2.6262119921261187

Epoch: 5| Step: 9
Training loss: 2.7206068165664625
Validation loss: 2.613126203527179

Epoch: 5| Step: 10
Training loss: 3.290002683968884
Validation loss: 2.617184509461748

Epoch: 115| Step: 0
Training loss: 2.911014384279713
Validation loss: 2.6083078828657897

Epoch: 5| Step: 1
Training loss: 3.20901498530364
Validation loss: 2.6013422140478437

Epoch: 5| Step: 2
Training loss: 2.8584963589842425
Validation loss: 2.597087770825333

Epoch: 5| Step: 3
Training loss: 3.1230494706153222
Validation loss: 2.59826732611987

Epoch: 5| Step: 4
Training loss: 3.1959186156298616
Validation loss: 2.594873214053289

Epoch: 5| Step: 5
Training loss: 2.624965576672776
Validation loss: 2.594754236780714

Epoch: 5| Step: 6
Training loss: 2.115337844811762
Validation loss: 2.592871127505126

Epoch: 5| Step: 7
Training loss: 3.1189990599723494
Validation loss: 2.587271546240922

Epoch: 5| Step: 8
Training loss: 3.4343154027347906
Validation loss: 2.585000818522623

Epoch: 5| Step: 9
Training loss: 2.243011110677085
Validation loss: 2.582419559005934

Epoch: 5| Step: 10
Training loss: 3.15410730128859
Validation loss: 2.5837867144132485

Epoch: 116| Step: 0
Training loss: 3.048636998033116
Validation loss: 2.5830119373353653

Epoch: 5| Step: 1
Training loss: 3.172699468788446
Validation loss: 2.580479532837193

Epoch: 5| Step: 2
Training loss: 2.3191681682743095
Validation loss: 2.5803643657087347

Epoch: 5| Step: 3
Training loss: 2.798464701577299
Validation loss: 2.5832019013967136

Epoch: 5| Step: 4
Training loss: 3.1849022545779673
Validation loss: 2.580984574796092

Epoch: 5| Step: 5
Training loss: 2.705366230850027
Validation loss: 2.5876096256291485

Epoch: 5| Step: 6
Training loss: 2.7191255682753206
Validation loss: 2.5911911401710666

Epoch: 5| Step: 7
Training loss: 3.086657630819301
Validation loss: 2.59052810977603

Epoch: 5| Step: 8
Training loss: 2.7930784403995625
Validation loss: 2.5995212262412406

Epoch: 5| Step: 9
Training loss: 3.147552593055405
Validation loss: 2.5987053661588373

Epoch: 5| Step: 10
Training loss: 3.1985168059579747
Validation loss: 2.59431290995288

Epoch: 117| Step: 0
Training loss: 2.997654315708263
Validation loss: 2.599706322954507

Epoch: 5| Step: 1
Training loss: 3.1490025167155333
Validation loss: 2.608869411647267

Epoch: 5| Step: 2
Training loss: 2.4694259297673664
Validation loss: 2.594689268939125

Epoch: 5| Step: 3
Training loss: 2.575494059599341
Validation loss: 2.595767928705369

Epoch: 5| Step: 4
Training loss: 2.8006624970738385
Validation loss: 2.5898004680221542

Epoch: 5| Step: 5
Training loss: 3.458943431919951
Validation loss: 2.58807682493562

Epoch: 5| Step: 6
Training loss: 3.008427861666711
Validation loss: 2.5824394790125065

Epoch: 5| Step: 7
Training loss: 2.9554516542985434
Validation loss: 2.5785553046997487

Epoch: 5| Step: 8
Training loss: 3.1779538989075253
Validation loss: 2.576702326241684

Epoch: 5| Step: 9
Training loss: 2.979426410440354
Validation loss: 2.5794978697988036

Epoch: 5| Step: 10
Training loss: 2.464313141648463
Validation loss: 2.578271070551681

Epoch: 118| Step: 0
Training loss: 2.662341683565667
Validation loss: 2.579175591970652

Epoch: 5| Step: 1
Training loss: 3.122306120376152
Validation loss: 2.5838376660095888

Epoch: 5| Step: 2
Training loss: 3.227406536849915
Validation loss: 2.5862892723802093

Epoch: 5| Step: 3
Training loss: 3.0997498257502603
Validation loss: 2.579903236381298

Epoch: 5| Step: 4
Training loss: 2.900365306602457
Validation loss: 2.5771490353498643

Epoch: 5| Step: 5
Training loss: 2.796649433608795
Validation loss: 2.580508803410627

Epoch: 5| Step: 6
Training loss: 3.14453974183636
Validation loss: 2.574440579089718

Epoch: 5| Step: 7
Training loss: 2.7228728855371593
Validation loss: 2.5728923438918114

Epoch: 5| Step: 8
Training loss: 3.292767175769967
Validation loss: 2.573689918524606

Epoch: 5| Step: 9
Training loss: 2.30035821364234
Validation loss: 2.5711656447367526

Epoch: 5| Step: 10
Training loss: 2.726016014443906
Validation loss: 2.569969982519198

Epoch: 119| Step: 0
Training loss: 2.940874150390087
Validation loss: 2.570885676236051

Epoch: 5| Step: 1
Training loss: 2.9473999073741686
Validation loss: 2.5715583649120335

Epoch: 5| Step: 2
Training loss: 2.574766526239289
Validation loss: 2.5720327429197445

Epoch: 5| Step: 3
Training loss: 2.7004593069976077
Validation loss: 2.5748281002759574

Epoch: 5| Step: 4
Training loss: 3.04183935084556
Validation loss: 2.5776074518642176

Epoch: 5| Step: 5
Training loss: 3.1282348674492604
Validation loss: 2.5776216534540546

Epoch: 5| Step: 6
Training loss: 3.124121275380668
Validation loss: 2.572903627147782

Epoch: 5| Step: 7
Training loss: 2.8788121698501525
Validation loss: 2.5809585964174246

Epoch: 5| Step: 8
Training loss: 3.0740752713798156
Validation loss: 2.584203703142028

Epoch: 5| Step: 9
Training loss: 2.7595660548528627
Validation loss: 2.5871110080101576

Epoch: 5| Step: 10
Training loss: 2.8710037321134867
Validation loss: 2.594864142554407

Epoch: 120| Step: 0
Training loss: 2.9427670273230278
Validation loss: 2.599730800484033

Epoch: 5| Step: 1
Training loss: 2.856575350939601
Validation loss: 2.6316719660540366

Epoch: 5| Step: 2
Training loss: 2.9391343460346495
Validation loss: 2.656931126397758

Epoch: 5| Step: 3
Training loss: 2.843598078767345
Validation loss: 2.6286493152156223

Epoch: 5| Step: 4
Training loss: 3.1417973545998485
Validation loss: 2.587862048154821

Epoch: 5| Step: 5
Training loss: 2.8300334750510756
Validation loss: 2.5713724553474315

Epoch: 5| Step: 6
Training loss: 2.984917396667653
Validation loss: 2.577421452449052

Epoch: 5| Step: 7
Training loss: 3.227088275771833
Validation loss: 2.5752136189250914

Epoch: 5| Step: 8
Training loss: 3.168458197586567
Validation loss: 2.574958384418803

Epoch: 5| Step: 9
Training loss: 2.3812081360829027
Validation loss: 2.581489006509464

Epoch: 5| Step: 10
Training loss: 3.02249469892291
Validation loss: 2.58118278517011

Epoch: 121| Step: 0
Training loss: 2.6173276949099678
Validation loss: 2.588648576340895

Epoch: 5| Step: 1
Training loss: 2.9669518094419365
Validation loss: 2.5820710164219007

Epoch: 5| Step: 2
Training loss: 2.693334589035698
Validation loss: 2.5842706334178245

Epoch: 5| Step: 3
Training loss: 2.9332377577152067
Validation loss: 2.5886595661137073

Epoch: 5| Step: 4
Training loss: 2.690347094921007
Validation loss: 2.586375742000885

Epoch: 5| Step: 5
Training loss: 2.736846417305905
Validation loss: 2.5836334070776044

Epoch: 5| Step: 6
Training loss: 3.3078469758901727
Validation loss: 2.5814108444912027

Epoch: 5| Step: 7
Training loss: 3.5631238156972276
Validation loss: 2.5765720287930276

Epoch: 5| Step: 8
Training loss: 2.4950480054009723
Validation loss: 2.5782477604739373

Epoch: 5| Step: 9
Training loss: 3.1249325554245404
Validation loss: 2.5776425016718703

Epoch: 5| Step: 10
Training loss: 2.9551005542254387
Validation loss: 2.578962057040492

Epoch: 122| Step: 0
Training loss: 3.156093631307937
Validation loss: 2.5819171698309087

Epoch: 5| Step: 1
Training loss: 3.117470635197053
Validation loss: 2.5855208518748185

Epoch: 5| Step: 2
Training loss: 2.97098561485606
Validation loss: 2.599445630165689

Epoch: 5| Step: 3
Training loss: 2.610780714202667
Validation loss: 2.6017236649512276

Epoch: 5| Step: 4
Training loss: 2.523248907547267
Validation loss: 2.6039168952196166

Epoch: 5| Step: 5
Training loss: 2.793396902279035
Validation loss: 2.606783598869947

Epoch: 5| Step: 6
Training loss: 3.024972294451992
Validation loss: 2.5911382777194123

Epoch: 5| Step: 7
Training loss: 2.806928329215982
Validation loss: 2.588723230018187

Epoch: 5| Step: 8
Training loss: 2.942450389978623
Validation loss: 2.590361581912375

Epoch: 5| Step: 9
Training loss: 3.066387278504211
Validation loss: 2.587984939128924

Epoch: 5| Step: 10
Training loss: 3.026631878248199
Validation loss: 2.5841015514696353

Epoch: 123| Step: 0
Training loss: 2.5529697254267063
Validation loss: 2.5929362175259185

Epoch: 5| Step: 1
Training loss: 3.554261703979601
Validation loss: 2.5879229312055836

Epoch: 5| Step: 2
Training loss: 2.9182511158560898
Validation loss: 2.591935805375413

Epoch: 5| Step: 3
Training loss: 2.975191215973596
Validation loss: 2.5932927000949193

Epoch: 5| Step: 4
Training loss: 2.8249969043545935
Validation loss: 2.5878544261565346

Epoch: 5| Step: 5
Training loss: 3.10797961952273
Validation loss: 2.593819740959993

Epoch: 5| Step: 6
Training loss: 2.6234794935963026
Validation loss: 2.5808088684903847

Epoch: 5| Step: 7
Training loss: 3.0729892700583976
Validation loss: 2.5766106894910767

Epoch: 5| Step: 8
Training loss: 2.9760743389176554
Validation loss: 2.569721570785168

Epoch: 5| Step: 9
Training loss: 2.52767135642957
Validation loss: 2.567265254405594

Epoch: 5| Step: 10
Training loss: 2.735244002537611
Validation loss: 2.5594128035825636

Epoch: 124| Step: 0
Training loss: 2.8508637708793287
Validation loss: 2.5619171424124243

Epoch: 5| Step: 1
Training loss: 3.080296249261641
Validation loss: 2.5656249747795217

Epoch: 5| Step: 2
Training loss: 2.722217409514587
Validation loss: 2.5642023142200694

Epoch: 5| Step: 3
Training loss: 2.7514070899134992
Validation loss: 2.561562668599064

Epoch: 5| Step: 4
Training loss: 3.0371580457314
Validation loss: 2.5577008662432354

Epoch: 5| Step: 5
Training loss: 3.5015564591212254
Validation loss: 2.560574278924151

Epoch: 5| Step: 6
Training loss: 2.987111539604208
Validation loss: 2.5604864733967547

Epoch: 5| Step: 7
Training loss: 1.775936970090611
Validation loss: 2.563913660211931

Epoch: 5| Step: 8
Training loss: 3.0160278683697874
Validation loss: 2.5633647039007026

Epoch: 5| Step: 9
Training loss: 2.8071765109325586
Validation loss: 2.566902840190429

Epoch: 5| Step: 10
Training loss: 3.2286382099194326
Validation loss: 2.5703973886721303

Epoch: 125| Step: 0
Training loss: 2.442159063621534
Validation loss: 2.5836248021692794

Epoch: 5| Step: 1
Training loss: 3.09279625573758
Validation loss: 2.592081090728998

Epoch: 5| Step: 2
Training loss: 2.8134660545187318
Validation loss: 2.5782255797593745

Epoch: 5| Step: 3
Training loss: 3.28056459080199
Validation loss: 2.576902150354682

Epoch: 5| Step: 4
Training loss: 3.2019753975051133
Validation loss: 2.5653889516041453

Epoch: 5| Step: 5
Training loss: 2.846713858607086
Validation loss: 2.5591576500983693

Epoch: 5| Step: 6
Training loss: 2.7851984521094826
Validation loss: 2.5549063630042697

Epoch: 5| Step: 7
Training loss: 2.705955566881641
Validation loss: 2.554911916418627

Epoch: 5| Step: 8
Training loss: 3.052403681654641
Validation loss: 2.557554653810166

Epoch: 5| Step: 9
Training loss: 3.3511165864676555
Validation loss: 2.5589029640832504

Epoch: 5| Step: 10
Training loss: 2.200710407345108
Validation loss: 2.560386258138669

Epoch: 126| Step: 0
Training loss: 3.0098782666198654
Validation loss: 2.557069423973051

Epoch: 5| Step: 1
Training loss: 2.7567646748449794
Validation loss: 2.5572883397586073

Epoch: 5| Step: 2
Training loss: 3.0247547523138976
Validation loss: 2.55446909695654

Epoch: 5| Step: 3
Training loss: 2.6916928076483484
Validation loss: 2.55841275629946

Epoch: 5| Step: 4
Training loss: 2.9311874415507586
Validation loss: 2.555760288092717

Epoch: 5| Step: 5
Training loss: 3.3290073138609575
Validation loss: 2.561919419942558

Epoch: 5| Step: 6
Training loss: 3.0695733109969003
Validation loss: 2.569085327996847

Epoch: 5| Step: 7
Training loss: 2.643018642115871
Validation loss: 2.5710866055207493

Epoch: 5| Step: 8
Training loss: 2.870491971638437
Validation loss: 2.5812308081151016

Epoch: 5| Step: 9
Training loss: 2.841652903891728
Validation loss: 2.574895856698486

Epoch: 5| Step: 10
Training loss: 2.7711243345187637
Validation loss: 2.565595627327403

Epoch: 127| Step: 0
Training loss: 3.144284066857004
Validation loss: 2.5584731196842476

Epoch: 5| Step: 1
Training loss: 3.1045350404501497
Validation loss: 2.5561589465279475

Epoch: 5| Step: 2
Training loss: 2.991367954936552
Validation loss: 2.5542885005036005

Epoch: 5| Step: 3
Training loss: 2.473885711139418
Validation loss: 2.552295751481393

Epoch: 5| Step: 4
Training loss: 2.865925440955796
Validation loss: 2.55144297987617

Epoch: 5| Step: 5
Training loss: 2.870542470724464
Validation loss: 2.5572418070355756

Epoch: 5| Step: 6
Training loss: 2.7786073452620625
Validation loss: 2.5488326692522985

Epoch: 5| Step: 7
Training loss: 2.9145635015664157
Validation loss: 2.5607926117737057

Epoch: 5| Step: 8
Training loss: 2.9641662547322407
Validation loss: 2.558970467943326

Epoch: 5| Step: 9
Training loss: 2.8987730916737373
Validation loss: 2.560627360865622

Epoch: 5| Step: 10
Training loss: 2.9016603715256077
Validation loss: 2.5642281754235907

Epoch: 128| Step: 0
Training loss: 2.625455544317128
Validation loss: 2.5690413619953936

Epoch: 5| Step: 1
Training loss: 2.818212091585365
Validation loss: 2.5674530290424764

Epoch: 5| Step: 2
Training loss: 2.8487401084845345
Validation loss: 2.556442982719991

Epoch: 5| Step: 3
Training loss: 2.098553286359657
Validation loss: 2.5511585477858834

Epoch: 5| Step: 4
Training loss: 3.020393988570267
Validation loss: 2.5526919943536086

Epoch: 5| Step: 5
Training loss: 3.20985308896251
Validation loss: 2.5514403031390107

Epoch: 5| Step: 6
Training loss: 3.1551753565787304
Validation loss: 2.553652306736189

Epoch: 5| Step: 7
Training loss: 2.7413169587564075
Validation loss: 2.55748523407055

Epoch: 5| Step: 8
Training loss: 3.24980353715272
Validation loss: 2.553784139988619

Epoch: 5| Step: 9
Training loss: 3.0330009515888494
Validation loss: 2.559060883057563

Epoch: 5| Step: 10
Training loss: 2.9156537249786596
Validation loss: 2.5567270926413386

Epoch: 129| Step: 0
Training loss: 3.0447757629612577
Validation loss: 2.553315010390072

Epoch: 5| Step: 1
Training loss: 2.7831333941374403
Validation loss: 2.558745466185271

Epoch: 5| Step: 2
Training loss: 2.6821596181025433
Validation loss: 2.5561547011347425

Epoch: 5| Step: 3
Training loss: 3.581422310989493
Validation loss: 2.5601450465883446

Epoch: 5| Step: 4
Training loss: 2.877591333605199
Validation loss: 2.5585808185099372

Epoch: 5| Step: 5
Training loss: 2.601940047444992
Validation loss: 2.5483965611337243

Epoch: 5| Step: 6
Training loss: 3.18538281306525
Validation loss: 2.5471254919233544

Epoch: 5| Step: 7
Training loss: 2.757681349102404
Validation loss: 2.546698801647208

Epoch: 5| Step: 8
Training loss: 2.5389102831476347
Validation loss: 2.5452562909707863

Epoch: 5| Step: 9
Training loss: 2.6559343038212746
Validation loss: 2.5461827242015818

Epoch: 5| Step: 10
Training loss: 3.0275039335141827
Validation loss: 2.5528941165971957

Epoch: 130| Step: 0
Training loss: 3.2933675178370154
Validation loss: 2.5493048441210404

Epoch: 5| Step: 1
Training loss: 3.156788090831413
Validation loss: 2.549812287505906

Epoch: 5| Step: 2
Training loss: 2.6774969906972577
Validation loss: 2.549523761955072

Epoch: 5| Step: 3
Training loss: 2.0327234645993326
Validation loss: 2.5482525879892

Epoch: 5| Step: 4
Training loss: 2.5108492994217593
Validation loss: 2.5659961795807376

Epoch: 5| Step: 5
Training loss: 2.791671430289536
Validation loss: 2.568799180750473

Epoch: 5| Step: 6
Training loss: 2.895784299879012
Validation loss: 2.576226939251056

Epoch: 5| Step: 7
Training loss: 2.854659397632099
Validation loss: 2.6055384803381734

Epoch: 5| Step: 8
Training loss: 3.1350032157820618
Validation loss: 2.5997068485601527

Epoch: 5| Step: 9
Training loss: 3.0374605717866845
Validation loss: 2.5612713889539123

Epoch: 5| Step: 10
Training loss: 3.4383534152365502
Validation loss: 2.54138047899928

Epoch: 131| Step: 0
Training loss: 3.211741845584452
Validation loss: 2.5381209462324894

Epoch: 5| Step: 1
Training loss: 3.2227805373760474
Validation loss: 2.5536007784564254

Epoch: 5| Step: 2
Training loss: 2.8497107777323003
Validation loss: 2.554455334684459

Epoch: 5| Step: 3
Training loss: 2.9928900389451805
Validation loss: 2.5573567323122455

Epoch: 5| Step: 4
Training loss: 2.580367159482227
Validation loss: 2.564155805987888

Epoch: 5| Step: 5
Training loss: 2.4020918551247252
Validation loss: 2.563979301380863

Epoch: 5| Step: 6
Training loss: 2.873630695164635
Validation loss: 2.563376731167017

Epoch: 5| Step: 7
Training loss: 2.936610147954913
Validation loss: 2.5587401229770603

Epoch: 5| Step: 8
Training loss: 2.8829941110858455
Validation loss: 2.555986230658591

Epoch: 5| Step: 9
Training loss: 3.3191871082220126
Validation loss: 2.5524164979775463

Epoch: 5| Step: 10
Training loss: 2.892439978660122
Validation loss: 2.5487968863150514

Epoch: 132| Step: 0
Training loss: 3.002744531893434
Validation loss: 2.5440684636582187

Epoch: 5| Step: 1
Training loss: 2.900868180644727
Validation loss: 2.545413128887199

Epoch: 5| Step: 2
Training loss: 3.332039263985087
Validation loss: 2.5406587617208025

Epoch: 5| Step: 3
Training loss: 2.6594609319517897
Validation loss: 2.5409150433593153

Epoch: 5| Step: 4
Training loss: 2.645542058656156
Validation loss: 2.5525444981929275

Epoch: 5| Step: 5
Training loss: 3.0912448489049438
Validation loss: 2.5827061680450085

Epoch: 5| Step: 6
Training loss: 3.20858210470289
Validation loss: 2.5954878789650815

Epoch: 5| Step: 7
Training loss: 2.851006440593251
Validation loss: 2.6276019200526464

Epoch: 5| Step: 8
Training loss: 2.8245724447329073
Validation loss: 2.6488700675823336

Epoch: 5| Step: 9
Training loss: 2.7786693816302916
Validation loss: 2.6316037396697136

Epoch: 5| Step: 10
Training loss: 2.634936101670721
Validation loss: 2.5717802719545344

Epoch: 133| Step: 0
Training loss: 2.8716882622147195
Validation loss: 2.543747922439898

Epoch: 5| Step: 1
Training loss: 3.0856605888417556
Validation loss: 2.534795435632271

Epoch: 5| Step: 2
Training loss: 2.813156136164797
Validation loss: 2.532850508212291

Epoch: 5| Step: 3
Training loss: 2.5088603364851303
Validation loss: 2.5351716288266624

Epoch: 5| Step: 4
Training loss: 3.1683001738820913
Validation loss: 2.5388572126497704

Epoch: 5| Step: 5
Training loss: 3.2344839473932816
Validation loss: 2.5427042717402624

Epoch: 5| Step: 6
Training loss: 2.9432720533351735
Validation loss: 2.5397372219041627

Epoch: 5| Step: 7
Training loss: 3.10676841170842
Validation loss: 2.5483707947908596

Epoch: 5| Step: 8
Training loss: 2.3780124031109184
Validation loss: 2.549502832620738

Epoch: 5| Step: 9
Training loss: 2.9778639784082426
Validation loss: 2.5460980451546673

Epoch: 5| Step: 10
Training loss: 2.9186048516526406
Validation loss: 2.548298731546934

Epoch: 134| Step: 0
Training loss: 3.333662557238244
Validation loss: 2.5458762599196034

Epoch: 5| Step: 1
Training loss: 2.9316494081938713
Validation loss: 2.5437996049522917

Epoch: 5| Step: 2
Training loss: 2.745725604323615
Validation loss: 2.5399358905953426

Epoch: 5| Step: 3
Training loss: 2.6037336574413334
Validation loss: 2.5405342141833014

Epoch: 5| Step: 4
Training loss: 3.0973471334573914
Validation loss: 2.5478309212908337

Epoch: 5| Step: 5
Training loss: 2.745225663350557
Validation loss: 2.5430928204382215

Epoch: 5| Step: 6
Training loss: 2.6573213099839146
Validation loss: 2.5416983291964286

Epoch: 5| Step: 7
Training loss: 2.766395763171577
Validation loss: 2.543209127007772

Epoch: 5| Step: 8
Training loss: 3.095970512900284
Validation loss: 2.5348759219733625

Epoch: 5| Step: 9
Training loss: 2.5879721574715404
Validation loss: 2.537507491214609

Epoch: 5| Step: 10
Training loss: 3.381354671980538
Validation loss: 2.535789207598209

Epoch: 135| Step: 0
Training loss: 3.219486041308181
Validation loss: 2.5374294545395517

Epoch: 5| Step: 1
Training loss: 3.0539370344224985
Validation loss: 2.5379613354224895

Epoch: 5| Step: 2
Training loss: 3.139953085919422
Validation loss: 2.526972289830645

Epoch: 5| Step: 3
Training loss: 2.530200599437676
Validation loss: 2.524993486862043

Epoch: 5| Step: 4
Training loss: 2.9966831945430985
Validation loss: 2.525020136469121

Epoch: 5| Step: 5
Training loss: 2.4905511632143065
Validation loss: 2.5283610626069803

Epoch: 5| Step: 6
Training loss: 2.7698970924294146
Validation loss: 2.5251666169704046

Epoch: 5| Step: 7
Training loss: 2.7860534849215486
Validation loss: 2.523762928734054

Epoch: 5| Step: 8
Training loss: 3.1433473241932233
Validation loss: 2.523874244851541

Epoch: 5| Step: 9
Training loss: 2.633915882218578
Validation loss: 2.5242123714674203

Epoch: 5| Step: 10
Training loss: 2.9971089738158896
Validation loss: 2.525008361048802

Epoch: 136| Step: 0
Training loss: 2.9900230766605134
Validation loss: 2.524232847299726

Epoch: 5| Step: 1
Training loss: 2.8832456681994545
Validation loss: 2.526301313900017

Epoch: 5| Step: 2
Training loss: 3.0486761002696676
Validation loss: 2.5248352302423918

Epoch: 5| Step: 3
Training loss: 3.1711524177907866
Validation loss: 2.5316923487471006

Epoch: 5| Step: 4
Training loss: 2.778696152083388
Validation loss: 2.534371625030291

Epoch: 5| Step: 5
Training loss: 2.642640016540097
Validation loss: 2.5381686940925796

Epoch: 5| Step: 6
Training loss: 2.8678636299389755
Validation loss: 2.541935137107967

Epoch: 5| Step: 7
Training loss: 2.948266286078639
Validation loss: 2.5538806572541826

Epoch: 5| Step: 8
Training loss: 2.94986072146839
Validation loss: 2.5694258900860927

Epoch: 5| Step: 9
Training loss: 2.7295947333711035
Validation loss: 2.574257094993812

Epoch: 5| Step: 10
Training loss: 2.7486563781365616
Validation loss: 2.5572011923398685

Epoch: 137| Step: 0
Training loss: 2.4517999459904334
Validation loss: 2.5407579610787403

Epoch: 5| Step: 1
Training loss: 3.033991881206918
Validation loss: 2.5254431349203244

Epoch: 5| Step: 2
Training loss: 2.81015773303343
Validation loss: 2.52171674554785

Epoch: 5| Step: 3
Training loss: 2.7457976744617563
Validation loss: 2.5288336738897748

Epoch: 5| Step: 4
Training loss: 2.566474437533556
Validation loss: 2.5312042829749455

Epoch: 5| Step: 5
Training loss: 3.02803451040701
Validation loss: 2.5333409678706276

Epoch: 5| Step: 6
Training loss: 3.3814680498083964
Validation loss: 2.530703088643291

Epoch: 5| Step: 7
Training loss: 3.2193121558076285
Validation loss: 2.5419449168915094

Epoch: 5| Step: 8
Training loss: 2.5392558332344124
Validation loss: 2.531451765795188

Epoch: 5| Step: 9
Training loss: 2.9744397701770886
Validation loss: 2.5380504434450057

Epoch: 5| Step: 10
Training loss: 3.0728707175402463
Validation loss: 2.5294680402984437

Epoch: 138| Step: 0
Training loss: 2.986279264540608
Validation loss: 2.5207973597322613

Epoch: 5| Step: 1
Training loss: 2.9790078678801923
Validation loss: 2.519312370671022

Epoch: 5| Step: 2
Training loss: 3.140929553699623
Validation loss: 2.5246210969998804

Epoch: 5| Step: 3
Training loss: 2.3530174646211734
Validation loss: 2.5364916557681454

Epoch: 5| Step: 4
Training loss: 3.073709331800339
Validation loss: 2.556535689325933

Epoch: 5| Step: 5
Training loss: 2.9980987246127193
Validation loss: 2.5729222876553917

Epoch: 5| Step: 6
Training loss: 2.711731896001789
Validation loss: 2.587221253333333

Epoch: 5| Step: 7
Training loss: 2.642137083252725
Validation loss: 2.611890283391025

Epoch: 5| Step: 8
Training loss: 2.9775363400385224
Validation loss: 2.599654924520275

Epoch: 5| Step: 9
Training loss: 2.6265680080449108
Validation loss: 2.61044924088583

Epoch: 5| Step: 10
Training loss: 3.3455930960089124
Validation loss: 2.633088817539884

Epoch: 139| Step: 0
Training loss: 2.83554990867855
Validation loss: 2.6170697311378928

Epoch: 5| Step: 1
Training loss: 2.7221389344724045
Validation loss: 2.5928812105193146

Epoch: 5| Step: 2
Training loss: 3.1946167130022287
Validation loss: 2.5706981692875397

Epoch: 5| Step: 3
Training loss: 2.984686071351398
Validation loss: 2.548127221421096

Epoch: 5| Step: 4
Training loss: 2.6075708239584268
Validation loss: 2.5470286290966797

Epoch: 5| Step: 5
Training loss: 2.7550097696231486
Validation loss: 2.5505251385355474

Epoch: 5| Step: 6
Training loss: 2.779152582944065
Validation loss: 2.548398308020573

Epoch: 5| Step: 7
Training loss: 3.4687464258673875
Validation loss: 2.5525695816382217

Epoch: 5| Step: 8
Training loss: 2.4808011050101597
Validation loss: 2.544662881341101

Epoch: 5| Step: 9
Training loss: 2.8716354585687194
Validation loss: 2.5497861172090293

Epoch: 5| Step: 10
Training loss: 3.2646796943612864
Validation loss: 2.541287274003641

Epoch: 140| Step: 0
Training loss: 2.821249512962668
Validation loss: 2.5400061301038797

Epoch: 5| Step: 1
Training loss: 3.1200806617091312
Validation loss: 2.543466855074383

Epoch: 5| Step: 2
Training loss: 2.6180269176244635
Validation loss: 2.536110923538345

Epoch: 5| Step: 3
Training loss: 2.9837853613149625
Validation loss: 2.5339366874658547

Epoch: 5| Step: 4
Training loss: 2.9386083257056796
Validation loss: 2.5371377474712915

Epoch: 5| Step: 5
Training loss: 2.8393208312187572
Validation loss: 2.5280753082693646

Epoch: 5| Step: 6
Training loss: 2.6262567327413997
Validation loss: 2.5338591873292384

Epoch: 5| Step: 7
Training loss: 2.677176853629422
Validation loss: 2.5283426339343325

Epoch: 5| Step: 8
Training loss: 2.7337992906770867
Validation loss: 2.540554493886653

Epoch: 5| Step: 9
Training loss: 3.186226683958218
Validation loss: 2.55299786138556

Epoch: 5| Step: 10
Training loss: 3.23259505531175
Validation loss: 2.5602664442428114

Epoch: 141| Step: 0
Training loss: 2.6469126224658868
Validation loss: 2.56350539718326

Epoch: 5| Step: 1
Training loss: 3.0701862338361514
Validation loss: 2.587389256518687

Epoch: 5| Step: 2
Training loss: 2.331451804091396
Validation loss: 2.5798233558634287

Epoch: 5| Step: 3
Training loss: 2.6702321673832543
Validation loss: 2.5845312737568102

Epoch: 5| Step: 4
Training loss: 2.7071902185748082
Validation loss: 2.5560043095740705

Epoch: 5| Step: 5
Training loss: 3.2606896884344416
Validation loss: 2.534374018353677

Epoch: 5| Step: 6
Training loss: 2.8368685116287127
Validation loss: 2.52539446021934

Epoch: 5| Step: 7
Training loss: 2.812248557824996
Validation loss: 2.517297580941858

Epoch: 5| Step: 8
Training loss: 3.081424706634295
Validation loss: 2.5198986307412414

Epoch: 5| Step: 9
Training loss: 2.9140410639815633
Validation loss: 2.516782165948747

Epoch: 5| Step: 10
Training loss: 3.2232350332530584
Validation loss: 2.521617780231793

Epoch: 142| Step: 0
Training loss: 3.0055546200183376
Validation loss: 2.5209598806115614

Epoch: 5| Step: 1
Training loss: 2.3896056351844592
Validation loss: 2.5196636058666355

Epoch: 5| Step: 2
Training loss: 2.2447856245084963
Validation loss: 2.520465339547882

Epoch: 5| Step: 3
Training loss: 2.922037211928607
Validation loss: 2.515992610799578

Epoch: 5| Step: 4
Training loss: 2.87226737811044
Validation loss: 2.5227454665945963

Epoch: 5| Step: 5
Training loss: 3.2977536734528075
Validation loss: 2.5156516347158044

Epoch: 5| Step: 6
Training loss: 3.1313141167142877
Validation loss: 2.5168547027573

Epoch: 5| Step: 7
Training loss: 3.1573730585793123
Validation loss: 2.5215908598145615

Epoch: 5| Step: 8
Training loss: 2.5143290907660365
Validation loss: 2.5245447366301796

Epoch: 5| Step: 9
Training loss: 2.8361728875280536
Validation loss: 2.5371363742748345

Epoch: 5| Step: 10
Training loss: 3.078856560384291
Validation loss: 2.5560352144442424

Epoch: 143| Step: 0
Training loss: 2.2594408545387266
Validation loss: 2.5606724334472113

Epoch: 5| Step: 1
Training loss: 2.9085867726715935
Validation loss: 2.559808447529735

Epoch: 5| Step: 2
Training loss: 2.999261447277642
Validation loss: 2.5881519101366024

Epoch: 5| Step: 3
Training loss: 3.123220623782338
Validation loss: 2.5845811795974964

Epoch: 5| Step: 4
Training loss: 3.0249953088645185
Validation loss: 2.5879528179500584

Epoch: 5| Step: 5
Training loss: 2.605373397981125
Validation loss: 2.5835922189558382

Epoch: 5| Step: 6
Training loss: 2.3628524517369254
Validation loss: 2.5475591851196686

Epoch: 5| Step: 7
Training loss: 3.1704608038389623
Validation loss: 2.519343494142345

Epoch: 5| Step: 8
Training loss: 3.108063234213727
Validation loss: 2.5191870201533435

Epoch: 5| Step: 9
Training loss: 2.9622369898969874
Validation loss: 2.5196677163755523

Epoch: 5| Step: 10
Training loss: 2.921355828656364
Validation loss: 2.5278397667873245

Epoch: 144| Step: 0
Training loss: 2.8756588719907445
Validation loss: 2.533877015373095

Epoch: 5| Step: 1
Training loss: 3.296955415007143
Validation loss: 2.533782581262914

Epoch: 5| Step: 2
Training loss: 3.0157445379886214
Validation loss: 2.540068660819316

Epoch: 5| Step: 3
Training loss: 2.6621010459047527
Validation loss: 2.5432805492282617

Epoch: 5| Step: 4
Training loss: 2.4828396257343526
Validation loss: 2.540148422969666

Epoch: 5| Step: 5
Training loss: 2.8705914739224476
Validation loss: 2.540916244002227

Epoch: 5| Step: 6
Training loss: 3.0978258815273563
Validation loss: 2.5375508599382552

Epoch: 5| Step: 7
Training loss: 2.734583993826705
Validation loss: 2.5361382933030705

Epoch: 5| Step: 8
Training loss: 2.4338427763713937
Validation loss: 2.5343109859990753

Epoch: 5| Step: 9
Training loss: 3.4116752885548958
Validation loss: 2.526909554748642

Epoch: 5| Step: 10
Training loss: 3.092818302928842
Validation loss: 2.526981771430632

Epoch: 145| Step: 0
Training loss: 2.685011487826132
Validation loss: 2.524402831630518

Epoch: 5| Step: 1
Training loss: 3.0432592603423028
Validation loss: 2.521067076012393

Epoch: 5| Step: 2
Training loss: 3.1098187767290684
Validation loss: 2.5259749070177238

Epoch: 5| Step: 3
Training loss: 3.017046341441213
Validation loss: 2.5224399604604955

Epoch: 5| Step: 4
Training loss: 2.3576643849865246
Validation loss: 2.51565475002973

Epoch: 5| Step: 5
Training loss: 3.21530381684897
Validation loss: 2.514124079177481

Epoch: 5| Step: 6
Training loss: 3.0485013875909655
Validation loss: 2.513300687184521

Epoch: 5| Step: 7
Training loss: 3.03337761843147
Validation loss: 2.5232901723676764

Epoch: 5| Step: 8
Training loss: 2.6107954168098004
Validation loss: 2.534621741906283

Epoch: 5| Step: 9
Training loss: 2.7468363163538396
Validation loss: 2.538293415269279

Epoch: 5| Step: 10
Training loss: 2.544520313495936
Validation loss: 2.5474484048128305

Epoch: 146| Step: 0
Training loss: 2.975362380580955
Validation loss: 2.5664429930988244

Epoch: 5| Step: 1
Training loss: 3.0063000331847065
Validation loss: 2.5704863356995498

Epoch: 5| Step: 2
Training loss: 2.736954436960239
Validation loss: 2.5479575727089263

Epoch: 5| Step: 3
Training loss: 2.87825458247326
Validation loss: 2.543804994659707

Epoch: 5| Step: 4
Training loss: 2.9873921586368373
Validation loss: 2.5194538775811544

Epoch: 5| Step: 5
Training loss: 2.9459891515921828
Validation loss: 2.509221453458974

Epoch: 5| Step: 6
Training loss: 3.092900631610495
Validation loss: 2.505181332093199

Epoch: 5| Step: 7
Training loss: 2.7913447426938682
Validation loss: 2.5071351724311928

Epoch: 5| Step: 8
Training loss: 2.3913434513573857
Validation loss: 2.5094921881309262

Epoch: 5| Step: 9
Training loss: 3.0552163215131323
Validation loss: 2.511011646383656

Epoch: 5| Step: 10
Training loss: 2.7788415832116415
Validation loss: 2.506603494531927

Epoch: 147| Step: 0
Training loss: 3.1683391537948142
Validation loss: 2.5088072035818203

Epoch: 5| Step: 1
Training loss: 2.358620428216854
Validation loss: 2.5075827729653746

Epoch: 5| Step: 2
Training loss: 2.714513261836778
Validation loss: 2.506228984390423

Epoch: 5| Step: 3
Training loss: 2.8042948243404275
Validation loss: 2.5050470535921763

Epoch: 5| Step: 4
Training loss: 2.907846648001902
Validation loss: 2.505065688435237

Epoch: 5| Step: 5
Training loss: 2.7009531458011242
Validation loss: 2.5067375659123248

Epoch: 5| Step: 6
Training loss: 2.8877298238870273
Validation loss: 2.5017391646584657

Epoch: 5| Step: 7
Training loss: 2.5692709809823997
Validation loss: 2.5064626490634967

Epoch: 5| Step: 8
Training loss: 3.3117280456455704
Validation loss: 2.513582303569086

Epoch: 5| Step: 9
Training loss: 2.7058575880888154
Validation loss: 2.522323908748299

Epoch: 5| Step: 10
Training loss: 3.3305629343759393
Validation loss: 2.524668107079289

Epoch: 148| Step: 0
Training loss: 2.822513387291839
Validation loss: 2.5237767806649107

Epoch: 5| Step: 1
Training loss: 3.2036675714730922
Validation loss: 2.5282121976782603

Epoch: 5| Step: 2
Training loss: 3.4542585212694625
Validation loss: 2.5202163653846865

Epoch: 5| Step: 3
Training loss: 2.5856653168218107
Validation loss: 2.5210202896188045

Epoch: 5| Step: 4
Training loss: 2.7212949220088714
Validation loss: 2.5143727715932047

Epoch: 5| Step: 5
Training loss: 2.6193833889345632
Validation loss: 2.5206223622206245

Epoch: 5| Step: 6
Training loss: 2.591712519085729
Validation loss: 2.511090049727322

Epoch: 5| Step: 7
Training loss: 2.3309789996091026
Validation loss: 2.5151650949692073

Epoch: 5| Step: 8
Training loss: 2.760196163559417
Validation loss: 2.513645124456823

Epoch: 5| Step: 9
Training loss: 3.3582607106827678
Validation loss: 2.5131585104428553

Epoch: 5| Step: 10
Training loss: 2.752452190514065
Validation loss: 2.5160179812104766

Epoch: 149| Step: 0
Training loss: 2.253716472391158
Validation loss: 2.520388311124214

Epoch: 5| Step: 1
Training loss: 3.0107990448835795
Validation loss: 2.525022567084481

Epoch: 5| Step: 2
Training loss: 2.9822639068757657
Validation loss: 2.5250097804376073

Epoch: 5| Step: 3
Training loss: 2.560111537679104
Validation loss: 2.5186651569109544

Epoch: 5| Step: 4
Training loss: 2.897647060977274
Validation loss: 2.522751977955489

Epoch: 5| Step: 5
Training loss: 3.0107326847684934
Validation loss: 2.523747583999123

Epoch: 5| Step: 6
Training loss: 2.22279891107686
Validation loss: 2.515174988016436

Epoch: 5| Step: 7
Training loss: 2.846834794230619
Validation loss: 2.519690100217317

Epoch: 5| Step: 8
Training loss: 2.847745498912202
Validation loss: 2.515331882303281

Epoch: 5| Step: 9
Training loss: 3.4445398549910946
Validation loss: 2.515124182025318

Epoch: 5| Step: 10
Training loss: 3.0984007432597416
Validation loss: 2.514961973118231

Epoch: 150| Step: 0
Training loss: 2.5912204035215654
Validation loss: 2.5089175882102253

Epoch: 5| Step: 1
Training loss: 3.378219905229436
Validation loss: 2.512463141219807

Epoch: 5| Step: 2
Training loss: 2.8274391986708
Validation loss: 2.5072723779196657

Epoch: 5| Step: 3
Training loss: 2.895796979131677
Validation loss: 2.505153595458108

Epoch: 5| Step: 4
Training loss: 2.571917279291096
Validation loss: 2.5062583503607563

Epoch: 5| Step: 5
Training loss: 2.8602330322295817
Validation loss: 2.4979448300284632

Epoch: 5| Step: 6
Training loss: 2.2154313103684107
Validation loss: 2.4968977517905104

Epoch: 5| Step: 7
Training loss: 2.9526234357259717
Validation loss: 2.4973115699040553

Epoch: 5| Step: 8
Training loss: 3.0533314692673414
Validation loss: 2.5023277930583845

Epoch: 5| Step: 9
Training loss: 2.6323519793535946
Validation loss: 2.5069587395858055

Epoch: 5| Step: 10
Training loss: 3.2554460525179176
Validation loss: 2.5089255680337947

Epoch: 151| Step: 0
Training loss: 2.977006373512998
Validation loss: 2.5078056605488603

Epoch: 5| Step: 1
Training loss: 3.02862592555572
Validation loss: 2.516339178712283

Epoch: 5| Step: 2
Training loss: 2.967754799526043
Validation loss: 2.529326284819364

Epoch: 5| Step: 3
Training loss: 2.3555314038296093
Validation loss: 2.526123280671483

Epoch: 5| Step: 4
Training loss: 2.0602295834650257
Validation loss: 2.535380724286475

Epoch: 5| Step: 5
Training loss: 3.4628802975469943
Validation loss: 2.535406061461852

Epoch: 5| Step: 6
Training loss: 3.118042180958482
Validation loss: 2.5270011930775467

Epoch: 5| Step: 7
Training loss: 3.2827206177088333
Validation loss: 2.5274563355519035

Epoch: 5| Step: 8
Training loss: 2.3316402650674037
Validation loss: 2.5128592755728554

Epoch: 5| Step: 9
Training loss: 2.98522330006402
Validation loss: 2.5060327927543256

Epoch: 5| Step: 10
Training loss: 2.2801673096622737
Validation loss: 2.506748343102291

Epoch: 152| Step: 0
Training loss: 3.27881655603324
Validation loss: 2.5039422403442737

Epoch: 5| Step: 1
Training loss: 2.723437422961936
Validation loss: 2.49911684208414

Epoch: 5| Step: 2
Training loss: 3.1901035521629937
Validation loss: 2.4991851473363464

Epoch: 5| Step: 3
Training loss: 2.6788707856517195
Validation loss: 2.498465184820845

Epoch: 5| Step: 4
Training loss: 2.780069765134921
Validation loss: 2.495192641188229

Epoch: 5| Step: 5
Training loss: 3.2724836685087886
Validation loss: 2.4942106853715034

Epoch: 5| Step: 6
Training loss: 3.0032218480843262
Validation loss: 2.4977059134233195

Epoch: 5| Step: 7
Training loss: 2.451005542476493
Validation loss: 2.5108114885285016

Epoch: 5| Step: 8
Training loss: 2.3303565269097746
Validation loss: 2.5239767376387574

Epoch: 5| Step: 9
Training loss: 2.717266247898611
Validation loss: 2.543009718521833

Epoch: 5| Step: 10
Training loss: 2.7520640170170036
Validation loss: 2.5870289132807227

Epoch: 153| Step: 0
Training loss: 2.806182802750889
Validation loss: 2.6013615289253758

Epoch: 5| Step: 1
Training loss: 2.8505317392715064
Validation loss: 2.6107189580278787

Epoch: 5| Step: 2
Training loss: 2.746910700820999
Validation loss: 2.5813372148075953

Epoch: 5| Step: 3
Training loss: 3.2643395042936314
Validation loss: 2.552043147186118

Epoch: 5| Step: 4
Training loss: 2.444351543722653
Validation loss: 2.535560033605343

Epoch: 5| Step: 5
Training loss: 2.6756660380933206
Validation loss: 2.5126187498848482

Epoch: 5| Step: 6
Training loss: 2.46334662817988
Validation loss: 2.5109780851860135

Epoch: 5| Step: 7
Training loss: 3.016853833231969
Validation loss: 2.501780039288301

Epoch: 5| Step: 8
Training loss: 3.032794834028517
Validation loss: 2.5035382694190815

Epoch: 5| Step: 9
Training loss: 3.035232916100586
Validation loss: 2.507856613270571

Epoch: 5| Step: 10
Training loss: 2.963277651932712
Validation loss: 2.5045658783806632

Epoch: 154| Step: 0
Training loss: 2.8172020495520886
Validation loss: 2.5042487188579305

Epoch: 5| Step: 1
Training loss: 2.708934208653648
Validation loss: 2.505920780262584

Epoch: 5| Step: 2
Training loss: 2.6003853365646803
Validation loss: 2.498469835039154

Epoch: 5| Step: 3
Training loss: 2.5967103540991894
Validation loss: 2.509792806067119

Epoch: 5| Step: 4
Training loss: 2.6791403520477344
Validation loss: 2.511680468389682

Epoch: 5| Step: 5
Training loss: 3.162777185166583
Validation loss: 2.5252350988016725

Epoch: 5| Step: 6
Training loss: 2.6742182935290293
Validation loss: 2.527809673360366

Epoch: 5| Step: 7
Training loss: 3.048998127217029
Validation loss: 2.5341767497380263

Epoch: 5| Step: 8
Training loss: 2.750465180326942
Validation loss: 2.5409335634653423

Epoch: 5| Step: 9
Training loss: 2.93674361859524
Validation loss: 2.5542479683221995

Epoch: 5| Step: 10
Training loss: 3.2796706985690265
Validation loss: 2.55631976982775

Epoch: 155| Step: 0
Training loss: 2.761337750388824
Validation loss: 2.532541130825272

Epoch: 5| Step: 1
Training loss: 2.842108619606163
Validation loss: 2.519601552646509

Epoch: 5| Step: 2
Training loss: 1.8454970794795182
Validation loss: 2.5042955217134453

Epoch: 5| Step: 3
Training loss: 2.658778793257963
Validation loss: 2.4995541010846116

Epoch: 5| Step: 4
Training loss: 3.2074210781458334
Validation loss: 2.507354345886634

Epoch: 5| Step: 5
Training loss: 3.369567171821188
Validation loss: 2.5044253098634273

Epoch: 5| Step: 6
Training loss: 2.995412816301532
Validation loss: 2.5052634063378076

Epoch: 5| Step: 7
Training loss: 2.7933124037378074
Validation loss: 2.5017460109595873

Epoch: 5| Step: 8
Training loss: 2.274513435731636
Validation loss: 2.500596989344734

Epoch: 5| Step: 9
Training loss: 3.0136981401763747
Validation loss: 2.500130415150243

Epoch: 5| Step: 10
Training loss: 3.227674832857262
Validation loss: 2.510252172647885

Epoch: 156| Step: 0
Training loss: 2.5841120704936724
Validation loss: 2.505480640828682

Epoch: 5| Step: 1
Training loss: 2.5955586389609677
Validation loss: 2.5054708302421878

Epoch: 5| Step: 2
Training loss: 2.1633111083070005
Validation loss: 2.512272681022422

Epoch: 5| Step: 3
Training loss: 2.8589660685641536
Validation loss: 2.5168090736286928

Epoch: 5| Step: 4
Training loss: 2.9453426126817743
Validation loss: 2.5166381128858086

Epoch: 5| Step: 5
Training loss: 3.081572949428809
Validation loss: 2.503316564141515

Epoch: 5| Step: 6
Training loss: 2.8032590155742723
Validation loss: 2.5055387156852484

Epoch: 5| Step: 7
Training loss: 2.9982361376539024
Validation loss: 2.5023055919945714

Epoch: 5| Step: 8
Training loss: 3.1793739107976347
Validation loss: 2.4918568437086037

Epoch: 5| Step: 9
Training loss: 2.8466058162048995
Validation loss: 2.4947396484750306

Epoch: 5| Step: 10
Training loss: 3.0756158041550097
Validation loss: 2.493853100108736

Epoch: 157| Step: 0
Training loss: 3.1179262590870382
Validation loss: 2.4909405459570984

Epoch: 5| Step: 1
Training loss: 2.8525108119214737
Validation loss: 2.4945559240729978

Epoch: 5| Step: 2
Training loss: 2.611692119329109
Validation loss: 2.494500779448515

Epoch: 5| Step: 3
Training loss: 2.63889576648909
Validation loss: 2.4975970173945066

Epoch: 5| Step: 4
Training loss: 2.705110823781386
Validation loss: 2.5044442830382314

Epoch: 5| Step: 5
Training loss: 2.842315647451228
Validation loss: 2.509598799732369

Epoch: 5| Step: 6
Training loss: 2.8303210757735195
Validation loss: 2.5157808899976626

Epoch: 5| Step: 7
Training loss: 3.012113592288093
Validation loss: 2.5061746535995577

Epoch: 5| Step: 8
Training loss: 2.9022036039830437
Validation loss: 2.4960274646546647

Epoch: 5| Step: 9
Training loss: 2.9493309555435023
Validation loss: 2.5046788895405725

Epoch: 5| Step: 10
Training loss: 2.5451980405846415
Validation loss: 2.505468255826603

Epoch: 158| Step: 0
Training loss: 2.7103652570004253
Validation loss: 2.5156351531429

Epoch: 5| Step: 1
Training loss: 3.067383745224309
Validation loss: 2.5183245396305978

Epoch: 5| Step: 2
Training loss: 2.7774058145919986
Validation loss: 2.5180325654333036

Epoch: 5| Step: 3
Training loss: 2.721721997871478
Validation loss: 2.517547757182861

Epoch: 5| Step: 4
Training loss: 3.1065983475252605
Validation loss: 2.5154854810879823

Epoch: 5| Step: 5
Training loss: 3.0019432767608465
Validation loss: 2.521815898098163

Epoch: 5| Step: 6
Training loss: 2.7236708908182132
Validation loss: 2.5220728238613663

Epoch: 5| Step: 7
Training loss: 2.971321036677614
Validation loss: 2.5048566978270435

Epoch: 5| Step: 8
Training loss: 2.7540207859327
Validation loss: 2.495736402696389

Epoch: 5| Step: 9
Training loss: 1.9437481821916427
Validation loss: 2.504153912729336

Epoch: 5| Step: 10
Training loss: 3.1702031582495143
Validation loss: 2.5049980797982463

Epoch: 159| Step: 0
Training loss: 2.5015282728056456
Validation loss: 2.499400152004326

Epoch: 5| Step: 1
Training loss: 2.7496724367124727
Validation loss: 2.508450706722077

Epoch: 5| Step: 2
Training loss: 2.789681074857871
Validation loss: 2.5127555794315035

Epoch: 5| Step: 3
Training loss: 3.2316318249476006
Validation loss: 2.504735447710729

Epoch: 5| Step: 4
Training loss: 2.6321508102459514
Validation loss: 2.484560131425069

Epoch: 5| Step: 5
Training loss: 2.43896948706077
Validation loss: 2.500401820428596

Epoch: 5| Step: 6
Training loss: 2.6414028128212625
Validation loss: 2.5082335383334824

Epoch: 5| Step: 7
Training loss: 3.0089611683980313
Validation loss: 2.5075215873189394

Epoch: 5| Step: 8
Training loss: 3.0132735972545905
Validation loss: 2.5124029399764307

Epoch: 5| Step: 9
Training loss: 3.2346400645274116
Validation loss: 2.5155355888165625

Epoch: 5| Step: 10
Training loss: 2.568422869343481
Validation loss: 2.5200380263834545

Epoch: 160| Step: 0
Training loss: 2.720160020020032
Validation loss: 2.535989188392462

Epoch: 5| Step: 1
Training loss: 3.021009944269304
Validation loss: 2.529445138927439

Epoch: 5| Step: 2
Training loss: 2.474816895464523
Validation loss: 2.511557624634953

Epoch: 5| Step: 3
Training loss: 2.524856876811549
Validation loss: 2.5000742808966114

Epoch: 5| Step: 4
Training loss: 2.8522165880823342
Validation loss: 2.4938189296924715

Epoch: 5| Step: 5
Training loss: 3.001512940696159
Validation loss: 2.4895165845899117

Epoch: 5| Step: 6
Training loss: 2.7137008786247394
Validation loss: 2.476968808207469

Epoch: 5| Step: 7
Training loss: 3.1438145170170624
Validation loss: 2.4828642724322725

Epoch: 5| Step: 8
Training loss: 2.930308527928016
Validation loss: 2.482593077142677

Epoch: 5| Step: 9
Training loss: 2.861429612374679
Validation loss: 2.4828361026924437

Epoch: 5| Step: 10
Training loss: 2.858423627163094
Validation loss: 2.4913055323109576

Epoch: 161| Step: 0
Training loss: 2.9295226190582198
Validation loss: 2.4953114773020584

Epoch: 5| Step: 1
Training loss: 2.8592679363280853
Validation loss: 2.4947854767567015

Epoch: 5| Step: 2
Training loss: 2.8039121273273593
Validation loss: 2.492696941402787

Epoch: 5| Step: 3
Training loss: 2.74970131032263
Validation loss: 2.504806479843534

Epoch: 5| Step: 4
Training loss: 3.286051116880111
Validation loss: 2.5203148822208497

Epoch: 5| Step: 5
Training loss: 3.06626676011355
Validation loss: 2.582603076155995

Epoch: 5| Step: 6
Training loss: 2.5457493453419726
Validation loss: 2.5984235463184486

Epoch: 5| Step: 7
Training loss: 2.979870977488869
Validation loss: 2.61747271092286

Epoch: 5| Step: 8
Training loss: 2.988270718425069
Validation loss: 2.5642542583131798

Epoch: 5| Step: 9
Training loss: 2.255388166086743
Validation loss: 2.535335506435441

Epoch: 5| Step: 10
Training loss: 2.6307627682128136
Validation loss: 2.5005772395935986

Epoch: 162| Step: 0
Training loss: 2.150729091246009
Validation loss: 2.491598324962169

Epoch: 5| Step: 1
Training loss: 3.12162201460638
Validation loss: 2.485580542933339

Epoch: 5| Step: 2
Training loss: 2.9533933487327535
Validation loss: 2.48408592989544

Epoch: 5| Step: 3
Training loss: 3.0013288098163766
Validation loss: 2.4852571299571147

Epoch: 5| Step: 4
Training loss: 2.938391692183725
Validation loss: 2.4853064710911834

Epoch: 5| Step: 5
Training loss: 2.375678517642792
Validation loss: 2.4859701123010822

Epoch: 5| Step: 6
Training loss: 3.14752350596164
Validation loss: 2.4852914665717467

Epoch: 5| Step: 7
Training loss: 2.9461888797911913
Validation loss: 2.483878799884787

Epoch: 5| Step: 8
Training loss: 2.675850659883283
Validation loss: 2.4879603097251337

Epoch: 5| Step: 9
Training loss: 2.3401511472809533
Validation loss: 2.514751318533349

Epoch: 5| Step: 10
Training loss: 3.1879496537735843
Validation loss: 2.521943141869899

Epoch: 163| Step: 0
Training loss: 3.1334827495688726
Validation loss: 2.5640919420260517

Epoch: 5| Step: 1
Training loss: 2.3085670017816438
Validation loss: 2.6144347577413805

Epoch: 5| Step: 2
Training loss: 2.582701349376424
Validation loss: 2.6072613316931976

Epoch: 5| Step: 3
Training loss: 3.0561997360745625
Validation loss: 2.602851739151703

Epoch: 5| Step: 4
Training loss: 2.606249462100186
Validation loss: 2.6007821079306295

Epoch: 5| Step: 5
Training loss: 2.644376448773118
Validation loss: 2.640522303838147

Epoch: 5| Step: 6
Training loss: 3.0434328638564967
Validation loss: 2.6413725311671623

Epoch: 5| Step: 7
Training loss: 2.993883732813121
Validation loss: 2.5859384755154213

Epoch: 5| Step: 8
Training loss: 2.6399551535178487
Validation loss: 2.531081073106639

Epoch: 5| Step: 9
Training loss: 3.194688358301172
Validation loss: 2.502798206455282

Epoch: 5| Step: 10
Training loss: 2.900313025056183
Validation loss: 2.48766940966317

Epoch: 164| Step: 0
Training loss: 2.7282130975470817
Validation loss: 2.4926028529644055

Epoch: 5| Step: 1
Training loss: 2.582817569642304
Validation loss: 2.4880278867519108

Epoch: 5| Step: 2
Training loss: 2.9169256549472182
Validation loss: 2.493304230500852

Epoch: 5| Step: 3
Training loss: 2.9133371877171954
Validation loss: 2.4913395941662664

Epoch: 5| Step: 4
Training loss: 2.472075817568878
Validation loss: 2.49214615223216

Epoch: 5| Step: 5
Training loss: 2.8525317073467313
Validation loss: 2.4970564874666437

Epoch: 5| Step: 6
Training loss: 3.160965673195706
Validation loss: 2.5011771158597544

Epoch: 5| Step: 7
Training loss: 3.446325728366513
Validation loss: 2.511831736343401

Epoch: 5| Step: 8
Training loss: 2.6255834021992706
Validation loss: 2.505222627427883

Epoch: 5| Step: 9
Training loss: 2.388206405390312
Validation loss: 2.492184376953341

Epoch: 5| Step: 10
Training loss: 3.025770445513081
Validation loss: 2.4934893430927505

Epoch: 165| Step: 0
Training loss: 2.6301544083207142
Validation loss: 2.498536163325194

Epoch: 5| Step: 1
Training loss: 2.802308500146384
Validation loss: 2.516142544086957

Epoch: 5| Step: 2
Training loss: 2.8961615250680803
Validation loss: 2.5305390184258933

Epoch: 5| Step: 3
Training loss: 2.726162069477682
Validation loss: 2.56178102128665

Epoch: 5| Step: 4
Training loss: 2.5641423986470704
Validation loss: 2.561450940602937

Epoch: 5| Step: 5
Training loss: 2.221685160535841
Validation loss: 2.5733452892817397

Epoch: 5| Step: 6
Training loss: 2.8597755360050563
Validation loss: 2.5951250871355724

Epoch: 5| Step: 7
Training loss: 2.4731327218529744
Validation loss: 2.5545631818228958

Epoch: 5| Step: 8
Training loss: 3.311790390301662
Validation loss: 2.5372102418928093

Epoch: 5| Step: 9
Training loss: 3.3514119716888717
Validation loss: 2.5372679926357984

Epoch: 5| Step: 10
Training loss: 3.020170117064723
Validation loss: 2.505812821315358

Epoch: 166| Step: 0
Training loss: 2.7069437032087142
Validation loss: 2.493329014868443

Epoch: 5| Step: 1
Training loss: 2.869114366051552
Validation loss: 2.4852489023852837

Epoch: 5| Step: 2
Training loss: 2.4377101905380343
Validation loss: 2.482903471226139

Epoch: 5| Step: 3
Training loss: 2.7031347021028016
Validation loss: 2.476251102992718

Epoch: 5| Step: 4
Training loss: 2.76828693797326
Validation loss: 2.495780157268851

Epoch: 5| Step: 5
Training loss: 3.2214826816754676
Validation loss: 2.503161965169273

Epoch: 5| Step: 6
Training loss: 2.5651412005905807
Validation loss: 2.504685236508044

Epoch: 5| Step: 7
Training loss: 2.921260667160335
Validation loss: 2.508269689399339

Epoch: 5| Step: 8
Training loss: 2.922354755691929
Validation loss: 2.5141276776797996

Epoch: 5| Step: 9
Training loss: 2.675556167825662
Validation loss: 2.5215300527129956

Epoch: 5| Step: 10
Training loss: 3.1709539269378695
Validation loss: 2.5521324777465004

Epoch: 167| Step: 0
Training loss: 2.3852437607735872
Validation loss: 2.5869630067039897

Epoch: 5| Step: 1
Training loss: 2.969819207645245
Validation loss: 2.555504244256118

Epoch: 5| Step: 2
Training loss: 2.9754062920110695
Validation loss: 2.5252676411067867

Epoch: 5| Step: 3
Training loss: 2.5338515111446025
Validation loss: 2.505993219187027

Epoch: 5| Step: 4
Training loss: 2.5112271932854635
Validation loss: 2.510681129903621

Epoch: 5| Step: 5
Training loss: 2.562372157931909
Validation loss: 2.5114508848844204

Epoch: 5| Step: 6
Training loss: 3.2204339520439693
Validation loss: 2.5144334214402457

Epoch: 5| Step: 7
Training loss: 2.6589558899812014
Validation loss: 2.5207234230444118

Epoch: 5| Step: 8
Training loss: 3.544253418165142
Validation loss: 2.5012184035075142

Epoch: 5| Step: 9
Training loss: 2.842165998363899
Validation loss: 2.491906996533395

Epoch: 5| Step: 10
Training loss: 2.5319668731932974
Validation loss: 2.4922384783486264

Epoch: 168| Step: 0
Training loss: 2.9652718497541395
Validation loss: 2.4819457930301865

Epoch: 5| Step: 1
Training loss: 3.09202943988716
Validation loss: 2.4859319632158474

Epoch: 5| Step: 2
Training loss: 2.681207253708916
Validation loss: 2.4923642646449142

Epoch: 5| Step: 3
Training loss: 2.5710168122817953
Validation loss: 2.495656168236802

Epoch: 5| Step: 4
Training loss: 3.1097194155003196
Validation loss: 2.4956767160563205

Epoch: 5| Step: 5
Training loss: 2.814446517438895
Validation loss: 2.494929317034003

Epoch: 5| Step: 6
Training loss: 2.7115781175551184
Validation loss: 2.489302978574466

Epoch: 5| Step: 7
Training loss: 2.743942264433276
Validation loss: 2.4964132554293648

Epoch: 5| Step: 8
Training loss: 3.234851009705497
Validation loss: 2.494846531869277

Epoch: 5| Step: 9
Training loss: 2.420569578718757
Validation loss: 2.4987304068425313

Epoch: 5| Step: 10
Training loss: 2.477422907733645
Validation loss: 2.5183326168953353

Epoch: 169| Step: 0
Training loss: 2.4378429073828074
Validation loss: 2.5710404003051743

Epoch: 5| Step: 1
Training loss: 2.819259573811029
Validation loss: 2.6684706864119585

Epoch: 5| Step: 2
Training loss: 2.7930579538038383
Validation loss: 2.690260356452418

Epoch: 5| Step: 3
Training loss: 2.444998919090859
Validation loss: 2.6540019280373275

Epoch: 5| Step: 4
Training loss: 2.840439095199902
Validation loss: 2.59049898507063

Epoch: 5| Step: 5
Training loss: 2.013476150428285
Validation loss: 2.5300568199513664

Epoch: 5| Step: 6
Training loss: 3.2149934050164575
Validation loss: 2.4815219324398576

Epoch: 5| Step: 7
Training loss: 3.29088406172488
Validation loss: 2.4808631935397476

Epoch: 5| Step: 8
Training loss: 2.8972830311176616
Validation loss: 2.48057639298869

Epoch: 5| Step: 9
Training loss: 3.1567900544985807
Validation loss: 2.4876592237936896

Epoch: 5| Step: 10
Training loss: 3.109923807909676
Validation loss: 2.495608891070967

Epoch: 170| Step: 0
Training loss: 3.411143017045644
Validation loss: 2.4999990617073515

Epoch: 5| Step: 1
Training loss: 2.5715318935314535
Validation loss: 2.4994376278105133

Epoch: 5| Step: 2
Training loss: 2.6265169029657778
Validation loss: 2.4939763790492604

Epoch: 5| Step: 3
Training loss: 2.5137156947302346
Validation loss: 2.4950196680517767

Epoch: 5| Step: 4
Training loss: 2.9641622330492385
Validation loss: 2.483968929477308

Epoch: 5| Step: 5
Training loss: 2.7280570145183716
Validation loss: 2.4855478347972153

Epoch: 5| Step: 6
Training loss: 2.7562992601901657
Validation loss: 2.4830592081446397

Epoch: 5| Step: 7
Training loss: 2.830331858126185
Validation loss: 2.502516857819545

Epoch: 5| Step: 8
Training loss: 3.0027081663720603
Validation loss: 2.510114194505189

Epoch: 5| Step: 9
Training loss: 2.8045571809632843
Validation loss: 2.5188911802089766

Epoch: 5| Step: 10
Training loss: 2.9845122460567644
Validation loss: 2.509063199264359

Epoch: 171| Step: 0
Training loss: 3.0101322096877747
Validation loss: 2.51107893231379

Epoch: 5| Step: 1
Training loss: 3.049213783363717
Validation loss: 2.5132423724462396

Epoch: 5| Step: 2
Training loss: 2.837479437530895
Validation loss: 2.4965765924792143

Epoch: 5| Step: 3
Training loss: 2.7338367041298226
Validation loss: 2.4952637158632465

Epoch: 5| Step: 4
Training loss: 2.5249213706889213
Validation loss: 2.5031429264576377

Epoch: 5| Step: 5
Training loss: 2.824961710982658
Validation loss: 2.515635860386297

Epoch: 5| Step: 6
Training loss: 2.5441826004977104
Validation loss: 2.5233849899978553

Epoch: 5| Step: 7
Training loss: 2.5564095295790077
Validation loss: 2.5167762258685085

Epoch: 5| Step: 8
Training loss: 2.8215074200503047
Validation loss: 2.5155226917796236

Epoch: 5| Step: 9
Training loss: 2.8693819301607117
Validation loss: 2.515188449469984

Epoch: 5| Step: 10
Training loss: 2.881416127345334
Validation loss: 2.5253261700088943

Epoch: 172| Step: 0
Training loss: 3.195607216075085
Validation loss: 2.528716076554658

Epoch: 5| Step: 1
Training loss: 3.0657280238705478
Validation loss: 2.4878416294600583

Epoch: 5| Step: 2
Training loss: 2.8061701434015474
Validation loss: 2.47359905455744

Epoch: 5| Step: 3
Training loss: 2.5094102184821843
Validation loss: 2.473392620247879

Epoch: 5| Step: 4
Training loss: 2.9613545710343
Validation loss: 2.481281409717404

Epoch: 5| Step: 5
Training loss: 2.7741840915776304
Validation loss: 2.481662885068716

Epoch: 5| Step: 6
Training loss: 2.856386718149026
Validation loss: 2.4835049088526104

Epoch: 5| Step: 7
Training loss: 3.099935340207011
Validation loss: 2.4771611740132955

Epoch: 5| Step: 8
Training loss: 2.2174905775487153
Validation loss: 2.476037953271513

Epoch: 5| Step: 9
Training loss: 2.989695016367649
Validation loss: 2.468966020692049

Epoch: 5| Step: 10
Training loss: 2.876664716322832
Validation loss: 2.4583149775978543

Epoch: 173| Step: 0
Training loss: 2.499158145304474
Validation loss: 2.456704732945293

Epoch: 5| Step: 1
Training loss: 2.6318505224839375
Validation loss: 2.4668877170273125

Epoch: 5| Step: 2
Training loss: 3.475759760729536
Validation loss: 2.4765318901033893

Epoch: 5| Step: 3
Training loss: 2.8703283418520367
Validation loss: 2.49669916295468

Epoch: 5| Step: 4
Training loss: 3.2202753693255284
Validation loss: 2.520028485086543

Epoch: 5| Step: 5
Training loss: 2.5260275194748547
Validation loss: 2.538795456896004

Epoch: 5| Step: 6
Training loss: 2.7148866060016696
Validation loss: 2.5518031482364427

Epoch: 5| Step: 7
Training loss: 2.6349844194852796
Validation loss: 2.515167283348038

Epoch: 5| Step: 8
Training loss: 2.810309765259888
Validation loss: 2.505071993487496

Epoch: 5| Step: 9
Training loss: 2.5824244859111274
Validation loss: 2.4930768947042448

Epoch: 5| Step: 10
Training loss: 2.770064330886074
Validation loss: 2.5172716032095286

Epoch: 174| Step: 0
Training loss: 2.476989516740036
Validation loss: 2.495557404239614

Epoch: 5| Step: 1
Training loss: 2.301994793830506
Validation loss: 2.4887009102560307

Epoch: 5| Step: 2
Training loss: 2.865164976313179
Validation loss: 2.497535651780457

Epoch: 5| Step: 3
Training loss: 3.2792398744301603
Validation loss: 2.492509110677313

Epoch: 5| Step: 4
Training loss: 2.9038123295466343
Validation loss: 2.4902608808200246

Epoch: 5| Step: 5
Training loss: 2.451193662751773
Validation loss: 2.478002727052268

Epoch: 5| Step: 6
Training loss: 2.9747690319513937
Validation loss: 2.4747233050834088

Epoch: 5| Step: 7
Training loss: 3.169999794463623
Validation loss: 2.4731045024264264

Epoch: 5| Step: 8
Training loss: 2.9226559498003386
Validation loss: 2.4844643026069093

Epoch: 5| Step: 9
Training loss: 2.418441405805191
Validation loss: 2.4791550388272032

Epoch: 5| Step: 10
Training loss: 3.0228987023950054
Validation loss: 2.4839173737319267

Epoch: 175| Step: 0
Training loss: 2.3336952700784277
Validation loss: 2.486068088819736

Epoch: 5| Step: 1
Training loss: 2.573555335547404
Validation loss: 2.496598456337732

Epoch: 5| Step: 2
Training loss: 3.0128796983182196
Validation loss: 2.5201166351627995

Epoch: 5| Step: 3
Training loss: 2.3366952132886114
Validation loss: 2.594669535359497

Epoch: 5| Step: 4
Training loss: 2.9706655646663975
Validation loss: 2.626309544292305

Epoch: 5| Step: 5
Training loss: 3.4003808088779914
Validation loss: 2.6282697686439875

Epoch: 5| Step: 6
Training loss: 3.022948232880735
Validation loss: 2.6024142216849997

Epoch: 5| Step: 7
Training loss: 2.6772950282921877
Validation loss: 2.5886381015000417

Epoch: 5| Step: 8
Training loss: 3.042603143904309
Validation loss: 2.5516607336884367

Epoch: 5| Step: 9
Training loss: 3.228984671765731
Validation loss: 2.5255539547077257

Epoch: 5| Step: 10
Training loss: 2.2107606419435815
Validation loss: 2.488144789035868

Testing loss: 2.719899233061018
