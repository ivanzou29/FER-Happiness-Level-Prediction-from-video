Epoch: 1| Step: 0
Training loss: 6.302327637363963
Validation loss: 5.785297106895029

Epoch: 5| Step: 1
Training loss: 4.92063050052583
Validation loss: 5.774762198208785

Epoch: 5| Step: 2
Training loss: 4.836049314324767
Validation loss: 5.763424482966666

Epoch: 5| Step: 3
Training loss: 5.489982846203741
Validation loss: 5.750167373425524

Epoch: 5| Step: 4
Training loss: 5.571595374604167
Validation loss: 5.735157615044291

Epoch: 5| Step: 5
Training loss: 5.73212706865446
Validation loss: 5.717910940846781

Epoch: 5| Step: 6
Training loss: 6.181087060522272
Validation loss: 5.698128661237174

Epoch: 5| Step: 7
Training loss: 6.379289567670023
Validation loss: 5.675796057879524

Epoch: 5| Step: 8
Training loss: 5.7024169482346405
Validation loss: 5.650625275484387

Epoch: 5| Step: 9
Training loss: 5.590291749714305
Validation loss: 5.622150321871536

Epoch: 5| Step: 10
Training loss: 6.281852427578588
Validation loss: 5.589808514667436

Epoch: 2| Step: 0
Training loss: 6.394195976625991
Validation loss: 5.553560830515678

Epoch: 5| Step: 1
Training loss: 5.921996424897109
Validation loss: 5.514296352505887

Epoch: 5| Step: 2
Training loss: 5.151975397300027
Validation loss: 5.471225426962791

Epoch: 5| Step: 3
Training loss: 5.0339319887837375
Validation loss: 5.42510268952166

Epoch: 5| Step: 4
Training loss: 4.3765912023363756
Validation loss: 5.376760295180386

Epoch: 5| Step: 5
Training loss: 5.635568650805732
Validation loss: 5.326484390783582

Epoch: 5| Step: 6
Training loss: 4.572736570016857
Validation loss: 5.273425822850846

Epoch: 5| Step: 7
Training loss: 5.873395335418286
Validation loss: 5.220873478241289

Epoch: 5| Step: 8
Training loss: 5.087550784895577
Validation loss: 5.1654354332666585

Epoch: 5| Step: 9
Training loss: 5.428718403569025
Validation loss: 5.107817536240608

Epoch: 5| Step: 10
Training loss: 5.264259953813843
Validation loss: 5.045998853368779

Epoch: 3| Step: 0
Training loss: 5.680073679056612
Validation loss: 4.980685450331275

Epoch: 5| Step: 1
Training loss: 5.040348900117144
Validation loss: 4.916434015380456

Epoch: 5| Step: 2
Training loss: 4.723154399841404
Validation loss: 4.850105646976812

Epoch: 5| Step: 3
Training loss: 4.577155625761104
Validation loss: 4.784594083858632

Epoch: 5| Step: 4
Training loss: 5.701669669300587
Validation loss: 4.711267395446246

Epoch: 5| Step: 5
Training loss: 4.674355349233539
Validation loss: 4.642349172013595

Epoch: 5| Step: 6
Training loss: 4.010367547597263
Validation loss: 4.598013682729563

Epoch: 5| Step: 7
Training loss: 5.55624706838936
Validation loss: 4.5676649467630375

Epoch: 5| Step: 8
Training loss: 4.721801377536053
Validation loss: 4.520050892214426

Epoch: 5| Step: 9
Training loss: 3.346346836106797
Validation loss: 4.496451766696325

Epoch: 5| Step: 10
Training loss: 3.9673713031512277
Validation loss: 4.480458299667728

Epoch: 4| Step: 0
Training loss: 4.125008785354044
Validation loss: 4.467405745067836

Epoch: 5| Step: 1
Training loss: 4.141492299350099
Validation loss: 4.445581590031239

Epoch: 5| Step: 2
Training loss: 4.314116023145092
Validation loss: 4.4187350782432055

Epoch: 5| Step: 3
Training loss: 4.885942356264576
Validation loss: 4.38969517166603

Epoch: 5| Step: 4
Training loss: 4.273802356382534
Validation loss: 4.364704922263849

Epoch: 5| Step: 5
Training loss: 4.115188721492731
Validation loss: 4.344143353700891

Epoch: 5| Step: 6
Training loss: 4.747701189017712
Validation loss: 4.322081667152314

Epoch: 5| Step: 7
Training loss: 4.53225044518729
Validation loss: 4.299496616604807

Epoch: 5| Step: 8
Training loss: 4.571944820681826
Validation loss: 4.272616675828973

Epoch: 5| Step: 9
Training loss: 4.575585191332323
Validation loss: 4.244659555043821

Epoch: 5| Step: 10
Training loss: 4.767018999180705
Validation loss: 4.216448230006933

Epoch: 5| Step: 0
Training loss: 3.6802717583283067
Validation loss: 4.1871538185965

Epoch: 5| Step: 1
Training loss: 4.137559209209797
Validation loss: 4.160299801076925

Epoch: 5| Step: 2
Training loss: 4.913971868264483
Validation loss: 4.1375063543292905

Epoch: 5| Step: 3
Training loss: 4.276480363775544
Validation loss: 4.118122424398212

Epoch: 5| Step: 4
Training loss: 4.317158049276922
Validation loss: 4.109860906839897

Epoch: 5| Step: 5
Training loss: 4.357346585801825
Validation loss: 4.087926785181087

Epoch: 5| Step: 6
Training loss: 4.193255667965385
Validation loss: 4.063189995843709

Epoch: 5| Step: 7
Training loss: 4.026650814084138
Validation loss: 4.04791767059402

Epoch: 5| Step: 8
Training loss: 3.989963576454134
Validation loss: 4.037419861887435

Epoch: 5| Step: 9
Training loss: 4.790846823616208
Validation loss: 4.021189325381289

Epoch: 5| Step: 10
Training loss: 3.5895160446605456
Validation loss: 4.005771574903299

Epoch: 6| Step: 0
Training loss: 4.458733704079723
Validation loss: 3.988880235706391

Epoch: 5| Step: 1
Training loss: 3.843681272807191
Validation loss: 3.979364235720472

Epoch: 5| Step: 2
Training loss: 4.4691962172734385
Validation loss: 3.970330909606611

Epoch: 5| Step: 3
Training loss: 3.5968256518626895
Validation loss: 3.9563663087851535

Epoch: 5| Step: 4
Training loss: 4.626630753332877
Validation loss: 3.9475117959936137

Epoch: 5| Step: 5
Training loss: 3.871528054519134
Validation loss: 3.936158456450875

Epoch: 5| Step: 6
Training loss: 4.153147292238776
Validation loss: 3.9237576878040965

Epoch: 5| Step: 7
Training loss: 3.5355150240941846
Validation loss: 3.9084964611016546

Epoch: 5| Step: 8
Training loss: 3.6849449486935817
Validation loss: 3.8956104895031536

Epoch: 5| Step: 9
Training loss: 4.186535852376915
Validation loss: 3.886610623234256

Epoch: 5| Step: 10
Training loss: 4.500183525581598
Validation loss: 3.8732102237269554

Epoch: 7| Step: 0
Training loss: 4.226441104859004
Validation loss: 3.8627075590878004

Epoch: 5| Step: 1
Training loss: 3.7165713299439744
Validation loss: 3.8519385915355975

Epoch: 5| Step: 2
Training loss: 4.353984165777906
Validation loss: 3.840849785287678

Epoch: 5| Step: 3
Training loss: 4.046733603345458
Validation loss: 3.823815195603312

Epoch: 5| Step: 4
Training loss: 4.949621845019214
Validation loss: 3.8149487212990167

Epoch: 5| Step: 5
Training loss: 3.3622671053755715
Validation loss: 3.805534779705234

Epoch: 5| Step: 6
Training loss: 3.7130575769605594
Validation loss: 3.7970768570904685

Epoch: 5| Step: 7
Training loss: 3.1486934434779417
Validation loss: 3.7817421300256737

Epoch: 5| Step: 8
Training loss: 3.284429553710375
Validation loss: 3.7738163014269235

Epoch: 5| Step: 9
Training loss: 4.27157769888336
Validation loss: 3.769196403789329

Epoch: 5| Step: 10
Training loss: 4.408907258160413
Validation loss: 3.7549575836410702

Epoch: 8| Step: 0
Training loss: 2.8566728341545318
Validation loss: 3.751540837545234

Epoch: 5| Step: 1
Training loss: 4.210957203325308
Validation loss: 3.7428213695854904

Epoch: 5| Step: 2
Training loss: 3.6468486716293356
Validation loss: 3.7258725879380092

Epoch: 5| Step: 3
Training loss: 4.144674372381523
Validation loss: 3.7216013394280822

Epoch: 5| Step: 4
Training loss: 3.734945724481058
Validation loss: 3.7175410183946087

Epoch: 5| Step: 5
Training loss: 3.4205711354092636
Validation loss: 3.7133165986331003

Epoch: 5| Step: 6
Training loss: 4.763318513634071
Validation loss: 3.7028696243762083

Epoch: 5| Step: 7
Training loss: 2.9758048307246168
Validation loss: 3.6915501341823753

Epoch: 5| Step: 8
Training loss: 3.659604090972292
Validation loss: 3.6889424757218476

Epoch: 5| Step: 9
Training loss: 4.153164973472038
Validation loss: 3.6814466471307736

Epoch: 5| Step: 10
Training loss: 4.88743238475498
Validation loss: 3.6724595672131417

Epoch: 9| Step: 0
Training loss: 4.06170810904249
Validation loss: 3.6682258201443463

Epoch: 5| Step: 1
Training loss: 3.552151288737034
Validation loss: 3.660348284267275

Epoch: 5| Step: 2
Training loss: 3.566814553828299
Validation loss: 3.6498782247855637

Epoch: 5| Step: 3
Training loss: 3.969268284394616
Validation loss: 3.641472589773757

Epoch: 5| Step: 4
Training loss: 3.7898802828438494
Validation loss: 3.6342866321701557

Epoch: 5| Step: 5
Training loss: 4.130231603081451
Validation loss: 3.627626464743182

Epoch: 5| Step: 6
Training loss: 3.7534932714188294
Validation loss: 3.6178542043006403

Epoch: 5| Step: 7
Training loss: 4.203287908523916
Validation loss: 3.6124709840558693

Epoch: 5| Step: 8
Training loss: 3.1858439912118
Validation loss: 3.6038716854825243

Epoch: 5| Step: 9
Training loss: 3.648491215769923
Validation loss: 3.5995904176190683

Epoch: 5| Step: 10
Training loss: 4.125819500523904
Validation loss: 3.5968875865296077

Epoch: 10| Step: 0
Training loss: 3.958201048129636
Validation loss: 3.5860921771109853

Epoch: 5| Step: 1
Training loss: 3.7607560079514295
Validation loss: 3.5820262258199675

Epoch: 5| Step: 2
Training loss: 3.8491998509817402
Validation loss: 3.574407666729504

Epoch: 5| Step: 3
Training loss: 3.6302925147535676
Validation loss: 3.5726872374108125

Epoch: 5| Step: 4
Training loss: 4.113333184619903
Validation loss: 3.5652552544443172

Epoch: 5| Step: 5
Training loss: 3.1629335249537522
Validation loss: 3.559526847518732

Epoch: 5| Step: 6
Training loss: 3.6065951124368967
Validation loss: 3.5577482359523303

Epoch: 5| Step: 7
Training loss: 3.847212309811183
Validation loss: 3.550479503140012

Epoch: 5| Step: 8
Training loss: 4.189851698333524
Validation loss: 3.54615583632826

Epoch: 5| Step: 9
Training loss: 4.080641631368433
Validation loss: 3.539889444314589

Epoch: 5| Step: 10
Training loss: 2.90505858580561
Validation loss: 3.5347385901047237

Epoch: 11| Step: 0
Training loss: 3.161326188285194
Validation loss: 3.5304389361216

Epoch: 5| Step: 1
Training loss: 4.0074667381767215
Validation loss: 3.530121874546702

Epoch: 5| Step: 2
Training loss: 3.8555047401673153
Validation loss: 3.519976329145893

Epoch: 5| Step: 3
Training loss: 3.65722617135345
Validation loss: 3.5157573307704806

Epoch: 5| Step: 4
Training loss: 3.5729465909692726
Validation loss: 3.506589301931835

Epoch: 5| Step: 5
Training loss: 3.8768450128581544
Validation loss: 3.5039849807429357

Epoch: 5| Step: 6
Training loss: 3.445267934359586
Validation loss: 3.499255484986427

Epoch: 5| Step: 7
Training loss: 3.9697091452954316
Validation loss: 3.4938172844275766

Epoch: 5| Step: 8
Training loss: 4.026664787654144
Validation loss: 3.489337647405661

Epoch: 5| Step: 9
Training loss: 3.3263259825115084
Validation loss: 3.486089739829116

Epoch: 5| Step: 10
Training loss: 3.896991591556318
Validation loss: 3.478973744873148

Epoch: 12| Step: 0
Training loss: 3.769036105352687
Validation loss: 3.4727886383313793

Epoch: 5| Step: 1
Training loss: 3.978135433018527
Validation loss: 3.470281794676943

Epoch: 5| Step: 2
Training loss: 3.5431384600082385
Validation loss: 3.465007237581594

Epoch: 5| Step: 3
Training loss: 3.93423108238379
Validation loss: 3.457059081118323

Epoch: 5| Step: 4
Training loss: 4.051628002221303
Validation loss: 3.4532013948106686

Epoch: 5| Step: 5
Training loss: 3.307084461039102
Validation loss: 3.4466817679379544

Epoch: 5| Step: 6
Training loss: 3.089777852933922
Validation loss: 3.4422744572642907

Epoch: 5| Step: 7
Training loss: 3.3031729616203696
Validation loss: 3.4415274488335226

Epoch: 5| Step: 8
Training loss: 4.089342613086136
Validation loss: 3.4341113028870223

Epoch: 5| Step: 9
Training loss: 3.6217925252402616
Validation loss: 3.428629564550741

Epoch: 5| Step: 10
Training loss: 3.494073755211866
Validation loss: 3.427172908041846

Epoch: 13| Step: 0
Training loss: 3.6790318644025835
Validation loss: 3.4205843936381255

Epoch: 5| Step: 1
Training loss: 3.814107337197406
Validation loss: 3.4156751497078672

Epoch: 5| Step: 2
Training loss: 3.344099365236505
Validation loss: 3.4126885683371064

Epoch: 5| Step: 3
Training loss: 3.8376945620243936
Validation loss: 3.409387972540211

Epoch: 5| Step: 4
Training loss: 3.4776679521010627
Validation loss: 3.4075311737106775

Epoch: 5| Step: 5
Training loss: 3.568944355871581
Validation loss: 3.411341149632142

Epoch: 5| Step: 6
Training loss: 3.754122947130641
Validation loss: 3.412816104629489

Epoch: 5| Step: 7
Training loss: 3.9688945353464153
Validation loss: 3.410967327454226

Epoch: 5| Step: 8
Training loss: 3.4686148677313504
Validation loss: 3.4031003713029686

Epoch: 5| Step: 9
Training loss: 3.4931940936471184
Validation loss: 3.3936172966129226

Epoch: 5| Step: 10
Training loss: 3.5099313704255892
Validation loss: 3.386786879540116

Epoch: 14| Step: 0
Training loss: 3.090489065731389
Validation loss: 3.384176654503121

Epoch: 5| Step: 1
Training loss: 4.126890731751497
Validation loss: 3.38198296342222

Epoch: 5| Step: 2
Training loss: 3.417242110260366
Validation loss: 3.3768114252054455

Epoch: 5| Step: 3
Training loss: 3.330849405503947
Validation loss: 3.3731172658580166

Epoch: 5| Step: 4
Training loss: 3.7038682924010153
Validation loss: 3.3673168266316478

Epoch: 5| Step: 5
Training loss: 3.963286115484336
Validation loss: 3.3639288906828178

Epoch: 5| Step: 6
Training loss: 3.816919235690248
Validation loss: 3.3616008004071456

Epoch: 5| Step: 7
Training loss: 3.0377282202113087
Validation loss: 3.3581088260043646

Epoch: 5| Step: 8
Training loss: 3.6175692461895683
Validation loss: 3.356442255785667

Epoch: 5| Step: 9
Training loss: 3.822721568160975
Validation loss: 3.352904126031389

Epoch: 5| Step: 10
Training loss: 3.4723746117953795
Validation loss: 3.347453909903001

Epoch: 15| Step: 0
Training loss: 3.2444519224327455
Validation loss: 3.3421694163603477

Epoch: 5| Step: 1
Training loss: 4.1397584404247985
Validation loss: 3.33836747597937

Epoch: 5| Step: 2
Training loss: 3.8215744337044844
Validation loss: 3.3350667250963406

Epoch: 5| Step: 3
Training loss: 3.62597077623764
Validation loss: 3.3330636889596406

Epoch: 5| Step: 4
Training loss: 3.567730460365158
Validation loss: 3.3291426115886615

Epoch: 5| Step: 5
Training loss: 3.4718594747311236
Validation loss: 3.324408899578172

Epoch: 5| Step: 6
Training loss: 3.4937685943818413
Validation loss: 3.3242233108792494

Epoch: 5| Step: 7
Training loss: 3.089558546018726
Validation loss: 3.3220466037635865

Epoch: 5| Step: 8
Training loss: 3.5652899274597156
Validation loss: 3.3175069094518244

Epoch: 5| Step: 9
Training loss: 3.6415964557737723
Validation loss: 3.314762852508596

Epoch: 5| Step: 10
Training loss: 3.4498984335724048
Validation loss: 3.31357808136786

Epoch: 16| Step: 0
Training loss: 3.826994063253909
Validation loss: 3.312122500690202

Epoch: 5| Step: 1
Training loss: 3.2719871931688154
Validation loss: 3.3141748486029234

Epoch: 5| Step: 2
Training loss: 3.618931393203101
Validation loss: 3.3092956677856638

Epoch: 5| Step: 3
Training loss: 3.4732999087120846
Validation loss: 3.3172215195546317

Epoch: 5| Step: 4
Training loss: 3.110149344633285
Validation loss: 3.3149185607520346

Epoch: 5| Step: 5
Training loss: 3.4705863422072962
Validation loss: 3.3156204833965983

Epoch: 5| Step: 6
Training loss: 3.0427296144202045
Validation loss: 3.3137583696137556

Epoch: 5| Step: 7
Training loss: 3.595845018163786
Validation loss: 3.3152723778241358

Epoch: 5| Step: 8
Training loss: 3.8630975847393176
Validation loss: 3.304492887399912

Epoch: 5| Step: 9
Training loss: 3.81348444001267
Validation loss: 3.307218782828007

Epoch: 5| Step: 10
Training loss: 3.9182531647220045
Validation loss: 3.3077482572863897

Epoch: 17| Step: 0
Training loss: 2.3857420875652355
Validation loss: 3.3052394249638435

Epoch: 5| Step: 1
Training loss: 2.9498523157943954
Validation loss: 3.304877161394771

Epoch: 5| Step: 2
Training loss: 2.708002970182517
Validation loss: 3.3074462208555677

Epoch: 5| Step: 3
Training loss: 4.099883864083788
Validation loss: 3.3037823726475044

Epoch: 5| Step: 4
Training loss: 3.6949763397161304
Validation loss: 3.297082670998368

Epoch: 5| Step: 5
Training loss: 3.8078352109210654
Validation loss: 3.2942778118111025

Epoch: 5| Step: 6
Training loss: 4.2163802661558085
Validation loss: 3.2919165092118727

Epoch: 5| Step: 7
Training loss: 3.473791634116926
Validation loss: 3.289647738805919

Epoch: 5| Step: 8
Training loss: 3.6866598950324434
Validation loss: 3.289568498066465

Epoch: 5| Step: 9
Training loss: 3.749126332553531
Validation loss: 3.2863091956524677

Epoch: 5| Step: 10
Training loss: 3.7188477062564824
Validation loss: 3.290507072747099

Epoch: 18| Step: 0
Training loss: 3.25683037387081
Validation loss: 3.2826347074000126

Epoch: 5| Step: 1
Training loss: 3.7338880915818224
Validation loss: 3.278802748005807

Epoch: 5| Step: 2
Training loss: 2.967617742553439
Validation loss: 3.2802158802450156

Epoch: 5| Step: 3
Training loss: 3.6876192235261662
Validation loss: 3.282315943528303

Epoch: 5| Step: 4
Training loss: 3.5793095256344976
Validation loss: 3.28496167121713

Epoch: 5| Step: 5
Training loss: 4.1121879204138825
Validation loss: 3.284251940883434

Epoch: 5| Step: 6
Training loss: 3.3755686245614287
Validation loss: 3.2772704916619975

Epoch: 5| Step: 7
Training loss: 3.5284493742396625
Validation loss: 3.2723726582780994

Epoch: 5| Step: 8
Training loss: 3.422631027800955
Validation loss: 3.2722036178312734

Epoch: 5| Step: 9
Training loss: 3.1766281218723744
Validation loss: 3.2698675803922965

Epoch: 5| Step: 10
Training loss: 3.847791454437631
Validation loss: 3.2690355402414903

Epoch: 19| Step: 0
Training loss: 2.8582417895131504
Validation loss: 3.265147683823215

Epoch: 5| Step: 1
Training loss: 3.5425659085255647
Validation loss: 3.2640946850420307

Epoch: 5| Step: 2
Training loss: 3.9821438395311413
Validation loss: 3.262825806120051

Epoch: 5| Step: 3
Training loss: 3.3010558606644405
Validation loss: 3.2597216307251364

Epoch: 5| Step: 4
Training loss: 3.9460988686845018
Validation loss: 3.2582282195078576

Epoch: 5| Step: 5
Training loss: 3.1383370183462858
Validation loss: 3.2579599672066255

Epoch: 5| Step: 6
Training loss: 3.377766076145761
Validation loss: 3.256623117976073

Epoch: 5| Step: 7
Training loss: 3.631131215869285
Validation loss: 3.2537293016164597

Epoch: 5| Step: 8
Training loss: 3.3051823815882724
Validation loss: 3.2535316109700245

Epoch: 5| Step: 9
Training loss: 3.8078771611524274
Validation loss: 3.2505633179150077

Epoch: 5| Step: 10
Training loss: 3.566088425178064
Validation loss: 3.252896317510792

Epoch: 20| Step: 0
Training loss: 3.3674428183636214
Validation loss: 3.251465892003584

Epoch: 5| Step: 1
Training loss: 3.0853023599747593
Validation loss: 3.249782267834678

Epoch: 5| Step: 2
Training loss: 4.200609553472869
Validation loss: 3.251091727188001

Epoch: 5| Step: 3
Training loss: 3.471540136523648
Validation loss: 3.249723570989147

Epoch: 5| Step: 4
Training loss: 3.775622128386243
Validation loss: 3.248378175459537

Epoch: 5| Step: 5
Training loss: 3.467022027239764
Validation loss: 3.2487010213603766

Epoch: 5| Step: 6
Training loss: 3.8327598695683296
Validation loss: 3.247681124145239

Epoch: 5| Step: 7
Training loss: 3.441151708050638
Validation loss: 3.240919185074189

Epoch: 5| Step: 8
Training loss: 3.792769233335509
Validation loss: 3.240501020335122

Epoch: 5| Step: 9
Training loss: 2.6675848174978283
Validation loss: 3.2433415216900436

Epoch: 5| Step: 10
Training loss: 3.068979376710253
Validation loss: 3.245124874975069

Epoch: 21| Step: 0
Training loss: 3.0434096755124718
Validation loss: 3.2457149771269567

Epoch: 5| Step: 1
Training loss: 3.0091408706808744
Validation loss: 3.246797639653446

Epoch: 5| Step: 2
Training loss: 3.40645073815397
Validation loss: 3.2491443602567465

Epoch: 5| Step: 3
Training loss: 3.3894822968232945
Validation loss: 3.2466461666019484

Epoch: 5| Step: 4
Training loss: 3.616242847719052
Validation loss: 3.240456924322477

Epoch: 5| Step: 5
Training loss: 3.526543645846393
Validation loss: 3.239397542502144

Epoch: 5| Step: 6
Training loss: 3.7552409106714015
Validation loss: 3.2335395100475504

Epoch: 5| Step: 7
Training loss: 4.410994984667376
Validation loss: 3.2319305005795647

Epoch: 5| Step: 8
Training loss: 3.7460035008924817
Validation loss: 3.2235921312846827

Epoch: 5| Step: 9
Training loss: 3.763257560631662
Validation loss: 3.2195362087034924

Epoch: 5| Step: 10
Training loss: 2.0780133669132326
Validation loss: 3.212399660323606

Epoch: 22| Step: 0
Training loss: 2.762812935896331
Validation loss: 3.201898161702358

Epoch: 5| Step: 1
Training loss: 3.8594283745044016
Validation loss: 3.205670842249528

Epoch: 5| Step: 2
Training loss: 3.2198223809009683
Validation loss: 3.209837449202112

Epoch: 5| Step: 3
Training loss: 3.9242058017280907
Validation loss: 3.204542526777255

Epoch: 5| Step: 4
Training loss: 3.181207466965331
Validation loss: 3.1935925103101157

Epoch: 5| Step: 5
Training loss: 3.8340121096726727
Validation loss: 3.195916744990327

Epoch: 5| Step: 6
Training loss: 2.840675452595305
Validation loss: 3.190502588715756

Epoch: 5| Step: 7
Training loss: 3.6271204830212147
Validation loss: 3.188733472880597

Epoch: 5| Step: 8
Training loss: 3.1293524377556934
Validation loss: 3.182518732913342

Epoch: 5| Step: 9
Training loss: 3.4005691332470622
Validation loss: 3.181018788596346

Epoch: 5| Step: 10
Training loss: 3.9896089770469847
Validation loss: 3.1816760492614877

Epoch: 23| Step: 0
Training loss: 3.499675190704087
Validation loss: 3.180118501446444

Epoch: 5| Step: 1
Training loss: 3.513779354943137
Validation loss: 3.175209297734068

Epoch: 5| Step: 2
Training loss: 2.801888091554335
Validation loss: 3.1765641703966776

Epoch: 5| Step: 3
Training loss: 3.9545843875845956
Validation loss: 3.1729493329481597

Epoch: 5| Step: 4
Training loss: 3.7682035489673584
Validation loss: 3.1718962865818665

Epoch: 5| Step: 5
Training loss: 3.4185197658528126
Validation loss: 3.1666223078169886

Epoch: 5| Step: 6
Training loss: 3.472684810765566
Validation loss: 3.1657539670442123

Epoch: 5| Step: 7
Training loss: 3.1062796823476506
Validation loss: 3.1623854255536146

Epoch: 5| Step: 8
Training loss: 3.7243370592720115
Validation loss: 3.1607462541637554

Epoch: 5| Step: 9
Training loss: 3.655939333506277
Validation loss: 3.1598840636819627

Epoch: 5| Step: 10
Training loss: 2.342282255265167
Validation loss: 3.156505526044829

Epoch: 24| Step: 0
Training loss: 3.554269216890822
Validation loss: 3.1560779103470815

Epoch: 5| Step: 1
Training loss: 3.7647563518093397
Validation loss: 3.155733830430818

Epoch: 5| Step: 2
Training loss: 3.129396321639467
Validation loss: 3.1518057349461763

Epoch: 5| Step: 3
Training loss: 3.1216065865142646
Validation loss: 3.1499693379274674

Epoch: 5| Step: 4
Training loss: 3.0185666930972834
Validation loss: 3.1502476713492826

Epoch: 5| Step: 5
Training loss: 3.154485228025804
Validation loss: 3.147178395489189

Epoch: 5| Step: 6
Training loss: 3.1751738433102683
Validation loss: 3.1452004384753627

Epoch: 5| Step: 7
Training loss: 4.070022660550855
Validation loss: 3.1456877923254396

Epoch: 5| Step: 8
Training loss: 3.544328624171038
Validation loss: 3.1436157956632393

Epoch: 5| Step: 9
Training loss: 3.628340924497019
Validation loss: 3.1429562651250915

Epoch: 5| Step: 10
Training loss: 3.148396001878346
Validation loss: 3.138659074216876

Epoch: 25| Step: 0
Training loss: 3.677910442462992
Validation loss: 3.1383151357236208

Epoch: 5| Step: 1
Training loss: 2.8711563622530814
Validation loss: 3.136365452123233

Epoch: 5| Step: 2
Training loss: 3.4563830441465497
Validation loss: 3.1363868799863788

Epoch: 5| Step: 3
Training loss: 3.7807445345910167
Validation loss: 3.131492719927942

Epoch: 5| Step: 4
Training loss: 3.6548232204618527
Validation loss: 3.130145834273136

Epoch: 5| Step: 5
Training loss: 3.591688277909004
Validation loss: 3.1248121332282977

Epoch: 5| Step: 6
Training loss: 2.8782815863709192
Validation loss: 3.1447015698751346

Epoch: 5| Step: 7
Training loss: 3.8297001303468794
Validation loss: 3.1543956317869464

Epoch: 5| Step: 8
Training loss: 3.230097203873618
Validation loss: 3.1352953064420515

Epoch: 5| Step: 9
Training loss: 3.105510054019738
Validation loss: 3.126526559393541

Epoch: 5| Step: 10
Training loss: 3.0344920959822277
Validation loss: 3.1307327961089166

Epoch: 26| Step: 0
Training loss: 3.9935960766855554
Validation loss: 3.190844396915562

Epoch: 5| Step: 1
Training loss: 3.4601366481367895
Validation loss: 3.1247985824155182

Epoch: 5| Step: 2
Training loss: 3.5850920833748265
Validation loss: 3.120404136802054

Epoch: 5| Step: 3
Training loss: 3.0104090988609644
Validation loss: 3.1537937844186192

Epoch: 5| Step: 4
Training loss: 3.510671015881506
Validation loss: 3.2376236657302364

Epoch: 5| Step: 5
Training loss: 2.898940543968748
Validation loss: 3.1868329026688014

Epoch: 5| Step: 6
Training loss: 3.4791694382220593
Validation loss: 3.145118899279274

Epoch: 5| Step: 7
Training loss: 3.443328909217181
Validation loss: 3.1347286499856435

Epoch: 5| Step: 8
Training loss: 3.4057083399154755
Validation loss: 3.129094889345623

Epoch: 5| Step: 9
Training loss: 3.2777922804200914
Validation loss: 3.1192584545172792

Epoch: 5| Step: 10
Training loss: 3.386062716926759
Validation loss: 3.1174041198243123

Epoch: 27| Step: 0
Training loss: 3.2097140392193837
Validation loss: 3.112639476848298

Epoch: 5| Step: 1
Training loss: 3.45753687377597
Validation loss: 3.1183172565699815

Epoch: 5| Step: 2
Training loss: 3.55552807605244
Validation loss: 3.1188996131010667

Epoch: 5| Step: 3
Training loss: 2.82589692924962
Validation loss: 3.1156850779836955

Epoch: 5| Step: 4
Training loss: 3.3943824867161756
Validation loss: 3.106568388435609

Epoch: 5| Step: 5
Training loss: 3.8999854552168935
Validation loss: 3.1055481248203725

Epoch: 5| Step: 6
Training loss: 3.1023154317715678
Validation loss: 3.1011491771171293

Epoch: 5| Step: 7
Training loss: 2.709966568124781
Validation loss: 3.1029321567135084

Epoch: 5| Step: 8
Training loss: 3.3278385809210316
Validation loss: 3.1034890609615537

Epoch: 5| Step: 9
Training loss: 3.7697880316522925
Validation loss: 3.109952362983498

Epoch: 5| Step: 10
Training loss: 3.70392403653647
Validation loss: 3.0994145324462297

Epoch: 28| Step: 0
Training loss: 2.9169132310100023
Validation loss: 3.091458909678753

Epoch: 5| Step: 1
Training loss: 3.346032762739871
Validation loss: 3.089292383995026

Epoch: 5| Step: 2
Training loss: 3.357465476329377
Validation loss: 3.0880017401692315

Epoch: 5| Step: 3
Training loss: 3.4005238409969243
Validation loss: 3.086987295597002

Epoch: 5| Step: 4
Training loss: 4.223405543921603
Validation loss: 3.085009003710828

Epoch: 5| Step: 5
Training loss: 3.551466201168125
Validation loss: 3.084331522708918

Epoch: 5| Step: 6
Training loss: 3.7144912568535156
Validation loss: 3.083384764247096

Epoch: 5| Step: 7
Training loss: 3.0356394654357963
Validation loss: 3.086954380698134

Epoch: 5| Step: 8
Training loss: 3.1886298477223933
Validation loss: 3.093924064955847

Epoch: 5| Step: 9
Training loss: 3.299569136495132
Validation loss: 3.093578480954141

Epoch: 5| Step: 10
Training loss: 2.5057415834186765
Validation loss: 3.0805922604471574

Epoch: 29| Step: 0
Training loss: 2.9393205885299007
Validation loss: 3.073594501222876

Epoch: 5| Step: 1
Training loss: 3.4877716068071316
Validation loss: 3.0721339565682113

Epoch: 5| Step: 2
Training loss: 3.3821170788063233
Validation loss: 3.068821314653957

Epoch: 5| Step: 3
Training loss: 3.2955222586249184
Validation loss: 3.0650714461258244

Epoch: 5| Step: 4
Training loss: 3.364108702700676
Validation loss: 3.0623019507874965

Epoch: 5| Step: 5
Training loss: 3.225192243183833
Validation loss: 3.058845859672608

Epoch: 5| Step: 6
Training loss: 3.2894982708463867
Validation loss: 3.054012178090903

Epoch: 5| Step: 7
Training loss: 3.593184451508644
Validation loss: 3.050237847287842

Epoch: 5| Step: 8
Training loss: 3.4883445400805893
Validation loss: 3.046371913170378

Epoch: 5| Step: 9
Training loss: 3.419232606734663
Validation loss: 3.044765731593688

Epoch: 5| Step: 10
Training loss: 3.116062965334729
Validation loss: 3.0466222026613448

Epoch: 30| Step: 0
Training loss: 3.1954620251727746
Validation loss: 3.0446005704872645

Epoch: 5| Step: 1
Training loss: 2.853540690662497
Validation loss: 3.0426587908374887

Epoch: 5| Step: 2
Training loss: 2.8535617456488422
Validation loss: 3.041805362503236

Epoch: 5| Step: 3
Training loss: 2.8169280903351765
Validation loss: 3.0476358629551017

Epoch: 5| Step: 4
Training loss: 3.720740290578815
Validation loss: 3.089743511593872

Epoch: 5| Step: 5
Training loss: 3.144392496210842
Validation loss: 3.044139280716954

Epoch: 5| Step: 6
Training loss: 3.8009872459111333
Validation loss: 3.041797212593823

Epoch: 5| Step: 7
Training loss: 3.237601914145712
Validation loss: 3.047586921290098

Epoch: 5| Step: 8
Training loss: 3.181492548541609
Validation loss: 3.0386365602612315

Epoch: 5| Step: 9
Training loss: 3.430520758064115
Validation loss: 3.038185763126438

Epoch: 5| Step: 10
Training loss: 4.094378008246681
Validation loss: 3.0358157374560113

Epoch: 31| Step: 0
Training loss: 3.6289434359218946
Validation loss: 3.0323203695889376

Epoch: 5| Step: 1
Training loss: 3.5334096060623748
Validation loss: 3.030669530261387

Epoch: 5| Step: 2
Training loss: 3.365883417577783
Validation loss: 3.031154805718319

Epoch: 5| Step: 3
Training loss: 2.596908209229172
Validation loss: 3.027564726884533

Epoch: 5| Step: 4
Training loss: 2.8204196053664945
Validation loss: 3.025988982113364

Epoch: 5| Step: 5
Training loss: 3.2990335205169754
Validation loss: 3.0319018477628137

Epoch: 5| Step: 6
Training loss: 3.7008118950104687
Validation loss: 3.04021868260706

Epoch: 5| Step: 7
Training loss: 3.6122784186916586
Validation loss: 3.0700054677425754

Epoch: 5| Step: 8
Training loss: 2.5130318491534522
Validation loss: 3.0341523406796798

Epoch: 5| Step: 9
Training loss: 3.35574428506197
Validation loss: 3.0260960096416305

Epoch: 5| Step: 10
Training loss: 3.6937251159552695
Validation loss: 3.022915551874663

Epoch: 32| Step: 0
Training loss: 3.098266541443556
Validation loss: 3.0190195977436174

Epoch: 5| Step: 1
Training loss: 3.5729296418038743
Validation loss: 3.0179780857435463

Epoch: 5| Step: 2
Training loss: 3.177249357961382
Validation loss: 3.0124040400708467

Epoch: 5| Step: 3
Training loss: 3.5727905755365885
Validation loss: 3.014727752757343

Epoch: 5| Step: 4
Training loss: 3.4431923638064146
Validation loss: 3.015087891079895

Epoch: 5| Step: 5
Training loss: 3.1281598709403617
Validation loss: 3.0171998791508052

Epoch: 5| Step: 6
Training loss: 3.240800455138646
Validation loss: 3.010784756984821

Epoch: 5| Step: 7
Training loss: 3.1051871310003643
Validation loss: 3.0074692601538517

Epoch: 5| Step: 8
Training loss: 3.068370874918774
Validation loss: 3.004483729747294

Epoch: 5| Step: 9
Training loss: 3.0171087696267747
Validation loss: 3.006322756490127

Epoch: 5| Step: 10
Training loss: 3.7743597384512384
Validation loss: 3.003793323834569

Epoch: 33| Step: 0
Training loss: 3.2480752086951945
Validation loss: 3.0003812933864435

Epoch: 5| Step: 1
Training loss: 2.7233532050476597
Validation loss: 3.004990547395584

Epoch: 5| Step: 2
Training loss: 3.674507009435434
Validation loss: 3.0007767124746527

Epoch: 5| Step: 3
Training loss: 3.3668327410184267
Validation loss: 3.001178336569217

Epoch: 5| Step: 4
Training loss: 3.555985366816927
Validation loss: 2.9983083063924876

Epoch: 5| Step: 5
Training loss: 2.988621591372594
Validation loss: 2.9975765567899435

Epoch: 5| Step: 6
Training loss: 3.263327926875446
Validation loss: 2.996130058899733

Epoch: 5| Step: 7
Training loss: 2.754554618101446
Validation loss: 2.9960153036819923

Epoch: 5| Step: 8
Training loss: 3.3854328957193136
Validation loss: 2.995490581749321

Epoch: 5| Step: 9
Training loss: 3.487529472855483
Validation loss: 2.9928007506012557

Epoch: 5| Step: 10
Training loss: 3.452419847667058
Validation loss: 2.991040466419114

Epoch: 34| Step: 0
Training loss: 3.4465653613295935
Validation loss: 2.9906346768967698

Epoch: 5| Step: 1
Training loss: 3.721749258279486
Validation loss: 2.986424873493358

Epoch: 5| Step: 2
Training loss: 3.3852755629648574
Validation loss: 2.984458025796591

Epoch: 5| Step: 3
Training loss: 3.2634772579989835
Validation loss: 2.9831787935085514

Epoch: 5| Step: 4
Training loss: 3.3385978293294656
Validation loss: 2.9799926809394606

Epoch: 5| Step: 5
Training loss: 2.902525288999855
Validation loss: 2.981399928477013

Epoch: 5| Step: 6
Training loss: 3.246277217523213
Validation loss: 2.98129104441881

Epoch: 5| Step: 7
Training loss: 2.8818465271111773
Validation loss: 2.9790340170029594

Epoch: 5| Step: 8
Training loss: 3.410318726888988
Validation loss: 2.97601452669781

Epoch: 5| Step: 9
Training loss: 3.011587177178278
Validation loss: 2.975214167395413

Epoch: 5| Step: 10
Training loss: 3.21256587929471
Validation loss: 2.9755359270691217

Epoch: 35| Step: 0
Training loss: 3.456739924165588
Validation loss: 2.981427686934018

Epoch: 5| Step: 1
Training loss: 3.7642689396108824
Validation loss: 2.977649114328282

Epoch: 5| Step: 2
Training loss: 3.6320182998633133
Validation loss: 2.9735416682010647

Epoch: 5| Step: 3
Training loss: 3.3011129178781555
Validation loss: 2.970514935397849

Epoch: 5| Step: 4
Training loss: 3.5395662399756405
Validation loss: 2.9697020355083765

Epoch: 5| Step: 5
Training loss: 3.4396319627164225
Validation loss: 2.970841218399744

Epoch: 5| Step: 6
Training loss: 2.4314234379977853
Validation loss: 2.9741988707160623

Epoch: 5| Step: 7
Training loss: 3.0218148226500734
Validation loss: 2.9721968928975753

Epoch: 5| Step: 8
Training loss: 3.5861576985088397
Validation loss: 2.970130654631426

Epoch: 5| Step: 9
Training loss: 2.4144680830599086
Validation loss: 2.966963047456269

Epoch: 5| Step: 10
Training loss: 2.9597229894975894
Validation loss: 2.965789481094237

Epoch: 36| Step: 0
Training loss: 3.350138612982497
Validation loss: 2.966618370302728

Epoch: 5| Step: 1
Training loss: 3.280869816144536
Validation loss: 2.963031612376324

Epoch: 5| Step: 2
Training loss: 3.3172515762328807
Validation loss: 2.969934939662133

Epoch: 5| Step: 3
Training loss: 2.7524540095423933
Validation loss: 2.9750743165923397

Epoch: 5| Step: 4
Training loss: 3.5082051964297
Validation loss: 2.98342242654115

Epoch: 5| Step: 5
Training loss: 3.423677431349318
Validation loss: 2.9929520116462345

Epoch: 5| Step: 6
Training loss: 3.524086226396724
Validation loss: 2.9930012419824172

Epoch: 5| Step: 7
Training loss: 3.4064643162490955
Validation loss: 2.9666774473262887

Epoch: 5| Step: 8
Training loss: 2.6107961473719707
Validation loss: 2.958919726715739

Epoch: 5| Step: 9
Training loss: 3.513407910934995
Validation loss: 2.9560434522452232

Epoch: 5| Step: 10
Training loss: 2.8333242266639513
Validation loss: 2.952422734406707

Epoch: 37| Step: 0
Training loss: 3.373123777713381
Validation loss: 2.9534413496573575

Epoch: 5| Step: 1
Training loss: 3.254454860714723
Validation loss: 2.9522870097722196

Epoch: 5| Step: 2
Training loss: 3.8861084732096396
Validation loss: 2.953834616412841

Epoch: 5| Step: 3
Training loss: 2.9976659278027418
Validation loss: 2.951427935045015

Epoch: 5| Step: 4
Training loss: 3.062595910886532
Validation loss: 2.949306504062437

Epoch: 5| Step: 5
Training loss: 3.472681240682716
Validation loss: 2.947919327199035

Epoch: 5| Step: 6
Training loss: 3.158104380123753
Validation loss: 2.9482296537960786

Epoch: 5| Step: 7
Training loss: 3.3655754177794366
Validation loss: 2.947884089879348

Epoch: 5| Step: 8
Training loss: 3.350775352823267
Validation loss: 2.9456798630858847

Epoch: 5| Step: 9
Training loss: 2.881073548712497
Validation loss: 2.9443292914203845

Epoch: 5| Step: 10
Training loss: 2.543189535796365
Validation loss: 2.9443564842656937

Epoch: 38| Step: 0
Training loss: 3.2573518495984617
Validation loss: 2.9530862403205926

Epoch: 5| Step: 1
Training loss: 3.3971823292723506
Validation loss: 2.975964678530033

Epoch: 5| Step: 2
Training loss: 3.5934387072209413
Validation loss: 2.953000904381242

Epoch: 5| Step: 3
Training loss: 2.8396822163266227
Validation loss: 2.9419412893688848

Epoch: 5| Step: 4
Training loss: 3.330680761316111
Validation loss: 2.9367436587511007

Epoch: 5| Step: 5
Training loss: 2.340520235576811
Validation loss: 2.9345613205213867

Epoch: 5| Step: 6
Training loss: 3.0291319063720503
Validation loss: 2.951878865681036

Epoch: 5| Step: 7
Training loss: 3.027692929711257
Validation loss: 2.983935949587456

Epoch: 5| Step: 8
Training loss: 3.2334235077176685
Validation loss: 2.9474986503343525

Epoch: 5| Step: 9
Training loss: 3.393605974207776
Validation loss: 2.938000943720831

Epoch: 5| Step: 10
Training loss: 4.021895563151589
Validation loss: 2.9416568103945755

Epoch: 39| Step: 0
Training loss: 3.837114390529464
Validation loss: 2.9385457015801646

Epoch: 5| Step: 1
Training loss: 3.2637498938722276
Validation loss: 2.9412762891104443

Epoch: 5| Step: 2
Training loss: 2.405423208104784
Validation loss: 2.9552826294427033

Epoch: 5| Step: 3
Training loss: 2.6166872371990806
Validation loss: 2.9379534523021356

Epoch: 5| Step: 4
Training loss: 3.070033868857576
Validation loss: 2.934867479576616

Epoch: 5| Step: 5
Training loss: 3.0334934702372722
Validation loss: 2.9313248130451393

Epoch: 5| Step: 6
Training loss: 3.814041826503911
Validation loss: 2.9302929131968245

Epoch: 5| Step: 7
Training loss: 2.9722255239339614
Validation loss: 2.930482510019226

Epoch: 5| Step: 8
Training loss: 3.5393462414712413
Validation loss: 2.928239701625963

Epoch: 5| Step: 9
Training loss: 3.2960519350830393
Validation loss: 2.9302800192575726

Epoch: 5| Step: 10
Training loss: 3.3175689492322773
Validation loss: 2.94207181298092

Epoch: 40| Step: 0
Training loss: 3.4588108116128273
Validation loss: 2.9376719574352816

Epoch: 5| Step: 1
Training loss: 3.216100546740665
Validation loss: 2.9339021010250694

Epoch: 5| Step: 2
Training loss: 3.032126073968954
Validation loss: 2.9254570132699316

Epoch: 5| Step: 3
Training loss: 2.8462846799269768
Validation loss: 2.923831043020969

Epoch: 5| Step: 4
Training loss: 2.9093175306698127
Validation loss: 2.92364453108341

Epoch: 5| Step: 5
Training loss: 3.34903321051455
Validation loss: 2.9200012057972375

Epoch: 5| Step: 6
Training loss: 2.876787376420242
Validation loss: 2.9191979790356024

Epoch: 5| Step: 7
Training loss: 4.0068305822304575
Validation loss: 2.9190370821532445

Epoch: 5| Step: 8
Training loss: 3.6088325125837906
Validation loss: 2.918199716986949

Epoch: 5| Step: 9
Training loss: 2.958929583857406
Validation loss: 2.919300902300156

Epoch: 5| Step: 10
Training loss: 2.812471262467115
Validation loss: 2.932234017317196

Epoch: 41| Step: 0
Training loss: 3.0403380083097584
Validation loss: 2.9505646811911213

Epoch: 5| Step: 1
Training loss: 2.936752711264873
Validation loss: 2.9500289915567595

Epoch: 5| Step: 2
Training loss: 3.6931726821039477
Validation loss: 2.921448328156554

Epoch: 5| Step: 3
Training loss: 2.932221235081003
Validation loss: 2.917653118854586

Epoch: 5| Step: 4
Training loss: 3.35979710965439
Validation loss: 2.915034389081577

Epoch: 5| Step: 5
Training loss: 3.3995571352935796
Validation loss: 2.9146467981900397

Epoch: 5| Step: 6
Training loss: 2.8721602969582563
Validation loss: 2.9134927555725416

Epoch: 5| Step: 7
Training loss: 3.3619949415306145
Validation loss: 2.912654872908161

Epoch: 5| Step: 8
Training loss: 3.3905123502942085
Validation loss: 2.9133939555963404

Epoch: 5| Step: 9
Training loss: 3.3371409762436928
Validation loss: 2.913292953199353

Epoch: 5| Step: 10
Training loss: 2.8297185465364403
Validation loss: 2.911713964576103

Epoch: 42| Step: 0
Training loss: 3.4185172550959386
Validation loss: 2.9138397357746544

Epoch: 5| Step: 1
Training loss: 4.168094822586602
Validation loss: 2.914442976725284

Epoch: 5| Step: 2
Training loss: 2.552630795257746
Validation loss: 2.9102904757971992

Epoch: 5| Step: 3
Training loss: 3.50202855860265
Validation loss: 2.910687171751727

Epoch: 5| Step: 4
Training loss: 2.9122158059231382
Validation loss: 2.909088776308629

Epoch: 5| Step: 5
Training loss: 2.9037494361538614
Validation loss: 2.9097552385283687

Epoch: 5| Step: 6
Training loss: 2.7469259767283054
Validation loss: 2.9091946242182116

Epoch: 5| Step: 7
Training loss: 3.28939288511928
Validation loss: 2.9108474151837282

Epoch: 5| Step: 8
Training loss: 3.254371344218317
Validation loss: 2.9139161555251563

Epoch: 5| Step: 9
Training loss: 3.138935906462241
Validation loss: 2.9205420880429744

Epoch: 5| Step: 10
Training loss: 3.000879794496212
Validation loss: 2.9033911885221664

Epoch: 43| Step: 0
Training loss: 3.167308809190136
Validation loss: 2.904910315686525

Epoch: 5| Step: 1
Training loss: 3.225066274509035
Validation loss: 2.903654924876296

Epoch: 5| Step: 2
Training loss: 3.161285613535525
Validation loss: 2.906320836331596

Epoch: 5| Step: 3
Training loss: 2.7632087454263714
Validation loss: 2.9081169568588687

Epoch: 5| Step: 4
Training loss: 3.508717171760393
Validation loss: 2.9099164512837987

Epoch: 5| Step: 5
Training loss: 2.9828532068783034
Validation loss: 2.911280335983088

Epoch: 5| Step: 6
Training loss: 2.8232600060781095
Validation loss: 2.9110298285340614

Epoch: 5| Step: 7
Training loss: 3.639349980216717
Validation loss: 2.903370051634668

Epoch: 5| Step: 8
Training loss: 3.1694810975704595
Validation loss: 2.9049222495349123

Epoch: 5| Step: 9
Training loss: 3.396504872080907
Validation loss: 2.903261585140465

Epoch: 5| Step: 10
Training loss: 3.3406531708317293
Validation loss: 2.9029699069218666

Epoch: 44| Step: 0
Training loss: 3.271228855459746
Validation loss: 2.9004156258609974

Epoch: 5| Step: 1
Training loss: 3.043519975246044
Validation loss: 2.9009968039894356

Epoch: 5| Step: 2
Training loss: 3.1302231435483576
Validation loss: 2.904454195451479

Epoch: 5| Step: 3
Training loss: 3.4251194731208088
Validation loss: 2.907606791061357

Epoch: 5| Step: 4
Training loss: 3.229803863333727
Validation loss: 2.9101508869001425

Epoch: 5| Step: 5
Training loss: 3.3671798528951737
Validation loss: 2.9038694955083484

Epoch: 5| Step: 6
Training loss: 3.415603394714877
Validation loss: 2.904319624013115

Epoch: 5| Step: 7
Training loss: 3.3363402791276977
Validation loss: 2.9002334925055444

Epoch: 5| Step: 8
Training loss: 2.518058689557572
Validation loss: 2.8944139024340814

Epoch: 5| Step: 9
Training loss: 2.962053959099363
Validation loss: 2.893314062196782

Epoch: 5| Step: 10
Training loss: 3.2817363560220696
Validation loss: 2.89170589885557

Epoch: 45| Step: 0
Training loss: 3.431690369855017
Validation loss: 2.890876017244536

Epoch: 5| Step: 1
Training loss: 3.3560698107436564
Validation loss: 2.890613401345904

Epoch: 5| Step: 2
Training loss: 3.2465488009301953
Validation loss: 2.8908158097152405

Epoch: 5| Step: 3
Training loss: 3.179286022287273
Validation loss: 2.887147961479724

Epoch: 5| Step: 4
Training loss: 2.7907800167895385
Validation loss: 2.8865691444057

Epoch: 5| Step: 5
Training loss: 3.3234704651338767
Validation loss: 2.8880087931017964

Epoch: 5| Step: 6
Training loss: 3.1550611013066794
Validation loss: 2.8877182029510364

Epoch: 5| Step: 7
Training loss: 3.151141423099189
Validation loss: 2.8851996390875447

Epoch: 5| Step: 8
Training loss: 2.825655369990915
Validation loss: 2.8844415576223734

Epoch: 5| Step: 9
Training loss: 3.2001352639220517
Validation loss: 2.884315475763184

Epoch: 5| Step: 10
Training loss: 3.332489876527856
Validation loss: 2.8834405706141704

Epoch: 46| Step: 0
Training loss: 3.2120331243134794
Validation loss: 2.8808125398422053

Epoch: 5| Step: 1
Training loss: 3.765400860079171
Validation loss: 2.8782326054351897

Epoch: 5| Step: 2
Training loss: 2.7530762199384395
Validation loss: 2.876028904932207

Epoch: 5| Step: 3
Training loss: 2.5570052246111983
Validation loss: 2.8825000943042642

Epoch: 5| Step: 4
Training loss: 2.8371809658223612
Validation loss: 2.8873097190883543

Epoch: 5| Step: 5
Training loss: 2.7355731192068955
Validation loss: 2.9217636510963754

Epoch: 5| Step: 6
Training loss: 3.3959860894105875
Validation loss: 2.9257989251432437

Epoch: 5| Step: 7
Training loss: 3.5532081292324484
Validation loss: 2.882071139753189

Epoch: 5| Step: 8
Training loss: 3.4339853525621407
Validation loss: 2.8744883400778445

Epoch: 5| Step: 9
Training loss: 3.272421740710122
Validation loss: 2.8741219201992605

Epoch: 5| Step: 10
Training loss: 3.1596963026686056
Validation loss: 2.8740135398056728

Epoch: 47| Step: 0
Training loss: 3.5445824831075976
Validation loss: 2.876406520401276

Epoch: 5| Step: 1
Training loss: 3.052258552668641
Validation loss: 2.8744559091964907

Epoch: 5| Step: 2
Training loss: 2.895299317957293
Validation loss: 2.8769498047754065

Epoch: 5| Step: 3
Training loss: 2.655247847057404
Validation loss: 2.8748244846836393

Epoch: 5| Step: 4
Training loss: 3.0167880804873914
Validation loss: 2.8728612209032494

Epoch: 5| Step: 5
Training loss: 3.207545955860954
Validation loss: 2.8743010567937715

Epoch: 5| Step: 6
Training loss: 2.8099410389589203
Validation loss: 2.8725445049121854

Epoch: 5| Step: 7
Training loss: 3.488375842957366
Validation loss: 2.8742879776795562

Epoch: 5| Step: 8
Training loss: 3.504555870574128
Validation loss: 2.8720761010744282

Epoch: 5| Step: 9
Training loss: 3.199171948585479
Validation loss: 2.873808537654449

Epoch: 5| Step: 10
Training loss: 3.402727317868428
Validation loss: 2.8775096602542463

Epoch: 48| Step: 0
Training loss: 3.189409020907937
Validation loss: 2.8867795198684045

Epoch: 5| Step: 1
Training loss: 3.1278226692978826
Validation loss: 2.882609360685864

Epoch: 5| Step: 2
Training loss: 3.319433764693683
Validation loss: 2.8744549227882388

Epoch: 5| Step: 3
Training loss: 2.416682922922465
Validation loss: 2.869839095580632

Epoch: 5| Step: 4
Training loss: 3.625674086410909
Validation loss: 2.8678825827680368

Epoch: 5| Step: 5
Training loss: 3.2442555645464832
Validation loss: 2.8638712360171725

Epoch: 5| Step: 6
Training loss: 3.01865752337164
Validation loss: 2.8622886184889165

Epoch: 5| Step: 7
Training loss: 2.987024858430678
Validation loss: 2.8622721221548346

Epoch: 5| Step: 8
Training loss: 3.266312376259601
Validation loss: 2.8609170013215066

Epoch: 5| Step: 9
Training loss: 3.5484489276119104
Validation loss: 2.8582742097335863

Epoch: 5| Step: 10
Training loss: 2.85143323631462
Validation loss: 2.8599861326196265

Epoch: 49| Step: 0
Training loss: 2.409572635762994
Validation loss: 2.857266042895019

Epoch: 5| Step: 1
Training loss: 2.82205087445292
Validation loss: 2.8583797877146577

Epoch: 5| Step: 2
Training loss: 3.4240056898747167
Validation loss: 2.8567432315445833

Epoch: 5| Step: 3
Training loss: 3.0380664752470476
Validation loss: 2.858018251654475

Epoch: 5| Step: 4
Training loss: 3.474739471110006
Validation loss: 2.852191846946444

Epoch: 5| Step: 5
Training loss: 3.5009170420759825
Validation loss: 2.8535556446061037

Epoch: 5| Step: 6
Training loss: 3.731290429182207
Validation loss: 2.8511003448742196

Epoch: 5| Step: 7
Training loss: 3.376341800282007
Validation loss: 2.8524078460176088

Epoch: 5| Step: 8
Training loss: 2.510440388378803
Validation loss: 2.8533895710273587

Epoch: 5| Step: 9
Training loss: 2.8276962882663934
Validation loss: 2.856542708611463

Epoch: 5| Step: 10
Training loss: 3.3211499403473987
Validation loss: 2.8523324144789965

Epoch: 50| Step: 0
Training loss: 3.0307838632110484
Validation loss: 2.857126166731491

Epoch: 5| Step: 1
Training loss: 2.974586772269264
Validation loss: 2.8572863131683945

Epoch: 5| Step: 2
Training loss: 3.1322629831918687
Validation loss: 2.856433492488296

Epoch: 5| Step: 3
Training loss: 2.6829726654036605
Validation loss: 2.8460108313868577

Epoch: 5| Step: 4
Training loss: 3.448770530669991
Validation loss: 2.846497921007625

Epoch: 5| Step: 5
Training loss: 3.4154196688822007
Validation loss: 2.8442487940707752

Epoch: 5| Step: 6
Training loss: 3.4084697804890154
Validation loss: 2.844328774421818

Epoch: 5| Step: 7
Training loss: 2.716669097462446
Validation loss: 2.84274192268385

Epoch: 5| Step: 8
Training loss: 3.4572850365885004
Validation loss: 2.842028367500847

Epoch: 5| Step: 9
Training loss: 2.980062514551869
Validation loss: 2.841272565244808

Epoch: 5| Step: 10
Training loss: 3.3134287845619634
Validation loss: 2.8386539060347578

Epoch: 51| Step: 0
Training loss: 3.6199661029893626
Validation loss: 2.8394100784911798

Epoch: 5| Step: 1
Training loss: 2.8918871624198026
Validation loss: 2.8381433543713626

Epoch: 5| Step: 2
Training loss: 2.905092890923631
Validation loss: 2.8470287468022946

Epoch: 5| Step: 3
Training loss: 2.809011542345766
Validation loss: 2.85064077861183

Epoch: 5| Step: 4
Training loss: 3.023050130627204
Validation loss: 2.8667042593722054

Epoch: 5| Step: 5
Training loss: 3.2130412614288106
Validation loss: 2.8967593876796744

Epoch: 5| Step: 6
Training loss: 3.018120558295632
Validation loss: 2.891219985421865

Epoch: 5| Step: 7
Training loss: 2.8349935678883402
Validation loss: 2.8929595131937216

Epoch: 5| Step: 8
Training loss: 3.632672575850315
Validation loss: 2.8884672111425806

Epoch: 5| Step: 9
Training loss: 2.9848854467241983
Validation loss: 2.8407819373200454

Epoch: 5| Step: 10
Training loss: 3.6424453833889783
Validation loss: 2.8388758892819683

Epoch: 52| Step: 0
Training loss: 3.0477245222442217
Validation loss: 2.8530567802544655

Epoch: 5| Step: 1
Training loss: 3.4122317924877352
Validation loss: 2.8807222204998073

Epoch: 5| Step: 2
Training loss: 3.357880015735113
Validation loss: 2.8813304010904477

Epoch: 5| Step: 3
Training loss: 3.466385181320847
Validation loss: 2.8558663715255848

Epoch: 5| Step: 4
Training loss: 2.9389547438795764
Validation loss: 2.839782581482199

Epoch: 5| Step: 5
Training loss: 3.386342662446085
Validation loss: 2.8352573670426917

Epoch: 5| Step: 6
Training loss: 2.5299697275574617
Validation loss: 2.835844317660509

Epoch: 5| Step: 7
Training loss: 3.4283706118037887
Validation loss: 2.8341669955956257

Epoch: 5| Step: 8
Training loss: 3.1649319431406284
Validation loss: 2.8307162297753368

Epoch: 5| Step: 9
Training loss: 2.669099492722364
Validation loss: 2.841067746144492

Epoch: 5| Step: 10
Training loss: 3.1637417854434546
Validation loss: 2.8553177467742805

Epoch: 53| Step: 0
Training loss: 3.1293723989041236
Validation loss: 2.86799826006903

Epoch: 5| Step: 1
Training loss: 2.8179192784310585
Validation loss: 2.8518806292423724

Epoch: 5| Step: 2
Training loss: 3.6820790158837475
Validation loss: 2.831050068323406

Epoch: 5| Step: 3
Training loss: 2.9784949730329116
Validation loss: 2.8293786061040724

Epoch: 5| Step: 4
Training loss: 2.6719049820137983
Validation loss: 2.8252631849363135

Epoch: 5| Step: 5
Training loss: 2.787870521039982
Validation loss: 2.826927002480653

Epoch: 5| Step: 6
Training loss: 3.0353168067049325
Validation loss: 2.8253007219636106

Epoch: 5| Step: 7
Training loss: 3.3039349359659296
Validation loss: 2.824256820125972

Epoch: 5| Step: 8
Training loss: 2.977218275346572
Validation loss: 2.824507398433374

Epoch: 5| Step: 9
Training loss: 3.574628295781665
Validation loss: 2.82443380588737

Epoch: 5| Step: 10
Training loss: 3.5200460482966562
Validation loss: 2.825393170464542

Epoch: 54| Step: 0
Training loss: 2.6359779051808387
Validation loss: 2.823697844845575

Epoch: 5| Step: 1
Training loss: 2.864730738690845
Validation loss: 2.822386038615386

Epoch: 5| Step: 2
Training loss: 3.7599771653151572
Validation loss: 2.824557676796647

Epoch: 5| Step: 3
Training loss: 2.9646539639932183
Validation loss: 2.8200277339767448

Epoch: 5| Step: 4
Training loss: 3.2540755027541253
Validation loss: 2.8212734913670228

Epoch: 5| Step: 5
Training loss: 3.1720826029370603
Validation loss: 2.8198391910321163

Epoch: 5| Step: 6
Training loss: 2.899075090965503
Validation loss: 2.8186113089183245

Epoch: 5| Step: 7
Training loss: 3.3627391914464524
Validation loss: 2.8193403376309636

Epoch: 5| Step: 8
Training loss: 2.958007167691412
Validation loss: 2.818027616467031

Epoch: 5| Step: 9
Training loss: 2.9180529070339887
Validation loss: 2.8161554369797246

Epoch: 5| Step: 10
Training loss: 3.614780358359906
Validation loss: 2.8153201722477617

Epoch: 55| Step: 0
Training loss: 2.5694080373114985
Validation loss: 2.8146642035471023

Epoch: 5| Step: 1
Training loss: 3.172889133934212
Validation loss: 2.8119918683254714

Epoch: 5| Step: 2
Training loss: 3.272084687225931
Validation loss: 2.8120636012367894

Epoch: 5| Step: 3
Training loss: 3.828381463626957
Validation loss: 2.8094282286462917

Epoch: 5| Step: 4
Training loss: 3.110120061047229
Validation loss: 2.8069542903875995

Epoch: 5| Step: 5
Training loss: 3.2832057392352767
Validation loss: 2.810867435523078

Epoch: 5| Step: 6
Training loss: 2.704715855988074
Validation loss: 2.81281415855097

Epoch: 5| Step: 7
Training loss: 3.196120330244979
Validation loss: 2.8402248504368988

Epoch: 5| Step: 8
Training loss: 2.959242846590603
Validation loss: 2.8544363498188843

Epoch: 5| Step: 9
Training loss: 3.1717547314021424
Validation loss: 2.941554936037044

Epoch: 5| Step: 10
Training loss: 3.0721032741790566
Validation loss: 2.9327001391882495

Epoch: 56| Step: 0
Training loss: 3.09895303335725
Validation loss: 2.898406151715705

Epoch: 5| Step: 1
Training loss: 2.814284119041937
Validation loss: 2.8919129947397613

Epoch: 5| Step: 2
Training loss: 3.7978883497752274
Validation loss: 2.9000295561860336

Epoch: 5| Step: 3
Training loss: 2.9612036914996693
Validation loss: 2.845330577201249

Epoch: 5| Step: 4
Training loss: 2.540654736634573
Validation loss: 2.815084765005424

Epoch: 5| Step: 5
Training loss: 3.27106384307404
Validation loss: 2.839852024503071

Epoch: 5| Step: 6
Training loss: 3.353934917776167
Validation loss: 2.9776721122375633

Epoch: 5| Step: 7
Training loss: 2.9935102203485218
Validation loss: 2.8518768807024206

Epoch: 5| Step: 8
Training loss: 3.6205968752532036
Validation loss: 2.8182140591990787

Epoch: 5| Step: 9
Training loss: 2.9474573395337855
Validation loss: 2.809865133419331

Epoch: 5| Step: 10
Training loss: 3.1944875981461367
Validation loss: 2.8127539361691096

Epoch: 57| Step: 0
Training loss: 2.9787507911773923
Validation loss: 2.81904376398473

Epoch: 5| Step: 1
Training loss: 3.2103668968176544
Validation loss: 2.8126389399657077

Epoch: 5| Step: 2
Training loss: 3.21373246593581
Validation loss: 2.818125369670383

Epoch: 5| Step: 3
Training loss: 3.290198775434785
Validation loss: 2.835259550685638

Epoch: 5| Step: 4
Training loss: 2.8445446874253473
Validation loss: 2.8480350646359174

Epoch: 5| Step: 5
Training loss: 3.241063375812061
Validation loss: 2.8435506875914913

Epoch: 5| Step: 6
Training loss: 3.675828728688453
Validation loss: 2.8256366891794715

Epoch: 5| Step: 7
Training loss: 3.379809026345339
Validation loss: 2.8101010226221295

Epoch: 5| Step: 8
Training loss: 3.3051614624380523
Validation loss: 2.8063855629011876

Epoch: 5| Step: 9
Training loss: 2.895938917105968
Validation loss: 2.80171693314773

Epoch: 5| Step: 10
Training loss: 2.0672530690792144
Validation loss: 2.801999315718535

Epoch: 58| Step: 0
Training loss: 3.6153102147552394
Validation loss: 2.8039993034571293

Epoch: 5| Step: 1
Training loss: 3.5342030288587463
Validation loss: 2.8028993953376973

Epoch: 5| Step: 2
Training loss: 3.2505284393291647
Validation loss: 2.8020188695907216

Epoch: 5| Step: 3
Training loss: 3.2312517059144583
Validation loss: 2.8064138393196174

Epoch: 5| Step: 4
Training loss: 3.240088682020663
Validation loss: 2.803240380307757

Epoch: 5| Step: 5
Training loss: 2.9773166131750064
Validation loss: 2.801414649359538

Epoch: 5| Step: 6
Training loss: 2.8402556024964034
Validation loss: 2.8023403507456774

Epoch: 5| Step: 7
Training loss: 2.6524036159135784
Validation loss: 2.807443356733028

Epoch: 5| Step: 8
Training loss: 3.04648701080353
Validation loss: 2.8175480904139043

Epoch: 5| Step: 9
Training loss: 2.667627896475664
Validation loss: 2.816917841862803

Epoch: 5| Step: 10
Training loss: 3.062384934112656
Validation loss: 2.8202227620033664

Epoch: 59| Step: 0
Training loss: 3.064148595398901
Validation loss: 2.8224582167412096

Epoch: 5| Step: 1
Training loss: 3.0375830179808236
Validation loss: 2.811706229510839

Epoch: 5| Step: 2
Training loss: 3.264491564433177
Validation loss: 2.7917146680142992

Epoch: 5| Step: 3
Training loss: 3.163482838974372
Validation loss: 2.7871836642410246

Epoch: 5| Step: 4
Training loss: 3.1605467301631407
Validation loss: 2.7835220416137987

Epoch: 5| Step: 5
Training loss: 3.3212558976861506
Validation loss: 2.7842305808567667

Epoch: 5| Step: 6
Training loss: 3.4014555059593232
Validation loss: 2.787739362519011

Epoch: 5| Step: 7
Training loss: 3.3361910649936637
Validation loss: 2.78534360816146

Epoch: 5| Step: 8
Training loss: 3.008483653306415
Validation loss: 2.783927774152147

Epoch: 5| Step: 9
Training loss: 2.40548931830379
Validation loss: 2.784240372325465

Epoch: 5| Step: 10
Training loss: 2.90207380269045
Validation loss: 2.7764915477786785

Epoch: 60| Step: 0
Training loss: 2.728695273031858
Validation loss: 2.772048311570059

Epoch: 5| Step: 1
Training loss: 3.487284177165952
Validation loss: 2.7654838287287524

Epoch: 5| Step: 2
Training loss: 3.573498662734592
Validation loss: 2.7609142044698123

Epoch: 5| Step: 3
Training loss: 3.536362988961578
Validation loss: 2.7578471549746975

Epoch: 5| Step: 4
Training loss: 2.7638598482618
Validation loss: 2.7589441447038228

Epoch: 5| Step: 5
Training loss: 2.5900194847817404
Validation loss: 2.760797426908257

Epoch: 5| Step: 6
Training loss: 2.383792563079927
Validation loss: 2.7627280689091243

Epoch: 5| Step: 7
Training loss: 3.2582492306937487
Validation loss: 2.772575728662697

Epoch: 5| Step: 8
Training loss: 3.225431747516252
Validation loss: 2.7748086985513027

Epoch: 5| Step: 9
Training loss: 2.794691373542354
Validation loss: 2.779857430202154

Epoch: 5| Step: 10
Training loss: 3.3102246513078937
Validation loss: 2.789496335019013

Epoch: 61| Step: 0
Training loss: 3.1625149933832764
Validation loss: 2.7712985655216

Epoch: 5| Step: 1
Training loss: 2.9230117626495113
Validation loss: 2.754165863155641

Epoch: 5| Step: 2
Training loss: 1.982106271060003
Validation loss: 2.757718780653247

Epoch: 5| Step: 3
Training loss: 3.784872038478481
Validation loss: 2.7617586229323656

Epoch: 5| Step: 4
Training loss: 3.2515198015070252
Validation loss: 2.7604951989365536

Epoch: 5| Step: 5
Training loss: 2.969375865617392
Validation loss: 2.7621231949101492

Epoch: 5| Step: 6
Training loss: 2.7637790187380222
Validation loss: 2.7588000621643523

Epoch: 5| Step: 7
Training loss: 3.3002172225204074
Validation loss: 2.755677910566027

Epoch: 5| Step: 8
Training loss: 3.2022580345875573
Validation loss: 2.7544551104891206

Epoch: 5| Step: 9
Training loss: 3.1450851426478734
Validation loss: 2.753175514801332

Epoch: 5| Step: 10
Training loss: 3.2349183736464315
Validation loss: 2.7517178931853348

Epoch: 62| Step: 0
Training loss: 3.4161700066065337
Validation loss: 2.7504812175676583

Epoch: 5| Step: 1
Training loss: 2.64783941396836
Validation loss: 2.7490658296731154

Epoch: 5| Step: 2
Training loss: 3.1161916571402926
Validation loss: 2.7497842597796565

Epoch: 5| Step: 3
Training loss: 3.3442659069184013
Validation loss: 2.749189212560914

Epoch: 5| Step: 4
Training loss: 2.741827003714556
Validation loss: 2.751059836004788

Epoch: 5| Step: 5
Training loss: 2.2631352918422993
Validation loss: 2.757281774565602

Epoch: 5| Step: 6
Training loss: 3.465794584426554
Validation loss: 2.77101593624844

Epoch: 5| Step: 7
Training loss: 3.451035639907974
Validation loss: 2.77641780670452

Epoch: 5| Step: 8
Training loss: 2.73305911417628
Validation loss: 2.7647861631243402

Epoch: 5| Step: 9
Training loss: 3.2497241563377584
Validation loss: 2.750961960488382

Epoch: 5| Step: 10
Training loss: 3.0540592884236926
Validation loss: 2.751912611596173

Epoch: 63| Step: 0
Training loss: 3.4227959773928163
Validation loss: 2.7422086901097695

Epoch: 5| Step: 1
Training loss: 3.300173009325343
Validation loss: 2.746908338684787

Epoch: 5| Step: 2
Training loss: 3.489565007555464
Validation loss: 2.742114706714861

Epoch: 5| Step: 3
Training loss: 2.9047056627449566
Validation loss: 2.7427488928637622

Epoch: 5| Step: 4
Training loss: 2.658267522812434
Validation loss: 2.7401993475878457

Epoch: 5| Step: 5
Training loss: 2.6717443601559996
Validation loss: 2.740775257788929

Epoch: 5| Step: 6
Training loss: 3.1048763069909673
Validation loss: 2.7376722462836636

Epoch: 5| Step: 7
Training loss: 3.444657243971072
Validation loss: 2.737807431716082

Epoch: 5| Step: 8
Training loss: 2.714994621201275
Validation loss: 2.7370133804348566

Epoch: 5| Step: 9
Training loss: 2.7527129056463306
Validation loss: 2.735905966917824

Epoch: 5| Step: 10
Training loss: 3.1123120415860717
Validation loss: 2.734810088857622

Epoch: 64| Step: 0
Training loss: 3.112454217168067
Validation loss: 2.735657079942268

Epoch: 5| Step: 1
Training loss: 3.4242155527199594
Validation loss: 2.737168735448134

Epoch: 5| Step: 2
Training loss: 2.9986729865860595
Validation loss: 2.739019326428176

Epoch: 5| Step: 3
Training loss: 3.2462716357979398
Validation loss: 2.7544498760859244

Epoch: 5| Step: 4
Training loss: 3.0966093163026716
Validation loss: 2.7572821827350413

Epoch: 5| Step: 5
Training loss: 3.270625178684993
Validation loss: 2.7429451882121314

Epoch: 5| Step: 6
Training loss: 3.4766764761425795
Validation loss: 2.735547689540443

Epoch: 5| Step: 7
Training loss: 2.6108151419166448
Validation loss: 2.7311500613444175

Epoch: 5| Step: 8
Training loss: 2.7050397849550563
Validation loss: 2.729379932256122

Epoch: 5| Step: 9
Training loss: 3.064576826644065
Validation loss: 2.728445845751436

Epoch: 5| Step: 10
Training loss: 2.383020710837921
Validation loss: 2.7264847348704246

Epoch: 65| Step: 0
Training loss: 3.0216361897259443
Validation loss: 2.727480396460361

Epoch: 5| Step: 1
Training loss: 3.4696522132215053
Validation loss: 2.7303194784535414

Epoch: 5| Step: 2
Training loss: 3.132476255870315
Validation loss: 2.7272897776359404

Epoch: 5| Step: 3
Training loss: 2.7755782341147235
Validation loss: 2.725713360985565

Epoch: 5| Step: 4
Training loss: 3.580903685969635
Validation loss: 2.7303962433239777

Epoch: 5| Step: 5
Training loss: 2.865817124510511
Validation loss: 2.729199399347125

Epoch: 5| Step: 6
Training loss: 2.5985172078287886
Validation loss: 2.729217599899029

Epoch: 5| Step: 7
Training loss: 3.357600111388431
Validation loss: 2.729469477588948

Epoch: 5| Step: 8
Training loss: 2.644632672797782
Validation loss: 2.7272517207049223

Epoch: 5| Step: 9
Training loss: 3.163638540992665
Validation loss: 2.7253863967341374

Epoch: 5| Step: 10
Training loss: 2.8893213580097097
Validation loss: 2.7247469689072266

Epoch: 66| Step: 0
Training loss: 3.4148180232565846
Validation loss: 2.7198446312280544

Epoch: 5| Step: 1
Training loss: 3.3576746696205872
Validation loss: 2.7160168342835824

Epoch: 5| Step: 2
Training loss: 3.1171220280170022
Validation loss: 2.7152097596801195

Epoch: 5| Step: 3
Training loss: 2.996882726442562
Validation loss: 2.720163438318468

Epoch: 5| Step: 4
Training loss: 2.7431847478861417
Validation loss: 2.72483548385289

Epoch: 5| Step: 5
Training loss: 2.5355662527182816
Validation loss: 2.7508599119862613

Epoch: 5| Step: 6
Training loss: 3.3173337971522425
Validation loss: 2.7565941203720734

Epoch: 5| Step: 7
Training loss: 2.941734184232347
Validation loss: 2.7366776491377234

Epoch: 5| Step: 8
Training loss: 2.924672465448288
Validation loss: 2.74006086236682

Epoch: 5| Step: 9
Training loss: 3.1677522973410612
Validation loss: 2.729403586876437

Epoch: 5| Step: 10
Training loss: 2.880407141411257
Validation loss: 2.7204889646745016

Epoch: 67| Step: 0
Training loss: 2.731946204380524
Validation loss: 2.7121091696523405

Epoch: 5| Step: 1
Training loss: 2.9537210821608006
Validation loss: 2.7111769688620546

Epoch: 5| Step: 2
Training loss: 3.5030654017392115
Validation loss: 2.7134923870036616

Epoch: 5| Step: 3
Training loss: 3.31029163378147
Validation loss: 2.7153077078571606

Epoch: 5| Step: 4
Training loss: 2.8567038811923324
Validation loss: 2.7225328002762996

Epoch: 5| Step: 5
Training loss: 3.1041691585931868
Validation loss: 2.7264949292938345

Epoch: 5| Step: 6
Training loss: 3.017235044463324
Validation loss: 2.726347212679713

Epoch: 5| Step: 7
Training loss: 3.0500745357723784
Validation loss: 2.7184930269057896

Epoch: 5| Step: 8
Training loss: 2.903106301763823
Validation loss: 2.723279319017967

Epoch: 5| Step: 9
Training loss: 2.621373168787508
Validation loss: 2.7075813713591232

Epoch: 5| Step: 10
Training loss: 3.3739386408483294
Validation loss: 2.7111470533134985

Epoch: 68| Step: 0
Training loss: 3.260554415359452
Validation loss: 2.70859398419799

Epoch: 5| Step: 1
Training loss: 2.9061113550073467
Validation loss: 2.7100300102296218

Epoch: 5| Step: 2
Training loss: 2.8843161530448307
Validation loss: 2.7126627644552412

Epoch: 5| Step: 3
Training loss: 3.1274407582576416
Validation loss: 2.7122795223302654

Epoch: 5| Step: 4
Training loss: 3.0120847803674273
Validation loss: 2.7108426991376606

Epoch: 5| Step: 5
Training loss: 3.5991824016387546
Validation loss: 2.710474763770187

Epoch: 5| Step: 6
Training loss: 2.8311350279110052
Validation loss: 2.707915484155257

Epoch: 5| Step: 7
Training loss: 3.0714227353164127
Validation loss: 2.7050748714955954

Epoch: 5| Step: 8
Training loss: 3.049521211659517
Validation loss: 2.7060680861500397

Epoch: 5| Step: 9
Training loss: 2.732186362510531
Validation loss: 2.7027680114299955

Epoch: 5| Step: 10
Training loss: 2.8660869929014554
Validation loss: 2.704754393033722

Epoch: 69| Step: 0
Training loss: 3.4258217542770137
Validation loss: 2.7028050007717863

Epoch: 5| Step: 1
Training loss: 2.997009853475396
Validation loss: 2.7000804767593958

Epoch: 5| Step: 2
Training loss: 3.077625989403497
Validation loss: 2.7088777782111797

Epoch: 5| Step: 3
Training loss: 2.6626311901169752
Validation loss: 2.702599880301183

Epoch: 5| Step: 4
Training loss: 2.9961163496336374
Validation loss: 2.6966611441711823

Epoch: 5| Step: 5
Training loss: 3.4309576024610466
Validation loss: 2.6939609472115085

Epoch: 5| Step: 6
Training loss: 3.1762164991849695
Validation loss: 2.692484787443556

Epoch: 5| Step: 7
Training loss: 2.9826186839021194
Validation loss: 2.69663256776575

Epoch: 5| Step: 8
Training loss: 3.006853698896064
Validation loss: 2.696061710132308

Epoch: 5| Step: 9
Training loss: 2.471103367408371
Validation loss: 2.697797869497308

Epoch: 5| Step: 10
Training loss: 3.0779040881823794
Validation loss: 2.6982073456043545

Epoch: 70| Step: 0
Training loss: 3.270729711231594
Validation loss: 2.6922456070783194

Epoch: 5| Step: 1
Training loss: 3.279269974344325
Validation loss: 2.6913177720014643

Epoch: 5| Step: 2
Training loss: 2.834476819885508
Validation loss: 2.691957926430067

Epoch: 5| Step: 3
Training loss: 2.845710162675752
Validation loss: 2.6996267409376404

Epoch: 5| Step: 4
Training loss: 2.8912052706215996
Validation loss: 2.718132244002337

Epoch: 5| Step: 5
Training loss: 2.6517772041393424
Validation loss: 2.7110554446442983

Epoch: 5| Step: 6
Training loss: 3.0670698674828856
Validation loss: 2.7115164191799717

Epoch: 5| Step: 7
Training loss: 3.2244419768406005
Validation loss: 2.6981295879606377

Epoch: 5| Step: 8
Training loss: 2.4072188371453116
Validation loss: 2.69325338770518

Epoch: 5| Step: 9
Training loss: 3.429095449592646
Validation loss: 2.6923799169105136

Epoch: 5| Step: 10
Training loss: 3.335826148289771
Validation loss: 2.6856567995128766

Epoch: 71| Step: 0
Training loss: 2.9767832436397277
Validation loss: 2.691072246180242

Epoch: 5| Step: 1
Training loss: 3.416726336694714
Validation loss: 2.698032140230366

Epoch: 5| Step: 2
Training loss: 2.8264458661242498
Validation loss: 2.70615970828785

Epoch: 5| Step: 3
Training loss: 2.8814149689354998
Validation loss: 2.7009770892420266

Epoch: 5| Step: 4
Training loss: 2.817288962772893
Validation loss: 2.693851896390245

Epoch: 5| Step: 5
Training loss: 3.035366762929654
Validation loss: 2.6936071507176513

Epoch: 5| Step: 6
Training loss: 2.2711700983011998
Validation loss: 2.6893087101919466

Epoch: 5| Step: 7
Training loss: 3.0437364895185905
Validation loss: 2.6886981411975217

Epoch: 5| Step: 8
Training loss: 3.213043635936665
Validation loss: 2.6867493661241997

Epoch: 5| Step: 9
Training loss: 3.1934643462773815
Validation loss: 2.6836728573358406

Epoch: 5| Step: 10
Training loss: 3.6550583160799652
Validation loss: 2.6858151843149

Epoch: 72| Step: 0
Training loss: 2.039405063193623
Validation loss: 2.6831101720723685

Epoch: 5| Step: 1
Training loss: 2.9394448517844536
Validation loss: 2.6842195694331035

Epoch: 5| Step: 2
Training loss: 3.4236247844994727
Validation loss: 2.683428544658655

Epoch: 5| Step: 3
Training loss: 2.9279213426374477
Validation loss: 2.684003686248682

Epoch: 5| Step: 4
Training loss: 3.3734627507630988
Validation loss: 2.6934428860298016

Epoch: 5| Step: 5
Training loss: 3.275263966412878
Validation loss: 2.7097078765162372

Epoch: 5| Step: 6
Training loss: 3.360446492910409
Validation loss: 2.725547721332304

Epoch: 5| Step: 7
Training loss: 2.333783946349736
Validation loss: 2.704657024751821

Epoch: 5| Step: 8
Training loss: 2.74657382811275
Validation loss: 2.6965857985483748

Epoch: 5| Step: 9
Training loss: 3.19778070978851
Validation loss: 2.683846183186714

Epoch: 5| Step: 10
Training loss: 3.364862688275661
Validation loss: 2.671024990636142

Epoch: 73| Step: 0
Training loss: 3.026885360961548
Validation loss: 2.6747264210776143

Epoch: 5| Step: 1
Training loss: 2.9532727401350036
Validation loss: 2.6741670081128364

Epoch: 5| Step: 2
Training loss: 2.175637697589908
Validation loss: 2.6776283973020214

Epoch: 5| Step: 3
Training loss: 3.2381311986967334
Validation loss: 2.6755174114397184

Epoch: 5| Step: 4
Training loss: 2.994525683104498
Validation loss: 2.6762167356836937

Epoch: 5| Step: 5
Training loss: 3.4452338869290906
Validation loss: 2.6716382907036076

Epoch: 5| Step: 6
Training loss: 2.5167085197791685
Validation loss: 2.6715531528639826

Epoch: 5| Step: 7
Training loss: 3.679294573301913
Validation loss: 2.6725534622212384

Epoch: 5| Step: 8
Training loss: 2.939427494178122
Validation loss: 2.6689120909025243

Epoch: 5| Step: 9
Training loss: 2.8453704911868156
Validation loss: 2.6701917178811416

Epoch: 5| Step: 10
Training loss: 3.155833150700625
Validation loss: 2.6806553999097407

Epoch: 74| Step: 0
Training loss: 3.2562685447940916
Validation loss: 2.674114801373154

Epoch: 5| Step: 1
Training loss: 3.1735764623782163
Validation loss: 2.670805109466934

Epoch: 5| Step: 2
Training loss: 2.9598186865253235
Validation loss: 2.6699360061248623

Epoch: 5| Step: 3
Training loss: 3.0311661541540995
Validation loss: 2.668618549851112

Epoch: 5| Step: 4
Training loss: 3.452101750037902
Validation loss: 2.6673410649858496

Epoch: 5| Step: 5
Training loss: 3.0468521508558313
Validation loss: 2.669707732782746

Epoch: 5| Step: 6
Training loss: 2.49779079099948
Validation loss: 2.671568197537404

Epoch: 5| Step: 7
Training loss: 3.262715480893965
Validation loss: 2.6692585219072558

Epoch: 5| Step: 8
Training loss: 2.1594503121830226
Validation loss: 2.6678880825179196

Epoch: 5| Step: 9
Training loss: 3.4655117006072707
Validation loss: 2.665304967499275

Epoch: 5| Step: 10
Training loss: 2.4297144848468832
Validation loss: 2.6660591678157957

Epoch: 75| Step: 0
Training loss: 3.0024383490313147
Validation loss: 2.6648537936537715

Epoch: 5| Step: 1
Training loss: 2.480534686316055
Validation loss: 2.665783441376599

Epoch: 5| Step: 2
Training loss: 3.001742492712143
Validation loss: 2.6663961068176274

Epoch: 5| Step: 3
Training loss: 3.3140006355004172
Validation loss: 2.6625482301312156

Epoch: 5| Step: 4
Training loss: 3.0288605071346035
Validation loss: 2.6622888327938257

Epoch: 5| Step: 5
Training loss: 2.9795938110025086
Validation loss: 2.6597878798853323

Epoch: 5| Step: 6
Training loss: 2.847881794855303
Validation loss: 2.660206822552209

Epoch: 5| Step: 7
Training loss: 3.393340961120466
Validation loss: 2.6566019364350058

Epoch: 5| Step: 8
Training loss: 3.080433401107654
Validation loss: 2.6595635060246123

Epoch: 5| Step: 9
Training loss: 2.6604444708948245
Validation loss: 2.6557646943248705

Epoch: 5| Step: 10
Training loss: 3.243602030471691
Validation loss: 2.6584510047208427

Epoch: 76| Step: 0
Training loss: 3.363123873441231
Validation loss: 2.6574439534086225

Epoch: 5| Step: 1
Training loss: 3.2789531116349897
Validation loss: 2.6573652017145357

Epoch: 5| Step: 2
Training loss: 3.052126071530885
Validation loss: 2.65294853676941

Epoch: 5| Step: 3
Training loss: 3.2975840597016384
Validation loss: 2.656328641920477

Epoch: 5| Step: 4
Training loss: 2.7139898260793114
Validation loss: 2.6523705776122273

Epoch: 5| Step: 5
Training loss: 3.3000565495125183
Validation loss: 2.6590381859261014

Epoch: 5| Step: 6
Training loss: 2.6848327353037913
Validation loss: 2.6555703632198586

Epoch: 5| Step: 7
Training loss: 2.962998611403522
Validation loss: 2.6646037829467786

Epoch: 5| Step: 8
Training loss: 2.654623543438721
Validation loss: 2.653217579193979

Epoch: 5| Step: 9
Training loss: 2.852768065739284
Validation loss: 2.6511204431006243

Epoch: 5| Step: 10
Training loss: 2.62360290405792
Validation loss: 2.6537031168952225

Epoch: 77| Step: 0
Training loss: 2.8838037786938258
Validation loss: 2.6509133900663593

Epoch: 5| Step: 1
Training loss: 2.783027252529873
Validation loss: 2.6578949459731858

Epoch: 5| Step: 2
Training loss: 2.8522638999860397
Validation loss: 2.6529663752786647

Epoch: 5| Step: 3
Training loss: 2.96892699667686
Validation loss: 2.652574059831478

Epoch: 5| Step: 4
Training loss: 3.426550331911677
Validation loss: 2.6499523617499947

Epoch: 5| Step: 5
Training loss: 3.154438669897317
Validation loss: 2.648465740733176

Epoch: 5| Step: 6
Training loss: 2.7397522288042833
Validation loss: 2.6470317637587026

Epoch: 5| Step: 7
Training loss: 2.243491401752806
Validation loss: 2.6511634888765028

Epoch: 5| Step: 8
Training loss: 2.967071701289138
Validation loss: 2.6503956547939214

Epoch: 5| Step: 9
Training loss: 3.266966475787356
Validation loss: 2.6587289118982325

Epoch: 5| Step: 10
Training loss: 3.490163058431293
Validation loss: 2.654617138732017

Epoch: 78| Step: 0
Training loss: 3.3481939144423065
Validation loss: 2.654204374366722

Epoch: 5| Step: 1
Training loss: 2.562199086454909
Validation loss: 2.6481291467739774

Epoch: 5| Step: 2
Training loss: 3.064109690612586
Validation loss: 2.646239984791481

Epoch: 5| Step: 3
Training loss: 3.094421467980175
Validation loss: 2.6456863256543244

Epoch: 5| Step: 4
Training loss: 3.1025608867661743
Validation loss: 2.64733681575596

Epoch: 5| Step: 5
Training loss: 3.013254291234814
Validation loss: 2.6478012162289684

Epoch: 5| Step: 6
Training loss: 2.7118280800309837
Validation loss: 2.6486109751393005

Epoch: 5| Step: 7
Training loss: 2.8316917900002267
Validation loss: 2.6441030512063017

Epoch: 5| Step: 8
Training loss: 2.880904561351134
Validation loss: 2.643991967279367

Epoch: 5| Step: 9
Training loss: 3.0819755520157286
Validation loss: 2.645379080198998

Epoch: 5| Step: 10
Training loss: 3.1358276469591093
Validation loss: 2.643227687907819

Epoch: 79| Step: 0
Training loss: 2.877709480303275
Validation loss: 2.6522065669254338

Epoch: 5| Step: 1
Training loss: 2.706579569776085
Validation loss: 2.690632953584165

Epoch: 5| Step: 2
Training loss: 3.0359459123480175
Validation loss: 2.752892731889292

Epoch: 5| Step: 3
Training loss: 2.9466523783180567
Validation loss: 2.8122056823014834

Epoch: 5| Step: 4
Training loss: 2.2369406315271423
Validation loss: 2.6944894260071015

Epoch: 5| Step: 5
Training loss: 3.125895410048613
Validation loss: 2.6611945952323577

Epoch: 5| Step: 6
Training loss: 3.0237999040917622
Validation loss: 2.6412725060670583

Epoch: 5| Step: 7
Training loss: 3.111583902749546
Validation loss: 2.6387025082594078

Epoch: 5| Step: 8
Training loss: 3.523057193912291
Validation loss: 2.6418809655602544

Epoch: 5| Step: 9
Training loss: 2.974795800902622
Validation loss: 2.6437695565760126

Epoch: 5| Step: 10
Training loss: 3.3309523343901954
Validation loss: 2.6503327352538935

Epoch: 80| Step: 0
Training loss: 3.4787278193631272
Validation loss: 2.6500418899825564

Epoch: 5| Step: 1
Training loss: 3.352605199564289
Validation loss: 2.644644840364024

Epoch: 5| Step: 2
Training loss: 2.856693532217224
Validation loss: 2.643695814394423

Epoch: 5| Step: 3
Training loss: 2.9254886903650155
Validation loss: 2.6411587172806934

Epoch: 5| Step: 4
Training loss: 2.7212993902263563
Validation loss: 2.6364513465498773

Epoch: 5| Step: 5
Training loss: 2.9515059942811135
Validation loss: 2.6377912708019413

Epoch: 5| Step: 6
Training loss: 3.229932452224823
Validation loss: 2.6481316454260413

Epoch: 5| Step: 7
Training loss: 2.981584612543775
Validation loss: 2.653149373483069

Epoch: 5| Step: 8
Training loss: 2.6360001552622263
Validation loss: 2.6430206421868903

Epoch: 5| Step: 9
Training loss: 2.7936301561973944
Validation loss: 2.6637874282393477

Epoch: 5| Step: 10
Training loss: 2.784735306740513
Validation loss: 2.6540187413587826

Epoch: 81| Step: 0
Training loss: 2.764746919883601
Validation loss: 2.6461812417915276

Epoch: 5| Step: 1
Training loss: 3.346304514871592
Validation loss: 2.6373900405706254

Epoch: 5| Step: 2
Training loss: 3.1930977530445332
Validation loss: 2.634867027703892

Epoch: 5| Step: 3
Training loss: 2.7390441267199215
Validation loss: 2.6374037540326087

Epoch: 5| Step: 4
Training loss: 3.0362146365924145
Validation loss: 2.638850564971625

Epoch: 5| Step: 5
Training loss: 3.03694922708796
Validation loss: 2.6403022671318133

Epoch: 5| Step: 6
Training loss: 3.077447342224565
Validation loss: 2.637751445400851

Epoch: 5| Step: 7
Training loss: 3.326310070345522
Validation loss: 2.6342528217930656

Epoch: 5| Step: 8
Training loss: 2.6793203741884812
Validation loss: 2.635285886215525

Epoch: 5| Step: 9
Training loss: 2.9312460047322517
Validation loss: 2.651101351981014

Epoch: 5| Step: 10
Training loss: 2.7208391252799746
Validation loss: 2.679481366634731

Epoch: 82| Step: 0
Training loss: 2.8534507874649555
Validation loss: 2.6871949824297334

Epoch: 5| Step: 1
Training loss: 2.962630218348038
Validation loss: 2.6555506114244642

Epoch: 5| Step: 2
Training loss: 3.158285108078999
Validation loss: 2.6436223125922083

Epoch: 5| Step: 3
Training loss: 2.7750611616388174
Validation loss: 2.6273136012204366

Epoch: 5| Step: 4
Training loss: 2.785218397305841
Validation loss: 2.627074143433657

Epoch: 5| Step: 5
Training loss: 3.2554700741125515
Validation loss: 2.6265216368572153

Epoch: 5| Step: 6
Training loss: 3.2261078816755315
Validation loss: 2.6284591162174267

Epoch: 5| Step: 7
Training loss: 2.9596756231572954
Validation loss: 2.629502923348645

Epoch: 5| Step: 8
Training loss: 2.7530253848046264
Validation loss: 2.6309895797215512

Epoch: 5| Step: 9
Training loss: 2.9751865681081697
Validation loss: 2.6296119978050734

Epoch: 5| Step: 10
Training loss: 3.067790852307402
Validation loss: 2.6358984207310434

Epoch: 83| Step: 0
Training loss: 2.967914985878693
Validation loss: 2.6489272537631865

Epoch: 5| Step: 1
Training loss: 2.9212549541073907
Validation loss: 2.6757097649537127

Epoch: 5| Step: 2
Training loss: 2.785702859065616
Validation loss: 2.6725547677569748

Epoch: 5| Step: 3
Training loss: 3.3155641598741816
Validation loss: 2.6704219985203217

Epoch: 5| Step: 4
Training loss: 2.7741974984775473
Validation loss: 2.6284571099428127

Epoch: 5| Step: 5
Training loss: 3.1675608192391667
Validation loss: 2.6299687310031152

Epoch: 5| Step: 6
Training loss: 2.8955504647469854
Validation loss: 2.627072732348491

Epoch: 5| Step: 7
Training loss: 2.9740838571615145
Validation loss: 2.626254418758639

Epoch: 5| Step: 8
Training loss: 2.5352030839399924
Validation loss: 2.6250846085436774

Epoch: 5| Step: 9
Training loss: 3.1671409419081185
Validation loss: 2.6258170189007024

Epoch: 5| Step: 10
Training loss: 3.16788746909446
Validation loss: 2.6268484499515194

Epoch: 84| Step: 0
Training loss: 2.5121133117692387
Validation loss: 2.624086903857272

Epoch: 5| Step: 1
Training loss: 2.7769952869313475
Validation loss: 2.6204141991797614

Epoch: 5| Step: 2
Training loss: 2.9095620592011393
Validation loss: 2.6227772697795735

Epoch: 5| Step: 3
Training loss: 3.357377704997773
Validation loss: 2.6227029701063715

Epoch: 5| Step: 4
Training loss: 3.0247296866710585
Validation loss: 2.628692984968133

Epoch: 5| Step: 5
Training loss: 2.652734382190123
Validation loss: 2.628912014246322

Epoch: 5| Step: 6
Training loss: 3.0484453898239297
Validation loss: 2.638846375864693

Epoch: 5| Step: 7
Training loss: 3.2609518828575212
Validation loss: 2.6611274976132555

Epoch: 5| Step: 8
Training loss: 3.1768025425301576
Validation loss: 2.6896132907486

Epoch: 5| Step: 9
Training loss: 3.0664810463111056
Validation loss: 2.6938017332620983

Epoch: 5| Step: 10
Training loss: 2.84371998530048
Validation loss: 2.6517282700013314

Epoch: 85| Step: 0
Training loss: 2.714864124249088
Validation loss: 2.618215872091741

Epoch: 5| Step: 1
Training loss: 2.9987426348107205
Validation loss: 2.631802255258688

Epoch: 5| Step: 2
Training loss: 3.3655102440158586
Validation loss: 2.6533727902200344

Epoch: 5| Step: 3
Training loss: 3.41545038361517
Validation loss: 2.677568632923155

Epoch: 5| Step: 4
Training loss: 2.6311232583879605
Validation loss: 2.6740899434474725

Epoch: 5| Step: 5
Training loss: 3.2491873678868908
Validation loss: 2.647645681489378

Epoch: 5| Step: 6
Training loss: 2.925383231334127
Validation loss: 2.634959250783772

Epoch: 5| Step: 7
Training loss: 2.9906779731993685
Validation loss: 2.629968165630717

Epoch: 5| Step: 8
Training loss: 2.918111570404583
Validation loss: 2.6255797836287336

Epoch: 5| Step: 9
Training loss: 2.9599802689281303
Validation loss: 2.6204213625324413

Epoch: 5| Step: 10
Training loss: 2.861144805347672
Validation loss: 2.621154773686995

Epoch: 86| Step: 0
Training loss: 2.530898835112581
Validation loss: 2.629809452994293

Epoch: 5| Step: 1
Training loss: 2.7049305789522
Validation loss: 2.6708160645045975

Epoch: 5| Step: 2
Training loss: 3.2744849811977828
Validation loss: 2.6451719324736733

Epoch: 5| Step: 3
Training loss: 2.471910409396449
Validation loss: 2.6530484444045803

Epoch: 5| Step: 4
Training loss: 3.1470639851104703
Validation loss: 2.6449528505604802

Epoch: 5| Step: 5
Training loss: 3.3678312106752966
Validation loss: 2.6378085062272776

Epoch: 5| Step: 6
Training loss: 3.3192513239895893
Validation loss: 2.635426741896967

Epoch: 5| Step: 7
Training loss: 3.0642273371747666
Validation loss: 2.6220183297472412

Epoch: 5| Step: 8
Training loss: 2.7322374108459306
Validation loss: 2.6207843629281067

Epoch: 5| Step: 9
Training loss: 3.2270523696967075
Validation loss: 2.62552724153977

Epoch: 5| Step: 10
Training loss: 2.73420409622159
Validation loss: 2.6226723200532027

Epoch: 87| Step: 0
Training loss: 2.9292486650503435
Validation loss: 2.6262567151705616

Epoch: 5| Step: 1
Training loss: 2.873822344200809
Validation loss: 2.6248841990190153

Epoch: 5| Step: 2
Training loss: 2.7682784115899013
Validation loss: 2.6213092641081044

Epoch: 5| Step: 3
Training loss: 3.2398585031954004
Validation loss: 2.61828286995391

Epoch: 5| Step: 4
Training loss: 2.9657241659999984
Validation loss: 2.6237333975592136

Epoch: 5| Step: 5
Training loss: 2.975167656029141
Validation loss: 2.6537739224683206

Epoch: 5| Step: 6
Training loss: 2.847062246485624
Validation loss: 2.659773842314508

Epoch: 5| Step: 7
Training loss: 2.9927546110645857
Validation loss: 2.6524969564116168

Epoch: 5| Step: 8
Training loss: 2.973418410014915
Validation loss: 2.663428950840049

Epoch: 5| Step: 9
Training loss: 3.391209143319732
Validation loss: 2.6393238562616608

Epoch: 5| Step: 10
Training loss: 2.775473349812828
Validation loss: 2.6208343551114406

Epoch: 88| Step: 0
Training loss: 2.9409873228399794
Validation loss: 2.614245370135045

Epoch: 5| Step: 1
Training loss: 2.7794315522644455
Validation loss: 2.610204091264556

Epoch: 5| Step: 2
Training loss: 2.782828493838049
Validation loss: 2.6132916486268876

Epoch: 5| Step: 3
Training loss: 3.0652881308905395
Validation loss: 2.613236225430137

Epoch: 5| Step: 4
Training loss: 2.9035505658360248
Validation loss: 2.611831788638982

Epoch: 5| Step: 5
Training loss: 3.138447476372782
Validation loss: 2.613979856466749

Epoch: 5| Step: 6
Training loss: 3.047223349978357
Validation loss: 2.612112539725076

Epoch: 5| Step: 7
Training loss: 2.6554267954058304
Validation loss: 2.612132470801785

Epoch: 5| Step: 8
Training loss: 3.4872450704614266
Validation loss: 2.613953238004259

Epoch: 5| Step: 9
Training loss: 2.828958799416129
Validation loss: 2.6126870390374624

Epoch: 5| Step: 10
Training loss: 2.8495695491776623
Validation loss: 2.611364906545256

Epoch: 89| Step: 0
Training loss: 2.7998074124725143
Validation loss: 2.621829736346676

Epoch: 5| Step: 1
Training loss: 3.28420974214058
Validation loss: 2.627277453757637

Epoch: 5| Step: 2
Training loss: 2.9838093326392223
Validation loss: 2.608781122755024

Epoch: 5| Step: 3
Training loss: 2.8437818588316714
Validation loss: 2.6156461038192766

Epoch: 5| Step: 4
Training loss: 3.048596174763031
Validation loss: 2.6119879547813096

Epoch: 5| Step: 5
Training loss: 2.9921299702265656
Validation loss: 2.6087470534202004

Epoch: 5| Step: 6
Training loss: 3.362702039583502
Validation loss: 2.6083383812990326

Epoch: 5| Step: 7
Training loss: 3.1688398299566867
Validation loss: 2.616232068596285

Epoch: 5| Step: 8
Training loss: 2.870769207316186
Validation loss: 2.6198684941090216

Epoch: 5| Step: 9
Training loss: 2.707849156065004
Validation loss: 2.616233206747593

Epoch: 5| Step: 10
Training loss: 2.1023099910048493
Validation loss: 2.6083129623588936

Epoch: 90| Step: 0
Training loss: 3.0843231227728696
Validation loss: 2.609057288170041

Epoch: 5| Step: 1
Training loss: 2.5011471024012844
Validation loss: 2.604487137959336

Epoch: 5| Step: 2
Training loss: 2.662086178852765
Validation loss: 2.6043300933420626

Epoch: 5| Step: 3
Training loss: 3.1503134314202015
Validation loss: 2.602411341248325

Epoch: 5| Step: 4
Training loss: 3.4974991174114605
Validation loss: 2.609480920235553

Epoch: 5| Step: 5
Training loss: 2.6652719207941393
Validation loss: 2.6272710126364096

Epoch: 5| Step: 6
Training loss: 2.6372563471047403
Validation loss: 2.656548383772328

Epoch: 5| Step: 7
Training loss: 3.16311518298459
Validation loss: 2.6583044881146467

Epoch: 5| Step: 8
Training loss: 2.6572797686525935
Validation loss: 2.6373877475344063

Epoch: 5| Step: 9
Training loss: 2.931760171769333
Validation loss: 2.6047590127602156

Epoch: 5| Step: 10
Training loss: 3.473352900893531
Validation loss: 2.5997631764997444

Epoch: 91| Step: 0
Training loss: 2.7269891880493917
Validation loss: 2.596169017918852

Epoch: 5| Step: 1
Training loss: 2.5726961254987915
Validation loss: 2.602367025072107

Epoch: 5| Step: 2
Training loss: 3.4740638240294572
Validation loss: 2.604175910851263

Epoch: 5| Step: 3
Training loss: 2.8052657442466136
Validation loss: 2.6076739890598675

Epoch: 5| Step: 4
Training loss: 3.141093356761482
Validation loss: 2.6042652339534644

Epoch: 5| Step: 5
Training loss: 2.6425730725653844
Validation loss: 2.6057367749203215

Epoch: 5| Step: 6
Training loss: 2.9169191160394905
Validation loss: 2.602245144307331

Epoch: 5| Step: 7
Training loss: 3.1287968267578328
Validation loss: 2.6044070684568315

Epoch: 5| Step: 8
Training loss: 2.7596248042739018
Validation loss: 2.5981416988692887

Epoch: 5| Step: 9
Training loss: 3.145228414079556
Validation loss: 2.596534944793088

Epoch: 5| Step: 10
Training loss: 3.2202981725500814
Validation loss: 2.5955716331469865

Epoch: 92| Step: 0
Training loss: 2.5120587393216436
Validation loss: 2.596934649979361

Epoch: 5| Step: 1
Training loss: 2.992936242349483
Validation loss: 2.615371822165945

Epoch: 5| Step: 2
Training loss: 3.423034889437892
Validation loss: 2.6174254969019075

Epoch: 5| Step: 3
Training loss: 2.712179465626467
Validation loss: 2.602762660076192

Epoch: 5| Step: 4
Training loss: 3.153085009318456
Validation loss: 2.5950893300246003

Epoch: 5| Step: 5
Training loss: 3.163442291886204
Validation loss: 2.5965029056895736

Epoch: 5| Step: 6
Training loss: 3.035689416350748
Validation loss: 2.5927399636726816

Epoch: 5| Step: 7
Training loss: 3.1350327232393047
Validation loss: 2.5927847296529114

Epoch: 5| Step: 8
Training loss: 2.7711640832201097
Validation loss: 2.598283569669343

Epoch: 5| Step: 9
Training loss: 2.7211379164540284
Validation loss: 2.5951133067847456

Epoch: 5| Step: 10
Training loss: 2.738319124621048
Validation loss: 2.59653586103652

Epoch: 93| Step: 0
Training loss: 2.970020544321437
Validation loss: 2.5976578112836637

Epoch: 5| Step: 1
Training loss: 3.303364085167544
Validation loss: 2.596057649580855

Epoch: 5| Step: 2
Training loss: 2.752570424855034
Validation loss: 2.599202687701692

Epoch: 5| Step: 3
Training loss: 3.439236566418489
Validation loss: 2.6033840215878863

Epoch: 5| Step: 4
Training loss: 2.640655065963497
Validation loss: 2.604940029039176

Epoch: 5| Step: 5
Training loss: 2.0117239646473677
Validation loss: 2.606121103266642

Epoch: 5| Step: 6
Training loss: 3.0209318123035156
Validation loss: 2.611620349538371

Epoch: 5| Step: 7
Training loss: 3.15199688181263
Validation loss: 2.616301618383861

Epoch: 5| Step: 8
Training loss: 3.0355700354403745
Validation loss: 2.5985510965716996

Epoch: 5| Step: 9
Training loss: 2.672375191610244
Validation loss: 2.6053547081591892

Epoch: 5| Step: 10
Training loss: 3.2431728841908023
Validation loss: 2.6110674516551717

Epoch: 94| Step: 0
Training loss: 2.803038385896643
Validation loss: 2.6018999353838

Epoch: 5| Step: 1
Training loss: 3.5017782870814367
Validation loss: 2.5985912317158792

Epoch: 5| Step: 2
Training loss: 2.89914367792398
Validation loss: 2.5985348458154043

Epoch: 5| Step: 3
Training loss: 2.9638300231916253
Validation loss: 2.5991116292204075

Epoch: 5| Step: 4
Training loss: 2.8073123985379005
Validation loss: 2.6035818540152387

Epoch: 5| Step: 5
Training loss: 3.1131695927181515
Validation loss: 2.6076339229267753

Epoch: 5| Step: 6
Training loss: 3.0268929225809273
Validation loss: 2.5921847466973267

Epoch: 5| Step: 7
Training loss: 3.22189029723272
Validation loss: 2.5846916191173417

Epoch: 5| Step: 8
Training loss: 2.6896039135118706
Validation loss: 2.5843322647207283

Epoch: 5| Step: 9
Training loss: 2.759876635047286
Validation loss: 2.587587812480357

Epoch: 5| Step: 10
Training loss: 2.3112624697557744
Validation loss: 2.587822145843441

Epoch: 95| Step: 0
Training loss: 2.955396959006139
Validation loss: 2.5886295191699884

Epoch: 5| Step: 1
Training loss: 3.2274319491019456
Validation loss: 2.588617697374742

Epoch: 5| Step: 2
Training loss: 2.779759554173007
Validation loss: 2.589936843792867

Epoch: 5| Step: 3
Training loss: 3.435690802529875
Validation loss: 2.5908898572444503

Epoch: 5| Step: 4
Training loss: 3.3867770391285807
Validation loss: 2.5838071988567357

Epoch: 5| Step: 5
Training loss: 2.8247442956838653
Validation loss: 2.5765084158770213

Epoch: 5| Step: 6
Training loss: 2.846064704958334
Validation loss: 2.5819446795627794

Epoch: 5| Step: 7
Training loss: 2.394460555708579
Validation loss: 2.5902412800021635

Epoch: 5| Step: 8
Training loss: 2.664811820423544
Validation loss: 2.607943711097777

Epoch: 5| Step: 9
Training loss: 3.1832865373723607
Validation loss: 2.6025803043999685

Epoch: 5| Step: 10
Training loss: 2.5677768989575056
Validation loss: 2.5792151131783827

Epoch: 96| Step: 0
Training loss: 2.550789007902397
Validation loss: 2.5835616695253596

Epoch: 5| Step: 1
Training loss: 2.9281418448730054
Validation loss: 2.588765218856605

Epoch: 5| Step: 2
Training loss: 3.3778324251048697
Validation loss: 2.5859697156073644

Epoch: 5| Step: 3
Training loss: 2.6912080777628775
Validation loss: 2.592302001476606

Epoch: 5| Step: 4
Training loss: 3.237969359320655
Validation loss: 2.5954531175586446

Epoch: 5| Step: 5
Training loss: 3.1091262487849844
Validation loss: 2.585733587388498

Epoch: 5| Step: 6
Training loss: 2.4037763092457993
Validation loss: 2.595297318155393

Epoch: 5| Step: 7
Training loss: 2.607367468562762
Validation loss: 2.5888716604813884

Epoch: 5| Step: 8
Training loss: 3.209007258458427
Validation loss: 2.588596322536606

Epoch: 5| Step: 9
Training loss: 3.077537209404389
Validation loss: 2.5800603891569027

Epoch: 5| Step: 10
Training loss: 3.0648273266292216
Validation loss: 2.5892795565701827

Epoch: 97| Step: 0
Training loss: 2.978976334758596
Validation loss: 2.6015299000179186

Epoch: 5| Step: 1
Training loss: 2.9955678625008075
Validation loss: 2.593209315695243

Epoch: 5| Step: 2
Training loss: 3.3313534260738624
Validation loss: 2.5808185297723396

Epoch: 5| Step: 3
Training loss: 2.8715539265038754
Validation loss: 2.5734009569475687

Epoch: 5| Step: 4
Training loss: 2.8247337452145396
Validation loss: 2.5780766785568883

Epoch: 5| Step: 5
Training loss: 3.049278524146698
Validation loss: 2.586211577602059

Epoch: 5| Step: 6
Training loss: 2.7871052689177884
Validation loss: 2.5866130574348816

Epoch: 5| Step: 7
Training loss: 2.6932616461602343
Validation loss: 2.5832379416466056

Epoch: 5| Step: 8
Training loss: 3.414536641802288
Validation loss: 2.5776775758667956

Epoch: 5| Step: 9
Training loss: 2.7673980718931404
Validation loss: 2.572847744455044

Epoch: 5| Step: 10
Training loss: 2.696961006570075
Validation loss: 2.5716769000792654

Epoch: 98| Step: 0
Training loss: 2.550221684113473
Validation loss: 2.5738398763152577

Epoch: 5| Step: 1
Training loss: 2.984251329346123
Validation loss: 2.588105549972492

Epoch: 5| Step: 2
Training loss: 2.9088898841261064
Validation loss: 2.590641820654005

Epoch: 5| Step: 3
Training loss: 2.895211040862198
Validation loss: 2.594458909012816

Epoch: 5| Step: 4
Training loss: 3.132597271382463
Validation loss: 2.6043650010579373

Epoch: 5| Step: 5
Training loss: 3.5735958035945057
Validation loss: 2.610934186567705

Epoch: 5| Step: 6
Training loss: 2.8796707028640607
Validation loss: 2.6251509467271346

Epoch: 5| Step: 7
Training loss: 2.371217425921472
Validation loss: 2.586861283102425

Epoch: 5| Step: 8
Training loss: 3.3774679132457917
Validation loss: 2.5753237513910436

Epoch: 5| Step: 9
Training loss: 2.5891990722291562
Validation loss: 2.572415745546293

Epoch: 5| Step: 10
Training loss: 2.858215430435107
Validation loss: 2.577674327650002

Epoch: 99| Step: 0
Training loss: 2.682482449064406
Validation loss: 2.5925754794210163

Epoch: 5| Step: 1
Training loss: 2.775716527586366
Validation loss: 2.591618999420974

Epoch: 5| Step: 2
Training loss: 2.961949962948026
Validation loss: 2.5756836758642585

Epoch: 5| Step: 3
Training loss: 2.969605653829783
Validation loss: 2.575854896813474

Epoch: 5| Step: 4
Training loss: 2.9105517637063025
Validation loss: 2.592636245853062

Epoch: 5| Step: 5
Training loss: 3.61927105935693
Validation loss: 2.5975940959365027

Epoch: 5| Step: 6
Training loss: 2.649896450538753
Validation loss: 2.6093131899229114

Epoch: 5| Step: 7
Training loss: 2.99206160238159
Validation loss: 2.5704005333819775

Epoch: 5| Step: 8
Training loss: 2.6612389779568146
Validation loss: 2.566013996648009

Epoch: 5| Step: 9
Training loss: 2.810991518478056
Validation loss: 2.573606940449679

Epoch: 5| Step: 10
Training loss: 3.261564513802809
Validation loss: 2.581730545507669

Epoch: 100| Step: 0
Training loss: 2.738924263894869
Validation loss: 2.618585705339708

Epoch: 5| Step: 1
Training loss: 3.2855208440667174
Validation loss: 2.6501552896164466

Epoch: 5| Step: 2
Training loss: 3.1690602709310305
Validation loss: 2.687716180377603

Epoch: 5| Step: 3
Training loss: 2.620929104541501
Validation loss: 2.603989286883113

Epoch: 5| Step: 4
Training loss: 3.012207941483997
Validation loss: 2.579102610181379

Epoch: 5| Step: 5
Training loss: 2.7450472708490024
Validation loss: 2.5658985993830243

Epoch: 5| Step: 6
Training loss: 2.5475898160815054
Validation loss: 2.5690333189268104

Epoch: 5| Step: 7
Training loss: 2.9620201527014913
Validation loss: 2.561705750581763

Epoch: 5| Step: 8
Training loss: 3.281230962788897
Validation loss: 2.564817395672603

Epoch: 5| Step: 9
Training loss: 2.9271124751223008
Validation loss: 2.5650706709032387

Epoch: 5| Step: 10
Training loss: 2.9299936363489616
Validation loss: 2.5601482329310237

Epoch: 101| Step: 0
Training loss: 2.9884543773888974
Validation loss: 2.562126603672781

Epoch: 5| Step: 1
Training loss: 3.0619531259966704
Validation loss: 2.563069352097747

Epoch: 5| Step: 2
Training loss: 2.828058652995283
Validation loss: 2.557536121748801

Epoch: 5| Step: 3
Training loss: 2.9010613176558038
Validation loss: 2.557948233941885

Epoch: 5| Step: 4
Training loss: 2.924312452057875
Validation loss: 2.5653180070043216

Epoch: 5| Step: 5
Training loss: 2.709152205479573
Validation loss: 2.5738085089160685

Epoch: 5| Step: 6
Training loss: 2.3023427641587855
Validation loss: 2.583149119096464

Epoch: 5| Step: 7
Training loss: 2.862388148891934
Validation loss: 2.580148814778376

Epoch: 5| Step: 8
Training loss: 2.7071948862090633
Validation loss: 2.587971826611711

Epoch: 5| Step: 9
Training loss: 3.467496078257966
Validation loss: 2.5917488420912327

Epoch: 5| Step: 10
Training loss: 3.380961486578998
Validation loss: 2.582278969979659

Epoch: 102| Step: 0
Training loss: 2.7332557349316255
Validation loss: 2.5727016280563264

Epoch: 5| Step: 1
Training loss: 3.2569128024568936
Validation loss: 2.5721339645711967

Epoch: 5| Step: 2
Training loss: 2.4465699299217
Validation loss: 2.558292820916917

Epoch: 5| Step: 3
Training loss: 2.807144406525196
Validation loss: 2.5553841442738885

Epoch: 5| Step: 4
Training loss: 2.7888470734817243
Validation loss: 2.5547149622607908

Epoch: 5| Step: 5
Training loss: 2.9722365936533963
Validation loss: 2.5517148007739836

Epoch: 5| Step: 6
Training loss: 3.188542962076613
Validation loss: 2.5516963086836837

Epoch: 5| Step: 7
Training loss: 3.1661073458432885
Validation loss: 2.5507419053427665

Epoch: 5| Step: 8
Training loss: 2.89488426043022
Validation loss: 2.5541273606025827

Epoch: 5| Step: 9
Training loss: 2.8127276010608946
Validation loss: 2.5526033331716698

Epoch: 5| Step: 10
Training loss: 2.963222779256051
Validation loss: 2.552535213991555

Epoch: 103| Step: 0
Training loss: 2.981979287314166
Validation loss: 2.5545609208160243

Epoch: 5| Step: 1
Training loss: 2.7420784692199938
Validation loss: 2.555263942332133

Epoch: 5| Step: 2
Training loss: 3.1008713574339075
Validation loss: 2.5554293454508463

Epoch: 5| Step: 3
Training loss: 2.407424342946315
Validation loss: 2.5547676125294134

Epoch: 5| Step: 4
Training loss: 2.9923535492641817
Validation loss: 2.556674421057235

Epoch: 5| Step: 5
Training loss: 2.7404758947822936
Validation loss: 2.55947671017769

Epoch: 5| Step: 6
Training loss: 3.5751630359100273
Validation loss: 2.5685805812953415

Epoch: 5| Step: 7
Training loss: 2.5010665525834495
Validation loss: 2.566338273430814

Epoch: 5| Step: 8
Training loss: 3.168108277358568
Validation loss: 2.5539236907247527

Epoch: 5| Step: 9
Training loss: 2.844732932107527
Validation loss: 2.554033307862108

Epoch: 5| Step: 10
Training loss: 2.866757893404494
Validation loss: 2.5554829586121337

Epoch: 104| Step: 0
Training loss: 3.2112861685314145
Validation loss: 2.551159070330041

Epoch: 5| Step: 1
Training loss: 2.785029725441766
Validation loss: 2.5507751313009117

Epoch: 5| Step: 2
Training loss: 2.875720058330059
Validation loss: 2.55083540507332

Epoch: 5| Step: 3
Training loss: 2.7474084260239153
Validation loss: 2.547304120436916

Epoch: 5| Step: 4
Training loss: 3.0262936056620315
Validation loss: 2.547691205872725

Epoch: 5| Step: 5
Training loss: 2.622656548175903
Validation loss: 2.5511796353723213

Epoch: 5| Step: 6
Training loss: 2.1615347852552946
Validation loss: 2.5476553958341044

Epoch: 5| Step: 7
Training loss: 3.0065430179159423
Validation loss: 2.548584151732913

Epoch: 5| Step: 8
Training loss: 3.075208802616092
Validation loss: 2.548999537678159

Epoch: 5| Step: 9
Training loss: 3.20658308236149
Validation loss: 2.5572836511366566

Epoch: 5| Step: 10
Training loss: 3.240477770676876
Validation loss: 2.568055156905755

Epoch: 105| Step: 0
Training loss: 3.368138013182103
Validation loss: 2.5800459411535965

Epoch: 5| Step: 1
Training loss: 2.585178690329045
Validation loss: 2.5669136384270494

Epoch: 5| Step: 2
Training loss: 3.293533729242678
Validation loss: 2.5686873164027726

Epoch: 5| Step: 3
Training loss: 2.4929356901869157
Validation loss: 2.5681181257018246

Epoch: 5| Step: 4
Training loss: 2.8647613655022672
Validation loss: 2.568921107510619

Epoch: 5| Step: 5
Training loss: 2.8323821172737187
Validation loss: 2.5745035719434775

Epoch: 5| Step: 6
Training loss: 3.114456242208477
Validation loss: 2.5786466178347958

Epoch: 5| Step: 7
Training loss: 3.2430208536960294
Validation loss: 2.5893100712122243

Epoch: 5| Step: 8
Training loss: 2.5536338196410333
Validation loss: 2.5673945173875143

Epoch: 5| Step: 9
Training loss: 2.9459621208847864
Validation loss: 2.5533728617463622

Epoch: 5| Step: 10
Training loss: 2.5503004009351065
Validation loss: 2.5555357661052467

Epoch: 106| Step: 0
Training loss: 3.065932705025602
Validation loss: 2.5508703704849975

Epoch: 5| Step: 1
Training loss: 2.827963808640152
Validation loss: 2.545578827651918

Epoch: 5| Step: 2
Training loss: 2.865573688742412
Validation loss: 2.548621618504731

Epoch: 5| Step: 3
Training loss: 3.559205522931736
Validation loss: 2.5493643964439197

Epoch: 5| Step: 4
Training loss: 2.6279002017518533
Validation loss: 2.548365394620076

Epoch: 5| Step: 5
Training loss: 2.748579351896961
Validation loss: 2.549465265170891

Epoch: 5| Step: 6
Training loss: 3.171870941009179
Validation loss: 2.5531230952262214

Epoch: 5| Step: 7
Training loss: 2.2680076961084
Validation loss: 2.5706579227676434

Epoch: 5| Step: 8
Training loss: 3.190377526021791
Validation loss: 2.6093365771607644

Epoch: 5| Step: 9
Training loss: 3.0443430234748643
Validation loss: 2.6231743714054145

Epoch: 5| Step: 10
Training loss: 2.5051279881230504
Validation loss: 2.595797332056831

Epoch: 107| Step: 0
Training loss: 2.1081010150195287
Validation loss: 2.5728798399856196

Epoch: 5| Step: 1
Training loss: 3.1229019751700493
Validation loss: 2.555260891361273

Epoch: 5| Step: 2
Training loss: 2.978686918742501
Validation loss: 2.5446821947388245

Epoch: 5| Step: 3
Training loss: 3.2255476493999904
Validation loss: 2.5404880194076767

Epoch: 5| Step: 4
Training loss: 2.887785800810002
Validation loss: 2.539672679295701

Epoch: 5| Step: 5
Training loss: 2.614965970636691
Validation loss: 2.5399349175983255

Epoch: 5| Step: 6
Training loss: 2.8730266266919045
Validation loss: 2.538559842644967

Epoch: 5| Step: 7
Training loss: 2.989671570719607
Validation loss: 2.536078312132619

Epoch: 5| Step: 8
Training loss: 2.7960840737195922
Validation loss: 2.5385664947153486

Epoch: 5| Step: 9
Training loss: 3.2741452273699876
Validation loss: 2.54055893083853

Epoch: 5| Step: 10
Training loss: 2.880067754054466
Validation loss: 2.5363571690246607

Epoch: 108| Step: 0
Training loss: 3.093467314164433
Validation loss: 2.5347949016237354

Epoch: 5| Step: 1
Training loss: 2.8866786102271025
Validation loss: 2.5358107212323637

Epoch: 5| Step: 2
Training loss: 3.1967312151213085
Validation loss: 2.54034779417798

Epoch: 5| Step: 3
Training loss: 2.8506210654310404
Validation loss: 2.5385200560935903

Epoch: 5| Step: 4
Training loss: 2.991157214921175
Validation loss: 2.5401968422076147

Epoch: 5| Step: 5
Training loss: 2.756758015497908
Validation loss: 2.5402402104313513

Epoch: 5| Step: 6
Training loss: 3.067660751794133
Validation loss: 2.5415499963178934

Epoch: 5| Step: 7
Training loss: 1.9996952778420098
Validation loss: 2.5370964289883124

Epoch: 5| Step: 8
Training loss: 3.1222723691751257
Validation loss: 2.539148719150398

Epoch: 5| Step: 9
Training loss: 2.788440367823204
Validation loss: 2.545686309649703

Epoch: 5| Step: 10
Training loss: 3.002177084297893
Validation loss: 2.546426179526799

Epoch: 109| Step: 0
Training loss: 2.7233065426495853
Validation loss: 2.547693435744677

Epoch: 5| Step: 1
Training loss: 2.5495653978882618
Validation loss: 2.5408311160049557

Epoch: 5| Step: 2
Training loss: 2.7194414684507535
Validation loss: 2.535265225501031

Epoch: 5| Step: 3
Training loss: 3.0869109730884574
Validation loss: 2.5373202577640215

Epoch: 5| Step: 4
Training loss: 2.926049661993228
Validation loss: 2.5353250696821137

Epoch: 5| Step: 5
Training loss: 2.9395992813020193
Validation loss: 2.53375414390267

Epoch: 5| Step: 6
Training loss: 2.8252149753301667
Validation loss: 2.5326138661450535

Epoch: 5| Step: 7
Training loss: 3.117367846786018
Validation loss: 2.535250496431428

Epoch: 5| Step: 8
Training loss: 2.713065859227591
Validation loss: 2.533503321588272

Epoch: 5| Step: 9
Training loss: 3.2699177102283534
Validation loss: 2.542900772966775

Epoch: 5| Step: 10
Training loss: 2.9556302540007025
Validation loss: 2.5487446795005204

Epoch: 110| Step: 0
Training loss: 2.8559997315393315
Validation loss: 2.5569226776278082

Epoch: 5| Step: 1
Training loss: 3.12199302961902
Validation loss: 2.5776849305862655

Epoch: 5| Step: 2
Training loss: 2.5096601768339144
Validation loss: 2.580596686652686

Epoch: 5| Step: 3
Training loss: 2.2776056731212027
Validation loss: 2.5751573373777785

Epoch: 5| Step: 4
Training loss: 3.280658196259341
Validation loss: 2.5568835668406065

Epoch: 5| Step: 5
Training loss: 2.7002137664660992
Validation loss: 2.5497416947547418

Epoch: 5| Step: 6
Training loss: 3.2120926535652563
Validation loss: 2.539244647816706

Epoch: 5| Step: 7
Training loss: 2.9855132004614204
Validation loss: 2.5363464256662893

Epoch: 5| Step: 8
Training loss: 2.8197473186889748
Validation loss: 2.535532775895619

Epoch: 5| Step: 9
Training loss: 3.1935618485123216
Validation loss: 2.534462351243442

Epoch: 5| Step: 10
Training loss: 2.9436103091130295
Validation loss: 2.534725977168662

Epoch: 111| Step: 0
Training loss: 2.8781439135465345
Validation loss: 2.5315674583107945

Epoch: 5| Step: 1
Training loss: 2.8030553972837744
Validation loss: 2.537226882397595

Epoch: 5| Step: 2
Training loss: 2.8274425715947804
Validation loss: 2.5512632233026085

Epoch: 5| Step: 3
Training loss: 3.2579347143873907
Validation loss: 2.559958939070794

Epoch: 5| Step: 4
Training loss: 3.0204675562605954
Validation loss: 2.5608333547124777

Epoch: 5| Step: 5
Training loss: 3.2871528935399112
Validation loss: 2.554712100796606

Epoch: 5| Step: 6
Training loss: 3.1104650072521847
Validation loss: 2.5451376554685017

Epoch: 5| Step: 7
Training loss: 2.702628470445295
Validation loss: 2.536299518836097

Epoch: 5| Step: 8
Training loss: 2.1273017086227513
Validation loss: 2.531075635034542

Epoch: 5| Step: 9
Training loss: 3.164769223253126
Validation loss: 2.53121335676462

Epoch: 5| Step: 10
Training loss: 2.463292136804954
Validation loss: 2.5291789768690647

Epoch: 112| Step: 0
Training loss: 3.2645067554508564
Validation loss: 2.531418849793148

Epoch: 5| Step: 1
Training loss: 2.5197944917593347
Validation loss: 2.5310998991378506

Epoch: 5| Step: 2
Training loss: 3.3574014233670293
Validation loss: 2.5291901490260904

Epoch: 5| Step: 3
Training loss: 3.111625278839907
Validation loss: 2.530703756220204

Epoch: 5| Step: 4
Training loss: 3.008066934500308
Validation loss: 2.5284257246388697

Epoch: 5| Step: 5
Training loss: 3.0095875444153473
Validation loss: 2.532497045649293

Epoch: 5| Step: 6
Training loss: 2.5167314453714242
Validation loss: 2.533988522535441

Epoch: 5| Step: 7
Training loss: 2.6839500757056967
Validation loss: 2.550262203887285

Epoch: 5| Step: 8
Training loss: 2.615789512647204
Validation loss: 2.567336472723914

Epoch: 5| Step: 9
Training loss: 3.0049059807767873
Validation loss: 2.602801763053298

Epoch: 5| Step: 10
Training loss: 2.480528823245245
Validation loss: 2.5606130550107644

Epoch: 113| Step: 0
Training loss: 2.3483278453249277
Validation loss: 2.5519186941602987

Epoch: 5| Step: 1
Training loss: 2.9822655057853367
Validation loss: 2.545659268123139

Epoch: 5| Step: 2
Training loss: 2.8091571014733328
Validation loss: 2.536820646675483

Epoch: 5| Step: 3
Training loss: 2.5428162981736064
Validation loss: 2.529128874885142

Epoch: 5| Step: 4
Training loss: 3.1011819678105224
Validation loss: 2.526177748192623

Epoch: 5| Step: 5
Training loss: 3.0840360167264294
Validation loss: 2.526501135506089

Epoch: 5| Step: 6
Training loss: 3.2758420429552255
Validation loss: 2.524820140791455

Epoch: 5| Step: 7
Training loss: 2.595964704182499
Validation loss: 2.528305870485799

Epoch: 5| Step: 8
Training loss: 3.1553772578961836
Validation loss: 2.526441226402007

Epoch: 5| Step: 9
Training loss: 2.7154593888015017
Validation loss: 2.524570438965757

Epoch: 5| Step: 10
Training loss: 3.0784101789789977
Validation loss: 2.533009955262879

Epoch: 114| Step: 0
Training loss: 2.700695467495029
Validation loss: 2.5336036146384986

Epoch: 5| Step: 1
Training loss: 2.6234549562147236
Validation loss: 2.554442426402714

Epoch: 5| Step: 2
Training loss: 2.5588939694451573
Validation loss: 2.5636288497232447

Epoch: 5| Step: 3
Training loss: 3.4218366786256746
Validation loss: 2.6036823070015083

Epoch: 5| Step: 4
Training loss: 2.9580107141369063
Validation loss: 2.653742893216762

Epoch: 5| Step: 5
Training loss: 3.3742123850404484
Validation loss: 2.666169691947327

Epoch: 5| Step: 6
Training loss: 3.7987390032122983
Validation loss: 2.6864881602014905

Epoch: 5| Step: 7
Training loss: 2.7512758936480273
Validation loss: 2.600851736225368

Epoch: 5| Step: 8
Training loss: 2.8889859888272453
Validation loss: 2.5566255878971504

Epoch: 5| Step: 9
Training loss: 2.581903174566803
Validation loss: 2.5656680340886333

Epoch: 5| Step: 10
Training loss: 2.1558136429371
Validation loss: 2.5876036871446684

Epoch: 115| Step: 0
Training loss: 2.785711417703235
Validation loss: 2.6139978451802515

Epoch: 5| Step: 1
Training loss: 2.3076762846855066
Validation loss: 2.6179216300820145

Epoch: 5| Step: 2
Training loss: 3.1711208405316103
Validation loss: 2.616243193844851

Epoch: 5| Step: 3
Training loss: 3.325967581943657
Validation loss: 2.5845003436142946

Epoch: 5| Step: 4
Training loss: 2.9435207269559918
Validation loss: 2.563183147930481

Epoch: 5| Step: 5
Training loss: 2.865727273661406
Validation loss: 2.5517070888873543

Epoch: 5| Step: 6
Training loss: 2.244898947669539
Validation loss: 2.549014780686533

Epoch: 5| Step: 7
Training loss: 3.0918934193115124
Validation loss: 2.5915368694333187

Epoch: 5| Step: 8
Training loss: 3.5126422350990656
Validation loss: 2.7316580657752505

Epoch: 5| Step: 9
Training loss: 3.384305487964149
Validation loss: 2.808094101215433

Epoch: 5| Step: 10
Training loss: 2.766399124338862
Validation loss: 2.769383044377565

Epoch: 116| Step: 0
Training loss: 3.224214378300359
Validation loss: 2.7234317627668347

Epoch: 5| Step: 1
Training loss: 2.6446522356810678
Validation loss: 2.5929826198510297

Epoch: 5| Step: 2
Training loss: 2.54608048291889
Validation loss: 2.550461695176485

Epoch: 5| Step: 3
Training loss: 2.9991197884229397
Validation loss: 2.543206141210049

Epoch: 5| Step: 4
Training loss: 3.264928862189602
Validation loss: 2.5702206703416484

Epoch: 5| Step: 5
Training loss: 2.701261374093487
Validation loss: 2.5793864267006694

Epoch: 5| Step: 6
Training loss: 3.4964606236450306
Validation loss: 2.5733819761412424

Epoch: 5| Step: 7
Training loss: 3.427078819078682
Validation loss: 2.5613484129803252

Epoch: 5| Step: 8
Training loss: 3.00596661094452
Validation loss: 2.5429187573978087

Epoch: 5| Step: 9
Training loss: 2.4913774567044036
Validation loss: 2.5422294702330253

Epoch: 5| Step: 10
Training loss: 2.630616582529382
Validation loss: 2.5495942833161127

Epoch: 117| Step: 0
Training loss: 3.0104650121764536
Validation loss: 2.544050755402988

Epoch: 5| Step: 1
Training loss: 3.0399865165210658
Validation loss: 2.5429006963469187

Epoch: 5| Step: 2
Training loss: 3.377440665039405
Validation loss: 2.547059218126508

Epoch: 5| Step: 3
Training loss: 3.277514265714627
Validation loss: 2.5604244463317034

Epoch: 5| Step: 4
Training loss: 3.0915019797772727
Validation loss: 2.5739700172566065

Epoch: 5| Step: 5
Training loss: 2.735995177788974
Validation loss: 2.5941549598561435

Epoch: 5| Step: 6
Training loss: 2.429155592023448
Validation loss: 2.6267681388042057

Epoch: 5| Step: 7
Training loss: 2.9093475242161424
Validation loss: 2.6793049118523564

Epoch: 5| Step: 8
Training loss: 2.925074330225013
Validation loss: 2.6664288857669867

Epoch: 5| Step: 9
Training loss: 2.7038052976246973
Validation loss: 2.671357346552436

Epoch: 5| Step: 10
Training loss: 2.4420001230825634
Validation loss: 2.6378397170858805

Epoch: 118| Step: 0
Training loss: 2.6305780635606175
Validation loss: 2.5874331039572196

Epoch: 5| Step: 1
Training loss: 2.8979073833990605
Validation loss: 2.5570462414459856

Epoch: 5| Step: 2
Training loss: 3.32965683048038
Validation loss: 2.548048353955561

Epoch: 5| Step: 3
Training loss: 3.2791383760646458
Validation loss: 2.5431454663595563

Epoch: 5| Step: 4
Training loss: 2.6741706846053845
Validation loss: 2.5437834967338

Epoch: 5| Step: 5
Training loss: 2.413281459444036
Validation loss: 2.5445135540734323

Epoch: 5| Step: 6
Training loss: 3.09151030879405
Validation loss: 2.540786366463607

Epoch: 5| Step: 7
Training loss: 2.8571645395273646
Validation loss: 2.54152087219274

Epoch: 5| Step: 8
Training loss: 2.5701348611499535
Validation loss: 2.538094321054638

Epoch: 5| Step: 9
Training loss: 2.8072660276319095
Validation loss: 2.536015840726191

Epoch: 5| Step: 10
Training loss: 3.320288229460927
Validation loss: 2.536977440204477

Epoch: 119| Step: 0
Training loss: 3.082930169080902
Validation loss: 2.5376651100987138

Epoch: 5| Step: 1
Training loss: 2.8994247523695664
Validation loss: 2.53370018023535

Epoch: 5| Step: 2
Training loss: 2.8489786225223517
Validation loss: 2.5377681642004526

Epoch: 5| Step: 3
Training loss: 2.2784863806747158
Validation loss: 2.531821899950789

Epoch: 5| Step: 4
Training loss: 3.1591668578275036
Validation loss: 2.5379339681457496

Epoch: 5| Step: 5
Training loss: 3.1382134891532503
Validation loss: 2.5341119006076807

Epoch: 5| Step: 6
Training loss: 3.325753813458593
Validation loss: 2.5321663094696216

Epoch: 5| Step: 7
Training loss: 2.6213198704973713
Validation loss: 2.538039316350499

Epoch: 5| Step: 8
Training loss: 2.8473593474658365
Validation loss: 2.538577819453945

Epoch: 5| Step: 9
Training loss: 3.0201055417344826
Validation loss: 2.5370676205407316

Epoch: 5| Step: 10
Training loss: 2.5121766143232716
Validation loss: 2.547978815070996

Epoch: 120| Step: 0
Training loss: 3.0498309541976467
Validation loss: 2.5791829960930164

Epoch: 5| Step: 1
Training loss: 3.2768631447463554
Validation loss: 2.6184689696131795

Epoch: 5| Step: 2
Training loss: 2.3136632931711305
Validation loss: 2.627854719397557

Epoch: 5| Step: 3
Training loss: 2.982883899727398
Validation loss: 2.6121144574647928

Epoch: 5| Step: 4
Training loss: 2.344576677125718
Validation loss: 2.6025263887687182

Epoch: 5| Step: 5
Training loss: 2.5851181899007276
Validation loss: 2.5588613768917776

Epoch: 5| Step: 6
Training loss: 2.9928240783665006
Validation loss: 2.544865364760198

Epoch: 5| Step: 7
Training loss: 3.7186720383109377
Validation loss: 2.5393698158790827

Epoch: 5| Step: 8
Training loss: 2.89737700523025
Validation loss: 2.5312085398311

Epoch: 5| Step: 9
Training loss: 2.517537402999306
Validation loss: 2.529535926300582

Epoch: 5| Step: 10
Training loss: 3.0837235246812194
Validation loss: 2.5274287652650527

Epoch: 121| Step: 0
Training loss: 2.776465683570953
Validation loss: 2.52289513930293

Epoch: 5| Step: 1
Training loss: 2.658984583023442
Validation loss: 2.5242803094392112

Epoch: 5| Step: 2
Training loss: 3.18679278138795
Validation loss: 2.52083318010813

Epoch: 5| Step: 3
Training loss: 3.30501848732168
Validation loss: 2.510071053395809

Epoch: 5| Step: 4
Training loss: 3.2238641498142444
Validation loss: 2.5060937692382472

Epoch: 5| Step: 5
Training loss: 2.8963080549945426
Validation loss: 2.5081560851950075

Epoch: 5| Step: 6
Training loss: 2.295043422645553
Validation loss: 2.5128714884602896

Epoch: 5| Step: 7
Training loss: 2.7198621733190462
Validation loss: 2.5190750654097585

Epoch: 5| Step: 8
Training loss: 2.84149180869003
Validation loss: 2.51662641437527

Epoch: 5| Step: 9
Training loss: 2.545605021060473
Validation loss: 2.5371346251912947

Epoch: 5| Step: 10
Training loss: 3.1338654458593886
Validation loss: 2.5557838915384368

Epoch: 122| Step: 0
Training loss: 2.50540130781394
Validation loss: 2.549906446673872

Epoch: 5| Step: 1
Training loss: 2.766279584930705
Validation loss: 2.552995171216099

Epoch: 5| Step: 2
Training loss: 3.2906958359559506
Validation loss: 2.5432544094967944

Epoch: 5| Step: 3
Training loss: 3.0007436148605673
Validation loss: 2.5415576078948034

Epoch: 5| Step: 4
Training loss: 2.8185043667767395
Validation loss: 2.5406694969346413

Epoch: 5| Step: 5
Training loss: 3.012681225909126
Validation loss: 2.5394698055639986

Epoch: 5| Step: 6
Training loss: 2.407629534127353
Validation loss: 2.5429745648816335

Epoch: 5| Step: 7
Training loss: 2.9628037180316267
Validation loss: 2.5489302440015384

Epoch: 5| Step: 8
Training loss: 2.8946251487173456
Validation loss: 2.5426951477112465

Epoch: 5| Step: 9
Training loss: 2.934873177486913
Validation loss: 2.529202632753404

Epoch: 5| Step: 10
Training loss: 2.9945893769428595
Validation loss: 2.516316880187634

Epoch: 123| Step: 0
Training loss: 3.1012159485429374
Validation loss: 2.5143530749896086

Epoch: 5| Step: 1
Training loss: 3.2146829632103815
Validation loss: 2.5135430640677976

Epoch: 5| Step: 2
Training loss: 2.8878667094890136
Validation loss: 2.509651341786409

Epoch: 5| Step: 3
Training loss: 2.664191100297159
Validation loss: 2.509806596694395

Epoch: 5| Step: 4
Training loss: 2.3463990563188823
Validation loss: 2.50487018095798

Epoch: 5| Step: 5
Training loss: 3.2277088114873265
Validation loss: 2.5076644874738383

Epoch: 5| Step: 6
Training loss: 2.477190678107094
Validation loss: 2.5131316911891934

Epoch: 5| Step: 7
Training loss: 3.0682311635271806
Validation loss: 2.5296914130620327

Epoch: 5| Step: 8
Training loss: 3.0674762389763623
Validation loss: 2.527402628951849

Epoch: 5| Step: 9
Training loss: 2.619518551452967
Validation loss: 2.5076838696021966

Epoch: 5| Step: 10
Training loss: 2.9188812749123065
Validation loss: 2.524829806132802

Epoch: 124| Step: 0
Training loss: 2.891334570321148
Validation loss: 2.521614470984924

Epoch: 5| Step: 1
Training loss: 2.6504575514302418
Validation loss: 2.5520316069540327

Epoch: 5| Step: 2
Training loss: 2.964145663657719
Validation loss: 2.5805323364605397

Epoch: 5| Step: 3
Training loss: 2.5517822918482356
Validation loss: 2.5524267759560133

Epoch: 5| Step: 4
Training loss: 2.686436819873196
Validation loss: 2.528696052690714

Epoch: 5| Step: 5
Training loss: 2.8309221292590707
Validation loss: 2.526823268005731

Epoch: 5| Step: 6
Training loss: 3.0552586170371865
Validation loss: 2.519447550520505

Epoch: 5| Step: 7
Training loss: 3.19872864263276
Validation loss: 2.5332775849645537

Epoch: 5| Step: 8
Training loss: 2.5899293635099765
Validation loss: 2.56886485675628

Epoch: 5| Step: 9
Training loss: 3.189184902894254
Validation loss: 2.550302367165888

Epoch: 5| Step: 10
Training loss: 3.155720883576991
Validation loss: 2.5356727052680856

Epoch: 125| Step: 0
Training loss: 2.5005048242136083
Validation loss: 2.516043190376582

Epoch: 5| Step: 1
Training loss: 2.6426396556606826
Validation loss: 2.5091254211532634

Epoch: 5| Step: 2
Training loss: 2.9461612035150364
Validation loss: 2.5128149624217317

Epoch: 5| Step: 3
Training loss: 2.905251936632625
Validation loss: 2.513298290114247

Epoch: 5| Step: 4
Training loss: 2.820176308849215
Validation loss: 2.5210461616082673

Epoch: 5| Step: 5
Training loss: 2.8741536760649553
Validation loss: 2.5151992098153184

Epoch: 5| Step: 6
Training loss: 3.0074226423986716
Validation loss: 2.5193760224932897

Epoch: 5| Step: 7
Training loss: 2.550181296392516
Validation loss: 2.514982918750404

Epoch: 5| Step: 8
Training loss: 3.040849410398146
Validation loss: 2.498324185312052

Epoch: 5| Step: 9
Training loss: 2.998651201306949
Validation loss: 2.4961381884813783

Epoch: 5| Step: 10
Training loss: 3.2753048762161865
Validation loss: 2.5019132522533964

Epoch: 126| Step: 0
Training loss: 2.806835658889851
Validation loss: 2.501924768516306

Epoch: 5| Step: 1
Training loss: 2.381802904714052
Validation loss: 2.4990599269663636

Epoch: 5| Step: 2
Training loss: 3.07029137834656
Validation loss: 2.5037334600664525

Epoch: 5| Step: 3
Training loss: 2.524518327754903
Validation loss: 2.5099542459376165

Epoch: 5| Step: 4
Training loss: 3.6435273352715627
Validation loss: 2.5158006946475178

Epoch: 5| Step: 5
Training loss: 2.9420241559227898
Validation loss: 2.531907155688407

Epoch: 5| Step: 6
Training loss: 2.6397169007607824
Validation loss: 2.5537096916742654

Epoch: 5| Step: 7
Training loss: 3.1204839499815225
Validation loss: 2.5845627654433994

Epoch: 5| Step: 8
Training loss: 2.8675097874255715
Validation loss: 2.6254441959262085

Epoch: 5| Step: 9
Training loss: 2.8315786276234785
Validation loss: 2.616372487644528

Epoch: 5| Step: 10
Training loss: 2.6134827768485547
Validation loss: 2.5846887387673227

Epoch: 127| Step: 0
Training loss: 2.917791440343751
Validation loss: 2.5543761025783556

Epoch: 5| Step: 1
Training loss: 2.78212064338573
Validation loss: 2.52164742804333

Epoch: 5| Step: 2
Training loss: 3.2302966366068664
Validation loss: 2.5031130574234797

Epoch: 5| Step: 3
Training loss: 2.3183047666601957
Validation loss: 2.4891443684648515

Epoch: 5| Step: 4
Training loss: 2.7523714590938173
Validation loss: 2.487379843265293

Epoch: 5| Step: 5
Training loss: 2.8121012087063675
Validation loss: 2.4879685530604583

Epoch: 5| Step: 6
Training loss: 2.7621425967079145
Validation loss: 2.490263640818701

Epoch: 5| Step: 7
Training loss: 2.9452571307171196
Validation loss: 2.4900175019711766

Epoch: 5| Step: 8
Training loss: 2.8491645659306664
Validation loss: 2.488049538256127

Epoch: 5| Step: 9
Training loss: 2.7922978802569403
Validation loss: 2.491258327969366

Epoch: 5| Step: 10
Training loss: 3.4284554530010873
Validation loss: 2.4859326716909353

Epoch: 128| Step: 0
Training loss: 2.9661542285580453
Validation loss: 2.4851235791525954

Epoch: 5| Step: 1
Training loss: 2.6369803291834097
Validation loss: 2.4830766038755265

Epoch: 5| Step: 2
Training loss: 2.9238341591975976
Validation loss: 2.489232001475369

Epoch: 5| Step: 3
Training loss: 2.8486157385072817
Validation loss: 2.4871592590414915

Epoch: 5| Step: 4
Training loss: 2.8591758783767065
Validation loss: 2.4857899083348785

Epoch: 5| Step: 5
Training loss: 2.855628054828642
Validation loss: 2.4886916768301215

Epoch: 5| Step: 6
Training loss: 2.986031277400124
Validation loss: 2.5022039911842158

Epoch: 5| Step: 7
Training loss: 2.9901709073318385
Validation loss: 2.5239347293546994

Epoch: 5| Step: 8
Training loss: 2.798224267551418
Validation loss: 2.5318474671517075

Epoch: 5| Step: 9
Training loss: 2.3425527948152167
Validation loss: 2.5570830618939624

Epoch: 5| Step: 10
Training loss: 3.3011331404513706
Validation loss: 2.5864707159849023

Epoch: 129| Step: 0
Training loss: 3.0173279692528694
Validation loss: 2.5721043834028

Epoch: 5| Step: 1
Training loss: 2.470611449941992
Validation loss: 2.5282717307085174

Epoch: 5| Step: 2
Training loss: 2.6989141753360886
Validation loss: 2.511009565667787

Epoch: 5| Step: 3
Training loss: 3.104627195328395
Validation loss: 2.502410700559879

Epoch: 5| Step: 4
Training loss: 3.147112319013468
Validation loss: 2.5033564114643236

Epoch: 5| Step: 5
Training loss: 2.638715968127153
Validation loss: 2.493404967866153

Epoch: 5| Step: 6
Training loss: 3.175137950873958
Validation loss: 2.4854166720028212

Epoch: 5| Step: 7
Training loss: 2.3916869952393482
Validation loss: 2.487365008944835

Epoch: 5| Step: 8
Training loss: 3.162415930795338
Validation loss: 2.4838191523951894

Epoch: 5| Step: 9
Training loss: 2.810485542269678
Validation loss: 2.491713374451148

Epoch: 5| Step: 10
Training loss: 2.611510539335062
Validation loss: 2.48428173564735

Epoch: 130| Step: 0
Training loss: 3.2008069093926643
Validation loss: 2.4949868216415108

Epoch: 5| Step: 1
Training loss: 3.0058022655393493
Validation loss: 2.4918151884940554

Epoch: 5| Step: 2
Training loss: 2.3276238638168993
Validation loss: 2.516138787483381

Epoch: 5| Step: 3
Training loss: 2.639661263206447
Validation loss: 2.5388608053791613

Epoch: 5| Step: 4
Training loss: 3.05021023260262
Validation loss: 2.5419317060560878

Epoch: 5| Step: 5
Training loss: 3.250909091275665
Validation loss: 2.4907744277716812

Epoch: 5| Step: 6
Training loss: 2.9773060428150493
Validation loss: 2.4885618129227525

Epoch: 5| Step: 7
Training loss: 2.5249882235110777
Validation loss: 2.483745611574301

Epoch: 5| Step: 8
Training loss: 2.600261832771559
Validation loss: 2.4872717649748517

Epoch: 5| Step: 9
Training loss: 3.0955293720954837
Validation loss: 2.484199827837778

Epoch: 5| Step: 10
Training loss: 2.817806578290762
Validation loss: 2.487077859342938

Epoch: 131| Step: 0
Training loss: 3.203669506405805
Validation loss: 2.4993497854081403

Epoch: 5| Step: 1
Training loss: 2.862245380121668
Validation loss: 2.508317483231788

Epoch: 5| Step: 2
Training loss: 2.6607183235115874
Validation loss: 2.5225026593373725

Epoch: 5| Step: 3
Training loss: 2.846846519017883
Validation loss: 2.5168759035804507

Epoch: 5| Step: 4
Training loss: 2.9009393551841196
Validation loss: 2.5158427236027605

Epoch: 5| Step: 5
Training loss: 2.9593224461369467
Validation loss: 2.527499769225066

Epoch: 5| Step: 6
Training loss: 2.52521596306043
Validation loss: 2.5280028814709814

Epoch: 5| Step: 7
Training loss: 3.052160598419172
Validation loss: 2.541882697583508

Epoch: 5| Step: 8
Training loss: 3.05792720152662
Validation loss: 2.5123825460460654

Epoch: 5| Step: 9
Training loss: 2.53917536558041
Validation loss: 2.5193161144016525

Epoch: 5| Step: 10
Training loss: 2.757423870595547
Validation loss: 2.5182331546384913

Epoch: 132| Step: 0
Training loss: 3.2419027548154014
Validation loss: 2.523861955188682

Epoch: 5| Step: 1
Training loss: 2.7033968221011473
Validation loss: 2.5337308558082046

Epoch: 5| Step: 2
Training loss: 2.5168899293944125
Validation loss: 2.535482688243275

Epoch: 5| Step: 3
Training loss: 2.64862645018155
Validation loss: 2.523984629730748

Epoch: 5| Step: 4
Training loss: 2.6657864985675097
Validation loss: 2.5144347254698114

Epoch: 5| Step: 5
Training loss: 2.9360265079829597
Validation loss: 2.5346825419052865

Epoch: 5| Step: 6
Training loss: 2.9060301338623478
Validation loss: 2.5213967679003684

Epoch: 5| Step: 7
Training loss: 2.8216421950109583
Validation loss: 2.5043685000326583

Epoch: 5| Step: 8
Training loss: 2.898319375646354
Validation loss: 2.495089875328575

Epoch: 5| Step: 9
Training loss: 3.2007258664852407
Validation loss: 2.4910897013892646

Epoch: 5| Step: 10
Training loss: 2.617213918068626
Validation loss: 2.4990874819564333

Epoch: 133| Step: 0
Training loss: 2.7837620224198476
Validation loss: 2.499217913950729

Epoch: 5| Step: 1
Training loss: 2.1498375232428084
Validation loss: 2.498725225651877

Epoch: 5| Step: 2
Training loss: 2.601210286810214
Validation loss: 2.514414022008897

Epoch: 5| Step: 3
Training loss: 3.112245700972636
Validation loss: 2.514691470516994

Epoch: 5| Step: 4
Training loss: 2.767575885176846
Validation loss: 2.5387388203852606

Epoch: 5| Step: 5
Training loss: 3.3265953309610232
Validation loss: 2.566919295198802

Epoch: 5| Step: 6
Training loss: 2.960440158594189
Validation loss: 2.586227897862402

Epoch: 5| Step: 7
Training loss: 3.1657785542217125
Validation loss: 2.573384153865385

Epoch: 5| Step: 8
Training loss: 3.034568935997226
Validation loss: 2.5565034648154854

Epoch: 5| Step: 9
Training loss: 2.792086289785718
Validation loss: 2.5214502160661985

Epoch: 5| Step: 10
Training loss: 2.5426468652788676
Validation loss: 2.5010969339608837

Epoch: 134| Step: 0
Training loss: 2.6886695268790595
Validation loss: 2.4990093832198594

Epoch: 5| Step: 1
Training loss: 2.8303151791570316
Validation loss: 2.489006025659087

Epoch: 5| Step: 2
Training loss: 2.7362805511455943
Validation loss: 2.489421108248353

Epoch: 5| Step: 3
Training loss: 3.3074253005215817
Validation loss: 2.4912881415584396

Epoch: 5| Step: 4
Training loss: 3.3785311275695027
Validation loss: 2.4928242975699275

Epoch: 5| Step: 5
Training loss: 2.4502023185182815
Validation loss: 2.4948137432934194

Epoch: 5| Step: 6
Training loss: 3.1847490893930934
Validation loss: 2.4897196571020586

Epoch: 5| Step: 7
Training loss: 2.667019721342675
Validation loss: 2.4861043982400752

Epoch: 5| Step: 8
Training loss: 2.6283956091289564
Validation loss: 2.487066526875298

Epoch: 5| Step: 9
Training loss: 2.9366984795684936
Validation loss: 2.4890799167670186

Epoch: 5| Step: 10
Training loss: 2.4984022757103017
Validation loss: 2.5012704984407104

Epoch: 135| Step: 0
Training loss: 3.2666376177475813
Validation loss: 2.5052657988163505

Epoch: 5| Step: 1
Training loss: 1.9402754193874703
Validation loss: 2.5211741194131183

Epoch: 5| Step: 2
Training loss: 2.6276234732234585
Validation loss: 2.556788247833252

Epoch: 5| Step: 3
Training loss: 3.062264881061439
Validation loss: 2.579680689460875

Epoch: 5| Step: 4
Training loss: 2.6884407348684296
Validation loss: 2.5651347343672732

Epoch: 5| Step: 5
Training loss: 3.176218600968021
Validation loss: 2.5418791444249456

Epoch: 5| Step: 6
Training loss: 3.2465373446527006
Validation loss: 2.501927051474132

Epoch: 5| Step: 7
Training loss: 2.5947246328970524
Validation loss: 2.489078520147467

Epoch: 5| Step: 8
Training loss: 2.5267252098823256
Validation loss: 2.4755270905787983

Epoch: 5| Step: 9
Training loss: 3.2393346529550553
Validation loss: 2.476820159879903

Epoch: 5| Step: 10
Training loss: 2.597923689534215
Validation loss: 2.4756247420462456

Epoch: 136| Step: 0
Training loss: 2.466302551854236
Validation loss: 2.4738372458772027

Epoch: 5| Step: 1
Training loss: 1.8787137446455402
Validation loss: 2.4787842350538756

Epoch: 5| Step: 2
Training loss: 3.5043460565674285
Validation loss: 2.4793976093400416

Epoch: 5| Step: 3
Training loss: 3.212510811754134
Validation loss: 2.4832976199176198

Epoch: 5| Step: 4
Training loss: 2.9831313492863045
Validation loss: 2.48154227135668

Epoch: 5| Step: 5
Training loss: 2.902915764732726
Validation loss: 2.492888439584723

Epoch: 5| Step: 6
Training loss: 3.0570692840401694
Validation loss: 2.5033519382729517

Epoch: 5| Step: 7
Training loss: 3.1316532263705086
Validation loss: 2.514825099494437

Epoch: 5| Step: 8
Training loss: 2.518563491314828
Validation loss: 2.533642723561803

Epoch: 5| Step: 9
Training loss: 2.6707731060630784
Validation loss: 2.5431537551110464

Epoch: 5| Step: 10
Training loss: 2.61370344415156
Validation loss: 2.5588239268020327

Epoch: 137| Step: 0
Training loss: 2.1946555678564774
Validation loss: 2.5788468440142966

Epoch: 5| Step: 1
Training loss: 3.268110579610042
Validation loss: 2.579315789578259

Epoch: 5| Step: 2
Training loss: 3.0473582349166075
Validation loss: 2.5834558228329216

Epoch: 5| Step: 3
Training loss: 3.238493283166909
Validation loss: 2.5544774959907004

Epoch: 5| Step: 4
Training loss: 2.799472476448522
Validation loss: 2.520029379298546

Epoch: 5| Step: 5
Training loss: 2.782948864482461
Validation loss: 2.5080448370517168

Epoch: 5| Step: 6
Training loss: 3.176506532100024
Validation loss: 2.501253476255953

Epoch: 5| Step: 7
Training loss: 2.380843653012846
Validation loss: 2.488807395289347

Epoch: 5| Step: 8
Training loss: 2.8448450683885698
Validation loss: 2.483381514760784

Epoch: 5| Step: 9
Training loss: 2.7415096825486605
Validation loss: 2.484274036298219

Epoch: 5| Step: 10
Training loss: 2.7060553923447297
Validation loss: 2.4907608981853397

Epoch: 138| Step: 0
Training loss: 2.5751487429722184
Validation loss: 2.50099608153717

Epoch: 5| Step: 1
Training loss: 2.5678739255754257
Validation loss: 2.498099718518953

Epoch: 5| Step: 2
Training loss: 2.869616402168287
Validation loss: 2.5054888387986978

Epoch: 5| Step: 3
Training loss: 3.213895674155885
Validation loss: 2.527653527721052

Epoch: 5| Step: 4
Training loss: 2.7316836818082133
Validation loss: 2.577926658938608

Epoch: 5| Step: 5
Training loss: 2.740149455205908
Validation loss: 2.633044667178487

Epoch: 5| Step: 6
Training loss: 2.4418082676818393
Validation loss: 2.675869574906807

Epoch: 5| Step: 7
Training loss: 3.291266710794565
Validation loss: 2.6935303257888132

Epoch: 5| Step: 8
Training loss: 2.1732961272738995
Validation loss: 2.6416020370682225

Epoch: 5| Step: 9
Training loss: 3.5158032181390295
Validation loss: 2.616685915546251

Epoch: 5| Step: 10
Training loss: 3.4892908837293652
Validation loss: 2.594228712932236

Epoch: 139| Step: 0
Training loss: 2.6672697478062197
Validation loss: 2.5642423611332354

Epoch: 5| Step: 1
Training loss: 2.9678333674333177
Validation loss: 2.552829658585475

Epoch: 5| Step: 2
Training loss: 2.590956504972003
Validation loss: 2.490621027083374

Epoch: 5| Step: 3
Training loss: 2.848777602540316
Validation loss: 2.483561946121265

Epoch: 5| Step: 4
Training loss: 2.4905138285294535
Validation loss: 2.519145674891709

Epoch: 5| Step: 5
Training loss: 2.9432262043737487
Validation loss: 2.561051001805185

Epoch: 5| Step: 6
Training loss: 2.590632944129387
Validation loss: 2.719342186233615

Epoch: 5| Step: 7
Training loss: 3.559797098185376
Validation loss: 2.753533946220845

Epoch: 5| Step: 8
Training loss: 3.2025981190619652
Validation loss: 2.623645131042169

Epoch: 5| Step: 9
Training loss: 2.909074784635159
Validation loss: 2.590390973395091

Epoch: 5| Step: 10
Training loss: 3.580647874313963
Validation loss: 2.6009332310374127

Epoch: 140| Step: 0
Training loss: 2.9435740229981695
Validation loss: 2.5594017292954665

Epoch: 5| Step: 1
Training loss: 2.7089074528890555
Validation loss: 2.5417802984643516

Epoch: 5| Step: 2
Training loss: 3.2018906610847897
Validation loss: 2.52040426422648

Epoch: 5| Step: 3
Training loss: 2.727771567471184
Validation loss: 2.5008465553887627

Epoch: 5| Step: 4
Training loss: 2.619401593047152
Validation loss: 2.522320486593101

Epoch: 5| Step: 5
Training loss: 3.081016460489877
Validation loss: 2.555957944045619

Epoch: 5| Step: 6
Training loss: 2.703040149216953
Validation loss: 2.645667744258267

Epoch: 5| Step: 7
Training loss: 2.5091417064035504
Validation loss: 2.7199146575315227

Epoch: 5| Step: 8
Training loss: 3.4438775289914685
Validation loss: 2.7515711682210537

Epoch: 5| Step: 9
Training loss: 3.2105636935983464
Validation loss: 2.6087395749898277

Epoch: 5| Step: 10
Training loss: 3.1360428059245016
Validation loss: 2.53681799392185

Epoch: 141| Step: 0
Training loss: 2.722360340385985
Validation loss: 2.519529184459982

Epoch: 5| Step: 1
Training loss: 3.1888949763749075
Validation loss: 2.5342935160726854

Epoch: 5| Step: 2
Training loss: 2.8705999455769495
Validation loss: 2.529200467668381

Epoch: 5| Step: 3
Training loss: 2.980647610438427
Validation loss: 2.570150796732339

Epoch: 5| Step: 4
Training loss: 2.7411709284130485
Validation loss: 2.604026371940235

Epoch: 5| Step: 5
Training loss: 2.6719406744487117
Validation loss: 2.699822337238972

Epoch: 5| Step: 6
Training loss: 3.1255282146356316
Validation loss: 2.7685167227729353

Epoch: 5| Step: 7
Training loss: 2.593372271506145
Validation loss: 2.7433024807805935

Epoch: 5| Step: 8
Training loss: 3.45568090240803
Validation loss: 2.6908397522781247

Epoch: 5| Step: 9
Training loss: 2.789989926309755
Validation loss: 2.5931657700746413

Epoch: 5| Step: 10
Training loss: 3.170593604216817
Validation loss: 2.5318594932661984

Epoch: 142| Step: 0
Training loss: 3.1338951161841972
Validation loss: 2.5049467398984633

Epoch: 5| Step: 1
Training loss: 3.0370123452145124
Validation loss: 2.5079543153762307

Epoch: 5| Step: 2
Training loss: 3.06676917388537
Validation loss: 2.5115202092292583

Epoch: 5| Step: 3
Training loss: 3.377012853496875
Validation loss: 2.5100707449505486

Epoch: 5| Step: 4
Training loss: 2.654121982631496
Validation loss: 2.505735594145754

Epoch: 5| Step: 5
Training loss: 2.6748353497466706
Validation loss: 2.518150902459485

Epoch: 5| Step: 6
Training loss: 2.13440608480893
Validation loss: 2.52704659759489

Epoch: 5| Step: 7
Training loss: 3.124508933584573
Validation loss: 2.5321010420881804

Epoch: 5| Step: 8
Training loss: 3.0194402880865705
Validation loss: 2.550265330200131

Epoch: 5| Step: 9
Training loss: 2.5046971064506494
Validation loss: 2.5706113468338336

Epoch: 5| Step: 10
Training loss: 2.7297730876254747
Validation loss: 2.602606320109955

Epoch: 143| Step: 0
Training loss: 2.5643249154272754
Validation loss: 2.6340567576310345

Epoch: 5| Step: 1
Training loss: 2.694330628166208
Validation loss: 2.663704892125154

Epoch: 5| Step: 2
Training loss: 3.0806632638150395
Validation loss: 2.6227883535806633

Epoch: 5| Step: 3
Training loss: 2.9553067660329044
Validation loss: 2.576514168993725

Epoch: 5| Step: 4
Training loss: 2.457790336339197
Validation loss: 2.566943212499215

Epoch: 5| Step: 5
Training loss: 2.639610411623766
Validation loss: 2.55281029686319

Epoch: 5| Step: 6
Training loss: 3.010443787414104
Validation loss: 2.5272921823695196

Epoch: 5| Step: 7
Training loss: 2.9158677959849464
Validation loss: 2.5142566493339342

Epoch: 5| Step: 8
Training loss: 3.091997054578555
Validation loss: 2.494591673187013

Epoch: 5| Step: 9
Training loss: 3.1067895923356192
Validation loss: 2.498019611280708

Epoch: 5| Step: 10
Training loss: 3.2320542417450286
Validation loss: 2.499498980575674

Epoch: 144| Step: 0
Training loss: 3.0346344606079456
Validation loss: 2.498512792714552

Epoch: 5| Step: 1
Training loss: 2.8391992396427015
Validation loss: 2.4989459635799913

Epoch: 5| Step: 2
Training loss: 3.533488956359127
Validation loss: 2.4978033875236947

Epoch: 5| Step: 3
Training loss: 2.7668335423833006
Validation loss: 2.4955510956942706

Epoch: 5| Step: 4
Training loss: 2.6995058914462255
Validation loss: 2.4989238689155773

Epoch: 5| Step: 5
Training loss: 2.9743666671953632
Validation loss: 2.4956458824502787

Epoch: 5| Step: 6
Training loss: 2.957793889538817
Validation loss: 2.497101462177677

Epoch: 5| Step: 7
Training loss: 2.661700502091791
Validation loss: 2.508893438602974

Epoch: 5| Step: 8
Training loss: 2.2126249202656925
Validation loss: 2.51312177989739

Epoch: 5| Step: 9
Training loss: 2.910816010311581
Validation loss: 2.5229737317151395

Epoch: 5| Step: 10
Training loss: 2.7804574587304103
Validation loss: 2.5265142327120507

Epoch: 145| Step: 0
Training loss: 2.8914844781682287
Validation loss: 2.525773114280239

Epoch: 5| Step: 1
Training loss: 2.707519927510679
Validation loss: 2.5221338242178355

Epoch: 5| Step: 2
Training loss: 2.982900365031913
Validation loss: 2.5161420499313962

Epoch: 5| Step: 3
Training loss: 2.5960467177891084
Validation loss: 2.509193797753709

Epoch: 5| Step: 4
Training loss: 2.638066062024873
Validation loss: 2.5091770658452837

Epoch: 5| Step: 5
Training loss: 2.9121196907827853
Validation loss: 2.5044407218042393

Epoch: 5| Step: 6
Training loss: 2.885803820989449
Validation loss: 2.498338912488842

Epoch: 5| Step: 7
Training loss: 2.8255522601698897
Validation loss: 2.498665514988674

Epoch: 5| Step: 8
Training loss: 2.3535912972468944
Validation loss: 2.499755739769481

Epoch: 5| Step: 9
Training loss: 3.5961383346919806
Validation loss: 2.516072493256592

Epoch: 5| Step: 10
Training loss: 2.6103309205249126
Validation loss: 2.515597198644546

Epoch: 146| Step: 0
Training loss: 2.915359167673528
Validation loss: 2.5211891696754143

Epoch: 5| Step: 1
Training loss: 2.713287302543728
Validation loss: 2.526574990378902

Epoch: 5| Step: 2
Training loss: 2.8392323251590432
Validation loss: 2.5246177490405413

Epoch: 5| Step: 3
Training loss: 2.76549559899316
Validation loss: 2.5299620598380126

Epoch: 5| Step: 4
Training loss: 2.733427831908089
Validation loss: 2.527275192422084

Epoch: 5| Step: 5
Training loss: 2.2507240402010993
Validation loss: 2.527175615988718

Epoch: 5| Step: 6
Training loss: 3.1314578659290415
Validation loss: 2.5318771288315056

Epoch: 5| Step: 7
Training loss: 2.9201455939587997
Validation loss: 2.517026091845129

Epoch: 5| Step: 8
Training loss: 2.670913701824526
Validation loss: 2.5072890698811903

Epoch: 5| Step: 9
Training loss: 2.950028183366018
Validation loss: 2.5039730086478684

Epoch: 5| Step: 10
Training loss: 3.2290886326046855
Validation loss: 2.498781845736143

Epoch: 147| Step: 0
Training loss: 2.818942257568886
Validation loss: 2.4883900942147315

Epoch: 5| Step: 1
Training loss: 2.783275081306671
Validation loss: 2.4936393607774034

Epoch: 5| Step: 2
Training loss: 2.867562168182429
Validation loss: 2.4948746944441824

Epoch: 5| Step: 3
Training loss: 3.14271134496605
Validation loss: 2.4946439856339824

Epoch: 5| Step: 4
Training loss: 2.644897886299011
Validation loss: 2.49374498676293

Epoch: 5| Step: 5
Training loss: 3.120691610122391
Validation loss: 2.5014586848717717

Epoch: 5| Step: 6
Training loss: 2.092592745130465
Validation loss: 2.504479325965761

Epoch: 5| Step: 7
Training loss: 2.6621736783204963
Validation loss: 2.508248556880258

Epoch: 5| Step: 8
Training loss: 2.741316784811847
Validation loss: 2.521230121471365

Epoch: 5| Step: 9
Training loss: 3.0704059926326885
Validation loss: 2.5106636201281303

Epoch: 5| Step: 10
Training loss: 3.1584392546621225
Validation loss: 2.510652277714803

Epoch: 148| Step: 0
Training loss: 2.4847521225781732
Validation loss: 2.499873756994911

Epoch: 5| Step: 1
Training loss: 2.914357188360771
Validation loss: 2.497103982593719

Epoch: 5| Step: 2
Training loss: 2.7735732354273708
Validation loss: 2.4888301401149677

Epoch: 5| Step: 3
Training loss: 2.936602516238605
Validation loss: 2.486474203162914

Epoch: 5| Step: 4
Training loss: 2.899905920146915
Validation loss: 2.481007983579385

Epoch: 5| Step: 5
Training loss: 3.2983217364533504
Validation loss: 2.482997143553097

Epoch: 5| Step: 6
Training loss: 2.522546758605879
Validation loss: 2.4820921838470826

Epoch: 5| Step: 7
Training loss: 2.764956118630395
Validation loss: 2.4812772278683903

Epoch: 5| Step: 8
Training loss: 2.5261347383217716
Validation loss: 2.479517433030131

Epoch: 5| Step: 9
Training loss: 2.854027255103913
Validation loss: 2.483700951364428

Epoch: 5| Step: 10
Training loss: 3.119204067284906
Validation loss: 2.4820392040314885

Epoch: 149| Step: 0
Training loss: 2.6111666986847686
Validation loss: 2.490914746193885

Epoch: 5| Step: 1
Training loss: 2.9820566809401603
Validation loss: 2.4876441201047057

Epoch: 5| Step: 2
Training loss: 2.7897420103504134
Validation loss: 2.5044961092191045

Epoch: 5| Step: 3
Training loss: 3.0592515805592546
Validation loss: 2.5190016470758825

Epoch: 5| Step: 4
Training loss: 2.7156984589258086
Validation loss: 2.5114825421572804

Epoch: 5| Step: 5
Training loss: 2.683465102220259
Validation loss: 2.5318989997184964

Epoch: 5| Step: 6
Training loss: 2.8138438087392963
Validation loss: 2.5479103840984663

Epoch: 5| Step: 7
Training loss: 2.5460321634902523
Validation loss: 2.563851676063838

Epoch: 5| Step: 8
Training loss: 2.404970299424357
Validation loss: 2.5774224714711096

Epoch: 5| Step: 9
Training loss: 3.249634648841643
Validation loss: 2.606342576802165

Epoch: 5| Step: 10
Training loss: 3.2082612330934817
Validation loss: 2.5908154035400153

Epoch: 150| Step: 0
Training loss: 2.5653780150391845
Validation loss: 2.556049186857407

Epoch: 5| Step: 1
Training loss: 3.029517238922356
Validation loss: 2.5171297251086937

Epoch: 5| Step: 2
Training loss: 3.1723112360692496
Validation loss: 2.4960608756138423

Epoch: 5| Step: 3
Training loss: 2.672906330789358
Validation loss: 2.485407027709887

Epoch: 5| Step: 4
Training loss: 2.7895317644552438
Validation loss: 2.481635574614577

Epoch: 5| Step: 5
Training loss: 2.6158304368515806
Validation loss: 2.470618794448328

Epoch: 5| Step: 6
Training loss: 3.190049741112048
Validation loss: 2.47614902533116

Epoch: 5| Step: 7
Training loss: 2.78741303723085
Validation loss: 2.47895253836194

Epoch: 5| Step: 8
Training loss: 2.8328716425500224
Validation loss: 2.4790532368905653

Epoch: 5| Step: 9
Training loss: 2.75856323398164
Validation loss: 2.474302079693687

Epoch: 5| Step: 10
Training loss: 2.6002563313525484
Validation loss: 2.492210299356445

Epoch: 151| Step: 0
Training loss: 2.8937427100466695
Validation loss: 2.5010392438792395

Epoch: 5| Step: 1
Training loss: 3.187549366288217
Validation loss: 2.522711291709395

Epoch: 5| Step: 2
Training loss: 2.9454690502057925
Validation loss: 2.5225429373502144

Epoch: 5| Step: 3
Training loss: 2.505358199133037
Validation loss: 2.523979011823266

Epoch: 5| Step: 4
Training loss: 2.8338366416740284
Validation loss: 2.522366396141185

Epoch: 5| Step: 5
Training loss: 3.4134926047518124
Validation loss: 2.5076673837104613

Epoch: 5| Step: 6
Training loss: 2.606867333352653
Validation loss: 2.508206172233158

Epoch: 5| Step: 7
Training loss: 2.60123860860344
Validation loss: 2.5128102535615024

Epoch: 5| Step: 8
Training loss: 2.7889258941620234
Validation loss: 2.517595431905412

Epoch: 5| Step: 9
Training loss: 2.3336528718225793
Validation loss: 2.5187443622336803

Epoch: 5| Step: 10
Training loss: 2.768277722588079
Validation loss: 2.5199569827049517

Epoch: 152| Step: 0
Training loss: 2.7617244477597693
Validation loss: 2.498407520163392

Epoch: 5| Step: 1
Training loss: 2.866256354782839
Validation loss: 2.4794711581504156

Epoch: 5| Step: 2
Training loss: 2.7541618066264877
Validation loss: 2.470287697185172

Epoch: 5| Step: 3
Training loss: 2.31479602961512
Validation loss: 2.468807036516036

Epoch: 5| Step: 4
Training loss: 2.750281059467722
Validation loss: 2.4701133858502744

Epoch: 5| Step: 5
Training loss: 3.2899934081037627
Validation loss: 2.470465065786225

Epoch: 5| Step: 6
Training loss: 2.5769807993033296
Validation loss: 2.4731759112675467

Epoch: 5| Step: 7
Training loss: 2.6868959679576268
Validation loss: 2.4733468941408354

Epoch: 5| Step: 8
Training loss: 2.7770157203160677
Validation loss: 2.4679307394725214

Epoch: 5| Step: 9
Training loss: 3.5058948738192326
Validation loss: 2.4705876709412413

Epoch: 5| Step: 10
Training loss: 2.5535550188419536
Validation loss: 2.476036926174156

Epoch: 153| Step: 0
Training loss: 3.197817093648214
Validation loss: 2.4787348054598017

Epoch: 5| Step: 1
Training loss: 2.4600092999352303
Validation loss: 2.4818064023144766

Epoch: 5| Step: 2
Training loss: 3.2931455517205572
Validation loss: 2.5007239124257006

Epoch: 5| Step: 3
Training loss: 2.559951910967959
Validation loss: 2.4987276038710204

Epoch: 5| Step: 4
Training loss: 2.979702312270636
Validation loss: 2.512409937572957

Epoch: 5| Step: 5
Training loss: 2.660252147856165
Validation loss: 2.555275300419511

Epoch: 5| Step: 6
Training loss: 2.8140412240333443
Validation loss: 2.607062704664605

Epoch: 5| Step: 7
Training loss: 2.563822800278289
Validation loss: 2.575767358388766

Epoch: 5| Step: 8
Training loss: 3.0347568637045303
Validation loss: 2.567847003889327

Epoch: 5| Step: 9
Training loss: 2.556472201588094
Validation loss: 2.528713860362442

Epoch: 5| Step: 10
Training loss: 2.856806367405675
Validation loss: 2.5105317660036666

Epoch: 154| Step: 0
Training loss: 3.386294926894168
Validation loss: 2.4878782365585397

Epoch: 5| Step: 1
Training loss: 2.5390040933787104
Validation loss: 2.4803959160213505

Epoch: 5| Step: 2
Training loss: 2.89379214427076
Validation loss: 2.495485564363897

Epoch: 5| Step: 3
Training loss: 2.109344595230813
Validation loss: 2.4914740825453863

Epoch: 5| Step: 4
Training loss: 3.058287545536168
Validation loss: 2.507623977636413

Epoch: 5| Step: 5
Training loss: 2.5541688351728267
Validation loss: 2.5392980029973637

Epoch: 5| Step: 6
Training loss: 2.68845341648568
Validation loss: 2.551355247951523

Epoch: 5| Step: 7
Training loss: 2.5868280726966857
Validation loss: 2.521346580415887

Epoch: 5| Step: 8
Training loss: 2.472967480783106
Validation loss: 2.510885606818585

Epoch: 5| Step: 9
Training loss: 3.5176052365695893
Validation loss: 2.537596184801735

Epoch: 5| Step: 10
Training loss: 3.0828520596842486
Validation loss: 2.568922338973811

Epoch: 155| Step: 0
Training loss: 2.941300064743789
Validation loss: 2.6050155945897395

Epoch: 5| Step: 1
Training loss: 2.6900043795241544
Validation loss: 2.5991330448208525

Epoch: 5| Step: 2
Training loss: 2.8451779312245393
Validation loss: 2.595357154083269

Epoch: 5| Step: 3
Training loss: 2.772532312670979
Validation loss: 2.5431585050650627

Epoch: 5| Step: 4
Training loss: 3.006395516472316
Validation loss: 2.512612962701086

Epoch: 5| Step: 5
Training loss: 3.239120025050342
Validation loss: 2.4930360028369303

Epoch: 5| Step: 6
Training loss: 2.61251623705331
Validation loss: 2.472536045072473

Epoch: 5| Step: 7
Training loss: 2.3465856056229017
Validation loss: 2.4703607181455287

Epoch: 5| Step: 8
Training loss: 3.000046411791056
Validation loss: 2.4541364823137424

Epoch: 5| Step: 9
Training loss: 2.510378561614468
Validation loss: 2.449078186432357

Epoch: 5| Step: 10
Training loss: 2.8572756872635416
Validation loss: 2.460511308738358

Epoch: 156| Step: 0
Training loss: 3.1549933925263245
Validation loss: 2.4476694600561277

Epoch: 5| Step: 1
Training loss: 2.3975288583492445
Validation loss: 2.4467673569848998

Epoch: 5| Step: 2
Training loss: 2.6206298963454158
Validation loss: 2.448140583955019

Epoch: 5| Step: 3
Training loss: 2.6451779452429114
Validation loss: 2.4498002561671828

Epoch: 5| Step: 4
Training loss: 2.2131058806245534
Validation loss: 2.4454350474042736

Epoch: 5| Step: 5
Training loss: 3.1480503648851483
Validation loss: 2.457910049382536

Epoch: 5| Step: 6
Training loss: 2.9047109158676605
Validation loss: 2.4643274208521975

Epoch: 5| Step: 7
Training loss: 3.0549169585933704
Validation loss: 2.465955620863388

Epoch: 5| Step: 8
Training loss: 3.0811309853369933
Validation loss: 2.4832722115068

Epoch: 5| Step: 9
Training loss: 2.22391349753241
Validation loss: 2.4974291975861216

Epoch: 5| Step: 10
Training loss: 3.063030897561914
Validation loss: 2.485018582244351

Epoch: 157| Step: 0
Training loss: 2.4395414753316413
Validation loss: 2.495766372339822

Epoch: 5| Step: 1
Training loss: 2.897672732242824
Validation loss: 2.5085000024848703

Epoch: 5| Step: 2
Training loss: 2.8331067798768337
Validation loss: 2.5343925468082493

Epoch: 5| Step: 3
Training loss: 2.473199432155316
Validation loss: 2.560781065921079

Epoch: 5| Step: 4
Training loss: 3.0473826450098818
Validation loss: 2.551864113013479

Epoch: 5| Step: 5
Training loss: 2.5330710747977063
Validation loss: 2.513669722034948

Epoch: 5| Step: 6
Training loss: 2.7471400908752437
Validation loss: 2.490230230319527

Epoch: 5| Step: 7
Training loss: 2.515328146911553
Validation loss: 2.473195004448988

Epoch: 5| Step: 8
Training loss: 2.7041900829678704
Validation loss: 2.468069428998286

Epoch: 5| Step: 9
Training loss: 3.204253802625601
Validation loss: 2.4587993103721772

Epoch: 5| Step: 10
Training loss: 3.182092755100484
Validation loss: 2.4598652050662464

Epoch: 158| Step: 0
Training loss: 2.7047429176616524
Validation loss: 2.463007095600415

Epoch: 5| Step: 1
Training loss: 2.9551350852181373
Validation loss: 2.4627885265399274

Epoch: 5| Step: 2
Training loss: 2.6796456825841535
Validation loss: 2.464799090536762

Epoch: 5| Step: 3
Training loss: 2.943590708186894
Validation loss: 2.460922236475803

Epoch: 5| Step: 4
Training loss: 2.7124241866666625
Validation loss: 2.4566023606972127

Epoch: 5| Step: 5
Training loss: 3.200588059036186
Validation loss: 2.4553830891817623

Epoch: 5| Step: 6
Training loss: 2.9019467889704016
Validation loss: 2.4573455541175515

Epoch: 5| Step: 7
Training loss: 2.614094013359342
Validation loss: 2.4678957608567647

Epoch: 5| Step: 8
Training loss: 2.9933154019652006
Validation loss: 2.479614900470036

Epoch: 5| Step: 9
Training loss: 1.9737131441237517
Validation loss: 2.484778074026441

Epoch: 5| Step: 10
Training loss: 2.7842791916518412
Validation loss: 2.498021346701355

Epoch: 159| Step: 0
Training loss: 2.6772887055900103
Validation loss: 2.491513298166232

Epoch: 5| Step: 1
Training loss: 3.117803909429098
Validation loss: 2.5082495523898443

Epoch: 5| Step: 2
Training loss: 2.61785716129497
Validation loss: 2.507368649900044

Epoch: 5| Step: 3
Training loss: 2.295393381582904
Validation loss: 2.4804907331008508

Epoch: 5| Step: 4
Training loss: 2.5874081028638254
Validation loss: 2.4545999490855097

Epoch: 5| Step: 5
Training loss: 3.14822424836109
Validation loss: 2.458310951171343

Epoch: 5| Step: 6
Training loss: 3.0101011610299393
Validation loss: 2.451781620460341

Epoch: 5| Step: 7
Training loss: 2.6886507276495637
Validation loss: 2.4551198083252337

Epoch: 5| Step: 8
Training loss: 2.66671808511117
Validation loss: 2.4502754410689898

Epoch: 5| Step: 9
Training loss: 2.9847268101904616
Validation loss: 2.4470042528351303

Epoch: 5| Step: 10
Training loss: 2.7484557410887804
Validation loss: 2.4492277297747522

Epoch: 160| Step: 0
Training loss: 3.007891448334833
Validation loss: 2.4521262714053256

Epoch: 5| Step: 1
Training loss: 2.7897615812149956
Validation loss: 2.4526652045058257

Epoch: 5| Step: 2
Training loss: 2.6985318183429623
Validation loss: 2.47842711191848

Epoch: 5| Step: 3
Training loss: 3.050655425892419
Validation loss: 2.4863892826199447

Epoch: 5| Step: 4
Training loss: 2.7217294437280053
Validation loss: 2.5254611259178317

Epoch: 5| Step: 5
Training loss: 2.6241145684247464
Validation loss: 2.5831282041670587

Epoch: 5| Step: 6
Training loss: 2.5500087064706607
Validation loss: 2.594247767511715

Epoch: 5| Step: 7
Training loss: 2.889516256956993
Validation loss: 2.603990125681291

Epoch: 5| Step: 8
Training loss: 2.774809591960674
Validation loss: 2.5777116799069253

Epoch: 5| Step: 9
Training loss: 2.7382723689785546
Validation loss: 2.537098888452687

Epoch: 5| Step: 10
Training loss: 3.0732345847637927
Validation loss: 2.4797556756437302

Epoch: 161| Step: 0
Training loss: 3.077654497620887
Validation loss: 2.470044177025932

Epoch: 5| Step: 1
Training loss: 2.3371650251788885
Validation loss: 2.4683284646267527

Epoch: 5| Step: 2
Training loss: 3.073524251236195
Validation loss: 2.4725106121309834

Epoch: 5| Step: 3
Training loss: 2.830776257490285
Validation loss: 2.4722017306792505

Epoch: 5| Step: 4
Training loss: 2.8956815464847554
Validation loss: 2.4806909388166467

Epoch: 5| Step: 5
Training loss: 2.7621636578622457
Validation loss: 2.4890904377364618

Epoch: 5| Step: 6
Training loss: 2.4281039950175356
Validation loss: 2.4767988470077373

Epoch: 5| Step: 7
Training loss: 2.7888992219035242
Validation loss: 2.474454660331186

Epoch: 5| Step: 8
Training loss: 2.7139915830387493
Validation loss: 2.4624575216334628

Epoch: 5| Step: 9
Training loss: 3.0862832950049106
Validation loss: 2.471406995187777

Epoch: 5| Step: 10
Training loss: 2.9018565779197147
Validation loss: 2.4767956176118555

Epoch: 162| Step: 0
Training loss: 2.970681937177893
Validation loss: 2.4712529851500067

Epoch: 5| Step: 1
Training loss: 2.8434706330625024
Validation loss: 2.5002921159368086

Epoch: 5| Step: 2
Training loss: 2.732279295947252
Validation loss: 2.5083400869178085

Epoch: 5| Step: 3
Training loss: 2.8640214033659017
Validation loss: 2.5424296664267003

Epoch: 5| Step: 4
Training loss: 3.1068437711089714
Validation loss: 2.5767683917879665

Epoch: 5| Step: 5
Training loss: 2.8688278287415425
Validation loss: 2.562963052205976

Epoch: 5| Step: 6
Training loss: 3.0591666317237207
Validation loss: 2.575649202575304

Epoch: 5| Step: 7
Training loss: 2.422029650272791
Validation loss: 2.557763016988636

Epoch: 5| Step: 8
Training loss: 2.3108046219430705
Validation loss: 2.5183696750681097

Epoch: 5| Step: 9
Training loss: 2.7494700528081886
Validation loss: 2.4959732800226333

Epoch: 5| Step: 10
Training loss: 2.752232945485949
Validation loss: 2.4897449997152385

Epoch: 163| Step: 0
Training loss: 2.9128174768394515
Validation loss: 2.4690540677356316

Epoch: 5| Step: 1
Training loss: 2.8409748999169295
Validation loss: 2.4710836983581466

Epoch: 5| Step: 2
Training loss: 2.827204939256206
Validation loss: 2.472682336173509

Epoch: 5| Step: 3
Training loss: 2.4770887519727967
Validation loss: 2.4810320078294428

Epoch: 5| Step: 4
Training loss: 2.435944868055827
Validation loss: 2.4829944942124014

Epoch: 5| Step: 5
Training loss: 2.827863143684931
Validation loss: 2.4896072247189864

Epoch: 5| Step: 6
Training loss: 3.0652325953583786
Validation loss: 2.4871783051761986

Epoch: 5| Step: 7
Training loss: 2.8774367247782426
Validation loss: 2.485448502029829

Epoch: 5| Step: 8
Training loss: 3.4035107158449045
Validation loss: 2.482726543093505

Epoch: 5| Step: 9
Training loss: 2.2511773737705054
Validation loss: 2.4894515421545886

Epoch: 5| Step: 10
Training loss: 2.652851668477729
Validation loss: 2.4973990405392725

Epoch: 164| Step: 0
Training loss: 2.998683958674003
Validation loss: 2.5090980632478734

Epoch: 5| Step: 1
Training loss: 2.993700088371614
Validation loss: 2.5383862565279967

Epoch: 5| Step: 2
Training loss: 2.989111053343651
Validation loss: 2.5354649594564576

Epoch: 5| Step: 3
Training loss: 2.3300455863324236
Validation loss: 2.5389250232972214

Epoch: 5| Step: 4
Training loss: 2.5020375531593113
Validation loss: 2.538042043584058

Epoch: 5| Step: 5
Training loss: 2.4580972418053153
Validation loss: 2.5315549578901435

Epoch: 5| Step: 6
Training loss: 2.636531568876823
Validation loss: 2.5394738496901335

Epoch: 5| Step: 7
Training loss: 2.9953784312522402
Validation loss: 2.5151935284565674

Epoch: 5| Step: 8
Training loss: 3.1927251436787687
Validation loss: 2.5323202052596527

Epoch: 5| Step: 9
Training loss: 2.5804555820425925
Validation loss: 2.508452895848549

Epoch: 5| Step: 10
Training loss: 2.741652564231833
Validation loss: 2.506628461896588

Epoch: 165| Step: 0
Training loss: 2.3940665212581766
Validation loss: 2.4881463901871688

Epoch: 5| Step: 1
Training loss: 3.2339624703894905
Validation loss: 2.4710380052606142

Epoch: 5| Step: 2
Training loss: 2.714436057236509
Validation loss: 2.4594802899161072

Epoch: 5| Step: 3
Training loss: 2.497520552389296
Validation loss: 2.4681577915874118

Epoch: 5| Step: 4
Training loss: 3.078846338633434
Validation loss: 2.4647783175468954

Epoch: 5| Step: 5
Training loss: 2.820079001273775
Validation loss: 2.4592093076233206

Epoch: 5| Step: 6
Training loss: 2.2348357039107194
Validation loss: 2.46517332176271

Epoch: 5| Step: 7
Training loss: 2.8729353415638577
Validation loss: 2.4763574364899905

Epoch: 5| Step: 8
Training loss: 2.944178355287624
Validation loss: 2.468415845834959

Epoch: 5| Step: 9
Training loss: 3.01435801716987
Validation loss: 2.478414702922578

Epoch: 5| Step: 10
Training loss: 2.622539638805197
Validation loss: 2.49426488054261

Epoch: 166| Step: 0
Training loss: 2.6061020843465905
Validation loss: 2.506436572330207

Epoch: 5| Step: 1
Training loss: 2.7694195077841157
Validation loss: 2.524577306112718

Epoch: 5| Step: 2
Training loss: 2.8000381739602704
Validation loss: 2.549031600590779

Epoch: 5| Step: 3
Training loss: 3.081179115455009
Validation loss: 2.5388132139243607

Epoch: 5| Step: 4
Training loss: 2.9435312566456804
Validation loss: 2.5590497952260027

Epoch: 5| Step: 5
Training loss: 3.0012137818603843
Validation loss: 2.555544915012906

Epoch: 5| Step: 6
Training loss: 2.657515459993597
Validation loss: 2.5161136414273044

Epoch: 5| Step: 7
Training loss: 2.8554148114455042
Validation loss: 2.4868050555811028

Epoch: 5| Step: 8
Training loss: 2.5940948624746896
Validation loss: 2.4759076244668017

Epoch: 5| Step: 9
Training loss: 2.6845253739077037
Validation loss: 2.4660644545544055

Epoch: 5| Step: 10
Training loss: 2.567338794375885
Validation loss: 2.4614240038840696

Epoch: 167| Step: 0
Training loss: 3.3164292549261
Validation loss: 2.457408713070889

Epoch: 5| Step: 1
Training loss: 2.510658431909596
Validation loss: 2.4651872434452047

Epoch: 5| Step: 2
Training loss: 3.1093113571631408
Validation loss: 2.458247065573005

Epoch: 5| Step: 3
Training loss: 2.8735286430602693
Validation loss: 2.46262938923303

Epoch: 5| Step: 4
Training loss: 3.3432897803631914
Validation loss: 2.45767987355542

Epoch: 5| Step: 5
Training loss: 2.791497116254096
Validation loss: 2.4550932619602905

Epoch: 5| Step: 6
Training loss: 2.7602391791714194
Validation loss: 2.46057937498214

Epoch: 5| Step: 7
Training loss: 2.9031897399056703
Validation loss: 2.474888999681418

Epoch: 5| Step: 8
Training loss: 2.425611800266238
Validation loss: 2.4668921108482715

Epoch: 5| Step: 9
Training loss: 1.8252866833361097
Validation loss: 2.4946135410824954

Epoch: 5| Step: 10
Training loss: 2.2615847638489
Validation loss: 2.4984158983364972

Epoch: 168| Step: 0
Training loss: 3.0198770697628556
Validation loss: 2.500754751080741

Epoch: 5| Step: 1
Training loss: 2.904362875952308
Validation loss: 2.497744006872384

Epoch: 5| Step: 2
Training loss: 2.5743792517122897
Validation loss: 2.490815568790333

Epoch: 5| Step: 3
Training loss: 2.6599769924000576
Validation loss: 2.4712991011486407

Epoch: 5| Step: 4
Training loss: 2.2586055009787596
Validation loss: 2.4724365120148786

Epoch: 5| Step: 5
Training loss: 2.802644968766713
Validation loss: 2.4657726805756948

Epoch: 5| Step: 6
Training loss: 2.966170465212465
Validation loss: 2.47234577224956

Epoch: 5| Step: 7
Training loss: 2.5043612585983106
Validation loss: 2.4687087342570107

Epoch: 5| Step: 8
Training loss: 2.962748514688937
Validation loss: 2.4678151718125787

Epoch: 5| Step: 9
Training loss: 2.3743932852526726
Validation loss: 2.472599057585882

Epoch: 5| Step: 10
Training loss: 3.360573204511162
Validation loss: 2.4821162203258167

Epoch: 169| Step: 0
Training loss: 2.7580506651486845
Validation loss: 2.4996928057053873

Epoch: 5| Step: 1
Training loss: 2.623565099997204
Validation loss: 2.519345285596247

Epoch: 5| Step: 2
Training loss: 2.533374224717576
Validation loss: 2.529600839027919

Epoch: 5| Step: 3
Training loss: 2.97635455669239
Validation loss: 2.5545219083476822

Epoch: 5| Step: 4
Training loss: 3.0980192070421624
Validation loss: 2.562476225311735

Epoch: 5| Step: 5
Training loss: 2.4453357049493025
Validation loss: 2.5849123441618755

Epoch: 5| Step: 6
Training loss: 3.015918302355343
Validation loss: 2.585638039024973

Epoch: 5| Step: 7
Training loss: 2.8948312210138845
Validation loss: 2.5529435784591046

Epoch: 5| Step: 8
Training loss: 2.6544475947711286
Validation loss: 2.620759516633336

Epoch: 5| Step: 9
Training loss: 2.822282351539967
Validation loss: 2.597050588661465

Epoch: 5| Step: 10
Training loss: 2.4489083952837456
Validation loss: 2.5516043536041413

Epoch: 170| Step: 0
Training loss: 2.5605491096958213
Validation loss: 2.5586740488219055

Epoch: 5| Step: 1
Training loss: 2.431037356141021
Validation loss: 2.5484746030031213

Epoch: 5| Step: 2
Training loss: 3.220881672866973
Validation loss: 2.530733013947682

Epoch: 5| Step: 3
Training loss: 3.0269234839334627
Validation loss: 2.516080659772621

Epoch: 5| Step: 4
Training loss: 2.7351384432272137
Validation loss: 2.502213320746549

Epoch: 5| Step: 5
Training loss: 2.7044362322242836
Validation loss: 2.4713748432360645

Epoch: 5| Step: 6
Training loss: 2.9092329570378905
Validation loss: 2.4586283804102673

Epoch: 5| Step: 7
Training loss: 2.5026393309685364
Validation loss: 2.463999120770721

Epoch: 5| Step: 8
Training loss: 2.950170259896525
Validation loss: 2.4605084518091176

Epoch: 5| Step: 9
Training loss: 2.933795947384322
Validation loss: 2.475047319734044

Epoch: 5| Step: 10
Training loss: 2.712411353425068
Validation loss: 2.486989955602737

Epoch: 171| Step: 0
Training loss: 3.131785236230151
Validation loss: 2.523960397781189

Epoch: 5| Step: 1
Training loss: 2.5846429909595936
Validation loss: 2.529777331403004

Epoch: 5| Step: 2
Training loss: 2.8414411289359816
Validation loss: 2.5889650674799367

Epoch: 5| Step: 3
Training loss: 2.6878150932655203
Validation loss: 2.6250079809674003

Epoch: 5| Step: 4
Training loss: 3.27193297996995
Validation loss: 2.6488209587578138

Epoch: 5| Step: 5
Training loss: 3.0892495453258384
Validation loss: 2.648478465662298

Epoch: 5| Step: 6
Training loss: 2.6224212695759834
Validation loss: 2.6250477702007804

Epoch: 5| Step: 7
Training loss: 3.1344060103307703
Validation loss: 2.5594657783987302

Epoch: 5| Step: 8
Training loss: 2.5726455257318515
Validation loss: 2.510084607587022

Epoch: 5| Step: 9
Training loss: 2.5027154480284106
Validation loss: 2.4790435006236624

Epoch: 5| Step: 10
Training loss: 2.4882771298840005
Validation loss: 2.4829674689173498

Epoch: 172| Step: 0
Training loss: 3.405675017097568
Validation loss: 2.4697101865459303

Epoch: 5| Step: 1
Training loss: 2.9117794144157507
Validation loss: 2.487917806654737

Epoch: 5| Step: 2
Training loss: 2.8073366877544035
Validation loss: 2.4682525438875973

Epoch: 5| Step: 3
Training loss: 2.6954104198415463
Validation loss: 2.4765809278655597

Epoch: 5| Step: 4
Training loss: 2.5849641656513183
Validation loss: 2.488167865503646

Epoch: 5| Step: 5
Training loss: 2.8179994856953745
Validation loss: 2.5304838342968665

Epoch: 5| Step: 6
Training loss: 2.332147489938284
Validation loss: 2.545371671791694

Epoch: 5| Step: 7
Training loss: 3.17574431338068
Validation loss: 2.555348858388915

Epoch: 5| Step: 8
Training loss: 2.5415045160151766
Validation loss: 2.5205708564283285

Epoch: 5| Step: 9
Training loss: 2.6255168405986913
Validation loss: 2.514443396892373

Epoch: 5| Step: 10
Training loss: 2.3781205807618475
Validation loss: 2.486490491392269

Epoch: 173| Step: 0
Training loss: 3.341869502836222
Validation loss: 2.4589189784637346

Epoch: 5| Step: 1
Training loss: 2.3612699667155574
Validation loss: 2.4538297365261657

Epoch: 5| Step: 2
Training loss: 2.914897073070375
Validation loss: 2.4458690205158855

Epoch: 5| Step: 3
Training loss: 2.2816719814523787
Validation loss: 2.446789487544864

Epoch: 5| Step: 4
Training loss: 2.3028167891051536
Validation loss: 2.4498934414350955

Epoch: 5| Step: 5
Training loss: 2.979077655734077
Validation loss: 2.457180898800343

Epoch: 5| Step: 6
Training loss: 2.8220227410895906
Validation loss: 2.4569746454669836

Epoch: 5| Step: 7
Training loss: 2.61626926085139
Validation loss: 2.465010105568202

Epoch: 5| Step: 8
Training loss: 2.297630341561149
Validation loss: 2.4579367973940776

Epoch: 5| Step: 9
Training loss: 2.920753794270514
Validation loss: 2.4591824233359496

Epoch: 5| Step: 10
Training loss: 3.1243845524329963
Validation loss: 2.4328874615124287

Epoch: 174| Step: 0
Training loss: 2.55572833868469
Validation loss: 2.4331779308426356

Epoch: 5| Step: 1
Training loss: 2.745056303659364
Validation loss: 2.4405986903638857

Epoch: 5| Step: 2
Training loss: 2.346056807484702
Validation loss: 2.44557830268588

Epoch: 5| Step: 3
Training loss: 2.8417300921061868
Validation loss: 2.4394634606576022

Epoch: 5| Step: 4
Training loss: 2.956312124877836
Validation loss: 2.434055809445618

Epoch: 5| Step: 5
Training loss: 3.123048707199275
Validation loss: 2.439674692569599

Epoch: 5| Step: 6
Training loss: 2.7647607174855424
Validation loss: 2.441130349203715

Epoch: 5| Step: 7
Training loss: 2.8654688535723882
Validation loss: 2.442408561263301

Epoch: 5| Step: 8
Training loss: 3.053489352519859
Validation loss: 2.4640757551900596

Epoch: 5| Step: 9
Training loss: 2.5737899863132268
Validation loss: 2.477717773395126

Epoch: 5| Step: 10
Training loss: 2.2969290798334248
Validation loss: 2.484091752577876

Epoch: 175| Step: 0
Training loss: 2.6577612672921656
Validation loss: 2.4922289622910734

Epoch: 5| Step: 1
Training loss: 2.254118435026966
Validation loss: 2.4878289041809247

Epoch: 5| Step: 2
Training loss: 2.7815169302757523
Validation loss: 2.4830617820473364

Epoch: 5| Step: 3
Training loss: 3.076381131275539
Validation loss: 2.486776056270765

Epoch: 5| Step: 4
Training loss: 2.749674170871791
Validation loss: 2.4826173029074305

Epoch: 5| Step: 5
Training loss: 2.429549529153875
Validation loss: 2.499538173882936

Epoch: 5| Step: 6
Training loss: 2.9468510906912155
Validation loss: 2.5024571362072825

Epoch: 5| Step: 7
Training loss: 2.471532292004772
Validation loss: 2.516325110095144

Epoch: 5| Step: 8
Training loss: 3.2542164667269593
Validation loss: 2.5170979585870166

Epoch: 5| Step: 9
Training loss: 2.631906234566739
Validation loss: 2.5067368602491906

Epoch: 5| Step: 10
Training loss: 2.978689960318077
Validation loss: 2.4750011860486345

Epoch: 176| Step: 0
Training loss: 2.4136729497084515
Validation loss: 2.464163639888039

Epoch: 5| Step: 1
Training loss: 2.7014791957880924
Validation loss: 2.4651226188026074

Epoch: 5| Step: 2
Training loss: 2.405061304338106
Validation loss: 2.4587927208833733

Epoch: 5| Step: 3
Training loss: 3.032610086705556
Validation loss: 2.462429919051683

Epoch: 5| Step: 4
Training loss: 2.979918662887757
Validation loss: 2.463576784976049

Epoch: 5| Step: 5
Training loss: 2.7111000210199934
Validation loss: 2.4666231110254646

Epoch: 5| Step: 6
Training loss: 3.205757362041336
Validation loss: 2.4670105353006746

Epoch: 5| Step: 7
Training loss: 2.634123433365838
Validation loss: 2.4581543190003954

Epoch: 5| Step: 8
Training loss: 3.0317284904441077
Validation loss: 2.4634605119794295

Epoch: 5| Step: 9
Training loss: 2.390734302290907
Validation loss: 2.4723213369578647

Epoch: 5| Step: 10
Training loss: 2.9209875707312927
Validation loss: 2.494416416851613

Epoch: 177| Step: 0
Training loss: 2.6199740478453326
Validation loss: 2.526703612801816

Epoch: 5| Step: 1
Training loss: 3.0544358562029426
Validation loss: 2.5822846874061054

Epoch: 5| Step: 2
Training loss: 2.219629032998176
Validation loss: 2.59179778253249

Epoch: 5| Step: 3
Training loss: 2.8633736755525234
Validation loss: 2.629671318589296

Epoch: 5| Step: 4
Training loss: 3.122918923758687
Validation loss: 2.5929757474988837

Epoch: 5| Step: 5
Training loss: 2.3169679523568156
Validation loss: 2.5717881479359574

Epoch: 5| Step: 6
Training loss: 3.0782219731116
Validation loss: 2.546627769245101

Epoch: 5| Step: 7
Training loss: 2.922574046349636
Validation loss: 2.511990912714792

Epoch: 5| Step: 8
Training loss: 2.2037375389954192
Validation loss: 2.4957852264467797

Epoch: 5| Step: 9
Training loss: 2.9136856285391475
Validation loss: 2.4779207446349774

Epoch: 5| Step: 10
Training loss: 2.8485579874793188
Validation loss: 2.467185891938596

Epoch: 178| Step: 0
Training loss: 2.3510337057614086
Validation loss: 2.476574915688563

Epoch: 5| Step: 1
Training loss: 3.0871713996264263
Validation loss: 2.4649617694862953

Epoch: 5| Step: 2
Training loss: 2.951625221115115
Validation loss: 2.470343616845322

Epoch: 5| Step: 3
Training loss: 2.944998565051728
Validation loss: 2.4704042206463646

Epoch: 5| Step: 4
Training loss: 2.7291149008309006
Validation loss: 2.481170475972444

Epoch: 5| Step: 5
Training loss: 2.5560053887885035
Validation loss: 2.4842979691117333

Epoch: 5| Step: 6
Training loss: 3.1412592764556933
Validation loss: 2.493198687125385

Epoch: 5| Step: 7
Training loss: 2.3997105503378595
Validation loss: 2.4785746998853297

Epoch: 5| Step: 8
Training loss: 2.9497844229341013
Validation loss: 2.472340948463177

Epoch: 5| Step: 9
Training loss: 2.823082321955792
Validation loss: 2.4804066278250603

Epoch: 5| Step: 10
Training loss: 2.6096154747443907
Validation loss: 2.4837693513053565

Epoch: 179| Step: 0
Training loss: 2.868085756879225
Validation loss: 2.5135506839611783

Epoch: 5| Step: 1
Training loss: 3.224119134116946
Validation loss: 2.5316996031416594

Epoch: 5| Step: 2
Training loss: 2.696570857326082
Validation loss: 2.5194677476065697

Epoch: 5| Step: 3
Training loss: 1.9337433111744595
Validation loss: 2.529767676857271

Epoch: 5| Step: 4
Training loss: 3.3434739043431216
Validation loss: 2.5429631508451678

Epoch: 5| Step: 5
Training loss: 3.169983398442163
Validation loss: 2.535164916275577

Epoch: 5| Step: 6
Training loss: 2.3543407972184105
Validation loss: 2.5342406225314513

Epoch: 5| Step: 7
Training loss: 2.2385164307073726
Validation loss: 2.5407944318520097

Epoch: 5| Step: 8
Training loss: 2.9795147530180395
Validation loss: 2.5318235291714126

Epoch: 5| Step: 9
Training loss: 2.4170979301363915
Validation loss: 2.521652362872573

Epoch: 5| Step: 10
Training loss: 2.540067127722451
Validation loss: 2.4972782649897836

Epoch: 180| Step: 0
Training loss: 2.5694038617019337
Validation loss: 2.492096703742081

Epoch: 5| Step: 1
Training loss: 3.1423034737618547
Validation loss: 2.497590249021091

Epoch: 5| Step: 2
Training loss: 3.2345181493363473
Validation loss: 2.4831993028317227

Epoch: 5| Step: 3
Training loss: 2.460691797010151
Validation loss: 2.493343057983085

Epoch: 5| Step: 4
Training loss: 2.7600691858548703
Validation loss: 2.508723845285015

Epoch: 5| Step: 5
Training loss: 2.472185569186681
Validation loss: 2.5121801186691646

Epoch: 5| Step: 6
Training loss: 2.61317295368959
Validation loss: 2.533300362635803

Epoch: 5| Step: 7
Training loss: 3.01696352332308
Validation loss: 2.5680468911258836

Epoch: 5| Step: 8
Training loss: 2.639250086999812
Validation loss: 2.566370027820013

Epoch: 5| Step: 9
Training loss: 2.5811104799115587
Validation loss: 2.531413429663101

Epoch: 5| Step: 10
Training loss: 2.7067715959301366
Validation loss: 2.514536957651657

Epoch: 181| Step: 0
Training loss: 2.62426038949223
Validation loss: 2.51728910164722

Epoch: 5| Step: 1
Training loss: 2.6764566501903033
Validation loss: 2.522203617257115

Epoch: 5| Step: 2
Training loss: 2.5450742007007876
Validation loss: 2.5272637815323242

Epoch: 5| Step: 3
Training loss: 2.1946211299776293
Validation loss: 2.550023277911579

Epoch: 5| Step: 4
Training loss: 3.3054873533363285
Validation loss: 2.5677903067897994

Epoch: 5| Step: 5
Training loss: 3.320194017876849
Validation loss: 2.5779922371617316

Epoch: 5| Step: 6
Training loss: 2.877091849220337
Validation loss: 2.6070275193794883

Epoch: 5| Step: 7
Training loss: 2.582451074954744
Validation loss: 2.6121708662556746

Epoch: 5| Step: 8
Training loss: 2.6509936215307053
Validation loss: 2.557660340527782

Epoch: 5| Step: 9
Training loss: 2.7454263627697455
Validation loss: 2.5309477382171885

Epoch: 5| Step: 10
Training loss: 2.3657596927731683
Validation loss: 2.501371341850037

Epoch: 182| Step: 0
Training loss: 2.5138482874430337
Validation loss: 2.443230911512978

Epoch: 5| Step: 1
Training loss: 2.7969723476751907
Validation loss: 2.4446821698074896

Epoch: 5| Step: 2
Training loss: 2.6542711853176417
Validation loss: 2.4372086278506377

Epoch: 5| Step: 3
Training loss: 2.691193371507871
Validation loss: 2.4449493307310726

Epoch: 5| Step: 4
Training loss: 3.1817106142067906
Validation loss: 2.4412071365377224

Epoch: 5| Step: 5
Training loss: 3.1352789627877633
Validation loss: 2.440283932222667

Epoch: 5| Step: 6
Training loss: 2.2788141911390705
Validation loss: 2.4409679146992302

Epoch: 5| Step: 7
Training loss: 2.5877091254159983
Validation loss: 2.4354923911021356

Epoch: 5| Step: 8
Training loss: 3.090917195855188
Validation loss: 2.4360827771425906

Epoch: 5| Step: 9
Training loss: 2.962617342270789
Validation loss: 2.436832832047521

Epoch: 5| Step: 10
Training loss: 2.786078301774626
Validation loss: 2.4423798923793396

Epoch: 183| Step: 0
Training loss: 2.703021979160402
Validation loss: 2.435988920967056

Epoch: 5| Step: 1
Training loss: 2.822494043524702
Validation loss: 2.439080527614615

Epoch: 5| Step: 2
Training loss: 3.346388444341506
Validation loss: 2.450381720588019

Epoch: 5| Step: 3
Training loss: 2.2044419485102815
Validation loss: 2.451720863750375

Epoch: 5| Step: 4
Training loss: 2.7162838855355433
Validation loss: 2.4758317808206565

Epoch: 5| Step: 5
Training loss: 2.593346437978445
Validation loss: 2.461806231961257

Epoch: 5| Step: 6
Training loss: 2.540941030593463
Validation loss: 2.4810330679909893

Epoch: 5| Step: 7
Training loss: 2.712164960992374
Validation loss: 2.486066380115935

Epoch: 5| Step: 8
Training loss: 2.761617051643692
Validation loss: 2.4818486614234887

Epoch: 5| Step: 9
Training loss: 2.8659470704775427
Validation loss: 2.4857536541381173

Epoch: 5| Step: 10
Training loss: 2.44762732777583
Validation loss: 2.4780574898063357

Epoch: 184| Step: 0
Training loss: 2.780121906681346
Validation loss: 2.485980019438094

Epoch: 5| Step: 1
Training loss: 2.608913540724582
Validation loss: 2.4933712241733237

Epoch: 5| Step: 2
Training loss: 2.6987740665156035
Validation loss: 2.500234328332169

Epoch: 5| Step: 3
Training loss: 2.4315583609641487
Validation loss: 2.5030232064670472

Epoch: 5| Step: 4
Training loss: 2.9462016658192747
Validation loss: 2.493957771336574

Epoch: 5| Step: 5
Training loss: 2.922605209088446
Validation loss: 2.498843352590083

Epoch: 5| Step: 6
Training loss: 2.2261343561087577
Validation loss: 2.4810529020213936

Epoch: 5| Step: 7
Training loss: 2.8178019246595367
Validation loss: 2.498352847404784

Epoch: 5| Step: 8
Training loss: 2.5198115229892015
Validation loss: 2.5035620549399717

Epoch: 5| Step: 9
Training loss: 2.956601473216054
Validation loss: 2.503079753910936

Epoch: 5| Step: 10
Training loss: 2.969423719555248
Validation loss: 2.5052583819207697

Epoch: 185| Step: 0
Training loss: 2.658778344896859
Validation loss: 2.494375351667903

Epoch: 5| Step: 1
Training loss: 2.8698506888650837
Validation loss: 2.4982082509133807

Epoch: 5| Step: 2
Training loss: 3.1650779319196096
Validation loss: 2.478954633575

Epoch: 5| Step: 3
Training loss: 2.6599814739872842
Validation loss: 2.4724292942244825

Epoch: 5| Step: 4
Training loss: 2.7583394614283168
Validation loss: 2.457145155236092

Epoch: 5| Step: 5
Training loss: 1.909646307467119
Validation loss: 2.4543474332597386

Epoch: 5| Step: 6
Training loss: 2.7435231664648287
Validation loss: 2.455594873680428

Epoch: 5| Step: 7
Training loss: 2.885925762191885
Validation loss: 2.456627491861696

Epoch: 5| Step: 8
Training loss: 2.8715697017275903
Validation loss: 2.467894729331964

Epoch: 5| Step: 9
Training loss: 2.729103281775026
Validation loss: 2.4573062313955965

Epoch: 5| Step: 10
Training loss: 2.35909405987239
Validation loss: 2.4723876699432292

Epoch: 186| Step: 0
Training loss: 2.476343572428611
Validation loss: 2.4704813921149804

Epoch: 5| Step: 1
Training loss: 1.9900013016931313
Validation loss: 2.4605222761588292

Epoch: 5| Step: 2
Training loss: 2.7407394889832504
Validation loss: 2.4876782372455795

Epoch: 5| Step: 3
Training loss: 3.087713189428924
Validation loss: 2.5002461589095417

Epoch: 5| Step: 4
Training loss: 2.3905766301466413
Validation loss: 2.494871555237598

Epoch: 5| Step: 5
Training loss: 2.600874159652509
Validation loss: 2.4922228428224793

Epoch: 5| Step: 6
Training loss: 2.7849937701883274
Validation loss: 2.492674642219937

Epoch: 5| Step: 7
Training loss: 2.668993729264921
Validation loss: 2.4980256313686926

Epoch: 5| Step: 8
Training loss: 3.3382303188946243
Validation loss: 2.4895849802412764

Epoch: 5| Step: 9
Training loss: 2.3913467414777125
Validation loss: 2.5162092409517434

Epoch: 5| Step: 10
Training loss: 2.993352359493198
Validation loss: 2.4956572827931676

Epoch: 187| Step: 0
Training loss: 2.9549761424900787
Validation loss: 2.493707653632616

Epoch: 5| Step: 1
Training loss: 2.8056065320796324
Validation loss: 2.5026922475619213

Epoch: 5| Step: 2
Training loss: 2.2229207556942265
Validation loss: 2.4999653239562787

Epoch: 5| Step: 3
Training loss: 2.6641111844891747
Validation loss: 2.4896233771209233

Epoch: 5| Step: 4
Training loss: 2.895782653218749
Validation loss: 2.4730978961129546

Epoch: 5| Step: 5
Training loss: 2.9676121187441082
Validation loss: 2.4572864717302205

Epoch: 5| Step: 6
Training loss: 2.1289638126535593
Validation loss: 2.4598821072041765

Epoch: 5| Step: 7
Training loss: 2.9266367579548875
Validation loss: 2.4505495726170454

Epoch: 5| Step: 8
Training loss: 2.842162978458161
Validation loss: 2.445232233961049

Epoch: 5| Step: 9
Training loss: 2.9787261388209583
Validation loss: 2.450375081784133

Epoch: 5| Step: 10
Training loss: 1.9722978020753892
Validation loss: 2.448380409636477

Epoch: 188| Step: 0
Training loss: 2.308082072036721
Validation loss: 2.4439294798722564

Epoch: 5| Step: 1
Training loss: 3.330676609526373
Validation loss: 2.4477663764208764

Epoch: 5| Step: 2
Training loss: 2.723800965839385
Validation loss: 2.4474590600778323

Epoch: 5| Step: 3
Training loss: 2.6580634714589575
Validation loss: 2.458961339511961

Epoch: 5| Step: 4
Training loss: 2.144154333125359
Validation loss: 2.466712102233208

Epoch: 5| Step: 5
Training loss: 3.0883569431654814
Validation loss: 2.468061372649065

Epoch: 5| Step: 6
Training loss: 2.6702457390615417
Validation loss: 2.4855887941610453

Epoch: 5| Step: 7
Training loss: 2.573523651885952
Validation loss: 2.4862984478450034

Epoch: 5| Step: 8
Training loss: 2.706022352550633
Validation loss: 2.5006053745350267

Epoch: 5| Step: 9
Training loss: 2.558468042445058
Validation loss: 2.4895819702913586

Epoch: 5| Step: 10
Training loss: 2.6876137288004793
Validation loss: 2.4853996835815053

Epoch: 189| Step: 0
Training loss: 2.0740274747023753
Validation loss: 2.4851727960545613

Epoch: 5| Step: 1
Training loss: 2.755741454804634
Validation loss: 2.4731991512452356

Epoch: 5| Step: 2
Training loss: 2.859093490667786
Validation loss: 2.474184592780657

Epoch: 5| Step: 3
Training loss: 3.219786097606992
Validation loss: 2.4723074450783695

Epoch: 5| Step: 4
Training loss: 2.6550309918277635
Validation loss: 2.4658630706579046

Epoch: 5| Step: 5
Training loss: 2.408297571710915
Validation loss: 2.4678437706390044

Epoch: 5| Step: 6
Training loss: 2.681755135710596
Validation loss: 2.4577770935215684

Epoch: 5| Step: 7
Training loss: 2.2362138344157567
Validation loss: 2.4560758150535436

Epoch: 5| Step: 8
Training loss: 2.44896233051406
Validation loss: 2.4647067735806543

Epoch: 5| Step: 9
Training loss: 3.0088397761264853
Validation loss: 2.4606637401702045

Epoch: 5| Step: 10
Training loss: 3.0876287147781007
Validation loss: 2.4676961429078257

Epoch: 190| Step: 0
Training loss: 2.6597089797559863
Validation loss: 2.4421946181755168

Epoch: 5| Step: 1
Training loss: 2.860146840467399
Validation loss: 2.4538723066186674

Epoch: 5| Step: 2
Training loss: 2.072799398149928
Validation loss: 2.4726625671912545

Epoch: 5| Step: 3
Training loss: 3.00768789058033
Validation loss: 2.483351273839046

Epoch: 5| Step: 4
Training loss: 2.505410157848713
Validation loss: 2.48169186975045

Epoch: 5| Step: 5
Training loss: 2.828877554397404
Validation loss: 2.4817694959572445

Epoch: 5| Step: 6
Training loss: 2.260941287804036
Validation loss: 2.4857278912976084

Epoch: 5| Step: 7
Training loss: 3.0725513478171758
Validation loss: 2.4928710177109332

Epoch: 5| Step: 8
Training loss: 2.7772912987586307
Validation loss: 2.479928049085122

Epoch: 5| Step: 9
Training loss: 2.5852272925438817
Validation loss: 2.4806754289285204

Epoch: 5| Step: 10
Training loss: 2.799086224088206
Validation loss: 2.481467491506296

Epoch: 191| Step: 0
Training loss: 2.2528329604425292
Validation loss: 2.479220820850851

Epoch: 5| Step: 1
Training loss: 2.5754111137714975
Validation loss: 2.4830061477799052

Epoch: 5| Step: 2
Training loss: 2.862274534183121
Validation loss: 2.492984010397996

Epoch: 5| Step: 3
Training loss: 2.703541541667742
Validation loss: 2.4756574735891785

Epoch: 5| Step: 4
Training loss: 2.9075749156218853
Validation loss: 2.463321989140091

Epoch: 5| Step: 5
Training loss: 2.7556452461826138
Validation loss: 2.4720607586702843

Epoch: 5| Step: 6
Training loss: 2.56851411650649
Validation loss: 2.4851867372276844

Epoch: 5| Step: 7
Training loss: 2.9211792142924335
Validation loss: 2.4791848014925906

Epoch: 5| Step: 8
Training loss: 2.690951238297441
Validation loss: 2.4862213352850593

Epoch: 5| Step: 9
Training loss: 2.5127051805820604
Validation loss: 2.488512052144844

Epoch: 5| Step: 10
Training loss: 2.78878278424918
Validation loss: 2.5033307130348

Epoch: 192| Step: 0
Training loss: 2.376866360211575
Validation loss: 2.487395417505982

Epoch: 5| Step: 1
Training loss: 2.3778875766291816
Validation loss: 2.4801989031904057

Epoch: 5| Step: 2
Training loss: 2.53839008524173
Validation loss: 2.4679048695240695

Epoch: 5| Step: 3
Training loss: 2.102097340421508
Validation loss: 2.4691530415026417

Epoch: 5| Step: 4
Training loss: 2.810842746327172
Validation loss: 2.4552535784235894

Epoch: 5| Step: 5
Training loss: 3.1877770396992924
Validation loss: 2.461664313152765

Epoch: 5| Step: 6
Training loss: 2.7456172350611516
Validation loss: 2.470288730824105

Epoch: 5| Step: 7
Training loss: 3.0969754754174135
Validation loss: 2.4579478125463443

Epoch: 5| Step: 8
Training loss: 2.8742411067971387
Validation loss: 2.4490744672280687

Epoch: 5| Step: 9
Training loss: 2.26783108347627
Validation loss: 2.459126447949334

Epoch: 5| Step: 10
Training loss: 2.9315187961340796
Validation loss: 2.458312997235056

Epoch: 193| Step: 0
Training loss: 2.9533471725288876
Validation loss: 2.4762131882731633

Epoch: 5| Step: 1
Training loss: 3.225283020375644
Validation loss: 2.484987713367922

Epoch: 5| Step: 2
Training loss: 2.5610999958277985
Validation loss: 2.5085556262781203

Epoch: 5| Step: 3
Training loss: 2.2153778239598467
Validation loss: 2.509154671998729

Epoch: 5| Step: 4
Training loss: 2.555189637464222
Validation loss: 2.507891165892009

Epoch: 5| Step: 5
Training loss: 3.2508053882072163
Validation loss: 2.522234553097241

Epoch: 5| Step: 6
Training loss: 2.714211194012117
Validation loss: 2.507941792325214

Epoch: 5| Step: 7
Training loss: 2.413920771811749
Validation loss: 2.499328914934506

Epoch: 5| Step: 8
Training loss: 2.629513447940586
Validation loss: 2.479345517020708

Epoch: 5| Step: 9
Training loss: 2.488685850488296
Validation loss: 2.4722592900371496

Epoch: 5| Step: 10
Training loss: 1.957327144586167
Validation loss: 2.4413371514499156

Epoch: 194| Step: 0
Training loss: 2.4289906965307644
Validation loss: 2.447869880628878

Epoch: 5| Step: 1
Training loss: 2.595418462364305
Validation loss: 2.435761144124186

Epoch: 5| Step: 2
Training loss: 2.4783681550580043
Validation loss: 2.4282046294663355

Epoch: 5| Step: 3
Training loss: 2.803713913786081
Validation loss: 2.434878744412299

Epoch: 5| Step: 4
Training loss: 2.089229999866
Validation loss: 2.4528331552944884

Epoch: 5| Step: 5
Training loss: 2.7187766589030615
Validation loss: 2.4595741226074885

Epoch: 5| Step: 6
Training loss: 2.19202782830443
Validation loss: 2.4657551814814007

Epoch: 5| Step: 7
Training loss: 3.1218482336170337
Validation loss: 2.4613271305523265

Epoch: 5| Step: 8
Training loss: 3.13290275767153
Validation loss: 2.4940534049916456

Epoch: 5| Step: 9
Training loss: 2.8420566086201666
Validation loss: 2.5041467167435676

Epoch: 5| Step: 10
Training loss: 2.9294623936955837
Validation loss: 2.5035193538908884

Epoch: 195| Step: 0
Training loss: 2.5060563162452816
Validation loss: 2.4877361995525167

Epoch: 5| Step: 1
Training loss: 2.5051643436453177
Validation loss: 2.493808588012103

Epoch: 5| Step: 2
Training loss: 2.9430261130903244
Validation loss: 2.487584650499052

Epoch: 5| Step: 3
Training loss: 2.9206995920280057
Validation loss: 2.477656824924475

Epoch: 5| Step: 4
Training loss: 2.5510290238760436
Validation loss: 2.4941102966216646

Epoch: 5| Step: 5
Training loss: 2.4472142828375834
Validation loss: 2.4951424824838204

Epoch: 5| Step: 6
Training loss: 2.8075364288656983
Validation loss: 2.5072315999872385

Epoch: 5| Step: 7
Training loss: 2.8347944157518086
Validation loss: 2.4760843068085316

Epoch: 5| Step: 8
Training loss: 2.772223666345105
Validation loss: 2.446650319726172

Epoch: 5| Step: 9
Training loss: 2.687642382021633
Validation loss: 2.4425592308542776

Epoch: 5| Step: 10
Training loss: 2.4075427855495546
Validation loss: 2.4318904754443724

Epoch: 196| Step: 0
Training loss: 2.6829312546518036
Validation loss: 2.4227968872835492

Epoch: 5| Step: 1
Training loss: 3.0154229131000236
Validation loss: 2.4408410678130776

Epoch: 5| Step: 2
Training loss: 2.823359737370356
Validation loss: 2.4289947842252295

Epoch: 5| Step: 3
Training loss: 2.836158260443816
Validation loss: 2.434828346628463

Epoch: 5| Step: 4
Training loss: 2.5601201985870468
Validation loss: 2.426784860559223

Epoch: 5| Step: 5
Training loss: 3.060618854350611
Validation loss: 2.4352270613826135

Epoch: 5| Step: 6
Training loss: 2.890872759124525
Validation loss: 2.4426870569256303

Epoch: 5| Step: 7
Training loss: 2.3241460195750174
Validation loss: 2.4562437779097457

Epoch: 5| Step: 8
Training loss: 2.4604356042023854
Validation loss: 2.4791451892110326

Epoch: 5| Step: 9
Training loss: 2.3101199506191836
Validation loss: 2.512050186214024

Epoch: 5| Step: 10
Training loss: 2.230026067572853
Validation loss: 2.529110575472927

Epoch: 197| Step: 0
Training loss: 3.048490907640179
Validation loss: 2.5430308288201995

Epoch: 5| Step: 1
Training loss: 2.9251758881203074
Validation loss: 2.509694485003066

Epoch: 5| Step: 2
Training loss: 2.7239342731607
Validation loss: 2.4924369772266246

Epoch: 5| Step: 3
Training loss: 2.0594227115273442
Validation loss: 2.469554030307322

Epoch: 5| Step: 4
Training loss: 2.5593936980033756
Validation loss: 2.4418275993094656

Epoch: 5| Step: 5
Training loss: 2.796515756050792
Validation loss: 2.436737681772913

Epoch: 5| Step: 6
Training loss: 2.859867741387699
Validation loss: 2.427670854818179

Epoch: 5| Step: 7
Training loss: 2.8111928657367393
Validation loss: 2.437705695741967

Epoch: 5| Step: 8
Training loss: 2.7043202133747557
Validation loss: 2.4391341231091332

Epoch: 5| Step: 9
Training loss: 2.762282425955867
Validation loss: 2.4331587970602673

Epoch: 5| Step: 10
Training loss: 2.2019309196550334
Validation loss: 2.440759009887356

Epoch: 198| Step: 0
Training loss: 2.4915851116123253
Validation loss: 2.443404768895432

Epoch: 5| Step: 1
Training loss: 2.404858967379297
Validation loss: 2.460438286690481

Epoch: 5| Step: 2
Training loss: 2.457130806123451
Validation loss: 2.4622643970154487

Epoch: 5| Step: 3
Training loss: 3.168338250790679
Validation loss: 2.463429298033031

Epoch: 5| Step: 4
Training loss: 2.429900819300694
Validation loss: 2.475607288774413

Epoch: 5| Step: 5
Training loss: 2.5729733871406126
Validation loss: 2.4893160423503136

Epoch: 5| Step: 6
Training loss: 3.0438389445944547
Validation loss: 2.5118210503670433

Epoch: 5| Step: 7
Training loss: 2.6820405021527898
Validation loss: 2.5052859981821585

Epoch: 5| Step: 8
Training loss: 2.5732399638273122
Validation loss: 2.5258440252246883

Epoch: 5| Step: 9
Training loss: 2.5422731728586943
Validation loss: 2.5166402327511515

Epoch: 5| Step: 10
Training loss: 2.939831072566839
Validation loss: 2.500606299272472

Epoch: 199| Step: 0
Training loss: 2.6866718169447736
Validation loss: 2.4965011107904633

Epoch: 5| Step: 1
Training loss: 2.6334222376177334
Validation loss: 2.469381818274812

Epoch: 5| Step: 2
Training loss: 2.7527900760537163
Validation loss: 2.4613292579549255

Epoch: 5| Step: 3
Training loss: 3.0269970504600185
Validation loss: 2.4484595306643167

Epoch: 5| Step: 4
Training loss: 2.6251496771873253
Validation loss: 2.437357638324365

Epoch: 5| Step: 5
Training loss: 2.9220248097248356
Validation loss: 2.430631249260443

Epoch: 5| Step: 6
Training loss: 2.4055932870401406
Validation loss: 2.456477030803699

Epoch: 5| Step: 7
Training loss: 2.892183780513208
Validation loss: 2.4535899043440152

Epoch: 5| Step: 8
Training loss: 2.5223873067130547
Validation loss: 2.449613906393297

Epoch: 5| Step: 9
Training loss: 2.252864074413004
Validation loss: 2.4416846111472155

Epoch: 5| Step: 10
Training loss: 2.3870372903034154
Validation loss: 2.4551559755560692

Epoch: 200| Step: 0
Training loss: 2.88246876391172
Validation loss: 2.444263209929755

Epoch: 5| Step: 1
Training loss: 2.6495670396768034
Validation loss: 2.4397479225928946

Epoch: 5| Step: 2
Training loss: 2.515477430860726
Validation loss: 2.4467314591967884

Epoch: 5| Step: 3
Training loss: 2.3407449403802048
Validation loss: 2.445642343114659

Epoch: 5| Step: 4
Training loss: 2.6511254637739063
Validation loss: 2.467390881288653

Epoch: 5| Step: 5
Training loss: 2.66271956707027
Validation loss: 2.479430096691304

Epoch: 5| Step: 6
Training loss: 2.2421033889997384
Validation loss: 2.4789978156665877

Epoch: 5| Step: 7
Training loss: 2.7430201296121615
Validation loss: 2.4932875410524744

Epoch: 5| Step: 8
Training loss: 2.4144849685324288
Validation loss: 2.4743372645864565

Epoch: 5| Step: 9
Training loss: 3.107484789294751
Validation loss: 2.489357248664973

Epoch: 5| Step: 10
Training loss: 2.900713497390825
Validation loss: 2.4522928843960754

Epoch: 201| Step: 0
Training loss: 3.0144602052912672
Validation loss: 2.442584666038367

Epoch: 5| Step: 1
Training loss: 2.693937354420748
Validation loss: 2.44276839520759

Epoch: 5| Step: 2
Training loss: 2.7759648372665815
Validation loss: 2.44649909312386

Epoch: 5| Step: 3
Training loss: 2.863414308545023
Validation loss: 2.40868347858079

Epoch: 5| Step: 4
Training loss: 2.7154396336265014
Validation loss: 2.4423840888708384

Epoch: 5| Step: 5
Training loss: 2.6719195267385847
Validation loss: 2.4475698710217952

Epoch: 5| Step: 6
Training loss: 2.1699052839220028
Validation loss: 2.4822549089060435

Epoch: 5| Step: 7
Training loss: 1.8003848750526876
Validation loss: 2.5296649403583915

Epoch: 5| Step: 8
Training loss: 2.9428576046153645
Validation loss: 2.5739814641095653

Epoch: 5| Step: 9
Training loss: 2.717653952469132
Validation loss: 2.5442073038773656

Epoch: 5| Step: 10
Training loss: 2.8418124798218463
Validation loss: 2.500599532893018

Epoch: 202| Step: 0
Training loss: 2.4312032896129447
Validation loss: 2.45459797199198

Epoch: 5| Step: 1
Training loss: 2.321781502608657
Validation loss: 2.4313765377346956

Epoch: 5| Step: 2
Training loss: 1.8528396129377638
Validation loss: 2.423245996540253

Epoch: 5| Step: 3
Training loss: 2.0832551432877615
Validation loss: 2.4183842534272926

Epoch: 5| Step: 4
Training loss: 2.8500229951700473
Validation loss: 2.4238606982296482

Epoch: 5| Step: 5
Training loss: 3.0573880875225194
Validation loss: 2.428431303536536

Epoch: 5| Step: 6
Training loss: 2.8873992241782496
Validation loss: 2.405351954641927

Epoch: 5| Step: 7
Training loss: 2.7316233713638045
Validation loss: 2.41165434954664

Epoch: 5| Step: 8
Training loss: 3.013092717154248
Validation loss: 2.4276510123406423

Epoch: 5| Step: 9
Training loss: 2.817761480049965
Validation loss: 2.4282298798063295

Epoch: 5| Step: 10
Training loss: 3.1080224243886865
Validation loss: 2.458551851477713

Epoch: 203| Step: 0
Training loss: 2.702059761911216
Validation loss: 2.484264437103076

Epoch: 5| Step: 1
Training loss: 2.217161012562561
Validation loss: 2.517095378748979

Epoch: 5| Step: 2
Training loss: 2.6968735749029857
Validation loss: 2.550065436499819

Epoch: 5| Step: 3
Training loss: 2.984802854535679
Validation loss: 2.528295103055246

Epoch: 5| Step: 4
Training loss: 2.4339542519902158
Validation loss: 2.5401416549411326

Epoch: 5| Step: 5
Training loss: 2.4473367423450596
Validation loss: 2.505843166632384

Epoch: 5| Step: 6
Training loss: 2.8288306941762134
Validation loss: 2.481762069788081

Epoch: 5| Step: 7
Training loss: 3.2147872382164753
Validation loss: 2.4937647926791757

Epoch: 5| Step: 8
Training loss: 2.4683537225527243
Validation loss: 2.475542179135239

Epoch: 5| Step: 9
Training loss: 2.840493486001782
Validation loss: 2.488553720927678

Epoch: 5| Step: 10
Training loss: 2.572553312974428
Validation loss: 2.4825230823549087

Epoch: 204| Step: 0
Training loss: 3.158051533738184
Validation loss: 2.4577035338780826

Epoch: 5| Step: 1
Training loss: 3.1414978939901164
Validation loss: 2.476227763281011

Epoch: 5| Step: 2
Training loss: 2.558106913368675
Validation loss: 2.467059569037313

Epoch: 5| Step: 3
Training loss: 2.139621694407267
Validation loss: 2.4547938437789343

Epoch: 5| Step: 4
Training loss: 2.760250926290294
Validation loss: 2.4785498874465373

Epoch: 5| Step: 5
Training loss: 2.3388846187698555
Validation loss: 2.4681173874148468

Epoch: 5| Step: 6
Training loss: 2.6184963312857223
Validation loss: 2.466087103509073

Epoch: 5| Step: 7
Training loss: 2.37845991986907
Validation loss: 2.4840750172312296

Epoch: 5| Step: 8
Training loss: 2.8024011500243784
Validation loss: 2.4821062492228507

Epoch: 5| Step: 9
Training loss: 2.644176555157804
Validation loss: 2.470074445940992

Epoch: 5| Step: 10
Training loss: 2.535921942192486
Validation loss: 2.4621352050100223

Epoch: 205| Step: 0
Training loss: 2.931767978735721
Validation loss: 2.461284753975947

Epoch: 5| Step: 1
Training loss: 2.472472752034287
Validation loss: 2.4472725576964436

Epoch: 5| Step: 2
Training loss: 2.740629704644266
Validation loss: 2.4333201219512204

Epoch: 5| Step: 3
Training loss: 2.2819241089500695
Validation loss: 2.442565724544718

Epoch: 5| Step: 4
Training loss: 2.7456586555486657
Validation loss: 2.4416420553545386

Epoch: 5| Step: 5
Training loss: 3.1821759208611633
Validation loss: 2.4266176530036616

Epoch: 5| Step: 6
Training loss: 2.5118630280296
Validation loss: 2.443153792193247

Epoch: 5| Step: 7
Training loss: 2.6119625944231144
Validation loss: 2.436116347255053

Epoch: 5| Step: 8
Training loss: 2.6947634815049057
Validation loss: 2.4410018125190756

Epoch: 5| Step: 9
Training loss: 2.6969709076519885
Validation loss: 2.421946761291727

Epoch: 5| Step: 10
Training loss: 2.0891044663841165
Validation loss: 2.4245328357434097

Epoch: 206| Step: 0
Training loss: 1.9709565649022307
Validation loss: 2.4371819205792002

Epoch: 5| Step: 1
Training loss: 2.4525737750577106
Validation loss: 2.438121240044531

Epoch: 5| Step: 2
Training loss: 2.9039280958074905
Validation loss: 2.441903241374998

Epoch: 5| Step: 3
Training loss: 3.1568080295489627
Validation loss: 2.460148237514008

Epoch: 5| Step: 4
Training loss: 2.7215745657174732
Validation loss: 2.4668135082828027

Epoch: 5| Step: 5
Training loss: 1.5458393676036815
Validation loss: 2.496906155564063

Epoch: 5| Step: 6
Training loss: 3.0243202517639385
Validation loss: 2.505734517834856

Epoch: 5| Step: 7
Training loss: 3.031137523334065
Validation loss: 2.5115474448008843

Epoch: 5| Step: 8
Training loss: 2.708910621348657
Validation loss: 2.502643985723247

Epoch: 5| Step: 9
Training loss: 2.4160896357777775
Validation loss: 2.4762999796367033

Epoch: 5| Step: 10
Training loss: 2.8629907978534876
Validation loss: 2.474924823633956

Epoch: 207| Step: 0
Training loss: 2.728042594303063
Validation loss: 2.4569767322931964

Epoch: 5| Step: 1
Training loss: 2.842739554504361
Validation loss: 2.4444929726700533

Epoch: 5| Step: 2
Training loss: 2.5569057341719037
Validation loss: 2.430275664809413

Epoch: 5| Step: 3
Training loss: 2.585547841382109
Validation loss: 2.422036513368925

Epoch: 5| Step: 4
Training loss: 2.3140270243313794
Validation loss: 2.422791748985662

Epoch: 5| Step: 5
Training loss: 2.5799558669758698
Validation loss: 2.4211404555154488

Epoch: 5| Step: 6
Training loss: 1.9880129889864055
Validation loss: 2.4253589670175724

Epoch: 5| Step: 7
Training loss: 3.123257265525092
Validation loss: 2.4283832855641934

Epoch: 5| Step: 8
Training loss: 3.216424342566235
Validation loss: 2.442740420588963

Epoch: 5| Step: 9
Training loss: 2.4169751222566744
Validation loss: 2.4461380472758565

Epoch: 5| Step: 10
Training loss: 2.6063038003980816
Validation loss: 2.468768690751646

Epoch: 208| Step: 0
Training loss: 2.6868604741898436
Validation loss: 2.4644654846045317

Epoch: 5| Step: 1
Training loss: 2.81753885508082
Validation loss: 2.490383747727258

Epoch: 5| Step: 2
Training loss: 2.619508903719833
Validation loss: 2.534857567970989

Epoch: 5| Step: 3
Training loss: 2.825527705639804
Validation loss: 2.5071610230775763

Epoch: 5| Step: 4
Training loss: 2.7127072936276924
Validation loss: 2.488014459695308

Epoch: 5| Step: 5
Training loss: 2.2738577857325044
Validation loss: 2.4514257051451622

Epoch: 5| Step: 6
Training loss: 2.6491892600098548
Validation loss: 2.429864875959123

Epoch: 5| Step: 7
Training loss: 2.3170389530363305
Validation loss: 2.4459011807288076

Epoch: 5| Step: 8
Training loss: 2.9953255793883384
Validation loss: 2.431813204168275

Epoch: 5| Step: 9
Training loss: 2.907853207310946
Validation loss: 2.454795618112806

Epoch: 5| Step: 10
Training loss: 2.283119271911069
Validation loss: 2.4453789208808634

Epoch: 209| Step: 0
Training loss: 2.8484125166575276
Validation loss: 2.4349376545678716

Epoch: 5| Step: 1
Training loss: 3.046513619143761
Validation loss: 2.430686604667827

Epoch: 5| Step: 2
Training loss: 2.595994277136656
Validation loss: 2.430810017037435

Epoch: 5| Step: 3
Training loss: 2.79061034605615
Validation loss: 2.4591057427590597

Epoch: 5| Step: 4
Training loss: 2.674368247183886
Validation loss: 2.4889185340453075

Epoch: 5| Step: 5
Training loss: 2.1917976669013672
Validation loss: 2.512802076926887

Epoch: 5| Step: 6
Training loss: 2.9406894656502294
Validation loss: 2.5438673639707186

Epoch: 5| Step: 7
Training loss: 2.29527901974976
Validation loss: 2.5778124050783275

Epoch: 5| Step: 8
Training loss: 2.4347126992182004
Validation loss: 2.5755203170590875

Epoch: 5| Step: 9
Training loss: 2.785042737704807
Validation loss: 2.573703093844464

Epoch: 5| Step: 10
Training loss: 2.102452653313227
Validation loss: 2.5706596630036174

Epoch: 210| Step: 0
Training loss: 2.3705817837224368
Validation loss: 2.526154254771891

Epoch: 5| Step: 1
Training loss: 2.577448993255869
Validation loss: 2.4848831553791983

Epoch: 5| Step: 2
Training loss: 2.8404634368912265
Validation loss: 2.476435650206535

Epoch: 5| Step: 3
Training loss: 2.2998432520651977
Validation loss: 2.4490735565298447

Epoch: 5| Step: 4
Training loss: 2.589786120387749
Validation loss: 2.439684125695074

Epoch: 5| Step: 5
Training loss: 2.7847369334486847
Validation loss: 2.4449192949605334

Epoch: 5| Step: 6
Training loss: 2.6276185735049844
Validation loss: 2.435487097485611

Epoch: 5| Step: 7
Training loss: 3.0708967046181432
Validation loss: 2.437016879137915

Epoch: 5| Step: 8
Training loss: 2.8064970591652196
Validation loss: 2.4338247390744328

Epoch: 5| Step: 9
Training loss: 2.4725056341741567
Validation loss: 2.4637839975075457

Epoch: 5| Step: 10
Training loss: 2.300494708885272
Validation loss: 2.4734778108012563

Epoch: 211| Step: 0
Training loss: 2.5329456066100042
Validation loss: 2.501757021772791

Epoch: 5| Step: 1
Training loss: 2.4408401687472527
Validation loss: 2.515100980841969

Epoch: 5| Step: 2
Training loss: 2.7490313297788576
Validation loss: 2.5241515665797016

Epoch: 5| Step: 3
Training loss: 2.2923411561604015
Validation loss: 2.4973569988854267

Epoch: 5| Step: 4
Training loss: 2.6255109380560673
Validation loss: 2.478269666721554

Epoch: 5| Step: 5
Training loss: 2.908175251188617
Validation loss: 2.4520999838008044

Epoch: 5| Step: 6
Training loss: 2.535111578267102
Validation loss: 2.4429871236304073

Epoch: 5| Step: 7
Training loss: 2.597362805764587
Validation loss: 2.437767304434844

Epoch: 5| Step: 8
Training loss: 2.4757700714311572
Validation loss: 2.4375313808628767

Epoch: 5| Step: 9
Training loss: 3.006098112524204
Validation loss: 2.423295209135389

Epoch: 5| Step: 10
Training loss: 2.3755598914084355
Validation loss: 2.424494318434902

Epoch: 212| Step: 0
Training loss: 2.4339393627478074
Validation loss: 2.444477889626747

Epoch: 5| Step: 1
Training loss: 3.0620537257548537
Validation loss: 2.438895769056845

Epoch: 5| Step: 2
Training loss: 2.3951179320859866
Validation loss: 2.476937885068286

Epoch: 5| Step: 3
Training loss: 2.974080009220518
Validation loss: 2.486438212581869

Epoch: 5| Step: 4
Training loss: 2.5436171775838936
Validation loss: 2.4753345216612956

Epoch: 5| Step: 5
Training loss: 2.665463523848442
Validation loss: 2.442515582982533

Epoch: 5| Step: 6
Training loss: 2.338615489947109
Validation loss: 2.4401623259124463

Epoch: 5| Step: 7
Training loss: 2.6454607683732436
Validation loss: 2.417802877374408

Epoch: 5| Step: 8
Training loss: 2.737183964571655
Validation loss: 2.3977155406837523

Epoch: 5| Step: 9
Training loss: 2.3182665092039207
Validation loss: 2.408363752034271

Epoch: 5| Step: 10
Training loss: 2.2769275631781096
Validation loss: 2.4108446381673994

Epoch: 213| Step: 0
Training loss: 3.160498149092171
Validation loss: 2.426134086445614

Epoch: 5| Step: 1
Training loss: 2.821750601796735
Validation loss: 2.4097860154349684

Epoch: 5| Step: 2
Training loss: 2.2941514040763393
Validation loss: 2.4120451478684397

Epoch: 5| Step: 3
Training loss: 2.7162328884746154
Validation loss: 2.4361900688608804

Epoch: 5| Step: 4
Training loss: 2.028206408355372
Validation loss: 2.45571486600141

Epoch: 5| Step: 5
Training loss: 2.826978250760596
Validation loss: 2.485396651027781

Epoch: 5| Step: 6
Training loss: 2.668074286008619
Validation loss: 2.4868287856929974

Epoch: 5| Step: 7
Training loss: 1.8724206348911199
Validation loss: 2.4574518043202604

Epoch: 5| Step: 8
Training loss: 3.2046177804878
Validation loss: 2.4439174584967702

Epoch: 5| Step: 9
Training loss: 2.463589066310874
Validation loss: 2.442974167855526

Epoch: 5| Step: 10
Training loss: 2.0611134116384733
Validation loss: 2.44263506856719

Epoch: 214| Step: 0
Training loss: 2.127154212042249
Validation loss: 2.4592462762962324

Epoch: 5| Step: 1
Training loss: 2.7665919106123553
Validation loss: 2.468627581891333

Epoch: 5| Step: 2
Training loss: 2.8239457247762276
Validation loss: 2.465497118062148

Epoch: 5| Step: 3
Training loss: 2.135673867220008
Validation loss: 2.4573190323189262

Epoch: 5| Step: 4
Training loss: 2.5807620346999323
Validation loss: 2.459912309403425

Epoch: 5| Step: 5
Training loss: 2.118503513458414
Validation loss: 2.4345565000545615

Epoch: 5| Step: 6
Training loss: 2.95359871107592
Validation loss: 2.434929691798972

Epoch: 5| Step: 7
Training loss: 2.5686772022930553
Validation loss: 2.436373493179831

Epoch: 5| Step: 8
Training loss: 2.3998973268163484
Validation loss: 2.4349631388330404

Epoch: 5| Step: 9
Training loss: 3.129774642241556
Validation loss: 2.429346647405448

Epoch: 5| Step: 10
Training loss: 2.6815758993918517
Validation loss: 2.4299169423563773

Epoch: 215| Step: 0
Training loss: 2.4543465652547787
Validation loss: 2.4383693456319944

Epoch: 5| Step: 1
Training loss: 2.825169910958871
Validation loss: 2.4517314284470895

Epoch: 5| Step: 2
Training loss: 2.52461578920787
Validation loss: 2.472368837533119

Epoch: 5| Step: 3
Training loss: 2.5205648505205995
Validation loss: 2.489536797436151

Epoch: 5| Step: 4
Training loss: 2.6046197013978665
Validation loss: 2.520611411441525

Epoch: 5| Step: 5
Training loss: 2.532438211242716
Validation loss: 2.5874295112972265

Epoch: 5| Step: 6
Training loss: 2.8399886523275266
Validation loss: 2.587314187828256

Epoch: 5| Step: 7
Training loss: 2.1988104378535613
Validation loss: 2.5533884802533002

Epoch: 5| Step: 8
Training loss: 2.702847505118499
Validation loss: 2.5379069076563985

Epoch: 5| Step: 9
Training loss: 2.2144905360371263
Validation loss: 2.482672032025722

Epoch: 5| Step: 10
Training loss: 3.1388620771165074
Validation loss: 2.4644818766842898

Epoch: 216| Step: 0
Training loss: 2.597967097678278
Validation loss: 2.4355501590892827

Epoch: 5| Step: 1
Training loss: 2.0235682853938624
Validation loss: 2.4284549696026265

Epoch: 5| Step: 2
Training loss: 3.0122377020266415
Validation loss: 2.4389797932345276

Epoch: 5| Step: 3
Training loss: 2.617183309523231
Validation loss: 2.43216901074966

Epoch: 5| Step: 4
Training loss: 2.4027391061874246
Validation loss: 2.449764816183233

Epoch: 5| Step: 5
Training loss: 2.5080574842919647
Validation loss: 2.434426405234386

Epoch: 5| Step: 6
Training loss: 2.7817250392572523
Validation loss: 2.4422743626278054

Epoch: 5| Step: 7
Training loss: 2.97809855558457
Validation loss: 2.4438512538552213

Epoch: 5| Step: 8
Training loss: 2.546026825822705
Validation loss: 2.4441018479358703

Epoch: 5| Step: 9
Training loss: 2.5435072274545005
Validation loss: 2.498934725968985

Epoch: 5| Step: 10
Training loss: 2.208333129402967
Validation loss: 2.509858137484339

Epoch: 217| Step: 0
Training loss: 2.964624047463329
Validation loss: 2.506770403573167

Epoch: 5| Step: 1
Training loss: 2.073223327752184
Validation loss: 2.4854742533260192

Epoch: 5| Step: 2
Training loss: 2.7564496787612445
Validation loss: 2.4787938937377216

Epoch: 5| Step: 3
Training loss: 2.746685024110625
Validation loss: 2.426092876740502

Epoch: 5| Step: 4
Training loss: 2.4005076268906653
Validation loss: 2.4028355947755657

Epoch: 5| Step: 5
Training loss: 2.429619791246583
Validation loss: 2.392077826033962

Epoch: 5| Step: 6
Training loss: 2.344109876342345
Validation loss: 2.400526277631714

Epoch: 5| Step: 7
Training loss: 2.8181453420006815
Validation loss: 2.3966199085704383

Epoch: 5| Step: 8
Training loss: 2.7477936997470587
Validation loss: 2.4151274864757664

Epoch: 5| Step: 9
Training loss: 2.103215358204447
Validation loss: 2.4192387571139773

Epoch: 5| Step: 10
Training loss: 2.972893644019635
Validation loss: 2.4454413531446604

Epoch: 218| Step: 0
Training loss: 2.8726149908012344
Validation loss: 2.451682520529923

Epoch: 5| Step: 1
Training loss: 2.3415649401016787
Validation loss: 2.53308753198494

Epoch: 5| Step: 2
Training loss: 2.9784138046120967
Validation loss: 2.5816348380650482

Epoch: 5| Step: 3
Training loss: 2.813218512414222
Validation loss: 2.653175464394031

Epoch: 5| Step: 4
Training loss: 2.224503592503897
Validation loss: 2.6659417307852307

Epoch: 5| Step: 5
Training loss: 2.698650559770568
Validation loss: 2.6328160726019645

Epoch: 5| Step: 6
Training loss: 2.5516049514107713
Validation loss: 2.5423519048662024

Epoch: 5| Step: 7
Training loss: 2.5029605501901355
Validation loss: 2.483059685137639

Epoch: 5| Step: 8
Training loss: 2.1960008295540554
Validation loss: 2.425845168405724

Epoch: 5| Step: 9
Training loss: 2.5333469323579627
Validation loss: 2.3896742105675086

Epoch: 5| Step: 10
Training loss: 2.525889053191609
Validation loss: 2.3978319439449707

Epoch: 219| Step: 0
Training loss: 2.5771716580459674
Validation loss: 2.392792879821149

Epoch: 5| Step: 1
Training loss: 2.8267928721785944
Validation loss: 2.393111673231326

Epoch: 5| Step: 2
Training loss: 2.238219361839372
Validation loss: 2.389553008001675

Epoch: 5| Step: 3
Training loss: 2.9202964721043907
Validation loss: 2.3876742509364757

Epoch: 5| Step: 4
Training loss: 2.5183253041443825
Validation loss: 2.3917191658490777

Epoch: 5| Step: 5
Training loss: 2.782087907050853
Validation loss: 2.3870661577535626

Epoch: 5| Step: 6
Training loss: 2.534829140647912
Validation loss: 2.393406228627446

Epoch: 5| Step: 7
Training loss: 2.8249246604123117
Validation loss: 2.3919720533819304

Epoch: 5| Step: 8
Training loss: 2.5505527084339494
Validation loss: 2.4252439420394807

Epoch: 5| Step: 9
Training loss: 2.6365721711282846
Validation loss: 2.4648717015363255

Epoch: 5| Step: 10
Training loss: 2.1328509540374996
Validation loss: 2.4900233499066626

Epoch: 220| Step: 0
Training loss: 2.907275275404367
Validation loss: 2.52360405348953

Epoch: 5| Step: 1
Training loss: 2.370310822236706
Validation loss: 2.511617690225891

Epoch: 5| Step: 2
Training loss: 2.5136872404469184
Validation loss: 2.5316394125050445

Epoch: 5| Step: 3
Training loss: 2.6138596970804935
Validation loss: 2.5181147364680676

Epoch: 5| Step: 4
Training loss: 2.7295921129964675
Validation loss: 2.51894650431826

Epoch: 5| Step: 5
Training loss: 2.6171709202483235
Validation loss: 2.529660069804762

Epoch: 5| Step: 6
Training loss: 2.1658759385962947
Validation loss: 2.5107460655164933

Epoch: 5| Step: 7
Training loss: 2.426244031219766
Validation loss: 2.5034229553865894

Epoch: 5| Step: 8
Training loss: 2.6241104798668204
Validation loss: 2.4928720646105123

Epoch: 5| Step: 9
Training loss: 2.493788632354171
Validation loss: 2.4695772628451986

Epoch: 5| Step: 10
Training loss: 2.6830364687016113
Validation loss: 2.4734602366613747

Epoch: 221| Step: 0
Training loss: 2.667047344295306
Validation loss: 2.453006557857739

Epoch: 5| Step: 1
Training loss: 2.2320481569092463
Validation loss: 2.437565919643656

Epoch: 5| Step: 2
Training loss: 2.194392761662721
Validation loss: 2.438046689881358

Epoch: 5| Step: 3
Training loss: 2.536057416392279
Validation loss: 2.440564109417983

Epoch: 5| Step: 4
Training loss: 2.868402956247462
Validation loss: 2.4335018147111667

Epoch: 5| Step: 5
Training loss: 2.616252584150836
Validation loss: 2.438965746134913

Epoch: 5| Step: 6
Training loss: 2.8334453971990867
Validation loss: 2.4384660460353476

Epoch: 5| Step: 7
Training loss: 2.5013924535537315
Validation loss: 2.4424094240641705

Epoch: 5| Step: 8
Training loss: 2.4435693542367165
Validation loss: 2.4418277830395105

Epoch: 5| Step: 9
Training loss: 2.6365818468509645
Validation loss: 2.4680333357047592

Epoch: 5| Step: 10
Training loss: 2.1819791608002364
Validation loss: 2.522874532706979

Epoch: 222| Step: 0
Training loss: 2.968013631948747
Validation loss: 2.5690944136844482

Epoch: 5| Step: 1
Training loss: 2.6739124761279447
Validation loss: 2.5777144427410796

Epoch: 5| Step: 2
Training loss: 2.950297621891605
Validation loss: 2.510214133184244

Epoch: 5| Step: 3
Training loss: 1.8053917769791101
Validation loss: 2.4506016954037286

Epoch: 5| Step: 4
Training loss: 2.6241317402984734
Validation loss: 2.4119973021672285

Epoch: 5| Step: 5
Training loss: 2.2692490630425803
Validation loss: 2.404450476009798

Epoch: 5| Step: 6
Training loss: 2.9149219380783307
Validation loss: 2.3886024572939486

Epoch: 5| Step: 7
Training loss: 2.6082695543903003
Validation loss: 2.3803703430864545

Epoch: 5| Step: 8
Training loss: 2.5430484413516456
Validation loss: 2.3871723528991944

Epoch: 5| Step: 9
Training loss: 2.449407883540418
Validation loss: 2.3888856631511035

Epoch: 5| Step: 10
Training loss: 1.8191466957402194
Validation loss: 2.4128995359350998

Epoch: 223| Step: 0
Training loss: 2.7348923547960307
Validation loss: 2.4338320618707705

Epoch: 5| Step: 1
Training loss: 3.223993123513359
Validation loss: 2.4739373909668876

Epoch: 5| Step: 2
Training loss: 1.8625575805570422
Validation loss: 2.500275192701473

Epoch: 5| Step: 3
Training loss: 2.451212435079013
Validation loss: 2.548699609224873

Epoch: 5| Step: 4
Training loss: 2.29405558366958
Validation loss: 2.550840653282436

Epoch: 5| Step: 5
Training loss: 2.6972431731618967
Validation loss: 2.581500997002187

Epoch: 5| Step: 6
Training loss: 2.4636356155729646
Validation loss: 2.5648255739055927

Epoch: 5| Step: 7
Training loss: 2.483625766851372
Validation loss: 2.50765324906264

Epoch: 5| Step: 8
Training loss: 2.4425189847022897
Validation loss: 2.4634839081308177

Epoch: 5| Step: 9
Training loss: 2.250804863130269
Validation loss: 2.4426366481227926

Epoch: 5| Step: 10
Training loss: 2.6843503193725438
Validation loss: 2.4244887848324663

Epoch: 224| Step: 0
Training loss: 2.773928660569378
Validation loss: 2.4093673014952404

Epoch: 5| Step: 1
Training loss: 2.4126258698670333
Validation loss: 2.3916370261237407

Epoch: 5| Step: 2
Training loss: 2.324420516288253
Validation loss: 2.4084360340576407

Epoch: 5| Step: 3
Training loss: 2.849329745800787
Validation loss: 2.4165023621266375

Epoch: 5| Step: 4
Training loss: 2.3968059942664555
Validation loss: 2.454457294513952

Epoch: 5| Step: 5
Training loss: 2.075082372845825
Validation loss: 2.4659432567096067

Epoch: 5| Step: 6
Training loss: 3.067270417144476
Validation loss: 2.539266033234342

Epoch: 5| Step: 7
Training loss: 1.9260133057963578
Validation loss: 2.5565325275613797

Epoch: 5| Step: 8
Training loss: 2.605079267178112
Validation loss: 2.5381368646424365

Epoch: 5| Step: 9
Training loss: 2.9969248905742787
Validation loss: 2.528884248044363

Epoch: 5| Step: 10
Training loss: 2.0547645467374838
Validation loss: 2.4613812842239766

Epoch: 225| Step: 0
Training loss: 3.0316067515180145
Validation loss: 2.4061133787131936

Epoch: 5| Step: 1
Training loss: 2.3640483525490117
Validation loss: 2.382388534767115

Epoch: 5| Step: 2
Training loss: 2.296777217107043
Validation loss: 2.3775318038012467

Epoch: 5| Step: 3
Training loss: 2.6758439773669425
Validation loss: 2.3788346672943788

Epoch: 5| Step: 4
Training loss: 2.176461953978401
Validation loss: 2.3726007262689475

Epoch: 5| Step: 5
Training loss: 2.5430437536942074
Validation loss: 2.3786862796318555

Epoch: 5| Step: 6
Training loss: 2.275095436693422
Validation loss: 2.405244011563429

Epoch: 5| Step: 7
Training loss: 2.164167270809653
Validation loss: 2.41700709310497

Epoch: 5| Step: 8
Training loss: 2.5459556558527496
Validation loss: 2.436509620344062

Epoch: 5| Step: 9
Training loss: 2.922142954896721
Validation loss: 2.47230910107497

Epoch: 5| Step: 10
Training loss: 2.487825312979758
Validation loss: 2.5412435483702556

Epoch: 226| Step: 0
Training loss: 3.2093539080349247
Validation loss: 2.5440799090124835

Epoch: 5| Step: 1
Training loss: 3.007092833191899
Validation loss: 2.541739852257756

Epoch: 5| Step: 2
Training loss: 2.2387557400577127
Validation loss: 2.5301152780892786

Epoch: 5| Step: 3
Training loss: 2.2151331905852683
Validation loss: 2.4646016277240017

Epoch: 5| Step: 4
Training loss: 2.056294788000366
Validation loss: 2.455833011023121

Epoch: 5| Step: 5
Training loss: 2.130151786768744
Validation loss: 2.438541193132737

Epoch: 5| Step: 6
Training loss: 2.368756369227399
Validation loss: 2.4114531520937654

Epoch: 5| Step: 7
Training loss: 2.416014342126529
Validation loss: 2.392264681909428

Epoch: 5| Step: 8
Training loss: 2.379091252491822
Validation loss: 2.3837809993166945

Epoch: 5| Step: 9
Training loss: 2.732613306654202
Validation loss: 2.375057640736298

Epoch: 5| Step: 10
Training loss: 2.402662798777158
Validation loss: 2.3916920835260576

Epoch: 227| Step: 0
Training loss: 1.9813534417811312
Validation loss: 2.430120632052533

Epoch: 5| Step: 1
Training loss: 2.1447350243649095
Validation loss: 2.4743387555221568

Epoch: 5| Step: 2
Training loss: 2.3637571754124758
Validation loss: 2.504533593732329

Epoch: 5| Step: 3
Training loss: 2.6799036945290933
Validation loss: 2.5094559361716158

Epoch: 5| Step: 4
Training loss: 2.8555292000484083
Validation loss: 2.4973327723881793

Epoch: 5| Step: 5
Training loss: 2.6573313587613323
Validation loss: 2.4621341065157285

Epoch: 5| Step: 6
Training loss: 2.185382581165598
Validation loss: 2.4632725979206067

Epoch: 5| Step: 7
Training loss: 2.0069338289689234
Validation loss: 2.426539402426241

Epoch: 5| Step: 8
Training loss: 2.1263196998578127
Validation loss: 2.4113784621243637

Epoch: 5| Step: 9
Training loss: 3.1771425001961644
Validation loss: 2.4291414205693918

Epoch: 5| Step: 10
Training loss: 2.6305948307104603
Validation loss: 2.4458513559593267

Epoch: 228| Step: 0
Training loss: 2.498897118485844
Validation loss: 2.4406311836745735

Epoch: 5| Step: 1
Training loss: 1.958137610644788
Validation loss: 2.495876693807734

Epoch: 5| Step: 2
Training loss: 2.4412591752574753
Validation loss: 2.5776861797427544

Epoch: 5| Step: 3
Training loss: 2.7595111057329658
Validation loss: 2.5638937752525366

Epoch: 5| Step: 4
Training loss: 2.6436964602268387
Validation loss: 2.499968743897983

Epoch: 5| Step: 5
Training loss: 2.735734438154986
Validation loss: 2.4590096757345274

Epoch: 5| Step: 6
Training loss: 2.5050953438406647
Validation loss: 2.4009757931225635

Epoch: 5| Step: 7
Training loss: 2.7755558144618737
Validation loss: 2.367553023175866

Epoch: 5| Step: 8
Training loss: 2.591408833458446
Validation loss: 2.3698969422199188

Epoch: 5| Step: 9
Training loss: 1.7314349850315944
Validation loss: 2.3729345281135195

Epoch: 5| Step: 10
Training loss: 2.5677484866414417
Validation loss: 2.3844014169399967

Epoch: 229| Step: 0
Training loss: 2.165901366815656
Validation loss: 2.4067009390238594

Epoch: 5| Step: 1
Training loss: 2.4264917484931554
Validation loss: 2.435964909235099

Epoch: 5| Step: 2
Training loss: 2.684661253120465
Validation loss: 2.459907052704992

Epoch: 5| Step: 3
Training loss: 2.635635175931815
Validation loss: 2.477846891665632

Epoch: 5| Step: 4
Training loss: 2.7566622747949796
Validation loss: 2.519647586009846

Epoch: 5| Step: 5
Training loss: 2.4853584694157465
Validation loss: 2.5822756530921485

Epoch: 5| Step: 6
Training loss: 2.4549743096275765
Validation loss: 2.600151082430276

Epoch: 5| Step: 7
Training loss: 2.205263871646953
Validation loss: 2.61158003963976

Epoch: 5| Step: 8
Training loss: 2.3013867551335436
Validation loss: 2.632329325429693

Epoch: 5| Step: 9
Training loss: 2.9420205902063707
Validation loss: 2.639150933418833

Epoch: 5| Step: 10
Training loss: 1.7695409509253957
Validation loss: 2.5764831664879138

Epoch: 230| Step: 0
Training loss: 3.1879224310308323
Validation loss: 2.518731148796649

Epoch: 5| Step: 1
Training loss: 1.879308391845784
Validation loss: 2.467760138136552

Epoch: 5| Step: 2
Training loss: 2.5231982610809003
Validation loss: 2.447190360296714

Epoch: 5| Step: 3
Training loss: 2.4459202410341363
Validation loss: 2.408332226365472

Epoch: 5| Step: 4
Training loss: 2.6779385300376854
Validation loss: 2.3893004105732834

Epoch: 5| Step: 5
Training loss: 2.618308120628812
Validation loss: 2.377658085151653

Epoch: 5| Step: 6
Training loss: 2.3297055403012843
Validation loss: 2.364411111486465

Epoch: 5| Step: 7
Training loss: 2.1871339764227415
Validation loss: 2.387871810677846

Epoch: 5| Step: 8
Training loss: 2.2997312886376453
Validation loss: 2.392999952313858

Epoch: 5| Step: 9
Training loss: 2.360797983486823
Validation loss: 2.42623274533551

Epoch: 5| Step: 10
Training loss: 2.320707961781959
Validation loss: 2.4449234703164704

Epoch: 231| Step: 0
Training loss: 2.46660926812207
Validation loss: 2.478661800553284

Epoch: 5| Step: 1
Training loss: 2.2701326975078864
Validation loss: 2.5238072203117157

Epoch: 5| Step: 2
Training loss: 2.271116034966291
Validation loss: 2.5167051511072747

Epoch: 5| Step: 3
Training loss: 2.6481135797603237
Validation loss: 2.5053310303267526

Epoch: 5| Step: 4
Training loss: 2.8557559598205833
Validation loss: 2.453004518341471

Epoch: 5| Step: 5
Training loss: 2.659719019512465
Validation loss: 2.432652700252274

Epoch: 5| Step: 6
Training loss: 2.3879552157562074
Validation loss: 2.419576681572775

Epoch: 5| Step: 7
Training loss: 2.275995342792915
Validation loss: 2.4299239688607197

Epoch: 5| Step: 8
Training loss: 1.9779033711497305
Validation loss: 2.452191191506337

Epoch: 5| Step: 9
Training loss: 2.1560299526108575
Validation loss: 2.4622418045215526

Epoch: 5| Step: 10
Training loss: 2.4949599005586256
Validation loss: 2.504448128837692

Epoch: 232| Step: 0
Training loss: 1.8564002339098897
Validation loss: 2.4936944936094996

Epoch: 5| Step: 1
Training loss: 2.364731928207753
Validation loss: 2.4743968572809196

Epoch: 5| Step: 2
Training loss: 2.2178077308761535
Validation loss: 2.474735116731486

Epoch: 5| Step: 3
Training loss: 2.6113297684292696
Validation loss: 2.4719904449168175

Epoch: 5| Step: 4
Training loss: 2.431865145570921
Validation loss: 2.456726805554343

Epoch: 5| Step: 5
Training loss: 2.1570622116900844
Validation loss: 2.470650268285016

Epoch: 5| Step: 6
Training loss: 2.512044313015636
Validation loss: 2.4863606950172783

Epoch: 5| Step: 7
Training loss: 1.675145951360288
Validation loss: 2.5193775376540772

Epoch: 5| Step: 8
Training loss: 2.1201504740304964
Validation loss: 2.5482658953309145

Epoch: 5| Step: 9
Training loss: 2.7232553269020676
Validation loss: 2.6001705846130316

Epoch: 5| Step: 10
Training loss: 3.0532636909649553
Validation loss: 2.6352779645865363

Epoch: 233| Step: 0
Training loss: 2.322434197059286
Validation loss: 2.62787231070992

Epoch: 5| Step: 1
Training loss: 2.263680511537127
Validation loss: 2.5556688915205825

Epoch: 5| Step: 2
Training loss: 2.317890277250376
Validation loss: 2.5192215679810603

Epoch: 5| Step: 3
Training loss: 2.2478837551457036
Validation loss: 2.4839443597936537

Epoch: 5| Step: 4
Training loss: 2.7409660031514673
Validation loss: 2.4889256154359014

Epoch: 5| Step: 5
Training loss: 2.2824125071341
Validation loss: 2.4390075382259004

Epoch: 5| Step: 6
Training loss: 2.576586177386328
Validation loss: 2.4160097316285714

Epoch: 5| Step: 7
Training loss: 2.3431768097927828
Validation loss: 2.4167476346289125

Epoch: 5| Step: 8
Training loss: 2.292144055205085
Validation loss: 2.3908274103295604

Epoch: 5| Step: 9
Training loss: 2.3687155044177723
Validation loss: 2.4295407647153358

Epoch: 5| Step: 10
Training loss: 2.503145623092371
Validation loss: 2.4356524894084046

Epoch: 234| Step: 0
Training loss: 2.358464854945984
Validation loss: 2.522761422574569

Epoch: 5| Step: 1
Training loss: 2.09267044703999
Validation loss: 2.595223486786411

Epoch: 5| Step: 2
Training loss: 2.426961958528508
Validation loss: 2.6306834692202328

Epoch: 5| Step: 3
Training loss: 2.1696926651697708
Validation loss: 2.652835306788921

Epoch: 5| Step: 4
Training loss: 2.8562860532526098
Validation loss: 2.588986011502873

Epoch: 5| Step: 5
Training loss: 2.343309895202428
Validation loss: 2.508458625177975

Epoch: 5| Step: 6
Training loss: 1.6659195974028838
Validation loss: 2.4497559754671676

Epoch: 5| Step: 7
Training loss: 2.505140645995646
Validation loss: 2.4146599279071506

Epoch: 5| Step: 8
Training loss: 2.9359217523027636
Validation loss: 2.4049533556760467

Epoch: 5| Step: 9
Training loss: 2.194864573547949
Validation loss: 2.3873547174848473

Epoch: 5| Step: 10
Training loss: 2.3752432246897004
Validation loss: 2.394406440992623

Epoch: 235| Step: 0
Training loss: 2.396773466225141
Validation loss: 2.4031704513757948

Epoch: 5| Step: 1
Training loss: 2.5671120054970507
Validation loss: 2.4180794874625433

Epoch: 5| Step: 2
Training loss: 1.8966535184412314
Validation loss: 2.4509812688868173

Epoch: 5| Step: 3
Training loss: 2.054497423554265
Validation loss: 2.4708793079588376

Epoch: 5| Step: 4
Training loss: 2.5211441436922892
Validation loss: 2.527437508753438

Epoch: 5| Step: 5
Training loss: 2.03295603779753
Validation loss: 2.6092537482178275

Epoch: 5| Step: 6
Training loss: 1.9586002357354222
Validation loss: 2.6895074551342795

Epoch: 5| Step: 7
Training loss: 3.098221754910797
Validation loss: 2.802282887486367

Epoch: 5| Step: 8
Training loss: 2.543161036286935
Validation loss: 2.6378913589040422

Epoch: 5| Step: 9
Training loss: 2.3294826363765693
Validation loss: 2.528966749221085

Epoch: 5| Step: 10
Training loss: 2.2199750929801327
Validation loss: 2.4539557908331737

Epoch: 236| Step: 0
Training loss: 1.9465481307680856
Validation loss: 2.439476586406732

Epoch: 5| Step: 1
Training loss: 2.6693360160994537
Validation loss: 2.4051781642904078

Epoch: 5| Step: 2
Training loss: 2.6923243668846806
Validation loss: 2.402815913699275

Epoch: 5| Step: 3
Training loss: 2.145701827183068
Validation loss: 2.4258544872773475

Epoch: 5| Step: 4
Training loss: 2.773096197914559
Validation loss: 2.432296712521038

Epoch: 5| Step: 5
Training loss: 2.452997580942671
Validation loss: 2.412544897287486

Epoch: 5| Step: 6
Training loss: 2.136825530959878
Validation loss: 2.4187160599262083

Epoch: 5| Step: 7
Training loss: 2.5931508854557594
Validation loss: 2.423443984460973

Epoch: 5| Step: 8
Training loss: 2.570799807469545
Validation loss: 2.4112875000020795

Epoch: 5| Step: 9
Training loss: 1.8584561682277128
Validation loss: 2.457162753208138

Epoch: 5| Step: 10
Training loss: 2.085541533988291
Validation loss: 2.4716344763206344

Epoch: 237| Step: 0
Training loss: 2.3077679236568023
Validation loss: 2.533325473698188

Epoch: 5| Step: 1
Training loss: 2.503877303362321
Validation loss: 2.521778698939377

Epoch: 5| Step: 2
Training loss: 1.9161699176535238
Validation loss: 2.5095284814506207

Epoch: 5| Step: 3
Training loss: 2.2738210872298104
Validation loss: 2.503518933020809

Epoch: 5| Step: 4
Training loss: 2.7252881588946205
Validation loss: 2.471460977783728

Epoch: 5| Step: 5
Training loss: 2.145407798078527
Validation loss: 2.4666817785474735

Epoch: 5| Step: 6
Training loss: 2.623080141903249
Validation loss: 2.449978982409595

Epoch: 5| Step: 7
Training loss: 2.7396407514194956
Validation loss: 2.512526675761076

Epoch: 5| Step: 8
Training loss: 2.0302538263016885
Validation loss: 2.5552191586102078

Epoch: 5| Step: 9
Training loss: 2.131120059171703
Validation loss: 2.60868661215204

Epoch: 5| Step: 10
Training loss: 2.2706886268729054
Validation loss: 2.6248074767126703

Epoch: 238| Step: 0
Training loss: 1.8113808300716068
Validation loss: 2.619310484110603

Epoch: 5| Step: 1
Training loss: 2.127346426310346
Validation loss: 2.5875385927731815

Epoch: 5| Step: 2
Training loss: 2.4271199192242072
Validation loss: 2.566572201602811

Epoch: 5| Step: 3
Training loss: 2.5054046384758566
Validation loss: 2.555609183159708

Epoch: 5| Step: 4
Training loss: 2.177655766868825
Validation loss: 2.4990814428838655

Epoch: 5| Step: 5
Training loss: 2.468680755030421
Validation loss: 2.492647501782157

Epoch: 5| Step: 6
Training loss: 2.0548326564324313
Validation loss: 2.454125008178228

Epoch: 5| Step: 7
Training loss: 2.455710342567009
Validation loss: 2.4285297403146697

Epoch: 5| Step: 8
Training loss: 1.9876390180612236
Validation loss: 2.4225034879397334

Epoch: 5| Step: 9
Training loss: 2.6597607020246974
Validation loss: 2.3871995240845942

Epoch: 5| Step: 10
Training loss: 1.9870161367220938
Validation loss: 2.3666394273154294

Epoch: 239| Step: 0
Training loss: 2.401385753632732
Validation loss: 2.3914130307024477

Epoch: 5| Step: 1
Training loss: 2.463014047481175
Validation loss: 2.4653027122800673

Epoch: 5| Step: 2
Training loss: 1.5999540113754005
Validation loss: 2.5067399682335925

Epoch: 5| Step: 3
Training loss: 2.936281966242057
Validation loss: 2.5576051902836525

Epoch: 5| Step: 4
Training loss: 2.642062546422121
Validation loss: 2.495469122191628

Epoch: 5| Step: 5
Training loss: 2.0843535277763374
Validation loss: 2.4091756576987957

Epoch: 5| Step: 6
Training loss: 2.0449504394868048
Validation loss: 2.385186858462933

Epoch: 5| Step: 7
Training loss: 2.4722869259752485
Validation loss: 2.418229675077355

Epoch: 5| Step: 8
Training loss: 1.8326395484904177
Validation loss: 2.4176274328637626

Epoch: 5| Step: 9
Training loss: 2.6893661584693276
Validation loss: 2.471217540045795

Epoch: 5| Step: 10
Training loss: 2.5190839976699655
Validation loss: 2.5157926016110865

Epoch: 240| Step: 0
Training loss: 2.3084515368038847
Validation loss: 2.4796520756520843

Epoch: 5| Step: 1
Training loss: 2.3004821686579073
Validation loss: 2.445593499493433

Epoch: 5| Step: 2
Training loss: 2.323322745325964
Validation loss: 2.4167012303065607

Epoch: 5| Step: 3
Training loss: 2.547884875452973
Validation loss: 2.3763741391470337

Epoch: 5| Step: 4
Training loss: 2.5198532490158883
Validation loss: 2.3733578446671517

Epoch: 5| Step: 5
Training loss: 1.698556915829869
Validation loss: 2.374409445119304

Epoch: 5| Step: 6
Training loss: 2.1829119933383483
Validation loss: 2.383963692689933

Epoch: 5| Step: 7
Training loss: 2.4342958958986607
Validation loss: 2.3953158154496204

Epoch: 5| Step: 8
Training loss: 2.070918041418163
Validation loss: 2.4275283444237408

Epoch: 5| Step: 9
Training loss: 2.1926510789030473
Validation loss: 2.4422643002408213

Epoch: 5| Step: 10
Training loss: 2.121373841284771
Validation loss: 2.4578012963440106

Epoch: 241| Step: 0
Training loss: 1.9276910253286679
Validation loss: 2.486880507872165

Epoch: 5| Step: 1
Training loss: 2.5254254615310403
Validation loss: 2.478686306760999

Epoch: 5| Step: 2
Training loss: 2.140247172404247
Validation loss: 2.507383794274773

Epoch: 5| Step: 3
Training loss: 2.420816497831737
Validation loss: 2.5188194180653514

Epoch: 5| Step: 4
Training loss: 2.021103503333093
Validation loss: 2.539482494164815

Epoch: 5| Step: 5
Training loss: 2.176578177171758
Validation loss: 2.557548225541651

Epoch: 5| Step: 6
Training loss: 2.5649020404216665
Validation loss: 2.5835974978671725

Epoch: 5| Step: 7
Training loss: 1.9460294696815092
Validation loss: 2.5898862868753216

Epoch: 5| Step: 8
Training loss: 1.9403218055535132
Validation loss: 2.5625372022824067

Epoch: 5| Step: 9
Training loss: 2.4890778372867373
Validation loss: 2.550932439417635

Epoch: 5| Step: 10
Training loss: 2.0320293398638776
Validation loss: 2.5008122016956587

Epoch: 242| Step: 0
Training loss: 2.24297858448324
Validation loss: 2.4507061845268403

Epoch: 5| Step: 1
Training loss: 2.1122079545797314
Validation loss: 2.455178027630957

Epoch: 5| Step: 2
Training loss: 2.2140081534920437
Validation loss: 2.459120787164918

Epoch: 5| Step: 3
Training loss: 2.1844837647347926
Validation loss: 2.4390636537030486

Epoch: 5| Step: 4
Training loss: 2.4148519762060126
Validation loss: 2.4074671670921726

Epoch: 5| Step: 5
Training loss: 2.718363416525951
Validation loss: 2.3963982777843684

Epoch: 5| Step: 6
Training loss: 2.192220227302425
Validation loss: 2.4310277824266233

Epoch: 5| Step: 7
Training loss: 1.7232311439960157
Validation loss: 2.434117301982994

Epoch: 5| Step: 8
Training loss: 1.8331954933136079
Validation loss: 2.4500887183156226

Epoch: 5| Step: 9
Training loss: 2.043309724846635
Validation loss: 2.491451232205878

Epoch: 5| Step: 10
Training loss: 2.0379494153858753
Validation loss: 2.503266438155593

Epoch: 243| Step: 0
Training loss: 2.1086817979891843
Validation loss: 2.4833895286362293

Epoch: 5| Step: 1
Training loss: 2.0506163903229755
Validation loss: 2.4346318520627275

Epoch: 5| Step: 2
Training loss: 2.0559152626357613
Validation loss: 2.3706261125920363

Epoch: 5| Step: 3
Training loss: 2.544083639473402
Validation loss: 2.3691431073298688

Epoch: 5| Step: 4
Training loss: 2.4017134669251186
Validation loss: 2.373785305756283

Epoch: 5| Step: 5
Training loss: 2.2717045737126673
Validation loss: 2.3948194048059888

Epoch: 5| Step: 6
Training loss: 2.0819655187941404
Validation loss: 2.4171046343537848

Epoch: 5| Step: 7
Training loss: 2.3297024701441496
Validation loss: 2.475326161683291

Epoch: 5| Step: 8
Training loss: 2.0300631063264327
Validation loss: 2.4715958279842876

Epoch: 5| Step: 9
Training loss: 1.6481052443499649
Validation loss: 2.537390721229744

Epoch: 5| Step: 10
Training loss: 2.0604784913489795
Validation loss: 2.5359207118898657

Epoch: 244| Step: 0
Training loss: 2.2290544451930754
Validation loss: 2.5465345912024047

Epoch: 5| Step: 1
Training loss: 2.0447360212074663
Validation loss: 2.5445420847795863

Epoch: 5| Step: 2
Training loss: 1.8335152738053053
Validation loss: 2.5648666365971797

Epoch: 5| Step: 3
Training loss: 2.3377375476918765
Validation loss: 2.5565572018561076

Epoch: 5| Step: 4
Training loss: 2.2736707220365253
Validation loss: 2.519170179073127

Epoch: 5| Step: 5
Training loss: 2.2493456842791537
Validation loss: 2.456963956715334

Epoch: 5| Step: 6
Training loss: 1.9099683298610968
Validation loss: 2.4208188699868405

Epoch: 5| Step: 7
Training loss: 2.4028885386473084
Validation loss: 2.413103520005988

Epoch: 5| Step: 8
Training loss: 1.9985161283413448
Validation loss: 2.419148599215519

Epoch: 5| Step: 9
Training loss: 2.332437706674624
Validation loss: 2.4379944637678244

Epoch: 5| Step: 10
Training loss: 1.1684754972357705
Validation loss: 2.4208080999603907

Epoch: 245| Step: 0
Training loss: 1.9103429660149338
Validation loss: 2.439187947599883

Epoch: 5| Step: 1
Training loss: 1.9315466322753947
Validation loss: 2.453902179523602

Epoch: 5| Step: 2
Training loss: 1.864226351473009
Validation loss: 2.4829291704472047

Epoch: 5| Step: 3
Training loss: 2.0505104685443833
Validation loss: 2.4648924097753895

Epoch: 5| Step: 4
Training loss: 2.30660186399085
Validation loss: 2.436363978314488

Epoch: 5| Step: 5
Training loss: 2.205613266483184
Validation loss: 2.425773996958538

Epoch: 5| Step: 6
Training loss: 2.1742927760723307
Validation loss: 2.4062688512746884

Epoch: 5| Step: 7
Training loss: 2.212519319094349
Validation loss: 2.404439680112029

Epoch: 5| Step: 8
Training loss: 2.192103093235925
Validation loss: 2.4024342061442434

Epoch: 5| Step: 9
Training loss: 2.0563658614982523
Validation loss: 2.430242089968927

Epoch: 5| Step: 10
Training loss: 1.8013488801689521
Validation loss: 2.4519202735437053

Epoch: 246| Step: 0
Training loss: 2.2785019718351656
Validation loss: 2.5128463964265246

Epoch: 5| Step: 1
Training loss: 2.227996578501569
Validation loss: 2.51690853868706

Epoch: 5| Step: 2
Training loss: 1.8154865520696786
Validation loss: 2.533741217172431

Epoch: 5| Step: 3
Training loss: 2.0565289850174837
Validation loss: 2.4670618198313976

Epoch: 5| Step: 4
Training loss: 1.7949941327947505
Validation loss: 2.416240443096341

Epoch: 5| Step: 5
Training loss: 2.253458861272382
Validation loss: 2.3823456230007682

Epoch: 5| Step: 6
Training loss: 1.680897121905422
Validation loss: 2.380531367919827

Epoch: 5| Step: 7
Training loss: 2.1122367378836193
Validation loss: 2.403021016710171

Epoch: 5| Step: 8
Training loss: 2.0515871045045553
Validation loss: 2.420449010225304

Epoch: 5| Step: 9
Training loss: 2.1607027380048103
Validation loss: 2.4298034931497603

Epoch: 5| Step: 10
Training loss: 2.5924125808205716
Validation loss: 2.4627229874323833

Epoch: 247| Step: 0
Training loss: 2.106547176779007
Validation loss: 2.418385630184242

Epoch: 5| Step: 1
Training loss: 1.8399700923230546
Validation loss: 2.3823037333121238

Epoch: 5| Step: 2
Training loss: 2.0590143516007013
Validation loss: 2.381343393645103

Epoch: 5| Step: 3
Training loss: 1.9095570379160418
Validation loss: 2.3876278785510627

Epoch: 5| Step: 4
Training loss: 2.032877929948099
Validation loss: 2.4065372704146357

Epoch: 5| Step: 5
Training loss: 1.935330745513076
Validation loss: 2.407932114913187

Epoch: 5| Step: 6
Training loss: 2.319461242503279
Validation loss: 2.3821390535418177

Epoch: 5| Step: 7
Training loss: 2.157605063310339
Validation loss: 2.342924367214733

Epoch: 5| Step: 8
Training loss: 2.237252683130868
Validation loss: 2.3631132072381886

Epoch: 5| Step: 9
Training loss: 2.156235846873841
Validation loss: 2.413638343588278

Epoch: 5| Step: 10
Training loss: 1.7135708544563273
Validation loss: 2.5160260001593873

Epoch: 248| Step: 0
Training loss: 2.1684154153466957
Validation loss: 2.5397975658415017

Epoch: 5| Step: 1
Training loss: 2.250499457978999
Validation loss: 2.520734014328345

Epoch: 5| Step: 2
Training loss: 1.8597609816559144
Validation loss: 2.504378401948787

Epoch: 5| Step: 3
Training loss: 2.195594850892937
Validation loss: 2.474077063379249

Epoch: 5| Step: 4
Training loss: 2.133808169072066
Validation loss: 2.4220999865603314

Epoch: 5| Step: 5
Training loss: 1.8754263075342243
Validation loss: 2.390912665932616

Epoch: 5| Step: 6
Training loss: 1.9476309446059639
Validation loss: 2.368725131922167

Epoch: 5| Step: 7
Training loss: 1.9494272858217356
Validation loss: 2.3703395332359185

Epoch: 5| Step: 8
Training loss: 2.1379955319678188
Validation loss: 2.3797258056848114

Epoch: 5| Step: 9
Training loss: 1.9877215423907415
Validation loss: 2.4431911884839184

Epoch: 5| Step: 10
Training loss: 2.023488519091658
Validation loss: 2.4576896469939515

Epoch: 249| Step: 0
Training loss: 2.0213009663551182
Validation loss: 2.50083803364205

Epoch: 5| Step: 1
Training loss: 2.2751162907987177
Validation loss: 2.532143214828089

Epoch: 5| Step: 2
Training loss: 2.1242921435636046
Validation loss: 2.4976401204377603

Epoch: 5| Step: 3
Training loss: 2.0447072205196672
Validation loss: 2.4956204302623783

Epoch: 5| Step: 4
Training loss: 1.8666290341852683
Validation loss: 2.4698978578550763

Epoch: 5| Step: 5
Training loss: 1.8738285855946184
Validation loss: 2.442887799164389

Epoch: 5| Step: 6
Training loss: 2.0402396009021477
Validation loss: 2.4312403519822796

Epoch: 5| Step: 7
Training loss: 1.7101930714525442
Validation loss: 2.4410304566290844

Epoch: 5| Step: 8
Training loss: 2.1358719007106015
Validation loss: 2.4630935019523688

Epoch: 5| Step: 9
Training loss: 2.0017111134206647
Validation loss: 2.454385465363382

Epoch: 5| Step: 10
Training loss: 1.963693027750447
Validation loss: 2.49247490023612

Epoch: 250| Step: 0
Training loss: 2.233011109559798
Validation loss: 2.5034884028550715

Epoch: 5| Step: 1
Training loss: 2.560506836369362
Validation loss: 2.5135684836810093

Epoch: 5| Step: 2
Training loss: 1.74480300064581
Validation loss: 2.485162308015507

Epoch: 5| Step: 3
Training loss: 1.283221426126391
Validation loss: 2.433671932820945

Epoch: 5| Step: 4
Training loss: 2.0562824977173495
Validation loss: 2.3959159341049343

Epoch: 5| Step: 5
Training loss: 2.14399698686388
Validation loss: 2.3772220088573026

Epoch: 5| Step: 6
Training loss: 1.6443614736165242
Validation loss: 2.3704322559453748

Epoch: 5| Step: 7
Training loss: 2.2144852605463976
Validation loss: 2.3777714002331605

Epoch: 5| Step: 8
Training loss: 1.5819225132625552
Validation loss: 2.4184399630925673

Epoch: 5| Step: 9
Training loss: 1.8476636696922575
Validation loss: 2.52577196632352

Epoch: 5| Step: 10
Training loss: 2.7296781473157874
Validation loss: 2.62477511171667

Epoch: 251| Step: 0
Training loss: 1.7088541384527112
Validation loss: 2.455120770557046

Epoch: 5| Step: 1
Training loss: 1.928269579643195
Validation loss: 2.376817561513478

Epoch: 5| Step: 2
Training loss: 2.314550264146893
Validation loss: 2.314564087194976

Epoch: 5| Step: 3
Training loss: 2.1063841915680515
Validation loss: 2.323717179591902

Epoch: 5| Step: 4
Training loss: 2.139030698173421
Validation loss: 2.3099411662400806

Epoch: 5| Step: 5
Training loss: 1.989532376846813
Validation loss: 2.3230759015975484

Epoch: 5| Step: 6
Training loss: 1.9993455531344808
Validation loss: 2.3657873027704115

Epoch: 5| Step: 7
Training loss: 1.951226799757944
Validation loss: 2.406309129478285

Epoch: 5| Step: 8
Training loss: 1.8393802909502777
Validation loss: 2.479827906080407

Epoch: 5| Step: 9
Training loss: 2.1668351792559766
Validation loss: 2.5285840323111044

Epoch: 5| Step: 10
Training loss: 1.9136557010512987
Validation loss: 2.555379703969547

Epoch: 252| Step: 0
Training loss: 2.5203312040085466
Validation loss: 2.572678997940864

Epoch: 5| Step: 1
Training loss: 1.8106136371439034
Validation loss: 2.56234073018897

Epoch: 5| Step: 2
Training loss: 1.5970492154099856
Validation loss: 2.5227662495396794

Epoch: 5| Step: 3
Training loss: 1.4993997008438493
Validation loss: 2.522473879351991

Epoch: 5| Step: 4
Training loss: 1.6790756175659256
Validation loss: 2.5261720955839237

Epoch: 5| Step: 5
Training loss: 2.0645652603400264
Validation loss: 2.5163700317934996

Epoch: 5| Step: 6
Training loss: 1.9082561005312793
Validation loss: 2.4608656568534326

Epoch: 5| Step: 7
Training loss: 2.311177262048259
Validation loss: 2.4484720459286353

Epoch: 5| Step: 8
Training loss: 1.925618131898334
Validation loss: 2.394527830427156

Epoch: 5| Step: 9
Training loss: 1.7143007431052695
Validation loss: 2.3741355201333474

Epoch: 5| Step: 10
Training loss: 2.119515915789536
Validation loss: 2.3190315262526013

Epoch: 253| Step: 0
Training loss: 1.6921642270165322
Validation loss: 2.2878763374213427

Epoch: 5| Step: 1
Training loss: 2.2194718811838925
Validation loss: 2.306697694468518

Epoch: 5| Step: 2
Training loss: 1.9832101842436407
Validation loss: 2.2933070832570004

Epoch: 5| Step: 3
Training loss: 2.0562680043646853
Validation loss: 2.3029833550516043

Epoch: 5| Step: 4
Training loss: 1.683775075543091
Validation loss: 2.3223634330794423

Epoch: 5| Step: 5
Training loss: 1.9382805021285336
Validation loss: 2.351255965491349

Epoch: 5| Step: 6
Training loss: 1.9481254370563152
Validation loss: 2.387731127253617

Epoch: 5| Step: 7
Training loss: 1.7561213517499705
Validation loss: 2.44895391610173

Epoch: 5| Step: 8
Training loss: 1.6176116681944959
Validation loss: 2.538749238560598

Epoch: 5| Step: 9
Training loss: 2.0674251359257174
Validation loss: 2.599884163399582

Epoch: 5| Step: 10
Training loss: 2.3764029926491173
Validation loss: 2.608847854378609

Epoch: 254| Step: 0
Training loss: 1.9385774754314367
Validation loss: 2.5279602748323136

Epoch: 5| Step: 1
Training loss: 1.7385951755243914
Validation loss: 2.462803118539028

Epoch: 5| Step: 2
Training loss: 2.0824002910433554
Validation loss: 2.407268617004691

Epoch: 5| Step: 3
Training loss: 1.9866468985852024
Validation loss: 2.38423847449563

Epoch: 5| Step: 4
Training loss: 1.7084959542011946
Validation loss: 2.3827867678351105

Epoch: 5| Step: 5
Training loss: 1.3256206462380344
Validation loss: 2.372627359296935

Epoch: 5| Step: 6
Training loss: 2.2087333125038344
Validation loss: 2.3382375271680265

Epoch: 5| Step: 7
Training loss: 1.544658652932809
Validation loss: 2.3628809484867794

Epoch: 5| Step: 8
Training loss: 1.861829275931621
Validation loss: 2.3697502153339727

Epoch: 5| Step: 9
Training loss: 2.370866893492791
Validation loss: 2.386807955172506

Epoch: 5| Step: 10
Training loss: 1.8335555187606967
Validation loss: 2.3752897028673576

Epoch: 255| Step: 0
Training loss: 1.404260117602866
Validation loss: 2.3906296653522414

Epoch: 5| Step: 1
Training loss: 1.9320509795813918
Validation loss: 2.3944881136686633

Epoch: 5| Step: 2
Training loss: 2.1845912668027223
Validation loss: 2.4261162781989722

Epoch: 5| Step: 3
Training loss: 1.8655264900308208
Validation loss: 2.4625893711487725

Epoch: 5| Step: 4
Training loss: 2.0594742283626757
Validation loss: 2.4563190710067024

Epoch: 5| Step: 5
Training loss: 1.9627217234351917
Validation loss: 2.4358083283320604

Epoch: 5| Step: 6
Training loss: 1.6167462617740382
Validation loss: 2.430590525042058

Epoch: 5| Step: 7
Training loss: 2.024010301028489
Validation loss: 2.4196118289404773

Epoch: 5| Step: 8
Training loss: 2.249407584295395
Validation loss: 2.410909623548924

Epoch: 5| Step: 9
Training loss: 1.938064000886762
Validation loss: 2.3953018654772915

Epoch: 5| Step: 10
Training loss: 1.0687163208233634
Validation loss: 2.408489342855374

Epoch: 256| Step: 0
Training loss: 1.8844172813011795
Validation loss: 2.4200131201153248

Epoch: 5| Step: 1
Training loss: 1.8159448837579177
Validation loss: 2.4436615139965876

Epoch: 5| Step: 2
Training loss: 1.860526233392806
Validation loss: 2.4872412332774045

Epoch: 5| Step: 3
Training loss: 1.4318879916910057
Validation loss: 2.522081964555648

Epoch: 5| Step: 4
Training loss: 1.8433092528018309
Validation loss: 2.538282929573696

Epoch: 5| Step: 5
Training loss: 1.711966496919644
Validation loss: 2.5040577833405

Epoch: 5| Step: 6
Training loss: 1.9973005912849027
Validation loss: 2.4238694578227196

Epoch: 5| Step: 7
Training loss: 2.232384815726137
Validation loss: 2.3666754588833725

Epoch: 5| Step: 8
Training loss: 2.023817225583165
Validation loss: 2.320539832722252

Epoch: 5| Step: 9
Training loss: 1.7826413526304594
Validation loss: 2.3032961492076325

Epoch: 5| Step: 10
Training loss: 1.8329909033749918
Validation loss: 2.309093888052619

Epoch: 257| Step: 0
Training loss: 1.8611202223951713
Validation loss: 2.3210280584159273

Epoch: 5| Step: 1
Training loss: 1.8395294115307972
Validation loss: 2.3242056307409906

Epoch: 5| Step: 2
Training loss: 1.5753798828969479
Validation loss: 2.354178849418437

Epoch: 5| Step: 3
Training loss: 1.6854432605709044
Validation loss: 2.4128004094168998

Epoch: 5| Step: 4
Training loss: 1.8384936131005125
Validation loss: 2.463356894807353

Epoch: 5| Step: 5
Training loss: 1.6833637549543892
Validation loss: 2.42918115277786

Epoch: 5| Step: 6
Training loss: 1.6207361769138957
Validation loss: 2.4208925750765613

Epoch: 5| Step: 7
Training loss: 1.9884714811264081
Validation loss: 2.4091797492185822

Epoch: 5| Step: 8
Training loss: 1.9450165550292287
Validation loss: 2.3668667659143345

Epoch: 5| Step: 9
Training loss: 2.2246347749112405
Validation loss: 2.3622944429196955

Epoch: 5| Step: 10
Training loss: 1.8121619073646311
Validation loss: 2.3828263272792554

Epoch: 258| Step: 0
Training loss: 1.8651672031630313
Validation loss: 2.423790957751339

Epoch: 5| Step: 1
Training loss: 1.6718431986698754
Validation loss: 2.4409638008439147

Epoch: 5| Step: 2
Training loss: 1.7757909006711612
Validation loss: 2.451964151308183

Epoch: 5| Step: 3
Training loss: 1.6489112498665668
Validation loss: 2.4805797962553044

Epoch: 5| Step: 4
Training loss: 1.731972757675853
Validation loss: 2.507092570074347

Epoch: 5| Step: 5
Training loss: 1.589361619131725
Validation loss: 2.483165496852502

Epoch: 5| Step: 6
Training loss: 1.9807139589092166
Validation loss: 2.426162415796636

Epoch: 5| Step: 7
Training loss: 2.11098548727319
Validation loss: 2.384218636141786

Epoch: 5| Step: 8
Training loss: 1.9816431780557486
Validation loss: 2.374202960995867

Epoch: 5| Step: 9
Training loss: 1.83970275468238
Validation loss: 2.36919666182723

Epoch: 5| Step: 10
Training loss: 1.5109381027772761
Validation loss: 2.4173121377104976

Epoch: 259| Step: 0
Training loss: 1.8479000519439592
Validation loss: 2.4348370972983258

Epoch: 5| Step: 1
Training loss: 1.4953582788553095
Validation loss: 2.465172639559769

Epoch: 5| Step: 2
Training loss: 1.5314875048738854
Validation loss: 2.4306120316193995

Epoch: 5| Step: 3
Training loss: 1.8464995104171638
Validation loss: 2.4589104453833963

Epoch: 5| Step: 4
Training loss: 2.051399762569539
Validation loss: 2.426522076809015

Epoch: 5| Step: 5
Training loss: 1.948998692996985
Validation loss: 2.4040804893614283

Epoch: 5| Step: 6
Training loss: 1.8490697764449646
Validation loss: 2.412195941284558

Epoch: 5| Step: 7
Training loss: 1.4974734963442318
Validation loss: 2.3790346383732395

Epoch: 5| Step: 8
Training loss: 1.6545634049376476
Validation loss: 2.3838170782875476

Epoch: 5| Step: 9
Training loss: 1.8972929341717006
Validation loss: 2.3829454750358985

Epoch: 5| Step: 10
Training loss: 1.881089938125278
Validation loss: 2.3652450696631715

Epoch: 260| Step: 0
Training loss: 1.687234504442028
Validation loss: 2.3549836991794955

Epoch: 5| Step: 1
Training loss: 2.003300923018128
Validation loss: 2.322643624501374

Epoch: 5| Step: 2
Training loss: 1.8434527529318103
Validation loss: 2.3131177820339666

Epoch: 5| Step: 3
Training loss: 2.220564516651909
Validation loss: 2.312626572758784

Epoch: 5| Step: 4
Training loss: 1.312184840919833
Validation loss: 2.319181112634479

Epoch: 5| Step: 5
Training loss: 1.4458970820786317
Validation loss: 2.3709540600249714

Epoch: 5| Step: 6
Training loss: 1.7971132866798167
Validation loss: 2.3965909604416065

Epoch: 5| Step: 7
Training loss: 1.5358944736480886
Validation loss: 2.4494467197407648

Epoch: 5| Step: 8
Training loss: 2.116437941180513
Validation loss: 2.48922598174815

Epoch: 5| Step: 9
Training loss: 1.6290642458176237
Validation loss: 2.4856762358948514

Epoch: 5| Step: 10
Training loss: 1.5490561626490156
Validation loss: 2.4504170580143603

Epoch: 261| Step: 0
Training loss: 2.0132633538536915
Validation loss: 2.496817035108233

Epoch: 5| Step: 1
Training loss: 1.877726479901198
Validation loss: 2.5546361521610423

Epoch: 5| Step: 2
Training loss: 1.3744652315073964
Validation loss: 2.530395350364469

Epoch: 5| Step: 3
Training loss: 2.0795697231174732
Validation loss: 2.4753361725257643

Epoch: 5| Step: 4
Training loss: 1.4408917426292132
Validation loss: 2.3955005063241583

Epoch: 5| Step: 5
Training loss: 1.6715707234657986
Validation loss: 2.3405231940596622

Epoch: 5| Step: 6
Training loss: 1.71002500404236
Validation loss: 2.3010118743820693

Epoch: 5| Step: 7
Training loss: 2.065282967047923
Validation loss: 2.2748291765095425

Epoch: 5| Step: 8
Training loss: 1.6822962883884809
Validation loss: 2.3096580835744

Epoch: 5| Step: 9
Training loss: 1.8209078883337346
Validation loss: 2.329354003026954

Epoch: 5| Step: 10
Training loss: 1.227652436015373
Validation loss: 2.3891369041122408

Epoch: 262| Step: 0
Training loss: 1.8219671628486556
Validation loss: 2.427532836414691

Epoch: 5| Step: 1
Training loss: 1.9311052434798224
Validation loss: 2.464318561638641

Epoch: 5| Step: 2
Training loss: 1.9155931852850752
Validation loss: 2.4961718547157683

Epoch: 5| Step: 3
Training loss: 1.464981520213986
Validation loss: 2.511630096960834

Epoch: 5| Step: 4
Training loss: 1.7247271556964248
Validation loss: 2.5123387255125467

Epoch: 5| Step: 5
Training loss: 1.7217022596276292
Validation loss: 2.450064279735559

Epoch: 5| Step: 6
Training loss: 1.627211606305196
Validation loss: 2.423861655419275

Epoch: 5| Step: 7
Training loss: 1.4952639676532153
Validation loss: 2.382996178293278

Epoch: 5| Step: 8
Training loss: 1.835337569242375
Validation loss: 2.3304961988608435

Epoch: 5| Step: 9
Training loss: 1.4446879919250561
Validation loss: 2.307256981447689

Epoch: 5| Step: 10
Training loss: 1.801438747367325
Validation loss: 2.3225347465320443

Epoch: 263| Step: 0
Training loss: 1.7438305005596177
Validation loss: 2.2986022936987873

Epoch: 5| Step: 1
Training loss: 1.2412902662616696
Validation loss: 2.36866806061283

Epoch: 5| Step: 2
Training loss: 1.5154676060702248
Validation loss: 2.4138661513241493

Epoch: 5| Step: 3
Training loss: 1.913919622577132
Validation loss: 2.445770315170525

Epoch: 5| Step: 4
Training loss: 1.7387194134828141
Validation loss: 2.499251875149953

Epoch: 5| Step: 5
Training loss: 1.4840760582509187
Validation loss: 2.4594778727039914

Epoch: 5| Step: 6
Training loss: 1.7442640579136084
Validation loss: 2.411210106457071

Epoch: 5| Step: 7
Training loss: 1.463393976581351
Validation loss: 2.363369603693228

Epoch: 5| Step: 8
Training loss: 1.6926124976000445
Validation loss: 2.328303579454692

Epoch: 5| Step: 9
Training loss: 1.9123145393754433
Validation loss: 2.304297131153013

Epoch: 5| Step: 10
Training loss: 1.858367647045243
Validation loss: 2.2897260852627945

Epoch: 264| Step: 0
Training loss: 1.8395086740598774
Validation loss: 2.325395412035023

Epoch: 5| Step: 1
Training loss: 1.896283532929322
Validation loss: 2.332235012619337

Epoch: 5| Step: 2
Training loss: 1.8219758648702786
Validation loss: 2.350085763057954

Epoch: 5| Step: 3
Training loss: 1.6937841038947938
Validation loss: 2.4259178362672205

Epoch: 5| Step: 4
Training loss: 1.6776701411961568
Validation loss: 2.4246432385215457

Epoch: 5| Step: 5
Training loss: 1.6966284641294302
Validation loss: 2.4579849660270083

Epoch: 5| Step: 6
Training loss: 1.4099594359278262
Validation loss: 2.490981990924429

Epoch: 5| Step: 7
Training loss: 1.7615545158212058
Validation loss: 2.48394173210496

Epoch: 5| Step: 8
Training loss: 1.6133527024081107
Validation loss: 2.3994158361171296

Epoch: 5| Step: 9
Training loss: 1.5961087293850902
Validation loss: 2.3856075113977644

Epoch: 5| Step: 10
Training loss: 1.3642957787224532
Validation loss: 2.356238471079934

Epoch: 265| Step: 0
Training loss: 1.644871692349468
Validation loss: 2.3396796712464143

Epoch: 5| Step: 1
Training loss: 1.8962653020795828
Validation loss: 2.3326447693395562

Epoch: 5| Step: 2
Training loss: 1.4469664312026536
Validation loss: 2.3276418705057296

Epoch: 5| Step: 3
Training loss: 1.702300615889003
Validation loss: 2.3197098517656287

Epoch: 5| Step: 4
Training loss: 1.7279357972138933
Validation loss: 2.334870952121284

Epoch: 5| Step: 5
Training loss: 1.5703290492462063
Validation loss: 2.3965606737480685

Epoch: 5| Step: 6
Training loss: 1.6977813604382521
Validation loss: 2.4816338824866775

Epoch: 5| Step: 7
Training loss: 1.528801186079746
Validation loss: 2.4334447060519215

Epoch: 5| Step: 8
Training loss: 1.7448602539550007
Validation loss: 2.437891090261666

Epoch: 5| Step: 9
Training loss: 1.5500525004201755
Validation loss: 2.3566923275367238

Epoch: 5| Step: 10
Training loss: 1.6916120373153056
Validation loss: 2.304590157604338

Epoch: 266| Step: 0
Training loss: 1.446946246574303
Validation loss: 2.312781434586736

Epoch: 5| Step: 1
Training loss: 1.8989911312159327
Validation loss: 2.3348668160285295

Epoch: 5| Step: 2
Training loss: 1.608432382620317
Validation loss: 2.3975310225802553

Epoch: 5| Step: 3
Training loss: 1.7551994059379985
Validation loss: 2.4965476912696363

Epoch: 5| Step: 4
Training loss: 1.7400833218454574
Validation loss: 2.511951117653983

Epoch: 5| Step: 5
Training loss: 1.2922983419535072
Validation loss: 2.486877131783626

Epoch: 5| Step: 6
Training loss: 1.4554292191252534
Validation loss: 2.4579086486110326

Epoch: 5| Step: 7
Training loss: 1.8479093414585788
Validation loss: 2.362447158527237

Epoch: 5| Step: 8
Training loss: 1.3716180999674084
Validation loss: 2.315535089305724

Epoch: 5| Step: 9
Training loss: 1.88892281570384
Validation loss: 2.3039161933476247

Epoch: 5| Step: 10
Training loss: 1.4581889853110002
Validation loss: 2.2739095189045515

Epoch: 267| Step: 0
Training loss: 1.813856340862436
Validation loss: 2.2708381452581885

Epoch: 5| Step: 1
Training loss: 1.6822650383730489
Validation loss: 2.2864832842530602

Epoch: 5| Step: 2
Training loss: 1.775447764804334
Validation loss: 2.3338407486275212

Epoch: 5| Step: 3
Training loss: 1.3283657528946762
Validation loss: 2.3798386883704468

Epoch: 5| Step: 4
Training loss: 1.62432407112907
Validation loss: 2.383650036387894

Epoch: 5| Step: 5
Training loss: 1.570296481985507
Validation loss: 2.431168272388474

Epoch: 5| Step: 6
Training loss: 1.8531540094842176
Validation loss: 2.4780717394695224

Epoch: 5| Step: 7
Training loss: 1.342922710097765
Validation loss: 2.4742416915576757

Epoch: 5| Step: 8
Training loss: 1.6680638020431855
Validation loss: 2.482886469739082

Epoch: 5| Step: 9
Training loss: 1.1404796141893416
Validation loss: 2.429064031763774

Epoch: 5| Step: 10
Training loss: 1.577284863125228
Validation loss: 2.391783641895751

Epoch: 268| Step: 0
Training loss: 1.465740773522807
Validation loss: 2.400148795114543

Epoch: 5| Step: 1
Training loss: 1.2534581034186012
Validation loss: 2.4307405118012766

Epoch: 5| Step: 2
Training loss: 1.494226630235073
Validation loss: 2.424918390661448

Epoch: 5| Step: 3
Training loss: 1.7831515819708874
Validation loss: 2.3980433257821963

Epoch: 5| Step: 4
Training loss: 1.4410219584796606
Validation loss: 2.40969368834391

Epoch: 5| Step: 5
Training loss: 1.3612788668987963
Validation loss: 2.4090663663238434

Epoch: 5| Step: 6
Training loss: 1.720369997371625
Validation loss: 2.404241241480241

Epoch: 5| Step: 7
Training loss: 1.8142167215563465
Validation loss: 2.399292860442797

Epoch: 5| Step: 8
Training loss: 1.5992862062898268
Validation loss: 2.346844544008338

Epoch: 5| Step: 9
Training loss: 1.6746428208495971
Validation loss: 2.295375673646919

Epoch: 5| Step: 10
Training loss: 1.7698999824929555
Validation loss: 2.290209318187241

Epoch: 269| Step: 0
Training loss: 1.6081937139651314
Validation loss: 2.3366658919602306

Epoch: 5| Step: 1
Training loss: 1.282370565772466
Validation loss: 2.3602537873576597

Epoch: 5| Step: 2
Training loss: 1.5762767733206722
Validation loss: 2.4241294209847917

Epoch: 5| Step: 3
Training loss: 1.6114755643956147
Validation loss: 2.4201527262216516

Epoch: 5| Step: 4
Training loss: 1.5582931343374369
Validation loss: 2.428510105427028

Epoch: 5| Step: 5
Training loss: 1.2292349306105723
Validation loss: 2.392038359573392

Epoch: 5| Step: 6
Training loss: 1.487136600887456
Validation loss: 2.383322961960949

Epoch: 5| Step: 7
Training loss: 1.510196520667551
Validation loss: 2.3518166729530843

Epoch: 5| Step: 8
Training loss: 1.7796981476288567
Validation loss: 2.2989841354260863

Epoch: 5| Step: 9
Training loss: 1.9623436008990631
Validation loss: 2.301832582352233

Epoch: 5| Step: 10
Training loss: 1.6745026519061845
Validation loss: 2.3017132788838937

Epoch: 270| Step: 0
Training loss: 1.428185763412394
Validation loss: 2.309770762296692

Epoch: 5| Step: 1
Training loss: 1.053897646677293
Validation loss: 2.380095437301798

Epoch: 5| Step: 2
Training loss: 1.682212032484344
Validation loss: 2.463213890831367

Epoch: 5| Step: 3
Training loss: 1.158442249025953
Validation loss: 2.558402120588628

Epoch: 5| Step: 4
Training loss: 1.7318145134563183
Validation loss: 2.5893709677391126

Epoch: 5| Step: 5
Training loss: 1.7155377975564894
Validation loss: 2.60464279317833

Epoch: 5| Step: 6
Training loss: 1.5954688284233896
Validation loss: 2.50894043376587

Epoch: 5| Step: 7
Training loss: 2.0083603167271056
Validation loss: 2.409172866522793

Epoch: 5| Step: 8
Training loss: 1.5445441979196946
Validation loss: 2.2933498898115046

Epoch: 5| Step: 9
Training loss: 1.376664151650472
Validation loss: 2.2561635438481757

Epoch: 5| Step: 10
Training loss: 1.6784061956389473
Validation loss: 2.2366265534463357

Epoch: 271| Step: 0
Training loss: 1.723616905247064
Validation loss: 2.209382620725203

Epoch: 5| Step: 1
Training loss: 1.3010809384179427
Validation loss: 2.2172991249209617

Epoch: 5| Step: 2
Training loss: 1.6626289891274784
Validation loss: 2.2715144192058774

Epoch: 5| Step: 3
Training loss: 1.4564200338876325
Validation loss: 2.329227732252052

Epoch: 5| Step: 4
Training loss: 1.661297717646941
Validation loss: 2.432912640595704

Epoch: 5| Step: 5
Training loss: 1.6691718664800916
Validation loss: 2.4954718291733937

Epoch: 5| Step: 6
Training loss: 1.4379023113361356
Validation loss: 2.5876943401830794

Epoch: 5| Step: 7
Training loss: 1.9295546760097735
Validation loss: 2.516595918942729

Epoch: 5| Step: 8
Training loss: 1.5237514856971213
Validation loss: 2.433575334250313

Epoch: 5| Step: 9
Training loss: 1.5821646174976776
Validation loss: 2.35618471453563

Epoch: 5| Step: 10
Training loss: 1.300353750368965
Validation loss: 2.2924726469101806

Epoch: 272| Step: 0
Training loss: 1.6767820557589643
Validation loss: 2.2628410074664544

Epoch: 5| Step: 1
Training loss: 1.8683767960342552
Validation loss: 2.262936152332801

Epoch: 5| Step: 2
Training loss: 1.4714922364756318
Validation loss: 2.305200327357716

Epoch: 5| Step: 3
Training loss: 1.6523098412319297
Validation loss: 2.3564616683387514

Epoch: 5| Step: 4
Training loss: 1.4845409902821824
Validation loss: 2.400460755904964

Epoch: 5| Step: 5
Training loss: 1.1677632230754407
Validation loss: 2.4715438398791862

Epoch: 5| Step: 6
Training loss: 1.72896433033286
Validation loss: 2.551347727903185

Epoch: 5| Step: 7
Training loss: 1.6679086428673298
Validation loss: 2.505524036967231

Epoch: 5| Step: 8
Training loss: 1.4336509589232256
Validation loss: 2.378246916007441

Epoch: 5| Step: 9
Training loss: 1.2191720378511446
Validation loss: 2.361181444338622

Epoch: 5| Step: 10
Training loss: 1.5473681347795845
Validation loss: 2.269812287108095

Epoch: 273| Step: 0
Training loss: 1.7158230220836246
Validation loss: 2.2677287732099454

Epoch: 5| Step: 1
Training loss: 1.5996883684898564
Validation loss: 2.2816623208924796

Epoch: 5| Step: 2
Training loss: 1.1928865335708978
Validation loss: 2.2813011890781048

Epoch: 5| Step: 3
Training loss: 1.4978799938369194
Validation loss: 2.3464805333451295

Epoch: 5| Step: 4
Training loss: 1.44006102935953
Validation loss: 2.337691421747295

Epoch: 5| Step: 5
Training loss: 1.4241430617166224
Validation loss: 2.37843990558965

Epoch: 5| Step: 6
Training loss: 1.5609242695504502
Validation loss: 2.4480425843943316

Epoch: 5| Step: 7
Training loss: 1.123002185761659
Validation loss: 2.473871349280041

Epoch: 5| Step: 8
Training loss: 1.4437153007003556
Validation loss: 2.467278447593636

Epoch: 5| Step: 9
Training loss: 1.7368291039870039
Validation loss: 2.4525021165307606

Epoch: 5| Step: 10
Training loss: 1.6100312163602353
Validation loss: 2.4610620048190093

Epoch: 274| Step: 0
Training loss: 1.2432494991937393
Validation loss: 2.3961981953440374

Epoch: 5| Step: 1
Training loss: 1.7619474478255377
Validation loss: 2.369794241709878

Epoch: 5| Step: 2
Training loss: 1.6850451521667598
Validation loss: 2.3002168888858385

Epoch: 5| Step: 3
Training loss: 1.3815062220513041
Validation loss: 2.2661854527062095

Epoch: 5| Step: 4
Training loss: 1.340223875702326
Validation loss: 2.2743573777772736

Epoch: 5| Step: 5
Training loss: 1.5444054204522102
Validation loss: 2.2777203516703852

Epoch: 5| Step: 6
Training loss: 1.4652182138559047
Validation loss: 2.337471125210898

Epoch: 5| Step: 7
Training loss: 1.5320537559649732
Validation loss: 2.3681217238448693

Epoch: 5| Step: 8
Training loss: 1.6337571035521108
Validation loss: 2.3985925594720743

Epoch: 5| Step: 9
Training loss: 1.0552524890052417
Validation loss: 2.424039615258045

Epoch: 5| Step: 10
Training loss: 1.609243072731904
Validation loss: 2.4347245817758356

Epoch: 275| Step: 0
Training loss: 1.323628566960853
Validation loss: 2.4638423237143057

Epoch: 5| Step: 1
Training loss: 1.7981209457293414
Validation loss: 2.4528421960441955

Epoch: 5| Step: 2
Training loss: 1.35899518724983
Validation loss: 2.465288932675303

Epoch: 5| Step: 3
Training loss: 1.58315796466517
Validation loss: 2.405929134919473

Epoch: 5| Step: 4
Training loss: 1.4790513795152114
Validation loss: 2.3569938532844383

Epoch: 5| Step: 5
Training loss: 1.1606038575514075
Validation loss: 2.3194269240385714

Epoch: 5| Step: 6
Training loss: 1.4885549218575553
Validation loss: 2.310440683071293

Epoch: 5| Step: 7
Training loss: 1.1646908593852214
Validation loss: 2.275042819990772

Epoch: 5| Step: 8
Training loss: 1.5447075040410632
Validation loss: 2.308984471639578

Epoch: 5| Step: 9
Training loss: 1.708760657790014
Validation loss: 2.274497322423282

Epoch: 5| Step: 10
Training loss: 1.290205339087144
Validation loss: 2.310401981376291

Epoch: 276| Step: 0
Training loss: 1.5159733951921517
Validation loss: 2.3409021063559243

Epoch: 5| Step: 1
Training loss: 1.6715010465435525
Validation loss: 2.409565006237397

Epoch: 5| Step: 2
Training loss: 1.2765530813516381
Validation loss: 2.4293272312333687

Epoch: 5| Step: 3
Training loss: 1.4697416488532191
Validation loss: 2.4571696517206867

Epoch: 5| Step: 4
Training loss: 1.6336604202800755
Validation loss: 2.4627612576529887

Epoch: 5| Step: 5
Training loss: 1.4445708975501015
Validation loss: 2.4360260999560297

Epoch: 5| Step: 6
Training loss: 1.523648134977755
Validation loss: 2.3814551694439987

Epoch: 5| Step: 7
Training loss: 1.2371025371934687
Validation loss: 2.361414270846517

Epoch: 5| Step: 8
Training loss: 1.399141230477889
Validation loss: 2.3225688397085853

Epoch: 5| Step: 9
Training loss: 1.3745094204437935
Validation loss: 2.3217357972650685

Epoch: 5| Step: 10
Training loss: 1.261718513795813
Validation loss: 2.317552288388698

Epoch: 277| Step: 0
Training loss: 1.3770519464621913
Validation loss: 2.313172335501127

Epoch: 5| Step: 1
Training loss: 1.513442680480774
Validation loss: 2.335274919860764

Epoch: 5| Step: 2
Training loss: 1.727898473534229
Validation loss: 2.3516094680165853

Epoch: 5| Step: 3
Training loss: 1.4278016707272045
Validation loss: 2.3628790161652033

Epoch: 5| Step: 4
Training loss: 1.5108721429995542
Validation loss: 2.403205162896214

Epoch: 5| Step: 5
Training loss: 1.1124265903726864
Validation loss: 2.406403356490727

Epoch: 5| Step: 6
Training loss: 1.143991023865411
Validation loss: 2.4120966147366385

Epoch: 5| Step: 7
Training loss: 1.2142306433539325
Validation loss: 2.435297852610306

Epoch: 5| Step: 8
Training loss: 1.2835266077146539
Validation loss: 2.431699199278259

Epoch: 5| Step: 9
Training loss: 1.8074276421337239
Validation loss: 2.418642794106163

Epoch: 5| Step: 10
Training loss: 1.441841948700463
Validation loss: 2.3791769114087464

Epoch: 278| Step: 0
Training loss: 0.9407069984763704
Validation loss: 2.39029806487173

Epoch: 5| Step: 1
Training loss: 1.583979332630114
Validation loss: 2.3761487362085347

Epoch: 5| Step: 2
Training loss: 1.4345658252248574
Validation loss: 2.3710160808401533

Epoch: 5| Step: 3
Training loss: 1.3252737518237314
Validation loss: 2.3857506733431895

Epoch: 5| Step: 4
Training loss: 1.274452740897132
Validation loss: 2.3963709691237045

Epoch: 5| Step: 5
Training loss: 1.0862774762716094
Validation loss: 2.337724418762197

Epoch: 5| Step: 6
Training loss: 1.555385796994844
Validation loss: 2.308747250041597

Epoch: 5| Step: 7
Training loss: 1.4027630277472993
Validation loss: 2.300889692733779

Epoch: 5| Step: 8
Training loss: 1.751552438154084
Validation loss: 2.321471566901135

Epoch: 5| Step: 9
Training loss: 1.5624154640217676
Validation loss: 2.3691936428452918

Epoch: 5| Step: 10
Training loss: 1.5630035351977454
Validation loss: 2.4300852141670446

Epoch: 279| Step: 0
Training loss: 1.246986045768504
Validation loss: 2.4247812881851596

Epoch: 5| Step: 1
Training loss: 1.3143403910435236
Validation loss: 2.4516796010291904

Epoch: 5| Step: 2
Training loss: 1.5154091592846948
Validation loss: 2.4323944817002667

Epoch: 5| Step: 3
Training loss: 1.6104088582799139
Validation loss: 2.4502084791103975

Epoch: 5| Step: 4
Training loss: 1.6062766314128225
Validation loss: 2.3651070406270005

Epoch: 5| Step: 5
Training loss: 1.297579792119706
Validation loss: 2.375398987705989

Epoch: 5| Step: 6
Training loss: 1.0612501759523352
Validation loss: 2.3904770787878653

Epoch: 5| Step: 7
Training loss: 1.4583013076898785
Validation loss: 2.3900937551698815

Epoch: 5| Step: 8
Training loss: 1.5905882195977437
Validation loss: 2.39954572543395

Epoch: 5| Step: 9
Training loss: 1.6609868384109092
Validation loss: 2.4073719168060106

Epoch: 5| Step: 10
Training loss: 1.4820787839450602
Validation loss: 2.4606639568748356

Epoch: 280| Step: 0
Training loss: 1.0769902214272262
Validation loss: 2.4503411373421864

Epoch: 5| Step: 1
Training loss: 1.4219445850825743
Validation loss: 2.427634893244292

Epoch: 5| Step: 2
Training loss: 1.4276326739491831
Validation loss: 2.4246736232643302

Epoch: 5| Step: 3
Training loss: 1.465442097847873
Validation loss: 2.4134434193828955

Epoch: 5| Step: 4
Training loss: 1.4026620657673743
Validation loss: 2.37965076843638

Epoch: 5| Step: 5
Training loss: 1.3720260884498825
Validation loss: 2.3653119180703444

Epoch: 5| Step: 6
Training loss: 1.2959058886430945
Validation loss: 2.341796318875935

Epoch: 5| Step: 7
Training loss: 1.5633563937266999
Validation loss: 2.3286975432699397

Epoch: 5| Step: 8
Training loss: 1.4594459467435115
Validation loss: 2.3346168888806034

Epoch: 5| Step: 9
Training loss: 1.3315089479862705
Validation loss: 2.3578201013191626

Epoch: 5| Step: 10
Training loss: 1.491797910631514
Validation loss: 2.371548498369622

Epoch: 281| Step: 0
Training loss: 1.6564231638084872
Validation loss: 2.339994302267131

Epoch: 5| Step: 1
Training loss: 1.1960151452186834
Validation loss: 2.3341867864478476

Epoch: 5| Step: 2
Training loss: 1.6122292697950218
Validation loss: 2.304584086082695

Epoch: 5| Step: 3
Training loss: 1.3377968859724843
Validation loss: 2.300156867789099

Epoch: 5| Step: 4
Training loss: 1.4981038506725435
Validation loss: 2.3181147990587894

Epoch: 5| Step: 5
Training loss: 1.3779975122836265
Validation loss: 2.312703230956236

Epoch: 5| Step: 6
Training loss: 0.9122589772818447
Validation loss: 2.3586077155220426

Epoch: 5| Step: 7
Training loss: 1.325277619697794
Validation loss: 2.4412831328163733

Epoch: 5| Step: 8
Training loss: 1.3396952021248163
Validation loss: 2.4707138487361706

Epoch: 5| Step: 9
Training loss: 1.2783000760848107
Validation loss: 2.4982769935250886

Epoch: 5| Step: 10
Training loss: 1.5279561641856259
Validation loss: 2.4793745536089

Epoch: 282| Step: 0
Training loss: 1.2430603511488112
Validation loss: 2.4484308677142863

Epoch: 5| Step: 1
Training loss: 1.4715962528708828
Validation loss: 2.446005898948251

Epoch: 5| Step: 2
Training loss: 1.1959082920005495
Validation loss: 2.390133834013074

Epoch: 5| Step: 3
Training loss: 1.2673357010243502
Validation loss: 2.3551508473120872

Epoch: 5| Step: 4
Training loss: 1.401836590455436
Validation loss: 2.2822035918834795

Epoch: 5| Step: 5
Training loss: 1.504074443973408
Validation loss: 2.2617872526991696

Epoch: 5| Step: 6
Training loss: 1.022575189861801
Validation loss: 2.307804423372992

Epoch: 5| Step: 7
Training loss: 1.6964958736865305
Validation loss: 2.3408249922378794

Epoch: 5| Step: 8
Training loss: 1.3733413402237544
Validation loss: 2.342368495232513

Epoch: 5| Step: 9
Training loss: 1.3320994877047012
Validation loss: 2.4502841543592973

Epoch: 5| Step: 10
Training loss: 1.4014812569264832
Validation loss: 2.5139625103954106

Epoch: 283| Step: 0
Training loss: 1.3876010720495997
Validation loss: 2.529906594590431

Epoch: 5| Step: 1
Training loss: 0.7587204439417764
Validation loss: 2.50048756100755

Epoch: 5| Step: 2
Training loss: 1.368898334913532
Validation loss: 2.499001408150124

Epoch: 5| Step: 3
Training loss: 0.8016467743531692
Validation loss: 2.395338907537675

Epoch: 5| Step: 4
Training loss: 1.4856353227885013
Validation loss: 2.311288934995512

Epoch: 5| Step: 5
Training loss: 1.3852388894117977
Validation loss: 2.3036409816639987

Epoch: 5| Step: 6
Training loss: 1.4259810634281282
Validation loss: 2.311010288847544

Epoch: 5| Step: 7
Training loss: 1.6296547466728257
Validation loss: 2.294305239611926

Epoch: 5| Step: 8
Training loss: 1.6543112870166201
Validation loss: 2.324778530551957

Epoch: 5| Step: 9
Training loss: 1.4841681888464708
Validation loss: 2.3641321708542984

Epoch: 5| Step: 10
Training loss: 1.4618941658006415
Validation loss: 2.4278290713900064

Epoch: 284| Step: 0
Training loss: 1.76623376124774
Validation loss: 2.4403889534606535

Epoch: 5| Step: 1
Training loss: 1.3349933076183578
Validation loss: 2.3950425881957065

Epoch: 5| Step: 2
Training loss: 1.0768612628399317
Validation loss: 2.3539937469748984

Epoch: 5| Step: 3
Training loss: 1.2785693247398
Validation loss: 2.316421815024815

Epoch: 5| Step: 4
Training loss: 1.3944128504479965
Validation loss: 2.3313203004378926

Epoch: 5| Step: 5
Training loss: 1.3092007723679262
Validation loss: 2.3742337234740205

Epoch: 5| Step: 6
Training loss: 1.3073145749135409
Validation loss: 2.438262410035944

Epoch: 5| Step: 7
Training loss: 1.3779249725152987
Validation loss: 2.4044203069755796

Epoch: 5| Step: 8
Training loss: 1.2821287537667
Validation loss: 2.3687311272439273

Epoch: 5| Step: 9
Training loss: 1.0957313030787945
Validation loss: 2.302767811693644

Epoch: 5| Step: 10
Training loss: 1.5011333316695965
Validation loss: 2.269033095678956

Epoch: 285| Step: 0
Training loss: 1.3947708394226572
Validation loss: 2.262330823828156

Epoch: 5| Step: 1
Training loss: 1.3409765587307516
Validation loss: 2.259270416858844

Epoch: 5| Step: 2
Training loss: 1.0087985751948931
Validation loss: 2.3074702089609698

Epoch: 5| Step: 3
Training loss: 1.2750918635765354
Validation loss: 2.3639726441527036

Epoch: 5| Step: 4
Training loss: 1.531208349167474
Validation loss: 2.4037967263402304

Epoch: 5| Step: 5
Training loss: 1.4724487644213042
Validation loss: 2.4502795968352347

Epoch: 5| Step: 6
Training loss: 1.077985837496579
Validation loss: 2.478668761275899

Epoch: 5| Step: 7
Training loss: 1.2138422428676918
Validation loss: 2.421645704007507

Epoch: 5| Step: 8
Training loss: 1.6568443383567448
Validation loss: 2.395973985421377

Epoch: 5| Step: 9
Training loss: 1.4391487451942093
Validation loss: 2.3043920595612666

Epoch: 5| Step: 10
Training loss: 1.3469739873140127
Validation loss: 2.2490341701141676

Epoch: 286| Step: 0
Training loss: 0.9921394396578584
Validation loss: 2.2148383121453024

Epoch: 5| Step: 1
Training loss: 1.772407333362124
Validation loss: 2.227620976363601

Epoch: 5| Step: 2
Training loss: 1.3853621603585806
Validation loss: 2.2593023317844305

Epoch: 5| Step: 3
Training loss: 0.9945653221844495
Validation loss: 2.3299380208742875

Epoch: 5| Step: 4
Training loss: 1.2684558245492856
Validation loss: 2.3674406440651468

Epoch: 5| Step: 5
Training loss: 1.4149142066099452
Validation loss: 2.4544731711370793

Epoch: 5| Step: 6
Training loss: 1.369738830398327
Validation loss: 2.5020215956583827

Epoch: 5| Step: 7
Training loss: 1.0786042184997262
Validation loss: 2.483258722603182

Epoch: 5| Step: 8
Training loss: 1.6087582341526583
Validation loss: 2.4391462090499405

Epoch: 5| Step: 9
Training loss: 1.1365810455076233
Validation loss: 2.3734558571378566

Epoch: 5| Step: 10
Training loss: 1.3136659620357838
Validation loss: 2.3331512517099853

Epoch: 287| Step: 0
Training loss: 1.0769161689845903
Validation loss: 2.352619601690039

Epoch: 5| Step: 1
Training loss: 1.305315882865864
Validation loss: 2.356169982327875

Epoch: 5| Step: 2
Training loss: 1.193606836412273
Validation loss: 2.383320246998372

Epoch: 5| Step: 3
Training loss: 1.6762733003844532
Validation loss: 2.365824902302628

Epoch: 5| Step: 4
Training loss: 1.239432584855067
Validation loss: 2.4313003330264933

Epoch: 5| Step: 5
Training loss: 1.202456746979037
Validation loss: 2.4368013801177693

Epoch: 5| Step: 6
Training loss: 1.6323993653011795
Validation loss: 2.463971682162197

Epoch: 5| Step: 7
Training loss: 1.0876717749672578
Validation loss: 2.4057493867692132

Epoch: 5| Step: 8
Training loss: 1.4455969453258994
Validation loss: 2.3663609736087867

Epoch: 5| Step: 9
Training loss: 1.1011956868975081
Validation loss: 2.332428110194353

Epoch: 5| Step: 10
Training loss: 1.3340224432365588
Validation loss: 2.3134217879260306

Epoch: 288| Step: 0
Training loss: 1.4905204848270577
Validation loss: 2.339153918286615

Epoch: 5| Step: 1
Training loss: 0.9887896651113697
Validation loss: 2.3507441620770964

Epoch: 5| Step: 2
Training loss: 1.1868763842180405
Validation loss: 2.308047892604929

Epoch: 5| Step: 3
Training loss: 1.468673785241033
Validation loss: 2.3493261976686934

Epoch: 5| Step: 4
Training loss: 0.9044200574384317
Validation loss: 2.309079000841547

Epoch: 5| Step: 5
Training loss: 1.2860625992989185
Validation loss: 2.3343908133769222

Epoch: 5| Step: 6
Training loss: 0.8237188188037694
Validation loss: 2.3852398818465237

Epoch: 5| Step: 7
Training loss: 1.5132559912547379
Validation loss: 2.385462736344135

Epoch: 5| Step: 8
Training loss: 1.4430558191290428
Validation loss: 2.419792685317526

Epoch: 5| Step: 9
Training loss: 1.3783791374766448
Validation loss: 2.4084836716268807

Epoch: 5| Step: 10
Training loss: 1.33229004256105
Validation loss: 2.37706271514905

Epoch: 289| Step: 0
Training loss: 0.8066989609727354
Validation loss: 2.356786501980868

Epoch: 5| Step: 1
Training loss: 0.8575822684525106
Validation loss: 2.3621113640186793

Epoch: 5| Step: 2
Training loss: 1.571131478439451
Validation loss: 2.3561110025239396

Epoch: 5| Step: 3
Training loss: 1.0666659531491596
Validation loss: 2.3539759244391014

Epoch: 5| Step: 4
Training loss: 1.2536631315797317
Validation loss: 2.3562661001630736

Epoch: 5| Step: 5
Training loss: 1.4877721361254794
Validation loss: 2.316298747318093

Epoch: 5| Step: 6
Training loss: 1.6804275656618703
Validation loss: 2.3652434980373793

Epoch: 5| Step: 7
Training loss: 0.9662152939716163
Validation loss: 2.335034666666367

Epoch: 5| Step: 8
Training loss: 1.351190681249444
Validation loss: 2.423317360718786

Epoch: 5| Step: 9
Training loss: 1.1710495648436994
Validation loss: 2.429992234618406

Epoch: 5| Step: 10
Training loss: 1.4053257766106662
Validation loss: 2.447780441092864

Epoch: 290| Step: 0
Training loss: 1.4919619564544688
Validation loss: 2.4497594874789317

Epoch: 5| Step: 1
Training loss: 1.02545003083125
Validation loss: 2.428651607133829

Epoch: 5| Step: 2
Training loss: 1.2491474104998854
Validation loss: 2.4124369885989356

Epoch: 5| Step: 3
Training loss: 0.9326481838967159
Validation loss: 2.3557084128170644

Epoch: 5| Step: 4
Training loss: 1.1890734237189178
Validation loss: 2.311761890716044

Epoch: 5| Step: 5
Training loss: 1.496123151764169
Validation loss: 2.306678311746354

Epoch: 5| Step: 6
Training loss: 1.3876957849747393
Validation loss: 2.3312710959974936

Epoch: 5| Step: 7
Training loss: 1.1075436156835898
Validation loss: 2.3611926937144014

Epoch: 5| Step: 8
Training loss: 1.1850554250479113
Validation loss: 2.3552627610814256

Epoch: 5| Step: 9
Training loss: 1.096828977048607
Validation loss: 2.3504332283595115

Epoch: 5| Step: 10
Training loss: 1.5438663238066637
Validation loss: 2.3547234696658643

Epoch: 291| Step: 0
Training loss: 1.3483887381815234
Validation loss: 2.3737725311785747

Epoch: 5| Step: 1
Training loss: 1.353772291808313
Validation loss: 2.380822726812589

Epoch: 5| Step: 2
Training loss: 1.3461137430274903
Validation loss: 2.373636160693903

Epoch: 5| Step: 3
Training loss: 1.1344074465312204
Validation loss: 2.324007216358388

Epoch: 5| Step: 4
Training loss: 0.8260753746579312
Validation loss: 2.3744494118937487

Epoch: 5| Step: 5
Training loss: 1.1033897665713994
Validation loss: 2.3409295134374917

Epoch: 5| Step: 6
Training loss: 1.1815077525694504
Validation loss: 2.309514474001904

Epoch: 5| Step: 7
Training loss: 1.2899162470812797
Validation loss: 2.3144523573874545

Epoch: 5| Step: 8
Training loss: 1.214661808434104
Validation loss: 2.330614839079036

Epoch: 5| Step: 9
Training loss: 1.3464358346200396
Validation loss: 2.3201665720885094

Epoch: 5| Step: 10
Training loss: 1.4131507674124135
Validation loss: 2.3464454595878936

Epoch: 292| Step: 0
Training loss: 1.4809421396434366
Validation loss: 2.3078062851685277

Epoch: 5| Step: 1
Training loss: 0.7357537333749873
Validation loss: 2.3584097197168163

Epoch: 5| Step: 2
Training loss: 0.8721392050055512
Validation loss: 2.381587518425886

Epoch: 5| Step: 3
Training loss: 1.2661016532108007
Validation loss: 2.421925379414034

Epoch: 5| Step: 4
Training loss: 0.8461957030013891
Validation loss: 2.393205318653246

Epoch: 5| Step: 5
Training loss: 1.3249147549684261
Validation loss: 2.404247397217938

Epoch: 5| Step: 6
Training loss: 1.3046629212399927
Validation loss: 2.400396174372342

Epoch: 5| Step: 7
Training loss: 1.11744126858938
Validation loss: 2.401478919481503

Epoch: 5| Step: 8
Training loss: 1.4896094135411062
Validation loss: 2.3864609325461723

Epoch: 5| Step: 9
Training loss: 1.5840938732526975
Validation loss: 2.3614073683511845

Epoch: 5| Step: 10
Training loss: 1.194822821949531
Validation loss: 2.2854034242470607

Epoch: 293| Step: 0
Training loss: 1.3932329219399109
Validation loss: 2.2639982160330536

Epoch: 5| Step: 1
Training loss: 1.2424128585897967
Validation loss: 2.25778452452848

Epoch: 5| Step: 2
Training loss: 1.1745898525187481
Validation loss: 2.2543722419452727

Epoch: 5| Step: 3
Training loss: 1.434576960289226
Validation loss: 2.3110569728295793

Epoch: 5| Step: 4
Training loss: 1.2825126009316485
Validation loss: 2.36728096886453

Epoch: 5| Step: 5
Training loss: 1.1825747998151737
Validation loss: 2.4499979346046676

Epoch: 5| Step: 6
Training loss: 1.2880823281377123
Validation loss: 2.49125775169877

Epoch: 5| Step: 7
Training loss: 1.2227052428938305
Validation loss: 2.529473835540814

Epoch: 5| Step: 8
Training loss: 1.401622618679758
Validation loss: 2.438454391977503

Epoch: 5| Step: 9
Training loss: 1.0862295732234688
Validation loss: 2.3619183828978336

Epoch: 5| Step: 10
Training loss: 1.0111842566245466
Validation loss: 2.3171469469064743

Epoch: 294| Step: 0
Training loss: 1.1483543002554133
Validation loss: 2.2973651397900863

Epoch: 5| Step: 1
Training loss: 1.0267055255071302
Validation loss: 2.2667556962441746

Epoch: 5| Step: 2
Training loss: 1.285551109063575
Validation loss: 2.298786590318327

Epoch: 5| Step: 3
Training loss: 0.9849123623390775
Validation loss: 2.3769322443607557

Epoch: 5| Step: 4
Training loss: 1.409707122037012
Validation loss: 2.4779371092632405

Epoch: 5| Step: 5
Training loss: 1.5175214091617963
Validation loss: 2.5346638168241626

Epoch: 5| Step: 6
Training loss: 1.3828831886284225
Validation loss: 2.4412242114382963

Epoch: 5| Step: 7
Training loss: 1.1868578529826752
Validation loss: 2.358046687671385

Epoch: 5| Step: 8
Training loss: 1.3755508533202945
Validation loss: 2.300227779961851

Epoch: 5| Step: 9
Training loss: 1.2418841105464349
Validation loss: 2.250702311973228

Epoch: 5| Step: 10
Training loss: 1.0762842469299243
Validation loss: 2.252141870768448

Epoch: 295| Step: 0
Training loss: 1.0200068508179918
Validation loss: 2.2496726437134758

Epoch: 5| Step: 1
Training loss: 1.5868517866386194
Validation loss: 2.2950056760939708

Epoch: 5| Step: 2
Training loss: 1.3352947808323596
Validation loss: 2.3581426931363736

Epoch: 5| Step: 3
Training loss: 1.111786813053129
Validation loss: 2.3935579392358903

Epoch: 5| Step: 4
Training loss: 1.1049308411717826
Validation loss: 2.4382285246000808

Epoch: 5| Step: 5
Training loss: 0.9812227063118847
Validation loss: 2.4674231506103914

Epoch: 5| Step: 6
Training loss: 1.1296571128631077
Validation loss: 2.520504100544281

Epoch: 5| Step: 7
Training loss: 1.1546311773828934
Validation loss: 2.5271548637262016

Epoch: 5| Step: 8
Training loss: 0.9981847619287916
Validation loss: 2.469136668493614

Epoch: 5| Step: 9
Training loss: 1.2736735212971393
Validation loss: 2.439586996488008

Epoch: 5| Step: 10
Training loss: 1.4495996349997409
Validation loss: 2.396145299973268

Epoch: 296| Step: 0
Training loss: 1.2040582975487002
Validation loss: 2.3297179980550795

Epoch: 5| Step: 1
Training loss: 1.1904281854033283
Validation loss: 2.293667488305098

Epoch: 5| Step: 2
Training loss: 0.9892564267057483
Validation loss: 2.273821120489858

Epoch: 5| Step: 3
Training loss: 1.0925562747629363
Validation loss: 2.252406079167286

Epoch: 5| Step: 4
Training loss: 1.1455347654744148
Validation loss: 2.294634071513905

Epoch: 5| Step: 5
Training loss: 1.5434415841227174
Validation loss: 2.3495429603657403

Epoch: 5| Step: 6
Training loss: 1.1408121660905317
Validation loss: 2.448870376524101

Epoch: 5| Step: 7
Training loss: 1.5049561638008457
Validation loss: 2.531207029726631

Epoch: 5| Step: 8
Training loss: 1.4996315980552906
Validation loss: 2.5649266352021582

Epoch: 5| Step: 9
Training loss: 0.9871162513943252
Validation loss: 2.4648592450990865

Epoch: 5| Step: 10
Training loss: 0.892909082536861
Validation loss: 2.377884734711498

Epoch: 297| Step: 0
Training loss: 1.3958704312457195
Validation loss: 2.3255468026555293

Epoch: 5| Step: 1
Training loss: 0.7748161128523701
Validation loss: 2.2567218766905337

Epoch: 5| Step: 2
Training loss: 1.1340652904754727
Validation loss: 2.2690799993039272

Epoch: 5| Step: 3
Training loss: 1.0081322332833382
Validation loss: 2.2729038313695216

Epoch: 5| Step: 4
Training loss: 1.3299661776895748
Validation loss: 2.2997240215278785

Epoch: 5| Step: 5
Training loss: 1.4744281177404157
Validation loss: 2.3851501408014415

Epoch: 5| Step: 6
Training loss: 1.197594403028055
Validation loss: 2.4232100285447222

Epoch: 5| Step: 7
Training loss: 1.09263935919948
Validation loss: 2.472632301965107

Epoch: 5| Step: 8
Training loss: 1.2337286500329931
Validation loss: 2.4886810099580785

Epoch: 5| Step: 9
Training loss: 1.111427503811901
Validation loss: 2.421788805096957

Epoch: 5| Step: 10
Training loss: 1.3092558594900887
Validation loss: 2.33298708358022

Epoch: 298| Step: 0
Training loss: 1.0937270025832815
Validation loss: 2.3466121367925865

Epoch: 5| Step: 1
Training loss: 1.2662342159420972
Validation loss: 2.3612042030699896

Epoch: 5| Step: 2
Training loss: 1.6316871963368018
Validation loss: 2.36317913201245

Epoch: 5| Step: 3
Training loss: 1.053698719084628
Validation loss: 2.3735264090941435

Epoch: 5| Step: 4
Training loss: 0.9666322818483303
Validation loss: 2.350930023090524

Epoch: 5| Step: 5
Training loss: 1.0766255552652952
Validation loss: 2.365900561179219

Epoch: 5| Step: 6
Training loss: 1.3227961277551212
Validation loss: 2.360952968135065

Epoch: 5| Step: 7
Training loss: 1.1012502998931857
Validation loss: 2.3774933057241596

Epoch: 5| Step: 8
Training loss: 1.215059807015788
Validation loss: 2.3999042713649636

Epoch: 5| Step: 9
Training loss: 0.8542863521616832
Validation loss: 2.4212212946933933

Epoch: 5| Step: 10
Training loss: 1.2383664941176973
Validation loss: 2.438944571272219

Epoch: 299| Step: 0
Training loss: 1.2994195265707396
Validation loss: 2.417222422330626

Epoch: 5| Step: 1
Training loss: 1.1395888652120962
Validation loss: 2.414110689192972

Epoch: 5| Step: 2
Training loss: 1.3701910541441173
Validation loss: 2.3853142660791478

Epoch: 5| Step: 3
Training loss: 0.9208885022433473
Validation loss: 2.3721905484160355

Epoch: 5| Step: 4
Training loss: 1.0505137617143958
Validation loss: 2.350075773930085

Epoch: 5| Step: 5
Training loss: 1.1011161170312762
Validation loss: 2.396699513587042

Epoch: 5| Step: 6
Training loss: 1.117754438906366
Validation loss: 2.4599127127222107

Epoch: 5| Step: 7
Training loss: 1.1863609673680304
Validation loss: 2.475018258274483

Epoch: 5| Step: 8
Training loss: 1.1007989171318062
Validation loss: 2.434355800603026

Epoch: 5| Step: 9
Training loss: 1.096885872376727
Validation loss: 2.405523106477892

Epoch: 5| Step: 10
Training loss: 1.309616327010733
Validation loss: 2.3284198039996857

Epoch: 300| Step: 0
Training loss: 1.1069095240442468
Validation loss: 2.410738824356058

Epoch: 5| Step: 1
Training loss: 1.2682488170357331
Validation loss: 2.4328400309776024

Epoch: 5| Step: 2
Training loss: 1.3062605825479205
Validation loss: 2.446099308415936

Epoch: 5| Step: 3
Training loss: 0.8153829778210511
Validation loss: 2.4285873931278346

Epoch: 5| Step: 4
Training loss: 1.204854687915773
Validation loss: 2.455161740502766

Epoch: 5| Step: 5
Training loss: 1.0349633954895974
Validation loss: 2.349813037094846

Epoch: 5| Step: 6
Training loss: 1.410163097417802
Validation loss: 2.2879983842868983

Epoch: 5| Step: 7
Training loss: 1.0231664167537364
Validation loss: 2.2611639916710287

Epoch: 5| Step: 8
Training loss: 1.3724871996506764
Validation loss: 2.285898786025244

Epoch: 5| Step: 9
Training loss: 1.153787671648941
Validation loss: 2.3113818559788966

Epoch: 5| Step: 10
Training loss: 1.0253448766766302
Validation loss: 2.3403363871735885

Epoch: 301| Step: 0
Training loss: 1.110566909292668
Validation loss: 2.3936151341488285

Epoch: 5| Step: 1
Training loss: 1.083631028329651
Validation loss: 2.4462744820323836

Epoch: 5| Step: 2
Training loss: 1.339967727486017
Validation loss: 2.4231968993210478

Epoch: 5| Step: 3
Training loss: 1.0263271160633292
Validation loss: 2.3657492513010565

Epoch: 5| Step: 4
Training loss: 1.011363552588361
Validation loss: 2.3901408991722164

Epoch: 5| Step: 5
Training loss: 1.0815147516776245
Validation loss: 2.395908044949369

Epoch: 5| Step: 6
Training loss: 0.9850064628892512
Validation loss: 2.418047180923529

Epoch: 5| Step: 7
Training loss: 1.189801846202778
Validation loss: 2.3786169391084613

Epoch: 5| Step: 8
Training loss: 1.1201361311197806
Validation loss: 2.3978297970919713

Epoch: 5| Step: 9
Training loss: 1.4963332499940787
Validation loss: 2.3819316385043456

Epoch: 5| Step: 10
Training loss: 0.9728276358363469
Validation loss: 2.349179217229995

Epoch: 302| Step: 0
Training loss: 1.1903686007065608
Validation loss: 2.3695905058921336

Epoch: 5| Step: 1
Training loss: 1.155302845442748
Validation loss: 2.3649573428534056

Epoch: 5| Step: 2
Training loss: 1.1223836250555812
Validation loss: 2.346002504011842

Epoch: 5| Step: 3
Training loss: 0.8868667210198545
Validation loss: 2.3395456424152417

Epoch: 5| Step: 4
Training loss: 0.9238814808315372
Validation loss: 2.3675550090722357

Epoch: 5| Step: 5
Training loss: 0.9997611654697409
Validation loss: 2.410670206926053

Epoch: 5| Step: 6
Training loss: 1.0339152256433497
Validation loss: 2.3702246903971855

Epoch: 5| Step: 7
Training loss: 1.3566311735685652
Validation loss: 2.4147789180110997

Epoch: 5| Step: 8
Training loss: 1.2112184752307469
Validation loss: 2.3998983533844838

Epoch: 5| Step: 9
Training loss: 1.2065692498908236
Validation loss: 2.358343840982609

Epoch: 5| Step: 10
Training loss: 1.097274170757734
Validation loss: 2.3862008901696714

Epoch: 303| Step: 0
Training loss: 0.7989686501909099
Validation loss: 2.4294772147313983

Epoch: 5| Step: 1
Training loss: 0.7170956272295672
Validation loss: 2.393282379644646

Epoch: 5| Step: 2
Training loss: 1.0457110980716366
Validation loss: 2.439820879324864

Epoch: 5| Step: 3
Training loss: 1.151688832531135
Validation loss: 2.4230269191760825

Epoch: 5| Step: 4
Training loss: 1.268686007309341
Validation loss: 2.4234603398272907

Epoch: 5| Step: 5
Training loss: 1.2134314174534035
Validation loss: 2.392480788219178

Epoch: 5| Step: 6
Training loss: 1.0043614761780877
Validation loss: 2.371600791641446

Epoch: 5| Step: 7
Training loss: 1.2787954498000058
Validation loss: 2.3413762958267754

Epoch: 5| Step: 8
Training loss: 1.030044891897601
Validation loss: 2.2991963784734075

Epoch: 5| Step: 9
Training loss: 1.2380032874203915
Validation loss: 2.295576575594037

Epoch: 5| Step: 10
Training loss: 1.3431437699544968
Validation loss: 2.3058232460367756

Epoch: 304| Step: 0
Training loss: 0.8882237908157526
Validation loss: 2.287284852118833

Epoch: 5| Step: 1
Training loss: 1.2914130772054202
Validation loss: 2.317122728163308

Epoch: 5| Step: 2
Training loss: 0.9369293383414039
Validation loss: 2.3812370074499634

Epoch: 5| Step: 3
Training loss: 0.6883099076954752
Validation loss: 2.4201931022657384

Epoch: 5| Step: 4
Training loss: 1.0056089811785884
Validation loss: 2.4225066346763704

Epoch: 5| Step: 5
Training loss: 1.144308647928094
Validation loss: 2.4139317531099698

Epoch: 5| Step: 6
Training loss: 1.313255592109165
Validation loss: 2.393807784335447

Epoch: 5| Step: 7
Training loss: 1.1454234632834153
Validation loss: 2.3427201686352928

Epoch: 5| Step: 8
Training loss: 1.2701418303343288
Validation loss: 2.3218922404530806

Epoch: 5| Step: 9
Training loss: 1.1949284753183802
Validation loss: 2.308901399413861

Epoch: 5| Step: 10
Training loss: 1.2593882860566723
Validation loss: 2.396113256194272

Epoch: 305| Step: 0
Training loss: 0.8386982402379614
Validation loss: 2.4349069604405

Epoch: 5| Step: 1
Training loss: 0.8605687260288588
Validation loss: 2.4750674347833352

Epoch: 5| Step: 2
Training loss: 1.174018527058594
Validation loss: 2.482108340740932

Epoch: 5| Step: 3
Training loss: 0.9379806240231928
Validation loss: 2.3821725551846726

Epoch: 5| Step: 4
Training loss: 1.424550400463277
Validation loss: 2.3721421474218967

Epoch: 5| Step: 5
Training loss: 1.1341031844408975
Validation loss: 2.363764554759152

Epoch: 5| Step: 6
Training loss: 1.0506935508462574
Validation loss: 2.3531808192824344

Epoch: 5| Step: 7
Training loss: 1.171831460779725
Validation loss: 2.3514183413699628

Epoch: 5| Step: 8
Training loss: 1.0973477184512321
Validation loss: 2.3529594234249744

Epoch: 5| Step: 9
Training loss: 0.9673578041520973
Validation loss: 2.392160558268538

Epoch: 5| Step: 10
Training loss: 1.3337926768774702
Validation loss: 2.4075627362529106

Epoch: 306| Step: 0
Training loss: 1.3421923458558114
Validation loss: 2.400728934905907

Epoch: 5| Step: 1
Training loss: 1.1174336409014352
Validation loss: 2.4180514360773238

Epoch: 5| Step: 2
Training loss: 1.0422348126105314
Validation loss: 2.409574605115072

Epoch: 5| Step: 3
Training loss: 0.7072174080101079
Validation loss: 2.3554336930800712

Epoch: 5| Step: 4
Training loss: 1.191665020966005
Validation loss: 2.380874980592818

Epoch: 5| Step: 5
Training loss: 1.0634958424847847
Validation loss: 2.343031699746624

Epoch: 5| Step: 6
Training loss: 1.1021582433172075
Validation loss: 2.3152619164672497

Epoch: 5| Step: 7
Training loss: 1.1718369032707268
Validation loss: 2.298190157450879

Epoch: 5| Step: 8
Training loss: 1.214099815708351
Validation loss: 2.2910286556882133

Epoch: 5| Step: 9
Training loss: 0.8956626500310678
Validation loss: 2.27516924045925

Epoch: 5| Step: 10
Training loss: 0.9255797412324415
Validation loss: 2.2997865230491854

Epoch: 307| Step: 0
Training loss: 0.8521236005997943
Validation loss: 2.3236887133648496

Epoch: 5| Step: 1
Training loss: 1.3140092981842715
Validation loss: 2.3801801327153833

Epoch: 5| Step: 2
Training loss: 1.0121175797312834
Validation loss: 2.4253698574179325

Epoch: 5| Step: 3
Training loss: 0.6848627573204674
Validation loss: 2.468677297975217

Epoch: 5| Step: 4
Training loss: 1.2662640594726176
Validation loss: 2.4479361232035837

Epoch: 5| Step: 5
Training loss: 0.8418336227432607
Validation loss: 2.412423729545016

Epoch: 5| Step: 6
Training loss: 1.2270458751114364
Validation loss: 2.410152854723585

Epoch: 5| Step: 7
Training loss: 1.072424704836351
Validation loss: 2.356185223741755

Epoch: 5| Step: 8
Training loss: 1.2116387090557765
Validation loss: 2.3090354222510814

Epoch: 5| Step: 9
Training loss: 1.0252386652653152
Validation loss: 2.2767483286357417

Epoch: 5| Step: 10
Training loss: 1.0766867844106514
Validation loss: 2.261729230811645

Epoch: 308| Step: 0
Training loss: 1.132107482407354
Validation loss: 2.3073541702259663

Epoch: 5| Step: 1
Training loss: 1.2517090558029162
Validation loss: 2.319661606795679

Epoch: 5| Step: 2
Training loss: 0.7291550680782094
Validation loss: 2.3948567829654133

Epoch: 5| Step: 3
Training loss: 1.1541513522310718
Validation loss: 2.401574736548161

Epoch: 5| Step: 4
Training loss: 0.8590089885521164
Validation loss: 2.444677221175495

Epoch: 5| Step: 5
Training loss: 1.0240759568877027
Validation loss: 2.441027249228037

Epoch: 5| Step: 6
Training loss: 0.957516605541967
Validation loss: 2.410550286567409

Epoch: 5| Step: 7
Training loss: 0.8063880580423738
Validation loss: 2.3790952836829256

Epoch: 5| Step: 8
Training loss: 1.144171023396428
Validation loss: 2.311329637188562

Epoch: 5| Step: 9
Training loss: 1.2325817554587486
Validation loss: 2.274813636246714

Epoch: 5| Step: 10
Training loss: 1.273673240512541
Validation loss: 2.319432873257269

Epoch: 309| Step: 0
Training loss: 0.7608915091839105
Validation loss: 2.3081212080419236

Epoch: 5| Step: 1
Training loss: 1.1316942154214285
Validation loss: 2.3313256953235304

Epoch: 5| Step: 2
Training loss: 0.8064863228250114
Validation loss: 2.343693489295837

Epoch: 5| Step: 3
Training loss: 1.3089845899253312
Validation loss: 2.3421424220033376

Epoch: 5| Step: 4
Training loss: 1.0089902870988594
Validation loss: 2.333715910318612

Epoch: 5| Step: 5
Training loss: 1.0271536647607769
Validation loss: 2.3397538198327408

Epoch: 5| Step: 6
Training loss: 1.0042896058313964
Validation loss: 2.319461172871004

Epoch: 5| Step: 7
Training loss: 0.9653862420365625
Validation loss: 2.3627747856347328

Epoch: 5| Step: 8
Training loss: 0.975803415918675
Validation loss: 2.346929366695913

Epoch: 5| Step: 9
Training loss: 1.1245926013370058
Validation loss: 2.414261818697171

Epoch: 5| Step: 10
Training loss: 1.1830097432126292
Validation loss: 2.4156916624285394

Epoch: 310| Step: 0
Training loss: 1.1480328632030539
Validation loss: 2.406325718498477

Epoch: 5| Step: 1
Training loss: 1.1235977546664029
Validation loss: 2.422026092759569

Epoch: 5| Step: 2
Training loss: 1.071685467303475
Validation loss: 2.4006494474856264

Epoch: 5| Step: 3
Training loss: 1.2163720039736121
Validation loss: 2.3886905483931673

Epoch: 5| Step: 4
Training loss: 0.968315026859263
Validation loss: 2.3773376389495438

Epoch: 5| Step: 5
Training loss: 0.904560553253489
Validation loss: 2.3952912440076384

Epoch: 5| Step: 6
Training loss: 0.6726669700556973
Validation loss: 2.382911236548188

Epoch: 5| Step: 7
Training loss: 1.0988457909881788
Validation loss: 2.3562210550383003

Epoch: 5| Step: 8
Training loss: 0.8530683589479491
Validation loss: 2.3214459808383747

Epoch: 5| Step: 9
Training loss: 1.0778256429178943
Validation loss: 2.3186476909741938

Epoch: 5| Step: 10
Training loss: 1.0761708226692053
Validation loss: 2.262069926803496

Epoch: 311| Step: 0
Training loss: 1.0451763092867163
Validation loss: 2.2412797238533484

Epoch: 5| Step: 1
Training loss: 0.8682640884842465
Validation loss: 2.28802840940747

Epoch: 5| Step: 2
Training loss: 1.0453292480404328
Validation loss: 2.347612389410103

Epoch: 5| Step: 3
Training loss: 0.7724288760161485
Validation loss: 2.357505492839261

Epoch: 5| Step: 4
Training loss: 0.8636895849516192
Validation loss: 2.413199884737031

Epoch: 5| Step: 5
Training loss: 0.9888078093478072
Validation loss: 2.4444871878064287

Epoch: 5| Step: 6
Training loss: 0.9045641773877537
Validation loss: 2.459769781575039

Epoch: 5| Step: 7
Training loss: 1.0984423663057326
Validation loss: 2.3936559562209347

Epoch: 5| Step: 8
Training loss: 1.2031381284319482
Validation loss: 2.3288342423159443

Epoch: 5| Step: 9
Training loss: 1.458593926534453
Validation loss: 2.3150792591807363

Epoch: 5| Step: 10
Training loss: 1.0455874025981102
Validation loss: 2.26057940988337

Epoch: 312| Step: 0
Training loss: 0.7781327427245224
Validation loss: 2.2657868064099316

Epoch: 5| Step: 1
Training loss: 0.6949586074838929
Validation loss: 2.305114091478573

Epoch: 5| Step: 2
Training loss: 0.9915426666940386
Validation loss: 2.3293486090776936

Epoch: 5| Step: 3
Training loss: 0.9783657667339172
Validation loss: 2.3401002573657994

Epoch: 5| Step: 4
Training loss: 1.13604333481607
Validation loss: 2.3407628099909537

Epoch: 5| Step: 5
Training loss: 1.0560063910724404
Validation loss: 2.356534372878357

Epoch: 5| Step: 6
Training loss: 1.1297537186711888
Validation loss: 2.3945835065466814

Epoch: 5| Step: 7
Training loss: 0.9128009208511568
Validation loss: 2.352429541733534

Epoch: 5| Step: 8
Training loss: 1.2283840381883342
Validation loss: 2.377666364795512

Epoch: 5| Step: 9
Training loss: 1.103170101119122
Validation loss: 2.3304395735786447

Epoch: 5| Step: 10
Training loss: 1.2116809162699491
Validation loss: 2.344656612373435

Epoch: 313| Step: 0
Training loss: 1.363419315375121
Validation loss: 2.3213637620717735

Epoch: 5| Step: 1
Training loss: 1.0506428340235603
Validation loss: 2.3396430480648474

Epoch: 5| Step: 2
Training loss: 1.0693735055115967
Validation loss: 2.393035529125687

Epoch: 5| Step: 3
Training loss: 0.6846461233697478
Validation loss: 2.384049857224094

Epoch: 5| Step: 4
Training loss: 1.2666419852930684
Validation loss: 2.404554028016403

Epoch: 5| Step: 5
Training loss: 0.8253800947074555
Validation loss: 2.414967480230368

Epoch: 5| Step: 6
Training loss: 0.7194219433724158
Validation loss: 2.4037005291033173

Epoch: 5| Step: 7
Training loss: 0.9531321916152545
Validation loss: 2.4277296178023025

Epoch: 5| Step: 8
Training loss: 0.9988624838363653
Validation loss: 2.401115093550325

Epoch: 5| Step: 9
Training loss: 1.147186895883142
Validation loss: 2.3528656743685956

Epoch: 5| Step: 10
Training loss: 0.7644693254987073
Validation loss: 2.3928576687040555

Epoch: 314| Step: 0
Training loss: 1.1398078918045935
Validation loss: 2.354748230353554

Epoch: 5| Step: 1
Training loss: 1.0395463089602601
Validation loss: 2.3525699573317036

Epoch: 5| Step: 2
Training loss: 0.7789585459456282
Validation loss: 2.3052006087220005

Epoch: 5| Step: 3
Training loss: 1.1034552903687183
Validation loss: 2.3254168105617117

Epoch: 5| Step: 4
Training loss: 1.0925965357713492
Validation loss: 2.3176195489668645

Epoch: 5| Step: 5
Training loss: 1.1108147318590147
Validation loss: 2.300120101822962

Epoch: 5| Step: 6
Training loss: 0.8515675045881289
Validation loss: 2.3351276363057805

Epoch: 5| Step: 7
Training loss: 1.1110924871526309
Validation loss: 2.3562202841684856

Epoch: 5| Step: 8
Training loss: 0.9110032098799433
Validation loss: 2.331680344830261

Epoch: 5| Step: 9
Training loss: 0.7111942121217658
Validation loss: 2.394334568446331

Epoch: 5| Step: 10
Training loss: 0.9954536026565787
Validation loss: 2.3842199640801116

Epoch: 315| Step: 0
Training loss: 0.9700052681022816
Validation loss: 2.3981503422319985

Epoch: 5| Step: 1
Training loss: 0.8284348681856684
Validation loss: 2.3650471753370446

Epoch: 5| Step: 2
Training loss: 1.2495558426442628
Validation loss: 2.336740787308234

Epoch: 5| Step: 3
Training loss: 0.780237610033807
Validation loss: 2.3163785660434155

Epoch: 5| Step: 4
Training loss: 0.7207482383275144
Validation loss: 2.2625624402008313

Epoch: 5| Step: 5
Training loss: 1.0502042639820697
Validation loss: 2.245952415638622

Epoch: 5| Step: 6
Training loss: 1.1238743130471038
Validation loss: 2.255486019074705

Epoch: 5| Step: 7
Training loss: 0.8823773822484767
Validation loss: 2.2432455200872186

Epoch: 5| Step: 8
Training loss: 0.6998268338999596
Validation loss: 2.302538958686839

Epoch: 5| Step: 9
Training loss: 0.973116386684159
Validation loss: 2.3247149585711804

Epoch: 5| Step: 10
Training loss: 1.5349509997421733
Validation loss: 2.4207707846780893

Epoch: 316| Step: 0
Training loss: 1.0752210345470015
Validation loss: 2.45200296584045

Epoch: 5| Step: 1
Training loss: 1.1338606622054568
Validation loss: 2.4385808315866657

Epoch: 5| Step: 2
Training loss: 1.0285910225602737
Validation loss: 2.4748109390839033

Epoch: 5| Step: 3
Training loss: 0.6556042264078286
Validation loss: 2.427297504990153

Epoch: 5| Step: 4
Training loss: 1.070268838924708
Validation loss: 2.374008131349718

Epoch: 5| Step: 5
Training loss: 0.8661264337480185
Validation loss: 2.300301070480099

Epoch: 5| Step: 6
Training loss: 1.3508663700040242
Validation loss: 2.270048048221853

Epoch: 5| Step: 7
Training loss: 0.8931329117378485
Validation loss: 2.267647448669425

Epoch: 5| Step: 8
Training loss: 1.0516633369425332
Validation loss: 2.2893353600964472

Epoch: 5| Step: 9
Training loss: 0.9330648096988537
Validation loss: 2.326440227294919

Epoch: 5| Step: 10
Training loss: 0.8043271711663854
Validation loss: 2.3935480897614307

Epoch: 317| Step: 0
Training loss: 1.0120766496391826
Validation loss: 2.4450714140306467

Epoch: 5| Step: 1
Training loss: 1.0378813950282924
Validation loss: 2.4930460248307504

Epoch: 5| Step: 2
Training loss: 1.0731634331532183
Validation loss: 2.502777047199083

Epoch: 5| Step: 3
Training loss: 0.8617316790637126
Validation loss: 2.4390082361561496

Epoch: 5| Step: 4
Training loss: 1.1068314958291086
Validation loss: 2.3926593077470466

Epoch: 5| Step: 5
Training loss: 0.8961320903793957
Validation loss: 2.328322264649956

Epoch: 5| Step: 6
Training loss: 1.0581358873108002
Validation loss: 2.268536853125566

Epoch: 5| Step: 7
Training loss: 0.7944200511075838
Validation loss: 2.2729242871304316

Epoch: 5| Step: 8
Training loss: 1.2651204174762702
Validation loss: 2.3238821840558193

Epoch: 5| Step: 9
Training loss: 0.8937806557686403
Validation loss: 2.3542932717178524

Epoch: 5| Step: 10
Training loss: 0.8446095291827735
Validation loss: 2.407861397772096

Epoch: 318| Step: 0
Training loss: 0.9107649245462085
Validation loss: 2.429771039682168

Epoch: 5| Step: 1
Training loss: 1.1573841100396627
Validation loss: 2.4469832889692933

Epoch: 5| Step: 2
Training loss: 0.9082194993378575
Validation loss: 2.383816622840725

Epoch: 5| Step: 3
Training loss: 0.8460815147015406
Validation loss: 2.3718688101380154

Epoch: 5| Step: 4
Training loss: 0.9922894703287254
Validation loss: 2.3150643561977886

Epoch: 5| Step: 5
Training loss: 1.1415901803525288
Validation loss: 2.3241894290046963

Epoch: 5| Step: 6
Training loss: 1.2071772613604699
Validation loss: 2.2839618353048947

Epoch: 5| Step: 7
Training loss: 0.746010900560976
Validation loss: 2.3222129493797836

Epoch: 5| Step: 8
Training loss: 0.7746669745948013
Validation loss: 2.3065627755626

Epoch: 5| Step: 9
Training loss: 0.9764384076431003
Validation loss: 2.336932889475311

Epoch: 5| Step: 10
Training loss: 0.9817217840730373
Validation loss: 2.3262146272645867

Epoch: 319| Step: 0
Training loss: 0.9831171627908475
Validation loss: 2.330475261692432

Epoch: 5| Step: 1
Training loss: 0.9882010928731811
Validation loss: 2.3652613462255685

Epoch: 5| Step: 2
Training loss: 0.9498564536413431
Validation loss: 2.3925113076478906

Epoch: 5| Step: 3
Training loss: 0.9711692811374181
Validation loss: 2.3656060325215553

Epoch: 5| Step: 4
Training loss: 0.9883503343160981
Validation loss: 2.3933448399785795

Epoch: 5| Step: 5
Training loss: 0.972006370031025
Validation loss: 2.3690876573689916

Epoch: 5| Step: 6
Training loss: 0.6884051563216674
Validation loss: 2.3576937914895946

Epoch: 5| Step: 7
Training loss: 0.8733268476626367
Validation loss: 2.3695736147955593

Epoch: 5| Step: 8
Training loss: 0.9691567951223369
Validation loss: 2.386591898059554

Epoch: 5| Step: 9
Training loss: 1.162957864239142
Validation loss: 2.374244823545537

Epoch: 5| Step: 10
Training loss: 0.8755497227398903
Validation loss: 2.3474025199156356

Epoch: 320| Step: 0
Training loss: 0.7609688221714183
Validation loss: 2.3719467653527126

Epoch: 5| Step: 1
Training loss: 0.9019489167628658
Validation loss: 2.3475209101703487

Epoch: 5| Step: 2
Training loss: 1.1398990881744788
Validation loss: 2.3412513830027124

Epoch: 5| Step: 3
Training loss: 1.0960305552574077
Validation loss: 2.3454107442648255

Epoch: 5| Step: 4
Training loss: 0.7078352935017762
Validation loss: 2.365127431128191

Epoch: 5| Step: 5
Training loss: 0.9998890696032965
Validation loss: 2.3452432831709644

Epoch: 5| Step: 6
Training loss: 0.8549761115746877
Validation loss: 2.313489549786926

Epoch: 5| Step: 7
Training loss: 1.1012866168478215
Validation loss: 2.2851330771654785

Epoch: 5| Step: 8
Training loss: 1.0564885902673304
Validation loss: 2.3249339309657193

Epoch: 5| Step: 9
Training loss: 1.0820279999281346
Validation loss: 2.3481041456761296

Epoch: 5| Step: 10
Training loss: 0.5643007013243219
Validation loss: 2.349315484009102

Epoch: 321| Step: 0
Training loss: 0.7448950120056032
Validation loss: 2.380376989735426

Epoch: 5| Step: 1
Training loss: 1.1258646503293395
Validation loss: 2.3965594034593187

Epoch: 5| Step: 2
Training loss: 1.193913158031818
Validation loss: 2.3592321185141643

Epoch: 5| Step: 3
Training loss: 0.6417790462086236
Validation loss: 2.3786660306878558

Epoch: 5| Step: 4
Training loss: 0.9209335498446795
Validation loss: 2.3920651400358985

Epoch: 5| Step: 5
Training loss: 1.0286134481362013
Validation loss: 2.393285717444948

Epoch: 5| Step: 6
Training loss: 0.5172962500801498
Validation loss: 2.368380086112494

Epoch: 5| Step: 7
Training loss: 0.9475209000328135
Validation loss: 2.3626227037335843

Epoch: 5| Step: 8
Training loss: 0.8368614295958895
Validation loss: 2.3522001407742983

Epoch: 5| Step: 9
Training loss: 0.955875555290459
Validation loss: 2.338497929292292

Epoch: 5| Step: 10
Training loss: 1.2344004471485714
Validation loss: 2.3757822511202566

Epoch: 322| Step: 0
Training loss: 0.8550000583358656
Validation loss: 2.353634752327265

Epoch: 5| Step: 1
Training loss: 1.109621262417182
Validation loss: 2.4217985746489727

Epoch: 5| Step: 2
Training loss: 0.9201728170765482
Validation loss: 2.460836462292921

Epoch: 5| Step: 3
Training loss: 1.0265354704528131
Validation loss: 2.419554478260005

Epoch: 5| Step: 4
Training loss: 0.7873812222596007
Validation loss: 2.386211105707225

Epoch: 5| Step: 5
Training loss: 0.8575964469721306
Validation loss: 2.372793749930482

Epoch: 5| Step: 6
Training loss: 1.0219871786063555
Validation loss: 2.334581255293828

Epoch: 5| Step: 7
Training loss: 0.6298512059051726
Validation loss: 2.2840242249003118

Epoch: 5| Step: 8
Training loss: 0.8283766598055253
Validation loss: 2.291584519809207

Epoch: 5| Step: 9
Training loss: 0.9952433827114822
Validation loss: 2.318029444536414

Epoch: 5| Step: 10
Training loss: 1.3431094217439865
Validation loss: 2.345702825542847

Epoch: 323| Step: 0
Training loss: 1.1005193221368748
Validation loss: 2.340111735163378

Epoch: 5| Step: 1
Training loss: 1.004664331527946
Validation loss: 2.3403955180479676

Epoch: 5| Step: 2
Training loss: 0.7695909660909529
Validation loss: 2.345173019416748

Epoch: 5| Step: 3
Training loss: 0.8618308609136605
Validation loss: 2.3828685692710136

Epoch: 5| Step: 4
Training loss: 0.9100597477780837
Validation loss: 2.3758630862825174

Epoch: 5| Step: 5
Training loss: 0.9575969347678469
Validation loss: 2.408012536222132

Epoch: 5| Step: 6
Training loss: 1.08836318869385
Validation loss: 2.387803254391855

Epoch: 5| Step: 7
Training loss: 0.9482812215390518
Validation loss: 2.368989851587782

Epoch: 5| Step: 8
Training loss: 0.8606650985983706
Validation loss: 2.323580713507248

Epoch: 5| Step: 9
Training loss: 0.7773307530835787
Validation loss: 2.2970347211869844

Epoch: 5| Step: 10
Training loss: 0.9678108215810173
Validation loss: 2.295932811757615

Epoch: 324| Step: 0
Training loss: 1.0189271503721467
Validation loss: 2.3199664326330276

Epoch: 5| Step: 1
Training loss: 1.0461052869028102
Validation loss: 2.3891011876925425

Epoch: 5| Step: 2
Training loss: 0.7641938125949893
Validation loss: 2.4657050415374266

Epoch: 5| Step: 3
Training loss: 1.1293033838496869
Validation loss: 2.4579320861354885

Epoch: 5| Step: 4
Training loss: 1.0753974689857533
Validation loss: 2.417174587897625

Epoch: 5| Step: 5
Training loss: 0.6228827376890784
Validation loss: 2.331536516050612

Epoch: 5| Step: 6
Training loss: 1.0106905864130369
Validation loss: 2.3100188313512877

Epoch: 5| Step: 7
Training loss: 0.7104502674632509
Validation loss: 2.2612734245029773

Epoch: 5| Step: 8
Training loss: 0.6183364169882754
Validation loss: 2.270523731688831

Epoch: 5| Step: 9
Training loss: 1.1521120000012477
Validation loss: 2.281686966587471

Epoch: 5| Step: 10
Training loss: 0.9233471705218133
Validation loss: 2.296225326367744

Epoch: 325| Step: 0
Training loss: 0.7652565984531824
Validation loss: 2.2944356968443707

Epoch: 5| Step: 1
Training loss: 1.2115653102587325
Validation loss: 2.3889708227898954

Epoch: 5| Step: 2
Training loss: 1.08892805673476
Validation loss: 2.41803219214163

Epoch: 5| Step: 3
Training loss: 0.8764544388092348
Validation loss: 2.434150582189576

Epoch: 5| Step: 4
Training loss: 0.6576484584369456
Validation loss: 2.4190799993699117

Epoch: 5| Step: 5
Training loss: 0.7523815965491625
Validation loss: 2.39969364423393

Epoch: 5| Step: 6
Training loss: 0.8289546769042256
Validation loss: 2.3623765925682148

Epoch: 5| Step: 7
Training loss: 1.1256070618415386
Validation loss: 2.3324818581087046

Epoch: 5| Step: 8
Training loss: 0.776671190541999
Validation loss: 2.310320055342266

Epoch: 5| Step: 9
Training loss: 0.8665974302023548
Validation loss: 2.3314131828787756

Epoch: 5| Step: 10
Training loss: 0.9945741319064265
Validation loss: 2.362475119218462

Epoch: 326| Step: 0
Training loss: 0.6282149596819844
Validation loss: 2.3791581978268344

Epoch: 5| Step: 1
Training loss: 0.9776255505512357
Validation loss: 2.3795907330555286

Epoch: 5| Step: 2
Training loss: 0.874398399350777
Validation loss: 2.4190726006545025

Epoch: 5| Step: 3
Training loss: 1.0076451125603803
Validation loss: 2.4451730612319627

Epoch: 5| Step: 4
Training loss: 0.5940681408288749
Validation loss: 2.3991398690294563

Epoch: 5| Step: 5
Training loss: 0.9335422581474498
Validation loss: 2.3840356499201243

Epoch: 5| Step: 6
Training loss: 0.9194627008677667
Validation loss: 2.3242647616805154

Epoch: 5| Step: 7
Training loss: 1.1046207262116012
Validation loss: 2.2897641108609177

Epoch: 5| Step: 8
Training loss: 1.159949338809692
Validation loss: 2.2859438654852515

Epoch: 5| Step: 9
Training loss: 0.8634958820300047
Validation loss: 2.323905838690694

Epoch: 5| Step: 10
Training loss: 0.9243542904755331
Validation loss: 2.3339184834512228

Epoch: 327| Step: 0
Training loss: 1.1754466749920292
Validation loss: 2.3730558891400326

Epoch: 5| Step: 1
Training loss: 0.9494432097612298
Validation loss: 2.398849691848797

Epoch: 5| Step: 2
Training loss: 1.0735325511622116
Validation loss: 2.391621609738207

Epoch: 5| Step: 3
Training loss: 0.6251355262683237
Validation loss: 2.3764764215379777

Epoch: 5| Step: 4
Training loss: 0.5090555675542717
Validation loss: 2.341222950936171

Epoch: 5| Step: 5
Training loss: 0.6743373328959448
Validation loss: 2.3233107917605356

Epoch: 5| Step: 6
Training loss: 0.9835329844495527
Validation loss: 2.2933310840010908

Epoch: 5| Step: 7
Training loss: 0.832696711236665
Validation loss: 2.2868999583832093

Epoch: 5| Step: 8
Training loss: 1.1445476023055927
Validation loss: 2.2778044102633546

Epoch: 5| Step: 9
Training loss: 0.8794742020731899
Validation loss: 2.2746375552973594

Epoch: 5| Step: 10
Training loss: 0.8159044174447851
Validation loss: 2.375943442856059

Epoch: 328| Step: 0
Training loss: 1.1167365811414731
Validation loss: 2.422102019817266

Epoch: 5| Step: 1
Training loss: 0.5515056202551101
Validation loss: 2.49439129641883

Epoch: 5| Step: 2
Training loss: 1.0315302843612113
Validation loss: 2.4777606666444747

Epoch: 5| Step: 3
Training loss: 1.0777569571075614
Validation loss: 2.4148557714730354

Epoch: 5| Step: 4
Training loss: 0.9097138012956557
Validation loss: 2.334463630947761

Epoch: 5| Step: 5
Training loss: 0.8246772178017584
Validation loss: 2.2730045146614795

Epoch: 5| Step: 6
Training loss: 0.8306619184454239
Validation loss: 2.229072412018736

Epoch: 5| Step: 7
Training loss: 0.7591664125907576
Validation loss: 2.2008781824969894

Epoch: 5| Step: 8
Training loss: 1.0209599565617287
Validation loss: 2.203762174958247

Epoch: 5| Step: 9
Training loss: 0.9102060197966838
Validation loss: 2.2782359094783233

Epoch: 5| Step: 10
Training loss: 0.6733318325614571
Validation loss: 2.3878189724269596

Epoch: 329| Step: 0
Training loss: 0.9329547690521266
Validation loss: 2.4703805755963213

Epoch: 5| Step: 1
Training loss: 0.6895986949058627
Validation loss: 2.483181366981967

Epoch: 5| Step: 2
Training loss: 1.1030725180269179
Validation loss: 2.4754487052391383

Epoch: 5| Step: 3
Training loss: 1.0540307720078852
Validation loss: 2.414869574516958

Epoch: 5| Step: 4
Training loss: 0.8537448252329797
Validation loss: 2.331631300819105

Epoch: 5| Step: 5
Training loss: 0.7675494705559189
Validation loss: 2.286158344106798

Epoch: 5| Step: 6
Training loss: 0.6664956340346314
Validation loss: 2.2334266323381438

Epoch: 5| Step: 7
Training loss: 1.0159645099974413
Validation loss: 2.2598517433910317

Epoch: 5| Step: 8
Training loss: 0.9513820596126531
Validation loss: 2.2824516811777324

Epoch: 5| Step: 9
Training loss: 1.0079874286094748
Validation loss: 2.384062769753289

Epoch: 5| Step: 10
Training loss: 0.966880101176283
Validation loss: 2.470258096114802

Epoch: 330| Step: 0
Training loss: 0.9399315454535518
Validation loss: 2.473329807787066

Epoch: 5| Step: 1
Training loss: 0.9427554643908106
Validation loss: 2.4625435849822694

Epoch: 5| Step: 2
Training loss: 1.0687733184769102
Validation loss: 2.383305036051392

Epoch: 5| Step: 3
Training loss: 1.0171186760795705
Validation loss: 2.3049905579460566

Epoch: 5| Step: 4
Training loss: 0.7351246923307525
Validation loss: 2.2761870168123997

Epoch: 5| Step: 5
Training loss: 0.6457687519967581
Validation loss: 2.253430981354555

Epoch: 5| Step: 6
Training loss: 1.0148503210076731
Validation loss: 2.2853230183703235

Epoch: 5| Step: 7
Training loss: 0.8339602536145936
Validation loss: 2.3200732858070756

Epoch: 5| Step: 8
Training loss: 0.9224676393244866
Validation loss: 2.3640639823605993

Epoch: 5| Step: 9
Training loss: 0.9500153264265011
Validation loss: 2.4152973612915085

Epoch: 5| Step: 10
Training loss: 0.7996686323652427
Validation loss: 2.448451043324931

Epoch: 331| Step: 0
Training loss: 0.8074174516369371
Validation loss: 2.497920485048893

Epoch: 5| Step: 1
Training loss: 0.8966109574985381
Validation loss: 2.532838783872487

Epoch: 5| Step: 2
Training loss: 1.0937229698110864
Validation loss: 2.4799345514021804

Epoch: 5| Step: 3
Training loss: 0.7668172545015534
Validation loss: 2.4235945541769546

Epoch: 5| Step: 4
Training loss: 0.9143128011620725
Validation loss: 2.36232433222664

Epoch: 5| Step: 5
Training loss: 0.7758534777191213
Validation loss: 2.2996207188460667

Epoch: 5| Step: 6
Training loss: 0.9539614587252064
Validation loss: 2.3085311937529682

Epoch: 5| Step: 7
Training loss: 0.9359728773050965
Validation loss: 2.263737496170915

Epoch: 5| Step: 8
Training loss: 1.0084544658149879
Validation loss: 2.3059953349603224

Epoch: 5| Step: 9
Training loss: 0.9912058261683176
Validation loss: 2.311199102798613

Epoch: 5| Step: 10
Training loss: 0.622326808491021
Validation loss: 2.3398513482932364

Epoch: 332| Step: 0
Training loss: 0.9033831270389934
Validation loss: 2.4192928822422184

Epoch: 5| Step: 1
Training loss: 1.0199802623035858
Validation loss: 2.475376387409853

Epoch: 5| Step: 2
Training loss: 0.8665118291590018
Validation loss: 2.519634307104382

Epoch: 5| Step: 3
Training loss: 1.138745889499251
Validation loss: 2.540499292189041

Epoch: 5| Step: 4
Training loss: 0.6571702635459685
Validation loss: 2.484690944265257

Epoch: 5| Step: 5
Training loss: 1.0261888285537168
Validation loss: 2.3987274085564705

Epoch: 5| Step: 6
Training loss: 0.7299671184633101
Validation loss: 2.306303975428285

Epoch: 5| Step: 7
Training loss: 1.075501608811456
Validation loss: 2.246950103742754

Epoch: 5| Step: 8
Training loss: 0.8842889710224838
Validation loss: 2.2421432135728483

Epoch: 5| Step: 9
Training loss: 0.71052883265795
Validation loss: 2.269261596241837

Epoch: 5| Step: 10
Training loss: 0.7763811602024862
Validation loss: 2.253522112418338

Epoch: 333| Step: 0
Training loss: 0.8319988333964422
Validation loss: 2.3067446335454767

Epoch: 5| Step: 1
Training loss: 0.9161976387394037
Validation loss: 2.4427916169779498

Epoch: 5| Step: 2
Training loss: 0.7980233314540456
Validation loss: 2.447615179496815

Epoch: 5| Step: 3
Training loss: 0.9047435868292355
Validation loss: 2.502986753269953

Epoch: 5| Step: 4
Training loss: 0.984868576799642
Validation loss: 2.4988150085231062

Epoch: 5| Step: 5
Training loss: 0.8044623643311757
Validation loss: 2.4148315538513807

Epoch: 5| Step: 6
Training loss: 0.7559262426010422
Validation loss: 2.371652199542205

Epoch: 5| Step: 7
Training loss: 0.7947563355185238
Validation loss: 2.326203669953619

Epoch: 5| Step: 8
Training loss: 0.7938210553182097
Validation loss: 2.3151118476327124

Epoch: 5| Step: 9
Training loss: 0.9996205444427446
Validation loss: 2.2794300258409588

Epoch: 5| Step: 10
Training loss: 0.9856097031629681
Validation loss: 2.285177757204745

Epoch: 334| Step: 0
Training loss: 0.6576226955055127
Validation loss: 2.3592945012615445

Epoch: 5| Step: 1
Training loss: 1.0397613011209428
Validation loss: 2.418648620644763

Epoch: 5| Step: 2
Training loss: 0.9045371937124048
Validation loss: 2.413618121802844

Epoch: 5| Step: 3
Training loss: 0.974471577475984
Validation loss: 2.4241050834401077

Epoch: 5| Step: 4
Training loss: 1.0280539375026059
Validation loss: 2.3938636356981213

Epoch: 5| Step: 5
Training loss: 0.6195816731468111
Validation loss: 2.3519971191954214

Epoch: 5| Step: 6
Training loss: 0.7555807225938257
Validation loss: 2.3331801573698217

Epoch: 5| Step: 7
Training loss: 0.7733409320386726
Validation loss: 2.326998695654815

Epoch: 5| Step: 8
Training loss: 0.8939912657108384
Validation loss: 2.3224337996698963

Epoch: 5| Step: 9
Training loss: 0.7272544355286699
Validation loss: 2.333551076062463

Epoch: 5| Step: 10
Training loss: 0.8484119263899275
Validation loss: 2.323701586206168

Epoch: 335| Step: 0
Training loss: 0.6586474721408453
Validation loss: 2.291823280181085

Epoch: 5| Step: 1
Training loss: 0.6134329930051008
Validation loss: 2.369477143094274

Epoch: 5| Step: 2
Training loss: 1.0049080210675847
Validation loss: 2.408408123160419

Epoch: 5| Step: 3
Training loss: 0.6939997549949786
Validation loss: 2.4074854625617843

Epoch: 5| Step: 4
Training loss: 0.7552846453466192
Validation loss: 2.447552800064483

Epoch: 5| Step: 5
Training loss: 0.8524682364041865
Validation loss: 2.3820417562022795

Epoch: 5| Step: 6
Training loss: 1.118625915295078
Validation loss: 2.3938723042585366

Epoch: 5| Step: 7
Training loss: 0.6983817647930988
Validation loss: 2.4095916748935218

Epoch: 5| Step: 8
Training loss: 0.8227938226361305
Validation loss: 2.3689238488135373

Epoch: 5| Step: 9
Training loss: 0.8771470838802599
Validation loss: 2.3629551390552965

Epoch: 5| Step: 10
Training loss: 1.0023343140060588
Validation loss: 2.3481058112037894

Epoch: 336| Step: 0
Training loss: 0.8218149866740583
Validation loss: 2.300393209979957

Epoch: 5| Step: 1
Training loss: 0.5547699396900104
Validation loss: 2.3325431642368915

Epoch: 5| Step: 2
Training loss: 0.868456281779412
Validation loss: 2.368397754251336

Epoch: 5| Step: 3
Training loss: 0.870003295705845
Validation loss: 2.4241629430064697

Epoch: 5| Step: 4
Training loss: 0.9493994835113059
Validation loss: 2.440873435012519

Epoch: 5| Step: 5
Training loss: 0.6548806845485065
Validation loss: 2.4701442081295357

Epoch: 5| Step: 6
Training loss: 0.8826847490358152
Validation loss: 2.4555579408646326

Epoch: 5| Step: 7
Training loss: 0.8913358896288264
Validation loss: 2.4313083519678873

Epoch: 5| Step: 8
Training loss: 0.7039075099921089
Validation loss: 2.3808474249640286

Epoch: 5| Step: 9
Training loss: 0.9986490124097805
Validation loss: 2.338496404370998

Epoch: 5| Step: 10
Training loss: 0.9476547543104277
Validation loss: 2.3138026698226795

Epoch: 337| Step: 0
Training loss: 0.7474374704138467
Validation loss: 2.329241360333603

Epoch: 5| Step: 1
Training loss: 0.7410086656081754
Validation loss: 2.281991610787107

Epoch: 5| Step: 2
Training loss: 0.9153207774779456
Validation loss: 2.326168779239358

Epoch: 5| Step: 3
Training loss: 0.6533282953752526
Validation loss: 2.366571655544312

Epoch: 5| Step: 4
Training loss: 0.9066446037155872
Validation loss: 2.4139218348970584

Epoch: 5| Step: 5
Training loss: 0.6531428622125819
Validation loss: 2.4454609695018914

Epoch: 5| Step: 6
Training loss: 0.9922534890645744
Validation loss: 2.477192905724869

Epoch: 5| Step: 7
Training loss: 0.7570999570990397
Validation loss: 2.4655477135014285

Epoch: 5| Step: 8
Training loss: 0.9668150312472072
Validation loss: 2.4592606339145573

Epoch: 5| Step: 9
Training loss: 0.8927689229433375
Validation loss: 2.4216718860445168

Epoch: 5| Step: 10
Training loss: 0.8374206718908082
Validation loss: 2.4163537641480386

Epoch: 338| Step: 0
Training loss: 0.7555157178383636
Validation loss: 2.371602354189971

Epoch: 5| Step: 1
Training loss: 0.6540799592700174
Validation loss: 2.3747560843238467

Epoch: 5| Step: 2
Training loss: 0.6253900741203021
Validation loss: 2.391167951343667

Epoch: 5| Step: 3
Training loss: 0.7921436696464227
Validation loss: 2.4046385037633864

Epoch: 5| Step: 4
Training loss: 1.0559214402620423
Validation loss: 2.419782018787719

Epoch: 5| Step: 5
Training loss: 0.7248572159618416
Validation loss: 2.441724564472278

Epoch: 5| Step: 6
Training loss: 0.7235584709910047
Validation loss: 2.4445791346845818

Epoch: 5| Step: 7
Training loss: 0.9170405463486666
Validation loss: 2.4192635118515953

Epoch: 5| Step: 8
Training loss: 0.8647398213396528
Validation loss: 2.3645393837671618

Epoch: 5| Step: 9
Training loss: 0.8369059790417858
Validation loss: 2.3826683556262145

Epoch: 5| Step: 10
Training loss: 0.9913291823040067
Validation loss: 2.339932947586434

Epoch: 339| Step: 0
Training loss: 0.8446206439872581
Validation loss: 2.326806198605346

Epoch: 5| Step: 1
Training loss: 0.8256918231682592
Validation loss: 2.2839770523544

Epoch: 5| Step: 2
Training loss: 0.841544305921312
Validation loss: 2.3473209067001166

Epoch: 5| Step: 3
Training loss: 0.6560195790805747
Validation loss: 2.372164125546741

Epoch: 5| Step: 4
Training loss: 0.7988223796162199
Validation loss: 2.374929036287603

Epoch: 5| Step: 5
Training loss: 0.9023239331732242
Validation loss: 2.3934388313512387

Epoch: 5| Step: 6
Training loss: 0.7351064083379969
Validation loss: 2.4052934677789306

Epoch: 5| Step: 7
Training loss: 0.7100484969809319
Validation loss: 2.403492006862166

Epoch: 5| Step: 8
Training loss: 0.9249388326576913
Validation loss: 2.4076959649327634

Epoch: 5| Step: 9
Training loss: 0.8747023007911365
Validation loss: 2.3244510293627165

Epoch: 5| Step: 10
Training loss: 0.7179170425939507
Validation loss: 2.280812152778576

Epoch: 340| Step: 0
Training loss: 0.886876835784195
Validation loss: 2.334812649775468

Epoch: 5| Step: 1
Training loss: 1.101047422501681
Validation loss: 2.3660453343083696

Epoch: 5| Step: 2
Training loss: 0.5360551788321155
Validation loss: 2.3338180311777315

Epoch: 5| Step: 3
Training loss: 0.8594143251611386
Validation loss: 2.32605423430127

Epoch: 5| Step: 4
Training loss: 0.6743611977608105
Validation loss: 2.3288196549534135

Epoch: 5| Step: 5
Training loss: 0.3827893386373624
Validation loss: 2.3606895474185956

Epoch: 5| Step: 6
Training loss: 0.9275031193066401
Validation loss: 2.394180932532859

Epoch: 5| Step: 7
Training loss: 0.9161510245454598
Validation loss: 2.4141236235871695

Epoch: 5| Step: 8
Training loss: 0.9434597048905677
Validation loss: 2.3808752950079057

Epoch: 5| Step: 9
Training loss: 0.77141367914317
Validation loss: 2.3549170888408644

Epoch: 5| Step: 10
Training loss: 0.48845693860756123
Validation loss: 2.3272328346254283

Epoch: 341| Step: 0
Training loss: 0.9657706314438793
Validation loss: 2.3225243309430783

Epoch: 5| Step: 1
Training loss: 0.6837858529602581
Validation loss: 2.310424016977458

Epoch: 5| Step: 2
Training loss: 0.7349519695106888
Validation loss: 2.314133318672899

Epoch: 5| Step: 3
Training loss: 0.7309505893013145
Validation loss: 2.346884669975206

Epoch: 5| Step: 4
Training loss: 0.8980883707794454
Validation loss: 2.3915379401871184

Epoch: 5| Step: 5
Training loss: 0.7321297024664913
Validation loss: 2.41822300366275

Epoch: 5| Step: 6
Training loss: 0.8420895025815984
Validation loss: 2.4112154076533967

Epoch: 5| Step: 7
Training loss: 0.7856960433848685
Validation loss: 2.408818249133969

Epoch: 5| Step: 8
Training loss: 0.593987016051087
Validation loss: 2.4173903571578834

Epoch: 5| Step: 9
Training loss: 0.9320697555837689
Validation loss: 2.3725321603921925

Epoch: 5| Step: 10
Training loss: 1.0448312310093049
Validation loss: 2.325960897585433

Epoch: 342| Step: 0
Training loss: 0.9037349264911279
Validation loss: 2.3432046125813133

Epoch: 5| Step: 1
Training loss: 0.8906142250881592
Validation loss: 2.3011916466056745

Epoch: 5| Step: 2
Training loss: 0.6050423628186129
Validation loss: 2.3249075041671596

Epoch: 5| Step: 3
Training loss: 0.7408126142741992
Validation loss: 2.3346720984528626

Epoch: 5| Step: 4
Training loss: 1.0289680201729772
Validation loss: 2.383415289285148

Epoch: 5| Step: 5
Training loss: 0.6068451526188947
Validation loss: 2.40605171280498

Epoch: 5| Step: 6
Training loss: 0.6834563852987969
Validation loss: 2.419521139267614

Epoch: 5| Step: 7
Training loss: 0.8855721206330912
Validation loss: 2.477928351471831

Epoch: 5| Step: 8
Training loss: 1.037375665591144
Validation loss: 2.4215690755660417

Epoch: 5| Step: 9
Training loss: 0.5795324051249725
Validation loss: 2.3895094079049537

Epoch: 5| Step: 10
Training loss: 0.7057307596411563
Validation loss: 2.3135598217125044

Epoch: 343| Step: 0
Training loss: 0.7296712673431992
Validation loss: 2.2656068675977905

Epoch: 5| Step: 1
Training loss: 0.8377591899230026
Validation loss: 2.222861370425287

Epoch: 5| Step: 2
Training loss: 0.9760197161008064
Validation loss: 2.2663831523628253

Epoch: 5| Step: 3
Training loss: 1.0402379092114553
Validation loss: 2.2710656232321256

Epoch: 5| Step: 4
Training loss: 1.0839716180274117
Validation loss: 2.352719148235307

Epoch: 5| Step: 5
Training loss: 0.5130916262610054
Validation loss: 2.392804930909021

Epoch: 5| Step: 6
Training loss: 0.5744637206817739
Validation loss: 2.4756678538134747

Epoch: 5| Step: 7
Training loss: 0.5806192513582686
Validation loss: 2.466100949343521

Epoch: 5| Step: 8
Training loss: 0.8603426254102718
Validation loss: 2.4399498449133654

Epoch: 5| Step: 9
Training loss: 0.7070646330818878
Validation loss: 2.3543345480155975

Epoch: 5| Step: 10
Training loss: 0.9493031719326358
Validation loss: 2.3143264377920634

Epoch: 344| Step: 0
Training loss: 0.8977279846904113
Validation loss: 2.256360301446064

Epoch: 5| Step: 1
Training loss: 0.8571310049611319
Validation loss: 2.3040492176975382

Epoch: 5| Step: 2
Training loss: 0.6349360075943503
Validation loss: 2.3066490573087606

Epoch: 5| Step: 3
Training loss: 0.7745947224226192
Validation loss: 2.383574082088704

Epoch: 5| Step: 4
Training loss: 0.7386234035555388
Validation loss: 2.4499446761778696

Epoch: 5| Step: 5
Training loss: 1.0738061840914506
Validation loss: 2.5088300807980457

Epoch: 5| Step: 6
Training loss: 0.9213342535448609
Validation loss: 2.4944350160042252

Epoch: 5| Step: 7
Training loss: 0.701213633534394
Validation loss: 2.425848687557414

Epoch: 5| Step: 8
Training loss: 0.7065506877358888
Validation loss: 2.378153384416603

Epoch: 5| Step: 9
Training loss: 0.7528598223579335
Validation loss: 2.3408879580609714

Epoch: 5| Step: 10
Training loss: 0.7783660683769587
Validation loss: 2.3040532611276108

Epoch: 345| Step: 0
Training loss: 0.5353300271892157
Validation loss: 2.237983125825098

Epoch: 5| Step: 1
Training loss: 0.7007670176750201
Validation loss: 2.221682496139516

Epoch: 5| Step: 2
Training loss: 0.7966580189018736
Validation loss: 2.258512007998865

Epoch: 5| Step: 3
Training loss: 0.861879271897095
Validation loss: 2.30461923572186

Epoch: 5| Step: 4
Training loss: 1.0747558915410897
Validation loss: 2.367181805631187

Epoch: 5| Step: 5
Training loss: 1.005474127908476
Validation loss: 2.421113609644919

Epoch: 5| Step: 6
Training loss: 0.792048705091731
Validation loss: 2.473098908881754

Epoch: 5| Step: 7
Training loss: 0.8298663778062557
Validation loss: 2.4573726024685

Epoch: 5| Step: 8
Training loss: 0.6810638479629204
Validation loss: 2.448051019218161

Epoch: 5| Step: 9
Training loss: 0.8643086391525218
Validation loss: 2.3934459317409966

Epoch: 5| Step: 10
Training loss: 0.8039845850140511
Validation loss: 2.3511968449735514

Epoch: 346| Step: 0
Training loss: 0.999754488132454
Validation loss: 2.2778028289527175

Epoch: 5| Step: 1
Training loss: 1.0831161183445988
Validation loss: 2.2665970292454074

Epoch: 5| Step: 2
Training loss: 0.6486227161663529
Validation loss: 2.3172059138961254

Epoch: 5| Step: 3
Training loss: 0.5450404321914005
Validation loss: 2.3906574519179498

Epoch: 5| Step: 4
Training loss: 0.6863408069600472
Validation loss: 2.435936433935708

Epoch: 5| Step: 5
Training loss: 0.8052123126827738
Validation loss: 2.4320585221635094

Epoch: 5| Step: 6
Training loss: 0.8899506140519007
Validation loss: 2.4443055868873236

Epoch: 5| Step: 7
Training loss: 0.6695621069404291
Validation loss: 2.4550427862668185

Epoch: 5| Step: 8
Training loss: 0.6413139964585243
Validation loss: 2.4275273179231727

Epoch: 5| Step: 9
Training loss: 0.8752311673659339
Validation loss: 2.3754813953676694

Epoch: 5| Step: 10
Training loss: 0.9378583541078271
Validation loss: 2.362486708052898

Epoch: 347| Step: 0
Training loss: 0.638155947541005
Validation loss: 2.292627728956421

Epoch: 5| Step: 1
Training loss: 0.4692527617920462
Validation loss: 2.3088451894244066

Epoch: 5| Step: 2
Training loss: 0.811289729540015
Validation loss: 2.2983178713177725

Epoch: 5| Step: 3
Training loss: 1.0721598922212652
Validation loss: 2.3242877853783583

Epoch: 5| Step: 4
Training loss: 0.6280251248035312
Validation loss: 2.2954131108883757

Epoch: 5| Step: 5
Training loss: 0.7252712054908355
Validation loss: 2.32716323665859

Epoch: 5| Step: 6
Training loss: 0.6041577080906492
Validation loss: 2.36864388107206

Epoch: 5| Step: 7
Training loss: 0.8214383346854071
Validation loss: 2.445848881255135

Epoch: 5| Step: 8
Training loss: 0.5432262770471376
Validation loss: 2.430306692748086

Epoch: 5| Step: 9
Training loss: 1.1942719561702853
Validation loss: 2.4270888611083916

Epoch: 5| Step: 10
Training loss: 0.7715757291763619
Validation loss: 2.4448576704074236

Epoch: 348| Step: 0
Training loss: 0.8086201760217009
Validation loss: 2.4044039623029856

Epoch: 5| Step: 1
Training loss: 0.5425218897679432
Validation loss: 2.359652483282553

Epoch: 5| Step: 2
Training loss: 0.9080872492547529
Validation loss: 2.318268113782713

Epoch: 5| Step: 3
Training loss: 0.8376171670629143
Validation loss: 2.3001749423810636

Epoch: 5| Step: 4
Training loss: 0.755530707295099
Validation loss: 2.309917157175739

Epoch: 5| Step: 5
Training loss: 0.9868193658919311
Validation loss: 2.344767919738417

Epoch: 5| Step: 6
Training loss: 0.986301716365982
Validation loss: 2.3849555991866054

Epoch: 5| Step: 7
Training loss: 0.7045156078924502
Validation loss: 2.3961761471890144

Epoch: 5| Step: 8
Training loss: 0.6930825553948692
Validation loss: 2.3980239127306335

Epoch: 5| Step: 9
Training loss: 0.6114908800014278
Validation loss: 2.439702831064153

Epoch: 5| Step: 10
Training loss: 0.4421524896679514
Validation loss: 2.3929982328634694

Epoch: 349| Step: 0
Training loss: 0.5618865323607043
Validation loss: 2.332445718183118

Epoch: 5| Step: 1
Training loss: 0.4586090501250803
Validation loss: 2.3086772719183988

Epoch: 5| Step: 2
Training loss: 0.6368311215335414
Validation loss: 2.326414845194829

Epoch: 5| Step: 3
Training loss: 0.6708396652665252
Validation loss: 2.3409446547651536

Epoch: 5| Step: 4
Training loss: 0.8213354362975896
Validation loss: 2.3494870996537816

Epoch: 5| Step: 5
Training loss: 0.6645734952678779
Validation loss: 2.3352295697300067

Epoch: 5| Step: 6
Training loss: 0.5751676439453653
Validation loss: 2.3838766636395268

Epoch: 5| Step: 7
Training loss: 1.0983323156750546
Validation loss: 2.379573175496159

Epoch: 5| Step: 8
Training loss: 0.938936531643818
Validation loss: 2.3947730476701024

Epoch: 5| Step: 9
Training loss: 0.8825529611597605
Validation loss: 2.410380069218263

Epoch: 5| Step: 10
Training loss: 0.8344576562523259
Validation loss: 2.3888718205060253

Epoch: 350| Step: 0
Training loss: 0.5147321658275658
Validation loss: 2.3841535721718374

Epoch: 5| Step: 1
Training loss: 0.9075420311581354
Validation loss: 2.4099673262300976

Epoch: 5| Step: 2
Training loss: 0.7140494347510188
Validation loss: 2.340457466883621

Epoch: 5| Step: 3
Training loss: 0.6201980417961224
Validation loss: 2.378772966184581

Epoch: 5| Step: 4
Training loss: 0.8868821115457317
Validation loss: 2.394868436156643

Epoch: 5| Step: 5
Training loss: 0.8117385744348703
Validation loss: 2.366521744347274

Epoch: 5| Step: 6
Training loss: 0.6439984980826309
Validation loss: 2.354343136717932

Epoch: 5| Step: 7
Training loss: 0.641289459449602
Validation loss: 2.379694006201988

Epoch: 5| Step: 8
Training loss: 0.7505324381121508
Validation loss: 2.36363033034245

Epoch: 5| Step: 9
Training loss: 0.9080646696482901
Validation loss: 2.409902466497404

Epoch: 5| Step: 10
Training loss: 0.7875569398670262
Validation loss: 2.374136843993134

Epoch: 351| Step: 0
Training loss: 0.9156473228675835
Validation loss: 2.342359805163275

Epoch: 5| Step: 1
Training loss: 0.5185187375813102
Validation loss: 2.3234998898903845

Epoch: 5| Step: 2
Training loss: 0.7397286894611029
Validation loss: 2.273746046249458

Epoch: 5| Step: 3
Training loss: 0.4599574710529044
Validation loss: 2.2884410011784846

Epoch: 5| Step: 4
Training loss: 0.6225102185172803
Validation loss: 2.2603192940483647

Epoch: 5| Step: 5
Training loss: 0.7958832347330622
Validation loss: 2.3120831083572755

Epoch: 5| Step: 6
Training loss: 0.8161292085169521
Validation loss: 2.3349670903323503

Epoch: 5| Step: 7
Training loss: 1.0069243191575041
Validation loss: 2.363434832525119

Epoch: 5| Step: 8
Training loss: 0.6400494897974921
Validation loss: 2.367174341633672

Epoch: 5| Step: 9
Training loss: 0.8371423968460793
Validation loss: 2.42684459150238

Epoch: 5| Step: 10
Training loss: 0.7156318114510418
Validation loss: 2.4361756668280115

Epoch: 352| Step: 0
Training loss: 0.9781056533216406
Validation loss: 2.4327112996915674

Epoch: 5| Step: 1
Training loss: 0.6965026955754354
Validation loss: 2.3564302664206394

Epoch: 5| Step: 2
Training loss: 0.5707438940673194
Validation loss: 2.313656848778489

Epoch: 5| Step: 3
Training loss: 0.7981871852681474
Validation loss: 2.3162828815259906

Epoch: 5| Step: 4
Training loss: 0.6958797155747762
Validation loss: 2.2964203528059763

Epoch: 5| Step: 5
Training loss: 0.8014866397051129
Validation loss: 2.3502707926021453

Epoch: 5| Step: 6
Training loss: 0.6370262386451453
Validation loss: 2.377701326807553

Epoch: 5| Step: 7
Training loss: 0.49765882147060264
Validation loss: 2.3738033861724626

Epoch: 5| Step: 8
Training loss: 0.6925814710817012
Validation loss: 2.4199419048007136

Epoch: 5| Step: 9
Training loss: 0.8263020153668785
Validation loss: 2.3956060183112187

Epoch: 5| Step: 10
Training loss: 0.8646475909762981
Validation loss: 2.415323162638594

Epoch: 353| Step: 0
Training loss: 0.9346683335196433
Validation loss: 2.331605438115406

Epoch: 5| Step: 1
Training loss: 0.3615043828838359
Validation loss: 2.3341858594812748

Epoch: 5| Step: 2
Training loss: 0.48396816395849535
Validation loss: 2.3383637258336925

Epoch: 5| Step: 3
Training loss: 0.8088587082643035
Validation loss: 2.308285311020988

Epoch: 5| Step: 4
Training loss: 0.6882231550347213
Validation loss: 2.3500568526143026

Epoch: 5| Step: 5
Training loss: 0.5114128712832414
Validation loss: 2.3304279689386

Epoch: 5| Step: 6
Training loss: 0.6650670699665286
Validation loss: 2.306497895689786

Epoch: 5| Step: 7
Training loss: 0.7833203920012317
Validation loss: 2.2950364288874754

Epoch: 5| Step: 8
Training loss: 1.0844190121384487
Validation loss: 2.306553657168091

Epoch: 5| Step: 9
Training loss: 0.8476353304342742
Validation loss: 2.288006505461492

Epoch: 5| Step: 10
Training loss: 0.751838179881427
Validation loss: 2.3318035847129135

Epoch: 354| Step: 0
Training loss: 0.755975088483613
Validation loss: 2.351784106939271

Epoch: 5| Step: 1
Training loss: 0.7470636105704289
Validation loss: 2.3692821558509647

Epoch: 5| Step: 2
Training loss: 0.7254703065065524
Validation loss: 2.393663072031802

Epoch: 5| Step: 3
Training loss: 0.5074536743067123
Validation loss: 2.405605424799051

Epoch: 5| Step: 4
Training loss: 0.7017762493596288
Validation loss: 2.358349259926897

Epoch: 5| Step: 5
Training loss: 0.6471359334799061
Validation loss: 2.3724495514142587

Epoch: 5| Step: 6
Training loss: 0.8459922525353246
Validation loss: 2.3092631352050725

Epoch: 5| Step: 7
Training loss: 0.8883963356853661
Validation loss: 2.3256659681850342

Epoch: 5| Step: 8
Training loss: 0.6797775340464675
Validation loss: 2.3066631066425676

Epoch: 5| Step: 9
Training loss: 0.7986892169038698
Validation loss: 2.3163563613099796

Epoch: 5| Step: 10
Training loss: 0.6361561729632362
Validation loss: 2.358977988169284

Epoch: 355| Step: 0
Training loss: 0.6397169003721012
Validation loss: 2.316088917167442

Epoch: 5| Step: 1
Training loss: 0.9876314220617989
Validation loss: 2.304938900630956

Epoch: 5| Step: 2
Training loss: 0.7668084321047441
Validation loss: 2.289013105094218

Epoch: 5| Step: 3
Training loss: 0.5623340891829414
Validation loss: 2.3195010265063916

Epoch: 5| Step: 4
Training loss: 0.49903314211492245
Validation loss: 2.3297174236419624

Epoch: 5| Step: 5
Training loss: 0.7433699173613234
Validation loss: 2.342549744778898

Epoch: 5| Step: 6
Training loss: 0.7566011323011307
Validation loss: 2.3561740924490153

Epoch: 5| Step: 7
Training loss: 0.5555274943046525
Validation loss: 2.359849255869359

Epoch: 5| Step: 8
Training loss: 0.7501789515309453
Validation loss: 2.337204286805415

Epoch: 5| Step: 9
Training loss: 1.0235557196674923
Validation loss: 2.3716142416319625

Epoch: 5| Step: 10
Training loss: 0.327537396494405
Validation loss: 2.346812696612904

Epoch: 356| Step: 0
Training loss: 0.908165059266115
Validation loss: 2.3325171236998656

Epoch: 5| Step: 1
Training loss: 0.38635431322410574
Validation loss: 2.346122644416078

Epoch: 5| Step: 2
Training loss: 0.712104384697249
Validation loss: 2.3643308454761596

Epoch: 5| Step: 3
Training loss: 0.9921424134590971
Validation loss: 2.3581174277749044

Epoch: 5| Step: 4
Training loss: 0.5468707765688617
Validation loss: 2.3493090271996238

Epoch: 5| Step: 5
Training loss: 0.8848754612533072
Validation loss: 2.357668275573617

Epoch: 5| Step: 6
Training loss: 0.7656420491714203
Validation loss: 2.356827388708734

Epoch: 5| Step: 7
Training loss: 0.7602682534923917
Validation loss: 2.3550538607287987

Epoch: 5| Step: 8
Training loss: 0.35676117579993377
Validation loss: 2.334193741980305

Epoch: 5| Step: 9
Training loss: 0.7374790819078725
Validation loss: 2.3147183957636557

Epoch: 5| Step: 10
Training loss: 0.39683746250481766
Validation loss: 2.3436827345735685

Epoch: 357| Step: 0
Training loss: 0.44569260286419804
Validation loss: 2.335833861182106

Epoch: 5| Step: 1
Training loss: 0.541385923282027
Validation loss: 2.3868704592661505

Epoch: 5| Step: 2
Training loss: 0.8272987778555817
Validation loss: 2.404057359672917

Epoch: 5| Step: 3
Training loss: 0.6531300403090199
Validation loss: 2.3724952014978435

Epoch: 5| Step: 4
Training loss: 0.6286700261182347
Validation loss: 2.343785476142623

Epoch: 5| Step: 5
Training loss: 0.7166677665332368
Validation loss: 2.3464241670677515

Epoch: 5| Step: 6
Training loss: 0.6999747595323644
Validation loss: 2.289995044334442

Epoch: 5| Step: 7
Training loss: 0.5080389838241579
Validation loss: 2.288872991759497

Epoch: 5| Step: 8
Training loss: 1.073619384015445
Validation loss: 2.290132050891812

Epoch: 5| Step: 9
Training loss: 0.7866040446389132
Validation loss: 2.3369171220857874

Epoch: 5| Step: 10
Training loss: 0.6499891903785383
Validation loss: 2.3753483510870494

Epoch: 358| Step: 0
Training loss: 0.8709744085150183
Validation loss: 2.385734082024788

Epoch: 5| Step: 1
Training loss: 0.8833563150859117
Validation loss: 2.356002954648282

Epoch: 5| Step: 2
Training loss: 0.36671021060241316
Validation loss: 2.377341513516263

Epoch: 5| Step: 3
Training loss: 0.669780860940278
Validation loss: 2.3467294996162664

Epoch: 5| Step: 4
Training loss: 0.7988755414922434
Validation loss: 2.3078472848358382

Epoch: 5| Step: 5
Training loss: 0.6141828482146886
Validation loss: 2.3286456665373976

Epoch: 5| Step: 6
Training loss: 0.8638665817020577
Validation loss: 2.3074936313208183

Epoch: 5| Step: 7
Training loss: 0.5402865679084955
Validation loss: 2.322004475647398

Epoch: 5| Step: 8
Training loss: 0.6381279965665665
Validation loss: 2.3208163637487265

Epoch: 5| Step: 9
Training loss: 0.8177615146391897
Validation loss: 2.3811339131969436

Epoch: 5| Step: 10
Training loss: 0.44087068593591655
Validation loss: 2.3538133361690132

Epoch: 359| Step: 0
Training loss: 0.5229913033898383
Validation loss: 2.354824541235844

Epoch: 5| Step: 1
Training loss: 0.8362785071630241
Validation loss: 2.321100406085834

Epoch: 5| Step: 2
Training loss: 0.938657776865216
Validation loss: 2.3148563201173062

Epoch: 5| Step: 3
Training loss: 0.6372088552865416
Validation loss: 2.320987233594996

Epoch: 5| Step: 4
Training loss: 0.3539362559955984
Validation loss: 2.327941319086243

Epoch: 5| Step: 5
Training loss: 0.6613606858954836
Validation loss: 2.323633344881452

Epoch: 5| Step: 6
Training loss: 0.7763935204604532
Validation loss: 2.338226407465752

Epoch: 5| Step: 7
Training loss: 0.5398496878665899
Validation loss: 2.369829935393431

Epoch: 5| Step: 8
Training loss: 0.5656436917077574
Validation loss: 2.374658019180243

Epoch: 5| Step: 9
Training loss: 0.7003815003038452
Validation loss: 2.3735537440516796

Epoch: 5| Step: 10
Training loss: 0.8761891390986981
Validation loss: 2.352812695015212

Epoch: 360| Step: 0
Training loss: 0.7331252725898255
Validation loss: 2.3211767065658457

Epoch: 5| Step: 1
Training loss: 0.6050909524916076
Validation loss: 2.263410786531552

Epoch: 5| Step: 2
Training loss: 0.748455842177626
Validation loss: 2.2958315812801695

Epoch: 5| Step: 3
Training loss: 0.5653440842206031
Validation loss: 2.2965955823101014

Epoch: 5| Step: 4
Training loss: 1.0521037914943479
Validation loss: 2.303221402379926

Epoch: 5| Step: 5
Training loss: 0.815186936113671
Validation loss: 2.338009814897107

Epoch: 5| Step: 6
Training loss: 0.4772052339157689
Validation loss: 2.3453892281121917

Epoch: 5| Step: 7
Training loss: 0.7304859669334228
Validation loss: 2.377637034412766

Epoch: 5| Step: 8
Training loss: 0.6329316627487158
Validation loss: 2.3724774736451684

Epoch: 5| Step: 9
Training loss: 0.46969372799133174
Validation loss: 2.3699295167924794

Epoch: 5| Step: 10
Training loss: 0.5814155291642368
Validation loss: 2.3516324262191097

Epoch: 361| Step: 0
Training loss: 0.615812871315156
Validation loss: 2.394877446306141

Epoch: 5| Step: 1
Training loss: 0.46681253255337607
Validation loss: 2.383073007863355

Epoch: 5| Step: 2
Training loss: 0.8585669446514821
Validation loss: 2.3824289815804747

Epoch: 5| Step: 3
Training loss: 0.878529141374266
Validation loss: 2.3432760162717696

Epoch: 5| Step: 4
Training loss: 0.5948772270896794
Validation loss: 2.312229228221246

Epoch: 5| Step: 5
Training loss: 0.7175101491496064
Validation loss: 2.28723626001856

Epoch: 5| Step: 6
Training loss: 0.7507353197987767
Validation loss: 2.2975511803581985

Epoch: 5| Step: 7
Training loss: 0.5590909332499531
Validation loss: 2.3193856228319207

Epoch: 5| Step: 8
Training loss: 0.8109717301216977
Validation loss: 2.3401455426851934

Epoch: 5| Step: 9
Training loss: 0.6159672081303745
Validation loss: 2.3513899128540814

Epoch: 5| Step: 10
Training loss: 0.6326285671848862
Validation loss: 2.3868042114375214

Epoch: 362| Step: 0
Training loss: 0.5371867176203331
Validation loss: 2.364801207542566

Epoch: 5| Step: 1
Training loss: 0.7511399665518415
Validation loss: 2.386424190980119

Epoch: 5| Step: 2
Training loss: 0.8101233421418199
Validation loss: 2.399057469378462

Epoch: 5| Step: 3
Training loss: 0.6565477286215486
Validation loss: 2.359561323069709

Epoch: 5| Step: 4
Training loss: 0.5715377918240077
Validation loss: 2.3733429646766098

Epoch: 5| Step: 5
Training loss: 0.7798034245423904
Validation loss: 2.348639558244286

Epoch: 5| Step: 6
Training loss: 0.30809265206788766
Validation loss: 2.313638996963669

Epoch: 5| Step: 7
Training loss: 0.7209049758883338
Validation loss: 2.333281343586983

Epoch: 5| Step: 8
Training loss: 0.718552354921338
Validation loss: 2.3065617524680833

Epoch: 5| Step: 9
Training loss: 0.7270775886753205
Validation loss: 2.297809216911415

Epoch: 5| Step: 10
Training loss: 0.666455545871729
Validation loss: 2.3007494675310105

Epoch: 363| Step: 0
Training loss: 0.5266833090365887
Validation loss: 2.3043096283682285

Epoch: 5| Step: 1
Training loss: 0.6353414652573505
Validation loss: 2.312478623295552

Epoch: 5| Step: 2
Training loss: 0.569905436267618
Validation loss: 2.3188060019939813

Epoch: 5| Step: 3
Training loss: 0.7171167808355603
Validation loss: 2.380963203622389

Epoch: 5| Step: 4
Training loss: 0.7424134964436535
Validation loss: 2.3901062220939635

Epoch: 5| Step: 5
Training loss: 0.8261524676124417
Validation loss: 2.4147825987353446

Epoch: 5| Step: 6
Training loss: 0.7966337025644559
Validation loss: 2.3361480241589123

Epoch: 5| Step: 7
Training loss: 0.38388817359184785
Validation loss: 2.3363574090243033

Epoch: 5| Step: 8
Training loss: 0.5500223870489594
Validation loss: 2.31415530323461

Epoch: 5| Step: 9
Training loss: 0.9078510873705581
Validation loss: 2.283745409308263

Epoch: 5| Step: 10
Training loss: 0.5857845106667536
Validation loss: 2.265004701037917

Epoch: 364| Step: 0
Training loss: 0.7230448734661739
Validation loss: 2.2885246839204094

Epoch: 5| Step: 1
Training loss: 0.48759505311136225
Validation loss: 2.3129049366215413

Epoch: 5| Step: 2
Training loss: 0.5876005350492208
Validation loss: 2.310199573899107

Epoch: 5| Step: 3
Training loss: 1.0803888298260844
Validation loss: 2.3963778137022667

Epoch: 5| Step: 4
Training loss: 0.42850279045531753
Validation loss: 2.3875737201038585

Epoch: 5| Step: 5
Training loss: 0.7433737660717381
Validation loss: 2.403241999934228

Epoch: 5| Step: 6
Training loss: 0.5999075679312503
Validation loss: 2.358838526780793

Epoch: 5| Step: 7
Training loss: 0.4634944823892393
Validation loss: 2.3647063451307697

Epoch: 5| Step: 8
Training loss: 0.5844604694877399
Validation loss: 2.3218373707117093

Epoch: 5| Step: 9
Training loss: 0.8048763238783706
Validation loss: 2.3124991541370106

Epoch: 5| Step: 10
Training loss: 0.6424682894351187
Validation loss: 2.261853209353016

Epoch: 365| Step: 0
Training loss: 0.544557976306281
Validation loss: 2.2957528510710885

Epoch: 5| Step: 1
Training loss: 0.5898887920234455
Validation loss: 2.3285945846281844

Epoch: 5| Step: 2
Training loss: 0.6382380187243242
Validation loss: 2.3310468273795957

Epoch: 5| Step: 3
Training loss: 0.30067638947348285
Validation loss: 2.3698805157596494

Epoch: 5| Step: 4
Training loss: 0.6932490301307692
Validation loss: 2.337060819374038

Epoch: 5| Step: 5
Training loss: 0.6826056614504377
Validation loss: 2.3553266301961098

Epoch: 5| Step: 6
Training loss: 0.7160799354520847
Validation loss: 2.3073363996440808

Epoch: 5| Step: 7
Training loss: 0.6912661911653044
Validation loss: 2.2650116166175462

Epoch: 5| Step: 8
Training loss: 0.8999741060452636
Validation loss: 2.2682020479312768

Epoch: 5| Step: 9
Training loss: 0.7794960933731775
Validation loss: 2.303421138114817

Epoch: 5| Step: 10
Training loss: 0.6885366859967662
Validation loss: 2.3063537903336666

Epoch: 366| Step: 0
Training loss: 0.610166378156977
Validation loss: 2.345053699465498

Epoch: 5| Step: 1
Training loss: 0.8661279133227296
Validation loss: 2.4055745050709754

Epoch: 5| Step: 2
Training loss: 0.695675808575358
Validation loss: 2.4335200377054567

Epoch: 5| Step: 3
Training loss: 0.6530708327030582
Validation loss: 2.390588126185374

Epoch: 5| Step: 4
Training loss: 0.8324442451868816
Validation loss: 2.334827877984904

Epoch: 5| Step: 5
Training loss: 0.5798313116714717
Validation loss: 2.326748917189447

Epoch: 5| Step: 6
Training loss: 0.5936718437555252
Validation loss: 2.2638202657422952

Epoch: 5| Step: 7
Training loss: 0.5593077358103048
Validation loss: 2.2582881707590734

Epoch: 5| Step: 8
Training loss: 0.5459403361447169
Validation loss: 2.280080066283258

Epoch: 5| Step: 9
Training loss: 0.634048455855053
Validation loss: 2.300951897420262

Epoch: 5| Step: 10
Training loss: 0.7254133673879001
Validation loss: 2.3489702331432176

Epoch: 367| Step: 0
Training loss: 0.677411071001367
Validation loss: 2.4633823119413285

Epoch: 5| Step: 1
Training loss: 0.7800349514417503
Validation loss: 2.5086767571586313

Epoch: 5| Step: 2
Training loss: 0.6183840584663052
Validation loss: 2.391159400027036

Epoch: 5| Step: 3
Training loss: 0.7450516698187906
Validation loss: 2.304651800219456

Epoch: 5| Step: 4
Training loss: 0.7688937959862031
Validation loss: 2.244451008519087

Epoch: 5| Step: 5
Training loss: 0.7567213796238694
Validation loss: 2.2557705596130075

Epoch: 5| Step: 6
Training loss: 0.7246699963323233
Validation loss: 2.26889637546897

Epoch: 5| Step: 7
Training loss: 0.3431666908749712
Validation loss: 2.318790744849947

Epoch: 5| Step: 8
Training loss: 0.6515089621377584
Validation loss: 2.3682831068176533

Epoch: 5| Step: 9
Training loss: 0.6320052001262353
Validation loss: 2.4009690961885353

Epoch: 5| Step: 10
Training loss: 0.797872629436143
Validation loss: 2.4121056306785102

Epoch: 368| Step: 0
Training loss: 0.5029060135982268
Validation loss: 2.377160698346742

Epoch: 5| Step: 1
Training loss: 0.731852195443099
Validation loss: 2.3563250499732686

Epoch: 5| Step: 2
Training loss: 0.7452123338739307
Validation loss: 2.224343026080381

Epoch: 5| Step: 3
Training loss: 0.6905214283813484
Validation loss: 2.259881972309951

Epoch: 5| Step: 4
Training loss: 0.7390871039845751
Validation loss: 2.2329874363456845

Epoch: 5| Step: 5
Training loss: 0.8029917654705515
Validation loss: 2.262704762858503

Epoch: 5| Step: 6
Training loss: 0.8154678061706964
Validation loss: 2.295043427672204

Epoch: 5| Step: 7
Training loss: 0.367870446455963
Validation loss: 2.3513164157795026

Epoch: 5| Step: 8
Training loss: 0.7185290453089818
Validation loss: 2.4235861119845454

Epoch: 5| Step: 9
Training loss: 0.5527918216251474
Validation loss: 2.4163808331814636

Epoch: 5| Step: 10
Training loss: 0.4155988082663969
Validation loss: 2.3999337253854076

Epoch: 369| Step: 0
Training loss: 0.6195937703589045
Validation loss: 2.3646418430652925

Epoch: 5| Step: 1
Training loss: 0.5908545870336648
Validation loss: 2.341963803681325

Epoch: 5| Step: 2
Training loss: 0.7382643763314375
Validation loss: 2.302237680391295

Epoch: 5| Step: 3
Training loss: 0.7570144934910826
Validation loss: 2.2743413231049496

Epoch: 5| Step: 4
Training loss: 0.4771830474006251
Validation loss: 2.2502869408239174

Epoch: 5| Step: 5
Training loss: 0.6264872260789351
Validation loss: 2.2816880980246568

Epoch: 5| Step: 6
Training loss: 0.848535951413592
Validation loss: 2.3103721582482706

Epoch: 5| Step: 7
Training loss: 0.66485812824987
Validation loss: 2.3568828589905197

Epoch: 5| Step: 8
Training loss: 0.6206981910811957
Validation loss: 2.4050490817556756

Epoch: 5| Step: 9
Training loss: 0.5891937059144625
Validation loss: 2.456975039877274

Epoch: 5| Step: 10
Training loss: 0.6594656542973024
Validation loss: 2.4807772224252616

Epoch: 370| Step: 0
Training loss: 0.4412455646086649
Validation loss: 2.4698422457236324

Epoch: 5| Step: 1
Training loss: 0.6642562807868003
Validation loss: 2.3902386358425196

Epoch: 5| Step: 2
Training loss: 0.7552061190517894
Validation loss: 2.2779775340664057

Epoch: 5| Step: 3
Training loss: 0.4505560333818697
Validation loss: 2.2520036059824475

Epoch: 5| Step: 4
Training loss: 0.7805988650074007
Validation loss: 2.243028693689834

Epoch: 5| Step: 5
Training loss: 0.6050275117750682
Validation loss: 2.269683753130714

Epoch: 5| Step: 6
Training loss: 0.5408614727433071
Validation loss: 2.2738382110165403

Epoch: 5| Step: 7
Training loss: 0.7055920870110176
Validation loss: 2.3559025386608132

Epoch: 5| Step: 8
Training loss: 0.7149802322589466
Validation loss: 2.4434747013020486

Epoch: 5| Step: 9
Training loss: 0.8186714833591099
Validation loss: 2.4527168004845126

Epoch: 5| Step: 10
Training loss: 0.679664940295226
Validation loss: 2.4182939764780924

Epoch: 371| Step: 0
Training loss: 0.8670664178669972
Validation loss: 2.363822519355153

Epoch: 5| Step: 1
Training loss: 0.5745867892662315
Validation loss: 2.3386533427180876

Epoch: 5| Step: 2
Training loss: 0.6610231069040622
Validation loss: 2.3343228444541912

Epoch: 5| Step: 3
Training loss: 0.7013191982201326
Validation loss: 2.3326520899499217

Epoch: 5| Step: 4
Training loss: 0.5954779277445588
Validation loss: 2.287172170802088

Epoch: 5| Step: 5
Training loss: 0.5122026965136973
Validation loss: 2.3067705677121326

Epoch: 5| Step: 6
Training loss: 0.43517698310483033
Validation loss: 2.2836145386674334

Epoch: 5| Step: 7
Training loss: 0.29881159418795
Validation loss: 2.2942758262872056

Epoch: 5| Step: 8
Training loss: 0.7621479879087313
Validation loss: 2.3234272130966076

Epoch: 5| Step: 9
Training loss: 0.6181663525193932
Validation loss: 2.31081262968456

Epoch: 5| Step: 10
Training loss: 0.7250641169642216
Validation loss: 2.3194552928047076

Epoch: 372| Step: 0
Training loss: 0.5090773455830245
Validation loss: 2.3432989308538326

Epoch: 5| Step: 1
Training loss: 0.7604842917972557
Validation loss: 2.331105515345503

Epoch: 5| Step: 2
Training loss: 0.6682642233006004
Validation loss: 2.3325059118803644

Epoch: 5| Step: 3
Training loss: 0.6822091166714418
Validation loss: 2.3305985762986836

Epoch: 5| Step: 4
Training loss: 0.555453000603233
Validation loss: 2.3285450165232024

Epoch: 5| Step: 5
Training loss: 0.39596399442911734
Validation loss: 2.3677017084995047

Epoch: 5| Step: 6
Training loss: 0.6680201014361012
Validation loss: 2.4184507097438854

Epoch: 5| Step: 7
Training loss: 0.7142330124690516
Validation loss: 2.3893595635879943

Epoch: 5| Step: 8
Training loss: 0.5424933788229511
Validation loss: 2.3708036014467333

Epoch: 5| Step: 9
Training loss: 0.7475766927869043
Validation loss: 2.3624429502607356

Epoch: 5| Step: 10
Training loss: 0.5878993949362737
Validation loss: 2.308223712685018

Epoch: 373| Step: 0
Training loss: 0.8502399779000817
Validation loss: 2.2808541282996395

Epoch: 5| Step: 1
Training loss: 0.6940572316099891
Validation loss: 2.236464232953536

Epoch: 5| Step: 2
Training loss: 0.6452346662453039
Validation loss: 2.242663184637705

Epoch: 5| Step: 3
Training loss: 0.647298478908275
Validation loss: 2.257333491144637

Epoch: 5| Step: 4
Training loss: 0.5559549760135553
Validation loss: 2.2848151703461683

Epoch: 5| Step: 5
Training loss: 0.7126698609373604
Validation loss: 2.319240416998783

Epoch: 5| Step: 6
Training loss: 0.6534083924270937
Validation loss: 2.3971984801156445

Epoch: 5| Step: 7
Training loss: 0.40426801495584097
Validation loss: 2.3970082013709466

Epoch: 5| Step: 8
Training loss: 0.3959752276058375
Validation loss: 2.3944549251284797

Epoch: 5| Step: 9
Training loss: 0.5097785451135973
Validation loss: 2.3963185194042986

Epoch: 5| Step: 10
Training loss: 0.5895614959213262
Validation loss: 2.400354498229713

Epoch: 374| Step: 0
Training loss: 0.5243920973399087
Validation loss: 2.377911560295411

Epoch: 5| Step: 1
Training loss: 0.7837485984777547
Validation loss: 2.3718751568961527

Epoch: 5| Step: 2
Training loss: 0.7892375034361577
Validation loss: 2.3380293216486865

Epoch: 5| Step: 3
Training loss: 0.4391387832459106
Validation loss: 2.304923050072702

Epoch: 5| Step: 4
Training loss: 0.5969607725977799
Validation loss: 2.289476429394976

Epoch: 5| Step: 5
Training loss: 0.527485524652387
Validation loss: 2.265613847534657

Epoch: 5| Step: 6
Training loss: 0.6873081546488946
Validation loss: 2.301241056383852

Epoch: 5| Step: 7
Training loss: 0.26082696857903304
Validation loss: 2.3137299809437697

Epoch: 5| Step: 8
Training loss: 0.7843115138771861
Validation loss: 2.3310368083546216

Epoch: 5| Step: 9
Training loss: 0.5868896631637325
Validation loss: 2.3787785465891966

Epoch: 5| Step: 10
Training loss: 0.5509409030543064
Validation loss: 2.368680454148507

Epoch: 375| Step: 0
Training loss: 0.6012673087216059
Validation loss: 2.4028863707065

Epoch: 5| Step: 1
Training loss: 0.5481050554254991
Validation loss: 2.401937584031947

Epoch: 5| Step: 2
Training loss: 0.5691534571094506
Validation loss: 2.3771012482400296

Epoch: 5| Step: 3
Training loss: 0.4944304268554915
Validation loss: 2.3272507584169495

Epoch: 5| Step: 4
Training loss: 0.6095683940257128
Validation loss: 2.282216052817304

Epoch: 5| Step: 5
Training loss: 0.6139280710786555
Validation loss: 2.2782821184045483

Epoch: 5| Step: 6
Training loss: 0.8350195791610188
Validation loss: 2.2657088205166596

Epoch: 5| Step: 7
Training loss: 0.4161390918317723
Validation loss: 2.277722293488712

Epoch: 5| Step: 8
Training loss: 0.53635989523613
Validation loss: 2.2826596314471375

Epoch: 5| Step: 9
Training loss: 0.6558018925589767
Validation loss: 2.3102894654899617

Epoch: 5| Step: 10
Training loss: 0.5833674716042748
Validation loss: 2.3240822648313237

Epoch: 376| Step: 0
Training loss: 0.7084165879483507
Validation loss: 2.3369441392940615

Epoch: 5| Step: 1
Training loss: 0.6420256491941542
Validation loss: 2.3143046852653137

Epoch: 5| Step: 2
Training loss: 0.6179729967899742
Validation loss: 2.328053563281375

Epoch: 5| Step: 3
Training loss: 0.588071041368276
Validation loss: 2.3170185492770177

Epoch: 5| Step: 4
Training loss: 0.7747742631774375
Validation loss: 2.3100096550171343

Epoch: 5| Step: 5
Training loss: 0.4166334874135278
Validation loss: 2.3218579176191283

Epoch: 5| Step: 6
Training loss: 0.5551529127257404
Validation loss: 2.3179782630513985

Epoch: 5| Step: 7
Training loss: 0.533068405850372
Validation loss: 2.319794367010515

Epoch: 5| Step: 8
Training loss: 0.4586460571092136
Validation loss: 2.3239324953030223

Epoch: 5| Step: 9
Training loss: 0.5109445087290461
Validation loss: 2.336842868131619

Epoch: 5| Step: 10
Training loss: 0.5940119266003042
Validation loss: 2.3408988800396697

Epoch: 377| Step: 0
Training loss: 0.40096374060137435
Validation loss: 2.3746140819012815

Epoch: 5| Step: 1
Training loss: 0.5739026399743472
Validation loss: 2.3491195249783203

Epoch: 5| Step: 2
Training loss: 0.7968197223713919
Validation loss: 2.3302001217035526

Epoch: 5| Step: 3
Training loss: 0.663663093279778
Validation loss: 2.334481436627058

Epoch: 5| Step: 4
Training loss: 0.38076882875490936
Validation loss: 2.3539155086871095

Epoch: 5| Step: 5
Training loss: 0.26752758244889213
Validation loss: 2.3480778374428093

Epoch: 5| Step: 6
Training loss: 0.6607423697213991
Validation loss: 2.331590331797581

Epoch: 5| Step: 7
Training loss: 0.5134793344961907
Validation loss: 2.3109197630082297

Epoch: 5| Step: 8
Training loss: 0.6730389825376988
Validation loss: 2.324297508117977

Epoch: 5| Step: 9
Training loss: 0.592023396967223
Validation loss: 2.3110665182810197

Epoch: 5| Step: 10
Training loss: 0.6955552695285275
Validation loss: 2.291816738580796

Epoch: 378| Step: 0
Training loss: 0.7985081113285086
Validation loss: 2.2640520247129583

Epoch: 5| Step: 1
Training loss: 0.678120395978777
Validation loss: 2.300317295029673

Epoch: 5| Step: 2
Training loss: 0.867457648460992
Validation loss: 2.356143695879925

Epoch: 5| Step: 3
Training loss: 0.45372347935499474
Validation loss: 2.3453095113116498

Epoch: 5| Step: 4
Training loss: 0.3419770338185814
Validation loss: 2.373595612111072

Epoch: 5| Step: 5
Training loss: 0.5007520324943838
Validation loss: 2.3813071232463643

Epoch: 5| Step: 6
Training loss: 0.7255117550455606
Validation loss: 2.3961952788538077

Epoch: 5| Step: 7
Training loss: 0.43194008705248677
Validation loss: 2.3648479093742867

Epoch: 5| Step: 8
Training loss: 0.4173033221339509
Validation loss: 2.323085313242194

Epoch: 5| Step: 9
Training loss: 0.48716620730886206
Validation loss: 2.2611198172800973

Epoch: 5| Step: 10
Training loss: 0.47535944564493304
Validation loss: 2.2729027553390657

Epoch: 379| Step: 0
Training loss: 0.45198128496306506
Validation loss: 2.3248236258167223

Epoch: 5| Step: 1
Training loss: 0.6005038817881345
Validation loss: 2.3371219121510025

Epoch: 5| Step: 2
Training loss: 0.5712548139690674
Validation loss: 2.404967553468597

Epoch: 5| Step: 3
Training loss: 0.7141732578648532
Validation loss: 2.408984154029548

Epoch: 5| Step: 4
Training loss: 0.711177827227053
Validation loss: 2.4001498610954486

Epoch: 5| Step: 5
Training loss: 0.7375348066747927
Validation loss: 2.331656965327194

Epoch: 5| Step: 6
Training loss: 0.6133386621511517
Validation loss: 2.322678833619875

Epoch: 5| Step: 7
Training loss: 0.28198753451381764
Validation loss: 2.261960037789513

Epoch: 5| Step: 8
Training loss: 0.591737372803141
Validation loss: 2.3070212496261457

Epoch: 5| Step: 9
Training loss: 0.30540029583147205
Validation loss: 2.3196410133566676

Epoch: 5| Step: 10
Training loss: 0.6250644173803941
Validation loss: 2.311011705443612

Epoch: 380| Step: 0
Training loss: 0.2524156981609458
Validation loss: 2.288617910829483

Epoch: 5| Step: 1
Training loss: 0.7344943822044722
Validation loss: 2.3415687731358883

Epoch: 5| Step: 2
Training loss: 0.6659410272699078
Validation loss: 2.369879975961624

Epoch: 5| Step: 3
Training loss: 0.6571152523377959
Validation loss: 2.3916485192092503

Epoch: 5| Step: 4
Training loss: 0.7330605125845879
Validation loss: 2.3527134798687017

Epoch: 5| Step: 5
Training loss: 0.4761044693163577
Validation loss: 2.3246988910644935

Epoch: 5| Step: 6
Training loss: 0.47243724825110894
Validation loss: 2.3151935686691836

Epoch: 5| Step: 7
Training loss: 0.5205457720057106
Validation loss: 2.2847154832919636

Epoch: 5| Step: 8
Training loss: 0.6619024262766062
Validation loss: 2.3306337735885405

Epoch: 5| Step: 9
Training loss: 0.580917573025845
Validation loss: 2.347041371291509

Epoch: 5| Step: 10
Training loss: 0.3283921811553883
Validation loss: 2.3782474840890995

Epoch: 381| Step: 0
Training loss: 0.5261261906717992
Validation loss: 2.4368534792570045

Epoch: 5| Step: 1
Training loss: 0.4636653099462998
Validation loss: 2.3851534926691365

Epoch: 5| Step: 2
Training loss: 0.3868719625893021
Validation loss: 2.3755964286954234

Epoch: 5| Step: 3
Training loss: 0.74601357713315
Validation loss: 2.3488086681590468

Epoch: 5| Step: 4
Training loss: 0.6874315054325448
Validation loss: 2.2992244031135147

Epoch: 5| Step: 5
Training loss: 0.589589373576717
Validation loss: 2.2855124070603154

Epoch: 5| Step: 6
Training loss: 0.5547480214372914
Validation loss: 2.2925877961898005

Epoch: 5| Step: 7
Training loss: 0.6108998269956178
Validation loss: 2.313557889196607

Epoch: 5| Step: 8
Training loss: 0.48812172381856067
Validation loss: 2.3100292195368235

Epoch: 5| Step: 9
Training loss: 0.5837424296964417
Validation loss: 2.3444450348706534

Epoch: 5| Step: 10
Training loss: 0.695817335500716
Validation loss: 2.37070461908304

Epoch: 382| Step: 0
Training loss: 0.5253219275958958
Validation loss: 2.31960857308358

Epoch: 5| Step: 1
Training loss: 0.5560497427085059
Validation loss: 2.329809079256738

Epoch: 5| Step: 2
Training loss: 0.6999397183756193
Validation loss: 2.313865515098743

Epoch: 5| Step: 3
Training loss: 0.7543061534877895
Validation loss: 2.2761791406713585

Epoch: 5| Step: 4
Training loss: 0.5275566519015528
Validation loss: 2.267532011114735

Epoch: 5| Step: 5
Training loss: 0.7532475810982259
Validation loss: 2.3344344809104727

Epoch: 5| Step: 6
Training loss: 0.25537853339538097
Validation loss: 2.3803527282729964

Epoch: 5| Step: 7
Training loss: 0.5608228741681832
Validation loss: 2.4308069348366645

Epoch: 5| Step: 8
Training loss: 0.5723593052555288
Validation loss: 2.42581740814369

Epoch: 5| Step: 9
Training loss: 0.3670671143919707
Validation loss: 2.419002606881674

Epoch: 5| Step: 10
Training loss: 0.49452437325226667
Validation loss: 2.385227179901562

Epoch: 383| Step: 0
Training loss: 0.6186496942308349
Validation loss: 2.3160394666186224

Epoch: 5| Step: 1
Training loss: 0.532574685012745
Validation loss: 2.319863388180446

Epoch: 5| Step: 2
Training loss: 0.5336789533692683
Validation loss: 2.2692297106708823

Epoch: 5| Step: 3
Training loss: 0.6401786179437068
Validation loss: 2.2696841354713286

Epoch: 5| Step: 4
Training loss: 0.5046776478281119
Validation loss: 2.2919781276520634

Epoch: 5| Step: 5
Training loss: 0.5648362070848906
Validation loss: 2.3219356671758105

Epoch: 5| Step: 6
Training loss: 0.5294419825218569
Validation loss: 2.378435710529632

Epoch: 5| Step: 7
Training loss: 0.34997481953776827
Validation loss: 2.3991321315265224

Epoch: 5| Step: 8
Training loss: 0.36309229130595155
Validation loss: 2.414871287948839

Epoch: 5| Step: 9
Training loss: 0.7320326114018991
Validation loss: 2.3903087074563376

Epoch: 5| Step: 10
Training loss: 0.7390789989863779
Validation loss: 2.3494815364237227

Epoch: 384| Step: 0
Training loss: 0.4409087086124425
Validation loss: 2.3137754931979777

Epoch: 5| Step: 1
Training loss: 0.4390342241732669
Validation loss: 2.316905595656678

Epoch: 5| Step: 2
Training loss: 0.5757121434141447
Validation loss: 2.275875925688273

Epoch: 5| Step: 3
Training loss: 0.4550444136154376
Validation loss: 2.293253141590252

Epoch: 5| Step: 4
Training loss: 0.42658504244866957
Validation loss: 2.3466766133312023

Epoch: 5| Step: 5
Training loss: 0.7725102810345288
Validation loss: 2.371464164925419

Epoch: 5| Step: 6
Training loss: 0.7477199148657762
Validation loss: 2.421779449409271

Epoch: 5| Step: 7
Training loss: 0.546695843369623
Validation loss: 2.403053025985494

Epoch: 5| Step: 8
Training loss: 0.6604776672165611
Validation loss: 2.37490281498267

Epoch: 5| Step: 9
Training loss: 0.4196728877508376
Validation loss: 2.306707176828082

Epoch: 5| Step: 10
Training loss: 0.5695243772241164
Validation loss: 2.265532259515761

Epoch: 385| Step: 0
Training loss: 0.6922295189497231
Validation loss: 2.2746165013980435

Epoch: 5| Step: 1
Training loss: 0.5148973532573295
Validation loss: 2.297683259135833

Epoch: 5| Step: 2
Training loss: 0.5012960623507552
Validation loss: 2.292856961852013

Epoch: 5| Step: 3
Training loss: 0.41260087051493927
Validation loss: 2.3095652330995655

Epoch: 5| Step: 4
Training loss: 0.5904891165587153
Validation loss: 2.3509815902027893

Epoch: 5| Step: 5
Training loss: 0.5429914456022094
Validation loss: 2.3493831223048454

Epoch: 5| Step: 6
Training loss: 0.7159698038793159
Validation loss: 2.3557914226222603

Epoch: 5| Step: 7
Training loss: 0.6598307693147702
Validation loss: 2.3155118938800117

Epoch: 5| Step: 8
Training loss: 0.274367983604516
Validation loss: 2.340962132987766

Epoch: 5| Step: 9
Training loss: 0.4780822971696925
Validation loss: 2.313994686494098

Epoch: 5| Step: 10
Training loss: 0.676444461383825
Validation loss: 2.340838955827947

Epoch: 386| Step: 0
Training loss: 0.6970892290374131
Validation loss: 2.3388132722850368

Epoch: 5| Step: 1
Training loss: 0.5045302615565083
Validation loss: 2.326646717444497

Epoch: 5| Step: 2
Training loss: 0.6975810301962976
Validation loss: 2.3243008181417766

Epoch: 5| Step: 3
Training loss: 0.6218150526894063
Validation loss: 2.3342132279044963

Epoch: 5| Step: 4
Training loss: 0.44733108641154423
Validation loss: 2.3160513287586726

Epoch: 5| Step: 5
Training loss: 0.7053345612813913
Validation loss: 2.3127443782563155

Epoch: 5| Step: 6
Training loss: 0.6033897392064338
Validation loss: 2.30923383358102

Epoch: 5| Step: 7
Training loss: 0.3060561398567254
Validation loss: 2.306256942900867

Epoch: 5| Step: 8
Training loss: 0.4853505339889835
Validation loss: 2.3216215073324658

Epoch: 5| Step: 9
Training loss: 0.33794915238136003
Validation loss: 2.319902516614718

Epoch: 5| Step: 10
Training loss: 0.2927709165824682
Validation loss: 2.334970325393748

Epoch: 387| Step: 0
Training loss: 0.491571601133494
Validation loss: 2.363387035394565

Epoch: 5| Step: 1
Training loss: 0.5931263961614772
Validation loss: 2.3399382672871414

Epoch: 5| Step: 2
Training loss: 0.46122254432075355
Validation loss: 2.315383495818566

Epoch: 5| Step: 3
Training loss: 0.5085253773567424
Validation loss: 2.29968608592797

Epoch: 5| Step: 4
Training loss: 0.6272098098991258
Validation loss: 2.2835026627904234

Epoch: 5| Step: 5
Training loss: 0.5592071792927542
Validation loss: 2.301976095395044

Epoch: 5| Step: 6
Training loss: 0.5759384975745534
Validation loss: 2.299681171979034

Epoch: 5| Step: 7
Training loss: 0.34078603315254236
Validation loss: 2.326199090845838

Epoch: 5| Step: 8
Training loss: 0.3059187489219371
Validation loss: 2.3606737217801346

Epoch: 5| Step: 9
Training loss: 0.6843384310562985
Validation loss: 2.4001799828712063

Epoch: 5| Step: 10
Training loss: 0.6348544249410516
Validation loss: 2.3764820267528717

Epoch: 388| Step: 0
Training loss: 0.7293216041168655
Validation loss: 2.3510611157720955

Epoch: 5| Step: 1
Training loss: 0.4673451830536844
Validation loss: 2.323412394554699

Epoch: 5| Step: 2
Training loss: 0.4972674385511196
Validation loss: 2.288705841348337

Epoch: 5| Step: 3
Training loss: 0.5287306174204458
Validation loss: 2.2736488776551207

Epoch: 5| Step: 4
Training loss: 0.7273474524185566
Validation loss: 2.2489908432325048

Epoch: 5| Step: 5
Training loss: 0.6610163215549678
Validation loss: 2.3053037825788167

Epoch: 5| Step: 6
Training loss: 0.2072988436205695
Validation loss: 2.3090694088703474

Epoch: 5| Step: 7
Training loss: 0.6407531517061436
Validation loss: 2.4219206806681863

Epoch: 5| Step: 8
Training loss: 0.3940358214456932
Validation loss: 2.409748344628118

Epoch: 5| Step: 9
Training loss: 0.41793463024022964
Validation loss: 2.3634873167048336

Epoch: 5| Step: 10
Training loss: 0.37657504318050666
Validation loss: 2.3166041014152094

Epoch: 389| Step: 0
Training loss: 0.5528993933115663
Validation loss: 2.3459290042579775

Epoch: 5| Step: 1
Training loss: 0.5486863519952264
Validation loss: 2.3015751439007546

Epoch: 5| Step: 2
Training loss: 0.4369483944496823
Validation loss: 2.328575141963957

Epoch: 5| Step: 3
Training loss: 0.5222552598767806
Validation loss: 2.347244183670871

Epoch: 5| Step: 4
Training loss: 0.45261876009938445
Validation loss: 2.3811731636540516

Epoch: 5| Step: 5
Training loss: 0.4846242447975853
Validation loss: 2.390865581111125

Epoch: 5| Step: 6
Training loss: 0.6740735698882144
Validation loss: 2.3570229309784247

Epoch: 5| Step: 7
Training loss: 0.4285131011026171
Validation loss: 2.369014728292705

Epoch: 5| Step: 8
Training loss: 0.44399451248755806
Validation loss: 2.3491901770506227

Epoch: 5| Step: 9
Training loss: 0.7050014887449089
Validation loss: 2.343259430547635

Epoch: 5| Step: 10
Training loss: 0.6480001100448821
Validation loss: 2.37249252817294

Epoch: 390| Step: 0
Training loss: 0.6850682731700469
Validation loss: 2.3777589419517864

Epoch: 5| Step: 1
Training loss: 0.553206252471871
Validation loss: 2.3623529444103797

Epoch: 5| Step: 2
Training loss: 0.6035235753199285
Validation loss: 2.383836362374626

Epoch: 5| Step: 3
Training loss: 0.32554639588758577
Validation loss: 2.3479611821177544

Epoch: 5| Step: 4
Training loss: 0.4434702898339766
Validation loss: 2.3319338171844493

Epoch: 5| Step: 5
Training loss: 0.4729647614758584
Validation loss: 2.345788459987594

Epoch: 5| Step: 6
Training loss: 0.36504920304502303
Validation loss: 2.366572870975101

Epoch: 5| Step: 7
Training loss: 0.4459675772454174
Validation loss: 2.344604861319689

Epoch: 5| Step: 8
Training loss: 0.5564433501166476
Validation loss: 2.3536275263895674

Epoch: 5| Step: 9
Training loss: 0.6996797288784258
Validation loss: 2.3325310232697203

Epoch: 5| Step: 10
Training loss: 0.49426049448448023
Validation loss: 2.3443354312316034

Epoch: 391| Step: 0
Training loss: 0.41422901763910774
Validation loss: 2.3439539962098253

Epoch: 5| Step: 1
Training loss: 0.40636367307898064
Validation loss: 2.339682991284499

Epoch: 5| Step: 2
Training loss: 0.47738921265821915
Validation loss: 2.3028094638232246

Epoch: 5| Step: 3
Training loss: 0.5868137673800969
Validation loss: 2.330746942946061

Epoch: 5| Step: 4
Training loss: 0.5203921706688248
Validation loss: 2.3647420673687107

Epoch: 5| Step: 5
Training loss: 0.6811966857696814
Validation loss: 2.3274191720843476

Epoch: 5| Step: 6
Training loss: 0.43556401514103743
Validation loss: 2.3285140451424398

Epoch: 5| Step: 7
Training loss: 0.5092379590438264
Validation loss: 2.3303710796247192

Epoch: 5| Step: 8
Training loss: 0.6165379836732605
Validation loss: 2.3376634974580677

Epoch: 5| Step: 9
Training loss: 0.19831802533648987
Validation loss: 2.3102816456879833

Epoch: 5| Step: 10
Training loss: 0.6928776101578148
Validation loss: 2.3664519303858587

Epoch: 392| Step: 0
Training loss: 0.424070350585549
Validation loss: 2.338439119889127

Epoch: 5| Step: 1
Training loss: 0.5298311415724266
Validation loss: 2.344736211421294

Epoch: 5| Step: 2
Training loss: 0.6870442960887277
Validation loss: 2.3482497015646953

Epoch: 5| Step: 3
Training loss: 0.4621602344014889
Validation loss: 2.34300552412232

Epoch: 5| Step: 4
Training loss: 0.5481979988318391
Validation loss: 2.3042413273062383

Epoch: 5| Step: 5
Training loss: 0.5869645082752775
Validation loss: 2.3352038292143646

Epoch: 5| Step: 6
Training loss: 0.4022865439921334
Validation loss: 2.3105814901217743

Epoch: 5| Step: 7
Training loss: 0.4718252711587019
Validation loss: 2.307248581361075

Epoch: 5| Step: 8
Training loss: 0.5924829465689467
Validation loss: 2.3397599507479936

Epoch: 5| Step: 9
Training loss: 0.4397826421646921
Validation loss: 2.3288884298316748

Epoch: 5| Step: 10
Training loss: 0.47294209246688723
Validation loss: 2.340213051098216

Epoch: 393| Step: 0
Training loss: 0.43380122333022597
Validation loss: 2.386868446478

Epoch: 5| Step: 1
Training loss: 0.48819310727877635
Validation loss: 2.4030175164032688

Epoch: 5| Step: 2
Training loss: 0.3346804342405601
Validation loss: 2.365213109363493

Epoch: 5| Step: 3
Training loss: 0.625697390572568
Validation loss: 2.369545236400343

Epoch: 5| Step: 4
Training loss: 0.4344736398903123
Validation loss: 2.3832082165984927

Epoch: 5| Step: 5
Training loss: 0.5515746226072695
Validation loss: 2.3299259218976758

Epoch: 5| Step: 6
Training loss: 0.44830521283834324
Validation loss: 2.3399933524029026

Epoch: 5| Step: 7
Training loss: 0.4886017014869298
Validation loss: 2.319878528867568

Epoch: 5| Step: 8
Training loss: 0.4127110793734679
Validation loss: 2.324133645568838

Epoch: 5| Step: 9
Training loss: 0.7296226211229357
Validation loss: 2.3382355372035

Epoch: 5| Step: 10
Training loss: 0.5171497515591045
Validation loss: 2.2934661676213

Epoch: 394| Step: 0
Training loss: 0.42913463744606917
Validation loss: 2.268764530764637

Epoch: 5| Step: 1
Training loss: 0.4572179201165628
Validation loss: 2.331492079518912

Epoch: 5| Step: 2
Training loss: 0.38887313922521494
Validation loss: 2.3004861982985387

Epoch: 5| Step: 3
Training loss: 0.6671694607942602
Validation loss: 2.3238866347970446

Epoch: 5| Step: 4
Training loss: 0.21923017593048036
Validation loss: 2.3913679883204058

Epoch: 5| Step: 5
Training loss: 0.5749942965846608
Validation loss: 2.389787428969829

Epoch: 5| Step: 6
Training loss: 0.7193722312071915
Validation loss: 2.3736056675070456

Epoch: 5| Step: 7
Training loss: 0.5915460590107136
Validation loss: 2.3535973512700985

Epoch: 5| Step: 8
Training loss: 0.5007461107039188
Validation loss: 2.3681234213028315

Epoch: 5| Step: 9
Training loss: 0.350422792010724
Validation loss: 2.3338473295175852

Epoch: 5| Step: 10
Training loss: 0.4737195279681025
Validation loss: 2.3514499988299415

Epoch: 395| Step: 0
Training loss: 0.5003746834210041
Validation loss: 2.4042335289253867

Epoch: 5| Step: 1
Training loss: 0.7512800498830002
Validation loss: 2.448679530538448

Epoch: 5| Step: 2
Training loss: 0.5893438380752224
Validation loss: 2.4632472873728424

Epoch: 5| Step: 3
Training loss: 0.4358366100918703
Validation loss: 2.356511967760702

Epoch: 5| Step: 4
Training loss: 0.3689142976470383
Validation loss: 2.3187044140577746

Epoch: 5| Step: 5
Training loss: 0.599819010020419
Validation loss: 2.315461501527587

Epoch: 5| Step: 6
Training loss: 0.44305754146742055
Validation loss: 2.287625945132118

Epoch: 5| Step: 7
Training loss: 0.7884015251476839
Validation loss: 2.3184313724874293

Epoch: 5| Step: 8
Training loss: 0.31967281805651043
Validation loss: 2.3491985712150156

Epoch: 5| Step: 9
Training loss: 0.3758426774668518
Validation loss: 2.3283835944188356

Epoch: 5| Step: 10
Training loss: 0.4936844903004459
Validation loss: 2.4164631057342354

Epoch: 396| Step: 0
Training loss: 0.4795186643418684
Validation loss: 2.350700299120845

Epoch: 5| Step: 1
Training loss: 0.5653146946381017
Validation loss: 2.3573749608016294

Epoch: 5| Step: 2
Training loss: 0.5680236349124773
Validation loss: 2.361222338564942

Epoch: 5| Step: 3
Training loss: 0.4010350321761766
Validation loss: 2.3718754346745183

Epoch: 5| Step: 4
Training loss: 0.6237993867927392
Validation loss: 2.386592313231926

Epoch: 5| Step: 5
Training loss: 0.4780038705114455
Validation loss: 2.405139609895551

Epoch: 5| Step: 6
Training loss: 0.5623934697893274
Validation loss: 2.39005901090478

Epoch: 5| Step: 7
Training loss: 0.6176567949234257
Validation loss: 2.3969143825872816

Epoch: 5| Step: 8
Training loss: 0.3899248715321669
Validation loss: 2.3578980045557048

Epoch: 5| Step: 9
Training loss: 0.4890754801578521
Validation loss: 2.3723904781718534

Epoch: 5| Step: 10
Training loss: 0.5134172570016162
Validation loss: 2.3570353705182323

Epoch: 397| Step: 0
Training loss: 0.6103239007403578
Validation loss: 2.2956995302546157

Epoch: 5| Step: 1
Training loss: 0.5559234013948865
Validation loss: 2.307714913225691

Epoch: 5| Step: 2
Training loss: 0.4844172828431309
Validation loss: 2.339049038259283

Epoch: 5| Step: 3
Training loss: 0.2623765706337438
Validation loss: 2.327189887905814

Epoch: 5| Step: 4
Training loss: 0.49134068074365905
Validation loss: 2.3375657000479246

Epoch: 5| Step: 5
Training loss: 0.35093907074818786
Validation loss: 2.342850574477716

Epoch: 5| Step: 6
Training loss: 0.49341517938498086
Validation loss: 2.3838551456987

Epoch: 5| Step: 7
Training loss: 0.6168963554419364
Validation loss: 2.332682026622128

Epoch: 5| Step: 8
Training loss: 0.5480662858370916
Validation loss: 2.344227424588565

Epoch: 5| Step: 9
Training loss: 0.6057361381525371
Validation loss: 2.3060060961887445

Epoch: 5| Step: 10
Training loss: 0.6301341183893151
Validation loss: 2.292601928337999

Epoch: 398| Step: 0
Training loss: 0.3555874050092917
Validation loss: 2.3199861518720963

Epoch: 5| Step: 1
Training loss: 0.4665352475229305
Validation loss: 2.3139161222459617

Epoch: 5| Step: 2
Training loss: 0.5711121113926522
Validation loss: 2.32437755951799

Epoch: 5| Step: 3
Training loss: 0.5955645540754253
Validation loss: 2.3839251576059923

Epoch: 5| Step: 4
Training loss: 0.5396773936303363
Validation loss: 2.388496587624399

Epoch: 5| Step: 5
Training loss: 0.623926528306873
Validation loss: 2.3777325771883513

Epoch: 5| Step: 6
Training loss: 0.5931584272220584
Validation loss: 2.3631373799051207

Epoch: 5| Step: 7
Training loss: 0.47057741314657814
Validation loss: 2.3656408357441734

Epoch: 5| Step: 8
Training loss: 0.26144014304108865
Validation loss: 2.330557313019874

Epoch: 5| Step: 9
Training loss: 0.4995369406081575
Validation loss: 2.3169561662768756

Epoch: 5| Step: 10
Training loss: 0.4603233448519851
Validation loss: 2.3261570144296706

Epoch: 399| Step: 0
Training loss: 0.36320570703787897
Validation loss: 2.3357002548555217

Epoch: 5| Step: 1
Training loss: 0.6225071545461678
Validation loss: 2.35640101169344

Epoch: 5| Step: 2
Training loss: 0.37049626888939574
Validation loss: 2.4061780891385856

Epoch: 5| Step: 3
Training loss: 0.48165070522430564
Validation loss: 2.4077890218376763

Epoch: 5| Step: 4
Training loss: 0.6482180258445224
Validation loss: 2.3882828022148828

Epoch: 5| Step: 5
Training loss: 0.47913571098789604
Validation loss: 2.39240416218528

Epoch: 5| Step: 6
Training loss: 0.5021781565396977
Validation loss: 2.381341885394895

Epoch: 5| Step: 7
Training loss: 0.45999653996327294
Validation loss: 2.3622967474115213

Epoch: 5| Step: 8
Training loss: 0.45514941987276536
Validation loss: 2.36092255165358

Epoch: 5| Step: 9
Training loss: 0.2709893715514446
Validation loss: 2.325400387402976

Epoch: 5| Step: 10
Training loss: 0.6800157258725755
Validation loss: 2.3421965002897975

Epoch: 400| Step: 0
Training loss: 0.7227381067052862
Validation loss: 2.274133676371943

Epoch: 5| Step: 1
Training loss: 0.583023556699578
Validation loss: 2.314292485726976

Epoch: 5| Step: 2
Training loss: 0.469120546748235
Validation loss: 2.3001568833928037

Epoch: 5| Step: 3
Training loss: 0.2719400547287214
Validation loss: 2.3497660124411457

Epoch: 5| Step: 4
Training loss: 0.4680465506200887
Validation loss: 2.358115001242292

Epoch: 5| Step: 5
Training loss: 0.5106101512734357
Validation loss: 2.3326924347721443

Epoch: 5| Step: 6
Training loss: 0.5076887126580801
Validation loss: 2.373022370064428

Epoch: 5| Step: 7
Training loss: 0.4030537313109943
Validation loss: 2.3647576107454364

Epoch: 5| Step: 8
Training loss: 0.4693133783336045
Validation loss: 2.3734203000753658

Epoch: 5| Step: 9
Training loss: 0.3998124204334098
Validation loss: 2.3064959505880753

Epoch: 5| Step: 10
Training loss: 0.6308225496958619
Validation loss: 2.275457473977746

Epoch: 401| Step: 0
Training loss: 0.4962845082620141
Validation loss: 2.3032980446991034

Epoch: 5| Step: 1
Training loss: 0.5386214456058064
Validation loss: 2.3107090849393757

Epoch: 5| Step: 2
Training loss: 0.5223373124219164
Validation loss: 2.381110787784174

Epoch: 5| Step: 3
Training loss: 0.5637369595476358
Validation loss: 2.355671305871767

Epoch: 5| Step: 4
Training loss: 0.2860047896999486
Validation loss: 2.401297686265415

Epoch: 5| Step: 5
Training loss: 0.5795148432988965
Validation loss: 2.3861488260785704

Epoch: 5| Step: 6
Training loss: 0.47045312471011896
Validation loss: 2.3530401195511277

Epoch: 5| Step: 7
Training loss: 0.43309807152865953
Validation loss: 2.3281548682520747

Epoch: 5| Step: 8
Training loss: 0.35130854016990376
Validation loss: 2.292261414153635

Epoch: 5| Step: 9
Training loss: 0.5628420002019348
Validation loss: 2.3378015474267024

Epoch: 5| Step: 10
Training loss: 0.4497840144466634
Validation loss: 2.363902748943105

Epoch: 402| Step: 0
Training loss: 0.48336116762693576
Validation loss: 2.3417917199000127

Epoch: 5| Step: 1
Training loss: 0.3853206020781154
Validation loss: 2.3747070965202455

Epoch: 5| Step: 2
Training loss: 0.5016084964850142
Validation loss: 2.368098907640035

Epoch: 5| Step: 3
Training loss: 0.33059449970994403
Validation loss: 2.3663749598531365

Epoch: 5| Step: 4
Training loss: 0.35533804114746687
Validation loss: 2.3268328010569537

Epoch: 5| Step: 5
Training loss: 0.6718887726902443
Validation loss: 2.3284864021958764

Epoch: 5| Step: 6
Training loss: 0.6073703560032392
Validation loss: 2.3101393921340256

Epoch: 5| Step: 7
Training loss: 0.42431243789274575
Validation loss: 2.293026043464246

Epoch: 5| Step: 8
Training loss: 0.5157859435470294
Validation loss: 2.3058030087563592

Epoch: 5| Step: 9
Training loss: 0.42648925012589256
Validation loss: 2.3095654484415067

Epoch: 5| Step: 10
Training loss: 0.45595500436586833
Validation loss: 2.3273858417077755

Epoch: 403| Step: 0
Training loss: 0.5337170370496471
Validation loss: 2.341348408915858

Epoch: 5| Step: 1
Training loss: 0.4919386946312647
Validation loss: 2.3581084076273986

Epoch: 5| Step: 2
Training loss: 0.38452361575550165
Validation loss: 2.3777754013168613

Epoch: 5| Step: 3
Training loss: 0.47203810127789136
Validation loss: 2.3486882842101147

Epoch: 5| Step: 4
Training loss: 0.4287691359239458
Validation loss: 2.33757897463445

Epoch: 5| Step: 5
Training loss: 0.3257259930373808
Validation loss: 2.316521972528032

Epoch: 5| Step: 6
Training loss: 0.5410929600497546
Validation loss: 2.299816095526662

Epoch: 5| Step: 7
Training loss: 0.4081488395259444
Validation loss: 2.318863807416944

Epoch: 5| Step: 8
Training loss: 0.3952131892971571
Validation loss: 2.3154123575618004

Epoch: 5| Step: 9
Training loss: 0.62749825899103
Validation loss: 2.328047019972276

Epoch: 5| Step: 10
Training loss: 0.5232416612167531
Validation loss: 2.342419095092257

Epoch: 404| Step: 0
Training loss: 0.3589422896562309
Validation loss: 2.3708804357729205

Epoch: 5| Step: 1
Training loss: 0.5018752219459737
Validation loss: 2.358201714531637

Epoch: 5| Step: 2
Training loss: 0.5128256786449991
Validation loss: 2.350742147801635

Epoch: 5| Step: 3
Training loss: 0.85745291338726
Validation loss: 2.341500390687878

Epoch: 5| Step: 4
Training loss: 0.47824690143680176
Validation loss: 2.3451285548631593

Epoch: 5| Step: 5
Training loss: 0.4060554955764811
Validation loss: 2.30299350280039

Epoch: 5| Step: 6
Training loss: 0.3374156259221722
Validation loss: 2.302996180547399

Epoch: 5| Step: 7
Training loss: 0.45124958244367813
Validation loss: 2.3094736055018545

Epoch: 5| Step: 8
Training loss: 0.2967878514921643
Validation loss: 2.3056685133841186

Epoch: 5| Step: 9
Training loss: 0.36313642670976143
Validation loss: 2.3484953555537658

Epoch: 5| Step: 10
Training loss: 0.3973054886493776
Validation loss: 2.3977301780052276

Epoch: 405| Step: 0
Training loss: 0.5449643682503528
Validation loss: 2.3544978875157203

Epoch: 5| Step: 1
Training loss: 0.46589448926040616
Validation loss: 2.3587490023611686

Epoch: 5| Step: 2
Training loss: 0.49781488737694074
Validation loss: 2.3741351195198406

Epoch: 5| Step: 3
Training loss: 0.40571731710045034
Validation loss: 2.3567413765160934

Epoch: 5| Step: 4
Training loss: 0.4907473126190652
Validation loss: 2.33495854838728

Epoch: 5| Step: 5
Training loss: 0.45212897635776617
Validation loss: 2.352520968495319

Epoch: 5| Step: 6
Training loss: 0.5840530865412241
Validation loss: 2.339256694923825

Epoch: 5| Step: 7
Training loss: 0.3403832001715737
Validation loss: 2.3520414887799617

Epoch: 5| Step: 8
Training loss: 0.5641499533447933
Validation loss: 2.309503349209824

Epoch: 5| Step: 9
Training loss: 0.40950796574168113
Validation loss: 2.345941007586573

Epoch: 5| Step: 10
Training loss: 0.3277835431687449
Validation loss: 2.305194390896936

Epoch: 406| Step: 0
Training loss: 0.4895636541050301
Validation loss: 2.3221459107204296

Epoch: 5| Step: 1
Training loss: 0.4465647207142182
Validation loss: 2.3451821833280166

Epoch: 5| Step: 2
Training loss: 0.5629394192430491
Validation loss: 2.401314038736055

Epoch: 5| Step: 3
Training loss: 0.5283698095802675
Validation loss: 2.40855192133539

Epoch: 5| Step: 4
Training loss: 0.558029583488574
Validation loss: 2.403917771704255

Epoch: 5| Step: 5
Training loss: 0.3076147654604551
Validation loss: 2.3780861294301783

Epoch: 5| Step: 6
Training loss: 0.3935707789460968
Validation loss: 2.4003367582549133

Epoch: 5| Step: 7
Training loss: 0.4506795765211077
Validation loss: 2.324411813161609

Epoch: 5| Step: 8
Training loss: 0.35642137839032006
Validation loss: 2.3421080177494784

Epoch: 5| Step: 9
Training loss: 0.49736520829380754
Validation loss: 2.336448726806478

Epoch: 5| Step: 10
Training loss: 0.3529972680920908
Validation loss: 2.3156044361590338

Epoch: 407| Step: 0
Training loss: 0.4557878256693866
Validation loss: 2.3344303286697725

Epoch: 5| Step: 1
Training loss: 0.45647066737192954
Validation loss: 2.3463563456862166

Epoch: 5| Step: 2
Training loss: 0.4315022035168979
Validation loss: 2.393898246032522

Epoch: 5| Step: 3
Training loss: 0.39406822908307193
Validation loss: 2.418646078889246

Epoch: 5| Step: 4
Training loss: 0.43029551403952854
Validation loss: 2.4163928217996977

Epoch: 5| Step: 5
Training loss: 0.5546855120556091
Validation loss: 2.3738529455594706

Epoch: 5| Step: 6
Training loss: 0.6016986494686648
Validation loss: 2.3680514720509085

Epoch: 5| Step: 7
Training loss: 0.4330168658158813
Validation loss: 2.344447474184985

Epoch: 5| Step: 8
Training loss: 0.3754496659958507
Validation loss: 2.2833249506546878

Epoch: 5| Step: 9
Training loss: 0.42296387412083103
Validation loss: 2.2921597827466664

Epoch: 5| Step: 10
Training loss: 0.5585391411397548
Validation loss: 2.3288669300055207

Epoch: 408| Step: 0
Training loss: 0.3515175366788651
Validation loss: 2.3764259427243757

Epoch: 5| Step: 1
Training loss: 0.44999743434386535
Validation loss: 2.367922680884643

Epoch: 5| Step: 2
Training loss: 0.5119319500757963
Validation loss: 2.3969967243582673

Epoch: 5| Step: 3
Training loss: 0.4621072248342735
Validation loss: 2.410258677241639

Epoch: 5| Step: 4
Training loss: 0.3356743047681606
Validation loss: 2.3743120739684116

Epoch: 5| Step: 5
Training loss: 0.6963460291689219
Validation loss: 2.3546612102414572

Epoch: 5| Step: 6
Training loss: 0.4100042333907707
Validation loss: 2.372997474873622

Epoch: 5| Step: 7
Training loss: 0.48068460407408975
Validation loss: 2.3384205670595026

Epoch: 5| Step: 8
Training loss: 0.49353433437974165
Validation loss: 2.330180460295652

Epoch: 5| Step: 9
Training loss: 0.2618469237569901
Validation loss: 2.3708710976199736

Epoch: 5| Step: 10
Training loss: 0.2551084228795052
Validation loss: 2.3523089801730466

Epoch: 409| Step: 0
Training loss: 0.5114275562429665
Validation loss: 2.3259916670976435

Epoch: 5| Step: 1
Training loss: 0.5370249733934049
Validation loss: 2.376439925828817

Epoch: 5| Step: 2
Training loss: 0.2925502585572108
Validation loss: 2.418510393177045

Epoch: 5| Step: 3
Training loss: 0.4930033809147444
Validation loss: 2.4081518176418255

Epoch: 5| Step: 4
Training loss: 0.4123848450923085
Validation loss: 2.400756495127478

Epoch: 5| Step: 5
Training loss: 0.5825045408636748
Validation loss: 2.380234155124182

Epoch: 5| Step: 6
Training loss: 0.31007917441000465
Validation loss: 2.321615044173213

Epoch: 5| Step: 7
Training loss: 0.46057945828607666
Validation loss: 2.278256775346697

Epoch: 5| Step: 8
Training loss: 0.3575575315760058
Validation loss: 2.281101788381014

Epoch: 5| Step: 9
Training loss: 0.42953762561760844
Validation loss: 2.293237409250127

Epoch: 5| Step: 10
Training loss: 0.47856023152364113
Validation loss: 2.3128052509743378

Epoch: 410| Step: 0
Training loss: 0.4116893272816859
Validation loss: 2.317584482561488

Epoch: 5| Step: 1
Training loss: 0.5173752873104944
Validation loss: 2.319550712722992

Epoch: 5| Step: 2
Training loss: 0.3351285531753114
Validation loss: 2.3781010169340075

Epoch: 5| Step: 3
Training loss: 0.5680585241926742
Validation loss: 2.357118681221804

Epoch: 5| Step: 4
Training loss: 0.3495889370021679
Validation loss: 2.3363696436756163

Epoch: 5| Step: 5
Training loss: 0.46975308222467527
Validation loss: 2.329867779144871

Epoch: 5| Step: 6
Training loss: 0.48414828008952737
Validation loss: 2.317263039571383

Epoch: 5| Step: 7
Training loss: 0.5717667888966957
Validation loss: 2.3474196824878697

Epoch: 5| Step: 8
Training loss: 0.3607446857359692
Validation loss: 2.3316509258040314

Epoch: 5| Step: 9
Training loss: 0.325440426114596
Validation loss: 2.348665184255158

Epoch: 5| Step: 10
Training loss: 0.2356956704680164
Validation loss: 2.3491393050663056

Epoch: 411| Step: 0
Training loss: 0.6099448840459206
Validation loss: 2.370138191995967

Epoch: 5| Step: 1
Training loss: 0.3649742709850433
Validation loss: 2.346294516540797

Epoch: 5| Step: 2
Training loss: 0.27260555681440973
Validation loss: 2.3545505208197657

Epoch: 5| Step: 3
Training loss: 0.5056272585409338
Validation loss: 2.3586985180501663

Epoch: 5| Step: 4
Training loss: 0.4705116230646857
Validation loss: 2.3389102546562617

Epoch: 5| Step: 5
Training loss: 0.3024779064015501
Validation loss: 2.3565175704199537

Epoch: 5| Step: 6
Training loss: 0.41177951574239
Validation loss: 2.3682670101501175

Epoch: 5| Step: 7
Training loss: 0.2848993738199692
Validation loss: 2.371825939892823

Epoch: 5| Step: 8
Training loss: 0.4287839579688884
Validation loss: 2.370031262798148

Epoch: 5| Step: 9
Training loss: 0.532309037564008
Validation loss: 2.3655674801616713

Epoch: 5| Step: 10
Training loss: 0.4906529922761078
Validation loss: 2.392543033211083

Epoch: 412| Step: 0
Training loss: 0.3357599365797749
Validation loss: 2.3874315496097673

Epoch: 5| Step: 1
Training loss: 0.4276293969774371
Validation loss: 2.4089591058268676

Epoch: 5| Step: 2
Training loss: 0.19025751791673443
Validation loss: 2.4207299104615196

Epoch: 5| Step: 3
Training loss: 0.29366831861302684
Validation loss: 2.37114918278033

Epoch: 5| Step: 4
Training loss: 0.5918119321613526
Validation loss: 2.3347150920112663

Epoch: 5| Step: 5
Training loss: 0.4539909966517147
Validation loss: 2.3699841330683222

Epoch: 5| Step: 6
Training loss: 0.528906336774495
Validation loss: 2.3232188345324354

Epoch: 5| Step: 7
Training loss: 0.5008817884243638
Validation loss: 2.3741333194577785

Epoch: 5| Step: 8
Training loss: 0.38003817325769923
Validation loss: 2.3160344451289117

Epoch: 5| Step: 9
Training loss: 0.2412482321629953
Validation loss: 2.342346269276474

Epoch: 5| Step: 10
Training loss: 0.505808146471326
Validation loss: 2.352637282489262

Epoch: 413| Step: 0
Training loss: 0.4722033608712022
Validation loss: 2.3483193618044504

Epoch: 5| Step: 1
Training loss: 0.43813286715748456
Validation loss: 2.3772689352440577

Epoch: 5| Step: 2
Training loss: 0.3427518419380417
Validation loss: 2.3432325698496728

Epoch: 5| Step: 3
Training loss: 0.41299334631425466
Validation loss: 2.3721061081087464

Epoch: 5| Step: 4
Training loss: 0.2761182978564864
Validation loss: 2.382973266751253

Epoch: 5| Step: 5
Training loss: 0.6021108976300089
Validation loss: 2.3658098904105023

Epoch: 5| Step: 6
Training loss: 0.530293388764146
Validation loss: 2.350609704584368

Epoch: 5| Step: 7
Training loss: 0.48367189321393134
Validation loss: 2.3351041326754425

Epoch: 5| Step: 8
Training loss: 0.29192841512811274
Validation loss: 2.318554412134875

Epoch: 5| Step: 9
Training loss: 0.36124268629992984
Validation loss: 2.343818982931045

Epoch: 5| Step: 10
Training loss: 0.30350380608169025
Validation loss: 2.354248040749699

Epoch: 414| Step: 0
Training loss: 0.10295909501310141
Validation loss: 2.3737653395422122

Epoch: 5| Step: 1
Training loss: 0.3772935466659837
Validation loss: 2.3718297099719337

Epoch: 5| Step: 2
Training loss: 0.48866260132501554
Validation loss: 2.4149895245514186

Epoch: 5| Step: 3
Training loss: 0.5789041681290849
Validation loss: 2.3934692368094943

Epoch: 5| Step: 4
Training loss: 0.4389991449823504
Validation loss: 2.4280383749210235

Epoch: 5| Step: 5
Training loss: 0.36569735308360235
Validation loss: 2.3131053035912363

Epoch: 5| Step: 6
Training loss: 0.5171284575629144
Validation loss: 2.2759234097626817

Epoch: 5| Step: 7
Training loss: 0.5131171825059695
Validation loss: 2.2580749913234888

Epoch: 5| Step: 8
Training loss: 0.44888548721007104
Validation loss: 2.260897068241269

Epoch: 5| Step: 9
Training loss: 0.3959257766625929
Validation loss: 2.28708693878282

Epoch: 5| Step: 10
Training loss: 0.41045361592970886
Validation loss: 2.337127434050244

Epoch: 415| Step: 0
Training loss: 0.4769712633687668
Validation loss: 2.36265384865234

Epoch: 5| Step: 1
Training loss: 0.43699797709933036
Validation loss: 2.353987913961844

Epoch: 5| Step: 2
Training loss: 0.5119185312506149
Validation loss: 2.4056586977478163

Epoch: 5| Step: 3
Training loss: 0.3308601820754619
Validation loss: 2.3657456324541117

Epoch: 5| Step: 4
Training loss: 0.4009337858115748
Validation loss: 2.3745237465559446

Epoch: 5| Step: 5
Training loss: 0.38407983999939066
Validation loss: 2.319817873802517

Epoch: 5| Step: 6
Training loss: 0.5654584650019796
Validation loss: 2.328243029362948

Epoch: 5| Step: 7
Training loss: 0.465406413903115
Validation loss: 2.3322835943636555

Epoch: 5| Step: 8
Training loss: 0.25954447919830553
Validation loss: 2.3144832145466063

Epoch: 5| Step: 9
Training loss: 0.31882762992089475
Validation loss: 2.328893419753219

Epoch: 5| Step: 10
Training loss: 0.49501954569904055
Validation loss: 2.3482918078914343

Epoch: 416| Step: 0
Training loss: 0.2968317803494501
Validation loss: 2.3752817905353254

Epoch: 5| Step: 1
Training loss: 0.3709052159080196
Validation loss: 2.382601731646779

Epoch: 5| Step: 2
Training loss: 0.5156802523515955
Validation loss: 2.381499975177956

Epoch: 5| Step: 3
Training loss: 0.41999867646258576
Validation loss: 2.390474512440173

Epoch: 5| Step: 4
Training loss: 0.43107789240309585
Validation loss: 2.3561781448963135

Epoch: 5| Step: 5
Training loss: 0.41746067647139623
Validation loss: 2.3326896696739405

Epoch: 5| Step: 6
Training loss: 0.433901651706308
Validation loss: 2.3586073666176026

Epoch: 5| Step: 7
Training loss: 0.44275038650340737
Validation loss: 2.3514051340093967

Epoch: 5| Step: 8
Training loss: 0.4427623005304786
Validation loss: 2.3556625930497224

Epoch: 5| Step: 9
Training loss: 0.36642673492104205
Validation loss: 2.3616473446980164

Epoch: 5| Step: 10
Training loss: 0.36534698300737595
Validation loss: 2.3477126358350957

Epoch: 417| Step: 0
Training loss: 0.3652547330843395
Validation loss: 2.3414585585818006

Epoch: 5| Step: 1
Training loss: 0.3656703774096724
Validation loss: 2.30370065714553

Epoch: 5| Step: 2
Training loss: 0.26411162545823386
Validation loss: 2.3336810627113866

Epoch: 5| Step: 3
Training loss: 0.18952330046647653
Validation loss: 2.3500000659346543

Epoch: 5| Step: 4
Training loss: 0.4165587841878401
Validation loss: 2.3727098583591864

Epoch: 5| Step: 5
Training loss: 0.7219095031947685
Validation loss: 2.347699923587948

Epoch: 5| Step: 6
Training loss: 0.23756794396826444
Validation loss: 2.3321429373411173

Epoch: 5| Step: 7
Training loss: 0.5040982789823534
Validation loss: 2.2855557959325257

Epoch: 5| Step: 8
Training loss: 0.5932446135892496
Validation loss: 2.345859792680306

Epoch: 5| Step: 9
Training loss: 0.414140100225128
Validation loss: 2.3627159815550187

Epoch: 5| Step: 10
Training loss: 0.1838701379465123
Validation loss: 2.3491866718342527

Epoch: 418| Step: 0
Training loss: 0.35000097198010766
Validation loss: 2.3756384269418933

Epoch: 5| Step: 1
Training loss: 0.19008021443289083
Validation loss: 2.375614958821642

Epoch: 5| Step: 2
Training loss: 0.31278383954481936
Validation loss: 2.391468323740489

Epoch: 5| Step: 3
Training loss: 0.34679827743765756
Validation loss: 2.3710426570630485

Epoch: 5| Step: 4
Training loss: 0.4589420867268883
Validation loss: 2.345802290210207

Epoch: 5| Step: 5
Training loss: 0.1446813178029034
Validation loss: 2.3555532218642674

Epoch: 5| Step: 6
Training loss: 0.49794481017036535
Validation loss: 2.3471733244798334

Epoch: 5| Step: 7
Training loss: 0.4901647936313819
Validation loss: 2.3292107724323556

Epoch: 5| Step: 8
Training loss: 0.4457660339785753
Validation loss: 2.3374681848003007

Epoch: 5| Step: 9
Training loss: 0.5040437377729886
Validation loss: 2.3514666156368933

Epoch: 5| Step: 10
Training loss: 0.5379733817737363
Validation loss: 2.370504360045747

Epoch: 419| Step: 0
Training loss: 0.35265970675456415
Validation loss: 2.3792876016007125

Epoch: 5| Step: 1
Training loss: 0.6065793096698281
Validation loss: 2.358105773437762

Epoch: 5| Step: 2
Training loss: 0.487789944476126
Validation loss: 2.3600804225722727

Epoch: 5| Step: 3
Training loss: 0.24162685197168815
Validation loss: 2.3500587714793855

Epoch: 5| Step: 4
Training loss: 0.5406732129775863
Validation loss: 2.34668024028188

Epoch: 5| Step: 5
Training loss: 0.32304085630186236
Validation loss: 2.3529771664977726

Epoch: 5| Step: 6
Training loss: 0.4578494548529412
Validation loss: 2.3594651982229258

Epoch: 5| Step: 7
Training loss: 0.2979682068602278
Validation loss: 2.3597553329370577

Epoch: 5| Step: 8
Training loss: 0.42748307113702383
Validation loss: 2.363820472029406

Epoch: 5| Step: 9
Training loss: 0.25170729717055473
Validation loss: 2.335879082696439

Epoch: 5| Step: 10
Training loss: 0.3234457314406715
Validation loss: 2.3201411395869713

Epoch: 420| Step: 0
Training loss: 0.5182262465300468
Validation loss: 2.344917749157604

Epoch: 5| Step: 1
Training loss: 0.23795205968835892
Validation loss: 2.316701282609406

Epoch: 5| Step: 2
Training loss: 0.3479810547590843
Validation loss: 2.323484780524913

Epoch: 5| Step: 3
Training loss: 0.3207518425574122
Validation loss: 2.3594246147191047

Epoch: 5| Step: 4
Training loss: 0.5182222784405658
Validation loss: 2.3776150130713116

Epoch: 5| Step: 5
Training loss: 0.4657221276793597
Validation loss: 2.382282458358403

Epoch: 5| Step: 6
Training loss: 0.26322206346966337
Validation loss: 2.3800556375055337

Epoch: 5| Step: 7
Training loss: 0.37741477645360816
Validation loss: 2.309904140924489

Epoch: 5| Step: 8
Training loss: 0.4325386131006616
Validation loss: 2.3029287088337735

Epoch: 5| Step: 9
Training loss: 0.4329467104007393
Validation loss: 2.315346083080993

Epoch: 5| Step: 10
Training loss: 0.45745850830892454
Validation loss: 2.325013421265034

Epoch: 421| Step: 0
Training loss: 0.6721928088813379
Validation loss: 2.3513699347337744

Epoch: 5| Step: 1
Training loss: 0.3866602728201323
Validation loss: 2.3512854314257567

Epoch: 5| Step: 2
Training loss: 0.37154228809973944
Validation loss: 2.4093720715398845

Epoch: 5| Step: 3
Training loss: 0.35437703429753353
Validation loss: 2.3695453862452207

Epoch: 5| Step: 4
Training loss: 0.3292332281143658
Validation loss: 2.369787343068705

Epoch: 5| Step: 5
Training loss: 0.2947316092835771
Validation loss: 2.3526469283877405

Epoch: 5| Step: 6
Training loss: 0.4686115855263132
Validation loss: 2.351875123047771

Epoch: 5| Step: 7
Training loss: 0.39069636646657896
Validation loss: 2.3380434718913627

Epoch: 5| Step: 8
Training loss: 0.3516019163287802
Validation loss: 2.2963273391155905

Epoch: 5| Step: 9
Training loss: 0.29299011152591026
Validation loss: 2.322569425823831

Epoch: 5| Step: 10
Training loss: 0.35325378921998024
Validation loss: 2.3475957229355005

Epoch: 422| Step: 0
Training loss: 0.21713349267758836
Validation loss: 2.3605199734559834

Epoch: 5| Step: 1
Training loss: 0.4017698398360547
Validation loss: 2.4229732652373706

Epoch: 5| Step: 2
Training loss: 0.38261461008789843
Validation loss: 2.4090913814867223

Epoch: 5| Step: 3
Training loss: 0.3226349765885966
Validation loss: 2.4100270538077884

Epoch: 5| Step: 4
Training loss: 0.2338577045450594
Validation loss: 2.4037051957406863

Epoch: 5| Step: 5
Training loss: 0.6641273018129172
Validation loss: 2.349835026596242

Epoch: 5| Step: 6
Training loss: 0.39965600331795703
Validation loss: 2.3576310842124903

Epoch: 5| Step: 7
Training loss: 0.18963462944324863
Validation loss: 2.3387213573369245

Epoch: 5| Step: 8
Training loss: 0.42299566830791197
Validation loss: 2.3051353023719643

Epoch: 5| Step: 9
Training loss: 0.4421741928416736
Validation loss: 2.2701706210446115

Epoch: 5| Step: 10
Training loss: 0.5276631835988016
Validation loss: 2.3310686117366632

Epoch: 423| Step: 0
Training loss: 0.2858314750131824
Validation loss: 2.2918565773978052

Epoch: 5| Step: 1
Training loss: 0.4345278258396225
Validation loss: 2.33931204814485

Epoch: 5| Step: 2
Training loss: 0.42555144871830536
Validation loss: 2.341332202623696

Epoch: 5| Step: 3
Training loss: 0.3063172256877319
Validation loss: 2.391729024999057

Epoch: 5| Step: 4
Training loss: 0.3109239172724396
Validation loss: 2.406039225148934

Epoch: 5| Step: 5
Training loss: 0.6225101945800644
Validation loss: 2.364239489385195

Epoch: 5| Step: 6
Training loss: 0.3935413594982644
Validation loss: 2.327904964404621

Epoch: 5| Step: 7
Training loss: 0.37252447489524876
Validation loss: 2.321152855687195

Epoch: 5| Step: 8
Training loss: 0.4300065156808938
Validation loss: 2.2765269629520986

Epoch: 5| Step: 9
Training loss: 0.3508611146369435
Validation loss: 2.275689995014301

Epoch: 5| Step: 10
Training loss: 0.5228239135499606
Validation loss: 2.3017683253995616

Epoch: 424| Step: 0
Training loss: 0.4863574620479281
Validation loss: 2.3362442897803066

Epoch: 5| Step: 1
Training loss: 0.3855691835699454
Validation loss: 2.3879675043606317

Epoch: 5| Step: 2
Training loss: 0.3435674204155656
Validation loss: 2.4456565237776933

Epoch: 5| Step: 3
Training loss: 0.30751714139162967
Validation loss: 2.447583224579416

Epoch: 5| Step: 4
Training loss: 0.23501030331202774
Validation loss: 2.3890562712699914

Epoch: 5| Step: 5
Training loss: 0.4952534896163431
Validation loss: 2.3410444562897337

Epoch: 5| Step: 6
Training loss: 0.43132409620208584
Validation loss: 2.299883538169322

Epoch: 5| Step: 7
Training loss: 0.42296820743048275
Validation loss: 2.280205500287793

Epoch: 5| Step: 8
Training loss: 0.45818310862185047
Validation loss: 2.3066708409082355

Epoch: 5| Step: 9
Training loss: 0.43332060381030935
Validation loss: 2.278225158580964

Epoch: 5| Step: 10
Training loss: 0.49740854383542343
Validation loss: 2.2715671610877397

Epoch: 425| Step: 0
Training loss: 0.3364937523995912
Validation loss: 2.319409847236877

Epoch: 5| Step: 1
Training loss: 0.32730384665386997
Validation loss: 2.3220742674273906

Epoch: 5| Step: 2
Training loss: 0.44613788473260124
Validation loss: 2.364828112159817

Epoch: 5| Step: 3
Training loss: 0.33741274429830814
Validation loss: 2.401981300072672

Epoch: 5| Step: 4
Training loss: 0.405634597347379
Validation loss: 2.358325050139729

Epoch: 5| Step: 5
Training loss: 0.23886720340756779
Validation loss: 2.3502251220721773

Epoch: 5| Step: 6
Training loss: 0.33399804962896484
Validation loss: 2.299668830206626

Epoch: 5| Step: 7
Training loss: 0.5471212377682504
Validation loss: 2.304362759411413

Epoch: 5| Step: 8
Training loss: 0.3841681707039696
Validation loss: 2.2934446062408167

Epoch: 5| Step: 9
Training loss: 0.6250882086496549
Validation loss: 2.3207660053838426

Epoch: 5| Step: 10
Training loss: 0.2534712366116898
Validation loss: 2.3527753538949674

Epoch: 426| Step: 0
Training loss: 0.44925011235099327
Validation loss: 2.382108255398426

Epoch: 5| Step: 1
Training loss: 0.38131870057273465
Validation loss: 2.4026714724025706

Epoch: 5| Step: 2
Training loss: 0.33798939578785464
Validation loss: 2.3720380310356672

Epoch: 5| Step: 3
Training loss: 0.4471369729064034
Validation loss: 2.3528381023286373

Epoch: 5| Step: 4
Training loss: 0.41852452413765356
Validation loss: 2.3358049268996672

Epoch: 5| Step: 5
Training loss: 0.39804426123123104
Validation loss: 2.2999430553302975

Epoch: 5| Step: 6
Training loss: 0.4591188436719099
Validation loss: 2.2830722502236376

Epoch: 5| Step: 7
Training loss: 0.23399204916620556
Validation loss: 2.282421081181943

Epoch: 5| Step: 8
Training loss: 0.4132507933154975
Validation loss: 2.3174744504026483

Epoch: 5| Step: 9
Training loss: 0.3846244359326868
Validation loss: 2.336364191308429

Epoch: 5| Step: 10
Training loss: 0.5166013028986086
Validation loss: 2.325887383949941

Epoch: 427| Step: 0
Training loss: 0.29526280282676337
Validation loss: 2.3634116380642665

Epoch: 5| Step: 1
Training loss: 0.5062230397333557
Validation loss: 2.3684460363891566

Epoch: 5| Step: 2
Training loss: 0.38866351708095154
Validation loss: 2.3441145571685618

Epoch: 5| Step: 3
Training loss: 0.41559561718785826
Validation loss: 2.3410860603563775

Epoch: 5| Step: 4
Training loss: 0.45531621115905957
Validation loss: 2.323122929644117

Epoch: 5| Step: 5
Training loss: 0.3793702578051838
Validation loss: 2.2942346103474596

Epoch: 5| Step: 6
Training loss: 0.3412941314296389
Validation loss: 2.301897310280131

Epoch: 5| Step: 7
Training loss: 0.47502592041165764
Validation loss: 2.3049383967870867

Epoch: 5| Step: 8
Training loss: 0.19566423216218573
Validation loss: 2.3552280085936736

Epoch: 5| Step: 9
Training loss: 0.39065795759403515
Validation loss: 2.3533696230050873

Epoch: 5| Step: 10
Training loss: 0.37986490555556746
Validation loss: 2.386038402611373

Epoch: 428| Step: 0
Training loss: 0.34814330070032024
Validation loss: 2.4049175372971714

Epoch: 5| Step: 1
Training loss: 0.2654083995689373
Validation loss: 2.433473513913492

Epoch: 5| Step: 2
Training loss: 0.518083836354848
Validation loss: 2.4068536607166457

Epoch: 5| Step: 3
Training loss: 0.2049949931632341
Validation loss: 2.4030564990366363

Epoch: 5| Step: 4
Training loss: 0.3381027481950702
Validation loss: 2.376236608223831

Epoch: 5| Step: 5
Training loss: 0.2896915756070571
Validation loss: 2.353900179606987

Epoch: 5| Step: 6
Training loss: 0.3337984292472214
Validation loss: 2.356597772930795

Epoch: 5| Step: 7
Training loss: 0.5415554727229366
Validation loss: 2.3324179289352043

Epoch: 5| Step: 8
Training loss: 0.37559704141771905
Validation loss: 2.3309220517043725

Epoch: 5| Step: 9
Training loss: 0.5149974761364027
Validation loss: 2.346059950215733

Epoch: 5| Step: 10
Training loss: 0.35625216332832826
Validation loss: 2.348366257134355

Epoch: 429| Step: 0
Training loss: 0.3791016929976068
Validation loss: 2.3383955413910007

Epoch: 5| Step: 1
Training loss: 0.5163795268059586
Validation loss: 2.3991135062790256

Epoch: 5| Step: 2
Training loss: 0.2555019269626088
Validation loss: 2.339479368905936

Epoch: 5| Step: 3
Training loss: 0.34000878327959644
Validation loss: 2.3370271043493243

Epoch: 5| Step: 4
Training loss: 0.41791584000865434
Validation loss: 2.348682531891774

Epoch: 5| Step: 5
Training loss: 0.44761445880633766
Validation loss: 2.3470711413600074

Epoch: 5| Step: 6
Training loss: 0.437349037964346
Validation loss: 2.3332814556571964

Epoch: 5| Step: 7
Training loss: 0.39041858941659496
Validation loss: 2.311552950765723

Epoch: 5| Step: 8
Training loss: 0.4318117863920706
Validation loss: 2.3086553273583523

Epoch: 5| Step: 9
Training loss: 0.2405198269907397
Validation loss: 2.3066557091082753

Epoch: 5| Step: 10
Training loss: 0.4430318790777626
Validation loss: 2.33995279930462

Epoch: 430| Step: 0
Training loss: 0.314116090026558
Validation loss: 2.3485059223132296

Epoch: 5| Step: 1
Training loss: 0.5322479243759888
Validation loss: 2.351205307208098

Epoch: 5| Step: 2
Training loss: 0.3866997723787623
Validation loss: 2.3032778720486498

Epoch: 5| Step: 3
Training loss: 0.6449878809034311
Validation loss: 2.3138644187848074

Epoch: 5| Step: 4
Training loss: 0.38762783356916086
Validation loss: 2.3145089850212384

Epoch: 5| Step: 5
Training loss: 0.36434420054691136
Validation loss: 2.322881868766631

Epoch: 5| Step: 6
Training loss: 0.3738193403306038
Validation loss: 2.3608015930862116

Epoch: 5| Step: 7
Training loss: 0.3127639252050039
Validation loss: 2.3145592435994624

Epoch: 5| Step: 8
Training loss: 0.27855002309884347
Validation loss: 2.361858390655034

Epoch: 5| Step: 9
Training loss: 0.34853069829508065
Validation loss: 2.341970836824333

Epoch: 5| Step: 10
Training loss: 0.31362299603612215
Validation loss: 2.3321628004063055

Epoch: 431| Step: 0
Training loss: 0.44974038065663136
Validation loss: 2.285295328907801

Epoch: 5| Step: 1
Training loss: 0.3965110394010168
Validation loss: 2.2836171173334536

Epoch: 5| Step: 2
Training loss: 0.4816526697637444
Validation loss: 2.2861112234469543

Epoch: 5| Step: 3
Training loss: 0.3278687930070421
Validation loss: 2.307163504315985

Epoch: 5| Step: 4
Training loss: 0.31064770818942794
Validation loss: 2.36470396113556

Epoch: 5| Step: 5
Training loss: 0.6050428553842924
Validation loss: 2.3810247699145983

Epoch: 5| Step: 6
Training loss: 0.3758241418798634
Validation loss: 2.3996432478469214

Epoch: 5| Step: 7
Training loss: 0.3960119731085241
Validation loss: 2.4121689985243973

Epoch: 5| Step: 8
Training loss: 0.42060324812445277
Validation loss: 2.4018986286005903

Epoch: 5| Step: 9
Training loss: 0.1664882328118136
Validation loss: 2.334238876105839

Epoch: 5| Step: 10
Training loss: 0.24862774096858078
Validation loss: 2.3102964685567944

Epoch: 432| Step: 0
Training loss: 0.4229759227255835
Validation loss: 2.3012033262674945

Epoch: 5| Step: 1
Training loss: 0.3128565304166799
Validation loss: 2.3193578373771535

Epoch: 5| Step: 2
Training loss: 0.25437856906008527
Validation loss: 2.351667385551072

Epoch: 5| Step: 3
Training loss: 0.44044254394172117
Validation loss: 2.3607651232818965

Epoch: 5| Step: 4
Training loss: 0.41905881326804595
Validation loss: 2.3675246562943597

Epoch: 5| Step: 5
Training loss: 0.6337509261355885
Validation loss: 2.3801864476177306

Epoch: 5| Step: 6
Training loss: 0.3801434561712475
Validation loss: 2.384560076881517

Epoch: 5| Step: 7
Training loss: 0.3421766841171949
Validation loss: 2.333110400579616

Epoch: 5| Step: 8
Training loss: 0.30315500386195016
Validation loss: 2.299636124356631

Epoch: 5| Step: 9
Training loss: 0.3269507194986578
Validation loss: 2.284893754583195

Epoch: 5| Step: 10
Training loss: 0.20264500061024332
Validation loss: 2.266278846318718

Epoch: 433| Step: 0
Training loss: 0.24058236140686987
Validation loss: 2.3162725186203383

Epoch: 5| Step: 1
Training loss: 0.36225417779865643
Validation loss: 2.3376428427226488

Epoch: 5| Step: 2
Training loss: 0.3814442374296806
Validation loss: 2.352150066311228

Epoch: 5| Step: 3
Training loss: 0.36105464173848756
Validation loss: 2.3400791541536274

Epoch: 5| Step: 4
Training loss: 0.31797642288510486
Validation loss: 2.3828744945802933

Epoch: 5| Step: 5
Training loss: 0.2861822821130415
Validation loss: 2.347252550936637

Epoch: 5| Step: 6
Training loss: 0.3957504093580123
Validation loss: 2.3784373267927124

Epoch: 5| Step: 7
Training loss: 0.6544185012961036
Validation loss: 2.3399074784821026

Epoch: 5| Step: 8
Training loss: 0.2789600448660354
Validation loss: 2.3144633808551722

Epoch: 5| Step: 9
Training loss: 0.43103239955069833
Validation loss: 2.306325740055727

Epoch: 5| Step: 10
Training loss: 0.18932780810880007
Validation loss: 2.3326484730591264

Epoch: 434| Step: 0
Training loss: 0.426268936978305
Validation loss: 2.2612919419685866

Epoch: 5| Step: 1
Training loss: 0.301897047690929
Validation loss: 2.307137341774453

Epoch: 5| Step: 2
Training loss: 0.23128994422748395
Validation loss: 2.301706078177018

Epoch: 5| Step: 3
Training loss: 0.2779537799014114
Validation loss: 2.3161048385251597

Epoch: 5| Step: 4
Training loss: 0.4294509236426974
Validation loss: 2.3835132334422613

Epoch: 5| Step: 5
Training loss: 0.4913836226840932
Validation loss: 2.3837096103208903

Epoch: 5| Step: 6
Training loss: 0.27298460647392403
Validation loss: 2.4144181776916716

Epoch: 5| Step: 7
Training loss: 0.4079265113567379
Validation loss: 2.3863278601197164

Epoch: 5| Step: 8
Training loss: 0.44734206233637275
Validation loss: 2.3582475860648016

Epoch: 5| Step: 9
Training loss: 0.2297058166284967
Validation loss: 2.339677903844681

Epoch: 5| Step: 10
Training loss: 0.5349133629481688
Validation loss: 2.3227436870008593

Epoch: 435| Step: 0
Training loss: 0.48945956153625686
Validation loss: 2.2999199724029236

Epoch: 5| Step: 1
Training loss: 0.1969905862132325
Validation loss: 2.338507862085627

Epoch: 5| Step: 2
Training loss: 0.4662405873184589
Validation loss: 2.3479519886538354

Epoch: 5| Step: 3
Training loss: 0.2466154321389393
Validation loss: 2.3465812951671516

Epoch: 5| Step: 4
Training loss: 0.20046548058749433
Validation loss: 2.3593827527081883

Epoch: 5| Step: 5
Training loss: 0.47776263411527936
Validation loss: 2.427735152201668

Epoch: 5| Step: 6
Training loss: 0.4250397305991243
Validation loss: 2.426581395853652

Epoch: 5| Step: 7
Training loss: 0.2791989695069894
Validation loss: 2.4354451586678123

Epoch: 5| Step: 8
Training loss: 0.3962655990670972
Validation loss: 2.4131438827932783

Epoch: 5| Step: 9
Training loss: 0.25505016576757467
Validation loss: 2.3617037688229185

Epoch: 5| Step: 10
Training loss: 0.4716074159591172
Validation loss: 2.343296572122764

Epoch: 436| Step: 0
Training loss: 0.41370421329134277
Validation loss: 2.3502436689804385

Epoch: 5| Step: 1
Training loss: 0.44061858869176385
Validation loss: 2.3323012419150873

Epoch: 5| Step: 2
Training loss: 0.2886384611703779
Validation loss: 2.324494113812346

Epoch: 5| Step: 3
Training loss: 0.2969953142608895
Validation loss: 2.354250276891963

Epoch: 5| Step: 4
Training loss: 0.21261330136516987
Validation loss: 2.3543919820187305

Epoch: 5| Step: 5
Training loss: 0.5407077174769523
Validation loss: 2.348163167194081

Epoch: 5| Step: 6
Training loss: 0.4304126862227716
Validation loss: 2.36667487935824

Epoch: 5| Step: 7
Training loss: 0.2982836231758744
Validation loss: 2.385478178561068

Epoch: 5| Step: 8
Training loss: 0.2685217542395505
Validation loss: 2.323711566249873

Epoch: 5| Step: 9
Training loss: 0.37279901708761887
Validation loss: 2.3551800204184747

Epoch: 5| Step: 10
Training loss: 0.43193128991854823
Validation loss: 2.3623904483047413

Epoch: 437| Step: 0
Training loss: 0.46325836382426727
Validation loss: 2.3935448829968635

Epoch: 5| Step: 1
Training loss: 0.3030496739658754
Validation loss: 2.3747362617550674

Epoch: 5| Step: 2
Training loss: 0.5538456398067982
Validation loss: 2.333714284503985

Epoch: 5| Step: 3
Training loss: 0.342211607950393
Validation loss: 2.2955414483103866

Epoch: 5| Step: 4
Training loss: 0.3563942232490096
Validation loss: 2.2846590160062465

Epoch: 5| Step: 5
Training loss: 0.4876530840965598
Validation loss: 2.3239018761355594

Epoch: 5| Step: 6
Training loss: 0.26874039211398176
Validation loss: 2.29283569607312

Epoch: 5| Step: 7
Training loss: 0.2232952819056288
Validation loss: 2.3141401461507294

Epoch: 5| Step: 8
Training loss: 0.42077781913823326
Validation loss: 2.3740670898307434

Epoch: 5| Step: 9
Training loss: 0.22895622163642815
Validation loss: 2.341535957298878

Epoch: 5| Step: 10
Training loss: 0.2794097592238299
Validation loss: 2.3360297148885603

Epoch: 438| Step: 0
Training loss: 0.22034338098900053
Validation loss: 2.3254076007305184

Epoch: 5| Step: 1
Training loss: 0.4278058205773477
Validation loss: 2.316636514043271

Epoch: 5| Step: 2
Training loss: 0.46613377994177063
Validation loss: 2.345586372064135

Epoch: 5| Step: 3
Training loss: 0.4288586685664626
Validation loss: 2.336198459170112

Epoch: 5| Step: 4
Training loss: 0.28596499472415887
Validation loss: 2.300617848659664

Epoch: 5| Step: 5
Training loss: 0.31138885365237434
Validation loss: 2.307154852764686

Epoch: 5| Step: 6
Training loss: 0.29008858511609975
Validation loss: 2.3087482854924706

Epoch: 5| Step: 7
Training loss: 0.47867934870998596
Validation loss: 2.281283647078665

Epoch: 5| Step: 8
Training loss: 0.37254191470026815
Validation loss: 2.347449651980653

Epoch: 5| Step: 9
Training loss: 0.24969771856039907
Validation loss: 2.322385434665733

Epoch: 5| Step: 10
Training loss: 0.16588824939455032
Validation loss: 2.3412950107245

Epoch: 439| Step: 0
Training loss: 0.3892494013174717
Validation loss: 2.340316852548351

Epoch: 5| Step: 1
Training loss: 0.4458074496084904
Validation loss: 2.335485329212821

Epoch: 5| Step: 2
Training loss: 0.2992561864715367
Validation loss: 2.3840521369228727

Epoch: 5| Step: 3
Training loss: 0.2703716059104446
Validation loss: 2.348456638016868

Epoch: 5| Step: 4
Training loss: 0.4206513566917887
Validation loss: 2.2799820741419388

Epoch: 5| Step: 5
Training loss: 0.40135645794043245
Validation loss: 2.2929438152404993

Epoch: 5| Step: 6
Training loss: 0.3042703119909271
Validation loss: 2.300261523357644

Epoch: 5| Step: 7
Training loss: 0.38889973157950425
Validation loss: 2.3300023217655963

Epoch: 5| Step: 8
Training loss: 0.38339074895206676
Validation loss: 2.298965297087948

Epoch: 5| Step: 9
Training loss: 0.37252169485088366
Validation loss: 2.333094423854958

Epoch: 5| Step: 10
Training loss: 0.29724855511813875
Validation loss: 2.282011785118517

Epoch: 440| Step: 0
Training loss: 0.5629342045747363
Validation loss: 2.318779047085402

Epoch: 5| Step: 1
Training loss: 0.4666725216509598
Validation loss: 2.3378631472027616

Epoch: 5| Step: 2
Training loss: 0.32616078477839117
Validation loss: 2.361925306150536

Epoch: 5| Step: 3
Training loss: 0.29485056185472325
Validation loss: 2.397319983755236

Epoch: 5| Step: 4
Training loss: 0.41773290308216265
Validation loss: 2.3860890229549345

Epoch: 5| Step: 5
Training loss: 0.3346292393728985
Validation loss: 2.410040815364597

Epoch: 5| Step: 6
Training loss: 0.36988021793275316
Validation loss: 2.351198935184298

Epoch: 5| Step: 7
Training loss: 0.20903675813242747
Validation loss: 2.3105650719139574

Epoch: 5| Step: 8
Training loss: 0.4670060140173488
Validation loss: 2.246628800519104

Epoch: 5| Step: 9
Training loss: 0.4043326799690637
Validation loss: 2.2822582305458248

Epoch: 5| Step: 10
Training loss: 0.27669341442541645
Validation loss: 2.2712687827213323

Epoch: 441| Step: 0
Training loss: 0.3943022639429942
Validation loss: 2.291549746382445

Epoch: 5| Step: 1
Training loss: 0.3664835411164753
Validation loss: 2.3666733455115985

Epoch: 5| Step: 2
Training loss: 0.38618347422200305
Validation loss: 2.3704922821048506

Epoch: 5| Step: 3
Training loss: 0.38413485026368444
Validation loss: 2.353197362314697

Epoch: 5| Step: 4
Training loss: 0.2152776498093447
Validation loss: 2.367884882971337

Epoch: 5| Step: 5
Training loss: 0.41429844018107104
Validation loss: 2.2926457712135084

Epoch: 5| Step: 6
Training loss: 0.5576832960928607
Validation loss: 2.266368802429087

Epoch: 5| Step: 7
Training loss: 0.31646099323429766
Validation loss: 2.270189015685412

Epoch: 5| Step: 8
Training loss: 0.42815284638443774
Validation loss: 2.321208662714355

Epoch: 5| Step: 9
Training loss: 0.4003986636959798
Validation loss: 2.366762920056102

Epoch: 5| Step: 10
Training loss: 0.33692465502908175
Validation loss: 2.398140587518975

Epoch: 442| Step: 0
Training loss: 0.3677110794368284
Validation loss: 2.3801578661692386

Epoch: 5| Step: 1
Training loss: 0.3485728834772903
Validation loss: 2.3722458755968616

Epoch: 5| Step: 2
Training loss: 0.3200014045803716
Validation loss: 2.3430225536843237

Epoch: 5| Step: 3
Training loss: 0.3953549690201587
Validation loss: 2.2790894716671226

Epoch: 5| Step: 4
Training loss: 0.438895469334855
Validation loss: 2.311463575796187

Epoch: 5| Step: 5
Training loss: 0.255460121872348
Validation loss: 2.2975883355606577

Epoch: 5| Step: 6
Training loss: 0.21937767304316194
Validation loss: 2.3184205702424245

Epoch: 5| Step: 7
Training loss: 0.3202828882067386
Validation loss: 2.3531654342125288

Epoch: 5| Step: 8
Training loss: 0.37126204037648625
Validation loss: 2.428623315791221

Epoch: 5| Step: 9
Training loss: 0.5237974381187919
Validation loss: 2.4083704028587403

Epoch: 5| Step: 10
Training loss: 0.4441292082729175
Validation loss: 2.4334420701866692

Epoch: 443| Step: 0
Training loss: 0.3971324566173199
Validation loss: 2.4207476534891965

Epoch: 5| Step: 1
Training loss: 0.2189036664054719
Validation loss: 2.3534641820375843

Epoch: 5| Step: 2
Training loss: 0.41290744685873854
Validation loss: 2.340839228527818

Epoch: 5| Step: 3
Training loss: 0.3131309814795518
Validation loss: 2.3073714084707033

Epoch: 5| Step: 4
Training loss: 0.3154677731223472
Validation loss: 2.288993599502292

Epoch: 5| Step: 5
Training loss: 0.4425893474075194
Validation loss: 2.2905174524805956

Epoch: 5| Step: 6
Training loss: 0.21640527428913156
Validation loss: 2.3331537195884895

Epoch: 5| Step: 7
Training loss: 0.4683641435063855
Validation loss: 2.360811541174373

Epoch: 5| Step: 8
Training loss: 0.2985814890597387
Validation loss: 2.341979622476495

Epoch: 5| Step: 9
Training loss: 0.4202787258093098
Validation loss: 2.329639241614135

Epoch: 5| Step: 10
Training loss: 0.27413104521351794
Validation loss: 2.3462437270953105

Epoch: 444| Step: 0
Training loss: 0.22206138317773202
Validation loss: 2.3995409294451964

Epoch: 5| Step: 1
Training loss: 0.38486924688308116
Validation loss: 2.352512324101932

Epoch: 5| Step: 2
Training loss: 0.2920543515174598
Validation loss: 2.3224112366719147

Epoch: 5| Step: 3
Training loss: 0.30611791827841356
Validation loss: 2.297243046524713

Epoch: 5| Step: 4
Training loss: 0.4403767691410769
Validation loss: 2.261024822749642

Epoch: 5| Step: 5
Training loss: 0.23820052577446357
Validation loss: 2.2992281863134094

Epoch: 5| Step: 6
Training loss: 0.5452296163971964
Validation loss: 2.2644070076600755

Epoch: 5| Step: 7
Training loss: 0.36130362762712104
Validation loss: 2.3186211223170248

Epoch: 5| Step: 8
Training loss: 0.3087460106039806
Validation loss: 2.3948260857518906

Epoch: 5| Step: 9
Training loss: 0.5157642465473797
Validation loss: 2.445515057290449

Epoch: 5| Step: 10
Training loss: 0.4085063264583365
Validation loss: 2.5154226908743054

Epoch: 445| Step: 0
Training loss: 0.4605336116987255
Validation loss: 2.474571913755414

Epoch: 5| Step: 1
Training loss: 0.2999533865398386
Validation loss: 2.4195269414402256

Epoch: 5| Step: 2
Training loss: 0.30736541132574574
Validation loss: 2.32599189965572

Epoch: 5| Step: 3
Training loss: 0.4549703511334972
Validation loss: 2.23524059278129

Epoch: 5| Step: 4
Training loss: 0.5424634929098769
Validation loss: 2.1939784684509607

Epoch: 5| Step: 5
Training loss: 0.427836453872736
Validation loss: 2.188561300720562

Epoch: 5| Step: 6
Training loss: 0.42567013681857313
Validation loss: 2.2343231305298215

Epoch: 5| Step: 7
Training loss: 0.4057018176137984
Validation loss: 2.2763271237725755

Epoch: 5| Step: 8
Training loss: 0.40600516203948306
Validation loss: 2.3747091196162775

Epoch: 5| Step: 9
Training loss: 0.21828158499405972
Validation loss: 2.440736479868944

Epoch: 5| Step: 10
Training loss: 0.5386316816951748
Validation loss: 2.492411096267077

Epoch: 446| Step: 0
Training loss: 0.4285431796510675
Validation loss: 2.469276746903413

Epoch: 5| Step: 1
Training loss: 0.343127814665265
Validation loss: 2.412952380639054

Epoch: 5| Step: 2
Training loss: 0.343734274851307
Validation loss: 2.309043154121854

Epoch: 5| Step: 3
Training loss: 0.4439241114738601
Validation loss: 2.2475917842289648

Epoch: 5| Step: 4
Training loss: 0.5440131372871013
Validation loss: 2.2168015008418887

Epoch: 5| Step: 5
Training loss: 0.5039363231112943
Validation loss: 2.254779255259349

Epoch: 5| Step: 6
Training loss: 0.39267458134040706
Validation loss: 2.3415548544072826

Epoch: 5| Step: 7
Training loss: 0.37897502628922475
Validation loss: 2.437870191045708

Epoch: 5| Step: 8
Training loss: 0.5256797250388829
Validation loss: 2.48505845268603

Epoch: 5| Step: 9
Training loss: 0.5094287680115194
Validation loss: 2.4482548578034447

Epoch: 5| Step: 10
Training loss: 0.3665873716328065
Validation loss: 2.391445472998824

Epoch: 447| Step: 0
Training loss: 0.3629801127592535
Validation loss: 2.3082170898386463

Epoch: 5| Step: 1
Training loss: 0.6567577713694259
Validation loss: 2.281205684126348

Epoch: 5| Step: 2
Training loss: 0.1662760431104962
Validation loss: 2.251004246178539

Epoch: 5| Step: 3
Training loss: 0.3549207928435521
Validation loss: 2.235748956281478

Epoch: 5| Step: 4
Training loss: 0.5470317615897808
Validation loss: 2.2467647682620444

Epoch: 5| Step: 5
Training loss: 0.3469399563223601
Validation loss: 2.33598994021533

Epoch: 5| Step: 6
Training loss: 0.34873526000248967
Validation loss: 2.358676008496489

Epoch: 5| Step: 7
Training loss: 0.2940969234591641
Validation loss: 2.42572256135528

Epoch: 5| Step: 8
Training loss: 0.5982147549259322
Validation loss: 2.4967098510178047

Epoch: 5| Step: 9
Training loss: 0.4547639343408543
Validation loss: 2.389625221761665

Epoch: 5| Step: 10
Training loss: 0.5320730005314988
Validation loss: 2.3051899580033637

Epoch: 448| Step: 0
Training loss: 0.42464596644203595
Validation loss: 2.2703571431809086

Epoch: 5| Step: 1
Training loss: 0.4888830215139345
Validation loss: 2.265932712160593

Epoch: 5| Step: 2
Training loss: 0.5354457545511913
Validation loss: 2.2500228071708968

Epoch: 5| Step: 3
Training loss: 0.2812907004047136
Validation loss: 2.3320713186460678

Epoch: 5| Step: 4
Training loss: 0.4570580173055088
Validation loss: 2.3794231956709555

Epoch: 5| Step: 5
Training loss: 0.5314437849365622
Validation loss: 2.403140528168523

Epoch: 5| Step: 6
Training loss: 0.5487759928532144
Validation loss: 2.4834195646962143

Epoch: 5| Step: 7
Training loss: 0.512169355637807
Validation loss: 2.4610897081596117

Epoch: 5| Step: 8
Training loss: 0.38533268692337475
Validation loss: 2.381583967779574

Epoch: 5| Step: 9
Training loss: 0.5873078153658239
Validation loss: 2.2541409548705835

Epoch: 5| Step: 10
Training loss: 0.40897885221379493
Validation loss: 2.285413375228286

Epoch: 449| Step: 0
Training loss: 0.45049003172376617
Validation loss: 2.240858444085192

Epoch: 5| Step: 1
Training loss: 0.49638358232797
Validation loss: 2.282556759362265

Epoch: 5| Step: 2
Training loss: 0.33205718892820646
Validation loss: 2.307962762271203

Epoch: 5| Step: 3
Training loss: 0.334132880941026
Validation loss: 2.4174456891329568

Epoch: 5| Step: 4
Training loss: 0.4499201564686447
Validation loss: 2.4408169252599814

Epoch: 5| Step: 5
Training loss: 0.5414902020604433
Validation loss: 2.4906510644552142

Epoch: 5| Step: 6
Training loss: 0.5206051390157932
Validation loss: 2.4548905258743705

Epoch: 5| Step: 7
Training loss: 0.3030930762833607
Validation loss: 2.3574978285650423

Epoch: 5| Step: 8
Training loss: 0.501155144760836
Validation loss: 2.2628674827545296

Epoch: 5| Step: 9
Training loss: 0.41668010531052546
Validation loss: 2.2509861907528843

Epoch: 5| Step: 10
Training loss: 0.4958904480562869
Validation loss: 2.2575749836064167

Epoch: 450| Step: 0
Training loss: 0.3467800800942801
Validation loss: 2.3139717298894777

Epoch: 5| Step: 1
Training loss: 0.4522491408846546
Validation loss: 2.337048847222809

Epoch: 5| Step: 2
Training loss: 0.3160467813832755
Validation loss: 2.3836396931810024

Epoch: 5| Step: 3
Training loss: 0.4679631622948861
Validation loss: 2.356958820136272

Epoch: 5| Step: 4
Training loss: 0.45436579082344336
Validation loss: 2.3996472829727877

Epoch: 5| Step: 5
Training loss: 0.33500147315669326
Validation loss: 2.353199077619488

Epoch: 5| Step: 6
Training loss: 0.4158626149646332
Validation loss: 2.339766742343606

Epoch: 5| Step: 7
Training loss: 0.3511389618281134
Validation loss: 2.3172709906987787

Epoch: 5| Step: 8
Training loss: 0.3001349056425208
Validation loss: 2.3174957362237523

Epoch: 5| Step: 9
Training loss: 0.2527981419724
Validation loss: 2.2844933836377876

Epoch: 5| Step: 10
Training loss: 0.43137522344436985
Validation loss: 2.3190859312103083

Epoch: 451| Step: 0
Training loss: 0.24630224387753252
Validation loss: 2.348799968354454

Epoch: 5| Step: 1
Training loss: 0.3743250454991218
Validation loss: 2.3595014697295316

Epoch: 5| Step: 2
Training loss: 0.19070132517639254
Validation loss: 2.386509380445522

Epoch: 5| Step: 3
Training loss: 0.27641211100780244
Validation loss: 2.3804477027279685

Epoch: 5| Step: 4
Training loss: 0.3349819121174824
Validation loss: 2.4095001580183304

Epoch: 5| Step: 5
Training loss: 0.3542651034980448
Validation loss: 2.406561281749246

Epoch: 5| Step: 6
Training loss: 0.35779449967330074
Validation loss: 2.3730162726898234

Epoch: 5| Step: 7
Training loss: 0.5315838213753552
Validation loss: 2.3912708670854084

Epoch: 5| Step: 8
Training loss: 0.4191392925202164
Validation loss: 2.360878515117156

Epoch: 5| Step: 9
Training loss: 0.3830197610114743
Validation loss: 2.3351276686926172

Epoch: 5| Step: 10
Training loss: 0.296669324099947
Validation loss: 2.263284646586079

Epoch: 452| Step: 0
Training loss: 0.37832744869341406
Validation loss: 2.354975794825041

Epoch: 5| Step: 1
Training loss: 0.32440554741438943
Validation loss: 2.31975018849393

Epoch: 5| Step: 2
Training loss: 0.4963966256068085
Validation loss: 2.3168299445777216

Epoch: 5| Step: 3
Training loss: 0.3646520981198804
Validation loss: 2.3821115641933317

Epoch: 5| Step: 4
Training loss: 0.34690833275247684
Validation loss: 2.3992210765764606

Epoch: 5| Step: 5
Training loss: 0.24793662977919337
Validation loss: 2.405116263353363

Epoch: 5| Step: 6
Training loss: 0.4145280272368974
Validation loss: 2.4175497735706593

Epoch: 5| Step: 7
Training loss: 0.35555869840352167
Validation loss: 2.420321547661075

Epoch: 5| Step: 8
Training loss: 0.30705663076234785
Validation loss: 2.3976487895158103

Epoch: 5| Step: 9
Training loss: 0.2755135741957141
Validation loss: 2.3545106409106578

Epoch: 5| Step: 10
Training loss: 0.37314306886332005
Validation loss: 2.3250697434424805

Epoch: 453| Step: 0
Training loss: 0.473821087413078
Validation loss: 2.2923071714767076

Epoch: 5| Step: 1
Training loss: 0.39280242585318803
Validation loss: 2.3405904736162872

Epoch: 5| Step: 2
Training loss: 0.5230123871764117
Validation loss: 2.3306480292306757

Epoch: 5| Step: 3
Training loss: 0.24558607597462453
Validation loss: 2.327705321799286

Epoch: 5| Step: 4
Training loss: 0.34755091196452836
Validation loss: 2.356973948768498

Epoch: 5| Step: 5
Training loss: 0.4043748752705825
Validation loss: 2.378713663069049

Epoch: 5| Step: 6
Training loss: 0.20338600152908876
Validation loss: 2.386687960468978

Epoch: 5| Step: 7
Training loss: 0.2683471710228678
Validation loss: 2.3537459885581002

Epoch: 5| Step: 8
Training loss: 0.3002141337305351
Validation loss: 2.3163434188725183

Epoch: 5| Step: 9
Training loss: 0.4101002609548829
Validation loss: 2.3003737869529504

Epoch: 5| Step: 10
Training loss: 0.34128406747605616
Validation loss: 2.2845424302042847

Epoch: 454| Step: 0
Training loss: 0.5459513902998815
Validation loss: 2.2815713267031574

Epoch: 5| Step: 1
Training loss: 0.28043302451928775
Validation loss: 2.290409043606869

Epoch: 5| Step: 2
Training loss: 0.33760718215510593
Validation loss: 2.338049186788807

Epoch: 5| Step: 3
Training loss: 0.21513189586578915
Validation loss: 2.356917067696549

Epoch: 5| Step: 4
Training loss: 0.3599872142786243
Validation loss: 2.414890755591986

Epoch: 5| Step: 5
Training loss: 0.33006033764827736
Validation loss: 2.38181649998358

Epoch: 5| Step: 6
Training loss: 0.3136124598572002
Validation loss: 2.370879218225189

Epoch: 5| Step: 7
Training loss: 0.32045578659301177
Validation loss: 2.3624341462998912

Epoch: 5| Step: 8
Training loss: 0.30044763815232883
Validation loss: 2.3130864411651273

Epoch: 5| Step: 9
Training loss: 0.33355360526608363
Validation loss: 2.319681386094827

Epoch: 5| Step: 10
Training loss: 0.4366935552109258
Validation loss: 2.276362669610651

Epoch: 455| Step: 0
Training loss: 0.2815967779643397
Validation loss: 2.3415451124523656

Epoch: 5| Step: 1
Training loss: 0.14782443307891743
Validation loss: 2.329086162564124

Epoch: 5| Step: 2
Training loss: 0.5035921936768603
Validation loss: 2.363910502527161

Epoch: 5| Step: 3
Training loss: 0.23633699164032995
Validation loss: 2.3520595548644865

Epoch: 5| Step: 4
Training loss: 0.34183953155277697
Validation loss: 2.379454211188551

Epoch: 5| Step: 5
Training loss: 0.404026733668245
Validation loss: 2.3499098567827192

Epoch: 5| Step: 6
Training loss: 0.37244710591503194
Validation loss: 2.3747580809294746

Epoch: 5| Step: 7
Training loss: 0.315233269823068
Validation loss: 2.322695549748316

Epoch: 5| Step: 8
Training loss: 0.40100251869590264
Validation loss: 2.354871993961167

Epoch: 5| Step: 9
Training loss: 0.3913660839738031
Validation loss: 2.3127793858627053

Epoch: 5| Step: 10
Training loss: 0.250319306784673
Validation loss: 2.321375331405633

Epoch: 456| Step: 0
Training loss: 0.3208365688945231
Validation loss: 2.3664590619149877

Epoch: 5| Step: 1
Training loss: 0.37392489975401694
Validation loss: 2.384988882831284

Epoch: 5| Step: 2
Training loss: 0.4941761773026758
Validation loss: 2.355957980934941

Epoch: 5| Step: 3
Training loss: 0.30147554102418167
Validation loss: 2.347247676497356

Epoch: 5| Step: 4
Training loss: 0.31162186266578007
Validation loss: 2.3183851554661796

Epoch: 5| Step: 5
Training loss: 0.2780173007449566
Validation loss: 2.3383711129579137

Epoch: 5| Step: 6
Training loss: 0.23901258863879676
Validation loss: 2.328952103642684

Epoch: 5| Step: 7
Training loss: 0.34082174437476237
Validation loss: 2.319083569408646

Epoch: 5| Step: 8
Training loss: 0.2563315250225878
Validation loss: 2.310478897016356

Epoch: 5| Step: 9
Training loss: 0.4779798037899085
Validation loss: 2.3390565700851638

Epoch: 5| Step: 10
Training loss: 0.21546884113500714
Validation loss: 2.3477601154668073

Epoch: 457| Step: 0
Training loss: 0.32340598206209953
Validation loss: 2.3793367202861746

Epoch: 5| Step: 1
Training loss: 0.3745784376812462
Validation loss: 2.3932135284411724

Epoch: 5| Step: 2
Training loss: 0.38217739048186067
Validation loss: 2.383394183446185

Epoch: 5| Step: 3
Training loss: 0.26419708783521395
Validation loss: 2.3898850996427985

Epoch: 5| Step: 4
Training loss: 0.34103392325791715
Validation loss: 2.381299466139409

Epoch: 5| Step: 5
Training loss: 0.3214023935163589
Validation loss: 2.3430838411389643

Epoch: 5| Step: 6
Training loss: 0.35251880492446724
Validation loss: 2.32975356737608

Epoch: 5| Step: 7
Training loss: 0.3925955469621269
Validation loss: 2.284376550343438

Epoch: 5| Step: 8
Training loss: 0.32863897985495394
Validation loss: 2.2850517939724613

Epoch: 5| Step: 9
Training loss: 0.30676554911174425
Validation loss: 2.3185147324126287

Epoch: 5| Step: 10
Training loss: 0.23741234586069287
Validation loss: 2.32477540646994

Epoch: 458| Step: 0
Training loss: 0.3116072060775849
Validation loss: 2.358151458762002

Epoch: 5| Step: 1
Training loss: 0.20310004704602577
Validation loss: 2.363013636936636

Epoch: 5| Step: 2
Training loss: 0.22413646836413847
Validation loss: 2.396204184515706

Epoch: 5| Step: 3
Training loss: 0.33491514688135765
Validation loss: 2.375568114694197

Epoch: 5| Step: 4
Training loss: 0.39405860538963083
Validation loss: 2.3864340064757896

Epoch: 5| Step: 5
Training loss: 0.2447834782887974
Validation loss: 2.3923281123660542

Epoch: 5| Step: 6
Training loss: 0.2747023890239008
Validation loss: 2.35863930800738

Epoch: 5| Step: 7
Training loss: 0.4516499121251692
Validation loss: 2.3310767841173785

Epoch: 5| Step: 8
Training loss: 0.35280207283215004
Validation loss: 2.2882000347873364

Epoch: 5| Step: 9
Training loss: 0.36461809764602243
Validation loss: 2.2966963767122555

Epoch: 5| Step: 10
Training loss: 0.32707137153806665
Validation loss: 2.2855695015839297

Epoch: 459| Step: 0
Training loss: 0.18865918418898767
Validation loss: 2.260410305615529

Epoch: 5| Step: 1
Training loss: 0.47277225300396936
Validation loss: 2.307690642153547

Epoch: 5| Step: 2
Training loss: 0.28472929828788035
Validation loss: 2.3469123714902573

Epoch: 5| Step: 3
Training loss: 0.26168522691251933
Validation loss: 2.351588590187839

Epoch: 5| Step: 4
Training loss: 0.40164416332574726
Validation loss: 2.4220218832228935

Epoch: 5| Step: 5
Training loss: 0.3135772258242514
Validation loss: 2.409403583602904

Epoch: 5| Step: 6
Training loss: 0.27832634902564807
Validation loss: 2.378850678984085

Epoch: 5| Step: 7
Training loss: 0.308506736076703
Validation loss: 2.330068221736178

Epoch: 5| Step: 8
Training loss: 0.3862832053889331
Validation loss: 2.331359361393154

Epoch: 5| Step: 9
Training loss: 0.21594842068871264
Validation loss: 2.3279824778650076

Epoch: 5| Step: 10
Training loss: 0.4016119403312678
Validation loss: 2.356998569433638

Epoch: 460| Step: 0
Training loss: 0.22798742888431892
Validation loss: 2.3362538574171454

Epoch: 5| Step: 1
Training loss: 0.417790847422691
Validation loss: 2.3463869679262537

Epoch: 5| Step: 2
Training loss: 0.2629650390417557
Validation loss: 2.388664468494469

Epoch: 5| Step: 3
Training loss: 0.24079925525487145
Validation loss: 2.3680953459712186

Epoch: 5| Step: 4
Training loss: 0.24274016203671706
Validation loss: 2.3701474973424514

Epoch: 5| Step: 5
Training loss: 0.40311953370875653
Validation loss: 2.379215023430841

Epoch: 5| Step: 6
Training loss: 0.35245071107119164
Validation loss: 2.3516257800880878

Epoch: 5| Step: 7
Training loss: 0.25416176483763897
Validation loss: 2.3481256516907063

Epoch: 5| Step: 8
Training loss: 0.2600882111894274
Validation loss: 2.3299356145077166

Epoch: 5| Step: 9
Training loss: 0.4127297455215548
Validation loss: 2.35791511682836

Epoch: 5| Step: 10
Training loss: 0.27245738256179386
Validation loss: 2.353167378868258

Epoch: 461| Step: 0
Training loss: 0.29210011455572166
Validation loss: 2.3400982426926484

Epoch: 5| Step: 1
Training loss: 0.43826110235949756
Validation loss: 2.360925554065432

Epoch: 5| Step: 2
Training loss: 0.27912441344312716
Validation loss: 2.3275641881983336

Epoch: 5| Step: 3
Training loss: 0.3395740052367663
Validation loss: 2.35804360983946

Epoch: 5| Step: 4
Training loss: 0.2683093805955942
Validation loss: 2.3484211805854858

Epoch: 5| Step: 5
Training loss: 0.29131386343230375
Validation loss: 2.3662970724293086

Epoch: 5| Step: 6
Training loss: 0.3004349907702228
Validation loss: 2.3596204252322144

Epoch: 5| Step: 7
Training loss: 0.2882838070763792
Validation loss: 2.328183118556288

Epoch: 5| Step: 8
Training loss: 0.14914071878876892
Validation loss: 2.390279214199445

Epoch: 5| Step: 9
Training loss: 0.3119363947584887
Validation loss: 2.3403943153118836

Epoch: 5| Step: 10
Training loss: 0.43435701429057016
Validation loss: 2.353798043454615

Epoch: 462| Step: 0
Training loss: 0.341559213027425
Validation loss: 2.383095932431337

Epoch: 5| Step: 1
Training loss: 0.26965268481668836
Validation loss: 2.340888606941607

Epoch: 5| Step: 2
Training loss: 0.1908096240202062
Validation loss: 2.337830223972554

Epoch: 5| Step: 3
Training loss: 0.24401374571709766
Validation loss: 2.3502960757766878

Epoch: 5| Step: 4
Training loss: 0.3031908961569635
Validation loss: 2.334821588633352

Epoch: 5| Step: 5
Training loss: 0.3226621673447788
Validation loss: 2.3589971693882203

Epoch: 5| Step: 6
Training loss: 0.44316120172000073
Validation loss: 2.3634721668526377

Epoch: 5| Step: 7
Training loss: 0.31106663040138305
Validation loss: 2.334029510977402

Epoch: 5| Step: 8
Training loss: 0.23253633581812425
Validation loss: 2.317595971206604

Epoch: 5| Step: 9
Training loss: 0.36095475159738427
Validation loss: 2.3719701476347073

Epoch: 5| Step: 10
Training loss: 0.2641625395436402
Validation loss: 2.376777630246242

Epoch: 463| Step: 0
Training loss: 0.36699450270332074
Validation loss: 2.3354808632537467

Epoch: 5| Step: 1
Training loss: 0.16789987726753763
Validation loss: 2.3409739602824198

Epoch: 5| Step: 2
Training loss: 0.38572074733978207
Validation loss: 2.331352946672854

Epoch: 5| Step: 3
Training loss: 0.2797658224565863
Validation loss: 2.3372287537589553

Epoch: 5| Step: 4
Training loss: 0.2274339703351242
Validation loss: 2.3656125166451156

Epoch: 5| Step: 5
Training loss: 0.24873526860231226
Validation loss: 2.367787607301615

Epoch: 5| Step: 6
Training loss: 0.424234942132466
Validation loss: 2.3649618707645397

Epoch: 5| Step: 7
Training loss: 0.17261172212372533
Validation loss: 2.351166919973803

Epoch: 5| Step: 8
Training loss: 0.48040713713801064
Validation loss: 2.390384916973445

Epoch: 5| Step: 9
Training loss: 0.2717100618716252
Validation loss: 2.4096280302246815

Epoch: 5| Step: 10
Training loss: 0.17904286228633265
Validation loss: 2.4037126849521457

Epoch: 464| Step: 0
Training loss: 0.23697138169185689
Validation loss: 2.352842529348963

Epoch: 5| Step: 1
Training loss: 0.23276744124871684
Validation loss: 2.358770004837922

Epoch: 5| Step: 2
Training loss: 0.37158616172710457
Validation loss: 2.370689573747971

Epoch: 5| Step: 3
Training loss: 0.2631955542173337
Validation loss: 2.389562514538843

Epoch: 5| Step: 4
Training loss: 0.44093566047939003
Validation loss: 2.350836138577495

Epoch: 5| Step: 5
Training loss: 0.2747327101632662
Validation loss: 2.3603241338423446

Epoch: 5| Step: 6
Training loss: 0.3051443099006911
Validation loss: 2.37670326036926

Epoch: 5| Step: 7
Training loss: 0.16992627609516564
Validation loss: 2.4230019669439153

Epoch: 5| Step: 8
Training loss: 0.3370802870099197
Validation loss: 2.410996302823039

Epoch: 5| Step: 9
Training loss: 0.3643646288159714
Validation loss: 2.4621476288943094

Epoch: 5| Step: 10
Training loss: 0.3651588280210952
Validation loss: 2.3966177245296425

Epoch: 465| Step: 0
Training loss: 0.2107134883455079
Validation loss: 2.369862808913996

Epoch: 5| Step: 1
Training loss: 0.29359021711025657
Validation loss: 2.3797933482811806

Epoch: 5| Step: 2
Training loss: 0.15193060337845335
Validation loss: 2.374633105510648

Epoch: 5| Step: 3
Training loss: 0.441868733870174
Validation loss: 2.3583880563779793

Epoch: 5| Step: 4
Training loss: 0.3237043229213637
Validation loss: 2.390174300456314

Epoch: 5| Step: 5
Training loss: 0.3258843210860465
Validation loss: 2.3763022379665126

Epoch: 5| Step: 6
Training loss: 0.23608478912879094
Validation loss: 2.394923899902429

Epoch: 5| Step: 7
Training loss: 0.31883943088548183
Validation loss: 2.397681926896848

Epoch: 5| Step: 8
Training loss: 0.24595697325859758
Validation loss: 2.3817564890546743

Epoch: 5| Step: 9
Training loss: 0.1714062638834806
Validation loss: 2.413856208414495

Epoch: 5| Step: 10
Training loss: 0.45534615543477036
Validation loss: 2.4056944997632805

Epoch: 466| Step: 0
Training loss: 0.24068617786152308
Validation loss: 2.3931671455546293

Epoch: 5| Step: 1
Training loss: 0.23358259557163372
Validation loss: 2.37024017564769

Epoch: 5| Step: 2
Training loss: 0.3932177518825722
Validation loss: 2.369959026396302

Epoch: 5| Step: 3
Training loss: 0.3413687286010416
Validation loss: 2.3500458062917184

Epoch: 5| Step: 4
Training loss: 0.16951825448077587
Validation loss: 2.366270500869895

Epoch: 5| Step: 5
Training loss: 0.3459004523263297
Validation loss: 2.375417775151774

Epoch: 5| Step: 6
Training loss: 0.22720592489656086
Validation loss: 2.350047726256709

Epoch: 5| Step: 7
Training loss: 0.1941689679738675
Validation loss: 2.338257389442906

Epoch: 5| Step: 8
Training loss: 0.23523302377485658
Validation loss: 2.347832688730573

Epoch: 5| Step: 9
Training loss: 0.33519376442550314
Validation loss: 2.3481090205210453

Epoch: 5| Step: 10
Training loss: 0.3635720350521146
Validation loss: 2.322252333530992

Epoch: 467| Step: 0
Training loss: 0.2803691076024312
Validation loss: 2.3120491965312175

Epoch: 5| Step: 1
Training loss: 0.3461062349431291
Validation loss: 2.3173479704064257

Epoch: 5| Step: 2
Training loss: 0.3758594280933508
Validation loss: 2.343063052557992

Epoch: 5| Step: 3
Training loss: 0.2843393355841386
Validation loss: 2.36208859883322

Epoch: 5| Step: 4
Training loss: 0.371285017815261
Validation loss: 2.368136894832249

Epoch: 5| Step: 5
Training loss: 0.21402885910550146
Validation loss: 2.3716881581970557

Epoch: 5| Step: 6
Training loss: 0.42713996659030773
Validation loss: 2.385062714882935

Epoch: 5| Step: 7
Training loss: 0.2810776897929414
Validation loss: 2.374758703282818

Epoch: 5| Step: 8
Training loss: 0.12243392576464672
Validation loss: 2.3706069778831793

Epoch: 5| Step: 9
Training loss: 0.24005043151848862
Validation loss: 2.339515261011833

Epoch: 5| Step: 10
Training loss: 0.1932733903302965
Validation loss: 2.391954055103439

Epoch: 468| Step: 0
Training loss: 0.22619472447537178
Validation loss: 2.379183335649315

Epoch: 5| Step: 1
Training loss: 0.29543449364656366
Validation loss: 2.3824357855090352

Epoch: 5| Step: 2
Training loss: 0.4563038245550585
Validation loss: 2.38957434803808

Epoch: 5| Step: 3
Training loss: 0.30897153593798016
Validation loss: 2.385621836146034

Epoch: 5| Step: 4
Training loss: 0.2266507716703501
Validation loss: 2.3664875661503837

Epoch: 5| Step: 5
Training loss: 0.4179015417521951
Validation loss: 2.317233634434539

Epoch: 5| Step: 6
Training loss: 0.19490598334776923
Validation loss: 2.2995466323833478

Epoch: 5| Step: 7
Training loss: 0.22817246028295052
Validation loss: 2.297057614919417

Epoch: 5| Step: 8
Training loss: 0.2634111881804703
Validation loss: 2.297560528632018

Epoch: 5| Step: 9
Training loss: 0.2749822171920614
Validation loss: 2.3239192337758925

Epoch: 5| Step: 10
Training loss: 0.35815712603262273
Validation loss: 2.369433289350373

Epoch: 469| Step: 0
Training loss: 0.23673387642803442
Validation loss: 2.3494695642774075

Epoch: 5| Step: 1
Training loss: 0.32860197866877866
Validation loss: 2.357100947571761

Epoch: 5| Step: 2
Training loss: 0.33261290820197537
Validation loss: 2.429640270784809

Epoch: 5| Step: 3
Training loss: 0.27386137941355737
Validation loss: 2.3634495834459934

Epoch: 5| Step: 4
Training loss: 0.2964069541798111
Validation loss: 2.3258088516216255

Epoch: 5| Step: 5
Training loss: 0.24915569009865096
Validation loss: 2.319253077980143

Epoch: 5| Step: 6
Training loss: 0.22770064678347388
Validation loss: 2.293809139462466

Epoch: 5| Step: 7
Training loss: 0.39613795062051504
Validation loss: 2.312224371973588

Epoch: 5| Step: 8
Training loss: 0.48990014829958467
Validation loss: 2.3416012042299004

Epoch: 5| Step: 9
Training loss: 0.17821975078565983
Validation loss: 2.3677883587061386

Epoch: 5| Step: 10
Training loss: 0.14953730991445194
Validation loss: 2.376590413216468

Epoch: 470| Step: 0
Training loss: 0.258628867608564
Validation loss: 2.3515196291329463

Epoch: 5| Step: 1
Training loss: 0.23198476929501674
Validation loss: 2.3486466161495247

Epoch: 5| Step: 2
Training loss: 0.42486885726160367
Validation loss: 2.3285073644038268

Epoch: 5| Step: 3
Training loss: 0.3086652672865855
Validation loss: 2.300629504490785

Epoch: 5| Step: 4
Training loss: 0.19853749384069166
Validation loss: 2.2972036080169356

Epoch: 5| Step: 5
Training loss: 0.33225156543081613
Validation loss: 2.288279360958255

Epoch: 5| Step: 6
Training loss: 0.2023702408965554
Validation loss: 2.3220455044966584

Epoch: 5| Step: 7
Training loss: 0.3318191187269052
Validation loss: 2.3495932518741514

Epoch: 5| Step: 8
Training loss: 0.28580278756568783
Validation loss: 2.370139342321785

Epoch: 5| Step: 9
Training loss: 0.3631511578355095
Validation loss: 2.3778038248820503

Epoch: 5| Step: 10
Training loss: 0.3486009898474795
Validation loss: 2.410613971803567

Epoch: 471| Step: 0
Training loss: 0.36875988736878884
Validation loss: 2.416593710364243

Epoch: 5| Step: 1
Training loss: 0.3108638369462198
Validation loss: 2.3981658973092803

Epoch: 5| Step: 2
Training loss: 0.2213674270173543
Validation loss: 2.3869081595271524

Epoch: 5| Step: 3
Training loss: 0.2255140991101168
Validation loss: 2.3729325742686314

Epoch: 5| Step: 4
Training loss: 0.37304228135720896
Validation loss: 2.364684788262683

Epoch: 5| Step: 5
Training loss: 0.257202322244246
Validation loss: 2.355970848026404

Epoch: 5| Step: 6
Training loss: 0.1864540610188024
Validation loss: 2.368798155412412

Epoch: 5| Step: 7
Training loss: 0.2986119429566874
Validation loss: 2.3724937746083494

Epoch: 5| Step: 8
Training loss: 0.19658575836150435
Validation loss: 2.357501647655991

Epoch: 5| Step: 9
Training loss: 0.3880467971546701
Validation loss: 2.343970555144935

Epoch: 5| Step: 10
Training loss: 0.21426789530395104
Validation loss: 2.3256405010222085

Epoch: 472| Step: 0
Training loss: 0.31154020258357235
Validation loss: 2.363768909257002

Epoch: 5| Step: 1
Training loss: 0.21470261186055778
Validation loss: 2.3449739411943944

Epoch: 5| Step: 2
Training loss: 0.1769302222817817
Validation loss: 2.345898656894182

Epoch: 5| Step: 3
Training loss: 0.41743238741078
Validation loss: 2.354768295214418

Epoch: 5| Step: 4
Training loss: 0.27685735254470994
Validation loss: 2.3459578814263504

Epoch: 5| Step: 5
Training loss: 0.17756051163733316
Validation loss: 2.338883814783753

Epoch: 5| Step: 6
Training loss: 0.31372718655903936
Validation loss: 2.3727943463284844

Epoch: 5| Step: 7
Training loss: 0.2960557928390596
Validation loss: 2.3534301420950228

Epoch: 5| Step: 8
Training loss: 0.20946495557737624
Validation loss: 2.350495294928472

Epoch: 5| Step: 9
Training loss: 0.3133954807842388
Validation loss: 2.3374485198182278

Epoch: 5| Step: 10
Training loss: 0.3393279139906323
Validation loss: 2.3630299809441384

Epoch: 473| Step: 0
Training loss: 0.13070239429987876
Validation loss: 2.3697804043806587

Epoch: 5| Step: 1
Training loss: 0.1920773457978612
Validation loss: 2.374007756631806

Epoch: 5| Step: 2
Training loss: 0.2390677027666006
Validation loss: 2.315377591002812

Epoch: 5| Step: 3
Training loss: 0.26289924165341366
Validation loss: 2.3044680755650018

Epoch: 5| Step: 4
Training loss: 0.3290163376934461
Validation loss: 2.263309793696782

Epoch: 5| Step: 5
Training loss: 0.2721630779000746
Validation loss: 2.305181351314858

Epoch: 5| Step: 6
Training loss: 0.28990068570506944
Validation loss: 2.3245665300634135

Epoch: 5| Step: 7
Training loss: 0.41078495704484336
Validation loss: 2.34171386873786

Epoch: 5| Step: 8
Training loss: 0.2976172354052638
Validation loss: 2.37333462404222

Epoch: 5| Step: 9
Training loss: 0.2986570753840726
Validation loss: 2.397038654599982

Epoch: 5| Step: 10
Training loss: 0.43628867234806795
Validation loss: 2.379439534705065

Epoch: 474| Step: 0
Training loss: 0.4518260919054429
Validation loss: 2.3516730041126648

Epoch: 5| Step: 1
Training loss: 0.20570205055069216
Validation loss: 2.3145707904574806

Epoch: 5| Step: 2
Training loss: 0.31345391117387367
Validation loss: 2.303279891659028

Epoch: 5| Step: 3
Training loss: 0.27627385319133557
Validation loss: 2.296731820079436

Epoch: 5| Step: 4
Training loss: 0.3497017892776477
Validation loss: 2.311240615184555

Epoch: 5| Step: 5
Training loss: 0.11314007578288317
Validation loss: 2.351472954773619

Epoch: 5| Step: 6
Training loss: 0.1425249118006222
Validation loss: 2.362336597346569

Epoch: 5| Step: 7
Training loss: 0.3891194512535017
Validation loss: 2.431646661824647

Epoch: 5| Step: 8
Training loss: 0.34480588394809686
Validation loss: 2.430341256143726

Epoch: 5| Step: 9
Training loss: 0.23039130348216907
Validation loss: 2.44531075023683

Epoch: 5| Step: 10
Training loss: 0.3485835064554632
Validation loss: 2.4424769278407146

Epoch: 475| Step: 0
Training loss: 0.37621194976584904
Validation loss: 2.393802722500343

Epoch: 5| Step: 1
Training loss: 0.29815330854803535
Validation loss: 2.393164579949204

Epoch: 5| Step: 2
Training loss: 0.40699556600653236
Validation loss: 2.3672589914291327

Epoch: 5| Step: 3
Training loss: 0.25495690332198606
Validation loss: 2.3075782773605265

Epoch: 5| Step: 4
Training loss: 0.22790512632539942
Validation loss: 2.3031371004521923

Epoch: 5| Step: 5
Training loss: 0.22905509392916218
Validation loss: 2.3148977979281242

Epoch: 5| Step: 6
Training loss: 0.19970581875085583
Validation loss: 2.274687318861056

Epoch: 5| Step: 7
Training loss: 0.18466230653083762
Validation loss: 2.320882272700504

Epoch: 5| Step: 8
Training loss: 0.3432885453877535
Validation loss: 2.368617258452502

Epoch: 5| Step: 9
Training loss: 0.37692636187325657
Validation loss: 2.4159438085037737

Epoch: 5| Step: 10
Training loss: 0.25860373140646387
Validation loss: 2.439804787042785

Epoch: 476| Step: 0
Training loss: 0.36330612671697493
Validation loss: 2.4189436676626412

Epoch: 5| Step: 1
Training loss: 0.2810819706720262
Validation loss: 2.38249464734218

Epoch: 5| Step: 2
Training loss: 0.369838075904528
Validation loss: 2.383810394986548

Epoch: 5| Step: 3
Training loss: 0.13331560604395504
Validation loss: 2.3589312798904203

Epoch: 5| Step: 4
Training loss: 0.3089248112730046
Validation loss: 2.337184031119932

Epoch: 5| Step: 5
Training loss: 0.18292886991641946
Validation loss: 2.3290168731503322

Epoch: 5| Step: 6
Training loss: 0.2811071244896557
Validation loss: 2.318740063876999

Epoch: 5| Step: 7
Training loss: 0.2761992763323008
Validation loss: 2.3804755322200197

Epoch: 5| Step: 8
Training loss: 0.18436572932519352
Validation loss: 2.3974780395264075

Epoch: 5| Step: 9
Training loss: 0.33598694326585327
Validation loss: 2.3860818491009455

Epoch: 5| Step: 10
Training loss: 0.43957550040342785
Validation loss: 2.400667539688146

Epoch: 477| Step: 0
Training loss: 0.3652323962479298
Validation loss: 2.4101372302210624

Epoch: 5| Step: 1
Training loss: 0.3498423561930524
Validation loss: 2.3434894868185143

Epoch: 5| Step: 2
Training loss: 0.2174769380280288
Validation loss: 2.3283490116349257

Epoch: 5| Step: 3
Training loss: 0.40769572869908527
Validation loss: 2.367528589150995

Epoch: 5| Step: 4
Training loss: 0.22087497266133457
Validation loss: 2.3318040030436773

Epoch: 5| Step: 5
Training loss: 0.19478291238570825
Validation loss: 2.3528730181413855

Epoch: 5| Step: 6
Training loss: 0.19338335986644195
Validation loss: 2.320956982741398

Epoch: 5| Step: 7
Training loss: 0.3445581667845749
Validation loss: 2.3456853935733633

Epoch: 5| Step: 8
Training loss: 0.19522964627514328
Validation loss: 2.3749971103704604

Epoch: 5| Step: 9
Training loss: 0.2940877271608458
Validation loss: 2.3446605988957097

Epoch: 5| Step: 10
Training loss: 0.23811547969950506
Validation loss: 2.356638817405998

Epoch: 478| Step: 0
Training loss: 0.30476725585939235
Validation loss: 2.3513111736105485

Epoch: 5| Step: 1
Training loss: 0.2108494610203093
Validation loss: 2.3499399221574

Epoch: 5| Step: 2
Training loss: 0.27319469570893284
Validation loss: 2.332429940244319

Epoch: 5| Step: 3
Training loss: 0.2764132565763452
Validation loss: 2.316920918325929

Epoch: 5| Step: 4
Training loss: 0.3259190133174576
Validation loss: 2.341747740710293

Epoch: 5| Step: 5
Training loss: 0.16158980098318695
Validation loss: 2.3194060621384693

Epoch: 5| Step: 6
Training loss: 0.346379647237879
Validation loss: 2.344312947800471

Epoch: 5| Step: 7
Training loss: 0.13608116938126474
Validation loss: 2.3035225141748827

Epoch: 5| Step: 8
Training loss: 0.22950304695570928
Validation loss: 2.339599008761246

Epoch: 5| Step: 9
Training loss: 0.3618592354036971
Validation loss: 2.317700927176861

Epoch: 5| Step: 10
Training loss: 0.30153363737034344
Validation loss: 2.3126146226593693

Epoch: 479| Step: 0
Training loss: 0.25563613237796057
Validation loss: 2.3059996837600134

Epoch: 5| Step: 1
Training loss: 0.27120257235470346
Validation loss: 2.3425925313804643

Epoch: 5| Step: 2
Training loss: 0.4395333110979332
Validation loss: 2.331850964455063

Epoch: 5| Step: 3
Training loss: 0.2406538580644456
Validation loss: 2.315336964399262

Epoch: 5| Step: 4
Training loss: 0.20411938493659612
Validation loss: 2.3379023340533927

Epoch: 5| Step: 5
Training loss: 0.23362553294158286
Validation loss: 2.348369566529168

Epoch: 5| Step: 6
Training loss: 0.15032143673333392
Validation loss: 2.3500065841181113

Epoch: 5| Step: 7
Training loss: 0.1482786910154819
Validation loss: 2.3224846528168976

Epoch: 5| Step: 8
Training loss: 0.32030852245559416
Validation loss: 2.311077216793886

Epoch: 5| Step: 9
Training loss: 0.3352963405992226
Validation loss: 2.319316303370842

Epoch: 5| Step: 10
Training loss: 0.17532561909280586
Validation loss: 2.334669920972884

Epoch: 480| Step: 0
Training loss: 0.1841997837498469
Validation loss: 2.3107476117462036

Epoch: 5| Step: 1
Training loss: 0.2577045966247272
Validation loss: 2.3195769728760327

Epoch: 5| Step: 2
Training loss: 0.21383334027008122
Validation loss: 2.3005392727765286

Epoch: 5| Step: 3
Training loss: 0.18122926914111184
Validation loss: 2.309898748170665

Epoch: 5| Step: 4
Training loss: 0.15748204626584617
Validation loss: 2.3708996363963455

Epoch: 5| Step: 5
Training loss: 0.22193517540520263
Validation loss: 2.349821900343503

Epoch: 5| Step: 6
Training loss: 0.3377596761283119
Validation loss: 2.3871613870405195

Epoch: 5| Step: 7
Training loss: 0.3559283753884187
Validation loss: 2.3853841373604157

Epoch: 5| Step: 8
Training loss: 0.344814678309718
Validation loss: 2.4273502421914985

Epoch: 5| Step: 9
Training loss: 0.3496269988833785
Validation loss: 2.388279278160525

Epoch: 5| Step: 10
Training loss: 0.29859122067133265
Validation loss: 2.3295734307522125

Epoch: 481| Step: 0
Training loss: 0.12019690527742383
Validation loss: 2.301711179376172

Epoch: 5| Step: 1
Training loss: 0.26267423864304934
Validation loss: 2.3009299048073792

Epoch: 5| Step: 2
Training loss: 0.27706033705648664
Validation loss: 2.2881503484462296

Epoch: 5| Step: 3
Training loss: 0.28488692537616095
Validation loss: 2.286912341600719

Epoch: 5| Step: 4
Training loss: 0.24391992129879553
Validation loss: 2.3218039844977594

Epoch: 5| Step: 5
Training loss: 0.37542474057783726
Validation loss: 2.3789977508636913

Epoch: 5| Step: 6
Training loss: 0.36124330504526353
Validation loss: 2.4080673767807608

Epoch: 5| Step: 7
Training loss: 0.2820434372189285
Validation loss: 2.4507655217872064

Epoch: 5| Step: 8
Training loss: 0.3719048520135564
Validation loss: 2.443396644337226

Epoch: 5| Step: 9
Training loss: 0.39420624367270585
Validation loss: 2.403605840962201

Epoch: 5| Step: 10
Training loss: 0.12419344296367757
Validation loss: 2.357838032882545

Epoch: 482| Step: 0
Training loss: 0.34977243126711277
Validation loss: 2.308902504746312

Epoch: 5| Step: 1
Training loss: 0.27021334213098785
Validation loss: 2.3165317660418068

Epoch: 5| Step: 2
Training loss: 0.19328428023976604
Validation loss: 2.332468380853916

Epoch: 5| Step: 3
Training loss: 0.3850132876122001
Validation loss: 2.3233676062337465

Epoch: 5| Step: 4
Training loss: 0.1920877798849065
Validation loss: 2.3683260758324494

Epoch: 5| Step: 5
Training loss: 0.23300491260856815
Validation loss: 2.3922980010317474

Epoch: 5| Step: 6
Training loss: 0.18347389285846002
Validation loss: 2.4139648241454035

Epoch: 5| Step: 7
Training loss: 0.29879704482070685
Validation loss: 2.3996913526865056

Epoch: 5| Step: 8
Training loss: 0.2546250805103248
Validation loss: 2.4014409835860633

Epoch: 5| Step: 9
Training loss: 0.34238904608945325
Validation loss: 2.3535364813772564

Epoch: 5| Step: 10
Training loss: 0.2642911491033145
Validation loss: 2.347724171417741

Epoch: 483| Step: 0
Training loss: 0.21900711956709928
Validation loss: 2.338263284721322

Epoch: 5| Step: 1
Training loss: 0.24099099792341205
Validation loss: 2.322128014870457

Epoch: 5| Step: 2
Training loss: 0.23691049653315518
Validation loss: 2.3329020671492677

Epoch: 5| Step: 3
Training loss: 0.2911800841496405
Validation loss: 2.3037601285503735

Epoch: 5| Step: 4
Training loss: 0.2918382577008626
Validation loss: 2.3027405104035767

Epoch: 5| Step: 5
Training loss: 0.30601035784818537
Validation loss: 2.3550597008988197

Epoch: 5| Step: 6
Training loss: 0.35050214228267873
Validation loss: 2.3828170628388827

Epoch: 5| Step: 7
Training loss: 0.2317522162914779
Validation loss: 2.359606683606304

Epoch: 5| Step: 8
Training loss: 0.118751472696157
Validation loss: 2.3799206762347325

Epoch: 5| Step: 9
Training loss: 0.35979170067939237
Validation loss: 2.359151540462805

Epoch: 5| Step: 10
Training loss: 0.3231734810730096
Validation loss: 2.335386949900647

Epoch: 484| Step: 0
Training loss: 0.31508267804901363
Validation loss: 2.3415067529740226

Epoch: 5| Step: 1
Training loss: 0.1319694408224327
Validation loss: 2.3838826009610914

Epoch: 5| Step: 2
Training loss: 0.3801147419775668
Validation loss: 2.35928438867378

Epoch: 5| Step: 3
Training loss: 0.21635339242897356
Validation loss: 2.367994019662285

Epoch: 5| Step: 4
Training loss: 0.3308592250242648
Validation loss: 2.3409818943924288

Epoch: 5| Step: 5
Training loss: 0.2823041789365806
Validation loss: 2.3571992781916093

Epoch: 5| Step: 6
Training loss: 0.24248529399444743
Validation loss: 2.328859214413553

Epoch: 5| Step: 7
Training loss: 0.1651566836821493
Validation loss: 2.3821651801284736

Epoch: 5| Step: 8
Training loss: 0.21557788264977146
Validation loss: 2.335762203096532

Epoch: 5| Step: 9
Training loss: 0.3936678058878032
Validation loss: 2.3569325109427264

Epoch: 5| Step: 10
Training loss: 0.32110213433524276
Validation loss: 2.3478131913628597

Epoch: 485| Step: 0
Training loss: 0.2541058709309315
Validation loss: 2.327270452286719

Epoch: 5| Step: 1
Training loss: 0.17970063327394856
Validation loss: 2.3794750653871564

Epoch: 5| Step: 2
Training loss: 0.3110223764521855
Validation loss: 2.3899175637529955

Epoch: 5| Step: 3
Training loss: 0.2691829753271383
Validation loss: 2.344612160988184

Epoch: 5| Step: 4
Training loss: 0.2389215558764486
Validation loss: 2.3776175393872983

Epoch: 5| Step: 5
Training loss: 0.3243173081759645
Validation loss: 2.33625609267658

Epoch: 5| Step: 6
Training loss: 0.3335788674351428
Validation loss: 2.292656396342422

Epoch: 5| Step: 7
Training loss: 0.3364039664538706
Validation loss: 2.295503501104775

Epoch: 5| Step: 8
Training loss: 0.3911114524769979
Validation loss: 2.2798380981165565

Epoch: 5| Step: 9
Training loss: 0.252150598660049
Validation loss: 2.28881173792165

Epoch: 5| Step: 10
Training loss: 0.19527137323346458
Validation loss: 2.368864361359045

Epoch: 486| Step: 0
Training loss: 0.29325311211790756
Validation loss: 2.3643807958744643

Epoch: 5| Step: 1
Training loss: 0.4455217906961537
Validation loss: 2.4151958095601778

Epoch: 5| Step: 2
Training loss: 0.23936798517441693
Validation loss: 2.423915076577887

Epoch: 5| Step: 3
Training loss: 0.26848322524427465
Validation loss: 2.359928678151289

Epoch: 5| Step: 4
Training loss: 0.24927413886960884
Validation loss: 2.3144474714667123

Epoch: 5| Step: 5
Training loss: 0.32131414112665513
Validation loss: 2.313103982483846

Epoch: 5| Step: 6
Training loss: 0.20043220460449032
Validation loss: 2.272839755913251

Epoch: 5| Step: 7
Training loss: 0.24681112392599308
Validation loss: 2.257211275779399

Epoch: 5| Step: 8
Training loss: 0.24776795241821695
Validation loss: 2.299277804416398

Epoch: 5| Step: 9
Training loss: 0.24082786628651334
Validation loss: 2.354370104767394

Epoch: 5| Step: 10
Training loss: 0.3455411348290887
Validation loss: 2.351279956950202

Epoch: 487| Step: 0
Training loss: 0.3975459952104619
Validation loss: 2.4065530961907506

Epoch: 5| Step: 1
Training loss: 0.3690947448636962
Validation loss: 2.3773165071909137

Epoch: 5| Step: 2
Training loss: 0.21773417508075407
Validation loss: 2.3837172526952277

Epoch: 5| Step: 3
Training loss: 0.2216331248179159
Validation loss: 2.3825395847075073

Epoch: 5| Step: 4
Training loss: 0.11834668793366979
Validation loss: 2.3663414956486633

Epoch: 5| Step: 5
Training loss: 0.35635383163625217
Validation loss: 2.330519044393818

Epoch: 5| Step: 6
Training loss: 0.3146113714245261
Validation loss: 2.338665061655241

Epoch: 5| Step: 7
Training loss: 0.1704226765227747
Validation loss: 2.331747490330432

Epoch: 5| Step: 8
Training loss: 0.21348326551239397
Validation loss: 2.2941363422353147

Epoch: 5| Step: 9
Training loss: 0.2655722902396196
Validation loss: 2.337465374900556

Epoch: 5| Step: 10
Training loss: 0.13679987680266853
Validation loss: 2.3546098870309558

Epoch: 488| Step: 0
Training loss: 0.15956918186081342
Validation loss: 2.3761928954122893

Epoch: 5| Step: 1
Training loss: 0.3392397347016709
Validation loss: 2.4291681824699483

Epoch: 5| Step: 2
Training loss: 0.34038179928533957
Validation loss: 2.3592991807568096

Epoch: 5| Step: 3
Training loss: 0.3107642246874387
Validation loss: 2.3324654671099934

Epoch: 5| Step: 4
Training loss: 0.20405953262005916
Validation loss: 2.3281668630149173

Epoch: 5| Step: 5
Training loss: 0.2144546540002566
Validation loss: 2.308417563298983

Epoch: 5| Step: 6
Training loss: 0.2724687855455034
Validation loss: 2.298073287572539

Epoch: 5| Step: 7
Training loss: 0.21490149155541138
Validation loss: 2.2872438800804367

Epoch: 5| Step: 8
Training loss: 0.29404468060783506
Validation loss: 2.30811438164191

Epoch: 5| Step: 9
Training loss: 0.3776721914996385
Validation loss: 2.3634873779895686

Epoch: 5| Step: 10
Training loss: 0.23174011994929314
Validation loss: 2.3625357121502266

Epoch: 489| Step: 0
Training loss: 0.33558387774364973
Validation loss: 2.360178409646494

Epoch: 5| Step: 1
Training loss: 0.2180201924371268
Validation loss: 2.3638913346060115

Epoch: 5| Step: 2
Training loss: 0.21645340904867624
Validation loss: 2.34666945773436

Epoch: 5| Step: 3
Training loss: 0.26806514162970857
Validation loss: 2.3201273608158846

Epoch: 5| Step: 4
Training loss: 0.1661491137861351
Validation loss: 2.3443578422737077

Epoch: 5| Step: 5
Training loss: 0.23600785172865688
Validation loss: 2.329508315752727

Epoch: 5| Step: 6
Training loss: 0.32439629163304035
Validation loss: 2.300485267224844

Epoch: 5| Step: 7
Training loss: 0.34337647691651385
Validation loss: 2.352961179760898

Epoch: 5| Step: 8
Training loss: 0.263845796092123
Validation loss: 2.32210088324029

Epoch: 5| Step: 9
Training loss: 0.215498844504301
Validation loss: 2.3659861526355184

Epoch: 5| Step: 10
Training loss: 0.27248445361525786
Validation loss: 2.352724127386132

Epoch: 490| Step: 0
Training loss: 0.3001588723595848
Validation loss: 2.365780250217963

Epoch: 5| Step: 1
Training loss: 0.21199282048434734
Validation loss: 2.32639369222306

Epoch: 5| Step: 2
Training loss: 0.16316612351028892
Validation loss: 2.306544540960463

Epoch: 5| Step: 3
Training loss: 0.19671049473403351
Validation loss: 2.3242974309097684

Epoch: 5| Step: 4
Training loss: 0.26895965560087703
Validation loss: 2.3196618024123032

Epoch: 5| Step: 5
Training loss: 0.28899922838322545
Validation loss: 2.341018073374171

Epoch: 5| Step: 6
Training loss: 0.3102895042066102
Validation loss: 2.3339219544800702

Epoch: 5| Step: 7
Training loss: 0.35211458302622856
Validation loss: 2.36342393659129

Epoch: 5| Step: 8
Training loss: 0.14245256355930666
Validation loss: 2.347550813939938

Epoch: 5| Step: 9
Training loss: 0.2917086395080802
Validation loss: 2.3921386572303014

Epoch: 5| Step: 10
Training loss: 0.23014389192664703
Validation loss: 2.3736491606542676

Epoch: 491| Step: 0
Training loss: 0.1345834814197308
Validation loss: 2.3334795544188114

Epoch: 5| Step: 1
Training loss: 0.3717113976475027
Validation loss: 2.332464470215254

Epoch: 5| Step: 2
Training loss: 0.17020641268818096
Validation loss: 2.3438683209923483

Epoch: 5| Step: 3
Training loss: 0.208789556376031
Validation loss: 2.315973158610672

Epoch: 5| Step: 4
Training loss: 0.20354654512900636
Validation loss: 2.3469737556241843

Epoch: 5| Step: 5
Training loss: 0.16484699698048086
Validation loss: 2.3020494727972025

Epoch: 5| Step: 6
Training loss: 0.24222308328163314
Validation loss: 2.2940650679964865

Epoch: 5| Step: 7
Training loss: 0.3295686842166166
Validation loss: 2.3154293199100175

Epoch: 5| Step: 8
Training loss: 0.30535674566188914
Validation loss: 2.3483020715284675

Epoch: 5| Step: 9
Training loss: 0.24133052255434265
Validation loss: 2.3614354222333906

Epoch: 5| Step: 10
Training loss: 0.2802771591311599
Validation loss: 2.3537161074044843

Epoch: 492| Step: 0
Training loss: 0.25026929775414636
Validation loss: 2.3698428421057116

Epoch: 5| Step: 1
Training loss: 0.24583786573650016
Validation loss: 2.394437942302225

Epoch: 5| Step: 2
Training loss: 0.22959589948176296
Validation loss: 2.377983371849353

Epoch: 5| Step: 3
Training loss: 0.2652676927991841
Validation loss: 2.338300339007131

Epoch: 5| Step: 4
Training loss: 0.25803436500745275
Validation loss: 2.312614336100105

Epoch: 5| Step: 5
Training loss: 0.23714864176309555
Validation loss: 2.2656782433261715

Epoch: 5| Step: 6
Training loss: 0.3279251557264797
Validation loss: 2.296836136692913

Epoch: 5| Step: 7
Training loss: 0.16383897222464427
Validation loss: 2.2831131887677936

Epoch: 5| Step: 8
Training loss: 0.3529342697513184
Validation loss: 2.315459043579041

Epoch: 5| Step: 9
Training loss: 0.17073148474381286
Validation loss: 2.344176824391882

Epoch: 5| Step: 10
Training loss: 0.21737874619347247
Validation loss: 2.3505043104805976

Epoch: 493| Step: 0
Training loss: 0.27017622638313565
Validation loss: 2.3656246029736487

Epoch: 5| Step: 1
Training loss: 0.22706300435953908
Validation loss: 2.3565962814788115

Epoch: 5| Step: 2
Training loss: 0.2470018269306256
Validation loss: 2.336122754667606

Epoch: 5| Step: 3
Training loss: 0.29305117401329817
Validation loss: 2.330822456891144

Epoch: 5| Step: 4
Training loss: 0.29770550508047766
Validation loss: 2.354038730172004

Epoch: 5| Step: 5
Training loss: 0.2631349111624914
Validation loss: 2.372961473398907

Epoch: 5| Step: 6
Training loss: 0.1379617723620838
Validation loss: 2.382857584682289

Epoch: 5| Step: 7
Training loss: 0.18659809875148328
Validation loss: 2.352483325240205

Epoch: 5| Step: 8
Training loss: 0.2810622489288478
Validation loss: 2.387541115137317

Epoch: 5| Step: 9
Training loss: 0.3123896284696633
Validation loss: 2.3667495026131053

Epoch: 5| Step: 10
Training loss: 0.21904619633766564
Validation loss: 2.3382115138672575

Epoch: 494| Step: 0
Training loss: 0.28768268099090005
Validation loss: 2.350018925526238

Epoch: 5| Step: 1
Training loss: 0.2653080507855687
Validation loss: 2.323244586454312

Epoch: 5| Step: 2
Training loss: 0.18939974121216555
Validation loss: 2.360551383959594

Epoch: 5| Step: 3
Training loss: 0.27709856075138867
Validation loss: 2.3663527914550118

Epoch: 5| Step: 4
Training loss: 0.21447060866386342
Validation loss: 2.363825468195213

Epoch: 5| Step: 5
Training loss: 0.2481866277651997
Validation loss: 2.374583668208636

Epoch: 5| Step: 6
Training loss: 0.28098641070583213
Validation loss: 2.3647514660420916

Epoch: 5| Step: 7
Training loss: 0.19797112108961878
Validation loss: 2.375690657704355

Epoch: 5| Step: 8
Training loss: 0.35278379446857877
Validation loss: 2.361703687410061

Epoch: 5| Step: 9
Training loss: 0.30239945620527015
Validation loss: 2.3687012376083705

Epoch: 5| Step: 10
Training loss: 0.202051922890345
Validation loss: 2.386494635630205

Epoch: 495| Step: 0
Training loss: 0.22062087425286261
Validation loss: 2.3649489124820007

Epoch: 5| Step: 1
Training loss: 0.2446841940772201
Validation loss: 2.330887877234353

Epoch: 5| Step: 2
Training loss: 0.22823379123801382
Validation loss: 2.320158403818616

Epoch: 5| Step: 3
Training loss: 0.1277796542557106
Validation loss: 2.3306711306656043

Epoch: 5| Step: 4
Training loss: 0.26571757442461513
Validation loss: 2.26073161536238

Epoch: 5| Step: 5
Training loss: 0.31574548791559504
Validation loss: 2.2809488690837427

Epoch: 5| Step: 6
Training loss: 0.1851031770574177
Validation loss: 2.291449099268946

Epoch: 5| Step: 7
Training loss: 0.2540479997952182
Validation loss: 2.305281237636526

Epoch: 5| Step: 8
Training loss: 0.3068503130599301
Validation loss: 2.3311096361169175

Epoch: 5| Step: 9
Training loss: 0.3436762448861398
Validation loss: 2.370259856274075

Epoch: 5| Step: 10
Training loss: 0.32950120652387443
Validation loss: 2.3579250705711017

Epoch: 496| Step: 0
Training loss: 0.13490319486608854
Validation loss: 2.3378949542204306

Epoch: 5| Step: 1
Training loss: 0.30454726537689525
Validation loss: 2.3102001126609513

Epoch: 5| Step: 2
Training loss: 0.30527744888530534
Validation loss: 2.2823328124944244

Epoch: 5| Step: 3
Training loss: 0.36935654637670357
Validation loss: 2.3034385438005414

Epoch: 5| Step: 4
Training loss: 0.2700657589403922
Validation loss: 2.3082210315618434

Epoch: 5| Step: 5
Training loss: 0.17462399270061382
Validation loss: 2.3253175576606173

Epoch: 5| Step: 6
Training loss: 0.3398999025278774
Validation loss: 2.3533578198800402

Epoch: 5| Step: 7
Training loss: 0.20988836586749582
Validation loss: 2.3959122661269805

Epoch: 5| Step: 8
Training loss: 0.1938961650583505
Validation loss: 2.3758174189027947

Epoch: 5| Step: 9
Training loss: 0.24106731076987462
Validation loss: 2.369525220934363

Epoch: 5| Step: 10
Training loss: 0.19543763920163285
Validation loss: 2.3653994491688586

Epoch: 497| Step: 0
Training loss: 0.19007136549652673
Validation loss: 2.34296177342399

Epoch: 5| Step: 1
Training loss: 0.2951330477317282
Validation loss: 2.3627390667468586

Epoch: 5| Step: 2
Training loss: 0.15921940337319376
Validation loss: 2.340113479231539

Epoch: 5| Step: 3
Training loss: 0.3039213230739346
Validation loss: 2.3352402514063

Epoch: 5| Step: 4
Training loss: 0.18475270216027814
Validation loss: 2.3414507990802615

Epoch: 5| Step: 5
Training loss: 0.21188731398287083
Validation loss: 2.3156870946648414

Epoch: 5| Step: 6
Training loss: 0.39695189774820355
Validation loss: 2.3584657473691037

Epoch: 5| Step: 7
Training loss: 0.27255078000083194
Validation loss: 2.3963376435135366

Epoch: 5| Step: 8
Training loss: 0.17983718525349973
Validation loss: 2.357230678022043

Epoch: 5| Step: 9
Training loss: 0.2600838139359559
Validation loss: 2.3731835267250028

Epoch: 5| Step: 10
Training loss: 0.14518266230195181
Validation loss: 2.3810941727486536

Epoch: 498| Step: 0
Training loss: 0.27480998952559155
Validation loss: 2.3440105760987344

Epoch: 5| Step: 1
Training loss: 0.21845040923080478
Validation loss: 2.3609286715747464

Epoch: 5| Step: 2
Training loss: 0.18564480656618976
Validation loss: 2.3173747229194754

Epoch: 5| Step: 3
Training loss: 0.14560438957812244
Validation loss: 2.2967046356807237

Epoch: 5| Step: 4
Training loss: 0.31600739806680733
Validation loss: 2.3581934274259235

Epoch: 5| Step: 5
Training loss: 0.12113249835601293
Validation loss: 2.371560743890286

Epoch: 5| Step: 6
Training loss: 0.2713185771489125
Validation loss: 2.4290489980340904

Epoch: 5| Step: 7
Training loss: 0.3594179542412895
Validation loss: 2.4243683893066406

Epoch: 5| Step: 8
Training loss: 0.22114587782615133
Validation loss: 2.421392690616064

Epoch: 5| Step: 9
Training loss: 0.2929182263360389
Validation loss: 2.415052038629217

Epoch: 5| Step: 10
Training loss: 0.1626260864330011
Validation loss: 2.4094119818556536

Epoch: 499| Step: 0
Training loss: 0.2389273872530443
Validation loss: 2.390066710741719

Epoch: 5| Step: 1
Training loss: 0.15568249879259835
Validation loss: 2.379412029253002

Epoch: 5| Step: 2
Training loss: 0.22791443506510556
Validation loss: 2.3319473953713907

Epoch: 5| Step: 3
Training loss: 0.3293191886392007
Validation loss: 2.321566636713733

Epoch: 5| Step: 4
Training loss: 0.20493365148867032
Validation loss: 2.3671131104069167

Epoch: 5| Step: 5
Training loss: 0.23493056414119268
Validation loss: 2.373710724946357

Epoch: 5| Step: 6
Training loss: 0.24696518994950847
Validation loss: 2.379035462196018

Epoch: 5| Step: 7
Training loss: 0.3386486239080211
Validation loss: 2.394064480521138

Epoch: 5| Step: 8
Training loss: 0.2759129596049481
Validation loss: 2.3404646327097898

Epoch: 5| Step: 9
Training loss: 0.20514958362832283
Validation loss: 2.3424790040531

Epoch: 5| Step: 10
Training loss: 0.2750733353626584
Validation loss: 2.3068990306421813

Epoch: 500| Step: 0
Training loss: 0.19911567040766243
Validation loss: 2.319946983961842

Epoch: 5| Step: 1
Training loss: 0.3038423260140765
Validation loss: 2.322160010919146

Epoch: 5| Step: 2
Training loss: 0.21525516998028046
Validation loss: 2.3398147951818564

Epoch: 5| Step: 3
Training loss: 0.1363401757409403
Validation loss: 2.3292421379309087

Epoch: 5| Step: 4
Training loss: 0.12360507886039272
Validation loss: 2.377762019061711

Epoch: 5| Step: 5
Training loss: 0.2208342795456702
Validation loss: 2.381921054280342

Epoch: 5| Step: 6
Training loss: 0.1607826821547952
Validation loss: 2.3831502942958784

Epoch: 5| Step: 7
Training loss: 0.311985510261164
Validation loss: 2.4053886394346105

Epoch: 5| Step: 8
Training loss: 0.2335288748710338
Validation loss: 2.3828116575791327

Epoch: 5| Step: 9
Training loss: 0.4617790202195204
Validation loss: 2.354399154977647

Epoch: 5| Step: 10
Training loss: 0.2253607662395758
Validation loss: 2.3572750143510697

Epoch: 501| Step: 0
Training loss: 0.14262121672882422
Validation loss: 2.3114819102297095

Epoch: 5| Step: 1
Training loss: 0.26596427735601963
Validation loss: 2.332468944697567

Epoch: 5| Step: 2
Training loss: 0.3377190523644819
Validation loss: 2.329673871270998

Epoch: 5| Step: 3
Training loss: 0.1807288182683073
Validation loss: 2.3396507209721005

Epoch: 5| Step: 4
Training loss: 0.3612820363936565
Validation loss: 2.3078231678974275

Epoch: 5| Step: 5
Training loss: 0.21289512209560846
Validation loss: 2.3604398162398526

Epoch: 5| Step: 6
Training loss: 0.1505047810771724
Validation loss: 2.353219796812032

Epoch: 5| Step: 7
Training loss: 0.2073714681753449
Validation loss: 2.362102880619752

Epoch: 5| Step: 8
Training loss: 0.2658474075220035
Validation loss: 2.3539384563785255

Epoch: 5| Step: 9
Training loss: 0.2496493234441106
Validation loss: 2.379325978522392

Epoch: 5| Step: 10
Training loss: 0.3202074855693117
Validation loss: 2.368193073947081

Epoch: 502| Step: 0
Training loss: 0.287822408888701
Validation loss: 2.378275769425548

Epoch: 5| Step: 1
Training loss: 0.14650735039140508
Validation loss: 2.363190881744969

Epoch: 5| Step: 2
Training loss: 0.31575492649131337
Validation loss: 2.3573738058784346

Epoch: 5| Step: 3
Training loss: 0.24992449186385413
Validation loss: 2.370214845631996

Epoch: 5| Step: 4
Training loss: 0.15492714948423422
Validation loss: 2.3203859825482276

Epoch: 5| Step: 5
Training loss: 0.14057636082097585
Validation loss: 2.386577834254199

Epoch: 5| Step: 6
Training loss: 0.3396871798039167
Validation loss: 2.3534461060386374

Epoch: 5| Step: 7
Training loss: 0.2516688139983855
Validation loss: 2.3426069353085297

Epoch: 5| Step: 8
Training loss: 0.3485855155940048
Validation loss: 2.383675703307717

Epoch: 5| Step: 9
Training loss: 0.17830765669870616
Validation loss: 2.35952949303338

Epoch: 5| Step: 10
Training loss: 0.171437106645573
Validation loss: 2.3607892157425803

Epoch: 503| Step: 0
Training loss: 0.2948269596585274
Validation loss: 2.3170384153114503

Epoch: 5| Step: 1
Training loss: 0.26128626432558694
Validation loss: 2.350928191629748

Epoch: 5| Step: 2
Training loss: 0.31350762519354575
Validation loss: 2.328627331829014

Epoch: 5| Step: 3
Training loss: 0.21728360464849364
Validation loss: 2.3627713960526453

Epoch: 5| Step: 4
Training loss: 0.16143430190032926
Validation loss: 2.336727170051046

Epoch: 5| Step: 5
Training loss: 0.30387536654416897
Validation loss: 2.3087328452894567

Epoch: 5| Step: 6
Training loss: 0.2164181158620497
Validation loss: 2.3457316639655517

Epoch: 5| Step: 7
Training loss: 0.1979893918856263
Validation loss: 2.354685443544911

Epoch: 5| Step: 8
Training loss: 0.292765941358494
Validation loss: 2.341530213686346

Epoch: 5| Step: 9
Training loss: 0.18700502547992803
Validation loss: 2.3731867502002943

Epoch: 5| Step: 10
Training loss: 0.14832592208859557
Validation loss: 2.386731047655943

Epoch: 504| Step: 0
Training loss: 0.33322488863529093
Validation loss: 2.372778481226226

Epoch: 5| Step: 1
Training loss: 0.3024174415620148
Validation loss: 2.3461087887639342

Epoch: 5| Step: 2
Training loss: 0.20639567613048604
Validation loss: 2.3074599664644984

Epoch: 5| Step: 3
Training loss: 0.15410663852623335
Validation loss: 2.2847141087397507

Epoch: 5| Step: 4
Training loss: 0.11115675418584982
Validation loss: 2.279855081129665

Epoch: 5| Step: 5
Training loss: 0.36633367897488295
Validation loss: 2.2588585858212653

Epoch: 5| Step: 6
Training loss: 0.2988105718905125
Validation loss: 2.2863418430202973

Epoch: 5| Step: 7
Training loss: 0.13964823742832178
Validation loss: 2.3196097639405666

Epoch: 5| Step: 8
Training loss: 0.19738224095137796
Validation loss: 2.3472243188040154

Epoch: 5| Step: 9
Training loss: 0.21873742305839933
Validation loss: 2.385060379181742

Epoch: 5| Step: 10
Training loss: 0.25968619257922604
Validation loss: 2.4112694502714

Epoch: 505| Step: 0
Training loss: 0.28614695126750594
Validation loss: 2.4068789736803398

Epoch: 5| Step: 1
Training loss: 0.1601815378182408
Validation loss: 2.420065894762436

Epoch: 5| Step: 2
Training loss: 0.44359686452343966
Validation loss: 2.36023026402207

Epoch: 5| Step: 3
Training loss: 0.2579091064477981
Validation loss: 2.3095804368572708

Epoch: 5| Step: 4
Training loss: 0.2441124632805523
Validation loss: 2.264706233475716

Epoch: 5| Step: 5
Training loss: 0.29923620596383227
Validation loss: 2.294708364063381

Epoch: 5| Step: 6
Training loss: 0.21783236916494553
Validation loss: 2.30375944973794

Epoch: 5| Step: 7
Training loss: 0.1746441407550732
Validation loss: 2.3028267149363155

Epoch: 5| Step: 8
Training loss: 0.3053822787694286
Validation loss: 2.3500827064351513

Epoch: 5| Step: 9
Training loss: 0.18882083580458797
Validation loss: 2.379597668993767

Epoch: 5| Step: 10
Training loss: 0.22923640342450957
Validation loss: 2.3771777053872127

Epoch: 506| Step: 0
Training loss: 0.35799462127108006
Validation loss: 2.419064359933025

Epoch: 5| Step: 1
Training loss: 0.18537244126450386
Validation loss: 2.380964712112477

Epoch: 5| Step: 2
Training loss: 0.19775265351828808
Validation loss: 2.2985118446576975

Epoch: 5| Step: 3
Training loss: 0.19010877712529156
Validation loss: 2.2457210011403324

Epoch: 5| Step: 4
Training loss: 0.2953006005286554
Validation loss: 2.2615813246271093

Epoch: 5| Step: 5
Training loss: 0.23222892028535666
Validation loss: 2.2957978392152123

Epoch: 5| Step: 6
Training loss: 0.3233019839755126
Validation loss: 2.3232176549050605

Epoch: 5| Step: 7
Training loss: 0.24644226040887351
Validation loss: 2.352954883312328

Epoch: 5| Step: 8
Training loss: 0.3723073289533565
Validation loss: 2.3632434320911364

Epoch: 5| Step: 9
Training loss: 0.2923782755997292
Validation loss: 2.3723964701742255

Epoch: 5| Step: 10
Training loss: 0.2684460506920315
Validation loss: 2.3694557789395914

Epoch: 507| Step: 0
Training loss: 0.14161765566172027
Validation loss: 2.3450052336010323

Epoch: 5| Step: 1
Training loss: 0.36287434667698637
Validation loss: 2.3158888111026505

Epoch: 5| Step: 2
Training loss: 0.28226585510649965
Validation loss: 2.285105873143708

Epoch: 5| Step: 3
Training loss: 0.2305697203757078
Validation loss: 2.2537194731588133

Epoch: 5| Step: 4
Training loss: 0.2351696292581656
Validation loss: 2.2499990155617806

Epoch: 5| Step: 5
Training loss: 0.29570158147975956
Validation loss: 2.30464080157

Epoch: 5| Step: 6
Training loss: 0.3525079306596383
Validation loss: 2.3119904911060245

Epoch: 5| Step: 7
Training loss: 0.2361630343903468
Validation loss: 2.34509614084745

Epoch: 5| Step: 8
Training loss: 0.28721296297165466
Validation loss: 2.399377993681197

Epoch: 5| Step: 9
Training loss: 0.25181821419639305
Validation loss: 2.4069033757004963

Epoch: 5| Step: 10
Training loss: 0.23221318308256522
Validation loss: 2.394972737507583

Epoch: 508| Step: 0
Training loss: 0.3056133947333829
Validation loss: 2.3697406477080674

Epoch: 5| Step: 1
Training loss: 0.3435138953596777
Validation loss: 2.3740964961730153

Epoch: 5| Step: 2
Training loss: 0.19933609218094298
Validation loss: 2.3443717673248714

Epoch: 5| Step: 3
Training loss: 0.18768942721505136
Validation loss: 2.3686166058035734

Epoch: 5| Step: 4
Training loss: 0.37448281147986545
Validation loss: 2.374926399705359

Epoch: 5| Step: 5
Training loss: 0.23126298829281716
Validation loss: 2.3812040018837806

Epoch: 5| Step: 6
Training loss: 0.23353082900262673
Validation loss: 2.326099870221925

Epoch: 5| Step: 7
Training loss: 0.22709555235777815
Validation loss: 2.3677478967490546

Epoch: 5| Step: 8
Training loss: 0.21749024731047345
Validation loss: 2.3385492827110133

Epoch: 5| Step: 9
Training loss: 0.2069799431618452
Validation loss: 2.3529476313167685

Epoch: 5| Step: 10
Training loss: 0.18009606849161647
Validation loss: 2.326225245089376

Epoch: 509| Step: 0
Training loss: 0.32411109331914345
Validation loss: 2.3039825501483304

Epoch: 5| Step: 1
Training loss: 0.24536509344903148
Validation loss: 2.340853361784867

Epoch: 5| Step: 2
Training loss: 0.22599253816439271
Validation loss: 2.3250119933525704

Epoch: 5| Step: 3
Training loss: 0.24060365161074865
Validation loss: 2.327927991194619

Epoch: 5| Step: 4
Training loss: 0.29704474314664614
Validation loss: 2.316075869187845

Epoch: 5| Step: 5
Training loss: 0.23798677352408895
Validation loss: 2.3157792756925013

Epoch: 5| Step: 6
Training loss: 0.20300372795090252
Validation loss: 2.346647703493502

Epoch: 5| Step: 7
Training loss: 0.16001871064798762
Validation loss: 2.385745402603314

Epoch: 5| Step: 8
Training loss: 0.2781349769688721
Validation loss: 2.3274490229588007

Epoch: 5| Step: 9
Training loss: 0.16185093006662857
Validation loss: 2.3445388527401607

Epoch: 5| Step: 10
Training loss: 0.3690052894481962
Validation loss: 2.345791221667167

Epoch: 510| Step: 0
Training loss: 0.2436146066678986
Validation loss: 2.3805760736589887

Epoch: 5| Step: 1
Training loss: 0.3274782255083044
Validation loss: 2.3384380246809715

Epoch: 5| Step: 2
Training loss: 0.2166570177971135
Validation loss: 2.334453077499051

Epoch: 5| Step: 3
Training loss: 0.3132702870722
Validation loss: 2.3370256618378233

Epoch: 5| Step: 4
Training loss: 0.14298396290163323
Validation loss: 2.3422188770710735

Epoch: 5| Step: 5
Training loss: 0.28024931215666343
Validation loss: 2.3521819537008737

Epoch: 5| Step: 6
Training loss: 0.23023908292515258
Validation loss: 2.3620192855211988

Epoch: 5| Step: 7
Training loss: 0.30504187736135735
Validation loss: 2.3400850382693497

Epoch: 5| Step: 8
Training loss: 0.15526464425385977
Validation loss: 2.356570636189605

Epoch: 5| Step: 9
Training loss: 0.2597017998551113
Validation loss: 2.3487242309687937

Epoch: 5| Step: 10
Training loss: 0.17238071126584326
Validation loss: 2.317171201906605

Epoch: 511| Step: 0
Training loss: 0.2937229620887918
Validation loss: 2.3332842151098263

Epoch: 5| Step: 1
Training loss: 0.35158041802415474
Validation loss: 2.3182679993279565

Epoch: 5| Step: 2
Training loss: 0.17546841015871995
Validation loss: 2.3662789211158315

Epoch: 5| Step: 3
Training loss: 0.24428836167216775
Validation loss: 2.390457847735955

Epoch: 5| Step: 4
Training loss: 0.2831958769824461
Validation loss: 2.361008782876783

Epoch: 5| Step: 5
Training loss: 0.18900608135208422
Validation loss: 2.4176485219124273

Epoch: 5| Step: 6
Training loss: 0.18875183006687837
Validation loss: 2.432230594204941

Epoch: 5| Step: 7
Training loss: 0.20187647119228128
Validation loss: 2.3929763159227977

Epoch: 5| Step: 8
Training loss: 0.2820068084608462
Validation loss: 2.329940427238373

Epoch: 5| Step: 9
Training loss: 0.23291365103029027
Validation loss: 2.2944932668027205

Epoch: 5| Step: 10
Training loss: 0.21771170934465767
Validation loss: 2.297547810596313

Epoch: 512| Step: 0
Training loss: 0.362318033553517
Validation loss: 2.261860461560295

Epoch: 5| Step: 1
Training loss: 0.20605825809802078
Validation loss: 2.2808714622953374

Epoch: 5| Step: 2
Training loss: 0.2579453732800426
Validation loss: 2.2883914270561276

Epoch: 5| Step: 3
Training loss: 0.2570297902074481
Validation loss: 2.330074677951609

Epoch: 5| Step: 4
Training loss: 0.21110770634696224
Validation loss: 2.380314995537185

Epoch: 5| Step: 5
Training loss: 0.2719195466433158
Validation loss: 2.423726454193237

Epoch: 5| Step: 6
Training loss: 0.2219446002567831
Validation loss: 2.4245153012288174

Epoch: 5| Step: 7
Training loss: 0.15489980741489498
Validation loss: 2.4261842326584704

Epoch: 5| Step: 8
Training loss: 0.2178880364341888
Validation loss: 2.365617717098229

Epoch: 5| Step: 9
Training loss: 0.1559882057003862
Validation loss: 2.3604640445219713

Epoch: 5| Step: 10
Training loss: 0.38839021378042005
Validation loss: 2.3294185786685637

Epoch: 513| Step: 0
Training loss: 0.17269115763983325
Validation loss: 2.3226009091566575

Epoch: 5| Step: 1
Training loss: 0.23840067950386298
Validation loss: 2.332554261574046

Epoch: 5| Step: 2
Training loss: 0.23216971173951523
Validation loss: 2.35232437356906

Epoch: 5| Step: 3
Training loss: 0.20852035631434024
Validation loss: 2.3742850257778025

Epoch: 5| Step: 4
Training loss: 0.35359414424697266
Validation loss: 2.3495262104750854

Epoch: 5| Step: 5
Training loss: 0.1729629664070114
Validation loss: 2.385487062975882

Epoch: 5| Step: 6
Training loss: 0.2119553609238662
Validation loss: 2.4146384358503443

Epoch: 5| Step: 7
Training loss: 0.3225039092462753
Validation loss: 2.39436384150927

Epoch: 5| Step: 8
Training loss: 0.13704954727658938
Validation loss: 2.350499387160144

Epoch: 5| Step: 9
Training loss: 0.2984902210502799
Validation loss: 2.366512230833457

Epoch: 5| Step: 10
Training loss: 0.20575232717465644
Validation loss: 2.3601074472658357

Epoch: 514| Step: 0
Training loss: 0.2895537403592339
Validation loss: 2.3525601749021687

Epoch: 5| Step: 1
Training loss: 0.15671072031294467
Validation loss: 2.3421509454104186

Epoch: 5| Step: 2
Training loss: 0.24181924017048312
Validation loss: 2.368354217706129

Epoch: 5| Step: 3
Training loss: 0.19298130218515533
Validation loss: 2.370879387989875

Epoch: 5| Step: 4
Training loss: 0.31469459029452174
Validation loss: 2.3916687139766966

Epoch: 5| Step: 5
Training loss: 0.2596772696158899
Validation loss: 2.3332282414772987

Epoch: 5| Step: 6
Training loss: 0.15873575031162726
Validation loss: 2.3436827717645157

Epoch: 5| Step: 7
Training loss: 0.29635743148873583
Validation loss: 2.324274260610414

Epoch: 5| Step: 8
Training loss: 0.1561944028169328
Validation loss: 2.32646904112793

Epoch: 5| Step: 9
Training loss: 0.16968048971669658
Validation loss: 2.3230174290317147

Epoch: 5| Step: 10
Training loss: 0.26288026729772
Validation loss: 2.3332285897818523

Epoch: 515| Step: 0
Training loss: 0.2589026723555804
Validation loss: 2.345443849646454

Epoch: 5| Step: 1
Training loss: 0.24667089390730249
Validation loss: 2.339846559234866

Epoch: 5| Step: 2
Training loss: 0.15101772699605165
Validation loss: 2.371478100533142

Epoch: 5| Step: 3
Training loss: 0.32789874223355614
Validation loss: 2.3592557441655675

Epoch: 5| Step: 4
Training loss: 0.285116806960306
Validation loss: 2.3789901116477075

Epoch: 5| Step: 5
Training loss: 0.1667146495700961
Validation loss: 2.37224319226485

Epoch: 5| Step: 6
Training loss: 0.13869419724159937
Validation loss: 2.3169350757714664

Epoch: 5| Step: 7
Training loss: 0.1477262308406602
Validation loss: 2.3113228169370186

Epoch: 5| Step: 8
Training loss: 0.14199990116455105
Validation loss: 2.316635571754555

Epoch: 5| Step: 9
Training loss: 0.320644183672498
Validation loss: 2.2655378902720202

Epoch: 5| Step: 10
Training loss: 0.2976081353696136
Validation loss: 2.2714956696274946

Epoch: 516| Step: 0
Training loss: 0.1602916958901174
Validation loss: 2.3026724650688126

Epoch: 5| Step: 1
Training loss: 0.18686890689459615
Validation loss: 2.356606059120579

Epoch: 5| Step: 2
Training loss: 0.1944018592399955
Validation loss: 2.3835463839611086

Epoch: 5| Step: 3
Training loss: 0.32988428597716873
Validation loss: 2.3307212959157115

Epoch: 5| Step: 4
Training loss: 0.19916671185479656
Validation loss: 2.348591837690685

Epoch: 5| Step: 5
Training loss: 0.20714928303315272
Validation loss: 2.3581738298215744

Epoch: 5| Step: 6
Training loss: 0.1379706558450159
Validation loss: 2.3511520876310765

Epoch: 5| Step: 7
Training loss: 0.26740965447237436
Validation loss: 2.327374763787317

Epoch: 5| Step: 8
Training loss: 0.20813986119488925
Validation loss: 2.3126395753501465

Epoch: 5| Step: 9
Training loss: 0.3428494187177515
Validation loss: 2.310531693135291

Epoch: 5| Step: 10
Training loss: 0.16760904031412338
Validation loss: 2.303970119034022

Epoch: 517| Step: 0
Training loss: 0.33000310914424497
Validation loss: 2.3339754186564727

Epoch: 5| Step: 1
Training loss: 0.1376121350935593
Validation loss: 2.347826137759746

Epoch: 5| Step: 2
Training loss: 0.2803291504676756
Validation loss: 2.353125746542929

Epoch: 5| Step: 3
Training loss: 0.16400864262094358
Validation loss: 2.3717924336999547

Epoch: 5| Step: 4
Training loss: 0.20432832887865002
Validation loss: 2.356317149030439

Epoch: 5| Step: 5
Training loss: 0.15001871518763735
Validation loss: 2.343134852252687

Epoch: 5| Step: 6
Training loss: 0.18647520829848974
Validation loss: 2.3173996049961825

Epoch: 5| Step: 7
Training loss: 0.20058781363882952
Validation loss: 2.326244726128821

Epoch: 5| Step: 8
Training loss: 0.30038825283428455
Validation loss: 2.3570214909155416

Epoch: 5| Step: 9
Training loss: 0.2688700817993751
Validation loss: 2.400825169521903

Epoch: 5| Step: 10
Training loss: 0.15168292432893082
Validation loss: 2.3487282815346577

Epoch: 518| Step: 0
Training loss: 0.2195038323572928
Validation loss: 2.322197359140916

Epoch: 5| Step: 1
Training loss: 0.25823278559746526
Validation loss: 2.3276938533133693

Epoch: 5| Step: 2
Training loss: 0.23133145521576007
Validation loss: 2.3643371365682913

Epoch: 5| Step: 3
Training loss: 0.17222621644284458
Validation loss: 2.342861650895167

Epoch: 5| Step: 4
Training loss: 0.1530611678805782
Validation loss: 2.3530319213107673

Epoch: 5| Step: 5
Training loss: 0.14814565226885748
Validation loss: 2.359046144364157

Epoch: 5| Step: 6
Training loss: 0.26864322936704255
Validation loss: 2.328821012554843

Epoch: 5| Step: 7
Training loss: 0.20626331452540086
Validation loss: 2.3698000963979085

Epoch: 5| Step: 8
Training loss: 0.2903667871822092
Validation loss: 2.3597924462773547

Epoch: 5| Step: 9
Training loss: 0.2505681020405897
Validation loss: 2.3974149779062763

Epoch: 5| Step: 10
Training loss: 0.0983209589958533
Validation loss: 2.3808106845268564

Epoch: 519| Step: 0
Training loss: 0.3233282890778433
Validation loss: 2.3902016241422417

Epoch: 5| Step: 1
Training loss: 0.14500180531068518
Validation loss: 2.3365594799471183

Epoch: 5| Step: 2
Training loss: 0.19676466870247825
Validation loss: 2.359074298048979

Epoch: 5| Step: 3
Training loss: 0.1410624468625416
Validation loss: 2.3537782948924413

Epoch: 5| Step: 4
Training loss: 0.18994001373329727
Validation loss: 2.317941861602725

Epoch: 5| Step: 5
Training loss: 0.2631322637266677
Validation loss: 2.3384581801563207

Epoch: 5| Step: 6
Training loss: 0.15813780837334634
Validation loss: 2.3377218668809885

Epoch: 5| Step: 7
Training loss: 0.28012274967874506
Validation loss: 2.390649863900724

Epoch: 5| Step: 8
Training loss: 0.25394506891318436
Validation loss: 2.3595983905702256

Epoch: 5| Step: 9
Training loss: 0.2480419038289459
Validation loss: 2.3855620079902717

Epoch: 5| Step: 10
Training loss: 0.12181158112203344
Validation loss: 2.357710495316052

Epoch: 520| Step: 0
Training loss: 0.17802879554713186
Validation loss: 2.3270112262892906

Epoch: 5| Step: 1
Training loss: 0.30919493290032835
Validation loss: 2.315437978188685

Epoch: 5| Step: 2
Training loss: 0.20399381905721717
Validation loss: 2.277897032633817

Epoch: 5| Step: 3
Training loss: 0.17575393570505957
Validation loss: 2.3146242020949526

Epoch: 5| Step: 4
Training loss: 0.16700373157954904
Validation loss: 2.3387376573562855

Epoch: 5| Step: 5
Training loss: 0.18914159743804726
Validation loss: 2.3649239491055623

Epoch: 5| Step: 6
Training loss: 0.2727718834939956
Validation loss: 2.319981484245555

Epoch: 5| Step: 7
Training loss: 0.2489270341556546
Validation loss: 2.344470814984248

Epoch: 5| Step: 8
Training loss: 0.13190332738986485
Validation loss: 2.378927790074156

Epoch: 5| Step: 9
Training loss: 0.27542062690665453
Validation loss: 2.3900120218937175

Epoch: 5| Step: 10
Training loss: 0.1760126339420811
Validation loss: 2.358118780196119

Epoch: 521| Step: 0
Training loss: 0.16030819012423708
Validation loss: 2.3582428474102075

Epoch: 5| Step: 1
Training loss: 0.23121852467238904
Validation loss: 2.3732850900184794

Epoch: 5| Step: 2
Training loss: 0.33925159428881796
Validation loss: 2.3734134486988854

Epoch: 5| Step: 3
Training loss: 0.10701858069623625
Validation loss: 2.3668177512976585

Epoch: 5| Step: 4
Training loss: 0.3038814593404963
Validation loss: 2.358308847455992

Epoch: 5| Step: 5
Training loss: 0.207060496945513
Validation loss: 2.344466561328773

Epoch: 5| Step: 6
Training loss: 0.26563842122447434
Validation loss: 2.3196194537912795

Epoch: 5| Step: 7
Training loss: 0.17961083725594948
Validation loss: 2.3433544741269605

Epoch: 5| Step: 8
Training loss: 0.2236816486191264
Validation loss: 2.3249012535888243

Epoch: 5| Step: 9
Training loss: 0.22504034574699336
Validation loss: 2.360908373485701

Epoch: 5| Step: 10
Training loss: 0.1293933076620729
Validation loss: 2.429181798653059

Epoch: 522| Step: 0
Training loss: 0.19464848176365057
Validation loss: 2.3868633027976895

Epoch: 5| Step: 1
Training loss: 0.2844843460336929
Validation loss: 2.3817372833867148

Epoch: 5| Step: 2
Training loss: 0.2406857212662627
Validation loss: 2.347605146027573

Epoch: 5| Step: 3
Training loss: 0.29315892722697884
Validation loss: 2.3934132584197902

Epoch: 5| Step: 4
Training loss: 0.2034372900157495
Validation loss: 2.350463970360486

Epoch: 5| Step: 5
Training loss: 0.1693308076004491
Validation loss: 2.3554015846848047

Epoch: 5| Step: 6
Training loss: 0.13580650068462977
Validation loss: 2.3400585152624904

Epoch: 5| Step: 7
Training loss: 0.19675062012302047
Validation loss: 2.3288317423393887

Epoch: 5| Step: 8
Training loss: 0.1653316826768818
Validation loss: 2.351428823037858

Epoch: 5| Step: 9
Training loss: 0.3214217494626667
Validation loss: 2.3737801796257165

Epoch: 5| Step: 10
Training loss: 0.13963077673577642
Validation loss: 2.351713139263979

Epoch: 523| Step: 0
Training loss: 0.2882293732029697
Validation loss: 2.3710064972380516

Epoch: 5| Step: 1
Training loss: 0.3399085827076058
Validation loss: 2.3685550038103194

Epoch: 5| Step: 2
Training loss: 0.12257888519581404
Validation loss: 2.351962762084948

Epoch: 5| Step: 3
Training loss: 0.215669717505545
Validation loss: 2.3535203699047003

Epoch: 5| Step: 4
Training loss: 0.2737167703369896
Validation loss: 2.3494754401515916

Epoch: 5| Step: 5
Training loss: 0.14306194051080695
Validation loss: 2.3107354411345407

Epoch: 5| Step: 6
Training loss: 0.18573275842008843
Validation loss: 2.359105556102516

Epoch: 5| Step: 7
Training loss: 0.1579038237727497
Validation loss: 2.367318812156952

Epoch: 5| Step: 8
Training loss: 0.16316510180762656
Validation loss: 2.346925755969165

Epoch: 5| Step: 9
Training loss: 0.200725142732746
Validation loss: 2.366136843329301

Epoch: 5| Step: 10
Training loss: 0.19770653239643557
Validation loss: 2.3970748933742305

Epoch: 524| Step: 0
Training loss: 0.08222084897684881
Validation loss: 2.356476476508703

Epoch: 5| Step: 1
Training loss: 0.21574643972316998
Validation loss: 2.35509302496933

Epoch: 5| Step: 2
Training loss: 0.29072558908005103
Validation loss: 2.33221078567275

Epoch: 5| Step: 3
Training loss: 0.32812766800658594
Validation loss: 2.3663193805647134

Epoch: 5| Step: 4
Training loss: 0.20495032006534453
Validation loss: 2.366483077991064

Epoch: 5| Step: 5
Training loss: 0.20243196368795527
Validation loss: 2.3581187095310425

Epoch: 5| Step: 6
Training loss: 0.3275725846262168
Validation loss: 2.392813637053695

Epoch: 5| Step: 7
Training loss: 0.24383513602187723
Validation loss: 2.398525848744238

Epoch: 5| Step: 8
Training loss: 0.17065637611792445
Validation loss: 2.3791211656851754

Epoch: 5| Step: 9
Training loss: 0.16136041230398102
Validation loss: 2.392069382999062

Epoch: 5| Step: 10
Training loss: 0.15137012232734814
Validation loss: 2.344177107639663

Epoch: 525| Step: 0
Training loss: 0.18734035052984582
Validation loss: 2.361033470048293

Epoch: 5| Step: 1
Training loss: 0.205319308192741
Validation loss: 2.2800694578813765

Epoch: 5| Step: 2
Training loss: 0.16318349147681566
Validation loss: 2.280759549936433

Epoch: 5| Step: 3
Training loss: 0.35279412170198104
Validation loss: 2.2714774368035284

Epoch: 5| Step: 4
Training loss: 0.32631182380785945
Validation loss: 2.2960934252705347

Epoch: 5| Step: 5
Training loss: 0.2602196647634378
Validation loss: 2.3601606506499326

Epoch: 5| Step: 6
Training loss: 0.310188866829229
Validation loss: 2.4084412349159754

Epoch: 5| Step: 7
Training loss: 0.21288588282351853
Validation loss: 2.470633325673445

Epoch: 5| Step: 8
Training loss: 0.15906372409904135
Validation loss: 2.444151103161329

Epoch: 5| Step: 9
Training loss: 0.20125612328081333
Validation loss: 2.425133427597632

Epoch: 5| Step: 10
Training loss: 0.19459379523543088
Validation loss: 2.363663391496865

Epoch: 526| Step: 0
Training loss: 0.2573037763723941
Validation loss: 2.373679642482115

Epoch: 5| Step: 1
Training loss: 0.23593742610601823
Validation loss: 2.317989157494689

Epoch: 5| Step: 2
Training loss: 0.3890554557683473
Validation loss: 2.3314539032073895

Epoch: 5| Step: 3
Training loss: 0.24688704105178289
Validation loss: 2.3042793725970725

Epoch: 5| Step: 4
Training loss: 0.13027439031295404
Validation loss: 2.345934592851055

Epoch: 5| Step: 5
Training loss: 0.23523513795088508
Validation loss: 2.357283267709123

Epoch: 5| Step: 6
Training loss: 0.13532460427271306
Validation loss: 2.3538376103309306

Epoch: 5| Step: 7
Training loss: 0.2847471045396268
Validation loss: 2.3817906365069894

Epoch: 5| Step: 8
Training loss: 0.13862799232209813
Validation loss: 2.3544415131002943

Epoch: 5| Step: 9
Training loss: 0.16183355145050118
Validation loss: 2.387578442421025

Epoch: 5| Step: 10
Training loss: 0.14632812431771297
Validation loss: 2.3738226430709166

Epoch: 527| Step: 0
Training loss: 0.14839483576553592
Validation loss: 2.3467898218020538

Epoch: 5| Step: 1
Training loss: 0.19933956820952636
Validation loss: 2.3425496019622454

Epoch: 5| Step: 2
Training loss: 0.19360380425257293
Validation loss: 2.3334447648062913

Epoch: 5| Step: 3
Training loss: 0.1850775052274002
Validation loss: 2.311318715237588

Epoch: 5| Step: 4
Training loss: 0.35037522638308843
Validation loss: 2.34930299158898

Epoch: 5| Step: 5
Training loss: 0.14691111394575168
Validation loss: 2.3388068434806644

Epoch: 5| Step: 6
Training loss: 0.20930205469389632
Validation loss: 2.3715582327421467

Epoch: 5| Step: 7
Training loss: 0.20143961450293713
Validation loss: 2.3546558274484957

Epoch: 5| Step: 8
Training loss: 0.2698716212083662
Validation loss: 2.385532826806402

Epoch: 5| Step: 9
Training loss: 0.14250086951408794
Validation loss: 2.3930224748572524

Epoch: 5| Step: 10
Training loss: 0.18963595544692602
Validation loss: 2.427075516263318

Epoch: 528| Step: 0
Training loss: 0.3566198261459288
Validation loss: 2.3891414205353962

Epoch: 5| Step: 1
Training loss: 0.18852294588319318
Validation loss: 2.350723359446897

Epoch: 5| Step: 2
Training loss: 0.14245519825760464
Validation loss: 2.3596063076878355

Epoch: 5| Step: 3
Training loss: 0.1305043400402693
Validation loss: 2.3751961778705786

Epoch: 5| Step: 4
Training loss: 0.15739775749783325
Validation loss: 2.346709545182257

Epoch: 5| Step: 5
Training loss: 0.22523059353546854
Validation loss: 2.340173482820142

Epoch: 5| Step: 6
Training loss: 0.22169812163618455
Validation loss: 2.3601169301128184

Epoch: 5| Step: 7
Training loss: 0.2660023169192535
Validation loss: 2.376571350799601

Epoch: 5| Step: 8
Training loss: 0.09267246875530921
Validation loss: 2.421132274775266

Epoch: 5| Step: 9
Training loss: 0.15037470275020315
Validation loss: 2.41055187651204

Epoch: 5| Step: 10
Training loss: 0.27062532647357657
Validation loss: 2.391144137094517

Epoch: 529| Step: 0
Training loss: 0.13304626004384373
Validation loss: 2.395978693322123

Epoch: 5| Step: 1
Training loss: 0.22349861649644015
Validation loss: 2.3127457904647737

Epoch: 5| Step: 2
Training loss: 0.21344413895007047
Validation loss: 2.3439877696417315

Epoch: 5| Step: 3
Training loss: 0.1801617934837296
Validation loss: 2.302756481747655

Epoch: 5| Step: 4
Training loss: 0.20110384707529372
Validation loss: 2.3127830152593596

Epoch: 5| Step: 5
Training loss: 0.340039229899655
Validation loss: 2.339403673592713

Epoch: 5| Step: 6
Training loss: 0.2549977390572414
Validation loss: 2.3412303558663057

Epoch: 5| Step: 7
Training loss: 0.16454252907184141
Validation loss: 2.4043208468655553

Epoch: 5| Step: 8
Training loss: 0.20685334028853172
Validation loss: 2.3906483904757057

Epoch: 5| Step: 9
Training loss: 0.29961499851723544
Validation loss: 2.383261360377095

Epoch: 5| Step: 10
Training loss: 0.2414688399571305
Validation loss: 2.400487416773827

Epoch: 530| Step: 0
Training loss: 0.20076105149788467
Validation loss: 2.4012507783874706

Epoch: 5| Step: 1
Training loss: 0.19386383680944927
Validation loss: 2.3865105244915688

Epoch: 5| Step: 2
Training loss: 0.21886333016232623
Validation loss: 2.3598609928497947

Epoch: 5| Step: 3
Training loss: 0.13842655026637518
Validation loss: 2.321898962307491

Epoch: 5| Step: 4
Training loss: 0.30067306901551655
Validation loss: 2.3020710961276407

Epoch: 5| Step: 5
Training loss: 0.18225747650676705
Validation loss: 2.3097868431903703

Epoch: 5| Step: 6
Training loss: 0.20031417481470626
Validation loss: 2.306049535254617

Epoch: 5| Step: 7
Training loss: 0.14670850772877997
Validation loss: 2.330184579402399

Epoch: 5| Step: 8
Training loss: 0.26201031229876515
Validation loss: 2.386529441455145

Epoch: 5| Step: 9
Training loss: 0.3460596476818483
Validation loss: 2.3998518828435444

Epoch: 5| Step: 10
Training loss: 0.20749188407284866
Validation loss: 2.3504870624536207

Epoch: 531| Step: 0
Training loss: 0.21896608783251792
Validation loss: 2.346201989395649

Epoch: 5| Step: 1
Training loss: 0.13359859580459157
Validation loss: 2.3724477252197507

Epoch: 5| Step: 2
Training loss: 0.2676768573236947
Validation loss: 2.3791748403902266

Epoch: 5| Step: 3
Training loss: 0.1910104161899942
Validation loss: 2.338575230865126

Epoch: 5| Step: 4
Training loss: 0.24520084579663773
Validation loss: 2.289341678105053

Epoch: 5| Step: 5
Training loss: 0.2391144459205476
Validation loss: 2.2722808169864868

Epoch: 5| Step: 6
Training loss: 0.2580895669045961
Validation loss: 2.2906634930827634

Epoch: 5| Step: 7
Training loss: 0.15736399147239882
Validation loss: 2.2852440366245528

Epoch: 5| Step: 8
Training loss: 0.30026148189059065
Validation loss: 2.3212404593854457

Epoch: 5| Step: 9
Training loss: 0.23962741252816983
Validation loss: 2.3747768696672793

Epoch: 5| Step: 10
Training loss: 0.25271444109406926
Validation loss: 2.3810306271354387

Epoch: 532| Step: 0
Training loss: 0.18967320744999958
Validation loss: 2.3777526486350298

Epoch: 5| Step: 1
Training loss: 0.18585346390511104
Validation loss: 2.378639094518366

Epoch: 5| Step: 2
Training loss: 0.17981889315985264
Validation loss: 2.367825561052254

Epoch: 5| Step: 3
Training loss: 0.10825257324811985
Validation loss: 2.328259200138572

Epoch: 5| Step: 4
Training loss: 0.2784870116956519
Validation loss: 2.328030523968351

Epoch: 5| Step: 5
Training loss: 0.2245048113702426
Validation loss: 2.320254507479845

Epoch: 5| Step: 6
Training loss: 0.2911521668106374
Validation loss: 2.2948251506012274

Epoch: 5| Step: 7
Training loss: 0.20940675565826203
Validation loss: 2.324999615134107

Epoch: 5| Step: 8
Training loss: 0.3092863423056505
Validation loss: 2.377924061979309

Epoch: 5| Step: 9
Training loss: 0.27138193516806747
Validation loss: 2.3816365756845888

Epoch: 5| Step: 10
Training loss: 0.20844836436929506
Validation loss: 2.391104827840252

Epoch: 533| Step: 0
Training loss: 0.20219217278801424
Validation loss: 2.4000744999923866

Epoch: 5| Step: 1
Training loss: 0.1213149158364
Validation loss: 2.3449403142510468

Epoch: 5| Step: 2
Training loss: 0.25073377391595514
Validation loss: 2.3497074676032677

Epoch: 5| Step: 3
Training loss: 0.23021947181446623
Validation loss: 2.330367947088584

Epoch: 5| Step: 4
Training loss: 0.2687166453888075
Validation loss: 2.31041487165704

Epoch: 5| Step: 5
Training loss: 0.28906515481090583
Validation loss: 2.287306110662965

Epoch: 5| Step: 6
Training loss: 0.36308155929281455
Validation loss: 2.3330037236516414

Epoch: 5| Step: 7
Training loss: 0.19984272867855937
Validation loss: 2.371371523104985

Epoch: 5| Step: 8
Training loss: 0.1870378520823319
Validation loss: 2.4094249744578455

Epoch: 5| Step: 9
Training loss: 0.12003098084827529
Validation loss: 2.379781074023523

Epoch: 5| Step: 10
Training loss: 0.16757004569435818
Validation loss: 2.3801699252213937

Epoch: 534| Step: 0
Training loss: 0.17298769035638986
Validation loss: 2.3768776033034156

Epoch: 5| Step: 1
Training loss: 0.11631606660116828
Validation loss: 2.353846949077549

Epoch: 5| Step: 2
Training loss: 0.2218693917196985
Validation loss: 2.354043546987796

Epoch: 5| Step: 3
Training loss: 0.26396104003333415
Validation loss: 2.339448015187512

Epoch: 5| Step: 4
Training loss: 0.25883695051378364
Validation loss: 2.3263094365692423

Epoch: 5| Step: 5
Training loss: 0.17107505391362696
Validation loss: 2.350854412943908

Epoch: 5| Step: 6
Training loss: 0.25164242002124687
Validation loss: 2.3365311021529234

Epoch: 5| Step: 7
Training loss: 0.17409976886409917
Validation loss: 2.32667985456792

Epoch: 5| Step: 8
Training loss: 0.2019749601944871
Validation loss: 2.3392669773804062

Epoch: 5| Step: 9
Training loss: 0.12960026777438108
Validation loss: 2.3348373361363652

Epoch: 5| Step: 10
Training loss: 0.2407956970084047
Validation loss: 2.3201752452845628

Epoch: 535| Step: 0
Training loss: 0.22495333830127856
Validation loss: 2.326182590003023

Epoch: 5| Step: 1
Training loss: 0.14211962410750148
Validation loss: 2.3713646982416248

Epoch: 5| Step: 2
Training loss: 0.1632939342883341
Validation loss: 2.385768598069889

Epoch: 5| Step: 3
Training loss: 0.2966215909286957
Validation loss: 2.457814374749752

Epoch: 5| Step: 4
Training loss: 0.1548480558903381
Validation loss: 2.4141153866798635

Epoch: 5| Step: 5
Training loss: 0.17008254249173332
Validation loss: 2.3818216265780117

Epoch: 5| Step: 6
Training loss: 0.19734909633302003
Validation loss: 2.3022033601836913

Epoch: 5| Step: 7
Training loss: 0.205049503690658
Validation loss: 2.3436204859453995

Epoch: 5| Step: 8
Training loss: 0.2646146802029698
Validation loss: 2.3060695002302904

Epoch: 5| Step: 9
Training loss: 0.2834469239120329
Validation loss: 2.3096579054249413

Epoch: 5| Step: 10
Training loss: 0.16788052859153643
Validation loss: 2.321121838685959

Epoch: 536| Step: 0
Training loss: 0.13407885359452887
Validation loss: 2.3108659939497507

Epoch: 5| Step: 1
Training loss: 0.18841902689746876
Validation loss: 2.3470003730674396

Epoch: 5| Step: 2
Training loss: 0.1270077514498115
Validation loss: 2.3787898000420387

Epoch: 5| Step: 3
Training loss: 0.17576943463776548
Validation loss: 2.3817957852222196

Epoch: 5| Step: 4
Training loss: 0.18679483252237916
Validation loss: 2.383001760642002

Epoch: 5| Step: 5
Training loss: 0.22592852122192683
Validation loss: 2.370042011533672

Epoch: 5| Step: 6
Training loss: 0.1915881985389119
Validation loss: 2.3814206931496917

Epoch: 5| Step: 7
Training loss: 0.16723709663158848
Validation loss: 2.338445343599805

Epoch: 5| Step: 8
Training loss: 0.28935779489489216
Validation loss: 2.331701626307287

Epoch: 5| Step: 9
Training loss: 0.2845892952875826
Validation loss: 2.344846809824005

Epoch: 5| Step: 10
Training loss: 0.16315530683620763
Validation loss: 2.324927036495891

Epoch: 537| Step: 0
Training loss: 0.1335426483797637
Validation loss: 2.2950335419035013

Epoch: 5| Step: 1
Training loss: 0.2894138185940545
Validation loss: 2.315442674903798

Epoch: 5| Step: 2
Training loss: 0.25967174640617674
Validation loss: 2.2944821920841014

Epoch: 5| Step: 3
Training loss: 0.31102933533879373
Validation loss: 2.3087178452637516

Epoch: 5| Step: 4
Training loss: 0.12300480774413393
Validation loss: 2.3444778876261907

Epoch: 5| Step: 5
Training loss: 0.13505910623691772
Validation loss: 2.371849269322869

Epoch: 5| Step: 6
Training loss: 0.13297953340037677
Validation loss: 2.3829287641333474

Epoch: 5| Step: 7
Training loss: 0.18092662187268133
Validation loss: 2.4031157753672123

Epoch: 5| Step: 8
Training loss: 0.12758276396596743
Validation loss: 2.419649347510042

Epoch: 5| Step: 9
Training loss: 0.16558295134533269
Validation loss: 2.336943499191249

Epoch: 5| Step: 10
Training loss: 0.20167502655548342
Validation loss: 2.332845198058275

Epoch: 538| Step: 0
Training loss: 0.17843859406651932
Validation loss: 2.3080288411173924

Epoch: 5| Step: 1
Training loss: 0.1556741055511899
Validation loss: 2.3032953277904094

Epoch: 5| Step: 2
Training loss: 0.16848498126372566
Validation loss: 2.278885958674874

Epoch: 5| Step: 3
Training loss: 0.2241735874774539
Validation loss: 2.3193553625566006

Epoch: 5| Step: 4
Training loss: 0.11416172812940319
Validation loss: 2.3474574342446397

Epoch: 5| Step: 5
Training loss: 0.2830238564144605
Validation loss: 2.373775743054183

Epoch: 5| Step: 6
Training loss: 0.2206113337479744
Validation loss: 2.368784470274485

Epoch: 5| Step: 7
Training loss: 0.10641900883725645
Validation loss: 2.3262992042866077

Epoch: 5| Step: 8
Training loss: 0.13989140641552278
Validation loss: 2.343723104999417

Epoch: 5| Step: 9
Training loss: 0.30487351974606547
Validation loss: 2.343052676798813

Epoch: 5| Step: 10
Training loss: 0.20492070832176715
Validation loss: 2.3330593197277114

Epoch: 539| Step: 0
Training loss: 0.22448578627105512
Validation loss: 2.3300927405165486

Epoch: 5| Step: 1
Training loss: 0.17385115095928189
Validation loss: 2.2849033358441453

Epoch: 5| Step: 2
Training loss: 0.23153259949169225
Validation loss: 2.304562506354782

Epoch: 5| Step: 3
Training loss: 0.13908495293135759
Validation loss: 2.3350075620385757

Epoch: 5| Step: 4
Training loss: 0.21259260754248155
Validation loss: 2.335095865700156

Epoch: 5| Step: 5
Training loss: 0.17034435368054607
Validation loss: 2.3029031922755974

Epoch: 5| Step: 6
Training loss: 0.20251957828161748
Validation loss: 2.317367238442081

Epoch: 5| Step: 7
Training loss: 0.27032673969137644
Validation loss: 2.2923543537754116

Epoch: 5| Step: 8
Training loss: 0.1548415421271716
Validation loss: 2.301511672574913

Epoch: 5| Step: 9
Training loss: 0.25358972627335047
Validation loss: 2.291455050082708

Epoch: 5| Step: 10
Training loss: 0.10379165608127044
Validation loss: 2.3443601846275066

Epoch: 540| Step: 0
Training loss: 0.2547353705369362
Validation loss: 2.3411191256006005

Epoch: 5| Step: 1
Training loss: 0.26969365741688983
Validation loss: 2.3298267730606

Epoch: 5| Step: 2
Training loss: 0.13739116707292176
Validation loss: 2.322116625928297

Epoch: 5| Step: 3
Training loss: 0.14654928676525372
Validation loss: 2.3083541660013656

Epoch: 5| Step: 4
Training loss: 0.14534195785959528
Validation loss: 2.3124204054872606

Epoch: 5| Step: 5
Training loss: 0.12572712563035582
Validation loss: 2.3324324616441423

Epoch: 5| Step: 6
Training loss: 0.3208214740088856
Validation loss: 2.3224294261744007

Epoch: 5| Step: 7
Training loss: 0.16126686646536467
Validation loss: 2.3036240115283073

Epoch: 5| Step: 8
Training loss: 0.22500699548972652
Validation loss: 2.279013313346974

Epoch: 5| Step: 9
Training loss: 0.1511182152587386
Validation loss: 2.275782961968474

Epoch: 5| Step: 10
Training loss: 0.13741679464668335
Validation loss: 2.3040564486339736

Epoch: 541| Step: 0
Training loss: 0.22012317043456098
Validation loss: 2.307546761266406

Epoch: 5| Step: 1
Training loss: 0.2515482939979816
Validation loss: 2.309516901368468

Epoch: 5| Step: 2
Training loss: 0.21879611210498343
Validation loss: 2.3553990818866355

Epoch: 5| Step: 3
Training loss: 0.16094579536391848
Validation loss: 2.391714539066107

Epoch: 5| Step: 4
Training loss: 0.1956816903290267
Validation loss: 2.3898947630822573

Epoch: 5| Step: 5
Training loss: 0.22228139978889386
Validation loss: 2.4270552284514415

Epoch: 5| Step: 6
Training loss: 0.2436795343734467
Validation loss: 2.4005693006563367

Epoch: 5| Step: 7
Training loss: 0.14580870247215294
Validation loss: 2.3578060164871752

Epoch: 5| Step: 8
Training loss: 0.1791918386659907
Validation loss: 2.3129143558473015

Epoch: 5| Step: 9
Training loss: 0.2319988841464692
Validation loss: 2.2958364950938113

Epoch: 5| Step: 10
Training loss: 0.25782041826515045
Validation loss: 2.2849020778115587

Epoch: 542| Step: 0
Training loss: 0.20081660927854994
Validation loss: 2.275397782796627

Epoch: 5| Step: 1
Training loss: 0.21595120668038792
Validation loss: 2.300338893407592

Epoch: 5| Step: 2
Training loss: 0.28220360738464767
Validation loss: 2.300975768286823

Epoch: 5| Step: 3
Training loss: 0.2603556020985635
Validation loss: 2.339014366558262

Epoch: 5| Step: 4
Training loss: 0.13819912799556305
Validation loss: 2.3885346083616836

Epoch: 5| Step: 5
Training loss: 0.27379180569389533
Validation loss: 2.390720966838352

Epoch: 5| Step: 6
Training loss: 0.21904952115561874
Validation loss: 2.3619201727318244

Epoch: 5| Step: 7
Training loss: 0.17129879513866303
Validation loss: 2.328817637401561

Epoch: 5| Step: 8
Training loss: 0.17735894343962436
Validation loss: 2.3461094132534868

Epoch: 5| Step: 9
Training loss: 0.12280480475984051
Validation loss: 2.3454383582569958

Epoch: 5| Step: 10
Training loss: 0.11853672799667878
Validation loss: 2.3587721209433785

Epoch: 543| Step: 0
Training loss: 0.13788994770045807
Validation loss: 2.3657218061180396

Epoch: 5| Step: 1
Training loss: 0.2706304747179688
Validation loss: 2.355369805644281

Epoch: 5| Step: 2
Training loss: 0.284448306622513
Validation loss: 2.342506574355637

Epoch: 5| Step: 3
Training loss: 0.18211237855428436
Validation loss: 2.3308300647950766

Epoch: 5| Step: 4
Training loss: 0.10316722648359074
Validation loss: 2.3499075319612457

Epoch: 5| Step: 5
Training loss: 0.2663328891998315
Validation loss: 2.3205425150790804

Epoch: 5| Step: 6
Training loss: 0.1918597299016582
Validation loss: 2.3444403869624444

Epoch: 5| Step: 7
Training loss: 0.23504725049696434
Validation loss: 2.389523679221813

Epoch: 5| Step: 8
Training loss: 0.2019413702991481
Validation loss: 2.3671029689471657

Epoch: 5| Step: 9
Training loss: 0.15080376639769363
Validation loss: 2.3715484832356415

Epoch: 5| Step: 10
Training loss: 0.13877953795957762
Validation loss: 2.363552382843718

Epoch: 544| Step: 0
Training loss: 0.16838205852949478
Validation loss: 2.3503199363254996

Epoch: 5| Step: 1
Training loss: 0.12511365908751754
Validation loss: 2.349938525755323

Epoch: 5| Step: 2
Training loss: 0.16628609671444713
Validation loss: 2.3343544591999423

Epoch: 5| Step: 3
Training loss: 0.17488984212919118
Validation loss: 2.366970925644793

Epoch: 5| Step: 4
Training loss: 0.2377497733673636
Validation loss: 2.413770348485682

Epoch: 5| Step: 5
Training loss: 0.21354857100203126
Validation loss: 2.392227192519664

Epoch: 5| Step: 6
Training loss: 0.16022090072185322
Validation loss: 2.3965610962860717

Epoch: 5| Step: 7
Training loss: 0.20756760881782252
Validation loss: 2.4292161617099404

Epoch: 5| Step: 8
Training loss: 0.12214680373243213
Validation loss: 2.3950032000268013

Epoch: 5| Step: 9
Training loss: 0.2545900380697559
Validation loss: 2.3562060015426867

Epoch: 5| Step: 10
Training loss: 0.27907131663851664
Validation loss: 2.328684974370982

Epoch: 545| Step: 0
Training loss: 0.17026641051461378
Validation loss: 2.33850126197088

Epoch: 5| Step: 1
Training loss: 0.22162550209362905
Validation loss: 2.2922026772727127

Epoch: 5| Step: 2
Training loss: 0.2543384102039246
Validation loss: 2.3442380783886434

Epoch: 5| Step: 3
Training loss: 0.17564956182747712
Validation loss: 2.3496197905437604

Epoch: 5| Step: 4
Training loss: 0.2341927773680462
Validation loss: 2.3440832020164137

Epoch: 5| Step: 5
Training loss: 0.11536501494370688
Validation loss: 2.3312729423511547

Epoch: 5| Step: 6
Training loss: 0.13227942014564528
Validation loss: 2.3180792491109776

Epoch: 5| Step: 7
Training loss: 0.22755532759133976
Validation loss: 2.278774428622529

Epoch: 5| Step: 8
Training loss: 0.13512980279538778
Validation loss: 2.308565218333969

Epoch: 5| Step: 9
Training loss: 0.12813042768751626
Validation loss: 2.349047601537586

Epoch: 5| Step: 10
Training loss: 0.23296459529454544
Validation loss: 2.3548167228971675

Epoch: 546| Step: 0
Training loss: 0.22388089674676337
Validation loss: 2.360579310089826

Epoch: 5| Step: 1
Training loss: 0.15808904914819327
Validation loss: 2.3766682755851236

Epoch: 5| Step: 2
Training loss: 0.1443039033930528
Validation loss: 2.3705416695499077

Epoch: 5| Step: 3
Training loss: 0.22017579673483462
Validation loss: 2.3684344317935

Epoch: 5| Step: 4
Training loss: 0.1162462060768146
Validation loss: 2.355412009988771

Epoch: 5| Step: 5
Training loss: 0.1726216387255736
Validation loss: 2.380223196074855

Epoch: 5| Step: 6
Training loss: 0.173526931593553
Validation loss: 2.367947622662295

Epoch: 5| Step: 7
Training loss: 0.14675839543575844
Validation loss: 2.3676869385937946

Epoch: 5| Step: 8
Training loss: 0.24655189707721864
Validation loss: 2.351691742910557

Epoch: 5| Step: 9
Training loss: 0.12328701957043187
Validation loss: 2.370568398708706

Epoch: 5| Step: 10
Training loss: 0.2647813836093666
Validation loss: 2.356385197779207

Epoch: 547| Step: 0
Training loss: 0.20477527781951896
Validation loss: 2.3436352981337865

Epoch: 5| Step: 1
Training loss: 0.12452187964174943
Validation loss: 2.340002038113576

Epoch: 5| Step: 2
Training loss: 0.2740676430944944
Validation loss: 2.358559855350545

Epoch: 5| Step: 3
Training loss: 0.14039404102302577
Validation loss: 2.342843149500943

Epoch: 5| Step: 4
Training loss: 0.22146335414591065
Validation loss: 2.3402214906083856

Epoch: 5| Step: 5
Training loss: 0.2022990343033581
Validation loss: 2.319022798479531

Epoch: 5| Step: 6
Training loss: 0.29775960784788025
Validation loss: 2.292562201996857

Epoch: 5| Step: 7
Training loss: 0.09674393320622617
Validation loss: 2.373920358272399

Epoch: 5| Step: 8
Training loss: 0.15815558131215474
Validation loss: 2.3709758134483674

Epoch: 5| Step: 9
Training loss: 0.13565678963359437
Validation loss: 2.3525676967081512

Epoch: 5| Step: 10
Training loss: 0.16592484965658855
Validation loss: 2.334916062176705

Epoch: 548| Step: 0
Training loss: 0.11738409796977287
Validation loss: 2.3306547577314767

Epoch: 5| Step: 1
Training loss: 0.23973259042909678
Validation loss: 2.3271599979048174

Epoch: 5| Step: 2
Training loss: 0.1214872473349575
Validation loss: 2.3372400268331237

Epoch: 5| Step: 3
Training loss: 0.21864777969565083
Validation loss: 2.323086721371478

Epoch: 5| Step: 4
Training loss: 0.1533953124860426
Validation loss: 2.3563285630664392

Epoch: 5| Step: 5
Training loss: 0.2926653117107411
Validation loss: 2.311759330136804

Epoch: 5| Step: 6
Training loss: 0.1606538068418268
Validation loss: 2.320684855066674

Epoch: 5| Step: 7
Training loss: 0.24569977150040087
Validation loss: 2.376525112895019

Epoch: 5| Step: 8
Training loss: 0.1624181346361714
Validation loss: 2.3906427916668287

Epoch: 5| Step: 9
Training loss: 0.12301526344776259
Validation loss: 2.377720448630524

Epoch: 5| Step: 10
Training loss: 0.1644693676953075
Validation loss: 2.33182540872529

Epoch: 549| Step: 0
Training loss: 0.18355784166495379
Validation loss: 2.3384697279540054

Epoch: 5| Step: 1
Training loss: 0.14213536375619534
Validation loss: 2.3576557012773636

Epoch: 5| Step: 2
Training loss: 0.20052514236741434
Validation loss: 2.3340864149173006

Epoch: 5| Step: 3
Training loss: 0.19811528470861436
Validation loss: 2.3424902797682083

Epoch: 5| Step: 4
Training loss: 0.12433999505285043
Validation loss: 2.369022957524512

Epoch: 5| Step: 5
Training loss: 0.22150520146055755
Validation loss: 2.318404392489885

Epoch: 5| Step: 6
Training loss: 0.15100739079192077
Validation loss: 2.3680804702624867

Epoch: 5| Step: 7
Training loss: 0.17852519237164458
Validation loss: 2.3684474489398246

Epoch: 5| Step: 8
Training loss: 0.2520998446256377
Validation loss: 2.3825362808110766

Epoch: 5| Step: 9
Training loss: 0.16132802409060373
Validation loss: 2.3990686271734663

Epoch: 5| Step: 10
Training loss: 0.266442191868096
Validation loss: 2.371296787456735

Epoch: 550| Step: 0
Training loss: 0.15948068209633465
Validation loss: 2.346815723084429

Epoch: 5| Step: 1
Training loss: 0.13841918972763867
Validation loss: 2.354396629880826

Epoch: 5| Step: 2
Training loss: 0.2643589533902762
Validation loss: 2.338671872325284

Epoch: 5| Step: 3
Training loss: 0.13446979949066448
Validation loss: 2.3301743135274657

Epoch: 5| Step: 4
Training loss: 0.1597410437273902
Validation loss: 2.3527469297900176

Epoch: 5| Step: 5
Training loss: 0.18336126135565664
Validation loss: 2.3582765232857272

Epoch: 5| Step: 6
Training loss: 0.20573376799318827
Validation loss: 2.3420363244973346

Epoch: 5| Step: 7
Training loss: 0.1446476931221867
Validation loss: 2.3354179256375405

Epoch: 5| Step: 8
Training loss: 0.21410665648354127
Validation loss: 2.3593157960683575

Epoch: 5| Step: 9
Training loss: 0.1201599672942956
Validation loss: 2.361525343096336

Epoch: 5| Step: 10
Training loss: 0.1333010886611468
Validation loss: 2.3490830211389158

Epoch: 551| Step: 0
Training loss: 0.15485453329445345
Validation loss: 2.357866493468614

Epoch: 5| Step: 1
Training loss: 0.18785285530430784
Validation loss: 2.3589411141471244

Epoch: 5| Step: 2
Training loss: 0.29035300786276913
Validation loss: 2.3458136494012014

Epoch: 5| Step: 3
Training loss: 0.22825979927060847
Validation loss: 2.3447260857930576

Epoch: 5| Step: 4
Training loss: 0.13710363571674947
Validation loss: 2.3295992863022805

Epoch: 5| Step: 5
Training loss: 0.12050881161267855
Validation loss: 2.3339895001131756

Epoch: 5| Step: 6
Training loss: 0.21403428956863157
Validation loss: 2.3272479069890033

Epoch: 5| Step: 7
Training loss: 0.11878970715198255
Validation loss: 2.3601432201020676

Epoch: 5| Step: 8
Training loss: 0.1968585052846467
Validation loss: 2.331236380097675

Epoch: 5| Step: 9
Training loss: 0.2162731305193816
Validation loss: 2.352000340097704

Epoch: 5| Step: 10
Training loss: 0.18284750505463263
Validation loss: 2.392895305705383

Epoch: 552| Step: 0
Training loss: 0.14166696945209495
Validation loss: 2.3507687302097633

Epoch: 5| Step: 1
Training loss: 0.14750300685193873
Validation loss: 2.42213670558402

Epoch: 5| Step: 2
Training loss: 0.16390117592862505
Validation loss: 2.4269537868481588

Epoch: 5| Step: 3
Training loss: 0.1773422232742804
Validation loss: 2.3593059709796895

Epoch: 5| Step: 4
Training loss: 0.12126984405600111
Validation loss: 2.3780269471772164

Epoch: 5| Step: 5
Training loss: 0.20391969928745565
Validation loss: 2.374065174172866

Epoch: 5| Step: 6
Training loss: 0.1554139059701959
Validation loss: 2.3381203817049303

Epoch: 5| Step: 7
Training loss: 0.13439547111139352
Validation loss: 2.340401361934443

Epoch: 5| Step: 8
Training loss: 0.2631188845660009
Validation loss: 2.328874049485064

Epoch: 5| Step: 9
Training loss: 0.2721879747126017
Validation loss: 2.3539129983188345

Epoch: 5| Step: 10
Training loss: 0.1588534129755453
Validation loss: 2.345603945214304

Epoch: 553| Step: 0
Training loss: 0.18050629196401613
Validation loss: 2.3893210854860993

Epoch: 5| Step: 1
Training loss: 0.183044260603062
Validation loss: 2.4092962966202314

Epoch: 5| Step: 2
Training loss: 0.16968171917743938
Validation loss: 2.4301972187088845

Epoch: 5| Step: 3
Training loss: 0.2731391096071438
Validation loss: 2.36721740658279

Epoch: 5| Step: 4
Training loss: 0.3057537739396825
Validation loss: 2.373363698665663

Epoch: 5| Step: 5
Training loss: 0.20267885068870592
Validation loss: 2.3643413631492263

Epoch: 5| Step: 6
Training loss: 0.1504742154745973
Validation loss: 2.4035406202410665

Epoch: 5| Step: 7
Training loss: 0.12580134160237272
Validation loss: 2.4336792813586965

Epoch: 5| Step: 8
Training loss: 0.2419860525023202
Validation loss: 2.455246363893428

Epoch: 5| Step: 9
Training loss: 0.17210302074510186
Validation loss: 2.4459879817399584

Epoch: 5| Step: 10
Training loss: 0.1418629896756147
Validation loss: 2.4035920430958013

Epoch: 554| Step: 0
Training loss: 0.20553302267295273
Validation loss: 2.3896994684189248

Epoch: 5| Step: 1
Training loss: 0.2450239604551139
Validation loss: 2.3586217781758045

Epoch: 5| Step: 2
Training loss: 0.20589273424957838
Validation loss: 2.3366686923985918

Epoch: 5| Step: 3
Training loss: 0.2918914059637259
Validation loss: 2.356674740797752

Epoch: 5| Step: 4
Training loss: 0.1761752217095432
Validation loss: 2.349270756298683

Epoch: 5| Step: 5
Training loss: 0.13931453239905975
Validation loss: 2.358359882543443

Epoch: 5| Step: 6
Training loss: 0.29304667390202715
Validation loss: 2.3939984443514133

Epoch: 5| Step: 7
Training loss: 0.2543010869534357
Validation loss: 2.398768634710615

Epoch: 5| Step: 8
Training loss: 0.18898094956320227
Validation loss: 2.355606560758868

Epoch: 5| Step: 9
Training loss: 0.293212458652302
Validation loss: 2.3648474258827963

Epoch: 5| Step: 10
Training loss: 0.24797871922366058
Validation loss: 2.3728254014945205

Epoch: 555| Step: 0
Training loss: 0.20943996645648488
Validation loss: 2.3399499880061083

Epoch: 5| Step: 1
Training loss: 0.2467500548526931
Validation loss: 2.3174472410597127

Epoch: 5| Step: 2
Training loss: 0.25895002145897866
Validation loss: 2.3342433856264324

Epoch: 5| Step: 3
Training loss: 0.20302838081656466
Validation loss: 2.3538831938894296

Epoch: 5| Step: 4
Training loss: 0.24741993167693396
Validation loss: 2.3774276527884095

Epoch: 5| Step: 5
Training loss: 0.21920694581794933
Validation loss: 2.431491847222276

Epoch: 5| Step: 6
Training loss: 0.12860593347552662
Validation loss: 2.416582566121478

Epoch: 5| Step: 7
Training loss: 0.28716015528855493
Validation loss: 2.4412148698510716

Epoch: 5| Step: 8
Training loss: 0.2035417682747667
Validation loss: 2.417611893781895

Epoch: 5| Step: 9
Training loss: 0.18442082280181468
Validation loss: 2.363868253617731

Epoch: 5| Step: 10
Training loss: 0.18185876238002222
Validation loss: 2.3138708349007286

Epoch: 556| Step: 0
Training loss: 0.217886326700614
Validation loss: 2.325488772549816

Epoch: 5| Step: 1
Training loss: 0.19683497226339886
Validation loss: 2.309831700616992

Epoch: 5| Step: 2
Training loss: 0.2009778892984886
Validation loss: 2.3247151339126106

Epoch: 5| Step: 3
Training loss: 0.3732588799704863
Validation loss: 2.3569548174335226

Epoch: 5| Step: 4
Training loss: 0.29127355320696974
Validation loss: 2.4065071110293155

Epoch: 5| Step: 5
Training loss: 0.18904831494168334
Validation loss: 2.4753377943902874

Epoch: 5| Step: 6
Training loss: 0.21452510786050472
Validation loss: 2.4862652140014805

Epoch: 5| Step: 7
Training loss: 0.1964672001485854
Validation loss: 2.4504944137762426

Epoch: 5| Step: 8
Training loss: 0.2152060574909444
Validation loss: 2.3810250584691977

Epoch: 5| Step: 9
Training loss: 0.24336455019718634
Validation loss: 2.3562351765452907

Epoch: 5| Step: 10
Training loss: 0.22127489278599163
Validation loss: 2.3188564968968652

Epoch: 557| Step: 0
Training loss: 0.22753122013313465
Validation loss: 2.327082449336628

Epoch: 5| Step: 1
Training loss: 0.31707479936433525
Validation loss: 2.3063831919053195

Epoch: 5| Step: 2
Training loss: 0.17231578010270812
Validation loss: 2.335233666756947

Epoch: 5| Step: 3
Training loss: 0.24354953163887433
Validation loss: 2.361594153095936

Epoch: 5| Step: 4
Training loss: 0.15555547495030497
Validation loss: 2.349342692003977

Epoch: 5| Step: 5
Training loss: 0.21625366546853939
Validation loss: 2.333382356219522

Epoch: 5| Step: 6
Training loss: 0.15482182474548437
Validation loss: 2.3479482468382016

Epoch: 5| Step: 7
Training loss: 0.22335097198050666
Validation loss: 2.3703084016973333

Epoch: 5| Step: 8
Training loss: 0.1909260857849296
Validation loss: 2.327349224997787

Epoch: 5| Step: 9
Training loss: 0.197015887515377
Validation loss: 2.3156847122369655

Epoch: 5| Step: 10
Training loss: 0.225967579813921
Validation loss: 2.3340529941256656

Epoch: 558| Step: 0
Training loss: 0.24826256693122753
Validation loss: 2.3586370657005014

Epoch: 5| Step: 1
Training loss: 0.23774059901769673
Validation loss: 2.331097183600743

Epoch: 5| Step: 2
Training loss: 0.14366930324042837
Validation loss: 2.3525601923377484

Epoch: 5| Step: 3
Training loss: 0.1713491001848817
Validation loss: 2.3981991975138555

Epoch: 5| Step: 4
Training loss: 0.2829094778466905
Validation loss: 2.3744472590149726

Epoch: 5| Step: 5
Training loss: 0.1547938564033557
Validation loss: 2.3409591526095985

Epoch: 5| Step: 6
Training loss: 0.18416630968394426
Validation loss: 2.3286630950554446

Epoch: 5| Step: 7
Training loss: 0.23141535633516583
Validation loss: 2.337134426901538

Epoch: 5| Step: 8
Training loss: 0.29242653580339173
Validation loss: 2.3336890320519847

Epoch: 5| Step: 9
Training loss: 0.1645368236202685
Validation loss: 2.364353377093793

Epoch: 5| Step: 10
Training loss: 0.21831226830261324
Validation loss: 2.335343757941721

Epoch: 559| Step: 0
Training loss: 0.22298938524745254
Validation loss: 2.3560377789460913

Epoch: 5| Step: 1
Training loss: 0.2615807582266271
Validation loss: 2.3200048764300982

Epoch: 5| Step: 2
Training loss: 0.26094180406230116
Validation loss: 2.3670000421525508

Epoch: 5| Step: 3
Training loss: 0.20451794364664622
Validation loss: 2.321573141969962

Epoch: 5| Step: 4
Training loss: 0.23816255051863539
Validation loss: 2.349177685055438

Epoch: 5| Step: 5
Training loss: 0.14493562216732805
Validation loss: 2.378785290907779

Epoch: 5| Step: 6
Training loss: 0.19807028246510602
Validation loss: 2.3956408067972395

Epoch: 5| Step: 7
Training loss: 0.1849464539735306
Validation loss: 2.386827182335745

Epoch: 5| Step: 8
Training loss: 0.1833184186511241
Validation loss: 2.3976045101089203

Epoch: 5| Step: 9
Training loss: 0.17139237006018326
Validation loss: 2.423680176084698

Epoch: 5| Step: 10
Training loss: 0.31306132923683344
Validation loss: 2.469514787791426

Epoch: 560| Step: 0
Training loss: 0.1992496578699427
Validation loss: 2.459697706292523

Epoch: 5| Step: 1
Training loss: 0.2265062344500425
Validation loss: 2.385658621232712

Epoch: 5| Step: 2
Training loss: 0.28605279682497786
Validation loss: 2.3394279690575

Epoch: 5| Step: 3
Training loss: 0.1520022268810558
Validation loss: 2.3427691818569545

Epoch: 5| Step: 4
Training loss: 0.2184896111440963
Validation loss: 2.3021917034123662

Epoch: 5| Step: 5
Training loss: 0.15870678753770637
Validation loss: 2.3197285873950646

Epoch: 5| Step: 6
Training loss: 0.13303716674525673
Validation loss: 2.316469730163873

Epoch: 5| Step: 7
Training loss: 0.23940843784361818
Validation loss: 2.3825918573238694

Epoch: 5| Step: 8
Training loss: 0.2131476382009271
Validation loss: 2.3921517404348216

Epoch: 5| Step: 9
Training loss: 0.18602919881898736
Validation loss: 2.372685084144672

Epoch: 5| Step: 10
Training loss: 0.15259773527812487
Validation loss: 2.367294611795845

Epoch: 561| Step: 0
Training loss: 0.19128990529930032
Validation loss: 2.369358222606794

Epoch: 5| Step: 1
Training loss: 0.12896008523322136
Validation loss: 2.3415862954198827

Epoch: 5| Step: 2
Training loss: 0.2678849208710658
Validation loss: 2.3680874539868837

Epoch: 5| Step: 3
Training loss: 0.20216851434200073
Validation loss: 2.3651593950244534

Epoch: 5| Step: 4
Training loss: 0.14133979674307068
Validation loss: 2.3384869659521272

Epoch: 5| Step: 5
Training loss: 0.23258118819326476
Validation loss: 2.3461712904382734

Epoch: 5| Step: 6
Training loss: 0.19439583243570138
Validation loss: 2.3591595454706975

Epoch: 5| Step: 7
Training loss: 0.16462452308684186
Validation loss: 2.372975149572604

Epoch: 5| Step: 8
Training loss: 0.18868475370502882
Validation loss: 2.3801851045041365

Epoch: 5| Step: 9
Training loss: 0.21499785185173234
Validation loss: 2.38158542259255

Epoch: 5| Step: 10
Training loss: 0.1517562173884746
Validation loss: 2.3432565154522624

Epoch: 562| Step: 0
Training loss: 0.20733417086403985
Validation loss: 2.316871909881479

Epoch: 5| Step: 1
Training loss: 0.18927803010297498
Validation loss: 2.307122148585391

Epoch: 5| Step: 2
Training loss: 0.12944365234802313
Validation loss: 2.3303762561383303

Epoch: 5| Step: 3
Training loss: 0.21314073447207957
Validation loss: 2.325992079309573

Epoch: 5| Step: 4
Training loss: 0.2687973452049879
Validation loss: 2.378787341250122

Epoch: 5| Step: 5
Training loss: 0.17125484903459393
Validation loss: 2.3762949029485574

Epoch: 5| Step: 6
Training loss: 0.2039161551835718
Validation loss: 2.3818916239923476

Epoch: 5| Step: 7
Training loss: 0.20051747893132796
Validation loss: 2.426789978782096

Epoch: 5| Step: 8
Training loss: 0.21431802235728137
Validation loss: 2.3257207068148547

Epoch: 5| Step: 9
Training loss: 0.2430327646984033
Validation loss: 2.347519736202372

Epoch: 5| Step: 10
Training loss: 0.2027569425660719
Validation loss: 2.3018362203776843

Epoch: 563| Step: 0
Training loss: 0.1885706809851403
Validation loss: 2.336377164388224

Epoch: 5| Step: 1
Training loss: 0.15642090034276473
Validation loss: 2.331273084758955

Epoch: 5| Step: 2
Training loss: 0.14195718504369714
Validation loss: 2.3719146389275263

Epoch: 5| Step: 3
Training loss: 0.2669965033471888
Validation loss: 2.4233539216552313

Epoch: 5| Step: 4
Training loss: 0.15985690030160585
Validation loss: 2.382558843626333

Epoch: 5| Step: 5
Training loss: 0.21394641053379596
Validation loss: 2.3917617727776173

Epoch: 5| Step: 6
Training loss: 0.2407725207078857
Validation loss: 2.3444398845001064

Epoch: 5| Step: 7
Training loss: 0.16408834934954888
Validation loss: 2.3132900927032884

Epoch: 5| Step: 8
Training loss: 0.2081645142501479
Validation loss: 2.3424306457992228

Epoch: 5| Step: 9
Training loss: 0.2500160480355269
Validation loss: 2.3595927930531766

Epoch: 5| Step: 10
Training loss: 0.15490575358334546
Validation loss: 2.351502441973708

Epoch: 564| Step: 0
Training loss: 0.12998789644979655
Validation loss: 2.3656780052155675

Epoch: 5| Step: 1
Training loss: 0.23523155096684356
Validation loss: 2.417530513976835

Epoch: 5| Step: 2
Training loss: 0.12067429898929502
Validation loss: 2.4146306418402768

Epoch: 5| Step: 3
Training loss: 0.14575963982483875
Validation loss: 2.3755654699180924

Epoch: 5| Step: 4
Training loss: 0.19582022477640149
Validation loss: 2.4200394262785205

Epoch: 5| Step: 5
Training loss: 0.12184622223090659
Validation loss: 2.3628089546074276

Epoch: 5| Step: 6
Training loss: 0.3074070045917196
Validation loss: 2.3605007904924635

Epoch: 5| Step: 7
Training loss: 0.2078958577211068
Validation loss: 2.326020607724551

Epoch: 5| Step: 8
Training loss: 0.2508802860113671
Validation loss: 2.3328687656569307

Epoch: 5| Step: 9
Training loss: 0.18447978711216861
Validation loss: 2.289358544706216

Epoch: 5| Step: 10
Training loss: 0.17474709526398363
Validation loss: 2.331186681213761

Epoch: 565| Step: 0
Training loss: 0.13553800251529946
Validation loss: 2.377440687550167

Epoch: 5| Step: 1
Training loss: 0.23638868738152277
Validation loss: 2.3928253055520905

Epoch: 5| Step: 2
Training loss: 0.2374251181734636
Validation loss: 2.4103472510602577

Epoch: 5| Step: 3
Training loss: 0.19868252150030233
Validation loss: 2.4342525885225297

Epoch: 5| Step: 4
Training loss: 0.18815110326499768
Validation loss: 2.385460600390399

Epoch: 5| Step: 5
Training loss: 0.20186072990009424
Validation loss: 2.346505288148033

Epoch: 5| Step: 6
Training loss: 0.1760374797844193
Validation loss: 2.312599447163511

Epoch: 5| Step: 7
Training loss: 0.13320693181211132
Validation loss: 2.2923214239011207

Epoch: 5| Step: 8
Training loss: 0.29267330531389457
Validation loss: 2.3048670467116255

Epoch: 5| Step: 9
Training loss: 0.2671639515722349
Validation loss: 2.294683238171808

Epoch: 5| Step: 10
Training loss: 0.2529157833563658
Validation loss: 2.327836992225261

Epoch: 566| Step: 0
Training loss: 0.18613810456669422
Validation loss: 2.3632683345720076

Epoch: 5| Step: 1
Training loss: 0.2870582223594676
Validation loss: 2.3784357994537717

Epoch: 5| Step: 2
Training loss: 0.21254518463285943
Validation loss: 2.394003090814718

Epoch: 5| Step: 3
Training loss: 0.17784802502642064
Validation loss: 2.385025917380716

Epoch: 5| Step: 4
Training loss: 0.1743771156145096
Validation loss: 2.3951568533039147

Epoch: 5| Step: 5
Training loss: 0.21219337970694255
Validation loss: 2.3469917394715165

Epoch: 5| Step: 6
Training loss: 0.17180483100964566
Validation loss: 2.2997711965777086

Epoch: 5| Step: 7
Training loss: 0.2200243648399389
Validation loss: 2.3125630674711353

Epoch: 5| Step: 8
Training loss: 0.12318473238378695
Validation loss: 2.3214851985507945

Epoch: 5| Step: 9
Training loss: 0.1640063882421662
Validation loss: 2.32819262902768

Epoch: 5| Step: 10
Training loss: 0.12906631733095897
Validation loss: 2.3418741136570773

Epoch: 567| Step: 0
Training loss: 0.2265770841705742
Validation loss: 2.368664655653152

Epoch: 5| Step: 1
Training loss: 0.18883467535448017
Validation loss: 2.3519422694408814

Epoch: 5| Step: 2
Training loss: 0.16987347735739403
Validation loss: 2.3591561501509766

Epoch: 5| Step: 3
Training loss: 0.2114450300585828
Validation loss: 2.365787906894658

Epoch: 5| Step: 4
Training loss: 0.1783325274692878
Validation loss: 2.37374775401495

Epoch: 5| Step: 5
Training loss: 0.15620979149358225
Validation loss: 2.3593348626216946

Epoch: 5| Step: 6
Training loss: 0.22882107754759537
Validation loss: 2.3430206246801433

Epoch: 5| Step: 7
Training loss: 0.17939735912903768
Validation loss: 2.380225348037613

Epoch: 5| Step: 8
Training loss: 0.1230894726481946
Validation loss: 2.3764204749219604

Epoch: 5| Step: 9
Training loss: 0.24526905962953624
Validation loss: 2.367615199133306

Epoch: 5| Step: 10
Training loss: 0.15209848884182012
Validation loss: 2.3619217194338478

Epoch: 568| Step: 0
Training loss: 0.11724198584705417
Validation loss: 2.3642236926599844

Epoch: 5| Step: 1
Training loss: 0.19326590195687715
Validation loss: 2.3298833161321233

Epoch: 5| Step: 2
Training loss: 0.0995822757434683
Validation loss: 2.3145018396304127

Epoch: 5| Step: 3
Training loss: 0.2234898155828754
Validation loss: 2.3064418416469197

Epoch: 5| Step: 4
Training loss: 0.22169217313987694
Validation loss: 2.298403048248578

Epoch: 5| Step: 5
Training loss: 0.2189982061954959
Validation loss: 2.3093142128840847

Epoch: 5| Step: 6
Training loss: 0.17297838160121395
Validation loss: 2.371295343088847

Epoch: 5| Step: 7
Training loss: 0.17767729209348954
Validation loss: 2.3778224229798224

Epoch: 5| Step: 8
Training loss: 0.1770844155633805
Validation loss: 2.444431981312566

Epoch: 5| Step: 9
Training loss: 0.3046275715701789
Validation loss: 2.424438323600626

Epoch: 5| Step: 10
Training loss: 0.21517134745755262
Validation loss: 2.355744368897077

Epoch: 569| Step: 0
Training loss: 0.2759107453194671
Validation loss: 2.272282758658315

Epoch: 5| Step: 1
Training loss: 0.26187698363506534
Validation loss: 2.256324417911319

Epoch: 5| Step: 2
Training loss: 0.2433811658652263
Validation loss: 2.254873820514207

Epoch: 5| Step: 3
Training loss: 0.22600667286353818
Validation loss: 2.2734863825160043

Epoch: 5| Step: 4
Training loss: 0.18663277342461898
Validation loss: 2.3230708473128923

Epoch: 5| Step: 5
Training loss: 0.1695559386985098
Validation loss: 2.376416896058581

Epoch: 5| Step: 6
Training loss: 0.2118092994324315
Validation loss: 2.4107880732050777

Epoch: 5| Step: 7
Training loss: 0.33178849041042946
Validation loss: 2.428817107233785

Epoch: 5| Step: 8
Training loss: 0.18735215199252392
Validation loss: 2.3871739718384144

Epoch: 5| Step: 9
Training loss: 0.15364980221056598
Validation loss: 2.3736966890438977

Epoch: 5| Step: 10
Training loss: 0.19092168584849048
Validation loss: 2.2917813612649964

Epoch: 570| Step: 0
Training loss: 0.2633141952639357
Validation loss: 2.2635625785083384

Epoch: 5| Step: 1
Training loss: 0.25509824454392543
Validation loss: 2.267598283984811

Epoch: 5| Step: 2
Training loss: 0.2990857927026939
Validation loss: 2.2895109711743724

Epoch: 5| Step: 3
Training loss: 0.1295453182674905
Validation loss: 2.3485870315250983

Epoch: 5| Step: 4
Training loss: 0.20262928225188764
Validation loss: 2.3955359973066006

Epoch: 5| Step: 5
Training loss: 0.3067776683548946
Validation loss: 2.4756675208889596

Epoch: 5| Step: 6
Training loss: 0.3427278754663882
Validation loss: 2.4215709038870883

Epoch: 5| Step: 7
Training loss: 0.24195896410155046
Validation loss: 2.3568769754781287

Epoch: 5| Step: 8
Training loss: 0.30254426955389807
Validation loss: 2.303147420054564

Epoch: 5| Step: 9
Training loss: 0.27779802539994264
Validation loss: 2.3088521258093433

Epoch: 5| Step: 10
Training loss: 0.48846383305085184
Validation loss: 2.350307287810571

Epoch: 571| Step: 0
Training loss: 0.4197715667695988
Validation loss: 2.402459979169855

Epoch: 5| Step: 1
Training loss: 0.2646464104944283
Validation loss: 2.357851404268831

Epoch: 5| Step: 2
Training loss: 0.25744160068632826
Validation loss: 2.3332405211042286

Epoch: 5| Step: 3
Training loss: 0.33815647978211244
Validation loss: 2.3032711503896715

Epoch: 5| Step: 4
Training loss: 0.19296001847007097
Validation loss: 2.3260779390373925

Epoch: 5| Step: 5
Training loss: 0.22910131891860436
Validation loss: 2.341692009341557

Epoch: 5| Step: 6
Training loss: 0.22707629316831726
Validation loss: 2.364699859877604

Epoch: 5| Step: 7
Training loss: 0.17958816602212613
Validation loss: 2.3686831891379967

Epoch: 5| Step: 8
Training loss: 0.12913988355503367
Validation loss: 2.3527421473673766

Epoch: 5| Step: 9
Training loss: 0.28661351624436393
Validation loss: 2.3231894142924037

Epoch: 5| Step: 10
Training loss: 0.18176342289601585
Validation loss: 2.355299527789897

Epoch: 572| Step: 0
Training loss: 0.2397446408975558
Validation loss: 2.3299835466168983

Epoch: 5| Step: 1
Training loss: 0.16660247189809124
Validation loss: 2.3376970212602526

Epoch: 5| Step: 2
Training loss: 0.1550939470190349
Validation loss: 2.323988568723955

Epoch: 5| Step: 3
Training loss: 0.2527399861392381
Validation loss: 2.3164668964528268

Epoch: 5| Step: 4
Training loss: 0.21632718421838926
Validation loss: 2.324765561118

Epoch: 5| Step: 5
Training loss: 0.24730917349750414
Validation loss: 2.331577765298491

Epoch: 5| Step: 6
Training loss: 0.3627134212806781
Validation loss: 2.355692455498344

Epoch: 5| Step: 7
Training loss: 0.183800712564844
Validation loss: 2.3610962693747064

Epoch: 5| Step: 8
Training loss: 0.21641616213301126
Validation loss: 2.3429895010777955

Epoch: 5| Step: 9
Training loss: 0.2340625985633021
Validation loss: 2.328889809133802

Epoch: 5| Step: 10
Training loss: 0.1754753099507813
Validation loss: 2.2893531057952226

Epoch: 573| Step: 0
Training loss: 0.21670431446549673
Validation loss: 2.3084825669044697

Epoch: 5| Step: 1
Training loss: 0.1777728636432087
Validation loss: 2.2993442750074258

Epoch: 5| Step: 2
Training loss: 0.30936426230783365
Validation loss: 2.3543608405071166

Epoch: 5| Step: 3
Training loss: 0.27793124929647406
Validation loss: 2.331441854981609

Epoch: 5| Step: 4
Training loss: 0.19133942274365015
Validation loss: 2.371549812323071

Epoch: 5| Step: 5
Training loss: 0.19103516398781742
Validation loss: 2.425802036718347

Epoch: 5| Step: 6
Training loss: 0.2451778959804388
Validation loss: 2.4393158079286237

Epoch: 5| Step: 7
Training loss: 0.3228502346226131
Validation loss: 2.42773120494388

Epoch: 5| Step: 8
Training loss: 0.1658763862579246
Validation loss: 2.4143473091495644

Epoch: 5| Step: 9
Training loss: 0.2536873534108876
Validation loss: 2.3098776143143263

Epoch: 5| Step: 10
Training loss: 0.20634460844144145
Validation loss: 2.2969652015464836

Epoch: 574| Step: 0
Training loss: 0.1831813807485492
Validation loss: 2.2787179136814903

Epoch: 5| Step: 1
Training loss: 0.2157013768225779
Validation loss: 2.342348408427888

Epoch: 5| Step: 2
Training loss: 0.25888926167715937
Validation loss: 2.3714078173616038

Epoch: 5| Step: 3
Training loss: 0.16674052342970255
Validation loss: 2.414122833507935

Epoch: 5| Step: 4
Training loss: 0.1531687248335651
Validation loss: 2.4200876002710214

Epoch: 5| Step: 5
Training loss: 0.27760443726193024
Validation loss: 2.3963345739416737

Epoch: 5| Step: 6
Training loss: 0.2535833359446814
Validation loss: 2.434731237983378

Epoch: 5| Step: 7
Training loss: 0.17240819805054894
Validation loss: 2.3383759850704076

Epoch: 5| Step: 8
Training loss: 0.1947606874674786
Validation loss: 2.343402677663019

Epoch: 5| Step: 9
Training loss: 0.29674841039018124
Validation loss: 2.304098540606304

Epoch: 5| Step: 10
Training loss: 0.1628326916758462
Validation loss: 2.312805905516946

Epoch: 575| Step: 0
Training loss: 0.1882726623824389
Validation loss: 2.3305255763622212

Epoch: 5| Step: 1
Training loss: 0.21753088953738822
Validation loss: 2.3648224966674305

Epoch: 5| Step: 2
Training loss: 0.31104447427203447
Validation loss: 2.3535474290768077

Epoch: 5| Step: 3
Training loss: 0.24819825276607832
Validation loss: 2.364808783644027

Epoch: 5| Step: 4
Training loss: 0.167105441143
Validation loss: 2.330449720578382

Epoch: 5| Step: 5
Training loss: 0.32342137098409024
Validation loss: 2.348302476549016

Epoch: 5| Step: 6
Training loss: 0.27134367500909534
Validation loss: 2.368672754600394

Epoch: 5| Step: 7
Training loss: 0.21385731957371018
Validation loss: 2.3964057994593704

Epoch: 5| Step: 8
Training loss: 0.16643147277411716
Validation loss: 2.466255402210311

Epoch: 5| Step: 9
Training loss: 0.3520470882227362
Validation loss: 2.4762738782560647

Epoch: 5| Step: 10
Training loss: 0.20358892793719677
Validation loss: 2.4789034782247756

Epoch: 576| Step: 0
Training loss: 0.1810937874228675
Validation loss: 2.3886649417988712

Epoch: 5| Step: 1
Training loss: 0.26194086186630194
Validation loss: 2.3371438373267495

Epoch: 5| Step: 2
Training loss: 0.296471748535523
Validation loss: 2.284480429575503

Epoch: 5| Step: 3
Training loss: 0.2854603491488176
Validation loss: 2.296731278716338

Epoch: 5| Step: 4
Training loss: 0.2366897558956458
Validation loss: 2.328698688195614

Epoch: 5| Step: 5
Training loss: 0.23754182591561485
Validation loss: 2.371995043880634

Epoch: 5| Step: 6
Training loss: 0.16987009465304947
Validation loss: 2.3930427699796692

Epoch: 5| Step: 7
Training loss: 0.2604652820349425
Validation loss: 2.463582183692713

Epoch: 5| Step: 8
Training loss: 0.13774823463627597
Validation loss: 2.465555302883738

Epoch: 5| Step: 9
Training loss: 0.1743270913490313
Validation loss: 2.427349215615613

Epoch: 5| Step: 10
Training loss: 0.19419058918590654
Validation loss: 2.423032744165661

Epoch: 577| Step: 0
Training loss: 0.2777053329585189
Validation loss: 2.3663283130770862

Epoch: 5| Step: 1
Training loss: 0.20662889429266135
Validation loss: 2.3267033154849504

Epoch: 5| Step: 2
Training loss: 0.15400045024547462
Validation loss: 2.2844181332399636

Epoch: 5| Step: 3
Training loss: 0.19240679325190013
Validation loss: 2.307971174198583

Epoch: 5| Step: 4
Training loss: 0.23156979589255688
Validation loss: 2.3178513703424892

Epoch: 5| Step: 5
Training loss: 0.20766469029825038
Validation loss: 2.3114139802639295

Epoch: 5| Step: 6
Training loss: 0.13737099241723263
Validation loss: 2.309568627507825

Epoch: 5| Step: 7
Training loss: 0.1841749670044709
Validation loss: 2.324790721378973

Epoch: 5| Step: 8
Training loss: 0.19332065579932503
Validation loss: 2.3534780956910373

Epoch: 5| Step: 9
Training loss: 0.21818699933871258
Validation loss: 2.3881704796820973

Epoch: 5| Step: 10
Training loss: 0.17130300863075434
Validation loss: 2.3688182224760452

Epoch: 578| Step: 0
Training loss: 0.19499691262307553
Validation loss: 2.3897230267247296

Epoch: 5| Step: 1
Training loss: 0.14683885281716483
Validation loss: 2.3386163170461023

Epoch: 5| Step: 2
Training loss: 0.22806356007671205
Validation loss: 2.3735474503859786

Epoch: 5| Step: 3
Training loss: 0.26754567026050746
Validation loss: 2.361456800325041

Epoch: 5| Step: 4
Training loss: 0.26004331846853024
Validation loss: 2.357654139815624

Epoch: 5| Step: 5
Training loss: 0.23761570333167517
Validation loss: 2.3375297527822663

Epoch: 5| Step: 6
Training loss: 0.22716031457578878
Validation loss: 2.3525992902100743

Epoch: 5| Step: 7
Training loss: 0.2795628435033423
Validation loss: 2.3683886882854526

Epoch: 5| Step: 8
Training loss: 0.20321695373834728
Validation loss: 2.3912404175926647

Epoch: 5| Step: 9
Training loss: 0.23162129307017848
Validation loss: 2.383235664253848

Epoch: 5| Step: 10
Training loss: 0.25132482389559446
Validation loss: 2.3806291117033216

Epoch: 579| Step: 0
Training loss: 0.2477224887148541
Validation loss: 2.3648003793030585

Epoch: 5| Step: 1
Training loss: 0.26052638921313287
Validation loss: 2.3272960382059074

Epoch: 5| Step: 2
Training loss: 0.2841824927961703
Validation loss: 2.311518624132434

Epoch: 5| Step: 3
Training loss: 0.16304673506068615
Validation loss: 2.295725777358929

Epoch: 5| Step: 4
Training loss: 0.29912151320450153
Validation loss: 2.3419170023658054

Epoch: 5| Step: 5
Training loss: 0.17677903443125334
Validation loss: 2.3830322702220648

Epoch: 5| Step: 6
Training loss: 0.2059399886697255
Validation loss: 2.4323086859311025

Epoch: 5| Step: 7
Training loss: 0.19670493637197575
Validation loss: 2.3995680850424774

Epoch: 5| Step: 8
Training loss: 0.2569550067789792
Validation loss: 2.3984359757773728

Epoch: 5| Step: 9
Training loss: 0.22199313652054548
Validation loss: 2.350299319734786

Epoch: 5| Step: 10
Training loss: 0.32955270063422015
Validation loss: 2.295790424537396

Epoch: 580| Step: 0
Training loss: 0.27046145375865654
Validation loss: 2.277468622171435

Epoch: 5| Step: 1
Training loss: 0.1955077721046002
Validation loss: 2.343637369929352

Epoch: 5| Step: 2
Training loss: 0.4936845053922315
Validation loss: 2.3305529459687815

Epoch: 5| Step: 3
Training loss: 0.23459486185737494
Validation loss: 2.3350073457492426

Epoch: 5| Step: 4
Training loss: 0.15070285216683013
Validation loss: 2.327347016983607

Epoch: 5| Step: 5
Training loss: 0.23302492077317297
Validation loss: 2.398592920729957

Epoch: 5| Step: 6
Training loss: 0.21977333418759729
Validation loss: 2.4080063986265516

Epoch: 5| Step: 7
Training loss: 0.4355246876081736
Validation loss: 2.407151875577715

Epoch: 5| Step: 8
Training loss: 0.2552358002706059
Validation loss: 2.361140297506841

Epoch: 5| Step: 9
Training loss: 0.35690397251859773
Validation loss: 2.3218636386787534

Epoch: 5| Step: 10
Training loss: 0.23456890509164927
Validation loss: 2.310064133175244

Epoch: 581| Step: 0
Training loss: 0.1498488166000242
Validation loss: 2.3031475747758963

Epoch: 5| Step: 1
Training loss: 0.24433978540453652
Validation loss: 2.3499012038750013

Epoch: 5| Step: 2
Training loss: 0.14377291952772736
Validation loss: 2.38328117873167

Epoch: 5| Step: 3
Training loss: 0.20246595058163278
Validation loss: 2.416612483072409

Epoch: 5| Step: 4
Training loss: 0.29941895612187663
Validation loss: 2.4337946123613428

Epoch: 5| Step: 5
Training loss: 0.180883521740016
Validation loss: 2.424002080032272

Epoch: 5| Step: 6
Training loss: 0.3111721796967597
Validation loss: 2.3980537843262004

Epoch: 5| Step: 7
Training loss: 0.17932515305731014
Validation loss: 2.365546073111131

Epoch: 5| Step: 8
Training loss: 0.22796291772651753
Validation loss: 2.3084790815014076

Epoch: 5| Step: 9
Training loss: 0.31502028076415717
Validation loss: 2.3136142949484206

Epoch: 5| Step: 10
Training loss: 0.1438185673428092
Validation loss: 2.312563404476732

Epoch: 582| Step: 0
Training loss: 0.2364506915968067
Validation loss: 2.3614507555948023

Epoch: 5| Step: 1
Training loss: 0.18594475299248886
Validation loss: 2.3382461777379375

Epoch: 5| Step: 2
Training loss: 0.16902539664910163
Validation loss: 2.33799372362343

Epoch: 5| Step: 3
Training loss: 0.22664372862486049
Validation loss: 2.3260958397664635

Epoch: 5| Step: 4
Training loss: 0.16765934147610914
Validation loss: 2.2890837252361256

Epoch: 5| Step: 5
Training loss: 0.20000749477112248
Validation loss: 2.3013938309630393

Epoch: 5| Step: 6
Training loss: 0.16007857067107553
Validation loss: 2.320290390367278

Epoch: 5| Step: 7
Training loss: 0.27117284560847243
Validation loss: 2.288820047742433

Epoch: 5| Step: 8
Training loss: 0.17335957159690488
Validation loss: 2.3185376296611975

Epoch: 5| Step: 9
Training loss: 0.11791744584984794
Validation loss: 2.315826427005716

Epoch: 5| Step: 10
Training loss: 0.16105746039002689
Validation loss: 2.3025742063484405

Epoch: 583| Step: 0
Training loss: 0.16186548178353252
Validation loss: 2.330482892730729

Epoch: 5| Step: 1
Training loss: 0.18847803500692295
Validation loss: 2.3115905984589364

Epoch: 5| Step: 2
Training loss: 0.23976123552229098
Validation loss: 2.3330987388999738

Epoch: 5| Step: 3
Training loss: 0.10517599394483675
Validation loss: 2.368624986321668

Epoch: 5| Step: 4
Training loss: 0.13295654591633368
Validation loss: 2.353477338628317

Epoch: 5| Step: 5
Training loss: 0.22788850204634986
Validation loss: 2.360314936940503

Epoch: 5| Step: 6
Training loss: 0.12402023101025769
Validation loss: 2.3742833354243698

Epoch: 5| Step: 7
Training loss: 0.14649924520674049
Validation loss: 2.375089510929363

Epoch: 5| Step: 8
Training loss: 0.17135409509276622
Validation loss: 2.383973934482222

Epoch: 5| Step: 9
Training loss: 0.2494929506294091
Validation loss: 2.3819743376320957

Epoch: 5| Step: 10
Training loss: 0.1528185817175275
Validation loss: 2.419701683782638

Epoch: 584| Step: 0
Training loss: 0.2940171619696837
Validation loss: 2.4111767536269273

Epoch: 5| Step: 1
Training loss: 0.1783325588036441
Validation loss: 2.3581490855343183

Epoch: 5| Step: 2
Training loss: 0.14130324806378267
Validation loss: 2.3549197222428044

Epoch: 5| Step: 3
Training loss: 0.1647134650208869
Validation loss: 2.3571357143187157

Epoch: 5| Step: 4
Training loss: 0.184947169032117
Validation loss: 2.350272534585491

Epoch: 5| Step: 5
Training loss: 0.1255470316469916
Validation loss: 2.3701961142903882

Epoch: 5| Step: 6
Training loss: 0.3069564383607811
Validation loss: 2.3939819155479367

Epoch: 5| Step: 7
Training loss: 0.16248913027098638
Validation loss: 2.382901550705428

Epoch: 5| Step: 8
Training loss: 0.17142602953328379
Validation loss: 2.317769120292485

Epoch: 5| Step: 9
Training loss: 0.11058943353865021
Validation loss: 2.353251012796043

Epoch: 5| Step: 10
Training loss: 0.19833699669947494
Validation loss: 2.3400281421612292

Epoch: 585| Step: 0
Training loss: 0.2521601868484169
Validation loss: 2.337874685329035

Epoch: 5| Step: 1
Training loss: 0.20150087360755914
Validation loss: 2.3450418014634846

Epoch: 5| Step: 2
Training loss: 0.1787686072514987
Validation loss: 2.3606721696450177

Epoch: 5| Step: 3
Training loss: 0.17144378842215055
Validation loss: 2.3747146296833908

Epoch: 5| Step: 4
Training loss: 0.25944780683709767
Validation loss: 2.351341078239505

Epoch: 5| Step: 5
Training loss: 0.16284025840661645
Validation loss: 2.329170345289036

Epoch: 5| Step: 6
Training loss: 0.24995427905664797
Validation loss: 2.255290810147956

Epoch: 5| Step: 7
Training loss: 0.26109746952021384
Validation loss: 2.2359287164475927

Epoch: 5| Step: 8
Training loss: 0.23596377700093943
Validation loss: 2.2566683430958636

Epoch: 5| Step: 9
Training loss: 0.15171267551318618
Validation loss: 2.2533178182135627

Epoch: 5| Step: 10
Training loss: 0.1281638877283804
Validation loss: 2.3095829321421038

Epoch: 586| Step: 0
Training loss: 0.28349968740069265
Validation loss: 2.326191913034925

Epoch: 5| Step: 1
Training loss: 0.18998154949023194
Validation loss: 2.3825647089118602

Epoch: 5| Step: 2
Training loss: 0.21816308611290172
Validation loss: 2.400653242780115

Epoch: 5| Step: 3
Training loss: 0.14708512144267094
Validation loss: 2.3581253335573864

Epoch: 5| Step: 4
Training loss: 0.13947773216764361
Validation loss: 2.379078783880752

Epoch: 5| Step: 5
Training loss: 0.17292601388252413
Validation loss: 2.338381113714312

Epoch: 5| Step: 6
Training loss: 0.15203168892478508
Validation loss: 2.2984705981601525

Epoch: 5| Step: 7
Training loss: 0.26481385357663645
Validation loss: 2.315302114770957

Epoch: 5| Step: 8
Training loss: 0.17472151157337054
Validation loss: 2.3362987520338945

Epoch: 5| Step: 9
Training loss: 0.19856125659571325
Validation loss: 2.3360990574810816

Epoch: 5| Step: 10
Training loss: 0.23007985617952964
Validation loss: 2.3628831395704504

Epoch: 587| Step: 0
Training loss: 0.1472354010471629
Validation loss: 2.40547314235651

Epoch: 5| Step: 1
Training loss: 0.16440742428521019
Validation loss: 2.397506351941792

Epoch: 5| Step: 2
Training loss: 0.14690296764110952
Validation loss: 2.34637370602257

Epoch: 5| Step: 3
Training loss: 0.2476184178285834
Validation loss: 2.371522942343734

Epoch: 5| Step: 4
Training loss: 0.23557370730485355
Validation loss: 2.3226609749885623

Epoch: 5| Step: 5
Training loss: 0.1150699994856507
Validation loss: 2.3152990841992804

Epoch: 5| Step: 6
Training loss: 0.31223623349787233
Validation loss: 2.335611990508856

Epoch: 5| Step: 7
Training loss: 0.17495085290086027
Validation loss: 2.3096177415284065

Epoch: 5| Step: 8
Training loss: 0.19056884376223562
Validation loss: 2.3379769907743655

Epoch: 5| Step: 9
Training loss: 0.16107617163003343
Validation loss: 2.3274375581666558

Epoch: 5| Step: 10
Training loss: 0.13878018219547114
Validation loss: 2.3459900562382767

Epoch: 588| Step: 0
Training loss: 0.15267587185208317
Validation loss: 2.356612782585574

Epoch: 5| Step: 1
Training loss: 0.1244678494830051
Validation loss: 2.33574820037604

Epoch: 5| Step: 2
Training loss: 0.1833094465253094
Validation loss: 2.3863718658756037

Epoch: 5| Step: 3
Training loss: 0.1875160726969902
Validation loss: 2.3496738707612983

Epoch: 5| Step: 4
Training loss: 0.15476939725827932
Validation loss: 2.3385938690700545

Epoch: 5| Step: 5
Training loss: 0.2059093523253516
Validation loss: 2.326380682204131

Epoch: 5| Step: 6
Training loss: 0.2730195666233695
Validation loss: 2.3278106820836584

Epoch: 5| Step: 7
Training loss: 0.17609782322536602
Validation loss: 2.2869884705994914

Epoch: 5| Step: 8
Training loss: 0.1600497927058527
Validation loss: 2.3086071134434887

Epoch: 5| Step: 9
Training loss: 0.1876942105613221
Validation loss: 2.2820088211330556

Epoch: 5| Step: 10
Training loss: 0.12857491363379336
Validation loss: 2.294710938641756

Epoch: 589| Step: 0
Training loss: 0.24387897203291276
Validation loss: 2.3259587604465493

Epoch: 5| Step: 1
Training loss: 0.12051127690014181
Validation loss: 2.3445362229866897

Epoch: 5| Step: 2
Training loss: 0.15953858409130087
Validation loss: 2.3256692784658117

Epoch: 5| Step: 3
Training loss: 0.11980774804339465
Validation loss: 2.341977483535558

Epoch: 5| Step: 4
Training loss: 0.1274204894691605
Validation loss: 2.3601301365159606

Epoch: 5| Step: 5
Training loss: 0.07131365129918908
Validation loss: 2.3459389618670317

Epoch: 5| Step: 6
Training loss: 0.09403626625047051
Validation loss: 2.379441133047679

Epoch: 5| Step: 7
Training loss: 0.11611733954855412
Validation loss: 2.368161428940813

Epoch: 5| Step: 8
Training loss: 0.10933677822933256
Validation loss: 2.3780630153447313

Epoch: 5| Step: 9
Training loss: 0.22940677108362503
Validation loss: 2.3386220628821275

Epoch: 5| Step: 10
Training loss: 0.2505681317753409
Validation loss: 2.3419010058089187

Epoch: 590| Step: 0
Training loss: 0.19814847977014408
Validation loss: 2.3756492301633587

Epoch: 5| Step: 1
Training loss: 0.10462437940171924
Validation loss: 2.3833055824897516

Epoch: 5| Step: 2
Training loss: 0.1477719368431134
Validation loss: 2.3686059085048314

Epoch: 5| Step: 3
Training loss: 0.22455178227317213
Validation loss: 2.3491426488396185

Epoch: 5| Step: 4
Training loss: 0.10734967059253467
Validation loss: 2.314501536136344

Epoch: 5| Step: 5
Training loss: 0.2131772343119082
Validation loss: 2.311450715764054

Epoch: 5| Step: 6
Training loss: 0.21477601977767727
Validation loss: 2.338915258819537

Epoch: 5| Step: 7
Training loss: 0.1424908044006395
Validation loss: 2.348114380109296

Epoch: 5| Step: 8
Training loss: 0.1862190019010814
Validation loss: 2.3612270940403133

Epoch: 5| Step: 9
Training loss: 0.2106922808251562
Validation loss: 2.393051752721914

Epoch: 5| Step: 10
Training loss: 0.1430986973381497
Validation loss: 2.4050680154597277

Epoch: 591| Step: 0
Training loss: 0.14988177776600867
Validation loss: 2.355820461427101

Epoch: 5| Step: 1
Training loss: 0.11145780773425137
Validation loss: 2.3360678526363605

Epoch: 5| Step: 2
Training loss: 0.1348687896597995
Validation loss: 2.3113616740221423

Epoch: 5| Step: 3
Training loss: 0.21851156216643766
Validation loss: 2.2844343056270966

Epoch: 5| Step: 4
Training loss: 0.1502937215249566
Validation loss: 2.314171819490795

Epoch: 5| Step: 5
Training loss: 0.22912956970681725
Validation loss: 2.320629185684507

Epoch: 5| Step: 6
Training loss: 0.19116415556181587
Validation loss: 2.348972004467147

Epoch: 5| Step: 7
Training loss: 0.13377206234926067
Validation loss: 2.337012515745212

Epoch: 5| Step: 8
Training loss: 0.13852310931774814
Validation loss: 2.35253851327425

Epoch: 5| Step: 9
Training loss: 0.2536354087603883
Validation loss: 2.340013256743625

Epoch: 5| Step: 10
Training loss: 0.12255859375
Validation loss: 2.33130075734365

Epoch: 592| Step: 0
Training loss: 0.14746172064769017
Validation loss: 2.3041005583847

Epoch: 5| Step: 1
Training loss: 0.1514853785138781
Validation loss: 2.3256859350701964

Epoch: 5| Step: 2
Training loss: 0.17546798023962001
Validation loss: 2.368840765522969

Epoch: 5| Step: 3
Training loss: 0.1930284654831168
Validation loss: 2.3030095647830624

Epoch: 5| Step: 4
Training loss: 0.1965740374679947
Validation loss: 2.318223734771295

Epoch: 5| Step: 5
Training loss: 0.21026727374328263
Validation loss: 2.3170172370395066

Epoch: 5| Step: 6
Training loss: 0.17841335179995466
Validation loss: 2.291911178327438

Epoch: 5| Step: 7
Training loss: 0.1277073537027685
Validation loss: 2.3276657330912935

Epoch: 5| Step: 8
Training loss: 0.15073959313755225
Validation loss: 2.3761138268762743

Epoch: 5| Step: 9
Training loss: 0.23043824656722267
Validation loss: 2.381110170859383

Epoch: 5| Step: 10
Training loss: 0.11309594174343346
Validation loss: 2.3976376759020743

Epoch: 593| Step: 0
Training loss: 0.14733403789756713
Validation loss: 2.4086310974086387

Epoch: 5| Step: 1
Training loss: 0.08248515231190244
Validation loss: 2.4138043170616754

Epoch: 5| Step: 2
Training loss: 0.08594854511461118
Validation loss: 2.392629324871859

Epoch: 5| Step: 3
Training loss: 0.19161249259858132
Validation loss: 2.360617253758187

Epoch: 5| Step: 4
Training loss: 0.2077254675985131
Validation loss: 2.3505251428614384

Epoch: 5| Step: 5
Training loss: 0.11630432399724469
Validation loss: 2.3645473298774173

Epoch: 5| Step: 6
Training loss: 0.09669966924689936
Validation loss: 2.3264406361214953

Epoch: 5| Step: 7
Training loss: 0.11232746142139516
Validation loss: 2.3240856716807365

Epoch: 5| Step: 8
Training loss: 0.2278819631578823
Validation loss: 2.344550352546363

Epoch: 5| Step: 9
Training loss: 0.1989825943356816
Validation loss: 2.3114953335026245

Epoch: 5| Step: 10
Training loss: 0.1599562838742637
Validation loss: 2.3439822480450916

Epoch: 594| Step: 0
Training loss: 0.10456481085502205
Validation loss: 2.336903992934983

Epoch: 5| Step: 1
Training loss: 0.21654966367245357
Validation loss: 2.334050814695156

Epoch: 5| Step: 2
Training loss: 0.143961731583758
Validation loss: 2.349041754605498

Epoch: 5| Step: 3
Training loss: 0.17878582953775712
Validation loss: 2.305413465976505

Epoch: 5| Step: 4
Training loss: 0.10592542343875438
Validation loss: 2.361860433440329

Epoch: 5| Step: 5
Training loss: 0.14960952514760423
Validation loss: 2.3474031227647156

Epoch: 5| Step: 6
Training loss: 0.17355097417917933
Validation loss: 2.3364854521753466

Epoch: 5| Step: 7
Training loss: 0.10727566392157932
Validation loss: 2.3877835734193655

Epoch: 5| Step: 8
Training loss: 0.10421913782445075
Validation loss: 2.3348250896126466

Epoch: 5| Step: 9
Training loss: 0.256895254269411
Validation loss: 2.3240368341797746

Epoch: 5| Step: 10
Training loss: 0.1666127182153656
Validation loss: 2.330021139673339

Epoch: 595| Step: 0
Training loss: 0.0861322136942491
Validation loss: 2.3243018626568053

Epoch: 5| Step: 1
Training loss: 0.21792151031496448
Validation loss: 2.347898092612344

Epoch: 5| Step: 2
Training loss: 0.12995391706349363
Validation loss: 2.3301246183960775

Epoch: 5| Step: 3
Training loss: 0.20185601465514047
Validation loss: 2.3345587767545473

Epoch: 5| Step: 4
Training loss: 0.1854193801538457
Validation loss: 2.3041670461707495

Epoch: 5| Step: 5
Training loss: 0.20261749727936262
Validation loss: 2.313149346352789

Epoch: 5| Step: 6
Training loss: 0.13470682990109026
Validation loss: 2.316534391619427

Epoch: 5| Step: 7
Training loss: 0.10289967568083898
Validation loss: 2.31595464498462

Epoch: 5| Step: 8
Training loss: 0.12425708539091063
Validation loss: 2.3370020154919504

Epoch: 5| Step: 9
Training loss: 0.14186459807776258
Validation loss: 2.323300346547225

Epoch: 5| Step: 10
Training loss: 0.15210879988480805
Validation loss: 2.3241944836143986

Epoch: 596| Step: 0
Training loss: 0.17988224464351724
Validation loss: 2.368058311876113

Epoch: 5| Step: 1
Training loss: 0.10331711989519791
Validation loss: 2.3790267331083705

Epoch: 5| Step: 2
Training loss: 0.21233145747698573
Validation loss: 2.4102002052081284

Epoch: 5| Step: 3
Training loss: 0.20218120069876117
Validation loss: 2.3643970626646515

Epoch: 5| Step: 4
Training loss: 0.1310921207640461
Validation loss: 2.328058888653664

Epoch: 5| Step: 5
Training loss: 0.15280842217853327
Validation loss: 2.320946866451195

Epoch: 5| Step: 6
Training loss: 0.2614665168200888
Validation loss: 2.2986699615503485

Epoch: 5| Step: 7
Training loss: 0.17515770201204556
Validation loss: 2.308046631914921

Epoch: 5| Step: 8
Training loss: 0.20433953206396108
Validation loss: 2.3212966652038247

Epoch: 5| Step: 9
Training loss: 0.07399270179500522
Validation loss: 2.363169979308944

Epoch: 5| Step: 10
Training loss: 0.10381242201341137
Validation loss: 2.387904251700235

Epoch: 597| Step: 0
Training loss: 0.14429331861325656
Validation loss: 2.401698431178546

Epoch: 5| Step: 1
Training loss: 0.21359727104538623
Validation loss: 2.408195808903261

Epoch: 5| Step: 2
Training loss: 0.146834108565038
Validation loss: 2.3907764533486255

Epoch: 5| Step: 3
Training loss: 0.1364393785891687
Validation loss: 2.3655908453032706

Epoch: 5| Step: 4
Training loss: 0.18702477591327407
Validation loss: 2.3589067391711516

Epoch: 5| Step: 5
Training loss: 0.11851633777668105
Validation loss: 2.301078355043132

Epoch: 5| Step: 6
Training loss: 0.1482556509103696
Validation loss: 2.3248745512950304

Epoch: 5| Step: 7
Training loss: 0.18414327882546477
Validation loss: 2.3119050208111034

Epoch: 5| Step: 8
Training loss: 0.18709054585369012
Validation loss: 2.3352873281442057

Epoch: 5| Step: 9
Training loss: 0.21915428234660123
Validation loss: 2.3659375553674313

Epoch: 5| Step: 10
Training loss: 0.18103313379478075
Validation loss: 2.3718988317106

Epoch: 598| Step: 0
Training loss: 0.1680039324619502
Validation loss: 2.4469331656390647

Epoch: 5| Step: 1
Training loss: 0.1304671687184521
Validation loss: 2.422929873985238

Epoch: 5| Step: 2
Training loss: 0.1920744365647381
Validation loss: 2.3849865771552023

Epoch: 5| Step: 3
Training loss: 0.12698825936885047
Validation loss: 2.3517513638785474

Epoch: 5| Step: 4
Training loss: 0.19812431965599817
Validation loss: 2.3155630734159396

Epoch: 5| Step: 5
Training loss: 0.16290143134957435
Validation loss: 2.3208775836796005

Epoch: 5| Step: 6
Training loss: 0.15505469407034356
Validation loss: 2.2388638755674504

Epoch: 5| Step: 7
Training loss: 0.15945983877257167
Validation loss: 2.2925400864069925

Epoch: 5| Step: 8
Training loss: 0.23731661794051911
Validation loss: 2.3099046814200106

Epoch: 5| Step: 9
Training loss: 0.1871888041888674
Validation loss: 2.3222477974134015

Epoch: 5| Step: 10
Training loss: 0.10639805575957113
Validation loss: 2.37978799863445

Epoch: 599| Step: 0
Training loss: 0.24048956056587772
Validation loss: 2.4130746676306

Epoch: 5| Step: 1
Training loss: 0.21887195116966396
Validation loss: 2.4034358288500948

Epoch: 5| Step: 2
Training loss: 0.19906335267583497
Validation loss: 2.3237699066138906

Epoch: 5| Step: 3
Training loss: 0.18466813658853426
Validation loss: 2.317533719899729

Epoch: 5| Step: 4
Training loss: 0.19477412409166217
Validation loss: 2.2831307655547937

Epoch: 5| Step: 5
Training loss: 0.15054012274533324
Validation loss: 2.286084120217166

Epoch: 5| Step: 6
Training loss: 0.18567260698448507
Validation loss: 2.3051361031149553

Epoch: 5| Step: 7
Training loss: 0.14069634190867567
Validation loss: 2.272713783406846

Epoch: 5| Step: 8
Training loss: 0.1999898740321017
Validation loss: 2.3151180676130214

Epoch: 5| Step: 9
Training loss: 0.1247033159722693
Validation loss: 2.333257787846835

Epoch: 5| Step: 10
Training loss: 0.17124531555903932
Validation loss: 2.3780007977640554

Epoch: 600| Step: 0
Training loss: 0.22954154599795307
Validation loss: 2.4200366900059485

Epoch: 5| Step: 1
Training loss: 0.1435527477003594
Validation loss: 2.4148111557415692

Epoch: 5| Step: 2
Training loss: 0.09823449599566683
Validation loss: 2.333637893008605

Epoch: 5| Step: 3
Training loss: 0.19439468262669501
Validation loss: 2.3061789682359217

Epoch: 5| Step: 4
Training loss: 0.17391082853612005
Validation loss: 2.3082374619999353

Epoch: 5| Step: 5
Training loss: 0.18647736584548164
Validation loss: 2.316248304015819

Epoch: 5| Step: 6
Training loss: 0.22921497565492413
Validation loss: 2.347856737008147

Epoch: 5| Step: 7
Training loss: 0.1391944106925394
Validation loss: 2.3330115288294855

Epoch: 5| Step: 8
Training loss: 0.09309213008604486
Validation loss: 2.408970556709371

Epoch: 5| Step: 9
Training loss: 0.1804470305150652
Validation loss: 2.380578370684023

Epoch: 5| Step: 10
Training loss: 0.23714132140882335
Validation loss: 2.3903503656997054

Epoch: 601| Step: 0
Training loss: 0.09350103360863168
Validation loss: 2.380403403829347

Epoch: 5| Step: 1
Training loss: 0.16563203477314797
Validation loss: 2.3161108732047233

Epoch: 5| Step: 2
Training loss: 0.18463127703704746
Validation loss: 2.2859521498439994

Epoch: 5| Step: 3
Training loss: 0.16223342010237599
Validation loss: 2.2659914890740547

Epoch: 5| Step: 4
Training loss: 0.24567588266986798
Validation loss: 2.286330847113266

Epoch: 5| Step: 5
Training loss: 0.15403376249360404
Validation loss: 2.340402256863848

Epoch: 5| Step: 6
Training loss: 0.14176803537289648
Validation loss: 2.3711827326600003

Epoch: 5| Step: 7
Training loss: 0.10917788437529834
Validation loss: 2.383847506992698

Epoch: 5| Step: 8
Training loss: 0.2857786857986333
Validation loss: 2.387520536482479

Epoch: 5| Step: 9
Training loss: 0.20230577399710997
Validation loss: 2.350221980547608

Epoch: 5| Step: 10
Training loss: 0.18480537220907273
Validation loss: 2.352741346482252

Epoch: 602| Step: 0
Training loss: 0.19048196124040967
Validation loss: 2.3377595586617668

Epoch: 5| Step: 1
Training loss: 0.19962784892553226
Validation loss: 2.355743317646594

Epoch: 5| Step: 2
Training loss: 0.19248165941184642
Validation loss: 2.333648495184566

Epoch: 5| Step: 3
Training loss: 0.07706206955793382
Validation loss: 2.330562571070532

Epoch: 5| Step: 4
Training loss: 0.20737197117608447
Validation loss: 2.3375207502510027

Epoch: 5| Step: 5
Training loss: 0.17727980280029434
Validation loss: 2.3785109494026044

Epoch: 5| Step: 6
Training loss: 0.2318186264195318
Validation loss: 2.354806134921122

Epoch: 5| Step: 7
Training loss: 0.12069481848865582
Validation loss: 2.3904818961786

Epoch: 5| Step: 8
Training loss: 0.17329869386328797
Validation loss: 2.350823599711789

Epoch: 5| Step: 9
Training loss: 0.2088759131933827
Validation loss: 2.336870553747341

Epoch: 5| Step: 10
Training loss: 0.15552682414932767
Validation loss: 2.325212516603359

Epoch: 603| Step: 0
Training loss: 0.18818911438917477
Validation loss: 2.3005710639997017

Epoch: 5| Step: 1
Training loss: 0.12740919648834176
Validation loss: 2.287511020703113

Epoch: 5| Step: 2
Training loss: 0.21558043150619371
Validation loss: 2.344896606484747

Epoch: 5| Step: 3
Training loss: 0.09227471570088978
Validation loss: 2.306286215651354

Epoch: 5| Step: 4
Training loss: 0.16549293475506172
Validation loss: 2.3103587561903844

Epoch: 5| Step: 5
Training loss: 0.0989804609137543
Validation loss: 2.300125433353588

Epoch: 5| Step: 6
Training loss: 0.19274294495133198
Validation loss: 2.3187447914945327

Epoch: 5| Step: 7
Training loss: 0.10753207189893811
Validation loss: 2.3100682670660246

Epoch: 5| Step: 8
Training loss: 0.24401144043101394
Validation loss: 2.332050951868655

Epoch: 5| Step: 9
Training loss: 0.135001998043286
Validation loss: 2.330801892218673

Epoch: 5| Step: 10
Training loss: 0.14402554293470413
Validation loss: 2.3310579054456633

Epoch: 604| Step: 0
Training loss: 0.1786796354802713
Validation loss: 2.3821836613111484

Epoch: 5| Step: 1
Training loss: 0.23254953612968424
Validation loss: 2.352154376916052

Epoch: 5| Step: 2
Training loss: 0.13791109992108122
Validation loss: 2.340199625214265

Epoch: 5| Step: 3
Training loss: 0.10440480955107033
Validation loss: 2.360381846095102

Epoch: 5| Step: 4
Training loss: 0.11849172733449176
Validation loss: 2.3610299123795957

Epoch: 5| Step: 5
Training loss: 0.21148163760231148
Validation loss: 2.3415462073020965

Epoch: 5| Step: 6
Training loss: 0.13381925645917433
Validation loss: 2.3322251855669847

Epoch: 5| Step: 7
Training loss: 0.17174558210347685
Validation loss: 2.3282119697292827

Epoch: 5| Step: 8
Training loss: 0.13079433105705346
Validation loss: 2.3754032884987137

Epoch: 5| Step: 9
Training loss: 0.11483179503776432
Validation loss: 2.316265944797509

Epoch: 5| Step: 10
Training loss: 0.1974576921507608
Validation loss: 2.33556242973824

Epoch: 605| Step: 0
Training loss: 0.15291045008226833
Validation loss: 2.3480768157870497

Epoch: 5| Step: 1
Training loss: 0.15288422762664053
Validation loss: 2.3598796519647203

Epoch: 5| Step: 2
Training loss: 0.18722066337131119
Validation loss: 2.346811947777712

Epoch: 5| Step: 3
Training loss: 0.14393299236395074
Validation loss: 2.3659246129935534

Epoch: 5| Step: 4
Training loss: 0.11435104706878642
Validation loss: 2.382059002294017

Epoch: 5| Step: 5
Training loss: 0.15356570244843432
Validation loss: 2.373788970665557

Epoch: 5| Step: 6
Training loss: 0.18891683357951033
Validation loss: 2.344205548167351

Epoch: 5| Step: 7
Training loss: 0.21203442860007957
Validation loss: 2.373004480858734

Epoch: 5| Step: 8
Training loss: 0.14225768306461697
Validation loss: 2.367778881680328

Epoch: 5| Step: 9
Training loss: 0.17836172870113923
Validation loss: 2.356931893127806

Epoch: 5| Step: 10
Training loss: 0.10306414177542914
Validation loss: 2.383923169215754

Epoch: 606| Step: 0
Training loss: 0.07840555301776865
Validation loss: 2.358036701826228

Epoch: 5| Step: 1
Training loss: 0.1469882437212166
Validation loss: 2.3467042337303554

Epoch: 5| Step: 2
Training loss: 0.21816297512073743
Validation loss: 2.3305954061185368

Epoch: 5| Step: 3
Training loss: 0.17159814102197118
Validation loss: 2.368033771015535

Epoch: 5| Step: 4
Training loss: 0.14913575425744496
Validation loss: 2.37081276468942

Epoch: 5| Step: 5
Training loss: 0.11694683953763185
Validation loss: 2.3718520914506507

Epoch: 5| Step: 6
Training loss: 0.2015034711144783
Validation loss: 2.389317714250392

Epoch: 5| Step: 7
Training loss: 0.1374423158004868
Validation loss: 2.3952992026223345

Epoch: 5| Step: 8
Training loss: 0.11689267423934592
Validation loss: 2.3784679251025405

Epoch: 5| Step: 9
Training loss: 0.13710818004902542
Validation loss: 2.371259919042349

Epoch: 5| Step: 10
Training loss: 0.1320766300449407
Validation loss: 2.3855187863106715

Epoch: 607| Step: 0
Training loss: 0.09698618845337385
Validation loss: 2.3700700278398856

Epoch: 5| Step: 1
Training loss: 0.15279859109974525
Validation loss: 2.311515932413068

Epoch: 5| Step: 2
Training loss: 0.1314884126465986
Validation loss: 2.2837926775643025

Epoch: 5| Step: 3
Training loss: 0.10530739379921379
Validation loss: 2.2999630749856252

Epoch: 5| Step: 4
Training loss: 0.1226022346277372
Validation loss: 2.285984593916497

Epoch: 5| Step: 5
Training loss: 0.2796618337948698
Validation loss: 2.3103636085920716

Epoch: 5| Step: 6
Training loss: 0.14362487245036107
Validation loss: 2.354477764819795

Epoch: 5| Step: 7
Training loss: 0.11643077588770898
Validation loss: 2.33819183430485

Epoch: 5| Step: 8
Training loss: 0.20438751011803455
Validation loss: 2.379475214068015

Epoch: 5| Step: 9
Training loss: 0.13882981292351088
Validation loss: 2.37854602079366

Epoch: 5| Step: 10
Training loss: 0.1026874785121424
Validation loss: 2.3780541085838682

Epoch: 608| Step: 0
Training loss: 0.17380062164291768
Validation loss: 2.320671722457978

Epoch: 5| Step: 1
Training loss: 0.17489759544176328
Validation loss: 2.342819013650116

Epoch: 5| Step: 2
Training loss: 0.11393612219411098
Validation loss: 2.304329412612998

Epoch: 5| Step: 3
Training loss: 0.17912977156636087
Validation loss: 2.316172634235442

Epoch: 5| Step: 4
Training loss: 0.14338873658688317
Validation loss: 2.316917389739283

Epoch: 5| Step: 5
Training loss: 0.18896549431740603
Validation loss: 2.3208889919570534

Epoch: 5| Step: 6
Training loss: 0.11593445577891903
Validation loss: 2.336400966285558

Epoch: 5| Step: 7
Training loss: 0.14523728716076523
Validation loss: 2.3323540243893706

Epoch: 5| Step: 8
Training loss: 0.11839748216052932
Validation loss: 2.344352489406918

Epoch: 5| Step: 9
Training loss: 0.12093601413178733
Validation loss: 2.3463684418848048

Epoch: 5| Step: 10
Training loss: 0.12816271052509273
Validation loss: 2.343592380706435

Epoch: 609| Step: 0
Training loss: 0.19189549220186694
Validation loss: 2.3347831950028692

Epoch: 5| Step: 1
Training loss: 0.1781657716033061
Validation loss: 2.3096833368148992

Epoch: 5| Step: 2
Training loss: 0.12662264283830352
Validation loss: 2.3167152599173257

Epoch: 5| Step: 3
Training loss: 0.14996104380272696
Validation loss: 2.3488486601592973

Epoch: 5| Step: 4
Training loss: 0.1277388977276679
Validation loss: 2.3504360898350183

Epoch: 5| Step: 5
Training loss: 0.1343284163015397
Validation loss: 2.3561263498625644

Epoch: 5| Step: 6
Training loss: 0.1329744557636869
Validation loss: 2.398989386630031

Epoch: 5| Step: 7
Training loss: 0.13393250314867786
Validation loss: 2.405083725124505

Epoch: 5| Step: 8
Training loss: 0.1298034540256116
Validation loss: 2.4302744791279616

Epoch: 5| Step: 9
Training loss: 0.18059417816378032
Validation loss: 2.390190975717997

Epoch: 5| Step: 10
Training loss: 0.10198920276618116
Validation loss: 2.3754093106746876

Epoch: 610| Step: 0
Training loss: 0.17461838197625998
Validation loss: 2.3938754452585966

Epoch: 5| Step: 1
Training loss: 0.19318918965358825
Validation loss: 2.364027764590502

Epoch: 5| Step: 2
Training loss: 0.08150556128892261
Validation loss: 2.3775466451756153

Epoch: 5| Step: 3
Training loss: 0.160135110762584
Validation loss: 2.3908190979868675

Epoch: 5| Step: 4
Training loss: 0.11820578429690533
Validation loss: 2.367704963258508

Epoch: 5| Step: 5
Training loss: 0.12615085344014548
Validation loss: 2.3528374818042024

Epoch: 5| Step: 6
Training loss: 0.17066098747181088
Validation loss: 2.3454255883221244

Epoch: 5| Step: 7
Training loss: 0.1272520580635881
Validation loss: 2.3502202276187054

Epoch: 5| Step: 8
Training loss: 0.14521287302348734
Validation loss: 2.334050468984624

Epoch: 5| Step: 9
Training loss: 0.1277249423169334
Validation loss: 2.342859777564524

Epoch: 5| Step: 10
Training loss: 0.1915372380842203
Validation loss: 2.386308046655977

Epoch: 611| Step: 0
Training loss: 0.17496850420019397
Validation loss: 2.376291505680768

Epoch: 5| Step: 1
Training loss: 0.10289174688997713
Validation loss: 2.3871671014072016

Epoch: 5| Step: 2
Training loss: 0.14173494173941073
Validation loss: 2.3544706351095264

Epoch: 5| Step: 3
Training loss: 0.17052583675660188
Validation loss: 2.363883974633917

Epoch: 5| Step: 4
Training loss: 0.10381976468546471
Validation loss: 2.3821618536510303

Epoch: 5| Step: 5
Training loss: 0.2548121065600354
Validation loss: 2.3950378292166197

Epoch: 5| Step: 6
Training loss: 0.19364643943969473
Validation loss: 2.3596383659299756

Epoch: 5| Step: 7
Training loss: 0.17627222582165586
Validation loss: 2.3475413802552674

Epoch: 5| Step: 8
Training loss: 0.13344790824570704
Validation loss: 2.3543266948380976

Epoch: 5| Step: 9
Training loss: 0.08731431097290632
Validation loss: 2.335771810024971

Epoch: 5| Step: 10
Training loss: 0.08141058895149295
Validation loss: 2.311635049363192

Epoch: 612| Step: 0
Training loss: 0.1853165250730255
Validation loss: 2.274808078037083

Epoch: 5| Step: 1
Training loss: 0.18896164016570907
Validation loss: 2.3247275301873755

Epoch: 5| Step: 2
Training loss: 0.18503264393705804
Validation loss: 2.3527184159903314

Epoch: 5| Step: 3
Training loss: 0.153827617619241
Validation loss: 2.353796953214576

Epoch: 5| Step: 4
Training loss: 0.10556338179752475
Validation loss: 2.350439229982709

Epoch: 5| Step: 5
Training loss: 0.14663696606623142
Validation loss: 2.3458452437060995

Epoch: 5| Step: 6
Training loss: 0.1787841105093087
Validation loss: 2.376986928920835

Epoch: 5| Step: 7
Training loss: 0.08990303447026274
Validation loss: 2.35959055165239

Epoch: 5| Step: 8
Training loss: 0.10107205337932332
Validation loss: 2.3799304765422433

Epoch: 5| Step: 9
Training loss: 0.18433227528957677
Validation loss: 2.365381014051977

Epoch: 5| Step: 10
Training loss: 0.13767223300006243
Validation loss: 2.3686340508419543

Epoch: 613| Step: 0
Training loss: 0.2033454175944912
Validation loss: 2.359517453440554

Epoch: 5| Step: 1
Training loss: 0.18685164211530042
Validation loss: 2.3403999713427237

Epoch: 5| Step: 2
Training loss: 0.1355755421118895
Validation loss: 2.321011353749457

Epoch: 5| Step: 3
Training loss: 0.17433929827316472
Validation loss: 2.341774813030094

Epoch: 5| Step: 4
Training loss: 0.17275580215923247
Validation loss: 2.348408497827565

Epoch: 5| Step: 5
Training loss: 0.18526415115366035
Validation loss: 2.404515927401274

Epoch: 5| Step: 6
Training loss: 0.18333353716304315
Validation loss: 2.443361194360366

Epoch: 5| Step: 7
Training loss: 0.12683392577460087
Validation loss: 2.4027704747794183

Epoch: 5| Step: 8
Training loss: 0.16449413966042117
Validation loss: 2.369168888130373

Epoch: 5| Step: 9
Training loss: 0.12211898977582264
Validation loss: 2.3590869408535133

Epoch: 5| Step: 10
Training loss: 0.11001024377332076
Validation loss: 2.3246126683020365

Epoch: 614| Step: 0
Training loss: 0.20751388542124596
Validation loss: 2.2810956391689463

Epoch: 5| Step: 1
Training loss: 0.16198424025211966
Validation loss: 2.3065031752433054

Epoch: 5| Step: 2
Training loss: 0.18452541875064285
Validation loss: 2.3037015685578957

Epoch: 5| Step: 3
Training loss: 0.2257994842426054
Validation loss: 2.3133563623644138

Epoch: 5| Step: 4
Training loss: 0.1198012259200603
Validation loss: 2.34488345504749

Epoch: 5| Step: 5
Training loss: 0.20776994742789823
Validation loss: 2.409641257849915

Epoch: 5| Step: 6
Training loss: 0.22841731834237475
Validation loss: 2.4433822590762486

Epoch: 5| Step: 7
Training loss: 0.15526910691850024
Validation loss: 2.4008043491462714

Epoch: 5| Step: 8
Training loss: 0.13900712282211977
Validation loss: 2.409185565655817

Epoch: 5| Step: 9
Training loss: 0.09759945648499561
Validation loss: 2.3702404114354536

Epoch: 5| Step: 10
Training loss: 0.13149581409498606
Validation loss: 2.328926125325509

Epoch: 615| Step: 0
Training loss: 0.20454490004088638
Validation loss: 2.333562788763471

Epoch: 5| Step: 1
Training loss: 0.13069506193373343
Validation loss: 2.2998752609379167

Epoch: 5| Step: 2
Training loss: 0.08989400080311878
Validation loss: 2.323282728832994

Epoch: 5| Step: 3
Training loss: 0.17616047219634814
Validation loss: 2.3283696563271836

Epoch: 5| Step: 4
Training loss: 0.11652790247732171
Validation loss: 2.3205981108662197

Epoch: 5| Step: 5
Training loss: 0.24222435209400442
Validation loss: 2.297399737597898

Epoch: 5| Step: 6
Training loss: 0.12122300002855994
Validation loss: 2.322418679505042

Epoch: 5| Step: 7
Training loss: 0.24722630397561912
Validation loss: 2.3747465541387927

Epoch: 5| Step: 8
Training loss: 0.13633137045989496
Validation loss: 2.407468118021293

Epoch: 5| Step: 9
Training loss: 0.12955252160982794
Validation loss: 2.3836790739189375

Epoch: 5| Step: 10
Training loss: 0.12595373139012428
Validation loss: 2.3890273087541236

Epoch: 616| Step: 0
Training loss: 0.13695800146940454
Validation loss: 2.382548079267282

Epoch: 5| Step: 1
Training loss: 0.09845459293886971
Validation loss: 2.366958197146344

Epoch: 5| Step: 2
Training loss: 0.10945287980127745
Validation loss: 2.33930710565268

Epoch: 5| Step: 3
Training loss: 0.13144437781082374
Validation loss: 2.3434491681601246

Epoch: 5| Step: 4
Training loss: 0.13090774012437137
Validation loss: 2.307395030989926

Epoch: 5| Step: 5
Training loss: 0.2580555290551908
Validation loss: 2.292988075314246

Epoch: 5| Step: 6
Training loss: 0.1760551861268628
Validation loss: 2.3035466772518176

Epoch: 5| Step: 7
Training loss: 0.18313015580649625
Validation loss: 2.328778176587059

Epoch: 5| Step: 8
Training loss: 0.1079600206012245
Validation loss: 2.3387235261120245

Epoch: 5| Step: 9
Training loss: 0.12507247313978412
Validation loss: 2.324500715649262

Epoch: 5| Step: 10
Training loss: 0.11449847185581048
Validation loss: 2.3751660349935433

Epoch: 617| Step: 0
Training loss: 0.1609333653520729
Validation loss: 2.337402353072719

Epoch: 5| Step: 1
Training loss: 0.08844184741802347
Validation loss: 2.354760380338555

Epoch: 5| Step: 2
Training loss: 0.18393231686033784
Validation loss: 2.3635205490683164

Epoch: 5| Step: 3
Training loss: 0.16060706400273275
Validation loss: 2.32017443371036

Epoch: 5| Step: 4
Training loss: 0.27873617858576916
Validation loss: 2.2884063368227276

Epoch: 5| Step: 5
Training loss: 0.10156470993278603
Validation loss: 2.3473997994480253

Epoch: 5| Step: 6
Training loss: 0.16852250968936247
Validation loss: 2.361444452470607

Epoch: 5| Step: 7
Training loss: 0.1056679768991892
Validation loss: 2.4030558141349196

Epoch: 5| Step: 8
Training loss: 0.12729659201957066
Validation loss: 2.395772996510975

Epoch: 5| Step: 9
Training loss: 0.1802026682075328
Validation loss: 2.4023964683443517

Epoch: 5| Step: 10
Training loss: 0.12041261829788985
Validation loss: 2.3982283817147354

Epoch: 618| Step: 0
Training loss: 0.09744836137470667
Validation loss: 2.3547268468809177

Epoch: 5| Step: 1
Training loss: 0.1346236393190333
Validation loss: 2.3639313379554436

Epoch: 5| Step: 2
Training loss: 0.15113168670164
Validation loss: 2.3601096045354044

Epoch: 5| Step: 3
Training loss: 0.12744696740188094
Validation loss: 2.3468630444440746

Epoch: 5| Step: 4
Training loss: 0.15815751277696086
Validation loss: 2.3243836951451273

Epoch: 5| Step: 5
Training loss: 0.19118234617414173
Validation loss: 2.325814073010327

Epoch: 5| Step: 6
Training loss: 0.11472720538573895
Validation loss: 2.3196604529888125

Epoch: 5| Step: 7
Training loss: 0.16557291691965986
Validation loss: 2.3073230655068606

Epoch: 5| Step: 8
Training loss: 0.11893473485758256
Validation loss: 2.347353788010807

Epoch: 5| Step: 9
Training loss: 0.10827472861855346
Validation loss: 2.329739141751228

Epoch: 5| Step: 10
Training loss: 0.2653745704895367
Validation loss: 2.37166408889625

Epoch: 619| Step: 0
Training loss: 0.12015623527943456
Validation loss: 2.328800343241949

Epoch: 5| Step: 1
Training loss: 0.1353320367774296
Validation loss: 2.355762075758893

Epoch: 5| Step: 2
Training loss: 0.18681628022336721
Validation loss: 2.3346752872549756

Epoch: 5| Step: 3
Training loss: 0.11042050090316459
Validation loss: 2.3308270863096943

Epoch: 5| Step: 4
Training loss: 0.16586884012046277
Validation loss: 2.3342981636347795

Epoch: 5| Step: 5
Training loss: 0.14271237310784973
Validation loss: 2.3281823136274946

Epoch: 5| Step: 6
Training loss: 0.19907405684981982
Validation loss: 2.335179213695765

Epoch: 5| Step: 7
Training loss: 0.2211667230235773
Validation loss: 2.3516552283070493

Epoch: 5| Step: 8
Training loss: 0.12525849882813517
Validation loss: 2.3137771839904473

Epoch: 5| Step: 9
Training loss: 0.10953545721465811
Validation loss: 2.341028391350402

Epoch: 5| Step: 10
Training loss: 0.14038548337535664
Validation loss: 2.355944244878842

Epoch: 620| Step: 0
Training loss: 0.12113267134627773
Validation loss: 2.364309139887068

Epoch: 5| Step: 1
Training loss: 0.16554009267497352
Validation loss: 2.3647020481917815

Epoch: 5| Step: 2
Training loss: 0.10908290910495659
Validation loss: 2.3645193389375887

Epoch: 5| Step: 3
Training loss: 0.08649040758515168
Validation loss: 2.3867100860705373

Epoch: 5| Step: 4
Training loss: 0.10756306905806504
Validation loss: 2.3542971591645108

Epoch: 5| Step: 5
Training loss: 0.1446295932029673
Validation loss: 2.3719319991834658

Epoch: 5| Step: 6
Training loss: 0.17730033191777858
Validation loss: 2.3679241695332354

Epoch: 5| Step: 7
Training loss: 0.12784090674284732
Validation loss: 2.345399183094187

Epoch: 5| Step: 8
Training loss: 0.13858961970078582
Validation loss: 2.340625677277477

Epoch: 5| Step: 9
Training loss: 0.22232622651231868
Validation loss: 2.314243642619883

Epoch: 5| Step: 10
Training loss: 0.0823624204373985
Validation loss: 2.347971928161423

Epoch: 621| Step: 0
Training loss: 0.1291312003345744
Validation loss: 2.34822772669467

Epoch: 5| Step: 1
Training loss: 0.09055980112860212
Validation loss: 2.3817201695131525

Epoch: 5| Step: 2
Training loss: 0.1679023622570006
Validation loss: 2.357453090803166

Epoch: 5| Step: 3
Training loss: 0.08601723299160582
Validation loss: 2.344516263007013

Epoch: 5| Step: 4
Training loss: 0.23012411082208387
Validation loss: 2.354880643300705

Epoch: 5| Step: 5
Training loss: 0.10992583295505691
Validation loss: 2.390003806471706

Epoch: 5| Step: 6
Training loss: 0.10255618633611423
Validation loss: 2.358899305503137

Epoch: 5| Step: 7
Training loss: 0.10563840290108475
Validation loss: 2.3355986959616986

Epoch: 5| Step: 8
Training loss: 0.12603098410926653
Validation loss: 2.353450071136469

Epoch: 5| Step: 9
Training loss: 0.13235215740228906
Validation loss: 2.3294592722343417

Epoch: 5| Step: 10
Training loss: 0.13573125754063592
Validation loss: 2.3425159216126406

Epoch: 622| Step: 0
Training loss: 0.11521721566670845
Validation loss: 2.3164983869164937

Epoch: 5| Step: 1
Training loss: 0.1744491221527739
Validation loss: 2.3304301019789615

Epoch: 5| Step: 2
Training loss: 0.09781160395336748
Validation loss: 2.3208971808520795

Epoch: 5| Step: 3
Training loss: 0.1738996037312534
Validation loss: 2.3107704395136737

Epoch: 5| Step: 4
Training loss: 0.10292513690711907
Validation loss: 2.344059607179259

Epoch: 5| Step: 5
Training loss: 0.0896976464709408
Validation loss: 2.349635807652744

Epoch: 5| Step: 6
Training loss: 0.11433553497509466
Validation loss: 2.338214932474005

Epoch: 5| Step: 7
Training loss: 0.11928064295214759
Validation loss: 2.337691907565343

Epoch: 5| Step: 8
Training loss: 0.17409696042673867
Validation loss: 2.3610201538726003

Epoch: 5| Step: 9
Training loss: 0.15035002643477458
Validation loss: 2.3309526050512974

Epoch: 5| Step: 10
Training loss: 0.14475141329931862
Validation loss: 2.3143958795682598

Epoch: 623| Step: 0
Training loss: 0.16439799791532986
Validation loss: 2.300666940927151

Epoch: 5| Step: 1
Training loss: 0.14471349953245857
Validation loss: 2.3488438850797566

Epoch: 5| Step: 2
Training loss: 0.13193108692512406
Validation loss: 2.348812399872272

Epoch: 5| Step: 3
Training loss: 0.22184265129246092
Validation loss: 2.367532128932948

Epoch: 5| Step: 4
Training loss: 0.14721739786256305
Validation loss: 2.3576373768715317

Epoch: 5| Step: 5
Training loss: 0.10200976957664327
Validation loss: 2.3761595468199843

Epoch: 5| Step: 6
Training loss: 0.11604560984749708
Validation loss: 2.37164265472262

Epoch: 5| Step: 7
Training loss: 0.23860563804423487
Validation loss: 2.3138727073263006

Epoch: 5| Step: 8
Training loss: 0.14271292127998308
Validation loss: 2.3017944854819676

Epoch: 5| Step: 9
Training loss: 0.12560915042758897
Validation loss: 2.297172013199265

Epoch: 5| Step: 10
Training loss: 0.19146172050583382
Validation loss: 2.2936639429462247

Epoch: 624| Step: 0
Training loss: 0.20389983141505338
Validation loss: 2.3018430971377764

Epoch: 5| Step: 1
Training loss: 0.11628419506482157
Validation loss: 2.328855893255595

Epoch: 5| Step: 2
Training loss: 0.19493891272685757
Validation loss: 2.3402934629255623

Epoch: 5| Step: 3
Training loss: 0.14971423072698395
Validation loss: 2.388467429413763

Epoch: 5| Step: 4
Training loss: 0.1199702045894538
Validation loss: 2.389823348607236

Epoch: 5| Step: 5
Training loss: 0.20153638537479088
Validation loss: 2.403246276501533

Epoch: 5| Step: 6
Training loss: 0.13434883988590815
Validation loss: 2.3698166932564204

Epoch: 5| Step: 7
Training loss: 0.17136773115654005
Validation loss: 2.366645979830594

Epoch: 5| Step: 8
Training loss: 0.12658117533286836
Validation loss: 2.29496940066127

Epoch: 5| Step: 9
Training loss: 0.16732338637181352
Validation loss: 2.2851350746684695

Epoch: 5| Step: 10
Training loss: 0.2014262988615492
Validation loss: 2.3141076946797976

Epoch: 625| Step: 0
Training loss: 0.15639799976597268
Validation loss: 2.316195091427856

Epoch: 5| Step: 1
Training loss: 0.11098457331681984
Validation loss: 2.3543408266186985

Epoch: 5| Step: 2
Training loss: 0.19372779734358295
Validation loss: 2.3752268071405123

Epoch: 5| Step: 3
Training loss: 0.18558114387874802
Validation loss: 2.413467678551397

Epoch: 5| Step: 4
Training loss: 0.13983132983840424
Validation loss: 2.421013564634879

Epoch: 5| Step: 5
Training loss: 0.21590941303060313
Validation loss: 2.4039125093368345

Epoch: 5| Step: 6
Training loss: 0.18017464407378475
Validation loss: 2.311792182740961

Epoch: 5| Step: 7
Training loss: 0.12408706955038179
Validation loss: 2.2860106408016505

Epoch: 5| Step: 8
Training loss: 0.2452875890049989
Validation loss: 2.293889409374529

Epoch: 5| Step: 9
Training loss: 0.14713836908894784
Validation loss: 2.285192814146957

Epoch: 5| Step: 10
Training loss: 0.20683492492773736
Validation loss: 2.290994377377947

Epoch: 626| Step: 0
Training loss: 0.11631502971250357
Validation loss: 2.386961159441929

Epoch: 5| Step: 1
Training loss: 0.14591322495821182
Validation loss: 2.441836851937342

Epoch: 5| Step: 2
Training loss: 0.29221404459933004
Validation loss: 2.45048983048886

Epoch: 5| Step: 3
Training loss: 0.17910481390710947
Validation loss: 2.427679530967082

Epoch: 5| Step: 4
Training loss: 0.1762802828735347
Validation loss: 2.3133883467511365

Epoch: 5| Step: 5
Training loss: 0.1929559255500685
Validation loss: 2.2599897651139322

Epoch: 5| Step: 6
Training loss: 0.31806447699350854
Validation loss: 2.2640356212406894

Epoch: 5| Step: 7
Training loss: 0.16329014151607113
Validation loss: 2.29797783987571

Epoch: 5| Step: 8
Training loss: 0.23688641329422408
Validation loss: 2.3077433276524943

Epoch: 5| Step: 9
Training loss: 0.18982625378333182
Validation loss: 2.3639862150825137

Epoch: 5| Step: 10
Training loss: 0.18062510714808258
Validation loss: 2.3980538313644226

Epoch: 627| Step: 0
Training loss: 0.11477583641758278
Validation loss: 2.395187539321109

Epoch: 5| Step: 1
Training loss: 0.1916989016032304
Validation loss: 2.401385978889398

Epoch: 5| Step: 2
Training loss: 0.19898506558331763
Validation loss: 2.381465248708468

Epoch: 5| Step: 3
Training loss: 0.19270282600025168
Validation loss: 2.319049102196501

Epoch: 5| Step: 4
Training loss: 0.3342170128190886
Validation loss: 2.257634886545458

Epoch: 5| Step: 5
Training loss: 0.24771757118788693
Validation loss: 2.257304525077292

Epoch: 5| Step: 6
Training loss: 0.3079718225868734
Validation loss: 2.2731959626909646

Epoch: 5| Step: 7
Training loss: 0.13288359982839681
Validation loss: 2.3101974687872557

Epoch: 5| Step: 8
Training loss: 0.1412465215566945
Validation loss: 2.392396901181649

Epoch: 5| Step: 9
Training loss: 0.3531224503889286
Validation loss: 2.4597460301292955

Epoch: 5| Step: 10
Training loss: 0.18223970331073774
Validation loss: 2.4616236628453225

Epoch: 628| Step: 0
Training loss: 0.19006770036790213
Validation loss: 2.4150294789723716

Epoch: 5| Step: 1
Training loss: 0.20997855533937662
Validation loss: 2.3820270666029746

Epoch: 5| Step: 2
Training loss: 0.24132430929697452
Validation loss: 2.3009888016197393

Epoch: 5| Step: 3
Training loss: 0.24728021262288863
Validation loss: 2.2801814310938626

Epoch: 5| Step: 4
Training loss: 0.34011111210989187
Validation loss: 2.2444060151643246

Epoch: 5| Step: 5
Training loss: 0.15630932516155457
Validation loss: 2.2666250486401656

Epoch: 5| Step: 6
Training loss: 0.16914392935011763
Validation loss: 2.3225757776037605

Epoch: 5| Step: 7
Training loss: 0.23922192051316962
Validation loss: 2.3409689183578206

Epoch: 5| Step: 8
Training loss: 0.31296641590316454
Validation loss: 2.3694040244879577

Epoch: 5| Step: 9
Training loss: 0.17877766140071852
Validation loss: 2.3819952225037992

Epoch: 5| Step: 10
Training loss: 0.24663318820987468
Validation loss: 2.3280782486358484

Epoch: 629| Step: 0
Training loss: 0.20071089807101436
Validation loss: 2.2886673568300338

Epoch: 5| Step: 1
Training loss: 0.2681441064175904
Validation loss: 2.2609425906340817

Epoch: 5| Step: 2
Training loss: 0.26588650060887936
Validation loss: 2.2698000009122423

Epoch: 5| Step: 3
Training loss: 0.17783983476371357
Validation loss: 2.2963222407488773

Epoch: 5| Step: 4
Training loss: 0.2560794844503138
Validation loss: 2.313796465695953

Epoch: 5| Step: 5
Training loss: 0.20092370178699856
Validation loss: 2.3159957289835855

Epoch: 5| Step: 6
Training loss: 0.2865518619555404
Validation loss: 2.3720475310334606

Epoch: 5| Step: 7
Training loss: 0.17367349669350995
Validation loss: 2.380464144578957

Epoch: 5| Step: 8
Training loss: 0.13841742017962114
Validation loss: 2.3988971831521813

Epoch: 5| Step: 9
Training loss: 0.2164952697545505
Validation loss: 2.360679892029759

Epoch: 5| Step: 10
Training loss: 0.1484426321849019
Validation loss: 2.428295193314942

Epoch: 630| Step: 0
Training loss: 0.2611473307714349
Validation loss: 2.3702969046423394

Epoch: 5| Step: 1
Training loss: 0.19624494180113625
Validation loss: 2.3243131096384184

Epoch: 5| Step: 2
Training loss: 0.2946764575390148
Validation loss: 2.322942311944437

Epoch: 5| Step: 3
Training loss: 0.16226372781525128
Validation loss: 2.3290516166296076

Epoch: 5| Step: 4
Training loss: 0.14794685815117667
Validation loss: 2.317421713999484

Epoch: 5| Step: 5
Training loss: 0.14822557655319815
Validation loss: 2.3110285275942024

Epoch: 5| Step: 6
Training loss: 0.13691819493564383
Validation loss: 2.360544956797687

Epoch: 5| Step: 7
Training loss: 0.11899009168621426
Validation loss: 2.3837242927780222

Epoch: 5| Step: 8
Training loss: 0.21098606998610558
Validation loss: 2.3610957720855654

Epoch: 5| Step: 9
Training loss: 0.1853566650395754
Validation loss: 2.3650538796831655

Epoch: 5| Step: 10
Training loss: 0.10240702074725298
Validation loss: 2.341876065499545

Epoch: 631| Step: 0
Training loss: 0.20286543474194196
Validation loss: 2.328384943190952

Epoch: 5| Step: 1
Training loss: 0.21266428263094297
Validation loss: 2.286297826556977

Epoch: 5| Step: 2
Training loss: 0.14519710137366207
Validation loss: 2.26335936217092

Epoch: 5| Step: 3
Training loss: 0.20935034571152852
Validation loss: 2.2738897879218345

Epoch: 5| Step: 4
Training loss: 0.17897897433288112
Validation loss: 2.317808438930194

Epoch: 5| Step: 5
Training loss: 0.22490245936693473
Validation loss: 2.3067426253038286

Epoch: 5| Step: 6
Training loss: 0.21359698327330456
Validation loss: 2.3870621453932714

Epoch: 5| Step: 7
Training loss: 0.2394919203777127
Validation loss: 2.4352054971317396

Epoch: 5| Step: 8
Training loss: 0.40046702330623
Validation loss: 2.4604840312844285

Epoch: 5| Step: 9
Training loss: 0.18875307345887998
Validation loss: 2.327431512100382

Epoch: 5| Step: 10
Training loss: 0.08398833376403475
Validation loss: 2.273562504402751

Epoch: 632| Step: 0
Training loss: 0.3321361824725908
Validation loss: 2.2702658522680954

Epoch: 5| Step: 1
Training loss: 0.28047234259299497
Validation loss: 2.2987751470716393

Epoch: 5| Step: 2
Training loss: 0.20179690326686045
Validation loss: 2.3212943012338694

Epoch: 5| Step: 3
Training loss: 0.0923172476137804
Validation loss: 2.369865366751939

Epoch: 5| Step: 4
Training loss: 0.24357572432569563
Validation loss: 2.440791263688802

Epoch: 5| Step: 5
Training loss: 0.27958933316902657
Validation loss: 2.476453724975465

Epoch: 5| Step: 6
Training loss: 0.19931560854492847
Validation loss: 2.4103148866179174

Epoch: 5| Step: 7
Training loss: 0.28348330088787604
Validation loss: 2.346671683072693

Epoch: 5| Step: 8
Training loss: 0.1602708534424759
Validation loss: 2.306087012658942

Epoch: 5| Step: 9
Training loss: 0.15216923768605448
Validation loss: 2.31850332793278

Epoch: 5| Step: 10
Training loss: 0.2050578879407731
Validation loss: 2.290737143322055

Epoch: 633| Step: 0
Training loss: 0.15160948526487927
Validation loss: 2.2759448972071614

Epoch: 5| Step: 1
Training loss: 0.3435130820094554
Validation loss: 2.28670849285274

Epoch: 5| Step: 2
Training loss: 0.20964091552409456
Validation loss: 2.284700824351299

Epoch: 5| Step: 3
Training loss: 0.23266370998332936
Validation loss: 2.3289533287993853

Epoch: 5| Step: 4
Training loss: 0.15140626464465753
Validation loss: 2.398958407810933

Epoch: 5| Step: 5
Training loss: 0.20249145080627848
Validation loss: 2.4080049198522686

Epoch: 5| Step: 6
Training loss: 0.21497211956128873
Validation loss: 2.4157934570241797

Epoch: 5| Step: 7
Training loss: 0.2555213617401527
Validation loss: 2.3907356051636355

Epoch: 5| Step: 8
Training loss: 0.18425402713629252
Validation loss: 2.3483371164644593

Epoch: 5| Step: 9
Training loss: 0.12415530860946289
Validation loss: 2.3423067972317413

Epoch: 5| Step: 10
Training loss: 0.21236220232611336
Validation loss: 2.316524696057517

Epoch: 634| Step: 0
Training loss: 0.13468362552619545
Validation loss: 2.3310404299456766

Epoch: 5| Step: 1
Training loss: 0.2654809140252628
Validation loss: 2.330714352019215

Epoch: 5| Step: 2
Training loss: 0.24388967968495243
Validation loss: 2.309362448669967

Epoch: 5| Step: 3
Training loss: 0.15330192431352888
Validation loss: 2.328102357815804

Epoch: 5| Step: 4
Training loss: 0.1274319860842645
Validation loss: 2.366764132139117

Epoch: 5| Step: 5
Training loss: 0.1801585781082633
Validation loss: 2.367364701955181

Epoch: 5| Step: 6
Training loss: 0.22091194840049747
Validation loss: 2.440752479879647

Epoch: 5| Step: 7
Training loss: 0.1863091821058385
Validation loss: 2.4207830501973224

Epoch: 5| Step: 8
Training loss: 0.2013515577346256
Validation loss: 2.35179903994331

Epoch: 5| Step: 9
Training loss: 0.20374739184494742
Validation loss: 2.2916751018678427

Epoch: 5| Step: 10
Training loss: 0.20430493603296987
Validation loss: 2.2930560251130236

Epoch: 635| Step: 0
Training loss: 0.23614774866565574
Validation loss: 2.2825995402300703

Epoch: 5| Step: 1
Training loss: 0.2832903760480501
Validation loss: 2.293547530971889

Epoch: 5| Step: 2
Training loss: 0.13292345152875462
Validation loss: 2.305109846384869

Epoch: 5| Step: 3
Training loss: 0.25927438393033103
Validation loss: 2.3443781928977856

Epoch: 5| Step: 4
Training loss: 0.22038917661378224
Validation loss: 2.354052062153074

Epoch: 5| Step: 5
Training loss: 0.1619374846116489
Validation loss: 2.3422636376538954

Epoch: 5| Step: 6
Training loss: 0.22102610830536767
Validation loss: 2.3916239036580755

Epoch: 5| Step: 7
Training loss: 0.17028857815579063
Validation loss: 2.3219449945628243

Epoch: 5| Step: 8
Training loss: 0.15005672842443069
Validation loss: 2.283201033734962

Epoch: 5| Step: 9
Training loss: 0.16423671986144706
Validation loss: 2.2750476755985933

Epoch: 5| Step: 10
Training loss: 0.26285044971037197
Validation loss: 2.263578976348119

Epoch: 636| Step: 0
Training loss: 0.21686908447267098
Validation loss: 2.312323236735485

Epoch: 5| Step: 1
Training loss: 0.12517842582091102
Validation loss: 2.33467287588849

Epoch: 5| Step: 2
Training loss: 0.24379235413182257
Validation loss: 2.322147582170319

Epoch: 5| Step: 3
Training loss: 0.22711822164474013
Validation loss: 2.3547016597295687

Epoch: 5| Step: 4
Training loss: 0.14939938267418465
Validation loss: 2.3763534530007178

Epoch: 5| Step: 5
Training loss: 0.1230821596750476
Validation loss: 2.337654821701816

Epoch: 5| Step: 6
Training loss: 0.10017265673439316
Validation loss: 2.3614491228201873

Epoch: 5| Step: 7
Training loss: 0.18606501061895525
Validation loss: 2.3138391768298847

Epoch: 5| Step: 8
Training loss: 0.20660715030319723
Validation loss: 2.2828579735303145

Epoch: 5| Step: 9
Training loss: 0.15504586439140666
Validation loss: 2.305203970633307

Epoch: 5| Step: 10
Training loss: 0.28800658086701975
Validation loss: 2.3053330496396156

Epoch: 637| Step: 0
Training loss: 0.19183008795977766
Validation loss: 2.2994213275122206

Epoch: 5| Step: 1
Training loss: 0.2925527798480969
Validation loss: 2.327229956186699

Epoch: 5| Step: 2
Training loss: 0.2139062105573084
Validation loss: 2.2841804866104303

Epoch: 5| Step: 3
Training loss: 0.21298067130897816
Validation loss: 2.2508509370175633

Epoch: 5| Step: 4
Training loss: 0.3138522692341406
Validation loss: 2.299510877318112

Epoch: 5| Step: 5
Training loss: 0.1640676599781037
Validation loss: 2.3104834407055854

Epoch: 5| Step: 6
Training loss: 0.15529514257008
Validation loss: 2.3491914145697232

Epoch: 5| Step: 7
Training loss: 0.2063750899168543
Validation loss: 2.4220884612106546

Epoch: 5| Step: 8
Training loss: 0.17217280856560624
Validation loss: 2.3926357847812008

Epoch: 5| Step: 9
Training loss: 0.1939968044617557
Validation loss: 2.341913719977136

Epoch: 5| Step: 10
Training loss: 0.27579237669633255
Validation loss: 2.2779940672882395

Epoch: 638| Step: 0
Training loss: 0.17264339066858062
Validation loss: 2.325644183928736

Epoch: 5| Step: 1
Training loss: 0.17571463912274546
Validation loss: 2.3015749835043993

Epoch: 5| Step: 2
Training loss: 0.13904700782290286
Validation loss: 2.3184987900089657

Epoch: 5| Step: 3
Training loss: 0.1700461634637075
Validation loss: 2.300494883843972

Epoch: 5| Step: 4
Training loss: 0.2168384031094778
Validation loss: 2.3316820017490896

Epoch: 5| Step: 5
Training loss: 0.23235544489536278
Validation loss: 2.311858977715184

Epoch: 5| Step: 6
Training loss: 0.18175780710547854
Validation loss: 2.352091069631445

Epoch: 5| Step: 7
Training loss: 0.2097175251744939
Validation loss: 2.3575759022992884

Epoch: 5| Step: 8
Training loss: 0.1974396646060367
Validation loss: 2.3795796525344293

Epoch: 5| Step: 9
Training loss: 0.1813492026645706
Validation loss: 2.3813203391666478

Epoch: 5| Step: 10
Training loss: 0.19062926764479465
Validation loss: 2.3435643976479636

Epoch: 639| Step: 0
Training loss: 0.16485378768154538
Validation loss: 2.3379413524769537

Epoch: 5| Step: 1
Training loss: 0.1912646158872837
Validation loss: 2.339020435293875

Epoch: 5| Step: 2
Training loss: 0.217826400611553
Validation loss: 2.273600265302798

Epoch: 5| Step: 3
Training loss: 0.1286484423332934
Validation loss: 2.2876240680333577

Epoch: 5| Step: 4
Training loss: 0.18479567599937718
Validation loss: 2.2672414035477906

Epoch: 5| Step: 5
Training loss: 0.20885995922633324
Validation loss: 2.2884659687563875

Epoch: 5| Step: 6
Training loss: 0.133485498405533
Validation loss: 2.3071191872741825

Epoch: 5| Step: 7
Training loss: 0.16903040512531106
Validation loss: 2.33462405726033

Epoch: 5| Step: 8
Training loss: 0.17926197875936425
Validation loss: 2.361372121667723

Epoch: 5| Step: 9
Training loss: 0.13294280896259303
Validation loss: 2.3544135128074464

Epoch: 5| Step: 10
Training loss: 0.2567333408140097
Validation loss: 2.3761811732897873

Epoch: 640| Step: 0
Training loss: 0.17257471597567456
Validation loss: 2.3756227481006675

Epoch: 5| Step: 1
Training loss: 0.14083933390957687
Validation loss: 2.318490304045485

Epoch: 5| Step: 2
Training loss: 0.1569459792770554
Validation loss: 2.301314760227909

Epoch: 5| Step: 3
Training loss: 0.13489182409811604
Validation loss: 2.284751562467136

Epoch: 5| Step: 4
Training loss: 0.23924388455703777
Validation loss: 2.242588879246358

Epoch: 5| Step: 5
Training loss: 0.15467069707989015
Validation loss: 2.334879042569828

Epoch: 5| Step: 6
Training loss: 0.09103085611463112
Validation loss: 2.3144991358734575

Epoch: 5| Step: 7
Training loss: 0.13656664288825113
Validation loss: 2.378076022907235

Epoch: 5| Step: 8
Training loss: 0.20457991072911777
Validation loss: 2.3675260163358294

Epoch: 5| Step: 9
Training loss: 0.25664362216168995
Validation loss: 2.353889637062686

Epoch: 5| Step: 10
Training loss: 0.20740820198468238
Validation loss: 2.348734101413884

Epoch: 641| Step: 0
Training loss: 0.11048683804153935
Validation loss: 2.3390261236916836

Epoch: 5| Step: 1
Training loss: 0.18045817835506153
Validation loss: 2.32931217290393

Epoch: 5| Step: 2
Training loss: 0.17018720585198396
Validation loss: 2.3126760314352

Epoch: 5| Step: 3
Training loss: 0.16549419532526374
Validation loss: 2.3244985407728835

Epoch: 5| Step: 4
Training loss: 0.14000212955132457
Validation loss: 2.2969966541179323

Epoch: 5| Step: 5
Training loss: 0.15966916448396218
Validation loss: 2.3345706628444907

Epoch: 5| Step: 6
Training loss: 0.12825554558827423
Validation loss: 2.3427236348306217

Epoch: 5| Step: 7
Training loss: 0.13433408751992854
Validation loss: 2.353224658336032

Epoch: 5| Step: 8
Training loss: 0.10338958228180556
Validation loss: 2.3284844187612435

Epoch: 5| Step: 9
Training loss: 0.15695184792568226
Validation loss: 2.300250090234692

Epoch: 5| Step: 10
Training loss: 0.10138161764170542
Validation loss: 2.3345061199014796

Epoch: 642| Step: 0
Training loss: 0.15767252800216236
Validation loss: 2.315999820739507

Epoch: 5| Step: 1
Training loss: 0.11955196475381276
Validation loss: 2.3406380276228655

Epoch: 5| Step: 2
Training loss: 0.18598788203929545
Validation loss: 2.3640521447912906

Epoch: 5| Step: 3
Training loss: 0.13993953163185127
Validation loss: 2.3639097206087247

Epoch: 5| Step: 4
Training loss: 0.15687867291394844
Validation loss: 2.3665378160539507

Epoch: 5| Step: 5
Training loss: 0.13117656413109627
Validation loss: 2.336045067952951

Epoch: 5| Step: 6
Training loss: 0.11325965050606271
Validation loss: 2.3068051155856635

Epoch: 5| Step: 7
Training loss: 0.15878571862222504
Validation loss: 2.308194099095845

Epoch: 5| Step: 8
Training loss: 0.2500819876461015
Validation loss: 2.3129917426785678

Epoch: 5| Step: 9
Training loss: 0.17116530154623896
Validation loss: 2.329491311341483

Epoch: 5| Step: 10
Training loss: 0.14320427432642188
Validation loss: 2.3613320855479207

Epoch: 643| Step: 0
Training loss: 0.18408986284914491
Validation loss: 2.3756226293947504

Epoch: 5| Step: 1
Training loss: 0.1487096625419455
Validation loss: 2.38057933666154

Epoch: 5| Step: 2
Training loss: 0.13102424967384835
Validation loss: 2.367898488860516

Epoch: 5| Step: 3
Training loss: 0.1459974269742278
Validation loss: 2.4014584586616454

Epoch: 5| Step: 4
Training loss: 0.15255196110190977
Validation loss: 2.303577609270748

Epoch: 5| Step: 5
Training loss: 0.0978702108617031
Validation loss: 2.2901088063867148

Epoch: 5| Step: 6
Training loss: 0.18837225206645228
Validation loss: 2.2869266618368593

Epoch: 5| Step: 7
Training loss: 0.17596327046652951
Validation loss: 2.2743923464294338

Epoch: 5| Step: 8
Training loss: 0.1784148134016236
Validation loss: 2.2608361926419285

Epoch: 5| Step: 9
Training loss: 0.20032447741937928
Validation loss: 2.268087111920914

Epoch: 5| Step: 10
Training loss: 0.1389176849640369
Validation loss: 2.270345976697844

Epoch: 644| Step: 0
Training loss: 0.11412267355124911
Validation loss: 2.3378678449223274

Epoch: 5| Step: 1
Training loss: 0.18872166049808203
Validation loss: 2.335742218627086

Epoch: 5| Step: 2
Training loss: 0.16090787156525754
Validation loss: 2.332127776793203

Epoch: 5| Step: 3
Training loss: 0.20430524601024336
Validation loss: 2.378131973156986

Epoch: 5| Step: 4
Training loss: 0.1282194074697092
Validation loss: 2.3410151253726093

Epoch: 5| Step: 5
Training loss: 0.14993841128770038
Validation loss: 2.3463566111892122

Epoch: 5| Step: 6
Training loss: 0.12295460268796171
Validation loss: 2.2985322370327657

Epoch: 5| Step: 7
Training loss: 0.161304544198719
Validation loss: 2.3394975122732062

Epoch: 5| Step: 8
Training loss: 0.1847158090644176
Validation loss: 2.314171827245399

Epoch: 5| Step: 9
Training loss: 0.1317238154291446
Validation loss: 2.313422169132912

Epoch: 5| Step: 10
Training loss: 0.17451716597583122
Validation loss: 2.2982835042880803

Epoch: 645| Step: 0
Training loss: 0.1420893325009931
Validation loss: 2.302030294825659

Epoch: 5| Step: 1
Training loss: 0.17753444157830292
Validation loss: 2.2923006167185

Epoch: 5| Step: 2
Training loss: 0.14080536057963736
Validation loss: 2.3423076126295976

Epoch: 5| Step: 3
Training loss: 0.20068888413632968
Validation loss: 2.3854836433344695

Epoch: 5| Step: 4
Training loss: 0.1373933497713683
Validation loss: 2.3498953121555597

Epoch: 5| Step: 5
Training loss: 0.14284272658674765
Validation loss: 2.360447164686282

Epoch: 5| Step: 6
Training loss: 0.11253783861240899
Validation loss: 2.365981625601068

Epoch: 5| Step: 7
Training loss: 0.180126007565679
Validation loss: 2.3503715844488426

Epoch: 5| Step: 8
Training loss: 0.14864965386037626
Validation loss: 2.334072208832781

Epoch: 5| Step: 9
Training loss: 0.22424127020370993
Validation loss: 2.3204379257233447

Epoch: 5| Step: 10
Training loss: 0.059824483380805
Validation loss: 2.323587285943307

Epoch: 646| Step: 0
Training loss: 0.1790587162862996
Validation loss: 2.2955362317724655

Epoch: 5| Step: 1
Training loss: 0.11302453170898524
Validation loss: 2.2970172736726338

Epoch: 5| Step: 2
Training loss: 0.17445529352148056
Validation loss: 2.3216551004530146

Epoch: 5| Step: 3
Training loss: 0.1292922713506026
Validation loss: 2.331481115672582

Epoch: 5| Step: 4
Training loss: 0.23494081545796797
Validation loss: 2.3442726892348134

Epoch: 5| Step: 5
Training loss: 0.24499498794012456
Validation loss: 2.3689636803369623

Epoch: 5| Step: 6
Training loss: 0.1602983193511398
Validation loss: 2.295411621005051

Epoch: 5| Step: 7
Training loss: 0.16634273839338745
Validation loss: 2.2937666924223454

Epoch: 5| Step: 8
Training loss: 0.26754351204084853
Validation loss: 2.2868054327590603

Epoch: 5| Step: 9
Training loss: 0.14603289647462947
Validation loss: 2.2908959932164756

Epoch: 5| Step: 10
Training loss: 0.2878469736864842
Validation loss: 2.303773025948599

Epoch: 647| Step: 0
Training loss: 0.20420822751255818
Validation loss: 2.321610809927314

Epoch: 5| Step: 1
Training loss: 0.17108102036939668
Validation loss: 2.36772184873781

Epoch: 5| Step: 2
Training loss: 0.19608983799653154
Validation loss: 2.384263767350959

Epoch: 5| Step: 3
Training loss: 0.23203587736145923
Validation loss: 2.3721273986798987

Epoch: 5| Step: 4
Training loss: 0.17737234364026627
Validation loss: 2.353938087722998

Epoch: 5| Step: 5
Training loss: 0.10131592345469247
Validation loss: 2.3280386293792787

Epoch: 5| Step: 6
Training loss: 0.19632524185401362
Validation loss: 2.332257034299715

Epoch: 5| Step: 7
Training loss: 0.14310142427031572
Validation loss: 2.328239887907535

Epoch: 5| Step: 8
Training loss: 0.19657272036352627
Validation loss: 2.3338776732113007

Epoch: 5| Step: 9
Training loss: 0.20828021484941947
Validation loss: 2.3609170506605124

Epoch: 5| Step: 10
Training loss: 0.16837139440766796
Validation loss: 2.369522314891031

Epoch: 648| Step: 0
Training loss: 0.2153595281851021
Validation loss: 2.3686721366007184

Epoch: 5| Step: 1
Training loss: 0.0860927815304959
Validation loss: 2.3674927811815167

Epoch: 5| Step: 2
Training loss: 0.11900126796285314
Validation loss: 2.392206462348433

Epoch: 5| Step: 3
Training loss: 0.11844056070771436
Validation loss: 2.3731654561698434

Epoch: 5| Step: 4
Training loss: 0.1284512088819722
Validation loss: 2.3692298757849364

Epoch: 5| Step: 5
Training loss: 0.20726634119271703
Validation loss: 2.3882708689278696

Epoch: 5| Step: 6
Training loss: 0.08151070876064107
Validation loss: 2.3440529379363837

Epoch: 5| Step: 7
Training loss: 0.10182912838892065
Validation loss: 2.351680192450705

Epoch: 5| Step: 8
Training loss: 0.197250781114528
Validation loss: 2.316285152659645

Epoch: 5| Step: 9
Training loss: 0.09896344299258619
Validation loss: 2.3324928996834875

Epoch: 5| Step: 10
Training loss: 0.1895870836292221
Validation loss: 2.3101984009403416

Epoch: 649| Step: 0
Training loss: 0.20098398749127236
Validation loss: 2.340969090291571

Epoch: 5| Step: 1
Training loss: 0.07634287371505334
Validation loss: 2.349871298377632

Epoch: 5| Step: 2
Training loss: 0.2017722014828999
Validation loss: 2.378125860854873

Epoch: 5| Step: 3
Training loss: 0.11209926891964768
Validation loss: 2.378613384566747

Epoch: 5| Step: 4
Training loss: 0.11340189954444616
Validation loss: 2.3933344310180185

Epoch: 5| Step: 5
Training loss: 0.10273482844756684
Validation loss: 2.368581778658981

Epoch: 5| Step: 6
Training loss: 0.11585251648319944
Validation loss: 2.3402384933245464

Epoch: 5| Step: 7
Training loss: 0.1243137656004066
Validation loss: 2.351896104883533

Epoch: 5| Step: 8
Training loss: 0.13903777781411342
Validation loss: 2.3432687627670172

Epoch: 5| Step: 9
Training loss: 0.18139168898557684
Validation loss: 2.300812918935359

Epoch: 5| Step: 10
Training loss: 0.1387999976993294
Validation loss: 2.3283994217975246

Epoch: 650| Step: 0
Training loss: 0.1304549615392372
Validation loss: 2.3190520460628785

Epoch: 5| Step: 1
Training loss: 0.18110892708665152
Validation loss: 2.3006146193376886

Epoch: 5| Step: 2
Training loss: 0.1530216734516651
Validation loss: 2.330239137351526

Epoch: 5| Step: 3
Training loss: 0.08447041536126174
Validation loss: 2.3572204766440366

Epoch: 5| Step: 4
Training loss: 0.09430848604821897
Validation loss: 2.3595827778973417

Epoch: 5| Step: 5
Training loss: 0.1099561129539827
Validation loss: 2.3761671875837598

Epoch: 5| Step: 6
Training loss: 0.15917876892760927
Validation loss: 2.365413150639475

Epoch: 5| Step: 7
Training loss: 0.14775750356910256
Validation loss: 2.377103354497786

Epoch: 5| Step: 8
Training loss: 0.2101972447795487
Validation loss: 2.3930326569891953

Epoch: 5| Step: 9
Training loss: 0.09381844088647232
Validation loss: 2.3197565518612473

Epoch: 5| Step: 10
Training loss: 0.24264943768530256
Validation loss: 2.2997762886918616

Epoch: 651| Step: 0
Training loss: 0.10951021045444179
Validation loss: 2.3060040995328888

Epoch: 5| Step: 1
Training loss: 0.12361014205001217
Validation loss: 2.2806026311674925

Epoch: 5| Step: 2
Training loss: 0.10411044828985819
Validation loss: 2.285690389070978

Epoch: 5| Step: 3
Training loss: 0.09336927213840102
Validation loss: 2.3032089515744456

Epoch: 5| Step: 4
Training loss: 0.14840457576217786
Validation loss: 2.307724515270383

Epoch: 5| Step: 5
Training loss: 0.08613387072598626
Validation loss: 2.328593625710102

Epoch: 5| Step: 6
Training loss: 0.18492440665558438
Validation loss: 2.3293548284618746

Epoch: 5| Step: 7
Training loss: 0.16769420564767376
Validation loss: 2.3370274915784957

Epoch: 5| Step: 8
Training loss: 0.0888745336325866
Validation loss: 2.344793451942048

Epoch: 5| Step: 9
Training loss: 0.14800650365738544
Validation loss: 2.3443419093942155

Epoch: 5| Step: 10
Training loss: 0.1972946863201827
Validation loss: 2.325910858922588

Epoch: 652| Step: 0
Training loss: 0.13788171420604745
Validation loss: 2.2634819930960273

Epoch: 5| Step: 1
Training loss: 0.10249533402039862
Validation loss: 2.3059830044691076

Epoch: 5| Step: 2
Training loss: 0.08958172424760162
Validation loss: 2.2705497758462845

Epoch: 5| Step: 3
Training loss: 0.21365177506328348
Validation loss: 2.285312612670787

Epoch: 5| Step: 4
Training loss: 0.11673066980325285
Validation loss: 2.3306928360381183

Epoch: 5| Step: 5
Training loss: 0.0708520834955478
Validation loss: 2.33734124404423

Epoch: 5| Step: 6
Training loss: 0.10118065173694284
Validation loss: 2.33835970116774

Epoch: 5| Step: 7
Training loss: 0.11190702273078874
Validation loss: 2.318827350771216

Epoch: 5| Step: 8
Training loss: 0.15824657597008931
Validation loss: 2.358803754700335

Epoch: 5| Step: 9
Training loss: 0.10848595548657275
Validation loss: 2.3472967011216643

Epoch: 5| Step: 10
Training loss: 0.11833148712732247
Validation loss: 2.3132877188890073

Epoch: 653| Step: 0
Training loss: 0.0882801906133908
Validation loss: 2.3447454448277787

Epoch: 5| Step: 1
Training loss: 0.09494764543321252
Validation loss: 2.3164495648672014

Epoch: 5| Step: 2
Training loss: 0.2147195196775017
Validation loss: 2.2966804313160867

Epoch: 5| Step: 3
Training loss: 0.10012658794324948
Validation loss: 2.353962715092231

Epoch: 5| Step: 4
Training loss: 0.17548112679546574
Validation loss: 2.319949937739279

Epoch: 5| Step: 5
Training loss: 0.10422815852326092
Validation loss: 2.3273779526740705

Epoch: 5| Step: 6
Training loss: 0.1037651599155016
Validation loss: 2.3187915718339505

Epoch: 5| Step: 7
Training loss: 0.11989525707707373
Validation loss: 2.3280332604630702

Epoch: 5| Step: 8
Training loss: 0.10587346169751505
Validation loss: 2.3605071580416013

Epoch: 5| Step: 9
Training loss: 0.11413077277314644
Validation loss: 2.387083141475884

Epoch: 5| Step: 10
Training loss: 0.10655796144838287
Validation loss: 2.3973072394120987

Epoch: 654| Step: 0
Training loss: 0.12274085698533528
Validation loss: 2.4167742112968282

Epoch: 5| Step: 1
Training loss: 0.15718399087541973
Validation loss: 2.38247553693606

Epoch: 5| Step: 2
Training loss: 0.10408779575722306
Validation loss: 2.3754157742440642

Epoch: 5| Step: 3
Training loss: 0.10775523478947593
Validation loss: 2.330575523094717

Epoch: 5| Step: 4
Training loss: 0.10551477681845332
Validation loss: 2.3231089743357525

Epoch: 5| Step: 5
Training loss: 0.12783848081074292
Validation loss: 2.3134412415865646

Epoch: 5| Step: 6
Training loss: 0.12075067188587402
Validation loss: 2.303242723643633

Epoch: 5| Step: 7
Training loss: 0.1308216424887509
Validation loss: 2.317724303664882

Epoch: 5| Step: 8
Training loss: 0.09326744062037197
Validation loss: 2.31976443697524

Epoch: 5| Step: 9
Training loss: 0.16416721748628366
Validation loss: 2.3218374181898604

Epoch: 5| Step: 10
Training loss: 0.17244134599427755
Validation loss: 2.3446483413568227

Epoch: 655| Step: 0
Training loss: 0.09577542610104789
Validation loss: 2.335657801893751

Epoch: 5| Step: 1
Training loss: 0.15580717159047494
Validation loss: 2.33131390375442

Epoch: 5| Step: 2
Training loss: 0.1366807884919859
Validation loss: 2.344705144486242

Epoch: 5| Step: 3
Training loss: 0.1174309546119495
Validation loss: 2.3289979381542025

Epoch: 5| Step: 4
Training loss: 0.0916839523932523
Validation loss: 2.3705010918267675

Epoch: 5| Step: 5
Training loss: 0.0855029427713159
Validation loss: 2.30380065217744

Epoch: 5| Step: 6
Training loss: 0.08181804527394895
Validation loss: 2.3437794826389657

Epoch: 5| Step: 7
Training loss: 0.08637439417781859
Validation loss: 2.320901467210985

Epoch: 5| Step: 8
Training loss: 0.18837186642985038
Validation loss: 2.339483655737062

Epoch: 5| Step: 9
Training loss: 0.10730569799424435
Validation loss: 2.331874939531777

Epoch: 5| Step: 10
Training loss: 0.19998235773713902
Validation loss: 2.350111430023843

Epoch: 656| Step: 0
Training loss: 0.12183406857753785
Validation loss: 2.3407293596680856

Epoch: 5| Step: 1
Training loss: 0.08071766727849666
Validation loss: 2.3430008870356156

Epoch: 5| Step: 2
Training loss: 0.11567983358114653
Validation loss: 2.3358080592783104

Epoch: 5| Step: 3
Training loss: 0.20347742538576763
Validation loss: 2.3435910100573913

Epoch: 5| Step: 4
Training loss: 0.1324533346385316
Validation loss: 2.3448332041085647

Epoch: 5| Step: 5
Training loss: 0.10358920721015803
Validation loss: 2.3233350968927624

Epoch: 5| Step: 6
Training loss: 0.08129936080620641
Validation loss: 2.3128454476385754

Epoch: 5| Step: 7
Training loss: 0.15034070982482747
Validation loss: 2.327932815784567

Epoch: 5| Step: 8
Training loss: 0.1112038521072224
Validation loss: 2.3456631356562476

Epoch: 5| Step: 9
Training loss: 0.11987757237238071
Validation loss: 2.322746264167508

Epoch: 5| Step: 10
Training loss: 0.09919341507300455
Validation loss: 2.3342491131223713

Epoch: 657| Step: 0
Training loss: 0.1735013075464597
Validation loss: 2.353717314225089

Epoch: 5| Step: 1
Training loss: 0.10953416057942353
Validation loss: 2.347879641278514

Epoch: 5| Step: 2
Training loss: 0.11780692742522444
Validation loss: 2.364900383874369

Epoch: 5| Step: 3
Training loss: 0.12865057066510271
Validation loss: 2.3499484554651895

Epoch: 5| Step: 4
Training loss: 0.13154288322372318
Validation loss: 2.3176508014355317

Epoch: 5| Step: 5
Training loss: 0.08536099102484818
Validation loss: 2.368713090906517

Epoch: 5| Step: 6
Training loss: 0.10700158783673706
Validation loss: 2.2916117213160914

Epoch: 5| Step: 7
Training loss: 0.1273127889732898
Validation loss: 2.3461914570597027

Epoch: 5| Step: 8
Training loss: 0.11622908795087361
Validation loss: 2.340477555677432

Epoch: 5| Step: 9
Training loss: 0.1796204089259588
Validation loss: 2.322753830646043

Epoch: 5| Step: 10
Training loss: 0.13500862741939054
Validation loss: 2.3214358546694824

Epoch: 658| Step: 0
Training loss: 0.09768887928399612
Validation loss: 2.348607391348784

Epoch: 5| Step: 1
Training loss: 0.060613232443268
Validation loss: 2.3388628513103225

Epoch: 5| Step: 2
Training loss: 0.07627660325363379
Validation loss: 2.332041204290454

Epoch: 5| Step: 3
Training loss: 0.10418409311042509
Validation loss: 2.3680715183773

Epoch: 5| Step: 4
Training loss: 0.12167574246962637
Validation loss: 2.3767941902462435

Epoch: 5| Step: 5
Training loss: 0.13218703672314347
Validation loss: 2.3779129311067497

Epoch: 5| Step: 6
Training loss: 0.19234703428375843
Validation loss: 2.38505124595544

Epoch: 5| Step: 7
Training loss: 0.16168292957307825
Validation loss: 2.3433806075637493

Epoch: 5| Step: 8
Training loss: 0.1608575492707108
Validation loss: 2.3199994375389443

Epoch: 5| Step: 9
Training loss: 0.1262295570440951
Validation loss: 2.2791984268239918

Epoch: 5| Step: 10
Training loss: 0.1537379874793566
Validation loss: 2.290477252355235

Epoch: 659| Step: 0
Training loss: 0.13813372409680058
Validation loss: 2.3071897743426795

Epoch: 5| Step: 1
Training loss: 0.16599526560987837
Validation loss: 2.337824443292597

Epoch: 5| Step: 2
Training loss: 0.1079075670578975
Validation loss: 2.3676850957327353

Epoch: 5| Step: 3
Training loss: 0.12891245595847475
Validation loss: 2.375944321161095

Epoch: 5| Step: 4
Training loss: 0.14241040175737185
Validation loss: 2.385664022191229

Epoch: 5| Step: 5
Training loss: 0.13143988565519205
Validation loss: 2.401536573721277

Epoch: 5| Step: 6
Training loss: 0.18856046716380118
Validation loss: 2.399206747541126

Epoch: 5| Step: 7
Training loss: 0.11070902914995215
Validation loss: 2.394939212606959

Epoch: 5| Step: 8
Training loss: 0.18053124159142184
Validation loss: 2.395813446354733

Epoch: 5| Step: 9
Training loss: 0.10256439531836907
Validation loss: 2.3591802851228234

Epoch: 5| Step: 10
Training loss: 0.22514076399376937
Validation loss: 2.357578049380163

Epoch: 660| Step: 0
Training loss: 0.14820684531875764
Validation loss: 2.3416845943760336

Epoch: 5| Step: 1
Training loss: 0.08343663524597468
Validation loss: 2.3590643056864717

Epoch: 5| Step: 2
Training loss: 0.11518011593760004
Validation loss: 2.3695851727003006

Epoch: 5| Step: 3
Training loss: 0.12206504428939562
Validation loss: 2.352873318865124

Epoch: 5| Step: 4
Training loss: 0.1528748034992967
Validation loss: 2.3841670373695396

Epoch: 5| Step: 5
Training loss: 0.18271968637366445
Validation loss: 2.370902482361649

Epoch: 5| Step: 6
Training loss: 0.11901992014566289
Validation loss: 2.3696371344307714

Epoch: 5| Step: 7
Training loss: 0.11343586170442695
Validation loss: 2.364377866701854

Epoch: 5| Step: 8
Training loss: 0.16893634882614814
Validation loss: 2.360871349356563

Epoch: 5| Step: 9
Training loss: 0.13277464214877197
Validation loss: 2.3740767696026026

Epoch: 5| Step: 10
Training loss: 0.20582022140770237
Validation loss: 2.3475811748912885

Epoch: 661| Step: 0
Training loss: 0.08162301526132126
Validation loss: 2.3501379912040012

Epoch: 5| Step: 1
Training loss: 0.08239158326837298
Validation loss: 2.377908551838815

Epoch: 5| Step: 2
Training loss: 0.18687115957147774
Validation loss: 2.3884964094519185

Epoch: 5| Step: 3
Training loss: 0.10873590811048645
Validation loss: 2.3619334960441063

Epoch: 5| Step: 4
Training loss: 0.15631267959343417
Validation loss: 2.357193077351297

Epoch: 5| Step: 5
Training loss: 0.10790909900406283
Validation loss: 2.333829837556587

Epoch: 5| Step: 6
Training loss: 0.1542482178660837
Validation loss: 2.3152345144745032

Epoch: 5| Step: 7
Training loss: 0.10227495421949642
Validation loss: 2.3048851688990752

Epoch: 5| Step: 8
Training loss: 0.1409624739255929
Validation loss: 2.3048780459498635

Epoch: 5| Step: 9
Training loss: 0.2013509194345277
Validation loss: 2.3290972697684795

Epoch: 5| Step: 10
Training loss: 0.09631139755422591
Validation loss: 2.3166126330201884

Epoch: 662| Step: 0
Training loss: 0.1471292542261414
Validation loss: 2.312205541167036

Epoch: 5| Step: 1
Training loss: 0.0856201587390826
Validation loss: 2.309360996648866

Epoch: 5| Step: 2
Training loss: 0.13445242824517986
Validation loss: 2.33366448129851

Epoch: 5| Step: 3
Training loss: 0.08352953257973349
Validation loss: 2.336689573798444

Epoch: 5| Step: 4
Training loss: 0.16494954519930405
Validation loss: 2.29646679251383

Epoch: 5| Step: 5
Training loss: 0.08040730922348222
Validation loss: 2.32745023183377

Epoch: 5| Step: 6
Training loss: 0.14756650493224807
Validation loss: 2.324631380958908

Epoch: 5| Step: 7
Training loss: 0.13906448153894924
Validation loss: 2.308079421849303

Epoch: 5| Step: 8
Training loss: 0.0851645988343885
Validation loss: 2.317218760242903

Epoch: 5| Step: 9
Training loss: 0.1282987294851103
Validation loss: 2.3211361792546574

Epoch: 5| Step: 10
Training loss: 0.11485579907534856
Validation loss: 2.310726334768046

Epoch: 663| Step: 0
Training loss: 0.12984136766297846
Validation loss: 2.3343060940773728

Epoch: 5| Step: 1
Training loss: 0.07945240475694805
Validation loss: 2.3051226928574615

Epoch: 5| Step: 2
Training loss: 0.12064489886101422
Validation loss: 2.3255280014567186

Epoch: 5| Step: 3
Training loss: 0.155634974989194
Validation loss: 2.2999362609470455

Epoch: 5| Step: 4
Training loss: 0.15318430803009123
Validation loss: 2.3575477203902455

Epoch: 5| Step: 5
Training loss: 0.13483365042073123
Validation loss: 2.3255087734771824

Epoch: 5| Step: 6
Training loss: 0.09727105945127988
Validation loss: 2.361212347692566

Epoch: 5| Step: 7
Training loss: 0.13172855949302145
Validation loss: 2.3694231372639125

Epoch: 5| Step: 8
Training loss: 0.08394973894540032
Validation loss: 2.3537369761645994

Epoch: 5| Step: 9
Training loss: 0.1386121634752308
Validation loss: 2.3732397705553434

Epoch: 5| Step: 10
Training loss: 0.08571108881897295
Validation loss: 2.3376869846775605

Epoch: 664| Step: 0
Training loss: 0.06632830098019855
Validation loss: 2.340559919846198

Epoch: 5| Step: 1
Training loss: 0.12458225944770135
Validation loss: 2.3248171836895963

Epoch: 5| Step: 2
Training loss: 0.1250767323299077
Validation loss: 2.3213419065195167

Epoch: 5| Step: 3
Training loss: 0.13851714568532458
Validation loss: 2.340447717074813

Epoch: 5| Step: 4
Training loss: 0.15521221033370203
Validation loss: 2.347721638049658

Epoch: 5| Step: 5
Training loss: 0.08612418218007763
Validation loss: 2.3795994153645927

Epoch: 5| Step: 6
Training loss: 0.20041294828707515
Validation loss: 2.40016207284493

Epoch: 5| Step: 7
Training loss: 0.13575197088539068
Validation loss: 2.3785987546293095

Epoch: 5| Step: 8
Training loss: 0.1375366676813292
Validation loss: 2.407013487405254

Epoch: 5| Step: 9
Training loss: 0.13140866305735877
Validation loss: 2.376915915055351

Epoch: 5| Step: 10
Training loss: 0.11317285745171381
Validation loss: 2.35186865119212

Epoch: 665| Step: 0
Training loss: 0.11214303531477461
Validation loss: 2.348597006245245

Epoch: 5| Step: 1
Training loss: 0.13010329698888395
Validation loss: 2.343115780793042

Epoch: 5| Step: 2
Training loss: 0.1409569372488932
Validation loss: 2.309263059714513

Epoch: 5| Step: 3
Training loss: 0.2230608175833657
Validation loss: 2.2939609204062203

Epoch: 5| Step: 4
Training loss: 0.09335624438188317
Validation loss: 2.3288296320532584

Epoch: 5| Step: 5
Training loss: 0.17720205637430744
Validation loss: 2.4112518671500247

Epoch: 5| Step: 6
Training loss: 0.2542215150660482
Validation loss: 2.4272333253977356

Epoch: 5| Step: 7
Training loss: 0.15780180786283862
Validation loss: 2.411576600488981

Epoch: 5| Step: 8
Training loss: 0.18030038262348866
Validation loss: 2.372266928246643

Epoch: 5| Step: 9
Training loss: 0.1249861225233008
Validation loss: 2.340248559496521

Epoch: 5| Step: 10
Training loss: 0.16633703310088188
Validation loss: 2.343578509001023

Epoch: 666| Step: 0
Training loss: 0.11864134262638601
Validation loss: 2.3206532805618636

Epoch: 5| Step: 1
Training loss: 0.08892431623666787
Validation loss: 2.337392171544571

Epoch: 5| Step: 2
Training loss: 0.11571919158384628
Validation loss: 2.331807503056469

Epoch: 5| Step: 3
Training loss: 0.13624051101478205
Validation loss: 2.3246364285421706

Epoch: 5| Step: 4
Training loss: 0.17317306124287699
Validation loss: 2.3207844441749113

Epoch: 5| Step: 5
Training loss: 0.17774976936156364
Validation loss: 2.3258358931517344

Epoch: 5| Step: 6
Training loss: 0.1386175317799244
Validation loss: 2.3225978985945166

Epoch: 5| Step: 7
Training loss: 0.2011404475876064
Validation loss: 2.3025872651483112

Epoch: 5| Step: 8
Training loss: 0.21714279140015644
Validation loss: 2.3086563556325483

Epoch: 5| Step: 9
Training loss: 0.10789274705295725
Validation loss: 2.3235449821118315

Epoch: 5| Step: 10
Training loss: 0.19520532528531792
Validation loss: 2.338734992579449

Epoch: 667| Step: 0
Training loss: 0.16884520216173857
Validation loss: 2.3665198989539094

Epoch: 5| Step: 1
Training loss: 0.11858795522522227
Validation loss: 2.3660938778969753

Epoch: 5| Step: 2
Training loss: 0.1411175446707744
Validation loss: 2.378317353325648

Epoch: 5| Step: 3
Training loss: 0.13446942549227112
Validation loss: 2.356084420544585

Epoch: 5| Step: 4
Training loss: 0.16993156493170852
Validation loss: 2.3485652175443104

Epoch: 5| Step: 5
Training loss: 0.17166380477883844
Validation loss: 2.3615454849871025

Epoch: 5| Step: 6
Training loss: 0.16157166799951805
Validation loss: 2.3145037469900354

Epoch: 5| Step: 7
Training loss: 0.15857246636640382
Validation loss: 2.337883843306136

Epoch: 5| Step: 8
Training loss: 0.2150117910556295
Validation loss: 2.3183286136654555

Epoch: 5| Step: 9
Training loss: 0.15932612324140194
Validation loss: 2.324692222520358

Epoch: 5| Step: 10
Training loss: 0.13978663189098328
Validation loss: 2.3346635257804085

Epoch: 668| Step: 0
Training loss: 0.10298180590709488
Validation loss: 2.3239526795076415

Epoch: 5| Step: 1
Training loss: 0.14715633131159855
Validation loss: 2.3322881417398817

Epoch: 5| Step: 2
Training loss: 0.12347417766364212
Validation loss: 2.383391841269525

Epoch: 5| Step: 3
Training loss: 0.1563095336984946
Validation loss: 2.3518720167009866

Epoch: 5| Step: 4
Training loss: 0.22379109973482908
Validation loss: 2.3394666480828237

Epoch: 5| Step: 5
Training loss: 0.0908435976265337
Validation loss: 2.33070305123166

Epoch: 5| Step: 6
Training loss: 0.10877515012174657
Validation loss: 2.3516550299010035

Epoch: 5| Step: 7
Training loss: 0.09802084098417932
Validation loss: 2.3341635913051526

Epoch: 5| Step: 8
Training loss: 0.08123789328003615
Validation loss: 2.362667346320062

Epoch: 5| Step: 9
Training loss: 0.15101873220966103
Validation loss: 2.318593485261194

Epoch: 5| Step: 10
Training loss: 0.1000251879858831
Validation loss: 2.3438773789879317

Epoch: 669| Step: 0
Training loss: 0.14072652304510141
Validation loss: 2.3085668674123463

Epoch: 5| Step: 1
Training loss: 0.14484722806094097
Validation loss: 2.333463599997222

Epoch: 5| Step: 2
Training loss: 0.16386473179865177
Validation loss: 2.3429870512185955

Epoch: 5| Step: 3
Training loss: 0.09520199028702511
Validation loss: 2.3140384586272407

Epoch: 5| Step: 4
Training loss: 0.12312047513160512
Validation loss: 2.3474108276428534

Epoch: 5| Step: 5
Training loss: 0.15577257650673018
Validation loss: 2.357220970400449

Epoch: 5| Step: 6
Training loss: 0.17867624748694388
Validation loss: 2.3638205194777115

Epoch: 5| Step: 7
Training loss: 0.1745286178731903
Validation loss: 2.3399886129361818

Epoch: 5| Step: 8
Training loss: 0.13181352071561322
Validation loss: 2.3450079852706667

Epoch: 5| Step: 9
Training loss: 0.08870488321262875
Validation loss: 2.3296254411634254

Epoch: 5| Step: 10
Training loss: 0.09494877834298754
Validation loss: 2.3070773040370836

Epoch: 670| Step: 0
Training loss: 0.1623560568244937
Validation loss: 2.32421455634547

Epoch: 5| Step: 1
Training loss: 0.10867076465278035
Validation loss: 2.331958025571143

Epoch: 5| Step: 2
Training loss: 0.1270610130816934
Validation loss: 2.356257332419695

Epoch: 5| Step: 3
Training loss: 0.17015629525792664
Validation loss: 2.3667359756911774

Epoch: 5| Step: 4
Training loss: 0.15274514601794664
Validation loss: 2.359923124870603

Epoch: 5| Step: 5
Training loss: 0.1490513319254315
Validation loss: 2.378677454958909

Epoch: 5| Step: 6
Training loss: 0.14278333736596263
Validation loss: 2.361624218439291

Epoch: 5| Step: 7
Training loss: 0.1331803193244351
Validation loss: 2.3236898375899493

Epoch: 5| Step: 8
Training loss: 0.142579940888847
Validation loss: 2.3149170132663097

Epoch: 5| Step: 9
Training loss: 0.1419221078076375
Validation loss: 2.323336293287827

Epoch: 5| Step: 10
Training loss: 0.13863054519265372
Validation loss: 2.2914749620935435

Epoch: 671| Step: 0
Training loss: 0.10262560598244451
Validation loss: 2.3223591223734474

Epoch: 5| Step: 1
Training loss: 0.11650286799541378
Validation loss: 2.3206732038570754

Epoch: 5| Step: 2
Training loss: 0.09375640728036273
Validation loss: 2.309545428215218

Epoch: 5| Step: 3
Training loss: 0.11539640995832429
Validation loss: 2.359885446515451

Epoch: 5| Step: 4
Training loss: 0.16350499866329454
Validation loss: 2.3467344701731796

Epoch: 5| Step: 5
Training loss: 0.1698809168769717
Validation loss: 2.3607253320672137

Epoch: 5| Step: 6
Training loss: 0.14459441067899395
Validation loss: 2.345735341557541

Epoch: 5| Step: 7
Training loss: 0.10317289999216266
Validation loss: 2.337364456461039

Epoch: 5| Step: 8
Training loss: 0.18731925120134388
Validation loss: 2.2884828210873494

Epoch: 5| Step: 9
Training loss: 0.17131547995998678
Validation loss: 2.3064919959133667

Epoch: 5| Step: 10
Training loss: 0.1999729037556141
Validation loss: 2.280545380820176

Epoch: 672| Step: 0
Training loss: 0.1320282839831305
Validation loss: 2.2898085286801937

Epoch: 5| Step: 1
Training loss: 0.21018464346880603
Validation loss: 2.335766773334525

Epoch: 5| Step: 2
Training loss: 0.08800200187068281
Validation loss: 2.324483098209774

Epoch: 5| Step: 3
Training loss: 0.08576631836446716
Validation loss: 2.3616206035839795

Epoch: 5| Step: 4
Training loss: 0.11520318239532162
Validation loss: 2.348086102657043

Epoch: 5| Step: 5
Training loss: 0.1586278347914904
Validation loss: 2.368005710860257

Epoch: 5| Step: 6
Training loss: 0.1035942462834457
Validation loss: 2.3587505190801386

Epoch: 5| Step: 7
Training loss: 0.15777928479648642
Validation loss: 2.350114946951219

Epoch: 5| Step: 8
Training loss: 0.12688841270854703
Validation loss: 2.3585433086268304

Epoch: 5| Step: 9
Training loss: 0.09019735452117243
Validation loss: 2.319897958221451

Epoch: 5| Step: 10
Training loss: 0.13826683152455124
Validation loss: 2.2933995613154106

Epoch: 673| Step: 0
Training loss: 0.1633435344997493
Validation loss: 2.2880679318353745

Epoch: 5| Step: 1
Training loss: 0.2029580200213517
Validation loss: 2.2573462256481895

Epoch: 5| Step: 2
Training loss: 0.20288268638182982
Validation loss: 2.283080516930128

Epoch: 5| Step: 3
Training loss: 0.16318187632818398
Validation loss: 2.3387757191581966

Epoch: 5| Step: 4
Training loss: 0.23136982712921683
Validation loss: 2.4036423102941313

Epoch: 5| Step: 5
Training loss: 0.08133771613527457
Validation loss: 2.3922193796109936

Epoch: 5| Step: 6
Training loss: 0.16855878106690503
Validation loss: 2.4116567822703163

Epoch: 5| Step: 7
Training loss: 0.17235594347499
Validation loss: 2.4105642083847707

Epoch: 5| Step: 8
Training loss: 0.16539187781787873
Validation loss: 2.4047766826724586

Epoch: 5| Step: 9
Training loss: 0.13048320050647982
Validation loss: 2.3496547159930516

Epoch: 5| Step: 10
Training loss: 0.14789009801465436
Validation loss: 2.353033977206279

Epoch: 674| Step: 0
Training loss: 0.15641995366148914
Validation loss: 2.322896080932017

Epoch: 5| Step: 1
Training loss: 0.16013916436216988
Validation loss: 2.3285107664303344

Epoch: 5| Step: 2
Training loss: 0.08940545231870978
Validation loss: 2.3554794617930406

Epoch: 5| Step: 3
Training loss: 0.22329805130742483
Validation loss: 2.372956195859187

Epoch: 5| Step: 4
Training loss: 0.1154584403461996
Validation loss: 2.3545487117736164

Epoch: 5| Step: 5
Training loss: 0.1120615898865008
Validation loss: 2.3041020999506263

Epoch: 5| Step: 6
Training loss: 0.10766638757896617
Validation loss: 2.309423119689749

Epoch: 5| Step: 7
Training loss: 0.14833570428111575
Validation loss: 2.2660739837109842

Epoch: 5| Step: 8
Training loss: 0.13249959971484415
Validation loss: 2.31682588859036

Epoch: 5| Step: 9
Training loss: 0.2116132262087271
Validation loss: 2.286230704724682

Epoch: 5| Step: 10
Training loss: 0.23028206133689835
Validation loss: 2.3215750236431227

Epoch: 675| Step: 0
Training loss: 0.11266830705863631
Validation loss: 2.362224055808551

Epoch: 5| Step: 1
Training loss: 0.16580818343088738
Validation loss: 2.423805896642267

Epoch: 5| Step: 2
Training loss: 0.2579180616953216
Validation loss: 2.416862282210448

Epoch: 5| Step: 3
Training loss: 0.10914772978576355
Validation loss: 2.387372870706845

Epoch: 5| Step: 4
Training loss: 0.14902767385358387
Validation loss: 2.327162880285734

Epoch: 5| Step: 5
Training loss: 0.13927395501010942
Validation loss: 2.329994913609957

Epoch: 5| Step: 6
Training loss: 0.12962586937744328
Validation loss: 2.3015262224941857

Epoch: 5| Step: 7
Training loss: 0.19188964876365036
Validation loss: 2.2992253274502854

Epoch: 5| Step: 8
Training loss: 0.15025571865911166
Validation loss: 2.2962428904281027

Epoch: 5| Step: 9
Training loss: 0.2027525145807507
Validation loss: 2.3318177903261

Epoch: 5| Step: 10
Training loss: 0.17054882255522125
Validation loss: 2.3204651842387634

Epoch: 676| Step: 0
Training loss: 0.10118622033769123
Validation loss: 2.3299340817818517

Epoch: 5| Step: 1
Training loss: 0.14681366466638382
Validation loss: 2.348230281351425

Epoch: 5| Step: 2
Training loss: 0.13467186969863734
Validation loss: 2.4030839056133826

Epoch: 5| Step: 3
Training loss: 0.17547855275932997
Validation loss: 2.4048191520687014

Epoch: 5| Step: 4
Training loss: 0.14626582054008566
Validation loss: 2.351673965066315

Epoch: 5| Step: 5
Training loss: 0.1657828100995749
Validation loss: 2.3556937135436273

Epoch: 5| Step: 6
Training loss: 0.1118923537351581
Validation loss: 2.291379214369187

Epoch: 5| Step: 7
Training loss: 0.20746325459063508
Validation loss: 2.273574609022223

Epoch: 5| Step: 8
Training loss: 0.11101928755230553
Validation loss: 2.282373560434702

Epoch: 5| Step: 9
Training loss: 0.1872223646304972
Validation loss: 2.247127185856975

Epoch: 5| Step: 10
Training loss: 0.15888318138194157
Validation loss: 2.258443387793387

Epoch: 677| Step: 0
Training loss: 0.18761355220045436
Validation loss: 2.2403653377600494

Epoch: 5| Step: 1
Training loss: 0.14427298591284057
Validation loss: 2.2554421244832104

Epoch: 5| Step: 2
Training loss: 0.15573843420216796
Validation loss: 2.332632891570136

Epoch: 5| Step: 3
Training loss: 0.1808311823546317
Validation loss: 2.359056464993923

Epoch: 5| Step: 4
Training loss: 0.19331098201401142
Validation loss: 2.356672948067809

Epoch: 5| Step: 5
Training loss: 0.18625717731702096
Validation loss: 2.393160707433091

Epoch: 5| Step: 6
Training loss: 0.12589918022161564
Validation loss: 2.377633987331578

Epoch: 5| Step: 7
Training loss: 0.17191759578694454
Validation loss: 2.3426986611479665

Epoch: 5| Step: 8
Training loss: 0.12993442972509103
Validation loss: 2.346176224480031

Epoch: 5| Step: 9
Training loss: 0.17629680264075992
Validation loss: 2.2806602566439325

Epoch: 5| Step: 10
Training loss: 0.15341802994054865
Validation loss: 2.264955934849573

Epoch: 678| Step: 0
Training loss: 0.1618588246360928
Validation loss: 2.2662008886703293

Epoch: 5| Step: 1
Training loss: 0.13826664292509044
Validation loss: 2.316775265884735

Epoch: 5| Step: 2
Training loss: 0.12159704399107928
Validation loss: 2.326910762282165

Epoch: 5| Step: 3
Training loss: 0.09826186743285051
Validation loss: 2.326699569797523

Epoch: 5| Step: 4
Training loss: 0.10140098052594726
Validation loss: 2.3562436685580157

Epoch: 5| Step: 5
Training loss: 0.20960440416161147
Validation loss: 2.3583673733508017

Epoch: 5| Step: 6
Training loss: 0.19602881682527945
Validation loss: 2.3617326995180488

Epoch: 5| Step: 7
Training loss: 0.14627504650857498
Validation loss: 2.396666942383456

Epoch: 5| Step: 8
Training loss: 0.17381110804554945
Validation loss: 2.426063836469914

Epoch: 5| Step: 9
Training loss: 0.10277077969021843
Validation loss: 2.365628567165421

Epoch: 5| Step: 10
Training loss: 0.1259276716595272
Validation loss: 2.3704469265513453

Epoch: 679| Step: 0
Training loss: 0.16616860802133204
Validation loss: 2.340224150406166

Epoch: 5| Step: 1
Training loss: 0.15160492716129287
Validation loss: 2.3476677530998655

Epoch: 5| Step: 2
Training loss: 0.12131063205011976
Validation loss: 2.302456260731472

Epoch: 5| Step: 3
Training loss: 0.09962115031184934
Validation loss: 2.3244024493506386

Epoch: 5| Step: 4
Training loss: 0.18908420509087262
Validation loss: 2.3514016495390164

Epoch: 5| Step: 5
Training loss: 0.11827309362390612
Validation loss: 2.359284272405662

Epoch: 5| Step: 6
Training loss: 0.18341017737305315
Validation loss: 2.35067329333201

Epoch: 5| Step: 7
Training loss: 0.1749455507755765
Validation loss: 2.366267013371199

Epoch: 5| Step: 8
Training loss: 0.15558365955452244
Validation loss: 2.3924609432023587

Epoch: 5| Step: 9
Training loss: 0.08220477143904564
Validation loss: 2.336524526627379

Epoch: 5| Step: 10
Training loss: 0.10021119540258601
Validation loss: 2.3408037794686103

Epoch: 680| Step: 0
Training loss: 0.10523867679036088
Validation loss: 2.2864481562997314

Epoch: 5| Step: 1
Training loss: 0.11789399408919758
Validation loss: 2.3003792611014955

Epoch: 5| Step: 2
Training loss: 0.14012220354037644
Validation loss: 2.3076812368778294

Epoch: 5| Step: 3
Training loss: 0.17345508451929656
Validation loss: 2.2765210266071967

Epoch: 5| Step: 4
Training loss: 0.1294490699271078
Validation loss: 2.330703871789035

Epoch: 5| Step: 5
Training loss: 0.19753781038219
Validation loss: 2.3281895827520542

Epoch: 5| Step: 6
Training loss: 0.13036057076150928
Validation loss: 2.3595878452368715

Epoch: 5| Step: 7
Training loss: 0.1083378794484983
Validation loss: 2.372234130728556

Epoch: 5| Step: 8
Training loss: 0.12709909263854588
Validation loss: 2.3376074362169095

Epoch: 5| Step: 9
Training loss: 0.182175351681716
Validation loss: 2.3534198839377707

Epoch: 5| Step: 10
Training loss: 0.07649446914701655
Validation loss: 2.3690225425195552

Epoch: 681| Step: 0
Training loss: 0.10477943244794616
Validation loss: 2.337398100812182

Epoch: 5| Step: 1
Training loss: 0.0847622532327759
Validation loss: 2.305840156626583

Epoch: 5| Step: 2
Training loss: 0.11815335091205031
Validation loss: 2.296575322879371

Epoch: 5| Step: 3
Training loss: 0.17608097272921572
Validation loss: 2.3026099678442233

Epoch: 5| Step: 4
Training loss: 0.2250682621297437
Validation loss: 2.3075662900079945

Epoch: 5| Step: 5
Training loss: 0.12922189099831405
Validation loss: 2.273353176190327

Epoch: 5| Step: 6
Training loss: 0.08979518759658603
Validation loss: 2.327483253979623

Epoch: 5| Step: 7
Training loss: 0.09965245867204396
Validation loss: 2.3161753277375436

Epoch: 5| Step: 8
Training loss: 0.0953344913814696
Validation loss: 2.3449699743367036

Epoch: 5| Step: 9
Training loss: 0.07650774791013254
Validation loss: 2.338296728660338

Epoch: 5| Step: 10
Training loss: 0.16095206787322147
Validation loss: 2.3639539490228008

Epoch: 682| Step: 0
Training loss: 0.09881556924966939
Validation loss: 2.373729060271938

Epoch: 5| Step: 1
Training loss: 0.15856320998506898
Validation loss: 2.3589683735925324

Epoch: 5| Step: 2
Training loss: 0.09500500468981342
Validation loss: 2.3763210215075876

Epoch: 5| Step: 3
Training loss: 0.12816797152263415
Validation loss: 2.3508287884416808

Epoch: 5| Step: 4
Training loss: 0.16690267428046382
Validation loss: 2.327206463124559

Epoch: 5| Step: 5
Training loss: 0.1486804567487215
Validation loss: 2.3168567368211237

Epoch: 5| Step: 6
Training loss: 0.16491693006806576
Validation loss: 2.348011132460625

Epoch: 5| Step: 7
Training loss: 0.1100123136371763
Validation loss: 2.3400458408619835

Epoch: 5| Step: 8
Training loss: 0.08235166336576688
Validation loss: 2.3417264498133856

Epoch: 5| Step: 9
Training loss: 0.11357752925544955
Validation loss: 2.3812794251266136

Epoch: 5| Step: 10
Training loss: 0.10825433259584843
Validation loss: 2.4000745202872453

Epoch: 683| Step: 0
Training loss: 0.15885159550342226
Validation loss: 2.4059151836173864

Epoch: 5| Step: 1
Training loss: 0.12382830264803782
Validation loss: 2.4064827998032268

Epoch: 5| Step: 2
Training loss: 0.12558525880241617
Validation loss: 2.388397331687595

Epoch: 5| Step: 3
Training loss: 0.09543922102656081
Validation loss: 2.3868855470677808

Epoch: 5| Step: 4
Training loss: 0.15781064268473352
Validation loss: 2.3872622042447826

Epoch: 5| Step: 5
Training loss: 0.07975819983282283
Validation loss: 2.371735048151466

Epoch: 5| Step: 6
Training loss: 0.1161845762342536
Validation loss: 2.3518067020778575

Epoch: 5| Step: 7
Training loss: 0.08580110302818532
Validation loss: 2.3312798669891124

Epoch: 5| Step: 8
Training loss: 0.07894072251753116
Validation loss: 2.3456705844943793

Epoch: 5| Step: 9
Training loss: 0.1680237325235711
Validation loss: 2.365149944317915

Epoch: 5| Step: 10
Training loss: 0.07642220968669605
Validation loss: 2.35900321605856

Epoch: 684| Step: 0
Training loss: 0.07815579165195014
Validation loss: 2.352272641354173

Epoch: 5| Step: 1
Training loss: 0.14745421741659384
Validation loss: 2.360150480401996

Epoch: 5| Step: 2
Training loss: 0.08201295501057014
Validation loss: 2.3467798437703067

Epoch: 5| Step: 3
Training loss: 0.09439943794554446
Validation loss: 2.3541888156915767

Epoch: 5| Step: 4
Training loss: 0.09008680513549858
Validation loss: 2.3634788951909065

Epoch: 5| Step: 5
Training loss: 0.10916834279252662
Validation loss: 2.3715745848846583

Epoch: 5| Step: 6
Training loss: 0.08992145640145714
Validation loss: 2.368242804323255

Epoch: 5| Step: 7
Training loss: 0.06284963889346405
Validation loss: 2.37988136580254

Epoch: 5| Step: 8
Training loss: 0.13688178559471045
Validation loss: 2.3611979117736106

Epoch: 5| Step: 9
Training loss: 0.06711055513661021
Validation loss: 2.3877013187050644

Epoch: 5| Step: 10
Training loss: 0.23240647144725118
Validation loss: 2.3655717944939187

Epoch: 685| Step: 0
Training loss: 0.09339833364476932
Validation loss: 2.340341939827915

Epoch: 5| Step: 1
Training loss: 0.10583932113025667
Validation loss: 2.355454655461256

Epoch: 5| Step: 2
Training loss: 0.089099658567765
Validation loss: 2.3550991273825383

Epoch: 5| Step: 3
Training loss: 0.16553101774656348
Validation loss: 2.412804901733162

Epoch: 5| Step: 4
Training loss: 0.08562289707445095
Validation loss: 2.361388935180854

Epoch: 5| Step: 5
Training loss: 0.10296427346543449
Validation loss: 2.3589813071290338

Epoch: 5| Step: 6
Training loss: 0.11922278073072723
Validation loss: 2.3712809604448952

Epoch: 5| Step: 7
Training loss: 0.08496702380687472
Validation loss: 2.363721128643064

Epoch: 5| Step: 8
Training loss: 0.065911052482307
Validation loss: 2.3176067573841674

Epoch: 5| Step: 9
Training loss: 0.18094807544498007
Validation loss: 2.316863580616711

Epoch: 5| Step: 10
Training loss: 0.15276843566821616
Validation loss: 2.30765774337866

Epoch: 686| Step: 0
Training loss: 0.0707853793788088
Validation loss: 2.273942478655229

Epoch: 5| Step: 1
Training loss: 0.0937191594576946
Validation loss: 2.2985335352859764

Epoch: 5| Step: 2
Training loss: 0.09151125158834782
Validation loss: 2.3386932935236304

Epoch: 5| Step: 3
Training loss: 0.09894741044077476
Validation loss: 2.3277756893548234

Epoch: 5| Step: 4
Training loss: 0.1372925502030399
Validation loss: 2.3425914151325316

Epoch: 5| Step: 5
Training loss: 0.20105312138539094
Validation loss: 2.3604184006989795

Epoch: 5| Step: 6
Training loss: 0.11285853028697584
Validation loss: 2.3419641331722314

Epoch: 5| Step: 7
Training loss: 0.09797624612569622
Validation loss: 2.366681536847751

Epoch: 5| Step: 8
Training loss: 0.13744665921055121
Validation loss: 2.3836844180595045

Epoch: 5| Step: 9
Training loss: 0.10399598104879688
Validation loss: 2.3752628757349

Epoch: 5| Step: 10
Training loss: 0.09988959483727268
Validation loss: 2.3794138619541014

Epoch: 687| Step: 0
Training loss: 0.14583623548299357
Validation loss: 2.3413324188762212

Epoch: 5| Step: 1
Training loss: 0.10304669564544594
Validation loss: 2.337825628708736

Epoch: 5| Step: 2
Training loss: 0.07959436041062845
Validation loss: 2.3459832460510013

Epoch: 5| Step: 3
Training loss: 0.08364288076155606
Validation loss: 2.345843508270718

Epoch: 5| Step: 4
Training loss: 0.10585657974719291
Validation loss: 2.3527028110547605

Epoch: 5| Step: 5
Training loss: 0.14553946592400033
Validation loss: 2.3591555981190155

Epoch: 5| Step: 6
Training loss: 0.11017727380697448
Validation loss: 2.378307187960355

Epoch: 5| Step: 7
Training loss: 0.07867227141783316
Validation loss: 2.353632578230767

Epoch: 5| Step: 8
Training loss: 0.08417449545724658
Validation loss: 2.3707537923206825

Epoch: 5| Step: 9
Training loss: 0.17175179096812349
Validation loss: 2.3591578464531024

Epoch: 5| Step: 10
Training loss: 0.09428033236422763
Validation loss: 2.3624997905247787

Epoch: 688| Step: 0
Training loss: 0.12788592019395892
Validation loss: 2.34406556989067

Epoch: 5| Step: 1
Training loss: 0.18672758185276525
Validation loss: 2.3611239458475604

Epoch: 5| Step: 2
Training loss: 0.11194062724902178
Validation loss: 2.361751793235345

Epoch: 5| Step: 3
Training loss: 0.1505542830706805
Validation loss: 2.3521178242624994

Epoch: 5| Step: 4
Training loss: 0.14282102665812096
Validation loss: 2.3481221274167066

Epoch: 5| Step: 5
Training loss: 0.08151230263991054
Validation loss: 2.3589364268774933

Epoch: 5| Step: 6
Training loss: 0.08849644616468749
Validation loss: 2.3861060028882286

Epoch: 5| Step: 7
Training loss: 0.08922126990265393
Validation loss: 2.3827022866578806

Epoch: 5| Step: 8
Training loss: 0.11651963417964081
Validation loss: 2.3791991063213023

Epoch: 5| Step: 9
Training loss: 0.08604132817415769
Validation loss: 2.355069643850213

Epoch: 5| Step: 10
Training loss: 0.1427933622930585
Validation loss: 2.304297812032148

Epoch: 689| Step: 0
Training loss: 0.09833108906572412
Validation loss: 2.298695127509466

Epoch: 5| Step: 1
Training loss: 0.09481334643592781
Validation loss: 2.3067935420806585

Epoch: 5| Step: 2
Training loss: 0.137461321440776
Validation loss: 2.3028195065784365

Epoch: 5| Step: 3
Training loss: 0.1648681816870444
Validation loss: 2.3155589792275495

Epoch: 5| Step: 4
Training loss: 0.10790117148714867
Validation loss: 2.3550631070229806

Epoch: 5| Step: 5
Training loss: 0.10730371912910544
Validation loss: 2.3639088172269083

Epoch: 5| Step: 6
Training loss: 0.15636931870337767
Validation loss: 2.390799783902551

Epoch: 5| Step: 7
Training loss: 0.11949674741032436
Validation loss: 2.3838175595447204

Epoch: 5| Step: 8
Training loss: 0.11416243786648808
Validation loss: 2.391406537473461

Epoch: 5| Step: 9
Training loss: 0.12602883370805176
Validation loss: 2.388190666288879

Epoch: 5| Step: 10
Training loss: 0.09713680879534493
Validation loss: 2.3178970947679236

Epoch: 690| Step: 0
Training loss: 0.09270340635391044
Validation loss: 2.320730203310864

Epoch: 5| Step: 1
Training loss: 0.10587153083433208
Validation loss: 2.298655653690316

Epoch: 5| Step: 2
Training loss: 0.11741055083095107
Validation loss: 2.2879151904481265

Epoch: 5| Step: 3
Training loss: 0.14047211707708027
Validation loss: 2.3287462857806145

Epoch: 5| Step: 4
Training loss: 0.1480582688307935
Validation loss: 2.318981789113879

Epoch: 5| Step: 5
Training loss: 0.1638777180449193
Validation loss: 2.386004295536696

Epoch: 5| Step: 6
Training loss: 0.09073442068701544
Validation loss: 2.3687195007757325

Epoch: 5| Step: 7
Training loss: 0.10513795085527307
Validation loss: 2.362207127774221

Epoch: 5| Step: 8
Training loss: 0.11082957131934365
Validation loss: 2.3827521128393427

Epoch: 5| Step: 9
Training loss: 0.13599050573647117
Validation loss: 2.390964815536303

Epoch: 5| Step: 10
Training loss: 0.15734803500775876
Validation loss: 2.370047388587362

Epoch: 691| Step: 0
Training loss: 0.13238274944323053
Validation loss: 2.344667415111455

Epoch: 5| Step: 1
Training loss: 0.1065583853402668
Validation loss: 2.3622872109137965

Epoch: 5| Step: 2
Training loss: 0.13350590444484114
Validation loss: 2.3543983873223673

Epoch: 5| Step: 3
Training loss: 0.11683817694560639
Validation loss: 2.3260060509362184

Epoch: 5| Step: 4
Training loss: 0.12298110687765929
Validation loss: 2.346942618359558

Epoch: 5| Step: 5
Training loss: 0.11633580575722524
Validation loss: 2.34659944097978

Epoch: 5| Step: 6
Training loss: 0.13830952920925138
Validation loss: 2.3481029348788134

Epoch: 5| Step: 7
Training loss: 0.11486252092856726
Validation loss: 2.384004916603853

Epoch: 5| Step: 8
Training loss: 0.13031780568306206
Validation loss: 2.35210180334652

Epoch: 5| Step: 9
Training loss: 0.1496150715393325
Validation loss: 2.36329082533516

Epoch: 5| Step: 10
Training loss: 0.06263812641932688
Validation loss: 2.380131687389589

Epoch: 692| Step: 0
Training loss: 0.16709254411469507
Validation loss: 2.3746862285187587

Epoch: 5| Step: 1
Training loss: 0.13509400069808905
Validation loss: 2.3831750662164204

Epoch: 5| Step: 2
Training loss: 0.11345341359322307
Validation loss: 2.3893734795857045

Epoch: 5| Step: 3
Training loss: 0.10925440867184816
Validation loss: 2.3414624366805943

Epoch: 5| Step: 4
Training loss: 0.09147472873133022
Validation loss: 2.3461814185708008

Epoch: 5| Step: 5
Training loss: 0.16496972314706904
Validation loss: 2.292582059662312

Epoch: 5| Step: 6
Training loss: 0.08661831407269399
Validation loss: 2.331454686664289

Epoch: 5| Step: 7
Training loss: 0.09294061655829684
Validation loss: 2.3496470217462164

Epoch: 5| Step: 8
Training loss: 0.07255431453978246
Validation loss: 2.3808744971257014

Epoch: 5| Step: 9
Training loss: 0.11520334407868865
Validation loss: 2.380637169678167

Epoch: 5| Step: 10
Training loss: 0.18276816262453857
Validation loss: 2.370264410829693

Epoch: 693| Step: 0
Training loss: 0.07449093587571008
Validation loss: 2.3297493253636263

Epoch: 5| Step: 1
Training loss: 0.1087178772997938
Validation loss: 2.2780194695377967

Epoch: 5| Step: 2
Training loss: 0.13488418091213245
Validation loss: 2.3126143826590595

Epoch: 5| Step: 3
Training loss: 0.16383951792397977
Validation loss: 2.3107977102791017

Epoch: 5| Step: 4
Training loss: 0.11312657517184814
Validation loss: 2.3269487795650736

Epoch: 5| Step: 5
Training loss: 0.1251256504942251
Validation loss: 2.3242875316931726

Epoch: 5| Step: 6
Training loss: 0.11404809697546107
Validation loss: 2.3235093290563524

Epoch: 5| Step: 7
Training loss: 0.09696730784315898
Validation loss: 2.3286425113132494

Epoch: 5| Step: 8
Training loss: 0.13812187757673955
Validation loss: 2.354306107889875

Epoch: 5| Step: 9
Training loss: 0.14745836066211376
Validation loss: 2.339507148790962

Epoch: 5| Step: 10
Training loss: 0.09414347885681341
Validation loss: 2.372822950567545

Epoch: 694| Step: 0
Training loss: 0.13189140142124814
Validation loss: 2.3824503865041176

Epoch: 5| Step: 1
Training loss: 0.09073728950507341
Validation loss: 2.3741638620176073

Epoch: 5| Step: 2
Training loss: 0.14355680892311048
Validation loss: 2.334992780757487

Epoch: 5| Step: 3
Training loss: 0.1376737618321923
Validation loss: 2.3143691413608978

Epoch: 5| Step: 4
Training loss: 0.10246788915363879
Validation loss: 2.299341120270559

Epoch: 5| Step: 5
Training loss: 0.11699450813755773
Validation loss: 2.288878583017058

Epoch: 5| Step: 6
Training loss: 0.1917268345472096
Validation loss: 2.2566138959781212

Epoch: 5| Step: 7
Training loss: 0.09085353633295591
Validation loss: 2.3032503514112164

Epoch: 5| Step: 8
Training loss: 0.1076872365716401
Validation loss: 2.2827511662402222

Epoch: 5| Step: 9
Training loss: 0.10683977897753379
Validation loss: 2.3161099699961634

Epoch: 5| Step: 10
Training loss: 0.14971487145445156
Validation loss: 2.335187934877874

Epoch: 695| Step: 0
Training loss: 0.09404048520271975
Validation loss: 2.35358649039802

Epoch: 5| Step: 1
Training loss: 0.13024165839668472
Validation loss: 2.3645514964517793

Epoch: 5| Step: 2
Training loss: 0.10553312103311781
Validation loss: 2.3786734122820947

Epoch: 5| Step: 3
Training loss: 0.1347078946066423
Validation loss: 2.367337356178178

Epoch: 5| Step: 4
Training loss: 0.14038010970205736
Validation loss: 2.3367704790608395

Epoch: 5| Step: 5
Training loss: 0.10630223518907739
Validation loss: 2.355863647956545

Epoch: 5| Step: 6
Training loss: 0.06218512949007768
Validation loss: 2.349521654999185

Epoch: 5| Step: 7
Training loss: 0.15023171711642086
Validation loss: 2.3315280967821796

Epoch: 5| Step: 8
Training loss: 0.09078842033820239
Validation loss: 2.3397297868844817

Epoch: 5| Step: 9
Training loss: 0.07692762959457872
Validation loss: 2.3128256653007027

Epoch: 5| Step: 10
Training loss: 0.10393796540722126
Validation loss: 2.3473750475256194

Epoch: 696| Step: 0
Training loss: 0.0978169882676946
Validation loss: 2.3338767164638767

Epoch: 5| Step: 1
Training loss: 0.10608314444999456
Validation loss: 2.357082205552626

Epoch: 5| Step: 2
Training loss: 0.1357683870019456
Validation loss: 2.3534580002227834

Epoch: 5| Step: 3
Training loss: 0.10815218284039162
Validation loss: 2.3208457477938835

Epoch: 5| Step: 4
Training loss: 0.10521144740371378
Validation loss: 2.3049973891486384

Epoch: 5| Step: 5
Training loss: 0.052096359541264334
Validation loss: 2.306416462325565

Epoch: 5| Step: 6
Training loss: 0.11200323280576636
Validation loss: 2.314562888203891

Epoch: 5| Step: 7
Training loss: 0.147358012121
Validation loss: 2.3187173842250797

Epoch: 5| Step: 8
Training loss: 0.073447743294959
Validation loss: 2.3515429964906684

Epoch: 5| Step: 9
Training loss: 0.13870647160037078
Validation loss: 2.354499408606408

Epoch: 5| Step: 10
Training loss: 0.08135572796419151
Validation loss: 2.32250539875753

Epoch: 697| Step: 0
Training loss: 0.15638725689437738
Validation loss: 2.3495597363237537

Epoch: 5| Step: 1
Training loss: 0.09775849711701945
Validation loss: 2.323685584507832

Epoch: 5| Step: 2
Training loss: 0.14235533984304852
Validation loss: 2.3550766237029905

Epoch: 5| Step: 3
Training loss: 0.08529565909553781
Validation loss: 2.3229215053436403

Epoch: 5| Step: 4
Training loss: 0.12912126872625398
Validation loss: 2.34824386028799

Epoch: 5| Step: 5
Training loss: 0.10996540832916632
Validation loss: 2.337139597758827

Epoch: 5| Step: 6
Training loss: 0.07738548691570044
Validation loss: 2.3097847016304622

Epoch: 5| Step: 7
Training loss: 0.08485238221463352
Validation loss: 2.3180331953861724

Epoch: 5| Step: 8
Training loss: 0.06896186041071246
Validation loss: 2.357518687229136

Epoch: 5| Step: 9
Training loss: 0.15898149825171715
Validation loss: 2.2937617445567358

Epoch: 5| Step: 10
Training loss: 0.10586258418859877
Validation loss: 2.327210781926498

Epoch: 698| Step: 0
Training loss: 0.09341439636884166
Validation loss: 2.345967211653629

Epoch: 5| Step: 1
Training loss: 0.08805155590598823
Validation loss: 2.351657435845717

Epoch: 5| Step: 2
Training loss: 0.11577627493070478
Validation loss: 2.355020563318737

Epoch: 5| Step: 3
Training loss: 0.12553996940093878
Validation loss: 2.3471279404672387

Epoch: 5| Step: 4
Training loss: 0.08753783629859549
Validation loss: 2.340710815134088

Epoch: 5| Step: 5
Training loss: 0.0925593163904209
Validation loss: 2.308871211586322

Epoch: 5| Step: 6
Training loss: 0.10304548456383313
Validation loss: 2.2909349063756874

Epoch: 5| Step: 7
Training loss: 0.1756973649247345
Validation loss: 2.295610262839837

Epoch: 5| Step: 8
Training loss: 0.0873648573760756
Validation loss: 2.329971505091689

Epoch: 5| Step: 9
Training loss: 0.0863117311411996
Validation loss: 2.3328221159547797

Epoch: 5| Step: 10
Training loss: 0.15038699603966155
Validation loss: 2.351596982331975

Epoch: 699| Step: 0
Training loss: 0.16645839214522842
Validation loss: 2.3302248690313476

Epoch: 5| Step: 1
Training loss: 0.1296740481857256
Validation loss: 2.3557256519976404

Epoch: 5| Step: 2
Training loss: 0.11514674103450827
Validation loss: 2.357472694398998

Epoch: 5| Step: 3
Training loss: 0.11074627275012802
Validation loss: 2.3617798940434547

Epoch: 5| Step: 4
Training loss: 0.09918841532811885
Validation loss: 2.335137399270018

Epoch: 5| Step: 5
Training loss: 0.16491029444829983
Validation loss: 2.304974929074946

Epoch: 5| Step: 6
Training loss: 0.10956664410738402
Validation loss: 2.3036607738769344

Epoch: 5| Step: 7
Training loss: 0.10133165479084022
Validation loss: 2.2732122870930684

Epoch: 5| Step: 8
Training loss: 0.13118621945403627
Validation loss: 2.277413995800925

Epoch: 5| Step: 9
Training loss: 0.1524419406976807
Validation loss: 2.2866655905594966

Epoch: 5| Step: 10
Training loss: 0.14235739409109277
Validation loss: 2.2840791415767225

Epoch: 700| Step: 0
Training loss: 0.09938016399725554
Validation loss: 2.2824143576305467

Epoch: 5| Step: 1
Training loss: 0.0969740835816598
Validation loss: 2.333458495701865

Epoch: 5| Step: 2
Training loss: 0.16897356756237827
Validation loss: 2.345203832557224

Epoch: 5| Step: 3
Training loss: 0.10724046735119737
Validation loss: 2.334913673018068

Epoch: 5| Step: 4
Training loss: 0.1119257379935906
Validation loss: 2.315645700738904

Epoch: 5| Step: 5
Training loss: 0.12579665533939052
Validation loss: 2.3337561060280514

Epoch: 5| Step: 6
Training loss: 0.15466289324548968
Validation loss: 2.355441399987591

Epoch: 5| Step: 7
Training loss: 0.1340169914183062
Validation loss: 2.370832939053481

Epoch: 5| Step: 8
Training loss: 0.10937956391758008
Validation loss: 2.3156501556863907

Epoch: 5| Step: 9
Training loss: 0.1277447156774349
Validation loss: 2.3258278180919443

Epoch: 5| Step: 10
Training loss: 0.09174076861492987
Validation loss: 2.316082340056273

Epoch: 701| Step: 0
Training loss: 0.1507993815692697
Validation loss: 2.3179123566881987

Epoch: 5| Step: 1
Training loss: 0.13247737959092187
Validation loss: 2.3310419784408336

Epoch: 5| Step: 2
Training loss: 0.09565226020611493
Validation loss: 2.3400890676366526

Epoch: 5| Step: 3
Training loss: 0.15232795242173017
Validation loss: 2.3468822919084174

Epoch: 5| Step: 4
Training loss: 0.08586785355306921
Validation loss: 2.3279497568328433

Epoch: 5| Step: 5
Training loss: 0.14506559571542216
Validation loss: 2.3456314312436106

Epoch: 5| Step: 6
Training loss: 0.08823904805300067
Validation loss: 2.3654309195143717

Epoch: 5| Step: 7
Training loss: 0.1454095124383512
Validation loss: 2.332947313075968

Epoch: 5| Step: 8
Training loss: 0.10815165324887466
Validation loss: 2.3408670601752783

Epoch: 5| Step: 9
Training loss: 0.08666100254638612
Validation loss: 2.358756304992669

Epoch: 5| Step: 10
Training loss: 0.0846248011778647
Validation loss: 2.3557480841822933

Epoch: 702| Step: 0
Training loss: 0.06720113796058433
Validation loss: 2.332234564137312

Epoch: 5| Step: 1
Training loss: 0.06786842821224794
Validation loss: 2.356509674474199

Epoch: 5| Step: 2
Training loss: 0.07994768521133534
Validation loss: 2.3456034036548115

Epoch: 5| Step: 3
Training loss: 0.1020354574279441
Validation loss: 2.3399648146643632

Epoch: 5| Step: 4
Training loss: 0.09068555987114545
Validation loss: 2.3615886037316183

Epoch: 5| Step: 5
Training loss: 0.09137912311038197
Validation loss: 2.3394702796363998

Epoch: 5| Step: 6
Training loss: 0.08020167298603183
Validation loss: 2.352813866342196

Epoch: 5| Step: 7
Training loss: 0.16652126725151956
Validation loss: 2.3396298197054644

Epoch: 5| Step: 8
Training loss: 0.10432189362732631
Validation loss: 2.333223478379844

Epoch: 5| Step: 9
Training loss: 0.12525120467998122
Validation loss: 2.3533646305137337

Epoch: 5| Step: 10
Training loss: 0.17495847043211998
Validation loss: 2.360191525007909

Epoch: 703| Step: 0
Training loss: 0.1378260323417829
Validation loss: 2.3627979071421117

Epoch: 5| Step: 1
Training loss: 0.09720093920141361
Validation loss: 2.377321795540048

Epoch: 5| Step: 2
Training loss: 0.1464701836387445
Validation loss: 2.322693121529798

Epoch: 5| Step: 3
Training loss: 0.09997380666115972
Validation loss: 2.3406143547924567

Epoch: 5| Step: 4
Training loss: 0.0940820753284721
Validation loss: 2.334123725522337

Epoch: 5| Step: 5
Training loss: 0.1002394857686935
Validation loss: 2.3239067333535157

Epoch: 5| Step: 6
Training loss: 0.10665861683635545
Validation loss: 2.2907026759897726

Epoch: 5| Step: 7
Training loss: 0.09422192406882872
Validation loss: 2.316065396880262

Epoch: 5| Step: 8
Training loss: 0.128302968680622
Validation loss: 2.3035358413759908

Epoch: 5| Step: 9
Training loss: 0.1075146794415476
Validation loss: 2.2986071435936877

Epoch: 5| Step: 10
Training loss: 0.08493202090082286
Validation loss: 2.2763562391378427

Epoch: 704| Step: 0
Training loss: 0.12157840416948158
Validation loss: 2.280160006059521

Epoch: 5| Step: 1
Training loss: 0.1204881599513467
Validation loss: 2.2804379739467775

Epoch: 5| Step: 2
Training loss: 0.10836007754009426
Validation loss: 2.273497036858152

Epoch: 5| Step: 3
Training loss: 0.10772140099080124
Validation loss: 2.297389544496997

Epoch: 5| Step: 4
Training loss: 0.14531606803123143
Validation loss: 2.337130411087846

Epoch: 5| Step: 5
Training loss: 0.0750635993781326
Validation loss: 2.3357490026975327

Epoch: 5| Step: 6
Training loss: 0.1056102227703122
Validation loss: 2.3176733836771635

Epoch: 5| Step: 7
Training loss: 0.09870588315335073
Validation loss: 2.3434847511405494

Epoch: 5| Step: 8
Training loss: 0.19459728897157777
Validation loss: 2.36215770064922

Epoch: 5| Step: 9
Training loss: 0.06543628815906058
Validation loss: 2.406658976861329

Epoch: 5| Step: 10
Training loss: 0.08137463709516658
Validation loss: 2.3780682362736507

Epoch: 705| Step: 0
Training loss: 0.09331045325417765
Validation loss: 2.415016413021667

Epoch: 5| Step: 1
Training loss: 0.15679330543290512
Validation loss: 2.3777206847546957

Epoch: 5| Step: 2
Training loss: 0.08392924894857288
Validation loss: 2.3700232271751775

Epoch: 5| Step: 3
Training loss: 0.10255891970958791
Validation loss: 2.3811055498399867

Epoch: 5| Step: 4
Training loss: 0.11371892204544207
Validation loss: 2.3488185158743837

Epoch: 5| Step: 5
Training loss: 0.15184563117344818
Validation loss: 2.3391149639291795

Epoch: 5| Step: 6
Training loss: 0.14166336026493892
Validation loss: 2.340628856873335

Epoch: 5| Step: 7
Training loss: 0.14466758046098743
Validation loss: 2.3246573234572745

Epoch: 5| Step: 8
Training loss: 0.07750519822553421
Validation loss: 2.330900597582318

Epoch: 5| Step: 9
Training loss: 0.11218681369109343
Validation loss: 2.342724171310751

Epoch: 5| Step: 10
Training loss: 0.08258967832155326
Validation loss: 2.313229891045416

Epoch: 706| Step: 0
Training loss: 0.13273642970039004
Validation loss: 2.3229960086787638

Epoch: 5| Step: 1
Training loss: 0.07415557355889707
Validation loss: 2.3623288141792815

Epoch: 5| Step: 2
Training loss: 0.11380369876686869
Validation loss: 2.3086803411641927

Epoch: 5| Step: 3
Training loss: 0.09677900164711338
Validation loss: 2.368418562381718

Epoch: 5| Step: 4
Training loss: 0.07840073919980223
Validation loss: 2.3476030154882195

Epoch: 5| Step: 5
Training loss: 0.17635009171606814
Validation loss: 2.3161392571290738

Epoch: 5| Step: 6
Training loss: 0.07838541081841448
Validation loss: 2.3189159919760787

Epoch: 5| Step: 7
Training loss: 0.12701141046483408
Validation loss: 2.319696855097831

Epoch: 5| Step: 8
Training loss: 0.0833415866157304
Validation loss: 2.331106157601255

Epoch: 5| Step: 9
Training loss: 0.09841629852070755
Validation loss: 2.295109475243395

Epoch: 5| Step: 10
Training loss: 0.11911418105403467
Validation loss: 2.297982691088521

Epoch: 707| Step: 0
Training loss: 0.08572505028024557
Validation loss: 2.3317049170246418

Epoch: 5| Step: 1
Training loss: 0.09101774945869903
Validation loss: 2.2989265226443414

Epoch: 5| Step: 2
Training loss: 0.11037767573928027
Validation loss: 2.315091244174627

Epoch: 5| Step: 3
Training loss: 0.060350001879763554
Validation loss: 2.34023334574637

Epoch: 5| Step: 4
Training loss: 0.11918912353845118
Validation loss: 2.3250136858973636

Epoch: 5| Step: 5
Training loss: 0.14984541691199987
Validation loss: 2.3515908424861527

Epoch: 5| Step: 6
Training loss: 0.0840534907205368
Validation loss: 2.3437585427186662

Epoch: 5| Step: 7
Training loss: 0.09330179941006331
Validation loss: 2.3277643831113566

Epoch: 5| Step: 8
Training loss: 0.11293174413881894
Validation loss: 2.3322890068065814

Epoch: 5| Step: 9
Training loss: 0.1254934020426256
Validation loss: 2.325177460792852

Epoch: 5| Step: 10
Training loss: 0.12233218903928335
Validation loss: 2.319611959978715

Epoch: 708| Step: 0
Training loss: 0.09404996725088925
Validation loss: 2.3094805130806506

Epoch: 5| Step: 1
Training loss: 0.10728415417372494
Validation loss: 2.3022632215852306

Epoch: 5| Step: 2
Training loss: 0.07759620101048076
Validation loss: 2.291773204247447

Epoch: 5| Step: 3
Training loss: 0.11115821202857397
Validation loss: 2.3065546774875516

Epoch: 5| Step: 4
Training loss: 0.08945040011524358
Validation loss: 2.266119308211422

Epoch: 5| Step: 5
Training loss: 0.14945890962819103
Validation loss: 2.2974546213321743

Epoch: 5| Step: 6
Training loss: 0.16828614565175332
Validation loss: 2.2840852165354373

Epoch: 5| Step: 7
Training loss: 0.09605365901549989
Validation loss: 2.304452117195849

Epoch: 5| Step: 8
Training loss: 0.06944234500466563
Validation loss: 2.2992144450058736

Epoch: 5| Step: 9
Training loss: 0.13828926628929206
Validation loss: 2.299658226329396

Epoch: 5| Step: 10
Training loss: 0.12481466725048039
Validation loss: 2.3379662514239996

Epoch: 709| Step: 0
Training loss: 0.12977285678470188
Validation loss: 2.3308090184366246

Epoch: 5| Step: 1
Training loss: 0.10108217033031412
Validation loss: 2.315871287002861

Epoch: 5| Step: 2
Training loss: 0.10353096362499513
Validation loss: 2.3223436666880497

Epoch: 5| Step: 3
Training loss: 0.07648291416935711
Validation loss: 2.3402055339491747

Epoch: 5| Step: 4
Training loss: 0.0941280698912038
Validation loss: 2.3233331915420066

Epoch: 5| Step: 5
Training loss: 0.07601678783668213
Validation loss: 2.330382893015911

Epoch: 5| Step: 6
Training loss: 0.08416786221423864
Validation loss: 2.3112237973506695

Epoch: 5| Step: 7
Training loss: 0.11112882107504102
Validation loss: 2.324026626087461

Epoch: 5| Step: 8
Training loss: 0.1464717986748147
Validation loss: 2.312840547238824

Epoch: 5| Step: 9
Training loss: 0.11765995948131437
Validation loss: 2.3233107481745434

Epoch: 5| Step: 10
Training loss: 0.1898495174834836
Validation loss: 2.298471638798294

Epoch: 710| Step: 0
Training loss: 0.11636369346528479
Validation loss: 2.3246067406108675

Epoch: 5| Step: 1
Training loss: 0.07956418401931692
Validation loss: 2.320504335945042

Epoch: 5| Step: 2
Training loss: 0.10405455506699629
Validation loss: 2.3376797719537947

Epoch: 5| Step: 3
Training loss: 0.1040852054320242
Validation loss: 2.3111788183056086

Epoch: 5| Step: 4
Training loss: 0.13387465001754179
Validation loss: 2.3372060237196677

Epoch: 5| Step: 5
Training loss: 0.12482191229623124
Validation loss: 2.3387248826231

Epoch: 5| Step: 6
Training loss: 0.10387007291472301
Validation loss: 2.308535387024549

Epoch: 5| Step: 7
Training loss: 0.10504008973237519
Validation loss: 2.3242479029697316

Epoch: 5| Step: 8
Training loss: 0.12395802222007156
Validation loss: 2.3228773344302223

Epoch: 5| Step: 9
Training loss: 0.09573251895652517
Validation loss: 2.3339311427957563

Epoch: 5| Step: 10
Training loss: 0.1411895150044642
Validation loss: 2.2951082476584617

Epoch: 711| Step: 0
Training loss: 0.08285458390636256
Validation loss: 2.2932509929745932

Epoch: 5| Step: 1
Training loss: 0.14909854311205692
Validation loss: 2.312597427377818

Epoch: 5| Step: 2
Training loss: 0.15341275459427875
Validation loss: 2.3048449579827297

Epoch: 5| Step: 3
Training loss: 0.10284796009064479
Validation loss: 2.317937575853884

Epoch: 5| Step: 4
Training loss: 0.07656347349579493
Validation loss: 2.3173764912903616

Epoch: 5| Step: 5
Training loss: 0.1227155303753725
Validation loss: 2.3361013126418575

Epoch: 5| Step: 6
Training loss: 0.11036382455131409
Validation loss: 2.3867060527031096

Epoch: 5| Step: 7
Training loss: 0.10837207078302505
Validation loss: 2.4012325875525877

Epoch: 5| Step: 8
Training loss: 0.09984978480003062
Validation loss: 2.3747437500246145

Epoch: 5| Step: 9
Training loss: 0.1300558429111458
Validation loss: 2.372129968665867

Epoch: 5| Step: 10
Training loss: 0.07091775307902261
Validation loss: 2.3620244800471983

Epoch: 712| Step: 0
Training loss: 0.12180318596439044
Validation loss: 2.3299260429317656

Epoch: 5| Step: 1
Training loss: 0.11820366093475612
Validation loss: 2.2793552808656763

Epoch: 5| Step: 2
Training loss: 0.16305483447224492
Validation loss: 2.253111279905386

Epoch: 5| Step: 3
Training loss: 0.09702171648186853
Validation loss: 2.3028086255333964

Epoch: 5| Step: 4
Training loss: 0.1022230227946804
Validation loss: 2.343885085065292

Epoch: 5| Step: 5
Training loss: 0.1520205823619521
Validation loss: 2.3896676139159836

Epoch: 5| Step: 6
Training loss: 0.13885870289266988
Validation loss: 2.359325001754654

Epoch: 5| Step: 7
Training loss: 0.12687570705592635
Validation loss: 2.396254451563409

Epoch: 5| Step: 8
Training loss: 0.09998428157862242
Validation loss: 2.371198980357382

Epoch: 5| Step: 9
Training loss: 0.10439741435766767
Validation loss: 2.3699942611175557

Epoch: 5| Step: 10
Training loss: 0.06315379980625171
Validation loss: 2.3725263848431384

Epoch: 713| Step: 0
Training loss: 0.09476843626124751
Validation loss: 2.324992418183098

Epoch: 5| Step: 1
Training loss: 0.07777074425506413
Validation loss: 2.3214985485228516

Epoch: 5| Step: 2
Training loss: 0.12869000358702923
Validation loss: 2.293133882550719

Epoch: 5| Step: 3
Training loss: 0.12162573921149519
Validation loss: 2.2852776955712266

Epoch: 5| Step: 4
Training loss: 0.13380585864368572
Validation loss: 2.2877176482159998

Epoch: 5| Step: 5
Training loss: 0.07739038795236182
Validation loss: 2.305607227634802

Epoch: 5| Step: 6
Training loss: 0.13246912605536434
Validation loss: 2.3285185674014772

Epoch: 5| Step: 7
Training loss: 0.08772693596975364
Validation loss: 2.3683805418216983

Epoch: 5| Step: 8
Training loss: 0.1660182391690147
Validation loss: 2.359521315982442

Epoch: 5| Step: 9
Training loss: 0.10082806915424715
Validation loss: 2.372224441816843

Epoch: 5| Step: 10
Training loss: 0.09438498349468032
Validation loss: 2.321219803195368

Epoch: 714| Step: 0
Training loss: 0.11180547802424194
Validation loss: 2.321682751857679

Epoch: 5| Step: 1
Training loss: 0.12716692015213074
Validation loss: 2.286611711403825

Epoch: 5| Step: 2
Training loss: 0.10219442944115625
Validation loss: 2.2981191846350773

Epoch: 5| Step: 3
Training loss: 0.10667493970258889
Validation loss: 2.309319833469049

Epoch: 5| Step: 4
Training loss: 0.15646053673512922
Validation loss: 2.3155186104524463

Epoch: 5| Step: 5
Training loss: 0.1309765035331632
Validation loss: 2.297547345300989

Epoch: 5| Step: 6
Training loss: 0.0825899884247434
Validation loss: 2.319306047973435

Epoch: 5| Step: 7
Training loss: 0.10467801994130325
Validation loss: 2.315466235839146

Epoch: 5| Step: 8
Training loss: 0.13175509764709942
Validation loss: 2.321608044881619

Epoch: 5| Step: 9
Training loss: 0.11608403353250007
Validation loss: 2.367789653633259

Epoch: 5| Step: 10
Training loss: 0.1219144359999695
Validation loss: 2.3507477729369093

Epoch: 715| Step: 0
Training loss: 0.07882182082363509
Validation loss: 2.3544547423545064

Epoch: 5| Step: 1
Training loss: 0.13987721197341188
Validation loss: 2.3121006888886204

Epoch: 5| Step: 2
Training loss: 0.11266439301297014
Validation loss: 2.3342295583060264

Epoch: 5| Step: 3
Training loss: 0.15203349603834557
Validation loss: 2.31234247014199

Epoch: 5| Step: 4
Training loss: 0.10250438376246021
Validation loss: 2.26685420585436

Epoch: 5| Step: 5
Training loss: 0.11256877283884288
Validation loss: 2.3027467443175773

Epoch: 5| Step: 6
Training loss: 0.09035772525238467
Validation loss: 2.2578565983042975

Epoch: 5| Step: 7
Training loss: 0.10695847348144695
Validation loss: 2.2800311283639503

Epoch: 5| Step: 8
Training loss: 0.12874143352064374
Validation loss: 2.3049571268030187

Epoch: 5| Step: 9
Training loss: 0.07905900069171179
Validation loss: 2.317274832941046

Epoch: 5| Step: 10
Training loss: 0.06429292536918965
Validation loss: 2.3536747832281115

Epoch: 716| Step: 0
Training loss: 0.09513042326529668
Validation loss: 2.374934856728196

Epoch: 5| Step: 1
Training loss: 0.13417055218289836
Validation loss: 2.3547518307185484

Epoch: 5| Step: 2
Training loss: 0.1010496229385323
Validation loss: 2.360353627768841

Epoch: 5| Step: 3
Training loss: 0.10688130742138381
Validation loss: 2.3169310160954613

Epoch: 5| Step: 4
Training loss: 0.18012999906624733
Validation loss: 2.315684549496682

Epoch: 5| Step: 5
Training loss: 0.07818816135204548
Validation loss: 2.3147563408424428

Epoch: 5| Step: 6
Training loss: 0.06745377549508816
Validation loss: 2.3265547433119993

Epoch: 5| Step: 7
Training loss: 0.12158997444648029
Validation loss: 2.309188796901625

Epoch: 5| Step: 8
Training loss: 0.09799242806589481
Validation loss: 2.3305286509351513

Epoch: 5| Step: 9
Training loss: 0.056250225669355176
Validation loss: 2.3269201501530468

Epoch: 5| Step: 10
Training loss: 0.10729012646387483
Validation loss: 2.3491419067493466

Epoch: 717| Step: 0
Training loss: 0.08824637259986004
Validation loss: 2.350949572032492

Epoch: 5| Step: 1
Training loss: 0.1571373242007571
Validation loss: 2.3515550387548303

Epoch: 5| Step: 2
Training loss: 0.14107955872866268
Validation loss: 2.3715707981851497

Epoch: 5| Step: 3
Training loss: 0.06668279370188931
Validation loss: 2.3245663260367566

Epoch: 5| Step: 4
Training loss: 0.10134793964286817
Validation loss: 2.3158418985114473

Epoch: 5| Step: 5
Training loss: 0.07455830948526088
Validation loss: 2.3454834333961103

Epoch: 5| Step: 6
Training loss: 0.07374223400502072
Validation loss: 2.351444831640272

Epoch: 5| Step: 7
Training loss: 0.09459263881135294
Validation loss: 2.3532279968490495

Epoch: 5| Step: 8
Training loss: 0.09144425641264398
Validation loss: 2.3710790736652143

Epoch: 5| Step: 9
Training loss: 0.07558310205232494
Validation loss: 2.37880405376444

Epoch: 5| Step: 10
Training loss: 0.10427442480482871
Validation loss: 2.360476760795112

Epoch: 718| Step: 0
Training loss: 0.1497430109930947
Validation loss: 2.3545108319987356

Epoch: 5| Step: 1
Training loss: 0.1486450112609034
Validation loss: 2.3680217795322442

Epoch: 5| Step: 2
Training loss: 0.13208860274638204
Validation loss: 2.355105655401425

Epoch: 5| Step: 3
Training loss: 0.09062080106380062
Validation loss: 2.304897253614991

Epoch: 5| Step: 4
Training loss: 0.056415878610707064
Validation loss: 2.3200252495057523

Epoch: 5| Step: 5
Training loss: 0.10552614028134286
Validation loss: 2.333491831624619

Epoch: 5| Step: 6
Training loss: 0.08610392840912648
Validation loss: 2.327700022050788

Epoch: 5| Step: 7
Training loss: 0.07380732578885349
Validation loss: 2.3097721441358283

Epoch: 5| Step: 8
Training loss: 0.07215382975620276
Validation loss: 2.350203883975353

Epoch: 5| Step: 9
Training loss: 0.0993221667634326
Validation loss: 2.3681928677250603

Epoch: 5| Step: 10
Training loss: 0.0864226076653349
Validation loss: 2.382031234889571

Epoch: 719| Step: 0
Training loss: 0.08466248048992346
Validation loss: 2.3251536589466157

Epoch: 5| Step: 1
Training loss: 0.09337401494753907
Validation loss: 2.357785770888835

Epoch: 5| Step: 2
Training loss: 0.12346245959996636
Validation loss: 2.360953331351842

Epoch: 5| Step: 3
Training loss: 0.10231606895348364
Validation loss: 2.3299147944367498

Epoch: 5| Step: 4
Training loss: 0.07143906267214153
Validation loss: 2.307564652435261

Epoch: 5| Step: 5
Training loss: 0.12493412696107477
Validation loss: 2.3113847530446177

Epoch: 5| Step: 6
Training loss: 0.10614937143805661
Validation loss: 2.269044090391876

Epoch: 5| Step: 7
Training loss: 0.07973183796206756
Validation loss: 2.319520486653554

Epoch: 5| Step: 8
Training loss: 0.15884236125125076
Validation loss: 2.3075865173794377

Epoch: 5| Step: 9
Training loss: 0.13969719975778946
Validation loss: 2.3103721094248857

Epoch: 5| Step: 10
Training loss: 0.0580433485409055
Validation loss: 2.331538792117698

Epoch: 720| Step: 0
Training loss: 0.16326187831096425
Validation loss: 2.328411816073848

Epoch: 5| Step: 1
Training loss: 0.13753330222984256
Validation loss: 2.3087043564280942

Epoch: 5| Step: 2
Training loss: 0.0659874267565705
Validation loss: 2.356600891269913

Epoch: 5| Step: 3
Training loss: 0.1470277562572575
Validation loss: 2.3550127733898445

Epoch: 5| Step: 4
Training loss: 0.1033012852157904
Validation loss: 2.357235816759169

Epoch: 5| Step: 5
Training loss: 0.0922226568038897
Validation loss: 2.322840100334376

Epoch: 5| Step: 6
Training loss: 0.1281202367734567
Validation loss: 2.36067257145725

Epoch: 5| Step: 7
Training loss: 0.18908224475629062
Validation loss: 2.3574391832107198

Epoch: 5| Step: 8
Training loss: 0.14981968989841887
Validation loss: 2.3412382518776496

Epoch: 5| Step: 9
Training loss: 0.17561957023413038
Validation loss: 2.327707477159053

Epoch: 5| Step: 10
Training loss: 0.06327303020639645
Validation loss: 2.3389698758993447

Epoch: 721| Step: 0
Training loss: 0.08104775295697651
Validation loss: 2.3177717228998698

Epoch: 5| Step: 1
Training loss: 0.16549881545806924
Validation loss: 2.303727727830905

Epoch: 5| Step: 2
Training loss: 0.10999106710911778
Validation loss: 2.311797612663133

Epoch: 5| Step: 3
Training loss: 0.14802545528412717
Validation loss: 2.3407416174674536

Epoch: 5| Step: 4
Training loss: 0.13279453324357018
Validation loss: 2.3327049672419293

Epoch: 5| Step: 5
Training loss: 0.13048621249261239
Validation loss: 2.304127016319558

Epoch: 5| Step: 6
Training loss: 0.14044041572730576
Validation loss: 2.290558267471995

Epoch: 5| Step: 7
Training loss: 0.09630005408143914
Validation loss: 2.2745078987672227

Epoch: 5| Step: 8
Training loss: 0.17319197459241312
Validation loss: 2.27908226134797

Epoch: 5| Step: 9
Training loss: 0.10870384460458876
Validation loss: 2.282494464436212

Epoch: 5| Step: 10
Training loss: 0.14842789393010508
Validation loss: 2.2576750866674056

Epoch: 722| Step: 0
Training loss: 0.10018525361251411
Validation loss: 2.29248531258524

Epoch: 5| Step: 1
Training loss: 0.10250284372722994
Validation loss: 2.3057010158077835

Epoch: 5| Step: 2
Training loss: 0.13245763070904226
Validation loss: 2.308292279075151

Epoch: 5| Step: 3
Training loss: 0.22271080352643216
Validation loss: 2.349634255045392

Epoch: 5| Step: 4
Training loss: 0.16887129556925706
Validation loss: 2.3284873672135586

Epoch: 5| Step: 5
Training loss: 0.20549214668652047
Validation loss: 2.3316844250044992

Epoch: 5| Step: 6
Training loss: 0.12843176183853358
Validation loss: 2.2788825421886667

Epoch: 5| Step: 7
Training loss: 0.06918365586141104
Validation loss: 2.2792949229944157

Epoch: 5| Step: 8
Training loss: 0.17343541049557767
Validation loss: 2.2682381301020302

Epoch: 5| Step: 9
Training loss: 0.17857112522610377
Validation loss: 2.2556101202782357

Epoch: 5| Step: 10
Training loss: 0.12271353817308545
Validation loss: 2.2832675956560733

Epoch: 723| Step: 0
Training loss: 0.13656909108350868
Validation loss: 2.3343539328767404

Epoch: 5| Step: 1
Training loss: 0.17611467739743572
Validation loss: 2.3505455049842103

Epoch: 5| Step: 2
Training loss: 0.1243551354263749
Validation loss: 2.3343697255412654

Epoch: 5| Step: 3
Training loss: 0.10376607090360637
Validation loss: 2.344890956106969

Epoch: 5| Step: 4
Training loss: 0.1525069243195792
Validation loss: 2.296241150998167

Epoch: 5| Step: 5
Training loss: 0.10964463411155316
Validation loss: 2.328736191906467

Epoch: 5| Step: 6
Training loss: 0.16130748298060277
Validation loss: 2.3461424464923444

Epoch: 5| Step: 7
Training loss: 0.1658325363793784
Validation loss: 2.3331681125643247

Epoch: 5| Step: 8
Training loss: 0.1653444804840736
Validation loss: 2.3655556230226447

Epoch: 5| Step: 9
Training loss: 0.15422930626264073
Validation loss: 2.3260393167697884

Epoch: 5| Step: 10
Training loss: 0.1582177120124211
Validation loss: 2.355042226065468

Epoch: 724| Step: 0
Training loss: 0.08595459941326866
Validation loss: 2.3505403483487846

Epoch: 5| Step: 1
Training loss: 0.10388510818796473
Validation loss: 2.3890636497340325

Epoch: 5| Step: 2
Training loss: 0.09979679669953023
Validation loss: 2.375777825840948

Epoch: 5| Step: 3
Training loss: 0.15541602731152188
Validation loss: 2.3938591490672425

Epoch: 5| Step: 4
Training loss: 0.1803033991885443
Validation loss: 2.381692118295771

Epoch: 5| Step: 5
Training loss: 0.08075087265747753
Validation loss: 2.3442490716991347

Epoch: 5| Step: 6
Training loss: 0.1517526579071069
Validation loss: 2.352772678866377

Epoch: 5| Step: 7
Training loss: 0.12483803120096439
Validation loss: 2.3386147872690066

Epoch: 5| Step: 8
Training loss: 0.17518895817080732
Validation loss: 2.296682102322894

Epoch: 5| Step: 9
Training loss: 0.06941678142750399
Validation loss: 2.312527639483829

Epoch: 5| Step: 10
Training loss: 0.19817208239093273
Validation loss: 2.352364937347013

Epoch: 725| Step: 0
Training loss: 0.13526671999611178
Validation loss: 2.33294858173827

Epoch: 5| Step: 1
Training loss: 0.08709479410936984
Validation loss: 2.3631445572367613

Epoch: 5| Step: 2
Training loss: 0.17605545591394467
Validation loss: 2.3163186449817426

Epoch: 5| Step: 3
Training loss: 0.11409842957319431
Validation loss: 2.3264871294827256

Epoch: 5| Step: 4
Training loss: 0.08148178214869908
Validation loss: 2.3506940642329033

Epoch: 5| Step: 5
Training loss: 0.10040538286024031
Validation loss: 2.3439371801305744

Epoch: 5| Step: 6
Training loss: 0.10452274071908607
Validation loss: 2.336286670635335

Epoch: 5| Step: 7
Training loss: 0.09130268791805164
Validation loss: 2.287096236792215

Epoch: 5| Step: 8
Training loss: 0.09591602952659506
Validation loss: 2.285891155311188

Epoch: 5| Step: 9
Training loss: 0.1774357288315195
Validation loss: 2.280572591467039

Epoch: 5| Step: 10
Training loss: 0.1421288177942879
Validation loss: 2.2858327392427458

Epoch: 726| Step: 0
Training loss: 0.08170378981589899
Validation loss: 2.3351495286072894

Epoch: 5| Step: 1
Training loss: 0.15687677319728968
Validation loss: 2.342183192767825

Epoch: 5| Step: 2
Training loss: 0.11500339473243792
Validation loss: 2.328296383907862

Epoch: 5| Step: 3
Training loss: 0.14841834998831696
Validation loss: 2.31478514063238

Epoch: 5| Step: 4
Training loss: 0.11584640678578073
Validation loss: 2.314089946048555

Epoch: 5| Step: 5
Training loss: 0.1281805272849376
Validation loss: 2.294100430210121

Epoch: 5| Step: 6
Training loss: 0.1524659302637026
Validation loss: 2.3001445564330165

Epoch: 5| Step: 7
Training loss: 0.14330594576934313
Validation loss: 2.296607741901337

Epoch: 5| Step: 8
Training loss: 0.1099198301798854
Validation loss: 2.2860782249501983

Epoch: 5| Step: 9
Training loss: 0.08781251615476629
Validation loss: 2.303418504824226

Epoch: 5| Step: 10
Training loss: 0.0874985266885017
Validation loss: 2.2956700275883213

Epoch: 727| Step: 0
Training loss: 0.136110492228325
Validation loss: 2.283429325128831

Epoch: 5| Step: 1
Training loss: 0.10036237649499029
Validation loss: 2.2934864561933304

Epoch: 5| Step: 2
Training loss: 0.1076514478589649
Validation loss: 2.2995869816548877

Epoch: 5| Step: 3
Training loss: 0.11793292903836014
Validation loss: 2.229326225399526

Epoch: 5| Step: 4
Training loss: 0.14864049382857117
Validation loss: 2.2555594955360556

Epoch: 5| Step: 5
Training loss: 0.09486700245857177
Validation loss: 2.297547771542752

Epoch: 5| Step: 6
Training loss: 0.14336059060477865
Validation loss: 2.327638271161612

Epoch: 5| Step: 7
Training loss: 0.10646277905570141
Validation loss: 2.31002352188281

Epoch: 5| Step: 8
Training loss: 0.15168703188664806
Validation loss: 2.3594326117379474

Epoch: 5| Step: 9
Training loss: 0.10289787003390581
Validation loss: 2.33682140418979

Epoch: 5| Step: 10
Training loss: 0.1398329349683313
Validation loss: 2.3242385522859355

Epoch: 728| Step: 0
Training loss: 0.10714348786812716
Validation loss: 2.307137936254694

Epoch: 5| Step: 1
Training loss: 0.1251833435383676
Validation loss: 2.3239157924846605

Epoch: 5| Step: 2
Training loss: 0.1039126627241063
Validation loss: 2.312782452158717

Epoch: 5| Step: 3
Training loss: 0.0990155179244539
Validation loss: 2.319831498593038

Epoch: 5| Step: 4
Training loss: 0.1277860898430487
Validation loss: 2.295147504080804

Epoch: 5| Step: 5
Training loss: 0.16242123675714096
Validation loss: 2.3036521280894564

Epoch: 5| Step: 6
Training loss: 0.07377924789740138
Validation loss: 2.296636186587355

Epoch: 5| Step: 7
Training loss: 0.08279005828460867
Validation loss: 2.317122322118266

Epoch: 5| Step: 8
Training loss: 0.12714986961484068
Validation loss: 2.3443015991082983

Epoch: 5| Step: 9
Training loss: 0.17867906213207022
Validation loss: 2.3481304713561113

Epoch: 5| Step: 10
Training loss: 0.09978958732307489
Validation loss: 2.3124398326501856

Epoch: 729| Step: 0
Training loss: 0.12336741431520223
Validation loss: 2.3234467065624904

Epoch: 5| Step: 1
Training loss: 0.07953553892217519
Validation loss: 2.373498823236211

Epoch: 5| Step: 2
Training loss: 0.15019229097142217
Validation loss: 2.3437607981662096

Epoch: 5| Step: 3
Training loss: 0.09198135749580959
Validation loss: 2.3182946195827747

Epoch: 5| Step: 4
Training loss: 0.0780248327650923
Validation loss: 2.321904307868194

Epoch: 5| Step: 5
Training loss: 0.1568385365081963
Validation loss: 2.3318793469832313

Epoch: 5| Step: 6
Training loss: 0.11847182069112938
Validation loss: 2.316249227092961

Epoch: 5| Step: 7
Training loss: 0.14326917060760688
Validation loss: 2.346729283314869

Epoch: 5| Step: 8
Training loss: 0.10349879487892112
Validation loss: 2.3606423414116517

Epoch: 5| Step: 9
Training loss: 0.18441319716528692
Validation loss: 2.371068670214488

Epoch: 5| Step: 10
Training loss: 0.11848637861242738
Validation loss: 2.348255141073391

Epoch: 730| Step: 0
Training loss: 0.10935407251010712
Validation loss: 2.324757470761465

Epoch: 5| Step: 1
Training loss: 0.17597449065416665
Validation loss: 2.3070034987046637

Epoch: 5| Step: 2
Training loss: 0.1772995334909028
Validation loss: 2.320730893729404

Epoch: 5| Step: 3
Training loss: 0.13686881685008404
Validation loss: 2.3194689175145244

Epoch: 5| Step: 4
Training loss: 0.08361848427370115
Validation loss: 2.303123298983112

Epoch: 5| Step: 5
Training loss: 0.1836839210976721
Validation loss: 2.305014381983101

Epoch: 5| Step: 6
Training loss: 0.1202884902467276
Validation loss: 2.301442375334487

Epoch: 5| Step: 7
Training loss: 0.11113530325486771
Validation loss: 2.3188157333460238

Epoch: 5| Step: 8
Training loss: 0.1400620996209056
Validation loss: 2.3488811260770124

Epoch: 5| Step: 9
Training loss: 0.10898113861200803
Validation loss: 2.3125659386685604

Epoch: 5| Step: 10
Training loss: 0.09679421471241402
Validation loss: 2.327120718292747

Epoch: 731| Step: 0
Training loss: 0.18039242711742723
Validation loss: 2.312265868170177

Epoch: 5| Step: 1
Training loss: 0.11798650626893555
Validation loss: 2.2938889058976706

Epoch: 5| Step: 2
Training loss: 0.1706482554663845
Validation loss: 2.3032606588191666

Epoch: 5| Step: 3
Training loss: 0.11682315852822879
Validation loss: 2.3271785204310476

Epoch: 5| Step: 4
Training loss: 0.08937983884083538
Validation loss: 2.333944061297728

Epoch: 5| Step: 5
Training loss: 0.08131542838220071
Validation loss: 2.364202092354182

Epoch: 5| Step: 6
Training loss: 0.17144719439829773
Validation loss: 2.3676093839784844

Epoch: 5| Step: 7
Training loss: 0.10088281430026058
Validation loss: 2.3483352425891644

Epoch: 5| Step: 8
Training loss: 0.12556569424236136
Validation loss: 2.3139893032732934

Epoch: 5| Step: 9
Training loss: 0.204845750945886
Validation loss: 2.335759188095535

Epoch: 5| Step: 10
Training loss: 0.11445042278237537
Validation loss: 2.3070362590160367

Epoch: 732| Step: 0
Training loss: 0.11642195672439494
Validation loss: 2.3319778412906444

Epoch: 5| Step: 1
Training loss: 0.12366901277518148
Validation loss: 2.3710374628321196

Epoch: 5| Step: 2
Training loss: 0.14761441813907375
Validation loss: 2.3912072080988906

Epoch: 5| Step: 3
Training loss: 0.16003437755115651
Validation loss: 2.3592004372548288

Epoch: 5| Step: 4
Training loss: 0.14799094791937362
Validation loss: 2.320355775093353

Epoch: 5| Step: 5
Training loss: 0.09379299985699144
Validation loss: 2.3177609148152643

Epoch: 5| Step: 6
Training loss: 0.07286086317117774
Validation loss: 2.2717926392095116

Epoch: 5| Step: 7
Training loss: 0.16443587006500912
Validation loss: 2.276860656026538

Epoch: 5| Step: 8
Training loss: 0.1358855471592729
Validation loss: 2.265429649658109

Epoch: 5| Step: 9
Training loss: 0.17243076008597086
Validation loss: 2.273416915793038

Epoch: 5| Step: 10
Training loss: 0.18480609789245428
Validation loss: 2.3008233392145283

Epoch: 733| Step: 0
Training loss: 0.10929397153099497
Validation loss: 2.3067773264066918

Epoch: 5| Step: 1
Training loss: 0.14685837367487878
Validation loss: 2.3302040713480467

Epoch: 5| Step: 2
Training loss: 0.15367023966529517
Validation loss: 2.315174298045655

Epoch: 5| Step: 3
Training loss: 0.1420018293840475
Validation loss: 2.2804056960371395

Epoch: 5| Step: 4
Training loss: 0.16290057950054337
Validation loss: 2.299662677689617

Epoch: 5| Step: 5
Training loss: 0.14001486794039641
Validation loss: 2.3047402897443368

Epoch: 5| Step: 6
Training loss: 0.09712056580385332
Validation loss: 2.294048731059744

Epoch: 5| Step: 7
Training loss: 0.09242535593437913
Validation loss: 2.3568320682075883

Epoch: 5| Step: 8
Training loss: 0.12592565261877323
Validation loss: 2.33768725445515

Epoch: 5| Step: 9
Training loss: 0.14784944273261832
Validation loss: 2.338394640211978

Epoch: 5| Step: 10
Training loss: 0.09377486177440372
Validation loss: 2.3811500485813943

Epoch: 734| Step: 0
Training loss: 0.12560191371740728
Validation loss: 2.3728267944215844

Epoch: 5| Step: 1
Training loss: 0.1008600001238207
Validation loss: 2.3608021957714924

Epoch: 5| Step: 2
Training loss: 0.15538940657439565
Validation loss: 2.356933214685933

Epoch: 5| Step: 3
Training loss: 0.10769077803426341
Validation loss: 2.3196447740338804

Epoch: 5| Step: 4
Training loss: 0.1471223733966501
Validation loss: 2.3197559307761475

Epoch: 5| Step: 5
Training loss: 0.13148183952783632
Validation loss: 2.3403133537595857

Epoch: 5| Step: 6
Training loss: 0.09335601493343351
Validation loss: 2.3054307487563612

Epoch: 5| Step: 7
Training loss: 0.1415817181066333
Validation loss: 2.3222175766423354

Epoch: 5| Step: 8
Training loss: 0.14146263937185266
Validation loss: 2.3171175546794665

Epoch: 5| Step: 9
Training loss: 0.09474597810586019
Validation loss: 2.321399132511375

Epoch: 5| Step: 10
Training loss: 0.11172827533315648
Validation loss: 2.365328211514199

Epoch: 735| Step: 0
Training loss: 0.13997581096280712
Validation loss: 2.4087538640037653

Epoch: 5| Step: 1
Training loss: 0.10178455506587263
Validation loss: 2.3543368161982885

Epoch: 5| Step: 2
Training loss: 0.07815286020381038
Validation loss: 2.364581335544939

Epoch: 5| Step: 3
Training loss: 0.1319409976126987
Validation loss: 2.3421726292253817

Epoch: 5| Step: 4
Training loss: 0.09022945559909801
Validation loss: 2.359446142501714

Epoch: 5| Step: 5
Training loss: 0.0958217838919282
Validation loss: 2.341491108901443

Epoch: 5| Step: 6
Training loss: 0.10406645385001098
Validation loss: 2.363019452009678

Epoch: 5| Step: 7
Training loss: 0.12093879414390873
Validation loss: 2.340277721463899

Epoch: 5| Step: 8
Training loss: 0.10771955080373784
Validation loss: 2.359727895176209

Epoch: 5| Step: 9
Training loss: 0.09436842968945304
Validation loss: 2.383022548294263

Epoch: 5| Step: 10
Training loss: 0.13655849328699327
Validation loss: 2.348886156475062

Epoch: 736| Step: 0
Training loss: 0.09168975240902533
Validation loss: 2.3696800323736187

Epoch: 5| Step: 1
Training loss: 0.1562028813842449
Validation loss: 2.382492704027478

Epoch: 5| Step: 2
Training loss: 0.07314845763441186
Validation loss: 2.349902033547481

Epoch: 5| Step: 3
Training loss: 0.09537886161973447
Validation loss: 2.360890132963435

Epoch: 5| Step: 4
Training loss: 0.08442312232583496
Validation loss: 2.3748810376185685

Epoch: 5| Step: 5
Training loss: 0.09995799672614843
Validation loss: 2.3224521468463366

Epoch: 5| Step: 6
Training loss: 0.10606612026209902
Validation loss: 2.33583612044026

Epoch: 5| Step: 7
Training loss: 0.14050896148593645
Validation loss: 2.3366387426197504

Epoch: 5| Step: 8
Training loss: 0.08981500041231244
Validation loss: 2.3160636435583095

Epoch: 5| Step: 9
Training loss: 0.07736039620740365
Validation loss: 2.315833054658956

Epoch: 5| Step: 10
Training loss: 0.08723553130954836
Validation loss: 2.3096603512326674

Epoch: 737| Step: 0
Training loss: 0.12079591810695889
Validation loss: 2.3265577903508214

Epoch: 5| Step: 1
Training loss: 0.07648930371548236
Validation loss: 2.345683336701711

Epoch: 5| Step: 2
Training loss: 0.13307703544329225
Validation loss: 2.3257978193740496

Epoch: 5| Step: 3
Training loss: 0.12247934476871696
Validation loss: 2.3611519219367914

Epoch: 5| Step: 4
Training loss: 0.11229411780333803
Validation loss: 2.339571265579603

Epoch: 5| Step: 5
Training loss: 0.0781151824981521
Validation loss: 2.3699089258377084

Epoch: 5| Step: 6
Training loss: 0.07754338250028936
Validation loss: 2.3750493541569937

Epoch: 5| Step: 7
Training loss: 0.11112108554210466
Validation loss: 2.3492791698175814

Epoch: 5| Step: 8
Training loss: 0.09883397899222326
Validation loss: 2.388681948497544

Epoch: 5| Step: 9
Training loss: 0.10840671954434035
Validation loss: 2.3407283827213425

Epoch: 5| Step: 10
Training loss: 0.10430753739107843
Validation loss: 2.3338839002983245

Epoch: 738| Step: 0
Training loss: 0.179983341237585
Validation loss: 2.3348409002266868

Epoch: 5| Step: 1
Training loss: 0.05742507766693262
Validation loss: 2.3254974970012823

Epoch: 5| Step: 2
Training loss: 0.1358537558500789
Validation loss: 2.3327653295354462

Epoch: 5| Step: 3
Training loss: 0.12450034145658846
Validation loss: 2.3175171523811167

Epoch: 5| Step: 4
Training loss: 0.07395451338847187
Validation loss: 2.3364685208985247

Epoch: 5| Step: 5
Training loss: 0.07991955630256738
Validation loss: 2.3450411362405674

Epoch: 5| Step: 6
Training loss: 0.07488569387922839
Validation loss: 2.3290979566060543

Epoch: 5| Step: 7
Training loss: 0.07917787555922981
Validation loss: 2.3353197432797663

Epoch: 5| Step: 8
Training loss: 0.06903102142797804
Validation loss: 2.3110710025773966

Epoch: 5| Step: 9
Training loss: 0.10377738354276847
Validation loss: 2.346874349344503

Epoch: 5| Step: 10
Training loss: 0.046647356021268065
Validation loss: 2.327327836527841

Epoch: 739| Step: 0
Training loss: 0.07126516111319524
Validation loss: 2.3532304698186013

Epoch: 5| Step: 1
Training loss: 0.10073510932388448
Validation loss: 2.331565040398435

Epoch: 5| Step: 2
Training loss: 0.1246617255066234
Validation loss: 2.3650674238135103

Epoch: 5| Step: 3
Training loss: 0.07085232667030306
Validation loss: 2.294293106926553

Epoch: 5| Step: 4
Training loss: 0.11149513533536838
Validation loss: 2.3234147789891555

Epoch: 5| Step: 5
Training loss: 0.08092198366760747
Validation loss: 2.313744490315709

Epoch: 5| Step: 6
Training loss: 0.0867184999823188
Validation loss: 2.3098683469652186

Epoch: 5| Step: 7
Training loss: 0.04870614551354069
Validation loss: 2.324945089984315

Epoch: 5| Step: 8
Training loss: 0.08536864978221789
Validation loss: 2.327250109589341

Epoch: 5| Step: 9
Training loss: 0.09995146519814048
Validation loss: 2.3145549416186384

Epoch: 5| Step: 10
Training loss: 0.1389154725826758
Validation loss: 2.318517610061203

Epoch: 740| Step: 0
Training loss: 0.14225064515627894
Validation loss: 2.29415423015101

Epoch: 5| Step: 1
Training loss: 0.10111193943588649
Validation loss: 2.3069833740128565

Epoch: 5| Step: 2
Training loss: 0.1086635397930657
Validation loss: 2.333689736762508

Epoch: 5| Step: 3
Training loss: 0.07749302179410668
Validation loss: 2.280069026685619

Epoch: 5| Step: 4
Training loss: 0.08812687698522954
Validation loss: 2.2904320668049154

Epoch: 5| Step: 5
Training loss: 0.152899261166373
Validation loss: 2.323330325926838

Epoch: 5| Step: 6
Training loss: 0.12824308431673737
Validation loss: 2.302201063465886

Epoch: 5| Step: 7
Training loss: 0.13189296195566613
Validation loss: 2.3114959545891316

Epoch: 5| Step: 8
Training loss: 0.09946074335985576
Validation loss: 2.254585034662671

Epoch: 5| Step: 9
Training loss: 0.19131539582432108
Validation loss: 2.2500518857791167

Epoch: 5| Step: 10
Training loss: 0.10841763816072521
Validation loss: 2.253245666384908

Epoch: 741| Step: 0
Training loss: 0.14540012266078128
Validation loss: 2.2556599886556317

Epoch: 5| Step: 1
Training loss: 0.12507088707563097
Validation loss: 2.2896705454596376

Epoch: 5| Step: 2
Training loss: 0.11796100366814016
Validation loss: 2.3068731707102277

Epoch: 5| Step: 3
Training loss: 0.11594054878729798
Validation loss: 2.3559617445780265

Epoch: 5| Step: 4
Training loss: 0.11655751807020964
Validation loss: 2.3222402232143415

Epoch: 5| Step: 5
Training loss: 0.11207694305611438
Validation loss: 2.323357717399879

Epoch: 5| Step: 6
Training loss: 0.13274009217404698
Validation loss: 2.31683034403483

Epoch: 5| Step: 7
Training loss: 0.14932303055314386
Validation loss: 2.2700778776684505

Epoch: 5| Step: 8
Training loss: 0.1117183346840668
Validation loss: 2.2477463558540203

Epoch: 5| Step: 9
Training loss: 0.07710197111719755
Validation loss: 2.241683731291671

Epoch: 5| Step: 10
Training loss: 0.09439866347989512
Validation loss: 2.2276852384754218

Epoch: 742| Step: 0
Training loss: 0.11539581272961598
Validation loss: 2.2398810892471435

Epoch: 5| Step: 1
Training loss: 0.08371236465277118
Validation loss: 2.2816493883971365

Epoch: 5| Step: 2
Training loss: 0.06967582806958145
Validation loss: 2.28492808290131

Epoch: 5| Step: 3
Training loss: 0.14873296418729642
Validation loss: 2.3252934907185874

Epoch: 5| Step: 4
Training loss: 0.16461297057089821
Validation loss: 2.3462689957549125

Epoch: 5| Step: 5
Training loss: 0.15605355072562313
Validation loss: 2.344474982246948

Epoch: 5| Step: 6
Training loss: 0.07780939368861317
Validation loss: 2.3135251647201427

Epoch: 5| Step: 7
Training loss: 0.13238800453997193
Validation loss: 2.2949820464132564

Epoch: 5| Step: 8
Training loss: 0.13130826962232553
Validation loss: 2.244851726098463

Epoch: 5| Step: 9
Training loss: 0.10678391890083319
Validation loss: 2.287513680150712

Epoch: 5| Step: 10
Training loss: 0.11469979671123103
Validation loss: 2.313261157935369

Epoch: 743| Step: 0
Training loss: 0.07932407084266345
Validation loss: 2.2818800645679476

Epoch: 5| Step: 1
Training loss: 0.06085527616196503
Validation loss: 2.32995390701245

Epoch: 5| Step: 2
Training loss: 0.15028688642799679
Validation loss: 2.3715948035741126

Epoch: 5| Step: 3
Training loss: 0.11752022160230163
Validation loss: 2.328517905164945

Epoch: 5| Step: 4
Training loss: 0.07974647543837077
Validation loss: 2.3290871014667105

Epoch: 5| Step: 5
Training loss: 0.12375490523861328
Validation loss: 2.315462516814581

Epoch: 5| Step: 6
Training loss: 0.17096645091753895
Validation loss: 2.3114392121024543

Epoch: 5| Step: 7
Training loss: 0.15176205352984284
Validation loss: 2.3365253445917262

Epoch: 5| Step: 8
Training loss: 0.10952105307355933
Validation loss: 2.3301778418425987

Epoch: 5| Step: 9
Training loss: 0.1558239253560794
Validation loss: 2.3906748755271834

Epoch: 5| Step: 10
Training loss: 0.06629238113049381
Validation loss: 2.374345916030151

Epoch: 744| Step: 0
Training loss: 0.14186391532969053
Validation loss: 2.400822336603161

Epoch: 5| Step: 1
Training loss: 0.18090248871090917
Validation loss: 2.441139206455398

Epoch: 5| Step: 2
Training loss: 0.17992097779024194
Validation loss: 2.4282707639700067

Epoch: 5| Step: 3
Training loss: 0.1916448118527704
Validation loss: 2.411991596671955

Epoch: 5| Step: 4
Training loss: 0.11517945694358575
Validation loss: 2.37885974926347

Epoch: 5| Step: 5
Training loss: 0.10771807668335484
Validation loss: 2.3321890405647228

Epoch: 5| Step: 6
Training loss: 0.127215327410104
Validation loss: 2.3091946975592874

Epoch: 5| Step: 7
Training loss: 0.12542086025790838
Validation loss: 2.252900085606076

Epoch: 5| Step: 8
Training loss: 0.18302753061348723
Validation loss: 2.282213068737075

Epoch: 5| Step: 9
Training loss: 0.09146815143919794
Validation loss: 2.3163295444638297

Epoch: 5| Step: 10
Training loss: 0.1563896747003413
Validation loss: 2.321649675918021

Epoch: 745| Step: 0
Training loss: 0.10712243306607666
Validation loss: 2.357596528113632

Epoch: 5| Step: 1
Training loss: 0.17025512048083302
Validation loss: 2.3905297360308766

Epoch: 5| Step: 2
Training loss: 0.13489270093096598
Validation loss: 2.4181895074341577

Epoch: 5| Step: 3
Training loss: 0.12211283896689414
Validation loss: 2.371474519075722

Epoch: 5| Step: 4
Training loss: 0.13562362625155872
Validation loss: 2.3396226239286793

Epoch: 5| Step: 5
Training loss: 0.19285662633016837
Validation loss: 2.307645879752523

Epoch: 5| Step: 6
Training loss: 0.11326511449010739
Validation loss: 2.3013579138296882

Epoch: 5| Step: 7
Training loss: 0.16012229792156146
Validation loss: 2.274144846802657

Epoch: 5| Step: 8
Training loss: 0.1773474432438851
Validation loss: 2.2818193167756857

Epoch: 5| Step: 9
Training loss: 0.16081447945617078
Validation loss: 2.3297039034348566

Epoch: 5| Step: 10
Training loss: 0.11300922074480534
Validation loss: 2.35811939389504

Epoch: 746| Step: 0
Training loss: 0.13386267704262256
Validation loss: 2.3482403285493008

Epoch: 5| Step: 1
Training loss: 0.10227255474272297
Validation loss: 2.3928985390529482

Epoch: 5| Step: 2
Training loss: 0.2247680352472586
Validation loss: 2.410684276402058

Epoch: 5| Step: 3
Training loss: 0.14648811971328432
Validation loss: 2.363278377500365

Epoch: 5| Step: 4
Training loss: 0.15122769604121275
Validation loss: 2.3316063837001364

Epoch: 5| Step: 5
Training loss: 0.1869401720201026
Validation loss: 2.307152463748529

Epoch: 5| Step: 6
Training loss: 0.22147851798304313
Validation loss: 2.2926995429507904

Epoch: 5| Step: 7
Training loss: 0.08245417585709898
Validation loss: 2.328960842639415

Epoch: 5| Step: 8
Training loss: 0.13180179153751162
Validation loss: 2.3514471096969127

Epoch: 5| Step: 9
Training loss: 0.13942292818806504
Validation loss: 2.385326331305688

Epoch: 5| Step: 10
Training loss: 0.14841777896379518
Validation loss: 2.3973282404065777

Epoch: 747| Step: 0
Training loss: 0.16146874522406096
Validation loss: 2.3747737994846556

Epoch: 5| Step: 1
Training loss: 0.12138116091881146
Validation loss: 2.385626499999003

Epoch: 5| Step: 2
Training loss: 0.10349895235063541
Validation loss: 2.323714611224826

Epoch: 5| Step: 3
Training loss: 0.13228757991510806
Validation loss: 2.305389247404221

Epoch: 5| Step: 4
Training loss: 0.13859579524538465
Validation loss: 2.2997367286434263

Epoch: 5| Step: 5
Training loss: 0.15077846232984918
Validation loss: 2.295591121531576

Epoch: 5| Step: 6
Training loss: 0.11387110338626172
Validation loss: 2.320597487244522

Epoch: 5| Step: 7
Training loss: 0.16094436029052808
Validation loss: 2.3184080694753546

Epoch: 5| Step: 8
Training loss: 0.15950341450727037
Validation loss: 2.3216934621818903

Epoch: 5| Step: 9
Training loss: 0.13455999968810825
Validation loss: 2.355219774701492

Epoch: 5| Step: 10
Training loss: 0.184247264014237
Validation loss: 2.388859503821986

Epoch: 748| Step: 0
Training loss: 0.1476546587681684
Validation loss: 2.409335871953156

Epoch: 5| Step: 1
Training loss: 0.15598855198713993
Validation loss: 2.3939208270555783

Epoch: 5| Step: 2
Training loss: 0.14325218376980026
Validation loss: 2.3274792633696073

Epoch: 5| Step: 3
Training loss: 0.16108165275595313
Validation loss: 2.301438956687538

Epoch: 5| Step: 4
Training loss: 0.12046822372153346
Validation loss: 2.3054435734249092

Epoch: 5| Step: 5
Training loss: 0.08691003875847927
Validation loss: 2.296285405571287

Epoch: 5| Step: 6
Training loss: 0.10169618318150873
Validation loss: 2.2857974964267886

Epoch: 5| Step: 7
Training loss: 0.08797549018226682
Validation loss: 2.3103567954754465

Epoch: 5| Step: 8
Training loss: 0.1665546418245454
Validation loss: 2.352774019105114

Epoch: 5| Step: 9
Training loss: 0.18057192953357243
Validation loss: 2.35815264156996

Epoch: 5| Step: 10
Training loss: 0.24298413832037682
Validation loss: 2.410427950211368

Epoch: 749| Step: 0
Training loss: 0.10907153622949227
Validation loss: 2.3174221620294433

Epoch: 5| Step: 1
Training loss: 0.08347448827944988
Validation loss: 2.2713233238106763

Epoch: 5| Step: 2
Training loss: 0.24144246499468952
Validation loss: 2.253082027437681

Epoch: 5| Step: 3
Training loss: 0.17488626356130182
Validation loss: 2.303068120525682

Epoch: 5| Step: 4
Training loss: 0.16633778336641938
Validation loss: 2.332488620887119

Epoch: 5| Step: 5
Training loss: 0.26213083989446523
Validation loss: 2.420194075206058

Epoch: 5| Step: 6
Training loss: 0.2427308923786404
Validation loss: 2.4067233147100033

Epoch: 5| Step: 7
Training loss: 0.11948248017889984
Validation loss: 2.3742305591882915

Epoch: 5| Step: 8
Training loss: 0.18410134656842067
Validation loss: 2.333982303422985

Epoch: 5| Step: 9
Training loss: 0.2636607980167466
Validation loss: 2.2785477534455265

Epoch: 5| Step: 10
Training loss: 0.17480228997829378
Validation loss: 2.2543886457941738

Epoch: 750| Step: 0
Training loss: 0.1935226252201813
Validation loss: 2.3352672243426422

Epoch: 5| Step: 1
Training loss: 0.22818090100125216
Validation loss: 2.3469793941606323

Epoch: 5| Step: 2
Training loss: 0.1816787884726269
Validation loss: 2.4009720079477015

Epoch: 5| Step: 3
Training loss: 0.1855215858492046
Validation loss: 2.429731235612366

Epoch: 5| Step: 4
Training loss: 0.2314888715999286
Validation loss: 2.411861637820396

Epoch: 5| Step: 5
Training loss: 0.28459090536012616
Validation loss: 2.424232549055277

Epoch: 5| Step: 6
Training loss: 0.16869886427100186
Validation loss: 2.3350993064341963

Epoch: 5| Step: 7
Training loss: 0.14912729856201698
Validation loss: 2.3307777966634533

Epoch: 5| Step: 8
Training loss: 0.18588213497018027
Validation loss: 2.3110628992228683

Epoch: 5| Step: 9
Training loss: 0.2555258229283386
Validation loss: 2.329863568149867

Epoch: 5| Step: 10
Training loss: 0.20660965656791286
Validation loss: 2.3421517066814954

Testing loss: 2.959327485937185
