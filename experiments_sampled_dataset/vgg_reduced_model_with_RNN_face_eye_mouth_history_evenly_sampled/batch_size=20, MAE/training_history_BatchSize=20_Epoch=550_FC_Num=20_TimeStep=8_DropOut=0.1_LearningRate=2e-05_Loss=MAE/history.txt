Epoch: 1| Step: 0
Training loss: 5.354392051696777
Validation loss: 5.115055848193425

Epoch: 5| Step: 1
Training loss: 5.84393310546875
Validation loss: 5.09849948780511

Epoch: 5| Step: 2
Training loss: 4.059883117675781
Validation loss: 5.082304334127775

Epoch: 5| Step: 3
Training loss: 5.529372215270996
Validation loss: 5.06371420685963

Epoch: 5| Step: 4
Training loss: 5.481503963470459
Validation loss: 5.042419777121595

Epoch: 5| Step: 5
Training loss: 4.7276930809021
Validation loss: 5.016927980607556

Epoch: 5| Step: 6
Training loss: 4.689360618591309
Validation loss: 4.988048174047983

Epoch: 5| Step: 7
Training loss: 4.240286827087402
Validation loss: 4.954420161503617

Epoch: 5| Step: 8
Training loss: 4.070521354675293
Validation loss: 4.917647925756311

Epoch: 5| Step: 9
Training loss: 4.097855567932129
Validation loss: 4.8760628751529165

Epoch: 5| Step: 10
Training loss: 4.656265735626221
Validation loss: 4.831637121015979

Epoch: 2| Step: 0
Training loss: 5.114485740661621
Validation loss: 4.781647846262942

Epoch: 5| Step: 1
Training loss: 4.110141754150391
Validation loss: 4.7287521208486245

Epoch: 5| Step: 2
Training loss: 5.119467258453369
Validation loss: 4.670571065718128

Epoch: 5| Step: 3
Training loss: 5.047979831695557
Validation loss: 4.610757514994631

Epoch: 5| Step: 4
Training loss: 4.4064040184021
Validation loss: 4.545019149780273

Epoch: 5| Step: 5
Training loss: 3.864150285720825
Validation loss: 4.477212439301193

Epoch: 5| Step: 6
Training loss: 4.047976493835449
Validation loss: 4.404121952672159

Epoch: 5| Step: 7
Training loss: 3.898834228515625
Validation loss: 4.335714509410243

Epoch: 5| Step: 8
Training loss: 3.293801784515381
Validation loss: 4.269098604879072

Epoch: 5| Step: 9
Training loss: 5.006472587585449
Validation loss: 4.209430961198704

Epoch: 5| Step: 10
Training loss: 2.9706995487213135
Validation loss: 4.155740809696977

Epoch: 3| Step: 0
Training loss: 3.6195693016052246
Validation loss: 4.108406246349376

Epoch: 5| Step: 1
Training loss: 5.335356712341309
Validation loss: 4.06510329246521

Epoch: 5| Step: 2
Training loss: 3.7813382148742676
Validation loss: 4.02084259833059

Epoch: 5| Step: 3
Training loss: 3.5019707679748535
Validation loss: 3.9810419826097387

Epoch: 5| Step: 4
Training loss: 3.0223584175109863
Validation loss: 3.9488082239704747

Epoch: 5| Step: 5
Training loss: 3.2921226024627686
Validation loss: 3.9159085571124987

Epoch: 5| Step: 6
Training loss: 3.6419148445129395
Validation loss: 3.8846150008581017

Epoch: 5| Step: 7
Training loss: 3.6242949962615967
Validation loss: 3.8552665838631253

Epoch: 5| Step: 8
Training loss: 4.505370140075684
Validation loss: 3.8281310655737437

Epoch: 5| Step: 9
Training loss: 3.4573593139648438
Validation loss: 3.797284949210382

Epoch: 5| Step: 10
Training loss: 3.9089319705963135
Validation loss: 3.7679192430229596

Epoch: 4| Step: 0
Training loss: 2.9891929626464844
Validation loss: 3.739583266678677

Epoch: 5| Step: 1
Training loss: 2.992530345916748
Validation loss: 3.7145809409438924

Epoch: 5| Step: 2
Training loss: 3.611464262008667
Validation loss: 3.6908432232436312

Epoch: 5| Step: 3
Training loss: 4.726528644561768
Validation loss: 3.6688915888468423

Epoch: 5| Step: 4
Training loss: 3.368166446685791
Validation loss: 3.6470280257604455

Epoch: 5| Step: 5
Training loss: 4.206820011138916
Validation loss: 3.6267475107664704

Epoch: 5| Step: 6
Training loss: 3.6803996562957764
Validation loss: 3.604923040636124

Epoch: 5| Step: 7
Training loss: 3.9096763134002686
Validation loss: 3.5869745310916694

Epoch: 5| Step: 8
Training loss: 3.3081729412078857
Validation loss: 3.570347550094769

Epoch: 5| Step: 9
Training loss: 2.565869092941284
Validation loss: 3.5515247468025453

Epoch: 5| Step: 10
Training loss: 3.6306302547454834
Validation loss: 3.533539861761114

Epoch: 5| Step: 0
Training loss: 2.155048131942749
Validation loss: 3.516977920327135

Epoch: 5| Step: 1
Training loss: 3.634507656097412
Validation loss: 3.506384593184276

Epoch: 5| Step: 2
Training loss: 4.613776683807373
Validation loss: 3.4937616317502913

Epoch: 5| Step: 3
Training loss: 3.5548641681671143
Validation loss: 3.4832142783749487

Epoch: 5| Step: 4
Training loss: 3.7460827827453613
Validation loss: 3.455426936508507

Epoch: 5| Step: 5
Training loss: 3.519036054611206
Validation loss: 3.436327483064385

Epoch: 5| Step: 6
Training loss: 3.9193496704101562
Validation loss: 3.4218831267408145

Epoch: 5| Step: 7
Training loss: 2.5281598567962646
Validation loss: 3.4037288927262828

Epoch: 5| Step: 8
Training loss: 2.8699607849121094
Validation loss: 3.3927408290165726

Epoch: 5| Step: 9
Training loss: 3.3688559532165527
Validation loss: 3.3769863677281204

Epoch: 5| Step: 10
Training loss: 3.295667886734009
Validation loss: 3.3658970632860736

Epoch: 6| Step: 0
Training loss: 2.1836390495300293
Validation loss: 3.3515217611866612

Epoch: 5| Step: 1
Training loss: 2.9766182899475098
Validation loss: 3.341113018733199

Epoch: 5| Step: 2
Training loss: 4.940188884735107
Validation loss: 3.330308009219426

Epoch: 5| Step: 3
Training loss: 3.8571078777313232
Validation loss: 3.3173781133467153

Epoch: 5| Step: 4
Training loss: 3.2200675010681152
Validation loss: 3.3029293091066423

Epoch: 5| Step: 5
Training loss: 3.1971142292022705
Validation loss: 3.300200544377809

Epoch: 5| Step: 6
Training loss: 3.040741205215454
Validation loss: 3.2833858971954673

Epoch: 5| Step: 7
Training loss: 3.116248369216919
Validation loss: 3.2740429755180114

Epoch: 5| Step: 8
Training loss: 3.4657680988311768
Validation loss: 3.2640174665758686

Epoch: 5| Step: 9
Training loss: 3.2050976753234863
Validation loss: 3.251939078812958

Epoch: 5| Step: 10
Training loss: 2.660946846008301
Validation loss: 3.2415266447169806

Epoch: 7| Step: 0
Training loss: 3.3871910572052
Validation loss: 3.233167209932881

Epoch: 5| Step: 1
Training loss: 4.0134711265563965
Validation loss: 3.2216645825293755

Epoch: 5| Step: 2
Training loss: 2.6866700649261475
Validation loss: 3.2151387173642396

Epoch: 5| Step: 3
Training loss: 2.2021431922912598
Validation loss: 3.2029355956662084

Epoch: 5| Step: 4
Training loss: 2.8885669708251953
Validation loss: 3.1962583372669835

Epoch: 5| Step: 5
Training loss: 3.1903438568115234
Validation loss: 3.1928151474204114

Epoch: 5| Step: 6
Training loss: 2.8906171321868896
Validation loss: 3.180629943006782

Epoch: 5| Step: 7
Training loss: 3.497288465499878
Validation loss: 3.166343709473969

Epoch: 5| Step: 8
Training loss: 3.2780463695526123
Validation loss: 3.159581043386972

Epoch: 5| Step: 9
Training loss: 3.398470640182495
Validation loss: 3.152538199578562

Epoch: 5| Step: 10
Training loss: 3.741121530532837
Validation loss: 3.1521171113496185

Epoch: 8| Step: 0
Training loss: 3.1275007724761963
Validation loss: 3.1430510910608436

Epoch: 5| Step: 1
Training loss: 3.493124485015869
Validation loss: 3.145202634155109

Epoch: 5| Step: 2
Training loss: 3.90873384475708
Validation loss: 3.1385838190714517

Epoch: 5| Step: 3
Training loss: 2.339770555496216
Validation loss: 3.123198773271294

Epoch: 5| Step: 4
Training loss: 3.2750420570373535
Validation loss: 3.118768822762274

Epoch: 5| Step: 5
Training loss: 3.352761745452881
Validation loss: 3.1124135730087117

Epoch: 5| Step: 6
Training loss: 3.2874207496643066
Validation loss: 3.1013847089582876

Epoch: 5| Step: 7
Training loss: 3.4880270957946777
Validation loss: 3.0981879029222714

Epoch: 5| Step: 8
Training loss: 3.4201035499572754
Validation loss: 3.090907806991249

Epoch: 5| Step: 9
Training loss: 2.655667543411255
Validation loss: 3.0796849317448114

Epoch: 5| Step: 10
Training loss: 2.0331058502197266
Validation loss: 3.0783239974770495

Epoch: 9| Step: 0
Training loss: 2.9757654666900635
Validation loss: 3.0882403466009323

Epoch: 5| Step: 1
Training loss: 2.9430365562438965
Validation loss: 3.0716653485451975

Epoch: 5| Step: 2
Training loss: 2.608991861343384
Validation loss: 3.058203325476698

Epoch: 5| Step: 3
Training loss: 3.1975789070129395
Validation loss: 3.0562547586297475

Epoch: 5| Step: 4
Training loss: 3.416774034500122
Validation loss: 3.056280123290195

Epoch: 5| Step: 5
Training loss: 3.346987247467041
Validation loss: 3.0410992535211707

Epoch: 5| Step: 6
Training loss: 2.7589361667633057
Validation loss: 3.050336014839911

Epoch: 5| Step: 7
Training loss: 3.3108012676239014
Validation loss: 3.07153050104777

Epoch: 5| Step: 8
Training loss: 2.70192813873291
Validation loss: 3.057822040332261

Epoch: 5| Step: 9
Training loss: 3.7464377880096436
Validation loss: 3.0414092463831746

Epoch: 5| Step: 10
Training loss: 3.1283061504364014
Validation loss: 3.031882475781184

Epoch: 10| Step: 0
Training loss: 3.083441972732544
Validation loss: 3.032537724382134

Epoch: 5| Step: 1
Training loss: 2.8893837928771973
Validation loss: 3.0275847270924556

Epoch: 5| Step: 2
Training loss: 3.315242290496826
Validation loss: 3.017675128034366

Epoch: 5| Step: 3
Training loss: 3.552647113800049
Validation loss: 3.009151192121608

Epoch: 5| Step: 4
Training loss: 3.2025630474090576
Validation loss: 3.004096226025653

Epoch: 5| Step: 5
Training loss: 3.2406420707702637
Validation loss: 2.998404969451248

Epoch: 5| Step: 6
Training loss: 2.4314846992492676
Validation loss: 2.9950502149520384

Epoch: 5| Step: 7
Training loss: 3.8028512001037598
Validation loss: 2.9858645213547574

Epoch: 5| Step: 8
Training loss: 2.717531442642212
Validation loss: 2.9805750744317168

Epoch: 5| Step: 9
Training loss: 2.8680062294006348
Validation loss: 2.9722336030775502

Epoch: 5| Step: 10
Training loss: 2.5862529277801514
Validation loss: 2.968548769591957

Epoch: 11| Step: 0
Training loss: 3.949333667755127
Validation loss: 2.9642554739470124

Epoch: 5| Step: 1
Training loss: 3.2639403343200684
Validation loss: 2.9573816535293416

Epoch: 5| Step: 2
Training loss: 2.741090774536133
Validation loss: 2.9545669606936875

Epoch: 5| Step: 3
Training loss: 2.654510498046875
Validation loss: 2.950320843727358

Epoch: 5| Step: 4
Training loss: 3.089524507522583
Validation loss: 2.9461606189768803

Epoch: 5| Step: 5
Training loss: 3.244807481765747
Validation loss: 2.945336321348785

Epoch: 5| Step: 6
Training loss: 2.3581745624542236
Validation loss: 2.9430539146546395

Epoch: 5| Step: 7
Training loss: 2.904761791229248
Validation loss: 2.9389530176757486

Epoch: 5| Step: 8
Training loss: 2.9281983375549316
Validation loss: 2.9355352386351554

Epoch: 5| Step: 9
Training loss: 3.687589168548584
Validation loss: 2.933253567705872

Epoch: 5| Step: 10
Training loss: 2.431891441345215
Validation loss: 2.931966350924584

Epoch: 12| Step: 0
Training loss: 3.02810001373291
Validation loss: 2.9288106938844085

Epoch: 5| Step: 1
Training loss: 3.005683422088623
Validation loss: 2.926612220784669

Epoch: 5| Step: 2
Training loss: 2.4274518489837646
Validation loss: 2.924367389371318

Epoch: 5| Step: 3
Training loss: 3.5725646018981934
Validation loss: 2.924495271457139

Epoch: 5| Step: 4
Training loss: 2.9298031330108643
Validation loss: 2.9190267824357554

Epoch: 5| Step: 5
Training loss: 2.930206775665283
Validation loss: 2.918948506796232

Epoch: 5| Step: 6
Training loss: 3.078247547149658
Validation loss: 2.9152136489909184

Epoch: 5| Step: 7
Training loss: 2.8759305477142334
Validation loss: 2.912526402422177

Epoch: 5| Step: 8
Training loss: 2.817955732345581
Validation loss: 2.912173742889076

Epoch: 5| Step: 9
Training loss: 3.3948893547058105
Validation loss: 2.9089325192154094

Epoch: 5| Step: 10
Training loss: 3.1019375324249268
Validation loss: 2.9076865385937434

Epoch: 13| Step: 0
Training loss: 2.9734506607055664
Validation loss: 2.9054689253530195

Epoch: 5| Step: 1
Training loss: 2.869821548461914
Validation loss: 2.9052863967034126

Epoch: 5| Step: 2
Training loss: 2.9935975074768066
Validation loss: 2.9021149399460002

Epoch: 5| Step: 3
Training loss: 2.7801201343536377
Validation loss: 2.9005179507758028

Epoch: 5| Step: 4
Training loss: 2.347669839859009
Validation loss: 2.897987655414048

Epoch: 5| Step: 5
Training loss: 2.958080768585205
Validation loss: 2.8965315485513337

Epoch: 5| Step: 6
Training loss: 2.533273220062256
Validation loss: 2.893162186427783

Epoch: 5| Step: 7
Training loss: 3.3556876182556152
Validation loss: 2.8920475488067954

Epoch: 5| Step: 8
Training loss: 3.385335922241211
Validation loss: 2.887280915373115

Epoch: 5| Step: 9
Training loss: 3.644479274749756
Validation loss: 2.884906117634107

Epoch: 5| Step: 10
Training loss: 3.1341562271118164
Validation loss: 2.883683227723645

Epoch: 14| Step: 0
Training loss: 3.153778553009033
Validation loss: 2.880837804527693

Epoch: 5| Step: 1
Training loss: 2.5042567253112793
Validation loss: 2.8827136716535016

Epoch: 5| Step: 2
Training loss: 3.896479368209839
Validation loss: 2.8761681279828473

Epoch: 5| Step: 3
Training loss: 3.4256129264831543
Validation loss: 2.877531208017821

Epoch: 5| Step: 4
Training loss: 2.9884731769561768
Validation loss: 2.8789655803352274

Epoch: 5| Step: 5
Training loss: 2.844651699066162
Validation loss: 2.8762485109349734

Epoch: 5| Step: 6
Training loss: 2.4943654537200928
Validation loss: 2.87147811407684

Epoch: 5| Step: 7
Training loss: 3.206555128097534
Validation loss: 2.8685909522477018

Epoch: 5| Step: 8
Training loss: 2.5822958946228027
Validation loss: 2.866840103621124

Epoch: 5| Step: 9
Training loss: 3.0407700538635254
Validation loss: 2.865512914555047

Epoch: 5| Step: 10
Training loss: 2.6360175609588623
Validation loss: 2.8643310326401905

Epoch: 15| Step: 0
Training loss: 3.4011473655700684
Validation loss: 2.8672067760139384

Epoch: 5| Step: 1
Training loss: 2.363579511642456
Validation loss: 2.8643630294389624

Epoch: 5| Step: 2
Training loss: 3.1227989196777344
Validation loss: 2.8634262597689064

Epoch: 5| Step: 3
Training loss: 3.138610363006592
Validation loss: 2.859048212728193

Epoch: 5| Step: 4
Training loss: 2.9132862091064453
Validation loss: 2.8584799356358026

Epoch: 5| Step: 5
Training loss: 2.656428575515747
Validation loss: 2.857248224237914

Epoch: 5| Step: 6
Training loss: 2.7942724227905273
Validation loss: 2.8534737453665784

Epoch: 5| Step: 7
Training loss: 2.943106174468994
Validation loss: 2.851542272875386

Epoch: 5| Step: 8
Training loss: 3.4413211345672607
Validation loss: 2.850718408502558

Epoch: 5| Step: 9
Training loss: 2.6921536922454834
Validation loss: 2.8456253492704002

Epoch: 5| Step: 10
Training loss: 3.2511343955993652
Validation loss: 2.8449409264390186

Epoch: 16| Step: 0
Training loss: 2.367553234100342
Validation loss: 2.840321792069302

Epoch: 5| Step: 1
Training loss: 2.72918963432312
Validation loss: 2.8399614134142475

Epoch: 5| Step: 2
Training loss: 2.717613935470581
Validation loss: 2.8466989763321413

Epoch: 5| Step: 3
Training loss: 3.559846878051758
Validation loss: 2.837063022839126

Epoch: 5| Step: 4
Training loss: 3.5730807781219482
Validation loss: 2.8329887774682816

Epoch: 5| Step: 5
Training loss: 2.8079781532287598
Validation loss: 2.8357277326686408

Epoch: 5| Step: 6
Training loss: 2.4886229038238525
Validation loss: 2.830749527100594

Epoch: 5| Step: 7
Training loss: 3.71272349357605
Validation loss: 2.8247669025134017

Epoch: 5| Step: 8
Training loss: 2.755009889602661
Validation loss: 2.824421275046564

Epoch: 5| Step: 9
Training loss: 2.7201004028320312
Validation loss: 2.8240230032192764

Epoch: 5| Step: 10
Training loss: 3.098665237426758
Validation loss: 2.8260675630261822

Epoch: 17| Step: 0
Training loss: 3.4486937522888184
Validation loss: 2.8223859674187115

Epoch: 5| Step: 1
Training loss: 2.798401355743408
Validation loss: 2.8172736167907715

Epoch: 5| Step: 2
Training loss: 1.793333649635315
Validation loss: 2.8144078818700646

Epoch: 5| Step: 3
Training loss: 3.3932831287384033
Validation loss: 2.811544556771555

Epoch: 5| Step: 4
Training loss: 3.628108501434326
Validation loss: 2.8084467226459133

Epoch: 5| Step: 5
Training loss: 3.206733226776123
Validation loss: 2.806608730746854

Epoch: 5| Step: 6
Training loss: 2.9587185382843018
Validation loss: 2.8042901715924664

Epoch: 5| Step: 7
Training loss: 3.179391860961914
Validation loss: 2.8044052559842347

Epoch: 5| Step: 8
Training loss: 2.313669204711914
Validation loss: 2.8081237295622468

Epoch: 5| Step: 9
Training loss: 2.6790175437927246
Validation loss: 2.814510335204422

Epoch: 5| Step: 10
Training loss: 2.9916176795959473
Validation loss: 2.810105477609942

Epoch: 18| Step: 0
Training loss: 2.1686229705810547
Validation loss: 2.800236512255925

Epoch: 5| Step: 1
Training loss: 3.584754228591919
Validation loss: 2.7960815916779223

Epoch: 5| Step: 2
Training loss: 3.420161485671997
Validation loss: 2.79443145567371

Epoch: 5| Step: 3
Training loss: 2.1434712409973145
Validation loss: 2.7890619206172165

Epoch: 5| Step: 4
Training loss: 2.8133597373962402
Validation loss: 2.7807099152636785

Epoch: 5| Step: 5
Training loss: 3.236016035079956
Validation loss: 2.7786375348285963

Epoch: 5| Step: 6
Training loss: 3.2618401050567627
Validation loss: 2.7801271228380102

Epoch: 5| Step: 7
Training loss: 2.9536774158477783
Validation loss: 2.77934129007401

Epoch: 5| Step: 8
Training loss: 2.6132452487945557
Validation loss: 2.7758898478682323

Epoch: 5| Step: 9
Training loss: 3.1616475582122803
Validation loss: 2.774372334121376

Epoch: 5| Step: 10
Training loss: 2.792975664138794
Validation loss: 2.772297672046128

Epoch: 19| Step: 0
Training loss: 2.4202027320861816
Validation loss: 2.769634269898938

Epoch: 5| Step: 1
Training loss: 3.561950206756592
Validation loss: 2.768718211881576

Epoch: 5| Step: 2
Training loss: 3.0039119720458984
Validation loss: 2.7691252846871652

Epoch: 5| Step: 3
Training loss: 3.06048321723938
Validation loss: 2.7694675794211765

Epoch: 5| Step: 4
Training loss: 3.1112499237060547
Validation loss: 2.769332011540731

Epoch: 5| Step: 5
Training loss: 2.817331314086914
Validation loss: 2.766116847274124

Epoch: 5| Step: 6
Training loss: 2.790048122406006
Validation loss: 2.7649807878719863

Epoch: 5| Step: 7
Training loss: 2.7679126262664795
Validation loss: 2.761630624853155

Epoch: 5| Step: 8
Training loss: 2.1401679515838623
Validation loss: 2.7621665513643654

Epoch: 5| Step: 9
Training loss: 3.4073777198791504
Validation loss: 2.7599253475025134

Epoch: 5| Step: 10
Training loss: 2.9805805683135986
Validation loss: 2.7581148070673787

Epoch: 20| Step: 0
Training loss: 3.1056416034698486
Validation loss: 2.7584497646618913

Epoch: 5| Step: 1
Training loss: 2.7005581855773926
Validation loss: 2.7593062359799623

Epoch: 5| Step: 2
Training loss: 2.392322063446045
Validation loss: 2.7567370655716106

Epoch: 5| Step: 3
Training loss: 2.406022548675537
Validation loss: 2.754074811935425

Epoch: 5| Step: 4
Training loss: 2.7923624515533447
Validation loss: 2.751798293923819

Epoch: 5| Step: 5
Training loss: 2.778907060623169
Validation loss: 2.7521043310883226

Epoch: 5| Step: 6
Training loss: 3.0730156898498535
Validation loss: 2.748760146479453

Epoch: 5| Step: 7
Training loss: 3.445791244506836
Validation loss: 2.754790218927527

Epoch: 5| Step: 8
Training loss: 2.616849660873413
Validation loss: 2.749610680405812

Epoch: 5| Step: 9
Training loss: 3.086294412612915
Validation loss: 2.750795133652226

Epoch: 5| Step: 10
Training loss: 3.6886918544769287
Validation loss: 2.7538125258620068

Epoch: 21| Step: 0
Training loss: 2.8745694160461426
Validation loss: 2.7544722864704747

Epoch: 5| Step: 1
Training loss: 2.2895355224609375
Validation loss: 2.7526917457580566

Epoch: 5| Step: 2
Training loss: 2.7215304374694824
Validation loss: 2.7517714705518497

Epoch: 5| Step: 3
Training loss: 3.008009195327759
Validation loss: 2.749944440780147

Epoch: 5| Step: 4
Training loss: 4.225050449371338
Validation loss: 2.7476420043617167

Epoch: 5| Step: 5
Training loss: 2.4580302238464355
Validation loss: 2.746794039203275

Epoch: 5| Step: 6
Training loss: 3.1347434520721436
Validation loss: 2.745581155182213

Epoch: 5| Step: 7
Training loss: 3.7406246662139893
Validation loss: 2.743690716323032

Epoch: 5| Step: 8
Training loss: 2.147331953048706
Validation loss: 2.7467968694625364

Epoch: 5| Step: 9
Training loss: 2.8587605953216553
Validation loss: 2.738980318910332

Epoch: 5| Step: 10
Training loss: 2.347984790802002
Validation loss: 2.7404645386562554

Epoch: 22| Step: 0
Training loss: 2.9552206993103027
Validation loss: 2.739290686063869

Epoch: 5| Step: 1
Training loss: 3.218043565750122
Validation loss: 2.7387245496114097

Epoch: 5| Step: 2
Training loss: 2.9967570304870605
Validation loss: 2.7381291799647833

Epoch: 5| Step: 3
Training loss: 3.0437428951263428
Validation loss: 2.7497196146236953

Epoch: 5| Step: 4
Training loss: 3.1763968467712402
Validation loss: 2.7505683001651557

Epoch: 5| Step: 5
Training loss: 2.7375712394714355
Validation loss: 2.7430564075387935

Epoch: 5| Step: 6
Training loss: 2.6825454235076904
Validation loss: 2.735096311056486

Epoch: 5| Step: 7
Training loss: 2.4126625061035156
Validation loss: 2.7325908830088954

Epoch: 5| Step: 8
Training loss: 2.491334915161133
Validation loss: 2.7325118818590717

Epoch: 5| Step: 9
Training loss: 3.2169413566589355
Validation loss: 2.798445306798463

Epoch: 5| Step: 10
Training loss: 2.9327685832977295
Validation loss: 2.7331381664481214

Epoch: 23| Step: 0
Training loss: 3.3752121925354004
Validation loss: 2.7293279068444365

Epoch: 5| Step: 1
Training loss: 2.8213212490081787
Validation loss: 2.7284081443663566

Epoch: 5| Step: 2
Training loss: 2.7908108234405518
Validation loss: 2.731126303313881

Epoch: 5| Step: 3
Training loss: 2.336780071258545
Validation loss: 2.732810115301481

Epoch: 5| Step: 4
Training loss: 2.4400928020477295
Validation loss: 2.7409726394120084

Epoch: 5| Step: 5
Training loss: 3.2368264198303223
Validation loss: 2.756479278687508

Epoch: 5| Step: 6
Training loss: 2.5733261108398438
Validation loss: 2.744104275139429

Epoch: 5| Step: 7
Training loss: 3.044071912765503
Validation loss: 2.7414302261926795

Epoch: 5| Step: 8
Training loss: 3.268660306930542
Validation loss: 2.7339328463359545

Epoch: 5| Step: 9
Training loss: 2.4572718143463135
Validation loss: 2.7320717201438

Epoch: 5| Step: 10
Training loss: 3.5362045764923096
Validation loss: 2.7302857598950787

Epoch: 24| Step: 0
Training loss: 2.3647773265838623
Validation loss: 2.7260853013684674

Epoch: 5| Step: 1
Training loss: 2.651017665863037
Validation loss: 2.7196720646273707

Epoch: 5| Step: 2
Training loss: 3.658808946609497
Validation loss: 2.71887957408864

Epoch: 5| Step: 3
Training loss: 2.430866241455078
Validation loss: 2.7154543040901102

Epoch: 5| Step: 4
Training loss: 2.3897342681884766
Validation loss: 2.715249423057802

Epoch: 5| Step: 5
Training loss: 3.0257303714752197
Validation loss: 2.7155731031971593

Epoch: 5| Step: 6
Training loss: 2.986196756362915
Validation loss: 2.7379924943370204

Epoch: 5| Step: 7
Training loss: 3.7393581867218018
Validation loss: 2.7569752303502892

Epoch: 5| Step: 8
Training loss: 2.788041830062866
Validation loss: 2.7507848867806057

Epoch: 5| Step: 9
Training loss: 2.8993160724639893
Validation loss: 2.7196201073226107

Epoch: 5| Step: 10
Training loss: 2.7059967517852783
Validation loss: 2.723352337396273

Epoch: 25| Step: 0
Training loss: 2.7356274127960205
Validation loss: 2.7957979914962605

Epoch: 5| Step: 1
Training loss: 3.1485772132873535
Validation loss: 2.805515666161814

Epoch: 5| Step: 2
Training loss: 2.971172332763672
Validation loss: 2.77514987350792

Epoch: 5| Step: 3
Training loss: 2.876286268234253
Validation loss: 2.787045189129409

Epoch: 5| Step: 4
Training loss: 3.4233412742614746
Validation loss: 2.8080523244796263

Epoch: 5| Step: 5
Training loss: 3.612943649291992
Validation loss: 2.848110539938814

Epoch: 5| Step: 6
Training loss: 3.115058422088623
Validation loss: 2.895783144940612

Epoch: 5| Step: 7
Training loss: 2.1619229316711426
Validation loss: 2.8261013774461645

Epoch: 5| Step: 8
Training loss: 2.7057878971099854
Validation loss: 2.8020012378692627

Epoch: 5| Step: 9
Training loss: 2.6592094898223877
Validation loss: 2.786969610439834

Epoch: 5| Step: 10
Training loss: 2.7909843921661377
Validation loss: 2.7976428718977076

Epoch: 26| Step: 0
Training loss: 3.5904641151428223
Validation loss: 2.848082673165106

Epoch: 5| Step: 1
Training loss: 2.9737186431884766
Validation loss: 2.8222291495210383

Epoch: 5| Step: 2
Training loss: 2.996788740158081
Validation loss: 2.8081833213888188

Epoch: 5| Step: 3
Training loss: 3.130852222442627
Validation loss: 2.786920150121053

Epoch: 5| Step: 4
Training loss: 3.2545387744903564
Validation loss: 2.7857508710635606

Epoch: 5| Step: 5
Training loss: 2.2905802726745605
Validation loss: 2.7730418841044107

Epoch: 5| Step: 6
Training loss: 2.6693389415740967
Validation loss: 2.765977313441615

Epoch: 5| Step: 7
Training loss: 3.003269910812378
Validation loss: 2.772122577954364

Epoch: 5| Step: 8
Training loss: 2.9983346462249756
Validation loss: 2.784590982621716

Epoch: 5| Step: 9
Training loss: 2.611367702484131
Validation loss: 2.7945619219092914

Epoch: 5| Step: 10
Training loss: 2.6066486835479736
Validation loss: 2.7973848081404165

Epoch: 27| Step: 0
Training loss: 3.0635757446289062
Validation loss: 2.7933836008912776

Epoch: 5| Step: 1
Training loss: 2.591804027557373
Validation loss: 2.8086112545382593

Epoch: 5| Step: 2
Training loss: 2.961639642715454
Validation loss: 2.7847858090554514

Epoch: 5| Step: 3
Training loss: 2.9260826110839844
Validation loss: 2.7671030618811168

Epoch: 5| Step: 4
Training loss: 2.9236652851104736
Validation loss: 2.7577692770188853

Epoch: 5| Step: 5
Training loss: 3.0911340713500977
Validation loss: 2.7534278131300405

Epoch: 5| Step: 6
Training loss: 2.5443763732910156
Validation loss: 2.7236886793567288

Epoch: 5| Step: 7
Training loss: 2.8999030590057373
Validation loss: 2.699328948092717

Epoch: 5| Step: 8
Training loss: 2.6417317390441895
Validation loss: 2.7037376280753844

Epoch: 5| Step: 9
Training loss: 3.017361640930176
Validation loss: 2.706650359656221

Epoch: 5| Step: 10
Training loss: 3.0872957706451416
Validation loss: 2.7053197096752863

Epoch: 28| Step: 0
Training loss: 3.048621416091919
Validation loss: 2.7049187306434876

Epoch: 5| Step: 1
Training loss: 2.9779438972473145
Validation loss: 2.696711596622262

Epoch: 5| Step: 2
Training loss: 2.4184958934783936
Validation loss: 2.695291639656149

Epoch: 5| Step: 3
Training loss: 2.5806527137756348
Validation loss: 2.6936392104753883

Epoch: 5| Step: 4
Training loss: 2.5802528858184814
Validation loss: 2.689254371068811

Epoch: 5| Step: 5
Training loss: 2.8089492321014404
Validation loss: 2.689857990511002

Epoch: 5| Step: 6
Training loss: 2.925454616546631
Validation loss: 2.7051858209794566

Epoch: 5| Step: 7
Training loss: 2.8167970180511475
Validation loss: 2.690227936672908

Epoch: 5| Step: 8
Training loss: 3.2197349071502686
Validation loss: 2.6898714137333695

Epoch: 5| Step: 9
Training loss: 2.4559688568115234
Validation loss: 2.6862167389162126

Epoch: 5| Step: 10
Training loss: 3.6918890476226807
Validation loss: 2.6848713633834675

Epoch: 29| Step: 0
Training loss: 3.124894380569458
Validation loss: 2.681263618571784

Epoch: 5| Step: 1
Training loss: 2.870722532272339
Validation loss: 2.6778503669205533

Epoch: 5| Step: 2
Training loss: 3.17130708694458
Validation loss: 2.6813438733418784

Epoch: 5| Step: 3
Training loss: 2.3284029960632324
Validation loss: 2.678212037650488

Epoch: 5| Step: 4
Training loss: 3.261714220046997
Validation loss: 2.6787818708727436

Epoch: 5| Step: 5
Training loss: 2.46177339553833
Validation loss: 2.6740867989037627

Epoch: 5| Step: 6
Training loss: 3.1921069622039795
Validation loss: 2.6720986622636036

Epoch: 5| Step: 7
Training loss: 3.194619655609131
Validation loss: 2.6696706715450493

Epoch: 5| Step: 8
Training loss: 2.570524215698242
Validation loss: 2.6709060438217653

Epoch: 5| Step: 9
Training loss: 2.2598891258239746
Validation loss: 2.6650618814652964

Epoch: 5| Step: 10
Training loss: 2.821394681930542
Validation loss: 2.6690012101204164

Epoch: 30| Step: 0
Training loss: 2.5108582973480225
Validation loss: 2.6773659029314594

Epoch: 5| Step: 1
Training loss: 2.2584068775177
Validation loss: 2.6945267928543912

Epoch: 5| Step: 2
Training loss: 3.2405006885528564
Validation loss: 2.7217671332820768

Epoch: 5| Step: 3
Training loss: 2.8721606731414795
Validation loss: 2.6853287707092943

Epoch: 5| Step: 4
Training loss: 3.696214199066162
Validation loss: 2.6642837280868203

Epoch: 5| Step: 5
Training loss: 2.483485221862793
Validation loss: 2.65989581231148

Epoch: 5| Step: 6
Training loss: 2.8785488605499268
Validation loss: 2.6610692624122865

Epoch: 5| Step: 7
Training loss: 2.373974561691284
Validation loss: 2.661305699297177

Epoch: 5| Step: 8
Training loss: 3.037493944168091
Validation loss: 2.654848201300508

Epoch: 5| Step: 9
Training loss: 3.063793182373047
Validation loss: 2.657320048219414

Epoch: 5| Step: 10
Training loss: 2.7529263496398926
Validation loss: 2.6567898693905083

Epoch: 31| Step: 0
Training loss: 3.1738171577453613
Validation loss: 2.65996959388897

Epoch: 5| Step: 1
Training loss: 2.8805527687072754
Validation loss: 2.657508978279688

Epoch: 5| Step: 2
Training loss: 2.487891674041748
Validation loss: 2.656900477665727

Epoch: 5| Step: 3
Training loss: 2.930130958557129
Validation loss: 2.664687305368403

Epoch: 5| Step: 4
Training loss: 3.0840632915496826
Validation loss: 2.6672034981430217

Epoch: 5| Step: 5
Training loss: 2.8213510513305664
Validation loss: 2.677201627403177

Epoch: 5| Step: 6
Training loss: 2.4331912994384766
Validation loss: 2.6972598055357575

Epoch: 5| Step: 7
Training loss: 2.9532816410064697
Validation loss: 2.712454726619105

Epoch: 5| Step: 8
Training loss: 3.0257339477539062
Validation loss: 2.6777070773545133

Epoch: 5| Step: 9
Training loss: 2.897928237915039
Validation loss: 2.645082284045476

Epoch: 5| Step: 10
Training loss: 2.3901615142822266
Validation loss: 2.6617555746468167

Epoch: 32| Step: 0
Training loss: 2.834735631942749
Validation loss: 2.6915106132466304

Epoch: 5| Step: 1
Training loss: 2.843292236328125
Validation loss: 2.703696830298311

Epoch: 5| Step: 2
Training loss: 2.431313991546631
Validation loss: 2.681491695424562

Epoch: 5| Step: 3
Training loss: 2.9555296897888184
Validation loss: 2.664009476220736

Epoch: 5| Step: 4
Training loss: 2.8039562702178955
Validation loss: 2.6552621318447973

Epoch: 5| Step: 5
Training loss: 3.380521297454834
Validation loss: 2.6515530053005425

Epoch: 5| Step: 6
Training loss: 3.005034923553467
Validation loss: 2.648033990654894

Epoch: 5| Step: 7
Training loss: 3.144292116165161
Validation loss: 2.648345706283405

Epoch: 5| Step: 8
Training loss: 1.8621454238891602
Validation loss: 2.640241430651757

Epoch: 5| Step: 9
Training loss: 2.99120831489563
Validation loss: 2.6517062802468576

Epoch: 5| Step: 10
Training loss: 2.817516326904297
Validation loss: 2.673650946668399

Epoch: 33| Step: 0
Training loss: 2.608543634414673
Validation loss: 2.698653518512685

Epoch: 5| Step: 1
Training loss: 2.6048583984375
Validation loss: 2.677499517317741

Epoch: 5| Step: 2
Training loss: 2.836972713470459
Validation loss: 2.6419876057614564

Epoch: 5| Step: 3
Training loss: 2.4510498046875
Validation loss: 2.6375001271565757

Epoch: 5| Step: 4
Training loss: 2.6578164100646973
Validation loss: 2.6449591600766746

Epoch: 5| Step: 5
Training loss: 3.1597630977630615
Validation loss: 2.646012411322645

Epoch: 5| Step: 6
Training loss: 3.2680716514587402
Validation loss: 2.6440023273550053

Epoch: 5| Step: 7
Training loss: 2.833404541015625
Validation loss: 2.646320319944812

Epoch: 5| Step: 8
Training loss: 3.4409098625183105
Validation loss: 2.6469631656523673

Epoch: 5| Step: 9
Training loss: 2.7131733894348145
Validation loss: 2.6429173510561705

Epoch: 5| Step: 10
Training loss: 2.4642255306243896
Validation loss: 2.6446918518312517

Epoch: 34| Step: 0
Training loss: 2.5662484169006348
Validation loss: 2.639666541930168

Epoch: 5| Step: 1
Training loss: 3.3397316932678223
Validation loss: 2.6400017251250563

Epoch: 5| Step: 2
Training loss: 2.710930585861206
Validation loss: 2.638305687135266

Epoch: 5| Step: 3
Training loss: 3.3653037548065186
Validation loss: 2.6340086742113997

Epoch: 5| Step: 4
Training loss: 2.4324567317962646
Validation loss: 2.6334612830992667

Epoch: 5| Step: 5
Training loss: 2.5082690715789795
Validation loss: 2.662360829691733

Epoch: 5| Step: 6
Training loss: 2.6158041954040527
Validation loss: 2.6618768707398446

Epoch: 5| Step: 7
Training loss: 3.169973134994507
Validation loss: 2.644565120820076

Epoch: 5| Step: 8
Training loss: 2.9468696117401123
Validation loss: 2.627969546984601

Epoch: 5| Step: 9
Training loss: 2.7602431774139404
Validation loss: 2.626217257591986

Epoch: 5| Step: 10
Training loss: 2.4514267444610596
Validation loss: 2.6240029155567126

Epoch: 35| Step: 0
Training loss: 3.318441867828369
Validation loss: 2.6249495885705434

Epoch: 5| Step: 1
Training loss: 2.17463755607605
Validation loss: 2.629451108235185

Epoch: 5| Step: 2
Training loss: 2.3204445838928223
Validation loss: 2.6294873247864428

Epoch: 5| Step: 3
Training loss: 3.1903316974639893
Validation loss: 2.6267101918497393

Epoch: 5| Step: 4
Training loss: 2.9014196395874023
Validation loss: 2.6267636847752396

Epoch: 5| Step: 5
Training loss: 2.9828813076019287
Validation loss: 2.6224772366144324

Epoch: 5| Step: 6
Training loss: 2.9718003273010254
Validation loss: 2.6197951198906027

Epoch: 5| Step: 7
Training loss: 2.677070140838623
Validation loss: 2.6220710328830186

Epoch: 5| Step: 8
Training loss: 3.3462295532226562
Validation loss: 2.623700670016709

Epoch: 5| Step: 9
Training loss: 2.4357144832611084
Validation loss: 2.633334803324874

Epoch: 5| Step: 10
Training loss: 2.280153274536133
Validation loss: 2.6504930270615445

Epoch: 36| Step: 0
Training loss: 2.676220417022705
Validation loss: 2.66703797412175

Epoch: 5| Step: 1
Training loss: 2.3149728775024414
Validation loss: 2.653394647823867

Epoch: 5| Step: 2
Training loss: 3.198906660079956
Validation loss: 2.637293049084243

Epoch: 5| Step: 3
Training loss: 3.635610580444336
Validation loss: 2.6155328801883164

Epoch: 5| Step: 4
Training loss: 3.2847201824188232
Validation loss: 2.612656057521861

Epoch: 5| Step: 5
Training loss: 1.9221283197402954
Validation loss: 2.618182792458483

Epoch: 5| Step: 6
Training loss: 2.547222852706909
Validation loss: 2.6187432581378567

Epoch: 5| Step: 7
Training loss: 3.2157089710235596
Validation loss: 2.624674553512245

Epoch: 5| Step: 8
Training loss: 2.519270420074463
Validation loss: 2.6263211978379117

Epoch: 5| Step: 9
Training loss: 2.6653594970703125
Validation loss: 2.619773933964391

Epoch: 5| Step: 10
Training loss: 2.837165594100952
Validation loss: 2.6116677509841097

Epoch: 37| Step: 0
Training loss: 2.4405484199523926
Validation loss: 2.6114498825483423

Epoch: 5| Step: 1
Training loss: 2.8362364768981934
Validation loss: 2.6177253569326093

Epoch: 5| Step: 2
Training loss: 3.3795769214630127
Validation loss: 2.631273061998429

Epoch: 5| Step: 3
Training loss: 2.183835506439209
Validation loss: 2.6436794470715266

Epoch: 5| Step: 4
Training loss: 3.065823793411255
Validation loss: 2.643947385972546

Epoch: 5| Step: 5
Training loss: 2.6103978157043457
Validation loss: 2.635680273015012

Epoch: 5| Step: 6
Training loss: 2.6406936645507812
Validation loss: 2.6206059096961893

Epoch: 5| Step: 7
Training loss: 2.5045409202575684
Validation loss: 2.6123076779868013

Epoch: 5| Step: 8
Training loss: 3.139491081237793
Validation loss: 2.6099923400468725

Epoch: 5| Step: 9
Training loss: 3.0729517936706543
Validation loss: 2.6113434478800785

Epoch: 5| Step: 10
Training loss: 2.683084011077881
Validation loss: 2.60690446822874

Epoch: 38| Step: 0
Training loss: 3.2093911170959473
Validation loss: 2.611714450261926

Epoch: 5| Step: 1
Training loss: 2.4269540309906006
Validation loss: 2.6143054039247575

Epoch: 5| Step: 2
Training loss: 2.5930397510528564
Validation loss: 2.610399928144229

Epoch: 5| Step: 3
Training loss: 2.667865514755249
Validation loss: 2.6073062291709324

Epoch: 5| Step: 4
Training loss: 3.718221664428711
Validation loss: 2.605501018544679

Epoch: 5| Step: 5
Training loss: 2.2648839950561523
Validation loss: 2.607330581193329

Epoch: 5| Step: 6
Training loss: 2.9697365760803223
Validation loss: 2.607008695602417

Epoch: 5| Step: 7
Training loss: 2.4983863830566406
Validation loss: 2.6085905003291305

Epoch: 5| Step: 8
Training loss: 2.7462382316589355
Validation loss: 2.622940855641519

Epoch: 5| Step: 9
Training loss: 2.5695908069610596
Validation loss: 2.6360074807238836

Epoch: 5| Step: 10
Training loss: 2.878141164779663
Validation loss: 2.656559346824564

Epoch: 39| Step: 0
Training loss: 2.5187301635742188
Validation loss: 2.6455882851795485

Epoch: 5| Step: 1
Training loss: 2.8955235481262207
Validation loss: 2.6373373334125807

Epoch: 5| Step: 2
Training loss: 2.103921890258789
Validation loss: 2.635851288354525

Epoch: 5| Step: 3
Training loss: 3.0363166332244873
Validation loss: 2.6278531525724675

Epoch: 5| Step: 4
Training loss: 3.101313352584839
Validation loss: 2.6101009666278796

Epoch: 5| Step: 5
Training loss: 3.034050464630127
Validation loss: 2.5995993127105055

Epoch: 5| Step: 6
Training loss: 2.6588287353515625
Validation loss: 2.588809408167357

Epoch: 5| Step: 7
Training loss: 2.52482271194458
Validation loss: 2.59145753101636

Epoch: 5| Step: 8
Training loss: 2.783360719680786
Validation loss: 2.5929770392756306

Epoch: 5| Step: 9
Training loss: 2.575561046600342
Validation loss: 2.5921067371163318

Epoch: 5| Step: 10
Training loss: 3.267936944961548
Validation loss: 2.5921995229618524

Epoch: 40| Step: 0
Training loss: 2.2464632987976074
Validation loss: 2.592953946000786

Epoch: 5| Step: 1
Training loss: 3.009514808654785
Validation loss: 2.5924358470465547

Epoch: 5| Step: 2
Training loss: 2.8070976734161377
Validation loss: 2.592148978223083

Epoch: 5| Step: 3
Training loss: 3.1389970779418945
Validation loss: 2.5871254885068504

Epoch: 5| Step: 4
Training loss: 3.42985463142395
Validation loss: 2.5887176862327

Epoch: 5| Step: 5
Training loss: 2.3081812858581543
Validation loss: 2.583176451344644

Epoch: 5| Step: 6
Training loss: 2.124812126159668
Validation loss: 2.5809345809362267

Epoch: 5| Step: 7
Training loss: 2.7853446006774902
Validation loss: 2.583332315568001

Epoch: 5| Step: 8
Training loss: 2.42669415473938
Validation loss: 2.579275123534664

Epoch: 5| Step: 9
Training loss: 2.7232606410980225
Validation loss: 2.5781051497305594

Epoch: 5| Step: 10
Training loss: 3.539184093475342
Validation loss: 2.576571282520089

Epoch: 41| Step: 0
Training loss: 2.4920623302459717
Validation loss: 2.5765651041461575

Epoch: 5| Step: 1
Training loss: 2.7511160373687744
Validation loss: 2.586544780321019

Epoch: 5| Step: 2
Training loss: 3.0463242530822754
Validation loss: 2.5900476376215615

Epoch: 5| Step: 3
Training loss: 2.0864415168762207
Validation loss: 2.602745276625438

Epoch: 5| Step: 4
Training loss: 2.3593714237213135
Validation loss: 2.614571040676486

Epoch: 5| Step: 5
Training loss: 3.264685869216919
Validation loss: 2.599195659801524

Epoch: 5| Step: 6
Training loss: 3.081449031829834
Validation loss: 2.57712306258499

Epoch: 5| Step: 7
Training loss: 3.0239500999450684
Validation loss: 2.5710556942929506

Epoch: 5| Step: 8
Training loss: 2.936081647872925
Validation loss: 2.568809578495641

Epoch: 5| Step: 9
Training loss: 2.830022096633911
Validation loss: 2.571071752937891

Epoch: 5| Step: 10
Training loss: 2.464164972305298
Validation loss: 2.5703742875847766

Epoch: 42| Step: 0
Training loss: 3.19262433052063
Validation loss: 2.5744180858776136

Epoch: 5| Step: 1
Training loss: 2.5688586235046387
Validation loss: 2.5680453392767135

Epoch: 5| Step: 2
Training loss: 2.5375425815582275
Validation loss: 2.571738999377015

Epoch: 5| Step: 3
Training loss: 2.0002408027648926
Validation loss: 2.5749097690787366

Epoch: 5| Step: 4
Training loss: 2.5544724464416504
Validation loss: 2.5775451916520313

Epoch: 5| Step: 5
Training loss: 2.7688889503479004
Validation loss: 2.573682556870163

Epoch: 5| Step: 6
Training loss: 2.740084171295166
Validation loss: 2.573807176723275

Epoch: 5| Step: 7
Training loss: 2.871047258377075
Validation loss: 2.5761972986241823

Epoch: 5| Step: 8
Training loss: 3.160309076309204
Validation loss: 2.578322328546996

Epoch: 5| Step: 9
Training loss: 3.821270704269409
Validation loss: 2.5769113212503414

Epoch: 5| Step: 10
Training loss: 1.8734643459320068
Validation loss: 2.5794220021975938

Epoch: 43| Step: 0
Training loss: 2.9030659198760986
Validation loss: 2.5685979755975867

Epoch: 5| Step: 1
Training loss: 3.05023193359375
Validation loss: 2.5657495683239353

Epoch: 5| Step: 2
Training loss: 2.384464979171753
Validation loss: 2.5630513032277427

Epoch: 5| Step: 3
Training loss: 2.262094259262085
Validation loss: 2.5570794997676725

Epoch: 5| Step: 4
Training loss: 4.354662895202637
Validation loss: 2.5612986728709233

Epoch: 5| Step: 5
Training loss: 2.738283634185791
Validation loss: 2.5618264495685534

Epoch: 5| Step: 6
Training loss: 2.1454110145568848
Validation loss: 2.55745630879556

Epoch: 5| Step: 7
Training loss: 2.595078945159912
Validation loss: 2.5594848612303376

Epoch: 5| Step: 8
Training loss: 2.332252025604248
Validation loss: 2.5548487991415043

Epoch: 5| Step: 9
Training loss: 2.611548900604248
Validation loss: 2.557325683614259

Epoch: 5| Step: 10
Training loss: 2.7402689456939697
Validation loss: 2.5686250220062914

Epoch: 44| Step: 0
Training loss: 2.746619701385498
Validation loss: 2.5691597564246065

Epoch: 5| Step: 1
Training loss: 2.6926486492156982
Validation loss: 2.575674351825509

Epoch: 5| Step: 2
Training loss: 2.7551980018615723
Validation loss: 2.6110380131711244

Epoch: 5| Step: 3
Training loss: 2.9212090969085693
Validation loss: 2.632331984017485

Epoch: 5| Step: 4
Training loss: 2.170578718185425
Validation loss: 2.609638206420406

Epoch: 5| Step: 5
Training loss: 2.4236958026885986
Validation loss: 2.5831531324694232

Epoch: 5| Step: 6
Training loss: 3.0107622146606445
Validation loss: 2.5782674128009426

Epoch: 5| Step: 7
Training loss: 2.6131818294525146
Validation loss: 2.5772536749480874

Epoch: 5| Step: 8
Training loss: 2.5536322593688965
Validation loss: 2.589250559447914

Epoch: 5| Step: 9
Training loss: 3.38751220703125
Validation loss: 2.594062251429404

Epoch: 5| Step: 10
Training loss: 2.988999366760254
Validation loss: 2.5879884509630102

Epoch: 45| Step: 0
Training loss: 3.5789737701416016
Validation loss: 2.572674266753658

Epoch: 5| Step: 1
Training loss: 3.0329842567443848
Validation loss: 2.545794604926981

Epoch: 5| Step: 2
Training loss: 3.4977498054504395
Validation loss: 2.544763075408115

Epoch: 5| Step: 3
Training loss: 2.856771469116211
Validation loss: 2.550572418397473

Epoch: 5| Step: 4
Training loss: 2.2652714252471924
Validation loss: 2.5657061556334138

Epoch: 5| Step: 5
Training loss: 2.9811086654663086
Validation loss: 2.562089668807163

Epoch: 5| Step: 6
Training loss: 2.154958486557007
Validation loss: 2.5501054358738724

Epoch: 5| Step: 7
Training loss: 1.9736512899398804
Validation loss: 2.5439917938683623

Epoch: 5| Step: 8
Training loss: 2.457745313644409
Validation loss: 2.5462029082800752

Epoch: 5| Step: 9
Training loss: 2.8908448219299316
Validation loss: 2.557153573600195

Epoch: 5| Step: 10
Training loss: 2.4880330562591553
Validation loss: 2.576344584905973

Epoch: 46| Step: 0
Training loss: 3.14129638671875
Validation loss: 2.571083950740035

Epoch: 5| Step: 1
Training loss: 3.0647785663604736
Validation loss: 2.5800769918708393

Epoch: 5| Step: 2
Training loss: 2.8256289958953857
Validation loss: 2.5801237654942337

Epoch: 5| Step: 3
Training loss: 2.585437297821045
Validation loss: 2.5786757648632093

Epoch: 5| Step: 4
Training loss: 2.947319507598877
Validation loss: 2.55903196847567

Epoch: 5| Step: 5
Training loss: 2.887958526611328
Validation loss: 2.5395682986064623

Epoch: 5| Step: 6
Training loss: 2.3998095989227295
Validation loss: 2.5364658576185986

Epoch: 5| Step: 7
Training loss: 2.7910656929016113
Validation loss: 2.533291327056064

Epoch: 5| Step: 8
Training loss: 2.338085889816284
Validation loss: 2.5346440602374334

Epoch: 5| Step: 9
Training loss: 2.2509071826934814
Validation loss: 2.5320720339334137

Epoch: 5| Step: 10
Training loss: 2.832056760787964
Validation loss: 2.531319487479425

Epoch: 47| Step: 0
Training loss: 2.783602476119995
Validation loss: 2.537824994774275

Epoch: 5| Step: 1
Training loss: 2.324577808380127
Validation loss: 2.547681636707757

Epoch: 5| Step: 2
Training loss: 3.1102070808410645
Validation loss: 2.5609944046184583

Epoch: 5| Step: 3
Training loss: 2.5022029876708984
Validation loss: 2.561183293660482

Epoch: 5| Step: 4
Training loss: 3.306619167327881
Validation loss: 2.5560580658656296

Epoch: 5| Step: 5
Training loss: 3.6851277351379395
Validation loss: 2.5521988817440566

Epoch: 5| Step: 6
Training loss: 2.6569457054138184
Validation loss: 2.5425858856529318

Epoch: 5| Step: 7
Training loss: 2.448716640472412
Validation loss: 2.541890965994968

Epoch: 5| Step: 8
Training loss: 2.491614818572998
Validation loss: 2.5363043251857964

Epoch: 5| Step: 9
Training loss: 1.9303356409072876
Validation loss: 2.5284718082797144

Epoch: 5| Step: 10
Training loss: 2.686527967453003
Validation loss: 2.521700297632525

Epoch: 48| Step: 0
Training loss: 2.8850789070129395
Validation loss: 2.5247865133388068

Epoch: 5| Step: 1
Training loss: 1.6499969959259033
Validation loss: 2.522990788182905

Epoch: 5| Step: 2
Training loss: 2.976262092590332
Validation loss: 2.5221593021064677

Epoch: 5| Step: 3
Training loss: 2.9149563312530518
Validation loss: 2.524037407290551

Epoch: 5| Step: 4
Training loss: 3.1441588401794434
Validation loss: 2.521379352897726

Epoch: 5| Step: 5
Training loss: 2.3064932823181152
Validation loss: 2.517602159130958

Epoch: 5| Step: 6
Training loss: 3.09708833694458
Validation loss: 2.5169523941573275

Epoch: 5| Step: 7
Training loss: 2.7572708129882812
Validation loss: 2.520692179279943

Epoch: 5| Step: 8
Training loss: 2.508760452270508
Validation loss: 2.525478514291907

Epoch: 5| Step: 9
Training loss: 2.588714122772217
Validation loss: 2.526997535459457

Epoch: 5| Step: 10
Training loss: 3.177553176879883
Validation loss: 2.53070972042699

Epoch: 49| Step: 0
Training loss: 3.261875867843628
Validation loss: 2.5247383809858754

Epoch: 5| Step: 1
Training loss: 2.7629809379577637
Validation loss: 2.522969574056646

Epoch: 5| Step: 2
Training loss: 2.722534418106079
Validation loss: 2.5277965850727533

Epoch: 5| Step: 3
Training loss: 2.375443935394287
Validation loss: 2.5347093305280133

Epoch: 5| Step: 4
Training loss: 3.2812302112579346
Validation loss: 2.5379242512487594

Epoch: 5| Step: 5
Training loss: 3.5072638988494873
Validation loss: 2.5341202161645375

Epoch: 5| Step: 6
Training loss: 2.054250955581665
Validation loss: 2.5306047931794198

Epoch: 5| Step: 7
Training loss: 2.1889350414276123
Validation loss: 2.5200479850974133

Epoch: 5| Step: 8
Training loss: 2.441702365875244
Validation loss: 2.514641736143379

Epoch: 5| Step: 9
Training loss: 2.7138073444366455
Validation loss: 2.519050085416404

Epoch: 5| Step: 10
Training loss: 2.415147066116333
Validation loss: 2.5181587921675814

Epoch: 50| Step: 0
Training loss: 2.5022037029266357
Validation loss: 2.547356228674612

Epoch: 5| Step: 1
Training loss: 2.38303279876709
Validation loss: 2.5927855430110807

Epoch: 5| Step: 2
Training loss: 2.5166492462158203
Validation loss: 2.6055785302192933

Epoch: 5| Step: 3
Training loss: 2.9584949016571045
Validation loss: 2.662042469106695

Epoch: 5| Step: 4
Training loss: 3.0727410316467285
Validation loss: 2.6754910099890923

Epoch: 5| Step: 5
Training loss: 3.204939603805542
Validation loss: 2.665831519711402

Epoch: 5| Step: 6
Training loss: 2.491264820098877
Validation loss: 2.6217747426802114

Epoch: 5| Step: 7
Training loss: 2.7899904251098633
Validation loss: 2.565573746158231

Epoch: 5| Step: 8
Training loss: 2.52091646194458
Validation loss: 2.56856200515583

Epoch: 5| Step: 9
Training loss: 2.863659620285034
Validation loss: 2.573872943078318

Epoch: 5| Step: 10
Training loss: 2.9835968017578125
Validation loss: 2.583067406890213

Epoch: 51| Step: 0
Training loss: 2.354562282562256
Validation loss: 2.5861987683080856

Epoch: 5| Step: 1
Training loss: 1.969635248184204
Validation loss: 2.587483298393988

Epoch: 5| Step: 2
Training loss: 3.4165549278259277
Validation loss: 2.579620950965471

Epoch: 5| Step: 3
Training loss: 2.418694019317627
Validation loss: 2.5613548012189966

Epoch: 5| Step: 4
Training loss: 3.5093905925750732
Validation loss: 2.5514348040344896

Epoch: 5| Step: 5
Training loss: 2.6937248706817627
Validation loss: 2.544011051936816

Epoch: 5| Step: 6
Training loss: 2.8161869049072266
Validation loss: 2.53760160938386

Epoch: 5| Step: 7
Training loss: 3.0123488903045654
Validation loss: 2.535147613094699

Epoch: 5| Step: 8
Training loss: 3.090592861175537
Validation loss: 2.532669375019689

Epoch: 5| Step: 9
Training loss: 2.929103136062622
Validation loss: 2.529667951727426

Epoch: 5| Step: 10
Training loss: 1.6981033086776733
Validation loss: 2.529529586915047

Epoch: 52| Step: 0
Training loss: 2.490726947784424
Validation loss: 2.527518026290401

Epoch: 5| Step: 1
Training loss: 3.4311251640319824
Validation loss: 2.5275062566162436

Epoch: 5| Step: 2
Training loss: 2.6844825744628906
Validation loss: 2.536337393586354

Epoch: 5| Step: 3
Training loss: 2.5936965942382812
Validation loss: 2.547521524531867

Epoch: 5| Step: 4
Training loss: 3.1837401390075684
Validation loss: 2.5568307394622476

Epoch: 5| Step: 5
Training loss: 2.27266001701355
Validation loss: 2.5420825250687136

Epoch: 5| Step: 6
Training loss: 2.4636647701263428
Validation loss: 2.5269981225331626

Epoch: 5| Step: 7
Training loss: 2.689802885055542
Validation loss: 2.529490360649683

Epoch: 5| Step: 8
Training loss: 2.6468615531921387
Validation loss: 2.52604950627973

Epoch: 5| Step: 9
Training loss: 2.777617931365967
Validation loss: 2.5246587466168147

Epoch: 5| Step: 10
Training loss: 2.6163299083709717
Validation loss: 2.52258958355073

Epoch: 53| Step: 0
Training loss: 2.971733570098877
Validation loss: 2.523117488430392

Epoch: 5| Step: 1
Training loss: 2.621403932571411
Validation loss: 2.5226517133815314

Epoch: 5| Step: 2
Training loss: 2.3666253089904785
Validation loss: 2.5180862103739092

Epoch: 5| Step: 3
Training loss: 2.8951668739318848
Validation loss: 2.520361056891821

Epoch: 5| Step: 4
Training loss: 2.761627674102783
Validation loss: 2.5242713343712593

Epoch: 5| Step: 5
Training loss: 2.491579532623291
Validation loss: 2.53916528660764

Epoch: 5| Step: 6
Training loss: 2.910804510116577
Validation loss: 2.5710434272725093

Epoch: 5| Step: 7
Training loss: 2.7819621562957764
Validation loss: 2.6165570033493863

Epoch: 5| Step: 8
Training loss: 2.9428765773773193
Validation loss: 2.6202536988002

Epoch: 5| Step: 9
Training loss: 2.597078561782837
Validation loss: 2.5698816366093133

Epoch: 5| Step: 10
Training loss: 2.6509461402893066
Validation loss: 2.547160553675826

Epoch: 54| Step: 0
Training loss: 2.7987656593322754
Validation loss: 2.524145269906649

Epoch: 5| Step: 1
Training loss: 3.047898054122925
Validation loss: 2.523737317772322

Epoch: 5| Step: 2
Training loss: 2.9196174144744873
Validation loss: 2.5187059012792443

Epoch: 5| Step: 3
Training loss: 3.129546642303467
Validation loss: 2.5181104290869927

Epoch: 5| Step: 4
Training loss: 2.1217308044433594
Validation loss: 2.5185543106448267

Epoch: 5| Step: 5
Training loss: 2.648496150970459
Validation loss: 2.5172783764459754

Epoch: 5| Step: 6
Training loss: 2.5766232013702393
Validation loss: 2.5201520894163396

Epoch: 5| Step: 7
Training loss: 2.931943655014038
Validation loss: 2.522235862670406

Epoch: 5| Step: 8
Training loss: 2.3244376182556152
Validation loss: 2.5211105449225313

Epoch: 5| Step: 9
Training loss: 2.8822193145751953
Validation loss: 2.524374605506979

Epoch: 5| Step: 10
Training loss: 2.2513630390167236
Validation loss: 2.5176875027277137

Epoch: 55| Step: 0
Training loss: 3.1835856437683105
Validation loss: 2.515178039509763

Epoch: 5| Step: 1
Training loss: 2.0118236541748047
Validation loss: 2.5168937995869625

Epoch: 5| Step: 2
Training loss: 3.053321599960327
Validation loss: 2.511036383208408

Epoch: 5| Step: 3
Training loss: 2.9851181507110596
Validation loss: 2.5108133131457913

Epoch: 5| Step: 4
Training loss: 2.2673122882843018
Validation loss: 2.5061407396870274

Epoch: 5| Step: 5
Training loss: 2.3985791206359863
Validation loss: 2.5096591928953766

Epoch: 5| Step: 6
Training loss: 3.110238790512085
Validation loss: 2.508196166766587

Epoch: 5| Step: 7
Training loss: 2.5229382514953613
Validation loss: 2.5080659492041475

Epoch: 5| Step: 8
Training loss: 2.6075022220611572
Validation loss: 2.5019282705040387

Epoch: 5| Step: 9
Training loss: 2.774773120880127
Validation loss: 2.503905365543981

Epoch: 5| Step: 10
Training loss: 2.732370376586914
Validation loss: 2.5065534037928425

Epoch: 56| Step: 0
Training loss: 2.4702160358428955
Validation loss: 2.5010713172215286

Epoch: 5| Step: 1
Training loss: 3.19622540473938
Validation loss: 2.5008111153879473

Epoch: 5| Step: 2
Training loss: 2.374586582183838
Validation loss: 2.5027788249395226

Epoch: 5| Step: 3
Training loss: 2.5212106704711914
Validation loss: 2.4980933845684095

Epoch: 5| Step: 4
Training loss: 2.407993793487549
Validation loss: 2.499153411516579

Epoch: 5| Step: 5
Training loss: 2.3149094581604004
Validation loss: 2.49927705846807

Epoch: 5| Step: 6
Training loss: 2.6121666431427
Validation loss: 2.500255456534765

Epoch: 5| Step: 7
Training loss: 2.658229351043701
Validation loss: 2.497433190704674

Epoch: 5| Step: 8
Training loss: 3.3459231853485107
Validation loss: 2.500266041806949

Epoch: 5| Step: 9
Training loss: 3.3971095085144043
Validation loss: 2.509168791514571

Epoch: 5| Step: 10
Training loss: 2.2373664379119873
Validation loss: 2.510505458360077

Epoch: 57| Step: 0
Training loss: 2.6493794918060303
Validation loss: 2.5243888157670216

Epoch: 5| Step: 1
Training loss: 2.9975359439849854
Validation loss: 2.529835242097096

Epoch: 5| Step: 2
Training loss: 2.7939791679382324
Validation loss: 2.507376665710121

Epoch: 5| Step: 3
Training loss: 2.8788676261901855
Validation loss: 2.492472981893888

Epoch: 5| Step: 4
Training loss: 2.084853410720825
Validation loss: 2.491224099231023

Epoch: 5| Step: 5
Training loss: 2.9729256629943848
Validation loss: 2.496208224245297

Epoch: 5| Step: 6
Training loss: 2.4024407863616943
Validation loss: 2.5050596447401148

Epoch: 5| Step: 7
Training loss: 2.9047439098358154
Validation loss: 2.5117592375765563

Epoch: 5| Step: 8
Training loss: 2.514711856842041
Validation loss: 2.5135134625178512

Epoch: 5| Step: 9
Training loss: 2.926281690597534
Validation loss: 2.518599740920528

Epoch: 5| Step: 10
Training loss: 2.6355690956115723
Validation loss: 2.5022659558121876

Epoch: 58| Step: 0
Training loss: 3.5049118995666504
Validation loss: 2.492728676847232

Epoch: 5| Step: 1
Training loss: 2.5645089149475098
Validation loss: 2.49056508720562

Epoch: 5| Step: 2
Training loss: 2.4324636459350586
Validation loss: 2.49129609523281

Epoch: 5| Step: 3
Training loss: 2.495201587677002
Validation loss: 2.491823645048244

Epoch: 5| Step: 4
Training loss: 2.9958930015563965
Validation loss: 2.496763244751961

Epoch: 5| Step: 5
Training loss: 2.4269275665283203
Validation loss: 2.4994717746652584

Epoch: 5| Step: 6
Training loss: 2.8487770557403564
Validation loss: 2.4966903399395686

Epoch: 5| Step: 7
Training loss: 2.467094659805298
Validation loss: 2.490985449924264

Epoch: 5| Step: 8
Training loss: 2.7668354511260986
Validation loss: 2.4919267213472756

Epoch: 5| Step: 9
Training loss: 2.516282558441162
Validation loss: 2.495553239699333

Epoch: 5| Step: 10
Training loss: 2.494037389755249
Validation loss: 2.4963872535254366

Epoch: 59| Step: 0
Training loss: 2.27901291847229
Validation loss: 2.5046807130177817

Epoch: 5| Step: 1
Training loss: 2.4626288414001465
Validation loss: 2.5310258634628786

Epoch: 5| Step: 2
Training loss: 3.0839781761169434
Validation loss: 2.58632823728746

Epoch: 5| Step: 3
Training loss: 2.6891140937805176
Validation loss: 2.5689480689264115

Epoch: 5| Step: 4
Training loss: 2.1989831924438477
Validation loss: 2.5513503269482682

Epoch: 5| Step: 5
Training loss: 3.2233664989471436
Validation loss: 2.5457216642236196

Epoch: 5| Step: 6
Training loss: 2.01947283744812
Validation loss: 2.5055737777422835

Epoch: 5| Step: 7
Training loss: 3.388789415359497
Validation loss: 2.4964692643893662

Epoch: 5| Step: 8
Training loss: 2.7069382667541504
Validation loss: 2.4871675993806575

Epoch: 5| Step: 9
Training loss: 2.662278652191162
Validation loss: 2.4819371674650457

Epoch: 5| Step: 10
Training loss: 2.91011381149292
Validation loss: 2.480266535153953

Epoch: 60| Step: 0
Training loss: 3.206712007522583
Validation loss: 2.4856750554935907

Epoch: 5| Step: 1
Training loss: 2.129265069961548
Validation loss: 2.488044592642015

Epoch: 5| Step: 2
Training loss: 2.373924970626831
Validation loss: 2.4909568627675376

Epoch: 5| Step: 3
Training loss: 2.800434112548828
Validation loss: 2.4880743129279024

Epoch: 5| Step: 4
Training loss: 3.4902050495147705
Validation loss: 2.4824484163714993

Epoch: 5| Step: 5
Training loss: 3.6241455078125
Validation loss: 2.4827333086280414

Epoch: 5| Step: 6
Training loss: 2.0534071922302246
Validation loss: 2.479961604200384

Epoch: 5| Step: 7
Training loss: 2.6628406047821045
Validation loss: 2.4764054436837473

Epoch: 5| Step: 8
Training loss: 2.006532907485962
Validation loss: 2.477607363013811

Epoch: 5| Step: 9
Training loss: 2.522636890411377
Validation loss: 2.48018305788758

Epoch: 5| Step: 10
Training loss: 2.702432870864868
Validation loss: 2.4901695661647345

Epoch: 61| Step: 0
Training loss: 2.784162998199463
Validation loss: 2.503898900042298

Epoch: 5| Step: 1
Training loss: 2.291431427001953
Validation loss: 2.5220310149654264

Epoch: 5| Step: 2
Training loss: 2.7455854415893555
Validation loss: 2.5455404584125807

Epoch: 5| Step: 3
Training loss: 2.4177777767181396
Validation loss: 2.5543104115352837

Epoch: 5| Step: 4
Training loss: 3.3641200065612793
Validation loss: 2.5075525199213335

Epoch: 5| Step: 5
Training loss: 3.2048110961914062
Validation loss: 2.4805397961729314

Epoch: 5| Step: 6
Training loss: 1.7910072803497314
Validation loss: 2.4736815216720744

Epoch: 5| Step: 7
Training loss: 2.9820444583892822
Validation loss: 2.475693315588018

Epoch: 5| Step: 8
Training loss: 3.030425548553467
Validation loss: 2.475907064253284

Epoch: 5| Step: 9
Training loss: 2.07190203666687
Validation loss: 2.4840170273216824

Epoch: 5| Step: 10
Training loss: 2.9300785064697266
Validation loss: 2.4941131094450593

Epoch: 62| Step: 0
Training loss: 2.158477306365967
Validation loss: 2.5114372878946285

Epoch: 5| Step: 1
Training loss: 2.7031495571136475
Validation loss: 2.519855768449845

Epoch: 5| Step: 2
Training loss: 2.983267307281494
Validation loss: 2.512345290953113

Epoch: 5| Step: 3
Training loss: 2.397118330001831
Validation loss: 2.4859789033089914

Epoch: 5| Step: 4
Training loss: 3.0284359455108643
Validation loss: 2.4829735627738376

Epoch: 5| Step: 5
Training loss: 2.583221912384033
Validation loss: 2.4709419024887906

Epoch: 5| Step: 6
Training loss: 2.188739538192749
Validation loss: 2.473156000978203

Epoch: 5| Step: 7
Training loss: 3.541806697845459
Validation loss: 2.474769356430218

Epoch: 5| Step: 8
Training loss: 2.387270450592041
Validation loss: 2.4762499229882353

Epoch: 5| Step: 9
Training loss: 3.147695779800415
Validation loss: 2.4768806888211157

Epoch: 5| Step: 10
Training loss: 2.612971544265747
Validation loss: 2.48216764901274

Epoch: 63| Step: 0
Training loss: 2.493373394012451
Validation loss: 2.484076443538871

Epoch: 5| Step: 1
Training loss: 2.8824708461761475
Validation loss: 2.481983425796673

Epoch: 5| Step: 2
Training loss: 2.7309365272521973
Validation loss: 2.4727452596028647

Epoch: 5| Step: 3
Training loss: 2.747197389602661
Validation loss: 2.467296172213811

Epoch: 5| Step: 4
Training loss: 3.551727771759033
Validation loss: 2.4678399691017727

Epoch: 5| Step: 5
Training loss: 2.516817569732666
Validation loss: 2.463897943496704

Epoch: 5| Step: 6
Training loss: 2.1097609996795654
Validation loss: 2.46159868086538

Epoch: 5| Step: 7
Training loss: 2.3475494384765625
Validation loss: 2.4573405865700013

Epoch: 5| Step: 8
Training loss: 2.7120473384857178
Validation loss: 2.4532676435286

Epoch: 5| Step: 9
Training loss: 2.5589966773986816
Validation loss: 2.4489893323631695

Epoch: 5| Step: 10
Training loss: 2.753833055496216
Validation loss: 2.4416541476403513

Epoch: 64| Step: 0
Training loss: 2.680143356323242
Validation loss: 2.4375987360554356

Epoch: 5| Step: 1
Training loss: 2.9014081954956055
Validation loss: 2.4364888873151553

Epoch: 5| Step: 2
Training loss: 2.773275136947632
Validation loss: 2.4354320290268108

Epoch: 5| Step: 3
Training loss: 2.7148938179016113
Validation loss: 2.4343124179429907

Epoch: 5| Step: 4
Training loss: 2.648820400238037
Validation loss: 2.4353558324998423

Epoch: 5| Step: 5
Training loss: 2.9894602298736572
Validation loss: 2.4317763646443686

Epoch: 5| Step: 6
Training loss: 2.2204976081848145
Validation loss: 2.4387165910454205

Epoch: 5| Step: 7
Training loss: 2.8667850494384766
Validation loss: 2.474366775123022

Epoch: 5| Step: 8
Training loss: 2.406581401824951
Validation loss: 2.480947620125227

Epoch: 5| Step: 9
Training loss: 2.158468723297119
Validation loss: 2.487059126618088

Epoch: 5| Step: 10
Training loss: 3.1184346675872803
Validation loss: 2.497955640157064

Epoch: 65| Step: 0
Training loss: 2.7115366458892822
Validation loss: 2.4826168680703766

Epoch: 5| Step: 1
Training loss: 2.6028213500976562
Validation loss: 2.499519645526845

Epoch: 5| Step: 2
Training loss: 2.6367039680480957
Validation loss: 2.4827583041242374

Epoch: 5| Step: 3
Training loss: 3.0889132022857666
Validation loss: 2.468979407382268

Epoch: 5| Step: 4
Training loss: 1.9938783645629883
Validation loss: 2.434829047931138

Epoch: 5| Step: 5
Training loss: 1.99269700050354
Validation loss: 2.425315995370188

Epoch: 5| Step: 6
Training loss: 2.494419574737549
Validation loss: 2.4178193820420133

Epoch: 5| Step: 7
Training loss: 2.591264486312866
Validation loss: 2.4233351266512306

Epoch: 5| Step: 8
Training loss: 3.0885658264160156
Validation loss: 2.4349002786861953

Epoch: 5| Step: 9
Training loss: 2.8955154418945312
Validation loss: 2.440354390810895

Epoch: 5| Step: 10
Training loss: 3.3676815032958984
Validation loss: 2.4452020942523913

Epoch: 66| Step: 0
Training loss: 3.1230037212371826
Validation loss: 2.440625170225738

Epoch: 5| Step: 1
Training loss: 3.2587974071502686
Validation loss: 2.433622283320273

Epoch: 5| Step: 2
Training loss: 2.311051845550537
Validation loss: 2.4267869200757755

Epoch: 5| Step: 3
Training loss: 2.636577606201172
Validation loss: 2.4219606076517413

Epoch: 5| Step: 4
Training loss: 2.8471035957336426
Validation loss: 2.4111850928234797

Epoch: 5| Step: 5
Training loss: 2.288182497024536
Validation loss: 2.41713394400894

Epoch: 5| Step: 6
Training loss: 2.943782329559326
Validation loss: 2.426449279631338

Epoch: 5| Step: 7
Training loss: 2.4868061542510986
Validation loss: 2.427227117682016

Epoch: 5| Step: 8
Training loss: 2.4401917457580566
Validation loss: 2.436567470591555

Epoch: 5| Step: 9
Training loss: 2.192612648010254
Validation loss: 2.446489034160491

Epoch: 5| Step: 10
Training loss: 2.7406787872314453
Validation loss: 2.4668045479764222

Epoch: 67| Step: 0
Training loss: 2.3293542861938477
Validation loss: 2.485617076196978

Epoch: 5| Step: 1
Training loss: 3.2132632732391357
Validation loss: 2.508374621791224

Epoch: 5| Step: 2
Training loss: 2.9394371509552
Validation loss: 2.4937551021575928

Epoch: 5| Step: 3
Training loss: 2.0354366302490234
Validation loss: 2.461150195008965

Epoch: 5| Step: 4
Training loss: 3.088611125946045
Validation loss: 2.4294523782627557

Epoch: 5| Step: 5
Training loss: 2.686769485473633
Validation loss: 2.4207885726805656

Epoch: 5| Step: 6
Training loss: 1.9203846454620361
Validation loss: 2.4169162447734545

Epoch: 5| Step: 7
Training loss: 2.6665215492248535
Validation loss: 2.4208099406252623

Epoch: 5| Step: 8
Training loss: 3.3327298164367676
Validation loss: 2.4233317529001543

Epoch: 5| Step: 9
Training loss: 2.3494420051574707
Validation loss: 2.4262068733092277

Epoch: 5| Step: 10
Training loss: 2.936197519302368
Validation loss: 2.425451229977351

Epoch: 68| Step: 0
Training loss: 3.0043864250183105
Validation loss: 2.423727480314111

Epoch: 5| Step: 1
Training loss: 2.9334592819213867
Validation loss: 2.429168730653742

Epoch: 5| Step: 2
Training loss: 2.9584288597106934
Validation loss: 2.433746732691283

Epoch: 5| Step: 3
Training loss: 2.096578598022461
Validation loss: 2.428671717643738

Epoch: 5| Step: 4
Training loss: 2.886923313140869
Validation loss: 2.4245519458606677

Epoch: 5| Step: 5
Training loss: 2.4463791847229004
Validation loss: 2.423353523336431

Epoch: 5| Step: 6
Training loss: 2.4717681407928467
Validation loss: 2.427185509794502

Epoch: 5| Step: 7
Training loss: 2.229893445968628
Validation loss: 2.439555783425608

Epoch: 5| Step: 8
Training loss: 2.613109588623047
Validation loss: 2.4579053181473927

Epoch: 5| Step: 9
Training loss: 2.728612184524536
Validation loss: 2.4728741440721738

Epoch: 5| Step: 10
Training loss: 2.990325450897217
Validation loss: 2.494535369257773

Epoch: 69| Step: 0
Training loss: 2.84907865524292
Validation loss: 2.4984602799979587

Epoch: 5| Step: 1
Training loss: 2.813232898712158
Validation loss: 2.5111806315760457

Epoch: 5| Step: 2
Training loss: 2.4075920581817627
Validation loss: 2.4823431558506464

Epoch: 5| Step: 3
Training loss: 2.896810531616211
Validation loss: 2.455748724681075

Epoch: 5| Step: 4
Training loss: 2.8897042274475098
Validation loss: 2.4344584172771824

Epoch: 5| Step: 5
Training loss: 1.8633806705474854
Validation loss: 2.4232780856470906

Epoch: 5| Step: 6
Training loss: 2.2704806327819824
Validation loss: 2.421724063093944

Epoch: 5| Step: 7
Training loss: 2.8777730464935303
Validation loss: 2.416330647724931

Epoch: 5| Step: 8
Training loss: 2.626124858856201
Validation loss: 2.4116926962329495

Epoch: 5| Step: 9
Training loss: 2.4946630001068115
Validation loss: 2.41254787547614

Epoch: 5| Step: 10
Training loss: 3.412736415863037
Validation loss: 2.410924485934678

Epoch: 70| Step: 0
Training loss: 2.6085381507873535
Validation loss: 2.4117986463731333

Epoch: 5| Step: 1
Training loss: 2.948732376098633
Validation loss: 2.4084618168492473

Epoch: 5| Step: 2
Training loss: 2.684539794921875
Validation loss: 2.4039072298234507

Epoch: 5| Step: 3
Training loss: 2.384779930114746
Validation loss: 2.407725323912918

Epoch: 5| Step: 4
Training loss: 2.3261656761169434
Validation loss: 2.403738775560933

Epoch: 5| Step: 5
Training loss: 2.648423910140991
Validation loss: 2.4002158000905025

Epoch: 5| Step: 6
Training loss: 2.7757675647735596
Validation loss: 2.3972887646767402

Epoch: 5| Step: 7
Training loss: 3.577950954437256
Validation loss: 2.399275971997169

Epoch: 5| Step: 8
Training loss: 2.7987780570983887
Validation loss: 2.3973503907521567

Epoch: 5| Step: 9
Training loss: 1.7197940349578857
Validation loss: 2.3945848044528755

Epoch: 5| Step: 10
Training loss: 2.6019911766052246
Validation loss: 2.392287290224465

Epoch: 71| Step: 0
Training loss: 2.433090925216675
Validation loss: 2.3972165456382175

Epoch: 5| Step: 1
Training loss: 2.2520339488983154
Validation loss: 2.4013885785174627

Epoch: 5| Step: 2
Training loss: 2.6995487213134766
Validation loss: 2.4083893388830204

Epoch: 5| Step: 3
Training loss: 3.274843692779541
Validation loss: 2.4088728889342277

Epoch: 5| Step: 4
Training loss: 2.5843489170074463
Validation loss: 2.4142455747050624

Epoch: 5| Step: 5
Training loss: 2.286865234375
Validation loss: 2.4167847710271038

Epoch: 5| Step: 6
Training loss: 3.0009098052978516
Validation loss: 2.414740729075606

Epoch: 5| Step: 7
Training loss: 2.996230125427246
Validation loss: 2.4118451008232693

Epoch: 5| Step: 8
Training loss: 2.583704710006714
Validation loss: 2.4132160371349705

Epoch: 5| Step: 9
Training loss: 2.433492660522461
Validation loss: 2.4226162331078642

Epoch: 5| Step: 10
Training loss: 2.4400670528411865
Validation loss: 2.44633452610303

Epoch: 72| Step: 0
Training loss: 3.483069658279419
Validation loss: 2.4531798183277087

Epoch: 5| Step: 1
Training loss: 2.754415512084961
Validation loss: 2.4647825482071086

Epoch: 5| Step: 2
Training loss: 2.500082015991211
Validation loss: 2.4544186489556425

Epoch: 5| Step: 3
Training loss: 3.2552521228790283
Validation loss: 2.4280395815449376

Epoch: 5| Step: 4
Training loss: 2.483844041824341
Validation loss: 2.4108591566803637

Epoch: 5| Step: 5
Training loss: 2.7485222816467285
Validation loss: 2.395581240295082

Epoch: 5| Step: 6
Training loss: 2.822892189025879
Validation loss: 2.385643320698892

Epoch: 5| Step: 7
Training loss: 1.5933668613433838
Validation loss: 2.38322457703211

Epoch: 5| Step: 8
Training loss: 2.137065887451172
Validation loss: 2.3816428107600056

Epoch: 5| Step: 9
Training loss: 2.514848232269287
Validation loss: 2.3794581992651826

Epoch: 5| Step: 10
Training loss: 2.884920120239258
Validation loss: 2.3779724054439093

Epoch: 73| Step: 0
Training loss: 2.5496175289154053
Validation loss: 2.379303583534815

Epoch: 5| Step: 1
Training loss: 2.8735508918762207
Validation loss: 2.384490810414796

Epoch: 5| Step: 2
Training loss: 2.596527576446533
Validation loss: 2.380943113757718

Epoch: 5| Step: 3
Training loss: 2.1984755992889404
Validation loss: 2.383665079711586

Epoch: 5| Step: 4
Training loss: 2.7687549591064453
Validation loss: 2.379835920949136

Epoch: 5| Step: 5
Training loss: 2.6381144523620605
Validation loss: 2.379623264394781

Epoch: 5| Step: 6
Training loss: 3.0472030639648438
Validation loss: 2.3814098476081766

Epoch: 5| Step: 7
Training loss: 2.953731060028076
Validation loss: 2.383401947636758

Epoch: 5| Step: 8
Training loss: 2.166050672531128
Validation loss: 2.3876740419736473

Epoch: 5| Step: 9
Training loss: 3.0127222537994385
Validation loss: 2.388188100630237

Epoch: 5| Step: 10
Training loss: 2.047750473022461
Validation loss: 2.391811042703608

Epoch: 74| Step: 0
Training loss: 3.1094753742218018
Validation loss: 2.401776011272143

Epoch: 5| Step: 1
Training loss: 2.5334010124206543
Validation loss: 2.421899828859555

Epoch: 5| Step: 2
Training loss: 2.9428493976593018
Validation loss: 2.437909277536536

Epoch: 5| Step: 3
Training loss: 2.364375352859497
Validation loss: 2.455070067477483

Epoch: 5| Step: 4
Training loss: 2.283979654312134
Validation loss: 2.4590314947148806

Epoch: 5| Step: 5
Training loss: 2.4034781455993652
Validation loss: 2.4692967399474113

Epoch: 5| Step: 6
Training loss: 2.374267101287842
Validation loss: 2.4508733005933863

Epoch: 5| Step: 7
Training loss: 2.684570550918579
Validation loss: 2.4454889989668325

Epoch: 5| Step: 8
Training loss: 3.353259325027466
Validation loss: 2.419366544292819

Epoch: 5| Step: 9
Training loss: 2.5341179370880127
Validation loss: 2.3903850368274155

Epoch: 5| Step: 10
Training loss: 2.454629898071289
Validation loss: 2.3766266953560615

Epoch: 75| Step: 0
Training loss: 3.022202491760254
Validation loss: 2.370428903128511

Epoch: 5| Step: 1
Training loss: 2.5200209617614746
Validation loss: 2.379966207729873

Epoch: 5| Step: 2
Training loss: 2.214845895767212
Validation loss: 2.3923148621794996

Epoch: 5| Step: 3
Training loss: 2.3732032775878906
Validation loss: 2.4061482337213334

Epoch: 5| Step: 4
Training loss: 2.531414031982422
Validation loss: 2.425709455244003

Epoch: 5| Step: 5
Training loss: 2.7965240478515625
Validation loss: 2.3988218051131054

Epoch: 5| Step: 6
Training loss: 2.6189773082733154
Validation loss: 2.3840001372880835

Epoch: 5| Step: 7
Training loss: 3.1200530529022217
Validation loss: 2.3737737927385556

Epoch: 5| Step: 8
Training loss: 2.413007974624634
Validation loss: 2.369928249748804

Epoch: 5| Step: 9
Training loss: 3.070969343185425
Validation loss: 2.3709820521775113

Epoch: 5| Step: 10
Training loss: 2.3244783878326416
Validation loss: 2.379894574483236

Epoch: 76| Step: 0
Training loss: 2.768848180770874
Validation loss: 2.3957742311621226

Epoch: 5| Step: 1
Training loss: 3.5025410652160645
Validation loss: 2.4165058315441175

Epoch: 5| Step: 2
Training loss: 2.142449378967285
Validation loss: 2.4116165689242783

Epoch: 5| Step: 3
Training loss: 2.1158714294433594
Validation loss: 2.4246732291354927

Epoch: 5| Step: 4
Training loss: 2.959756851196289
Validation loss: 2.4454430713448474

Epoch: 5| Step: 5
Training loss: 2.1893551349639893
Validation loss: 2.455605355642175

Epoch: 5| Step: 6
Training loss: 2.5870561599731445
Validation loss: 2.4476420956273235

Epoch: 5| Step: 7
Training loss: 2.5067145824432373
Validation loss: 2.408942926314569

Epoch: 5| Step: 8
Training loss: 2.3115530014038086
Validation loss: 2.375781674538889

Epoch: 5| Step: 9
Training loss: 3.2150089740753174
Validation loss: 2.3659740878689672

Epoch: 5| Step: 10
Training loss: 2.672788143157959
Validation loss: 2.3659310058880876

Epoch: 77| Step: 0
Training loss: 2.5710670948028564
Validation loss: 2.358933546209848

Epoch: 5| Step: 1
Training loss: 2.201293468475342
Validation loss: 2.3591891437448482

Epoch: 5| Step: 2
Training loss: 2.95096492767334
Validation loss: 2.3668986084640666

Epoch: 5| Step: 3
Training loss: 2.2070140838623047
Validation loss: 2.3851252678901917

Epoch: 5| Step: 4
Training loss: 2.6237730979919434
Validation loss: 2.388915838733796

Epoch: 5| Step: 5
Training loss: 2.3923332691192627
Validation loss: 2.406890389739826

Epoch: 5| Step: 6
Training loss: 2.572077512741089
Validation loss: 2.4066978705826627

Epoch: 5| Step: 7
Training loss: 2.6306369304656982
Validation loss: 2.3850595438352196

Epoch: 5| Step: 8
Training loss: 3.210973024368286
Validation loss: 2.37274323227585

Epoch: 5| Step: 9
Training loss: 2.4399571418762207
Validation loss: 2.367577862995927

Epoch: 5| Step: 10
Training loss: 3.445655584335327
Validation loss: 2.368372586465651

Epoch: 78| Step: 0
Training loss: 3.182072162628174
Validation loss: 2.3584813071835424

Epoch: 5| Step: 1
Training loss: 3.0602188110351562
Validation loss: 2.3534579353947795

Epoch: 5| Step: 2
Training loss: 2.4050345420837402
Validation loss: 2.3544685789333877

Epoch: 5| Step: 3
Training loss: 2.2891032695770264
Validation loss: 2.355406230495822

Epoch: 5| Step: 4
Training loss: 2.7498879432678223
Validation loss: 2.3567110748701197

Epoch: 5| Step: 5
Training loss: 2.2111973762512207
Validation loss: 2.3685028681191067

Epoch: 5| Step: 6
Training loss: 2.6490635871887207
Validation loss: 2.379517670600645

Epoch: 5| Step: 7
Training loss: 1.8833646774291992
Validation loss: 2.3921940890691613

Epoch: 5| Step: 8
Training loss: 2.488802433013916
Validation loss: 2.412881499977522

Epoch: 5| Step: 9
Training loss: 2.580749988555908
Validation loss: 2.4341513905473935

Epoch: 5| Step: 10
Training loss: 3.4973254203796387
Validation loss: 2.453052928370814

Epoch: 79| Step: 0
Training loss: 2.0382277965545654
Validation loss: 2.432938395007964

Epoch: 5| Step: 1
Training loss: 3.100468158721924
Validation loss: 2.393879800714472

Epoch: 5| Step: 2
Training loss: 2.7225022315979004
Validation loss: 2.3648171424865723

Epoch: 5| Step: 3
Training loss: 2.871182918548584
Validation loss: 2.3579350697096957

Epoch: 5| Step: 4
Training loss: 2.4916300773620605
Validation loss: 2.3548520098450365

Epoch: 5| Step: 5
Training loss: 1.9858442544937134
Validation loss: 2.350103762841994

Epoch: 5| Step: 6
Training loss: 3.1591124534606934
Validation loss: 2.348892505450915

Epoch: 5| Step: 7
Training loss: 2.9219932556152344
Validation loss: 2.347041650484967

Epoch: 5| Step: 8
Training loss: 2.550565004348755
Validation loss: 2.344338358089488

Epoch: 5| Step: 9
Training loss: 2.6258480548858643
Validation loss: 2.3476026955471245

Epoch: 5| Step: 10
Training loss: 2.4450838565826416
Validation loss: 2.343035877391856

Epoch: 80| Step: 0
Training loss: 2.703033924102783
Validation loss: 2.345346094459616

Epoch: 5| Step: 1
Training loss: 2.1051127910614014
Validation loss: 2.346633936769219

Epoch: 5| Step: 2
Training loss: 3.3404903411865234
Validation loss: 2.3485235680815992

Epoch: 5| Step: 3
Training loss: 2.850536346435547
Validation loss: 2.3504577734137095

Epoch: 5| Step: 4
Training loss: 2.2791504859924316
Validation loss: 2.3450052097279537

Epoch: 5| Step: 5
Training loss: 2.036006450653076
Validation loss: 2.346810689536474

Epoch: 5| Step: 6
Training loss: 2.613983631134033
Validation loss: 2.343639814725486

Epoch: 5| Step: 7
Training loss: 2.355496883392334
Validation loss: 2.3476649484326764

Epoch: 5| Step: 8
Training loss: 3.1778244972229004
Validation loss: 2.3461311504405034

Epoch: 5| Step: 9
Training loss: 2.704261541366577
Validation loss: 2.350745980457593

Epoch: 5| Step: 10
Training loss: 2.6665537357330322
Validation loss: 2.353315750757853

Epoch: 81| Step: 0
Training loss: 2.495985746383667
Validation loss: 2.3665869082173994

Epoch: 5| Step: 1
Training loss: 2.780508518218994
Validation loss: 2.374371538880051

Epoch: 5| Step: 2
Training loss: 2.178255558013916
Validation loss: 2.3807192464028635

Epoch: 5| Step: 3
Training loss: 2.6556763648986816
Validation loss: 2.391683929709978

Epoch: 5| Step: 4
Training loss: 2.9415783882141113
Validation loss: 2.403465101795812

Epoch: 5| Step: 5
Training loss: 2.880079746246338
Validation loss: 2.4027486462746896

Epoch: 5| Step: 6
Training loss: 2.200232982635498
Validation loss: 2.3921050025570776

Epoch: 5| Step: 7
Training loss: 2.229468822479248
Validation loss: 2.373822266055692

Epoch: 5| Step: 8
Training loss: 2.8405117988586426
Validation loss: 2.3575743603449997

Epoch: 5| Step: 9
Training loss: 2.2525031566619873
Validation loss: 2.346990790418399

Epoch: 5| Step: 10
Training loss: 3.3529303073883057
Validation loss: 2.3499346753602386

Epoch: 82| Step: 0
Training loss: 3.1473464965820312
Validation loss: 2.3499549537576656

Epoch: 5| Step: 1
Training loss: 2.2274060249328613
Validation loss: 2.350256607096682

Epoch: 5| Step: 2
Training loss: 2.6259164810180664
Validation loss: 2.3557810450112946

Epoch: 5| Step: 3
Training loss: 2.1725358963012695
Validation loss: 2.3633929068042385

Epoch: 5| Step: 4
Training loss: 2.4699947834014893
Validation loss: 2.3784478864362164

Epoch: 5| Step: 5
Training loss: 2.962263584136963
Validation loss: 2.3854757483287523

Epoch: 5| Step: 6
Training loss: 2.6930832862854004
Validation loss: 2.3928406956375285

Epoch: 5| Step: 7
Training loss: 1.718754529953003
Validation loss: 2.3974584097503335

Epoch: 5| Step: 8
Training loss: 3.325218915939331
Validation loss: 2.4347530846954673

Epoch: 5| Step: 9
Training loss: 2.717438220977783
Validation loss: 2.439642244769681

Epoch: 5| Step: 10
Training loss: 2.734072685241699
Validation loss: 2.418948465777982

Epoch: 83| Step: 0
Training loss: 1.5655988454818726
Validation loss: 2.407117256554224

Epoch: 5| Step: 1
Training loss: 2.1854565143585205
Validation loss: 2.3811228916209233

Epoch: 5| Step: 2
Training loss: 2.5516104698181152
Validation loss: 2.380233754393875

Epoch: 5| Step: 3
Training loss: 2.1925809383392334
Validation loss: 2.372556386455413

Epoch: 5| Step: 4
Training loss: 2.9578633308410645
Validation loss: 2.348506353234732

Epoch: 5| Step: 5
Training loss: 3.6640846729278564
Validation loss: 2.3384866611931914

Epoch: 5| Step: 6
Training loss: 2.3738410472869873
Validation loss: 2.3299176923690306

Epoch: 5| Step: 7
Training loss: 3.3702635765075684
Validation loss: 2.326359769349457

Epoch: 5| Step: 8
Training loss: 2.914445400238037
Validation loss: 2.326342369920464

Epoch: 5| Step: 9
Training loss: 2.253927230834961
Validation loss: 2.326984915682065

Epoch: 5| Step: 10
Training loss: 2.633455276489258
Validation loss: 2.32821919584787

Epoch: 84| Step: 0
Training loss: 2.781674861907959
Validation loss: 2.3293001626127507

Epoch: 5| Step: 1
Training loss: 2.424917697906494
Validation loss: 2.3352313528778734

Epoch: 5| Step: 2
Training loss: 2.6704747676849365
Validation loss: 2.3489866692532777

Epoch: 5| Step: 3
Training loss: 2.6559555530548096
Validation loss: 2.3525031535856185

Epoch: 5| Step: 4
Training loss: 1.9837749004364014
Validation loss: 2.3769288780868694

Epoch: 5| Step: 5
Training loss: 2.67395281791687
Validation loss: 2.390483046090731

Epoch: 5| Step: 6
Training loss: 2.7302393913269043
Validation loss: 2.4064535761392243

Epoch: 5| Step: 7
Training loss: 3.0087857246398926
Validation loss: 2.414396242428851

Epoch: 5| Step: 8
Training loss: 2.9314706325531006
Validation loss: 2.428023902318811

Epoch: 5| Step: 9
Training loss: 2.4591126441955566
Validation loss: 2.435405574819093

Epoch: 5| Step: 10
Training loss: 2.358154296875
Validation loss: 2.4406185201419297

Epoch: 85| Step: 0
Training loss: 2.233691692352295
Validation loss: 2.438619675174836

Epoch: 5| Step: 1
Training loss: 1.683420181274414
Validation loss: 2.4419553638786398

Epoch: 5| Step: 2
Training loss: 3.3940720558166504
Validation loss: 2.42262460595818

Epoch: 5| Step: 3
Training loss: 2.3400096893310547
Validation loss: 2.387758775423932

Epoch: 5| Step: 4
Training loss: 1.7686522006988525
Validation loss: 2.377534120313583

Epoch: 5| Step: 5
Training loss: 2.933022975921631
Validation loss: 2.3705958294612106

Epoch: 5| Step: 6
Training loss: 2.7753875255584717
Validation loss: 2.3668128649393716

Epoch: 5| Step: 7
Training loss: 3.212057113647461
Validation loss: 2.3639173174417145

Epoch: 5| Step: 8
Training loss: 3.35670804977417
Validation loss: 2.364976777825304

Epoch: 5| Step: 9
Training loss: 2.5467052459716797
Validation loss: 2.361240312617312

Epoch: 5| Step: 10
Training loss: 2.608959674835205
Validation loss: 2.360557891989267

Epoch: 86| Step: 0
Training loss: 3.2163925170898438
Validation loss: 2.3688048854950936

Epoch: 5| Step: 1
Training loss: 2.900049924850464
Validation loss: 2.3628194024485927

Epoch: 5| Step: 2
Training loss: 2.094486713409424
Validation loss: 2.3664536399226033

Epoch: 5| Step: 3
Training loss: 2.5316262245178223
Validation loss: 2.3767417989751345

Epoch: 5| Step: 4
Training loss: 2.1472973823547363
Validation loss: 2.3729396302212953

Epoch: 5| Step: 5
Training loss: 2.659661293029785
Validation loss: 2.36364855048477

Epoch: 5| Step: 6
Training loss: 2.574434518814087
Validation loss: 2.366202319822004

Epoch: 5| Step: 7
Training loss: 2.5912704467773438
Validation loss: 2.365638258636639

Epoch: 5| Step: 8
Training loss: 3.6582703590393066
Validation loss: 2.3654495516131

Epoch: 5| Step: 9
Training loss: 2.3872029781341553
Validation loss: 2.3655601419428343

Epoch: 5| Step: 10
Training loss: 1.8496603965759277
Validation loss: 2.365573988165907

Epoch: 87| Step: 0
Training loss: 2.8678925037384033
Validation loss: 2.3684720121404177

Epoch: 5| Step: 1
Training loss: 2.272538900375366
Validation loss: 2.370383708707748

Epoch: 5| Step: 2
Training loss: 2.149686098098755
Validation loss: 2.363791163249682

Epoch: 5| Step: 3
Training loss: 2.404461622238159
Validation loss: 2.360496469723281

Epoch: 5| Step: 4
Training loss: 2.3810367584228516
Validation loss: 2.3574431609081965

Epoch: 5| Step: 5
Training loss: 2.2560245990753174
Validation loss: 2.353892218682074

Epoch: 5| Step: 6
Training loss: 3.1371288299560547
Validation loss: 2.355632135944982

Epoch: 5| Step: 7
Training loss: 2.385359525680542
Validation loss: 2.3461537220144786

Epoch: 5| Step: 8
Training loss: 3.1005711555480957
Validation loss: 2.3482317616862636

Epoch: 5| Step: 9
Training loss: 3.1161437034606934
Validation loss: 2.350555281485281

Epoch: 5| Step: 10
Training loss: 2.557032346725464
Validation loss: 2.352667434241182

Epoch: 88| Step: 0
Training loss: 2.6629557609558105
Validation loss: 2.345174474100913

Epoch: 5| Step: 1
Training loss: 2.348334550857544
Validation loss: 2.3489479634069625

Epoch: 5| Step: 2
Training loss: 2.370445489883423
Validation loss: 2.3552696807410127

Epoch: 5| Step: 3
Training loss: 2.897678852081299
Validation loss: 2.3572359315810667

Epoch: 5| Step: 4
Training loss: 2.437565803527832
Validation loss: 2.352052496325585

Epoch: 5| Step: 5
Training loss: 2.9567720890045166
Validation loss: 2.3434880625817085

Epoch: 5| Step: 6
Training loss: 2.833045244216919
Validation loss: 2.3423340743587864

Epoch: 5| Step: 7
Training loss: 2.5828909873962402
Validation loss: 2.346050017623491

Epoch: 5| Step: 8
Training loss: 2.305438756942749
Validation loss: 2.349059865038882

Epoch: 5| Step: 9
Training loss: 2.3740837574005127
Validation loss: 2.3464636136126775

Epoch: 5| Step: 10
Training loss: 3.0631163120269775
Validation loss: 2.3464569455833844

Epoch: 89| Step: 0
Training loss: 2.484793186187744
Validation loss: 2.348170981612257

Epoch: 5| Step: 1
Training loss: 1.8275039196014404
Validation loss: 2.3439495025142545

Epoch: 5| Step: 2
Training loss: 3.0161471366882324
Validation loss: 2.3484658938582226

Epoch: 5| Step: 3
Training loss: 2.563234806060791
Validation loss: 2.353117730027886

Epoch: 5| Step: 4
Training loss: 2.379805564880371
Validation loss: 2.3568043888256116

Epoch: 5| Step: 5
Training loss: 2.394253969192505
Validation loss: 2.3550941354484967

Epoch: 5| Step: 6
Training loss: 2.4166977405548096
Validation loss: 2.3525094909052693

Epoch: 5| Step: 7
Training loss: 3.259596586227417
Validation loss: 2.3544451498216197

Epoch: 5| Step: 8
Training loss: 2.7545223236083984
Validation loss: 2.3596636915719635

Epoch: 5| Step: 9
Training loss: 2.682220220565796
Validation loss: 2.3675998974871892

Epoch: 5| Step: 10
Training loss: 2.819586753845215
Validation loss: 2.371966374817715

Epoch: 90| Step: 0
Training loss: 2.706815004348755
Validation loss: 2.3741204943708194

Epoch: 5| Step: 1
Training loss: 2.599644422531128
Validation loss: 2.375133752822876

Epoch: 5| Step: 2
Training loss: 2.676881790161133
Validation loss: 2.3603610159248434

Epoch: 5| Step: 3
Training loss: 3.1187148094177246
Validation loss: 2.347875407947007

Epoch: 5| Step: 4
Training loss: 2.246141195297241
Validation loss: 2.340009081748224

Epoch: 5| Step: 5
Training loss: 2.549187183380127
Validation loss: 2.3334522683133363

Epoch: 5| Step: 6
Training loss: 2.792945623397827
Validation loss: 2.3367569574745755

Epoch: 5| Step: 7
Training loss: 2.838416576385498
Validation loss: 2.330753066206491

Epoch: 5| Step: 8
Training loss: 2.7481164932250977
Validation loss: 2.3261042512873167

Epoch: 5| Step: 9
Training loss: 2.1993014812469482
Validation loss: 2.326360817878477

Epoch: 5| Step: 10
Training loss: 1.9346275329589844
Validation loss: 2.3269581512738298

Epoch: 91| Step: 0
Training loss: 2.605989933013916
Validation loss: 2.3271942189944688

Epoch: 5| Step: 1
Training loss: 3.148449420928955
Validation loss: 2.326154460189163

Epoch: 5| Step: 2
Training loss: 2.355271816253662
Validation loss: 2.331244496889012

Epoch: 5| Step: 3
Training loss: 2.3035037517547607
Validation loss: 2.327091891278503

Epoch: 5| Step: 4
Training loss: 3.287804365158081
Validation loss: 2.3345554849152923

Epoch: 5| Step: 5
Training loss: 2.2798328399658203
Validation loss: 2.3311560461598058

Epoch: 5| Step: 6
Training loss: 2.647840976715088
Validation loss: 2.333478771230226

Epoch: 5| Step: 7
Training loss: 2.3840620517730713
Validation loss: 2.349095090743034

Epoch: 5| Step: 8
Training loss: 2.387984037399292
Validation loss: 2.3616150476599254

Epoch: 5| Step: 9
Training loss: 2.3424553871154785
Validation loss: 2.3767486926048034

Epoch: 5| Step: 10
Training loss: 2.819362163543701
Validation loss: 2.376458239811723

Epoch: 92| Step: 0
Training loss: 2.0974044799804688
Validation loss: 2.3635122596576648

Epoch: 5| Step: 1
Training loss: 2.9396848678588867
Validation loss: 2.3446648274698565

Epoch: 5| Step: 2
Training loss: 2.970930337905884
Validation loss: 2.3438387276023946

Epoch: 5| Step: 3
Training loss: 2.732959270477295
Validation loss: 2.330081803824312

Epoch: 5| Step: 4
Training loss: 2.8384885787963867
Validation loss: 2.326911562232561

Epoch: 5| Step: 5
Training loss: 1.5410734415054321
Validation loss: 2.32544364980472

Epoch: 5| Step: 6
Training loss: 3.0444061756134033
Validation loss: 2.3391784570550405

Epoch: 5| Step: 7
Training loss: 2.8716816902160645
Validation loss: 2.342006990986486

Epoch: 5| Step: 8
Training loss: 2.5246806144714355
Validation loss: 2.33991696757655

Epoch: 5| Step: 9
Training loss: 2.2933311462402344
Validation loss: 2.355661233266195

Epoch: 5| Step: 10
Training loss: 2.5227925777435303
Validation loss: 2.3516765230445453

Epoch: 93| Step: 0
Training loss: 3.1859967708587646
Validation loss: 2.3459167941924064

Epoch: 5| Step: 1
Training loss: 1.8098831176757812
Validation loss: 2.3462903268875612

Epoch: 5| Step: 2
Training loss: 2.618816375732422
Validation loss: 2.3479693935763453

Epoch: 5| Step: 3
Training loss: 2.4478142261505127
Validation loss: 2.335338141328545

Epoch: 5| Step: 4
Training loss: 2.8963046073913574
Validation loss: 2.3261746796228553

Epoch: 5| Step: 5
Training loss: 2.6393847465515137
Validation loss: 2.326115527460652

Epoch: 5| Step: 6
Training loss: 2.712825059890747
Validation loss: 2.318011350529168

Epoch: 5| Step: 7
Training loss: 2.6458263397216797
Validation loss: 2.318811088479975

Epoch: 5| Step: 8
Training loss: 2.957819700241089
Validation loss: 2.3274268206729682

Epoch: 5| Step: 9
Training loss: 2.371534824371338
Validation loss: 2.3344181788864957

Epoch: 5| Step: 10
Training loss: 2.033855676651001
Validation loss: 2.3430630160916235

Epoch: 94| Step: 0
Training loss: 2.1584272384643555
Validation loss: 2.346086138038225

Epoch: 5| Step: 1
Training loss: 2.9934093952178955
Validation loss: 2.351680701778781

Epoch: 5| Step: 2
Training loss: 2.4147515296936035
Validation loss: 2.3460567971711517

Epoch: 5| Step: 3
Training loss: 2.5297484397888184
Validation loss: 2.3341825572393273

Epoch: 5| Step: 4
Training loss: 2.97646164894104
Validation loss: 2.33213956381685

Epoch: 5| Step: 5
Training loss: 1.824819803237915
Validation loss: 2.320025254321355

Epoch: 5| Step: 6
Training loss: 2.9729905128479004
Validation loss: 2.3160100854853147

Epoch: 5| Step: 7
Training loss: 2.7128663063049316
Validation loss: 2.3205122845147246

Epoch: 5| Step: 8
Training loss: 2.5666005611419678
Validation loss: 2.3199105980575725

Epoch: 5| Step: 9
Training loss: 2.445680618286133
Validation loss: 2.316982164177843

Epoch: 5| Step: 10
Training loss: 2.7531826496124268
Validation loss: 2.3262157619640393

Epoch: 95| Step: 0
Training loss: 2.8812527656555176
Validation loss: 2.3404339205834175

Epoch: 5| Step: 1
Training loss: 2.8379147052764893
Validation loss: 2.329715282686295

Epoch: 5| Step: 2
Training loss: 2.633171558380127
Validation loss: 2.3338668064404557

Epoch: 5| Step: 3
Training loss: 2.586272716522217
Validation loss: 2.3274826285659627

Epoch: 5| Step: 4
Training loss: 2.6365959644317627
Validation loss: 2.3325325237807406

Epoch: 5| Step: 5
Training loss: 2.8081161975860596
Validation loss: 2.3348267629582393

Epoch: 5| Step: 6
Training loss: 1.9400840997695923
Validation loss: 2.357342045794251

Epoch: 5| Step: 7
Training loss: 3.234102725982666
Validation loss: 2.3878281360031455

Epoch: 5| Step: 8
Training loss: 2.531249523162842
Validation loss: 2.3938235108570387

Epoch: 5| Step: 9
Training loss: 2.1307876110076904
Validation loss: 2.398789918550881

Epoch: 5| Step: 10
Training loss: 2.1068670749664307
Validation loss: 2.3934227804983816

Epoch: 96| Step: 0
Training loss: 2.8872132301330566
Validation loss: 2.3927743998906945

Epoch: 5| Step: 1
Training loss: 2.4460177421569824
Validation loss: 2.3740655222246723

Epoch: 5| Step: 2
Training loss: 2.9198801517486572
Validation loss: 2.367783525938629

Epoch: 5| Step: 3
Training loss: 2.0676567554473877
Validation loss: 2.356041516027143

Epoch: 5| Step: 4
Training loss: 2.589190721511841
Validation loss: 2.3539761420219176

Epoch: 5| Step: 5
Training loss: 2.997706174850464
Validation loss: 2.360134345228954

Epoch: 5| Step: 6
Training loss: 2.605959415435791
Validation loss: 2.3729114096651793

Epoch: 5| Step: 7
Training loss: 2.317946672439575
Validation loss: 2.3760667077956663

Epoch: 5| Step: 8
Training loss: 2.136971950531006
Validation loss: 2.380534423294888

Epoch: 5| Step: 9
Training loss: 2.7027275562286377
Validation loss: 2.380686044692993

Epoch: 5| Step: 10
Training loss: 2.964317798614502
Validation loss: 2.366108489292924

Epoch: 97| Step: 0
Training loss: 2.6384150981903076
Validation loss: 2.386448860168457

Epoch: 5| Step: 1
Training loss: 2.010002613067627
Validation loss: 2.396962094050582

Epoch: 5| Step: 2
Training loss: 2.230452060699463
Validation loss: 2.410715515895556

Epoch: 5| Step: 3
Training loss: 2.344805955886841
Validation loss: 2.4201025450101463

Epoch: 5| Step: 4
Training loss: 2.7890305519104004
Validation loss: 2.4305010200828634

Epoch: 5| Step: 5
Training loss: 2.8670215606689453
Validation loss: 2.3957587211362776

Epoch: 5| Step: 6
Training loss: 3.0573794841766357
Validation loss: 2.378859653267809

Epoch: 5| Step: 7
Training loss: 2.9279932975769043
Validation loss: 2.377700639027421

Epoch: 5| Step: 8
Training loss: 2.3778176307678223
Validation loss: 2.375265003532492

Epoch: 5| Step: 9
Training loss: 2.9955437183380127
Validation loss: 2.36444826023553

Epoch: 5| Step: 10
Training loss: 2.189718723297119
Validation loss: 2.358553960759153

Epoch: 98| Step: 0
Training loss: 2.3516743183135986
Validation loss: 2.359196460375222

Epoch: 5| Step: 1
Training loss: 2.1421592235565186
Validation loss: 2.3687446322492374

Epoch: 5| Step: 2
Training loss: 2.3044345378875732
Validation loss: 2.367719501577398

Epoch: 5| Step: 3
Training loss: 2.6677732467651367
Validation loss: 2.358646931186799

Epoch: 5| Step: 4
Training loss: 3.3364644050598145
Validation loss: 2.3577360978690525

Epoch: 5| Step: 5
Training loss: 2.486577033996582
Validation loss: 2.3448553444236837

Epoch: 5| Step: 6
Training loss: 2.7397563457489014
Validation loss: 2.325606720421904

Epoch: 5| Step: 7
Training loss: 2.4763054847717285
Validation loss: 2.3088205834870696

Epoch: 5| Step: 8
Training loss: 3.2049574851989746
Validation loss: 2.3030343491544008

Epoch: 5| Step: 9
Training loss: 2.5445358753204346
Validation loss: 2.2952327279634375

Epoch: 5| Step: 10
Training loss: 1.8942899703979492
Validation loss: 2.2920626107082573

Epoch: 99| Step: 0
Training loss: 2.3675670623779297
Validation loss: 2.293294970707227

Epoch: 5| Step: 1
Training loss: 3.1669697761535645
Validation loss: 2.295185568512127

Epoch: 5| Step: 2
Training loss: 2.881627321243286
Validation loss: 2.297160683139678

Epoch: 5| Step: 3
Training loss: 2.887120008468628
Validation loss: 2.294924719359285

Epoch: 5| Step: 4
Training loss: 1.9019016027450562
Validation loss: 2.301813433247228

Epoch: 5| Step: 5
Training loss: 2.7669425010681152
Validation loss: 2.3048794718198877

Epoch: 5| Step: 6
Training loss: 2.122252941131592
Validation loss: 2.316141128540039

Epoch: 5| Step: 7
Training loss: 2.065048933029175
Validation loss: 2.3089722433397846

Epoch: 5| Step: 8
Training loss: 2.784409523010254
Validation loss: 2.295266315501223

Epoch: 5| Step: 9
Training loss: 2.49688720703125
Validation loss: 2.2958831428199686

Epoch: 5| Step: 10
Training loss: 2.7893893718719482
Validation loss: 2.293334117499731

Epoch: 100| Step: 0
Training loss: 2.6963448524475098
Validation loss: 2.2939716974894204

Epoch: 5| Step: 1
Training loss: 1.923704743385315
Validation loss: 2.2945271897059616

Epoch: 5| Step: 2
Training loss: 2.9006810188293457
Validation loss: 2.2945843588921333

Epoch: 5| Step: 3
Training loss: 2.7569162845611572
Validation loss: 2.298934685286655

Epoch: 5| Step: 4
Training loss: 2.25689435005188
Validation loss: 2.2884188288001606

Epoch: 5| Step: 5
Training loss: 2.6203227043151855
Validation loss: 2.2864723410657657

Epoch: 5| Step: 6
Training loss: 2.165114402770996
Validation loss: 2.2853492767580095

Epoch: 5| Step: 7
Training loss: 3.0476512908935547
Validation loss: 2.2873499624190794

Epoch: 5| Step: 8
Training loss: 2.6413886547088623
Validation loss: 2.298445652889949

Epoch: 5| Step: 9
Training loss: 2.874732255935669
Validation loss: 2.296924957665064

Epoch: 5| Step: 10
Training loss: 2.0341224670410156
Validation loss: 2.3061547022993847

Epoch: 101| Step: 0
Training loss: 1.7278261184692383
Validation loss: 2.300460530865577

Epoch: 5| Step: 1
Training loss: 2.3167176246643066
Validation loss: 2.3049990669373543

Epoch: 5| Step: 2
Training loss: 2.706071615219116
Validation loss: 2.287587337596442

Epoch: 5| Step: 3
Training loss: 3.4505157470703125
Validation loss: 2.2800909344867994

Epoch: 5| Step: 4
Training loss: 3.0973010063171387
Validation loss: 2.2841217838307863

Epoch: 5| Step: 5
Training loss: 2.4670567512512207
Validation loss: 2.287113123042609

Epoch: 5| Step: 6
Training loss: 2.206571102142334
Validation loss: 2.282855451747935

Epoch: 5| Step: 7
Training loss: 2.424307346343994
Validation loss: 2.284835603929335

Epoch: 5| Step: 8
Training loss: 2.4822494983673096
Validation loss: 2.2861682830318326

Epoch: 5| Step: 9
Training loss: 2.7580819129943848
Validation loss: 2.3062301143523185

Epoch: 5| Step: 10
Training loss: 2.3050880432128906
Validation loss: 2.307328049854566

Epoch: 102| Step: 0
Training loss: 2.8719098567962646
Validation loss: 2.307123963550855

Epoch: 5| Step: 1
Training loss: 3.1835134029388428
Validation loss: 2.3033015599814792

Epoch: 5| Step: 2
Training loss: 1.9317424297332764
Validation loss: 2.2856295518977667

Epoch: 5| Step: 3
Training loss: 2.648191213607788
Validation loss: 2.2770609060923257

Epoch: 5| Step: 4
Training loss: 2.13230562210083
Validation loss: 2.2831898632869927

Epoch: 5| Step: 5
Training loss: 2.066183567047119
Validation loss: 2.2869869406505297

Epoch: 5| Step: 6
Training loss: 2.921112537384033
Validation loss: 2.272606926579629

Epoch: 5| Step: 7
Training loss: 2.332071304321289
Validation loss: 2.271418115144135

Epoch: 5| Step: 8
Training loss: 2.486516237258911
Validation loss: 2.2846976134084884

Epoch: 5| Step: 9
Training loss: 2.7877655029296875
Validation loss: 2.2767610062835035

Epoch: 5| Step: 10
Training loss: 2.544335126876831
Validation loss: 2.2725226084391275

Epoch: 103| Step: 0
Training loss: 2.5791990756988525
Validation loss: 2.278142367639849

Epoch: 5| Step: 1
Training loss: 2.2092843055725098
Validation loss: 2.2717980928318475

Epoch: 5| Step: 2
Training loss: 2.6829917430877686
Validation loss: 2.2743046104267077

Epoch: 5| Step: 3
Training loss: 2.0524814128875732
Validation loss: 2.2700380791899977

Epoch: 5| Step: 4
Training loss: 3.2545852661132812
Validation loss: 2.2887955250278598

Epoch: 5| Step: 5
Training loss: 2.2899603843688965
Validation loss: 2.2946035746605165

Epoch: 5| Step: 6
Training loss: 2.36610746383667
Validation loss: 2.303689226027458

Epoch: 5| Step: 7
Training loss: 2.989100933074951
Validation loss: 2.283282972151233

Epoch: 5| Step: 8
Training loss: 2.3785948753356934
Validation loss: 2.2783526912812264

Epoch: 5| Step: 9
Training loss: 2.1858654022216797
Validation loss: 2.279440825985324

Epoch: 5| Step: 10
Training loss: 2.886119842529297
Validation loss: 2.2746165490919545

Epoch: 104| Step: 0
Training loss: 2.5126636028289795
Validation loss: 2.268492173123103

Epoch: 5| Step: 1
Training loss: 1.846075415611267
Validation loss: 2.2714482199761177

Epoch: 5| Step: 2
Training loss: 2.657646417617798
Validation loss: 2.2688214548172487

Epoch: 5| Step: 3
Training loss: 3.0110042095184326
Validation loss: 2.267463812264063

Epoch: 5| Step: 4
Training loss: 1.9451717138290405
Validation loss: 2.26840901631181

Epoch: 5| Step: 5
Training loss: 1.8316017389297485
Validation loss: 2.2694337393647883

Epoch: 5| Step: 6
Training loss: 3.2846741676330566
Validation loss: 2.2752554019292197

Epoch: 5| Step: 7
Training loss: 2.600146770477295
Validation loss: 2.2726285380701863

Epoch: 5| Step: 8
Training loss: 2.502256393432617
Validation loss: 2.2803215160164783

Epoch: 5| Step: 9
Training loss: 3.000917673110962
Validation loss: 2.294650154729043

Epoch: 5| Step: 10
Training loss: 2.586442232131958
Validation loss: 2.3432065184398363

Epoch: 105| Step: 0
Training loss: 3.006560802459717
Validation loss: 2.309873643741813

Epoch: 5| Step: 1
Training loss: 3.0340609550476074
Validation loss: 2.2970741666773313

Epoch: 5| Step: 2
Training loss: 2.541247606277466
Validation loss: 2.263653785951676

Epoch: 5| Step: 3
Training loss: 2.586336135864258
Validation loss: 2.2635862852937434

Epoch: 5| Step: 4
Training loss: 1.5663963556289673
Validation loss: 2.2554069821552565

Epoch: 5| Step: 5
Training loss: 2.628342866897583
Validation loss: 2.2475578887488252

Epoch: 5| Step: 6
Training loss: 2.208594799041748
Validation loss: 2.252416564572242

Epoch: 5| Step: 7
Training loss: 2.707271099090576
Validation loss: 2.2495524678179013

Epoch: 5| Step: 8
Training loss: 2.3535351753234863
Validation loss: 2.2588773901744554

Epoch: 5| Step: 9
Training loss: 2.5158095359802246
Validation loss: 2.263450562313039

Epoch: 5| Step: 10
Training loss: 2.660627841949463
Validation loss: 2.269275565301218

Epoch: 106| Step: 0
Training loss: 2.1038401126861572
Validation loss: 2.2846932116375176

Epoch: 5| Step: 1
Training loss: 2.8474369049072266
Validation loss: 2.2899853721741708

Epoch: 5| Step: 2
Training loss: 2.4882988929748535
Validation loss: 2.2890866700039116

Epoch: 5| Step: 3
Training loss: 2.523771047592163
Validation loss: 2.274536191776235

Epoch: 5| Step: 4
Training loss: 2.4970736503601074
Validation loss: 2.263139250457928

Epoch: 5| Step: 5
Training loss: 2.040889024734497
Validation loss: 2.250594077571746

Epoch: 5| Step: 6
Training loss: 2.609616756439209
Validation loss: 2.2530889690563245

Epoch: 5| Step: 7
Training loss: 2.199894428253174
Validation loss: 2.2513908006811656

Epoch: 5| Step: 8
Training loss: 2.664489507675171
Validation loss: 2.252692166195121

Epoch: 5| Step: 9
Training loss: 2.3839945793151855
Validation loss: 2.2504681823074177

Epoch: 5| Step: 10
Training loss: 3.481998920440674
Validation loss: 2.248009886792911

Epoch: 107| Step: 0
Training loss: 2.505124568939209
Validation loss: 2.2534710873839674

Epoch: 5| Step: 1
Training loss: 2.505148410797119
Validation loss: 2.2607018652782647

Epoch: 5| Step: 2
Training loss: 2.4888672828674316
Validation loss: 2.2780408756707304

Epoch: 5| Step: 3
Training loss: 2.6740078926086426
Validation loss: 2.299762923230407

Epoch: 5| Step: 4
Training loss: 2.4571971893310547
Validation loss: 2.3012562439005864

Epoch: 5| Step: 5
Training loss: 2.183309555053711
Validation loss: 2.3018571587019068

Epoch: 5| Step: 6
Training loss: 2.3367767333984375
Validation loss: 2.2852358689872165

Epoch: 5| Step: 7
Training loss: 2.052865743637085
Validation loss: 2.244734994826778

Epoch: 5| Step: 8
Training loss: 2.794686794281006
Validation loss: 2.2394577380149596

Epoch: 5| Step: 9
Training loss: 2.7875828742980957
Validation loss: 2.243609546333231

Epoch: 5| Step: 10
Training loss: 2.9380147457122803
Validation loss: 2.244319350488724

Epoch: 108| Step: 0
Training loss: 2.708988666534424
Validation loss: 2.246241731028403

Epoch: 5| Step: 1
Training loss: 2.4915289878845215
Validation loss: 2.244955455103228

Epoch: 5| Step: 2
Training loss: 2.067023992538452
Validation loss: 2.247081006726911

Epoch: 5| Step: 3
Training loss: 2.932514190673828
Validation loss: 2.241636212154101

Epoch: 5| Step: 4
Training loss: 3.0135061740875244
Validation loss: 2.244627042483258

Epoch: 5| Step: 5
Training loss: 2.7133007049560547
Validation loss: 2.2374553321510233

Epoch: 5| Step: 6
Training loss: 2.1957826614379883
Validation loss: 2.247951102513139

Epoch: 5| Step: 7
Training loss: 2.0669445991516113
Validation loss: 2.250317067228338

Epoch: 5| Step: 8
Training loss: 2.6720850467681885
Validation loss: 2.24789192599635

Epoch: 5| Step: 9
Training loss: 2.435943841934204
Validation loss: 2.2493573337472896

Epoch: 5| Step: 10
Training loss: 2.4601664543151855
Validation loss: 2.2374768718596427

Epoch: 109| Step: 0
Training loss: 2.186225414276123
Validation loss: 2.2441123839347594

Epoch: 5| Step: 1
Training loss: 3.317505359649658
Validation loss: 2.2389763862855974

Epoch: 5| Step: 2
Training loss: 2.888148784637451
Validation loss: 2.239726213998692

Epoch: 5| Step: 3
Training loss: 2.654654026031494
Validation loss: 2.2420769724794614

Epoch: 5| Step: 4
Training loss: 2.367676019668579
Validation loss: 2.246859945276732

Epoch: 5| Step: 5
Training loss: 2.7689788341522217
Validation loss: 2.2449612130400953

Epoch: 5| Step: 6
Training loss: 1.983589768409729
Validation loss: 2.2383298822628555

Epoch: 5| Step: 7
Training loss: 2.207857608795166
Validation loss: 2.2309123751937703

Epoch: 5| Step: 8
Training loss: 2.22393798828125
Validation loss: 2.231152231975268

Epoch: 5| Step: 9
Training loss: 2.318272113800049
Validation loss: 2.236966562527482

Epoch: 5| Step: 10
Training loss: 2.5682904720306396
Validation loss: 2.237103407100965

Epoch: 110| Step: 0
Training loss: 2.344182014465332
Validation loss: 2.228517404166601

Epoch: 5| Step: 1
Training loss: 2.5519721508026123
Validation loss: 2.236060832136421

Epoch: 5| Step: 2
Training loss: 2.3310139179229736
Validation loss: 2.2392226214049966

Epoch: 5| Step: 3
Training loss: 2.420741081237793
Validation loss: 2.239661757664014

Epoch: 5| Step: 4
Training loss: 2.3925585746765137
Validation loss: 2.2439416429047943

Epoch: 5| Step: 5
Training loss: 2.4618515968322754
Validation loss: 2.2578993394810665

Epoch: 5| Step: 6
Training loss: 3.488590955734253
Validation loss: 2.267848717269077

Epoch: 5| Step: 7
Training loss: 2.334014415740967
Validation loss: 2.24655242120066

Epoch: 5| Step: 8
Training loss: 2.8429601192474365
Validation loss: 2.2349640630906626

Epoch: 5| Step: 9
Training loss: 2.1208622455596924
Validation loss: 2.226540101471768

Epoch: 5| Step: 10
Training loss: 2.1009726524353027
Validation loss: 2.2286611346788305

Epoch: 111| Step: 0
Training loss: 2.4983012676239014
Validation loss: 2.2294408736690396

Epoch: 5| Step: 1
Training loss: 2.4111294746398926
Validation loss: 2.233068891750869

Epoch: 5| Step: 2
Training loss: 2.3579654693603516
Validation loss: 2.2268996418163343

Epoch: 5| Step: 3
Training loss: 2.7526919841766357
Validation loss: 2.219455821539766

Epoch: 5| Step: 4
Training loss: 2.699233293533325
Validation loss: 2.223127354857742

Epoch: 5| Step: 5
Training loss: 2.1425209045410156
Validation loss: 2.217882566554572

Epoch: 5| Step: 6
Training loss: 2.6256988048553467
Validation loss: 2.2242119491741223

Epoch: 5| Step: 7
Training loss: 2.3615269660949707
Validation loss: 2.238165242697603

Epoch: 5| Step: 8
Training loss: 2.87634015083313
Validation loss: 2.272179224157846

Epoch: 5| Step: 9
Training loss: 2.542400598526001
Validation loss: 2.2856091709547144

Epoch: 5| Step: 10
Training loss: 2.1544744968414307
Validation loss: 2.267696075541999

Epoch: 112| Step: 0
Training loss: 2.952073812484741
Validation loss: 2.2328173191316667

Epoch: 5| Step: 1
Training loss: 2.203315496444702
Validation loss: 2.218583283885833

Epoch: 5| Step: 2
Training loss: 2.4074771404266357
Validation loss: 2.2205934345081286

Epoch: 5| Step: 3
Training loss: 2.5142321586608887
Validation loss: 2.2299550630713023

Epoch: 5| Step: 4
Training loss: 3.3805370330810547
Validation loss: 2.2318582714244886

Epoch: 5| Step: 5
Training loss: 2.6477091312408447
Validation loss: 2.2330261174068657

Epoch: 5| Step: 6
Training loss: 2.806422710418701
Validation loss: 2.232236982673727

Epoch: 5| Step: 7
Training loss: 1.8974316120147705
Validation loss: 2.221648609766396

Epoch: 5| Step: 8
Training loss: 2.350515127182007
Validation loss: 2.214008874790643

Epoch: 5| Step: 9
Training loss: 2.137848377227783
Validation loss: 2.2149011037682973

Epoch: 5| Step: 10
Training loss: 2.28468918800354
Validation loss: 2.25330683236481

Epoch: 113| Step: 0
Training loss: 1.8155549764633179
Validation loss: 2.2997709640892605

Epoch: 5| Step: 1
Training loss: 2.741483211517334
Validation loss: 2.329273539204751

Epoch: 5| Step: 2
Training loss: 2.2789714336395264
Validation loss: 2.3104334236473165

Epoch: 5| Step: 3
Training loss: 2.0987229347229004
Validation loss: 2.282627372331517

Epoch: 5| Step: 4
Training loss: 2.3383820056915283
Validation loss: 2.232946249746507

Epoch: 5| Step: 5
Training loss: 2.2018065452575684
Validation loss: 2.2099656674169723

Epoch: 5| Step: 6
Training loss: 2.8592145442962646
Validation loss: 2.214655354458799

Epoch: 5| Step: 7
Training loss: 3.2136712074279785
Validation loss: 2.2233684755140737

Epoch: 5| Step: 8
Training loss: 2.179842710494995
Validation loss: 2.2322830846232753

Epoch: 5| Step: 9
Training loss: 2.968100070953369
Validation loss: 2.2388493553284676

Epoch: 5| Step: 10
Training loss: 2.9389939308166504
Validation loss: 2.247886678223969

Epoch: 114| Step: 0
Training loss: 2.2105026245117188
Validation loss: 2.239697317923269

Epoch: 5| Step: 1
Training loss: 2.9470391273498535
Validation loss: 2.230789646025627

Epoch: 5| Step: 2
Training loss: 2.2370479106903076
Validation loss: 2.216385837524168

Epoch: 5| Step: 3
Training loss: 2.1689376831054688
Validation loss: 2.2109094563350884

Epoch: 5| Step: 4
Training loss: 2.722696304321289
Validation loss: 2.2035258969952984

Epoch: 5| Step: 5
Training loss: 2.181278705596924
Validation loss: 2.213447009363482

Epoch: 5| Step: 6
Training loss: 2.654306411743164
Validation loss: 2.2218532510983047

Epoch: 5| Step: 7
Training loss: 2.1043238639831543
Validation loss: 2.2503080444951213

Epoch: 5| Step: 8
Training loss: 3.333662509918213
Validation loss: 2.2676938836292555

Epoch: 5| Step: 9
Training loss: 2.5582425594329834
Validation loss: 2.272021655113466

Epoch: 5| Step: 10
Training loss: 2.3087754249572754
Validation loss: 2.2618640597148607

Epoch: 115| Step: 0
Training loss: 2.043719530105591
Validation loss: 2.2334220281211277

Epoch: 5| Step: 1
Training loss: 1.731079339981079
Validation loss: 2.217997027981666

Epoch: 5| Step: 2
Training loss: 2.6113038063049316
Validation loss: 2.2184005860359437

Epoch: 5| Step: 3
Training loss: 2.040335178375244
Validation loss: 2.2165281746977117

Epoch: 5| Step: 4
Training loss: 2.431607723236084
Validation loss: 2.204709809313538

Epoch: 5| Step: 5
Training loss: 3.223583221435547
Validation loss: 2.202632575906733

Epoch: 5| Step: 6
Training loss: 2.681443691253662
Validation loss: 2.200092036236999

Epoch: 5| Step: 7
Training loss: 3.0120553970336914
Validation loss: 2.2062122475716377

Epoch: 5| Step: 8
Training loss: 2.4615657329559326
Validation loss: 2.206237892950735

Epoch: 5| Step: 9
Training loss: 2.2664244174957275
Validation loss: 2.210967097231137

Epoch: 5| Step: 10
Training loss: 2.819791078567505
Validation loss: 2.209112157103836

Epoch: 116| Step: 0
Training loss: 3.1271071434020996
Validation loss: 2.220491922029885

Epoch: 5| Step: 1
Training loss: 2.020601511001587
Validation loss: 2.232476995837304

Epoch: 5| Step: 2
Training loss: 2.0475921630859375
Validation loss: 2.2461513985869703

Epoch: 5| Step: 3
Training loss: 2.2035374641418457
Validation loss: 2.2748603872073594

Epoch: 5| Step: 4
Training loss: 2.2880961894989014
Validation loss: 2.302330063235375

Epoch: 5| Step: 5
Training loss: 2.782370090484619
Validation loss: 2.2792517472338933

Epoch: 5| Step: 6
Training loss: 2.6800575256347656
Validation loss: 2.234574076949909

Epoch: 5| Step: 7
Training loss: 2.9803307056427
Validation loss: 2.207704213357741

Epoch: 5| Step: 8
Training loss: 2.42134165763855
Validation loss: 2.198903017146613

Epoch: 5| Step: 9
Training loss: 2.5608229637145996
Validation loss: 2.197265668581891

Epoch: 5| Step: 10
Training loss: 2.0318074226379395
Validation loss: 2.2062808134222545

Epoch: 117| Step: 0
Training loss: 2.3814051151275635
Validation loss: 2.210686094017439

Epoch: 5| Step: 1
Training loss: 2.5725815296173096
Validation loss: 2.2207537261388635

Epoch: 5| Step: 2
Training loss: 2.3101539611816406
Validation loss: 2.2242235932298886

Epoch: 5| Step: 3
Training loss: 2.5598087310791016
Validation loss: 2.2234521014716035

Epoch: 5| Step: 4
Training loss: 2.970569610595703
Validation loss: 2.222746387604744

Epoch: 5| Step: 5
Training loss: 2.0439233779907227
Validation loss: 2.2184806152056624

Epoch: 5| Step: 6
Training loss: 2.3767924308776855
Validation loss: 2.204493695689786

Epoch: 5| Step: 7
Training loss: 3.345867872238159
Validation loss: 2.194890260696411

Epoch: 5| Step: 8
Training loss: 2.6400306224823
Validation loss: 2.1992833537440144

Epoch: 5| Step: 9
Training loss: 2.6987359523773193
Validation loss: 2.217622264739006

Epoch: 5| Step: 10
Training loss: 1.574366569519043
Validation loss: 2.2454328139623008

Epoch: 118| Step: 0
Training loss: 3.0176680088043213
Validation loss: 2.26783900748017

Epoch: 5| Step: 1
Training loss: 2.589379072189331
Validation loss: 2.2634457695868706

Epoch: 5| Step: 2
Training loss: 2.5240204334259033
Validation loss: 2.2359499598062165

Epoch: 5| Step: 3
Training loss: 2.3139379024505615
Validation loss: 2.218550459031136

Epoch: 5| Step: 4
Training loss: 2.5088868141174316
Validation loss: 2.205638436860936

Epoch: 5| Step: 5
Training loss: 2.2200207710266113
Validation loss: 2.197764012121385

Epoch: 5| Step: 6
Training loss: 1.58274507522583
Validation loss: 2.1903060982304234

Epoch: 5| Step: 7
Training loss: 2.3809497356414795
Validation loss: 2.1845899474236274

Epoch: 5| Step: 8
Training loss: 2.903378486633301
Validation loss: 2.1893294498484623

Epoch: 5| Step: 9
Training loss: 2.547452926635742
Validation loss: 2.1909376241827525

Epoch: 5| Step: 10
Training loss: 2.569049835205078
Validation loss: 2.1926927745983167

Epoch: 119| Step: 0
Training loss: 2.8053956031799316
Validation loss: 2.1860822887830835

Epoch: 5| Step: 1
Training loss: 1.7695471048355103
Validation loss: 2.2015807320994716

Epoch: 5| Step: 2
Training loss: 3.0324466228485107
Validation loss: 2.2307896357710644

Epoch: 5| Step: 3
Training loss: 2.2296690940856934
Validation loss: 2.2855242298495386

Epoch: 5| Step: 4
Training loss: 2.245150327682495
Validation loss: 2.263573815745692

Epoch: 5| Step: 5
Training loss: 3.0061705112457275
Validation loss: 2.226331546742429

Epoch: 5| Step: 6
Training loss: 2.5777008533477783
Validation loss: 2.19459879526528

Epoch: 5| Step: 7
Training loss: 2.5333034992218018
Validation loss: 2.1973817720208118

Epoch: 5| Step: 8
Training loss: 1.927207589149475
Validation loss: 2.2145404533673356

Epoch: 5| Step: 9
Training loss: 2.7229228019714355
Validation loss: 2.208735078893682

Epoch: 5| Step: 10
Training loss: 2.3091070652008057
Validation loss: 2.221934526197372

Epoch: 120| Step: 0
Training loss: 2.3338513374328613
Validation loss: 2.208528780168103

Epoch: 5| Step: 1
Training loss: 2.7126967906951904
Validation loss: 2.198278659133501

Epoch: 5| Step: 2
Training loss: 2.919645309448242
Validation loss: 2.195207711189024

Epoch: 5| Step: 3
Training loss: 2.6731860637664795
Validation loss: 2.190692692674616

Epoch: 5| Step: 4
Training loss: 2.6877734661102295
Validation loss: 2.188740127830095

Epoch: 5| Step: 5
Training loss: 2.4627623558044434
Validation loss: 2.188275170582597

Epoch: 5| Step: 6
Training loss: 2.8108859062194824
Validation loss: 2.1828579646284862

Epoch: 5| Step: 7
Training loss: 2.3848423957824707
Validation loss: 2.183507042546426

Epoch: 5| Step: 8
Training loss: 2.1971664428710938
Validation loss: 2.193023507313062

Epoch: 5| Step: 9
Training loss: 1.8093812465667725
Validation loss: 2.223278045654297

Epoch: 5| Step: 10
Training loss: 2.3285748958587646
Validation loss: 2.252072003579909

Epoch: 121| Step: 0
Training loss: 2.659198760986328
Validation loss: 2.2695526153810563

Epoch: 5| Step: 1
Training loss: 2.954197406768799
Validation loss: 2.2531230424040105

Epoch: 5| Step: 2
Training loss: 2.150970697402954
Validation loss: 2.2231686397265364

Epoch: 5| Step: 3
Training loss: 2.7584328651428223
Validation loss: 2.1994816885199597

Epoch: 5| Step: 4
Training loss: 2.29893159866333
Validation loss: 2.1835939986731416

Epoch: 5| Step: 5
Training loss: 2.03472900390625
Validation loss: 2.175827587804487

Epoch: 5| Step: 6
Training loss: 2.2466869354248047
Validation loss: 2.165271776978688

Epoch: 5| Step: 7
Training loss: 2.1693217754364014
Validation loss: 2.1683736847292994

Epoch: 5| Step: 8
Training loss: 2.525728702545166
Validation loss: 2.1724179406319895

Epoch: 5| Step: 9
Training loss: 2.6023812294006348
Validation loss: 2.171509345372518

Epoch: 5| Step: 10
Training loss: 2.5656399726867676
Validation loss: 2.1713341846260974

Epoch: 122| Step: 0
Training loss: 2.0464749336242676
Validation loss: 2.180288598101626

Epoch: 5| Step: 1
Training loss: 3.073728322982788
Validation loss: 2.1836956547152613

Epoch: 5| Step: 2
Training loss: 2.6969380378723145
Validation loss: 2.179573407737158

Epoch: 5| Step: 3
Training loss: 2.2419495582580566
Validation loss: 2.1887477213336575

Epoch: 5| Step: 4
Training loss: 2.6634085178375244
Validation loss: 2.1868124674725276

Epoch: 5| Step: 5
Training loss: 2.3976187705993652
Validation loss: 2.1895980194050777

Epoch: 5| Step: 6
Training loss: 2.748295545578003
Validation loss: 2.1940485867120887

Epoch: 5| Step: 7
Training loss: 2.4014930725097656
Validation loss: 2.2074717783158824

Epoch: 5| Step: 8
Training loss: 2.728297472000122
Validation loss: 2.183724288017519

Epoch: 5| Step: 9
Training loss: 1.4467220306396484
Validation loss: 2.16161560755904

Epoch: 5| Step: 10
Training loss: 2.3363239765167236
Validation loss: 2.1521381972938456

Epoch: 123| Step: 0
Training loss: 2.307753086090088
Validation loss: 2.159553233013358

Epoch: 5| Step: 1
Training loss: 1.8605754375457764
Validation loss: 2.17080355716008

Epoch: 5| Step: 2
Training loss: 2.7002010345458984
Validation loss: 2.176741830764278

Epoch: 5| Step: 3
Training loss: 2.552652359008789
Validation loss: 2.179992691163094

Epoch: 5| Step: 4
Training loss: 2.2661523818969727
Validation loss: 2.182195089196646

Epoch: 5| Step: 5
Training loss: 2.3344244956970215
Validation loss: 2.175304512823782

Epoch: 5| Step: 6
Training loss: 2.8391919136047363
Validation loss: 2.1790647250349804

Epoch: 5| Step: 7
Training loss: 2.743340015411377
Validation loss: 2.1821249633707027

Epoch: 5| Step: 8
Training loss: 2.5432028770446777
Validation loss: 2.17822584285531

Epoch: 5| Step: 9
Training loss: 2.6202034950256348
Validation loss: 2.170329163151403

Epoch: 5| Step: 10
Training loss: 2.6397345066070557
Validation loss: 2.1758515116988972

Epoch: 124| Step: 0
Training loss: 1.9237287044525146
Validation loss: 2.1750071125645793

Epoch: 5| Step: 1
Training loss: 3.083465337753296
Validation loss: 2.19938241025453

Epoch: 5| Step: 2
Training loss: 2.569974660873413
Validation loss: 2.2121181180400233

Epoch: 5| Step: 3
Training loss: 2.5901830196380615
Validation loss: 2.2320926945696593

Epoch: 5| Step: 4
Training loss: 2.267840623855591
Validation loss: 2.216766349730953

Epoch: 5| Step: 5
Training loss: 2.415393590927124
Validation loss: 2.1909405531421786

Epoch: 5| Step: 6
Training loss: 2.056044101715088
Validation loss: 2.176504542750697

Epoch: 5| Step: 7
Training loss: 2.652100086212158
Validation loss: 2.1728467402919645

Epoch: 5| Step: 8
Training loss: 2.3385303020477295
Validation loss: 2.1553645031426543

Epoch: 5| Step: 9
Training loss: 2.514244556427002
Validation loss: 2.1582977130848873

Epoch: 5| Step: 10
Training loss: 2.377746105194092
Validation loss: 2.165089379074753

Epoch: 125| Step: 0
Training loss: 2.561194896697998
Validation loss: 2.1764933063137915

Epoch: 5| Step: 1
Training loss: 1.9316765069961548
Validation loss: 2.168260484613398

Epoch: 5| Step: 2
Training loss: 2.375732898712158
Validation loss: 2.1530252477174163

Epoch: 5| Step: 3
Training loss: 2.5727474689483643
Validation loss: 2.1548827284125873

Epoch: 5| Step: 4
Training loss: 2.198416233062744
Validation loss: 2.145413118024026

Epoch: 5| Step: 5
Training loss: 2.2681033611297607
Validation loss: 2.152648957826758

Epoch: 5| Step: 6
Training loss: 2.7334864139556885
Validation loss: 2.141738873656078

Epoch: 5| Step: 7
Training loss: 2.29980731010437
Validation loss: 2.15253008309231

Epoch: 5| Step: 8
Training loss: 2.664513349533081
Validation loss: 2.145446423561342

Epoch: 5| Step: 9
Training loss: 2.749267578125
Validation loss: 2.162225907848727

Epoch: 5| Step: 10
Training loss: 2.3218135833740234
Validation loss: 2.179801587135561

Epoch: 126| Step: 0
Training loss: 2.405550718307495
Validation loss: 2.179663678651215

Epoch: 5| Step: 1
Training loss: 2.300973415374756
Validation loss: 2.1794304052988687

Epoch: 5| Step: 2
Training loss: 2.4095964431762695
Validation loss: 2.1746426743845784

Epoch: 5| Step: 3
Training loss: 2.214569568634033
Validation loss: 2.151977631353563

Epoch: 5| Step: 4
Training loss: 1.884892225265503
Validation loss: 2.156329272895731

Epoch: 5| Step: 5
Training loss: 2.357606887817383
Validation loss: 2.1574707659341956

Epoch: 5| Step: 6
Training loss: 2.25673246383667
Validation loss: 2.1501058763073337

Epoch: 5| Step: 7
Training loss: 1.845415711402893
Validation loss: 2.1377256019141084

Epoch: 5| Step: 8
Training loss: 3.4206981658935547
Validation loss: 2.139225841850363

Epoch: 5| Step: 9
Training loss: 2.6357553005218506
Validation loss: 2.149801013290241

Epoch: 5| Step: 10
Training loss: 2.8551254272460938
Validation loss: 2.1482537536210913

Epoch: 127| Step: 0
Training loss: 2.238236904144287
Validation loss: 2.1533150057638846

Epoch: 5| Step: 1
Training loss: 2.351438522338867
Validation loss: 2.171480522360853

Epoch: 5| Step: 2
Training loss: 2.7478363513946533
Validation loss: 2.1765470171487458

Epoch: 5| Step: 3
Training loss: 2.7047839164733887
Validation loss: 2.172878703763408

Epoch: 5| Step: 4
Training loss: 2.587925434112549
Validation loss: 2.1656248851488997

Epoch: 5| Step: 5
Training loss: 2.4696805477142334
Validation loss: 2.1591984123312016

Epoch: 5| Step: 6
Training loss: 1.9681110382080078
Validation loss: 2.149518994874852

Epoch: 5| Step: 7
Training loss: 1.9755265712738037
Validation loss: 2.1477783367198002

Epoch: 5| Step: 8
Training loss: 2.397634983062744
Validation loss: 2.1565820401714695

Epoch: 5| Step: 9
Training loss: 2.400268316268921
Validation loss: 2.158619793512488

Epoch: 5| Step: 10
Training loss: 2.599942684173584
Validation loss: 2.155257157100144

Epoch: 128| Step: 0
Training loss: 1.9709495306015015
Validation loss: 2.1445533306367937

Epoch: 5| Step: 1
Training loss: 1.8714736700057983
Validation loss: 2.142200058506381

Epoch: 5| Step: 2
Training loss: 2.38420033454895
Validation loss: 2.140008226517708

Epoch: 5| Step: 3
Training loss: 2.873035192489624
Validation loss: 2.140151778856913

Epoch: 5| Step: 4
Training loss: 2.7087137699127197
Validation loss: 2.1330221801675777

Epoch: 5| Step: 5
Training loss: 3.0069260597229004
Validation loss: 2.131159543991089

Epoch: 5| Step: 6
Training loss: 2.7252721786499023
Validation loss: 2.133292946764218

Epoch: 5| Step: 7
Training loss: 2.2432427406311035
Validation loss: 2.133343768376176

Epoch: 5| Step: 8
Training loss: 2.270510673522949
Validation loss: 2.1364439405420774

Epoch: 5| Step: 9
Training loss: 1.7880609035491943
Validation loss: 2.131442464807982

Epoch: 5| Step: 10
Training loss: 2.6363747119903564
Validation loss: 2.1562254544227355

Epoch: 129| Step: 0
Training loss: 2.2186503410339355
Validation loss: 2.1750337346907584

Epoch: 5| Step: 1
Training loss: 2.1484615802764893
Validation loss: 2.193778628944069

Epoch: 5| Step: 2
Training loss: 2.3308663368225098
Validation loss: 2.1922528333561395

Epoch: 5| Step: 3
Training loss: 2.4590401649475098
Validation loss: 2.1780136118653

Epoch: 5| Step: 4
Training loss: 2.4617831707000732
Validation loss: 2.1526904311231387

Epoch: 5| Step: 5
Training loss: 2.6522648334503174
Validation loss: 2.139028872213056

Epoch: 5| Step: 6
Training loss: 2.4551753997802734
Validation loss: 2.136855850937546

Epoch: 5| Step: 7
Training loss: 2.3983311653137207
Validation loss: 2.1377040724600516

Epoch: 5| Step: 8
Training loss: 2.2620255947113037
Validation loss: 2.1353026769494496

Epoch: 5| Step: 9
Training loss: 2.934863328933716
Validation loss: 2.1278360838531167

Epoch: 5| Step: 10
Training loss: 2.126030445098877
Validation loss: 2.1460363711080244

Epoch: 130| Step: 0
Training loss: 2.198615312576294
Validation loss: 2.1405283738208074

Epoch: 5| Step: 1
Training loss: 1.9902833700180054
Validation loss: 2.1507876419251963

Epoch: 5| Step: 2
Training loss: 1.7927367687225342
Validation loss: 2.1534782148176626

Epoch: 5| Step: 3
Training loss: 2.3520760536193848
Validation loss: 2.153809952479537

Epoch: 5| Step: 4
Training loss: 2.540780544281006
Validation loss: 2.170550920630014

Epoch: 5| Step: 5
Training loss: 2.107520818710327
Validation loss: 2.1737927018955188

Epoch: 5| Step: 6
Training loss: 3.181318759918213
Validation loss: 2.149959946191439

Epoch: 5| Step: 7
Training loss: 2.502764940261841
Validation loss: 2.14121498087401

Epoch: 5| Step: 8
Training loss: 2.5489304065704346
Validation loss: 2.126606551549768

Epoch: 5| Step: 9
Training loss: 2.2969517707824707
Validation loss: 2.133023900370444

Epoch: 5| Step: 10
Training loss: 2.8359134197235107
Validation loss: 2.1361445662795857

Epoch: 131| Step: 0
Training loss: 2.634902000427246
Validation loss: 2.1282264776127313

Epoch: 5| Step: 1
Training loss: 3.003077983856201
Validation loss: 2.1433130541155414

Epoch: 5| Step: 2
Training loss: 1.7582666873931885
Validation loss: 2.136997838174143

Epoch: 5| Step: 3
Training loss: 2.1591904163360596
Validation loss: 2.1427418980547177

Epoch: 5| Step: 4
Training loss: 2.6076464653015137
Validation loss: 2.1440087749112036

Epoch: 5| Step: 5
Training loss: 2.6341443061828613
Validation loss: 2.1446180484628163

Epoch: 5| Step: 6
Training loss: 2.0403826236724854
Validation loss: 2.142537978387648

Epoch: 5| Step: 7
Training loss: 1.8948885202407837
Validation loss: 2.136920254717591

Epoch: 5| Step: 8
Training loss: 2.2335011959075928
Validation loss: 2.132835429201844

Epoch: 5| Step: 9
Training loss: 2.6467385292053223
Validation loss: 2.1281713003753335

Epoch: 5| Step: 10
Training loss: 2.684786081314087
Validation loss: 2.1178639832363335

Epoch: 132| Step: 0
Training loss: 2.4767775535583496
Validation loss: 2.122347552289245

Epoch: 5| Step: 1
Training loss: 2.372572422027588
Validation loss: 2.137496804678312

Epoch: 5| Step: 2
Training loss: 2.840003490447998
Validation loss: 2.123455544953705

Epoch: 5| Step: 3
Training loss: 2.1060478687286377
Validation loss: 2.1215868457671134

Epoch: 5| Step: 4
Training loss: 2.295095205307007
Validation loss: 2.116127457669986

Epoch: 5| Step: 5
Training loss: 2.26434326171875
Validation loss: 2.114339035044434

Epoch: 5| Step: 6
Training loss: 2.3497962951660156
Validation loss: 2.11392145387588

Epoch: 5| Step: 7
Training loss: 2.8306238651275635
Validation loss: 2.112550071490708

Epoch: 5| Step: 8
Training loss: 2.4065232276916504
Validation loss: 2.1062928681732505

Epoch: 5| Step: 9
Training loss: 2.058345317840576
Validation loss: 2.1041748241711686

Epoch: 5| Step: 10
Training loss: 2.0333924293518066
Validation loss: 2.111481415328159

Epoch: 133| Step: 0
Training loss: 3.0496253967285156
Validation loss: 2.123017039350284

Epoch: 5| Step: 1
Training loss: 2.6745541095733643
Validation loss: 2.1367582736476773

Epoch: 5| Step: 2
Training loss: 1.9399821758270264
Validation loss: 2.128762323369262

Epoch: 5| Step: 3
Training loss: 2.6082634925842285
Validation loss: 2.1320222603377474

Epoch: 5| Step: 4
Training loss: 1.5109975337982178
Validation loss: 2.118606335373335

Epoch: 5| Step: 5
Training loss: 1.8206393718719482
Validation loss: 2.109417846125941

Epoch: 5| Step: 6
Training loss: 2.8416998386383057
Validation loss: 2.1116830559187036

Epoch: 5| Step: 7
Training loss: 2.860973358154297
Validation loss: 2.112669619180823

Epoch: 5| Step: 8
Training loss: 2.2869086265563965
Validation loss: 2.1080148194425847

Epoch: 5| Step: 9
Training loss: 2.0687451362609863
Validation loss: 2.1199874877929688

Epoch: 5| Step: 10
Training loss: 2.48150634765625
Validation loss: 2.1050401374857914

Epoch: 134| Step: 0
Training loss: 2.5793304443359375
Validation loss: 2.1134357990757113

Epoch: 5| Step: 1
Training loss: 2.1470401287078857
Validation loss: 2.115517557308238

Epoch: 5| Step: 2
Training loss: 2.478645086288452
Validation loss: 2.1306311981652373

Epoch: 5| Step: 3
Training loss: 2.0787670612335205
Validation loss: 2.1503943192061556

Epoch: 5| Step: 4
Training loss: 2.2137317657470703
Validation loss: 2.1618798471266225

Epoch: 5| Step: 5
Training loss: 2.8510804176330566
Validation loss: 2.156137909940494

Epoch: 5| Step: 6
Training loss: 2.8296618461608887
Validation loss: 2.138569797238996

Epoch: 5| Step: 7
Training loss: 2.565380573272705
Validation loss: 2.1171974571802283

Epoch: 5| Step: 8
Training loss: 2.4884250164031982
Validation loss: 2.108175818638135

Epoch: 5| Step: 9
Training loss: 1.9862430095672607
Validation loss: 2.1167247167197605

Epoch: 5| Step: 10
Training loss: 1.9073898792266846
Validation loss: 2.115559783033145

Epoch: 135| Step: 0
Training loss: 2.1824593544006348
Validation loss: 2.1140922577150407

Epoch: 5| Step: 1
Training loss: 2.012377977371216
Validation loss: 2.11133671832341

Epoch: 5| Step: 2
Training loss: 2.3466956615448
Validation loss: 2.114439795094152

Epoch: 5| Step: 3
Training loss: 2.730241537094116
Validation loss: 2.1451478081364788

Epoch: 5| Step: 4
Training loss: 2.6554324626922607
Validation loss: 2.1782864960291053

Epoch: 5| Step: 5
Training loss: 2.1489837169647217
Validation loss: 2.210664241544662

Epoch: 5| Step: 6
Training loss: 2.1277966499328613
Validation loss: 2.2102786648658013

Epoch: 5| Step: 7
Training loss: 2.9418487548828125
Validation loss: 2.160351635307394

Epoch: 5| Step: 8
Training loss: 1.8507614135742188
Validation loss: 2.136908867025888

Epoch: 5| Step: 9
Training loss: 2.357933759689331
Validation loss: 2.1300132018263622

Epoch: 5| Step: 10
Training loss: 2.9174585342407227
Validation loss: 2.120864229817544

Epoch: 136| Step: 0
Training loss: 2.4634017944335938
Validation loss: 2.1139229446329098

Epoch: 5| Step: 1
Training loss: 2.487361192703247
Validation loss: 2.119196540565901

Epoch: 5| Step: 2
Training loss: 2.0804576873779297
Validation loss: 2.119536917696717

Epoch: 5| Step: 3
Training loss: 2.2449817657470703
Validation loss: 2.113980371464965

Epoch: 5| Step: 4
Training loss: 2.2026357650756836
Validation loss: 2.101648364015805

Epoch: 5| Step: 5
Training loss: 2.4826576709747314
Validation loss: 2.0934988234632756

Epoch: 5| Step: 6
Training loss: 2.8523547649383545
Validation loss: 2.0992816878903295

Epoch: 5| Step: 7
Training loss: 2.284590005874634
Validation loss: 2.1256722122110348

Epoch: 5| Step: 8
Training loss: 3.025183916091919
Validation loss: 2.1345011777775262

Epoch: 5| Step: 9
Training loss: 2.0835063457489014
Validation loss: 2.1380791459032285

Epoch: 5| Step: 10
Training loss: 1.8102447986602783
Validation loss: 2.1259444939192904

Epoch: 137| Step: 0
Training loss: 2.6862432956695557
Validation loss: 2.087101382593955

Epoch: 5| Step: 1
Training loss: 1.6787054538726807
Validation loss: 2.0871202125344226

Epoch: 5| Step: 2
Training loss: 2.772495985031128
Validation loss: 2.095476991386824

Epoch: 5| Step: 3
Training loss: 2.406285285949707
Validation loss: 2.0879549005980134

Epoch: 5| Step: 4
Training loss: 2.9018616676330566
Validation loss: 2.0895714067643687

Epoch: 5| Step: 5
Training loss: 1.6234241724014282
Validation loss: 2.088167421279415

Epoch: 5| Step: 6
Training loss: 2.0140843391418457
Validation loss: 2.0886401540489605

Epoch: 5| Step: 7
Training loss: 2.4574060440063477
Validation loss: 2.1111525566347185

Epoch: 5| Step: 8
Training loss: 2.559084415435791
Validation loss: 2.1363781652142926

Epoch: 5| Step: 9
Training loss: 2.270026683807373
Validation loss: 2.1765413207392537

Epoch: 5| Step: 10
Training loss: 2.8071672916412354
Validation loss: 2.157021414849066

Epoch: 138| Step: 0
Training loss: 1.659213662147522
Validation loss: 2.145218223653814

Epoch: 5| Step: 1
Training loss: 2.3347818851470947
Validation loss: 2.102502296047826

Epoch: 5| Step: 2
Training loss: 1.9592615365982056
Validation loss: 2.107721536390243

Epoch: 5| Step: 3
Training loss: 2.1064677238464355
Validation loss: 2.108871083105764

Epoch: 5| Step: 4
Training loss: 2.346407413482666
Validation loss: 2.0964829575630928

Epoch: 5| Step: 5
Training loss: 2.5988924503326416
Validation loss: 2.115050110765683

Epoch: 5| Step: 6
Training loss: 2.27323055267334
Validation loss: 2.1080943948479107

Epoch: 5| Step: 7
Training loss: 2.417534351348877
Validation loss: 2.1081823918127243

Epoch: 5| Step: 8
Training loss: 2.8806142807006836
Validation loss: 2.1049353461111746

Epoch: 5| Step: 9
Training loss: 2.895481586456299
Validation loss: 2.09994069222481

Epoch: 5| Step: 10
Training loss: 2.472208261489868
Validation loss: 2.1081523972172893

Epoch: 139| Step: 0
Training loss: 2.4626567363739014
Validation loss: 2.114686396814162

Epoch: 5| Step: 1
Training loss: 2.467453718185425
Validation loss: 2.116383825578997

Epoch: 5| Step: 2
Training loss: 1.7142661809921265
Validation loss: 2.108506477007302

Epoch: 5| Step: 3
Training loss: 1.9136348962783813
Validation loss: 2.0988181662815872

Epoch: 5| Step: 4
Training loss: 2.00441312789917
Validation loss: 2.096189098973428

Epoch: 5| Step: 5
Training loss: 2.2157273292541504
Validation loss: 2.104139071638866

Epoch: 5| Step: 6
Training loss: 2.3756637573242188
Validation loss: 2.1154866180112286

Epoch: 5| Step: 7
Training loss: 3.3140869140625
Validation loss: 2.12666836092549

Epoch: 5| Step: 8
Training loss: 2.54282283782959
Validation loss: 2.1168076658761628

Epoch: 5| Step: 9
Training loss: 2.231330394744873
Validation loss: 2.1076373028498825

Epoch: 5| Step: 10
Training loss: 2.55753755569458
Validation loss: 2.111350938838015

Epoch: 140| Step: 0
Training loss: 2.2697136402130127
Validation loss: 2.1037682922937537

Epoch: 5| Step: 1
Training loss: 1.93851637840271
Validation loss: 2.1101218218444497

Epoch: 5| Step: 2
Training loss: 2.510213613510132
Validation loss: 2.1097708312414025

Epoch: 5| Step: 3
Training loss: 2.7992968559265137
Validation loss: 2.1126467656063777

Epoch: 5| Step: 4
Training loss: 2.705791711807251
Validation loss: 2.1134936091720418

Epoch: 5| Step: 5
Training loss: 2.134427547454834
Validation loss: 2.11632719860282

Epoch: 5| Step: 6
Training loss: 1.8640811443328857
Validation loss: 2.1077353544132684

Epoch: 5| Step: 7
Training loss: 2.3622403144836426
Validation loss: 2.123206202701856

Epoch: 5| Step: 8
Training loss: 2.5727391242980957
Validation loss: 2.1358843465005197

Epoch: 5| Step: 9
Training loss: 2.117418050765991
Validation loss: 2.1507142128482943

Epoch: 5| Step: 10
Training loss: 2.456454277038574
Validation loss: 2.146149109768611

Epoch: 141| Step: 0
Training loss: 2.4756836891174316
Validation loss: 2.147551599369254

Epoch: 5| Step: 1
Training loss: 2.5127997398376465
Validation loss: 2.1443927749510734

Epoch: 5| Step: 2
Training loss: 2.0545098781585693
Validation loss: 2.1415502461053992

Epoch: 5| Step: 3
Training loss: 1.8779497146606445
Validation loss: 2.118011797628095

Epoch: 5| Step: 4
Training loss: 2.5537450313568115
Validation loss: 2.1142374700115574

Epoch: 5| Step: 5
Training loss: 2.1538326740264893
Validation loss: 2.096805203345514

Epoch: 5| Step: 6
Training loss: 2.1773147583007812
Validation loss: 2.1000023580366567

Epoch: 5| Step: 7
Training loss: 2.2635817527770996
Validation loss: 2.0924724148165796

Epoch: 5| Step: 8
Training loss: 2.7687439918518066
Validation loss: 2.089244040109778

Epoch: 5| Step: 9
Training loss: 1.9894592761993408
Validation loss: 2.085646624206215

Epoch: 5| Step: 10
Training loss: 2.9499270915985107
Validation loss: 2.087917791899814

Epoch: 142| Step: 0
Training loss: 2.1105246543884277
Validation loss: 2.1013701654249624

Epoch: 5| Step: 1
Training loss: 2.3551526069641113
Validation loss: 2.097462284949518

Epoch: 5| Step: 2
Training loss: 1.9859377145767212
Validation loss: 2.0917967852725776

Epoch: 5| Step: 3
Training loss: 2.806766986846924
Validation loss: 2.1121369254204536

Epoch: 5| Step: 4
Training loss: 2.1985745429992676
Validation loss: 2.1218064626057944

Epoch: 5| Step: 5
Training loss: 2.159388303756714
Validation loss: 2.1186533410062074

Epoch: 5| Step: 6
Training loss: 2.88625431060791
Validation loss: 2.109764637485627

Epoch: 5| Step: 7
Training loss: 2.3540098667144775
Validation loss: 2.0973268593511274

Epoch: 5| Step: 8
Training loss: 1.9479557275772095
Validation loss: 2.0925281611821984

Epoch: 5| Step: 9
Training loss: 2.2472758293151855
Validation loss: 2.0984641377643873

Epoch: 5| Step: 10
Training loss: 2.3271756172180176
Validation loss: 2.113935511599305

Epoch: 143| Step: 0
Training loss: 1.9698537588119507
Validation loss: 2.112272377937071

Epoch: 5| Step: 1
Training loss: 1.695775032043457
Validation loss: 2.1104128668385167

Epoch: 5| Step: 2
Training loss: 2.6382975578308105
Validation loss: 2.1091082506282355

Epoch: 5| Step: 3
Training loss: 2.519561767578125
Validation loss: 2.120928722043191

Epoch: 5| Step: 4
Training loss: 1.9626314640045166
Validation loss: 2.138742326408304

Epoch: 5| Step: 5
Training loss: 2.3823413848876953
Validation loss: 2.163568922268447

Epoch: 5| Step: 6
Training loss: 2.8204121589660645
Validation loss: 2.1889007745250577

Epoch: 5| Step: 7
Training loss: 2.8274688720703125
Validation loss: 2.1913693361384894

Epoch: 5| Step: 8
Training loss: 3.049639940261841
Validation loss: 2.1693834822664977

Epoch: 5| Step: 9
Training loss: 1.9161958694458008
Validation loss: 2.110366403415639

Epoch: 5| Step: 10
Training loss: 2.0168254375457764
Validation loss: 2.1084698912917927

Epoch: 144| Step: 0
Training loss: 2.7142558097839355
Validation loss: 2.116334274250974

Epoch: 5| Step: 1
Training loss: 2.650383949279785
Validation loss: 2.1328290970094743

Epoch: 5| Step: 2
Training loss: 2.298676013946533
Validation loss: 2.1231883956540014

Epoch: 5| Step: 3
Training loss: 2.2412052154541016
Validation loss: 2.1162741517507904

Epoch: 5| Step: 4
Training loss: 2.4528253078460693
Validation loss: 2.0964072699187906

Epoch: 5| Step: 5
Training loss: 2.415480852127075
Validation loss: 2.0887709266395977

Epoch: 5| Step: 6
Training loss: 2.0457167625427246
Validation loss: 2.0743680282305648

Epoch: 5| Step: 7
Training loss: 2.0176470279693604
Validation loss: 2.0624011434534544

Epoch: 5| Step: 8
Training loss: 2.250702381134033
Validation loss: 2.07883987375485

Epoch: 5| Step: 9
Training loss: 2.402514696121216
Validation loss: 2.081083054183632

Epoch: 5| Step: 10
Training loss: 2.298081398010254
Validation loss: 2.0839324946044595

Epoch: 145| Step: 0
Training loss: 2.128657579421997
Validation loss: 2.0788599214246197

Epoch: 5| Step: 1
Training loss: 2.091826915740967
Validation loss: 2.0707052574362805

Epoch: 5| Step: 2
Training loss: 2.4009623527526855
Validation loss: 2.0670835330922115

Epoch: 5| Step: 3
Training loss: 2.544349431991577
Validation loss: 2.070193027937284

Epoch: 5| Step: 4
Training loss: 2.4571590423583984
Validation loss: 2.0622644732075353

Epoch: 5| Step: 5
Training loss: 1.973801851272583
Validation loss: 2.065757946301532

Epoch: 5| Step: 6
Training loss: 1.7252557277679443
Validation loss: 2.0634716146735737

Epoch: 5| Step: 7
Training loss: 2.816678524017334
Validation loss: 2.068270285924276

Epoch: 5| Step: 8
Training loss: 2.4727725982666016
Validation loss: 2.0672399664437897

Epoch: 5| Step: 9
Training loss: 2.583160161972046
Validation loss: 2.069250593903244

Epoch: 5| Step: 10
Training loss: 2.279867649078369
Validation loss: 2.0591863022055676

Epoch: 146| Step: 0
Training loss: 2.6072089672088623
Validation loss: 2.0602860848108926

Epoch: 5| Step: 1
Training loss: 1.9761031866073608
Validation loss: 2.0638745036176456

Epoch: 5| Step: 2
Training loss: 2.2954633235931396
Validation loss: 2.0598965024435394

Epoch: 5| Step: 3
Training loss: 2.0602269172668457
Validation loss: 2.0522481408170474

Epoch: 5| Step: 4
Training loss: 2.891043186187744
Validation loss: 2.0534925973543556

Epoch: 5| Step: 5
Training loss: 2.05790376663208
Validation loss: 2.055311979786042

Epoch: 5| Step: 6
Training loss: 2.1583495140075684
Validation loss: 2.063095126100766

Epoch: 5| Step: 7
Training loss: 1.807763695716858
Validation loss: 2.065664246518125

Epoch: 5| Step: 8
Training loss: 2.8021934032440186
Validation loss: 2.0828816531806864

Epoch: 5| Step: 9
Training loss: 2.0025954246520996
Validation loss: 2.09993568799829

Epoch: 5| Step: 10
Training loss: 2.7976601123809814
Validation loss: 2.1043406660838793

Epoch: 147| Step: 0
Training loss: 2.085563898086548
Validation loss: 2.075109625375399

Epoch: 5| Step: 1
Training loss: 1.5126314163208008
Validation loss: 2.059280621108188

Epoch: 5| Step: 2
Training loss: 2.6481685638427734
Validation loss: 2.069814351297194

Epoch: 5| Step: 3
Training loss: 2.5027477741241455
Validation loss: 2.078999291184128

Epoch: 5| Step: 4
Training loss: 2.625742197036743
Validation loss: 2.088091209370603

Epoch: 5| Step: 5
Training loss: 2.433708429336548
Validation loss: 2.081532698805614

Epoch: 5| Step: 6
Training loss: 2.113664388656616
Validation loss: 2.0800573697654148

Epoch: 5| Step: 7
Training loss: 2.3569040298461914
Validation loss: 2.0816839702667727

Epoch: 5| Step: 8
Training loss: 2.6241068840026855
Validation loss: 2.104870391148393

Epoch: 5| Step: 9
Training loss: 1.7110958099365234
Validation loss: 2.105628623757311

Epoch: 5| Step: 10
Training loss: 2.8846750259399414
Validation loss: 2.121577678188201

Epoch: 148| Step: 0
Training loss: 1.7784544229507446
Validation loss: 2.135580348712142

Epoch: 5| Step: 1
Training loss: 2.693605899810791
Validation loss: 2.133408264447284

Epoch: 5| Step: 2
Training loss: 2.3925094604492188
Validation loss: 2.1450919810161797

Epoch: 5| Step: 3
Training loss: 2.4602763652801514
Validation loss: 2.1594055878218783

Epoch: 5| Step: 4
Training loss: 2.820901393890381
Validation loss: 2.1739751767086726

Epoch: 5| Step: 5
Training loss: 2.274547815322876
Validation loss: 2.1526595751444497

Epoch: 5| Step: 6
Training loss: 2.331303119659424
Validation loss: 2.133376788067561

Epoch: 5| Step: 7
Training loss: 3.1104001998901367
Validation loss: 2.1142357036631596

Epoch: 5| Step: 8
Training loss: 1.827223777770996
Validation loss: 2.093285024807017

Epoch: 5| Step: 9
Training loss: 1.7917327880859375
Validation loss: 2.087206466223604

Epoch: 5| Step: 10
Training loss: 2.122882843017578
Validation loss: 2.1050330208193873

Epoch: 149| Step: 0
Training loss: 2.527475595474243
Validation loss: 2.119096344517123

Epoch: 5| Step: 1
Training loss: 2.4303195476531982
Validation loss: 2.1151683394626906

Epoch: 5| Step: 2
Training loss: 1.9790337085723877
Validation loss: 2.0916625581761843

Epoch: 5| Step: 3
Training loss: 2.1196141242980957
Validation loss: 2.072020963955951

Epoch: 5| Step: 4
Training loss: 2.1169681549072266
Validation loss: 2.0677777592853834

Epoch: 5| Step: 5
Training loss: 2.3477513790130615
Validation loss: 2.0420866550937777

Epoch: 5| Step: 6
Training loss: 2.673853635787964
Validation loss: 2.049701844492266

Epoch: 5| Step: 7
Training loss: 1.7092292308807373
Validation loss: 2.0495197132069576

Epoch: 5| Step: 8
Training loss: 2.280649185180664
Validation loss: 2.051075852045449

Epoch: 5| Step: 9
Training loss: 2.601619005203247
Validation loss: 2.046805174120011

Epoch: 5| Step: 10
Training loss: 2.4171745777130127
Validation loss: 2.0422420142799296

Epoch: 150| Step: 0
Training loss: 2.359959602355957
Validation loss: 2.0440857436067317

Epoch: 5| Step: 1
Training loss: 1.7408931255340576
Validation loss: 2.050096329822335

Epoch: 5| Step: 2
Training loss: 2.7565925121307373
Validation loss: 2.0621635606212

Epoch: 5| Step: 3
Training loss: 2.2605221271514893
Validation loss: 2.057043798508183

Epoch: 5| Step: 4
Training loss: 3.023557186126709
Validation loss: 2.0552291408661874

Epoch: 5| Step: 5
Training loss: 1.7755680084228516
Validation loss: 2.0568294730237735

Epoch: 5| Step: 6
Training loss: 2.353057861328125
Validation loss: 2.047888712216449

Epoch: 5| Step: 7
Training loss: 2.1062703132629395
Validation loss: 2.0621584051398822

Epoch: 5| Step: 8
Training loss: 1.8937273025512695
Validation loss: 2.0523329409219886

Epoch: 5| Step: 9
Training loss: 2.442805051803589
Validation loss: 2.056638794560586

Epoch: 5| Step: 10
Training loss: 2.4018678665161133
Validation loss: 2.0626009997501167

Epoch: 151| Step: 0
Training loss: 3.049267053604126
Validation loss: 2.0631370570070002

Epoch: 5| Step: 1
Training loss: 2.6369221210479736
Validation loss: 2.0724435390964633

Epoch: 5| Step: 2
Training loss: 2.1212821006774902
Validation loss: 2.083383192298233

Epoch: 5| Step: 3
Training loss: 2.2614433765411377
Validation loss: 2.0920962466988513

Epoch: 5| Step: 4
Training loss: 2.2303054332733154
Validation loss: 2.102741393991696

Epoch: 5| Step: 5
Training loss: 1.6583316326141357
Validation loss: 2.0906050730777044

Epoch: 5| Step: 6
Training loss: 2.2669434547424316
Validation loss: 2.072084129497569

Epoch: 5| Step: 7
Training loss: 2.0428524017333984
Validation loss: 2.03529094624263

Epoch: 5| Step: 8
Training loss: 2.8434784412384033
Validation loss: 2.037050662502166

Epoch: 5| Step: 9
Training loss: 2.1570370197296143
Validation loss: 2.0554399003264723

Epoch: 5| Step: 10
Training loss: 1.892634630203247
Validation loss: 2.053609186603177

Epoch: 152| Step: 0
Training loss: 2.4804575443267822
Validation loss: 2.0610830694116573

Epoch: 5| Step: 1
Training loss: 1.9182682037353516
Validation loss: 2.062437429223009

Epoch: 5| Step: 2
Training loss: 2.2587618827819824
Validation loss: 2.0589662598025416

Epoch: 5| Step: 3
Training loss: 2.9432263374328613
Validation loss: 2.0783466164783766

Epoch: 5| Step: 4
Training loss: 1.7986373901367188
Validation loss: 2.114924453919934

Epoch: 5| Step: 5
Training loss: 1.8200823068618774
Validation loss: 2.1242416212635655

Epoch: 5| Step: 6
Training loss: 2.4071173667907715
Validation loss: 2.1201051435162945

Epoch: 5| Step: 7
Training loss: 2.1059956550598145
Validation loss: 2.1226157578088904

Epoch: 5| Step: 8
Training loss: 2.1642954349517822
Validation loss: 2.117584320806688

Epoch: 5| Step: 9
Training loss: 2.8782966136932373
Validation loss: 2.111063084294719

Epoch: 5| Step: 10
Training loss: 2.517622709274292
Validation loss: 2.09482600099297

Epoch: 153| Step: 0
Training loss: 2.0736165046691895
Validation loss: 2.073788350628268

Epoch: 5| Step: 1
Training loss: 2.4473447799682617
Validation loss: 2.0822715836186565

Epoch: 5| Step: 2
Training loss: 2.5947318077087402
Validation loss: 2.0691893716012277

Epoch: 5| Step: 3
Training loss: 2.664412021636963
Validation loss: 2.0679462058569795

Epoch: 5| Step: 4
Training loss: 2.4690937995910645
Validation loss: 2.055161472289793

Epoch: 5| Step: 5
Training loss: 1.9048700332641602
Validation loss: 2.04044722869832

Epoch: 5| Step: 6
Training loss: 1.9547008275985718
Validation loss: 2.0436659782163558

Epoch: 5| Step: 7
Training loss: 2.504669427871704
Validation loss: 2.0401424759177753

Epoch: 5| Step: 8
Training loss: 2.1780083179473877
Validation loss: 2.034181558957664

Epoch: 5| Step: 9
Training loss: 1.779941201210022
Validation loss: 2.0244611911876227

Epoch: 5| Step: 10
Training loss: 2.2965033054351807
Validation loss: 2.010594629472302

Epoch: 154| Step: 0
Training loss: 2.419698476791382
Validation loss: 2.0044582966835267

Epoch: 5| Step: 1
Training loss: 2.7214648723602295
Validation loss: 1.9941632132376395

Epoch: 5| Step: 2
Training loss: 2.6123485565185547
Validation loss: 2.003338511272143

Epoch: 5| Step: 3
Training loss: 2.0809719562530518
Validation loss: 2.0057920884060603

Epoch: 5| Step: 4
Training loss: 3.260648250579834
Validation loss: 1.9998507550967637

Epoch: 5| Step: 5
Training loss: 2.120314836502075
Validation loss: 2.007031281789144

Epoch: 5| Step: 6
Training loss: 2.43965482711792
Validation loss: 2.012285204343898

Epoch: 5| Step: 7
Training loss: 2.1206586360931396
Validation loss: 2.0160384678071543

Epoch: 5| Step: 8
Training loss: 1.7326513528823853
Validation loss: 2.0271153155193535

Epoch: 5| Step: 9
Training loss: 1.4919440746307373
Validation loss: 2.02485562909034

Epoch: 5| Step: 10
Training loss: 1.8225975036621094
Validation loss: 2.0175885231264177

Epoch: 155| Step: 0
Training loss: 2.109835147857666
Validation loss: 2.00038613939798

Epoch: 5| Step: 1
Training loss: 2.5274975299835205
Validation loss: 2.0027229119372625

Epoch: 5| Step: 2
Training loss: 2.403552770614624
Validation loss: 1.9943049043737433

Epoch: 5| Step: 3
Training loss: 2.3259594440460205
Validation loss: 1.993946765058784

Epoch: 5| Step: 4
Training loss: 2.6284217834472656
Validation loss: 2.010894395971811

Epoch: 5| Step: 5
Training loss: 2.236254930496216
Validation loss: 2.0083307732817945

Epoch: 5| Step: 6
Training loss: 2.2306745052337646
Validation loss: 2.0001862177284817

Epoch: 5| Step: 7
Training loss: 1.5168540477752686
Validation loss: 2.0061474884710004

Epoch: 5| Step: 8
Training loss: 2.193098545074463
Validation loss: 2.024193527877972

Epoch: 5| Step: 9
Training loss: 2.346820592880249
Validation loss: 2.063187578673004

Epoch: 5| Step: 10
Training loss: 2.2715282440185547
Validation loss: 2.0946820730804117

Epoch: 156| Step: 0
Training loss: 2.423828125
Validation loss: 2.098049299691313

Epoch: 5| Step: 1
Training loss: 2.0770888328552246
Validation loss: 2.084576137604252

Epoch: 5| Step: 2
Training loss: 2.4153995513916016
Validation loss: 2.0666412307370092

Epoch: 5| Step: 3
Training loss: 1.8603435754776
Validation loss: 2.0344428221384683

Epoch: 5| Step: 4
Training loss: 1.9689114093780518
Validation loss: 2.0229533026295323

Epoch: 5| Step: 5
Training loss: 2.573575258255005
Validation loss: 2.0403196106674852

Epoch: 5| Step: 6
Training loss: 2.692777156829834
Validation loss: 2.0348750532314344

Epoch: 5| Step: 7
Training loss: 2.2190170288085938
Validation loss: 2.0328074142497075

Epoch: 5| Step: 8
Training loss: 2.3505258560180664
Validation loss: 2.034567033090899

Epoch: 5| Step: 9
Training loss: 1.458315134048462
Validation loss: 2.033789698795606

Epoch: 5| Step: 10
Training loss: 2.9168951511383057
Validation loss: 2.0360820934336674

Epoch: 157| Step: 0
Training loss: 1.7166827917099
Validation loss: 2.0312489130163707

Epoch: 5| Step: 1
Training loss: 1.9623746871948242
Validation loss: 2.0371059281851656

Epoch: 5| Step: 2
Training loss: 3.1039233207702637
Validation loss: 2.0334087956336235

Epoch: 5| Step: 3
Training loss: 1.6486024856567383
Validation loss: 2.0324500632542435

Epoch: 5| Step: 4
Training loss: 2.4225821495056152
Validation loss: 2.0285399806114937

Epoch: 5| Step: 5
Training loss: 1.7594623565673828
Validation loss: 2.032595352459979

Epoch: 5| Step: 6
Training loss: 2.741976261138916
Validation loss: 2.047097644498271

Epoch: 5| Step: 7
Training loss: 2.2160284519195557
Validation loss: 2.0487210571124987

Epoch: 5| Step: 8
Training loss: 2.775550365447998
Validation loss: 2.0231706301371255

Epoch: 5| Step: 9
Training loss: 2.087982654571533
Validation loss: 2.0096146278483893

Epoch: 5| Step: 10
Training loss: 2.2683842182159424
Validation loss: 2.0076387518195697

Epoch: 158| Step: 0
Training loss: 2.6018104553222656
Validation loss: 2.0074022957073745

Epoch: 5| Step: 1
Training loss: 2.6561717987060547
Validation loss: 2.01174836004934

Epoch: 5| Step: 2
Training loss: 2.448516607284546
Validation loss: 2.0044427969122447

Epoch: 5| Step: 3
Training loss: 1.9149776697158813
Validation loss: 2.0177860900919926

Epoch: 5| Step: 4
Training loss: 1.7952792644500732
Validation loss: 2.0148678851383988

Epoch: 5| Step: 5
Training loss: 2.244602680206299
Validation loss: 2.016136648834393

Epoch: 5| Step: 6
Training loss: 1.9488433599472046
Validation loss: 2.023284307090185

Epoch: 5| Step: 7
Training loss: 2.206130027770996
Validation loss: 2.0392481921821513

Epoch: 5| Step: 8
Training loss: 2.2817654609680176
Validation loss: 2.061159154420258

Epoch: 5| Step: 9
Training loss: 2.3219618797302246
Validation loss: 2.089038165666724

Epoch: 5| Step: 10
Training loss: 2.4754440784454346
Validation loss: 2.112066295839125

Epoch: 159| Step: 0
Training loss: 2.5216822624206543
Validation loss: 2.0835547113931305

Epoch: 5| Step: 1
Training loss: 2.2376296520233154
Validation loss: 2.0633824973978023

Epoch: 5| Step: 2
Training loss: 1.8381414413452148
Validation loss: 2.057843226258473

Epoch: 5| Step: 3
Training loss: 1.5937260389328003
Validation loss: 2.0282477614700154

Epoch: 5| Step: 4
Training loss: 2.171239137649536
Validation loss: 2.027260172751642

Epoch: 5| Step: 5
Training loss: 2.1273999214172363
Validation loss: 2.0268452346965833

Epoch: 5| Step: 6
Training loss: 3.0558438301086426
Validation loss: 2.021596613750663

Epoch: 5| Step: 7
Training loss: 1.969744086265564
Validation loss: 2.0278198437024186

Epoch: 5| Step: 8
Training loss: 2.569837808609009
Validation loss: 2.0113224098759312

Epoch: 5| Step: 9
Training loss: 2.3119711875915527
Validation loss: 2.0050646874212448

Epoch: 5| Step: 10
Training loss: 2.1917037963867188
Validation loss: 2.0165968197648243

Epoch: 160| Step: 0
Training loss: 2.3399112224578857
Validation loss: 2.0117678360272477

Epoch: 5| Step: 1
Training loss: 2.2427096366882324
Validation loss: 2.022169837387659

Epoch: 5| Step: 2
Training loss: 2.351546287536621
Validation loss: 2.0202888096532514

Epoch: 5| Step: 3
Training loss: 2.11917781829834
Validation loss: 2.014564129614061

Epoch: 5| Step: 4
Training loss: 2.1160826683044434
Validation loss: 2.0235992400876937

Epoch: 5| Step: 5
Training loss: 2.2330448627471924
Validation loss: 2.022412048873081

Epoch: 5| Step: 6
Training loss: 1.734877586364746
Validation loss: 2.0280076060243832

Epoch: 5| Step: 7
Training loss: 2.1387104988098145
Validation loss: 2.0122728219596286

Epoch: 5| Step: 8
Training loss: 2.189570903778076
Validation loss: 2.015808928397394

Epoch: 5| Step: 9
Training loss: 2.178630828857422
Validation loss: 2.0141545828952583

Epoch: 5| Step: 10
Training loss: 2.797610282897949
Validation loss: 2.0198811126011673

Epoch: 161| Step: 0
Training loss: 2.26894211769104
Validation loss: 2.0154195421485492

Epoch: 5| Step: 1
Training loss: 1.6213514804840088
Validation loss: 2.027488548268554

Epoch: 5| Step: 2
Training loss: 2.362030029296875
Validation loss: 2.032635790045543

Epoch: 5| Step: 3
Training loss: 2.284480571746826
Validation loss: 2.017814343975436

Epoch: 5| Step: 4
Training loss: 2.3406882286071777
Validation loss: 2.0239624400292673

Epoch: 5| Step: 5
Training loss: 1.8783365488052368
Validation loss: 2.0254148514040056

Epoch: 5| Step: 6
Training loss: 2.491777181625366
Validation loss: 2.0505133059716996

Epoch: 5| Step: 7
Training loss: 2.6866698265075684
Validation loss: 2.0425583329252017

Epoch: 5| Step: 8
Training loss: 2.0640156269073486
Validation loss: 2.043084418901833

Epoch: 5| Step: 9
Training loss: 2.361999988555908
Validation loss: 2.0355261705254994

Epoch: 5| Step: 10
Training loss: 2.1124930381774902
Validation loss: 2.037945948621278

Epoch: 162| Step: 0
Training loss: 2.119683027267456
Validation loss: 2.0305374476217453

Epoch: 5| Step: 1
Training loss: 2.1281087398529053
Validation loss: 2.0366414234202397

Epoch: 5| Step: 2
Training loss: 2.4344167709350586
Validation loss: 2.0275428654045187

Epoch: 5| Step: 3
Training loss: 1.8447151184082031
Validation loss: 2.035506640711138

Epoch: 5| Step: 4
Training loss: 2.1690096855163574
Validation loss: 2.0345119660900486

Epoch: 5| Step: 5
Training loss: 1.4562392234802246
Validation loss: 2.0557534233216317

Epoch: 5| Step: 6
Training loss: 2.730620861053467
Validation loss: 2.049928762579477

Epoch: 5| Step: 7
Training loss: 2.419898271560669
Validation loss: 2.05124334878819

Epoch: 5| Step: 8
Training loss: 2.774451971054077
Validation loss: 2.0514246468902915

Epoch: 5| Step: 9
Training loss: 2.379256010055542
Validation loss: 2.0618771891440115

Epoch: 5| Step: 10
Training loss: 1.8749477863311768
Validation loss: 2.053084796474826

Epoch: 163| Step: 0
Training loss: 1.4983171224594116
Validation loss: 2.049234458195266

Epoch: 5| Step: 1
Training loss: 1.9648163318634033
Validation loss: 2.0448124139539656

Epoch: 5| Step: 2
Training loss: 2.1333839893341064
Validation loss: 2.024097196517452

Epoch: 5| Step: 3
Training loss: 2.377419948577881
Validation loss: 2.0197564273752193

Epoch: 5| Step: 4
Training loss: 2.92816162109375
Validation loss: 2.004461009015319

Epoch: 5| Step: 5
Training loss: 2.632140636444092
Validation loss: 2.003070506998288

Epoch: 5| Step: 6
Training loss: 1.8391964435577393
Validation loss: 2.000390878287695

Epoch: 5| Step: 7
Training loss: 1.9907134771347046
Validation loss: 1.9941782130989978

Epoch: 5| Step: 8
Training loss: 2.3250441551208496
Validation loss: 1.9825242129705285

Epoch: 5| Step: 9
Training loss: 2.215345859527588
Validation loss: 1.9820243030466058

Epoch: 5| Step: 10
Training loss: 2.558762788772583
Validation loss: 2.0052731857504895

Epoch: 164| Step: 0
Training loss: 2.493481159210205
Validation loss: 2.0215140311948714

Epoch: 5| Step: 1
Training loss: 2.426424264907837
Validation loss: 2.0333844051566174

Epoch: 5| Step: 2
Training loss: 2.115732192993164
Validation loss: 2.041981315100065

Epoch: 5| Step: 3
Training loss: 2.2083003520965576
Validation loss: 2.0340596193908365

Epoch: 5| Step: 4
Training loss: 2.846578598022461
Validation loss: 2.033410611973014

Epoch: 5| Step: 5
Training loss: 1.9723783731460571
Validation loss: 2.0299370442667315

Epoch: 5| Step: 6
Training loss: 2.4024014472961426
Validation loss: 2.0265902601262575

Epoch: 5| Step: 7
Training loss: 1.903144121170044
Validation loss: 2.0371852382536857

Epoch: 5| Step: 8
Training loss: 2.2592642307281494
Validation loss: 2.0319632522521482

Epoch: 5| Step: 9
Training loss: 1.865645408630371
Validation loss: 2.018810390144266

Epoch: 5| Step: 10
Training loss: 1.6087446212768555
Validation loss: 2.0201576422619563

Epoch: 165| Step: 0
Training loss: 2.04148530960083
Validation loss: 2.0442049580235637

Epoch: 5| Step: 1
Training loss: 2.1775412559509277
Validation loss: 2.0540717007011495

Epoch: 5| Step: 2
Training loss: 2.482339382171631
Validation loss: 2.062386517883629

Epoch: 5| Step: 3
Training loss: 1.925750970840454
Validation loss: 2.078682235492173

Epoch: 5| Step: 4
Training loss: 1.9469209909439087
Validation loss: 2.071133772532145

Epoch: 5| Step: 5
Training loss: 2.454500913619995
Validation loss: 2.0785953806292627

Epoch: 5| Step: 6
Training loss: 2.0315728187561035
Validation loss: 2.061560889726044

Epoch: 5| Step: 7
Training loss: 2.0387654304504395
Validation loss: 2.057224847937143

Epoch: 5| Step: 8
Training loss: 2.2353668212890625
Validation loss: 2.0514849885817497

Epoch: 5| Step: 9
Training loss: 2.5080747604370117
Validation loss: 2.0544709313300347

Epoch: 5| Step: 10
Training loss: 2.461699962615967
Validation loss: 2.0420744290915867

Epoch: 166| Step: 0
Training loss: 2.0597636699676514
Validation loss: 2.027828493425923

Epoch: 5| Step: 1
Training loss: 2.233421564102173
Validation loss: 2.018467982610067

Epoch: 5| Step: 2
Training loss: 2.471898317337036
Validation loss: 2.0083714915860083

Epoch: 5| Step: 3
Training loss: 2.5809950828552246
Validation loss: 2.0390689808835267

Epoch: 5| Step: 4
Training loss: 2.034843683242798
Validation loss: 2.010170257219704

Epoch: 5| Step: 5
Training loss: 2.2835545539855957
Validation loss: 1.9848522473407049

Epoch: 5| Step: 6
Training loss: 1.984047293663025
Validation loss: 1.9730527785516554

Epoch: 5| Step: 7
Training loss: 2.188943386077881
Validation loss: 1.97744644072748

Epoch: 5| Step: 8
Training loss: 2.2279322147369385
Validation loss: 1.9793263737873366

Epoch: 5| Step: 9
Training loss: 2.182436466217041
Validation loss: 1.9739361898873442

Epoch: 5| Step: 10
Training loss: 2.051046848297119
Validation loss: 1.9808366708858038

Epoch: 167| Step: 0
Training loss: 2.1812288761138916
Validation loss: 1.9740822635671145

Epoch: 5| Step: 1
Training loss: 2.032100200653076
Validation loss: 1.9818843077587824

Epoch: 5| Step: 2
Training loss: 1.9735008478164673
Validation loss: 1.9923161563052927

Epoch: 5| Step: 3
Training loss: 2.383105754852295
Validation loss: 2.0050477661112303

Epoch: 5| Step: 4
Training loss: 1.549682378768921
Validation loss: 2.0379510207842757

Epoch: 5| Step: 5
Training loss: 2.448516845703125
Validation loss: 2.0641115685944915

Epoch: 5| Step: 6
Training loss: 2.804293155670166
Validation loss: 2.071146244643837

Epoch: 5| Step: 7
Training loss: 2.135176181793213
Validation loss: 2.0639728179541965

Epoch: 5| Step: 8
Training loss: 1.7075645923614502
Validation loss: 2.0624669469812864

Epoch: 5| Step: 9
Training loss: 2.5441949367523193
Validation loss: 2.0616775084567327

Epoch: 5| Step: 10
Training loss: 2.4355249404907227
Validation loss: 2.0658737126217095

Epoch: 168| Step: 0
Training loss: 2.2686679363250732
Validation loss: 2.0910148966696953

Epoch: 5| Step: 1
Training loss: 1.9679988622665405
Validation loss: 2.1229003321739937

Epoch: 5| Step: 2
Training loss: 2.3358235359191895
Validation loss: 2.120941590237361

Epoch: 5| Step: 3
Training loss: 2.520009756088257
Validation loss: 2.1147048498994563

Epoch: 5| Step: 4
Training loss: 2.1706457138061523
Validation loss: 2.1030273181135937

Epoch: 5| Step: 5
Training loss: 1.9317651987075806
Validation loss: 2.073491829697804

Epoch: 5| Step: 6
Training loss: 2.2453017234802246
Validation loss: 2.0581668166704077

Epoch: 5| Step: 7
Training loss: 1.9327971935272217
Validation loss: 2.054593822007538

Epoch: 5| Step: 8
Training loss: 3.0321104526519775
Validation loss: 2.0415649542244534

Epoch: 5| Step: 9
Training loss: 2.1860554218292236
Validation loss: 2.0355804709978003

Epoch: 5| Step: 10
Training loss: 1.4954473972320557
Validation loss: 2.044601217392952

Epoch: 169| Step: 0
Training loss: 2.197885751724243
Validation loss: 2.036897856702087

Epoch: 5| Step: 1
Training loss: 2.5431034564971924
Validation loss: 2.0418790386569117

Epoch: 5| Step: 2
Training loss: 2.4902801513671875
Validation loss: 2.054278290399941

Epoch: 5| Step: 3
Training loss: 1.9124263525009155
Validation loss: 2.062855433392268

Epoch: 5| Step: 4
Training loss: 2.092986583709717
Validation loss: 2.0515953238292406

Epoch: 5| Step: 5
Training loss: 1.3877671957015991
Validation loss: 2.077995031110702

Epoch: 5| Step: 6
Training loss: 2.2228331565856934
Validation loss: 2.0737436022809757

Epoch: 5| Step: 7
Training loss: 2.2729332447052
Validation loss: 2.085222690336166

Epoch: 5| Step: 8
Training loss: 1.8288402557373047
Validation loss: 2.0922125129289526

Epoch: 5| Step: 9
Training loss: 2.5435733795166016
Validation loss: 2.077221474339885

Epoch: 5| Step: 10
Training loss: 2.3173370361328125
Validation loss: 2.0864454341191117

Epoch: 170| Step: 0
Training loss: 2.106106758117676
Validation loss: 2.0682979873431626

Epoch: 5| Step: 1
Training loss: 2.1933434009552
Validation loss: 2.051392416800222

Epoch: 5| Step: 2
Training loss: 2.6588568687438965
Validation loss: 2.038860765836572

Epoch: 5| Step: 3
Training loss: 1.9378502368927002
Validation loss: 2.0354884875717985

Epoch: 5| Step: 4
Training loss: 1.7666361331939697
Validation loss: 2.0244551679139495

Epoch: 5| Step: 5
Training loss: 1.751565933227539
Validation loss: 2.012323269280054

Epoch: 5| Step: 6
Training loss: 2.2166526317596436
Validation loss: 2.027499980823968

Epoch: 5| Step: 7
Training loss: 2.5621724128723145
Validation loss: 2.027148033982964

Epoch: 5| Step: 8
Training loss: 2.0291666984558105
Validation loss: 2.030358649069263

Epoch: 5| Step: 9
Training loss: 2.105973482131958
Validation loss: 2.0121146991688716

Epoch: 5| Step: 10
Training loss: 2.3209853172302246
Validation loss: 2.0041833821163384

Epoch: 171| Step: 0
Training loss: 1.7756519317626953
Validation loss: 2.0226618884712138

Epoch: 5| Step: 1
Training loss: 2.3575198650360107
Validation loss: 2.018675820801848

Epoch: 5| Step: 2
Training loss: 1.7960669994354248
Validation loss: 2.023767602059149

Epoch: 5| Step: 3
Training loss: 2.106879472732544
Validation loss: 2.045188593608077

Epoch: 5| Step: 4
Training loss: 2.2794737815856934
Validation loss: 2.047451462796939

Epoch: 5| Step: 5
Training loss: 2.557630777359009
Validation loss: 2.063540276660714

Epoch: 5| Step: 6
Training loss: 2.070950984954834
Validation loss: 2.052549118636757

Epoch: 5| Step: 7
Training loss: 2.024693727493286
Validation loss: 2.058255913437054

Epoch: 5| Step: 8
Training loss: 2.4624953269958496
Validation loss: 2.0757782331077

Epoch: 5| Step: 9
Training loss: 2.696169376373291
Validation loss: 2.0605616390064196

Epoch: 5| Step: 10
Training loss: 1.7566879987716675
Validation loss: 2.0690633635367117

Epoch: 172| Step: 0
Training loss: 2.6286568641662598
Validation loss: 2.0655748433964227

Epoch: 5| Step: 1
Training loss: 1.6885236501693726
Validation loss: 2.018609372518396

Epoch: 5| Step: 2
Training loss: 2.324833393096924
Validation loss: 1.9939311396691106

Epoch: 5| Step: 3
Training loss: 2.0405356884002686
Validation loss: 1.988751406310707

Epoch: 5| Step: 4
Training loss: 2.1067490577697754
Validation loss: 1.9797303843241867

Epoch: 5| Step: 5
Training loss: 2.9587297439575195
Validation loss: 1.977138865378595

Epoch: 5| Step: 6
Training loss: 2.405136823654175
Validation loss: 1.980852368057415

Epoch: 5| Step: 7
Training loss: 2.157053232192993
Validation loss: 2.0072584370131135

Epoch: 5| Step: 8
Training loss: 1.3435271978378296
Validation loss: 2.0260915346043085

Epoch: 5| Step: 9
Training loss: 2.362941026687622
Validation loss: 2.038645818669309

Epoch: 5| Step: 10
Training loss: 1.7944234609603882
Validation loss: 2.0343332226558397

Epoch: 173| Step: 0
Training loss: 2.374492645263672
Validation loss: 2.0193199470479

Epoch: 5| Step: 1
Training loss: 1.7268425226211548
Validation loss: 2.0007196651991976

Epoch: 5| Step: 2
Training loss: 1.8471565246582031
Validation loss: 2.0137828511576497

Epoch: 5| Step: 3
Training loss: 1.5039299726486206
Validation loss: 2.0431656709281345

Epoch: 5| Step: 4
Training loss: 2.3178653717041016
Validation loss: 2.0388531864330335

Epoch: 5| Step: 5
Training loss: 2.241543769836426
Validation loss: 2.0191490342540126

Epoch: 5| Step: 6
Training loss: 2.670050621032715
Validation loss: 2.007685802316153

Epoch: 5| Step: 7
Training loss: 2.3784430027008057
Validation loss: 2.0313158368551605

Epoch: 5| Step: 8
Training loss: 1.8653218746185303
Validation loss: 2.0379045394159134

Epoch: 5| Step: 9
Training loss: 2.4722819328308105
Validation loss: 2.0596556022603023

Epoch: 5| Step: 10
Training loss: 2.381746292114258
Validation loss: 2.0691321306331183

Epoch: 174| Step: 0
Training loss: 2.1383121013641357
Validation loss: 2.085517306481638

Epoch: 5| Step: 1
Training loss: 2.4673385620117188
Validation loss: 2.089317954996581

Epoch: 5| Step: 2
Training loss: 2.3058598041534424
Validation loss: 2.0815735811828286

Epoch: 5| Step: 3
Training loss: 1.7097173929214478
Validation loss: 2.057693176372077

Epoch: 5| Step: 4
Training loss: 2.1558337211608887
Validation loss: 2.0603364744494037

Epoch: 5| Step: 5
Training loss: 2.387430191040039
Validation loss: 2.046367146635568

Epoch: 5| Step: 6
Training loss: 2.242211103439331
Validation loss: 2.0420499129961898

Epoch: 5| Step: 7
Training loss: 1.9681329727172852
Validation loss: 2.0392787879513157

Epoch: 5| Step: 8
Training loss: 1.8789228200912476
Validation loss: 2.030595132099685

Epoch: 5| Step: 9
Training loss: 1.9468828439712524
Validation loss: 2.0283346727330196

Epoch: 5| Step: 10
Training loss: 2.3678908348083496
Validation loss: 2.0382528048689648

Epoch: 175| Step: 0
Training loss: 1.3091850280761719
Validation loss: 2.0343008810474026

Epoch: 5| Step: 1
Training loss: 2.445512056350708
Validation loss: 2.0384609148066533

Epoch: 5| Step: 2
Training loss: 2.2474570274353027
Validation loss: 2.0392910459990143

Epoch: 5| Step: 3
Training loss: 2.1978774070739746
Validation loss: 2.037045499329926

Epoch: 5| Step: 4
Training loss: 2.146235942840576
Validation loss: 2.0232634852009435

Epoch: 5| Step: 5
Training loss: 2.393044948577881
Validation loss: 2.016951189246229

Epoch: 5| Step: 6
Training loss: 1.834829330444336
Validation loss: 2.0070148411617486

Epoch: 5| Step: 7
Training loss: 1.9738460779190063
Validation loss: 2.0087730730733564

Epoch: 5| Step: 8
Training loss: 2.219287157058716
Validation loss: 2.015238883674786

Epoch: 5| Step: 9
Training loss: 1.841793417930603
Validation loss: 2.009160039245441

Epoch: 5| Step: 10
Training loss: 2.79244065284729
Validation loss: 2.01817762467169

Epoch: 176| Step: 0
Training loss: 2.1857409477233887
Validation loss: 2.021143615886729

Epoch: 5| Step: 1
Training loss: 1.1767171621322632
Validation loss: 2.0051274273985173

Epoch: 5| Step: 2
Training loss: 1.9257049560546875
Validation loss: 2.0088898443406626

Epoch: 5| Step: 3
Training loss: 2.306988000869751
Validation loss: 2.0073646986356346

Epoch: 5| Step: 4
Training loss: 2.855368137359619
Validation loss: 2.007086899972731

Epoch: 5| Step: 5
Training loss: 1.8200095891952515
Validation loss: 2.017717440923055

Epoch: 5| Step: 6
Training loss: 1.8060353994369507
Validation loss: 2.020443767629644

Epoch: 5| Step: 7
Training loss: 2.5106875896453857
Validation loss: 2.0233534971872964

Epoch: 5| Step: 8
Training loss: 2.251103639602661
Validation loss: 2.035404448868126

Epoch: 5| Step: 9
Training loss: 2.5805811882019043
Validation loss: 2.0433972920140913

Epoch: 5| Step: 10
Training loss: 1.7718580961227417
Validation loss: 2.0451473241211264

Epoch: 177| Step: 0
Training loss: 2.3167836666107178
Validation loss: 2.037391501088296

Epoch: 5| Step: 1
Training loss: 1.9418487548828125
Validation loss: 2.02624362514865

Epoch: 5| Step: 2
Training loss: 1.441620945930481
Validation loss: 2.0174324333026843

Epoch: 5| Step: 3
Training loss: 2.3325133323669434
Validation loss: 2.0244089941824637

Epoch: 5| Step: 4
Training loss: 1.8943458795547485
Validation loss: 2.0214210633308656

Epoch: 5| Step: 5
Training loss: 2.835143566131592
Validation loss: 2.0183503961050384

Epoch: 5| Step: 6
Training loss: 2.2174649238586426
Validation loss: 2.02232386091704

Epoch: 5| Step: 7
Training loss: 1.558063268661499
Validation loss: 2.027158530809546

Epoch: 5| Step: 8
Training loss: 2.2226743698120117
Validation loss: 2.011926193391123

Epoch: 5| Step: 9
Training loss: 2.191511869430542
Validation loss: 2.0104470906719083

Epoch: 5| Step: 10
Training loss: 2.1492605209350586
Validation loss: 2.026348570341705

Epoch: 178| Step: 0
Training loss: 2.868830919265747
Validation loss: 2.0376023938578944

Epoch: 5| Step: 1
Training loss: 2.0752651691436768
Validation loss: 2.03653218412912

Epoch: 5| Step: 2
Training loss: 2.200953960418701
Validation loss: 2.0233404585110244

Epoch: 5| Step: 3
Training loss: 1.9379627704620361
Validation loss: 2.0003377314536803

Epoch: 5| Step: 4
Training loss: 1.7936763763427734
Validation loss: 1.9960179457100489

Epoch: 5| Step: 5
Training loss: 2.3424153327941895
Validation loss: 2.0158138634056173

Epoch: 5| Step: 6
Training loss: 1.949119210243225
Validation loss: 2.040150470631097

Epoch: 5| Step: 7
Training loss: 1.6858612298965454
Validation loss: 2.062062135306738

Epoch: 5| Step: 8
Training loss: 2.3015689849853516
Validation loss: 2.0883562705850087

Epoch: 5| Step: 9
Training loss: 2.4456825256347656
Validation loss: 2.0723344920783915

Epoch: 5| Step: 10
Training loss: 1.9482933282852173
Validation loss: 2.0352036414607877

Epoch: 179| Step: 0
Training loss: 2.669501781463623
Validation loss: 2.0135905101735103

Epoch: 5| Step: 1
Training loss: 2.416512966156006
Validation loss: 2.046259358365049

Epoch: 5| Step: 2
Training loss: 1.6613891124725342
Validation loss: 2.0880238195901275

Epoch: 5| Step: 3
Training loss: 1.7723716497421265
Validation loss: 2.089847103241951

Epoch: 5| Step: 4
Training loss: 1.780321478843689
Validation loss: 2.0859505156035065

Epoch: 5| Step: 5
Training loss: 1.8750050067901611
Validation loss: 2.066698364032212

Epoch: 5| Step: 6
Training loss: 2.2535269260406494
Validation loss: 2.0471811063828005

Epoch: 5| Step: 7
Training loss: 2.105898380279541
Validation loss: 2.0697036379127094

Epoch: 5| Step: 8
Training loss: 2.0688602924346924
Validation loss: 2.085086173908685

Epoch: 5| Step: 9
Training loss: 2.363379955291748
Validation loss: 2.096831593462216

Epoch: 5| Step: 10
Training loss: 2.299593210220337
Validation loss: 2.0813389491009455

Epoch: 180| Step: 0
Training loss: 2.1404991149902344
Validation loss: 2.0571498819576797

Epoch: 5| Step: 1
Training loss: 2.2419273853302
Validation loss: 2.0341117561504407

Epoch: 5| Step: 2
Training loss: 2.043483018875122
Validation loss: 2.0152678182048183

Epoch: 5| Step: 3
Training loss: 1.7538931369781494
Validation loss: 1.9994394112658758

Epoch: 5| Step: 4
Training loss: 2.5426526069641113
Validation loss: 1.9937767162117908

Epoch: 5| Step: 5
Training loss: 1.6732372045516968
Validation loss: 2.022188432755009

Epoch: 5| Step: 6
Training loss: 1.8447837829589844
Validation loss: 2.074662108575144

Epoch: 5| Step: 7
Training loss: 1.9114797115325928
Validation loss: 2.0907013544472317

Epoch: 5| Step: 8
Training loss: 1.8798099756240845
Validation loss: 2.108767801715482

Epoch: 5| Step: 9
Training loss: 2.053372383117676
Validation loss: 2.104790928543255

Epoch: 5| Step: 10
Training loss: 3.1886677742004395
Validation loss: 2.1224444937962357

Epoch: 181| Step: 0
Training loss: 1.699652075767517
Validation loss: 2.0805231845507057

Epoch: 5| Step: 1
Training loss: 1.8641433715820312
Validation loss: 2.0372027440737654

Epoch: 5| Step: 2
Training loss: 2.551983594894409
Validation loss: 2.02814103839218

Epoch: 5| Step: 3
Training loss: 2.5651609897613525
Validation loss: 2.024697402472137

Epoch: 5| Step: 4
Training loss: 2.360496997833252
Validation loss: 2.032512472521874

Epoch: 5| Step: 5
Training loss: 1.8227431774139404
Validation loss: 2.0635589425281813

Epoch: 5| Step: 6
Training loss: 1.514364242553711
Validation loss: 2.032578754168685

Epoch: 5| Step: 7
Training loss: 2.0251071453094482
Validation loss: 2.0372846152192805

Epoch: 5| Step: 8
Training loss: 1.5178329944610596
Validation loss: 2.016152766443068

Epoch: 5| Step: 9
Training loss: 3.0291826725006104
Validation loss: 2.0293025368003437

Epoch: 5| Step: 10
Training loss: 1.7072330713272095
Validation loss: 2.0653833368773102

Epoch: 182| Step: 0
Training loss: 1.679993987083435
Validation loss: 2.0701887735756497

Epoch: 5| Step: 1
Training loss: 1.8030471801757812
Validation loss: 2.077412356612503

Epoch: 5| Step: 2
Training loss: 2.4217286109924316
Validation loss: 2.077176142764348

Epoch: 5| Step: 3
Training loss: 1.8583076000213623
Validation loss: 2.06093607923036

Epoch: 5| Step: 4
Training loss: 2.393158435821533
Validation loss: 2.0357768817614486

Epoch: 5| Step: 5
Training loss: 2.3071517944335938
Validation loss: 2.037783440723214

Epoch: 5| Step: 6
Training loss: 1.4079337120056152
Validation loss: 2.0383951138424616

Epoch: 5| Step: 7
Training loss: 2.620882034301758
Validation loss: 2.0465496522124096

Epoch: 5| Step: 8
Training loss: 1.9277031421661377
Validation loss: 2.0365696440460863

Epoch: 5| Step: 9
Training loss: 2.057446002960205
Validation loss: 2.0202210821131223

Epoch: 5| Step: 10
Training loss: 2.687614917755127
Validation loss: 2.0228869530462448

Epoch: 183| Step: 0
Training loss: 2.510695219039917
Validation loss: 2.0268002415216095

Epoch: 5| Step: 1
Training loss: 2.147477626800537
Validation loss: 2.028489675573123

Epoch: 5| Step: 2
Training loss: 1.788394570350647
Validation loss: 2.020704584736978

Epoch: 5| Step: 3
Training loss: 1.414096474647522
Validation loss: 2.014925046633649

Epoch: 5| Step: 4
Training loss: 2.1708052158355713
Validation loss: 1.997963979680051

Epoch: 5| Step: 5
Training loss: 2.195934295654297
Validation loss: 1.9845232412379274

Epoch: 5| Step: 6
Training loss: 1.9703495502471924
Validation loss: 2.0017314931397796

Epoch: 5| Step: 7
Training loss: 1.7303657531738281
Validation loss: 2.00546327201269

Epoch: 5| Step: 8
Training loss: 2.308114767074585
Validation loss: 2.002656804618015

Epoch: 5| Step: 9
Training loss: 2.067047595977783
Validation loss: 2.00778486651759

Epoch: 5| Step: 10
Training loss: 2.1901187896728516
Validation loss: 2.046355808934858

Epoch: 184| Step: 0
Training loss: 1.9876434803009033
Validation loss: 2.0581308359740884

Epoch: 5| Step: 1
Training loss: 1.5776193141937256
Validation loss: 2.080225190808696

Epoch: 5| Step: 2
Training loss: 2.4664008617401123
Validation loss: 2.1022185638386715

Epoch: 5| Step: 3
Training loss: 1.9225223064422607
Validation loss: 2.109105884387929

Epoch: 5| Step: 4
Training loss: 1.8526604175567627
Validation loss: 2.0832899078246085

Epoch: 5| Step: 5
Training loss: 2.2408485412597656
Validation loss: 2.076073169708252

Epoch: 5| Step: 6
Training loss: 2.080569267272949
Validation loss: 2.0782247269025413

Epoch: 5| Step: 7
Training loss: 2.609109878540039
Validation loss: 2.0820170679400043

Epoch: 5| Step: 8
Training loss: 1.8493611812591553
Validation loss: 2.063730514177712

Epoch: 5| Step: 9
Training loss: 2.0873847007751465
Validation loss: 2.063360183469711

Epoch: 5| Step: 10
Training loss: 1.7058916091918945
Validation loss: 2.056171927400815

Epoch: 185| Step: 0
Training loss: 2.0505878925323486
Validation loss: 2.0609367227041595

Epoch: 5| Step: 1
Training loss: 1.8460519313812256
Validation loss: 2.04692643304025

Epoch: 5| Step: 2
Training loss: 1.59268319606781
Validation loss: 2.031209937987789

Epoch: 5| Step: 3
Training loss: 1.3782148361206055
Validation loss: 2.036835039815595

Epoch: 5| Step: 4
Training loss: 2.42313814163208
Validation loss: 2.037942099314864

Epoch: 5| Step: 5
Training loss: 2.0843420028686523
Validation loss: 2.0501056012286933

Epoch: 5| Step: 6
Training loss: 1.8142387866973877
Validation loss: 2.032653030528817

Epoch: 5| Step: 7
Training loss: 2.6044557094573975
Validation loss: 2.013767842323549

Epoch: 5| Step: 8
Training loss: 2.0487446784973145
Validation loss: 2.016038474216256

Epoch: 5| Step: 9
Training loss: 1.9888856410980225
Validation loss: 2.004789008889147

Epoch: 5| Step: 10
Training loss: 2.162221908569336
Validation loss: 2.0044928109774025

Epoch: 186| Step: 0
Training loss: 1.692291259765625
Validation loss: 2.0175659528342624

Epoch: 5| Step: 1
Training loss: 1.7575581073760986
Validation loss: 2.009722925001575

Epoch: 5| Step: 2
Training loss: 1.9759536981582642
Validation loss: 2.026984860820155

Epoch: 5| Step: 3
Training loss: 2.2717795372009277
Validation loss: 2.013527645859667

Epoch: 5| Step: 4
Training loss: 1.4535918235778809
Validation loss: 2.024489325861777

Epoch: 5| Step: 5
Training loss: 1.9507849216461182
Validation loss: 2.028068047697826

Epoch: 5| Step: 6
Training loss: 1.9168388843536377
Validation loss: 2.0258006998287734

Epoch: 5| Step: 7
Training loss: 2.05302095413208
Validation loss: 2.038765463777768

Epoch: 5| Step: 8
Training loss: 1.6152923107147217
Validation loss: 2.032973550981091

Epoch: 5| Step: 9
Training loss: 2.4972755908966064
Validation loss: 2.046474870815072

Epoch: 5| Step: 10
Training loss: 2.435429096221924
Validation loss: 2.0512779143548783

Epoch: 187| Step: 0
Training loss: 2.2936463356018066
Validation loss: 2.0730985005696616

Epoch: 5| Step: 1
Training loss: 1.438359260559082
Validation loss: 2.0587198926556494

Epoch: 5| Step: 2
Training loss: 1.6038223505020142
Validation loss: 2.090033087679135

Epoch: 5| Step: 3
Training loss: 1.4858496189117432
Validation loss: 2.086760546571465

Epoch: 5| Step: 4
Training loss: 1.730543851852417
Validation loss: 2.0779000072069067

Epoch: 5| Step: 5
Training loss: 1.2874046564102173
Validation loss: 2.0442789652014293

Epoch: 5| Step: 6
Training loss: 2.038393497467041
Validation loss: 2.038649792312294

Epoch: 5| Step: 7
Training loss: 2.190413475036621
Validation loss: 2.033164992127367

Epoch: 5| Step: 8
Training loss: 2.737031936645508
Validation loss: 2.031462638608871

Epoch: 5| Step: 9
Training loss: 2.4446041584014893
Validation loss: 2.0331720254754506

Epoch: 5| Step: 10
Training loss: 2.4348514080047607
Validation loss: 2.029505702757066

Epoch: 188| Step: 0
Training loss: 2.172236680984497
Validation loss: 2.0190216751508814

Epoch: 5| Step: 1
Training loss: 1.9716570377349854
Validation loss: 1.9831931514124717

Epoch: 5| Step: 2
Training loss: 1.839059829711914
Validation loss: 1.963944653029083

Epoch: 5| Step: 3
Training loss: 1.1555604934692383
Validation loss: 1.9834695490457679

Epoch: 5| Step: 4
Training loss: 2.2831602096557617
Validation loss: 2.016214120772577

Epoch: 5| Step: 5
Training loss: 2.2956302165985107
Validation loss: 2.0484256654657345

Epoch: 5| Step: 6
Training loss: 2.459733247756958
Validation loss: 2.071254188014615

Epoch: 5| Step: 7
Training loss: 2.2699832916259766
Validation loss: 2.076831438208139

Epoch: 5| Step: 8
Training loss: 2.0348477363586426
Validation loss: 2.104528181014522

Epoch: 5| Step: 9
Training loss: 1.6193733215332031
Validation loss: 2.096789367737309

Epoch: 5| Step: 10
Training loss: 1.7722810506820679
Validation loss: 2.068488977288687

Epoch: 189| Step: 0
Training loss: 1.8721990585327148
Validation loss: 2.0411511441712737

Epoch: 5| Step: 1
Training loss: 1.854877233505249
Validation loss: 2.011731720739795

Epoch: 5| Step: 2
Training loss: 1.8521270751953125
Validation loss: 2.0033554992368146

Epoch: 5| Step: 3
Training loss: 2.0161004066467285
Validation loss: 1.9995276748493154

Epoch: 5| Step: 4
Training loss: 1.7567211389541626
Validation loss: 1.9878761947795909

Epoch: 5| Step: 5
Training loss: 2.670405864715576
Validation loss: 1.9627514769954066

Epoch: 5| Step: 6
Training loss: 2.0965142250061035
Validation loss: 1.9713820744586248

Epoch: 5| Step: 7
Training loss: 2.2327022552490234
Validation loss: 1.976487191774512

Epoch: 5| Step: 8
Training loss: 2.0711185932159424
Validation loss: 2.005213261932455

Epoch: 5| Step: 9
Training loss: 1.8633842468261719
Validation loss: 2.0214988300877232

Epoch: 5| Step: 10
Training loss: 1.461021900177002
Validation loss: 2.0392689653622207

Epoch: 190| Step: 0
Training loss: 1.4741535186767578
Validation loss: 2.053407458848851

Epoch: 5| Step: 1
Training loss: 2.097078323364258
Validation loss: 2.0577680680059616

Epoch: 5| Step: 2
Training loss: 1.3984647989273071
Validation loss: 2.050969135376715

Epoch: 5| Step: 3
Training loss: 1.7518537044525146
Validation loss: 2.0872834959337787

Epoch: 5| Step: 4
Training loss: 2.084012985229492
Validation loss: 2.104246752236479

Epoch: 5| Step: 5
Training loss: 2.1800990104675293
Validation loss: 2.1262171242826726

Epoch: 5| Step: 6
Training loss: 2.5754992961883545
Validation loss: 2.1359395519379647

Epoch: 5| Step: 7
Training loss: 1.7046544551849365
Validation loss: 2.147606962470598

Epoch: 5| Step: 8
Training loss: 1.9709405899047852
Validation loss: 2.1071586634523127

Epoch: 5| Step: 9
Training loss: 2.05299711227417
Validation loss: 2.117038260224045

Epoch: 5| Step: 10
Training loss: 2.2266716957092285
Validation loss: 2.0933014731253348

Epoch: 191| Step: 0
Training loss: 1.9468364715576172
Validation loss: 2.0818628059920443

Epoch: 5| Step: 1
Training loss: 1.8940231800079346
Validation loss: 2.0594046756785405

Epoch: 5| Step: 2
Training loss: 1.955609679222107
Validation loss: 2.0391434777167534

Epoch: 5| Step: 3
Training loss: 2.481870174407959
Validation loss: 2.034474256218121

Epoch: 5| Step: 4
Training loss: 1.9285297393798828
Validation loss: 2.0200009166553454

Epoch: 5| Step: 5
Training loss: 1.9659640789031982
Validation loss: 2.0023687629289526

Epoch: 5| Step: 6
Training loss: 1.4793206453323364
Validation loss: 1.996011277680756

Epoch: 5| Step: 7
Training loss: 1.9259560108184814
Validation loss: 1.9925325045021631

Epoch: 5| Step: 8
Training loss: 1.791053056716919
Validation loss: 1.9832075616364837

Epoch: 5| Step: 9
Training loss: 2.0189759731292725
Validation loss: 1.9902629083202732

Epoch: 5| Step: 10
Training loss: 1.7507829666137695
Validation loss: 1.989674351548636

Epoch: 192| Step: 0
Training loss: 2.1728262901306152
Validation loss: 2.002453391269971

Epoch: 5| Step: 1
Training loss: 1.8931224346160889
Validation loss: 2.021813525948473

Epoch: 5| Step: 2
Training loss: 1.6930519342422485
Validation loss: 2.0265281636227845

Epoch: 5| Step: 3
Training loss: 1.8164478540420532
Validation loss: 2.0356229633413334

Epoch: 5| Step: 4
Training loss: 1.795019507408142
Validation loss: 2.035763434184495

Epoch: 5| Step: 5
Training loss: 2.2467994689941406
Validation loss: 2.0359719850683726

Epoch: 5| Step: 6
Training loss: 1.4146867990493774
Validation loss: 2.035010655721029

Epoch: 5| Step: 7
Training loss: 2.055513858795166
Validation loss: 2.044187045866443

Epoch: 5| Step: 8
Training loss: 1.8688957691192627
Validation loss: 2.048673150359943

Epoch: 5| Step: 9
Training loss: 2.2290520668029785
Validation loss: 2.0753932127388577

Epoch: 5| Step: 10
Training loss: 1.8539190292358398
Validation loss: 2.054595470428467

Epoch: 193| Step: 0
Training loss: 1.7290111780166626
Validation loss: 2.0477365293810443

Epoch: 5| Step: 1
Training loss: 1.6891653537750244
Validation loss: 2.052806879884453

Epoch: 5| Step: 2
Training loss: 1.527419924736023
Validation loss: 2.067496435616606

Epoch: 5| Step: 3
Training loss: 2.3760929107666016
Validation loss: 2.0596313963654223

Epoch: 5| Step: 4
Training loss: 2.2421932220458984
Validation loss: 2.0582548802898777

Epoch: 5| Step: 5
Training loss: 1.5642421245574951
Validation loss: 2.044134404069634

Epoch: 5| Step: 6
Training loss: 1.8901573419570923
Validation loss: 2.042888487538984

Epoch: 5| Step: 7
Training loss: 2.104735851287842
Validation loss: 2.05739813850772

Epoch: 5| Step: 8
Training loss: 1.9873504638671875
Validation loss: 2.0599624802989345

Epoch: 5| Step: 9
Training loss: 2.0002124309539795
Validation loss: 2.072302419652221

Epoch: 5| Step: 10
Training loss: 1.7389761209487915
Validation loss: 2.070800919686594

Epoch: 194| Step: 0
Training loss: 1.5162643194198608
Validation loss: 2.025029989980882

Epoch: 5| Step: 1
Training loss: 1.7346630096435547
Validation loss: 1.9986216483577606

Epoch: 5| Step: 2
Training loss: 1.8536596298217773
Validation loss: 1.9979433718548025

Epoch: 5| Step: 3
Training loss: 2.4678592681884766
Validation loss: 1.995014831583987

Epoch: 5| Step: 4
Training loss: 1.68197500705719
Validation loss: 1.999837334438037

Epoch: 5| Step: 5
Training loss: 2.1086533069610596
Validation loss: 1.9747726558357157

Epoch: 5| Step: 6
Training loss: 2.500004291534424
Validation loss: 1.9700730616046536

Epoch: 5| Step: 7
Training loss: 1.7256981134414673
Validation loss: 1.9768824551695137

Epoch: 5| Step: 8
Training loss: 1.8844856023788452
Validation loss: 1.9814016024271648

Epoch: 5| Step: 9
Training loss: 1.619458794593811
Validation loss: 2.0239585163772746

Epoch: 5| Step: 10
Training loss: 1.7582906484603882
Validation loss: 2.0748501246975315

Epoch: 195| Step: 0
Training loss: 2.092442035675049
Validation loss: 2.08575407151253

Epoch: 5| Step: 1
Training loss: 2.4392454624176025
Validation loss: 2.103463731786256

Epoch: 5| Step: 2
Training loss: 1.7488845586776733
Validation loss: 2.0865586367986535

Epoch: 5| Step: 3
Training loss: 2.135148763656616
Validation loss: 2.098864015712533

Epoch: 5| Step: 4
Training loss: 2.263676166534424
Validation loss: 2.0806527855575725

Epoch: 5| Step: 5
Training loss: 1.6844279766082764
Validation loss: 2.079271178091726

Epoch: 5| Step: 6
Training loss: 1.430350661277771
Validation loss: 2.074318378202377

Epoch: 5| Step: 7
Training loss: 1.248049259185791
Validation loss: 2.0707833997664915

Epoch: 5| Step: 8
Training loss: 1.325831413269043
Validation loss: 2.068441947301229

Epoch: 5| Step: 9
Training loss: 2.4501473903656006
Validation loss: 2.059388683688256

Epoch: 5| Step: 10
Training loss: 1.9432287216186523
Validation loss: 2.046560702785369

Epoch: 196| Step: 0
Training loss: 1.9315738677978516
Validation loss: 2.0189186860156316

Epoch: 5| Step: 1
Training loss: 1.848311185836792
Validation loss: 2.0032886510254233

Epoch: 5| Step: 2
Training loss: 1.5245167016983032
Validation loss: 2.0014917453130088

Epoch: 5| Step: 3
Training loss: 1.5470597743988037
Validation loss: 2.0073068385483115

Epoch: 5| Step: 4
Training loss: 1.6674880981445312
Validation loss: 2.0222764899653773

Epoch: 5| Step: 5
Training loss: 2.1835215091705322
Validation loss: 2.067481476773498

Epoch: 5| Step: 6
Training loss: 2.026116371154785
Validation loss: 2.0761654710256927

Epoch: 5| Step: 7
Training loss: 2.035917282104492
Validation loss: 2.093647669720393

Epoch: 5| Step: 8
Training loss: 1.5739389657974243
Validation loss: 2.0777238799679663

Epoch: 5| Step: 9
Training loss: 2.0817973613739014
Validation loss: 2.0477383162385676

Epoch: 5| Step: 10
Training loss: 2.3096377849578857
Validation loss: 2.04329421699688

Epoch: 197| Step: 0
Training loss: 1.3317826986312866
Validation loss: 2.0400983543806177

Epoch: 5| Step: 1
Training loss: 1.9555366039276123
Validation loss: 2.00850119257486

Epoch: 5| Step: 2
Training loss: 1.7128841876983643
Validation loss: 1.9901006196134834

Epoch: 5| Step: 3
Training loss: 1.632043480873108
Validation loss: 1.9795511717437415

Epoch: 5| Step: 4
Training loss: 2.286681890487671
Validation loss: 2.008943880757978

Epoch: 5| Step: 5
Training loss: 1.8130626678466797
Validation loss: 2.0383600855386383

Epoch: 5| Step: 6
Training loss: 2.161320209503174
Validation loss: 2.0802922864114084

Epoch: 5| Step: 7
Training loss: 1.7242399454116821
Validation loss: 2.1081772453041485

Epoch: 5| Step: 8
Training loss: 2.185523271560669
Validation loss: 2.0840495196721887

Epoch: 5| Step: 9
Training loss: 2.172879695892334
Validation loss: 2.045607877034013

Epoch: 5| Step: 10
Training loss: 1.3920890092849731
Validation loss: 2.0412921149243592

Epoch: 198| Step: 0
Training loss: 1.5650142431259155
Validation loss: 2.054181760357272

Epoch: 5| Step: 1
Training loss: 1.639261245727539
Validation loss: 2.0721617308996056

Epoch: 5| Step: 2
Training loss: 1.9930347204208374
Validation loss: 2.063719108540525

Epoch: 5| Step: 3
Training loss: 2.2083277702331543
Validation loss: 2.051537508605629

Epoch: 5| Step: 4
Training loss: 1.832578420639038
Validation loss: 2.068701487715526

Epoch: 5| Step: 5
Training loss: 1.6788530349731445
Validation loss: 2.062827697364233

Epoch: 5| Step: 6
Training loss: 2.0754497051239014
Validation loss: 2.074539035879156

Epoch: 5| Step: 7
Training loss: 1.6607948541641235
Validation loss: 2.09359255144673

Epoch: 5| Step: 8
Training loss: 1.528652548789978
Validation loss: 2.076251550387311

Epoch: 5| Step: 9
Training loss: 2.2374112606048584
Validation loss: 2.0716698272253877

Epoch: 5| Step: 10
Training loss: 2.0065391063690186
Validation loss: 2.0569846425005185

Epoch: 199| Step: 0
Training loss: 1.5086586475372314
Validation loss: 2.0552875354725826

Epoch: 5| Step: 1
Training loss: 1.5503864288330078
Validation loss: 2.049163685050062

Epoch: 5| Step: 2
Training loss: 1.9173942804336548
Validation loss: 2.05765684189335

Epoch: 5| Step: 3
Training loss: 2.0104312896728516
Validation loss: 2.025467485509893

Epoch: 5| Step: 4
Training loss: 1.8866046667099
Validation loss: 2.01420561985303

Epoch: 5| Step: 5
Training loss: 2.02797532081604
Validation loss: 2.008404754823254

Epoch: 5| Step: 6
Training loss: 1.9367440938949585
Validation loss: 1.9971001558406378

Epoch: 5| Step: 7
Training loss: 2.055436611175537
Validation loss: 1.9992706391119188

Epoch: 5| Step: 8
Training loss: 1.6330492496490479
Validation loss: 2.007838956771358

Epoch: 5| Step: 9
Training loss: 1.9680750370025635
Validation loss: 2.018623726342314

Epoch: 5| Step: 10
Training loss: 1.3994969129562378
Validation loss: 2.0501439366289365

Epoch: 200| Step: 0
Training loss: 2.1995818614959717
Validation loss: 2.047688689283145

Epoch: 5| Step: 1
Training loss: 2.007429599761963
Validation loss: 2.0513916118170625

Epoch: 5| Step: 2
Training loss: 2.422398328781128
Validation loss: 2.0482557076279835

Epoch: 5| Step: 3
Training loss: 2.240957498550415
Validation loss: 2.0633781417723625

Epoch: 5| Step: 4
Training loss: 1.7444963455200195
Validation loss: 2.0845336862789687

Epoch: 5| Step: 5
Training loss: 1.4191973209381104
Validation loss: 2.0877419838341336

Epoch: 5| Step: 6
Training loss: 1.3803828954696655
Validation loss: 2.083600330096419

Epoch: 5| Step: 7
Training loss: 1.7012020349502563
Validation loss: 2.0750931693661596

Epoch: 5| Step: 8
Training loss: 1.3622779846191406
Validation loss: 2.071906235910231

Epoch: 5| Step: 9
Training loss: 1.5662829875946045
Validation loss: 2.0278071767540387

Epoch: 5| Step: 10
Training loss: 1.8589165210723877
Validation loss: 2.0094307571329098

Epoch: 201| Step: 0
Training loss: 2.06508731842041
Validation loss: 1.9969914523504113

Epoch: 5| Step: 1
Training loss: 1.5606803894042969
Validation loss: 1.9849734588335919

Epoch: 5| Step: 2
Training loss: 1.4457613229751587
Validation loss: 1.9692753412390267

Epoch: 5| Step: 3
Training loss: 2.206756114959717
Validation loss: 1.9806533769894672

Epoch: 5| Step: 4
Training loss: 1.7669016122817993
Validation loss: 1.9895507943245672

Epoch: 5| Step: 5
Training loss: 1.693402886390686
Validation loss: 2.03579955972651

Epoch: 5| Step: 6
Training loss: 1.865586519241333
Validation loss: 2.0519168799923313

Epoch: 5| Step: 7
Training loss: 1.4748166799545288
Validation loss: 2.065081609192715

Epoch: 5| Step: 8
Training loss: 2.330202579498291
Validation loss: 2.069632096957135

Epoch: 5| Step: 9
Training loss: 1.8336460590362549
Validation loss: 2.056234255913765

Epoch: 5| Step: 10
Training loss: 1.8093698024749756
Validation loss: 2.0733024510004188

Epoch: 202| Step: 0
Training loss: 1.510267972946167
Validation loss: 2.0794397989908853

Epoch: 5| Step: 1
Training loss: 1.8523931503295898
Validation loss: 2.0669880541422034

Epoch: 5| Step: 2
Training loss: 1.8392692804336548
Validation loss: 2.0421617313097884

Epoch: 5| Step: 3
Training loss: 1.995104193687439
Validation loss: 2.039563253361692

Epoch: 5| Step: 4
Training loss: 1.749765396118164
Validation loss: 2.0173360955330635

Epoch: 5| Step: 5
Training loss: 1.8184648752212524
Validation loss: 1.9939167935361144

Epoch: 5| Step: 6
Training loss: 1.4941985607147217
Validation loss: 1.9971789442082888

Epoch: 5| Step: 7
Training loss: 2.001077175140381
Validation loss: 2.028799295425415

Epoch: 5| Step: 8
Training loss: 2.0630130767822266
Validation loss: 2.0726199047539824

Epoch: 5| Step: 9
Training loss: 1.7545254230499268
Validation loss: 2.095725605564733

Epoch: 5| Step: 10
Training loss: 2.320873260498047
Validation loss: 2.0947898895509782

Epoch: 203| Step: 0
Training loss: 1.6171928644180298
Validation loss: 2.12848489258879

Epoch: 5| Step: 1
Training loss: 1.954628348350525
Validation loss: 2.1415848834540254

Epoch: 5| Step: 2
Training loss: 1.9488780498504639
Validation loss: 2.113932563412574

Epoch: 5| Step: 3
Training loss: 1.8769309520721436
Validation loss: 2.0865436702646236

Epoch: 5| Step: 4
Training loss: 1.4889477491378784
Validation loss: 2.069134336645885

Epoch: 5| Step: 5
Training loss: 1.8909797668457031
Validation loss: 2.079855493319932

Epoch: 5| Step: 6
Training loss: 1.843817114830017
Validation loss: 2.054363384041735

Epoch: 5| Step: 7
Training loss: 2.202347755432129
Validation loss: 2.0677827430027786

Epoch: 5| Step: 8
Training loss: 1.2006635665893555
Validation loss: 2.0509795860577653

Epoch: 5| Step: 9
Training loss: 2.136216640472412
Validation loss: 2.011719843392731

Epoch: 5| Step: 10
Training loss: 1.8291383981704712
Validation loss: 2.014434517070811

Epoch: 204| Step: 0
Training loss: 1.7176008224487305
Validation loss: 2.027797193937404

Epoch: 5| Step: 1
Training loss: 2.309053421020508
Validation loss: 2.0658539136250815

Epoch: 5| Step: 2
Training loss: 2.733509063720703
Validation loss: 2.0706761780605523

Epoch: 5| Step: 3
Training loss: 1.936865210533142
Validation loss: 2.052810944536681

Epoch: 5| Step: 4
Training loss: 1.4344241619110107
Validation loss: 2.051395471378039

Epoch: 5| Step: 5
Training loss: 1.6480659246444702
Validation loss: 2.0241473772192515

Epoch: 5| Step: 6
Training loss: 1.6371657848358154
Validation loss: 2.023740609486898

Epoch: 5| Step: 7
Training loss: 2.477781057357788
Validation loss: 2.0290174740616993

Epoch: 5| Step: 8
Training loss: 0.9471833109855652
Validation loss: 2.042781804197578

Epoch: 5| Step: 9
Training loss: 1.7735083103179932
Validation loss: 2.0593659570140224

Epoch: 5| Step: 10
Training loss: 1.282840609550476
Validation loss: 2.0515188504290838

Epoch: 205| Step: 0
Training loss: 2.2613534927368164
Validation loss: 2.0653042883001347

Epoch: 5| Step: 1
Training loss: 2.072962999343872
Validation loss: 2.059117101853894

Epoch: 5| Step: 2
Training loss: 1.481731653213501
Validation loss: 2.0965054214641614

Epoch: 5| Step: 3
Training loss: 1.1893656253814697
Validation loss: 2.106802637859057

Epoch: 5| Step: 4
Training loss: 2.1061816215515137
Validation loss: 2.1586778484364992

Epoch: 5| Step: 5
Training loss: 1.4629802703857422
Validation loss: 2.1327525210636917

Epoch: 5| Step: 6
Training loss: 1.6247955560684204
Validation loss: 2.0912396471987487

Epoch: 5| Step: 7
Training loss: 2.303117036819458
Validation loss: 2.0654159412589124

Epoch: 5| Step: 8
Training loss: 2.190016269683838
Validation loss: 2.023812859289108

Epoch: 5| Step: 9
Training loss: 1.3823235034942627
Validation loss: 2.0162316701745473

Epoch: 5| Step: 10
Training loss: 1.6067746877670288
Validation loss: 2.0098884156955186

Epoch: 206| Step: 0
Training loss: 1.6601667404174805
Validation loss: 2.0102324203778337

Epoch: 5| Step: 1
Training loss: 1.1848464012145996
Validation loss: 1.9826635006935365

Epoch: 5| Step: 2
Training loss: 1.7122188806533813
Validation loss: 1.9817648626142932

Epoch: 5| Step: 3
Training loss: 1.9182335138320923
Validation loss: 1.9857144842865646

Epoch: 5| Step: 4
Training loss: 1.3707908391952515
Validation loss: 2.0001824132857786

Epoch: 5| Step: 5
Training loss: 2.162978172302246
Validation loss: 2.04072218812922

Epoch: 5| Step: 6
Training loss: 2.2274415493011475
Validation loss: 2.09656854855117

Epoch: 5| Step: 7
Training loss: 1.9633283615112305
Validation loss: 2.0772136270358996

Epoch: 5| Step: 8
Training loss: 2.050532579421997
Validation loss: 2.056431854924848

Epoch: 5| Step: 9
Training loss: 1.9192718267440796
Validation loss: 2.0702964259732153

Epoch: 5| Step: 10
Training loss: 1.3862637281417847
Validation loss: 2.0498403554321616

Epoch: 207| Step: 0
Training loss: 1.7554630041122437
Validation loss: 2.0569388533151276

Epoch: 5| Step: 1
Training loss: 1.280012845993042
Validation loss: 2.0567937743279243

Epoch: 5| Step: 2
Training loss: 1.8973684310913086
Validation loss: 2.0597928929072555

Epoch: 5| Step: 3
Training loss: 1.784452199935913
Validation loss: 2.041517871682362

Epoch: 5| Step: 4
Training loss: 1.821215033531189
Validation loss: 2.037139677232312

Epoch: 5| Step: 5
Training loss: 1.7168760299682617
Validation loss: 2.014959144335921

Epoch: 5| Step: 6
Training loss: 1.31625497341156
Validation loss: 2.006259946412938

Epoch: 5| Step: 7
Training loss: 1.7065610885620117
Validation loss: 2.008861405875093

Epoch: 5| Step: 8
Training loss: 2.017472505569458
Validation loss: 2.0184813135413715

Epoch: 5| Step: 9
Training loss: 1.9068372249603271
Validation loss: 2.030405003537414

Epoch: 5| Step: 10
Training loss: 1.978775978088379
Validation loss: 2.0352475463703112

Epoch: 208| Step: 0
Training loss: 1.554685354232788
Validation loss: 2.078675026534706

Epoch: 5| Step: 1
Training loss: 2.464046001434326
Validation loss: 2.0756593750369166

Epoch: 5| Step: 2
Training loss: 1.6867263317108154
Validation loss: 2.0637873680360856

Epoch: 5| Step: 3
Training loss: 1.7058086395263672
Validation loss: 2.0807181212209884

Epoch: 5| Step: 4
Training loss: 0.8426947593688965
Validation loss: 2.062953523410264

Epoch: 5| Step: 5
Training loss: 2.1084165573120117
Validation loss: 2.0613258218252533

Epoch: 5| Step: 6
Training loss: 1.6116710901260376
Validation loss: 2.061666496338383

Epoch: 5| Step: 7
Training loss: 1.5548083782196045
Validation loss: 2.075691028307843

Epoch: 5| Step: 8
Training loss: 1.7623693943023682
Validation loss: 2.0836248731100433

Epoch: 5| Step: 9
Training loss: 1.626502275466919
Validation loss: 2.084139826477215

Epoch: 5| Step: 10
Training loss: 2.08705472946167
Validation loss: 2.0684650533942768

Epoch: 209| Step: 0
Training loss: 1.4368473291397095
Validation loss: 2.05203809789432

Epoch: 5| Step: 1
Training loss: 1.7154725790023804
Validation loss: 2.0378417097112185

Epoch: 5| Step: 2
Training loss: 1.8336639404296875
Validation loss: 2.0312089099678943

Epoch: 5| Step: 3
Training loss: 1.9137548208236694
Validation loss: 2.013930816804209

Epoch: 5| Step: 4
Training loss: 1.7857410907745361
Validation loss: 2.023362312265622

Epoch: 5| Step: 5
Training loss: 1.8646667003631592
Validation loss: 2.0589577254428657

Epoch: 5| Step: 6
Training loss: 1.516130805015564
Validation loss: 2.0701245389958864

Epoch: 5| Step: 7
Training loss: 1.3397217988967896
Validation loss: 2.0778573661722164

Epoch: 5| Step: 8
Training loss: 1.7456724643707275
Validation loss: 2.026251180197603

Epoch: 5| Step: 9
Training loss: 1.8421207666397095
Validation loss: 2.0143044699904737

Epoch: 5| Step: 10
Training loss: 1.9378596544265747
Validation loss: 2.0242761117155834

Epoch: 210| Step: 0
Training loss: 1.365097999572754
Validation loss: 2.0323928453589

Epoch: 5| Step: 1
Training loss: 1.6951148509979248
Validation loss: 2.0299334295334353

Epoch: 5| Step: 2
Training loss: 1.9183437824249268
Validation loss: 2.0225054756287606

Epoch: 5| Step: 3
Training loss: 1.7202253341674805
Validation loss: 2.036747083869032

Epoch: 5| Step: 4
Training loss: 1.2840076684951782
Validation loss: 2.0843204323963453

Epoch: 5| Step: 5
Training loss: 1.940844178199768
Validation loss: 2.1172647732560352

Epoch: 5| Step: 6
Training loss: 2.0655744075775146
Validation loss: 2.1128752244416105

Epoch: 5| Step: 7
Training loss: 1.8089649677276611
Validation loss: 2.046956349444646

Epoch: 5| Step: 8
Training loss: 1.7775914669036865
Validation loss: 2.0103160206989577

Epoch: 5| Step: 9
Training loss: 1.6880741119384766
Validation loss: 1.993832649723176

Epoch: 5| Step: 10
Training loss: 1.8390700817108154
Validation loss: 1.997611512419998

Epoch: 211| Step: 0
Training loss: 1.9025650024414062
Validation loss: 2.0008586491307905

Epoch: 5| Step: 1
Training loss: 1.7673286199569702
Validation loss: 2.01500593462298

Epoch: 5| Step: 2
Training loss: 1.4683053493499756
Validation loss: 2.0003462850406604

Epoch: 5| Step: 3
Training loss: 1.7053111791610718
Validation loss: 1.9903336455745082

Epoch: 5| Step: 4
Training loss: 1.7590382099151611
Validation loss: 2.009380849458838

Epoch: 5| Step: 5
Training loss: 1.8361142873764038
Validation loss: 2.038444580570344

Epoch: 5| Step: 6
Training loss: 1.7362031936645508
Validation loss: 2.0523386437405824

Epoch: 5| Step: 7
Training loss: 2.1341283321380615
Validation loss: 2.0937347681291643

Epoch: 5| Step: 8
Training loss: 1.8534482717514038
Validation loss: 2.1074837228303314

Epoch: 5| Step: 9
Training loss: 1.134515643119812
Validation loss: 2.1263022986791467

Epoch: 5| Step: 10
Training loss: 1.4030392169952393
Validation loss: 2.1107038169778805

Epoch: 212| Step: 0
Training loss: 1.45391047000885
Validation loss: 2.0954200747192546

Epoch: 5| Step: 1
Training loss: 1.7080299854278564
Validation loss: 2.0865016547582482

Epoch: 5| Step: 2
Training loss: 1.91988205909729
Validation loss: 2.088098551637383

Epoch: 5| Step: 3
Training loss: 2.3087334632873535
Validation loss: 2.1045657870590047

Epoch: 5| Step: 4
Training loss: 1.5109288692474365
Validation loss: 2.0706089773485736

Epoch: 5| Step: 5
Training loss: 1.788230299949646
Validation loss: 2.0698165560281403

Epoch: 5| Step: 6
Training loss: 1.7869154214859009
Validation loss: 2.049975513130106

Epoch: 5| Step: 7
Training loss: 1.2945306301116943
Validation loss: 2.0741817887111376

Epoch: 5| Step: 8
Training loss: 1.537665605545044
Validation loss: 2.105595064419572

Epoch: 5| Step: 9
Training loss: 1.9927070140838623
Validation loss: 2.1075254999181277

Epoch: 5| Step: 10
Training loss: 1.7155455350875854
Validation loss: 2.10556318683009

Epoch: 213| Step: 0
Training loss: 1.771767020225525
Validation loss: 2.1226323855820524

Epoch: 5| Step: 1
Training loss: 1.8205150365829468
Validation loss: 2.133059476011543

Epoch: 5| Step: 2
Training loss: 1.5595271587371826
Validation loss: 2.0859087256975073

Epoch: 5| Step: 3
Training loss: 2.2437000274658203
Validation loss: 2.0733650422865346

Epoch: 5| Step: 4
Training loss: 1.4535812139511108
Validation loss: 2.054058180060438

Epoch: 5| Step: 5
Training loss: 1.5446867942810059
Validation loss: 2.049160130562321

Epoch: 5| Step: 6
Training loss: 1.8111412525177002
Validation loss: 2.041032987256204

Epoch: 5| Step: 7
Training loss: 1.8894355297088623
Validation loss: 2.032909413819672

Epoch: 5| Step: 8
Training loss: 1.806540846824646
Validation loss: 2.013216587804979

Epoch: 5| Step: 9
Training loss: 1.1574029922485352
Validation loss: 2.0001121080049904

Epoch: 5| Step: 10
Training loss: 1.5291519165039062
Validation loss: 2.003150083685434

Epoch: 214| Step: 0
Training loss: 1.9014075994491577
Validation loss: 2.0237820045922392

Epoch: 5| Step: 1
Training loss: 1.612752914428711
Validation loss: 2.0581846096182383

Epoch: 5| Step: 2
Training loss: 1.779667615890503
Validation loss: 2.083777996801561

Epoch: 5| Step: 3
Training loss: 1.5371854305267334
Validation loss: 2.047099636447045

Epoch: 5| Step: 4
Training loss: 1.7213722467422485
Validation loss: 2.022399797234484

Epoch: 5| Step: 5
Training loss: 1.5734682083129883
Validation loss: 2.017076823019212

Epoch: 5| Step: 6
Training loss: 1.41872239112854
Validation loss: 2.0078771614259288

Epoch: 5| Step: 7
Training loss: 1.519883155822754
Validation loss: 2.0279643458704792

Epoch: 5| Step: 8
Training loss: 1.7611671686172485
Validation loss: 2.0226123691886984

Epoch: 5| Step: 9
Training loss: 2.111323595046997
Validation loss: 2.027247746785482

Epoch: 5| Step: 10
Training loss: 1.4545314311981201
Validation loss: 2.0318757872427664

Epoch: 215| Step: 0
Training loss: 1.630065679550171
Validation loss: 2.0279330130546325

Epoch: 5| Step: 1
Training loss: 1.9036037921905518
Validation loss: 2.025427774716449

Epoch: 5| Step: 2
Training loss: 1.6940906047821045
Validation loss: 2.043177371383995

Epoch: 5| Step: 3
Training loss: 1.3696749210357666
Validation loss: 2.0298825925396335

Epoch: 5| Step: 4
Training loss: 1.6727358102798462
Validation loss: 2.037417111858245

Epoch: 5| Step: 5
Training loss: 1.4195698499679565
Validation loss: 2.048729404326408

Epoch: 5| Step: 6
Training loss: 1.1879724264144897
Validation loss: 2.0367344399934173

Epoch: 5| Step: 7
Training loss: 1.4184447526931763
Validation loss: 2.041132252703431

Epoch: 5| Step: 8
Training loss: 1.5268757343292236
Validation loss: 2.0329735163719422

Epoch: 5| Step: 9
Training loss: 1.8923194408416748
Validation loss: 2.060981442851405

Epoch: 5| Step: 10
Training loss: 2.281402111053467
Validation loss: 2.067227650714177

Epoch: 216| Step: 0
Training loss: 1.4025208950042725
Validation loss: 2.060548484966319

Epoch: 5| Step: 1
Training loss: 1.2084323167800903
Validation loss: 2.0670741335038216

Epoch: 5| Step: 2
Training loss: 1.7219836711883545
Validation loss: 2.069043030021011

Epoch: 5| Step: 3
Training loss: 2.013249397277832
Validation loss: 2.0756187964511175

Epoch: 5| Step: 4
Training loss: 1.5838321447372437
Validation loss: 2.057525593747375

Epoch: 5| Step: 5
Training loss: 1.2115734815597534
Validation loss: 2.0458082306769585

Epoch: 5| Step: 6
Training loss: 1.849543571472168
Validation loss: 2.031988879685761

Epoch: 5| Step: 7
Training loss: 1.5962833166122437
Validation loss: 2.0136990342088925

Epoch: 5| Step: 8
Training loss: 1.8321822881698608
Validation loss: 2.013132752910737

Epoch: 5| Step: 9
Training loss: 1.8396894931793213
Validation loss: 2.008282785774559

Epoch: 5| Step: 10
Training loss: 1.4939292669296265
Validation loss: 1.9919496069672287

Epoch: 217| Step: 0
Training loss: 1.336126685142517
Validation loss: 1.9791226592115176

Epoch: 5| Step: 1
Training loss: 1.6745271682739258
Validation loss: 1.9829557505987023

Epoch: 5| Step: 2
Training loss: 1.6712881326675415
Validation loss: 1.9882279647293912

Epoch: 5| Step: 3
Training loss: 0.9325383305549622
Validation loss: 1.975215619610202

Epoch: 5| Step: 4
Training loss: 1.6694263219833374
Validation loss: 1.9872895056201565

Epoch: 5| Step: 5
Training loss: 1.5745418071746826
Validation loss: 2.00218855181048

Epoch: 5| Step: 6
Training loss: 1.9670928716659546
Validation loss: 1.9934094144452004

Epoch: 5| Step: 7
Training loss: 1.703597068786621
Validation loss: 2.0385230818102436

Epoch: 5| Step: 8
Training loss: 1.4438294172286987
Validation loss: 2.0387616260077364

Epoch: 5| Step: 9
Training loss: 1.7952502965927124
Validation loss: 2.0547173048860286

Epoch: 5| Step: 10
Training loss: 1.7696853876113892
Validation loss: 2.103580632517415

Epoch: 218| Step: 0
Training loss: 1.3596422672271729
Validation loss: 2.138171701021092

Epoch: 5| Step: 1
Training loss: 1.463149905204773
Validation loss: 2.1333872310576902

Epoch: 5| Step: 2
Training loss: 1.1429532766342163
Validation loss: 2.105277338335591

Epoch: 5| Step: 3
Training loss: 2.0356040000915527
Validation loss: 2.0878554467231996

Epoch: 5| Step: 4
Training loss: 1.396759271621704
Validation loss: 2.0893875116943033

Epoch: 5| Step: 5
Training loss: 1.9949071407318115
Validation loss: 2.0769044365934146

Epoch: 5| Step: 6
Training loss: 1.1231495141983032
Validation loss: 2.0546222271457797

Epoch: 5| Step: 7
Training loss: 1.816834807395935
Validation loss: 2.0480813467374412

Epoch: 5| Step: 8
Training loss: 1.588010311126709
Validation loss: 2.0562835290867794

Epoch: 5| Step: 9
Training loss: 1.6998103857040405
Validation loss: 2.046003812102861

Epoch: 5| Step: 10
Training loss: 2.3307383060455322
Validation loss: 2.049892376827937

Epoch: 219| Step: 0
Training loss: 1.5050541162490845
Validation loss: 2.027926047643026

Epoch: 5| Step: 1
Training loss: 1.4243577718734741
Validation loss: 2.0376537589616674

Epoch: 5| Step: 2
Training loss: 1.5957468748092651
Validation loss: 1.9869574731396091

Epoch: 5| Step: 3
Training loss: 2.216993808746338
Validation loss: 1.9819612900416057

Epoch: 5| Step: 4
Training loss: 1.3080333471298218
Validation loss: 1.9827020552850538

Epoch: 5| Step: 5
Training loss: 1.7919546365737915
Validation loss: 1.9930264501161472

Epoch: 5| Step: 6
Training loss: 1.6023437976837158
Validation loss: 1.9914802940942908

Epoch: 5| Step: 7
Training loss: 1.649558663368225
Validation loss: 1.9909450725842548

Epoch: 5| Step: 8
Training loss: 1.319637656211853
Validation loss: 2.018072969170027

Epoch: 5| Step: 9
Training loss: 1.5896656513214111
Validation loss: 2.0486563610774216

Epoch: 5| Step: 10
Training loss: 1.6283906698226929
Validation loss: 2.10195908751539

Epoch: 220| Step: 0
Training loss: 1.5698251724243164
Validation loss: 2.10726515195703

Epoch: 5| Step: 1
Training loss: 1.3715479373931885
Validation loss: 2.0629643163373395

Epoch: 5| Step: 2
Training loss: 1.2719818353652954
Validation loss: 2.0388426575609433

Epoch: 5| Step: 3
Training loss: 1.6480414867401123
Validation loss: 2.0063806861959477

Epoch: 5| Step: 4
Training loss: 1.478906273841858
Validation loss: 2.004925443280128

Epoch: 5| Step: 5
Training loss: 1.5832198858261108
Validation loss: 1.986848949104227

Epoch: 5| Step: 6
Training loss: 1.6734336614608765
Validation loss: 1.9761565000780168

Epoch: 5| Step: 7
Training loss: 1.6716514825820923
Validation loss: 1.9986764307945006

Epoch: 5| Step: 8
Training loss: 1.5782363414764404
Validation loss: 2.0162218873218825

Epoch: 5| Step: 9
Training loss: 1.9172966480255127
Validation loss: 2.012342155620616

Epoch: 5| Step: 10
Training loss: 1.4382495880126953
Validation loss: 2.0149611144937496

Epoch: 221| Step: 0
Training loss: 1.5073423385620117
Validation loss: 1.9998007025769962

Epoch: 5| Step: 1
Training loss: 1.8211157321929932
Validation loss: 2.021030769553236

Epoch: 5| Step: 2
Training loss: 1.6237396001815796
Validation loss: 2.032875353290189

Epoch: 5| Step: 3
Training loss: 0.9178878664970398
Validation loss: 2.050543692804152

Epoch: 5| Step: 4
Training loss: 1.4234672784805298
Validation loss: 2.0472829175251785

Epoch: 5| Step: 5
Training loss: 1.7163569927215576
Validation loss: 2.0544398535964308

Epoch: 5| Step: 6
Training loss: 1.388847827911377
Validation loss: 2.023522716696544

Epoch: 5| Step: 7
Training loss: 1.843065619468689
Validation loss: 2.0047003838323776

Epoch: 5| Step: 8
Training loss: 1.6198456287384033
Validation loss: 2.017327238154668

Epoch: 5| Step: 9
Training loss: 1.7930330038070679
Validation loss: 1.9973279122383363

Epoch: 5| Step: 10
Training loss: 1.2247014045715332
Validation loss: 1.9885827008114065

Epoch: 222| Step: 0
Training loss: 1.134737253189087
Validation loss: 1.9934237195599465

Epoch: 5| Step: 1
Training loss: 1.2112746238708496
Validation loss: 1.9865460613722443

Epoch: 5| Step: 2
Training loss: 1.6529064178466797
Validation loss: 2.0070998053396902

Epoch: 5| Step: 3
Training loss: 1.614900827407837
Validation loss: 2.017026816644976

Epoch: 5| Step: 4
Training loss: 1.6161458492279053
Validation loss: 2.0140762995648127

Epoch: 5| Step: 5
Training loss: 1.7789676189422607
Validation loss: 2.046113923031797

Epoch: 5| Step: 6
Training loss: 1.3562915325164795
Validation loss: 2.047544680615907

Epoch: 5| Step: 7
Training loss: 1.3958027362823486
Validation loss: 2.065177684189171

Epoch: 5| Step: 8
Training loss: 1.6788280010223389
Validation loss: 2.0379288811837473

Epoch: 5| Step: 9
Training loss: 1.5796935558319092
Validation loss: 2.0008953617465113

Epoch: 5| Step: 10
Training loss: 1.7102906703948975
Validation loss: 2.000262301455262

Epoch: 223| Step: 0
Training loss: 1.3672780990600586
Validation loss: 1.9826294658004597

Epoch: 5| Step: 1
Training loss: 1.2521040439605713
Validation loss: 1.9986458798890472

Epoch: 5| Step: 2
Training loss: 1.5590083599090576
Validation loss: 2.0060225712355746

Epoch: 5| Step: 3
Training loss: 1.4592006206512451
Validation loss: 2.0103102960894184

Epoch: 5| Step: 4
Training loss: 1.2359733581542969
Validation loss: 2.014563154148799

Epoch: 5| Step: 5
Training loss: 1.7670133113861084
Validation loss: 2.009665184123542

Epoch: 5| Step: 6
Training loss: 1.5470421314239502
Validation loss: 1.989606201007802

Epoch: 5| Step: 7
Training loss: 1.600343942642212
Validation loss: 1.996208026844968

Epoch: 5| Step: 8
Training loss: 1.7364650964736938
Validation loss: 1.989751205649427

Epoch: 5| Step: 9
Training loss: 1.8337501287460327
Validation loss: 1.9970213315820182

Epoch: 5| Step: 10
Training loss: 1.4819992780685425
Validation loss: 2.00098245118254

Epoch: 224| Step: 0
Training loss: 1.7554298639297485
Validation loss: 2.025239339438818

Epoch: 5| Step: 1
Training loss: 1.6168769598007202
Validation loss: 2.0688069071820987

Epoch: 5| Step: 2
Training loss: 1.5253894329071045
Validation loss: 2.0774012457939888

Epoch: 5| Step: 3
Training loss: 1.349996566772461
Validation loss: 2.045185068602203

Epoch: 5| Step: 4
Training loss: 1.8186426162719727
Validation loss: 2.009690043746784

Epoch: 5| Step: 5
Training loss: 1.306216835975647
Validation loss: 1.999222424722487

Epoch: 5| Step: 6
Training loss: 0.7402397990226746
Validation loss: 1.999441881333628

Epoch: 5| Step: 7
Training loss: 1.4377176761627197
Validation loss: 2.003047416287084

Epoch: 5| Step: 8
Training loss: 1.6658817529678345
Validation loss: 2.0149401849316013

Epoch: 5| Step: 9
Training loss: 2.193077564239502
Validation loss: 1.9954705443433536

Epoch: 5| Step: 10
Training loss: 1.2353935241699219
Validation loss: 2.0007471884450605

Epoch: 225| Step: 0
Training loss: 1.1982831954956055
Validation loss: 2.00640453574478

Epoch: 5| Step: 1
Training loss: 1.851806879043579
Validation loss: 1.9967584251075663

Epoch: 5| Step: 2
Training loss: 1.545262098312378
Validation loss: 1.9875645791330645

Epoch: 5| Step: 3
Training loss: 1.629600167274475
Validation loss: 1.9808954000473022

Epoch: 5| Step: 4
Training loss: 1.8159996271133423
Validation loss: 1.983382155818324

Epoch: 5| Step: 5
Training loss: 1.6836540699005127
Validation loss: 1.955172582339215

Epoch: 5| Step: 6
Training loss: 1.3340370655059814
Validation loss: 1.973083573002969

Epoch: 5| Step: 7
Training loss: 1.4746387004852295
Validation loss: 1.9735548214245868

Epoch: 5| Step: 8
Training loss: 1.4258793592453003
Validation loss: 1.9682036138349963

Epoch: 5| Step: 9
Training loss: 1.1463121175765991
Validation loss: 1.9770015593497985

Epoch: 5| Step: 10
Training loss: 1.5093704462051392
Validation loss: 2.0152885619030205

Epoch: 226| Step: 0
Training loss: 1.1406910419464111
Validation loss: 2.0762877464294434

Epoch: 5| Step: 1
Training loss: 1.4881480932235718
Validation loss: 2.126823879057361

Epoch: 5| Step: 2
Training loss: 1.1093149185180664
Validation loss: 2.2038075052281862

Epoch: 5| Step: 3
Training loss: 1.514269471168518
Validation loss: 2.2768610754320697

Epoch: 5| Step: 4
Training loss: 1.5820486545562744
Validation loss: 2.2381466409211517

Epoch: 5| Step: 5
Training loss: 1.9765650033950806
Validation loss: 2.1200266448400353

Epoch: 5| Step: 6
Training loss: 2.023545265197754
Validation loss: 2.038933882149317

Epoch: 5| Step: 7
Training loss: 1.802527666091919
Validation loss: 2.000587858179564

Epoch: 5| Step: 8
Training loss: 1.4342472553253174
Validation loss: 1.9599693821322532

Epoch: 5| Step: 9
Training loss: 1.4361088275909424
Validation loss: 1.938696486975557

Epoch: 5| Step: 10
Training loss: 1.306955099105835
Validation loss: 1.9395233636261315

Epoch: 227| Step: 0
Training loss: 1.7538135051727295
Validation loss: 1.9432475464318388

Epoch: 5| Step: 1
Training loss: 1.6338014602661133
Validation loss: 1.9668948470905263

Epoch: 5| Step: 2
Training loss: 1.3453953266143799
Validation loss: 1.982227881749471

Epoch: 5| Step: 3
Training loss: 1.8168100118637085
Validation loss: 2.035362438489032

Epoch: 5| Step: 4
Training loss: 1.4204576015472412
Validation loss: 2.0494017742013417

Epoch: 5| Step: 5
Training loss: 1.671730399131775
Validation loss: 2.0264837459851335

Epoch: 5| Step: 6
Training loss: 1.612694501876831
Validation loss: 1.9975470419852965

Epoch: 5| Step: 7
Training loss: 1.1326850652694702
Validation loss: 1.9964720561940184

Epoch: 5| Step: 8
Training loss: 1.7647979259490967
Validation loss: 2.016366720199585

Epoch: 5| Step: 9
Training loss: 1.5022934675216675
Validation loss: 2.0060673567556564

Epoch: 5| Step: 10
Training loss: 1.4056599140167236
Validation loss: 1.9886140925909883

Epoch: 228| Step: 0
Training loss: 1.4341766834259033
Validation loss: 2.010929292248141

Epoch: 5| Step: 1
Training loss: 1.1395645141601562
Validation loss: 2.0315980962527695

Epoch: 5| Step: 2
Training loss: 1.6042896509170532
Validation loss: 2.0426595826302805

Epoch: 5| Step: 3
Training loss: 1.8363730907440186
Validation loss: 2.024433156495453

Epoch: 5| Step: 4
Training loss: 1.183048963546753
Validation loss: 2.005706126971911

Epoch: 5| Step: 5
Training loss: 1.0509790182113647
Validation loss: 1.980899355744803

Epoch: 5| Step: 6
Training loss: 1.5093719959259033
Validation loss: 1.976502864591537

Epoch: 5| Step: 7
Training loss: 1.1098568439483643
Validation loss: 1.9712115180107854

Epoch: 5| Step: 8
Training loss: 2.1143462657928467
Validation loss: 1.985141069658341

Epoch: 5| Step: 9
Training loss: 1.5695146322250366
Validation loss: 1.9856516520182292

Epoch: 5| Step: 10
Training loss: 1.4853482246398926
Validation loss: 2.013982936900149

Epoch: 229| Step: 0
Training loss: 1.7561900615692139
Validation loss: 2.016113909341956

Epoch: 5| Step: 1
Training loss: 1.0827702283859253
Validation loss: 2.043781799654807

Epoch: 5| Step: 2
Training loss: 1.2625757455825806
Validation loss: 2.070274891391877

Epoch: 5| Step: 3
Training loss: 1.2268993854522705
Validation loss: 2.064727371738803

Epoch: 5| Step: 4
Training loss: 1.7619879245758057
Validation loss: 2.04065897387843

Epoch: 5| Step: 5
Training loss: 1.4235913753509521
Validation loss: 1.9947038158293693

Epoch: 5| Step: 6
Training loss: 2.0258355140686035
Validation loss: 1.9889905350182646

Epoch: 5| Step: 7
Training loss: 1.5491042137145996
Validation loss: 1.973958412806193

Epoch: 5| Step: 8
Training loss: 0.9566844701766968
Validation loss: 1.9703798947795745

Epoch: 5| Step: 9
Training loss: 1.6247098445892334
Validation loss: 1.9634305584815241

Epoch: 5| Step: 10
Training loss: 1.3528286218643188
Validation loss: 1.9770085862887803

Epoch: 230| Step: 0
Training loss: 0.9314433336257935
Validation loss: 1.9829573682559434

Epoch: 5| Step: 1
Training loss: 1.6268293857574463
Validation loss: 2.015876939219813

Epoch: 5| Step: 2
Training loss: 1.649635672569275
Validation loss: 2.0046906445616033

Epoch: 5| Step: 3
Training loss: 1.2888356447219849
Validation loss: 2.000906927611238

Epoch: 5| Step: 4
Training loss: 1.4251307249069214
Validation loss: 1.982326836996181

Epoch: 5| Step: 5
Training loss: 1.4686108827590942
Validation loss: 1.992203943191036

Epoch: 5| Step: 6
Training loss: 1.3621649742126465
Validation loss: 2.000274763312391

Epoch: 5| Step: 7
Training loss: 1.0739883184432983
Validation loss: 2.0045382873986357

Epoch: 5| Step: 8
Training loss: 1.6566007137298584
Validation loss: 2.013058166350088

Epoch: 5| Step: 9
Training loss: 1.7416566610336304
Validation loss: 2.0149801674709527

Epoch: 5| Step: 10
Training loss: 1.562789797782898
Validation loss: 2.0092678249523206

Epoch: 231| Step: 0
Training loss: 1.056663990020752
Validation loss: 1.9999798036390735

Epoch: 5| Step: 1
Training loss: 0.9522315859794617
Validation loss: 1.9894120411206317

Epoch: 5| Step: 2
Training loss: 1.550468921661377
Validation loss: 1.9852448906949771

Epoch: 5| Step: 3
Training loss: 1.5453667640686035
Validation loss: 1.9937065262948312

Epoch: 5| Step: 4
Training loss: 1.9415886402130127
Validation loss: 1.9778178712373138

Epoch: 5| Step: 5
Training loss: 1.1713051795959473
Validation loss: 1.966695834231633

Epoch: 5| Step: 6
Training loss: 1.7547376155853271
Validation loss: 1.963136537100679

Epoch: 5| Step: 7
Training loss: 1.654195785522461
Validation loss: 1.9738610688076224

Epoch: 5| Step: 8
Training loss: 0.7827561497688293
Validation loss: 1.9833625285856185

Epoch: 5| Step: 9
Training loss: 1.6420469284057617
Validation loss: 1.9932655198599702

Epoch: 5| Step: 10
Training loss: 1.5272616147994995
Validation loss: 1.9859479396573958

Epoch: 232| Step: 0
Training loss: 1.2394144535064697
Validation loss: 2.0147204578563733

Epoch: 5| Step: 1
Training loss: 1.2934744358062744
Validation loss: 2.035340657798193

Epoch: 5| Step: 2
Training loss: 1.6783440113067627
Validation loss: 2.049177683809752

Epoch: 5| Step: 3
Training loss: 1.2395246028900146
Validation loss: 2.0450337317682084

Epoch: 5| Step: 4
Training loss: 1.1071701049804688
Validation loss: 2.044818232136388

Epoch: 5| Step: 5
Training loss: 1.4681150913238525
Validation loss: 2.035839355120095

Epoch: 5| Step: 6
Training loss: 1.772520661354065
Validation loss: 2.001529583366968

Epoch: 5| Step: 7
Training loss: 1.1437827348709106
Validation loss: 2.0226630574913433

Epoch: 5| Step: 8
Training loss: 1.1969265937805176
Validation loss: 2.011892955790284

Epoch: 5| Step: 9
Training loss: 1.8315248489379883
Validation loss: 2.0069252162851314

Epoch: 5| Step: 10
Training loss: 1.5964250564575195
Validation loss: 1.998977966206048

Epoch: 233| Step: 0
Training loss: 0.891757607460022
Validation loss: 1.9981603673709336

Epoch: 5| Step: 1
Training loss: 1.747097373008728
Validation loss: 2.0028612844405638

Epoch: 5| Step: 2
Training loss: 1.528824806213379
Validation loss: 2.01229937102205

Epoch: 5| Step: 3
Training loss: 1.3047118186950684
Validation loss: 2.05176176563386

Epoch: 5| Step: 4
Training loss: 1.4952341318130493
Validation loss: 1.9994504759388585

Epoch: 5| Step: 5
Training loss: 1.346334457397461
Validation loss: 1.9659281712706371

Epoch: 5| Step: 6
Training loss: 1.2939846515655518
Validation loss: 1.9450315262681694

Epoch: 5| Step: 7
Training loss: 1.3474336862564087
Validation loss: 1.9244129991018644

Epoch: 5| Step: 8
Training loss: 1.6257784366607666
Validation loss: 1.935705518209806

Epoch: 5| Step: 9
Training loss: 1.4786818027496338
Validation loss: 1.9523194707849973

Epoch: 5| Step: 10
Training loss: 1.9159440994262695
Validation loss: 1.976918940903038

Epoch: 234| Step: 0
Training loss: 1.3668066263198853
Validation loss: 2.020268791465349

Epoch: 5| Step: 1
Training loss: 1.2332165241241455
Validation loss: 2.0823176727500012

Epoch: 5| Step: 2
Training loss: 1.2972381114959717
Validation loss: 2.1608360992964877

Epoch: 5| Step: 3
Training loss: 1.6616061925888062
Validation loss: 2.2284222828444613

Epoch: 5| Step: 4
Training loss: 1.0434646606445312
Validation loss: 2.1694593737202306

Epoch: 5| Step: 5
Training loss: 1.1776165962219238
Validation loss: 2.111777890113092

Epoch: 5| Step: 6
Training loss: 1.9241281747817993
Validation loss: 2.0669594221217658

Epoch: 5| Step: 7
Training loss: 1.9694888591766357
Validation loss: 2.0333762655976

Epoch: 5| Step: 8
Training loss: 1.337319016456604
Validation loss: 2.00217237523807

Epoch: 5| Step: 9
Training loss: 1.5304642915725708
Validation loss: 1.9553611329806748

Epoch: 5| Step: 10
Training loss: 1.5625412464141846
Validation loss: 1.9529592401237899

Epoch: 235| Step: 0
Training loss: 1.5151578187942505
Validation loss: 1.9479407866795857

Epoch: 5| Step: 1
Training loss: 1.2900022268295288
Validation loss: 1.921610834777996

Epoch: 5| Step: 2
Training loss: 1.4424247741699219
Validation loss: 1.944078004488381

Epoch: 5| Step: 3
Training loss: 1.753400444984436
Validation loss: 1.9323824451815697

Epoch: 5| Step: 4
Training loss: 1.2647621631622314
Validation loss: 1.9338286256277433

Epoch: 5| Step: 5
Training loss: 1.0558890104293823
Validation loss: 1.9425336276331255

Epoch: 5| Step: 6
Training loss: 1.658517599105835
Validation loss: 1.9569573684405255

Epoch: 5| Step: 7
Training loss: 1.6001209020614624
Validation loss: 1.9883389921598538

Epoch: 5| Step: 8
Training loss: 1.9077460765838623
Validation loss: 2.0133225494815457

Epoch: 5| Step: 9
Training loss: 1.2903563976287842
Validation loss: 2.022329353517102

Epoch: 5| Step: 10
Training loss: 1.1187797784805298
Validation loss: 2.031533225890129

Epoch: 236| Step: 0
Training loss: 1.6758038997650146
Validation loss: 2.0794839756463164

Epoch: 5| Step: 1
Training loss: 1.5739142894744873
Validation loss: 2.0970785438373523

Epoch: 5| Step: 2
Training loss: 1.2511928081512451
Validation loss: 2.069128510772541

Epoch: 5| Step: 3
Training loss: 1.229665994644165
Validation loss: 2.046306769053141

Epoch: 5| Step: 4
Training loss: 1.2533838748931885
Validation loss: 2.054384554586103

Epoch: 5| Step: 5
Training loss: 1.2771354913711548
Validation loss: 2.050190853816207

Epoch: 5| Step: 6
Training loss: 1.3343713283538818
Validation loss: 2.0361306949328353

Epoch: 5| Step: 7
Training loss: 1.7047388553619385
Validation loss: 2.030870795249939

Epoch: 5| Step: 8
Training loss: 1.292415976524353
Validation loss: 1.9896709560066141

Epoch: 5| Step: 9
Training loss: 1.4716451168060303
Validation loss: 1.972521197411322

Epoch: 5| Step: 10
Training loss: 1.2904548645019531
Validation loss: 1.9691988793752526

Epoch: 237| Step: 0
Training loss: 1.2951046228408813
Validation loss: 1.9765157955949024

Epoch: 5| Step: 1
Training loss: 1.8391122817993164
Validation loss: 1.984281950099494

Epoch: 5| Step: 2
Training loss: 2.048616886138916
Validation loss: 1.9927770373641804

Epoch: 5| Step: 3
Training loss: 1.69195556640625
Validation loss: 2.012922276732742

Epoch: 5| Step: 4
Training loss: 1.075190544128418
Validation loss: 1.986170107318509

Epoch: 5| Step: 5
Training loss: 1.0681123733520508
Validation loss: 1.9641411522383332

Epoch: 5| Step: 6
Training loss: 1.2600237131118774
Validation loss: 1.9547285802902714

Epoch: 5| Step: 7
Training loss: 1.060558557510376
Validation loss: 1.977868309584997

Epoch: 5| Step: 8
Training loss: 0.9331779479980469
Validation loss: 1.9979734331048944

Epoch: 5| Step: 9
Training loss: 1.5787594318389893
Validation loss: 1.9905653743333713

Epoch: 5| Step: 10
Training loss: 1.6193581819534302
Validation loss: 1.987703013163741

Epoch: 238| Step: 0
Training loss: 1.6198108196258545
Validation loss: 1.9946525071256904

Epoch: 5| Step: 1
Training loss: 1.0231586694717407
Validation loss: 2.0403656600624003

Epoch: 5| Step: 2
Training loss: 1.4840677976608276
Validation loss: 2.074595738482732

Epoch: 5| Step: 3
Training loss: 1.6541893482208252
Validation loss: 2.0888919009957263

Epoch: 5| Step: 4
Training loss: 1.5508321523666382
Validation loss: 2.0661489450803368

Epoch: 5| Step: 5
Training loss: 1.2809494733810425
Validation loss: 2.0163148641586304

Epoch: 5| Step: 6
Training loss: 0.9825464487075806
Validation loss: 1.9991564020033805

Epoch: 5| Step: 7
Training loss: 1.4092673063278198
Validation loss: 2.010742961719472

Epoch: 5| Step: 8
Training loss: 1.3251953125
Validation loss: 2.0206336282914683

Epoch: 5| Step: 9
Training loss: 1.604978322982788
Validation loss: 2.038453148257348

Epoch: 5| Step: 10
Training loss: 1.2178583145141602
Validation loss: 2.023480162825636

Epoch: 239| Step: 0
Training loss: 1.67698073387146
Validation loss: 1.9906570129497076

Epoch: 5| Step: 1
Training loss: 1.3952319622039795
Validation loss: 1.9946087688528082

Epoch: 5| Step: 2
Training loss: 1.3081389665603638
Validation loss: 2.0443811160261913

Epoch: 5| Step: 3
Training loss: 1.6956870555877686
Validation loss: 2.10679111173076

Epoch: 5| Step: 4
Training loss: 0.9949294924736023
Validation loss: 2.0924909768566007

Epoch: 5| Step: 5
Training loss: 0.7154995799064636
Validation loss: 2.0199575603649182

Epoch: 5| Step: 6
Training loss: 1.4797208309173584
Validation loss: 1.9999983669609152

Epoch: 5| Step: 7
Training loss: 1.6489137411117554
Validation loss: 1.9884630275029007

Epoch: 5| Step: 8
Training loss: 1.9695972204208374
Validation loss: 1.9833351899218816

Epoch: 5| Step: 9
Training loss: 1.3754441738128662
Validation loss: 1.974748255104147

Epoch: 5| Step: 10
Training loss: 1.247680902481079
Validation loss: 1.9840631895167853

Epoch: 240| Step: 0
Training loss: 1.1246157884597778
Validation loss: 1.9729091345622976

Epoch: 5| Step: 1
Training loss: 1.3429771661758423
Validation loss: 1.9961518138967536

Epoch: 5| Step: 2
Training loss: 1.172447681427002
Validation loss: 2.021723319125432

Epoch: 5| Step: 3
Training loss: 2.0353798866271973
Validation loss: 2.070762979087009

Epoch: 5| Step: 4
Training loss: 1.1236958503723145
Validation loss: 2.1055699984232583

Epoch: 5| Step: 5
Training loss: 1.3673527240753174
Validation loss: 2.049397717240036

Epoch: 5| Step: 6
Training loss: 1.509189248085022
Validation loss: 2.049077498015537

Epoch: 5| Step: 7
Training loss: 1.6083037853240967
Validation loss: 2.026597276810677

Epoch: 5| Step: 8
Training loss: 1.006029486656189
Validation loss: 2.0226696652750813

Epoch: 5| Step: 9
Training loss: 0.996008038520813
Validation loss: 1.9917142570659678

Epoch: 5| Step: 10
Training loss: 1.5740245580673218
Validation loss: 1.98260558548794

Epoch: 241| Step: 0
Training loss: 1.5805344581604004
Validation loss: 1.973241130510966

Epoch: 5| Step: 1
Training loss: 0.8986152410507202
Validation loss: 1.9726806609861312

Epoch: 5| Step: 2
Training loss: 0.8742090463638306
Validation loss: 1.9487896632122736

Epoch: 5| Step: 3
Training loss: 1.7399269342422485
Validation loss: 1.9502797793316584

Epoch: 5| Step: 4
Training loss: 1.522401213645935
Validation loss: 1.9401096733667518

Epoch: 5| Step: 5
Training loss: 1.4020171165466309
Validation loss: 1.946082257455395

Epoch: 5| Step: 6
Training loss: 1.5166456699371338
Validation loss: 1.9361192321264615

Epoch: 5| Step: 7
Training loss: 1.1997026205062866
Validation loss: 1.943978335267754

Epoch: 5| Step: 8
Training loss: 1.6103439331054688
Validation loss: 1.953317121792865

Epoch: 5| Step: 9
Training loss: 1.2795809507369995
Validation loss: 1.9598654188135618

Epoch: 5| Step: 10
Training loss: 1.1447994709014893
Validation loss: 1.9673466195342362

Epoch: 242| Step: 0
Training loss: 0.8886756896972656
Validation loss: 1.9633791113412509

Epoch: 5| Step: 1
Training loss: 2.1297523975372314
Validation loss: 1.9708023763472033

Epoch: 5| Step: 2
Training loss: 1.3339321613311768
Validation loss: 1.9842656940542243

Epoch: 5| Step: 3
Training loss: 1.2401834726333618
Validation loss: 1.9802458055557743

Epoch: 5| Step: 4
Training loss: 1.3041956424713135
Validation loss: 2.0124464381125664

Epoch: 5| Step: 5
Training loss: 1.4036067724227905
Validation loss: 2.021107486499253

Epoch: 5| Step: 6
Training loss: 1.5086065530776978
Validation loss: 2.0192464525981615

Epoch: 5| Step: 7
Training loss: 1.0051144361495972
Validation loss: 2.013332341306953

Epoch: 5| Step: 8
Training loss: 1.1014419794082642
Validation loss: 2.01707750110216

Epoch: 5| Step: 9
Training loss: 1.0975300073623657
Validation loss: 2.0001930421398533

Epoch: 5| Step: 10
Training loss: 1.395995020866394
Validation loss: 1.9833191338405813

Epoch: 243| Step: 0
Training loss: 1.6987375020980835
Validation loss: 1.9541341181724303

Epoch: 5| Step: 1
Training loss: 1.2808603048324585
Validation loss: 1.9499640554510138

Epoch: 5| Step: 2
Training loss: 1.409500002861023
Validation loss: 1.9234552434695664

Epoch: 5| Step: 3
Training loss: 0.981999397277832
Validation loss: 1.9219885820983558

Epoch: 5| Step: 4
Training loss: 0.9907181859016418
Validation loss: 1.9050811285613685

Epoch: 5| Step: 5
Training loss: 1.5544618368148804
Validation loss: 1.9126667130377986

Epoch: 5| Step: 6
Training loss: 1.3815581798553467
Validation loss: 1.9402566558571273

Epoch: 5| Step: 7
Training loss: 2.030949115753174
Validation loss: 1.9533813909817768

Epoch: 5| Step: 8
Training loss: 1.397356629371643
Validation loss: 1.9642768508644515

Epoch: 5| Step: 9
Training loss: 0.8779333829879761
Validation loss: 1.9154079203964562

Epoch: 5| Step: 10
Training loss: 1.1818621158599854
Validation loss: 1.9378352280585998

Epoch: 244| Step: 0
Training loss: 1.4230844974517822
Validation loss: 1.9266064654114425

Epoch: 5| Step: 1
Training loss: 1.4524610042572021
Validation loss: 1.9540104340481501

Epoch: 5| Step: 2
Training loss: 1.9279931783676147
Validation loss: 1.9653035402297974

Epoch: 5| Step: 3
Training loss: 1.175939917564392
Validation loss: 1.9757400315294984

Epoch: 5| Step: 4
Training loss: 1.271223783493042
Validation loss: 1.999841849009196

Epoch: 5| Step: 5
Training loss: 1.4373022317886353
Validation loss: 1.9937277532392932

Epoch: 5| Step: 6
Training loss: 0.8160229921340942
Validation loss: 2.0020371842127975

Epoch: 5| Step: 7
Training loss: 1.0068891048431396
Validation loss: 1.9450392671810683

Epoch: 5| Step: 8
Training loss: 1.3440173864364624
Validation loss: 1.9146802758657804

Epoch: 5| Step: 9
Training loss: 1.3236396312713623
Validation loss: 1.9203537856378863

Epoch: 5| Step: 10
Training loss: 1.2246893644332886
Validation loss: 1.9447252083850164

Epoch: 245| Step: 0
Training loss: 1.582139253616333
Validation loss: 1.9367987071314166

Epoch: 5| Step: 1
Training loss: 1.5256825685501099
Validation loss: 1.9424556814214236

Epoch: 5| Step: 2
Training loss: 1.4152154922485352
Validation loss: 1.968415291078629

Epoch: 5| Step: 3
Training loss: 0.7283350825309753
Validation loss: 1.9929979514050227

Epoch: 5| Step: 4
Training loss: 0.8955966234207153
Validation loss: 2.0321846879938597

Epoch: 5| Step: 5
Training loss: 0.8873982429504395
Validation loss: 2.0859725295856433

Epoch: 5| Step: 6
Training loss: 1.3152461051940918
Validation loss: 2.0842168113236785

Epoch: 5| Step: 7
Training loss: 1.4792180061340332
Validation loss: 2.0751328750323226

Epoch: 5| Step: 8
Training loss: 1.5693206787109375
Validation loss: 2.0142353939753708

Epoch: 5| Step: 9
Training loss: 1.3299696445465088
Validation loss: 2.0241251709640666

Epoch: 5| Step: 10
Training loss: 1.7980555295944214
Validation loss: 2.0094684221411265

Epoch: 246| Step: 0
Training loss: 1.1375411748886108
Validation loss: 1.990768007052842

Epoch: 5| Step: 1
Training loss: 1.2745534181594849
Validation loss: 1.9899997121544295

Epoch: 5| Step: 2
Training loss: 1.017037272453308
Validation loss: 1.975231711582471

Epoch: 5| Step: 3
Training loss: 1.2586015462875366
Validation loss: 2.014770605230844

Epoch: 5| Step: 4
Training loss: 1.513928771018982
Validation loss: 2.031387604692931

Epoch: 5| Step: 5
Training loss: 1.1070080995559692
Validation loss: 2.0299160211317

Epoch: 5| Step: 6
Training loss: 1.3292433023452759
Validation loss: 2.031351662451221

Epoch: 5| Step: 7
Training loss: 1.7114713191986084
Validation loss: 2.0309059671176377

Epoch: 5| Step: 8
Training loss: 1.4582319259643555
Validation loss: 1.99904635132

Epoch: 5| Step: 9
Training loss: 1.0320414304733276
Validation loss: 1.9695697164022794

Epoch: 5| Step: 10
Training loss: 1.3651485443115234
Validation loss: 1.9687303650763728

Epoch: 247| Step: 0
Training loss: 0.7754018902778625
Validation loss: 1.965456662639495

Epoch: 5| Step: 1
Training loss: 1.9112262725830078
Validation loss: 1.9552086322538313

Epoch: 5| Step: 2
Training loss: 1.0101035833358765
Validation loss: 1.9466953226315078

Epoch: 5| Step: 3
Training loss: 1.3102470636367798
Validation loss: 1.9629829622084094

Epoch: 5| Step: 4
Training loss: 1.1854578256607056
Validation loss: 1.9499905596497238

Epoch: 5| Step: 5
Training loss: 1.2156890630722046
Validation loss: 1.9656364943391533

Epoch: 5| Step: 6
Training loss: 1.1471418142318726
Validation loss: 1.9660505299927087

Epoch: 5| Step: 7
Training loss: 1.522106409072876
Validation loss: 1.9682087103525798

Epoch: 5| Step: 8
Training loss: 1.5485438108444214
Validation loss: 1.97913271381009

Epoch: 5| Step: 9
Training loss: 1.123180627822876
Validation loss: 1.9929513790274178

Epoch: 5| Step: 10
Training loss: 1.3066174983978271
Validation loss: 1.983786888020013

Epoch: 248| Step: 0
Training loss: 1.5040624141693115
Validation loss: 1.9756121084254274

Epoch: 5| Step: 1
Training loss: 1.7184919118881226
Validation loss: 1.95231250280975

Epoch: 5| Step: 2
Training loss: 0.7718168497085571
Validation loss: 1.943747156409807

Epoch: 5| Step: 3
Training loss: 1.3831508159637451
Validation loss: 1.9348711980286466

Epoch: 5| Step: 4
Training loss: 1.4201059341430664
Validation loss: 1.933124578127297

Epoch: 5| Step: 5
Training loss: 1.5467019081115723
Validation loss: 1.9441995300272459

Epoch: 5| Step: 6
Training loss: 1.2439334392547607
Validation loss: 1.9511962270223966

Epoch: 5| Step: 7
Training loss: 1.2130671739578247
Validation loss: 1.9741280386524815

Epoch: 5| Step: 8
Training loss: 0.9445205926895142
Validation loss: 2.0110101276828396

Epoch: 5| Step: 9
Training loss: 1.4533907175064087
Validation loss: 1.9968338884333128

Epoch: 5| Step: 10
Training loss: 0.8298370838165283
Validation loss: 1.9857527620048934

Epoch: 249| Step: 0
Training loss: 1.0207618474960327
Validation loss: 1.9860715443088162

Epoch: 5| Step: 1
Training loss: 1.22797429561615
Validation loss: 1.9619907768823768

Epoch: 5| Step: 2
Training loss: 1.5988497734069824
Validation loss: 1.9368943296453005

Epoch: 5| Step: 3
Training loss: 1.5222527980804443
Validation loss: 1.9481004258637786

Epoch: 5| Step: 4
Training loss: 1.3371957540512085
Validation loss: 1.9388287528868644

Epoch: 5| Step: 5
Training loss: 1.1714924573898315
Validation loss: 1.9458299888077604

Epoch: 5| Step: 6
Training loss: 1.113816499710083
Validation loss: 1.9503505896496516

Epoch: 5| Step: 7
Training loss: 0.9784377813339233
Validation loss: 1.9893951954380158

Epoch: 5| Step: 8
Training loss: 0.8774771690368652
Validation loss: 1.974334684751367

Epoch: 5| Step: 9
Training loss: 1.536245346069336
Validation loss: 1.9824086658416256

Epoch: 5| Step: 10
Training loss: 1.3532730340957642
Validation loss: 1.98570433996057

Epoch: 250| Step: 0
Training loss: 1.2894847393035889
Validation loss: 1.9791883473755212

Epoch: 5| Step: 1
Training loss: 1.41245698928833
Validation loss: 1.9935991328249696

Epoch: 5| Step: 2
Training loss: 1.6397857666015625
Validation loss: 1.9641978202327606

Epoch: 5| Step: 3
Training loss: 0.7179014682769775
Validation loss: 1.9568704635866228

Epoch: 5| Step: 4
Training loss: 1.1218441724777222
Validation loss: 1.952849764977732

Epoch: 5| Step: 5
Training loss: 1.7219219207763672
Validation loss: 1.9776311894898773

Epoch: 5| Step: 6
Training loss: 0.6629714965820312
Validation loss: 1.9947454160259617

Epoch: 5| Step: 7
Training loss: 1.2228432893753052
Validation loss: 2.000435149797829

Epoch: 5| Step: 8
Training loss: 0.8952457308769226
Validation loss: 2.0274223550673454

Epoch: 5| Step: 9
Training loss: 1.88754141330719
Validation loss: 2.002962771282401

Epoch: 5| Step: 10
Training loss: 1.0307221412658691
Validation loss: 2.0294544184079735

Epoch: 251| Step: 0
Training loss: 1.7180038690567017
Validation loss: 2.0191090850419897

Epoch: 5| Step: 1
Training loss: 1.0779434442520142
Validation loss: 1.9990468537935646

Epoch: 5| Step: 2
Training loss: 1.670896291732788
Validation loss: 1.967373146805712

Epoch: 5| Step: 3
Training loss: 1.1411041021347046
Validation loss: 1.9758090537081483

Epoch: 5| Step: 4
Training loss: 1.2773163318634033
Validation loss: 1.961667142888551

Epoch: 5| Step: 5
Training loss: 0.8587746620178223
Validation loss: 1.9308606809185398

Epoch: 5| Step: 6
Training loss: 1.519036889076233
Validation loss: 1.9107677782735517

Epoch: 5| Step: 7
Training loss: 1.1208727359771729
Validation loss: 1.9016308502484394

Epoch: 5| Step: 8
Training loss: 1.2873773574829102
Validation loss: 1.9265996230545865

Epoch: 5| Step: 9
Training loss: 0.8307977914810181
Validation loss: 1.9405267238616943

Epoch: 5| Step: 10
Training loss: 1.1318975687026978
Validation loss: 1.9273166425766484

Epoch: 252| Step: 0
Training loss: 1.6615444421768188
Validation loss: 1.9412091291078957

Epoch: 5| Step: 1
Training loss: 0.9654544591903687
Validation loss: 1.9738646886681999

Epoch: 5| Step: 2
Training loss: 1.273744821548462
Validation loss: 1.9871523393097745

Epoch: 5| Step: 3
Training loss: 1.040723204612732
Validation loss: 1.993300368708949

Epoch: 5| Step: 4
Training loss: 1.0871398448944092
Validation loss: 1.9937297221153014

Epoch: 5| Step: 5
Training loss: 1.018254041671753
Validation loss: 2.0319281342209026

Epoch: 5| Step: 6
Training loss: 0.9303056001663208
Validation loss: 1.9837898785068142

Epoch: 5| Step: 7
Training loss: 1.5320791006088257
Validation loss: 1.9569980149628015

Epoch: 5| Step: 8
Training loss: 1.4792344570159912
Validation loss: 1.919709227418387

Epoch: 5| Step: 9
Training loss: 1.5120644569396973
Validation loss: 1.887531699672822

Epoch: 5| Step: 10
Training loss: 0.9755910038948059
Validation loss: 1.8849677988277969

Epoch: 253| Step: 0
Training loss: 1.260960340499878
Validation loss: 1.8975700434818064

Epoch: 5| Step: 1
Training loss: 1.1470739841461182
Validation loss: 1.903059159555743

Epoch: 5| Step: 2
Training loss: 1.1177880764007568
Validation loss: 1.9542064538566015

Epoch: 5| Step: 3
Training loss: 1.584007740020752
Validation loss: 1.9717351467378679

Epoch: 5| Step: 4
Training loss: 1.7813482284545898
Validation loss: 1.9724514689496768

Epoch: 5| Step: 5
Training loss: 1.2867575883865356
Validation loss: 1.9685385791204308

Epoch: 5| Step: 6
Training loss: 0.6575149893760681
Validation loss: 1.9699510143649193

Epoch: 5| Step: 7
Training loss: 1.2144629955291748
Validation loss: 2.01549171504154

Epoch: 5| Step: 8
Training loss: 1.0590063333511353
Validation loss: 1.9867713233476043

Epoch: 5| Step: 9
Training loss: 1.0693790912628174
Validation loss: 1.9827956640592186

Epoch: 5| Step: 10
Training loss: 1.1515860557556152
Validation loss: 1.9619160441942112

Epoch: 254| Step: 0
Training loss: 1.365483283996582
Validation loss: 1.9248927665013138

Epoch: 5| Step: 1
Training loss: 1.207850456237793
Validation loss: 1.924975024756565

Epoch: 5| Step: 2
Training loss: 1.399149775505066
Validation loss: 1.8777997365561865

Epoch: 5| Step: 3
Training loss: 1.3105947971343994
Validation loss: 1.8767766811514413

Epoch: 5| Step: 4
Training loss: 1.3535175323486328
Validation loss: 1.8734477053406418

Epoch: 5| Step: 5
Training loss: 0.9978303909301758
Validation loss: 1.8791482602396319

Epoch: 5| Step: 6
Training loss: 1.097135066986084
Validation loss: 1.8769122349318637

Epoch: 5| Step: 7
Training loss: 1.123512864112854
Validation loss: 1.9079336133054507

Epoch: 5| Step: 8
Training loss: 0.8713037371635437
Validation loss: 1.9630997321938957

Epoch: 5| Step: 9
Training loss: 1.1235750913619995
Validation loss: 2.0217493887870543

Epoch: 5| Step: 10
Training loss: 1.4151718616485596
Validation loss: 2.0266376656870686

Epoch: 255| Step: 0
Training loss: 0.8093658685684204
Validation loss: 2.002081537759432

Epoch: 5| Step: 1
Training loss: 0.9145285487174988
Validation loss: 1.9823746271030878

Epoch: 5| Step: 2
Training loss: 1.1732934713363647
Validation loss: 1.98491088292932

Epoch: 5| Step: 3
Training loss: 1.9489963054656982
Validation loss: 1.9581600363536547

Epoch: 5| Step: 4
Training loss: 1.58565354347229
Validation loss: 1.928093530798471

Epoch: 5| Step: 5
Training loss: 1.1813856363296509
Validation loss: 1.9410410978460824

Epoch: 5| Step: 6
Training loss: 1.328086256980896
Validation loss: 1.9743653625570319

Epoch: 5| Step: 7
Training loss: 1.2242238521575928
Validation loss: 2.02106559917491

Epoch: 5| Step: 8
Training loss: 1.2011600732803345
Validation loss: 2.037055206555192

Epoch: 5| Step: 9
Training loss: 1.7531793117523193
Validation loss: 2.007734512770048

Epoch: 5| Step: 10
Training loss: 1.1119829416275024
Validation loss: 1.9685572501151793

Epoch: 256| Step: 0
Training loss: 1.2578821182250977
Validation loss: 1.9249410603636055

Epoch: 5| Step: 1
Training loss: 0.9349201917648315
Validation loss: 1.9003520140083887

Epoch: 5| Step: 2
Training loss: 1.414750099182129
Validation loss: 1.926873617274787

Epoch: 5| Step: 3
Training loss: 1.6629703044891357
Validation loss: 1.9538460495651409

Epoch: 5| Step: 4
Training loss: 1.081486463546753
Validation loss: 1.957859363607181

Epoch: 5| Step: 5
Training loss: 1.291259527206421
Validation loss: 1.968495899631131

Epoch: 5| Step: 6
Training loss: 0.915634036064148
Validation loss: 2.0022493511117916

Epoch: 5| Step: 7
Training loss: 1.4264795780181885
Validation loss: 2.0509303551848217

Epoch: 5| Step: 8
Training loss: 1.2265756130218506
Validation loss: 2.0456225948949016

Epoch: 5| Step: 9
Training loss: 1.1859679222106934
Validation loss: 2.0488043703058714

Epoch: 5| Step: 10
Training loss: 1.3731205463409424
Validation loss: 1.9907562732696533

Epoch: 257| Step: 0
Training loss: 1.6787980794906616
Validation loss: 1.92977342554318

Epoch: 5| Step: 1
Training loss: 1.4056462049484253
Validation loss: 1.9068900846665906

Epoch: 5| Step: 2
Training loss: 1.0255779027938843
Validation loss: 1.868305319099016

Epoch: 5| Step: 3
Training loss: 0.7770404815673828
Validation loss: 1.872849049106721

Epoch: 5| Step: 4
Training loss: 0.9409335255622864
Validation loss: 1.8616764096803562

Epoch: 5| Step: 5
Training loss: 1.4594497680664062
Validation loss: 1.8849872517329391

Epoch: 5| Step: 6
Training loss: 1.1767704486846924
Validation loss: 1.889621506455124

Epoch: 5| Step: 7
Training loss: 1.0631705522537231
Validation loss: 1.9421723658038723

Epoch: 5| Step: 8
Training loss: 0.9995058178901672
Validation loss: 1.9663009259008593

Epoch: 5| Step: 9
Training loss: 1.4410717487335205
Validation loss: 2.001538010053737

Epoch: 5| Step: 10
Training loss: 1.121870994567871
Validation loss: 2.031778545789821

Epoch: 258| Step: 0
Training loss: 1.3421365022659302
Validation loss: 2.039763367304238

Epoch: 5| Step: 1
Training loss: 1.0841683149337769
Validation loss: 2.000208185565087

Epoch: 5| Step: 2
Training loss: 1.4578617811203003
Validation loss: 1.9958027626878472

Epoch: 5| Step: 3
Training loss: 1.158873200416565
Validation loss: 1.982489957604357

Epoch: 5| Step: 4
Training loss: 1.4211158752441406
Validation loss: 1.9604705123491184

Epoch: 5| Step: 5
Training loss: 1.2761452198028564
Validation loss: 1.9456267741418654

Epoch: 5| Step: 6
Training loss: 0.9046028256416321
Validation loss: 1.9200026540346042

Epoch: 5| Step: 7
Training loss: 1.2368390560150146
Validation loss: 1.9174337105084491

Epoch: 5| Step: 8
Training loss: 1.6089961528778076
Validation loss: 1.9535350902106172

Epoch: 5| Step: 9
Training loss: 1.2655315399169922
Validation loss: 1.9795525599551458

Epoch: 5| Step: 10
Training loss: 0.9912738800048828
Validation loss: 1.9532738129297893

Epoch: 259| Step: 0
Training loss: 1.2293059825897217
Validation loss: 1.9314795745316373

Epoch: 5| Step: 1
Training loss: 1.0425944328308105
Validation loss: 1.9153139680944464

Epoch: 5| Step: 2
Training loss: 1.502686619758606
Validation loss: 1.917637727593863

Epoch: 5| Step: 3
Training loss: 1.2494103908538818
Validation loss: 1.9338241008020216

Epoch: 5| Step: 4
Training loss: 1.2024009227752686
Validation loss: 1.9616090059280396

Epoch: 5| Step: 5
Training loss: 1.0817883014678955
Validation loss: 1.979581344512201

Epoch: 5| Step: 6
Training loss: 0.794244110584259
Validation loss: 1.9942213155890023

Epoch: 5| Step: 7
Training loss: 1.3033926486968994
Validation loss: 1.9864583425624396

Epoch: 5| Step: 8
Training loss: 1.1943618059158325
Validation loss: 1.9959931758142286

Epoch: 5| Step: 9
Training loss: 0.9492768049240112
Validation loss: 2.0062500699873893

Epoch: 5| Step: 10
Training loss: 1.5986452102661133
Validation loss: 1.9897385322919456

Epoch: 260| Step: 0
Training loss: 0.8748582005500793
Validation loss: 1.988948263147826

Epoch: 5| Step: 1
Training loss: 1.2167253494262695
Validation loss: 1.963953843680761

Epoch: 5| Step: 2
Training loss: 0.9250891804695129
Validation loss: 1.9465348669277724

Epoch: 5| Step: 3
Training loss: 1.1895145177841187
Validation loss: 1.936053805453803

Epoch: 5| Step: 4
Training loss: 0.8960580825805664
Validation loss: 1.9280094831220564

Epoch: 5| Step: 5
Training loss: 1.4332836866378784
Validation loss: 1.9086700716326315

Epoch: 5| Step: 6
Training loss: 1.3060847520828247
Validation loss: 1.933833670872514

Epoch: 5| Step: 7
Training loss: 0.7824264168739319
Validation loss: 1.9321465466612129

Epoch: 5| Step: 8
Training loss: 1.3086010217666626
Validation loss: 1.9480103497864099

Epoch: 5| Step: 9
Training loss: 1.4292256832122803
Validation loss: 1.9266200642431937

Epoch: 5| Step: 10
Training loss: 1.2904047966003418
Validation loss: 1.9153220192078622

Epoch: 261| Step: 0
Training loss: 1.340749979019165
Validation loss: 1.926587668798303

Epoch: 5| Step: 1
Training loss: 0.8896442651748657
Validation loss: 1.9663148541604318

Epoch: 5| Step: 2
Training loss: 1.253132700920105
Validation loss: 1.9426743317675847

Epoch: 5| Step: 3
Training loss: 0.8747115135192871
Validation loss: 1.9409587434543076

Epoch: 5| Step: 4
Training loss: 0.9089078903198242
Validation loss: 1.956667156629665

Epoch: 5| Step: 5
Training loss: 1.4185211658477783
Validation loss: 1.9692553256147651

Epoch: 5| Step: 6
Training loss: 1.1312509775161743
Validation loss: 1.940652960090227

Epoch: 5| Step: 7
Training loss: 1.2358595132827759
Validation loss: 1.915394695856238

Epoch: 5| Step: 8
Training loss: 1.0865097045898438
Validation loss: 1.9136961813895934

Epoch: 5| Step: 9
Training loss: 1.268066644668579
Validation loss: 1.9022620134456183

Epoch: 5| Step: 10
Training loss: 1.1073416471481323
Validation loss: 1.8867065329705515

Epoch: 262| Step: 0
Training loss: 1.0447049140930176
Validation loss: 1.9499901981763943

Epoch: 5| Step: 1
Training loss: 1.3916645050048828
Validation loss: 1.9561048887109245

Epoch: 5| Step: 2
Training loss: 1.3417266607284546
Validation loss: 1.9851086716498099

Epoch: 5| Step: 3
Training loss: 1.1270681619644165
Validation loss: 1.9643811115654566

Epoch: 5| Step: 4
Training loss: 1.11223566532135
Validation loss: 1.962881148502391

Epoch: 5| Step: 5
Training loss: 1.142687439918518
Validation loss: 1.946448831148045

Epoch: 5| Step: 6
Training loss: 0.95555180311203
Validation loss: 1.915943048333609

Epoch: 5| Step: 7
Training loss: 1.2326265573501587
Validation loss: 1.9195403437460623

Epoch: 5| Step: 8
Training loss: 1.0938608646392822
Validation loss: 1.9310536525582755

Epoch: 5| Step: 9
Training loss: 1.0666710138320923
Validation loss: 1.9196637010061612

Epoch: 5| Step: 10
Training loss: 1.1972905397415161
Validation loss: 1.958685318628947

Epoch: 263| Step: 0
Training loss: 1.2499864101409912
Validation loss: 1.9580138844828452

Epoch: 5| Step: 1
Training loss: 1.0464074611663818
Validation loss: 2.0004880684678272

Epoch: 5| Step: 2
Training loss: 1.0695545673370361
Validation loss: 2.0302343278802852

Epoch: 5| Step: 3
Training loss: 1.5610148906707764
Validation loss: 2.0116401731327014

Epoch: 5| Step: 4
Training loss: 0.7881230115890503
Validation loss: 2.0280209792557584

Epoch: 5| Step: 5
Training loss: 1.0932536125183105
Validation loss: 2.0020775897528535

Epoch: 5| Step: 6
Training loss: 1.3811477422714233
Validation loss: 1.9558353090798983

Epoch: 5| Step: 7
Training loss: 1.3682215213775635
Validation loss: 1.9275200366973877

Epoch: 5| Step: 8
Training loss: 0.8658906817436218
Validation loss: 1.9320611287188787

Epoch: 5| Step: 9
Training loss: 0.6958105564117432
Validation loss: 1.888192968983804

Epoch: 5| Step: 10
Training loss: 1.0929104089736938
Validation loss: 1.8935430588260773

Epoch: 264| Step: 0
Training loss: 0.9300495386123657
Validation loss: 1.9274597834515315

Epoch: 5| Step: 1
Training loss: 0.7460964918136597
Validation loss: 1.9061133271904402

Epoch: 5| Step: 2
Training loss: 1.4017293453216553
Validation loss: 1.908539141378095

Epoch: 5| Step: 3
Training loss: 0.9732910990715027
Validation loss: 1.935256483734295

Epoch: 5| Step: 4
Training loss: 0.9058586359024048
Validation loss: 1.9271076443374797

Epoch: 5| Step: 5
Training loss: 1.2119996547698975
Validation loss: 1.9079633605095647

Epoch: 5| Step: 6
Training loss: 1.151743769645691
Validation loss: 1.9456667284811697

Epoch: 5| Step: 7
Training loss: 1.2189357280731201
Validation loss: 1.9223299180307696

Epoch: 5| Step: 8
Training loss: 1.133667230606079
Validation loss: 1.9308994982832222

Epoch: 5| Step: 9
Training loss: 1.4512827396392822
Validation loss: 1.9353329507253503

Epoch: 5| Step: 10
Training loss: 1.1076804399490356
Validation loss: 1.9476277956398584

Epoch: 265| Step: 0
Training loss: 0.7931593060493469
Validation loss: 1.9440064302054785

Epoch: 5| Step: 1
Training loss: 0.9902430772781372
Validation loss: 1.9319030572009344

Epoch: 5| Step: 2
Training loss: 1.0613365173339844
Validation loss: 1.9444145707673923

Epoch: 5| Step: 3
Training loss: 1.033137559890747
Validation loss: 1.9089267112875496

Epoch: 5| Step: 4
Training loss: 1.0453604459762573
Validation loss: 1.9125469192381828

Epoch: 5| Step: 5
Training loss: 1.1215342283248901
Validation loss: 1.9109460512797039

Epoch: 5| Step: 6
Training loss: 1.1738061904907227
Validation loss: 1.8930531740188599

Epoch: 5| Step: 7
Training loss: 1.014162302017212
Validation loss: 1.904756164038053

Epoch: 5| Step: 8
Training loss: 1.1409568786621094
Validation loss: 1.9425646053847445

Epoch: 5| Step: 9
Training loss: 1.068000078201294
Validation loss: 1.9358894568617626

Epoch: 5| Step: 10
Training loss: 1.5816503763198853
Validation loss: 1.9461654104212278

Epoch: 266| Step: 0
Training loss: 1.0037710666656494
Validation loss: 1.9709432227637178

Epoch: 5| Step: 1
Training loss: 0.9284024238586426
Validation loss: 1.949427104765369

Epoch: 5| Step: 2
Training loss: 1.1275007724761963
Validation loss: 1.9465700887864636

Epoch: 5| Step: 3
Training loss: 0.9708564877510071
Validation loss: 1.9308443543731526

Epoch: 5| Step: 4
Training loss: 1.4246737957000732
Validation loss: 1.9171535225324734

Epoch: 5| Step: 5
Training loss: 0.6277345418930054
Validation loss: 1.9056135416030884

Epoch: 5| Step: 6
Training loss: 1.3369135856628418
Validation loss: 1.8788256517020605

Epoch: 5| Step: 7
Training loss: 1.0648537874221802
Validation loss: 1.867260689376503

Epoch: 5| Step: 8
Training loss: 1.2223031520843506
Validation loss: 1.874733114755282

Epoch: 5| Step: 9
Training loss: 1.0340584516525269
Validation loss: 1.8978225851571688

Epoch: 5| Step: 10
Training loss: 1.1002330780029297
Validation loss: 1.9181004583194692

Epoch: 267| Step: 0
Training loss: 1.3214163780212402
Validation loss: 1.9342763808465773

Epoch: 5| Step: 1
Training loss: 1.1237331628799438
Validation loss: 1.943569432022751

Epoch: 5| Step: 2
Training loss: 0.9143751263618469
Validation loss: 1.9502784975113407

Epoch: 5| Step: 3
Training loss: 1.246037483215332
Validation loss: 1.952306632072695

Epoch: 5| Step: 4
Training loss: 0.9588581323623657
Validation loss: 1.9371771402256464

Epoch: 5| Step: 5
Training loss: 0.9858759641647339
Validation loss: 1.9286528325849963

Epoch: 5| Step: 6
Training loss: 1.3266868591308594
Validation loss: 1.9317927386171074

Epoch: 5| Step: 7
Training loss: 1.0886279344558716
Validation loss: 1.9360157341085455

Epoch: 5| Step: 8
Training loss: 0.7787120342254639
Validation loss: 1.8995466783482542

Epoch: 5| Step: 9
Training loss: 1.4506580829620361
Validation loss: 1.895098990009677

Epoch: 5| Step: 10
Training loss: 0.44731953740119934
Validation loss: 1.9016983932064426

Epoch: 268| Step: 0
Training loss: 0.7227377891540527
Validation loss: 1.8926322883175266

Epoch: 5| Step: 1
Training loss: 1.0686856508255005
Validation loss: 1.9283732175827026

Epoch: 5| Step: 2
Training loss: 1.201333999633789
Validation loss: 1.9665618019719278

Epoch: 5| Step: 3
Training loss: 1.3083103895187378
Validation loss: 1.9753453270081551

Epoch: 5| Step: 4
Training loss: 1.2532628774642944
Validation loss: 1.968512632513559

Epoch: 5| Step: 5
Training loss: 0.8883659243583679
Validation loss: 1.9591074592323714

Epoch: 5| Step: 6
Training loss: 0.955898106098175
Validation loss: 1.940170414986149

Epoch: 5| Step: 7
Training loss: 1.4419519901275635
Validation loss: 1.9474938172166065

Epoch: 5| Step: 8
Training loss: 1.0295883417129517
Validation loss: 1.936516531052128

Epoch: 5| Step: 9
Training loss: 0.8800568580627441
Validation loss: 1.9368671037817513

Epoch: 5| Step: 10
Training loss: 0.9951647520065308
Validation loss: 1.9331065967518797

Epoch: 269| Step: 0
Training loss: 1.415239691734314
Validation loss: 1.9433302315332557

Epoch: 5| Step: 1
Training loss: 1.2350127696990967
Validation loss: 1.9684832275554698

Epoch: 5| Step: 2
Training loss: 1.305968999862671
Validation loss: 1.9479060173034668

Epoch: 5| Step: 3
Training loss: 1.3397157192230225
Validation loss: 1.9391642565368323

Epoch: 5| Step: 4
Training loss: 1.3994426727294922
Validation loss: 1.913089898324782

Epoch: 5| Step: 5
Training loss: 0.6244311928749084
Validation loss: 1.8679731481818742

Epoch: 5| Step: 6
Training loss: 1.0377743244171143
Validation loss: 1.86278824908759

Epoch: 5| Step: 7
Training loss: 0.9518102407455444
Validation loss: 1.879260898918234

Epoch: 5| Step: 8
Training loss: 0.826686680316925
Validation loss: 1.8764660640429425

Epoch: 5| Step: 9
Training loss: 0.8450281023979187
Validation loss: 1.9099301420232302

Epoch: 5| Step: 10
Training loss: 0.734660267829895
Validation loss: 1.9084035094066332

Epoch: 270| Step: 0
Training loss: 0.9286012649536133
Validation loss: 1.9358931433769964

Epoch: 5| Step: 1
Training loss: 1.2539737224578857
Validation loss: 1.9288088967723231

Epoch: 5| Step: 2
Training loss: 1.0365129709243774
Validation loss: 1.951906709260838

Epoch: 5| Step: 3
Training loss: 0.8056539297103882
Validation loss: 1.942208751555412

Epoch: 5| Step: 4
Training loss: 1.4168988466262817
Validation loss: 1.9356414848758328

Epoch: 5| Step: 5
Training loss: 1.2488489151000977
Validation loss: 1.9204953819192865

Epoch: 5| Step: 6
Training loss: 1.0418914556503296
Validation loss: 1.9105269242358465

Epoch: 5| Step: 7
Training loss: 1.2479050159454346
Validation loss: 1.9065286920916649

Epoch: 5| Step: 8
Training loss: 0.8567380905151367
Validation loss: 1.8990690644069383

Epoch: 5| Step: 9
Training loss: 1.0420916080474854
Validation loss: 1.8850632790596253

Epoch: 5| Step: 10
Training loss: 0.7282765507698059
Validation loss: 1.8766842452428674

Epoch: 271| Step: 0
Training loss: 0.6735869646072388
Validation loss: 1.9083074472283805

Epoch: 5| Step: 1
Training loss: 0.8268682360649109
Validation loss: 1.9448555156748781

Epoch: 5| Step: 2
Training loss: 1.146066665649414
Validation loss: 1.9541247685750325

Epoch: 5| Step: 3
Training loss: 0.8780587911605835
Validation loss: 1.9460789875317646

Epoch: 5| Step: 4
Training loss: 1.5440930128097534
Validation loss: 1.940796636766003

Epoch: 5| Step: 5
Training loss: 1.0863573551177979
Validation loss: 1.9236564046593123

Epoch: 5| Step: 6
Training loss: 1.0677125453948975
Validation loss: 1.8994911191284016

Epoch: 5| Step: 7
Training loss: 1.002906322479248
Validation loss: 1.8651153708017

Epoch: 5| Step: 8
Training loss: 0.8265325427055359
Validation loss: 1.868764897828461

Epoch: 5| Step: 9
Training loss: 1.3320704698562622
Validation loss: 1.8841539441898305

Epoch: 5| Step: 10
Training loss: 1.0225825309753418
Validation loss: 1.8620120645851217

Epoch: 272| Step: 0
Training loss: 1.0897109508514404
Validation loss: 1.8602472453989007

Epoch: 5| Step: 1
Training loss: 0.5607816576957703
Validation loss: 1.837427375137165

Epoch: 5| Step: 2
Training loss: 0.817102313041687
Validation loss: 1.889841128421086

Epoch: 5| Step: 3
Training loss: 1.1304724216461182
Validation loss: 1.9128880513611661

Epoch: 5| Step: 4
Training loss: 1.263237476348877
Validation loss: 1.9510212508581017

Epoch: 5| Step: 5
Training loss: 0.8671303987503052
Validation loss: 1.991001925160808

Epoch: 5| Step: 6
Training loss: 0.7693984508514404
Validation loss: 1.9687336952455583

Epoch: 5| Step: 7
Training loss: 1.488532543182373
Validation loss: 1.9626904008209065

Epoch: 5| Step: 8
Training loss: 1.3581665754318237
Validation loss: 1.9373394494415612

Epoch: 5| Step: 9
Training loss: 0.9930793642997742
Validation loss: 1.9059747137049192

Epoch: 5| Step: 10
Training loss: 0.9821810722351074
Validation loss: 1.9020846377136886

Epoch: 273| Step: 0
Training loss: 0.9403276443481445
Validation loss: 1.8688191829189178

Epoch: 5| Step: 1
Training loss: 0.9541869163513184
Validation loss: 1.897146632594447

Epoch: 5| Step: 2
Training loss: 0.6834993958473206
Validation loss: 1.8815418366462953

Epoch: 5| Step: 3
Training loss: 0.8573185205459595
Validation loss: 1.9034949438546294

Epoch: 5| Step: 4
Training loss: 0.8936389684677124
Validation loss: 1.9102136947775399

Epoch: 5| Step: 5
Training loss: 0.9564964175224304
Validation loss: 1.9121267975017588

Epoch: 5| Step: 6
Training loss: 1.2296993732452393
Validation loss: 1.8976521786823068

Epoch: 5| Step: 7
Training loss: 1.1732711791992188
Validation loss: 1.9183800810126848

Epoch: 5| Step: 8
Training loss: 0.9221096038818359
Validation loss: 1.907026760039791

Epoch: 5| Step: 9
Training loss: 1.327476143836975
Validation loss: 1.914504825427968

Epoch: 5| Step: 10
Training loss: 1.2884211540222168
Validation loss: 1.9324796558708273

Epoch: 274| Step: 0
Training loss: 0.9429197311401367
Validation loss: 1.9306035913446897

Epoch: 5| Step: 1
Training loss: 1.2826488018035889
Validation loss: 1.9058982646593483

Epoch: 5| Step: 2
Training loss: 0.8710107803344727
Validation loss: 1.9028213562503937

Epoch: 5| Step: 3
Training loss: 1.4191768169403076
Validation loss: 1.8786199682502336

Epoch: 5| Step: 4
Training loss: 0.7835649251937866
Validation loss: 1.8787003153113908

Epoch: 5| Step: 5
Training loss: 0.9119448661804199
Validation loss: 1.8713030597215057

Epoch: 5| Step: 6
Training loss: 1.3336577415466309
Validation loss: 1.873808442905385

Epoch: 5| Step: 7
Training loss: 0.8218334317207336
Validation loss: 1.8847213573353265

Epoch: 5| Step: 8
Training loss: 0.5672610998153687
Validation loss: 1.9115193325986144

Epoch: 5| Step: 9
Training loss: 0.9270709156990051
Validation loss: 1.9399190218217912

Epoch: 5| Step: 10
Training loss: 1.1108453273773193
Validation loss: 1.9338072217920774

Epoch: 275| Step: 0
Training loss: 0.4198049008846283
Validation loss: 1.9686616492527786

Epoch: 5| Step: 1
Training loss: 0.9382859468460083
Validation loss: 1.9469500844196608

Epoch: 5| Step: 2
Training loss: 1.0079686641693115
Validation loss: 1.9354900640826072

Epoch: 5| Step: 3
Training loss: 0.8700481653213501
Validation loss: 1.933904981100431

Epoch: 5| Step: 4
Training loss: 1.5541812181472778
Validation loss: 1.9263070014215284

Epoch: 5| Step: 5
Training loss: 1.0076167583465576
Validation loss: 1.9100479669468378

Epoch: 5| Step: 6
Training loss: 0.914525032043457
Validation loss: 1.9046384467873523

Epoch: 5| Step: 7
Training loss: 1.117254614830017
Validation loss: 1.9001005464984524

Epoch: 5| Step: 8
Training loss: 0.973084568977356
Validation loss: 1.873276202909408

Epoch: 5| Step: 9
Training loss: 1.089803695678711
Validation loss: 1.8948722782955374

Epoch: 5| Step: 10
Training loss: 0.8458647727966309
Validation loss: 1.8882290073620376

Epoch: 276| Step: 0
Training loss: 1.0422430038452148
Validation loss: 1.8773021364724765

Epoch: 5| Step: 1
Training loss: 1.205786108970642
Validation loss: 1.8958307491835726

Epoch: 5| Step: 2
Training loss: 1.486647367477417
Validation loss: 1.9298141951202064

Epoch: 5| Step: 3
Training loss: 0.7046077251434326
Validation loss: 1.9553633505298245

Epoch: 5| Step: 4
Training loss: 1.3099513053894043
Validation loss: 1.9582479705092728

Epoch: 5| Step: 5
Training loss: 0.6700451970100403
Validation loss: 1.977968208251461

Epoch: 5| Step: 6
Training loss: 0.8386508226394653
Validation loss: 1.9464216712982423

Epoch: 5| Step: 7
Training loss: 0.9051529169082642
Validation loss: 1.937577324528848

Epoch: 5| Step: 8
Training loss: 0.5853497385978699
Validation loss: 1.9109710467759

Epoch: 5| Step: 9
Training loss: 0.9718710780143738
Validation loss: 1.9282779155238983

Epoch: 5| Step: 10
Training loss: 0.992475152015686
Validation loss: 1.9334256533653504

Epoch: 277| Step: 0
Training loss: 1.0611869096755981
Validation loss: 1.9125387335336337

Epoch: 5| Step: 1
Training loss: 0.9922659993171692
Validation loss: 1.9426379280705606

Epoch: 5| Step: 2
Training loss: 1.0858280658721924
Validation loss: 1.9250866225970689

Epoch: 5| Step: 3
Training loss: 1.2610108852386475
Validation loss: 1.8949659639789211

Epoch: 5| Step: 4
Training loss: 0.5764066576957703
Validation loss: 1.9229013573738836

Epoch: 5| Step: 5
Training loss: 0.8428783416748047
Validation loss: 1.9223030869678785

Epoch: 5| Step: 6
Training loss: 0.6547949910163879
Validation loss: 1.9339022995323263

Epoch: 5| Step: 7
Training loss: 1.1627063751220703
Validation loss: 1.9577111556965818

Epoch: 5| Step: 8
Training loss: 0.8414657711982727
Validation loss: 1.9104226635348411

Epoch: 5| Step: 9
Training loss: 0.9557228088378906
Validation loss: 1.9021197941995436

Epoch: 5| Step: 10
Training loss: 1.3184080123901367
Validation loss: 1.8982498056145125

Epoch: 278| Step: 0
Training loss: 1.2573628425598145
Validation loss: 1.905305148452841

Epoch: 5| Step: 1
Training loss: 0.7947268486022949
Validation loss: 1.8832132483041415

Epoch: 5| Step: 2
Training loss: 1.2379062175750732
Validation loss: 1.86011452187774

Epoch: 5| Step: 3
Training loss: 0.8689780235290527
Validation loss: 1.8511507793139386

Epoch: 5| Step: 4
Training loss: 1.2554357051849365
Validation loss: 1.8905749423529512

Epoch: 5| Step: 5
Training loss: 1.0638993978500366
Validation loss: 1.8852440131607877

Epoch: 5| Step: 6
Training loss: 0.5895563960075378
Validation loss: 1.90122180087592

Epoch: 5| Step: 7
Training loss: 1.0090992450714111
Validation loss: 1.9301513100183139

Epoch: 5| Step: 8
Training loss: 1.071510910987854
Validation loss: 1.964571810537769

Epoch: 5| Step: 9
Training loss: 0.8370858430862427
Validation loss: 1.939641628214108

Epoch: 5| Step: 10
Training loss: 0.5603034496307373
Validation loss: 1.9492343266805012

Epoch: 279| Step: 0
Training loss: 1.0057687759399414
Validation loss: 1.9395342642261135

Epoch: 5| Step: 1
Training loss: 1.0332376956939697
Validation loss: 1.9425407712177565

Epoch: 5| Step: 2
Training loss: 1.4003379344940186
Validation loss: 1.9342742594339515

Epoch: 5| Step: 3
Training loss: 0.6685799956321716
Validation loss: 1.9256625188294278

Epoch: 5| Step: 4
Training loss: 1.13664710521698
Validation loss: 1.915931873424079

Epoch: 5| Step: 5
Training loss: 0.7868753671646118
Validation loss: 1.8857215835202126

Epoch: 5| Step: 6
Training loss: 0.7444080114364624
Validation loss: 1.8763039650455597

Epoch: 5| Step: 7
Training loss: 0.7549190521240234
Validation loss: 1.8868529822236748

Epoch: 5| Step: 8
Training loss: 1.2877488136291504
Validation loss: 1.8797932465871174

Epoch: 5| Step: 9
Training loss: 0.9630104899406433
Validation loss: 1.8808347909681258

Epoch: 5| Step: 10
Training loss: 0.7543585300445557
Validation loss: 1.9309989944581063

Epoch: 280| Step: 0
Training loss: 0.9104012250900269
Validation loss: 1.9152295474083192

Epoch: 5| Step: 1
Training loss: 0.9239313006401062
Validation loss: 1.927403901212959

Epoch: 5| Step: 2
Training loss: 1.4148328304290771
Validation loss: 1.8973407283906014

Epoch: 5| Step: 3
Training loss: 1.0556398630142212
Validation loss: 1.916176695977488

Epoch: 5| Step: 4
Training loss: 0.7050545811653137
Validation loss: 1.9134196978743359

Epoch: 5| Step: 5
Training loss: 0.817158043384552
Validation loss: 1.8950467917226976

Epoch: 5| Step: 6
Training loss: 0.7702630758285522
Validation loss: 1.8703901524184852

Epoch: 5| Step: 7
Training loss: 1.3152419328689575
Validation loss: 1.875907677476124

Epoch: 5| Step: 8
Training loss: 0.8874704241752625
Validation loss: 1.8557643595562185

Epoch: 5| Step: 9
Training loss: 0.7226070165634155
Validation loss: 1.842517428500678

Epoch: 5| Step: 10
Training loss: 0.8158250451087952
Validation loss: 1.8336153953306136

Epoch: 281| Step: 0
Training loss: 0.7466586232185364
Validation loss: 1.8682538501677974

Epoch: 5| Step: 1
Training loss: 0.6421027779579163
Validation loss: 1.9144841753026491

Epoch: 5| Step: 2
Training loss: 1.0194586515426636
Validation loss: 1.9566027374677761

Epoch: 5| Step: 3
Training loss: 1.0083084106445312
Validation loss: 1.9854831387919765

Epoch: 5| Step: 4
Training loss: 0.9544489979743958
Validation loss: 1.9751402126845492

Epoch: 5| Step: 5
Training loss: 1.2278894186019897
Validation loss: 1.9791611086937688

Epoch: 5| Step: 6
Training loss: 1.0244200229644775
Validation loss: 1.97252780647688

Epoch: 5| Step: 7
Training loss: 1.1903188228607178
Validation loss: 1.9761246532522223

Epoch: 5| Step: 8
Training loss: 0.8502968549728394
Validation loss: 1.9481322996077999

Epoch: 5| Step: 9
Training loss: 1.0647423267364502
Validation loss: 1.9280926155787643

Epoch: 5| Step: 10
Training loss: 0.7289667725563049
Validation loss: 1.87854887336813

Epoch: 282| Step: 0
Training loss: 1.0249922275543213
Validation loss: 1.8972121002853557

Epoch: 5| Step: 1
Training loss: 0.5306956768035889
Validation loss: 1.919398723110076

Epoch: 5| Step: 2
Training loss: 1.2402360439300537
Validation loss: 1.9444703209784724

Epoch: 5| Step: 3
Training loss: 0.9899512529373169
Validation loss: 1.913938783830212

Epoch: 5| Step: 4
Training loss: 0.8495526313781738
Validation loss: 1.9353540020604287

Epoch: 5| Step: 5
Training loss: 0.5200895071029663
Validation loss: 1.882861328381364

Epoch: 5| Step: 6
Training loss: 1.227548599243164
Validation loss: 1.8966005668845227

Epoch: 5| Step: 7
Training loss: 1.2138439416885376
Validation loss: 1.9154004537931053

Epoch: 5| Step: 8
Training loss: 1.069248080253601
Validation loss: 1.906926211490426

Epoch: 5| Step: 9
Training loss: 0.5693982839584351
Validation loss: 1.9006750865649151

Epoch: 5| Step: 10
Training loss: 1.205031394958496
Validation loss: 1.8950599547355407

Epoch: 283| Step: 0
Training loss: 0.8838285207748413
Validation loss: 1.8783853323228898

Epoch: 5| Step: 1
Training loss: 0.997116208076477
Validation loss: 1.8778935311942972

Epoch: 5| Step: 2
Training loss: 0.8746814727783203
Validation loss: 1.8403215331415976

Epoch: 5| Step: 3
Training loss: 0.5669292211532593
Validation loss: 1.8363592009390555

Epoch: 5| Step: 4
Training loss: 0.9714282155036926
Validation loss: 1.8210801091245425

Epoch: 5| Step: 5
Training loss: 1.0838987827301025
Validation loss: 1.8369401539525678

Epoch: 5| Step: 6
Training loss: 1.0070348978042603
Validation loss: 1.8314971321372575

Epoch: 5| Step: 7
Training loss: 1.28020441532135
Validation loss: 1.8560602229128602

Epoch: 5| Step: 8
Training loss: 1.1962515115737915
Validation loss: 1.8715418154193508

Epoch: 5| Step: 9
Training loss: 0.9158061146736145
Validation loss: 1.8809283394967355

Epoch: 5| Step: 10
Training loss: 0.8202784061431885
Validation loss: 1.9288578661539222

Epoch: 284| Step: 0
Training loss: 0.8608518838882446
Validation loss: 2.0040321914098596

Epoch: 5| Step: 1
Training loss: 0.7255417108535767
Validation loss: 1.9785410460605417

Epoch: 5| Step: 2
Training loss: 0.6608640551567078
Validation loss: 1.9077754930783344

Epoch: 5| Step: 3
Training loss: 1.3539412021636963
Validation loss: 1.8589249913410475

Epoch: 5| Step: 4
Training loss: 1.180631160736084
Validation loss: 1.8303699467771797

Epoch: 5| Step: 5
Training loss: 1.1103647947311401
Validation loss: 1.807207404926259

Epoch: 5| Step: 6
Training loss: 1.1145811080932617
Validation loss: 1.7999239570351058

Epoch: 5| Step: 7
Training loss: 0.8479520082473755
Validation loss: 1.7844238101795156

Epoch: 5| Step: 8
Training loss: 0.8676818013191223
Validation loss: 1.8048353092644804

Epoch: 5| Step: 9
Training loss: 0.8648732900619507
Validation loss: 1.8152250910318026

Epoch: 5| Step: 10
Training loss: 1.035387396812439
Validation loss: 1.8434817432075419

Epoch: 285| Step: 0
Training loss: 0.8323081731796265
Validation loss: 1.8418497257335211

Epoch: 5| Step: 1
Training loss: 1.0562303066253662
Validation loss: 1.8363026880448865

Epoch: 5| Step: 2
Training loss: 1.042172908782959
Validation loss: 1.8541379064641974

Epoch: 5| Step: 3
Training loss: 0.583847165107727
Validation loss: 1.8384390159319806

Epoch: 5| Step: 4
Training loss: 0.9719427227973938
Validation loss: 1.852709371556518

Epoch: 5| Step: 5
Training loss: 1.0429744720458984
Validation loss: 1.863979419072469

Epoch: 5| Step: 6
Training loss: 0.574108898639679
Validation loss: 1.8646990509443386

Epoch: 5| Step: 7
Training loss: 1.6740753650665283
Validation loss: 1.9087783726312781

Epoch: 5| Step: 8
Training loss: 0.7459169626235962
Validation loss: 1.8785058964965164

Epoch: 5| Step: 9
Training loss: 0.8436811566352844
Validation loss: 1.9028563422541465

Epoch: 5| Step: 10
Training loss: 0.8103146553039551
Validation loss: 1.8830295557616858

Epoch: 286| Step: 0
Training loss: 1.616162657737732
Validation loss: 1.8746430168869674

Epoch: 5| Step: 1
Training loss: 0.5151396989822388
Validation loss: 1.8922808093409385

Epoch: 5| Step: 2
Training loss: 0.817977786064148
Validation loss: 1.8688723579529793

Epoch: 5| Step: 3
Training loss: 1.0129584074020386
Validation loss: 1.8477048053536365

Epoch: 5| Step: 4
Training loss: 0.7179988026618958
Validation loss: 1.8621848347366496

Epoch: 5| Step: 5
Training loss: 1.0724884271621704
Validation loss: 1.8807182414557344

Epoch: 5| Step: 6
Training loss: 0.906472384929657
Validation loss: 1.8435343901316326

Epoch: 5| Step: 7
Training loss: 0.9461911916732788
Validation loss: 1.8423485345737909

Epoch: 5| Step: 8
Training loss: 1.1706346273422241
Validation loss: 1.8923720364929528

Epoch: 5| Step: 9
Training loss: 0.7770568132400513
Validation loss: 1.895445357086838

Epoch: 5| Step: 10
Training loss: 0.42670002579689026
Validation loss: 1.8830479421923239

Epoch: 287| Step: 0
Training loss: 0.7662534713745117
Validation loss: 1.8837031241386168

Epoch: 5| Step: 1
Training loss: 0.8950554132461548
Validation loss: 1.8750007614012687

Epoch: 5| Step: 2
Training loss: 1.1725807189941406
Validation loss: 1.8781142747530373

Epoch: 5| Step: 3
Training loss: 0.9524334669113159
Validation loss: 1.8685038935753606

Epoch: 5| Step: 4
Training loss: 0.9756887555122375
Validation loss: 1.9032146546148485

Epoch: 5| Step: 5
Training loss: 0.8763130307197571
Validation loss: 1.8892290592193604

Epoch: 5| Step: 6
Training loss: 1.0118476152420044
Validation loss: 1.8751840027429725

Epoch: 5| Step: 7
Training loss: 0.7780838012695312
Validation loss: 1.8680990678007885

Epoch: 5| Step: 8
Training loss: 1.009982943534851
Validation loss: 1.8542437450860136

Epoch: 5| Step: 9
Training loss: 0.6791980266571045
Validation loss: 1.8575730195609472

Epoch: 5| Step: 10
Training loss: 0.9781294465065002
Validation loss: 1.8825342001453522

Epoch: 288| Step: 0
Training loss: 1.2356637716293335
Validation loss: 1.8569770346405685

Epoch: 5| Step: 1
Training loss: 0.7917722463607788
Validation loss: 1.8742641338738062

Epoch: 5| Step: 2
Training loss: 1.029036045074463
Validation loss: 1.8494269078777683

Epoch: 5| Step: 3
Training loss: 1.11008620262146
Validation loss: 1.8448763201313634

Epoch: 5| Step: 4
Training loss: 1.1909139156341553
Validation loss: 1.822450444262515

Epoch: 5| Step: 5
Training loss: 0.5068849325180054
Validation loss: 1.8199194656905306

Epoch: 5| Step: 6
Training loss: 1.018691062927246
Validation loss: 1.7986347316413798

Epoch: 5| Step: 7
Training loss: 0.9662187695503235
Validation loss: 1.816611651451357

Epoch: 5| Step: 8
Training loss: 0.7785079479217529
Validation loss: 1.835909849853926

Epoch: 5| Step: 9
Training loss: 0.9155460596084595
Validation loss: 1.8672206222370107

Epoch: 5| Step: 10
Training loss: 0.5587778687477112
Validation loss: 1.9075992863665345

Epoch: 289| Step: 0
Training loss: 1.0264683961868286
Validation loss: 1.9561608927224272

Epoch: 5| Step: 1
Training loss: 0.9071090817451477
Validation loss: 1.991054279829866

Epoch: 5| Step: 2
Training loss: 0.8015927076339722
Validation loss: 1.932078912693967

Epoch: 5| Step: 3
Training loss: 0.9414151310920715
Validation loss: 1.912209705639911

Epoch: 5| Step: 4
Training loss: 1.1014114618301392
Validation loss: 1.882339362175234

Epoch: 5| Step: 5
Training loss: 0.7994261980056763
Validation loss: 1.8523386396387571

Epoch: 5| Step: 6
Training loss: 1.1960160732269287
Validation loss: 1.837916660052474

Epoch: 5| Step: 7
Training loss: 0.7956334352493286
Validation loss: 1.8201579329788045

Epoch: 5| Step: 8
Training loss: 0.8648662567138672
Validation loss: 1.8255915052147322

Epoch: 5| Step: 9
Training loss: 0.970109760761261
Validation loss: 1.8723917289446759

Epoch: 5| Step: 10
Training loss: 0.9815183281898499
Validation loss: 1.8712716102600098

Epoch: 290| Step: 0
Training loss: 0.823539137840271
Validation loss: 1.8903399052158478

Epoch: 5| Step: 1
Training loss: 0.6848835945129395
Validation loss: 1.8933145294907272

Epoch: 5| Step: 2
Training loss: 0.8567838668823242
Validation loss: 1.8786345784382155

Epoch: 5| Step: 3
Training loss: 1.2827309370040894
Validation loss: 1.8901342192003805

Epoch: 5| Step: 4
Training loss: 1.0812468528747559
Validation loss: 1.8938090673056982

Epoch: 5| Step: 5
Training loss: 1.0243620872497559
Validation loss: 1.8812253577734834

Epoch: 5| Step: 6
Training loss: 0.7103105783462524
Validation loss: 1.8686423570879045

Epoch: 5| Step: 7
Training loss: 0.7292963862419128
Validation loss: 1.8717904167790567

Epoch: 5| Step: 8
Training loss: 0.9438046216964722
Validation loss: 1.8815215851670952

Epoch: 5| Step: 9
Training loss: 1.1006686687469482
Validation loss: 1.9000035344913442

Epoch: 5| Step: 10
Training loss: 1.0710327625274658
Validation loss: 1.9321364202807028

Epoch: 291| Step: 0
Training loss: 1.3062465190887451
Validation loss: 1.9018804373279694

Epoch: 5| Step: 1
Training loss: 0.588699996471405
Validation loss: 1.8791113745781682

Epoch: 5| Step: 2
Training loss: 0.9801009893417358
Validation loss: 1.8418335517247517

Epoch: 5| Step: 3
Training loss: 0.5054785013198853
Validation loss: 1.8689816369805285

Epoch: 5| Step: 4
Training loss: 1.0226311683654785
Validation loss: 1.8717059473837576

Epoch: 5| Step: 5
Training loss: 1.0230095386505127
Validation loss: 1.8934216268600956

Epoch: 5| Step: 6
Training loss: 0.9607365727424622
Validation loss: 1.8930665382774927

Epoch: 5| Step: 7
Training loss: 1.1770093441009521
Validation loss: 1.896489292062739

Epoch: 5| Step: 8
Training loss: 0.9810370206832886
Validation loss: 1.9063170558662825

Epoch: 5| Step: 9
Training loss: 0.7338917851448059
Validation loss: 1.8753717343012493

Epoch: 5| Step: 10
Training loss: 0.9470394253730774
Validation loss: 1.874590822445449

Epoch: 292| Step: 0
Training loss: 0.7492036819458008
Validation loss: 1.8429596078011297

Epoch: 5| Step: 1
Training loss: 0.8243941068649292
Validation loss: 1.8096599117402108

Epoch: 5| Step: 2
Training loss: 0.8082809448242188
Validation loss: 1.7925375353905462

Epoch: 5| Step: 3
Training loss: 0.6986043453216553
Validation loss: 1.8106857576677877

Epoch: 5| Step: 4
Training loss: 0.9070748090744019
Validation loss: 1.8510703937981718

Epoch: 5| Step: 5
Training loss: 1.1269268989562988
Validation loss: 1.8623595904278498

Epoch: 5| Step: 6
Training loss: 1.093215823173523
Validation loss: 1.9026390737102878

Epoch: 5| Step: 7
Training loss: 0.5437192916870117
Validation loss: 1.9111715106553928

Epoch: 5| Step: 8
Training loss: 1.1246658563613892
Validation loss: 1.9675091517868863

Epoch: 5| Step: 9
Training loss: 1.0491206645965576
Validation loss: 1.969687359307402

Epoch: 5| Step: 10
Training loss: 1.1481835842132568
Validation loss: 1.9441644709597352

Epoch: 293| Step: 0
Training loss: 1.1182092428207397
Validation loss: 1.9049379543591571

Epoch: 5| Step: 1
Training loss: 0.7807449102401733
Validation loss: 1.8778724337136874

Epoch: 5| Step: 2
Training loss: 1.2598978281021118
Validation loss: 1.8425990868640203

Epoch: 5| Step: 3
Training loss: 0.5982108116149902
Validation loss: 1.8462412780331028

Epoch: 5| Step: 4
Training loss: 1.3518152236938477
Validation loss: 1.8376281876717844

Epoch: 5| Step: 5
Training loss: 0.773155927658081
Validation loss: 1.849353512128194

Epoch: 5| Step: 6
Training loss: 0.8393150568008423
Validation loss: 1.821067202475763

Epoch: 5| Step: 7
Training loss: 0.6592333316802979
Validation loss: 1.8595885845922655

Epoch: 5| Step: 8
Training loss: 0.802631676197052
Validation loss: 1.9066810479728125

Epoch: 5| Step: 9
Training loss: 1.0368645191192627
Validation loss: 1.9387804436427292

Epoch: 5| Step: 10
Training loss: 0.6067335605621338
Validation loss: 1.889654585110244

Epoch: 294| Step: 0
Training loss: 1.1434376239776611
Validation loss: 1.8833902266717726

Epoch: 5| Step: 1
Training loss: 0.6014001965522766
Validation loss: 1.861816055031233

Epoch: 5| Step: 2
Training loss: 1.1518088579177856
Validation loss: 1.8722794196938957

Epoch: 5| Step: 3
Training loss: 1.2792775630950928
Validation loss: 1.8655418606214627

Epoch: 5| Step: 4
Training loss: 0.9230440855026245
Validation loss: 1.8590439904120661

Epoch: 5| Step: 5
Training loss: 0.9598367810249329
Validation loss: 1.8616428503426172

Epoch: 5| Step: 6
Training loss: 0.9454971551895142
Validation loss: 1.9429035545677267

Epoch: 5| Step: 7
Training loss: 0.7395596504211426
Validation loss: 1.951681403703587

Epoch: 5| Step: 8
Training loss: 0.6519865989685059
Validation loss: 1.9606662001661075

Epoch: 5| Step: 9
Training loss: 0.8543715476989746
Validation loss: 1.9195234096178444

Epoch: 5| Step: 10
Training loss: 1.0595571994781494
Validation loss: 1.8614522257158834

Epoch: 295| Step: 0
Training loss: 1.0272822380065918
Validation loss: 1.8799885575489332

Epoch: 5| Step: 1
Training loss: 1.2032153606414795
Validation loss: 1.9262438051162227

Epoch: 5| Step: 2
Training loss: 1.1016403436660767
Validation loss: 1.8906554868144374

Epoch: 5| Step: 3
Training loss: 0.7155253291130066
Validation loss: 1.8865060383273708

Epoch: 5| Step: 4
Training loss: 0.6820254921913147
Validation loss: 1.8790985307385843

Epoch: 5| Step: 5
Training loss: 0.7356103658676147
Validation loss: 1.8919588724772136

Epoch: 5| Step: 6
Training loss: 1.1867893934249878
Validation loss: 1.8967992862065632

Epoch: 5| Step: 7
Training loss: 0.6417984962463379
Validation loss: 1.9269479577259352

Epoch: 5| Step: 8
Training loss: 0.9125993847846985
Validation loss: 1.9546265832839473

Epoch: 5| Step: 9
Training loss: 0.902989387512207
Validation loss: 1.9412671930046492

Epoch: 5| Step: 10
Training loss: 1.0082987546920776
Validation loss: 1.9460740371416974

Epoch: 296| Step: 0
Training loss: 0.8617281913757324
Validation loss: 1.919295234064902

Epoch: 5| Step: 1
Training loss: 1.0280870199203491
Validation loss: 1.9098790243107786

Epoch: 5| Step: 2
Training loss: 0.8274707794189453
Validation loss: 1.8853420352423063

Epoch: 5| Step: 3
Training loss: 0.8258768916130066
Validation loss: 1.8689699711338166

Epoch: 5| Step: 4
Training loss: 0.9952551126480103
Validation loss: 1.8681282099857126

Epoch: 5| Step: 5
Training loss: 0.868606448173523
Validation loss: 1.8747630452597013

Epoch: 5| Step: 6
Training loss: 0.9113714098930359
Validation loss: 1.8815334150868077

Epoch: 5| Step: 7
Training loss: 0.9570072293281555
Validation loss: 1.8583202515878985

Epoch: 5| Step: 8
Training loss: 0.9382174611091614
Validation loss: 1.8659501614109162

Epoch: 5| Step: 9
Training loss: 0.7173325419425964
Validation loss: 1.8857341338229436

Epoch: 5| Step: 10
Training loss: 0.6785945892333984
Validation loss: 1.9103402322338474

Epoch: 297| Step: 0
Training loss: 0.992702305316925
Validation loss: 1.984947830118159

Epoch: 5| Step: 1
Training loss: 1.0066978931427002
Validation loss: 1.9741304023291475

Epoch: 5| Step: 2
Training loss: 0.8513253927230835
Validation loss: 1.943454888559157

Epoch: 5| Step: 3
Training loss: 0.4220147132873535
Validation loss: 1.8896414374792447

Epoch: 5| Step: 4
Training loss: 0.795970618724823
Validation loss: 1.8691831365708382

Epoch: 5| Step: 5
Training loss: 0.681136965751648
Validation loss: 1.8430980059408373

Epoch: 5| Step: 6
Training loss: 1.28550124168396
Validation loss: 1.8486066582382366

Epoch: 5| Step: 7
Training loss: 1.413701057434082
Validation loss: 1.8747667420294978

Epoch: 5| Step: 8
Training loss: 0.9263268709182739
Validation loss: 1.904182408445625

Epoch: 5| Step: 9
Training loss: 1.1996718645095825
Validation loss: 1.8842366010912004

Epoch: 5| Step: 10
Training loss: 0.580035924911499
Validation loss: 1.8906972151930614

Epoch: 298| Step: 0
Training loss: 0.4332819879055023
Validation loss: 1.9143439582599107

Epoch: 5| Step: 1
Training loss: 0.5250482559204102
Validation loss: 1.900419835121401

Epoch: 5| Step: 2
Training loss: 1.1296528577804565
Validation loss: 1.8969143590619486

Epoch: 5| Step: 3
Training loss: 1.2524585723876953
Validation loss: 1.8902754501629901

Epoch: 5| Step: 4
Training loss: 0.6590734720230103
Validation loss: 1.8641658457376624

Epoch: 5| Step: 5
Training loss: 0.8820420503616333
Validation loss: 1.875408136716453

Epoch: 5| Step: 6
Training loss: 0.9990450739860535
Validation loss: 1.852008205588146

Epoch: 5| Step: 7
Training loss: 0.7279534339904785
Validation loss: 1.8632707160006288

Epoch: 5| Step: 8
Training loss: 1.2395881414413452
Validation loss: 1.8721389257779686

Epoch: 5| Step: 9
Training loss: 0.9962723851203918
Validation loss: 1.8642149381740118

Epoch: 5| Step: 10
Training loss: 0.3673856258392334
Validation loss: 1.8583005935915056

Epoch: 299| Step: 0
Training loss: 0.9827896952629089
Validation loss: 1.8485855338394002

Epoch: 5| Step: 1
Training loss: 0.6888350248336792
Validation loss: 1.9051244335789834

Epoch: 5| Step: 2
Training loss: 0.543655514717102
Validation loss: 1.9190807906530236

Epoch: 5| Step: 3
Training loss: 0.9871085286140442
Validation loss: 1.9323084149309384

Epoch: 5| Step: 4
Training loss: 0.8641542196273804
Validation loss: 1.9255800426647227

Epoch: 5| Step: 5
Training loss: 0.8420325517654419
Validation loss: 1.9287386171279415

Epoch: 5| Step: 6
Training loss: 0.9840441942214966
Validation loss: 1.9132813125528314

Epoch: 5| Step: 7
Training loss: 1.157806158065796
Validation loss: 1.8926669923208093

Epoch: 5| Step: 8
Training loss: 0.37430813908576965
Validation loss: 1.876182504879531

Epoch: 5| Step: 9
Training loss: 0.956920325756073
Validation loss: 1.8588860240033878

Epoch: 5| Step: 10
Training loss: 1.105843186378479
Validation loss: 1.8615275095867854

Epoch: 300| Step: 0
Training loss: 1.3744075298309326
Validation loss: 1.8564988579801334

Epoch: 5| Step: 1
Training loss: 0.8441084027290344
Validation loss: 1.8418623990910028

Epoch: 5| Step: 2
Training loss: 0.7880053520202637
Validation loss: 1.834772099730789

Epoch: 5| Step: 3
Training loss: 1.1221641302108765
Validation loss: 1.8507725256745533

Epoch: 5| Step: 4
Training loss: 0.7511810064315796
Validation loss: 1.8285314331772506

Epoch: 5| Step: 5
Training loss: 0.7083455920219421
Validation loss: 1.8761180857176423

Epoch: 5| Step: 6
Training loss: 0.7950278520584106
Validation loss: 1.8943663374070199

Epoch: 5| Step: 7
Training loss: 0.6852157711982727
Validation loss: 1.9092664410991054

Epoch: 5| Step: 8
Training loss: 0.636135458946228
Validation loss: 1.8815541908305178

Epoch: 5| Step: 9
Training loss: 1.0813138484954834
Validation loss: 1.866100844516549

Epoch: 5| Step: 10
Training loss: 0.8404827117919922
Validation loss: 1.8794535885574997

Epoch: 301| Step: 0
Training loss: 1.2356793880462646
Validation loss: 1.8628708329252017

Epoch: 5| Step: 1
Training loss: 1.0189528465270996
Validation loss: 1.862075667227468

Epoch: 5| Step: 2
Training loss: 0.6328347325325012
Validation loss: 1.8598674625478766

Epoch: 5| Step: 3
Training loss: 0.8159719705581665
Validation loss: 1.8709810536394837

Epoch: 5| Step: 4
Training loss: 0.821603000164032
Validation loss: 1.8669863811103247

Epoch: 5| Step: 5
Training loss: 0.8396089673042297
Validation loss: 1.8746341736085954

Epoch: 5| Step: 6
Training loss: 1.212942123413086
Validation loss: 1.8796069250311902

Epoch: 5| Step: 7
Training loss: 0.7142097353935242
Validation loss: 1.8565068168024863

Epoch: 5| Step: 8
Training loss: 1.0104795694351196
Validation loss: 1.8123500834229171

Epoch: 5| Step: 9
Training loss: 0.7943686842918396
Validation loss: 1.8028778645300096

Epoch: 5| Step: 10
Training loss: 0.4333493709564209
Validation loss: 1.8103694838862265

Epoch: 302| Step: 0
Training loss: 0.6883687973022461
Validation loss: 1.7824427479056901

Epoch: 5| Step: 1
Training loss: 0.6665666103363037
Validation loss: 1.8164245646487

Epoch: 5| Step: 2
Training loss: 0.8976084589958191
Validation loss: 1.8589050039168327

Epoch: 5| Step: 3
Training loss: 0.8132007718086243
Validation loss: 1.8765727512298092

Epoch: 5| Step: 4
Training loss: 0.8675531148910522
Validation loss: 1.889219735258369

Epoch: 5| Step: 5
Training loss: 1.0858078002929688
Validation loss: 1.901176824364611

Epoch: 5| Step: 6
Training loss: 1.0267189741134644
Validation loss: 1.9205287682112826

Epoch: 5| Step: 7
Training loss: 0.8569148182868958
Validation loss: 1.9167838711892404

Epoch: 5| Step: 8
Training loss: 0.7738009095191956
Validation loss: 1.8648109948763283

Epoch: 5| Step: 9
Training loss: 0.8189870119094849
Validation loss: 1.8291722164359143

Epoch: 5| Step: 10
Training loss: 0.86897873878479
Validation loss: 1.8295397591847244

Epoch: 303| Step: 0
Training loss: 0.987151026725769
Validation loss: 1.7781069586353917

Epoch: 5| Step: 1
Training loss: 0.79295814037323
Validation loss: 1.7851418705396755

Epoch: 5| Step: 2
Training loss: 0.6286810636520386
Validation loss: 1.7837096914168327

Epoch: 5| Step: 3
Training loss: 0.8189762830734253
Validation loss: 1.8027959049388926

Epoch: 5| Step: 4
Training loss: 0.9199660420417786
Validation loss: 1.8148755373493317

Epoch: 5| Step: 5
Training loss: 0.6807724237442017
Validation loss: 1.8034375944445211

Epoch: 5| Step: 6
Training loss: 0.8867326974868774
Validation loss: 1.8784472916715889

Epoch: 5| Step: 7
Training loss: 1.1426681280136108
Validation loss: 1.9036168449668474

Epoch: 5| Step: 8
Training loss: 0.8116245269775391
Validation loss: 1.9368681100107008

Epoch: 5| Step: 9
Training loss: 0.8050277829170227
Validation loss: 1.9039658679757068

Epoch: 5| Step: 10
Training loss: 0.8538109064102173
Validation loss: 1.8672547827484787

Epoch: 304| Step: 0
Training loss: 1.3227421045303345
Validation loss: 1.8057411793739564

Epoch: 5| Step: 1
Training loss: 0.6345289349555969
Validation loss: 1.781231343105275

Epoch: 5| Step: 2
Training loss: 0.6633225083351135
Validation loss: 1.77346581925628

Epoch: 5| Step: 3
Training loss: 0.7088570594787598
Validation loss: 1.7746031027968212

Epoch: 5| Step: 4
Training loss: 0.6794931292533875
Validation loss: 1.788006471049401

Epoch: 5| Step: 5
Training loss: 0.7929304838180542
Validation loss: 1.8202526133547547

Epoch: 5| Step: 6
Training loss: 0.8508238792419434
Validation loss: 1.8316778726475214

Epoch: 5| Step: 7
Training loss: 0.9427675008773804
Validation loss: 1.880347580038091

Epoch: 5| Step: 8
Training loss: 1.0044077634811401
Validation loss: 1.899968167786957

Epoch: 5| Step: 9
Training loss: 0.5186171531677246
Validation loss: 1.9108081094680294

Epoch: 5| Step: 10
Training loss: 1.105894684791565
Validation loss: 1.9028425139765586

Epoch: 305| Step: 0
Training loss: 0.4789530634880066
Validation loss: 1.9024064976681945

Epoch: 5| Step: 1
Training loss: 0.6641573905944824
Validation loss: 1.8800463548270605

Epoch: 5| Step: 2
Training loss: 0.7369539737701416
Validation loss: 1.8588193257649739

Epoch: 5| Step: 3
Training loss: 0.5611516833305359
Validation loss: 1.8387410089533816

Epoch: 5| Step: 4
Training loss: 0.7288777828216553
Validation loss: 1.811027116672967

Epoch: 5| Step: 5
Training loss: 0.5582127571105957
Validation loss: 1.8103407300928587

Epoch: 5| Step: 6
Training loss: 1.2582108974456787
Validation loss: 1.8185957067756242

Epoch: 5| Step: 7
Training loss: 0.8758050799369812
Validation loss: 1.8330856484751548

Epoch: 5| Step: 8
Training loss: 1.19142746925354
Validation loss: 1.8114312810282553

Epoch: 5| Step: 9
Training loss: 0.8949824571609497
Validation loss: 1.8028003913100048

Epoch: 5| Step: 10
Training loss: 1.0476592779159546
Validation loss: 1.791580475786681

Epoch: 306| Step: 0
Training loss: 0.5805813074111938
Validation loss: 1.781854429552632

Epoch: 5| Step: 1
Training loss: 0.529513418674469
Validation loss: 1.7894488919165827

Epoch: 5| Step: 2
Training loss: 0.9821071624755859
Validation loss: 1.7644319816302227

Epoch: 5| Step: 3
Training loss: 0.7659032940864563
Validation loss: 1.795910798093324

Epoch: 5| Step: 4
Training loss: 1.0849411487579346
Validation loss: 1.8194898879656227

Epoch: 5| Step: 5
Training loss: 0.7490842342376709
Validation loss: 1.84336849950975

Epoch: 5| Step: 6
Training loss: 0.5882250666618347
Validation loss: 1.829662364016297

Epoch: 5| Step: 7
Training loss: 0.5188410878181458
Validation loss: 1.8735538785175612

Epoch: 5| Step: 8
Training loss: 1.0494678020477295
Validation loss: 1.894677827435155

Epoch: 5| Step: 9
Training loss: 0.7832998037338257
Validation loss: 1.8399966750093686

Epoch: 5| Step: 10
Training loss: 1.1299238204956055
Validation loss: 1.8220630538079046

Epoch: 307| Step: 0
Training loss: 0.9286373257637024
Validation loss: 1.8284729116706437

Epoch: 5| Step: 1
Training loss: 0.8878217935562134
Validation loss: 1.8144972273098525

Epoch: 5| Step: 2
Training loss: 0.716673731803894
Validation loss: 1.7982302814401605

Epoch: 5| Step: 3
Training loss: 0.5911019444465637
Validation loss: 1.7883445062944967

Epoch: 5| Step: 4
Training loss: 0.6195774078369141
Validation loss: 1.7833340116726455

Epoch: 5| Step: 5
Training loss: 1.1140985488891602
Validation loss: 1.8042742898387294

Epoch: 5| Step: 6
Training loss: 0.7297784686088562
Validation loss: 1.8015717280808317

Epoch: 5| Step: 7
Training loss: 0.9160822629928589
Validation loss: 1.8076455029108192

Epoch: 5| Step: 8
Training loss: 0.6617863774299622
Validation loss: 1.839681674075383

Epoch: 5| Step: 9
Training loss: 0.6789180040359497
Validation loss: 1.8380714014012327

Epoch: 5| Step: 10
Training loss: 0.7865625619888306
Validation loss: 1.834938803026753

Epoch: 308| Step: 0
Training loss: 0.6768215894699097
Validation loss: 1.837658739859058

Epoch: 5| Step: 1
Training loss: 0.4795275330543518
Validation loss: 1.8509508871263074

Epoch: 5| Step: 2
Training loss: 0.8986396789550781
Validation loss: 1.82189558141975

Epoch: 5| Step: 3
Training loss: 0.8466060757637024
Validation loss: 1.8319637544693486

Epoch: 5| Step: 4
Training loss: 0.70421302318573
Validation loss: 1.80542928044514

Epoch: 5| Step: 5
Training loss: 0.8573541641235352
Validation loss: 1.7973964163052139

Epoch: 5| Step: 6
Training loss: 0.7570953965187073
Validation loss: 1.7925006215290358

Epoch: 5| Step: 7
Training loss: 0.6580547094345093
Validation loss: 1.7788702005981116

Epoch: 5| Step: 8
Training loss: 0.6012271642684937
Validation loss: 1.7776742289143224

Epoch: 5| Step: 9
Training loss: 0.83241206407547
Validation loss: 1.800718225458617

Epoch: 5| Step: 10
Training loss: 1.2202013731002808
Validation loss: 1.7938649628752021

Epoch: 309| Step: 0
Training loss: 0.7631110548973083
Validation loss: 1.8080599590014386

Epoch: 5| Step: 1
Training loss: 0.8344915509223938
Validation loss: 1.8417171585944392

Epoch: 5| Step: 2
Training loss: 0.6436811685562134
Validation loss: 1.8439725291344427

Epoch: 5| Step: 3
Training loss: 0.9008611440658569
Validation loss: 1.8227706006778184

Epoch: 5| Step: 4
Training loss: 0.9618808627128601
Validation loss: 1.8037553346285256

Epoch: 5| Step: 5
Training loss: 0.7589336633682251
Validation loss: 1.7783741604897283

Epoch: 5| Step: 6
Training loss: 0.5848926305770874
Validation loss: 1.781255813055141

Epoch: 5| Step: 7
Training loss: 0.6838830709457397
Validation loss: 1.770535619028153

Epoch: 5| Step: 8
Training loss: 0.6969199776649475
Validation loss: 1.8059729670965543

Epoch: 5| Step: 9
Training loss: 0.7021068930625916
Validation loss: 1.8006821037620626

Epoch: 5| Step: 10
Training loss: 0.7631391882896423
Validation loss: 1.7809289719468804

Epoch: 310| Step: 0
Training loss: 0.7052494287490845
Validation loss: 1.7771968674916092

Epoch: 5| Step: 1
Training loss: 0.9222432971000671
Validation loss: 1.8121326251696515

Epoch: 5| Step: 2
Training loss: 0.8111023902893066
Validation loss: 1.8090025212175103

Epoch: 5| Step: 3
Training loss: 0.9224048852920532
Validation loss: 1.8430097718392648

Epoch: 5| Step: 4
Training loss: 0.6387491822242737
Validation loss: 1.83217115043312

Epoch: 5| Step: 5
Training loss: 0.5174400210380554
Validation loss: 1.8450704261820803

Epoch: 5| Step: 6
Training loss: 0.7081494927406311
Validation loss: 1.8042372939407185

Epoch: 5| Step: 7
Training loss: 0.7202264666557312
Validation loss: 1.8178167714867541

Epoch: 5| Step: 8
Training loss: 0.5943067073822021
Validation loss: 1.8056806954004432

Epoch: 5| Step: 9
Training loss: 0.8513832092285156
Validation loss: 1.8088354231208883

Epoch: 5| Step: 10
Training loss: 0.8905736207962036
Validation loss: 1.847211273767615

Epoch: 311| Step: 0
Training loss: 0.7804219126701355
Validation loss: 1.829331636428833

Epoch: 5| Step: 1
Training loss: 0.6713211536407471
Validation loss: 1.8349516032844462

Epoch: 5| Step: 2
Training loss: 0.9069966077804565
Validation loss: 1.8608951530148905

Epoch: 5| Step: 3
Training loss: 1.0461602210998535
Validation loss: 1.8149330564724502

Epoch: 5| Step: 4
Training loss: 0.8781312704086304
Validation loss: 1.8102859053560483

Epoch: 5| Step: 5
Training loss: 0.8117401003837585
Validation loss: 1.7778432792232883

Epoch: 5| Step: 6
Training loss: 0.9029390215873718
Validation loss: 1.794382869556386

Epoch: 5| Step: 7
Training loss: 0.4432363510131836
Validation loss: 1.7741630449089953

Epoch: 5| Step: 8
Training loss: 0.6398563385009766
Validation loss: 1.7751166820526123

Epoch: 5| Step: 9
Training loss: 0.354505717754364
Validation loss: 1.7871047668559576

Epoch: 5| Step: 10
Training loss: 0.6867241263389587
Validation loss: 1.7929005046044626

Epoch: 312| Step: 0
Training loss: 0.4581723213195801
Validation loss: 1.802086127701626

Epoch: 5| Step: 1
Training loss: 0.4891597628593445
Validation loss: 1.828344206656179

Epoch: 5| Step: 2
Training loss: 0.6037842035293579
Validation loss: 1.846993766805177

Epoch: 5| Step: 3
Training loss: 0.7025690078735352
Validation loss: 1.8537343535372006

Epoch: 5| Step: 4
Training loss: 1.2231591939926147
Validation loss: 1.8398586127065844

Epoch: 5| Step: 5
Training loss: 0.9753836393356323
Validation loss: 1.8478490742303992

Epoch: 5| Step: 6
Training loss: 0.8139065504074097
Validation loss: 1.830704519825597

Epoch: 5| Step: 7
Training loss: 0.4801155924797058
Validation loss: 1.8332840806694441

Epoch: 5| Step: 8
Training loss: 0.9176338315010071
Validation loss: 1.8455859538047545

Epoch: 5| Step: 9
Training loss: 0.8514440655708313
Validation loss: 1.8626457209228187

Epoch: 5| Step: 10
Training loss: 0.6542978286743164
Validation loss: 1.8240079456760037

Epoch: 313| Step: 0
Training loss: 0.6650810241699219
Validation loss: 1.810884589790016

Epoch: 5| Step: 1
Training loss: 0.7216132283210754
Validation loss: 1.7919760980913717

Epoch: 5| Step: 2
Training loss: 0.7199605107307434
Validation loss: 1.8141048467287453

Epoch: 5| Step: 3
Training loss: 0.5773304104804993
Validation loss: 1.7931612845390075

Epoch: 5| Step: 4
Training loss: 0.6451235413551331
Validation loss: 1.8076796698313888

Epoch: 5| Step: 5
Training loss: 0.8166528940200806
Validation loss: 1.8394818331605645

Epoch: 5| Step: 6
Training loss: 0.4207673668861389
Validation loss: 1.8854299911888697

Epoch: 5| Step: 7
Training loss: 0.8766897320747375
Validation loss: 1.8432923645101569

Epoch: 5| Step: 8
Training loss: 0.6862689256668091
Validation loss: 1.851956323910785

Epoch: 5| Step: 9
Training loss: 1.154766321182251
Validation loss: 1.8395959613143757

Epoch: 5| Step: 10
Training loss: 0.8582191467285156
Validation loss: 1.8255589931241927

Epoch: 314| Step: 0
Training loss: 0.6399248838424683
Validation loss: 1.8339694597387826

Epoch: 5| Step: 1
Training loss: 0.5448423624038696
Validation loss: 1.8070977913436068

Epoch: 5| Step: 2
Training loss: 0.6109617352485657
Validation loss: 1.785687272266675

Epoch: 5| Step: 3
Training loss: 0.6436566114425659
Validation loss: 1.8074433085738972

Epoch: 5| Step: 4
Training loss: 0.7572802305221558
Validation loss: 1.7959354410889328

Epoch: 5| Step: 5
Training loss: 0.6884347796440125
Validation loss: 1.839023352951132

Epoch: 5| Step: 6
Training loss: 1.1992714405059814
Validation loss: 1.8577660834917458

Epoch: 5| Step: 7
Training loss: 0.8014699816703796
Validation loss: 1.8420332772757417

Epoch: 5| Step: 8
Training loss: 0.6534527540206909
Validation loss: 1.8501978048714258

Epoch: 5| Step: 9
Training loss: 0.9037078619003296
Validation loss: 1.8506438527055966

Epoch: 5| Step: 10
Training loss: 0.7251575589179993
Validation loss: 1.8240060165364256

Epoch: 315| Step: 0
Training loss: 0.6449986696243286
Validation loss: 1.8221558934898787

Epoch: 5| Step: 1
Training loss: 0.9213451147079468
Validation loss: 1.8250161345287035

Epoch: 5| Step: 2
Training loss: 0.9609779119491577
Validation loss: 1.8119989184923069

Epoch: 5| Step: 3
Training loss: 0.5623884201049805
Validation loss: 1.8304113008642708

Epoch: 5| Step: 4
Training loss: 0.4008760452270508
Validation loss: 1.8121871986696798

Epoch: 5| Step: 5
Training loss: 0.8291562795639038
Validation loss: 1.8111877492679063

Epoch: 5| Step: 6
Training loss: 0.49164333939552307
Validation loss: 1.8159800306443246

Epoch: 5| Step: 7
Training loss: 1.0345470905303955
Validation loss: 1.8281631033907655

Epoch: 5| Step: 8
Training loss: 0.5764871835708618
Validation loss: 1.818744460741679

Epoch: 5| Step: 9
Training loss: 0.9937790036201477
Validation loss: 1.8399484439562726

Epoch: 5| Step: 10
Training loss: 0.5483919978141785
Validation loss: 1.8141459739336403

Epoch: 316| Step: 0
Training loss: 0.7362211346626282
Validation loss: 1.8322377871441584

Epoch: 5| Step: 1
Training loss: 0.6291343569755554
Validation loss: 1.8414013026863016

Epoch: 5| Step: 2
Training loss: 0.8781049847602844
Validation loss: 1.8522111574808757

Epoch: 5| Step: 3
Training loss: 1.0361135005950928
Validation loss: 1.846013206307606

Epoch: 5| Step: 4
Training loss: 0.9265741109848022
Validation loss: 1.8493706103294127

Epoch: 5| Step: 5
Training loss: 0.5183850526809692
Validation loss: 1.8587291753420265

Epoch: 5| Step: 6
Training loss: 0.7529209852218628
Validation loss: 1.8732626053594774

Epoch: 5| Step: 7
Training loss: 0.6544400453567505
Validation loss: 1.8278756615936116

Epoch: 5| Step: 8
Training loss: 0.4060600697994232
Validation loss: 1.8205571072075957

Epoch: 5| Step: 9
Training loss: 1.0495662689208984
Validation loss: 1.7592021470428796

Epoch: 5| Step: 10
Training loss: 0.37944623827934265
Validation loss: 1.7586827521683068

Epoch: 317| Step: 0
Training loss: 0.7796603441238403
Validation loss: 1.7398174244870421

Epoch: 5| Step: 1
Training loss: 0.6666302680969238
Validation loss: 1.7494864245896697

Epoch: 5| Step: 2
Training loss: 0.5744431614875793
Validation loss: 1.7930456220462758

Epoch: 5| Step: 3
Training loss: 0.8105802536010742
Validation loss: 1.803936421230275

Epoch: 5| Step: 4
Training loss: 1.0029385089874268
Validation loss: 1.8283188419957315

Epoch: 5| Step: 5
Training loss: 1.0965023040771484
Validation loss: 1.821940081093901

Epoch: 5| Step: 6
Training loss: 0.6347958445549011
Validation loss: 1.804744484604046

Epoch: 5| Step: 7
Training loss: 0.4597323536872864
Validation loss: 1.7921144936674385

Epoch: 5| Step: 8
Training loss: 0.6603610515594482
Validation loss: 1.7832093341376192

Epoch: 5| Step: 9
Training loss: 0.7015422582626343
Validation loss: 1.7678762738422682

Epoch: 5| Step: 10
Training loss: 0.5214284658432007
Validation loss: 1.7858335356558523

Epoch: 318| Step: 0
Training loss: 0.6837000250816345
Validation loss: 1.7915789055567917

Epoch: 5| Step: 1
Training loss: 0.9909188151359558
Validation loss: 1.7861982622454244

Epoch: 5| Step: 2
Training loss: 0.7659401893615723
Validation loss: 1.809239819485654

Epoch: 5| Step: 3
Training loss: 0.5014590620994568
Validation loss: 1.822504715252948

Epoch: 5| Step: 4
Training loss: 0.7678235769271851
Validation loss: 1.8198751377803024

Epoch: 5| Step: 5
Training loss: 0.6022351980209351
Validation loss: 1.837126261444502

Epoch: 5| Step: 6
Training loss: 0.7228652238845825
Validation loss: 1.8683575955770348

Epoch: 5| Step: 7
Training loss: 0.5276275873184204
Validation loss: 1.85462954608343

Epoch: 5| Step: 8
Training loss: 0.5243624448776245
Validation loss: 1.846252546515516

Epoch: 5| Step: 9
Training loss: 0.6348907947540283
Validation loss: 1.8146253478142522

Epoch: 5| Step: 10
Training loss: 1.054823875427246
Validation loss: 1.820584386907598

Epoch: 319| Step: 0
Training loss: 0.7039827108383179
Validation loss: 1.8058262409702424

Epoch: 5| Step: 1
Training loss: 0.8032439947128296
Validation loss: 1.7693001019057406

Epoch: 5| Step: 2
Training loss: 0.7989431619644165
Validation loss: 1.7767740975144088

Epoch: 5| Step: 3
Training loss: 0.8857195973396301
Validation loss: 1.7931600642460648

Epoch: 5| Step: 4
Training loss: 0.7479825019836426
Validation loss: 1.7711872029048141

Epoch: 5| Step: 5
Training loss: 0.5771931409835815
Validation loss: 1.7848523457845051

Epoch: 5| Step: 6
Training loss: 0.6555919051170349
Validation loss: 1.8175070619070401

Epoch: 5| Step: 7
Training loss: 1.0251857042312622
Validation loss: 1.792880751753366

Epoch: 5| Step: 8
Training loss: 0.49081793427467346
Validation loss: 1.809526615245368

Epoch: 5| Step: 9
Training loss: 0.5984915494918823
Validation loss: 1.8062877065391951

Epoch: 5| Step: 10
Training loss: 0.39488938450813293
Validation loss: 1.8422027223853654

Epoch: 320| Step: 0
Training loss: 0.5644980072975159
Validation loss: 1.8315247502378238

Epoch: 5| Step: 1
Training loss: 0.8133559226989746
Validation loss: 1.8269499988966091

Epoch: 5| Step: 2
Training loss: 0.8963180780410767
Validation loss: 1.8326832761046707

Epoch: 5| Step: 3
Training loss: 0.8981170654296875
Validation loss: 1.8107986014376405

Epoch: 5| Step: 4
Training loss: 0.6356745958328247
Validation loss: 1.8053637371268323

Epoch: 5| Step: 5
Training loss: 0.45876988768577576
Validation loss: 1.7917622725168865

Epoch: 5| Step: 6
Training loss: 0.33977532386779785
Validation loss: 1.7919478313897246

Epoch: 5| Step: 7
Training loss: 0.7154244780540466
Validation loss: 1.7875553343885688

Epoch: 5| Step: 8
Training loss: 0.8825680613517761
Validation loss: 1.7927820554343603

Epoch: 5| Step: 9
Training loss: 0.7818671464920044
Validation loss: 1.7765234055057648

Epoch: 5| Step: 10
Training loss: 0.77195143699646
Validation loss: 1.7549528127075524

Epoch: 321| Step: 0
Training loss: 0.8165956735610962
Validation loss: 1.7670236197851037

Epoch: 5| Step: 1
Training loss: 0.8055621385574341
Validation loss: 1.7881111021964782

Epoch: 5| Step: 2
Training loss: 1.0418367385864258
Validation loss: 1.7853871545483988

Epoch: 5| Step: 3
Training loss: 0.3112742304801941
Validation loss: 1.822047245117926

Epoch: 5| Step: 4
Training loss: 0.8157039880752563
Validation loss: 1.8114283341233448

Epoch: 5| Step: 5
Training loss: 0.5546146631240845
Validation loss: 1.833982099768936

Epoch: 5| Step: 6
Training loss: 0.484567254781723
Validation loss: 1.8350937763849895

Epoch: 5| Step: 7
Training loss: 0.8424602746963501
Validation loss: 1.829944783641446

Epoch: 5| Step: 8
Training loss: 0.4448482096195221
Validation loss: 1.8588600517601095

Epoch: 5| Step: 9
Training loss: 0.8561893701553345
Validation loss: 1.821278892537599

Epoch: 5| Step: 10
Training loss: 0.552625834941864
Validation loss: 1.842987383565595

Epoch: 322| Step: 0
Training loss: 0.7136875987052917
Validation loss: 1.807667254119791

Epoch: 5| Step: 1
Training loss: 0.9580782651901245
Validation loss: 1.7992449575854885

Epoch: 5| Step: 2
Training loss: 0.43070879578590393
Validation loss: 1.7808141990374493

Epoch: 5| Step: 3
Training loss: 0.6976686716079712
Validation loss: 1.7776948880123835

Epoch: 5| Step: 4
Training loss: 0.8404491543769836
Validation loss: 1.8074433547194286

Epoch: 5| Step: 5
Training loss: 0.44328784942626953
Validation loss: 1.8110135562958256

Epoch: 5| Step: 6
Training loss: 0.7656360864639282
Validation loss: 1.843328465697586

Epoch: 5| Step: 7
Training loss: 0.6563485860824585
Validation loss: 1.8386996125662198

Epoch: 5| Step: 8
Training loss: 0.7414712905883789
Validation loss: 1.836060840596435

Epoch: 5| Step: 9
Training loss: 0.5674703121185303
Validation loss: 1.822543828718124

Epoch: 5| Step: 10
Training loss: 0.7955372333526611
Validation loss: 1.7901596087281422

Epoch: 323| Step: 0
Training loss: 0.5020659565925598
Validation loss: 1.779130926696203

Epoch: 5| Step: 1
Training loss: 0.6168301701545715
Validation loss: 1.7885922488345896

Epoch: 5| Step: 2
Training loss: 0.8620263934135437
Validation loss: 1.76876143229905

Epoch: 5| Step: 3
Training loss: 0.7152372598648071
Validation loss: 1.7728195472430157

Epoch: 5| Step: 4
Training loss: 0.7782684564590454
Validation loss: 1.7917471406280354

Epoch: 5| Step: 5
Training loss: 0.6108871698379517
Validation loss: 1.7896527705654022

Epoch: 5| Step: 6
Training loss: 0.6318564414978027
Validation loss: 1.7968989136398479

Epoch: 5| Step: 7
Training loss: 0.6341315507888794
Validation loss: 1.8104148705800374

Epoch: 5| Step: 8
Training loss: 0.6020189523696899
Validation loss: 1.8165315299905755

Epoch: 5| Step: 9
Training loss: 0.7488110065460205
Validation loss: 1.8260229146608742

Epoch: 5| Step: 10
Training loss: 0.8121683597564697
Validation loss: 1.8446706238613333

Epoch: 324| Step: 0
Training loss: 0.5640443563461304
Validation loss: 1.8368968284258278

Epoch: 5| Step: 1
Training loss: 0.6658617258071899
Validation loss: 1.8433808947122226

Epoch: 5| Step: 2
Training loss: 0.7683886289596558
Validation loss: 1.8369323156213249

Epoch: 5| Step: 3
Training loss: 0.7676564455032349
Validation loss: 1.8219836463210404

Epoch: 5| Step: 4
Training loss: 0.6637595891952515
Validation loss: 1.8245620971084924

Epoch: 5| Step: 5
Training loss: 0.6595436930656433
Validation loss: 1.785634575351592

Epoch: 5| Step: 6
Training loss: 0.5437635779380798
Validation loss: 1.8209671256362752

Epoch: 5| Step: 7
Training loss: 0.8166953325271606
Validation loss: 1.7702737341644943

Epoch: 5| Step: 8
Training loss: 0.6807710528373718
Validation loss: 1.7922256633799563

Epoch: 5| Step: 9
Training loss: 0.49535316228866577
Validation loss: 1.7861267802535847

Epoch: 5| Step: 10
Training loss: 0.8645709753036499
Validation loss: 1.7682273176408583

Epoch: 325| Step: 0
Training loss: 0.9571613073348999
Validation loss: 1.7706395272285707

Epoch: 5| Step: 1
Training loss: 0.645261287689209
Validation loss: 1.7651976718697497

Epoch: 5| Step: 2
Training loss: 0.9612240791320801
Validation loss: 1.7650208191205097

Epoch: 5| Step: 3
Training loss: 0.5679185390472412
Validation loss: 1.746697916779467

Epoch: 5| Step: 4
Training loss: 0.679146409034729
Validation loss: 1.77807278274208

Epoch: 5| Step: 5
Training loss: 0.4054761826992035
Validation loss: 1.778741983957188

Epoch: 5| Step: 6
Training loss: 0.5479958653450012
Validation loss: 1.7823760868400655

Epoch: 5| Step: 7
Training loss: 0.7238289713859558
Validation loss: 1.7513843877341158

Epoch: 5| Step: 8
Training loss: 0.5877152681350708
Validation loss: 1.7766948118004748

Epoch: 5| Step: 9
Training loss: 0.8450937271118164
Validation loss: 1.7717840697175713

Epoch: 5| Step: 10
Training loss: 0.6431992650032043
Validation loss: 1.7723295047718992

Epoch: 326| Step: 0
Training loss: 0.8499950170516968
Validation loss: 1.7677553789589995

Epoch: 5| Step: 1
Training loss: 0.6829716563224792
Validation loss: 1.7937793052324684

Epoch: 5| Step: 2
Training loss: 0.8406881093978882
Validation loss: 1.840575098991394

Epoch: 5| Step: 3
Training loss: 0.2780042588710785
Validation loss: 1.8230809242494646

Epoch: 5| Step: 4
Training loss: 0.4172028601169586
Validation loss: 1.8331334911366945

Epoch: 5| Step: 5
Training loss: 0.46192654967308044
Validation loss: 1.8268613712761992

Epoch: 5| Step: 6
Training loss: 0.9586183428764343
Validation loss: 1.822442643104061

Epoch: 5| Step: 7
Training loss: 0.7474591135978699
Validation loss: 1.8043155618893203

Epoch: 5| Step: 8
Training loss: 1.0268887281417847
Validation loss: 1.805761908972135

Epoch: 5| Step: 9
Training loss: 0.5769915580749512
Validation loss: 1.7512737166497014

Epoch: 5| Step: 10
Training loss: 0.3497498333454132
Validation loss: 1.7282586918082288

Epoch: 327| Step: 0
Training loss: 1.243723750114441
Validation loss: 1.7534194966798187

Epoch: 5| Step: 1
Training loss: 0.8251538276672363
Validation loss: 1.7616347856419061

Epoch: 5| Step: 2
Training loss: 0.6028949618339539
Validation loss: 1.6974926199964298

Epoch: 5| Step: 3
Training loss: 0.602848470211029
Validation loss: 1.7186709475773636

Epoch: 5| Step: 4
Training loss: 0.6936141848564148
Validation loss: 1.7044593070143013

Epoch: 5| Step: 5
Training loss: 0.7853890061378479
Validation loss: 1.7163031306318057

Epoch: 5| Step: 6
Training loss: 0.4409366548061371
Validation loss: 1.7438665307978147

Epoch: 5| Step: 7
Training loss: 0.5327814221382141
Validation loss: 1.7932530885101647

Epoch: 5| Step: 8
Training loss: 0.4994552731513977
Validation loss: 1.7894957219400713

Epoch: 5| Step: 9
Training loss: 0.6807313561439514
Validation loss: 1.81498928992979

Epoch: 5| Step: 10
Training loss: 0.39561694860458374
Validation loss: 1.7947343728875602

Epoch: 328| Step: 0
Training loss: 0.7057808041572571
Validation loss: 1.787834548181103

Epoch: 5| Step: 1
Training loss: 0.7765941023826599
Validation loss: 1.7470328474557528

Epoch: 5| Step: 2
Training loss: 0.5493133068084717
Validation loss: 1.7436085208769767

Epoch: 5| Step: 3
Training loss: 0.5106551647186279
Validation loss: 1.7240948959063458

Epoch: 5| Step: 4
Training loss: 0.7755893468856812
Validation loss: 1.7268098015939035

Epoch: 5| Step: 5
Training loss: 0.731397271156311
Validation loss: 1.7337306096989622

Epoch: 5| Step: 6
Training loss: 0.2667306661605835
Validation loss: 1.7303306389880437

Epoch: 5| Step: 7
Training loss: 0.6760597229003906
Validation loss: 1.736194174776795

Epoch: 5| Step: 8
Training loss: 0.6051577925682068
Validation loss: 1.7317675736642653

Epoch: 5| Step: 9
Training loss: 0.6397631168365479
Validation loss: 1.7866111724607405

Epoch: 5| Step: 10
Training loss: 0.8980427980422974
Validation loss: 1.7820360763098604

Epoch: 329| Step: 0
Training loss: 0.605768084526062
Validation loss: 1.770522008660019

Epoch: 5| Step: 1
Training loss: 0.6610905528068542
Validation loss: 1.7862059813673778

Epoch: 5| Step: 2
Training loss: 0.6903218030929565
Validation loss: 1.7760456313369095

Epoch: 5| Step: 3
Training loss: 0.49257516860961914
Validation loss: 1.7441120506614767

Epoch: 5| Step: 4
Training loss: 0.8144332766532898
Validation loss: 1.7267775599674513

Epoch: 5| Step: 5
Training loss: 0.8088086247444153
Validation loss: 1.739201356005925

Epoch: 5| Step: 6
Training loss: 0.6852062940597534
Validation loss: 1.7255680407247236

Epoch: 5| Step: 7
Training loss: 0.7162160873413086
Validation loss: 1.729049713380875

Epoch: 5| Step: 8
Training loss: 0.3511364161968231
Validation loss: 1.7489501019959808

Epoch: 5| Step: 9
Training loss: 0.6579936742782593
Validation loss: 1.7673550331464378

Epoch: 5| Step: 10
Training loss: 0.48063772916793823
Validation loss: 1.7581693305764148

Epoch: 330| Step: 0
Training loss: 0.657196044921875
Validation loss: 1.7590314534402662

Epoch: 5| Step: 1
Training loss: 0.20904096961021423
Validation loss: 1.7747907638549805

Epoch: 5| Step: 2
Training loss: 0.8686149716377258
Validation loss: 1.7758591995444348

Epoch: 5| Step: 3
Training loss: 0.3530048131942749
Validation loss: 1.8011779528792187

Epoch: 5| Step: 4
Training loss: 0.5914977788925171
Validation loss: 1.7862811956995277

Epoch: 5| Step: 5
Training loss: 0.6616323590278625
Validation loss: 1.7765564598062986

Epoch: 5| Step: 6
Training loss: 0.7255862951278687
Validation loss: 1.7800329269901398

Epoch: 5| Step: 7
Training loss: 0.6767878532409668
Validation loss: 1.7728995892309374

Epoch: 5| Step: 8
Training loss: 0.7592710256576538
Validation loss: 1.746411818330006

Epoch: 5| Step: 9
Training loss: 0.6387336850166321
Validation loss: 1.7809379754527923

Epoch: 5| Step: 10
Training loss: 0.8255048990249634
Validation loss: 1.783205695049737

Epoch: 331| Step: 0
Training loss: 0.6444750428199768
Validation loss: 1.7788897534852386

Epoch: 5| Step: 1
Training loss: 0.8240653276443481
Validation loss: 1.774723534942955

Epoch: 5| Step: 2
Training loss: 0.5418969988822937
Validation loss: 1.756124173441241

Epoch: 5| Step: 3
Training loss: 0.6849378347396851
Validation loss: 1.7747600898947766

Epoch: 5| Step: 4
Training loss: 0.5702179074287415
Validation loss: 1.7665897543712328

Epoch: 5| Step: 5
Training loss: 0.609038233757019
Validation loss: 1.7623449012797365

Epoch: 5| Step: 6
Training loss: 0.6955809593200684
Validation loss: 1.7512258368153726

Epoch: 5| Step: 7
Training loss: 0.7162399291992188
Validation loss: 1.7383584271195114

Epoch: 5| Step: 8
Training loss: 0.4789190888404846
Validation loss: 1.7200695160896546

Epoch: 5| Step: 9
Training loss: 0.48302823305130005
Validation loss: 1.7557437727528233

Epoch: 5| Step: 10
Training loss: 0.6086001396179199
Validation loss: 1.7641701185575096

Epoch: 332| Step: 0
Training loss: 0.5754197239875793
Validation loss: 1.7641708030495593

Epoch: 5| Step: 1
Training loss: 0.45304688811302185
Validation loss: 1.7661301012962096

Epoch: 5| Step: 2
Training loss: 0.708709180355072
Validation loss: 1.7460274645077285

Epoch: 5| Step: 3
Training loss: 0.5605376958847046
Validation loss: 1.7374839346895936

Epoch: 5| Step: 4
Training loss: 0.9020590782165527
Validation loss: 1.7454288069919874

Epoch: 5| Step: 5
Training loss: 0.3337784707546234
Validation loss: 1.7341870877050585

Epoch: 5| Step: 6
Training loss: 0.4149007797241211
Validation loss: 1.750151688052762

Epoch: 5| Step: 7
Training loss: 0.7483537793159485
Validation loss: 1.7601568083609305

Epoch: 5| Step: 8
Training loss: 0.9059730768203735
Validation loss: 1.7897421108779086

Epoch: 5| Step: 9
Training loss: 0.6357611417770386
Validation loss: 1.8281415585548646

Epoch: 5| Step: 10
Training loss: 0.5872189402580261
Validation loss: 1.8705103961370324

Epoch: 333| Step: 0
Training loss: 0.7733328938484192
Validation loss: 1.8408101399739583

Epoch: 5| Step: 1
Training loss: 0.42369118332862854
Validation loss: 1.801890798794326

Epoch: 5| Step: 2
Training loss: 0.8208553194999695
Validation loss: 1.776222276431258

Epoch: 5| Step: 3
Training loss: 0.6200343370437622
Validation loss: 1.773814465409966

Epoch: 5| Step: 4
Training loss: 0.709061861038208
Validation loss: 1.7821252563948273

Epoch: 5| Step: 5
Training loss: 0.9213906526565552
Validation loss: 1.7845418837762648

Epoch: 5| Step: 6
Training loss: 0.7375845313072205
Validation loss: 1.7513481942556237

Epoch: 5| Step: 7
Training loss: 0.827385425567627
Validation loss: 1.7580272254123483

Epoch: 5| Step: 8
Training loss: 0.34250885248184204
Validation loss: 1.7895966550355316

Epoch: 5| Step: 9
Training loss: 0.6138273477554321
Validation loss: 1.8402321620654034

Epoch: 5| Step: 10
Training loss: 0.5785387754440308
Validation loss: 1.8157003387328117

Epoch: 334| Step: 0
Training loss: 0.6537505388259888
Validation loss: 1.8428954065486949

Epoch: 5| Step: 1
Training loss: 0.6629347205162048
Validation loss: 1.8421392389523086

Epoch: 5| Step: 2
Training loss: 0.639559268951416
Validation loss: 1.8060740168376634

Epoch: 5| Step: 3
Training loss: 0.4813981056213379
Validation loss: 1.7507614563870173

Epoch: 5| Step: 4
Training loss: 0.6138205528259277
Validation loss: 1.7549816934011315

Epoch: 5| Step: 5
Training loss: 0.7064496278762817
Validation loss: 1.7617284226161178

Epoch: 5| Step: 6
Training loss: 0.5275648832321167
Validation loss: 1.7745094337771017

Epoch: 5| Step: 7
Training loss: 0.6679482460021973
Validation loss: 1.802473379719642

Epoch: 5| Step: 8
Training loss: 0.7129536271095276
Validation loss: 1.8048591062586794

Epoch: 5| Step: 9
Training loss: 0.5872701406478882
Validation loss: 1.8194085474937194

Epoch: 5| Step: 10
Training loss: 0.6036477088928223
Validation loss: 1.7937167306100168

Epoch: 335| Step: 0
Training loss: 0.5631435513496399
Validation loss: 1.7755020587675032

Epoch: 5| Step: 1
Training loss: 0.33543023467063904
Validation loss: 1.7722621156323342

Epoch: 5| Step: 2
Training loss: 0.5837336778640747
Validation loss: 1.7599687230202459

Epoch: 5| Step: 3
Training loss: 0.6433342695236206
Validation loss: 1.7453245847455916

Epoch: 5| Step: 4
Training loss: 0.40144410729408264
Validation loss: 1.7802334664970316

Epoch: 5| Step: 5
Training loss: 0.5328506827354431
Validation loss: 1.7746339171163497

Epoch: 5| Step: 6
Training loss: 0.5046474933624268
Validation loss: 1.7895785365053403

Epoch: 5| Step: 7
Training loss: 0.8630737066268921
Validation loss: 1.8129127384513937

Epoch: 5| Step: 8
Training loss: 0.6689037680625916
Validation loss: 1.8248225053151448

Epoch: 5| Step: 9
Training loss: 0.7334926128387451
Validation loss: 1.8050074820877404

Epoch: 5| Step: 10
Training loss: 0.7183768153190613
Validation loss: 1.7634242683328607

Epoch: 336| Step: 0
Training loss: 0.5626264810562134
Validation loss: 1.7733372308874642

Epoch: 5| Step: 1
Training loss: 0.8491140604019165
Validation loss: 1.750410372211087

Epoch: 5| Step: 2
Training loss: 0.6644236445426941
Validation loss: 1.7593612350443357

Epoch: 5| Step: 3
Training loss: 0.6271539926528931
Validation loss: 1.743655122736449

Epoch: 5| Step: 4
Training loss: 0.2522777020931244
Validation loss: 1.7741188618444628

Epoch: 5| Step: 5
Training loss: 0.42529743909835815
Validation loss: 1.7716282644579489

Epoch: 5| Step: 6
Training loss: 0.5993117094039917
Validation loss: 1.7811211539853005

Epoch: 5| Step: 7
Training loss: 0.6339559555053711
Validation loss: 1.786996151811333

Epoch: 5| Step: 8
Training loss: 0.6687341332435608
Validation loss: 1.8134319910439112

Epoch: 5| Step: 9
Training loss: 0.3802803158760071
Validation loss: 1.789409641296633

Epoch: 5| Step: 10
Training loss: 0.8355072140693665
Validation loss: 1.8025910674884755

Epoch: 337| Step: 0
Training loss: 0.6381980776786804
Validation loss: 1.7894980471621278

Epoch: 5| Step: 1
Training loss: 0.5149894952774048
Validation loss: 1.7975134221456384

Epoch: 5| Step: 2
Training loss: 0.7594670057296753
Validation loss: 1.781918207804362

Epoch: 5| Step: 3
Training loss: 0.4662391245365143
Validation loss: 1.762017237242832

Epoch: 5| Step: 4
Training loss: 0.5125335454940796
Validation loss: 1.765180959496447

Epoch: 5| Step: 5
Training loss: 0.5992307066917419
Validation loss: 1.7575582060762631

Epoch: 5| Step: 6
Training loss: 0.6183472871780396
Validation loss: 1.7621626507851385

Epoch: 5| Step: 7
Training loss: 0.7213301658630371
Validation loss: 1.714005668958028

Epoch: 5| Step: 8
Training loss: 0.5053868889808655
Validation loss: 1.7752060762015722

Epoch: 5| Step: 9
Training loss: 0.8471217155456543
Validation loss: 1.737916866297363

Epoch: 5| Step: 10
Training loss: 0.4436321258544922
Validation loss: 1.7622151836272208

Epoch: 338| Step: 0
Training loss: 0.6755606532096863
Validation loss: 1.770979171158165

Epoch: 5| Step: 1
Training loss: 0.39315634965896606
Validation loss: 1.7579870018907773

Epoch: 5| Step: 2
Training loss: 0.5822808146476746
Validation loss: 1.7747124318153626

Epoch: 5| Step: 3
Training loss: 0.518885612487793
Validation loss: 1.7651334847173383

Epoch: 5| Step: 4
Training loss: 0.634191632270813
Validation loss: 1.779378350063037

Epoch: 5| Step: 5
Training loss: 0.74654221534729
Validation loss: 1.7892191820247199

Epoch: 5| Step: 6
Training loss: 1.0840708017349243
Validation loss: 1.8186589312809769

Epoch: 5| Step: 7
Training loss: 0.5778731107711792
Validation loss: 1.839544633383392

Epoch: 5| Step: 8
Training loss: 0.24613702297210693
Validation loss: 1.7888401528840423

Epoch: 5| Step: 9
Training loss: 0.6994441747665405
Validation loss: 1.7570689096245715

Epoch: 5| Step: 10
Training loss: 0.5369361042976379
Validation loss: 1.7236857247608963

Epoch: 339| Step: 0
Training loss: 0.5954378843307495
Validation loss: 1.7163912826968777

Epoch: 5| Step: 1
Training loss: 0.525446891784668
Validation loss: 1.7372723881916334

Epoch: 5| Step: 2
Training loss: 0.5296782851219177
Validation loss: 1.7304016133790374

Epoch: 5| Step: 3
Training loss: 0.6227547526359558
Validation loss: 1.7673511364126717

Epoch: 5| Step: 4
Training loss: 0.741299033164978
Validation loss: 1.791479654209588

Epoch: 5| Step: 5
Training loss: 0.9253190755844116
Validation loss: 1.7959591957830614

Epoch: 5| Step: 6
Training loss: 0.5161036849021912
Validation loss: 1.8193544367308259

Epoch: 5| Step: 7
Training loss: 0.6949917078018188
Validation loss: 1.7859799618362098

Epoch: 5| Step: 8
Training loss: 0.41423720121383667
Validation loss: 1.7775289525267899

Epoch: 5| Step: 9
Training loss: 0.5654980540275574
Validation loss: 1.7848633848210818

Epoch: 5| Step: 10
Training loss: 0.3966233730316162
Validation loss: 1.7837918548173801

Epoch: 340| Step: 0
Training loss: 0.6012324094772339
Validation loss: 1.7658990583112162

Epoch: 5| Step: 1
Training loss: 0.47061675786972046
Validation loss: 1.7695028192253524

Epoch: 5| Step: 2
Training loss: 0.4876320958137512
Validation loss: 1.757392652573124

Epoch: 5| Step: 3
Training loss: 0.6013140678405762
Validation loss: 1.7407587882011168

Epoch: 5| Step: 4
Training loss: 0.7833071351051331
Validation loss: 1.7482399068852907

Epoch: 5| Step: 5
Training loss: 0.5516565442085266
Validation loss: 1.7530657296539636

Epoch: 5| Step: 6
Training loss: 0.614679217338562
Validation loss: 1.748318572198191

Epoch: 5| Step: 7
Training loss: 0.6508990526199341
Validation loss: 1.7761456556217645

Epoch: 5| Step: 8
Training loss: 0.5167405009269714
Validation loss: 1.800058643023173

Epoch: 5| Step: 9
Training loss: 0.6817098259925842
Validation loss: 1.775038629449824

Epoch: 5| Step: 10
Training loss: 0.38629552721977234
Validation loss: 1.7874216943658807

Epoch: 341| Step: 0
Training loss: 0.4703747630119324
Validation loss: 1.7636212046428392

Epoch: 5| Step: 1
Training loss: 0.6268734931945801
Validation loss: 1.7937994105841524

Epoch: 5| Step: 2
Training loss: 0.4363226890563965
Validation loss: 1.7824517501297819

Epoch: 5| Step: 3
Training loss: 0.38758355379104614
Validation loss: 1.7522712164027716

Epoch: 5| Step: 4
Training loss: 0.44080209732055664
Validation loss: 1.7409563833667385

Epoch: 5| Step: 5
Training loss: 0.6587709784507751
Validation loss: 1.7353585509843723

Epoch: 5| Step: 6
Training loss: 0.9215878248214722
Validation loss: 1.7448811287521033

Epoch: 5| Step: 7
Training loss: 0.7617070078849792
Validation loss: 1.7368589037208146

Epoch: 5| Step: 8
Training loss: 0.6074231266975403
Validation loss: 1.7393650124149937

Epoch: 5| Step: 9
Training loss: 0.5258356332778931
Validation loss: 1.7409019136941561

Epoch: 5| Step: 10
Training loss: 0.5746883153915405
Validation loss: 1.7397974973083825

Epoch: 342| Step: 0
Training loss: 0.5725415349006653
Validation loss: 1.776851261815717

Epoch: 5| Step: 1
Training loss: 0.6900540590286255
Validation loss: 1.7946241606948197

Epoch: 5| Step: 2
Training loss: 0.4293106198310852
Validation loss: 1.8191502645451536

Epoch: 5| Step: 3
Training loss: 0.7246190309524536
Validation loss: 1.8016821402375416

Epoch: 5| Step: 4
Training loss: 0.530021071434021
Validation loss: 1.7933090194579093

Epoch: 5| Step: 5
Training loss: 0.3456595242023468
Validation loss: 1.797512162116266

Epoch: 5| Step: 6
Training loss: 0.7600123286247253
Validation loss: 1.7589664869411017

Epoch: 5| Step: 7
Training loss: 0.6109785437583923
Validation loss: 1.7430585507423646

Epoch: 5| Step: 8
Training loss: 0.4221149981021881
Validation loss: 1.7065650801504813

Epoch: 5| Step: 9
Training loss: 0.5655125379562378
Validation loss: 1.7083594517041278

Epoch: 5| Step: 10
Training loss: 0.570228099822998
Validation loss: 1.7069004915093864

Epoch: 343| Step: 0
Training loss: 0.6938276290893555
Validation loss: 1.68303612355263

Epoch: 5| Step: 1
Training loss: 0.5579918026924133
Validation loss: 1.6916888195981261

Epoch: 5| Step: 2
Training loss: 0.2881922125816345
Validation loss: 1.7308561981365245

Epoch: 5| Step: 3
Training loss: 0.8008719682693481
Validation loss: 1.746470453918621

Epoch: 5| Step: 4
Training loss: 0.6349999904632568
Validation loss: 1.745120588169303

Epoch: 5| Step: 5
Training loss: 0.5553088188171387
Validation loss: 1.7430301814950921

Epoch: 5| Step: 6
Training loss: 0.6472885608673096
Validation loss: 1.7325187472886936

Epoch: 5| Step: 7
Training loss: 0.5283347368240356
Validation loss: 1.7622295989785144

Epoch: 5| Step: 8
Training loss: 0.4428904056549072
Validation loss: 1.7520704602682462

Epoch: 5| Step: 9
Training loss: 0.4735754132270813
Validation loss: 1.733592261550247

Epoch: 5| Step: 10
Training loss: 0.461263507604599
Validation loss: 1.777096054887259

Epoch: 344| Step: 0
Training loss: 0.589839518070221
Validation loss: 1.7793882546886322

Epoch: 5| Step: 1
Training loss: 0.660470724105835
Validation loss: 1.7861187073492235

Epoch: 5| Step: 2
Training loss: 0.5156177878379822
Validation loss: 1.7776567487306492

Epoch: 5| Step: 3
Training loss: 0.6951972842216492
Validation loss: 1.7592116478950746

Epoch: 5| Step: 4
Training loss: 0.3625333905220032
Validation loss: 1.7892887182133173

Epoch: 5| Step: 5
Training loss: 0.48878997564315796
Validation loss: 1.7669157033325524

Epoch: 5| Step: 6
Training loss: 0.7180465459823608
Validation loss: 1.7608173406252297

Epoch: 5| Step: 7
Training loss: 0.21726879477500916
Validation loss: 1.740225427894182

Epoch: 5| Step: 8
Training loss: 0.35846567153930664
Validation loss: 1.7240098753283102

Epoch: 5| Step: 9
Training loss: 0.9214332699775696
Validation loss: 1.752391557539663

Epoch: 5| Step: 10
Training loss: 0.5549648404121399
Validation loss: 1.7626329237414944

Epoch: 345| Step: 0
Training loss: 0.6101300120353699
Validation loss: 1.7836651545698925

Epoch: 5| Step: 1
Training loss: 0.42160695791244507
Validation loss: 1.7783879977400585

Epoch: 5| Step: 2
Training loss: 0.5323455929756165
Validation loss: 1.8154986314876105

Epoch: 5| Step: 3
Training loss: 0.551302433013916
Validation loss: 1.7632663057696434

Epoch: 5| Step: 4
Training loss: 0.6036219000816345
Validation loss: 1.7718451010283602

Epoch: 5| Step: 5
Training loss: 0.5558332204818726
Validation loss: 1.758002660607779

Epoch: 5| Step: 6
Training loss: 0.6031895279884338
Validation loss: 1.7261356666523924

Epoch: 5| Step: 7
Training loss: 0.47203439474105835
Validation loss: 1.759261845260538

Epoch: 5| Step: 8
Training loss: 0.48704832792282104
Validation loss: 1.7446579164074314

Epoch: 5| Step: 9
Training loss: 0.5903089642524719
Validation loss: 1.7332437281967492

Epoch: 5| Step: 10
Training loss: 0.6481507420539856
Validation loss: 1.7270268163373392

Epoch: 346| Step: 0
Training loss: 0.7124972939491272
Validation loss: 1.7068030494515614

Epoch: 5| Step: 1
Training loss: 0.4453392028808594
Validation loss: 1.7516853232537546

Epoch: 5| Step: 2
Training loss: 0.5430357456207275
Validation loss: 1.7236307282601633

Epoch: 5| Step: 3
Training loss: 0.8569698333740234
Validation loss: 1.7067332139579199

Epoch: 5| Step: 4
Training loss: 0.5442864894866943
Validation loss: 1.6964647667382353

Epoch: 5| Step: 5
Training loss: 0.6344685554504395
Validation loss: 1.6769696999621648

Epoch: 5| Step: 6
Training loss: 0.490530788898468
Validation loss: 1.6986774988071893

Epoch: 5| Step: 7
Training loss: 0.4614790976047516
Validation loss: 1.734396376917439

Epoch: 5| Step: 8
Training loss: 0.5756303071975708
Validation loss: 1.7312783733490975

Epoch: 5| Step: 9
Training loss: 0.6023788452148438
Validation loss: 1.7779303648138558

Epoch: 5| Step: 10
Training loss: 0.36854150891304016
Validation loss: 1.7826800038737636

Epoch: 347| Step: 0
Training loss: 0.7097705602645874
Validation loss: 1.793493814365838

Epoch: 5| Step: 1
Training loss: 0.4537486135959625
Validation loss: 1.816100707618139

Epoch: 5| Step: 2
Training loss: 0.5254950523376465
Validation loss: 1.782104540896672

Epoch: 5| Step: 3
Training loss: 0.44977694749832153
Validation loss: 1.7640110754197644

Epoch: 5| Step: 4
Training loss: 0.364565372467041
Validation loss: 1.7715145029047483

Epoch: 5| Step: 5
Training loss: 0.49906763434410095
Validation loss: 1.747078280295095

Epoch: 5| Step: 6
Training loss: 0.7326740026473999
Validation loss: 1.7323143507844658

Epoch: 5| Step: 7
Training loss: 0.7711597681045532
Validation loss: 1.7167316559822328

Epoch: 5| Step: 8
Training loss: 0.5734659433364868
Validation loss: 1.6869255362018463

Epoch: 5| Step: 9
Training loss: 0.5181114673614502
Validation loss: 1.7279180185769194

Epoch: 5| Step: 10
Training loss: 0.3214555084705353
Validation loss: 1.7070158861016715

Epoch: 348| Step: 0
Training loss: 0.3791504502296448
Validation loss: 1.6798739356379355

Epoch: 5| Step: 1
Training loss: 0.7127634882926941
Validation loss: 1.7227233814936813

Epoch: 5| Step: 2
Training loss: 0.38358965516090393
Validation loss: 1.7159396422806608

Epoch: 5| Step: 3
Training loss: 0.4718344807624817
Validation loss: 1.7539883403367893

Epoch: 5| Step: 4
Training loss: 0.5606578588485718
Validation loss: 1.7419829317318496

Epoch: 5| Step: 5
Training loss: 0.6333411335945129
Validation loss: 1.797437378155288

Epoch: 5| Step: 6
Training loss: 0.6302856802940369
Validation loss: 1.7952614830386253

Epoch: 5| Step: 7
Training loss: 0.7870346307754517
Validation loss: 1.7749946014855498

Epoch: 5| Step: 8
Training loss: 0.37608224153518677
Validation loss: 1.7572395506725516

Epoch: 5| Step: 9
Training loss: 0.3669303059577942
Validation loss: 1.7241599329056279

Epoch: 5| Step: 10
Training loss: 0.5049555897712708
Validation loss: 1.7359466898825862

Epoch: 349| Step: 0
Training loss: 0.5408345460891724
Validation loss: 1.7239626799860308

Epoch: 5| Step: 1
Training loss: 0.5984268188476562
Validation loss: 1.6904412059373752

Epoch: 5| Step: 2
Training loss: 0.40021467208862305
Validation loss: 1.6779009231957056

Epoch: 5| Step: 3
Training loss: 0.45232701301574707
Validation loss: 1.671637547913418

Epoch: 5| Step: 4
Training loss: 0.35275572538375854
Validation loss: 1.6950583047764276

Epoch: 5| Step: 5
Training loss: 0.8555739521980286
Validation loss: 1.6859506330182474

Epoch: 5| Step: 6
Training loss: 0.34415894746780396
Validation loss: 1.7187332786539549

Epoch: 5| Step: 7
Training loss: 0.4983662962913513
Validation loss: 1.7489734388166858

Epoch: 5| Step: 8
Training loss: 0.5683623552322388
Validation loss: 1.753503740474742

Epoch: 5| Step: 9
Training loss: 0.5778210163116455
Validation loss: 1.7673859339888378

Epoch: 5| Step: 10
Training loss: 0.9690661430358887
Validation loss: 1.8134055663180608

Epoch: 350| Step: 0
Training loss: 0.4523913860321045
Validation loss: 1.7878134507004932

Epoch: 5| Step: 1
Training loss: 0.5750870704650879
Validation loss: 1.8192184932770268

Epoch: 5| Step: 2
Training loss: 0.7005963325500488
Validation loss: 1.7830539198331936

Epoch: 5| Step: 3
Training loss: 0.3914453387260437
Validation loss: 1.7689399257782967

Epoch: 5| Step: 4
Training loss: 0.46438589692115784
Validation loss: 1.749993831880631

Epoch: 5| Step: 5
Training loss: 0.654248058795929
Validation loss: 1.7228394349416096

Epoch: 5| Step: 6
Training loss: 0.6140549778938293
Validation loss: 1.7272079439573391

Epoch: 5| Step: 7
Training loss: 0.5022974014282227
Validation loss: 1.7214075391010573

Epoch: 5| Step: 8
Training loss: 0.8051983118057251
Validation loss: 1.6925320458668534

Epoch: 5| Step: 9
Training loss: 0.6719695925712585
Validation loss: 1.671737394025249

Epoch: 5| Step: 10
Training loss: 0.23079365491867065
Validation loss: 1.720458976684078

Epoch: 351| Step: 0
Training loss: 0.36805781722068787
Validation loss: 1.716515980741029

Epoch: 5| Step: 1
Training loss: 0.345060259103775
Validation loss: 1.7310261290560487

Epoch: 5| Step: 2
Training loss: 0.7116809487342834
Validation loss: 1.7278340798552319

Epoch: 5| Step: 3
Training loss: 0.5387675166130066
Validation loss: 1.7627680070938603

Epoch: 5| Step: 4
Training loss: 0.5614240765571594
Validation loss: 1.7683534699101602

Epoch: 5| Step: 5
Training loss: 0.6668029427528381
Validation loss: 1.7715417236410163

Epoch: 5| Step: 6
Training loss: 0.7267406582832336
Validation loss: 1.7692715788400302

Epoch: 5| Step: 7
Training loss: 0.6507191061973572
Validation loss: 1.7777673672604304

Epoch: 5| Step: 8
Training loss: 0.6193404793739319
Validation loss: 1.761021379501589

Epoch: 5| Step: 9
Training loss: 0.3873785734176636
Validation loss: 1.7415645686529015

Epoch: 5| Step: 10
Training loss: 0.31964111328125
Validation loss: 1.723398441909462

Epoch: 352| Step: 0
Training loss: 0.5212787389755249
Validation loss: 1.7124867669997677

Epoch: 5| Step: 1
Training loss: 0.46194761991500854
Validation loss: 1.7391043363078948

Epoch: 5| Step: 2
Training loss: 0.5051583051681519
Validation loss: 1.716949906400455

Epoch: 5| Step: 3
Training loss: 0.6392444372177124
Validation loss: 1.6822390812699513

Epoch: 5| Step: 4
Training loss: 0.535286545753479
Validation loss: 1.7060444970284738

Epoch: 5| Step: 5
Training loss: 0.5513855814933777
Validation loss: 1.7420811755682832

Epoch: 5| Step: 6
Training loss: 0.9270788431167603
Validation loss: 1.7733369950325257

Epoch: 5| Step: 7
Training loss: 0.4649476408958435
Validation loss: 1.7894497071543047

Epoch: 5| Step: 8
Training loss: 0.40376320481300354
Validation loss: 1.7803090797957553

Epoch: 5| Step: 9
Training loss: 0.5760161876678467
Validation loss: 1.760041074086261

Epoch: 5| Step: 10
Training loss: 0.4342929720878601
Validation loss: 1.7415441274642944

Epoch: 353| Step: 0
Training loss: 0.3272572457790375
Validation loss: 1.7270507261317263

Epoch: 5| Step: 1
Training loss: 0.6227343678474426
Validation loss: 1.7117634883490942

Epoch: 5| Step: 2
Training loss: 0.34105440974235535
Validation loss: 1.7110703517031927

Epoch: 5| Step: 3
Training loss: 0.43408331274986267
Validation loss: 1.6956265690506145

Epoch: 5| Step: 4
Training loss: 0.70640629529953
Validation loss: 1.697239036201149

Epoch: 5| Step: 5
Training loss: 0.4247179925441742
Validation loss: 1.6834928053681568

Epoch: 5| Step: 6
Training loss: 0.5062438249588013
Validation loss: 1.7149246136347454

Epoch: 5| Step: 7
Training loss: 0.6268681287765503
Validation loss: 1.7184598971438665

Epoch: 5| Step: 8
Training loss: 0.5131102800369263
Validation loss: 1.740896358284899

Epoch: 5| Step: 9
Training loss: 0.559981107711792
Validation loss: 1.7100768294385684

Epoch: 5| Step: 10
Training loss: 0.6354244947433472
Validation loss: 1.7089971316758024

Epoch: 354| Step: 0
Training loss: 0.5382562875747681
Validation loss: 1.6777301821657407

Epoch: 5| Step: 1
Training loss: 0.4335336685180664
Validation loss: 1.7009732402781004

Epoch: 5| Step: 2
Training loss: 0.6511567831039429
Validation loss: 1.6971950492551249

Epoch: 5| Step: 3
Training loss: 0.35946834087371826
Validation loss: 1.7040741687179894

Epoch: 5| Step: 4
Training loss: 0.5837349891662598
Validation loss: 1.6911087113042031

Epoch: 5| Step: 5
Training loss: 0.5090157389640808
Validation loss: 1.6739364157440841

Epoch: 5| Step: 6
Training loss: 0.46018552780151367
Validation loss: 1.6985852423534598

Epoch: 5| Step: 7
Training loss: 0.30449268221855164
Validation loss: 1.6885127431602889

Epoch: 5| Step: 8
Training loss: 0.6830455660820007
Validation loss: 1.6958642877558225

Epoch: 5| Step: 9
Training loss: 0.5416301488876343
Validation loss: 1.6825795840191584

Epoch: 5| Step: 10
Training loss: 0.5610875487327576
Validation loss: 1.7117688912217335

Epoch: 355| Step: 0
Training loss: 0.3535374701023102
Validation loss: 1.699096514332679

Epoch: 5| Step: 1
Training loss: 0.49534663558006287
Validation loss: 1.7095528084744689

Epoch: 5| Step: 2
Training loss: 0.4637978672981262
Validation loss: 1.706316549290893

Epoch: 5| Step: 3
Training loss: 0.43493232131004333
Validation loss: 1.720144412850821

Epoch: 5| Step: 4
Training loss: 0.46651124954223633
Validation loss: 1.7196147646955264

Epoch: 5| Step: 5
Training loss: 0.3362189829349518
Validation loss: 1.7342424931064728

Epoch: 5| Step: 6
Training loss: 0.7705830335617065
Validation loss: 1.7309523282512542

Epoch: 5| Step: 7
Training loss: 0.41259899735450745
Validation loss: 1.7417138802107943

Epoch: 5| Step: 8
Training loss: 0.49130481481552124
Validation loss: 1.7140619921427902

Epoch: 5| Step: 9
Training loss: 0.7754641771316528
Validation loss: 1.7259065643433602

Epoch: 5| Step: 10
Training loss: 0.49932053685188293
Validation loss: 1.7233960436236473

Epoch: 356| Step: 0
Training loss: 0.537510097026825
Validation loss: 1.7197604935656312

Epoch: 5| Step: 1
Training loss: 0.5231040716171265
Validation loss: 1.7063801032240673

Epoch: 5| Step: 2
Training loss: 0.47682446241378784
Validation loss: 1.6843256450468493

Epoch: 5| Step: 3
Training loss: 0.4684642255306244
Validation loss: 1.6779884484506422

Epoch: 5| Step: 4
Training loss: 0.39977705478668213
Validation loss: 1.6860103889178204

Epoch: 5| Step: 5
Training loss: 0.45576390624046326
Validation loss: 1.6478037334257556

Epoch: 5| Step: 6
Training loss: 0.4739972949028015
Validation loss: 1.6651380792740853

Epoch: 5| Step: 7
Training loss: 0.36066001653671265
Validation loss: 1.6741745997500677

Epoch: 5| Step: 8
Training loss: 0.39853543043136597
Validation loss: 1.6701684664654475

Epoch: 5| Step: 9
Training loss: 0.8115963935852051
Validation loss: 1.6855122338059128

Epoch: 5| Step: 10
Training loss: 0.47551605105400085
Validation loss: 1.6821479733272264

Epoch: 357| Step: 0
Training loss: 0.45956844091415405
Validation loss: 1.677146621929702

Epoch: 5| Step: 1
Training loss: 0.3679282069206238
Validation loss: 1.6967892698062363

Epoch: 5| Step: 2
Training loss: 0.7323042750358582
Validation loss: 1.6894669020047752

Epoch: 5| Step: 3
Training loss: 0.5955139994621277
Validation loss: 1.7041540876511605

Epoch: 5| Step: 4
Training loss: 0.6089364290237427
Validation loss: 1.7009388721117409

Epoch: 5| Step: 5
Training loss: 0.260988712310791
Validation loss: 1.7054576950688516

Epoch: 5| Step: 6
Training loss: 0.2953895926475525
Validation loss: 1.7156745515843874

Epoch: 5| Step: 7
Training loss: 0.6270924210548401
Validation loss: 1.7508648710866128

Epoch: 5| Step: 8
Training loss: 0.522955060005188
Validation loss: 1.7277194864006453

Epoch: 5| Step: 9
Training loss: 0.3780978322029114
Validation loss: 1.7292511360619658

Epoch: 5| Step: 10
Training loss: 0.526263415813446
Validation loss: 1.7490691946398826

Epoch: 358| Step: 0
Training loss: 0.46728700399398804
Validation loss: 1.7602543677053144

Epoch: 5| Step: 1
Training loss: 0.5267659425735474
Validation loss: 1.744677580812926

Epoch: 5| Step: 2
Training loss: 0.26500749588012695
Validation loss: 1.728868547306266

Epoch: 5| Step: 3
Training loss: 0.5649192333221436
Validation loss: 1.707037812920027

Epoch: 5| Step: 4
Training loss: 0.6099449992179871
Validation loss: 1.716811700533795

Epoch: 5| Step: 5
Training loss: 0.5279837846755981
Validation loss: 1.7164850273439962

Epoch: 5| Step: 6
Training loss: 0.6406274437904358
Validation loss: 1.7151793767047185

Epoch: 5| Step: 7
Training loss: 0.5477733016014099
Validation loss: 1.725986626840407

Epoch: 5| Step: 8
Training loss: 0.2490553855895996
Validation loss: 1.6727218576656875

Epoch: 5| Step: 9
Training loss: 0.40063387155532837
Validation loss: 1.6541871819444882

Epoch: 5| Step: 10
Training loss: 0.6353819370269775
Validation loss: 1.6780444909167547

Epoch: 359| Step: 0
Training loss: 0.5017523765563965
Validation loss: 1.6762443325852836

Epoch: 5| Step: 1
Training loss: 0.592003583908081
Validation loss: 1.674414978232435

Epoch: 5| Step: 2
Training loss: 0.6065396070480347
Validation loss: 1.6540295968773544

Epoch: 5| Step: 3
Training loss: 0.2467447817325592
Validation loss: 1.6628487904866536

Epoch: 5| Step: 4
Training loss: 0.5631791949272156
Validation loss: 1.6595912569312639

Epoch: 5| Step: 5
Training loss: 0.49202996492385864
Validation loss: 1.668334989137547

Epoch: 5| Step: 6
Training loss: 0.4184979498386383
Validation loss: 1.699174581035491

Epoch: 5| Step: 7
Training loss: 0.48356667160987854
Validation loss: 1.696620911680242

Epoch: 5| Step: 8
Training loss: 0.5221530795097351
Validation loss: 1.7156811555226643

Epoch: 5| Step: 9
Training loss: 0.4675292372703552
Validation loss: 1.6994799362715853

Epoch: 5| Step: 10
Training loss: 0.48997440934181213
Validation loss: 1.6918259820630472

Epoch: 360| Step: 0
Training loss: 0.32203322649002075
Validation loss: 1.7132065283354891

Epoch: 5| Step: 1
Training loss: 0.36790603399276733
Validation loss: 1.7294964123797674

Epoch: 5| Step: 2
Training loss: 0.3062019944190979
Validation loss: 1.7206152203262493

Epoch: 5| Step: 3
Training loss: 0.5978201627731323
Validation loss: 1.724546399167789

Epoch: 5| Step: 4
Training loss: 0.5172712802886963
Validation loss: 1.6915365649807839

Epoch: 5| Step: 5
Training loss: 0.7244340181350708
Validation loss: 1.6912981848562918

Epoch: 5| Step: 6
Training loss: 0.3656562268733978
Validation loss: 1.6816481492852653

Epoch: 5| Step: 7
Training loss: 0.3674921989440918
Validation loss: 1.6846640058743056

Epoch: 5| Step: 8
Training loss: 0.7742620706558228
Validation loss: 1.6820165559809694

Epoch: 5| Step: 9
Training loss: 0.38027113676071167
Validation loss: 1.6951186336496824

Epoch: 5| Step: 10
Training loss: 0.4251800775527954
Validation loss: 1.6839825132841706

Epoch: 361| Step: 0
Training loss: 0.4180322289466858
Validation loss: 1.6894697373913181

Epoch: 5| Step: 1
Training loss: 0.4720446467399597
Validation loss: 1.670625522572507

Epoch: 5| Step: 2
Training loss: 0.4801791310310364
Validation loss: 1.676564730623717

Epoch: 5| Step: 3
Training loss: 0.5284581780433655
Validation loss: 1.6768309993128623

Epoch: 5| Step: 4
Training loss: 0.49242138862609863
Validation loss: 1.6872216232361332

Epoch: 5| Step: 5
Training loss: 0.45594263076782227
Validation loss: 1.7005761477255052

Epoch: 5| Step: 6
Training loss: 0.2381691038608551
Validation loss: 1.7148986042186778

Epoch: 5| Step: 7
Training loss: 0.4552142024040222
Validation loss: 1.6927507564585695

Epoch: 5| Step: 8
Training loss: 0.7236893773078918
Validation loss: 1.6797982883709732

Epoch: 5| Step: 9
Training loss: 0.3708525598049164
Validation loss: 1.680975749928464

Epoch: 5| Step: 10
Training loss: 0.5156871676445007
Validation loss: 1.7069376335349133

Epoch: 362| Step: 0
Training loss: 0.4678191542625427
Validation loss: 1.7059642794311687

Epoch: 5| Step: 1
Training loss: 0.3778638243675232
Validation loss: 1.7054880780558432

Epoch: 5| Step: 2
Training loss: 0.6941975951194763
Validation loss: 1.6671831902637277

Epoch: 5| Step: 3
Training loss: 0.5549864768981934
Validation loss: 1.6807104208136117

Epoch: 5| Step: 4
Training loss: 0.3814237117767334
Validation loss: 1.6759828085540442

Epoch: 5| Step: 5
Training loss: 0.5052620768547058
Validation loss: 1.7049049369750484

Epoch: 5| Step: 6
Training loss: 0.4439684748649597
Validation loss: 1.7074013756167503

Epoch: 5| Step: 7
Training loss: 0.35443758964538574
Validation loss: 1.7359740247008622

Epoch: 5| Step: 8
Training loss: 0.45421695709228516
Validation loss: 1.724038290721114

Epoch: 5| Step: 9
Training loss: 0.3347848057746887
Validation loss: 1.7292286478063112

Epoch: 5| Step: 10
Training loss: 0.5010005235671997
Validation loss: 1.7171926408685663

Epoch: 363| Step: 0
Training loss: 0.3641800880432129
Validation loss: 1.7202251483035345

Epoch: 5| Step: 1
Training loss: 0.48794689774513245
Validation loss: 1.7209242223411478

Epoch: 5| Step: 2
Training loss: 0.39524489641189575
Validation loss: 1.7065562419993903

Epoch: 5| Step: 3
Training loss: 0.5258697271347046
Validation loss: 1.6945827340566983

Epoch: 5| Step: 4
Training loss: 0.5466398596763611
Validation loss: 1.6735145789320751

Epoch: 5| Step: 5
Training loss: 0.30698198080062866
Validation loss: 1.6531211330044655

Epoch: 5| Step: 6
Training loss: 0.37558338046073914
Validation loss: 1.6573537857301774

Epoch: 5| Step: 7
Training loss: 0.5473121404647827
Validation loss: 1.6552236759534447

Epoch: 5| Step: 8
Training loss: 0.5319298505783081
Validation loss: 1.6626178487654655

Epoch: 5| Step: 9
Training loss: 0.32197126746177673
Validation loss: 1.6461885962434994

Epoch: 5| Step: 10
Training loss: 0.5917790532112122
Validation loss: 1.6443444503250944

Epoch: 364| Step: 0
Training loss: 0.22483570873737335
Validation loss: 1.6836307048797607

Epoch: 5| Step: 1
Training loss: 0.37011393904685974
Validation loss: 1.6752659550277136

Epoch: 5| Step: 2
Training loss: 0.2774201035499573
Validation loss: 1.6752008904692948

Epoch: 5| Step: 3
Training loss: 0.4112843871116638
Validation loss: 1.6866717569289669

Epoch: 5| Step: 4
Training loss: 0.46323108673095703
Validation loss: 1.6991435866202078

Epoch: 5| Step: 5
Training loss: 0.8731916546821594
Validation loss: 1.6728544658230198

Epoch: 5| Step: 6
Training loss: 0.45064496994018555
Validation loss: 1.6955427585109588

Epoch: 5| Step: 7
Training loss: 0.3245104253292084
Validation loss: 1.6760067991031113

Epoch: 5| Step: 8
Training loss: 0.46408843994140625
Validation loss: 1.6840145305920673

Epoch: 5| Step: 9
Training loss: 0.4411107003688812
Validation loss: 1.6732069997377292

Epoch: 5| Step: 10
Training loss: 0.545240044593811
Validation loss: 1.655949443899175

Epoch: 365| Step: 0
Training loss: 0.35571739077568054
Validation loss: 1.6864473217277116

Epoch: 5| Step: 1
Training loss: 0.48481011390686035
Validation loss: 1.677244932420792

Epoch: 5| Step: 2
Training loss: 0.33966270089149475
Validation loss: 1.701986587175759

Epoch: 5| Step: 3
Training loss: 0.40907588601112366
Validation loss: 1.6931490334131385

Epoch: 5| Step: 4
Training loss: 0.5310653448104858
Validation loss: 1.6747794894761936

Epoch: 5| Step: 5
Training loss: 0.43736106157302856
Validation loss: 1.6816657281691028

Epoch: 5| Step: 6
Training loss: 0.5806384086608887
Validation loss: 1.689511283751457

Epoch: 5| Step: 7
Training loss: 0.4024084210395813
Validation loss: 1.6854952227684759

Epoch: 5| Step: 8
Training loss: 0.2658720910549164
Validation loss: 1.7165063504249818

Epoch: 5| Step: 9
Training loss: 0.35681331157684326
Validation loss: 1.7124435568368563

Epoch: 5| Step: 10
Training loss: 0.594174325466156
Validation loss: 1.6910553747607815

Epoch: 366| Step: 0
Training loss: 0.4107421040534973
Validation loss: 1.6712715766763175

Epoch: 5| Step: 1
Training loss: 0.49397021532058716
Validation loss: 1.6700186588430916

Epoch: 5| Step: 2
Training loss: 0.5780012011528015
Validation loss: 1.6600511048429756

Epoch: 5| Step: 3
Training loss: 0.4887116551399231
Validation loss: 1.6764989206867833

Epoch: 5| Step: 4
Training loss: 0.2547658681869507
Validation loss: 1.6505552722561745

Epoch: 5| Step: 5
Training loss: 0.41090840101242065
Validation loss: 1.6306913219472414

Epoch: 5| Step: 6
Training loss: 0.5585736632347107
Validation loss: 1.6313984752983175

Epoch: 5| Step: 7
Training loss: 0.38762152194976807
Validation loss: 1.6241755024079354

Epoch: 5| Step: 8
Training loss: 0.3568463921546936
Validation loss: 1.661333757062112

Epoch: 5| Step: 9
Training loss: 0.5009104013442993
Validation loss: 1.6718985111482683

Epoch: 5| Step: 10
Training loss: 0.5808857083320618
Validation loss: 1.66939535064082

Epoch: 367| Step: 0
Training loss: 0.5422130823135376
Validation loss: 1.7048295902949508

Epoch: 5| Step: 1
Training loss: 0.4659334719181061
Validation loss: 1.7297457975725974

Epoch: 5| Step: 2
Training loss: 0.39170604944229126
Validation loss: 1.7120149225317023

Epoch: 5| Step: 3
Training loss: 0.47729605436325073
Validation loss: 1.711991963847991

Epoch: 5| Step: 4
Training loss: 0.2962428033351898
Validation loss: 1.6856634078487274

Epoch: 5| Step: 5
Training loss: 0.34900927543640137
Validation loss: 1.6761594433938303

Epoch: 5| Step: 6
Training loss: 0.40916934609413147
Validation loss: 1.657749806680987

Epoch: 5| Step: 7
Training loss: 0.5252774953842163
Validation loss: 1.647085259037633

Epoch: 5| Step: 8
Training loss: 0.5451898574829102
Validation loss: 1.6374956689855105

Epoch: 5| Step: 9
Training loss: 0.5276328325271606
Validation loss: 1.6369151620454685

Epoch: 5| Step: 10
Training loss: 0.5003188252449036
Validation loss: 1.6614465008499801

Epoch: 368| Step: 0
Training loss: 0.45456749200820923
Validation loss: 1.6798213681867045

Epoch: 5| Step: 1
Training loss: 0.3562517762184143
Validation loss: 1.6787565651760306

Epoch: 5| Step: 2
Training loss: 0.3446896970272064
Validation loss: 1.6954179925303305

Epoch: 5| Step: 3
Training loss: 0.5003634095191956
Validation loss: 1.6859670954365884

Epoch: 5| Step: 4
Training loss: 0.2826107144355774
Validation loss: 1.6829954501121276

Epoch: 5| Step: 5
Training loss: 0.4655505120754242
Validation loss: 1.693660689938453

Epoch: 5| Step: 6
Training loss: 0.4877685606479645
Validation loss: 1.6711614593382804

Epoch: 5| Step: 7
Training loss: 0.5631807446479797
Validation loss: 1.6894649356924079

Epoch: 5| Step: 8
Training loss: 0.4775862693786621
Validation loss: 1.6758908661462928

Epoch: 5| Step: 9
Training loss: 0.4763617515563965
Validation loss: 1.6783912681764173

Epoch: 5| Step: 10
Training loss: 0.4439069330692291
Validation loss: 1.6795547303333078

Epoch: 369| Step: 0
Training loss: 0.7130082845687866
Validation loss: 1.6707447369893391

Epoch: 5| Step: 1
Training loss: 0.5497428178787231
Validation loss: 1.6493972142537434

Epoch: 5| Step: 2
Training loss: 0.3983679413795471
Validation loss: 1.6746500294695619

Epoch: 5| Step: 3
Training loss: 0.4991333484649658
Validation loss: 1.6741586500598538

Epoch: 5| Step: 4
Training loss: 0.2204454392194748
Validation loss: 1.6873169740041096

Epoch: 5| Step: 5
Training loss: 0.3658360242843628
Validation loss: 1.683847012058381

Epoch: 5| Step: 6
Training loss: 0.5168622136116028
Validation loss: 1.7166037905600764

Epoch: 5| Step: 7
Training loss: 0.3676583170890808
Validation loss: 1.7155482974103702

Epoch: 5| Step: 8
Training loss: 0.5517084002494812
Validation loss: 1.7009624896510955

Epoch: 5| Step: 9
Training loss: 0.383343368768692
Validation loss: 1.704357870163456

Epoch: 5| Step: 10
Training loss: 0.39097467064857483
Validation loss: 1.717406565143216

Epoch: 370| Step: 0
Training loss: 0.5712290406227112
Validation loss: 1.7314205887497112

Epoch: 5| Step: 1
Training loss: 0.3515486717224121
Validation loss: 1.7290272943435177

Epoch: 5| Step: 2
Training loss: 0.2639864385128021
Validation loss: 1.6982951407791467

Epoch: 5| Step: 3
Training loss: 0.6833860278129578
Validation loss: 1.7119050090030958

Epoch: 5| Step: 4
Training loss: 0.27031803131103516
Validation loss: 1.7031388962140648

Epoch: 5| Step: 5
Training loss: 0.38038021326065063
Validation loss: 1.6804713427379567

Epoch: 5| Step: 6
Training loss: 0.40672001242637634
Validation loss: 1.6921757139185423

Epoch: 5| Step: 7
Training loss: 0.2940575182437897
Validation loss: 1.6962151758132442

Epoch: 5| Step: 8
Training loss: 0.5319265127182007
Validation loss: 1.6434521854564708

Epoch: 5| Step: 9
Training loss: 0.3500162661075592
Validation loss: 1.684566201702241

Epoch: 5| Step: 10
Training loss: 0.7885181307792664
Validation loss: 1.682450266294582

Epoch: 371| Step: 0
Training loss: 0.45080241560935974
Validation loss: 1.6710579087657313

Epoch: 5| Step: 1
Training loss: 0.18691176176071167
Validation loss: 1.691024826418969

Epoch: 5| Step: 2
Training loss: 0.6169611215591431
Validation loss: 1.6802372535069783

Epoch: 5| Step: 3
Training loss: 0.4652593731880188
Validation loss: 1.6715178489685059

Epoch: 5| Step: 4
Training loss: 0.36139342188835144
Validation loss: 1.696443057829334

Epoch: 5| Step: 5
Training loss: 0.32396793365478516
Validation loss: 1.6724802255630493

Epoch: 5| Step: 6
Training loss: 0.41987818479537964
Validation loss: 1.7171927177777855

Epoch: 5| Step: 7
Training loss: 0.8630290031433105
Validation loss: 1.7226990358803862

Epoch: 5| Step: 8
Training loss: 0.3636295795440674
Validation loss: 1.7306035423791537

Epoch: 5| Step: 9
Training loss: 0.3265654444694519
Validation loss: 1.7478921336512412

Epoch: 5| Step: 10
Training loss: 0.3840057849884033
Validation loss: 1.7256214144409343

Epoch: 372| Step: 0
Training loss: 0.44899678230285645
Validation loss: 1.7273231270492717

Epoch: 5| Step: 1
Training loss: 0.339368999004364
Validation loss: 1.6990258341194482

Epoch: 5| Step: 2
Training loss: 0.7644443511962891
Validation loss: 1.7041947559643817

Epoch: 5| Step: 3
Training loss: 0.25431931018829346
Validation loss: 1.7041918577686432

Epoch: 5| Step: 4
Training loss: 0.3566588759422302
Validation loss: 1.6910021907539778

Epoch: 5| Step: 5
Training loss: 0.41028690338134766
Validation loss: 1.6987158252346901

Epoch: 5| Step: 6
Training loss: 0.68931645154953
Validation loss: 1.6400873225222352

Epoch: 5| Step: 7
Training loss: 0.43644270300865173
Validation loss: 1.6235946378400248

Epoch: 5| Step: 8
Training loss: 0.23429012298583984
Validation loss: 1.668164740326584

Epoch: 5| Step: 9
Training loss: 0.2463863641023636
Validation loss: 1.6630434605383104

Epoch: 5| Step: 10
Training loss: 0.45175737142562866
Validation loss: 1.652347573670008

Epoch: 373| Step: 0
Training loss: 0.2914886176586151
Validation loss: 1.667505133536554

Epoch: 5| Step: 1
Training loss: 0.4952269196510315
Validation loss: 1.6900669502955612

Epoch: 5| Step: 2
Training loss: 0.46145114302635193
Validation loss: 1.6897015366502988

Epoch: 5| Step: 3
Training loss: 0.3844330906867981
Validation loss: 1.6812225772488503

Epoch: 5| Step: 4
Training loss: 0.49315232038497925
Validation loss: 1.6850223413077734

Epoch: 5| Step: 5
Training loss: 0.5072294473648071
Validation loss: 1.6560659690569806

Epoch: 5| Step: 6
Training loss: 0.5729624629020691
Validation loss: 1.6644463462214316

Epoch: 5| Step: 7
Training loss: 0.6377872228622437
Validation loss: 1.6402524914792789

Epoch: 5| Step: 8
Training loss: 0.33280450105667114
Validation loss: 1.6511212548901957

Epoch: 5| Step: 9
Training loss: 0.22443664073944092
Validation loss: 1.6609912687732327

Epoch: 5| Step: 10
Training loss: 0.2551301121711731
Validation loss: 1.6666079785234185

Epoch: 374| Step: 0
Training loss: 0.47396811842918396
Validation loss: 1.668094042808779

Epoch: 5| Step: 1
Training loss: 0.3524554371833801
Validation loss: 1.6768869635879353

Epoch: 5| Step: 2
Training loss: 0.3273668885231018
Validation loss: 1.6785467017081477

Epoch: 5| Step: 3
Training loss: 0.24878151714801788
Validation loss: 1.6904956845827

Epoch: 5| Step: 4
Training loss: 0.487466961145401
Validation loss: 1.6896596006167832

Epoch: 5| Step: 5
Training loss: 0.769625186920166
Validation loss: 1.695470643299882

Epoch: 5| Step: 6
Training loss: 0.2733384966850281
Validation loss: 1.6940674089616345

Epoch: 5| Step: 7
Training loss: 0.3054218292236328
Validation loss: 1.6533363711449407

Epoch: 5| Step: 8
Training loss: 0.6307559013366699
Validation loss: 1.6615976851473573

Epoch: 5| Step: 9
Training loss: 0.31679192185401917
Validation loss: 1.7039394135116248

Epoch: 5| Step: 10
Training loss: 0.5005282163619995
Validation loss: 1.6884485636987994

Epoch: 375| Step: 0
Training loss: 0.38182884454727173
Validation loss: 1.6886352018643451

Epoch: 5| Step: 1
Training loss: 0.7408971786499023
Validation loss: 1.7059936331164451

Epoch: 5| Step: 2
Training loss: 0.4941716194152832
Validation loss: 1.7175467283495012

Epoch: 5| Step: 3
Training loss: 0.42861002683639526
Validation loss: 1.7183510667534285

Epoch: 5| Step: 4
Training loss: 0.28271833062171936
Validation loss: 1.721399582842345

Epoch: 5| Step: 5
Training loss: 0.40902209281921387
Validation loss: 1.7234491045757006

Epoch: 5| Step: 6
Training loss: 0.4760940670967102
Validation loss: 1.7320723277266308

Epoch: 5| Step: 7
Training loss: 0.37024176120758057
Validation loss: 1.7151530199153449

Epoch: 5| Step: 8
Training loss: 0.44757795333862305
Validation loss: 1.6992796031377648

Epoch: 5| Step: 9
Training loss: 0.35023823380470276
Validation loss: 1.6722230898436679

Epoch: 5| Step: 10
Training loss: 0.3973139226436615
Validation loss: 1.711379740827827

Epoch: 376| Step: 0
Training loss: 0.2632790505886078
Validation loss: 1.687878336957706

Epoch: 5| Step: 1
Training loss: 0.3827766478061676
Validation loss: 1.6734818207320346

Epoch: 5| Step: 2
Training loss: 0.661361813545227
Validation loss: 1.684592080372636

Epoch: 5| Step: 3
Training loss: 0.41880136728286743
Validation loss: 1.7020819584528606

Epoch: 5| Step: 4
Training loss: 0.5222492814064026
Validation loss: 1.690848760707404

Epoch: 5| Step: 5
Training loss: 0.6293718218803406
Validation loss: 1.7028507865885252

Epoch: 5| Step: 6
Training loss: 0.21596279740333557
Validation loss: 1.693203390285533

Epoch: 5| Step: 7
Training loss: 0.28365081548690796
Validation loss: 1.6908277003995833

Epoch: 5| Step: 8
Training loss: 0.3674297332763672
Validation loss: 1.674772862465151

Epoch: 5| Step: 9
Training loss: 0.3087131977081299
Validation loss: 1.6656911962775773

Epoch: 5| Step: 10
Training loss: 0.4169486463069916
Validation loss: 1.6674209474235453

Epoch: 377| Step: 0
Training loss: 0.39412009716033936
Validation loss: 1.6585411666541972

Epoch: 5| Step: 1
Training loss: 0.4591699540615082
Validation loss: 1.654756481929492

Epoch: 5| Step: 2
Training loss: 0.3340016305446625
Validation loss: 1.6813251715834423

Epoch: 5| Step: 3
Training loss: 0.41313308477401733
Validation loss: 1.6839572716784734

Epoch: 5| Step: 4
Training loss: 0.44129204750061035
Validation loss: 1.672533986388996

Epoch: 5| Step: 5
Training loss: 0.6066733598709106
Validation loss: 1.6651270658739152

Epoch: 5| Step: 6
Training loss: 0.5293858647346497
Validation loss: 1.6632841556302962

Epoch: 5| Step: 7
Training loss: 0.0938301831483841
Validation loss: 1.671939306361701

Epoch: 5| Step: 8
Training loss: 0.4154384136199951
Validation loss: 1.6792482637589978

Epoch: 5| Step: 9
Training loss: 0.4325067102909088
Validation loss: 1.6993567853845575

Epoch: 5| Step: 10
Training loss: 0.28609606623649597
Validation loss: 1.6934760180852746

Epoch: 378| Step: 0
Training loss: 0.22635838389396667
Validation loss: 1.6540034317201184

Epoch: 5| Step: 1
Training loss: 0.45224228501319885
Validation loss: 1.6477719558182584

Epoch: 5| Step: 2
Training loss: 0.3487154543399811
Validation loss: 1.6461077813179261

Epoch: 5| Step: 3
Training loss: 0.21871328353881836
Validation loss: 1.644246990962695

Epoch: 5| Step: 4
Training loss: 0.6569852828979492
Validation loss: 1.6417261720985494

Epoch: 5| Step: 5
Training loss: 0.336870014667511
Validation loss: 1.6437852715933194

Epoch: 5| Step: 6
Training loss: 0.6223365068435669
Validation loss: 1.6247594151445615

Epoch: 5| Step: 7
Training loss: 0.35947033762931824
Validation loss: 1.6235547399008146

Epoch: 5| Step: 8
Training loss: 0.5126951336860657
Validation loss: 1.640260778447633

Epoch: 5| Step: 9
Training loss: 0.45339831709861755
Validation loss: 1.6692348475097327

Epoch: 5| Step: 10
Training loss: 0.4376794099807739
Validation loss: 1.665908222557396

Epoch: 379| Step: 0
Training loss: 0.5807161927223206
Validation loss: 1.6838736841755528

Epoch: 5| Step: 1
Training loss: 0.3684781491756439
Validation loss: 1.6723382793447024

Epoch: 5| Step: 2
Training loss: 0.4107878804206848
Validation loss: 1.6659350869476155

Epoch: 5| Step: 3
Training loss: 0.3918553590774536
Validation loss: 1.6375245535245506

Epoch: 5| Step: 4
Training loss: 0.38718047738075256
Validation loss: 1.652666905874847

Epoch: 5| Step: 5
Training loss: 0.4843171238899231
Validation loss: 1.6185510901994602

Epoch: 5| Step: 6
Training loss: 0.46033531427383423
Validation loss: 1.6109308171015915

Epoch: 5| Step: 7
Training loss: 0.14978346228599548
Validation loss: 1.633871486110072

Epoch: 5| Step: 8
Training loss: 0.46403151750564575
Validation loss: 1.6160832899872974

Epoch: 5| Step: 9
Training loss: 0.3698272705078125
Validation loss: 1.6568502956821072

Epoch: 5| Step: 10
Training loss: 0.4774089753627777
Validation loss: 1.6356545494448753

Epoch: 380| Step: 0
Training loss: 0.40910348296165466
Validation loss: 1.6443684742014895

Epoch: 5| Step: 1
Training loss: 0.2329261302947998
Validation loss: 1.6612131851975636

Epoch: 5| Step: 2
Training loss: 0.6304022073745728
Validation loss: 1.641171984775092

Epoch: 5| Step: 3
Training loss: 0.3890992999076843
Validation loss: 1.6451660484396002

Epoch: 5| Step: 4
Training loss: 0.25637921690940857
Validation loss: 1.6470902171186221

Epoch: 5| Step: 5
Training loss: 0.4844028055667877
Validation loss: 1.6509671044606034

Epoch: 5| Step: 6
Training loss: 0.365925133228302
Validation loss: 1.6377661279452744

Epoch: 5| Step: 7
Training loss: 0.27227601408958435
Validation loss: 1.6562444061361334

Epoch: 5| Step: 8
Training loss: 0.25451523065567017
Validation loss: 1.648286457984678

Epoch: 5| Step: 9
Training loss: 0.3455577492713928
Validation loss: 1.6336862092377038

Epoch: 5| Step: 10
Training loss: 0.6943094730377197
Validation loss: 1.6465923939981768

Epoch: 381| Step: 0
Training loss: 0.38901105523109436
Validation loss: 1.655495451342675

Epoch: 5| Step: 1
Training loss: 0.35000303387641907
Validation loss: 1.6798550454519128

Epoch: 5| Step: 2
Training loss: 0.5076411962509155
Validation loss: 1.6780060645072692

Epoch: 5| Step: 3
Training loss: 0.5189501643180847
Validation loss: 1.670023997624715

Epoch: 5| Step: 4
Training loss: 0.30809637904167175
Validation loss: 1.635337669362304

Epoch: 5| Step: 5
Training loss: 0.5472750663757324
Validation loss: 1.6443220184695335

Epoch: 5| Step: 6
Training loss: 0.15084952116012573
Validation loss: 1.6417325119818411

Epoch: 5| Step: 7
Training loss: 0.2922687828540802
Validation loss: 1.6371270110530238

Epoch: 5| Step: 8
Training loss: 0.3552359938621521
Validation loss: 1.6415003922677809

Epoch: 5| Step: 9
Training loss: 0.4944896697998047
Validation loss: 1.642169338400646

Epoch: 5| Step: 10
Training loss: 0.5209391117095947
Validation loss: 1.6306778500157018

Epoch: 382| Step: 0
Training loss: 0.24751806259155273
Validation loss: 1.627926052257579

Epoch: 5| Step: 1
Training loss: 0.4438784718513489
Validation loss: 1.624903489184636

Epoch: 5| Step: 2
Training loss: 0.41890639066696167
Validation loss: 1.6445093603544338

Epoch: 5| Step: 3
Training loss: 0.32295578718185425
Validation loss: 1.6309297264263194

Epoch: 5| Step: 4
Training loss: 0.4564167857170105
Validation loss: 1.6218343601431897

Epoch: 5| Step: 5
Training loss: 0.21500149369239807
Validation loss: 1.6291139856461556

Epoch: 5| Step: 6
Training loss: 0.358331561088562
Validation loss: 1.6343525571207846

Epoch: 5| Step: 7
Training loss: 0.27325350046157837
Validation loss: 1.6242763457759735

Epoch: 5| Step: 8
Training loss: 0.5203579664230347
Validation loss: 1.6179389735703826

Epoch: 5| Step: 9
Training loss: 0.7135081887245178
Validation loss: 1.6302961341796383

Epoch: 5| Step: 10
Training loss: 0.3070133328437805
Validation loss: 1.6601992858353483

Epoch: 383| Step: 0
Training loss: 0.2439025342464447
Validation loss: 1.6418794444812241

Epoch: 5| Step: 1
Training loss: 0.36732664704322815
Validation loss: 1.6312395577789636

Epoch: 5| Step: 2
Training loss: 0.6060874462127686
Validation loss: 1.6189555327097576

Epoch: 5| Step: 3
Training loss: 0.44485554099082947
Validation loss: 1.63490935807587

Epoch: 5| Step: 4
Training loss: 0.488588809967041
Validation loss: 1.6239294582797634

Epoch: 5| Step: 5
Training loss: 0.4008099436759949
Validation loss: 1.6233947687251593

Epoch: 5| Step: 6
Training loss: 0.2558691203594208
Validation loss: 1.6287611940855622

Epoch: 5| Step: 7
Training loss: 0.27958551049232483
Validation loss: 1.6204652914436914

Epoch: 5| Step: 8
Training loss: 0.2804434895515442
Validation loss: 1.6379800983654556

Epoch: 5| Step: 9
Training loss: 0.5049472451210022
Validation loss: 1.6273723379258187

Epoch: 5| Step: 10
Training loss: 0.32588502764701843
Validation loss: 1.6647369118147

Epoch: 384| Step: 0
Training loss: 0.4041898846626282
Validation loss: 1.6317714016924623

Epoch: 5| Step: 1
Training loss: 0.26652416586875916
Validation loss: 1.645587900633453

Epoch: 5| Step: 2
Training loss: 0.41837725043296814
Validation loss: 1.6356754790070236

Epoch: 5| Step: 3
Training loss: 0.5636308193206787
Validation loss: 1.6312103784212502

Epoch: 5| Step: 4
Training loss: 0.30707377195358276
Validation loss: 1.633724913802198

Epoch: 5| Step: 5
Training loss: 0.35016342997550964
Validation loss: 1.648383144409426

Epoch: 5| Step: 6
Training loss: 0.15581221878528595
Validation loss: 1.5966387717954573

Epoch: 5| Step: 7
Training loss: 0.4860681891441345
Validation loss: 1.6312827730691561

Epoch: 5| Step: 8
Training loss: 0.540812075138092
Validation loss: 1.651705067644837

Epoch: 5| Step: 9
Training loss: 0.26274359226226807
Validation loss: 1.6603685463628461

Epoch: 5| Step: 10
Training loss: 0.3944636583328247
Validation loss: 1.689485494808484

Epoch: 385| Step: 0
Training loss: 0.4501509666442871
Validation loss: 1.6976875156484625

Epoch: 5| Step: 1
Training loss: 0.4966354966163635
Validation loss: 1.704668637244932

Epoch: 5| Step: 2
Training loss: 0.449896901845932
Validation loss: 1.7168336901613461

Epoch: 5| Step: 3
Training loss: 0.323499470949173
Validation loss: 1.675068409212174

Epoch: 5| Step: 4
Training loss: 0.3658921420574188
Validation loss: 1.660192749833548

Epoch: 5| Step: 5
Training loss: 0.448483943939209
Validation loss: 1.6460758639920143

Epoch: 5| Step: 6
Training loss: 0.37356239557266235
Validation loss: 1.626329166914827

Epoch: 5| Step: 7
Training loss: 0.16263748705387115
Validation loss: 1.6419172748442619

Epoch: 5| Step: 8
Training loss: 0.25561264157295227
Validation loss: 1.5904971957206726

Epoch: 5| Step: 9
Training loss: 0.45839667320251465
Validation loss: 1.622238689853299

Epoch: 5| Step: 10
Training loss: 0.516732394695282
Validation loss: 1.6384163492469377

Epoch: 386| Step: 0
Training loss: 0.38192111253738403
Validation loss: 1.6338929540367537

Epoch: 5| Step: 1
Training loss: 0.37968873977661133
Validation loss: 1.6897797904988772

Epoch: 5| Step: 2
Training loss: 0.36209335923194885
Validation loss: 1.6691458763614777

Epoch: 5| Step: 3
Training loss: 0.4859638214111328
Validation loss: 1.7137311376551145

Epoch: 5| Step: 4
Training loss: 0.39765867590904236
Validation loss: 1.6594135716397276

Epoch: 5| Step: 5
Training loss: 0.08752839267253876
Validation loss: 1.6292170786088513

Epoch: 5| Step: 6
Training loss: 0.6214306950569153
Validation loss: 1.6397545504313644

Epoch: 5| Step: 7
Training loss: 0.49972018599510193
Validation loss: 1.628597976059042

Epoch: 5| Step: 8
Training loss: 0.3283018469810486
Validation loss: 1.6564249306596734

Epoch: 5| Step: 9
Training loss: 0.34200945496559143
Validation loss: 1.6312732952897266

Epoch: 5| Step: 10
Training loss: 0.39609402418136597
Validation loss: 1.6399152663446241

Epoch: 387| Step: 0
Training loss: 0.5102419257164001
Validation loss: 1.6561751493843653

Epoch: 5| Step: 1
Training loss: 0.4887828230857849
Validation loss: 1.6783975785778416

Epoch: 5| Step: 2
Training loss: 0.30585977435112
Validation loss: 1.6765952738382484

Epoch: 5| Step: 3
Training loss: 0.3716815114021301
Validation loss: 1.698350268025552

Epoch: 5| Step: 4
Training loss: 0.2779086232185364
Validation loss: 1.6833957677246423

Epoch: 5| Step: 5
Training loss: 0.2402302324771881
Validation loss: 1.7007285676976687

Epoch: 5| Step: 6
Training loss: 0.5047175884246826
Validation loss: 1.6723762314806703

Epoch: 5| Step: 7
Training loss: 0.38535574078559875
Validation loss: 1.656673240405257

Epoch: 5| Step: 8
Training loss: 0.5089446306228638
Validation loss: 1.650166352589925

Epoch: 5| Step: 9
Training loss: 0.2057572305202484
Validation loss: 1.604883281133508

Epoch: 5| Step: 10
Training loss: 0.5534853935241699
Validation loss: 1.609884250548578

Epoch: 388| Step: 0
Training loss: 0.5176002979278564
Validation loss: 1.6362513810075738

Epoch: 5| Step: 1
Training loss: 0.3653976321220398
Validation loss: 1.603242257589935

Epoch: 5| Step: 2
Training loss: 0.3143203556537628
Validation loss: 1.6098923977985178

Epoch: 5| Step: 3
Training loss: 0.35905468463897705
Validation loss: 1.5891796683752408

Epoch: 5| Step: 4
Training loss: 0.28771838545799255
Validation loss: 1.6209483774759437

Epoch: 5| Step: 5
Training loss: 0.5267843008041382
Validation loss: 1.5951640208562214

Epoch: 5| Step: 6
Training loss: 0.1747289001941681
Validation loss: 1.6304554349632674

Epoch: 5| Step: 7
Training loss: 0.4165527820587158
Validation loss: 1.6295309476954962

Epoch: 5| Step: 8
Training loss: 0.35260510444641113
Validation loss: 1.633334323924075

Epoch: 5| Step: 9
Training loss: 0.4415428042411804
Validation loss: 1.637473612703303

Epoch: 5| Step: 10
Training loss: 0.35213345289230347
Validation loss: 1.6386535424058155

Epoch: 389| Step: 0
Training loss: 0.5485180616378784
Validation loss: 1.6366308299444055

Epoch: 5| Step: 1
Training loss: 0.42502498626708984
Validation loss: 1.6121365011379283

Epoch: 5| Step: 2
Training loss: 0.3184039294719696
Validation loss: 1.6026955958335631

Epoch: 5| Step: 3
Training loss: 0.4020267426967621
Validation loss: 1.6186172321278562

Epoch: 5| Step: 4
Training loss: 0.3695046007633209
Validation loss: 1.6077043817889305

Epoch: 5| Step: 5
Training loss: 0.2648729681968689
Validation loss: 1.6071323925449001

Epoch: 5| Step: 6
Training loss: 0.4692502021789551
Validation loss: 1.6075178423235494

Epoch: 5| Step: 7
Training loss: 0.192780539393425
Validation loss: 1.612514171549069

Epoch: 5| Step: 8
Training loss: 0.33539262413978577
Validation loss: 1.6024601215957313

Epoch: 5| Step: 9
Training loss: 0.2945822775363922
Validation loss: 1.6427897176434916

Epoch: 5| Step: 10
Training loss: 0.4201018810272217
Validation loss: 1.6550846138308126

Epoch: 390| Step: 0
Training loss: 0.4306020736694336
Validation loss: 1.6533067739138039

Epoch: 5| Step: 1
Training loss: 0.3804474174976349
Validation loss: 1.6747418065224924

Epoch: 5| Step: 2
Training loss: 0.31103605031967163
Validation loss: 1.6989755502311132

Epoch: 5| Step: 3
Training loss: 0.5966894030570984
Validation loss: 1.6578331160288986

Epoch: 5| Step: 4
Training loss: 0.337629109621048
Validation loss: 1.666862988984713

Epoch: 5| Step: 5
Training loss: 0.35870617628097534
Validation loss: 1.6506567296161447

Epoch: 5| Step: 6
Training loss: 0.23139755427837372
Validation loss: 1.6367526413292013

Epoch: 5| Step: 7
Training loss: 0.4167498052120209
Validation loss: 1.6070956914655623

Epoch: 5| Step: 8
Training loss: 0.24321198463439941
Validation loss: 1.618956660711637

Epoch: 5| Step: 9
Training loss: 0.3551097810268402
Validation loss: 1.6165517709588493

Epoch: 5| Step: 10
Training loss: 0.3773411810398102
Validation loss: 1.6023911852990427

Epoch: 391| Step: 0
Training loss: 0.2493751049041748
Validation loss: 1.61953902757296

Epoch: 5| Step: 1
Training loss: 0.4150599539279938
Validation loss: 1.6081332698945077

Epoch: 5| Step: 2
Training loss: 0.2963539958000183
Validation loss: 1.6394302383545907

Epoch: 5| Step: 3
Training loss: 0.2714388966560364
Validation loss: 1.6173496656520392

Epoch: 5| Step: 4
Training loss: 0.3017174005508423
Validation loss: 1.6531942967445619

Epoch: 5| Step: 5
Training loss: 0.43686971068382263
Validation loss: 1.6341500961652367

Epoch: 5| Step: 6
Training loss: 0.45235657691955566
Validation loss: 1.6366826334307272

Epoch: 5| Step: 7
Training loss: 0.5075918436050415
Validation loss: 1.660147169584869

Epoch: 5| Step: 8
Training loss: 0.5953313112258911
Validation loss: 1.693912939358783

Epoch: 5| Step: 9
Training loss: 0.3609851896762848
Validation loss: 1.6525781334087413

Epoch: 5| Step: 10
Training loss: 0.17986980080604553
Validation loss: 1.639258720541513

Epoch: 392| Step: 0
Training loss: 0.48427098989486694
Validation loss: 1.6508770514560003

Epoch: 5| Step: 1
Training loss: 0.344836950302124
Validation loss: 1.6365768653090282

Epoch: 5| Step: 2
Training loss: 0.41160258650779724
Validation loss: 1.6413120608175955

Epoch: 5| Step: 3
Training loss: 0.3133745491504669
Validation loss: 1.6372119508763796

Epoch: 5| Step: 4
Training loss: 0.3729678988456726
Validation loss: 1.6302162011464436

Epoch: 5| Step: 5
Training loss: 0.30483245849609375
Validation loss: 1.6198370725877824

Epoch: 5| Step: 6
Training loss: 0.4826931953430176
Validation loss: 1.6430240510612406

Epoch: 5| Step: 7
Training loss: 0.2167816460132599
Validation loss: 1.6362856485510384

Epoch: 5| Step: 8
Training loss: 0.45836979150772095
Validation loss: 1.6304019240922825

Epoch: 5| Step: 9
Training loss: 0.34948021173477173
Validation loss: 1.6382566440489985

Epoch: 5| Step: 10
Training loss: 0.32996866106987
Validation loss: 1.6592939117903351

Epoch: 393| Step: 0
Training loss: 0.22717809677124023
Validation loss: 1.6735510723565215

Epoch: 5| Step: 1
Training loss: 0.35181766748428345
Validation loss: 1.6775410059959657

Epoch: 5| Step: 2
Training loss: 0.5167660713195801
Validation loss: 1.6401001637981785

Epoch: 5| Step: 3
Training loss: 0.6060975790023804
Validation loss: 1.630218586614055

Epoch: 5| Step: 4
Training loss: 0.25896474719047546
Validation loss: 1.6540765121418943

Epoch: 5| Step: 5
Training loss: 0.4356679916381836
Validation loss: 1.676679204869014

Epoch: 5| Step: 6
Training loss: 0.2456982135772705
Validation loss: 1.666210029714851

Epoch: 5| Step: 7
Training loss: 0.6781275868415833
Validation loss: 1.6457324694561701

Epoch: 5| Step: 8
Training loss: 0.33656302094459534
Validation loss: 1.6195218921989523

Epoch: 5| Step: 9
Training loss: 0.33053120970726013
Validation loss: 1.6193508640412362

Epoch: 5| Step: 10
Training loss: 0.2245652824640274
Validation loss: 1.6122054226936833

Epoch: 394| Step: 0
Training loss: 0.31664538383483887
Validation loss: 1.6081472955724245

Epoch: 5| Step: 1
Training loss: 0.3897427022457123
Validation loss: 1.602376909666164

Epoch: 5| Step: 2
Training loss: 0.3484947085380554
Validation loss: 1.6099401212507678

Epoch: 5| Step: 3
Training loss: 0.5671665668487549
Validation loss: 1.62573290512126

Epoch: 5| Step: 4
Training loss: 0.2694989740848541
Validation loss: 1.623298906510876

Epoch: 5| Step: 5
Training loss: 0.4986002445220947
Validation loss: 1.636149045600686

Epoch: 5| Step: 6
Training loss: 0.36240154504776
Validation loss: 1.642383506221156

Epoch: 5| Step: 7
Training loss: 0.14647838473320007
Validation loss: 1.6428192700109174

Epoch: 5| Step: 8
Training loss: 0.39429348707199097
Validation loss: 1.6262083579135198

Epoch: 5| Step: 9
Training loss: 0.3752900958061218
Validation loss: 1.6289210601519513

Epoch: 5| Step: 10
Training loss: 0.335759699344635
Validation loss: 1.670810084189138

Epoch: 395| Step: 0
Training loss: 0.42465701699256897
Validation loss: 1.658700458465084

Epoch: 5| Step: 1
Training loss: 0.23705165088176727
Validation loss: 1.6109475551113006

Epoch: 5| Step: 2
Training loss: 0.3214358687400818
Validation loss: 1.6162039759338542

Epoch: 5| Step: 3
Training loss: 0.4830964207649231
Validation loss: 1.605453150246733

Epoch: 5| Step: 4
Training loss: 0.3595273196697235
Validation loss: 1.6125488858069144

Epoch: 5| Step: 5
Training loss: 0.28026604652404785
Validation loss: 1.6396064899301017

Epoch: 5| Step: 6
Training loss: 0.6398584246635437
Validation loss: 1.6356594741985362

Epoch: 5| Step: 7
Training loss: 0.5223931074142456
Validation loss: 1.6214385532563733

Epoch: 5| Step: 8
Training loss: 0.3209335207939148
Validation loss: 1.6129613768669866

Epoch: 5| Step: 9
Training loss: 0.4679489731788635
Validation loss: 1.6086057398908882

Epoch: 5| Step: 10
Training loss: 0.2992330491542816
Validation loss: 1.616740088309011

Epoch: 396| Step: 0
Training loss: 0.5494442582130432
Validation loss: 1.6162755604713195

Epoch: 5| Step: 1
Training loss: 0.3440897464752197
Validation loss: 1.5972364807641635

Epoch: 5| Step: 2
Training loss: 0.37451404333114624
Validation loss: 1.60478457584176

Epoch: 5| Step: 3
Training loss: 0.40800410509109497
Validation loss: 1.6214333747022895

Epoch: 5| Step: 4
Training loss: 0.4682721495628357
Validation loss: 1.614221998440322

Epoch: 5| Step: 5
Training loss: 0.2236439436674118
Validation loss: 1.6331876888070056

Epoch: 5| Step: 6
Training loss: 0.3994348645210266
Validation loss: 1.6097681842824465

Epoch: 5| Step: 7
Training loss: 0.4776391386985779
Validation loss: 1.6174738355862197

Epoch: 5| Step: 8
Training loss: 0.40069660544395447
Validation loss: 1.6482692585196546

Epoch: 5| Step: 9
Training loss: 0.4177285134792328
Validation loss: 1.6324368087194299

Epoch: 5| Step: 10
Training loss: 0.32737261056900024
Validation loss: 1.6073752551950433

Epoch: 397| Step: 0
Training loss: 0.3399898111820221
Validation loss: 1.6206909712924753

Epoch: 5| Step: 1
Training loss: 0.5357349514961243
Validation loss: 1.642630530941871

Epoch: 5| Step: 2
Training loss: 0.3605371117591858
Validation loss: 1.639308524388139

Epoch: 5| Step: 3
Training loss: 0.3528974950313568
Validation loss: 1.6337226975348689

Epoch: 5| Step: 4
Training loss: 0.4017524719238281
Validation loss: 1.6268886994290095

Epoch: 5| Step: 5
Training loss: 0.49604788422584534
Validation loss: 1.6431355591743224

Epoch: 5| Step: 6
Training loss: 0.37993353605270386
Validation loss: 1.622715780811925

Epoch: 5| Step: 7
Training loss: 0.38643115758895874
Validation loss: 1.6168907650055424

Epoch: 5| Step: 8
Training loss: 0.4621029496192932
Validation loss: 1.6232511766495243

Epoch: 5| Step: 9
Training loss: 0.22869309782981873
Validation loss: 1.625142551237537

Epoch: 5| Step: 10
Training loss: 0.2952105700969696
Validation loss: 1.6448637106085335

Epoch: 398| Step: 0
Training loss: 0.36624401807785034
Validation loss: 1.6287897914968512

Epoch: 5| Step: 1
Training loss: 0.2553216516971588
Validation loss: 1.6522706836782477

Epoch: 5| Step: 2
Training loss: 0.3090028166770935
Validation loss: 1.7144289132087462

Epoch: 5| Step: 3
Training loss: 0.6140736937522888
Validation loss: 1.6903885128677532

Epoch: 5| Step: 4
Training loss: 0.40019434690475464
Validation loss: 1.6816881997610933

Epoch: 5| Step: 5
Training loss: 0.2950705885887146
Validation loss: 1.6676888606881584

Epoch: 5| Step: 6
Training loss: 0.21042969822883606
Validation loss: 1.640590504933429

Epoch: 5| Step: 7
Training loss: 0.4909983277320862
Validation loss: 1.5924785175631124

Epoch: 5| Step: 8
Training loss: 0.5829902291297913
Validation loss: 1.6189147221144808

Epoch: 5| Step: 9
Training loss: 0.38703814148902893
Validation loss: 1.6103559335072835

Epoch: 5| Step: 10
Training loss: 0.2793230712413788
Validation loss: 1.594829059416248

Epoch: 399| Step: 0
Training loss: 0.378348171710968
Validation loss: 1.5885580534576087

Epoch: 5| Step: 1
Training loss: 0.3011320233345032
Validation loss: 1.5911056469845515

Epoch: 5| Step: 2
Training loss: 0.5470242500305176
Validation loss: 1.6182819438237015

Epoch: 5| Step: 3
Training loss: 0.3067764341831207
Validation loss: 1.6292844433938303

Epoch: 5| Step: 4
Training loss: 0.5246797800064087
Validation loss: 1.6652218699455261

Epoch: 5| Step: 5
Training loss: 0.31621265411376953
Validation loss: 1.6639984884569723

Epoch: 5| Step: 6
Training loss: 0.17102780938148499
Validation loss: 1.6789133318008915

Epoch: 5| Step: 7
Training loss: 0.28893640637397766
Validation loss: 1.6991487549197288

Epoch: 5| Step: 8
Training loss: 0.42456912994384766
Validation loss: 1.694533207083261

Epoch: 5| Step: 9
Training loss: 0.4928254187107086
Validation loss: 1.6819004153692594

Epoch: 5| Step: 10
Training loss: 0.37186864018440247
Validation loss: 1.648661482718683

Epoch: 400| Step: 0
Training loss: 0.429696261882782
Validation loss: 1.6080160384537072

Epoch: 5| Step: 1
Training loss: 0.36563554406166077
Validation loss: 1.5926972204639065

Epoch: 5| Step: 2
Training loss: 0.21832814812660217
Validation loss: 1.6063768004858365

Epoch: 5| Step: 3
Training loss: 0.37911707162857056
Validation loss: 1.5854461462266984

Epoch: 5| Step: 4
Training loss: 0.36888086795806885
Validation loss: 1.5821411699377081

Epoch: 5| Step: 5
Training loss: 0.2986437678337097
Validation loss: 1.642399598193425

Epoch: 5| Step: 6
Training loss: 0.2837701439857483
Validation loss: 1.5988423542309833

Epoch: 5| Step: 7
Training loss: 0.435324490070343
Validation loss: 1.6020946823140627

Epoch: 5| Step: 8
Training loss: 0.3376845121383667
Validation loss: 1.6341642243887788

Epoch: 5| Step: 9
Training loss: 0.426527738571167
Validation loss: 1.6307857357045656

Epoch: 5| Step: 10
Training loss: 0.3456989824771881
Validation loss: 1.6371485597343856

Epoch: 401| Step: 0
Training loss: 0.3533813953399658
Validation loss: 1.620548976364956

Epoch: 5| Step: 1
Training loss: 0.39708706736564636
Validation loss: 1.6139251173183482

Epoch: 5| Step: 2
Training loss: 0.43893107771873474
Validation loss: 1.6245497285678823

Epoch: 5| Step: 3
Training loss: 0.27377191185951233
Validation loss: 1.6132726387311054

Epoch: 5| Step: 4
Training loss: 0.3231455683708191
Validation loss: 1.5870451427275134

Epoch: 5| Step: 5
Training loss: 0.4081999659538269
Validation loss: 1.5923809582187283

Epoch: 5| Step: 6
Training loss: 0.6192191243171692
Validation loss: 1.6032915371720509

Epoch: 5| Step: 7
Training loss: 0.2403789460659027
Validation loss: 1.5631666773109025

Epoch: 5| Step: 8
Training loss: 0.28555575013160706
Validation loss: 1.6320282054203812

Epoch: 5| Step: 9
Training loss: 0.3641093075275421
Validation loss: 1.6660779868402789

Epoch: 5| Step: 10
Training loss: 0.4886105954647064
Validation loss: 1.636949614811969

Epoch: 402| Step: 0
Training loss: 0.5558516383171082
Validation loss: 1.6372673460232314

Epoch: 5| Step: 1
Training loss: 0.2200423777103424
Validation loss: 1.5579672853151958

Epoch: 5| Step: 2
Training loss: 0.5764411091804504
Validation loss: 1.5926858096994378

Epoch: 5| Step: 3
Training loss: 0.2924097776412964
Validation loss: 1.5643219191540954

Epoch: 5| Step: 4
Training loss: 0.4574573040008545
Validation loss: 1.537268461719636

Epoch: 5| Step: 5
Training loss: 0.5261327624320984
Validation loss: 1.5605112442406275

Epoch: 5| Step: 6
Training loss: 0.21743814647197723
Validation loss: 1.557324791467318

Epoch: 5| Step: 7
Training loss: 0.1977628767490387
Validation loss: 1.5994106364506546

Epoch: 5| Step: 8
Training loss: 0.481087863445282
Validation loss: 1.6140689555034842

Epoch: 5| Step: 9
Training loss: 0.39109137654304504
Validation loss: 1.6382396656979796

Epoch: 5| Step: 10
Training loss: 0.30912524461746216
Validation loss: 1.6186902939632375

Epoch: 403| Step: 0
Training loss: 0.2769850194454193
Validation loss: 1.579650108532239

Epoch: 5| Step: 1
Training loss: 0.41750985383987427
Validation loss: 1.5740734774579284

Epoch: 5| Step: 2
Training loss: 0.3151741921901703
Validation loss: 1.5771102341272498

Epoch: 5| Step: 3
Training loss: 0.3412973880767822
Validation loss: 1.5885055411246516

Epoch: 5| Step: 4
Training loss: 0.4016043543815613
Validation loss: 1.5899681878346268

Epoch: 5| Step: 5
Training loss: 0.3594592809677124
Validation loss: 1.5938650843917683

Epoch: 5| Step: 6
Training loss: 0.19833257794380188
Validation loss: 1.6178859241547123

Epoch: 5| Step: 7
Training loss: 0.5151331424713135
Validation loss: 1.6314175769846926

Epoch: 5| Step: 8
Training loss: 0.36709684133529663
Validation loss: 1.6461761318227297

Epoch: 5| Step: 9
Training loss: 0.7193077206611633
Validation loss: 1.6451640821272326

Epoch: 5| Step: 10
Training loss: 0.41947150230407715
Validation loss: 1.6316166718800862

Epoch: 404| Step: 0
Training loss: 0.23675933480262756
Validation loss: 1.5905169992036716

Epoch: 5| Step: 1
Training loss: 0.33370810747146606
Validation loss: 1.5996750311184955

Epoch: 5| Step: 2
Training loss: 0.4318862855434418
Validation loss: 1.5846242571389804

Epoch: 5| Step: 3
Training loss: 0.33155637979507446
Validation loss: 1.5867569356836297

Epoch: 5| Step: 4
Training loss: 0.5062191486358643
Validation loss: 1.6043979121792702

Epoch: 5| Step: 5
Training loss: 0.48501577973365784
Validation loss: 1.5823744343173118

Epoch: 5| Step: 6
Training loss: 0.4553893506526947
Validation loss: 1.5887342422239241

Epoch: 5| Step: 7
Training loss: 0.2730993628501892
Validation loss: 1.6203909433016213

Epoch: 5| Step: 8
Training loss: 0.37933552265167236
Validation loss: 1.6583114567623343

Epoch: 5| Step: 9
Training loss: 0.4574373662471771
Validation loss: 1.69040633017017

Epoch: 5| Step: 10
Training loss: 0.4387911558151245
Validation loss: 1.6846906985006025

Epoch: 405| Step: 0
Training loss: 0.4146839678287506
Validation loss: 1.6682012273419289

Epoch: 5| Step: 1
Training loss: 0.38071662187576294
Validation loss: 1.6203477267296083

Epoch: 5| Step: 2
Training loss: 0.25705718994140625
Validation loss: 1.6125248311668314

Epoch: 5| Step: 3
Training loss: 0.43220072984695435
Validation loss: 1.5858719374543877

Epoch: 5| Step: 4
Training loss: 0.2499188482761383
Validation loss: 1.5887909871275707

Epoch: 5| Step: 5
Training loss: 0.38637956976890564
Validation loss: 1.5923391503672446

Epoch: 5| Step: 6
Training loss: 0.39997774362564087
Validation loss: 1.5977870751452703

Epoch: 5| Step: 7
Training loss: 0.2644776403903961
Validation loss: 1.6295595451067852

Epoch: 5| Step: 8
Training loss: 0.40510401129722595
Validation loss: 1.641788883875775

Epoch: 5| Step: 9
Training loss: 0.32535797357559204
Validation loss: 1.6470634219467

Epoch: 5| Step: 10
Training loss: 0.48239797353744507
Validation loss: 1.6537759214319208

Epoch: 406| Step: 0
Training loss: 0.44305261969566345
Validation loss: 1.6381222765932801

Epoch: 5| Step: 1
Training loss: 0.5678337812423706
Validation loss: 1.6671872485068537

Epoch: 5| Step: 2
Training loss: 0.30514615774154663
Validation loss: 1.6681519426325315

Epoch: 5| Step: 3
Training loss: 0.2053155153989792
Validation loss: 1.6582439317498157

Epoch: 5| Step: 4
Training loss: 0.2872222065925598
Validation loss: 1.6393300128239456

Epoch: 5| Step: 5
Training loss: 0.3786620497703552
Validation loss: 1.633057878863427

Epoch: 5| Step: 6
Training loss: 0.2152300775051117
Validation loss: 1.6035192737015345

Epoch: 5| Step: 7
Training loss: 0.3415113091468811
Validation loss: 1.5989715873554189

Epoch: 5| Step: 8
Training loss: 0.36479562520980835
Validation loss: 1.6054361494638587

Epoch: 5| Step: 9
Training loss: 0.5383551716804504
Validation loss: 1.5986618598302205

Epoch: 5| Step: 10
Training loss: 0.1817535161972046
Validation loss: 1.5995560230747345

Epoch: 407| Step: 0
Training loss: 0.2894020080566406
Validation loss: 1.5859944839631357

Epoch: 5| Step: 1
Training loss: 0.3151819109916687
Validation loss: 1.6036603925048665

Epoch: 5| Step: 2
Training loss: 0.3327907919883728
Validation loss: 1.6368085633042038

Epoch: 5| Step: 3
Training loss: 0.2679280936717987
Validation loss: 1.589103998676423

Epoch: 5| Step: 4
Training loss: 0.37229400873184204
Validation loss: 1.6373976174221243

Epoch: 5| Step: 5
Training loss: 0.4841795861721039
Validation loss: 1.6081466290258593

Epoch: 5| Step: 6
Training loss: 0.3775697350502014
Validation loss: 1.6331996366541872

Epoch: 5| Step: 7
Training loss: 0.3761811852455139
Validation loss: 1.6152635287213069

Epoch: 5| Step: 8
Training loss: 0.24603036046028137
Validation loss: 1.6223825690566853

Epoch: 5| Step: 9
Training loss: 0.4832455515861511
Validation loss: 1.6233289421245616

Epoch: 5| Step: 10
Training loss: 0.23870888352394104
Validation loss: 1.6327581482548867

Epoch: 408| Step: 0
Training loss: 0.334244966506958
Validation loss: 1.614543346948521

Epoch: 5| Step: 1
Training loss: 0.4776782989501953
Validation loss: 1.6067555540351457

Epoch: 5| Step: 2
Training loss: 0.27048060297966003
Validation loss: 1.6310980268703994

Epoch: 5| Step: 3
Training loss: 0.36209386587142944
Validation loss: 1.6109119140973656

Epoch: 5| Step: 4
Training loss: 0.3138611912727356
Validation loss: 1.6484423401535198

Epoch: 5| Step: 5
Training loss: 0.33939528465270996
Validation loss: 1.6132293772953812

Epoch: 5| Step: 6
Training loss: 0.4292888641357422
Validation loss: 1.6179572523281138

Epoch: 5| Step: 7
Training loss: 0.27741289138793945
Validation loss: 1.5952220014346543

Epoch: 5| Step: 8
Training loss: 0.16542139649391174
Validation loss: 1.5798585991705618

Epoch: 5| Step: 9
Training loss: 0.3127906024456024
Validation loss: 1.5753033340618174

Epoch: 5| Step: 10
Training loss: 0.2613913416862488
Validation loss: 1.573091568485383

Epoch: 409| Step: 0
Training loss: 0.37898126244544983
Validation loss: 1.5730318753950057

Epoch: 5| Step: 1
Training loss: 0.326668918132782
Validation loss: 1.598484831471597

Epoch: 5| Step: 2
Training loss: 0.30500391125679016
Validation loss: 1.585516301534509

Epoch: 5| Step: 3
Training loss: 0.17549555003643036
Validation loss: 1.5652951245666833

Epoch: 5| Step: 4
Training loss: 0.2334248572587967
Validation loss: 1.5827549478059173

Epoch: 5| Step: 5
Training loss: 0.30938270688056946
Validation loss: 1.6009236702355005

Epoch: 5| Step: 6
Training loss: 0.3506213426589966
Validation loss: 1.6238340805935603

Epoch: 5| Step: 7
Training loss: 0.26751524209976196
Validation loss: 1.6340559118537492

Epoch: 5| Step: 8
Training loss: 0.5673421621322632
Validation loss: 1.652951777622264

Epoch: 5| Step: 9
Training loss: 0.2989315390586853
Validation loss: 1.6263777748230965

Epoch: 5| Step: 10
Training loss: 0.4341643452644348
Validation loss: 1.6463573325064875

Epoch: 410| Step: 0
Training loss: 0.3603418469429016
Validation loss: 1.5919121708921207

Epoch: 5| Step: 1
Training loss: 0.19597069919109344
Validation loss: 1.5861898750387213

Epoch: 5| Step: 2
Training loss: 0.3112550973892212
Validation loss: 1.5801498774559266

Epoch: 5| Step: 3
Training loss: 0.28020796179771423
Validation loss: 1.5460266195317751

Epoch: 5| Step: 4
Training loss: 0.24045109748840332
Validation loss: 1.5705192563354329

Epoch: 5| Step: 5
Training loss: 0.4751843810081482
Validation loss: 1.589698237757529

Epoch: 5| Step: 6
Training loss: 0.4659505784511566
Validation loss: 1.5774122489395963

Epoch: 5| Step: 7
Training loss: 0.1924426555633545
Validation loss: 1.6005894291785456

Epoch: 5| Step: 8
Training loss: 0.26814141869544983
Validation loss: 1.609541844296199

Epoch: 5| Step: 9
Training loss: 0.38972601294517517
Validation loss: 1.6380457455112087

Epoch: 5| Step: 10
Training loss: 0.30709123611450195
Validation loss: 1.6179635601658975

Epoch: 411| Step: 0
Training loss: 0.14778535068035126
Validation loss: 1.5986087540144562

Epoch: 5| Step: 1
Training loss: 0.2757549285888672
Validation loss: 1.620451593911776

Epoch: 5| Step: 2
Training loss: 0.3908917307853699
Validation loss: 1.6234599787701842

Epoch: 5| Step: 3
Training loss: 0.39077430963516235
Validation loss: 1.5896281401316326

Epoch: 5| Step: 4
Training loss: 0.2881031036376953
Validation loss: 1.5937288416329252

Epoch: 5| Step: 5
Training loss: 0.32732850313186646
Validation loss: 1.596958323191571

Epoch: 5| Step: 6
Training loss: 0.30745911598205566
Validation loss: 1.57445397556469

Epoch: 5| Step: 7
Training loss: 0.2792186439037323
Validation loss: 1.568175035138284

Epoch: 5| Step: 8
Training loss: 0.32053056359291077
Validation loss: 1.5775925331218268

Epoch: 5| Step: 9
Training loss: 0.4447275996208191
Validation loss: 1.558786488348438

Epoch: 5| Step: 10
Training loss: 0.2941279709339142
Validation loss: 1.5772720741969284

Epoch: 412| Step: 0
Training loss: 0.4623337686061859
Validation loss: 1.591415879546955

Epoch: 5| Step: 1
Training loss: 0.27295827865600586
Validation loss: 1.570038955698731

Epoch: 5| Step: 2
Training loss: 0.18831397593021393
Validation loss: 1.5909083081829933

Epoch: 5| Step: 3
Training loss: 0.406118780374527
Validation loss: 1.5811453468056136

Epoch: 5| Step: 4
Training loss: 0.3798961043357849
Validation loss: 1.6076581683210147

Epoch: 5| Step: 5
Training loss: 0.15645530819892883
Validation loss: 1.5726729451969106

Epoch: 5| Step: 6
Training loss: 0.3689136207103729
Validation loss: 1.595314234815618

Epoch: 5| Step: 7
Training loss: 0.2343335598707199
Validation loss: 1.5862073808588006

Epoch: 5| Step: 8
Training loss: 0.4110969603061676
Validation loss: 1.601246154436501

Epoch: 5| Step: 9
Training loss: 0.20934835076332092
Validation loss: 1.5798533257617746

Epoch: 5| Step: 10
Training loss: 0.15639515221118927
Validation loss: 1.5809264875227405

Epoch: 413| Step: 0
Training loss: 0.408992201089859
Validation loss: 1.5722461990130845

Epoch: 5| Step: 1
Training loss: 0.1710481494665146
Validation loss: 1.585286387833216

Epoch: 5| Step: 2
Training loss: 0.28271380066871643
Validation loss: 1.5846889070285264

Epoch: 5| Step: 3
Training loss: 0.2099185436964035
Validation loss: 1.629171758569697

Epoch: 5| Step: 4
Training loss: 0.33238521218299866
Validation loss: 1.6147065386977246

Epoch: 5| Step: 5
Training loss: 0.2727326452732086
Validation loss: 1.5980565996580227

Epoch: 5| Step: 6
Training loss: 0.489645779132843
Validation loss: 1.6125197474674513

Epoch: 5| Step: 7
Training loss: 0.15744136273860931
Validation loss: 1.6021704135402557

Epoch: 5| Step: 8
Training loss: 0.3054191768169403
Validation loss: 1.5835243707062097

Epoch: 5| Step: 9
Training loss: 0.30408966541290283
Validation loss: 1.5745189177092684

Epoch: 5| Step: 10
Training loss: 0.2646741271018982
Validation loss: 1.5524972843867477

Epoch: 414| Step: 0
Training loss: 0.23546557128429413
Validation loss: 1.572581991072624

Epoch: 5| Step: 1
Training loss: 0.35848110914230347
Validation loss: 1.5641712834758144

Epoch: 5| Step: 2
Training loss: 0.37385740876197815
Validation loss: 1.5638610509134108

Epoch: 5| Step: 3
Training loss: 0.2030671089887619
Validation loss: 1.5789263030534149

Epoch: 5| Step: 4
Training loss: 0.4419637620449066
Validation loss: 1.5444695424008112

Epoch: 5| Step: 5
Training loss: 0.22842445969581604
Validation loss: 1.5523154177973348

Epoch: 5| Step: 6
Training loss: 0.32109007239341736
Validation loss: 1.5667624499208184

Epoch: 5| Step: 7
Training loss: 0.13036635518074036
Validation loss: 1.588863213857015

Epoch: 5| Step: 8
Training loss: 0.3869588375091553
Validation loss: 1.5697464801931893

Epoch: 5| Step: 9
Training loss: 0.2941933274269104
Validation loss: 1.5886491062820598

Epoch: 5| Step: 10
Training loss: 0.31764712929725647
Validation loss: 1.5843455253108856

Epoch: 415| Step: 0
Training loss: 0.24621227383613586
Validation loss: 1.594640734375164

Epoch: 5| Step: 1
Training loss: 0.22588658332824707
Validation loss: 1.5645420423118017

Epoch: 5| Step: 2
Training loss: 0.25058799982070923
Validation loss: 1.5739503816891742

Epoch: 5| Step: 3
Training loss: 0.33403125405311584
Validation loss: 1.5710555616245474

Epoch: 5| Step: 4
Training loss: 0.48947006464004517
Validation loss: 1.5822262046157674

Epoch: 5| Step: 5
Training loss: 0.2618916630744934
Validation loss: 1.5974977247176632

Epoch: 5| Step: 6
Training loss: 0.16910693049430847
Validation loss: 1.5983134790133404

Epoch: 5| Step: 7
Training loss: 0.39932185411453247
Validation loss: 1.6166919098105481

Epoch: 5| Step: 8
Training loss: 0.3732089698314667
Validation loss: 1.6093849956348378

Epoch: 5| Step: 9
Training loss: 0.353529691696167
Validation loss: 1.606280754971248

Epoch: 5| Step: 10
Training loss: 0.24321234226226807
Validation loss: 1.5999090030629148

Epoch: 416| Step: 0
Training loss: 0.2852838337421417
Validation loss: 1.5732518908798054

Epoch: 5| Step: 1
Training loss: 0.3336328864097595
Validation loss: 1.5748947525537142

Epoch: 5| Step: 2
Training loss: 0.30798572301864624
Validation loss: 1.568212975737869

Epoch: 5| Step: 3
Training loss: 0.3658077120780945
Validation loss: 1.5564583129780267

Epoch: 5| Step: 4
Training loss: 0.3523343801498413
Validation loss: 1.5699741532725673

Epoch: 5| Step: 5
Training loss: 0.279818058013916
Validation loss: 1.5253432591756184

Epoch: 5| Step: 6
Training loss: 0.2531476616859436
Validation loss: 1.5694511193101124

Epoch: 5| Step: 7
Training loss: 0.186749666929245
Validation loss: 1.5580690740257181

Epoch: 5| Step: 8
Training loss: 0.3485299348831177
Validation loss: 1.5316706703555198

Epoch: 5| Step: 9
Training loss: 0.3431665301322937
Validation loss: 1.5586126645406086

Epoch: 5| Step: 10
Training loss: 0.21136164665222168
Validation loss: 1.579029949762488

Epoch: 417| Step: 0
Training loss: 0.2844275236129761
Validation loss: 1.5747618431686072

Epoch: 5| Step: 1
Training loss: 0.24376097321510315
Validation loss: 1.581628176473802

Epoch: 5| Step: 2
Training loss: 0.206635981798172
Validation loss: 1.5780377644364552

Epoch: 5| Step: 3
Training loss: 0.15934398770332336
Validation loss: 1.5446554973561277

Epoch: 5| Step: 4
Training loss: 0.5350678563117981
Validation loss: 1.5605610416781517

Epoch: 5| Step: 5
Training loss: 0.29594311118125916
Validation loss: 1.5735987078758977

Epoch: 5| Step: 6
Training loss: 0.30617013573646545
Validation loss: 1.5762516990784676

Epoch: 5| Step: 7
Training loss: 0.22790518403053284
Validation loss: 1.5856536729361421

Epoch: 5| Step: 8
Training loss: 0.4515046179294586
Validation loss: 1.590465449517773

Epoch: 5| Step: 9
Training loss: 0.18620316684246063
Validation loss: 1.5876993171630367

Epoch: 5| Step: 10
Training loss: 0.26897215843200684
Validation loss: 1.5954114365321335

Epoch: 418| Step: 0
Training loss: 0.2429737150669098
Validation loss: 1.5676423208687895

Epoch: 5| Step: 1
Training loss: 0.18475975096225739
Validation loss: 1.5860307396099131

Epoch: 5| Step: 2
Training loss: 0.25872737169265747
Validation loss: 1.607547922800946

Epoch: 5| Step: 3
Training loss: 0.2932935357093811
Validation loss: 1.6050415936336722

Epoch: 5| Step: 4
Training loss: 0.343383252620697
Validation loss: 1.6215101454847602

Epoch: 5| Step: 5
Training loss: 0.32869911193847656
Validation loss: 1.5952082821117934

Epoch: 5| Step: 6
Training loss: 0.23481853306293488
Validation loss: 1.6205018130681847

Epoch: 5| Step: 7
Training loss: 0.2895861268043518
Validation loss: 1.6175865768104472

Epoch: 5| Step: 8
Training loss: 0.3655514121055603
Validation loss: 1.589571218336782

Epoch: 5| Step: 9
Training loss: 0.2239527404308319
Validation loss: 1.5750588447816911

Epoch: 5| Step: 10
Training loss: 0.4544759690761566
Validation loss: 1.5804555839107883

Epoch: 419| Step: 0
Training loss: 0.48297184705734253
Validation loss: 1.5734903876499464

Epoch: 5| Step: 1
Training loss: 0.09974803775548935
Validation loss: 1.5470846276129446

Epoch: 5| Step: 2
Training loss: 0.2920787036418915
Validation loss: 1.5701353434593446

Epoch: 5| Step: 3
Training loss: 0.4265316426753998
Validation loss: 1.5842062004150883

Epoch: 5| Step: 4
Training loss: 0.2871215045452118
Validation loss: 1.610594944287372

Epoch: 5| Step: 5
Training loss: 0.31688952445983887
Validation loss: 1.6084096406095771

Epoch: 5| Step: 6
Training loss: 0.3166998326778412
Validation loss: 1.61837722152792

Epoch: 5| Step: 7
Training loss: 0.19435900449752808
Validation loss: 1.6274728057205037

Epoch: 5| Step: 8
Training loss: 0.2822808623313904
Validation loss: 1.6174205823611187

Epoch: 5| Step: 9
Training loss: 0.3443249762058258
Validation loss: 1.632823363427193

Epoch: 5| Step: 10
Training loss: 0.17634938657283783
Validation loss: 1.6225303783211658

Epoch: 420| Step: 0
Training loss: 0.3200555741786957
Validation loss: 1.608415384446421

Epoch: 5| Step: 1
Training loss: 0.31206661462783813
Validation loss: 1.630236215488885

Epoch: 5| Step: 2
Training loss: 0.25011998414993286
Validation loss: 1.6088126423538371

Epoch: 5| Step: 3
Training loss: 0.32375556230545044
Validation loss: 1.5883749441433979

Epoch: 5| Step: 4
Training loss: 0.2432936429977417
Validation loss: 1.5750335288304154

Epoch: 5| Step: 5
Training loss: 0.32491880655288696
Validation loss: 1.5766278287415862

Epoch: 5| Step: 6
Training loss: 0.3143138289451599
Validation loss: 1.5548257853395195

Epoch: 5| Step: 7
Training loss: 0.3106309771537781
Validation loss: 1.561145160787849

Epoch: 5| Step: 8
Training loss: 0.45924893021583557
Validation loss: 1.5673667410368561

Epoch: 5| Step: 9
Training loss: 0.2733863592147827
Validation loss: 1.556404846970753

Epoch: 5| Step: 10
Training loss: 0.1096985936164856
Validation loss: 1.5289731358969083

Epoch: 421| Step: 0
Training loss: 0.15377753973007202
Validation loss: 1.5374956412981915

Epoch: 5| Step: 1
Training loss: 0.26304376125335693
Validation loss: 1.5890172168772707

Epoch: 5| Step: 2
Training loss: 0.3356882929801941
Validation loss: 1.607772074719911

Epoch: 5| Step: 3
Training loss: 0.2486293762922287
Validation loss: 1.6231167752255675

Epoch: 5| Step: 4
Training loss: 0.2553021311759949
Validation loss: 1.6270991627888014

Epoch: 5| Step: 5
Training loss: 0.36676546931266785
Validation loss: 1.65196136249009

Epoch: 5| Step: 6
Training loss: 0.31091222167015076
Validation loss: 1.6394662408418552

Epoch: 5| Step: 7
Training loss: 0.31272023916244507
Validation loss: 1.6229083973874328

Epoch: 5| Step: 8
Training loss: 0.30399829149246216
Validation loss: 1.5988925862055954

Epoch: 5| Step: 9
Training loss: 0.19566282629966736
Validation loss: 1.6057558392965665

Epoch: 5| Step: 10
Training loss: 0.3900199830532074
Validation loss: 1.6068539157990487

Epoch: 422| Step: 0
Training loss: 0.26595091819763184
Validation loss: 1.5733486426773893

Epoch: 5| Step: 1
Training loss: 0.411571204662323
Validation loss: 1.5600580707673104

Epoch: 5| Step: 2
Training loss: 0.21057602763175964
Validation loss: 1.5965160618546188

Epoch: 5| Step: 3
Training loss: 0.49058133363723755
Validation loss: 1.5751844054909163

Epoch: 5| Step: 4
Training loss: 0.2503066658973694
Validation loss: 1.5899570116432764

Epoch: 5| Step: 5
Training loss: 0.19212540984153748
Validation loss: 1.599912501150562

Epoch: 5| Step: 6
Training loss: 0.32706552743911743
Validation loss: 1.5641603687758088

Epoch: 5| Step: 7
Training loss: 0.11113574355840683
Validation loss: 1.5864689080945906

Epoch: 5| Step: 8
Training loss: 0.3198363184928894
Validation loss: 1.5917186249968827

Epoch: 5| Step: 9
Training loss: 0.20885531604290009
Validation loss: 1.585261978128905

Epoch: 5| Step: 10
Training loss: 0.2564656436443329
Validation loss: 1.5736483848223122

Epoch: 423| Step: 0
Training loss: 0.24595801532268524
Validation loss: 1.5716085062232068

Epoch: 5| Step: 1
Training loss: 0.3436034619808197
Validation loss: 1.5658208516336256

Epoch: 5| Step: 2
Training loss: 0.3669414520263672
Validation loss: 1.5229237335984425

Epoch: 5| Step: 3
Training loss: 0.4404943883419037
Validation loss: 1.526618037172543

Epoch: 5| Step: 4
Training loss: 0.14834937453269958
Validation loss: 1.5716490252043611

Epoch: 5| Step: 5
Training loss: 0.2694629728794098
Validation loss: 1.5678741367914344

Epoch: 5| Step: 6
Training loss: 0.2446366548538208
Validation loss: 1.5729051610474944

Epoch: 5| Step: 7
Training loss: 0.20061805844306946
Validation loss: 1.5692870616912842

Epoch: 5| Step: 8
Training loss: 0.2960170805454254
Validation loss: 1.5840135479486117

Epoch: 5| Step: 9
Training loss: 0.2749265730381012
Validation loss: 1.5950598742372246

Epoch: 5| Step: 10
Training loss: 0.1374039500951767
Validation loss: 1.5662639217991983

Epoch: 424| Step: 0
Training loss: 0.31081727147102356
Validation loss: 1.5806419593031689

Epoch: 5| Step: 1
Training loss: 0.3678678870201111
Validation loss: 1.6084424193187425

Epoch: 5| Step: 2
Training loss: 0.187292218208313
Validation loss: 1.5863358205364597

Epoch: 5| Step: 3
Training loss: 0.1342484951019287
Validation loss: 1.6083359884959396

Epoch: 5| Step: 4
Training loss: 0.16859953105449677
Validation loss: 1.5890295505523682

Epoch: 5| Step: 5
Training loss: 0.3526056408882141
Validation loss: 1.5633843252735753

Epoch: 5| Step: 6
Training loss: 0.2478475570678711
Validation loss: 1.5883289620440493

Epoch: 5| Step: 7
Training loss: 0.4100269377231598
Validation loss: 1.5435875231219875

Epoch: 5| Step: 8
Training loss: 0.19927193224430084
Validation loss: 1.5448393642261464

Epoch: 5| Step: 9
Training loss: 0.4596785604953766
Validation loss: 1.5414557969698341

Epoch: 5| Step: 10
Training loss: 0.14567746222019196
Validation loss: 1.5371391773223877

Epoch: 425| Step: 0
Training loss: 0.27418774366378784
Validation loss: 1.590833742131469

Epoch: 5| Step: 1
Training loss: 0.1351480633020401
Validation loss: 1.568772638997724

Epoch: 5| Step: 2
Training loss: 0.29917269945144653
Validation loss: 1.5958394465907928

Epoch: 5| Step: 3
Training loss: 0.33137255907058716
Validation loss: 1.627396745066489

Epoch: 5| Step: 4
Training loss: 0.1788630485534668
Validation loss: 1.6207012373914

Epoch: 5| Step: 5
Training loss: 0.5971230864524841
Validation loss: 1.6607861890587756

Epoch: 5| Step: 6
Training loss: 0.28918686509132385
Validation loss: 1.6358324827686432

Epoch: 5| Step: 7
Training loss: 0.28244897723197937
Validation loss: 1.599089760934153

Epoch: 5| Step: 8
Training loss: 0.33848562836647034
Validation loss: 1.5748050674315421

Epoch: 5| Step: 9
Training loss: 0.2102721631526947
Validation loss: 1.608973051912041

Epoch: 5| Step: 10
Training loss: 0.22395636141300201
Validation loss: 1.5857425082114436

Epoch: 426| Step: 0
Training loss: 0.3770131766796112
Validation loss: 1.6002972510553175

Epoch: 5| Step: 1
Training loss: 0.23382826149463654
Validation loss: 1.6358228793708227

Epoch: 5| Step: 2
Training loss: 0.2191576510667801
Validation loss: 1.607199368938323

Epoch: 5| Step: 3
Training loss: 0.39032605290412903
Validation loss: 1.5947490815193421

Epoch: 5| Step: 4
Training loss: 0.447969526052475
Validation loss: 1.6018941005071003

Epoch: 5| Step: 5
Training loss: 0.2785617709159851
Validation loss: 1.6132141915700768

Epoch: 5| Step: 6
Training loss: 0.20763757824897766
Validation loss: 1.5880843388136996

Epoch: 5| Step: 7
Training loss: 0.21609897911548615
Validation loss: 1.5913427683614916

Epoch: 5| Step: 8
Training loss: 0.304556667804718
Validation loss: 1.6240369940316806

Epoch: 5| Step: 9
Training loss: 0.2791809141635895
Validation loss: 1.5972881599139142

Epoch: 5| Step: 10
Training loss: 0.2648372948169708
Validation loss: 1.618543795360032

Epoch: 427| Step: 0
Training loss: 0.19110184907913208
Validation loss: 1.6299723950765466

Epoch: 5| Step: 1
Training loss: 0.21832624077796936
Validation loss: 1.6177436523540045

Epoch: 5| Step: 2
Training loss: 0.4646530747413635
Validation loss: 1.5783364208795692

Epoch: 5| Step: 3
Training loss: 0.10084164142608643
Validation loss: 1.5563209249127297

Epoch: 5| Step: 4
Training loss: 0.14259003102779388
Validation loss: 1.558252638386142

Epoch: 5| Step: 5
Training loss: 0.3071773648262024
Validation loss: 1.562886357307434

Epoch: 5| Step: 6
Training loss: 0.3487432897090912
Validation loss: 1.569923641861126

Epoch: 5| Step: 7
Training loss: 0.3091779947280884
Validation loss: 1.5580529871807303

Epoch: 5| Step: 8
Training loss: 0.24611344933509827
Validation loss: 1.52638747871563

Epoch: 5| Step: 9
Training loss: 0.22357821464538574
Validation loss: 1.5438245522078646

Epoch: 5| Step: 10
Training loss: 0.3150922954082489
Validation loss: 1.514563791213497

Epoch: 428| Step: 0
Training loss: 0.29392001032829285
Validation loss: 1.5396204276751446

Epoch: 5| Step: 1
Training loss: 0.23744645714759827
Validation loss: 1.5402291602985834

Epoch: 5| Step: 2
Training loss: 0.17056508362293243
Validation loss: 1.5617602473946028

Epoch: 5| Step: 3
Training loss: 0.40627115964889526
Validation loss: 1.5569447612249723

Epoch: 5| Step: 4
Training loss: 0.26733002066612244
Validation loss: 1.5779114782169301

Epoch: 5| Step: 5
Training loss: 0.22418570518493652
Validation loss: 1.5560395615075224

Epoch: 5| Step: 6
Training loss: 0.2270224392414093
Validation loss: 1.5880872331639773

Epoch: 5| Step: 7
Training loss: 0.2702721655368805
Validation loss: 1.578801421708958

Epoch: 5| Step: 8
Training loss: 0.30806273221969604
Validation loss: 1.5463991421525196

Epoch: 5| Step: 9
Training loss: 0.25387513637542725
Validation loss: 1.5391730416205622

Epoch: 5| Step: 10
Training loss: 0.20678769052028656
Validation loss: 1.5831104042709514

Epoch: 429| Step: 0
Training loss: 0.2609068751335144
Validation loss: 1.5732504424228464

Epoch: 5| Step: 1
Training loss: 0.2182750254869461
Validation loss: 1.5646407296580653

Epoch: 5| Step: 2
Training loss: 0.4989069104194641
Validation loss: 1.5652264997523317

Epoch: 5| Step: 3
Training loss: 0.27050429582595825
Validation loss: 1.570798466282506

Epoch: 5| Step: 4
Training loss: 0.19038763642311096
Validation loss: 1.574711681694113

Epoch: 5| Step: 5
Training loss: 0.30681177973747253
Validation loss: 1.5587095111928961

Epoch: 5| Step: 6
Training loss: 0.3270270824432373
Validation loss: 1.5858113265806628

Epoch: 5| Step: 7
Training loss: 0.19477325677871704
Validation loss: 1.5805490266892217

Epoch: 5| Step: 8
Training loss: 0.1478240042924881
Validation loss: 1.588329110094296

Epoch: 5| Step: 9
Training loss: 0.258356511592865
Validation loss: 1.606320975929178

Epoch: 5| Step: 10
Training loss: 0.24085353314876556
Validation loss: 1.6016739696584723

Epoch: 430| Step: 0
Training loss: 0.17790736258029938
Validation loss: 1.628707214068341

Epoch: 5| Step: 1
Training loss: 0.2510446012020111
Validation loss: 1.6097955678098945

Epoch: 5| Step: 2
Training loss: 0.20970821380615234
Validation loss: 1.6284594125645135

Epoch: 5| Step: 3
Training loss: 0.35792550444602966
Validation loss: 1.5802410469260266

Epoch: 5| Step: 4
Training loss: 0.3291253447532654
Validation loss: 1.5811206012643793

Epoch: 5| Step: 5
Training loss: 0.16227729618549347
Validation loss: 1.5714539366383706

Epoch: 5| Step: 6
Training loss: 0.3290552496910095
Validation loss: 1.5529221898765975

Epoch: 5| Step: 7
Training loss: 0.27673864364624023
Validation loss: 1.5723171605858752

Epoch: 5| Step: 8
Training loss: 0.19383098185062408
Validation loss: 1.574207055953241

Epoch: 5| Step: 9
Training loss: 0.3473847210407257
Validation loss: 1.567687270461872

Epoch: 5| Step: 10
Training loss: 0.3945000469684601
Validation loss: 1.5548930232242872

Epoch: 431| Step: 0
Training loss: 0.2347722351551056
Validation loss: 1.544235102591976

Epoch: 5| Step: 1
Training loss: 0.25517019629478455
Validation loss: 1.5462457864515242

Epoch: 5| Step: 2
Training loss: 0.22811567783355713
Validation loss: 1.5678760697764735

Epoch: 5| Step: 3
Training loss: 0.20647673308849335
Validation loss: 1.5672054970136253

Epoch: 5| Step: 4
Training loss: 0.28621426224708557
Validation loss: 1.5717790229346162

Epoch: 5| Step: 5
Training loss: 0.23121896386146545
Validation loss: 1.6045470250550138

Epoch: 5| Step: 6
Training loss: 0.25317785143852234
Validation loss: 1.6083927346814064

Epoch: 5| Step: 7
Training loss: 0.3643572926521301
Validation loss: 1.5983651466267084

Epoch: 5| Step: 8
Training loss: 0.2730296850204468
Validation loss: 1.564287208741711

Epoch: 5| Step: 9
Training loss: 0.34599000215530396
Validation loss: 1.5726327575663084

Epoch: 5| Step: 10
Training loss: 0.2836041748523712
Validation loss: 1.5632506096234886

Epoch: 432| Step: 0
Training loss: 0.4901212751865387
Validation loss: 1.5654319755492672

Epoch: 5| Step: 1
Training loss: 0.2110981047153473
Validation loss: 1.5277802572455457

Epoch: 5| Step: 2
Training loss: 0.18724402785301208
Validation loss: 1.5553956788073304

Epoch: 5| Step: 3
Training loss: 0.25585073232650757
Validation loss: 1.547179566916599

Epoch: 5| Step: 4
Training loss: 0.2618092894554138
Validation loss: 1.5569212769949308

Epoch: 5| Step: 5
Training loss: 0.2500041127204895
Validation loss: 1.5307533202632781

Epoch: 5| Step: 6
Training loss: 0.20226521790027618
Validation loss: 1.5502015723977038

Epoch: 5| Step: 7
Training loss: 0.4045569896697998
Validation loss: 1.5741715892668693

Epoch: 5| Step: 8
Training loss: 0.2039809674024582
Validation loss: 1.5700983110294546

Epoch: 5| Step: 9
Training loss: 0.11948823928833008
Validation loss: 1.5895425914436259

Epoch: 5| Step: 10
Training loss: 0.3015846014022827
Validation loss: 1.592390016842914

Epoch: 433| Step: 0
Training loss: 0.161148339509964
Validation loss: 1.6140179672548849

Epoch: 5| Step: 1
Training loss: 0.20261387526988983
Validation loss: 1.5701424614075692

Epoch: 5| Step: 2
Training loss: 0.28672918677330017
Validation loss: 1.5939650381765058

Epoch: 5| Step: 3
Training loss: 0.24557510018348694
Validation loss: 1.5575183591535013

Epoch: 5| Step: 4
Training loss: 0.1471177488565445
Validation loss: 1.5723034092175063

Epoch: 5| Step: 5
Training loss: 0.20400556921958923
Validation loss: 1.5759324873647382

Epoch: 5| Step: 6
Training loss: 0.22762203216552734
Validation loss: 1.5545048675229471

Epoch: 5| Step: 7
Training loss: 0.29612553119659424
Validation loss: 1.5526175537417013

Epoch: 5| Step: 8
Training loss: 0.3758649230003357
Validation loss: 1.5616622112130607

Epoch: 5| Step: 9
Training loss: 0.267293781042099
Validation loss: 1.56168249986505

Epoch: 5| Step: 10
Training loss: 0.3350669741630554
Validation loss: 1.580573461389029

Epoch: 434| Step: 0
Training loss: 0.22523002326488495
Validation loss: 1.5565968713452738

Epoch: 5| Step: 1
Training loss: 0.1970757395029068
Validation loss: 1.5508188662990448

Epoch: 5| Step: 2
Training loss: 0.2766939103603363
Validation loss: 1.560038319198034

Epoch: 5| Step: 3
Training loss: 0.26372241973876953
Validation loss: 1.5146524803612822

Epoch: 5| Step: 4
Training loss: 0.2651231288909912
Validation loss: 1.5076723598664807

Epoch: 5| Step: 5
Training loss: 0.3437046706676483
Validation loss: 1.5362146926182572

Epoch: 5| Step: 6
Training loss: 0.2709953188896179
Validation loss: 1.5004588955192155

Epoch: 5| Step: 7
Training loss: 0.24826402962207794
Validation loss: 1.5322351173688007

Epoch: 5| Step: 8
Training loss: 0.14275477826595306
Validation loss: 1.540585780656466

Epoch: 5| Step: 9
Training loss: 0.2758219540119171
Validation loss: 1.5549922104804748

Epoch: 5| Step: 10
Training loss: 0.19967225193977356
Validation loss: 1.5374166068210398

Epoch: 435| Step: 0
Training loss: 0.380769819021225
Validation loss: 1.5282843548764464

Epoch: 5| Step: 1
Training loss: 0.24895410239696503
Validation loss: 1.5262671901333718

Epoch: 5| Step: 2
Training loss: 0.16134661436080933
Validation loss: 1.52289020117893

Epoch: 5| Step: 3
Training loss: 0.4004379212856293
Validation loss: 1.544197069701328

Epoch: 5| Step: 4
Training loss: 0.24325962364673615
Validation loss: 1.5316623821053454

Epoch: 5| Step: 5
Training loss: 0.16311180591583252
Validation loss: 1.5601127929584955

Epoch: 5| Step: 6
Training loss: 0.31770116090774536
Validation loss: 1.5588420321864467

Epoch: 5| Step: 7
Training loss: 0.11822203546762466
Validation loss: 1.5905745067904073

Epoch: 5| Step: 8
Training loss: 0.21808382868766785
Validation loss: 1.5668644674362675

Epoch: 5| Step: 9
Training loss: 0.22634172439575195
Validation loss: 1.5628909180241246

Epoch: 5| Step: 10
Training loss: 0.2080734521150589
Validation loss: 1.5938622887416551

Epoch: 436| Step: 0
Training loss: 0.2509881556034088
Validation loss: 1.5925319246066514

Epoch: 5| Step: 1
Training loss: 0.19189146161079407
Validation loss: 1.5697043172774776

Epoch: 5| Step: 2
Training loss: 0.17632651329040527
Validation loss: 1.5450230798413676

Epoch: 5| Step: 3
Training loss: 0.30621084570884705
Validation loss: 1.533677307508325

Epoch: 5| Step: 4
Training loss: 0.23684963583946228
Validation loss: 1.5742049101860291

Epoch: 5| Step: 5
Training loss: 0.41090211272239685
Validation loss: 1.5485819706352808

Epoch: 5| Step: 6
Training loss: 0.26731714606285095
Validation loss: 1.5517820876131776

Epoch: 5| Step: 7
Training loss: 0.18916544318199158
Validation loss: 1.5529198108180877

Epoch: 5| Step: 8
Training loss: 0.37298884987831116
Validation loss: 1.5679230023455877

Epoch: 5| Step: 9
Training loss: 0.22194154560565948
Validation loss: 1.6072427906015867

Epoch: 5| Step: 10
Training loss: 0.369811087846756
Validation loss: 1.6118618211438578

Epoch: 437| Step: 0
Training loss: 0.2579015791416168
Validation loss: 1.6028816238526375

Epoch: 5| Step: 1
Training loss: 0.3247123956680298
Validation loss: 1.6207879666359193

Epoch: 5| Step: 2
Training loss: 0.1644093245267868
Validation loss: 1.6393253328979656

Epoch: 5| Step: 3
Training loss: 0.15109948813915253
Validation loss: 1.6041117573297152

Epoch: 5| Step: 4
Training loss: 0.3174092173576355
Validation loss: 1.6239782981975104

Epoch: 5| Step: 5
Training loss: 0.24437585473060608
Validation loss: 1.5860246419906616

Epoch: 5| Step: 6
Training loss: 0.28641340136528015
Validation loss: 1.6007174702100857

Epoch: 5| Step: 7
Training loss: 0.3519551157951355
Validation loss: 1.572705291932629

Epoch: 5| Step: 8
Training loss: 0.2963625490665436
Validation loss: 1.5967941104724843

Epoch: 5| Step: 9
Training loss: 0.20310434699058533
Validation loss: 1.5670340817461732

Epoch: 5| Step: 10
Training loss: 0.2201259881258011
Validation loss: 1.591415669328423

Epoch: 438| Step: 0
Training loss: 0.28164732456207275
Validation loss: 1.5946770791084535

Epoch: 5| Step: 1
Training loss: 0.18270377814769745
Validation loss: 1.5491838967928322

Epoch: 5| Step: 2
Training loss: 0.3057957589626312
Validation loss: 1.5868535426355177

Epoch: 5| Step: 3
Training loss: 0.32773128151893616
Validation loss: 1.5876219387977355

Epoch: 5| Step: 4
Training loss: 0.2587340772151947
Validation loss: 1.5609721047903902

Epoch: 5| Step: 5
Training loss: 0.2662230432033539
Validation loss: 1.6032981718740156

Epoch: 5| Step: 6
Training loss: 0.2119588851928711
Validation loss: 1.6023316716635099

Epoch: 5| Step: 7
Training loss: 0.24953798949718475
Validation loss: 1.5952629966120566

Epoch: 5| Step: 8
Training loss: 0.17692109942436218
Validation loss: 1.5641116147400231

Epoch: 5| Step: 9
Training loss: 0.29395538568496704
Validation loss: 1.60016861525915

Epoch: 5| Step: 10
Training loss: 0.3668442368507385
Validation loss: 1.559217450439289

Epoch: 439| Step: 0
Training loss: 0.2903955578804016
Validation loss: 1.5409059345081288

Epoch: 5| Step: 1
Training loss: 0.19325704872608185
Validation loss: 1.5635538639560822

Epoch: 5| Step: 2
Training loss: 0.2599882483482361
Validation loss: 1.5648485614407448

Epoch: 5| Step: 3
Training loss: 0.23981428146362305
Validation loss: 1.5558267895893385

Epoch: 5| Step: 4
Training loss: 0.21924647688865662
Validation loss: 1.5656877615118538

Epoch: 5| Step: 5
Training loss: 0.1789540946483612
Validation loss: 1.5603670227912165

Epoch: 5| Step: 6
Training loss: 0.3768713176250458
Validation loss: 1.561743647821488

Epoch: 5| Step: 7
Training loss: 0.15634390711784363
Validation loss: 1.5988234146948783

Epoch: 5| Step: 8
Training loss: 0.22946491837501526
Validation loss: 1.5963055344038113

Epoch: 5| Step: 9
Training loss: 0.275334894657135
Validation loss: 1.5757132499448714

Epoch: 5| Step: 10
Training loss: 0.3338584303855896
Validation loss: 1.6082875049242409

Epoch: 440| Step: 0
Training loss: 0.27065396308898926
Validation loss: 1.599958712054837

Epoch: 5| Step: 1
Training loss: 0.18379221856594086
Validation loss: 1.5864901311935917

Epoch: 5| Step: 2
Training loss: 0.29596757888793945
Validation loss: 1.553647215648364

Epoch: 5| Step: 3
Training loss: 0.24889607727527618
Validation loss: 1.577395285329511

Epoch: 5| Step: 4
Training loss: 0.1319689154624939
Validation loss: 1.576980875384423

Epoch: 5| Step: 5
Training loss: 0.2573411464691162
Validation loss: 1.562396558382178

Epoch: 5| Step: 6
Training loss: 0.38317790627479553
Validation loss: 1.5869206395200504

Epoch: 5| Step: 7
Training loss: 0.3131564259529114
Validation loss: 1.5644602557664276

Epoch: 5| Step: 8
Training loss: 0.11391036212444305
Validation loss: 1.577072787028487

Epoch: 5| Step: 9
Training loss: 0.3390497863292694
Validation loss: 1.5623998808604416

Epoch: 5| Step: 10
Training loss: 0.1459059715270996
Validation loss: 1.5386701117279709

Epoch: 441| Step: 0
Training loss: 0.19482921063899994
Validation loss: 1.541470653267317

Epoch: 5| Step: 1
Training loss: 0.18757319450378418
Validation loss: 1.560551542107777

Epoch: 5| Step: 2
Training loss: 0.2621682286262512
Validation loss: 1.6026851720707391

Epoch: 5| Step: 3
Training loss: 0.2544088065624237
Validation loss: 1.6073071879725302

Epoch: 5| Step: 4
Training loss: 0.253640353679657
Validation loss: 1.607361194907978

Epoch: 5| Step: 5
Training loss: 0.21936039626598358
Validation loss: 1.5924424535484725

Epoch: 5| Step: 6
Training loss: 0.2571569085121155
Validation loss: 1.5943795865581882

Epoch: 5| Step: 7
Training loss: 0.16848981380462646
Validation loss: 1.5792932433466758

Epoch: 5| Step: 8
Training loss: 0.365213006734848
Validation loss: 1.5601460536321003

Epoch: 5| Step: 9
Training loss: 0.1721602827310562
Validation loss: 1.5335518454992643

Epoch: 5| Step: 10
Training loss: 0.410116583108902
Validation loss: 1.5620153501469602

Epoch: 442| Step: 0
Training loss: 0.20385310053825378
Validation loss: 1.5616371759804346

Epoch: 5| Step: 1
Training loss: 0.1880902498960495
Validation loss: 1.5149189195325297

Epoch: 5| Step: 2
Training loss: 0.3410598933696747
Validation loss: 1.5173689934515184

Epoch: 5| Step: 3
Training loss: 0.19947651028633118
Validation loss: 1.5069529228312994

Epoch: 5| Step: 4
Training loss: 0.2584232687950134
Validation loss: 1.5156925724398704

Epoch: 5| Step: 5
Training loss: 0.28370600938796997
Validation loss: 1.5494345003558743

Epoch: 5| Step: 6
Training loss: 0.14677511155605316
Validation loss: 1.5181043814587336

Epoch: 5| Step: 7
Training loss: 0.2030828446149826
Validation loss: 1.5480274090202906

Epoch: 5| Step: 8
Training loss: 0.35553544759750366
Validation loss: 1.5318340306640954

Epoch: 5| Step: 9
Training loss: 0.22172904014587402
Validation loss: 1.549839319721345

Epoch: 5| Step: 10
Training loss: 0.23730763792991638
Validation loss: 1.5692828714206655

Epoch: 443| Step: 0
Training loss: 0.18326303362846375
Validation loss: 1.5686139752787929

Epoch: 5| Step: 1
Training loss: 0.2537264823913574
Validation loss: 1.5636288863356396

Epoch: 5| Step: 2
Training loss: 0.1811118870973587
Validation loss: 1.5652631341770131

Epoch: 5| Step: 3
Training loss: 0.30742886662483215
Validation loss: 1.5280386145396898

Epoch: 5| Step: 4
Training loss: 0.2488112896680832
Validation loss: 1.5511140643909413

Epoch: 5| Step: 5
Training loss: 0.17534098029136658
Validation loss: 1.5471874501115532

Epoch: 5| Step: 6
Training loss: 0.2294916808605194
Validation loss: 1.5640532150063464

Epoch: 5| Step: 7
Training loss: 0.16246813535690308
Validation loss: 1.5666289803802327

Epoch: 5| Step: 8
Training loss: 0.261141836643219
Validation loss: 1.58696279346302

Epoch: 5| Step: 9
Training loss: 0.24447014927864075
Validation loss: 1.6021614587435158

Epoch: 5| Step: 10
Training loss: 0.2570042908191681
Validation loss: 1.5807442460008847

Epoch: 444| Step: 0
Training loss: 0.25616657733917236
Validation loss: 1.5722749284518662

Epoch: 5| Step: 1
Training loss: 0.16705673933029175
Validation loss: 1.5423948123890867

Epoch: 5| Step: 2
Training loss: 0.2844642698764801
Validation loss: 1.5341243795169297

Epoch: 5| Step: 3
Training loss: 0.2239171266555786
Validation loss: 1.5655319575340516

Epoch: 5| Step: 4
Training loss: 0.20331330597400665
Validation loss: 1.5840863091971285

Epoch: 5| Step: 5
Training loss: 0.17295077443122864
Validation loss: 1.578975937699759

Epoch: 5| Step: 6
Training loss: 0.2662147581577301
Validation loss: 1.59052320449583

Epoch: 5| Step: 7
Training loss: 0.26591628789901733
Validation loss: 1.6221835908069406

Epoch: 5| Step: 8
Training loss: 0.39244210720062256
Validation loss: 1.5927292223899596

Epoch: 5| Step: 9
Training loss: 0.13301625847816467
Validation loss: 1.5750632644981466

Epoch: 5| Step: 10
Training loss: 0.23323749005794525
Validation loss: 1.592137905859178

Epoch: 445| Step: 0
Training loss: 0.2843833565711975
Validation loss: 1.5663557590976838

Epoch: 5| Step: 1
Training loss: 0.18688485026359558
Validation loss: 1.5587980196040163

Epoch: 5| Step: 2
Training loss: 0.22343900799751282
Validation loss: 1.5332794227907736

Epoch: 5| Step: 3
Training loss: 0.2852533459663391
Validation loss: 1.5181029458199777

Epoch: 5| Step: 4
Training loss: 0.11909256130456924
Validation loss: 1.5253718335141417

Epoch: 5| Step: 5
Training loss: 0.18055583536624908
Validation loss: 1.536459239580298

Epoch: 5| Step: 6
Training loss: 0.17455501854419708
Validation loss: 1.5451183754910705

Epoch: 5| Step: 7
Training loss: 0.30395835638046265
Validation loss: 1.5508995415062032

Epoch: 5| Step: 8
Training loss: 0.20289278030395508
Validation loss: 1.565193760779596

Epoch: 5| Step: 9
Training loss: 0.13105352222919464
Validation loss: 1.59011883120383

Epoch: 5| Step: 10
Training loss: 0.29448872804641724
Validation loss: 1.5687151224382463

Epoch: 446| Step: 0
Training loss: 0.2725982069969177
Validation loss: 1.5966738757266794

Epoch: 5| Step: 1
Training loss: 0.17967884242534637
Validation loss: 1.5733424514852545

Epoch: 5| Step: 2
Training loss: 0.18527479469776154
Validation loss: 1.514517984082622

Epoch: 5| Step: 3
Training loss: 0.2472076416015625
Validation loss: 1.5279322901079733

Epoch: 5| Step: 4
Training loss: 0.18491250276565552
Validation loss: 1.5263154006773425

Epoch: 5| Step: 5
Training loss: 0.17624235153198242
Validation loss: 1.544060012345673

Epoch: 5| Step: 6
Training loss: 0.16754427552223206
Validation loss: 1.5532152101557741

Epoch: 5| Step: 7
Training loss: 0.2805998921394348
Validation loss: 1.552460124415736

Epoch: 5| Step: 8
Training loss: 0.2652952969074249
Validation loss: 1.5502996098610662

Epoch: 5| Step: 9
Training loss: 0.4020296037197113
Validation loss: 1.5502998200795983

Epoch: 5| Step: 10
Training loss: 0.1438036859035492
Validation loss: 1.5809345322270547

Epoch: 447| Step: 0
Training loss: 0.12673567235469818
Validation loss: 1.5946498506812639

Epoch: 5| Step: 1
Training loss: 0.2977987825870514
Validation loss: 1.5996576675804712

Epoch: 5| Step: 2
Training loss: 0.1391090750694275
Validation loss: 1.5739525928292224

Epoch: 5| Step: 3
Training loss: 0.2660488486289978
Validation loss: 1.5812375801865772

Epoch: 5| Step: 4
Training loss: 0.27630162239074707
Validation loss: 1.579252891643073

Epoch: 5| Step: 5
Training loss: 0.37716323137283325
Validation loss: 1.5627899682650002

Epoch: 5| Step: 6
Training loss: 0.2424890697002411
Validation loss: 1.545447184193519

Epoch: 5| Step: 7
Training loss: 0.11292172968387604
Validation loss: 1.5410593402001165

Epoch: 5| Step: 8
Training loss: 0.1348920613527298
Validation loss: 1.561701520796745

Epoch: 5| Step: 9
Training loss: 0.13455519080162048
Validation loss: 1.5389966298175115

Epoch: 5| Step: 10
Training loss: 0.3296419680118561
Validation loss: 1.5355278151009673

Epoch: 448| Step: 0
Training loss: 0.20498180389404297
Validation loss: 1.5439645410865865

Epoch: 5| Step: 1
Training loss: 0.18321630358695984
Validation loss: 1.5922547322447582

Epoch: 5| Step: 2
Training loss: 0.18403048813343048
Validation loss: 1.5918592560675837

Epoch: 5| Step: 3
Training loss: 0.26553449034690857
Validation loss: 1.5672496390599076

Epoch: 5| Step: 4
Training loss: 0.21480241417884827
Validation loss: 1.5644240545970138

Epoch: 5| Step: 5
Training loss: 0.34909945726394653
Validation loss: 1.582930031643119

Epoch: 5| Step: 6
Training loss: 0.10396256297826767
Validation loss: 1.5934329212352794

Epoch: 5| Step: 7
Training loss: 0.17163990437984467
Validation loss: 1.5636278583157448

Epoch: 5| Step: 8
Training loss: 0.2180223912000656
Validation loss: 1.5351846269381944

Epoch: 5| Step: 9
Training loss: 0.18550188839435577
Validation loss: 1.5321680268933695

Epoch: 5| Step: 10
Training loss: 0.26140230894088745
Validation loss: 1.5043834473497124

Epoch: 449| Step: 0
Training loss: 0.1268470734357834
Validation loss: 1.4992677966753643

Epoch: 5| Step: 1
Training loss: 0.1474328488111496
Validation loss: 1.502015439412927

Epoch: 5| Step: 2
Training loss: 0.2372659146785736
Validation loss: 1.513582811560682

Epoch: 5| Step: 3
Training loss: 0.14530465006828308
Validation loss: 1.5050338878426501

Epoch: 5| Step: 4
Training loss: 0.22327089309692383
Validation loss: 1.512557768052624

Epoch: 5| Step: 5
Training loss: 0.19259707629680634
Validation loss: 1.5370856997787312

Epoch: 5| Step: 6
Training loss: 0.3107549846172333
Validation loss: 1.5558146917691795

Epoch: 5| Step: 7
Training loss: 0.15301655232906342
Validation loss: 1.5609734583926458

Epoch: 5| Step: 8
Training loss: 0.28922900557518005
Validation loss: 1.5599785402256956

Epoch: 5| Step: 9
Training loss: 0.23978447914123535
Validation loss: 1.552229719777261

Epoch: 5| Step: 10
Training loss: 0.3136959671974182
Validation loss: 1.537187332748085

Epoch: 450| Step: 0
Training loss: 0.16259220242500305
Validation loss: 1.553034192772322

Epoch: 5| Step: 1
Training loss: 0.24560144543647766
Validation loss: 1.5339327319975822

Epoch: 5| Step: 2
Training loss: 0.24691316485404968
Validation loss: 1.5808608890861593

Epoch: 5| Step: 3
Training loss: 0.164605051279068
Validation loss: 1.5923938264128983

Epoch: 5| Step: 4
Training loss: 0.17599302530288696
Validation loss: 1.5722816733903782

Epoch: 5| Step: 5
Training loss: 0.1593533605337143
Validation loss: 1.580156824922049

Epoch: 5| Step: 6
Training loss: 0.21893219649791718
Validation loss: 1.5373520453770955

Epoch: 5| Step: 7
Training loss: 0.19368042051792145
Validation loss: 1.5471735833793558

Epoch: 5| Step: 8
Training loss: 0.31322893500328064
Validation loss: 1.536525668636445

Epoch: 5| Step: 9
Training loss: 0.410851389169693
Validation loss: 1.5303076287751556

Epoch: 5| Step: 10
Training loss: 0.2836320400238037
Validation loss: 1.51260930620214

Epoch: 451| Step: 0
Training loss: 0.4322764277458191
Validation loss: 1.5348326570244246

Epoch: 5| Step: 1
Training loss: 0.243742898106575
Validation loss: 1.500436693109492

Epoch: 5| Step: 2
Training loss: 0.11539323627948761
Validation loss: 1.5183403440701064

Epoch: 5| Step: 3
Training loss: 0.3903241753578186
Validation loss: 1.5171800698003461

Epoch: 5| Step: 4
Training loss: 0.16320405900478363
Validation loss: 1.5213402298188978

Epoch: 5| Step: 5
Training loss: 0.19947631657123566
Validation loss: 1.5388942495469125

Epoch: 5| Step: 6
Training loss: 0.2333560436964035
Validation loss: 1.5428725884806724

Epoch: 5| Step: 7
Training loss: 0.2636330723762512
Validation loss: 1.5582821933172082

Epoch: 5| Step: 8
Training loss: 0.254273921251297
Validation loss: 1.526340658946704

Epoch: 5| Step: 9
Training loss: 0.1985812932252884
Validation loss: 1.537232595105325

Epoch: 5| Step: 10
Training loss: 0.17571967840194702
Validation loss: 1.5334024096048007

Epoch: 452| Step: 0
Training loss: 0.27661603689193726
Validation loss: 1.5311443010965984

Epoch: 5| Step: 1
Training loss: 0.21705090999603271
Validation loss: 1.5356753180103917

Epoch: 5| Step: 2
Training loss: 0.20653650164604187
Validation loss: 1.5426202063919396

Epoch: 5| Step: 3
Training loss: 0.1886257827281952
Validation loss: 1.5555510508116854

Epoch: 5| Step: 4
Training loss: 0.18152618408203125
Validation loss: 1.5449410382137503

Epoch: 5| Step: 5
Training loss: 0.08024903386831284
Validation loss: 1.531715831448955

Epoch: 5| Step: 6
Training loss: 0.28472501039505005
Validation loss: 1.5444757989657822

Epoch: 5| Step: 7
Training loss: 0.3929448425769806
Validation loss: 1.493557192945993

Epoch: 5| Step: 8
Training loss: 0.14399883151054382
Validation loss: 1.495705827589958

Epoch: 5| Step: 9
Training loss: 0.30906379222869873
Validation loss: 1.5184843399191414

Epoch: 5| Step: 10
Training loss: 0.1440713256597519
Validation loss: 1.5036634450317712

Epoch: 453| Step: 0
Training loss: 0.14715878665447235
Validation loss: 1.5348428705687165

Epoch: 5| Step: 1
Training loss: 0.2716981768608093
Validation loss: 1.5073678826773038

Epoch: 5| Step: 2
Training loss: 0.14579662680625916
Validation loss: 1.5048750677416403

Epoch: 5| Step: 3
Training loss: 0.20671911537647247
Validation loss: 1.5092850308264456

Epoch: 5| Step: 4
Training loss: 0.20889143645763397
Validation loss: 1.5245269562608452

Epoch: 5| Step: 5
Training loss: 0.20417270064353943
Validation loss: 1.509144211328158

Epoch: 5| Step: 6
Training loss: 0.2849689722061157
Validation loss: 1.4844177743440032

Epoch: 5| Step: 7
Training loss: 0.2795734703540802
Validation loss: 1.5188484294440157

Epoch: 5| Step: 8
Training loss: 0.17753517627716064
Validation loss: 1.5294565923752323

Epoch: 5| Step: 9
Training loss: 0.21452859044075012
Validation loss: 1.528477499561925

Epoch: 5| Step: 10
Training loss: 0.19007618725299835
Validation loss: 1.5516751453440676

Epoch: 454| Step: 0
Training loss: 0.1073242649435997
Validation loss: 1.5427558473361436

Epoch: 5| Step: 1
Training loss: 0.2107100784778595
Validation loss: 1.525359066583777

Epoch: 5| Step: 2
Training loss: 0.40067172050476074
Validation loss: 1.5436086757208711

Epoch: 5| Step: 3
Training loss: 0.1388808935880661
Validation loss: 1.5303822896813835

Epoch: 5| Step: 4
Training loss: 0.19067928194999695
Validation loss: 1.5314540119581326

Epoch: 5| Step: 5
Training loss: 0.1500852108001709
Validation loss: 1.5172409408835954

Epoch: 5| Step: 6
Training loss: 0.125498428940773
Validation loss: 1.5216609188305434

Epoch: 5| Step: 7
Training loss: 0.290229856967926
Validation loss: 1.5347538725022347

Epoch: 5| Step: 8
Training loss: 0.17930875718593597
Validation loss: 1.4950246862185899

Epoch: 5| Step: 9
Training loss: 0.2030155211687088
Validation loss: 1.490788564887098

Epoch: 5| Step: 10
Training loss: 0.33288809657096863
Validation loss: 1.5463233814444592

Epoch: 455| Step: 0
Training loss: 0.16558603942394257
Validation loss: 1.5625186145946544

Epoch: 5| Step: 1
Training loss: 0.15229497849941254
Validation loss: 1.5509212299059796

Epoch: 5| Step: 2
Training loss: 0.30601292848587036
Validation loss: 1.5526515770983953

Epoch: 5| Step: 3
Training loss: 0.13742806017398834
Validation loss: 1.5611149636648034

Epoch: 5| Step: 4
Training loss: 0.3714166283607483
Validation loss: 1.5522580838972522

Epoch: 5| Step: 5
Training loss: 0.22163505852222443
Validation loss: 1.5602939167330343

Epoch: 5| Step: 6
Training loss: 0.1875723898410797
Validation loss: 1.541267675738181

Epoch: 5| Step: 7
Training loss: 0.22079584002494812
Validation loss: 1.523347153458544

Epoch: 5| Step: 8
Training loss: 0.2007438838481903
Validation loss: 1.5275345745907034

Epoch: 5| Step: 9
Training loss: 0.18656380474567413
Validation loss: 1.5128842297420706

Epoch: 5| Step: 10
Training loss: 0.16353470087051392
Validation loss: 1.5145976069152995

Epoch: 456| Step: 0
Training loss: 0.23711080849170685
Validation loss: 1.5294738315766858

Epoch: 5| Step: 1
Training loss: 0.0936383455991745
Validation loss: 1.5542486047232023

Epoch: 5| Step: 2
Training loss: 0.24391058087348938
Validation loss: 1.5573908436682917

Epoch: 5| Step: 3
Training loss: 0.09824899584054947
Validation loss: 1.5444635550181072

Epoch: 5| Step: 4
Training loss: 0.10417404025793076
Validation loss: 1.5498776076942362

Epoch: 5| Step: 5
Training loss: 0.08806686848402023
Validation loss: 1.5312215833253757

Epoch: 5| Step: 6
Training loss: 0.29235923290252686
Validation loss: 1.5351479143224738

Epoch: 5| Step: 7
Training loss: 0.32781749963760376
Validation loss: 1.5639805460488925

Epoch: 5| Step: 8
Training loss: 0.19196675717830658
Validation loss: 1.5378628610282816

Epoch: 5| Step: 9
Training loss: 0.341372549533844
Validation loss: 1.552579718251382

Epoch: 5| Step: 10
Training loss: 0.10898444056510925
Validation loss: 1.5486347239504579

Epoch: 457| Step: 0
Training loss: 0.24616780877113342
Validation loss: 1.555746070800289

Epoch: 5| Step: 1
Training loss: 0.17881402373313904
Validation loss: 1.5402722807340725

Epoch: 5| Step: 2
Training loss: 0.15101872384548187
Validation loss: 1.5521961053212483

Epoch: 5| Step: 3
Training loss: 0.19281736016273499
Validation loss: 1.527600380041266

Epoch: 5| Step: 4
Training loss: 0.1591804176568985
Validation loss: 1.5354356419655584

Epoch: 5| Step: 5
Training loss: 0.17069828510284424
Validation loss: 1.5002829310714558

Epoch: 5| Step: 6
Training loss: 0.19118478894233704
Validation loss: 1.485276270938176

Epoch: 5| Step: 7
Training loss: 0.18122997879981995
Validation loss: 1.532302318080779

Epoch: 5| Step: 8
Training loss: 0.1359264999628067
Validation loss: 1.5227013300823908

Epoch: 5| Step: 9
Training loss: 0.29768243432044983
Validation loss: 1.5289306666261406

Epoch: 5| Step: 10
Training loss: 0.3357742428779602
Validation loss: 1.543366446289965

Epoch: 458| Step: 0
Training loss: 0.18137745559215546
Validation loss: 1.5289870449291763

Epoch: 5| Step: 1
Training loss: 0.22852881252765656
Validation loss: 1.5270930169731058

Epoch: 5| Step: 2
Training loss: 0.21703755855560303
Validation loss: 1.5211872708412908

Epoch: 5| Step: 3
Training loss: 0.06820458918809891
Validation loss: 1.5258948764493387

Epoch: 5| Step: 4
Training loss: 0.1955406367778778
Validation loss: 1.5214161206317205

Epoch: 5| Step: 5
Training loss: 0.22240813076496124
Validation loss: 1.5274638341319176

Epoch: 5| Step: 6
Training loss: 0.23296160995960236
Validation loss: 1.4975579284852552

Epoch: 5| Step: 7
Training loss: 0.38586145639419556
Validation loss: 1.4978916504049813

Epoch: 5| Step: 8
Training loss: 0.16020314395427704
Validation loss: 1.4997606905557777

Epoch: 5| Step: 9
Training loss: 0.22062459588050842
Validation loss: 1.496433505447962

Epoch: 5| Step: 10
Training loss: 0.2715771496295929
Validation loss: 1.4937042228637203

Epoch: 459| Step: 0
Training loss: 0.25578469038009644
Validation loss: 1.4941873370960195

Epoch: 5| Step: 1
Training loss: 0.12488057464361191
Validation loss: 1.509901576144721

Epoch: 5| Step: 2
Training loss: 0.26416611671447754
Validation loss: 1.5355115090647051

Epoch: 5| Step: 3
Training loss: 0.22393223643302917
Validation loss: 1.5282687115412887

Epoch: 5| Step: 4
Training loss: 0.14088502526283264
Validation loss: 1.5215073067654845

Epoch: 5| Step: 5
Training loss: 0.19506661593914032
Validation loss: 1.5189933789673673

Epoch: 5| Step: 6
Training loss: 0.2478567659854889
Validation loss: 1.5248689997580744

Epoch: 5| Step: 7
Training loss: 0.2171427309513092
Validation loss: 1.5001171917043707

Epoch: 5| Step: 8
Training loss: 0.21254172921180725
Validation loss: 1.5101454559192862

Epoch: 5| Step: 9
Training loss: 0.23314955830574036
Validation loss: 1.5088155256804598

Epoch: 5| Step: 10
Training loss: 0.20581527054309845
Validation loss: 1.5011926838146743

Epoch: 460| Step: 0
Training loss: 0.22721442580223083
Validation loss: 1.4822799723635438

Epoch: 5| Step: 1
Training loss: 0.21828392148017883
Validation loss: 1.4940043316092542

Epoch: 5| Step: 2
Training loss: 0.190036803483963
Validation loss: 1.5089729562882455

Epoch: 5| Step: 3
Training loss: 0.1598406285047531
Validation loss: 1.505776036170221

Epoch: 5| Step: 4
Training loss: 0.19945532083511353
Validation loss: 1.5279997292385306

Epoch: 5| Step: 5
Training loss: 0.18459996581077576
Validation loss: 1.4887876010710193

Epoch: 5| Step: 6
Training loss: 0.12168858200311661
Validation loss: 1.4921832315383419

Epoch: 5| Step: 7
Training loss: 0.1662885695695877
Validation loss: 1.5143071630949616

Epoch: 5| Step: 8
Training loss: 0.3130801320075989
Validation loss: 1.5066361170943066

Epoch: 5| Step: 9
Training loss: 0.2040785253047943
Validation loss: 1.542390460609108

Epoch: 5| Step: 10
Training loss: 0.13870550692081451
Validation loss: 1.512686780703965

Epoch: 461| Step: 0
Training loss: 0.10786592960357666
Validation loss: 1.5326479455476165

Epoch: 5| Step: 1
Training loss: 0.23252424597740173
Validation loss: 1.520148592610513

Epoch: 5| Step: 2
Training loss: 0.15272706747055054
Validation loss: 1.5205884466889084

Epoch: 5| Step: 3
Training loss: 0.20965787768363953
Validation loss: 1.51430191339985

Epoch: 5| Step: 4
Training loss: 0.28648748993873596
Validation loss: 1.5239281718448927

Epoch: 5| Step: 5
Training loss: 0.2980484962463379
Validation loss: 1.5386799099624797

Epoch: 5| Step: 6
Training loss: 0.27278146147727966
Validation loss: 1.5743143763593448

Epoch: 5| Step: 7
Training loss: 0.14347541332244873
Validation loss: 1.5512016075913624

Epoch: 5| Step: 8
Training loss: 0.1592576801776886
Validation loss: 1.5517029352085565

Epoch: 5| Step: 9
Training loss: 0.09771563112735748
Validation loss: 1.5571797663165676

Epoch: 5| Step: 10
Training loss: 0.2807495892047882
Validation loss: 1.5542053368783766

Epoch: 462| Step: 0
Training loss: 0.1212405413389206
Validation loss: 1.572722533697723

Epoch: 5| Step: 1
Training loss: 0.23648515343666077
Validation loss: 1.5323620970531175

Epoch: 5| Step: 2
Training loss: 0.19388872385025024
Validation loss: 1.5212523168133152

Epoch: 5| Step: 3
Training loss: 0.24959206581115723
Validation loss: 1.5311561938255065

Epoch: 5| Step: 4
Training loss: 0.21598713099956512
Validation loss: 1.5134249079611994

Epoch: 5| Step: 5
Training loss: 0.199636772274971
Validation loss: 1.4880598001582648

Epoch: 5| Step: 6
Training loss: 0.237489253282547
Validation loss: 1.4587180691380655

Epoch: 5| Step: 7
Training loss: 0.24072925746440887
Validation loss: 1.4666435795445596

Epoch: 5| Step: 8
Training loss: 0.27910858392715454
Validation loss: 1.4739995579565726

Epoch: 5| Step: 9
Training loss: 0.2148788422346115
Validation loss: 1.470882991308807

Epoch: 5| Step: 10
Training loss: 0.12151608616113663
Validation loss: 1.5201123658046927

Epoch: 463| Step: 0
Training loss: 0.15406303107738495
Validation loss: 1.4956529678836945

Epoch: 5| Step: 1
Training loss: 0.18349310755729675
Validation loss: 1.533750690439696

Epoch: 5| Step: 2
Training loss: 0.2761434316635132
Validation loss: 1.5493707374859882

Epoch: 5| Step: 3
Training loss: 0.12436423450708389
Validation loss: 1.5917637322538642

Epoch: 5| Step: 4
Training loss: 0.2928050756454468
Validation loss: 1.616107847100945

Epoch: 5| Step: 5
Training loss: 0.1977415382862091
Validation loss: 1.5972242124619023

Epoch: 5| Step: 6
Training loss: 0.2437131702899933
Validation loss: 1.5877210747811101

Epoch: 5| Step: 7
Training loss: 0.1327790766954422
Validation loss: 1.6208387664569321

Epoch: 5| Step: 8
Training loss: 0.2793789803981781
Validation loss: 1.6114178575495237

Epoch: 5| Step: 9
Training loss: 0.21420808136463165
Validation loss: 1.5436861425317743

Epoch: 5| Step: 10
Training loss: 0.22062069177627563
Validation loss: 1.51124442649144

Epoch: 464| Step: 0
Training loss: 0.15459728240966797
Validation loss: 1.5306719733822731

Epoch: 5| Step: 1
Training loss: 0.22068944573402405
Validation loss: 1.4883663974782473

Epoch: 5| Step: 2
Training loss: 0.2408423125743866
Validation loss: 1.4882769956383655

Epoch: 5| Step: 3
Training loss: 0.21202194690704346
Validation loss: 1.4960644283602316

Epoch: 5| Step: 4
Training loss: 0.2673403322696686
Validation loss: 1.4845531704605266

Epoch: 5| Step: 5
Training loss: 0.199386328458786
Validation loss: 1.484029012341653

Epoch: 5| Step: 6
Training loss: 0.2438991516828537
Validation loss: 1.5160795962938698

Epoch: 5| Step: 7
Training loss: 0.14823263883590698
Validation loss: 1.4981003038344844

Epoch: 5| Step: 8
Training loss: 0.14175328612327576
Validation loss: 1.5315139703853156

Epoch: 5| Step: 9
Training loss: 0.38181912899017334
Validation loss: 1.5221888583193544

Epoch: 5| Step: 10
Training loss: 0.2281280905008316
Validation loss: 1.5344558761965843

Epoch: 465| Step: 0
Training loss: 0.24268731474876404
Validation loss: 1.5249336637476438

Epoch: 5| Step: 1
Training loss: 0.24662737548351288
Validation loss: 1.5407691700484163

Epoch: 5| Step: 2
Training loss: 0.1739424765110016
Validation loss: 1.5475097240940217

Epoch: 5| Step: 3
Training loss: 0.22389943897724152
Validation loss: 1.5421523810714803

Epoch: 5| Step: 4
Training loss: 0.2407676726579666
Validation loss: 1.5679157639062533

Epoch: 5| Step: 5
Training loss: 0.18333402276039124
Validation loss: 1.5513630977240942

Epoch: 5| Step: 6
Training loss: 0.24876625835895538
Validation loss: 1.5100249346866403

Epoch: 5| Step: 7
Training loss: 0.215200275182724
Validation loss: 1.5310072693773495

Epoch: 5| Step: 8
Training loss: 0.135704904794693
Validation loss: 1.5038014047889299

Epoch: 5| Step: 9
Training loss: 0.13213661313056946
Validation loss: 1.5231157400274788

Epoch: 5| Step: 10
Training loss: 0.27875322103500366
Validation loss: 1.5110566692967569

Epoch: 466| Step: 0
Training loss: 0.2178908884525299
Validation loss: 1.542869294843366

Epoch: 5| Step: 1
Training loss: 0.1717146337032318
Validation loss: 1.520371893400787

Epoch: 5| Step: 2
Training loss: 0.29971200227737427
Validation loss: 1.5411706406583068

Epoch: 5| Step: 3
Training loss: 0.16784289479255676
Validation loss: 1.5629149983006139

Epoch: 5| Step: 4
Training loss: 0.24604026973247528
Validation loss: 1.5487383565595072

Epoch: 5| Step: 5
Training loss: 0.1618569940328598
Validation loss: 1.5180490068210069

Epoch: 5| Step: 6
Training loss: 0.19465985894203186
Validation loss: 1.563565892557944

Epoch: 5| Step: 7
Training loss: 0.16768869757652283
Validation loss: 1.5157021566103863

Epoch: 5| Step: 8
Training loss: 0.17525088787078857
Validation loss: 1.5202889801353536

Epoch: 5| Step: 9
Training loss: 0.1001109704375267
Validation loss: 1.508651271943123

Epoch: 5| Step: 10
Training loss: 0.270862340927124
Validation loss: 1.5008378323688303

Epoch: 467| Step: 0
Training loss: 0.15990382432937622
Validation loss: 1.528965465484127

Epoch: 5| Step: 1
Training loss: 0.14354568719863892
Validation loss: 1.5404837862137826

Epoch: 5| Step: 2
Training loss: 0.15027238428592682
Validation loss: 1.5525896190315165

Epoch: 5| Step: 3
Training loss: 0.22105126082897186
Validation loss: 1.572373854216709

Epoch: 5| Step: 4
Training loss: 0.1435876190662384
Validation loss: 1.5303135187395158

Epoch: 5| Step: 5
Training loss: 0.30896174907684326
Validation loss: 1.5562764085749143

Epoch: 5| Step: 6
Training loss: 0.2058122158050537
Validation loss: 1.5644036710903209

Epoch: 5| Step: 7
Training loss: 0.21141822636127472
Validation loss: 1.5342098230956702

Epoch: 5| Step: 8
Training loss: 0.4088047444820404
Validation loss: 1.5243157661089333

Epoch: 5| Step: 9
Training loss: 0.14175447821617126
Validation loss: 1.5184735252011208

Epoch: 5| Step: 10
Training loss: 0.1694600135087967
Validation loss: 1.4888866870634017

Epoch: 468| Step: 0
Training loss: 0.11230359226465225
Validation loss: 1.4870335812209754

Epoch: 5| Step: 1
Training loss: 0.3032091557979584
Validation loss: 1.4973097642262776

Epoch: 5| Step: 2
Training loss: 0.18158379197120667
Validation loss: 1.4901584617553219

Epoch: 5| Step: 3
Training loss: 0.2297554314136505
Validation loss: 1.473226697214188

Epoch: 5| Step: 4
Training loss: 0.24680647253990173
Validation loss: 1.488098878373382

Epoch: 5| Step: 5
Training loss: 0.1873171627521515
Validation loss: 1.5055966838713615

Epoch: 5| Step: 6
Training loss: 0.2038288563489914
Validation loss: 1.5112200231962307

Epoch: 5| Step: 7
Training loss: 0.1982981264591217
Validation loss: 1.5154108744795605

Epoch: 5| Step: 8
Training loss: 0.26689547300338745
Validation loss: 1.5475049993043304

Epoch: 5| Step: 9
Training loss: 0.24335965514183044
Validation loss: 1.5786232807302987

Epoch: 5| Step: 10
Training loss: 0.1767979860305786
Validation loss: 1.5776606221352854

Epoch: 469| Step: 0
Training loss: 0.4896778464317322
Validation loss: 1.5929640108539211

Epoch: 5| Step: 1
Training loss: 0.2330530434846878
Validation loss: 1.5803097050677064

Epoch: 5| Step: 2
Training loss: 0.2663680911064148
Validation loss: 1.56791679961707

Epoch: 5| Step: 3
Training loss: 0.17362889647483826
Validation loss: 1.5657240242086432

Epoch: 5| Step: 4
Training loss: 0.18873685598373413
Validation loss: 1.5212700277246454

Epoch: 5| Step: 5
Training loss: 0.1653657853603363
Validation loss: 1.5050226988330964

Epoch: 5| Step: 6
Training loss: 0.2502390444278717
Validation loss: 1.500150263950389

Epoch: 5| Step: 7
Training loss: 0.21514658629894257
Validation loss: 1.518572675284519

Epoch: 5| Step: 8
Training loss: 0.12914785742759705
Validation loss: 1.4933459604940107

Epoch: 5| Step: 9
Training loss: 0.13369056582450867
Validation loss: 1.4760510921478271

Epoch: 5| Step: 10
Training loss: 0.21291950345039368
Validation loss: 1.5081263960048716

Epoch: 470| Step: 0
Training loss: 0.1220695972442627
Validation loss: 1.5243566036224365

Epoch: 5| Step: 1
Training loss: 0.25592148303985596
Validation loss: 1.482520107300051

Epoch: 5| Step: 2
Training loss: 0.26242464780807495
Validation loss: 1.5006228390560354

Epoch: 5| Step: 3
Training loss: 0.15182062983512878
Validation loss: 1.4983344975338186

Epoch: 5| Step: 4
Training loss: 0.20301929116249084
Validation loss: 1.5056989577508741

Epoch: 5| Step: 5
Training loss: 0.2923983931541443
Validation loss: 1.4757751713516891

Epoch: 5| Step: 6
Training loss: 0.16340036690235138
Validation loss: 1.4836229073104037

Epoch: 5| Step: 7
Training loss: 0.1411384642124176
Validation loss: 1.5055791690785398

Epoch: 5| Step: 8
Training loss: 0.37903958559036255
Validation loss: 1.5088845058794944

Epoch: 5| Step: 9
Training loss: 0.16485382616519928
Validation loss: 1.4962406081538047

Epoch: 5| Step: 10
Training loss: 0.16844619810581207
Validation loss: 1.5199448267618816

Epoch: 471| Step: 0
Training loss: 0.2781282067298889
Validation loss: 1.5111147870299637

Epoch: 5| Step: 1
Training loss: 0.13281619548797607
Validation loss: 1.5087437245153612

Epoch: 5| Step: 2
Training loss: 0.20992669463157654
Validation loss: 1.4893240492830995

Epoch: 5| Step: 3
Training loss: 0.13640251755714417
Validation loss: 1.481702131609763

Epoch: 5| Step: 4
Training loss: 0.14515161514282227
Validation loss: 1.476535617664296

Epoch: 5| Step: 5
Training loss: 0.23334769904613495
Validation loss: 1.511190709247384

Epoch: 5| Step: 6
Training loss: 0.18184354901313782
Validation loss: 1.4794591190994426

Epoch: 5| Step: 7
Training loss: 0.16266101598739624
Validation loss: 1.491732494805449

Epoch: 5| Step: 8
Training loss: 0.1423354297876358
Validation loss: 1.5098942005506126

Epoch: 5| Step: 9
Training loss: 0.32772746682167053
Validation loss: 1.5045092528866184

Epoch: 5| Step: 10
Training loss: 0.20276939868927002
Validation loss: 1.505167959838785

Epoch: 472| Step: 0
Training loss: 0.11857280880212784
Validation loss: 1.4895123640696208

Epoch: 5| Step: 1
Training loss: 0.18013744056224823
Validation loss: 1.5187310172665505

Epoch: 5| Step: 2
Training loss: 0.09280923008918762
Validation loss: 1.4886649193302277

Epoch: 5| Step: 3
Training loss: 0.0874709039926529
Validation loss: 1.4856947557900542

Epoch: 5| Step: 4
Training loss: 0.27846580743789673
Validation loss: 1.5046418687348724

Epoch: 5| Step: 5
Training loss: 0.18527404963970184
Validation loss: 1.4959321239943146

Epoch: 5| Step: 6
Training loss: 0.1912827044725418
Validation loss: 1.498657109916851

Epoch: 5| Step: 7
Training loss: 0.34535086154937744
Validation loss: 1.5167849230509933

Epoch: 5| Step: 8
Training loss: 0.1860400140285492
Validation loss: 1.5106407134763655

Epoch: 5| Step: 9
Training loss: 0.21432653069496155
Validation loss: 1.510893937080137

Epoch: 5| Step: 10
Training loss: 0.1926354169845581
Validation loss: 1.5263581506667598

Epoch: 473| Step: 0
Training loss: 0.25441330671310425
Validation loss: 1.5432618087337864

Epoch: 5| Step: 1
Training loss: 0.11080487072467804
Validation loss: 1.5385546914992794

Epoch: 5| Step: 2
Training loss: 0.19531095027923584
Validation loss: 1.4958657923565115

Epoch: 5| Step: 3
Training loss: 0.12352719157934189
Validation loss: 1.5127013050099856

Epoch: 5| Step: 4
Training loss: 0.10540975630283356
Validation loss: 1.510333425255232

Epoch: 5| Step: 5
Training loss: 0.13527271151542664
Validation loss: 1.5016862756462508

Epoch: 5| Step: 6
Training loss: 0.2075248658657074
Validation loss: 1.4907163048303256

Epoch: 5| Step: 7
Training loss: 0.31994661688804626
Validation loss: 1.4562447583803566

Epoch: 5| Step: 8
Training loss: 0.22134867310523987
Validation loss: 1.4709510393040155

Epoch: 5| Step: 9
Training loss: 0.19045041501522064
Validation loss: 1.451756881129357

Epoch: 5| Step: 10
Training loss: 0.16636593639850616
Validation loss: 1.459106868313205

Epoch: 474| Step: 0
Training loss: 0.14684954285621643
Validation loss: 1.4879574980787051

Epoch: 5| Step: 1
Training loss: 0.1665368378162384
Validation loss: 1.4705026688114289

Epoch: 5| Step: 2
Training loss: 0.12374572455883026
Validation loss: 1.4675101772431405

Epoch: 5| Step: 3
Training loss: 0.26193398237228394
Validation loss: 1.4484197939595869

Epoch: 5| Step: 4
Training loss: 0.31164175271987915
Validation loss: 1.4705070616096578

Epoch: 5| Step: 5
Training loss: 0.2056780606508255
Validation loss: 1.4744006497885591

Epoch: 5| Step: 6
Training loss: 0.30661097168922424
Validation loss: 1.4943922918329957

Epoch: 5| Step: 7
Training loss: 0.1330808401107788
Validation loss: 1.4808538024143507

Epoch: 5| Step: 8
Training loss: 0.16955454647541046
Validation loss: 1.4913629972806541

Epoch: 5| Step: 9
Training loss: 0.1377851814031601
Validation loss: 1.482128926502761

Epoch: 5| Step: 10
Training loss: 0.13032683730125427
Validation loss: 1.487174194346192

Epoch: 475| Step: 0
Training loss: 0.2050538808107376
Validation loss: 1.5119646505642963

Epoch: 5| Step: 1
Training loss: 0.31648269295692444
Validation loss: 1.471957084953144

Epoch: 5| Step: 2
Training loss: 0.23724651336669922
Validation loss: 1.465766627301452

Epoch: 5| Step: 3
Training loss: 0.1745389997959137
Validation loss: 1.480610191822052

Epoch: 5| Step: 4
Training loss: 0.199422687292099
Validation loss: 1.493665797736055

Epoch: 5| Step: 5
Training loss: 0.2006097286939621
Validation loss: 1.486098167716816

Epoch: 5| Step: 6
Training loss: 0.11633442342281342
Validation loss: 1.480038369855573

Epoch: 5| Step: 7
Training loss: 0.3340502381324768
Validation loss: 1.5027625035214167

Epoch: 5| Step: 8
Training loss: 0.13291844725608826
Validation loss: 1.5491847466397028

Epoch: 5| Step: 9
Training loss: 0.24212193489074707
Validation loss: 1.590946832651733

Epoch: 5| Step: 10
Training loss: 0.28018665313720703
Validation loss: 1.5795414704148487

Epoch: 476| Step: 0
Training loss: 0.264759361743927
Validation loss: 1.5633044665859592

Epoch: 5| Step: 1
Training loss: 0.18749840557575226
Validation loss: 1.5225499259528292

Epoch: 5| Step: 2
Training loss: 0.14623944461345673
Validation loss: 1.5001718856955086

Epoch: 5| Step: 3
Training loss: 0.12493611872196198
Validation loss: 1.462409180979575

Epoch: 5| Step: 4
Training loss: 0.45044055581092834
Validation loss: 1.4837264566011326

Epoch: 5| Step: 5
Training loss: 0.24312682449817657
Validation loss: 1.464078200760708

Epoch: 5| Step: 6
Training loss: 0.24802961945533752
Validation loss: 1.4584129010477374

Epoch: 5| Step: 7
Training loss: 0.1837560385465622
Validation loss: 1.4441335124354209

Epoch: 5| Step: 8
Training loss: 0.18897190690040588
Validation loss: 1.4515168077202254

Epoch: 5| Step: 9
Training loss: 0.23411794006824493
Validation loss: 1.4920086847838534

Epoch: 5| Step: 10
Training loss: 0.20126873254776
Validation loss: 1.4853299894640524

Epoch: 477| Step: 0
Training loss: 0.33783334493637085
Validation loss: 1.5126577077373382

Epoch: 5| Step: 1
Training loss: 0.10442721843719482
Validation loss: 1.483051037275663

Epoch: 5| Step: 2
Training loss: 0.21824948489665985
Validation loss: 1.5228843201873123

Epoch: 5| Step: 3
Training loss: 0.17765295505523682
Validation loss: 1.519823323013962

Epoch: 5| Step: 4
Training loss: 0.22728247940540314
Validation loss: 1.4973539921545214

Epoch: 5| Step: 5
Training loss: 0.22057123482227325
Validation loss: 1.4861673167956773

Epoch: 5| Step: 6
Training loss: 0.2760681211948395
Validation loss: 1.4858641111722557

Epoch: 5| Step: 7
Training loss: 0.19150760769844055
Validation loss: 1.4842989547278291

Epoch: 5| Step: 8
Training loss: 0.22061161696910858
Validation loss: 1.499287457876308

Epoch: 5| Step: 9
Training loss: 0.2556532621383667
Validation loss: 1.4894009187657347

Epoch: 5| Step: 10
Training loss: 0.1775955706834793
Validation loss: 1.4798259312106716

Epoch: 478| Step: 0
Training loss: 0.1411542445421219
Validation loss: 1.5063936659084853

Epoch: 5| Step: 1
Training loss: 0.2106766253709793
Validation loss: 1.5316320068092757

Epoch: 5| Step: 2
Training loss: 0.361837238073349
Validation loss: 1.5113072702961583

Epoch: 5| Step: 3
Training loss: 0.25359398126602173
Validation loss: 1.5241665391511814

Epoch: 5| Step: 4
Training loss: 0.19340194761753082
Validation loss: 1.5196057852878366

Epoch: 5| Step: 5
Training loss: 0.17260131239891052
Validation loss: 1.5133402187337157

Epoch: 5| Step: 6
Training loss: 0.12529557943344116
Validation loss: 1.4912008752105057

Epoch: 5| Step: 7
Training loss: 0.18161018192768097
Validation loss: 1.5191119191467122

Epoch: 5| Step: 8
Training loss: 0.2973160147666931
Validation loss: 1.5088743855876308

Epoch: 5| Step: 9
Training loss: 0.16714894771575928
Validation loss: 1.5058719278663717

Epoch: 5| Step: 10
Training loss: 0.11146922409534454
Validation loss: 1.5159519897994174

Epoch: 479| Step: 0
Training loss: 0.15799188613891602
Validation loss: 1.5183726728603404

Epoch: 5| Step: 1
Training loss: 0.13587038218975067
Validation loss: 1.5389252144803283

Epoch: 5| Step: 2
Training loss: 0.19322475790977478
Validation loss: 1.5127266696704331

Epoch: 5| Step: 3
Training loss: 0.25906628370285034
Validation loss: 1.5151893528558875

Epoch: 5| Step: 4
Training loss: 0.20791220664978027
Validation loss: 1.4937048637738792

Epoch: 5| Step: 5
Training loss: 0.2416648417711258
Validation loss: 1.4893937142946387

Epoch: 5| Step: 6
Training loss: 0.08050358295440674
Validation loss: 1.4669305034863052

Epoch: 5| Step: 7
Training loss: 0.19475413858890533
Validation loss: 1.5014207824583976

Epoch: 5| Step: 8
Training loss: 0.22044865787029266
Validation loss: 1.5035079871454546

Epoch: 5| Step: 9
Training loss: 0.13216671347618103
Validation loss: 1.5009402953168398

Epoch: 5| Step: 10
Training loss: 0.2857407331466675
Validation loss: 1.5024422727605349

Epoch: 480| Step: 0
Training loss: 0.12238013744354248
Validation loss: 1.5207252207622732

Epoch: 5| Step: 1
Training loss: 0.23635125160217285
Validation loss: 1.5042082135395338

Epoch: 5| Step: 2
Training loss: 0.15064117312431335
Validation loss: 1.5390960977923485

Epoch: 5| Step: 3
Training loss: 0.19491873681545258
Validation loss: 1.5278618854861106

Epoch: 5| Step: 4
Training loss: 0.18847814202308655
Validation loss: 1.516871416440574

Epoch: 5| Step: 5
Training loss: 0.33463266491889954
Validation loss: 1.5216969354178316

Epoch: 5| Step: 6
Training loss: 0.18427897989749908
Validation loss: 1.4957906584585867

Epoch: 5| Step: 7
Training loss: 0.1387639343738556
Validation loss: 1.499382721480503

Epoch: 5| Step: 8
Training loss: 0.19103756546974182
Validation loss: 1.4869236856378534

Epoch: 5| Step: 9
Training loss: 0.1631886065006256
Validation loss: 1.4877031798003821

Epoch: 5| Step: 10
Training loss: 0.18156874179840088
Validation loss: 1.4776912043171544

Epoch: 481| Step: 0
Training loss: 0.1677210032939911
Validation loss: 1.4992476278735745

Epoch: 5| Step: 1
Training loss: 0.10921882092952728
Validation loss: 1.5142582667771207

Epoch: 5| Step: 2
Training loss: 0.17159144580364227
Validation loss: 1.501998007938426

Epoch: 5| Step: 3
Training loss: 0.14919866621494293
Validation loss: 1.5012336918102798

Epoch: 5| Step: 4
Training loss: 0.1477208435535431
Validation loss: 1.5229027168725127

Epoch: 5| Step: 5
Training loss: 0.13511021435260773
Validation loss: 1.4868659550143826

Epoch: 5| Step: 6
Training loss: 0.127018004655838
Validation loss: 1.4896523132119128

Epoch: 5| Step: 7
Training loss: 0.17536033689975739
Validation loss: 1.4902657129431283

Epoch: 5| Step: 8
Training loss: 0.24847204983234406
Validation loss: 1.5079782964080892

Epoch: 5| Step: 9
Training loss: 0.24818375706672668
Validation loss: 1.501097225373791

Epoch: 5| Step: 10
Training loss: 0.3621656894683838
Validation loss: 1.4816638641459967

Epoch: 482| Step: 0
Training loss: 0.147191122174263
Validation loss: 1.507508998276085

Epoch: 5| Step: 1
Training loss: 0.1372305005788803
Validation loss: 1.518359100946816

Epoch: 5| Step: 2
Training loss: 0.14800730347633362
Validation loss: 1.5186136025254444

Epoch: 5| Step: 3
Training loss: 0.15430404245853424
Validation loss: 1.5066027795114825

Epoch: 5| Step: 4
Training loss: 0.1619531810283661
Validation loss: 1.5116986984847693

Epoch: 5| Step: 5
Training loss: 0.21216300129890442
Validation loss: 1.5434901368233465

Epoch: 5| Step: 6
Training loss: 0.11353851854801178
Validation loss: 1.5317811478850663

Epoch: 5| Step: 7
Training loss: 0.20590439438819885
Validation loss: 1.5270783965305617

Epoch: 5| Step: 8
Training loss: 0.2037055492401123
Validation loss: 1.52678305743843

Epoch: 5| Step: 9
Training loss: 0.3370897173881531
Validation loss: 1.5622560824117353

Epoch: 5| Step: 10
Training loss: 0.2574135363101959
Validation loss: 1.5378194771787173

Epoch: 483| Step: 0
Training loss: 0.14861170947551727
Validation loss: 1.5675130813352522

Epoch: 5| Step: 1
Training loss: 0.20203259587287903
Validation loss: 1.5651647185766568

Epoch: 5| Step: 2
Training loss: 0.11621826887130737
Validation loss: 1.5501508969132618

Epoch: 5| Step: 3
Training loss: 0.13185063004493713
Validation loss: 1.517298157497119

Epoch: 5| Step: 4
Training loss: 0.24704229831695557
Validation loss: 1.4903481775714504

Epoch: 5| Step: 5
Training loss: 0.17836248874664307
Validation loss: 1.5158654464188444

Epoch: 5| Step: 6
Training loss: 0.20157170295715332
Validation loss: 1.501899862802157

Epoch: 5| Step: 7
Training loss: 0.23034462332725525
Validation loss: 1.4639228223472514

Epoch: 5| Step: 8
Training loss: 0.21095983684062958
Validation loss: 1.4784304044579948

Epoch: 5| Step: 9
Training loss: 0.14635518193244934
Validation loss: 1.4559517592512152

Epoch: 5| Step: 10
Training loss: 0.3560110628604889
Validation loss: 1.4539321378995014

Epoch: 484| Step: 0
Training loss: 0.1558951437473297
Validation loss: 1.4685356193973171

Epoch: 5| Step: 1
Training loss: 0.2645406126976013
Validation loss: 1.48494892351089

Epoch: 5| Step: 2
Training loss: 0.19330373406410217
Validation loss: 1.5038892248625397

Epoch: 5| Step: 3
Training loss: 0.18765513598918915
Validation loss: 1.4885889176399476

Epoch: 5| Step: 4
Training loss: 0.10177457332611084
Validation loss: 1.4966453967555877

Epoch: 5| Step: 5
Training loss: 0.2469651699066162
Validation loss: 1.497855979909179

Epoch: 5| Step: 6
Training loss: 0.20364519953727722
Validation loss: 1.5223651457858343

Epoch: 5| Step: 7
Training loss: 0.1480478197336197
Validation loss: 1.5582454601923625

Epoch: 5| Step: 8
Training loss: 0.08919064700603485
Validation loss: 1.524433102659

Epoch: 5| Step: 9
Training loss: 0.2701476216316223
Validation loss: 1.5228956117424914

Epoch: 5| Step: 10
Training loss: 0.2101823389530182
Validation loss: 1.5443883788201116

Epoch: 485| Step: 0
Training loss: 0.12207317352294922
Validation loss: 1.5255553504472137

Epoch: 5| Step: 1
Training loss: 0.12891681492328644
Validation loss: 1.5289827905675417

Epoch: 5| Step: 2
Training loss: 0.18577858805656433
Validation loss: 1.5179399469847321

Epoch: 5| Step: 3
Training loss: 0.1351838856935501
Validation loss: 1.5212045920792447

Epoch: 5| Step: 4
Training loss: 0.28349679708480835
Validation loss: 1.5222813929280927

Epoch: 5| Step: 5
Training loss: 0.11787140369415283
Validation loss: 1.527782073584936

Epoch: 5| Step: 6
Training loss: 0.24500592052936554
Validation loss: 1.5057568447564238

Epoch: 5| Step: 7
Training loss: 0.23331817984580994
Validation loss: 1.4944574666279618

Epoch: 5| Step: 8
Training loss: 0.13606573641300201
Validation loss: 1.484452296328801

Epoch: 5| Step: 9
Training loss: 0.09129422158002853
Validation loss: 1.4814074834187825

Epoch: 5| Step: 10
Training loss: 0.23058468103408813
Validation loss: 1.4757708503353981

Epoch: 486| Step: 0
Training loss: 0.16791854798793793
Validation loss: 1.4729595389417423

Epoch: 5| Step: 1
Training loss: 0.12641499936580658
Validation loss: 1.497420326355965

Epoch: 5| Step: 2
Training loss: 0.15344974398612976
Validation loss: 1.4970775970848658

Epoch: 5| Step: 3
Training loss: 0.13459189236164093
Validation loss: 1.5056299471086072

Epoch: 5| Step: 4
Training loss: 0.1607944369316101
Validation loss: 1.4961686070247362

Epoch: 5| Step: 5
Training loss: 0.15440399944782257
Validation loss: 1.4951615384829942

Epoch: 5| Step: 6
Training loss: 0.10600824654102325
Validation loss: 1.5201589426686686

Epoch: 5| Step: 7
Training loss: 0.18656696379184723
Validation loss: 1.4967028863968388

Epoch: 5| Step: 8
Training loss: 0.13879165053367615
Validation loss: 1.494001038612858

Epoch: 5| Step: 9
Training loss: 0.3730843961238861
Validation loss: 1.4900443989743468

Epoch: 5| Step: 10
Training loss: 0.1819486767053604
Validation loss: 1.4878737093299947

Epoch: 487| Step: 0
Training loss: 0.1450708657503128
Validation loss: 1.4787893936198244

Epoch: 5| Step: 1
Training loss: 0.14625997841358185
Validation loss: 1.485904296239217

Epoch: 5| Step: 2
Training loss: 0.20027604699134827
Validation loss: 1.4870202413169287

Epoch: 5| Step: 3
Training loss: 0.14547309279441833
Validation loss: 1.5113753016277025

Epoch: 5| Step: 4
Training loss: 0.2405131608247757
Validation loss: 1.5332349948985602

Epoch: 5| Step: 5
Training loss: 0.11555004119873047
Validation loss: 1.5068136902265652

Epoch: 5| Step: 6
Training loss: 0.14204475283622742
Validation loss: 1.4804183103704964

Epoch: 5| Step: 7
Training loss: 0.13794663548469543
Validation loss: 1.491697439583399

Epoch: 5| Step: 8
Training loss: 0.13336750864982605
Validation loss: 1.5016293346240956

Epoch: 5| Step: 9
Training loss: 0.08555275201797485
Validation loss: 1.496271808301249

Epoch: 5| Step: 10
Training loss: 0.33145439624786377
Validation loss: 1.514701384370045

Epoch: 488| Step: 0
Training loss: 0.2045501172542572
Validation loss: 1.4890279577624412

Epoch: 5| Step: 1
Training loss: 0.15054413676261902
Validation loss: 1.4885256546799854

Epoch: 5| Step: 2
Training loss: 0.14294707775115967
Validation loss: 1.4998980619574105

Epoch: 5| Step: 3
Training loss: 0.15506413578987122
Validation loss: 1.473641389159746

Epoch: 5| Step: 4
Training loss: 0.09850533306598663
Validation loss: 1.4758438269297283

Epoch: 5| Step: 5
Training loss: 0.286329448223114
Validation loss: 1.4896710495794974

Epoch: 5| Step: 6
Training loss: 0.16195769608020782
Validation loss: 1.499218770252761

Epoch: 5| Step: 7
Training loss: 0.13606882095336914
Validation loss: 1.511716999674356

Epoch: 5| Step: 8
Training loss: 0.16373023390769958
Validation loss: 1.529240615906254

Epoch: 5| Step: 9
Training loss: 0.19176805019378662
Validation loss: 1.5016462238886024

Epoch: 5| Step: 10
Training loss: 0.12752573192119598
Validation loss: 1.5423982374129757

Epoch: 489| Step: 0
Training loss: 0.15864892303943634
Validation loss: 1.5086263584834274

Epoch: 5| Step: 1
Training loss: 0.1441059410572052
Validation loss: 1.4932214290865007

Epoch: 5| Step: 2
Training loss: 0.24866752326488495
Validation loss: 1.4714294325920843

Epoch: 5| Step: 3
Training loss: 0.15911927819252014
Validation loss: 1.452029296146926

Epoch: 5| Step: 4
Training loss: 0.17313635349273682
Validation loss: 1.450325785144683

Epoch: 5| Step: 5
Training loss: 0.14520956575870514
Validation loss: 1.4151753097452142

Epoch: 5| Step: 6
Training loss: 0.22858774662017822
Validation loss: 1.4273360339544152

Epoch: 5| Step: 7
Training loss: 0.11036767065525055
Validation loss: 1.430820697097368

Epoch: 5| Step: 8
Training loss: 0.1823781430721283
Validation loss: 1.4591016628408944

Epoch: 5| Step: 9
Training loss: 0.23436859250068665
Validation loss: 1.4460308090333016

Epoch: 5| Step: 10
Training loss: 0.17498540878295898
Validation loss: 1.463769417937084

Epoch: 490| Step: 0
Training loss: 0.22696399688720703
Validation loss: 1.4962027393361574

Epoch: 5| Step: 1
Training loss: 0.20471520721912384
Validation loss: 1.5077201653552312

Epoch: 5| Step: 2
Training loss: 0.15651237964630127
Validation loss: 1.4720347978735482

Epoch: 5| Step: 3
Training loss: 0.14563335478305817
Validation loss: 1.49221642427547

Epoch: 5| Step: 4
Training loss: 0.35368767380714417
Validation loss: 1.4713654018217517

Epoch: 5| Step: 5
Training loss: 0.16931255161762238
Validation loss: 1.4623895947651198

Epoch: 5| Step: 6
Training loss: 0.10934928804636002
Validation loss: 1.4494179564137613

Epoch: 5| Step: 7
Training loss: 0.17997875809669495
Validation loss: 1.4591440577660837

Epoch: 5| Step: 8
Training loss: 0.08336268365383148
Validation loss: 1.4338799958587976

Epoch: 5| Step: 9
Training loss: 0.11309752613306046
Validation loss: 1.4540248141493848

Epoch: 5| Step: 10
Training loss: 0.24932505190372467
Validation loss: 1.46394774734333

Epoch: 491| Step: 0
Training loss: 0.1956387162208557
Validation loss: 1.4518895995232366

Epoch: 5| Step: 1
Training loss: 0.12607188522815704
Validation loss: 1.473790375135278

Epoch: 5| Step: 2
Training loss: 0.1745554357767105
Validation loss: 1.4808835585912068

Epoch: 5| Step: 3
Training loss: 0.1622219979763031
Validation loss: 1.496848105102457

Epoch: 5| Step: 4
Training loss: 0.16212132573127747
Validation loss: 1.5070418632158669

Epoch: 5| Step: 5
Training loss: 0.14846782386302948
Validation loss: 1.5256357872357933

Epoch: 5| Step: 6
Training loss: 0.07338075339794159
Validation loss: 1.486793755203165

Epoch: 5| Step: 7
Training loss: 0.2079150378704071
Validation loss: 1.5053452137977845

Epoch: 5| Step: 8
Training loss: 0.2901310920715332
Validation loss: 1.4830562568479968

Epoch: 5| Step: 9
Training loss: 0.12482915818691254
Validation loss: 1.4938625238275016

Epoch: 5| Step: 10
Training loss: 0.1484326422214508
Validation loss: 1.481033311095289

Epoch: 492| Step: 0
Training loss: 0.1079924926161766
Validation loss: 1.4749871338567426

Epoch: 5| Step: 1
Training loss: 0.19133248925209045
Validation loss: 1.4917233105628722

Epoch: 5| Step: 2
Training loss: 0.15115506947040558
Validation loss: 1.4815557182476085

Epoch: 5| Step: 3
Training loss: 0.34174126386642456
Validation loss: 1.4845713787181403

Epoch: 5| Step: 4
Training loss: 0.18401964008808136
Validation loss: 1.491000606167701

Epoch: 5| Step: 5
Training loss: 0.1542728692293167
Validation loss: 1.4596087778768232

Epoch: 5| Step: 6
Training loss: 0.17254027724266052
Validation loss: 1.4887508692279938

Epoch: 5| Step: 7
Training loss: 0.11874540895223618
Validation loss: 1.4854639076417493

Epoch: 5| Step: 8
Training loss: 0.22335544228553772
Validation loss: 1.480459855448815

Epoch: 5| Step: 9
Training loss: 0.1758209615945816
Validation loss: 1.511506547210037

Epoch: 5| Step: 10
Training loss: 0.13433220982551575
Validation loss: 1.4928312724636448

Epoch: 493| Step: 0
Training loss: 0.07039555162191391
Validation loss: 1.4892804661104757

Epoch: 5| Step: 1
Training loss: 0.13946178555488586
Validation loss: 1.490545303590836

Epoch: 5| Step: 2
Training loss: 0.08986818045377731
Validation loss: 1.5020535261400285

Epoch: 5| Step: 3
Training loss: 0.09502960741519928
Validation loss: 1.4970275484105593

Epoch: 5| Step: 4
Training loss: 0.13192591071128845
Validation loss: 1.5116706868653655

Epoch: 5| Step: 5
Training loss: 0.26161476969718933
Validation loss: 1.4822043244556715

Epoch: 5| Step: 6
Training loss: 0.23036818206310272
Validation loss: 1.4908161676058205

Epoch: 5| Step: 7
Training loss: 0.16842293739318848
Validation loss: 1.463518109372867

Epoch: 5| Step: 8
Training loss: 0.3440159857273102
Validation loss: 1.4653605863612185

Epoch: 5| Step: 9
Training loss: 0.20285208523273468
Validation loss: 1.4754406521397252

Epoch: 5| Step: 10
Training loss: 0.10982857644557953
Validation loss: 1.4498617982351651

Epoch: 494| Step: 0
Training loss: 0.22272832691669464
Validation loss: 1.4844815731048584

Epoch: 5| Step: 1
Training loss: 0.10680238902568817
Validation loss: 1.4786039962563464

Epoch: 5| Step: 2
Training loss: 0.20409326255321503
Validation loss: 1.4945436510988461

Epoch: 5| Step: 3
Training loss: 0.1526513397693634
Validation loss: 1.505708094566099

Epoch: 5| Step: 4
Training loss: 0.11852079629898071
Validation loss: 1.5166471953033118

Epoch: 5| Step: 5
Training loss: 0.13762924075126648
Validation loss: 1.4874099685299782

Epoch: 5| Step: 6
Training loss: 0.10202749073505402
Validation loss: 1.4573449511681833

Epoch: 5| Step: 7
Training loss: 0.1288493573665619
Validation loss: 1.4512885052670714

Epoch: 5| Step: 8
Training loss: 0.21461749076843262
Validation loss: 1.4686834632709462

Epoch: 5| Step: 9
Training loss: 0.21727971732616425
Validation loss: 1.4625725861518615

Epoch: 5| Step: 10
Training loss: 0.1822207123041153
Validation loss: 1.4651776436836488

Epoch: 495| Step: 0
Training loss: 0.09399458765983582
Validation loss: 1.467879177421652

Epoch: 5| Step: 1
Training loss: 0.18295836448669434
Validation loss: 1.4705311726498347

Epoch: 5| Step: 2
Training loss: 0.15460556745529175
Validation loss: 1.4766824014725224

Epoch: 5| Step: 3
Training loss: 0.2514336109161377
Validation loss: 1.467493341815087

Epoch: 5| Step: 4
Training loss: 0.14113320410251617
Validation loss: 1.457807566529961

Epoch: 5| Step: 5
Training loss: 0.11747229099273682
Validation loss: 1.4742630822684175

Epoch: 5| Step: 6
Training loss: 0.16525468230247498
Validation loss: 1.4914455965001097

Epoch: 5| Step: 7
Training loss: 0.15580064058303833
Validation loss: 1.472712262984245

Epoch: 5| Step: 8
Training loss: 0.3217850923538208
Validation loss: 1.4873912526715187

Epoch: 5| Step: 9
Training loss: 0.0980197861790657
Validation loss: 1.4820885812082598

Epoch: 5| Step: 10
Training loss: 0.09287279099225998
Validation loss: 1.4806556124841013

Epoch: 496| Step: 0
Training loss: 0.06371113657951355
Validation loss: 1.4755322164104832

Epoch: 5| Step: 1
Training loss: 0.21581606566905975
Validation loss: 1.4770510401777042

Epoch: 5| Step: 2
Training loss: 0.1027894988656044
Validation loss: 1.45832654224929

Epoch: 5| Step: 3
Training loss: 0.11666029691696167
Validation loss: 1.492295543352763

Epoch: 5| Step: 4
Training loss: 0.263970285654068
Validation loss: 1.480133894951113

Epoch: 5| Step: 5
Training loss: 0.09619063138961792
Validation loss: 1.4937075209873978

Epoch: 5| Step: 6
Training loss: 0.19070963561534882
Validation loss: 1.4731755743744552

Epoch: 5| Step: 7
Training loss: 0.23507902026176453
Validation loss: 1.4677393077522196

Epoch: 5| Step: 8
Training loss: 0.1309659630060196
Validation loss: 1.4734935914316485

Epoch: 5| Step: 9
Training loss: 0.19185253977775574
Validation loss: 1.4684521767400927

Epoch: 5| Step: 10
Training loss: 0.12142596393823624
Validation loss: 1.466892861550854

Epoch: 497| Step: 0
Training loss: 0.28987160325050354
Validation loss: 1.4678321064159434

Epoch: 5| Step: 1
Training loss: 0.17938902974128723
Validation loss: 1.4464233177964405

Epoch: 5| Step: 2
Training loss: 0.13195472955703735
Validation loss: 1.4597531095627816

Epoch: 5| Step: 3
Training loss: 0.12591378390789032
Validation loss: 1.4899164656157136

Epoch: 5| Step: 4
Training loss: 0.14730127155780792
Validation loss: 1.4746743248355003

Epoch: 5| Step: 5
Training loss: 0.2410663664340973
Validation loss: 1.5069939333905455

Epoch: 5| Step: 6
Training loss: 0.14067068696022034
Validation loss: 1.4749033028079617

Epoch: 5| Step: 7
Training loss: 0.15074202418327332
Validation loss: 1.508853930299

Epoch: 5| Step: 8
Training loss: 0.13939550518989563
Validation loss: 1.5048927312256188

Epoch: 5| Step: 9
Training loss: 0.06567437201738358
Validation loss: 1.4771684113369192

Epoch: 5| Step: 10
Training loss: 0.14046256244182587
Validation loss: 1.4840098029823714

Epoch: 498| Step: 0
Training loss: 0.11339066177606583
Validation loss: 1.4979732357045656

Epoch: 5| Step: 1
Training loss: 0.1599331796169281
Validation loss: 1.489340252773736

Epoch: 5| Step: 2
Training loss: 0.09486380964517593
Validation loss: 1.4702714079169816

Epoch: 5| Step: 3
Training loss: 0.1565762460231781
Validation loss: 1.480794757925054

Epoch: 5| Step: 4
Training loss: 0.08659432083368301
Validation loss: 1.4727315941164572

Epoch: 5| Step: 5
Training loss: 0.20208780467510223
Validation loss: 1.478791722687342

Epoch: 5| Step: 6
Training loss: 0.11856099218130112
Validation loss: 1.4797650075727893

Epoch: 5| Step: 7
Training loss: 0.14015427231788635
Validation loss: 1.49745620963394

Epoch: 5| Step: 8
Training loss: 0.18659834563732147
Validation loss: 1.456177032122048

Epoch: 5| Step: 9
Training loss: 0.1623358428478241
Validation loss: 1.4940134158698462

Epoch: 5| Step: 10
Training loss: 0.2779867947101593
Validation loss: 1.459801257297557

Epoch: 499| Step: 0
Training loss: 0.11497888714075089
Validation loss: 1.4830353119040047

Epoch: 5| Step: 1
Training loss: 0.07578185945749283
Validation loss: 1.4753650029500325

Epoch: 5| Step: 2
Training loss: 0.23158541321754456
Validation loss: 1.4763830246463898

Epoch: 5| Step: 3
Training loss: 0.14178650081157684
Validation loss: 1.4704048941212315

Epoch: 5| Step: 4
Training loss: 0.12804409861564636
Validation loss: 1.4410127503897554

Epoch: 5| Step: 5
Training loss: 0.10443127155303955
Validation loss: 1.4588682728428994

Epoch: 5| Step: 6
Training loss: 0.1258879154920578
Validation loss: 1.4477568185457619

Epoch: 5| Step: 7
Training loss: 0.3533558249473572
Validation loss: 1.4665642258941487

Epoch: 5| Step: 8
Training loss: 0.17898575961589813
Validation loss: 1.4833968788064935

Epoch: 5| Step: 9
Training loss: 0.20022054016590118
Validation loss: 1.4862598667862594

Epoch: 5| Step: 10
Training loss: 0.19139482080936432
Validation loss: 1.4816297433709587

Epoch: 500| Step: 0
Training loss: 0.2095119059085846
Validation loss: 1.4683080309180803

Epoch: 5| Step: 1
Training loss: 0.10181454569101334
Validation loss: 1.4810856901189333

Epoch: 5| Step: 2
Training loss: 0.12565001845359802
Validation loss: 1.5114797071744037

Epoch: 5| Step: 3
Training loss: 0.12144748866558075
Validation loss: 1.4734713262127292

Epoch: 5| Step: 4
Training loss: 0.15818552672863007
Validation loss: 1.4537503514238583

Epoch: 5| Step: 5
Training loss: 0.15729543566703796
Validation loss: 1.4729496573889127

Epoch: 5| Step: 6
Training loss: 0.11678687483072281
Validation loss: 1.4664230330656933

Epoch: 5| Step: 7
Training loss: 0.2312326431274414
Validation loss: 1.4753738295647405

Epoch: 5| Step: 8
Training loss: 0.08151193708181381
Validation loss: 1.4692583289197696

Epoch: 5| Step: 9
Training loss: 0.10405313968658447
Validation loss: 1.4708373777327999

Epoch: 5| Step: 10
Training loss: 0.3598332107067108
Validation loss: 1.4844811526677941

Epoch: 501| Step: 0
Training loss: 0.29815611243247986
Validation loss: 1.469033839882061

Epoch: 5| Step: 1
Training loss: 0.14464084804058075
Validation loss: 1.467556422115654

Epoch: 5| Step: 2
Training loss: 0.1473296731710434
Validation loss: 1.4716596231665662

Epoch: 5| Step: 3
Training loss: 0.16578982770442963
Validation loss: 1.4521748237712409

Epoch: 5| Step: 4
Training loss: 0.12012996524572372
Validation loss: 1.4632516958380257

Epoch: 5| Step: 5
Training loss: 0.22298431396484375
Validation loss: 1.4674641701482958

Epoch: 5| Step: 6
Training loss: 0.17130687832832336
Validation loss: 1.4663729103662635

Epoch: 5| Step: 7
Training loss: 0.11829469352960587
Validation loss: 1.4424343685950003

Epoch: 5| Step: 8
Training loss: 0.1790820062160492
Validation loss: 1.4639559843206917

Epoch: 5| Step: 9
Training loss: 0.14869169890880585
Validation loss: 1.4723121158538326

Epoch: 5| Step: 10
Training loss: 0.1451183259487152
Validation loss: 1.4885942769306961

Epoch: 502| Step: 0
Training loss: 0.2211446315050125
Validation loss: 1.481549169427605

Epoch: 5| Step: 1
Training loss: 0.1771080046892166
Validation loss: 1.5048779358146012

Epoch: 5| Step: 2
Training loss: 0.17067447304725647
Validation loss: 1.4519711002226798

Epoch: 5| Step: 3
Training loss: 0.17667439579963684
Validation loss: 1.466132636993162

Epoch: 5| Step: 4
Training loss: 0.11123062670230865
Validation loss: 1.505247063534234

Epoch: 5| Step: 5
Training loss: 0.22591981291770935
Validation loss: 1.495397690803774

Epoch: 5| Step: 6
Training loss: 0.22867079079151154
Validation loss: 1.4711254963310816

Epoch: 5| Step: 7
Training loss: 0.1355222463607788
Validation loss: 1.4824749244156705

Epoch: 5| Step: 8
Training loss: 0.12654578685760498
Validation loss: 1.4839571663128432

Epoch: 5| Step: 9
Training loss: 0.1338653564453125
Validation loss: 1.4646264500515436

Epoch: 5| Step: 10
Training loss: 0.10942231118679047
Validation loss: 1.477343415701261

Epoch: 503| Step: 0
Training loss: 0.15351387858390808
Validation loss: 1.4663160859897573

Epoch: 5| Step: 1
Training loss: 0.1346302032470703
Validation loss: 1.4855306725348196

Epoch: 5| Step: 2
Training loss: 0.09024660289287567
Validation loss: 1.4493570545668244

Epoch: 5| Step: 3
Training loss: 0.19091284275054932
Validation loss: 1.4538570078470374

Epoch: 5| Step: 4
Training loss: 0.17961135506629944
Validation loss: 1.4355397570517756

Epoch: 5| Step: 5
Training loss: 0.0916164368391037
Validation loss: 1.457122310515373

Epoch: 5| Step: 6
Training loss: 0.06704850494861603
Validation loss: 1.4585011979585052

Epoch: 5| Step: 7
Training loss: 0.21455688774585724
Validation loss: 1.456660637291529

Epoch: 5| Step: 8
Training loss: 0.12695643305778503
Validation loss: 1.4715324140364123

Epoch: 5| Step: 9
Training loss: 0.3068825900554657
Validation loss: 1.467478999527552

Epoch: 5| Step: 10
Training loss: 0.13406062126159668
Validation loss: 1.5061643418445383

Epoch: 504| Step: 0
Training loss: 0.1060558557510376
Validation loss: 1.4987188859652447

Epoch: 5| Step: 1
Training loss: 0.14462688565254211
Validation loss: 1.477685869380992

Epoch: 5| Step: 2
Training loss: 0.2318766564130783
Validation loss: 1.490710126456394

Epoch: 5| Step: 3
Training loss: 0.07482387125492096
Validation loss: 1.4534518526446434

Epoch: 5| Step: 4
Training loss: 0.2159866988658905
Validation loss: 1.4803311594070927

Epoch: 5| Step: 5
Training loss: 0.18420708179473877
Validation loss: 1.4800491986736175

Epoch: 5| Step: 6
Training loss: 0.285617858171463
Validation loss: 1.461074258691521

Epoch: 5| Step: 7
Training loss: 0.14357562363147736
Validation loss: 1.4783850241732854

Epoch: 5| Step: 8
Training loss: 0.21418142318725586
Validation loss: 1.4605228413817704

Epoch: 5| Step: 9
Training loss: 0.18316364288330078
Validation loss: 1.452372512509746

Epoch: 5| Step: 10
Training loss: 0.12523692846298218
Validation loss: 1.4755997145047752

Epoch: 505| Step: 0
Training loss: 0.2633221745491028
Validation loss: 1.4878016120644026

Epoch: 5| Step: 1
Training loss: 0.17578184604644775
Validation loss: 1.4977615071881203

Epoch: 5| Step: 2
Training loss: 0.0848885178565979
Validation loss: 1.4857238761840328

Epoch: 5| Step: 3
Training loss: 0.20679254829883575
Validation loss: 1.4688267105369157

Epoch: 5| Step: 4
Training loss: 0.18218258023262024
Validation loss: 1.4763152740334953

Epoch: 5| Step: 5
Training loss: 0.14706222712993622
Validation loss: 1.4764247639204866

Epoch: 5| Step: 6
Training loss: 0.1803446114063263
Validation loss: 1.4574743393928773

Epoch: 5| Step: 7
Training loss: 0.19263815879821777
Validation loss: 1.4678025207211893

Epoch: 5| Step: 8
Training loss: 0.14893749356269836
Validation loss: 1.4645177395113054

Epoch: 5| Step: 9
Training loss: 0.13757064938545227
Validation loss: 1.48293290856064

Epoch: 5| Step: 10
Training loss: 0.17091865837574005
Validation loss: 1.4948174838096864

Epoch: 506| Step: 0
Training loss: 0.13399624824523926
Validation loss: 1.488655718423987

Epoch: 5| Step: 1
Training loss: 0.12498517334461212
Validation loss: 1.4622519311084543

Epoch: 5| Step: 2
Training loss: 0.20231279730796814
Validation loss: 1.4899233425817182

Epoch: 5| Step: 3
Training loss: 0.26706060767173767
Validation loss: 1.4806723876665997

Epoch: 5| Step: 4
Training loss: 0.1534370481967926
Validation loss: 1.4643161066116825

Epoch: 5| Step: 5
Training loss: 0.08459697663784027
Validation loss: 1.4508271127618768

Epoch: 5| Step: 6
Training loss: 0.12957176566123962
Validation loss: 1.43881602825657

Epoch: 5| Step: 7
Training loss: 0.17625710368156433
Validation loss: 1.4452147253098027

Epoch: 5| Step: 8
Training loss: 0.1907641738653183
Validation loss: 1.4438632348532319

Epoch: 5| Step: 9
Training loss: 0.0665079802274704
Validation loss: 1.4928316506006385

Epoch: 5| Step: 10
Training loss: 0.15713946521282196
Validation loss: 1.4999543133602347

Epoch: 507| Step: 0
Training loss: 0.1535370796918869
Validation loss: 1.5230966139865179

Epoch: 5| Step: 1
Training loss: 0.23384876549243927
Validation loss: 1.5202164624326973

Epoch: 5| Step: 2
Training loss: 0.09821057319641113
Validation loss: 1.49245999961771

Epoch: 5| Step: 3
Training loss: 0.1305195838212967
Validation loss: 1.4877619743347168

Epoch: 5| Step: 4
Training loss: 0.20299763977527618
Validation loss: 1.5213865541642713

Epoch: 5| Step: 5
Training loss: 0.16614483296871185
Validation loss: 1.496477170657086

Epoch: 5| Step: 6
Training loss: 0.11500529944896698
Validation loss: 1.4967726815131404

Epoch: 5| Step: 7
Training loss: 0.1348726451396942
Validation loss: 1.4893403219920334

Epoch: 5| Step: 8
Training loss: 0.09127743542194366
Validation loss: 1.4887241907017206

Epoch: 5| Step: 9
Training loss: 0.07466679811477661
Validation loss: 1.4549885026870235

Epoch: 5| Step: 10
Training loss: 0.3195967376232147
Validation loss: 1.462124031077149

Epoch: 508| Step: 0
Training loss: 0.17590562999248505
Validation loss: 1.4547198780121342

Epoch: 5| Step: 1
Training loss: 0.1549280434846878
Validation loss: 1.4237442183238205

Epoch: 5| Step: 2
Training loss: 0.13323505222797394
Validation loss: 1.4376815172933763

Epoch: 5| Step: 3
Training loss: 0.11499083042144775
Validation loss: 1.4216952926369124

Epoch: 5| Step: 4
Training loss: 0.11901644617319107
Validation loss: 1.4283266202096017

Epoch: 5| Step: 5
Training loss: 0.08757095038890839
Validation loss: 1.4352051942579207

Epoch: 5| Step: 6
Training loss: 0.15758591890335083
Validation loss: 1.4825481791650095

Epoch: 5| Step: 7
Training loss: 0.23373070359230042
Validation loss: 1.439185187380801

Epoch: 5| Step: 8
Training loss: 0.18989188969135284
Validation loss: 1.448819625762201

Epoch: 5| Step: 9
Training loss: 0.19952592253684998
Validation loss: 1.4510833768434421

Epoch: 5| Step: 10
Training loss: 0.16704058647155762
Validation loss: 1.4457817180182344

Epoch: 509| Step: 0
Training loss: 0.11147812753915787
Validation loss: 1.4102287471935313

Epoch: 5| Step: 1
Training loss: 0.13167324662208557
Validation loss: 1.4212114849398214

Epoch: 5| Step: 2
Training loss: 0.2161058634519577
Validation loss: 1.4444864039779992

Epoch: 5| Step: 3
Training loss: 0.16521988809108734
Validation loss: 1.4572737319495088

Epoch: 5| Step: 4
Training loss: 0.21843819320201874
Validation loss: 1.4733123330659763

Epoch: 5| Step: 5
Training loss: 0.11347754299640656
Validation loss: 1.470459371484736

Epoch: 5| Step: 6
Training loss: 0.1457306295633316
Validation loss: 1.4697399985405706

Epoch: 5| Step: 7
Training loss: 0.059686560183763504
Validation loss: 1.4453484601871942

Epoch: 5| Step: 8
Training loss: 0.21108636260032654
Validation loss: 1.4400519171068746

Epoch: 5| Step: 9
Training loss: 0.09968779981136322
Validation loss: 1.468242370954124

Epoch: 5| Step: 10
Training loss: 0.1628400683403015
Validation loss: 1.472568070375791

Epoch: 510| Step: 0
Training loss: 0.15742799639701843
Validation loss: 1.4753744884203839

Epoch: 5| Step: 1
Training loss: 0.15815596282482147
Validation loss: 1.4760963224595594

Epoch: 5| Step: 2
Training loss: 0.14516958594322205
Validation loss: 1.4533763944461782

Epoch: 5| Step: 3
Training loss: 0.08928412944078445
Validation loss: 1.481127937634786

Epoch: 5| Step: 4
Training loss: 0.22388191521167755
Validation loss: 1.4757375832526916

Epoch: 5| Step: 5
Training loss: 0.15615741908550262
Validation loss: 1.4873996870492094

Epoch: 5| Step: 6
Training loss: 0.12880787253379822
Validation loss: 1.4375315327798166

Epoch: 5| Step: 7
Training loss: 0.26945263147354126
Validation loss: 1.4537661729320404

Epoch: 5| Step: 8
Training loss: 0.15414850413799286
Validation loss: 1.4386714491792905

Epoch: 5| Step: 9
Training loss: 0.22043640911579132
Validation loss: 1.4269522364421556

Epoch: 5| Step: 10
Training loss: 0.1613941341638565
Validation loss: 1.4057468278433687

Epoch: 511| Step: 0
Training loss: 0.31170544028282166
Validation loss: 1.4382772189314648

Epoch: 5| Step: 1
Training loss: 0.1732073277235031
Validation loss: 1.3908422813620618

Epoch: 5| Step: 2
Training loss: 0.12760667502880096
Validation loss: 1.4259650604699248

Epoch: 5| Step: 3
Training loss: 0.11646758019924164
Validation loss: 1.4456188396740985

Epoch: 5| Step: 4
Training loss: 0.20067858695983887
Validation loss: 1.479466094765612

Epoch: 5| Step: 5
Training loss: 0.08531837165355682
Validation loss: 1.4984938950948818

Epoch: 5| Step: 6
Training loss: 0.11426956951618195
Validation loss: 1.4800813787726945

Epoch: 5| Step: 7
Training loss: 0.1872534304857254
Validation loss: 1.5058786407593758

Epoch: 5| Step: 8
Training loss: 0.11108306795358658
Validation loss: 1.508040387143371

Epoch: 5| Step: 9
Training loss: 0.09794539958238602
Validation loss: 1.4820324092782953

Epoch: 5| Step: 10
Training loss: 0.13897861540317535
Validation loss: 1.4878381734253259

Epoch: 512| Step: 0
Training loss: 0.18361827731132507
Validation loss: 1.4787577397079879

Epoch: 5| Step: 1
Training loss: 0.14269617199897766
Validation loss: 1.4828096692280104

Epoch: 5| Step: 2
Training loss: 0.11486320197582245
Validation loss: 1.4637839101975965

Epoch: 5| Step: 3
Training loss: 0.21435299515724182
Validation loss: 1.4502083639944754

Epoch: 5| Step: 4
Training loss: 0.13223391771316528
Validation loss: 1.4588811859007804

Epoch: 5| Step: 5
Training loss: 0.22667470574378967
Validation loss: 1.4917390807982414

Epoch: 5| Step: 6
Training loss: 0.16239891946315765
Validation loss: 1.4964290408677952

Epoch: 5| Step: 7
Training loss: 0.20379996299743652
Validation loss: 1.4624324344819593

Epoch: 5| Step: 8
Training loss: 0.12770994007587433
Validation loss: 1.4498310435202815

Epoch: 5| Step: 9
Training loss: 0.08334164321422577
Validation loss: 1.5137123395037908

Epoch: 5| Step: 10
Training loss: 0.1965961456298828
Validation loss: 1.463915551862409

Epoch: 513| Step: 0
Training loss: 0.17801037430763245
Validation loss: 1.4568455808906144

Epoch: 5| Step: 1
Training loss: 0.11210504919290543
Validation loss: 1.452406103892993

Epoch: 5| Step: 2
Training loss: 0.19602593779563904
Validation loss: 1.4628051724485172

Epoch: 5| Step: 3
Training loss: 0.09742007404565811
Validation loss: 1.4396191566221175

Epoch: 5| Step: 4
Training loss: 0.1593155711889267
Validation loss: 1.4729837435548023

Epoch: 5| Step: 5
Training loss: 0.09695645421743393
Validation loss: 1.4683116353968138

Epoch: 5| Step: 6
Training loss: 0.13775396347045898
Validation loss: 1.4416993125792472

Epoch: 5| Step: 7
Training loss: 0.13429981470108032
Validation loss: 1.4467352564616869

Epoch: 5| Step: 8
Training loss: 0.12539765238761902
Validation loss: 1.4449726355973112

Epoch: 5| Step: 9
Training loss: 0.1606508493423462
Validation loss: 1.4277811909234652

Epoch: 5| Step: 10
Training loss: 0.22075900435447693
Validation loss: 1.4533495864560526

Epoch: 514| Step: 0
Training loss: 0.15867654979228973
Validation loss: 1.4957489531527284

Epoch: 5| Step: 1
Training loss: 0.09637586772441864
Validation loss: 1.4815825781514567

Epoch: 5| Step: 2
Training loss: 0.2651998698711395
Validation loss: 1.4789220133135397

Epoch: 5| Step: 3
Training loss: 0.1267278641462326
Validation loss: 1.488710743124767

Epoch: 5| Step: 4
Training loss: 0.11411042511463165
Validation loss: 1.476815899213155

Epoch: 5| Step: 5
Training loss: 0.24903646111488342
Validation loss: 1.477761835180303

Epoch: 5| Step: 6
Training loss: 0.142704039812088
Validation loss: 1.4753767175059165

Epoch: 5| Step: 7
Training loss: 0.08445826172828674
Validation loss: 1.4413348000536683

Epoch: 5| Step: 8
Training loss: 0.12857909500598907
Validation loss: 1.4516351479356007

Epoch: 5| Step: 9
Training loss: 0.09703406691551208
Validation loss: 1.4239907033981816

Epoch: 5| Step: 10
Training loss: 0.15011483430862427
Validation loss: 1.4420844495937388

Epoch: 515| Step: 0
Training loss: 0.22408552467823029
Validation loss: 1.4589158014584613

Epoch: 5| Step: 1
Training loss: 0.23516714572906494
Validation loss: 1.44011902552779

Epoch: 5| Step: 2
Training loss: 0.14618147909641266
Validation loss: 1.4643398472057876

Epoch: 5| Step: 3
Training loss: 0.1883780062198639
Validation loss: 1.4678336587003482

Epoch: 5| Step: 4
Training loss: 0.10478248447179794
Validation loss: 1.459878739490304

Epoch: 5| Step: 5
Training loss: 0.13899138569831848
Validation loss: 1.4483200657752253

Epoch: 5| Step: 6
Training loss: 0.11439521610736847
Validation loss: 1.4832233011081655

Epoch: 5| Step: 7
Training loss: 0.17999252676963806
Validation loss: 1.4559895364187097

Epoch: 5| Step: 8
Training loss: 0.1257699579000473
Validation loss: 1.4580811044221282

Epoch: 5| Step: 9
Training loss: 0.10778723657131195
Validation loss: 1.4677889866213645

Epoch: 5| Step: 10
Training loss: 0.12568919360637665
Validation loss: 1.5147556156240485

Epoch: 516| Step: 0
Training loss: 0.21949200332164764
Validation loss: 1.5113975437738563

Epoch: 5| Step: 1
Training loss: 0.16538405418395996
Validation loss: 1.4890883686721965

Epoch: 5| Step: 2
Training loss: 0.13111773133277893
Validation loss: 1.4590019333747126

Epoch: 5| Step: 3
Training loss: 0.16205936670303345
Validation loss: 1.471806695384364

Epoch: 5| Step: 4
Training loss: 0.09631093591451645
Validation loss: 1.444826651644963

Epoch: 5| Step: 5
Training loss: 0.13351662456989288
Validation loss: 1.4305094390787103

Epoch: 5| Step: 6
Training loss: 0.2467435598373413
Validation loss: 1.4396951942033664

Epoch: 5| Step: 7
Training loss: 0.16608992218971252
Validation loss: 1.4498373859672136

Epoch: 5| Step: 8
Training loss: 0.14518249034881592
Validation loss: 1.4411415207770564

Epoch: 5| Step: 9
Training loss: 0.14900588989257812
Validation loss: 1.451590807207169

Epoch: 5| Step: 10
Training loss: 0.16087496280670166
Validation loss: 1.4564619256604103

Epoch: 517| Step: 0
Training loss: 0.1782970130443573
Validation loss: 1.4851976645890104

Epoch: 5| Step: 1
Training loss: 0.1237892135977745
Validation loss: 1.4669431460800992

Epoch: 5| Step: 2
Training loss: 0.15781766176223755
Validation loss: 1.4533581913158458

Epoch: 5| Step: 3
Training loss: 0.1476476937532425
Validation loss: 1.4548956027594946

Epoch: 5| Step: 4
Training loss: 0.11929607391357422
Validation loss: 1.482660283324539

Epoch: 5| Step: 5
Training loss: 0.08433616161346436
Validation loss: 1.4513900382544405

Epoch: 5| Step: 6
Training loss: 0.28601503372192383
Validation loss: 1.4632058746071273

Epoch: 5| Step: 7
Training loss: 0.1636253297328949
Validation loss: 1.4650377547869118

Epoch: 5| Step: 8
Training loss: 0.12418843805789948
Validation loss: 1.463694857012841

Epoch: 5| Step: 9
Training loss: 0.07559380680322647
Validation loss: 1.459818592635534

Epoch: 5| Step: 10
Training loss: 0.08067891746759415
Validation loss: 1.4561803379366476

Epoch: 518| Step: 0
Training loss: 0.13031552731990814
Validation loss: 1.4552315794011599

Epoch: 5| Step: 1
Training loss: 0.2052466869354248
Validation loss: 1.4550085734295588

Epoch: 5| Step: 2
Training loss: 0.1959463506937027
Validation loss: 1.441679339255056

Epoch: 5| Step: 3
Training loss: 0.06726390868425369
Validation loss: 1.4231283280157274

Epoch: 5| Step: 4
Training loss: 0.1964389532804489
Validation loss: 1.4198652871193425

Epoch: 5| Step: 5
Training loss: 0.13987664878368378
Validation loss: 1.4501590933851016

Epoch: 5| Step: 6
Training loss: 0.12967385351657867
Validation loss: 1.4562854382299608

Epoch: 5| Step: 7
Training loss: 0.15593008697032928
Validation loss: 1.4481980210991316

Epoch: 5| Step: 8
Training loss: 0.1136358231306076
Validation loss: 1.4491410659205528

Epoch: 5| Step: 9
Training loss: 0.12215547263622284
Validation loss: 1.4566724813112648

Epoch: 5| Step: 10
Training loss: 0.0940893292427063
Validation loss: 1.469696835805011

Epoch: 519| Step: 0
Training loss: 0.09518890827894211
Validation loss: 1.4898537390975541

Epoch: 5| Step: 1
Training loss: 0.18416117131710052
Validation loss: 1.4506582816441853

Epoch: 5| Step: 2
Training loss: 0.06432007253170013
Validation loss: 1.4471582834438612

Epoch: 5| Step: 3
Training loss: 0.21961355209350586
Validation loss: 1.465815741528747

Epoch: 5| Step: 4
Training loss: 0.1590634286403656
Validation loss: 1.4756905084015222

Epoch: 5| Step: 5
Training loss: 0.08944424986839294
Validation loss: 1.4662596307775027

Epoch: 5| Step: 6
Training loss: 0.10423529148101807
Validation loss: 1.456474636190681

Epoch: 5| Step: 7
Training loss: 0.23916363716125488
Validation loss: 1.4564981742571759

Epoch: 5| Step: 8
Training loss: 0.1453019231557846
Validation loss: 1.4376882750500914

Epoch: 5| Step: 9
Training loss: 0.07790157198905945
Validation loss: 1.414732022952008

Epoch: 5| Step: 10
Training loss: 0.12830482423305511
Validation loss: 1.431749040080655

Epoch: 520| Step: 0
Training loss: 0.13061824440956116
Validation loss: 1.4788859774989467

Epoch: 5| Step: 1
Training loss: 0.10186703503131866
Validation loss: 1.4565996149534821

Epoch: 5| Step: 2
Training loss: 0.11274830996990204
Validation loss: 1.4323049488887991

Epoch: 5| Step: 3
Training loss: 0.36435002088546753
Validation loss: 1.4488996433955368

Epoch: 5| Step: 4
Training loss: 0.10240820795297623
Validation loss: 1.4688183985730654

Epoch: 5| Step: 5
Training loss: 0.07462520897388458
Validation loss: 1.4715863927718131

Epoch: 5| Step: 6
Training loss: 0.15304556488990784
Validation loss: 1.4837199923812703

Epoch: 5| Step: 7
Training loss: 0.11368201673030853
Validation loss: 1.46462328972355

Epoch: 5| Step: 8
Training loss: 0.16182652115821838
Validation loss: 1.4767069329497635

Epoch: 5| Step: 9
Training loss: 0.1283113956451416
Validation loss: 1.4557010396834342

Epoch: 5| Step: 10
Training loss: 0.11658401787281036
Validation loss: 1.4527427598994265

Epoch: 521| Step: 0
Training loss: 0.10041666030883789
Validation loss: 1.4677662029061267

Epoch: 5| Step: 1
Training loss: 0.08296093344688416
Validation loss: 1.436362192194949

Epoch: 5| Step: 2
Training loss: 0.1668037474155426
Validation loss: 1.4588888832317886

Epoch: 5| Step: 3
Training loss: 0.1612500101327896
Validation loss: 1.4264816430307203

Epoch: 5| Step: 4
Training loss: 0.18958915770053864
Validation loss: 1.4526590531872166

Epoch: 5| Step: 5
Training loss: 0.1350267231464386
Validation loss: 1.440104365348816

Epoch: 5| Step: 6
Training loss: 0.12246181815862656
Validation loss: 1.4365123112996419

Epoch: 5| Step: 7
Training loss: 0.21125152707099915
Validation loss: 1.455288794732863

Epoch: 5| Step: 8
Training loss: 0.16271476447582245
Validation loss: 1.4631275105220016

Epoch: 5| Step: 9
Training loss: 0.1638401299715042
Validation loss: 1.4878972614965131

Epoch: 5| Step: 10
Training loss: 0.10228884965181351
Validation loss: 1.539266792676782

Epoch: 522| Step: 0
Training loss: 0.24910330772399902
Validation loss: 1.537175073418566

Epoch: 5| Step: 1
Training loss: 0.16379351913928986
Validation loss: 1.5288921171619045

Epoch: 5| Step: 2
Training loss: 0.11458887904882431
Validation loss: 1.5335583802192443

Epoch: 5| Step: 3
Training loss: 0.11854211986064911
Validation loss: 1.5026176482118585

Epoch: 5| Step: 4
Training loss: 0.146072119474411
Validation loss: 1.490417545200676

Epoch: 5| Step: 5
Training loss: 0.12272417545318604
Validation loss: 1.4688900157969484

Epoch: 5| Step: 6
Training loss: 0.2497854232788086
Validation loss: 1.4910390966682023

Epoch: 5| Step: 7
Training loss: 0.0960671678185463
Validation loss: 1.4626800808855283

Epoch: 5| Step: 8
Training loss: 0.12001314014196396
Validation loss: 1.5061804068985807

Epoch: 5| Step: 9
Training loss: 0.2095077484846115
Validation loss: 1.4655715034854027

Epoch: 5| Step: 10
Training loss: 0.08275029808282852
Validation loss: 1.469614585240682

Epoch: 523| Step: 0
Training loss: 0.10802896320819855
Validation loss: 1.4616289984795354

Epoch: 5| Step: 1
Training loss: 0.08656022697687149
Validation loss: 1.4530318142265402

Epoch: 5| Step: 2
Training loss: 0.08993712067604065
Validation loss: 1.4824238746396956

Epoch: 5| Step: 3
Training loss: 0.11212079226970673
Validation loss: 1.4407793347553541

Epoch: 5| Step: 4
Training loss: 0.1295950710773468
Validation loss: 1.476039037909559

Epoch: 5| Step: 5
Training loss: 0.1086246594786644
Validation loss: 1.4942885073282386

Epoch: 5| Step: 6
Training loss: 0.13429096341133118
Validation loss: 1.5017572244008381

Epoch: 5| Step: 7
Training loss: 0.15695415437221527
Validation loss: 1.4947226688426027

Epoch: 5| Step: 8
Training loss: 0.12461906671524048
Validation loss: 1.506747567525474

Epoch: 5| Step: 9
Training loss: 0.11558900773525238
Validation loss: 1.490705249130085

Epoch: 5| Step: 10
Training loss: 0.3232515752315521
Validation loss: 1.5109613928743588

Epoch: 524| Step: 0
Training loss: 0.10127594321966171
Validation loss: 1.4857156443339523

Epoch: 5| Step: 1
Training loss: 0.1176203042268753
Validation loss: 1.4798280699278719

Epoch: 5| Step: 2
Training loss: 0.10645576566457748
Validation loss: 1.484628790168352

Epoch: 5| Step: 3
Training loss: 0.1387438327074051
Validation loss: 1.4700073901043142

Epoch: 5| Step: 4
Training loss: 0.14581477642059326
Validation loss: 1.4797008678477297

Epoch: 5| Step: 5
Training loss: 0.15921367704868317
Validation loss: 1.4911865982958066

Epoch: 5| Step: 6
Training loss: 0.19130972027778625
Validation loss: 1.4860828076639483

Epoch: 5| Step: 7
Training loss: 0.24842295050621033
Validation loss: 1.4870993334759948

Epoch: 5| Step: 8
Training loss: 0.11766047775745392
Validation loss: 1.5075727970369401

Epoch: 5| Step: 9
Training loss: 0.08926671743392944
Validation loss: 1.4875050437065862

Epoch: 5| Step: 10
Training loss: 0.0796574056148529
Validation loss: 1.4928332246759886

Epoch: 525| Step: 0
Training loss: 0.11987543106079102
Validation loss: 1.4967476232077486

Epoch: 5| Step: 1
Training loss: 0.12811565399169922
Validation loss: 1.4806191075232722

Epoch: 5| Step: 2
Training loss: 0.06630180776119232
Validation loss: 1.483724380052218

Epoch: 5| Step: 3
Training loss: 0.09471974521875381
Validation loss: 1.4869938037728752

Epoch: 5| Step: 4
Training loss: 0.19901446998119354
Validation loss: 1.4790564890830749

Epoch: 5| Step: 5
Training loss: 0.20894911885261536
Validation loss: 1.4769542217254639

Epoch: 5| Step: 6
Training loss: 0.08381374180316925
Validation loss: 1.5018075614847162

Epoch: 5| Step: 7
Training loss: 0.07783514261245728
Validation loss: 1.48192133057502

Epoch: 5| Step: 8
Training loss: 0.05336945131421089
Validation loss: 1.4708962132853847

Epoch: 5| Step: 9
Training loss: 0.17366638779640198
Validation loss: 1.482435498186337

Epoch: 5| Step: 10
Training loss: 0.16294735670089722
Validation loss: 1.483040669912933

Epoch: 526| Step: 0
Training loss: 0.13350926339626312
Validation loss: 1.4967461068143126

Epoch: 5| Step: 1
Training loss: 0.19677643477916718
Validation loss: 1.4632827927989345

Epoch: 5| Step: 2
Training loss: 0.14620020985603333
Validation loss: 1.450505043229749

Epoch: 5| Step: 3
Training loss: 0.13574694097042084
Validation loss: 1.4508207805695073

Epoch: 5| Step: 4
Training loss: 0.10335016250610352
Validation loss: 1.4792578387004074

Epoch: 5| Step: 5
Training loss: 0.1099080815911293
Validation loss: 1.4656414255019157

Epoch: 5| Step: 6
Training loss: 0.18986926972866058
Validation loss: 1.465456897212613

Epoch: 5| Step: 7
Training loss: 0.10830887407064438
Validation loss: 1.4843764907570296

Epoch: 5| Step: 8
Training loss: 0.14540116488933563
Validation loss: 1.4826701046318136

Epoch: 5| Step: 9
Training loss: 0.15633192658424377
Validation loss: 1.4856030633372646

Epoch: 5| Step: 10
Training loss: 0.08553140610456467
Validation loss: 1.4836002748499635

Epoch: 527| Step: 0
Training loss: 0.08025715500116348
Validation loss: 1.4786619332528883

Epoch: 5| Step: 1
Training loss: 0.07346801459789276
Validation loss: 1.5143563337223505

Epoch: 5| Step: 2
Training loss: 0.16585412621498108
Validation loss: 1.4853154715671335

Epoch: 5| Step: 3
Training loss: 0.21659019589424133
Validation loss: 1.4883253830735401

Epoch: 5| Step: 4
Training loss: 0.2256968468427658
Validation loss: 1.4476696240004672

Epoch: 5| Step: 5
Training loss: 0.14372389018535614
Validation loss: 1.4815405132949993

Epoch: 5| Step: 6
Training loss: 0.12007403373718262
Validation loss: 1.4842453605385237

Epoch: 5| Step: 7
Training loss: 0.12626510858535767
Validation loss: 1.468423270410107

Epoch: 5| Step: 8
Training loss: 0.12709246575832367
Validation loss: 1.4768343522984495

Epoch: 5| Step: 9
Training loss: 0.11166850477457047
Validation loss: 1.4821404782674645

Epoch: 5| Step: 10
Training loss: 0.1638977825641632
Validation loss: 1.492488968756891

Epoch: 528| Step: 0
Training loss: 0.2006930559873581
Validation loss: 1.4934400858417634

Epoch: 5| Step: 1
Training loss: 0.11339191347360611
Validation loss: 1.458983734089841

Epoch: 5| Step: 2
Training loss: 0.07079692929983139
Validation loss: 1.454095261712228

Epoch: 5| Step: 3
Training loss: 0.1595575362443924
Validation loss: 1.447008377762251

Epoch: 5| Step: 4
Training loss: 0.10405717045068741
Validation loss: 1.4601106118130427

Epoch: 5| Step: 5
Training loss: 0.11778869479894638
Validation loss: 1.4733578171781314

Epoch: 5| Step: 6
Training loss: 0.14236028492450714
Validation loss: 1.4606839700411725

Epoch: 5| Step: 7
Training loss: 0.15427181124687195
Validation loss: 1.4605111242622457

Epoch: 5| Step: 8
Training loss: 0.1987573206424713
Validation loss: 1.4863446181820286

Epoch: 5| Step: 9
Training loss: 0.14238600432872772
Validation loss: 1.5155869824911958

Epoch: 5| Step: 10
Training loss: 0.20902439951896667
Validation loss: 1.5339850418029293

Epoch: 529| Step: 0
Training loss: 0.11158385127782822
Validation loss: 1.5359362222815072

Epoch: 5| Step: 1
Training loss: 0.1655583381652832
Validation loss: 1.483385964106488

Epoch: 5| Step: 2
Training loss: 0.11188513040542603
Validation loss: 1.4891290228853944

Epoch: 5| Step: 3
Training loss: 0.08153074979782104
Validation loss: 1.469627937962932

Epoch: 5| Step: 4
Training loss: 0.190103217959404
Validation loss: 1.4418152686088317

Epoch: 5| Step: 5
Training loss: 0.09550570696592331
Validation loss: 1.4821205318615

Epoch: 5| Step: 6
Training loss: 0.17529888451099396
Validation loss: 1.474937254382718

Epoch: 5| Step: 7
Training loss: 0.1258619725704193
Validation loss: 1.4623917200232064

Epoch: 5| Step: 8
Training loss: 0.15057139098644257
Validation loss: 1.4765023659634333

Epoch: 5| Step: 9
Training loss: 0.1395534723997116
Validation loss: 1.4630615820166886

Epoch: 5| Step: 10
Training loss: 0.08371914178133011
Validation loss: 1.4710626807264102

Epoch: 530| Step: 0
Training loss: 0.21111369132995605
Validation loss: 1.4697211468091576

Epoch: 5| Step: 1
Training loss: 0.1076449602842331
Validation loss: 1.449608797668129

Epoch: 5| Step: 2
Training loss: 0.15698567032814026
Validation loss: 1.4756973315310735

Epoch: 5| Step: 3
Training loss: 0.09630680829286575
Validation loss: 1.47261332824666

Epoch: 5| Step: 4
Training loss: 0.1647631824016571
Validation loss: 1.4735824331160514

Epoch: 5| Step: 5
Training loss: 0.18244801461696625
Validation loss: 1.4841771843612834

Epoch: 5| Step: 6
Training loss: 0.16428020596504211
Validation loss: 1.495413290557041

Epoch: 5| Step: 7
Training loss: 0.0892929881811142
Validation loss: 1.4989458014888148

Epoch: 5| Step: 8
Training loss: 0.19798161089420319
Validation loss: 1.5090501885260306

Epoch: 5| Step: 9
Training loss: 0.1124289259314537
Validation loss: 1.4784889772374143

Epoch: 5| Step: 10
Training loss: 0.12538036704063416
Validation loss: 1.479838933995975

Epoch: 531| Step: 0
Training loss: 0.1219261884689331
Validation loss: 1.481391977879309

Epoch: 5| Step: 1
Training loss: 0.07043115049600601
Validation loss: 1.461249041300948

Epoch: 5| Step: 2
Training loss: 0.0902932733297348
Validation loss: 1.4665052096048992

Epoch: 5| Step: 3
Training loss: 0.23587599396705627
Validation loss: 1.4553989594982517

Epoch: 5| Step: 4
Training loss: 0.16420194506645203
Validation loss: 1.4827436170270365

Epoch: 5| Step: 5
Training loss: 0.12387553602457047
Validation loss: 1.4640834703240344

Epoch: 5| Step: 6
Training loss: 0.12244021892547607
Validation loss: 1.4662493249421478

Epoch: 5| Step: 7
Training loss: 0.10182806104421616
Validation loss: 1.477349756866373

Epoch: 5| Step: 8
Training loss: 0.15489628911018372
Validation loss: 1.4648816444540536

Epoch: 5| Step: 9
Training loss: 0.16451528668403625
Validation loss: 1.4433569574868808

Epoch: 5| Step: 10
Training loss: 0.17096386849880219
Validation loss: 1.4454347933492353

Epoch: 532| Step: 0
Training loss: 0.16400639712810516
Validation loss: 1.4501424489482757

Epoch: 5| Step: 1
Training loss: 0.14714963734149933
Validation loss: 1.464094974661386

Epoch: 5| Step: 2
Training loss: 0.1425924003124237
Validation loss: 1.472845523588119

Epoch: 5| Step: 3
Training loss: 0.12559251487255096
Validation loss: 1.4581031132769842

Epoch: 5| Step: 4
Training loss: 0.17927812039852142
Validation loss: 1.4540573884082097

Epoch: 5| Step: 5
Training loss: 0.10061348974704742
Validation loss: 1.4410447856431365

Epoch: 5| Step: 6
Training loss: 0.08638554811477661
Validation loss: 1.4585314527634652

Epoch: 5| Step: 7
Training loss: 0.25012826919555664
Validation loss: 1.4748413306410595

Epoch: 5| Step: 8
Training loss: 0.10008339583873749
Validation loss: 1.4508862777422833

Epoch: 5| Step: 9
Training loss: 0.13078071177005768
Validation loss: 1.4753569095365462

Epoch: 5| Step: 10
Training loss: 0.08521649241447449
Validation loss: 1.4805550600892754

Epoch: 533| Step: 0
Training loss: 0.07969079166650772
Validation loss: 1.4820602247791905

Epoch: 5| Step: 1
Training loss: 0.22459320724010468
Validation loss: 1.4573294475514402

Epoch: 5| Step: 2
Training loss: 0.08316293358802795
Validation loss: 1.458996932993653

Epoch: 5| Step: 3
Training loss: 0.1284753531217575
Validation loss: 1.4634449392236688

Epoch: 5| Step: 4
Training loss: 0.12178083509206772
Validation loss: 1.471491931587137

Epoch: 5| Step: 5
Training loss: 0.1186712235212326
Validation loss: 1.4843496968669276

Epoch: 5| Step: 6
Training loss: 0.0962851345539093
Validation loss: 1.4871184659260575

Epoch: 5| Step: 7
Training loss: 0.05429587513208389
Validation loss: 1.493567685927114

Epoch: 5| Step: 8
Training loss: 0.13888049125671387
Validation loss: 1.5183358679535568

Epoch: 5| Step: 9
Training loss: 0.17616768181324005
Validation loss: 1.4765799686472902

Epoch: 5| Step: 10
Training loss: 0.1270758956670761
Validation loss: 1.4603670002311788

Epoch: 534| Step: 0
Training loss: 0.14019478857517242
Validation loss: 1.4400884079676803

Epoch: 5| Step: 1
Training loss: 0.13505157828330994
Validation loss: 1.470290203248301

Epoch: 5| Step: 2
Training loss: 0.12521164119243622
Validation loss: 1.4711843921292214

Epoch: 5| Step: 3
Training loss: 0.12610957026481628
Validation loss: 1.4745960684232815

Epoch: 5| Step: 4
Training loss: 0.10301394760608673
Validation loss: 1.491242088297362

Epoch: 5| Step: 5
Training loss: 0.13758298754692078
Validation loss: 1.518198428615447

Epoch: 5| Step: 6
Training loss: 0.11481957137584686
Validation loss: 1.5244324559806495

Epoch: 5| Step: 7
Training loss: 0.22525644302368164
Validation loss: 1.4801142549002042

Epoch: 5| Step: 8
Training loss: 0.14746412634849548
Validation loss: 1.4615102916635492

Epoch: 5| Step: 9
Training loss: 0.1433115303516388
Validation loss: 1.4452080918896584

Epoch: 5| Step: 10
Training loss: 0.170857772231102
Validation loss: 1.4397846870524909

Epoch: 535| Step: 0
Training loss: 0.13249054551124573
Validation loss: 1.456841899502662

Epoch: 5| Step: 1
Training loss: 0.1627328097820282
Validation loss: 1.4237958872190086

Epoch: 5| Step: 2
Training loss: 0.1237882524728775
Validation loss: 1.4262765569071616

Epoch: 5| Step: 3
Training loss: 0.21203172206878662
Validation loss: 1.4322369816482707

Epoch: 5| Step: 4
Training loss: 0.19957688450813293
Validation loss: 1.4434901366951645

Epoch: 5| Step: 5
Training loss: 0.13375549018383026
Validation loss: 1.4474662452615716

Epoch: 5| Step: 6
Training loss: 0.2608141601085663
Validation loss: 1.450378506414352

Epoch: 5| Step: 7
Training loss: 0.11331471055746078
Validation loss: 1.429839813581077

Epoch: 5| Step: 8
Training loss: 0.08459443598985672
Validation loss: 1.439732228555987

Epoch: 5| Step: 9
Training loss: 0.11829744279384613
Validation loss: 1.4579794137708602

Epoch: 5| Step: 10
Training loss: 0.18239037692546844
Validation loss: 1.4463326315726004

Epoch: 536| Step: 0
Training loss: 0.24066953361034393
Validation loss: 1.4776794307975358

Epoch: 5| Step: 1
Training loss: 0.21044862270355225
Validation loss: 1.4934742617350754

Epoch: 5| Step: 2
Training loss: 0.23830553889274597
Validation loss: 1.5089933013403287

Epoch: 5| Step: 3
Training loss: 0.13370130956172943
Validation loss: 1.520514198528823

Epoch: 5| Step: 4
Training loss: 0.08283989131450653
Validation loss: 1.4811563350821053

Epoch: 5| Step: 5
Training loss: 0.14514696598052979
Validation loss: 1.5036023848800248

Epoch: 5| Step: 6
Training loss: 0.18792687356472015
Validation loss: 1.4870142206068961

Epoch: 5| Step: 7
Training loss: 0.2577771544456482
Validation loss: 1.4889204079105007

Epoch: 5| Step: 8
Training loss: 0.07663235068321228
Validation loss: 1.4842181744114045

Epoch: 5| Step: 9
Training loss: 0.18501348793506622
Validation loss: 1.4497364144171438

Epoch: 5| Step: 10
Training loss: 0.22363391518592834
Validation loss: 1.4415131089507893

Epoch: 537| Step: 0
Training loss: 0.14339947700500488
Validation loss: 1.4646702081926408

Epoch: 5| Step: 1
Training loss: 0.24151070415973663
Validation loss: 1.4423956838987206

Epoch: 5| Step: 2
Training loss: 0.18982043862342834
Validation loss: 1.44801208537112

Epoch: 5| Step: 3
Training loss: 0.16633373498916626
Validation loss: 1.4591754764638922

Epoch: 5| Step: 4
Training loss: 0.11564458906650543
Validation loss: 1.4629338236265286

Epoch: 5| Step: 5
Training loss: 0.19750279188156128
Validation loss: 1.4819985756310083

Epoch: 5| Step: 6
Training loss: 0.06646404415369034
Validation loss: 1.5025458412785684

Epoch: 5| Step: 7
Training loss: 0.20274968445301056
Validation loss: 1.4771227951972716

Epoch: 5| Step: 8
Training loss: 0.08954700827598572
Validation loss: 1.472570946139674

Epoch: 5| Step: 9
Training loss: 0.08362573385238647
Validation loss: 1.4979078308228524

Epoch: 5| Step: 10
Training loss: 0.1024942621588707
Validation loss: 1.4745480962978896

Epoch: 538| Step: 0
Training loss: 0.10409282147884369
Validation loss: 1.4749697472459526

Epoch: 5| Step: 1
Training loss: 0.1491171270608902
Validation loss: 1.4956192355002127

Epoch: 5| Step: 2
Training loss: 0.2974098324775696
Validation loss: 1.481728192298643

Epoch: 5| Step: 3
Training loss: 0.0918550044298172
Validation loss: 1.463098265791452

Epoch: 5| Step: 4
Training loss: 0.1039334312081337
Validation loss: 1.469841846855738

Epoch: 5| Step: 5
Training loss: 0.12351459264755249
Validation loss: 1.465979814529419

Epoch: 5| Step: 6
Training loss: 0.14783170819282532
Validation loss: 1.4729875467156852

Epoch: 5| Step: 7
Training loss: 0.12894444167613983
Validation loss: 1.466400255439102

Epoch: 5| Step: 8
Training loss: 0.11217937618494034
Validation loss: 1.4462872128332815

Epoch: 5| Step: 9
Training loss: 0.15109595656394958
Validation loss: 1.4210558091440508

Epoch: 5| Step: 10
Training loss: 0.07737550884485245
Validation loss: 1.409333025255511

Epoch: 539| Step: 0
Training loss: 0.19648805260658264
Validation loss: 1.4376914757554249

Epoch: 5| Step: 1
Training loss: 0.10461272299289703
Validation loss: 1.4447559169543687

Epoch: 5| Step: 2
Training loss: 0.10730969905853271
Validation loss: 1.4219443528882918

Epoch: 5| Step: 3
Training loss: 0.1950979083776474
Validation loss: 1.4464610635593373

Epoch: 5| Step: 4
Training loss: 0.17660489678382874
Validation loss: 1.4771048830401512

Epoch: 5| Step: 5
Training loss: 0.21514534950256348
Validation loss: 1.4905708861607376

Epoch: 5| Step: 6
Training loss: 0.1147780567407608
Validation loss: 1.4962801023196148

Epoch: 5| Step: 7
Training loss: 0.0834561139345169
Validation loss: 1.489021651206478

Epoch: 5| Step: 8
Training loss: 0.10883140563964844
Validation loss: 1.5109566847483318

Epoch: 5| Step: 9
Training loss: 0.12312982976436615
Validation loss: 1.5203193362041185

Epoch: 5| Step: 10
Training loss: 0.1529499590396881
Validation loss: 1.4760225780548588

Epoch: 540| Step: 0
Training loss: 0.14039617776870728
Validation loss: 1.4731191627440914

Epoch: 5| Step: 1
Training loss: 0.1552397906780243
Validation loss: 1.469432706473976

Epoch: 5| Step: 2
Training loss: 0.1488354206085205
Validation loss: 1.4324756296732093

Epoch: 5| Step: 3
Training loss: 0.17767879366874695
Validation loss: 1.4696746846681

Epoch: 5| Step: 4
Training loss: 0.12649628520011902
Validation loss: 1.4217650595531668

Epoch: 5| Step: 5
Training loss: 0.11536824703216553
Validation loss: 1.4677681935730802

Epoch: 5| Step: 6
Training loss: 0.14390131831169128
Validation loss: 1.4460486981176561

Epoch: 5| Step: 7
Training loss: 0.2985530495643616
Validation loss: 1.4714551510349396

Epoch: 5| Step: 8
Training loss: 0.11731640249490738
Validation loss: 1.4914175105351273

Epoch: 5| Step: 9
Training loss: 0.08933131396770477
Validation loss: 1.4653074613181494

Epoch: 5| Step: 10
Training loss: 0.15640296041965485
Validation loss: 1.5042795019765054

Epoch: 541| Step: 0
Training loss: 0.08797850459814072
Validation loss: 1.4815717666379866

Epoch: 5| Step: 1
Training loss: 0.12968245148658752
Validation loss: 1.4710427586750319

Epoch: 5| Step: 2
Training loss: 0.21188800036907196
Validation loss: 1.4767528131443968

Epoch: 5| Step: 3
Training loss: 0.08633971959352493
Validation loss: 1.479097847015627

Epoch: 5| Step: 4
Training loss: 0.1098238006234169
Validation loss: 1.4834758479108092

Epoch: 5| Step: 5
Training loss: 0.15058203041553497
Validation loss: 1.4602377799249464

Epoch: 5| Step: 6
Training loss: 0.10893173515796661
Validation loss: 1.4568912060030046

Epoch: 5| Step: 7
Training loss: 0.0894547700881958
Validation loss: 1.4611655255799652

Epoch: 5| Step: 8
Training loss: 0.15147081017494202
Validation loss: 1.4855156508825158

Epoch: 5| Step: 9
Training loss: 0.15706929564476013
Validation loss: 1.4629241202467231

Epoch: 5| Step: 10
Training loss: 0.1548984944820404
Validation loss: 1.5152471232157882

Epoch: 542| Step: 0
Training loss: 0.11439790576696396
Validation loss: 1.495679501564272

Epoch: 5| Step: 1
Training loss: 0.16368582844734192
Validation loss: 1.4756512629088534

Epoch: 5| Step: 2
Training loss: 0.13221900165081024
Validation loss: 1.47019822366776

Epoch: 5| Step: 3
Training loss: 0.08674174547195435
Validation loss: 1.4522817429675852

Epoch: 5| Step: 4
Training loss: 0.20770497620105743
Validation loss: 1.4543386133768226

Epoch: 5| Step: 5
Training loss: 0.1410953849554062
Validation loss: 1.4535649514967395

Epoch: 5| Step: 6
Training loss: 0.13798007369041443
Validation loss: 1.4675117103002404

Epoch: 5| Step: 7
Training loss: 0.09145702421665192
Validation loss: 1.4340244288085608

Epoch: 5| Step: 8
Training loss: 0.11581110954284668
Validation loss: 1.4368325279605003

Epoch: 5| Step: 9
Training loss: 0.12198974937200546
Validation loss: 1.4373562348786222

Epoch: 5| Step: 10
Training loss: 0.1031646803021431
Validation loss: 1.4514789940208517

Epoch: 543| Step: 0
Training loss: 0.19821853935718536
Validation loss: 1.4444362245580202

Epoch: 5| Step: 1
Training loss: 0.17462876439094543
Validation loss: 1.4735516527647614

Epoch: 5| Step: 2
Training loss: 0.11993912607431412
Validation loss: 1.4717539125873196

Epoch: 5| Step: 3
Training loss: 0.07326138764619827
Validation loss: 1.4488739992982598

Epoch: 5| Step: 4
Training loss: 0.08542501926422119
Validation loss: 1.4452001189672818

Epoch: 5| Step: 5
Training loss: 0.08899001777172089
Validation loss: 1.4650730010001891

Epoch: 5| Step: 6
Training loss: 0.0906163901090622
Validation loss: 1.4375166111094977

Epoch: 5| Step: 7
Training loss: 0.1203051209449768
Validation loss: 1.4553739268292663

Epoch: 5| Step: 8
Training loss: 0.14232137799263
Validation loss: 1.442598004494944

Epoch: 5| Step: 9
Training loss: 0.15320979058742523
Validation loss: 1.453387709074123

Epoch: 5| Step: 10
Training loss: 0.04718213900923729
Validation loss: 1.4381138188864595

Epoch: 544| Step: 0
Training loss: 0.17836707830429077
Validation loss: 1.4433256772256666

Epoch: 5| Step: 1
Training loss: 0.15835365653038025
Validation loss: 1.4413249223462996

Epoch: 5| Step: 2
Training loss: 0.11491396278142929
Validation loss: 1.4561547374212613

Epoch: 5| Step: 3
Training loss: 0.0781487375497818
Validation loss: 1.4696385091350925

Epoch: 5| Step: 4
Training loss: 0.11189421266317368
Validation loss: 1.450085025961681

Epoch: 5| Step: 5
Training loss: 0.16356346011161804
Validation loss: 1.45882337580445

Epoch: 5| Step: 6
Training loss: 0.21352355182170868
Validation loss: 1.47457665910003

Epoch: 5| Step: 7
Training loss: 0.08712490648031235
Validation loss: 1.49711698614141

Epoch: 5| Step: 8
Training loss: 0.09376372396945953
Validation loss: 1.4831179931599607

Epoch: 5| Step: 9
Training loss: 0.08887071162462234
Validation loss: 1.5026728978721045

Epoch: 5| Step: 10
Training loss: 0.09110293537378311
Validation loss: 1.5045430173156082

Epoch: 545| Step: 0
Training loss: 0.09038130939006805
Validation loss: 1.527166566541118

Epoch: 5| Step: 1
Training loss: 0.11948704719543457
Validation loss: 1.5101364415179017

Epoch: 5| Step: 2
Training loss: 0.1176414042711258
Validation loss: 1.4894590390625821

Epoch: 5| Step: 3
Training loss: 0.27198776602745056
Validation loss: 1.4998447279776297

Epoch: 5| Step: 4
Training loss: 0.07822515070438385
Validation loss: 1.488492864434437

Epoch: 5| Step: 5
Training loss: 0.10028703510761261
Validation loss: 1.4643504837507844

Epoch: 5| Step: 6
Training loss: 0.11686597019433975
Validation loss: 1.4857350600663053

Epoch: 5| Step: 7
Training loss: 0.15063664317131042
Validation loss: 1.430430922456967

Epoch: 5| Step: 8
Training loss: 0.16565832495689392
Validation loss: 1.4423720849457609

Epoch: 5| Step: 9
Training loss: 0.16643190383911133
Validation loss: 1.4875641433141564

Epoch: 5| Step: 10
Training loss: 0.1789417266845703
Validation loss: 1.4986049834118094

Epoch: 546| Step: 0
Training loss: 0.13351845741271973
Validation loss: 1.5021018430750857

Epoch: 5| Step: 1
Training loss: 0.13994815945625305
Validation loss: 1.4952848842067104

Epoch: 5| Step: 2
Training loss: 0.13799381256103516
Validation loss: 1.4960817060162943

Epoch: 5| Step: 3
Training loss: 0.07776772975921631
Validation loss: 1.4971737630905644

Epoch: 5| Step: 4
Training loss: 0.24897579848766327
Validation loss: 1.532053841057644

Epoch: 5| Step: 5
Training loss: 0.195078045129776
Validation loss: 1.5219410760428316

Epoch: 5| Step: 6
Training loss: 0.2091682404279709
Validation loss: 1.5420900237175725

Epoch: 5| Step: 7
Training loss: 0.13824054598808289
Validation loss: 1.5167612170660367

Epoch: 5| Step: 8
Training loss: 0.25140199065208435
Validation loss: 1.5273557786018617

Epoch: 5| Step: 9
Training loss: 0.09486289322376251
Validation loss: 1.516100150282665

Epoch: 5| Step: 10
Training loss: 0.0953628420829773
Validation loss: 1.5034385419660998

Epoch: 547| Step: 0
Training loss: 0.08284138143062592
Validation loss: 1.4902861643862981

Epoch: 5| Step: 1
Training loss: 0.20065638422966003
Validation loss: 1.4989107103757962

Epoch: 5| Step: 2
Training loss: 0.07532338798046112
Validation loss: 1.4984715138712237

Epoch: 5| Step: 3
Training loss: 0.248469740152359
Validation loss: 1.4831028779347737

Epoch: 5| Step: 4
Training loss: 0.12479658424854279
Validation loss: 1.4582375621282926

Epoch: 5| Step: 5
Training loss: 0.14368495345115662
Validation loss: 1.4810175511144823

Epoch: 5| Step: 6
Training loss: 0.14794042706489563
Validation loss: 1.4756912095572359

Epoch: 5| Step: 7
Training loss: 0.12865647673606873
Validation loss: 1.468380892148582

Epoch: 5| Step: 8
Training loss: 0.12257863581180573
Validation loss: 1.454164763932587

Epoch: 5| Step: 9
Training loss: 0.1430666744709015
Validation loss: 1.475012179343931

Epoch: 5| Step: 10
Training loss: 0.113951176404953
Validation loss: 1.4942308677140104

Epoch: 548| Step: 0
Training loss: 0.2947249412536621
Validation loss: 1.4815627259592856

Epoch: 5| Step: 1
Training loss: 0.21906352043151855
Validation loss: 1.5083326075666694

Epoch: 5| Step: 2
Training loss: 0.1478048712015152
Validation loss: 1.5065536716932892

Epoch: 5| Step: 3
Training loss: 0.17108067870140076
Validation loss: 1.5025920637192265

Epoch: 5| Step: 4
Training loss: 0.14865489304065704
Validation loss: 1.4840432213198753

Epoch: 5| Step: 5
Training loss: 0.05817844718694687
Validation loss: 1.45486419944353

Epoch: 5| Step: 6
Training loss: 0.07070477306842804
Validation loss: 1.4567821397576282

Epoch: 5| Step: 7
Training loss: 0.08481286466121674
Validation loss: 1.4528267524575675

Epoch: 5| Step: 8
Training loss: 0.1168576031923294
Validation loss: 1.447949778649115

Epoch: 5| Step: 9
Training loss: 0.12373820692300797
Validation loss: 1.4632563206457323

Epoch: 5| Step: 10
Training loss: 0.1339629739522934
Validation loss: 1.4595888865891324

Epoch: 549| Step: 0
Training loss: 0.1070706695318222
Validation loss: 1.4823187730645622

Epoch: 5| Step: 1
Training loss: 0.22482237219810486
Validation loss: 1.472918047699877

Epoch: 5| Step: 2
Training loss: 0.09691467136144638
Validation loss: 1.4711710983707058

Epoch: 5| Step: 3
Training loss: 0.15704019367694855
Validation loss: 1.5116665183856923

Epoch: 5| Step: 4
Training loss: 0.1718958616256714
Validation loss: 1.4956224259509836

Epoch: 5| Step: 5
Training loss: 0.18536476790905
Validation loss: 1.4826699738861413

Epoch: 5| Step: 6
Training loss: 0.14712922275066376
Validation loss: 1.4597634807709725

Epoch: 5| Step: 7
Training loss: 0.06370226293802261
Validation loss: 1.454872319775243

Epoch: 5| Step: 8
Training loss: 0.13584503531455994
Validation loss: 1.4581713804634668

Epoch: 5| Step: 9
Training loss: 0.11548803001642227
Validation loss: 1.4498973508034982

Epoch: 5| Step: 10
Training loss: 0.1318623274564743
Validation loss: 1.4309160094107352

Epoch: 550| Step: 0
Training loss: 0.14039960503578186
Validation loss: 1.4383748295486614

Epoch: 5| Step: 1
Training loss: 0.13619795441627502
Validation loss: 1.4263860717896493

Epoch: 5| Step: 2
Training loss: 0.19929499924182892
Validation loss: 1.4710918434204594

Epoch: 5| Step: 3
Training loss: 0.12454827129840851
Validation loss: 1.4285302982535413

Epoch: 5| Step: 4
Training loss: 0.16435657441616058
Validation loss: 1.4505445829001806

Epoch: 5| Step: 5
Training loss: 0.1051354855298996
Validation loss: 1.4403185100965603

Epoch: 5| Step: 6
Training loss: 0.21426841616630554
Validation loss: 1.4433725700583508

Epoch: 5| Step: 7
Training loss: 0.048644471913576126
Validation loss: 1.4769823845996652

Epoch: 5| Step: 8
Training loss: 0.1592390388250351
Validation loss: 1.455353501022503

Epoch: 5| Step: 9
Training loss: 0.1225723996758461
Validation loss: 1.4701261815204416

Epoch: 5| Step: 10
Training loss: 0.12751032412052155
Validation loss: 1.4508937405001732

Testing loss: 2.1283430788252087
