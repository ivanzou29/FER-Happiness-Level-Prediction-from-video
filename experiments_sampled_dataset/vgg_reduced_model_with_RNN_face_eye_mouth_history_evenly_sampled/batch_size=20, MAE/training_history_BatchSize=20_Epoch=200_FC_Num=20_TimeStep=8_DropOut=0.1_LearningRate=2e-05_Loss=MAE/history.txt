Epoch: 1| Step: 0
Training loss: 4.900859832763672
Validation loss: 5.237682604020642

Epoch: 5| Step: 1
Training loss: 6.598736763000488
Validation loss: 5.211841701179423

Epoch: 5| Step: 2
Training loss: 5.316697120666504
Validation loss: 5.191365780368928

Epoch: 5| Step: 3
Training loss: 4.81571102142334
Validation loss: 5.170707897473407

Epoch: 5| Step: 4
Training loss: 4.828167915344238
Validation loss: 5.148571870660269

Epoch: 5| Step: 5
Training loss: 4.550044059753418
Validation loss: 5.122872470527567

Epoch: 5| Step: 6
Training loss: 3.7461228370666504
Validation loss: 5.093970878149873

Epoch: 5| Step: 7
Training loss: 4.694525718688965
Validation loss: 5.062025326554493

Epoch: 5| Step: 8
Training loss: 4.858933448791504
Validation loss: 5.025563691252021

Epoch: 5| Step: 9
Training loss: 5.190054893493652
Validation loss: 4.985500950967112

Epoch: 5| Step: 10
Training loss: 4.360189437866211
Validation loss: 4.940144769607052

Epoch: 2| Step: 0
Training loss: 5.1108012199401855
Validation loss: 4.891268094380696

Epoch: 5| Step: 1
Training loss: 3.5926830768585205
Validation loss: 4.837933335252988

Epoch: 5| Step: 2
Training loss: 4.9448370933532715
Validation loss: 4.782604043201734

Epoch: 5| Step: 3
Training loss: 3.7418580055236816
Validation loss: 4.725150862047749

Epoch: 5| Step: 4
Training loss: 4.231240272521973
Validation loss: 4.6678528119159

Epoch: 5| Step: 5
Training loss: 5.047109127044678
Validation loss: 4.610808572461528

Epoch: 5| Step: 6
Training loss: 4.703795433044434
Validation loss: 4.554541059719619

Epoch: 5| Step: 7
Training loss: 4.094602108001709
Validation loss: 4.502318356626777

Epoch: 5| Step: 8
Training loss: 3.5154457092285156
Validation loss: 4.451564160726404

Epoch: 5| Step: 9
Training loss: 4.805544853210449
Validation loss: 4.405106072784752

Epoch: 5| Step: 10
Training loss: 4.757696628570557
Validation loss: 4.356468375011157

Epoch: 3| Step: 0
Training loss: 4.83682107925415
Validation loss: 4.30979545142061

Epoch: 5| Step: 1
Training loss: 4.2349700927734375
Validation loss: 4.267768203571278

Epoch: 5| Step: 2
Training loss: 3.0293290615081787
Validation loss: 4.2274832469160835

Epoch: 5| Step: 3
Training loss: 4.224625587463379
Validation loss: 4.193948907236899

Epoch: 5| Step: 4
Training loss: 4.058940887451172
Validation loss: 4.159335549159716

Epoch: 5| Step: 5
Training loss: 3.9752554893493652
Validation loss: 4.127258270017562

Epoch: 5| Step: 6
Training loss: 4.032883644104004
Validation loss: 4.108025758497177

Epoch: 5| Step: 7
Training loss: 3.556411027908325
Validation loss: 4.092529542984501

Epoch: 5| Step: 8
Training loss: 3.991795778274536
Validation loss: 4.079461953973257

Epoch: 5| Step: 9
Training loss: 4.369264125823975
Validation loss: 4.047351978158438

Epoch: 5| Step: 10
Training loss: 3.445282220840454
Validation loss: 4.03101904930607

Epoch: 4| Step: 0
Training loss: 4.327378749847412
Validation loss: 4.016716608437159

Epoch: 5| Step: 1
Training loss: 4.334999084472656
Validation loss: 3.9957249702945834

Epoch: 5| Step: 2
Training loss: 3.296861171722412
Validation loss: 3.970915953318278

Epoch: 5| Step: 3
Training loss: 4.529046058654785
Validation loss: 3.947327454884847

Epoch: 5| Step: 4
Training loss: 4.594192981719971
Validation loss: 3.9248646920727146

Epoch: 5| Step: 5
Training loss: 3.069519281387329
Validation loss: 3.9089046242416545

Epoch: 5| Step: 6
Training loss: 3.505791187286377
Validation loss: 3.8865167710088913

Epoch: 5| Step: 7
Training loss: 3.8510608673095703
Validation loss: 3.863683303197225

Epoch: 5| Step: 8
Training loss: 2.2155070304870605
Validation loss: 3.8355652721979285

Epoch: 5| Step: 9
Training loss: 3.988754987716675
Validation loss: 3.819919611818047

Epoch: 5| Step: 10
Training loss: 3.8136606216430664
Validation loss: 3.797604622379426

Epoch: 5| Step: 0
Training loss: 3.5281310081481934
Validation loss: 3.7789498247126097

Epoch: 5| Step: 1
Training loss: 3.6956028938293457
Validation loss: 3.763834589271135

Epoch: 5| Step: 2
Training loss: 3.101395606994629
Validation loss: 3.7495187072343725

Epoch: 5| Step: 3
Training loss: 4.249392986297607
Validation loss: 3.7311718668988956

Epoch: 5| Step: 4
Training loss: 3.3220901489257812
Validation loss: 3.7101426893664944

Epoch: 5| Step: 5
Training loss: 3.0786099433898926
Validation loss: 3.6929103277062856

Epoch: 5| Step: 6
Training loss: 3.569005250930786
Validation loss: 3.684873083586334

Epoch: 5| Step: 7
Training loss: 3.7426578998565674
Validation loss: 3.6700064751409713

Epoch: 5| Step: 8
Training loss: 3.6656157970428467
Validation loss: 3.654694726390223

Epoch: 5| Step: 9
Training loss: 4.051650047302246
Validation loss: 3.6412607931321666

Epoch: 5| Step: 10
Training loss: 3.593601942062378
Validation loss: 3.6283898661213536

Epoch: 6| Step: 0
Training loss: 2.6886043548583984
Validation loss: 3.61126047308727

Epoch: 5| Step: 1
Training loss: 4.282512187957764
Validation loss: 3.597332041750672

Epoch: 5| Step: 2
Training loss: 4.360712051391602
Validation loss: 3.586721004978303

Epoch: 5| Step: 3
Training loss: 3.360175371170044
Validation loss: 3.5706845714199926

Epoch: 5| Step: 4
Training loss: 2.134396553039551
Validation loss: 3.5521145328398673

Epoch: 5| Step: 5
Training loss: 3.2005715370178223
Validation loss: 3.5373991663737963

Epoch: 5| Step: 6
Training loss: 3.475107192993164
Validation loss: 3.521883190319102

Epoch: 5| Step: 7
Training loss: 3.74750018119812
Validation loss: 3.510105730384909

Epoch: 5| Step: 8
Training loss: 3.5591843128204346
Validation loss: 3.4935527770749983

Epoch: 5| Step: 9
Training loss: 3.4184093475341797
Validation loss: 3.4772495736357985

Epoch: 5| Step: 10
Training loss: 3.9861526489257812
Validation loss: 3.4686925616315616

Epoch: 7| Step: 0
Training loss: 4.000243186950684
Validation loss: 3.447047474563763

Epoch: 5| Step: 1
Training loss: 3.0060412883758545
Validation loss: 3.4344974512694986

Epoch: 5| Step: 2
Training loss: 3.493054151535034
Validation loss: 3.421942041766259

Epoch: 5| Step: 3
Training loss: 3.034768581390381
Validation loss: 3.407672884643719

Epoch: 5| Step: 4
Training loss: 2.626295328140259
Validation loss: 3.3935118259922152

Epoch: 5| Step: 5
Training loss: 3.777496814727783
Validation loss: 3.379526940725183

Epoch: 5| Step: 6
Training loss: 2.1239418983459473
Validation loss: 3.3633262700932

Epoch: 5| Step: 7
Training loss: 3.281726360321045
Validation loss: 3.3507733806487052

Epoch: 5| Step: 8
Training loss: 3.030089855194092
Validation loss: 3.3352654005891536

Epoch: 5| Step: 9
Training loss: 4.281218528747559
Validation loss: 3.3527113750416744

Epoch: 5| Step: 10
Training loss: 4.1462225914001465
Validation loss: 3.305872009646508

Epoch: 8| Step: 0
Training loss: 2.934351921081543
Validation loss: 3.3021454657277753

Epoch: 5| Step: 1
Training loss: 4.371601104736328
Validation loss: 3.2959370843825804

Epoch: 5| Step: 2
Training loss: 2.8080837726593018
Validation loss: 3.282773792102773

Epoch: 5| Step: 3
Training loss: 3.157214879989624
Validation loss: 3.275839582566292

Epoch: 5| Step: 4
Training loss: 4.233504295349121
Validation loss: 3.2684009049528386

Epoch: 5| Step: 5
Training loss: 3.003887891769409
Validation loss: 3.2620737757734073

Epoch: 5| Step: 6
Training loss: 3.2314095497131348
Validation loss: 3.2485262270896667

Epoch: 5| Step: 7
Training loss: 3.366950273513794
Validation loss: 3.2368769953327794

Epoch: 5| Step: 8
Training loss: 2.4519147872924805
Validation loss: 3.228281077518258

Epoch: 5| Step: 9
Training loss: 2.6870968341827393
Validation loss: 3.219489300122825

Epoch: 5| Step: 10
Training loss: 3.436715841293335
Validation loss: 3.2125169384864067

Epoch: 9| Step: 0
Training loss: 2.8942134380340576
Validation loss: 3.1969419576788463

Epoch: 5| Step: 1
Training loss: 2.437802791595459
Validation loss: 3.1832395292097524

Epoch: 5| Step: 2
Training loss: 3.439159393310547
Validation loss: 3.1695056884519515

Epoch: 5| Step: 3
Training loss: 2.8601624965667725
Validation loss: 3.1626573788222445

Epoch: 5| Step: 4
Training loss: 3.160933017730713
Validation loss: 3.1533665657043457

Epoch: 5| Step: 5
Training loss: 3.058734178543091
Validation loss: 3.1419064819171862

Epoch: 5| Step: 6
Training loss: 3.322737216949463
Validation loss: 3.1359183275571434

Epoch: 5| Step: 7
Training loss: 3.7135250568389893
Validation loss: 3.1245795449902936

Epoch: 5| Step: 8
Training loss: 3.705923557281494
Validation loss: 3.1120629695154007

Epoch: 5| Step: 9
Training loss: 3.205235004425049
Validation loss: 3.107932044613746

Epoch: 5| Step: 10
Training loss: 2.882476329803467
Validation loss: 3.1139172354052143

Epoch: 10| Step: 0
Training loss: 3.6137192249298096
Validation loss: 3.121815412275253

Epoch: 5| Step: 1
Training loss: 3.0042572021484375
Validation loss: 3.098965826854911

Epoch: 5| Step: 2
Training loss: 2.583660840988159
Validation loss: 3.093843662610618

Epoch: 5| Step: 3
Training loss: 3.281404972076416
Validation loss: 3.1070974308957338

Epoch: 5| Step: 4
Training loss: 3.1220765113830566
Validation loss: 3.17504539797383

Epoch: 5| Step: 5
Training loss: 3.393601894378662
Validation loss: 3.069950918997488

Epoch: 5| Step: 6
Training loss: 3.678356170654297
Validation loss: 3.0625678006038872

Epoch: 5| Step: 7
Training loss: 2.834096670150757
Validation loss: 3.079188746790732

Epoch: 5| Step: 8
Training loss: 3.2034244537353516
Validation loss: 3.093327478695941

Epoch: 5| Step: 9
Training loss: 2.4783642292022705
Validation loss: 3.092001043340211

Epoch: 5| Step: 10
Training loss: 3.285196304321289
Validation loss: 3.0571160111376035

Epoch: 11| Step: 0
Training loss: 3.088461399078369
Validation loss: 3.0404468326158423

Epoch: 5| Step: 1
Training loss: 2.899571657180786
Validation loss: 3.038389634060603

Epoch: 5| Step: 2
Training loss: 3.69915771484375
Validation loss: 3.0517520878904607

Epoch: 5| Step: 3
Training loss: 2.7689990997314453
Validation loss: 3.0519831565118607

Epoch: 5| Step: 4
Training loss: 3.5267245769500732
Validation loss: 3.036010757569344

Epoch: 5| Step: 5
Training loss: 3.448078155517578
Validation loss: 3.0163302267751386

Epoch: 5| Step: 6
Training loss: 3.058570623397827
Validation loss: 3.006754511146135

Epoch: 5| Step: 7
Training loss: 2.812434196472168
Validation loss: 3.0031441591119252

Epoch: 5| Step: 8
Training loss: 2.8558080196380615
Validation loss: 3.0025418112354894

Epoch: 5| Step: 9
Training loss: 2.6770710945129395
Validation loss: 3.000128235868228

Epoch: 5| Step: 10
Training loss: 3.0374653339385986
Validation loss: 2.9976207158898793

Epoch: 12| Step: 0
Training loss: 2.7393476963043213
Validation loss: 2.993537284994638

Epoch: 5| Step: 1
Training loss: 2.8653955459594727
Validation loss: 2.986156012422295

Epoch: 5| Step: 2
Training loss: 3.093357801437378
Validation loss: 2.9829132890188568

Epoch: 5| Step: 3
Training loss: 2.7883822917938232
Validation loss: 2.975212412495767

Epoch: 5| Step: 4
Training loss: 3.217665433883667
Validation loss: 2.9683923029130503

Epoch: 5| Step: 5
Training loss: 2.6002211570739746
Validation loss: 2.96261142915295

Epoch: 5| Step: 6
Training loss: 3.5198447704315186
Validation loss: 2.9595214705313406

Epoch: 5| Step: 7
Training loss: 2.601699113845825
Validation loss: 2.956490442317019

Epoch: 5| Step: 8
Training loss: 3.6114439964294434
Validation loss: 2.949382746091453

Epoch: 5| Step: 9
Training loss: 3.8360676765441895
Validation loss: 2.945790344668973

Epoch: 5| Step: 10
Training loss: 2.476827621459961
Validation loss: 2.941013954019034

Epoch: 13| Step: 0
Training loss: 2.7255775928497314
Validation loss: 2.9360474771068943

Epoch: 5| Step: 1
Training loss: 2.7398977279663086
Validation loss: 2.9304000639146373

Epoch: 5| Step: 2
Training loss: 3.517887830734253
Validation loss: 2.926851257201164

Epoch: 5| Step: 3
Training loss: 2.58014178276062
Validation loss: 2.922634099119453

Epoch: 5| Step: 4
Training loss: 3.0019423961639404
Validation loss: 2.9187449844934608

Epoch: 5| Step: 5
Training loss: 2.636220932006836
Validation loss: 2.915054008524905

Epoch: 5| Step: 6
Training loss: 3.8626716136932373
Validation loss: 2.9126908010052097

Epoch: 5| Step: 7
Training loss: 2.6352217197418213
Validation loss: 2.9108157670626076

Epoch: 5| Step: 8
Training loss: 3.2547168731689453
Validation loss: 2.912247957721833

Epoch: 5| Step: 9
Training loss: 3.384150266647339
Validation loss: 2.901787457927581

Epoch: 5| Step: 10
Training loss: 2.7394189834594727
Validation loss: 2.9001323356423327

Epoch: 14| Step: 0
Training loss: 3.5407822132110596
Validation loss: 2.906102436845021

Epoch: 5| Step: 1
Training loss: 2.896591901779175
Validation loss: 2.9215601567299134

Epoch: 5| Step: 2
Training loss: 2.7726681232452393
Validation loss: 2.968973946827714

Epoch: 5| Step: 3
Training loss: 3.0143356323242188
Validation loss: 2.9172971710082023

Epoch: 5| Step: 4
Training loss: 3.4257755279541016
Validation loss: 2.894137136397823

Epoch: 5| Step: 5
Training loss: 3.381753444671631
Validation loss: 2.91245089807818

Epoch: 5| Step: 6
Training loss: 2.52702260017395
Validation loss: 2.9297500605224283

Epoch: 5| Step: 7
Training loss: 2.9885952472686768
Validation loss: 2.9258510451163016

Epoch: 5| Step: 8
Training loss: 2.68681263923645
Validation loss: 2.8930364065272833

Epoch: 5| Step: 9
Training loss: 2.6591763496398926
Validation loss: 2.88148162698233

Epoch: 5| Step: 10
Training loss: 3.260613441467285
Validation loss: 2.8811372710812475

Epoch: 15| Step: 0
Training loss: 3.665714740753174
Validation loss: 2.8853026384948404

Epoch: 5| Step: 1
Training loss: 3.249422073364258
Validation loss: 2.8896631809972946

Epoch: 5| Step: 2
Training loss: 2.579796314239502
Validation loss: 2.884173772668326

Epoch: 5| Step: 3
Training loss: 2.745711088180542
Validation loss: 2.8757329064030803

Epoch: 5| Step: 4
Training loss: 2.493830442428589
Validation loss: 2.8659431447264967

Epoch: 5| Step: 5
Training loss: 2.3376293182373047
Validation loss: 2.85941380839194

Epoch: 5| Step: 6
Training loss: 2.8440287113189697
Validation loss: 2.8588390657978673

Epoch: 5| Step: 7
Training loss: 2.5969455242156982
Validation loss: 2.8568085957598943

Epoch: 5| Step: 8
Training loss: 4.1635870933532715
Validation loss: 2.85703013020177

Epoch: 5| Step: 9
Training loss: 3.466480255126953
Validation loss: 2.8570971668407483

Epoch: 5| Step: 10
Training loss: 2.5766193866729736
Validation loss: 2.8532152868086293

Epoch: 16| Step: 0
Training loss: 3.0114006996154785
Validation loss: 2.8501459321668072

Epoch: 5| Step: 1
Training loss: 3.081868886947632
Validation loss: 2.8493895210245603

Epoch: 5| Step: 2
Training loss: 2.6731741428375244
Validation loss: 2.8427653235773884

Epoch: 5| Step: 3
Training loss: 2.9988811016082764
Validation loss: 2.8402571755070842

Epoch: 5| Step: 4
Training loss: 2.938992500305176
Validation loss: 2.837465368291383

Epoch: 5| Step: 5
Training loss: 2.825059652328491
Validation loss: 2.8349367367324008

Epoch: 5| Step: 6
Training loss: 3.2268340587615967
Validation loss: 2.8338420211627917

Epoch: 5| Step: 7
Training loss: 2.7483267784118652
Validation loss: 2.831243130468553

Epoch: 5| Step: 8
Training loss: 3.017430067062378
Validation loss: 2.830746917314427

Epoch: 5| Step: 9
Training loss: 2.642930507659912
Validation loss: 2.8274695001622683

Epoch: 5| Step: 10
Training loss: 3.446484327316284
Validation loss: 2.8250759058101202

Epoch: 17| Step: 0
Training loss: 2.9358723163604736
Validation loss: 2.8246408508669947

Epoch: 5| Step: 1
Training loss: 3.1745591163635254
Validation loss: 2.822686892683788

Epoch: 5| Step: 2
Training loss: 3.024322509765625
Validation loss: 2.819888145692887

Epoch: 5| Step: 3
Training loss: 2.9188008308410645
Validation loss: 2.8190648530119207

Epoch: 5| Step: 4
Training loss: 2.54702091217041
Validation loss: 2.8179421476138535

Epoch: 5| Step: 5
Training loss: 2.7466366291046143
Validation loss: 2.8165296739147556

Epoch: 5| Step: 6
Training loss: 3.5255630016326904
Validation loss: 2.814764848319433

Epoch: 5| Step: 7
Training loss: 2.911839008331299
Validation loss: 2.813375178203788

Epoch: 5| Step: 8
Training loss: 2.3390774726867676
Validation loss: 2.8115150697769655

Epoch: 5| Step: 9
Training loss: 3.017249584197998
Validation loss: 2.8107557040388866

Epoch: 5| Step: 10
Training loss: 3.3324055671691895
Validation loss: 2.8086833210401636

Epoch: 18| Step: 0
Training loss: 3.3359198570251465
Validation loss: 2.807516159549836

Epoch: 5| Step: 1
Training loss: 2.839555263519287
Validation loss: 2.805375106873051

Epoch: 5| Step: 2
Training loss: 2.8573336601257324
Validation loss: 2.8040416573965423

Epoch: 5| Step: 3
Training loss: 2.5403733253479004
Validation loss: 2.802542963335591

Epoch: 5| Step: 4
Training loss: 3.542299747467041
Validation loss: 2.8009048072240685

Epoch: 5| Step: 5
Training loss: 3.1482839584350586
Validation loss: 2.79951411421581

Epoch: 5| Step: 6
Training loss: 2.048887252807617
Validation loss: 2.7977436665565736

Epoch: 5| Step: 7
Training loss: 3.1972484588623047
Validation loss: 2.797100797776253

Epoch: 5| Step: 8
Training loss: 2.8320915699005127
Validation loss: 2.794553187585646

Epoch: 5| Step: 9
Training loss: 2.5656466484069824
Validation loss: 2.7927098786959084

Epoch: 5| Step: 10
Training loss: 3.4577388763427734
Validation loss: 2.7908854253830446

Epoch: 19| Step: 0
Training loss: 3.104187250137329
Validation loss: 2.788902098132718

Epoch: 5| Step: 1
Training loss: 2.267791271209717
Validation loss: 2.7867529725515716

Epoch: 5| Step: 2
Training loss: 2.9414875507354736
Validation loss: 2.785002403361823

Epoch: 5| Step: 3
Training loss: 3.5479989051818848
Validation loss: 2.7824240243563088

Epoch: 5| Step: 4
Training loss: 3.041152238845825
Validation loss: 2.78179148961139

Epoch: 5| Step: 5
Training loss: 3.3518786430358887
Validation loss: 2.779114143822783

Epoch: 5| Step: 6
Training loss: 2.8792202472686768
Validation loss: 2.7797224008908836

Epoch: 5| Step: 7
Training loss: 3.0448174476623535
Validation loss: 2.77733362361949

Epoch: 5| Step: 8
Training loss: 2.540022611618042
Validation loss: 2.7770025166132117

Epoch: 5| Step: 9
Training loss: 2.8673691749572754
Validation loss: 2.7744707343398884

Epoch: 5| Step: 10
Training loss: 2.4919309616088867
Validation loss: 2.7729788749448714

Epoch: 20| Step: 0
Training loss: 3.4209377765655518
Validation loss: 2.7707238735691195

Epoch: 5| Step: 1
Training loss: 2.885746717453003
Validation loss: 2.7713244679153606

Epoch: 5| Step: 2
Training loss: 2.7336792945861816
Validation loss: 2.7712427441791823

Epoch: 5| Step: 3
Training loss: 3.091186761856079
Validation loss: 2.7695909571904007

Epoch: 5| Step: 4
Training loss: 1.7377967834472656
Validation loss: 2.767685136487407

Epoch: 5| Step: 5
Training loss: 3.1341347694396973
Validation loss: 2.765909840983729

Epoch: 5| Step: 6
Training loss: 2.3155674934387207
Validation loss: 2.7666818941793134

Epoch: 5| Step: 7
Training loss: 3.3776068687438965
Validation loss: 2.7676235014392483

Epoch: 5| Step: 8
Training loss: 2.902907609939575
Validation loss: 2.764199069751206

Epoch: 5| Step: 9
Training loss: 3.144216299057007
Validation loss: 2.7646160253914456

Epoch: 5| Step: 10
Training loss: 3.350290060043335
Validation loss: 2.7667141268330235

Epoch: 21| Step: 0
Training loss: 2.9154152870178223
Validation loss: 2.767680137388168

Epoch: 5| Step: 1
Training loss: 3.2501189708709717
Validation loss: 2.852765014094691

Epoch: 5| Step: 2
Training loss: 2.7910351753234863
Validation loss: 2.7859091989455687

Epoch: 5| Step: 3
Training loss: 3.4135584831237793
Validation loss: 2.761324901734629

Epoch: 5| Step: 4
Training loss: 2.9723377227783203
Validation loss: 2.761943845338719

Epoch: 5| Step: 5
Training loss: 1.9914073944091797
Validation loss: 2.7646412182879705

Epoch: 5| Step: 6
Training loss: 3.020458459854126
Validation loss: 2.7704162700201875

Epoch: 5| Step: 7
Training loss: 2.980863094329834
Validation loss: 2.7760600300245386

Epoch: 5| Step: 8
Training loss: 3.215991258621216
Validation loss: 2.775019112453666

Epoch: 5| Step: 9
Training loss: 2.4242191314697266
Validation loss: 2.7732593218485513

Epoch: 5| Step: 10
Training loss: 3.2128472328186035
Validation loss: 2.7635598233951035

Epoch: 22| Step: 0
Training loss: 3.478754758834839
Validation loss: 2.761572189228509

Epoch: 5| Step: 1
Training loss: 3.3117294311523438
Validation loss: 2.7595303802080053

Epoch: 5| Step: 2
Training loss: 3.3366150856018066
Validation loss: 2.7543526644347818

Epoch: 5| Step: 3
Training loss: 2.6227736473083496
Validation loss: 2.752778476284396

Epoch: 5| Step: 4
Training loss: 3.141321897506714
Validation loss: 2.758718216291038

Epoch: 5| Step: 5
Training loss: 3.2044074535369873
Validation loss: 2.7556184568712787

Epoch: 5| Step: 6
Training loss: 2.1851329803466797
Validation loss: 2.770797769228617

Epoch: 5| Step: 7
Training loss: 2.2268357276916504
Validation loss: 2.7618567405208463

Epoch: 5| Step: 8
Training loss: 2.5408663749694824
Validation loss: 2.807140217032484

Epoch: 5| Step: 9
Training loss: 2.7817530632019043
Validation loss: 2.8924637891912974

Epoch: 5| Step: 10
Training loss: 3.3772945404052734
Validation loss: 2.9304061961430374

Epoch: 23| Step: 0
Training loss: 2.993469476699829
Validation loss: 2.9195725994725383

Epoch: 5| Step: 1
Training loss: 2.9672579765319824
Validation loss: 2.880819853915963

Epoch: 5| Step: 2
Training loss: 4.243739604949951
Validation loss: 2.850807143795875

Epoch: 5| Step: 3
Training loss: 2.5927348136901855
Validation loss: 2.798233429590861

Epoch: 5| Step: 4
Training loss: 3.254990339279175
Validation loss: 2.7559324182489866

Epoch: 5| Step: 5
Training loss: 2.2241005897521973
Validation loss: 2.7496387035615983

Epoch: 5| Step: 6
Training loss: 2.9131553173065186
Validation loss: 2.7703656586267615

Epoch: 5| Step: 7
Training loss: 3.0198311805725098
Validation loss: 2.8426331961026756

Epoch: 5| Step: 8
Training loss: 2.3871943950653076
Validation loss: 2.951160002780217

Epoch: 5| Step: 9
Training loss: 2.6766674518585205
Validation loss: 2.989138239173479

Epoch: 5| Step: 10
Training loss: 3.491919755935669
Validation loss: 2.8751803444277857

Epoch: 24| Step: 0
Training loss: 2.657285690307617
Validation loss: 2.8241139432435394

Epoch: 5| Step: 1
Training loss: 2.687316656112671
Validation loss: 2.763043806117068

Epoch: 5| Step: 2
Training loss: 3.000467538833618
Validation loss: 2.732670012340751

Epoch: 5| Step: 3
Training loss: 3.432938814163208
Validation loss: 2.774858590095274

Epoch: 5| Step: 4
Training loss: 3.1702518463134766
Validation loss: 2.8258410192305043

Epoch: 5| Step: 5
Training loss: 2.7990028858184814
Validation loss: 2.8714011074394308

Epoch: 5| Step: 6
Training loss: 3.4108645915985107
Validation loss: 2.9194655623487247

Epoch: 5| Step: 7
Training loss: 2.3396434783935547
Validation loss: 2.932023130437379

Epoch: 5| Step: 8
Training loss: 2.2941582202911377
Validation loss: 2.869955673012682

Epoch: 5| Step: 9
Training loss: 3.2511444091796875
Validation loss: 2.839421938824397

Epoch: 5| Step: 10
Training loss: 3.2562999725341797
Validation loss: 2.8068851322256108

Epoch: 25| Step: 0
Training loss: 3.3622756004333496
Validation loss: 2.7749886897302445

Epoch: 5| Step: 1
Training loss: 2.901010513305664
Validation loss: 2.7577987024860997

Epoch: 5| Step: 2
Training loss: 2.5183024406433105
Validation loss: 2.7567864592357347

Epoch: 5| Step: 3
Training loss: 2.4219393730163574
Validation loss: 2.7592145396817114

Epoch: 5| Step: 4
Training loss: 2.824892520904541
Validation loss: 2.748884093376898

Epoch: 5| Step: 5
Training loss: 3.055410861968994
Validation loss: 2.741224108203765

Epoch: 5| Step: 6
Training loss: 2.993086576461792
Validation loss: 2.734526426561417

Epoch: 5| Step: 7
Training loss: 2.9259047508239746
Validation loss: 2.7346924402380504

Epoch: 5| Step: 8
Training loss: 3.1506643295288086
Validation loss: 2.7301384069586314

Epoch: 5| Step: 9
Training loss: 2.7758002281188965
Validation loss: 2.7245563845480643

Epoch: 5| Step: 10
Training loss: 2.978966236114502
Validation loss: 2.726322753455049

Epoch: 26| Step: 0
Training loss: 3.4326882362365723
Validation loss: 2.722874500418222

Epoch: 5| Step: 1
Training loss: 2.1923012733459473
Validation loss: 2.7186841259720507

Epoch: 5| Step: 2
Training loss: 3.253755569458008
Validation loss: 2.716124342333886

Epoch: 5| Step: 3
Training loss: 3.1880831718444824
Validation loss: 2.7085857288811797

Epoch: 5| Step: 4
Training loss: 2.5201144218444824
Validation loss: 2.707208210422147

Epoch: 5| Step: 5
Training loss: 2.741657018661499
Validation loss: 2.703038392528411

Epoch: 5| Step: 6
Training loss: 2.6448893547058105
Validation loss: 2.7040160291938373

Epoch: 5| Step: 7
Training loss: 2.7541160583496094
Validation loss: 2.7064249618079073

Epoch: 5| Step: 8
Training loss: 2.815957546234131
Validation loss: 2.703320316089097

Epoch: 5| Step: 9
Training loss: 3.2750885486602783
Validation loss: 2.7032495237165883

Epoch: 5| Step: 10
Training loss: 2.8208446502685547
Validation loss: 2.695449031809325

Epoch: 27| Step: 0
Training loss: 2.550687313079834
Validation loss: 2.6929130682381253

Epoch: 5| Step: 1
Training loss: 2.5627236366271973
Validation loss: 2.690836980778684

Epoch: 5| Step: 2
Training loss: 3.048551559448242
Validation loss: 2.6875976541990876

Epoch: 5| Step: 3
Training loss: 2.669070243835449
Validation loss: 2.6838916988782984

Epoch: 5| Step: 4
Training loss: 2.9511451721191406
Validation loss: 2.698624477591566

Epoch: 5| Step: 5
Training loss: 2.8328871726989746
Validation loss: 2.7033510977222073

Epoch: 5| Step: 6
Training loss: 2.9882705211639404
Validation loss: 2.699566620652394

Epoch: 5| Step: 7
Training loss: 2.7482333183288574
Validation loss: 2.6939960756609516

Epoch: 5| Step: 8
Training loss: 2.895855665206909
Validation loss: 2.6796553596373527

Epoch: 5| Step: 9
Training loss: 3.4426066875457764
Validation loss: 2.6819165573325208

Epoch: 5| Step: 10
Training loss: 2.764796257019043
Validation loss: 2.6807970308488414

Epoch: 28| Step: 0
Training loss: 2.9192090034484863
Validation loss: 2.676177345296388

Epoch: 5| Step: 1
Training loss: 2.6227447986602783
Validation loss: 2.679111619149485

Epoch: 5| Step: 2
Training loss: 1.905515432357788
Validation loss: 2.67556058719594

Epoch: 5| Step: 3
Training loss: 3.111635208129883
Validation loss: 2.677754730306646

Epoch: 5| Step: 4
Training loss: 3.1232211589813232
Validation loss: 2.6755622381805093

Epoch: 5| Step: 5
Training loss: 2.6533539295196533
Validation loss: 2.669544437880157

Epoch: 5| Step: 6
Training loss: 3.1810734272003174
Validation loss: 2.6701949745096187

Epoch: 5| Step: 7
Training loss: 3.1907711029052734
Validation loss: 2.667290751652051

Epoch: 5| Step: 8
Training loss: 2.655913829803467
Validation loss: 2.6697119000137493

Epoch: 5| Step: 9
Training loss: 2.642709970474243
Validation loss: 2.673085868999522

Epoch: 5| Step: 10
Training loss: 3.4758503437042236
Validation loss: 2.6669016294581915

Epoch: 29| Step: 0
Training loss: 2.353606700897217
Validation loss: 2.66873586562372

Epoch: 5| Step: 1
Training loss: 2.8971962928771973
Validation loss: 2.6680744232669955

Epoch: 5| Step: 2
Training loss: 2.5024633407592773
Validation loss: 2.666242686651086

Epoch: 5| Step: 3
Training loss: 2.680114507675171
Validation loss: 2.661171692673878

Epoch: 5| Step: 4
Training loss: 2.9305472373962402
Validation loss: 2.664417874428534

Epoch: 5| Step: 5
Training loss: 2.936206340789795
Validation loss: 2.66749636332194

Epoch: 5| Step: 6
Training loss: 2.6784780025482178
Validation loss: 2.6664955667270127

Epoch: 5| Step: 7
Training loss: 3.8823819160461426
Validation loss: 2.663662661788284

Epoch: 5| Step: 8
Training loss: 3.5717921257019043
Validation loss: 2.664900682305777

Epoch: 5| Step: 9
Training loss: 1.988843560218811
Validation loss: 2.666246670548634

Epoch: 5| Step: 10
Training loss: 2.9153170585632324
Validation loss: 2.6622995817533104

Epoch: 30| Step: 0
Training loss: 3.016981363296509
Validation loss: 2.6631743651564403

Epoch: 5| Step: 1
Training loss: 2.6711325645446777
Validation loss: 2.6576506245520806

Epoch: 5| Step: 2
Training loss: 2.2763257026672363
Validation loss: 2.658287843068441

Epoch: 5| Step: 3
Training loss: 3.065333604812622
Validation loss: 2.660938265503094

Epoch: 5| Step: 4
Training loss: 2.051785707473755
Validation loss: 2.6624104028107016

Epoch: 5| Step: 5
Training loss: 2.814352512359619
Validation loss: 2.658311051707114

Epoch: 5| Step: 6
Training loss: 2.6703076362609863
Validation loss: 2.6571059432080997

Epoch: 5| Step: 7
Training loss: 2.9718403816223145
Validation loss: 2.656210494297807

Epoch: 5| Step: 8
Training loss: 2.9839236736297607
Validation loss: 2.6551945183866765

Epoch: 5| Step: 9
Training loss: 3.4636921882629395
Validation loss: 2.6486119429270425

Epoch: 5| Step: 10
Training loss: 3.3722527027130127
Validation loss: 2.6548289791230233

Epoch: 31| Step: 0
Training loss: 3.1296050548553467
Validation loss: 2.6494620666708997

Epoch: 5| Step: 1
Training loss: 2.5067315101623535
Validation loss: 2.647968012799499

Epoch: 5| Step: 2
Training loss: 2.1756844520568848
Validation loss: 2.648994873928767

Epoch: 5| Step: 3
Training loss: 2.6978518962860107
Validation loss: 2.649872162008798

Epoch: 5| Step: 4
Training loss: 2.961038589477539
Validation loss: 2.6522070387358307

Epoch: 5| Step: 5
Training loss: 2.904841899871826
Validation loss: 2.658359735242782

Epoch: 5| Step: 6
Training loss: 3.3297295570373535
Validation loss: 2.6580875637710735

Epoch: 5| Step: 7
Training loss: 2.582663059234619
Validation loss: 2.653823406465592

Epoch: 5| Step: 8
Training loss: 2.7585153579711914
Validation loss: 2.652056230011807

Epoch: 5| Step: 9
Training loss: 3.35082745552063
Validation loss: 2.645584193609094

Epoch: 5| Step: 10
Training loss: 2.6565208435058594
Validation loss: 2.6388051176583893

Epoch: 32| Step: 0
Training loss: 2.7830309867858887
Validation loss: 2.641851514898321

Epoch: 5| Step: 1
Training loss: 2.0901458263397217
Validation loss: 2.6451752801095285

Epoch: 5| Step: 2
Training loss: 3.3137428760528564
Validation loss: 2.64374832184084

Epoch: 5| Step: 3
Training loss: 2.914961576461792
Validation loss: 2.6472184324777253

Epoch: 5| Step: 4
Training loss: 3.0424411296844482
Validation loss: 2.6542709386476906

Epoch: 5| Step: 5
Training loss: 2.6540331840515137
Validation loss: 2.666950738558205

Epoch: 5| Step: 6
Training loss: 2.6442275047302246
Validation loss: 2.6977550547610045

Epoch: 5| Step: 7
Training loss: 3.290916919708252
Validation loss: 2.6931939971062446

Epoch: 5| Step: 8
Training loss: 2.694119930267334
Validation loss: 2.66891618697874

Epoch: 5| Step: 9
Training loss: 2.80531907081604
Validation loss: 2.646581398543491

Epoch: 5| Step: 10
Training loss: 2.8219590187072754
Validation loss: 2.6398511778923774

Epoch: 33| Step: 0
Training loss: 2.8620400428771973
Validation loss: 2.639133358514437

Epoch: 5| Step: 1
Training loss: 2.8484630584716797
Validation loss: 2.6416549913344847

Epoch: 5| Step: 2
Training loss: 2.9670050144195557
Validation loss: 2.644239769187025

Epoch: 5| Step: 3
Training loss: 3.3431785106658936
Validation loss: 2.640802350095523

Epoch: 5| Step: 4
Training loss: 3.2250607013702393
Validation loss: 2.642874804876184

Epoch: 5| Step: 5
Training loss: 2.5806655883789062
Validation loss: 2.64042729203419

Epoch: 5| Step: 6
Training loss: 2.408057689666748
Validation loss: 2.641505615685576

Epoch: 5| Step: 7
Training loss: 3.2393078804016113
Validation loss: 2.636749654687861

Epoch: 5| Step: 8
Training loss: 3.182145595550537
Validation loss: 2.63510755056976

Epoch: 5| Step: 9
Training loss: 2.4356110095977783
Validation loss: 2.6300735909451722

Epoch: 5| Step: 10
Training loss: 1.8370392322540283
Validation loss: 2.6311483511360745

Epoch: 34| Step: 0
Training loss: 2.866065502166748
Validation loss: 2.644881579183763

Epoch: 5| Step: 1
Training loss: 2.2633755207061768
Validation loss: 2.665008783340454

Epoch: 5| Step: 2
Training loss: 2.551999807357788
Validation loss: 2.679951319130518

Epoch: 5| Step: 3
Training loss: 3.041095733642578
Validation loss: 2.685587006230508

Epoch: 5| Step: 4
Training loss: 3.4548957347869873
Validation loss: 2.6903333125575895

Epoch: 5| Step: 5
Training loss: 2.162545680999756
Validation loss: 2.6645204661994852

Epoch: 5| Step: 6
Training loss: 3.003204822540283
Validation loss: 2.634922126288055

Epoch: 5| Step: 7
Training loss: 2.653461456298828
Validation loss: 2.6188431478315786

Epoch: 5| Step: 8
Training loss: 2.910782814025879
Validation loss: 2.6198733314391105

Epoch: 5| Step: 9
Training loss: 2.9038047790527344
Validation loss: 2.621667097973567

Epoch: 5| Step: 10
Training loss: 3.201108932495117
Validation loss: 2.621886904521655

Epoch: 35| Step: 0
Training loss: 2.7504477500915527
Validation loss: 2.6256517517951226

Epoch: 5| Step: 1
Training loss: 3.0859475135803223
Validation loss: 2.6280486378618466

Epoch: 5| Step: 2
Training loss: 3.0979580879211426
Validation loss: 2.6320786296680407

Epoch: 5| Step: 3
Training loss: 2.5717244148254395
Validation loss: 2.6209978954766386

Epoch: 5| Step: 4
Training loss: 3.903726100921631
Validation loss: 2.617666898235198

Epoch: 5| Step: 5
Training loss: 2.606356143951416
Validation loss: 2.6203583773746284

Epoch: 5| Step: 6
Training loss: 3.2631888389587402
Validation loss: 2.615463697782127

Epoch: 5| Step: 7
Training loss: 1.9158636331558228
Validation loss: 2.616478625164237

Epoch: 5| Step: 8
Training loss: 2.2913568019866943
Validation loss: 2.6126819605468423

Epoch: 5| Step: 9
Training loss: 2.7262580394744873
Validation loss: 2.614384789620676

Epoch: 5| Step: 10
Training loss: 2.5511670112609863
Validation loss: 2.6259142711598384

Epoch: 36| Step: 0
Training loss: 2.1419177055358887
Validation loss: 2.628693519100066

Epoch: 5| Step: 1
Training loss: 3.264669895172119
Validation loss: 2.630644290677963

Epoch: 5| Step: 2
Training loss: 2.4630932807922363
Validation loss: 2.6178232367320726

Epoch: 5| Step: 3
Training loss: 2.227141857147217
Validation loss: 2.6134872974887973

Epoch: 5| Step: 4
Training loss: 3.412177324295044
Validation loss: 2.6190918466096282

Epoch: 5| Step: 5
Training loss: 3.05008602142334
Validation loss: 2.6197560858982865

Epoch: 5| Step: 6
Training loss: 2.7928225994110107
Validation loss: 2.6264063004524476

Epoch: 5| Step: 7
Training loss: 2.7986268997192383
Validation loss: 2.616227726782522

Epoch: 5| Step: 8
Training loss: 3.57684326171875
Validation loss: 2.6168430492442143

Epoch: 5| Step: 9
Training loss: 2.458698034286499
Validation loss: 2.6179875789150113

Epoch: 5| Step: 10
Training loss: 2.61775279045105
Validation loss: 2.617780816170477

Epoch: 37| Step: 0
Training loss: 2.5925023555755615
Validation loss: 2.612760497677711

Epoch: 5| Step: 1
Training loss: 2.3409218788146973
Validation loss: 2.601986026251188

Epoch: 5| Step: 2
Training loss: 3.1061367988586426
Validation loss: 2.5995112157637075

Epoch: 5| Step: 3
Training loss: 2.711843729019165
Validation loss: 2.6123182286498365

Epoch: 5| Step: 4
Training loss: 2.5999948978424072
Validation loss: 2.6129288340127594

Epoch: 5| Step: 5
Training loss: 2.88531756401062
Validation loss: 2.6384919740820445

Epoch: 5| Step: 6
Training loss: 2.0219006538391113
Validation loss: 2.6300970354387836

Epoch: 5| Step: 7
Training loss: 2.3991808891296387
Validation loss: 2.609237652952953

Epoch: 5| Step: 8
Training loss: 3.1836578845977783
Validation loss: 2.599333104266915

Epoch: 5| Step: 9
Training loss: 3.428485870361328
Validation loss: 2.5958228598358812

Epoch: 5| Step: 10
Training loss: 3.459451675415039
Validation loss: 2.596933464850149

Epoch: 38| Step: 0
Training loss: 2.7402825355529785
Validation loss: 2.6014268654648975

Epoch: 5| Step: 1
Training loss: 2.8726186752319336
Validation loss: 2.5935833633586927

Epoch: 5| Step: 2
Training loss: 3.0976336002349854
Validation loss: 2.587105102436517

Epoch: 5| Step: 3
Training loss: 2.937509059906006
Validation loss: 2.5991536904406805

Epoch: 5| Step: 4
Training loss: 2.024242401123047
Validation loss: 2.5948493480682373

Epoch: 5| Step: 5
Training loss: 3.4084384441375732
Validation loss: 2.61794142312901

Epoch: 5| Step: 6
Training loss: 2.465195417404175
Validation loss: 2.6382910666927213

Epoch: 5| Step: 7
Training loss: 3.3387084007263184
Validation loss: 2.652865763633482

Epoch: 5| Step: 8
Training loss: 2.788748264312744
Validation loss: 2.6662874734529884

Epoch: 5| Step: 9
Training loss: 2.4518494606018066
Validation loss: 2.7018496554384948

Epoch: 5| Step: 10
Training loss: 2.2414913177490234
Validation loss: 2.6294200369106826

Epoch: 39| Step: 0
Training loss: 2.5352423191070557
Validation loss: 2.5890334703589

Epoch: 5| Step: 1
Training loss: 2.929443359375
Validation loss: 2.5804525062602055

Epoch: 5| Step: 2
Training loss: 2.8036749362945557
Validation loss: 2.588622075255199

Epoch: 5| Step: 3
Training loss: 2.8373749256134033
Validation loss: 2.5964876246708695

Epoch: 5| Step: 4
Training loss: 3.478290557861328
Validation loss: 2.6058613536178425

Epoch: 5| Step: 5
Training loss: 2.422788381576538
Validation loss: 2.600691774839996

Epoch: 5| Step: 6
Training loss: 2.6911838054656982
Validation loss: 2.595186533466462

Epoch: 5| Step: 7
Training loss: 2.6064982414245605
Validation loss: 2.5968012527752946

Epoch: 5| Step: 8
Training loss: 2.598890781402588
Validation loss: 2.5917384752663235

Epoch: 5| Step: 9
Training loss: 2.818838119506836
Validation loss: 2.577045561164938

Epoch: 5| Step: 10
Training loss: 2.8927292823791504
Validation loss: 2.5752644385060957

Epoch: 40| Step: 0
Training loss: 2.7514584064483643
Validation loss: 2.578684499186854

Epoch: 5| Step: 1
Training loss: 2.7586193084716797
Validation loss: 2.593198237880584

Epoch: 5| Step: 2
Training loss: 1.9308542013168335
Validation loss: 2.6105382647565616

Epoch: 5| Step: 3
Training loss: 2.9814982414245605
Validation loss: 2.6261364465118735

Epoch: 5| Step: 4
Training loss: 2.5760865211486816
Validation loss: 2.628903822232318

Epoch: 5| Step: 5
Training loss: 2.8293933868408203
Validation loss: 2.6101971159699144

Epoch: 5| Step: 6
Training loss: 3.085461139678955
Validation loss: 2.6060860900468725

Epoch: 5| Step: 7
Training loss: 2.2435550689697266
Validation loss: 2.582653263563751

Epoch: 5| Step: 8
Training loss: 1.9814618825912476
Validation loss: 2.573577386076732

Epoch: 5| Step: 9
Training loss: 3.5080502033233643
Validation loss: 2.5624708872969433

Epoch: 5| Step: 10
Training loss: 3.751347541809082
Validation loss: 2.5606366947133052

Epoch: 41| Step: 0
Training loss: 2.4697446823120117
Validation loss: 2.560571227022397

Epoch: 5| Step: 1
Training loss: 2.301323652267456
Validation loss: 2.563263626508815

Epoch: 5| Step: 2
Training loss: 2.2568376064300537
Validation loss: 2.5610378096180577

Epoch: 5| Step: 3
Training loss: 2.704124689102173
Validation loss: 2.5601813434272684

Epoch: 5| Step: 4
Training loss: 3.1742241382598877
Validation loss: 2.5586094394806893

Epoch: 5| Step: 5
Training loss: 2.4918508529663086
Validation loss: 2.5604602393283638

Epoch: 5| Step: 6
Training loss: 2.2337117195129395
Validation loss: 2.559204081053375

Epoch: 5| Step: 7
Training loss: 3.133732795715332
Validation loss: 2.5523063572504188

Epoch: 5| Step: 8
Training loss: 2.9506356716156006
Validation loss: 2.5577002263838247

Epoch: 5| Step: 9
Training loss: 2.8546831607818604
Validation loss: 2.5798504480751614

Epoch: 5| Step: 10
Training loss: 3.6521494388580322
Validation loss: 2.6016034926137617

Epoch: 42| Step: 0
Training loss: 3.3584952354431152
Validation loss: 2.618461114104076

Epoch: 5| Step: 1
Training loss: 2.9216487407684326
Validation loss: 2.633345362960651

Epoch: 5| Step: 2
Training loss: 2.7040016651153564
Validation loss: 2.6548380646654355

Epoch: 5| Step: 3
Training loss: 3.1237473487854004
Validation loss: 2.623995957836028

Epoch: 5| Step: 4
Training loss: 2.6591508388519287
Validation loss: 2.611524425527101

Epoch: 5| Step: 5
Training loss: 2.1664464473724365
Validation loss: 2.573382480170137

Epoch: 5| Step: 6
Training loss: 2.49599289894104
Validation loss: 2.548501863274523

Epoch: 5| Step: 7
Training loss: 2.367252826690674
Validation loss: 2.5427068843636462

Epoch: 5| Step: 8
Training loss: 2.6293983459472656
Validation loss: 2.5572452775893675

Epoch: 5| Step: 9
Training loss: 2.7169458866119385
Validation loss: 2.560986577823598

Epoch: 5| Step: 10
Training loss: 3.220998764038086
Validation loss: 2.5632803260639148

Epoch: 43| Step: 0
Training loss: 2.3593201637268066
Validation loss: 2.557486880210138

Epoch: 5| Step: 1
Training loss: 2.335815906524658
Validation loss: 2.5447640983007287

Epoch: 5| Step: 2
Training loss: 2.6831510066986084
Validation loss: 2.537620080414639

Epoch: 5| Step: 3
Training loss: 2.3474087715148926
Validation loss: 2.538947316908067

Epoch: 5| Step: 4
Training loss: 2.8724753856658936
Validation loss: 2.5327479300960416

Epoch: 5| Step: 5
Training loss: 2.9118142127990723
Validation loss: 2.5439452740453903

Epoch: 5| Step: 6
Training loss: 2.580186128616333
Validation loss: 2.5711632954177035

Epoch: 5| Step: 7
Training loss: 3.3300766944885254
Validation loss: 2.5690452898702314

Epoch: 5| Step: 8
Training loss: 3.0286614894866943
Validation loss: 2.57283801673561

Epoch: 5| Step: 9
Training loss: 2.8317136764526367
Validation loss: 2.57691817386176

Epoch: 5| Step: 10
Training loss: 2.622370958328247
Validation loss: 2.5705381670305805

Epoch: 44| Step: 0
Training loss: 2.432626485824585
Validation loss: 2.5570961839409283

Epoch: 5| Step: 1
Training loss: 2.2882466316223145
Validation loss: 2.5390897643181587

Epoch: 5| Step: 2
Training loss: 2.324305295944214
Validation loss: 2.533588663224251

Epoch: 5| Step: 3
Training loss: 2.459336280822754
Validation loss: 2.5396810962307836

Epoch: 5| Step: 4
Training loss: 2.8111846446990967
Validation loss: 2.5321024207658667

Epoch: 5| Step: 5
Training loss: 2.544400453567505
Validation loss: 2.524329134213027

Epoch: 5| Step: 6
Training loss: 3.0056066513061523
Validation loss: 2.536857871599095

Epoch: 5| Step: 7
Training loss: 2.52124285697937
Validation loss: 2.5403950573295675

Epoch: 5| Step: 8
Training loss: 3.534127712249756
Validation loss: 2.5410958592609694

Epoch: 5| Step: 9
Training loss: 3.149851083755493
Validation loss: 2.5399751611935195

Epoch: 5| Step: 10
Training loss: 2.889967441558838
Validation loss: 2.5337058498013403

Epoch: 45| Step: 0
Training loss: 3.144559621810913
Validation loss: 2.533021883297992

Epoch: 5| Step: 1
Training loss: 2.7293758392333984
Validation loss: 2.5325215939552552

Epoch: 5| Step: 2
Training loss: 3.3257694244384766
Validation loss: 2.520757347024897

Epoch: 5| Step: 3
Training loss: 2.4253225326538086
Validation loss: 2.517262933074787

Epoch: 5| Step: 4
Training loss: 2.3431878089904785
Validation loss: 2.515305147376112

Epoch: 5| Step: 5
Training loss: 2.8956735134124756
Validation loss: 2.5152226135294926

Epoch: 5| Step: 6
Training loss: 3.120532512664795
Validation loss: 2.5319802453441005

Epoch: 5| Step: 7
Training loss: 2.3005385398864746
Validation loss: 2.540818827126616

Epoch: 5| Step: 8
Training loss: 2.282839059829712
Validation loss: 2.55429184052252

Epoch: 5| Step: 9
Training loss: 3.0127272605895996
Validation loss: 2.558605756810916

Epoch: 5| Step: 10
Training loss: 2.0060408115386963
Validation loss: 2.5491479878784506

Epoch: 46| Step: 0
Training loss: 2.510502338409424
Validation loss: 2.5423184312799925

Epoch: 5| Step: 1
Training loss: 2.738168478012085
Validation loss: 2.545598799182523

Epoch: 5| Step: 2
Training loss: 2.997511148452759
Validation loss: 2.5303514131935696

Epoch: 5| Step: 3
Training loss: 3.2102248668670654
Validation loss: 2.512328870834843

Epoch: 5| Step: 4
Training loss: 3.1804797649383545
Validation loss: 2.5189343293507895

Epoch: 5| Step: 5
Training loss: 2.5028176307678223
Validation loss: 2.5258766861372095

Epoch: 5| Step: 6
Training loss: 3.0049355030059814
Validation loss: 2.529974409328994

Epoch: 5| Step: 7
Training loss: 2.5971641540527344
Validation loss: 2.534023748931064

Epoch: 5| Step: 8
Training loss: 2.747316360473633
Validation loss: 2.540943953298753

Epoch: 5| Step: 9
Training loss: 2.2241568565368652
Validation loss: 2.529708421358498

Epoch: 5| Step: 10
Training loss: 2.25687575340271
Validation loss: 2.5319908844527377

Epoch: 47| Step: 0
Training loss: 3.1991703510284424
Validation loss: 2.5402676623354674

Epoch: 5| Step: 1
Training loss: 2.4017679691314697
Validation loss: 2.521265540071713

Epoch: 5| Step: 2
Training loss: 2.693382740020752
Validation loss: 2.5292862230731594

Epoch: 5| Step: 3
Training loss: 2.9721128940582275
Validation loss: 2.5080317066561792

Epoch: 5| Step: 4
Training loss: 2.9152543544769287
Validation loss: 2.500458917310161

Epoch: 5| Step: 5
Training loss: 2.237957715988159
Validation loss: 2.4968358932002896

Epoch: 5| Step: 6
Training loss: 2.6626477241516113
Validation loss: 2.494567568584155

Epoch: 5| Step: 7
Training loss: 2.37545108795166
Validation loss: 2.498439517072452

Epoch: 5| Step: 8
Training loss: 2.3089804649353027
Validation loss: 2.5191625856584117

Epoch: 5| Step: 9
Training loss: 3.549187421798706
Validation loss: 2.550125962944441

Epoch: 5| Step: 10
Training loss: 2.4949755668640137
Validation loss: 2.6113171423635175

Epoch: 48| Step: 0
Training loss: 2.4880683422088623
Validation loss: 2.5738526877536567

Epoch: 5| Step: 1
Training loss: 2.2068448066711426
Validation loss: 2.56380126296833

Epoch: 5| Step: 2
Training loss: 2.066584825515747
Validation loss: 2.5669990995878815

Epoch: 5| Step: 3
Training loss: 2.864793300628662
Validation loss: 2.5505230375515517

Epoch: 5| Step: 4
Training loss: 2.9486868381500244
Validation loss: 2.5267467498779297

Epoch: 5| Step: 5
Training loss: 2.743779420852661
Validation loss: 2.5109399877568728

Epoch: 5| Step: 6
Training loss: 3.8959076404571533
Validation loss: 2.496224272635675

Epoch: 5| Step: 7
Training loss: 2.1444108486175537
Validation loss: 2.502614164865145

Epoch: 5| Step: 8
Training loss: 2.944305896759033
Validation loss: 2.506580111800983

Epoch: 5| Step: 9
Training loss: 2.468320608139038
Validation loss: 2.5167866432538597

Epoch: 5| Step: 10
Training loss: 3.150498151779175
Validation loss: 2.5260356805657826

Epoch: 49| Step: 0
Training loss: 2.9858040809631348
Validation loss: 2.5277805610369612

Epoch: 5| Step: 1
Training loss: 3.5306873321533203
Validation loss: 2.5180116135586976

Epoch: 5| Step: 2
Training loss: 2.9474003314971924
Validation loss: 2.5144685545275287

Epoch: 5| Step: 3
Training loss: 2.6208603382110596
Validation loss: 2.4989896999892367

Epoch: 5| Step: 4
Training loss: 2.7311789989471436
Validation loss: 2.5005575239017444

Epoch: 5| Step: 5
Training loss: 2.609046459197998
Validation loss: 2.550833781560262

Epoch: 5| Step: 6
Training loss: 2.4186127185821533
Validation loss: 2.517951088566934

Epoch: 5| Step: 7
Training loss: 2.7526025772094727
Validation loss: 2.495599341648881

Epoch: 5| Step: 8
Training loss: 2.7023158073425293
Validation loss: 2.57511507567539

Epoch: 5| Step: 9
Training loss: 1.9690160751342773
Validation loss: 2.691102986694664

Epoch: 5| Step: 10
Training loss: 2.9940025806427
Validation loss: 2.746894851807625

Epoch: 50| Step: 0
Training loss: 3.168964385986328
Validation loss: 2.722939257980675

Epoch: 5| Step: 1
Training loss: 2.749084949493408
Validation loss: 2.721625156300042

Epoch: 5| Step: 2
Training loss: 2.6669869422912598
Validation loss: 2.706963892905943

Epoch: 5| Step: 3
Training loss: 2.9385743141174316
Validation loss: 2.6631796103651806

Epoch: 5| Step: 4
Training loss: 2.5572783946990967
Validation loss: 2.633449446770453

Epoch: 5| Step: 5
Training loss: 3.330073118209839
Validation loss: 2.548040484869352

Epoch: 5| Step: 6
Training loss: 2.676945686340332
Validation loss: 2.510217539725765

Epoch: 5| Step: 7
Training loss: 2.0991103649139404
Validation loss: 2.5254276311525734

Epoch: 5| Step: 8
Training loss: 3.1679980754852295
Validation loss: 2.570707389103469

Epoch: 5| Step: 9
Training loss: 2.5466067790985107
Validation loss: 2.5950309948254655

Epoch: 5| Step: 10
Training loss: 2.374138593673706
Validation loss: 2.570668540975099

Epoch: 51| Step: 0
Training loss: 3.4977478981018066
Validation loss: 2.533290642564015

Epoch: 5| Step: 1
Training loss: 2.312370777130127
Validation loss: 2.5143588358356106

Epoch: 5| Step: 2
Training loss: 2.319899320602417
Validation loss: 2.5074194362086635

Epoch: 5| Step: 3
Training loss: 2.4190611839294434
Validation loss: 2.5024800941508305

Epoch: 5| Step: 4
Training loss: 2.611811876296997
Validation loss: 2.5004375621836674

Epoch: 5| Step: 5
Training loss: 2.326995611190796
Validation loss: 2.493584373945831

Epoch: 5| Step: 6
Training loss: 3.1339306831359863
Validation loss: 2.5026729952904487

Epoch: 5| Step: 7
Training loss: 2.1307573318481445
Validation loss: 2.5188743798963484

Epoch: 5| Step: 8
Training loss: 2.53535795211792
Validation loss: 2.5264747822156517

Epoch: 5| Step: 9
Training loss: 2.950435161590576
Validation loss: 2.5340533743622484

Epoch: 5| Step: 10
Training loss: 3.51580548286438
Validation loss: 2.5510659679289787

Epoch: 52| Step: 0
Training loss: 2.897752523422241
Validation loss: 2.551602191822503

Epoch: 5| Step: 1
Training loss: 2.419980049133301
Validation loss: 2.529033604488578

Epoch: 5| Step: 2
Training loss: 2.187605619430542
Validation loss: 2.501136161947763

Epoch: 5| Step: 3
Training loss: 2.5717110633850098
Validation loss: 2.4901581220729376

Epoch: 5| Step: 4
Training loss: 2.576063871383667
Validation loss: 2.4956142235827703

Epoch: 5| Step: 5
Training loss: 2.6236374378204346
Validation loss: 2.5071138976722636

Epoch: 5| Step: 6
Training loss: 3.357741117477417
Validation loss: 2.505915664857434

Epoch: 5| Step: 7
Training loss: 3.1797115802764893
Validation loss: 2.511842502060757

Epoch: 5| Step: 8
Training loss: 1.8306396007537842
Validation loss: 2.485426482333932

Epoch: 5| Step: 9
Training loss: 3.3538711071014404
Validation loss: 2.4898754114745767

Epoch: 5| Step: 10
Training loss: 2.4543216228485107
Validation loss: 2.4786358418003207

Epoch: 53| Step: 0
Training loss: 2.23935604095459
Validation loss: 2.469543569831438

Epoch: 5| Step: 1
Training loss: 2.529975414276123
Validation loss: 2.4665969007758686

Epoch: 5| Step: 2
Training loss: 2.5100419521331787
Validation loss: 2.4672578380953882

Epoch: 5| Step: 3
Training loss: 2.5278172492980957
Validation loss: 2.4659544473053305

Epoch: 5| Step: 4
Training loss: 3.28064227104187
Validation loss: 2.4655298263795915

Epoch: 5| Step: 5
Training loss: 2.805469274520874
Validation loss: 2.465770847053938

Epoch: 5| Step: 6
Training loss: 3.0504000186920166
Validation loss: 2.47020133080021

Epoch: 5| Step: 7
Training loss: 2.9207634925842285
Validation loss: 2.477200279953659

Epoch: 5| Step: 8
Training loss: 2.5500082969665527
Validation loss: 2.4808201994947208

Epoch: 5| Step: 9
Training loss: 2.815448522567749
Validation loss: 2.478569592199018

Epoch: 5| Step: 10
Training loss: 2.1455342769622803
Validation loss: 2.4709256131161927

Epoch: 54| Step: 0
Training loss: 1.7763144969940186
Validation loss: 2.465247654145764

Epoch: 5| Step: 1
Training loss: 2.426452159881592
Validation loss: 2.4593401724292385

Epoch: 5| Step: 2
Training loss: 2.830026865005493
Validation loss: 2.462248320220619

Epoch: 5| Step: 3
Training loss: 2.284606456756592
Validation loss: 2.4553687675024873

Epoch: 5| Step: 4
Training loss: 2.56209135055542
Validation loss: 2.454564207343645

Epoch: 5| Step: 5
Training loss: 2.5947747230529785
Validation loss: 2.45684548347227

Epoch: 5| Step: 6
Training loss: 3.4295661449432373
Validation loss: 2.463969155024457

Epoch: 5| Step: 7
Training loss: 3.258340835571289
Validation loss: 2.4662029281739266

Epoch: 5| Step: 8
Training loss: 2.6137709617614746
Validation loss: 2.459512282443303

Epoch: 5| Step: 9
Training loss: 2.496056079864502
Validation loss: 2.4682930848931752

Epoch: 5| Step: 10
Training loss: 3.1510441303253174
Validation loss: 2.4733481560983965

Epoch: 55| Step: 0
Training loss: 2.602522373199463
Validation loss: 2.4734295439976517

Epoch: 5| Step: 1
Training loss: 3.4981067180633545
Validation loss: 2.468784442511938

Epoch: 5| Step: 2
Training loss: 2.2034897804260254
Validation loss: 2.4709681028960855

Epoch: 5| Step: 3
Training loss: 2.8050296306610107
Validation loss: 2.4604314552840365

Epoch: 5| Step: 4
Training loss: 3.1501553058624268
Validation loss: 2.457354789139122

Epoch: 5| Step: 5
Training loss: 2.110792875289917
Validation loss: 2.4500074642960743

Epoch: 5| Step: 6
Training loss: 2.7025272846221924
Validation loss: 2.4496673230201966

Epoch: 5| Step: 7
Training loss: 2.8283514976501465
Validation loss: 2.447486598004577

Epoch: 5| Step: 8
Training loss: 2.1420459747314453
Validation loss: 2.4440835163157475

Epoch: 5| Step: 9
Training loss: 2.423657178878784
Validation loss: 2.4448352782957015

Epoch: 5| Step: 10
Training loss: 2.9488940238952637
Validation loss: 2.449605944336102

Epoch: 56| Step: 0
Training loss: 3.1440720558166504
Validation loss: 2.450835303593707

Epoch: 5| Step: 1
Training loss: 2.9930331707000732
Validation loss: 2.4622335485232774

Epoch: 5| Step: 2
Training loss: 1.6997661590576172
Validation loss: 2.475516962748702

Epoch: 5| Step: 3
Training loss: 2.682159900665283
Validation loss: 2.4945617952654437

Epoch: 5| Step: 4
Training loss: 2.571025848388672
Validation loss: 2.503031269196541

Epoch: 5| Step: 5
Training loss: 2.6547532081604004
Validation loss: 2.5046855147166918

Epoch: 5| Step: 6
Training loss: 2.478982448577881
Validation loss: 2.490057776051183

Epoch: 5| Step: 7
Training loss: 2.238999128341675
Validation loss: 2.488472661664409

Epoch: 5| Step: 8
Training loss: 2.63956880569458
Validation loss: 2.4770863953457085

Epoch: 5| Step: 9
Training loss: 3.1942343711853027
Validation loss: 2.4778571333936465

Epoch: 5| Step: 10
Training loss: 3.1254215240478516
Validation loss: 2.4608414275671846

Epoch: 57| Step: 0
Training loss: 2.1401100158691406
Validation loss: 2.468524263751122

Epoch: 5| Step: 1
Training loss: 2.9998984336853027
Validation loss: 2.4741619402362454

Epoch: 5| Step: 2
Training loss: 2.7865214347839355
Validation loss: 2.4681141658495833

Epoch: 5| Step: 3
Training loss: 2.3883700370788574
Validation loss: 2.4564196653263544

Epoch: 5| Step: 4
Training loss: 2.6059770584106445
Validation loss: 2.4545245221866074

Epoch: 5| Step: 5
Training loss: 2.537132978439331
Validation loss: 2.442555283987394

Epoch: 5| Step: 6
Training loss: 2.0326082706451416
Validation loss: 2.4396878365547425

Epoch: 5| Step: 7
Training loss: 2.78517484664917
Validation loss: 2.434124605630034

Epoch: 5| Step: 8
Training loss: 2.5175211429595947
Validation loss: 2.435681337951332

Epoch: 5| Step: 9
Training loss: 3.4929897785186768
Validation loss: 2.446183399487567

Epoch: 5| Step: 10
Training loss: 3.0468311309814453
Validation loss: 2.444615423038442

Epoch: 58| Step: 0
Training loss: 2.9551477432250977
Validation loss: 2.4527271024642454

Epoch: 5| Step: 1
Training loss: 2.985124111175537
Validation loss: 2.4503584754082466

Epoch: 5| Step: 2
Training loss: 2.977389097213745
Validation loss: 2.446385440006051

Epoch: 5| Step: 3
Training loss: 2.900176525115967
Validation loss: 2.4633997409574446

Epoch: 5| Step: 4
Training loss: 2.653413772583008
Validation loss: 2.4711375774875766

Epoch: 5| Step: 5
Training loss: 2.5214617252349854
Validation loss: 2.4716553893140567

Epoch: 5| Step: 6
Training loss: 2.48630952835083
Validation loss: 2.454285849807083

Epoch: 5| Step: 7
Training loss: 2.0827107429504395
Validation loss: 2.437441820739418

Epoch: 5| Step: 8
Training loss: 3.3777732849121094
Validation loss: 2.433476068640268

Epoch: 5| Step: 9
Training loss: 1.2732884883880615
Validation loss: 2.4285931689764864

Epoch: 5| Step: 10
Training loss: 2.973952293395996
Validation loss: 2.428151935659429

Epoch: 59| Step: 0
Training loss: 2.5609707832336426
Validation loss: 2.434356766362344

Epoch: 5| Step: 1
Training loss: 2.6489689350128174
Validation loss: 2.4435782278737714

Epoch: 5| Step: 2
Training loss: 2.561339855194092
Validation loss: 2.441272215176654

Epoch: 5| Step: 3
Training loss: 2.5896153450012207
Validation loss: 2.4491479268638034

Epoch: 5| Step: 4
Training loss: 2.362536668777466
Validation loss: 2.475564120918192

Epoch: 5| Step: 5
Training loss: 2.825775623321533
Validation loss: 2.484288082327894

Epoch: 5| Step: 6
Training loss: 1.9823486804962158
Validation loss: 2.4822383926760767

Epoch: 5| Step: 7
Training loss: 2.5411925315856934
Validation loss: 2.468007908072523

Epoch: 5| Step: 8
Training loss: 3.2341246604919434
Validation loss: 2.46764640397923

Epoch: 5| Step: 9
Training loss: 2.5921175479888916
Validation loss: 2.44339402773047

Epoch: 5| Step: 10
Training loss: 3.487233877182007
Validation loss: 2.436029208603726

Epoch: 60| Step: 0
Training loss: 3.2363669872283936
Validation loss: 2.433258612950643

Epoch: 5| Step: 1
Training loss: 2.6457722187042236
Validation loss: 2.4397807480186544

Epoch: 5| Step: 2
Training loss: 2.8654046058654785
Validation loss: 2.448031356257777

Epoch: 5| Step: 3
Training loss: 3.0727832317352295
Validation loss: 2.443749350886191

Epoch: 5| Step: 4
Training loss: 2.2122881412506104
Validation loss: 2.428538890295131

Epoch: 5| Step: 5
Training loss: 3.1010680198669434
Validation loss: 2.4205872768996866

Epoch: 5| Step: 6
Training loss: 1.9318926334381104
Validation loss: 2.4106920829383274

Epoch: 5| Step: 7
Training loss: 2.7420060634613037
Validation loss: 2.414051225108485

Epoch: 5| Step: 8
Training loss: 2.0544958114624023
Validation loss: 2.409148993030671

Epoch: 5| Step: 9
Training loss: 2.5365400314331055
Validation loss: 2.4057255855170627

Epoch: 5| Step: 10
Training loss: 2.8520963191986084
Validation loss: 2.4062996397736254

Epoch: 61| Step: 0
Training loss: 2.5505030155181885
Validation loss: 2.4035847417769896

Epoch: 5| Step: 1
Training loss: 2.9727931022644043
Validation loss: 2.413335008005942

Epoch: 5| Step: 2
Training loss: 2.5769951343536377
Validation loss: 2.406198819478353

Epoch: 5| Step: 3
Training loss: 2.43668794631958
Validation loss: 2.4164944028341644

Epoch: 5| Step: 4
Training loss: 2.7240676879882812
Validation loss: 2.4261699004839827

Epoch: 5| Step: 5
Training loss: 2.565274715423584
Validation loss: 2.440279786304761

Epoch: 5| Step: 6
Training loss: 3.1665828227996826
Validation loss: 2.4421412790975263

Epoch: 5| Step: 7
Training loss: 2.2225348949432373
Validation loss: 2.443273082856209

Epoch: 5| Step: 8
Training loss: 2.3027760982513428
Validation loss: 2.43863538260101

Epoch: 5| Step: 9
Training loss: 2.9436633586883545
Validation loss: 2.421657854510892

Epoch: 5| Step: 10
Training loss: 2.7134151458740234
Validation loss: 2.4134071873080347

Epoch: 62| Step: 0
Training loss: 2.63041615486145
Validation loss: 2.401002314782912

Epoch: 5| Step: 1
Training loss: 2.1867542266845703
Validation loss: 2.401365203242148

Epoch: 5| Step: 2
Training loss: 2.1728382110595703
Validation loss: 2.402664569116408

Epoch: 5| Step: 3
Training loss: 3.5677361488342285
Validation loss: 2.397087066404281

Epoch: 5| Step: 4
Training loss: 2.663088321685791
Validation loss: 2.3977805824689966

Epoch: 5| Step: 5
Training loss: 2.056044340133667
Validation loss: 2.3996746668251614

Epoch: 5| Step: 6
Training loss: 2.175251007080078
Validation loss: 2.395090456931822

Epoch: 5| Step: 7
Training loss: 2.352839708328247
Validation loss: 2.3914347438402075

Epoch: 5| Step: 8
Training loss: 2.8713698387145996
Validation loss: 2.4076218605041504

Epoch: 5| Step: 9
Training loss: 3.0612423419952393
Validation loss: 2.4261228679328837

Epoch: 5| Step: 10
Training loss: 3.3703694343566895
Validation loss: 2.424704567078621

Epoch: 63| Step: 0
Training loss: 2.6144986152648926
Validation loss: 2.4401496020696496

Epoch: 5| Step: 1
Training loss: 2.5951361656188965
Validation loss: 2.4382758935292563

Epoch: 5| Step: 2
Training loss: 3.0947320461273193
Validation loss: 2.4280620416005454

Epoch: 5| Step: 3
Training loss: 2.6518447399139404
Validation loss: 2.4080498859446537

Epoch: 5| Step: 4
Training loss: 2.1228723526000977
Validation loss: 2.400242392734815

Epoch: 5| Step: 5
Training loss: 2.4059481620788574
Validation loss: 2.3951055362660396

Epoch: 5| Step: 6
Training loss: 3.3648681640625
Validation loss: 2.4029048950441423

Epoch: 5| Step: 7
Training loss: 2.827322006225586
Validation loss: 2.417793484144313

Epoch: 5| Step: 8
Training loss: 2.0186171531677246
Validation loss: 2.4238538049882457

Epoch: 5| Step: 9
Training loss: 2.513415813446045
Validation loss: 2.461899644585066

Epoch: 5| Step: 10
Training loss: 2.8653876781463623
Validation loss: 2.5040729353504796

Epoch: 64| Step: 0
Training loss: 2.9072890281677246
Validation loss: 2.5074215909486175

Epoch: 5| Step: 1
Training loss: 2.6013572216033936
Validation loss: 2.4926942522807787

Epoch: 5| Step: 2
Training loss: 2.1702077388763428
Validation loss: 2.4647884779078986

Epoch: 5| Step: 3
Training loss: 2.4363503456115723
Validation loss: 2.4365026027925554

Epoch: 5| Step: 4
Training loss: 2.703139305114746
Validation loss: 2.4225347093356553

Epoch: 5| Step: 5
Training loss: 2.378828525543213
Validation loss: 2.4125703073317006

Epoch: 5| Step: 6
Training loss: 2.6775717735290527
Validation loss: 2.4064971887937157

Epoch: 5| Step: 7
Training loss: 3.112628221511841
Validation loss: 2.410517359292635

Epoch: 5| Step: 8
Training loss: 2.638732433319092
Validation loss: 2.412180649336948

Epoch: 5| Step: 9
Training loss: 3.035626173019409
Validation loss: 2.412794333632274

Epoch: 5| Step: 10
Training loss: 2.3792238235473633
Validation loss: 2.423451041662565

Epoch: 65| Step: 0
Training loss: 2.070479154586792
Validation loss: 2.437468223674323

Epoch: 5| Step: 1
Training loss: 2.573448657989502
Validation loss: 2.4628307050274265

Epoch: 5| Step: 2
Training loss: 2.6235952377319336
Validation loss: 2.4568510542633715

Epoch: 5| Step: 3
Training loss: 2.953437328338623
Validation loss: 2.4559068782355196

Epoch: 5| Step: 4
Training loss: 2.3996243476867676
Validation loss: 2.4598818927682857

Epoch: 5| Step: 5
Training loss: 2.7334258556365967
Validation loss: 2.4460226361469557

Epoch: 5| Step: 6
Training loss: 2.6011276245117188
Validation loss: 2.4060024215329077

Epoch: 5| Step: 7
Training loss: 2.954153537750244
Validation loss: 2.3938180451752036

Epoch: 5| Step: 8
Training loss: 2.087125778198242
Validation loss: 2.378622337054181

Epoch: 5| Step: 9
Training loss: 2.5092930793762207
Validation loss: 2.3791108618500414

Epoch: 5| Step: 10
Training loss: 3.6173088550567627
Validation loss: 2.3794594246854066

Epoch: 66| Step: 0
Training loss: 2.452296495437622
Validation loss: 2.3805327082193024

Epoch: 5| Step: 1
Training loss: 3.204212188720703
Validation loss: 2.383928104113507

Epoch: 5| Step: 2
Training loss: 3.053893566131592
Validation loss: 2.381713495459608

Epoch: 5| Step: 3
Training loss: 2.7580461502075195
Validation loss: 2.3733130526799027

Epoch: 5| Step: 4
Training loss: 2.760929822921753
Validation loss: 2.3758869504415863

Epoch: 5| Step: 5
Training loss: 2.3077335357666016
Validation loss: 2.373081745639924

Epoch: 5| Step: 6
Training loss: 2.807255744934082
Validation loss: 2.3736669709605556

Epoch: 5| Step: 7
Training loss: 2.7626140117645264
Validation loss: 2.3720578173155427

Epoch: 5| Step: 8
Training loss: 2.6066734790802
Validation loss: 2.370903391991892

Epoch: 5| Step: 9
Training loss: 2.228644609451294
Validation loss: 2.375237016267674

Epoch: 5| Step: 10
Training loss: 1.954457402229309
Validation loss: 2.382142779647663

Epoch: 67| Step: 0
Training loss: 2.684636354446411
Validation loss: 2.3972092507987894

Epoch: 5| Step: 1
Training loss: 2.799032688140869
Validation loss: 2.4136957276252007

Epoch: 5| Step: 2
Training loss: 2.702223539352417
Validation loss: 2.4364373478838193

Epoch: 5| Step: 3
Training loss: 2.1939425468444824
Validation loss: 2.455276794331048

Epoch: 5| Step: 4
Training loss: 2.1444344520568848
Validation loss: 2.4715662771655666

Epoch: 5| Step: 5
Training loss: 2.813127279281616
Validation loss: 2.4554342762116463

Epoch: 5| Step: 6
Training loss: 2.3646178245544434
Validation loss: 2.419362809068413

Epoch: 5| Step: 7
Training loss: 3.456972599029541
Validation loss: 2.387744278036138

Epoch: 5| Step: 8
Training loss: 2.170097589492798
Validation loss: 2.3680956056041103

Epoch: 5| Step: 9
Training loss: 2.529390335083008
Validation loss: 2.3676226959433606

Epoch: 5| Step: 10
Training loss: 3.291036367416382
Validation loss: 2.3707664397455033

Epoch: 68| Step: 0
Training loss: 2.4521594047546387
Validation loss: 2.3831583158944243

Epoch: 5| Step: 1
Training loss: 3.028107166290283
Validation loss: 2.3889366401139127

Epoch: 5| Step: 2
Training loss: 2.6847972869873047
Validation loss: 2.3935900606134886

Epoch: 5| Step: 3
Training loss: 3.00290846824646
Validation loss: 2.394639180552575

Epoch: 5| Step: 4
Training loss: 2.400078296661377
Validation loss: 2.396931735418176

Epoch: 5| Step: 5
Training loss: 3.2949249744415283
Validation loss: 2.401058207276047

Epoch: 5| Step: 6
Training loss: 2.8089795112609863
Validation loss: 2.3995564958100677

Epoch: 5| Step: 7
Training loss: 1.719247817993164
Validation loss: 2.3977047653608423

Epoch: 5| Step: 8
Training loss: 2.0999884605407715
Validation loss: 2.3977985535898516

Epoch: 5| Step: 9
Training loss: 2.6672823429107666
Validation loss: 2.391700780519875

Epoch: 5| Step: 10
Training loss: 3.1914937496185303
Validation loss: 2.395002644549134

Epoch: 69| Step: 0
Training loss: 2.062893867492676
Validation loss: 2.383825881506807

Epoch: 5| Step: 1
Training loss: 2.297938108444214
Validation loss: 2.3767048364044516

Epoch: 5| Step: 2
Training loss: 1.8516204357147217
Validation loss: 2.3822790909838933

Epoch: 5| Step: 3
Training loss: 2.5349063873291016
Validation loss: 2.37582109051366

Epoch: 5| Step: 4
Training loss: 2.975954532623291
Validation loss: 2.3962571082576627

Epoch: 5| Step: 5
Training loss: 3.1099116802215576
Validation loss: 2.4558004897127867

Epoch: 5| Step: 6
Training loss: 2.7043867111206055
Validation loss: 2.542950020041517

Epoch: 5| Step: 7
Training loss: 2.7059712409973145
Validation loss: 2.6407597141881145

Epoch: 5| Step: 8
Training loss: 2.8747220039367676
Validation loss: 2.5783856017615205

Epoch: 5| Step: 9
Training loss: 2.927208423614502
Validation loss: 2.4825883091136975

Epoch: 5| Step: 10
Training loss: 3.154029369354248
Validation loss: 2.427369163882348

Epoch: 70| Step: 0
Training loss: 2.8538312911987305
Validation loss: 2.386163526965726

Epoch: 5| Step: 1
Training loss: 2.460890293121338
Validation loss: 2.3744273057547947

Epoch: 5| Step: 2
Training loss: 2.3181509971618652
Validation loss: 2.3656903620689147

Epoch: 5| Step: 3
Training loss: 2.4658939838409424
Validation loss: 2.3601732869302072

Epoch: 5| Step: 4
Training loss: 2.6877646446228027
Validation loss: 2.3610968589782715

Epoch: 5| Step: 5
Training loss: 2.5848898887634277
Validation loss: 2.3676455687451106

Epoch: 5| Step: 6
Training loss: 3.0258209705352783
Validation loss: 2.382385628197783

Epoch: 5| Step: 7
Training loss: 2.493365526199341
Validation loss: 2.3797583887653966

Epoch: 5| Step: 8
Training loss: 2.6761364936828613
Validation loss: 2.376822566473356

Epoch: 5| Step: 9
Training loss: 2.8117098808288574
Validation loss: 2.367779206204158

Epoch: 5| Step: 10
Training loss: 2.3332364559173584
Validation loss: 2.355025588825185

Epoch: 71| Step: 0
Training loss: 2.315864086151123
Validation loss: 2.3527070565890242

Epoch: 5| Step: 1
Training loss: 2.5314953327178955
Validation loss: 2.354619005674957

Epoch: 5| Step: 2
Training loss: 3.1917977333068848
Validation loss: 2.3567684132565736

Epoch: 5| Step: 3
Training loss: 2.755596160888672
Validation loss: 2.350474537059825

Epoch: 5| Step: 4
Training loss: 2.529287338256836
Validation loss: 2.3651961947000153

Epoch: 5| Step: 5
Training loss: 2.172827959060669
Validation loss: 2.375822595370713

Epoch: 5| Step: 6
Training loss: 2.98590087890625
Validation loss: 2.392300454519128

Epoch: 5| Step: 7
Training loss: 2.2841174602508545
Validation loss: 2.4023543109175978

Epoch: 5| Step: 8
Training loss: 3.095315933227539
Validation loss: 2.3983932566899124

Epoch: 5| Step: 9
Training loss: 2.638282537460327
Validation loss: 2.3903272690311557

Epoch: 5| Step: 10
Training loss: 2.363882064819336
Validation loss: 2.3818615380153862

Epoch: 72| Step: 0
Training loss: 2.7657408714294434
Validation loss: 2.3748860846283617

Epoch: 5| Step: 1
Training loss: 2.9386062622070312
Validation loss: 2.3605864663277902

Epoch: 5| Step: 2
Training loss: 3.208925724029541
Validation loss: 2.344690768949447

Epoch: 5| Step: 3
Training loss: 3.213488817214966
Validation loss: 2.3370746925312984

Epoch: 5| Step: 4
Training loss: 2.4569625854492188
Validation loss: 2.3359188046506656

Epoch: 5| Step: 5
Training loss: 2.6714930534362793
Validation loss: 2.3353266664730605

Epoch: 5| Step: 6
Training loss: 2.1582653522491455
Validation loss: 2.337917676535986

Epoch: 5| Step: 7
Training loss: 2.8682103157043457
Validation loss: 2.337615712996452

Epoch: 5| Step: 8
Training loss: 2.0495471954345703
Validation loss: 2.3384009932958953

Epoch: 5| Step: 9
Training loss: 2.072230339050293
Validation loss: 2.337424998642296

Epoch: 5| Step: 10
Training loss: 2.4086198806762695
Validation loss: 2.344103085097446

Epoch: 73| Step: 0
Training loss: 2.413936138153076
Validation loss: 2.3487047738926385

Epoch: 5| Step: 1
Training loss: 2.7950282096862793
Validation loss: 2.3479019134275374

Epoch: 5| Step: 2
Training loss: 2.5284409523010254
Validation loss: 2.3489738536137406

Epoch: 5| Step: 3
Training loss: 2.362697124481201
Validation loss: 2.3483939068291777

Epoch: 5| Step: 4
Training loss: 2.8544273376464844
Validation loss: 2.3495734122491654

Epoch: 5| Step: 5
Training loss: 2.6275107860565186
Validation loss: 2.348567837028093

Epoch: 5| Step: 6
Training loss: 3.107362747192383
Validation loss: 2.3360043776932584

Epoch: 5| Step: 7
Training loss: 2.5386691093444824
Validation loss: 2.332287432045065

Epoch: 5| Step: 8
Training loss: 2.4397919178009033
Validation loss: 2.3301953654135428

Epoch: 5| Step: 9
Training loss: 2.756767988204956
Validation loss: 2.329912913742886

Epoch: 5| Step: 10
Training loss: 2.093096971511841
Validation loss: 2.331581360550337

Epoch: 74| Step: 0
Training loss: 2.671074151992798
Validation loss: 2.334888051914912

Epoch: 5| Step: 1
Training loss: 2.825658082962036
Validation loss: 2.339966374058877

Epoch: 5| Step: 2
Training loss: 3.5413269996643066
Validation loss: 2.3428813924071608

Epoch: 5| Step: 3
Training loss: 2.275106430053711
Validation loss: 2.3445138367273475

Epoch: 5| Step: 4
Training loss: 2.531315326690674
Validation loss: 2.344010122360722

Epoch: 5| Step: 5
Training loss: 3.102386474609375
Validation loss: 2.3438417244982976

Epoch: 5| Step: 6
Training loss: 2.1952550411224365
Validation loss: 2.3431292759474887

Epoch: 5| Step: 7
Training loss: 2.486420154571533
Validation loss: 2.3436715115783033

Epoch: 5| Step: 8
Training loss: 2.221353530883789
Validation loss: 2.344143500892065

Epoch: 5| Step: 9
Training loss: 2.224332571029663
Validation loss: 2.344448366472798

Epoch: 5| Step: 10
Training loss: 2.9731616973876953
Validation loss: 2.3345653780045046

Epoch: 75| Step: 0
Training loss: 2.655637741088867
Validation loss: 2.3265654604922057

Epoch: 5| Step: 1
Training loss: 2.9034972190856934
Validation loss: 2.3212471995302426

Epoch: 5| Step: 2
Training loss: 2.8397786617279053
Validation loss: 2.3262662861936834

Epoch: 5| Step: 3
Training loss: 1.9985473155975342
Validation loss: 2.3282060187350035

Epoch: 5| Step: 4
Training loss: 3.1300714015960693
Validation loss: 2.3523031639796432

Epoch: 5| Step: 5
Training loss: 2.3792784214019775
Validation loss: 2.3454806086837605

Epoch: 5| Step: 6
Training loss: 2.4582793712615967
Validation loss: 2.3604967132691415

Epoch: 5| Step: 7
Training loss: 2.5670876502990723
Validation loss: 2.3619950843113724

Epoch: 5| Step: 8
Training loss: 2.47178316116333
Validation loss: 2.3493335605949484

Epoch: 5| Step: 9
Training loss: 3.099414348602295
Validation loss: 2.3432708914561937

Epoch: 5| Step: 10
Training loss: 2.090294361114502
Validation loss: 2.3479956606382966

Epoch: 76| Step: 0
Training loss: 2.7486462593078613
Validation loss: 2.3361290911192536

Epoch: 5| Step: 1
Training loss: 2.714430570602417
Validation loss: 2.334754566992483

Epoch: 5| Step: 2
Training loss: 2.469350576400757
Validation loss: 2.333318205289943

Epoch: 5| Step: 3
Training loss: 2.265577793121338
Validation loss: 2.348014067578059

Epoch: 5| Step: 4
Training loss: 2.991631031036377
Validation loss: 2.3727939769785893

Epoch: 5| Step: 5
Training loss: 2.3972725868225098
Validation loss: 2.414839447185557

Epoch: 5| Step: 6
Training loss: 2.2966930866241455
Validation loss: 2.3920259219343945

Epoch: 5| Step: 7
Training loss: 2.5583291053771973
Validation loss: 2.3603031712193645

Epoch: 5| Step: 8
Training loss: 2.965130567550659
Validation loss: 2.330679896057293

Epoch: 5| Step: 9
Training loss: 2.568681478500366
Validation loss: 2.3324646744676816

Epoch: 5| Step: 10
Training loss: 2.622528553009033
Validation loss: 2.323494145947118

Epoch: 77| Step: 0
Training loss: 2.1429877281188965
Validation loss: 2.3217957891443723

Epoch: 5| Step: 1
Training loss: 2.535792827606201
Validation loss: 2.3185109861435427

Epoch: 5| Step: 2
Training loss: 2.6478652954101562
Validation loss: 2.334421160400555

Epoch: 5| Step: 3
Training loss: 2.8881657123565674
Validation loss: 2.333376129468282

Epoch: 5| Step: 4
Training loss: 2.6176156997680664
Validation loss: 2.3396313344278643

Epoch: 5| Step: 5
Training loss: 2.3137707710266113
Validation loss: 2.3424085776011148

Epoch: 5| Step: 6
Training loss: 2.334916591644287
Validation loss: 2.340912298489642

Epoch: 5| Step: 7
Training loss: 3.0303597450256348
Validation loss: 2.3387388977953183

Epoch: 5| Step: 8
Training loss: 2.549959659576416
Validation loss: 2.3251128324898342

Epoch: 5| Step: 9
Training loss: 2.6996102333068848
Validation loss: 2.353268802806895

Epoch: 5| Step: 10
Training loss: 2.977421283721924
Validation loss: 2.417819341023763

Epoch: 78| Step: 0
Training loss: 2.501337766647339
Validation loss: 2.3775597387744534

Epoch: 5| Step: 1
Training loss: 2.3184072971343994
Validation loss: 2.347669288676272

Epoch: 5| Step: 2
Training loss: 2.240283966064453
Validation loss: 2.331076688663934

Epoch: 5| Step: 3
Training loss: 2.8201212882995605
Validation loss: 2.320688832190729

Epoch: 5| Step: 4
Training loss: 2.5417368412017822
Validation loss: 2.320035816520773

Epoch: 5| Step: 5
Training loss: 3.0687038898468018
Validation loss: 2.31728837566991

Epoch: 5| Step: 6
Training loss: 3.0436105728149414
Validation loss: 2.322274931015507

Epoch: 5| Step: 7
Training loss: 2.056067705154419
Validation loss: 2.325870426752234

Epoch: 5| Step: 8
Training loss: 2.6815285682678223
Validation loss: 2.347755491092641

Epoch: 5| Step: 9
Training loss: 2.0804359912872314
Validation loss: 2.3398336723286617

Epoch: 5| Step: 10
Training loss: 3.0775935649871826
Validation loss: 2.3359187879870014

Epoch: 79| Step: 0
Training loss: 2.81779146194458
Validation loss: 2.3242555510613228

Epoch: 5| Step: 1
Training loss: 2.8602352142333984
Validation loss: 2.320261937315746

Epoch: 5| Step: 2
Training loss: 3.381007432937622
Validation loss: 2.318649127919187

Epoch: 5| Step: 3
Training loss: 2.1927542686462402
Validation loss: 2.3095868736185055

Epoch: 5| Step: 4
Training loss: 2.0188965797424316
Validation loss: 2.3050326070477887

Epoch: 5| Step: 5
Training loss: 2.8585948944091797
Validation loss: 2.322468976820669

Epoch: 5| Step: 6
Training loss: 2.533032178878784
Validation loss: 2.3421968824119976

Epoch: 5| Step: 7
Training loss: 2.278729200363159
Validation loss: 2.329925178199686

Epoch: 5| Step: 8
Training loss: 2.8555855751037598
Validation loss: 2.3087887815249863

Epoch: 5| Step: 9
Training loss: 2.3442771434783936
Validation loss: 2.3015314532864477

Epoch: 5| Step: 10
Training loss: 2.136143684387207
Validation loss: 2.302100996817312

Epoch: 80| Step: 0
Training loss: 2.6000561714172363
Validation loss: 2.3244145941990677

Epoch: 5| Step: 1
Training loss: 2.950894594192505
Validation loss: 2.3467888601364626

Epoch: 5| Step: 2
Training loss: 2.1150383949279785
Validation loss: 2.350646516328217

Epoch: 5| Step: 3
Training loss: 2.9689574241638184
Validation loss: 2.369116488323417

Epoch: 5| Step: 4
Training loss: 2.9547078609466553
Validation loss: 2.3609361699832383

Epoch: 5| Step: 5
Training loss: 2.3135945796966553
Validation loss: 2.3524285926613757

Epoch: 5| Step: 6
Training loss: 2.815208911895752
Validation loss: 2.359819450686055

Epoch: 5| Step: 7
Training loss: 2.1848301887512207
Validation loss: 2.3732183466675463

Epoch: 5| Step: 8
Training loss: 2.601198673248291
Validation loss: 2.362902541314402

Epoch: 5| Step: 9
Training loss: 2.0770885944366455
Validation loss: 2.3224442171794113

Epoch: 5| Step: 10
Training loss: 2.7885894775390625
Validation loss: 2.321091736516645

Epoch: 81| Step: 0
Training loss: 2.3863744735717773
Validation loss: 2.309248901182605

Epoch: 5| Step: 1
Training loss: 2.5311238765716553
Validation loss: 2.3002053999131724

Epoch: 5| Step: 2
Training loss: 1.98737370967865
Validation loss: 2.3256295316962787

Epoch: 5| Step: 3
Training loss: 2.697169303894043
Validation loss: 2.3189823473653486

Epoch: 5| Step: 4
Training loss: 2.4872169494628906
Validation loss: 2.319481506142565

Epoch: 5| Step: 5
Training loss: 2.4958126544952393
Validation loss: 2.307092361552741

Epoch: 5| Step: 6
Training loss: 2.8447062969207764
Validation loss: 2.3036003779339533

Epoch: 5| Step: 7
Training loss: 2.744396448135376
Validation loss: 2.2958211860349103

Epoch: 5| Step: 8
Training loss: 2.254584789276123
Validation loss: 2.299329573108304

Epoch: 5| Step: 9
Training loss: 2.8813960552215576
Validation loss: 2.2963218124963904

Epoch: 5| Step: 10
Training loss: 3.1414737701416016
Validation loss: 2.3041465282440186

Epoch: 82| Step: 0
Training loss: 1.7722759246826172
Validation loss: 2.308885979396041

Epoch: 5| Step: 1
Training loss: 2.9540507793426514
Validation loss: 2.331799594304895

Epoch: 5| Step: 2
Training loss: 3.0330650806427
Validation loss: 2.336826862827424

Epoch: 5| Step: 3
Training loss: 2.2420754432678223
Validation loss: 2.3323423631729616

Epoch: 5| Step: 4
Training loss: 2.497905969619751
Validation loss: 2.3235851551896785

Epoch: 5| Step: 5
Training loss: 2.839676856994629
Validation loss: 2.324744742403748

Epoch: 5| Step: 6
Training loss: 2.3585071563720703
Validation loss: 2.327308313820952

Epoch: 5| Step: 7
Training loss: 2.298870801925659
Validation loss: 2.312927605003439

Epoch: 5| Step: 8
Training loss: 2.7234315872192383
Validation loss: 2.32084233273742

Epoch: 5| Step: 9
Training loss: 2.536116123199463
Validation loss: 2.3065653436927387

Epoch: 5| Step: 10
Training loss: 2.93788480758667
Validation loss: 2.303136723015898

Epoch: 83| Step: 0
Training loss: 2.5145344734191895
Validation loss: 2.292299735930658

Epoch: 5| Step: 1
Training loss: 2.805194139480591
Validation loss: 2.2829249879365325

Epoch: 5| Step: 2
Training loss: 2.0213663578033447
Validation loss: 2.2683038480820192

Epoch: 5| Step: 3
Training loss: 2.1122491359710693
Validation loss: 2.264463505437297

Epoch: 5| Step: 4
Training loss: 2.38350510597229
Validation loss: 2.2791022716029996

Epoch: 5| Step: 5
Training loss: 2.8735437393188477
Validation loss: 2.2868842770976405

Epoch: 5| Step: 6
Training loss: 2.6962666511535645
Validation loss: 2.2956204568186114

Epoch: 5| Step: 7
Training loss: 3.004319429397583
Validation loss: 2.2967986291454685

Epoch: 5| Step: 8
Training loss: 2.677623748779297
Validation loss: 2.2945124538995887

Epoch: 5| Step: 9
Training loss: 2.9089865684509277
Validation loss: 2.287167215860018

Epoch: 5| Step: 10
Training loss: 2.6812644004821777
Validation loss: 2.284879699830086

Epoch: 84| Step: 0
Training loss: 2.38254451751709
Validation loss: 2.2926817914491058

Epoch: 5| Step: 1
Training loss: 3.037308931350708
Validation loss: 2.302967384297361

Epoch: 5| Step: 2
Training loss: 2.9379525184631348
Validation loss: 2.313126051297752

Epoch: 5| Step: 3
Training loss: 2.117372989654541
Validation loss: 2.3352190909847135

Epoch: 5| Step: 4
Training loss: 2.3786213397979736
Validation loss: 2.312102953592936

Epoch: 5| Step: 5
Training loss: 2.652700424194336
Validation loss: 2.288352399744013

Epoch: 5| Step: 6
Training loss: 3.060377836227417
Validation loss: 2.2743601619556384

Epoch: 5| Step: 7
Training loss: 2.9399657249450684
Validation loss: 2.271330110488399

Epoch: 5| Step: 8
Training loss: 2.3056540489196777
Validation loss: 2.2769999452816543

Epoch: 5| Step: 9
Training loss: 2.397449016571045
Validation loss: 2.2783517401705504

Epoch: 5| Step: 10
Training loss: 1.8745118379592896
Validation loss: 2.2773818533907653

Epoch: 85| Step: 0
Training loss: 2.951197385787964
Validation loss: 2.2964888759838638

Epoch: 5| Step: 1
Training loss: 2.792475461959839
Validation loss: 2.3088068346823416

Epoch: 5| Step: 2
Training loss: 1.9491859674453735
Validation loss: 2.3057730044088056

Epoch: 5| Step: 3
Training loss: 2.6986145973205566
Validation loss: 2.3371519721964353

Epoch: 5| Step: 4
Training loss: 2.407987594604492
Validation loss: 2.3884314029447493

Epoch: 5| Step: 5
Training loss: 2.6142826080322266
Validation loss: 2.398271092804529

Epoch: 5| Step: 6
Training loss: 2.474236011505127
Validation loss: 2.3752609811803347

Epoch: 5| Step: 7
Training loss: 2.3817460536956787
Validation loss: 2.3684429712192987

Epoch: 5| Step: 8
Training loss: 2.4148831367492676
Validation loss: 2.31326989717381

Epoch: 5| Step: 9
Training loss: 2.67138934135437
Validation loss: 2.305130727829472

Epoch: 5| Step: 10
Training loss: 2.9315967559814453
Validation loss: 2.312028446505147

Epoch: 86| Step: 0
Training loss: 2.59061861038208
Validation loss: 2.3089038402803483

Epoch: 5| Step: 1
Training loss: 2.495258092880249
Validation loss: 2.3001217252464703

Epoch: 5| Step: 2
Training loss: 2.230498790740967
Validation loss: 2.2874384054573635

Epoch: 5| Step: 3
Training loss: 2.1407017707824707
Validation loss: 2.2916899701600433

Epoch: 5| Step: 4
Training loss: 2.935153007507324
Validation loss: 2.28808529146256

Epoch: 5| Step: 5
Training loss: 3.2210259437561035
Validation loss: 2.2829266171301565

Epoch: 5| Step: 6
Training loss: 1.5253862142562866
Validation loss: 2.2784224197428715

Epoch: 5| Step: 7
Training loss: 2.418297529220581
Validation loss: 2.2753878793408795

Epoch: 5| Step: 8
Training loss: 3.0107007026672363
Validation loss: 2.2681342094175276

Epoch: 5| Step: 9
Training loss: 3.2964587211608887
Validation loss: 2.2585889472756335

Epoch: 5| Step: 10
Training loss: 2.6106135845184326
Validation loss: 2.248942054728026

Epoch: 87| Step: 0
Training loss: 2.366708517074585
Validation loss: 2.244761238815964

Epoch: 5| Step: 1
Training loss: 2.216228485107422
Validation loss: 2.244800147189889

Epoch: 5| Step: 2
Training loss: 2.6755244731903076
Validation loss: 2.257842666359358

Epoch: 5| Step: 3
Training loss: 2.5022599697113037
Validation loss: 2.2614659955424647

Epoch: 5| Step: 4
Training loss: 2.3038430213928223
Validation loss: 2.2891332436633367

Epoch: 5| Step: 5
Training loss: 3.0091452598571777
Validation loss: 2.323178909158194

Epoch: 5| Step: 6
Training loss: 2.2364425659179688
Validation loss: 2.3622228099453833

Epoch: 5| Step: 7
Training loss: 2.55293869972229
Validation loss: 2.370477455918507

Epoch: 5| Step: 8
Training loss: 3.12106990814209
Validation loss: 2.387341263473675

Epoch: 5| Step: 9
Training loss: 2.1621816158294678
Validation loss: 2.3406106015687347

Epoch: 5| Step: 10
Training loss: 3.0332772731781006
Validation loss: 2.3088619670560284

Epoch: 88| Step: 0
Training loss: 2.693246364593506
Validation loss: 2.2774355103892665

Epoch: 5| Step: 1
Training loss: 2.7324163913726807
Validation loss: 2.2559793174907727

Epoch: 5| Step: 2
Training loss: 2.182704210281372
Validation loss: 2.249970859096896

Epoch: 5| Step: 3
Training loss: 2.4608302116394043
Validation loss: 2.2439934771548034

Epoch: 5| Step: 4
Training loss: 2.5660483837127686
Validation loss: 2.2463586125322568

Epoch: 5| Step: 5
Training loss: 2.0911545753479004
Validation loss: 2.2388575346239152

Epoch: 5| Step: 6
Training loss: 2.8508036136627197
Validation loss: 2.247123308079217

Epoch: 5| Step: 7
Training loss: 2.7639870643615723
Validation loss: 2.2459253098375056

Epoch: 5| Step: 8
Training loss: 2.412834644317627
Validation loss: 2.244475159593808

Epoch: 5| Step: 9
Training loss: 2.864356517791748
Validation loss: 2.242763980742424

Epoch: 5| Step: 10
Training loss: 2.3235087394714355
Validation loss: 2.2456551341600317

Epoch: 89| Step: 0
Training loss: 2.8725361824035645
Validation loss: 2.2398225440773913

Epoch: 5| Step: 1
Training loss: 2.3463051319122314
Validation loss: 2.2407670123602754

Epoch: 5| Step: 2
Training loss: 2.6622421741485596
Validation loss: 2.2421806396976596

Epoch: 5| Step: 3
Training loss: 2.75327467918396
Validation loss: 2.242823238013893

Epoch: 5| Step: 4
Training loss: 2.4211885929107666
Validation loss: 2.24305223905912

Epoch: 5| Step: 5
Training loss: 2.57995867729187
Validation loss: 2.2387982286432737

Epoch: 5| Step: 6
Training loss: 2.3686039447784424
Validation loss: 2.239482197710263

Epoch: 5| Step: 7
Training loss: 2.459523916244507
Validation loss: 2.247976128773023

Epoch: 5| Step: 8
Training loss: 2.4955251216888428
Validation loss: 2.2582781801941576

Epoch: 5| Step: 9
Training loss: 2.366849660873413
Validation loss: 2.258606254413564

Epoch: 5| Step: 10
Training loss: 2.468463182449341
Validation loss: 2.283784204913724

Epoch: 90| Step: 0
Training loss: 2.9469528198242188
Validation loss: 2.3006360171943583

Epoch: 5| Step: 1
Training loss: 2.0624852180480957
Validation loss: 2.2976336684278262

Epoch: 5| Step: 2
Training loss: 2.529318332672119
Validation loss: 2.26593683099234

Epoch: 5| Step: 3
Training loss: 2.6625285148620605
Validation loss: 2.2621156092612975

Epoch: 5| Step: 4
Training loss: 2.176706314086914
Validation loss: 2.25349485745994

Epoch: 5| Step: 5
Training loss: 2.766019105911255
Validation loss: 2.245994326888874

Epoch: 5| Step: 6
Training loss: 2.5671589374542236
Validation loss: 2.23869151197454

Epoch: 5| Step: 7
Training loss: 3.1642026901245117
Validation loss: 2.2388916925717424

Epoch: 5| Step: 8
Training loss: 2.463364839553833
Validation loss: 2.2390656842980334

Epoch: 5| Step: 9
Training loss: 2.9355742931365967
Validation loss: 2.241492450878184

Epoch: 5| Step: 10
Training loss: 1.464977502822876
Validation loss: 2.2422933988673712

Epoch: 91| Step: 0
Training loss: 2.3687996864318848
Validation loss: 2.25208883131704

Epoch: 5| Step: 1
Training loss: 2.7787723541259766
Validation loss: 2.257900745637955

Epoch: 5| Step: 2
Training loss: 2.480722665786743
Validation loss: 2.2741125834885465

Epoch: 5| Step: 3
Training loss: 2.6093297004699707
Validation loss: 2.314696435005434

Epoch: 5| Step: 4
Training loss: 2.726287603378296
Validation loss: 2.318574061957739

Epoch: 5| Step: 5
Training loss: 2.051136016845703
Validation loss: 2.328931180379724

Epoch: 5| Step: 6
Training loss: 2.7729618549346924
Validation loss: 2.3591484049315095

Epoch: 5| Step: 7
Training loss: 3.2723822593688965
Validation loss: 2.38438085843158

Epoch: 5| Step: 8
Training loss: 2.1660609245300293
Validation loss: 2.379388045239192

Epoch: 5| Step: 9
Training loss: 2.7805795669555664
Validation loss: 2.354832447985167

Epoch: 5| Step: 10
Training loss: 1.9350388050079346
Validation loss: 2.3338023821512857

Epoch: 92| Step: 0
Training loss: 2.6648201942443848
Validation loss: 2.3067711117447063

Epoch: 5| Step: 1
Training loss: 2.688657283782959
Validation loss: 2.2758025507773123

Epoch: 5| Step: 2
Training loss: 2.9085280895233154
Validation loss: 2.2643006181204193

Epoch: 5| Step: 3
Training loss: 2.5413663387298584
Validation loss: 2.255888515903104

Epoch: 5| Step: 4
Training loss: 2.476780414581299
Validation loss: 2.2434732824243526

Epoch: 5| Step: 5
Training loss: 2.0412228107452393
Validation loss: 2.2468887785429597

Epoch: 5| Step: 6
Training loss: 1.670310378074646
Validation loss: 2.242147437987789

Epoch: 5| Step: 7
Training loss: 2.324291467666626
Validation loss: 2.2454102834065757

Epoch: 5| Step: 8
Training loss: 3.4542064666748047
Validation loss: 2.284830090820148

Epoch: 5| Step: 9
Training loss: 3.0909388065338135
Validation loss: 2.329883155002389

Epoch: 5| Step: 10
Training loss: 2.1327953338623047
Validation loss: 2.2540915755815405

Epoch: 93| Step: 0
Training loss: 2.6109840869903564
Validation loss: 2.240151128461284

Epoch: 5| Step: 1
Training loss: 3.229762315750122
Validation loss: 2.2376095992262646

Epoch: 5| Step: 2
Training loss: 2.339841365814209
Validation loss: 2.2265916280849005

Epoch: 5| Step: 3
Training loss: 2.1998708248138428
Validation loss: 2.2202367705683552

Epoch: 5| Step: 4
Training loss: 2.2022125720977783
Validation loss: 2.2197183178317164

Epoch: 5| Step: 5
Training loss: 2.4940712451934814
Validation loss: 2.2218859298254854

Epoch: 5| Step: 6
Training loss: 2.6179378032684326
Validation loss: 2.241984095624698

Epoch: 5| Step: 7
Training loss: 2.865741014480591
Validation loss: 2.2418802566425775

Epoch: 5| Step: 8
Training loss: 2.9560036659240723
Validation loss: 2.2550044982664046

Epoch: 5| Step: 9
Training loss: 2.074505090713501
Validation loss: 2.268495541746898

Epoch: 5| Step: 10
Training loss: 2.285714626312256
Validation loss: 2.3017750222195863

Epoch: 94| Step: 0
Training loss: 2.867034435272217
Validation loss: 2.317248514903489

Epoch: 5| Step: 1
Training loss: 2.482377052307129
Validation loss: 2.2769834841451337

Epoch: 5| Step: 2
Training loss: 2.2635021209716797
Validation loss: 2.281034977205338

Epoch: 5| Step: 3
Training loss: 3.0774118900299072
Validation loss: 2.272044527915216

Epoch: 5| Step: 4
Training loss: 2.626312017440796
Validation loss: 2.269943032213437

Epoch: 5| Step: 5
Training loss: 2.0316286087036133
Validation loss: 2.2926165596131356

Epoch: 5| Step: 6
Training loss: 2.2825655937194824
Validation loss: 2.2961621105030017

Epoch: 5| Step: 7
Training loss: 2.3547160625457764
Validation loss: 2.265159224951139

Epoch: 5| Step: 8
Training loss: 2.431030750274658
Validation loss: 2.251272552756853

Epoch: 5| Step: 9
Training loss: 2.2013301849365234
Validation loss: 2.253422455121112

Epoch: 5| Step: 10
Training loss: 3.0145130157470703
Validation loss: 2.247020552235265

Epoch: 95| Step: 0
Training loss: 2.649528980255127
Validation loss: 2.253240899373126

Epoch: 5| Step: 1
Training loss: 2.232957363128662
Validation loss: 2.26448046007464

Epoch: 5| Step: 2
Training loss: 2.7464401721954346
Validation loss: 2.262009010520033

Epoch: 5| Step: 3
Training loss: 2.7832064628601074
Validation loss: 2.251915631755706

Epoch: 5| Step: 4
Training loss: 2.1289455890655518
Validation loss: 2.250934144502045

Epoch: 5| Step: 5
Training loss: 3.2538928985595703
Validation loss: 2.2489530988918838

Epoch: 5| Step: 6
Training loss: 2.217053174972534
Validation loss: 2.2443733676787345

Epoch: 5| Step: 7
Training loss: 2.7771594524383545
Validation loss: 2.239109312334368

Epoch: 5| Step: 8
Training loss: 1.7140610218048096
Validation loss: 2.2378978267792733

Epoch: 5| Step: 9
Training loss: 1.908413290977478
Validation loss: 2.234007530314948

Epoch: 5| Step: 10
Training loss: 3.2053427696228027
Validation loss: 2.234489761373048

Epoch: 96| Step: 0
Training loss: 2.5334274768829346
Validation loss: 2.2384371116597164

Epoch: 5| Step: 1
Training loss: 2.5767297744750977
Validation loss: 2.2340884836771155

Epoch: 5| Step: 2
Training loss: 2.3597254753112793
Validation loss: 2.2354542106710453

Epoch: 5| Step: 3
Training loss: 3.387467861175537
Validation loss: 2.2250656517603065

Epoch: 5| Step: 4
Training loss: 1.9507265090942383
Validation loss: 2.2227315915528165

Epoch: 5| Step: 5
Training loss: 2.137122631072998
Validation loss: 2.2227279652831373

Epoch: 5| Step: 6
Training loss: 2.289456844329834
Validation loss: 2.2183316753756617

Epoch: 5| Step: 7
Training loss: 2.012836456298828
Validation loss: 2.221037757012152

Epoch: 5| Step: 8
Training loss: 2.952704668045044
Validation loss: 2.2437147401994273

Epoch: 5| Step: 9
Training loss: 2.794203281402588
Validation loss: 2.2575360728848364

Epoch: 5| Step: 10
Training loss: 2.469470262527466
Validation loss: 2.2835327374037875

Epoch: 97| Step: 0
Training loss: 2.137450695037842
Validation loss: 2.2951155349772465

Epoch: 5| Step: 1
Training loss: 2.3338265419006348
Validation loss: 2.289737783452516

Epoch: 5| Step: 2
Training loss: 2.771260976791382
Validation loss: 2.2763990150984896

Epoch: 5| Step: 3
Training loss: 2.5510413646698
Validation loss: 2.2686360087445987

Epoch: 5| Step: 4
Training loss: 2.459106922149658
Validation loss: 2.2565967895651378

Epoch: 5| Step: 5
Training loss: 2.495293378829956
Validation loss: 2.2667116542016306

Epoch: 5| Step: 6
Training loss: 2.8289568424224854
Validation loss: 2.262699891162175

Epoch: 5| Step: 7
Training loss: 2.869319438934326
Validation loss: 2.2741176543697232

Epoch: 5| Step: 8
Training loss: 2.8402316570281982
Validation loss: 2.270510653013824

Epoch: 5| Step: 9
Training loss: 1.983833909034729
Validation loss: 2.2790082013735207

Epoch: 5| Step: 10
Training loss: 2.3517894744873047
Validation loss: 2.286809916137367

Epoch: 98| Step: 0
Training loss: 2.2147860527038574
Validation loss: 2.2571801857281755

Epoch: 5| Step: 1
Training loss: 2.2004966735839844
Validation loss: 2.232151690349784

Epoch: 5| Step: 2
Training loss: 3.014816999435425
Validation loss: 2.216190243280062

Epoch: 5| Step: 3
Training loss: 1.744598150253296
Validation loss: 2.2058139257533576

Epoch: 5| Step: 4
Training loss: 2.869741916656494
Validation loss: 2.2052044445468533

Epoch: 5| Step: 5
Training loss: 2.5701210498809814
Validation loss: 2.210478905708559

Epoch: 5| Step: 6
Training loss: 2.7018980979919434
Validation loss: 2.2118455107494066

Epoch: 5| Step: 7
Training loss: 2.6799416542053223
Validation loss: 2.2137198576363186

Epoch: 5| Step: 8
Training loss: 2.626052141189575
Validation loss: 2.204588523475073

Epoch: 5| Step: 9
Training loss: 2.176471471786499
Validation loss: 2.2000363001259426

Epoch: 5| Step: 10
Training loss: 2.510117292404175
Validation loss: 2.201262871424357

Epoch: 99| Step: 0
Training loss: 2.195265531539917
Validation loss: 2.1990397976290796

Epoch: 5| Step: 1
Training loss: 2.239631175994873
Validation loss: 2.1923208031603085

Epoch: 5| Step: 2
Training loss: 2.6136250495910645
Validation loss: 2.198710374934699

Epoch: 5| Step: 3
Training loss: 3.073965072631836
Validation loss: 2.2032335009626163

Epoch: 5| Step: 4
Training loss: 2.2400460243225098
Validation loss: 2.210513030329058

Epoch: 5| Step: 5
Training loss: 2.182863712310791
Validation loss: 2.1945152423715077

Epoch: 5| Step: 6
Training loss: 2.7031102180480957
Validation loss: 2.211936876338015

Epoch: 5| Step: 7
Training loss: 2.54960298538208
Validation loss: 2.2199291093375093

Epoch: 5| Step: 8
Training loss: 2.6396567821502686
Validation loss: 2.226301634183494

Epoch: 5| Step: 9
Training loss: 2.4737401008605957
Validation loss: 2.2690137432467554

Epoch: 5| Step: 10
Training loss: 2.39327335357666
Validation loss: 2.2954690187208113

Epoch: 100| Step: 0
Training loss: 2.104668617248535
Validation loss: 2.3370815528336393

Epoch: 5| Step: 1
Training loss: 2.442375659942627
Validation loss: 2.379157832873765

Epoch: 5| Step: 2
Training loss: 2.4595909118652344
Validation loss: 2.3666909663907942

Epoch: 5| Step: 3
Training loss: 2.611588716506958
Validation loss: 2.362135115490165

Epoch: 5| Step: 4
Training loss: 2.721574306488037
Validation loss: 2.3346621131384246

Epoch: 5| Step: 5
Training loss: 3.080256938934326
Validation loss: 2.3017333553683375

Epoch: 5| Step: 6
Training loss: 2.334506034851074
Validation loss: 2.2734226539570797

Epoch: 5| Step: 7
Training loss: 2.0788331031799316
Validation loss: 2.244954873156804

Epoch: 5| Step: 8
Training loss: 2.542128324508667
Validation loss: 2.2296535199688328

Epoch: 5| Step: 9
Training loss: 2.6486575603485107
Validation loss: 2.2212088313153995

Epoch: 5| Step: 10
Training loss: 2.59722900390625
Validation loss: 2.2233088195964856

Epoch: 101| Step: 0
Training loss: 2.6899991035461426
Validation loss: 2.219162110359438

Epoch: 5| Step: 1
Training loss: 2.5065884590148926
Validation loss: 2.2209095442166893

Epoch: 5| Step: 2
Training loss: 2.8372318744659424
Validation loss: 2.2168287974531933

Epoch: 5| Step: 3
Training loss: 3.3548684120178223
Validation loss: 2.195550139232348

Epoch: 5| Step: 4
Training loss: 1.723004937171936
Validation loss: 2.1803592276829544

Epoch: 5| Step: 5
Training loss: 2.4543166160583496
Validation loss: 2.175858856529318

Epoch: 5| Step: 6
Training loss: 1.6462621688842773
Validation loss: 2.172775281372891

Epoch: 5| Step: 7
Training loss: 2.7295212745666504
Validation loss: 2.192555853115615

Epoch: 5| Step: 8
Training loss: 2.051466464996338
Validation loss: 2.241068393953385

Epoch: 5| Step: 9
Training loss: 2.639028310775757
Validation loss: 2.270438737766717

Epoch: 5| Step: 10
Training loss: 2.88725209236145
Validation loss: 2.29941991836794

Epoch: 102| Step: 0
Training loss: 2.8078582286834717
Validation loss: 2.275160430580057

Epoch: 5| Step: 1
Training loss: 2.767056703567505
Validation loss: 2.2235127931000083

Epoch: 5| Step: 2
Training loss: 2.1470139026641846
Validation loss: 2.196894253453901

Epoch: 5| Step: 3
Training loss: 2.3546085357666016
Validation loss: 2.1769656109553512

Epoch: 5| Step: 4
Training loss: 2.7654807567596436
Validation loss: 2.1774045011048675

Epoch: 5| Step: 5
Training loss: 2.5725414752960205
Validation loss: 2.1770291712976273

Epoch: 5| Step: 6
Training loss: 2.3022048473358154
Validation loss: 2.1773863838564966

Epoch: 5| Step: 7
Training loss: 2.7604992389678955
Validation loss: 2.1847487188154653

Epoch: 5| Step: 8
Training loss: 2.3302299976348877
Validation loss: 2.180635698380009

Epoch: 5| Step: 9
Training loss: 2.377042293548584
Validation loss: 2.190343403047131

Epoch: 5| Step: 10
Training loss: 2.426603317260742
Validation loss: 2.194804996572515

Epoch: 103| Step: 0
Training loss: 2.6945347785949707
Validation loss: 2.1943624275986866

Epoch: 5| Step: 1
Training loss: 2.0884623527526855
Validation loss: 2.210790564936976

Epoch: 5| Step: 2
Training loss: 3.0801234245300293
Validation loss: 2.2448743158771145

Epoch: 5| Step: 3
Training loss: 2.681446075439453
Validation loss: 2.2656931210589666

Epoch: 5| Step: 4
Training loss: 2.3813323974609375
Validation loss: 2.2843069235483804

Epoch: 5| Step: 5
Training loss: 2.5586063861846924
Validation loss: 2.2869235238721295

Epoch: 5| Step: 6
Training loss: 2.522350549697876
Validation loss: 2.317245283434468

Epoch: 5| Step: 7
Training loss: 2.4287354946136475
Validation loss: 2.3451668805973505

Epoch: 5| Step: 8
Training loss: 2.2983388900756836
Validation loss: 2.3652345800912506

Epoch: 5| Step: 9
Training loss: 2.632568597793579
Validation loss: 2.407146223129765

Epoch: 5| Step: 10
Training loss: 2.360323667526245
Validation loss: 2.395201239534604

Epoch: 104| Step: 0
Training loss: 2.6813485622406006
Validation loss: 2.345475478838849

Epoch: 5| Step: 1
Training loss: 2.2927393913269043
Validation loss: 2.287115417500978

Epoch: 5| Step: 2
Training loss: 2.8371965885162354
Validation loss: 2.2423552531068043

Epoch: 5| Step: 3
Training loss: 2.5220353603363037
Validation loss: 2.2133872867912374

Epoch: 5| Step: 4
Training loss: 2.657884120941162
Validation loss: 2.2011866210609354

Epoch: 5| Step: 5
Training loss: 1.4511075019836426
Validation loss: 2.2031102103571736

Epoch: 5| Step: 6
Training loss: 3.0076212882995605
Validation loss: 2.18937365470394

Epoch: 5| Step: 7
Training loss: 1.6486631631851196
Validation loss: 2.1943270442306355

Epoch: 5| Step: 8
Training loss: 2.8558201789855957
Validation loss: 2.1964636874455277

Epoch: 5| Step: 9
Training loss: 2.5117697715759277
Validation loss: 2.1997090334533365

Epoch: 5| Step: 10
Training loss: 3.075202465057373
Validation loss: 2.197849994064659

Epoch: 105| Step: 0
Training loss: 2.5297698974609375
Validation loss: 2.1887129070938274

Epoch: 5| Step: 1
Training loss: 3.185492992401123
Validation loss: 2.1821612670857418

Epoch: 5| Step: 2
Training loss: 2.3727097511291504
Validation loss: 2.182711806348575

Epoch: 5| Step: 3
Training loss: 2.434445858001709
Validation loss: 2.1722276172330304

Epoch: 5| Step: 4
Training loss: 2.9197821617126465
Validation loss: 2.178043967934065

Epoch: 5| Step: 5
Training loss: 2.2537789344787598
Validation loss: 2.1742150322083504

Epoch: 5| Step: 6
Training loss: 2.659636974334717
Validation loss: 2.1785013239870787

Epoch: 5| Step: 7
Training loss: 2.676182508468628
Validation loss: 2.172201079706992

Epoch: 5| Step: 8
Training loss: 2.146667003631592
Validation loss: 2.1545724791865193

Epoch: 5| Step: 9
Training loss: 2.1504147052764893
Validation loss: 2.1545351371970227

Epoch: 5| Step: 10
Training loss: 1.917273998260498
Validation loss: 2.1498277392438663

Epoch: 106| Step: 0
Training loss: 2.556331157684326
Validation loss: 2.1508981027910785

Epoch: 5| Step: 1
Training loss: 2.541037082672119
Validation loss: 2.14803433674638

Epoch: 5| Step: 2
Training loss: 2.639587879180908
Validation loss: 2.154464114096857

Epoch: 5| Step: 3
Training loss: 2.527855396270752
Validation loss: 2.1684094834071335

Epoch: 5| Step: 4
Training loss: 2.31742525100708
Validation loss: 2.1733039373992593

Epoch: 5| Step: 5
Training loss: 2.2994654178619385
Validation loss: 2.204195455838275

Epoch: 5| Step: 6
Training loss: 2.350856065750122
Validation loss: 2.2294107303824475

Epoch: 5| Step: 7
Training loss: 2.5432190895080566
Validation loss: 2.22808442577239

Epoch: 5| Step: 8
Training loss: 2.7685656547546387
Validation loss: 2.205987391933318

Epoch: 5| Step: 9
Training loss: 2.366450786590576
Validation loss: 2.167260559656287

Epoch: 5| Step: 10
Training loss: 2.1357107162475586
Validation loss: 2.151368748757147

Epoch: 107| Step: 0
Training loss: 2.701733112335205
Validation loss: 2.129499387997453

Epoch: 5| Step: 1
Training loss: 2.2647523880004883
Validation loss: 2.129517800064497

Epoch: 5| Step: 2
Training loss: 2.212411880493164
Validation loss: 2.145162082487537

Epoch: 5| Step: 3
Training loss: 2.5775065422058105
Validation loss: 2.1391041971022084

Epoch: 5| Step: 4
Training loss: 2.8218650817871094
Validation loss: 2.13477675889128

Epoch: 5| Step: 5
Training loss: 2.3849916458129883
Validation loss: 2.1317829931935957

Epoch: 5| Step: 6
Training loss: 2.1376984119415283
Validation loss: 2.134999126516363

Epoch: 5| Step: 7
Training loss: 2.720126152038574
Validation loss: 2.1548019327143186

Epoch: 5| Step: 8
Training loss: 2.6286628246307373
Validation loss: 2.1589062700989428

Epoch: 5| Step: 9
Training loss: 2.9516022205352783
Validation loss: 2.140196390049432

Epoch: 5| Step: 10
Training loss: 1.5831456184387207
Validation loss: 2.1359677776213615

Epoch: 108| Step: 0
Training loss: 2.3330941200256348
Validation loss: 2.135677327391922

Epoch: 5| Step: 1
Training loss: 2.5664947032928467
Validation loss: 2.1398147485589467

Epoch: 5| Step: 2
Training loss: 2.5389442443847656
Validation loss: 2.149309745398901

Epoch: 5| Step: 3
Training loss: 2.6297192573547363
Validation loss: 2.1497982663493

Epoch: 5| Step: 4
Training loss: 2.7180545330047607
Validation loss: 2.1688486619662215

Epoch: 5| Step: 5
Training loss: 2.500195264816284
Validation loss: 2.1880577943658315

Epoch: 5| Step: 6
Training loss: 2.2470691204071045
Validation loss: 2.1964289449876353

Epoch: 5| Step: 7
Training loss: 2.215426206588745
Validation loss: 2.199017458064582

Epoch: 5| Step: 8
Training loss: 2.462806224822998
Validation loss: 2.178607976564797

Epoch: 5| Step: 9
Training loss: 2.667109251022339
Validation loss: 2.166851717938659

Epoch: 5| Step: 10
Training loss: 2.0334882736206055
Validation loss: 2.1536378591291365

Epoch: 109| Step: 0
Training loss: 2.5065722465515137
Validation loss: 2.1624582698268275

Epoch: 5| Step: 1
Training loss: 2.2456421852111816
Validation loss: 2.1788304774991927

Epoch: 5| Step: 2
Training loss: 2.095607280731201
Validation loss: 2.176381411090974

Epoch: 5| Step: 3
Training loss: 2.449681520462036
Validation loss: 2.178729691813069

Epoch: 5| Step: 4
Training loss: 2.8197884559631348
Validation loss: 2.1647027936033023

Epoch: 5| Step: 5
Training loss: 2.1047472953796387
Validation loss: 2.1673271015126216

Epoch: 5| Step: 6
Training loss: 2.5867397785186768
Validation loss: 2.1772568148951374

Epoch: 5| Step: 7
Training loss: 2.9914443492889404
Validation loss: 2.1671490848705335

Epoch: 5| Step: 8
Training loss: 2.4881224632263184
Validation loss: 2.173249921491069

Epoch: 5| Step: 9
Training loss: 2.1685822010040283
Validation loss: 2.1850841993926675

Epoch: 5| Step: 10
Training loss: 2.3836305141448975
Validation loss: 2.166164694293853

Epoch: 110| Step: 0
Training loss: 2.0794529914855957
Validation loss: 2.1643363404017624

Epoch: 5| Step: 1
Training loss: 2.132956027984619
Validation loss: 2.14972186088562

Epoch: 5| Step: 2
Training loss: 3.121079444885254
Validation loss: 2.1551616396955264

Epoch: 5| Step: 3
Training loss: 3.0059406757354736
Validation loss: 2.1527642409006753

Epoch: 5| Step: 4
Training loss: 2.678581714630127
Validation loss: 2.148181552528053

Epoch: 5| Step: 5
Training loss: 3.015578031539917
Validation loss: 2.139347868580972

Epoch: 5| Step: 6
Training loss: 2.197606086730957
Validation loss: 2.1336756547292075

Epoch: 5| Step: 7
Training loss: 1.8540709018707275
Validation loss: 2.1627299016521824

Epoch: 5| Step: 8
Training loss: 1.9980475902557373
Validation loss: 2.17539127924109

Epoch: 5| Step: 9
Training loss: 1.9362272024154663
Validation loss: 2.1635221973542245

Epoch: 5| Step: 10
Training loss: 2.733445882797241
Validation loss: 2.1570761037129227

Epoch: 111| Step: 0
Training loss: 2.382467746734619
Validation loss: 2.132277081089635

Epoch: 5| Step: 1
Training loss: 2.2446341514587402
Validation loss: 2.1233979771214146

Epoch: 5| Step: 2
Training loss: 2.510485887527466
Validation loss: 2.1197985192780853

Epoch: 5| Step: 3
Training loss: 2.40504789352417
Validation loss: 2.1207808781695623

Epoch: 5| Step: 4
Training loss: 2.8656580448150635
Validation loss: 2.1137796294304634

Epoch: 5| Step: 5
Training loss: 2.3296267986297607
Validation loss: 2.1217391157662995

Epoch: 5| Step: 6
Training loss: 2.6173481941223145
Validation loss: 2.1217104619549167

Epoch: 5| Step: 7
Training loss: 2.512538433074951
Validation loss: 2.127071096051124

Epoch: 5| Step: 8
Training loss: 1.9586849212646484
Validation loss: 2.1236650379755164

Epoch: 5| Step: 9
Training loss: 2.4035191535949707
Validation loss: 2.131626506005564

Epoch: 5| Step: 10
Training loss: 2.6547884941101074
Validation loss: 2.1485103599486814

Epoch: 112| Step: 0
Training loss: 3.034043550491333
Validation loss: 2.1590097335077103

Epoch: 5| Step: 1
Training loss: 2.2017455101013184
Validation loss: 2.174688941688948

Epoch: 5| Step: 2
Training loss: 2.597965717315674
Validation loss: 2.2360406165481894

Epoch: 5| Step: 3
Training loss: 1.7794405221939087
Validation loss: 2.328839035444362

Epoch: 5| Step: 4
Training loss: 2.7707016468048096
Validation loss: 2.3798803257685837

Epoch: 5| Step: 5
Training loss: 2.9669947624206543
Validation loss: 2.3726869603639007

Epoch: 5| Step: 6
Training loss: 2.170301914215088
Validation loss: 2.331257671438238

Epoch: 5| Step: 7
Training loss: 2.5108094215393066
Validation loss: 2.2627269990982546

Epoch: 5| Step: 8
Training loss: 2.8135600090026855
Validation loss: 2.184556862359406

Epoch: 5| Step: 9
Training loss: 2.22450590133667
Validation loss: 2.1519522128566617

Epoch: 5| Step: 10
Training loss: 2.088956832885742
Validation loss: 2.158392693406792

Epoch: 113| Step: 0
Training loss: 2.240450382232666
Validation loss: 2.1609217402755574

Epoch: 5| Step: 1
Training loss: 2.5139424800872803
Validation loss: 2.162689851176354

Epoch: 5| Step: 2
Training loss: 2.741791248321533
Validation loss: 2.1635858679330475

Epoch: 5| Step: 3
Training loss: 2.4157958030700684
Validation loss: 2.1673916347565187

Epoch: 5| Step: 4
Training loss: 2.361952304840088
Validation loss: 2.161112702021035

Epoch: 5| Step: 5
Training loss: 2.3976776599884033
Validation loss: 2.162306302337236

Epoch: 5| Step: 6
Training loss: 2.558797836303711
Validation loss: 2.153625331899171

Epoch: 5| Step: 7
Training loss: 2.5346763134002686
Validation loss: 2.1504731793557443

Epoch: 5| Step: 8
Training loss: 1.6387908458709717
Validation loss: 2.146105712459933

Epoch: 5| Step: 9
Training loss: 2.6298160552978516
Validation loss: 2.1468794627856185

Epoch: 5| Step: 10
Training loss: 3.3193817138671875
Validation loss: 2.139400887232955

Epoch: 114| Step: 0
Training loss: 2.6341712474823
Validation loss: 2.13788499370698

Epoch: 5| Step: 1
Training loss: 2.3491992950439453
Validation loss: 2.136228399892007

Epoch: 5| Step: 2
Training loss: 2.3697659969329834
Validation loss: 2.1341015626025457

Epoch: 5| Step: 3
Training loss: 2.707818031311035
Validation loss: 2.1363316684640865

Epoch: 5| Step: 4
Training loss: 2.1840620040893555
Validation loss: 2.143554097862654

Epoch: 5| Step: 5
Training loss: 2.063920736312866
Validation loss: 2.160296163251323

Epoch: 5| Step: 6
Training loss: 2.232196092605591
Validation loss: 2.2092754738305205

Epoch: 5| Step: 7
Training loss: 2.2316789627075195
Validation loss: 2.2219138055719356

Epoch: 5| Step: 8
Training loss: 2.9514007568359375
Validation loss: 2.2399655362611175

Epoch: 5| Step: 9
Training loss: 2.7047533988952637
Validation loss: 2.2082728724325857

Epoch: 5| Step: 10
Training loss: 2.2804183959960938
Validation loss: 2.1596794871873755

Epoch: 115| Step: 0
Training loss: 2.472809076309204
Validation loss: 2.142041831888178

Epoch: 5| Step: 1
Training loss: 3.088825225830078
Validation loss: 2.1412170753684094

Epoch: 5| Step: 2
Training loss: 2.406586170196533
Validation loss: 2.135386520816434

Epoch: 5| Step: 3
Training loss: 2.7773115634918213
Validation loss: 2.143039484177866

Epoch: 5| Step: 4
Training loss: 2.552302598953247
Validation loss: 2.1497072545430993

Epoch: 5| Step: 5
Training loss: 2.226566791534424
Validation loss: 2.1559873729623775

Epoch: 5| Step: 6
Training loss: 2.6649444103240967
Validation loss: 2.172130334761835

Epoch: 5| Step: 7
Training loss: 2.5231833457946777
Validation loss: 2.168778573313067

Epoch: 5| Step: 8
Training loss: 2.36902117729187
Validation loss: 2.178272262696297

Epoch: 5| Step: 9
Training loss: 2.091984748840332
Validation loss: 2.191154299243804

Epoch: 5| Step: 10
Training loss: 1.6106103658676147
Validation loss: 2.19093894702132

Epoch: 116| Step: 0
Training loss: 2.15848970413208
Validation loss: 2.2157130497758106

Epoch: 5| Step: 1
Training loss: 3.0015435218811035
Validation loss: 2.2971555494493052

Epoch: 5| Step: 2
Training loss: 2.3837664127349854
Validation loss: 2.2658993710753736

Epoch: 5| Step: 3
Training loss: 3.0626578330993652
Validation loss: 2.2415038834335985

Epoch: 5| Step: 4
Training loss: 2.2066454887390137
Validation loss: 2.2152283371135755

Epoch: 5| Step: 5
Training loss: 2.0639824867248535
Validation loss: 2.1840960876916045

Epoch: 5| Step: 6
Training loss: 2.1243326663970947
Validation loss: 2.1921601910744943

Epoch: 5| Step: 7
Training loss: 2.1734347343444824
Validation loss: 2.200728393370105

Epoch: 5| Step: 8
Training loss: 2.776240348815918
Validation loss: 2.214455545589488

Epoch: 5| Step: 9
Training loss: 2.5514426231384277
Validation loss: 2.2525547806934645

Epoch: 5| Step: 10
Training loss: 2.592066526412964
Validation loss: 2.278108558347148

Epoch: 117| Step: 0
Training loss: 2.832864761352539
Validation loss: 2.2262233482894076

Epoch: 5| Step: 1
Training loss: 2.3157851696014404
Validation loss: 2.17506145405513

Epoch: 5| Step: 2
Training loss: 2.7616915702819824
Validation loss: 2.1486160806430283

Epoch: 5| Step: 3
Training loss: 2.0339972972869873
Validation loss: 2.1302499822390977

Epoch: 5| Step: 4
Training loss: 3.070563793182373
Validation loss: 2.137172829720282

Epoch: 5| Step: 5
Training loss: 2.2250123023986816
Validation loss: 2.128097698252688

Epoch: 5| Step: 6
Training loss: 2.5107979774475098
Validation loss: 2.1312636329281713

Epoch: 5| Step: 7
Training loss: 2.5540130138397217
Validation loss: 2.1376644052484983

Epoch: 5| Step: 8
Training loss: 2.8799386024475098
Validation loss: 2.1345297162250807

Epoch: 5| Step: 9
Training loss: 1.6391197443008423
Validation loss: 2.14471528350666

Epoch: 5| Step: 10
Training loss: 2.0062248706817627
Validation loss: 2.1442185486516645

Epoch: 118| Step: 0
Training loss: 2.96382474899292
Validation loss: 2.160233674510833

Epoch: 5| Step: 1
Training loss: 2.378546953201294
Validation loss: 2.1807828334070023

Epoch: 5| Step: 2
Training loss: 2.0826632976531982
Validation loss: 2.1910784885447514

Epoch: 5| Step: 3
Training loss: 2.5394794940948486
Validation loss: 2.213434068105554

Epoch: 5| Step: 4
Training loss: 2.0900521278381348
Validation loss: 2.2403603574281097

Epoch: 5| Step: 5
Training loss: 2.3696892261505127
Validation loss: 2.1977690060933432

Epoch: 5| Step: 6
Training loss: 2.4342052936553955
Validation loss: 2.1618896786884596

Epoch: 5| Step: 7
Training loss: 2.8532111644744873
Validation loss: 2.148223300133982

Epoch: 5| Step: 8
Training loss: 2.2349929809570312
Validation loss: 2.132377532220656

Epoch: 5| Step: 9
Training loss: 2.3698954582214355
Validation loss: 2.1136399263976724

Epoch: 5| Step: 10
Training loss: 2.2490077018737793
Validation loss: 2.1080458753852436

Epoch: 119| Step: 0
Training loss: 1.9929325580596924
Validation loss: 2.111245560389693

Epoch: 5| Step: 1
Training loss: 2.280991554260254
Validation loss: 2.120735422257454

Epoch: 5| Step: 2
Training loss: 2.442124605178833
Validation loss: 2.1197192950915267

Epoch: 5| Step: 3
Training loss: 2.815218448638916
Validation loss: 2.1258736272012033

Epoch: 5| Step: 4
Training loss: 2.246493339538574
Validation loss: 2.129076885920699

Epoch: 5| Step: 5
Training loss: 2.7056078910827637
Validation loss: 2.142509844995314

Epoch: 5| Step: 6
Training loss: 2.2398433685302734
Validation loss: 2.157649145331434

Epoch: 5| Step: 7
Training loss: 2.8356525897979736
Validation loss: 2.153418279463245

Epoch: 5| Step: 8
Training loss: 2.817713975906372
Validation loss: 2.161706029727895

Epoch: 5| Step: 9
Training loss: 2.150054454803467
Validation loss: 2.1569248040517173

Epoch: 5| Step: 10
Training loss: 1.7715574502944946
Validation loss: 2.1438156814985376

Epoch: 120| Step: 0
Training loss: 2.3937859535217285
Validation loss: 2.133718498291508

Epoch: 5| Step: 1
Training loss: 2.429408311843872
Validation loss: 2.126557678304693

Epoch: 5| Step: 2
Training loss: 2.0356950759887695
Validation loss: 2.1088254554297334

Epoch: 5| Step: 3
Training loss: 2.056946039199829
Validation loss: 2.0999083288254274

Epoch: 5| Step: 4
Training loss: 2.3882548809051514
Validation loss: 2.0923966002720658

Epoch: 5| Step: 5
Training loss: 3.0759658813476562
Validation loss: 2.0968309858793854

Epoch: 5| Step: 6
Training loss: 2.4295601844787598
Validation loss: 2.09378340167384

Epoch: 5| Step: 7
Training loss: 2.402662992477417
Validation loss: 2.1108984972841

Epoch: 5| Step: 8
Training loss: 2.7971208095550537
Validation loss: 2.1575827226843884

Epoch: 5| Step: 9
Training loss: 2.5248804092407227
Validation loss: 2.1995009606884373

Epoch: 5| Step: 10
Training loss: 2.139307975769043
Validation loss: 2.2007658097051803

Epoch: 121| Step: 0
Training loss: 2.905911922454834
Validation loss: 2.195368259183822

Epoch: 5| Step: 1
Training loss: 2.227202892303467
Validation loss: 2.1957992533201813

Epoch: 5| Step: 2
Training loss: 2.5528132915496826
Validation loss: 2.149590530703145

Epoch: 5| Step: 3
Training loss: 2.9952340126037598
Validation loss: 2.1138155101447977

Epoch: 5| Step: 4
Training loss: 2.23958158493042
Validation loss: 2.108080405060963

Epoch: 5| Step: 5
Training loss: 2.5067524909973145
Validation loss: 2.0969859618012623

Epoch: 5| Step: 6
Training loss: 2.1038029193878174
Validation loss: 2.1126035605707476

Epoch: 5| Step: 7
Training loss: 1.8344485759735107
Validation loss: 2.117225399581335

Epoch: 5| Step: 8
Training loss: 2.1526074409484863
Validation loss: 2.1132522347152873

Epoch: 5| Step: 9
Training loss: 2.3439788818359375
Validation loss: 2.121153591781534

Epoch: 5| Step: 10
Training loss: 2.5569353103637695
Validation loss: 2.10251360811213

Epoch: 122| Step: 0
Training loss: 2.050405502319336
Validation loss: 2.105299667645526

Epoch: 5| Step: 1
Training loss: 1.9604864120483398
Validation loss: 2.12249086236441

Epoch: 5| Step: 2
Training loss: 2.4575679302215576
Validation loss: 2.152145649797173

Epoch: 5| Step: 3
Training loss: 1.9893443584442139
Validation loss: 2.1625599374053297

Epoch: 5| Step: 4
Training loss: 2.8526785373687744
Validation loss: 2.16536719183768

Epoch: 5| Step: 5
Training loss: 2.203484058380127
Validation loss: 2.1383190180665705

Epoch: 5| Step: 6
Training loss: 2.786184072494507
Validation loss: 2.11868929606612

Epoch: 5| Step: 7
Training loss: 2.4631056785583496
Validation loss: 2.0978974270564255

Epoch: 5| Step: 8
Training loss: 2.455700397491455
Validation loss: 2.0830125988170667

Epoch: 5| Step: 9
Training loss: 2.133780002593994
Validation loss: 2.0876059403983493

Epoch: 5| Step: 10
Training loss: 2.970512866973877
Validation loss: 2.080760609719061

Epoch: 123| Step: 0
Training loss: 2.599684953689575
Validation loss: 2.081264070285264

Epoch: 5| Step: 1
Training loss: 2.406111717224121
Validation loss: 2.0791430537418654

Epoch: 5| Step: 2
Training loss: 2.4617629051208496
Validation loss: 2.0703509469186105

Epoch: 5| Step: 3
Training loss: 1.5504590272903442
Validation loss: 2.077807354670699

Epoch: 5| Step: 4
Training loss: 2.005938768386841
Validation loss: 2.0904125193113923

Epoch: 5| Step: 5
Training loss: 2.4289822578430176
Validation loss: 2.137880168935304

Epoch: 5| Step: 6
Training loss: 2.21934175491333
Validation loss: 2.1384052217647596

Epoch: 5| Step: 7
Training loss: 3.162336587905884
Validation loss: 2.137102275766352

Epoch: 5| Step: 8
Training loss: 2.5454068183898926
Validation loss: 2.129069411626426

Epoch: 5| Step: 9
Training loss: 2.384026527404785
Validation loss: 2.1168131751398884

Epoch: 5| Step: 10
Training loss: 2.688335657119751
Validation loss: 2.142876999352568

Epoch: 124| Step: 0
Training loss: 1.8343355655670166
Validation loss: 2.1436699308374876

Epoch: 5| Step: 1
Training loss: 2.2988102436065674
Validation loss: 2.128981157015729

Epoch: 5| Step: 2
Training loss: 2.6068246364593506
Validation loss: 2.1141372521718345

Epoch: 5| Step: 3
Training loss: 3.192429304122925
Validation loss: 2.110039036761048

Epoch: 5| Step: 4
Training loss: 2.325543165206909
Validation loss: 2.108287465187811

Epoch: 5| Step: 5
Training loss: 2.30787992477417
Validation loss: 2.0906637150754213

Epoch: 5| Step: 6
Training loss: 2.0423922538757324
Validation loss: 2.096446673075358

Epoch: 5| Step: 7
Training loss: 2.7314460277557373
Validation loss: 2.08662901642502

Epoch: 5| Step: 8
Training loss: 3.21246337890625
Validation loss: 2.095006504366475

Epoch: 5| Step: 9
Training loss: 2.0002801418304443
Validation loss: 2.100806474685669

Epoch: 5| Step: 10
Training loss: 1.8550344705581665
Validation loss: 2.124737431926112

Epoch: 125| Step: 0
Training loss: 2.6715707778930664
Validation loss: 2.1643883438520533

Epoch: 5| Step: 1
Training loss: 2.271177291870117
Validation loss: 2.177284945723831

Epoch: 5| Step: 2
Training loss: 2.171482801437378
Validation loss: 2.1911454354563067

Epoch: 5| Step: 3
Training loss: 2.0958847999572754
Validation loss: 2.1793414290233324

Epoch: 5| Step: 4
Training loss: 2.64743709564209
Validation loss: 2.1495653044792915

Epoch: 5| Step: 5
Training loss: 2.390343189239502
Validation loss: 2.102146076899703

Epoch: 5| Step: 6
Training loss: 1.9727942943572998
Validation loss: 2.0877329111099243

Epoch: 5| Step: 7
Training loss: 2.831001043319702
Validation loss: 2.0759676989688667

Epoch: 5| Step: 8
Training loss: 2.374451160430908
Validation loss: 2.0727927197692213

Epoch: 5| Step: 9
Training loss: 2.634471893310547
Validation loss: 2.08184907256916

Epoch: 5| Step: 10
Training loss: 2.1037709712982178
Validation loss: 2.0826158472286758

Epoch: 126| Step: 0
Training loss: 2.3877322673797607
Validation loss: 2.0829370534548195

Epoch: 5| Step: 1
Training loss: 1.9954103231430054
Validation loss: 2.0836441696331067

Epoch: 5| Step: 2
Training loss: 2.3834400177001953
Validation loss: 2.0860992349604124

Epoch: 5| Step: 3
Training loss: 2.5438084602355957
Validation loss: 2.08745934373589

Epoch: 5| Step: 4
Training loss: 2.402991771697998
Validation loss: 2.093684429763466

Epoch: 5| Step: 5
Training loss: 2.7002243995666504
Validation loss: 2.094516310640561

Epoch: 5| Step: 6
Training loss: 2.1467976570129395
Validation loss: 2.1100526240564164

Epoch: 5| Step: 7
Training loss: 2.371840238571167
Validation loss: 2.1382253644286946

Epoch: 5| Step: 8
Training loss: 2.5537686347961426
Validation loss: 2.137660091923129

Epoch: 5| Step: 9
Training loss: 2.1856529712677
Validation loss: 2.150184344219905

Epoch: 5| Step: 10
Training loss: 2.7254912853240967
Validation loss: 2.1417314685801023

Epoch: 127| Step: 0
Training loss: 2.650413990020752
Validation loss: 2.1082846669740576

Epoch: 5| Step: 1
Training loss: 2.4687705039978027
Validation loss: 2.0980776279203353

Epoch: 5| Step: 2
Training loss: 2.6861908435821533
Validation loss: 2.0926551562483593

Epoch: 5| Step: 3
Training loss: 1.0327972173690796
Validation loss: 2.0839877923329673

Epoch: 5| Step: 4
Training loss: 2.3442649841308594
Validation loss: 2.0854455706893757

Epoch: 5| Step: 5
Training loss: 1.9878313541412354
Validation loss: 2.0828533839153986

Epoch: 5| Step: 6
Training loss: 2.6136839389801025
Validation loss: 2.082400292478582

Epoch: 5| Step: 7
Training loss: 2.873553991317749
Validation loss: 2.0818220402604792

Epoch: 5| Step: 8
Training loss: 2.6141679286956787
Validation loss: 2.0821242281185683

Epoch: 5| Step: 9
Training loss: 1.8046910762786865
Validation loss: 2.079916008057133

Epoch: 5| Step: 10
Training loss: 3.019580841064453
Validation loss: 2.0948606050142677

Epoch: 128| Step: 0
Training loss: 2.5825648307800293
Validation loss: 2.0899819917576288

Epoch: 5| Step: 1
Training loss: 2.0555038452148438
Validation loss: 2.0840600908443494

Epoch: 5| Step: 2
Training loss: 2.41864013671875
Validation loss: 2.098360769210323

Epoch: 5| Step: 3
Training loss: 2.2062861919403076
Validation loss: 2.1136509436433033

Epoch: 5| Step: 4
Training loss: 2.799406051635742
Validation loss: 2.1455326105958674

Epoch: 5| Step: 5
Training loss: 2.5694804191589355
Validation loss: 2.189144795940768

Epoch: 5| Step: 6
Training loss: 2.290686845779419
Validation loss: 2.1696699639802337

Epoch: 5| Step: 7
Training loss: 2.345566511154175
Validation loss: 2.151707923540505

Epoch: 5| Step: 8
Training loss: 2.1410250663757324
Validation loss: 2.1145923791393155

Epoch: 5| Step: 9
Training loss: 2.1289639472961426
Validation loss: 2.1326800033610356

Epoch: 5| Step: 10
Training loss: 2.510377883911133
Validation loss: 2.1347661915645806

Epoch: 129| Step: 0
Training loss: 2.2683944702148438
Validation loss: 2.122605481455403

Epoch: 5| Step: 1
Training loss: 2.1878085136413574
Validation loss: 2.1207078861933883

Epoch: 5| Step: 2
Training loss: 2.371548652648926
Validation loss: 2.1265583140875703

Epoch: 5| Step: 3
Training loss: 2.5294408798217773
Validation loss: 2.11619080779373

Epoch: 5| Step: 4
Training loss: 2.187661647796631
Validation loss: 2.1059341110208982

Epoch: 5| Step: 5
Training loss: 2.5221056938171387
Validation loss: 2.101546654137232

Epoch: 5| Step: 6
Training loss: 2.3835017681121826
Validation loss: 2.0890094977553173

Epoch: 5| Step: 7
Training loss: 2.4437599182128906
Validation loss: 2.106433795344445

Epoch: 5| Step: 8
Training loss: 2.6949214935302734
Validation loss: 2.1438262975344093

Epoch: 5| Step: 9
Training loss: 2.075105905532837
Validation loss: 2.165502204689928

Epoch: 5| Step: 10
Training loss: 2.4606003761291504
Validation loss: 2.184660747487058

Epoch: 130| Step: 0
Training loss: 2.234377384185791
Validation loss: 2.129733685524233

Epoch: 5| Step: 1
Training loss: 2.3593249320983887
Validation loss: 2.076689058734525

Epoch: 5| Step: 2
Training loss: 2.449195146560669
Validation loss: 2.0720145112724713

Epoch: 5| Step: 3
Training loss: 2.2925381660461426
Validation loss: 2.0739646521947717

Epoch: 5| Step: 4
Training loss: 2.371551513671875
Validation loss: 2.0758055948442027

Epoch: 5| Step: 5
Training loss: 2.520420789718628
Validation loss: 2.0764622611384236

Epoch: 5| Step: 6
Training loss: 2.444223403930664
Validation loss: 2.0805824597676597

Epoch: 5| Step: 7
Training loss: 1.6907069683074951
Validation loss: 2.0923041746180546

Epoch: 5| Step: 8
Training loss: 1.627375602722168
Validation loss: 2.1057638481099117

Epoch: 5| Step: 9
Training loss: 3.1524758338928223
Validation loss: 2.1011648331919024

Epoch: 5| Step: 10
Training loss: 2.71860933303833
Validation loss: 2.0939390941332747

Epoch: 131| Step: 0
Training loss: 2.7872281074523926
Validation loss: 2.0852328795258717

Epoch: 5| Step: 1
Training loss: 2.37239670753479
Validation loss: 2.067451516787211

Epoch: 5| Step: 2
Training loss: 2.0955474376678467
Validation loss: 2.058879626694546

Epoch: 5| Step: 3
Training loss: 2.6097474098205566
Validation loss: 2.0519271948004283

Epoch: 5| Step: 4
Training loss: 1.8152687549591064
Validation loss: 2.0572742467285483

Epoch: 5| Step: 5
Training loss: 2.475332260131836
Validation loss: 2.0542522450929046

Epoch: 5| Step: 6
Training loss: 2.1315062046051025
Validation loss: 2.0426501663782264

Epoch: 5| Step: 7
Training loss: 2.6494922637939453
Validation loss: 2.064588448052765

Epoch: 5| Step: 8
Training loss: 2.0274500846862793
Validation loss: 2.0691629225207913

Epoch: 5| Step: 9
Training loss: 2.5976626873016357
Validation loss: 2.0938171981483378

Epoch: 5| Step: 10
Training loss: 2.252680540084839
Validation loss: 2.112262389993155

Epoch: 132| Step: 0
Training loss: 2.032640218734741
Validation loss: 2.139338893275107

Epoch: 5| Step: 1
Training loss: 2.0295755863189697
Validation loss: 2.101438024992584

Epoch: 5| Step: 2
Training loss: 2.444058656692505
Validation loss: 2.076239215430393

Epoch: 5| Step: 3
Training loss: 2.2377877235412598
Validation loss: 2.040291546493448

Epoch: 5| Step: 4
Training loss: 1.8773376941680908
Validation loss: 2.054126544665265

Epoch: 5| Step: 5
Training loss: 2.228713274002075
Validation loss: 2.054043833927442

Epoch: 5| Step: 6
Training loss: 2.7383182048797607
Validation loss: 2.0495592573637604

Epoch: 5| Step: 7
Training loss: 2.4652132987976074
Validation loss: 2.051763208963538

Epoch: 5| Step: 8
Training loss: 2.454113721847534
Validation loss: 2.0535492538124003

Epoch: 5| Step: 9
Training loss: 2.647751808166504
Validation loss: 2.0519004316740137

Epoch: 5| Step: 10
Training loss: 2.467515468597412
Validation loss: 2.0871607154928227

Epoch: 133| Step: 0
Training loss: 2.4245753288269043
Validation loss: 2.1113453116468204

Epoch: 5| Step: 1
Training loss: 1.6271947622299194
Validation loss: 2.1233589392836376

Epoch: 5| Step: 2
Training loss: 2.1242146492004395
Validation loss: 2.1434260158128637

Epoch: 5| Step: 3
Training loss: 2.685821056365967
Validation loss: 2.114703773170389

Epoch: 5| Step: 4
Training loss: 1.870021104812622
Validation loss: 2.0838557930402857

Epoch: 5| Step: 5
Training loss: 1.8855386972427368
Validation loss: 2.0745715466878747

Epoch: 5| Step: 6
Training loss: 2.5879459381103516
Validation loss: 2.0679493527258597

Epoch: 5| Step: 7
Training loss: 2.697096109390259
Validation loss: 2.0850797430161507

Epoch: 5| Step: 8
Training loss: 2.4605486392974854
Validation loss: 2.080238767849502

Epoch: 5| Step: 9
Training loss: 2.731025218963623
Validation loss: 2.0694829084539927

Epoch: 5| Step: 10
Training loss: 2.6230103969573975
Validation loss: 2.081791813655566

Epoch: 134| Step: 0
Training loss: 2.576324701309204
Validation loss: 2.0732275337301274

Epoch: 5| Step: 1
Training loss: 2.0712897777557373
Validation loss: 2.075313005396115

Epoch: 5| Step: 2
Training loss: 2.4406707286834717
Validation loss: 2.070325864258633

Epoch: 5| Step: 3
Training loss: 2.113433361053467
Validation loss: 2.0825336158916516

Epoch: 5| Step: 4
Training loss: 2.4093844890594482
Validation loss: 2.0780169822836436

Epoch: 5| Step: 5
Training loss: 2.796966552734375
Validation loss: 2.089257001876831

Epoch: 5| Step: 6
Training loss: 2.0231587886810303
Validation loss: 2.0967732642286565

Epoch: 5| Step: 7
Training loss: 2.3329732418060303
Validation loss: 2.0996910307997014

Epoch: 5| Step: 8
Training loss: 2.18367338180542
Validation loss: 2.105444210831837

Epoch: 5| Step: 9
Training loss: 2.142162322998047
Validation loss: 2.115076991819566

Epoch: 5| Step: 10
Training loss: 2.4167189598083496
Validation loss: 2.11798946831816

Epoch: 135| Step: 0
Training loss: 2.9248766899108887
Validation loss: 2.1070969130403254

Epoch: 5| Step: 1
Training loss: 1.8123050928115845
Validation loss: 2.1064473326488207

Epoch: 5| Step: 2
Training loss: 1.7477153539657593
Validation loss: 2.084301712692425

Epoch: 5| Step: 3
Training loss: 2.497560977935791
Validation loss: 2.0824476108756116

Epoch: 5| Step: 4
Training loss: 2.4936416149139404
Validation loss: 2.060725842752764

Epoch: 5| Step: 5
Training loss: 1.9135040044784546
Validation loss: 2.0582347941654984

Epoch: 5| Step: 6
Training loss: 2.4862961769104004
Validation loss: 2.0661734791212183

Epoch: 5| Step: 7
Training loss: 2.209118604660034
Validation loss: 2.0712634286572857

Epoch: 5| Step: 8
Training loss: 2.503493309020996
Validation loss: 2.087518302343225

Epoch: 5| Step: 9
Training loss: 2.0175187587738037
Validation loss: 2.0919132463393675

Epoch: 5| Step: 10
Training loss: 2.7016375064849854
Validation loss: 2.097873992817376

Epoch: 136| Step: 0
Training loss: 2.533480167388916
Validation loss: 2.086316616304459

Epoch: 5| Step: 1
Training loss: 2.461982250213623
Validation loss: 2.089738189533193

Epoch: 5| Step: 2
Training loss: 1.9867480993270874
Validation loss: 2.0892083939685615

Epoch: 5| Step: 3
Training loss: 1.7651755809783936
Validation loss: 2.084584661709365

Epoch: 5| Step: 4
Training loss: 2.538635015487671
Validation loss: 2.083110955453688

Epoch: 5| Step: 5
Training loss: 1.8787851333618164
Validation loss: 2.0825729472662813

Epoch: 5| Step: 6
Training loss: 2.397414445877075
Validation loss: 2.0759844241603727

Epoch: 5| Step: 7
Training loss: 2.4988770484924316
Validation loss: 2.077590404018279

Epoch: 5| Step: 8
Training loss: 2.2866311073303223
Validation loss: 2.083787953981789

Epoch: 5| Step: 9
Training loss: 2.079697370529175
Validation loss: 2.089364849111085

Epoch: 5| Step: 10
Training loss: 2.615121841430664
Validation loss: 2.1048278757320937

Epoch: 137| Step: 0
Training loss: 1.591592788696289
Validation loss: 2.106708784257212

Epoch: 5| Step: 1
Training loss: 2.2120602130889893
Validation loss: 2.1083353821949293

Epoch: 5| Step: 2
Training loss: 2.5845000743865967
Validation loss: 2.0901830555290304

Epoch: 5| Step: 3
Training loss: 2.1062281131744385
Validation loss: 2.086643652249408

Epoch: 5| Step: 4
Training loss: 1.9987783432006836
Validation loss: 2.0636332342701573

Epoch: 5| Step: 5
Training loss: 3.1521008014678955
Validation loss: 2.047056059683523

Epoch: 5| Step: 6
Training loss: 1.9023014307022095
Validation loss: 2.0728090399055072

Epoch: 5| Step: 7
Training loss: 2.3329010009765625
Validation loss: 2.0819527872147097

Epoch: 5| Step: 8
Training loss: 2.606485605239868
Validation loss: 2.0909612230075303

Epoch: 5| Step: 9
Training loss: 2.2793586254119873
Validation loss: 2.0823377870744273

Epoch: 5| Step: 10
Training loss: 2.1620781421661377
Validation loss: 2.091242769713043

Epoch: 138| Step: 0
Training loss: 2.5895602703094482
Validation loss: 2.088152244526853

Epoch: 5| Step: 1
Training loss: 2.4267427921295166
Validation loss: 2.094056301219489

Epoch: 5| Step: 2
Training loss: 1.7091987133026123
Validation loss: 2.10995860638157

Epoch: 5| Step: 3
Training loss: 3.2367031574249268
Validation loss: 2.130241863189205

Epoch: 5| Step: 4
Training loss: 2.2058982849121094
Validation loss: 2.1224670743429535

Epoch: 5| Step: 5
Training loss: 2.1829326152801514
Validation loss: 2.1016918510519047

Epoch: 5| Step: 6
Training loss: 1.9805418252944946
Validation loss: 2.081008388150123

Epoch: 5| Step: 7
Training loss: 2.12483549118042
Validation loss: 2.063975913550264

Epoch: 5| Step: 8
Training loss: 1.9199295043945312
Validation loss: 2.0469621419906616

Epoch: 5| Step: 9
Training loss: 1.9254729747772217
Validation loss: 2.0372120103528424

Epoch: 5| Step: 10
Training loss: 2.6346795558929443
Validation loss: 2.0329880791325725

Epoch: 139| Step: 0
Training loss: 1.9291309118270874
Validation loss: 2.042793003461694

Epoch: 5| Step: 1
Training loss: 2.1421587467193604
Validation loss: 2.0507902253058647

Epoch: 5| Step: 2
Training loss: 2.710733413696289
Validation loss: 2.060272334724344

Epoch: 5| Step: 3
Training loss: 2.2782511711120605
Validation loss: 2.078762395407564

Epoch: 5| Step: 4
Training loss: 2.326763868331909
Validation loss: 2.0965621407314012

Epoch: 5| Step: 5
Training loss: 1.7172763347625732
Validation loss: 2.089080161945794

Epoch: 5| Step: 6
Training loss: 2.668826103210449
Validation loss: 2.0769426617571103

Epoch: 5| Step: 7
Training loss: 2.357642889022827
Validation loss: 2.0762807810178368

Epoch: 5| Step: 8
Training loss: 2.3678297996520996
Validation loss: 2.078230083629649

Epoch: 5| Step: 9
Training loss: 1.9796327352523804
Validation loss: 2.0779007891173005

Epoch: 5| Step: 10
Training loss: 2.1669492721557617
Validation loss: 2.0719551783736034

Epoch: 140| Step: 0
Training loss: 2.695812463760376
Validation loss: 2.0883479836166545

Epoch: 5| Step: 1
Training loss: 1.7211719751358032
Validation loss: 2.085650861904185

Epoch: 5| Step: 2
Training loss: 1.8107659816741943
Validation loss: 2.0892017041483233

Epoch: 5| Step: 3
Training loss: 2.007721185684204
Validation loss: 2.1005882960493847

Epoch: 5| Step: 4
Training loss: 2.21378755569458
Validation loss: 2.08180493949562

Epoch: 5| Step: 5
Training loss: 2.461322546005249
Validation loss: 2.077099387363721

Epoch: 5| Step: 6
Training loss: 2.4035110473632812
Validation loss: 2.0817030386258195

Epoch: 5| Step: 7
Training loss: 2.3002548217773438
Validation loss: 2.0793302289901243

Epoch: 5| Step: 8
Training loss: 2.0894808769226074
Validation loss: 2.084642694842431

Epoch: 5| Step: 9
Training loss: 2.354518413543701
Validation loss: 2.094112565440516

Epoch: 5| Step: 10
Training loss: 2.3549787998199463
Validation loss: 2.0970050878422235

Epoch: 141| Step: 0
Training loss: 2.0750269889831543
Validation loss: 2.091381080688969

Epoch: 5| Step: 1
Training loss: 2.5089504718780518
Validation loss: 2.093675994103955

Epoch: 5| Step: 2
Training loss: 2.027620553970337
Validation loss: 2.1092437467267438

Epoch: 5| Step: 3
Training loss: 2.2572665214538574
Validation loss: 2.1181216586020684

Epoch: 5| Step: 4
Training loss: 2.3747897148132324
Validation loss: 2.132268451875256

Epoch: 5| Step: 5
Training loss: 1.9236907958984375
Validation loss: 2.13446996929825

Epoch: 5| Step: 6
Training loss: 1.6870567798614502
Validation loss: 2.1599345002123105

Epoch: 5| Step: 7
Training loss: 2.336423873901367
Validation loss: 2.167058483246834

Epoch: 5| Step: 8
Training loss: 2.598015546798706
Validation loss: 2.1527979861023607

Epoch: 5| Step: 9
Training loss: 2.4813897609710693
Validation loss: 2.094356652229063

Epoch: 5| Step: 10
Training loss: 2.470785140991211
Validation loss: 2.0838841058874644

Epoch: 142| Step: 0
Training loss: 2.2281301021575928
Validation loss: 2.0656161667198263

Epoch: 5| Step: 1
Training loss: 2.198826313018799
Validation loss: 2.0650132112605597

Epoch: 5| Step: 2
Training loss: 2.9322564601898193
Validation loss: 2.077142169398646

Epoch: 5| Step: 3
Training loss: 1.8463261127471924
Validation loss: 2.0729141286624375

Epoch: 5| Step: 4
Training loss: 1.72504460811615
Validation loss: 2.0824163908599527

Epoch: 5| Step: 5
Training loss: 2.019909381866455
Validation loss: 2.0948397600522606

Epoch: 5| Step: 6
Training loss: 2.0956997871398926
Validation loss: 2.0846405747116252

Epoch: 5| Step: 7
Training loss: 2.2539901733398438
Validation loss: 2.0902014227323633

Epoch: 5| Step: 8
Training loss: 2.164463758468628
Validation loss: 2.0717990500952608

Epoch: 5| Step: 9
Training loss: 2.656611204147339
Validation loss: 2.0656365886811288

Epoch: 5| Step: 10
Training loss: 2.0547196865081787
Validation loss: 2.066922269841676

Epoch: 143| Step: 0
Training loss: 2.104623794555664
Validation loss: 2.0452722349474506

Epoch: 5| Step: 1
Training loss: 2.036180019378662
Validation loss: 2.0472832392620783

Epoch: 5| Step: 2
Training loss: 2.306239366531372
Validation loss: 2.04246045953484

Epoch: 5| Step: 3
Training loss: 2.5099010467529297
Validation loss: 2.0338696164469563

Epoch: 5| Step: 4
Training loss: 2.4353346824645996
Validation loss: 2.0232489698676654

Epoch: 5| Step: 5
Training loss: 2.3151438236236572
Validation loss: 2.0432954590807677

Epoch: 5| Step: 6
Training loss: 2.121161937713623
Validation loss: 2.04583526426746

Epoch: 5| Step: 7
Training loss: 2.1468777656555176
Validation loss: 2.069852526469897

Epoch: 5| Step: 8
Training loss: 1.6485544443130493
Validation loss: 2.0917017511142197

Epoch: 5| Step: 9
Training loss: 1.9040380716323853
Validation loss: 2.1225964074493735

Epoch: 5| Step: 10
Training loss: 2.6514394283294678
Validation loss: 2.116914141562677

Epoch: 144| Step: 0
Training loss: 1.9262679815292358
Validation loss: 2.1237367506950133

Epoch: 5| Step: 1
Training loss: 2.0097060203552246
Validation loss: 2.112033901676055

Epoch: 5| Step: 2
Training loss: 2.7517261505126953
Validation loss: 2.1206206339661793

Epoch: 5| Step: 3
Training loss: 2.077907085418701
Validation loss: 2.1141210679085023

Epoch: 5| Step: 4
Training loss: 2.4787535667419434
Validation loss: 2.120245328513525

Epoch: 5| Step: 5
Training loss: 1.6358352899551392
Validation loss: 2.1134762302521737

Epoch: 5| Step: 6
Training loss: 2.0373356342315674
Validation loss: 2.103589073304207

Epoch: 5| Step: 7
Training loss: 1.8153022527694702
Validation loss: 2.113250437603202

Epoch: 5| Step: 8
Training loss: 2.8884952068328857
Validation loss: 2.117631255939443

Epoch: 5| Step: 9
Training loss: 2.3529810905456543
Validation loss: 2.1292288739194154

Epoch: 5| Step: 10
Training loss: 1.8058125972747803
Validation loss: 2.106133968599381

Epoch: 145| Step: 0
Training loss: 2.3366589546203613
Validation loss: 2.108582886316443

Epoch: 5| Step: 1
Training loss: 1.492089867591858
Validation loss: 2.112409850602509

Epoch: 5| Step: 2
Training loss: 2.687753677368164
Validation loss: 2.1062972417441745

Epoch: 5| Step: 3
Training loss: 2.2288455963134766
Validation loss: 2.0942481948483374

Epoch: 5| Step: 4
Training loss: 1.9477189779281616
Validation loss: 2.1130812962849936

Epoch: 5| Step: 5
Training loss: 2.45143985748291
Validation loss: 2.0988245574376916

Epoch: 5| Step: 6
Training loss: 2.075005054473877
Validation loss: 2.0920923756014917

Epoch: 5| Step: 7
Training loss: 2.024477243423462
Validation loss: 2.1232001140553463

Epoch: 5| Step: 8
Training loss: 1.7023303508758545
Validation loss: 2.1219626780479186

Epoch: 5| Step: 9
Training loss: 2.595029830932617
Validation loss: 2.115570068359375

Epoch: 5| Step: 10
Training loss: 2.0700039863586426
Validation loss: 2.120903753465222

Epoch: 146| Step: 0
Training loss: 1.9184716939926147
Validation loss: 2.1134812114059285

Epoch: 5| Step: 1
Training loss: 2.2567131519317627
Validation loss: 2.1441766908091884

Epoch: 5| Step: 2
Training loss: 1.7813565731048584
Validation loss: 2.156628449757894

Epoch: 5| Step: 3
Training loss: 2.5855560302734375
Validation loss: 2.170376544357628

Epoch: 5| Step: 4
Training loss: 2.4820237159729004
Validation loss: 2.159661736539615

Epoch: 5| Step: 5
Training loss: 1.5677802562713623
Validation loss: 2.131003354185371

Epoch: 5| Step: 6
Training loss: 2.2713654041290283
Validation loss: 2.1313604808622792

Epoch: 5| Step: 7
Training loss: 1.8923559188842773
Validation loss: 2.114671007279427

Epoch: 5| Step: 8
Training loss: 2.336773157119751
Validation loss: 2.0701272269730926

Epoch: 5| Step: 9
Training loss: 2.1360247135162354
Validation loss: 2.056973336845316

Epoch: 5| Step: 10
Training loss: 2.499476194381714
Validation loss: 2.043128422511521

Epoch: 147| Step: 0
Training loss: 2.174898624420166
Validation loss: 2.051660542847008

Epoch: 5| Step: 1
Training loss: 1.6253139972686768
Validation loss: 2.046476892245713

Epoch: 5| Step: 2
Training loss: 2.4842543601989746
Validation loss: 2.0548254777026433

Epoch: 5| Step: 3
Training loss: 2.2110328674316406
Validation loss: 2.074735341533538

Epoch: 5| Step: 4
Training loss: 1.940315842628479
Validation loss: 2.0983484534807104

Epoch: 5| Step: 5
Training loss: 2.3871288299560547
Validation loss: 2.138884154699182

Epoch: 5| Step: 6
Training loss: 2.5651981830596924
Validation loss: 2.13459373289539

Epoch: 5| Step: 7
Training loss: 1.964708924293518
Validation loss: 2.1147896243679907

Epoch: 5| Step: 8
Training loss: 2.63944673538208
Validation loss: 2.089881581644858

Epoch: 5| Step: 9
Training loss: 2.1776013374328613
Validation loss: 2.0888457016278337

Epoch: 5| Step: 10
Training loss: 1.6648589372634888
Validation loss: 2.0732516909158356

Epoch: 148| Step: 0
Training loss: 1.620582938194275
Validation loss: 2.084032266370712

Epoch: 5| Step: 1
Training loss: 2.1146204471588135
Validation loss: 2.110458030495592

Epoch: 5| Step: 2
Training loss: 2.7232468128204346
Validation loss: 2.122393693975223

Epoch: 5| Step: 3
Training loss: 2.293389081954956
Validation loss: 2.138807563371556

Epoch: 5| Step: 4
Training loss: 2.5305001735687256
Validation loss: 2.1619543567780526

Epoch: 5| Step: 5
Training loss: 2.138645887374878
Validation loss: 2.1796822445366972

Epoch: 5| Step: 6
Training loss: 2.0502758026123047
Validation loss: 2.20806719410804

Epoch: 5| Step: 7
Training loss: 2.2400691509246826
Validation loss: 2.2250621382908156

Epoch: 5| Step: 8
Training loss: 2.050964832305908
Validation loss: 2.210542958269837

Epoch: 5| Step: 9
Training loss: 2.2895383834838867
Validation loss: 2.2038975274691017

Epoch: 5| Step: 10
Training loss: 1.566636085510254
Validation loss: 2.173335967525359

Epoch: 149| Step: 0
Training loss: 1.6013672351837158
Validation loss: 2.141260636750088

Epoch: 5| Step: 1
Training loss: 2.162810802459717
Validation loss: 2.114808722208905

Epoch: 5| Step: 2
Training loss: 2.1432480812072754
Validation loss: 2.0962813797817437

Epoch: 5| Step: 3
Training loss: 2.0025172233581543
Validation loss: 2.1143891555006786

Epoch: 5| Step: 4
Training loss: 2.025359630584717
Validation loss: 2.0967939848540933

Epoch: 5| Step: 5
Training loss: 2.09991192817688
Validation loss: 2.0902810712014475

Epoch: 5| Step: 6
Training loss: 2.113368272781372
Validation loss: 2.0955933640080113

Epoch: 5| Step: 7
Training loss: 1.8513492345809937
Validation loss: 2.0688524194943008

Epoch: 5| Step: 8
Training loss: 2.7399051189422607
Validation loss: 2.0512895020105506

Epoch: 5| Step: 9
Training loss: 2.152609348297119
Validation loss: 2.0571333746756277

Epoch: 5| Step: 10
Training loss: 2.236135721206665
Validation loss: 2.060947569467688

Epoch: 150| Step: 0
Training loss: 1.4714874029159546
Validation loss: 2.0736400350447624

Epoch: 5| Step: 1
Training loss: 1.2647255659103394
Validation loss: 2.070144071373888

Epoch: 5| Step: 2
Training loss: 1.8575798273086548
Validation loss: 2.0758691782592447

Epoch: 5| Step: 3
Training loss: 2.5216946601867676
Validation loss: 2.0968470265788417

Epoch: 5| Step: 4
Training loss: 2.2814722061157227
Validation loss: 2.107619659875029

Epoch: 5| Step: 5
Training loss: 2.072803020477295
Validation loss: 2.1293918983910674

Epoch: 5| Step: 6
Training loss: 2.3506922721862793
Validation loss: 2.1407393870815152

Epoch: 5| Step: 7
Training loss: 2.389509677886963
Validation loss: 2.1631196455288957

Epoch: 5| Step: 8
Training loss: 2.610487461090088
Validation loss: 2.1411339185571157

Epoch: 5| Step: 9
Training loss: 2.0218701362609863
Validation loss: 2.1219414741762224

Epoch: 5| Step: 10
Training loss: 2.344334363937378
Validation loss: 2.118067213284072

Epoch: 151| Step: 0
Training loss: 1.8782844543457031
Validation loss: 2.1030361652374268

Epoch: 5| Step: 1
Training loss: 1.9632213115692139
Validation loss: 2.093020794212177

Epoch: 5| Step: 2
Training loss: 2.2778565883636475
Validation loss: 2.10987465740532

Epoch: 5| Step: 3
Training loss: 2.2479262351989746
Validation loss: 2.1129690934252996

Epoch: 5| Step: 4
Training loss: 2.601672649383545
Validation loss: 2.1107064036912817

Epoch: 5| Step: 5
Training loss: 2.0321199893951416
Validation loss: 2.100857732116535

Epoch: 5| Step: 6
Training loss: 2.1309590339660645
Validation loss: 2.098507683764222

Epoch: 5| Step: 7
Training loss: 2.472029447555542
Validation loss: 2.0911805424638974

Epoch: 5| Step: 8
Training loss: 2.3371126651763916
Validation loss: 2.069825513388521

Epoch: 5| Step: 9
Training loss: 1.6702543497085571
Validation loss: 2.0878856105189167

Epoch: 5| Step: 10
Training loss: 1.4413108825683594
Validation loss: 2.0934961508679133

Epoch: 152| Step: 0
Training loss: 1.8463938236236572
Validation loss: 2.0904198820872972

Epoch: 5| Step: 1
Training loss: 1.7449896335601807
Validation loss: 2.0962726300762546

Epoch: 5| Step: 2
Training loss: 1.9908769130706787
Validation loss: 2.0703337577081498

Epoch: 5| Step: 3
Training loss: 2.1707656383514404
Validation loss: 2.0677288552766204

Epoch: 5| Step: 4
Training loss: 2.3913938999176025
Validation loss: 2.0843382830260904

Epoch: 5| Step: 5
Training loss: 1.8258819580078125
Validation loss: 2.100835677116148

Epoch: 5| Step: 6
Training loss: 2.2858188152313232
Validation loss: 2.096767969028924

Epoch: 5| Step: 7
Training loss: 2.346526622772217
Validation loss: 2.0921499934247745

Epoch: 5| Step: 8
Training loss: 2.5502688884735107
Validation loss: 2.0694388407532887

Epoch: 5| Step: 9
Training loss: 1.885136604309082
Validation loss: 2.0729570017066052

Epoch: 5| Step: 10
Training loss: 2.1108450889587402
Validation loss: 2.051964042007282

Epoch: 153| Step: 0
Training loss: 1.560152292251587
Validation loss: 2.0529403225068124

Epoch: 5| Step: 1
Training loss: 1.327955961227417
Validation loss: 2.0648319849403958

Epoch: 5| Step: 2
Training loss: 2.430854320526123
Validation loss: 2.0694982544068368

Epoch: 5| Step: 3
Training loss: 2.560976505279541
Validation loss: 2.075398342583769

Epoch: 5| Step: 4
Training loss: 1.829789400100708
Validation loss: 2.0503475127681607

Epoch: 5| Step: 5
Training loss: 2.0428147315979004
Validation loss: 2.0490115598965715

Epoch: 5| Step: 6
Training loss: 1.7010008096694946
Validation loss: 2.0648838704632175

Epoch: 5| Step: 7
Training loss: 2.3062503337860107
Validation loss: 2.077459184072351

Epoch: 5| Step: 8
Training loss: 2.4817755222320557
Validation loss: 2.0840273992989653

Epoch: 5| Step: 9
Training loss: 2.223806381225586
Validation loss: 2.1191112149146294

Epoch: 5| Step: 10
Training loss: 2.2866368293762207
Validation loss: 2.13950184083754

Epoch: 154| Step: 0
Training loss: 1.7719371318817139
Validation loss: 2.1601369893679054

Epoch: 5| Step: 1
Training loss: 2.0101702213287354
Validation loss: 2.1774526667851273

Epoch: 5| Step: 2
Training loss: 1.5121523141860962
Validation loss: 2.187230033259238

Epoch: 5| Step: 3
Training loss: 2.398791790008545
Validation loss: 2.1822440752419094

Epoch: 5| Step: 4
Training loss: 1.7942087650299072
Validation loss: 2.1547770884729203

Epoch: 5| Step: 5
Training loss: 1.8712804317474365
Validation loss: 2.1169287748234247

Epoch: 5| Step: 6
Training loss: 2.3750088214874268
Validation loss: 2.105031518525975

Epoch: 5| Step: 7
Training loss: 2.655449390411377
Validation loss: 2.0698532647984003

Epoch: 5| Step: 8
Training loss: 1.6319668292999268
Validation loss: 2.0624908734393377

Epoch: 5| Step: 9
Training loss: 2.7824883460998535
Validation loss: 2.065051976070609

Epoch: 5| Step: 10
Training loss: 2.0352697372436523
Validation loss: 2.058525149540235

Epoch: 155| Step: 0
Training loss: 1.9662672281265259
Validation loss: 2.0554233289534047

Epoch: 5| Step: 1
Training loss: 2.7364580631256104
Validation loss: 2.074351886267303

Epoch: 5| Step: 2
Training loss: 2.068286418914795
Validation loss: 2.068167640316871

Epoch: 5| Step: 3
Training loss: 2.138878345489502
Validation loss: 2.0809542914872527

Epoch: 5| Step: 4
Training loss: 2.5317089557647705
Validation loss: 2.079291784635154

Epoch: 5| Step: 5
Training loss: 2.152439594268799
Validation loss: 2.091557241255237

Epoch: 5| Step: 6
Training loss: 1.9484131336212158
Validation loss: 2.089203944770239

Epoch: 5| Step: 7
Training loss: 1.8325109481811523
Validation loss: 2.105157588117866

Epoch: 5| Step: 8
Training loss: 2.064417839050293
Validation loss: 2.0978724161783853

Epoch: 5| Step: 9
Training loss: 1.540177345275879
Validation loss: 2.0991259108307543

Epoch: 5| Step: 10
Training loss: 1.5061014890670776
Validation loss: 2.0947296555324266

Epoch: 156| Step: 0
Training loss: 2.1928391456604004
Validation loss: 2.105300413664951

Epoch: 5| Step: 1
Training loss: 2.1444127559661865
Validation loss: 2.0977740774872484

Epoch: 5| Step: 2
Training loss: 1.9543384313583374
Validation loss: 2.1262432144534205

Epoch: 5| Step: 3
Training loss: 1.7525017261505127
Validation loss: 2.145027365735782

Epoch: 5| Step: 4
Training loss: 2.0028841495513916
Validation loss: 2.1567428714485577

Epoch: 5| Step: 5
Training loss: 1.8423351049423218
Validation loss: 2.108989764285344

Epoch: 5| Step: 6
Training loss: 2.093677520751953
Validation loss: 2.083086109930469

Epoch: 5| Step: 7
Training loss: 1.9159015417099
Validation loss: 2.0638362207720355

Epoch: 5| Step: 8
Training loss: 2.145355463027954
Validation loss: 2.032684850436385

Epoch: 5| Step: 9
Training loss: 2.3681039810180664
Validation loss: 2.028905640366257

Epoch: 5| Step: 10
Training loss: 2.148935317993164
Validation loss: 2.019271972358868

Epoch: 157| Step: 0
Training loss: 2.4408841133117676
Validation loss: 2.0260136832473097

Epoch: 5| Step: 1
Training loss: 2.5198867321014404
Validation loss: 2.0182007230738157

Epoch: 5| Step: 2
Training loss: 2.267913341522217
Validation loss: 2.027447723573254

Epoch: 5| Step: 3
Training loss: 2.0639488697052
Validation loss: 2.028329021187239

Epoch: 5| Step: 4
Training loss: 1.9565422534942627
Validation loss: 2.051462622099025

Epoch: 5| Step: 5
Training loss: 1.8361603021621704
Validation loss: 2.055926012736495

Epoch: 5| Step: 6
Training loss: 2.0508875846862793
Validation loss: 2.068520406241058

Epoch: 5| Step: 7
Training loss: 1.8134088516235352
Validation loss: 2.0759464002424672

Epoch: 5| Step: 8
Training loss: 1.530701994895935
Validation loss: 2.065249454590582

Epoch: 5| Step: 9
Training loss: 1.7073396444320679
Validation loss: 2.079068758154428

Epoch: 5| Step: 10
Training loss: 2.1331679821014404
Validation loss: 2.07700006423458

Epoch: 158| Step: 0
Training loss: 2.447735548019409
Validation loss: 2.085323246576453

Epoch: 5| Step: 1
Training loss: 1.4930566549301147
Validation loss: 2.113494562846358

Epoch: 5| Step: 2
Training loss: 2.2965755462646484
Validation loss: 2.0873444336716847

Epoch: 5| Step: 3
Training loss: 1.6029691696166992
Validation loss: 2.112396993944722

Epoch: 5| Step: 4
Training loss: 2.516939640045166
Validation loss: 2.114852697618546

Epoch: 5| Step: 5
Training loss: 1.7516390085220337
Validation loss: 2.1075694599459247

Epoch: 5| Step: 6
Training loss: 2.2839953899383545
Validation loss: 2.134793844274295

Epoch: 5| Step: 7
Training loss: 1.5284103155136108
Validation loss: 2.13068312726995

Epoch: 5| Step: 8
Training loss: 2.0572898387908936
Validation loss: 2.126714801275602

Epoch: 5| Step: 9
Training loss: 1.592151403427124
Validation loss: 2.1113594296158

Epoch: 5| Step: 10
Training loss: 2.3896377086639404
Validation loss: 2.1066673237790345

Epoch: 159| Step: 0
Training loss: 2.405444622039795
Validation loss: 2.0878401725522933

Epoch: 5| Step: 1
Training loss: 2.1690914630889893
Validation loss: 2.0743686306861138

Epoch: 5| Step: 2
Training loss: 1.720298171043396
Validation loss: 2.0688310130949943

Epoch: 5| Step: 3
Training loss: 2.2144062519073486
Validation loss: 2.057741140806547

Epoch: 5| Step: 4
Training loss: 1.4777543544769287
Validation loss: 2.0582396266280965

Epoch: 5| Step: 5
Training loss: 1.9890657663345337
Validation loss: 2.069469045567256

Epoch: 5| Step: 6
Training loss: 2.085714817047119
Validation loss: 2.0720277627309165

Epoch: 5| Step: 7
Training loss: 2.073988676071167
Validation loss: 2.0813355535589237

Epoch: 5| Step: 8
Training loss: 2.133028268814087
Validation loss: 2.097735487004762

Epoch: 5| Step: 9
Training loss: 1.6897106170654297
Validation loss: 2.088453479992446

Epoch: 5| Step: 10
Training loss: 1.6199414730072021
Validation loss: 2.093619790128482

Epoch: 160| Step: 0
Training loss: 1.9815113544464111
Validation loss: 2.081094459820819

Epoch: 5| Step: 1
Training loss: 2.3123602867126465
Validation loss: 2.0575768255418345

Epoch: 5| Step: 2
Training loss: 1.7611116170883179
Validation loss: 2.0382754905249483

Epoch: 5| Step: 3
Training loss: 1.5847663879394531
Validation loss: 2.0404669725766746

Epoch: 5| Step: 4
Training loss: 2.383552074432373
Validation loss: 2.0273858552337973

Epoch: 5| Step: 5
Training loss: 2.0410282611846924
Validation loss: 2.039160402872229

Epoch: 5| Step: 6
Training loss: 2.0344719886779785
Validation loss: 2.0246900179052867

Epoch: 5| Step: 7
Training loss: 2.0169665813446045
Validation loss: 2.002987966742567

Epoch: 5| Step: 8
Training loss: 1.670000433921814
Validation loss: 2.0067958575423046

Epoch: 5| Step: 9
Training loss: 1.8778254985809326
Validation loss: 2.019732203534854

Epoch: 5| Step: 10
Training loss: 2.042590379714966
Validation loss: 2.0271739626443512

Epoch: 161| Step: 0
Training loss: 2.4437897205352783
Validation loss: 2.0510967662257533

Epoch: 5| Step: 1
Training loss: 1.6307891607284546
Validation loss: 2.098318703712956

Epoch: 5| Step: 2
Training loss: 2.191129684448242
Validation loss: 2.147696984711514

Epoch: 5| Step: 3
Training loss: 1.8641897439956665
Validation loss: 2.2073901596889702

Epoch: 5| Step: 4
Training loss: 2.1296894550323486
Validation loss: 2.2246796751535065

Epoch: 5| Step: 5
Training loss: 2.273256778717041
Validation loss: 2.2250651569776636

Epoch: 5| Step: 6
Training loss: 1.8048391342163086
Validation loss: 2.191985612274498

Epoch: 5| Step: 7
Training loss: 1.8544849157333374
Validation loss: 2.1392701466878257

Epoch: 5| Step: 8
Training loss: 1.8604313135147095
Validation loss: 2.096767138409358

Epoch: 5| Step: 9
Training loss: 2.108254909515381
Validation loss: 2.039502174623551

Epoch: 5| Step: 10
Training loss: 1.8279080390930176
Validation loss: 2.0187346243089244

Epoch: 162| Step: 0
Training loss: 1.8800662755966187
Validation loss: 2.005748547533507

Epoch: 5| Step: 1
Training loss: 1.520713448524475
Validation loss: 2.0058248812152493

Epoch: 5| Step: 2
Training loss: 1.8368526697158813
Validation loss: 2.012385276056105

Epoch: 5| Step: 3
Training loss: 2.0187716484069824
Validation loss: 2.0207082379248833

Epoch: 5| Step: 4
Training loss: 2.2304739952087402
Validation loss: 2.011287045735185

Epoch: 5| Step: 5
Training loss: 1.7567650079727173
Validation loss: 2.021525013831354

Epoch: 5| Step: 6
Training loss: 1.7211048603057861
Validation loss: 2.026471471273771

Epoch: 5| Step: 7
Training loss: 1.831941843032837
Validation loss: 2.0248672705824657

Epoch: 5| Step: 8
Training loss: 2.347014904022217
Validation loss: 2.023080668141765

Epoch: 5| Step: 9
Training loss: 2.425412654876709
Validation loss: 2.0468240963515414

Epoch: 5| Step: 10
Training loss: 1.8800517320632935
Validation loss: 2.0602834224700928

Epoch: 163| Step: 0
Training loss: 1.5003191232681274
Validation loss: 2.090298301430159

Epoch: 5| Step: 1
Training loss: 2.3103339672088623
Validation loss: 2.1060028883718673

Epoch: 5| Step: 2
Training loss: 2.2643134593963623
Validation loss: 2.1352621663001274

Epoch: 5| Step: 3
Training loss: 2.264767646789551
Validation loss: 2.1860408257412653

Epoch: 5| Step: 4
Training loss: 1.7229887247085571
Validation loss: 2.2367929463745444

Epoch: 5| Step: 5
Training loss: 1.8561280965805054
Validation loss: 2.23784573488338

Epoch: 5| Step: 6
Training loss: 1.9505622386932373
Validation loss: 2.2210294943983837

Epoch: 5| Step: 7
Training loss: 2.0182735919952393
Validation loss: 2.215296253081291

Epoch: 5| Step: 8
Training loss: 2.4541897773742676
Validation loss: 2.1734009455609065

Epoch: 5| Step: 9
Training loss: 1.716834306716919
Validation loss: 2.124984202846404

Epoch: 5| Step: 10
Training loss: 1.814570426940918
Validation loss: 2.0741620730328303

Epoch: 164| Step: 0
Training loss: 1.6979259252548218
Validation loss: 2.0401203311899656

Epoch: 5| Step: 1
Training loss: 1.9126918315887451
Validation loss: 2.0282383990544144

Epoch: 5| Step: 2
Training loss: 1.4800817966461182
Validation loss: 2.009411891301473

Epoch: 5| Step: 3
Training loss: 1.8168443441390991
Validation loss: 2.0062421637196697

Epoch: 5| Step: 4
Training loss: 1.8389549255371094
Validation loss: 2.02442099971156

Epoch: 5| Step: 5
Training loss: 1.8321977853775024
Validation loss: 2.0673224003084245

Epoch: 5| Step: 6
Training loss: 2.4914000034332275
Validation loss: 2.1111383976474887

Epoch: 5| Step: 7
Training loss: 2.15950345993042
Validation loss: 2.0767167281079035

Epoch: 5| Step: 8
Training loss: 2.179508924484253
Validation loss: 2.0638755726557907

Epoch: 5| Step: 9
Training loss: 2.378878355026245
Validation loss: 2.0271461817526046

Epoch: 5| Step: 10
Training loss: 1.6811020374298096
Validation loss: 2.009773551776845

Epoch: 165| Step: 0
Training loss: 1.44566810131073
Validation loss: 2.0191559548019082

Epoch: 5| Step: 1
Training loss: 1.5597426891326904
Validation loss: 2.022127305307696

Epoch: 5| Step: 2
Training loss: 2.3108627796173096
Validation loss: 2.0295210564008324

Epoch: 5| Step: 3
Training loss: 2.2856838703155518
Validation loss: 2.0345076130282496

Epoch: 5| Step: 4
Training loss: 2.1630606651306152
Validation loss: 2.0315762155799457

Epoch: 5| Step: 5
Training loss: 1.679833173751831
Validation loss: 2.046683854954217

Epoch: 5| Step: 6
Training loss: 1.656956672668457
Validation loss: 2.072731069339219

Epoch: 5| Step: 7
Training loss: 2.177182912826538
Validation loss: 2.105472914634212

Epoch: 5| Step: 8
Training loss: 2.1248347759246826
Validation loss: 2.1293707252830587

Epoch: 5| Step: 9
Training loss: 2.2354540824890137
Validation loss: 2.186187069903138

Epoch: 5| Step: 10
Training loss: 1.9719243049621582
Validation loss: 2.1883208264586744

Epoch: 166| Step: 0
Training loss: 1.8764352798461914
Validation loss: 2.187422121724775

Epoch: 5| Step: 1
Training loss: 2.4106974601745605
Validation loss: 2.1947374728418167

Epoch: 5| Step: 2
Training loss: 2.3940324783325195
Validation loss: 2.2314311791491765

Epoch: 5| Step: 3
Training loss: 1.547737717628479
Validation loss: 2.2627721140461583

Epoch: 5| Step: 4
Training loss: 2.4923834800720215
Validation loss: 2.222047613513085

Epoch: 5| Step: 5
Training loss: 1.5491176843643188
Validation loss: 2.1562594059974916

Epoch: 5| Step: 6
Training loss: 2.257763624191284
Validation loss: 2.1088664326616513

Epoch: 5| Step: 7
Training loss: 1.8478772640228271
Validation loss: 2.0729062018855924

Epoch: 5| Step: 8
Training loss: 2.257697343826294
Validation loss: 2.064857800801595

Epoch: 5| Step: 9
Training loss: 1.5008618831634521
Validation loss: 2.0475761839138564

Epoch: 5| Step: 10
Training loss: 2.1437249183654785
Validation loss: 2.033239221060148

Epoch: 167| Step: 0
Training loss: 1.7439552545547485
Validation loss: 2.026152031396025

Epoch: 5| Step: 1
Training loss: 2.1732983589172363
Validation loss: 2.0522724377211703

Epoch: 5| Step: 2
Training loss: 1.8469264507293701
Validation loss: 2.054945244584032

Epoch: 5| Step: 3
Training loss: 2.087353467941284
Validation loss: 2.0605158190573416

Epoch: 5| Step: 4
Training loss: 2.1261520385742188
Validation loss: 2.0634505646203154

Epoch: 5| Step: 5
Training loss: 1.499280333518982
Validation loss: 2.0634758241714968

Epoch: 5| Step: 6
Training loss: 1.8794454336166382
Validation loss: 2.042362338753157

Epoch: 5| Step: 7
Training loss: 1.4961873292922974
Validation loss: 2.0443492845822404

Epoch: 5| Step: 8
Training loss: 1.731218695640564
Validation loss: 2.0514805675834737

Epoch: 5| Step: 9
Training loss: 2.107257127761841
Validation loss: 2.0677166062016643

Epoch: 5| Step: 10
Training loss: 2.4614696502685547
Validation loss: 2.0988064145529144

Epoch: 168| Step: 0
Training loss: 2.4877328872680664
Validation loss: 2.0935283501942954

Epoch: 5| Step: 1
Training loss: 1.7268626689910889
Validation loss: 2.0664418974230365

Epoch: 5| Step: 2
Training loss: 2.2667269706726074
Validation loss: 2.0605509152976413

Epoch: 5| Step: 3
Training loss: 0.8263519406318665
Validation loss: 2.0371979795476443

Epoch: 5| Step: 4
Training loss: 1.7667911052703857
Validation loss: 2.0564921504707745

Epoch: 5| Step: 5
Training loss: 1.5543228387832642
Validation loss: 2.0797208957774664

Epoch: 5| Step: 6
Training loss: 2.620068073272705
Validation loss: 2.0709258856311923

Epoch: 5| Step: 7
Training loss: 1.95553719997406
Validation loss: 2.0795643380893174

Epoch: 5| Step: 8
Training loss: 2.0422587394714355
Validation loss: 2.1112303528734433

Epoch: 5| Step: 9
Training loss: 1.900368094444275
Validation loss: 2.122850764182306

Epoch: 5| Step: 10
Training loss: 1.488542079925537
Validation loss: 2.1523099740346274

Epoch: 169| Step: 0
Training loss: 2.7062413692474365
Validation loss: 2.157577872276306

Epoch: 5| Step: 1
Training loss: 2.2874629497528076
Validation loss: 2.1371300323035127

Epoch: 5| Step: 2
Training loss: 1.770439863204956
Validation loss: 2.1032149894263155

Epoch: 5| Step: 3
Training loss: 1.596110224723816
Validation loss: 2.0805459458340883

Epoch: 5| Step: 4
Training loss: 1.1259698867797852
Validation loss: 2.051236608976959

Epoch: 5| Step: 5
Training loss: 1.6893037557601929
Validation loss: 2.0441636282910585

Epoch: 5| Step: 6
Training loss: 1.796114206314087
Validation loss: 2.0397728463654876

Epoch: 5| Step: 7
Training loss: 2.125558614730835
Validation loss: 2.0232712786684752

Epoch: 5| Step: 8
Training loss: 1.7427765130996704
Validation loss: 2.043216492540093

Epoch: 5| Step: 9
Training loss: 1.7491391897201538
Validation loss: 2.05468742052714

Epoch: 5| Step: 10
Training loss: 1.6581535339355469
Validation loss: 2.077868253953995

Epoch: 170| Step: 0
Training loss: 2.2063984870910645
Validation loss: 2.0903034005113827

Epoch: 5| Step: 1
Training loss: 1.6116809844970703
Validation loss: 2.1140035147308023

Epoch: 5| Step: 2
Training loss: 1.4294049739837646
Validation loss: 2.117479649923181

Epoch: 5| Step: 3
Training loss: 2.0898265838623047
Validation loss: 2.111627495417031

Epoch: 5| Step: 4
Training loss: 1.7542197704315186
Validation loss: 2.0947232605308614

Epoch: 5| Step: 5
Training loss: 2.256613254547119
Validation loss: 2.0536145266666206

Epoch: 5| Step: 6
Training loss: 1.1117109060287476
Validation loss: 2.0457906902477307

Epoch: 5| Step: 7
Training loss: 2.050867795944214
Validation loss: 2.0499362689192577

Epoch: 5| Step: 8
Training loss: 1.7376285791397095
Validation loss: 2.06354945705783

Epoch: 5| Step: 9
Training loss: 2.150489091873169
Validation loss: 2.0650702266282934

Epoch: 5| Step: 10
Training loss: 1.7466098070144653
Validation loss: 2.0684065895695842

Epoch: 171| Step: 0
Training loss: 2.0908167362213135
Validation loss: 2.0747483622643257

Epoch: 5| Step: 1
Training loss: 1.6655222177505493
Validation loss: 2.0709248255657893

Epoch: 5| Step: 2
Training loss: 1.981213927268982
Validation loss: 2.042644863487572

Epoch: 5| Step: 3
Training loss: 1.7694498300552368
Validation loss: 2.0634841380580777

Epoch: 5| Step: 4
Training loss: 1.994515061378479
Validation loss: 2.080687407524355

Epoch: 5| Step: 5
Training loss: 2.4258463382720947
Validation loss: 2.0842527266471618

Epoch: 5| Step: 6
Training loss: 1.550405740737915
Validation loss: 2.0680387430293585

Epoch: 5| Step: 7
Training loss: 2.2174220085144043
Validation loss: 2.0767545635982225

Epoch: 5| Step: 8
Training loss: 1.0092850923538208
Validation loss: 2.1028131592658257

Epoch: 5| Step: 9
Training loss: 1.623822808265686
Validation loss: 2.082964425445885

Epoch: 5| Step: 10
Training loss: 1.5687057971954346
Validation loss: 2.1037077198746386

Epoch: 172| Step: 0
Training loss: 1.620218276977539
Validation loss: 2.102444150114572

Epoch: 5| Step: 1
Training loss: 1.92757248878479
Validation loss: 2.1159467056233394

Epoch: 5| Step: 2
Training loss: 1.334908366203308
Validation loss: 2.1174473198511268

Epoch: 5| Step: 3
Training loss: 1.2268859148025513
Validation loss: 2.1251026943165767

Epoch: 5| Step: 4
Training loss: 1.6919084787368774
Validation loss: 2.1228089358216975

Epoch: 5| Step: 5
Training loss: 2.000635862350464
Validation loss: 2.147168440203513

Epoch: 5| Step: 6
Training loss: 2.4443562030792236
Validation loss: 2.1426428723078903

Epoch: 5| Step: 7
Training loss: 1.850545883178711
Validation loss: 2.116632875575814

Epoch: 5| Step: 8
Training loss: 1.620335340499878
Validation loss: 2.085358832472114

Epoch: 5| Step: 9
Training loss: 2.1805710792541504
Validation loss: 2.0810589123797674

Epoch: 5| Step: 10
Training loss: 1.7665414810180664
Validation loss: 2.051288946982353

Epoch: 173| Step: 0
Training loss: 1.1008057594299316
Validation loss: 2.042538904374646

Epoch: 5| Step: 1
Training loss: 1.7652400732040405
Validation loss: 2.042689647725833

Epoch: 5| Step: 2
Training loss: 1.8109477758407593
Validation loss: 2.0678360449370516

Epoch: 5| Step: 3
Training loss: 1.9836695194244385
Validation loss: 2.06395544544343

Epoch: 5| Step: 4
Training loss: 1.3917272090911865
Validation loss: 2.074098825454712

Epoch: 5| Step: 5
Training loss: 2.1070330142974854
Validation loss: 2.0827495513423795

Epoch: 5| Step: 6
Training loss: 1.7032277584075928
Validation loss: 2.0679338414181947

Epoch: 5| Step: 7
Training loss: 1.5388805866241455
Validation loss: 2.0606341643999984

Epoch: 5| Step: 8
Training loss: 1.9707725048065186
Validation loss: 2.0811048323108303

Epoch: 5| Step: 9
Training loss: 2.006077289581299
Validation loss: 2.091149030193206

Epoch: 5| Step: 10
Training loss: 1.9940439462661743
Validation loss: 2.1195802034870272

Epoch: 174| Step: 0
Training loss: 1.3121768236160278
Validation loss: 2.1105108568745274

Epoch: 5| Step: 1
Training loss: 1.759918212890625
Validation loss: 2.125317506892707

Epoch: 5| Step: 2
Training loss: 1.5076302289962769
Validation loss: 2.1102089561441892

Epoch: 5| Step: 3
Training loss: 1.8316242694854736
Validation loss: 2.1002742244351293

Epoch: 5| Step: 4
Training loss: 1.529768466949463
Validation loss: 2.096703225566495

Epoch: 5| Step: 5
Training loss: 1.8159418106079102
Validation loss: 2.0965032795424103

Epoch: 5| Step: 6
Training loss: 1.9592288732528687
Validation loss: 2.0724875568061747

Epoch: 5| Step: 7
Training loss: 1.6361865997314453
Validation loss: 2.041835202965685

Epoch: 5| Step: 8
Training loss: 1.6689001321792603
Validation loss: 2.0295844129336778

Epoch: 5| Step: 9
Training loss: 2.1331887245178223
Validation loss: 2.0492047340639177

Epoch: 5| Step: 10
Training loss: 2.1417183876037598
Validation loss: 2.066895995088803

Epoch: 175| Step: 0
Training loss: 1.839917540550232
Validation loss: 2.067255384178572

Epoch: 5| Step: 1
Training loss: 1.5605653524398804
Validation loss: 2.0723082993620183

Epoch: 5| Step: 2
Training loss: 1.7981065511703491
Validation loss: 2.068901733685565

Epoch: 5| Step: 3
Training loss: 1.6973590850830078
Validation loss: 2.088741160208179

Epoch: 5| Step: 4
Training loss: 1.302016019821167
Validation loss: 2.106679503635694

Epoch: 5| Step: 5
Training loss: 1.6925086975097656
Validation loss: 2.0999228877405964

Epoch: 5| Step: 6
Training loss: 2.0592942237854004
Validation loss: 2.1043901417845037

Epoch: 5| Step: 7
Training loss: 1.9507118463516235
Validation loss: 2.105607958250148

Epoch: 5| Step: 8
Training loss: 2.0780253410339355
Validation loss: 2.105677845657513

Epoch: 5| Step: 9
Training loss: 1.7107595205307007
Validation loss: 2.0710516924499185

Epoch: 5| Step: 10
Training loss: 1.4979286193847656
Validation loss: 2.0962745502430904

Epoch: 176| Step: 0
Training loss: 1.413329005241394
Validation loss: 2.086806542129927

Epoch: 5| Step: 1
Training loss: 1.8987939357757568
Validation loss: 2.101623204446608

Epoch: 5| Step: 2
Training loss: 1.6475951671600342
Validation loss: 2.099906449676842

Epoch: 5| Step: 3
Training loss: 1.7211277484893799
Validation loss: 2.062132468787573

Epoch: 5| Step: 4
Training loss: 1.7408326864242554
Validation loss: 2.042076349258423

Epoch: 5| Step: 5
Training loss: 2.294750213623047
Validation loss: 2.0098247861349456

Epoch: 5| Step: 6
Training loss: 2.1909186840057373
Validation loss: 2.002743613335394

Epoch: 5| Step: 7
Training loss: 1.4071537256240845
Validation loss: 1.987575206705319

Epoch: 5| Step: 8
Training loss: 1.1656429767608643
Validation loss: 1.9807522271269111

Epoch: 5| Step: 9
Training loss: 1.654288649559021
Validation loss: 1.9924739150590793

Epoch: 5| Step: 10
Training loss: 2.0337700843811035
Validation loss: 2.0243775229300223

Epoch: 177| Step: 0
Training loss: 1.8486192226409912
Validation loss: 2.0279627089859336

Epoch: 5| Step: 1
Training loss: 1.8151153326034546
Validation loss: 2.0829003549391225

Epoch: 5| Step: 2
Training loss: 1.35211181640625
Validation loss: 2.105576084506127

Epoch: 5| Step: 3
Training loss: 1.3723535537719727
Validation loss: 2.1251363574817614

Epoch: 5| Step: 4
Training loss: 1.4521033763885498
Validation loss: 2.1420177285389235

Epoch: 5| Step: 5
Training loss: 1.8812965154647827
Validation loss: 2.1619184991364837

Epoch: 5| Step: 6
Training loss: 1.8242696523666382
Validation loss: 2.1581482720631424

Epoch: 5| Step: 7
Training loss: 1.7640626430511475
Validation loss: 2.143602301997523

Epoch: 5| Step: 8
Training loss: 1.8411823511123657
Validation loss: 2.1096842929881108

Epoch: 5| Step: 9
Training loss: 1.8980598449707031
Validation loss: 2.0724828896983976

Epoch: 5| Step: 10
Training loss: 1.6221195459365845
Validation loss: 2.063616693660777

Epoch: 178| Step: 0
Training loss: 1.1580584049224854
Validation loss: 2.057911196062642

Epoch: 5| Step: 1
Training loss: 1.5276461839675903
Validation loss: 2.0563639927935857

Epoch: 5| Step: 2
Training loss: 1.6250998973846436
Validation loss: 2.042733719271998

Epoch: 5| Step: 3
Training loss: 1.8534473180770874
Validation loss: 2.027663471878216

Epoch: 5| Step: 4
Training loss: 1.8786693811416626
Validation loss: 2.044571904725926

Epoch: 5| Step: 5
Training loss: 1.480600357055664
Validation loss: 2.0636736398102133

Epoch: 5| Step: 6
Training loss: 1.5067235231399536
Validation loss: 2.095059076944987

Epoch: 5| Step: 7
Training loss: 1.9857228994369507
Validation loss: 2.1097564133264686

Epoch: 5| Step: 8
Training loss: 2.04763126373291
Validation loss: 2.1188992377250426

Epoch: 5| Step: 9
Training loss: 1.548465371131897
Validation loss: 2.1012419449385775

Epoch: 5| Step: 10
Training loss: 1.810775876045227
Validation loss: 2.1118234921527166

Epoch: 179| Step: 0
Training loss: 1.0732561349868774
Validation loss: 2.0828969222243114

Epoch: 5| Step: 1
Training loss: 1.9202057123184204
Validation loss: 2.0663156355580976

Epoch: 5| Step: 2
Training loss: 1.3950115442276
Validation loss: 2.0667965873595207

Epoch: 5| Step: 3
Training loss: 1.7901557683944702
Validation loss: 2.058640081395385

Epoch: 5| Step: 4
Training loss: 1.5866644382476807
Validation loss: 2.052028058677591

Epoch: 5| Step: 5
Training loss: 1.7766567468643188
Validation loss: 2.0440992604019823

Epoch: 5| Step: 6
Training loss: 1.6958343982696533
Validation loss: 2.0718395620264034

Epoch: 5| Step: 7
Training loss: 1.7696075439453125
Validation loss: 2.0678314444839314

Epoch: 5| Step: 8
Training loss: 1.9297382831573486
Validation loss: 2.0790589163380284

Epoch: 5| Step: 9
Training loss: 1.3571981191635132
Validation loss: 2.0880832569573515

Epoch: 5| Step: 10
Training loss: 1.8241561651229858
Validation loss: 2.1220182475223335

Epoch: 180| Step: 0
Training loss: 2.053279399871826
Validation loss: 2.158203476218767

Epoch: 5| Step: 1
Training loss: 2.041435956954956
Validation loss: 2.1590036243520756

Epoch: 5| Step: 2
Training loss: 1.4938499927520752
Validation loss: 2.1427166949036303

Epoch: 5| Step: 3
Training loss: 1.4180657863616943
Validation loss: 2.145874531038346

Epoch: 5| Step: 4
Training loss: 1.3646072149276733
Validation loss: 2.155897596830963

Epoch: 5| Step: 5
Training loss: 1.7176475524902344
Validation loss: 2.1444446912375827

Epoch: 5| Step: 6
Training loss: 1.466645359992981
Validation loss: 2.1565879262903684

Epoch: 5| Step: 7
Training loss: 1.6381601095199585
Validation loss: 2.1340899159831386

Epoch: 5| Step: 8
Training loss: 1.4612435102462769
Validation loss: 2.0989072066481396

Epoch: 5| Step: 9
Training loss: 1.2073403596878052
Validation loss: 2.0702818196306945

Epoch: 5| Step: 10
Training loss: 2.3901150226593018
Validation loss: 2.0535103864567255

Epoch: 181| Step: 0
Training loss: 1.4241794347763062
Validation loss: 2.0501684117060837

Epoch: 5| Step: 1
Training loss: 1.341515302658081
Validation loss: 2.0273953701860163

Epoch: 5| Step: 2
Training loss: 1.9450809955596924
Validation loss: 2.016430982979395

Epoch: 5| Step: 3
Training loss: 1.5185569524765015
Validation loss: 2.010074343732608

Epoch: 5| Step: 4
Training loss: 1.7657381296157837
Validation loss: 2.0366968390762166

Epoch: 5| Step: 5
Training loss: 1.70901620388031
Validation loss: 2.0224541502614177

Epoch: 5| Step: 6
Training loss: 1.0565892457962036
Validation loss: 2.0366248879381406

Epoch: 5| Step: 7
Training loss: 2.3899102210998535
Validation loss: 2.0556816516384

Epoch: 5| Step: 8
Training loss: 1.714923620223999
Validation loss: 2.063203965463946

Epoch: 5| Step: 9
Training loss: 1.5519710779190063
Validation loss: 2.0711719323230047

Epoch: 5| Step: 10
Training loss: 1.8030102252960205
Validation loss: 2.0857451987522904

Epoch: 182| Step: 0
Training loss: 2.17018461227417
Validation loss: 2.097344752280943

Epoch: 5| Step: 1
Training loss: 1.3250653743743896
Validation loss: 2.131065586561798

Epoch: 5| Step: 2
Training loss: 2.0534613132476807
Validation loss: 2.11597748597463

Epoch: 5| Step: 3
Training loss: 2.024345874786377
Validation loss: 2.138032126170333

Epoch: 5| Step: 4
Training loss: 1.8917824029922485
Validation loss: 2.106222327037524

Epoch: 5| Step: 5
Training loss: 1.3238027095794678
Validation loss: 2.0983978830358034

Epoch: 5| Step: 6
Training loss: 1.3188625574111938
Validation loss: 2.1122993551274782

Epoch: 5| Step: 7
Training loss: 1.3628219366073608
Validation loss: 2.1469137617336806

Epoch: 5| Step: 8
Training loss: 1.5576437711715698
Validation loss: 2.1413263300413727

Epoch: 5| Step: 9
Training loss: 1.3966567516326904
Validation loss: 2.1542086242347636

Epoch: 5| Step: 10
Training loss: 1.3362176418304443
Validation loss: 2.15533705424237

Epoch: 183| Step: 0
Training loss: 1.185190200805664
Validation loss: 2.152876374542072

Epoch: 5| Step: 1
Training loss: 1.1699440479278564
Validation loss: 2.154165898599932

Epoch: 5| Step: 2
Training loss: 1.8047349452972412
Validation loss: 2.125270511514397

Epoch: 5| Step: 3
Training loss: 1.8905500173568726
Validation loss: 2.088199343732608

Epoch: 5| Step: 4
Training loss: 1.5939791202545166
Validation loss: 2.0823654410659627

Epoch: 5| Step: 5
Training loss: 2.138584613800049
Validation loss: 2.062579116513652

Epoch: 5| Step: 6
Training loss: 1.577232837677002
Validation loss: 2.0730866206589567

Epoch: 5| Step: 7
Training loss: 1.7656948566436768
Validation loss: 2.088541708966737

Epoch: 5| Step: 8
Training loss: 1.8146400451660156
Validation loss: 2.112969001134237

Epoch: 5| Step: 9
Training loss: 1.1223911046981812
Validation loss: 2.133432649797009

Epoch: 5| Step: 10
Training loss: 1.4700583219528198
Validation loss: 2.174263987489926

Epoch: 184| Step: 0
Training loss: 1.8582807779312134
Validation loss: 2.1984956892587806

Epoch: 5| Step: 1
Training loss: 1.3609323501586914
Validation loss: 2.205807611506472

Epoch: 5| Step: 2
Training loss: 1.4834811687469482
Validation loss: 2.2020984772712953

Epoch: 5| Step: 3
Training loss: 1.3019330501556396
Validation loss: 2.1915714792025986

Epoch: 5| Step: 4
Training loss: 1.684586524963379
Validation loss: 2.182620034422926

Epoch: 5| Step: 5
Training loss: 1.5579502582550049
Validation loss: 2.170420123684791

Epoch: 5| Step: 6
Training loss: 1.4254525899887085
Validation loss: 2.1614192198681574

Epoch: 5| Step: 7
Training loss: 1.6325995922088623
Validation loss: 2.1511123949481594

Epoch: 5| Step: 8
Training loss: 1.5924437046051025
Validation loss: 2.145581965805382

Epoch: 5| Step: 9
Training loss: 1.595152497291565
Validation loss: 2.1316898381838234

Epoch: 5| Step: 10
Training loss: 1.9630084037780762
Validation loss: 2.113407281137282

Epoch: 185| Step: 0
Training loss: 1.6457641124725342
Validation loss: 2.116657490371376

Epoch: 5| Step: 1
Training loss: 1.8516159057617188
Validation loss: 2.081364349652362

Epoch: 5| Step: 2
Training loss: 1.7368627786636353
Validation loss: 2.093811337665845

Epoch: 5| Step: 3
Training loss: 1.4114844799041748
Validation loss: 2.1118934744147846

Epoch: 5| Step: 4
Training loss: 1.2154890298843384
Validation loss: 2.0891703072414605

Epoch: 5| Step: 5
Training loss: 1.6659746170043945
Validation loss: 2.101238783969674

Epoch: 5| Step: 6
Training loss: 1.4962553977966309
Validation loss: 2.099213073330541

Epoch: 5| Step: 7
Training loss: 2.1385622024536133
Validation loss: 2.073574596835721

Epoch: 5| Step: 8
Training loss: 1.297601342201233
Validation loss: 2.082723476553476

Epoch: 5| Step: 9
Training loss: 1.3283106088638306
Validation loss: 2.0889495649645404

Epoch: 5| Step: 10
Training loss: 1.3652801513671875
Validation loss: 2.087950013017142

Epoch: 186| Step: 0
Training loss: 1.2885706424713135
Validation loss: 2.0515662239443873

Epoch: 5| Step: 1
Training loss: 1.8164494037628174
Validation loss: 2.0476737073672715

Epoch: 5| Step: 2
Training loss: 1.8842365741729736
Validation loss: 2.056771347599645

Epoch: 5| Step: 3
Training loss: 1.546668291091919
Validation loss: 2.0609277076618646

Epoch: 5| Step: 4
Training loss: 0.6396269798278809
Validation loss: 2.124313303219375

Epoch: 5| Step: 5
Training loss: 1.739485740661621
Validation loss: 2.1577927527889127

Epoch: 5| Step: 6
Training loss: 2.021178722381592
Validation loss: 2.1667941795882357

Epoch: 5| Step: 7
Training loss: 1.9832664728164673
Validation loss: 2.1567036567195768

Epoch: 5| Step: 8
Training loss: 1.6558090448379517
Validation loss: 2.118890139364427

Epoch: 5| Step: 9
Training loss: 1.2274854183197021
Validation loss: 2.107022628989271

Epoch: 5| Step: 10
Training loss: 1.375475525856018
Validation loss: 2.073751711076306

Epoch: 187| Step: 0
Training loss: 1.706446647644043
Validation loss: 2.085859731961322

Epoch: 5| Step: 1
Training loss: 1.65261971950531
Validation loss: 2.068455457687378

Epoch: 5| Step: 2
Training loss: 1.6392608880996704
Validation loss: 2.093512386404058

Epoch: 5| Step: 3
Training loss: 1.2417091131210327
Validation loss: 2.075835189511699

Epoch: 5| Step: 4
Training loss: 1.3980381488800049
Validation loss: 2.0591346576649654

Epoch: 5| Step: 5
Training loss: 2.00960111618042
Validation loss: 2.0466926943871284

Epoch: 5| Step: 6
Training loss: 1.4511622190475464
Validation loss: 2.063718972667571

Epoch: 5| Step: 7
Training loss: 1.4575512409210205
Validation loss: 2.0670807976876535

Epoch: 5| Step: 8
Training loss: 1.29986572265625
Validation loss: 2.112608471224385

Epoch: 5| Step: 9
Training loss: 1.3716098070144653
Validation loss: 2.0947817551192416

Epoch: 5| Step: 10
Training loss: 1.5393346548080444
Validation loss: 2.111705962047782

Epoch: 188| Step: 0
Training loss: 0.9221107363700867
Validation loss: 2.079949986550116

Epoch: 5| Step: 1
Training loss: 2.0138018131256104
Validation loss: 2.0533437805791057

Epoch: 5| Step: 2
Training loss: 1.8794746398925781
Validation loss: 2.049836518943951

Epoch: 5| Step: 3
Training loss: 1.8338186740875244
Validation loss: 2.0260597992968816

Epoch: 5| Step: 4
Training loss: 1.546872854232788
Validation loss: 2.0485108642167944

Epoch: 5| Step: 5
Training loss: 1.4526805877685547
Validation loss: 2.050459918155465

Epoch: 5| Step: 6
Training loss: 1.8766494989395142
Validation loss: 2.0686907973340762

Epoch: 5| Step: 7
Training loss: 1.2596728801727295
Validation loss: 2.0848595403855845

Epoch: 5| Step: 8
Training loss: 1.0777053833007812
Validation loss: 2.0899243559888614

Epoch: 5| Step: 9
Training loss: 1.3843191862106323
Validation loss: 2.128543890932555

Epoch: 5| Step: 10
Training loss: 1.1812900304794312
Validation loss: 2.195945014235794

Epoch: 189| Step: 0
Training loss: 1.8745689392089844
Validation loss: 2.2140822974584435

Epoch: 5| Step: 1
Training loss: 1.2674378156661987
Validation loss: 2.195753551298572

Epoch: 5| Step: 2
Training loss: 1.306557059288025
Validation loss: 2.1268193619225615

Epoch: 5| Step: 3
Training loss: 1.3580701351165771
Validation loss: 2.095622701029624

Epoch: 5| Step: 4
Training loss: 1.5652735233306885
Validation loss: 2.076155380536151

Epoch: 5| Step: 5
Training loss: 1.6105092763900757
Validation loss: 2.0633795184473835

Epoch: 5| Step: 6
Training loss: 1.3742282390594482
Validation loss: 2.0624861358314432

Epoch: 5| Step: 7
Training loss: 2.0441792011260986
Validation loss: 2.037178772752003

Epoch: 5| Step: 8
Training loss: 1.4398537874221802
Validation loss: 2.0276175224652855

Epoch: 5| Step: 9
Training loss: 1.0564453601837158
Validation loss: 2.0189929367393575

Epoch: 5| Step: 10
Training loss: 1.9529963731765747
Validation loss: 2.0417357260181057

Epoch: 190| Step: 0
Training loss: 1.4469082355499268
Validation loss: 2.0763775802427724

Epoch: 5| Step: 1
Training loss: 1.507098913192749
Validation loss: 2.1151360234906598

Epoch: 5| Step: 2
Training loss: 2.0093963146209717
Validation loss: 2.152195603616776

Epoch: 5| Step: 3
Training loss: 1.422979474067688
Validation loss: 2.1257479165190007

Epoch: 5| Step: 4
Training loss: 1.5734782218933105
Validation loss: 2.134442651143638

Epoch: 5| Step: 5
Training loss: 1.2015149593353271
Validation loss: 2.123897308944374

Epoch: 5| Step: 6
Training loss: 0.8733388781547546
Validation loss: 2.130142372141602

Epoch: 5| Step: 7
Training loss: 1.5167956352233887
Validation loss: 2.1301235588647986

Epoch: 5| Step: 8
Training loss: 1.7764489650726318
Validation loss: 2.1029718011938114

Epoch: 5| Step: 9
Training loss: 1.7208608388900757
Validation loss: 2.102526130214814

Epoch: 5| Step: 10
Training loss: 1.3202159404754639
Validation loss: 2.0941197667070615

Epoch: 191| Step: 0
Training loss: 1.460047960281372
Validation loss: 2.0936705720040107

Epoch: 5| Step: 1
Training loss: 1.1953424215316772
Validation loss: 2.1108989484848513

Epoch: 5| Step: 2
Training loss: 1.715047836303711
Validation loss: 2.1024794783643497

Epoch: 5| Step: 3
Training loss: 1.5032387971878052
Validation loss: 2.1330751629285913

Epoch: 5| Step: 4
Training loss: 1.8172242641448975
Validation loss: 2.14990383578885

Epoch: 5| Step: 5
Training loss: 1.3516416549682617
Validation loss: 2.132093988439088

Epoch: 5| Step: 6
Training loss: 1.6247844696044922
Validation loss: 2.120252875871556

Epoch: 5| Step: 7
Training loss: 1.2830276489257812
Validation loss: 2.0846092277957546

Epoch: 5| Step: 8
Training loss: 1.058856725692749
Validation loss: 2.0745108204503215

Epoch: 5| Step: 9
Training loss: 0.8285869359970093
Validation loss: 2.0682933676627373

Epoch: 5| Step: 10
Training loss: 2.0086302757263184
Validation loss: 2.068663284342776

Epoch: 192| Step: 0
Training loss: 1.0487723350524902
Validation loss: 2.079157378083916

Epoch: 5| Step: 1
Training loss: 1.8561210632324219
Validation loss: 2.0707781814759776

Epoch: 5| Step: 2
Training loss: 1.103930950164795
Validation loss: 2.0647857394269717

Epoch: 5| Step: 3
Training loss: 2.3059139251708984
Validation loss: 2.057651137792936

Epoch: 5| Step: 4
Training loss: 1.2130658626556396
Validation loss: 2.043555159722605

Epoch: 5| Step: 5
Training loss: 1.483373999595642
Validation loss: 2.0431844431866883

Epoch: 5| Step: 6
Training loss: 1.2955234050750732
Validation loss: 2.045336177272181

Epoch: 5| Step: 7
Training loss: 1.1664760112762451
Validation loss: 2.048412976726409

Epoch: 5| Step: 8
Training loss: 1.292081594467163
Validation loss: 2.074740784142607

Epoch: 5| Step: 9
Training loss: 1.6259523630142212
Validation loss: 2.0880298947775238

Epoch: 5| Step: 10
Training loss: 1.3068209886550903
Validation loss: 2.0959004958470664

Epoch: 193| Step: 0
Training loss: 1.053378701210022
Validation loss: 2.0980689397422214

Epoch: 5| Step: 1
Training loss: 2.0648739337921143
Validation loss: 2.0873405471924813

Epoch: 5| Step: 2
Training loss: 1.3682878017425537
Validation loss: 2.1040680498205204

Epoch: 5| Step: 3
Training loss: 1.558370590209961
Validation loss: 2.0911699097643615

Epoch: 5| Step: 4
Training loss: 1.5394474267959595
Validation loss: 2.0551773719890143

Epoch: 5| Step: 5
Training loss: 1.378568410873413
Validation loss: 2.059189272183244

Epoch: 5| Step: 6
Training loss: 1.460815191268921
Validation loss: 2.029732786199098

Epoch: 5| Step: 7
Training loss: 1.0651214122772217
Validation loss: 2.0501173721846713

Epoch: 5| Step: 8
Training loss: 1.057037353515625
Validation loss: 2.036331661285893

Epoch: 5| Step: 9
Training loss: 1.6282247304916382
Validation loss: 2.061406945669523

Epoch: 5| Step: 10
Training loss: 1.3923856019973755
Validation loss: 2.101039143018825

Epoch: 194| Step: 0
Training loss: 1.8349025249481201
Validation loss: 2.126860696782348

Epoch: 5| Step: 1
Training loss: 1.5053848028182983
Validation loss: 2.1758662885235203

Epoch: 5| Step: 2
Training loss: 1.3886981010437012
Validation loss: 2.1484147258984145

Epoch: 5| Step: 3
Training loss: 1.2019026279449463
Validation loss: 2.1112224312238794

Epoch: 5| Step: 4
Training loss: 1.7225255966186523
Validation loss: 2.105701349114859

Epoch: 5| Step: 5
Training loss: 1.5094789266586304
Validation loss: 2.0597139276484007

Epoch: 5| Step: 6
Training loss: 1.4590132236480713
Validation loss: 2.0583999310770342

Epoch: 5| Step: 7
Training loss: 1.2501575946807861
Validation loss: 2.053098670897945

Epoch: 5| Step: 8
Training loss: 1.0669398307800293
Validation loss: 2.054929335912069

Epoch: 5| Step: 9
Training loss: 1.2270570993423462
Validation loss: 2.114264957366451

Epoch: 5| Step: 10
Training loss: 1.538090705871582
Validation loss: 2.1458437058233444

Epoch: 195| Step: 0
Training loss: 1.4103715419769287
Validation loss: 2.1476651507039226

Epoch: 5| Step: 1
Training loss: 1.3798311948776245
Validation loss: 2.1593213940179474

Epoch: 5| Step: 2
Training loss: 1.773956537246704
Validation loss: 2.119072280904298

Epoch: 5| Step: 3
Training loss: 1.6876178979873657
Validation loss: 2.130830964734477

Epoch: 5| Step: 4
Training loss: 1.3441162109375
Validation loss: 2.1044887470942673

Epoch: 5| Step: 5
Training loss: 0.9219063520431519
Validation loss: 2.1014074330688803

Epoch: 5| Step: 6
Training loss: 1.4417747259140015
Validation loss: 2.095438482940838

Epoch: 5| Step: 7
Training loss: 1.7662124633789062
Validation loss: 2.0909832728806363

Epoch: 5| Step: 8
Training loss: 1.0784263610839844
Validation loss: 2.0488776801734843

Epoch: 5| Step: 9
Training loss: 1.1834181547164917
Validation loss: 2.0760304197188346

Epoch: 5| Step: 10
Training loss: 1.1565908193588257
Validation loss: 2.0698355961871404

Epoch: 196| Step: 0
Training loss: 2.055746555328369
Validation loss: 2.0866507176429994

Epoch: 5| Step: 1
Training loss: 1.1928808689117432
Validation loss: 2.0732372755645425

Epoch: 5| Step: 2
Training loss: 1.4943609237670898
Validation loss: 2.0589792061877508

Epoch: 5| Step: 3
Training loss: 1.2572768926620483
Validation loss: 2.0495302254153835

Epoch: 5| Step: 4
Training loss: 1.54355788230896
Validation loss: 2.060998538488983

Epoch: 5| Step: 5
Training loss: 1.4928401708602905
Validation loss: 2.068738752795804

Epoch: 5| Step: 6
Training loss: 1.4457937479019165
Validation loss: 2.0574327130471506

Epoch: 5| Step: 7
Training loss: 1.1243938207626343
Validation loss: 2.0625017227665072

Epoch: 5| Step: 8
Training loss: 0.9771007299423218
Validation loss: 2.0741966385995187

Epoch: 5| Step: 9
Training loss: 1.2891321182250977
Validation loss: 2.0680020727137083

Epoch: 5| Step: 10
Training loss: 1.0123417377471924
Validation loss: 2.0979892746094735

Epoch: 197| Step: 0
Training loss: 1.5466969013214111
Validation loss: 2.1326999843761487

Epoch: 5| Step: 1
Training loss: 1.4099496603012085
Validation loss: 2.134128678229547

Epoch: 5| Step: 2
Training loss: 0.9104387164115906
Validation loss: 2.15012530613971

Epoch: 5| Step: 3
Training loss: 1.2052586078643799
Validation loss: 2.168933190325255

Epoch: 5| Step: 4
Training loss: 1.4199011325836182
Validation loss: 2.16316044586961

Epoch: 5| Step: 5
Training loss: 1.1441080570220947
Validation loss: 2.131810047293222

Epoch: 5| Step: 6
Training loss: 1.3631629943847656
Validation loss: 2.1533000494844172

Epoch: 5| Step: 7
Training loss: 1.198457956314087
Validation loss: 2.1294726940893356

Epoch: 5| Step: 8
Training loss: 1.574764370918274
Validation loss: 2.1083348745940835

Epoch: 5| Step: 9
Training loss: 1.9118156433105469
Validation loss: 2.1401138203118437

Epoch: 5| Step: 10
Training loss: 1.3856369256973267
Validation loss: 2.1322476428042174

Epoch: 198| Step: 0
Training loss: 1.7018530368804932
Validation loss: 2.110990911401728

Epoch: 5| Step: 1
Training loss: 1.6106445789337158
Validation loss: 2.105877596844909

Epoch: 5| Step: 2
Training loss: 1.5176331996917725
Validation loss: 2.092174594120313

Epoch: 5| Step: 3
Training loss: 1.5884475708007812
Validation loss: 2.108795776162096

Epoch: 5| Step: 4
Training loss: 0.9621635675430298
Validation loss: 2.0964521490117556

Epoch: 5| Step: 5
Training loss: 0.988444447517395
Validation loss: 2.0944384580017417

Epoch: 5| Step: 6
Training loss: 1.180778980255127
Validation loss: 2.1225243588929534

Epoch: 5| Step: 7
Training loss: 0.8655235171318054
Validation loss: 2.1580606532353226

Epoch: 5| Step: 8
Training loss: 2.0870137214660645
Validation loss: 2.1434738430925595

Epoch: 5| Step: 9
Training loss: 1.197986364364624
Validation loss: 2.1208058839203208

Epoch: 5| Step: 10
Training loss: 1.1152485609054565
Validation loss: 2.122396929289705

Epoch: 199| Step: 0
Training loss: 1.474980354309082
Validation loss: 2.141331652159332

Epoch: 5| Step: 1
Training loss: 1.2768280506134033
Validation loss: 2.141222256486134

Epoch: 5| Step: 2
Training loss: 1.183326244354248
Validation loss: 2.1053777381937993

Epoch: 5| Step: 3
Training loss: 1.2839546203613281
Validation loss: 2.114319964121747

Epoch: 5| Step: 4
Training loss: 1.1314939260482788
Validation loss: 2.087851175697901

Epoch: 5| Step: 5
Training loss: 1.4378526210784912
Validation loss: 2.042040365998463

Epoch: 5| Step: 6
Training loss: 2.0377910137176514
Validation loss: 2.0602278606865996

Epoch: 5| Step: 7
Training loss: 0.9969002604484558
Validation loss: 2.065671161938739

Epoch: 5| Step: 8
Training loss: 0.9847081303596497
Validation loss: 2.057019187558082

Epoch: 5| Step: 9
Training loss: 1.550289511680603
Validation loss: 2.083189618202948

Epoch: 5| Step: 10
Training loss: 0.8636547923088074
Validation loss: 2.1151744268273793

Epoch: 200| Step: 0
Training loss: 1.012893557548523
Validation loss: 2.122553038340743

Epoch: 5| Step: 1
Training loss: 1.7310072183609009
Validation loss: 2.0843735664121565

Epoch: 5| Step: 2
Training loss: 1.071673035621643
Validation loss: 2.070206222995635

Epoch: 5| Step: 3
Training loss: 1.7628695964813232
Validation loss: 2.071203162593226

Epoch: 5| Step: 4
Training loss: 1.4988141059875488
Validation loss: 2.0944600720559396

Epoch: 5| Step: 5
Training loss: 1.2192214727401733
Validation loss: 2.0994543849780993

Epoch: 5| Step: 6
Training loss: 1.3082225322723389
Validation loss: 2.0940723496098674

Epoch: 5| Step: 7
Training loss: 0.9998124241828918
Validation loss: 2.1168106807175504

Epoch: 5| Step: 8
Training loss: 0.8091700673103333
Validation loss: 2.110560319756949

Epoch: 5| Step: 9
Training loss: 1.2751327753067017
Validation loss: 2.1271724700927734

Epoch: 5| Step: 10
Training loss: 1.744767665863037
Validation loss: 2.060299688769925

Testing loss: 2.289188279045953
