Epoch: 1| Step: 0
Training loss: 5.495150089263916
Validation loss: 5.112357811261249

Epoch: 5| Step: 1
Training loss: 4.6013946533203125
Validation loss: 5.082116101377753

Epoch: 5| Step: 2
Training loss: 4.396085739135742
Validation loss: 5.055451393127441

Epoch: 5| Step: 3
Training loss: 4.855538845062256
Validation loss: 5.027902931295415

Epoch: 5| Step: 4
Training loss: 3.2395966053009033
Validation loss: 4.997252120766588

Epoch: 5| Step: 5
Training loss: 4.5164313316345215
Validation loss: 4.962706642766153

Epoch: 5| Step: 6
Training loss: 5.565370082855225
Validation loss: 4.924092328676614

Epoch: 5| Step: 7
Training loss: 3.247290849685669
Validation loss: 4.881133105165215

Epoch: 5| Step: 8
Training loss: 5.946630954742432
Validation loss: 4.833297801274125

Epoch: 5| Step: 9
Training loss: 5.038750171661377
Validation loss: 4.780235341800156

Epoch: 5| Step: 10
Training loss: 5.346569061279297
Validation loss: 4.723097524335308

Epoch: 2| Step: 0
Training loss: 3.895704746246338
Validation loss: 4.663581443089311

Epoch: 5| Step: 1
Training loss: 4.0921125411987305
Validation loss: 4.599501717475153

Epoch: 5| Step: 2
Training loss: 3.607088088989258
Validation loss: 4.530958411514118

Epoch: 5| Step: 3
Training loss: 5.409367561340332
Validation loss: 4.462338488589051

Epoch: 5| Step: 4
Training loss: 4.182698726654053
Validation loss: 4.391619923294232

Epoch: 5| Step: 5
Training loss: 4.573378086090088
Validation loss: 4.321677243837747

Epoch: 5| Step: 6
Training loss: 3.9480369091033936
Validation loss: 4.250688629765665

Epoch: 5| Step: 7
Training loss: 4.482457160949707
Validation loss: 4.179639421483522

Epoch: 5| Step: 8
Training loss: 3.4708263874053955
Validation loss: 4.114516330021684

Epoch: 5| Step: 9
Training loss: 4.1589531898498535
Validation loss: 4.0484824231875844

Epoch: 5| Step: 10
Training loss: 3.5727572441101074
Validation loss: 3.9835917180584324

Epoch: 3| Step: 0
Training loss: 4.1647047996521
Validation loss: 3.9271181270640385

Epoch: 5| Step: 1
Training loss: 2.731931447982788
Validation loss: 3.882295352156444

Epoch: 5| Step: 2
Training loss: 3.5623297691345215
Validation loss: 3.8444727210588354

Epoch: 5| Step: 3
Training loss: 3.0333731174468994
Validation loss: 3.8079793735217025

Epoch: 5| Step: 4
Training loss: 3.5749409198760986
Validation loss: 3.7698640361908944

Epoch: 5| Step: 5
Training loss: 3.3725669384002686
Validation loss: 3.7266255424868677

Epoch: 5| Step: 6
Training loss: 4.60259485244751
Validation loss: 3.698872971278365

Epoch: 5| Step: 7
Training loss: 3.0684237480163574
Validation loss: 3.674754188906762

Epoch: 5| Step: 8
Training loss: 4.133813381195068
Validation loss: 3.65404942727858

Epoch: 5| Step: 9
Training loss: 3.8235714435577393
Validation loss: 3.634868001425138

Epoch: 5| Step: 10
Training loss: 4.004474639892578
Validation loss: 3.6161323362781155

Epoch: 4| Step: 0
Training loss: 3.716775417327881
Validation loss: 3.5969889548517044

Epoch: 5| Step: 1
Training loss: 2.4719934463500977
Validation loss: 3.5774468375790502

Epoch: 5| Step: 2
Training loss: 3.9782676696777344
Validation loss: 3.5592429919909407

Epoch: 5| Step: 3
Training loss: 3.473407030105591
Validation loss: 3.550288987416093

Epoch: 5| Step: 4
Training loss: 3.4288532733917236
Validation loss: 3.529332660859631

Epoch: 5| Step: 5
Training loss: 3.3654754161834717
Validation loss: 3.5010524078082015

Epoch: 5| Step: 6
Training loss: 3.5272274017333984
Validation loss: 3.4929762604416057

Epoch: 5| Step: 7
Training loss: 3.7138874530792236
Validation loss: 3.486698001943609

Epoch: 5| Step: 8
Training loss: 3.6887435913085938
Validation loss: 3.466330487241027

Epoch: 5| Step: 9
Training loss: 3.3362159729003906
Validation loss: 3.4487785318846345

Epoch: 5| Step: 10
Training loss: 3.2102229595184326
Validation loss: 3.4305258848333873

Epoch: 5| Step: 0
Training loss: 2.841745376586914
Validation loss: 3.397997881776543

Epoch: 5| Step: 1
Training loss: 2.706533432006836
Validation loss: 3.377710852571713

Epoch: 5| Step: 2
Training loss: 3.721836805343628
Validation loss: 3.362435120408253

Epoch: 5| Step: 3
Training loss: 2.924501895904541
Validation loss: 3.3480947017669678

Epoch: 5| Step: 4
Training loss: 4.27984619140625
Validation loss: 3.344438568238289

Epoch: 5| Step: 5
Training loss: 3.050560712814331
Validation loss: 3.3332339948223484

Epoch: 5| Step: 6
Training loss: 3.986374616622925
Validation loss: 3.314732249065112

Epoch: 5| Step: 7
Training loss: 3.218289613723755
Validation loss: 3.287779897771856

Epoch: 5| Step: 8
Training loss: 2.342308759689331
Validation loss: 3.278701666862734

Epoch: 5| Step: 9
Training loss: 3.451582670211792
Validation loss: 3.282184636721047

Epoch: 5| Step: 10
Training loss: 3.656066656112671
Validation loss: 3.243362816431189

Epoch: 6| Step: 0
Training loss: 2.8321962356567383
Validation loss: 3.228881482155092

Epoch: 5| Step: 1
Training loss: 2.505187511444092
Validation loss: 3.2257023011484454

Epoch: 5| Step: 2
Training loss: 3.925407886505127
Validation loss: 3.2156480204674507

Epoch: 5| Step: 3
Training loss: 3.5090339183807373
Validation loss: 3.202359107232863

Epoch: 5| Step: 4
Training loss: 3.640291929244995
Validation loss: 3.189859015967256

Epoch: 5| Step: 5
Training loss: 2.9356918334960938
Validation loss: 3.175894434734057

Epoch: 5| Step: 6
Training loss: 2.7253620624542236
Validation loss: 3.1632803486239527

Epoch: 5| Step: 7
Training loss: 3.031764507293701
Validation loss: 3.1558151988572973

Epoch: 5| Step: 8
Training loss: 2.732377529144287
Validation loss: 3.146092020055299

Epoch: 5| Step: 9
Training loss: 3.2281851768493652
Validation loss: 3.1388926608588106

Epoch: 5| Step: 10
Training loss: 4.088725566864014
Validation loss: 3.1275967115996988

Epoch: 7| Step: 0
Training loss: 2.8944311141967773
Validation loss: 3.1212427975029073

Epoch: 5| Step: 1
Training loss: 3.355041980743408
Validation loss: 3.107866107776601

Epoch: 5| Step: 2
Training loss: 2.9613938331604004
Validation loss: 3.094393584036058

Epoch: 5| Step: 3
Training loss: 3.3865485191345215
Validation loss: 3.0887043347922702

Epoch: 5| Step: 4
Training loss: 3.654576063156128
Validation loss: 3.0810818056906424

Epoch: 5| Step: 5
Training loss: 3.2116591930389404
Validation loss: 3.0746954025760775

Epoch: 5| Step: 6
Training loss: 2.7928965091705322
Validation loss: 3.0589681927875807

Epoch: 5| Step: 7
Training loss: 2.5422141551971436
Validation loss: 3.050115103362709

Epoch: 5| Step: 8
Training loss: 3.2879128456115723
Validation loss: 3.045936994655158

Epoch: 5| Step: 9
Training loss: 3.0678248405456543
Validation loss: 3.031585826668688

Epoch: 5| Step: 10
Training loss: 3.1040244102478027
Validation loss: 3.0248943298093733

Epoch: 8| Step: 0
Training loss: 2.5541324615478516
Validation loss: 3.019701252701462

Epoch: 5| Step: 1
Training loss: 3.1139156818389893
Validation loss: 3.0114595095316568

Epoch: 5| Step: 2
Training loss: 2.622340679168701
Validation loss: 3.004562839385002

Epoch: 5| Step: 3
Training loss: 3.795793056488037
Validation loss: 3.00532183852247

Epoch: 5| Step: 4
Training loss: 3.554689407348633
Validation loss: 2.9944425552122054

Epoch: 5| Step: 5
Training loss: 3.170422315597534
Validation loss: 2.9860100130881033

Epoch: 5| Step: 6
Training loss: 2.983212947845459
Validation loss: 2.9856756425672963

Epoch: 5| Step: 7
Training loss: 2.9573049545288086
Validation loss: 2.974541615414363

Epoch: 5| Step: 8
Training loss: 2.518482208251953
Validation loss: 2.963736177772604

Epoch: 5| Step: 9
Training loss: 3.0677037239074707
Validation loss: 2.959051416766259

Epoch: 5| Step: 10
Training loss: 3.300114870071411
Validation loss: 2.951451732266334

Epoch: 9| Step: 0
Training loss: 2.8417649269104004
Validation loss: 2.962477917312294

Epoch: 5| Step: 1
Training loss: 2.035604953765869
Validation loss: 2.9352885087331138

Epoch: 5| Step: 2
Training loss: 4.020219326019287
Validation loss: 2.945319280829481

Epoch: 5| Step: 3
Training loss: 3.8231360912323
Validation loss: 2.9229905861680225

Epoch: 5| Step: 4
Training loss: 3.6663761138916016
Validation loss: 2.923145135243734

Epoch: 5| Step: 5
Training loss: 2.4109787940979004
Validation loss: 2.9262740432575183

Epoch: 5| Step: 6
Training loss: 2.3192081451416016
Validation loss: 2.9472163313178608

Epoch: 5| Step: 7
Training loss: 3.314690113067627
Validation loss: 2.9140216740228797

Epoch: 5| Step: 8
Training loss: 3.2957801818847656
Validation loss: 2.916284274029475

Epoch: 5| Step: 9
Training loss: 2.1839821338653564
Validation loss: 2.897541833180253

Epoch: 5| Step: 10
Training loss: 3.3337674140930176
Validation loss: 2.889322027083366

Epoch: 10| Step: 0
Training loss: 2.73360013961792
Validation loss: 2.893848137188983

Epoch: 5| Step: 1
Training loss: 3.2029519081115723
Validation loss: 2.889957981724893

Epoch: 5| Step: 2
Training loss: 2.4756436347961426
Validation loss: 2.872079603133663

Epoch: 5| Step: 3
Training loss: 2.9296610355377197
Validation loss: 2.8590536989191526

Epoch: 5| Step: 4
Training loss: 3.307119369506836
Validation loss: 2.8568488038996214

Epoch: 5| Step: 5
Training loss: 3.2840569019317627
Validation loss: 2.8556288134667183

Epoch: 5| Step: 6
Training loss: 2.8735427856445312
Validation loss: 2.850978138626263

Epoch: 5| Step: 7
Training loss: 2.5696558952331543
Validation loss: 2.845045802413776

Epoch: 5| Step: 8
Training loss: 2.739434003829956
Validation loss: 2.8457137512904342

Epoch: 5| Step: 9
Training loss: 3.4100875854492188
Validation loss: 2.847722330401021

Epoch: 5| Step: 10
Training loss: 3.2105367183685303
Validation loss: 2.8345399825803694

Epoch: 11| Step: 0
Training loss: 2.699143886566162
Validation loss: 2.8259234505314983

Epoch: 5| Step: 1
Training loss: 2.605703592300415
Validation loss: 2.8227245858920518

Epoch: 5| Step: 2
Training loss: 2.3227155208587646
Validation loss: 2.818486257265973

Epoch: 5| Step: 3
Training loss: 3.9478759765625
Validation loss: 2.81619349346366

Epoch: 5| Step: 4
Training loss: 3.404174327850342
Validation loss: 2.8098308937523955

Epoch: 5| Step: 5
Training loss: 3.4684925079345703
Validation loss: 2.803879596853769

Epoch: 5| Step: 6
Training loss: 2.8705010414123535
Validation loss: 2.803607007508637

Epoch: 5| Step: 7
Training loss: 3.29590106010437
Validation loss: 2.8048932731792493

Epoch: 5| Step: 8
Training loss: 2.5731961727142334
Validation loss: 2.797531012565859

Epoch: 5| Step: 9
Training loss: 2.810447931289673
Validation loss: 2.792610206911641

Epoch: 5| Step: 10
Training loss: 2.234041929244995
Validation loss: 2.78757409639256

Epoch: 12| Step: 0
Training loss: 2.7377424240112305
Validation loss: 2.7905836412983556

Epoch: 5| Step: 1
Training loss: 2.890716791152954
Validation loss: 2.803235770553671

Epoch: 5| Step: 2
Training loss: 2.7269198894500732
Validation loss: 2.783352008429907

Epoch: 5| Step: 3
Training loss: 2.5830087661743164
Validation loss: 2.773012299691477

Epoch: 5| Step: 4
Training loss: 3.145359754562378
Validation loss: 2.768516586672875

Epoch: 5| Step: 5
Training loss: 3.613337278366089
Validation loss: 2.7687185118275304

Epoch: 5| Step: 6
Training loss: 2.332846164703369
Validation loss: 2.763446743770312

Epoch: 5| Step: 7
Training loss: 2.8947691917419434
Validation loss: 2.764764867803102

Epoch: 5| Step: 8
Training loss: 2.666285276412964
Validation loss: 2.7752507373850834

Epoch: 5| Step: 9
Training loss: 3.3068974018096924
Validation loss: 2.765001553361134

Epoch: 5| Step: 10
Training loss: 3.2608139514923096
Validation loss: 2.750739492395873

Epoch: 13| Step: 0
Training loss: 3.2971034049987793
Validation loss: 2.7517969454488447

Epoch: 5| Step: 1
Training loss: 3.7086615562438965
Validation loss: 2.755690000390494

Epoch: 5| Step: 2
Training loss: 2.6538822650909424
Validation loss: 2.7598401243968675

Epoch: 5| Step: 3
Training loss: 2.370537042617798
Validation loss: 2.765125766877205

Epoch: 5| Step: 4
Training loss: 2.7782468795776367
Validation loss: 2.76204171488362

Epoch: 5| Step: 5
Training loss: 3.1314966678619385
Validation loss: 2.766021615715437

Epoch: 5| Step: 6
Training loss: 3.471174955368042
Validation loss: 2.7554278578809512

Epoch: 5| Step: 7
Training loss: 2.6140031814575195
Validation loss: 2.7409652740724626

Epoch: 5| Step: 8
Training loss: 2.2420811653137207
Validation loss: 2.7319707332118863

Epoch: 5| Step: 9
Training loss: 2.8046021461486816
Validation loss: 2.7266116091000137

Epoch: 5| Step: 10
Training loss: 2.7761189937591553
Validation loss: 2.7183045033485658

Epoch: 14| Step: 0
Training loss: 3.1242096424102783
Validation loss: 2.716684631122056

Epoch: 5| Step: 1
Training loss: 3.174528121948242
Validation loss: 2.7138476730674825

Epoch: 5| Step: 2
Training loss: 2.906750202178955
Validation loss: 2.71350355814862

Epoch: 5| Step: 3
Training loss: 3.299297332763672
Validation loss: 2.7123829010994203

Epoch: 5| Step: 4
Training loss: 2.2420012950897217
Validation loss: 2.7072793975953133

Epoch: 5| Step: 5
Training loss: 2.936338424682617
Validation loss: 2.70226873377318

Epoch: 5| Step: 6
Training loss: 2.7813076972961426
Validation loss: 2.705168475386917

Epoch: 5| Step: 7
Training loss: 2.662349224090576
Validation loss: 2.7013837547712427

Epoch: 5| Step: 8
Training loss: 3.508209228515625
Validation loss: 2.698061035525414

Epoch: 5| Step: 9
Training loss: 1.9220244884490967
Validation loss: 2.696636305060438

Epoch: 5| Step: 10
Training loss: 3.1108155250549316
Validation loss: 2.6980153104310394

Epoch: 15| Step: 0
Training loss: 2.781646490097046
Validation loss: 2.7169531929877495

Epoch: 5| Step: 1
Training loss: 3.0484843254089355
Validation loss: 2.716374440859723

Epoch: 5| Step: 2
Training loss: 3.317413330078125
Validation loss: 2.6919675155352523

Epoch: 5| Step: 3
Training loss: 2.843989610671997
Validation loss: 2.7075113275999665

Epoch: 5| Step: 4
Training loss: 2.1422982215881348
Validation loss: 2.702684981848604

Epoch: 5| Step: 5
Training loss: 2.5111846923828125
Validation loss: 2.6977717261160574

Epoch: 5| Step: 6
Training loss: 2.5603535175323486
Validation loss: 2.694937224029213

Epoch: 5| Step: 7
Training loss: 2.594111204147339
Validation loss: 2.689593494579356

Epoch: 5| Step: 8
Training loss: 3.333181381225586
Validation loss: 2.6816300551096597

Epoch: 5| Step: 9
Training loss: 3.103647470474243
Validation loss: 2.67443674097779

Epoch: 5| Step: 10
Training loss: 3.32641339302063
Validation loss: 2.676725359373195

Epoch: 16| Step: 0
Training loss: 3.033334255218506
Validation loss: 2.6736804695539576

Epoch: 5| Step: 1
Training loss: 2.802433490753174
Validation loss: 2.6757037126889793

Epoch: 5| Step: 2
Training loss: 2.6587536334991455
Validation loss: 2.6852708478127756

Epoch: 5| Step: 3
Training loss: 2.9301095008850098
Validation loss: 2.679486769501881

Epoch: 5| Step: 4
Training loss: 2.42948579788208
Validation loss: 2.669238544279529

Epoch: 5| Step: 5
Training loss: 3.4757492542266846
Validation loss: 2.666981707337082

Epoch: 5| Step: 6
Training loss: 3.2792811393737793
Validation loss: 2.662095715922694

Epoch: 5| Step: 7
Training loss: 2.3035640716552734
Validation loss: 2.661763593714724

Epoch: 5| Step: 8
Training loss: 3.2735209465026855
Validation loss: 2.657420450641263

Epoch: 5| Step: 9
Training loss: 2.196016788482666
Validation loss: 2.6523788898221907

Epoch: 5| Step: 10
Training loss: 2.9850051403045654
Validation loss: 2.64976772698023

Epoch: 17| Step: 0
Training loss: 2.4222559928894043
Validation loss: 2.6468856821778

Epoch: 5| Step: 1
Training loss: 3.369920015335083
Validation loss: 2.636782835888606

Epoch: 5| Step: 2
Training loss: 2.470292091369629
Validation loss: 2.641110722736646

Epoch: 5| Step: 3
Training loss: 3.0248332023620605
Validation loss: 2.6408177114302114

Epoch: 5| Step: 4
Training loss: 2.6375088691711426
Validation loss: 2.655151269769156

Epoch: 5| Step: 5
Training loss: 3.2066798210144043
Validation loss: 2.6742231333127586

Epoch: 5| Step: 6
Training loss: 2.5474421977996826
Validation loss: 2.6821888339134956

Epoch: 5| Step: 7
Training loss: 2.9833462238311768
Validation loss: 2.688448106088946

Epoch: 5| Step: 8
Training loss: 2.965549945831299
Validation loss: 2.643132348214426

Epoch: 5| Step: 9
Training loss: 2.704284191131592
Validation loss: 2.622721331093901

Epoch: 5| Step: 10
Training loss: 2.824951648712158
Validation loss: 2.614922328661847

Epoch: 18| Step: 0
Training loss: 2.998868227005005
Validation loss: 2.634456067956904

Epoch: 5| Step: 1
Training loss: 3.6269097328186035
Validation loss: 2.6436705845658497

Epoch: 5| Step: 2
Training loss: 2.6124942302703857
Validation loss: 2.630715185596097

Epoch: 5| Step: 3
Training loss: 2.7815279960632324
Validation loss: 2.6340567604187997

Epoch: 5| Step: 4
Training loss: 2.760345220565796
Validation loss: 2.62094614582677

Epoch: 5| Step: 5
Training loss: 2.367069721221924
Validation loss: 2.609898920982115

Epoch: 5| Step: 6
Training loss: 2.7958998680114746
Validation loss: 2.613262202150078

Epoch: 5| Step: 7
Training loss: 2.513869047164917
Validation loss: 2.6101454201564995

Epoch: 5| Step: 8
Training loss: 2.6334011554718018
Validation loss: 2.6064890277001167

Epoch: 5| Step: 9
Training loss: 2.935161590576172
Validation loss: 2.601751471078524

Epoch: 5| Step: 10
Training loss: 2.9911508560180664
Validation loss: 2.603344696824269

Epoch: 19| Step: 0
Training loss: 2.7819278240203857
Validation loss: 2.6028202656776673

Epoch: 5| Step: 1
Training loss: 2.926008462905884
Validation loss: 2.6056171719745924

Epoch: 5| Step: 2
Training loss: 3.164193868637085
Validation loss: 2.6005048803103867

Epoch: 5| Step: 3
Training loss: 2.1763062477111816
Validation loss: 2.5959232622577297

Epoch: 5| Step: 4
Training loss: 2.697296619415283
Validation loss: 2.5950129544863136

Epoch: 5| Step: 5
Training loss: 3.0017247200012207
Validation loss: 2.5972932820679038

Epoch: 5| Step: 6
Training loss: 2.232027769088745
Validation loss: 2.596390039690079

Epoch: 5| Step: 7
Training loss: 2.8572518825531006
Validation loss: 2.5971738369234147

Epoch: 5| Step: 8
Training loss: 2.675454616546631
Validation loss: 2.598916733136741

Epoch: 5| Step: 9
Training loss: 3.4262917041778564
Validation loss: 2.596756407009658

Epoch: 5| Step: 10
Training loss: 2.9198381900787354
Validation loss: 2.5966841866893153

Epoch: 20| Step: 0
Training loss: 3.2231171131134033
Validation loss: 2.606681687857515

Epoch: 5| Step: 1
Training loss: 2.2189135551452637
Validation loss: 2.5937026418665403

Epoch: 5| Step: 2
Training loss: 2.1075634956359863
Validation loss: 2.584246561091433

Epoch: 5| Step: 3
Training loss: 2.2778232097625732
Validation loss: 2.5792627488413165

Epoch: 5| Step: 4
Training loss: 2.9430527687072754
Validation loss: 2.5740857765238774

Epoch: 5| Step: 5
Training loss: 2.8238613605499268
Validation loss: 2.566864231581329

Epoch: 5| Step: 6
Training loss: 3.23717999458313
Validation loss: 2.5698651985455583

Epoch: 5| Step: 7
Training loss: 3.0484867095947266
Validation loss: 2.580124988350817

Epoch: 5| Step: 8
Training loss: 2.7061047554016113
Validation loss: 2.6631456446904007

Epoch: 5| Step: 9
Training loss: 2.891047239303589
Validation loss: 2.7856544499756186

Epoch: 5| Step: 10
Training loss: 3.424851417541504
Validation loss: 2.806706646437286

Epoch: 21| Step: 0
Training loss: 2.8894665241241455
Validation loss: 2.788201501292567

Epoch: 5| Step: 1
Training loss: 2.331958293914795
Validation loss: 2.7715054865806334

Epoch: 5| Step: 2
Training loss: 3.1518845558166504
Validation loss: 2.7713659168571554

Epoch: 5| Step: 3
Training loss: 3.0747907161712646
Validation loss: 2.727584787594375

Epoch: 5| Step: 4
Training loss: 2.680673599243164
Validation loss: 2.645693281645416

Epoch: 5| Step: 5
Training loss: 2.556264877319336
Validation loss: 2.6520040112157024

Epoch: 5| Step: 6
Training loss: 3.416236400604248
Validation loss: 2.696220438967469

Epoch: 5| Step: 7
Training loss: 3.048994541168213
Validation loss: 2.7313848182719243

Epoch: 5| Step: 8
Training loss: 2.971789836883545
Validation loss: 2.738081419339744

Epoch: 5| Step: 9
Training loss: 2.722808361053467
Validation loss: 2.654026121221563

Epoch: 5| Step: 10
Training loss: 2.8000757694244385
Validation loss: 2.5915442359062935

Epoch: 22| Step: 0
Training loss: 2.874138355255127
Validation loss: 2.5662216935106503

Epoch: 5| Step: 1
Training loss: 2.679521322250366
Validation loss: 2.563157932732695

Epoch: 5| Step: 2
Training loss: 2.444688320159912
Validation loss: 2.572889950967604

Epoch: 5| Step: 3
Training loss: 2.5994153022766113
Validation loss: 2.6007307460231166

Epoch: 5| Step: 4
Training loss: 3.089900016784668
Validation loss: 2.6326315992621967

Epoch: 5| Step: 5
Training loss: 2.335874319076538
Validation loss: 2.666958471780182

Epoch: 5| Step: 6
Training loss: 2.344773769378662
Validation loss: 2.727931966063797

Epoch: 5| Step: 7
Training loss: 3.4772744178771973
Validation loss: 2.7447706883953464

Epoch: 5| Step: 8
Training loss: 3.315218448638916
Validation loss: 2.731346220098516

Epoch: 5| Step: 9
Training loss: 2.663656711578369
Validation loss: 2.6884089618600826

Epoch: 5| Step: 10
Training loss: 3.524946689605713
Validation loss: 2.6809895961515364

Epoch: 23| Step: 0
Training loss: 2.145918369293213
Validation loss: 2.681178472375357

Epoch: 5| Step: 1
Training loss: 3.01609468460083
Validation loss: 2.6702672717391804

Epoch: 5| Step: 2
Training loss: 2.684476852416992
Validation loss: 2.6728972978489374

Epoch: 5| Step: 3
Training loss: 3.240568161010742
Validation loss: 2.6665401304921796

Epoch: 5| Step: 4
Training loss: 3.3123619556427
Validation loss: 2.6552549844147055

Epoch: 5| Step: 5
Training loss: 2.6819045543670654
Validation loss: 2.6411742138606247

Epoch: 5| Step: 6
Training loss: 2.9121012687683105
Validation loss: 2.6334024244739163

Epoch: 5| Step: 7
Training loss: 2.967133045196533
Validation loss: 2.6313974626602663

Epoch: 5| Step: 8
Training loss: 2.9071338176727295
Validation loss: 2.634839678323397

Epoch: 5| Step: 9
Training loss: 2.4192867279052734
Validation loss: 2.6403061830869285

Epoch: 5| Step: 10
Training loss: 2.9580647945404053
Validation loss: 2.6344331720823884

Epoch: 24| Step: 0
Training loss: 3.4103446006774902
Validation loss: 2.625263293584188

Epoch: 5| Step: 1
Training loss: 2.398284673690796
Validation loss: 2.619777533315843

Epoch: 5| Step: 2
Training loss: 3.017080783843994
Validation loss: 2.616340942280267

Epoch: 5| Step: 3
Training loss: 2.559774875640869
Validation loss: 2.617075938050465

Epoch: 5| Step: 4
Training loss: 2.673466920852661
Validation loss: 2.6102180327138593

Epoch: 5| Step: 5
Training loss: 2.9341018199920654
Validation loss: 2.6068301662322013

Epoch: 5| Step: 6
Training loss: 2.3589324951171875
Validation loss: 2.601369816769836

Epoch: 5| Step: 7
Training loss: 3.540376663208008
Validation loss: 2.5997491036691973

Epoch: 5| Step: 8
Training loss: 3.2733073234558105
Validation loss: 2.5993415950447

Epoch: 5| Step: 9
Training loss: 2.643584728240967
Validation loss: 2.5948293439803587

Epoch: 5| Step: 10
Training loss: 1.9371957778930664
Validation loss: 2.592303999008671

Epoch: 25| Step: 0
Training loss: 2.6298720836639404
Validation loss: 2.5932043983090307

Epoch: 5| Step: 1
Training loss: 3.0546884536743164
Validation loss: 2.5995716792280956

Epoch: 5| Step: 2
Training loss: 2.8258016109466553
Validation loss: 2.5934385843174432

Epoch: 5| Step: 3
Training loss: 2.1629297733306885
Validation loss: 2.6039109870951664

Epoch: 5| Step: 4
Training loss: 3.601449489593506
Validation loss: 2.602922531866258

Epoch: 5| Step: 5
Training loss: 3.0427584648132324
Validation loss: 2.58736619898068

Epoch: 5| Step: 6
Training loss: 2.45166015625
Validation loss: 2.577595054462392

Epoch: 5| Step: 7
Training loss: 3.005322217941284
Validation loss: 2.581917457683112

Epoch: 5| Step: 8
Training loss: 2.8594560623168945
Validation loss: 2.5833992778614

Epoch: 5| Step: 9
Training loss: 2.1113815307617188
Validation loss: 2.5833073585264144

Epoch: 5| Step: 10
Training loss: 2.9767730236053467
Validation loss: 2.585613460950954

Epoch: 26| Step: 0
Training loss: 2.6362993717193604
Validation loss: 2.583226168027488

Epoch: 5| Step: 1
Training loss: 2.672351837158203
Validation loss: 2.58225154876709

Epoch: 5| Step: 2
Training loss: 3.0394229888916016
Validation loss: 2.5777430380544355

Epoch: 5| Step: 3
Training loss: 2.8607394695281982
Validation loss: 2.580236009372178

Epoch: 5| Step: 4
Training loss: 2.9316625595092773
Validation loss: 2.575121751395605

Epoch: 5| Step: 5
Training loss: 2.6183085441589355
Validation loss: 2.5784790849172943

Epoch: 5| Step: 6
Training loss: 2.33663272857666
Validation loss: 2.574626999516641

Epoch: 5| Step: 7
Training loss: 2.7778220176696777
Validation loss: 2.5755110581715903

Epoch: 5| Step: 8
Training loss: 3.0313446521759033
Validation loss: 2.561429797962148

Epoch: 5| Step: 9
Training loss: 2.291572332382202
Validation loss: 2.5632417919815227

Epoch: 5| Step: 10
Training loss: 3.5065529346466064
Validation loss: 2.5636026167100474

Epoch: 27| Step: 0
Training loss: 2.6466174125671387
Validation loss: 2.5636725656447874

Epoch: 5| Step: 1
Training loss: 2.3834176063537598
Validation loss: 2.5616861081892446

Epoch: 5| Step: 2
Training loss: 2.440204620361328
Validation loss: 2.558706970625026

Epoch: 5| Step: 3
Training loss: 2.563474178314209
Validation loss: 2.5598599116007485

Epoch: 5| Step: 4
Training loss: 3.0120134353637695
Validation loss: 2.5648416344837477

Epoch: 5| Step: 5
Training loss: 3.4272398948669434
Validation loss: 2.5750406698514055

Epoch: 5| Step: 6
Training loss: 3.037902593612671
Validation loss: 2.571002003967121

Epoch: 5| Step: 7
Training loss: 2.57820463180542
Validation loss: 2.554731774073775

Epoch: 5| Step: 8
Training loss: 2.469414234161377
Validation loss: 2.547072651565716

Epoch: 5| Step: 9
Training loss: 2.855294704437256
Validation loss: 2.542308650990968

Epoch: 5| Step: 10
Training loss: 3.0032577514648438
Validation loss: 2.53510864832068

Epoch: 28| Step: 0
Training loss: 2.6621246337890625
Validation loss: 2.5223689233103106

Epoch: 5| Step: 1
Training loss: 3.1169936656951904
Validation loss: 2.501343645075316

Epoch: 5| Step: 2
Training loss: 3.2262630462646484
Validation loss: 2.506349760998962

Epoch: 5| Step: 3
Training loss: 2.6008193492889404
Validation loss: 2.5136363890863236

Epoch: 5| Step: 4
Training loss: 2.836975336074829
Validation loss: 2.5174685626901607

Epoch: 5| Step: 5
Training loss: 2.731656551361084
Validation loss: 2.513696183440506

Epoch: 5| Step: 6
Training loss: 2.232623338699341
Validation loss: 2.5007307657631497

Epoch: 5| Step: 7
Training loss: 1.9572168588638306
Validation loss: 2.492056703054777

Epoch: 5| Step: 8
Training loss: 2.404202938079834
Validation loss: 2.4882860670807543

Epoch: 5| Step: 9
Training loss: 3.6636569499969482
Validation loss: 2.503461017403551

Epoch: 5| Step: 10
Training loss: 2.669041633605957
Validation loss: 2.5068161205578874

Epoch: 29| Step: 0
Training loss: 2.0661842823028564
Validation loss: 2.4923471737933416

Epoch: 5| Step: 1
Training loss: 2.1604082584381104
Validation loss: 2.4921524857962005

Epoch: 5| Step: 2
Training loss: 2.0422523021698
Validation loss: 2.491667342442338

Epoch: 5| Step: 3
Training loss: 2.7793424129486084
Validation loss: 2.499731761153026

Epoch: 5| Step: 4
Training loss: 3.405534029006958
Validation loss: 2.5108332377608105

Epoch: 5| Step: 5
Training loss: 2.7329485416412354
Validation loss: 2.496662893602925

Epoch: 5| Step: 6
Training loss: 2.8089096546173096
Validation loss: 2.486878131025581

Epoch: 5| Step: 7
Training loss: 2.930636405944824
Validation loss: 2.485317219970047

Epoch: 5| Step: 8
Training loss: 2.7746284008026123
Validation loss: 2.4775651847162554

Epoch: 5| Step: 9
Training loss: 3.489588499069214
Validation loss: 2.477308670679728

Epoch: 5| Step: 10
Training loss: 2.754479169845581
Validation loss: 2.477964739645681

Epoch: 30| Step: 0
Training loss: 2.8098323345184326
Validation loss: 2.475691374912057

Epoch: 5| Step: 1
Training loss: 2.7295608520507812
Validation loss: 2.4782433317553614

Epoch: 5| Step: 2
Training loss: 2.6572868824005127
Validation loss: 2.481218763577041

Epoch: 5| Step: 3
Training loss: 3.7962799072265625
Validation loss: 2.488448750588202

Epoch: 5| Step: 4
Training loss: 2.7542943954467773
Validation loss: 2.488241077751242

Epoch: 5| Step: 5
Training loss: 3.1344032287597656
Validation loss: 2.494291561906056

Epoch: 5| Step: 6
Training loss: 2.838437080383301
Validation loss: 2.5209933198908323

Epoch: 5| Step: 7
Training loss: 2.522523880004883
Validation loss: 2.497817231762794

Epoch: 5| Step: 8
Training loss: 1.9796253442764282
Validation loss: 2.498285637106947

Epoch: 5| Step: 9
Training loss: 2.3053383827209473
Validation loss: 2.478038203331732

Epoch: 5| Step: 10
Training loss: 2.1115055084228516
Validation loss: 2.469008517521684

Epoch: 31| Step: 0
Training loss: 1.978482961654663
Validation loss: 2.4694899512875463

Epoch: 5| Step: 1
Training loss: 3.0179502964019775
Validation loss: 2.4705633706943964

Epoch: 5| Step: 2
Training loss: 3.323310136795044
Validation loss: 2.4805583030946794

Epoch: 5| Step: 3
Training loss: 3.0795300006866455
Validation loss: 2.477808108893774

Epoch: 5| Step: 4
Training loss: 2.1666362285614014
Validation loss: 2.4765919305944957

Epoch: 5| Step: 5
Training loss: 2.983717679977417
Validation loss: 2.4785525978252454

Epoch: 5| Step: 6
Training loss: 2.261749029159546
Validation loss: 2.475718982758061

Epoch: 5| Step: 7
Training loss: 2.9837965965270996
Validation loss: 2.482711867619586

Epoch: 5| Step: 8
Training loss: 2.6527950763702393
Validation loss: 2.4854312865964827

Epoch: 5| Step: 9
Training loss: 2.5051755905151367
Validation loss: 2.4866840813749578

Epoch: 5| Step: 10
Training loss: 2.7391600608825684
Validation loss: 2.4830446525286605

Epoch: 32| Step: 0
Training loss: 2.6742911338806152
Validation loss: 2.4817316839771886

Epoch: 5| Step: 1
Training loss: 2.684544801712036
Validation loss: 2.4830024562856203

Epoch: 5| Step: 2
Training loss: 2.688324213027954
Validation loss: 2.4881444566993305

Epoch: 5| Step: 3
Training loss: 2.3215019702911377
Validation loss: 2.475952039482773

Epoch: 5| Step: 4
Training loss: 3.1066536903381348
Validation loss: 2.4626377500513548

Epoch: 5| Step: 5
Training loss: 2.9752726554870605
Validation loss: 2.4620917843234156

Epoch: 5| Step: 6
Training loss: 2.326303005218506
Validation loss: 2.466007335211641

Epoch: 5| Step: 7
Training loss: 2.70573091506958
Validation loss: 2.463026346698884

Epoch: 5| Step: 8
Training loss: 2.581608533859253
Validation loss: 2.4647401250818723

Epoch: 5| Step: 9
Training loss: 3.2747840881347656
Validation loss: 2.4634737763353574

Epoch: 5| Step: 10
Training loss: 2.2955589294433594
Validation loss: 2.4654047155892975

Epoch: 33| Step: 0
Training loss: 3.275446653366089
Validation loss: 2.4599713510082615

Epoch: 5| Step: 1
Training loss: 2.39422607421875
Validation loss: 2.473487272057482

Epoch: 5| Step: 2
Training loss: 2.4991443157196045
Validation loss: 2.4850498091789985

Epoch: 5| Step: 3
Training loss: 2.970846176147461
Validation loss: 2.4845280852369083

Epoch: 5| Step: 4
Training loss: 3.266040325164795
Validation loss: 2.46457342691319

Epoch: 5| Step: 5
Training loss: 2.8202476501464844
Validation loss: 2.461845346676406

Epoch: 5| Step: 6
Training loss: 2.965653419494629
Validation loss: 2.463040674886396

Epoch: 5| Step: 7
Training loss: 1.979478120803833
Validation loss: 2.460792936304564

Epoch: 5| Step: 8
Training loss: 2.2607452869415283
Validation loss: 2.453929365322154

Epoch: 5| Step: 9
Training loss: 2.6701791286468506
Validation loss: 2.4546055383579706

Epoch: 5| Step: 10
Training loss: 2.380300998687744
Validation loss: 2.452619166784389

Epoch: 34| Step: 0
Training loss: 2.5779192447662354
Validation loss: 2.4582018416414977

Epoch: 5| Step: 1
Training loss: 2.5951602458953857
Validation loss: 2.461134023563836

Epoch: 5| Step: 2
Training loss: 3.2470574378967285
Validation loss: 2.461708835376206

Epoch: 5| Step: 3
Training loss: 2.001024007797241
Validation loss: 2.465161423529348

Epoch: 5| Step: 4
Training loss: 2.536159038543701
Validation loss: 2.4704627503630934

Epoch: 5| Step: 5
Training loss: 2.6571195125579834
Validation loss: 2.4845245192127843

Epoch: 5| Step: 6
Training loss: 2.421851634979248
Validation loss: 2.490845993000974

Epoch: 5| Step: 7
Training loss: 3.434108018875122
Validation loss: 2.5062520760361866

Epoch: 5| Step: 8
Training loss: 3.1738390922546387
Validation loss: 2.513564009820261

Epoch: 5| Step: 9
Training loss: 2.3665738105773926
Validation loss: 2.496322339580905

Epoch: 5| Step: 10
Training loss: 2.539632558822632
Validation loss: 2.476137879074261

Epoch: 35| Step: 0
Training loss: 3.0350935459136963
Validation loss: 2.4621564213947584

Epoch: 5| Step: 1
Training loss: 2.474545955657959
Validation loss: 2.4591122724676646

Epoch: 5| Step: 2
Training loss: 2.1556384563446045
Validation loss: 2.459807312616738

Epoch: 5| Step: 3
Training loss: 2.9493460655212402
Validation loss: 2.4519264723664973

Epoch: 5| Step: 4
Training loss: 3.212831974029541
Validation loss: 2.442493538702688

Epoch: 5| Step: 5
Training loss: 2.9343602657318115
Validation loss: 2.4428722012427544

Epoch: 5| Step: 6
Training loss: 2.2813096046447754
Validation loss: 2.4427291988044657

Epoch: 5| Step: 7
Training loss: 2.566751480102539
Validation loss: 2.4448785115313787

Epoch: 5| Step: 8
Training loss: 1.925424337387085
Validation loss: 2.450368636397905

Epoch: 5| Step: 9
Training loss: 3.1196296215057373
Validation loss: 2.4646775337957565

Epoch: 5| Step: 10
Training loss: 2.9708542823791504
Validation loss: 2.4738909044573383

Epoch: 36| Step: 0
Training loss: 2.1436028480529785
Validation loss: 2.475852571507936

Epoch: 5| Step: 1
Training loss: 1.968409776687622
Validation loss: 2.4821577841235745

Epoch: 5| Step: 2
Training loss: 2.3728365898132324
Validation loss: 2.481177512035575

Epoch: 5| Step: 3
Training loss: 2.7377054691314697
Validation loss: 2.462826692929832

Epoch: 5| Step: 4
Training loss: 2.654052257537842
Validation loss: 2.4437154749388337

Epoch: 5| Step: 5
Training loss: 2.5773348808288574
Validation loss: 2.4334156846487396

Epoch: 5| Step: 6
Training loss: 3.0628883838653564
Validation loss: 2.434423933746994

Epoch: 5| Step: 7
Training loss: 3.6501922607421875
Validation loss: 2.432038027753112

Epoch: 5| Step: 8
Training loss: 2.724139451980591
Validation loss: 2.428040724928661

Epoch: 5| Step: 9
Training loss: 3.005544900894165
Validation loss: 2.4281914477707236

Epoch: 5| Step: 10
Training loss: 2.383479595184326
Validation loss: 2.4310460398274083

Epoch: 37| Step: 0
Training loss: 2.4849002361297607
Validation loss: 2.4338787858204176

Epoch: 5| Step: 1
Training loss: 2.5541999340057373
Validation loss: 2.432883175470496

Epoch: 5| Step: 2
Training loss: 2.9126410484313965
Validation loss: 2.4380314632128646

Epoch: 5| Step: 3
Training loss: 2.539139986038208
Validation loss: 2.446118039469565

Epoch: 5| Step: 4
Training loss: 1.8142566680908203
Validation loss: 2.4640831460234938

Epoch: 5| Step: 5
Training loss: 2.695474147796631
Validation loss: 2.489822388977133

Epoch: 5| Step: 6
Training loss: 3.2609572410583496
Validation loss: 2.4825605218128493

Epoch: 5| Step: 7
Training loss: 2.8188562393188477
Validation loss: 2.46390934400661

Epoch: 5| Step: 8
Training loss: 2.7496964931488037
Validation loss: 2.453708915300267

Epoch: 5| Step: 9
Training loss: 2.6301465034484863
Validation loss: 2.4433671069401566

Epoch: 5| Step: 10
Training loss: 2.8512120246887207
Validation loss: 2.4342973668088197

Epoch: 38| Step: 0
Training loss: 1.9807850122451782
Validation loss: 2.4255606205232683

Epoch: 5| Step: 1
Training loss: 3.2326488494873047
Validation loss: 2.4244182725106516

Epoch: 5| Step: 2
Training loss: 1.9490137100219727
Validation loss: 2.4216564624540267

Epoch: 5| Step: 3
Training loss: 3.1701455116271973
Validation loss: 2.419811056506249

Epoch: 5| Step: 4
Training loss: 3.0947842597961426
Validation loss: 2.41887645054889

Epoch: 5| Step: 5
Training loss: 2.4450690746307373
Validation loss: 2.420933623467722

Epoch: 5| Step: 6
Training loss: 2.5131735801696777
Validation loss: 2.4169541558911725

Epoch: 5| Step: 7
Training loss: 2.835297107696533
Validation loss: 2.4224726359049478

Epoch: 5| Step: 8
Training loss: 2.940216064453125
Validation loss: 2.425624539775233

Epoch: 5| Step: 9
Training loss: 2.379056215286255
Validation loss: 2.4293614715658207

Epoch: 5| Step: 10
Training loss: 2.6484272480010986
Validation loss: 2.434004129902009

Epoch: 39| Step: 0
Training loss: 2.3372204303741455
Validation loss: 2.4526816926976687

Epoch: 5| Step: 1
Training loss: 2.7604966163635254
Validation loss: 2.454565966001121

Epoch: 5| Step: 2
Training loss: 3.1273388862609863
Validation loss: 2.461834176894157

Epoch: 5| Step: 3
Training loss: 2.827155113220215
Validation loss: 2.453569863432197

Epoch: 5| Step: 4
Training loss: 2.3241682052612305
Validation loss: 2.457450061716059

Epoch: 5| Step: 5
Training loss: 2.4767680168151855
Validation loss: 2.44937406047698

Epoch: 5| Step: 6
Training loss: 2.238201141357422
Validation loss: 2.450175271239332

Epoch: 5| Step: 7
Training loss: 2.462505578994751
Validation loss: 2.4454467194054716

Epoch: 5| Step: 8
Training loss: 3.331521987915039
Validation loss: 2.442859626585437

Epoch: 5| Step: 9
Training loss: 2.8010451793670654
Validation loss: 2.4324803788174867

Epoch: 5| Step: 10
Training loss: 2.396629810333252
Validation loss: 2.422800253796321

Epoch: 40| Step: 0
Training loss: 2.9559288024902344
Validation loss: 2.4170660562412714

Epoch: 5| Step: 1
Training loss: 2.7964940071105957
Validation loss: 2.41808299351764

Epoch: 5| Step: 2
Training loss: 3.057164430618286
Validation loss: 2.4191430435385755

Epoch: 5| Step: 3
Training loss: 2.059001922607422
Validation loss: 2.4139188105060208

Epoch: 5| Step: 4
Training loss: 2.8787944316864014
Validation loss: 2.427845690840034

Epoch: 5| Step: 5
Training loss: 2.548412561416626
Validation loss: 2.424968640009562

Epoch: 5| Step: 6
Training loss: 3.187134027481079
Validation loss: 2.4152578999919276

Epoch: 5| Step: 7
Training loss: 2.67537260055542
Validation loss: 2.4082607223141577

Epoch: 5| Step: 8
Training loss: 2.0466041564941406
Validation loss: 2.400396139391007

Epoch: 5| Step: 9
Training loss: 2.2606348991394043
Validation loss: 2.409492346548265

Epoch: 5| Step: 10
Training loss: 2.7376210689544678
Validation loss: 2.4239728758412022

Epoch: 41| Step: 0
Training loss: 2.5554144382476807
Validation loss: 2.4598013124158307

Epoch: 5| Step: 1
Training loss: 2.3549768924713135
Validation loss: 2.479192292818459

Epoch: 5| Step: 2
Training loss: 1.690975546836853
Validation loss: 2.4769384937901653

Epoch: 5| Step: 3
Training loss: 2.7524235248565674
Validation loss: 2.4447215244334233

Epoch: 5| Step: 4
Training loss: 3.0043609142303467
Validation loss: 2.421484280658025

Epoch: 5| Step: 5
Training loss: 2.227776288986206
Validation loss: 2.4028268988414476

Epoch: 5| Step: 6
Training loss: 3.245312452316284
Validation loss: 2.4076450409427768

Epoch: 5| Step: 7
Training loss: 3.466749906539917
Validation loss: 2.409514122111823

Epoch: 5| Step: 8
Training loss: 2.4734368324279785
Validation loss: 2.4087953541868474

Epoch: 5| Step: 9
Training loss: 3.269810438156128
Validation loss: 2.40593861251749

Epoch: 5| Step: 10
Training loss: 2.3431670665740967
Validation loss: 2.400681285447972

Epoch: 42| Step: 0
Training loss: 2.2911605834960938
Validation loss: 2.405807131080217

Epoch: 5| Step: 1
Training loss: 3.066868782043457
Validation loss: 2.407117592391147

Epoch: 5| Step: 2
Training loss: 2.600470542907715
Validation loss: 2.4089910291856333

Epoch: 5| Step: 3
Training loss: 2.997633218765259
Validation loss: 2.4137274475507837

Epoch: 5| Step: 4
Training loss: 2.5698256492614746
Validation loss: 2.4229298419849847

Epoch: 5| Step: 5
Training loss: 2.837458372116089
Validation loss: 2.42722854562985

Epoch: 5| Step: 6
Training loss: 2.7336583137512207
Validation loss: 2.4358213742574057

Epoch: 5| Step: 7
Training loss: 2.6018035411834717
Validation loss: 2.4497189137243454

Epoch: 5| Step: 8
Training loss: 2.5063040256500244
Validation loss: 2.438859208937614

Epoch: 5| Step: 9
Training loss: 2.4986369609832764
Validation loss: 2.428786123952558

Epoch: 5| Step: 10
Training loss: 2.372417449951172
Validation loss: 2.4083823978259997

Epoch: 43| Step: 0
Training loss: 2.3989696502685547
Validation loss: 2.3993452928399526

Epoch: 5| Step: 1
Training loss: 2.5699734687805176
Validation loss: 2.419386443271432

Epoch: 5| Step: 2
Training loss: 2.438032627105713
Validation loss: 2.4145128906414075

Epoch: 5| Step: 3
Training loss: 2.553799867630005
Validation loss: 2.407827728538103

Epoch: 5| Step: 4
Training loss: 2.1804821491241455
Validation loss: 2.4070151185476654

Epoch: 5| Step: 5
Training loss: 3.138554334640503
Validation loss: 2.4089815334607194

Epoch: 5| Step: 6
Training loss: 2.7950100898742676
Validation loss: 2.4000790529353644

Epoch: 5| Step: 7
Training loss: 2.202298402786255
Validation loss: 2.394740532803279

Epoch: 5| Step: 8
Training loss: 3.3863563537597656
Validation loss: 2.383411915071549

Epoch: 5| Step: 9
Training loss: 2.3151440620422363
Validation loss: 2.3780187291483723

Epoch: 5| Step: 10
Training loss: 3.3020565509796143
Validation loss: 2.3835706223723707

Epoch: 44| Step: 0
Training loss: 2.423321008682251
Validation loss: 2.3970118543153167

Epoch: 5| Step: 1
Training loss: 2.458935499191284
Validation loss: 2.4175788125684186

Epoch: 5| Step: 2
Training loss: 2.8851616382598877
Validation loss: 2.448666677680067

Epoch: 5| Step: 3
Training loss: 2.61032772064209
Validation loss: 2.486711473875148

Epoch: 5| Step: 4
Training loss: 2.4755616188049316
Validation loss: 2.506252578509751

Epoch: 5| Step: 5
Training loss: 2.9577910900115967
Validation loss: 2.4692936917786956

Epoch: 5| Step: 6
Training loss: 3.249425172805786
Validation loss: 2.4470612823322253

Epoch: 5| Step: 7
Training loss: 2.8410768508911133
Validation loss: 2.4195460324646323

Epoch: 5| Step: 8
Training loss: 2.3619675636291504
Validation loss: 2.4036430492196033

Epoch: 5| Step: 9
Training loss: 2.218898296356201
Validation loss: 2.4099704603995047

Epoch: 5| Step: 10
Training loss: 2.703742027282715
Validation loss: 2.413287321726481

Epoch: 45| Step: 0
Training loss: 2.4874045848846436
Validation loss: 2.41355719617618

Epoch: 5| Step: 1
Training loss: 2.3598759174346924
Validation loss: 2.422945673747729

Epoch: 5| Step: 2
Training loss: 2.7786402702331543
Validation loss: 2.4293321563351538

Epoch: 5| Step: 3
Training loss: 2.63339900970459
Validation loss: 2.427549023782053

Epoch: 5| Step: 4
Training loss: 3.0111680030822754
Validation loss: 2.4247677864566928

Epoch: 5| Step: 5
Training loss: 3.007814645767212
Validation loss: 2.4168665614179385

Epoch: 5| Step: 6
Training loss: 2.8014914989471436
Validation loss: 2.406612592358743

Epoch: 5| Step: 7
Training loss: 2.7443325519561768
Validation loss: 2.397838907857095

Epoch: 5| Step: 8
Training loss: 2.052978038787842
Validation loss: 2.400180632068265

Epoch: 5| Step: 9
Training loss: 3.2255046367645264
Validation loss: 2.4108042332433883

Epoch: 5| Step: 10
Training loss: 1.878056526184082
Validation loss: 2.4196556998837377

Epoch: 46| Step: 0
Training loss: 2.7076330184936523
Validation loss: 2.429330015695223

Epoch: 5| Step: 1
Training loss: 2.9601094722747803
Validation loss: 2.4243025266995994

Epoch: 5| Step: 2
Training loss: 2.974973678588867
Validation loss: 2.415566062414518

Epoch: 5| Step: 3
Training loss: 2.793581962585449
Validation loss: 2.40639393560348

Epoch: 5| Step: 4
Training loss: 2.67825984954834
Validation loss: 2.4013955336745068

Epoch: 5| Step: 5
Training loss: 2.872055768966675
Validation loss: 2.3958168260512815

Epoch: 5| Step: 6
Training loss: 1.9253549575805664
Validation loss: 2.3879376149946645

Epoch: 5| Step: 7
Training loss: 3.564444065093994
Validation loss: 2.389567816129295

Epoch: 5| Step: 8
Training loss: 2.1027722358703613
Validation loss: 2.3847105426173054

Epoch: 5| Step: 9
Training loss: 1.9315096139907837
Validation loss: 2.381382338462337

Epoch: 5| Step: 10
Training loss: 2.4124438762664795
Validation loss: 2.376120300703151

Epoch: 47| Step: 0
Training loss: 2.8537368774414062
Validation loss: 2.3697791702003888

Epoch: 5| Step: 1
Training loss: 2.0036773681640625
Validation loss: 2.372697188008216

Epoch: 5| Step: 2
Training loss: 2.89687180519104
Validation loss: 2.365178951653101

Epoch: 5| Step: 3
Training loss: 2.754462242126465
Validation loss: 2.3737001880522697

Epoch: 5| Step: 4
Training loss: 2.267310380935669
Validation loss: 2.376005306038805

Epoch: 5| Step: 5
Training loss: 2.724583148956299
Validation loss: 2.38950240483848

Epoch: 5| Step: 6
Training loss: 3.0269744396209717
Validation loss: 2.391333382616761

Epoch: 5| Step: 7
Training loss: 2.9459421634674072
Validation loss: 2.4025243277190835

Epoch: 5| Step: 8
Training loss: 2.999265670776367
Validation loss: 2.3908143902337677

Epoch: 5| Step: 9
Training loss: 2.562133312225342
Validation loss: 2.396797082757437

Epoch: 5| Step: 10
Training loss: 1.6715322732925415
Validation loss: 2.3880765463716243

Epoch: 48| Step: 0
Training loss: 2.671919822692871
Validation loss: 2.3769586522092103

Epoch: 5| Step: 1
Training loss: 2.857382297515869
Validation loss: 2.367067160144929

Epoch: 5| Step: 2
Training loss: 2.1472411155700684
Validation loss: 2.3605875174204507

Epoch: 5| Step: 3
Training loss: 2.1853625774383545
Validation loss: 2.3579974430863575

Epoch: 5| Step: 4
Training loss: 2.5026566982269287
Validation loss: 2.359453075675554

Epoch: 5| Step: 5
Training loss: 2.8405470848083496
Validation loss: 2.359007614915089

Epoch: 5| Step: 6
Training loss: 3.1959712505340576
Validation loss: 2.3673282336163264

Epoch: 5| Step: 7
Training loss: 2.7711832523345947
Validation loss: 2.3693312880813435

Epoch: 5| Step: 8
Training loss: 2.8402276039123535
Validation loss: 2.3667163541240077

Epoch: 5| Step: 9
Training loss: 1.9644562005996704
Validation loss: 2.352709670220652

Epoch: 5| Step: 10
Training loss: 3.0293450355529785
Validation loss: 2.35073858435436

Epoch: 49| Step: 0
Training loss: 2.4158685207366943
Validation loss: 2.3540439503167265

Epoch: 5| Step: 1
Training loss: 2.8641116619110107
Validation loss: 2.3582663330980527

Epoch: 5| Step: 2
Training loss: 1.98394775390625
Validation loss: 2.36766835822854

Epoch: 5| Step: 3
Training loss: 2.0143179893493652
Validation loss: 2.3739187204709618

Epoch: 5| Step: 4
Training loss: 2.44711971282959
Validation loss: 2.386131284057453

Epoch: 5| Step: 5
Training loss: 2.545660972595215
Validation loss: 2.390874360197334

Epoch: 5| Step: 6
Training loss: 2.9846832752227783
Validation loss: 2.386301863578058

Epoch: 5| Step: 7
Training loss: 2.636735439300537
Validation loss: 2.37639602281714

Epoch: 5| Step: 8
Training loss: 3.4428439140319824
Validation loss: 2.3754007739405476

Epoch: 5| Step: 9
Training loss: 2.6220932006835938
Validation loss: 2.355517569408622

Epoch: 5| Step: 10
Training loss: 2.883960008621216
Validation loss: 2.3481340433961604

Epoch: 50| Step: 0
Training loss: 3.0313258171081543
Validation loss: 2.346536579952445

Epoch: 5| Step: 1
Training loss: 2.4889895915985107
Validation loss: 2.343454840362713

Epoch: 5| Step: 2
Training loss: 2.532299757003784
Validation loss: 2.3439051925495105

Epoch: 5| Step: 3
Training loss: 2.5064752101898193
Validation loss: 2.3539137481361307

Epoch: 5| Step: 4
Training loss: 3.1039936542510986
Validation loss: 2.3509535789489746

Epoch: 5| Step: 5
Training loss: 3.1768596172332764
Validation loss: 2.352366421812324

Epoch: 5| Step: 6
Training loss: 2.8814456462860107
Validation loss: 2.349512520656791

Epoch: 5| Step: 7
Training loss: 2.2391610145568848
Validation loss: 2.337755109674187

Epoch: 5| Step: 8
Training loss: 2.2391607761383057
Validation loss: 2.335172971089681

Epoch: 5| Step: 9
Training loss: 2.243359327316284
Validation loss: 2.330246510044221

Epoch: 5| Step: 10
Training loss: 2.4137372970581055
Validation loss: 2.3461994406997517

Epoch: 51| Step: 0
Training loss: 2.7527904510498047
Validation loss: 2.3969796537071146

Epoch: 5| Step: 1
Training loss: 3.146149158477783
Validation loss: 2.47093217859986

Epoch: 5| Step: 2
Training loss: 2.807857036590576
Validation loss: 2.4645122943385953

Epoch: 5| Step: 3
Training loss: 2.6654937267303467
Validation loss: 2.455782034063852

Epoch: 5| Step: 4
Training loss: 2.395250082015991
Validation loss: 2.4224792090795373

Epoch: 5| Step: 5
Training loss: 2.6050870418548584
Validation loss: 2.426111682768791

Epoch: 5| Step: 6
Training loss: 3.2965869903564453
Validation loss: 2.3865529721783054

Epoch: 5| Step: 7
Training loss: 1.9980134963989258
Validation loss: 2.368177524176977

Epoch: 5| Step: 8
Training loss: 2.581042766571045
Validation loss: 2.353839742240085

Epoch: 5| Step: 9
Training loss: 2.6293225288391113
Validation loss: 2.3413732987578197

Epoch: 5| Step: 10
Training loss: 1.7543374300003052
Validation loss: 2.3383286845299507

Epoch: 52| Step: 0
Training loss: 2.5113918781280518
Validation loss: 2.332520754106583

Epoch: 5| Step: 1
Training loss: 2.272460460662842
Validation loss: 2.3294796161754157

Epoch: 5| Step: 2
Training loss: 2.567098379135132
Validation loss: 2.3287881189777004

Epoch: 5| Step: 3
Training loss: 2.9980947971343994
Validation loss: 2.333305299922984

Epoch: 5| Step: 4
Training loss: 2.8983607292175293
Validation loss: 2.337427831465198

Epoch: 5| Step: 5
Training loss: 2.4650752544403076
Validation loss: 2.3410141788503176

Epoch: 5| Step: 6
Training loss: 1.9928324222564697
Validation loss: 2.3453816624097925

Epoch: 5| Step: 7
Training loss: 2.3973450660705566
Validation loss: 2.3531732533567693

Epoch: 5| Step: 8
Training loss: 2.935384511947632
Validation loss: 2.3761454859087543

Epoch: 5| Step: 9
Training loss: 2.5626115798950195
Validation loss: 2.39738489479147

Epoch: 5| Step: 10
Training loss: 3.1511197090148926
Validation loss: 2.4346630278454033

Epoch: 53| Step: 0
Training loss: 2.6200711727142334
Validation loss: 2.42469366904228

Epoch: 5| Step: 1
Training loss: 2.3183140754699707
Validation loss: 2.4014553408468924

Epoch: 5| Step: 2
Training loss: 2.894679546356201
Validation loss: 2.3711168099475164

Epoch: 5| Step: 3
Training loss: 2.544787883758545
Validation loss: 2.3519921251522597

Epoch: 5| Step: 4
Training loss: 2.062511444091797
Validation loss: 2.3296878722406205

Epoch: 5| Step: 5
Training loss: 3.123586893081665
Validation loss: 2.3220024416523595

Epoch: 5| Step: 6
Training loss: 2.2628228664398193
Validation loss: 2.3165226187757266

Epoch: 5| Step: 7
Training loss: 3.1002440452575684
Validation loss: 2.3154845289004746

Epoch: 5| Step: 8
Training loss: 2.519806146621704
Validation loss: 2.3135265381105485

Epoch: 5| Step: 9
Training loss: 3.044816255569458
Validation loss: 2.3134598834540254

Epoch: 5| Step: 10
Training loss: 2.0445804595947266
Validation loss: 2.3176523895673853

Epoch: 54| Step: 0
Training loss: 2.9235033988952637
Validation loss: 2.3250299064061974

Epoch: 5| Step: 1
Training loss: 2.32950496673584
Validation loss: 2.3340233167012534

Epoch: 5| Step: 2
Training loss: 1.573383092880249
Validation loss: 2.3369655865494923

Epoch: 5| Step: 3
Training loss: 2.677654266357422
Validation loss: 2.3640939881724696

Epoch: 5| Step: 4
Training loss: 3.343674898147583
Validation loss: 2.375252116111017

Epoch: 5| Step: 5
Training loss: 3.3077540397644043
Validation loss: 2.3448696123656405

Epoch: 5| Step: 6
Training loss: 2.123201370239258
Validation loss: 2.327598853777814

Epoch: 5| Step: 7
Training loss: 2.734715700149536
Validation loss: 2.3213377716720744

Epoch: 5| Step: 8
Training loss: 2.590266704559326
Validation loss: 2.3139454664722567

Epoch: 5| Step: 9
Training loss: 2.284630537033081
Validation loss: 2.3109581547398723

Epoch: 5| Step: 10
Training loss: 2.5749990940093994
Validation loss: 2.3090267617215394

Epoch: 55| Step: 0
Training loss: 2.4071905612945557
Validation loss: 2.311523045262983

Epoch: 5| Step: 1
Training loss: 2.470888376235962
Validation loss: 2.3118207377772175

Epoch: 5| Step: 2
Training loss: 2.2949814796447754
Validation loss: 2.3069759158677954

Epoch: 5| Step: 3
Training loss: 2.5106022357940674
Validation loss: 2.308355441657446

Epoch: 5| Step: 4
Training loss: 2.9406559467315674
Validation loss: 2.3116489456545923

Epoch: 5| Step: 5
Training loss: 2.6226837635040283
Validation loss: 2.308123678289434

Epoch: 5| Step: 6
Training loss: 2.625953197479248
Validation loss: 2.308207306810605

Epoch: 5| Step: 7
Training loss: 2.230830192565918
Validation loss: 2.3153167924573346

Epoch: 5| Step: 8
Training loss: 2.4266467094421387
Validation loss: 2.3127477733037805

Epoch: 5| Step: 9
Training loss: 2.9874203205108643
Validation loss: 2.315188402770668

Epoch: 5| Step: 10
Training loss: 2.9632790088653564
Validation loss: 2.323598074656661

Epoch: 56| Step: 0
Training loss: 2.958298683166504
Validation loss: 2.35332993794513

Epoch: 5| Step: 1
Training loss: 1.5211231708526611
Validation loss: 2.3641223907470703

Epoch: 5| Step: 2
Training loss: 3.0179498195648193
Validation loss: 2.399308625087943

Epoch: 5| Step: 3
Training loss: 2.397650957107544
Validation loss: 2.409054776673676

Epoch: 5| Step: 4
Training loss: 2.7444005012512207
Validation loss: 2.464460657488915

Epoch: 5| Step: 5
Training loss: 3.266244411468506
Validation loss: 2.510969982352308

Epoch: 5| Step: 6
Training loss: 2.6810059547424316
Validation loss: 2.5258842616952877

Epoch: 5| Step: 7
Training loss: 2.342838764190674
Validation loss: 2.490271214515932

Epoch: 5| Step: 8
Training loss: 2.785437822341919
Validation loss: 2.471653389674361

Epoch: 5| Step: 9
Training loss: 2.6502187252044678
Validation loss: 2.4244336774272304

Epoch: 5| Step: 10
Training loss: 2.5755176544189453
Validation loss: 2.377665158241026

Epoch: 57| Step: 0
Training loss: 2.189744472503662
Validation loss: 2.3563715770680416

Epoch: 5| Step: 1
Training loss: 3.0559115409851074
Validation loss: 2.3514179465591267

Epoch: 5| Step: 2
Training loss: 3.026876926422119
Validation loss: 2.34002504041118

Epoch: 5| Step: 3
Training loss: 2.4099574089050293
Validation loss: 2.3418989258427776

Epoch: 5| Step: 4
Training loss: 3.025923728942871
Validation loss: 2.347688833872477

Epoch: 5| Step: 5
Training loss: 2.237485885620117
Validation loss: 2.3632830958212576

Epoch: 5| Step: 6
Training loss: 2.7371037006378174
Validation loss: 2.3739719570323987

Epoch: 5| Step: 7
Training loss: 3.481677293777466
Validation loss: 2.3697983628960064

Epoch: 5| Step: 8
Training loss: 1.7443307638168335
Validation loss: 2.346100050915954

Epoch: 5| Step: 9
Training loss: 2.1005444526672363
Validation loss: 2.3543309242494646

Epoch: 5| Step: 10
Training loss: 2.569566011428833
Validation loss: 2.3523475534172467

Epoch: 58| Step: 0
Training loss: 2.5838494300842285
Validation loss: 2.338469707837669

Epoch: 5| Step: 1
Training loss: 2.5126659870147705
Validation loss: 2.33123045070197

Epoch: 5| Step: 2
Training loss: 2.50486421585083
Validation loss: 2.3088192427030174

Epoch: 5| Step: 3
Training loss: 2.247303009033203
Validation loss: 2.310136784789383

Epoch: 5| Step: 4
Training loss: 2.81853985786438
Validation loss: 2.3275420050467215

Epoch: 5| Step: 5
Training loss: 2.53092622756958
Validation loss: 2.3296585365008284

Epoch: 5| Step: 6
Training loss: 2.5097053050994873
Validation loss: 2.3253010549852924

Epoch: 5| Step: 7
Training loss: 2.763392925262451
Validation loss: 2.3332876966845606

Epoch: 5| Step: 8
Training loss: 2.7871575355529785
Validation loss: 2.340017872471963

Epoch: 5| Step: 9
Training loss: 2.942305088043213
Validation loss: 2.3627017851798766

Epoch: 5| Step: 10
Training loss: 2.2053279876708984
Validation loss: 2.3735215035817956

Epoch: 59| Step: 0
Training loss: 2.6179139614105225
Validation loss: 2.3777225248275267

Epoch: 5| Step: 1
Training loss: 3.027981996536255
Validation loss: 2.403587087508171

Epoch: 5| Step: 2
Training loss: 2.455679416656494
Validation loss: 2.387500091265607

Epoch: 5| Step: 3
Training loss: 2.4863409996032715
Validation loss: 2.3685604218513734

Epoch: 5| Step: 4
Training loss: 1.9721189737319946
Validation loss: 2.3420627732430734

Epoch: 5| Step: 5
Training loss: 2.267005443572998
Validation loss: 2.3169518773273756

Epoch: 5| Step: 6
Training loss: 3.170285224914551
Validation loss: 2.2986973383093394

Epoch: 5| Step: 7
Training loss: 3.080993413925171
Validation loss: 2.29320026469487

Epoch: 5| Step: 8
Training loss: 2.345519542694092
Validation loss: 2.294824272073725

Epoch: 5| Step: 9
Training loss: 2.213533639907837
Validation loss: 2.2940075243673017

Epoch: 5| Step: 10
Training loss: 2.9371044635772705
Validation loss: 2.288868611858737

Epoch: 60| Step: 0
Training loss: 3.2240493297576904
Validation loss: 2.285438850361814

Epoch: 5| Step: 1
Training loss: 2.640618085861206
Validation loss: 2.2898554391758417

Epoch: 5| Step: 2
Training loss: 2.690307140350342
Validation loss: 2.298543163525161

Epoch: 5| Step: 3
Training loss: 1.9331636428833008
Validation loss: 2.304467911361366

Epoch: 5| Step: 4
Training loss: 2.508507251739502
Validation loss: 2.3579237794363372

Epoch: 5| Step: 5
Training loss: 3.220500946044922
Validation loss: 2.4049731762178483

Epoch: 5| Step: 6
Training loss: 3.0665647983551025
Validation loss: 2.451387566904868

Epoch: 5| Step: 7
Training loss: 2.364201307296753
Validation loss: 2.484170462495537

Epoch: 5| Step: 8
Training loss: 2.757699489593506
Validation loss: 2.4468625617283646

Epoch: 5| Step: 9
Training loss: 1.8678737878799438
Validation loss: 2.369282881418864

Epoch: 5| Step: 10
Training loss: 2.4304370880126953
Validation loss: 2.3238322504105104

Epoch: 61| Step: 0
Training loss: 2.6368556022644043
Validation loss: 2.299018954717985

Epoch: 5| Step: 1
Training loss: 2.4044699668884277
Validation loss: 2.3127790651013775

Epoch: 5| Step: 2
Training loss: 2.316089153289795
Validation loss: 2.329908004371069

Epoch: 5| Step: 3
Training loss: 2.4699530601501465
Validation loss: 2.322788273134539

Epoch: 5| Step: 4
Training loss: 2.421539306640625
Validation loss: 2.317106226439117

Epoch: 5| Step: 5
Training loss: 2.264723777770996
Validation loss: 2.312383031332365

Epoch: 5| Step: 6
Training loss: 2.7217354774475098
Validation loss: 2.300072458482558

Epoch: 5| Step: 7
Training loss: 2.935073137283325
Validation loss: 2.285964911983859

Epoch: 5| Step: 8
Training loss: 2.4382078647613525
Validation loss: 2.278923496123283

Epoch: 5| Step: 9
Training loss: 3.1555099487304688
Validation loss: 2.2705737326734807

Epoch: 5| Step: 10
Training loss: 2.450960874557495
Validation loss: 2.2717730691356044

Epoch: 62| Step: 0
Training loss: 2.407945156097412
Validation loss: 2.2780348536788777

Epoch: 5| Step: 1
Training loss: 2.6659188270568848
Validation loss: 2.2961643075430267

Epoch: 5| Step: 2
Training loss: 2.1136345863342285
Validation loss: 2.308003456361832

Epoch: 5| Step: 3
Training loss: 2.108487606048584
Validation loss: 2.32869291305542

Epoch: 5| Step: 4
Training loss: 3.0825870037078857
Validation loss: 2.331413702298236

Epoch: 5| Step: 5
Training loss: 2.2880547046661377
Validation loss: 2.3257714574055006

Epoch: 5| Step: 6
Training loss: 2.6924023628234863
Validation loss: 2.341404289327642

Epoch: 5| Step: 7
Training loss: 3.3442530632019043
Validation loss: 2.3006640582956295

Epoch: 5| Step: 8
Training loss: 2.5543289184570312
Validation loss: 2.2888240224571637

Epoch: 5| Step: 9
Training loss: 1.9610307216644287
Validation loss: 2.2908703921943583

Epoch: 5| Step: 10
Training loss: 3.023186206817627
Validation loss: 2.2862841236975884

Epoch: 63| Step: 0
Training loss: 2.222940444946289
Validation loss: 2.283585525328113

Epoch: 5| Step: 1
Training loss: 2.8921570777893066
Validation loss: 2.2817044693936586

Epoch: 5| Step: 2
Training loss: 2.141366481781006
Validation loss: 2.287142081927228

Epoch: 5| Step: 3
Training loss: 3.2366859912872314
Validation loss: 2.294327837164684

Epoch: 5| Step: 4
Training loss: 2.1719510555267334
Validation loss: 2.2836177067090104

Epoch: 5| Step: 5
Training loss: 2.7966530323028564
Validation loss: 2.289349745678645

Epoch: 5| Step: 6
Training loss: 2.238459587097168
Validation loss: 2.289864174781307

Epoch: 5| Step: 7
Training loss: 2.635009288787842
Validation loss: 2.286583673569464

Epoch: 5| Step: 8
Training loss: 2.371570110321045
Validation loss: 2.2868190542344125

Epoch: 5| Step: 9
Training loss: 2.7278378009796143
Validation loss: 2.302376708676738

Epoch: 5| Step: 10
Training loss: 2.861564874649048
Validation loss: 2.344730036233061

Epoch: 64| Step: 0
Training loss: 3.204555034637451
Validation loss: 2.41219767960169

Epoch: 5| Step: 1
Training loss: 2.935018539428711
Validation loss: 2.4125244412370908

Epoch: 5| Step: 2
Training loss: 2.4569828510284424
Validation loss: 2.4074117265721804

Epoch: 5| Step: 3
Training loss: 2.6124062538146973
Validation loss: 2.3985598830766577

Epoch: 5| Step: 4
Training loss: 3.3375308513641357
Validation loss: 2.3566558796872377

Epoch: 5| Step: 5
Training loss: 2.4519526958465576
Validation loss: 2.3070892044292983

Epoch: 5| Step: 6
Training loss: 2.595088481903076
Validation loss: 2.2637726747861473

Epoch: 5| Step: 7
Training loss: 2.0648105144500732
Validation loss: 2.2543739964885097

Epoch: 5| Step: 8
Training loss: 2.5730741024017334
Validation loss: 2.2900482146970687

Epoch: 5| Step: 9
Training loss: 2.5699572563171387
Validation loss: 2.311678704395089

Epoch: 5| Step: 10
Training loss: 1.7465095520019531
Validation loss: 2.3210726117575042

Epoch: 65| Step: 0
Training loss: 2.5786502361297607
Validation loss: 2.3412705749593754

Epoch: 5| Step: 1
Training loss: 2.689535140991211
Validation loss: 2.333248548610236

Epoch: 5| Step: 2
Training loss: 2.8435802459716797
Validation loss: 2.3264869336158998

Epoch: 5| Step: 3
Training loss: 2.7207274436950684
Validation loss: 2.308073725751651

Epoch: 5| Step: 4
Training loss: 2.547839641571045
Validation loss: 2.2880736935523247

Epoch: 5| Step: 5
Training loss: 3.3033363819122314
Validation loss: 2.281187968869363

Epoch: 5| Step: 6
Training loss: 2.567986011505127
Validation loss: 2.283210313448342

Epoch: 5| Step: 7
Training loss: 2.585531711578369
Validation loss: 2.287105511593562

Epoch: 5| Step: 8
Training loss: 2.1681628227233887
Validation loss: 2.3040444594557568

Epoch: 5| Step: 9
Training loss: 2.3294646739959717
Validation loss: 2.323397118558166

Epoch: 5| Step: 10
Training loss: 2.064544439315796
Validation loss: 2.3379710297430716

Epoch: 66| Step: 0
Training loss: 2.537968635559082
Validation loss: 2.357699312189574

Epoch: 5| Step: 1
Training loss: 2.600505828857422
Validation loss: 2.3688095218391827

Epoch: 5| Step: 2
Training loss: 2.5902671813964844
Validation loss: 2.3525985543445875

Epoch: 5| Step: 3
Training loss: 3.0368947982788086
Validation loss: 2.305315294573384

Epoch: 5| Step: 4
Training loss: 2.897904634475708
Validation loss: 2.265962617371672

Epoch: 5| Step: 5
Training loss: 2.658909320831299
Validation loss: 2.2489318386200936

Epoch: 5| Step: 6
Training loss: 2.4107470512390137
Validation loss: 2.2538101493671374

Epoch: 5| Step: 7
Training loss: 2.4595284461975098
Validation loss: 2.245466927046417

Epoch: 5| Step: 8
Training loss: 2.2575759887695312
Validation loss: 2.2476493671376216

Epoch: 5| Step: 9
Training loss: 2.4519267082214355
Validation loss: 2.2518485643530406

Epoch: 5| Step: 10
Training loss: 2.6117820739746094
Validation loss: 2.255222746120986

Epoch: 67| Step: 0
Training loss: 2.102966547012329
Validation loss: 2.259700200890982

Epoch: 5| Step: 1
Training loss: 2.82623553276062
Validation loss: 2.268605466811888

Epoch: 5| Step: 2
Training loss: 2.5306243896484375
Validation loss: 2.269714727196642

Epoch: 5| Step: 3
Training loss: 2.7716383934020996
Validation loss: 2.256574874283165

Epoch: 5| Step: 4
Training loss: 2.11995530128479
Validation loss: 2.2552792410696707

Epoch: 5| Step: 5
Training loss: 2.5109400749206543
Validation loss: 2.253717476321805

Epoch: 5| Step: 6
Training loss: 2.1515591144561768
Validation loss: 2.2565349994167203

Epoch: 5| Step: 7
Training loss: 2.6339104175567627
Validation loss: 2.2540225777574765

Epoch: 5| Step: 8
Training loss: 2.719430446624756
Validation loss: 2.2586231359871487

Epoch: 5| Step: 9
Training loss: 3.385155200958252
Validation loss: 2.260414349135532

Epoch: 5| Step: 10
Training loss: 2.4092273712158203
Validation loss: 2.2596381069511495

Epoch: 68| Step: 0
Training loss: 2.3576321601867676
Validation loss: 2.2510737731892574

Epoch: 5| Step: 1
Training loss: 2.852792739868164
Validation loss: 2.2533611943644862

Epoch: 5| Step: 2
Training loss: 2.0164780616760254
Validation loss: 2.251376190493184

Epoch: 5| Step: 3
Training loss: 2.6488850116729736
Validation loss: 2.2508984035061252

Epoch: 5| Step: 4
Training loss: 2.917267322540283
Validation loss: 2.2412425138617076

Epoch: 5| Step: 5
Training loss: 2.527306318283081
Validation loss: 2.237761789752591

Epoch: 5| Step: 6
Training loss: 2.4972825050354004
Validation loss: 2.2371051414038545

Epoch: 5| Step: 7
Training loss: 2.8010354042053223
Validation loss: 2.237989374386367

Epoch: 5| Step: 8
Training loss: 2.609393358230591
Validation loss: 2.238279419560586

Epoch: 5| Step: 9
Training loss: 2.3271639347076416
Validation loss: 2.2430314248608005

Epoch: 5| Step: 10
Training loss: 2.5516912937164307
Validation loss: 2.245862392969029

Epoch: 69| Step: 0
Training loss: 2.5624380111694336
Validation loss: 2.2509250820323987

Epoch: 5| Step: 1
Training loss: 2.297987461090088
Validation loss: 2.2554845861209336

Epoch: 5| Step: 2
Training loss: 2.3937504291534424
Validation loss: 2.2604718426222443

Epoch: 5| Step: 3
Training loss: 3.079742193222046
Validation loss: 2.2705355690371607

Epoch: 5| Step: 4
Training loss: 2.6574273109436035
Validation loss: 2.2885605135271625

Epoch: 5| Step: 5
Training loss: 2.9040818214416504
Validation loss: 2.296424347867248

Epoch: 5| Step: 6
Training loss: 2.517454147338867
Validation loss: 2.298214756032472

Epoch: 5| Step: 7
Training loss: 2.5505735874176025
Validation loss: 2.2910370108901814

Epoch: 5| Step: 8
Training loss: 1.905815839767456
Validation loss: 2.3047776991321194

Epoch: 5| Step: 9
Training loss: 2.363111972808838
Validation loss: 2.315983667168566

Epoch: 5| Step: 10
Training loss: 2.821399450302124
Validation loss: 2.3416445127097507

Epoch: 70| Step: 0
Training loss: 2.53253173828125
Validation loss: 2.324319431858678

Epoch: 5| Step: 1
Training loss: 2.2050278186798096
Validation loss: 2.3188554151083833

Epoch: 5| Step: 2
Training loss: 2.4027647972106934
Validation loss: 2.322750896535894

Epoch: 5| Step: 3
Training loss: 2.2415714263916016
Validation loss: 2.3356075261228826

Epoch: 5| Step: 4
Training loss: 2.4136481285095215
Validation loss: 2.3290252095909527

Epoch: 5| Step: 5
Training loss: 2.5758254528045654
Validation loss: 2.32676241987495

Epoch: 5| Step: 6
Training loss: 2.4551916122436523
Validation loss: 2.3318053650599655

Epoch: 5| Step: 7
Training loss: 2.9592812061309814
Validation loss: 2.289125939851166

Epoch: 5| Step: 8
Training loss: 2.944704532623291
Validation loss: 2.2526740874013593

Epoch: 5| Step: 9
Training loss: 2.7063210010528564
Validation loss: 2.2334316263916674

Epoch: 5| Step: 10
Training loss: 2.5271244049072266
Validation loss: 2.229044980900262

Epoch: 71| Step: 0
Training loss: 2.67626953125
Validation loss: 2.24156258695869

Epoch: 5| Step: 1
Training loss: 2.4407379627227783
Validation loss: 2.285965624675956

Epoch: 5| Step: 2
Training loss: 2.4235808849334717
Validation loss: 2.3253656228383384

Epoch: 5| Step: 3
Training loss: 3.0311520099639893
Validation loss: 2.390415968433503

Epoch: 5| Step: 4
Training loss: 2.549379348754883
Validation loss: 2.370060841242472

Epoch: 5| Step: 5
Training loss: 3.30558705329895
Validation loss: 2.338823769682197

Epoch: 5| Step: 6
Training loss: 2.592825412750244
Validation loss: 2.2867459917581208

Epoch: 5| Step: 7
Training loss: 2.577402114868164
Validation loss: 2.2556565641075053

Epoch: 5| Step: 8
Training loss: 2.5646424293518066
Validation loss: 2.2489418752731813

Epoch: 5| Step: 9
Training loss: 2.4898264408111572
Validation loss: 2.2551055467256935

Epoch: 5| Step: 10
Training loss: 2.103433609008789
Validation loss: 2.2428989807764688

Epoch: 72| Step: 0
Training loss: 3.0204403400421143
Validation loss: 2.2326620881275465

Epoch: 5| Step: 1
Training loss: 2.595024585723877
Validation loss: 2.243792897911482

Epoch: 5| Step: 2
Training loss: 2.9003167152404785
Validation loss: 2.257329689559116

Epoch: 5| Step: 3
Training loss: 2.9232840538024902
Validation loss: 2.276955768626223

Epoch: 5| Step: 4
Training loss: 2.0250535011291504
Validation loss: 2.2664832940665622

Epoch: 5| Step: 5
Training loss: 2.433511257171631
Validation loss: 2.258608919318004

Epoch: 5| Step: 6
Training loss: 2.509023427963257
Validation loss: 2.237485021673223

Epoch: 5| Step: 7
Training loss: 2.213890790939331
Validation loss: 2.2254396484744166

Epoch: 5| Step: 8
Training loss: 2.2177653312683105
Validation loss: 2.2259584626843854

Epoch: 5| Step: 9
Training loss: 2.316131353378296
Validation loss: 2.229717157220328

Epoch: 5| Step: 10
Training loss: 2.759897232055664
Validation loss: 2.2189936945515294

Epoch: 73| Step: 0
Training loss: 2.9060816764831543
Validation loss: 2.2181356440308275

Epoch: 5| Step: 1
Training loss: 2.086313247680664
Validation loss: 2.2198967190199

Epoch: 5| Step: 2
Training loss: 3.193178653717041
Validation loss: 2.2219730166978735

Epoch: 5| Step: 3
Training loss: 2.5485599040985107
Validation loss: 2.230865555424844

Epoch: 5| Step: 4
Training loss: 2.437995195388794
Validation loss: 2.239733237092213

Epoch: 5| Step: 5
Training loss: 2.4283628463745117
Validation loss: 2.2693981944873767

Epoch: 5| Step: 6
Training loss: 2.578118085861206
Validation loss: 2.346391411237819

Epoch: 5| Step: 7
Training loss: 2.2492763996124268
Validation loss: 2.3940642226126885

Epoch: 5| Step: 8
Training loss: 3.2240500450134277
Validation loss: 2.3346457699293732

Epoch: 5| Step: 9
Training loss: 2.2644708156585693
Validation loss: 2.2523989741520216

Epoch: 5| Step: 10
Training loss: 2.2189788818359375
Validation loss: 2.2111583781498734

Epoch: 74| Step: 0
Training loss: 3.088059663772583
Validation loss: 2.2121688909428094

Epoch: 5| Step: 1
Training loss: 2.2410309314727783
Validation loss: 2.214489929137691

Epoch: 5| Step: 2
Training loss: 2.3090100288391113
Validation loss: 2.219822035040907

Epoch: 5| Step: 3
Training loss: 2.0254673957824707
Validation loss: 2.2401999247971403

Epoch: 5| Step: 4
Training loss: 2.6272404193878174
Validation loss: 2.2909184502017115

Epoch: 5| Step: 5
Training loss: 2.667910575866699
Validation loss: 2.285090072180635

Epoch: 5| Step: 6
Training loss: 2.7456142902374268
Validation loss: 2.262888123912196

Epoch: 5| Step: 7
Training loss: 2.6550843715667725
Validation loss: 2.2609222524909565

Epoch: 5| Step: 8
Training loss: 2.7548317909240723
Validation loss: 2.271628222157878

Epoch: 5| Step: 9
Training loss: 2.881194591522217
Validation loss: 2.278324140015469

Epoch: 5| Step: 10
Training loss: 1.906084418296814
Validation loss: 2.2621174166279454

Epoch: 75| Step: 0
Training loss: 1.848459005355835
Validation loss: 2.2422295360155005

Epoch: 5| Step: 1
Training loss: 2.830303907394409
Validation loss: 2.211618815698931

Epoch: 5| Step: 2
Training loss: 2.686824083328247
Validation loss: 2.209660050689533

Epoch: 5| Step: 3
Training loss: 2.4107470512390137
Validation loss: 2.2077416143109723

Epoch: 5| Step: 4
Training loss: 1.7892959117889404
Validation loss: 2.1964502129503476

Epoch: 5| Step: 5
Training loss: 2.6086177825927734
Validation loss: 2.204738655397969

Epoch: 5| Step: 6
Training loss: 2.729712963104248
Validation loss: 2.220025812425921

Epoch: 5| Step: 7
Training loss: 3.3253798484802246
Validation loss: 2.2345529807511197

Epoch: 5| Step: 8
Training loss: 2.1031312942504883
Validation loss: 2.2297487592184417

Epoch: 5| Step: 9
Training loss: 2.7467966079711914
Validation loss: 2.2347805448757705

Epoch: 5| Step: 10
Training loss: 2.765517473220825
Validation loss: 2.226787039028701

Epoch: 76| Step: 0
Training loss: 2.7406067848205566
Validation loss: 2.23782253778109

Epoch: 5| Step: 1
Training loss: 1.8629505634307861
Validation loss: 2.233242957822738

Epoch: 5| Step: 2
Training loss: 2.1970303058624268
Validation loss: 2.2589780669058523

Epoch: 5| Step: 3
Training loss: 2.019003391265869
Validation loss: 2.2747252756549465

Epoch: 5| Step: 4
Training loss: 2.955955982208252
Validation loss: 2.346624107771022

Epoch: 5| Step: 5
Training loss: 1.8209612369537354
Validation loss: 2.3780463536580405

Epoch: 5| Step: 6
Training loss: 2.9662246704101562
Validation loss: 2.361994486983104

Epoch: 5| Step: 7
Training loss: 3.6584644317626953
Validation loss: 2.3467350416286017

Epoch: 5| Step: 8
Training loss: 2.6574137210845947
Validation loss: 2.313531821773898

Epoch: 5| Step: 9
Training loss: 2.8641269207000732
Validation loss: 2.2838185243709113

Epoch: 5| Step: 10
Training loss: 2.3894155025482178
Validation loss: 2.260548504449988

Epoch: 77| Step: 0
Training loss: 2.917210102081299
Validation loss: 2.2468486755124983

Epoch: 5| Step: 1
Training loss: 2.6820130348205566
Validation loss: 2.22618959283316

Epoch: 5| Step: 2
Training loss: 2.6645801067352295
Validation loss: 2.2201040009016633

Epoch: 5| Step: 3
Training loss: 2.999572277069092
Validation loss: 2.2156603682425713

Epoch: 5| Step: 4
Training loss: 2.415674924850464
Validation loss: 2.2203490836645967

Epoch: 5| Step: 5
Training loss: 2.44290828704834
Validation loss: 2.2183338006337485

Epoch: 5| Step: 6
Training loss: 2.5057027339935303
Validation loss: 2.241052414781304

Epoch: 5| Step: 7
Training loss: 2.6462833881378174
Validation loss: 2.2301407911444224

Epoch: 5| Step: 8
Training loss: 2.243921995162964
Validation loss: 2.2239021934488767

Epoch: 5| Step: 9
Training loss: 2.405792713165283
Validation loss: 2.2208297996110815

Epoch: 5| Step: 10
Training loss: 1.7849242687225342
Validation loss: 2.232170743326987

Epoch: 78| Step: 0
Training loss: 2.7110719680786133
Validation loss: 2.260064499352568

Epoch: 5| Step: 1
Training loss: 2.7569949626922607
Validation loss: 2.2689543949660433

Epoch: 5| Step: 2
Training loss: 2.320737361907959
Validation loss: 2.292264005189301

Epoch: 5| Step: 3
Training loss: 2.753340244293213
Validation loss: 2.2921175572179977

Epoch: 5| Step: 4
Training loss: 2.477912187576294
Validation loss: 2.3159555107034664

Epoch: 5| Step: 5
Training loss: 2.924389362335205
Validation loss: 2.351395768503989

Epoch: 5| Step: 6
Training loss: 2.5586555004119873
Validation loss: 2.382451388143724

Epoch: 5| Step: 7
Training loss: 1.9322211742401123
Validation loss: 2.4507766923596783

Epoch: 5| Step: 8
Training loss: 2.6050949096679688
Validation loss: 2.421918599836288

Epoch: 5| Step: 9
Training loss: 2.7179722785949707
Validation loss: 2.3283338444207304

Epoch: 5| Step: 10
Training loss: 2.4054927825927734
Validation loss: 2.254823689819664

Epoch: 79| Step: 0
Training loss: 2.744446277618408
Validation loss: 2.196869097730165

Epoch: 5| Step: 1
Training loss: 2.476793050765991
Validation loss: 2.1868832162631455

Epoch: 5| Step: 2
Training loss: 2.697003126144409
Validation loss: 2.1801078422095186

Epoch: 5| Step: 3
Training loss: 2.381437063217163
Validation loss: 2.1839600481012815

Epoch: 5| Step: 4
Training loss: 2.513871669769287
Validation loss: 2.206957883732293

Epoch: 5| Step: 5
Training loss: 2.101663112640381
Validation loss: 2.213879241738268

Epoch: 5| Step: 6
Training loss: 2.7173056602478027
Validation loss: 2.193123407261346

Epoch: 5| Step: 7
Training loss: 2.4928359985351562
Validation loss: 2.1773122818239274

Epoch: 5| Step: 8
Training loss: 2.2541019916534424
Validation loss: 2.16926404224929

Epoch: 5| Step: 9
Training loss: 2.7142062187194824
Validation loss: 2.163358493517804

Epoch: 5| Step: 10
Training loss: 2.9153079986572266
Validation loss: 2.1683523411391885

Epoch: 80| Step: 0
Training loss: 2.7198071479797363
Validation loss: 2.1661400102799937

Epoch: 5| Step: 1
Training loss: 2.4124248027801514
Validation loss: 2.17042439727373

Epoch: 5| Step: 2
Training loss: 2.426647663116455
Validation loss: 2.1677012699906544

Epoch: 5| Step: 3
Training loss: 2.35837984085083
Validation loss: 2.169158435636951

Epoch: 5| Step: 4
Training loss: 2.282823085784912
Validation loss: 2.172125406162713

Epoch: 5| Step: 5
Training loss: 2.192028284072876
Validation loss: 2.1816296808181272

Epoch: 5| Step: 6
Training loss: 2.706184148788452
Validation loss: 2.1967110223667596

Epoch: 5| Step: 7
Training loss: 3.3917107582092285
Validation loss: 2.214107387809343

Epoch: 5| Step: 8
Training loss: 2.3398382663726807
Validation loss: 2.2449812940371934

Epoch: 5| Step: 9
Training loss: 2.494187116622925
Validation loss: 2.2295957688362367

Epoch: 5| Step: 10
Training loss: 2.362452983856201
Validation loss: 2.213410526193598

Epoch: 81| Step: 0
Training loss: 2.277592182159424
Validation loss: 2.2203215937460623

Epoch: 5| Step: 1
Training loss: 2.6240041255950928
Validation loss: 2.211733243798697

Epoch: 5| Step: 2
Training loss: 2.2761616706848145
Validation loss: 2.2199886973186205

Epoch: 5| Step: 3
Training loss: 2.9330787658691406
Validation loss: 2.199995622839979

Epoch: 5| Step: 4
Training loss: 2.6036150455474854
Validation loss: 2.1940529372102473

Epoch: 5| Step: 5
Training loss: 3.153057098388672
Validation loss: 2.1839582317618915

Epoch: 5| Step: 6
Training loss: 2.392322540283203
Validation loss: 2.1659733787659676

Epoch: 5| Step: 7
Training loss: 1.998274803161621
Validation loss: 2.1602711190459547

Epoch: 5| Step: 8
Training loss: 2.005052328109741
Validation loss: 2.1592912443222536

Epoch: 5| Step: 9
Training loss: 2.3555214405059814
Validation loss: 2.15608880084048

Epoch: 5| Step: 10
Training loss: 2.945484161376953
Validation loss: 2.153337017182381

Epoch: 82| Step: 0
Training loss: 2.3008124828338623
Validation loss: 2.1554961307074434

Epoch: 5| Step: 1
Training loss: 2.4632906913757324
Validation loss: 2.1453138692404634

Epoch: 5| Step: 2
Training loss: 1.935886025428772
Validation loss: 2.143338721285584

Epoch: 5| Step: 3
Training loss: 2.7269489765167236
Validation loss: 2.159757867936165

Epoch: 5| Step: 4
Training loss: 2.917224884033203
Validation loss: 2.1635602597267396

Epoch: 5| Step: 5
Training loss: 2.782219648361206
Validation loss: 2.177908300071634

Epoch: 5| Step: 6
Training loss: 2.8973755836486816
Validation loss: 2.1735286866464922

Epoch: 5| Step: 7
Training loss: 2.6502130031585693
Validation loss: 2.161648673395957

Epoch: 5| Step: 8
Training loss: 2.1168124675750732
Validation loss: 2.1549012891707884

Epoch: 5| Step: 9
Training loss: 2.2845804691314697
Validation loss: 2.1503514115528395

Epoch: 5| Step: 10
Training loss: 2.067401170730591
Validation loss: 2.1646420981294368

Epoch: 83| Step: 0
Training loss: 2.4896833896636963
Validation loss: 2.2482057886738933

Epoch: 5| Step: 1
Training loss: 2.1759395599365234
Validation loss: 2.3260857623110534

Epoch: 5| Step: 2
Training loss: 2.6461598873138428
Validation loss: 2.3122640681523148

Epoch: 5| Step: 3
Training loss: 2.545616865158081
Validation loss: 2.2681703772596133

Epoch: 5| Step: 4
Training loss: 2.5281453132629395
Validation loss: 2.195780401588768

Epoch: 5| Step: 5
Training loss: 2.4085865020751953
Validation loss: 2.157384944218461

Epoch: 5| Step: 6
Training loss: 3.000762701034546
Validation loss: 2.1306188068082257

Epoch: 5| Step: 7
Training loss: 2.1455016136169434
Validation loss: 2.136008370307184

Epoch: 5| Step: 8
Training loss: 2.949608087539673
Validation loss: 2.134756677894182

Epoch: 5| Step: 9
Training loss: 2.207113265991211
Validation loss: 2.1302419657348306

Epoch: 5| Step: 10
Training loss: 2.2685511112213135
Validation loss: 2.1268874893906298

Epoch: 84| Step: 0
Training loss: 2.234546661376953
Validation loss: 2.135977598928636

Epoch: 5| Step: 1
Training loss: 2.585268497467041
Validation loss: 2.1382620975535405

Epoch: 5| Step: 2
Training loss: 2.7209877967834473
Validation loss: 2.142099416384133

Epoch: 5| Step: 3
Training loss: 2.794161319732666
Validation loss: 2.146646471433742

Epoch: 5| Step: 4
Training loss: 2.8284857273101807
Validation loss: 2.1426573748229654

Epoch: 5| Step: 5
Training loss: 2.6985270977020264
Validation loss: 2.143208037140549

Epoch: 5| Step: 6
Training loss: 2.2137179374694824
Validation loss: 2.1534713852790093

Epoch: 5| Step: 7
Training loss: 2.070080518722534
Validation loss: 2.1621781933692192

Epoch: 5| Step: 8
Training loss: 2.9023375511169434
Validation loss: 2.1835710566530944

Epoch: 5| Step: 9
Training loss: 1.8667185306549072
Validation loss: 2.208933543133479

Epoch: 5| Step: 10
Training loss: 2.625669479370117
Validation loss: 2.203959431699527

Epoch: 85| Step: 0
Training loss: 2.023110866546631
Validation loss: 2.1883081620739353

Epoch: 5| Step: 1
Training loss: 2.7913248538970947
Validation loss: 2.1794636159814815

Epoch: 5| Step: 2
Training loss: 2.5987548828125
Validation loss: 2.169195164916336

Epoch: 5| Step: 3
Training loss: 2.574737071990967
Validation loss: 2.167697778312109

Epoch: 5| Step: 4
Training loss: 2.0718138217926025
Validation loss: 2.1641028824672905

Epoch: 5| Step: 5
Training loss: 2.4709115028381348
Validation loss: 2.173705823959843

Epoch: 5| Step: 6
Training loss: 2.515725612640381
Validation loss: 2.1764824621139036

Epoch: 5| Step: 7
Training loss: 2.601839542388916
Validation loss: 2.1908328533172607

Epoch: 5| Step: 8
Training loss: 2.3910858631134033
Validation loss: 2.204321451084588

Epoch: 5| Step: 9
Training loss: 2.5475876331329346
Validation loss: 2.220044594939037

Epoch: 5| Step: 10
Training loss: 2.590378522872925
Validation loss: 2.2571196774000764

Epoch: 86| Step: 0
Training loss: 2.933450937271118
Validation loss: 2.306085204565397

Epoch: 5| Step: 1
Training loss: 2.4902572631835938
Validation loss: 2.303724809359479

Epoch: 5| Step: 2
Training loss: 2.527470111846924
Validation loss: 2.2640838546137654

Epoch: 5| Step: 3
Training loss: 2.4167380332946777
Validation loss: 2.221044999296947

Epoch: 5| Step: 4
Training loss: 2.5568690299987793
Validation loss: 2.1948746506885817

Epoch: 5| Step: 5
Training loss: 2.4274675846099854
Validation loss: 2.1786505201811432

Epoch: 5| Step: 6
Training loss: 2.422764301300049
Validation loss: 2.1649232513161114

Epoch: 5| Step: 7
Training loss: 1.8808809518814087
Validation loss: 2.148515373147944

Epoch: 5| Step: 8
Training loss: 2.672307252883911
Validation loss: 2.149784525235494

Epoch: 5| Step: 9
Training loss: 2.6437699794769287
Validation loss: 2.1461048895312893

Epoch: 5| Step: 10
Training loss: 2.3076000213623047
Validation loss: 2.14447759812878

Epoch: 87| Step: 0
Training loss: 1.5227797031402588
Validation loss: 2.1396555567300446

Epoch: 5| Step: 1
Training loss: 2.8820090293884277
Validation loss: 2.1511557935386576

Epoch: 5| Step: 2
Training loss: 2.1987857818603516
Validation loss: 2.1577292744831373

Epoch: 5| Step: 3
Training loss: 2.492363452911377
Validation loss: 2.171962591909593

Epoch: 5| Step: 4
Training loss: 2.8943073749542236
Validation loss: 2.191941507401005

Epoch: 5| Step: 5
Training loss: 2.5442440509796143
Validation loss: 2.2444797767105924

Epoch: 5| Step: 6
Training loss: 2.987888813018799
Validation loss: 2.230776333039807

Epoch: 5| Step: 7
Training loss: 2.3225836753845215
Validation loss: 2.2177254666564283

Epoch: 5| Step: 8
Training loss: 2.0571446418762207
Validation loss: 2.1924276403201524

Epoch: 5| Step: 9
Training loss: 3.028881788253784
Validation loss: 2.195830616899716

Epoch: 5| Step: 10
Training loss: 2.356287717819214
Validation loss: 2.2120033207760064

Epoch: 88| Step: 0
Training loss: 2.8254494667053223
Validation loss: 2.1799585652607743

Epoch: 5| Step: 1
Training loss: 2.095245361328125
Validation loss: 2.156685503580237

Epoch: 5| Step: 2
Training loss: 2.6184206008911133
Validation loss: 2.1365998073290755

Epoch: 5| Step: 3
Training loss: 2.393962860107422
Validation loss: 2.132637941709129

Epoch: 5| Step: 4
Training loss: 2.8284752368927
Validation loss: 2.134271111539615

Epoch: 5| Step: 5
Training loss: 2.5062038898468018
Validation loss: 2.1449097074488157

Epoch: 5| Step: 6
Training loss: 2.662122964859009
Validation loss: 2.1467819239503596

Epoch: 5| Step: 7
Training loss: 2.017632007598877
Validation loss: 2.1391731680080457

Epoch: 5| Step: 8
Training loss: 2.5046019554138184
Validation loss: 2.133039087377569

Epoch: 5| Step: 9
Training loss: 2.7434449195861816
Validation loss: 2.1329336371473087

Epoch: 5| Step: 10
Training loss: 2.064493179321289
Validation loss: 2.134157875532745

Epoch: 89| Step: 0
Training loss: 2.173499584197998
Validation loss: 2.141117549711658

Epoch: 5| Step: 1
Training loss: 2.7533249855041504
Validation loss: 2.14787862377782

Epoch: 5| Step: 2
Training loss: 2.395869731903076
Validation loss: 2.147175322296799

Epoch: 5| Step: 3
Training loss: 2.3155550956726074
Validation loss: 2.1524316828737975

Epoch: 5| Step: 4
Training loss: 2.476475954055786
Validation loss: 2.1666387742565525

Epoch: 5| Step: 5
Training loss: 2.606600522994995
Validation loss: 2.184737515705888

Epoch: 5| Step: 6
Training loss: 2.2499442100524902
Validation loss: 2.2167643103548276

Epoch: 5| Step: 7
Training loss: 2.5215892791748047
Validation loss: 2.2528035973989837

Epoch: 5| Step: 8
Training loss: 2.945981740951538
Validation loss: 2.2772958663202103

Epoch: 5| Step: 9
Training loss: 2.749110698699951
Validation loss: 2.2714604023964173

Epoch: 5| Step: 10
Training loss: 1.8955587148666382
Validation loss: 2.2318399170393586

Epoch: 90| Step: 0
Training loss: 2.290532112121582
Validation loss: 2.191899084275769

Epoch: 5| Step: 1
Training loss: 2.3605010509490967
Validation loss: 2.1469944753954486

Epoch: 5| Step: 2
Training loss: 2.405052661895752
Validation loss: 2.112710524630803

Epoch: 5| Step: 3
Training loss: 2.9859566688537598
Validation loss: 2.110387732905726

Epoch: 5| Step: 4
Training loss: 3.02337646484375
Validation loss: 2.129856396746892

Epoch: 5| Step: 5
Training loss: 2.592245101928711
Validation loss: 2.140501176157305

Epoch: 5| Step: 6
Training loss: 2.4131011962890625
Validation loss: 2.1630916595458984

Epoch: 5| Step: 7
Training loss: 2.5809385776519775
Validation loss: 2.1461381117502847

Epoch: 5| Step: 8
Training loss: 2.598039150238037
Validation loss: 2.133975108464559

Epoch: 5| Step: 9
Training loss: 2.0059032440185547
Validation loss: 2.1146338293629308

Epoch: 5| Step: 10
Training loss: 2.1534409523010254
Validation loss: 2.1163983332213534

Epoch: 91| Step: 0
Training loss: 2.3907418251037598
Validation loss: 2.109835696476762

Epoch: 5| Step: 1
Training loss: 2.949902057647705
Validation loss: 2.113383138051597

Epoch: 5| Step: 2
Training loss: 1.7880332469940186
Validation loss: 2.1222575249210482

Epoch: 5| Step: 3
Training loss: 3.1927547454833984
Validation loss: 2.1404693331769717

Epoch: 5| Step: 4
Training loss: 2.534048557281494
Validation loss: 2.1719809245037776

Epoch: 5| Step: 5
Training loss: 2.584303379058838
Validation loss: 2.2044036337124404

Epoch: 5| Step: 6
Training loss: 1.9133679866790771
Validation loss: 2.2565494327134985

Epoch: 5| Step: 7
Training loss: 2.701364755630493
Validation loss: 2.3092614425125944

Epoch: 5| Step: 8
Training loss: 2.2797091007232666
Validation loss: 2.296109891706897

Epoch: 5| Step: 9
Training loss: 2.630750894546509
Validation loss: 2.2553736061178227

Epoch: 5| Step: 10
Training loss: 2.2356936931610107
Validation loss: 2.2085624792242564

Epoch: 92| Step: 0
Training loss: 2.5669374465942383
Validation loss: 2.1654495846840645

Epoch: 5| Step: 1
Training loss: 2.8510079383850098
Validation loss: 2.1287187965967322

Epoch: 5| Step: 2
Training loss: 2.339914321899414
Validation loss: 2.10659094266994

Epoch: 5| Step: 3
Training loss: 2.1809298992156982
Validation loss: 2.1025904019673667

Epoch: 5| Step: 4
Training loss: 2.43546724319458
Validation loss: 2.1052567317921627

Epoch: 5| Step: 5
Training loss: 2.4104621410369873
Validation loss: 2.1065133335769817

Epoch: 5| Step: 6
Training loss: 2.3890795707702637
Validation loss: 2.1002458859515447

Epoch: 5| Step: 7
Training loss: 2.289395809173584
Validation loss: 2.101462310360324

Epoch: 5| Step: 8
Training loss: 2.918038845062256
Validation loss: 2.0999031195076565

Epoch: 5| Step: 9
Training loss: 2.527719497680664
Validation loss: 2.1093492136206677

Epoch: 5| Step: 10
Training loss: 2.460571765899658
Validation loss: 2.1150630263872046

Epoch: 93| Step: 0
Training loss: 2.437103509902954
Validation loss: 2.1175508883691605

Epoch: 5| Step: 1
Training loss: 2.089582681655884
Validation loss: 2.116176220678514

Epoch: 5| Step: 2
Training loss: 2.79891300201416
Validation loss: 2.1088266257316834

Epoch: 5| Step: 3
Training loss: 2.5491015911102295
Validation loss: 2.1188723400074947

Epoch: 5| Step: 4
Training loss: 2.1980159282684326
Validation loss: 2.1268999140749694

Epoch: 5| Step: 5
Training loss: 1.7641111612319946
Validation loss: 2.145629826412406

Epoch: 5| Step: 6
Training loss: 2.6541690826416016
Validation loss: 2.1730346269505

Epoch: 5| Step: 7
Training loss: 2.554973840713501
Validation loss: 2.1988269616198797

Epoch: 5| Step: 8
Training loss: 2.621739625930786
Validation loss: 2.2319392106866323

Epoch: 5| Step: 9
Training loss: 2.509687900543213
Validation loss: 2.250966618137975

Epoch: 5| Step: 10
Training loss: 3.034557819366455
Validation loss: 2.225772624374718

Epoch: 94| Step: 0
Training loss: 2.44049334526062
Validation loss: 2.209402408651126

Epoch: 5| Step: 1
Training loss: 3.3167152404785156
Validation loss: 2.201893625720855

Epoch: 5| Step: 2
Training loss: 2.233280658721924
Validation loss: 2.188796889397406

Epoch: 5| Step: 3
Training loss: 2.498561382293701
Validation loss: 2.1666438143740416

Epoch: 5| Step: 4
Training loss: 2.197880268096924
Validation loss: 2.1709194721714145

Epoch: 5| Step: 5
Training loss: 2.054856777191162
Validation loss: 2.1700834125600834

Epoch: 5| Step: 6
Training loss: 2.1485636234283447
Validation loss: 2.168088618145194

Epoch: 5| Step: 7
Training loss: 2.2293057441711426
Validation loss: 2.170683894106137

Epoch: 5| Step: 8
Training loss: 3.058619976043701
Validation loss: 2.1814955921583277

Epoch: 5| Step: 9
Training loss: 1.858304738998413
Validation loss: 2.1738752011329896

Epoch: 5| Step: 10
Training loss: 3.24617075920105
Validation loss: 2.1786809698227914

Epoch: 95| Step: 0
Training loss: 2.3129756450653076
Validation loss: 2.1721939502223844

Epoch: 5| Step: 1
Training loss: 3.2145371437072754
Validation loss: 2.156001780622749

Epoch: 5| Step: 2
Training loss: 2.4404799938201904
Validation loss: 2.149133264377553

Epoch: 5| Step: 3
Training loss: 2.089369773864746
Validation loss: 2.1460600360747306

Epoch: 5| Step: 4
Training loss: 2.3486595153808594
Validation loss: 2.134428289628798

Epoch: 5| Step: 5
Training loss: 1.8615432977676392
Validation loss: 2.122094635040529

Epoch: 5| Step: 6
Training loss: 2.7332963943481445
Validation loss: 2.1193143654895086

Epoch: 5| Step: 7
Training loss: 2.7659356594085693
Validation loss: 2.133930201171547

Epoch: 5| Step: 8
Training loss: 2.5914530754089355
Validation loss: 2.154558026662437

Epoch: 5| Step: 9
Training loss: 2.3111889362335205
Validation loss: 2.164634353371077

Epoch: 5| Step: 10
Training loss: 2.2171292304992676
Validation loss: 2.209186161718061

Epoch: 96| Step: 0
Training loss: 3.2071235179901123
Validation loss: 2.229115706618114

Epoch: 5| Step: 1
Training loss: 2.2814571857452393
Validation loss: 2.260258864330989

Epoch: 5| Step: 2
Training loss: 2.784092426300049
Validation loss: 2.3127618323090258

Epoch: 5| Step: 3
Training loss: 2.7053520679473877
Validation loss: 2.2949360903873237

Epoch: 5| Step: 4
Training loss: 1.948938012123108
Validation loss: 2.22141856275579

Epoch: 5| Step: 5
Training loss: 1.928392767906189
Validation loss: 2.1466178073677966

Epoch: 5| Step: 6
Training loss: 2.273237705230713
Validation loss: 2.1081683084528935

Epoch: 5| Step: 7
Training loss: 2.708308219909668
Validation loss: 2.086868401496641

Epoch: 5| Step: 8
Training loss: 2.2206838130950928
Validation loss: 2.0893923595387447

Epoch: 5| Step: 9
Training loss: 2.694500207901001
Validation loss: 2.0922558384556926

Epoch: 5| Step: 10
Training loss: 1.9917658567428589
Validation loss: 2.08847431085443

Epoch: 97| Step: 0
Training loss: 2.7418506145477295
Validation loss: 2.092633144829863

Epoch: 5| Step: 1
Training loss: 2.3345844745635986
Validation loss: 2.087720068552161

Epoch: 5| Step: 2
Training loss: 2.0074331760406494
Validation loss: 2.0868460747503463

Epoch: 5| Step: 3
Training loss: 2.447460174560547
Validation loss: 2.085278736647739

Epoch: 5| Step: 4
Training loss: 2.066082239151001
Validation loss: 2.0888249720296552

Epoch: 5| Step: 5
Training loss: 2.5042998790740967
Validation loss: 2.08251961072286

Epoch: 5| Step: 6
Training loss: 2.177694320678711
Validation loss: 2.084932924598776

Epoch: 5| Step: 7
Training loss: 2.4026129245758057
Validation loss: 2.0870380427247737

Epoch: 5| Step: 8
Training loss: 2.8169779777526855
Validation loss: 2.085994506394991

Epoch: 5| Step: 9
Training loss: 2.725181818008423
Validation loss: 2.0935515703693515

Epoch: 5| Step: 10
Training loss: 2.5282132625579834
Validation loss: 2.1040408329297136

Epoch: 98| Step: 0
Training loss: 2.115208148956299
Validation loss: 2.122871587353368

Epoch: 5| Step: 1
Training loss: 2.640160322189331
Validation loss: 2.1442296299883115

Epoch: 5| Step: 2
Training loss: 2.542271852493286
Validation loss: 2.1708124247930383

Epoch: 5| Step: 3
Training loss: 1.9289789199829102
Validation loss: 2.187007870725406

Epoch: 5| Step: 4
Training loss: 2.0609498023986816
Validation loss: 2.165045363928682

Epoch: 5| Step: 5
Training loss: 2.5646469593048096
Validation loss: 2.1290335501393964

Epoch: 5| Step: 6
Training loss: 3.264331102371216
Validation loss: 2.1010643128425843

Epoch: 5| Step: 7
Training loss: 2.5671181678771973
Validation loss: 2.0855935824814664

Epoch: 5| Step: 8
Training loss: 2.6405954360961914
Validation loss: 2.080591304327852

Epoch: 5| Step: 9
Training loss: 2.1120810508728027
Validation loss: 2.071930508459768

Epoch: 5| Step: 10
Training loss: 2.2981724739074707
Validation loss: 2.07160234579476

Epoch: 99| Step: 0
Training loss: 2.3525729179382324
Validation loss: 2.0648262757127003

Epoch: 5| Step: 1
Training loss: 2.441143035888672
Validation loss: 2.064680722451979

Epoch: 5| Step: 2
Training loss: 2.9329004287719727
Validation loss: 2.0715370652496174

Epoch: 5| Step: 3
Training loss: 2.30842924118042
Validation loss: 2.0863489925220446

Epoch: 5| Step: 4
Training loss: 2.0917747020721436
Validation loss: 2.1110641930692937

Epoch: 5| Step: 5
Training loss: 2.8621394634246826
Validation loss: 2.119981150473318

Epoch: 5| Step: 6
Training loss: 2.930891752243042
Validation loss: 2.1371313910330496

Epoch: 5| Step: 7
Training loss: 1.6997005939483643
Validation loss: 2.1558516230634464

Epoch: 5| Step: 8
Training loss: 1.858446478843689
Validation loss: 2.1690034815060195

Epoch: 5| Step: 9
Training loss: 2.8750319480895996
Validation loss: 2.164702476993684

Epoch: 5| Step: 10
Training loss: 2.475003242492676
Validation loss: 2.149675974281885

Epoch: 100| Step: 0
Training loss: 2.4623444080352783
Validation loss: 2.1150749870525893

Epoch: 5| Step: 1
Training loss: 1.1515995264053345
Validation loss: 2.0913579207594677

Epoch: 5| Step: 2
Training loss: 2.382798671722412
Validation loss: 2.0682731905291156

Epoch: 5| Step: 3
Training loss: 2.444788694381714
Validation loss: 2.0669711815413607

Epoch: 5| Step: 4
Training loss: 2.5849881172180176
Validation loss: 2.0629475321820987

Epoch: 5| Step: 5
Training loss: 2.9649910926818848
Validation loss: 2.0703719559536187

Epoch: 5| Step: 6
Training loss: 2.7765421867370605
Validation loss: 2.0647684604890886

Epoch: 5| Step: 7
Training loss: 1.243652582168579
Validation loss: 2.063065790360974

Epoch: 5| Step: 8
Training loss: 2.6873888969421387
Validation loss: 2.0594284367817703

Epoch: 5| Step: 9
Training loss: 3.3119454383850098
Validation loss: 2.06464631583101

Epoch: 5| Step: 10
Training loss: 2.4614572525024414
Validation loss: 2.063917072870398

Epoch: 101| Step: 0
Training loss: 3.0590105056762695
Validation loss: 2.069570428581648

Epoch: 5| Step: 1
Training loss: 2.3109018802642822
Validation loss: 2.0726656503574823

Epoch: 5| Step: 2
Training loss: 2.8427748680114746
Validation loss: 2.076497754743022

Epoch: 5| Step: 3
Training loss: 2.314903974533081
Validation loss: 2.0872445144960956

Epoch: 5| Step: 4
Training loss: 2.3557026386260986
Validation loss: 2.0995314505792435

Epoch: 5| Step: 5
Training loss: 2.4824299812316895
Validation loss: 2.119302847052133

Epoch: 5| Step: 6
Training loss: 1.925344467163086
Validation loss: 2.112853087404723

Epoch: 5| Step: 7
Training loss: 1.9996013641357422
Validation loss: 2.110247499199324

Epoch: 5| Step: 8
Training loss: 2.11860990524292
Validation loss: 2.1073661542707876

Epoch: 5| Step: 9
Training loss: 3.0930473804473877
Validation loss: 2.105069834698913

Epoch: 5| Step: 10
Training loss: 1.6944884061813354
Validation loss: 2.095033912248509

Epoch: 102| Step: 0
Training loss: 2.617737293243408
Validation loss: 2.0961711868163078

Epoch: 5| Step: 1
Training loss: 2.2526984214782715
Validation loss: 2.098648473780642

Epoch: 5| Step: 2
Training loss: 2.2834270000457764
Validation loss: 2.125373130203575

Epoch: 5| Step: 3
Training loss: 1.9166595935821533
Validation loss: 2.122920943844703

Epoch: 5| Step: 4
Training loss: 2.968367338180542
Validation loss: 2.1325150177042973

Epoch: 5| Step: 5
Training loss: 2.4307217597961426
Validation loss: 2.130919994846467

Epoch: 5| Step: 6
Training loss: 1.8305728435516357
Validation loss: 2.1148176218873713

Epoch: 5| Step: 7
Training loss: 3.055497407913208
Validation loss: 2.107843922030541

Epoch: 5| Step: 8
Training loss: 2.5524649620056152
Validation loss: 2.08043134468858

Epoch: 5| Step: 9
Training loss: 2.1176819801330566
Validation loss: 2.0737125694110827

Epoch: 5| Step: 10
Training loss: 2.2410295009613037
Validation loss: 2.060910801733694

Epoch: 103| Step: 0
Training loss: 2.7062795162200928
Validation loss: 2.049286082226743

Epoch: 5| Step: 1
Training loss: 2.3636786937713623
Validation loss: 2.0593572329449397

Epoch: 5| Step: 2
Training loss: 1.9277839660644531
Validation loss: 2.0631068163020636

Epoch: 5| Step: 3
Training loss: 2.40837025642395
Validation loss: 2.0698785192223004

Epoch: 5| Step: 4
Training loss: 2.9706156253814697
Validation loss: 2.072628313495267

Epoch: 5| Step: 5
Training loss: 2.721073627471924
Validation loss: 2.075783832098848

Epoch: 5| Step: 6
Training loss: 2.3621883392333984
Validation loss: 2.069011649777812

Epoch: 5| Step: 7
Training loss: 1.888250708580017
Validation loss: 2.0683427215904318

Epoch: 5| Step: 8
Training loss: 2.2223334312438965
Validation loss: 2.0587173995151313

Epoch: 5| Step: 9
Training loss: 2.7460625171661377
Validation loss: 2.0542379194690334

Epoch: 5| Step: 10
Training loss: 2.460721492767334
Validation loss: 2.06747361921495

Epoch: 104| Step: 0
Training loss: 2.211444854736328
Validation loss: 2.0946581491860012

Epoch: 5| Step: 1
Training loss: 2.1367321014404297
Validation loss: 2.1316897728109874

Epoch: 5| Step: 2
Training loss: 3.0572822093963623
Validation loss: 2.223514005702029

Epoch: 5| Step: 3
Training loss: 2.4548752307891846
Validation loss: 2.3939120141408776

Epoch: 5| Step: 4
Training loss: 2.856757879257202
Validation loss: 2.5485894039113033

Epoch: 5| Step: 5
Training loss: 2.3970744609832764
Validation loss: 2.603385868892875

Epoch: 5| Step: 6
Training loss: 3.1124107837677
Validation loss: 2.587993302652913

Epoch: 5| Step: 7
Training loss: 3.2939610481262207
Validation loss: 2.567513765827302

Epoch: 5| Step: 8
Training loss: 2.1675686836242676
Validation loss: 2.486276303568194

Epoch: 5| Step: 9
Training loss: 2.794647693634033
Validation loss: 2.3048521164924867

Epoch: 5| Step: 10
Training loss: 2.206265449523926
Validation loss: 2.154537864910659

Epoch: 105| Step: 0
Training loss: 2.7489733695983887
Validation loss: 2.0996177555412374

Epoch: 5| Step: 1
Training loss: 2.4982082843780518
Validation loss: 2.0786801204886487

Epoch: 5| Step: 2
Training loss: 2.2305407524108887
Validation loss: 2.0958296509199243

Epoch: 5| Step: 3
Training loss: 2.368795871734619
Validation loss: 2.1050562294580604

Epoch: 5| Step: 4
Training loss: 2.172314405441284
Validation loss: 2.146775884013022

Epoch: 5| Step: 5
Training loss: 2.1204845905303955
Validation loss: 2.152410089328725

Epoch: 5| Step: 6
Training loss: 2.9881205558776855
Validation loss: 2.1676409923902122

Epoch: 5| Step: 7
Training loss: 2.2728114128112793
Validation loss: 2.168870202956661

Epoch: 5| Step: 8
Training loss: 3.0106348991394043
Validation loss: 2.143645809542748

Epoch: 5| Step: 9
Training loss: 2.533879041671753
Validation loss: 2.143281917418203

Epoch: 5| Step: 10
Training loss: 2.7981293201446533
Validation loss: 2.129262003847348

Epoch: 106| Step: 0
Training loss: 2.718053102493286
Validation loss: 2.1111557752855363

Epoch: 5| Step: 1
Training loss: 1.7308919429779053
Validation loss: 2.0944146930530505

Epoch: 5| Step: 2
Training loss: 2.2088866233825684
Validation loss: 2.102855340127022

Epoch: 5| Step: 3
Training loss: 2.960175037384033
Validation loss: 2.1094761445958126

Epoch: 5| Step: 4
Training loss: 3.006333827972412
Validation loss: 2.1327106747575986

Epoch: 5| Step: 5
Training loss: 2.8357186317443848
Validation loss: 2.143496500548496

Epoch: 5| Step: 6
Training loss: 2.4257864952087402
Validation loss: 2.154726073306094

Epoch: 5| Step: 7
Training loss: 2.2436985969543457
Validation loss: 2.1605645302803285

Epoch: 5| Step: 8
Training loss: 2.2411885261535645
Validation loss: 2.1651714527478783

Epoch: 5| Step: 9
Training loss: 2.4207632541656494
Validation loss: 2.1748183004317747

Epoch: 5| Step: 10
Training loss: 1.7149566411972046
Validation loss: 2.182035048802694

Epoch: 107| Step: 0
Training loss: 2.2725143432617188
Validation loss: 2.1741357516216975

Epoch: 5| Step: 1
Training loss: 2.69496488571167
Validation loss: 2.165598287377306

Epoch: 5| Step: 2
Training loss: 2.472254991531372
Validation loss: 2.1518687535357732

Epoch: 5| Step: 3
Training loss: 2.1018879413604736
Validation loss: 2.1292607732998428

Epoch: 5| Step: 4
Training loss: 2.138451099395752
Validation loss: 2.0938002345382527

Epoch: 5| Step: 5
Training loss: 3.0739994049072266
Validation loss: 2.081372712248115

Epoch: 5| Step: 6
Training loss: 1.9883460998535156
Validation loss: 2.074773935861485

Epoch: 5| Step: 7
Training loss: 2.4680867195129395
Validation loss: 2.0682240968109458

Epoch: 5| Step: 8
Training loss: 1.9630683660507202
Validation loss: 2.069749491189116

Epoch: 5| Step: 9
Training loss: 2.4876084327697754
Validation loss: 2.0650521145072034

Epoch: 5| Step: 10
Training loss: 3.0137076377868652
Validation loss: 2.0691652669701526

Epoch: 108| Step: 0
Training loss: 2.0197436809539795
Validation loss: 2.075835261293637

Epoch: 5| Step: 1
Training loss: 2.4001059532165527
Validation loss: 2.0706854379305275

Epoch: 5| Step: 2
Training loss: 2.298840045928955
Validation loss: 2.065918266132314

Epoch: 5| Step: 3
Training loss: 2.7938504219055176
Validation loss: 2.0657383908507643

Epoch: 5| Step: 4
Training loss: 2.341254711151123
Validation loss: 2.074142327872656

Epoch: 5| Step: 5
Training loss: 2.404505968093872
Validation loss: 2.0782710852161532

Epoch: 5| Step: 6
Training loss: 2.184194326400757
Validation loss: 2.08661699423226

Epoch: 5| Step: 7
Training loss: 2.252589702606201
Validation loss: 2.0990538212560836

Epoch: 5| Step: 8
Training loss: 1.9312025308609009
Validation loss: 2.108859105776715

Epoch: 5| Step: 9
Training loss: 3.0321497917175293
Validation loss: 2.1255102362684024

Epoch: 5| Step: 10
Training loss: 3.052988290786743
Validation loss: 2.136997304936891

Epoch: 109| Step: 0
Training loss: 2.3834965229034424
Validation loss: 2.14444040483044

Epoch: 5| Step: 1
Training loss: 2.7802846431732178
Validation loss: 2.1357679546520276

Epoch: 5| Step: 2
Training loss: 2.1515440940856934
Validation loss: 2.136494431444394

Epoch: 5| Step: 3
Training loss: 2.515685558319092
Validation loss: 2.1251360908631356

Epoch: 5| Step: 4
Training loss: 2.4175314903259277
Validation loss: 2.102037445191414

Epoch: 5| Step: 5
Training loss: 2.567979335784912
Validation loss: 2.0850774242031958

Epoch: 5| Step: 6
Training loss: 2.372734546661377
Validation loss: 2.0800338727171703

Epoch: 5| Step: 7
Training loss: 2.3342881202697754
Validation loss: 2.0765308782618535

Epoch: 5| Step: 8
Training loss: 2.7887163162231445
Validation loss: 2.0774637652981665

Epoch: 5| Step: 9
Training loss: 1.7588058710098267
Validation loss: 2.069657600054177

Epoch: 5| Step: 10
Training loss: 2.2132489681243896
Validation loss: 2.070443207217801

Epoch: 110| Step: 0
Training loss: 2.855282783508301
Validation loss: 2.0714085819900676

Epoch: 5| Step: 1
Training loss: 2.4218502044677734
Validation loss: 2.0670713814355994

Epoch: 5| Step: 2
Training loss: 2.305849552154541
Validation loss: 2.0837513298116703

Epoch: 5| Step: 3
Training loss: 2.2997422218322754
Validation loss: 2.084250469361582

Epoch: 5| Step: 4
Training loss: 2.4506726264953613
Validation loss: 2.083377863771172

Epoch: 5| Step: 5
Training loss: 1.9899547100067139
Validation loss: 2.1055086325573664

Epoch: 5| Step: 6
Training loss: 2.4590632915496826
Validation loss: 2.118839676662158

Epoch: 5| Step: 7
Training loss: 2.402632713317871
Validation loss: 2.1194963173199723

Epoch: 5| Step: 8
Training loss: 2.5506317615509033
Validation loss: 2.115708751063193

Epoch: 5| Step: 9
Training loss: 1.9522054195404053
Validation loss: 2.121693681645137

Epoch: 5| Step: 10
Training loss: 2.6440718173980713
Validation loss: 2.116997080464517

Epoch: 111| Step: 0
Training loss: 3.3204948902130127
Validation loss: 2.1114822382568033

Epoch: 5| Step: 1
Training loss: 2.2611289024353027
Validation loss: 2.0982577928932766

Epoch: 5| Step: 2
Training loss: 1.7726627588272095
Validation loss: 2.0821830662347938

Epoch: 5| Step: 3
Training loss: 2.868533134460449
Validation loss: 2.0741641547090266

Epoch: 5| Step: 4
Training loss: 2.3340353965759277
Validation loss: 2.0743771740185317

Epoch: 5| Step: 5
Training loss: 1.9775712490081787
Validation loss: 2.090845613069432

Epoch: 5| Step: 6
Training loss: 2.1843044757843018
Validation loss: 2.0915315305033038

Epoch: 5| Step: 7
Training loss: 2.196441411972046
Validation loss: 2.0918274438509377

Epoch: 5| Step: 8
Training loss: 2.150418281555176
Validation loss: 2.10058779357582

Epoch: 5| Step: 9
Training loss: 2.7741870880126953
Validation loss: 2.095761622152021

Epoch: 5| Step: 10
Training loss: 2.2320897579193115
Validation loss: 2.083008513655714

Epoch: 112| Step: 0
Training loss: 2.371851682662964
Validation loss: 2.077609787705124

Epoch: 5| Step: 1
Training loss: 2.6135361194610596
Validation loss: 2.0776685143029816

Epoch: 5| Step: 2
Training loss: 1.9555009603500366
Validation loss: 2.06847196496943

Epoch: 5| Step: 3
Training loss: 2.5887610912323
Validation loss: 2.0576102156792917

Epoch: 5| Step: 4
Training loss: 1.978021264076233
Validation loss: 2.0592594659456642

Epoch: 5| Step: 5
Training loss: 2.5110793113708496
Validation loss: 2.068348346217986

Epoch: 5| Step: 6
Training loss: 2.372145891189575
Validation loss: 2.0610983551189466

Epoch: 5| Step: 7
Training loss: 2.4798996448516846
Validation loss: 2.068006278366171

Epoch: 5| Step: 8
Training loss: 2.4648630619049072
Validation loss: 2.0579719671639065

Epoch: 5| Step: 9
Training loss: 1.9813454151153564
Validation loss: 2.0679753531691847

Epoch: 5| Step: 10
Training loss: 2.6917247772216797
Validation loss: 2.0550114852125927

Epoch: 113| Step: 0
Training loss: 2.33679461479187
Validation loss: 2.057322959746084

Epoch: 5| Step: 1
Training loss: 2.253209352493286
Validation loss: 2.050226862712573

Epoch: 5| Step: 2
Training loss: 2.5377612113952637
Validation loss: 2.0445059550705778

Epoch: 5| Step: 3
Training loss: 2.771660566329956
Validation loss: 2.046420697242983

Epoch: 5| Step: 4
Training loss: 2.015821933746338
Validation loss: 2.0351465786657026

Epoch: 5| Step: 5
Training loss: 2.1042792797088623
Validation loss: 2.02997988013811

Epoch: 5| Step: 6
Training loss: 2.214932918548584
Validation loss: 2.0413603808290217

Epoch: 5| Step: 7
Training loss: 2.4196083545684814
Validation loss: 2.0439121351447156

Epoch: 5| Step: 8
Training loss: 2.335541248321533
Validation loss: 2.045882801855764

Epoch: 5| Step: 9
Training loss: 2.339475154876709
Validation loss: 2.0567605803089757

Epoch: 5| Step: 10
Training loss: 2.7071855068206787
Validation loss: 2.06330931058494

Epoch: 114| Step: 0
Training loss: 2.536562204360962
Validation loss: 2.0778628177540277

Epoch: 5| Step: 1
Training loss: 2.220341205596924
Validation loss: 2.0825534123246388

Epoch: 5| Step: 2
Training loss: 1.9925590753555298
Validation loss: 2.0990170458311677

Epoch: 5| Step: 3
Training loss: 2.9134411811828613
Validation loss: 2.1166922853839014

Epoch: 5| Step: 4
Training loss: 2.234900712966919
Validation loss: 2.1256451875932756

Epoch: 5| Step: 5
Training loss: 1.9815925359725952
Validation loss: 2.148612919674125

Epoch: 5| Step: 6
Training loss: 2.5487473011016846
Validation loss: 2.162423756814772

Epoch: 5| Step: 7
Training loss: 1.9791419506072998
Validation loss: 2.1472336707576627

Epoch: 5| Step: 8
Training loss: 2.6928207874298096
Validation loss: 2.101756321486606

Epoch: 5| Step: 9
Training loss: 2.4249424934387207
Validation loss: 2.0742052088501635

Epoch: 5| Step: 10
Training loss: 2.3108959197998047
Validation loss: 2.0690704981486

Epoch: 115| Step: 0
Training loss: 2.1945724487304688
Validation loss: 2.0503396321368474

Epoch: 5| Step: 1
Training loss: 1.9827864170074463
Validation loss: 2.035144937935696

Epoch: 5| Step: 2
Training loss: 2.5908656120300293
Validation loss: 2.032938736741261

Epoch: 5| Step: 3
Training loss: 2.4540019035339355
Validation loss: 2.0356420368276615

Epoch: 5| Step: 4
Training loss: 2.617096185684204
Validation loss: 2.039452763013942

Epoch: 5| Step: 5
Training loss: 1.8267908096313477
Validation loss: 2.0339758678149154

Epoch: 5| Step: 6
Training loss: 2.233283519744873
Validation loss: 2.042038462495291

Epoch: 5| Step: 7
Training loss: 2.359154462814331
Validation loss: 2.0382849426679712

Epoch: 5| Step: 8
Training loss: 2.7703540325164795
Validation loss: 2.048669449744686

Epoch: 5| Step: 9
Training loss: 2.6525425910949707
Validation loss: 2.0444956594897854

Epoch: 5| Step: 10
Training loss: 2.001821517944336
Validation loss: 2.052329014706355

Epoch: 116| Step: 0
Training loss: 2.7911999225616455
Validation loss: 2.0668507199133597

Epoch: 5| Step: 1
Training loss: 1.856580376625061
Validation loss: 2.0895545636453936

Epoch: 5| Step: 2
Training loss: 2.12636137008667
Validation loss: 2.0980417343877975

Epoch: 5| Step: 3
Training loss: 2.7542190551757812
Validation loss: 2.0997532644579486

Epoch: 5| Step: 4
Training loss: 2.734846830368042
Validation loss: 2.1185277046695834

Epoch: 5| Step: 5
Training loss: 2.676104784011841
Validation loss: 2.1212103597579466

Epoch: 5| Step: 6
Training loss: 1.7647273540496826
Validation loss: 2.1404481908326507

Epoch: 5| Step: 7
Training loss: 2.0550355911254883
Validation loss: 2.1343833733630437

Epoch: 5| Step: 8
Training loss: 2.704965114593506
Validation loss: 2.0915640733575307

Epoch: 5| Step: 9
Training loss: 2.3562469482421875
Validation loss: 2.062006042849633

Epoch: 5| Step: 10
Training loss: 2.0715858936309814
Validation loss: 2.048673447742257

Epoch: 117| Step: 0
Training loss: 1.8804118633270264
Validation loss: 2.043282967741771

Epoch: 5| Step: 1
Training loss: 2.6831846237182617
Validation loss: 2.0362917402739167

Epoch: 5| Step: 2
Training loss: 2.0208218097686768
Validation loss: 2.0289355439524495

Epoch: 5| Step: 3
Training loss: 2.4690053462982178
Validation loss: 2.0396668962253037

Epoch: 5| Step: 4
Training loss: 2.279837131500244
Validation loss: 2.045649654121809

Epoch: 5| Step: 5
Training loss: 2.441568374633789
Validation loss: 2.0389676683692524

Epoch: 5| Step: 6
Training loss: 2.5967819690704346
Validation loss: 2.0380475700542493

Epoch: 5| Step: 7
Training loss: 2.6065917015075684
Validation loss: 2.0453383512394403

Epoch: 5| Step: 8
Training loss: 2.2185940742492676
Validation loss: 2.0365737971439155

Epoch: 5| Step: 9
Training loss: 2.20595645904541
Validation loss: 2.053601044480519

Epoch: 5| Step: 10
Training loss: 2.0752294063568115
Validation loss: 2.0757948762627056

Epoch: 118| Step: 0
Training loss: 2.446582555770874
Validation loss: 2.1401266154422554

Epoch: 5| Step: 1
Training loss: 2.6071457862854004
Validation loss: 2.204460092770156

Epoch: 5| Step: 2
Training loss: 2.4752120971679688
Validation loss: 2.2702213256589827

Epoch: 5| Step: 3
Training loss: 2.0279746055603027
Validation loss: 2.3111812350570515

Epoch: 5| Step: 4
Training loss: 2.221457004547119
Validation loss: 2.285006215495448

Epoch: 5| Step: 5
Training loss: 2.6717193126678467
Validation loss: 2.21757629481695

Epoch: 5| Step: 6
Training loss: 1.9615312814712524
Validation loss: 2.130677971788632

Epoch: 5| Step: 7
Training loss: 2.529860734939575
Validation loss: 2.0697081768384544

Epoch: 5| Step: 8
Training loss: 2.5434892177581787
Validation loss: 2.0306528896413822

Epoch: 5| Step: 9
Training loss: 2.3169217109680176
Validation loss: 2.0245305581759383

Epoch: 5| Step: 10
Training loss: 2.2415904998779297
Validation loss: 2.0340965563251125

Epoch: 119| Step: 0
Training loss: 2.1900336742401123
Validation loss: 2.0311093586747364

Epoch: 5| Step: 1
Training loss: 2.53214430809021
Validation loss: 2.034641445323985

Epoch: 5| Step: 2
Training loss: 1.8359014987945557
Validation loss: 2.041361726740355

Epoch: 5| Step: 3
Training loss: 2.5590548515319824
Validation loss: 2.044624511913587

Epoch: 5| Step: 4
Training loss: 2.6004691123962402
Validation loss: 2.044453174837174

Epoch: 5| Step: 5
Training loss: 2.521594285964966
Validation loss: 2.050588996179642

Epoch: 5| Step: 6
Training loss: 2.424492359161377
Validation loss: 2.0392179591681368

Epoch: 5| Step: 7
Training loss: 2.518165111541748
Validation loss: 2.0394352969302925

Epoch: 5| Step: 8
Training loss: 2.074105978012085
Validation loss: 2.023800188495267

Epoch: 5| Step: 9
Training loss: 2.8240907192230225
Validation loss: 2.0144023715808825

Epoch: 5| Step: 10
Training loss: 2.1321237087249756
Validation loss: 2.02240655755484

Epoch: 120| Step: 0
Training loss: 2.195010185241699
Validation loss: 2.0261455966580297

Epoch: 5| Step: 1
Training loss: 1.7876743078231812
Validation loss: 2.048941345625026

Epoch: 5| Step: 2
Training loss: 2.7190921306610107
Validation loss: 2.0598856044071976

Epoch: 5| Step: 3
Training loss: 2.0798277854919434
Validation loss: 2.0779012967181463

Epoch: 5| Step: 4
Training loss: 2.6805567741394043
Validation loss: 2.1012755773400746

Epoch: 5| Step: 5
Training loss: 2.161816358566284
Validation loss: 2.102412187924949

Epoch: 5| Step: 6
Training loss: 2.2479870319366455
Validation loss: 2.1036750962657313

Epoch: 5| Step: 7
Training loss: 2.014075517654419
Validation loss: 2.0986045432347122

Epoch: 5| Step: 8
Training loss: 2.7435007095336914
Validation loss: 2.1015095390299314

Epoch: 5| Step: 9
Training loss: 2.3661792278289795
Validation loss: 2.1089552833187963

Epoch: 5| Step: 10
Training loss: 2.610137701034546
Validation loss: 2.109636555435837

Epoch: 121| Step: 0
Training loss: 2.215250015258789
Validation loss: 2.0930832175798315

Epoch: 5| Step: 1
Training loss: 2.4217991828918457
Validation loss: 2.075426778485698

Epoch: 5| Step: 2
Training loss: 2.219757318496704
Validation loss: 2.061370973945946

Epoch: 5| Step: 3
Training loss: 2.526268720626831
Validation loss: 2.0222460044327604

Epoch: 5| Step: 4
Training loss: 2.2362427711486816
Validation loss: 2.00761991418818

Epoch: 5| Step: 5
Training loss: 2.0902905464172363
Validation loss: 2.0060634100308983

Epoch: 5| Step: 6
Training loss: 2.6713266372680664
Validation loss: 2.0108441704063007

Epoch: 5| Step: 7
Training loss: 2.349302053451538
Validation loss: 2.0178874948973298

Epoch: 5| Step: 8
Training loss: 2.288910388946533
Validation loss: 2.035698793267691

Epoch: 5| Step: 9
Training loss: 1.6248546838760376
Validation loss: 2.0332210576662453

Epoch: 5| Step: 10
Training loss: 3.1714723110198975
Validation loss: 2.0301097080271733

Epoch: 122| Step: 0
Training loss: 2.8783156871795654
Validation loss: 2.0207382273930374

Epoch: 5| Step: 1
Training loss: 2.091169834136963
Validation loss: 2.029286315364222

Epoch: 5| Step: 2
Training loss: 2.2897391319274902
Validation loss: 2.0336472244672876

Epoch: 5| Step: 3
Training loss: 1.9884793758392334
Validation loss: 2.049160333089931

Epoch: 5| Step: 4
Training loss: 2.0558383464813232
Validation loss: 2.062369433782434

Epoch: 5| Step: 5
Training loss: 2.7079081535339355
Validation loss: 2.048271161253734

Epoch: 5| Step: 6
Training loss: 1.851858377456665
Validation loss: 2.0410447120666504

Epoch: 5| Step: 7
Training loss: 2.823516368865967
Validation loss: 2.0445764808244604

Epoch: 5| Step: 8
Training loss: 1.6357355117797852
Validation loss: 2.0357333306343324

Epoch: 5| Step: 9
Training loss: 2.0131187438964844
Validation loss: 2.0399058390689153

Epoch: 5| Step: 10
Training loss: 3.0246920585632324
Validation loss: 2.033885940428703

Epoch: 123| Step: 0
Training loss: 2.879218578338623
Validation loss: 2.027038220436342

Epoch: 5| Step: 1
Training loss: 1.7986414432525635
Validation loss: 2.026837497629145

Epoch: 5| Step: 2
Training loss: 1.8858217000961304
Validation loss: 2.019683175189521

Epoch: 5| Step: 3
Training loss: 2.7166543006896973
Validation loss: 2.029113179893904

Epoch: 5| Step: 4
Training loss: 2.5142438411712646
Validation loss: 2.0326481955025786

Epoch: 5| Step: 5
Training loss: 1.9550567865371704
Validation loss: 2.026017532553724

Epoch: 5| Step: 6
Training loss: 2.5330147743225098
Validation loss: 2.0397633442314724

Epoch: 5| Step: 7
Training loss: 2.2542030811309814
Validation loss: 2.0304553226758073

Epoch: 5| Step: 8
Training loss: 2.2682037353515625
Validation loss: 2.0340027322051344

Epoch: 5| Step: 9
Training loss: 2.212944507598877
Validation loss: 2.046638002959631

Epoch: 5| Step: 10
Training loss: 2.1515111923217773
Validation loss: 2.028215756980322

Epoch: 124| Step: 0
Training loss: 2.226144313812256
Validation loss: 2.015105378243231

Epoch: 5| Step: 1
Training loss: 2.125640869140625
Validation loss: 2.01898439468876

Epoch: 5| Step: 2
Training loss: 2.2555794715881348
Validation loss: 2.017938798473727

Epoch: 5| Step: 3
Training loss: 2.507321834564209
Validation loss: 2.0213205865634385

Epoch: 5| Step: 4
Training loss: 2.868281602859497
Validation loss: 2.0173182538760606

Epoch: 5| Step: 5
Training loss: 2.0462450981140137
Validation loss: 2.024777417541832

Epoch: 5| Step: 6
Training loss: 1.5896494388580322
Validation loss: 2.0204604620574624

Epoch: 5| Step: 7
Training loss: 2.2864837646484375
Validation loss: 2.006667051264035

Epoch: 5| Step: 8
Training loss: 2.128758192062378
Validation loss: 1.9904138529172508

Epoch: 5| Step: 9
Training loss: 2.5722222328186035
Validation loss: 1.9887658921621179

Epoch: 5| Step: 10
Training loss: 2.475592613220215
Validation loss: 1.9859422099205755

Epoch: 125| Step: 0
Training loss: 2.490583896636963
Validation loss: 1.9667691825538554

Epoch: 5| Step: 1
Training loss: 1.611432671546936
Validation loss: 1.9789029962273055

Epoch: 5| Step: 2
Training loss: 2.5887417793273926
Validation loss: 1.9825720069228963

Epoch: 5| Step: 3
Training loss: 2.5010082721710205
Validation loss: 1.9829266789138957

Epoch: 5| Step: 4
Training loss: 1.8563716411590576
Validation loss: 1.9944859089389924

Epoch: 5| Step: 5
Training loss: 2.301565647125244
Validation loss: 2.0166196656483475

Epoch: 5| Step: 6
Training loss: 3.013551712036133
Validation loss: 2.010769059581141

Epoch: 5| Step: 7
Training loss: 2.098684310913086
Validation loss: 2.0234550993929625

Epoch: 5| Step: 8
Training loss: 2.05666446685791
Validation loss: 2.0074379726122786

Epoch: 5| Step: 9
Training loss: 2.6514980792999268
Validation loss: 2.003768867061984

Epoch: 5| Step: 10
Training loss: 1.9638068675994873
Validation loss: 1.9881484995606125

Epoch: 126| Step: 0
Training loss: 2.4635531902313232
Validation loss: 1.9921787682399954

Epoch: 5| Step: 1
Training loss: 1.7789194583892822
Validation loss: 1.985456137246983

Epoch: 5| Step: 2
Training loss: 1.8981506824493408
Validation loss: 1.9953685986098422

Epoch: 5| Step: 3
Training loss: 2.3627305030822754
Validation loss: 1.983007542548641

Epoch: 5| Step: 4
Training loss: 2.2003445625305176
Validation loss: 1.9843045024461643

Epoch: 5| Step: 5
Training loss: 2.084543228149414
Validation loss: 1.9800345820765342

Epoch: 5| Step: 6
Training loss: 2.336812973022461
Validation loss: 1.9895460579984932

Epoch: 5| Step: 7
Training loss: 2.723684310913086
Validation loss: 1.9900346404762679

Epoch: 5| Step: 8
Training loss: 2.00715708732605
Validation loss: 1.9859025375817412

Epoch: 5| Step: 9
Training loss: 2.7716758251190186
Validation loss: 1.9836101224345546

Epoch: 5| Step: 10
Training loss: 2.2436563968658447
Validation loss: 1.991361456532632

Epoch: 127| Step: 0
Training loss: 2.716099500656128
Validation loss: 1.991439111771122

Epoch: 5| Step: 1
Training loss: 2.590388298034668
Validation loss: 1.9911367290763444

Epoch: 5| Step: 2
Training loss: 2.366536855697632
Validation loss: 1.990203042184153

Epoch: 5| Step: 3
Training loss: 2.392429828643799
Validation loss: 2.0120194445374193

Epoch: 5| Step: 4
Training loss: 1.7520946264266968
Validation loss: 2.0199584473845777

Epoch: 5| Step: 5
Training loss: 2.5476152896881104
Validation loss: 2.0395120920673495

Epoch: 5| Step: 6
Training loss: 1.7305171489715576
Validation loss: 2.0664701154155116

Epoch: 5| Step: 7
Training loss: 2.021394968032837
Validation loss: 2.0697832081907537

Epoch: 5| Step: 8
Training loss: 2.2981724739074707
Validation loss: 2.0582314537417505

Epoch: 5| Step: 9
Training loss: 2.5524024963378906
Validation loss: 2.0328068348669235

Epoch: 5| Step: 10
Training loss: 1.9617385864257812
Validation loss: 2.009401443184063

Epoch: 128| Step: 0
Training loss: 2.147620677947998
Validation loss: 1.997452284700127

Epoch: 5| Step: 1
Training loss: 2.613103151321411
Validation loss: 1.9912991152014783

Epoch: 5| Step: 2
Training loss: 2.395582675933838
Validation loss: 2.0038293792355444

Epoch: 5| Step: 3
Training loss: 2.463578701019287
Validation loss: 2.006154134709348

Epoch: 5| Step: 4
Training loss: 2.3096437454223633
Validation loss: 1.9979103739543627

Epoch: 5| Step: 5
Training loss: 1.4685852527618408
Validation loss: 1.9996250047478625

Epoch: 5| Step: 6
Training loss: 3.1808552742004395
Validation loss: 2.015775760014852

Epoch: 5| Step: 7
Training loss: 1.8297615051269531
Validation loss: 2.0330451829459077

Epoch: 5| Step: 8
Training loss: 1.889443039894104
Validation loss: 2.0599318691479263

Epoch: 5| Step: 9
Training loss: 2.5133204460144043
Validation loss: 2.07907525954708

Epoch: 5| Step: 10
Training loss: 2.2287259101867676
Validation loss: 2.127016859669839

Epoch: 129| Step: 0
Training loss: 1.7007701396942139
Validation loss: 2.1378271989924933

Epoch: 5| Step: 1
Training loss: 2.295405864715576
Validation loss: 2.112162208044401

Epoch: 5| Step: 2
Training loss: 2.944645404815674
Validation loss: 2.098608260513634

Epoch: 5| Step: 3
Training loss: 2.3813774585723877
Validation loss: 2.0551836939268213

Epoch: 5| Step: 4
Training loss: 3.014470338821411
Validation loss: 2.020220753967121

Epoch: 5| Step: 5
Training loss: 2.780137300491333
Validation loss: 2.0065759048667005

Epoch: 5| Step: 6
Training loss: 1.5824987888336182
Validation loss: 1.997346092295903

Epoch: 5| Step: 7
Training loss: 1.7694520950317383
Validation loss: 1.9905214514783633

Epoch: 5| Step: 8
Training loss: 2.3289549350738525
Validation loss: 1.9803395399483301

Epoch: 5| Step: 9
Training loss: 1.877791404724121
Validation loss: 1.9925411426892845

Epoch: 5| Step: 10
Training loss: 2.40940260887146
Validation loss: 1.9838508739266345

Epoch: 130| Step: 0
Training loss: 2.1703364849090576
Validation loss: 1.9940359348891883

Epoch: 5| Step: 1
Training loss: 2.6841816902160645
Validation loss: 1.9907735598984586

Epoch: 5| Step: 2
Training loss: 2.0741701126098633
Validation loss: 1.9897542807363695

Epoch: 5| Step: 3
Training loss: 1.753980040550232
Validation loss: 2.003463706662578

Epoch: 5| Step: 4
Training loss: 2.7746431827545166
Validation loss: 2.0148689208492154

Epoch: 5| Step: 5
Training loss: 2.5049331188201904
Validation loss: 2.0356271984756633

Epoch: 5| Step: 6
Training loss: 2.4012794494628906
Validation loss: 2.0523946362157024

Epoch: 5| Step: 7
Training loss: 2.433946132659912
Validation loss: 2.0713554479742564

Epoch: 5| Step: 8
Training loss: 1.6397640705108643
Validation loss: 2.0855153068419425

Epoch: 5| Step: 9
Training loss: 2.1965725421905518
Validation loss: 2.0831741184316654

Epoch: 5| Step: 10
Training loss: 2.2361669540405273
Validation loss: 2.0611613796603296

Epoch: 131| Step: 0
Training loss: 2.080479145050049
Validation loss: 2.032460105034613

Epoch: 5| Step: 1
Training loss: 2.9080405235290527
Validation loss: 2.01520679073949

Epoch: 5| Step: 2
Training loss: 1.9220983982086182
Validation loss: 1.9884778017638831

Epoch: 5| Step: 3
Training loss: 1.8282188177108765
Validation loss: 1.9879274214467695

Epoch: 5| Step: 4
Training loss: 2.428823947906494
Validation loss: 1.9894873160187916

Epoch: 5| Step: 5
Training loss: 1.41945481300354
Validation loss: 2.0015536662070983

Epoch: 5| Step: 6
Training loss: 2.287428379058838
Validation loss: 1.993254873060411

Epoch: 5| Step: 7
Training loss: 2.4679906368255615
Validation loss: 2.0039347089746946

Epoch: 5| Step: 8
Training loss: 2.8440635204315186
Validation loss: 2.036748481053178

Epoch: 5| Step: 9
Training loss: 2.2089591026306152
Validation loss: 2.057357582994687

Epoch: 5| Step: 10
Training loss: 2.2505860328674316
Validation loss: 2.0711010450957925

Epoch: 132| Step: 0
Training loss: 1.8455654382705688
Validation loss: 2.089135763465717

Epoch: 5| Step: 1
Training loss: 2.559309482574463
Validation loss: 2.0885607145165883

Epoch: 5| Step: 2
Training loss: 2.158627986907959
Validation loss: 2.0918146359023226

Epoch: 5| Step: 3
Training loss: 2.148428440093994
Validation loss: 2.075006418330695

Epoch: 5| Step: 4
Training loss: 2.381284713745117
Validation loss: 2.067078350692667

Epoch: 5| Step: 5
Training loss: 2.1566429138183594
Validation loss: 2.0522192678143902

Epoch: 5| Step: 6
Training loss: 2.488337993621826
Validation loss: 2.030191509954391

Epoch: 5| Step: 7
Training loss: 2.276364803314209
Validation loss: 2.0087419863670104

Epoch: 5| Step: 8
Training loss: 2.2266013622283936
Validation loss: 1.9990753102046188

Epoch: 5| Step: 9
Training loss: 2.3708653450012207
Validation loss: 1.9895714444498862

Epoch: 5| Step: 10
Training loss: 2.124717950820923
Validation loss: 1.981374861091696

Epoch: 133| Step: 0
Training loss: 1.5695387125015259
Validation loss: 1.9776495323386243

Epoch: 5| Step: 1
Training loss: 2.9348697662353516
Validation loss: 1.980482393695462

Epoch: 5| Step: 2
Training loss: 1.998018503189087
Validation loss: 1.977114503101636

Epoch: 5| Step: 3
Training loss: 2.7105746269226074
Validation loss: 1.9736454563756143

Epoch: 5| Step: 4
Training loss: 2.3796074390411377
Validation loss: 1.9719389587320306

Epoch: 5| Step: 5
Training loss: 2.1567697525024414
Validation loss: 1.9748505738473707

Epoch: 5| Step: 6
Training loss: 2.052502393722534
Validation loss: 1.991743254405196

Epoch: 5| Step: 7
Training loss: 2.177450180053711
Validation loss: 1.9864670794497254

Epoch: 5| Step: 8
Training loss: 1.825549840927124
Validation loss: 2.003021809362596

Epoch: 5| Step: 9
Training loss: 2.0318758487701416
Validation loss: 2.017864465713501

Epoch: 5| Step: 10
Training loss: 2.704629898071289
Validation loss: 2.033103609597811

Epoch: 134| Step: 0
Training loss: 2.1029529571533203
Validation loss: 2.044173662380506

Epoch: 5| Step: 1
Training loss: 2.166417360305786
Validation loss: 2.0625620913761917

Epoch: 5| Step: 2
Training loss: 2.4856419563293457
Validation loss: 2.0807614198295017

Epoch: 5| Step: 3
Training loss: 1.9888999462127686
Validation loss: 2.083453022023683

Epoch: 5| Step: 4
Training loss: 1.8923801183700562
Validation loss: 2.087839970024683

Epoch: 5| Step: 5
Training loss: 1.7790024280548096
Validation loss: 2.0653745628172353

Epoch: 5| Step: 6
Training loss: 2.882627010345459
Validation loss: 2.028759769214097

Epoch: 5| Step: 7
Training loss: 2.1561553478240967
Validation loss: 2.015511771684052

Epoch: 5| Step: 8
Training loss: 2.4343414306640625
Validation loss: 2.003518563444896

Epoch: 5| Step: 9
Training loss: 2.361868381500244
Validation loss: 1.9967306685704056

Epoch: 5| Step: 10
Training loss: 2.580352783203125
Validation loss: 1.9899353801563222

Epoch: 135| Step: 0
Training loss: 2.6816508769989014
Validation loss: 2.0008311938214045

Epoch: 5| Step: 1
Training loss: 2.0595202445983887
Validation loss: 1.9916408677254953

Epoch: 5| Step: 2
Training loss: 1.8506698608398438
Validation loss: 1.9885133620231383

Epoch: 5| Step: 3
Training loss: 2.2778372764587402
Validation loss: 1.9966794752305554

Epoch: 5| Step: 4
Training loss: 2.5798614025115967
Validation loss: 2.0042172170454458

Epoch: 5| Step: 5
Training loss: 2.4358439445495605
Validation loss: 2.0101874823211343

Epoch: 5| Step: 6
Training loss: 2.167177677154541
Validation loss: 2.0210509428413967

Epoch: 5| Step: 7
Training loss: 1.8060951232910156
Validation loss: 2.0223615759162494

Epoch: 5| Step: 8
Training loss: 2.5331978797912598
Validation loss: 2.0429660863773798

Epoch: 5| Step: 9
Training loss: 2.2257633209228516
Validation loss: 2.0432296414529123

Epoch: 5| Step: 10
Training loss: 2.0511722564697266
Validation loss: 2.042369314419326

Epoch: 136| Step: 0
Training loss: 2.221707344055176
Validation loss: 2.069454394361024

Epoch: 5| Step: 1
Training loss: 2.071535587310791
Validation loss: 2.076041752292264

Epoch: 5| Step: 2
Training loss: 2.360757350921631
Validation loss: 2.092888924383348

Epoch: 5| Step: 3
Training loss: 2.527458429336548
Validation loss: 2.074839202306604

Epoch: 5| Step: 4
Training loss: 1.6012516021728516
Validation loss: 2.0665533286268993

Epoch: 5| Step: 5
Training loss: 2.625185489654541
Validation loss: 2.061138815777276

Epoch: 5| Step: 6
Training loss: 2.5633292198181152
Validation loss: 2.046100369063757

Epoch: 5| Step: 7
Training loss: 2.3464629650115967
Validation loss: 2.0421965660587436

Epoch: 5| Step: 8
Training loss: 2.0091445446014404
Validation loss: 2.0373635407417052

Epoch: 5| Step: 9
Training loss: 2.3399271965026855
Validation loss: 2.034512896691599

Epoch: 5| Step: 10
Training loss: 1.7752240896224976
Validation loss: 2.0143485966549126

Epoch: 137| Step: 0
Training loss: 1.626818299293518
Validation loss: 2.0086740421992477

Epoch: 5| Step: 1
Training loss: 2.3914403915405273
Validation loss: 1.9968343787295844

Epoch: 5| Step: 2
Training loss: 2.8284780979156494
Validation loss: 1.9957336533454157

Epoch: 5| Step: 3
Training loss: 1.8049976825714111
Validation loss: 1.9907903491809804

Epoch: 5| Step: 4
Training loss: 2.444309949874878
Validation loss: 1.992339095761699

Epoch: 5| Step: 5
Training loss: 2.4403932094573975
Validation loss: 1.9914408806831605

Epoch: 5| Step: 6
Training loss: 2.375211477279663
Validation loss: 1.993056115283761

Epoch: 5| Step: 7
Training loss: 1.964220404624939
Validation loss: 2.0142371757056123

Epoch: 5| Step: 8
Training loss: 2.070667266845703
Validation loss: 2.034461977661297

Epoch: 5| Step: 9
Training loss: 2.2994208335876465
Validation loss: 2.063002044154752

Epoch: 5| Step: 10
Training loss: 2.1513426303863525
Validation loss: 2.035572123783891

Epoch: 138| Step: 0
Training loss: 2.261747121810913
Validation loss: 2.0168154367836575

Epoch: 5| Step: 1
Training loss: 2.471501350402832
Validation loss: 1.989256553752448

Epoch: 5| Step: 2
Training loss: 2.2745065689086914
Validation loss: 1.9828785683519097

Epoch: 5| Step: 3
Training loss: 2.6763248443603516
Validation loss: 1.9851474787599297

Epoch: 5| Step: 4
Training loss: 1.9785114526748657
Validation loss: 1.9847312870846

Epoch: 5| Step: 5
Training loss: 2.1365809440612793
Validation loss: 1.9927350744124381

Epoch: 5| Step: 6
Training loss: 1.7446399927139282
Validation loss: 1.9887578513032647

Epoch: 5| Step: 7
Training loss: 1.8765335083007812
Validation loss: 2.0068761558942896

Epoch: 5| Step: 8
Training loss: 1.8496835231781006
Validation loss: 2.041973234504782

Epoch: 5| Step: 9
Training loss: 2.4993858337402344
Validation loss: 2.0586144949800227

Epoch: 5| Step: 10
Training loss: 2.354668378829956
Validation loss: 2.10038467761009

Epoch: 139| Step: 0
Training loss: 2.695250988006592
Validation loss: 2.1190865629462787

Epoch: 5| Step: 1
Training loss: 2.278197765350342
Validation loss: 2.1041426197175057

Epoch: 5| Step: 2
Training loss: 1.6066592931747437
Validation loss: 2.0913517064945673

Epoch: 5| Step: 3
Training loss: 2.339085340499878
Validation loss: 2.069199647954715

Epoch: 5| Step: 4
Training loss: 1.7334868907928467
Validation loss: 2.0502496611687446

Epoch: 5| Step: 5
Training loss: 2.353764295578003
Validation loss: 2.037846521664691

Epoch: 5| Step: 6
Training loss: 2.2608494758605957
Validation loss: 2.0395827652305685

Epoch: 5| Step: 7
Training loss: 2.531832218170166
Validation loss: 2.022365172704061

Epoch: 5| Step: 8
Training loss: 2.2831532955169678
Validation loss: 2.017243141769081

Epoch: 5| Step: 9
Training loss: 1.8821338415145874
Validation loss: 2.01819807739668

Epoch: 5| Step: 10
Training loss: 2.3639841079711914
Validation loss: 2.012036910621069

Epoch: 140| Step: 0
Training loss: 1.8094030618667603
Validation loss: 1.9992312487735544

Epoch: 5| Step: 1
Training loss: 2.089344024658203
Validation loss: 2.0029718927157822

Epoch: 5| Step: 2
Training loss: 2.751655101776123
Validation loss: 2.011825528196109

Epoch: 5| Step: 3
Training loss: 2.6455912590026855
Validation loss: 2.035700677543558

Epoch: 5| Step: 4
Training loss: 2.4987633228302
Validation loss: 2.0566761365500827

Epoch: 5| Step: 5
Training loss: 1.9567792415618896
Validation loss: 2.0791441112436275

Epoch: 5| Step: 6
Training loss: 1.4351335763931274
Validation loss: 2.078413824881277

Epoch: 5| Step: 7
Training loss: 2.4089386463165283
Validation loss: 2.089388962714903

Epoch: 5| Step: 8
Training loss: 2.6847825050354004
Validation loss: 2.096015949403086

Epoch: 5| Step: 9
Training loss: 1.46052885055542
Validation loss: 2.069995508399061

Epoch: 5| Step: 10
Training loss: 2.294327974319458
Validation loss: 2.039532930620255

Epoch: 141| Step: 0
Training loss: 2.5184905529022217
Validation loss: 2.0230003761988815

Epoch: 5| Step: 1
Training loss: 2.3584847450256348
Validation loss: 2.0238901697179323

Epoch: 5| Step: 2
Training loss: 2.472245454788208
Validation loss: 2.029922285387593

Epoch: 5| Step: 3
Training loss: 1.9980056285858154
Validation loss: 2.0242280088445193

Epoch: 5| Step: 4
Training loss: 1.7765305042266846
Validation loss: 2.021351636096995

Epoch: 5| Step: 5
Training loss: 2.3914389610290527
Validation loss: 2.0226166248321533

Epoch: 5| Step: 6
Training loss: 1.6326777935028076
Validation loss: 2.0290434501504384

Epoch: 5| Step: 7
Training loss: 1.5943577289581299
Validation loss: 2.0055519509059128

Epoch: 5| Step: 8
Training loss: 2.6095499992370605
Validation loss: 2.019240438297231

Epoch: 5| Step: 9
Training loss: 2.4226582050323486
Validation loss: 2.052939468814481

Epoch: 5| Step: 10
Training loss: 2.1412575244903564
Validation loss: 2.0887397104693997

Epoch: 142| Step: 0
Training loss: 2.248599052429199
Validation loss: 2.1309741620094544

Epoch: 5| Step: 1
Training loss: 2.981417179107666
Validation loss: 2.142147833301175

Epoch: 5| Step: 2
Training loss: 2.374931573867798
Validation loss: 2.130005692922941

Epoch: 5| Step: 3
Training loss: 1.7482150793075562
Validation loss: 2.1095448950285554

Epoch: 5| Step: 4
Training loss: 1.7042843103408813
Validation loss: 2.075675672100436

Epoch: 5| Step: 5
Training loss: 1.985372543334961
Validation loss: 2.0464579418141353

Epoch: 5| Step: 6
Training loss: 2.081085681915283
Validation loss: 2.032958981811359

Epoch: 5| Step: 7
Training loss: 2.4976089000701904
Validation loss: 2.016087930689576

Epoch: 5| Step: 8
Training loss: 2.3615870475769043
Validation loss: 2.014928553694038

Epoch: 5| Step: 9
Training loss: 2.056178569793701
Validation loss: 2.018553762025731

Epoch: 5| Step: 10
Training loss: 1.861702799797058
Validation loss: 2.024092096154408

Epoch: 143| Step: 0
Training loss: 1.7794125080108643
Validation loss: 2.021212341964886

Epoch: 5| Step: 1
Training loss: 2.3054728507995605
Validation loss: 2.0073585215435235

Epoch: 5| Step: 2
Training loss: 2.320321798324585
Validation loss: 2.0111671724627094

Epoch: 5| Step: 3
Training loss: 1.9721183776855469
Validation loss: 2.010699946393249

Epoch: 5| Step: 4
Training loss: 2.719986915588379
Validation loss: 2.0050942949069444

Epoch: 5| Step: 5
Training loss: 2.5358686447143555
Validation loss: 1.9989141418087868

Epoch: 5| Step: 6
Training loss: 1.847360610961914
Validation loss: 2.0151050321517454

Epoch: 5| Step: 7
Training loss: 1.719125747680664
Validation loss: 2.02679157000716

Epoch: 5| Step: 8
Training loss: 2.2671103477478027
Validation loss: 2.0352925562089488

Epoch: 5| Step: 9
Training loss: 1.9706470966339111
Validation loss: 2.039876268756005

Epoch: 5| Step: 10
Training loss: 2.3488473892211914
Validation loss: 2.04925960622808

Epoch: 144| Step: 0
Training loss: 2.1592278480529785
Validation loss: 2.0248725491185344

Epoch: 5| Step: 1
Training loss: 2.4579086303710938
Validation loss: 2.040038788190452

Epoch: 5| Step: 2
Training loss: 1.9452314376831055
Validation loss: 2.050604466469057

Epoch: 5| Step: 3
Training loss: 1.8829114437103271
Validation loss: 2.0471516988610707

Epoch: 5| Step: 4
Training loss: 2.2812371253967285
Validation loss: 2.0294961557593396

Epoch: 5| Step: 5
Training loss: 2.350461959838867
Validation loss: 2.0108398327263455

Epoch: 5| Step: 6
Training loss: 1.9598970413208008
Validation loss: 1.9955577106886013

Epoch: 5| Step: 7
Training loss: 2.2534821033477783
Validation loss: 1.9939192879584529

Epoch: 5| Step: 8
Training loss: 2.1701064109802246
Validation loss: 1.992666611107447

Epoch: 5| Step: 9
Training loss: 1.8283754587173462
Validation loss: 2.007099797648768

Epoch: 5| Step: 10
Training loss: 2.223588228225708
Validation loss: 2.017957395122897

Epoch: 145| Step: 0
Training loss: 1.5555503368377686
Validation loss: 2.0411997841250513

Epoch: 5| Step: 1
Training loss: 2.908573865890503
Validation loss: 2.0572570164998374

Epoch: 5| Step: 2
Training loss: 2.3519845008850098
Validation loss: 2.0617836316426597

Epoch: 5| Step: 3
Training loss: 1.4023644924163818
Validation loss: 2.0671865735002743

Epoch: 5| Step: 4
Training loss: 1.4811947345733643
Validation loss: 2.0520029349993636

Epoch: 5| Step: 5
Training loss: 2.0139966011047363
Validation loss: 2.041132917968176

Epoch: 5| Step: 6
Training loss: 2.7101757526397705
Validation loss: 2.0255569360589467

Epoch: 5| Step: 7
Training loss: 2.390925884246826
Validation loss: 2.0153640829106814

Epoch: 5| Step: 8
Training loss: 2.745420217514038
Validation loss: 2.00197918440706

Epoch: 5| Step: 9
Training loss: 1.7567390203475952
Validation loss: 2.013168599015923

Epoch: 5| Step: 10
Training loss: 2.1613235473632812
Validation loss: 2.0385437703901723

Epoch: 146| Step: 0
Training loss: 2.4911131858825684
Validation loss: 2.061625152505854

Epoch: 5| Step: 1
Training loss: 2.6275217533111572
Validation loss: 2.0690497634231404

Epoch: 5| Step: 2
Training loss: 2.2575409412384033
Validation loss: 2.1017427239366757

Epoch: 5| Step: 3
Training loss: 2.1309218406677246
Validation loss: 2.096225639825226

Epoch: 5| Step: 4
Training loss: 2.5333504676818848
Validation loss: 2.080765055071923

Epoch: 5| Step: 5
Training loss: 2.0510101318359375
Validation loss: 2.020168083970265

Epoch: 5| Step: 6
Training loss: 1.9290632009506226
Validation loss: 2.0001111876580024

Epoch: 5| Step: 7
Training loss: 1.9008458852767944
Validation loss: 1.9919581349178026

Epoch: 5| Step: 8
Training loss: 1.9115715026855469
Validation loss: 1.9986143663365354

Epoch: 5| Step: 9
Training loss: 1.913076400756836
Validation loss: 2.006565915640964

Epoch: 5| Step: 10
Training loss: 2.1011734008789062
Validation loss: 2.0232053533677132

Epoch: 147| Step: 0
Training loss: 2.1637468338012695
Validation loss: 2.022039847989236

Epoch: 5| Step: 1
Training loss: 1.8364626169204712
Validation loss: 2.0141445385512484

Epoch: 5| Step: 2
Training loss: 2.6235804557800293
Validation loss: 2.0063762305885233

Epoch: 5| Step: 3
Training loss: 2.0846517086029053
Validation loss: 1.9970754179903256

Epoch: 5| Step: 4
Training loss: 1.8715603351593018
Validation loss: 1.9903309806700675

Epoch: 5| Step: 5
Training loss: 2.45074462890625
Validation loss: 1.9980816815489082

Epoch: 5| Step: 6
Training loss: 2.7919955253601074
Validation loss: 2.0238123452791603

Epoch: 5| Step: 7
Training loss: 1.9424461126327515
Validation loss: 2.0172370992681032

Epoch: 5| Step: 8
Training loss: 2.1166584491729736
Validation loss: 2.0233925721978627

Epoch: 5| Step: 9
Training loss: 2.1307995319366455
Validation loss: 2.0155195805334274

Epoch: 5| Step: 10
Training loss: 1.7201327085494995
Validation loss: 2.035290361732565

Epoch: 148| Step: 0
Training loss: 2.1607348918914795
Validation loss: 2.04512676500505

Epoch: 5| Step: 1
Training loss: 2.2784411907196045
Validation loss: 2.054785382363104

Epoch: 5| Step: 2
Training loss: 2.1461341381073
Validation loss: 2.055797533322406

Epoch: 5| Step: 3
Training loss: 2.4405388832092285
Validation loss: 2.04939176190284

Epoch: 5| Step: 4
Training loss: 1.7602825164794922
Validation loss: 2.039223260776971

Epoch: 5| Step: 5
Training loss: 2.639723300933838
Validation loss: 2.021944429284783

Epoch: 5| Step: 6
Training loss: 1.8445218801498413
Validation loss: 2.015718326773695

Epoch: 5| Step: 7
Training loss: 2.001983404159546
Validation loss: 2.025979341999177

Epoch: 5| Step: 8
Training loss: 1.5564543008804321
Validation loss: 2.012552458752868

Epoch: 5| Step: 9
Training loss: 1.8838657140731812
Validation loss: 2.01596309292701

Epoch: 5| Step: 10
Training loss: 2.562985420227051
Validation loss: 2.0304637621807795

Epoch: 149| Step: 0
Training loss: 1.7105869054794312
Validation loss: 2.056798865718226

Epoch: 5| Step: 1
Training loss: 2.6315701007843018
Validation loss: 2.086395873818346

Epoch: 5| Step: 2
Training loss: 2.4025256633758545
Validation loss: 2.066056131034769

Epoch: 5| Step: 3
Training loss: 2.8956472873687744
Validation loss: 2.0510476635348414

Epoch: 5| Step: 4
Training loss: 2.3278117179870605
Validation loss: 2.055586673880136

Epoch: 5| Step: 5
Training loss: 1.7901499271392822
Validation loss: 2.048243999481201

Epoch: 5| Step: 6
Training loss: 1.6364772319793701
Validation loss: 2.0432782352611585

Epoch: 5| Step: 7
Training loss: 1.6380300521850586
Validation loss: 2.028909358926999

Epoch: 5| Step: 8
Training loss: 1.8468959331512451
Validation loss: 2.0271052263116323

Epoch: 5| Step: 9
Training loss: 1.9978828430175781
Validation loss: 2.028588439828606

Epoch: 5| Step: 10
Training loss: 2.5650668144226074
Validation loss: 2.0196913596122497

Epoch: 150| Step: 0
Training loss: 2.4789793491363525
Validation loss: 2.037953597243114

Epoch: 5| Step: 1
Training loss: 1.9622291326522827
Validation loss: 2.0541284622684604

Epoch: 5| Step: 2
Training loss: 2.023465156555176
Validation loss: 2.0599260740382697

Epoch: 5| Step: 3
Training loss: 2.842144727706909
Validation loss: 2.049471462926557

Epoch: 5| Step: 4
Training loss: 2.065093517303467
Validation loss: 2.0737300636947795

Epoch: 5| Step: 5
Training loss: 2.2740445137023926
Validation loss: 2.0758098684331423

Epoch: 5| Step: 6
Training loss: 2.4381823539733887
Validation loss: 2.0803999746999433

Epoch: 5| Step: 7
Training loss: 2.0613789558410645
Validation loss: 2.0981510454608547

Epoch: 5| Step: 8
Training loss: 1.4458568096160889
Validation loss: 2.0779927417796147

Epoch: 5| Step: 9
Training loss: 1.8067817687988281
Validation loss: 2.0719613708475584

Epoch: 5| Step: 10
Training loss: 1.9976623058319092
Validation loss: 2.046793888973933

Epoch: 151| Step: 0
Training loss: 2.5425803661346436
Validation loss: 2.0227295737112723

Epoch: 5| Step: 1
Training loss: 2.4762864112854004
Validation loss: 2.02213728556069

Epoch: 5| Step: 2
Training loss: 1.7436103820800781
Validation loss: 2.0325988313203216

Epoch: 5| Step: 3
Training loss: 2.129014253616333
Validation loss: 2.0283520375528643

Epoch: 5| Step: 4
Training loss: 2.3223273754119873
Validation loss: 2.026782165291489

Epoch: 5| Step: 5
Training loss: 2.022653102874756
Validation loss: 2.0089721730960313

Epoch: 5| Step: 6
Training loss: 2.0090785026550293
Validation loss: 2.005905005239671

Epoch: 5| Step: 7
Training loss: 1.7514574527740479
Validation loss: 2.006830125726679

Epoch: 5| Step: 8
Training loss: 2.2094407081604004
Validation loss: 2.003000097890054

Epoch: 5| Step: 9
Training loss: 1.7501646280288696
Validation loss: 2.0101181666056314

Epoch: 5| Step: 10
Training loss: 2.0524277687072754
Validation loss: 2.014049417229109

Epoch: 152| Step: 0
Training loss: 1.5125254392623901
Validation loss: 2.038131252411873

Epoch: 5| Step: 1
Training loss: 2.557054281234741
Validation loss: 2.044558050811932

Epoch: 5| Step: 2
Training loss: 1.8094695806503296
Validation loss: 2.036582181530614

Epoch: 5| Step: 3
Training loss: 2.5555920600891113
Validation loss: 2.0221283487094346

Epoch: 5| Step: 4
Training loss: 1.288116216659546
Validation loss: 2.014358664071688

Epoch: 5| Step: 5
Training loss: 2.4079182147979736
Validation loss: 2.0153867019120084

Epoch: 5| Step: 6
Training loss: 2.4493777751922607
Validation loss: 2.0193359646745908

Epoch: 5| Step: 7
Training loss: 1.9854446649551392
Validation loss: 2.0247126112702074

Epoch: 5| Step: 8
Training loss: 2.1248421669006348
Validation loss: 2.0333418333402244

Epoch: 5| Step: 9
Training loss: 2.564232349395752
Validation loss: 2.018648491110853

Epoch: 5| Step: 10
Training loss: 1.9691953659057617
Validation loss: 2.001802421385242

Epoch: 153| Step: 0
Training loss: 2.243011474609375
Validation loss: 1.9977731140710975

Epoch: 5| Step: 1
Training loss: 2.3570785522460938
Validation loss: 1.9954872131347656

Epoch: 5| Step: 2
Training loss: 2.3912243843078613
Validation loss: 2.0004437021029893

Epoch: 5| Step: 3
Training loss: 1.5738641023635864
Validation loss: 2.0213741153799076

Epoch: 5| Step: 4
Training loss: 2.417296886444092
Validation loss: 2.065177822625765

Epoch: 5| Step: 5
Training loss: 2.444295644760132
Validation loss: 2.0713532663160756

Epoch: 5| Step: 6
Training loss: 1.6345970630645752
Validation loss: 2.084249242659538

Epoch: 5| Step: 7
Training loss: 2.4570789337158203
Validation loss: 2.060139151029689

Epoch: 5| Step: 8
Training loss: 2.3773369789123535
Validation loss: 2.036404117461174

Epoch: 5| Step: 9
Training loss: 2.1646170616149902
Validation loss: 2.0489278160115725

Epoch: 5| Step: 10
Training loss: 0.994152307510376
Validation loss: 2.0764219965986026

Epoch: 154| Step: 0
Training loss: 2.1063601970672607
Validation loss: 2.0964227517445884

Epoch: 5| Step: 1
Training loss: 2.221061944961548
Validation loss: 2.1084319686376922

Epoch: 5| Step: 2
Training loss: 2.0941925048828125
Validation loss: 2.1621765244391655

Epoch: 5| Step: 3
Training loss: 2.537160873413086
Validation loss: 2.1900763024565992

Epoch: 5| Step: 4
Training loss: 2.0940983295440674
Validation loss: 2.1668365155496905

Epoch: 5| Step: 5
Training loss: 2.404773712158203
Validation loss: 2.141188666384707

Epoch: 5| Step: 6
Training loss: 2.227724075317383
Validation loss: 2.100510685674606

Epoch: 5| Step: 7
Training loss: 2.1668057441711426
Validation loss: 2.0721243107190697

Epoch: 5| Step: 8
Training loss: 1.994907021522522
Validation loss: 2.0486943542316394

Epoch: 5| Step: 9
Training loss: 1.8438984155654907
Validation loss: 2.0451161528146393

Epoch: 5| Step: 10
Training loss: 1.8898003101348877
Validation loss: 2.0776643419778473

Epoch: 155| Step: 0
Training loss: 1.9962654113769531
Validation loss: 2.117207033659822

Epoch: 5| Step: 1
Training loss: 2.3240725994110107
Validation loss: 2.1463776429494223

Epoch: 5| Step: 2
Training loss: 1.9204353094100952
Validation loss: 2.1535286608562676

Epoch: 5| Step: 3
Training loss: 2.1107559204101562
Validation loss: 2.1634797767926286

Epoch: 5| Step: 4
Training loss: 2.645252227783203
Validation loss: 2.1244137184594267

Epoch: 5| Step: 5
Training loss: 2.6001200675964355
Validation loss: 2.091759330482893

Epoch: 5| Step: 6
Training loss: 2.163750171661377
Validation loss: 2.045404088112616

Epoch: 5| Step: 7
Training loss: 2.1245193481445312
Validation loss: 2.025268268841569

Epoch: 5| Step: 8
Training loss: 1.62161386013031
Validation loss: 2.019400583800449

Epoch: 5| Step: 9
Training loss: 2.117885112762451
Validation loss: 2.0305275045415407

Epoch: 5| Step: 10
Training loss: 2.009333610534668
Validation loss: 2.043958253757928

Epoch: 156| Step: 0
Training loss: 2.2932960987091064
Validation loss: 2.058977016838648

Epoch: 5| Step: 1
Training loss: 2.6617300510406494
Validation loss: 2.097269247936946

Epoch: 5| Step: 2
Training loss: 2.400010585784912
Validation loss: 2.1479051959130073

Epoch: 5| Step: 3
Training loss: 1.624518632888794
Validation loss: 2.1816978146952968

Epoch: 5| Step: 4
Training loss: 2.5749080181121826
Validation loss: 2.187279165432017

Epoch: 5| Step: 5
Training loss: 2.2102367877960205
Validation loss: 2.1772662003835044

Epoch: 5| Step: 6
Training loss: 2.0240366458892822
Validation loss: 2.164919166154759

Epoch: 5| Step: 7
Training loss: 2.115515947341919
Validation loss: 2.1330220058400142

Epoch: 5| Step: 8
Training loss: 2.2851803302764893
Validation loss: 2.088136875501243

Epoch: 5| Step: 9
Training loss: 1.880110502243042
Validation loss: 2.0805747432093464

Epoch: 5| Step: 10
Training loss: 2.0510518550872803
Validation loss: 2.081489943688916

Epoch: 157| Step: 0
Training loss: 1.7850120067596436
Validation loss: 2.077446785024417

Epoch: 5| Step: 1
Training loss: 2.5998008251190186
Validation loss: 2.0802286363417104

Epoch: 5| Step: 2
Training loss: 1.8931916952133179
Validation loss: 2.0821256278663554

Epoch: 5| Step: 3
Training loss: 1.7313432693481445
Validation loss: 2.0786189648412887

Epoch: 5| Step: 4
Training loss: 2.2264270782470703
Validation loss: 2.0465553076036516

Epoch: 5| Step: 5
Training loss: 1.7706149816513062
Validation loss: 2.0472548571966027

Epoch: 5| Step: 6
Training loss: 2.194749355316162
Validation loss: 2.0468601539570797

Epoch: 5| Step: 7
Training loss: 3.0145668983459473
Validation loss: 2.0483903474705194

Epoch: 5| Step: 8
Training loss: 2.0032198429107666
Validation loss: 2.0408931521959204

Epoch: 5| Step: 9
Training loss: 1.7943559885025024
Validation loss: 2.049297268672656

Epoch: 5| Step: 10
Training loss: 2.1489078998565674
Validation loss: 2.060663834694893

Epoch: 158| Step: 0
Training loss: 1.606419563293457
Validation loss: 2.0557190308006863

Epoch: 5| Step: 1
Training loss: 2.495246410369873
Validation loss: 2.051893590598978

Epoch: 5| Step: 2
Training loss: 2.642462968826294
Validation loss: 2.043736078405893

Epoch: 5| Step: 3
Training loss: 2.3603885173797607
Validation loss: 2.0540075994306997

Epoch: 5| Step: 4
Training loss: 1.7278438806533813
Validation loss: 2.053677169225549

Epoch: 5| Step: 5
Training loss: 2.5271084308624268
Validation loss: 2.0596905241730394

Epoch: 5| Step: 6
Training loss: 1.638655424118042
Validation loss: 2.062937496810831

Epoch: 5| Step: 7
Training loss: 2.0451340675354004
Validation loss: 2.0610014097664946

Epoch: 5| Step: 8
Training loss: 1.6335077285766602
Validation loss: 2.0503584672045965

Epoch: 5| Step: 9
Training loss: 2.237525224685669
Validation loss: 2.0457132157459053

Epoch: 5| Step: 10
Training loss: 2.2267603874206543
Validation loss: 2.0382015320562545

Epoch: 159| Step: 0
Training loss: 2.487215042114258
Validation loss: 2.030036049504434

Epoch: 5| Step: 1
Training loss: 1.9355090856552124
Validation loss: 2.031043001400527

Epoch: 5| Step: 2
Training loss: 2.0672075748443604
Validation loss: 2.044780223600326

Epoch: 5| Step: 3
Training loss: 2.2464029788970947
Validation loss: 2.0466905486199165

Epoch: 5| Step: 4
Training loss: 1.6318256855010986
Validation loss: 2.043361884291454

Epoch: 5| Step: 5
Training loss: 2.1601531505584717
Validation loss: 2.044656712521789

Epoch: 5| Step: 6
Training loss: 2.1566174030303955
Validation loss: 2.0592959260427826

Epoch: 5| Step: 7
Training loss: 2.1254048347473145
Validation loss: 2.058160020459083

Epoch: 5| Step: 8
Training loss: 2.2642617225646973
Validation loss: 2.059069682193059

Epoch: 5| Step: 9
Training loss: 2.2108187675476074
Validation loss: 2.0735829978860836

Epoch: 5| Step: 10
Training loss: 1.3752845525741577
Validation loss: 2.0717528866183375

Epoch: 160| Step: 0
Training loss: 1.4791393280029297
Validation loss: 2.075595155838997

Epoch: 5| Step: 1
Training loss: 1.8789145946502686
Validation loss: 2.0835318565368652

Epoch: 5| Step: 2
Training loss: 2.4751811027526855
Validation loss: 2.1107975693159204

Epoch: 5| Step: 3
Training loss: 2.4330220222473145
Validation loss: 2.118865771960187

Epoch: 5| Step: 4
Training loss: 1.9560420513153076
Validation loss: 2.1219849330122753

Epoch: 5| Step: 5
Training loss: 1.7958269119262695
Validation loss: 2.0815639188212733

Epoch: 5| Step: 6
Training loss: 2.7640328407287598
Validation loss: 2.046533748667727

Epoch: 5| Step: 7
Training loss: 1.8968833684921265
Validation loss: 2.0343066005296606

Epoch: 5| Step: 8
Training loss: 2.265561580657959
Validation loss: 2.0485418560684368

Epoch: 5| Step: 9
Training loss: 1.8697659969329834
Validation loss: 2.048320544663296

Epoch: 5| Step: 10
Training loss: 1.9592924118041992
Validation loss: 2.038391725991362

Epoch: 161| Step: 0
Training loss: 1.919232964515686
Validation loss: 2.0391419728597007

Epoch: 5| Step: 1
Training loss: 1.941346526145935
Validation loss: 2.033881641203357

Epoch: 5| Step: 2
Training loss: 2.416855812072754
Validation loss: 2.0191106821901057

Epoch: 5| Step: 3
Training loss: 2.198741912841797
Validation loss: 2.0144870614492767

Epoch: 5| Step: 4
Training loss: 1.9170383214950562
Validation loss: 1.9953923251039238

Epoch: 5| Step: 5
Training loss: 2.2022738456726074
Validation loss: 1.9979011371571531

Epoch: 5| Step: 6
Training loss: 1.992349624633789
Validation loss: 2.001545488193471

Epoch: 5| Step: 7
Training loss: 1.8905893564224243
Validation loss: 2.0385093483873593

Epoch: 5| Step: 8
Training loss: 2.1716561317443848
Validation loss: 2.073481426444105

Epoch: 5| Step: 9
Training loss: 2.3193230628967285
Validation loss: 2.100248602128798

Epoch: 5| Step: 10
Training loss: 2.0136003494262695
Validation loss: 2.120560223056424

Epoch: 162| Step: 0
Training loss: 1.3619701862335205
Validation loss: 2.0975609556321175

Epoch: 5| Step: 1
Training loss: 1.94353449344635
Validation loss: 2.0903332669247865

Epoch: 5| Step: 2
Training loss: 1.8952420949935913
Validation loss: 2.103156066709949

Epoch: 5| Step: 3
Training loss: 1.8023040294647217
Validation loss: 2.124578640025149

Epoch: 5| Step: 4
Training loss: 2.036033868789673
Validation loss: 2.1228653333520375

Epoch: 5| Step: 5
Training loss: 2.1862359046936035
Validation loss: 2.1225385665893555

Epoch: 5| Step: 6
Training loss: 1.7284284830093384
Validation loss: 2.11228810715419

Epoch: 5| Step: 7
Training loss: 2.330012798309326
Validation loss: 2.094158472553376

Epoch: 5| Step: 8
Training loss: 2.3499741554260254
Validation loss: 2.096117822072839

Epoch: 5| Step: 9
Training loss: 2.7143588066101074
Validation loss: 2.0762706700191704

Epoch: 5| Step: 10
Training loss: 2.078259229660034
Validation loss: 2.085781087157547

Epoch: 163| Step: 0
Training loss: 2.2241458892822266
Validation loss: 2.0853066931488695

Epoch: 5| Step: 1
Training loss: 1.8934061527252197
Validation loss: 2.080128597956832

Epoch: 5| Step: 2
Training loss: 1.2090848684310913
Validation loss: 2.081208480301724

Epoch: 5| Step: 3
Training loss: 2.0844576358795166
Validation loss: 2.0779117820083455

Epoch: 5| Step: 4
Training loss: 1.8780943155288696
Validation loss: 2.0827551862244964

Epoch: 5| Step: 5
Training loss: 2.258565902709961
Validation loss: 2.0739763987961637

Epoch: 5| Step: 6
Training loss: 2.011545419692993
Validation loss: 2.072769573939744

Epoch: 5| Step: 7
Training loss: 2.35663104057312
Validation loss: 2.084879421418713

Epoch: 5| Step: 8
Training loss: 1.8311271667480469
Validation loss: 2.0711052340845906

Epoch: 5| Step: 9
Training loss: 1.8756110668182373
Validation loss: 2.0607601929736394

Epoch: 5| Step: 10
Training loss: 2.5604517459869385
Validation loss: 2.073629363890617

Epoch: 164| Step: 0
Training loss: 1.9832077026367188
Validation loss: 2.0806818264786915

Epoch: 5| Step: 1
Training loss: 2.39479923248291
Validation loss: 2.09316837146718

Epoch: 5| Step: 2
Training loss: 1.7274097204208374
Validation loss: 2.07725429022184

Epoch: 5| Step: 3
Training loss: 1.4001485109329224
Validation loss: 2.093193631018362

Epoch: 5| Step: 4
Training loss: 1.9195029735565186
Validation loss: 2.092744964425282

Epoch: 5| Step: 5
Training loss: 1.4952147006988525
Validation loss: 2.0871133496684413

Epoch: 5| Step: 6
Training loss: 2.3304030895233154
Validation loss: 2.1114413379341044

Epoch: 5| Step: 7
Training loss: 2.0518250465393066
Validation loss: 2.087450319720853

Epoch: 5| Step: 8
Training loss: 2.7842345237731934
Validation loss: 2.06731395054889

Epoch: 5| Step: 9
Training loss: 2.1294703483581543
Validation loss: 2.042042137474142

Epoch: 5| Step: 10
Training loss: 1.9183944463729858
Validation loss: 2.038510307188957

Epoch: 165| Step: 0
Training loss: 2.0928468704223633
Validation loss: 2.051633514383788

Epoch: 5| Step: 1
Training loss: 1.629306435585022
Validation loss: 2.061739211441368

Epoch: 5| Step: 2
Training loss: 1.7165329456329346
Validation loss: 2.0582169922449256

Epoch: 5| Step: 3
Training loss: 1.5250917673110962
Validation loss: 2.0878534124743555

Epoch: 5| Step: 4
Training loss: 2.306978702545166
Validation loss: 2.083861029276284

Epoch: 5| Step: 5
Training loss: 2.0567264556884766
Validation loss: 2.100824063824069

Epoch: 5| Step: 6
Training loss: 1.8926700353622437
Validation loss: 2.1134353119839906

Epoch: 5| Step: 7
Training loss: 1.9213783740997314
Validation loss: 2.1214975708274433

Epoch: 5| Step: 8
Training loss: 2.4251511096954346
Validation loss: 2.153087172456967

Epoch: 5| Step: 9
Training loss: 2.2316370010375977
Validation loss: 2.130662206680544

Epoch: 5| Step: 10
Training loss: 2.0958919525146484
Validation loss: 2.095313467005248

Epoch: 166| Step: 0
Training loss: 1.7577279806137085
Validation loss: 2.0831467746406473

Epoch: 5| Step: 1
Training loss: 1.7102129459381104
Validation loss: 2.0619970880528933

Epoch: 5| Step: 2
Training loss: 2.4131767749786377
Validation loss: 2.0490582168743177

Epoch: 5| Step: 3
Training loss: 1.9603383541107178
Validation loss: 2.0519545873006186

Epoch: 5| Step: 4
Training loss: 2.569662570953369
Validation loss: 2.0544484507653022

Epoch: 5| Step: 5
Training loss: 1.6377769708633423
Validation loss: 2.0604119326478694

Epoch: 5| Step: 6
Training loss: 1.7993316650390625
Validation loss: 2.0741579019895164

Epoch: 5| Step: 7
Training loss: 2.1317172050476074
Validation loss: 2.0734761530353176

Epoch: 5| Step: 8
Training loss: 2.099863290786743
Validation loss: 2.0829580009624524

Epoch: 5| Step: 9
Training loss: 1.9468599557876587
Validation loss: 2.0676710272348053

Epoch: 5| Step: 10
Training loss: 1.8121682405471802
Validation loss: 2.0633095413125973

Epoch: 167| Step: 0
Training loss: 2.4089579582214355
Validation loss: 2.051080498644101

Epoch: 5| Step: 1
Training loss: 1.921425223350525
Validation loss: 2.0474895687513452

Epoch: 5| Step: 2
Training loss: 2.2011146545410156
Validation loss: 2.0513459585046254

Epoch: 5| Step: 3
Training loss: 2.1798157691955566
Validation loss: 2.0401739433247554

Epoch: 5| Step: 4
Training loss: 1.9144184589385986
Validation loss: 2.0409582994317494

Epoch: 5| Step: 5
Training loss: 2.000567674636841
Validation loss: 2.050914118366857

Epoch: 5| Step: 6
Training loss: 1.3134435415267944
Validation loss: 2.0449857609246367

Epoch: 5| Step: 7
Training loss: 1.6791473627090454
Validation loss: 2.0637663026009836

Epoch: 5| Step: 8
Training loss: 2.509770631790161
Validation loss: 2.0744143378350044

Epoch: 5| Step: 9
Training loss: 1.9469521045684814
Validation loss: 2.0744192959159933

Epoch: 5| Step: 10
Training loss: 1.4415847063064575
Validation loss: 2.0873718800083285

Epoch: 168| Step: 0
Training loss: 1.8016141653060913
Validation loss: 2.0961369532410816

Epoch: 5| Step: 1
Training loss: 1.8098499774932861
Validation loss: 2.081465650630254

Epoch: 5| Step: 2
Training loss: 1.9152851104736328
Validation loss: 2.0917958854347147

Epoch: 5| Step: 3
Training loss: 1.7291374206542969
Validation loss: 2.083941182782573

Epoch: 5| Step: 4
Training loss: 1.969626784324646
Validation loss: 2.0987431849202802

Epoch: 5| Step: 5
Training loss: 2.0515646934509277
Validation loss: 2.0901862677707466

Epoch: 5| Step: 6
Training loss: 2.1384596824645996
Validation loss: 2.084000797681911

Epoch: 5| Step: 7
Training loss: 1.2921785116195679
Validation loss: 2.0959058307832286

Epoch: 5| Step: 8
Training loss: 1.7841014862060547
Validation loss: 2.0883127707307056

Epoch: 5| Step: 9
Training loss: 2.2506279945373535
Validation loss: 2.089339424205083

Epoch: 5| Step: 10
Training loss: 2.6289730072021484
Validation loss: 2.113198226498019

Epoch: 169| Step: 0
Training loss: 1.6479381322860718
Validation loss: 2.1274623909304218

Epoch: 5| Step: 1
Training loss: 1.7917400598526
Validation loss: 2.1398343168279177

Epoch: 5| Step: 2
Training loss: 1.961200475692749
Validation loss: 2.1283950036571873

Epoch: 5| Step: 3
Training loss: 1.9649097919464111
Validation loss: 2.1151074696612615

Epoch: 5| Step: 4
Training loss: 2.717822551727295
Validation loss: 2.102787583105026

Epoch: 5| Step: 5
Training loss: 1.9918712377548218
Validation loss: 2.098792714457358

Epoch: 5| Step: 6
Training loss: 2.0681252479553223
Validation loss: 2.0726772585222797

Epoch: 5| Step: 7
Training loss: 2.166135311126709
Validation loss: 2.062639718414635

Epoch: 5| Step: 8
Training loss: 1.794490098953247
Validation loss: 2.0771805547898814

Epoch: 5| Step: 9
Training loss: 1.8701808452606201
Validation loss: 2.0551228677072833

Epoch: 5| Step: 10
Training loss: 1.6349003314971924
Validation loss: 2.065113603427846

Epoch: 170| Step: 0
Training loss: 1.5945035219192505
Validation loss: 2.0423293523890997

Epoch: 5| Step: 1
Training loss: 2.247459888458252
Validation loss: 2.034721807766986

Epoch: 5| Step: 2
Training loss: 1.991416573524475
Validation loss: 2.027194062868754

Epoch: 5| Step: 3
Training loss: 2.9269442558288574
Validation loss: 2.024586751896848

Epoch: 5| Step: 4
Training loss: 1.6914386749267578
Validation loss: 2.0338885399603073

Epoch: 5| Step: 5
Training loss: 1.7701539993286133
Validation loss: 2.0389100377277662

Epoch: 5| Step: 6
Training loss: 2.079618453979492
Validation loss: 2.058112739234842

Epoch: 5| Step: 7
Training loss: 1.7736101150512695
Validation loss: 2.0574943942408406

Epoch: 5| Step: 8
Training loss: 1.8704535961151123
Validation loss: 2.071479626881179

Epoch: 5| Step: 9
Training loss: 1.5733368396759033
Validation loss: 2.077678249728295

Epoch: 5| Step: 10
Training loss: 1.7842950820922852
Validation loss: 2.0719796457598285

Epoch: 171| Step: 0
Training loss: 1.758857011795044
Validation loss: 2.083893524703159

Epoch: 5| Step: 1
Training loss: 1.9949390888214111
Validation loss: 2.069847647861768

Epoch: 5| Step: 2
Training loss: 1.9602848291397095
Validation loss: 2.074541579010666

Epoch: 5| Step: 3
Training loss: 1.4958966970443726
Validation loss: 2.076812446758311

Epoch: 5| Step: 4
Training loss: 1.3217689990997314
Validation loss: 2.0774408912145965

Epoch: 5| Step: 5
Training loss: 1.9259777069091797
Validation loss: 2.064996155359412

Epoch: 5| Step: 6
Training loss: 1.546195387840271
Validation loss: 2.0681660124050674

Epoch: 5| Step: 7
Training loss: 2.2383086681365967
Validation loss: 2.066217362239797

Epoch: 5| Step: 8
Training loss: 1.988879919052124
Validation loss: 2.089053985893085

Epoch: 5| Step: 9
Training loss: 2.4359772205352783
Validation loss: 2.099609277581656

Epoch: 5| Step: 10
Training loss: 2.141512393951416
Validation loss: 2.118241169119394

Epoch: 172| Step: 0
Training loss: 1.8800232410430908
Validation loss: 2.113302602562853

Epoch: 5| Step: 1
Training loss: 1.8082603216171265
Validation loss: 2.115468466153709

Epoch: 5| Step: 2
Training loss: 2.1868491172790527
Validation loss: 2.12551107457889

Epoch: 5| Step: 3
Training loss: 1.8207862377166748
Validation loss: 2.1211241445233746

Epoch: 5| Step: 4
Training loss: 2.0649774074554443
Validation loss: 2.1014118758581017

Epoch: 5| Step: 5
Training loss: 1.7243626117706299
Validation loss: 2.0899671739147556

Epoch: 5| Step: 6
Training loss: 1.537029504776001
Validation loss: 2.075830113503241

Epoch: 5| Step: 7
Training loss: 1.9560037851333618
Validation loss: 2.0844828454397057

Epoch: 5| Step: 8
Training loss: 1.4769901037216187
Validation loss: 2.086038807386993

Epoch: 5| Step: 9
Training loss: 2.393601179122925
Validation loss: 2.07975185045632

Epoch: 5| Step: 10
Training loss: 1.6326701641082764
Validation loss: 2.0735510190327964

Epoch: 173| Step: 0
Training loss: 1.8356914520263672
Validation loss: 2.0750267633827786

Epoch: 5| Step: 1
Training loss: 1.7098162174224854
Validation loss: 2.07028450504426

Epoch: 5| Step: 2
Training loss: 1.914308786392212
Validation loss: 2.0621431566053823

Epoch: 5| Step: 3
Training loss: 2.040177822113037
Validation loss: 2.0662836336320445

Epoch: 5| Step: 4
Training loss: 2.359386920928955
Validation loss: 2.081250206116707

Epoch: 5| Step: 5
Training loss: 2.278078317642212
Validation loss: 2.0792301239505893

Epoch: 5| Step: 6
Training loss: 0.991794228553772
Validation loss: 2.0675747138197704

Epoch: 5| Step: 7
Training loss: 1.916937232017517
Validation loss: 2.07296629746755

Epoch: 5| Step: 8
Training loss: 1.6282514333724976
Validation loss: 2.0806505013537664

Epoch: 5| Step: 9
Training loss: 2.0569863319396973
Validation loss: 2.0797745694396315

Epoch: 5| Step: 10
Training loss: 1.6518186330795288
Validation loss: 2.096008931436846

Epoch: 174| Step: 0
Training loss: 2.3931515216827393
Validation loss: 2.0661985822903213

Epoch: 5| Step: 1
Training loss: 1.7960437536239624
Validation loss: 2.077198964293285

Epoch: 5| Step: 2
Training loss: 1.7224622964859009
Validation loss: 2.0595120781211445

Epoch: 5| Step: 3
Training loss: 1.807979941368103
Validation loss: 2.0543329023545787

Epoch: 5| Step: 4
Training loss: 1.4925765991210938
Validation loss: 2.0555637651874172

Epoch: 5| Step: 5
Training loss: 1.8744213581085205
Validation loss: 2.0546617443843553

Epoch: 5| Step: 6
Training loss: 1.2171285152435303
Validation loss: 2.0700993742994083

Epoch: 5| Step: 7
Training loss: 1.8218955993652344
Validation loss: 2.0430976883057625

Epoch: 5| Step: 8
Training loss: 2.176815986633301
Validation loss: 2.0546375730986237

Epoch: 5| Step: 9
Training loss: 1.9768245220184326
Validation loss: 2.0708943361877115

Epoch: 5| Step: 10
Training loss: 2.1022791862487793
Validation loss: 2.0999100631283176

Epoch: 175| Step: 0
Training loss: 1.6697375774383545
Validation loss: 2.1061336955716534

Epoch: 5| Step: 1
Training loss: 1.9997352361679077
Validation loss: 2.085890136739259

Epoch: 5| Step: 2
Training loss: 1.1605989933013916
Validation loss: 2.1024036228015857

Epoch: 5| Step: 3
Training loss: 1.8106704950332642
Validation loss: 2.118433121711977

Epoch: 5| Step: 4
Training loss: 2.1050965785980225
Validation loss: 2.127988998607923

Epoch: 5| Step: 5
Training loss: 2.2088003158569336
Validation loss: 2.1049547144161758

Epoch: 5| Step: 6
Training loss: 2.1026246547698975
Validation loss: 2.1167135546284337

Epoch: 5| Step: 7
Training loss: 1.2995824813842773
Validation loss: 2.0969091999915337

Epoch: 5| Step: 8
Training loss: 1.6577186584472656
Validation loss: 2.0880231498390116

Epoch: 5| Step: 9
Training loss: 2.1779322624206543
Validation loss: 2.0572436407048214

Epoch: 5| Step: 10
Training loss: 1.9458786249160767
Validation loss: 2.0599024564989152

Epoch: 176| Step: 0
Training loss: 2.256333827972412
Validation loss: 2.043317820436211

Epoch: 5| Step: 1
Training loss: 1.7597147226333618
Validation loss: 2.0593750630655596

Epoch: 5| Step: 2
Training loss: 1.6359193325042725
Validation loss: 2.080460604800973

Epoch: 5| Step: 3
Training loss: 1.6447954177856445
Validation loss: 2.080035053273683

Epoch: 5| Step: 4
Training loss: 1.718274712562561
Validation loss: 2.072695791080434

Epoch: 5| Step: 5
Training loss: 1.8181127309799194
Validation loss: 2.0626568384067987

Epoch: 5| Step: 6
Training loss: 1.923052191734314
Validation loss: 2.098776617357808

Epoch: 5| Step: 7
Training loss: 1.921542763710022
Validation loss: 2.10995311890879

Epoch: 5| Step: 8
Training loss: 1.980470061302185
Validation loss: 2.100494559093188

Epoch: 5| Step: 9
Training loss: 1.857012152671814
Validation loss: 2.1079119123438352

Epoch: 5| Step: 10
Training loss: 1.7672556638717651
Validation loss: 2.104530131945046

Epoch: 177| Step: 0
Training loss: 2.0410170555114746
Validation loss: 2.1006360669289865

Epoch: 5| Step: 1
Training loss: 1.9518678188323975
Validation loss: 2.0859051776188675

Epoch: 5| Step: 2
Training loss: 1.6525795459747314
Validation loss: 2.073875550300844

Epoch: 5| Step: 3
Training loss: 1.5890973806381226
Validation loss: 2.0658545186442714

Epoch: 5| Step: 4
Training loss: 2.0190579891204834
Validation loss: 2.051565570216025

Epoch: 5| Step: 5
Training loss: 1.574824571609497
Validation loss: 2.050157335496718

Epoch: 5| Step: 6
Training loss: 1.2624061107635498
Validation loss: 2.0577283802852837

Epoch: 5| Step: 7
Training loss: 1.9497299194335938
Validation loss: 2.083577576503959

Epoch: 5| Step: 8
Training loss: 2.15514874458313
Validation loss: 2.0863335196689894

Epoch: 5| Step: 9
Training loss: 1.8715007305145264
Validation loss: 2.0912576695924163

Epoch: 5| Step: 10
Training loss: 2.1489644050598145
Validation loss: 2.0916366115693124

Epoch: 178| Step: 0
Training loss: 1.776245355606079
Validation loss: 2.097910984869926

Epoch: 5| Step: 1
Training loss: 1.8533014059066772
Validation loss: 2.0882574153202835

Epoch: 5| Step: 2
Training loss: 2.090546131134033
Validation loss: 2.1067668904540358

Epoch: 5| Step: 3
Training loss: 1.142120599746704
Validation loss: 2.1173104829685663

Epoch: 5| Step: 4
Training loss: 1.8315961360931396
Validation loss: 2.0979609156167633

Epoch: 5| Step: 5
Training loss: 1.2820740938186646
Validation loss: 2.0685561574915403

Epoch: 5| Step: 6
Training loss: 2.4122891426086426
Validation loss: 2.062558156187816

Epoch: 5| Step: 7
Training loss: 1.3877063989639282
Validation loss: 2.0430355072021484

Epoch: 5| Step: 8
Training loss: 2.560682773590088
Validation loss: 2.021658174453243

Epoch: 5| Step: 9
Training loss: 2.0614678859710693
Validation loss: 2.0266122792356756

Epoch: 5| Step: 10
Training loss: 1.6613781452178955
Validation loss: 1.9872845911210584

Epoch: 179| Step: 0
Training loss: 1.9900773763656616
Validation loss: 2.007923937612964

Epoch: 5| Step: 1
Training loss: 1.4348968267440796
Validation loss: 2.0288553391733477

Epoch: 5| Step: 2
Training loss: 2.1051695346832275
Validation loss: 2.0350217050121677

Epoch: 5| Step: 3
Training loss: 1.7051975727081299
Validation loss: 2.025322920532637

Epoch: 5| Step: 4
Training loss: 2.0167860984802246
Validation loss: 2.025716462442952

Epoch: 5| Step: 5
Training loss: 1.249104619026184
Validation loss: 2.0514506550245386

Epoch: 5| Step: 6
Training loss: 1.571001410484314
Validation loss: 2.0735137642070813

Epoch: 5| Step: 7
Training loss: 1.7965152263641357
Validation loss: 2.11145080033169

Epoch: 5| Step: 8
Training loss: 2.0651724338531494
Validation loss: 2.1415541684755715

Epoch: 5| Step: 9
Training loss: 1.5894594192504883
Validation loss: 2.1442742193898847

Epoch: 5| Step: 10
Training loss: 2.90543532371521
Validation loss: 2.106870452562968

Epoch: 180| Step: 0
Training loss: 1.8685600757598877
Validation loss: 2.080889278842557

Epoch: 5| Step: 1
Training loss: 1.2066770792007446
Validation loss: 2.0640718372919227

Epoch: 5| Step: 2
Training loss: 2.1666927337646484
Validation loss: 2.0638948794334167

Epoch: 5| Step: 3
Training loss: 1.666430115699768
Validation loss: 2.059679158272282

Epoch: 5| Step: 4
Training loss: 1.912998914718628
Validation loss: 2.058190832855881

Epoch: 5| Step: 5
Training loss: 1.5815492868423462
Validation loss: 2.071778840916131

Epoch: 5| Step: 6
Training loss: 2.067148447036743
Validation loss: 2.0577856263806744

Epoch: 5| Step: 7
Training loss: 1.7344920635223389
Validation loss: 2.054987859982316

Epoch: 5| Step: 8
Training loss: 1.6978557109832764
Validation loss: 2.058255845500577

Epoch: 5| Step: 9
Training loss: 1.85445237159729
Validation loss: 2.0651527438112485

Epoch: 5| Step: 10
Training loss: 1.926340937614441
Validation loss: 2.0805187661160707

Epoch: 181| Step: 0
Training loss: 0.9471553564071655
Validation loss: 2.0766734461630545

Epoch: 5| Step: 1
Training loss: 1.8344751596450806
Validation loss: 2.0792470670515493

Epoch: 5| Step: 2
Training loss: 1.583106517791748
Validation loss: 2.06756075479651

Epoch: 5| Step: 3
Training loss: 1.6450620889663696
Validation loss: 2.0608355127355105

Epoch: 5| Step: 4
Training loss: 1.7908909320831299
Validation loss: 2.06757656861377

Epoch: 5| Step: 5
Training loss: 1.8951603174209595
Validation loss: 2.0711966483823714

Epoch: 5| Step: 6
Training loss: 1.8219528198242188
Validation loss: 2.070015980351356

Epoch: 5| Step: 7
Training loss: 1.6881952285766602
Validation loss: 2.093002647481939

Epoch: 5| Step: 8
Training loss: 2.5911641120910645
Validation loss: 2.086135379729732

Epoch: 5| Step: 9
Training loss: 1.4487969875335693
Validation loss: 2.087721304226947

Epoch: 5| Step: 10
Training loss: 2.4436371326446533
Validation loss: 2.1064003103522846

Epoch: 182| Step: 0
Training loss: 1.2957754135131836
Validation loss: 2.1297202699927875

Epoch: 5| Step: 1
Training loss: 1.110230803489685
Validation loss: 2.156176397877355

Epoch: 5| Step: 2
Training loss: 1.8101475238800049
Validation loss: 2.14323285190008

Epoch: 5| Step: 3
Training loss: 1.5993040800094604
Validation loss: 2.104055268790132

Epoch: 5| Step: 4
Training loss: 1.9447238445281982
Validation loss: 2.0786924810819727

Epoch: 5| Step: 5
Training loss: 1.4960107803344727
Validation loss: 2.074550323588874

Epoch: 5| Step: 6
Training loss: 2.512087345123291
Validation loss: 2.0754412630552888

Epoch: 5| Step: 7
Training loss: 2.4664487838745117
Validation loss: 2.0672480265299478

Epoch: 5| Step: 8
Training loss: 2.0146994590759277
Validation loss: 2.0726076249153382

Epoch: 5| Step: 9
Training loss: 1.5658035278320312
Validation loss: 2.06475507315769

Epoch: 5| Step: 10
Training loss: 1.6695302724838257
Validation loss: 2.0549896122306905

Epoch: 183| Step: 0
Training loss: 1.9758355617523193
Validation loss: 2.069175430523452

Epoch: 5| Step: 1
Training loss: 1.9630506038665771
Validation loss: 2.0878933014408236

Epoch: 5| Step: 2
Training loss: 1.4571164846420288
Validation loss: 2.074848528831236

Epoch: 5| Step: 3
Training loss: 1.4311853647232056
Validation loss: 2.0852216392435055

Epoch: 5| Step: 4
Training loss: 1.5948890447616577
Validation loss: 2.0744387257483696

Epoch: 5| Step: 5
Training loss: 1.7312572002410889
Validation loss: 2.057694281301191

Epoch: 5| Step: 6
Training loss: 1.789285659790039
Validation loss: 2.050110960519442

Epoch: 5| Step: 7
Training loss: 1.756604552268982
Validation loss: 2.056289311378233

Epoch: 5| Step: 8
Training loss: 1.944352149963379
Validation loss: 2.07956709143936

Epoch: 5| Step: 9
Training loss: 2.0521578788757324
Validation loss: 2.0937488514889955

Epoch: 5| Step: 10
Training loss: 1.7002019882202148
Validation loss: 2.0978253836272867

Epoch: 184| Step: 0
Training loss: 2.008467197418213
Validation loss: 2.0939038979109896

Epoch: 5| Step: 1
Training loss: 1.966831922531128
Validation loss: 2.1118395572067588

Epoch: 5| Step: 2
Training loss: 1.740862250328064
Validation loss: 2.1571712416987263

Epoch: 5| Step: 3
Training loss: 1.8181383609771729
Validation loss: 2.2148401147575787

Epoch: 5| Step: 4
Training loss: 1.8320316076278687
Validation loss: 2.2203791808056574

Epoch: 5| Step: 5
Training loss: 1.821354627609253
Validation loss: 2.2137688308633785

Epoch: 5| Step: 6
Training loss: 1.3986093997955322
Validation loss: 2.1670231716607207

Epoch: 5| Step: 7
Training loss: 2.066521167755127
Validation loss: 2.124046607684064

Epoch: 5| Step: 8
Training loss: 1.7683671712875366
Validation loss: 2.095113100544099

Epoch: 5| Step: 9
Training loss: 1.9745254516601562
Validation loss: 2.0903135627828617

Epoch: 5| Step: 10
Training loss: 0.9897059202194214
Validation loss: 2.078546106174428

Epoch: 185| Step: 0
Training loss: 1.7283527851104736
Validation loss: 2.0881385880131877

Epoch: 5| Step: 1
Training loss: 1.5633469820022583
Validation loss: 2.0786163294187157

Epoch: 5| Step: 2
Training loss: 1.4821150302886963
Validation loss: 2.0832891336051365

Epoch: 5| Step: 3
Training loss: 1.9380130767822266
Validation loss: 2.0473783221296085

Epoch: 5| Step: 4
Training loss: 1.7378361225128174
Validation loss: 2.0408133614447808

Epoch: 5| Step: 5
Training loss: 2.230483055114746
Validation loss: 2.078371496610744

Epoch: 5| Step: 6
Training loss: 2.0081677436828613
Validation loss: 2.1149003685161634

Epoch: 5| Step: 7
Training loss: 1.8340696096420288
Validation loss: 2.1294677154992216

Epoch: 5| Step: 8
Training loss: 1.9764289855957031
Validation loss: 2.1542419528448455

Epoch: 5| Step: 9
Training loss: 1.7466825246810913
Validation loss: 2.124920515603917

Epoch: 5| Step: 10
Training loss: 1.827528953552246
Validation loss: 2.1050165878829135

Epoch: 186| Step: 0
Training loss: 1.492695689201355
Validation loss: 2.0927679102907897

Epoch: 5| Step: 1
Training loss: 1.7096869945526123
Validation loss: 2.093319982610723

Epoch: 5| Step: 2
Training loss: 2.0138747692108154
Validation loss: 2.1261306398658344

Epoch: 5| Step: 3
Training loss: 1.724879503250122
Validation loss: 2.1540555159250894

Epoch: 5| Step: 4
Training loss: 1.2805880308151245
Validation loss: 2.1596318560261882

Epoch: 5| Step: 5
Training loss: 1.7242333889007568
Validation loss: 2.155330845104751

Epoch: 5| Step: 6
Training loss: 2.3831419944763184
Validation loss: 2.1617680954676803

Epoch: 5| Step: 7
Training loss: 2.168700695037842
Validation loss: 2.1107751887331725

Epoch: 5| Step: 8
Training loss: 1.431327223777771
Validation loss: 2.118796287044402

Epoch: 5| Step: 9
Training loss: 1.7175060510635376
Validation loss: 2.0909697804399716

Epoch: 5| Step: 10
Training loss: 1.9520063400268555
Validation loss: 2.076444733527399

Epoch: 187| Step: 0
Training loss: 1.9675853252410889
Validation loss: 2.048688975713586

Epoch: 5| Step: 1
Training loss: 1.5385587215423584
Validation loss: 2.040777814003729

Epoch: 5| Step: 2
Training loss: 1.7795813083648682
Validation loss: 2.026377086998314

Epoch: 5| Step: 3
Training loss: 2.37532114982605
Validation loss: 2.0194833355565227

Epoch: 5| Step: 4
Training loss: 1.1902358531951904
Validation loss: 2.011877347064275

Epoch: 5| Step: 5
Training loss: 0.9743229150772095
Validation loss: 2.02258284630314

Epoch: 5| Step: 6
Training loss: 1.7732139825820923
Validation loss: 2.0461757054892917

Epoch: 5| Step: 7
Training loss: 1.9220308065414429
Validation loss: 2.071111294531053

Epoch: 5| Step: 8
Training loss: 2.319985866546631
Validation loss: 2.0948572235722698

Epoch: 5| Step: 9
Training loss: 1.5353853702545166
Validation loss: 2.1260229849046275

Epoch: 5| Step: 10
Training loss: 1.6960738897323608
Validation loss: 2.1320564464856218

Epoch: 188| Step: 0
Training loss: 1.8223133087158203
Validation loss: 2.1222503544181905

Epoch: 5| Step: 1
Training loss: 2.3075037002563477
Validation loss: 2.134567165887484

Epoch: 5| Step: 2
Training loss: 1.5354572534561157
Validation loss: 2.115224402437928

Epoch: 5| Step: 3
Training loss: 2.1095590591430664
Validation loss: 2.1265240587213987

Epoch: 5| Step: 4
Training loss: 1.6085689067840576
Validation loss: 2.120344818279307

Epoch: 5| Step: 5
Training loss: 1.1078407764434814
Validation loss: 2.078216616825391

Epoch: 5| Step: 6
Training loss: 1.3103909492492676
Validation loss: 2.0642625349824146

Epoch: 5| Step: 7
Training loss: 1.1104693412780762
Validation loss: 2.0690665014328493

Epoch: 5| Step: 8
Training loss: 2.3999435901641846
Validation loss: 2.0883053554001676

Epoch: 5| Step: 9
Training loss: 1.5685689449310303
Validation loss: 2.104497137890067

Epoch: 5| Step: 10
Training loss: 1.9236328601837158
Validation loss: 2.129924907479235

Epoch: 189| Step: 0
Training loss: 1.7924104928970337
Validation loss: 2.121790935916285

Epoch: 5| Step: 1
Training loss: 1.3234063386917114
Validation loss: 2.1287284230673187

Epoch: 5| Step: 2
Training loss: 1.4453649520874023
Validation loss: 2.0883077344586773

Epoch: 5| Step: 3
Training loss: 1.9405314922332764
Validation loss: 2.0600727347917456

Epoch: 5| Step: 4
Training loss: 1.7270902395248413
Validation loss: 2.0601226565658406

Epoch: 5| Step: 5
Training loss: 2.135931968688965
Validation loss: 2.078761041805308

Epoch: 5| Step: 6
Training loss: 1.4054065942764282
Validation loss: 2.098429908034622

Epoch: 5| Step: 7
Training loss: 1.4522676467895508
Validation loss: 2.112380159798489

Epoch: 5| Step: 8
Training loss: 1.6432710886001587
Validation loss: 2.099265411335935

Epoch: 5| Step: 9
Training loss: 2.0189716815948486
Validation loss: 2.1316027359295915

Epoch: 5| Step: 10
Training loss: 2.227717638015747
Validation loss: 2.1608473729061823

Epoch: 190| Step: 0
Training loss: 2.0865700244903564
Validation loss: 2.1911084293037333

Epoch: 5| Step: 1
Training loss: 1.4733912944793701
Validation loss: 2.1973128446968655

Epoch: 5| Step: 2
Training loss: 1.7862350940704346
Validation loss: 2.1815082732067315

Epoch: 5| Step: 3
Training loss: 1.0574277639389038
Validation loss: 2.146289284511279

Epoch: 5| Step: 4
Training loss: 1.0601379871368408
Validation loss: 2.1433882354408182

Epoch: 5| Step: 5
Training loss: 2.037003993988037
Validation loss: 2.1196249915707495

Epoch: 5| Step: 6
Training loss: 1.6020758152008057
Validation loss: 2.1226597498821955

Epoch: 5| Step: 7
Training loss: 1.1302894353866577
Validation loss: 2.0974007755197506

Epoch: 5| Step: 8
Training loss: 1.9179595708847046
Validation loss: 2.108418574897192

Epoch: 5| Step: 9
Training loss: 2.1242008209228516
Validation loss: 2.0918275771602506

Epoch: 5| Step: 10
Training loss: 2.0777230262756348
Validation loss: 2.1030478656932874

Epoch: 191| Step: 0
Training loss: 1.086224913597107
Validation loss: 2.081818965173537

Epoch: 5| Step: 1
Training loss: 1.42561674118042
Validation loss: 2.0885393183718444

Epoch: 5| Step: 2
Training loss: 1.7279001474380493
Validation loss: 2.0719328336818243

Epoch: 5| Step: 3
Training loss: 1.4181389808654785
Validation loss: 2.0937282103364185

Epoch: 5| Step: 4
Training loss: 1.8568462133407593
Validation loss: 2.109331480918392

Epoch: 5| Step: 5
Training loss: 1.072291612625122
Validation loss: 2.1126542475915726

Epoch: 5| Step: 6
Training loss: 2.151867151260376
Validation loss: 2.124155382956228

Epoch: 5| Step: 7
Training loss: 1.8465763330459595
Validation loss: 2.1242694970100158

Epoch: 5| Step: 8
Training loss: 2.1152586936950684
Validation loss: 2.1266984337119648

Epoch: 5| Step: 9
Training loss: 1.9413344860076904
Validation loss: 2.1030854153376755

Epoch: 5| Step: 10
Training loss: 1.164099097251892
Validation loss: 2.1059441592103694

Epoch: 192| Step: 0
Training loss: 1.2418360710144043
Validation loss: 2.088326556708223

Epoch: 5| Step: 1
Training loss: 1.7429323196411133
Validation loss: 2.0600092308495634

Epoch: 5| Step: 2
Training loss: 1.5465443134307861
Validation loss: 2.058162404644874

Epoch: 5| Step: 3
Training loss: 1.798971176147461
Validation loss: 2.0632877734399613

Epoch: 5| Step: 4
Training loss: 1.7708994150161743
Validation loss: 2.0770593920061664

Epoch: 5| Step: 5
Training loss: 1.0661581754684448
Validation loss: 2.072781978114959

Epoch: 5| Step: 6
Training loss: 1.92975652217865
Validation loss: 2.083355088387766

Epoch: 5| Step: 7
Training loss: 1.7319362163543701
Validation loss: 2.1007948049934964

Epoch: 5| Step: 8
Training loss: 1.5530970096588135
Validation loss: 2.0609919896689792

Epoch: 5| Step: 9
Training loss: 1.9184119701385498
Validation loss: 2.064390168395094

Epoch: 5| Step: 10
Training loss: 1.5754376649856567
Validation loss: 2.0659048147098993

Epoch: 193| Step: 0
Training loss: 1.3117395639419556
Validation loss: 2.055474155692644

Epoch: 5| Step: 1
Training loss: 1.8918033838272095
Validation loss: 2.056925085283095

Epoch: 5| Step: 2
Training loss: 2.305588483810425
Validation loss: 2.063453879407657

Epoch: 5| Step: 3
Training loss: 1.1712347269058228
Validation loss: 2.0942537553848757

Epoch: 5| Step: 4
Training loss: 1.4409750699996948
Validation loss: 2.088390600296759

Epoch: 5| Step: 5
Training loss: 1.5792080163955688
Validation loss: 2.1037112820533013

Epoch: 5| Step: 6
Training loss: 1.484714388847351
Validation loss: 2.1006454703628377

Epoch: 5| Step: 7
Training loss: 1.7850844860076904
Validation loss: 2.108426373492005

Epoch: 5| Step: 8
Training loss: 1.5996720790863037
Validation loss: 2.1296636827530397

Epoch: 5| Step: 9
Training loss: 1.6240508556365967
Validation loss: 2.1102889635229625

Epoch: 5| Step: 10
Training loss: 1.3239091634750366
Validation loss: 2.106239195792906

Epoch: 194| Step: 0
Training loss: 1.5295614004135132
Validation loss: 2.093367161289338

Epoch: 5| Step: 1
Training loss: 1.6262657642364502
Validation loss: 2.070065438106496

Epoch: 5| Step: 2
Training loss: 1.8582016229629517
Validation loss: 2.0619499862834973

Epoch: 5| Step: 3
Training loss: 1.5330514907836914
Validation loss: 2.0494168958356305

Epoch: 5| Step: 4
Training loss: 1.6122543811798096
Validation loss: 2.0525580811244186

Epoch: 5| Step: 5
Training loss: 1.2891569137573242
Validation loss: 2.0468285365771224

Epoch: 5| Step: 6
Training loss: 2.0342013835906982
Validation loss: 2.070012779646022

Epoch: 5| Step: 7
Training loss: 1.6137371063232422
Validation loss: 2.0844954982880624

Epoch: 5| Step: 8
Training loss: 1.2766811847686768
Validation loss: 2.1333030872447516

Epoch: 5| Step: 9
Training loss: 1.9465469121932983
Validation loss: 2.162207193272088

Epoch: 5| Step: 10
Training loss: 1.3353458642959595
Validation loss: 2.188996599566552

Epoch: 195| Step: 0
Training loss: 1.6403976678848267
Validation loss: 2.2326865375682874

Epoch: 5| Step: 1
Training loss: 1.9957717657089233
Validation loss: 2.243954579035441

Epoch: 5| Step: 2
Training loss: 1.4968105554580688
Validation loss: 2.204949135421425

Epoch: 5| Step: 3
Training loss: 2.094057559967041
Validation loss: 2.161204158618886

Epoch: 5| Step: 4
Training loss: 1.097593903541565
Validation loss: 2.1633522830983645

Epoch: 5| Step: 5
Training loss: 1.8081315755844116
Validation loss: 2.1244689520969184

Epoch: 5| Step: 6
Training loss: 0.9109871983528137
Validation loss: 2.10645132423729

Epoch: 5| Step: 7
Training loss: 2.1283278465270996
Validation loss: 2.094925667649956

Epoch: 5| Step: 8
Training loss: 1.5796363353729248
Validation loss: 2.0731378652716197

Epoch: 5| Step: 9
Training loss: 1.3980767726898193
Validation loss: 2.072119111655861

Epoch: 5| Step: 10
Training loss: 1.4493286609649658
Validation loss: 2.061875935523741

Epoch: 196| Step: 0
Training loss: 1.7887738943099976
Validation loss: 2.075934589550059

Epoch: 5| Step: 1
Training loss: 1.6744022369384766
Validation loss: 2.0480894273327244

Epoch: 5| Step: 2
Training loss: 2.335339069366455
Validation loss: 2.0379515847852154

Epoch: 5| Step: 3
Training loss: 1.8954668045043945
Validation loss: 2.0449944055208595

Epoch: 5| Step: 4
Training loss: 1.2378690242767334
Validation loss: 2.0296775423070437

Epoch: 5| Step: 5
Training loss: 1.0656158924102783
Validation loss: 2.049091551893501

Epoch: 5| Step: 6
Training loss: 1.496190071105957
Validation loss: 2.052038518331384

Epoch: 5| Step: 7
Training loss: 1.8688876628875732
Validation loss: 2.097256011860345

Epoch: 5| Step: 8
Training loss: 1.4754165410995483
Validation loss: 2.132350073065809

Epoch: 5| Step: 9
Training loss: 1.2594913244247437
Validation loss: 2.1334720734627015

Epoch: 5| Step: 10
Training loss: 1.363214135169983
Validation loss: 2.134560710640364

Epoch: 197| Step: 0
Training loss: 1.5923819541931152
Validation loss: 2.14242640361991

Epoch: 5| Step: 1
Training loss: 1.5354540348052979
Validation loss: 2.1359822391181864

Epoch: 5| Step: 2
Training loss: 1.2981717586517334
Validation loss: 2.1357572642705773

Epoch: 5| Step: 3
Training loss: 1.7061347961425781
Validation loss: 2.146449994015437

Epoch: 5| Step: 4
Training loss: 1.3142081499099731
Validation loss: 2.120804981518817

Epoch: 5| Step: 5
Training loss: 1.242327332496643
Validation loss: 2.1068244595681467

Epoch: 5| Step: 6
Training loss: 1.716303825378418
Validation loss: 2.0897197800297893

Epoch: 5| Step: 7
Training loss: 1.6057548522949219
Validation loss: 2.0700890261639833

Epoch: 5| Step: 8
Training loss: 1.6874529123306274
Validation loss: 2.0668380568104405

Epoch: 5| Step: 9
Training loss: 1.8548011779785156
Validation loss: 2.03843964299848

Epoch: 5| Step: 10
Training loss: 1.55528724193573
Validation loss: 2.0387006754516275

Epoch: 198| Step: 0
Training loss: 1.7867801189422607
Validation loss: 2.01458228018976

Epoch: 5| Step: 1
Training loss: 1.572790503501892
Validation loss: 2.029733875746368

Epoch: 5| Step: 2
Training loss: 1.475140929222107
Validation loss: 2.0320543755767164

Epoch: 5| Step: 3
Training loss: 1.4611519575119019
Validation loss: 2.0480444738941808

Epoch: 5| Step: 4
Training loss: 1.3998997211456299
Validation loss: 2.0944668887763895

Epoch: 5| Step: 5
Training loss: 1.1623626947402954
Validation loss: 2.104260501041207

Epoch: 5| Step: 6
Training loss: 1.0521175861358643
Validation loss: 2.095358487098448

Epoch: 5| Step: 7
Training loss: 1.8373912572860718
Validation loss: 2.072749435260732

Epoch: 5| Step: 8
Training loss: 1.6776371002197266
Validation loss: 2.0599289568521644

Epoch: 5| Step: 9
Training loss: 2.17458176612854
Validation loss: 2.0616361402696177

Epoch: 5| Step: 10
Training loss: 1.825801968574524
Validation loss: 2.0408664006058888

Epoch: 199| Step: 0
Training loss: 1.4766947031021118
Validation loss: 2.0637632352049633

Epoch: 5| Step: 1
Training loss: 1.7656062841415405
Validation loss: 2.063221421293033

Epoch: 5| Step: 2
Training loss: 1.6534065008163452
Validation loss: 2.068653360489876

Epoch: 5| Step: 3
Training loss: 1.2930142879486084
Validation loss: 2.0754201886474446

Epoch: 5| Step: 4
Training loss: 1.184303641319275
Validation loss: 2.0870336986357167

Epoch: 5| Step: 5
Training loss: 1.2056554555892944
Validation loss: 2.096671022394652

Epoch: 5| Step: 6
Training loss: 1.4352614879608154
Validation loss: 2.133244160682924

Epoch: 5| Step: 7
Training loss: 1.4972704648971558
Validation loss: 2.1363542720835698

Epoch: 5| Step: 8
Training loss: 2.246281862258911
Validation loss: 2.1361692079933743

Epoch: 5| Step: 9
Training loss: 1.4719724655151367
Validation loss: 2.088587976271106

Epoch: 5| Step: 10
Training loss: 2.114677906036377
Validation loss: 2.06255768704158

Epoch: 200| Step: 0
Training loss: 1.475570797920227
Validation loss: 2.0635184177788357

Epoch: 5| Step: 1
Training loss: 1.422041893005371
Validation loss: 2.07811761671497

Epoch: 5| Step: 2
Training loss: 1.4659451246261597
Validation loss: 2.0547463624708113

Epoch: 5| Step: 3
Training loss: 1.2342216968536377
Validation loss: 2.078130455427272

Epoch: 5| Step: 4
Training loss: 1.8839786052703857
Validation loss: 2.107169428179341

Epoch: 5| Step: 5
Training loss: 1.9129879474639893
Validation loss: 2.132136280818652

Epoch: 5| Step: 6
Training loss: 1.8633619546890259
Validation loss: 2.1776903175538584

Epoch: 5| Step: 7
Training loss: 1.7375173568725586
Validation loss: 2.152384155540056

Epoch: 5| Step: 8
Training loss: 1.6207689046859741
Validation loss: 2.1475543770738827

Epoch: 5| Step: 9
Training loss: 1.4446640014648438
Validation loss: 2.1207668166006766

Epoch: 5| Step: 10
Training loss: 1.0260777473449707
Validation loss: 2.0950554083752375

Epoch: 201| Step: 0
Training loss: 1.667360544204712
Validation loss: 2.094236389283211

Epoch: 5| Step: 1
Training loss: 1.886234998703003
Validation loss: 2.1147625984684115

Epoch: 5| Step: 2
Training loss: 1.2288439273834229
Validation loss: 2.1217857714622252

Epoch: 5| Step: 3
Training loss: 2.2266201972961426
Validation loss: 2.118296915485013

Epoch: 5| Step: 4
Training loss: 1.6342155933380127
Validation loss: 2.1185250282287598

Epoch: 5| Step: 5
Training loss: 0.9451354742050171
Validation loss: 2.1716740067287157

Epoch: 5| Step: 6
Training loss: 1.6572234630584717
Validation loss: 2.212701997449321

Epoch: 5| Step: 7
Training loss: 1.51993727684021
Validation loss: 2.23863568100878

Epoch: 5| Step: 8
Training loss: 1.7349497079849243
Validation loss: 2.2092876280507734

Epoch: 5| Step: 9
Training loss: 1.4200053215026855
Validation loss: 2.174307341216713

Epoch: 5| Step: 10
Training loss: 1.8931480646133423
Validation loss: 2.1249488297329155

Epoch: 202| Step: 0
Training loss: 1.2227892875671387
Validation loss: 2.0833985959329913

Epoch: 5| Step: 1
Training loss: 1.370590329170227
Validation loss: 2.0336622576559744

Epoch: 5| Step: 2
Training loss: 2.021329402923584
Validation loss: 2.0139300131028697

Epoch: 5| Step: 3
Training loss: 1.412635326385498
Validation loss: 2.0042176554279942

Epoch: 5| Step: 4
Training loss: 1.2407761812210083
Validation loss: 2.036681500814294

Epoch: 5| Step: 5
Training loss: 1.5233991146087646
Validation loss: 2.062381039383591

Epoch: 5| Step: 6
Training loss: 1.6616878509521484
Validation loss: 2.10603404045105

Epoch: 5| Step: 7
Training loss: 1.6003673076629639
Validation loss: 2.136616217192783

Epoch: 5| Step: 8
Training loss: 2.212723970413208
Validation loss: 2.1685873000852522

Epoch: 5| Step: 9
Training loss: 1.4835729598999023
Validation loss: 2.160534768976191

Epoch: 5| Step: 10
Training loss: 2.0687062740325928
Validation loss: 2.1302785591412614

Epoch: 203| Step: 0
Training loss: 1.384244441986084
Validation loss: 2.063383533108619

Epoch: 5| Step: 1
Training loss: 2.0579426288604736
Validation loss: 2.0334240877500145

Epoch: 5| Step: 2
Training loss: 1.32711660861969
Validation loss: 2.017729063187876

Epoch: 5| Step: 3
Training loss: 1.8873180150985718
Validation loss: 2.020422194593696

Epoch: 5| Step: 4
Training loss: 1.2544333934783936
Validation loss: 2.014340745505466

Epoch: 5| Step: 5
Training loss: 1.6952747106552124
Validation loss: 2.0383360308985554

Epoch: 5| Step: 6
Training loss: 1.7506229877471924
Validation loss: 2.0534543170723865

Epoch: 5| Step: 7
Training loss: 1.6529518365859985
Validation loss: 2.0587618530437513

Epoch: 5| Step: 8
Training loss: 1.1108518838882446
Validation loss: 2.086424889103059

Epoch: 5| Step: 9
Training loss: 1.8716647624969482
Validation loss: 2.1049132488107167

Epoch: 5| Step: 10
Training loss: 1.4407663345336914
Validation loss: 2.0884138909719323

Epoch: 204| Step: 0
Training loss: 1.170021891593933
Validation loss: 2.1223586554168374

Epoch: 5| Step: 1
Training loss: 1.5959501266479492
Validation loss: 2.1245695570463776

Epoch: 5| Step: 2
Training loss: 1.662476897239685
Validation loss: 2.1516520977020264

Epoch: 5| Step: 3
Training loss: 1.5603632926940918
Validation loss: 2.1660338781213246

Epoch: 5| Step: 4
Training loss: 1.8455638885498047
Validation loss: 2.163593044845007

Epoch: 5| Step: 5
Training loss: 1.963620901107788
Validation loss: 2.111089801275602

Epoch: 5| Step: 6
Training loss: 1.6740909814834595
Validation loss: 2.0880788474954586

Epoch: 5| Step: 7
Training loss: 1.6915744543075562
Validation loss: 2.068236158740136

Epoch: 5| Step: 8
Training loss: 1.0167968273162842
Validation loss: 2.034707156560754

Epoch: 5| Step: 9
Training loss: 1.5138639211654663
Validation loss: 2.04035440311637

Epoch: 5| Step: 10
Training loss: 1.2181992530822754
Validation loss: 2.0185651497174333

Epoch: 205| Step: 0
Training loss: 1.587464690208435
Validation loss: 2.0129947662353516

Epoch: 5| Step: 1
Training loss: 1.1429319381713867
Validation loss: 2.0247452438518567

Epoch: 5| Step: 2
Training loss: 1.1038970947265625
Validation loss: 2.037960945918996

Epoch: 5| Step: 3
Training loss: 1.736672043800354
Validation loss: 2.0414459320806686

Epoch: 5| Step: 4
Training loss: 1.8607070446014404
Validation loss: 2.0656934399758615

Epoch: 5| Step: 5
Training loss: 1.7252388000488281
Validation loss: 2.0489185343506517

Epoch: 5| Step: 6
Training loss: 0.936165452003479
Validation loss: 2.0476946600021853

Epoch: 5| Step: 7
Training loss: 1.3570659160614014
Validation loss: 2.064035786095486

Epoch: 5| Step: 8
Training loss: 2.0932860374450684
Validation loss: 2.0767590051056235

Epoch: 5| Step: 9
Training loss: 1.5666090250015259
Validation loss: 2.061625078160276

Epoch: 5| Step: 10
Training loss: 1.3050053119659424
Validation loss: 2.0848827746606644

Epoch: 206| Step: 0
Training loss: 2.6649329662323
Validation loss: 2.0568452214681976

Epoch: 5| Step: 1
Training loss: 0.7010431885719299
Validation loss: 2.070076782216308

Epoch: 5| Step: 2
Training loss: 1.5674206018447876
Validation loss: 2.0945502763153403

Epoch: 5| Step: 3
Training loss: 1.3004305362701416
Validation loss: 2.0976667686175277

Epoch: 5| Step: 4
Training loss: 2.0817348957061768
Validation loss: 2.083669529166273

Epoch: 5| Step: 5
Training loss: 1.088120937347412
Validation loss: 2.0549790295221473

Epoch: 5| Step: 6
Training loss: 1.3575811386108398
Validation loss: 2.036331799722487

Epoch: 5| Step: 7
Training loss: 1.6753994226455688
Validation loss: 2.017845848555206

Epoch: 5| Step: 8
Training loss: 1.321830153465271
Validation loss: 2.0530105970239125

Epoch: 5| Step: 9
Training loss: 1.1420010328292847
Validation loss: 2.081888259098094

Epoch: 5| Step: 10
Training loss: 1.631110668182373
Validation loss: 2.095410261102902

Epoch: 207| Step: 0
Training loss: 1.4548988342285156
Validation loss: 2.0917803536179247

Epoch: 5| Step: 1
Training loss: 1.7863337993621826
Validation loss: 2.1014947224688787

Epoch: 5| Step: 2
Training loss: 1.3245853185653687
Validation loss: 2.1163338409957064

Epoch: 5| Step: 3
Training loss: 1.3896629810333252
Validation loss: 2.1347913075518865

Epoch: 5| Step: 4
Training loss: 1.7082087993621826
Validation loss: 2.117776152908161

Epoch: 5| Step: 5
Training loss: 1.865535020828247
Validation loss: 2.090137726517134

Epoch: 5| Step: 6
Training loss: 1.618422269821167
Validation loss: 2.0827687632653022

Epoch: 5| Step: 7
Training loss: 0.9406920671463013
Validation loss: 2.057732407764722

Epoch: 5| Step: 8
Training loss: 1.4608421325683594
Validation loss: 2.0544869899749756

Epoch: 5| Step: 9
Training loss: 1.6050517559051514
Validation loss: 2.0542085862928823

Epoch: 5| Step: 10
Training loss: 0.9268151521682739
Validation loss: 2.0422353052323863

Epoch: 208| Step: 0
Training loss: 1.1290777921676636
Validation loss: 2.0516004177831833

Epoch: 5| Step: 1
Training loss: 1.3023204803466797
Validation loss: 2.066042718066964

Epoch: 5| Step: 2
Training loss: 1.1051671504974365
Validation loss: 2.0527731398100495

Epoch: 5| Step: 3
Training loss: 1.2373558282852173
Validation loss: 2.0283754230827413

Epoch: 5| Step: 4
Training loss: 1.4781873226165771
Validation loss: 2.036226616110853

Epoch: 5| Step: 5
Training loss: 1.627683401107788
Validation loss: 2.0227831461096324

Epoch: 5| Step: 6
Training loss: 1.6907951831817627
Validation loss: 2.0508786016894924

Epoch: 5| Step: 7
Training loss: 1.7629722356796265
Validation loss: 2.090958447866542

Epoch: 5| Step: 8
Training loss: 1.5836074352264404
Validation loss: 2.089486386186333

Epoch: 5| Step: 9
Training loss: 1.3463190793991089
Validation loss: 2.123340609253094

Epoch: 5| Step: 10
Training loss: 1.4685190916061401
Validation loss: 2.1173968648397796

Epoch: 209| Step: 0
Training loss: 1.8525949716567993
Validation loss: 2.1209767531323176

Epoch: 5| Step: 1
Training loss: 1.3531038761138916
Validation loss: 2.0997636382297804

Epoch: 5| Step: 2
Training loss: 1.7084457874298096
Validation loss: 2.092785471229143

Epoch: 5| Step: 3
Training loss: 1.111159324645996
Validation loss: 2.095658806062514

Epoch: 5| Step: 4
Training loss: 2.3137106895446777
Validation loss: 2.087196136033663

Epoch: 5| Step: 5
Training loss: 1.3118382692337036
Validation loss: 2.07633142061131

Epoch: 5| Step: 6
Training loss: 1.1342802047729492
Validation loss: 2.083942368466367

Epoch: 5| Step: 7
Training loss: 1.5214707851409912
Validation loss: 2.073162632603799

Epoch: 5| Step: 8
Training loss: 1.2115167379379272
Validation loss: 2.0446569996495403

Epoch: 5| Step: 9
Training loss: 1.0310932397842407
Validation loss: 2.025284218531783

Epoch: 5| Step: 10
Training loss: 1.1303462982177734
Validation loss: 2.0484712175143662

Epoch: 210| Step: 0
Training loss: 1.5478993654251099
Validation loss: 2.0731516576582387

Epoch: 5| Step: 1
Training loss: 1.4518630504608154
Validation loss: 2.086323666316207

Epoch: 5| Step: 2
Training loss: 0.8942568898200989
Validation loss: 2.0768034201796337

Epoch: 5| Step: 3
Training loss: 1.671172857284546
Validation loss: 2.041026976800734

Epoch: 5| Step: 4
Training loss: 2.048687696456909
Validation loss: 2.0200528662691832

Epoch: 5| Step: 5
Training loss: 0.9699681401252747
Validation loss: 2.0246906613790863

Epoch: 5| Step: 6
Training loss: 1.3786357641220093
Validation loss: 2.025523608730685

Epoch: 5| Step: 7
Training loss: 1.3752573728561401
Validation loss: 2.0393804696298417

Epoch: 5| Step: 8
Training loss: 1.5257906913757324
Validation loss: 2.0474671343321442

Epoch: 5| Step: 9
Training loss: 1.4517412185668945
Validation loss: 2.0437255162064747

Epoch: 5| Step: 10
Training loss: 1.3160170316696167
Validation loss: 2.0745079978819816

Epoch: 211| Step: 0
Training loss: 1.3811136484146118
Validation loss: 2.1125769717718965

Epoch: 5| Step: 1
Training loss: 1.5231326818466187
Validation loss: 2.115695943114578

Epoch: 5| Step: 2
Training loss: 1.1498878002166748
Validation loss: 2.09114791757317

Epoch: 5| Step: 3
Training loss: 1.7163200378417969
Validation loss: 2.1326856126067457

Epoch: 5| Step: 4
Training loss: 1.1540625095367432
Validation loss: 2.1018583902748684

Epoch: 5| Step: 5
Training loss: 1.592003583908081
Validation loss: 2.028896583023892

Epoch: 5| Step: 6
Training loss: 1.2409040927886963
Validation loss: 2.011443293222817

Epoch: 5| Step: 7
Training loss: 1.6518173217773438
Validation loss: 2.012054028049592

Epoch: 5| Step: 8
Training loss: 1.1560877561569214
Validation loss: 2.0132944340346963

Epoch: 5| Step: 9
Training loss: 1.4655373096466064
Validation loss: 2.0207701088279806

Epoch: 5| Step: 10
Training loss: 1.7444281578063965
Validation loss: 2.035922428613068

Epoch: 212| Step: 0
Training loss: 1.2525478601455688
Validation loss: 2.045228850456976

Epoch: 5| Step: 1
Training loss: 1.5349665880203247
Validation loss: 2.058683290276476

Epoch: 5| Step: 2
Training loss: 0.7433124780654907
Validation loss: 2.062765170169133

Epoch: 5| Step: 3
Training loss: 1.0849601030349731
Validation loss: 2.0983803028701455

Epoch: 5| Step: 4
Training loss: 1.5108035802841187
Validation loss: 2.1062961034877326

Epoch: 5| Step: 5
Training loss: 2.7714128494262695
Validation loss: 2.1138412901150283

Epoch: 5| Step: 6
Training loss: 1.0771005153656006
Validation loss: 2.1063600022305726

Epoch: 5| Step: 7
Training loss: 1.493523359298706
Validation loss: 2.0896870372115925

Epoch: 5| Step: 8
Training loss: 1.642234444618225
Validation loss: 2.085778779880975

Epoch: 5| Step: 9
Training loss: 1.289768934249878
Validation loss: 2.10321403831564

Epoch: 5| Step: 10
Training loss: 1.6700522899627686
Validation loss: 2.0915502348253803

Epoch: 213| Step: 0
Training loss: 0.968018651008606
Validation loss: 2.060330897249201

Epoch: 5| Step: 1
Training loss: 1.6995187997817993
Validation loss: 2.03784518600792

Epoch: 5| Step: 2
Training loss: 1.188230276107788
Validation loss: 2.020433488712516

Epoch: 5| Step: 3
Training loss: 0.9149802327156067
Validation loss: 2.0382503155739076

Epoch: 5| Step: 4
Training loss: 1.3366262912750244
Validation loss: 2.0567085050767466

Epoch: 5| Step: 5
Training loss: 1.582270622253418
Validation loss: 2.042170656624661

Epoch: 5| Step: 6
Training loss: 1.5910663604736328
Validation loss: 2.0370495755185365

Epoch: 5| Step: 7
Training loss: 1.492040753364563
Validation loss: 2.0148624271474858

Epoch: 5| Step: 8
Training loss: 1.1447792053222656
Validation loss: 2.01730175172129

Epoch: 5| Step: 9
Training loss: 1.6571922302246094
Validation loss: 2.017799841460361

Epoch: 5| Step: 10
Training loss: 1.6872971057891846
Validation loss: 2.0495172700574322

Epoch: 214| Step: 0
Training loss: 0.8581146001815796
Validation loss: 2.0435196404816

Epoch: 5| Step: 1
Training loss: 0.8743804693222046
Validation loss: 2.085827362152838

Epoch: 5| Step: 2
Training loss: 1.5391871929168701
Validation loss: 2.0831349434391147

Epoch: 5| Step: 3
Training loss: 1.563622236251831
Validation loss: 2.0909892923088482

Epoch: 5| Step: 4
Training loss: 1.7594887018203735
Validation loss: 2.0601160141729538

Epoch: 5| Step: 5
Training loss: 0.8675268888473511
Validation loss: 2.0546562735752394

Epoch: 5| Step: 6
Training loss: 1.203385591506958
Validation loss: 2.0362933886948453

Epoch: 5| Step: 7
Training loss: 1.2752816677093506
Validation loss: 2.0507681446690715

Epoch: 5| Step: 8
Training loss: 1.6888606548309326
Validation loss: 2.01971802660214

Epoch: 5| Step: 9
Training loss: 1.8871595859527588
Validation loss: 2.0226864071302515

Epoch: 5| Step: 10
Training loss: 1.372979760169983
Validation loss: 2.0250719208871164

Epoch: 215| Step: 0
Training loss: 1.3172850608825684
Validation loss: 2.0415899176751413

Epoch: 5| Step: 1
Training loss: 1.1316497325897217
Validation loss: 2.01667954075721

Epoch: 5| Step: 2
Training loss: 1.0528655052185059
Validation loss: 2.0276113299913305

Epoch: 5| Step: 3
Training loss: 1.0642836093902588
Validation loss: 2.037797126718747

Epoch: 5| Step: 4
Training loss: 1.6727746725082397
Validation loss: 2.04722023266618

Epoch: 5| Step: 5
Training loss: 1.5564377307891846
Validation loss: 2.0360572517559095

Epoch: 5| Step: 6
Training loss: 1.1498658657073975
Validation loss: 2.057461546313378

Epoch: 5| Step: 7
Training loss: 1.572485327720642
Validation loss: 2.053767145320933

Epoch: 5| Step: 8
Training loss: 1.4273077249526978
Validation loss: 2.0787637079915693

Epoch: 5| Step: 9
Training loss: 1.7571423053741455
Validation loss: 2.0976367150583575

Epoch: 5| Step: 10
Training loss: 1.1424591541290283
Validation loss: 2.1054926085215744

Epoch: 216| Step: 0
Training loss: 1.445652961730957
Validation loss: 2.04930966900241

Epoch: 5| Step: 1
Training loss: 1.543508529663086
Validation loss: 2.019268015379547

Epoch: 5| Step: 2
Training loss: 0.882969856262207
Validation loss: 2.0185224266462427

Epoch: 5| Step: 3
Training loss: 1.7744405269622803
Validation loss: 2.0259602582582863

Epoch: 5| Step: 4
Training loss: 1.1658166646957397
Validation loss: 1.9958633222887594

Epoch: 5| Step: 5
Training loss: 1.410278081893921
Validation loss: 2.0159103306390906

Epoch: 5| Step: 6
Training loss: 0.8037705421447754
Validation loss: 2.000628691847606

Epoch: 5| Step: 7
Training loss: 1.1173372268676758
Validation loss: 2.0093430729322534

Epoch: 5| Step: 8
Training loss: 1.6347545385360718
Validation loss: 2.0303077569571872

Epoch: 5| Step: 9
Training loss: 1.5167078971862793
Validation loss: 2.0351502869718816

Epoch: 5| Step: 10
Training loss: 1.239369511604309
Validation loss: 2.0796085890903266

Epoch: 217| Step: 0
Training loss: 1.1433515548706055
Validation loss: 2.082351517933671

Epoch: 5| Step: 1
Training loss: 0.9690672159194946
Validation loss: 2.051569886105035

Epoch: 5| Step: 2
Training loss: 1.453424334526062
Validation loss: 1.9984611362539313

Epoch: 5| Step: 3
Training loss: 1.5849264860153198
Validation loss: 1.9950800480381135

Epoch: 5| Step: 4
Training loss: 1.0360372066497803
Validation loss: 2.008234998231293

Epoch: 5| Step: 5
Training loss: 1.605942964553833
Validation loss: 2.0462322440198673

Epoch: 5| Step: 6
Training loss: 1.4399911165237427
Validation loss: 2.072026139946394

Epoch: 5| Step: 7
Training loss: 1.6229604482650757
Validation loss: 2.107041069256362

Epoch: 5| Step: 8
Training loss: 1.1664901971817017
Validation loss: 2.0977150496616157

Epoch: 5| Step: 9
Training loss: 1.6662546396255493
Validation loss: 2.0667201242139264

Epoch: 5| Step: 10
Training loss: 0.9259927272796631
Validation loss: 2.016177349193122

Epoch: 218| Step: 0
Training loss: 1.236452579498291
Validation loss: 2.0030572183670534

Epoch: 5| Step: 1
Training loss: 1.1116392612457275
Validation loss: 1.9904283605596071

Epoch: 5| Step: 2
Training loss: 1.1968975067138672
Validation loss: 2.0024096042879167

Epoch: 5| Step: 3
Training loss: 1.4845890998840332
Validation loss: 2.0075040927497287

Epoch: 5| Step: 4
Training loss: 1.653113603591919
Validation loss: 2.010351050284601

Epoch: 5| Step: 5
Training loss: 1.0461317300796509
Validation loss: 2.0350887595966296

Epoch: 5| Step: 6
Training loss: 1.2274491786956787
Validation loss: 2.067568814882668

Epoch: 5| Step: 7
Training loss: 1.5936973094940186
Validation loss: 2.0855814141611897

Epoch: 5| Step: 8
Training loss: 1.4879698753356934
Validation loss: 2.078784783681234

Epoch: 5| Step: 9
Training loss: 1.5307878255844116
Validation loss: 2.0369317993041007

Epoch: 5| Step: 10
Training loss: 0.880687415599823
Validation loss: 2.0182249507596417

Epoch: 219| Step: 0
Training loss: 1.339930772781372
Validation loss: 2.0351465709747805

Epoch: 5| Step: 1
Training loss: 1.6367899179458618
Validation loss: 2.0460574421831357

Epoch: 5| Step: 2
Training loss: 0.8619518280029297
Validation loss: 2.0616351301952074

Epoch: 5| Step: 3
Training loss: 0.8639338612556458
Validation loss: 2.074524712818925

Epoch: 5| Step: 4
Training loss: 1.5619359016418457
Validation loss: 2.1207171409360823

Epoch: 5| Step: 5
Training loss: 2.1253347396850586
Validation loss: 2.174467163701211

Epoch: 5| Step: 6
Training loss: 1.3393402099609375
Validation loss: 2.1469445177303847

Epoch: 5| Step: 7
Training loss: 1.6634546518325806
Validation loss: 2.076807564304721

Epoch: 5| Step: 8
Training loss: 0.9237314462661743
Validation loss: 2.040849310095592

Epoch: 5| Step: 9
Training loss: 0.9535940885543823
Validation loss: 2.01587301300418

Epoch: 5| Step: 10
Training loss: 1.274621844291687
Validation loss: 2.019260298821234

Epoch: 220| Step: 0
Training loss: 0.9512437582015991
Validation loss: 2.004621100682084

Epoch: 5| Step: 1
Training loss: 1.3447959423065186
Validation loss: 2.000189294097244

Epoch: 5| Step: 2
Training loss: 1.3008108139038086
Validation loss: 2.005888277484525

Epoch: 5| Step: 3
Training loss: 1.2516629695892334
Validation loss: 1.997607659268123

Epoch: 5| Step: 4
Training loss: 1.4074994325637817
Validation loss: 2.0335595530848347

Epoch: 5| Step: 5
Training loss: 1.2773447036743164
Validation loss: 2.021876399235059

Epoch: 5| Step: 6
Training loss: 1.4429221153259277
Validation loss: 2.047523847190283

Epoch: 5| Step: 7
Training loss: 0.8264299631118774
Validation loss: 2.0473853747049966

Epoch: 5| Step: 8
Training loss: 1.1443016529083252
Validation loss: 2.041937005135321

Epoch: 5| Step: 9
Training loss: 1.4108331203460693
Validation loss: 2.059122772626979

Epoch: 5| Step: 10
Training loss: 1.6838462352752686
Validation loss: 2.0503125831645024

Epoch: 221| Step: 0
Training loss: 1.676457166671753
Validation loss: 2.044179703599663

Epoch: 5| Step: 1
Training loss: 1.7664554119110107
Validation loss: 2.0207883670765865

Epoch: 5| Step: 2
Training loss: 1.0002233982086182
Validation loss: 2.0195089078718618

Epoch: 5| Step: 3
Training loss: 1.2488806247711182
Validation loss: 2.0144906556734474

Epoch: 5| Step: 4
Training loss: 0.7923955917358398
Validation loss: 2.03749357756748

Epoch: 5| Step: 5
Training loss: 0.9668352007865906
Validation loss: 2.0066438336526193

Epoch: 5| Step: 6
Training loss: 1.3831912279129028
Validation loss: 2.0232422582564817

Epoch: 5| Step: 7
Training loss: 1.1885017156600952
Validation loss: 2.01493247350057

Epoch: 5| Step: 8
Training loss: 1.4900665283203125
Validation loss: 2.046239129958614

Epoch: 5| Step: 9
Training loss: 1.3139890432357788
Validation loss: 2.050492153372816

Epoch: 5| Step: 10
Training loss: 1.1854796409606934
Validation loss: 2.0354060921617734

Epoch: 222| Step: 0
Training loss: 1.1979608535766602
Validation loss: 2.0128189543242097

Epoch: 5| Step: 1
Training loss: 1.349794626235962
Validation loss: 2.013349735608665

Epoch: 5| Step: 2
Training loss: 1.3311628103256226
Validation loss: 1.998760433607204

Epoch: 5| Step: 3
Training loss: 0.7506932616233826
Validation loss: 1.990819832330109

Epoch: 5| Step: 4
Training loss: 1.8697645664215088
Validation loss: 1.9958288079948836

Epoch: 5| Step: 5
Training loss: 0.9978352785110474
Validation loss: 2.030064481560902

Epoch: 5| Step: 6
Training loss: 0.9569217562675476
Validation loss: 2.0416498120113085

Epoch: 5| Step: 7
Training loss: 1.8045222759246826
Validation loss: 2.0789265030173847

Epoch: 5| Step: 8
Training loss: 1.1822102069854736
Validation loss: 2.1121520483365623

Epoch: 5| Step: 9
Training loss: 1.4688645601272583
Validation loss: 2.0819740538956015

Epoch: 5| Step: 10
Training loss: 1.2063369750976562
Validation loss: 2.0500426112964587

Epoch: 223| Step: 0
Training loss: 1.1054109334945679
Validation loss: 1.994573413684804

Epoch: 5| Step: 1
Training loss: 1.4604880809783936
Validation loss: 1.993342459842723

Epoch: 5| Step: 2
Training loss: 1.3114302158355713
Validation loss: 2.015542194407473

Epoch: 5| Step: 3
Training loss: 1.8392508029937744
Validation loss: 2.014432740467851

Epoch: 5| Step: 4
Training loss: 1.2674500942230225
Validation loss: 2.0378057636240476

Epoch: 5| Step: 5
Training loss: 1.4029585123062134
Validation loss: 2.017945558794083

Epoch: 5| Step: 6
Training loss: 1.782588005065918
Validation loss: 2.0662895505146315

Epoch: 5| Step: 7
Training loss: 1.09001886844635
Validation loss: 2.1289763027621853

Epoch: 5| Step: 8
Training loss: 0.8000723123550415
Validation loss: 2.1658257720290974

Epoch: 5| Step: 9
Training loss: 1.4704220294952393
Validation loss: 2.1439214444929555

Epoch: 5| Step: 10
Training loss: 0.7725304961204529
Validation loss: 2.081251211063836

Epoch: 224| Step: 0
Training loss: 1.7636035680770874
Validation loss: 2.040264155275078

Epoch: 5| Step: 1
Training loss: 1.4652265310287476
Validation loss: 2.0108746431207143

Epoch: 5| Step: 2
Training loss: 1.2252013683319092
Validation loss: 1.9988534091621317

Epoch: 5| Step: 3
Training loss: 0.9353524446487427
Validation loss: 1.9622914611652333

Epoch: 5| Step: 4
Training loss: 1.0650298595428467
Validation loss: 1.9666058196816394

Epoch: 5| Step: 5
Training loss: 1.1800321340560913
Validation loss: 1.9611699427327802

Epoch: 5| Step: 6
Training loss: 1.7177015542984009
Validation loss: 2.0291307869777886

Epoch: 5| Step: 7
Training loss: 1.302612543106079
Validation loss: 2.035392665093945

Epoch: 5| Step: 8
Training loss: 1.1002466678619385
Validation loss: 2.0592720970030753

Epoch: 5| Step: 9
Training loss: 1.1777057647705078
Validation loss: 2.0546959279685892

Epoch: 5| Step: 10
Training loss: 1.1116187572479248
Validation loss: 2.0669648519126316

Epoch: 225| Step: 0
Training loss: 0.9475990533828735
Validation loss: 2.082773103508898

Epoch: 5| Step: 1
Training loss: 1.2661043405532837
Validation loss: 2.105412329396894

Epoch: 5| Step: 2
Training loss: 1.1220057010650635
Validation loss: 2.1119087972948627

Epoch: 5| Step: 3
Training loss: 1.2359793186187744
Validation loss: 2.114414706025072

Epoch: 5| Step: 4
Training loss: 1.3459705114364624
Validation loss: 2.0907992727013043

Epoch: 5| Step: 5
Training loss: 1.6124836206436157
Validation loss: 2.0578727465803905

Epoch: 5| Step: 6
Training loss: 1.0757464170455933
Validation loss: 2.040249163104642

Epoch: 5| Step: 7
Training loss: 1.1473290920257568
Validation loss: 1.9996912415309618

Epoch: 5| Step: 8
Training loss: 1.330094575881958
Validation loss: 2.0177503132051036

Epoch: 5| Step: 9
Training loss: 1.712186574935913
Validation loss: 2.006361053835961

Epoch: 5| Step: 10
Training loss: 1.1734617948532104
Validation loss: 2.015458330031364

Epoch: 226| Step: 0
Training loss: 0.971749484539032
Validation loss: 2.0429047640933784

Epoch: 5| Step: 1
Training loss: 1.0927544832229614
Validation loss: 2.0206221354904996

Epoch: 5| Step: 2
Training loss: 1.2292743921279907
Validation loss: 2.019300599252024

Epoch: 5| Step: 3
Training loss: 1.320951223373413
Validation loss: 2.012198084144182

Epoch: 5| Step: 4
Training loss: 1.027177095413208
Validation loss: 2.005718442701524

Epoch: 5| Step: 5
Training loss: 0.9560655355453491
Validation loss: 2.0191290147842897

Epoch: 5| Step: 6
Training loss: 0.758320152759552
Validation loss: 2.0495400121135097

Epoch: 5| Step: 7
Training loss: 1.2721340656280518
Validation loss: 2.021983754250311

Epoch: 5| Step: 8
Training loss: 1.5796416997909546
Validation loss: 2.0572556231611516

Epoch: 5| Step: 9
Training loss: 1.5612826347351074
Validation loss: 2.1032917858451925

Epoch: 5| Step: 10
Training loss: 1.9485085010528564
Validation loss: 2.1371437375263502

Epoch: 227| Step: 0
Training loss: 1.1834453344345093
Validation loss: 2.140634867452806

Epoch: 5| Step: 1
Training loss: 1.8218885660171509
Validation loss: 2.11682919533022

Epoch: 5| Step: 2
Training loss: 0.9222240447998047
Validation loss: 2.051324498268866

Epoch: 5| Step: 3
Training loss: 1.1156644821166992
Validation loss: 2.052093723768829

Epoch: 5| Step: 4
Training loss: 1.454058289527893
Validation loss: 2.0313468030703965

Epoch: 5| Step: 5
Training loss: 0.8893038034439087
Validation loss: 2.019455873838035

Epoch: 5| Step: 6
Training loss: 1.2248220443725586
Validation loss: 2.025635152734736

Epoch: 5| Step: 7
Training loss: 0.9716499447822571
Validation loss: 2.013480603054006

Epoch: 5| Step: 8
Training loss: 1.7383251190185547
Validation loss: 1.9802368058953235

Epoch: 5| Step: 9
Training loss: 1.4976390600204468
Validation loss: 2.0049408751149334

Epoch: 5| Step: 10
Training loss: 0.9309362769126892
Validation loss: 2.0498814018823768

Epoch: 228| Step: 0
Training loss: 0.8217344284057617
Validation loss: 2.0823594024104457

Epoch: 5| Step: 1
Training loss: 1.1823039054870605
Validation loss: 2.1007322495983494

Epoch: 5| Step: 2
Training loss: 1.7138677835464478
Validation loss: 2.072419176819504

Epoch: 5| Step: 3
Training loss: 0.9642131924629211
Validation loss: 2.048955027775098

Epoch: 5| Step: 4
Training loss: 0.7852258682250977
Validation loss: 2.0104532754549416

Epoch: 5| Step: 5
Training loss: 2.026177406311035
Validation loss: 1.9804496842045938

Epoch: 5| Step: 6
Training loss: 0.6702935099601746
Validation loss: 1.9637158250295987

Epoch: 5| Step: 7
Training loss: 1.1237398386001587
Validation loss: 1.9746021198970016

Epoch: 5| Step: 8
Training loss: 0.9209022521972656
Validation loss: 1.9824725120298323

Epoch: 5| Step: 9
Training loss: 1.6117229461669922
Validation loss: 1.9655326104933215

Epoch: 5| Step: 10
Training loss: 1.6052387952804565
Validation loss: 1.9790234411916425

Epoch: 229| Step: 0
Training loss: 1.137196660041809
Validation loss: 2.0352180645030034

Epoch: 5| Step: 1
Training loss: 2.121799945831299
Validation loss: 2.0846689337043354

Epoch: 5| Step: 2
Training loss: 1.3560857772827148
Validation loss: 2.170785898803383

Epoch: 5| Step: 3
Training loss: 1.3096578121185303
Validation loss: 2.2236806256796724

Epoch: 5| Step: 4
Training loss: 1.0729517936706543
Validation loss: 2.1811935106913247

Epoch: 5| Step: 5
Training loss: 1.4685585498809814
Validation loss: 2.1048327440856607

Epoch: 5| Step: 6
Training loss: 1.034374475479126
Validation loss: 1.9943356180703768

Epoch: 5| Step: 7
Training loss: 1.367687463760376
Validation loss: 1.9823129459093976

Epoch: 5| Step: 8
Training loss: 1.072936773300171
Validation loss: 1.9813130670978176

Epoch: 5| Step: 9
Training loss: 1.1473040580749512
Validation loss: 1.9909336656652472

Epoch: 5| Step: 10
Training loss: 1.4431582689285278
Validation loss: 1.987704441111575

Epoch: 230| Step: 0
Training loss: 0.7532850503921509
Validation loss: 1.9909030493869577

Epoch: 5| Step: 1
Training loss: 0.9053619503974915
Validation loss: 1.9949357330158193

Epoch: 5| Step: 2
Training loss: 0.7933006286621094
Validation loss: 2.026228707323792

Epoch: 5| Step: 3
Training loss: 1.2208999395370483
Validation loss: 2.0727199123751734

Epoch: 5| Step: 4
Training loss: 1.6678730249404907
Validation loss: 2.1005607189670688

Epoch: 5| Step: 5
Training loss: 1.3124040365219116
Validation loss: 2.1175206784279115

Epoch: 5| Step: 6
Training loss: 1.2360050678253174
Validation loss: 2.1094379014866327

Epoch: 5| Step: 7
Training loss: 0.8882671594619751
Validation loss: 2.0851235761437366

Epoch: 5| Step: 8
Training loss: 1.5491498708724976
Validation loss: 2.0575812632037747

Epoch: 5| Step: 9
Training loss: 1.1220619678497314
Validation loss: 2.0321975959244596

Epoch: 5| Step: 10
Training loss: 1.5633485317230225
Validation loss: 2.041776967305009

Epoch: 231| Step: 0
Training loss: 0.8757351040840149
Validation loss: 2.0688649723606725

Epoch: 5| Step: 1
Training loss: 1.2285290956497192
Validation loss: 2.0901168059277278

Epoch: 5| Step: 2
Training loss: 1.2287614345550537
Validation loss: 2.097300893516951

Epoch: 5| Step: 3
Training loss: 1.323073148727417
Validation loss: 2.113921662812592

Epoch: 5| Step: 4
Training loss: 0.7569026947021484
Validation loss: 2.1636614004770913

Epoch: 5| Step: 5
Training loss: 1.5370429754257202
Validation loss: 2.187147363539665

Epoch: 5| Step: 6
Training loss: 1.1344501972198486
Validation loss: 2.1763707553186724

Epoch: 5| Step: 7
Training loss: 1.74080491065979
Validation loss: 2.1783861883224978

Epoch: 5| Step: 8
Training loss: 1.2684118747711182
Validation loss: 2.077160040537516

Epoch: 5| Step: 9
Training loss: 1.5688146352767944
Validation loss: 2.0126892956354285

Epoch: 5| Step: 10
Training loss: 1.0290764570236206
Validation loss: 1.9784630267850813

Epoch: 232| Step: 0
Training loss: 1.4569642543792725
Validation loss: 1.9232039887418029

Epoch: 5| Step: 1
Training loss: 1.4854681491851807
Validation loss: 1.9113171023707236

Epoch: 5| Step: 2
Training loss: 1.0452165603637695
Validation loss: 1.888168805388994

Epoch: 5| Step: 3
Training loss: 1.1740925312042236
Validation loss: 1.8699532452450003

Epoch: 5| Step: 4
Training loss: 1.347385048866272
Validation loss: 1.9077429950878184

Epoch: 5| Step: 5
Training loss: 0.9329419136047363
Validation loss: 1.9444052314245572

Epoch: 5| Step: 6
Training loss: 1.4026799201965332
Validation loss: 1.9922506604143368

Epoch: 5| Step: 7
Training loss: 1.12714684009552
Validation loss: 2.009010441841618

Epoch: 5| Step: 8
Training loss: 1.1146036386489868
Validation loss: 2.007437462447792

Epoch: 5| Step: 9
Training loss: 1.327146053314209
Validation loss: 2.056760190635599

Epoch: 5| Step: 10
Training loss: 1.3979097604751587
Validation loss: 2.0399316856938023

Epoch: 233| Step: 0
Training loss: 1.3902199268341064
Validation loss: 2.0401458945325626

Epoch: 5| Step: 1
Training loss: 0.8326260447502136
Validation loss: 2.0726362582175963

Epoch: 5| Step: 2
Training loss: 1.6917049884796143
Validation loss: 2.0785581219580864

Epoch: 5| Step: 3
Training loss: 1.4320824146270752
Validation loss: 2.0793314762012933

Epoch: 5| Step: 4
Training loss: 1.0678240060806274
Validation loss: 2.124665089832839

Epoch: 5| Step: 5
Training loss: 1.2351957559585571
Validation loss: 2.1052585763316

Epoch: 5| Step: 6
Training loss: 0.8929430842399597
Validation loss: 2.091947845233384

Epoch: 5| Step: 7
Training loss: 1.5853632688522339
Validation loss: 2.038630703444122

Epoch: 5| Step: 8
Training loss: 0.8186931610107422
Validation loss: 2.043578367079458

Epoch: 5| Step: 9
Training loss: 1.131636381149292
Validation loss: 2.0276434447175715

Epoch: 5| Step: 10
Training loss: 0.8553215265274048
Validation loss: 2.0205741864378735

Epoch: 234| Step: 0
Training loss: 0.7649110555648804
Validation loss: 1.9922175612500919

Epoch: 5| Step: 1
Training loss: 1.112890601158142
Validation loss: 1.9768365660021383

Epoch: 5| Step: 2
Training loss: 0.9598253965377808
Validation loss: 1.9595015048980713

Epoch: 5| Step: 3
Training loss: 1.1097548007965088
Validation loss: 1.9736519077772736

Epoch: 5| Step: 4
Training loss: 1.7647384405136108
Validation loss: 1.9566156889802666

Epoch: 5| Step: 5
Training loss: 1.5235717296600342
Validation loss: 1.9645729782760784

Epoch: 5| Step: 6
Training loss: 1.4904643297195435
Validation loss: 2.0015439371908865

Epoch: 5| Step: 7
Training loss: 1.2844984531402588
Validation loss: 2.0188059742732714

Epoch: 5| Step: 8
Training loss: 1.1597493886947632
Validation loss: 2.0409200691407725

Epoch: 5| Step: 9
Training loss: 0.8074003458023071
Validation loss: 2.050608620848707

Epoch: 5| Step: 10
Training loss: 0.997416079044342
Validation loss: 2.0471149183088735

Epoch: 235| Step: 0
Training loss: 1.3816550970077515
Validation loss: 2.064155283794608

Epoch: 5| Step: 1
Training loss: 1.0585403442382812
Validation loss: 2.0623969570282967

Epoch: 5| Step: 2
Training loss: 0.9903335571289062
Validation loss: 2.054936416687504

Epoch: 5| Step: 3
Training loss: 1.1705316305160522
Validation loss: 2.039145105628557

Epoch: 5| Step: 4
Training loss: 1.0507621765136719
Validation loss: 2.012387979415155

Epoch: 5| Step: 5
Training loss: 0.5590230226516724
Validation loss: 2.0074728560704056

Epoch: 5| Step: 6
Training loss: 0.9787516593933105
Validation loss: 1.9876028465968307

Epoch: 5| Step: 7
Training loss: 1.9949061870574951
Validation loss: 1.9734799426089051

Epoch: 5| Step: 8
Training loss: 0.878614604473114
Validation loss: 1.97506897423857

Epoch: 5| Step: 9
Training loss: 1.517223596572876
Validation loss: 1.9569055418814383

Epoch: 5| Step: 10
Training loss: 1.0079929828643799
Validation loss: 1.964259345044372

Epoch: 236| Step: 0
Training loss: 1.1241575479507446
Validation loss: 1.9761813507285169

Epoch: 5| Step: 1
Training loss: 1.249418020248413
Validation loss: 1.98594041280849

Epoch: 5| Step: 2
Training loss: 0.8584233522415161
Validation loss: 2.0156539640119

Epoch: 5| Step: 3
Training loss: 1.1015770435333252
Validation loss: 2.0536957017837034

Epoch: 5| Step: 4
Training loss: 1.187347412109375
Validation loss: 2.0978978359571068

Epoch: 5| Step: 5
Training loss: 1.180315375328064
Validation loss: 2.1268409477767123

Epoch: 5| Step: 6
Training loss: 1.3357999324798584
Validation loss: 2.1486564336284513

Epoch: 5| Step: 7
Training loss: 1.0993058681488037
Validation loss: 2.1248697350102086

Epoch: 5| Step: 8
Training loss: 0.8834436535835266
Validation loss: 2.081733067830404

Epoch: 5| Step: 9
Training loss: 1.1812434196472168
Validation loss: 2.0222435933287426

Epoch: 5| Step: 10
Training loss: 1.037007451057434
Validation loss: 1.9905874729156494

Epoch: 237| Step: 0
Training loss: 1.3476417064666748
Validation loss: 1.9931689641808952

Epoch: 5| Step: 1
Training loss: 1.2181764841079712
Validation loss: 1.9872882622544483

Epoch: 5| Step: 2
Training loss: 1.3662458658218384
Validation loss: 1.984362038232947

Epoch: 5| Step: 3
Training loss: 1.043682336807251
Validation loss: 1.9826647491865261

Epoch: 5| Step: 4
Training loss: 0.8984795808792114
Validation loss: 1.9905103650144351

Epoch: 5| Step: 5
Training loss: 1.0990660190582275
Validation loss: 2.0482285202190442

Epoch: 5| Step: 6
Training loss: 1.272642970085144
Validation loss: 2.0925268614163963

Epoch: 5| Step: 7
Training loss: 0.8331344723701477
Validation loss: 2.070355692217427

Epoch: 5| Step: 8
Training loss: 1.1962248086929321
Validation loss: 2.0253154398292623

Epoch: 5| Step: 9
Training loss: 1.7374114990234375
Validation loss: 1.9994930951826033

Epoch: 5| Step: 10
Training loss: 0.7602952122688293
Validation loss: 1.97775895877551

Epoch: 238| Step: 0
Training loss: 1.085268259048462
Validation loss: 1.9859408986183904

Epoch: 5| Step: 1
Training loss: 1.4935497045516968
Validation loss: 2.000877006079561

Epoch: 5| Step: 2
Training loss: 1.119542121887207
Validation loss: 2.0046182652955413

Epoch: 5| Step: 3
Training loss: 1.3126475811004639
Validation loss: 2.003977152609056

Epoch: 5| Step: 4
Training loss: 1.1028448343276978
Validation loss: 2.011348480819374

Epoch: 5| Step: 5
Training loss: 0.7957266569137573
Validation loss: 2.0294015817744757

Epoch: 5| Step: 6
Training loss: 1.4954211711883545
Validation loss: 2.070594810670422

Epoch: 5| Step: 7
Training loss: 1.099124789237976
Validation loss: 2.102172745171414

Epoch: 5| Step: 8
Training loss: 1.0101840496063232
Validation loss: 2.139650962686026

Epoch: 5| Step: 9
Training loss: 1.048537015914917
Validation loss: 2.1190452652592815

Epoch: 5| Step: 10
Training loss: 1.0116868019104004
Validation loss: 2.036141559641848

Epoch: 239| Step: 0
Training loss: 0.9008327722549438
Validation loss: 1.9731027413440008

Epoch: 5| Step: 1
Training loss: 0.41314539313316345
Validation loss: 1.9565978998778968

Epoch: 5| Step: 2
Training loss: 1.5426985025405884
Validation loss: 1.9637766140763477

Epoch: 5| Step: 3
Training loss: 1.0706336498260498
Validation loss: 1.983956875339631

Epoch: 5| Step: 4
Training loss: 1.5619652271270752
Validation loss: 1.9923169894884991

Epoch: 5| Step: 5
Training loss: 1.127591609954834
Validation loss: 2.0044603963052072

Epoch: 5| Step: 6
Training loss: 1.315840721130371
Validation loss: 1.999774887997617

Epoch: 5| Step: 7
Training loss: 1.2690742015838623
Validation loss: 2.031539770864671

Epoch: 5| Step: 8
Training loss: 0.9194320440292358
Validation loss: 2.0668588953633464

Epoch: 5| Step: 9
Training loss: 1.1027356386184692
Validation loss: 2.0650016800049813

Epoch: 5| Step: 10
Training loss: 1.2624343633651733
Validation loss: 2.0835752999910744

Epoch: 240| Step: 0
Training loss: 1.0341143608093262
Validation loss: 2.0453869553022486

Epoch: 5| Step: 1
Training loss: 1.5349042415618896
Validation loss: 2.0041800698926373

Epoch: 5| Step: 2
Training loss: 1.0381453037261963
Validation loss: 1.9862761805134435

Epoch: 5| Step: 3
Training loss: 1.0596222877502441
Validation loss: 1.9844225657883512

Epoch: 5| Step: 4
Training loss: 1.218937635421753
Validation loss: 1.9866308140498337

Epoch: 5| Step: 5
Training loss: 1.1675771474838257
Validation loss: 1.9801514353803409

Epoch: 5| Step: 6
Training loss: 1.1478418111801147
Validation loss: 1.9791494338743147

Epoch: 5| Step: 7
Training loss: 0.8307741284370422
Validation loss: 2.0067034895702074

Epoch: 5| Step: 8
Training loss: 1.0015214681625366
Validation loss: 2.0071869255394064

Epoch: 5| Step: 9
Training loss: 1.0198757648468018
Validation loss: 2.025166892236279

Epoch: 5| Step: 10
Training loss: 1.0612297058105469
Validation loss: 2.0348184595825853

Epoch: 241| Step: 0
Training loss: 1.5909488201141357
Validation loss: 2.0137243399056057

Epoch: 5| Step: 1
Training loss: 1.2712936401367188
Validation loss: 1.976345915948191

Epoch: 5| Step: 2
Training loss: 1.1295225620269775
Validation loss: 1.968027263559321

Epoch: 5| Step: 3
Training loss: 0.48073846101760864
Validation loss: 1.9607366259380052

Epoch: 5| Step: 4
Training loss: 0.7852216958999634
Validation loss: 1.9313940335345525

Epoch: 5| Step: 5
Training loss: 1.0537415742874146
Validation loss: 1.932395770985593

Epoch: 5| Step: 6
Training loss: 0.8199920654296875
Validation loss: 1.9393251762595227

Epoch: 5| Step: 7
Training loss: 0.9399453997612
Validation loss: 1.9487628065129763

Epoch: 5| Step: 8
Training loss: 0.8886104822158813
Validation loss: 1.9740107213297198

Epoch: 5| Step: 9
Training loss: 1.3063232898712158
Validation loss: 1.9656204844033847

Epoch: 5| Step: 10
Training loss: 1.5956929922103882
Validation loss: 2.017644730947351

Epoch: 242| Step: 0
Training loss: 1.0196317434310913
Validation loss: 2.0231697341447235

Epoch: 5| Step: 1
Training loss: 0.9221920967102051
Validation loss: 2.02174735325639

Epoch: 5| Step: 2
Training loss: 1.410649299621582
Validation loss: 2.0133365713140017

Epoch: 5| Step: 3
Training loss: 1.1215083599090576
Validation loss: 2.0091223768008653

Epoch: 5| Step: 4
Training loss: 0.6428459286689758
Validation loss: 1.9809813268723027

Epoch: 5| Step: 5
Training loss: 1.033738374710083
Validation loss: 1.9943448753767117

Epoch: 5| Step: 6
Training loss: 1.3082656860351562
Validation loss: 1.9654694834063131

Epoch: 5| Step: 7
Training loss: 0.9059768915176392
Validation loss: 1.9499836185927033

Epoch: 5| Step: 8
Training loss: 0.7100216746330261
Validation loss: 1.9664305333168275

Epoch: 5| Step: 9
Training loss: 1.2069634199142456
Validation loss: 2.0006757372169086

Epoch: 5| Step: 10
Training loss: 1.557385802268982
Validation loss: 2.0482187476209415

Epoch: 243| Step: 0
Training loss: 0.7588165998458862
Validation loss: 2.0927849149191253

Epoch: 5| Step: 1
Training loss: 1.3236103057861328
Validation loss: 2.0548329507150958

Epoch: 5| Step: 2
Training loss: 1.1568642854690552
Validation loss: 2.031875906452056

Epoch: 5| Step: 3
Training loss: 0.9703640937805176
Validation loss: 1.9753416943293747

Epoch: 5| Step: 4
Training loss: 1.3154445886611938
Validation loss: 1.947733643234417

Epoch: 5| Step: 5
Training loss: 0.3746655583381653
Validation loss: 1.9527381363735403

Epoch: 5| Step: 6
Training loss: 1.1359093189239502
Validation loss: 1.9494568276148971

Epoch: 5| Step: 7
Training loss: 0.8176409006118774
Validation loss: 1.9468836156270837

Epoch: 5| Step: 8
Training loss: 1.6858718395233154
Validation loss: 1.9474366736668411

Epoch: 5| Step: 9
Training loss: 1.0398280620574951
Validation loss: 1.9481537803526847

Epoch: 5| Step: 10
Training loss: 1.3482054471969604
Validation loss: 1.9809268507906186

Epoch: 244| Step: 0
Training loss: 1.5712053775787354
Validation loss: 2.012691428584437

Epoch: 5| Step: 1
Training loss: 0.8491511344909668
Validation loss: 2.0438070758696525

Epoch: 5| Step: 2
Training loss: 1.381014347076416
Validation loss: 2.0510880062657018

Epoch: 5| Step: 3
Training loss: 0.6538354158401489
Validation loss: 1.9986675080432688

Epoch: 5| Step: 4
Training loss: 0.9269424676895142
Validation loss: 1.9684794910492436

Epoch: 5| Step: 5
Training loss: 1.4921655654907227
Validation loss: 1.9604547895411009

Epoch: 5| Step: 6
Training loss: 0.8052440881729126
Validation loss: 1.9501849835918796

Epoch: 5| Step: 7
Training loss: 0.7920238375663757
Validation loss: 1.9543361740727578

Epoch: 5| Step: 8
Training loss: 0.9539326429367065
Validation loss: 1.9602616525465442

Epoch: 5| Step: 9
Training loss: 1.0188114643096924
Validation loss: 1.9967322118820683

Epoch: 5| Step: 10
Training loss: 1.0781599283218384
Validation loss: 2.008027785567827

Epoch: 245| Step: 0
Training loss: 1.0062849521636963
Validation loss: 2.0316847306425854

Epoch: 5| Step: 1
Training loss: 1.369629144668579
Validation loss: 2.0536850780569096

Epoch: 5| Step: 2
Training loss: 1.0884766578674316
Validation loss: 2.045988468713658

Epoch: 5| Step: 3
Training loss: 0.8551225662231445
Validation loss: 2.04481848337317

Epoch: 5| Step: 4
Training loss: 1.0201902389526367
Validation loss: 2.052677277595766

Epoch: 5| Step: 5
Training loss: 0.7293241024017334
Validation loss: 2.009287444494104

Epoch: 5| Step: 6
Training loss: 1.0154651403427124
Validation loss: 1.9743926166206278

Epoch: 5| Step: 7
Training loss: 1.0436201095581055
Validation loss: 1.9784122167095062

Epoch: 5| Step: 8
Training loss: 0.7900496125221252
Validation loss: 1.9617096724048737

Epoch: 5| Step: 9
Training loss: 0.8469220995903015
Validation loss: 1.9491475384722474

Epoch: 5| Step: 10
Training loss: 1.5593256950378418
Validation loss: 1.944521898864418

Epoch: 246| Step: 0
Training loss: 0.9258052706718445
Validation loss: 1.9524619246041903

Epoch: 5| Step: 1
Training loss: 0.6280535459518433
Validation loss: 1.9612756224088772

Epoch: 5| Step: 2
Training loss: 1.1981308460235596
Validation loss: 1.9789046036299838

Epoch: 5| Step: 3
Training loss: 1.4898817539215088
Validation loss: 1.9897633649969613

Epoch: 5| Step: 4
Training loss: 1.0662672519683838
Validation loss: 1.984406530216176

Epoch: 5| Step: 5
Training loss: 1.261509656906128
Validation loss: 2.0033622313571233

Epoch: 5| Step: 6
Training loss: 0.8211991190910339
Validation loss: 1.9905906620846

Epoch: 5| Step: 7
Training loss: 0.7714108228683472
Validation loss: 2.0216806575816166

Epoch: 5| Step: 8
Training loss: 0.7914578318595886
Validation loss: 2.0180778093235467

Epoch: 5| Step: 9
Training loss: 1.493182897567749
Validation loss: 2.02447493614689

Epoch: 5| Step: 10
Training loss: 0.7290753722190857
Validation loss: 2.026616232369536

Epoch: 247| Step: 0
Training loss: 0.9435917735099792
Validation loss: 2.0020040260848178

Epoch: 5| Step: 1
Training loss: 0.7344738841056824
Validation loss: 1.9706762195915304

Epoch: 5| Step: 2
Training loss: 1.0506631135940552
Validation loss: 1.9521006089384838

Epoch: 5| Step: 3
Training loss: 1.0580823421478271
Validation loss: 1.9382350137156825

Epoch: 5| Step: 4
Training loss: 0.938908576965332
Validation loss: 1.9524535684175388

Epoch: 5| Step: 5
Training loss: 0.9406893849372864
Validation loss: 1.97348335096913

Epoch: 5| Step: 6
Training loss: 1.0203378200531006
Validation loss: 2.0120313013753583

Epoch: 5| Step: 7
Training loss: 1.7325313091278076
Validation loss: 2.043496677952428

Epoch: 5| Step: 8
Training loss: 0.8462664484977722
Validation loss: 2.034271679898744

Epoch: 5| Step: 9
Training loss: 1.444492220878601
Validation loss: 2.0069693211586244

Epoch: 5| Step: 10
Training loss: 0.5206856727600098
Validation loss: 1.9795807728203394

Epoch: 248| Step: 0
Training loss: 0.6857223510742188
Validation loss: 1.9280240061462566

Epoch: 5| Step: 1
Training loss: 0.9999938011169434
Validation loss: 1.922138939621628

Epoch: 5| Step: 2
Training loss: 1.8859001398086548
Validation loss: 1.9339145998800955

Epoch: 5| Step: 3
Training loss: 1.1135292053222656
Validation loss: 1.9281710988731795

Epoch: 5| Step: 4
Training loss: 0.8330904245376587
Validation loss: 1.9293777519656765

Epoch: 5| Step: 5
Training loss: 1.0554444789886475
Validation loss: 1.9699099730419856

Epoch: 5| Step: 6
Training loss: 0.9933778047561646
Validation loss: 1.9369301616504628

Epoch: 5| Step: 7
Training loss: 0.656303882598877
Validation loss: 1.9640349829068748

Epoch: 5| Step: 8
Training loss: 0.6658682227134705
Validation loss: 1.9820213599871563

Epoch: 5| Step: 9
Training loss: 0.9795069694519043
Validation loss: 1.983511483797463

Epoch: 5| Step: 10
Training loss: 0.8121589422225952
Validation loss: 1.9739683007681241

Epoch: 249| Step: 0
Training loss: 0.6186462640762329
Validation loss: 1.996662344983829

Epoch: 5| Step: 1
Training loss: 0.6923430562019348
Validation loss: 1.9762322633497176

Epoch: 5| Step: 2
Training loss: 0.9442414045333862
Validation loss: 2.003909916006109

Epoch: 5| Step: 3
Training loss: 0.957990825176239
Validation loss: 1.9853339220887871

Epoch: 5| Step: 4
Training loss: 1.1100225448608398
Validation loss: 1.9718124853667391

Epoch: 5| Step: 5
Training loss: 1.4040206670761108
Validation loss: 1.967421462458949

Epoch: 5| Step: 6
Training loss: 1.0594009160995483
Validation loss: 1.9878108462979716

Epoch: 5| Step: 7
Training loss: 0.9738454818725586
Validation loss: 1.9676681974882722

Epoch: 5| Step: 8
Training loss: 0.5597611665725708
Validation loss: 1.957156035207933

Epoch: 5| Step: 9
Training loss: 0.9456942677497864
Validation loss: 1.954193381853001

Epoch: 5| Step: 10
Training loss: 1.3629564046859741
Validation loss: 1.94451863919535

Epoch: 250| Step: 0
Training loss: 1.0400327444076538
Validation loss: 1.926007818150264

Epoch: 5| Step: 1
Training loss: 0.9938977956771851
Validation loss: 1.9202591885802567

Epoch: 5| Step: 2
Training loss: 0.6604822278022766
Validation loss: 1.925082024707589

Epoch: 5| Step: 3
Training loss: 0.9417091608047485
Validation loss: 1.9362990689534012

Epoch: 5| Step: 4
Training loss: 0.9627838134765625
Validation loss: 1.9434893746529855

Epoch: 5| Step: 5
Training loss: 1.0412452220916748
Validation loss: 1.9555382190212127

Epoch: 5| Step: 6
Training loss: 1.0594857931137085
Validation loss: 1.9852628195157616

Epoch: 5| Step: 7
Training loss: 0.6626279950141907
Validation loss: 1.9912071638209845

Epoch: 5| Step: 8
Training loss: 1.2567192316055298
Validation loss: 1.9791608446387834

Epoch: 5| Step: 9
Training loss: 0.7993543744087219
Validation loss: 1.9667620376874042

Epoch: 5| Step: 10
Training loss: 1.177305817604065
Validation loss: 1.980452440118277

Epoch: 251| Step: 0
Training loss: 0.914753794670105
Validation loss: 1.937167658600756

Epoch: 5| Step: 1
Training loss: 0.6300954818725586
Validation loss: 1.9376736302529611

Epoch: 5| Step: 2
Training loss: 0.6323341727256775
Validation loss: 1.936722642631941

Epoch: 5| Step: 3
Training loss: 1.0501279830932617
Validation loss: 1.9454761602545296

Epoch: 5| Step: 4
Training loss: 1.532586693763733
Validation loss: 1.9225570771002

Epoch: 5| Step: 5
Training loss: 0.8648208379745483
Validation loss: 1.946542050248833

Epoch: 5| Step: 6
Training loss: 0.8368561863899231
Validation loss: 1.9681429632248417

Epoch: 5| Step: 7
Training loss: 1.2274644374847412
Validation loss: 1.9382085864261915

Epoch: 5| Step: 8
Training loss: 1.2581623792648315
Validation loss: 1.9650890365723641

Epoch: 5| Step: 9
Training loss: 0.6653725504875183
Validation loss: 1.9417335948636454

Epoch: 5| Step: 10
Training loss: 0.9350723028182983
Validation loss: 1.945016130324333

Epoch: 252| Step: 0
Training loss: 0.6357563734054565
Validation loss: 1.928919453133819

Epoch: 5| Step: 1
Training loss: 0.6664648056030273
Validation loss: 1.9418184295777352

Epoch: 5| Step: 2
Training loss: 0.9215404391288757
Validation loss: 1.9439613383303407

Epoch: 5| Step: 3
Training loss: 0.9422379732131958
Validation loss: 1.9489341333348265

Epoch: 5| Step: 4
Training loss: 0.8781010508537292
Validation loss: 1.9516080733268493

Epoch: 5| Step: 5
Training loss: 1.3247073888778687
Validation loss: 1.951874352270557

Epoch: 5| Step: 6
Training loss: 1.033569574356079
Validation loss: 1.958061275943633

Epoch: 5| Step: 7
Training loss: 0.9893859028816223
Validation loss: 1.949736943808935

Epoch: 5| Step: 8
Training loss: 1.095855951309204
Validation loss: 1.928818125878611

Epoch: 5| Step: 9
Training loss: 0.792201817035675
Validation loss: 1.9181890769671368

Epoch: 5| Step: 10
Training loss: 0.9567189812660217
Validation loss: 1.900189738119802

Epoch: 253| Step: 0
Training loss: 1.0699783563613892
Validation loss: 1.908213351362495

Epoch: 5| Step: 1
Training loss: 0.8262613415718079
Validation loss: 1.9153512472747474

Epoch: 5| Step: 2
Training loss: 1.1242506504058838
Validation loss: 1.9284228765836327

Epoch: 5| Step: 3
Training loss: 1.129236102104187
Validation loss: 1.924299350348852

Epoch: 5| Step: 4
Training loss: 0.7284348607063293
Validation loss: 1.9477985905062767

Epoch: 5| Step: 5
Training loss: 0.6431073546409607
Validation loss: 1.9577537813494283

Epoch: 5| Step: 6
Training loss: 1.457068681716919
Validation loss: 1.974226144052321

Epoch: 5| Step: 7
Training loss: 0.7819852828979492
Validation loss: 1.9686169470510175

Epoch: 5| Step: 8
Training loss: 0.6698447465896606
Validation loss: 1.9245166752928047

Epoch: 5| Step: 9
Training loss: 1.0822274684906006
Validation loss: 1.9025145756301058

Epoch: 5| Step: 10
Training loss: 0.8095238208770752
Validation loss: 1.920236623415383

Epoch: 254| Step: 0
Training loss: 1.0128214359283447
Validation loss: 1.9229919038793093

Epoch: 5| Step: 1
Training loss: 1.0718028545379639
Validation loss: 1.9405159488801034

Epoch: 5| Step: 2
Training loss: 0.989229679107666
Validation loss: 1.9359459851377754

Epoch: 5| Step: 3
Training loss: 0.9546672701835632
Validation loss: 1.9647248355291222

Epoch: 5| Step: 4
Training loss: 1.2668778896331787
Validation loss: 1.992500933267737

Epoch: 5| Step: 5
Training loss: 0.5735039710998535
Validation loss: 2.017796283127159

Epoch: 5| Step: 6
Training loss: 0.6947733759880066
Validation loss: 2.0113975771011843

Epoch: 5| Step: 7
Training loss: 0.5936360955238342
Validation loss: 1.9696773636725642

Epoch: 5| Step: 8
Training loss: 1.116615653038025
Validation loss: 1.9392491604692192

Epoch: 5| Step: 9
Training loss: 0.6993288993835449
Validation loss: 1.923920032798603

Epoch: 5| Step: 10
Training loss: 1.1507833003997803
Validation loss: 1.8997958052542903

Epoch: 255| Step: 0
Training loss: 0.9335876703262329
Validation loss: 1.9136442189575524

Epoch: 5| Step: 1
Training loss: 0.5284671187400818
Validation loss: 1.9186620045733709

Epoch: 5| Step: 2
Training loss: 0.6377665400505066
Validation loss: 1.9248819223014257

Epoch: 5| Step: 3
Training loss: 1.2895565032958984
Validation loss: 1.90443084573233

Epoch: 5| Step: 4
Training loss: 1.0240998268127441
Validation loss: 1.9366592925081971

Epoch: 5| Step: 5
Training loss: 0.916583240032196
Validation loss: 1.9282632130448536

Epoch: 5| Step: 6
Training loss: 1.0130795240402222
Validation loss: 1.9354792820510043

Epoch: 5| Step: 7
Training loss: 0.7890408635139465
Validation loss: 1.9166356927605086

Epoch: 5| Step: 8
Training loss: 1.1266039609909058
Validation loss: 1.9216433776322233

Epoch: 5| Step: 9
Training loss: 0.8422822952270508
Validation loss: 1.9344104131062825

Epoch: 5| Step: 10
Training loss: 0.550767719745636
Validation loss: 1.9042301895797893

Epoch: 256| Step: 0
Training loss: 0.8266010284423828
Validation loss: 1.9318650307193879

Epoch: 5| Step: 1
Training loss: 0.74723881483078
Validation loss: 1.9567185217334377

Epoch: 5| Step: 2
Training loss: 1.5454013347625732
Validation loss: 1.9933625754489694

Epoch: 5| Step: 3
Training loss: 0.8044594526290894
Validation loss: 1.9630333274923346

Epoch: 5| Step: 4
Training loss: 0.6254385709762573
Validation loss: 1.9727949045037712

Epoch: 5| Step: 5
Training loss: 0.652073860168457
Validation loss: 1.9558196824084046

Epoch: 5| Step: 6
Training loss: 0.5391566157341003
Validation loss: 1.9501673406170261

Epoch: 5| Step: 7
Training loss: 0.7287458777427673
Validation loss: 1.932648866407333

Epoch: 5| Step: 8
Training loss: 1.2853620052337646
Validation loss: 1.9149036561289141

Epoch: 5| Step: 9
Training loss: 0.9170397520065308
Validation loss: 1.9311581273232736

Epoch: 5| Step: 10
Training loss: 1.0373601913452148
Validation loss: 1.914866155193698

Epoch: 257| Step: 0
Training loss: 0.45666855573654175
Validation loss: 1.908127410437471

Epoch: 5| Step: 1
Training loss: 1.14192533493042
Validation loss: 1.8912331506770144

Epoch: 5| Step: 2
Training loss: 0.7461345791816711
Validation loss: 1.9351465125237741

Epoch: 5| Step: 3
Training loss: 1.403171420097351
Validation loss: 1.9248117336662867

Epoch: 5| Step: 4
Training loss: 1.0983814001083374
Validation loss: 1.9254991213480632

Epoch: 5| Step: 5
Training loss: 1.0483030080795288
Validation loss: 1.9114459727400093

Epoch: 5| Step: 6
Training loss: 0.6837934255599976
Validation loss: 1.9251166466743714

Epoch: 5| Step: 7
Training loss: 1.053131341934204
Validation loss: 1.9906646077350905

Epoch: 5| Step: 8
Training loss: 0.5358105897903442
Validation loss: 1.9525680849629063

Epoch: 5| Step: 9
Training loss: 0.8410132527351379
Validation loss: 2.012426516061188

Epoch: 5| Step: 10
Training loss: 1.2549248933792114
Validation loss: 2.0146221576198453

Epoch: 258| Step: 0
Training loss: 1.0045878887176514
Validation loss: 1.979085430022209

Epoch: 5| Step: 1
Training loss: 0.8110918998718262
Validation loss: 1.9532400779826666

Epoch: 5| Step: 2
Training loss: 0.9540424346923828
Validation loss: 1.9365774123899397

Epoch: 5| Step: 3
Training loss: 0.6568964719772339
Validation loss: 1.9214721546378186

Epoch: 5| Step: 4
Training loss: 0.9181225895881653
Validation loss: 1.8943275841333533

Epoch: 5| Step: 5
Training loss: 0.8471841812133789
Validation loss: 1.902957122812989

Epoch: 5| Step: 6
Training loss: 0.7335197925567627
Validation loss: 1.892850742545179

Epoch: 5| Step: 7
Training loss: 1.3476778268814087
Validation loss: 1.8912215963486703

Epoch: 5| Step: 8
Training loss: 0.7446650266647339
Validation loss: 1.8795243815709186

Epoch: 5| Step: 9
Training loss: 1.1399646997451782
Validation loss: 1.8950586806061447

Epoch: 5| Step: 10
Training loss: 0.6939241886138916
Validation loss: 1.9219785031451975

Epoch: 259| Step: 0
Training loss: 0.8775001764297485
Validation loss: 1.9624980008730324

Epoch: 5| Step: 1
Training loss: 0.5827500224113464
Validation loss: 1.9482005103941886

Epoch: 5| Step: 2
Training loss: 1.0068572759628296
Validation loss: 1.9314463625672043

Epoch: 5| Step: 3
Training loss: 0.6115963459014893
Validation loss: 1.955124621750206

Epoch: 5| Step: 4
Training loss: 1.3492228984832764
Validation loss: 1.9701582372829478

Epoch: 5| Step: 5
Training loss: 0.9675626754760742
Validation loss: 1.945283705188382

Epoch: 5| Step: 6
Training loss: 0.9005923271179199
Validation loss: 1.962270857185446

Epoch: 5| Step: 7
Training loss: 0.9069629907608032
Validation loss: 1.913485542420418

Epoch: 5| Step: 8
Training loss: 0.7965126633644104
Validation loss: 1.9215940467772945

Epoch: 5| Step: 9
Training loss: 0.609335720539093
Validation loss: 1.9376878392311834

Epoch: 5| Step: 10
Training loss: 1.3250881433486938
Validation loss: 1.9574864910494896

Epoch: 260| Step: 0
Training loss: 0.514418363571167
Validation loss: 1.9539231331117692

Epoch: 5| Step: 1
Training loss: 1.3712332248687744
Validation loss: 1.8990319121268489

Epoch: 5| Step: 2
Training loss: 0.9686406254768372
Validation loss: 1.8658213987145373

Epoch: 5| Step: 3
Training loss: 0.8129318952560425
Validation loss: 1.8756407435222338

Epoch: 5| Step: 4
Training loss: 0.7878586053848267
Validation loss: 1.8828931008615801

Epoch: 5| Step: 5
Training loss: 0.9503909945487976
Validation loss: 1.9009112914403279

Epoch: 5| Step: 6
Training loss: 0.7480896711349487
Validation loss: 1.9073981879859843

Epoch: 5| Step: 7
Training loss: 0.8646649122238159
Validation loss: 1.9224564952235068

Epoch: 5| Step: 8
Training loss: 0.6307434439659119
Validation loss: 1.8934882212710638

Epoch: 5| Step: 9
Training loss: 1.1371922492980957
Validation loss: 1.9324460491057365

Epoch: 5| Step: 10
Training loss: 0.8436458706855774
Validation loss: 1.9740306510720202

Epoch: 261| Step: 0
Training loss: 1.1774799823760986
Validation loss: 2.0302332575603197

Epoch: 5| Step: 1
Training loss: 0.8004854917526245
Validation loss: 2.067608038584391

Epoch: 5| Step: 2
Training loss: 1.3524796962738037
Validation loss: 1.964020336827924

Epoch: 5| Step: 3
Training loss: 0.8683997988700867
Validation loss: 1.9070723966885639

Epoch: 5| Step: 4
Training loss: 1.4141006469726562
Validation loss: 1.858649105154058

Epoch: 5| Step: 5
Training loss: 1.1019928455352783
Validation loss: 1.8580408096313477

Epoch: 5| Step: 6
Training loss: 0.7489979267120361
Validation loss: 1.8691072284534413

Epoch: 5| Step: 7
Training loss: 0.7720425724983215
Validation loss: 1.8902667863394624

Epoch: 5| Step: 8
Training loss: 0.7563968896865845
Validation loss: 1.8809494920956191

Epoch: 5| Step: 9
Training loss: 0.4541633725166321
Validation loss: 1.8783854117957495

Epoch: 5| Step: 10
Training loss: 0.4071730077266693
Validation loss: 1.8757593708653604

Epoch: 262| Step: 0
Training loss: 0.625097393989563
Validation loss: 1.9132970340790287

Epoch: 5| Step: 1
Training loss: 0.8885371088981628
Validation loss: 1.9489359778742636

Epoch: 5| Step: 2
Training loss: 1.206912875175476
Validation loss: 2.0089424066646124

Epoch: 5| Step: 3
Training loss: 0.9001489877700806
Validation loss: 2.0080842997438166

Epoch: 5| Step: 4
Training loss: 0.7532992959022522
Validation loss: 1.9652627873164352

Epoch: 5| Step: 5
Training loss: 1.021824598312378
Validation loss: 1.9385978791021532

Epoch: 5| Step: 6
Training loss: 0.6854408383369446
Validation loss: 1.9458962537909066

Epoch: 5| Step: 7
Training loss: 0.7396025657653809
Validation loss: 1.9193251825148059

Epoch: 5| Step: 8
Training loss: 0.5155870914459229
Validation loss: 1.9083502766906575

Epoch: 5| Step: 9
Training loss: 1.046343207359314
Validation loss: 1.8738925944092453

Epoch: 5| Step: 10
Training loss: 1.0020289421081543
Validation loss: 1.9000011233873264

Epoch: 263| Step: 0
Training loss: 0.9358001947402954
Validation loss: 1.8716662160811885

Epoch: 5| Step: 1
Training loss: 0.7261143922805786
Validation loss: 1.8723990955660421

Epoch: 5| Step: 2
Training loss: 0.6097890138626099
Validation loss: 1.8854813973108928

Epoch: 5| Step: 3
Training loss: 0.9369009137153625
Validation loss: 1.8836697378466207

Epoch: 5| Step: 4
Training loss: 0.6881455183029175
Validation loss: 1.8886558368641844

Epoch: 5| Step: 5
Training loss: 0.6660111546516418
Validation loss: 1.8967237100806287

Epoch: 5| Step: 6
Training loss: 0.8250195384025574
Validation loss: 1.9154810687547088

Epoch: 5| Step: 7
Training loss: 0.4033803343772888
Validation loss: 1.9272309169974378

Epoch: 5| Step: 8
Training loss: 0.9082269668579102
Validation loss: 1.9319595342041345

Epoch: 5| Step: 9
Training loss: 1.395395040512085
Validation loss: 1.8917292689764371

Epoch: 5| Step: 10
Training loss: 1.046184778213501
Validation loss: 1.9096484530356623

Epoch: 264| Step: 0
Training loss: 0.9132612943649292
Validation loss: 1.880440737611504

Epoch: 5| Step: 1
Training loss: 0.9461965560913086
Validation loss: 1.8760358287442116

Epoch: 5| Step: 2
Training loss: 0.6917389631271362
Validation loss: 1.8895269452884633

Epoch: 5| Step: 3
Training loss: 0.7558470964431763
Validation loss: 1.8757463501345726

Epoch: 5| Step: 4
Training loss: 0.7328627705574036
Validation loss: 1.8771963914235432

Epoch: 5| Step: 5
Training loss: 1.1419665813446045
Validation loss: 1.9320569884392522

Epoch: 5| Step: 6
Training loss: 0.6424813866615295
Validation loss: 1.9674221879692488

Epoch: 5| Step: 7
Training loss: 0.6639634370803833
Validation loss: 1.9740844670162405

Epoch: 5| Step: 8
Training loss: 0.47628504037857056
Validation loss: 1.9509134113147695

Epoch: 5| Step: 9
Training loss: 1.1804311275482178
Validation loss: 1.9517579360674786

Epoch: 5| Step: 10
Training loss: 0.9833351373672485
Validation loss: 1.9238188741027669

Epoch: 265| Step: 0
Training loss: 0.7828720211982727
Validation loss: 1.8996444722657562

Epoch: 5| Step: 1
Training loss: 0.8441652059555054
Validation loss: 1.923135067826958

Epoch: 5| Step: 2
Training loss: 0.4548727869987488
Validation loss: 1.8776638994934738

Epoch: 5| Step: 3
Training loss: 0.6676079630851746
Validation loss: 1.86712634435264

Epoch: 5| Step: 4
Training loss: 0.6047001481056213
Validation loss: 1.8566848718991844

Epoch: 5| Step: 5
Training loss: 0.7504501342773438
Validation loss: 1.887792956444525

Epoch: 5| Step: 6
Training loss: 0.8172609210014343
Validation loss: 1.9156485155064573

Epoch: 5| Step: 7
Training loss: 0.3697064220905304
Validation loss: 1.9338764003528062

Epoch: 5| Step: 8
Training loss: 1.3289170265197754
Validation loss: 1.9715847033326344

Epoch: 5| Step: 9
Training loss: 1.268325686454773
Validation loss: 1.9630719179748206

Epoch: 5| Step: 10
Training loss: 1.1897293329238892
Validation loss: 1.9518605457839144

Epoch: 266| Step: 0
Training loss: 0.770367443561554
Validation loss: 1.9487442829275643

Epoch: 5| Step: 1
Training loss: 0.5854218602180481
Validation loss: 1.9729094043854745

Epoch: 5| Step: 2
Training loss: 0.6557106971740723
Validation loss: 1.9402395615013697

Epoch: 5| Step: 3
Training loss: 0.894966721534729
Validation loss: 1.9340230072698286

Epoch: 5| Step: 4
Training loss: 0.9829602241516113
Validation loss: 1.9393818762994581

Epoch: 5| Step: 5
Training loss: 0.8823320269584656
Validation loss: 1.9196316990801083

Epoch: 5| Step: 6
Training loss: 0.9517887234687805
Validation loss: 1.9219692701934485

Epoch: 5| Step: 7
Training loss: 0.8057430982589722
Validation loss: 1.9288317439376668

Epoch: 5| Step: 8
Training loss: 0.6554343700408936
Validation loss: 1.9375330273823073

Epoch: 5| Step: 9
Training loss: 0.661845326423645
Validation loss: 1.9248918051360755

Epoch: 5| Step: 10
Training loss: 1.0910040140151978
Validation loss: 1.899407547648235

Epoch: 267| Step: 0
Training loss: 0.9622710943222046
Validation loss: 1.9009032134086854

Epoch: 5| Step: 1
Training loss: 1.266892433166504
Validation loss: 1.8773732967274164

Epoch: 5| Step: 2
Training loss: 0.6797107458114624
Validation loss: 1.863348066165883

Epoch: 5| Step: 3
Training loss: 0.3812423348426819
Validation loss: 1.8750964928698797

Epoch: 5| Step: 4
Training loss: 0.8508360981941223
Validation loss: 1.899258541804488

Epoch: 5| Step: 5
Training loss: 0.5587545037269592
Validation loss: 1.9017843982224822

Epoch: 5| Step: 6
Training loss: 0.732469916343689
Validation loss: 1.9059912338051745

Epoch: 5| Step: 7
Training loss: 0.5130357146263123
Validation loss: 1.9513162925679197

Epoch: 5| Step: 8
Training loss: 1.0726925134658813
Validation loss: 1.9876804761989142

Epoch: 5| Step: 9
Training loss: 0.8519363403320312
Validation loss: 2.0325265558817054

Epoch: 5| Step: 10
Training loss: 1.2590545415878296
Validation loss: 2.0135445594787598

Epoch: 268| Step: 0
Training loss: 0.5663808584213257
Validation loss: 1.9628525446820002

Epoch: 5| Step: 1
Training loss: 0.6276446580886841
Validation loss: 1.9046542003590574

Epoch: 5| Step: 2
Training loss: 1.3868216276168823
Validation loss: 1.9143845189002253

Epoch: 5| Step: 3
Training loss: 0.6541584730148315
Validation loss: 1.8947342775201286

Epoch: 5| Step: 4
Training loss: 0.7307541966438293
Validation loss: 1.8847742913871683

Epoch: 5| Step: 5
Training loss: 0.7336623072624207
Validation loss: 1.8777727375748337

Epoch: 5| Step: 6
Training loss: 0.9027813673019409
Validation loss: 1.8826864457899524

Epoch: 5| Step: 7
Training loss: 0.7937154173851013
Validation loss: 1.9411639423780545

Epoch: 5| Step: 8
Training loss: 0.7744248509407043
Validation loss: 1.9867151706449446

Epoch: 5| Step: 9
Training loss: 0.9916356801986694
Validation loss: 1.9961518651695662

Epoch: 5| Step: 10
Training loss: 1.0547637939453125
Validation loss: 1.9799192656752884

Epoch: 269| Step: 0
Training loss: 0.777684211730957
Validation loss: 1.9422351032175043

Epoch: 5| Step: 1
Training loss: 0.6023222208023071
Validation loss: 1.8719883836725706

Epoch: 5| Step: 2
Training loss: 1.0548758506774902
Validation loss: 1.8571158378354964

Epoch: 5| Step: 3
Training loss: 0.9199946522712708
Validation loss: 1.8757282251952796

Epoch: 5| Step: 4
Training loss: 0.9186444282531738
Validation loss: 1.8869013247951385

Epoch: 5| Step: 5
Training loss: 0.8231639862060547
Validation loss: 1.8901395567001835

Epoch: 5| Step: 6
Training loss: 0.5614811778068542
Validation loss: 1.9196834692391016

Epoch: 5| Step: 7
Training loss: 0.8867059946060181
Validation loss: 1.9297290771238265

Epoch: 5| Step: 8
Training loss: 0.8542835116386414
Validation loss: 1.9713922674937914

Epoch: 5| Step: 9
Training loss: 0.6063156127929688
Validation loss: 2.0322994519305486

Epoch: 5| Step: 10
Training loss: 1.0545263290405273
Validation loss: 2.0402309894561768

Epoch: 270| Step: 0
Training loss: 0.9404733777046204
Validation loss: 2.0113017148869012

Epoch: 5| Step: 1
Training loss: 0.7979993224143982
Validation loss: 1.9531634469186105

Epoch: 5| Step: 2
Training loss: 1.172908067703247
Validation loss: 1.9496135634760703

Epoch: 5| Step: 3
Training loss: 1.2681317329406738
Validation loss: 1.9122435623599636

Epoch: 5| Step: 4
Training loss: 0.7117453217506409
Validation loss: 1.8667795991384855

Epoch: 5| Step: 5
Training loss: 0.7358002662658691
Validation loss: 1.8638189992597025

Epoch: 5| Step: 6
Training loss: 0.7731673121452332
Validation loss: 1.839287636100605

Epoch: 5| Step: 7
Training loss: 0.5982292890548706
Validation loss: 1.8365325863643358

Epoch: 5| Step: 8
Training loss: 0.6076325178146362
Validation loss: 1.8540450924186296

Epoch: 5| Step: 9
Training loss: 0.6970956921577454
Validation loss: 1.9090105205453851

Epoch: 5| Step: 10
Training loss: 0.5535927414894104
Validation loss: 1.9284199078877766

Epoch: 271| Step: 0
Training loss: 0.6445564031600952
Validation loss: 1.9383106629053752

Epoch: 5| Step: 1
Training loss: 1.4349005222320557
Validation loss: 1.9064376149126279

Epoch: 5| Step: 2
Training loss: 0.7867964506149292
Validation loss: 1.9311912828876125

Epoch: 5| Step: 3
Training loss: 0.9133720397949219
Validation loss: 1.9167698198749172

Epoch: 5| Step: 4
Training loss: 0.7192360162734985
Validation loss: 1.9152673867440992

Epoch: 5| Step: 5
Training loss: 0.8648750185966492
Validation loss: 1.922721452610467

Epoch: 5| Step: 6
Training loss: 0.5641137957572937
Validation loss: 1.9128013246802873

Epoch: 5| Step: 7
Training loss: 0.6810477375984192
Validation loss: 1.9196811978534987

Epoch: 5| Step: 8
Training loss: 0.6078275442123413
Validation loss: 1.9218486483379076

Epoch: 5| Step: 9
Training loss: 0.7329358458518982
Validation loss: 1.9044165559994277

Epoch: 5| Step: 10
Training loss: 0.6331498026847839
Validation loss: 1.9123001342178674

Epoch: 272| Step: 0
Training loss: 0.6001262664794922
Validation loss: 1.8959935852276382

Epoch: 5| Step: 1
Training loss: 0.7770277261734009
Validation loss: 1.9073551213869484

Epoch: 5| Step: 2
Training loss: 0.8225377202033997
Validation loss: 1.8537681346298547

Epoch: 5| Step: 3
Training loss: 0.801689624786377
Validation loss: 1.8476203154492121

Epoch: 5| Step: 4
Training loss: 0.9127867817878723
Validation loss: 1.835150041887837

Epoch: 5| Step: 5
Training loss: 1.106682538986206
Validation loss: 1.8609013442070252

Epoch: 5| Step: 6
Training loss: 0.4512013792991638
Validation loss: 1.8711071988587737

Epoch: 5| Step: 7
Training loss: 0.7871311902999878
Validation loss: 1.8799175959761425

Epoch: 5| Step: 8
Training loss: 0.7780267000198364
Validation loss: 1.9146498544241792

Epoch: 5| Step: 9
Training loss: 0.7275522947311401
Validation loss: 1.9339253056433894

Epoch: 5| Step: 10
Training loss: 0.6825774312019348
Validation loss: 1.9278438040005264

Epoch: 273| Step: 0
Training loss: 0.8127399682998657
Validation loss: 1.9419976536945631

Epoch: 5| Step: 1
Training loss: 0.8647233843803406
Validation loss: 1.9374737688290176

Epoch: 5| Step: 2
Training loss: 0.8812834024429321
Validation loss: 1.9235063464410844

Epoch: 5| Step: 3
Training loss: 0.9115051031112671
Validation loss: 1.9183024642288045

Epoch: 5| Step: 4
Training loss: 0.8451221585273743
Validation loss: 1.903894555184149

Epoch: 5| Step: 5
Training loss: 0.740702748298645
Validation loss: 1.884766722238192

Epoch: 5| Step: 6
Training loss: 0.7257674932479858
Validation loss: 1.8966778850042691

Epoch: 5| Step: 7
Training loss: 0.498585045337677
Validation loss: 1.8817372116991269

Epoch: 5| Step: 8
Training loss: 0.6661558747291565
Validation loss: 1.8624010150150587

Epoch: 5| Step: 9
Training loss: 0.5718744397163391
Validation loss: 1.852850494846221

Epoch: 5| Step: 10
Training loss: 0.8284763693809509
Validation loss: 1.8495423755338114

Epoch: 274| Step: 0
Training loss: 0.8520981669425964
Validation loss: 1.8463939325783842

Epoch: 5| Step: 1
Training loss: 0.5454317927360535
Validation loss: 1.8609474423111125

Epoch: 5| Step: 2
Training loss: 0.8769688606262207
Validation loss: 1.8590900141705748

Epoch: 5| Step: 3
Training loss: 0.49789589643478394
Validation loss: 1.8586938060739988

Epoch: 5| Step: 4
Training loss: 0.7581628561019897
Validation loss: 1.881855796742183

Epoch: 5| Step: 5
Training loss: 0.8015846014022827
Validation loss: 1.8689261559517152

Epoch: 5| Step: 6
Training loss: 0.6355898976325989
Validation loss: 1.881665252870129

Epoch: 5| Step: 7
Training loss: 0.6584715843200684
Validation loss: 1.865800852416664

Epoch: 5| Step: 8
Training loss: 0.8683816194534302
Validation loss: 1.8585765156694638

Epoch: 5| Step: 9
Training loss: 0.6524218320846558
Validation loss: 1.8523492044018162

Epoch: 5| Step: 10
Training loss: 1.0018776655197144
Validation loss: 1.8182845782208186

Epoch: 275| Step: 0
Training loss: 0.4711534380912781
Validation loss: 1.8622080856753933

Epoch: 5| Step: 1
Training loss: 0.9027657508850098
Validation loss: 1.8585846283102547

Epoch: 5| Step: 2
Training loss: 0.8161330223083496
Validation loss: 1.887248840383304

Epoch: 5| Step: 3
Training loss: 0.5581647157669067
Validation loss: 1.8784454022684405

Epoch: 5| Step: 4
Training loss: 0.5790220499038696
Validation loss: 1.8561375410326066

Epoch: 5| Step: 5
Training loss: 0.8385809659957886
Validation loss: 1.8828001150520899

Epoch: 5| Step: 6
Training loss: 0.9312278032302856
Validation loss: 1.8708630300337268

Epoch: 5| Step: 7
Training loss: 0.5828680992126465
Validation loss: 1.8991749248197

Epoch: 5| Step: 8
Training loss: 0.7653516530990601
Validation loss: 1.9188017332425682

Epoch: 5| Step: 9
Training loss: 0.9605199098587036
Validation loss: 1.89529082082933

Epoch: 5| Step: 10
Training loss: 0.558742880821228
Validation loss: 1.8661418781485608

Epoch: 276| Step: 0
Training loss: 0.47888508439064026
Validation loss: 1.864454900064776

Epoch: 5| Step: 1
Training loss: 0.48339176177978516
Validation loss: 1.8821548723405408

Epoch: 5| Step: 2
Training loss: 0.5077221393585205
Validation loss: 1.8747046045077744

Epoch: 5| Step: 3
Training loss: 1.1454343795776367
Validation loss: 1.8895227050268522

Epoch: 5| Step: 4
Training loss: 0.7520655393600464
Validation loss: 1.9150788450753817

Epoch: 5| Step: 5
Training loss: 0.8853782415390015
Validation loss: 1.9618218893645911

Epoch: 5| Step: 6
Training loss: 0.8879307508468628
Validation loss: 1.953054448609711

Epoch: 5| Step: 7
Training loss: 0.9562824964523315
Validation loss: 1.9455665670415407

Epoch: 5| Step: 8
Training loss: 0.653842568397522
Validation loss: 1.904725113222676

Epoch: 5| Step: 9
Training loss: 0.4928019642829895
Validation loss: 1.8910890779187601

Epoch: 5| Step: 10
Training loss: 0.7984216213226318
Validation loss: 1.8793138560428415

Epoch: 277| Step: 0
Training loss: 0.9749189615249634
Validation loss: 1.8747763556818808

Epoch: 5| Step: 1
Training loss: 0.8969759941101074
Validation loss: 1.8728910633312759

Epoch: 5| Step: 2
Training loss: 0.5541998744010925
Validation loss: 1.8646620704281716

Epoch: 5| Step: 3
Training loss: 0.8895623087882996
Validation loss: 1.8823962352609123

Epoch: 5| Step: 4
Training loss: 0.4021478295326233
Validation loss: 1.8830766741947462

Epoch: 5| Step: 5
Training loss: 0.8495334386825562
Validation loss: 1.906933593493636

Epoch: 5| Step: 6
Training loss: 0.4831991195678711
Validation loss: 1.9131539816497474

Epoch: 5| Step: 7
Training loss: 0.6877955794334412
Validation loss: 1.8818895393802273

Epoch: 5| Step: 8
Training loss: 0.9104815721511841
Validation loss: 1.8550733661138883

Epoch: 5| Step: 9
Training loss: 0.6150547862052917
Validation loss: 1.8516689231318813

Epoch: 5| Step: 10
Training loss: 0.7318050265312195
Validation loss: 1.8611188780876897

Epoch: 278| Step: 0
Training loss: 0.4152437150478363
Validation loss: 1.8658570346011911

Epoch: 5| Step: 1
Training loss: 0.7064022421836853
Validation loss: 1.8590393117679063

Epoch: 5| Step: 2
Training loss: 0.6579293012619019
Validation loss: 1.845692567927863

Epoch: 5| Step: 3
Training loss: 0.47153395414352417
Validation loss: 1.8373334510352022

Epoch: 5| Step: 4
Training loss: 1.108095645904541
Validation loss: 1.8566056682217507

Epoch: 5| Step: 5
Training loss: 1.107285737991333
Validation loss: 1.9001980699518675

Epoch: 5| Step: 6
Training loss: 0.33296364545822144
Validation loss: 1.901306229252969

Epoch: 5| Step: 7
Training loss: 0.7959128618240356
Validation loss: 1.880958221291983

Epoch: 5| Step: 8
Training loss: 0.5769084095954895
Validation loss: 1.8472889302879252

Epoch: 5| Step: 9
Training loss: 0.6560026407241821
Validation loss: 1.8079738360579296

Epoch: 5| Step: 10
Training loss: 0.906516432762146
Validation loss: 1.7903016677466772

Epoch: 279| Step: 0
Training loss: 0.5083130598068237
Validation loss: 1.8187087018002746

Epoch: 5| Step: 1
Training loss: 0.5497903823852539
Validation loss: 1.8037547539639216

Epoch: 5| Step: 2
Training loss: 0.687389075756073
Validation loss: 1.8400831658353087

Epoch: 5| Step: 3
Training loss: 0.580433189868927
Validation loss: 1.876328165813159

Epoch: 5| Step: 4
Training loss: 0.8378973007202148
Validation loss: 1.893562142566968

Epoch: 5| Step: 5
Training loss: 0.8579419851303101
Validation loss: 1.9038954293856056

Epoch: 5| Step: 6
Training loss: 1.223828673362732
Validation loss: 1.8744108779456026

Epoch: 5| Step: 7
Training loss: 0.6373689770698547
Validation loss: 1.8451165883771834

Epoch: 5| Step: 8
Training loss: 0.5148965120315552
Validation loss: 1.8257421293566305

Epoch: 5| Step: 9
Training loss: 0.7987162470817566
Validation loss: 1.8596707492746332

Epoch: 5| Step: 10
Training loss: 0.9609746336936951
Validation loss: 1.8744653142908567

Epoch: 280| Step: 0
Training loss: 0.8486776351928711
Validation loss: 1.8850972960072179

Epoch: 5| Step: 1
Training loss: 0.5865267515182495
Validation loss: 1.8998768303983955

Epoch: 5| Step: 2
Training loss: 0.6462555527687073
Validation loss: 1.9234381080955587

Epoch: 5| Step: 3
Training loss: 0.5662176012992859
Validation loss: 1.9400325949474047

Epoch: 5| Step: 4
Training loss: 0.8363939523696899
Validation loss: 1.9406694045630835

Epoch: 5| Step: 5
Training loss: 0.8198337554931641
Validation loss: 1.901716701446041

Epoch: 5| Step: 6
Training loss: 0.5404527187347412
Validation loss: 1.8818527280643422

Epoch: 5| Step: 7
Training loss: 0.870252251625061
Validation loss: 1.849138536760884

Epoch: 5| Step: 8
Training loss: 0.6806398630142212
Validation loss: 1.8278433661307059

Epoch: 5| Step: 9
Training loss: 0.7548916935920715
Validation loss: 1.8024538511871009

Epoch: 5| Step: 10
Training loss: 0.7623365521430969
Validation loss: 1.8198999717671385

Epoch: 281| Step: 0
Training loss: 0.6186248660087585
Validation loss: 1.819197654724121

Epoch: 5| Step: 1
Training loss: 0.5791078805923462
Validation loss: 1.8500598528051888

Epoch: 5| Step: 2
Training loss: 0.7492822408676147
Validation loss: 1.8379195672209545

Epoch: 5| Step: 3
Training loss: 0.6813682317733765
Validation loss: 1.8613615728193713

Epoch: 5| Step: 4
Training loss: 1.2550294399261475
Validation loss: 1.863447678986416

Epoch: 5| Step: 5
Training loss: 0.4637299180030823
Validation loss: 1.9031563740904613

Epoch: 5| Step: 6
Training loss: 0.6386763453483582
Validation loss: 1.8882682900274954

Epoch: 5| Step: 7
Training loss: 0.47892457246780396
Validation loss: 1.9060170368481708

Epoch: 5| Step: 8
Training loss: 0.6941310167312622
Validation loss: 1.9054288351407616

Epoch: 5| Step: 9
Training loss: 0.8013002276420593
Validation loss: 1.8793059382387387

Epoch: 5| Step: 10
Training loss: 0.599190354347229
Validation loss: 1.8421475759116552

Epoch: 282| Step: 0
Training loss: 1.202829122543335
Validation loss: 1.8405342281505626

Epoch: 5| Step: 1
Training loss: 0.5787121653556824
Validation loss: 1.8302225605134042

Epoch: 5| Step: 2
Training loss: 0.8010057210922241
Validation loss: 1.8389083326503795

Epoch: 5| Step: 3
Training loss: 0.39759981632232666
Validation loss: 1.8297949811463714

Epoch: 5| Step: 4
Training loss: 0.8437995910644531
Validation loss: 1.8423830334858229

Epoch: 5| Step: 5
Training loss: 0.7507316470146179
Validation loss: 1.8547884405300181

Epoch: 5| Step: 6
Training loss: 0.5100600123405457
Validation loss: 1.8477068216569963

Epoch: 5| Step: 7
Training loss: 0.5811226963996887
Validation loss: 1.8566925294937626

Epoch: 5| Step: 8
Training loss: 0.46920618414878845
Validation loss: 1.8700414972920572

Epoch: 5| Step: 9
Training loss: 0.5776919722557068
Validation loss: 1.8787988642210602

Epoch: 5| Step: 10
Training loss: 0.6671587824821472
Validation loss: 1.8698801488004706

Epoch: 283| Step: 0
Training loss: 0.5968695878982544
Validation loss: 1.8744243268043763

Epoch: 5| Step: 1
Training loss: 0.4643716812133789
Validation loss: 1.8458293317466654

Epoch: 5| Step: 2
Training loss: 0.7108954191207886
Validation loss: 1.8888691932924333

Epoch: 5| Step: 3
Training loss: 0.7112379670143127
Validation loss: 1.9016466192019883

Epoch: 5| Step: 4
Training loss: 0.6811195611953735
Validation loss: 1.8706440438506424

Epoch: 5| Step: 5
Training loss: 0.7193437814712524
Validation loss: 1.863158046558339

Epoch: 5| Step: 6
Training loss: 0.5468102097511292
Validation loss: 1.853718170555689

Epoch: 5| Step: 7
Training loss: 0.3313066065311432
Validation loss: 1.8687664821583738

Epoch: 5| Step: 8
Training loss: 0.6418606042861938
Validation loss: 1.842001259967845

Epoch: 5| Step: 9
Training loss: 0.8294660449028015
Validation loss: 1.8420751710091867

Epoch: 5| Step: 10
Training loss: 0.8545302152633667
Validation loss: 1.8425472333867063

Epoch: 284| Step: 0
Training loss: 0.4802510738372803
Validation loss: 1.8459226226293912

Epoch: 5| Step: 1
Training loss: 0.6475312113761902
Validation loss: 1.8608011199582009

Epoch: 5| Step: 2
Training loss: 0.5441423654556274
Validation loss: 1.8660331169764202

Epoch: 5| Step: 3
Training loss: 0.4665481448173523
Validation loss: 1.8848812516017626

Epoch: 5| Step: 4
Training loss: 0.8059981465339661
Validation loss: 1.9026826530374505

Epoch: 5| Step: 5
Training loss: 0.6992277503013611
Validation loss: 1.9270313087330069

Epoch: 5| Step: 6
Training loss: 0.9251251220703125
Validation loss: 1.9217262511612268

Epoch: 5| Step: 7
Training loss: 0.801283061504364
Validation loss: 1.887523074303904

Epoch: 5| Step: 8
Training loss: 0.35442396998405457
Validation loss: 1.877590005115796

Epoch: 5| Step: 9
Training loss: 0.6914089918136597
Validation loss: 1.8484559546234787

Epoch: 5| Step: 10
Training loss: 0.8885806798934937
Validation loss: 1.8287092729281353

Epoch: 285| Step: 0
Training loss: 0.39074450731277466
Validation loss: 1.8397732293733986

Epoch: 5| Step: 1
Training loss: 0.6338613033294678
Validation loss: 1.8391223312706075

Epoch: 5| Step: 2
Training loss: 0.9653484225273132
Validation loss: 1.841016008007911

Epoch: 5| Step: 3
Training loss: 0.457146018743515
Validation loss: 1.8537989598448559

Epoch: 5| Step: 4
Training loss: 0.5087100863456726
Validation loss: 1.8283531383801532

Epoch: 5| Step: 5
Training loss: 0.7544827461242676
Validation loss: 1.8831614255905151

Epoch: 5| Step: 6
Training loss: 0.6388750076293945
Validation loss: 1.897165959881198

Epoch: 5| Step: 7
Training loss: 0.746737539768219
Validation loss: 1.924605337522363

Epoch: 5| Step: 8
Training loss: 0.38444018363952637
Validation loss: 1.8875412530796503

Epoch: 5| Step: 9
Training loss: 0.8749076724052429
Validation loss: 1.8844719125378517

Epoch: 5| Step: 10
Training loss: 0.7856833934783936
Validation loss: 1.8830212444387457

Epoch: 286| Step: 0
Training loss: 0.7048571109771729
Validation loss: 1.89167744241735

Epoch: 5| Step: 1
Training loss: 0.7602423429489136
Validation loss: 1.8658920077867405

Epoch: 5| Step: 2
Training loss: 0.7443262338638306
Validation loss: 1.8369323861214422

Epoch: 5| Step: 3
Training loss: 0.6377494931221008
Validation loss: 1.8169390193877681

Epoch: 5| Step: 4
Training loss: 0.8643355369567871
Validation loss: 1.8144029891619118

Epoch: 5| Step: 5
Training loss: 0.6271452307701111
Validation loss: 1.8431068594737718

Epoch: 5| Step: 6
Training loss: 0.5872277021408081
Validation loss: 1.8484047433381439

Epoch: 5| Step: 7
Training loss: 0.8621255159378052
Validation loss: 1.8681380030929402

Epoch: 5| Step: 8
Training loss: 0.31683194637298584
Validation loss: 1.8765272325085056

Epoch: 5| Step: 9
Training loss: 0.6832027435302734
Validation loss: 1.8734079535289476

Epoch: 5| Step: 10
Training loss: 0.3366720378398895
Validation loss: 1.8655625774014382

Epoch: 287| Step: 0
Training loss: 1.0028231143951416
Validation loss: 1.848559771814654

Epoch: 5| Step: 1
Training loss: 0.7059470415115356
Validation loss: 1.8451684854363883

Epoch: 5| Step: 2
Training loss: 0.4800705909729004
Validation loss: 1.8446315091143373

Epoch: 5| Step: 3
Training loss: 0.6806581616401672
Validation loss: 1.8251798358014835

Epoch: 5| Step: 4
Training loss: 0.4214503765106201
Validation loss: 1.8609471346742363

Epoch: 5| Step: 5
Training loss: 0.8075429797172546
Validation loss: 1.8945409751707507

Epoch: 5| Step: 6
Training loss: 0.6721500158309937
Validation loss: 1.8781390805398264

Epoch: 5| Step: 7
Training loss: 0.5360029935836792
Validation loss: 1.8522905636859197

Epoch: 5| Step: 8
Training loss: 0.6501287817955017
Validation loss: 1.8663839729883338

Epoch: 5| Step: 9
Training loss: 0.9201387166976929
Validation loss: 1.823926047612262

Epoch: 5| Step: 10
Training loss: 0.4496381878852844
Validation loss: 1.8043934414463658

Epoch: 288| Step: 0
Training loss: 0.5584869980812073
Validation loss: 1.839982339130935

Epoch: 5| Step: 1
Training loss: 0.433488667011261
Validation loss: 1.8489564093210364

Epoch: 5| Step: 2
Training loss: 0.5829304456710815
Validation loss: 1.8483460923676849

Epoch: 5| Step: 3
Training loss: 0.42867350578308105
Validation loss: 1.8417982132204118

Epoch: 5| Step: 4
Training loss: 0.685024619102478
Validation loss: 1.8084441743871218

Epoch: 5| Step: 5
Training loss: 0.7964414358139038
Validation loss: 1.828823604891377

Epoch: 5| Step: 6
Training loss: 0.6101342439651489
Validation loss: 1.8239592057402416

Epoch: 5| Step: 7
Training loss: 0.4181951582431793
Validation loss: 1.8340559364646993

Epoch: 5| Step: 8
Training loss: 0.7073250412940979
Validation loss: 1.8281353378808627

Epoch: 5| Step: 9
Training loss: 1.102374792098999
Validation loss: 1.9201851403841408

Epoch: 5| Step: 10
Training loss: 0.5767378807067871
Validation loss: 1.9209626169614895

Epoch: 289| Step: 0
Training loss: 0.5831164121627808
Validation loss: 1.9235846150305964

Epoch: 5| Step: 1
Training loss: 0.5008677244186401
Validation loss: 1.8820650398090322

Epoch: 5| Step: 2
Training loss: 0.443464457988739
Validation loss: 1.8862550181727256

Epoch: 5| Step: 3
Training loss: 1.0425405502319336
Validation loss: 1.8715947648530364

Epoch: 5| Step: 4
Training loss: 0.5548412203788757
Validation loss: 1.8431612381371119

Epoch: 5| Step: 5
Training loss: 0.8663398623466492
Validation loss: 1.8235829568678332

Epoch: 5| Step: 6
Training loss: 0.4928743243217468
Validation loss: 1.8335136393065095

Epoch: 5| Step: 7
Training loss: 0.6630674600601196
Validation loss: 1.8219239750216085

Epoch: 5| Step: 8
Training loss: 0.6285656690597534
Validation loss: 1.82073639797908

Epoch: 5| Step: 9
Training loss: 0.5514348745346069
Validation loss: 1.8663319977380897

Epoch: 5| Step: 10
Training loss: 0.5834817886352539
Validation loss: 1.9276112958949099

Epoch: 290| Step: 0
Training loss: 0.602037787437439
Validation loss: 1.9646652988208237

Epoch: 5| Step: 1
Training loss: 0.6950723528862
Validation loss: 1.9379510571879726

Epoch: 5| Step: 2
Training loss: 0.6973684430122375
Validation loss: 1.8899420615165465

Epoch: 5| Step: 3
Training loss: 0.8321993947029114
Validation loss: 1.8621999525254773

Epoch: 5| Step: 4
Training loss: 0.3392356038093567
Validation loss: 1.828872392254491

Epoch: 5| Step: 5
Training loss: 0.7996284365653992
Validation loss: 1.8858485106498963

Epoch: 5| Step: 6
Training loss: 0.9837841987609863
Validation loss: 1.886329576533328

Epoch: 5| Step: 7
Training loss: 0.5954616665840149
Validation loss: 1.8647810746264715

Epoch: 5| Step: 8
Training loss: 0.5684228539466858
Validation loss: 1.8555516504472302

Epoch: 5| Step: 9
Training loss: 0.4538934826850891
Validation loss: 1.8772114835759646

Epoch: 5| Step: 10
Training loss: 0.3138558566570282
Validation loss: 1.8376282312536751

Epoch: 291| Step: 0
Training loss: 0.9597204923629761
Validation loss: 1.8470631863481255

Epoch: 5| Step: 1
Training loss: 0.7343132495880127
Validation loss: 1.8877698349696335

Epoch: 5| Step: 2
Training loss: 0.8369722366333008
Validation loss: 1.8463848303723078

Epoch: 5| Step: 3
Training loss: 0.547832190990448
Validation loss: 1.8571312324975127

Epoch: 5| Step: 4
Training loss: 0.4557943344116211
Validation loss: 1.8624108209404895

Epoch: 5| Step: 5
Training loss: 0.5266320109367371
Validation loss: 1.8844967119155391

Epoch: 5| Step: 6
Training loss: 0.6041578054428101
Validation loss: 1.8975846767425537

Epoch: 5| Step: 7
Training loss: 0.8208765983581543
Validation loss: 1.9516767327503493

Epoch: 5| Step: 8
Training loss: 0.5966458320617676
Validation loss: 1.9247385737716511

Epoch: 5| Step: 9
Training loss: 0.35075512528419495
Validation loss: 1.9149968457478348

Epoch: 5| Step: 10
Training loss: 0.4034636318683624
Validation loss: 1.9041359386136454

Epoch: 292| Step: 0
Training loss: 0.6363712549209595
Validation loss: 1.8749593701413882

Epoch: 5| Step: 1
Training loss: 0.6976121664047241
Validation loss: 1.8560612675964192

Epoch: 5| Step: 2
Training loss: 0.500874400138855
Validation loss: 1.8494365369119952

Epoch: 5| Step: 3
Training loss: 0.5876418352127075
Validation loss: 1.8292525147878995

Epoch: 5| Step: 4
Training loss: 0.5505509376525879
Validation loss: 1.819314197827411

Epoch: 5| Step: 5
Training loss: 0.4893950819969177
Validation loss: 1.8577833688387306

Epoch: 5| Step: 6
Training loss: 0.3428344130516052
Validation loss: 1.869914359943841

Epoch: 5| Step: 7
Training loss: 0.7608336806297302
Validation loss: 1.8670654040510937

Epoch: 5| Step: 8
Training loss: 0.9028674364089966
Validation loss: 1.8830645135653916

Epoch: 5| Step: 9
Training loss: 0.43892019987106323
Validation loss: 1.8810098196870537

Epoch: 5| Step: 10
Training loss: 0.9371542930603027
Validation loss: 1.8710237856834167

Epoch: 293| Step: 0
Training loss: 0.842812180519104
Validation loss: 1.8700818310501754

Epoch: 5| Step: 1
Training loss: 0.7562955617904663
Validation loss: 1.870578396704889

Epoch: 5| Step: 2
Training loss: 0.7669137120246887
Validation loss: 1.851095986622636

Epoch: 5| Step: 3
Training loss: 0.37791258096694946
Validation loss: 1.8770153881401144

Epoch: 5| Step: 4
Training loss: 0.37185099720954895
Validation loss: 1.8823400107763146

Epoch: 5| Step: 5
Training loss: 0.45360809564590454
Validation loss: 1.8682013224529963

Epoch: 5| Step: 6
Training loss: 0.5457518100738525
Validation loss: 1.8554058113405782

Epoch: 5| Step: 7
Training loss: 0.4550841450691223
Validation loss: 1.8272519137269707

Epoch: 5| Step: 8
Training loss: 0.944949746131897
Validation loss: 1.8582702054772327

Epoch: 5| Step: 9
Training loss: 0.7798191905021667
Validation loss: 1.8354956270546041

Epoch: 5| Step: 10
Training loss: 0.36842983961105347
Validation loss: 1.8525029907944381

Epoch: 294| Step: 0
Training loss: 0.9569915533065796
Validation loss: 1.848609100105942

Epoch: 5| Step: 1
Training loss: 0.7313767671585083
Validation loss: 1.8409323756412794

Epoch: 5| Step: 2
Training loss: 0.5673182010650635
Validation loss: 1.8591086338925105

Epoch: 5| Step: 3
Training loss: 0.8131955862045288
Validation loss: 1.8869432941559823

Epoch: 5| Step: 4
Training loss: 0.4042636752128601
Validation loss: 1.8977446248454433

Epoch: 5| Step: 5
Training loss: 0.47436413168907166
Validation loss: 1.8784241996785647

Epoch: 5| Step: 6
Training loss: 0.7605680227279663
Validation loss: 1.8353061765752814

Epoch: 5| Step: 7
Training loss: 0.37256404757499695
Validation loss: 1.866554521745251

Epoch: 5| Step: 8
Training loss: 0.529719352722168
Validation loss: 1.8301897523223714

Epoch: 5| Step: 9
Training loss: 0.4400233328342438
Validation loss: 1.8390062726953977

Epoch: 5| Step: 10
Training loss: 0.3488719165325165
Validation loss: 1.8539717966510403

Epoch: 295| Step: 0
Training loss: 1.0988988876342773
Validation loss: 1.872714352864091

Epoch: 5| Step: 1
Training loss: 0.48654669523239136
Validation loss: 1.8771908334506455

Epoch: 5| Step: 2
Training loss: 0.7044748067855835
Validation loss: 1.8910347120736235

Epoch: 5| Step: 3
Training loss: 0.35409432649612427
Validation loss: 1.8888453360526793

Epoch: 5| Step: 4
Training loss: 0.5523408651351929
Validation loss: 1.8769357883802025

Epoch: 5| Step: 5
Training loss: 0.4063916802406311
Validation loss: 1.9226524958046534

Epoch: 5| Step: 6
Training loss: 0.6014796495437622
Validation loss: 1.899240255355835

Epoch: 5| Step: 7
Training loss: 0.6664140224456787
Validation loss: 1.8948562709234094

Epoch: 5| Step: 8
Training loss: 0.5718545913696289
Validation loss: 1.8808014110852314

Epoch: 5| Step: 9
Training loss: 0.4841740131378174
Validation loss: 1.875654592308947

Epoch: 5| Step: 10
Training loss: 0.5057405233383179
Validation loss: 1.8798427312604842

Epoch: 296| Step: 0
Training loss: 0.521462082862854
Validation loss: 1.8648390872504121

Epoch: 5| Step: 1
Training loss: 0.41874322295188904
Validation loss: 1.873404779741841

Epoch: 5| Step: 2
Training loss: 0.6421651840209961
Validation loss: 1.8694035417290145

Epoch: 5| Step: 3
Training loss: 0.8359695672988892
Validation loss: 1.8714675634138045

Epoch: 5| Step: 4
Training loss: 0.4363137185573578
Validation loss: 1.8433244369363273

Epoch: 5| Step: 5
Training loss: 0.602509081363678
Validation loss: 1.8345301215366652

Epoch: 5| Step: 6
Training loss: 0.47284001111984253
Validation loss: 1.8604123079648582

Epoch: 5| Step: 7
Training loss: 0.3390567898750305
Validation loss: 1.8438816314102502

Epoch: 5| Step: 8
Training loss: 0.4765649735927582
Validation loss: 1.833513029160038

Epoch: 5| Step: 9
Training loss: 0.7931531667709351
Validation loss: 1.8461941544727614

Epoch: 5| Step: 10
Training loss: 0.6114601492881775
Validation loss: 1.8667881001708329

Epoch: 297| Step: 0
Training loss: 0.5743510723114014
Validation loss: 1.8614587296721756

Epoch: 5| Step: 1
Training loss: 0.4379039704799652
Validation loss: 1.8752186920053215

Epoch: 5| Step: 2
Training loss: 0.47042638063430786
Validation loss: 1.8393079914072508

Epoch: 5| Step: 3
Training loss: 0.7037336230278015
Validation loss: 1.8450850825155936

Epoch: 5| Step: 4
Training loss: 0.4424917697906494
Validation loss: 1.8282336701628983

Epoch: 5| Step: 5
Training loss: 0.8463756442070007
Validation loss: 1.8094320066513554

Epoch: 5| Step: 6
Training loss: 0.4069380760192871
Validation loss: 1.8667808860860846

Epoch: 5| Step: 7
Training loss: 0.4769503176212311
Validation loss: 1.8468550610285934

Epoch: 5| Step: 8
Training loss: 0.5214027166366577
Validation loss: 1.890602965508738

Epoch: 5| Step: 9
Training loss: 0.606708288192749
Validation loss: 1.8784643168090491

Epoch: 5| Step: 10
Training loss: 0.7547022700309753
Validation loss: 1.8934862754678214

Epoch: 298| Step: 0
Training loss: 0.4444437623023987
Validation loss: 1.9055123034343924

Epoch: 5| Step: 1
Training loss: 1.0790536403656006
Validation loss: 1.9170455048161168

Epoch: 5| Step: 2
Training loss: 0.4711318910121918
Validation loss: 1.933558460204832

Epoch: 5| Step: 3
Training loss: 0.798457145690918
Validation loss: 1.9119838386453607

Epoch: 5| Step: 4
Training loss: 0.3954726755619049
Validation loss: 1.9083086726486043

Epoch: 5| Step: 5
Training loss: 0.6574326157569885
Validation loss: 1.8823775091478903

Epoch: 5| Step: 6
Training loss: 0.46856459975242615
Validation loss: 1.8666718262498097

Epoch: 5| Step: 7
Training loss: 0.25068894028663635
Validation loss: 1.8653408968320457

Epoch: 5| Step: 8
Training loss: 0.43979042768478394
Validation loss: 1.8316716045461676

Epoch: 5| Step: 9
Training loss: 0.6022936105728149
Validation loss: 1.8284479674472605

Epoch: 5| Step: 10
Training loss: 0.5011698007583618
Validation loss: 1.8219345564483314

Epoch: 299| Step: 0
Training loss: 0.4119921624660492
Validation loss: 1.808592846316676

Epoch: 5| Step: 1
Training loss: 0.7474755644798279
Validation loss: 1.8476765399338098

Epoch: 5| Step: 2
Training loss: 0.852317214012146
Validation loss: 1.8478978282661849

Epoch: 5| Step: 3
Training loss: 0.5533167719841003
Validation loss: 1.893262832395492

Epoch: 5| Step: 4
Training loss: 0.38498926162719727
Validation loss: 1.8672854156904324

Epoch: 5| Step: 5
Training loss: 0.6428545713424683
Validation loss: 1.8796252614708358

Epoch: 5| Step: 6
Training loss: 0.4885627329349518
Validation loss: 1.8521194470826017

Epoch: 5| Step: 7
Training loss: 0.31191954016685486
Validation loss: 1.8439294240807975

Epoch: 5| Step: 8
Training loss: 0.4148925244808197
Validation loss: 1.8348739236913703

Epoch: 5| Step: 9
Training loss: 0.3119449019432068
Validation loss: 1.8644644291170183

Epoch: 5| Step: 10
Training loss: 0.761900782585144
Validation loss: 1.8431310628050117

Epoch: 300| Step: 0
Training loss: 0.6669755578041077
Validation loss: 1.8480608303059813

Epoch: 5| Step: 1
Training loss: 0.35595831274986267
Validation loss: 1.8627980947494507

Epoch: 5| Step: 2
Training loss: 0.3138033449649811
Validation loss: 1.8402446675044235

Epoch: 5| Step: 3
Training loss: 0.46842485666275024
Validation loss: 1.8475398684060702

Epoch: 5| Step: 4
Training loss: 0.6466104984283447
Validation loss: 1.8649738988568705

Epoch: 5| Step: 5
Training loss: 0.43226513266563416
Validation loss: 1.8557892448158675

Epoch: 5| Step: 6
Training loss: 0.7902935147285461
Validation loss: 1.8641685439694313

Epoch: 5| Step: 7
Training loss: 0.5893901586532593
Validation loss: 1.8260902589367283

Epoch: 5| Step: 8
Training loss: 0.5695632696151733
Validation loss: 1.822610834593414

Epoch: 5| Step: 9
Training loss: 0.5576309561729431
Validation loss: 1.8049168868731427

Epoch: 5| Step: 10
Training loss: 0.5449893474578857
Validation loss: 1.8333925790684198

Epoch: 301| Step: 0
Training loss: 0.6124193072319031
Validation loss: 1.8920315183619016

Epoch: 5| Step: 1
Training loss: 0.549199104309082
Validation loss: 1.8950358372862621

Epoch: 5| Step: 2
Training loss: 0.7531603574752808
Validation loss: 1.9262866409876014

Epoch: 5| Step: 3
Training loss: 0.5744916200637817
Validation loss: 1.8929880101193663

Epoch: 5| Step: 4
Training loss: 0.41624417901039124
Validation loss: 1.863408556548498

Epoch: 5| Step: 5
Training loss: 0.3912767171859741
Validation loss: 1.8633591359661472

Epoch: 5| Step: 6
Training loss: 0.7049175500869751
Validation loss: 1.8385947250550794

Epoch: 5| Step: 7
Training loss: 0.46399420499801636
Validation loss: 1.8183002061741327

Epoch: 5| Step: 8
Training loss: 0.5219491124153137
Validation loss: 1.828046352632584

Epoch: 5| Step: 9
Training loss: 0.507834792137146
Validation loss: 1.8318894524728098

Epoch: 5| Step: 10
Training loss: 0.8227999806404114
Validation loss: 1.840518090032762

Epoch: 302| Step: 0
Training loss: 0.6815477609634399
Validation loss: 1.818891186867991

Epoch: 5| Step: 1
Training loss: 0.29495319724082947
Validation loss: 1.8368653661461287

Epoch: 5| Step: 2
Training loss: 0.2254764586687088
Validation loss: 1.8695606736726658

Epoch: 5| Step: 3
Training loss: 0.6319657564163208
Validation loss: 1.861381781998501

Epoch: 5| Step: 4
Training loss: 0.33707723021507263
Validation loss: 1.8819707337246145

Epoch: 5| Step: 5
Training loss: 0.9042148590087891
Validation loss: 1.8551740293861718

Epoch: 5| Step: 6
Training loss: 0.70305335521698
Validation loss: 1.8768284654104581

Epoch: 5| Step: 7
Training loss: 0.4805581569671631
Validation loss: 1.8309030814837384

Epoch: 5| Step: 8
Training loss: 0.4227532744407654
Validation loss: 1.8463561047789872

Epoch: 5| Step: 9
Training loss: 0.659136176109314
Validation loss: 1.8342625556453582

Epoch: 5| Step: 10
Training loss: 0.42422035336494446
Validation loss: 1.7983887451951222

Epoch: 303| Step: 0
Training loss: 0.7886970639228821
Validation loss: 1.7773456035121795

Epoch: 5| Step: 1
Training loss: 0.5945425629615784
Validation loss: 1.7910735030328073

Epoch: 5| Step: 2
Training loss: 0.7328526377677917
Validation loss: 1.7918887164003106

Epoch: 5| Step: 3
Training loss: 0.443000853061676
Validation loss: 1.8054074471996677

Epoch: 5| Step: 4
Training loss: 0.5077065825462341
Validation loss: 1.8342244330272879

Epoch: 5| Step: 5
Training loss: 0.5134230256080627
Validation loss: 1.8844344077571746

Epoch: 5| Step: 6
Training loss: 0.2512686550617218
Validation loss: 1.912615437661448

Epoch: 5| Step: 7
Training loss: 0.536601185798645
Validation loss: 1.9235734452483475

Epoch: 5| Step: 8
Training loss: 0.44232091307640076
Validation loss: 1.908026255587096

Epoch: 5| Step: 9
Training loss: 0.46874862909317017
Validation loss: 1.8923753435893724

Epoch: 5| Step: 10
Training loss: 0.5274649262428284
Validation loss: 1.8604331888178343

Epoch: 304| Step: 0
Training loss: 0.4160328805446625
Validation loss: 1.85035224499241

Epoch: 5| Step: 1
Training loss: 0.54613196849823
Validation loss: 1.8096561675430627

Epoch: 5| Step: 2
Training loss: 0.6009777784347534
Validation loss: 1.7924952994110763

Epoch: 5| Step: 3
Training loss: 0.4057115912437439
Validation loss: 1.810072115672532

Epoch: 5| Step: 4
Training loss: 0.4562404155731201
Validation loss: 1.8139966764757711

Epoch: 5| Step: 5
Training loss: 0.571558952331543
Validation loss: 1.8279966718407088

Epoch: 5| Step: 6
Training loss: 0.7647837400436401
Validation loss: 1.8254479951755975

Epoch: 5| Step: 7
Training loss: 0.4162592887878418
Validation loss: 1.8081008195877075

Epoch: 5| Step: 8
Training loss: 0.2454376518726349
Validation loss: 1.8497579187475226

Epoch: 5| Step: 9
Training loss: 0.5168191194534302
Validation loss: 1.820867892234556

Epoch: 5| Step: 10
Training loss: 0.7052619457244873
Validation loss: 1.8176057082350536

Epoch: 305| Step: 0
Training loss: 0.4558587968349457
Validation loss: 1.828190638173011

Epoch: 5| Step: 1
Training loss: 0.5130043029785156
Validation loss: 1.8591377991502003

Epoch: 5| Step: 2
Training loss: 0.7486602067947388
Validation loss: 1.849411485015705

Epoch: 5| Step: 3
Training loss: 0.5662328004837036
Validation loss: 1.9198740451566634

Epoch: 5| Step: 4
Training loss: 0.5294532775878906
Validation loss: 1.9535282145264328

Epoch: 5| Step: 5
Training loss: 0.5231236219406128
Validation loss: 2.0059685066182125

Epoch: 5| Step: 6
Training loss: 0.6372391581535339
Validation loss: 1.9515920313455726

Epoch: 5| Step: 7
Training loss: 0.5558772087097168
Validation loss: 1.8859656408268919

Epoch: 5| Step: 8
Training loss: 0.5334717631340027
Validation loss: 1.8550019161675566

Epoch: 5| Step: 9
Training loss: 0.5085973739624023
Validation loss: 1.8009029819119362

Epoch: 5| Step: 10
Training loss: 0.4796968996524811
Validation loss: 1.8117753280106412

Epoch: 306| Step: 0
Training loss: 0.7249700427055359
Validation loss: 1.8117848032264299

Epoch: 5| Step: 1
Training loss: 0.6074711084365845
Validation loss: 1.8051261312218123

Epoch: 5| Step: 2
Training loss: 0.36040830612182617
Validation loss: 1.8289669918757614

Epoch: 5| Step: 3
Training loss: 0.3954766094684601
Validation loss: 1.8830387515406455

Epoch: 5| Step: 4
Training loss: 0.792359471321106
Validation loss: 1.9690285408368675

Epoch: 5| Step: 5
Training loss: 0.44868364930152893
Validation loss: 1.9724959045328119

Epoch: 5| Step: 6
Training loss: 0.547565758228302
Validation loss: 1.9672822849724882

Epoch: 5| Step: 7
Training loss: 0.6004148721694946
Validation loss: 1.9281191082410916

Epoch: 5| Step: 8
Training loss: 0.6658017039299011
Validation loss: 1.8992110580526373

Epoch: 5| Step: 9
Training loss: 0.4433356821537018
Validation loss: 1.851406325576126

Epoch: 5| Step: 10
Training loss: 0.6118988990783691
Validation loss: 1.8446671911465224

Epoch: 307| Step: 0
Training loss: 0.49796104431152344
Validation loss: 1.7993097048933788

Epoch: 5| Step: 1
Training loss: 0.5881019234657288
Validation loss: 1.8011846029630272

Epoch: 5| Step: 2
Training loss: 0.4252271056175232
Validation loss: 1.7951602012880388

Epoch: 5| Step: 3
Training loss: 0.6344485878944397
Validation loss: 1.8334423944514284

Epoch: 5| Step: 4
Training loss: 0.4000937044620514
Validation loss: 1.8486203275701052

Epoch: 5| Step: 5
Training loss: 0.6049738526344299
Validation loss: 1.8711538135364492

Epoch: 5| Step: 6
Training loss: 0.4524795114994049
Validation loss: 1.89390811099801

Epoch: 5| Step: 7
Training loss: 0.37514734268188477
Validation loss: 1.8533845338770139

Epoch: 5| Step: 8
Training loss: 0.6235793828964233
Validation loss: 1.8376167076890186

Epoch: 5| Step: 9
Training loss: 0.5612659454345703
Validation loss: 1.8309362242298741

Epoch: 5| Step: 10
Training loss: 0.5984705090522766
Validation loss: 1.794831791231709

Epoch: 308| Step: 0
Training loss: 0.4456210136413574
Validation loss: 1.8292199437336256

Epoch: 5| Step: 1
Training loss: 0.3743269741535187
Validation loss: 1.7982076983298025

Epoch: 5| Step: 2
Training loss: 0.40420469641685486
Validation loss: 1.802764340113568

Epoch: 5| Step: 3
Training loss: 0.7341907620429993
Validation loss: 1.7828904582608132

Epoch: 5| Step: 4
Training loss: 0.6882191896438599
Validation loss: 1.8022713443284393

Epoch: 5| Step: 5
Training loss: 0.5245370268821716
Validation loss: 1.8107993320752216

Epoch: 5| Step: 6
Training loss: 0.3392550051212311
Validation loss: 1.8055999099567372

Epoch: 5| Step: 7
Training loss: 0.32027122378349304
Validation loss: 1.830107342812323

Epoch: 5| Step: 8
Training loss: 0.5472856760025024
Validation loss: 1.8109269513878772

Epoch: 5| Step: 9
Training loss: 0.458466112613678
Validation loss: 1.7836754040051532

Epoch: 5| Step: 10
Training loss: 0.5662081241607666
Validation loss: 1.7957618864633704

Epoch: 309| Step: 0
Training loss: 0.33718234300613403
Validation loss: 1.8074430522098337

Epoch: 5| Step: 1
Training loss: 0.4434918463230133
Validation loss: 1.8098983072465467

Epoch: 5| Step: 2
Training loss: 0.7353354692459106
Validation loss: 1.8213399174392864

Epoch: 5| Step: 3
Training loss: 0.5125113129615784
Validation loss: 1.8278645828206053

Epoch: 5| Step: 4
Training loss: 0.41716432571411133
Validation loss: 1.8262684319608955

Epoch: 5| Step: 5
Training loss: 0.36843040585517883
Validation loss: 1.808935639678791

Epoch: 5| Step: 6
Training loss: 0.5822736024856567
Validation loss: 1.791339987067766

Epoch: 5| Step: 7
Training loss: 0.5494335293769836
Validation loss: 1.800027822935453

Epoch: 5| Step: 8
Training loss: 0.5789573788642883
Validation loss: 1.8291443688895113

Epoch: 5| Step: 9
Training loss: 0.5067570805549622
Validation loss: 1.7943984885369577

Epoch: 5| Step: 10
Training loss: 0.5356332063674927
Validation loss: 1.8320098807734828

Epoch: 310| Step: 0
Training loss: 0.5438008904457092
Validation loss: 1.8149990497096893

Epoch: 5| Step: 1
Training loss: 0.6790052056312561
Validation loss: 1.8335758486101705

Epoch: 5| Step: 2
Training loss: 0.40031132102012634
Validation loss: 1.838309705898326

Epoch: 5| Step: 3
Training loss: 0.29410505294799805
Validation loss: 1.846248710027305

Epoch: 5| Step: 4
Training loss: 0.4842102527618408
Validation loss: 1.8498370826885264

Epoch: 5| Step: 5
Training loss: 0.5013546943664551
Validation loss: 1.8805261440174554

Epoch: 5| Step: 6
Training loss: 0.5279984474182129
Validation loss: 1.8608730634053547

Epoch: 5| Step: 7
Training loss: 0.7510699033737183
Validation loss: 1.867631253375802

Epoch: 5| Step: 8
Training loss: 0.3345230221748352
Validation loss: 1.8853503952744186

Epoch: 5| Step: 9
Training loss: 0.5706321001052856
Validation loss: 1.854187265519173

Epoch: 5| Step: 10
Training loss: 0.5960068702697754
Validation loss: 1.8435520266973844

Epoch: 311| Step: 0
Training loss: 0.36876407265663147
Validation loss: 1.8530612453337638

Epoch: 5| Step: 1
Training loss: 0.5619933009147644
Validation loss: 1.8423126102775655

Epoch: 5| Step: 2
Training loss: 0.6542535424232483
Validation loss: 1.8125648062716249

Epoch: 5| Step: 3
Training loss: 0.5166248083114624
Validation loss: 1.853403857959214

Epoch: 5| Step: 4
Training loss: 0.5726345181465149
Validation loss: 1.8438988654844222

Epoch: 5| Step: 5
Training loss: 0.6305496096611023
Validation loss: 1.8417649474195255

Epoch: 5| Step: 6
Training loss: 0.6032091379165649
Validation loss: 1.8627574866817844

Epoch: 5| Step: 7
Training loss: 0.36621028184890747
Validation loss: 1.9177234262548468

Epoch: 5| Step: 8
Training loss: 0.25356513261795044
Validation loss: 1.9194665775504163

Epoch: 5| Step: 9
Training loss: 0.3641284704208374
Validation loss: 1.9030121603319723

Epoch: 5| Step: 10
Training loss: 0.3325387239456177
Validation loss: 1.8654713566585253

Epoch: 312| Step: 0
Training loss: 0.3205806314945221
Validation loss: 1.8312386261519564

Epoch: 5| Step: 1
Training loss: 0.9145450592041016
Validation loss: 1.81536445694585

Epoch: 5| Step: 2
Training loss: 0.42762964963912964
Validation loss: 1.833074390247304

Epoch: 5| Step: 3
Training loss: 0.434932142496109
Validation loss: 1.8354210520303378

Epoch: 5| Step: 4
Training loss: 0.3693017065525055
Validation loss: 1.8499998431051932

Epoch: 5| Step: 5
Training loss: 0.6026022434234619
Validation loss: 1.8460930534588393

Epoch: 5| Step: 6
Training loss: 0.4202725291252136
Validation loss: 1.8303723873630646

Epoch: 5| Step: 7
Training loss: 0.35905224084854126
Validation loss: 1.7970324011259182

Epoch: 5| Step: 8
Training loss: 0.5092355012893677
Validation loss: 1.8067430808979978

Epoch: 5| Step: 9
Training loss: 0.5338840484619141
Validation loss: 1.7748738386297738

Epoch: 5| Step: 10
Training loss: 0.5696806907653809
Validation loss: 1.7677164462304884

Epoch: 313| Step: 0
Training loss: 0.41734594106674194
Validation loss: 1.7475670306913313

Epoch: 5| Step: 1
Training loss: 0.43323835730552673
Validation loss: 1.7570293129131358

Epoch: 5| Step: 2
Training loss: 0.2666989862918854
Validation loss: 1.7594951391220093

Epoch: 5| Step: 3
Training loss: 0.6528496742248535
Validation loss: 1.7665851308453469

Epoch: 5| Step: 4
Training loss: 0.7389695048332214
Validation loss: 1.7842835585276287

Epoch: 5| Step: 5
Training loss: 0.3753078579902649
Validation loss: 1.7954078271824827

Epoch: 5| Step: 6
Training loss: 0.42455124855041504
Validation loss: 1.831894015753141

Epoch: 5| Step: 7
Training loss: 0.5085153579711914
Validation loss: 1.8520438824930499

Epoch: 5| Step: 8
Training loss: 0.509072482585907
Validation loss: 1.873946394971622

Epoch: 5| Step: 9
Training loss: 0.30540555715560913
Validation loss: 1.8315569841733543

Epoch: 5| Step: 10
Training loss: 0.5443415641784668
Validation loss: 1.828934496448886

Epoch: 314| Step: 0
Training loss: 0.9527467489242554
Validation loss: 1.8268230909942298

Epoch: 5| Step: 1
Training loss: 0.29214316606521606
Validation loss: 1.8100726437825028

Epoch: 5| Step: 2
Training loss: 0.4319984018802643
Validation loss: 1.7986803977720198

Epoch: 5| Step: 3
Training loss: 0.6443139314651489
Validation loss: 1.7946578482145905

Epoch: 5| Step: 4
Training loss: 0.42975515127182007
Validation loss: 1.788611101847823

Epoch: 5| Step: 5
Training loss: 0.2611285150051117
Validation loss: 1.7873230365014845

Epoch: 5| Step: 6
Training loss: 0.37663009762763977
Validation loss: 1.8234918655887726

Epoch: 5| Step: 7
Training loss: 0.5930832624435425
Validation loss: 1.8358705274520382

Epoch: 5| Step: 8
Training loss: 0.2959340512752533
Validation loss: 1.824330496531661

Epoch: 5| Step: 9
Training loss: 0.2999628782272339
Validation loss: 1.8250686814708095

Epoch: 5| Step: 10
Training loss: 0.612663984298706
Validation loss: 1.7695309423631238

Epoch: 315| Step: 0
Training loss: 0.39159584045410156
Validation loss: 1.7558365355255783

Epoch: 5| Step: 1
Training loss: 0.3671957850456238
Validation loss: 1.7645779168733986

Epoch: 5| Step: 2
Training loss: 0.3933698534965515
Validation loss: 1.7977173597581926

Epoch: 5| Step: 3
Training loss: 0.5253190994262695
Validation loss: 1.7492246320170741

Epoch: 5| Step: 4
Training loss: 0.7689959406852722
Validation loss: 1.7677431286022227

Epoch: 5| Step: 5
Training loss: 0.2542012631893158
Validation loss: 1.7699951997367285

Epoch: 5| Step: 6
Training loss: 0.49986371397972107
Validation loss: 1.7966130266907394

Epoch: 5| Step: 7
Training loss: 0.3682955205440521
Validation loss: 1.8282627405658844

Epoch: 5| Step: 8
Training loss: 0.4248265326023102
Validation loss: 1.819185592794931

Epoch: 5| Step: 9
Training loss: 0.6638587117195129
Validation loss: 1.8097931697804441

Epoch: 5| Step: 10
Training loss: 0.37951403856277466
Validation loss: 1.8083740318975141

Epoch: 316| Step: 0
Training loss: 0.7230733633041382
Validation loss: 1.784471163185694

Epoch: 5| Step: 1
Training loss: 0.35998234152793884
Validation loss: 1.7518514766488025

Epoch: 5| Step: 2
Training loss: 0.5042169690132141
Validation loss: 1.7441768287330546

Epoch: 5| Step: 3
Training loss: 0.2618139386177063
Validation loss: 1.7466270910796298

Epoch: 5| Step: 4
Training loss: 0.3021755814552307
Validation loss: 1.7594745774422922

Epoch: 5| Step: 5
Training loss: 0.23323512077331543
Validation loss: 1.7605854413842643

Epoch: 5| Step: 6
Training loss: 0.6238098740577698
Validation loss: 1.763524765609413

Epoch: 5| Step: 7
Training loss: 0.43878859281539917
Validation loss: 1.7607996707321496

Epoch: 5| Step: 8
Training loss: 0.38445261120796204
Validation loss: 1.769312652208472

Epoch: 5| Step: 9
Training loss: 0.5939540266990662
Validation loss: 1.77016326432587

Epoch: 5| Step: 10
Training loss: 0.6524989604949951
Validation loss: 1.789798790408719

Epoch: 317| Step: 0
Training loss: 0.31760749220848083
Validation loss: 1.7781369750217726

Epoch: 5| Step: 1
Training loss: 0.25141048431396484
Validation loss: 1.7826391650784401

Epoch: 5| Step: 2
Training loss: 0.5201471447944641
Validation loss: 1.8120972289833972

Epoch: 5| Step: 3
Training loss: 0.3696557283401489
Validation loss: 1.8368685117331884

Epoch: 5| Step: 4
Training loss: 0.23375527560710907
Validation loss: 1.8185769729716803

Epoch: 5| Step: 5
Training loss: 0.5614944696426392
Validation loss: 1.7816808787725305

Epoch: 5| Step: 6
Training loss: 0.4134986996650696
Validation loss: 1.7808913133477653

Epoch: 5| Step: 7
Training loss: 0.29888972640037537
Validation loss: 1.8117412341538297

Epoch: 5| Step: 8
Training loss: 0.4779624938964844
Validation loss: 1.7679338609018633

Epoch: 5| Step: 9
Training loss: 0.692867636680603
Validation loss: 1.774664427644463

Epoch: 5| Step: 10
Training loss: 0.7281819581985474
Validation loss: 1.7726305197643977

Epoch: 318| Step: 0
Training loss: 0.5151289701461792
Validation loss: 1.7946731531491844

Epoch: 5| Step: 1
Training loss: 0.418415367603302
Validation loss: 1.8454450176608177

Epoch: 5| Step: 2
Training loss: 0.334479421377182
Validation loss: 1.851818484644736

Epoch: 5| Step: 3
Training loss: 0.2747253477573395
Validation loss: 1.8408288468596756

Epoch: 5| Step: 4
Training loss: 0.622624397277832
Validation loss: 1.8371256897526402

Epoch: 5| Step: 5
Training loss: 0.4841436445713043
Validation loss: 1.8163782114623694

Epoch: 5| Step: 6
Training loss: 0.36392611265182495
Validation loss: 1.8086666394305486

Epoch: 5| Step: 7
Training loss: 0.5983734130859375
Validation loss: 1.7833961632943922

Epoch: 5| Step: 8
Training loss: 0.26253849267959595
Validation loss: 1.784978582013038

Epoch: 5| Step: 9
Training loss: 0.4349428117275238
Validation loss: 1.7476334366747128

Epoch: 5| Step: 10
Training loss: 0.22809192538261414
Validation loss: 1.7610677185878958

Epoch: 319| Step: 0
Training loss: 0.5308172702789307
Validation loss: 1.746441706534355

Epoch: 5| Step: 1
Training loss: 0.39265817403793335
Validation loss: 1.7577169326043898

Epoch: 5| Step: 2
Training loss: 0.4178987443447113
Validation loss: 1.7568856477737427

Epoch: 5| Step: 3
Training loss: 0.27433547377586365
Validation loss: 1.7449148906174528

Epoch: 5| Step: 4
Training loss: 0.29338735342025757
Validation loss: 1.7457424697055612

Epoch: 5| Step: 5
Training loss: 0.45530444383621216
Validation loss: 1.7642483019059705

Epoch: 5| Step: 6
Training loss: 0.3551168143749237
Validation loss: 1.7945226443711149

Epoch: 5| Step: 7
Training loss: 0.5687438249588013
Validation loss: 1.827734270403462

Epoch: 5| Step: 8
Training loss: 0.464525043964386
Validation loss: 1.8595101705161474

Epoch: 5| Step: 9
Training loss: 0.6697260141372681
Validation loss: 1.8820442768835253

Epoch: 5| Step: 10
Training loss: 0.6380617022514343
Validation loss: 1.8493448726592525

Epoch: 320| Step: 0
Training loss: 0.6032253503799438
Validation loss: 1.8161869689982424

Epoch: 5| Step: 1
Training loss: 0.5108480453491211
Validation loss: 1.7899252342921432

Epoch: 5| Step: 2
Training loss: 0.2732602059841156
Validation loss: 1.8249228436459777

Epoch: 5| Step: 3
Training loss: 0.6617283821105957
Validation loss: 1.7841884231054654

Epoch: 5| Step: 4
Training loss: 0.616594135761261
Validation loss: 1.7565474394829041

Epoch: 5| Step: 5
Training loss: 0.5150781869888306
Validation loss: 1.7443741342072845

Epoch: 5| Step: 6
Training loss: 0.3836902976036072
Validation loss: 1.7403164448276642

Epoch: 5| Step: 7
Training loss: 0.37006324529647827
Validation loss: 1.7137778664147982

Epoch: 5| Step: 8
Training loss: 0.4210479259490967
Validation loss: 1.7480813187937583

Epoch: 5| Step: 9
Training loss: 0.33844977617263794
Validation loss: 1.7622231847496443

Epoch: 5| Step: 10
Training loss: 0.35448363423347473
Validation loss: 1.7764863480803788

Epoch: 321| Step: 0
Training loss: 0.4419219493865967
Validation loss: 1.8131256590607345

Epoch: 5| Step: 1
Training loss: 0.3010479807853699
Validation loss: 1.7994839145291237

Epoch: 5| Step: 2
Training loss: 0.3885512948036194
Validation loss: 1.7672082826655398

Epoch: 5| Step: 3
Training loss: 0.35257941484451294
Validation loss: 1.7577304814451484

Epoch: 5| Step: 4
Training loss: 0.4082888960838318
Validation loss: 1.7895364428079257

Epoch: 5| Step: 5
Training loss: 0.27839991450309753
Validation loss: 1.7917996568064536

Epoch: 5| Step: 6
Training loss: 0.4894162118434906
Validation loss: 1.783104746572433

Epoch: 5| Step: 7
Training loss: 0.5639881491661072
Validation loss: 1.8111041156194543

Epoch: 5| Step: 8
Training loss: 0.7402717471122742
Validation loss: 1.7970491929720807

Epoch: 5| Step: 9
Training loss: 0.42356157302856445
Validation loss: 1.8031260185344244

Epoch: 5| Step: 10
Training loss: 0.6718440651893616
Validation loss: 1.8187258935743762

Epoch: 322| Step: 0
Training loss: 0.3395203948020935
Validation loss: 1.826340558708355

Epoch: 5| Step: 1
Training loss: 0.3147321343421936
Validation loss: 1.8244532205725228

Epoch: 5| Step: 2
Training loss: 0.510894238948822
Validation loss: 1.8301611549110823

Epoch: 5| Step: 3
Training loss: 0.7157589197158813
Validation loss: 1.8097802554407427

Epoch: 5| Step: 4
Training loss: 0.21773386001586914
Validation loss: 1.7657720940087431

Epoch: 5| Step: 5
Training loss: 0.28074589371681213
Validation loss: 1.7380714403685702

Epoch: 5| Step: 6
Training loss: 0.4649128019809723
Validation loss: 1.742345968882243

Epoch: 5| Step: 7
Training loss: 0.6900277733802795
Validation loss: 1.7305560881091702

Epoch: 5| Step: 8
Training loss: 0.4542686343193054
Validation loss: 1.7135744556303947

Epoch: 5| Step: 9
Training loss: 0.7410866618156433
Validation loss: 1.72542562407832

Epoch: 5| Step: 10
Training loss: 0.47690144181251526
Validation loss: 1.736448698146369

Epoch: 323| Step: 0
Training loss: 0.36459264159202576
Validation loss: 1.7466463132571148

Epoch: 5| Step: 1
Training loss: 0.31311163306236267
Validation loss: 1.7775930281608336

Epoch: 5| Step: 2
Training loss: 0.3838779926300049
Validation loss: 1.7762922420296618

Epoch: 5| Step: 3
Training loss: 0.41018757224082947
Validation loss: 1.7609402659118816

Epoch: 5| Step: 4
Training loss: 0.2947046756744385
Validation loss: 1.792787673652813

Epoch: 5| Step: 5
Training loss: 0.20288893580436707
Validation loss: 1.7945556204806092

Epoch: 5| Step: 6
Training loss: 0.7997825741767883
Validation loss: 1.79153839747111

Epoch: 5| Step: 7
Training loss: 0.3732542097568512
Validation loss: 1.817935255266005

Epoch: 5| Step: 8
Training loss: 0.6365801095962524
Validation loss: 1.7989369028358049

Epoch: 5| Step: 9
Training loss: 0.6524456143379211
Validation loss: 1.8037867405081307

Epoch: 5| Step: 10
Training loss: 0.4511071443557739
Validation loss: 1.8075317490485407

Epoch: 324| Step: 0
Training loss: 0.6672764420509338
Validation loss: 1.7972790874460691

Epoch: 5| Step: 1
Training loss: 0.4328617453575134
Validation loss: 1.824029012392926

Epoch: 5| Step: 2
Training loss: 0.5372185707092285
Validation loss: 1.7872243145460724

Epoch: 5| Step: 3
Training loss: 0.3321235775947571
Validation loss: 1.8045476521215131

Epoch: 5| Step: 4
Training loss: 0.5334766507148743
Validation loss: 1.8264552034357542

Epoch: 5| Step: 5
Training loss: 0.28850477933883667
Validation loss: 1.854603975049911

Epoch: 5| Step: 6
Training loss: 0.5342321991920471
Validation loss: 1.8399259608278993

Epoch: 5| Step: 7
Training loss: 0.5224274396896362
Validation loss: 1.884472418856877

Epoch: 5| Step: 8
Training loss: 0.33982574939727783
Validation loss: 1.8755390438982236

Epoch: 5| Step: 9
Training loss: 0.3207855820655823
Validation loss: 1.834249646432938

Epoch: 5| Step: 10
Training loss: 0.2662249505519867
Validation loss: 1.8351970641843733

Epoch: 325| Step: 0
Training loss: 0.20785820484161377
Validation loss: 1.799386412866654

Epoch: 5| Step: 1
Training loss: 0.35592907667160034
Validation loss: 1.8051506242444437

Epoch: 5| Step: 2
Training loss: 0.3889513313770294
Validation loss: 1.7679437770638415

Epoch: 5| Step: 3
Training loss: 0.6408030390739441
Validation loss: 1.7512300181132492

Epoch: 5| Step: 4
Training loss: 0.24257898330688477
Validation loss: 1.7941843271255493

Epoch: 5| Step: 5
Training loss: 0.6500428915023804
Validation loss: 1.7629838425626037

Epoch: 5| Step: 6
Training loss: 0.3235130310058594
Validation loss: 1.780092082997804

Epoch: 5| Step: 7
Training loss: 0.41141873598098755
Validation loss: 1.7674820756399503

Epoch: 5| Step: 8
Training loss: 0.36195388436317444
Validation loss: 1.756401288893915

Epoch: 5| Step: 9
Training loss: 0.4338878095149994
Validation loss: 1.8017044528838126

Epoch: 5| Step: 10
Training loss: 0.23508863151073456
Validation loss: 1.8219718599832186

Epoch: 326| Step: 0
Training loss: 0.28657007217407227
Validation loss: 1.7886352090425388

Epoch: 5| Step: 1
Training loss: 0.5936199426651001
Validation loss: 1.7690618781633274

Epoch: 5| Step: 2
Training loss: 0.2699069678783417
Validation loss: 1.7703096135970084

Epoch: 5| Step: 3
Training loss: 0.26934707164764404
Validation loss: 1.7611715370608914

Epoch: 5| Step: 4
Training loss: 0.43427032232284546
Validation loss: 1.7452680077604068

Epoch: 5| Step: 5
Training loss: 0.24782446026802063
Validation loss: 1.7505342345083914

Epoch: 5| Step: 6
Training loss: 0.37002652883529663
Validation loss: 1.7704068255680863

Epoch: 5| Step: 7
Training loss: 0.5748920440673828
Validation loss: 1.8117838700612385

Epoch: 5| Step: 8
Training loss: 0.4406396746635437
Validation loss: 1.8296658672312254

Epoch: 5| Step: 9
Training loss: 0.33423322439193726
Validation loss: 1.813811085557425

Epoch: 5| Step: 10
Training loss: 0.4904092848300934
Validation loss: 1.8571767255824099

Epoch: 327| Step: 0
Training loss: 0.37668633460998535
Validation loss: 1.8509143398654075

Epoch: 5| Step: 1
Training loss: 0.6489288210868835
Validation loss: 1.8226323948111585

Epoch: 5| Step: 2
Training loss: 0.4131351113319397
Validation loss: 1.801651841850691

Epoch: 5| Step: 3
Training loss: 0.3367549479007721
Validation loss: 1.7979515316665813

Epoch: 5| Step: 4
Training loss: 0.45454517006874084
Validation loss: 1.808481147212367

Epoch: 5| Step: 5
Training loss: 0.3281237483024597
Validation loss: 1.7595751388098604

Epoch: 5| Step: 6
Training loss: 0.2759779095649719
Validation loss: 1.7952119137651177

Epoch: 5| Step: 7
Training loss: 0.6595569849014282
Validation loss: 1.811120424219357

Epoch: 5| Step: 8
Training loss: 0.4892082214355469
Validation loss: 1.8066596241407498

Epoch: 5| Step: 9
Training loss: 0.5499634146690369
Validation loss: 1.8128236263029036

Epoch: 5| Step: 10
Training loss: 0.34312766790390015
Validation loss: 1.80330103828061

Epoch: 328| Step: 0
Training loss: 0.2705098092556
Validation loss: 1.7877092028176913

Epoch: 5| Step: 1
Training loss: 0.3362847864627838
Validation loss: 1.7615825091638873

Epoch: 5| Step: 2
Training loss: 0.49531587958335876
Validation loss: 1.7692621202879055

Epoch: 5| Step: 3
Training loss: 0.6613544225692749
Validation loss: 1.769235477652601

Epoch: 5| Step: 4
Training loss: 0.4508475661277771
Validation loss: 1.792414253757846

Epoch: 5| Step: 5
Training loss: 0.6681259870529175
Validation loss: 1.745462171493038

Epoch: 5| Step: 6
Training loss: 0.5377618670463562
Validation loss: 1.7462063143330235

Epoch: 5| Step: 7
Training loss: 0.2959778308868408
Validation loss: 1.7715426196334183

Epoch: 5| Step: 8
Training loss: 0.495053768157959
Validation loss: 1.8052296138578845

Epoch: 5| Step: 9
Training loss: 0.40611663460731506
Validation loss: 1.8429838880415885

Epoch: 5| Step: 10
Training loss: 0.23569157719612122
Validation loss: 1.8199744404003184

Epoch: 329| Step: 0
Training loss: 0.40905147790908813
Validation loss: 1.7729067353792087

Epoch: 5| Step: 1
Training loss: 0.46627146005630493
Validation loss: 1.775875445335142

Epoch: 5| Step: 2
Training loss: 0.5681762099266052
Validation loss: 1.7792532238908993

Epoch: 5| Step: 3
Training loss: 0.6035205125808716
Validation loss: 1.8024163323064004

Epoch: 5| Step: 4
Training loss: 0.35895586013793945
Validation loss: 1.8229304141895746

Epoch: 5| Step: 5
Training loss: 0.3937431275844574
Validation loss: 1.8166094133930821

Epoch: 5| Step: 6
Training loss: 0.37286847829818726
Validation loss: 1.8171042062902962

Epoch: 5| Step: 7
Training loss: 0.38401323556900024
Validation loss: 1.8494893145817581

Epoch: 5| Step: 8
Training loss: 0.4367622435092926
Validation loss: 1.8769212025468067

Epoch: 5| Step: 9
Training loss: 0.31060779094696045
Validation loss: 1.8787414860981766

Epoch: 5| Step: 10
Training loss: 0.46396955847740173
Validation loss: 1.8934739276927004

Epoch: 330| Step: 0
Training loss: 0.4692201614379883
Validation loss: 1.881300864681121

Epoch: 5| Step: 1
Training loss: 0.31306618452072144
Validation loss: 1.8430408482910485

Epoch: 5| Step: 2
Training loss: 0.22133572399616241
Validation loss: 1.7859510619153258

Epoch: 5| Step: 3
Training loss: 0.40623894333839417
Validation loss: 1.7740312660894086

Epoch: 5| Step: 4
Training loss: 0.27963346242904663
Validation loss: 1.7892533579180319

Epoch: 5| Step: 5
Training loss: 0.32716450095176697
Validation loss: 1.7784719210799023

Epoch: 5| Step: 6
Training loss: 0.5950576663017273
Validation loss: 1.811373673459535

Epoch: 5| Step: 7
Training loss: 0.765030026435852
Validation loss: 1.8201550745194959

Epoch: 5| Step: 8
Training loss: 0.43766528367996216
Validation loss: 1.8284380333397978

Epoch: 5| Step: 9
Training loss: 0.4432179927825928
Validation loss: 1.8476012650356497

Epoch: 5| Step: 10
Training loss: 0.4644649922847748
Validation loss: 1.84314436809991

Epoch: 331| Step: 0
Training loss: 0.5377140045166016
Validation loss: 1.8633253010370399

Epoch: 5| Step: 1
Training loss: 0.3273831903934479
Validation loss: 1.8535202254531205

Epoch: 5| Step: 2
Training loss: 0.5306146740913391
Validation loss: 1.811833163743378

Epoch: 5| Step: 3
Training loss: 0.44794565439224243
Validation loss: 1.824747771345159

Epoch: 5| Step: 4
Training loss: 0.38589829206466675
Validation loss: 1.8031728472760928

Epoch: 5| Step: 5
Training loss: 0.21898463368415833
Validation loss: 1.7885850680771695

Epoch: 5| Step: 6
Training loss: 0.5762099027633667
Validation loss: 1.7791374960253317

Epoch: 5| Step: 7
Training loss: 0.21796290576457977
Validation loss: 1.7796983629144647

Epoch: 5| Step: 8
Training loss: 0.36050406098365784
Validation loss: 1.774695796351279

Epoch: 5| Step: 9
Training loss: 0.3613632619380951
Validation loss: 1.7977001333749423

Epoch: 5| Step: 10
Training loss: 0.5048272609710693
Validation loss: 1.7762428086291078

Epoch: 332| Step: 0
Training loss: 0.5179149508476257
Validation loss: 1.7935000811853716

Epoch: 5| Step: 1
Training loss: 0.5716770887374878
Validation loss: 1.8251270235225718

Epoch: 5| Step: 2
Training loss: 0.29321643710136414
Validation loss: 1.8491041839763682

Epoch: 5| Step: 3
Training loss: 0.18939335644245148
Validation loss: 1.8459834244943434

Epoch: 5| Step: 4
Training loss: 0.42921748757362366
Validation loss: 1.836428016744634

Epoch: 5| Step: 5
Training loss: 0.12027845531702042
Validation loss: 1.7957699914132395

Epoch: 5| Step: 6
Training loss: 0.31097203493118286
Validation loss: 1.7787584527846305

Epoch: 5| Step: 7
Training loss: 0.355916827917099
Validation loss: 1.7731983264287312

Epoch: 5| Step: 8
Training loss: 0.3417450487613678
Validation loss: 1.76344177287112

Epoch: 5| Step: 9
Training loss: 0.4791285991668701
Validation loss: 1.7652790610508253

Epoch: 5| Step: 10
Training loss: 0.6147923469543457
Validation loss: 1.749563427381618

Epoch: 333| Step: 0
Training loss: 0.17800888419151306
Validation loss: 1.7212891681219942

Epoch: 5| Step: 1
Training loss: 0.39298439025878906
Validation loss: 1.730386354589975

Epoch: 5| Step: 2
Training loss: 0.6089889407157898
Validation loss: 1.72121819244918

Epoch: 5| Step: 3
Training loss: 0.21389761567115784
Validation loss: 1.7589242381434287

Epoch: 5| Step: 4
Training loss: 0.20835880935192108
Validation loss: 1.7700372178067443

Epoch: 5| Step: 5
Training loss: 0.8240111470222473
Validation loss: 1.7616288533774755

Epoch: 5| Step: 6
Training loss: 0.3790205121040344
Validation loss: 1.8019863841354207

Epoch: 5| Step: 7
Training loss: 0.49364060163497925
Validation loss: 1.8146205191971154

Epoch: 5| Step: 8
Training loss: 0.27217572927474976
Validation loss: 1.7937154334078553

Epoch: 5| Step: 9
Training loss: 0.2401237040758133
Validation loss: 1.7786517630341232

Epoch: 5| Step: 10
Training loss: 0.2900923490524292
Validation loss: 1.7520472913660028

Epoch: 334| Step: 0
Training loss: 0.38180413842201233
Validation loss: 1.7469573725936234

Epoch: 5| Step: 1
Training loss: 0.26023319363594055
Validation loss: 1.7479362244247107

Epoch: 5| Step: 2
Training loss: 0.24353182315826416
Validation loss: 1.773382967518222

Epoch: 5| Step: 3
Training loss: 0.24780602753162384
Validation loss: 1.7784652453596874

Epoch: 5| Step: 4
Training loss: 0.405148983001709
Validation loss: 1.7416772432224725

Epoch: 5| Step: 5
Training loss: 0.5224884748458862
Validation loss: 1.7648505523640623

Epoch: 5| Step: 6
Training loss: 0.5139000415802002
Validation loss: 1.7755248533782138

Epoch: 5| Step: 7
Training loss: 0.5203758478164673
Validation loss: 1.7369931205626457

Epoch: 5| Step: 8
Training loss: 0.4629089832305908
Validation loss: 1.7573622413860854

Epoch: 5| Step: 9
Training loss: 0.2260577380657196
Validation loss: 1.7963793841741418

Epoch: 5| Step: 10
Training loss: 0.24262653291225433
Validation loss: 1.8194363219763643

Epoch: 335| Step: 0
Training loss: 0.2848951816558838
Validation loss: 1.8080606640026133

Epoch: 5| Step: 1
Training loss: 0.1999601125717163
Validation loss: 1.7998157150001937

Epoch: 5| Step: 2
Training loss: 0.39396050572395325
Validation loss: 1.7661575014873216

Epoch: 5| Step: 3
Training loss: 0.6751323342323303
Validation loss: 1.7781177643806703

Epoch: 5| Step: 4
Training loss: 0.44570255279541016
Validation loss: 1.7656865683935021

Epoch: 5| Step: 5
Training loss: 0.4111263155937195
Validation loss: 1.742655925853278

Epoch: 5| Step: 6
Training loss: 0.4938625693321228
Validation loss: 1.7402558954813148

Epoch: 5| Step: 7
Training loss: 0.20115026831626892
Validation loss: 1.7583951911618632

Epoch: 5| Step: 8
Training loss: 0.2645077109336853
Validation loss: 1.732934421108615

Epoch: 5| Step: 9
Training loss: 0.21619825065135956
Validation loss: 1.777247549385153

Epoch: 5| Step: 10
Training loss: 0.3193965554237366
Validation loss: 1.7727299326209611

Epoch: 336| Step: 0
Training loss: 0.60261070728302
Validation loss: 1.7752296501590359

Epoch: 5| Step: 1
Training loss: 0.28760963678359985
Validation loss: 1.7839780264003302

Epoch: 5| Step: 2
Training loss: 0.45668214559555054
Validation loss: 1.7602777583624727

Epoch: 5| Step: 3
Training loss: 0.2445993423461914
Validation loss: 1.783203617219002

Epoch: 5| Step: 4
Training loss: 0.39108315110206604
Validation loss: 1.7742455313282628

Epoch: 5| Step: 5
Training loss: 0.28949451446533203
Validation loss: 1.7825371283356861

Epoch: 5| Step: 6
Training loss: 0.4214864671230316
Validation loss: 1.791718739335255

Epoch: 5| Step: 7
Training loss: 0.41799822449684143
Validation loss: 1.8107599801914667

Epoch: 5| Step: 8
Training loss: 0.18793991208076477
Validation loss: 1.8350232878038961

Epoch: 5| Step: 9
Training loss: 0.2885262072086334
Validation loss: 1.838632579772703

Epoch: 5| Step: 10
Training loss: 0.4169257581233978
Validation loss: 1.8126716498405702

Epoch: 337| Step: 0
Training loss: 0.35932713747024536
Validation loss: 1.8136959165655158

Epoch: 5| Step: 1
Training loss: 0.17206302285194397
Validation loss: 1.8149629856950493

Epoch: 5| Step: 2
Training loss: 0.20597238838672638
Validation loss: 1.7901148655081307

Epoch: 5| Step: 3
Training loss: 0.1676182746887207
Validation loss: 1.8028795026963758

Epoch: 5| Step: 4
Training loss: 0.171980619430542
Validation loss: 1.786238037129884

Epoch: 5| Step: 5
Training loss: 0.23768790066242218
Validation loss: 1.799956221734324

Epoch: 5| Step: 6
Training loss: 0.5391565561294556
Validation loss: 1.7618912560965425

Epoch: 5| Step: 7
Training loss: 0.27355897426605225
Validation loss: 1.8110897259045673

Epoch: 5| Step: 8
Training loss: 0.5620636940002441
Validation loss: 1.7860453615906418

Epoch: 5| Step: 9
Training loss: 0.7701489925384521
Validation loss: 1.755022750105909

Epoch: 5| Step: 10
Training loss: 0.3169174790382385
Validation loss: 1.7705259438483947

Epoch: 338| Step: 0
Training loss: 0.3309217393398285
Validation loss: 1.7850928716762091

Epoch: 5| Step: 1
Training loss: 0.31889909505844116
Validation loss: 1.7818403602928243

Epoch: 5| Step: 2
Training loss: 0.48816949129104614
Validation loss: 1.7714101050489692

Epoch: 5| Step: 3
Training loss: 0.20441336929798126
Validation loss: 1.7768700917561848

Epoch: 5| Step: 4
Training loss: 0.16444171965122223
Validation loss: 1.7721883750730945

Epoch: 5| Step: 5
Training loss: 0.7023237943649292
Validation loss: 1.7860778377902122

Epoch: 5| Step: 6
Training loss: 0.3411370813846588
Validation loss: 1.7228351498162875

Epoch: 5| Step: 7
Training loss: 0.22247934341430664
Validation loss: 1.708517361712712

Epoch: 5| Step: 8
Training loss: 0.30579909682273865
Validation loss: 1.7010086146734094

Epoch: 5| Step: 9
Training loss: 0.3364332914352417
Validation loss: 1.690731167793274

Epoch: 5| Step: 10
Training loss: 0.27350908517837524
Validation loss: 1.698364088612218

Epoch: 339| Step: 0
Training loss: 0.2419109344482422
Validation loss: 1.7240630529260124

Epoch: 5| Step: 1
Training loss: 0.3507001996040344
Validation loss: 1.7164697890640588

Epoch: 5| Step: 2
Training loss: 0.34950321912765503
Validation loss: 1.7501969004190097

Epoch: 5| Step: 3
Training loss: 0.26095014810562134
Validation loss: 1.7792645795370943

Epoch: 5| Step: 4
Training loss: 0.3133391737937927
Validation loss: 1.7862659744037095

Epoch: 5| Step: 5
Training loss: 0.5108786225318909
Validation loss: 1.7884949125269407

Epoch: 5| Step: 6
Training loss: 0.4559197425842285
Validation loss: 1.802988326677712

Epoch: 5| Step: 7
Training loss: 0.22319304943084717
Validation loss: 1.803718836076798

Epoch: 5| Step: 8
Training loss: 0.41963377594947815
Validation loss: 1.7944947545246412

Epoch: 5| Step: 9
Training loss: 0.30010294914245605
Validation loss: 1.8190106832852928

Epoch: 5| Step: 10
Training loss: 0.2123490571975708
Validation loss: 1.8246698238516366

Epoch: 340| Step: 0
Training loss: 0.31080856919288635
Validation loss: 1.8392722311840262

Epoch: 5| Step: 1
Training loss: 0.2671055197715759
Validation loss: 1.8470976737237745

Epoch: 5| Step: 2
Training loss: 0.5366649627685547
Validation loss: 1.812677514168524

Epoch: 5| Step: 3
Training loss: 0.4633137583732605
Validation loss: 1.8101426657810007

Epoch: 5| Step: 4
Training loss: 0.3501569628715515
Validation loss: 1.806902338099736

Epoch: 5| Step: 5
Training loss: 0.392078161239624
Validation loss: 1.771829141083584

Epoch: 5| Step: 6
Training loss: 0.4326633810997009
Validation loss: 1.7905676172625633

Epoch: 5| Step: 7
Training loss: 0.2609246075153351
Validation loss: 1.7795007485215382

Epoch: 5| Step: 8
Training loss: 0.30507850646972656
Validation loss: 1.8007628430602372

Epoch: 5| Step: 9
Training loss: 0.22899767756462097
Validation loss: 1.8165332527570828

Epoch: 5| Step: 10
Training loss: 0.37963932752609253
Validation loss: 1.77634108707469

Epoch: 341| Step: 0
Training loss: 0.49154385924339294
Validation loss: 1.765933734114452

Epoch: 5| Step: 1
Training loss: 0.2451045960187912
Validation loss: 1.7507277368217387

Epoch: 5| Step: 2
Training loss: 0.2469007521867752
Validation loss: 1.7678844851832236

Epoch: 5| Step: 3
Training loss: 0.31141138076782227
Validation loss: 1.7356411487825456

Epoch: 5| Step: 4
Training loss: 0.24933770298957825
Validation loss: 1.7558715394748154

Epoch: 5| Step: 5
Training loss: 0.32040607929229736
Validation loss: 1.729251327053193

Epoch: 5| Step: 6
Training loss: 0.47384142875671387
Validation loss: 1.7695704070470666

Epoch: 5| Step: 7
Training loss: 0.30019113421440125
Validation loss: 1.7848701912869689

Epoch: 5| Step: 8
Training loss: 0.27598780393600464
Validation loss: 1.7917186675533172

Epoch: 5| Step: 9
Training loss: 0.40236592292785645
Validation loss: 1.7437559404680807

Epoch: 5| Step: 10
Training loss: 0.49362120032310486
Validation loss: 1.7311364040579846

Epoch: 342| Step: 0
Training loss: 0.3616328835487366
Validation loss: 1.7389789890217524

Epoch: 5| Step: 1
Training loss: 0.31528276205062866
Validation loss: 1.7607469943261915

Epoch: 5| Step: 2
Training loss: 0.3679637908935547
Validation loss: 1.7274321625309605

Epoch: 5| Step: 3
Training loss: 0.3556952178478241
Validation loss: 1.757843404687861

Epoch: 5| Step: 4
Training loss: 0.19072438776493073
Validation loss: 1.8050845976798766

Epoch: 5| Step: 5
Training loss: 0.5649451613426208
Validation loss: 1.7891180912653606

Epoch: 5| Step: 6
Training loss: 0.4111155569553375
Validation loss: 1.778474909003063

Epoch: 5| Step: 7
Training loss: 0.2918141782283783
Validation loss: 1.8022192357688822

Epoch: 5| Step: 8
Training loss: 0.34981536865234375
Validation loss: 1.8383171045652

Epoch: 5| Step: 9
Training loss: 0.28060728311538696
Validation loss: 1.8153336150671846

Epoch: 5| Step: 10
Training loss: 0.5261548757553101
Validation loss: 1.8109709408975416

Epoch: 343| Step: 0
Training loss: 0.20520775020122528
Validation loss: 1.7759699821472168

Epoch: 5| Step: 1
Training loss: 0.4770474433898926
Validation loss: 1.779577188594367

Epoch: 5| Step: 2
Training loss: 0.2808910012245178
Validation loss: 1.7742851254760579

Epoch: 5| Step: 3
Training loss: 0.232082799077034
Validation loss: 1.7687742479385868

Epoch: 5| Step: 4
Training loss: 0.2117493450641632
Validation loss: 1.7756501064505628

Epoch: 5| Step: 5
Training loss: 0.25923359394073486
Validation loss: 1.7728144020162604

Epoch: 5| Step: 6
Training loss: 0.2131659984588623
Validation loss: 1.7891700165246123

Epoch: 5| Step: 7
Training loss: 0.425968736410141
Validation loss: 1.8221339923079296

Epoch: 5| Step: 8
Training loss: 0.1774413287639618
Validation loss: 1.808899784600863

Epoch: 5| Step: 9
Training loss: 0.39560914039611816
Validation loss: 1.8178676546260875

Epoch: 5| Step: 10
Training loss: 0.5854632258415222
Validation loss: 1.8007670551218011

Epoch: 344| Step: 0
Training loss: 0.3793744146823883
Validation loss: 1.78435593523005

Epoch: 5| Step: 1
Training loss: 0.6056669354438782
Validation loss: 1.7683333748130388

Epoch: 5| Step: 2
Training loss: 0.2531138062477112
Validation loss: 1.7705075074267644

Epoch: 5| Step: 3
Training loss: 0.23079660534858704
Validation loss: 1.7524565906934841

Epoch: 5| Step: 4
Training loss: 0.27632835507392883
Validation loss: 1.7423170023067023

Epoch: 5| Step: 5
Training loss: 0.19823887944221497
Validation loss: 1.7504718060134559

Epoch: 5| Step: 6
Training loss: 0.37951144576072693
Validation loss: 1.7842761239697855

Epoch: 5| Step: 7
Training loss: 0.3301730155944824
Validation loss: 1.7576519314960768

Epoch: 5| Step: 8
Training loss: 0.2941516041755676
Validation loss: 1.745348439421705

Epoch: 5| Step: 9
Training loss: 0.14891691505908966
Validation loss: 1.7717068772162161

Epoch: 5| Step: 10
Training loss: 0.28348761796951294
Validation loss: 1.8036451672994962

Epoch: 345| Step: 0
Training loss: 0.16322922706604004
Validation loss: 1.7688761423992854

Epoch: 5| Step: 1
Training loss: 0.3143526017665863
Validation loss: 1.814235956438126

Epoch: 5| Step: 2
Training loss: 0.20518922805786133
Validation loss: 1.8033776103809316

Epoch: 5| Step: 3
Training loss: 0.2826407849788666
Validation loss: 1.7814169673509495

Epoch: 5| Step: 4
Training loss: 0.2414272278547287
Validation loss: 1.7929000649400937

Epoch: 5| Step: 5
Training loss: 0.5612869262695312
Validation loss: 1.7677992531048354

Epoch: 5| Step: 6
Training loss: 0.29463568329811096
Validation loss: 1.7992306217070548

Epoch: 5| Step: 7
Training loss: 0.4960258901119232
Validation loss: 1.7733871077978483

Epoch: 5| Step: 8
Training loss: 0.14361870288848877
Validation loss: 1.7959553535266588

Epoch: 5| Step: 9
Training loss: 0.4289851188659668
Validation loss: 1.7659572350081576

Epoch: 5| Step: 10
Training loss: 0.21377307176589966
Validation loss: 1.7837125101397115

Epoch: 346| Step: 0
Training loss: 0.25861331820487976
Validation loss: 1.7783745770813317

Epoch: 5| Step: 1
Training loss: 0.7143135070800781
Validation loss: 1.7436399472657071

Epoch: 5| Step: 2
Training loss: 0.18564137816429138
Validation loss: 1.75639303909835

Epoch: 5| Step: 3
Training loss: 0.13933315873146057
Validation loss: 1.7311974007596251

Epoch: 5| Step: 4
Training loss: 0.1892421394586563
Validation loss: 1.7473135686689807

Epoch: 5| Step: 5
Training loss: 0.19227193295955658
Validation loss: 1.7409540555810417

Epoch: 5| Step: 6
Training loss: 0.15123029053211212
Validation loss: 1.7369120531184699

Epoch: 5| Step: 7
Training loss: 0.5762859582901001
Validation loss: 1.736607801529669

Epoch: 5| Step: 8
Training loss: 0.28294020891189575
Validation loss: 1.7080771871792373

Epoch: 5| Step: 9
Training loss: 0.2719058692455292
Validation loss: 1.7453081864182667

Epoch: 5| Step: 10
Training loss: 0.3630763292312622
Validation loss: 1.767579286329208

Epoch: 347| Step: 0
Training loss: 0.18607155978679657
Validation loss: 1.7826149175243993

Epoch: 5| Step: 1
Training loss: 0.5819944739341736
Validation loss: 1.8091143062037807

Epoch: 5| Step: 2
Training loss: 0.2694849669933319
Validation loss: 1.8412181792720672

Epoch: 5| Step: 3
Training loss: 0.550600528717041
Validation loss: 1.858457464043812

Epoch: 5| Step: 4
Training loss: 0.24965424835681915
Validation loss: 1.881674958813575

Epoch: 5| Step: 5
Training loss: 0.23605069518089294
Validation loss: 1.8557512837071573

Epoch: 5| Step: 6
Training loss: 0.38281017541885376
Validation loss: 1.821610830163443

Epoch: 5| Step: 7
Training loss: 0.34498825669288635
Validation loss: 1.7872412807197982

Epoch: 5| Step: 8
Training loss: 0.28297561407089233
Validation loss: 1.7809318047697826

Epoch: 5| Step: 9
Training loss: 0.32043367624282837
Validation loss: 1.7524287982653546

Epoch: 5| Step: 10
Training loss: 0.2559220790863037
Validation loss: 1.7256850222105622

Epoch: 348| Step: 0
Training loss: 0.27933937311172485
Validation loss: 1.7407379919482815

Epoch: 5| Step: 1
Training loss: 0.3794885277748108
Validation loss: 1.7105546177074473

Epoch: 5| Step: 2
Training loss: 0.23217327892780304
Validation loss: 1.7267946979050994

Epoch: 5| Step: 3
Training loss: 0.3282250165939331
Validation loss: 1.7343724440502863

Epoch: 5| Step: 4
Training loss: 0.24635811150074005
Validation loss: 1.7820162747495918

Epoch: 5| Step: 5
Training loss: 0.5463474988937378
Validation loss: 1.7865990464405348

Epoch: 5| Step: 6
Training loss: 0.5581890344619751
Validation loss: 1.8318379117596535

Epoch: 5| Step: 7
Training loss: 0.2475699931383133
Validation loss: 1.8169169272145917

Epoch: 5| Step: 8
Training loss: 0.24967598915100098
Validation loss: 1.8193148438648512

Epoch: 5| Step: 9
Training loss: 0.1918478012084961
Validation loss: 1.7905515624630837

Epoch: 5| Step: 10
Training loss: 0.18698306381702423
Validation loss: 1.7702252531564364

Epoch: 349| Step: 0
Training loss: 0.21866583824157715
Validation loss: 1.7686196168263753

Epoch: 5| Step: 1
Training loss: 0.2576989233493805
Validation loss: 1.762487171798624

Epoch: 5| Step: 2
Training loss: 0.3502587080001831
Validation loss: 1.7574825299683439

Epoch: 5| Step: 3
Training loss: 0.16853347420692444
Validation loss: 1.719905371307045

Epoch: 5| Step: 4
Training loss: 0.3531252443790436
Validation loss: 1.752511643594311

Epoch: 5| Step: 5
Training loss: 0.5152215957641602
Validation loss: 1.7779937623649515

Epoch: 5| Step: 6
Training loss: 0.58270263671875
Validation loss: 1.7885755133885208

Epoch: 5| Step: 7
Training loss: 0.3051982820034027
Validation loss: 1.833715167096866

Epoch: 5| Step: 8
Training loss: 0.35299456119537354
Validation loss: 1.8184415986461024

Epoch: 5| Step: 9
Training loss: 0.41181468963623047
Validation loss: 1.8257087430646342

Epoch: 5| Step: 10
Training loss: 0.23458155989646912
Validation loss: 1.7808597959497923

Epoch: 350| Step: 0
Training loss: 0.341208815574646
Validation loss: 1.763857344145416

Epoch: 5| Step: 1
Training loss: 0.2721969485282898
Validation loss: 1.7584568095463577

Epoch: 5| Step: 2
Training loss: 0.21714477241039276
Validation loss: 1.756819837836809

Epoch: 5| Step: 3
Training loss: 0.2662270665168762
Validation loss: 1.7503686976689163

Epoch: 5| Step: 4
Training loss: 0.40673312544822693
Validation loss: 1.7409779128207956

Epoch: 5| Step: 5
Training loss: 0.2853069305419922
Validation loss: 1.7623964291746899

Epoch: 5| Step: 6
Training loss: 0.30638962984085083
Validation loss: 1.7421789989676526

Epoch: 5| Step: 7
Training loss: 0.3506602644920349
Validation loss: 1.7441963931565643

Epoch: 5| Step: 8
Training loss: 0.6811987161636353
Validation loss: 1.7232025233648156

Epoch: 5| Step: 9
Training loss: 0.14607204496860504
Validation loss: 1.7271651734587967

Epoch: 5| Step: 10
Training loss: 0.16834579408168793
Validation loss: 1.7074331160514586

Epoch: 351| Step: 0
Training loss: 0.17422012984752655
Validation loss: 1.7146577373627694

Epoch: 5| Step: 1
Training loss: 0.19531705975532532
Validation loss: 1.72409696989162

Epoch: 5| Step: 2
Training loss: 0.2914656102657318
Validation loss: 1.732444195337193

Epoch: 5| Step: 3
Training loss: 0.1674993485212326
Validation loss: 1.7738722062879992

Epoch: 5| Step: 4
Training loss: 0.19835595786571503
Validation loss: 1.7773684609320857

Epoch: 5| Step: 5
Training loss: 0.23341365158557892
Validation loss: 1.7954154834952405

Epoch: 5| Step: 6
Training loss: 0.36089709401130676
Validation loss: 1.7835618295977194

Epoch: 5| Step: 7
Training loss: 0.32757654786109924
Validation loss: 1.771463550547118

Epoch: 5| Step: 8
Training loss: 0.6639413237571716
Validation loss: 1.7704075126237766

Epoch: 5| Step: 9
Training loss: 0.258914053440094
Validation loss: 1.7637325140737719

Epoch: 5| Step: 10
Training loss: 0.4794729948043823
Validation loss: 1.7486660160044187

Epoch: 352| Step: 0
Training loss: 0.15851613879203796
Validation loss: 1.756693797726785

Epoch: 5| Step: 1
Training loss: 0.3603769838809967
Validation loss: 1.7479759275272329

Epoch: 5| Step: 2
Training loss: 0.23431949317455292
Validation loss: 1.7723665339972383

Epoch: 5| Step: 3
Training loss: 0.22330479323863983
Validation loss: 1.7513933335581133

Epoch: 5| Step: 4
Training loss: 0.19679400324821472
Validation loss: 1.769901038498007

Epoch: 5| Step: 5
Training loss: 0.3426854610443115
Validation loss: 1.7751974610872165

Epoch: 5| Step: 6
Training loss: 0.18847426772117615
Validation loss: 1.7339359291138188

Epoch: 5| Step: 7
Training loss: 0.4692688584327698
Validation loss: 1.744007448996267

Epoch: 5| Step: 8
Training loss: 0.44473639130592346
Validation loss: 1.7402269583876415

Epoch: 5| Step: 9
Training loss: 0.27709975838661194
Validation loss: 1.7564891230675481

Epoch: 5| Step: 10
Training loss: 0.22613757848739624
Validation loss: 1.7617347548084874

Epoch: 353| Step: 0
Training loss: 0.15530551970005035
Validation loss: 1.7718634874589982

Epoch: 5| Step: 1
Training loss: 0.20065584778785706
Validation loss: 1.7752579207061439

Epoch: 5| Step: 2
Training loss: 0.26708129048347473
Validation loss: 1.7664958328329108

Epoch: 5| Step: 3
Training loss: 0.35861098766326904
Validation loss: 1.7940743559150285

Epoch: 5| Step: 4
Training loss: 0.20688876509666443
Validation loss: 1.7374238647440428

Epoch: 5| Step: 5
Training loss: 0.24873337149620056
Validation loss: 1.7664393071205384

Epoch: 5| Step: 6
Training loss: 0.5838326215744019
Validation loss: 1.7167116211306663

Epoch: 5| Step: 7
Training loss: 0.4352642595767975
Validation loss: 1.7015102986366517

Epoch: 5| Step: 8
Training loss: 0.2317592352628708
Validation loss: 1.7156806120308496

Epoch: 5| Step: 9
Training loss: 0.31683650612831116
Validation loss: 1.67868177096049

Epoch: 5| Step: 10
Training loss: 0.4031374156475067
Validation loss: 1.6736855968352287

Epoch: 354| Step: 0
Training loss: 0.2652837932109833
Validation loss: 1.6833896342144217

Epoch: 5| Step: 1
Training loss: 0.6266135573387146
Validation loss: 1.6895353076278523

Epoch: 5| Step: 2
Training loss: 0.24226848781108856
Validation loss: 1.6842170761477562

Epoch: 5| Step: 3
Training loss: 0.21236450970172882
Validation loss: 1.7028085518908758

Epoch: 5| Step: 4
Training loss: 0.18689079582691193
Validation loss: 1.7105239155471965

Epoch: 5| Step: 5
Training loss: 0.24684634804725647
Validation loss: 1.6920812001792334

Epoch: 5| Step: 6
Training loss: 0.18447771668434143
Validation loss: 1.7154889978388304

Epoch: 5| Step: 7
Training loss: 0.4837437570095062
Validation loss: 1.7251265792436496

Epoch: 5| Step: 8
Training loss: 0.20871801674365997
Validation loss: 1.7065899923283567

Epoch: 5| Step: 9
Training loss: 0.11958923190832138
Validation loss: 1.7263244928852204

Epoch: 5| Step: 10
Training loss: 0.2699166536331177
Validation loss: 1.7159666175483375

Epoch: 355| Step: 0
Training loss: 0.39465802907943726
Validation loss: 1.712973456228933

Epoch: 5| Step: 1
Training loss: 0.3207232356071472
Validation loss: 1.6973408281162221

Epoch: 5| Step: 2
Training loss: 0.12429428100585938
Validation loss: 1.7233296552652955

Epoch: 5| Step: 3
Training loss: 0.1942691057920456
Validation loss: 1.7290616394371114

Epoch: 5| Step: 4
Training loss: 0.19059936702251434
Validation loss: 1.7527219415992819

Epoch: 5| Step: 5
Training loss: 0.3077579438686371
Validation loss: 1.7542863533061037

Epoch: 5| Step: 6
Training loss: 0.17959892749786377
Validation loss: 1.754265674980738

Epoch: 5| Step: 7
Training loss: 0.5401500463485718
Validation loss: 1.744820325605331

Epoch: 5| Step: 8
Training loss: 0.17877648770809174
Validation loss: 1.7584867118507304

Epoch: 5| Step: 9
Training loss: 0.23427578806877136
Validation loss: 1.7480643577473138

Epoch: 5| Step: 10
Training loss: 0.48723670840263367
Validation loss: 1.7532256726295716

Epoch: 356| Step: 0
Training loss: 0.18532775342464447
Validation loss: 1.7552452369402813

Epoch: 5| Step: 1
Training loss: 0.23383502662181854
Validation loss: 1.750993396646233

Epoch: 5| Step: 2
Training loss: 0.19137728214263916
Validation loss: 1.7379818706102268

Epoch: 5| Step: 3
Training loss: 0.18763980269432068
Validation loss: 1.7484483206143944

Epoch: 5| Step: 4
Training loss: 0.20718884468078613
Validation loss: 1.7445185492115636

Epoch: 5| Step: 5
Training loss: 0.41512197256088257
Validation loss: 1.7179529551536805

Epoch: 5| Step: 6
Training loss: 0.17505833506584167
Validation loss: 1.7175763166078957

Epoch: 5| Step: 7
Training loss: 0.3476901352405548
Validation loss: 1.7259826467883201

Epoch: 5| Step: 8
Training loss: 0.5047107934951782
Validation loss: 1.73393831458143

Epoch: 5| Step: 9
Training loss: 0.36640939116477966
Validation loss: 1.7512266482076337

Epoch: 5| Step: 10
Training loss: 0.36716559529304504
Validation loss: 1.760117269331409

Epoch: 357| Step: 0
Training loss: 0.20069925487041473
Validation loss: 1.7908275999048704

Epoch: 5| Step: 1
Training loss: 0.4480861723423004
Validation loss: 1.8013991348205074

Epoch: 5| Step: 2
Training loss: 0.25181323289871216
Validation loss: 1.7989429991732362

Epoch: 5| Step: 3
Training loss: 0.21461685001850128
Validation loss: 1.7653553050051454

Epoch: 5| Step: 4
Training loss: 0.31197598576545715
Validation loss: 1.7686476912549747

Epoch: 5| Step: 5
Training loss: 0.4662882685661316
Validation loss: 1.7450084570915467

Epoch: 5| Step: 6
Training loss: 0.17586588859558105
Validation loss: 1.753908690585885

Epoch: 5| Step: 7
Training loss: 0.2656313478946686
Validation loss: 1.7446102737098612

Epoch: 5| Step: 8
Training loss: 0.27582281827926636
Validation loss: 1.7359209573397072

Epoch: 5| Step: 9
Training loss: 0.19564209878444672
Validation loss: 1.7511580208296418

Epoch: 5| Step: 10
Training loss: 0.386653333902359
Validation loss: 1.7812490283801992

Epoch: 358| Step: 0
Training loss: 0.5282713174819946
Validation loss: 1.801697229826322

Epoch: 5| Step: 1
Training loss: 0.359072744846344
Validation loss: 1.8181860049565632

Epoch: 5| Step: 2
Training loss: 0.2523967921733856
Validation loss: 1.7918476007317985

Epoch: 5| Step: 3
Training loss: 0.15679509937763214
Validation loss: 1.7484084008842387

Epoch: 5| Step: 4
Training loss: 0.22515758872032166
Validation loss: 1.7360410690307617

Epoch: 5| Step: 5
Training loss: 0.16162988543510437
Validation loss: 1.7311099511320873

Epoch: 5| Step: 6
Training loss: 0.2064281404018402
Validation loss: 1.7020473070042108

Epoch: 5| Step: 7
Training loss: 0.2557050883769989
Validation loss: 1.7063381107904578

Epoch: 5| Step: 8
Training loss: 0.4746758043766022
Validation loss: 1.6975599386358773

Epoch: 5| Step: 9
Training loss: 0.21363289654254913
Validation loss: 1.708872143940259

Epoch: 5| Step: 10
Training loss: 0.34493204951286316
Validation loss: 1.6935539194332656

Epoch: 359| Step: 0
Training loss: 0.1686488538980484
Validation loss: 1.7458353542512464

Epoch: 5| Step: 1
Training loss: 0.5523878931999207
Validation loss: 1.7996192286091466

Epoch: 5| Step: 2
Training loss: 0.3031880855560303
Validation loss: 1.7814048092852357

Epoch: 5| Step: 3
Training loss: 0.4843255579471588
Validation loss: 1.7734666832031742

Epoch: 5| Step: 4
Training loss: 0.2534037232398987
Validation loss: 1.706830975829914

Epoch: 5| Step: 5
Training loss: 0.21737535297870636
Validation loss: 1.69491103131284

Epoch: 5| Step: 6
Training loss: 0.24918611347675323
Validation loss: 1.711596978607998

Epoch: 5| Step: 7
Training loss: 0.16324247419834137
Validation loss: 1.7174866404584659

Epoch: 5| Step: 8
Training loss: 0.46502286195755005
Validation loss: 1.6963680585225422

Epoch: 5| Step: 9
Training loss: 0.39596402645111084
Validation loss: 1.7120030208300518

Epoch: 5| Step: 10
Training loss: 0.1334620863199234
Validation loss: 1.7034822119179593

Epoch: 360| Step: 0
Training loss: 0.18907685577869415
Validation loss: 1.7069088823051863

Epoch: 5| Step: 1
Training loss: 0.1761177033185959
Validation loss: 1.7276123980040192

Epoch: 5| Step: 2
Training loss: 0.44031277298927307
Validation loss: 1.7313464572352748

Epoch: 5| Step: 3
Training loss: 0.15944094955921173
Validation loss: 1.7395519312991892

Epoch: 5| Step: 4
Training loss: 0.2902963161468506
Validation loss: 1.7547324165221183

Epoch: 5| Step: 5
Training loss: 0.27375203371047974
Validation loss: 1.7837030182602585

Epoch: 5| Step: 6
Training loss: 0.45532283186912537
Validation loss: 1.7723661879057526

Epoch: 5| Step: 7
Training loss: 0.2727809548377991
Validation loss: 1.7416322282565537

Epoch: 5| Step: 8
Training loss: 0.38511237502098083
Validation loss: 1.7695406700975151

Epoch: 5| Step: 9
Training loss: 0.16783607006072998
Validation loss: 1.7581091632125199

Epoch: 5| Step: 10
Training loss: 0.2183178961277008
Validation loss: 1.7643717450480307

Epoch: 361| Step: 0
Training loss: 0.21310213208198547
Validation loss: 1.7426170995158534

Epoch: 5| Step: 1
Training loss: 0.34359803795814514
Validation loss: 1.7430567267120525

Epoch: 5| Step: 2
Training loss: 0.47125664353370667
Validation loss: 1.7626096830573132

Epoch: 5| Step: 3
Training loss: 0.21865396201610565
Validation loss: 1.7982061524544992

Epoch: 5| Step: 4
Training loss: 0.21776695549488068
Validation loss: 1.7866089254297235

Epoch: 5| Step: 5
Training loss: 0.19994819164276123
Validation loss: 1.7939262492682344

Epoch: 5| Step: 6
Training loss: 0.24277731776237488
Validation loss: 1.7599144558752737

Epoch: 5| Step: 7
Training loss: 0.4181900918483734
Validation loss: 1.7310039856100594

Epoch: 5| Step: 8
Training loss: 0.14820726215839386
Validation loss: 1.7351023689393075

Epoch: 5| Step: 9
Training loss: 0.3726751208305359
Validation loss: 1.730482373186337

Epoch: 5| Step: 10
Training loss: 0.19405528903007507
Validation loss: 1.717350734177456

Epoch: 362| Step: 0
Training loss: 0.17835357785224915
Validation loss: 1.7002317008151804

Epoch: 5| Step: 1
Training loss: 0.4515591561794281
Validation loss: 1.708586239045666

Epoch: 5| Step: 2
Training loss: 0.17122061550617218
Validation loss: 1.7177015337892758

Epoch: 5| Step: 3
Training loss: 0.4151703417301178
Validation loss: 1.7024249005061325

Epoch: 5| Step: 4
Training loss: 0.1101580262184143
Validation loss: 1.7195403178532918

Epoch: 5| Step: 5
Training loss: 0.2673192620277405
Validation loss: 1.7554408824571999

Epoch: 5| Step: 6
Training loss: 0.33669915795326233
Validation loss: 1.8030586165766562

Epoch: 5| Step: 7
Training loss: 0.25092166662216187
Validation loss: 1.790022583417995

Epoch: 5| Step: 8
Training loss: 0.4498099684715271
Validation loss: 1.7518884315285632

Epoch: 5| Step: 9
Training loss: 0.13254854083061218
Validation loss: 1.7298466031269362

Epoch: 5| Step: 10
Training loss: 0.20595969259738922
Validation loss: 1.7037736574808757

Epoch: 363| Step: 0
Training loss: 0.4111846089363098
Validation loss: 1.7020392879363029

Epoch: 5| Step: 1
Training loss: 0.20552906394004822
Validation loss: 1.6888899777525215

Epoch: 5| Step: 2
Training loss: 0.33239755034446716
Validation loss: 1.7071722681804369

Epoch: 5| Step: 3
Training loss: 0.20425093173980713
Validation loss: 1.7316520547354093

Epoch: 5| Step: 4
Training loss: 0.30589690804481506
Validation loss: 1.7097331195749261

Epoch: 5| Step: 5
Training loss: 0.14421144127845764
Validation loss: 1.7633721995097336

Epoch: 5| Step: 6
Training loss: 0.48096150159835815
Validation loss: 1.795169436803428

Epoch: 5| Step: 7
Training loss: 0.5370211005210876
Validation loss: 1.8099950308440833

Epoch: 5| Step: 8
Training loss: 0.19648385047912598
Validation loss: 1.7707866814828688

Epoch: 5| Step: 9
Training loss: 0.1967819631099701
Validation loss: 1.7626184455810054

Epoch: 5| Step: 10
Training loss: 0.2708360552787781
Validation loss: 1.7514717514796923

Epoch: 364| Step: 0
Training loss: 0.2884320020675659
Validation loss: 1.7208229649451472

Epoch: 5| Step: 1
Training loss: 0.2779529392719269
Validation loss: 1.7200313806533813

Epoch: 5| Step: 2
Training loss: 0.3720547556877136
Validation loss: 1.6940324485942881

Epoch: 5| Step: 3
Training loss: 0.15017277002334595
Validation loss: 1.7026976218787573

Epoch: 5| Step: 4
Training loss: 0.21296341717243195
Validation loss: 1.68874228513369

Epoch: 5| Step: 5
Training loss: 0.223908931016922
Validation loss: 1.723321714708882

Epoch: 5| Step: 6
Training loss: 0.25813743472099304
Validation loss: 1.739943414606074

Epoch: 5| Step: 7
Training loss: 0.38062065839767456
Validation loss: 1.7424523445867723

Epoch: 5| Step: 8
Training loss: 0.21986563503742218
Validation loss: 1.7134557539416897

Epoch: 5| Step: 9
Training loss: 0.47055721282958984
Validation loss: 1.708405827963224

Epoch: 5| Step: 10
Training loss: 0.1799125075340271
Validation loss: 1.688093602016408

Epoch: 365| Step: 0
Training loss: 0.13769391179084778
Validation loss: 1.6932331618442331

Epoch: 5| Step: 1
Training loss: 0.4561518728733063
Validation loss: 1.6749025429448774

Epoch: 5| Step: 2
Training loss: 0.28748807311058044
Validation loss: 1.7004933690512052

Epoch: 5| Step: 3
Training loss: 0.20381736755371094
Validation loss: 1.6927532944627988

Epoch: 5| Step: 4
Training loss: 0.20658311247825623
Validation loss: 1.6788930328943397

Epoch: 5| Step: 5
Training loss: 0.29127955436706543
Validation loss: 1.667926303801998

Epoch: 5| Step: 6
Training loss: 0.167973592877388
Validation loss: 1.716719321025315

Epoch: 5| Step: 7
Training loss: 0.1882668435573578
Validation loss: 1.694711450607546

Epoch: 5| Step: 8
Training loss: 0.33951449394226074
Validation loss: 1.717723367034748

Epoch: 5| Step: 9
Training loss: 0.19354966282844543
Validation loss: 1.7271449001886512

Epoch: 5| Step: 10
Training loss: 0.31769415736198425
Validation loss: 1.7151960660052556

Epoch: 366| Step: 0
Training loss: 0.12908592820167542
Validation loss: 1.71236978935939

Epoch: 5| Step: 1
Training loss: 0.1802622377872467
Validation loss: 1.7148867948080904

Epoch: 5| Step: 2
Training loss: 0.08916381001472473
Validation loss: 1.7301148676103162

Epoch: 5| Step: 3
Training loss: 0.2965070605278015
Validation loss: 1.714182185870345

Epoch: 5| Step: 4
Training loss: 0.4553091526031494
Validation loss: 1.7089664807883642

Epoch: 5| Step: 5
Training loss: 0.23737986385822296
Validation loss: 1.7260683582675072

Epoch: 5| Step: 6
Training loss: 0.28745776414871216
Validation loss: 1.7114684812484249

Epoch: 5| Step: 7
Training loss: 0.21382799744606018
Validation loss: 1.7298190209173387

Epoch: 5| Step: 8
Training loss: 0.14260171353816986
Validation loss: 1.7500128374304822

Epoch: 5| Step: 9
Training loss: 0.3606107532978058
Validation loss: 1.7254853658778693

Epoch: 5| Step: 10
Training loss: 0.2603394091129303
Validation loss: 1.7024690463978758

Epoch: 367| Step: 0
Training loss: 0.24943003058433533
Validation loss: 1.706845937236663

Epoch: 5| Step: 1
Training loss: 0.21198830008506775
Validation loss: 1.7079987423394316

Epoch: 5| Step: 2
Training loss: 0.3828211724758148
Validation loss: 1.700420195056546

Epoch: 5| Step: 3
Training loss: 0.25377780199050903
Validation loss: 1.721051694244467

Epoch: 5| Step: 4
Training loss: 0.18911364674568176
Validation loss: 1.6926222103898243

Epoch: 5| Step: 5
Training loss: 0.28216788172721863
Validation loss: 1.6997462921245123

Epoch: 5| Step: 6
Training loss: 0.1641712188720703
Validation loss: 1.7362002582960232

Epoch: 5| Step: 7
Training loss: 0.18120329082012177
Validation loss: 1.7219191097444104

Epoch: 5| Step: 8
Training loss: 0.4068024158477783
Validation loss: 1.7293155513783938

Epoch: 5| Step: 9
Training loss: 0.2936314642429352
Validation loss: 1.6994482522369714

Epoch: 5| Step: 10
Training loss: 0.2904811501502991
Validation loss: 1.6837261082023702

Epoch: 368| Step: 0
Training loss: 0.17087309062480927
Validation loss: 1.698125535441983

Epoch: 5| Step: 1
Training loss: 0.4127129912376404
Validation loss: 1.7033770956018919

Epoch: 5| Step: 2
Training loss: 0.2601185441017151
Validation loss: 1.7172458428208546

Epoch: 5| Step: 3
Training loss: 0.297916978597641
Validation loss: 1.7383043484021259

Epoch: 5| Step: 4
Training loss: 0.1945127546787262
Validation loss: 1.7256881947158484

Epoch: 5| Step: 5
Training loss: 0.20118507742881775
Validation loss: 1.7173397592318955

Epoch: 5| Step: 6
Training loss: 0.16789387166500092
Validation loss: 1.6931584035196612

Epoch: 5| Step: 7
Training loss: 0.32042789459228516
Validation loss: 1.680482050423981

Epoch: 5| Step: 8
Training loss: 0.2291068583726883
Validation loss: 1.7033905136969782

Epoch: 5| Step: 9
Training loss: 0.2744472920894623
Validation loss: 1.6749712638957526

Epoch: 5| Step: 10
Training loss: 0.3495199680328369
Validation loss: 1.6654339983899107

Epoch: 369| Step: 0
Training loss: 0.24652650952339172
Validation loss: 1.6635114069907897

Epoch: 5| Step: 1
Training loss: 0.1986846923828125
Validation loss: 1.6656921781519407

Epoch: 5| Step: 2
Training loss: 0.2300075739622116
Validation loss: 1.6793166399002075

Epoch: 5| Step: 3
Training loss: 0.1801169365644455
Validation loss: 1.713101076823409

Epoch: 5| Step: 4
Training loss: 0.4031997323036194
Validation loss: 1.7114559911912488

Epoch: 5| Step: 5
Training loss: 0.5116738080978394
Validation loss: 1.7207627257993143

Epoch: 5| Step: 6
Training loss: 0.23968365788459778
Validation loss: 1.6969528018787343

Epoch: 5| Step: 7
Training loss: 0.27916547656059265
Validation loss: 1.6802666879469348

Epoch: 5| Step: 8
Training loss: 0.272041380405426
Validation loss: 1.6956355091064208

Epoch: 5| Step: 9
Training loss: 0.14785727858543396
Validation loss: 1.6989647009039437

Epoch: 5| Step: 10
Training loss: 0.23287366330623627
Validation loss: 1.7048180513484503

Epoch: 370| Step: 0
Training loss: 0.34468287229537964
Validation loss: 1.7311721770994124

Epoch: 5| Step: 1
Training loss: 0.2156050205230713
Validation loss: 1.742752557159752

Epoch: 5| Step: 2
Training loss: 0.2058488428592682
Validation loss: 1.7577333629772227

Epoch: 5| Step: 3
Training loss: 0.26788029074668884
Validation loss: 1.736031606633176

Epoch: 5| Step: 4
Training loss: 0.5715876817703247
Validation loss: 1.75851704612855

Epoch: 5| Step: 5
Training loss: 0.2961236238479614
Validation loss: 1.710123336443337

Epoch: 5| Step: 6
Training loss: 0.22735214233398438
Validation loss: 1.6993980170578085

Epoch: 5| Step: 7
Training loss: 0.2310204803943634
Validation loss: 1.6594861758652555

Epoch: 5| Step: 8
Training loss: 0.23257355391979218
Validation loss: 1.6718722761318248

Epoch: 5| Step: 9
Training loss: 0.22788505256175995
Validation loss: 1.6634242034727527

Epoch: 5| Step: 10
Training loss: 0.2456313520669937
Validation loss: 1.6627977343015774

Epoch: 371| Step: 0
Training loss: 0.2739346921443939
Validation loss: 1.657352238573054

Epoch: 5| Step: 1
Training loss: 0.5307881236076355
Validation loss: 1.6902402639389038

Epoch: 5| Step: 2
Training loss: 0.23027999699115753
Validation loss: 1.7061543477478849

Epoch: 5| Step: 3
Training loss: 0.4366324841976166
Validation loss: 1.7003979721376974

Epoch: 5| Step: 4
Training loss: 0.20677952468395233
Validation loss: 1.7131477684103034

Epoch: 5| Step: 5
Training loss: 0.23404169082641602
Validation loss: 1.7092417542652418

Epoch: 5| Step: 6
Training loss: 0.21722133457660675
Validation loss: 1.6743828019788187

Epoch: 5| Step: 7
Training loss: 0.1453779637813568
Validation loss: 1.6908276337449268

Epoch: 5| Step: 8
Training loss: 0.211043119430542
Validation loss: 1.7104851763735536

Epoch: 5| Step: 9
Training loss: 0.16663536429405212
Validation loss: 1.7114674737376552

Epoch: 5| Step: 10
Training loss: 0.16441234946250916
Validation loss: 1.704588492070475

Epoch: 372| Step: 0
Training loss: 0.25256508588790894
Validation loss: 1.695378461191731

Epoch: 5| Step: 1
Training loss: 0.16186782717704773
Validation loss: 1.7146614366962063

Epoch: 5| Step: 2
Training loss: 0.400149405002594
Validation loss: 1.7094513447053972

Epoch: 5| Step: 3
Training loss: 0.27748650312423706
Validation loss: 1.7011828640455842

Epoch: 5| Step: 4
Training loss: 0.25013574957847595
Validation loss: 1.7166020370298816

Epoch: 5| Step: 5
Training loss: 0.09360350668430328
Validation loss: 1.6972616744297806

Epoch: 5| Step: 6
Training loss: 0.37158268690109253
Validation loss: 1.7034672139793314

Epoch: 5| Step: 7
Training loss: 0.26000550389289856
Validation loss: 1.6957818705548522

Epoch: 5| Step: 8
Training loss: 0.35141879320144653
Validation loss: 1.7211153353414228

Epoch: 5| Step: 9
Training loss: 0.1686895787715912
Validation loss: 1.7102358930854387

Epoch: 5| Step: 10
Training loss: 0.24694913625717163
Validation loss: 1.7060246929045646

Epoch: 373| Step: 0
Training loss: 0.35540691018104553
Validation loss: 1.71970401271697

Epoch: 5| Step: 1
Training loss: 0.15157005190849304
Validation loss: 1.7285884580304545

Epoch: 5| Step: 2
Training loss: 0.13320805132389069
Validation loss: 1.7091881575122956

Epoch: 5| Step: 3
Training loss: 0.43720024824142456
Validation loss: 1.729127169937216

Epoch: 5| Step: 4
Training loss: 0.14369086921215057
Validation loss: 1.7133961672423987

Epoch: 5| Step: 5
Training loss: 0.22605343163013458
Validation loss: 1.6934081123721214

Epoch: 5| Step: 6
Training loss: 0.21846938133239746
Validation loss: 1.7258253828171761

Epoch: 5| Step: 7
Training loss: 0.2582627534866333
Validation loss: 1.758631933119989

Epoch: 5| Step: 8
Training loss: 0.426199346780777
Validation loss: 1.751025935654999

Epoch: 5| Step: 9
Training loss: 0.2571629285812378
Validation loss: 1.7568041624561432

Epoch: 5| Step: 10
Training loss: 0.097867950797081
Validation loss: 1.7315205425344489

Epoch: 374| Step: 0
Training loss: 0.20931486785411835
Validation loss: 1.7412083264320128

Epoch: 5| Step: 1
Training loss: 0.1372889131307602
Validation loss: 1.6963662973014257

Epoch: 5| Step: 2
Training loss: 0.6615350246429443
Validation loss: 1.7328771404040757

Epoch: 5| Step: 3
Training loss: 0.24155505001544952
Validation loss: 1.7143870040934572

Epoch: 5| Step: 4
Training loss: 0.21697959303855896
Validation loss: 1.6719107166413338

Epoch: 5| Step: 5
Training loss: 0.12998881936073303
Validation loss: 1.7123294209921232

Epoch: 5| Step: 6
Training loss: 0.22752109169960022
Validation loss: 1.7121282239114084

Epoch: 5| Step: 7
Training loss: 0.3182426989078522
Validation loss: 1.7018662780843756

Epoch: 5| Step: 8
Training loss: 0.4192049503326416
Validation loss: 1.7156598670508272

Epoch: 5| Step: 9
Training loss: 0.248627707362175
Validation loss: 1.7279144820346628

Epoch: 5| Step: 10
Training loss: 0.47345128655433655
Validation loss: 1.7260199310959026

Epoch: 375| Step: 0
Training loss: 0.24395985901355743
Validation loss: 1.7254659193818287

Epoch: 5| Step: 1
Training loss: 0.21846434473991394
Validation loss: 1.7332127196814424

Epoch: 5| Step: 2
Training loss: 0.37463364005088806
Validation loss: 1.7594324683630338

Epoch: 5| Step: 3
Training loss: 0.3057378828525543
Validation loss: 1.7203713899017663

Epoch: 5| Step: 4
Training loss: 0.2164727747440338
Validation loss: 1.7522896592335035

Epoch: 5| Step: 5
Training loss: 0.2582516074180603
Validation loss: 1.735543870156811

Epoch: 5| Step: 6
Training loss: 0.28713518381118774
Validation loss: 1.7265236108533797

Epoch: 5| Step: 7
Training loss: 0.1707085818052292
Validation loss: 1.7311635530123146

Epoch: 5| Step: 8
Training loss: 0.3356311321258545
Validation loss: 1.7242952290401663

Epoch: 5| Step: 9
Training loss: 0.282304584980011
Validation loss: 1.7192946646803169

Epoch: 5| Step: 10
Training loss: 0.5295004844665527
Validation loss: 1.705478859204118

Epoch: 376| Step: 0
Training loss: 0.2850450873374939
Validation loss: 1.6837123734976656

Epoch: 5| Step: 1
Training loss: 0.15231823921203613
Validation loss: 1.6733805056541198

Epoch: 5| Step: 2
Training loss: 0.6441483497619629
Validation loss: 1.6553766086537351

Epoch: 5| Step: 3
Training loss: 0.28336596488952637
Validation loss: 1.6686172190532889

Epoch: 5| Step: 4
Training loss: 0.24824409186840057
Validation loss: 1.6821024481968214

Epoch: 5| Step: 5
Training loss: 0.1780260056257248
Validation loss: 1.69048894733511

Epoch: 5| Step: 6
Training loss: 0.5058990120887756
Validation loss: 1.7170822492209814

Epoch: 5| Step: 7
Training loss: 0.1465146690607071
Validation loss: 1.7143343622966478

Epoch: 5| Step: 8
Training loss: 0.3361656665802002
Validation loss: 1.706360996410411

Epoch: 5| Step: 9
Training loss: 0.1594037413597107
Validation loss: 1.7416850046444965

Epoch: 5| Step: 10
Training loss: 0.10041085630655289
Validation loss: 1.7361861646816295

Epoch: 377| Step: 0
Training loss: 0.5046005845069885
Validation loss: 1.741161366944672

Epoch: 5| Step: 1
Training loss: 0.1874742954969406
Validation loss: 1.7205684236300889

Epoch: 5| Step: 2
Training loss: 0.23103007674217224
Validation loss: 1.7387824250805763

Epoch: 5| Step: 3
Training loss: 0.18590182065963745
Validation loss: 1.7209350601319344

Epoch: 5| Step: 4
Training loss: 0.13420771062374115
Validation loss: 1.7655398076580417

Epoch: 5| Step: 5
Training loss: 0.292876660823822
Validation loss: 1.779747429714408

Epoch: 5| Step: 6
Training loss: 0.29708346724510193
Validation loss: 1.7201960176549933

Epoch: 5| Step: 7
Training loss: 0.19591180980205536
Validation loss: 1.7437300118066932

Epoch: 5| Step: 8
Training loss: 0.21492162346839905
Validation loss: 1.7230392797018892

Epoch: 5| Step: 9
Training loss: 0.2508077621459961
Validation loss: 1.710696997821972

Epoch: 5| Step: 10
Training loss: 0.3780583441257477
Validation loss: 1.7256525331927883

Epoch: 378| Step: 0
Training loss: 0.2957225441932678
Validation loss: 1.7094408010923734

Epoch: 5| Step: 1
Training loss: 0.16975697875022888
Validation loss: 1.677008839063747

Epoch: 5| Step: 2
Training loss: 0.21276096999645233
Validation loss: 1.6962339390990555

Epoch: 5| Step: 3
Training loss: 0.41122549772262573
Validation loss: 1.6595588300817756

Epoch: 5| Step: 4
Training loss: 0.23972997069358826
Validation loss: 1.6841258951412734

Epoch: 5| Step: 5
Training loss: 0.259438157081604
Validation loss: 1.6885172961860575

Epoch: 5| Step: 6
Training loss: 0.3229197859764099
Validation loss: 1.71934647457574

Epoch: 5| Step: 7
Training loss: 0.42587003111839294
Validation loss: 1.7190483308607531

Epoch: 5| Step: 8
Training loss: 0.15123692154884338
Validation loss: 1.7490034564848869

Epoch: 5| Step: 9
Training loss: 0.18617454171180725
Validation loss: 1.758436861858573

Epoch: 5| Step: 10
Training loss: 0.3058261275291443
Validation loss: 1.7595264860378799

Epoch: 379| Step: 0
Training loss: 0.1720496565103531
Validation loss: 1.7124509734492148

Epoch: 5| Step: 1
Training loss: 0.14374588429927826
Validation loss: 1.7052935464407808

Epoch: 5| Step: 2
Training loss: 0.19114065170288086
Validation loss: 1.7222957726447814

Epoch: 5| Step: 3
Training loss: 0.3796655535697937
Validation loss: 1.712946339320111

Epoch: 5| Step: 4
Training loss: 0.1851276308298111
Validation loss: 1.6868658911797307

Epoch: 5| Step: 5
Training loss: 0.349877268075943
Validation loss: 1.6677329783798547

Epoch: 5| Step: 6
Training loss: 0.26109743118286133
Validation loss: 1.6483659808353712

Epoch: 5| Step: 7
Training loss: 0.26931506395339966
Validation loss: 1.68102466675543

Epoch: 5| Step: 8
Training loss: 0.2629612386226654
Validation loss: 1.694211603492819

Epoch: 5| Step: 9
Training loss: 0.19318056106567383
Validation loss: 1.6519835533634308

Epoch: 5| Step: 10
Training loss: 0.33216026425361633
Validation loss: 1.6943037292008758

Epoch: 380| Step: 0
Training loss: 0.33868950605392456
Validation loss: 1.7050360832163083

Epoch: 5| Step: 1
Training loss: 0.4191650450229645
Validation loss: 1.716444625649401

Epoch: 5| Step: 2
Training loss: 0.20115642249584198
Validation loss: 1.6819324096043904

Epoch: 5| Step: 3
Training loss: 0.22271576523780823
Validation loss: 1.6514200600244666

Epoch: 5| Step: 4
Training loss: 0.3411705791950226
Validation loss: 1.6320807754352529

Epoch: 5| Step: 5
Training loss: 0.41144293546676636
Validation loss: 1.6242068634238294

Epoch: 5| Step: 6
Training loss: 0.18805339932441711
Validation loss: 1.6207672306286391

Epoch: 5| Step: 7
Training loss: 0.1790049523115158
Validation loss: 1.6417173044655913

Epoch: 5| Step: 8
Training loss: 0.14765729010105133
Validation loss: 1.625780850328425

Epoch: 5| Step: 9
Training loss: 0.2564180791378021
Validation loss: 1.6581680095323952

Epoch: 5| Step: 10
Training loss: 0.21393221616744995
Validation loss: 1.6628696482668641

Epoch: 381| Step: 0
Training loss: 0.1271754652261734
Validation loss: 1.719852905119619

Epoch: 5| Step: 1
Training loss: 0.22202439606189728
Validation loss: 1.7351554286095403

Epoch: 5| Step: 2
Training loss: 0.43338099122047424
Validation loss: 1.7711346533990675

Epoch: 5| Step: 3
Training loss: 0.21015504002571106
Validation loss: 1.7559168261866416

Epoch: 5| Step: 4
Training loss: 0.31676968932151794
Validation loss: 1.7398339971419303

Epoch: 5| Step: 5
Training loss: 0.13182449340820312
Validation loss: 1.7168774194614862

Epoch: 5| Step: 6
Training loss: 0.33672618865966797
Validation loss: 1.67501611222503

Epoch: 5| Step: 7
Training loss: 0.22847433388233185
Validation loss: 1.697006630641158

Epoch: 5| Step: 8
Training loss: 0.193246990442276
Validation loss: 1.680954485811213

Epoch: 5| Step: 9
Training loss: 0.38324347138404846
Validation loss: 1.6820740263949159

Epoch: 5| Step: 10
Training loss: 0.25535592436790466
Validation loss: 1.6724075271237282

Epoch: 382| Step: 0
Training loss: 0.2148045301437378
Validation loss: 1.669240374718943

Epoch: 5| Step: 1
Training loss: 0.21951894462108612
Validation loss: 1.738298801965611

Epoch: 5| Step: 2
Training loss: 0.1477993279695511
Validation loss: 1.7635809208757134

Epoch: 5| Step: 3
Training loss: 0.22841887176036835
Validation loss: 1.769973639518984

Epoch: 5| Step: 4
Training loss: 0.26049864292144775
Validation loss: 1.749496154887702

Epoch: 5| Step: 5
Training loss: 0.36785465478897095
Validation loss: 1.7249943543505926

Epoch: 5| Step: 6
Training loss: 0.26944270730018616
Validation loss: 1.7078244455399052

Epoch: 5| Step: 7
Training loss: 0.157147616147995
Validation loss: 1.696722968932121

Epoch: 5| Step: 8
Training loss: 0.11325319111347198
Validation loss: 1.705688940581455

Epoch: 5| Step: 9
Training loss: 0.22667288780212402
Validation loss: 1.7503152214070803

Epoch: 5| Step: 10
Training loss: 0.43361908197402954
Validation loss: 1.746391075913624

Epoch: 383| Step: 0
Training loss: 0.3722904324531555
Validation loss: 1.7775998576994865

Epoch: 5| Step: 1
Training loss: 0.13500133156776428
Validation loss: 1.7465176454154394

Epoch: 5| Step: 2
Training loss: 0.19407080113887787
Validation loss: 1.7150939946533532

Epoch: 5| Step: 3
Training loss: 0.27509284019470215
Validation loss: 1.736389592129697

Epoch: 5| Step: 4
Training loss: 0.23180000483989716
Validation loss: 1.7304758307754353

Epoch: 5| Step: 5
Training loss: 0.18445736169815063
Validation loss: 1.7087437491263113

Epoch: 5| Step: 6
Training loss: 0.5779373049736023
Validation loss: 1.6896917896886026

Epoch: 5| Step: 7
Training loss: 0.22827477753162384
Validation loss: 1.6696418434061029

Epoch: 5| Step: 8
Training loss: 0.2350357472896576
Validation loss: 1.6678125730124853

Epoch: 5| Step: 9
Training loss: 0.21713459491729736
Validation loss: 1.687293339801091

Epoch: 5| Step: 10
Training loss: 0.17613881826400757
Validation loss: 1.7073071925870833

Epoch: 384| Step: 0
Training loss: 0.2748657166957855
Validation loss: 1.7056058658066617

Epoch: 5| Step: 1
Training loss: 0.14355522394180298
Validation loss: 1.7021051222278225

Epoch: 5| Step: 2
Training loss: 0.139358252286911
Validation loss: 1.668882554577243

Epoch: 5| Step: 3
Training loss: 0.13967224955558777
Validation loss: 1.714656242760279

Epoch: 5| Step: 4
Training loss: 0.3828718662261963
Validation loss: 1.7040713666587748

Epoch: 5| Step: 5
Training loss: 0.5902938842773438
Validation loss: 1.7196205931325113

Epoch: 5| Step: 6
Training loss: 0.14563271403312683
Validation loss: 1.6806344665506834

Epoch: 5| Step: 7
Training loss: 0.2604168951511383
Validation loss: 1.6953059434890747

Epoch: 5| Step: 8
Training loss: 0.26473793387413025
Validation loss: 1.7083235671443324

Epoch: 5| Step: 9
Training loss: 0.1457396298646927
Validation loss: 1.6756487995065668

Epoch: 5| Step: 10
Training loss: 0.1895938217639923
Validation loss: 1.6581195387788998

Epoch: 385| Step: 0
Training loss: 0.1900251805782318
Validation loss: 1.7000754059001963

Epoch: 5| Step: 1
Training loss: 0.2022072970867157
Validation loss: 1.707178124817469

Epoch: 5| Step: 2
Training loss: 0.3491979241371155
Validation loss: 1.7243510856423327

Epoch: 5| Step: 3
Training loss: 0.4975112974643707
Validation loss: 1.7337745902358845

Epoch: 5| Step: 4
Training loss: 0.15588834881782532
Validation loss: 1.7119355009448143

Epoch: 5| Step: 5
Training loss: 0.10421035438776016
Validation loss: 1.693618833377797

Epoch: 5| Step: 6
Training loss: 0.20768511295318604
Validation loss: 1.705780711225284

Epoch: 5| Step: 7
Training loss: 0.11456265300512314
Validation loss: 1.6992267203587357

Epoch: 5| Step: 8
Training loss: 0.18691644072532654
Validation loss: 1.7309595077268538

Epoch: 5| Step: 9
Training loss: 0.128584086894989
Validation loss: 1.7430560114563152

Epoch: 5| Step: 10
Training loss: 0.4428926110267639
Validation loss: 1.7348914415605607

Epoch: 386| Step: 0
Training loss: 0.17326898872852325
Validation loss: 1.7598936391133133

Epoch: 5| Step: 1
Training loss: 0.37516874074935913
Validation loss: 1.7134668686056649

Epoch: 5| Step: 2
Training loss: 0.16617080569267273
Validation loss: 1.7338973629859187

Epoch: 5| Step: 3
Training loss: 0.2889479100704193
Validation loss: 1.6936787366867065

Epoch: 5| Step: 4
Training loss: 0.23754778504371643
Validation loss: 1.6870139311718684

Epoch: 5| Step: 5
Training loss: 0.1626112163066864
Validation loss: 1.6542511954102466

Epoch: 5| Step: 6
Training loss: 0.15124668180942535
Validation loss: 1.6649293822626914

Epoch: 5| Step: 7
Training loss: 0.3108086585998535
Validation loss: 1.6866192510051112

Epoch: 5| Step: 8
Training loss: 0.2120898962020874
Validation loss: 1.678961834599895

Epoch: 5| Step: 9
Training loss: 0.29080453515052795
Validation loss: 1.7118514327592746

Epoch: 5| Step: 10
Training loss: 0.3841325044631958
Validation loss: 1.7324099694528887

Epoch: 387| Step: 0
Training loss: 0.18791328370571136
Validation loss: 1.7052740576446697

Epoch: 5| Step: 1
Training loss: 0.2136448323726654
Validation loss: 1.7109449999306792

Epoch: 5| Step: 2
Training loss: 0.21752920746803284
Validation loss: 1.7008777703008344

Epoch: 5| Step: 3
Training loss: 0.20148804783821106
Validation loss: 1.697751106754426

Epoch: 5| Step: 4
Training loss: 0.1309862732887268
Validation loss: 1.6908873409353278

Epoch: 5| Step: 5
Training loss: 0.18223488330841064
Validation loss: 1.699206349670246

Epoch: 5| Step: 6
Training loss: 0.21378859877586365
Validation loss: 1.6719008761067544

Epoch: 5| Step: 7
Training loss: 0.39594364166259766
Validation loss: 1.6854919220811577

Epoch: 5| Step: 8
Training loss: 0.24097661674022675
Validation loss: 1.7390948367375199

Epoch: 5| Step: 9
Training loss: 0.5983063578605652
Validation loss: 1.760797732619829

Epoch: 5| Step: 10
Training loss: 0.15244416892528534
Validation loss: 1.795713291373304

Epoch: 388| Step: 0
Training loss: 0.4372240900993347
Validation loss: 1.7999357843911776

Epoch: 5| Step: 1
Training loss: 0.19128528237342834
Validation loss: 1.7471578159639913

Epoch: 5| Step: 2
Training loss: 0.3335852026939392
Validation loss: 1.7250388694065872

Epoch: 5| Step: 3
Training loss: 0.19278894364833832
Validation loss: 1.6773271522214335

Epoch: 5| Step: 4
Training loss: 0.24082669615745544
Validation loss: 1.6727639180357738

Epoch: 5| Step: 5
Training loss: 0.17446359992027283
Validation loss: 1.6512944159969207

Epoch: 5| Step: 6
Training loss: 0.17821790277957916
Validation loss: 1.6945265646903747

Epoch: 5| Step: 7
Training loss: 0.22066807746887207
Validation loss: 1.6909801113990046

Epoch: 5| Step: 8
Training loss: 0.15938636660575867
Validation loss: 1.7057207040889288

Epoch: 5| Step: 9
Training loss: 0.24684138596057892
Validation loss: 1.7317357191475489

Epoch: 5| Step: 10
Training loss: 0.30004972219467163
Validation loss: 1.7314477415495022

Epoch: 389| Step: 0
Training loss: 0.3717643618583679
Validation loss: 1.7312451998392742

Epoch: 5| Step: 1
Training loss: 0.1447833627462387
Validation loss: 1.7261502614585302

Epoch: 5| Step: 2
Training loss: 0.25631093978881836
Validation loss: 1.7134354806715442

Epoch: 5| Step: 3
Training loss: 0.36553168296813965
Validation loss: 1.727333063720375

Epoch: 5| Step: 4
Training loss: 0.4131688177585602
Validation loss: 1.7135056372611754

Epoch: 5| Step: 5
Training loss: 0.19878175854682922
Validation loss: 1.694382118922408

Epoch: 5| Step: 6
Training loss: 0.18097177147865295
Validation loss: 1.6667141170911892

Epoch: 5| Step: 7
Training loss: 0.1708631068468094
Validation loss: 1.6729406695212088

Epoch: 5| Step: 8
Training loss: 0.16640014946460724
Validation loss: 1.6918970013177523

Epoch: 5| Step: 9
Training loss: 0.27553826570510864
Validation loss: 1.6960659180918047

Epoch: 5| Step: 10
Training loss: 0.19755955040454865
Validation loss: 1.7116327529312463

Epoch: 390| Step: 0
Training loss: 0.16516657173633575
Validation loss: 1.741732496087269

Epoch: 5| Step: 1
Training loss: 0.43005651235580444
Validation loss: 1.7770785631672028

Epoch: 5| Step: 2
Training loss: 0.2137819230556488
Validation loss: 1.7527453373837214

Epoch: 5| Step: 3
Training loss: 0.23193831741809845
Validation loss: 1.7677117791227115

Epoch: 5| Step: 4
Training loss: 0.3058398365974426
Validation loss: 1.7180486750859085

Epoch: 5| Step: 5
Training loss: 0.20400157570838928
Validation loss: 1.733211910852822

Epoch: 5| Step: 6
Training loss: 0.18597203493118286
Validation loss: 1.7108226617177327

Epoch: 5| Step: 7
Training loss: 0.4706884026527405
Validation loss: 1.7312086923148042

Epoch: 5| Step: 8
Training loss: 0.2255714237689972
Validation loss: 1.7175183706386115

Epoch: 5| Step: 9
Training loss: 0.18601123988628387
Validation loss: 1.7070244384068314

Epoch: 5| Step: 10
Training loss: 0.10745108872652054
Validation loss: 1.690850051500464

Epoch: 391| Step: 0
Training loss: 0.13590629398822784
Validation loss: 1.6736323628374326

Epoch: 5| Step: 1
Training loss: 0.3680921196937561
Validation loss: 1.7058103231973545

Epoch: 5| Step: 2
Training loss: 0.261221706867218
Validation loss: 1.6745525816435456

Epoch: 5| Step: 3
Training loss: 0.3004516363143921
Validation loss: 1.7147000297423332

Epoch: 5| Step: 4
Training loss: 0.1744435727596283
Validation loss: 1.7321667850658458

Epoch: 5| Step: 5
Training loss: 0.27727875113487244
Validation loss: 1.744535655103704

Epoch: 5| Step: 6
Training loss: 0.22638551890850067
Validation loss: 1.7716268416373961

Epoch: 5| Step: 7
Training loss: 0.24574434757232666
Validation loss: 1.771928100175755

Epoch: 5| Step: 8
Training loss: 0.15697206556797028
Validation loss: 1.7434517901430848

Epoch: 5| Step: 9
Training loss: 0.22658288478851318
Validation loss: 1.735776444917084

Epoch: 5| Step: 10
Training loss: 0.279491662979126
Validation loss: 1.7173975385645384

Epoch: 392| Step: 0
Training loss: 0.3327394425868988
Validation loss: 1.7145903161776963

Epoch: 5| Step: 1
Training loss: 0.1722269356250763
Validation loss: 1.696659008661906

Epoch: 5| Step: 2
Training loss: 0.3031652867794037
Validation loss: 1.7243041761459843

Epoch: 5| Step: 3
Training loss: 0.21623595058918
Validation loss: 1.718186802761529

Epoch: 5| Step: 4
Training loss: 0.3274485170841217
Validation loss: 1.7028472013370965

Epoch: 5| Step: 5
Training loss: 0.26601746678352356
Validation loss: 1.720528684636598

Epoch: 5| Step: 6
Training loss: 0.1496352255344391
Validation loss: 1.6914864047881095

Epoch: 5| Step: 7
Training loss: 0.23900218307971954
Validation loss: 1.6750467964397964

Epoch: 5| Step: 8
Training loss: 0.13943345844745636
Validation loss: 1.6644034283135527

Epoch: 5| Step: 9
Training loss: 0.26523739099502563
Validation loss: 1.6430167972400624

Epoch: 5| Step: 10
Training loss: 0.20351135730743408
Validation loss: 1.6430689775815575

Epoch: 393| Step: 0
Training loss: 0.17266058921813965
Validation loss: 1.6748167827565184

Epoch: 5| Step: 1
Training loss: 0.25156861543655396
Validation loss: 1.6972545449451735

Epoch: 5| Step: 2
Training loss: 0.19053886830806732
Validation loss: 1.6917482665790025

Epoch: 5| Step: 3
Training loss: 0.17585095763206482
Validation loss: 1.7127317741353025

Epoch: 5| Step: 4
Training loss: 0.36229202151298523
Validation loss: 1.7205955674571376

Epoch: 5| Step: 5
Training loss: 0.1399611532688141
Validation loss: 1.702393897118107

Epoch: 5| Step: 6
Training loss: 0.34930482506752014
Validation loss: 1.7328609061497513

Epoch: 5| Step: 7
Training loss: 0.3386138081550598
Validation loss: 1.692718731459751

Epoch: 5| Step: 8
Training loss: 0.2798083424568176
Validation loss: 1.6792281648164153

Epoch: 5| Step: 9
Training loss: 0.14671838283538818
Validation loss: 1.6733267794373214

Epoch: 5| Step: 10
Training loss: 0.24469737708568573
Validation loss: 1.6729274847174203

Epoch: 394| Step: 0
Training loss: 0.192905992269516
Validation loss: 1.6751083481696345

Epoch: 5| Step: 1
Training loss: 0.21014471352100372
Validation loss: 1.685350307854273

Epoch: 5| Step: 2
Training loss: 0.2374645471572876
Validation loss: 1.6715998188141854

Epoch: 5| Step: 3
Training loss: 0.14054732024669647
Validation loss: 1.6572806360901042

Epoch: 5| Step: 4
Training loss: 0.2831307351589203
Validation loss: 1.644212713805578

Epoch: 5| Step: 5
Training loss: 0.3375703692436218
Validation loss: 1.6499051381182928

Epoch: 5| Step: 6
Training loss: 0.2670696973800659
Validation loss: 1.659977073310524

Epoch: 5| Step: 7
Training loss: 0.13054469227790833
Validation loss: 1.665924076111086

Epoch: 5| Step: 8
Training loss: 0.30346041917800903
Validation loss: 1.6660320502455517

Epoch: 5| Step: 9
Training loss: 0.1071033924818039
Validation loss: 1.6784143922149495

Epoch: 5| Step: 10
Training loss: 0.1507340520620346
Validation loss: 1.6837962250555716

Epoch: 395| Step: 0
Training loss: 0.3081226348876953
Validation loss: 1.681735638649233

Epoch: 5| Step: 1
Training loss: 0.17368921637535095
Validation loss: 1.695937410477669

Epoch: 5| Step: 2
Training loss: 0.1718578338623047
Validation loss: 1.6954920407264464

Epoch: 5| Step: 3
Training loss: 0.09950866550207138
Validation loss: 1.6798552620795466

Epoch: 5| Step: 4
Training loss: 0.12636151909828186
Validation loss: 1.6804484346861481

Epoch: 5| Step: 5
Training loss: 0.29936957359313965
Validation loss: 1.6729039838237147

Epoch: 5| Step: 6
Training loss: 0.12479124218225479
Validation loss: 1.699176589647929

Epoch: 5| Step: 7
Training loss: 0.1837487518787384
Validation loss: 1.680422700861449

Epoch: 5| Step: 8
Training loss: 0.1456340104341507
Validation loss: 1.6955285508145568

Epoch: 5| Step: 9
Training loss: 0.3806694447994232
Validation loss: 1.6774190754018805

Epoch: 5| Step: 10
Training loss: 0.2200036346912384
Validation loss: 1.6952722072601318

Epoch: 396| Step: 0
Training loss: 0.19909581542015076
Validation loss: 1.6994073711415774

Epoch: 5| Step: 1
Training loss: 0.12629586458206177
Validation loss: 1.7226623130101029

Epoch: 5| Step: 2
Training loss: 0.24843263626098633
Validation loss: 1.7047149891494422

Epoch: 5| Step: 3
Training loss: 0.35062018036842346
Validation loss: 1.7027173772934945

Epoch: 5| Step: 4
Training loss: 0.1452798694372177
Validation loss: 1.696668981223978

Epoch: 5| Step: 5
Training loss: 0.13771206140518188
Validation loss: 1.688021549614527

Epoch: 5| Step: 6
Training loss: 0.1801699846982956
Validation loss: 1.6790414035961192

Epoch: 5| Step: 7
Training loss: 0.14915518462657928
Validation loss: 1.676300855093105

Epoch: 5| Step: 8
Training loss: 0.1201210618019104
Validation loss: 1.6392029126485188

Epoch: 5| Step: 9
Training loss: 0.45190495252609253
Validation loss: 1.6503750060194282

Epoch: 5| Step: 10
Training loss: 0.11726225167512894
Validation loss: 1.671883136995377

Epoch: 397| Step: 0
Training loss: 0.16908985376358032
Validation loss: 1.6553270893712198

Epoch: 5| Step: 1
Training loss: 0.15815028548240662
Validation loss: 1.629065889184193

Epoch: 5| Step: 2
Training loss: 0.15372583270072937
Validation loss: 1.6306072460707797

Epoch: 5| Step: 3
Training loss: 0.18824759125709534
Validation loss: 1.6213478170415407

Epoch: 5| Step: 4
Training loss: 0.11580995470285416
Validation loss: 1.6389723490643244

Epoch: 5| Step: 5
Training loss: 0.15818457305431366
Validation loss: 1.6572217556738085

Epoch: 5| Step: 6
Training loss: 0.1895167976617813
Validation loss: 1.6349404742640834

Epoch: 5| Step: 7
Training loss: 0.12352706491947174
Validation loss: 1.6498876925437682

Epoch: 5| Step: 8
Training loss: 0.43139785528182983
Validation loss: 1.6642188769514843

Epoch: 5| Step: 9
Training loss: 0.3050147593021393
Validation loss: 1.6910153371031567

Epoch: 5| Step: 10
Training loss: 0.1744321882724762
Validation loss: 1.6786582816031672

Epoch: 398| Step: 0
Training loss: 0.21546757221221924
Validation loss: 1.7185225115027478

Epoch: 5| Step: 1
Training loss: 0.23788568377494812
Validation loss: 1.7062777229534682

Epoch: 5| Step: 2
Training loss: 0.2023880034685135
Validation loss: 1.6957131790858444

Epoch: 5| Step: 3
Training loss: 0.13292506337165833
Validation loss: 1.7167869126924904

Epoch: 5| Step: 4
Training loss: 0.21116606891155243
Validation loss: 1.6910022932996032

Epoch: 5| Step: 5
Training loss: 0.1868457794189453
Validation loss: 1.6778846453594904

Epoch: 5| Step: 6
Training loss: 0.1586953103542328
Validation loss: 1.6958631456539195

Epoch: 5| Step: 7
Training loss: 0.2511051893234253
Validation loss: 1.658797085926097

Epoch: 5| Step: 8
Training loss: 0.17200292646884918
Validation loss: 1.659486013074075

Epoch: 5| Step: 9
Training loss: 0.15502305328845978
Validation loss: 1.6452467031376337

Epoch: 5| Step: 10
Training loss: 0.5205705165863037
Validation loss: 1.660898740573596

Epoch: 399| Step: 0
Training loss: 0.2497442662715912
Validation loss: 1.6641172004002396

Epoch: 5| Step: 1
Training loss: 0.15493100881576538
Validation loss: 1.736494189949446

Epoch: 5| Step: 2
Training loss: 0.45592936873435974
Validation loss: 1.7343301221888552

Epoch: 5| Step: 3
Training loss: 0.1972176879644394
Validation loss: 1.7374830374153711

Epoch: 5| Step: 4
Training loss: 0.1664688140153885
Validation loss: 1.681427336508228

Epoch: 5| Step: 5
Training loss: 0.13097843527793884
Validation loss: 1.6634187800909883

Epoch: 5| Step: 6
Training loss: 0.15079233050346375
Validation loss: 1.635415095154957

Epoch: 5| Step: 7
Training loss: 0.21282920241355896
Validation loss: 1.636090906717444

Epoch: 5| Step: 8
Training loss: 0.3082508146762848
Validation loss: 1.6452799035656838

Epoch: 5| Step: 9
Training loss: 0.1906709372997284
Validation loss: 1.6661259333292644

Epoch: 5| Step: 10
Training loss: 0.07313698530197144
Validation loss: 1.6565866547246133

Epoch: 400| Step: 0
Training loss: 0.2657480835914612
Validation loss: 1.6610079683283323

Epoch: 5| Step: 1
Training loss: 0.18497925996780396
Validation loss: 1.6795234577630156

Epoch: 5| Step: 2
Training loss: 0.16027173399925232
Validation loss: 1.696784503998295

Epoch: 5| Step: 3
Training loss: 0.12779249250888824
Validation loss: 1.7189837745440903

Epoch: 5| Step: 4
Training loss: 0.18519170582294464
Validation loss: 1.7082584083721202

Epoch: 5| Step: 5
Training loss: 0.2058570832014084
Validation loss: 1.7170105352196643

Epoch: 5| Step: 6
Training loss: 0.2076496183872223
Validation loss: 1.7088347583688714

Epoch: 5| Step: 7
Training loss: 0.13785162568092346
Validation loss: 1.6833648309912732

Epoch: 5| Step: 8
Training loss: 0.35998883843421936
Validation loss: 1.65540894128943

Epoch: 5| Step: 9
Training loss: 0.355168879032135
Validation loss: 1.628024790235745

Epoch: 5| Step: 10
Training loss: 0.1770099401473999
Validation loss: 1.6241816013090071

Epoch: 401| Step: 0
Training loss: 0.1716374009847641
Validation loss: 1.6094003685059086

Epoch: 5| Step: 1
Training loss: 0.25992998480796814
Validation loss: 1.619324784125051

Epoch: 5| Step: 2
Training loss: 0.22206246852874756
Validation loss: 1.6115929067775767

Epoch: 5| Step: 3
Training loss: 0.1653127372264862
Validation loss: 1.653557623586347

Epoch: 5| Step: 4
Training loss: 0.15221232175827026
Validation loss: 1.6200601285503757

Epoch: 5| Step: 5
Training loss: 0.13665826618671417
Validation loss: 1.6573295208715624

Epoch: 5| Step: 6
Training loss: 0.2288626730442047
Validation loss: 1.6740436207863592

Epoch: 5| Step: 7
Training loss: 0.12520913779735565
Validation loss: 1.6531954580737698

Epoch: 5| Step: 8
Training loss: 0.33132404088974
Validation loss: 1.6871374499413274

Epoch: 5| Step: 9
Training loss: 0.18118351697921753
Validation loss: 1.673153571544155

Epoch: 5| Step: 10
Training loss: 0.2176370918750763
Validation loss: 1.66439268665929

Epoch: 402| Step: 0
Training loss: 0.21729925274848938
Validation loss: 1.6694412321172736

Epoch: 5| Step: 1
Training loss: 0.380929559469223
Validation loss: 1.640961274023979

Epoch: 5| Step: 2
Training loss: 0.22036126255989075
Validation loss: 1.6181867520014446

Epoch: 5| Step: 3
Training loss: 0.20418354868888855
Validation loss: 1.6337499426257225

Epoch: 5| Step: 4
Training loss: 0.19022758305072784
Validation loss: 1.6184613576499365

Epoch: 5| Step: 5
Training loss: 0.24478492140769958
Validation loss: 1.6298035537042925

Epoch: 5| Step: 6
Training loss: 0.23408189415931702
Validation loss: 1.613354653440496

Epoch: 5| Step: 7
Training loss: 0.20672085881233215
Validation loss: 1.633220899489618

Epoch: 5| Step: 8
Training loss: 0.16339348256587982
Validation loss: 1.6432086524143015

Epoch: 5| Step: 9
Training loss: 0.14452627301216125
Validation loss: 1.6536575491710375

Epoch: 5| Step: 10
Training loss: 0.32410168647766113
Validation loss: 1.703396806152918

Epoch: 403| Step: 0
Training loss: 0.4762297570705414
Validation loss: 1.7369141104400798

Epoch: 5| Step: 1
Training loss: 0.22193773090839386
Validation loss: 1.6870531702554354

Epoch: 5| Step: 2
Training loss: 0.24088755249977112
Validation loss: 1.6752378863673056

Epoch: 5| Step: 3
Training loss: 0.20728453993797302
Validation loss: 1.685051195083126

Epoch: 5| Step: 4
Training loss: 0.10952723026275635
Validation loss: 1.6764583946556173

Epoch: 5| Step: 5
Training loss: 0.1490449160337448
Validation loss: 1.688111525709911

Epoch: 5| Step: 6
Training loss: 0.3970876634120941
Validation loss: 1.6924446923758394

Epoch: 5| Step: 7
Training loss: 0.18731170892715454
Validation loss: 1.6966621952672158

Epoch: 5| Step: 8
Training loss: 0.1767231822013855
Validation loss: 1.676529844601949

Epoch: 5| Step: 9
Training loss: 0.14452126622200012
Validation loss: 1.7170702718919324

Epoch: 5| Step: 10
Training loss: 0.24091482162475586
Validation loss: 1.757085177206224

Epoch: 404| Step: 0
Training loss: 0.2255823165178299
Validation loss: 1.7474239487801828

Epoch: 5| Step: 1
Training loss: 0.22885450720787048
Validation loss: 1.7286169631506807

Epoch: 5| Step: 2
Training loss: 0.23733238875865936
Validation loss: 1.709294790862709

Epoch: 5| Step: 3
Training loss: 0.19887886941432953
Validation loss: 1.6925002387774888

Epoch: 5| Step: 4
Training loss: 0.18834348022937775
Validation loss: 1.683526046814457

Epoch: 5| Step: 5
Training loss: 0.23456628620624542
Validation loss: 1.6772127638580978

Epoch: 5| Step: 6
Training loss: 0.2828100323677063
Validation loss: 1.6842864277542278

Epoch: 5| Step: 7
Training loss: 0.23590430617332458
Validation loss: 1.6641191192852554

Epoch: 5| Step: 8
Training loss: 0.5089491605758667
Validation loss: 1.6377129362475487

Epoch: 5| Step: 9
Training loss: 0.17231714725494385
Validation loss: 1.667186552478421

Epoch: 5| Step: 10
Training loss: 0.16927431523799896
Validation loss: 1.6545531467724872

Epoch: 405| Step: 0
Training loss: 0.15479154884815216
Validation loss: 1.655336513314196

Epoch: 5| Step: 1
Training loss: 0.1842818558216095
Validation loss: 1.6708457213576122

Epoch: 5| Step: 2
Training loss: 0.29468366503715515
Validation loss: 1.654018481572469

Epoch: 5| Step: 3
Training loss: 0.15765520930290222
Validation loss: 1.6867792683262979

Epoch: 5| Step: 4
Training loss: 0.37824946641921997
Validation loss: 1.6426933837193314

Epoch: 5| Step: 5
Training loss: 0.3140583634376526
Validation loss: 1.6632363770597725

Epoch: 5| Step: 6
Training loss: 0.08716194331645966
Validation loss: 1.6598975978871828

Epoch: 5| Step: 7
Training loss: 0.09359560906887054
Validation loss: 1.685352184439218

Epoch: 5| Step: 8
Training loss: 0.1080537810921669
Validation loss: 1.651118109303136

Epoch: 5| Step: 9
Training loss: 0.15805591642856598
Validation loss: 1.6762731703378821

Epoch: 5| Step: 10
Training loss: 0.15974855422973633
Validation loss: 1.6810281891976633

Epoch: 406| Step: 0
Training loss: 0.304191529750824
Validation loss: 1.6730032300436368

Epoch: 5| Step: 1
Training loss: 0.22099241614341736
Validation loss: 1.6671472031583068

Epoch: 5| Step: 2
Training loss: 0.12652476131916046
Validation loss: 1.6614820393182899

Epoch: 5| Step: 3
Training loss: 0.34007081389427185
Validation loss: 1.6440259077215706

Epoch: 5| Step: 4
Training loss: 0.3304564952850342
Validation loss: 1.626848450271032

Epoch: 5| Step: 5
Training loss: 0.13518556952476501
Validation loss: 1.6309912050923994

Epoch: 5| Step: 6
Training loss: 0.2129773646593094
Validation loss: 1.635893496133948

Epoch: 5| Step: 7
Training loss: 0.2125750333070755
Validation loss: 1.6470681928819226

Epoch: 5| Step: 8
Training loss: 0.15537120401859283
Validation loss: 1.6576806268384379

Epoch: 5| Step: 9
Training loss: 0.18100333213806152
Validation loss: 1.6850753573961155

Epoch: 5| Step: 10
Training loss: 0.3143734037876129
Validation loss: 1.6704289759359052

Epoch: 407| Step: 0
Training loss: 0.2683247923851013
Validation loss: 1.6736021772507699

Epoch: 5| Step: 1
Training loss: 0.1756402999162674
Validation loss: 1.6745779001584618

Epoch: 5| Step: 2
Training loss: 0.1912175565958023
Validation loss: 1.6576271851857503

Epoch: 5| Step: 3
Training loss: 0.19318526983261108
Validation loss: 1.6636638282447733

Epoch: 5| Step: 4
Training loss: 0.3164147734642029
Validation loss: 1.692830821519257

Epoch: 5| Step: 5
Training loss: 0.21425791084766388
Validation loss: 1.6766662456656014

Epoch: 5| Step: 6
Training loss: 0.20603743195533752
Validation loss: 1.6578326148371543

Epoch: 5| Step: 7
Training loss: 0.18737348914146423
Validation loss: 1.6405147890890799

Epoch: 5| Step: 8
Training loss: 0.25691261887550354
Validation loss: 1.6304530962820976

Epoch: 5| Step: 9
Training loss: 0.19682207703590393
Validation loss: 1.6645737783883208

Epoch: 5| Step: 10
Training loss: 0.1777646690607071
Validation loss: 1.6560035021074357

Epoch: 408| Step: 0
Training loss: 0.14472803473472595
Validation loss: 1.685552341963655

Epoch: 5| Step: 1
Training loss: 0.18765756487846375
Validation loss: 1.70013008194585

Epoch: 5| Step: 2
Training loss: 0.15040245652198792
Validation loss: 1.7084334588819934

Epoch: 5| Step: 3
Training loss: 0.1896052211523056
Validation loss: 1.7312328610368954

Epoch: 5| Step: 4
Training loss: 0.26505571603775024
Validation loss: 1.7099212972066735

Epoch: 5| Step: 5
Training loss: 0.19320166110992432
Validation loss: 1.7304708034761491

Epoch: 5| Step: 6
Training loss: 0.3065412938594818
Validation loss: 1.711433106853116

Epoch: 5| Step: 7
Training loss: 0.12241774797439575
Validation loss: 1.6770417151912567

Epoch: 5| Step: 8
Training loss: 0.24603338539600372
Validation loss: 1.6864780482425485

Epoch: 5| Step: 9
Training loss: 0.18707290291786194
Validation loss: 1.6607401242820166

Epoch: 5| Step: 10
Training loss: 0.31409233808517456
Validation loss: 1.6569119717485161

Epoch: 409| Step: 0
Training loss: 0.22532328963279724
Validation loss: 1.6767032787364016

Epoch: 5| Step: 1
Training loss: 0.33282196521759033
Validation loss: 1.647119277907956

Epoch: 5| Step: 2
Training loss: 0.15895506739616394
Validation loss: 1.666025129697656

Epoch: 5| Step: 3
Training loss: 0.22614936530590057
Validation loss: 1.664840006059216

Epoch: 5| Step: 4
Training loss: 0.17718151211738586
Validation loss: 1.6746391045149935

Epoch: 5| Step: 5
Training loss: 0.40399542450904846
Validation loss: 1.6704980199055006

Epoch: 5| Step: 6
Training loss: 0.10394182056188583
Validation loss: 1.638029004937859

Epoch: 5| Step: 7
Training loss: 0.18370136618614197
Validation loss: 1.6557125763226581

Epoch: 5| Step: 8
Training loss: 0.12658347189426422
Validation loss: 1.695787372127656

Epoch: 5| Step: 9
Training loss: 0.17048095166683197
Validation loss: 1.6714014622472948

Epoch: 5| Step: 10
Training loss: 0.12162895500659943
Validation loss: 1.653668526680239

Epoch: 410| Step: 0
Training loss: 0.1810021847486496
Validation loss: 1.6462083619127992

Epoch: 5| Step: 1
Training loss: 0.20541520416736603
Validation loss: 1.6544966255464861

Epoch: 5| Step: 2
Training loss: 0.34513965249061584
Validation loss: 1.6418526608456847

Epoch: 5| Step: 3
Training loss: 0.1580580770969391
Validation loss: 1.636884327857725

Epoch: 5| Step: 4
Training loss: 0.341571569442749
Validation loss: 1.6378017317864202

Epoch: 5| Step: 5
Training loss: 0.11573807895183563
Validation loss: 1.6412461560259584

Epoch: 5| Step: 6
Training loss: 0.09540550410747528
Validation loss: 1.6386475101594002

Epoch: 5| Step: 7
Training loss: 0.33112484216690063
Validation loss: 1.6806867558469054

Epoch: 5| Step: 8
Training loss: 0.13717807829380035
Validation loss: 1.6981549173273065

Epoch: 5| Step: 9
Training loss: 0.10662509500980377
Validation loss: 1.6870635824818765

Epoch: 5| Step: 10
Training loss: 0.17354412376880646
Validation loss: 1.7277590094074127

Epoch: 411| Step: 0
Training loss: 0.14189989864826202
Validation loss: 1.7155564036420596

Epoch: 5| Step: 1
Training loss: 0.23708105087280273
Validation loss: 1.7242430179349837

Epoch: 5| Step: 2
Training loss: 0.1822742372751236
Validation loss: 1.7148903185321438

Epoch: 5| Step: 3
Training loss: 0.23224934935569763
Validation loss: 1.675233878115172

Epoch: 5| Step: 4
Training loss: 0.39603590965270996
Validation loss: 1.6475464413242955

Epoch: 5| Step: 5
Training loss: 0.20811745524406433
Validation loss: 1.6619646523588447

Epoch: 5| Step: 6
Training loss: 0.28970450162887573
Validation loss: 1.6388089374829364

Epoch: 5| Step: 7
Training loss: 0.24697311222553253
Validation loss: 1.6271305430320002

Epoch: 5| Step: 8
Training loss: 0.17420771718025208
Validation loss: 1.6536868951653922

Epoch: 5| Step: 9
Training loss: 0.21328774094581604
Validation loss: 1.6403656569860314

Epoch: 5| Step: 10
Training loss: 0.21867965161800385
Validation loss: 1.6285321180538466

Epoch: 412| Step: 0
Training loss: 0.1069551482796669
Validation loss: 1.631853792295661

Epoch: 5| Step: 1
Training loss: 0.14988040924072266
Validation loss: 1.6557670972680534

Epoch: 5| Step: 2
Training loss: 0.1319337785243988
Validation loss: 1.6780970455497823

Epoch: 5| Step: 3
Training loss: 0.13890719413757324
Validation loss: 1.7305824448985438

Epoch: 5| Step: 4
Training loss: 0.2888976037502289
Validation loss: 1.7595833552780973

Epoch: 5| Step: 5
Training loss: 0.4400281310081482
Validation loss: 1.7670370494165728

Epoch: 5| Step: 6
Training loss: 0.5315951108932495
Validation loss: 1.7348826111003917

Epoch: 5| Step: 7
Training loss: 0.1989055871963501
Validation loss: 1.6958128008791196

Epoch: 5| Step: 8
Training loss: 0.11796782910823822
Validation loss: 1.6789797563706674

Epoch: 5| Step: 9
Training loss: 0.21534475684165955
Validation loss: 1.640675998503162

Epoch: 5| Step: 10
Training loss: 0.1640840470790863
Validation loss: 1.631379827376335

Epoch: 413| Step: 0
Training loss: 0.17418085038661957
Validation loss: 1.6471996127918203

Epoch: 5| Step: 1
Training loss: 0.2532772123813629
Validation loss: 1.6537262201309204

Epoch: 5| Step: 2
Training loss: 0.3790176808834076
Validation loss: 1.606903737591159

Epoch: 5| Step: 3
Training loss: 0.3163297772407532
Validation loss: 1.6291875070141209

Epoch: 5| Step: 4
Training loss: 0.20538608729839325
Validation loss: 1.6186735476216962

Epoch: 5| Step: 5
Training loss: 0.20196731388568878
Validation loss: 1.6542354783704203

Epoch: 5| Step: 6
Training loss: 0.13780143857002258
Validation loss: 1.7022815929946078

Epoch: 5| Step: 7
Training loss: 0.17971280217170715
Validation loss: 1.750278619027907

Epoch: 5| Step: 8
Training loss: 0.34231042861938477
Validation loss: 1.7669493805977605

Epoch: 5| Step: 9
Training loss: 0.2726637125015259
Validation loss: 1.7756996231694375

Epoch: 5| Step: 10
Training loss: 0.18639004230499268
Validation loss: 1.7392849435088455

Epoch: 414| Step: 0
Training loss: 0.12354777753353119
Validation loss: 1.7290702878787954

Epoch: 5| Step: 1
Training loss: 0.17644940316677094
Validation loss: 1.6944863578324676

Epoch: 5| Step: 2
Training loss: 0.2731582224369049
Validation loss: 1.6806004137121222

Epoch: 5| Step: 3
Training loss: 0.187234029173851
Validation loss: 1.6904425877396778

Epoch: 5| Step: 4
Training loss: 0.12729941308498383
Validation loss: 1.651695797520299

Epoch: 5| Step: 5
Training loss: 0.14780838787555695
Validation loss: 1.624846496889668

Epoch: 5| Step: 6
Training loss: 0.4008827209472656
Validation loss: 1.6672233394397202

Epoch: 5| Step: 7
Training loss: 0.184990793466568
Validation loss: 1.6812809526279409

Epoch: 5| Step: 8
Training loss: 0.20186682045459747
Validation loss: 1.6597045467745872

Epoch: 5| Step: 9
Training loss: 0.3504331111907959
Validation loss: 1.6820945662836875

Epoch: 5| Step: 10
Training loss: 0.21666565537452698
Validation loss: 1.7107285017608314

Epoch: 415| Step: 0
Training loss: 0.24163766205310822
Validation loss: 1.6688213886753205

Epoch: 5| Step: 1
Training loss: 0.20864081382751465
Validation loss: 1.6371046362384674

Epoch: 5| Step: 2
Training loss: 0.16673289239406586
Validation loss: 1.6507993128991896

Epoch: 5| Step: 3
Training loss: 0.2479138821363449
Validation loss: 1.6387005929023988

Epoch: 5| Step: 4
Training loss: 0.28116142749786377
Validation loss: 1.6482085220275386

Epoch: 5| Step: 5
Training loss: 0.1857309192419052
Validation loss: 1.6682318513111403

Epoch: 5| Step: 6
Training loss: 0.10152404010295868
Validation loss: 1.6936973064176497

Epoch: 5| Step: 7
Training loss: 0.12505783140659332
Validation loss: 1.6876116978224887

Epoch: 5| Step: 8
Training loss: 0.16400101780891418
Validation loss: 1.682860097577495

Epoch: 5| Step: 9
Training loss: 0.15551649034023285
Validation loss: 1.6946770914139286

Epoch: 5| Step: 10
Training loss: 0.2687552571296692
Validation loss: 1.686856423654864

Epoch: 416| Step: 0
Training loss: 0.1731952726840973
Validation loss: 1.6655015791616132

Epoch: 5| Step: 1
Training loss: 0.1309988796710968
Validation loss: 1.6763047300359255

Epoch: 5| Step: 2
Training loss: 0.1732066571712494
Validation loss: 1.686734293096809

Epoch: 5| Step: 3
Training loss: 0.17313627898693085
Validation loss: 1.6804086444198445

Epoch: 5| Step: 4
Training loss: 0.2902466654777527
Validation loss: 1.703191500838085

Epoch: 5| Step: 5
Training loss: 0.15279564261436462
Validation loss: 1.6837096291203653

Epoch: 5| Step: 6
Training loss: 0.21635417640209198
Validation loss: 1.6755985931683612

Epoch: 5| Step: 7
Training loss: 0.11630596220493317
Validation loss: 1.6896451750109274

Epoch: 5| Step: 8
Training loss: 0.33925962448120117
Validation loss: 1.6808840446574713

Epoch: 5| Step: 9
Training loss: 0.2628234028816223
Validation loss: 1.6703527127542803

Epoch: 5| Step: 10
Training loss: 0.15700721740722656
Validation loss: 1.6764892070524153

Epoch: 417| Step: 0
Training loss: 0.11983473598957062
Validation loss: 1.6541409159219393

Epoch: 5| Step: 1
Training loss: 0.3157775402069092
Validation loss: 1.6779194301174534

Epoch: 5| Step: 2
Training loss: 0.23702816665172577
Validation loss: 1.6674360190668414

Epoch: 5| Step: 3
Training loss: 0.13186927139759064
Validation loss: 1.675620279004497

Epoch: 5| Step: 4
Training loss: 0.20326972007751465
Validation loss: 1.6584186259136404

Epoch: 5| Step: 5
Training loss: 0.15206511318683624
Validation loss: 1.6638837347748459

Epoch: 5| Step: 6
Training loss: 0.1811067759990692
Validation loss: 1.6485461547810545

Epoch: 5| Step: 7
Training loss: 0.1290406733751297
Validation loss: 1.6552690664927165

Epoch: 5| Step: 8
Training loss: 0.23333533108234406
Validation loss: 1.644794738420876

Epoch: 5| Step: 9
Training loss: 0.12348415702581406
Validation loss: 1.6696483717169812

Epoch: 5| Step: 10
Training loss: 0.15874214470386505
Validation loss: 1.6764612864422541

Epoch: 418| Step: 0
Training loss: 0.14717921614646912
Validation loss: 1.6778886343843193

Epoch: 5| Step: 1
Training loss: 0.11407699435949326
Validation loss: 1.6768675004282305

Epoch: 5| Step: 2
Training loss: 0.13057945668697357
Validation loss: 1.6258249282836914

Epoch: 5| Step: 3
Training loss: 0.07921843230724335
Validation loss: 1.6547167736996886

Epoch: 5| Step: 4
Training loss: 0.21624048054218292
Validation loss: 1.6309542925127092

Epoch: 5| Step: 5
Training loss: 0.140223428606987
Validation loss: 1.5891776161809121

Epoch: 5| Step: 6
Training loss: 0.15673932433128357
Validation loss: 1.6015170485742631

Epoch: 5| Step: 7
Training loss: 0.2020617425441742
Validation loss: 1.6037202714591898

Epoch: 5| Step: 8
Training loss: 0.22479352355003357
Validation loss: 1.6088702319770731

Epoch: 5| Step: 9
Training loss: 0.11515319347381592
Validation loss: 1.5985440772066835

Epoch: 5| Step: 10
Training loss: 0.37073981761932373
Validation loss: 1.586963777901024

Epoch: 419| Step: 0
Training loss: 0.14333797991275787
Validation loss: 1.5714128914699759

Epoch: 5| Step: 1
Training loss: 0.43264347314834595
Validation loss: 1.5903555270164245

Epoch: 5| Step: 2
Training loss: 0.10713372379541397
Validation loss: 1.5835374965462634

Epoch: 5| Step: 3
Training loss: 0.13232776522636414
Validation loss: 1.581118578551918

Epoch: 5| Step: 4
Training loss: 0.10663070529699326
Validation loss: 1.584692398707072

Epoch: 5| Step: 5
Training loss: 0.1566554754972458
Validation loss: 1.5777607669112503

Epoch: 5| Step: 6
Training loss: 0.12880480289459229
Validation loss: 1.5863455469890306

Epoch: 5| Step: 7
Training loss: 0.09526487439870834
Validation loss: 1.6070729917095554

Epoch: 5| Step: 8
Training loss: 0.24029536545276642
Validation loss: 1.597947060420949

Epoch: 5| Step: 9
Training loss: 0.16262422502040863
Validation loss: 1.5976386031796854

Epoch: 5| Step: 10
Training loss: 0.1196131557226181
Validation loss: 1.5977055975185928

Epoch: 420| Step: 0
Training loss: 0.13721288740634918
Validation loss: 1.5998560356837448

Epoch: 5| Step: 1
Training loss: 0.14645938575267792
Validation loss: 1.6162627179135558

Epoch: 5| Step: 2
Training loss: 0.1290607899427414
Validation loss: 1.5991009992937888

Epoch: 5| Step: 3
Training loss: 0.2980155348777771
Validation loss: 1.6270013880986038

Epoch: 5| Step: 4
Training loss: 0.1420009434223175
Validation loss: 1.6176825620794808

Epoch: 5| Step: 5
Training loss: 0.09555228054523468
Validation loss: 1.6756124586187384

Epoch: 5| Step: 6
Training loss: 0.10819512605667114
Validation loss: 1.665003509931667

Epoch: 5| Step: 7
Training loss: 0.12123242765665054
Validation loss: 1.665990980722571

Epoch: 5| Step: 8
Training loss: 0.336681991815567
Validation loss: 1.627535734125363

Epoch: 5| Step: 9
Training loss: 0.1222604289650917
Validation loss: 1.6419808787684287

Epoch: 5| Step: 10
Training loss: 0.23831920325756073
Validation loss: 1.6015223700513121

Epoch: 421| Step: 0
Training loss: 0.16876216232776642
Validation loss: 1.6061592448142268

Epoch: 5| Step: 1
Training loss: 0.21314814686775208
Validation loss: 1.5997687911474576

Epoch: 5| Step: 2
Training loss: 0.10637073218822479
Validation loss: 1.5715261249132053

Epoch: 5| Step: 3
Training loss: 0.1090330258011818
Validation loss: 1.607330515820493

Epoch: 5| Step: 4
Training loss: 0.12724407017230988
Validation loss: 1.60437822598283

Epoch: 5| Step: 5
Training loss: 0.3242301642894745
Validation loss: 1.6290825643847067

Epoch: 5| Step: 6
Training loss: 0.08467964828014374
Validation loss: 1.6116205197508617

Epoch: 5| Step: 7
Training loss: 0.14059719443321228
Validation loss: 1.6353742102141022

Epoch: 5| Step: 8
Training loss: 0.1250205636024475
Validation loss: 1.651498843264836

Epoch: 5| Step: 9
Training loss: 0.11969824135303497
Validation loss: 1.6673484028026622

Epoch: 5| Step: 10
Training loss: 0.28547486662864685
Validation loss: 1.6525552823979368

Epoch: 422| Step: 0
Training loss: 0.3292987048625946
Validation loss: 1.645319365685986

Epoch: 5| Step: 1
Training loss: 0.1545606553554535
Validation loss: 1.6282855567111765

Epoch: 5| Step: 2
Training loss: 0.09553398936986923
Validation loss: 1.6206496248963058

Epoch: 5| Step: 3
Training loss: 0.23316092789173126
Validation loss: 1.612203731331774

Epoch: 5| Step: 4
Training loss: 0.1906213015317917
Validation loss: 1.578903366160649

Epoch: 5| Step: 5
Training loss: 0.11882396042346954
Validation loss: 1.5746919775521884

Epoch: 5| Step: 6
Training loss: 0.12686209380626678
Validation loss: 1.5788368781407673

Epoch: 5| Step: 7
Training loss: 0.2353074550628662
Validation loss: 1.5680530301986202

Epoch: 5| Step: 8
Training loss: 0.220560222864151
Validation loss: 1.5692053828188168

Epoch: 5| Step: 9
Training loss: 0.2689969837665558
Validation loss: 1.5840593525158462

Epoch: 5| Step: 10
Training loss: 0.15549176931381226
Validation loss: 1.5841761641604926

Epoch: 423| Step: 0
Training loss: 0.10675327479839325
Validation loss: 1.6126846433967672

Epoch: 5| Step: 1
Training loss: 0.1690894365310669
Validation loss: 1.6333963101910007

Epoch: 5| Step: 2
Training loss: 0.19146713614463806
Validation loss: 1.6826405884117208

Epoch: 5| Step: 3
Training loss: 0.18046927452087402
Validation loss: 1.6798566567000521

Epoch: 5| Step: 4
Training loss: 0.1746811866760254
Validation loss: 1.6487469506520096

Epoch: 5| Step: 5
Training loss: 0.24606600403785706
Validation loss: 1.6568691845863097

Epoch: 5| Step: 6
Training loss: 0.1189327985048294
Validation loss: 1.6152226899259834

Epoch: 5| Step: 7
Training loss: 0.12433107942342758
Validation loss: 1.5858911147681616

Epoch: 5| Step: 8
Training loss: 0.3313709497451782
Validation loss: 1.574415578637072

Epoch: 5| Step: 9
Training loss: 0.19522199034690857
Validation loss: 1.593246442015453

Epoch: 5| Step: 10
Training loss: 0.10414965450763702
Validation loss: 1.5832368917362665

Epoch: 424| Step: 0
Training loss: 0.28711533546447754
Validation loss: 1.5835182154050438

Epoch: 5| Step: 1
Training loss: 0.23932936787605286
Validation loss: 1.5998188475126862

Epoch: 5| Step: 2
Training loss: 0.1722377985715866
Validation loss: 1.5975415918134874

Epoch: 5| Step: 3
Training loss: 0.128390833735466
Validation loss: 1.6199339512855775

Epoch: 5| Step: 4
Training loss: 0.12561874091625214
Validation loss: 1.6487664022753317

Epoch: 5| Step: 5
Training loss: 0.16278882324695587
Validation loss: 1.6631636991295764

Epoch: 5| Step: 6
Training loss: 0.1185065507888794
Validation loss: 1.6848666360301356

Epoch: 5| Step: 7
Training loss: 0.13033132255077362
Validation loss: 1.6804054424326906

Epoch: 5| Step: 8
Training loss: 0.16105368733406067
Validation loss: 1.6751830385577293

Epoch: 5| Step: 9
Training loss: 0.3299044668674469
Validation loss: 1.6616703310320455

Epoch: 5| Step: 10
Training loss: 0.179127499461174
Validation loss: 1.6377877586631364

Epoch: 425| Step: 0
Training loss: 0.08650237321853638
Validation loss: 1.601020275905568

Epoch: 5| Step: 1
Training loss: 0.1448703557252884
Validation loss: 1.5998599836903233

Epoch: 5| Step: 2
Training loss: 0.19196096062660217
Validation loss: 1.5914671831233527

Epoch: 5| Step: 3
Training loss: 0.16703040897846222
Validation loss: 1.6001853840325468

Epoch: 5| Step: 4
Training loss: 0.10816596448421478
Validation loss: 1.6165436108907063

Epoch: 5| Step: 5
Training loss: 0.21650490164756775
Validation loss: 1.6473563153256652

Epoch: 5| Step: 6
Training loss: 0.13119719922542572
Validation loss: 1.654161605783688

Epoch: 5| Step: 7
Training loss: 0.1127949208021164
Validation loss: 1.658944155580254

Epoch: 5| Step: 8
Training loss: 0.48321905732154846
Validation loss: 1.7154045104980469

Epoch: 5| Step: 9
Training loss: 0.13368627429008484
Validation loss: 1.7286241567263039

Epoch: 5| Step: 10
Training loss: 0.15078860521316528
Validation loss: 1.6929522765580045

Epoch: 426| Step: 0
Training loss: 0.1881740838289261
Validation loss: 1.6506451791332615

Epoch: 5| Step: 1
Training loss: 0.1294025182723999
Validation loss: 1.6215812749760126

Epoch: 5| Step: 2
Training loss: 0.13611431419849396
Validation loss: 1.613611940414675

Epoch: 5| Step: 3
Training loss: 0.16660574078559875
Validation loss: 1.622319950852343

Epoch: 5| Step: 4
Training loss: 0.1751527339220047
Validation loss: 1.593615339648339

Epoch: 5| Step: 5
Training loss: 0.14223209023475647
Validation loss: 1.6243385435432516

Epoch: 5| Step: 6
Training loss: 0.09856033325195312
Validation loss: 1.612402981327426

Epoch: 5| Step: 7
Training loss: 0.30249208211898804
Validation loss: 1.6050657835057986

Epoch: 5| Step: 8
Training loss: 0.16886195540428162
Validation loss: 1.647428443354945

Epoch: 5| Step: 9
Training loss: 0.0913955569267273
Validation loss: 1.6246720449898833

Epoch: 5| Step: 10
Training loss: 0.07802426815032959
Validation loss: 1.649943995219405

Epoch: 427| Step: 0
Training loss: 0.19007277488708496
Validation loss: 1.663133623779461

Epoch: 5| Step: 1
Training loss: 0.292719304561615
Validation loss: 1.657262832887711

Epoch: 5| Step: 2
Training loss: 0.10842796415090561
Validation loss: 1.65014664588436

Epoch: 5| Step: 3
Training loss: 0.11297202110290527
Validation loss: 1.6512864712745912

Epoch: 5| Step: 4
Training loss: 0.226851224899292
Validation loss: 1.64188640604737

Epoch: 5| Step: 5
Training loss: 0.11114199459552765
Validation loss: 1.636375819483111

Epoch: 5| Step: 6
Training loss: 0.15732522308826447
Validation loss: 1.6296187216235745

Epoch: 5| Step: 7
Training loss: 0.1625555455684662
Validation loss: 1.6385843471814228

Epoch: 5| Step: 8
Training loss: 0.11881685256958008
Validation loss: 1.6091671759082424

Epoch: 5| Step: 9
Training loss: 0.24011948704719543
Validation loss: 1.6363533671184252

Epoch: 5| Step: 10
Training loss: 0.18490228056907654
Validation loss: 1.6225687624305807

Epoch: 428| Step: 0
Training loss: 0.16415861248970032
Validation loss: 1.6025919439972087

Epoch: 5| Step: 1
Training loss: 0.2912544906139374
Validation loss: 1.5826547286843742

Epoch: 5| Step: 2
Training loss: 0.20792844891548157
Validation loss: 1.586464169204876

Epoch: 5| Step: 3
Training loss: 0.07424338907003403
Validation loss: 1.5735112954211492

Epoch: 5| Step: 4
Training loss: 0.1550692617893219
Validation loss: 1.5774382455374605

Epoch: 5| Step: 5
Training loss: 0.1688023805618286
Validation loss: 1.5968494274282967

Epoch: 5| Step: 6
Training loss: 0.0894356518983841
Validation loss: 1.6116943410647813

Epoch: 5| Step: 7
Training loss: 0.15650472044944763
Validation loss: 1.6168810039438226

Epoch: 5| Step: 8
Training loss: 0.25817087292671204
Validation loss: 1.6199468886980446

Epoch: 5| Step: 9
Training loss: 0.1294374167919159
Validation loss: 1.6360473863540157

Epoch: 5| Step: 10
Training loss: 0.0696970522403717
Validation loss: 1.6390294323685348

Epoch: 429| Step: 0
Training loss: 0.15579113364219666
Validation loss: 1.649543826298047

Epoch: 5| Step: 1
Training loss: 0.10875348001718521
Validation loss: 1.6435351217946699

Epoch: 5| Step: 2
Training loss: 0.09402898699045181
Validation loss: 1.6248147513276787

Epoch: 5| Step: 3
Training loss: 0.14005844295024872
Validation loss: 1.603392194676143

Epoch: 5| Step: 4
Training loss: 0.08519009500741959
Validation loss: 1.5948429299939064

Epoch: 5| Step: 5
Training loss: 0.1656821221113205
Validation loss: 1.590319493765472

Epoch: 5| Step: 6
Training loss: 0.09327290952205658
Validation loss: 1.5812321555229925

Epoch: 5| Step: 7
Training loss: 0.2616867423057556
Validation loss: 1.5978854599819388

Epoch: 5| Step: 8
Training loss: 0.12323005497455597
Validation loss: 1.6018131330449095

Epoch: 5| Step: 9
Training loss: 0.192239448428154
Validation loss: 1.5954255275828864

Epoch: 5| Step: 10
Training loss: 0.30057498812675476
Validation loss: 1.5928843905848842

Epoch: 430| Step: 0
Training loss: 0.10648350417613983
Validation loss: 1.6180472450871621

Epoch: 5| Step: 1
Training loss: 0.1390220820903778
Validation loss: 1.607692042986552

Epoch: 5| Step: 2
Training loss: 0.17499558627605438
Validation loss: 1.6015448839433732

Epoch: 5| Step: 3
Training loss: 0.13267716765403748
Validation loss: 1.5818371003673923

Epoch: 5| Step: 4
Training loss: 0.2502254247665405
Validation loss: 1.5779103822605585

Epoch: 5| Step: 5
Training loss: 0.07816994190216064
Validation loss: 1.566144920164539

Epoch: 5| Step: 6
Training loss: 0.18574193120002747
Validation loss: 1.5758195795038694

Epoch: 5| Step: 7
Training loss: 0.15168897807598114
Validation loss: 1.587266843806031

Epoch: 5| Step: 8
Training loss: 0.2698657512664795
Validation loss: 1.5866679658171952

Epoch: 5| Step: 9
Training loss: 0.08896084129810333
Validation loss: 1.597642998541555

Epoch: 5| Step: 10
Training loss: 0.2525451183319092
Validation loss: 1.6068253876060568

Epoch: 431| Step: 0
Training loss: 0.08683701604604721
Validation loss: 1.6163196525266093

Epoch: 5| Step: 1
Training loss: 0.13884516060352325
Validation loss: 1.6413432885241765

Epoch: 5| Step: 2
Training loss: 0.13829711079597473
Validation loss: 1.6475887170401953

Epoch: 5| Step: 3
Training loss: 0.21155476570129395
Validation loss: 1.6545721971860496

Epoch: 5| Step: 4
Training loss: 0.16696929931640625
Validation loss: 1.6643878939331218

Epoch: 5| Step: 5
Training loss: 0.09118146449327469
Validation loss: 1.6440232799899193

Epoch: 5| Step: 6
Training loss: 0.26279860734939575
Validation loss: 1.6074699535164783

Epoch: 5| Step: 7
Training loss: 0.1591825932264328
Validation loss: 1.6056884245205951

Epoch: 5| Step: 8
Training loss: 0.116513691842556
Validation loss: 1.606560919874458

Epoch: 5| Step: 9
Training loss: 0.2740759253501892
Validation loss: 1.6159090444605837

Epoch: 5| Step: 10
Training loss: 0.09493382275104523
Validation loss: 1.6235360868515507

Epoch: 432| Step: 0
Training loss: 0.16707901656627655
Validation loss: 1.6055032841620906

Epoch: 5| Step: 1
Training loss: 0.29330378770828247
Validation loss: 1.630905948659425

Epoch: 5| Step: 2
Training loss: 0.14145080745220184
Validation loss: 1.6295663233726256

Epoch: 5| Step: 3
Training loss: 0.1562400758266449
Validation loss: 1.6423335024105605

Epoch: 5| Step: 4
Training loss: 0.14494310319423676
Validation loss: 1.6503258238556564

Epoch: 5| Step: 5
Training loss: 0.19919922947883606
Validation loss: 1.6527716895585418

Epoch: 5| Step: 6
Training loss: 0.14400795102119446
Validation loss: 1.6362678953396377

Epoch: 5| Step: 7
Training loss: 0.13045953214168549
Validation loss: 1.6245235537969938

Epoch: 5| Step: 8
Training loss: 0.1572299301624298
Validation loss: 1.610223348422717

Epoch: 5| Step: 9
Training loss: 0.10442440211772919
Validation loss: 1.6244724181390577

Epoch: 5| Step: 10
Training loss: 0.30634182691574097
Validation loss: 1.6033258540655977

Epoch: 433| Step: 0
Training loss: 0.23804453015327454
Validation loss: 1.6264880446977512

Epoch: 5| Step: 1
Training loss: 0.09025625139474869
Validation loss: 1.626441535129342

Epoch: 5| Step: 2
Training loss: 0.17893704771995544
Validation loss: 1.6126955875786402

Epoch: 5| Step: 3
Training loss: 0.22400684654712677
Validation loss: 1.6209527895014773

Epoch: 5| Step: 4
Training loss: 0.11272643506526947
Validation loss: 1.612703484873618

Epoch: 5| Step: 5
Training loss: 0.17817096412181854
Validation loss: 1.6439719418043732

Epoch: 5| Step: 6
Training loss: 0.1602691113948822
Validation loss: 1.6597175252053045

Epoch: 5| Step: 7
Training loss: 0.1963714361190796
Validation loss: 1.670332589457112

Epoch: 5| Step: 8
Training loss: 0.07720082998275757
Validation loss: 1.651248542211389

Epoch: 5| Step: 9
Training loss: 0.11313295364379883
Validation loss: 1.6326227521383634

Epoch: 5| Step: 10
Training loss: 0.07440736144781113
Validation loss: 1.591516403741734

Epoch: 434| Step: 0
Training loss: 0.1187407597899437
Validation loss: 1.5821153040855163

Epoch: 5| Step: 1
Training loss: 0.23125477135181427
Validation loss: 1.5990423182005524

Epoch: 5| Step: 2
Training loss: 0.20811936259269714
Validation loss: 1.6111857480900262

Epoch: 5| Step: 3
Training loss: 0.24928072094917297
Validation loss: 1.6118796128098682

Epoch: 5| Step: 4
Training loss: 0.12282474339008331
Validation loss: 1.5997060844975133

Epoch: 5| Step: 5
Training loss: 0.24773618578910828
Validation loss: 1.626928142322007

Epoch: 5| Step: 6
Training loss: 0.15352225303649902
Validation loss: 1.621115558890886

Epoch: 5| Step: 7
Training loss: 0.1677773892879486
Validation loss: 1.6285275874599334

Epoch: 5| Step: 8
Training loss: 0.19368553161621094
Validation loss: 1.6301513615474905

Epoch: 5| Step: 9
Training loss: 0.19018664956092834
Validation loss: 1.6267726728993077

Epoch: 5| Step: 10
Training loss: 0.1869107484817505
Validation loss: 1.6023101063184841

Epoch: 435| Step: 0
Training loss: 0.2293998897075653
Validation loss: 1.6321341594060261

Epoch: 5| Step: 1
Training loss: 0.11602556705474854
Validation loss: 1.6091753769946355

Epoch: 5| Step: 2
Training loss: 0.19539771974086761
Validation loss: 1.5916797768685125

Epoch: 5| Step: 3
Training loss: 0.09213674813508987
Validation loss: 1.6115981109680668

Epoch: 5| Step: 4
Training loss: 0.23192627727985382
Validation loss: 1.6467140682281987

Epoch: 5| Step: 5
Training loss: 0.13984520733356476
Validation loss: 1.6376616480529949

Epoch: 5| Step: 6
Training loss: 0.12784698605537415
Validation loss: 1.6249746584123181

Epoch: 5| Step: 7
Training loss: 0.18673314154148102
Validation loss: 1.6613150130036056

Epoch: 5| Step: 8
Training loss: 0.15478704869747162
Validation loss: 1.6280386883725402

Epoch: 5| Step: 9
Training loss: 0.2841568887233734
Validation loss: 1.6186552624548636

Epoch: 5| Step: 10
Training loss: 0.10521437972784042
Validation loss: 1.6583469990761048

Epoch: 436| Step: 0
Training loss: 0.15448160469532013
Validation loss: 1.632390672160733

Epoch: 5| Step: 1
Training loss: 0.15156880021095276
Validation loss: 1.6277754268338602

Epoch: 5| Step: 2
Training loss: 0.11644633114337921
Validation loss: 1.602846852553788

Epoch: 5| Step: 3
Training loss: 0.2557547092437744
Validation loss: 1.5877176305299163

Epoch: 5| Step: 4
Training loss: 0.18179967999458313
Validation loss: 1.5740702293252433

Epoch: 5| Step: 5
Training loss: 0.20864693820476532
Validation loss: 1.5754734284134322

Epoch: 5| Step: 6
Training loss: 0.26476508378982544
Validation loss: 1.5599121265513922

Epoch: 5| Step: 7
Training loss: 0.3865521550178528
Validation loss: 1.5642548786696566

Epoch: 5| Step: 8
Training loss: 0.16290739178657532
Validation loss: 1.5720285689958962

Epoch: 5| Step: 9
Training loss: 0.22339899837970734
Validation loss: 1.609112613944597

Epoch: 5| Step: 10
Training loss: 0.23773238062858582
Validation loss: 1.6145847984539565

Epoch: 437| Step: 0
Training loss: 0.13896523416042328
Validation loss: 1.6444433530171711

Epoch: 5| Step: 1
Training loss: 0.32361045479774475
Validation loss: 1.6424745603274273

Epoch: 5| Step: 2
Training loss: 0.20466968417167664
Validation loss: 1.6788066766595329

Epoch: 5| Step: 3
Training loss: 0.15964263677597046
Validation loss: 1.619366483021808

Epoch: 5| Step: 4
Training loss: 0.0998513400554657
Validation loss: 1.6188619508538196

Epoch: 5| Step: 5
Training loss: 0.13152766227722168
Validation loss: 1.6010152909063524

Epoch: 5| Step: 6
Training loss: 0.2707616090774536
Validation loss: 1.593757111539123

Epoch: 5| Step: 7
Training loss: 0.312771737575531
Validation loss: 1.572936870718515

Epoch: 5| Step: 8
Training loss: 0.1528078019618988
Validation loss: 1.5834727992293656

Epoch: 5| Step: 9
Training loss: 0.2097257375717163
Validation loss: 1.618767665278527

Epoch: 5| Step: 10
Training loss: 0.16246023774147034
Validation loss: 1.583434138887672

Epoch: 438| Step: 0
Training loss: 0.16195133328437805
Validation loss: 1.604961169663296

Epoch: 5| Step: 1
Training loss: 0.2095920294523239
Validation loss: 1.60536705165781

Epoch: 5| Step: 2
Training loss: 0.14525900781154633
Validation loss: 1.6020053535379388

Epoch: 5| Step: 3
Training loss: 0.1336044818162918
Validation loss: 1.6032308134981381

Epoch: 5| Step: 4
Training loss: 0.1126885786652565
Validation loss: 1.5941199282164216

Epoch: 5| Step: 5
Training loss: 0.2912493348121643
Validation loss: 1.5856563173314577

Epoch: 5| Step: 6
Training loss: 0.29228201508522034
Validation loss: 1.6057081209715975

Epoch: 5| Step: 7
Training loss: 0.15680918097496033
Validation loss: 1.5755022661660307

Epoch: 5| Step: 8
Training loss: 0.1289374828338623
Validation loss: 1.5851121205155567

Epoch: 5| Step: 9
Training loss: 0.17896713316440582
Validation loss: 1.5765207608540852

Epoch: 5| Step: 10
Training loss: 0.1393033117055893
Validation loss: 1.6102022329966228

Epoch: 439| Step: 0
Training loss: 0.25106239318847656
Validation loss: 1.6324210295113184

Epoch: 5| Step: 1
Training loss: 0.10530407726764679
Validation loss: 1.621079001375424

Epoch: 5| Step: 2
Training loss: 0.1343560665845871
Validation loss: 1.5820713786668674

Epoch: 5| Step: 3
Training loss: 0.1233505979180336
Validation loss: 1.5921021981905865

Epoch: 5| Step: 4
Training loss: 0.08045206218957901
Validation loss: 1.6100358988649102

Epoch: 5| Step: 5
Training loss: 0.15593571960926056
Validation loss: 1.6031927062619118

Epoch: 5| Step: 6
Training loss: 0.19850550591945648
Validation loss: 1.6029169315932899

Epoch: 5| Step: 7
Training loss: 0.22870612144470215
Validation loss: 1.6056548703101374

Epoch: 5| Step: 8
Training loss: 0.15490150451660156
Validation loss: 1.6083544633721794

Epoch: 5| Step: 9
Training loss: 0.27624547481536865
Validation loss: 1.5916481864067815

Epoch: 5| Step: 10
Training loss: 0.11242632567882538
Validation loss: 1.6423621203309746

Epoch: 440| Step: 0
Training loss: 0.17881375551223755
Validation loss: 1.6522208541952155

Epoch: 5| Step: 1
Training loss: 0.19765961170196533
Validation loss: 1.6619923294231456

Epoch: 5| Step: 2
Training loss: 0.25478023290634155
Validation loss: 1.6606208534650906

Epoch: 5| Step: 3
Training loss: 0.18117743730545044
Validation loss: 1.6121056246501144

Epoch: 5| Step: 4
Training loss: 0.17055216431617737
Validation loss: 1.6038341073579685

Epoch: 5| Step: 5
Training loss: 0.22205257415771484
Validation loss: 1.5635611075226978

Epoch: 5| Step: 6
Training loss: 0.10954512655735016
Validation loss: 1.576250405721767

Epoch: 5| Step: 7
Training loss: 0.13073495030403137
Validation loss: 1.5686487228639665

Epoch: 5| Step: 8
Training loss: 0.2250889241695404
Validation loss: 1.5989222641914123

Epoch: 5| Step: 9
Training loss: 0.14603784680366516
Validation loss: 1.5802149759825839

Epoch: 5| Step: 10
Training loss: 0.17043408751487732
Validation loss: 1.5782338983269149

Epoch: 441| Step: 0
Training loss: 0.2253694236278534
Validation loss: 1.5892506607117192

Epoch: 5| Step: 1
Training loss: 0.27566879987716675
Validation loss: 1.5722064997560234

Epoch: 5| Step: 2
Training loss: 0.15678110718727112
Validation loss: 1.5626583535184142

Epoch: 5| Step: 3
Training loss: 0.12590332329273224
Validation loss: 1.5693608612142584

Epoch: 5| Step: 4
Training loss: 0.23828844726085663
Validation loss: 1.5802348941885016

Epoch: 5| Step: 5
Training loss: 0.15368154644966125
Validation loss: 1.596464519218732

Epoch: 5| Step: 6
Training loss: 0.09051163494586945
Validation loss: 1.5872741847909906

Epoch: 5| Step: 7
Training loss: 0.1812092363834381
Validation loss: 1.6280109305535593

Epoch: 5| Step: 8
Training loss: 0.10661168396472931
Validation loss: 1.5964427263505998

Epoch: 5| Step: 9
Training loss: 0.12464006245136261
Validation loss: 1.6206157386943858

Epoch: 5| Step: 10
Training loss: 0.18291416764259338
Validation loss: 1.5942439225412184

Epoch: 442| Step: 0
Training loss: 0.1041618213057518
Validation loss: 1.5823881497947119

Epoch: 5| Step: 1
Training loss: 0.14861996471881866
Validation loss: 1.5713632440054288

Epoch: 5| Step: 2
Training loss: 0.14126916229724884
Validation loss: 1.5855300900756673

Epoch: 5| Step: 3
Training loss: 0.11195500195026398
Validation loss: 1.548144050823745

Epoch: 5| Step: 4
Training loss: 0.1939263641834259
Validation loss: 1.5654870912592898

Epoch: 5| Step: 5
Training loss: 0.26878732442855835
Validation loss: 1.5791175044992918

Epoch: 5| Step: 6
Training loss: 0.23687322437763214
Validation loss: 1.5886758008310873

Epoch: 5| Step: 7
Training loss: 0.13055650889873505
Validation loss: 1.5770226460631176

Epoch: 5| Step: 8
Training loss: 0.11401023715734482
Validation loss: 1.5975517624167985

Epoch: 5| Step: 9
Training loss: 0.2718943953514099
Validation loss: 1.5996732224700272

Epoch: 5| Step: 10
Training loss: 0.15834909677505493
Validation loss: 1.60878247855812

Epoch: 443| Step: 0
Training loss: 0.16531318426132202
Validation loss: 1.579605101257242

Epoch: 5| Step: 1
Training loss: 0.13402044773101807
Validation loss: 1.5701443790107645

Epoch: 5| Step: 2
Training loss: 0.14451129734516144
Validation loss: 1.5714608212952972

Epoch: 5| Step: 3
Training loss: 0.16267570853233337
Validation loss: 1.5706225364438948

Epoch: 5| Step: 4
Training loss: 0.134541854262352
Validation loss: 1.5489076170870053

Epoch: 5| Step: 5
Training loss: 0.09750612080097198
Validation loss: 1.5505409266359063

Epoch: 5| Step: 6
Training loss: 0.13771919906139374
Validation loss: 1.5892145223515008

Epoch: 5| Step: 7
Training loss: 0.23983259499073029
Validation loss: 1.5737405720577444

Epoch: 5| Step: 8
Training loss: 0.18989279866218567
Validation loss: 1.5689014465578142

Epoch: 5| Step: 9
Training loss: 0.1919296681880951
Validation loss: 1.6084176327592583

Epoch: 5| Step: 10
Training loss: 0.06770426034927368
Validation loss: 1.6236352112985426

Epoch: 444| Step: 0
Training loss: 0.11035237461328506
Validation loss: 1.6194591804217267

Epoch: 5| Step: 1
Training loss: 0.0886022299528122
Validation loss: 1.6446756906406854

Epoch: 5| Step: 2
Training loss: 0.14568693935871124
Validation loss: 1.6383423113053845

Epoch: 5| Step: 3
Training loss: 0.1850162297487259
Validation loss: 1.614440801323101

Epoch: 5| Step: 4
Training loss: 0.2236570566892624
Validation loss: 1.6079934361160442

Epoch: 5| Step: 5
Training loss: 0.17601574957370758
Validation loss: 1.5629029671351116

Epoch: 5| Step: 6
Training loss: 0.18284490704536438
Validation loss: 1.596808966769967

Epoch: 5| Step: 7
Training loss: 0.16517138481140137
Validation loss: 1.5972956559991325

Epoch: 5| Step: 8
Training loss: 0.1358005255460739
Validation loss: 1.5977880967560636

Epoch: 5| Step: 9
Training loss: 0.12654344737529755
Validation loss: 1.6028852232040898

Epoch: 5| Step: 10
Training loss: 0.12672048807144165
Validation loss: 1.5874721157935359

Epoch: 445| Step: 0
Training loss: 0.21486437320709229
Validation loss: 1.5978969066373763

Epoch: 5| Step: 1
Training loss: 0.13541501760482788
Validation loss: 1.6055042038681686

Epoch: 5| Step: 2
Training loss: 0.10618889331817627
Validation loss: 1.589337541211036

Epoch: 5| Step: 3
Training loss: 0.14116603136062622
Validation loss: 1.6282120212431876

Epoch: 5| Step: 4
Training loss: 0.17765049636363983
Validation loss: 1.6427463831440094

Epoch: 5| Step: 5
Training loss: 0.10343930870294571
Validation loss: 1.616301719860364

Epoch: 5| Step: 6
Training loss: 0.23050037026405334
Validation loss: 1.5745655964779597

Epoch: 5| Step: 7
Training loss: 0.09348998218774796
Validation loss: 1.5580967164808703

Epoch: 5| Step: 8
Training loss: 0.15340332686901093
Validation loss: 1.515698003512557

Epoch: 5| Step: 9
Training loss: 0.21740278601646423
Validation loss: 1.5431606769561768

Epoch: 5| Step: 10
Training loss: 0.2650533616542816
Validation loss: 1.5535320620382986

Epoch: 446| Step: 0
Training loss: 0.06442718952894211
Validation loss: 1.5669899986636253

Epoch: 5| Step: 1
Training loss: 0.22171738743782043
Validation loss: 1.5906683091194398

Epoch: 5| Step: 2
Training loss: 0.138866126537323
Validation loss: 1.6104689900593092

Epoch: 5| Step: 3
Training loss: 0.17784467339515686
Validation loss: 1.5950996529671453

Epoch: 5| Step: 4
Training loss: 0.28326714038848877
Validation loss: 1.6278938349857126

Epoch: 5| Step: 5
Training loss: 0.1464831829071045
Validation loss: 1.6035719212665354

Epoch: 5| Step: 6
Training loss: 0.09725870192050934
Validation loss: 1.6051979680215158

Epoch: 5| Step: 7
Training loss: 0.09488342702388763
Validation loss: 1.5990664138588855

Epoch: 5| Step: 8
Training loss: 0.08932120352983475
Validation loss: 1.5916686724590998

Epoch: 5| Step: 9
Training loss: 0.15443596243858337
Validation loss: 1.5725611614924606

Epoch: 5| Step: 10
Training loss: 0.11781678348779678
Validation loss: 1.5684843229991134

Epoch: 447| Step: 0
Training loss: 0.2198486328125
Validation loss: 1.5799970742194884

Epoch: 5| Step: 1
Training loss: 0.14034883677959442
Validation loss: 1.5872954303218472

Epoch: 5| Step: 2
Training loss: 0.10783357918262482
Validation loss: 1.5694285220997308

Epoch: 5| Step: 3
Training loss: 0.195731058716774
Validation loss: 1.5719643164706487

Epoch: 5| Step: 4
Training loss: 0.120968297123909
Validation loss: 1.5975325184483682

Epoch: 5| Step: 5
Training loss: 0.12688913941383362
Validation loss: 1.6080159717990505

Epoch: 5| Step: 6
Training loss: 0.12424023449420929
Validation loss: 1.6059337008383967

Epoch: 5| Step: 7
Training loss: 0.27358296513557434
Validation loss: 1.6122744737132904

Epoch: 5| Step: 8
Training loss: 0.14596351981163025
Validation loss: 1.5989132824764456

Epoch: 5| Step: 9
Training loss: 0.1433372050523758
Validation loss: 1.580638563761147

Epoch: 5| Step: 10
Training loss: 0.11314105242490768
Validation loss: 1.58074741337889

Epoch: 448| Step: 0
Training loss: 0.07050161808729172
Validation loss: 1.5650266883193806

Epoch: 5| Step: 1
Training loss: 0.06383711099624634
Validation loss: 1.5896551121947586

Epoch: 5| Step: 2
Training loss: 0.1785748302936554
Validation loss: 1.57134368342738

Epoch: 5| Step: 3
Training loss: 0.185647115111351
Validation loss: 1.5905184899607012

Epoch: 5| Step: 4
Training loss: 0.21043804287910461
Validation loss: 1.5875368041376914

Epoch: 5| Step: 5
Training loss: 0.11535954475402832
Validation loss: 1.5708835945334485

Epoch: 5| Step: 6
Training loss: 0.18904320895671844
Validation loss: 1.5977790227500341

Epoch: 5| Step: 7
Training loss: 0.09319795668125153
Validation loss: 1.591918876094203

Epoch: 5| Step: 8
Training loss: 0.13738635182380676
Validation loss: 1.604107774713988

Epoch: 5| Step: 9
Training loss: 0.09850616753101349
Validation loss: 1.5864549285622054

Epoch: 5| Step: 10
Training loss: 0.24945233762264252
Validation loss: 1.5715278297342279

Epoch: 449| Step: 0
Training loss: 0.11681846529245377
Validation loss: 1.5885937098533875

Epoch: 5| Step: 1
Training loss: 0.18611977994441986
Validation loss: 1.56309853189735

Epoch: 5| Step: 2
Training loss: 0.10490727424621582
Validation loss: 1.5401278170206214

Epoch: 5| Step: 3
Training loss: 0.21878597140312195
Validation loss: 1.5814003662396503

Epoch: 5| Step: 4
Training loss: 0.12099993228912354
Validation loss: 1.5676232845552507

Epoch: 5| Step: 5
Training loss: 0.19823245704174042
Validation loss: 1.556168125521752

Epoch: 5| Step: 6
Training loss: 0.0701851099729538
Validation loss: 1.5507551726474558

Epoch: 5| Step: 7
Training loss: 0.22046217322349548
Validation loss: 1.535082435095182

Epoch: 5| Step: 8
Training loss: 0.12881259620189667
Validation loss: 1.5922817927534862

Epoch: 5| Step: 9
Training loss: 0.11588975042104721
Validation loss: 1.5896839211064

Epoch: 5| Step: 10
Training loss: 0.1705966591835022
Validation loss: 1.6281450679225307

Epoch: 450| Step: 0
Training loss: 0.11909084022045135
Validation loss: 1.640998440404092

Epoch: 5| Step: 1
Training loss: 0.1665126383304596
Validation loss: 1.6140843463200394

Epoch: 5| Step: 2
Training loss: 0.14163312315940857
Validation loss: 1.6170030178562287

Epoch: 5| Step: 3
Training loss: 0.11599038541316986
Validation loss: 1.595604665817753

Epoch: 5| Step: 4
Training loss: 0.18042978644371033
Validation loss: 1.5876246588204497

Epoch: 5| Step: 5
Training loss: 0.17778882384300232
Validation loss: 1.5863584369741461

Epoch: 5| Step: 6
Training loss: 0.10893650352954865
Validation loss: 1.5932188931331839

Epoch: 5| Step: 7
Training loss: 0.1767515242099762
Validation loss: 1.567126840673467

Epoch: 5| Step: 8
Training loss: 0.23864701390266418
Validation loss: 1.5840129557476248

Epoch: 5| Step: 9
Training loss: 0.18216614425182343
Validation loss: 1.5985510842774504

Epoch: 5| Step: 10
Training loss: 0.1246379017829895
Validation loss: 1.5949878827218087

Epoch: 451| Step: 0
Training loss: 0.13629862666130066
Validation loss: 1.6357285354727058

Epoch: 5| Step: 1
Training loss: 0.08324512839317322
Validation loss: 1.6441066034378544

Epoch: 5| Step: 2
Training loss: 0.23277950286865234
Validation loss: 1.672582875015915

Epoch: 5| Step: 3
Training loss: 0.24455752968788147
Validation loss: 1.6556277864722795

Epoch: 5| Step: 4
Training loss: 0.1514948606491089
Validation loss: 1.6448339070043256

Epoch: 5| Step: 5
Training loss: 0.19158229231834412
Validation loss: 1.6448819957753664

Epoch: 5| Step: 6
Training loss: 0.2808825373649597
Validation loss: 1.6370065340431788

Epoch: 5| Step: 7
Training loss: 0.10418449342250824
Validation loss: 1.6269161265383485

Epoch: 5| Step: 8
Training loss: 0.10627660900354385
Validation loss: 1.6382002445959276

Epoch: 5| Step: 9
Training loss: 0.13821157813072205
Validation loss: 1.605041693615657

Epoch: 5| Step: 10
Training loss: 0.09179431945085526
Validation loss: 1.5867077342925533

Epoch: 452| Step: 0
Training loss: 0.15452492237091064
Validation loss: 1.5729540765926402

Epoch: 5| Step: 1
Training loss: 0.1258898675441742
Validation loss: 1.5896333007402317

Epoch: 5| Step: 2
Training loss: 0.16859620809555054
Validation loss: 1.5847210576457362

Epoch: 5| Step: 3
Training loss: 0.18510480225086212
Validation loss: 1.5754657176233107

Epoch: 5| Step: 4
Training loss: 0.15982133150100708
Validation loss: 1.5789341401028376

Epoch: 5| Step: 5
Training loss: 0.1072695404291153
Validation loss: 1.5610488384000716

Epoch: 5| Step: 6
Training loss: 0.19561022520065308
Validation loss: 1.6031837617197344

Epoch: 5| Step: 7
Training loss: 0.13074779510498047
Validation loss: 1.607328332880492

Epoch: 5| Step: 8
Training loss: 0.15717412531375885
Validation loss: 1.597072624391125

Epoch: 5| Step: 9
Training loss: 0.3401922285556793
Validation loss: 1.617810381356106

Epoch: 5| Step: 10
Training loss: 0.15048682689666748
Validation loss: 1.5777294174317391

Epoch: 453| Step: 0
Training loss: 0.10318592935800552
Validation loss: 1.5714911350639917

Epoch: 5| Step: 1
Training loss: 0.1165585070848465
Validation loss: 1.547780434290568

Epoch: 5| Step: 2
Training loss: 0.2971925735473633
Validation loss: 1.556452610159433

Epoch: 5| Step: 3
Training loss: 0.08387097716331482
Validation loss: 1.5535753023239873

Epoch: 5| Step: 4
Training loss: 0.19224345684051514
Validation loss: 1.5688402063103133

Epoch: 5| Step: 5
Training loss: 0.12436380237340927
Validation loss: 1.5752574102852934

Epoch: 5| Step: 6
Training loss: 0.15389864146709442
Validation loss: 1.5744744552079069

Epoch: 5| Step: 7
Training loss: 0.1270473450422287
Validation loss: 1.5703102388689596

Epoch: 5| Step: 8
Training loss: 0.10215537250041962
Validation loss: 1.5806376421323387

Epoch: 5| Step: 9
Training loss: 0.2123243361711502
Validation loss: 1.5902690182449997

Epoch: 5| Step: 10
Training loss: 0.0851421058177948
Validation loss: 1.58936736916983

Epoch: 454| Step: 0
Training loss: 0.17313960194587708
Validation loss: 1.5697108853247859

Epoch: 5| Step: 1
Training loss: 0.08316874504089355
Validation loss: 1.5411626036449144

Epoch: 5| Step: 2
Training loss: 0.19537167251110077
Validation loss: 1.5254920862054313

Epoch: 5| Step: 3
Training loss: 0.15995068848133087
Validation loss: 1.5433233168817335

Epoch: 5| Step: 4
Training loss: 0.10895276069641113
Validation loss: 1.5174953899075907

Epoch: 5| Step: 5
Training loss: 0.2181776463985443
Validation loss: 1.523313853048509

Epoch: 5| Step: 6
Training loss: 0.1006103977560997
Validation loss: 1.5165181711155882

Epoch: 5| Step: 7
Training loss: 0.12440164387226105
Validation loss: 1.525453011194865

Epoch: 5| Step: 8
Training loss: 0.09590311348438263
Validation loss: 1.5570220267900856

Epoch: 5| Step: 9
Training loss: 0.14042788743972778
Validation loss: 1.5691535665142922

Epoch: 5| Step: 10
Training loss: 0.09053319692611694
Validation loss: 1.6080043341523858

Epoch: 455| Step: 0
Training loss: 0.21427342295646667
Validation loss: 1.594391115250126

Epoch: 5| Step: 1
Training loss: 0.12444955110549927
Validation loss: 1.6046105584790629

Epoch: 5| Step: 2
Training loss: 0.0939895361661911
Validation loss: 1.5910233707838162

Epoch: 5| Step: 3
Training loss: 0.15865428745746613
Validation loss: 1.571001306015958

Epoch: 5| Step: 4
Training loss: 0.17717039585113525
Validation loss: 1.5966581593277633

Epoch: 5| Step: 5
Training loss: 0.27119213342666626
Validation loss: 1.5857613791701615

Epoch: 5| Step: 6
Training loss: 0.15077340602874756
Validation loss: 1.5556944236960462

Epoch: 5| Step: 7
Training loss: 0.082878477871418
Validation loss: 1.5720664890863563

Epoch: 5| Step: 8
Training loss: 0.10757181793451309
Validation loss: 1.5762443798844532

Epoch: 5| Step: 9
Training loss: 0.11925442516803741
Validation loss: 1.587559087302095

Epoch: 5| Step: 10
Training loss: 0.15270939469337463
Validation loss: 1.6163851022720337

Epoch: 456| Step: 0
Training loss: 0.1093253642320633
Validation loss: 1.5724616025083809

Epoch: 5| Step: 1
Training loss: 0.10537330061197281
Validation loss: 1.581869677830768

Epoch: 5| Step: 2
Training loss: 0.19023743271827698
Validation loss: 1.5889063035288165

Epoch: 5| Step: 3
Training loss: 0.07989896833896637
Validation loss: 1.5831814658257268

Epoch: 5| Step: 4
Training loss: 0.10850652307271957
Validation loss: 1.588348174607882

Epoch: 5| Step: 5
Training loss: 0.08380945771932602
Validation loss: 1.5693159744303713

Epoch: 5| Step: 6
Training loss: 0.07785690575838089
Validation loss: 1.5649423958152853

Epoch: 5| Step: 7
Training loss: 0.20522566139698029
Validation loss: 1.5663713037326772

Epoch: 5| Step: 8
Training loss: 0.162283793091774
Validation loss: 1.5838846634793025

Epoch: 5| Step: 9
Training loss: 0.2607945501804352
Validation loss: 1.598636487478851

Epoch: 5| Step: 10
Training loss: 0.13025929033756256
Validation loss: 1.5694061556170065

Epoch: 457| Step: 0
Training loss: 0.17556825280189514
Validation loss: 1.5818103103227512

Epoch: 5| Step: 1
Training loss: 0.0830099806189537
Validation loss: 1.567874098336825

Epoch: 5| Step: 2
Training loss: 0.05977121740579605
Validation loss: 1.5866992947875813

Epoch: 5| Step: 3
Training loss: 0.09135911613702774
Validation loss: 1.5736654676416868

Epoch: 5| Step: 4
Training loss: 0.23303714394569397
Validation loss: 1.585221440561356

Epoch: 5| Step: 5
Training loss: 0.15588119626045227
Validation loss: 1.5720046335651028

Epoch: 5| Step: 6
Training loss: 0.20994225144386292
Validation loss: 1.6129707136461813

Epoch: 5| Step: 7
Training loss: 0.13052943348884583
Validation loss: 1.5974236496033207

Epoch: 5| Step: 8
Training loss: 0.10168199241161346
Validation loss: 1.6061739146068532

Epoch: 5| Step: 9
Training loss: 0.1054314598441124
Validation loss: 1.5941593595730361

Epoch: 5| Step: 10
Training loss: 0.15163348615169525
Validation loss: 1.6015529299295077

Epoch: 458| Step: 0
Training loss: 0.06093538925051689
Validation loss: 1.607437401689509

Epoch: 5| Step: 1
Training loss: 0.08935963362455368
Validation loss: 1.6116534394602622

Epoch: 5| Step: 2
Training loss: 0.13862203061580658
Validation loss: 1.6142937098779986

Epoch: 5| Step: 3
Training loss: 0.17684780061244965
Validation loss: 1.6050310186160508

Epoch: 5| Step: 4
Training loss: 0.22762612998485565
Validation loss: 1.5989728255938458

Epoch: 5| Step: 5
Training loss: 0.07531043142080307
Validation loss: 1.5669504090022015

Epoch: 5| Step: 6
Training loss: 0.1401822865009308
Validation loss: 1.5731862411704114

Epoch: 5| Step: 7
Training loss: 0.33481118083000183
Validation loss: 1.5524226170714184

Epoch: 5| Step: 8
Training loss: 0.1260196417570114
Validation loss: 1.5494708476528045

Epoch: 5| Step: 9
Training loss: 0.1213541030883789
Validation loss: 1.5619995670933877

Epoch: 5| Step: 10
Training loss: 0.14676052331924438
Validation loss: 1.5462498536673925

Epoch: 459| Step: 0
Training loss: 0.13673970103263855
Validation loss: 1.5690924224033151

Epoch: 5| Step: 1
Training loss: 0.11120326817035675
Validation loss: 1.55803922940326

Epoch: 5| Step: 2
Training loss: 0.2650805115699768
Validation loss: 1.5844379381466938

Epoch: 5| Step: 3
Training loss: 0.1753706932067871
Validation loss: 1.576712255836815

Epoch: 5| Step: 4
Training loss: 0.07451675087213516
Validation loss: 1.5655057366176317

Epoch: 5| Step: 5
Training loss: 0.19067004323005676
Validation loss: 1.5571171660577097

Epoch: 5| Step: 6
Training loss: 0.07835130393505096
Validation loss: 1.5329472300826863

Epoch: 5| Step: 7
Training loss: 0.2143915444612503
Validation loss: 1.5637423607610887

Epoch: 5| Step: 8
Training loss: 0.09961456060409546
Validation loss: 1.5298656020113217

Epoch: 5| Step: 9
Training loss: 0.07549379765987396
Validation loss: 1.5702823067224154

Epoch: 5| Step: 10
Training loss: 0.09334064275026321
Validation loss: 1.5787796563999628

Epoch: 460| Step: 0
Training loss: 0.11442746967077255
Validation loss: 1.5658850336587558

Epoch: 5| Step: 1
Training loss: 0.10130877792835236
Validation loss: 1.5766466253547258

Epoch: 5| Step: 2
Training loss: 0.12325147539377213
Validation loss: 1.5711045342106973

Epoch: 5| Step: 3
Training loss: 0.09992554038763046
Validation loss: 1.556147695869528

Epoch: 5| Step: 4
Training loss: 0.10468320548534393
Validation loss: 1.5768994105759488

Epoch: 5| Step: 5
Training loss: 0.16919878125190735
Validation loss: 1.5591392850363126

Epoch: 5| Step: 6
Training loss: 0.13832756876945496
Validation loss: 1.5406479925237677

Epoch: 5| Step: 7
Training loss: 0.09409832954406738
Validation loss: 1.5727203071758311

Epoch: 5| Step: 8
Training loss: 0.19271230697631836
Validation loss: 1.5347276477403538

Epoch: 5| Step: 9
Training loss: 0.15403661131858826
Validation loss: 1.5606045158960486

Epoch: 5| Step: 10
Training loss: 0.12244822084903717
Validation loss: 1.5386091803991666

Epoch: 461| Step: 0
Training loss: 0.10050714015960693
Validation loss: 1.561363963670628

Epoch: 5| Step: 1
Training loss: 0.09267202764749527
Validation loss: 1.571602108658001

Epoch: 5| Step: 2
Training loss: 0.2060270756483078
Validation loss: 1.575143083449333

Epoch: 5| Step: 3
Training loss: 0.08525524288415909
Validation loss: 1.5695108444459978

Epoch: 5| Step: 4
Training loss: 0.20743000507354736
Validation loss: 1.5717104968204294

Epoch: 5| Step: 5
Training loss: 0.136994868516922
Validation loss: 1.5780346329494188

Epoch: 5| Step: 6
Training loss: 0.24002330005168915
Validation loss: 1.5632088799630441

Epoch: 5| Step: 7
Training loss: 0.1261509656906128
Validation loss: 1.5606001038705148

Epoch: 5| Step: 8
Training loss: 0.15433084964752197
Validation loss: 1.5538810965835408

Epoch: 5| Step: 9
Training loss: 0.1293593794107437
Validation loss: 1.5614933890681113

Epoch: 5| Step: 10
Training loss: 0.11952276527881622
Validation loss: 1.5461215255081013

Epoch: 462| Step: 0
Training loss: 0.06794771552085876
Validation loss: 1.5476575871949554

Epoch: 5| Step: 1
Training loss: 0.05279774218797684
Validation loss: 1.5489856363624654

Epoch: 5| Step: 2
Training loss: 0.10352104902267456
Validation loss: 1.5512264133781515

Epoch: 5| Step: 3
Training loss: 0.061147917062044144
Validation loss: 1.562869538543045

Epoch: 5| Step: 4
Training loss: 0.12193816900253296
Validation loss: 1.5549215309081539

Epoch: 5| Step: 5
Training loss: 0.1298999786376953
Validation loss: 1.5676624915933097

Epoch: 5| Step: 6
Training loss: 0.13162535429000854
Validation loss: 1.5647520224253337

Epoch: 5| Step: 7
Training loss: 0.21817803382873535
Validation loss: 1.5691918198780348

Epoch: 5| Step: 8
Training loss: 0.19488704204559326
Validation loss: 1.559487565871208

Epoch: 5| Step: 9
Training loss: 0.15745803713798523
Validation loss: 1.5581034819285076

Epoch: 5| Step: 10
Training loss: 0.27220216393470764
Validation loss: 1.5706490880699568

Epoch: 463| Step: 0
Training loss: 0.1911233365535736
Validation loss: 1.540665675235051

Epoch: 5| Step: 1
Training loss: 0.06075292080640793
Validation loss: 1.567331915260643

Epoch: 5| Step: 2
Training loss: 0.10835918039083481
Validation loss: 1.5721916306403376

Epoch: 5| Step: 3
Training loss: 0.10023703426122665
Validation loss: 1.570774785933956

Epoch: 5| Step: 4
Training loss: 0.15047474205493927
Validation loss: 1.5667076597931564

Epoch: 5| Step: 5
Training loss: 0.15119969844818115
Validation loss: 1.574537402840071

Epoch: 5| Step: 6
Training loss: 0.14889156818389893
Validation loss: 1.573009701185329

Epoch: 5| Step: 7
Training loss: 0.07842367887496948
Validation loss: 1.542161395472865

Epoch: 5| Step: 8
Training loss: 0.09678228944540024
Validation loss: 1.539206604803762

Epoch: 5| Step: 9
Training loss: 0.156056210398674
Validation loss: 1.5756097814088226

Epoch: 5| Step: 10
Training loss: 0.19149565696716309
Validation loss: 1.551646941451616

Epoch: 464| Step: 0
Training loss: 0.11705589294433594
Validation loss: 1.5496700630393079

Epoch: 5| Step: 1
Training loss: 0.07641446590423584
Validation loss: 1.5498638729895315

Epoch: 5| Step: 2
Training loss: 0.09554243832826614
Validation loss: 1.5474835903413835

Epoch: 5| Step: 3
Training loss: 0.08408669382333755
Validation loss: 1.5457979363779868

Epoch: 5| Step: 4
Training loss: 0.3061949610710144
Validation loss: 1.5504285584213913

Epoch: 5| Step: 5
Training loss: 0.1479162871837616
Validation loss: 1.5614148263008363

Epoch: 5| Step: 6
Training loss: 0.10510706901550293
Validation loss: 1.5825814034349175

Epoch: 5| Step: 7
Training loss: 0.08717647939920425
Validation loss: 1.5737030839407316

Epoch: 5| Step: 8
Training loss: 0.1601884514093399
Validation loss: 1.5690968831380208

Epoch: 5| Step: 9
Training loss: 0.13791485130786896
Validation loss: 1.607684818647241

Epoch: 5| Step: 10
Training loss: 0.1390785574913025
Validation loss: 1.595153977794032

Epoch: 465| Step: 0
Training loss: 0.08916595578193665
Validation loss: 1.5660765106960008

Epoch: 5| Step: 1
Training loss: 0.17843936383724213
Validation loss: 1.5253582513460548

Epoch: 5| Step: 2
Training loss: 0.1859712451696396
Validation loss: 1.5447541731660084

Epoch: 5| Step: 3
Training loss: 0.13507835566997528
Validation loss: 1.54396451416836

Epoch: 5| Step: 4
Training loss: 0.19504162669181824
Validation loss: 1.5820492640618355

Epoch: 5| Step: 5
Training loss: 0.0958855003118515
Validation loss: 1.5774782514700325

Epoch: 5| Step: 6
Training loss: 0.15025636553764343
Validation loss: 1.5740680066488122

Epoch: 5| Step: 7
Training loss: 0.2214387208223343
Validation loss: 1.6081124018597346

Epoch: 5| Step: 8
Training loss: 0.1027199998497963
Validation loss: 1.5804069196024249

Epoch: 5| Step: 9
Training loss: 0.13981816172599792
Validation loss: 1.5759879030207151

Epoch: 5| Step: 10
Training loss: 0.1359597146511078
Validation loss: 1.5923536567277805

Epoch: 466| Step: 0
Training loss: 0.09658025205135345
Validation loss: 1.6068428741988314

Epoch: 5| Step: 1
Training loss: 0.13943037390708923
Validation loss: 1.639184960754969

Epoch: 5| Step: 2
Training loss: 0.21231956779956818
Validation loss: 1.6243955076381724

Epoch: 5| Step: 3
Training loss: 0.17315344512462616
Validation loss: 1.6598252134938394

Epoch: 5| Step: 4
Training loss: 0.16197314858436584
Validation loss: 1.6176657702333184

Epoch: 5| Step: 5
Training loss: 0.1485057771205902
Validation loss: 1.5956656394466278

Epoch: 5| Step: 6
Training loss: 0.09301286935806274
Validation loss: 1.5834492175809798

Epoch: 5| Step: 7
Training loss: 0.12431623786687851
Validation loss: 1.5698616530305596

Epoch: 5| Step: 8
Training loss: 0.19165098667144775
Validation loss: 1.553667632482385

Epoch: 5| Step: 9
Training loss: 0.167307049036026
Validation loss: 1.5441996564147293

Epoch: 5| Step: 10
Training loss: 0.11771319806575775
Validation loss: 1.5768951523688532

Epoch: 467| Step: 0
Training loss: 0.11211931705474854
Validation loss: 1.5587437857863724

Epoch: 5| Step: 1
Training loss: 0.1409941464662552
Validation loss: 1.5837997339105094

Epoch: 5| Step: 2
Training loss: 0.0921425148844719
Validation loss: 1.5452671358662267

Epoch: 5| Step: 3
Training loss: 0.1515546292066574
Validation loss: 1.5695080141867361

Epoch: 5| Step: 4
Training loss: 0.18036599457263947
Validation loss: 1.5809448008896203

Epoch: 5| Step: 5
Training loss: 0.22071561217308044
Validation loss: 1.600042095748327

Epoch: 5| Step: 6
Training loss: 0.15874914824962616
Validation loss: 1.6164073277545232

Epoch: 5| Step: 7
Training loss: 0.15106967091560364
Validation loss: 1.5804273672001337

Epoch: 5| Step: 8
Training loss: 0.1800156682729721
Validation loss: 1.58694387379513

Epoch: 5| Step: 9
Training loss: 0.13637812435626984
Validation loss: 1.5442405464828655

Epoch: 5| Step: 10
Training loss: 0.10471111536026001
Validation loss: 1.5595218802011142

Epoch: 468| Step: 0
Training loss: 0.12929394841194153
Validation loss: 1.5675552634782688

Epoch: 5| Step: 1
Training loss: 0.19353362917900085
Validation loss: 1.5664556244368195

Epoch: 5| Step: 2
Training loss: 0.14212064445018768
Validation loss: 1.5819008593918176

Epoch: 5| Step: 3
Training loss: 0.09039197117090225
Validation loss: 1.601977567518911

Epoch: 5| Step: 4
Training loss: 0.12465425580739975
Validation loss: 1.5646062948370492

Epoch: 5| Step: 5
Training loss: 0.1236342191696167
Validation loss: 1.6172035855631675

Epoch: 5| Step: 6
Training loss: 0.07954898476600647
Validation loss: 1.5918179173623361

Epoch: 5| Step: 7
Training loss: 0.0975019633769989
Validation loss: 1.6016928854809012

Epoch: 5| Step: 8
Training loss: 0.21450455486774445
Validation loss: 1.5905584840364353

Epoch: 5| Step: 9
Training loss: 0.15599150955677032
Validation loss: 1.5845660650601952

Epoch: 5| Step: 10
Training loss: 0.1068357452750206
Validation loss: 1.5764200302862352

Epoch: 469| Step: 0
Training loss: 0.21535281836986542
Validation loss: 1.591102377060921

Epoch: 5| Step: 1
Training loss: 0.0951770693063736
Validation loss: 1.561406361159458

Epoch: 5| Step: 2
Training loss: 0.19496560096740723
Validation loss: 1.6026781541044994

Epoch: 5| Step: 3
Training loss: 0.1132424920797348
Validation loss: 1.625420170445596

Epoch: 5| Step: 4
Training loss: 0.12041399627923965
Validation loss: 1.61760454024038

Epoch: 5| Step: 5
Training loss: 0.15456101298332214
Validation loss: 1.5885878429617932

Epoch: 5| Step: 6
Training loss: 0.12186839431524277
Validation loss: 1.5999005494579193

Epoch: 5| Step: 7
Training loss: 0.139743834733963
Validation loss: 1.5984066404322141

Epoch: 5| Step: 8
Training loss: 0.0999625101685524
Validation loss: 1.6002301939072148

Epoch: 5| Step: 9
Training loss: 0.13967113196849823
Validation loss: 1.6052975834056895

Epoch: 5| Step: 10
Training loss: 0.11767347902059555
Validation loss: 1.5812272814012343

Epoch: 470| Step: 0
Training loss: 0.10734827816486359
Validation loss: 1.5662831093675347

Epoch: 5| Step: 1
Training loss: 0.09716302156448364
Validation loss: 1.5778542898034538

Epoch: 5| Step: 2
Training loss: 0.21405920386314392
Validation loss: 1.5851266948125695

Epoch: 5| Step: 3
Training loss: 0.1433144360780716
Validation loss: 1.5735568000424294

Epoch: 5| Step: 4
Training loss: 0.1267712116241455
Validation loss: 1.5610566395585255

Epoch: 5| Step: 5
Training loss: 0.1535308063030243
Validation loss: 1.5585533752236316

Epoch: 5| Step: 6
Training loss: 0.10843352973461151
Validation loss: 1.5713950126401839

Epoch: 5| Step: 7
Training loss: 0.17821571230888367
Validation loss: 1.5406077536203528

Epoch: 5| Step: 8
Training loss: 0.09335583448410034
Validation loss: 1.535104456768241

Epoch: 5| Step: 9
Training loss: 0.11285295337438583
Validation loss: 1.5386261593910955

Epoch: 5| Step: 10
Training loss: 0.07608860731124878
Validation loss: 1.527068026604191

Epoch: 471| Step: 0
Training loss: 0.1054808646440506
Validation loss: 1.5493969596842283

Epoch: 5| Step: 1
Training loss: 0.15528801083564758
Validation loss: 1.5646257054421209

Epoch: 5| Step: 2
Training loss: 0.11192338168621063
Validation loss: 1.5890824974224131

Epoch: 5| Step: 3
Training loss: 0.1990930289030075
Validation loss: 1.5838481239093247

Epoch: 5| Step: 4
Training loss: 0.1642569601535797
Validation loss: 1.5875156194933

Epoch: 5| Step: 5
Training loss: 0.1099015474319458
Validation loss: 1.5554553321612778

Epoch: 5| Step: 6
Training loss: 0.10503890365362167
Validation loss: 1.5534830631748322

Epoch: 5| Step: 7
Training loss: 0.14129284024238586
Validation loss: 1.5352013111114502

Epoch: 5| Step: 8
Training loss: 0.22831428050994873
Validation loss: 1.5387791382369174

Epoch: 5| Step: 9
Training loss: 0.1282634139060974
Validation loss: 1.5315853741861158

Epoch: 5| Step: 10
Training loss: 0.07050959020853043
Validation loss: 1.5515309226128362

Epoch: 472| Step: 0
Training loss: 0.12268848717212677
Validation loss: 1.5345190750655306

Epoch: 5| Step: 1
Training loss: 0.07939107716083527
Validation loss: 1.563180224869841

Epoch: 5| Step: 2
Training loss: 0.06563904881477356
Validation loss: 1.5748390997609785

Epoch: 5| Step: 3
Training loss: 0.12190146744251251
Validation loss: 1.5838725464318388

Epoch: 5| Step: 4
Training loss: 0.11662093549966812
Validation loss: 1.5861639335591307

Epoch: 5| Step: 5
Training loss: 0.10848865658044815
Validation loss: 1.5972385227039296

Epoch: 5| Step: 6
Training loss: 0.16051140427589417
Validation loss: 1.5663444508788407

Epoch: 5| Step: 7
Training loss: 0.17405861616134644
Validation loss: 1.5593942083338255

Epoch: 5| Step: 8
Training loss: 0.18155601620674133
Validation loss: 1.5426025544443438

Epoch: 5| Step: 9
Training loss: 0.1699906289577484
Validation loss: 1.5399975225489626

Epoch: 5| Step: 10
Training loss: 0.14841966331005096
Validation loss: 1.5150661417233047

Epoch: 473| Step: 0
Training loss: 0.10958752781152725
Validation loss: 1.5331344642946798

Epoch: 5| Step: 1
Training loss: 0.13017451763153076
Validation loss: 1.532729765420319

Epoch: 5| Step: 2
Training loss: 0.09922029078006744
Validation loss: 1.551413542480879

Epoch: 5| Step: 3
Training loss: 0.1174871101975441
Validation loss: 1.540533254223485

Epoch: 5| Step: 4
Training loss: 0.125227689743042
Validation loss: 1.5696163997855237

Epoch: 5| Step: 5
Training loss: 0.2315916121006012
Validation loss: 1.5808850052536174

Epoch: 5| Step: 6
Training loss: 0.12098344415426254
Validation loss: 1.5850676144323042

Epoch: 5| Step: 7
Training loss: 0.1597403883934021
Validation loss: 1.5794292137187014

Epoch: 5| Step: 8
Training loss: 0.15827429294586182
Validation loss: 1.5774056949923116

Epoch: 5| Step: 9
Training loss: 0.1170722097158432
Validation loss: 1.5739613066437423

Epoch: 5| Step: 10
Training loss: 0.18702314794063568
Validation loss: 1.5438330404220089

Epoch: 474| Step: 0
Training loss: 0.10350539535284042
Validation loss: 1.5704140099146033

Epoch: 5| Step: 1
Training loss: 0.13470929861068726
Validation loss: 1.5975625284256474

Epoch: 5| Step: 2
Training loss: 0.13448505103588104
Validation loss: 1.5733668752895889

Epoch: 5| Step: 3
Training loss: 0.235378235578537
Validation loss: 1.5734985489999094

Epoch: 5| Step: 4
Training loss: 0.13445945084095
Validation loss: 1.5849835949559365

Epoch: 5| Step: 5
Training loss: 0.14625602960586548
Validation loss: 1.5569658112782303

Epoch: 5| Step: 6
Training loss: 0.1911410391330719
Validation loss: 1.5023298237913398

Epoch: 5| Step: 7
Training loss: 0.10685708373785019
Validation loss: 1.4970801447027473

Epoch: 5| Step: 8
Training loss: 0.1924734115600586
Validation loss: 1.5113168403666506

Epoch: 5| Step: 9
Training loss: 0.09823919832706451
Validation loss: 1.5115630254950574

Epoch: 5| Step: 10
Training loss: 0.11421147733926773
Validation loss: 1.5462139293711672

Epoch: 475| Step: 0
Training loss: 0.09165345132350922
Validation loss: 1.5672114972145326

Epoch: 5| Step: 1
Training loss: 0.21983428299427032
Validation loss: 1.5832028235158613

Epoch: 5| Step: 2
Training loss: 0.1253720223903656
Validation loss: 1.588585158830048

Epoch: 5| Step: 3
Training loss: 0.1046326756477356
Validation loss: 1.5809423910674227

Epoch: 5| Step: 4
Training loss: 0.0820486843585968
Validation loss: 1.5980565214669833

Epoch: 5| Step: 5
Training loss: 0.10478685051202774
Validation loss: 1.5827253954384917

Epoch: 5| Step: 6
Training loss: 0.19257338345050812
Validation loss: 1.5793046400111208

Epoch: 5| Step: 7
Training loss: 0.09551369398832321
Validation loss: 1.5692291413584063

Epoch: 5| Step: 8
Training loss: 0.20558524131774902
Validation loss: 1.5683145779435352

Epoch: 5| Step: 9
Training loss: 0.14588330686092377
Validation loss: 1.5815822373154342

Epoch: 5| Step: 10
Training loss: 0.12720473110675812
Validation loss: 1.5603562349914222

Epoch: 476| Step: 0
Training loss: 0.13606059551239014
Validation loss: 1.5850976039004583

Epoch: 5| Step: 1
Training loss: 0.18440254032611847
Validation loss: 1.5819756113072878

Epoch: 5| Step: 2
Training loss: 0.11993911117315292
Validation loss: 1.622949520746867

Epoch: 5| Step: 3
Training loss: 0.1040971502661705
Validation loss: 1.6143781638914538

Epoch: 5| Step: 4
Training loss: 0.09555736184120178
Validation loss: 1.6109083211550148

Epoch: 5| Step: 5
Training loss: 0.09155987948179245
Validation loss: 1.6108492253929056

Epoch: 5| Step: 6
Training loss: 0.09326484054327011
Validation loss: 1.5831767897452078

Epoch: 5| Step: 7
Training loss: 0.165615051984787
Validation loss: 1.6013765655538088

Epoch: 5| Step: 8
Training loss: 0.115909144282341
Validation loss: 1.5663038005111038

Epoch: 5| Step: 9
Training loss: 0.10442845523357391
Validation loss: 1.5792515585499425

Epoch: 5| Step: 10
Training loss: 0.17127300798892975
Validation loss: 1.551560542916739

Epoch: 477| Step: 0
Training loss: 0.07931281626224518
Validation loss: 1.5545876743972942

Epoch: 5| Step: 1
Training loss: 0.14794670045375824
Validation loss: 1.564535398637095

Epoch: 5| Step: 2
Training loss: 0.16068650782108307
Validation loss: 1.5499535734935472

Epoch: 5| Step: 3
Training loss: 0.12779243290424347
Validation loss: 1.5536505483811902

Epoch: 5| Step: 4
Training loss: 0.06880520284175873
Validation loss: 1.5395276059386551

Epoch: 5| Step: 5
Training loss: 0.09827753901481628
Validation loss: 1.5657949204085975

Epoch: 5| Step: 6
Training loss: 0.14122164249420166
Validation loss: 1.558434199261409

Epoch: 5| Step: 7
Training loss: 0.10372881591320038
Validation loss: 1.548533046117393

Epoch: 5| Step: 8
Training loss: 0.08880352228879929
Validation loss: 1.5656597422015281

Epoch: 5| Step: 9
Training loss: 0.14229972660541534
Validation loss: 1.5840665871097195

Epoch: 5| Step: 10
Training loss: 0.17283938825130463
Validation loss: 1.581532113013729

Epoch: 478| Step: 0
Training loss: 0.0963268131017685
Validation loss: 1.5432181409610215

Epoch: 5| Step: 1
Training loss: 0.06233569234609604
Validation loss: 1.556396270311007

Epoch: 5| Step: 2
Training loss: 0.08580293506383896
Validation loss: 1.5389643894728793

Epoch: 5| Step: 3
Training loss: 0.06725913286209106
Validation loss: 1.5500523492854128

Epoch: 5| Step: 4
Training loss: 0.11433053016662598
Validation loss: 1.5488561020102551

Epoch: 5| Step: 5
Training loss: 0.21705341339111328
Validation loss: 1.5820107511294785

Epoch: 5| Step: 6
Training loss: 0.11664341390132904
Validation loss: 1.5626846962077643

Epoch: 5| Step: 7
Training loss: 0.12400643527507782
Validation loss: 1.5654465844554286

Epoch: 5| Step: 8
Training loss: 0.1903342455625534
Validation loss: 1.5553019033965243

Epoch: 5| Step: 9
Training loss: 0.10974309593439102
Validation loss: 1.532384431490334

Epoch: 5| Step: 10
Training loss: 0.16198641061782837
Validation loss: 1.5228276547565256

Epoch: 479| Step: 0
Training loss: 0.18118983507156372
Validation loss: 1.5342079791971432

Epoch: 5| Step: 1
Training loss: 0.1132357120513916
Validation loss: 1.5411987567460665

Epoch: 5| Step: 2
Training loss: 0.11862654983997345
Validation loss: 1.5397298502665695

Epoch: 5| Step: 3
Training loss: 0.098680779337883
Validation loss: 1.5762962269526657

Epoch: 5| Step: 4
Training loss: 0.10353755950927734
Validation loss: 1.55639055467421

Epoch: 5| Step: 5
Training loss: 0.08260522037744522
Validation loss: 1.5557589377126386

Epoch: 5| Step: 6
Training loss: 0.09567489475011826
Validation loss: 1.5461918884708035

Epoch: 5| Step: 7
Training loss: 0.0787457600235939
Validation loss: 1.5700201065309587

Epoch: 5| Step: 8
Training loss: 0.1969691962003708
Validation loss: 1.5816511748939432

Epoch: 5| Step: 9
Training loss: 0.0891638919711113
Validation loss: 1.5722707112630208

Epoch: 5| Step: 10
Training loss: 0.15290462970733643
Validation loss: 1.550266024886921

Epoch: 480| Step: 0
Training loss: 0.10038970410823822
Validation loss: 1.5724359455929007

Epoch: 5| Step: 1
Training loss: 0.122747041285038
Validation loss: 1.5571409451064242

Epoch: 5| Step: 2
Training loss: 0.23470202088356018
Validation loss: 1.588184784176529

Epoch: 5| Step: 3
Training loss: 0.18319165706634521
Validation loss: 1.5794376557873142

Epoch: 5| Step: 4
Training loss: 0.12162928283214569
Validation loss: 1.579833105046262

Epoch: 5| Step: 5
Training loss: 0.10670135915279388
Validation loss: 1.57509571185676

Epoch: 5| Step: 6
Training loss: 0.1064525842666626
Validation loss: 1.5469556752071585

Epoch: 5| Step: 7
Training loss: 0.1347343623638153
Validation loss: 1.5441155459291191

Epoch: 5| Step: 8
Training loss: 0.04139648377895355
Validation loss: 1.5547789873615387

Epoch: 5| Step: 9
Training loss: 0.15158803761005402
Validation loss: 1.55524665950447

Epoch: 5| Step: 10
Training loss: 0.07928303629159927
Validation loss: 1.5780112986923547

Epoch: 481| Step: 0
Training loss: 0.15812139213085175
Validation loss: 1.5728348929394957

Epoch: 5| Step: 1
Training loss: 0.13637061417102814
Validation loss: 1.557146854298089

Epoch: 5| Step: 2
Training loss: 0.10788266360759735
Validation loss: 1.54942141297043

Epoch: 5| Step: 3
Training loss: 0.18520227074623108
Validation loss: 1.5366601072331911

Epoch: 5| Step: 4
Training loss: 0.08561527729034424
Validation loss: 1.5457523022928545

Epoch: 5| Step: 5
Training loss: 0.06861691176891327
Validation loss: 1.5284304118925525

Epoch: 5| Step: 6
Training loss: 0.12034308910369873
Validation loss: 1.5126957547280095

Epoch: 5| Step: 7
Training loss: 0.09151547402143478
Validation loss: 1.5333752016867361

Epoch: 5| Step: 8
Training loss: 0.2616282105445862
Validation loss: 1.5242116041080926

Epoch: 5| Step: 9
Training loss: 0.08207002282142639
Validation loss: 1.5659095394995906

Epoch: 5| Step: 10
Training loss: 0.12733377516269684
Validation loss: 1.554803067638028

Epoch: 482| Step: 0
Training loss: 0.16162380576133728
Validation loss: 1.5466578243881144

Epoch: 5| Step: 1
Training loss: 0.09500329196453094
Validation loss: 1.5840834879106092

Epoch: 5| Step: 2
Training loss: 0.08837619423866272
Validation loss: 1.5499911500561623

Epoch: 5| Step: 3
Training loss: 0.17668960988521576
Validation loss: 1.5789064566294353

Epoch: 5| Step: 4
Training loss: 0.12663188576698303
Validation loss: 1.5421055209252141

Epoch: 5| Step: 5
Training loss: 0.09004877507686615
Validation loss: 1.556567129268441

Epoch: 5| Step: 6
Training loss: 0.09058664739131927
Validation loss: 1.530756292804595

Epoch: 5| Step: 7
Training loss: 0.18558061122894287
Validation loss: 1.5367995615928405

Epoch: 5| Step: 8
Training loss: 0.06912003457546234
Validation loss: 1.5491040560507006

Epoch: 5| Step: 9
Training loss: 0.05536212772130966
Validation loss: 1.5496899415087957

Epoch: 5| Step: 10
Training loss: 0.10260751098394394
Validation loss: 1.530597423353503

Epoch: 483| Step: 0
Training loss: 0.12079624086618423
Validation loss: 1.5383765607751825

Epoch: 5| Step: 1
Training loss: 0.12517063319683075
Validation loss: 1.5466407896370016

Epoch: 5| Step: 2
Training loss: 0.11781992763280869
Validation loss: 1.5334567792953984

Epoch: 5| Step: 3
Training loss: 0.1626558005809784
Validation loss: 1.5225032914069392

Epoch: 5| Step: 4
Training loss: 0.15208421647548676
Validation loss: 1.5297704140345256

Epoch: 5| Step: 5
Training loss: 0.04505111277103424
Validation loss: 1.5209537706067484

Epoch: 5| Step: 6
Training loss: 0.08374176174402237
Validation loss: 1.5088110136729416

Epoch: 5| Step: 7
Training loss: 0.08609198033809662
Validation loss: 1.5066170871898692

Epoch: 5| Step: 8
Training loss: 0.13573753833770752
Validation loss: 1.5140564480135519

Epoch: 5| Step: 9
Training loss: 0.17804190516471863
Validation loss: 1.5159269802031978

Epoch: 5| Step: 10
Training loss: 0.09146863967180252
Validation loss: 1.552499435281241

Epoch: 484| Step: 0
Training loss: 0.0888662114739418
Validation loss: 1.5306348211021834

Epoch: 5| Step: 1
Training loss: 0.1537080556154251
Validation loss: 1.532612080215126

Epoch: 5| Step: 2
Training loss: 0.14493778347969055
Validation loss: 1.5663963453744048

Epoch: 5| Step: 3
Training loss: 0.11881349235773087
Validation loss: 1.5599257753741356

Epoch: 5| Step: 4
Training loss: 0.07920589298009872
Validation loss: 1.588352055959804

Epoch: 5| Step: 5
Training loss: 0.1537056863307953
Validation loss: 1.5298357214978946

Epoch: 5| Step: 6
Training loss: 0.07360033690929413
Validation loss: 1.5336873095522645

Epoch: 5| Step: 7
Training loss: 0.08300606906414032
Validation loss: 1.55304769931301

Epoch: 5| Step: 8
Training loss: 0.1071697250008583
Validation loss: 1.5200388957095403

Epoch: 5| Step: 9
Training loss: 0.11219128221273422
Validation loss: 1.5466442543973205

Epoch: 5| Step: 10
Training loss: 0.06933125108480453
Validation loss: 1.5448004084248697

Epoch: 485| Step: 0
Training loss: 0.09160113334655762
Validation loss: 1.5575498727060133

Epoch: 5| Step: 1
Training loss: 0.08958875387907028
Validation loss: 1.5634139160956106

Epoch: 5| Step: 2
Training loss: 0.1036878377199173
Validation loss: 1.5882745468488304

Epoch: 5| Step: 3
Training loss: 0.16092823445796967
Validation loss: 1.5969980596214213

Epoch: 5| Step: 4
Training loss: 0.15911325812339783
Validation loss: 1.567587629441292

Epoch: 5| Step: 5
Training loss: 0.10969562828540802
Validation loss: 1.5597606371807795

Epoch: 5| Step: 6
Training loss: 0.11329929530620575
Validation loss: 1.5537796097417031

Epoch: 5| Step: 7
Training loss: 0.12998345494270325
Validation loss: 1.5361951358856694

Epoch: 5| Step: 8
Training loss: 0.13352808356285095
Validation loss: 1.5236711053438083

Epoch: 5| Step: 9
Training loss: 0.20447643101215363
Validation loss: 1.5504476434441024

Epoch: 5| Step: 10
Training loss: 0.12085548788309097
Validation loss: 1.5334774986390145

Epoch: 486| Step: 0
Training loss: 0.06757643818855286
Validation loss: 1.5697639808859876

Epoch: 5| Step: 1
Training loss: 0.12152149528265
Validation loss: 1.5583396547584123

Epoch: 5| Step: 2
Training loss: 0.09814729541540146
Validation loss: 1.5577695959357805

Epoch: 5| Step: 3
Training loss: 0.168196439743042
Validation loss: 1.5754806341663483

Epoch: 5| Step: 4
Training loss: 0.14053209125995636
Validation loss: 1.5806469199477986

Epoch: 5| Step: 5
Training loss: 0.08268493413925171
Validation loss: 1.589719598011304

Epoch: 5| Step: 6
Training loss: 0.17587034404277802
Validation loss: 1.5926736259973178

Epoch: 5| Step: 7
Training loss: 0.16428405046463013
Validation loss: 1.583078452335891

Epoch: 5| Step: 8
Training loss: 0.07613535225391388
Validation loss: 1.5771761684007541

Epoch: 5| Step: 9
Training loss: 0.08114518970251083
Validation loss: 1.5562364285992039

Epoch: 5| Step: 10
Training loss: 0.0805312991142273
Validation loss: 1.5516489193003664

Epoch: 487| Step: 0
Training loss: 0.06475846469402313
Validation loss: 1.5438631965268044

Epoch: 5| Step: 1
Training loss: 0.07072208821773529
Validation loss: 1.545613763152912

Epoch: 5| Step: 2
Training loss: 0.07386675477027893
Validation loss: 1.5408644176298572

Epoch: 5| Step: 3
Training loss: 0.08397667109966278
Validation loss: 1.5550752980734712

Epoch: 5| Step: 4
Training loss: 0.18156345188617706
Validation loss: 1.5387039838298675

Epoch: 5| Step: 5
Training loss: 0.09345812350511551
Validation loss: 1.5412835292918707

Epoch: 5| Step: 6
Training loss: 0.30847153067588806
Validation loss: 1.5525241615951701

Epoch: 5| Step: 7
Training loss: 0.12405355274677277
Validation loss: 1.5502204023381716

Epoch: 5| Step: 8
Training loss: 0.04664216563105583
Validation loss: 1.5380179459048855

Epoch: 5| Step: 9
Training loss: 0.0905524343252182
Validation loss: 1.5694721937179565

Epoch: 5| Step: 10
Training loss: 0.0918654128909111
Validation loss: 1.5277639114728538

Epoch: 488| Step: 0
Training loss: 0.1859693080186844
Validation loss: 1.5579639404050765

Epoch: 5| Step: 1
Training loss: 0.09318431466817856
Validation loss: 1.5372058999153875

Epoch: 5| Step: 2
Training loss: 0.08478006720542908
Validation loss: 1.5441495526221491

Epoch: 5| Step: 3
Training loss: 0.18914851546287537
Validation loss: 1.5168398490516088

Epoch: 5| Step: 4
Training loss: 0.11166325956583023
Validation loss: 1.49968026145812

Epoch: 5| Step: 5
Training loss: 0.08581192046403885
Validation loss: 1.5144510602438321

Epoch: 5| Step: 6
Training loss: 0.1620970368385315
Validation loss: 1.5228751526083997

Epoch: 5| Step: 7
Training loss: 0.07472443580627441
Validation loss: 1.5318126819467033

Epoch: 5| Step: 8
Training loss: 0.08346141874790192
Validation loss: 1.5201357244163431

Epoch: 5| Step: 9
Training loss: 0.11777429282665253
Validation loss: 1.5573472310138006

Epoch: 5| Step: 10
Training loss: 0.07878533750772476
Validation loss: 1.547034482802114

Epoch: 489| Step: 0
Training loss: 0.17729665338993073
Validation loss: 1.5329360577367968

Epoch: 5| Step: 1
Training loss: 0.11817292869091034
Validation loss: 1.5699831952330887

Epoch: 5| Step: 2
Training loss: 0.12497587502002716
Validation loss: 1.577773206977434

Epoch: 5| Step: 3
Training loss: 0.1016242504119873
Validation loss: 1.5876936245990056

Epoch: 5| Step: 4
Training loss: 0.14743979275226593
Validation loss: 1.5835660273028958

Epoch: 5| Step: 5
Training loss: 0.0863485112786293
Validation loss: 1.5731586974154237

Epoch: 5| Step: 6
Training loss: 0.061525993049144745
Validation loss: 1.5528902379415368

Epoch: 5| Step: 7
Training loss: 0.08783523738384247
Validation loss: 1.5229793569093109

Epoch: 5| Step: 8
Training loss: 0.18371157348155975
Validation loss: 1.514039974058828

Epoch: 5| Step: 9
Training loss: 0.08745080977678299
Validation loss: 1.5111590572582778

Epoch: 5| Step: 10
Training loss: 0.18008078634738922
Validation loss: 1.5309078219116374

Epoch: 490| Step: 0
Training loss: 0.16115319728851318
Validation loss: 1.5371354420979817

Epoch: 5| Step: 1
Training loss: 0.08658887445926666
Validation loss: 1.5660839926811956

Epoch: 5| Step: 2
Training loss: 0.1642821729183197
Validation loss: 1.5674020551866101

Epoch: 5| Step: 3
Training loss: 0.12366533279418945
Validation loss: 1.5799927057758454

Epoch: 5| Step: 4
Training loss: 0.06678944081068039
Validation loss: 1.582984907652742

Epoch: 5| Step: 5
Training loss: 0.19302430748939514
Validation loss: 1.598953188106578

Epoch: 5| Step: 6
Training loss: 0.10557039082050323
Validation loss: 1.5563339494889783

Epoch: 5| Step: 7
Training loss: 0.159091979265213
Validation loss: 1.5837206994333575

Epoch: 5| Step: 8
Training loss: 0.08390796184539795
Validation loss: 1.5388099685792

Epoch: 5| Step: 9
Training loss: 0.08997806161642075
Validation loss: 1.5679072853057616

Epoch: 5| Step: 10
Training loss: 0.058521874248981476
Validation loss: 1.5631309619513891

Epoch: 491| Step: 0
Training loss: 0.19837918877601624
Validation loss: 1.5584530074109313

Epoch: 5| Step: 1
Training loss: 0.09360603988170624
Validation loss: 1.5525607223151832

Epoch: 5| Step: 2
Training loss: 0.14614780247211456
Validation loss: 1.589382472858634

Epoch: 5| Step: 3
Training loss: 0.11462579667568207
Validation loss: 1.5811166032668083

Epoch: 5| Step: 4
Training loss: 0.07345355302095413
Validation loss: 1.5836264651308778

Epoch: 5| Step: 5
Training loss: 0.06357710063457489
Validation loss: 1.5672446207333637

Epoch: 5| Step: 6
Training loss: 0.06332425773143768
Validation loss: 1.5485900589214858

Epoch: 5| Step: 7
Training loss: 0.13576282560825348
Validation loss: 1.5529210208564677

Epoch: 5| Step: 8
Training loss: 0.0933464914560318
Validation loss: 1.5561020053843015

Epoch: 5| Step: 9
Training loss: 0.1129688024520874
Validation loss: 1.520014948742364

Epoch: 5| Step: 10
Training loss: 0.15700998902320862
Validation loss: 1.5286317704826273

Epoch: 492| Step: 0
Training loss: 0.14634032547473907
Validation loss: 1.5438089729637228

Epoch: 5| Step: 1
Training loss: 0.2050199955701828
Validation loss: 1.5297525505865774

Epoch: 5| Step: 2
Training loss: 0.07965085655450821
Validation loss: 1.565214467305009

Epoch: 5| Step: 3
Training loss: 0.10107360035181046
Validation loss: 1.5847333195388957

Epoch: 5| Step: 4
Training loss: 0.0960603803396225
Validation loss: 1.5758729775746663

Epoch: 5| Step: 5
Training loss: 0.17793801426887512
Validation loss: 1.5880319520991335

Epoch: 5| Step: 6
Training loss: 0.07828231900930405
Validation loss: 1.5824970635034705

Epoch: 5| Step: 7
Training loss: 0.1304789036512375
Validation loss: 1.5633042461128646

Epoch: 5| Step: 8
Training loss: 0.14043250679969788
Validation loss: 1.5434237334036058

Epoch: 5| Step: 9
Training loss: 0.10362765938043594
Validation loss: 1.5256345938610774

Epoch: 5| Step: 10
Training loss: 0.07052642107009888
Validation loss: 1.5526355992081344

Epoch: 493| Step: 0
Training loss: 0.08140164613723755
Validation loss: 1.5586961443706224

Epoch: 5| Step: 1
Training loss: 0.13487020134925842
Validation loss: 1.565587171944239

Epoch: 5| Step: 2
Training loss: 0.1558607518672943
Validation loss: 1.5809224049250286

Epoch: 5| Step: 3
Training loss: 0.11818782240152359
Validation loss: 1.573957436828203

Epoch: 5| Step: 4
Training loss: 0.1713503897190094
Validation loss: 1.5699852756274644

Epoch: 5| Step: 5
Training loss: 0.12159468978643417
Validation loss: 1.5587827710695163

Epoch: 5| Step: 6
Training loss: 0.15500545501708984
Validation loss: 1.6071432162356634

Epoch: 5| Step: 7
Training loss: 0.18300195038318634
Validation loss: 1.5962486087635

Epoch: 5| Step: 8
Training loss: 0.292707622051239
Validation loss: 1.6244434771999237

Epoch: 5| Step: 9
Training loss: 0.1159883588552475
Validation loss: 1.589295179613175

Epoch: 5| Step: 10
Training loss: 0.16615018248558044
Validation loss: 1.5416519141966296

Epoch: 494| Step: 0
Training loss: 0.218724325299263
Validation loss: 1.5354243529740201

Epoch: 5| Step: 1
Training loss: 0.148477241396904
Validation loss: 1.50830227392976

Epoch: 5| Step: 2
Training loss: 0.21162617206573486
Validation loss: 1.5101217416024977

Epoch: 5| Step: 3
Training loss: 0.1435067355632782
Validation loss: 1.5222733264328332

Epoch: 5| Step: 4
Training loss: 0.12087662518024445
Validation loss: 1.517061020738335

Epoch: 5| Step: 5
Training loss: 0.19393320381641388
Validation loss: 1.5346732959952405

Epoch: 5| Step: 6
Training loss: 0.157747283577919
Validation loss: 1.5672424377933625

Epoch: 5| Step: 7
Training loss: 0.14230139553546906
Validation loss: 1.6002663168855893

Epoch: 5| Step: 8
Training loss: 0.11000548303127289
Validation loss: 1.5985166859883133

Epoch: 5| Step: 9
Training loss: 0.11359366029500961
Validation loss: 1.6525331799701979

Epoch: 5| Step: 10
Training loss: 0.203505277633667
Validation loss: 1.6455079394002115

Epoch: 495| Step: 0
Training loss: 0.19265760481357574
Validation loss: 1.6369503877496208

Epoch: 5| Step: 1
Training loss: 0.16127026081085205
Validation loss: 1.621958517259167

Epoch: 5| Step: 2
Training loss: 0.10588916391134262
Validation loss: 1.557792095727818

Epoch: 5| Step: 3
Training loss: 0.08343680202960968
Validation loss: 1.579287899437771

Epoch: 5| Step: 4
Training loss: 0.20389814674854279
Validation loss: 1.5750832865315099

Epoch: 5| Step: 5
Training loss: 0.10973743349313736
Validation loss: 1.5586163433649207

Epoch: 5| Step: 6
Training loss: 0.09147508442401886
Validation loss: 1.5216411159884544

Epoch: 5| Step: 7
Training loss: 0.12026248872280121
Validation loss: 1.5536477706765617

Epoch: 5| Step: 8
Training loss: 0.1263565570116043
Validation loss: 1.5509265174147904

Epoch: 5| Step: 9
Training loss: 0.08400563895702362
Validation loss: 1.5417842659898984

Epoch: 5| Step: 10
Training loss: 0.10870347172021866
Validation loss: 1.5617938849233812

Epoch: 496| Step: 0
Training loss: 0.07364635169506073
Validation loss: 1.559354098894263

Epoch: 5| Step: 1
Training loss: 0.12328877300024033
Validation loss: 1.5467039872241277

Epoch: 5| Step: 2
Training loss: 0.14688709378242493
Validation loss: 1.543426787981423

Epoch: 5| Step: 3
Training loss: 0.10940380394458771
Validation loss: 1.5566704785952004

Epoch: 5| Step: 4
Training loss: 0.14325416088104248
Validation loss: 1.5396884884885562

Epoch: 5| Step: 5
Training loss: 0.09318682551383972
Validation loss: 1.5562684728253273

Epoch: 5| Step: 6
Training loss: 0.09670186787843704
Validation loss: 1.5698746660704255

Epoch: 5| Step: 7
Training loss: 0.2203955203294754
Validation loss: 1.5450772521316365

Epoch: 5| Step: 8
Training loss: 0.07031078636646271
Validation loss: 1.5375774560436126

Epoch: 5| Step: 9
Training loss: 0.1103455051779747
Validation loss: 1.519532108819613

Epoch: 5| Step: 10
Training loss: 0.09489089995622635
Validation loss: 1.4970006667157656

Epoch: 497| Step: 0
Training loss: 0.07031193375587463
Validation loss: 1.5371102812469646

Epoch: 5| Step: 1
Training loss: 0.25545620918273926
Validation loss: 1.5376652043352845

Epoch: 5| Step: 2
Training loss: 0.06346619129180908
Validation loss: 1.5038199732380528

Epoch: 5| Step: 3
Training loss: 0.07648931443691254
Validation loss: 1.540808367472823

Epoch: 5| Step: 4
Training loss: 0.0936107337474823
Validation loss: 1.5232042407476774

Epoch: 5| Step: 5
Training loss: 0.06569372862577438
Validation loss: 1.547571523215181

Epoch: 5| Step: 6
Training loss: 0.07782940566539764
Validation loss: 1.5321194920488583

Epoch: 5| Step: 7
Training loss: 0.06988339126110077
Validation loss: 1.5517185195799796

Epoch: 5| Step: 8
Training loss: 0.08133117109537125
Validation loss: 1.5383949971968127

Epoch: 5| Step: 9
Training loss: 0.11453509330749512
Validation loss: 1.5235779823795441

Epoch: 5| Step: 10
Training loss: 0.16529588401317596
Validation loss: 1.5108502936619583

Epoch: 498| Step: 0
Training loss: 0.1732354760169983
Validation loss: 1.512053774249169

Epoch: 5| Step: 1
Training loss: 0.09128756076097488
Validation loss: 1.5032910864840272

Epoch: 5| Step: 2
Training loss: 0.07760436832904816
Validation loss: 1.506567306416009

Epoch: 5| Step: 3
Training loss: 0.06651900708675385
Validation loss: 1.548861631783106

Epoch: 5| Step: 4
Training loss: 0.056696366518735886
Validation loss: 1.5214961241650324

Epoch: 5| Step: 5
Training loss: 0.18428537249565125
Validation loss: 1.527667103275176

Epoch: 5| Step: 6
Training loss: 0.09225496649742126
Validation loss: 1.516746065949881

Epoch: 5| Step: 7
Training loss: 0.06795652955770493
Validation loss: 1.5332553681506906

Epoch: 5| Step: 8
Training loss: 0.09354878962039948
Validation loss: 1.5522010531476749

Epoch: 5| Step: 9
Training loss: 0.13201655447483063
Validation loss: 1.5602967123831473

Epoch: 5| Step: 10
Training loss: 0.18205633759498596
Validation loss: 1.5632804170731576

Epoch: 499| Step: 0
Training loss: 0.11911842972040176
Validation loss: 1.5696223781954857

Epoch: 5| Step: 1
Training loss: 0.10067617893218994
Validation loss: 1.574445697569078

Epoch: 5| Step: 2
Training loss: 0.08683185279369354
Validation loss: 1.5525975855447913

Epoch: 5| Step: 3
Training loss: 0.2284344881772995
Validation loss: 1.52796422666119

Epoch: 5| Step: 4
Training loss: 0.11670452356338501
Validation loss: 1.5604760634001864

Epoch: 5| Step: 5
Training loss: 0.12431130558252335
Validation loss: 1.5272806357311945

Epoch: 5| Step: 6
Training loss: 0.10850676149129868
Validation loss: 1.5143697710447415

Epoch: 5| Step: 7
Training loss: 0.1494801640510559
Validation loss: 1.5006234492025068

Epoch: 5| Step: 8
Training loss: 0.09148697555065155
Validation loss: 1.4999780565179803

Epoch: 5| Step: 9
Training loss: 0.11980687081813812
Validation loss: 1.5097557319107877

Epoch: 5| Step: 10
Training loss: 0.07859109342098236
Validation loss: 1.5412600098117706

Epoch: 500| Step: 0
Training loss: 0.08974860608577728
Validation loss: 1.5730966970484743

Epoch: 5| Step: 1
Training loss: 0.16885225474834442
Validation loss: 1.6250087061235983

Epoch: 5| Step: 2
Training loss: 0.14728450775146484
Validation loss: 1.598505263687462

Epoch: 5| Step: 3
Training loss: 0.128705695271492
Validation loss: 1.583783475301599

Epoch: 5| Step: 4
Training loss: 0.17520737648010254
Validation loss: 1.5782363286582373

Epoch: 5| Step: 5
Training loss: 0.07414214313030243
Validation loss: 1.5419478044714978

Epoch: 5| Step: 6
Training loss: 0.11690445989370346
Validation loss: 1.5181250713204826

Epoch: 5| Step: 7
Training loss: 0.09255097061395645
Validation loss: 1.486704776363988

Epoch: 5| Step: 8
Training loss: 0.11421885341405869
Validation loss: 1.5101347982242543

Epoch: 5| Step: 9
Training loss: 0.09361301362514496
Validation loss: 1.505271582193272

Epoch: 5| Step: 10
Training loss: 0.25287824869155884
Validation loss: 1.4904583564368628

Epoch: 501| Step: 0
Training loss: 0.09511594474315643
Validation loss: 1.5353695474645144

Epoch: 5| Step: 1
Training loss: 0.06838572770357132
Validation loss: 1.5274088677539621

Epoch: 5| Step: 2
Training loss: 0.0820944532752037
Validation loss: 1.548679300533828

Epoch: 5| Step: 3
Training loss: 0.0698874294757843
Validation loss: 1.569096783156036

Epoch: 5| Step: 4
Training loss: 0.13736625015735626
Validation loss: 1.572532283362522

Epoch: 5| Step: 5
Training loss: 0.10715854167938232
Validation loss: 1.5934331083810458

Epoch: 5| Step: 6
Training loss: 0.15129680931568146
Validation loss: 1.586298934874996

Epoch: 5| Step: 7
Training loss: 0.1217745915055275
Validation loss: 1.5758712022535262

Epoch: 5| Step: 8
Training loss: 0.1255655586719513
Validation loss: 1.572166141643319

Epoch: 5| Step: 9
Training loss: 0.18649563193321228
Validation loss: 1.5448615884268155

Epoch: 5| Step: 10
Training loss: 0.24022652208805084
Validation loss: 1.549271470756941

Epoch: 502| Step: 0
Training loss: 0.09167177230119705
Validation loss: 1.523810875031256

Epoch: 5| Step: 1
Training loss: 0.10318922996520996
Validation loss: 1.5473782811113583

Epoch: 5| Step: 2
Training loss: 0.06313301622867584
Validation loss: 1.5454909250300417

Epoch: 5| Step: 3
Training loss: 0.08013119548559189
Validation loss: 1.5505818846405193

Epoch: 5| Step: 4
Training loss: 0.23801103234291077
Validation loss: 1.5430935659716207

Epoch: 5| Step: 5
Training loss: 0.0830501839518547
Validation loss: 1.5291264390432706

Epoch: 5| Step: 6
Training loss: 0.08772623538970947
Validation loss: 1.5434186407314834

Epoch: 5| Step: 7
Training loss: 0.09651178121566772
Validation loss: 1.5486234682862476

Epoch: 5| Step: 8
Training loss: 0.14780625700950623
Validation loss: 1.5371581392903482

Epoch: 5| Step: 9
Training loss: 0.13504815101623535
Validation loss: 1.551937025080445

Epoch: 5| Step: 10
Training loss: 0.06437484174966812
Validation loss: 1.5577205188812748

Epoch: 503| Step: 0
Training loss: 0.12620458006858826
Validation loss: 1.536231921565148

Epoch: 5| Step: 1
Training loss: 0.07948753982782364
Validation loss: 1.533340475892508

Epoch: 5| Step: 2
Training loss: 0.09590189903974533
Validation loss: 1.5610700089444396

Epoch: 5| Step: 3
Training loss: 0.1256905049085617
Validation loss: 1.5477511100871588

Epoch: 5| Step: 4
Training loss: 0.09757733345031738
Validation loss: 1.5609911231584446

Epoch: 5| Step: 5
Training loss: 0.16419823467731476
Validation loss: 1.5503577179806207

Epoch: 5| Step: 6
Training loss: 0.07998921722173691
Validation loss: 1.5734003692544916

Epoch: 5| Step: 7
Training loss: 0.0927944928407669
Validation loss: 1.5950134492689563

Epoch: 5| Step: 8
Training loss: 0.16319027543067932
Validation loss: 1.5749601164171774

Epoch: 5| Step: 9
Training loss: 0.09600584208965302
Validation loss: 1.540535537145471

Epoch: 5| Step: 10
Training loss: 0.06465651094913483
Validation loss: 1.5384651089227328

Epoch: 504| Step: 0
Training loss: 0.1835685670375824
Validation loss: 1.5332976874484812

Epoch: 5| Step: 1
Training loss: 0.16306383907794952
Validation loss: 1.5360211595412223

Epoch: 5| Step: 2
Training loss: 0.08887621015310287
Validation loss: 1.5125703196371756

Epoch: 5| Step: 3
Training loss: 0.07923071086406708
Validation loss: 1.507836398258004

Epoch: 5| Step: 4
Training loss: 0.08838367462158203
Validation loss: 1.5158746396341631

Epoch: 5| Step: 5
Training loss: 0.08296527713537216
Validation loss: 1.5412503365547425

Epoch: 5| Step: 6
Training loss: 0.13928821682929993
Validation loss: 1.5139721106457453

Epoch: 5| Step: 7
Training loss: 0.08185505867004395
Validation loss: 1.4958589974270071

Epoch: 5| Step: 8
Training loss: 0.11289174854755402
Validation loss: 1.5201850488621702

Epoch: 5| Step: 9
Training loss: 0.06583797186613083
Validation loss: 1.514043483682858

Epoch: 5| Step: 10
Training loss: 0.04949720576405525
Validation loss: 1.5431067315481042

Epoch: 505| Step: 0
Training loss: 0.061539243906736374
Validation loss: 1.4936061956549203

Epoch: 5| Step: 1
Training loss: 0.1596561223268509
Validation loss: 1.5406733751296997

Epoch: 5| Step: 2
Training loss: 0.09713611751794815
Validation loss: 1.5102101218315862

Epoch: 5| Step: 3
Training loss: 0.10466749966144562
Validation loss: 1.5209989265729023

Epoch: 5| Step: 4
Training loss: 0.14003291726112366
Validation loss: 1.4982953840686428

Epoch: 5| Step: 5
Training loss: 0.060420989990234375
Validation loss: 1.5192193344075193

Epoch: 5| Step: 6
Training loss: 0.13095952570438385
Validation loss: 1.502438610599887

Epoch: 5| Step: 7
Training loss: 0.07694417983293533
Validation loss: 1.5386145653263215

Epoch: 5| Step: 8
Training loss: 0.15210214257240295
Validation loss: 1.5141678804992347

Epoch: 5| Step: 9
Training loss: 0.11458142846822739
Validation loss: 1.5096976603231123

Epoch: 5| Step: 10
Training loss: 0.17255505919456482
Validation loss: 1.5540137713955295

Epoch: 506| Step: 0
Training loss: 0.1492546945810318
Validation loss: 1.534690192950669

Epoch: 5| Step: 1
Training loss: 0.07894067466259003
Validation loss: 1.5859246484694942

Epoch: 5| Step: 2
Training loss: 0.06863804161548615
Validation loss: 1.5671888346313148

Epoch: 5| Step: 3
Training loss: 0.11081665754318237
Validation loss: 1.5721101632682226

Epoch: 5| Step: 4
Training loss: 0.08672861754894257
Validation loss: 1.5465344562325427

Epoch: 5| Step: 5
Training loss: 0.13828812539577484
Validation loss: 1.554671520827919

Epoch: 5| Step: 6
Training loss: 0.13555657863616943
Validation loss: 1.5482718726640106

Epoch: 5| Step: 7
Training loss: 0.14727170765399933
Validation loss: 1.5410118103027344

Epoch: 5| Step: 8
Training loss: 0.17764338850975037
Validation loss: 1.5680254261980775

Epoch: 5| Step: 9
Training loss: 0.19668520987033844
Validation loss: 1.5726519066800353

Epoch: 5| Step: 10
Training loss: 0.10576619952917099
Validation loss: 1.60521638008856

Epoch: 507| Step: 0
Training loss: 0.1158701628446579
Validation loss: 1.5585875639351465

Epoch: 5| Step: 1
Training loss: 0.19865623116493225
Validation loss: 1.5750941307313981

Epoch: 5| Step: 2
Training loss: 0.13759012520313263
Validation loss: 1.5664564281381586

Epoch: 5| Step: 3
Training loss: 0.12893718481063843
Validation loss: 1.5541158735111196

Epoch: 5| Step: 4
Training loss: 0.0813564881682396
Validation loss: 1.5742973178945563

Epoch: 5| Step: 5
Training loss: 0.10285339504480362
Validation loss: 1.556755660682596

Epoch: 5| Step: 6
Training loss: 0.15154217183589935
Validation loss: 1.5705029451718895

Epoch: 5| Step: 7
Training loss: 0.16489861905574799
Validation loss: 1.5433970869228404

Epoch: 5| Step: 8
Training loss: 0.1223570853471756
Validation loss: 1.54789105538399

Epoch: 5| Step: 9
Training loss: 0.08052490651607513
Validation loss: 1.5509385152529644

Epoch: 5| Step: 10
Training loss: 0.20203886926174164
Validation loss: 1.5599532652926702

Epoch: 508| Step: 0
Training loss: 0.14013296365737915
Validation loss: 1.563793497700845

Epoch: 5| Step: 1
Training loss: 0.08229117840528488
Validation loss: 1.5670174014183782

Epoch: 5| Step: 2
Training loss: 0.10989665985107422
Validation loss: 1.6020631021068943

Epoch: 5| Step: 3
Training loss: 0.13275866210460663
Validation loss: 1.6090531182545487

Epoch: 5| Step: 4
Training loss: 0.13307425379753113
Validation loss: 1.6399399388221003

Epoch: 5| Step: 5
Training loss: 0.21107840538024902
Validation loss: 1.6254911063819804

Epoch: 5| Step: 6
Training loss: 0.20664918422698975
Validation loss: 1.5865879520293205

Epoch: 5| Step: 7
Training loss: 0.07692800462245941
Validation loss: 1.5656281376397738

Epoch: 5| Step: 8
Training loss: 0.0726957768201828
Validation loss: 1.5622235946757819

Epoch: 5| Step: 9
Training loss: 0.09261099994182587
Validation loss: 1.5637750728155977

Epoch: 5| Step: 10
Training loss: 0.1368728131055832
Validation loss: 1.527780863546556

Epoch: 509| Step: 0
Training loss: 0.15978504717350006
Validation loss: 1.5195772673494072

Epoch: 5| Step: 1
Training loss: 0.11126501858234406
Validation loss: 1.528034008318378

Epoch: 5| Step: 2
Training loss: 0.0747048482298851
Validation loss: 1.528398388175554

Epoch: 5| Step: 3
Training loss: 0.06336714327335358
Validation loss: 1.567487548115433

Epoch: 5| Step: 4
Training loss: 0.09190253168344498
Validation loss: 1.541922712838778

Epoch: 5| Step: 5
Training loss: 0.14959169924259186
Validation loss: 1.5876503375268751

Epoch: 5| Step: 6
Training loss: 0.11410896480083466
Validation loss: 1.5689985188104774

Epoch: 5| Step: 7
Training loss: 0.1412590742111206
Validation loss: 1.5711820907490228

Epoch: 5| Step: 8
Training loss: 0.0980776995420456
Validation loss: 1.552339373096343

Epoch: 5| Step: 9
Training loss: 0.13950759172439575
Validation loss: 1.5554759322956044

Epoch: 5| Step: 10
Training loss: 0.05972856655716896
Validation loss: 1.4990085619752125

Epoch: 510| Step: 0
Training loss: 0.1585654616355896
Validation loss: 1.5562104896832538

Epoch: 5| Step: 1
Training loss: 0.22020947933197021
Validation loss: 1.4986024902712913

Epoch: 5| Step: 2
Training loss: 0.11251237243413925
Validation loss: 1.5085876846826205

Epoch: 5| Step: 3
Training loss: 0.17678959667682648
Validation loss: 1.5121836303382792

Epoch: 5| Step: 4
Training loss: 0.10549898445606232
Validation loss: 1.523000382607983

Epoch: 5| Step: 5
Training loss: 0.1047477126121521
Validation loss: 1.5322586644080378

Epoch: 5| Step: 6
Training loss: 0.12491588294506073
Validation loss: 1.5073217448367868

Epoch: 5| Step: 7
Training loss: 0.10509593784809113
Validation loss: 1.5375981612872052

Epoch: 5| Step: 8
Training loss: 0.08834747225046158
Validation loss: 1.5430068059634137

Epoch: 5| Step: 9
Training loss: 0.1284097284078598
Validation loss: 1.5393533886119883

Epoch: 5| Step: 10
Training loss: 0.1101638674736023
Validation loss: 1.5446790059407551

Epoch: 511| Step: 0
Training loss: 0.1513993740081787
Validation loss: 1.5567327699353617

Epoch: 5| Step: 1
Training loss: 0.07014389336109161
Validation loss: 1.5469335253520677

Epoch: 5| Step: 2
Training loss: 0.2340848445892334
Validation loss: 1.5030306987864996

Epoch: 5| Step: 3
Training loss: 0.053592704236507416
Validation loss: 1.5008891026178997

Epoch: 5| Step: 4
Training loss: 0.06302113085985184
Validation loss: 1.5402522933098577

Epoch: 5| Step: 5
Training loss: 0.08868762105703354
Validation loss: 1.5200220487451042

Epoch: 5| Step: 6
Training loss: 0.10836634784936905
Validation loss: 1.5357438543791413

Epoch: 5| Step: 7
Training loss: 0.11968255043029785
Validation loss: 1.5492831250672698

Epoch: 5| Step: 8
Training loss: 0.12690624594688416
Validation loss: 1.5684854997101652

Epoch: 5| Step: 9
Training loss: 0.08794493228197098
Validation loss: 1.5697604456255514

Epoch: 5| Step: 10
Training loss: 0.11275465786457062
Validation loss: 1.5939084970822899

Epoch: 512| Step: 0
Training loss: 0.06902159750461578
Validation loss: 1.5747400509413851

Epoch: 5| Step: 1
Training loss: 0.12544319033622742
Validation loss: 1.5843996065919117

Epoch: 5| Step: 2
Training loss: 0.19617126882076263
Validation loss: 1.5580436798834032

Epoch: 5| Step: 3
Training loss: 0.1271314173936844
Validation loss: 1.552220021524737

Epoch: 5| Step: 4
Training loss: 0.10318229347467422
Validation loss: 1.5579624675935315

Epoch: 5| Step: 5
Training loss: 0.0675516277551651
Validation loss: 1.5426847357903757

Epoch: 5| Step: 6
Training loss: 0.08360188454389572
Validation loss: 1.569132762570535

Epoch: 5| Step: 7
Training loss: 0.1291113793849945
Validation loss: 1.5378400318084224

Epoch: 5| Step: 8
Training loss: 0.14379441738128662
Validation loss: 1.540528840916131

Epoch: 5| Step: 9
Training loss: 0.16440294682979584
Validation loss: 1.5674250869340793

Epoch: 5| Step: 10
Training loss: 0.08267226070165634
Validation loss: 1.579640789698529

Epoch: 513| Step: 0
Training loss: 0.13120917975902557
Validation loss: 1.5836161503227808

Epoch: 5| Step: 1
Training loss: 0.06694509088993073
Validation loss: 1.559133480953914

Epoch: 5| Step: 2
Training loss: 0.10464028269052505
Validation loss: 1.5498051425462127

Epoch: 5| Step: 3
Training loss: 0.16339826583862305
Validation loss: 1.5805089396815146

Epoch: 5| Step: 4
Training loss: 0.08579634130001068
Validation loss: 1.5351179158815773

Epoch: 5| Step: 5
Training loss: 0.09519340097904205
Validation loss: 1.532771231025778

Epoch: 5| Step: 6
Training loss: 0.15303117036819458
Validation loss: 1.5339003865436842

Epoch: 5| Step: 7
Training loss: 0.12112537771463394
Validation loss: 1.5114326246323124

Epoch: 5| Step: 8
Training loss: 0.06727670133113861
Validation loss: 1.521100490964869

Epoch: 5| Step: 9
Training loss: 0.15983666479587555
Validation loss: 1.541650269621162

Epoch: 5| Step: 10
Training loss: 0.0783001258969307
Validation loss: 1.5140669358673917

Epoch: 514| Step: 0
Training loss: 0.0937618538737297
Validation loss: 1.5283093106362127

Epoch: 5| Step: 1
Training loss: 0.09639569371938705
Validation loss: 1.5291963110687912

Epoch: 5| Step: 2
Training loss: 0.11356578767299652
Validation loss: 1.5393298236272668

Epoch: 5| Step: 3
Training loss: 0.13363845646381378
Validation loss: 1.5464717354825748

Epoch: 5| Step: 4
Training loss: 0.08715040981769562
Validation loss: 1.5542139660927556

Epoch: 5| Step: 5
Training loss: 0.0914827436208725
Validation loss: 1.564304183888179

Epoch: 5| Step: 6
Training loss: 0.1094122901558876
Validation loss: 1.583136789260372

Epoch: 5| Step: 7
Training loss: 0.0870131403207779
Validation loss: 1.5360245243195565

Epoch: 5| Step: 8
Training loss: 0.09999433159828186
Validation loss: 1.5589205347081667

Epoch: 5| Step: 9
Training loss: 0.15572042763233185
Validation loss: 1.5380896227334135

Epoch: 5| Step: 10
Training loss: 0.11129175871610641
Validation loss: 1.5263638291307675

Epoch: 515| Step: 0
Training loss: 0.17265555262565613
Validation loss: 1.5320291942165745

Epoch: 5| Step: 1
Training loss: 0.11788424104452133
Validation loss: 1.5219251237889773

Epoch: 5| Step: 2
Training loss: 0.08338286727666855
Validation loss: 1.530220006101875

Epoch: 5| Step: 3
Training loss: 0.11733277887105942
Validation loss: 1.5149424076080322

Epoch: 5| Step: 4
Training loss: 0.1962892711162567
Validation loss: 1.5273514704037738

Epoch: 5| Step: 5
Training loss: 0.06800563633441925
Validation loss: 1.53683086492682

Epoch: 5| Step: 6
Training loss: 0.06980706751346588
Validation loss: 1.5195457922515048

Epoch: 5| Step: 7
Training loss: 0.05011477321386337
Validation loss: 1.5070391111476447

Epoch: 5| Step: 8
Training loss: 0.14695873856544495
Validation loss: 1.49253721134637

Epoch: 5| Step: 9
Training loss: 0.07182113081216812
Validation loss: 1.4820340884629117

Epoch: 5| Step: 10
Training loss: 0.16109120845794678
Validation loss: 1.5056358986003424

Epoch: 516| Step: 0
Training loss: 0.054073333740234375
Validation loss: 1.5184309367210633

Epoch: 5| Step: 1
Training loss: 0.09708315134048462
Validation loss: 1.5060335077265257

Epoch: 5| Step: 2
Training loss: 0.0771193653345108
Validation loss: 1.5100691433875792

Epoch: 5| Step: 3
Training loss: 0.12394978106021881
Validation loss: 1.5235802627378894

Epoch: 5| Step: 4
Training loss: 0.06145445629954338
Validation loss: 1.5154397692731632

Epoch: 5| Step: 5
Training loss: 0.12270790338516235
Validation loss: 1.5684178439519738

Epoch: 5| Step: 6
Training loss: 0.1090431660413742
Validation loss: 1.5632066893321213

Epoch: 5| Step: 7
Training loss: 0.08950735628604889
Validation loss: 1.604610808434025

Epoch: 5| Step: 8
Training loss: 0.13013990223407745
Validation loss: 1.5791323928422825

Epoch: 5| Step: 9
Training loss: 0.1573300063610077
Validation loss: 1.5692406918412896

Epoch: 5| Step: 10
Training loss: 0.11026489734649658
Validation loss: 1.530551593790772

Epoch: 517| Step: 0
Training loss: 0.12560823559761047
Validation loss: 1.5099018414815266

Epoch: 5| Step: 1
Training loss: 0.09693382680416107
Validation loss: 1.5085549982645179

Epoch: 5| Step: 2
Training loss: 0.16638708114624023
Validation loss: 1.492122487355304

Epoch: 5| Step: 3
Training loss: 0.2004510462284088
Validation loss: 1.5055730573592647

Epoch: 5| Step: 4
Training loss: 0.10893791913986206
Validation loss: 1.5198471584627706

Epoch: 5| Step: 5
Training loss: 0.16274209320545197
Validation loss: 1.4911541079962125

Epoch: 5| Step: 6
Training loss: 0.07761360704898834
Validation loss: 1.5089435180028279

Epoch: 5| Step: 7
Training loss: 0.053683411329984665
Validation loss: 1.523117261548196

Epoch: 5| Step: 8
Training loss: 0.10038701444864273
Validation loss: 1.5430302466115644

Epoch: 5| Step: 9
Training loss: 0.064095139503479
Validation loss: 1.5673264700879332

Epoch: 5| Step: 10
Training loss: 0.0980987697839737
Validation loss: 1.5908502904317712

Epoch: 518| Step: 0
Training loss: 0.07765959203243256
Validation loss: 1.5680857871168403

Epoch: 5| Step: 1
Training loss: 0.1756936013698578
Validation loss: 1.566689263107956

Epoch: 5| Step: 2
Training loss: 0.08067218959331512
Validation loss: 1.535129931665236

Epoch: 5| Step: 3
Training loss: 0.08069679886102676
Validation loss: 1.558909749472013

Epoch: 5| Step: 4
Training loss: 0.1515154242515564
Validation loss: 1.5395674282504666

Epoch: 5| Step: 5
Training loss: 0.14952319860458374
Validation loss: 1.5421762158793788

Epoch: 5| Step: 6
Training loss: 0.10399585962295532
Validation loss: 1.55065712236589

Epoch: 5| Step: 7
Training loss: 0.06596552580595016
Validation loss: 1.5235686161184823

Epoch: 5| Step: 8
Training loss: 0.07536512613296509
Validation loss: 1.5383471006988196

Epoch: 5| Step: 9
Training loss: 0.10653535276651382
Validation loss: 1.5099167464881815

Epoch: 5| Step: 10
Training loss: 0.08531134575605392
Validation loss: 1.5234484800728418

Epoch: 519| Step: 0
Training loss: 0.08598238229751587
Validation loss: 1.5251839455737863

Epoch: 5| Step: 1
Training loss: 0.13935896754264832
Validation loss: 1.5355782111485798

Epoch: 5| Step: 2
Training loss: 0.12167336791753769
Validation loss: 1.545431443440017

Epoch: 5| Step: 3
Training loss: 0.13741974532604218
Validation loss: 1.5360724938813077

Epoch: 5| Step: 4
Training loss: 0.1272437870502472
Validation loss: 1.5314450994614632

Epoch: 5| Step: 5
Training loss: 0.08573655039072037
Validation loss: 1.5301518055700487

Epoch: 5| Step: 6
Training loss: 0.06311560422182083
Validation loss: 1.5062237593435472

Epoch: 5| Step: 7
Training loss: 0.15739116072654724
Validation loss: 1.522008333154904

Epoch: 5| Step: 8
Training loss: 0.12139232456684113
Validation loss: 1.4952897128238474

Epoch: 5| Step: 9
Training loss: 0.11047708988189697
Validation loss: 1.5502691864967346

Epoch: 5| Step: 10
Training loss: 0.23137332499027252
Validation loss: 1.539674961438743

Epoch: 520| Step: 0
Training loss: 0.12382501363754272
Validation loss: 1.5593358034728675

Epoch: 5| Step: 1
Training loss: 0.14884276688098907
Validation loss: 1.5432881245049097

Epoch: 5| Step: 2
Training loss: 0.08000384271144867
Validation loss: 1.5226297532358477

Epoch: 5| Step: 3
Training loss: 0.09538482129573822
Validation loss: 1.5154012351907709

Epoch: 5| Step: 4
Training loss: 0.16348609328269958
Validation loss: 1.5439011909628426

Epoch: 5| Step: 5
Training loss: 0.0786743313074112
Validation loss: 1.5551609287979782

Epoch: 5| Step: 6
Training loss: 0.10055837780237198
Validation loss: 1.5416620239134757

Epoch: 5| Step: 7
Training loss: 0.11480853706598282
Validation loss: 1.533768153959705

Epoch: 5| Step: 8
Training loss: 0.07206425815820694
Validation loss: 1.4986996137967674

Epoch: 5| Step: 9
Training loss: 0.10257645696401596
Validation loss: 1.5145821481622674

Epoch: 5| Step: 10
Training loss: 0.07203522324562073
Validation loss: 1.5163925283698625

Epoch: 521| Step: 0
Training loss: 0.10866525024175644
Validation loss: 1.5264052870453044

Epoch: 5| Step: 1
Training loss: 0.0932043045759201
Validation loss: 1.516423334357559

Epoch: 5| Step: 2
Training loss: 0.17307713627815247
Validation loss: 1.5559416503034613

Epoch: 5| Step: 3
Training loss: 0.11102132499217987
Validation loss: 1.5321669091460526

Epoch: 5| Step: 4
Training loss: 0.07087687402963638
Validation loss: 1.5517326862581315

Epoch: 5| Step: 5
Training loss: 0.1317240446805954
Validation loss: 1.5797011826627998

Epoch: 5| Step: 6
Training loss: 0.10734613239765167
Validation loss: 1.5515873624432472

Epoch: 5| Step: 7
Training loss: 0.09212027490139008
Validation loss: 1.5272995066899124

Epoch: 5| Step: 8
Training loss: 0.09262635558843613
Validation loss: 1.518090158380488

Epoch: 5| Step: 9
Training loss: 0.1075955256819725
Validation loss: 1.5120346943537395

Epoch: 5| Step: 10
Training loss: 0.0695844516158104
Validation loss: 1.5045774034274522

Epoch: 522| Step: 0
Training loss: 0.15258917212486267
Validation loss: 1.5139457730836765

Epoch: 5| Step: 1
Training loss: 0.07949133217334747
Validation loss: 1.5245411806209113

Epoch: 5| Step: 2
Training loss: 0.1061016321182251
Validation loss: 1.5171623781163206

Epoch: 5| Step: 3
Training loss: 0.16676726937294006
Validation loss: 1.5078947031369774

Epoch: 5| Step: 4
Training loss: 0.08751450479030609
Validation loss: 1.5054949483563822

Epoch: 5| Step: 5
Training loss: 0.10060597956180573
Validation loss: 1.5191220096362534

Epoch: 5| Step: 6
Training loss: 0.057714082300662994
Validation loss: 1.4964371265903595

Epoch: 5| Step: 7
Training loss: 0.06427671760320663
Validation loss: 1.4626450923181349

Epoch: 5| Step: 8
Training loss: 0.1444096565246582
Validation loss: 1.4962351533674425

Epoch: 5| Step: 9
Training loss: 0.0696258395910263
Validation loss: 1.5030648298161005

Epoch: 5| Step: 10
Training loss: 0.060864657163619995
Validation loss: 1.4822992374820094

Epoch: 523| Step: 0
Training loss: 0.10964743047952652
Validation loss: 1.4915542012901717

Epoch: 5| Step: 1
Training loss: 0.04661315679550171
Validation loss: 1.5154703278695383

Epoch: 5| Step: 2
Training loss: 0.1207817941904068
Validation loss: 1.5168898823440715

Epoch: 5| Step: 3
Training loss: 0.1736224889755249
Validation loss: 1.5403584395685503

Epoch: 5| Step: 4
Training loss: 0.07426389306783676
Validation loss: 1.5318775907639535

Epoch: 5| Step: 5
Training loss: 0.05195096880197525
Validation loss: 1.5589190016510666

Epoch: 5| Step: 6
Training loss: 0.11068473011255264
Validation loss: 1.5358652517359743

Epoch: 5| Step: 7
Training loss: 0.08410949259996414
Validation loss: 1.5137121856853526

Epoch: 5| Step: 8
Training loss: 0.13845883309841156
Validation loss: 1.5131107254694867

Epoch: 5| Step: 9
Training loss: 0.07507829368114471
Validation loss: 1.489817798778575

Epoch: 5| Step: 10
Training loss: 0.12792542576789856
Validation loss: 1.4857600799170874

Epoch: 524| Step: 0
Training loss: 0.09041064977645874
Validation loss: 1.5116627946976693

Epoch: 5| Step: 1
Training loss: 0.10202991962432861
Validation loss: 1.5177655707123459

Epoch: 5| Step: 2
Training loss: 0.14966228604316711
Validation loss: 1.547888571216214

Epoch: 5| Step: 3
Training loss: 0.10639452934265137
Validation loss: 1.548487292182061

Epoch: 5| Step: 4
Training loss: 0.19832205772399902
Validation loss: 1.5694708055065525

Epoch: 5| Step: 5
Training loss: 0.07597793638706207
Validation loss: 1.5643342310382473

Epoch: 5| Step: 6
Training loss: 0.1291351020336151
Validation loss: 1.554352860296926

Epoch: 5| Step: 7
Training loss: 0.055157650262117386
Validation loss: 1.5388476393556083

Epoch: 5| Step: 8
Training loss: 0.058769386261701584
Validation loss: 1.5238428256844962

Epoch: 5| Step: 9
Training loss: 0.07922621071338654
Validation loss: 1.507217393126539

Epoch: 5| Step: 10
Training loss: 0.08246936649084091
Validation loss: 1.5029518399187314

Epoch: 525| Step: 0
Training loss: 0.14319457113742828
Validation loss: 1.4645110112364574

Epoch: 5| Step: 1
Training loss: 0.1029273271560669
Validation loss: 1.4763492743174236

Epoch: 5| Step: 2
Training loss: 0.11730370670557022
Validation loss: 1.4987601413521716

Epoch: 5| Step: 3
Training loss: 0.09663961082696915
Validation loss: 1.4992695764828754

Epoch: 5| Step: 4
Training loss: 0.13999351859092712
Validation loss: 1.4930826624234517

Epoch: 5| Step: 5
Training loss: 0.07183799147605896
Validation loss: 1.5319072046587545

Epoch: 5| Step: 6
Training loss: 0.18164384365081787
Validation loss: 1.509998518933532

Epoch: 5| Step: 7
Training loss: 0.08356454223394394
Validation loss: 1.526412825430593

Epoch: 5| Step: 8
Training loss: 0.08353859931230545
Validation loss: 1.5352249812054377

Epoch: 5| Step: 9
Training loss: 0.051229916512966156
Validation loss: 1.5264313925978958

Epoch: 5| Step: 10
Training loss: 0.10713714361190796
Validation loss: 1.5516780807125954

Epoch: 526| Step: 0
Training loss: 0.08669477701187134
Validation loss: 1.5395813244645313

Epoch: 5| Step: 1
Training loss: 0.06966407597064972
Validation loss: 1.5345066926812614

Epoch: 5| Step: 2
Training loss: 0.0560016855597496
Validation loss: 1.5399199096105431

Epoch: 5| Step: 3
Training loss: 0.10280926525592804
Validation loss: 1.5191296172398392

Epoch: 5| Step: 4
Training loss: 0.07897193729877472
Validation loss: 1.4948292355383597

Epoch: 5| Step: 5
Training loss: 0.09600448608398438
Validation loss: 1.4844253319565968

Epoch: 5| Step: 6
Training loss: 0.08509968221187592
Validation loss: 1.501469946676685

Epoch: 5| Step: 7
Training loss: 0.14680075645446777
Validation loss: 1.5195490865297214

Epoch: 5| Step: 8
Training loss: 0.06456102430820465
Validation loss: 1.522794021073208

Epoch: 5| Step: 9
Training loss: 0.1821986734867096
Validation loss: 1.5470247140494726

Epoch: 5| Step: 10
Training loss: 0.09147558361291885
Validation loss: 1.5458178404838807

Epoch: 527| Step: 0
Training loss: 0.16733457148075104
Validation loss: 1.552455912354172

Epoch: 5| Step: 1
Training loss: 0.1284855604171753
Validation loss: 1.5412327179344751

Epoch: 5| Step: 2
Training loss: 0.06960491836071014
Validation loss: 1.5611722161692958

Epoch: 5| Step: 3
Training loss: 0.11639442294836044
Validation loss: 1.5323930837774788

Epoch: 5| Step: 4
Training loss: 0.08547941595315933
Validation loss: 1.5016514934519285

Epoch: 5| Step: 5
Training loss: 0.0643220990896225
Validation loss: 1.5275488361235587

Epoch: 5| Step: 6
Training loss: 0.053820837289094925
Validation loss: 1.5172393437354796

Epoch: 5| Step: 7
Training loss: 0.08326342701911926
Validation loss: 1.5197846633131786

Epoch: 5| Step: 8
Training loss: 0.16570188105106354
Validation loss: 1.518101087180517

Epoch: 5| Step: 9
Training loss: 0.06439146399497986
Validation loss: 1.5390364918657529

Epoch: 5| Step: 10
Training loss: 0.04970654472708702
Validation loss: 1.5228176796308128

Epoch: 528| Step: 0
Training loss: 0.1580113172531128
Validation loss: 1.5348804253403858

Epoch: 5| Step: 1
Training loss: 0.08674752712249756
Validation loss: 1.5516534505351898

Epoch: 5| Step: 2
Training loss: 0.07160471379756927
Validation loss: 1.561922715556237

Epoch: 5| Step: 3
Training loss: 0.07293455302715302
Validation loss: 1.6025489953256422

Epoch: 5| Step: 4
Training loss: 0.16749833524227142
Validation loss: 1.5740136318309332

Epoch: 5| Step: 5
Training loss: 0.09220211207866669
Validation loss: 1.575650417676536

Epoch: 5| Step: 6
Training loss: 0.12511415779590607
Validation loss: 1.552001686506374

Epoch: 5| Step: 7
Training loss: 0.07710175961256027
Validation loss: 1.554200453142966

Epoch: 5| Step: 8
Training loss: 0.0873573049902916
Validation loss: 1.5469476728029148

Epoch: 5| Step: 9
Training loss: 0.12451603263616562
Validation loss: 1.5410761743463495

Epoch: 5| Step: 10
Training loss: 0.1186755821108818
Validation loss: 1.5399346390078146

Epoch: 529| Step: 0
Training loss: 0.05462627485394478
Validation loss: 1.5037541171555877

Epoch: 5| Step: 1
Training loss: 0.10544723272323608
Validation loss: 1.5083188356891755

Epoch: 5| Step: 2
Training loss: 0.1340826004743576
Validation loss: 1.494069404499505

Epoch: 5| Step: 3
Training loss: 0.09278476238250732
Validation loss: 1.4997027138228058

Epoch: 5| Step: 4
Training loss: 0.06356483697891235
Validation loss: 1.4999421796491068

Epoch: 5| Step: 5
Training loss: 0.12165119498968124
Validation loss: 1.4914987715341712

Epoch: 5| Step: 6
Training loss: 0.06656385958194733
Validation loss: 1.4892970977290985

Epoch: 5| Step: 7
Training loss: 0.1026386022567749
Validation loss: 1.5215687828679239

Epoch: 5| Step: 8
Training loss: 0.12114205211400986
Validation loss: 1.511421989369136

Epoch: 5| Step: 9
Training loss: 0.0898815393447876
Validation loss: 1.5326542982491114

Epoch: 5| Step: 10
Training loss: 0.060228895395994186
Validation loss: 1.532435760703138

Epoch: 530| Step: 0
Training loss: 0.09342166781425476
Validation loss: 1.5206000625446279

Epoch: 5| Step: 1
Training loss: 0.11418092250823975
Validation loss: 1.5341558520511915

Epoch: 5| Step: 2
Training loss: 0.1281200647354126
Validation loss: 1.5080448132689281

Epoch: 5| Step: 3
Training loss: 0.051495980471372604
Validation loss: 1.543751383340487

Epoch: 5| Step: 4
Training loss: 0.08441814035177231
Validation loss: 1.5193692612391647

Epoch: 5| Step: 5
Training loss: 0.07116290926933289
Validation loss: 1.5401422644174227

Epoch: 5| Step: 6
Training loss: 0.0846320390701294
Validation loss: 1.499128996684987

Epoch: 5| Step: 7
Training loss: 0.11303025484085083
Validation loss: 1.5239110774891351

Epoch: 5| Step: 8
Training loss: 0.16806891560554504
Validation loss: 1.512448856907506

Epoch: 5| Step: 9
Training loss: 0.09180043637752533
Validation loss: 1.4943207899729412

Epoch: 5| Step: 10
Training loss: 0.1698959916830063
Validation loss: 1.5164615582394343

Epoch: 531| Step: 0
Training loss: 0.09450171142816544
Validation loss: 1.499311049779256

Epoch: 5| Step: 1
Training loss: 0.16281303763389587
Validation loss: 1.5246356482146888

Epoch: 5| Step: 2
Training loss: 0.06845608353614807
Validation loss: 1.516718372221916

Epoch: 5| Step: 3
Training loss: 0.07783015072345734
Validation loss: 1.530910930325908

Epoch: 5| Step: 4
Training loss: 0.04577517509460449
Validation loss: 1.541904439208328

Epoch: 5| Step: 5
Training loss: 0.1405009925365448
Validation loss: 1.5423015240700013

Epoch: 5| Step: 6
Training loss: 0.11029273271560669
Validation loss: 1.5556844690794587

Epoch: 5| Step: 7
Training loss: 0.14781422913074493
Validation loss: 1.530386564552143

Epoch: 5| Step: 8
Training loss: 0.06674311310052872
Validation loss: 1.530211349969269

Epoch: 5| Step: 9
Training loss: 0.09122155606746674
Validation loss: 1.5150765936861756

Epoch: 5| Step: 10
Training loss: 0.12475939095020294
Validation loss: 1.5158690765339842

Epoch: 532| Step: 0
Training loss: 0.07707475125789642
Validation loss: 1.52430094826606

Epoch: 5| Step: 1
Training loss: 0.09300496429204941
Validation loss: 1.5293770297881095

Epoch: 5| Step: 2
Training loss: 0.06976191699504852
Validation loss: 1.5337887425576486

Epoch: 5| Step: 3
Training loss: 0.09170405566692352
Validation loss: 1.5397111356899302

Epoch: 5| Step: 4
Training loss: 0.13155342638492584
Validation loss: 1.5248364088355855

Epoch: 5| Step: 5
Training loss: 0.11621896177530289
Validation loss: 1.5414349532896472

Epoch: 5| Step: 6
Training loss: 0.11691047251224518
Validation loss: 1.54965111132591

Epoch: 5| Step: 7
Training loss: 0.08805813640356064
Validation loss: 1.5436625006378337

Epoch: 5| Step: 8
Training loss: 0.08156871795654297
Validation loss: 1.5084380577969294

Epoch: 5| Step: 9
Training loss: 0.16868805885314941
Validation loss: 1.5119711891297372

Epoch: 5| Step: 10
Training loss: 0.13347968459129333
Validation loss: 1.4675468872952204

Epoch: 533| Step: 0
Training loss: 0.11667387187480927
Validation loss: 1.4847588346850487

Epoch: 5| Step: 1
Training loss: 0.08943946659564972
Validation loss: 1.4664036016310416

Epoch: 5| Step: 2
Training loss: 0.16498711705207825
Validation loss: 1.4807195919816212

Epoch: 5| Step: 3
Training loss: 0.1496126800775528
Validation loss: 1.500665517263515

Epoch: 5| Step: 4
Training loss: 0.0987572968006134
Validation loss: 1.5104726027416926

Epoch: 5| Step: 5
Training loss: 0.11970599740743637
Validation loss: 1.5307580655620945

Epoch: 5| Step: 6
Training loss: 0.08849048614501953
Validation loss: 1.5549875151726507

Epoch: 5| Step: 7
Training loss: 0.07505642622709274
Validation loss: 1.5348876445524153

Epoch: 5| Step: 8
Training loss: 0.13854381442070007
Validation loss: 1.5341830894511232

Epoch: 5| Step: 9
Training loss: 0.05821039155125618
Validation loss: 1.550021384351997

Epoch: 5| Step: 10
Training loss: 0.09993292391300201
Validation loss: 1.561205752434269

Epoch: 534| Step: 0
Training loss: 0.10169658809900284
Validation loss: 1.534386868117958

Epoch: 5| Step: 1
Training loss: 0.07107987254858017
Validation loss: 1.5298944545048538

Epoch: 5| Step: 2
Training loss: 0.08518653362989426
Validation loss: 1.5268167475218415

Epoch: 5| Step: 3
Training loss: 0.06591950356960297
Validation loss: 1.5023879927973594

Epoch: 5| Step: 4
Training loss: 0.18177351355552673
Validation loss: 1.5133995907281035

Epoch: 5| Step: 5
Training loss: 0.08844520151615143
Validation loss: 1.5133090301226544

Epoch: 5| Step: 6
Training loss: 0.07399691641330719
Validation loss: 1.5261716868287774

Epoch: 5| Step: 7
Training loss: 0.0991276353597641
Validation loss: 1.526960821561916

Epoch: 5| Step: 8
Training loss: 0.11403335630893707
Validation loss: 1.5321457104016376

Epoch: 5| Step: 9
Training loss: 0.1377982795238495
Validation loss: 1.5252621353313487

Epoch: 5| Step: 10
Training loss: 0.08382268249988556
Validation loss: 1.5355111847641647

Epoch: 535| Step: 0
Training loss: 0.06264422833919525
Validation loss: 1.5327489376068115

Epoch: 5| Step: 1
Training loss: 0.04489367455244064
Validation loss: 1.5475863487489763

Epoch: 5| Step: 2
Training loss: 0.08425656706094742
Validation loss: 1.5219988592209355

Epoch: 5| Step: 3
Training loss: 0.10339689254760742
Validation loss: 1.4948118040638585

Epoch: 5| Step: 4
Training loss: 0.06162266060709953
Validation loss: 1.5182529341789983

Epoch: 5| Step: 5
Training loss: 0.11697550117969513
Validation loss: 1.5167583214339388

Epoch: 5| Step: 6
Training loss: 0.17908158898353577
Validation loss: 1.4902786067737046

Epoch: 5| Step: 7
Training loss: 0.12568774819374084
Validation loss: 1.4859621665811027

Epoch: 5| Step: 8
Training loss: 0.08682028949260712
Validation loss: 1.5038274475323257

Epoch: 5| Step: 9
Training loss: 0.1203492283821106
Validation loss: 1.5156399011611938

Epoch: 5| Step: 10
Training loss: 0.11628106236457825
Validation loss: 1.5004076637247556

Epoch: 536| Step: 0
Training loss: 0.11924536526203156
Validation loss: 1.5325195443245672

Epoch: 5| Step: 1
Training loss: 0.09309186041355133
Validation loss: 1.513409714544973

Epoch: 5| Step: 2
Training loss: 0.07181569188833237
Validation loss: 1.5027615921471709

Epoch: 5| Step: 3
Training loss: 0.08256910741329193
Validation loss: 1.4981474735403573

Epoch: 5| Step: 4
Training loss: 0.1127128154039383
Validation loss: 1.5050238678532262

Epoch: 5| Step: 5
Training loss: 0.13897454738616943
Validation loss: 1.4773856080988401

Epoch: 5| Step: 6
Training loss: 0.11868713051080704
Validation loss: 1.5078363751852384

Epoch: 5| Step: 7
Training loss: 0.06850532442331314
Validation loss: 1.4718704633815314

Epoch: 5| Step: 8
Training loss: 0.1286412477493286
Validation loss: 1.5048900355574906

Epoch: 5| Step: 9
Training loss: 0.10405346006155014
Validation loss: 1.5156674244070565

Epoch: 5| Step: 10
Training loss: 0.0849054753780365
Validation loss: 1.5174492578352652

Epoch: 537| Step: 0
Training loss: 0.07357852160930634
Validation loss: 1.5382241792576288

Epoch: 5| Step: 1
Training loss: 0.11150076240301132
Validation loss: 1.5498075126319804

Epoch: 5| Step: 2
Training loss: 0.06463734060525894
Validation loss: 1.536247226499742

Epoch: 5| Step: 3
Training loss: 0.15035495162010193
Validation loss: 1.5583090077164352

Epoch: 5| Step: 4
Training loss: 0.08999131619930267
Validation loss: 1.529109061405223

Epoch: 5| Step: 5
Training loss: 0.06476706266403198
Validation loss: 1.5354702882869269

Epoch: 5| Step: 6
Training loss: 0.08622074127197266
Validation loss: 1.5365972429193475

Epoch: 5| Step: 7
Training loss: 0.09821286797523499
Validation loss: 1.5471338072130758

Epoch: 5| Step: 8
Training loss: 0.11533913761377335
Validation loss: 1.5592074330135057

Epoch: 5| Step: 9
Training loss: 0.13156989216804504
Validation loss: 1.5547409557527112

Epoch: 5| Step: 10
Training loss: 0.1169087365269661
Validation loss: 1.5664458454296153

Epoch: 538| Step: 0
Training loss: 0.13595810532569885
Validation loss: 1.5668426713635843

Epoch: 5| Step: 1
Training loss: 0.11145887523889542
Validation loss: 1.5784546700857018

Epoch: 5| Step: 2
Training loss: 0.1274632066488266
Validation loss: 1.5496649024307088

Epoch: 5| Step: 3
Training loss: 0.1705676168203354
Validation loss: 1.5600025051383561

Epoch: 5| Step: 4
Training loss: 0.07888542860746384
Validation loss: 1.5397040690145185

Epoch: 5| Step: 5
Training loss: 0.07717514038085938
Validation loss: 1.56186354801219

Epoch: 5| Step: 6
Training loss: 0.06393835693597794
Validation loss: 1.5230884212319569

Epoch: 5| Step: 7
Training loss: 0.07927154004573822
Validation loss: 1.5273026010041595

Epoch: 5| Step: 8
Training loss: 0.08440598100423813
Validation loss: 1.5265623138796898

Epoch: 5| Step: 9
Training loss: 0.1331544667482376
Validation loss: 1.5225949184868925

Epoch: 5| Step: 10
Training loss: 0.06045602262020111
Validation loss: 1.5147941317609561

Epoch: 539| Step: 0
Training loss: 0.09499800950288773
Validation loss: 1.519766176900556

Epoch: 5| Step: 1
Training loss: 0.10695374011993408
Validation loss: 1.495489743448073

Epoch: 5| Step: 2
Training loss: 0.09052823483943939
Validation loss: 1.4716267111480876

Epoch: 5| Step: 3
Training loss: 0.12725049257278442
Validation loss: 1.5132282357062063

Epoch: 5| Step: 4
Training loss: 0.09756161272525787
Validation loss: 1.5144312548381027

Epoch: 5| Step: 5
Training loss: 0.10408969223499298
Validation loss: 1.5226743721192884

Epoch: 5| Step: 6
Training loss: 0.1125444620847702
Validation loss: 1.5434685586601176

Epoch: 5| Step: 7
Training loss: 0.09440083801746368
Validation loss: 1.5364902275864796

Epoch: 5| Step: 8
Training loss: 0.12717756628990173
Validation loss: 1.525027850622772

Epoch: 5| Step: 9
Training loss: 0.14414028823375702
Validation loss: 1.541322544056882

Epoch: 5| Step: 10
Training loss: 0.07420516014099121
Validation loss: 1.5277568345428796

Epoch: 540| Step: 0
Training loss: 0.0983918234705925
Validation loss: 1.532591167316642

Epoch: 5| Step: 1
Training loss: 0.11535213142633438
Validation loss: 1.5494781694104593

Epoch: 5| Step: 2
Training loss: 0.10560699552297592
Validation loss: 1.5476970441879765

Epoch: 5| Step: 3
Training loss: 0.07063300907611847
Validation loss: 1.5519488268001105

Epoch: 5| Step: 4
Training loss: 0.06567909568548203
Validation loss: 1.5296082727370723

Epoch: 5| Step: 5
Training loss: 0.13477686047554016
Validation loss: 1.5458044505888415

Epoch: 5| Step: 6
Training loss: 0.05740528553724289
Validation loss: 1.536479635905194

Epoch: 5| Step: 7
Training loss: 0.11526231467723846
Validation loss: 1.5611005213952833

Epoch: 5| Step: 8
Training loss: 0.07126403599977493
Validation loss: 1.5384380317503406

Epoch: 5| Step: 9
Training loss: 0.13986971974372864
Validation loss: 1.5150115630959953

Epoch: 5| Step: 10
Training loss: 0.13934457302093506
Validation loss: 1.5409596056066535

Epoch: 541| Step: 0
Training loss: 0.07730688899755478
Validation loss: 1.520939411655549

Epoch: 5| Step: 1
Training loss: 0.15785327553749084
Validation loss: 1.5065975599391486

Epoch: 5| Step: 2
Training loss: 0.17359629273414612
Validation loss: 1.5059174068512455

Epoch: 5| Step: 3
Training loss: 0.1666276752948761
Validation loss: 1.5090408171376875

Epoch: 5| Step: 4
Training loss: 0.07395229488611221
Validation loss: 1.4976026896507508

Epoch: 5| Step: 5
Training loss: 0.056968845427036285
Validation loss: 1.514131115328881

Epoch: 5| Step: 6
Training loss: 0.10282858461141586
Validation loss: 1.5657804730117961

Epoch: 5| Step: 7
Training loss: 0.1872958093881607
Validation loss: 1.5970862732138684

Epoch: 5| Step: 8
Training loss: 0.09107571840286255
Validation loss: 1.5812091865847189

Epoch: 5| Step: 9
Training loss: 0.08864729106426239
Validation loss: 1.5781194509998444

Epoch: 5| Step: 10
Training loss: 0.07524492591619492
Validation loss: 1.5598365574754693

Epoch: 542| Step: 0
Training loss: 0.1184096559882164
Validation loss: 1.5585180687647995

Epoch: 5| Step: 1
Training loss: 0.07472211122512817
Validation loss: 1.5320476716564548

Epoch: 5| Step: 2
Training loss: 0.10854645073413849
Validation loss: 1.5424682062159303

Epoch: 5| Step: 3
Training loss: 0.07658253610134125
Validation loss: 1.5427870705563536

Epoch: 5| Step: 4
Training loss: 0.1938757598400116
Validation loss: 1.541947680134927

Epoch: 5| Step: 5
Training loss: 0.1286650151014328
Validation loss: 1.523864855048477

Epoch: 5| Step: 6
Training loss: 0.15604174137115479
Validation loss: 1.5217793680006457

Epoch: 5| Step: 7
Training loss: 0.06628759205341339
Validation loss: 1.5269912814581266

Epoch: 5| Step: 8
Training loss: 0.08805842697620392
Validation loss: 1.4955379539920437

Epoch: 5| Step: 9
Training loss: 0.06374435126781464
Validation loss: 1.5002584124124179

Epoch: 5| Step: 10
Training loss: 0.05644189938902855
Validation loss: 1.5059931367956183

Epoch: 543| Step: 0
Training loss: 0.06893010437488556
Validation loss: 1.5155509338583997

Epoch: 5| Step: 1
Training loss: 0.09596500545740128
Validation loss: 1.5041387491328742

Epoch: 5| Step: 2
Training loss: 0.07779846340417862
Validation loss: 1.4835814250412809

Epoch: 5| Step: 3
Training loss: 0.17273792624473572
Validation loss: 1.4890113633166078

Epoch: 5| Step: 4
Training loss: 0.09726454317569733
Validation loss: 1.4877956772363314

Epoch: 5| Step: 5
Training loss: 0.11565502732992172
Validation loss: 1.5047636416650587

Epoch: 5| Step: 6
Training loss: 0.11405773460865021
Validation loss: 1.5091627259408273

Epoch: 5| Step: 7
Training loss: 0.09323416650295258
Validation loss: 1.5453541509566768

Epoch: 5| Step: 8
Training loss: 0.06147042661905289
Validation loss: 1.5585229050728582

Epoch: 5| Step: 9
Training loss: 0.09166961908340454
Validation loss: 1.55485660670906

Epoch: 5| Step: 10
Training loss: 0.13242094218730927
Validation loss: 1.5463293329361947

Epoch: 544| Step: 0
Training loss: 0.11285598576068878
Validation loss: 1.5482560614103913

Epoch: 5| Step: 1
Training loss: 0.11997342109680176
Validation loss: 1.4952108289605828

Epoch: 5| Step: 2
Training loss: 0.10833947360515594
Validation loss: 1.5041255335653982

Epoch: 5| Step: 3
Training loss: 0.09636660665273666
Validation loss: 1.5071495579135032

Epoch: 5| Step: 4
Training loss: 0.10344111919403076
Validation loss: 1.4907959686812533

Epoch: 5| Step: 5
Training loss: 0.0807395651936531
Validation loss: 1.5283406710111966

Epoch: 5| Step: 6
Training loss: 0.1246238574385643
Validation loss: 1.5303717749093169

Epoch: 5| Step: 7
Training loss: 0.10261674970388412
Validation loss: 1.5549644116432435

Epoch: 5| Step: 8
Training loss: 0.16201241314411163
Validation loss: 1.540193256511483

Epoch: 5| Step: 9
Training loss: 0.10894472897052765
Validation loss: 1.5151501496632893

Epoch: 5| Step: 10
Training loss: 0.07816121727228165
Validation loss: 1.5324982648254724

Epoch: 545| Step: 0
Training loss: 0.11213359981775284
Validation loss: 1.5240346539405085

Epoch: 5| Step: 1
Training loss: 0.12402303516864777
Validation loss: 1.5406562846194032

Epoch: 5| Step: 2
Training loss: 0.09926837682723999
Validation loss: 1.5255110084369619

Epoch: 5| Step: 3
Training loss: 0.06334167718887329
Validation loss: 1.5105798782840851

Epoch: 5| Step: 4
Training loss: 0.12359090149402618
Validation loss: 1.5043028990427654

Epoch: 5| Step: 5
Training loss: 0.08833224326372147
Validation loss: 1.5128520227247668

Epoch: 5| Step: 6
Training loss: 0.10926534235477448
Validation loss: 1.519450936266171

Epoch: 5| Step: 7
Training loss: 0.10630997270345688
Validation loss: 1.5105899495463218

Epoch: 5| Step: 8
Training loss: 0.13713712990283966
Validation loss: 1.5186974579288113

Epoch: 5| Step: 9
Training loss: 0.11418414115905762
Validation loss: 1.5167607427925192

Epoch: 5| Step: 10
Training loss: 0.05511365830898285
Validation loss: 1.5091981182816208

Epoch: 546| Step: 0
Training loss: 0.11591513454914093
Validation loss: 1.5080522708995368

Epoch: 5| Step: 1
Training loss: 0.13154049217700958
Validation loss: 1.5074478669833111

Epoch: 5| Step: 2
Training loss: 0.1323479413986206
Validation loss: 1.533677863818343

Epoch: 5| Step: 3
Training loss: 0.13650837540626526
Validation loss: 1.5040023378146592

Epoch: 5| Step: 4
Training loss: 0.07867933809757233
Validation loss: 1.5179113418825212

Epoch: 5| Step: 5
Training loss: 0.056217778474092484
Validation loss: 1.5249413059603782

Epoch: 5| Step: 6
Training loss: 0.06886432319879532
Validation loss: 1.5222530916172972

Epoch: 5| Step: 7
Training loss: 0.081048384308815
Validation loss: 1.5323075504713162

Epoch: 5| Step: 8
Training loss: 0.0637492835521698
Validation loss: 1.5462164468662714

Epoch: 5| Step: 9
Training loss: 0.08100499212741852
Validation loss: 1.5242105222517444

Epoch: 5| Step: 10
Training loss: 0.07494620978832245
Validation loss: 1.5239621490560553

Epoch: 547| Step: 0
Training loss: 0.10086486488580704
Validation loss: 1.5342732180831253

Epoch: 5| Step: 1
Training loss: 0.044894881546497345
Validation loss: 1.5189803595183997

Epoch: 5| Step: 2
Training loss: 0.05878130719065666
Validation loss: 1.523129169658948

Epoch: 5| Step: 3
Training loss: 0.06048621982336044
Validation loss: 1.5146149851942574

Epoch: 5| Step: 4
Training loss: 0.09602351486682892
Validation loss: 1.4987519748749272

Epoch: 5| Step: 5
Training loss: 0.09992790222167969
Validation loss: 1.5366088651841687

Epoch: 5| Step: 6
Training loss: 0.05936678498983383
Validation loss: 1.5353221688219296

Epoch: 5| Step: 7
Training loss: 0.09133142977952957
Validation loss: 1.536966598162087

Epoch: 5| Step: 8
Training loss: 0.09375768899917603
Validation loss: 1.5239847706210228

Epoch: 5| Step: 9
Training loss: 0.1457575261592865
Validation loss: 1.5626107172299457

Epoch: 5| Step: 10
Training loss: 0.06917489320039749
Validation loss: 1.55163291833734

Epoch: 548| Step: 0
Training loss: 0.1327667534351349
Validation loss: 1.5477581972716956

Epoch: 5| Step: 1
Training loss: 0.076033815741539
Validation loss: 1.5394415496498026

Epoch: 5| Step: 2
Training loss: 0.0980469137430191
Validation loss: 1.5272774491258847

Epoch: 5| Step: 3
Training loss: 0.139801025390625
Validation loss: 1.52194292570955

Epoch: 5| Step: 4
Training loss: 0.06894411891698837
Validation loss: 1.5411402384440105

Epoch: 5| Step: 5
Training loss: 0.04901107773184776
Validation loss: 1.5201549683847735

Epoch: 5| Step: 6
Training loss: 0.10881628096103668
Validation loss: 1.5273890943937405

Epoch: 5| Step: 7
Training loss: 0.07140902429819107
Validation loss: 1.5196071581173969

Epoch: 5| Step: 8
Training loss: 0.08575804531574249
Validation loss: 1.4936539511526785

Epoch: 5| Step: 9
Training loss: 0.07136555761098862
Validation loss: 1.4968482819936608

Epoch: 5| Step: 10
Training loss: 0.09930578619241714
Validation loss: 1.4809652066999865

Epoch: 549| Step: 0
Training loss: 0.10136999189853668
Validation loss: 1.512105103461973

Epoch: 5| Step: 1
Training loss: 0.07391904294490814
Validation loss: 1.5040010277942946

Epoch: 5| Step: 2
Training loss: 0.06871376186609268
Validation loss: 1.5136832806371874

Epoch: 5| Step: 3
Training loss: 0.1649765521287918
Validation loss: 1.5081313784404466

Epoch: 5| Step: 4
Training loss: 0.0918431431055069
Validation loss: 1.5276166072455786

Epoch: 5| Step: 5
Training loss: 0.1258348971605301
Validation loss: 1.527631639793355

Epoch: 5| Step: 6
Training loss: 0.108146071434021
Validation loss: 1.5265268766751854

Epoch: 5| Step: 7
Training loss: 0.08166588842868805
Validation loss: 1.500746641748695

Epoch: 5| Step: 8
Training loss: 0.07097098976373672
Validation loss: 1.488004861339446

Epoch: 5| Step: 9
Training loss: 0.09499356895685196
Validation loss: 1.4887791974570161

Epoch: 5| Step: 10
Training loss: 0.08026289194822311
Validation loss: 1.509498696173391

Epoch: 550| Step: 0
Training loss: 0.0783846527338028
Validation loss: 1.5030458896390853

Epoch: 5| Step: 1
Training loss: 0.06442194432020187
Validation loss: 1.4863838495746735

Epoch: 5| Step: 2
Training loss: 0.09090033918619156
Validation loss: 1.5127081524941228

Epoch: 5| Step: 3
Training loss: 0.10384998470544815
Validation loss: 1.532890845370549

Epoch: 5| Step: 4
Training loss: 0.08849506080150604
Validation loss: 1.5396195022008752

Epoch: 5| Step: 5
Training loss: 0.1003631204366684
Validation loss: 1.506572772097844

Epoch: 5| Step: 6
Training loss: 0.07795095443725586
Validation loss: 1.5204796823122169

Epoch: 5| Step: 7
Training loss: 0.1123269572854042
Validation loss: 1.5052339594851258

Epoch: 5| Step: 8
Training loss: 0.11054398864507675
Validation loss: 1.543337522014495

Epoch: 5| Step: 9
Training loss: 0.1383216381072998
Validation loss: 1.5434874180824525

Epoch: 5| Step: 10
Training loss: 0.16403447091579437
Validation loss: 1.534696380938253

Epoch: 551| Step: 0
Training loss: 0.1813560426235199
Validation loss: 1.555489545227379

Epoch: 5| Step: 1
Training loss: 0.10324849933385849
Validation loss: 1.5368433498567151

Epoch: 5| Step: 2
Training loss: 0.06615665555000305
Validation loss: 1.5536795175203713

Epoch: 5| Step: 3
Training loss: 0.10245434939861298
Validation loss: 1.5689942811125068

Epoch: 5| Step: 4
Training loss: 0.08715075999498367
Validation loss: 1.5821488403504895

Epoch: 5| Step: 5
Training loss: 0.17257770895957947
Validation loss: 1.5967024180196947

Epoch: 5| Step: 6
Training loss: 0.1817377507686615
Validation loss: 1.5690853954643331

Epoch: 5| Step: 7
Training loss: 0.08865497261285782
Validation loss: 1.5484992945066063

Epoch: 5| Step: 8
Training loss: 0.09140925109386444
Validation loss: 1.5352483398170882

Epoch: 5| Step: 9
Training loss: 0.07105915248394012
Validation loss: 1.5163876702708583

Epoch: 5| Step: 10
Training loss: 0.08207584172487259
Validation loss: 1.5020645549220424

Epoch: 552| Step: 0
Training loss: 0.1578943431377411
Validation loss: 1.468068140809254

Epoch: 5| Step: 1
Training loss: 0.09917628765106201
Validation loss: 1.5014847427286127

Epoch: 5| Step: 2
Training loss: 0.160565584897995
Validation loss: 1.4916981471482145

Epoch: 5| Step: 3
Training loss: 0.1702069342136383
Validation loss: 1.5073880572472849

Epoch: 5| Step: 4
Training loss: 0.09739278256893158
Validation loss: 1.5198090332810597

Epoch: 5| Step: 5
Training loss: 0.07792407274246216
Validation loss: 1.523970542415496

Epoch: 5| Step: 6
Training loss: 0.13860607147216797
Validation loss: 1.5570536153290861

Epoch: 5| Step: 7
Training loss: 0.138572558760643
Validation loss: 1.5713177880933207

Epoch: 5| Step: 8
Training loss: 0.10120105743408203
Validation loss: 1.5550095035183815

Epoch: 5| Step: 9
Training loss: 0.1144508570432663
Validation loss: 1.5477427333913825

Epoch: 5| Step: 10
Training loss: 0.11732804775238037
Validation loss: 1.5155571686324252

Epoch: 553| Step: 0
Training loss: 0.15262135863304138
Validation loss: 1.5120266816949333

Epoch: 5| Step: 1
Training loss: 0.07839757949113846
Validation loss: 1.484731896590161

Epoch: 5| Step: 2
Training loss: 0.12854301929473877
Validation loss: 1.503697035774108

Epoch: 5| Step: 3
Training loss: 0.07734347879886627
Validation loss: 1.5179087115872292

Epoch: 5| Step: 4
Training loss: 0.0725085437297821
Validation loss: 1.5317951274174515

Epoch: 5| Step: 5
Training loss: 0.09722138941287994
Validation loss: 1.5472510283993137

Epoch: 5| Step: 6
Training loss: 0.08413856476545334
Validation loss: 1.542411288907451

Epoch: 5| Step: 7
Training loss: 0.128603994846344
Validation loss: 1.541140898581474

Epoch: 5| Step: 8
Training loss: 0.14562958478927612
Validation loss: 1.5529762262939124

Epoch: 5| Step: 9
Training loss: 0.11803209781646729
Validation loss: 1.53605915077271

Epoch: 5| Step: 10
Training loss: 0.06511570513248444
Validation loss: 1.537748118241628

Epoch: 554| Step: 0
Training loss: 0.07038851082324982
Validation loss: 1.510857916647388

Epoch: 5| Step: 1
Training loss: 0.0843239575624466
Validation loss: 1.493408856853362

Epoch: 5| Step: 2
Training loss: 0.07668675482273102
Validation loss: 1.5001584714458835

Epoch: 5| Step: 3
Training loss: 0.12825825810432434
Validation loss: 1.4726203116037513

Epoch: 5| Step: 4
Training loss: 0.1039385050535202
Validation loss: 1.4600048898368754

Epoch: 5| Step: 5
Training loss: 0.07848234474658966
Validation loss: 1.4540174058688584

Epoch: 5| Step: 6
Training loss: 0.11973259598016739
Validation loss: 1.4624831432937293

Epoch: 5| Step: 7
Training loss: 0.14739353954792023
Validation loss: 1.4994800039516982

Epoch: 5| Step: 8
Training loss: 0.08448337018489838
Validation loss: 1.5186115452038345

Epoch: 5| Step: 9
Training loss: 0.10875780880451202
Validation loss: 1.5426536029384983

Epoch: 5| Step: 10
Training loss: 0.10738469660282135
Validation loss: 1.5658150257602814

Epoch: 555| Step: 0
Training loss: 0.06816863268613815
Validation loss: 1.5520751848015735

Epoch: 5| Step: 1
Training loss: 0.058406613767147064
Validation loss: 1.5417090154463244

Epoch: 5| Step: 2
Training loss: 0.08388475328683853
Validation loss: 1.5705967052008516

Epoch: 5| Step: 3
Training loss: 0.08446405827999115
Validation loss: 1.5846632924131168

Epoch: 5| Step: 4
Training loss: 0.09956496953964233
Validation loss: 1.5787862770019039

Epoch: 5| Step: 5
Training loss: 0.07211469858884811
Validation loss: 1.5686387669655584

Epoch: 5| Step: 6
Training loss: 0.12530021369457245
Validation loss: 1.5565544405291158

Epoch: 5| Step: 7
Training loss: 0.09844254702329636
Validation loss: 1.5597503339090655

Epoch: 5| Step: 8
Training loss: 0.09511569142341614
Validation loss: 1.5259953378349222

Epoch: 5| Step: 9
Training loss: 0.1099417433142662
Validation loss: 1.510435927298761

Epoch: 5| Step: 10
Training loss: 0.212254136800766
Validation loss: 1.5091820416911956

Epoch: 556| Step: 0
Training loss: 0.14524775743484497
Validation loss: 1.511447065620012

Epoch: 5| Step: 1
Training loss: 0.09669096767902374
Validation loss: 1.513197111827071

Epoch: 5| Step: 2
Training loss: 0.11045847833156586
Validation loss: 1.4992976214296074

Epoch: 5| Step: 3
Training loss: 0.10782022774219513
Validation loss: 1.5414954923814344

Epoch: 5| Step: 4
Training loss: 0.08872610330581665
Validation loss: 1.551265166651818

Epoch: 5| Step: 5
Training loss: 0.09389914572238922
Validation loss: 1.528093736658814

Epoch: 5| Step: 6
Training loss: 0.1550096571445465
Validation loss: 1.5083145069819626

Epoch: 5| Step: 7
Training loss: 0.06817110627889633
Validation loss: 1.5204763040747693

Epoch: 5| Step: 8
Training loss: 0.08941054344177246
Validation loss: 1.4755699724279425

Epoch: 5| Step: 9
Training loss: 0.06865623593330383
Validation loss: 1.4679067852676555

Epoch: 5| Step: 10
Training loss: 0.09491957724094391
Validation loss: 1.4579814659651888

Epoch: 557| Step: 0
Training loss: 0.19120123982429504
Validation loss: 1.4797846117327291

Epoch: 5| Step: 1
Training loss: 0.12507745623588562
Validation loss: 1.475779898705021

Epoch: 5| Step: 2
Training loss: 0.12501183152198792
Validation loss: 1.495075419384946

Epoch: 5| Step: 3
Training loss: 0.13174453377723694
Validation loss: 1.5046993737579675

Epoch: 5| Step: 4
Training loss: 0.10068446397781372
Validation loss: 1.5089703676521138

Epoch: 5| Step: 5
Training loss: 0.09538072347640991
Validation loss: 1.4955583567260413

Epoch: 5| Step: 6
Training loss: 0.07469075918197632
Validation loss: 1.5253264263112059

Epoch: 5| Step: 7
Training loss: 0.055295430123806
Validation loss: 1.5533206937133626

Epoch: 5| Step: 8
Training loss: 0.1284162998199463
Validation loss: 1.5529611834915735

Epoch: 5| Step: 9
Training loss: 0.10500109195709229
Validation loss: 1.568450976443547

Epoch: 5| Step: 10
Training loss: 0.08234673738479614
Validation loss: 1.5367396031656573

Epoch: 558| Step: 0
Training loss: 0.1253085434436798
Validation loss: 1.5463886542986798

Epoch: 5| Step: 1
Training loss: 0.09273061901330948
Validation loss: 1.4753165873148109

Epoch: 5| Step: 2
Training loss: 0.1191396713256836
Validation loss: 1.4913126262285377

Epoch: 5| Step: 3
Training loss: 0.1128951758146286
Validation loss: 1.5005352381737

Epoch: 5| Step: 4
Training loss: 0.1283983588218689
Validation loss: 1.4984749004405031

Epoch: 5| Step: 5
Training loss: 0.0936564952135086
Validation loss: 1.463060543101321

Epoch: 5| Step: 6
Training loss: 0.09702451527118683
Validation loss: 1.4845133776305823

Epoch: 5| Step: 7
Training loss: 0.04416279122233391
Validation loss: 1.4948536247335455

Epoch: 5| Step: 8
Training loss: 0.08200179040431976
Validation loss: 1.512454745590046

Epoch: 5| Step: 9
Training loss: 0.14912855625152588
Validation loss: 1.5398104626645324

Epoch: 5| Step: 10
Training loss: 0.09239237755537033
Validation loss: 1.5338056856586086

Epoch: 559| Step: 0
Training loss: 0.09660789370536804
Validation loss: 1.538204272588094

Epoch: 5| Step: 1
Training loss: 0.10024430602788925
Validation loss: 1.5437868359268352

Epoch: 5| Step: 2
Training loss: 0.0941094160079956
Validation loss: 1.545062316361294

Epoch: 5| Step: 3
Training loss: 0.10437468439340591
Validation loss: 1.5137699316906672

Epoch: 5| Step: 4
Training loss: 0.06886349618434906
Validation loss: 1.4998106636026853

Epoch: 5| Step: 5
Training loss: 0.07644806802272797
Validation loss: 1.4584590376064341

Epoch: 5| Step: 6
Training loss: 0.11587107181549072
Validation loss: 1.4716074799978605

Epoch: 5| Step: 7
Training loss: 0.09959334135055542
Validation loss: 1.4854448892736947

Epoch: 5| Step: 8
Training loss: 0.08653240650892258
Validation loss: 1.4666894315391459

Epoch: 5| Step: 9
Training loss: 0.13016550242900848
Validation loss: 1.4482776041953795

Epoch: 5| Step: 10
Training loss: 0.06857678294181824
Validation loss: 1.4832365243665633

Epoch: 560| Step: 0
Training loss: 0.09310740232467651
Validation loss: 1.4805959706665368

Epoch: 5| Step: 1
Training loss: 0.09716947376728058
Validation loss: 1.4915852617192011

Epoch: 5| Step: 2
Training loss: 0.06661896407604218
Validation loss: 1.5055750326443744

Epoch: 5| Step: 3
Training loss: 0.09571439027786255
Validation loss: 1.5157779788458219

Epoch: 5| Step: 4
Training loss: 0.08623157441616058
Validation loss: 1.5313487386190763

Epoch: 5| Step: 5
Training loss: 0.12413656711578369
Validation loss: 1.5313263740590823

Epoch: 5| Step: 6
Training loss: 0.10832077264785767
Validation loss: 1.5265722941326838

Epoch: 5| Step: 7
Training loss: 0.08066684752702713
Validation loss: 1.5017120440800984

Epoch: 5| Step: 8
Training loss: 0.1324138045310974
Validation loss: 1.5097642470431585

Epoch: 5| Step: 9
Training loss: 0.08175612986087799
Validation loss: 1.4851818507717502

Epoch: 5| Step: 10
Training loss: 0.10084451735019684
Validation loss: 1.4846001055932814

Epoch: 561| Step: 0
Training loss: 0.1322956085205078
Validation loss: 1.4741628669923352

Epoch: 5| Step: 1
Training loss: 0.06166114658117294
Validation loss: 1.4725503216507614

Epoch: 5| Step: 2
Training loss: 0.09112691134214401
Validation loss: 1.4980592458478865

Epoch: 5| Step: 3
Training loss: 0.11462587118148804
Validation loss: 1.4972256140042377

Epoch: 5| Step: 4
Training loss: 0.08355941623449326
Validation loss: 1.5072215282788841

Epoch: 5| Step: 5
Training loss: 0.15737739205360413
Validation loss: 1.559930573227585

Epoch: 5| Step: 6
Training loss: 0.08183477818965912
Validation loss: 1.5616725029483918

Epoch: 5| Step: 7
Training loss: 0.08787871897220612
Validation loss: 1.5843217795894993

Epoch: 5| Step: 8
Training loss: 0.0895392894744873
Validation loss: 1.5571082932974702

Epoch: 5| Step: 9
Training loss: 0.1326238214969635
Validation loss: 1.5510023447775072

Epoch: 5| Step: 10
Training loss: 0.07989338785409927
Validation loss: 1.5441551772497033

Epoch: 562| Step: 0
Training loss: 0.07570452988147736
Validation loss: 1.509336099829725

Epoch: 5| Step: 1
Training loss: 0.1308285892009735
Validation loss: 1.4808289466365692

Epoch: 5| Step: 2
Training loss: 0.05968315154314041
Validation loss: 1.512037532303923

Epoch: 5| Step: 3
Training loss: 0.12068699300289154
Validation loss: 1.5377104538743214

Epoch: 5| Step: 4
Training loss: 0.06707755476236343
Validation loss: 1.5027229414191297

Epoch: 5| Step: 5
Training loss: 0.10801198333501816
Validation loss: 1.5337768575196624

Epoch: 5| Step: 6
Training loss: 0.05930667370557785
Validation loss: 1.5117067906164354

Epoch: 5| Step: 7
Training loss: 0.11920835077762604
Validation loss: 1.5225741863250732

Epoch: 5| Step: 8
Training loss: 0.09753947705030441
Validation loss: 1.5118654331853312

Epoch: 5| Step: 9
Training loss: 0.08940502256155014
Validation loss: 1.5384362359200754

Epoch: 5| Step: 10
Training loss: 0.06768078356981277
Validation loss: 1.5299115642424552

Epoch: 563| Step: 0
Training loss: 0.07964801788330078
Validation loss: 1.5432731041344263

Epoch: 5| Step: 1
Training loss: 0.06225010007619858
Validation loss: 1.51547283511008

Epoch: 5| Step: 2
Training loss: 0.1035223975777626
Validation loss: 1.5130500819093438

Epoch: 5| Step: 3
Training loss: 0.13011440634727478
Validation loss: 1.5170530349977556

Epoch: 5| Step: 4
Training loss: 0.134654700756073
Validation loss: 1.5090638065850863

Epoch: 5| Step: 5
Training loss: 0.10564590990543365
Validation loss: 1.4876724263673187

Epoch: 5| Step: 6
Training loss: 0.07193517684936523
Validation loss: 1.5184986309338642

Epoch: 5| Step: 7
Training loss: 0.08610597252845764
Validation loss: 1.535707437863914

Epoch: 5| Step: 8
Training loss: 0.15740986168384552
Validation loss: 1.5375847970285723

Epoch: 5| Step: 9
Training loss: 0.08562701940536499
Validation loss: 1.552961580855872

Epoch: 5| Step: 10
Training loss: 0.10416746139526367
Validation loss: 1.5644839681604856

Epoch: 564| Step: 0
Training loss: 0.10634191334247589
Validation loss: 1.5712912262126963

Epoch: 5| Step: 1
Training loss: 0.17776551842689514
Validation loss: 1.5733540750318957

Epoch: 5| Step: 2
Training loss: 0.12077194452285767
Validation loss: 1.5482896310026928

Epoch: 5| Step: 3
Training loss: 0.06536741554737091
Validation loss: 1.5164600315914358

Epoch: 5| Step: 4
Training loss: 0.09557685256004333
Validation loss: 1.4841550139970676

Epoch: 5| Step: 5
Training loss: 0.08027839660644531
Validation loss: 1.495278686605474

Epoch: 5| Step: 6
Training loss: 0.07793682813644409
Validation loss: 1.4537979056758266

Epoch: 5| Step: 7
Training loss: 0.0731225460767746
Validation loss: 1.4456787083738594

Epoch: 5| Step: 8
Training loss: 0.12011981010437012
Validation loss: 1.4563499291737874

Epoch: 5| Step: 9
Training loss: 0.15384931862354279
Validation loss: 1.4337603789503857

Epoch: 5| Step: 10
Training loss: 0.055306293070316315
Validation loss: 1.4780520957003358

Epoch: 565| Step: 0
Training loss: 0.06794341653585434
Validation loss: 1.471912440433297

Epoch: 5| Step: 1
Training loss: 0.11039795726537704
Validation loss: 1.4708811134420416

Epoch: 5| Step: 2
Training loss: 0.10008583217859268
Validation loss: 1.4881488174520514

Epoch: 5| Step: 3
Training loss: 0.09596845507621765
Validation loss: 1.5218022305478331

Epoch: 5| Step: 4
Training loss: 0.07587432861328125
Validation loss: 1.545634469678325

Epoch: 5| Step: 5
Training loss: 0.05915128067135811
Validation loss: 1.518569197705997

Epoch: 5| Step: 6
Training loss: 0.09023965150117874
Validation loss: 1.5341292145431682

Epoch: 5| Step: 7
Training loss: 0.1273806095123291
Validation loss: 1.5091262145708966

Epoch: 5| Step: 8
Training loss: 0.0762036070227623
Validation loss: 1.5182311919427687

Epoch: 5| Step: 9
Training loss: 0.09506875276565552
Validation loss: 1.4986463938989947

Epoch: 5| Step: 10
Training loss: 0.08570818603038788
Validation loss: 1.4975445930675795

Epoch: 566| Step: 0
Training loss: 0.11613025516271591
Validation loss: 1.4891675915769351

Epoch: 5| Step: 1
Training loss: 0.07783524692058563
Validation loss: 1.497255777799955

Epoch: 5| Step: 2
Training loss: 0.16031315922737122
Validation loss: 1.500028379501835

Epoch: 5| Step: 3
Training loss: 0.09503283351659775
Validation loss: 1.4909548528732792

Epoch: 5| Step: 4
Training loss: 0.09943042695522308
Validation loss: 1.4982187837682746

Epoch: 5| Step: 5
Training loss: 0.08711163699626923
Validation loss: 1.5286379155292307

Epoch: 5| Step: 6
Training loss: 0.10803095996379852
Validation loss: 1.5091971383299878

Epoch: 5| Step: 7
Training loss: 0.145845428109169
Validation loss: 1.548682032092925

Epoch: 5| Step: 8
Training loss: 0.13780048489570618
Validation loss: 1.539592073809716

Epoch: 5| Step: 9
Training loss: 0.09468181431293488
Validation loss: 1.5408268308126798

Epoch: 5| Step: 10
Training loss: 0.06892527639865875
Validation loss: 1.5014692109118226

Epoch: 567| Step: 0
Training loss: 0.07826953381299973
Validation loss: 1.5007142802720428

Epoch: 5| Step: 1
Training loss: 0.11868355423212051
Validation loss: 1.4819297021435154

Epoch: 5| Step: 2
Training loss: 0.09402511268854141
Validation loss: 1.4728281600500948

Epoch: 5| Step: 3
Training loss: 0.0848802998661995
Validation loss: 1.4836787767307733

Epoch: 5| Step: 4
Training loss: 0.10153494030237198
Validation loss: 1.448294544732699

Epoch: 5| Step: 5
Training loss: 0.09467093646526337
Validation loss: 1.489784897014659

Epoch: 5| Step: 6
Training loss: 0.09381715208292007
Validation loss: 1.4834183300695112

Epoch: 5| Step: 7
Training loss: 0.08349965512752533
Validation loss: 1.5110942240684264

Epoch: 5| Step: 8
Training loss: 0.11920158565044403
Validation loss: 1.5081560457906416

Epoch: 5| Step: 9
Training loss: 0.1420058310031891
Validation loss: 1.528139893726636

Epoch: 5| Step: 10
Training loss: 0.1196356937289238
Validation loss: 1.5138960282007854

Epoch: 568| Step: 0
Training loss: 0.05615047365427017
Validation loss: 1.4919699122828822

Epoch: 5| Step: 1
Training loss: 0.0976233258843422
Validation loss: 1.4916979907661356

Epoch: 5| Step: 2
Training loss: 0.17371824383735657
Validation loss: 1.453969652934741

Epoch: 5| Step: 3
Training loss: 0.05862585827708244
Validation loss: 1.4842469583275497

Epoch: 5| Step: 4
Training loss: 0.08141231536865234
Validation loss: 1.4858947248869045

Epoch: 5| Step: 5
Training loss: 0.08286267518997192
Validation loss: 1.504724803470796

Epoch: 5| Step: 6
Training loss: 0.066886767745018
Validation loss: 1.5123641824209562

Epoch: 5| Step: 7
Training loss: 0.08105632662773132
Validation loss: 1.5061583929164435

Epoch: 5| Step: 8
Training loss: 0.06333077698945999
Validation loss: 1.5006716353918916

Epoch: 5| Step: 9
Training loss: 0.0840793251991272
Validation loss: 1.505461444136917

Epoch: 5| Step: 10
Training loss: 0.08507096767425537
Validation loss: 1.4943640680723294

Epoch: 569| Step: 0
Training loss: 0.08858969062566757
Validation loss: 1.5195743935082549

Epoch: 5| Step: 1
Training loss: 0.10879838466644287
Validation loss: 1.5310232036857194

Epoch: 5| Step: 2
Training loss: 0.09238354861736298
Validation loss: 1.5569326531502508

Epoch: 5| Step: 3
Training loss: 0.12994089722633362
Validation loss: 1.5499586623202088

Epoch: 5| Step: 4
Training loss: 0.0556442029774189
Validation loss: 1.543069689504562

Epoch: 5| Step: 5
Training loss: 0.06424325704574585
Validation loss: 1.4995765577080429

Epoch: 5| Step: 6
Training loss: 0.10239867866039276
Validation loss: 1.4819902771262712

Epoch: 5| Step: 7
Training loss: 0.0865447148680687
Validation loss: 1.4798542056032407

Epoch: 5| Step: 8
Training loss: 0.16825900971889496
Validation loss: 1.495945163952407

Epoch: 5| Step: 9
Training loss: 0.0646459087729454
Validation loss: 1.5053903569457352

Epoch: 5| Step: 10
Training loss: 0.07613859325647354
Validation loss: 1.522684576690838

Epoch: 570| Step: 0
Training loss: 0.05662710219621658
Validation loss: 1.5434473201792727

Epoch: 5| Step: 1
Training loss: 0.08081551641225815
Validation loss: 1.515535084791081

Epoch: 5| Step: 2
Training loss: 0.09712132066488266
Validation loss: 1.523352688358676

Epoch: 5| Step: 3
Training loss: 0.05607889965176582
Validation loss: 1.5232259714475243

Epoch: 5| Step: 4
Training loss: 0.08997051417827606
Validation loss: 1.522380345611162

Epoch: 5| Step: 5
Training loss: 0.07428296655416489
Validation loss: 1.495315174902639

Epoch: 5| Step: 6
Training loss: 0.11374932527542114
Validation loss: 1.5031466663524669

Epoch: 5| Step: 7
Training loss: 0.07499317824840546
Validation loss: 1.486720424185517

Epoch: 5| Step: 8
Training loss: 0.10986338555812836
Validation loss: 1.4927945688206663

Epoch: 5| Step: 9
Training loss: 0.16471333801746368
Validation loss: 1.4771515810361473

Epoch: 5| Step: 10
Training loss: 0.087087482213974
Validation loss: 1.4503201566716677

Epoch: 571| Step: 0
Training loss: 0.06949985027313232
Validation loss: 1.4749609802358894

Epoch: 5| Step: 1
Training loss: 0.07916049659252167
Validation loss: 1.4887042135320685

Epoch: 5| Step: 2
Training loss: 0.10135491192340851
Validation loss: 1.4938217619413972

Epoch: 5| Step: 3
Training loss: 0.083043172955513
Validation loss: 1.5013530433818858

Epoch: 5| Step: 4
Training loss: 0.10951954126358032
Validation loss: 1.5232261880751579

Epoch: 5| Step: 5
Training loss: 0.10880808532238007
Validation loss: 1.5013266404469807

Epoch: 5| Step: 6
Training loss: 0.059349726885557175
Validation loss: 1.4732651556691816

Epoch: 5| Step: 7
Training loss: 0.06759654730558395
Validation loss: 1.4838100543586157

Epoch: 5| Step: 8
Training loss: 0.11595549434423447
Validation loss: 1.4978125608095558

Epoch: 5| Step: 9
Training loss: 0.05630495026707649
Validation loss: 1.4734522988719325

Epoch: 5| Step: 10
Training loss: 0.0827636867761612
Validation loss: 1.4889027546810847

Epoch: 572| Step: 0
Training loss: 0.07769725471735
Validation loss: 1.484860929750627

Epoch: 5| Step: 1
Training loss: 0.0956953912973404
Validation loss: 1.4944563078623947

Epoch: 5| Step: 2
Training loss: 0.08542709052562714
Validation loss: 1.4960702978154665

Epoch: 5| Step: 3
Training loss: 0.1161373034119606
Validation loss: 1.4807527283186555

Epoch: 5| Step: 4
Training loss: 0.059666119515895844
Validation loss: 1.4947539516674575

Epoch: 5| Step: 5
Training loss: 0.07677958905696869
Validation loss: 1.4827245550770913

Epoch: 5| Step: 6
Training loss: 0.14620307087898254
Validation loss: 1.5139324331796298

Epoch: 5| Step: 7
Training loss: 0.16454364359378815
Validation loss: 1.524918697213614

Epoch: 5| Step: 8
Training loss: 0.11664564907550812
Validation loss: 1.4957874744169173

Epoch: 5| Step: 9
Training loss: 0.03386538475751877
Validation loss: 1.5137519554425312

Epoch: 5| Step: 10
Training loss: 0.104388028383255
Validation loss: 1.5204699218914073

Epoch: 573| Step: 0
Training loss: 0.0688977837562561
Validation loss: 1.5317215996403848

Epoch: 5| Step: 1
Training loss: 0.07598647475242615
Validation loss: 1.5290548570694462

Epoch: 5| Step: 2
Training loss: 0.08032013475894928
Validation loss: 1.519275939592751

Epoch: 5| Step: 3
Training loss: 0.14108192920684814
Validation loss: 1.5511703978302658

Epoch: 5| Step: 4
Training loss: 0.14229333400726318
Validation loss: 1.5244246054721136

Epoch: 5| Step: 5
Training loss: 0.08093947172164917
Validation loss: 1.502408032776207

Epoch: 5| Step: 6
Training loss: 0.06357108056545258
Validation loss: 1.4553085757840065

Epoch: 5| Step: 7
Training loss: 0.07080189883708954
Validation loss: 1.4583548102327573

Epoch: 5| Step: 8
Training loss: 0.1421099603176117
Validation loss: 1.4449228900735096

Epoch: 5| Step: 9
Training loss: 0.06232236698269844
Validation loss: 1.4552188214435373

Epoch: 5| Step: 10
Training loss: 0.1746976673603058
Validation loss: 1.4567305490534792

Epoch: 574| Step: 0
Training loss: 0.1221485361456871
Validation loss: 1.4637545693305232

Epoch: 5| Step: 1
Training loss: 0.12262686342000961
Validation loss: 1.4471189155373523

Epoch: 5| Step: 2
Training loss: 0.04319312050938606
Validation loss: 1.467780501611771

Epoch: 5| Step: 3
Training loss: 0.10393276065587997
Validation loss: 1.5087813151779996

Epoch: 5| Step: 4
Training loss: 0.08246802538633347
Validation loss: 1.4844439644967355

Epoch: 5| Step: 5
Training loss: 0.07263269275426865
Validation loss: 1.5026343919897591

Epoch: 5| Step: 6
Training loss: 0.10280527174472809
Validation loss: 1.5019871630976278

Epoch: 5| Step: 7
Training loss: 0.10040239989757538
Validation loss: 1.475087845197288

Epoch: 5| Step: 8
Training loss: 0.08789993822574615
Validation loss: 1.4857643163332375

Epoch: 5| Step: 9
Training loss: 0.07450133562088013
Validation loss: 1.4467927422574771

Epoch: 5| Step: 10
Training loss: 0.07479804009199142
Validation loss: 1.4585157132917834

Epoch: 575| Step: 0
Training loss: 0.06358690559864044
Validation loss: 1.4679822268024567

Epoch: 5| Step: 1
Training loss: 0.055501580238342285
Validation loss: 1.5008561880357805

Epoch: 5| Step: 2
Training loss: 0.10704468190670013
Validation loss: 1.476248707181664

Epoch: 5| Step: 3
Training loss: 0.08427280187606812
Validation loss: 1.482176229517947

Epoch: 5| Step: 4
Training loss: 0.09040011465549469
Validation loss: 1.5002262489770049

Epoch: 5| Step: 5
Training loss: 0.07700682431459427
Validation loss: 1.5126776169705134

Epoch: 5| Step: 6
Training loss: 0.06379435211420059
Validation loss: 1.545017142449656

Epoch: 5| Step: 7
Training loss: 0.08797945827245712
Validation loss: 1.5413614498671664

Epoch: 5| Step: 8
Training loss: 0.08565889298915863
Validation loss: 1.501269168751214

Epoch: 5| Step: 9
Training loss: 0.07525177299976349
Validation loss: 1.5309808215787333

Epoch: 5| Step: 10
Training loss: 0.1481381058692932
Validation loss: 1.5388652964304852

Epoch: 576| Step: 0
Training loss: 0.07050365209579468
Validation loss: 1.5366103533775575

Epoch: 5| Step: 1
Training loss: 0.11230595409870148
Validation loss: 1.528294567138918

Epoch: 5| Step: 2
Training loss: 0.08853043615818024
Validation loss: 1.4856528915384764

Epoch: 5| Step: 3
Training loss: 0.05935247614979744
Validation loss: 1.499367335791229

Epoch: 5| Step: 4
Training loss: 0.09260226041078568
Validation loss: 1.4853747711386731

Epoch: 5| Step: 5
Training loss: 0.12799081206321716
Validation loss: 1.4700732154230918

Epoch: 5| Step: 6
Training loss: 0.08325591683387756
Validation loss: 1.4461003593219224

Epoch: 5| Step: 7
Training loss: 0.08490066975355148
Validation loss: 1.4806020285493584

Epoch: 5| Step: 8
Training loss: 0.0972268283367157
Validation loss: 1.4696169912174184

Epoch: 5| Step: 9
Training loss: 0.04553157836198807
Validation loss: 1.475113594403831

Epoch: 5| Step: 10
Training loss: 0.05843120068311691
Validation loss: 1.4891487334364204

Epoch: 577| Step: 0
Training loss: 0.16407497227191925
Validation loss: 1.534498248049008

Epoch: 5| Step: 1
Training loss: 0.06829135864973068
Validation loss: 1.4752856903178717

Epoch: 5| Step: 2
Training loss: 0.13607662916183472
Validation loss: 1.4987811644872029

Epoch: 5| Step: 3
Training loss: 0.08273054659366608
Validation loss: 1.463566501935323

Epoch: 5| Step: 4
Training loss: 0.06853092461824417
Validation loss: 1.437925273372281

Epoch: 5| Step: 5
Training loss: 0.07960377633571625
Validation loss: 1.4620261743504515

Epoch: 5| Step: 6
Training loss: 0.09372025728225708
Validation loss: 1.4797231958758446

Epoch: 5| Step: 7
Training loss: 0.13272342085838318
Validation loss: 1.480937337362638

Epoch: 5| Step: 8
Training loss: 0.09964650869369507
Validation loss: 1.4811401944006644

Epoch: 5| Step: 9
Training loss: 0.09085255861282349
Validation loss: 1.4890186914833643

Epoch: 5| Step: 10
Training loss: 0.11837232857942581
Validation loss: 1.543933996590235

Epoch: 578| Step: 0
Training loss: 0.11455657333135605
Validation loss: 1.5611038913008988

Epoch: 5| Step: 1
Training loss: 0.08627112209796906
Validation loss: 1.5893845045438377

Epoch: 5| Step: 2
Training loss: 0.09857149422168732
Validation loss: 1.5953562926220637

Epoch: 5| Step: 3
Training loss: 0.10291401296854019
Validation loss: 1.5525268803360641

Epoch: 5| Step: 4
Training loss: 0.09112296998500824
Validation loss: 1.5534179056844404

Epoch: 5| Step: 5
Training loss: 0.07360796630382538
Validation loss: 1.520726098809191

Epoch: 5| Step: 6
Training loss: 0.08472496271133423
Validation loss: 1.5314586265112764

Epoch: 5| Step: 7
Training loss: 0.09423483908176422
Validation loss: 1.5285101923891293

Epoch: 5| Step: 8
Training loss: 0.06528711318969727
Validation loss: 1.4851849066313876

Epoch: 5| Step: 9
Training loss: 0.07144740968942642
Validation loss: 1.4843536769190142

Epoch: 5| Step: 10
Training loss: 0.07328621298074722
Validation loss: 1.4724127464396979

Epoch: 579| Step: 0
Training loss: 0.12012408673763275
Validation loss: 1.4526189270839895

Epoch: 5| Step: 1
Training loss: 0.03936901316046715
Validation loss: 1.4696203726594166

Epoch: 5| Step: 2
Training loss: 0.10232953727245331
Validation loss: 1.4798252941459737

Epoch: 5| Step: 3
Training loss: 0.08407348394393921
Validation loss: 1.4642734912133986

Epoch: 5| Step: 4
Training loss: 0.06518763303756714
Validation loss: 1.463570257668854

Epoch: 5| Step: 5
Training loss: 0.08866678178310394
Validation loss: 1.4695255961469424

Epoch: 5| Step: 6
Training loss: 0.07739551365375519
Validation loss: 1.4797904824697843

Epoch: 5| Step: 7
Training loss: 0.11239210516214371
Validation loss: 1.4948433035163469

Epoch: 5| Step: 8
Training loss: 0.056549228727817535
Validation loss: 1.4719030023902975

Epoch: 5| Step: 9
Training loss: 0.07676424086093903
Validation loss: 1.498002076661715

Epoch: 5| Step: 10
Training loss: 0.08993227034807205
Validation loss: 1.5052884868396226

Epoch: 580| Step: 0
Training loss: 0.077103391289711
Validation loss: 1.5466416651202786

Epoch: 5| Step: 1
Training loss: 0.08352841436862946
Validation loss: 1.5289695134726904

Epoch: 5| Step: 2
Training loss: 0.05774746090173721
Validation loss: 1.5377818256296136

Epoch: 5| Step: 3
Training loss: 0.044058170169591904
Validation loss: 1.5290281285521805

Epoch: 5| Step: 4
Training loss: 0.1116986870765686
Validation loss: 1.5036973453337146

Epoch: 5| Step: 5
Training loss: 0.06767766922712326
Validation loss: 1.4806161234455724

Epoch: 5| Step: 6
Training loss: 0.08599022775888443
Validation loss: 1.499192004562706

Epoch: 5| Step: 7
Training loss: 0.141042098402977
Validation loss: 1.5145608968632196

Epoch: 5| Step: 8
Training loss: 0.09992460906505585
Validation loss: 1.4894769114832724

Epoch: 5| Step: 9
Training loss: 0.07384215295314789
Validation loss: 1.506448858527727

Epoch: 5| Step: 10
Training loss: 0.07348264008760452
Validation loss: 1.4943666855494182

Epoch: 581| Step: 0
Training loss: 0.05964291840791702
Validation loss: 1.5100468781686598

Epoch: 5| Step: 1
Training loss: 0.08106452226638794
Validation loss: 1.484609898700509

Epoch: 5| Step: 2
Training loss: 0.08635614812374115
Validation loss: 1.5068415134183821

Epoch: 5| Step: 3
Training loss: 0.07820574939250946
Validation loss: 1.497700604059363

Epoch: 5| Step: 4
Training loss: 0.06097844988107681
Validation loss: 1.4869163690074798

Epoch: 5| Step: 5
Training loss: 0.10932356119155884
Validation loss: 1.4771726721076555

Epoch: 5| Step: 6
Training loss: 0.13199745118618011
Validation loss: 1.5033701235248196

Epoch: 5| Step: 7
Training loss: 0.10555148124694824
Validation loss: 1.5064463115507556

Epoch: 5| Step: 8
Training loss: 0.05213113874197006
Validation loss: 1.5049198365980578

Epoch: 5| Step: 9
Training loss: 0.08420203626155853
Validation loss: 1.5057219664255779

Epoch: 5| Step: 10
Training loss: 0.09545092284679413
Validation loss: 1.4918188856494041

Epoch: 582| Step: 0
Training loss: 0.059802986681461334
Validation loss: 1.512010144931014

Epoch: 5| Step: 1
Training loss: 0.07470973581075668
Validation loss: 1.4914328718698153

Epoch: 5| Step: 2
Training loss: 0.10240118205547333
Validation loss: 1.5206039515874719

Epoch: 5| Step: 3
Training loss: 0.10121283680200577
Validation loss: 1.5012983686180525

Epoch: 5| Step: 4
Training loss: 0.07965421676635742
Validation loss: 1.5141660116052116

Epoch: 5| Step: 5
Training loss: 0.07825684547424316
Validation loss: 1.4836808532796881

Epoch: 5| Step: 6
Training loss: 0.06161078065633774
Validation loss: 1.4643125200784335

Epoch: 5| Step: 7
Training loss: 0.0572308711707592
Validation loss: 1.4798431204211326

Epoch: 5| Step: 8
Training loss: 0.11132099479436874
Validation loss: 1.442245998049295

Epoch: 5| Step: 9
Training loss: 0.04897082969546318
Validation loss: 1.4656194217743412

Epoch: 5| Step: 10
Training loss: 0.13046570122241974
Validation loss: 1.441814189316124

Epoch: 583| Step: 0
Training loss: 0.0770760327577591
Validation loss: 1.4580595634316886

Epoch: 5| Step: 1
Training loss: 0.07141042500734329
Validation loss: 1.4686486105765066

Epoch: 5| Step: 2
Training loss: 0.14640915393829346
Validation loss: 1.4460361696058703

Epoch: 5| Step: 3
Training loss: 0.08540062606334686
Validation loss: 1.4794657140649774

Epoch: 5| Step: 4
Training loss: 0.10552415996789932
Validation loss: 1.4641772098438715

Epoch: 5| Step: 5
Training loss: 0.07846499979496002
Validation loss: 1.4644490659877818

Epoch: 5| Step: 6
Training loss: 0.07470552623271942
Validation loss: 1.4721470955879457

Epoch: 5| Step: 7
Training loss: 0.06603025645017624
Validation loss: 1.5073295741952875

Epoch: 5| Step: 8
Training loss: 0.07025918364524841
Validation loss: 1.5240743455066477

Epoch: 5| Step: 9
Training loss: 0.07699471712112427
Validation loss: 1.5144832852066203

Epoch: 5| Step: 10
Training loss: 0.11351245641708374
Validation loss: 1.5290233563351374

Epoch: 584| Step: 0
Training loss: 0.11242055892944336
Validation loss: 1.544114185917762

Epoch: 5| Step: 1
Training loss: 0.07184705883264542
Validation loss: 1.4852900812702794

Epoch: 5| Step: 2
Training loss: 0.10665114223957062
Validation loss: 1.5095486640930176

Epoch: 5| Step: 3
Training loss: 0.08326055109500885
Validation loss: 1.4978980889884375

Epoch: 5| Step: 4
Training loss: 0.08822374045848846
Validation loss: 1.4879620703317786

Epoch: 5| Step: 5
Training loss: 0.0898783951997757
Validation loss: 1.4853439561782344

Epoch: 5| Step: 6
Training loss: 0.09596870094537735
Validation loss: 1.4913060383130146

Epoch: 5| Step: 7
Training loss: 0.061716534197330475
Validation loss: 1.5023215868139779

Epoch: 5| Step: 8
Training loss: 0.05763796716928482
Validation loss: 1.4688763477469002

Epoch: 5| Step: 9
Training loss: 0.04688870906829834
Validation loss: 1.4805596015786613

Epoch: 5| Step: 10
Training loss: 0.07285933196544647
Validation loss: 1.4631517491033

Epoch: 585| Step: 0
Training loss: 0.055041275918483734
Validation loss: 1.461807943159534

Epoch: 5| Step: 1
Training loss: 0.0956098809838295
Validation loss: 1.4755283183948968

Epoch: 5| Step: 2
Training loss: 0.07429433614015579
Validation loss: 1.4884144067764282

Epoch: 5| Step: 3
Training loss: 0.14060547947883606
Validation loss: 1.4827522385504939

Epoch: 5| Step: 4
Training loss: 0.12530618906021118
Validation loss: 1.4647451087992678

Epoch: 5| Step: 5
Training loss: 0.06356428563594818
Validation loss: 1.486468566361294

Epoch: 5| Step: 6
Training loss: 0.09450320154428482
Validation loss: 1.518438862216088

Epoch: 5| Step: 7
Training loss: 0.07904579490423203
Validation loss: 1.5275822518974222

Epoch: 5| Step: 8
Training loss: 0.06673245131969452
Validation loss: 1.518391361800573

Epoch: 5| Step: 9
Training loss: 0.12319502979516983
Validation loss: 1.5307062966849214

Epoch: 5| Step: 10
Training loss: 0.06988619267940521
Validation loss: 1.5424549669347785

Epoch: 586| Step: 0
Training loss: 0.08010299503803253
Validation loss: 1.5390043066393944

Epoch: 5| Step: 1
Training loss: 0.08409290015697479
Validation loss: 1.5209931788905975

Epoch: 5| Step: 2
Training loss: 0.09873183071613312
Validation loss: 1.4858928957293112

Epoch: 5| Step: 3
Training loss: 0.08696771413087845
Validation loss: 1.493968702131702

Epoch: 5| Step: 4
Training loss: 0.13463318347930908
Validation loss: 1.4913408833165323

Epoch: 5| Step: 5
Training loss: 0.05706317350268364
Validation loss: 1.4682591922821537

Epoch: 5| Step: 6
Training loss: 0.07565627247095108
Validation loss: 1.4676397039044289

Epoch: 5| Step: 7
Training loss: 0.07238025218248367
Validation loss: 1.4669507677837084

Epoch: 5| Step: 8
Training loss: 0.08523966372013092
Validation loss: 1.4640733618890085

Epoch: 5| Step: 9
Training loss: 0.05433393642306328
Validation loss: 1.4801412141451271

Epoch: 5| Step: 10
Training loss: 0.1024470403790474
Validation loss: 1.464511973883516

Epoch: 587| Step: 0
Training loss: 0.08207596838474274
Validation loss: 1.464407350427361

Epoch: 5| Step: 1
Training loss: 0.04798401519656181
Validation loss: 1.4751712340180592

Epoch: 5| Step: 2
Training loss: 0.06041416525840759
Validation loss: 1.4965156009120326

Epoch: 5| Step: 3
Training loss: 0.06265102326869965
Validation loss: 1.494695391706241

Epoch: 5| Step: 4
Training loss: 0.06548866629600525
Validation loss: 1.4853992423703593

Epoch: 5| Step: 5
Training loss: 0.06307028234004974
Validation loss: 1.5096821220972205

Epoch: 5| Step: 6
Training loss: 0.08605097234249115
Validation loss: 1.4861354276698122

Epoch: 5| Step: 7
Training loss: 0.051229894161224365
Validation loss: 1.4999822211521927

Epoch: 5| Step: 8
Training loss: 0.12277647107839584
Validation loss: 1.496907223937332

Epoch: 5| Step: 9
Training loss: 0.08932235091924667
Validation loss: 1.5038804674661288

Epoch: 5| Step: 10
Training loss: 0.07352352142333984
Validation loss: 1.504779883610305

Epoch: 588| Step: 0
Training loss: 0.05903360992670059
Validation loss: 1.5028601423386605

Epoch: 5| Step: 1
Training loss: 0.05239409953355789
Validation loss: 1.5042654750167683

Epoch: 5| Step: 2
Training loss: 0.04053163155913353
Validation loss: 1.4931989100671583

Epoch: 5| Step: 3
Training loss: 0.09721490740776062
Validation loss: 1.5018946252843386

Epoch: 5| Step: 4
Training loss: 0.10738770663738251
Validation loss: 1.5167120983523708

Epoch: 5| Step: 5
Training loss: 0.09530198574066162
Validation loss: 1.51136984491861

Epoch: 5| Step: 6
Training loss: 0.06068149954080582
Validation loss: 1.5069104010058987

Epoch: 5| Step: 7
Training loss: 0.07048846781253815
Validation loss: 1.502129045865869

Epoch: 5| Step: 8
Training loss: 0.08086425065994263
Validation loss: 1.4994529421611498

Epoch: 5| Step: 9
Training loss: 0.10533864796161652
Validation loss: 1.4931878761578632

Epoch: 5| Step: 10
Training loss: 0.058522358536720276
Validation loss: 1.488957061562487

Epoch: 589| Step: 0
Training loss: 0.05104931443929672
Validation loss: 1.4827011221198625

Epoch: 5| Step: 1
Training loss: 0.057797420769929886
Validation loss: 1.4774022807357132

Epoch: 5| Step: 2
Training loss: 0.05517130345106125
Validation loss: 1.4941419004112162

Epoch: 5| Step: 3
Training loss: 0.047051187604665756
Validation loss: 1.4970127318495063

Epoch: 5| Step: 4
Training loss: 0.054290998727083206
Validation loss: 1.4893598248881679

Epoch: 5| Step: 5
Training loss: 0.0737224668264389
Validation loss: 1.5105739216650687

Epoch: 5| Step: 6
Training loss: 0.08917589485645294
Validation loss: 1.489055513053812

Epoch: 5| Step: 7
Training loss: 0.06486152112483978
Validation loss: 1.5064252499611146

Epoch: 5| Step: 8
Training loss: 0.10434788465499878
Validation loss: 1.4887267338332308

Epoch: 5| Step: 9
Training loss: 0.14682288467884064
Validation loss: 1.5192505774959442

Epoch: 5| Step: 10
Training loss: 0.03902478143572807
Validation loss: 1.501891577115623

Epoch: 590| Step: 0
Training loss: 0.06835119426250458
Validation loss: 1.5033500258640577

Epoch: 5| Step: 1
Training loss: 0.0681171640753746
Validation loss: 1.495141859977476

Epoch: 5| Step: 2
Training loss: 0.13173165917396545
Validation loss: 1.5124345992201118

Epoch: 5| Step: 3
Training loss: 0.09041981399059296
Validation loss: 1.50911287594867

Epoch: 5| Step: 4
Training loss: 0.1061917096376419
Validation loss: 1.5122180741320375

Epoch: 5| Step: 5
Training loss: 0.08840174227952957
Validation loss: 1.5330576114757086

Epoch: 5| Step: 6
Training loss: 0.07072760164737701
Validation loss: 1.5216460343330138

Epoch: 5| Step: 7
Training loss: 0.039116621017456055
Validation loss: 1.511327951185165

Epoch: 5| Step: 8
Training loss: 0.08676876872777939
Validation loss: 1.4988072867034583

Epoch: 5| Step: 9
Training loss: 0.053706228733062744
Validation loss: 1.4670442355576383

Epoch: 5| Step: 10
Training loss: 0.0553080290555954
Validation loss: 1.4843525066170642

Epoch: 591| Step: 0
Training loss: 0.0747113823890686
Validation loss: 1.4664096473365702

Epoch: 5| Step: 1
Training loss: 0.08449932187795639
Validation loss: 1.474227827082398

Epoch: 5| Step: 2
Training loss: 0.07570008188486099
Validation loss: 1.4615840258136872

Epoch: 5| Step: 3
Training loss: 0.05254005268216133
Validation loss: 1.4777792102547103

Epoch: 5| Step: 4
Training loss: 0.05093764141201973
Validation loss: 1.4934857340269192

Epoch: 5| Step: 5
Training loss: 0.06399382650852203
Validation loss: 1.4922447076407812

Epoch: 5| Step: 6
Training loss: 0.07531829178333282
Validation loss: 1.497175674284658

Epoch: 5| Step: 7
Training loss: 0.07985199987888336
Validation loss: 1.5284148839212233

Epoch: 5| Step: 8
Training loss: 0.1184644103050232
Validation loss: 1.5230012734731038

Epoch: 5| Step: 9
Training loss: 0.08776628971099854
Validation loss: 1.5192834895144227

Epoch: 5| Step: 10
Training loss: 0.09243341535329819
Validation loss: 1.524377615221085

Epoch: 592| Step: 0
Training loss: 0.14066404104232788
Validation loss: 1.48707527114499

Epoch: 5| Step: 1
Training loss: 0.07220688462257385
Validation loss: 1.4868336621151175

Epoch: 5| Step: 2
Training loss: 0.1065923199057579
Validation loss: 1.47371893928897

Epoch: 5| Step: 3
Training loss: 0.10149216651916504
Validation loss: 1.4769704085524364

Epoch: 5| Step: 4
Training loss: 0.06351108849048615
Validation loss: 1.5034927886019471

Epoch: 5| Step: 5
Training loss: 0.055789846926927567
Validation loss: 1.4907783756973922

Epoch: 5| Step: 6
Training loss: 0.07746841013431549
Validation loss: 1.5074854858459965

Epoch: 5| Step: 7
Training loss: 0.062317173928022385
Validation loss: 1.5108287872806672

Epoch: 5| Step: 8
Training loss: 0.08687486499547958
Validation loss: 1.4833526585691719

Epoch: 5| Step: 9
Training loss: 0.06828667223453522
Validation loss: 1.4563418716512702

Epoch: 5| Step: 10
Training loss: 0.05337006226181984
Validation loss: 1.4372686692463454

Epoch: 593| Step: 0
Training loss: 0.06820960342884064
Validation loss: 1.4507083482639764

Epoch: 5| Step: 1
Training loss: 0.048115216195583344
Validation loss: 1.4321452533045123

Epoch: 5| Step: 2
Training loss: 0.09467647969722748
Validation loss: 1.455066632199031

Epoch: 5| Step: 3
Training loss: 0.09251593798398972
Validation loss: 1.445104686162805

Epoch: 5| Step: 4
Training loss: 0.11181934177875519
Validation loss: 1.4532534383958386

Epoch: 5| Step: 5
Training loss: 0.07189011573791504
Validation loss: 1.4549006082678353

Epoch: 5| Step: 6
Training loss: 0.057883940637111664
Validation loss: 1.4856172633427445

Epoch: 5| Step: 7
Training loss: 0.09176740050315857
Validation loss: 1.4627614931393695

Epoch: 5| Step: 8
Training loss: 0.06904378533363342
Validation loss: 1.4729985088430426

Epoch: 5| Step: 9
Training loss: 0.054836709052324295
Validation loss: 1.4701554326600925

Epoch: 5| Step: 10
Training loss: 0.06556399911642075
Validation loss: 1.488046121212744

Epoch: 594| Step: 0
Training loss: 0.04941399022936821
Validation loss: 1.4585432083375993

Epoch: 5| Step: 1
Training loss: 0.051552824676036835
Validation loss: 1.4546453286242742

Epoch: 5| Step: 2
Training loss: 0.08104304224252701
Validation loss: 1.4545935635925622

Epoch: 5| Step: 3
Training loss: 0.07363106310367584
Validation loss: 1.4658023541973484

Epoch: 5| Step: 4
Training loss: 0.0937548279762268
Validation loss: 1.4472299057950255

Epoch: 5| Step: 5
Training loss: 0.05234871059656143
Validation loss: 1.4576692811904415

Epoch: 5| Step: 6
Training loss: 0.07606079429388046
Validation loss: 1.4662639197482858

Epoch: 5| Step: 7
Training loss: 0.07958757877349854
Validation loss: 1.4606543946009811

Epoch: 5| Step: 8
Training loss: 0.1164025068283081
Validation loss: 1.4731406639981013

Epoch: 5| Step: 9
Training loss: 0.07195769250392914
Validation loss: 1.493214722602598

Epoch: 5| Step: 10
Training loss: 0.06801359355449677
Validation loss: 1.5348334850803498

Epoch: 595| Step: 0
Training loss: 0.05616254732012749
Validation loss: 1.524645111894095

Epoch: 5| Step: 1
Training loss: 0.0933908075094223
Validation loss: 1.521080268326626

Epoch: 5| Step: 2
Training loss: 0.06075997278094292
Validation loss: 1.5037515086512412

Epoch: 5| Step: 3
Training loss: 0.06609263271093369
Validation loss: 1.5194284839014853

Epoch: 5| Step: 4
Training loss: 0.05471987649798393
Validation loss: 1.491891868652836

Epoch: 5| Step: 5
Training loss: 0.09288477152585983
Validation loss: 1.4721863256987704

Epoch: 5| Step: 6
Training loss: 0.05784384161233902
Validation loss: 1.47864378652265

Epoch: 5| Step: 7
Training loss: 0.05828557536005974
Validation loss: 1.4615906156519407

Epoch: 5| Step: 8
Training loss: 0.10808483511209488
Validation loss: 1.4875883799727245

Epoch: 5| Step: 9
Training loss: 0.07739909738302231
Validation loss: 1.4812233499301377

Epoch: 5| Step: 10
Training loss: 0.05851922184228897
Validation loss: 1.482230673554123

Epoch: 596| Step: 0
Training loss: 0.06972725689411163
Validation loss: 1.5007175630138767

Epoch: 5| Step: 1
Training loss: 0.04995672404766083
Validation loss: 1.495525275507281

Epoch: 5| Step: 2
Training loss: 0.0816882997751236
Validation loss: 1.5128317968819731

Epoch: 5| Step: 3
Training loss: 0.11404166370630264
Validation loss: 1.5028570775062806

Epoch: 5| Step: 4
Training loss: 0.10761579126119614
Validation loss: 1.4626512219828944

Epoch: 5| Step: 5
Training loss: 0.07749345153570175
Validation loss: 1.4825484842382453

Epoch: 5| Step: 6
Training loss: 0.06705932319164276
Validation loss: 1.4680036050017162

Epoch: 5| Step: 7
Training loss: 0.07864025980234146
Validation loss: 1.4738891419544016

Epoch: 5| Step: 8
Training loss: 0.04881639406085014
Validation loss: 1.4733983996093913

Epoch: 5| Step: 9
Training loss: 0.05538583919405937
Validation loss: 1.4536624326500842

Epoch: 5| Step: 10
Training loss: 0.06637002527713776
Validation loss: 1.4513276238595285

Epoch: 597| Step: 0
Training loss: 0.054808128625154495
Validation loss: 1.463532745197255

Epoch: 5| Step: 1
Training loss: 0.12889380753040314
Validation loss: 1.4719982070307578

Epoch: 5| Step: 2
Training loss: 0.09390924125909805
Validation loss: 1.4802668274089854

Epoch: 5| Step: 3
Training loss: 0.12576967477798462
Validation loss: 1.5104419877452235

Epoch: 5| Step: 4
Training loss: 0.0601985938847065
Validation loss: 1.4905169933072981

Epoch: 5| Step: 5
Training loss: 0.08944591134786606
Validation loss: 1.4949195699025226

Epoch: 5| Step: 6
Training loss: 0.04183559864759445
Validation loss: 1.5136418022135252

Epoch: 5| Step: 7
Training loss: 0.06347142159938812
Validation loss: 1.4786263729936333

Epoch: 5| Step: 8
Training loss: 0.06962303072214127
Validation loss: 1.5079162774547454

Epoch: 5| Step: 9
Training loss: 0.06862867623567581
Validation loss: 1.4908654151424285

Epoch: 5| Step: 10
Training loss: 0.06977827101945877
Validation loss: 1.4822770549405007

Epoch: 598| Step: 0
Training loss: 0.048804838210344315
Validation loss: 1.4982362242155178

Epoch: 5| Step: 1
Training loss: 0.0676511898636818
Validation loss: 1.5058047649680928

Epoch: 5| Step: 2
Training loss: 0.059279732406139374
Validation loss: 1.5243500208341947

Epoch: 5| Step: 3
Training loss: 0.047978635877370834
Validation loss: 1.5104597383929836

Epoch: 5| Step: 4
Training loss: 0.07953127473592758
Validation loss: 1.5452138890502274

Epoch: 5| Step: 5
Training loss: 0.08917998522520065
Validation loss: 1.5270552699283888

Epoch: 5| Step: 6
Training loss: 0.06703679263591766
Validation loss: 1.5583492235470844

Epoch: 5| Step: 7
Training loss: 0.12400467693805695
Validation loss: 1.5596525169187976

Epoch: 5| Step: 8
Training loss: 0.09078174829483032
Validation loss: 1.5575698383392826

Epoch: 5| Step: 9
Training loss: 0.10894860327243805
Validation loss: 1.533769884417134

Epoch: 5| Step: 10
Training loss: 0.07403841614723206
Validation loss: 1.512154181157389

Epoch: 599| Step: 0
Training loss: 0.05107733607292175
Validation loss: 1.5070599791824177

Epoch: 5| Step: 1
Training loss: 0.06742936372756958
Validation loss: 1.4798729983709191

Epoch: 5| Step: 2
Training loss: 0.07264582067728043
Validation loss: 1.4799243583474109

Epoch: 5| Step: 3
Training loss: 0.061717331409454346
Validation loss: 1.4874497972508913

Epoch: 5| Step: 4
Training loss: 0.10055241733789444
Validation loss: 1.49081414873882

Epoch: 5| Step: 5
Training loss: 0.08560057729482651
Validation loss: 1.5046026860513995

Epoch: 5| Step: 6
Training loss: 0.09228462725877762
Validation loss: 1.4948523570132513

Epoch: 5| Step: 7
Training loss: 0.09564990550279617
Validation loss: 1.5137002993655462

Epoch: 5| Step: 8
Training loss: 0.09968188405036926
Validation loss: 1.52015471202071

Epoch: 5| Step: 9
Training loss: 0.0879124328494072
Validation loss: 1.5301733888605589

Epoch: 5| Step: 10
Training loss: 0.08306223899126053
Validation loss: 1.5342463216473978

Epoch: 600| Step: 0
Training loss: 0.09722594171762466
Validation loss: 1.5351961197391633

Epoch: 5| Step: 1
Training loss: 0.07958413660526276
Validation loss: 1.5266632956843222

Epoch: 5| Step: 2
Training loss: 0.08768968284130096
Validation loss: 1.493395798949785

Epoch: 5| Step: 3
Training loss: 0.12102584540843964
Validation loss: 1.497745197306397

Epoch: 5| Step: 4
Training loss: 0.0799405500292778
Validation loss: 1.5027089375321583

Epoch: 5| Step: 5
Training loss: 0.12717348337173462
Validation loss: 1.5079687526149135

Epoch: 5| Step: 6
Training loss: 0.08014055341482162
Validation loss: 1.5098711316303541

Epoch: 5| Step: 7
Training loss: 0.1021193414926529
Validation loss: 1.5321274431802894

Epoch: 5| Step: 8
Training loss: 0.11218581348657608
Validation loss: 1.5370190015403173

Epoch: 5| Step: 9
Training loss: 0.08629918098449707
Validation loss: 1.5404883238577074

Epoch: 5| Step: 10
Training loss: 0.07400145381689072
Validation loss: 1.4930414076774352

Testing loss: 2.010980407396952
