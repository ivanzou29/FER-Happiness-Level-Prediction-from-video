Epoch: 1| Step: 0
Training loss: 4.786700248718262
Validation loss: 5.263537278739355

Epoch: 5| Step: 1
Training loss: 3.960115909576416
Validation loss: 5.251883783648091

Epoch: 5| Step: 2
Training loss: 4.961574554443359
Validation loss: 5.2406244841955045

Epoch: 5| Step: 3
Training loss: 5.0218329429626465
Validation loss: 5.22931904946604

Epoch: 5| Step: 4
Training loss: 5.952199935913086
Validation loss: 5.216920632188038

Epoch: 5| Step: 5
Training loss: 5.603473663330078
Validation loss: 5.202772699376588

Epoch: 5| Step: 6
Training loss: 4.908742904663086
Validation loss: 5.186627695637364

Epoch: 5| Step: 7
Training loss: 6.100793838500977
Validation loss: 5.168247827919581

Epoch: 5| Step: 8
Training loss: 3.7802982330322266
Validation loss: 5.146930504870671

Epoch: 5| Step: 9
Training loss: 5.4166998863220215
Validation loss: 5.122897445514638

Epoch: 5| Step: 10
Training loss: 4.270976543426514
Validation loss: 5.095168282908778

Epoch: 2| Step: 0
Training loss: 5.018065452575684
Validation loss: 5.0636882730709605

Epoch: 5| Step: 1
Training loss: 5.604578971862793
Validation loss: 5.027740386224562

Epoch: 5| Step: 2
Training loss: 4.534463882446289
Validation loss: 4.987796106646138

Epoch: 5| Step: 3
Training loss: 4.179080009460449
Validation loss: 4.941147881169473

Epoch: 5| Step: 4
Training loss: 4.331758975982666
Validation loss: 4.89218508812689

Epoch: 5| Step: 5
Training loss: 6.4243669509887695
Validation loss: 4.837164437899026

Epoch: 5| Step: 6
Training loss: 4.2233357429504395
Validation loss: 4.779453226315078

Epoch: 5| Step: 7
Training loss: 3.8987412452697754
Validation loss: 4.718526671009679

Epoch: 5| Step: 8
Training loss: 3.5080268383026123
Validation loss: 4.655615560470089

Epoch: 5| Step: 9
Training loss: 5.432528972625732
Validation loss: 4.592741181773524

Epoch: 5| Step: 10
Training loss: 3.4078080654144287
Validation loss: 4.529341584892683

Epoch: 3| Step: 0
Training loss: 3.7317843437194824
Validation loss: 4.466758035844372

Epoch: 5| Step: 1
Training loss: 5.0113348960876465
Validation loss: 4.405592441558838

Epoch: 5| Step: 2
Training loss: 3.8874878883361816
Validation loss: 4.3443169388719785

Epoch: 5| Step: 3
Training loss: 4.9554338455200195
Validation loss: 4.281990143560594

Epoch: 5| Step: 4
Training loss: 4.015151023864746
Validation loss: 4.221422690217213

Epoch: 5| Step: 5
Training loss: 2.4792919158935547
Validation loss: 4.168967482864216

Epoch: 5| Step: 6
Training loss: 3.8165340423583984
Validation loss: 4.110994487680415

Epoch: 5| Step: 7
Training loss: 4.557816982269287
Validation loss: 4.042615495702272

Epoch: 5| Step: 8
Training loss: 2.8137965202331543
Validation loss: 3.9957069632827595

Epoch: 5| Step: 9
Training loss: 4.626970291137695
Validation loss: 3.9642919622441775

Epoch: 5| Step: 10
Training loss: 4.033915042877197
Validation loss: 3.9335113750991

Epoch: 4| Step: 0
Training loss: 3.084704637527466
Validation loss: 3.900472794809649

Epoch: 5| Step: 1
Training loss: 3.5801689624786377
Validation loss: 3.8623301854697605

Epoch: 5| Step: 2
Training loss: 3.5511295795440674
Validation loss: 3.835145719589726

Epoch: 5| Step: 3
Training loss: 3.574380397796631
Validation loss: 3.8090686644277265

Epoch: 5| Step: 4
Training loss: 3.1223666667938232
Validation loss: 3.7967587645335863

Epoch: 5| Step: 5
Training loss: 4.152281761169434
Validation loss: 3.7800925880350094

Epoch: 5| Step: 6
Training loss: 3.9152073860168457
Validation loss: 3.753304296924222

Epoch: 5| Step: 7
Training loss: 3.7975316047668457
Validation loss: 3.7380647377301286

Epoch: 5| Step: 8
Training loss: 4.17308235168457
Validation loss: 3.7325658798217773

Epoch: 5| Step: 9
Training loss: 3.4342658519744873
Validation loss: 3.716016677118117

Epoch: 5| Step: 10
Training loss: 4.1567254066467285
Validation loss: 3.7014566365108696

Epoch: 5| Step: 0
Training loss: 3.363851547241211
Validation loss: 3.688147811479466

Epoch: 5| Step: 1
Training loss: 4.056396484375
Validation loss: 3.673037713573825

Epoch: 5| Step: 2
Training loss: 2.9904541969299316
Validation loss: 3.6583415385215514

Epoch: 5| Step: 3
Training loss: 3.9521827697753906
Validation loss: 3.643269354297269

Epoch: 5| Step: 4
Training loss: 4.581086158752441
Validation loss: 3.630513555260115

Epoch: 5| Step: 5
Training loss: 3.31304931640625
Validation loss: 3.6167768201520367

Epoch: 5| Step: 6
Training loss: 3.624549150466919
Validation loss: 3.6010675071388163

Epoch: 5| Step: 7
Training loss: 2.9396393299102783
Validation loss: 3.585122226386942

Epoch: 5| Step: 8
Training loss: 2.671661615371704
Validation loss: 3.5707043345256517

Epoch: 5| Step: 9
Training loss: 3.55084490776062
Validation loss: 3.556890744034962

Epoch: 5| Step: 10
Training loss: 3.8805298805236816
Validation loss: 3.5433317410048617

Epoch: 6| Step: 0
Training loss: 3.8360073566436768
Validation loss: 3.5385685479769142

Epoch: 5| Step: 1
Training loss: 3.696821689605713
Validation loss: 3.516032467606247

Epoch: 5| Step: 2
Training loss: 3.1163744926452637
Validation loss: 3.505834435903898

Epoch: 5| Step: 3
Training loss: 2.731584310531616
Validation loss: 3.494899760010422

Epoch: 5| Step: 4
Training loss: 3.3860268592834473
Validation loss: 3.4845888435199694

Epoch: 5| Step: 5
Training loss: 3.633038282394409
Validation loss: 3.4766522889496176

Epoch: 5| Step: 6
Training loss: 3.948674440383911
Validation loss: 3.463427871786138

Epoch: 5| Step: 7
Training loss: 3.387852430343628
Validation loss: 3.4521933473566526

Epoch: 5| Step: 8
Training loss: 3.5080628395080566
Validation loss: 3.439823842817737

Epoch: 5| Step: 9
Training loss: 3.1400153636932373
Validation loss: 3.4259947243557183

Epoch: 5| Step: 10
Training loss: 3.1462366580963135
Validation loss: 3.414383226825345

Epoch: 7| Step: 0
Training loss: 3.9762001037597656
Validation loss: 3.4022984453426894

Epoch: 5| Step: 1
Training loss: 4.072373867034912
Validation loss: 3.399000885666058

Epoch: 5| Step: 2
Training loss: 2.80483341217041
Validation loss: 3.397258476544452

Epoch: 5| Step: 3
Training loss: 3.663203477859497
Validation loss: 3.3811225942386094

Epoch: 5| Step: 4
Training loss: 4.350609302520752
Validation loss: 3.37702876265331

Epoch: 5| Step: 5
Training loss: 3.005572557449341
Validation loss: 3.3621440215777327

Epoch: 5| Step: 6
Training loss: 2.6996049880981445
Validation loss: 3.3562754405442106

Epoch: 5| Step: 7
Training loss: 3.3137927055358887
Validation loss: 3.3556004442194456

Epoch: 5| Step: 8
Training loss: 2.784205675125122
Validation loss: 3.3501031039863505

Epoch: 5| Step: 9
Training loss: 2.4985480308532715
Validation loss: 3.344292558649535

Epoch: 5| Step: 10
Training loss: 3.447411060333252
Validation loss: 3.3339656552960797

Epoch: 8| Step: 0
Training loss: 3.618657350540161
Validation loss: 3.3221921792594333

Epoch: 5| Step: 1
Training loss: 2.914616346359253
Validation loss: 3.312670894848403

Epoch: 5| Step: 2
Training loss: 3.193303108215332
Validation loss: 3.3022364288248043

Epoch: 5| Step: 3
Training loss: 3.394343852996826
Validation loss: 3.2961760541444183

Epoch: 5| Step: 4
Training loss: 2.791022539138794
Validation loss: 3.2907213395641697

Epoch: 5| Step: 5
Training loss: 2.867316722869873
Validation loss: 3.2830173071994575

Epoch: 5| Step: 6
Training loss: 3.332355499267578
Validation loss: 3.2715760764255317

Epoch: 5| Step: 7
Training loss: 3.3182902336120605
Validation loss: 3.2624475468871412

Epoch: 5| Step: 8
Training loss: 3.538890838623047
Validation loss: 3.2591754749257076

Epoch: 5| Step: 9
Training loss: 3.0162951946258545
Validation loss: 3.2515432116805867

Epoch: 5| Step: 10
Training loss: 3.968430519104004
Validation loss: 3.2632964400834936

Epoch: 9| Step: 0
Training loss: 3.7037510871887207
Validation loss: 3.2347223886879544

Epoch: 5| Step: 1
Training loss: 3.0915257930755615
Validation loss: 3.244744057296425

Epoch: 5| Step: 2
Training loss: 3.070164203643799
Validation loss: 3.2272216094437467

Epoch: 5| Step: 3
Training loss: 2.9913296699523926
Validation loss: 3.221217478475263

Epoch: 5| Step: 4
Training loss: 3.9124598503112793
Validation loss: 3.225403416541315

Epoch: 5| Step: 5
Training loss: 2.0554232597351074
Validation loss: 3.226741485698249

Epoch: 5| Step: 6
Training loss: 3.336676836013794
Validation loss: 3.2239950036489837

Epoch: 5| Step: 7
Training loss: 2.899513006210327
Validation loss: 3.214007559642997

Epoch: 5| Step: 8
Training loss: 3.92712664604187
Validation loss: 3.2023804110865437

Epoch: 5| Step: 9
Training loss: 3.5094306468963623
Validation loss: 3.191217222521382

Epoch: 5| Step: 10
Training loss: 2.7801403999328613
Validation loss: 3.1841565947378836

Epoch: 10| Step: 0
Training loss: 3.735525608062744
Validation loss: 3.1912592995551323

Epoch: 5| Step: 1
Training loss: 2.2836012840270996
Validation loss: 3.1829281289090394

Epoch: 5| Step: 2
Training loss: 2.941906452178955
Validation loss: 3.1737223363691762

Epoch: 5| Step: 3
Training loss: 2.8201098442077637
Validation loss: 3.166438530850154

Epoch: 5| Step: 4
Training loss: 3.3473942279815674
Validation loss: 3.157196416649767

Epoch: 5| Step: 5
Training loss: 3.678945541381836
Validation loss: 3.1504754122867378

Epoch: 5| Step: 6
Training loss: 2.995901107788086
Validation loss: 3.1520162320906118

Epoch: 5| Step: 7
Training loss: 3.669745683670044
Validation loss: 3.145517518443446

Epoch: 5| Step: 8
Training loss: 3.497954845428467
Validation loss: 3.135011762701055

Epoch: 5| Step: 9
Training loss: 3.148838758468628
Validation loss: 3.1331685230296147

Epoch: 5| Step: 10
Training loss: 2.630141258239746
Validation loss: 3.1415387174134612

Epoch: 11| Step: 0
Training loss: 4.2206902503967285
Validation loss: 3.132822480252994

Epoch: 5| Step: 1
Training loss: 2.907959222793579
Validation loss: 3.1233324543122323

Epoch: 5| Step: 2
Training loss: 3.912329912185669
Validation loss: 3.1149130405918246

Epoch: 5| Step: 3
Training loss: 2.885890483856201
Validation loss: 3.1128514530838176

Epoch: 5| Step: 4
Training loss: 3.228421449661255
Validation loss: 3.1082127888997397

Epoch: 5| Step: 5
Training loss: 2.6600608825683594
Validation loss: 3.1028444382452194

Epoch: 5| Step: 6
Training loss: 2.9200215339660645
Validation loss: 3.0964528309401644

Epoch: 5| Step: 7
Training loss: 3.0953876972198486
Validation loss: 3.091482613676338

Epoch: 5| Step: 8
Training loss: 2.2977488040924072
Validation loss: 3.0847036120712117

Epoch: 5| Step: 9
Training loss: 2.8151211738586426
Validation loss: 3.1017635432622765

Epoch: 5| Step: 10
Training loss: 3.5856311321258545
Validation loss: 3.0799732003160702

Epoch: 12| Step: 0
Training loss: 3.191962242126465
Validation loss: 3.0821900598464476

Epoch: 5| Step: 1
Training loss: 3.818655490875244
Validation loss: 3.0791725240727907

Epoch: 5| Step: 2
Training loss: 3.1664726734161377
Validation loss: 3.072333630695138

Epoch: 5| Step: 3
Training loss: 3.0091819763183594
Validation loss: 3.068578809820196

Epoch: 5| Step: 4
Training loss: 3.2132461071014404
Validation loss: 3.0684362970372683

Epoch: 5| Step: 5
Training loss: 3.164762020111084
Validation loss: 3.0701620912039154

Epoch: 5| Step: 6
Training loss: 2.893115520477295
Validation loss: 3.062424103418986

Epoch: 5| Step: 7
Training loss: 2.972565174102783
Validation loss: 3.060318995547551

Epoch: 5| Step: 8
Training loss: 2.902754306793213
Validation loss: 3.0623869793389433

Epoch: 5| Step: 9
Training loss: 2.7657368183135986
Validation loss: 3.0592568561594975

Epoch: 5| Step: 10
Training loss: 3.0651512145996094
Validation loss: 3.051528469208748

Epoch: 13| Step: 0
Training loss: 3.4954819679260254
Validation loss: 3.043812080096173

Epoch: 5| Step: 1
Training loss: 2.4150702953338623
Validation loss: 3.0420435910583823

Epoch: 5| Step: 2
Training loss: 2.5886178016662598
Validation loss: 3.0410716226024013

Epoch: 5| Step: 3
Training loss: 3.0289547443389893
Validation loss: 3.040359657297852

Epoch: 5| Step: 4
Training loss: 3.341294527053833
Validation loss: 3.033956471309867

Epoch: 5| Step: 5
Training loss: 2.726983070373535
Validation loss: 3.028756169862645

Epoch: 5| Step: 6
Training loss: 2.8762755393981934
Validation loss: 3.028425552511728

Epoch: 5| Step: 7
Training loss: 2.8304848670959473
Validation loss: 3.0276339259198917

Epoch: 5| Step: 8
Training loss: 3.328024387359619
Validation loss: 3.0240409938238

Epoch: 5| Step: 9
Training loss: 3.906182050704956
Validation loss: 3.0215436053532425

Epoch: 5| Step: 10
Training loss: 3.455705165863037
Validation loss: 3.0161590012170936

Epoch: 14| Step: 0
Training loss: 2.7346949577331543
Validation loss: 3.012527042819608

Epoch: 5| Step: 1
Training loss: 3.5852272510528564
Validation loss: 3.0109360987140286

Epoch: 5| Step: 2
Training loss: 2.8466005325317383
Validation loss: 3.0096695294944187

Epoch: 5| Step: 3
Training loss: 2.9215683937072754
Validation loss: 3.0072611326812417

Epoch: 5| Step: 4
Training loss: 3.1323304176330566
Validation loss: 3.003956904975317

Epoch: 5| Step: 5
Training loss: 3.1998422145843506
Validation loss: 3.0003884197563253

Epoch: 5| Step: 6
Training loss: 3.008892774581909
Validation loss: 3.001697189064436

Epoch: 5| Step: 7
Training loss: 2.6454923152923584
Validation loss: 2.997839194472118

Epoch: 5| Step: 8
Training loss: 3.3180782794952393
Validation loss: 2.9944084434099096

Epoch: 5| Step: 9
Training loss: 2.9742825031280518
Validation loss: 2.992644104906308

Epoch: 5| Step: 10
Training loss: 3.38875412940979
Validation loss: 2.9919871284115698

Epoch: 15| Step: 0
Training loss: 2.8976707458496094
Validation loss: 2.9886430412210445

Epoch: 5| Step: 1
Training loss: 2.6847431659698486
Validation loss: 2.9848691724961802

Epoch: 5| Step: 2
Training loss: 2.2108497619628906
Validation loss: 2.98352018479378

Epoch: 5| Step: 3
Training loss: 2.9689910411834717
Validation loss: 2.9813511038339264

Epoch: 5| Step: 4
Training loss: 3.677417039871216
Validation loss: 3.0015616955295688

Epoch: 5| Step: 5
Training loss: 3.6563637256622314
Validation loss: 2.981333171167681

Epoch: 5| Step: 6
Training loss: 3.2997443675994873
Validation loss: 2.985557715098063

Epoch: 5| Step: 7
Training loss: 3.279766798019409
Validation loss: 2.976819153754942

Epoch: 5| Step: 8
Training loss: 2.6401352882385254
Validation loss: 2.975750074591688

Epoch: 5| Step: 9
Training loss: 3.0533430576324463
Validation loss: 2.9743800060723418

Epoch: 5| Step: 10
Training loss: 3.193847894668579
Validation loss: 2.9741423258217434

Epoch: 16| Step: 0
Training loss: 3.2670414447784424
Validation loss: 2.973702141033706

Epoch: 5| Step: 1
Training loss: 3.0335278511047363
Validation loss: 2.967655917649628

Epoch: 5| Step: 2
Training loss: 2.5488083362579346
Validation loss: 2.9693464643211773

Epoch: 5| Step: 3
Training loss: 2.575634002685547
Validation loss: 2.9704410106905046

Epoch: 5| Step: 4
Training loss: 3.4486565589904785
Validation loss: 2.981549314273301

Epoch: 5| Step: 5
Training loss: 2.849514961242676
Validation loss: 2.9630743893243934

Epoch: 5| Step: 6
Training loss: 3.832752227783203
Validation loss: 2.9610156654029764

Epoch: 5| Step: 7
Training loss: 2.8608927726745605
Validation loss: 2.9599826540998233

Epoch: 5| Step: 8
Training loss: 2.9053478240966797
Validation loss: 2.9602339267730713

Epoch: 5| Step: 9
Training loss: 3.7201855182647705
Validation loss: 2.9618133960231656

Epoch: 5| Step: 10
Training loss: 2.2466745376586914
Validation loss: 2.9544993908174577

Epoch: 17| Step: 0
Training loss: 3.3070919513702393
Validation loss: 2.9509092120714087

Epoch: 5| Step: 1
Training loss: 3.144127368927002
Validation loss: 2.9494267663648053

Epoch: 5| Step: 2
Training loss: 2.728318929672241
Validation loss: 2.9531538742844776

Epoch: 5| Step: 3
Training loss: 3.3169479370117188
Validation loss: 2.9510502892155803

Epoch: 5| Step: 4
Training loss: 2.9763216972351074
Validation loss: 2.9462076412734164

Epoch: 5| Step: 5
Training loss: 2.9545321464538574
Validation loss: 2.941104506933561

Epoch: 5| Step: 6
Training loss: 2.8069233894348145
Validation loss: 2.9384611422015774

Epoch: 5| Step: 7
Training loss: 3.2921836376190186
Validation loss: 2.9375433485995055

Epoch: 5| Step: 8
Training loss: 3.5441582202911377
Validation loss: 2.9359353998655915

Epoch: 5| Step: 9
Training loss: 2.020479679107666
Validation loss: 2.9368025910469795

Epoch: 5| Step: 10
Training loss: 3.1253137588500977
Validation loss: 2.9318789256516324

Epoch: 18| Step: 0
Training loss: 3.1245298385620117
Validation loss: 2.941465744408228

Epoch: 5| Step: 1
Training loss: 2.790863037109375
Validation loss: 2.9371256982126543

Epoch: 5| Step: 2
Training loss: 3.1962742805480957
Validation loss: 2.929393635001234

Epoch: 5| Step: 3
Training loss: 2.805102825164795
Validation loss: 2.9341776601729856

Epoch: 5| Step: 4
Training loss: 2.033402681350708
Validation loss: 2.9408151744514384

Epoch: 5| Step: 5
Training loss: 4.091935157775879
Validation loss: 2.9290987881281043

Epoch: 5| Step: 6
Training loss: 3.0424065589904785
Validation loss: 2.924382876324397

Epoch: 5| Step: 7
Training loss: 2.7849955558776855
Validation loss: 2.9261089871006627

Epoch: 5| Step: 8
Training loss: 3.0788655281066895
Validation loss: 2.9235030579310592

Epoch: 5| Step: 9
Training loss: 2.665252208709717
Validation loss: 2.918618320136942

Epoch: 5| Step: 10
Training loss: 3.532207489013672
Validation loss: 2.917795299201883

Epoch: 19| Step: 0
Training loss: 2.729689121246338
Validation loss: 2.914791545560283

Epoch: 5| Step: 1
Training loss: 3.9633216857910156
Validation loss: 2.9088257256374566

Epoch: 5| Step: 2
Training loss: 3.2856736183166504
Validation loss: 2.9086698178322083

Epoch: 5| Step: 3
Training loss: 3.4276695251464844
Validation loss: 2.906470444894606

Epoch: 5| Step: 4
Training loss: 2.7994468212127686
Validation loss: 2.90606600751159

Epoch: 5| Step: 5
Training loss: 2.1652235984802246
Validation loss: 2.9160581378526587

Epoch: 5| Step: 6
Training loss: 2.8681912422180176
Validation loss: 2.932598049922656

Epoch: 5| Step: 7
Training loss: 2.9966399669647217
Validation loss: 2.927713140364616

Epoch: 5| Step: 8
Training loss: 2.528421401977539
Validation loss: 2.9065548271261235

Epoch: 5| Step: 9
Training loss: 2.899994373321533
Validation loss: 2.9026957276046916

Epoch: 5| Step: 10
Training loss: 3.288874864578247
Validation loss: 2.909381466527139

Epoch: 20| Step: 0
Training loss: 2.6135449409484863
Validation loss: 2.9062533865692797

Epoch: 5| Step: 1
Training loss: 3.1564531326293945
Validation loss: 2.9013526824212845

Epoch: 5| Step: 2
Training loss: 3.629687547683716
Validation loss: 2.8978941235491025

Epoch: 5| Step: 3
Training loss: 2.7763209342956543
Validation loss: 2.892915548816804

Epoch: 5| Step: 4
Training loss: 2.8821911811828613
Validation loss: 2.8904729094556583

Epoch: 5| Step: 5
Training loss: 2.9346487522125244
Validation loss: 2.8974685361308437

Epoch: 5| Step: 6
Training loss: 2.8825178146362305
Validation loss: 2.9072019438589773

Epoch: 5| Step: 7
Training loss: 2.9057230949401855
Validation loss: 2.8973706614586616

Epoch: 5| Step: 8
Training loss: 3.134427547454834
Validation loss: 2.889809669986848

Epoch: 5| Step: 9
Training loss: 3.5623714923858643
Validation loss: 2.8901716406627367

Epoch: 5| Step: 10
Training loss: 2.210329532623291
Validation loss: 2.888764783900271

Epoch: 21| Step: 0
Training loss: 2.3087222576141357
Validation loss: 2.88083202351806

Epoch: 5| Step: 1
Training loss: 2.949615955352783
Validation loss: 2.8792262410604827

Epoch: 5| Step: 2
Training loss: 2.9904491901397705
Validation loss: 2.8753052988360004

Epoch: 5| Step: 3
Training loss: 4.389188289642334
Validation loss: 2.876501234628821

Epoch: 5| Step: 4
Training loss: 2.9902050495147705
Validation loss: 2.8738536629625546

Epoch: 5| Step: 5
Training loss: 2.7651724815368652
Validation loss: 2.8770018495539182

Epoch: 5| Step: 6
Training loss: 2.3244056701660156
Validation loss: 2.8771852575322634

Epoch: 5| Step: 7
Training loss: 2.3083040714263916
Validation loss: 2.8757589529919367

Epoch: 5| Step: 8
Training loss: 3.0256919860839844
Validation loss: 2.875608480104836

Epoch: 5| Step: 9
Training loss: 3.1664040088653564
Validation loss: 2.8727490158491236

Epoch: 5| Step: 10
Training loss: 3.491312026977539
Validation loss: 2.871742030625702

Epoch: 22| Step: 0
Training loss: 2.962679862976074
Validation loss: 2.869836825196461

Epoch: 5| Step: 1
Training loss: 2.2588095664978027
Validation loss: 2.863340772608275

Epoch: 5| Step: 2
Training loss: 2.655643939971924
Validation loss: 2.8560768276132564

Epoch: 5| Step: 3
Training loss: 3.0735905170440674
Validation loss: 2.847291500337662

Epoch: 5| Step: 4
Training loss: 3.228821277618408
Validation loss: 2.848816571697112

Epoch: 5| Step: 5
Training loss: 2.6172375679016113
Validation loss: 2.8452922708244732

Epoch: 5| Step: 6
Training loss: 3.283179759979248
Validation loss: 2.845958138024935

Epoch: 5| Step: 7
Training loss: 3.649094820022583
Validation loss: 2.8427003993782947

Epoch: 5| Step: 8
Training loss: 3.2709269523620605
Validation loss: 2.842130873792915

Epoch: 5| Step: 9
Training loss: 2.8342130184173584
Validation loss: 2.844182470793365

Epoch: 5| Step: 10
Training loss: 2.550398826599121
Validation loss: 2.8523252394891556

Epoch: 23| Step: 0
Training loss: 2.4008069038391113
Validation loss: 2.876491282575874

Epoch: 5| Step: 1
Training loss: 2.569697856903076
Validation loss: 2.875019045286281

Epoch: 5| Step: 2
Training loss: 2.471125841140747
Validation loss: 2.892012296184417

Epoch: 5| Step: 3
Training loss: 2.191946268081665
Validation loss: 2.874516430721488

Epoch: 5| Step: 4
Training loss: 3.547959089279175
Validation loss: 2.853000792123938

Epoch: 5| Step: 5
Training loss: 3.5186119079589844
Validation loss: 2.8339771762970956

Epoch: 5| Step: 6
Training loss: 2.0871572494506836
Validation loss: 2.8318185742183397

Epoch: 5| Step: 7
Training loss: 2.6059207916259766
Validation loss: 2.8349508098376694

Epoch: 5| Step: 8
Training loss: 3.7833328247070312
Validation loss: 2.83604403977753

Epoch: 5| Step: 9
Training loss: 4.074028015136719
Validation loss: 2.8357029473909767

Epoch: 5| Step: 10
Training loss: 3.062133550643921
Validation loss: 2.8354423097384873

Epoch: 24| Step: 0
Training loss: 2.691226005554199
Validation loss: 2.827286451093612

Epoch: 5| Step: 1
Training loss: 2.424612045288086
Validation loss: 2.8258203716688257

Epoch: 5| Step: 2
Training loss: 3.958282470703125
Validation loss: 2.8570662134437153

Epoch: 5| Step: 3
Training loss: 2.9035353660583496
Validation loss: 2.832736225538356

Epoch: 5| Step: 4
Training loss: 2.262702465057373
Validation loss: 2.8225121113561813

Epoch: 5| Step: 5
Training loss: 2.4218411445617676
Validation loss: 2.8219794432322183

Epoch: 5| Step: 6
Training loss: 3.4202628135681152
Validation loss: 2.8196303998270342

Epoch: 5| Step: 7
Training loss: 3.803086042404175
Validation loss: 2.81858403195617

Epoch: 5| Step: 8
Training loss: 2.721829891204834
Validation loss: 2.8204804030797814

Epoch: 5| Step: 9
Training loss: 2.4704699516296387
Validation loss: 2.820377640826728

Epoch: 5| Step: 10
Training loss: 3.1933047771453857
Validation loss: 2.8211777287144817

Epoch: 25| Step: 0
Training loss: 3.1366360187530518
Validation loss: 2.8147281856947046

Epoch: 5| Step: 1
Training loss: 2.344756603240967
Validation loss: 2.817094636219804

Epoch: 5| Step: 2
Training loss: 2.6355957984924316
Validation loss: 2.8123958674810265

Epoch: 5| Step: 3
Training loss: 3.0342140197753906
Validation loss: 2.8120115136587494

Epoch: 5| Step: 4
Training loss: 3.216297149658203
Validation loss: 2.811218725737705

Epoch: 5| Step: 5
Training loss: 2.409902572631836
Validation loss: 2.8110582751612507

Epoch: 5| Step: 6
Training loss: 3.238900661468506
Validation loss: 2.8120971187468498

Epoch: 5| Step: 7
Training loss: 2.7850441932678223
Validation loss: 2.8138080053432013

Epoch: 5| Step: 8
Training loss: 3.063584804534912
Validation loss: 2.8095284687575472

Epoch: 5| Step: 9
Training loss: 2.915386199951172
Validation loss: 2.8152360275227535

Epoch: 5| Step: 10
Training loss: 3.3119699954986572
Validation loss: 2.81822802687204

Epoch: 26| Step: 0
Training loss: 2.8875129222869873
Validation loss: 2.8188660478079193

Epoch: 5| Step: 1
Training loss: 2.9431920051574707
Validation loss: 2.898626865879182

Epoch: 5| Step: 2
Training loss: 3.3219597339630127
Validation loss: 2.818465086721605

Epoch: 5| Step: 3
Training loss: 2.991589307785034
Validation loss: 2.8067702734342186

Epoch: 5| Step: 4
Training loss: 3.0986950397491455
Validation loss: 2.8069398890259447

Epoch: 5| Step: 5
Training loss: 3.2138209342956543
Validation loss: 2.8376007900443128

Epoch: 5| Step: 6
Training loss: 2.389944553375244
Validation loss: 2.886284884586129

Epoch: 5| Step: 7
Training loss: 2.0079240798950195
Validation loss: 2.818647699971353

Epoch: 5| Step: 8
Training loss: 3.2083420753479004
Validation loss: 2.812227626000681

Epoch: 5| Step: 9
Training loss: 3.477518081665039
Validation loss: 2.80860044622934

Epoch: 5| Step: 10
Training loss: 2.6242451667785645
Validation loss: 2.80097540732353

Epoch: 27| Step: 0
Training loss: 2.209379196166992
Validation loss: 2.803319941284836

Epoch: 5| Step: 1
Training loss: 3.047217607498169
Validation loss: 2.803373567519649

Epoch: 5| Step: 2
Training loss: 3.044440507888794
Validation loss: 2.8073437572807394

Epoch: 5| Step: 3
Training loss: 2.110461950302124
Validation loss: 2.8041516478343675

Epoch: 5| Step: 4
Training loss: 2.5680480003356934
Validation loss: 2.7999633486552904

Epoch: 5| Step: 5
Training loss: 2.969364881515503
Validation loss: 2.804464522228446

Epoch: 5| Step: 6
Training loss: 3.5369839668273926
Validation loss: 2.808501443555278

Epoch: 5| Step: 7
Training loss: 3.2802436351776123
Validation loss: 2.812149963071269

Epoch: 5| Step: 8
Training loss: 2.489816427230835
Validation loss: 2.8052672955297653

Epoch: 5| Step: 9
Training loss: 3.6815345287323
Validation loss: 2.798809920587847

Epoch: 5| Step: 10
Training loss: 3.0489566326141357
Validation loss: 2.7933433440423783

Epoch: 28| Step: 0
Training loss: 3.2185654640197754
Validation loss: 2.7990285965704147

Epoch: 5| Step: 1
Training loss: 2.8308753967285156
Validation loss: 2.805320042435841

Epoch: 5| Step: 2
Training loss: 2.418680191040039
Validation loss: 2.798883104837069

Epoch: 5| Step: 3
Training loss: 2.4768686294555664
Validation loss: 2.7897158335613947

Epoch: 5| Step: 4
Training loss: 2.710132598876953
Validation loss: 2.785724973165861

Epoch: 5| Step: 5
Training loss: 3.3627307415008545
Validation loss: 2.7867441382459415

Epoch: 5| Step: 6
Training loss: 2.796051502227783
Validation loss: 2.7880374821283485

Epoch: 5| Step: 7
Training loss: 3.2722244262695312
Validation loss: 2.797266439724994

Epoch: 5| Step: 8
Training loss: 2.392570972442627
Validation loss: 2.793320950641427

Epoch: 5| Step: 9
Training loss: 2.5545389652252197
Validation loss: 2.7865367551003732

Epoch: 5| Step: 10
Training loss: 4.014350891113281
Validation loss: 2.780973113993163

Epoch: 29| Step: 0
Training loss: 2.5098400115966797
Validation loss: 2.776452431114771

Epoch: 5| Step: 1
Training loss: 3.811077833175659
Validation loss: 2.7799612322161273

Epoch: 5| Step: 2
Training loss: 2.6338143348693848
Validation loss: 2.7798441558755855

Epoch: 5| Step: 3
Training loss: 2.490238666534424
Validation loss: 2.780056950866535

Epoch: 5| Step: 4
Training loss: 2.4815592765808105
Validation loss: 2.777187531994235

Epoch: 5| Step: 5
Training loss: 2.74869966506958
Validation loss: 2.7772913773854575

Epoch: 5| Step: 6
Training loss: 3.0595364570617676
Validation loss: 2.7754786809285483

Epoch: 5| Step: 7
Training loss: 2.8928370475769043
Validation loss: 2.7721909194864254

Epoch: 5| Step: 8
Training loss: 2.448972702026367
Validation loss: 2.77197616587403

Epoch: 5| Step: 9
Training loss: 2.7319228649139404
Validation loss: 2.7710838804962816

Epoch: 5| Step: 10
Training loss: 4.12640380859375
Validation loss: 2.7733086616762224

Epoch: 30| Step: 0
Training loss: 2.3014111518859863
Validation loss: 2.777414560317993

Epoch: 5| Step: 1
Training loss: 3.3492884635925293
Validation loss: 2.775145205118323

Epoch: 5| Step: 2
Training loss: 1.5300980806350708
Validation loss: 2.7735240792715423

Epoch: 5| Step: 3
Training loss: 3.5070393085479736
Validation loss: 2.767720696746662

Epoch: 5| Step: 4
Training loss: 3.0825021266937256
Validation loss: 2.7720524188010924

Epoch: 5| Step: 5
Training loss: 2.4526286125183105
Validation loss: 2.7812504460734706

Epoch: 5| Step: 6
Training loss: 3.672100067138672
Validation loss: 2.7867386443640596

Epoch: 5| Step: 7
Training loss: 2.2809700965881348
Validation loss: 2.7728353725966586

Epoch: 5| Step: 8
Training loss: 2.9110450744628906
Validation loss: 2.7656249487271873

Epoch: 5| Step: 9
Training loss: 3.1358418464660645
Validation loss: 2.764390125069567

Epoch: 5| Step: 10
Training loss: 3.6584482192993164
Validation loss: 2.7632001881958335

Epoch: 31| Step: 0
Training loss: 2.4673824310302734
Validation loss: 2.7678053532877276

Epoch: 5| Step: 1
Training loss: 2.6394991874694824
Validation loss: 2.775276953174222

Epoch: 5| Step: 2
Training loss: 3.633704662322998
Validation loss: 2.783242587120302

Epoch: 5| Step: 3
Training loss: 2.399742364883423
Validation loss: 2.7924649715423584

Epoch: 5| Step: 4
Training loss: 3.203265428543091
Validation loss: 2.7722108248741395

Epoch: 5| Step: 5
Training loss: 2.430687427520752
Validation loss: 2.759839665505194

Epoch: 5| Step: 6
Training loss: 2.9003779888153076
Validation loss: 2.75578732644358

Epoch: 5| Step: 7
Training loss: 2.8215208053588867
Validation loss: 2.75704005969468

Epoch: 5| Step: 8
Training loss: 2.379230260848999
Validation loss: 2.757660086436938

Epoch: 5| Step: 9
Training loss: 3.5133070945739746
Validation loss: 2.7736318470329366

Epoch: 5| Step: 10
Training loss: 3.4295732975006104
Validation loss: 2.813714042786629

Epoch: 32| Step: 0
Training loss: 3.9361069202423096
Validation loss: 2.8111457722161406

Epoch: 5| Step: 1
Training loss: 2.6071484088897705
Validation loss: 2.764327579928983

Epoch: 5| Step: 2
Training loss: 1.9573428630828857
Validation loss: 2.752718146129321

Epoch: 5| Step: 3
Training loss: 2.582962989807129
Validation loss: 2.751747788921479

Epoch: 5| Step: 4
Training loss: 3.4361884593963623
Validation loss: 2.7554479568235335

Epoch: 5| Step: 5
Training loss: 3.3343968391418457
Validation loss: 2.758065621058146

Epoch: 5| Step: 6
Training loss: 2.94246768951416
Validation loss: 2.768052162662629

Epoch: 5| Step: 7
Training loss: 2.5875442028045654
Validation loss: 2.7552281887300554

Epoch: 5| Step: 8
Training loss: 2.6171257495880127
Validation loss: 2.750738254157446

Epoch: 5| Step: 9
Training loss: 3.064784526824951
Validation loss: 2.750110705693563

Epoch: 5| Step: 10
Training loss: 2.5658748149871826
Validation loss: 2.7525187666698168

Epoch: 33| Step: 0
Training loss: 2.724536418914795
Validation loss: 2.7573532494165565

Epoch: 5| Step: 1
Training loss: 3.3735015392303467
Validation loss: 2.7624092384051253

Epoch: 5| Step: 2
Training loss: 3.5660667419433594
Validation loss: 2.772723179991527

Epoch: 5| Step: 3
Training loss: 1.9993031024932861
Validation loss: 2.783754023172522

Epoch: 5| Step: 4
Training loss: 2.8296990394592285
Validation loss: 2.7630045516516573

Epoch: 5| Step: 5
Training loss: 3.2420215606689453
Validation loss: 2.760009019605575

Epoch: 5| Step: 6
Training loss: 2.8124136924743652
Validation loss: 2.7543039296263006

Epoch: 5| Step: 7
Training loss: 2.505125045776367
Validation loss: 2.751411627697688

Epoch: 5| Step: 8
Training loss: 2.614048719406128
Validation loss: 2.750786027600688

Epoch: 5| Step: 9
Training loss: 3.408311367034912
Validation loss: 2.755827542274229

Epoch: 5| Step: 10
Training loss: 2.522768497467041
Validation loss: 2.76150111357371

Epoch: 34| Step: 0
Training loss: 2.8057124614715576
Validation loss: 2.7629741955828924

Epoch: 5| Step: 1
Training loss: 2.6826393604278564
Validation loss: 2.758005795940276

Epoch: 5| Step: 2
Training loss: 3.2601771354675293
Validation loss: 2.7517070667718047

Epoch: 5| Step: 3
Training loss: 2.8430914878845215
Validation loss: 2.745488336009364

Epoch: 5| Step: 4
Training loss: 2.945991039276123
Validation loss: 2.7446967324902936

Epoch: 5| Step: 5
Training loss: 2.393852710723877
Validation loss: 2.738852580388387

Epoch: 5| Step: 6
Training loss: 2.7284646034240723
Validation loss: 2.7399118741353354

Epoch: 5| Step: 7
Training loss: 3.421294689178467
Validation loss: 2.7495257341733543

Epoch: 5| Step: 8
Training loss: 2.381141185760498
Validation loss: 2.744530447067753

Epoch: 5| Step: 9
Training loss: 3.1116974353790283
Validation loss: 2.738914810201173

Epoch: 5| Step: 10
Training loss: 2.920642852783203
Validation loss: 2.7377545397768737

Epoch: 35| Step: 0
Training loss: 2.717813491821289
Validation loss: 2.7395714200953

Epoch: 5| Step: 1
Training loss: 2.1445493698120117
Validation loss: 2.741415226331321

Epoch: 5| Step: 2
Training loss: 2.9167025089263916
Validation loss: 2.7578286663178475

Epoch: 5| Step: 3
Training loss: 3.3824684619903564
Validation loss: 2.7849825505287416

Epoch: 5| Step: 4
Training loss: 3.9274959564208984
Validation loss: 2.7837037860706286

Epoch: 5| Step: 5
Training loss: 2.914435863494873
Validation loss: 2.749208665663196

Epoch: 5| Step: 6
Training loss: 2.913804292678833
Validation loss: 2.7337651073291735

Epoch: 5| Step: 7
Training loss: 2.008514165878296
Validation loss: 2.732220385664253

Epoch: 5| Step: 8
Training loss: 2.8550143241882324
Validation loss: 2.747659429427116

Epoch: 5| Step: 9
Training loss: 2.9410476684570312
Validation loss: 2.767451996444374

Epoch: 5| Step: 10
Training loss: 2.88988995552063
Validation loss: 2.740179051635086

Epoch: 36| Step: 0
Training loss: 1.7472645044326782
Validation loss: 2.7313141925360567

Epoch: 5| Step: 1
Training loss: 2.977595329284668
Validation loss: 2.729421733528055

Epoch: 5| Step: 2
Training loss: 2.702488899230957
Validation loss: 2.7598184898335445

Epoch: 5| Step: 3
Training loss: 3.2803854942321777
Validation loss: 2.82031830920968

Epoch: 5| Step: 4
Training loss: 3.097644329071045
Validation loss: 2.8496379903567735

Epoch: 5| Step: 5
Training loss: 2.666059732437134
Validation loss: 2.8108710089037494

Epoch: 5| Step: 6
Training loss: 2.9377002716064453
Validation loss: 2.782897751818421

Epoch: 5| Step: 7
Training loss: 2.5895836353302
Validation loss: 2.7570891687946935

Epoch: 5| Step: 8
Training loss: 2.5511202812194824
Validation loss: 2.753096990687873

Epoch: 5| Step: 9
Training loss: 3.450023651123047
Validation loss: 2.75955944420189

Epoch: 5| Step: 10
Training loss: 3.8033883571624756
Validation loss: 2.7525046563917592

Epoch: 37| Step: 0
Training loss: 1.9154504537582397
Validation loss: 2.7325466935352614

Epoch: 5| Step: 1
Training loss: 3.3789336681365967
Validation loss: 2.729314024730395

Epoch: 5| Step: 2
Training loss: 3.6762633323669434
Validation loss: 2.7310447051960933

Epoch: 5| Step: 3
Training loss: 2.5521469116210938
Validation loss: 2.727101195243097

Epoch: 5| Step: 4
Training loss: 2.7336108684539795
Validation loss: 2.7287194959578978

Epoch: 5| Step: 5
Training loss: 2.370657444000244
Validation loss: 2.7261720652221353

Epoch: 5| Step: 6
Training loss: 3.6885204315185547
Validation loss: 2.7279094752445014

Epoch: 5| Step: 7
Training loss: 3.08500337600708
Validation loss: 2.7257159961167203

Epoch: 5| Step: 8
Training loss: 2.018122434616089
Validation loss: 2.724029330797093

Epoch: 5| Step: 9
Training loss: 2.9782779216766357
Validation loss: 2.720005391746439

Epoch: 5| Step: 10
Training loss: 2.9918298721313477
Validation loss: 2.72018511320955

Epoch: 38| Step: 0
Training loss: 2.571556568145752
Validation loss: 2.7201029280180573

Epoch: 5| Step: 1
Training loss: 3.421945571899414
Validation loss: 2.7177600706777265

Epoch: 5| Step: 2
Training loss: 2.1675374507904053
Validation loss: 2.7251361416232203

Epoch: 5| Step: 3
Training loss: 3.1918344497680664
Validation loss: 2.719671723663166

Epoch: 5| Step: 4
Training loss: 2.5111212730407715
Validation loss: 2.7232653094876196

Epoch: 5| Step: 5
Training loss: 2.9943995475769043
Validation loss: 2.7255730398239626

Epoch: 5| Step: 6
Training loss: 2.5338377952575684
Validation loss: 2.7210258642832437

Epoch: 5| Step: 7
Training loss: 2.929405450820923
Validation loss: 2.7157276163819017

Epoch: 5| Step: 8
Training loss: 3.5061163902282715
Validation loss: 2.7133581253790084

Epoch: 5| Step: 9
Training loss: 2.3414406776428223
Validation loss: 2.71412996579242

Epoch: 5| Step: 10
Training loss: 3.0851237773895264
Validation loss: 2.7128324585576213

Epoch: 39| Step: 0
Training loss: 2.7904889583587646
Validation loss: 2.7117836552281536

Epoch: 5| Step: 1
Training loss: 2.69606876373291
Validation loss: 2.7105834150827057

Epoch: 5| Step: 2
Training loss: 3.1419577598571777
Validation loss: 2.709770735873971

Epoch: 5| Step: 3
Training loss: 2.5985183715820312
Validation loss: 2.709051788494151

Epoch: 5| Step: 4
Training loss: 3.197483539581299
Validation loss: 2.707935192251718

Epoch: 5| Step: 5
Training loss: 3.682112216949463
Validation loss: 2.70501188565326

Epoch: 5| Step: 6
Training loss: 2.6802802085876465
Validation loss: 2.7073164434843164

Epoch: 5| Step: 7
Training loss: 3.127549648284912
Validation loss: 2.716525549529701

Epoch: 5| Step: 8
Training loss: 2.789604425430298
Validation loss: 2.7129500553172123

Epoch: 5| Step: 9
Training loss: 1.9031317234039307
Validation loss: 2.72351925347441

Epoch: 5| Step: 10
Training loss: 2.5018856525421143
Validation loss: 2.7298923666759203

Epoch: 40| Step: 0
Training loss: 2.5287368297576904
Validation loss: 2.7285108899557464

Epoch: 5| Step: 1
Training loss: 2.9443695545196533
Validation loss: 2.734052768317602

Epoch: 5| Step: 2
Training loss: 3.0450427532196045
Validation loss: 2.7224292037307576

Epoch: 5| Step: 3
Training loss: 3.0622782707214355
Validation loss: 2.7190841090294624

Epoch: 5| Step: 4
Training loss: 3.217200756072998
Validation loss: 2.7082943326683453

Epoch: 5| Step: 5
Training loss: 2.3083386421203613
Validation loss: 2.6961096820010932

Epoch: 5| Step: 6
Training loss: 2.6840121746063232
Validation loss: 2.698649003941526

Epoch: 5| Step: 7
Training loss: 2.753391742706299
Validation loss: 2.6994064597673315

Epoch: 5| Step: 8
Training loss: 2.918996810913086
Validation loss: 2.700538848036079

Epoch: 5| Step: 9
Training loss: 3.4770331382751465
Validation loss: 2.7000901186338035

Epoch: 5| Step: 10
Training loss: 2.1151764392852783
Validation loss: 2.6947542877607447

Epoch: 41| Step: 0
Training loss: 2.3542027473449707
Validation loss: 2.693231726205477

Epoch: 5| Step: 1
Training loss: 2.6140050888061523
Validation loss: 2.693251779002528

Epoch: 5| Step: 2
Training loss: 2.4672152996063232
Validation loss: 2.6915833360405377

Epoch: 5| Step: 3
Training loss: 2.3241779804229736
Validation loss: 2.6911392468278126

Epoch: 5| Step: 4
Training loss: 3.2393951416015625
Validation loss: 2.6910607404606317

Epoch: 5| Step: 5
Training loss: 2.907763719558716
Validation loss: 2.6920405126387075

Epoch: 5| Step: 6
Training loss: 3.0210444927215576
Validation loss: 2.688417847438525

Epoch: 5| Step: 7
Training loss: 2.4851081371307373
Validation loss: 2.6883046870590537

Epoch: 5| Step: 8
Training loss: 3.438676118850708
Validation loss: 2.6861607669502177

Epoch: 5| Step: 9
Training loss: 3.2210445404052734
Validation loss: 2.690462455954603

Epoch: 5| Step: 10
Training loss: 2.916074514389038
Validation loss: 2.68701183924111

Epoch: 42| Step: 0
Training loss: 2.842547655105591
Validation loss: 2.6874654933970463

Epoch: 5| Step: 1
Training loss: 3.0760695934295654
Validation loss: 2.6860482846536944

Epoch: 5| Step: 2
Training loss: 2.8272013664245605
Validation loss: 2.691675857831073

Epoch: 5| Step: 3
Training loss: 2.6528255939483643
Validation loss: 2.6871756558777182

Epoch: 5| Step: 4
Training loss: 2.9132299423217773
Validation loss: 2.6845732145411993

Epoch: 5| Step: 5
Training loss: 3.0455689430236816
Validation loss: 2.6807329500875166

Epoch: 5| Step: 6
Training loss: 2.7564613819122314
Validation loss: 2.6861264833839993

Epoch: 5| Step: 7
Training loss: 2.293189287185669
Validation loss: 2.6871519652746056

Epoch: 5| Step: 8
Training loss: 3.276456832885742
Validation loss: 2.684787601552984

Epoch: 5| Step: 9
Training loss: 2.307284116744995
Validation loss: 2.684400568726242

Epoch: 5| Step: 10
Training loss: 3.0447988510131836
Validation loss: 2.6787345153029247

Epoch: 43| Step: 0
Training loss: 3.0795674324035645
Validation loss: 2.6766048682633268

Epoch: 5| Step: 1
Training loss: 2.7446484565734863
Validation loss: 2.672846491618823

Epoch: 5| Step: 2
Training loss: 2.5696351528167725
Validation loss: 2.671246183815823

Epoch: 5| Step: 3
Training loss: 2.932725667953491
Validation loss: 2.673744883588565

Epoch: 5| Step: 4
Training loss: 2.62371826171875
Validation loss: 2.67781372480495

Epoch: 5| Step: 5
Training loss: 2.8490376472473145
Validation loss: 2.677236423697523

Epoch: 5| Step: 6
Training loss: 2.3885555267333984
Validation loss: 2.6690343990120837

Epoch: 5| Step: 7
Training loss: 2.9536869525909424
Validation loss: 2.669208352283765

Epoch: 5| Step: 8
Training loss: 3.431720733642578
Validation loss: 2.6689172483259633

Epoch: 5| Step: 9
Training loss: 2.8077926635742188
Validation loss: 2.6685920094931

Epoch: 5| Step: 10
Training loss: 2.5073421001434326
Validation loss: 2.669557935448103

Epoch: 44| Step: 0
Training loss: 2.3115272521972656
Validation loss: 2.666016770947364

Epoch: 5| Step: 1
Training loss: 3.337144374847412
Validation loss: 2.66705975737623

Epoch: 5| Step: 2
Training loss: 2.540560483932495
Validation loss: 2.667003390609577

Epoch: 5| Step: 3
Training loss: 3.5098814964294434
Validation loss: 2.6641048513432986

Epoch: 5| Step: 4
Training loss: 3.352283477783203
Validation loss: 2.663203554768716

Epoch: 5| Step: 5
Training loss: 2.6933906078338623
Validation loss: 2.6657074651410504

Epoch: 5| Step: 6
Training loss: 2.6837868690490723
Validation loss: 2.6672957071693997

Epoch: 5| Step: 7
Training loss: 3.015784502029419
Validation loss: 2.673790882992488

Epoch: 5| Step: 8
Training loss: 2.7992591857910156
Validation loss: 2.689324120039581

Epoch: 5| Step: 9
Training loss: 2.2470364570617676
Validation loss: 2.6787220739549205

Epoch: 5| Step: 10
Training loss: 2.3326783180236816
Validation loss: 2.6707369563400105

Epoch: 45| Step: 0
Training loss: 3.5052847862243652
Validation loss: 2.66203446157517

Epoch: 5| Step: 1
Training loss: 1.8790075778961182
Validation loss: 2.656688100548201

Epoch: 5| Step: 2
Training loss: 3.117070436477661
Validation loss: 2.6570775739608274

Epoch: 5| Step: 3
Training loss: 2.6728014945983887
Validation loss: 2.6574211069332656

Epoch: 5| Step: 4
Training loss: 2.6608738899230957
Validation loss: 2.659022610674622

Epoch: 5| Step: 5
Training loss: 2.7089200019836426
Validation loss: 2.6622106721324306

Epoch: 5| Step: 6
Training loss: 3.1643569469451904
Validation loss: 2.6653190428210842

Epoch: 5| Step: 7
Training loss: 2.317093849182129
Validation loss: 2.6652854565651185

Epoch: 5| Step: 8
Training loss: 2.7277474403381348
Validation loss: 2.6634002654783187

Epoch: 5| Step: 9
Training loss: 3.0356945991516113
Validation loss: 2.6579905889367543

Epoch: 5| Step: 10
Training loss: 3.0376546382904053
Validation loss: 2.6505600611368814

Epoch: 46| Step: 0
Training loss: 2.747431755065918
Validation loss: 2.648579264199862

Epoch: 5| Step: 1
Training loss: 2.9614689350128174
Validation loss: 2.647224598033454

Epoch: 5| Step: 2
Training loss: 2.429166316986084
Validation loss: 2.649090282378658

Epoch: 5| Step: 3
Training loss: 2.625732421875
Validation loss: 2.657475633005942

Epoch: 5| Step: 4
Training loss: 2.5758917331695557
Validation loss: 2.651364880223428

Epoch: 5| Step: 5
Training loss: 2.729968309402466
Validation loss: 2.646724654782203

Epoch: 5| Step: 6
Training loss: 3.3797576427459717
Validation loss: 2.643695985117266

Epoch: 5| Step: 7
Training loss: 2.343708038330078
Validation loss: 2.6433715448584607

Epoch: 5| Step: 8
Training loss: 2.700096607208252
Validation loss: 2.64855460710423

Epoch: 5| Step: 9
Training loss: 3.240412950515747
Validation loss: 2.6528804545761435

Epoch: 5| Step: 10
Training loss: 3.0138027667999268
Validation loss: 2.654969112847441

Epoch: 47| Step: 0
Training loss: 3.0670084953308105
Validation loss: 2.6524886546596402

Epoch: 5| Step: 1
Training loss: 2.291644811630249
Validation loss: 2.6495042898321666

Epoch: 5| Step: 2
Training loss: 3.2586750984191895
Validation loss: 2.6494587416289956

Epoch: 5| Step: 3
Training loss: 3.037263870239258
Validation loss: 2.645112127386114

Epoch: 5| Step: 4
Training loss: 2.499783992767334
Validation loss: 2.6428935989256828

Epoch: 5| Step: 5
Training loss: 2.678389549255371
Validation loss: 2.639591481096001

Epoch: 5| Step: 6
Training loss: 2.927180290222168
Validation loss: 2.6413160190787366

Epoch: 5| Step: 7
Training loss: 2.737863302230835
Validation loss: 2.641951245646323

Epoch: 5| Step: 8
Training loss: 3.268671751022339
Validation loss: 2.637772878011068

Epoch: 5| Step: 9
Training loss: 2.7500967979431152
Validation loss: 2.6432066502109652

Epoch: 5| Step: 10
Training loss: 2.094456195831299
Validation loss: 2.6456962170139438

Epoch: 48| Step: 0
Training loss: 2.9472947120666504
Validation loss: 2.6412925771487656

Epoch: 5| Step: 1
Training loss: 2.7774345874786377
Validation loss: 2.642830502602362

Epoch: 5| Step: 2
Training loss: 2.6493165493011475
Validation loss: 2.636551856994629

Epoch: 5| Step: 3
Training loss: 2.581118106842041
Validation loss: 2.635334776293847

Epoch: 5| Step: 4
Training loss: 2.6202938556671143
Validation loss: 2.634821202165337

Epoch: 5| Step: 5
Training loss: 2.9285826683044434
Validation loss: 2.6343536658953597

Epoch: 5| Step: 6
Training loss: 2.795609712600708
Validation loss: 2.6335600960639214

Epoch: 5| Step: 7
Training loss: 2.7877354621887207
Validation loss: 2.6335518513956377

Epoch: 5| Step: 8
Training loss: 3.2916131019592285
Validation loss: 2.6328282792081117

Epoch: 5| Step: 9
Training loss: 2.739409923553467
Validation loss: 2.638818399880522

Epoch: 5| Step: 10
Training loss: 2.4231395721435547
Validation loss: 2.6384850727614535

Epoch: 49| Step: 0
Training loss: 2.714595317840576
Validation loss: 2.640644842578519

Epoch: 5| Step: 1
Training loss: 2.9426941871643066
Validation loss: 2.6493031811970535

Epoch: 5| Step: 2
Training loss: 3.3773720264434814
Validation loss: 2.6561569782995407

Epoch: 5| Step: 3
Training loss: 3.0771422386169434
Validation loss: 2.64138985449268

Epoch: 5| Step: 4
Training loss: 2.9730000495910645
Validation loss: 2.6301174112545547

Epoch: 5| Step: 5
Training loss: 2.4788661003112793
Validation loss: 2.6269412835439048

Epoch: 5| Step: 6
Training loss: 2.674962282180786
Validation loss: 2.6290260104722876

Epoch: 5| Step: 7
Training loss: 2.6199395656585693
Validation loss: 2.627988483316155

Epoch: 5| Step: 8
Training loss: 2.439061403274536
Validation loss: 2.6286839695386988

Epoch: 5| Step: 9
Training loss: 2.4696412086486816
Validation loss: 2.6246629735474944

Epoch: 5| Step: 10
Training loss: 2.84613037109375
Validation loss: 2.6244914890617452

Epoch: 50| Step: 0
Training loss: 3.1116340160369873
Validation loss: 2.633370032874487

Epoch: 5| Step: 1
Training loss: 2.9350638389587402
Validation loss: 2.6367490445413897

Epoch: 5| Step: 2
Training loss: 2.706028461456299
Validation loss: 2.629200622599612

Epoch: 5| Step: 3
Training loss: 2.057042121887207
Validation loss: 2.623969998410953

Epoch: 5| Step: 4
Training loss: 2.7827746868133545
Validation loss: 2.620026698676489

Epoch: 5| Step: 5
Training loss: 2.766721248626709
Validation loss: 2.616748527813983

Epoch: 5| Step: 6
Training loss: 2.6791298389434814
Validation loss: 2.617590988835981

Epoch: 5| Step: 7
Training loss: 2.327130079269409
Validation loss: 2.617218314960439

Epoch: 5| Step: 8
Training loss: 3.344158887863159
Validation loss: 2.621508308636245

Epoch: 5| Step: 9
Training loss: 2.666670322418213
Validation loss: 2.6200277907873994

Epoch: 5| Step: 10
Training loss: 3.139496088027954
Validation loss: 2.6213528135771393

Epoch: 51| Step: 0
Training loss: 2.973870277404785
Validation loss: 2.6289860048601703

Epoch: 5| Step: 1
Training loss: 3.105802536010742
Validation loss: 2.625508177664972

Epoch: 5| Step: 2
Training loss: 1.8967335224151611
Validation loss: 2.620705460989347

Epoch: 5| Step: 3
Training loss: 3.075340986251831
Validation loss: 2.615002865432411

Epoch: 5| Step: 4
Training loss: 3.1399381160736084
Validation loss: 2.6108817156924995

Epoch: 5| Step: 5
Training loss: 2.3726096153259277
Validation loss: 2.615056924922492

Epoch: 5| Step: 6
Training loss: 3.222811222076416
Validation loss: 2.611001496673912

Epoch: 5| Step: 7
Training loss: 1.940777063369751
Validation loss: 2.6165216225449757

Epoch: 5| Step: 8
Training loss: 2.6717867851257324
Validation loss: 2.6105840052327802

Epoch: 5| Step: 9
Training loss: 2.502864122390747
Validation loss: 2.6029768195203555

Epoch: 5| Step: 10
Training loss: 3.7167913913726807
Validation loss: 2.6029108955014135

Epoch: 52| Step: 0
Training loss: 3.1394810676574707
Validation loss: 2.6020129726779078

Epoch: 5| Step: 1
Training loss: 2.995239734649658
Validation loss: 2.6024654321773077

Epoch: 5| Step: 2
Training loss: 2.873267412185669
Validation loss: 2.6027806958844586

Epoch: 5| Step: 3
Training loss: 2.8124163150787354
Validation loss: 2.6038374234271306

Epoch: 5| Step: 4
Training loss: 2.1948182582855225
Validation loss: 2.6027177046704035

Epoch: 5| Step: 5
Training loss: 2.3444199562072754
Validation loss: 2.600468656068207

Epoch: 5| Step: 6
Training loss: 3.1825523376464844
Validation loss: 2.60075193835843

Epoch: 5| Step: 7
Training loss: 2.4245448112487793
Validation loss: 2.5992005871188257

Epoch: 5| Step: 8
Training loss: 2.386272668838501
Validation loss: 2.597716551955028

Epoch: 5| Step: 9
Training loss: 2.5827436447143555
Validation loss: 2.5975740673721477

Epoch: 5| Step: 10
Training loss: 3.5591843128204346
Validation loss: 2.5951166204226914

Epoch: 53| Step: 0
Training loss: 2.5230789184570312
Validation loss: 2.596230040314377

Epoch: 5| Step: 1
Training loss: 3.200223445892334
Validation loss: 2.5956253133794314

Epoch: 5| Step: 2
Training loss: 2.4509687423706055
Validation loss: 2.593241572380066

Epoch: 5| Step: 3
Training loss: 3.3217062950134277
Validation loss: 2.5936283731973298

Epoch: 5| Step: 4
Training loss: 2.816760301589966
Validation loss: 2.5924308146199873

Epoch: 5| Step: 5
Training loss: 3.1080069541931152
Validation loss: 2.5931155194518385

Epoch: 5| Step: 6
Training loss: 2.243262767791748
Validation loss: 2.5988657679609073

Epoch: 5| Step: 7
Training loss: 1.6340802907943726
Validation loss: 2.5940228610910396

Epoch: 5| Step: 8
Training loss: 2.7932872772216797
Validation loss: 2.592117832553002

Epoch: 5| Step: 9
Training loss: 2.7725002765655518
Validation loss: 2.5928483163156817

Epoch: 5| Step: 10
Training loss: 3.5675039291381836
Validation loss: 2.592740927973101

Epoch: 54| Step: 0
Training loss: 3.1659786701202393
Validation loss: 2.590847440945205

Epoch: 5| Step: 1
Training loss: 3.4097790718078613
Validation loss: 2.589749297788066

Epoch: 5| Step: 2
Training loss: 2.5105795860290527
Validation loss: 2.5886753900076753

Epoch: 5| Step: 3
Training loss: 2.777992010116577
Validation loss: 2.5875479021380023

Epoch: 5| Step: 4
Training loss: 2.287297010421753
Validation loss: 2.5881538801295783

Epoch: 5| Step: 5
Training loss: 2.709007978439331
Validation loss: 2.591020809706821

Epoch: 5| Step: 6
Training loss: 3.0381827354431152
Validation loss: 2.5863317417842087

Epoch: 5| Step: 7
Training loss: 3.5129828453063965
Validation loss: 2.590153173733783

Epoch: 5| Step: 8
Training loss: 2.428131103515625
Validation loss: 2.589022098049041

Epoch: 5| Step: 9
Training loss: 2.500290632247925
Validation loss: 2.59048935931216

Epoch: 5| Step: 10
Training loss: 1.7193082571029663
Validation loss: 2.5854133944357596

Epoch: 55| Step: 0
Training loss: 2.9596409797668457
Validation loss: 2.5861976813244563

Epoch: 5| Step: 1
Training loss: 2.6952896118164062
Validation loss: 2.5942894668989283

Epoch: 5| Step: 2
Training loss: 2.0418636798858643
Validation loss: 2.5941284036123626

Epoch: 5| Step: 3
Training loss: 2.7153561115264893
Validation loss: 2.591300077335809

Epoch: 5| Step: 4
Training loss: 3.209901809692383
Validation loss: 2.5978226148954002

Epoch: 5| Step: 5
Training loss: 2.200167179107666
Validation loss: 2.591821385968116

Epoch: 5| Step: 6
Training loss: 2.559582233428955
Validation loss: 2.5822970328792447

Epoch: 5| Step: 7
Training loss: 3.6442923545837402
Validation loss: 2.5806107110874628

Epoch: 5| Step: 8
Training loss: 2.6355807781219482
Validation loss: 2.582932674756614

Epoch: 5| Step: 9
Training loss: 2.450592041015625
Validation loss: 2.5849545078892864

Epoch: 5| Step: 10
Training loss: 3.193801164627075
Validation loss: 2.586547218343263

Epoch: 56| Step: 0
Training loss: 3.1262054443359375
Validation loss: 2.577473889115036

Epoch: 5| Step: 1
Training loss: 2.344712018966675
Validation loss: 2.575836863569034

Epoch: 5| Step: 2
Training loss: 2.213771343231201
Validation loss: 2.5721597620235976

Epoch: 5| Step: 3
Training loss: 3.0866360664367676
Validation loss: 2.5668338626943608

Epoch: 5| Step: 4
Training loss: 3.4857330322265625
Validation loss: 2.5700751466135823

Epoch: 5| Step: 5
Training loss: 2.5159685611724854
Validation loss: 2.5686877876199703

Epoch: 5| Step: 6
Training loss: 2.6783018112182617
Validation loss: 2.5725848777319795

Epoch: 5| Step: 7
Training loss: 2.2960262298583984
Validation loss: 2.5797520734930552

Epoch: 5| Step: 8
Training loss: 2.898158311843872
Validation loss: 2.576709742187172

Epoch: 5| Step: 9
Training loss: 3.3968520164489746
Validation loss: 2.569190917476531

Epoch: 5| Step: 10
Training loss: 1.9691213369369507
Validation loss: 2.567285829974759

Epoch: 57| Step: 0
Training loss: 2.135523796081543
Validation loss: 2.562669143881849

Epoch: 5| Step: 1
Training loss: 3.3610730171203613
Validation loss: 2.56293818002106

Epoch: 5| Step: 2
Training loss: 3.169254779815674
Validation loss: 2.5643346591662337

Epoch: 5| Step: 3
Training loss: 2.5530285835266113
Validation loss: 2.565207196820167

Epoch: 5| Step: 4
Training loss: 2.851184368133545
Validation loss: 2.5659975954281387

Epoch: 5| Step: 5
Training loss: 2.3233447074890137
Validation loss: 2.5663537004942536

Epoch: 5| Step: 6
Training loss: 2.7450637817382812
Validation loss: 2.564648223179643

Epoch: 5| Step: 7
Training loss: 2.1387717723846436
Validation loss: 2.564386475470758

Epoch: 5| Step: 8
Training loss: 2.9714348316192627
Validation loss: 2.564554229859383

Epoch: 5| Step: 9
Training loss: 3.1801772117614746
Validation loss: 2.572545564302834

Epoch: 5| Step: 10
Training loss: 2.604515790939331
Validation loss: 2.579705394724364

Epoch: 58| Step: 0
Training loss: 2.3121402263641357
Validation loss: 2.594453478372225

Epoch: 5| Step: 1
Training loss: 2.951892375946045
Validation loss: 2.611184007378035

Epoch: 5| Step: 2
Training loss: 2.452258348464966
Validation loss: 2.6445517693796465

Epoch: 5| Step: 3
Training loss: 2.590702772140503
Validation loss: 2.596475580687164

Epoch: 5| Step: 4
Training loss: 3.2525906562805176
Validation loss: 2.564397322234287

Epoch: 5| Step: 5
Training loss: 3.0027401447296143
Validation loss: 2.5579036435773297

Epoch: 5| Step: 6
Training loss: 2.2863571643829346
Validation loss: 2.57295730293438

Epoch: 5| Step: 7
Training loss: 2.4944849014282227
Validation loss: 2.620144062144782

Epoch: 5| Step: 8
Training loss: 3.2258095741271973
Validation loss: 2.6253205730069067

Epoch: 5| Step: 9
Training loss: 3.2747414112091064
Validation loss: 2.584910169724495

Epoch: 5| Step: 10
Training loss: 2.502291440963745
Validation loss: 2.562039536814536

Epoch: 59| Step: 0
Training loss: 2.6725666522979736
Validation loss: 2.5493603726868987

Epoch: 5| Step: 1
Training loss: 2.639251470565796
Validation loss: 2.563576662412254

Epoch: 5| Step: 2
Training loss: 2.9260616302490234
Validation loss: 2.6345107581025813

Epoch: 5| Step: 3
Training loss: 3.1418941020965576
Validation loss: 2.692869435074509

Epoch: 5| Step: 4
Training loss: 2.935652494430542
Validation loss: 2.6986133103729575

Epoch: 5| Step: 5
Training loss: 2.54580020904541
Validation loss: 2.688215850501932

Epoch: 5| Step: 6
Training loss: 2.615658760070801
Validation loss: 2.6402726839947444

Epoch: 5| Step: 7
Training loss: 2.4591147899627686
Validation loss: 2.559263070424398

Epoch: 5| Step: 8
Training loss: 2.7949767112731934
Validation loss: 2.554227613633679

Epoch: 5| Step: 9
Training loss: 2.5657293796539307
Validation loss: 2.611335490339546

Epoch: 5| Step: 10
Training loss: 3.4060521125793457
Validation loss: 2.711004913494151

Epoch: 60| Step: 0
Training loss: 2.7329368591308594
Validation loss: 2.783168826051938

Epoch: 5| Step: 1
Training loss: 3.3590807914733887
Validation loss: 2.6975900588497037

Epoch: 5| Step: 2
Training loss: 3.174799919128418
Validation loss: 2.5877226962838122

Epoch: 5| Step: 3
Training loss: 2.8886187076568604
Validation loss: 2.5605494591497604

Epoch: 5| Step: 4
Training loss: 2.9213814735412598
Validation loss: 2.554916017798967

Epoch: 5| Step: 5
Training loss: 2.494520902633667
Validation loss: 2.580492409326697

Epoch: 5| Step: 6
Training loss: 2.4994654655456543
Validation loss: 2.637378647763242

Epoch: 5| Step: 7
Training loss: 2.3932507038116455
Validation loss: 2.670455209670528

Epoch: 5| Step: 8
Training loss: 2.6841750144958496
Validation loss: 2.706109857046476

Epoch: 5| Step: 9
Training loss: 2.6001670360565186
Validation loss: 2.700770103803245

Epoch: 5| Step: 10
Training loss: 3.0355730056762695
Validation loss: 2.631381283524216

Epoch: 61| Step: 0
Training loss: 2.7882142066955566
Validation loss: 2.5538651174114597

Epoch: 5| Step: 1
Training loss: 2.6344738006591797
Validation loss: 2.541984304305046

Epoch: 5| Step: 2
Training loss: 2.4961631298065186
Validation loss: 2.5488477778691117

Epoch: 5| Step: 3
Training loss: 2.9483718872070312
Validation loss: 2.563602355218703

Epoch: 5| Step: 4
Training loss: 2.554131269454956
Validation loss: 2.585985729771276

Epoch: 5| Step: 5
Training loss: 1.9715217351913452
Validation loss: 2.6178797573171635

Epoch: 5| Step: 6
Training loss: 3.250960111618042
Validation loss: 2.636801158228228

Epoch: 5| Step: 7
Training loss: 2.5362792015075684
Validation loss: 2.631467914068571

Epoch: 5| Step: 8
Training loss: 3.294365406036377
Validation loss: 2.5955696567412345

Epoch: 5| Step: 9
Training loss: 2.9372763633728027
Validation loss: 2.5625013818023024

Epoch: 5| Step: 10
Training loss: 2.998758554458618
Validation loss: 2.5527671075636342

Epoch: 62| Step: 0
Training loss: 2.354172468185425
Validation loss: 2.5455400379755164

Epoch: 5| Step: 1
Training loss: 2.778096914291382
Validation loss: 2.5417405661716255

Epoch: 5| Step: 2
Training loss: 2.9420571327209473
Validation loss: 2.5372401027269262

Epoch: 5| Step: 3
Training loss: 2.59895658493042
Validation loss: 2.5469923839774182

Epoch: 5| Step: 4
Training loss: 2.8961853981018066
Validation loss: 2.545513947804769

Epoch: 5| Step: 5
Training loss: 2.4841790199279785
Validation loss: 2.540193047574771

Epoch: 5| Step: 6
Training loss: 2.8153185844421387
Validation loss: 2.530135170105965

Epoch: 5| Step: 7
Training loss: 2.358654022216797
Validation loss: 2.5263314964950725

Epoch: 5| Step: 8
Training loss: 2.9325366020202637
Validation loss: 2.533375673396613

Epoch: 5| Step: 9
Training loss: 3.0164902210235596
Validation loss: 2.539621273676554

Epoch: 5| Step: 10
Training loss: 2.811732053756714
Validation loss: 2.5445873122061453

Epoch: 63| Step: 0
Training loss: 2.138406753540039
Validation loss: 2.5389888158408542

Epoch: 5| Step: 1
Training loss: 3.1328883171081543
Validation loss: 2.539890989180534

Epoch: 5| Step: 2
Training loss: 2.932133674621582
Validation loss: 2.5342318473323697

Epoch: 5| Step: 3
Training loss: 2.8291726112365723
Validation loss: 2.528214518741895

Epoch: 5| Step: 4
Training loss: 2.0965049266815186
Validation loss: 2.53579968021762

Epoch: 5| Step: 5
Training loss: 2.9537289142608643
Validation loss: 2.533451605868596

Epoch: 5| Step: 6
Training loss: 3.1280341148376465
Validation loss: 2.5312485899976505

Epoch: 5| Step: 7
Training loss: 2.3357348442077637
Validation loss: 2.527161987878943

Epoch: 5| Step: 8
Training loss: 2.807748794555664
Validation loss: 2.525038347449354

Epoch: 5| Step: 9
Training loss: 2.584162950515747
Validation loss: 2.5232297579447427

Epoch: 5| Step: 10
Training loss: 2.8673110008239746
Validation loss: 2.522516691556541

Epoch: 64| Step: 0
Training loss: 3.1724324226379395
Validation loss: 2.5229766112501903

Epoch: 5| Step: 1
Training loss: 2.206845998764038
Validation loss: 2.5240893235770603

Epoch: 5| Step: 2
Training loss: 2.486560821533203
Validation loss: 2.5327753366962558

Epoch: 5| Step: 3
Training loss: 3.1549551486968994
Validation loss: 2.5379135377945437

Epoch: 5| Step: 4
Training loss: 3.8828587532043457
Validation loss: 2.547322598836755

Epoch: 5| Step: 5
Training loss: 2.3911659717559814
Validation loss: 2.5447082058075936

Epoch: 5| Step: 6
Training loss: 2.907095193862915
Validation loss: 2.5423274758041545

Epoch: 5| Step: 7
Training loss: 2.0968563556671143
Validation loss: 2.5416766546105825

Epoch: 5| Step: 8
Training loss: 2.450226068496704
Validation loss: 2.544887404288015

Epoch: 5| Step: 9
Training loss: 2.426079750061035
Validation loss: 2.542341239990727

Epoch: 5| Step: 10
Training loss: 2.5949957370758057
Validation loss: 2.533427587119482

Epoch: 65| Step: 0
Training loss: 2.9213974475860596
Validation loss: 2.535271821483489

Epoch: 5| Step: 1
Training loss: 2.4836268424987793
Validation loss: 2.5257468326117403

Epoch: 5| Step: 2
Training loss: 2.8406319618225098
Validation loss: 2.5162225205411195

Epoch: 5| Step: 3
Training loss: 3.2996010780334473
Validation loss: 2.5151132819473103

Epoch: 5| Step: 4
Training loss: 2.219637155532837
Validation loss: 2.515679615800099

Epoch: 5| Step: 5
Training loss: 2.5612399578094482
Validation loss: 2.5182342683115313

Epoch: 5| Step: 6
Training loss: 3.2531967163085938
Validation loss: 2.515886301635414

Epoch: 5| Step: 7
Training loss: 1.976365327835083
Validation loss: 2.516758108651766

Epoch: 5| Step: 8
Training loss: 2.7086071968078613
Validation loss: 2.518994797942459

Epoch: 5| Step: 9
Training loss: 2.9157135486602783
Validation loss: 2.5182235497300343

Epoch: 5| Step: 10
Training loss: 2.487806797027588
Validation loss: 2.5116378786743327

Epoch: 66| Step: 0
Training loss: 2.4362130165100098
Validation loss: 2.5078304249753236

Epoch: 5| Step: 1
Training loss: 2.8500723838806152
Validation loss: 2.506885579837266

Epoch: 5| Step: 2
Training loss: 2.2062771320343018
Validation loss: 2.5064269522184968

Epoch: 5| Step: 3
Training loss: 3.373051404953003
Validation loss: 2.511874621914279

Epoch: 5| Step: 4
Training loss: 3.286947727203369
Validation loss: 2.511926363873225

Epoch: 5| Step: 5
Training loss: 2.5290160179138184
Validation loss: 2.5135923688129713

Epoch: 5| Step: 6
Training loss: 2.4211463928222656
Validation loss: 2.5116880298942648

Epoch: 5| Step: 7
Training loss: 2.637012004852295
Validation loss: 2.509498198827108

Epoch: 5| Step: 8
Training loss: 2.9394097328186035
Validation loss: 2.5041679720724783

Epoch: 5| Step: 9
Training loss: 2.140679121017456
Validation loss: 2.5048252087767406

Epoch: 5| Step: 10
Training loss: 2.949422836303711
Validation loss: 2.5167949558586202

Epoch: 67| Step: 0
Training loss: 2.545487880706787
Validation loss: 2.5354380094876854

Epoch: 5| Step: 1
Training loss: 2.163672924041748
Validation loss: 2.555856022783505

Epoch: 5| Step: 2
Training loss: 2.7654426097869873
Validation loss: 2.5725665297559512

Epoch: 5| Step: 3
Training loss: 2.389045476913452
Validation loss: 2.5802952653618267

Epoch: 5| Step: 4
Training loss: 2.5584349632263184
Validation loss: 2.5457926745055826

Epoch: 5| Step: 5
Training loss: 3.4766407012939453
Validation loss: 2.515180182713334

Epoch: 5| Step: 6
Training loss: 3.2525463104248047
Validation loss: 2.5006976973625923

Epoch: 5| Step: 7
Training loss: 2.880833864212036
Validation loss: 2.5029246909644014

Epoch: 5| Step: 8
Training loss: 1.9685938358306885
Validation loss: 2.5108035995114233

Epoch: 5| Step: 9
Training loss: 2.7370269298553467
Validation loss: 2.5276456725212837

Epoch: 5| Step: 10
Training loss: 3.274243116378784
Validation loss: 2.5249197124153056

Epoch: 68| Step: 0
Training loss: 2.614408493041992
Validation loss: 2.5279464285860778

Epoch: 5| Step: 1
Training loss: 3.457350969314575
Validation loss: 2.5222683414336173

Epoch: 5| Step: 2
Training loss: 2.2959463596343994
Validation loss: 2.51849341136153

Epoch: 5| Step: 3
Training loss: 2.1820778846740723
Validation loss: 2.5097067048472743

Epoch: 5| Step: 4
Training loss: 3.548081159591675
Validation loss: 2.509625591257567

Epoch: 5| Step: 5
Training loss: 2.390768527984619
Validation loss: 2.5060533067231536

Epoch: 5| Step: 6
Training loss: 2.4701426029205322
Validation loss: 2.4969965386134323

Epoch: 5| Step: 7
Training loss: 2.686617612838745
Validation loss: 2.4987578289483183

Epoch: 5| Step: 8
Training loss: 2.969910144805908
Validation loss: 2.4959767198049896

Epoch: 5| Step: 9
Training loss: 2.601086378097534
Validation loss: 2.498956039387693

Epoch: 5| Step: 10
Training loss: 2.4784951210021973
Validation loss: 2.5051061107266333

Epoch: 69| Step: 0
Training loss: 2.8646881580352783
Validation loss: 2.5153882836782806

Epoch: 5| Step: 1
Training loss: 3.2346510887145996
Validation loss: 2.5132362868196223

Epoch: 5| Step: 2
Training loss: 3.23065185546875
Validation loss: 2.5068279645776235

Epoch: 5| Step: 3
Training loss: 2.397902011871338
Validation loss: 2.507348373372068

Epoch: 5| Step: 4
Training loss: 2.630439519882202
Validation loss: 2.508958929328508

Epoch: 5| Step: 5
Training loss: 2.890014171600342
Validation loss: 2.5017954611009166

Epoch: 5| Step: 6
Training loss: 3.2693092823028564
Validation loss: 2.4979937358569075

Epoch: 5| Step: 7
Training loss: 1.9256683588027954
Validation loss: 2.5056961556916595

Epoch: 5| Step: 8
Training loss: 2.1003875732421875
Validation loss: 2.4983230483147407

Epoch: 5| Step: 9
Training loss: 2.560021162033081
Validation loss: 2.495051381408527

Epoch: 5| Step: 10
Training loss: 2.5090253353118896
Validation loss: 2.489812889406758

Epoch: 70| Step: 0
Training loss: 2.699733257293701
Validation loss: 2.493096500314692

Epoch: 5| Step: 1
Training loss: 2.7915587425231934
Validation loss: 2.4929853408567366

Epoch: 5| Step: 2
Training loss: 3.015367031097412
Validation loss: 2.5004725661329044

Epoch: 5| Step: 3
Training loss: 2.2582736015319824
Validation loss: 2.493124290179181

Epoch: 5| Step: 4
Training loss: 1.7801799774169922
Validation loss: 2.4933259230788036

Epoch: 5| Step: 5
Training loss: 2.932116746902466
Validation loss: 2.49228697951122

Epoch: 5| Step: 6
Training loss: 3.308323621749878
Validation loss: 2.487599831755443

Epoch: 5| Step: 7
Training loss: 2.823996067047119
Validation loss: 2.479563731019215

Epoch: 5| Step: 8
Training loss: 2.4532525539398193
Validation loss: 2.477904232599402

Epoch: 5| Step: 9
Training loss: 2.9288365840911865
Validation loss: 2.484152634938558

Epoch: 5| Step: 10
Training loss: 2.524296283721924
Validation loss: 2.4871258197292203

Epoch: 71| Step: 0
Training loss: 2.4430668354034424
Validation loss: 2.493981231925308

Epoch: 5| Step: 1
Training loss: 2.7439942359924316
Validation loss: 2.5034936371669976

Epoch: 5| Step: 2
Training loss: 3.0867788791656494
Validation loss: 2.4910963453272337

Epoch: 5| Step: 3
Training loss: 2.2868640422821045
Validation loss: 2.4744591328405563

Epoch: 5| Step: 4
Training loss: 2.4788405895233154
Validation loss: 2.472157939787834

Epoch: 5| Step: 5
Training loss: 2.47762393951416
Validation loss: 2.473074548987932

Epoch: 5| Step: 6
Training loss: 3.4057421684265137
Validation loss: 2.4726782306548087

Epoch: 5| Step: 7
Training loss: 2.509342670440674
Validation loss: 2.4766159826709377

Epoch: 5| Step: 8
Training loss: 3.046854019165039
Validation loss: 2.4751694228059504

Epoch: 5| Step: 9
Training loss: 2.612305164337158
Validation loss: 2.4760711757085656

Epoch: 5| Step: 10
Training loss: 2.398293972015381
Validation loss: 2.476917087390859

Epoch: 72| Step: 0
Training loss: 2.732912302017212
Validation loss: 2.4685832377403014

Epoch: 5| Step: 1
Training loss: 3.189892292022705
Validation loss: 2.471165826243739

Epoch: 5| Step: 2
Training loss: 3.509368419647217
Validation loss: 2.468968975928522

Epoch: 5| Step: 3
Training loss: 2.674363613128662
Validation loss: 2.479853986411966

Epoch: 5| Step: 4
Training loss: 2.1500353813171387
Validation loss: 2.507110041956748

Epoch: 5| Step: 5
Training loss: 2.1871159076690674
Validation loss: 2.5042493830444994

Epoch: 5| Step: 6
Training loss: 1.7877833843231201
Validation loss: 2.4922902481530302

Epoch: 5| Step: 7
Training loss: 2.2698702812194824
Validation loss: 2.4834507819144958

Epoch: 5| Step: 8
Training loss: 2.81451153755188
Validation loss: 2.473139061722704

Epoch: 5| Step: 9
Training loss: 2.9144515991210938
Validation loss: 2.468359428067361

Epoch: 5| Step: 10
Training loss: 3.249094247817993
Validation loss: 2.4695385220230266

Epoch: 73| Step: 0
Training loss: 2.690504550933838
Validation loss: 2.477063840435397

Epoch: 5| Step: 1
Training loss: 2.1980178356170654
Validation loss: 2.4799605672077467

Epoch: 5| Step: 2
Training loss: 2.790566921234131
Validation loss: 2.485556069240775

Epoch: 5| Step: 3
Training loss: 2.3578758239746094
Validation loss: 2.4860927289532078

Epoch: 5| Step: 4
Training loss: 2.879586696624756
Validation loss: 2.4860035962955926

Epoch: 5| Step: 5
Training loss: 2.8870654106140137
Validation loss: 2.4820596479600474

Epoch: 5| Step: 6
Training loss: 2.8992531299591064
Validation loss: 2.4848401392659833

Epoch: 5| Step: 7
Training loss: 2.564764976501465
Validation loss: 2.482216799131004

Epoch: 5| Step: 8
Training loss: 2.8994202613830566
Validation loss: 2.479644880499891

Epoch: 5| Step: 9
Training loss: 2.6996264457702637
Validation loss: 2.475130945123652

Epoch: 5| Step: 10
Training loss: 2.829824686050415
Validation loss: 2.469536171164564

Epoch: 74| Step: 0
Training loss: 2.4712462425231934
Validation loss: 2.466351689830903

Epoch: 5| Step: 1
Training loss: 2.5598626136779785
Validation loss: 2.459583008161155

Epoch: 5| Step: 2
Training loss: 2.845733165740967
Validation loss: 2.4604945349436935

Epoch: 5| Step: 3
Training loss: 2.5933964252471924
Validation loss: 2.4656689731023644

Epoch: 5| Step: 4
Training loss: 1.900286078453064
Validation loss: 2.4791108921010006

Epoch: 5| Step: 5
Training loss: 2.0606346130371094
Validation loss: 2.4817891044001423

Epoch: 5| Step: 6
Training loss: 3.2461295127868652
Validation loss: 2.480047240052172

Epoch: 5| Step: 7
Training loss: 2.334817409515381
Validation loss: 2.470852757012972

Epoch: 5| Step: 8
Training loss: 3.002652168273926
Validation loss: 2.460328863513085

Epoch: 5| Step: 9
Training loss: 3.599735736846924
Validation loss: 2.460893231053506

Epoch: 5| Step: 10
Training loss: 2.711507797241211
Validation loss: 2.456325525878578

Epoch: 75| Step: 0
Training loss: 2.7209737300872803
Validation loss: 2.4547989035165436

Epoch: 5| Step: 1
Training loss: 3.013491153717041
Validation loss: 2.450454237640545

Epoch: 5| Step: 2
Training loss: 2.5461044311523438
Validation loss: 2.4498916825940533

Epoch: 5| Step: 3
Training loss: 2.4181127548217773
Validation loss: 2.454831228461317

Epoch: 5| Step: 4
Training loss: 2.57159686088562
Validation loss: 2.4580902104736655

Epoch: 5| Step: 5
Training loss: 2.6498470306396484
Validation loss: 2.461465722771101

Epoch: 5| Step: 6
Training loss: 2.5275230407714844
Validation loss: 2.4617746260858353

Epoch: 5| Step: 7
Training loss: 2.7909111976623535
Validation loss: 2.4592014615253737

Epoch: 5| Step: 8
Training loss: 2.9707438945770264
Validation loss: 2.4528899654265373

Epoch: 5| Step: 9
Training loss: 2.608506917953491
Validation loss: 2.460542958269837

Epoch: 5| Step: 10
Training loss: 2.4186625480651855
Validation loss: 2.452043984525947

Epoch: 76| Step: 0
Training loss: 2.7780964374542236
Validation loss: 2.448462660594653

Epoch: 5| Step: 1
Training loss: 3.2596499919891357
Validation loss: 2.4449673288611957

Epoch: 5| Step: 2
Training loss: 2.537463426589966
Validation loss: 2.4468274757426274

Epoch: 5| Step: 3
Training loss: 2.6241424083709717
Validation loss: 2.446551876683389

Epoch: 5| Step: 4
Training loss: 2.26936674118042
Validation loss: 2.4441811371875066

Epoch: 5| Step: 5
Training loss: 2.7270960807800293
Validation loss: 2.441734654929048

Epoch: 5| Step: 6
Training loss: 2.1281986236572266
Validation loss: 2.448063596602409

Epoch: 5| Step: 7
Training loss: 2.8698630332946777
Validation loss: 2.44813185609797

Epoch: 5| Step: 8
Training loss: 2.85221529006958
Validation loss: 2.451241003569736

Epoch: 5| Step: 9
Training loss: 2.647047519683838
Validation loss: 2.446300579655555

Epoch: 5| Step: 10
Training loss: 2.5389368534088135
Validation loss: 2.452068628803376

Epoch: 77| Step: 0
Training loss: 2.255084276199341
Validation loss: 2.4568974100133425

Epoch: 5| Step: 1
Training loss: 3.3968491554260254
Validation loss: 2.4535185726740028

Epoch: 5| Step: 2
Training loss: 3.007187604904175
Validation loss: 2.440271044290194

Epoch: 5| Step: 3
Training loss: 2.6334190368652344
Validation loss: 2.442400191419868

Epoch: 5| Step: 4
Training loss: 2.934983253479004
Validation loss: 2.4372356143049014

Epoch: 5| Step: 5
Training loss: 1.3917559385299683
Validation loss: 2.439837107094385

Epoch: 5| Step: 6
Training loss: 2.563218832015991
Validation loss: 2.4363340921299432

Epoch: 5| Step: 7
Training loss: 2.8051018714904785
Validation loss: 2.4369943167573664

Epoch: 5| Step: 8
Training loss: 2.316122531890869
Validation loss: 2.434241392279184

Epoch: 5| Step: 9
Training loss: 2.988469123840332
Validation loss: 2.4368783222731722

Epoch: 5| Step: 10
Training loss: 3.008798360824585
Validation loss: 2.443873384947418

Epoch: 78| Step: 0
Training loss: 2.3787734508514404
Validation loss: 2.43877233997468

Epoch: 5| Step: 1
Training loss: 2.976057529449463
Validation loss: 2.442203921656455

Epoch: 5| Step: 2
Training loss: 2.625258684158325
Validation loss: 2.4350224899989303

Epoch: 5| Step: 3
Training loss: 2.7335829734802246
Validation loss: 2.43821959341726

Epoch: 5| Step: 4
Training loss: 2.7257080078125
Validation loss: 2.4421476497445056

Epoch: 5| Step: 5
Training loss: 2.361107349395752
Validation loss: 2.442399791491929

Epoch: 5| Step: 6
Training loss: 2.9896762371063232
Validation loss: 2.44082574946906

Epoch: 5| Step: 7
Training loss: 3.273894786834717
Validation loss: 2.433972958595522

Epoch: 5| Step: 8
Training loss: 2.3830089569091797
Validation loss: 2.4377979847692672

Epoch: 5| Step: 9
Training loss: 2.203381061553955
Validation loss: 2.4321992012762252

Epoch: 5| Step: 10
Training loss: 2.5887088775634766
Validation loss: 2.4371535393499557

Epoch: 79| Step: 0
Training loss: 2.284463405609131
Validation loss: 2.4322722650343374

Epoch: 5| Step: 1
Training loss: 3.2732677459716797
Validation loss: 2.428733964120188

Epoch: 5| Step: 2
Training loss: 2.901340961456299
Validation loss: 2.4286300572015906

Epoch: 5| Step: 3
Training loss: 2.736482620239258
Validation loss: 2.437047363609396

Epoch: 5| Step: 4
Training loss: 2.411367893218994
Validation loss: 2.4430262683540263

Epoch: 5| Step: 5
Training loss: 2.367649793624878
Validation loss: 2.441119101739699

Epoch: 5| Step: 6
Training loss: 2.7850942611694336
Validation loss: 2.443302390395954

Epoch: 5| Step: 7
Training loss: 1.7838380336761475
Validation loss: 2.4309249026800996

Epoch: 5| Step: 8
Training loss: 2.8676326274871826
Validation loss: 2.425297521775769

Epoch: 5| Step: 9
Training loss: 2.6786861419677734
Validation loss: 2.430202127784811

Epoch: 5| Step: 10
Training loss: 3.094566583633423
Validation loss: 2.4304601197601645

Epoch: 80| Step: 0
Training loss: 2.2835116386413574
Validation loss: 2.435687777816608

Epoch: 5| Step: 1
Training loss: 2.560236692428589
Validation loss: 2.442296217846614

Epoch: 5| Step: 2
Training loss: 3.2315382957458496
Validation loss: 2.4405173306824057

Epoch: 5| Step: 3
Training loss: 2.2680504322052
Validation loss: 2.4382192652712584

Epoch: 5| Step: 4
Training loss: 2.6026699542999268
Validation loss: 2.426418217279578

Epoch: 5| Step: 5
Training loss: 2.528292179107666
Validation loss: 2.427319211344565

Epoch: 5| Step: 6
Training loss: 2.866865634918213
Validation loss: 2.428739168310678

Epoch: 5| Step: 7
Training loss: 2.379694700241089
Validation loss: 2.429525908603463

Epoch: 5| Step: 8
Training loss: 2.989144802093506
Validation loss: 2.4346961616187968

Epoch: 5| Step: 9
Training loss: 2.7535135746002197
Validation loss: 2.4314843018849692

Epoch: 5| Step: 10
Training loss: 2.6290698051452637
Validation loss: 2.4324796891981557

Epoch: 81| Step: 0
Training loss: 3.1532492637634277
Validation loss: 2.4295474880485126

Epoch: 5| Step: 1
Training loss: 2.3339366912841797
Validation loss: 2.436876389288133

Epoch: 5| Step: 2
Training loss: 2.5798444747924805
Validation loss: 2.4338967261775846

Epoch: 5| Step: 3
Training loss: 3.2220864295959473
Validation loss: 2.427245278512278

Epoch: 5| Step: 4
Training loss: 2.0348334312438965
Validation loss: 2.4202448629563853

Epoch: 5| Step: 5
Training loss: 2.6815991401672363
Validation loss: 2.41679048538208

Epoch: 5| Step: 6
Training loss: 2.8517489433288574
Validation loss: 2.419704432128578

Epoch: 5| Step: 7
Training loss: 2.206172466278076
Validation loss: 2.423344868485646

Epoch: 5| Step: 8
Training loss: 2.5370407104492188
Validation loss: 2.4256018566828903

Epoch: 5| Step: 9
Training loss: 2.86690354347229
Validation loss: 2.4202267098170456

Epoch: 5| Step: 10
Training loss: 2.5615081787109375
Validation loss: 2.4216164312055035

Epoch: 82| Step: 0
Training loss: 1.9068580865859985
Validation loss: 2.4228584099841375

Epoch: 5| Step: 1
Training loss: 3.48753023147583
Validation loss: 2.423854310025451

Epoch: 5| Step: 2
Training loss: 2.9159321784973145
Validation loss: 2.420196707530688

Epoch: 5| Step: 3
Training loss: 2.348935604095459
Validation loss: 2.4200358185716855

Epoch: 5| Step: 4
Training loss: 3.375141143798828
Validation loss: 2.4237024937906573

Epoch: 5| Step: 5
Training loss: 2.9119114875793457
Validation loss: 2.4262587434502056

Epoch: 5| Step: 6
Training loss: 1.9199683666229248
Validation loss: 2.424946949046145

Epoch: 5| Step: 7
Training loss: 2.244576930999756
Validation loss: 2.412646162894464

Epoch: 5| Step: 8
Training loss: 2.281975269317627
Validation loss: 2.4127294709605556

Epoch: 5| Step: 9
Training loss: 2.8141963481903076
Validation loss: 2.4358546016036824

Epoch: 5| Step: 10
Training loss: 2.9104325771331787
Validation loss: 2.4698791196269374

Epoch: 83| Step: 0
Training loss: 2.451066017150879
Validation loss: 2.506347810068438

Epoch: 5| Step: 1
Training loss: 2.4115333557128906
Validation loss: 2.4829435015237458

Epoch: 5| Step: 2
Training loss: 2.6138577461242676
Validation loss: 2.4671121489617134

Epoch: 5| Step: 3
Training loss: 2.3965258598327637
Validation loss: 2.4233022633419243

Epoch: 5| Step: 4
Training loss: 2.502394914627075
Validation loss: 2.408253595393191

Epoch: 5| Step: 5
Training loss: 3.0719118118286133
Validation loss: 2.409199663387832

Epoch: 5| Step: 6
Training loss: 3.0811245441436768
Validation loss: 2.4065100492969638

Epoch: 5| Step: 7
Training loss: 2.73211407661438
Validation loss: 2.4127115972580446

Epoch: 5| Step: 8
Training loss: 2.5089104175567627
Validation loss: 2.4198618627363637

Epoch: 5| Step: 9
Training loss: 2.926180124282837
Validation loss: 2.4254094708350395

Epoch: 5| Step: 10
Training loss: 2.4344420433044434
Validation loss: 2.429833665970833

Epoch: 84| Step: 0
Training loss: 2.5685229301452637
Validation loss: 2.420971547403643

Epoch: 5| Step: 1
Training loss: 2.0311367511749268
Validation loss: 2.41635565347569

Epoch: 5| Step: 2
Training loss: 2.8900697231292725
Validation loss: 2.425069437232069

Epoch: 5| Step: 3
Training loss: 2.5927977561950684
Validation loss: 2.4156197219766598

Epoch: 5| Step: 4
Training loss: 3.016014337539673
Validation loss: 2.4223487479712373

Epoch: 5| Step: 5
Training loss: 2.2378196716308594
Validation loss: 2.4216972627947406

Epoch: 5| Step: 6
Training loss: 2.647947311401367
Validation loss: 2.4182658349314043

Epoch: 5| Step: 7
Training loss: 2.5616047382354736
Validation loss: 2.4281413247508388

Epoch: 5| Step: 8
Training loss: 2.570425510406494
Validation loss: 2.444953264728669

Epoch: 5| Step: 9
Training loss: 2.6828389167785645
Validation loss: 2.4599990998545

Epoch: 5| Step: 10
Training loss: 3.3383290767669678
Validation loss: 2.4705177660911315

Epoch: 85| Step: 0
Training loss: 3.1725940704345703
Validation loss: 2.4872437036165627

Epoch: 5| Step: 1
Training loss: 2.7165513038635254
Validation loss: 2.4726473900579635

Epoch: 5| Step: 2
Training loss: 2.695923328399658
Validation loss: 2.4545351818043697

Epoch: 5| Step: 3
Training loss: 2.8607068061828613
Validation loss: 2.4346354648631108

Epoch: 5| Step: 4
Training loss: 2.3334877490997314
Validation loss: 2.427349505885955

Epoch: 5| Step: 5
Training loss: 3.6383557319641113
Validation loss: 2.4198281547074676

Epoch: 5| Step: 6
Training loss: 2.2597806453704834
Validation loss: 2.414707750402471

Epoch: 5| Step: 7
Training loss: 2.4813971519470215
Validation loss: 2.416079987761795

Epoch: 5| Step: 8
Training loss: 2.4252636432647705
Validation loss: 2.40757933996057

Epoch: 5| Step: 9
Training loss: 1.9491697549819946
Validation loss: 2.407223629695113

Epoch: 5| Step: 10
Training loss: 2.5615041255950928
Validation loss: 2.407096749992781

Epoch: 86| Step: 0
Training loss: 3.466153383255005
Validation loss: 2.4003833673333608

Epoch: 5| Step: 1
Training loss: 3.2250359058380127
Validation loss: 2.4114360424780075

Epoch: 5| Step: 2
Training loss: 2.5206921100616455
Validation loss: 2.4050392309824624

Epoch: 5| Step: 3
Training loss: 2.1032073497772217
Validation loss: 2.413442891131165

Epoch: 5| Step: 4
Training loss: 2.753688335418701
Validation loss: 2.4128060135790097

Epoch: 5| Step: 5
Training loss: 2.013120174407959
Validation loss: 2.407241598252327

Epoch: 5| Step: 6
Training loss: 2.6341300010681152
Validation loss: 2.408652987531436

Epoch: 5| Step: 7
Training loss: 2.459786891937256
Validation loss: 2.3912755443203833

Epoch: 5| Step: 8
Training loss: 2.6398987770080566
Validation loss: 2.3994716187959075

Epoch: 5| Step: 9
Training loss: 2.583460569381714
Validation loss: 2.3958953734367125

Epoch: 5| Step: 10
Training loss: 2.5373973846435547
Validation loss: 2.398787675365325

Epoch: 87| Step: 0
Training loss: 2.6412205696105957
Validation loss: 2.3964980212591027

Epoch: 5| Step: 1
Training loss: 3.1134884357452393
Validation loss: 2.3949202670845935

Epoch: 5| Step: 2
Training loss: 1.961200475692749
Validation loss: 2.397566359530213

Epoch: 5| Step: 3
Training loss: 2.5174083709716797
Validation loss: 2.39557469788418

Epoch: 5| Step: 4
Training loss: 2.7468037605285645
Validation loss: 2.3970738534004457

Epoch: 5| Step: 5
Training loss: 2.8570709228515625
Validation loss: 2.3949507641535934

Epoch: 5| Step: 6
Training loss: 2.121176242828369
Validation loss: 2.3969635066165718

Epoch: 5| Step: 7
Training loss: 3.158045768737793
Validation loss: 2.396455905770743

Epoch: 5| Step: 8
Training loss: 2.749746561050415
Validation loss: 2.399443572567355

Epoch: 5| Step: 9
Training loss: 2.389425277709961
Validation loss: 2.395109949573394

Epoch: 5| Step: 10
Training loss: 2.7741832733154297
Validation loss: 2.400739756963586

Epoch: 88| Step: 0
Training loss: 3.138561248779297
Validation loss: 2.401821195438344

Epoch: 5| Step: 1
Training loss: 2.5424282550811768
Validation loss: 2.3899973079722416

Epoch: 5| Step: 2
Training loss: 2.7728466987609863
Validation loss: 2.3941591067980696

Epoch: 5| Step: 3
Training loss: 3.334001064300537
Validation loss: 2.39076752303749

Epoch: 5| Step: 4
Training loss: 2.4147191047668457
Validation loss: 2.3929421773520847

Epoch: 5| Step: 5
Training loss: 2.187263011932373
Validation loss: 2.3982282966695805

Epoch: 5| Step: 6
Training loss: 2.8159050941467285
Validation loss: 2.4180786378922

Epoch: 5| Step: 7
Training loss: 2.2685611248016357
Validation loss: 2.4594557926219

Epoch: 5| Step: 8
Training loss: 2.101775884628296
Validation loss: 2.499319317520306

Epoch: 5| Step: 9
Training loss: 2.612760066986084
Validation loss: 2.5005088365206154

Epoch: 5| Step: 10
Training loss: 2.9117958545684814
Validation loss: 2.453335928660567

Epoch: 89| Step: 0
Training loss: 2.5699939727783203
Validation loss: 2.4358450622968775

Epoch: 5| Step: 1
Training loss: 3.03105092048645
Validation loss: 2.4171555657540598

Epoch: 5| Step: 2
Training loss: 2.145224094390869
Validation loss: 2.401807454324538

Epoch: 5| Step: 3
Training loss: 2.7283267974853516
Validation loss: 2.394634021225796

Epoch: 5| Step: 4
Training loss: 2.8021669387817383
Validation loss: 2.385106143131051

Epoch: 5| Step: 5
Training loss: 2.8503174781799316
Validation loss: 2.381952431894118

Epoch: 5| Step: 6
Training loss: 2.3285114765167236
Validation loss: 2.3727336647689983

Epoch: 5| Step: 7
Training loss: 3.180281400680542
Validation loss: 2.3784122979769142

Epoch: 5| Step: 8
Training loss: 3.186363935470581
Validation loss: 2.379590674113202

Epoch: 5| Step: 9
Training loss: 2.1900229454040527
Validation loss: 2.37788878205002

Epoch: 5| Step: 10
Training loss: 1.8334531784057617
Validation loss: 2.37651297097565

Epoch: 90| Step: 0
Training loss: 3.6069703102111816
Validation loss: 2.377746981959189

Epoch: 5| Step: 1
Training loss: 2.8023860454559326
Validation loss: 2.379108093118155

Epoch: 5| Step: 2
Training loss: 2.3731849193573
Validation loss: 2.3780848031402915

Epoch: 5| Step: 3
Training loss: 2.690486431121826
Validation loss: 2.387289818897042

Epoch: 5| Step: 4
Training loss: 2.2140839099884033
Validation loss: 2.3977703381610174

Epoch: 5| Step: 5
Training loss: 1.9760777950286865
Validation loss: 2.385636270687144

Epoch: 5| Step: 6
Training loss: 2.6720495223999023
Validation loss: 2.3860769989669963

Epoch: 5| Step: 7
Training loss: 2.3063244819641113
Validation loss: 2.3822862230321413

Epoch: 5| Step: 8
Training loss: 2.300513744354248
Validation loss: 2.3908138480237735

Epoch: 5| Step: 9
Training loss: 2.8224587440490723
Validation loss: 2.3919328630611463

Epoch: 5| Step: 10
Training loss: 3.14544939994812
Validation loss: 2.3882338923792683

Epoch: 91| Step: 0
Training loss: 2.4995083808898926
Validation loss: 2.3870605191876813

Epoch: 5| Step: 1
Training loss: 2.6834142208099365
Validation loss: 2.3786794741948447

Epoch: 5| Step: 2
Training loss: 2.904998779296875
Validation loss: 2.372976331300633

Epoch: 5| Step: 3
Training loss: 2.5093276500701904
Validation loss: 2.3711102906093804

Epoch: 5| Step: 4
Training loss: 2.380678415298462
Validation loss: 2.3707756175789783

Epoch: 5| Step: 5
Training loss: 1.8350023031234741
Validation loss: 2.3710219449894403

Epoch: 5| Step: 6
Training loss: 2.365541934967041
Validation loss: 2.370308901674004

Epoch: 5| Step: 7
Training loss: 2.72245454788208
Validation loss: 2.3778025360517603

Epoch: 5| Step: 8
Training loss: 2.8267650604248047
Validation loss: 2.3748854232090775

Epoch: 5| Step: 9
Training loss: 3.1355037689208984
Validation loss: 2.380094053924725

Epoch: 5| Step: 10
Training loss: 2.979853391647339
Validation loss: 2.3737595158238567

Epoch: 92| Step: 0
Training loss: 2.367000102996826
Validation loss: 2.376018190896639

Epoch: 5| Step: 1
Training loss: 2.2418274879455566
Validation loss: 2.3751355012257895

Epoch: 5| Step: 2
Training loss: 2.3177077770233154
Validation loss: 2.387608012845439

Epoch: 5| Step: 3
Training loss: 2.6115477085113525
Validation loss: 2.388744600357548

Epoch: 5| Step: 4
Training loss: 2.746812582015991
Validation loss: 2.3940524952386015

Epoch: 5| Step: 5
Training loss: 2.631399631500244
Validation loss: 2.38889540139065

Epoch: 5| Step: 6
Training loss: 2.6064610481262207
Validation loss: 2.378430733116724

Epoch: 5| Step: 7
Training loss: 2.2201695442199707
Validation loss: 2.372377722494064

Epoch: 5| Step: 8
Training loss: 3.67730975151062
Validation loss: 2.3664697267675914

Epoch: 5| Step: 9
Training loss: 2.2466864585876465
Validation loss: 2.3644221572465796

Epoch: 5| Step: 10
Training loss: 3.1210858821868896
Validation loss: 2.3649671385365147

Epoch: 93| Step: 0
Training loss: 2.550844430923462
Validation loss: 2.364778933986541

Epoch: 5| Step: 1
Training loss: 2.0590991973876953
Validation loss: 2.3622627104482343

Epoch: 5| Step: 2
Training loss: 3.2415709495544434
Validation loss: 2.3626460054869294

Epoch: 5| Step: 3
Training loss: 1.8336646556854248
Validation loss: 2.3596937079583444

Epoch: 5| Step: 4
Training loss: 2.111464262008667
Validation loss: 2.3607011584825415

Epoch: 5| Step: 5
Training loss: 2.992238759994507
Validation loss: 2.3656823096736783

Epoch: 5| Step: 6
Training loss: 2.618037462234497
Validation loss: 2.3635845312508206

Epoch: 5| Step: 7
Training loss: 2.46093487739563
Validation loss: 2.372532731743269

Epoch: 5| Step: 8
Training loss: 2.7617783546447754
Validation loss: 2.38127653573149

Epoch: 5| Step: 9
Training loss: 2.9975101947784424
Validation loss: 2.3694313110843783

Epoch: 5| Step: 10
Training loss: 3.0503957271575928
Validation loss: 2.357049003724129

Epoch: 94| Step: 0
Training loss: 2.3881828784942627
Validation loss: 2.3623005984931864

Epoch: 5| Step: 1
Training loss: 3.02247953414917
Validation loss: 2.3594254832113943

Epoch: 5| Step: 2
Training loss: 3.1778900623321533
Validation loss: 2.3601933615182036

Epoch: 5| Step: 3
Training loss: 2.5916354656219482
Validation loss: 2.3584524354627057

Epoch: 5| Step: 4
Training loss: 1.8747600317001343
Validation loss: 2.356417143216697

Epoch: 5| Step: 5
Training loss: 2.3054001331329346
Validation loss: 2.3544147834982923

Epoch: 5| Step: 6
Training loss: 3.0287907123565674
Validation loss: 2.35140065480304

Epoch: 5| Step: 7
Training loss: 2.618170738220215
Validation loss: 2.3514241454421834

Epoch: 5| Step: 8
Training loss: 2.561016082763672
Validation loss: 2.3558307386213735

Epoch: 5| Step: 9
Training loss: 2.6534924507141113
Validation loss: 2.3611195343796925

Epoch: 5| Step: 10
Training loss: 2.325573682785034
Validation loss: 2.3604994973828717

Epoch: 95| Step: 0
Training loss: 2.327202320098877
Validation loss: 2.3705409188424387

Epoch: 5| Step: 1
Training loss: 2.880474328994751
Validation loss: 2.367842556327902

Epoch: 5| Step: 2
Training loss: 2.7492785453796387
Validation loss: 2.347458775325488

Epoch: 5| Step: 3
Training loss: 1.9157466888427734
Validation loss: 2.352310408828079

Epoch: 5| Step: 4
Training loss: 2.714846134185791
Validation loss: 2.3579009848256267

Epoch: 5| Step: 5
Training loss: 2.45489501953125
Validation loss: 2.3612347751535396

Epoch: 5| Step: 6
Training loss: 2.7456982135772705
Validation loss: 2.373872995376587

Epoch: 5| Step: 7
Training loss: 2.987286329269409
Validation loss: 2.374676558279222

Epoch: 5| Step: 8
Training loss: 3.000290632247925
Validation loss: 2.359902940770631

Epoch: 5| Step: 9
Training loss: 2.7113773822784424
Validation loss: 2.352288653773646

Epoch: 5| Step: 10
Training loss: 2.136615514755249
Validation loss: 2.344645869347357

Epoch: 96| Step: 0
Training loss: 2.477288007736206
Validation loss: 2.3419260876153105

Epoch: 5| Step: 1
Training loss: 2.1242928504943848
Validation loss: 2.348936116823586

Epoch: 5| Step: 2
Training loss: 2.3857386112213135
Validation loss: 2.3619340222368956

Epoch: 5| Step: 3
Training loss: 3.008606433868408
Validation loss: 2.3728295141650784

Epoch: 5| Step: 4
Training loss: 2.429795980453491
Validation loss: 2.370054078358476

Epoch: 5| Step: 5
Training loss: 2.781599521636963
Validation loss: 2.3742179127149683

Epoch: 5| Step: 6
Training loss: 2.4154162406921387
Validation loss: 2.355825185775757

Epoch: 5| Step: 7
Training loss: 2.2931108474731445
Validation loss: 2.3510195747498543

Epoch: 5| Step: 8
Training loss: 3.244518995285034
Validation loss: 2.3424207625850553

Epoch: 5| Step: 9
Training loss: 2.689607620239258
Validation loss: 2.336447810613981

Epoch: 5| Step: 10
Training loss: 2.718743085861206
Validation loss: 2.346621051911385

Epoch: 97| Step: 0
Training loss: 2.5966832637786865
Validation loss: 2.35797712110704

Epoch: 5| Step: 1
Training loss: 2.631614923477173
Validation loss: 2.3698055513443483

Epoch: 5| Step: 2
Training loss: 3.067018985748291
Validation loss: 2.3823273002460437

Epoch: 5| Step: 3
Training loss: 2.627835988998413
Validation loss: 2.3738313951799945

Epoch: 5| Step: 4
Training loss: 3.1271026134490967
Validation loss: 2.3577676229579474

Epoch: 5| Step: 5
Training loss: 2.232659101486206
Validation loss: 2.3506139991103963

Epoch: 5| Step: 6
Training loss: 2.014620304107666
Validation loss: 2.342709010647189

Epoch: 5| Step: 7
Training loss: 2.574518918991089
Validation loss: 2.3396220412305606

Epoch: 5| Step: 8
Training loss: 3.021409273147583
Validation loss: 2.3595068147105556

Epoch: 5| Step: 9
Training loss: 2.3068251609802246
Validation loss: 2.361902416393321

Epoch: 5| Step: 10
Training loss: 2.586756467819214
Validation loss: 2.3821391751689296

Epoch: 98| Step: 0
Training loss: 1.7725458145141602
Validation loss: 2.404813761352211

Epoch: 5| Step: 1
Training loss: 2.463714122772217
Validation loss: 2.4254072353404057

Epoch: 5| Step: 2
Training loss: 3.0315442085266113
Validation loss: 2.4360313466800156

Epoch: 5| Step: 3
Training loss: 2.5180726051330566
Validation loss: 2.4051277176026375

Epoch: 5| Step: 4
Training loss: 2.765752077102661
Validation loss: 2.365550036071449

Epoch: 5| Step: 5
Training loss: 2.773756742477417
Validation loss: 2.3371286007665817

Epoch: 5| Step: 6
Training loss: 2.3869500160217285
Validation loss: 2.327967761665262

Epoch: 5| Step: 7
Training loss: 3.4097588062286377
Validation loss: 2.333394214671145

Epoch: 5| Step: 8
Training loss: 2.2577149868011475
Validation loss: 2.3545399570977814

Epoch: 5| Step: 9
Training loss: 1.9869369268417358
Validation loss: 2.3669917019464637

Epoch: 5| Step: 10
Training loss: 3.518627166748047
Validation loss: 2.3885583877563477

Epoch: 99| Step: 0
Training loss: 2.4653561115264893
Validation loss: 2.3812325808309738

Epoch: 5| Step: 1
Training loss: 2.294107437133789
Validation loss: 2.3780555238005934

Epoch: 5| Step: 2
Training loss: 3.255366563796997
Validation loss: 2.362660797693396

Epoch: 5| Step: 3
Training loss: 2.1427459716796875
Validation loss: 2.342389670751428

Epoch: 5| Step: 4
Training loss: 2.9357593059539795
Validation loss: 2.3226232759414183

Epoch: 5| Step: 5
Training loss: 2.697122097015381
Validation loss: 2.3263087349553264

Epoch: 5| Step: 6
Training loss: 2.5908024311065674
Validation loss: 2.33294012213266

Epoch: 5| Step: 7
Training loss: 2.0315515995025635
Validation loss: 2.3479011148534794

Epoch: 5| Step: 8
Training loss: 2.412126302719116
Validation loss: 2.3760066750229045

Epoch: 5| Step: 9
Training loss: 2.7332139015197754
Validation loss: 2.408444545602286

Epoch: 5| Step: 10
Training loss: 3.3763670921325684
Validation loss: 2.4024441985673803

Epoch: 100| Step: 0
Training loss: 2.7553744316101074
Validation loss: 2.392658423351985

Epoch: 5| Step: 1
Training loss: 2.956111431121826
Validation loss: 2.3808347127770864

Epoch: 5| Step: 2
Training loss: 2.3024301528930664
Validation loss: 2.37913869145096

Epoch: 5| Step: 3
Training loss: 1.918737769126892
Validation loss: 2.357787275827059

Epoch: 5| Step: 4
Training loss: 3.1397414207458496
Validation loss: 2.350466912792575

Epoch: 5| Step: 5
Training loss: 3.229081630706787
Validation loss: 2.341132140928699

Epoch: 5| Step: 6
Training loss: 2.8081583976745605
Validation loss: 2.3298117550470496

Epoch: 5| Step: 7
Training loss: 2.3903989791870117
Validation loss: 2.328473739726569

Epoch: 5| Step: 8
Training loss: 2.2299208641052246
Validation loss: 2.3479273396153606

Epoch: 5| Step: 9
Training loss: 2.9708847999572754
Validation loss: 2.3492767631366687

Epoch: 5| Step: 10
Training loss: 1.6540619134902954
Validation loss: 2.3377933899561563

Epoch: 101| Step: 0
Training loss: 2.3779640197753906
Validation loss: 2.3353864710818053

Epoch: 5| Step: 1
Training loss: 2.8836607933044434
Validation loss: 2.364161809285482

Epoch: 5| Step: 2
Training loss: 2.4569783210754395
Validation loss: 2.4174377892607

Epoch: 5| Step: 3
Training loss: 3.196028709411621
Validation loss: 2.4562521237199024

Epoch: 5| Step: 4
Training loss: 2.1200008392333984
Validation loss: 2.454137861087758

Epoch: 5| Step: 5
Training loss: 3.1614670753479004
Validation loss: 2.366895385967788

Epoch: 5| Step: 6
Training loss: 2.4722976684570312
Validation loss: 2.3359241280504452

Epoch: 5| Step: 7
Training loss: 2.616933822631836
Validation loss: 2.3240079520851054

Epoch: 5| Step: 8
Training loss: 2.268150806427002
Validation loss: 2.324350518565024

Epoch: 5| Step: 9
Training loss: 2.542513847351074
Validation loss: 2.3533643138024116

Epoch: 5| Step: 10
Training loss: 2.5595085620880127
Validation loss: 2.395814818720664

Epoch: 102| Step: 0
Training loss: 2.4316396713256836
Validation loss: 2.413718690154373

Epoch: 5| Step: 1
Training loss: 2.7121264934539795
Validation loss: 2.36486191134299

Epoch: 5| Step: 2
Training loss: 3.221301555633545
Validation loss: 2.337456818549864

Epoch: 5| Step: 3
Training loss: 2.4090328216552734
Validation loss: 2.329797908823977

Epoch: 5| Step: 4
Training loss: 2.3652825355529785
Validation loss: 2.321431072809363

Epoch: 5| Step: 5
Training loss: 2.2013943195343018
Validation loss: 2.324589406290362

Epoch: 5| Step: 6
Training loss: 2.5532636642456055
Validation loss: 2.3224477293670818

Epoch: 5| Step: 7
Training loss: 2.64296293258667
Validation loss: 2.3222838447939966

Epoch: 5| Step: 8
Training loss: 2.9388022422790527
Validation loss: 2.3292769770468436

Epoch: 5| Step: 9
Training loss: 2.1912550926208496
Validation loss: 2.32989437349381

Epoch: 5| Step: 10
Training loss: 2.8504629135131836
Validation loss: 2.3394121726353965

Epoch: 103| Step: 0
Training loss: 2.659986972808838
Validation loss: 2.3416675085662515

Epoch: 5| Step: 1
Training loss: 2.641352415084839
Validation loss: 2.3385824106072866

Epoch: 5| Step: 2
Training loss: 2.185098648071289
Validation loss: 2.330096496048794

Epoch: 5| Step: 3
Training loss: 2.896958827972412
Validation loss: 2.331173878844066

Epoch: 5| Step: 4
Training loss: 2.2558748722076416
Validation loss: 2.3369433764488465

Epoch: 5| Step: 5
Training loss: 2.783405303955078
Validation loss: 2.3314796314444592

Epoch: 5| Step: 6
Training loss: 2.8023746013641357
Validation loss: 2.3283076465770765

Epoch: 5| Step: 7
Training loss: 2.3657219409942627
Validation loss: 2.33115824063619

Epoch: 5| Step: 8
Training loss: 2.5891525745391846
Validation loss: 2.3317828255314983

Epoch: 5| Step: 9
Training loss: 2.3658862113952637
Validation loss: 2.3255180876742125

Epoch: 5| Step: 10
Training loss: 2.886026382446289
Validation loss: 2.319796772413356

Epoch: 104| Step: 0
Training loss: 1.785585641860962
Validation loss: 2.336040655771891

Epoch: 5| Step: 1
Training loss: 2.7489991188049316
Validation loss: 2.338938743837418

Epoch: 5| Step: 2
Training loss: 2.1921472549438477
Validation loss: 2.336596687634786

Epoch: 5| Step: 3
Training loss: 3.199368715286255
Validation loss: 2.3374511708495436

Epoch: 5| Step: 4
Training loss: 3.3012795448303223
Validation loss: 2.3291603031978814

Epoch: 5| Step: 5
Training loss: 2.8078255653381348
Validation loss: 2.3274635704614783

Epoch: 5| Step: 6
Training loss: 2.3574604988098145
Validation loss: 2.3318229336892404

Epoch: 5| Step: 7
Training loss: 2.9164438247680664
Validation loss: 2.3387783599156204

Epoch: 5| Step: 8
Training loss: 2.103621244430542
Validation loss: 2.35537382864183

Epoch: 5| Step: 9
Training loss: 2.191965103149414
Validation loss: 2.361094090246385

Epoch: 5| Step: 10
Training loss: 3.044130325317383
Validation loss: 2.356865980291879

Epoch: 105| Step: 0
Training loss: 2.2852141857147217
Validation loss: 2.3463295582802064

Epoch: 5| Step: 1
Training loss: 2.243196964263916
Validation loss: 2.3318771469977593

Epoch: 5| Step: 2
Training loss: 2.4704039096832275
Validation loss: 2.3149084660314743

Epoch: 5| Step: 3
Training loss: 2.851850748062134
Validation loss: 2.3140870730082193

Epoch: 5| Step: 4
Training loss: 2.8097290992736816
Validation loss: 2.32680768095037

Epoch: 5| Step: 5
Training loss: 2.864302396774292
Validation loss: 2.342782971679523

Epoch: 5| Step: 6
Training loss: 2.948246479034424
Validation loss: 2.3583957456773326

Epoch: 5| Step: 7
Training loss: 2.4575700759887695
Validation loss: 2.397897110190443

Epoch: 5| Step: 8
Training loss: 2.4971888065338135
Validation loss: 2.40721784868548

Epoch: 5| Step: 9
Training loss: 2.1314215660095215
Validation loss: 2.3805182210860716

Epoch: 5| Step: 10
Training loss: 2.9219810962677
Validation loss: 2.3439255837471253

Epoch: 106| Step: 0
Training loss: 2.841939926147461
Validation loss: 2.3245227900884484

Epoch: 5| Step: 1
Training loss: 2.8567652702331543
Validation loss: 2.3195081641597133

Epoch: 5| Step: 2
Training loss: 2.2792561054229736
Validation loss: 2.317524581827143

Epoch: 5| Step: 3
Training loss: 2.0395607948303223
Validation loss: 2.3442684091547483

Epoch: 5| Step: 4
Training loss: 2.885810136795044
Validation loss: 2.3522805706147225

Epoch: 5| Step: 5
Training loss: 3.3658130168914795
Validation loss: 2.3363011101240754

Epoch: 5| Step: 6
Training loss: 2.352177143096924
Validation loss: 2.317059942471084

Epoch: 5| Step: 7
Training loss: 2.159268856048584
Validation loss: 2.3100131916743454

Epoch: 5| Step: 8
Training loss: 2.376465320587158
Validation loss: 2.3052860254882486

Epoch: 5| Step: 9
Training loss: 2.7879867553710938
Validation loss: 2.309590229424097

Epoch: 5| Step: 10
Training loss: 2.4288840293884277
Validation loss: 2.3124034148390575

Epoch: 107| Step: 0
Training loss: 2.390378952026367
Validation loss: 2.3142717089704288

Epoch: 5| Step: 1
Training loss: 1.8733917474746704
Validation loss: 2.3075638996657504

Epoch: 5| Step: 2
Training loss: 2.786510467529297
Validation loss: 2.3038387349856797

Epoch: 5| Step: 3
Training loss: 2.083244800567627
Validation loss: 2.3043852954782467

Epoch: 5| Step: 4
Training loss: 2.4947941303253174
Validation loss: 2.309924133362309

Epoch: 5| Step: 5
Training loss: 3.3238205909729004
Validation loss: 2.316159276552098

Epoch: 5| Step: 6
Training loss: 2.695070266723633
Validation loss: 2.3098185985319075

Epoch: 5| Step: 7
Training loss: 2.7581896781921387
Validation loss: 2.3079031821220153

Epoch: 5| Step: 8
Training loss: 2.7119648456573486
Validation loss: 2.319383385360882

Epoch: 5| Step: 9
Training loss: 2.612086057662964
Validation loss: 2.327197123599309

Epoch: 5| Step: 10
Training loss: 2.3690555095672607
Validation loss: 2.32188085843158

Epoch: 108| Step: 0
Training loss: 2.4175612926483154
Validation loss: 2.3206504288540093

Epoch: 5| Step: 1
Training loss: 2.632511854171753
Validation loss: 2.3165518647880963

Epoch: 5| Step: 2
Training loss: 2.2044482231140137
Validation loss: 2.3215915849131923

Epoch: 5| Step: 3
Training loss: 2.5536229610443115
Validation loss: 2.3089371599176878

Epoch: 5| Step: 4
Training loss: 3.4161102771759033
Validation loss: 2.303479169004707

Epoch: 5| Step: 5
Training loss: 2.6890273094177246
Validation loss: 2.3098391666207263

Epoch: 5| Step: 6
Training loss: 3.329716920852661
Validation loss: 2.302376616385675

Epoch: 5| Step: 7
Training loss: 2.4111313819885254
Validation loss: 2.299926180993357

Epoch: 5| Step: 8
Training loss: 2.0520200729370117
Validation loss: 2.287586878704768

Epoch: 5| Step: 9
Training loss: 2.444030284881592
Validation loss: 2.2899790810000513

Epoch: 5| Step: 10
Training loss: 1.7764965295791626
Validation loss: 2.2861789247041107

Epoch: 109| Step: 0
Training loss: 1.6977307796478271
Validation loss: 2.2862859592642835

Epoch: 5| Step: 1
Training loss: 2.12544322013855
Validation loss: 2.2842896369195755

Epoch: 5| Step: 2
Training loss: 2.9654219150543213
Validation loss: 2.2978236341989167

Epoch: 5| Step: 3
Training loss: 3.069974660873413
Validation loss: 2.35208236786627

Epoch: 5| Step: 4
Training loss: 2.720595121383667
Validation loss: 2.377176438608477

Epoch: 5| Step: 5
Training loss: 2.8402187824249268
Validation loss: 2.365409561382827

Epoch: 5| Step: 6
Training loss: 2.9851555824279785
Validation loss: 2.3369448287512666

Epoch: 5| Step: 7
Training loss: 2.9024782180786133
Validation loss: 2.3039860981766895

Epoch: 5| Step: 8
Training loss: 2.0988075733184814
Validation loss: 2.298316394129107

Epoch: 5| Step: 9
Training loss: 2.8637290000915527
Validation loss: 2.302931503583026

Epoch: 5| Step: 10
Training loss: 2.033801555633545
Validation loss: 2.339848029998041

Epoch: 110| Step: 0
Training loss: 3.175037384033203
Validation loss: 2.3731106558153705

Epoch: 5| Step: 1
Training loss: 1.945894479751587
Validation loss: 2.366464379013226

Epoch: 5| Step: 2
Training loss: 2.7235312461853027
Validation loss: 2.356972707215176

Epoch: 5| Step: 3
Training loss: 2.6831862926483154
Validation loss: 2.307463365216409

Epoch: 5| Step: 4
Training loss: 2.881190299987793
Validation loss: 2.2964835051567323

Epoch: 5| Step: 5
Training loss: 1.613990068435669
Validation loss: 2.2999912923382175

Epoch: 5| Step: 6
Training loss: 3.104168176651001
Validation loss: 2.314895937519689

Epoch: 5| Step: 7
Training loss: 2.627917766571045
Validation loss: 2.331911745891776

Epoch: 5| Step: 8
Training loss: 2.1165692806243896
Validation loss: 2.3438662354664137

Epoch: 5| Step: 9
Training loss: 2.7002902030944824
Validation loss: 2.363034845680319

Epoch: 5| Step: 10
Training loss: 2.874530792236328
Validation loss: 2.344385841841339

Epoch: 111| Step: 0
Training loss: 2.4570956230163574
Validation loss: 2.3345916450664563

Epoch: 5| Step: 1
Training loss: 2.732778310775757
Validation loss: 2.3229114496579735

Epoch: 5| Step: 2
Training loss: 2.5636963844299316
Validation loss: 2.3177962149343183

Epoch: 5| Step: 3
Training loss: 2.6667559146881104
Validation loss: 2.3064371129517913

Epoch: 5| Step: 4
Training loss: 2.5865931510925293
Validation loss: 2.296962712400703

Epoch: 5| Step: 5
Training loss: 1.8970773220062256
Validation loss: 2.301747780974193

Epoch: 5| Step: 6
Training loss: 2.2647109031677246
Validation loss: 2.302933080222017

Epoch: 5| Step: 7
Training loss: 2.7001850605010986
Validation loss: 2.3148981191778697

Epoch: 5| Step: 8
Training loss: 3.43471097946167
Validation loss: 2.3129480474738666

Epoch: 5| Step: 9
Training loss: 2.3390235900878906
Validation loss: 2.3037647303714546

Epoch: 5| Step: 10
Training loss: 2.2915964126586914
Validation loss: 2.300947677704596

Epoch: 112| Step: 0
Training loss: 2.361859083175659
Validation loss: 2.2949459245128017

Epoch: 5| Step: 1
Training loss: 2.324370861053467
Validation loss: 2.2886366151994273

Epoch: 5| Step: 2
Training loss: 2.367560863494873
Validation loss: 2.284550969318677

Epoch: 5| Step: 3
Training loss: 2.423027753829956
Validation loss: 2.2864114340915473

Epoch: 5| Step: 4
Training loss: 1.8620983362197876
Validation loss: 2.2892336178851385

Epoch: 5| Step: 5
Training loss: 2.6084418296813965
Validation loss: 2.2933392909265335

Epoch: 5| Step: 6
Training loss: 2.803380250930786
Validation loss: 2.294089896704561

Epoch: 5| Step: 7
Training loss: 2.7529637813568115
Validation loss: 2.2792170996307046

Epoch: 5| Step: 8
Training loss: 2.794637441635132
Validation loss: 2.27992388766299

Epoch: 5| Step: 9
Training loss: 3.225937604904175
Validation loss: 2.2814689861830844

Epoch: 5| Step: 10
Training loss: 2.368847608566284
Validation loss: 2.280374737196071

Epoch: 113| Step: 0
Training loss: 3.2605316638946533
Validation loss: 2.291079633979387

Epoch: 5| Step: 1
Training loss: 2.097851276397705
Validation loss: 2.2869070524810464

Epoch: 5| Step: 2
Training loss: 2.402851104736328
Validation loss: 2.289617028287662

Epoch: 5| Step: 3
Training loss: 2.8771393299102783
Validation loss: 2.2885557118282525

Epoch: 5| Step: 4
Training loss: 2.9782772064208984
Validation loss: 2.2973607163275442

Epoch: 5| Step: 5
Training loss: 1.9708385467529297
Validation loss: 2.3051394326712495

Epoch: 5| Step: 6
Training loss: 2.611677408218384
Validation loss: 2.3069060925514466

Epoch: 5| Step: 7
Training loss: 2.259242534637451
Validation loss: 2.3098822357834026

Epoch: 5| Step: 8
Training loss: 2.4541308879852295
Validation loss: 2.3333256001113565

Epoch: 5| Step: 9
Training loss: 2.6047420501708984
Validation loss: 2.330873735489384

Epoch: 5| Step: 10
Training loss: 2.2447848320007324
Validation loss: 2.314629998258365

Epoch: 114| Step: 0
Training loss: 2.7407522201538086
Validation loss: 2.302050905842935

Epoch: 5| Step: 1
Training loss: 2.5188865661621094
Validation loss: 2.286215172019056

Epoch: 5| Step: 2
Training loss: 2.5802717208862305
Validation loss: 2.282477242972261

Epoch: 5| Step: 3
Training loss: 1.8698982000350952
Validation loss: 2.2707954017064904

Epoch: 5| Step: 4
Training loss: 2.938845634460449
Validation loss: 2.2752305640969226

Epoch: 5| Step: 5
Training loss: 2.26714825630188
Validation loss: 2.266257316835465

Epoch: 5| Step: 6
Training loss: 2.7251105308532715
Validation loss: 2.2627948227749077

Epoch: 5| Step: 7
Training loss: 2.1490397453308105
Validation loss: 2.2645176508093394

Epoch: 5| Step: 8
Training loss: 3.4226927757263184
Validation loss: 2.262924830118815

Epoch: 5| Step: 9
Training loss: 2.2060739994049072
Validation loss: 2.2653013326788463

Epoch: 5| Step: 10
Training loss: 2.264779806137085
Validation loss: 2.2709417214957615

Epoch: 115| Step: 0
Training loss: 2.7757914066314697
Validation loss: 2.3106898364200386

Epoch: 5| Step: 1
Training loss: 3.0567755699157715
Validation loss: 2.298305401238062

Epoch: 5| Step: 2
Training loss: 2.3795981407165527
Validation loss: 2.2603967548698507

Epoch: 5| Step: 3
Training loss: 2.563063621520996
Validation loss: 2.2620147876842047

Epoch: 5| Step: 4
Training loss: 2.825643539428711
Validation loss: 2.2701608903946413

Epoch: 5| Step: 5
Training loss: 2.059767723083496
Validation loss: 2.2774799177723546

Epoch: 5| Step: 6
Training loss: 2.7342331409454346
Validation loss: 2.293665139905868

Epoch: 5| Step: 7
Training loss: 2.7575957775115967
Validation loss: 2.2942179531179447

Epoch: 5| Step: 8
Training loss: 2.0078036785125732
Validation loss: 2.281151927927489

Epoch: 5| Step: 9
Training loss: 2.0543553829193115
Validation loss: 2.275053554965604

Epoch: 5| Step: 10
Training loss: 2.831411361694336
Validation loss: 2.284858198576076

Epoch: 116| Step: 0
Training loss: 2.142606735229492
Validation loss: 2.3319727220842914

Epoch: 5| Step: 1
Training loss: 2.686084270477295
Validation loss: 2.340860228384695

Epoch: 5| Step: 2
Training loss: 2.9286627769470215
Validation loss: 2.347788328765541

Epoch: 5| Step: 3
Training loss: 2.8566431999206543
Validation loss: 2.33760150530005

Epoch: 5| Step: 4
Training loss: 2.138404369354248
Validation loss: 2.305940753670149

Epoch: 5| Step: 5
Training loss: 2.6570041179656982
Validation loss: 2.2768031320264264

Epoch: 5| Step: 6
Training loss: 2.076441764831543
Validation loss: 2.263822570923836

Epoch: 5| Step: 7
Training loss: 2.2901337146759033
Validation loss: 2.2699268223136984

Epoch: 5| Step: 8
Training loss: 2.7725868225097656
Validation loss: 2.2761170479559127

Epoch: 5| Step: 9
Training loss: 2.8572092056274414
Validation loss: 2.2735031932912846

Epoch: 5| Step: 10
Training loss: 2.445272207260132
Validation loss: 2.290373830385106

Epoch: 117| Step: 0
Training loss: 2.8599743843078613
Validation loss: 2.27479052030912

Epoch: 5| Step: 1
Training loss: 2.6993677616119385
Validation loss: 2.2703672121929865

Epoch: 5| Step: 2
Training loss: 2.389206647872925
Validation loss: 2.274754875449724

Epoch: 5| Step: 3
Training loss: 2.2460036277770996
Validation loss: 2.295848431125764

Epoch: 5| Step: 4
Training loss: 2.2207441329956055
Validation loss: 2.3153605614939043

Epoch: 5| Step: 5
Training loss: 2.4829068183898926
Validation loss: 2.3475294702796528

Epoch: 5| Step: 6
Training loss: 2.262612819671631
Validation loss: 2.353470251124392

Epoch: 5| Step: 7
Training loss: 2.3918442726135254
Validation loss: 2.3193471149731706

Epoch: 5| Step: 8
Training loss: 2.860128879547119
Validation loss: 2.3001953837692097

Epoch: 5| Step: 9
Training loss: 2.3060600757598877
Validation loss: 2.2909637945954517

Epoch: 5| Step: 10
Training loss: 3.2482666969299316
Validation loss: 2.2824578721036195

Epoch: 118| Step: 0
Training loss: 2.766101360321045
Validation loss: 2.2946448710656937

Epoch: 5| Step: 1
Training loss: 2.4726459980010986
Validation loss: 2.3048167510699202

Epoch: 5| Step: 2
Training loss: 2.2438344955444336
Validation loss: 2.3376868104421966

Epoch: 5| Step: 3
Training loss: 2.8069446086883545
Validation loss: 2.3728148757770495

Epoch: 5| Step: 4
Training loss: 2.975501537322998
Validation loss: 2.352342144135506

Epoch: 5| Step: 5
Training loss: 2.610954999923706
Validation loss: 2.3112202036765312

Epoch: 5| Step: 6
Training loss: 2.686328649520874
Validation loss: 2.2647894300440305

Epoch: 5| Step: 7
Training loss: 1.8424079418182373
Validation loss: 2.2548957153033187

Epoch: 5| Step: 8
Training loss: 2.8521182537078857
Validation loss: 2.2628570679695375

Epoch: 5| Step: 9
Training loss: 2.090231418609619
Validation loss: 2.263214288219329

Epoch: 5| Step: 10
Training loss: 2.4906022548675537
Validation loss: 2.2690391681527577

Epoch: 119| Step: 0
Training loss: 2.4693686962127686
Validation loss: 2.2852389017740884

Epoch: 5| Step: 1
Training loss: 3.3040771484375
Validation loss: 2.3148017980719127

Epoch: 5| Step: 2
Training loss: 1.9585182666778564
Validation loss: 2.321753926174615

Epoch: 5| Step: 3
Training loss: 2.2161197662353516
Validation loss: 2.30221652471891

Epoch: 5| Step: 4
Training loss: 3.455599308013916
Validation loss: 2.2774945946149927

Epoch: 5| Step: 5
Training loss: 2.261173725128174
Validation loss: 2.241815341416226

Epoch: 5| Step: 6
Training loss: 3.4188480377197266
Validation loss: 2.22942973977776

Epoch: 5| Step: 7
Training loss: 2.0274622440338135
Validation loss: 2.2368700811939854

Epoch: 5| Step: 8
Training loss: 2.3133509159088135
Validation loss: 2.2480519151174896

Epoch: 5| Step: 9
Training loss: 2.496241569519043
Validation loss: 2.2599107168054067

Epoch: 5| Step: 10
Training loss: 2.085123062133789
Validation loss: 2.2670496253557104

Epoch: 120| Step: 0
Training loss: 2.580763339996338
Validation loss: 2.269885422081076

Epoch: 5| Step: 1
Training loss: 2.6375889778137207
Validation loss: 2.2881448127890147

Epoch: 5| Step: 2
Training loss: 2.483943223953247
Validation loss: 2.352863662986345

Epoch: 5| Step: 3
Training loss: 2.2676737308502197
Validation loss: 2.3672538136923187

Epoch: 5| Step: 4
Training loss: 3.4283854961395264
Validation loss: 2.4117241418489845

Epoch: 5| Step: 5
Training loss: 2.964568614959717
Validation loss: 2.40138078248629

Epoch: 5| Step: 6
Training loss: 2.7414395809173584
Validation loss: 2.405019757568195

Epoch: 5| Step: 7
Training loss: 2.415828227996826
Validation loss: 2.3781194635616836

Epoch: 5| Step: 8
Training loss: 2.23478364944458
Validation loss: 2.370112011509557

Epoch: 5| Step: 9
Training loss: 2.212773561477661
Validation loss: 2.3342780169620307

Epoch: 5| Step: 10
Training loss: 2.6668806076049805
Validation loss: 2.2796352755638862

Epoch: 121| Step: 0
Training loss: 2.2114901542663574
Validation loss: 2.234512672629408

Epoch: 5| Step: 1
Training loss: 2.2785980701446533
Validation loss: 2.2347657154965144

Epoch: 5| Step: 2
Training loss: 2.6750030517578125
Validation loss: 2.255375013556532

Epoch: 5| Step: 3
Training loss: 3.010042667388916
Validation loss: 2.2703684863223823

Epoch: 5| Step: 4
Training loss: 2.384838581085205
Validation loss: 2.3194800833220124

Epoch: 5| Step: 5
Training loss: 2.4079697132110596
Validation loss: 2.351180068908199

Epoch: 5| Step: 6
Training loss: 2.806391477584839
Validation loss: 2.3964347095899683

Epoch: 5| Step: 7
Training loss: 2.439192771911621
Validation loss: 2.2934110139005925

Epoch: 5| Step: 8
Training loss: 2.0636990070343018
Validation loss: 2.242550996042067

Epoch: 5| Step: 9
Training loss: 2.2777838706970215
Validation loss: 2.2364682535971365

Epoch: 5| Step: 10
Training loss: 3.298920154571533
Validation loss: 2.236423279649468

Epoch: 122| Step: 0
Training loss: 2.4139766693115234
Validation loss: 2.2347289208442933

Epoch: 5| Step: 1
Training loss: 2.6131198406219482
Validation loss: 2.249943812688192

Epoch: 5| Step: 2
Training loss: 1.9677155017852783
Validation loss: 2.271991842536516

Epoch: 5| Step: 3
Training loss: 2.546746015548706
Validation loss: 2.304026062770556

Epoch: 5| Step: 4
Training loss: 3.0727639198303223
Validation loss: 2.3031975069353656

Epoch: 5| Step: 5
Training loss: 2.6476001739501953
Validation loss: 2.2893582697837584

Epoch: 5| Step: 6
Training loss: 2.0561599731445312
Validation loss: 2.2773353643314813

Epoch: 5| Step: 7
Training loss: 3.0155818462371826
Validation loss: 2.2574829042598767

Epoch: 5| Step: 8
Training loss: 2.8187012672424316
Validation loss: 2.2529225067425798

Epoch: 5| Step: 9
Training loss: 1.9538114070892334
Validation loss: 2.2747164310947543

Epoch: 5| Step: 10
Training loss: 2.369783878326416
Validation loss: 2.307088064891036

Epoch: 123| Step: 0
Training loss: 3.033715009689331
Validation loss: 2.319159177041823

Epoch: 5| Step: 1
Training loss: 1.608173131942749
Validation loss: 2.296298260329872

Epoch: 5| Step: 2
Training loss: 2.508723497390747
Validation loss: 2.2973807883518997

Epoch: 5| Step: 3
Training loss: 2.534553050994873
Validation loss: 2.2674718056955645

Epoch: 5| Step: 4
Training loss: 2.5944271087646484
Validation loss: 2.254912922459264

Epoch: 5| Step: 5
Training loss: 2.548302173614502
Validation loss: 2.273944954718313

Epoch: 5| Step: 6
Training loss: 2.653435707092285
Validation loss: 2.279987307005031

Epoch: 5| Step: 7
Training loss: 2.924827814102173
Validation loss: 2.264659199663388

Epoch: 5| Step: 8
Training loss: 2.915942430496216
Validation loss: 2.237806035626319

Epoch: 5| Step: 9
Training loss: 2.034550428390503
Validation loss: 2.2279011664852018

Epoch: 5| Step: 10
Training loss: 1.9252936840057373
Validation loss: 2.2283207613934755

Epoch: 124| Step: 0
Training loss: 2.6535778045654297
Validation loss: 2.2280499294239986

Epoch: 5| Step: 1
Training loss: 2.283756971359253
Validation loss: 2.2203522933426725

Epoch: 5| Step: 2
Training loss: 2.7785258293151855
Validation loss: 2.2170076113875195

Epoch: 5| Step: 3
Training loss: 2.4375245571136475
Validation loss: 2.220460848141742

Epoch: 5| Step: 4
Training loss: 2.7824459075927734
Validation loss: 2.2313734075074554

Epoch: 5| Step: 5
Training loss: 2.249025821685791
Validation loss: 2.2355528416172152

Epoch: 5| Step: 6
Training loss: 2.0702884197235107
Validation loss: 2.2494238217671714

Epoch: 5| Step: 7
Training loss: 2.5249123573303223
Validation loss: 2.263187316156203

Epoch: 5| Step: 8
Training loss: 2.392728567123413
Validation loss: 2.266907253573018

Epoch: 5| Step: 9
Training loss: 2.6436305046081543
Validation loss: 2.2656937055690314

Epoch: 5| Step: 10
Training loss: 2.557358980178833
Validation loss: 2.266341153011527

Epoch: 125| Step: 0
Training loss: 1.9858691692352295
Validation loss: 2.253075297160815

Epoch: 5| Step: 1
Training loss: 2.6531825065612793
Validation loss: 2.2414444697800504

Epoch: 5| Step: 2
Training loss: 2.667726993560791
Validation loss: 2.2220218053428074

Epoch: 5| Step: 3
Training loss: 2.8902347087860107
Validation loss: 2.212576996895575

Epoch: 5| Step: 4
Training loss: 2.5391674041748047
Validation loss: 2.2183980582862772

Epoch: 5| Step: 5
Training loss: 1.9016107320785522
Validation loss: 2.2191938187486384

Epoch: 5| Step: 6
Training loss: 2.7140145301818848
Validation loss: 2.2247951364004486

Epoch: 5| Step: 7
Training loss: 2.8830106258392334
Validation loss: 2.23120431874388

Epoch: 5| Step: 8
Training loss: 2.220674753189087
Validation loss: 2.245483395873859

Epoch: 5| Step: 9
Training loss: 2.333130121231079
Validation loss: 2.221097207838489

Epoch: 5| Step: 10
Training loss: 2.9383087158203125
Validation loss: 2.217309021180676

Epoch: 126| Step: 0
Training loss: 2.1094822883605957
Validation loss: 2.2160772713281776

Epoch: 5| Step: 1
Training loss: 2.453139543533325
Validation loss: 2.217221890726397

Epoch: 5| Step: 2
Training loss: 2.3368518352508545
Validation loss: 2.2320261168223556

Epoch: 5| Step: 3
Training loss: 2.232567548751831
Validation loss: 2.240310231844584

Epoch: 5| Step: 4
Training loss: 2.9427504539489746
Validation loss: 2.2648074806377454

Epoch: 5| Step: 5
Training loss: 1.8748257160186768
Validation loss: 2.2690922188502487

Epoch: 5| Step: 6
Training loss: 1.9799261093139648
Validation loss: 2.2528774046128794

Epoch: 5| Step: 7
Training loss: 3.068229913711548
Validation loss: 2.2399232618270384

Epoch: 5| Step: 8
Training loss: 3.1482996940612793
Validation loss: 2.218963940938314

Epoch: 5| Step: 9
Training loss: 2.392458438873291
Validation loss: 2.221715719469132

Epoch: 5| Step: 10
Training loss: 2.832052707672119
Validation loss: 2.2292598037309546

Epoch: 127| Step: 0
Training loss: 2.109952449798584
Validation loss: 2.252313158845389

Epoch: 5| Step: 1
Training loss: 2.789620876312256
Validation loss: 2.251267877958154

Epoch: 5| Step: 2
Training loss: 2.7680301666259766
Validation loss: 2.2262213589042745

Epoch: 5| Step: 3
Training loss: 2.8306071758270264
Validation loss: 2.2187185210566365

Epoch: 5| Step: 4
Training loss: 1.8781036138534546
Validation loss: 2.201647427774245

Epoch: 5| Step: 5
Training loss: 2.787278175354004
Validation loss: 2.200928818794989

Epoch: 5| Step: 6
Training loss: 2.3159842491149902
Validation loss: 2.21239915714469

Epoch: 5| Step: 7
Training loss: 2.2015767097473145
Validation loss: 2.229387593525712

Epoch: 5| Step: 8
Training loss: 2.884230136871338
Validation loss: 2.223683052165534

Epoch: 5| Step: 9
Training loss: 2.3567442893981934
Validation loss: 2.2135217087243193

Epoch: 5| Step: 10
Training loss: 2.464029550552368
Validation loss: 2.2074962328839045

Epoch: 128| Step: 0
Training loss: 2.2216899394989014
Validation loss: 2.208550037876252

Epoch: 5| Step: 1
Training loss: 2.815730571746826
Validation loss: 2.209346786622078

Epoch: 5| Step: 2
Training loss: 2.234367847442627
Validation loss: 2.202163714234547

Epoch: 5| Step: 3
Training loss: 2.7746691703796387
Validation loss: 2.2000364257443334

Epoch: 5| Step: 4
Training loss: 2.374742031097412
Validation loss: 2.211029109134469

Epoch: 5| Step: 5
Training loss: 2.513596296310425
Validation loss: 2.212929671810519

Epoch: 5| Step: 6
Training loss: 2.3506836891174316
Validation loss: 2.2527999057564685

Epoch: 5| Step: 7
Training loss: 2.3052549362182617
Validation loss: 2.2607531662910216

Epoch: 5| Step: 8
Training loss: 2.651689052581787
Validation loss: 2.272701814610471

Epoch: 5| Step: 9
Training loss: 2.431980609893799
Validation loss: 2.225417693456014

Epoch: 5| Step: 10
Training loss: 2.4849777221679688
Validation loss: 2.2202590050235873

Epoch: 129| Step: 0
Training loss: 1.9721729755401611
Validation loss: 2.2126056148159887

Epoch: 5| Step: 1
Training loss: 2.1692309379577637
Validation loss: 2.210142212529336

Epoch: 5| Step: 2
Training loss: 2.3860926628112793
Validation loss: 2.229851815008348

Epoch: 5| Step: 3
Training loss: 2.002077579498291
Validation loss: 2.2267961450802383

Epoch: 5| Step: 4
Training loss: 2.4707260131835938
Validation loss: 2.2233262754255727

Epoch: 5| Step: 5
Training loss: 2.63191294670105
Validation loss: 2.2221487158088276

Epoch: 5| Step: 6
Training loss: 2.825014591217041
Validation loss: 2.233560977443572

Epoch: 5| Step: 7
Training loss: 2.481018543243408
Validation loss: 2.253592486022621

Epoch: 5| Step: 8
Training loss: 2.6350390911102295
Validation loss: 2.2598005340945337

Epoch: 5| Step: 9
Training loss: 2.932246446609497
Validation loss: 2.246496074943132

Epoch: 5| Step: 10
Training loss: 2.4617156982421875
Validation loss: 2.2348694032238376

Epoch: 130| Step: 0
Training loss: 3.123070240020752
Validation loss: 2.207060037120696

Epoch: 5| Step: 1
Training loss: 2.1091740131378174
Validation loss: 2.2104342957978607

Epoch: 5| Step: 2
Training loss: 2.6229255199432373
Validation loss: 2.1950124745727866

Epoch: 5| Step: 3
Training loss: 2.208106279373169
Validation loss: 2.2058516394707466

Epoch: 5| Step: 4
Training loss: 1.9106286764144897
Validation loss: 2.2087293312113774

Epoch: 5| Step: 5
Training loss: 2.046628475189209
Validation loss: 2.192014927505165

Epoch: 5| Step: 6
Training loss: 2.7960028648376465
Validation loss: 2.207297532789169

Epoch: 5| Step: 7
Training loss: 2.543058395385742
Validation loss: 2.211974943837812

Epoch: 5| Step: 8
Training loss: 2.4618823528289795
Validation loss: 2.220140549444383

Epoch: 5| Step: 9
Training loss: 2.4313979148864746
Validation loss: 2.227916209928451

Epoch: 5| Step: 10
Training loss: 2.6596572399139404
Validation loss: 2.228545847759452

Epoch: 131| Step: 0
Training loss: 2.5685267448425293
Validation loss: 2.2112866781091176

Epoch: 5| Step: 1
Training loss: 2.314906597137451
Validation loss: 2.217830393903999

Epoch: 5| Step: 2
Training loss: 2.1117777824401855
Validation loss: 2.224226256852509

Epoch: 5| Step: 3
Training loss: 2.6425681114196777
Validation loss: 2.250193367722214

Epoch: 5| Step: 4
Training loss: 1.9100929498672485
Validation loss: 2.2655105847184376

Epoch: 5| Step: 5
Training loss: 2.132786273956299
Validation loss: 2.260957717895508

Epoch: 5| Step: 6
Training loss: 2.264355182647705
Validation loss: 2.254775221629809

Epoch: 5| Step: 7
Training loss: 3.3913044929504395
Validation loss: 2.2736181264282553

Epoch: 5| Step: 8
Training loss: 1.8361871242523193
Validation loss: 2.2774670329145206

Epoch: 5| Step: 9
Training loss: 3.035841226577759
Validation loss: 2.2570772350475354

Epoch: 5| Step: 10
Training loss: 2.766580581665039
Validation loss: 2.249817091931579

Epoch: 132| Step: 0
Training loss: 2.1094119548797607
Validation loss: 2.220684107913766

Epoch: 5| Step: 1
Training loss: 2.068357467651367
Validation loss: 2.215560931031422

Epoch: 5| Step: 2
Training loss: 2.184110164642334
Validation loss: 2.2043897464711177

Epoch: 5| Step: 3
Training loss: 2.7889888286590576
Validation loss: 2.1992189858549382

Epoch: 5| Step: 4
Training loss: 2.60589599609375
Validation loss: 2.1995354006367345

Epoch: 5| Step: 5
Training loss: 2.5882744789123535
Validation loss: 2.1920981637893187

Epoch: 5| Step: 6
Training loss: 2.8032708168029785
Validation loss: 2.210631591017528

Epoch: 5| Step: 7
Training loss: 2.4048171043395996
Validation loss: 2.2117099172325543

Epoch: 5| Step: 8
Training loss: 2.4935827255249023
Validation loss: 2.2013012568155923

Epoch: 5| Step: 9
Training loss: 2.166511297225952
Validation loss: 2.2002125106832033

Epoch: 5| Step: 10
Training loss: 2.6114766597747803
Validation loss: 2.2038810304416123

Epoch: 133| Step: 0
Training loss: 2.34169602394104
Validation loss: 2.248505844864794

Epoch: 5| Step: 1
Training loss: 1.913067102432251
Validation loss: 2.302799896527362

Epoch: 5| Step: 2
Training loss: 1.673749566078186
Validation loss: 2.3156874102930867

Epoch: 5| Step: 3
Training loss: 2.2948861122131348
Validation loss: 2.3497414563291814

Epoch: 5| Step: 4
Training loss: 3.1937358379364014
Validation loss: 2.309735446847895

Epoch: 5| Step: 5
Training loss: 1.9425220489501953
Validation loss: 2.218657898646529

Epoch: 5| Step: 6
Training loss: 2.557880401611328
Validation loss: 2.1854660690471692

Epoch: 5| Step: 7
Training loss: 3.2625985145568848
Validation loss: 2.1879942776054464

Epoch: 5| Step: 8
Training loss: 2.670304536819458
Validation loss: 2.2048209892806185

Epoch: 5| Step: 9
Training loss: 2.1528689861297607
Validation loss: 2.2311233089816187

Epoch: 5| Step: 10
Training loss: 2.9245779514312744
Validation loss: 2.245200833966655

Epoch: 134| Step: 0
Training loss: 2.829012393951416
Validation loss: 2.2335578280110515

Epoch: 5| Step: 1
Training loss: 2.1818604469299316
Validation loss: 2.1906120161856375

Epoch: 5| Step: 2
Training loss: 2.496502161026001
Validation loss: 2.182020900070026

Epoch: 5| Step: 3
Training loss: 2.4202475547790527
Validation loss: 2.175410516800419

Epoch: 5| Step: 4
Training loss: 2.1320738792419434
Validation loss: 2.1766383314645417

Epoch: 5| Step: 5
Training loss: 2.8311879634857178
Validation loss: 2.188602901274158

Epoch: 5| Step: 6
Training loss: 3.1766409873962402
Validation loss: 2.2156122730624292

Epoch: 5| Step: 7
Training loss: 2.6037259101867676
Validation loss: 2.2559333667960217

Epoch: 5| Step: 8
Training loss: 1.5343451499938965
Validation loss: 2.280057584085772

Epoch: 5| Step: 9
Training loss: 2.018430233001709
Validation loss: 2.3083590999726327

Epoch: 5| Step: 10
Training loss: 2.8590641021728516
Validation loss: 2.275350921897478

Epoch: 135| Step: 0
Training loss: 1.9970792531967163
Validation loss: 2.197587464445381

Epoch: 5| Step: 1
Training loss: 1.8170782327651978
Validation loss: 2.1710100173950195

Epoch: 5| Step: 2
Training loss: 2.073495626449585
Validation loss: 2.1931902670091197

Epoch: 5| Step: 3
Training loss: 2.871767520904541
Validation loss: 2.274827439297912

Epoch: 5| Step: 4
Training loss: 2.4349491596221924
Validation loss: 2.3315392604438205

Epoch: 5| Step: 5
Training loss: 2.79598331451416
Validation loss: 2.3376425927685154

Epoch: 5| Step: 6
Training loss: 3.0364444255828857
Validation loss: 2.313233208912675

Epoch: 5| Step: 7
Training loss: 2.5418574810028076
Validation loss: 2.284246849757369

Epoch: 5| Step: 8
Training loss: 3.0744102001190186
Validation loss: 2.2282493114471436

Epoch: 5| Step: 9
Training loss: 2.3132433891296387
Validation loss: 2.204713095900833

Epoch: 5| Step: 10
Training loss: 2.2288076877593994
Validation loss: 2.2076862806914956

Epoch: 136| Step: 0
Training loss: 2.9886722564697266
Validation loss: 2.2074414094289145

Epoch: 5| Step: 1
Training loss: 2.6488659381866455
Validation loss: 2.207079561807776

Epoch: 5| Step: 2
Training loss: 2.0936591625213623
Validation loss: 2.22043175594781

Epoch: 5| Step: 3
Training loss: 2.3167548179626465
Validation loss: 2.1852509847251316

Epoch: 5| Step: 4
Training loss: 2.5801944732666016
Validation loss: 2.175465678655973

Epoch: 5| Step: 5
Training loss: 2.443012237548828
Validation loss: 2.179873271655011

Epoch: 5| Step: 6
Training loss: 2.2105915546417236
Validation loss: 2.189224922528831

Epoch: 5| Step: 7
Training loss: 2.543853998184204
Validation loss: 2.1998407379273446

Epoch: 5| Step: 8
Training loss: 2.2597854137420654
Validation loss: 2.2104379130947973

Epoch: 5| Step: 9
Training loss: 2.47924542427063
Validation loss: 2.207415589722254

Epoch: 5| Step: 10
Training loss: 1.9840763807296753
Validation loss: 2.2336056719544115

Epoch: 137| Step: 0
Training loss: 2.337620973587036
Validation loss: 2.2152617669874624

Epoch: 5| Step: 1
Training loss: 2.264096736907959
Validation loss: 2.216171277466641

Epoch: 5| Step: 2
Training loss: 2.3292932510375977
Validation loss: 2.192917320036119

Epoch: 5| Step: 3
Training loss: 2.173962354660034
Validation loss: 2.189007072038548

Epoch: 5| Step: 4
Training loss: 3.052891254425049
Validation loss: 2.178708904532976

Epoch: 5| Step: 5
Training loss: 1.7066017389297485
Validation loss: 2.175419866397817

Epoch: 5| Step: 6
Training loss: 2.0775551795959473
Validation loss: 2.186668683123845

Epoch: 5| Step: 7
Training loss: 2.4692115783691406
Validation loss: 2.2273155207275064

Epoch: 5| Step: 8
Training loss: 2.561352014541626
Validation loss: 2.2981134845364477

Epoch: 5| Step: 9
Training loss: 3.3449196815490723
Validation loss: 2.3941728479118756

Epoch: 5| Step: 10
Training loss: 2.499187469482422
Validation loss: 2.3388441865162184

Epoch: 138| Step: 0
Training loss: 2.808952569961548
Validation loss: 2.2045920074626966

Epoch: 5| Step: 1
Training loss: 2.14788818359375
Validation loss: 2.1636175224857945

Epoch: 5| Step: 2
Training loss: 2.1737163066864014
Validation loss: 2.188860834285777

Epoch: 5| Step: 3
Training loss: 2.375845193862915
Validation loss: 2.2177443735061155

Epoch: 5| Step: 4
Training loss: 2.9760947227478027
Validation loss: 2.229039845928069

Epoch: 5| Step: 5
Training loss: 2.1365842819213867
Validation loss: 2.212957533456946

Epoch: 5| Step: 6
Training loss: 2.8606932163238525
Validation loss: 2.198150465565343

Epoch: 5| Step: 7
Training loss: 1.9940290451049805
Validation loss: 2.169918901176863

Epoch: 5| Step: 8
Training loss: 2.0473742485046387
Validation loss: 2.14637860175102

Epoch: 5| Step: 9
Training loss: 2.884133815765381
Validation loss: 2.1395348041288313

Epoch: 5| Step: 10
Training loss: 2.5709869861602783
Validation loss: 2.1333889474150953

Epoch: 139| Step: 0
Training loss: 2.519902229309082
Validation loss: 2.130599570530717

Epoch: 5| Step: 1
Training loss: 2.6870274543762207
Validation loss: 2.1307225675993067

Epoch: 5| Step: 2
Training loss: 2.368837833404541
Validation loss: 2.1321057888769333

Epoch: 5| Step: 3
Training loss: 2.5560078620910645
Validation loss: 2.135412085440851

Epoch: 5| Step: 4
Training loss: 3.1223862171173096
Validation loss: 2.1405628650419173

Epoch: 5| Step: 5
Training loss: 2.2170357704162598
Validation loss: 2.154632604250344

Epoch: 5| Step: 6
Training loss: 2.292203903198242
Validation loss: 2.1731612143977994

Epoch: 5| Step: 7
Training loss: 2.6192028522491455
Validation loss: 2.1702695995248775

Epoch: 5| Step: 8
Training loss: 2.46738862991333
Validation loss: 2.181509671672698

Epoch: 5| Step: 9
Training loss: 1.875268578529358
Validation loss: 2.169925187223701

Epoch: 5| Step: 10
Training loss: 1.755359411239624
Validation loss: 2.174245601059288

Epoch: 140| Step: 0
Training loss: 3.041273832321167
Validation loss: 2.2024782755041636

Epoch: 5| Step: 1
Training loss: 2.0884506702423096
Validation loss: 2.191569423162809

Epoch: 5| Step: 2
Training loss: 3.001129627227783
Validation loss: 2.1728149844754125

Epoch: 5| Step: 3
Training loss: 2.8884713649749756
Validation loss: 2.194499738754765

Epoch: 5| Step: 4
Training loss: 2.0519957542419434
Validation loss: 2.206345753003192

Epoch: 5| Step: 5
Training loss: 2.2377841472625732
Validation loss: 2.1917841613933606

Epoch: 5| Step: 6
Training loss: 2.0194599628448486
Validation loss: 2.154057623237692

Epoch: 5| Step: 7
Training loss: 1.929311752319336
Validation loss: 2.144535877371347

Epoch: 5| Step: 8
Training loss: 2.687859535217285
Validation loss: 2.1611831675293627

Epoch: 5| Step: 9
Training loss: 1.8117586374282837
Validation loss: 2.1891175598226567

Epoch: 5| Step: 10
Training loss: 2.934765100479126
Validation loss: 2.2205313585137807

Epoch: 141| Step: 0
Training loss: 2.1886658668518066
Validation loss: 2.2333283885832755

Epoch: 5| Step: 1
Training loss: 2.445338726043701
Validation loss: 2.2407080152983307

Epoch: 5| Step: 2
Training loss: 3.026714324951172
Validation loss: 2.204180094503587

Epoch: 5| Step: 3
Training loss: 2.2661845684051514
Validation loss: 2.1837166458047848

Epoch: 5| Step: 4
Training loss: 1.9194881916046143
Validation loss: 2.1819532250845306

Epoch: 5| Step: 5
Training loss: 1.8392770290374756
Validation loss: 2.1909148872539563

Epoch: 5| Step: 6
Training loss: 2.323906421661377
Validation loss: 2.1978042151338313

Epoch: 5| Step: 7
Training loss: 2.8125076293945312
Validation loss: 2.2091367116538425

Epoch: 5| Step: 8
Training loss: 2.7620506286621094
Validation loss: 2.202151293395668

Epoch: 5| Step: 9
Training loss: 1.920619010925293
Validation loss: 2.211767735019807

Epoch: 5| Step: 10
Training loss: 3.11346173286438
Validation loss: 2.210122821151569

Epoch: 142| Step: 0
Training loss: 2.579010486602783
Validation loss: 2.2161949283333233

Epoch: 5| Step: 1
Training loss: 2.1572394371032715
Validation loss: 2.2031857275193736

Epoch: 5| Step: 2
Training loss: 2.3282909393310547
Validation loss: 2.1933884543757283

Epoch: 5| Step: 3
Training loss: 2.576720714569092
Validation loss: 2.1844699587873233

Epoch: 5| Step: 4
Training loss: 2.028959035873413
Validation loss: 2.1962456062275875

Epoch: 5| Step: 5
Training loss: 3.0135843753814697
Validation loss: 2.224618927125008

Epoch: 5| Step: 6
Training loss: 2.491335391998291
Validation loss: 2.206099825520669

Epoch: 5| Step: 7
Training loss: 2.4673800468444824
Validation loss: 2.183589304647138

Epoch: 5| Step: 8
Training loss: 2.7173514366149902
Validation loss: 2.160320774201424

Epoch: 5| Step: 9
Training loss: 2.0696988105773926
Validation loss: 2.1523280912829983

Epoch: 5| Step: 10
Training loss: 2.0249252319335938
Validation loss: 2.16032975463457

Epoch: 143| Step: 0
Training loss: 2.4585909843444824
Validation loss: 2.205411018863801

Epoch: 5| Step: 1
Training loss: 2.4469611644744873
Validation loss: 2.268148814478228

Epoch: 5| Step: 2
Training loss: 2.955814838409424
Validation loss: 2.342065765011695

Epoch: 5| Step: 3
Training loss: 2.317103624343872
Validation loss: 2.3563656499308925

Epoch: 5| Step: 4
Training loss: 2.6386849880218506
Validation loss: 2.323519232452557

Epoch: 5| Step: 5
Training loss: 2.0978803634643555
Validation loss: 2.2371514074264036

Epoch: 5| Step: 6
Training loss: 2.1954703330993652
Validation loss: 2.2033487058454946

Epoch: 5| Step: 7
Training loss: 2.894998550415039
Validation loss: 2.222856148596733

Epoch: 5| Step: 8
Training loss: 1.818097472190857
Validation loss: 2.2290916724871566

Epoch: 5| Step: 9
Training loss: 2.761077404022217
Validation loss: 2.21479380771678

Epoch: 5| Step: 10
Training loss: 1.967982530593872
Validation loss: 2.2012894897050757

Epoch: 144| Step: 0
Training loss: 2.64811110496521
Validation loss: 2.180198851452079

Epoch: 5| Step: 1
Training loss: 2.2486846446990967
Validation loss: 2.1540410467373428

Epoch: 5| Step: 2
Training loss: 2.795850992202759
Validation loss: 2.1388593258396273

Epoch: 5| Step: 3
Training loss: 2.602959156036377
Validation loss: 2.1459327936172485

Epoch: 5| Step: 4
Training loss: 1.9213225841522217
Validation loss: 2.139585277085663

Epoch: 5| Step: 5
Training loss: 2.3535213470458984
Validation loss: 2.1259560918295257

Epoch: 5| Step: 6
Training loss: 2.589529037475586
Validation loss: 2.1272193411345124

Epoch: 5| Step: 7
Training loss: 1.824533462524414
Validation loss: 2.1241879129922516

Epoch: 5| Step: 8
Training loss: 2.315488576889038
Validation loss: 2.1182880555429766

Epoch: 5| Step: 9
Training loss: 2.1985340118408203
Validation loss: 2.126024760225768

Epoch: 5| Step: 10
Training loss: 2.9452688694000244
Validation loss: 2.1258353315373903

Epoch: 145| Step: 0
Training loss: 2.5268898010253906
Validation loss: 2.133804826326268

Epoch: 5| Step: 1
Training loss: 3.3632354736328125
Validation loss: 2.1460953425335627

Epoch: 5| Step: 2
Training loss: 2.4986934661865234
Validation loss: 2.1563425115359727

Epoch: 5| Step: 3
Training loss: 1.5992199182510376
Validation loss: 2.1490522417970883

Epoch: 5| Step: 4
Training loss: 1.9415442943572998
Validation loss: 2.1627804745909986

Epoch: 5| Step: 5
Training loss: 2.4407272338867188
Validation loss: 2.192274865283761

Epoch: 5| Step: 6
Training loss: 2.417240858078003
Validation loss: 2.1800035981721777

Epoch: 5| Step: 7
Training loss: 1.6839653253555298
Validation loss: 2.1801963249842324

Epoch: 5| Step: 8
Training loss: 2.6858744621276855
Validation loss: 2.2118543732550835

Epoch: 5| Step: 9
Training loss: 2.1944661140441895
Validation loss: 2.2006779768133677

Epoch: 5| Step: 10
Training loss: 2.775411367416382
Validation loss: 2.1782131746251094

Epoch: 146| Step: 0
Training loss: 2.7319588661193848
Validation loss: 2.1796569362763436

Epoch: 5| Step: 1
Training loss: 2.115143299102783
Validation loss: 2.155540386835734

Epoch: 5| Step: 2
Training loss: 2.934140205383301
Validation loss: 2.152070337726224

Epoch: 5| Step: 3
Training loss: 2.4885807037353516
Validation loss: 2.1465961651135514

Epoch: 5| Step: 4
Training loss: 2.320525646209717
Validation loss: 2.142248276741274

Epoch: 5| Step: 5
Training loss: 1.868814468383789
Validation loss: 2.1333545805305563

Epoch: 5| Step: 6
Training loss: 2.7163567543029785
Validation loss: 2.14052552048878

Epoch: 5| Step: 7
Training loss: 2.243227958679199
Validation loss: 2.1465275928538334

Epoch: 5| Step: 8
Training loss: 1.7828048467636108
Validation loss: 2.151027694825203

Epoch: 5| Step: 9
Training loss: 2.113720417022705
Validation loss: 2.1716790237734394

Epoch: 5| Step: 10
Training loss: 2.694193124771118
Validation loss: 2.1675999036399265

Epoch: 147| Step: 0
Training loss: 2.411006212234497
Validation loss: 2.1724208452368297

Epoch: 5| Step: 1
Training loss: 2.3954403400421143
Validation loss: 2.165128097739271

Epoch: 5| Step: 2
Training loss: 2.4790701866149902
Validation loss: 2.160327042302778

Epoch: 5| Step: 3
Training loss: 2.1642725467681885
Validation loss: 2.1421689551363707

Epoch: 5| Step: 4
Training loss: 2.7585060596466064
Validation loss: 2.1530333642036683

Epoch: 5| Step: 5
Training loss: 2.2552809715270996
Validation loss: 2.1352324178141933

Epoch: 5| Step: 6
Training loss: 2.001927137374878
Validation loss: 2.1721663436582013

Epoch: 5| Step: 7
Training loss: 2.2528648376464844
Validation loss: 2.183795162426528

Epoch: 5| Step: 8
Training loss: 2.048441171646118
Validation loss: 2.1611857491154827

Epoch: 5| Step: 9
Training loss: 3.1463451385498047
Validation loss: 2.156861394964239

Epoch: 5| Step: 10
Training loss: 1.8253031969070435
Validation loss: 2.1639758310010357

Epoch: 148| Step: 0
Training loss: 2.5078470706939697
Validation loss: 2.2515294141666864

Epoch: 5| Step: 1
Training loss: 2.695711851119995
Validation loss: 2.3126627399075415

Epoch: 5| Step: 2
Training loss: 2.6184096336364746
Validation loss: 2.2991780927104335

Epoch: 5| Step: 3
Training loss: 3.090646982192993
Validation loss: 2.291460678141604

Epoch: 5| Step: 4
Training loss: 2.3640999794006348
Validation loss: 2.246770612655147

Epoch: 5| Step: 5
Training loss: 2.4643912315368652
Validation loss: 2.218434641438146

Epoch: 5| Step: 6
Training loss: 1.6520265340805054
Validation loss: 2.199166385076379

Epoch: 5| Step: 7
Training loss: 2.4470064640045166
Validation loss: 2.1801186210365704

Epoch: 5| Step: 8
Training loss: 1.808053731918335
Validation loss: 2.176851046982632

Epoch: 5| Step: 9
Training loss: 1.7332509756088257
Validation loss: 2.17595523916265

Epoch: 5| Step: 10
Training loss: 2.8493118286132812
Validation loss: 2.1693883172927366

Epoch: 149| Step: 0
Training loss: 2.6457102298736572
Validation loss: 2.1611789887951267

Epoch: 5| Step: 1
Training loss: 1.875523328781128
Validation loss: 2.142602769277429

Epoch: 5| Step: 2
Training loss: 2.3943867683410645
Validation loss: 2.109887916554687

Epoch: 5| Step: 3
Training loss: 3.135140895843506
Validation loss: 2.124794119147844

Epoch: 5| Step: 4
Training loss: 2.0306801795959473
Validation loss: 2.149768275599326

Epoch: 5| Step: 5
Training loss: 2.204225540161133
Validation loss: 2.1677813171058573

Epoch: 5| Step: 6
Training loss: 2.713758945465088
Validation loss: 2.1858130526799027

Epoch: 5| Step: 7
Training loss: 2.482013702392578
Validation loss: 2.160369444918889

Epoch: 5| Step: 8
Training loss: 2.795490026473999
Validation loss: 2.121466573848519

Epoch: 5| Step: 9
Training loss: 1.3879919052124023
Validation loss: 2.107174269614681

Epoch: 5| Step: 10
Training loss: 2.721822500228882
Validation loss: 2.1196230867857575

Epoch: 150| Step: 0
Training loss: 2.4008114337921143
Validation loss: 2.157638221658686

Epoch: 5| Step: 1
Training loss: 2.4902994632720947
Validation loss: 2.1666975841727307

Epoch: 5| Step: 2
Training loss: 2.2133572101593018
Validation loss: 2.1518952538890224

Epoch: 5| Step: 3
Training loss: 2.5830636024475098
Validation loss: 2.1552731452449674

Epoch: 5| Step: 4
Training loss: 1.7763612270355225
Validation loss: 2.1566873083832445

Epoch: 5| Step: 5
Training loss: 1.1992955207824707
Validation loss: 2.1622033298656507

Epoch: 5| Step: 6
Training loss: 2.188173770904541
Validation loss: 2.1435804520883868

Epoch: 5| Step: 7
Training loss: 3.0911686420440674
Validation loss: 2.1364011802980976

Epoch: 5| Step: 8
Training loss: 2.4544224739074707
Validation loss: 2.1477481908695673

Epoch: 5| Step: 9
Training loss: 2.902395725250244
Validation loss: 2.1442680692160003

Epoch: 5| Step: 10
Training loss: 2.4484312534332275
Validation loss: 2.143817422210529

Epoch: 151| Step: 0
Training loss: 2.238722562789917
Validation loss: 2.1314651632821686

Epoch: 5| Step: 1
Training loss: 2.071279525756836
Validation loss: 2.133385089135939

Epoch: 5| Step: 2
Training loss: 2.364074230194092
Validation loss: 2.1129246014420704

Epoch: 5| Step: 3
Training loss: 2.7327988147735596
Validation loss: 2.119665591947494

Epoch: 5| Step: 4
Training loss: 2.0904107093811035
Validation loss: 2.1207498888815604

Epoch: 5| Step: 5
Training loss: 1.5145868062973022
Validation loss: 2.1658646573302565

Epoch: 5| Step: 6
Training loss: 2.6325926780700684
Validation loss: 2.204329752152966

Epoch: 5| Step: 7
Training loss: 2.6114449501037598
Validation loss: 2.234714379874609

Epoch: 5| Step: 8
Training loss: 2.631863832473755
Validation loss: 2.235300817797261

Epoch: 5| Step: 9
Training loss: 2.2123141288757324
Validation loss: 2.1735367467326503

Epoch: 5| Step: 10
Training loss: 2.6274526119232178
Validation loss: 2.139493303914224

Epoch: 152| Step: 0
Training loss: 2.306849241256714
Validation loss: 2.1288046785580215

Epoch: 5| Step: 1
Training loss: 2.530770778656006
Validation loss: 2.1370918173943796

Epoch: 5| Step: 2
Training loss: 1.8502260446548462
Validation loss: 2.12406083332595

Epoch: 5| Step: 3
Training loss: 2.1556403636932373
Validation loss: 2.126743911415018

Epoch: 5| Step: 4
Training loss: 1.7567460536956787
Validation loss: 2.109216026080552

Epoch: 5| Step: 5
Training loss: 2.7870259284973145
Validation loss: 2.088559196841332

Epoch: 5| Step: 6
Training loss: 2.1486945152282715
Validation loss: 2.0916606854367

Epoch: 5| Step: 7
Training loss: 2.7014877796173096
Validation loss: 2.121787753156436

Epoch: 5| Step: 8
Training loss: 2.7622323036193848
Validation loss: 2.165303632777224

Epoch: 5| Step: 9
Training loss: 2.897263288497925
Validation loss: 2.1972475128789104

Epoch: 5| Step: 10
Training loss: 2.280363082885742
Validation loss: 2.208875245945428

Epoch: 153| Step: 0
Training loss: 2.771597385406494
Validation loss: 2.1943562543520363

Epoch: 5| Step: 1
Training loss: 2.0194544792175293
Validation loss: 2.1607552959072973

Epoch: 5| Step: 2
Training loss: 2.481269359588623
Validation loss: 2.117409852243239

Epoch: 5| Step: 3
Training loss: 2.15077543258667
Validation loss: 2.090587523675734

Epoch: 5| Step: 4
Training loss: 2.8057498931884766
Validation loss: 2.078551838474889

Epoch: 5| Step: 5
Training loss: 2.122086763381958
Validation loss: 2.0831537015976442

Epoch: 5| Step: 6
Training loss: 2.8234825134277344
Validation loss: 2.089164072467435

Epoch: 5| Step: 7
Training loss: 2.6649703979492188
Validation loss: 2.104877838524439

Epoch: 5| Step: 8
Training loss: 2.096073627471924
Validation loss: 2.120303874374718

Epoch: 5| Step: 9
Training loss: 2.0134503841400146
Validation loss: 2.1285003821055093

Epoch: 5| Step: 10
Training loss: 1.7873750925064087
Validation loss: 2.124825977510022

Epoch: 154| Step: 0
Training loss: 1.8697073459625244
Validation loss: 2.1272079124245593

Epoch: 5| Step: 1
Training loss: 2.4120984077453613
Validation loss: 2.1356110188268844

Epoch: 5| Step: 2
Training loss: 2.135618209838867
Validation loss: 2.1508025764137186

Epoch: 5| Step: 3
Training loss: 2.33685564994812
Validation loss: 2.151360780962052

Epoch: 5| Step: 4
Training loss: 3.2447991371154785
Validation loss: 2.158780080015941

Epoch: 5| Step: 5
Training loss: 2.520709276199341
Validation loss: 2.1655568076718237

Epoch: 5| Step: 6
Training loss: 2.031981945037842
Validation loss: 2.1674829426632134

Epoch: 5| Step: 7
Training loss: 2.018021821975708
Validation loss: 2.183825704359239

Epoch: 5| Step: 8
Training loss: 2.270416736602783
Validation loss: 2.2381759228244906

Epoch: 5| Step: 9
Training loss: 2.388566732406616
Validation loss: 2.2138561843543925

Epoch: 5| Step: 10
Training loss: 2.299368381500244
Validation loss: 2.1883253410298336

Epoch: 155| Step: 0
Training loss: 2.3078954219818115
Validation loss: 2.1574238256741594

Epoch: 5| Step: 1
Training loss: 2.5229578018188477
Validation loss: 2.1406103257210023

Epoch: 5| Step: 2
Training loss: 1.727046251296997
Validation loss: 2.1296792671244633

Epoch: 5| Step: 3
Training loss: 2.275481700897217
Validation loss: 2.1421826411319036

Epoch: 5| Step: 4
Training loss: 2.3288352489471436
Validation loss: 2.1727724716227543

Epoch: 5| Step: 5
Training loss: 1.9712207317352295
Validation loss: 2.1452101097312024

Epoch: 5| Step: 6
Training loss: 2.6432042121887207
Validation loss: 2.146733308351168

Epoch: 5| Step: 7
Training loss: 2.400524854660034
Validation loss: 2.1190617366503646

Epoch: 5| Step: 8
Training loss: 2.6403093338012695
Validation loss: 2.1114197238799064

Epoch: 5| Step: 9
Training loss: 2.210235357284546
Validation loss: 2.1211864384271766

Epoch: 5| Step: 10
Training loss: 2.7139134407043457
Validation loss: 2.10761655786986

Epoch: 156| Step: 0
Training loss: 2.1097309589385986
Validation loss: 2.13360115661416

Epoch: 5| Step: 1
Training loss: 1.8489587306976318
Validation loss: 2.1661135573540964

Epoch: 5| Step: 2
Training loss: 2.2691633701324463
Validation loss: 2.1911909913503997

Epoch: 5| Step: 3
Training loss: 2.1737985610961914
Validation loss: 2.186664806899204

Epoch: 5| Step: 4
Training loss: 2.711578845977783
Validation loss: 2.175697498424079

Epoch: 5| Step: 5
Training loss: 1.8737258911132812
Validation loss: 2.1674771462717364

Epoch: 5| Step: 6
Training loss: 2.245147466659546
Validation loss: 2.1638315646879134

Epoch: 5| Step: 7
Training loss: 2.717726707458496
Validation loss: 2.171882026938982

Epoch: 5| Step: 8
Training loss: 2.6454195976257324
Validation loss: 2.2007520609004523

Epoch: 5| Step: 9
Training loss: 2.499276638031006
Validation loss: 2.2145019987578034

Epoch: 5| Step: 10
Training loss: 2.391141891479492
Validation loss: 2.1889401097451486

Epoch: 157| Step: 0
Training loss: 3.2012970447540283
Validation loss: 2.141832467048399

Epoch: 5| Step: 1
Training loss: 2.4709839820861816
Validation loss: 2.142308076222738

Epoch: 5| Step: 2
Training loss: 2.1257846355438232
Validation loss: 2.1313673398827993

Epoch: 5| Step: 3
Training loss: 1.875502347946167
Validation loss: 2.1139739674906575

Epoch: 5| Step: 4
Training loss: 2.6431798934936523
Validation loss: 2.113550219484555

Epoch: 5| Step: 5
Training loss: 2.105374813079834
Validation loss: 2.106952980000486

Epoch: 5| Step: 6
Training loss: 2.229640245437622
Validation loss: 2.1101841439482985

Epoch: 5| Step: 7
Training loss: 2.184483051300049
Validation loss: 2.0915859796667613

Epoch: 5| Step: 8
Training loss: 2.3870677947998047
Validation loss: 2.1036813438579602

Epoch: 5| Step: 9
Training loss: 2.239466905593872
Validation loss: 2.1116469060221026

Epoch: 5| Step: 10
Training loss: 1.7688589096069336
Validation loss: 2.1393161435281076

Epoch: 158| Step: 0
Training loss: 2.4020233154296875
Validation loss: 2.1528199680389895

Epoch: 5| Step: 1
Training loss: 1.8035099506378174
Validation loss: 2.1477039629413235

Epoch: 5| Step: 2
Training loss: 2.683354616165161
Validation loss: 2.1665792644664807

Epoch: 5| Step: 3
Training loss: 2.297593116760254
Validation loss: 2.196328857893585

Epoch: 5| Step: 4
Training loss: 2.338489055633545
Validation loss: 2.2407733060980357

Epoch: 5| Step: 5
Training loss: 1.9165165424346924
Validation loss: 2.2516646026283182

Epoch: 5| Step: 6
Training loss: 2.5002405643463135
Validation loss: 2.245632319040196

Epoch: 5| Step: 7
Training loss: 2.5900325775146484
Validation loss: 2.216907544802594

Epoch: 5| Step: 8
Training loss: 2.298274517059326
Validation loss: 2.1707489567418254

Epoch: 5| Step: 9
Training loss: 2.207834482192993
Validation loss: 2.1618336631405737

Epoch: 5| Step: 10
Training loss: 2.296689987182617
Validation loss: 2.131899195332681

Epoch: 159| Step: 0
Training loss: 2.3310599327087402
Validation loss: 2.1215842757173764

Epoch: 5| Step: 1
Training loss: 2.3775150775909424
Validation loss: 2.0961863379324637

Epoch: 5| Step: 2
Training loss: 2.163931369781494
Validation loss: 2.0855827254633748

Epoch: 5| Step: 3
Training loss: 2.210005283355713
Validation loss: 2.120973126862639

Epoch: 5| Step: 4
Training loss: 2.277303695678711
Validation loss: 2.162492903329993

Epoch: 5| Step: 5
Training loss: 2.1666150093078613
Validation loss: 2.17817928970501

Epoch: 5| Step: 6
Training loss: 2.097292423248291
Validation loss: 2.1658589737389677

Epoch: 5| Step: 7
Training loss: 2.259504795074463
Validation loss: 2.1145961656365344

Epoch: 5| Step: 8
Training loss: 2.494192123413086
Validation loss: 2.0833859930756273

Epoch: 5| Step: 9
Training loss: 2.253866672515869
Validation loss: 2.074876158468185

Epoch: 5| Step: 10
Training loss: 2.799769401550293
Validation loss: 2.090527944667365

Epoch: 160| Step: 0
Training loss: 1.8610347509384155
Validation loss: 2.096042799693282

Epoch: 5| Step: 1
Training loss: 2.3190345764160156
Validation loss: 2.092362780724802

Epoch: 5| Step: 2
Training loss: 2.4513797760009766
Validation loss: 2.1053696601621565

Epoch: 5| Step: 3
Training loss: 2.5787620544433594
Validation loss: 2.093078315898936

Epoch: 5| Step: 4
Training loss: 2.279790163040161
Validation loss: 2.1204089118588354

Epoch: 5| Step: 5
Training loss: 1.865112543106079
Validation loss: 2.153044428876651

Epoch: 5| Step: 6
Training loss: 2.394258975982666
Validation loss: 2.172517937998618

Epoch: 5| Step: 7
Training loss: 2.8438479900360107
Validation loss: 2.1992723531620477

Epoch: 5| Step: 8
Training loss: 1.9119958877563477
Validation loss: 2.1760353170415407

Epoch: 5| Step: 9
Training loss: 2.155303478240967
Validation loss: 2.1623587685246624

Epoch: 5| Step: 10
Training loss: 2.722410202026367
Validation loss: 2.1392542777522916

Epoch: 161| Step: 0
Training loss: 2.1379284858703613
Validation loss: 2.132898857516627

Epoch: 5| Step: 1
Training loss: 2.3061771392822266
Validation loss: 2.1260928620574293

Epoch: 5| Step: 2
Training loss: 2.181520938873291
Validation loss: 2.1245534214922177

Epoch: 5| Step: 3
Training loss: 2.0876355171203613
Validation loss: 2.132757653472244

Epoch: 5| Step: 4
Training loss: 2.2334465980529785
Validation loss: 2.1320057530556955

Epoch: 5| Step: 5
Training loss: 2.7691519260406494
Validation loss: 2.145431322436179

Epoch: 5| Step: 6
Training loss: 1.4114209413528442
Validation loss: 2.1564802815837245

Epoch: 5| Step: 7
Training loss: 2.7775206565856934
Validation loss: 2.146211962546072

Epoch: 5| Step: 8
Training loss: 2.082139015197754
Validation loss: 2.159387303936866

Epoch: 5| Step: 9
Training loss: 2.709264039993286
Validation loss: 2.1416503280721684

Epoch: 5| Step: 10
Training loss: 1.9413777589797974
Validation loss: 2.15293619196902

Epoch: 162| Step: 0
Training loss: 2.655905246734619
Validation loss: 2.143381469993181

Epoch: 5| Step: 1
Training loss: 3.0444564819335938
Validation loss: 2.119670893556328

Epoch: 5| Step: 2
Training loss: 1.7540655136108398
Validation loss: 2.1122103365518714

Epoch: 5| Step: 3
Training loss: 1.622053861618042
Validation loss: 2.1291441763600996

Epoch: 5| Step: 4
Training loss: 2.38865327835083
Validation loss: 2.1544424897880963

Epoch: 5| Step: 5
Training loss: 2.9898266792297363
Validation loss: 2.1561022676447386

Epoch: 5| Step: 6
Training loss: 2.0175068378448486
Validation loss: 2.1362390223369805

Epoch: 5| Step: 7
Training loss: 2.2520079612731934
Validation loss: 2.12509717992557

Epoch: 5| Step: 8
Training loss: 1.663901686668396
Validation loss: 2.132456882025606

Epoch: 5| Step: 9
Training loss: 2.3859682083129883
Validation loss: 2.142484267552694

Epoch: 5| Step: 10
Training loss: 1.6619958877563477
Validation loss: 2.125456502360682

Epoch: 163| Step: 0
Training loss: 1.8109350204467773
Validation loss: 2.132920406197989

Epoch: 5| Step: 1
Training loss: 2.205012083053589
Validation loss: 2.1363048579103205

Epoch: 5| Step: 2
Training loss: 2.835069179534912
Validation loss: 2.154409179123499

Epoch: 5| Step: 3
Training loss: 2.4813015460968018
Validation loss: 2.143383938779113

Epoch: 5| Step: 4
Training loss: 2.5221023559570312
Validation loss: 2.08977533155872

Epoch: 5| Step: 5
Training loss: 2.0853359699249268
Validation loss: 2.083189574621057

Epoch: 5| Step: 6
Training loss: 1.8836971521377563
Validation loss: 2.088118868489419

Epoch: 5| Step: 7
Training loss: 2.36008358001709
Validation loss: 2.0931614855284333

Epoch: 5| Step: 8
Training loss: 2.080977201461792
Validation loss: 2.1049461287836873

Epoch: 5| Step: 9
Training loss: 2.0085747241973877
Validation loss: 2.133656750443161

Epoch: 5| Step: 10
Training loss: 2.081328868865967
Validation loss: 2.1560641437448482

Epoch: 164| Step: 0
Training loss: 2.285546064376831
Validation loss: 2.170412717326995

Epoch: 5| Step: 1
Training loss: 2.088137149810791
Validation loss: 2.127555239585138

Epoch: 5| Step: 2
Training loss: 2.126298666000366
Validation loss: 2.1401633062670307

Epoch: 5| Step: 3
Training loss: 2.426039934158325
Validation loss: 2.1251683235168457

Epoch: 5| Step: 4
Training loss: 2.4634811878204346
Validation loss: 2.1383080867029007

Epoch: 5| Step: 5
Training loss: 2.1654133796691895
Validation loss: 2.1484854708435717

Epoch: 5| Step: 6
Training loss: 2.315370559692383
Validation loss: 2.138283796207879

Epoch: 5| Step: 7
Training loss: 2.068708896636963
Validation loss: 2.156440573353921

Epoch: 5| Step: 8
Training loss: 1.9425910711288452
Validation loss: 2.163132116358767

Epoch: 5| Step: 9
Training loss: 2.4561972618103027
Validation loss: 2.1393252957251763

Epoch: 5| Step: 10
Training loss: 2.0389270782470703
Validation loss: 2.099027572139617

Epoch: 165| Step: 0
Training loss: 2.4043760299682617
Validation loss: 2.07520826144885

Epoch: 5| Step: 1
Training loss: 2.0340139865875244
Validation loss: 2.0624278694070797

Epoch: 5| Step: 2
Training loss: 2.2660772800445557
Validation loss: 2.0704779894121232

Epoch: 5| Step: 3
Training loss: 2.569861888885498
Validation loss: 2.0611174850053686

Epoch: 5| Step: 4
Training loss: 2.1307356357574463
Validation loss: 2.067851251171481

Epoch: 5| Step: 5
Training loss: 2.2638626098632812
Validation loss: 2.0496433422129643

Epoch: 5| Step: 6
Training loss: 1.7774940729141235
Validation loss: 2.0798907767059984

Epoch: 5| Step: 7
Training loss: 2.54348087310791
Validation loss: 2.094438927147978

Epoch: 5| Step: 8
Training loss: 1.822662353515625
Validation loss: 2.1091882028887348

Epoch: 5| Step: 9
Training loss: 2.577348232269287
Validation loss: 2.102846837812854

Epoch: 5| Step: 10
Training loss: 1.9557048082351685
Validation loss: 2.0858906469037457

Epoch: 166| Step: 0
Training loss: 1.6243884563446045
Validation loss: 2.0783515386683966

Epoch: 5| Step: 1
Training loss: 2.471407413482666
Validation loss: 2.0996316850826306

Epoch: 5| Step: 2
Training loss: 2.6500372886657715
Validation loss: 2.105749835250198

Epoch: 5| Step: 3
Training loss: 2.097161293029785
Validation loss: 2.127960599878783

Epoch: 5| Step: 4
Training loss: 2.2802765369415283
Validation loss: 2.1103925089682303

Epoch: 5| Step: 5
Training loss: 2.3080358505249023
Validation loss: 2.1190772876944592

Epoch: 5| Step: 6
Training loss: 1.655595064163208
Validation loss: 2.150207104221467

Epoch: 5| Step: 7
Training loss: 2.467014789581299
Validation loss: 2.187588027728501

Epoch: 5| Step: 8
Training loss: 1.4494431018829346
Validation loss: 2.1442818872390257

Epoch: 5| Step: 9
Training loss: 2.9737000465393066
Validation loss: 2.109661130494969

Epoch: 5| Step: 10
Training loss: 1.945194959640503
Validation loss: 2.0757031722735335

Epoch: 167| Step: 0
Training loss: 2.277101755142212
Validation loss: 2.0619838532581123

Epoch: 5| Step: 1
Training loss: 1.3702479600906372
Validation loss: 2.0675955741636214

Epoch: 5| Step: 2
Training loss: 1.7386369705200195
Validation loss: 2.0550731869154077

Epoch: 5| Step: 3
Training loss: 1.5568767786026
Validation loss: 2.0505194587092244

Epoch: 5| Step: 4
Training loss: 2.4640374183654785
Validation loss: 2.0556592364465036

Epoch: 5| Step: 5
Training loss: 2.5612847805023193
Validation loss: 2.1022228540912753

Epoch: 5| Step: 6
Training loss: 2.6360442638397217
Validation loss: 2.141130289723796

Epoch: 5| Step: 7
Training loss: 2.494908094406128
Validation loss: 2.181131342405914

Epoch: 5| Step: 8
Training loss: 2.4236934185028076
Validation loss: 2.175613116192561

Epoch: 5| Step: 9
Training loss: 2.2011263370513916
Validation loss: 2.14929473528298

Epoch: 5| Step: 10
Training loss: 2.7352399826049805
Validation loss: 2.1241846276867773

Epoch: 168| Step: 0
Training loss: 2.4198110103607178
Validation loss: 2.1603126166969218

Epoch: 5| Step: 1
Training loss: 2.3490090370178223
Validation loss: 2.184705585561773

Epoch: 5| Step: 2
Training loss: 2.6204636096954346
Validation loss: 2.1945953010230936

Epoch: 5| Step: 3
Training loss: 1.8456941843032837
Validation loss: 2.1795014847991285

Epoch: 5| Step: 4
Training loss: 1.6959419250488281
Validation loss: 2.1395596022246988

Epoch: 5| Step: 5
Training loss: 2.1818203926086426
Validation loss: 2.0993554989496865

Epoch: 5| Step: 6
Training loss: 2.448276996612549
Validation loss: 2.114532389948445

Epoch: 5| Step: 7
Training loss: 2.1520140171051025
Validation loss: 2.0870485510877383

Epoch: 5| Step: 8
Training loss: 2.1808438301086426
Validation loss: 2.091407314423592

Epoch: 5| Step: 9
Training loss: 2.4293720722198486
Validation loss: 2.118799255740258

Epoch: 5| Step: 10
Training loss: 2.0992486476898193
Validation loss: 2.115931726271106

Epoch: 169| Step: 0
Training loss: 1.7202867269515991
Validation loss: 2.0950399778222524

Epoch: 5| Step: 1
Training loss: 1.7234036922454834
Validation loss: 2.0816904267957135

Epoch: 5| Step: 2
Training loss: 2.49737811088562
Validation loss: 2.067839930134435

Epoch: 5| Step: 3
Training loss: 2.4610893726348877
Validation loss: 2.0537666569473925

Epoch: 5| Step: 4
Training loss: 2.385490894317627
Validation loss: 2.066412874447402

Epoch: 5| Step: 5
Training loss: 1.9845718145370483
Validation loss: 2.078962015849288

Epoch: 5| Step: 6
Training loss: 1.7488300800323486
Validation loss: 2.106923013605097

Epoch: 5| Step: 7
Training loss: 3.0016613006591797
Validation loss: 2.1281098255547146

Epoch: 5| Step: 8
Training loss: 2.6938397884368896
Validation loss: 2.1181602708755003

Epoch: 5| Step: 9
Training loss: 1.51814603805542
Validation loss: 2.128300489917878

Epoch: 5| Step: 10
Training loss: 2.2474191188812256
Validation loss: 2.1225512540468605

Epoch: 170| Step: 0
Training loss: 2.311554431915283
Validation loss: 2.116509614452239

Epoch: 5| Step: 1
Training loss: 1.9522380828857422
Validation loss: 2.0951552391052246

Epoch: 5| Step: 2
Training loss: 2.448312520980835
Validation loss: 2.1075986841673493

Epoch: 5| Step: 3
Training loss: 1.7795770168304443
Validation loss: 2.1038913778079453

Epoch: 5| Step: 4
Training loss: 1.7675437927246094
Validation loss: 2.1228581628491803

Epoch: 5| Step: 5
Training loss: 1.7557742595672607
Validation loss: 2.1142127103702997

Epoch: 5| Step: 6
Training loss: 2.1281943321228027
Validation loss: 2.12110794872366

Epoch: 5| Step: 7
Training loss: 2.8953168392181396
Validation loss: 2.114913877620492

Epoch: 5| Step: 8
Training loss: 2.013807535171509
Validation loss: 2.087583416251726

Epoch: 5| Step: 9
Training loss: 2.0891003608703613
Validation loss: 2.079842000879267

Epoch: 5| Step: 10
Training loss: 2.5378262996673584
Validation loss: 2.0621289053270893

Epoch: 171| Step: 0
Training loss: 2.397394895553589
Validation loss: 2.0577016338225333

Epoch: 5| Step: 1
Training loss: 2.1843905448913574
Validation loss: 2.0527916800591255

Epoch: 5| Step: 2
Training loss: 2.2943949699401855
Validation loss: 2.0291165203176518

Epoch: 5| Step: 3
Training loss: 2.0145554542541504
Validation loss: 2.049037984622422

Epoch: 5| Step: 4
Training loss: 1.7606102228164673
Validation loss: 2.0743195292770222

Epoch: 5| Step: 5
Training loss: 1.791235327720642
Validation loss: 2.1036872915042344

Epoch: 5| Step: 6
Training loss: 2.6558899879455566
Validation loss: 2.1220326731281896

Epoch: 5| Step: 7
Training loss: 2.3322982788085938
Validation loss: 2.1026604406295286

Epoch: 5| Step: 8
Training loss: 1.8085238933563232
Validation loss: 2.135380503951862

Epoch: 5| Step: 9
Training loss: 1.8970615863800049
Validation loss: 2.125576698651878

Epoch: 5| Step: 10
Training loss: 2.4582836627960205
Validation loss: 2.1360582843903573

Epoch: 172| Step: 0
Training loss: 1.6265166997909546
Validation loss: 2.093477140190781

Epoch: 5| Step: 1
Training loss: 2.282289981842041
Validation loss: 2.0782700918054067

Epoch: 5| Step: 2
Training loss: 2.3909032344818115
Validation loss: 2.057547225747057

Epoch: 5| Step: 3
Training loss: 1.592228651046753
Validation loss: 2.059285512534521

Epoch: 5| Step: 4
Training loss: 2.106055736541748
Validation loss: 2.0672379437313286

Epoch: 5| Step: 5
Training loss: 2.6581504344940186
Validation loss: 2.0944846804423998

Epoch: 5| Step: 6
Training loss: 2.2206084728240967
Validation loss: 2.102528948937693

Epoch: 5| Step: 7
Training loss: 2.1910817623138428
Validation loss: 2.1184416714534966

Epoch: 5| Step: 8
Training loss: 2.163893222808838
Validation loss: 2.1503920939660843

Epoch: 5| Step: 9
Training loss: 2.108942985534668
Validation loss: 2.1537850082561536

Epoch: 5| Step: 10
Training loss: 1.902215838432312
Validation loss: 2.1602570523497877

Epoch: 173| Step: 0
Training loss: 1.5327117443084717
Validation loss: 2.1464081605275473

Epoch: 5| Step: 1
Training loss: 2.5384395122528076
Validation loss: 2.1493886260576147

Epoch: 5| Step: 2
Training loss: 2.0607247352600098
Validation loss: 2.1266399275872017

Epoch: 5| Step: 3
Training loss: 1.5018759965896606
Validation loss: 2.129629724769182

Epoch: 5| Step: 4
Training loss: 2.2118966579437256
Validation loss: 2.162399157401054

Epoch: 5| Step: 5
Training loss: 2.1720592975616455
Validation loss: 2.138791871327226

Epoch: 5| Step: 6
Training loss: 2.9064691066741943
Validation loss: 2.1490530403711463

Epoch: 5| Step: 7
Training loss: 1.5250250101089478
Validation loss: 2.095952714643171

Epoch: 5| Step: 8
Training loss: 2.357454538345337
Validation loss: 2.0657713695238997

Epoch: 5| Step: 9
Training loss: 2.4429259300231934
Validation loss: 2.045231303861064

Epoch: 5| Step: 10
Training loss: 1.925269603729248
Validation loss: 2.048694190158639

Epoch: 174| Step: 0
Training loss: 2.5277202129364014
Validation loss: 2.0468476844090286

Epoch: 5| Step: 1
Training loss: 2.0083322525024414
Validation loss: 2.0301375927463656

Epoch: 5| Step: 2
Training loss: 1.7354637384414673
Validation loss: 2.054008856896431

Epoch: 5| Step: 3
Training loss: 2.0181174278259277
Validation loss: 2.080365768042944

Epoch: 5| Step: 4
Training loss: 2.176457166671753
Validation loss: 2.1452935664884505

Epoch: 5| Step: 5
Training loss: 2.5240015983581543
Validation loss: 2.2133757452810965

Epoch: 5| Step: 6
Training loss: 1.9647767543792725
Validation loss: 2.1809409356886342

Epoch: 5| Step: 7
Training loss: 1.4981420040130615
Validation loss: 2.081077660283735

Epoch: 5| Step: 8
Training loss: 2.3613815307617188
Validation loss: 2.069102338565293

Epoch: 5| Step: 9
Training loss: 2.422887086868286
Validation loss: 2.0754435703318608

Epoch: 5| Step: 10
Training loss: 2.6561450958251953
Validation loss: 2.0642466852741856

Epoch: 175| Step: 0
Training loss: 2.6607112884521484
Validation loss: 2.063927423569464

Epoch: 5| Step: 1
Training loss: 2.915637493133545
Validation loss: 2.062153175312986

Epoch: 5| Step: 2
Training loss: 1.5720092058181763
Validation loss: 2.0991462969010874

Epoch: 5| Step: 3
Training loss: 2.4640979766845703
Validation loss: 2.1666762111007527

Epoch: 5| Step: 4
Training loss: 2.4361929893493652
Validation loss: 2.1920492520896335

Epoch: 5| Step: 5
Training loss: 1.7036793231964111
Validation loss: 2.1427001889033983

Epoch: 5| Step: 6
Training loss: 1.3227828741073608
Validation loss: 2.054512898127238

Epoch: 5| Step: 7
Training loss: 2.7171759605407715
Validation loss: 2.037950461910617

Epoch: 5| Step: 8
Training loss: 1.4482190608978271
Validation loss: 2.0349901747959915

Epoch: 5| Step: 9
Training loss: 2.366946220397949
Validation loss: 2.035855234310191

Epoch: 5| Step: 10
Training loss: 2.1631977558135986
Validation loss: 2.0320957886275424

Epoch: 176| Step: 0
Training loss: 1.9213674068450928
Validation loss: 2.016828701060305

Epoch: 5| Step: 1
Training loss: 1.5416619777679443
Validation loss: 2.050871226095384

Epoch: 5| Step: 2
Training loss: 2.3529789447784424
Validation loss: 2.065311460084813

Epoch: 5| Step: 3
Training loss: 1.4831254482269287
Validation loss: 2.088083173639031

Epoch: 5| Step: 4
Training loss: 2.4001073837280273
Validation loss: 2.0900419771030383

Epoch: 5| Step: 5
Training loss: 2.0699267387390137
Validation loss: 2.0945486227671304

Epoch: 5| Step: 6
Training loss: 2.049062967300415
Validation loss: 2.1242388576589604

Epoch: 5| Step: 7
Training loss: 2.6742706298828125
Validation loss: 2.1214451302764235

Epoch: 5| Step: 8
Training loss: 2.366672992706299
Validation loss: 2.0978802455368863

Epoch: 5| Step: 9
Training loss: 2.828108310699463
Validation loss: 2.0942236915711434

Epoch: 5| Step: 10
Training loss: 1.3442513942718506
Validation loss: 2.070538633613176

Epoch: 177| Step: 0
Training loss: 2.420443534851074
Validation loss: 2.065739767525786

Epoch: 5| Step: 1
Training loss: 2.359802007675171
Validation loss: 2.063825980309517

Epoch: 5| Step: 2
Training loss: 2.286188840866089
Validation loss: 2.066860014392484

Epoch: 5| Step: 3
Training loss: 2.194946527481079
Validation loss: 2.0574494907932896

Epoch: 5| Step: 4
Training loss: 1.7707363367080688
Validation loss: 2.0519236621036323

Epoch: 5| Step: 5
Training loss: 1.8254581689834595
Validation loss: 2.0732691608449465

Epoch: 5| Step: 6
Training loss: 1.4789637327194214
Validation loss: 2.083218166905065

Epoch: 5| Step: 7
Training loss: 2.466578483581543
Validation loss: 2.0803716131435928

Epoch: 5| Step: 8
Training loss: 1.9642757177352905
Validation loss: 2.0695647719085857

Epoch: 5| Step: 9
Training loss: 2.149559497833252
Validation loss: 2.0763901202909407

Epoch: 5| Step: 10
Training loss: 1.9570869207382202
Validation loss: 2.1111399383955103

Epoch: 178| Step: 0
Training loss: 1.5727039575576782
Validation loss: 2.117510462319979

Epoch: 5| Step: 1
Training loss: 2.3159894943237305
Validation loss: 2.148192697955716

Epoch: 5| Step: 2
Training loss: 1.8229097127914429
Validation loss: 2.145450839432337

Epoch: 5| Step: 3
Training loss: 2.0318527221679688
Validation loss: 2.1483461959387666

Epoch: 5| Step: 4
Training loss: 2.0823562145233154
Validation loss: 2.1553567506933726

Epoch: 5| Step: 5
Training loss: 2.0959155559539795
Validation loss: 2.192642834878737

Epoch: 5| Step: 6
Training loss: 1.9031744003295898
Validation loss: 2.1726655421718473

Epoch: 5| Step: 7
Training loss: 2.478001117706299
Validation loss: 2.146327487884029

Epoch: 5| Step: 8
Training loss: 1.7976741790771484
Validation loss: 2.1152074362642024

Epoch: 5| Step: 9
Training loss: 2.140125036239624
Validation loss: 2.0916214963441253

Epoch: 5| Step: 10
Training loss: 2.4636244773864746
Validation loss: 2.040723967295821

Epoch: 179| Step: 0
Training loss: 2.2508187294006348
Validation loss: 2.060706136047199

Epoch: 5| Step: 1
Training loss: 2.305817127227783
Validation loss: 2.0747331470571537

Epoch: 5| Step: 2
Training loss: 1.8758589029312134
Validation loss: 2.058229930939213

Epoch: 5| Step: 3
Training loss: 2.43876314163208
Validation loss: 2.030109715718095

Epoch: 5| Step: 4
Training loss: 2.024700880050659
Validation loss: 2.017887553861064

Epoch: 5| Step: 5
Training loss: 1.8690516948699951
Validation loss: 2.0329783219163136

Epoch: 5| Step: 6
Training loss: 1.7468668222427368
Validation loss: 2.071591700277021

Epoch: 5| Step: 7
Training loss: 2.411083936691284
Validation loss: 2.120957669391427

Epoch: 5| Step: 8
Training loss: 1.9456634521484375
Validation loss: 2.129240030883461

Epoch: 5| Step: 9
Training loss: 2.4643170833587646
Validation loss: 2.14016289992999

Epoch: 5| Step: 10
Training loss: 1.8989802598953247
Validation loss: 2.138873261790122

Epoch: 180| Step: 0
Training loss: 2.6168084144592285
Validation loss: 2.0930873706776607

Epoch: 5| Step: 1
Training loss: 1.462929368019104
Validation loss: 2.0349198810515867

Epoch: 5| Step: 2
Training loss: 2.3241512775421143
Validation loss: 2.0543803450881795

Epoch: 5| Step: 3
Training loss: 2.077671527862549
Validation loss: 2.053778253575807

Epoch: 5| Step: 4
Training loss: 2.1135177612304688
Validation loss: 2.0582336379635717

Epoch: 5| Step: 5
Training loss: 1.849782943725586
Validation loss: 2.0706798466303016

Epoch: 5| Step: 6
Training loss: 1.7944892644882202
Validation loss: 2.079163602603379

Epoch: 5| Step: 7
Training loss: 2.26751971244812
Validation loss: 2.084881128803376

Epoch: 5| Step: 8
Training loss: 2.277038812637329
Validation loss: 2.1367398526078913

Epoch: 5| Step: 9
Training loss: 2.150728940963745
Validation loss: 2.1802171558462162

Epoch: 5| Step: 10
Training loss: 1.5429108142852783
Validation loss: 2.2094557669854935

Epoch: 181| Step: 0
Training loss: 1.8625282049179077
Validation loss: 2.1892255044752553

Epoch: 5| Step: 1
Training loss: 1.897385835647583
Validation loss: 2.133814496378745

Epoch: 5| Step: 2
Training loss: 2.045980453491211
Validation loss: 2.078850843573129

Epoch: 5| Step: 3
Training loss: 1.6808964014053345
Validation loss: 2.0807194530322985

Epoch: 5| Step: 4
Training loss: 2.4366629123687744
Validation loss: 2.0582986211264007

Epoch: 5| Step: 5
Training loss: 2.065174102783203
Validation loss: 2.0745031961830716

Epoch: 5| Step: 6
Training loss: 1.8965599536895752
Validation loss: 2.0922076599572295

Epoch: 5| Step: 7
Training loss: 2.179340362548828
Validation loss: 2.1047346758586105

Epoch: 5| Step: 8
Training loss: 2.066556930541992
Validation loss: 2.116278717594762

Epoch: 5| Step: 9
Training loss: 2.211667537689209
Validation loss: 2.111246988337527

Epoch: 5| Step: 10
Training loss: 2.353705644607544
Validation loss: 2.1008423041271906

Epoch: 182| Step: 0
Training loss: 2.0751938819885254
Validation loss: 2.129532188497564

Epoch: 5| Step: 1
Training loss: 2.5685017108917236
Validation loss: 2.125640574321952

Epoch: 5| Step: 2
Training loss: 2.4042534828186035
Validation loss: 2.145111979976777

Epoch: 5| Step: 3
Training loss: 1.3631253242492676
Validation loss: 2.1569534911904285

Epoch: 5| Step: 4
Training loss: 1.8044910430908203
Validation loss: 2.1289684490490983

Epoch: 5| Step: 5
Training loss: 1.7940986156463623
Validation loss: 2.139748839921849

Epoch: 5| Step: 6
Training loss: 1.4817520380020142
Validation loss: 2.1082655024784867

Epoch: 5| Step: 7
Training loss: 2.3998496532440186
Validation loss: 2.057599159979051

Epoch: 5| Step: 8
Training loss: 1.8970813751220703
Validation loss: 2.052791218603811

Epoch: 5| Step: 9
Training loss: 2.0149738788604736
Validation loss: 2.0345362463305072

Epoch: 5| Step: 10
Training loss: 2.5151054859161377
Validation loss: 2.027526190204005

Epoch: 183| Step: 0
Training loss: 2.104640007019043
Validation loss: 2.0338441697500085

Epoch: 5| Step: 1
Training loss: 2.3843026161193848
Validation loss: 2.0221412899673625

Epoch: 5| Step: 2
Training loss: 1.381126046180725
Validation loss: 2.0066502222450833

Epoch: 5| Step: 3
Training loss: 2.0588271617889404
Validation loss: 2.006073888911996

Epoch: 5| Step: 4
Training loss: 2.1085312366485596
Validation loss: 2.0190620563363515

Epoch: 5| Step: 5
Training loss: 2.5692667961120605
Validation loss: 2.044408154743974

Epoch: 5| Step: 6
Training loss: 2.0741336345672607
Validation loss: 2.0723082775710733

Epoch: 5| Step: 7
Training loss: 1.3307775259017944
Validation loss: 2.0997995407350603

Epoch: 5| Step: 8
Training loss: 2.0475807189941406
Validation loss: 2.0910093707423054

Epoch: 5| Step: 9
Training loss: 2.33182954788208
Validation loss: 2.09707296791897

Epoch: 5| Step: 10
Training loss: 2.0489466190338135
Validation loss: 2.115744895832513

Epoch: 184| Step: 0
Training loss: 2.0846781730651855
Validation loss: 2.095723316233645

Epoch: 5| Step: 1
Training loss: 2.494659900665283
Validation loss: 2.0781169732411704

Epoch: 5| Step: 2
Training loss: 2.52274751663208
Validation loss: 2.066328766525433

Epoch: 5| Step: 3
Training loss: 1.875430703163147
Validation loss: 2.0195001145844818

Epoch: 5| Step: 4
Training loss: 1.927018404006958
Validation loss: 2.018358740755307

Epoch: 5| Step: 5
Training loss: 2.2092156410217285
Validation loss: 2.031045852168914

Epoch: 5| Step: 6
Training loss: 2.4266719818115234
Validation loss: 2.0321669617006854

Epoch: 5| Step: 7
Training loss: 1.4787862300872803
Validation loss: 2.041009355616826

Epoch: 5| Step: 8
Training loss: 2.030879259109497
Validation loss: 2.0573256810506186

Epoch: 5| Step: 9
Training loss: 1.9209048748016357
Validation loss: 2.1122765720531507

Epoch: 5| Step: 10
Training loss: 1.196454644203186
Validation loss: 2.185346052210818

Epoch: 185| Step: 0
Training loss: 2.1573824882507324
Validation loss: 2.2324196497599282

Epoch: 5| Step: 1
Training loss: 1.6225776672363281
Validation loss: 2.230276741007323

Epoch: 5| Step: 2
Training loss: 1.6811622381210327
Validation loss: 2.1799554517192226

Epoch: 5| Step: 3
Training loss: 2.2347772121429443
Validation loss: 2.123978187960963

Epoch: 5| Step: 4
Training loss: 1.9072768688201904
Validation loss: 2.09075492171831

Epoch: 5| Step: 5
Training loss: 3.2441864013671875
Validation loss: 2.0708392230413293

Epoch: 5| Step: 6
Training loss: 2.0284736156463623
Validation loss: 2.064758808382096

Epoch: 5| Step: 7
Training loss: 2.220790147781372
Validation loss: 2.0589072447951122

Epoch: 5| Step: 8
Training loss: 2.3178791999816895
Validation loss: 2.051577919272966

Epoch: 5| Step: 9
Training loss: 1.693094253540039
Validation loss: 2.031437263693861

Epoch: 5| Step: 10
Training loss: 1.2721847295761108
Validation loss: 2.0351858164674494

Epoch: 186| Step: 0
Training loss: 2.1532740592956543
Validation loss: 2.0307009348305325

Epoch: 5| Step: 1
Training loss: 1.5230895280838013
Validation loss: 2.07383410392269

Epoch: 5| Step: 2
Training loss: 2.0750489234924316
Validation loss: 2.1169874334848053

Epoch: 5| Step: 3
Training loss: 2.5132076740264893
Validation loss: 2.115547587794642

Epoch: 5| Step: 4
Training loss: 2.252596378326416
Validation loss: 2.1287650357010546

Epoch: 5| Step: 5
Training loss: 1.8463255167007446
Validation loss: 2.1047616543308383

Epoch: 5| Step: 6
Training loss: 1.570442795753479
Validation loss: 2.103386216266181

Epoch: 5| Step: 7
Training loss: 1.8680553436279297
Validation loss: 2.0645783767905286

Epoch: 5| Step: 8
Training loss: 2.1509203910827637
Validation loss: 2.064107128368911

Epoch: 5| Step: 9
Training loss: 2.0867793560028076
Validation loss: 2.0865376175090833

Epoch: 5| Step: 10
Training loss: 2.113494396209717
Validation loss: 2.092661460240682

Epoch: 187| Step: 0
Training loss: 2.4758126735687256
Validation loss: 2.0899462084616385

Epoch: 5| Step: 1
Training loss: 2.866438627243042
Validation loss: 2.141857511253767

Epoch: 5| Step: 2
Training loss: 1.4376299381256104
Validation loss: 2.134755548610482

Epoch: 5| Step: 3
Training loss: 1.6439712047576904
Validation loss: 2.1505987823650403

Epoch: 5| Step: 4
Training loss: 2.7151079177856445
Validation loss: 2.121533416932629

Epoch: 5| Step: 5
Training loss: 1.6838464736938477
Validation loss: 2.0890188191526677

Epoch: 5| Step: 6
Training loss: 1.841162085533142
Validation loss: 2.0789254993520756

Epoch: 5| Step: 7
Training loss: 2.003939151763916
Validation loss: 2.079917896178461

Epoch: 5| Step: 8
Training loss: 1.4858487844467163
Validation loss: 2.0728561673113095

Epoch: 5| Step: 9
Training loss: 1.878483772277832
Validation loss: 2.0629977064747966

Epoch: 5| Step: 10
Training loss: 1.7900508642196655
Validation loss: 2.0806677328642977

Epoch: 188| Step: 0
Training loss: 2.240314483642578
Validation loss: 2.082986767574023

Epoch: 5| Step: 1
Training loss: 2.5984230041503906
Validation loss: 2.080244920587027

Epoch: 5| Step: 2
Training loss: 1.8894445896148682
Validation loss: 2.07528248909981

Epoch: 5| Step: 3
Training loss: 1.9285247325897217
Validation loss: 2.0665369777269262

Epoch: 5| Step: 4
Training loss: 1.6526539325714111
Validation loss: 2.0839034818833873

Epoch: 5| Step: 5
Training loss: 2.0157296657562256
Validation loss: 2.113699197769165

Epoch: 5| Step: 6
Training loss: 2.787576675415039
Validation loss: 2.1148029886266237

Epoch: 5| Step: 7
Training loss: 1.3645946979522705
Validation loss: 2.128261091888592

Epoch: 5| Step: 8
Training loss: 2.0190868377685547
Validation loss: 2.1081708169752553

Epoch: 5| Step: 9
Training loss: 1.8080341815948486
Validation loss: 2.1185870632048576

Epoch: 5| Step: 10
Training loss: 1.3533456325531006
Validation loss: 2.0846972824424825

Epoch: 189| Step: 0
Training loss: 1.8447179794311523
Validation loss: 2.1095137057765836

Epoch: 5| Step: 1
Training loss: 2.194179058074951
Validation loss: 2.137251571942401

Epoch: 5| Step: 2
Training loss: 2.758509397506714
Validation loss: 2.1642364994172127

Epoch: 5| Step: 3
Training loss: 1.914049506187439
Validation loss: 2.2160747948513237

Epoch: 5| Step: 4
Training loss: 2.1208930015563965
Validation loss: 2.2252703956378403

Epoch: 5| Step: 5
Training loss: 1.5770432949066162
Validation loss: 2.1285762351046325

Epoch: 5| Step: 6
Training loss: 1.5787439346313477
Validation loss: 2.0648455030174664

Epoch: 5| Step: 7
Training loss: 1.8530553579330444
Validation loss: 2.079674874582598

Epoch: 5| Step: 8
Training loss: 1.7096354961395264
Validation loss: 2.094496726989746

Epoch: 5| Step: 9
Training loss: 2.605917453765869
Validation loss: 2.093715254978467

Epoch: 5| Step: 10
Training loss: 1.5431134700775146
Validation loss: 2.1342146204363917

Epoch: 190| Step: 0
Training loss: 1.4915028810501099
Validation loss: 2.1384617795226393

Epoch: 5| Step: 1
Training loss: 2.518613576889038
Validation loss: 2.108057193858649

Epoch: 5| Step: 2
Training loss: 1.5552862882614136
Validation loss: 2.124720411915933

Epoch: 5| Step: 3
Training loss: 1.4006415605545044
Validation loss: 2.1068112875825618

Epoch: 5| Step: 4
Training loss: 2.2542495727539062
Validation loss: 2.095083155939656

Epoch: 5| Step: 5
Training loss: 2.0540852546691895
Validation loss: 2.0896656333759265

Epoch: 5| Step: 6
Training loss: 1.8084980249404907
Validation loss: 2.0886217509546587

Epoch: 5| Step: 7
Training loss: 2.0692572593688965
Validation loss: 2.101727743302622

Epoch: 5| Step: 8
Training loss: 2.2600839138031006
Validation loss: 2.103068241509058

Epoch: 5| Step: 9
Training loss: 1.9482625722885132
Validation loss: 2.115607415476153

Epoch: 5| Step: 10
Training loss: 1.894646406173706
Validation loss: 2.1470516048451906

Epoch: 191| Step: 0
Training loss: 2.485729932785034
Validation loss: 2.1687134901682534

Epoch: 5| Step: 1
Training loss: 1.6033923625946045
Validation loss: 2.1731742569195327

Epoch: 5| Step: 2
Training loss: 1.7622137069702148
Validation loss: 2.1361393415799705

Epoch: 5| Step: 3
Training loss: 2.2571513652801514
Validation loss: 2.1095711338904595

Epoch: 5| Step: 4
Training loss: 1.8718845844268799
Validation loss: 2.1280082810309624

Epoch: 5| Step: 5
Training loss: 1.9236068725585938
Validation loss: 2.1216597454522246

Epoch: 5| Step: 6
Training loss: 2.043875217437744
Validation loss: 2.1141374546994447

Epoch: 5| Step: 7
Training loss: 2.1784584522247314
Validation loss: 2.122533763608625

Epoch: 5| Step: 8
Training loss: 2.0533649921417236
Validation loss: 2.0802527730182936

Epoch: 5| Step: 9
Training loss: 1.8453130722045898
Validation loss: 2.057418971933344

Epoch: 5| Step: 10
Training loss: 1.5080276727676392
Validation loss: 2.046457447031493

Epoch: 192| Step: 0
Training loss: 2.074084520339966
Validation loss: 2.0682629513484176

Epoch: 5| Step: 1
Training loss: 2.010715961456299
Validation loss: 2.0827692529206634

Epoch: 5| Step: 2
Training loss: 1.95407235622406
Validation loss: 2.0708732271707184

Epoch: 5| Step: 3
Training loss: 1.923145055770874
Validation loss: 2.0692763725916543

Epoch: 5| Step: 4
Training loss: 1.511592149734497
Validation loss: 2.0734356103404874

Epoch: 5| Step: 5
Training loss: 2.3825812339782715
Validation loss: 2.075703449146722

Epoch: 5| Step: 6
Training loss: 2.680685520172119
Validation loss: 2.0630937545530257

Epoch: 5| Step: 7
Training loss: 1.5687479972839355
Validation loss: 2.1079437578878095

Epoch: 5| Step: 8
Training loss: 1.7667548656463623
Validation loss: 2.1764312585194907

Epoch: 5| Step: 9
Training loss: 1.254181146621704
Validation loss: 2.248419601430175

Epoch: 5| Step: 10
Training loss: 1.9696381092071533
Validation loss: 2.2751934835987706

Epoch: 193| Step: 0
Training loss: 1.6299247741699219
Validation loss: 2.259583742387833

Epoch: 5| Step: 1
Training loss: 1.9570019245147705
Validation loss: 2.2355217010744157

Epoch: 5| Step: 2
Training loss: 1.58121657371521
Validation loss: 2.2092560427163237

Epoch: 5| Step: 3
Training loss: 2.2157187461853027
Validation loss: 2.1760859233076855

Epoch: 5| Step: 4
Training loss: 2.0126936435699463
Validation loss: 2.1465400444564

Epoch: 5| Step: 5
Training loss: 1.9960453510284424
Validation loss: 2.1084919283466954

Epoch: 5| Step: 6
Training loss: 1.6836169958114624
Validation loss: 2.0911640287727438

Epoch: 5| Step: 7
Training loss: 2.2458884716033936
Validation loss: 2.084240828790972

Epoch: 5| Step: 8
Training loss: 2.406262159347534
Validation loss: 2.0893885756051667

Epoch: 5| Step: 9
Training loss: 2.0402894020080566
Validation loss: 2.089436384939378

Epoch: 5| Step: 10
Training loss: 1.6845155954360962
Validation loss: 2.075782843815383

Epoch: 194| Step: 0
Training loss: 1.388271689414978
Validation loss: 2.0468392474676973

Epoch: 5| Step: 1
Training loss: 1.8329261541366577
Validation loss: 2.047436214262439

Epoch: 5| Step: 2
Training loss: 1.3805296421051025
Validation loss: 2.0667411050488873

Epoch: 5| Step: 3
Training loss: 2.3247530460357666
Validation loss: 2.096873414131903

Epoch: 5| Step: 4
Training loss: 1.911014199256897
Validation loss: 2.1273096069212882

Epoch: 5| Step: 5
Training loss: 2.277144193649292
Validation loss: 2.1829210994064168

Epoch: 5| Step: 6
Training loss: 2.7597928047180176
Validation loss: 2.195151686668396

Epoch: 5| Step: 7
Training loss: 2.1691596508026123
Validation loss: 2.142780452646235

Epoch: 5| Step: 8
Training loss: 1.62124502658844
Validation loss: 2.0808273053938344

Epoch: 5| Step: 9
Training loss: 2.189847946166992
Validation loss: 2.09466581062604

Epoch: 5| Step: 10
Training loss: 1.897284984588623
Validation loss: 2.0937767285172657

Epoch: 195| Step: 0
Training loss: 1.8036819696426392
Validation loss: 2.06179327477691

Epoch: 5| Step: 1
Training loss: 2.249727725982666
Validation loss: 2.089985660327378

Epoch: 5| Step: 2
Training loss: 1.6245253086090088
Validation loss: 2.1376528483565136

Epoch: 5| Step: 3
Training loss: 1.8733030557632446
Validation loss: 2.224329686933948

Epoch: 5| Step: 4
Training loss: 2.4661002159118652
Validation loss: 2.26725608559065

Epoch: 5| Step: 5
Training loss: 2.3169729709625244
Validation loss: 2.281941121624362

Epoch: 5| Step: 6
Training loss: 2.3345706462860107
Validation loss: 2.258440153573149

Epoch: 5| Step: 7
Training loss: 2.2173781394958496
Validation loss: 2.1991992945312173

Epoch: 5| Step: 8
Training loss: 1.3963803052902222
Validation loss: 2.145341375822662

Epoch: 5| Step: 9
Training loss: 1.450330138206482
Validation loss: 2.1212364524923344

Epoch: 5| Step: 10
Training loss: 1.7351912260055542
Validation loss: 2.0945023849446285

Epoch: 196| Step: 0
Training loss: 1.817557692527771
Validation loss: 2.091951075420585

Epoch: 5| Step: 1
Training loss: 2.0595054626464844
Validation loss: 2.09590059198359

Epoch: 5| Step: 2
Training loss: 2.291344165802002
Validation loss: 2.085667399949925

Epoch: 5| Step: 3
Training loss: 1.637876272201538
Validation loss: 2.108683837357388

Epoch: 5| Step: 4
Training loss: 2.656000852584839
Validation loss: 2.151728491629324

Epoch: 5| Step: 5
Training loss: 1.824904441833496
Validation loss: 2.1607041205129316

Epoch: 5| Step: 6
Training loss: 2.0615501403808594
Validation loss: 2.2041473363035466

Epoch: 5| Step: 7
Training loss: 1.5935728549957275
Validation loss: 2.209214584801787

Epoch: 5| Step: 8
Training loss: 1.5250790119171143
Validation loss: 2.193436863601849

Epoch: 5| Step: 9
Training loss: 1.9780315160751343
Validation loss: 2.176847977022971

Epoch: 5| Step: 10
Training loss: 1.7851043939590454
Validation loss: 2.1331679551832137

Epoch: 197| Step: 0
Training loss: 1.8119239807128906
Validation loss: 2.1175573282344367

Epoch: 5| Step: 1
Training loss: 2.1393673419952393
Validation loss: 2.1266230895955074

Epoch: 5| Step: 2
Training loss: 1.8892656564712524
Validation loss: 2.135086347979884

Epoch: 5| Step: 3
Training loss: 1.9848072528839111
Validation loss: 2.1461886821254605

Epoch: 5| Step: 4
Training loss: 1.6677452325820923
Validation loss: 2.132698553864674

Epoch: 5| Step: 5
Training loss: 1.7408115863800049
Validation loss: 2.1197045195487236

Epoch: 5| Step: 6
Training loss: 1.2910566329956055
Validation loss: 2.1309208921206895

Epoch: 5| Step: 7
Training loss: 1.8884742259979248
Validation loss: 2.1882605424491306

Epoch: 5| Step: 8
Training loss: 2.604914665222168
Validation loss: 2.237539699000697

Epoch: 5| Step: 9
Training loss: 1.7431833744049072
Validation loss: 2.1886667871987946

Epoch: 5| Step: 10
Training loss: 2.153348922729492
Validation loss: 2.148549877187257

Epoch: 198| Step: 0
Training loss: 2.0854763984680176
Validation loss: 2.126251066884687

Epoch: 5| Step: 1
Training loss: 1.5436124801635742
Validation loss: 2.097680732768069

Epoch: 5| Step: 2
Training loss: 3.0185844898223877
Validation loss: 2.0866468029637493

Epoch: 5| Step: 3
Training loss: 1.4012664556503296
Validation loss: 2.0888650148145613

Epoch: 5| Step: 4
Training loss: 1.0711761713027954
Validation loss: 2.08517821117114

Epoch: 5| Step: 5
Training loss: 1.3295727968215942
Validation loss: 2.0786482800719557

Epoch: 5| Step: 6
Training loss: 1.737375020980835
Validation loss: 2.077406165420368

Epoch: 5| Step: 7
Training loss: 2.4503464698791504
Validation loss: 2.1074210264349498

Epoch: 5| Step: 8
Training loss: 2.0298056602478027
Validation loss: 2.1346978474688787

Epoch: 5| Step: 9
Training loss: 1.9891197681427002
Validation loss: 2.154029856445969

Epoch: 5| Step: 10
Training loss: 1.9292750358581543
Validation loss: 2.165574053282379

Epoch: 199| Step: 0
Training loss: 1.237660527229309
Validation loss: 2.169092652618244

Epoch: 5| Step: 1
Training loss: 1.387419581413269
Validation loss: 2.1859321286601405

Epoch: 5| Step: 2
Training loss: 1.6740131378173828
Validation loss: 2.2067687972899406

Epoch: 5| Step: 3
Training loss: 2.185863733291626
Validation loss: 2.2139935288377988

Epoch: 5| Step: 4
Training loss: 1.7318528890609741
Validation loss: 2.1777340673631236

Epoch: 5| Step: 5
Training loss: 2.388793468475342
Validation loss: 2.1863346817672893

Epoch: 5| Step: 6
Training loss: 1.3379770517349243
Validation loss: 2.1601929856884863

Epoch: 5| Step: 7
Training loss: 1.6555026769638062
Validation loss: 2.143666516068161

Epoch: 5| Step: 8
Training loss: 3.074753761291504
Validation loss: 2.1169258086912093

Epoch: 5| Step: 9
Training loss: 1.5678212642669678
Validation loss: 2.0969901341263966

Epoch: 5| Step: 10
Training loss: 2.1924829483032227
Validation loss: 2.077334847501529

Epoch: 200| Step: 0
Training loss: 1.8844592571258545
Validation loss: 2.081923601447895

Epoch: 5| Step: 1
Training loss: 1.686327576637268
Validation loss: 2.0863867241849183

Epoch: 5| Step: 2
Training loss: 1.9953956604003906
Validation loss: 2.076371333932364

Epoch: 5| Step: 3
Training loss: 2.044123888015747
Validation loss: 2.0680970671356365

Epoch: 5| Step: 4
Training loss: 1.8290666341781616
Validation loss: 2.0713858066066617

Epoch: 5| Step: 5
Training loss: 1.7906057834625244
Validation loss: 2.0580926761832288

Epoch: 5| Step: 6
Training loss: 1.5706051588058472
Validation loss: 2.0833776920072493

Epoch: 5| Step: 7
Training loss: 1.904260277748108
Validation loss: 2.09093871039729

Epoch: 5| Step: 8
Training loss: 1.81706964969635
Validation loss: 2.073342364321473

Epoch: 5| Step: 9
Training loss: 2.0543181896209717
Validation loss: 2.0555426305340183

Epoch: 5| Step: 10
Training loss: 1.8979501724243164
Validation loss: 2.076883956950198

Epoch: 201| Step: 0
Training loss: 2.054065704345703
Validation loss: 2.0978836513334707

Epoch: 5| Step: 1
Training loss: 1.9593101739883423
Validation loss: 2.09598248363823

Epoch: 5| Step: 2
Training loss: 1.6622536182403564
Validation loss: 2.125507535472993

Epoch: 5| Step: 3
Training loss: 1.0010673999786377
Validation loss: 2.1262934361734698

Epoch: 5| Step: 4
Training loss: 1.8940327167510986
Validation loss: 2.1471722869462866

Epoch: 5| Step: 5
Training loss: 2.2559077739715576
Validation loss: 2.1586597581063547

Epoch: 5| Step: 6
Training loss: 1.8814719915390015
Validation loss: 2.1270785613726546

Epoch: 5| Step: 7
Training loss: 2.21537446975708
Validation loss: 2.130850208702908

Epoch: 5| Step: 8
Training loss: 1.7865726947784424
Validation loss: 2.1207920864064205

Epoch: 5| Step: 9
Training loss: 1.5250507593154907
Validation loss: 2.156071121974658

Epoch: 5| Step: 10
Training loss: 1.866772174835205
Validation loss: 2.1813653643413256

Epoch: 202| Step: 0
Training loss: 2.20379900932312
Validation loss: 2.1876888557146956

Epoch: 5| Step: 1
Training loss: 1.9348888397216797
Validation loss: 2.2318238468580347

Epoch: 5| Step: 2
Training loss: 2.02947998046875
Validation loss: 2.22487989805078

Epoch: 5| Step: 3
Training loss: 2.15425443649292
Validation loss: 2.228175460651357

Epoch: 5| Step: 4
Training loss: 1.6270023584365845
Validation loss: 2.17801006122302

Epoch: 5| Step: 5
Training loss: 1.9889600276947021
Validation loss: 2.1345589417283253

Epoch: 5| Step: 6
Training loss: 1.968317985534668
Validation loss: 2.141575413365518

Epoch: 5| Step: 7
Training loss: 1.3076388835906982
Validation loss: 2.132691623062216

Epoch: 5| Step: 8
Training loss: 2.0261974334716797
Validation loss: 2.1270994947802637

Epoch: 5| Step: 9
Training loss: 1.5463906526565552
Validation loss: 2.0895867757899786

Epoch: 5| Step: 10
Training loss: 1.5979901552200317
Validation loss: 2.117470746399254

Epoch: 203| Step: 0
Training loss: 1.7556571960449219
Validation loss: 2.1449733395730295

Epoch: 5| Step: 1
Training loss: 1.5825884342193604
Validation loss: 2.129168297654839

Epoch: 5| Step: 2
Training loss: 1.3201651573181152
Validation loss: 2.122317447457262

Epoch: 5| Step: 3
Training loss: 1.8078052997589111
Validation loss: 2.1204403305566437

Epoch: 5| Step: 4
Training loss: 1.846623182296753
Validation loss: 2.1052212356239237

Epoch: 5| Step: 5
Training loss: 1.9930660724639893
Validation loss: 2.1144386209467405

Epoch: 5| Step: 6
Training loss: 2.1090950965881348
Validation loss: 2.1101462546215264

Epoch: 5| Step: 7
Training loss: 1.998762845993042
Validation loss: 2.127905732841902

Epoch: 5| Step: 8
Training loss: 1.9125896692276
Validation loss: 2.1162933957192207

Epoch: 5| Step: 9
Training loss: 1.8794292211532593
Validation loss: 2.1468636784502255

Epoch: 5| Step: 10
Training loss: 1.6945726871490479
Validation loss: 2.1423117832470964

Epoch: 204| Step: 0
Training loss: 1.584280014038086
Validation loss: 2.1484173472209642

Epoch: 5| Step: 1
Training loss: 2.068726062774658
Validation loss: 2.1635228805644537

Epoch: 5| Step: 2
Training loss: 1.8755909204483032
Validation loss: 2.166603763898214

Epoch: 5| Step: 3
Training loss: 1.3918371200561523
Validation loss: 2.20652634866776

Epoch: 5| Step: 4
Training loss: 2.5542593002319336
Validation loss: 2.1743198530648344

Epoch: 5| Step: 5
Training loss: 1.9502102136611938
Validation loss: 2.150139957345942

Epoch: 5| Step: 6
Training loss: 2.6155619621276855
Validation loss: 2.142803612575736

Epoch: 5| Step: 7
Training loss: 1.2127748727798462
Validation loss: 2.1195231637647076

Epoch: 5| Step: 8
Training loss: 1.3206883668899536
Validation loss: 2.0982215301964873

Epoch: 5| Step: 9
Training loss: 1.5760459899902344
Validation loss: 2.0907054075630764

Epoch: 5| Step: 10
Training loss: 1.7705495357513428
Validation loss: 2.0885844256288264

Epoch: 205| Step: 0
Training loss: 1.8257554769515991
Validation loss: 2.0928486700980895

Epoch: 5| Step: 1
Training loss: 1.8900295495986938
Validation loss: 2.0939065948609383

Epoch: 5| Step: 2
Training loss: 1.415329098701477
Validation loss: 2.069757761493806

Epoch: 5| Step: 3
Training loss: 1.740396499633789
Validation loss: 2.064311699200702

Epoch: 5| Step: 4
Training loss: 1.821062684059143
Validation loss: 2.059698144594828

Epoch: 5| Step: 5
Training loss: 1.8833410739898682
Validation loss: 2.054229503036827

Epoch: 5| Step: 6
Training loss: 1.553430199623108
Validation loss: 2.06071606374556

Epoch: 5| Step: 7
Training loss: 1.8276647329330444
Validation loss: 2.0614008493320917

Epoch: 5| Step: 8
Training loss: 1.5994203090667725
Validation loss: 2.095511728717435

Epoch: 5| Step: 9
Training loss: 1.967024803161621
Validation loss: 2.128545836735797

Epoch: 5| Step: 10
Training loss: 2.218946695327759
Validation loss: 2.146331214135693

Epoch: 206| Step: 0
Training loss: 2.318300485610962
Validation loss: 2.1436835847875124

Epoch: 5| Step: 1
Training loss: 2.177126884460449
Validation loss: 2.132246914730277

Epoch: 5| Step: 2
Training loss: 1.9276033639907837
Validation loss: 2.1393530907169467

Epoch: 5| Step: 3
Training loss: 1.9712845087051392
Validation loss: 2.124320084048856

Epoch: 5| Step: 4
Training loss: 1.8673279285430908
Validation loss: 2.1431866627867504

Epoch: 5| Step: 5
Training loss: 1.7366079092025757
Validation loss: 2.1671966557861655

Epoch: 5| Step: 6
Training loss: 1.5504659414291382
Validation loss: 2.2045264064624743

Epoch: 5| Step: 7
Training loss: 1.0025720596313477
Validation loss: 2.2117485410423687

Epoch: 5| Step: 8
Training loss: 1.2708885669708252
Validation loss: 2.1870446717867287

Epoch: 5| Step: 9
Training loss: 2.03955078125
Validation loss: 2.2025033761096258

Epoch: 5| Step: 10
Training loss: 1.6887589693069458
Validation loss: 2.202743649482727

Epoch: 207| Step: 0
Training loss: 1.5753493309020996
Validation loss: 2.1664392307240474

Epoch: 5| Step: 1
Training loss: 1.3272831439971924
Validation loss: 2.14385203776821

Epoch: 5| Step: 2
Training loss: 1.7096812725067139
Validation loss: 2.1324175801328433

Epoch: 5| Step: 3
Training loss: 1.778824806213379
Validation loss: 2.1262875782546176

Epoch: 5| Step: 4
Training loss: 1.2527644634246826
Validation loss: 2.1010658971724974

Epoch: 5| Step: 5
Training loss: 1.8515088558197021
Validation loss: 2.1072914203008017

Epoch: 5| Step: 6
Training loss: 1.4967375993728638
Validation loss: 2.085459675840152

Epoch: 5| Step: 7
Training loss: 2.5135207176208496
Validation loss: 2.087695220465301

Epoch: 5| Step: 8
Training loss: 2.5180580615997314
Validation loss: 2.1131570621203353

Epoch: 5| Step: 9
Training loss: 1.7240585088729858
Validation loss: 2.1318341762788835

Epoch: 5| Step: 10
Training loss: 1.5682140588760376
Validation loss: 2.1345712715579617

Epoch: 208| Step: 0
Training loss: 1.7548402547836304
Validation loss: 2.161638916179698

Epoch: 5| Step: 1
Training loss: 1.9882005453109741
Validation loss: 2.1886854915208716

Epoch: 5| Step: 2
Training loss: 1.2516151666641235
Validation loss: 2.191715425060641

Epoch: 5| Step: 3
Training loss: 1.37491774559021
Validation loss: 2.177182851299163

Epoch: 5| Step: 4
Training loss: 1.6670554876327515
Validation loss: 2.1725882407157653

Epoch: 5| Step: 5
Training loss: 1.5644440650939941
Validation loss: 2.147576447456114

Epoch: 5| Step: 6
Training loss: 1.5249961614608765
Validation loss: 2.158702690114257

Epoch: 5| Step: 7
Training loss: 1.7568902969360352
Validation loss: 2.172246220291302

Epoch: 5| Step: 8
Training loss: 2.9657020568847656
Validation loss: 2.148788870021861

Epoch: 5| Step: 9
Training loss: 1.4453351497650146
Validation loss: 2.13564875818068

Epoch: 5| Step: 10
Training loss: 2.136310338973999
Validation loss: 2.1248902274716284

Epoch: 209| Step: 0
Training loss: 1.558947205543518
Validation loss: 2.121923300527757

Epoch: 5| Step: 1
Training loss: 1.0473872423171997
Validation loss: 2.102144400278727

Epoch: 5| Step: 2
Training loss: 1.9234731197357178
Validation loss: 2.1178739711802494

Epoch: 5| Step: 3
Training loss: 1.7602647542953491
Validation loss: 2.1111967666174776

Epoch: 5| Step: 4
Training loss: 1.3175935745239258
Validation loss: 2.1061890996912473

Epoch: 5| Step: 5
Training loss: 2.2963953018188477
Validation loss: 2.1012572614095544

Epoch: 5| Step: 6
Training loss: 1.3849918842315674
Validation loss: 2.1018542499952417

Epoch: 5| Step: 7
Training loss: 1.6255455017089844
Validation loss: 2.1282348684085313

Epoch: 5| Step: 8
Training loss: 2.0018532276153564
Validation loss: 2.1500240038799983

Epoch: 5| Step: 9
Training loss: 2.2696421146392822
Validation loss: 2.1630306410533127

Epoch: 5| Step: 10
Training loss: 2.264364719390869
Validation loss: 2.1433538262562086

Epoch: 210| Step: 0
Training loss: 2.4982283115386963
Validation loss: 2.128195554979386

Epoch: 5| Step: 1
Training loss: 1.733245849609375
Validation loss: 2.083011192660178

Epoch: 5| Step: 2
Training loss: 1.5565736293792725
Validation loss: 2.1088112887515815

Epoch: 5| Step: 3
Training loss: 2.121656894683838
Validation loss: 2.0916102611890404

Epoch: 5| Step: 4
Training loss: 1.2797157764434814
Validation loss: 2.096426461332588

Epoch: 5| Step: 5
Training loss: 1.9113759994506836
Validation loss: 2.106007924643896

Epoch: 5| Step: 6
Training loss: 1.0397651195526123
Validation loss: 2.0934192544670513

Epoch: 5| Step: 7
Training loss: 2.089346170425415
Validation loss: 2.116219097568143

Epoch: 5| Step: 8
Training loss: 1.1023716926574707
Validation loss: 2.110312468262129

Epoch: 5| Step: 9
Training loss: 1.573184609413147
Validation loss: 2.1418154419109388

Epoch: 5| Step: 10
Training loss: 2.0466573238372803
Validation loss: 2.1274162838535924

Epoch: 211| Step: 0
Training loss: 0.9143017530441284
Validation loss: 2.130143730871139

Epoch: 5| Step: 1
Training loss: 1.7713611125946045
Validation loss: 2.144065764642531

Epoch: 5| Step: 2
Training loss: 2.0069048404693604
Validation loss: 2.140815217007873

Epoch: 5| Step: 3
Training loss: 2.0543007850646973
Validation loss: 2.134490418177779

Epoch: 5| Step: 4
Training loss: 1.705498456954956
Validation loss: 2.1269131219515236

Epoch: 5| Step: 5
Training loss: 1.8058172464370728
Validation loss: 2.12629948892901

Epoch: 5| Step: 6
Training loss: 1.347313404083252
Validation loss: 2.1007769312909854

Epoch: 5| Step: 7
Training loss: 1.8157360553741455
Validation loss: 2.0826411965072795

Epoch: 5| Step: 8
Training loss: 1.8560842275619507
Validation loss: 2.0774707883916874

Epoch: 5| Step: 9
Training loss: 1.6858389377593994
Validation loss: 2.1094547945966005

Epoch: 5| Step: 10
Training loss: 1.7711474895477295
Validation loss: 2.1241988597377652

Epoch: 212| Step: 0
Training loss: 1.068589448928833
Validation loss: 2.1322644525958645

Epoch: 5| Step: 1
Training loss: 1.6123727560043335
Validation loss: 2.101802736200312

Epoch: 5| Step: 2
Training loss: 1.7278563976287842
Validation loss: 2.0936172085423626

Epoch: 5| Step: 3
Training loss: 2.045302152633667
Validation loss: 2.074567117998677

Epoch: 5| Step: 4
Training loss: 2.5207247734069824
Validation loss: 2.0630570034826956

Epoch: 5| Step: 5
Training loss: 1.1598936319351196
Validation loss: 2.059894282330749

Epoch: 5| Step: 6
Training loss: 1.6812794208526611
Validation loss: 2.084650912592488

Epoch: 5| Step: 7
Training loss: 1.8846302032470703
Validation loss: 2.112138917369227

Epoch: 5| Step: 8
Training loss: 1.419050931930542
Validation loss: 2.1295010453911236

Epoch: 5| Step: 9
Training loss: 2.148855686187744
Validation loss: 2.119010576637842

Epoch: 5| Step: 10
Training loss: 1.6215965747833252
Validation loss: 2.1335286940297773

Epoch: 213| Step: 0
Training loss: 1.7028224468231201
Validation loss: 2.0865807751173615

Epoch: 5| Step: 1
Training loss: 2.2386343479156494
Validation loss: 2.1097318459582586

Epoch: 5| Step: 2
Training loss: 2.038801670074463
Validation loss: 2.1158691298577095

Epoch: 5| Step: 3
Training loss: 2.0568714141845703
Validation loss: 2.13624087713098

Epoch: 5| Step: 4
Training loss: 1.7303107976913452
Validation loss: 2.1260651875567693

Epoch: 5| Step: 5
Training loss: 1.3120262622833252
Validation loss: 2.1928261838933474

Epoch: 5| Step: 6
Training loss: 1.246092438697815
Validation loss: 2.1977671166901946

Epoch: 5| Step: 7
Training loss: 1.410775065422058
Validation loss: 2.1710139705288793

Epoch: 5| Step: 8
Training loss: 1.7434812784194946
Validation loss: 2.15223696924025

Epoch: 5| Step: 9
Training loss: 1.76528000831604
Validation loss: 2.087991519640851

Epoch: 5| Step: 10
Training loss: 1.4145121574401855
Validation loss: 2.0674180061586442

Epoch: 214| Step: 0
Training loss: 1.7480872869491577
Validation loss: 2.0807802651518132

Epoch: 5| Step: 1
Training loss: 1.7995116710662842
Validation loss: 2.071732456966113

Epoch: 5| Step: 2
Training loss: 1.842594861984253
Validation loss: 2.0680392993393766

Epoch: 5| Step: 3
Training loss: 1.8108491897583008
Validation loss: 2.07690695793398

Epoch: 5| Step: 4
Training loss: 1.952188491821289
Validation loss: 2.0726915533824632

Epoch: 5| Step: 5
Training loss: 1.682471513748169
Validation loss: 2.1062448345204836

Epoch: 5| Step: 6
Training loss: 1.5375314950942993
Validation loss: 2.156996901317309

Epoch: 5| Step: 7
Training loss: 1.7650388479232788
Validation loss: 2.2336601082996657

Epoch: 5| Step: 8
Training loss: 1.9065793752670288
Validation loss: 2.210915486017863

Epoch: 5| Step: 9
Training loss: 2.080934524536133
Validation loss: 2.1490688746975315

Epoch: 5| Step: 10
Training loss: 1.4084948301315308
Validation loss: 2.074081177352577

Epoch: 215| Step: 0
Training loss: 1.5658372640609741
Validation loss: 2.0924502085613947

Epoch: 5| Step: 1
Training loss: 1.724848985671997
Validation loss: 2.0755855601320983

Epoch: 5| Step: 2
Training loss: 1.841139554977417
Validation loss: 2.09837366432272

Epoch: 5| Step: 3
Training loss: 1.3498953580856323
Validation loss: 2.1159970132253503

Epoch: 5| Step: 4
Training loss: 1.9530398845672607
Validation loss: 2.1213380162433912

Epoch: 5| Step: 5
Training loss: 0.968347430229187
Validation loss: 2.1054514941348823

Epoch: 5| Step: 6
Training loss: 1.9224040508270264
Validation loss: 2.1131814910519506

Epoch: 5| Step: 7
Training loss: 1.824448823928833
Validation loss: 2.138689346210931

Epoch: 5| Step: 8
Training loss: 2.2146856784820557
Validation loss: 2.109159487549977

Epoch: 5| Step: 9
Training loss: 1.819082260131836
Validation loss: 2.0908440313031598

Epoch: 5| Step: 10
Training loss: 1.4368700981140137
Validation loss: 2.061614554415467

Epoch: 216| Step: 0
Training loss: 1.6047741174697876
Validation loss: 2.0764395883006435

Epoch: 5| Step: 1
Training loss: 1.5970795154571533
Validation loss: 2.0653862453276113

Epoch: 5| Step: 2
Training loss: 1.4214866161346436
Validation loss: 2.091496206098987

Epoch: 5| Step: 3
Training loss: 2.0285019874572754
Validation loss: 2.1032926113374772

Epoch: 5| Step: 4
Training loss: 1.268419623374939
Validation loss: 2.08500736887737

Epoch: 5| Step: 5
Training loss: 2.0613560676574707
Validation loss: 2.0856047317545903

Epoch: 5| Step: 6
Training loss: 1.4361746311187744
Validation loss: 2.0964682640567904

Epoch: 5| Step: 7
Training loss: 1.6261011362075806
Validation loss: 2.106838059681718

Epoch: 5| Step: 8
Training loss: 1.4670436382293701
Validation loss: 2.1119376510702152

Epoch: 5| Step: 9
Training loss: 1.8629510402679443
Validation loss: 2.1058962396396104

Epoch: 5| Step: 10
Training loss: 1.4763389825820923
Validation loss: 2.1108881401759323

Epoch: 217| Step: 0
Training loss: 1.1463000774383545
Validation loss: 2.134897696074619

Epoch: 5| Step: 1
Training loss: 1.4098228216171265
Validation loss: 2.1194969018300376

Epoch: 5| Step: 2
Training loss: 1.2984625101089478
Validation loss: 2.1017956579885175

Epoch: 5| Step: 3
Training loss: 2.100050449371338
Validation loss: 2.075294820211267

Epoch: 5| Step: 4
Training loss: 2.2494473457336426
Validation loss: 2.067584462063287

Epoch: 5| Step: 5
Training loss: 1.5231138467788696
Validation loss: 2.071266761390112

Epoch: 5| Step: 6
Training loss: 1.635422706604004
Validation loss: 2.0617571671803794

Epoch: 5| Step: 7
Training loss: 1.869139313697815
Validation loss: 2.0743044307154994

Epoch: 5| Step: 8
Training loss: 1.4305579662322998
Validation loss: 2.081137175201088

Epoch: 5| Step: 9
Training loss: 1.5358655452728271
Validation loss: 2.0775892080799228

Epoch: 5| Step: 10
Training loss: 1.8437780141830444
Validation loss: 2.1160892312244703

Epoch: 218| Step: 0
Training loss: 1.4928843975067139
Validation loss: 2.1236864341202604

Epoch: 5| Step: 1
Training loss: 2.0154552459716797
Validation loss: 2.1180964336600354

Epoch: 5| Step: 2
Training loss: 1.305034875869751
Validation loss: 2.1000810976951354

Epoch: 5| Step: 3
Training loss: 1.7291133403778076
Validation loss: 2.1270947366632442

Epoch: 5| Step: 4
Training loss: 1.5327980518341064
Validation loss: 2.109284077921221

Epoch: 5| Step: 5
Training loss: 1.6879656314849854
Validation loss: 2.081376744854835

Epoch: 5| Step: 6
Training loss: 1.9006742238998413
Validation loss: 2.1070857996581704

Epoch: 5| Step: 7
Training loss: 1.239781141281128
Validation loss: 2.089635697744226

Epoch: 5| Step: 8
Training loss: 1.216415524482727
Validation loss: 2.0709106383785123

Epoch: 5| Step: 9
Training loss: 2.3538060188293457
Validation loss: 2.0809619913819017

Epoch: 5| Step: 10
Training loss: 1.3356940746307373
Validation loss: 2.0847951314782582

Epoch: 219| Step: 0
Training loss: 1.6871325969696045
Validation loss: 2.108693110045566

Epoch: 5| Step: 1
Training loss: 1.9914464950561523
Validation loss: 2.083160954137002

Epoch: 5| Step: 2
Training loss: 1.7110992670059204
Validation loss: 2.056368026682126

Epoch: 5| Step: 3
Training loss: 1.634518027305603
Validation loss: 2.036919305401464

Epoch: 5| Step: 4
Training loss: 1.341158390045166
Validation loss: 2.055775337321784

Epoch: 5| Step: 5
Training loss: 2.143958568572998
Validation loss: 2.0357427725227932

Epoch: 5| Step: 6
Training loss: 1.8964271545410156
Validation loss: 2.0384125312169394

Epoch: 5| Step: 7
Training loss: 1.3717490434646606
Validation loss: 2.0462563563418645

Epoch: 5| Step: 8
Training loss: 1.2359964847564697
Validation loss: 2.0608722227875904

Epoch: 5| Step: 9
Training loss: 1.3025487661361694
Validation loss: 2.0965158349724224

Epoch: 5| Step: 10
Training loss: 1.2955571413040161
Validation loss: 2.117496742997118

Epoch: 220| Step: 0
Training loss: 1.5731126070022583
Validation loss: 2.141754070917765

Epoch: 5| Step: 1
Training loss: 1.6397892236709595
Validation loss: 2.104658261422188

Epoch: 5| Step: 2
Training loss: 1.2176393270492554
Validation loss: 2.1212037558196695

Epoch: 5| Step: 3
Training loss: 1.785819411277771
Validation loss: 2.1308315825718704

Epoch: 5| Step: 4
Training loss: 1.4317266941070557
Validation loss: 2.131666996145761

Epoch: 5| Step: 5
Training loss: 1.2069932222366333
Validation loss: 2.1200120551611787

Epoch: 5| Step: 6
Training loss: 1.8312969207763672
Validation loss: 2.1183530105057584

Epoch: 5| Step: 7
Training loss: 1.1618191003799438
Validation loss: 2.1326423665528655

Epoch: 5| Step: 8
Training loss: 1.1796449422836304
Validation loss: 2.0923438097841

Epoch: 5| Step: 9
Training loss: 2.460392475128174
Validation loss: 2.0985984891973515

Epoch: 5| Step: 10
Training loss: 2.0919368267059326
Validation loss: 2.0638586064820648

Epoch: 221| Step: 0
Training loss: 1.8244234323501587
Validation loss: 2.06649871026316

Epoch: 5| Step: 1
Training loss: 1.9543920755386353
Validation loss: 2.057407227895593

Epoch: 5| Step: 2
Training loss: 1.7868680953979492
Validation loss: 2.0680758568548385

Epoch: 5| Step: 3
Training loss: 1.3781070709228516
Validation loss: 2.0622271235271166

Epoch: 5| Step: 4
Training loss: 1.6931108236312866
Validation loss: 2.0767087039127143

Epoch: 5| Step: 5
Training loss: 1.7450401782989502
Validation loss: 2.0608375251934095

Epoch: 5| Step: 6
Training loss: 1.5374174118041992
Validation loss: 2.094464704554568

Epoch: 5| Step: 7
Training loss: 1.5229450464248657
Validation loss: 2.100495505076583

Epoch: 5| Step: 8
Training loss: 1.0046122074127197
Validation loss: 2.1057206302560787

Epoch: 5| Step: 9
Training loss: 1.4366323947906494
Validation loss: 2.0985471792118524

Epoch: 5| Step: 10
Training loss: 1.2426434755325317
Validation loss: 2.0960148713921987

Epoch: 222| Step: 0
Training loss: 1.180503487586975
Validation loss: 2.084411836439563

Epoch: 5| Step: 1
Training loss: 1.1200945377349854
Validation loss: 2.0825766991543513

Epoch: 5| Step: 2
Training loss: 1.659794569015503
Validation loss: 2.072278288102919

Epoch: 5| Step: 3
Training loss: 1.6418898105621338
Validation loss: 2.0816176527289936

Epoch: 5| Step: 4
Training loss: 1.6662826538085938
Validation loss: 2.08190574953633

Epoch: 5| Step: 5
Training loss: 1.7540823221206665
Validation loss: 2.1201458669477895

Epoch: 5| Step: 6
Training loss: 1.6015278100967407
Validation loss: 2.1496880823566067

Epoch: 5| Step: 7
Training loss: 1.9164083003997803
Validation loss: 2.154940661563668

Epoch: 5| Step: 8
Training loss: 1.2798818349838257
Validation loss: 2.136393911095076

Epoch: 5| Step: 9
Training loss: 1.9896749258041382
Validation loss: 2.1435354319951867

Epoch: 5| Step: 10
Training loss: 1.5186245441436768
Validation loss: 2.126787195923508

Epoch: 223| Step: 0
Training loss: 1.3051187992095947
Validation loss: 2.092637713237475

Epoch: 5| Step: 1
Training loss: 1.3954356908798218
Validation loss: 2.077232394167172

Epoch: 5| Step: 2
Training loss: 1.1622958183288574
Validation loss: 2.0747895497147755

Epoch: 5| Step: 3
Training loss: 1.5103336572647095
Validation loss: 2.080603159883971

Epoch: 5| Step: 4
Training loss: 1.5762239694595337
Validation loss: 2.0811336040496826

Epoch: 5| Step: 5
Training loss: 1.0042529106140137
Validation loss: 2.0926802209628526

Epoch: 5| Step: 6
Training loss: 2.145395517349243
Validation loss: 2.076488120581514

Epoch: 5| Step: 7
Training loss: 1.9940662384033203
Validation loss: 2.10012541022352

Epoch: 5| Step: 8
Training loss: 1.499180555343628
Validation loss: 2.1067468645752117

Epoch: 5| Step: 9
Training loss: 2.1127352714538574
Validation loss: 2.106661404332807

Epoch: 5| Step: 10
Training loss: 1.3864924907684326
Validation loss: 2.101519510310183

Epoch: 224| Step: 0
Training loss: 1.6931190490722656
Validation loss: 2.08075802300566

Epoch: 5| Step: 1
Training loss: 1.0643202066421509
Validation loss: 2.0577904203886628

Epoch: 5| Step: 2
Training loss: 1.5659663677215576
Validation loss: 2.055223741839009

Epoch: 5| Step: 3
Training loss: 1.7815160751342773
Validation loss: 2.064013837486185

Epoch: 5| Step: 4
Training loss: 1.4523475170135498
Validation loss: 2.087977349117238

Epoch: 5| Step: 5
Training loss: 1.2930021286010742
Validation loss: 2.0977848781052457

Epoch: 5| Step: 6
Training loss: 1.6217159032821655
Validation loss: 2.1290737992973736

Epoch: 5| Step: 7
Training loss: 1.4966545104980469
Validation loss: 2.144716203853648

Epoch: 5| Step: 8
Training loss: 1.922093152999878
Validation loss: 2.1422855418215514

Epoch: 5| Step: 9
Training loss: 1.7383606433868408
Validation loss: 2.1189456742296935

Epoch: 5| Step: 10
Training loss: 1.6664289236068726
Validation loss: 2.0957375047027424

Epoch: 225| Step: 0
Training loss: 1.505492925643921
Validation loss: 2.062767897882769

Epoch: 5| Step: 1
Training loss: 1.4015566110610962
Validation loss: 2.038878111429112

Epoch: 5| Step: 2
Training loss: 1.6159076690673828
Validation loss: 2.043055857381513

Epoch: 5| Step: 3
Training loss: 1.1152747869491577
Validation loss: 2.034917413547475

Epoch: 5| Step: 4
Training loss: 1.661444902420044
Validation loss: 2.0635903407168645

Epoch: 5| Step: 5
Training loss: 1.5291357040405273
Validation loss: 2.0772303599183277

Epoch: 5| Step: 6
Training loss: 1.7227576971054077
Validation loss: 2.082692164246754

Epoch: 5| Step: 7
Training loss: 1.3639200925827026
Validation loss: 2.1341462673679477

Epoch: 5| Step: 8
Training loss: 1.651663064956665
Validation loss: 2.1637197053560646

Epoch: 5| Step: 9
Training loss: 1.918522596359253
Validation loss: 2.169946741032344

Epoch: 5| Step: 10
Training loss: 1.8334782123565674
Validation loss: 2.140305547304051

Epoch: 226| Step: 0
Training loss: 2.091334581375122
Validation loss: 2.1264899430736417

Epoch: 5| Step: 1
Training loss: 1.4832136631011963
Validation loss: 2.10297550693635

Epoch: 5| Step: 2
Training loss: 2.0122532844543457
Validation loss: 2.0918843156547955

Epoch: 5| Step: 3
Training loss: 1.2779604196548462
Validation loss: 2.0829572446884645

Epoch: 5| Step: 4
Training loss: 1.083404779434204
Validation loss: 2.085755850679131

Epoch: 5| Step: 5
Training loss: 1.205420970916748
Validation loss: 2.079469450058476

Epoch: 5| Step: 6
Training loss: 2.292933702468872
Validation loss: 2.1236482076747443

Epoch: 5| Step: 7
Training loss: 1.7160866260528564
Validation loss: 2.132711620740993

Epoch: 5| Step: 8
Training loss: 1.260988712310791
Validation loss: 2.181995632827923

Epoch: 5| Step: 9
Training loss: 1.3242058753967285
Validation loss: 2.185772829158332

Epoch: 5| Step: 10
Training loss: 1.8173537254333496
Validation loss: 2.163387207574742

Epoch: 227| Step: 0
Training loss: 1.521262526512146
Validation loss: 2.172572128234371

Epoch: 5| Step: 1
Training loss: 1.7248502969741821
Validation loss: 2.1772292813947125

Epoch: 5| Step: 2
Training loss: 1.4874026775360107
Validation loss: 2.176051847396358

Epoch: 5| Step: 3
Training loss: 2.274935483932495
Validation loss: 2.159538180597367

Epoch: 5| Step: 4
Training loss: 1.2915807962417603
Validation loss: 2.135886828104655

Epoch: 5| Step: 5
Training loss: 1.2569500207901
Validation loss: 2.109855794137524

Epoch: 5| Step: 6
Training loss: 1.6821972131729126
Validation loss: 2.0681882186602523

Epoch: 5| Step: 7
Training loss: 1.1637241840362549
Validation loss: 2.0560569199182654

Epoch: 5| Step: 8
Training loss: 1.1496269702911377
Validation loss: 2.0677301627333446

Epoch: 5| Step: 9
Training loss: 1.4297387599945068
Validation loss: 2.0497428729969966

Epoch: 5| Step: 10
Training loss: 2.021449089050293
Validation loss: 2.061725857437298

Epoch: 228| Step: 0
Training loss: 1.3261034488677979
Validation loss: 2.0603713566257107

Epoch: 5| Step: 1
Training loss: 1.7598626613616943
Validation loss: 2.0294900196854786

Epoch: 5| Step: 2
Training loss: 1.6223499774932861
Validation loss: 2.058284495466499

Epoch: 5| Step: 3
Training loss: 1.7580158710479736
Validation loss: 2.0663159008949035

Epoch: 5| Step: 4
Training loss: 1.155944585800171
Validation loss: 2.0719290420573246

Epoch: 5| Step: 5
Training loss: 0.7580575942993164
Validation loss: 2.0593261052203435

Epoch: 5| Step: 6
Training loss: 1.9308404922485352
Validation loss: 2.0858362310676166

Epoch: 5| Step: 7
Training loss: 2.027688503265381
Validation loss: 2.111640250811013

Epoch: 5| Step: 8
Training loss: 1.5289076566696167
Validation loss: 2.1244138261323333

Epoch: 5| Step: 9
Training loss: 1.381765604019165
Validation loss: 2.1262193456772835

Epoch: 5| Step: 10
Training loss: 1.6237423419952393
Validation loss: 2.0613326488002652

Epoch: 229| Step: 0
Training loss: 1.3880629539489746
Validation loss: 2.052484203410405

Epoch: 5| Step: 1
Training loss: 1.7569156885147095
Validation loss: 2.0539018389999226

Epoch: 5| Step: 2
Training loss: 1.8622421026229858
Validation loss: 2.0448701202228503

Epoch: 5| Step: 3
Training loss: 1.3322553634643555
Validation loss: 2.044896456503099

Epoch: 5| Step: 4
Training loss: 2.0071988105773926
Validation loss: 2.0452916186342955

Epoch: 5| Step: 5
Training loss: 0.4815642833709717
Validation loss: 2.074480956600558

Epoch: 5| Step: 6
Training loss: 1.510080099105835
Validation loss: 2.094664622378606

Epoch: 5| Step: 7
Training loss: 1.6367841958999634
Validation loss: 2.0825566707118863

Epoch: 5| Step: 8
Training loss: 1.5501759052276611
Validation loss: 2.0817271278750513

Epoch: 5| Step: 9
Training loss: 1.6888309717178345
Validation loss: 2.101486767491987

Epoch: 5| Step: 10
Training loss: 1.340349793434143
Validation loss: 2.099385440990489

Epoch: 230| Step: 0
Training loss: 1.689368486404419
Validation loss: 2.0893139890445176

Epoch: 5| Step: 1
Training loss: 1.9293372631072998
Validation loss: 2.092060512112033

Epoch: 5| Step: 2
Training loss: 1.61831533908844
Validation loss: 2.105584854720741

Epoch: 5| Step: 3
Training loss: 1.5463180541992188
Validation loss: 2.094716884756601

Epoch: 5| Step: 4
Training loss: 1.0869886875152588
Validation loss: 2.1209679021630237

Epoch: 5| Step: 5
Training loss: 1.0387943983078003
Validation loss: 2.1126190654693113

Epoch: 5| Step: 6
Training loss: 1.2136435508728027
Validation loss: 2.1203878182236866

Epoch: 5| Step: 7
Training loss: 1.9600995779037476
Validation loss: 2.10853636136619

Epoch: 5| Step: 8
Training loss: 1.5953199863433838
Validation loss: 2.1055013184906333

Epoch: 5| Step: 9
Training loss: 1.3537218570709229
Validation loss: 2.1189682663127942

Epoch: 5| Step: 10
Training loss: 1.4708678722381592
Validation loss: 2.105570553451456

Epoch: 231| Step: 0
Training loss: 1.6911777257919312
Validation loss: 2.1023687072979507

Epoch: 5| Step: 1
Training loss: 1.2526649236679077
Validation loss: 2.104094138709448

Epoch: 5| Step: 2
Training loss: 1.1829564571380615
Validation loss: 2.1169126251692414

Epoch: 5| Step: 3
Training loss: 1.8701629638671875
Validation loss: 2.100522759140179

Epoch: 5| Step: 4
Training loss: 1.4667425155639648
Validation loss: 2.095459324057384

Epoch: 5| Step: 5
Training loss: 1.3965705633163452
Validation loss: 2.073485553905528

Epoch: 5| Step: 6
Training loss: 0.7218173742294312
Validation loss: 2.051408580554429

Epoch: 5| Step: 7
Training loss: 1.8540277481079102
Validation loss: 2.0506663424994356

Epoch: 5| Step: 8
Training loss: 1.6501973867416382
Validation loss: 2.0535228124228855

Epoch: 5| Step: 9
Training loss: 1.3784395456314087
Validation loss: 2.057869036992391

Epoch: 5| Step: 10
Training loss: 1.8137741088867188
Validation loss: 2.090532572038712

Epoch: 232| Step: 0
Training loss: 1.0012699365615845
Validation loss: 2.0849058179445166

Epoch: 5| Step: 1
Training loss: 1.525154948234558
Validation loss: 2.055660519548642

Epoch: 5| Step: 2
Training loss: 1.681272268295288
Validation loss: 2.0507832855306645

Epoch: 5| Step: 3
Training loss: 1.404581904411316
Validation loss: 2.072628298113423

Epoch: 5| Step: 4
Training loss: 1.484678030014038
Validation loss: 2.054738759994507

Epoch: 5| Step: 5
Training loss: 1.8337246179580688
Validation loss: 2.0558241195576166

Epoch: 5| Step: 6
Training loss: 1.0417006015777588
Validation loss: 2.0642210693769556

Epoch: 5| Step: 7
Training loss: 1.2342811822891235
Validation loss: 2.063669567467064

Epoch: 5| Step: 8
Training loss: 1.9752289056777954
Validation loss: 2.1067537979413102

Epoch: 5| Step: 9
Training loss: 1.479933500289917
Validation loss: 2.1336806563920874

Epoch: 5| Step: 10
Training loss: 1.783281683921814
Validation loss: 2.086917959233766

Epoch: 233| Step: 0
Training loss: 1.4183884859085083
Validation loss: 2.0470270085078415

Epoch: 5| Step: 1
Training loss: 1.7790496349334717
Validation loss: 2.0375646801405054

Epoch: 5| Step: 2
Training loss: 1.6532928943634033
Validation loss: 2.0713961150056575

Epoch: 5| Step: 3
Training loss: 1.7222799062728882
Validation loss: 2.041410202621132

Epoch: 5| Step: 4
Training loss: 1.5337131023406982
Validation loss: 2.057133472093972

Epoch: 5| Step: 5
Training loss: 1.6258951425552368
Validation loss: 2.044687569782298

Epoch: 5| Step: 6
Training loss: 1.7526439428329468
Validation loss: 2.059018829817413

Epoch: 5| Step: 7
Training loss: 0.8217149972915649
Validation loss: 2.077725721943763

Epoch: 5| Step: 8
Training loss: 1.6101372241973877
Validation loss: 2.1463026974790838

Epoch: 5| Step: 9
Training loss: 1.4978901147842407
Validation loss: 2.17006746415169

Epoch: 5| Step: 10
Training loss: 1.8120336532592773
Validation loss: 2.1513704202508412

Epoch: 234| Step: 0
Training loss: 1.1346089839935303
Validation loss: 2.0930909879745974

Epoch: 5| Step: 1
Training loss: 1.242706298828125
Validation loss: 2.055943041719416

Epoch: 5| Step: 2
Training loss: 1.8098360300064087
Validation loss: 2.068167773626184

Epoch: 5| Step: 3
Training loss: 1.6146587133407593
Validation loss: 2.064034382502238

Epoch: 5| Step: 4
Training loss: 1.7845439910888672
Validation loss: 2.0531980145362114

Epoch: 5| Step: 5
Training loss: 1.8303439617156982
Validation loss: 2.0616308091789164

Epoch: 5| Step: 6
Training loss: 1.9481165409088135
Validation loss: 2.058093987485414

Epoch: 5| Step: 7
Training loss: 0.9884415864944458
Validation loss: 2.0481776704070387

Epoch: 5| Step: 8
Training loss: 1.2670496702194214
Validation loss: 2.0724575468288955

Epoch: 5| Step: 9
Training loss: 1.9687076807022095
Validation loss: 2.125711287221601

Epoch: 5| Step: 10
Training loss: 1.7775144577026367
Validation loss: 2.1214046503907893

Epoch: 235| Step: 0
Training loss: 2.270721912384033
Validation loss: 2.112323368749311

Epoch: 5| Step: 1
Training loss: 1.2537633180618286
Validation loss: 2.083323488953293

Epoch: 5| Step: 2
Training loss: 1.577528715133667
Validation loss: 2.079065671531103

Epoch: 5| Step: 3
Training loss: 1.3354839086532593
Validation loss: 2.063841414707963

Epoch: 5| Step: 4
Training loss: 1.54875910282135
Validation loss: 2.093592796274411

Epoch: 5| Step: 5
Training loss: 1.899728775024414
Validation loss: 2.0963167708407164

Epoch: 5| Step: 6
Training loss: 1.7267825603485107
Validation loss: 2.094981296088106

Epoch: 5| Step: 7
Training loss: 1.2887276411056519
Validation loss: 2.0580465742336806

Epoch: 5| Step: 8
Training loss: 0.6394937038421631
Validation loss: 2.0532776873598815

Epoch: 5| Step: 9
Training loss: 1.5726754665374756
Validation loss: 2.1207794143307592

Epoch: 5| Step: 10
Training loss: 1.5077944993972778
Validation loss: 2.1441525592598865

Epoch: 236| Step: 0
Training loss: 1.3131624460220337
Validation loss: 2.115108290026265

Epoch: 5| Step: 1
Training loss: 1.172528862953186
Validation loss: 2.053123915067283

Epoch: 5| Step: 2
Training loss: 1.9892632961273193
Validation loss: 2.061718166515391

Epoch: 5| Step: 3
Training loss: 1.1343562602996826
Validation loss: 2.0825587805881294

Epoch: 5| Step: 4
Training loss: 1.326631784439087
Validation loss: 2.0738469528895553

Epoch: 5| Step: 5
Training loss: 1.6638119220733643
Validation loss: 2.07207667058514

Epoch: 5| Step: 6
Training loss: 1.955798864364624
Validation loss: 2.0846614401827575

Epoch: 5| Step: 7
Training loss: 1.9156043529510498
Validation loss: 2.0690692688829158

Epoch: 5| Step: 8
Training loss: 1.2561455965042114
Validation loss: 2.0492552762390464

Epoch: 5| Step: 9
Training loss: 1.64055597782135
Validation loss: 2.1033703614306707

Epoch: 5| Step: 10
Training loss: 0.9471590518951416
Validation loss: 2.118820719821479

Epoch: 237| Step: 0
Training loss: 0.9700518846511841
Validation loss: 2.1374992555187595

Epoch: 5| Step: 1
Training loss: 1.6027042865753174
Validation loss: 2.095397064762731

Epoch: 5| Step: 2
Training loss: 1.432819128036499
Validation loss: 2.088133382540877

Epoch: 5| Step: 3
Training loss: 1.483073353767395
Validation loss: 2.0658745534958376

Epoch: 5| Step: 4
Training loss: 1.32374107837677
Validation loss: 2.0874381116641465

Epoch: 5| Step: 5
Training loss: 1.7155942916870117
Validation loss: 2.0832204972544024

Epoch: 5| Step: 6
Training loss: 1.3562467098236084
Validation loss: 2.068626699909087

Epoch: 5| Step: 7
Training loss: 1.888634443283081
Validation loss: 2.1167784390910978

Epoch: 5| Step: 8
Training loss: 1.6761401891708374
Validation loss: 2.1115524794465754

Epoch: 5| Step: 9
Training loss: 1.1638212203979492
Validation loss: 2.099549621664068

Epoch: 5| Step: 10
Training loss: 1.825866937637329
Validation loss: 2.1065568847040974

Epoch: 238| Step: 0
Training loss: 1.7533981800079346
Validation loss: 2.130222811493822

Epoch: 5| Step: 1
Training loss: 1.6931473016738892
Validation loss: 2.122120475256315

Epoch: 5| Step: 2
Training loss: 1.7799503803253174
Validation loss: 2.0537857112064155

Epoch: 5| Step: 3
Training loss: 1.4012728929519653
Validation loss: 2.069041185481574

Epoch: 5| Step: 4
Training loss: 1.4808199405670166
Validation loss: 2.0762084222609

Epoch: 5| Step: 5
Training loss: 1.6577783823013306
Validation loss: 2.0770862743418705

Epoch: 5| Step: 6
Training loss: 1.3489739894866943
Validation loss: 2.0693040381195726

Epoch: 5| Step: 7
Training loss: 0.7293688654899597
Validation loss: 2.05299900936824

Epoch: 5| Step: 8
Training loss: 1.2176158428192139
Validation loss: 2.058619228742456

Epoch: 5| Step: 9
Training loss: 1.878204345703125
Validation loss: 2.1240318949504564

Epoch: 5| Step: 10
Training loss: 1.291656494140625
Validation loss: 2.1337168319250948

Epoch: 239| Step: 0
Training loss: 1.4101871252059937
Validation loss: 2.1179389825431247

Epoch: 5| Step: 1
Training loss: 1.3211917877197266
Validation loss: 2.0799889026149625

Epoch: 5| Step: 2
Training loss: 1.2298619747161865
Validation loss: 2.058000001856076

Epoch: 5| Step: 3
Training loss: 1.4483674764633179
Validation loss: 2.0442957237202632

Epoch: 5| Step: 4
Training loss: 1.9633592367172241
Validation loss: 2.0355399706030406

Epoch: 5| Step: 5
Training loss: 1.914860725402832
Validation loss: 2.0396883961974934

Epoch: 5| Step: 6
Training loss: 1.1404216289520264
Validation loss: 2.0653355595886067

Epoch: 5| Step: 7
Training loss: 1.5236358642578125
Validation loss: 2.070452772161012

Epoch: 5| Step: 8
Training loss: 1.5368655920028687
Validation loss: 2.0932361951438327

Epoch: 5| Step: 9
Training loss: 1.0403214693069458
Validation loss: 2.063136036678027

Epoch: 5| Step: 10
Training loss: 1.197765827178955
Validation loss: 2.0599127943797777

Epoch: 240| Step: 0
Training loss: 1.6396958827972412
Validation loss: 2.0598955833783714

Epoch: 5| Step: 1
Training loss: 1.4432986974716187
Validation loss: 2.0727491430056992

Epoch: 5| Step: 2
Training loss: 0.9757469296455383
Validation loss: 2.0510103087271414

Epoch: 5| Step: 3
Training loss: 1.2397700548171997
Validation loss: 2.0452939976928053

Epoch: 5| Step: 4
Training loss: 1.4778510332107544
Validation loss: 2.0239222075349543

Epoch: 5| Step: 5
Training loss: 1.1690794229507446
Validation loss: 2.0250427876749346

Epoch: 5| Step: 6
Training loss: 0.9965735673904419
Validation loss: 2.0177127956062235

Epoch: 5| Step: 7
Training loss: 1.1239207983016968
Validation loss: 2.0208679091545845

Epoch: 5| Step: 8
Training loss: 1.653472900390625
Validation loss: 2.037611944701082

Epoch: 5| Step: 9
Training loss: 2.043994426727295
Validation loss: 2.0508022410895235

Epoch: 5| Step: 10
Training loss: 2.102557420730591
Validation loss: 2.1128243682205037

Epoch: 241| Step: 0
Training loss: 1.6856276988983154
Validation loss: 2.127502933625252

Epoch: 5| Step: 1
Training loss: 1.8193836212158203
Validation loss: 2.0991265030317408

Epoch: 5| Step: 2
Training loss: 1.5048730373382568
Validation loss: 2.0868628691601496

Epoch: 5| Step: 3
Training loss: 1.747096300125122
Validation loss: 2.0729724437959733

Epoch: 5| Step: 4
Training loss: 1.2957572937011719
Validation loss: 2.060936330467142

Epoch: 5| Step: 5
Training loss: 1.24786376953125
Validation loss: 2.0653825882942445

Epoch: 5| Step: 6
Training loss: 1.6344337463378906
Validation loss: 2.0575030529370872

Epoch: 5| Step: 7
Training loss: 1.369478464126587
Validation loss: 2.0505224991870183

Epoch: 5| Step: 8
Training loss: 1.2020319700241089
Validation loss: 2.026845326987646

Epoch: 5| Step: 9
Training loss: 1.0241971015930176
Validation loss: 2.0115471604049846

Epoch: 5| Step: 10
Training loss: 1.3838409185409546
Validation loss: 2.058529071910407

Epoch: 242| Step: 0
Training loss: 1.8436577320098877
Validation loss: 2.113500546383601

Epoch: 5| Step: 1
Training loss: 0.7067266702651978
Validation loss: 2.097067548382667

Epoch: 5| Step: 2
Training loss: 1.6966009140014648
Validation loss: 2.060567089306411

Epoch: 5| Step: 3
Training loss: 2.0532374382019043
Validation loss: 2.0419672560948197

Epoch: 5| Step: 4
Training loss: 1.537692666053772
Validation loss: 2.033421672800536

Epoch: 5| Step: 5
Training loss: 1.1385393142700195
Validation loss: 2.0593344319251274

Epoch: 5| Step: 6
Training loss: 1.427196741104126
Validation loss: 2.0608389941594933

Epoch: 5| Step: 7
Training loss: 1.4991590976715088
Validation loss: 2.0646044361975884

Epoch: 5| Step: 8
Training loss: 1.4581787586212158
Validation loss: 2.079672844179215

Epoch: 5| Step: 9
Training loss: 1.2374907732009888
Validation loss: 2.0586990259026967

Epoch: 5| Step: 10
Training loss: 1.619990348815918
Validation loss: 2.059820698153588

Epoch: 243| Step: 0
Training loss: 2.3964831829071045
Validation loss: 2.1170018462724585

Epoch: 5| Step: 1
Training loss: 1.3961800336837769
Validation loss: 2.100963698920383

Epoch: 5| Step: 2
Training loss: 1.258007287979126
Validation loss: 2.080230279635358

Epoch: 5| Step: 3
Training loss: 1.5344820022583008
Validation loss: 2.0720619386242283

Epoch: 5| Step: 4
Training loss: 1.1914653778076172
Validation loss: 2.0859869603187806

Epoch: 5| Step: 5
Training loss: 1.3023390769958496
Validation loss: 2.0949261701235207

Epoch: 5| Step: 6
Training loss: 1.1916996240615845
Validation loss: 2.062788309589509

Epoch: 5| Step: 7
Training loss: 2.0133697986602783
Validation loss: 2.05253012975057

Epoch: 5| Step: 8
Training loss: 1.557314157485962
Validation loss: 2.0399279658512404

Epoch: 5| Step: 9
Training loss: 0.710546612739563
Validation loss: 2.0558286674561037

Epoch: 5| Step: 10
Training loss: 1.4887099266052246
Validation loss: 2.0738995203407864

Epoch: 244| Step: 0
Training loss: 1.663657784461975
Validation loss: 2.0554020404815674

Epoch: 5| Step: 1
Training loss: 1.1540018320083618
Validation loss: 2.0424495691894204

Epoch: 5| Step: 2
Training loss: 1.4917799234390259
Validation loss: 2.060454691610029

Epoch: 5| Step: 3
Training loss: 1.314040184020996
Validation loss: 2.0693497106593144

Epoch: 5| Step: 4
Training loss: 1.8472532033920288
Validation loss: 2.0894503029443885

Epoch: 5| Step: 5
Training loss: 1.6906780004501343
Validation loss: 2.066736098258726

Epoch: 5| Step: 6
Training loss: 1.5906401872634888
Validation loss: 2.0568638193991875

Epoch: 5| Step: 7
Training loss: 1.0366779565811157
Validation loss: 2.068407917535433

Epoch: 5| Step: 8
Training loss: 1.352445363998413
Validation loss: 2.075010176627867

Epoch: 5| Step: 9
Training loss: 1.2804886102676392
Validation loss: 2.093448228733514

Epoch: 5| Step: 10
Training loss: 1.2180700302124023
Validation loss: 2.0621556440989175

Epoch: 245| Step: 0
Training loss: 1.4818401336669922
Validation loss: 2.057967571802037

Epoch: 5| Step: 1
Training loss: 1.218887209892273
Validation loss: 2.0544100371740197

Epoch: 5| Step: 2
Training loss: 1.8462190628051758
Validation loss: 2.0614751385104273

Epoch: 5| Step: 3
Training loss: 1.2393505573272705
Validation loss: 2.0786083616236204

Epoch: 5| Step: 4
Training loss: 1.073754072189331
Validation loss: 2.085229368620021

Epoch: 5| Step: 5
Training loss: 0.9954074025154114
Validation loss: 2.094611637053951

Epoch: 5| Step: 6
Training loss: 1.4230356216430664
Validation loss: 2.069866854657409

Epoch: 5| Step: 7
Training loss: 1.406963586807251
Validation loss: 2.0574278036753335

Epoch: 5| Step: 8
Training loss: 1.5035362243652344
Validation loss: 2.07355994947495

Epoch: 5| Step: 9
Training loss: 1.884039282798767
Validation loss: 2.0697604225527857

Epoch: 5| Step: 10
Training loss: 1.1163053512573242
Validation loss: 2.0531831120931976

Epoch: 246| Step: 0
Training loss: 0.8809555172920227
Validation loss: 2.0658897840848534

Epoch: 5| Step: 1
Training loss: 1.4657983779907227
Validation loss: 2.0563296182181245

Epoch: 5| Step: 2
Training loss: 1.1189593076705933
Validation loss: 2.046746237303621

Epoch: 5| Step: 3
Training loss: 1.417276382446289
Validation loss: 2.0307419069351687

Epoch: 5| Step: 4
Training loss: 1.453173041343689
Validation loss: 2.044755769032304

Epoch: 5| Step: 5
Training loss: 1.3390341997146606
Validation loss: 2.0267914097796202

Epoch: 5| Step: 6
Training loss: 1.1341146230697632
Validation loss: 2.018778847109887

Epoch: 5| Step: 7
Training loss: 1.797774314880371
Validation loss: 2.016169403188972

Epoch: 5| Step: 8
Training loss: 1.4333257675170898
Validation loss: 2.0170540155902987

Epoch: 5| Step: 9
Training loss: 1.4145176410675049
Validation loss: 1.9971368787109212

Epoch: 5| Step: 10
Training loss: 1.7840890884399414
Validation loss: 2.01903711852207

Epoch: 247| Step: 0
Training loss: 1.7121694087982178
Validation loss: 2.021256809593529

Epoch: 5| Step: 1
Training loss: 0.8386834859848022
Validation loss: 2.0411007737600677

Epoch: 5| Step: 2
Training loss: 1.119519829750061
Validation loss: 2.0553033633898665

Epoch: 5| Step: 3
Training loss: 1.6105802059173584
Validation loss: 2.060240545580464

Epoch: 5| Step: 4
Training loss: 1.1004106998443604
Validation loss: 2.0576286905555317

Epoch: 5| Step: 5
Training loss: 1.5476890802383423
Validation loss: 2.0647702729830177

Epoch: 5| Step: 6
Training loss: 1.3423621654510498
Validation loss: 2.0552759375623477

Epoch: 5| Step: 7
Training loss: 1.5653468370437622
Validation loss: 2.0714888239419587

Epoch: 5| Step: 8
Training loss: 0.7906478643417358
Validation loss: 2.057152686580535

Epoch: 5| Step: 9
Training loss: 1.4456384181976318
Validation loss: 2.0952397777188208

Epoch: 5| Step: 10
Training loss: 1.9254043102264404
Validation loss: 2.0761956809669413

Epoch: 248| Step: 0
Training loss: 1.2780635356903076
Validation loss: 2.059944232304891

Epoch: 5| Step: 1
Training loss: 0.9668774604797363
Validation loss: 2.0314023161447174

Epoch: 5| Step: 2
Training loss: 1.415614128112793
Validation loss: 2.0536327246696717

Epoch: 5| Step: 3
Training loss: 1.557478904724121
Validation loss: 2.036577550313806

Epoch: 5| Step: 4
Training loss: 1.384190320968628
Validation loss: 2.0409568279020247

Epoch: 5| Step: 5
Training loss: 1.2891196012496948
Validation loss: 2.028591743079565

Epoch: 5| Step: 6
Training loss: 1.5032786130905151
Validation loss: 2.0418414723488594

Epoch: 5| Step: 7
Training loss: 1.4235329627990723
Validation loss: 2.0419115379292476

Epoch: 5| Step: 8
Training loss: 1.384402871131897
Validation loss: 2.0524804899769444

Epoch: 5| Step: 9
Training loss: 1.6743751764297485
Validation loss: 2.04456397538544

Epoch: 5| Step: 10
Training loss: 0.873593807220459
Validation loss: 2.033613807411604

Epoch: 249| Step: 0
Training loss: 1.9050865173339844
Validation loss: 2.0434297925682476

Epoch: 5| Step: 1
Training loss: 1.4936870336532593
Validation loss: 2.019200876194944

Epoch: 5| Step: 2
Training loss: 1.3611767292022705
Validation loss: 2.014658010134133

Epoch: 5| Step: 3
Training loss: 1.0507081747055054
Validation loss: 2.0094775884382186

Epoch: 5| Step: 4
Training loss: 1.443652868270874
Validation loss: 2.0132489742771273

Epoch: 5| Step: 5
Training loss: 1.320676565170288
Validation loss: 2.0048800501772153

Epoch: 5| Step: 6
Training loss: 1.1081793308258057
Validation loss: 2.029753270969596

Epoch: 5| Step: 7
Training loss: 1.4716336727142334
Validation loss: 2.024968929188226

Epoch: 5| Step: 8
Training loss: 1.3020045757293701
Validation loss: 1.9951045179879794

Epoch: 5| Step: 9
Training loss: 1.1925181150436401
Validation loss: 1.9973553162749096

Epoch: 5| Step: 10
Training loss: 1.3958441019058228
Validation loss: 2.0213580298167404

Epoch: 250| Step: 0
Training loss: 1.2812268733978271
Validation loss: 2.024494949207511

Epoch: 5| Step: 1
Training loss: 1.4669017791748047
Validation loss: 2.0571441445299374

Epoch: 5| Step: 2
Training loss: 1.8065845966339111
Validation loss: 2.0587444433601956

Epoch: 5| Step: 3
Training loss: 0.9513498544692993
Validation loss: 2.0466108347779963

Epoch: 5| Step: 4
Training loss: 1.1256942749023438
Validation loss: 2.015822743856779

Epoch: 5| Step: 5
Training loss: 1.2317218780517578
Validation loss: 2.031609724926692

Epoch: 5| Step: 6
Training loss: 1.5906823873519897
Validation loss: 2.0309080064937635

Epoch: 5| Step: 7
Training loss: 1.4591549634933472
Validation loss: 2.028971802803778

Epoch: 5| Step: 8
Training loss: 1.342279076576233
Validation loss: 2.0195417814357306

Epoch: 5| Step: 9
Training loss: 1.2083901166915894
Validation loss: 2.0478428179217922

Epoch: 5| Step: 10
Training loss: 1.6819709539413452
Validation loss: 2.0708705122752855

Epoch: 251| Step: 0
Training loss: 1.2801042795181274
Validation loss: 2.0718344437178744

Epoch: 5| Step: 1
Training loss: 1.6711286306381226
Validation loss: 2.0358079069404194

Epoch: 5| Step: 2
Training loss: 0.80498206615448
Validation loss: 2.030757215715224

Epoch: 5| Step: 3
Training loss: 1.5717270374298096
Validation loss: 2.003508637028356

Epoch: 5| Step: 4
Training loss: 1.2756068706512451
Validation loss: 2.012272814268707

Epoch: 5| Step: 5
Training loss: 1.0044114589691162
Validation loss: 1.9930002497088524

Epoch: 5| Step: 6
Training loss: 1.2633179426193237
Validation loss: 2.033788796394102

Epoch: 5| Step: 7
Training loss: 1.7992188930511475
Validation loss: 2.013086913734354

Epoch: 5| Step: 8
Training loss: 1.0532314777374268
Validation loss: 2.0015934116096905

Epoch: 5| Step: 9
Training loss: 1.1188851594924927
Validation loss: 2.0284308592478433

Epoch: 5| Step: 10
Training loss: 1.7901707887649536
Validation loss: 2.0277758875200824

Epoch: 252| Step: 0
Training loss: 1.3479831218719482
Validation loss: 2.0566730678722425

Epoch: 5| Step: 1
Training loss: 1.4174798727035522
Validation loss: 2.0745061059151926

Epoch: 5| Step: 2
Training loss: 1.4387061595916748
Validation loss: 2.079892767372952

Epoch: 5| Step: 3
Training loss: 1.1667449474334717
Validation loss: 2.0731276107090775

Epoch: 5| Step: 4
Training loss: 1.5705630779266357
Validation loss: 2.078654853246545

Epoch: 5| Step: 5
Training loss: 1.0901429653167725
Validation loss: 2.053076426188151

Epoch: 5| Step: 6
Training loss: 1.233235239982605
Validation loss: 2.0400739587763304

Epoch: 5| Step: 7
Training loss: 1.190053105354309
Validation loss: 2.027512288862659

Epoch: 5| Step: 8
Training loss: 1.8829662799835205
Validation loss: 1.9967769140838294

Epoch: 5| Step: 9
Training loss: 0.8563112020492554
Validation loss: 1.986923369028235

Epoch: 5| Step: 10
Training loss: 1.213909387588501
Validation loss: 1.9746894849243986

Epoch: 253| Step: 0
Training loss: 1.2169561386108398
Validation loss: 1.9970134176233763

Epoch: 5| Step: 1
Training loss: 1.7863861322402954
Validation loss: 2.0000702104260846

Epoch: 5| Step: 2
Training loss: 1.164052128791809
Validation loss: 1.9714841868287774

Epoch: 5| Step: 3
Training loss: 1.2858712673187256
Validation loss: 1.9514861081236152

Epoch: 5| Step: 4
Training loss: 1.1464242935180664
Validation loss: 1.9497040010267688

Epoch: 5| Step: 5
Training loss: 1.1613820791244507
Validation loss: 1.972990664102698

Epoch: 5| Step: 6
Training loss: 0.7779485583305359
Validation loss: 2.004117550388459

Epoch: 5| Step: 7
Training loss: 1.2311084270477295
Validation loss: 2.0350029058353876

Epoch: 5| Step: 8
Training loss: 1.3076199293136597
Validation loss: 2.032305061176259

Epoch: 5| Step: 9
Training loss: 1.559861421585083
Validation loss: 2.0944417702254428

Epoch: 5| Step: 10
Training loss: 2.1314537525177
Validation loss: 2.128987687890248

Epoch: 254| Step: 0
Training loss: 1.756797194480896
Validation loss: 2.1636159573831866

Epoch: 5| Step: 1
Training loss: 1.4027897119522095
Validation loss: 2.137409876751643

Epoch: 5| Step: 2
Training loss: 1.4164059162139893
Validation loss: 2.099677115358332

Epoch: 5| Step: 3
Training loss: 1.3882770538330078
Validation loss: 2.0987234884692776

Epoch: 5| Step: 4
Training loss: 1.695879578590393
Validation loss: 2.0955303945849018

Epoch: 5| Step: 5
Training loss: 1.38388192653656
Validation loss: 2.0495272605649886

Epoch: 5| Step: 6
Training loss: 1.1802955865859985
Validation loss: 2.0355361700057983

Epoch: 5| Step: 7
Training loss: 1.5943514108657837
Validation loss: 1.9993509836094354

Epoch: 5| Step: 8
Training loss: 1.307620882987976
Validation loss: 1.9875024339204193

Epoch: 5| Step: 9
Training loss: 1.2209315299987793
Validation loss: 2.0080461860984884

Epoch: 5| Step: 10
Training loss: 1.0894782543182373
Validation loss: 2.0064541370637956

Epoch: 255| Step: 0
Training loss: 1.0238018035888672
Validation loss: 2.0307699749546666

Epoch: 5| Step: 1
Training loss: 1.6295474767684937
Validation loss: 2.043739611102689

Epoch: 5| Step: 2
Training loss: 1.5259774923324585
Validation loss: 2.013298019286125

Epoch: 5| Step: 3
Training loss: 0.9285286664962769
Validation loss: 1.9950843126543107

Epoch: 5| Step: 4
Training loss: 1.2838611602783203
Validation loss: 2.0011374027498308

Epoch: 5| Step: 5
Training loss: 1.3509918451309204
Validation loss: 2.0263297506558

Epoch: 5| Step: 6
Training loss: 1.4794915914535522
Validation loss: 2.041805690334689

Epoch: 5| Step: 7
Training loss: 1.352191686630249
Validation loss: 2.0555028274495113

Epoch: 5| Step: 8
Training loss: 1.2781472206115723
Validation loss: 2.0704760089997323

Epoch: 5| Step: 9
Training loss: 1.3004570007324219
Validation loss: 2.0696039943284887

Epoch: 5| Step: 10
Training loss: 1.4981027841567993
Validation loss: 2.061107417588593

Epoch: 256| Step: 0
Training loss: 0.9506546258926392
Validation loss: 2.091798790039555

Epoch: 5| Step: 1
Training loss: 1.1370055675506592
Validation loss: 2.0761960321857083

Epoch: 5| Step: 2
Training loss: 1.7072551250457764
Validation loss: 2.0566778644438712

Epoch: 5| Step: 3
Training loss: 1.1747777462005615
Validation loss: 2.0428306069425357

Epoch: 5| Step: 4
Training loss: 1.5982552766799927
Validation loss: 2.0226064625606743

Epoch: 5| Step: 5
Training loss: 1.3002420663833618
Validation loss: 2.01189753829792

Epoch: 5| Step: 6
Training loss: 1.65227472782135
Validation loss: 2.0158820716283654

Epoch: 5| Step: 7
Training loss: 1.3749549388885498
Validation loss: 2.023901095954321

Epoch: 5| Step: 8
Training loss: 1.090341329574585
Validation loss: 2.011235688322334

Epoch: 5| Step: 9
Training loss: 1.1035411357879639
Validation loss: 2.0775258412925144

Epoch: 5| Step: 10
Training loss: 1.5299243927001953
Validation loss: 2.099352659717683

Epoch: 257| Step: 0
Training loss: 1.0739115476608276
Validation loss: 2.094133648821103

Epoch: 5| Step: 1
Training loss: 1.3219062089920044
Validation loss: 2.0483768934844644

Epoch: 5| Step: 2
Training loss: 1.3948546648025513
Validation loss: 2.0495582293438654

Epoch: 5| Step: 3
Training loss: 1.4142781496047974
Validation loss: 2.067248514903489

Epoch: 5| Step: 4
Training loss: 1.2363710403442383
Validation loss: 2.074277654770882

Epoch: 5| Step: 5
Training loss: 1.3016701936721802
Validation loss: 2.055818715403157

Epoch: 5| Step: 6
Training loss: 1.6253999471664429
Validation loss: 2.046326414231331

Epoch: 5| Step: 7
Training loss: 0.9589837193489075
Validation loss: 2.0673951333568943

Epoch: 5| Step: 8
Training loss: 1.8029429912567139
Validation loss: 2.090127024599301

Epoch: 5| Step: 9
Training loss: 1.3001692295074463
Validation loss: 2.0930571094635995

Epoch: 5| Step: 10
Training loss: 1.4259097576141357
Validation loss: 2.0489619034592823

Epoch: 258| Step: 0
Training loss: 1.0823819637298584
Validation loss: 2.0381916710125503

Epoch: 5| Step: 1
Training loss: 1.3273086547851562
Validation loss: 2.031843703280213

Epoch: 5| Step: 2
Training loss: 1.4931230545043945
Validation loss: 2.01551224852121

Epoch: 5| Step: 3
Training loss: 1.6050230264663696
Validation loss: 2.0076556936387093

Epoch: 5| Step: 4
Training loss: 1.1032384634017944
Validation loss: 2.006102054349838

Epoch: 5| Step: 5
Training loss: 1.3251279592514038
Validation loss: 2.0020857677664807

Epoch: 5| Step: 6
Training loss: 1.3826439380645752
Validation loss: 2.0120485328858897

Epoch: 5| Step: 7
Training loss: 1.2152948379516602
Validation loss: 2.0060308799948743

Epoch: 5| Step: 8
Training loss: 1.0563721656799316
Validation loss: 2.0050694737383115

Epoch: 5| Step: 9
Training loss: 1.4964077472686768
Validation loss: 2.0031498721850816

Epoch: 5| Step: 10
Training loss: 1.2087122201919556
Validation loss: 1.9908444817348192

Epoch: 259| Step: 0
Training loss: 1.180199384689331
Validation loss: 1.9864735987878614

Epoch: 5| Step: 1
Training loss: 1.3652900457382202
Validation loss: 1.968841984707822

Epoch: 5| Step: 2
Training loss: 1.136231541633606
Validation loss: 1.9895861366743683

Epoch: 5| Step: 3
Training loss: 1.3694124221801758
Validation loss: 1.9602358571944698

Epoch: 5| Step: 4
Training loss: 1.1773123741149902
Validation loss: 2.000149316685174

Epoch: 5| Step: 5
Training loss: 0.9787117838859558
Validation loss: 1.985779578967761

Epoch: 5| Step: 6
Training loss: 1.560058355331421
Validation loss: 1.996704109253422

Epoch: 5| Step: 7
Training loss: 1.4468481540679932
Validation loss: 1.9880765458588958

Epoch: 5| Step: 8
Training loss: 1.05649733543396
Validation loss: 2.0130019803201

Epoch: 5| Step: 9
Training loss: 1.3972415924072266
Validation loss: 2.0066193867755193

Epoch: 5| Step: 10
Training loss: 1.209808588027954
Validation loss: 2.0092106634570706

Epoch: 260| Step: 0
Training loss: 1.1462942361831665
Validation loss: 2.010471979777018

Epoch: 5| Step: 1
Training loss: 1.3262906074523926
Validation loss: 2.025693844723445

Epoch: 5| Step: 2
Training loss: 1.485365629196167
Validation loss: 2.022716191507155

Epoch: 5| Step: 3
Training loss: 1.0595659017562866
Validation loss: 2.031527126989057

Epoch: 5| Step: 4
Training loss: 1.602668046951294
Validation loss: 2.029919280800768

Epoch: 5| Step: 5
Training loss: 1.468414306640625
Validation loss: 2.0342548765161985

Epoch: 5| Step: 6
Training loss: 1.1178172826766968
Validation loss: 2.0299440519784087

Epoch: 5| Step: 7
Training loss: 1.3866865634918213
Validation loss: 2.048183625744235

Epoch: 5| Step: 8
Training loss: 0.9704095125198364
Validation loss: 2.047665501153597

Epoch: 5| Step: 9
Training loss: 1.0999486446380615
Validation loss: 2.04059410736125

Epoch: 5| Step: 10
Training loss: 0.8687941431999207
Validation loss: 2.0344278376589537

Epoch: 261| Step: 0
Training loss: 1.433729887008667
Validation loss: 2.0233227847724833

Epoch: 5| Step: 1
Training loss: 1.1684277057647705
Validation loss: 2.038466151042651

Epoch: 5| Step: 2
Training loss: 1.4920949935913086
Validation loss: 2.019982235406035

Epoch: 5| Step: 3
Training loss: 1.5203654766082764
Validation loss: 2.02852499997744

Epoch: 5| Step: 4
Training loss: 0.7756203413009644
Validation loss: 2.023038879517586

Epoch: 5| Step: 5
Training loss: 0.9372862577438354
Validation loss: 2.009356553836535

Epoch: 5| Step: 6
Training loss: 1.2221636772155762
Validation loss: 1.9953540582810678

Epoch: 5| Step: 7
Training loss: 1.278748631477356
Validation loss: 1.9942952125303206

Epoch: 5| Step: 8
Training loss: 1.4431451559066772
Validation loss: 1.9746862970372683

Epoch: 5| Step: 9
Training loss: 0.9359992742538452
Validation loss: 1.9819532825100807

Epoch: 5| Step: 10
Training loss: 1.365196704864502
Validation loss: 1.975548928783786

Epoch: 262| Step: 0
Training loss: 1.5670464038848877
Validation loss: 2.0078989921077603

Epoch: 5| Step: 1
Training loss: 1.2406977415084839
Validation loss: 2.002858249090051

Epoch: 5| Step: 2
Training loss: 1.3441698551177979
Validation loss: 2.024745725816296

Epoch: 5| Step: 3
Training loss: 0.9683858752250671
Validation loss: 2.029308710046994

Epoch: 5| Step: 4
Training loss: 1.2558331489562988
Validation loss: 2.0108026022552163

Epoch: 5| Step: 5
Training loss: 1.100650429725647
Validation loss: 2.00970491286247

Epoch: 5| Step: 6
Training loss: 1.6240355968475342
Validation loss: 2.019936864094068

Epoch: 5| Step: 7
Training loss: 1.2787811756134033
Validation loss: 2.0177183715246056

Epoch: 5| Step: 8
Training loss: 1.1728922128677368
Validation loss: 2.0154171630900395

Epoch: 5| Step: 9
Training loss: 1.1729670763015747
Validation loss: 1.9967217855556036

Epoch: 5| Step: 10
Training loss: 0.7357742190361023
Validation loss: 1.9984913692679456

Epoch: 263| Step: 0
Training loss: 1.5109533071517944
Validation loss: 2.023145547477148

Epoch: 5| Step: 1
Training loss: 1.235733151435852
Validation loss: 2.017938594664297

Epoch: 5| Step: 2
Training loss: 0.7898036241531372
Validation loss: 2.021493334924021

Epoch: 5| Step: 3
Training loss: 1.7088022232055664
Validation loss: 2.00525083849507

Epoch: 5| Step: 4
Training loss: 1.305532693862915
Validation loss: 2.0011928901877454

Epoch: 5| Step: 5
Training loss: 0.9265693426132202
Validation loss: 2.0171126114424838

Epoch: 5| Step: 6
Training loss: 1.0661144256591797
Validation loss: 2.0206519032037384

Epoch: 5| Step: 7
Training loss: 1.1745418310165405
Validation loss: 2.0161486133452384

Epoch: 5| Step: 8
Training loss: 1.234703779220581
Validation loss: 2.0126341337798745

Epoch: 5| Step: 9
Training loss: 0.9367954134941101
Validation loss: 2.0169766872159895

Epoch: 5| Step: 10
Training loss: 1.5260767936706543
Validation loss: 2.00835415112075

Epoch: 264| Step: 0
Training loss: 1.008709192276001
Validation loss: 2.007512233590567

Epoch: 5| Step: 1
Training loss: 1.1449930667877197
Validation loss: 2.004839030645227

Epoch: 5| Step: 2
Training loss: 1.6988518238067627
Validation loss: 2.018488032843477

Epoch: 5| Step: 3
Training loss: 1.3035762310028076
Validation loss: 2.0173269753815024

Epoch: 5| Step: 4
Training loss: 1.246849775314331
Validation loss: 2.02118613643031

Epoch: 5| Step: 5
Training loss: 1.1625888347625732
Validation loss: 2.006709489771115

Epoch: 5| Step: 6
Training loss: 0.9412689208984375
Validation loss: 2.029123379338172

Epoch: 5| Step: 7
Training loss: 0.7398730516433716
Validation loss: 2.0074597968850085

Epoch: 5| Step: 8
Training loss: 1.2485162019729614
Validation loss: 2.0221465851670954

Epoch: 5| Step: 9
Training loss: 1.197267770767212
Validation loss: 2.0055150037170737

Epoch: 5| Step: 10
Training loss: 1.500366449356079
Validation loss: 2.018084890098982

Epoch: 265| Step: 0
Training loss: 0.906940758228302
Validation loss: 2.001310517711024

Epoch: 5| Step: 1
Training loss: 1.2301020622253418
Validation loss: 1.9970794544425061

Epoch: 5| Step: 2
Training loss: 1.4545412063598633
Validation loss: 1.9773431131916661

Epoch: 5| Step: 3
Training loss: 1.4743446111679077
Validation loss: 1.972529572825278

Epoch: 5| Step: 4
Training loss: 1.1010158061981201
Validation loss: 1.9791834585128292

Epoch: 5| Step: 5
Training loss: 0.5942050814628601
Validation loss: 1.9934685678892239

Epoch: 5| Step: 6
Training loss: 1.682187795639038
Validation loss: 2.0153237786344302

Epoch: 5| Step: 7
Training loss: 1.484376311302185
Validation loss: 2.003779313897574

Epoch: 5| Step: 8
Training loss: 1.002225637435913
Validation loss: 2.0139991583362704

Epoch: 5| Step: 9
Training loss: 0.9888100624084473
Validation loss: 1.9976128378222067

Epoch: 5| Step: 10
Training loss: 1.3994832038879395
Validation loss: 1.9943959200254051

Epoch: 266| Step: 0
Training loss: 1.4147027730941772
Validation loss: 2.0173657504461144

Epoch: 5| Step: 1
Training loss: 1.3831526041030884
Validation loss: 1.9896205907226892

Epoch: 5| Step: 2
Training loss: 1.2578465938568115
Validation loss: 2.014827084797685

Epoch: 5| Step: 3
Training loss: 0.9843387603759766
Validation loss: 2.0317878133507183

Epoch: 5| Step: 4
Training loss: 1.1990821361541748
Validation loss: 1.9872738930486864

Epoch: 5| Step: 5
Training loss: 0.637461245059967
Validation loss: 1.999652002447395

Epoch: 5| Step: 6
Training loss: 1.3032325506210327
Validation loss: 1.992718788885301

Epoch: 5| Step: 7
Training loss: 1.2419503927230835
Validation loss: 2.015605242021622

Epoch: 5| Step: 8
Training loss: 1.7812105417251587
Validation loss: 1.9824592938987158

Epoch: 5| Step: 9
Training loss: 1.2300828695297241
Validation loss: 1.9753378245138353

Epoch: 5| Step: 10
Training loss: 0.8101393580436707
Validation loss: 1.9740364115725282

Epoch: 267| Step: 0
Training loss: 1.7273943424224854
Validation loss: 1.951338170677103

Epoch: 5| Step: 1
Training loss: 0.8561512231826782
Validation loss: 1.9651964377331477

Epoch: 5| Step: 2
Training loss: 1.2834160327911377
Validation loss: 1.9792073926618021

Epoch: 5| Step: 3
Training loss: 0.9384872317314148
Validation loss: 1.968411696854458

Epoch: 5| Step: 4
Training loss: 1.0920442342758179
Validation loss: 1.9512372888544554

Epoch: 5| Step: 5
Training loss: 1.0045331716537476
Validation loss: 1.960001814749933

Epoch: 5| Step: 6
Training loss: 1.053468942642212
Validation loss: 1.986109648981402

Epoch: 5| Step: 7
Training loss: 1.468247413635254
Validation loss: 1.9909260606253019

Epoch: 5| Step: 8
Training loss: 1.3099838495254517
Validation loss: 1.9971427699571014

Epoch: 5| Step: 9
Training loss: 0.9976075291633606
Validation loss: 2.006575688239067

Epoch: 5| Step: 10
Training loss: 1.4168483018875122
Validation loss: 2.0295984104115474

Epoch: 268| Step: 0
Training loss: 1.6838449239730835
Validation loss: 2.023539414969824

Epoch: 5| Step: 1
Training loss: 1.320433259010315
Validation loss: 2.0343308858974005

Epoch: 5| Step: 2
Training loss: 1.4511886835098267
Validation loss: 2.03403111427061

Epoch: 5| Step: 3
Training loss: 1.244781494140625
Validation loss: 1.9974126687613867

Epoch: 5| Step: 4
Training loss: 1.2582017183303833
Validation loss: 2.0038100801488405

Epoch: 5| Step: 5
Training loss: 1.050544023513794
Validation loss: 2.0087079143011444

Epoch: 5| Step: 6
Training loss: 0.8475569486618042
Validation loss: 1.9894389644745858

Epoch: 5| Step: 7
Training loss: 1.0820671319961548
Validation loss: 1.988214039033459

Epoch: 5| Step: 8
Training loss: 1.0029016733169556
Validation loss: 1.9753409508735902

Epoch: 5| Step: 9
Training loss: 1.2124032974243164
Validation loss: 1.98392056521549

Epoch: 5| Step: 10
Training loss: 1.1575640439987183
Validation loss: 1.997779239890396

Epoch: 269| Step: 0
Training loss: 1.0525472164154053
Validation loss: 2.0107074950331

Epoch: 5| Step: 1
Training loss: 1.3805733919143677
Validation loss: 1.9857190783305834

Epoch: 5| Step: 2
Training loss: 1.0147570371627808
Validation loss: 1.9960773734636204

Epoch: 5| Step: 3
Training loss: 1.3663502931594849
Validation loss: 1.9877300595724454

Epoch: 5| Step: 4
Training loss: 0.7577790021896362
Validation loss: 1.9950244067817606

Epoch: 5| Step: 5
Training loss: 1.108013391494751
Validation loss: 2.012860651939146

Epoch: 5| Step: 6
Training loss: 0.9943822622299194
Validation loss: 2.051175317456645

Epoch: 5| Step: 7
Training loss: 1.651882529258728
Validation loss: 2.0407449173670944

Epoch: 5| Step: 8
Training loss: 1.2435948848724365
Validation loss: 1.9939131159936228

Epoch: 5| Step: 9
Training loss: 1.5454611778259277
Validation loss: 1.9803507815125168

Epoch: 5| Step: 10
Training loss: 1.1928942203521729
Validation loss: 2.0018443574187574

Epoch: 270| Step: 0
Training loss: 1.2466952800750732
Validation loss: 2.0242048950605493

Epoch: 5| Step: 1
Training loss: 1.3585840463638306
Validation loss: 2.0403366857959377

Epoch: 5| Step: 2
Training loss: 1.0801293849945068
Validation loss: 2.0004656366122666

Epoch: 5| Step: 3
Training loss: 1.1828722953796387
Validation loss: 2.007483923307029

Epoch: 5| Step: 4
Training loss: 1.116227388381958
Validation loss: 2.013754719047136

Epoch: 5| Step: 5
Training loss: 1.122619867324829
Validation loss: 2.0340435889459427

Epoch: 5| Step: 6
Training loss: 1.5548677444458008
Validation loss: 2.0121037255051317

Epoch: 5| Step: 7
Training loss: 0.9828697443008423
Validation loss: 1.9892885300420946

Epoch: 5| Step: 8
Training loss: 1.4583795070648193
Validation loss: 1.9655506636506768

Epoch: 5| Step: 9
Training loss: 1.1045693159103394
Validation loss: 1.95497005344719

Epoch: 5| Step: 10
Training loss: 1.1511458158493042
Validation loss: 1.946132585566531

Epoch: 271| Step: 0
Training loss: 1.2342474460601807
Validation loss: 1.9580290740536106

Epoch: 5| Step: 1
Training loss: 0.814418613910675
Validation loss: 1.9859802287112

Epoch: 5| Step: 2
Training loss: 1.1524295806884766
Validation loss: 1.9987517428654495

Epoch: 5| Step: 3
Training loss: 1.109541416168213
Validation loss: 1.974815050760905

Epoch: 5| Step: 4
Training loss: 1.2019259929656982
Validation loss: 2.0137337792304253

Epoch: 5| Step: 5
Training loss: 1.2831740379333496
Validation loss: 2.0197712503453737

Epoch: 5| Step: 6
Training loss: 1.342867136001587
Validation loss: 2.0323506209158126

Epoch: 5| Step: 7
Training loss: 1.5302127599716187
Validation loss: 2.023148831500802

Epoch: 5| Step: 8
Training loss: 1.096203327178955
Validation loss: 2.0425399452127437

Epoch: 5| Step: 9
Training loss: 1.3658792972564697
Validation loss: 2.0077171094955935

Epoch: 5| Step: 10
Training loss: 0.96470707654953
Validation loss: 1.9633601660369544

Epoch: 272| Step: 0
Training loss: 1.569311499595642
Validation loss: 1.9852138385977796

Epoch: 5| Step: 1
Training loss: 0.7509528398513794
Validation loss: 1.9933735811582176

Epoch: 5| Step: 2
Training loss: 0.8694836497306824
Validation loss: 2.0163198055759555

Epoch: 5| Step: 3
Training loss: 1.0089269876480103
Validation loss: 2.0235171189872165

Epoch: 5| Step: 4
Training loss: 0.8497373461723328
Validation loss: 2.01428565415003

Epoch: 5| Step: 5
Training loss: 1.0147333145141602
Validation loss: 2.0182451740387948

Epoch: 5| Step: 6
Training loss: 1.4434255361557007
Validation loss: 2.022307308771277

Epoch: 5| Step: 7
Training loss: 1.4440480470657349
Validation loss: 2.0484338909067135

Epoch: 5| Step: 8
Training loss: 1.2108170986175537
Validation loss: 2.019149818728047

Epoch: 5| Step: 9
Training loss: 1.2697795629501343
Validation loss: 1.9834398864417948

Epoch: 5| Step: 10
Training loss: 1.5572540760040283
Validation loss: 1.9689934984330209

Epoch: 273| Step: 0
Training loss: 1.1852003335952759
Validation loss: 1.960527027166018

Epoch: 5| Step: 1
Training loss: 1.0391664505004883
Validation loss: 1.9589114830058107

Epoch: 5| Step: 2
Training loss: 1.3225980997085571
Validation loss: 1.9651247403954948

Epoch: 5| Step: 3
Training loss: 1.5410100221633911
Validation loss: 1.941288927549957

Epoch: 5| Step: 4
Training loss: 1.2655665874481201
Validation loss: 1.9197272331483903

Epoch: 5| Step: 5
Training loss: 1.1468689441680908
Validation loss: 1.953464328601796

Epoch: 5| Step: 6
Training loss: 0.7587420344352722
Validation loss: 1.9810630249720749

Epoch: 5| Step: 7
Training loss: 1.1137616634368896
Validation loss: 1.982564897947414

Epoch: 5| Step: 8
Training loss: 1.180787444114685
Validation loss: 1.9559318455316688

Epoch: 5| Step: 9
Training loss: 1.0600969791412354
Validation loss: 1.9460799078787527

Epoch: 5| Step: 10
Training loss: 1.1546812057495117
Validation loss: 1.9380119718531126

Epoch: 274| Step: 0
Training loss: 1.2694565057754517
Validation loss: 1.9563525402417747

Epoch: 5| Step: 1
Training loss: 1.2815710306167603
Validation loss: 1.961030117927059

Epoch: 5| Step: 2
Training loss: 0.7761942744255066
Validation loss: 1.9812128620762979

Epoch: 5| Step: 3
Training loss: 1.5237858295440674
Validation loss: 1.9891754337536391

Epoch: 5| Step: 4
Training loss: 1.0377037525177002
Validation loss: 1.977537762734198

Epoch: 5| Step: 5
Training loss: 1.5313856601715088
Validation loss: 1.9996114059161114

Epoch: 5| Step: 6
Training loss: 0.5448098182678223
Validation loss: 1.9995810857383154

Epoch: 5| Step: 7
Training loss: 0.7445656657218933
Validation loss: 2.0256764068398425

Epoch: 5| Step: 8
Training loss: 1.2036569118499756
Validation loss: 1.998902205497988

Epoch: 5| Step: 9
Training loss: 1.4260562658309937
Validation loss: 2.0380701711100917

Epoch: 5| Step: 10
Training loss: 1.3241935968399048
Validation loss: 2.0123129942083873

Epoch: 275| Step: 0
Training loss: 0.8139749765396118
Validation loss: 1.992244476913124

Epoch: 5| Step: 1
Training loss: 0.8857482671737671
Validation loss: 1.9957919864244358

Epoch: 5| Step: 2
Training loss: 1.4340959787368774
Validation loss: 1.9771607563059816

Epoch: 5| Step: 3
Training loss: 0.7387396097183228
Validation loss: 1.9810592871840282

Epoch: 5| Step: 4
Training loss: 1.2448439598083496
Validation loss: 1.9554841646584131

Epoch: 5| Step: 5
Training loss: 1.4225155115127563
Validation loss: 1.962524962681596

Epoch: 5| Step: 6
Training loss: 1.5644261837005615
Validation loss: 1.9402138430585143

Epoch: 5| Step: 7
Training loss: 1.0504748821258545
Validation loss: 1.970408699845755

Epoch: 5| Step: 8
Training loss: 0.7605146169662476
Validation loss: 1.9807654119306994

Epoch: 5| Step: 9
Training loss: 1.3247661590576172
Validation loss: 1.970885069139542

Epoch: 5| Step: 10
Training loss: 0.986385703086853
Validation loss: 1.9919664141952351

Epoch: 276| Step: 0
Training loss: 1.127213954925537
Validation loss: 2.00254762300881

Epoch: 5| Step: 1
Training loss: 0.7846866846084595
Validation loss: 1.9854449649010935

Epoch: 5| Step: 2
Training loss: 0.4354884624481201
Validation loss: 1.988644576841785

Epoch: 5| Step: 3
Training loss: 1.617862343788147
Validation loss: 1.969117433794083

Epoch: 5| Step: 4
Training loss: 0.9295451045036316
Validation loss: 1.9533364208795692

Epoch: 5| Step: 5
Training loss: 1.1758947372436523
Validation loss: 1.9343013250699608

Epoch: 5| Step: 6
Training loss: 1.3445301055908203
Validation loss: 1.934125986150516

Epoch: 5| Step: 7
Training loss: 1.5789668560028076
Validation loss: 1.9201424955039896

Epoch: 5| Step: 8
Training loss: 1.2335773706436157
Validation loss: 1.9108640327248523

Epoch: 5| Step: 9
Training loss: 0.8057636022567749
Validation loss: 1.9174639665952293

Epoch: 5| Step: 10
Training loss: 1.2116460800170898
Validation loss: 1.9391401531875774

Epoch: 277| Step: 0
Training loss: 1.305023431777954
Validation loss: 1.9468848141290809

Epoch: 5| Step: 1
Training loss: 0.9379583597183228
Validation loss: 1.9625546060582644

Epoch: 5| Step: 2
Training loss: 0.9718239903450012
Validation loss: 1.985640295090214

Epoch: 5| Step: 3
Training loss: 0.9021788835525513
Validation loss: 1.9841698177399174

Epoch: 5| Step: 4
Training loss: 1.4102611541748047
Validation loss: 1.953948284990044

Epoch: 5| Step: 5
Training loss: 0.9960268139839172
Validation loss: 1.9616872943857664

Epoch: 5| Step: 6
Training loss: 1.583847165107727
Validation loss: 1.9548253884879492

Epoch: 5| Step: 7
Training loss: 0.9409130811691284
Validation loss: 1.9697136468784784

Epoch: 5| Step: 8
Training loss: 1.3968870639801025
Validation loss: 1.9890987885895597

Epoch: 5| Step: 9
Training loss: 0.9326335787773132
Validation loss: 1.99641264125865

Epoch: 5| Step: 10
Training loss: 0.9658359289169312
Validation loss: 2.034409781937958

Epoch: 278| Step: 0
Training loss: 0.846720814704895
Validation loss: 2.027150737342014

Epoch: 5| Step: 1
Training loss: 0.9682550430297852
Validation loss: 2.0210197920440347

Epoch: 5| Step: 2
Training loss: 0.9304292798042297
Validation loss: 1.9859672848896315

Epoch: 5| Step: 3
Training loss: 1.1914007663726807
Validation loss: 1.9963615966099564

Epoch: 5| Step: 4
Training loss: 1.1107914447784424
Validation loss: 1.993930588486374

Epoch: 5| Step: 5
Training loss: 0.8990350961685181
Validation loss: 2.0213565570051952

Epoch: 5| Step: 6
Training loss: 1.3606336116790771
Validation loss: 2.009020436194635

Epoch: 5| Step: 7
Training loss: 1.2483375072479248
Validation loss: 2.0034768363480926

Epoch: 5| Step: 8
Training loss: 0.824837863445282
Validation loss: 2.0017740880289385

Epoch: 5| Step: 9
Training loss: 1.4765055179595947
Validation loss: 1.9933623472849529

Epoch: 5| Step: 10
Training loss: 1.2473416328430176
Validation loss: 1.9519676220032476

Epoch: 279| Step: 0
Training loss: 0.7221413850784302
Validation loss: 1.9670178262136315

Epoch: 5| Step: 1
Training loss: 1.2980725765228271
Validation loss: 1.9683958817553777

Epoch: 5| Step: 2
Training loss: 0.9909378290176392
Validation loss: 1.9707222523227814

Epoch: 5| Step: 3
Training loss: 1.2716182470321655
Validation loss: 1.9872687093673214

Epoch: 5| Step: 4
Training loss: 1.6173534393310547
Validation loss: 1.9976111612012308

Epoch: 5| Step: 5
Training loss: 1.3072022199630737
Validation loss: 2.007624705632528

Epoch: 5| Step: 6
Training loss: 1.2037384510040283
Validation loss: 2.02586962843454

Epoch: 5| Step: 7
Training loss: 1.1777335405349731
Validation loss: 1.9896332679256317

Epoch: 5| Step: 8
Training loss: 1.049590826034546
Validation loss: 1.998505844864794

Epoch: 5| Step: 9
Training loss: 0.6521686315536499
Validation loss: 2.0043429636186167

Epoch: 5| Step: 10
Training loss: 0.7346071600914001
Validation loss: 1.9969161530976653

Epoch: 280| Step: 0
Training loss: 1.2574996948242188
Validation loss: 1.9800847730328959

Epoch: 5| Step: 1
Training loss: 1.3057470321655273
Validation loss: 1.971242182998247

Epoch: 5| Step: 2
Training loss: 1.1451804637908936
Validation loss: 1.9608821176713513

Epoch: 5| Step: 3
Training loss: 0.8214683532714844
Validation loss: 1.9572176869197557

Epoch: 5| Step: 4
Training loss: 0.7345925569534302
Validation loss: 1.9314805769151258

Epoch: 5| Step: 5
Training loss: 1.2339580059051514
Validation loss: 1.9203554455951979

Epoch: 5| Step: 6
Training loss: 0.8090423345565796
Validation loss: 1.9015748090641473

Epoch: 5| Step: 7
Training loss: 0.9371713399887085
Validation loss: 1.9192048452233756

Epoch: 5| Step: 8
Training loss: 1.2716814279556274
Validation loss: 1.926521239742156

Epoch: 5| Step: 9
Training loss: 1.2573579549789429
Validation loss: 1.9329896767934163

Epoch: 5| Step: 10
Training loss: 0.886412501335144
Validation loss: 1.9222729923904582

Epoch: 281| Step: 0
Training loss: 0.8866507411003113
Validation loss: 1.9521741713246992

Epoch: 5| Step: 1
Training loss: 0.6194556355476379
Validation loss: 1.9867767377566266

Epoch: 5| Step: 2
Training loss: 0.9735099077224731
Validation loss: 1.9632052221605856

Epoch: 5| Step: 3
Training loss: 1.1415044069290161
Validation loss: 1.9635341551996046

Epoch: 5| Step: 4
Training loss: 1.3726433515548706
Validation loss: 1.9820472886485438

Epoch: 5| Step: 5
Training loss: 1.1958664655685425
Validation loss: 1.9711407410201205

Epoch: 5| Step: 6
Training loss: 1.1496938467025757
Validation loss: 1.9640075731021103

Epoch: 5| Step: 7
Training loss: 0.8215362429618835
Validation loss: 1.9309758524740896

Epoch: 5| Step: 8
Training loss: 1.2992159128189087
Validation loss: 1.9087291840584046

Epoch: 5| Step: 9
Training loss: 0.9983304738998413
Validation loss: 1.9168319317602343

Epoch: 5| Step: 10
Training loss: 1.2405694723129272
Validation loss: 1.901657360856251

Epoch: 282| Step: 0
Training loss: 1.4379030466079712
Validation loss: 1.9006066450508692

Epoch: 5| Step: 1
Training loss: 1.1856210231781006
Validation loss: 1.9198739477383193

Epoch: 5| Step: 2
Training loss: 0.8200990557670593
Validation loss: 1.9197121512505315

Epoch: 5| Step: 3
Training loss: 1.070312261581421
Validation loss: 1.9319101777127994

Epoch: 5| Step: 4
Training loss: 1.0242702960968018
Validation loss: 1.9465894199186755

Epoch: 5| Step: 5
Training loss: 0.5800108313560486
Validation loss: 1.9677927596594698

Epoch: 5| Step: 6
Training loss: 0.6233835816383362
Validation loss: 1.9769870645256453

Epoch: 5| Step: 7
Training loss: 1.3129369020462036
Validation loss: 1.9843480830551476

Epoch: 5| Step: 8
Training loss: 1.352203607559204
Validation loss: 2.0199131850273377

Epoch: 5| Step: 9
Training loss: 1.0755589008331299
Validation loss: 1.980846502447641

Epoch: 5| Step: 10
Training loss: 1.2493016719818115
Validation loss: 1.9857861713696552

Epoch: 283| Step: 0
Training loss: 1.2224609851837158
Validation loss: 1.9765144496835687

Epoch: 5| Step: 1
Training loss: 1.1084036827087402
Validation loss: 1.958644010687387

Epoch: 5| Step: 2
Training loss: 0.7052015662193298
Validation loss: 1.9398333718699794

Epoch: 5| Step: 3
Training loss: 0.9461671113967896
Validation loss: 1.9370453921697472

Epoch: 5| Step: 4
Training loss: 0.9517409205436707
Validation loss: 1.9214014109744821

Epoch: 5| Step: 5
Training loss: 1.017728567123413
Validation loss: 1.9143801812202699

Epoch: 5| Step: 6
Training loss: 1.0267611742019653
Validation loss: 1.9213880364612868

Epoch: 5| Step: 7
Training loss: 1.1249710321426392
Validation loss: 1.9374573653744114

Epoch: 5| Step: 8
Training loss: 1.4051265716552734
Validation loss: 1.9320961403590378

Epoch: 5| Step: 9
Training loss: 1.1900198459625244
Validation loss: 1.942036549250285

Epoch: 5| Step: 10
Training loss: 0.8703383207321167
Validation loss: 1.9468805892493135

Epoch: 284| Step: 0
Training loss: 0.9840462803840637
Validation loss: 1.941223165040375

Epoch: 5| Step: 1
Training loss: 1.1026884317398071
Validation loss: 1.9541461724106983

Epoch: 5| Step: 2
Training loss: 0.9940377473831177
Validation loss: 1.9487680324944117

Epoch: 5| Step: 3
Training loss: 1.1563746929168701
Validation loss: 1.9512660682842295

Epoch: 5| Step: 4
Training loss: 0.8937438726425171
Validation loss: 1.9456684012566843

Epoch: 5| Step: 5
Training loss: 0.7162067890167236
Validation loss: 1.967868851077172

Epoch: 5| Step: 6
Training loss: 0.8475696444511414
Validation loss: 1.9728584725369689

Epoch: 5| Step: 7
Training loss: 0.8675248026847839
Validation loss: 1.994753618394175

Epoch: 5| Step: 8
Training loss: 1.317225694656372
Validation loss: 1.992864804883157

Epoch: 5| Step: 9
Training loss: 1.0117824077606201
Validation loss: 2.004766628306399

Epoch: 5| Step: 10
Training loss: 1.8074427843093872
Validation loss: 1.9658856366270332

Epoch: 285| Step: 0
Training loss: 1.1498489379882812
Validation loss: 1.9684213976706229

Epoch: 5| Step: 1
Training loss: 1.13126540184021
Validation loss: 1.9484428712116775

Epoch: 5| Step: 2
Training loss: 0.8217790722846985
Validation loss: 1.947194158390004

Epoch: 5| Step: 3
Training loss: 0.7525392770767212
Validation loss: 1.9105807581255514

Epoch: 5| Step: 4
Training loss: 1.4907290935516357
Validation loss: 1.9289941787719727

Epoch: 5| Step: 5
Training loss: 0.9729768633842468
Validation loss: 1.9417180233104254

Epoch: 5| Step: 6
Training loss: 1.392951488494873
Validation loss: 1.963109694501405

Epoch: 5| Step: 7
Training loss: 0.9649065732955933
Validation loss: 1.979909376431537

Epoch: 5| Step: 8
Training loss: 0.9001649022102356
Validation loss: 1.9566852661871141

Epoch: 5| Step: 9
Training loss: 1.121435523033142
Validation loss: 1.9645541483356106

Epoch: 5| Step: 10
Training loss: 1.116083025932312
Validation loss: 1.9333397803768035

Epoch: 286| Step: 0
Training loss: 0.9090250730514526
Validation loss: 1.9671784677813131

Epoch: 5| Step: 1
Training loss: 0.7812942266464233
Validation loss: 1.9642153645074496

Epoch: 5| Step: 2
Training loss: 1.1268401145935059
Validation loss: 1.9438113320258357

Epoch: 5| Step: 3
Training loss: 1.0956534147262573
Validation loss: 1.9486977720773349

Epoch: 5| Step: 4
Training loss: 1.089893102645874
Validation loss: 1.949124623370427

Epoch: 5| Step: 5
Training loss: 0.7283209562301636
Validation loss: 1.9544773768353205

Epoch: 5| Step: 6
Training loss: 1.1689174175262451
Validation loss: 1.9431812891396143

Epoch: 5| Step: 7
Training loss: 1.1704673767089844
Validation loss: 1.9333000952197659

Epoch: 5| Step: 8
Training loss: 1.0124346017837524
Validation loss: 1.9228745070836877

Epoch: 5| Step: 9
Training loss: 1.281760573387146
Validation loss: 1.907437160450925

Epoch: 5| Step: 10
Training loss: 0.9592404365539551
Validation loss: 1.8722245488115536

Epoch: 287| Step: 0
Training loss: 1.5379592180252075
Validation loss: 1.8753642933343047

Epoch: 5| Step: 1
Training loss: 0.8406183123588562
Validation loss: 1.867678496145433

Epoch: 5| Step: 2
Training loss: 0.8832639455795288
Validation loss: 1.882166672778386

Epoch: 5| Step: 3
Training loss: 0.765591561794281
Validation loss: 1.8707389523906093

Epoch: 5| Step: 4
Training loss: 1.2162630558013916
Validation loss: 1.8742082118988037

Epoch: 5| Step: 5
Training loss: 1.269627332687378
Validation loss: 1.9124073033691735

Epoch: 5| Step: 6
Training loss: 1.1471450328826904
Validation loss: 1.9324348177961124

Epoch: 5| Step: 7
Training loss: 1.0110160112380981
Validation loss: 1.9347536858691965

Epoch: 5| Step: 8
Training loss: 0.9509202837944031
Validation loss: 1.932164660064123

Epoch: 5| Step: 9
Training loss: 1.1383090019226074
Validation loss: 1.944013395617085

Epoch: 5| Step: 10
Training loss: 0.5487284660339355
Validation loss: 1.922604424979097

Epoch: 288| Step: 0
Training loss: 0.9781671762466431
Validation loss: 1.9470987332764493

Epoch: 5| Step: 1
Training loss: 1.0231037139892578
Validation loss: 1.9189846438746299

Epoch: 5| Step: 2
Training loss: 1.6420457363128662
Validation loss: 1.9533482456720004

Epoch: 5| Step: 3
Training loss: 0.9595333933830261
Validation loss: 1.9151127017954344

Epoch: 5| Step: 4
Training loss: 0.632684588432312
Validation loss: 1.918243436403172

Epoch: 5| Step: 5
Training loss: 0.9467015266418457
Validation loss: 1.9321590136456233

Epoch: 5| Step: 6
Training loss: 1.2700397968292236
Validation loss: 1.9264375984027822

Epoch: 5| Step: 7
Training loss: 0.7450804710388184
Validation loss: 1.893212185111097

Epoch: 5| Step: 8
Training loss: 1.0537654161453247
Validation loss: 1.914458026168167

Epoch: 5| Step: 9
Training loss: 1.1956427097320557
Validation loss: 1.9052217929593978

Epoch: 5| Step: 10
Training loss: 1.068751335144043
Validation loss: 1.899537117250504

Epoch: 289| Step: 0
Training loss: 1.0273584127426147
Validation loss: 1.9238187395116335

Epoch: 5| Step: 1
Training loss: 1.1408064365386963
Validation loss: 1.9485624964519213

Epoch: 5| Step: 2
Training loss: 1.3019088506698608
Validation loss: 1.894043319968767

Epoch: 5| Step: 3
Training loss: 0.6959511637687683
Validation loss: 1.9001238320463447

Epoch: 5| Step: 4
Training loss: 1.1878705024719238
Validation loss: 1.9179936570505942

Epoch: 5| Step: 5
Training loss: 0.8815170526504517
Validation loss: 1.8990389018930414

Epoch: 5| Step: 6
Training loss: 1.1858946084976196
Validation loss: 1.9089366133495043

Epoch: 5| Step: 7
Training loss: 0.8588279485702515
Validation loss: 1.906222101180784

Epoch: 5| Step: 8
Training loss: 0.7234064340591431
Validation loss: 1.9046028134643391

Epoch: 5| Step: 9
Training loss: 1.0770083665847778
Validation loss: 1.9141972603336457

Epoch: 5| Step: 10
Training loss: 1.100244402885437
Validation loss: 1.9395829118708128

Epoch: 290| Step: 0
Training loss: 1.2930736541748047
Validation loss: 1.9361342307059997

Epoch: 5| Step: 1
Training loss: 0.8617199659347534
Validation loss: 1.9446585588557745

Epoch: 5| Step: 2
Training loss: 1.3988374471664429
Validation loss: 1.9352152424473916

Epoch: 5| Step: 3
Training loss: 1.014293909072876
Validation loss: 1.939389181393449

Epoch: 5| Step: 4
Training loss: 0.7661336660385132
Validation loss: 1.938148444698703

Epoch: 5| Step: 5
Training loss: 1.133963942527771
Validation loss: 1.942054820317094

Epoch: 5| Step: 6
Training loss: 0.6840196847915649
Validation loss: 1.9369622917585476

Epoch: 5| Step: 7
Training loss: 1.0400710105895996
Validation loss: 1.92467664646846

Epoch: 5| Step: 8
Training loss: 1.0016554594039917
Validation loss: 1.932239745252876

Epoch: 5| Step: 9
Training loss: 0.671197772026062
Validation loss: 1.8980998762192265

Epoch: 5| Step: 10
Training loss: 1.112859845161438
Validation loss: 1.9066470182070168

Epoch: 291| Step: 0
Training loss: 1.0562266111373901
Validation loss: 1.878027642926862

Epoch: 5| Step: 1
Training loss: 0.7892661690711975
Validation loss: 1.89085586865743

Epoch: 5| Step: 2
Training loss: 0.7664355635643005
Validation loss: 1.8519037782504995

Epoch: 5| Step: 3
Training loss: 0.9154973030090332
Validation loss: 1.892087269854802

Epoch: 5| Step: 4
Training loss: 1.1024200916290283
Validation loss: 1.8612769444783528

Epoch: 5| Step: 5
Training loss: 0.6180377006530762
Validation loss: 1.8820771094291442

Epoch: 5| Step: 6
Training loss: 1.1850467920303345
Validation loss: 1.9189491553973126

Epoch: 5| Step: 7
Training loss: 1.0958446264266968
Validation loss: 1.9134037622841455

Epoch: 5| Step: 8
Training loss: 1.6565158367156982
Validation loss: 1.8843093226032872

Epoch: 5| Step: 9
Training loss: 0.985162615776062
Validation loss: 1.8844195514596918

Epoch: 5| Step: 10
Training loss: 0.8550460934638977
Validation loss: 1.8714911553167528

Epoch: 292| Step: 0
Training loss: 0.9115833044052124
Validation loss: 1.8861335131429857

Epoch: 5| Step: 1
Training loss: 0.7087208032608032
Validation loss: 1.9090405151408205

Epoch: 5| Step: 2
Training loss: 0.6174200773239136
Validation loss: 1.8926995313295754

Epoch: 5| Step: 3
Training loss: 1.0202972888946533
Validation loss: 1.919841835575719

Epoch: 5| Step: 4
Training loss: 1.1119308471679688
Validation loss: 1.91596354464049

Epoch: 5| Step: 5
Training loss: 0.872381865978241
Validation loss: 1.916752294827533

Epoch: 5| Step: 6
Training loss: 1.1406532526016235
Validation loss: 1.9106150647645355

Epoch: 5| Step: 7
Training loss: 1.13433039188385
Validation loss: 1.88456634295884

Epoch: 5| Step: 8
Training loss: 0.9188350439071655
Validation loss: 1.881548317529822

Epoch: 5| Step: 9
Training loss: 1.1714537143707275
Validation loss: 1.8823815776455788

Epoch: 5| Step: 10
Training loss: 1.2619123458862305
Validation loss: 1.8794743912194365

Epoch: 293| Step: 0
Training loss: 0.6889459490776062
Validation loss: 1.8779542856318976

Epoch: 5| Step: 1
Training loss: 0.4076809883117676
Validation loss: 1.8740491918338242

Epoch: 5| Step: 2
Training loss: 1.2417428493499756
Validation loss: 1.8641639012162403

Epoch: 5| Step: 3
Training loss: 0.7712548971176147
Validation loss: 1.875117559586802

Epoch: 5| Step: 4
Training loss: 1.5132713317871094
Validation loss: 1.8769363280265563

Epoch: 5| Step: 5
Training loss: 0.7993513941764832
Validation loss: 1.8600008538974229

Epoch: 5| Step: 6
Training loss: 1.3870084285736084
Validation loss: 1.907733735217843

Epoch: 5| Step: 7
Training loss: 0.8599767684936523
Validation loss: 1.8870735835003596

Epoch: 5| Step: 8
Training loss: 0.8704472780227661
Validation loss: 1.9025201156575193

Epoch: 5| Step: 9
Training loss: 1.168121337890625
Validation loss: 1.8740527104305964

Epoch: 5| Step: 10
Training loss: 0.9230881333351135
Validation loss: 1.8830452067877657

Epoch: 294| Step: 0
Training loss: 1.2766406536102295
Validation loss: 1.8791473040016748

Epoch: 5| Step: 1
Training loss: 0.42817407846450806
Validation loss: 1.9097580909729004

Epoch: 5| Step: 2
Training loss: 1.188749074935913
Validation loss: 1.910724380964874

Epoch: 5| Step: 3
Training loss: 0.9648376703262329
Validation loss: 1.9225410210188998

Epoch: 5| Step: 4
Training loss: 0.9057424664497375
Validation loss: 1.917186624260359

Epoch: 5| Step: 5
Training loss: 1.1648590564727783
Validation loss: 1.9140608310699463

Epoch: 5| Step: 6
Training loss: 0.5407223701477051
Validation loss: 1.905747603344661

Epoch: 5| Step: 7
Training loss: 0.9667507410049438
Validation loss: 1.9122546475420716

Epoch: 5| Step: 8
Training loss: 1.2889293432235718
Validation loss: 1.9102544528181835

Epoch: 5| Step: 9
Training loss: 0.9696899652481079
Validation loss: 1.922244955134648

Epoch: 5| Step: 10
Training loss: 0.7480385899543762
Validation loss: 1.9190812469810568

Epoch: 295| Step: 0
Training loss: 0.8178836703300476
Validation loss: 1.8767338318209494

Epoch: 5| Step: 1
Training loss: 0.6202178001403809
Validation loss: 1.8878795485342703

Epoch: 5| Step: 2
Training loss: 1.0754610300064087
Validation loss: 1.8616464086758193

Epoch: 5| Step: 3
Training loss: 1.0370157957077026
Validation loss: 1.878580880421464

Epoch: 5| Step: 4
Training loss: 0.8105206489562988
Validation loss: 1.8676419450390724

Epoch: 5| Step: 5
Training loss: 0.7907214164733887
Validation loss: 1.8614548508838942

Epoch: 5| Step: 6
Training loss: 1.2672439813613892
Validation loss: 1.8812007968143751

Epoch: 5| Step: 7
Training loss: 1.2163721323013306
Validation loss: 1.8800279350690945

Epoch: 5| Step: 8
Training loss: 0.6124657988548279
Validation loss: 1.8769962864537393

Epoch: 5| Step: 9
Training loss: 1.0010037422180176
Validation loss: 1.8903008660962504

Epoch: 5| Step: 10
Training loss: 1.2638832330703735
Validation loss: 1.896472457916506

Epoch: 296| Step: 0
Training loss: 1.0891964435577393
Validation loss: 1.8929013321476598

Epoch: 5| Step: 1
Training loss: 1.121994137763977
Validation loss: 1.9056229450369393

Epoch: 5| Step: 2
Training loss: 0.8847963213920593
Validation loss: 1.8927990992863972

Epoch: 5| Step: 3
Training loss: 0.626764178276062
Validation loss: 1.8826222330011346

Epoch: 5| Step: 4
Training loss: 0.8303461074829102
Validation loss: 1.8643894451920704

Epoch: 5| Step: 5
Training loss: 0.7201290130615234
Validation loss: 1.8661724764813659

Epoch: 5| Step: 6
Training loss: 1.166990041732788
Validation loss: 1.8607920703067575

Epoch: 5| Step: 7
Training loss: 1.0858049392700195
Validation loss: 1.8637827724538825

Epoch: 5| Step: 8
Training loss: 0.924101710319519
Validation loss: 1.8635761814732705

Epoch: 5| Step: 9
Training loss: 1.0956298112869263
Validation loss: 1.8559779710667108

Epoch: 5| Step: 10
Training loss: 0.9559439420700073
Validation loss: 1.8315808721767959

Epoch: 297| Step: 0
Training loss: 0.9441021680831909
Validation loss: 1.8582751430490965

Epoch: 5| Step: 1
Training loss: 0.9383468627929688
Validation loss: 1.867875822128788

Epoch: 5| Step: 2
Training loss: 0.7546573281288147
Validation loss: 1.8691918350035144

Epoch: 5| Step: 3
Training loss: 1.1886249780654907
Validation loss: 1.8569892170608684

Epoch: 5| Step: 4
Training loss: 0.7972097396850586
Validation loss: 1.864105038745429

Epoch: 5| Step: 5
Training loss: 1.0473004579544067
Validation loss: 1.8651621598069386

Epoch: 5| Step: 6
Training loss: 0.8234182596206665
Validation loss: 1.905724335742253

Epoch: 5| Step: 7
Training loss: 0.9745861291885376
Validation loss: 1.892476556121662

Epoch: 5| Step: 8
Training loss: 0.734049916267395
Validation loss: 1.8952537454584593

Epoch: 5| Step: 9
Training loss: 1.2353183031082153
Validation loss: 1.8706303129913986

Epoch: 5| Step: 10
Training loss: 0.704765796661377
Validation loss: 1.9142893129779446

Epoch: 298| Step: 0
Training loss: 0.8281927108764648
Validation loss: 1.9067109682226693

Epoch: 5| Step: 1
Training loss: 0.8374516367912292
Validation loss: 1.9077221526894519

Epoch: 5| Step: 2
Training loss: 1.075674057006836
Validation loss: 1.9205733691492388

Epoch: 5| Step: 3
Training loss: 1.1603288650512695
Validation loss: 1.8992762360521542

Epoch: 5| Step: 4
Training loss: 1.067535161972046
Validation loss: 1.889195139690112

Epoch: 5| Step: 5
Training loss: 0.8626660108566284
Validation loss: 1.8958708881050028

Epoch: 5| Step: 6
Training loss: 0.7857723236083984
Validation loss: 1.8898277718533751

Epoch: 5| Step: 7
Training loss: 1.0612328052520752
Validation loss: 1.8796219492471347

Epoch: 5| Step: 8
Training loss: 0.5929540395736694
Validation loss: 1.886085093662303

Epoch: 5| Step: 9
Training loss: 0.8231106996536255
Validation loss: 1.8825478592226583

Epoch: 5| Step: 10
Training loss: 1.195703148841858
Validation loss: 1.9340293843259093

Epoch: 299| Step: 0
Training loss: 0.7978017926216125
Validation loss: 1.9175604710014917

Epoch: 5| Step: 1
Training loss: 1.2320294380187988
Validation loss: 1.9338400543376963

Epoch: 5| Step: 2
Training loss: 1.2261009216308594
Validation loss: 1.8563267364296863

Epoch: 5| Step: 3
Training loss: 0.6660553216934204
Validation loss: 1.873844292856032

Epoch: 5| Step: 4
Training loss: 0.6803528070449829
Validation loss: 1.8755028452924503

Epoch: 5| Step: 5
Training loss: 1.159514307975769
Validation loss: 1.855481529748568

Epoch: 5| Step: 6
Training loss: 0.9782708287239075
Validation loss: 1.8237547233540525

Epoch: 5| Step: 7
Training loss: 0.6605927348136902
Validation loss: 1.873546511896195

Epoch: 5| Step: 8
Training loss: 0.9836385846138
Validation loss: 1.8817761905731694

Epoch: 5| Step: 9
Training loss: 0.8414379954338074
Validation loss: 1.8922113141705912

Epoch: 5| Step: 10
Training loss: 1.1482518911361694
Validation loss: 1.8636089576187955

Epoch: 300| Step: 0
Training loss: 0.6764900088310242
Validation loss: 1.8941080365129697

Epoch: 5| Step: 1
Training loss: 0.3439805209636688
Validation loss: 1.896347161262266

Epoch: 5| Step: 2
Training loss: 0.8236675262451172
Validation loss: 1.896019845880488

Epoch: 5| Step: 3
Training loss: 0.858210563659668
Validation loss: 1.8799056276198356

Epoch: 5| Step: 4
Training loss: 0.7528220415115356
Validation loss: 1.8658850167387275

Epoch: 5| Step: 5
Training loss: 1.0356979370117188
Validation loss: 1.8786899069304108

Epoch: 5| Step: 6
Training loss: 0.9456698298454285
Validation loss: 1.8647079006318124

Epoch: 5| Step: 7
Training loss: 1.1026359796524048
Validation loss: 1.8735784561403337

Epoch: 5| Step: 8
Training loss: 1.024803876876831
Validation loss: 1.8955309442294541

Epoch: 5| Step: 9
Training loss: 0.948819637298584
Validation loss: 1.8798528922501432

Epoch: 5| Step: 10
Training loss: 1.435107946395874
Validation loss: 1.885639080437281

Epoch: 301| Step: 0
Training loss: 0.6905462741851807
Validation loss: 1.8758066866987495

Epoch: 5| Step: 1
Training loss: 0.8448649644851685
Validation loss: 1.8661271654149538

Epoch: 5| Step: 2
Training loss: 1.152651071548462
Validation loss: 1.8545636336008708

Epoch: 5| Step: 3
Training loss: 0.9259144067764282
Validation loss: 1.8532092135439637

Epoch: 5| Step: 4
Training loss: 0.6190779805183411
Validation loss: 1.8451483518846574

Epoch: 5| Step: 5
Training loss: 1.4680113792419434
Validation loss: 1.8499210893466909

Epoch: 5| Step: 6
Training loss: 0.6465392112731934
Validation loss: 1.8576995813718407

Epoch: 5| Step: 7
Training loss: 0.7185074090957642
Validation loss: 1.8772754771735078

Epoch: 5| Step: 8
Training loss: 0.9268184900283813
Validation loss: 1.9077731127380042

Epoch: 5| Step: 9
Training loss: 0.6190457940101624
Validation loss: 1.8803803549017957

Epoch: 5| Step: 10
Training loss: 1.3773506879806519
Validation loss: 1.873970926448863

Epoch: 302| Step: 0
Training loss: 0.7079771757125854
Validation loss: 1.8654816266029113

Epoch: 5| Step: 1
Training loss: 1.229797124862671
Validation loss: 1.8849469948840398

Epoch: 5| Step: 2
Training loss: 0.8508201837539673
Validation loss: 1.8874814946164367

Epoch: 5| Step: 3
Training loss: 0.6922749280929565
Validation loss: 1.8848125460327312

Epoch: 5| Step: 4
Training loss: 0.7666264772415161
Validation loss: 1.8534779984463927

Epoch: 5| Step: 5
Training loss: 0.9760511517524719
Validation loss: 1.858342424515755

Epoch: 5| Step: 6
Training loss: 1.0424911975860596
Validation loss: 1.9039026242430492

Epoch: 5| Step: 7
Training loss: 0.9538930654525757
Validation loss: 1.8610350419116277

Epoch: 5| Step: 8
Training loss: 0.8386104702949524
Validation loss: 1.8607396976922148

Epoch: 5| Step: 9
Training loss: 0.7789492607116699
Validation loss: 1.8654366936734927

Epoch: 5| Step: 10
Training loss: 0.883610725402832
Validation loss: 1.855582675626201

Epoch: 303| Step: 0
Training loss: 1.1382114887237549
Validation loss: 1.8621388250781643

Epoch: 5| Step: 1
Training loss: 1.16774582862854
Validation loss: 1.8809749080288796

Epoch: 5| Step: 2
Training loss: 0.9379145503044128
Validation loss: 1.8696243583515126

Epoch: 5| Step: 3
Training loss: 1.0326298475265503
Validation loss: 1.843239015148532

Epoch: 5| Step: 4
Training loss: 0.7274799942970276
Validation loss: 1.855178322843326

Epoch: 5| Step: 5
Training loss: 0.5454090237617493
Validation loss: 1.820085399894304

Epoch: 5| Step: 6
Training loss: 0.8185545206069946
Validation loss: 1.8115347482824837

Epoch: 5| Step: 7
Training loss: 0.746266782283783
Validation loss: 1.8440614913099556

Epoch: 5| Step: 8
Training loss: 1.275591254234314
Validation loss: 1.8790185066961473

Epoch: 5| Step: 9
Training loss: 1.0298186540603638
Validation loss: 1.89173295164621

Epoch: 5| Step: 10
Training loss: 0.8202638030052185
Validation loss: 1.8566263901290072

Epoch: 304| Step: 0
Training loss: 0.6583491563796997
Validation loss: 1.8778911598267094

Epoch: 5| Step: 1
Training loss: 1.0307875871658325
Validation loss: 1.8889603691716348

Epoch: 5| Step: 2
Training loss: 0.8101012110710144
Validation loss: 1.9501961585014098

Epoch: 5| Step: 3
Training loss: 0.9452954530715942
Validation loss: 1.9337717076783538

Epoch: 5| Step: 4
Training loss: 1.518913984298706
Validation loss: 1.8916468953573575

Epoch: 5| Step: 5
Training loss: 0.7352808117866516
Validation loss: 1.872622892420779

Epoch: 5| Step: 6
Training loss: 0.9364935159683228
Validation loss: 1.9279509898154967

Epoch: 5| Step: 7
Training loss: 0.7543222904205322
Validation loss: 1.915093486027051

Epoch: 5| Step: 8
Training loss: 0.7275403141975403
Validation loss: 1.8887743385889197

Epoch: 5| Step: 9
Training loss: 0.9971824884414673
Validation loss: 1.8544897571686776

Epoch: 5| Step: 10
Training loss: 1.1975210905075073
Validation loss: 1.816614071528117

Epoch: 305| Step: 0
Training loss: 0.9221699833869934
Validation loss: 1.8532117541118334

Epoch: 5| Step: 1
Training loss: 0.7890077829360962
Validation loss: 1.8463870594578404

Epoch: 5| Step: 2
Training loss: 1.0221459865570068
Validation loss: 1.8568560256752917

Epoch: 5| Step: 3
Training loss: 0.6785798072814941
Validation loss: 1.8747061426921556

Epoch: 5| Step: 4
Training loss: 1.0411458015441895
Validation loss: 1.9003669267059655

Epoch: 5| Step: 5
Training loss: 0.6699697375297546
Validation loss: 1.9287366815792617

Epoch: 5| Step: 6
Training loss: 0.9864760637283325
Validation loss: 1.999667211245465

Epoch: 5| Step: 7
Training loss: 1.6430953741073608
Validation loss: 2.0352329707914785

Epoch: 5| Step: 8
Training loss: 1.1427850723266602
Validation loss: 1.9499601984536776

Epoch: 5| Step: 9
Training loss: 0.5932115912437439
Validation loss: 1.867377628562271

Epoch: 5| Step: 10
Training loss: 0.7999889254570007
Validation loss: 1.8741375707810926

Epoch: 306| Step: 0
Training loss: 0.8132196664810181
Validation loss: 1.865853355776879

Epoch: 5| Step: 1
Training loss: 0.9861596822738647
Validation loss: 1.8900620027254986

Epoch: 5| Step: 2
Training loss: 0.9380868077278137
Validation loss: 1.8718213214669177

Epoch: 5| Step: 3
Training loss: 1.1413118839263916
Validation loss: 1.8457419833829325

Epoch: 5| Step: 4
Training loss: 0.8385219573974609
Validation loss: 1.9208906081414991

Epoch: 5| Step: 5
Training loss: 1.1459434032440186
Validation loss: 1.9562126513450377

Epoch: 5| Step: 6
Training loss: 1.0492815971374512
Validation loss: 1.9528112014134724

Epoch: 5| Step: 7
Training loss: 0.9289790987968445
Validation loss: 1.923200217626428

Epoch: 5| Step: 8
Training loss: 0.7258225083351135
Validation loss: 1.8999160720456032

Epoch: 5| Step: 9
Training loss: 0.540557861328125
Validation loss: 1.8790384723294167

Epoch: 5| Step: 10
Training loss: 1.1873458623886108
Validation loss: 1.870984378681388

Epoch: 307| Step: 0
Training loss: 0.575131356716156
Validation loss: 1.8352668759643391

Epoch: 5| Step: 1
Training loss: 1.043772578239441
Validation loss: 1.821772962488154

Epoch: 5| Step: 2
Training loss: 1.0416690111160278
Validation loss: 1.8094817105159964

Epoch: 5| Step: 3
Training loss: 0.8712885975837708
Validation loss: 1.8203230263084493

Epoch: 5| Step: 4
Training loss: 1.0560040473937988
Validation loss: 1.85220976286037

Epoch: 5| Step: 5
Training loss: 0.8136754035949707
Validation loss: 1.8817811883905882

Epoch: 5| Step: 6
Training loss: 1.0387970209121704
Validation loss: 1.8865078521031204

Epoch: 5| Step: 7
Training loss: 1.100466251373291
Validation loss: 1.8838302832777782

Epoch: 5| Step: 8
Training loss: 0.7211126685142517
Validation loss: 1.8948248355619368

Epoch: 5| Step: 9
Training loss: 0.7993178963661194
Validation loss: 1.9246962467829387

Epoch: 5| Step: 10
Training loss: 0.7392855286598206
Validation loss: 1.909711157121966

Epoch: 308| Step: 0
Training loss: 0.8176754117012024
Validation loss: 1.9276164411216654

Epoch: 5| Step: 1
Training loss: 0.621922492980957
Validation loss: 1.9014294826856224

Epoch: 5| Step: 2
Training loss: 1.120987057685852
Validation loss: 1.884972027553025

Epoch: 5| Step: 3
Training loss: 0.8501993417739868
Validation loss: 1.8755057409245481

Epoch: 5| Step: 4
Training loss: 0.8474502563476562
Validation loss: 1.8632534421900266

Epoch: 5| Step: 5
Training loss: 0.7835988402366638
Validation loss: 1.8721770522414998

Epoch: 5| Step: 6
Training loss: 1.1855541467666626
Validation loss: 1.8665361250600507

Epoch: 5| Step: 7
Training loss: 0.9424517750740051
Validation loss: 1.8813607884991554

Epoch: 5| Step: 8
Training loss: 0.9313473701477051
Validation loss: 1.831740862579756

Epoch: 5| Step: 9
Training loss: 0.9197497367858887
Validation loss: 1.8540330189530567

Epoch: 5| Step: 10
Training loss: 0.618370532989502
Validation loss: 1.8633136979995235

Epoch: 309| Step: 0
Training loss: 0.7683161497116089
Validation loss: 1.8654677175706433

Epoch: 5| Step: 1
Training loss: 0.5365639328956604
Validation loss: 1.8627804735655427

Epoch: 5| Step: 2
Training loss: 1.1926164627075195
Validation loss: 1.889890588739867

Epoch: 5| Step: 3
Training loss: 1.0188976526260376
Validation loss: 1.8890479995358376

Epoch: 5| Step: 4
Training loss: 1.2128809690475464
Validation loss: 1.85942199666013

Epoch: 5| Step: 5
Training loss: 1.117917776107788
Validation loss: 1.8768076845394668

Epoch: 5| Step: 6
Training loss: 0.801120936870575
Validation loss: 1.836466746945535

Epoch: 5| Step: 7
Training loss: 0.5827810168266296
Validation loss: 1.8407974832801408

Epoch: 5| Step: 8
Training loss: 0.8425923585891724
Validation loss: 1.8215021497459822

Epoch: 5| Step: 9
Training loss: 1.094844102859497
Validation loss: 1.8433957279369395

Epoch: 5| Step: 10
Training loss: 0.5499056577682495
Validation loss: 1.8645493407403269

Epoch: 310| Step: 0
Training loss: 1.248117446899414
Validation loss: 1.8702034206800564

Epoch: 5| Step: 1
Training loss: 0.6471972465515137
Validation loss: 1.8662232147750033

Epoch: 5| Step: 2
Training loss: 1.11625075340271
Validation loss: 1.8997895409983974

Epoch: 5| Step: 3
Training loss: 1.0759421586990356
Validation loss: 1.9514721401276127

Epoch: 5| Step: 4
Training loss: 0.5755457878112793
Validation loss: 1.9433878185928508

Epoch: 5| Step: 5
Training loss: 0.6345634460449219
Validation loss: 1.9247557963094404

Epoch: 5| Step: 6
Training loss: 0.8861136436462402
Validation loss: 1.8726150528077157

Epoch: 5| Step: 7
Training loss: 0.812165379524231
Validation loss: 1.8488486351505402

Epoch: 5| Step: 8
Training loss: 1.025848627090454
Validation loss: 1.8340367706873084

Epoch: 5| Step: 9
Training loss: 0.8096288442611694
Validation loss: 1.8125215653450257

Epoch: 5| Step: 10
Training loss: 0.7152271270751953
Validation loss: 1.8192441232742802

Epoch: 311| Step: 0
Training loss: 0.8290386199951172
Validation loss: 1.8070962480319444

Epoch: 5| Step: 1
Training loss: 0.7727402448654175
Validation loss: 1.828605600582656

Epoch: 5| Step: 2
Training loss: 1.2343518733978271
Validation loss: 1.8418335696702361

Epoch: 5| Step: 3
Training loss: 1.11970055103302
Validation loss: 1.854806689805882

Epoch: 5| Step: 4
Training loss: 0.8003858327865601
Validation loss: 1.8558667064994894

Epoch: 5| Step: 5
Training loss: 0.907293975353241
Validation loss: 1.8258931393264441

Epoch: 5| Step: 6
Training loss: 0.797999382019043
Validation loss: 1.84364410625991

Epoch: 5| Step: 7
Training loss: 0.6833189129829407
Validation loss: 1.8397611238623177

Epoch: 5| Step: 8
Training loss: 0.8877485394477844
Validation loss: 1.8247092705900951

Epoch: 5| Step: 9
Training loss: 0.9152033925056458
Validation loss: 1.8274350422684864

Epoch: 5| Step: 10
Training loss: 0.6231445074081421
Validation loss: 1.8268776209123674

Epoch: 312| Step: 0
Training loss: 0.725016713142395
Validation loss: 1.8546738214390253

Epoch: 5| Step: 1
Training loss: 1.2722289562225342
Validation loss: 1.8869378207832255

Epoch: 5| Step: 2
Training loss: 0.6167072057723999
Validation loss: 1.914018242589889

Epoch: 5| Step: 3
Training loss: 0.50892174243927
Validation loss: 1.8903588479565037

Epoch: 5| Step: 4
Training loss: 0.7584123611450195
Validation loss: 1.8795349162112

Epoch: 5| Step: 5
Training loss: 0.9382246732711792
Validation loss: 1.9102755182532853

Epoch: 5| Step: 6
Training loss: 1.0605568885803223
Validation loss: 1.905586181148406

Epoch: 5| Step: 7
Training loss: 1.3353338241577148
Validation loss: 1.9018821229216873

Epoch: 5| Step: 8
Training loss: 0.9220487475395203
Validation loss: 1.853155691136596

Epoch: 5| Step: 9
Training loss: 0.535317599773407
Validation loss: 1.8591085518560102

Epoch: 5| Step: 10
Training loss: 0.8871375322341919
Validation loss: 1.8341193391430763

Epoch: 313| Step: 0
Training loss: 0.9867315292358398
Validation loss: 1.863699657942659

Epoch: 5| Step: 1
Training loss: 0.4731718599796295
Validation loss: 1.8325720730648245

Epoch: 5| Step: 2
Training loss: 0.590203583240509
Validation loss: 1.8543598472431142

Epoch: 5| Step: 3
Training loss: 1.0733487606048584
Validation loss: 1.8422873686718684

Epoch: 5| Step: 4
Training loss: 0.9351726770401001
Validation loss: 1.8606033248286094

Epoch: 5| Step: 5
Training loss: 0.7258710861206055
Validation loss: 1.874244002885716

Epoch: 5| Step: 6
Training loss: 0.5161517858505249
Validation loss: 1.8793357738884546

Epoch: 5| Step: 7
Training loss: 1.0446903705596924
Validation loss: 1.9021017807786182

Epoch: 5| Step: 8
Training loss: 0.9419089555740356
Validation loss: 1.8935633320962229

Epoch: 5| Step: 9
Training loss: 0.9713207483291626
Validation loss: 1.8320793374892204

Epoch: 5| Step: 10
Training loss: 1.0450491905212402
Validation loss: 1.860625292665215

Epoch: 314| Step: 0
Training loss: 0.7111417651176453
Validation loss: 1.8462250283969346

Epoch: 5| Step: 1
Training loss: 0.593673825263977
Validation loss: 1.8303996068175121

Epoch: 5| Step: 2
Training loss: 0.6430224776268005
Validation loss: 1.8309476734489523

Epoch: 5| Step: 3
Training loss: 0.9317163228988647
Validation loss: 1.8537979946341565

Epoch: 5| Step: 4
Training loss: 0.7600339651107788
Validation loss: 1.8252430987614456

Epoch: 5| Step: 5
Training loss: 1.1547573804855347
Validation loss: 1.8668834547842703

Epoch: 5| Step: 6
Training loss: 0.6879687905311584
Validation loss: 1.848135232925415

Epoch: 5| Step: 7
Training loss: 0.8122259378433228
Validation loss: 1.879441281800629

Epoch: 5| Step: 8
Training loss: 1.024585485458374
Validation loss: 1.8653551417012368

Epoch: 5| Step: 9
Training loss: 0.9116547703742981
Validation loss: 1.827137634318362

Epoch: 5| Step: 10
Training loss: 0.8947048187255859
Validation loss: 1.848490620172152

Epoch: 315| Step: 0
Training loss: 0.7505884170532227
Validation loss: 1.850243899130052

Epoch: 5| Step: 1
Training loss: 0.6939185857772827
Validation loss: 1.8568204423432708

Epoch: 5| Step: 2
Training loss: 1.1556001901626587
Validation loss: 1.8524136081818612

Epoch: 5| Step: 3
Training loss: 0.7058274149894714
Validation loss: 1.8612596783586728

Epoch: 5| Step: 4
Training loss: 0.9865733981132507
Validation loss: 1.8541493467105332

Epoch: 5| Step: 5
Training loss: 0.832107663154602
Validation loss: 1.8369629472814581

Epoch: 5| Step: 6
Training loss: 0.9930605888366699
Validation loss: 1.8392970049253075

Epoch: 5| Step: 7
Training loss: 1.2044771909713745
Validation loss: 1.809779828594577

Epoch: 5| Step: 8
Training loss: 0.6456372141838074
Validation loss: 1.839827650336809

Epoch: 5| Step: 9
Training loss: 0.5053629875183105
Validation loss: 1.8325246713494743

Epoch: 5| Step: 10
Training loss: 0.5705666542053223
Validation loss: 1.8409911150573401

Epoch: 316| Step: 0
Training loss: 0.6614614129066467
Validation loss: 1.8332997855319773

Epoch: 5| Step: 1
Training loss: 0.7891901731491089
Validation loss: 1.8562407788409983

Epoch: 5| Step: 2
Training loss: 0.7825024724006653
Validation loss: 1.8393454269696308

Epoch: 5| Step: 3
Training loss: 1.0423038005828857
Validation loss: 1.8386495280009445

Epoch: 5| Step: 4
Training loss: 0.9078241586685181
Validation loss: 1.8456082831146896

Epoch: 5| Step: 5
Training loss: 1.049505591392517
Validation loss: 1.8566197451724802

Epoch: 5| Step: 6
Training loss: 0.6982719898223877
Validation loss: 1.867732265944122

Epoch: 5| Step: 7
Training loss: 0.43075117468833923
Validation loss: 1.835650667067497

Epoch: 5| Step: 8
Training loss: 0.7920635938644409
Validation loss: 1.864542071537305

Epoch: 5| Step: 9
Training loss: 0.786415696144104
Validation loss: 1.8543900956389725

Epoch: 5| Step: 10
Training loss: 1.1736118793487549
Validation loss: 1.8880259452327606

Epoch: 317| Step: 0
Training loss: 0.7256795167922974
Validation loss: 1.890171108707305

Epoch: 5| Step: 1
Training loss: 1.318493127822876
Validation loss: 1.8875550262389644

Epoch: 5| Step: 2
Training loss: 0.8891869783401489
Validation loss: 1.8941172092191634

Epoch: 5| Step: 3
Training loss: 0.9991073608398438
Validation loss: 1.895140395369581

Epoch: 5| Step: 4
Training loss: 0.7285764813423157
Validation loss: 1.8575120254229474

Epoch: 5| Step: 5
Training loss: 0.7438676953315735
Validation loss: 1.8522203904326244

Epoch: 5| Step: 6
Training loss: 0.6074294447898865
Validation loss: 1.817003018112593

Epoch: 5| Step: 7
Training loss: 0.6394544243812561
Validation loss: 1.8068519497430453

Epoch: 5| Step: 8
Training loss: 0.6750494241714478
Validation loss: 1.805505028334997

Epoch: 5| Step: 9
Training loss: 0.9527266621589661
Validation loss: 1.8195042199985956

Epoch: 5| Step: 10
Training loss: 0.7845343947410583
Validation loss: 1.8021018876824328

Epoch: 318| Step: 0
Training loss: 0.7957631945610046
Validation loss: 1.7783335101219915

Epoch: 5| Step: 1
Training loss: 0.8337596654891968
Validation loss: 1.7696464087373467

Epoch: 5| Step: 2
Training loss: 0.8681084513664246
Validation loss: 1.788345565078079

Epoch: 5| Step: 3
Training loss: 0.44253960251808167
Validation loss: 1.799083581534765

Epoch: 5| Step: 4
Training loss: 0.7859252095222473
Validation loss: 1.8218523340840493

Epoch: 5| Step: 5
Training loss: 1.0696048736572266
Validation loss: 1.794775906429496

Epoch: 5| Step: 6
Training loss: 0.9214677810668945
Validation loss: 1.7826895329260057

Epoch: 5| Step: 7
Training loss: 0.8767819404602051
Validation loss: 1.8231761724718156

Epoch: 5| Step: 8
Training loss: 0.4529206156730652
Validation loss: 1.8121461740104101

Epoch: 5| Step: 9
Training loss: 0.6899877190589905
Validation loss: 1.7942067679538523

Epoch: 5| Step: 10
Training loss: 1.2048348188400269
Validation loss: 1.8058295596030451

Epoch: 319| Step: 0
Training loss: 0.6220585703849792
Validation loss: 1.7986553779212378

Epoch: 5| Step: 1
Training loss: 0.770628809928894
Validation loss: 1.8177996450854885

Epoch: 5| Step: 2
Training loss: 0.6334901452064514
Validation loss: 1.833075487485496

Epoch: 5| Step: 3
Training loss: 0.7274506688117981
Validation loss: 1.8106964121582687

Epoch: 5| Step: 4
Training loss: 0.9113157987594604
Validation loss: 1.8163203545795974

Epoch: 5| Step: 5
Training loss: 0.8870309591293335
Validation loss: 1.8378368782740768

Epoch: 5| Step: 6
Training loss: 0.7585352063179016
Validation loss: 1.857198666500789

Epoch: 5| Step: 7
Training loss: 0.6863741874694824
Validation loss: 1.8770828554707188

Epoch: 5| Step: 8
Training loss: 1.1521745920181274
Validation loss: 1.8691765749326317

Epoch: 5| Step: 9
Training loss: 0.9237037897109985
Validation loss: 1.849995356734081

Epoch: 5| Step: 10
Training loss: 0.5716171860694885
Validation loss: 1.8679263860948625

Epoch: 320| Step: 0
Training loss: 0.8514465093612671
Validation loss: 1.8741803361523537

Epoch: 5| Step: 1
Training loss: 0.5419148206710815
Validation loss: 1.8502020605148808

Epoch: 5| Step: 2
Training loss: 0.6378322839736938
Validation loss: 1.8531563179467314

Epoch: 5| Step: 3
Training loss: 0.7452628016471863
Validation loss: 1.842091627018426

Epoch: 5| Step: 4
Training loss: 0.5493561625480652
Validation loss: 1.8494382532694007

Epoch: 5| Step: 5
Training loss: 1.13019597530365
Validation loss: 1.8390205226918703

Epoch: 5| Step: 6
Training loss: 1.2163150310516357
Validation loss: 1.8232722308046074

Epoch: 5| Step: 7
Training loss: 0.8207457661628723
Validation loss: 1.8266256701561712

Epoch: 5| Step: 8
Training loss: 0.8347050547599792
Validation loss: 1.827855651096631

Epoch: 5| Step: 9
Training loss: 0.66356360912323
Validation loss: 1.8273767937896073

Epoch: 5| Step: 10
Training loss: 0.6369345188140869
Validation loss: 1.824081124797944

Epoch: 321| Step: 0
Training loss: 0.9498688578605652
Validation loss: 1.824264931422408

Epoch: 5| Step: 1
Training loss: 0.7000175714492798
Validation loss: 1.8230114008790703

Epoch: 5| Step: 2
Training loss: 0.703039288520813
Validation loss: 1.8082435233618623

Epoch: 5| Step: 3
Training loss: 0.650135338306427
Validation loss: 1.8106536813961562

Epoch: 5| Step: 4
Training loss: 0.9144166707992554
Validation loss: 1.794090728605947

Epoch: 5| Step: 5
Training loss: 0.8112936019897461
Validation loss: 1.802072996734291

Epoch: 5| Step: 6
Training loss: 0.33458980917930603
Validation loss: 1.7822847955970353

Epoch: 5| Step: 7
Training loss: 0.7776800394058228
Validation loss: 1.8061206853517922

Epoch: 5| Step: 8
Training loss: 0.6498854160308838
Validation loss: 1.7960112440970637

Epoch: 5| Step: 9
Training loss: 0.9437950849533081
Validation loss: 1.8359240819049139

Epoch: 5| Step: 10
Training loss: 1.1335468292236328
Validation loss: 1.8653984185188048

Epoch: 322| Step: 0
Training loss: 0.6340565085411072
Validation loss: 1.890956231342849

Epoch: 5| Step: 1
Training loss: 0.7889424562454224
Validation loss: 1.8911558710118777

Epoch: 5| Step: 2
Training loss: 0.658852219581604
Validation loss: 1.8761731719457975

Epoch: 5| Step: 3
Training loss: 0.7158704400062561
Validation loss: 1.845305008272971

Epoch: 5| Step: 4
Training loss: 0.8730484843254089
Validation loss: 1.8331028274310532

Epoch: 5| Step: 5
Training loss: 0.840957760810852
Validation loss: 1.8579292951091644

Epoch: 5| Step: 6
Training loss: 0.9104883074760437
Validation loss: 1.833855270057596

Epoch: 5| Step: 7
Training loss: 0.8472962379455566
Validation loss: 1.8128302020411338

Epoch: 5| Step: 8
Training loss: 0.642767071723938
Validation loss: 1.7892606335301553

Epoch: 5| Step: 9
Training loss: 0.8097273111343384
Validation loss: 1.8083146631076772

Epoch: 5| Step: 10
Training loss: 0.9472420811653137
Validation loss: 1.8029548096400436

Epoch: 323| Step: 0
Training loss: 0.8563364744186401
Validation loss: 1.8377877627649615

Epoch: 5| Step: 1
Training loss: 0.6825070381164551
Validation loss: 1.8280783289222307

Epoch: 5| Step: 2
Training loss: 0.451676607131958
Validation loss: 1.8174890882225447

Epoch: 5| Step: 3
Training loss: 0.8118454217910767
Validation loss: 1.8194054570249332

Epoch: 5| Step: 4
Training loss: 0.8457670211791992
Validation loss: 1.8193552750413136

Epoch: 5| Step: 5
Training loss: 0.6166563630104065
Validation loss: 1.8194897661926925

Epoch: 5| Step: 6
Training loss: 0.46004343032836914
Validation loss: 1.8476755542139853

Epoch: 5| Step: 7
Training loss: 0.8929511308670044
Validation loss: 1.852317529339944

Epoch: 5| Step: 8
Training loss: 0.894612193107605
Validation loss: 1.8473771361894504

Epoch: 5| Step: 9
Training loss: 1.0176399946212769
Validation loss: 1.8398880522738221

Epoch: 5| Step: 10
Training loss: 0.8171930909156799
Validation loss: 1.8600222244057605

Epoch: 324| Step: 0
Training loss: 0.9632219076156616
Validation loss: 1.8542106484854093

Epoch: 5| Step: 1
Training loss: 0.8311702609062195
Validation loss: 1.8600215758046796

Epoch: 5| Step: 2
Training loss: 0.6078742742538452
Validation loss: 1.880857749651837

Epoch: 5| Step: 3
Training loss: 0.6723170876502991
Validation loss: 1.8747174047654676

Epoch: 5| Step: 4
Training loss: 0.8696361780166626
Validation loss: 1.86769530593708

Epoch: 5| Step: 5
Training loss: 0.36911359429359436
Validation loss: 1.8356476458170081

Epoch: 5| Step: 6
Training loss: 1.1917158365249634
Validation loss: 1.8514548847752232

Epoch: 5| Step: 7
Training loss: 0.7718001008033752
Validation loss: 1.81092224326185

Epoch: 5| Step: 8
Training loss: 0.6826644539833069
Validation loss: 1.8283198328428372

Epoch: 5| Step: 9
Training loss: 0.5464261174201965
Validation loss: 1.8188685473575388

Epoch: 5| Step: 10
Training loss: 0.7199913263320923
Validation loss: 1.8173485481610863

Epoch: 325| Step: 0
Training loss: 0.6923896074295044
Validation loss: 1.8089267412821453

Epoch: 5| Step: 1
Training loss: 0.6632410287857056
Validation loss: 1.805882567359555

Epoch: 5| Step: 2
Training loss: 0.6333892941474915
Validation loss: 1.820538761795208

Epoch: 5| Step: 3
Training loss: 0.6022075414657593
Validation loss: 1.8120949588796145

Epoch: 5| Step: 4
Training loss: 0.8622667193412781
Validation loss: 1.870383297243426

Epoch: 5| Step: 5
Training loss: 0.6813095808029175
Validation loss: 1.8544763236917474

Epoch: 5| Step: 6
Training loss: 0.4442242681980133
Validation loss: 1.824774992081427

Epoch: 5| Step: 7
Training loss: 1.1643359661102295
Validation loss: 1.8366380109581897

Epoch: 5| Step: 8
Training loss: 0.9385975003242493
Validation loss: 1.8345238418989285

Epoch: 5| Step: 9
Training loss: 0.8582488894462585
Validation loss: 1.8335965371900989

Epoch: 5| Step: 10
Training loss: 0.9556155204772949
Validation loss: 1.8037148214155627

Epoch: 326| Step: 0
Training loss: 1.2003071308135986
Validation loss: 1.810122069492135

Epoch: 5| Step: 1
Training loss: 0.7445250153541565
Validation loss: 1.834468359588295

Epoch: 5| Step: 2
Training loss: 0.6638372540473938
Validation loss: 1.8646005840711697

Epoch: 5| Step: 3
Training loss: 0.5418971180915833
Validation loss: 1.8726997901034612

Epoch: 5| Step: 4
Training loss: 0.9096277356147766
Validation loss: 1.882382074991862

Epoch: 5| Step: 5
Training loss: 0.701879620552063
Validation loss: 1.883409692395118

Epoch: 5| Step: 6
Training loss: 0.8419016003608704
Validation loss: 1.8874943935742943

Epoch: 5| Step: 7
Training loss: 0.7979329228401184
Validation loss: 1.8830059753951205

Epoch: 5| Step: 8
Training loss: 0.7480298280715942
Validation loss: 1.8701924995709491

Epoch: 5| Step: 9
Training loss: 0.49561038613319397
Validation loss: 1.8610362583591091

Epoch: 5| Step: 10
Training loss: 0.63911372423172
Validation loss: 1.8746980544059508

Epoch: 327| Step: 0
Training loss: 0.771234929561615
Validation loss: 1.843808081842238

Epoch: 5| Step: 1
Training loss: 0.6695514917373657
Validation loss: 1.8287123275059525

Epoch: 5| Step: 2
Training loss: 0.8237541913986206
Validation loss: 1.8259968270537674

Epoch: 5| Step: 3
Training loss: 0.5922427773475647
Validation loss: 1.8349672056013537

Epoch: 5| Step: 4
Training loss: 0.8839486837387085
Validation loss: 1.8141444985584547

Epoch: 5| Step: 5
Training loss: 0.41704264283180237
Validation loss: 1.8143196016229608

Epoch: 5| Step: 6
Training loss: 0.918907642364502
Validation loss: 1.8127397926904822

Epoch: 5| Step: 7
Training loss: 1.1647453308105469
Validation loss: 1.836318185252528

Epoch: 5| Step: 8
Training loss: 0.800226092338562
Validation loss: 1.8068345272412865

Epoch: 5| Step: 9
Training loss: 0.570957362651825
Validation loss: 1.8395830482564948

Epoch: 5| Step: 10
Training loss: 0.4092944264411926
Validation loss: 1.8522117663455266

Epoch: 328| Step: 0
Training loss: 0.8403600454330444
Validation loss: 1.8699029812248804

Epoch: 5| Step: 1
Training loss: 0.7141337394714355
Validation loss: 1.844715133790047

Epoch: 5| Step: 2
Training loss: 0.9313877820968628
Validation loss: 1.8108260990470968

Epoch: 5| Step: 3
Training loss: 1.0087366104125977
Validation loss: 1.8238256464722336

Epoch: 5| Step: 4
Training loss: 1.3113207817077637
Validation loss: 1.8311275512941423

Epoch: 5| Step: 5
Training loss: 0.6280754208564758
Validation loss: 1.8443234505191926

Epoch: 5| Step: 6
Training loss: 0.7386922836303711
Validation loss: 1.8268968879535634

Epoch: 5| Step: 7
Training loss: 0.7123505473136902
Validation loss: 1.8228859016972203

Epoch: 5| Step: 8
Training loss: 0.3237115740776062
Validation loss: 1.831609518297257

Epoch: 5| Step: 9
Training loss: 0.6131724715232849
Validation loss: 1.843981324985463

Epoch: 5| Step: 10
Training loss: 0.6433020830154419
Validation loss: 1.8431094833599624

Epoch: 329| Step: 0
Training loss: 0.7685586214065552
Validation loss: 1.8881160700193016

Epoch: 5| Step: 1
Training loss: 1.0579168796539307
Validation loss: 1.9255809130207184

Epoch: 5| Step: 2
Training loss: 0.5897938013076782
Validation loss: 1.942134782832156

Epoch: 5| Step: 3
Training loss: 0.9697456359863281
Validation loss: 1.904179947350615

Epoch: 5| Step: 4
Training loss: 0.6298767328262329
Validation loss: 1.9046671198260399

Epoch: 5| Step: 5
Training loss: 0.6789039969444275
Validation loss: 1.8453665138572775

Epoch: 5| Step: 6
Training loss: 0.8174441456794739
Validation loss: 1.835356472640909

Epoch: 5| Step: 7
Training loss: 0.6707804203033447
Validation loss: 1.83034134680225

Epoch: 5| Step: 8
Training loss: 0.7680323719978333
Validation loss: 1.7998617977224372

Epoch: 5| Step: 9
Training loss: 0.7161812782287598
Validation loss: 1.8044604050215853

Epoch: 5| Step: 10
Training loss: 0.5580511689186096
Validation loss: 1.825194820280998

Epoch: 330| Step: 0
Training loss: 0.7516095638275146
Validation loss: 1.7991172857182

Epoch: 5| Step: 1
Training loss: 0.8777896761894226
Validation loss: 1.7856342754056376

Epoch: 5| Step: 2
Training loss: 0.574847400188446
Validation loss: 1.8069272143866426

Epoch: 5| Step: 3
Training loss: 0.46626758575439453
Validation loss: 1.8089332580566406

Epoch: 5| Step: 4
Training loss: 0.5084640383720398
Validation loss: 1.8470295475375267

Epoch: 5| Step: 5
Training loss: 1.0551702976226807
Validation loss: 1.840911175615044

Epoch: 5| Step: 6
Training loss: 0.9323701858520508
Validation loss: 1.8297867146871423

Epoch: 5| Step: 7
Training loss: 0.7736867666244507
Validation loss: 1.8346672596470002

Epoch: 5| Step: 8
Training loss: 0.6674373149871826
Validation loss: 1.8442402039804766

Epoch: 5| Step: 9
Training loss: 0.6753311157226562
Validation loss: 1.8690836916687668

Epoch: 5| Step: 10
Training loss: 0.6995333433151245
Validation loss: 1.8530191452272478

Epoch: 331| Step: 0
Training loss: 0.6810020804405212
Validation loss: 1.8110250734513806

Epoch: 5| Step: 1
Training loss: 0.8617246747016907
Validation loss: 1.8177216796464817

Epoch: 5| Step: 2
Training loss: 0.8176509141921997
Validation loss: 1.7635171874876945

Epoch: 5| Step: 3
Training loss: 0.7009552717208862
Validation loss: 1.785847815134192

Epoch: 5| Step: 4
Training loss: 0.8041287660598755
Validation loss: 1.778749281360257

Epoch: 5| Step: 5
Training loss: 0.5816289782524109
Validation loss: 1.7678658705885693

Epoch: 5| Step: 6
Training loss: 0.5961881875991821
Validation loss: 1.802761431663267

Epoch: 5| Step: 7
Training loss: 0.8933694958686829
Validation loss: 1.8235198374717467

Epoch: 5| Step: 8
Training loss: 0.7413362264633179
Validation loss: 1.8824561654880483

Epoch: 5| Step: 9
Training loss: 0.5231688022613525
Validation loss: 1.8366001908497145

Epoch: 5| Step: 10
Training loss: 0.6407559514045715
Validation loss: 1.8189946989859305

Epoch: 332| Step: 0
Training loss: 0.828912079334259
Validation loss: 1.8271748942713584

Epoch: 5| Step: 1
Training loss: 0.7643995881080627
Validation loss: 1.8431282735640002

Epoch: 5| Step: 2
Training loss: 0.6850823163986206
Validation loss: 1.8597118046975905

Epoch: 5| Step: 3
Training loss: 0.587870717048645
Validation loss: 1.829530433941913

Epoch: 5| Step: 4
Training loss: 0.5194754600524902
Validation loss: 1.8038050282386042

Epoch: 5| Step: 5
Training loss: 0.3300517201423645
Validation loss: 1.7906524135220436

Epoch: 5| Step: 6
Training loss: 0.5778754949569702
Validation loss: 1.8232645898736932

Epoch: 5| Step: 7
Training loss: 0.8114549517631531
Validation loss: 1.8296701549201884

Epoch: 5| Step: 8
Training loss: 0.9753099679946899
Validation loss: 1.7781116039522233

Epoch: 5| Step: 9
Training loss: 1.0705530643463135
Validation loss: 1.7808665088427964

Epoch: 5| Step: 10
Training loss: 0.7260423302650452
Validation loss: 1.798090709153042

Epoch: 333| Step: 0
Training loss: 0.7083805799484253
Validation loss: 1.7837560330667803

Epoch: 5| Step: 1
Training loss: 0.5996304154396057
Validation loss: 1.7868447303771973

Epoch: 5| Step: 2
Training loss: 0.8414634466171265
Validation loss: 1.8094606271354101

Epoch: 5| Step: 3
Training loss: 0.8118247985839844
Validation loss: 1.8141875907938967

Epoch: 5| Step: 4
Training loss: 0.5841902494430542
Validation loss: 1.8222454876028082

Epoch: 5| Step: 5
Training loss: 0.8859540820121765
Validation loss: 1.7886283807857062

Epoch: 5| Step: 6
Training loss: 0.5883089900016785
Validation loss: 1.7819167606292232

Epoch: 5| Step: 7
Training loss: 0.7739357948303223
Validation loss: 1.77640200173983

Epoch: 5| Step: 8
Training loss: 0.7582076191902161
Validation loss: 1.7752366027524393

Epoch: 5| Step: 9
Training loss: 0.5587478876113892
Validation loss: 1.7603782069298528

Epoch: 5| Step: 10
Training loss: 0.546025276184082
Validation loss: 1.7818140009398102

Epoch: 334| Step: 0
Training loss: 0.21881374716758728
Validation loss: 1.7728122959854782

Epoch: 5| Step: 1
Training loss: 0.7488193511962891
Validation loss: 1.806451823121758

Epoch: 5| Step: 2
Training loss: 0.7453442811965942
Validation loss: 1.8265839853594381

Epoch: 5| Step: 3
Training loss: 0.6331769227981567
Validation loss: 1.8332500457763672

Epoch: 5| Step: 4
Training loss: 0.5304346084594727
Validation loss: 1.8128696859523814

Epoch: 5| Step: 5
Training loss: 0.5088474750518799
Validation loss: 1.7981541977133801

Epoch: 5| Step: 6
Training loss: 0.8554506301879883
Validation loss: 1.7562938685058265

Epoch: 5| Step: 7
Training loss: 0.547968864440918
Validation loss: 1.7610867766923801

Epoch: 5| Step: 8
Training loss: 0.9134455919265747
Validation loss: 1.77802397102438

Epoch: 5| Step: 9
Training loss: 1.1450960636138916
Validation loss: 1.7589287181054392

Epoch: 5| Step: 10
Training loss: 0.6282049417495728
Validation loss: 1.7510072838875554

Epoch: 335| Step: 0
Training loss: 0.6165860891342163
Validation loss: 1.7715705287071966

Epoch: 5| Step: 1
Training loss: 0.6047065854072571
Validation loss: 1.7941541030842771

Epoch: 5| Step: 2
Training loss: 0.5937789678573608
Validation loss: 1.803947376948531

Epoch: 5| Step: 3
Training loss: 0.8334752917289734
Validation loss: 1.817609735714492

Epoch: 5| Step: 4
Training loss: 0.6764869093894958
Validation loss: 1.8417827916401688

Epoch: 5| Step: 5
Training loss: 0.833188533782959
Validation loss: 1.8619428424425022

Epoch: 5| Step: 6
Training loss: 0.6276289820671082
Validation loss: 1.8585711691969184

Epoch: 5| Step: 7
Training loss: 0.5545841455459595
Validation loss: 1.845791857729676

Epoch: 5| Step: 8
Training loss: 0.4583134055137634
Validation loss: 1.8590538681194346

Epoch: 5| Step: 9
Training loss: 0.7771718502044678
Validation loss: 1.8309746288484143

Epoch: 5| Step: 10
Training loss: 0.9163072109222412
Validation loss: 1.8459070792762182

Epoch: 336| Step: 0
Training loss: 0.7679691314697266
Validation loss: 1.8362106764188377

Epoch: 5| Step: 1
Training loss: 0.7222653031349182
Validation loss: 1.8498677463941677

Epoch: 5| Step: 2
Training loss: 0.6500785946846008
Validation loss: 1.8091545258798907

Epoch: 5| Step: 3
Training loss: 0.5848139524459839
Validation loss: 1.7784618523813063

Epoch: 5| Step: 4
Training loss: 0.5613602995872498
Validation loss: 1.7741050925306094

Epoch: 5| Step: 5
Training loss: 0.615424633026123
Validation loss: 1.7903499885271954

Epoch: 5| Step: 6
Training loss: 0.8480600118637085
Validation loss: 1.8438870547920145

Epoch: 5| Step: 7
Training loss: 0.7066009640693665
Validation loss: 1.7883667612588534

Epoch: 5| Step: 8
Training loss: 0.46667805314064026
Validation loss: 1.7877896255062473

Epoch: 5| Step: 9
Training loss: 0.8073674440383911
Validation loss: 1.82591127580212

Epoch: 5| Step: 10
Training loss: 0.9952533841133118
Validation loss: 1.830826505537956

Epoch: 337| Step: 0
Training loss: 0.7475292086601257
Validation loss: 1.8168669349403792

Epoch: 5| Step: 1
Training loss: 0.5718787312507629
Validation loss: 1.808901773985996

Epoch: 5| Step: 2
Training loss: 0.6233241558074951
Validation loss: 1.766604322259144

Epoch: 5| Step: 3
Training loss: 0.6250268816947937
Validation loss: 1.7869184427363898

Epoch: 5| Step: 4
Training loss: 1.0267679691314697
Validation loss: 1.7577744581366097

Epoch: 5| Step: 5
Training loss: 0.6963258981704712
Validation loss: 1.7973707529806322

Epoch: 5| Step: 6
Training loss: 0.7920122742652893
Validation loss: 1.7897279954725696

Epoch: 5| Step: 7
Training loss: 0.7152166366577148
Validation loss: 1.781137999027006

Epoch: 5| Step: 8
Training loss: 0.8148082494735718
Validation loss: 1.823891471791011

Epoch: 5| Step: 9
Training loss: 0.5952340364456177
Validation loss: 1.8309290767997823

Epoch: 5| Step: 10
Training loss: 0.33275389671325684
Validation loss: 1.8242588940487112

Epoch: 338| Step: 0
Training loss: 0.8637546300888062
Validation loss: 1.8342722641524447

Epoch: 5| Step: 1
Training loss: 0.616566002368927
Validation loss: 1.8230666242619997

Epoch: 5| Step: 2
Training loss: 0.7388392686843872
Validation loss: 1.8211440322219685

Epoch: 5| Step: 3
Training loss: 0.6379770040512085
Validation loss: 1.8397560991266722

Epoch: 5| Step: 4
Training loss: 0.7386855483055115
Validation loss: 1.8334051383438932

Epoch: 5| Step: 5
Training loss: 0.8039650917053223
Validation loss: 1.8433540162219797

Epoch: 5| Step: 6
Training loss: 0.613385796546936
Validation loss: 1.825392161646197

Epoch: 5| Step: 7
Training loss: 0.48987025022506714
Validation loss: 1.812450183335171

Epoch: 5| Step: 8
Training loss: 0.5163009762763977
Validation loss: 1.8237292651207215

Epoch: 5| Step: 9
Training loss: 0.8647695779800415
Validation loss: 1.8298568674313125

Epoch: 5| Step: 10
Training loss: 0.7963556051254272
Validation loss: 1.8034580958786832

Epoch: 339| Step: 0
Training loss: 0.6401663422584534
Validation loss: 1.8277636676706293

Epoch: 5| Step: 1
Training loss: 0.927006721496582
Validation loss: 1.8207655888731762

Epoch: 5| Step: 2
Training loss: 0.6491736173629761
Validation loss: 1.8179944484464583

Epoch: 5| Step: 3
Training loss: 0.4694678783416748
Validation loss: 1.809480736332555

Epoch: 5| Step: 4
Training loss: 0.6885155439376831
Validation loss: 1.8207592823172127

Epoch: 5| Step: 5
Training loss: 0.7532216310501099
Validation loss: 1.835065698110929

Epoch: 5| Step: 6
Training loss: 0.8259917497634888
Validation loss: 1.839458918058744

Epoch: 5| Step: 7
Training loss: 0.6805123090744019
Validation loss: 1.8157104189677904

Epoch: 5| Step: 8
Training loss: 0.4058813452720642
Validation loss: 1.806260662694131

Epoch: 5| Step: 9
Training loss: 0.6449156999588013
Validation loss: 1.7933820678341774

Epoch: 5| Step: 10
Training loss: 0.6383984684944153
Validation loss: 1.7891400860201927

Epoch: 340| Step: 0
Training loss: 0.4472976624965668
Validation loss: 1.7753369859469834

Epoch: 5| Step: 1
Training loss: 0.49333375692367554
Validation loss: 1.7825165166649768

Epoch: 5| Step: 2
Training loss: 1.1228821277618408
Validation loss: 1.8285917492323025

Epoch: 5| Step: 3
Training loss: 0.9815551042556763
Validation loss: 1.823922517479107

Epoch: 5| Step: 4
Training loss: 0.7749921083450317
Validation loss: 1.823116628072595

Epoch: 5| Step: 5
Training loss: 0.43085312843322754
Validation loss: 1.8405741696716638

Epoch: 5| Step: 6
Training loss: 0.6741236448287964
Validation loss: 1.8213501489290627

Epoch: 5| Step: 7
Training loss: 0.5007138252258301
Validation loss: 1.8312247081469464

Epoch: 5| Step: 8
Training loss: 0.888104259967804
Validation loss: 1.837048739515325

Epoch: 5| Step: 9
Training loss: 0.5567690134048462
Validation loss: 1.822336035390054

Epoch: 5| Step: 10
Training loss: 0.48542189598083496
Validation loss: 1.8061456116296912

Epoch: 341| Step: 0
Training loss: 0.4348166584968567
Validation loss: 1.8197225844988258

Epoch: 5| Step: 1
Training loss: 0.6309146881103516
Validation loss: 1.8043212300987654

Epoch: 5| Step: 2
Training loss: 0.5821515917778015
Validation loss: 1.7811775720247658

Epoch: 5| Step: 3
Training loss: 0.5258666276931763
Validation loss: 1.802783848136984

Epoch: 5| Step: 4
Training loss: 0.46486836671829224
Validation loss: 1.7966014774896766

Epoch: 5| Step: 5
Training loss: 0.6129134297370911
Validation loss: 1.7893570648726596

Epoch: 5| Step: 6
Training loss: 0.8175646066665649
Validation loss: 1.8046002452091505

Epoch: 5| Step: 7
Training loss: 0.5613919496536255
Validation loss: 1.8233075359816193

Epoch: 5| Step: 8
Training loss: 1.0671417713165283
Validation loss: 1.8000789932025376

Epoch: 5| Step: 9
Training loss: 0.749443769454956
Validation loss: 1.790178096422585

Epoch: 5| Step: 10
Training loss: 0.614657461643219
Validation loss: 1.8002071585706485

Epoch: 342| Step: 0
Training loss: 0.5591644644737244
Validation loss: 1.7902764428046443

Epoch: 5| Step: 1
Training loss: 0.7788761258125305
Validation loss: 1.809237781391349

Epoch: 5| Step: 2
Training loss: 0.6519536375999451
Validation loss: 1.837012598591466

Epoch: 5| Step: 3
Training loss: 0.5980542302131653
Validation loss: 1.8416816931898876

Epoch: 5| Step: 4
Training loss: 0.615373969078064
Validation loss: 1.8575914777735227

Epoch: 5| Step: 5
Training loss: 0.41723304986953735
Validation loss: 1.8150250706621396

Epoch: 5| Step: 6
Training loss: 0.7149735689163208
Validation loss: 1.827468793879273

Epoch: 5| Step: 7
Training loss: 0.7236847877502441
Validation loss: 1.815875361042638

Epoch: 5| Step: 8
Training loss: 0.7463257312774658
Validation loss: 1.8420453994504866

Epoch: 5| Step: 9
Training loss: 0.7295953631401062
Validation loss: 1.8416897968579364

Epoch: 5| Step: 10
Training loss: 0.5549674034118652
Validation loss: 1.813919363483306

Epoch: 343| Step: 0
Training loss: 0.4799232482910156
Validation loss: 1.7625703157917145

Epoch: 5| Step: 1
Training loss: 0.6574724912643433
Validation loss: 1.7968808566370318

Epoch: 5| Step: 2
Training loss: 0.5653229355812073
Validation loss: 1.789219630661831

Epoch: 5| Step: 3
Training loss: 0.6849650144577026
Validation loss: 1.7547388358782696

Epoch: 5| Step: 4
Training loss: 0.5571826696395874
Validation loss: 1.7911049896670925

Epoch: 5| Step: 5
Training loss: 0.8574239611625671
Validation loss: 1.7905589713845202

Epoch: 5| Step: 6
Training loss: 0.4460310935974121
Validation loss: 1.7965256321814753

Epoch: 5| Step: 7
Training loss: 0.7397382855415344
Validation loss: 1.8210012707658993

Epoch: 5| Step: 8
Training loss: 0.651624321937561
Validation loss: 1.8468784504039313

Epoch: 5| Step: 9
Training loss: 0.6363709568977356
Validation loss: 1.8177005629385672

Epoch: 5| Step: 10
Training loss: 0.7198764681816101
Validation loss: 1.8008468868911907

Epoch: 344| Step: 0
Training loss: 0.526953399181366
Validation loss: 1.7921580242854294

Epoch: 5| Step: 1
Training loss: 0.5204206705093384
Validation loss: 1.7606595267531693

Epoch: 5| Step: 2
Training loss: 0.6721931099891663
Validation loss: 1.7505550820340392

Epoch: 5| Step: 3
Training loss: 0.6959003210067749
Validation loss: 1.7490518554564445

Epoch: 5| Step: 4
Training loss: 0.5918558835983276
Validation loss: 1.7565649478666243

Epoch: 5| Step: 5
Training loss: 0.5352498888969421
Validation loss: 1.7972022256543558

Epoch: 5| Step: 6
Training loss: 0.6380736231803894
Validation loss: 1.7777059821672336

Epoch: 5| Step: 7
Training loss: 0.7863881587982178
Validation loss: 1.8188747000950638

Epoch: 5| Step: 8
Training loss: 0.4978744387626648
Validation loss: 1.7990378577222106

Epoch: 5| Step: 9
Training loss: 0.8307539224624634
Validation loss: 1.7995119017939414

Epoch: 5| Step: 10
Training loss: 0.5717918872833252
Validation loss: 1.8308475530275734

Epoch: 345| Step: 0
Training loss: 0.5868409276008606
Validation loss: 1.828281726888431

Epoch: 5| Step: 1
Training loss: 0.8825410604476929
Validation loss: 1.8487594089200419

Epoch: 5| Step: 2
Training loss: 0.8382212519645691
Validation loss: 1.8055591583251953

Epoch: 5| Step: 3
Training loss: 0.4065442979335785
Validation loss: 1.8172976509217293

Epoch: 5| Step: 4
Training loss: 0.6356245279312134
Validation loss: 1.7791030791498

Epoch: 5| Step: 5
Training loss: 0.4476684629917145
Validation loss: 1.7798679080060733

Epoch: 5| Step: 6
Training loss: 0.573022186756134
Validation loss: 1.8271775245666504

Epoch: 5| Step: 7
Training loss: 0.5345474481582642
Validation loss: 1.8265143953343874

Epoch: 5| Step: 8
Training loss: 0.4992736279964447
Validation loss: 1.8379191807521287

Epoch: 5| Step: 9
Training loss: 0.5678604245185852
Validation loss: 1.8434941819919053

Epoch: 5| Step: 10
Training loss: 1.151906132698059
Validation loss: 1.8650131943405315

Epoch: 346| Step: 0
Training loss: 0.3907124698162079
Validation loss: 1.836427370707194

Epoch: 5| Step: 1
Training loss: 0.5373535752296448
Validation loss: 1.839560631782778

Epoch: 5| Step: 2
Training loss: 0.658653974533081
Validation loss: 1.8481661119768698

Epoch: 5| Step: 3
Training loss: 0.48925238847732544
Validation loss: 1.8113110116733018

Epoch: 5| Step: 4
Training loss: 0.8335375785827637
Validation loss: 1.8184101786664737

Epoch: 5| Step: 5
Training loss: 0.6355785727500916
Validation loss: 1.799472205100521

Epoch: 5| Step: 6
Training loss: 0.9475399255752563
Validation loss: 1.7801969141088507

Epoch: 5| Step: 7
Training loss: 0.7529245615005493
Validation loss: 1.7938867974024948

Epoch: 5| Step: 8
Training loss: 0.6472963690757751
Validation loss: 1.8211997862785094

Epoch: 5| Step: 9
Training loss: 0.5268522500991821
Validation loss: 1.7875386796971804

Epoch: 5| Step: 10
Training loss: 0.44006356596946716
Validation loss: 1.790890803901098

Epoch: 347| Step: 0
Training loss: 0.5900156497955322
Validation loss: 1.7919410582511657

Epoch: 5| Step: 1
Training loss: 0.5682163238525391
Validation loss: 1.8129603350034325

Epoch: 5| Step: 2
Training loss: 0.6360918283462524
Validation loss: 1.794548680705409

Epoch: 5| Step: 3
Training loss: 0.506865918636322
Validation loss: 1.7649746197526173

Epoch: 5| Step: 4
Training loss: 0.6388527154922485
Validation loss: 1.783888736078816

Epoch: 5| Step: 5
Training loss: 0.41555675864219666
Validation loss: 1.7704199731990855

Epoch: 5| Step: 6
Training loss: 0.6830019354820251
Validation loss: 1.7976479581607285

Epoch: 5| Step: 7
Training loss: 0.6010112762451172
Validation loss: 1.8020766896586264

Epoch: 5| Step: 8
Training loss: 1.125058650970459
Validation loss: 1.7982408410759383

Epoch: 5| Step: 9
Training loss: 0.6428495049476624
Validation loss: 1.8108359600908013

Epoch: 5| Step: 10
Training loss: 0.299475759267807
Validation loss: 1.7840234720578758

Epoch: 348| Step: 0
Training loss: 0.9486786723136902
Validation loss: 1.8395474174971223

Epoch: 5| Step: 1
Training loss: 0.6256674528121948
Validation loss: 1.8326970582367272

Epoch: 5| Step: 2
Training loss: 0.38954049348831177
Validation loss: 1.8267894726927563

Epoch: 5| Step: 3
Training loss: 0.652924656867981
Validation loss: 1.8109544233609272

Epoch: 5| Step: 4
Training loss: 0.32742342352867126
Validation loss: 1.8045291746816328

Epoch: 5| Step: 5
Training loss: 0.7435351610183716
Validation loss: 1.7989081182787496

Epoch: 5| Step: 6
Training loss: 0.4973600506782532
Validation loss: 1.761143369059409

Epoch: 5| Step: 7
Training loss: 0.9000313878059387
Validation loss: 1.7564547882285169

Epoch: 5| Step: 8
Training loss: 0.4344146251678467
Validation loss: 1.7366446013091712

Epoch: 5| Step: 9
Training loss: 0.5673450231552124
Validation loss: 1.729085861995656

Epoch: 5| Step: 10
Training loss: 0.48268699645996094
Validation loss: 1.7326588681949082

Epoch: 349| Step: 0
Training loss: 0.815621554851532
Validation loss: 1.7243021457426009

Epoch: 5| Step: 1
Training loss: 0.5892320275306702
Validation loss: 1.7110679354718936

Epoch: 5| Step: 2
Training loss: 0.7282460331916809
Validation loss: 1.7452138470065208

Epoch: 5| Step: 3
Training loss: 0.3788684606552124
Validation loss: 1.7357520775128437

Epoch: 5| Step: 4
Training loss: 0.756986141204834
Validation loss: 1.7460719141908871

Epoch: 5| Step: 5
Training loss: 0.4819226861000061
Validation loss: 1.76796160205718

Epoch: 5| Step: 6
Training loss: 0.5489162802696228
Validation loss: 1.7902451561343284

Epoch: 5| Step: 7
Training loss: 0.5051020383834839
Validation loss: 1.8045007105796569

Epoch: 5| Step: 8
Training loss: 0.6787245869636536
Validation loss: 1.822185452266406

Epoch: 5| Step: 9
Training loss: 0.4984757900238037
Validation loss: 1.8118776890539354

Epoch: 5| Step: 10
Training loss: 0.6946930885314941
Validation loss: 1.8132610526136173

Epoch: 350| Step: 0
Training loss: 0.5610771179199219
Validation loss: 1.7873771857189875

Epoch: 5| Step: 1
Training loss: 0.5206292271614075
Validation loss: 1.7428265117829846

Epoch: 5| Step: 2
Training loss: 0.607184648513794
Validation loss: 1.7566499684446601

Epoch: 5| Step: 3
Training loss: 0.5850287675857544
Validation loss: 1.7588730101944299

Epoch: 5| Step: 4
Training loss: 0.7613080739974976
Validation loss: 1.7443896262876448

Epoch: 5| Step: 5
Training loss: 0.6618030071258545
Validation loss: 1.7305700471324306

Epoch: 5| Step: 6
Training loss: 0.5902830958366394
Validation loss: 1.7403106920180782

Epoch: 5| Step: 7
Training loss: 0.4173796772956848
Validation loss: 1.773381313970012

Epoch: 5| Step: 8
Training loss: 0.769600510597229
Validation loss: 1.7614251131652503

Epoch: 5| Step: 9
Training loss: 0.4422883093357086
Validation loss: 1.800246770663928

Epoch: 5| Step: 10
Training loss: 0.770554780960083
Validation loss: 1.8137676844032862

Epoch: 351| Step: 0
Training loss: 0.6774624586105347
Validation loss: 1.8530185812263078

Epoch: 5| Step: 1
Training loss: 0.5904842615127563
Validation loss: 1.8453261621536747

Epoch: 5| Step: 2
Training loss: 0.44942373037338257
Validation loss: 1.7951762996694094

Epoch: 5| Step: 3
Training loss: 0.5395483374595642
Validation loss: 1.8552288073365406

Epoch: 5| Step: 4
Training loss: 0.7826327085494995
Validation loss: 1.885306481392153

Epoch: 5| Step: 5
Training loss: 0.96809321641922
Validation loss: 1.8259404205506848

Epoch: 5| Step: 6
Training loss: 0.561660885810852
Validation loss: 1.7638051381675146

Epoch: 5| Step: 7
Training loss: 0.6009466052055359
Validation loss: 1.7874054831843222

Epoch: 5| Step: 8
Training loss: 0.6668264269828796
Validation loss: 1.786773092003279

Epoch: 5| Step: 9
Training loss: 0.6249862909317017
Validation loss: 1.8131067124746179

Epoch: 5| Step: 10
Training loss: 0.675762951374054
Validation loss: 1.816220876991108

Epoch: 352| Step: 0
Training loss: 0.4934925138950348
Validation loss: 1.7956362821722542

Epoch: 5| Step: 1
Training loss: 0.4227479100227356
Validation loss: 1.7749614010574997

Epoch: 5| Step: 2
Training loss: 0.5506342649459839
Validation loss: 1.801329897296044

Epoch: 5| Step: 3
Training loss: 0.7357476949691772
Validation loss: 1.8149091005325317

Epoch: 5| Step: 4
Training loss: 0.40548038482666016
Validation loss: 1.8581977326382872

Epoch: 5| Step: 5
Training loss: 0.9519979357719421
Validation loss: 1.8801279837085354

Epoch: 5| Step: 6
Training loss: 1.0060386657714844
Validation loss: 1.8397876767702

Epoch: 5| Step: 7
Training loss: 0.5115461945533752
Validation loss: 1.7531917723276282

Epoch: 5| Step: 8
Training loss: 0.6609131693840027
Validation loss: 1.748940989535342

Epoch: 5| Step: 9
Training loss: 0.826982855796814
Validation loss: 1.7575573690475956

Epoch: 5| Step: 10
Training loss: 0.6859214901924133
Validation loss: 1.7617272433414255

Epoch: 353| Step: 0
Training loss: 0.5154028534889221
Validation loss: 1.7775940125988376

Epoch: 5| Step: 1
Training loss: 0.707562267780304
Validation loss: 1.7608091280024538

Epoch: 5| Step: 2
Training loss: 0.6413140296936035
Validation loss: 1.7458543354465115

Epoch: 5| Step: 3
Training loss: 0.7575724124908447
Validation loss: 1.7291664641390565

Epoch: 5| Step: 4
Training loss: 0.78025883436203
Validation loss: 1.729485745071083

Epoch: 5| Step: 5
Training loss: 0.6214338541030884
Validation loss: 1.7433104976530998

Epoch: 5| Step: 6
Training loss: 0.5250467658042908
Validation loss: 1.7570089486337477

Epoch: 5| Step: 7
Training loss: 0.8732694387435913
Validation loss: 1.766224172807509

Epoch: 5| Step: 8
Training loss: 0.5494860410690308
Validation loss: 1.7527182256021807

Epoch: 5| Step: 9
Training loss: 0.7605502605438232
Validation loss: 1.733138435630388

Epoch: 5| Step: 10
Training loss: 0.32339033484458923
Validation loss: 1.756673748775195

Epoch: 354| Step: 0
Training loss: 0.5769671201705933
Validation loss: 1.7455021501869283

Epoch: 5| Step: 1
Training loss: 0.8882417678833008
Validation loss: 1.748522154746517

Epoch: 5| Step: 2
Training loss: 0.5499201416969299
Validation loss: 1.7503276191731936

Epoch: 5| Step: 3
Training loss: 0.31213322281837463
Validation loss: 1.7687829950804352

Epoch: 5| Step: 4
Training loss: 0.6195909976959229
Validation loss: 1.7801786379147602

Epoch: 5| Step: 5
Training loss: 0.5400079488754272
Validation loss: 1.814185598845123

Epoch: 5| Step: 6
Training loss: 0.29129546880722046
Validation loss: 1.80724415856023

Epoch: 5| Step: 7
Training loss: 0.5783048868179321
Validation loss: 1.8151513966180945

Epoch: 5| Step: 8
Training loss: 0.8343342542648315
Validation loss: 1.8184595902760823

Epoch: 5| Step: 9
Training loss: 0.6464051008224487
Validation loss: 1.8077591234637844

Epoch: 5| Step: 10
Training loss: 0.6851839423179626
Validation loss: 1.7587028934109596

Epoch: 355| Step: 0
Training loss: 0.38041216135025024
Validation loss: 1.7651396618094495

Epoch: 5| Step: 1
Training loss: 0.44233447313308716
Validation loss: 1.7926731647983674

Epoch: 5| Step: 2
Training loss: 0.4283750653266907
Validation loss: 1.7666435985155002

Epoch: 5| Step: 3
Training loss: 0.7688154578208923
Validation loss: 1.7852877634827808

Epoch: 5| Step: 4
Training loss: 0.5376293063163757
Validation loss: 1.7415991214013868

Epoch: 5| Step: 5
Training loss: 0.7730098962783813
Validation loss: 1.7591626413406865

Epoch: 5| Step: 6
Training loss: 0.5193993449211121
Validation loss: 1.7473114434108938

Epoch: 5| Step: 7
Training loss: 0.6193596124649048
Validation loss: 1.7189028275910245

Epoch: 5| Step: 8
Training loss: 0.39150288701057434
Validation loss: 1.7232928365789435

Epoch: 5| Step: 9
Training loss: 0.7240298390388489
Validation loss: 1.732552420708441

Epoch: 5| Step: 10
Training loss: 0.7306139469146729
Validation loss: 1.7536707270529963

Epoch: 356| Step: 0
Training loss: 0.6751787066459656
Validation loss: 1.7480176379603725

Epoch: 5| Step: 1
Training loss: 0.5111697912216187
Validation loss: 1.7347828931705926

Epoch: 5| Step: 2
Training loss: 0.8242219090461731
Validation loss: 1.7521790407037223

Epoch: 5| Step: 3
Training loss: 0.46610841155052185
Validation loss: 1.7510575440622145

Epoch: 5| Step: 4
Training loss: 0.3861834406852722
Validation loss: 1.7098271013588033

Epoch: 5| Step: 5
Training loss: 0.8265373110771179
Validation loss: 1.7351994642647364

Epoch: 5| Step: 6
Training loss: 0.5244630575180054
Validation loss: 1.7346579990079325

Epoch: 5| Step: 7
Training loss: 0.6902856230735779
Validation loss: 1.7719663394394742

Epoch: 5| Step: 8
Training loss: 0.2477428913116455
Validation loss: 1.7780254553723078

Epoch: 5| Step: 9
Training loss: 0.6387246251106262
Validation loss: 1.836092169566821

Epoch: 5| Step: 10
Training loss: 0.48762765526771545
Validation loss: 1.815598500672207

Epoch: 357| Step: 0
Training loss: 0.43725958466529846
Validation loss: 1.8265024833781744

Epoch: 5| Step: 1
Training loss: 0.30178526043891907
Validation loss: 1.7977268119012155

Epoch: 5| Step: 2
Training loss: 0.7677119374275208
Validation loss: 1.7667889274576658

Epoch: 5| Step: 3
Training loss: 0.4588245451450348
Validation loss: 1.7506154365437006

Epoch: 5| Step: 4
Training loss: 0.7533974647521973
Validation loss: 1.7299317236869567

Epoch: 5| Step: 5
Training loss: 0.4745873808860779
Validation loss: 1.7505531695581251

Epoch: 5| Step: 6
Training loss: 0.5432819128036499
Validation loss: 1.7469895488472396

Epoch: 5| Step: 7
Training loss: 0.5737271904945374
Validation loss: 1.7414604297248266

Epoch: 5| Step: 8
Training loss: 0.6547247767448425
Validation loss: 1.7339010097647225

Epoch: 5| Step: 9
Training loss: 0.7827851176261902
Validation loss: 1.7604928529390724

Epoch: 5| Step: 10
Training loss: 0.519168496131897
Validation loss: 1.7611727919629825

Epoch: 358| Step: 0
Training loss: 0.5259152054786682
Validation loss: 1.7563059342804777

Epoch: 5| Step: 1
Training loss: 0.7318057417869568
Validation loss: 1.7588741087144422

Epoch: 5| Step: 2
Training loss: 0.3746243119239807
Validation loss: 1.75708572582532

Epoch: 5| Step: 3
Training loss: 0.5266057252883911
Validation loss: 1.7576349883951166

Epoch: 5| Step: 4
Training loss: 0.7188990116119385
Validation loss: 1.7562450978063768

Epoch: 5| Step: 5
Training loss: 0.4105820059776306
Validation loss: 1.7692924622566468

Epoch: 5| Step: 6
Training loss: 0.7891420125961304
Validation loss: 1.763196696517288

Epoch: 5| Step: 7
Training loss: 0.4950525760650635
Validation loss: 1.7519963249083488

Epoch: 5| Step: 8
Training loss: 0.7002353072166443
Validation loss: 1.7675816858968427

Epoch: 5| Step: 9
Training loss: 0.6035202741622925
Validation loss: 1.7690476576487224

Epoch: 5| Step: 10
Training loss: 0.41454824805259705
Validation loss: 1.809877449466336

Epoch: 359| Step: 0
Training loss: 0.3506632447242737
Validation loss: 1.843204181681397

Epoch: 5| Step: 1
Training loss: 0.4831703305244446
Validation loss: 1.882205278642716

Epoch: 5| Step: 2
Training loss: 0.5820063352584839
Validation loss: 1.8141265300012404

Epoch: 5| Step: 3
Training loss: 0.6263532042503357
Validation loss: 1.817641414621825

Epoch: 5| Step: 4
Training loss: 0.6119064092636108
Validation loss: 1.7817564882257932

Epoch: 5| Step: 5
Training loss: 0.7676820755004883
Validation loss: 1.7633387504085418

Epoch: 5| Step: 6
Training loss: 0.730315625667572
Validation loss: 1.771591886397331

Epoch: 5| Step: 7
Training loss: 0.41173678636550903
Validation loss: 1.7519473939813592

Epoch: 5| Step: 8
Training loss: 0.42097586393356323
Validation loss: 1.7617615653622536

Epoch: 5| Step: 9
Training loss: 0.6625093221664429
Validation loss: 1.743787573229882

Epoch: 5| Step: 10
Training loss: 0.5437957644462585
Validation loss: 1.7583605768860027

Epoch: 360| Step: 0
Training loss: 0.24977242946624756
Validation loss: 1.7510435017206336

Epoch: 5| Step: 1
Training loss: 0.6189504861831665
Validation loss: 1.7599841971551218

Epoch: 5| Step: 2
Training loss: 0.6291464567184448
Validation loss: 1.7893472743290726

Epoch: 5| Step: 3
Training loss: 0.7493849396705627
Validation loss: 1.7920754007113877

Epoch: 5| Step: 4
Training loss: 0.5059617161750793
Validation loss: 1.8158445640276837

Epoch: 5| Step: 5
Training loss: 0.3990466892719269
Validation loss: 1.8225620126211515

Epoch: 5| Step: 6
Training loss: 0.8988691568374634
Validation loss: 1.8392305656145977

Epoch: 5| Step: 7
Training loss: 0.48669537901878357
Validation loss: 1.8308757658927672

Epoch: 5| Step: 8
Training loss: 0.548349142074585
Validation loss: 1.844664183996057

Epoch: 5| Step: 9
Training loss: 0.7101044654846191
Validation loss: 1.8236500704160301

Epoch: 5| Step: 10
Training loss: 0.4735374450683594
Validation loss: 1.8241353791247132

Epoch: 361| Step: 0
Training loss: 0.5265126824378967
Validation loss: 1.8255671314013902

Epoch: 5| Step: 1
Training loss: 0.7000848054885864
Validation loss: 1.7914873374405729

Epoch: 5| Step: 2
Training loss: 0.34333616495132446
Validation loss: 1.7832411104632961

Epoch: 5| Step: 3
Training loss: 0.6884411573410034
Validation loss: 1.7807507489317207

Epoch: 5| Step: 4
Training loss: 0.6032798290252686
Validation loss: 1.7726569714084748

Epoch: 5| Step: 5
Training loss: 0.45615315437316895
Validation loss: 1.7669811197506484

Epoch: 5| Step: 6
Training loss: 0.6091184020042419
Validation loss: 1.759950566035445

Epoch: 5| Step: 7
Training loss: 0.38381797075271606
Validation loss: 1.743203701511506

Epoch: 5| Step: 8
Training loss: 0.4214622974395752
Validation loss: 1.7407646358654063

Epoch: 5| Step: 9
Training loss: 0.7457927465438843
Validation loss: 1.7373649715095438

Epoch: 5| Step: 10
Training loss: 0.2652059495449066
Validation loss: 1.705465603900212

Epoch: 362| Step: 0
Training loss: 0.3027690052986145
Validation loss: 1.7392039914284982

Epoch: 5| Step: 1
Training loss: 0.45872563123703003
Validation loss: 1.7406518972048195

Epoch: 5| Step: 2
Training loss: 0.6913555264472961
Validation loss: 1.7854826091438212

Epoch: 5| Step: 3
Training loss: 0.7685732245445251
Validation loss: 1.7994305395310926

Epoch: 5| Step: 4
Training loss: 0.6234697103500366
Validation loss: 1.8101560531123992

Epoch: 5| Step: 5
Training loss: 0.5729994177818298
Validation loss: 1.7827808177599342

Epoch: 5| Step: 6
Training loss: 0.5189850330352783
Validation loss: 1.7695969458549254

Epoch: 5| Step: 7
Training loss: 0.4324564039707184
Validation loss: 1.733671765173635

Epoch: 5| Step: 8
Training loss: 0.577226459980011
Validation loss: 1.7311488518150904

Epoch: 5| Step: 9
Training loss: 0.273573100566864
Validation loss: 1.711616285385624

Epoch: 5| Step: 10
Training loss: 0.5936975479125977
Validation loss: 1.6959415026890334

Epoch: 363| Step: 0
Training loss: 0.3204379379749298
Validation loss: 1.7046137432898245

Epoch: 5| Step: 1
Training loss: 0.5847960114479065
Validation loss: 1.720789409452869

Epoch: 5| Step: 2
Training loss: 0.5205599069595337
Validation loss: 1.7310404175071306

Epoch: 5| Step: 3
Training loss: 0.5590922832489014
Validation loss: 1.7672129651551605

Epoch: 5| Step: 4
Training loss: 0.6554301977157593
Validation loss: 1.728346319608791

Epoch: 5| Step: 5
Training loss: 0.44129905104637146
Validation loss: 1.750416583912347

Epoch: 5| Step: 6
Training loss: 0.4395177364349365
Validation loss: 1.749802040797408

Epoch: 5| Step: 7
Training loss: 0.5774072408676147
Validation loss: 1.7650520160634031

Epoch: 5| Step: 8
Training loss: 0.5611769556999207
Validation loss: 1.7672298633924095

Epoch: 5| Step: 9
Training loss: 0.7419196367263794
Validation loss: 1.7854209792229436

Epoch: 5| Step: 10
Training loss: 0.5014182925224304
Validation loss: 1.7619502249584402

Epoch: 364| Step: 0
Training loss: 0.520391583442688
Validation loss: 1.81247321380082

Epoch: 5| Step: 1
Training loss: 0.5190373063087463
Validation loss: 1.7827717347811627

Epoch: 5| Step: 2
Training loss: 0.45273932814598083
Validation loss: 1.8034453263846777

Epoch: 5| Step: 3
Training loss: 0.29379358887672424
Validation loss: 1.7513685328986055

Epoch: 5| Step: 4
Training loss: 0.7350099086761475
Validation loss: 1.7413486191021499

Epoch: 5| Step: 5
Training loss: 0.415513813495636
Validation loss: 1.7215659977287374

Epoch: 5| Step: 6
Training loss: 0.6614275574684143
Validation loss: 1.680347998936971

Epoch: 5| Step: 7
Training loss: 0.8007558584213257
Validation loss: 1.6975946721210275

Epoch: 5| Step: 8
Training loss: 0.41082268953323364
Validation loss: 1.720362522268808

Epoch: 5| Step: 9
Training loss: 0.437234103679657
Validation loss: 1.696678005239015

Epoch: 5| Step: 10
Training loss: 0.4761331081390381
Validation loss: 1.7329652232508506

Epoch: 365| Step: 0
Training loss: 0.31721487641334534
Validation loss: 1.7335629181195331

Epoch: 5| Step: 1
Training loss: 0.962997317314148
Validation loss: 1.7485963221519225

Epoch: 5| Step: 2
Training loss: 0.5211035013198853
Validation loss: 1.7598290956148537

Epoch: 5| Step: 3
Training loss: 0.6873674988746643
Validation loss: 1.771688651013118

Epoch: 5| Step: 4
Training loss: 0.45053166151046753
Validation loss: 1.767904785371596

Epoch: 5| Step: 5
Training loss: 0.2897205054759979
Validation loss: 1.750499354895725

Epoch: 5| Step: 6
Training loss: 0.40299147367477417
Validation loss: 1.737477312805832

Epoch: 5| Step: 7
Training loss: 0.4535413384437561
Validation loss: 1.7396380811609247

Epoch: 5| Step: 8
Training loss: 0.41197091341018677
Validation loss: 1.7429585905485256

Epoch: 5| Step: 9
Training loss: 0.45863208174705505
Validation loss: 1.7531763456201042

Epoch: 5| Step: 10
Training loss: 0.6604850888252258
Validation loss: 1.7659642440016552

Epoch: 366| Step: 0
Training loss: 0.5927737951278687
Validation loss: 1.7632805993480067

Epoch: 5| Step: 1
Training loss: 0.4750664234161377
Validation loss: 1.7541562690529773

Epoch: 5| Step: 2
Training loss: 0.5392740964889526
Validation loss: 1.763759946310392

Epoch: 5| Step: 3
Training loss: 0.6543053388595581
Validation loss: 1.7697373026160783

Epoch: 5| Step: 4
Training loss: 0.2716568112373352
Validation loss: 1.7319331938220608

Epoch: 5| Step: 5
Training loss: 0.5285221338272095
Validation loss: 1.763672701774105

Epoch: 5| Step: 6
Training loss: 0.3768561780452728
Validation loss: 1.7441969430574806

Epoch: 5| Step: 7
Training loss: 0.7915806174278259
Validation loss: 1.7750729245524253

Epoch: 5| Step: 8
Training loss: 0.20312324166297913
Validation loss: 1.7734000464921356

Epoch: 5| Step: 9
Training loss: 0.539517343044281
Validation loss: 1.8197624093742781

Epoch: 5| Step: 10
Training loss: 0.4620518684387207
Validation loss: 1.8445077980718305

Epoch: 367| Step: 0
Training loss: 0.45889586210250854
Validation loss: 1.8315113206063547

Epoch: 5| Step: 1
Training loss: 0.5552376508712769
Validation loss: 1.7976886239103091

Epoch: 5| Step: 2
Training loss: 0.5644747018814087
Validation loss: 1.79246647127213

Epoch: 5| Step: 3
Training loss: 0.33406296372413635
Validation loss: 1.7800576340767644

Epoch: 5| Step: 4
Training loss: 0.659430205821991
Validation loss: 1.7770768468097975

Epoch: 5| Step: 5
Training loss: 0.6103237867355347
Validation loss: 1.7581330448068597

Epoch: 5| Step: 6
Training loss: 0.4064258933067322
Validation loss: 1.7542602233989264

Epoch: 5| Step: 7
Training loss: 0.5313231348991394
Validation loss: 1.747633872493621

Epoch: 5| Step: 8
Training loss: 0.6666997075080872
Validation loss: 1.8360381831404984

Epoch: 5| Step: 9
Training loss: 0.6381479501724243
Validation loss: 1.7767971138800345

Epoch: 5| Step: 10
Training loss: 0.47900891304016113
Validation loss: 1.7840159195725636

Epoch: 368| Step: 0
Training loss: 0.385469526052475
Validation loss: 1.7531772903216782

Epoch: 5| Step: 1
Training loss: 0.6358421444892883
Validation loss: 1.772591515894859

Epoch: 5| Step: 2
Training loss: 0.5373324751853943
Validation loss: 1.7651626410022858

Epoch: 5| Step: 3
Training loss: 0.5308713912963867
Validation loss: 1.7713257381992955

Epoch: 5| Step: 4
Training loss: 0.4751741290092468
Validation loss: 1.7423327481874855

Epoch: 5| Step: 5
Training loss: 0.58514404296875
Validation loss: 1.7466243749023767

Epoch: 5| Step: 6
Training loss: 0.775174617767334
Validation loss: 1.7669071548728532

Epoch: 5| Step: 7
Training loss: 0.44613009691238403
Validation loss: 1.7658003555831088

Epoch: 5| Step: 8
Training loss: 0.39081045985221863
Validation loss: 1.7836484716784569

Epoch: 5| Step: 9
Training loss: 0.4006583094596863
Validation loss: 1.7528070057592084

Epoch: 5| Step: 10
Training loss: 0.49337780475616455
Validation loss: 1.7438015476349862

Epoch: 369| Step: 0
Training loss: 0.4016839563846588
Validation loss: 1.7397404075950704

Epoch: 5| Step: 1
Training loss: 0.6765998601913452
Validation loss: 1.7315248468870759

Epoch: 5| Step: 2
Training loss: 0.3642158508300781
Validation loss: 1.7555712884472263

Epoch: 5| Step: 3
Training loss: 0.5495232343673706
Validation loss: 1.7466450096458517

Epoch: 5| Step: 4
Training loss: 0.43486467003822327
Validation loss: 1.7806783645383772

Epoch: 5| Step: 5
Training loss: 0.4495517611503601
Validation loss: 1.7512802962333924

Epoch: 5| Step: 6
Training loss: 0.2545900344848633
Validation loss: 1.7649970528899983

Epoch: 5| Step: 7
Training loss: 0.4214995801448822
Validation loss: 1.7573835484443172

Epoch: 5| Step: 8
Training loss: 0.7504043579101562
Validation loss: 1.7757510498005857

Epoch: 5| Step: 9
Training loss: 0.6486935615539551
Validation loss: 1.7943641024251138

Epoch: 5| Step: 10
Training loss: 0.5107147097587585
Validation loss: 1.7015346801409157

Epoch: 370| Step: 0
Training loss: 0.47116953134536743
Validation loss: 1.748249835865472

Epoch: 5| Step: 1
Training loss: 0.6032353043556213
Validation loss: 1.7232938222987677

Epoch: 5| Step: 2
Training loss: 0.6257262229919434
Validation loss: 1.7423973288587344

Epoch: 5| Step: 3
Training loss: 0.41675829887390137
Validation loss: 1.7522900924887708

Epoch: 5| Step: 4
Training loss: 0.49403852224349976
Validation loss: 1.763487014719235

Epoch: 5| Step: 5
Training loss: 0.37543222308158875
Validation loss: 1.7378935224266463

Epoch: 5| Step: 6
Training loss: 0.6559485197067261
Validation loss: 1.758798740243399

Epoch: 5| Step: 7
Training loss: 0.43612369894981384
Validation loss: 1.7580564765519993

Epoch: 5| Step: 8
Training loss: 0.41575247049331665
Validation loss: 1.802513184085969

Epoch: 5| Step: 9
Training loss: 0.6868655681610107
Validation loss: 1.8200487475241385

Epoch: 5| Step: 10
Training loss: 0.6332112550735474
Validation loss: 1.754968274024225

Epoch: 371| Step: 0
Training loss: 0.7993023991584778
Validation loss: 1.712791919708252

Epoch: 5| Step: 1
Training loss: 0.4616560935974121
Validation loss: 1.7351004301860768

Epoch: 5| Step: 2
Training loss: 0.606078028678894
Validation loss: 1.7783844855523878

Epoch: 5| Step: 3
Training loss: 0.5576790571212769
Validation loss: 1.8185729339558592

Epoch: 5| Step: 4
Training loss: 0.6413766741752625
Validation loss: 1.798845644920103

Epoch: 5| Step: 5
Training loss: 0.5877283811569214
Validation loss: 1.7796335784337853

Epoch: 5| Step: 6
Training loss: 0.4561910629272461
Validation loss: 1.757767314551979

Epoch: 5| Step: 7
Training loss: 0.3506590723991394
Validation loss: 1.8098712557105607

Epoch: 5| Step: 8
Training loss: 0.7351495623588562
Validation loss: 1.8492665444650958

Epoch: 5| Step: 9
Training loss: 0.6612206697463989
Validation loss: 1.8575311796639555

Epoch: 5| Step: 10
Training loss: 0.31344571709632874
Validation loss: 1.868874030728494

Epoch: 372| Step: 0
Training loss: 0.34134307503700256
Validation loss: 1.8092397259127708

Epoch: 5| Step: 1
Training loss: 0.6817847490310669
Validation loss: 1.798713699463875

Epoch: 5| Step: 2
Training loss: 0.41272515058517456
Validation loss: 1.8153364594264696

Epoch: 5| Step: 3
Training loss: 0.6058900356292725
Validation loss: 1.8062994287860008

Epoch: 5| Step: 4
Training loss: 0.6039738655090332
Validation loss: 1.7835428509660947

Epoch: 5| Step: 5
Training loss: 0.5028430223464966
Validation loss: 1.7820195357004802

Epoch: 5| Step: 6
Training loss: 0.4127916693687439
Validation loss: 1.790289750663183

Epoch: 5| Step: 7
Training loss: 0.5389674305915833
Validation loss: 1.7392524006546184

Epoch: 5| Step: 8
Training loss: 0.6612635850906372
Validation loss: 1.7723223996418778

Epoch: 5| Step: 9
Training loss: 0.5128125548362732
Validation loss: 1.778636738818179

Epoch: 5| Step: 10
Training loss: 0.5649588704109192
Validation loss: 1.7548011938730876

Epoch: 373| Step: 0
Training loss: 0.4412466883659363
Validation loss: 1.757154518558133

Epoch: 5| Step: 1
Training loss: 0.3471425175666809
Validation loss: 1.7565683677632322

Epoch: 5| Step: 2
Training loss: 0.4451560080051422
Validation loss: 1.7619148826086393

Epoch: 5| Step: 3
Training loss: 0.42270976305007935
Validation loss: 1.8031095509888024

Epoch: 5| Step: 4
Training loss: 0.42404705286026
Validation loss: 1.7856406960436093

Epoch: 5| Step: 5
Training loss: 0.738431453704834
Validation loss: 1.7825892484316261

Epoch: 5| Step: 6
Training loss: 0.7456009984016418
Validation loss: 1.7898172588758572

Epoch: 5| Step: 7
Training loss: 0.5826528668403625
Validation loss: 1.7987612267976165

Epoch: 5| Step: 8
Training loss: 0.4928578734397888
Validation loss: 1.8019804352073259

Epoch: 5| Step: 9
Training loss: 0.35770171880722046
Validation loss: 1.785583398675406

Epoch: 5| Step: 10
Training loss: 0.37154915928840637
Validation loss: 1.7387031662848689

Epoch: 374| Step: 0
Training loss: 0.49012452363967896
Validation loss: 1.7507965769819034

Epoch: 5| Step: 1
Training loss: 0.4512695372104645
Validation loss: 1.757422492068301

Epoch: 5| Step: 2
Training loss: 0.5783327221870422
Validation loss: 1.79077281490449

Epoch: 5| Step: 3
Training loss: 0.37497419118881226
Validation loss: 1.7843696032800982

Epoch: 5| Step: 4
Training loss: 0.29775816202163696
Validation loss: 1.7916381935919485

Epoch: 5| Step: 5
Training loss: 0.40254440903663635
Validation loss: 1.8198111377736574

Epoch: 5| Step: 6
Training loss: 0.5065621733665466
Validation loss: 1.8326878945032756

Epoch: 5| Step: 7
Training loss: 0.33058467507362366
Validation loss: 1.8069349950359714

Epoch: 5| Step: 8
Training loss: 0.5391436219215393
Validation loss: 1.7800664068550192

Epoch: 5| Step: 9
Training loss: 0.5792766213417053
Validation loss: 1.7786712236301874

Epoch: 5| Step: 10
Training loss: 0.46809202432632446
Validation loss: 1.7841497569955804

Epoch: 375| Step: 0
Training loss: 0.4128599762916565
Validation loss: 1.7741750760744976

Epoch: 5| Step: 1
Training loss: 0.2546122670173645
Validation loss: 1.7356854472109067

Epoch: 5| Step: 2
Training loss: 0.6568211317062378
Validation loss: 1.7573943650850685

Epoch: 5| Step: 3
Training loss: 0.27359455823898315
Validation loss: 1.7632568856721282

Epoch: 5| Step: 4
Training loss: 0.4780917763710022
Validation loss: 1.7570643348078574

Epoch: 5| Step: 5
Training loss: 0.46089044213294983
Validation loss: 1.7846019421854327

Epoch: 5| Step: 6
Training loss: 0.5630500912666321
Validation loss: 1.781703584937639

Epoch: 5| Step: 7
Training loss: 0.35465455055236816
Validation loss: 1.7625896956330986

Epoch: 5| Step: 8
Training loss: 0.3806878328323364
Validation loss: 1.7862654937210904

Epoch: 5| Step: 9
Training loss: 0.7288013696670532
Validation loss: 1.7797607247547438

Epoch: 5| Step: 10
Training loss: 0.5886178016662598
Validation loss: 1.7997573729484313

Epoch: 376| Step: 0
Training loss: 0.3329508900642395
Validation loss: 1.8113639047068935

Epoch: 5| Step: 1
Training loss: 0.3908645808696747
Validation loss: 1.8019584840343845

Epoch: 5| Step: 2
Training loss: 0.5974395871162415
Validation loss: 1.759196932597827

Epoch: 5| Step: 3
Training loss: 0.4562184810638428
Validation loss: 1.7420021641638972

Epoch: 5| Step: 4
Training loss: 0.5490835905075073
Validation loss: 1.7307867004025368

Epoch: 5| Step: 5
Training loss: 0.4175308346748352
Validation loss: 1.7392762053397395

Epoch: 5| Step: 6
Training loss: 0.39328187704086304
Validation loss: 1.741317843878141

Epoch: 5| Step: 7
Training loss: 0.3585665225982666
Validation loss: 1.750783589578444

Epoch: 5| Step: 8
Training loss: 0.6680516004562378
Validation loss: 1.750952624505566

Epoch: 5| Step: 9
Training loss: 0.288670152425766
Validation loss: 1.7691756909893406

Epoch: 5| Step: 10
Training loss: 0.4457637667655945
Validation loss: 1.766718859954547

Epoch: 377| Step: 0
Training loss: 0.3385029733181
Validation loss: 1.7884696414393764

Epoch: 5| Step: 1
Training loss: 0.42975419759750366
Validation loss: 1.8208842405708887

Epoch: 5| Step: 2
Training loss: 0.5622711181640625
Validation loss: 1.8645740170632639

Epoch: 5| Step: 3
Training loss: 0.7010401487350464
Validation loss: 1.8897198515553628

Epoch: 5| Step: 4
Training loss: 0.4899630546569824
Validation loss: 1.8414107086837932

Epoch: 5| Step: 5
Training loss: 0.37014228105545044
Validation loss: 1.7885538224251039

Epoch: 5| Step: 6
Training loss: 0.42118972539901733
Validation loss: 1.794169415709793

Epoch: 5| Step: 7
Training loss: 0.5115863680839539
Validation loss: 1.7849878829012635

Epoch: 5| Step: 8
Training loss: 0.55145663022995
Validation loss: 1.8106330351162983

Epoch: 5| Step: 9
Training loss: 0.5639110803604126
Validation loss: 1.7631595250098937

Epoch: 5| Step: 10
Training loss: 0.3124373257160187
Validation loss: 1.7677964049000894

Epoch: 378| Step: 0
Training loss: 0.426567405462265
Validation loss: 1.7814050553947367

Epoch: 5| Step: 1
Training loss: 0.2669250965118408
Validation loss: 1.768122298743135

Epoch: 5| Step: 2
Training loss: 0.3330843448638916
Validation loss: 1.767145042137433

Epoch: 5| Step: 3
Training loss: 0.32635945081710815
Validation loss: 1.7580322437388922

Epoch: 5| Step: 4
Training loss: 0.46638840436935425
Validation loss: 1.7866203810579033

Epoch: 5| Step: 5
Training loss: 0.34330984950065613
Validation loss: 1.7478535085596063

Epoch: 5| Step: 6
Training loss: 0.6040358543395996
Validation loss: 1.7372568986749137

Epoch: 5| Step: 7
Training loss: 0.4982316493988037
Validation loss: 1.7465902195181897

Epoch: 5| Step: 8
Training loss: 0.25464779138565063
Validation loss: 1.7484992601538216

Epoch: 5| Step: 9
Training loss: 0.48489776253700256
Validation loss: 1.7487708624973093

Epoch: 5| Step: 10
Training loss: 0.789581298828125
Validation loss: 1.746979195584533

Epoch: 379| Step: 0
Training loss: 0.46173399686813354
Validation loss: 1.7427766399998819

Epoch: 5| Step: 1
Training loss: 0.37782809138298035
Validation loss: 1.7541524184647428

Epoch: 5| Step: 2
Training loss: 0.40352144837379456
Validation loss: 1.7479992425569923

Epoch: 5| Step: 3
Training loss: 0.3480558395385742
Validation loss: 1.7723873507591985

Epoch: 5| Step: 4
Training loss: 0.41764482855796814
Validation loss: 1.750003340423748

Epoch: 5| Step: 5
Training loss: 0.21068140864372253
Validation loss: 1.7320234108996648

Epoch: 5| Step: 6
Training loss: 0.4675101339817047
Validation loss: 1.7319555949139338

Epoch: 5| Step: 7
Training loss: 0.27695518732070923
Validation loss: 1.7340747323087466

Epoch: 5| Step: 8
Training loss: 0.4946923851966858
Validation loss: 1.7439633018227034

Epoch: 5| Step: 9
Training loss: 0.6443387269973755
Validation loss: 1.7372581176860358

Epoch: 5| Step: 10
Training loss: 0.38411885499954224
Validation loss: 1.762977542415742

Epoch: 380| Step: 0
Training loss: 0.38963693380355835
Validation loss: 1.7623000491049983

Epoch: 5| Step: 1
Training loss: 0.5211054682731628
Validation loss: 1.7313180520970335

Epoch: 5| Step: 2
Training loss: 0.47149839997291565
Validation loss: 1.7340282329949

Epoch: 5| Step: 3
Training loss: 0.25260886549949646
Validation loss: 1.6928185109169251

Epoch: 5| Step: 4
Training loss: 0.5683315992355347
Validation loss: 1.6707707733236334

Epoch: 5| Step: 5
Training loss: 0.5936821103096008
Validation loss: 1.6679881721414545

Epoch: 5| Step: 6
Training loss: 0.30200058221817017
Validation loss: 1.6893201438329553

Epoch: 5| Step: 7
Training loss: 0.33787432312965393
Validation loss: 1.690816201189513

Epoch: 5| Step: 8
Training loss: 0.3698959946632385
Validation loss: 1.6958159464661793

Epoch: 5| Step: 9
Training loss: 0.25088828802108765
Validation loss: 1.6836775451578119

Epoch: 5| Step: 10
Training loss: 0.45501482486724854
Validation loss: 1.718271622093775

Epoch: 381| Step: 0
Training loss: 0.2981589138507843
Validation loss: 1.7001932205692414

Epoch: 5| Step: 1
Training loss: 0.5299094915390015
Validation loss: 1.7225158599115187

Epoch: 5| Step: 2
Training loss: 0.43451008200645447
Validation loss: 1.7367391970849806

Epoch: 5| Step: 3
Training loss: 0.40433424711227417
Validation loss: 1.7436247359039962

Epoch: 5| Step: 4
Training loss: 0.4649154245853424
Validation loss: 1.7424776297743603

Epoch: 5| Step: 5
Training loss: 0.2958222031593323
Validation loss: 1.711975492456908

Epoch: 5| Step: 6
Training loss: 0.4303761422634125
Validation loss: 1.7345396421288932

Epoch: 5| Step: 7
Training loss: 0.48718777298927307
Validation loss: 1.7188077729235414

Epoch: 5| Step: 8
Training loss: 0.5714319348335266
Validation loss: 1.7097516828967678

Epoch: 5| Step: 9
Training loss: 0.3166487216949463
Validation loss: 1.7320758411961217

Epoch: 5| Step: 10
Training loss: 0.2457389235496521
Validation loss: 1.7440602740933817

Epoch: 382| Step: 0
Training loss: 0.3105519711971283
Validation loss: 1.7454032064766012

Epoch: 5| Step: 1
Training loss: 0.4516821503639221
Validation loss: 1.7219214471437598

Epoch: 5| Step: 2
Training loss: 0.5133501887321472
Validation loss: 1.719855135486972

Epoch: 5| Step: 3
Training loss: 0.3591165244579315
Validation loss: 1.721685835110244

Epoch: 5| Step: 4
Training loss: 0.38609954714775085
Validation loss: 1.741267106866324

Epoch: 5| Step: 5
Training loss: 0.596498966217041
Validation loss: 1.7262690964565481

Epoch: 5| Step: 6
Training loss: 0.3817731738090515
Validation loss: 1.7405867986781622

Epoch: 5| Step: 7
Training loss: 0.27734771370887756
Validation loss: 1.7487623781286261

Epoch: 5| Step: 8
Training loss: 0.3065362870693207
Validation loss: 1.7558327733829457

Epoch: 5| Step: 9
Training loss: 0.4205213189125061
Validation loss: 1.7367865206092916

Epoch: 5| Step: 10
Training loss: 0.2801033556461334
Validation loss: 1.7231674425063594

Epoch: 383| Step: 0
Training loss: 0.2882896065711975
Validation loss: 1.7789982736751597

Epoch: 5| Step: 1
Training loss: 0.39145421981811523
Validation loss: 1.7770269275993429

Epoch: 5| Step: 2
Training loss: 0.4216248393058777
Validation loss: 1.7725321823550808

Epoch: 5| Step: 3
Training loss: 0.6802237033843994
Validation loss: 1.8005316872750559

Epoch: 5| Step: 4
Training loss: 0.56255042552948
Validation loss: 1.78225451900113

Epoch: 5| Step: 5
Training loss: 0.23250126838684082
Validation loss: 1.7466056090529247

Epoch: 5| Step: 6
Training loss: 0.5851253271102905
Validation loss: 1.7754050172785276

Epoch: 5| Step: 7
Training loss: 0.5675972700119019
Validation loss: 1.8113502994660409

Epoch: 5| Step: 8
Training loss: 0.42294272780418396
Validation loss: 1.8170550356629074

Epoch: 5| Step: 9
Training loss: 0.30608224868774414
Validation loss: 1.7967441082000732

Epoch: 5| Step: 10
Training loss: 0.3786054253578186
Validation loss: 1.7397040577344998

Epoch: 384| Step: 0
Training loss: 0.27788084745407104
Validation loss: 1.7327548060365903

Epoch: 5| Step: 1
Training loss: 0.38272804021835327
Validation loss: 1.7442298435395764

Epoch: 5| Step: 2
Training loss: 0.7079106569290161
Validation loss: 1.7350726140442716

Epoch: 5| Step: 3
Training loss: 0.34340357780456543
Validation loss: 1.7171575920556181

Epoch: 5| Step: 4
Training loss: 0.3029819428920746
Validation loss: 1.725492928617744

Epoch: 5| Step: 5
Training loss: 0.37457290291786194
Validation loss: 1.7212723198757376

Epoch: 5| Step: 6
Training loss: 0.6003618836402893
Validation loss: 1.7125380641670638

Epoch: 5| Step: 7
Training loss: 0.6152299642562866
Validation loss: 1.7422400623239496

Epoch: 5| Step: 8
Training loss: 0.3142375349998474
Validation loss: 1.7347940309073335

Epoch: 5| Step: 9
Training loss: 0.5031319260597229
Validation loss: 1.7435859967303533

Epoch: 5| Step: 10
Training loss: 0.18729178607463837
Validation loss: 1.7503246979046894

Epoch: 385| Step: 0
Training loss: 0.349260151386261
Validation loss: 1.7753303050994873

Epoch: 5| Step: 1
Training loss: 0.2639857232570648
Validation loss: 1.7340180617506786

Epoch: 5| Step: 2
Training loss: 0.44546371698379517
Validation loss: 1.7347615047167706

Epoch: 5| Step: 3
Training loss: 0.48490676283836365
Validation loss: 1.7342065354829193

Epoch: 5| Step: 4
Training loss: 0.22018174827098846
Validation loss: 1.6932646023329867

Epoch: 5| Step: 5
Training loss: 0.23596540093421936
Validation loss: 1.7129659396345898

Epoch: 5| Step: 6
Training loss: 0.4087206721305847
Validation loss: 1.729030357894077

Epoch: 5| Step: 7
Training loss: 0.42802461981773376
Validation loss: 1.7358864212548861

Epoch: 5| Step: 8
Training loss: 0.3507044017314911
Validation loss: 1.7534621287417669

Epoch: 5| Step: 9
Training loss: 0.6671153903007507
Validation loss: 1.7350359052740119

Epoch: 5| Step: 10
Training loss: 0.6035696864128113
Validation loss: 1.729135767106087

Epoch: 386| Step: 0
Training loss: 0.23308150470256805
Validation loss: 1.6929647384151336

Epoch: 5| Step: 1
Training loss: 0.4192555844783783
Validation loss: 1.7328393882320774

Epoch: 5| Step: 2
Training loss: 0.26784756779670715
Validation loss: 1.7561843472142373

Epoch: 5| Step: 3
Training loss: 0.4514910578727722
Validation loss: 1.7232830011716453

Epoch: 5| Step: 4
Training loss: 0.32091397047042847
Validation loss: 1.712546786954326

Epoch: 5| Step: 5
Training loss: 0.3959946632385254
Validation loss: 1.7310217990670154

Epoch: 5| Step: 6
Training loss: 0.5051196217536926
Validation loss: 1.7420014450626988

Epoch: 5| Step: 7
Training loss: 0.4819576144218445
Validation loss: 1.7361514235055575

Epoch: 5| Step: 8
Training loss: 0.46036332845687866
Validation loss: 1.729130301424252

Epoch: 5| Step: 9
Training loss: 0.4446011483669281
Validation loss: 1.7128031779361028

Epoch: 5| Step: 10
Training loss: 0.4679308831691742
Validation loss: 1.726302824994569

Epoch: 387| Step: 0
Training loss: 0.32778438925743103
Validation loss: 1.7371865651940788

Epoch: 5| Step: 1
Training loss: 0.603887677192688
Validation loss: 1.7575309443217453

Epoch: 5| Step: 2
Training loss: 0.3737061619758606
Validation loss: 1.735564330572723

Epoch: 5| Step: 3
Training loss: 0.3551635444164276
Validation loss: 1.750829017290505

Epoch: 5| Step: 4
Training loss: 0.3374137282371521
Validation loss: 1.739011279998287

Epoch: 5| Step: 5
Training loss: 0.40994057059288025
Validation loss: 1.7207951725170176

Epoch: 5| Step: 6
Training loss: 0.16923558712005615
Validation loss: 1.707575375033963

Epoch: 5| Step: 7
Training loss: 0.5171085596084595
Validation loss: 1.7307305464180567

Epoch: 5| Step: 8
Training loss: 0.4466431736946106
Validation loss: 1.7353825876789708

Epoch: 5| Step: 9
Training loss: 0.28225383162498474
Validation loss: 1.702811610314154

Epoch: 5| Step: 10
Training loss: 0.5936007499694824
Validation loss: 1.7049640532462829

Epoch: 388| Step: 0
Training loss: 0.3389317989349365
Validation loss: 1.706558721039885

Epoch: 5| Step: 1
Training loss: 0.521103024482727
Validation loss: 1.7002866421976397

Epoch: 5| Step: 2
Training loss: 0.29715290665626526
Validation loss: 1.6976427147465367

Epoch: 5| Step: 3
Training loss: 0.456575483083725
Validation loss: 1.6773308579639723

Epoch: 5| Step: 4
Training loss: 0.4485946595668793
Validation loss: 1.7180351108633063

Epoch: 5| Step: 5
Training loss: 0.47894057631492615
Validation loss: 1.6748953134782854

Epoch: 5| Step: 6
Training loss: 0.5174103379249573
Validation loss: 1.7247099876403809

Epoch: 5| Step: 7
Training loss: 0.4563310146331787
Validation loss: 1.6906971726366269

Epoch: 5| Step: 8
Training loss: 0.20237457752227783
Validation loss: 1.6872898160770375

Epoch: 5| Step: 9
Training loss: 0.31222063302993774
Validation loss: 1.6966281206377092

Epoch: 5| Step: 10
Training loss: 0.203059583902359
Validation loss: 1.7044393888083837

Epoch: 389| Step: 0
Training loss: 0.5056964159011841
Validation loss: 1.7016337866424232

Epoch: 5| Step: 1
Training loss: 0.36725109815597534
Validation loss: 1.6718343406595209

Epoch: 5| Step: 2
Training loss: 0.1709812432527542
Validation loss: 1.6952996382149317

Epoch: 5| Step: 3
Training loss: 0.3245108723640442
Validation loss: 1.69898021605707

Epoch: 5| Step: 4
Training loss: 0.35691675543785095
Validation loss: 1.6824932508571173

Epoch: 5| Step: 5
Training loss: 0.40220969915390015
Validation loss: 1.715426774435146

Epoch: 5| Step: 6
Training loss: 0.5783013701438904
Validation loss: 1.6924846377424014

Epoch: 5| Step: 7
Training loss: 0.41326791048049927
Validation loss: 1.6916798340376986

Epoch: 5| Step: 8
Training loss: 0.20620493590831757
Validation loss: 1.711038520259242

Epoch: 5| Step: 9
Training loss: 0.417764812707901
Validation loss: 1.732957036264481

Epoch: 5| Step: 10
Training loss: 0.5006283521652222
Validation loss: 1.736826910767504

Epoch: 390| Step: 0
Training loss: 0.567031979560852
Validation loss: 1.7295162113763953

Epoch: 5| Step: 1
Training loss: 0.5207217335700989
Validation loss: 1.7250991059887795

Epoch: 5| Step: 2
Training loss: 0.3198835849761963
Validation loss: 1.7110972648025842

Epoch: 5| Step: 3
Training loss: 0.4930146634578705
Validation loss: 1.7022554464237665

Epoch: 5| Step: 4
Training loss: 0.23163263499736786
Validation loss: 1.709057169575845

Epoch: 5| Step: 5
Training loss: 0.3664703071117401
Validation loss: 1.6899272780264578

Epoch: 5| Step: 6
Training loss: 0.17224374413490295
Validation loss: 1.6826569021389048

Epoch: 5| Step: 7
Training loss: 0.4049331247806549
Validation loss: 1.688119315331982

Epoch: 5| Step: 8
Training loss: 0.21590204536914825
Validation loss: 1.6950617439003401

Epoch: 5| Step: 9
Training loss: 0.4437008500099182
Validation loss: 1.7126189098563245

Epoch: 5| Step: 10
Training loss: 0.3167136609554291
Validation loss: 1.7186106994587889

Epoch: 391| Step: 0
Training loss: 0.5592325329780579
Validation loss: 1.7299122374544862

Epoch: 5| Step: 1
Training loss: 0.35905885696411133
Validation loss: 1.7041783960916663

Epoch: 5| Step: 2
Training loss: 0.37145325541496277
Validation loss: 1.6636469146256805

Epoch: 5| Step: 3
Training loss: 0.37721046805381775
Validation loss: 1.695140625840874

Epoch: 5| Step: 4
Training loss: 0.29628923535346985
Validation loss: 1.667217295656922

Epoch: 5| Step: 5
Training loss: 0.3630741536617279
Validation loss: 1.6670941537426365

Epoch: 5| Step: 6
Training loss: 0.39772090315818787
Validation loss: 1.7094802189898748

Epoch: 5| Step: 7
Training loss: 0.24153093993663788
Validation loss: 1.6873850668630292

Epoch: 5| Step: 8
Training loss: 0.26317423582077026
Validation loss: 1.6838711141258158

Epoch: 5| Step: 9
Training loss: 0.40893030166625977
Validation loss: 1.7324571109587146

Epoch: 5| Step: 10
Training loss: 0.4951482117176056
Validation loss: 1.720345474058582

Epoch: 392| Step: 0
Training loss: 0.34194329380989075
Validation loss: 1.7338935867432625

Epoch: 5| Step: 1
Training loss: 0.2632891833782196
Validation loss: 1.7014910239045338

Epoch: 5| Step: 2
Training loss: 0.32794541120529175
Validation loss: 1.6873290923333937

Epoch: 5| Step: 3
Training loss: 0.3807583451271057
Validation loss: 1.7256445186112517

Epoch: 5| Step: 4
Training loss: 0.332034170627594
Validation loss: 1.7046949978797667

Epoch: 5| Step: 5
Training loss: 0.4160310626029968
Validation loss: 1.718620277220203

Epoch: 5| Step: 6
Training loss: 0.22919397056102753
Validation loss: 1.7284183104832966

Epoch: 5| Step: 7
Training loss: 0.2250320017337799
Validation loss: 1.7066075507030691

Epoch: 5| Step: 8
Training loss: 0.5292365550994873
Validation loss: 1.7326185690459384

Epoch: 5| Step: 9
Training loss: 0.5612372159957886
Validation loss: 1.7281381314800632

Epoch: 5| Step: 10
Training loss: 0.5043619275093079
Validation loss: 1.722106836175406

Epoch: 393| Step: 0
Training loss: 0.24951830506324768
Validation loss: 1.7097278256570139

Epoch: 5| Step: 1
Training loss: 0.2069675475358963
Validation loss: 1.7003668892768122

Epoch: 5| Step: 2
Training loss: 0.28079086542129517
Validation loss: 1.7478799781491678

Epoch: 5| Step: 3
Training loss: 0.44839534163475037
Validation loss: 1.7312768684920443

Epoch: 5| Step: 4
Training loss: 0.6179027557373047
Validation loss: 1.7439152835517802

Epoch: 5| Step: 5
Training loss: 0.3680686354637146
Validation loss: 1.7239273068725423

Epoch: 5| Step: 6
Training loss: 0.2182709276676178
Validation loss: 1.7613313864636164

Epoch: 5| Step: 7
Training loss: 0.43977952003479004
Validation loss: 1.7522152700731832

Epoch: 5| Step: 8
Training loss: 0.22996680438518524
Validation loss: 1.7750198148912

Epoch: 5| Step: 9
Training loss: 0.4451219439506531
Validation loss: 1.7670031696237543

Epoch: 5| Step: 10
Training loss: 0.6943250298500061
Validation loss: 1.7979765245991368

Epoch: 394| Step: 0
Training loss: 0.3045087456703186
Validation loss: 1.8105756518661336

Epoch: 5| Step: 1
Training loss: 0.3756712079048157
Validation loss: 1.785558997943837

Epoch: 5| Step: 2
Training loss: 0.33873113989830017
Validation loss: 1.7636812194701164

Epoch: 5| Step: 3
Training loss: 0.37613624334335327
Validation loss: 1.7484523942393642

Epoch: 5| Step: 4
Training loss: 0.33629053831100464
Validation loss: 1.7572778226226888

Epoch: 5| Step: 5
Training loss: 0.37854844331741333
Validation loss: 1.7595587661189418

Epoch: 5| Step: 6
Training loss: 0.22863411903381348
Validation loss: 1.7133213063722015

Epoch: 5| Step: 7
Training loss: 0.5276256799697876
Validation loss: 1.7326388602615685

Epoch: 5| Step: 8
Training loss: 0.4136892259120941
Validation loss: 1.7173612117767334

Epoch: 5| Step: 9
Training loss: 0.34577494859695435
Validation loss: 1.70118748757147

Epoch: 5| Step: 10
Training loss: 0.6042967438697815
Validation loss: 1.6782393352959746

Epoch: 395| Step: 0
Training loss: 0.5918251276016235
Validation loss: 1.6727244712973153

Epoch: 5| Step: 1
Training loss: 0.22614865005016327
Validation loss: 1.679181319411083

Epoch: 5| Step: 2
Training loss: 0.21850843727588654
Validation loss: 1.6727081716701548

Epoch: 5| Step: 3
Training loss: 0.3899340033531189
Validation loss: 1.6759498555173156

Epoch: 5| Step: 4
Training loss: 0.6086463928222656
Validation loss: 1.6519065851806312

Epoch: 5| Step: 5
Training loss: 0.3062271177768707
Validation loss: 1.7034659372862948

Epoch: 5| Step: 6
Training loss: 0.20733602344989777
Validation loss: 1.710653353762883

Epoch: 5| Step: 7
Training loss: 0.439019113779068
Validation loss: 1.7242797536234702

Epoch: 5| Step: 8
Training loss: 0.18992504477500916
Validation loss: 1.6830809449636808

Epoch: 5| Step: 9
Training loss: 0.40249696373939514
Validation loss: 1.7208623168289021

Epoch: 5| Step: 10
Training loss: 0.3632572293281555
Validation loss: 1.6891116403764295

Epoch: 396| Step: 0
Training loss: 0.2785486578941345
Validation loss: 1.636457855983447

Epoch: 5| Step: 1
Training loss: 0.2870291769504547
Validation loss: 1.6309182797708819

Epoch: 5| Step: 2
Training loss: 0.48148298263549805
Validation loss: 1.6826314387782928

Epoch: 5| Step: 3
Training loss: 0.47638288140296936
Validation loss: 1.6462310924324939

Epoch: 5| Step: 4
Training loss: 0.3163169026374817
Validation loss: 1.6319744779217629

Epoch: 5| Step: 5
Training loss: 0.264332115650177
Validation loss: 1.6433421219548872

Epoch: 5| Step: 6
Training loss: 0.36461561918258667
Validation loss: 1.6608442093736382

Epoch: 5| Step: 7
Training loss: 0.41511183977127075
Validation loss: 1.7012992187212872

Epoch: 5| Step: 8
Training loss: 0.35896962881088257
Validation loss: 1.6766042978532854

Epoch: 5| Step: 9
Training loss: 0.4312107563018799
Validation loss: 1.652597722186837

Epoch: 5| Step: 10
Training loss: 0.29817137122154236
Validation loss: 1.658277165505194

Epoch: 397| Step: 0
Training loss: 0.19432654976844788
Validation loss: 1.6632493772814352

Epoch: 5| Step: 1
Training loss: 0.3676517605781555
Validation loss: 1.7251958552227225

Epoch: 5| Step: 2
Training loss: 0.3487855792045593
Validation loss: 1.7126340161087692

Epoch: 5| Step: 3
Training loss: 0.3327415883541107
Validation loss: 1.7236814883447462

Epoch: 5| Step: 4
Training loss: 0.33919504284858704
Validation loss: 1.7269825871272753

Epoch: 5| Step: 5
Training loss: 0.33133670687675476
Validation loss: 1.7507497649038992

Epoch: 5| Step: 6
Training loss: 0.512809693813324
Validation loss: 1.7697485621257494

Epoch: 5| Step: 7
Training loss: 0.36091598868370056
Validation loss: 1.7799914806119856

Epoch: 5| Step: 8
Training loss: 0.4405929446220398
Validation loss: 1.7700933589730212

Epoch: 5| Step: 9
Training loss: 0.3967277705669403
Validation loss: 1.7781430175227504

Epoch: 5| Step: 10
Training loss: 0.4207918047904968
Validation loss: 1.7451063125364241

Epoch: 398| Step: 0
Training loss: 0.28817933797836304
Validation loss: 1.6843506392612253

Epoch: 5| Step: 1
Training loss: 0.25695547461509705
Validation loss: 1.6507995756723548

Epoch: 5| Step: 2
Training loss: 0.453846275806427
Validation loss: 1.643984866398637

Epoch: 5| Step: 3
Training loss: 0.3246799111366272
Validation loss: 1.639541297189651

Epoch: 5| Step: 4
Training loss: 0.19476327300071716
Validation loss: 1.6522888124630015

Epoch: 5| Step: 5
Training loss: 0.433572381734848
Validation loss: 1.6504527163761917

Epoch: 5| Step: 6
Training loss: 0.4761320948600769
Validation loss: 1.618418957597466

Epoch: 5| Step: 7
Training loss: 0.3126491904258728
Validation loss: 1.6425712256021396

Epoch: 5| Step: 8
Training loss: 0.4682706892490387
Validation loss: 1.6277272291080926

Epoch: 5| Step: 9
Training loss: 0.3452669382095337
Validation loss: 1.6390261393721386

Epoch: 5| Step: 10
Training loss: 0.400509238243103
Validation loss: 1.6302147116712344

Epoch: 399| Step: 0
Training loss: 0.4215320944786072
Validation loss: 1.6460170579212967

Epoch: 5| Step: 1
Training loss: 0.5096509456634521
Validation loss: 1.6423350585404264

Epoch: 5| Step: 2
Training loss: 0.4515399932861328
Validation loss: 1.6648085706977434

Epoch: 5| Step: 3
Training loss: 0.22787992656230927
Validation loss: 1.683184903155091

Epoch: 5| Step: 4
Training loss: 0.32880109548568726
Validation loss: 1.6794753177191621

Epoch: 5| Step: 5
Training loss: 0.5064295530319214
Validation loss: 1.6866649863540486

Epoch: 5| Step: 6
Training loss: 0.44288429617881775
Validation loss: 1.6956270561423352

Epoch: 5| Step: 7
Training loss: 0.3211076855659485
Validation loss: 1.7004788582042982

Epoch: 5| Step: 8
Training loss: 0.19825595617294312
Validation loss: 1.7475937861268238

Epoch: 5| Step: 9
Training loss: 0.28148356080055237
Validation loss: 1.7381081722115959

Epoch: 5| Step: 10
Training loss: 0.37083226442337036
Validation loss: 1.73078352725634

Epoch: 400| Step: 0
Training loss: 0.26867038011550903
Validation loss: 1.7368921554216774

Epoch: 5| Step: 1
Training loss: 0.43318885564804077
Validation loss: 1.6839568256050028

Epoch: 5| Step: 2
Training loss: 0.22411660850048065
Validation loss: 1.7016243319357596

Epoch: 5| Step: 3
Training loss: 0.42425280809402466
Validation loss: 1.7157305363685853

Epoch: 5| Step: 4
Training loss: 0.28492051362991333
Validation loss: 1.6849478367836244

Epoch: 5| Step: 5
Training loss: 0.15463756024837494
Validation loss: 1.7037696556378437

Epoch: 5| Step: 6
Training loss: 0.3521699905395508
Validation loss: 1.6854744611247894

Epoch: 5| Step: 7
Training loss: 0.540515124797821
Validation loss: 1.729293123368294

Epoch: 5| Step: 8
Training loss: 0.45341143012046814
Validation loss: 1.7424798293780255

Epoch: 5| Step: 9
Training loss: 0.24627070128917694
Validation loss: 1.72930633893577

Epoch: 5| Step: 10
Training loss: 0.3375723361968994
Validation loss: 1.7320863572500085

Epoch: 401| Step: 0
Training loss: 0.3630048334598541
Validation loss: 1.6987131334120227

Epoch: 5| Step: 1
Training loss: 0.4276265501976013
Validation loss: 1.717298739699907

Epoch: 5| Step: 2
Training loss: 0.3559066653251648
Validation loss: 1.708070444804366

Epoch: 5| Step: 3
Training loss: 0.255659282207489
Validation loss: 1.7047762819515762

Epoch: 5| Step: 4
Training loss: 0.3267264664173126
Validation loss: 1.7168594944861628

Epoch: 5| Step: 5
Training loss: 0.3718145787715912
Validation loss: 1.716090568932154

Epoch: 5| Step: 6
Training loss: 0.4282001852989197
Validation loss: 1.7073575732528523

Epoch: 5| Step: 7
Training loss: 0.345960408449173
Validation loss: 1.7068992942892096

Epoch: 5| Step: 8
Training loss: 0.3223862648010254
Validation loss: 1.7230703946082824

Epoch: 5| Step: 9
Training loss: 0.4445881247520447
Validation loss: 1.7515134939583399

Epoch: 5| Step: 10
Training loss: 0.2849736511707306
Validation loss: 1.7643576386154338

Epoch: 402| Step: 0
Training loss: 0.4412325322628021
Validation loss: 1.7353004896512596

Epoch: 5| Step: 1
Training loss: 0.2873462736606598
Validation loss: 1.7532564440081198

Epoch: 5| Step: 2
Training loss: 0.2858518958091736
Validation loss: 1.7254070992110877

Epoch: 5| Step: 3
Training loss: 0.4603165090084076
Validation loss: 1.718222645662164

Epoch: 5| Step: 4
Training loss: 0.33315029740333557
Validation loss: 1.7263695886058192

Epoch: 5| Step: 5
Training loss: 0.26202574372291565
Validation loss: 1.6964569886525471

Epoch: 5| Step: 6
Training loss: 0.3628996014595032
Validation loss: 1.715269902701019

Epoch: 5| Step: 7
Training loss: 0.25026077032089233
Validation loss: 1.7037424733561854

Epoch: 5| Step: 8
Training loss: 0.18472173810005188
Validation loss: 1.6597733010527909

Epoch: 5| Step: 9
Training loss: 0.4082260727882385
Validation loss: 1.6763993399117583

Epoch: 5| Step: 10
Training loss: 0.4545561969280243
Validation loss: 1.664225725717442

Epoch: 403| Step: 0
Training loss: 0.3646368682384491
Validation loss: 1.68776592452039

Epoch: 5| Step: 1
Training loss: 0.3868059515953064
Validation loss: 1.6995063776611

Epoch: 5| Step: 2
Training loss: 0.5668073892593384
Validation loss: 1.705519199371338

Epoch: 5| Step: 3
Training loss: 0.3260849714279175
Validation loss: 1.7271620701718073

Epoch: 5| Step: 4
Training loss: 0.2838881015777588
Validation loss: 1.7121797761609476

Epoch: 5| Step: 5
Training loss: 0.17335471510887146
Validation loss: 1.7092037764928674

Epoch: 5| Step: 6
Training loss: 0.31383830308914185
Validation loss: 1.6937470384823379

Epoch: 5| Step: 7
Training loss: 0.5336326360702515
Validation loss: 1.654750168964427

Epoch: 5| Step: 8
Training loss: 0.43153834342956543
Validation loss: 1.670229128611985

Epoch: 5| Step: 9
Training loss: 0.2835882902145386
Validation loss: 1.6545452687048143

Epoch: 5| Step: 10
Training loss: 0.30170750617980957
Validation loss: 1.6583889863824333

Epoch: 404| Step: 0
Training loss: 0.2504880130290985
Validation loss: 1.6929051235157957

Epoch: 5| Step: 1
Training loss: 0.12749473750591278
Validation loss: 1.7188359665614303

Epoch: 5| Step: 2
Training loss: 0.6394349336624146
Validation loss: 1.7489377734481648

Epoch: 5| Step: 3
Training loss: 0.3634569048881531
Validation loss: 1.7148173970560874

Epoch: 5| Step: 4
Training loss: 0.3678273856639862
Validation loss: 1.6837771925874936

Epoch: 5| Step: 5
Training loss: 0.28523963689804077
Validation loss: 1.6821168827754196

Epoch: 5| Step: 6
Training loss: 0.40567922592163086
Validation loss: 1.6913175480340117

Epoch: 5| Step: 7
Training loss: 0.3643915057182312
Validation loss: 1.6961951550617014

Epoch: 5| Step: 8
Training loss: 0.3068113625049591
Validation loss: 1.66864901204263

Epoch: 5| Step: 9
Training loss: 0.4195363521575928
Validation loss: 1.6853428425327424

Epoch: 5| Step: 10
Training loss: 0.5440582036972046
Validation loss: 1.6994026091790968

Epoch: 405| Step: 0
Training loss: 0.5410526990890503
Validation loss: 1.7235772904529367

Epoch: 5| Step: 1
Training loss: 0.41237887740135193
Validation loss: 1.6938965141132314

Epoch: 5| Step: 2
Training loss: 0.23393826186656952
Validation loss: 1.7051051265449935

Epoch: 5| Step: 3
Training loss: 0.42494574189186096
Validation loss: 1.705431963807793

Epoch: 5| Step: 4
Training loss: 0.25172895193099976
Validation loss: 1.6861469950727237

Epoch: 5| Step: 5
Training loss: 0.4189596176147461
Validation loss: 1.7213120537419473

Epoch: 5| Step: 6
Training loss: 0.5452421307563782
Validation loss: 1.7503247337956582

Epoch: 5| Step: 7
Training loss: 0.17614200711250305
Validation loss: 1.7065160838506555

Epoch: 5| Step: 8
Training loss: 0.4025896191596985
Validation loss: 1.696380981834986

Epoch: 5| Step: 9
Training loss: 0.2301788330078125
Validation loss: 1.7201640721290343

Epoch: 5| Step: 10
Training loss: 0.4361114501953125
Validation loss: 1.7687624462189213

Epoch: 406| Step: 0
Training loss: 0.5695248246192932
Validation loss: 1.7384810755329747

Epoch: 5| Step: 1
Training loss: 0.3320693075656891
Validation loss: 1.7239584666426464

Epoch: 5| Step: 2
Training loss: 0.37581580877304077
Validation loss: 1.7060278987371793

Epoch: 5| Step: 3
Training loss: 0.5698063969612122
Validation loss: 1.7017510860197005

Epoch: 5| Step: 4
Training loss: 0.21930956840515137
Validation loss: 1.746476755347303

Epoch: 5| Step: 5
Training loss: 0.2886044383049011
Validation loss: 1.7156733415460075

Epoch: 5| Step: 6
Training loss: 0.5097368359565735
Validation loss: 1.723828733608287

Epoch: 5| Step: 7
Training loss: 0.45615825057029724
Validation loss: 1.7608945241538427

Epoch: 5| Step: 8
Training loss: 0.2909768223762512
Validation loss: 1.7356604030055385

Epoch: 5| Step: 9
Training loss: 0.3004830479621887
Validation loss: 1.7343600988388062

Epoch: 5| Step: 10
Training loss: 0.2629881501197815
Validation loss: 1.7733988582447011

Epoch: 407| Step: 0
Training loss: 0.46588045358657837
Validation loss: 1.7462676199533607

Epoch: 5| Step: 1
Training loss: 0.37015312910079956
Validation loss: 1.7600897230127805

Epoch: 5| Step: 2
Training loss: 0.21321964263916016
Validation loss: 1.7435680012549124

Epoch: 5| Step: 3
Training loss: 0.20290212333202362
Validation loss: 1.7046491869034306

Epoch: 5| Step: 4
Training loss: 0.30110985040664673
Validation loss: 1.7204817187401555

Epoch: 5| Step: 5
Training loss: 0.2614857256412506
Validation loss: 1.6887313883791688

Epoch: 5| Step: 6
Training loss: 0.24168863892555237
Validation loss: 1.6843946300527102

Epoch: 5| Step: 7
Training loss: 0.2580569088459015
Validation loss: 1.6739188727512155

Epoch: 5| Step: 8
Training loss: 0.2676776051521301
Validation loss: 1.6833284067851242

Epoch: 5| Step: 9
Training loss: 0.6049158573150635
Validation loss: 1.6761650782759472

Epoch: 5| Step: 10
Training loss: 0.5235855579376221
Validation loss: 1.6949524212909002

Epoch: 408| Step: 0
Training loss: 0.28700533509254456
Validation loss: 1.6953384927524033

Epoch: 5| Step: 1
Training loss: 0.44419607520103455
Validation loss: 1.694906642360072

Epoch: 5| Step: 2
Training loss: 0.25213226675987244
Validation loss: 1.721484536765724

Epoch: 5| Step: 3
Training loss: 0.2578410506248474
Validation loss: 1.7189210948123728

Epoch: 5| Step: 4
Training loss: 0.5430794954299927
Validation loss: 1.7132103468782158

Epoch: 5| Step: 5
Training loss: 0.25300049781799316
Validation loss: 1.7024573702966013

Epoch: 5| Step: 6
Training loss: 0.2664969265460968
Validation loss: 1.7319189976620417

Epoch: 5| Step: 7
Training loss: 0.3697456121444702
Validation loss: 1.7435190498187978

Epoch: 5| Step: 8
Training loss: 0.27846625447273254
Validation loss: 1.766891884547408

Epoch: 5| Step: 9
Training loss: 0.5129746794700623
Validation loss: 1.719483906222928

Epoch: 5| Step: 10
Training loss: 0.27034977078437805
Validation loss: 1.71555293503628

Epoch: 409| Step: 0
Training loss: 0.2567318081855774
Validation loss: 1.6972056409364105

Epoch: 5| Step: 1
Training loss: 0.27985960245132446
Validation loss: 1.698069614748801

Epoch: 5| Step: 2
Training loss: 0.30146822333335876
Validation loss: 1.7064761513022966

Epoch: 5| Step: 3
Training loss: 0.3820072412490845
Validation loss: 1.7101727954802974

Epoch: 5| Step: 4
Training loss: 0.24718590080738068
Validation loss: 1.7087431517980431

Epoch: 5| Step: 5
Training loss: 0.1886189877986908
Validation loss: 1.7165732409364434

Epoch: 5| Step: 6
Training loss: 0.3047974705696106
Validation loss: 1.7139506019571775

Epoch: 5| Step: 7
Training loss: 0.4653509259223938
Validation loss: 1.7499171149346135

Epoch: 5| Step: 8
Training loss: 0.20713181793689728
Validation loss: 1.7302209561870945

Epoch: 5| Step: 9
Training loss: 0.45140379667282104
Validation loss: 1.6580486874426565

Epoch: 5| Step: 10
Training loss: 0.5220057368278503
Validation loss: 1.659527277433744

Epoch: 410| Step: 0
Training loss: 0.17646664381027222
Validation loss: 1.6830365850079445

Epoch: 5| Step: 1
Training loss: 0.2433656007051468
Validation loss: 1.7054450306841122

Epoch: 5| Step: 2
Training loss: 0.7707576751708984
Validation loss: 1.694122056807241

Epoch: 5| Step: 3
Training loss: 0.407003253698349
Validation loss: 1.696236607848957

Epoch: 5| Step: 4
Training loss: 0.18279317021369934
Validation loss: 1.7128078565802625

Epoch: 5| Step: 5
Training loss: 0.3054991066455841
Validation loss: 1.7373614964946624

Epoch: 5| Step: 6
Training loss: 0.30596810579299927
Validation loss: 1.7404920439566336

Epoch: 5| Step: 7
Training loss: 0.36654478311538696
Validation loss: 1.7229370660679315

Epoch: 5| Step: 8
Training loss: 0.40294304490089417
Validation loss: 1.7322880580861082

Epoch: 5| Step: 9
Training loss: 0.21321122348308563
Validation loss: 1.7317175429354432

Epoch: 5| Step: 10
Training loss: 0.24203592538833618
Validation loss: 1.6960986288644935

Epoch: 411| Step: 0
Training loss: 0.47802847623825073
Validation loss: 1.7094605712480442

Epoch: 5| Step: 1
Training loss: 0.2262115478515625
Validation loss: 1.6958285352235198

Epoch: 5| Step: 2
Training loss: 0.27048811316490173
Validation loss: 1.6730077869148665

Epoch: 5| Step: 3
Training loss: 0.33312880992889404
Validation loss: 1.6815918671187533

Epoch: 5| Step: 4
Training loss: 0.33959612250328064
Validation loss: 1.6993244207033547

Epoch: 5| Step: 5
Training loss: 0.2702229619026184
Validation loss: 1.6676321311663556

Epoch: 5| Step: 6
Training loss: 0.1613062620162964
Validation loss: 1.6515358737719956

Epoch: 5| Step: 7
Training loss: 0.3019523024559021
Validation loss: 1.6685599588578748

Epoch: 5| Step: 8
Training loss: 0.3558666408061981
Validation loss: 1.6407256036676385

Epoch: 5| Step: 9
Training loss: 0.2971850037574768
Validation loss: 1.6395256147589734

Epoch: 5| Step: 10
Training loss: 0.36484718322753906
Validation loss: 1.6334501774080339

Epoch: 412| Step: 0
Training loss: 0.38974934816360474
Validation loss: 1.6487140168425858

Epoch: 5| Step: 1
Training loss: 0.40185147523880005
Validation loss: 1.6425043716225574

Epoch: 5| Step: 2
Training loss: 0.4803468585014343
Validation loss: 1.6527900029254217

Epoch: 5| Step: 3
Training loss: 0.22842884063720703
Validation loss: 1.6668423132229877

Epoch: 5| Step: 4
Training loss: 0.32036441564559937
Validation loss: 1.6757222093561643

Epoch: 5| Step: 5
Training loss: 0.1727183312177658
Validation loss: 1.705378278609245

Epoch: 5| Step: 6
Training loss: 0.18387094140052795
Validation loss: 1.7146744958816036

Epoch: 5| Step: 7
Training loss: 0.21875150501728058
Validation loss: 1.7188600429924585

Epoch: 5| Step: 8
Training loss: 0.23539328575134277
Validation loss: 1.734891019841676

Epoch: 5| Step: 9
Training loss: 0.43427205085754395
Validation loss: 1.7013427519029187

Epoch: 5| Step: 10
Training loss: 0.10249916464090347
Validation loss: 1.723448089374009

Epoch: 413| Step: 0
Training loss: 0.42411118745803833
Validation loss: 1.701697467475809

Epoch: 5| Step: 1
Training loss: 0.3033779561519623
Validation loss: 1.720541795735718

Epoch: 5| Step: 2
Training loss: 0.25086984038352966
Validation loss: 1.6981670446293329

Epoch: 5| Step: 3
Training loss: 0.21805039048194885
Validation loss: 1.710807555465288

Epoch: 5| Step: 4
Training loss: 0.31587502360343933
Validation loss: 1.6663233862128308

Epoch: 5| Step: 5
Training loss: 0.21907345950603485
Validation loss: 1.6745940305853402

Epoch: 5| Step: 6
Training loss: 0.29392683506011963
Validation loss: 1.6801677999957916

Epoch: 5| Step: 7
Training loss: 0.15557961165905
Validation loss: 1.6793169936826151

Epoch: 5| Step: 8
Training loss: 0.38586094975471497
Validation loss: 1.7105963947952434

Epoch: 5| Step: 9
Training loss: 0.3655919134616852
Validation loss: 1.7385501130934684

Epoch: 5| Step: 10
Training loss: 0.3943239152431488
Validation loss: 1.7243728163421794

Epoch: 414| Step: 0
Training loss: 0.2939593195915222
Validation loss: 1.7490786403738043

Epoch: 5| Step: 1
Training loss: 0.33399534225463867
Validation loss: 1.7338524223655782

Epoch: 5| Step: 2
Training loss: 0.2675492763519287
Validation loss: 1.7232197753844722

Epoch: 5| Step: 3
Training loss: 0.3622680902481079
Validation loss: 1.6830436234833093

Epoch: 5| Step: 4
Training loss: 0.28755658864974976
Validation loss: 1.6869083027685843

Epoch: 5| Step: 5
Training loss: 0.45122212171554565
Validation loss: 1.6753454310919649

Epoch: 5| Step: 6
Training loss: 0.1781207025051117
Validation loss: 1.6651394264672392

Epoch: 5| Step: 7
Training loss: 0.3694053292274475
Validation loss: 1.678573154634045

Epoch: 5| Step: 8
Training loss: 0.5729830861091614
Validation loss: 1.7169039967239543

Epoch: 5| Step: 9
Training loss: 0.5811302065849304
Validation loss: 1.7035748548405145

Epoch: 5| Step: 10
Training loss: 0.18122905492782593
Validation loss: 1.702477442320957

Epoch: 415| Step: 0
Training loss: 0.3061581552028656
Validation loss: 1.6490760695549749

Epoch: 5| Step: 1
Training loss: 0.26288989186286926
Validation loss: 1.7226030313840477

Epoch: 5| Step: 2
Training loss: 0.5613731145858765
Validation loss: 1.718668842828402

Epoch: 5| Step: 3
Training loss: 0.4240857660770416
Validation loss: 1.7373661982115878

Epoch: 5| Step: 4
Training loss: 0.33926454186439514
Validation loss: 1.717124549291467

Epoch: 5| Step: 5
Training loss: 0.23169298470020294
Validation loss: 1.7381165117345831

Epoch: 5| Step: 6
Training loss: 0.27623459696769714
Validation loss: 1.7435632059651036

Epoch: 5| Step: 7
Training loss: 0.6174819469451904
Validation loss: 1.7306105603453934

Epoch: 5| Step: 8
Training loss: 0.20794346928596497
Validation loss: 1.7202582308041152

Epoch: 5| Step: 9
Training loss: 0.4107179641723633
Validation loss: 1.736833869770009

Epoch: 5| Step: 10
Training loss: 0.24212519824504852
Validation loss: 1.7495555236775389

Epoch: 416| Step: 0
Training loss: 0.32226499915122986
Validation loss: 1.7686364182861902

Epoch: 5| Step: 1
Training loss: 0.2068764716386795
Validation loss: 1.7567991236204743

Epoch: 5| Step: 2
Training loss: 0.22369635105133057
Validation loss: 1.7410489871937742

Epoch: 5| Step: 3
Training loss: 0.3236358165740967
Validation loss: 1.7693847558831657

Epoch: 5| Step: 4
Training loss: 0.23585379123687744
Validation loss: 1.7897421467688777

Epoch: 5| Step: 5
Training loss: 0.3016546666622162
Validation loss: 1.7567288170578659

Epoch: 5| Step: 6
Training loss: 0.43361973762512207
Validation loss: 1.7506374178394195

Epoch: 5| Step: 7
Training loss: 0.21249930560588837
Validation loss: 1.7146370846738097

Epoch: 5| Step: 8
Training loss: 0.2611658275127411
Validation loss: 1.7266720520552767

Epoch: 5| Step: 9
Training loss: 0.5462648272514343
Validation loss: 1.6867176537872643

Epoch: 5| Step: 10
Training loss: 0.28981703519821167
Validation loss: 1.6817377100708664

Epoch: 417| Step: 0
Training loss: 0.1206849217414856
Validation loss: 1.6827808298090452

Epoch: 5| Step: 1
Training loss: 0.4943597912788391
Validation loss: 1.6967622387793757

Epoch: 5| Step: 2
Training loss: 0.22269997000694275
Validation loss: 1.7004485617401779

Epoch: 5| Step: 3
Training loss: 0.33886218070983887
Validation loss: 1.7325779673873738

Epoch: 5| Step: 4
Training loss: 0.3049171566963196
Validation loss: 1.7564803349074496

Epoch: 5| Step: 5
Training loss: 0.3488350212574005
Validation loss: 1.7537023707102704

Epoch: 5| Step: 6
Training loss: 0.4472503066062927
Validation loss: 1.7615838678934241

Epoch: 5| Step: 7
Training loss: 0.2832508683204651
Validation loss: 1.7112874728377148

Epoch: 5| Step: 8
Training loss: 0.33053892850875854
Validation loss: 1.7358470552711076

Epoch: 5| Step: 9
Training loss: 0.3746940791606903
Validation loss: 1.7434716891216975

Epoch: 5| Step: 10
Training loss: 0.44432303309440613
Validation loss: 1.7441727576717254

Epoch: 418| Step: 0
Training loss: 0.25557640194892883
Validation loss: 1.743120836955245

Epoch: 5| Step: 1
Training loss: 0.20568367838859558
Validation loss: 1.7560794225303076

Epoch: 5| Step: 2
Training loss: 0.3431028723716736
Validation loss: 1.7448804096509052

Epoch: 5| Step: 3
Training loss: 0.426577091217041
Validation loss: 1.7352765247385988

Epoch: 5| Step: 4
Training loss: 0.29907140135765076
Validation loss: 1.751777377179874

Epoch: 5| Step: 5
Training loss: 0.30417558550834656
Validation loss: 1.7375936687633555

Epoch: 5| Step: 6
Training loss: 0.32342326641082764
Validation loss: 1.7128822534315047

Epoch: 5| Step: 7
Training loss: 0.2711164951324463
Validation loss: 1.7157195165593138

Epoch: 5| Step: 8
Training loss: 0.2100830078125
Validation loss: 1.7031301247176303

Epoch: 5| Step: 9
Training loss: 0.4279772639274597
Validation loss: 1.683201583482886

Epoch: 5| Step: 10
Training loss: 0.32047680020332336
Validation loss: 1.683155499478822

Epoch: 419| Step: 0
Training loss: 0.38220152258872986
Validation loss: 1.6773250923361829

Epoch: 5| Step: 1
Training loss: 0.39493170380592346
Validation loss: 1.6666438323195263

Epoch: 5| Step: 2
Training loss: 0.3219696879386902
Validation loss: 1.6695996740812897

Epoch: 5| Step: 3
Training loss: 0.41916966438293457
Validation loss: 1.7077064309068906

Epoch: 5| Step: 4
Training loss: 0.34199026226997375
Validation loss: 1.755935767645477

Epoch: 5| Step: 5
Training loss: 0.321227103471756
Validation loss: 1.7675355839472946

Epoch: 5| Step: 6
Training loss: 0.35697537660598755
Validation loss: 1.7412773063105922

Epoch: 5| Step: 7
Training loss: 0.2889326512813568
Validation loss: 1.737120302774573

Epoch: 5| Step: 8
Training loss: 0.18246743083000183
Validation loss: 1.7663941806362522

Epoch: 5| Step: 9
Training loss: 0.34851402044296265
Validation loss: 1.7137242562027388

Epoch: 5| Step: 10
Training loss: 0.42570364475250244
Validation loss: 1.721366879119668

Epoch: 420| Step: 0
Training loss: 0.34585145115852356
Validation loss: 1.699008625040772

Epoch: 5| Step: 1
Training loss: 0.34853237867355347
Validation loss: 1.7116103095393027

Epoch: 5| Step: 2
Training loss: 0.21889939904212952
Validation loss: 1.7123092759040095

Epoch: 5| Step: 3
Training loss: 0.16705678403377533
Validation loss: 1.7024021687046174

Epoch: 5| Step: 4
Training loss: 0.3859200179576874
Validation loss: 1.7057993732472903

Epoch: 5| Step: 5
Training loss: 0.31932398676872253
Validation loss: 1.6735627997306086

Epoch: 5| Step: 6
Training loss: 0.2348470240831375
Validation loss: 1.6749606619599045

Epoch: 5| Step: 7
Training loss: 0.18901444971561432
Validation loss: 1.6293111796020179

Epoch: 5| Step: 8
Training loss: 0.5348318815231323
Validation loss: 1.629249128603166

Epoch: 5| Step: 9
Training loss: 0.39119213819503784
Validation loss: 1.6301716495585699

Epoch: 5| Step: 10
Training loss: 0.13354574143886566
Validation loss: 1.6603406013980988

Epoch: 421| Step: 0
Training loss: 0.2793305516242981
Validation loss: 1.677388346323403

Epoch: 5| Step: 1
Training loss: 0.2990983724594116
Validation loss: 1.6958523873359925

Epoch: 5| Step: 2
Training loss: 0.30231451988220215
Validation loss: 1.7007443404966784

Epoch: 5| Step: 3
Training loss: 0.22791151702404022
Validation loss: 1.691995607909336

Epoch: 5| Step: 4
Training loss: 0.3348962366580963
Validation loss: 1.7052754150923861

Epoch: 5| Step: 5
Training loss: 0.23582904040813446
Validation loss: 1.698558722772906

Epoch: 5| Step: 6
Training loss: 0.4596390724182129
Validation loss: 1.706679847932631

Epoch: 5| Step: 7
Training loss: 0.19541296362876892
Validation loss: 1.677766046216411

Epoch: 5| Step: 8
Training loss: 0.42310625314712524
Validation loss: 1.6970262662056954

Epoch: 5| Step: 9
Training loss: 0.440222829580307
Validation loss: 1.660168691348004

Epoch: 5| Step: 10
Training loss: 0.1470647156238556
Validation loss: 1.6754173899209628

Epoch: 422| Step: 0
Training loss: 0.4271824359893799
Validation loss: 1.6738853313589608

Epoch: 5| Step: 1
Training loss: 0.18049165606498718
Validation loss: 1.7167683634706723

Epoch: 5| Step: 2
Training loss: 0.41669073700904846
Validation loss: 1.707322182193879

Epoch: 5| Step: 3
Training loss: 0.282675564289093
Validation loss: 1.6586249912938764

Epoch: 5| Step: 4
Training loss: 0.3321279287338257
Validation loss: 1.649693073764924

Epoch: 5| Step: 5
Training loss: 0.24171042442321777
Validation loss: 1.7054610130607442

Epoch: 5| Step: 6
Training loss: 0.24341388046741486
Validation loss: 1.7014056956896217

Epoch: 5| Step: 7
Training loss: 0.2307889461517334
Validation loss: 1.7252042146139248

Epoch: 5| Step: 8
Training loss: 0.4646466374397278
Validation loss: 1.738715930651593

Epoch: 5| Step: 9
Training loss: 0.31838560104370117
Validation loss: 1.7140633085722565

Epoch: 5| Step: 10
Training loss: 0.3127693235874176
Validation loss: 1.7378017607555594

Epoch: 423| Step: 0
Training loss: 0.27673953771591187
Validation loss: 1.691236243453077

Epoch: 5| Step: 1
Training loss: 0.23969002068042755
Validation loss: 1.6808337050099527

Epoch: 5| Step: 2
Training loss: 0.32012680172920227
Validation loss: 1.6925534458570584

Epoch: 5| Step: 3
Training loss: 0.3178790211677551
Validation loss: 1.6818163087291103

Epoch: 5| Step: 4
Training loss: 0.28672903776168823
Validation loss: 1.672768029474443

Epoch: 5| Step: 5
Training loss: 0.31825724244117737
Validation loss: 1.6937042449110298

Epoch: 5| Step: 6
Training loss: 0.28580769896507263
Validation loss: 1.664540470287364

Epoch: 5| Step: 7
Training loss: 0.28620511293411255
Validation loss: 1.6875998704664168

Epoch: 5| Step: 8
Training loss: 0.2843700051307678
Validation loss: 1.7133342860847391

Epoch: 5| Step: 9
Training loss: 0.17830510437488556
Validation loss: 1.692931689241881

Epoch: 5| Step: 10
Training loss: 0.15967364609241486
Validation loss: 1.7152366215182888

Epoch: 424| Step: 0
Training loss: 0.20162001252174377
Validation loss: 1.7070313717729302

Epoch: 5| Step: 1
Training loss: 0.38077086210250854
Validation loss: 1.6833325996193835

Epoch: 5| Step: 2
Training loss: 0.3527534604072571
Validation loss: 1.672154789329857

Epoch: 5| Step: 3
Training loss: 0.3681184947490692
Validation loss: 1.6603081098166845

Epoch: 5| Step: 4
Training loss: 0.3871663212776184
Validation loss: 1.6795602434424943

Epoch: 5| Step: 5
Training loss: 0.25165683031082153
Validation loss: 1.6685475521190192

Epoch: 5| Step: 6
Training loss: 0.332610160112381
Validation loss: 1.6574990377631238

Epoch: 5| Step: 7
Training loss: 0.2003588229417801
Validation loss: 1.6870960189450173

Epoch: 5| Step: 8
Training loss: 0.2475161999464035
Validation loss: 1.7057395955567718

Epoch: 5| Step: 9
Training loss: 0.1826346516609192
Validation loss: 1.708947781593569

Epoch: 5| Step: 10
Training loss: 0.23919737339019775
Validation loss: 1.6966475094518354

Epoch: 425| Step: 0
Training loss: 0.15585772693157196
Validation loss: 1.678896398954494

Epoch: 5| Step: 1
Training loss: 0.17351838946342468
Validation loss: 1.709272776880572

Epoch: 5| Step: 2
Training loss: 0.35779690742492676
Validation loss: 1.6886424851673905

Epoch: 5| Step: 3
Training loss: 0.2609107494354248
Validation loss: 1.7011369146326536

Epoch: 5| Step: 4
Training loss: 0.42888325452804565
Validation loss: 1.68293636075912

Epoch: 5| Step: 5
Training loss: 0.3099324107170105
Validation loss: 1.6767948058343702

Epoch: 5| Step: 6
Training loss: 0.20083460211753845
Validation loss: 1.6925079668721845

Epoch: 5| Step: 7
Training loss: 0.22178888320922852
Validation loss: 1.710797223993527

Epoch: 5| Step: 8
Training loss: 0.38244980573654175
Validation loss: 1.7116949622349074

Epoch: 5| Step: 9
Training loss: 0.2894967198371887
Validation loss: 1.728770504715622

Epoch: 5| Step: 10
Training loss: 0.20989388227462769
Validation loss: 1.723467799925035

Epoch: 426| Step: 0
Training loss: 0.2148604691028595
Validation loss: 1.7170519815978182

Epoch: 5| Step: 1
Training loss: 0.42859792709350586
Validation loss: 1.7184742291768391

Epoch: 5| Step: 2
Training loss: 0.1496116667985916
Validation loss: 1.701449232716714

Epoch: 5| Step: 3
Training loss: 0.3069944381713867
Validation loss: 1.6889708695873138

Epoch: 5| Step: 4
Training loss: 0.39313507080078125
Validation loss: 1.6759984365073584

Epoch: 5| Step: 5
Training loss: 0.25608164072036743
Validation loss: 1.6691291921882219

Epoch: 5| Step: 6
Training loss: 0.21200892329216003
Validation loss: 1.6774606666257303

Epoch: 5| Step: 7
Training loss: 0.2335633486509323
Validation loss: 1.6655000922500447

Epoch: 5| Step: 8
Training loss: 0.40313929319381714
Validation loss: 1.6570892539075626

Epoch: 5| Step: 9
Training loss: 0.28351831436157227
Validation loss: 1.6741598626618743

Epoch: 5| Step: 10
Training loss: 0.25265583395957947
Validation loss: 1.6707143065749959

Epoch: 427| Step: 0
Training loss: 0.25660866498947144
Validation loss: 1.6525503153442054

Epoch: 5| Step: 1
Training loss: 0.2608502209186554
Validation loss: 1.6488291473798855

Epoch: 5| Step: 2
Training loss: 0.15414993464946747
Validation loss: 1.6531556165346535

Epoch: 5| Step: 3
Training loss: 0.22561988234519958
Validation loss: 1.6522918631953578

Epoch: 5| Step: 4
Training loss: 0.22384802997112274
Validation loss: 1.670806650192507

Epoch: 5| Step: 5
Training loss: 0.2724701166152954
Validation loss: 1.6521801922910957

Epoch: 5| Step: 6
Training loss: 0.4670298099517822
Validation loss: 1.6575806051172235

Epoch: 5| Step: 7
Training loss: 0.2378595769405365
Validation loss: 1.7005522199856338

Epoch: 5| Step: 8
Training loss: 0.37430864572525024
Validation loss: 1.682524101708525

Epoch: 5| Step: 9
Training loss: 0.2408287227153778
Validation loss: 1.6944501797358196

Epoch: 5| Step: 10
Training loss: 0.3013877272605896
Validation loss: 1.7066666990198114

Epoch: 428| Step: 0
Training loss: 0.275454044342041
Validation loss: 1.6714678374669885

Epoch: 5| Step: 1
Training loss: 0.3043142557144165
Validation loss: 1.7087184190750122

Epoch: 5| Step: 2
Training loss: 0.2187384068965912
Validation loss: 1.6666873039737824

Epoch: 5| Step: 3
Training loss: 0.39209914207458496
Validation loss: 1.6795270660872101

Epoch: 5| Step: 4
Training loss: 0.20746493339538574
Validation loss: 1.6584288112578853

Epoch: 5| Step: 5
Training loss: 0.44920283555984497
Validation loss: 1.6929700964240617

Epoch: 5| Step: 6
Training loss: 0.17623856663703918
Validation loss: 1.7157389348553074

Epoch: 5| Step: 7
Training loss: 0.4852963984012604
Validation loss: 1.761138012332301

Epoch: 5| Step: 8
Training loss: 0.3983375132083893
Validation loss: 1.7944773153592182

Epoch: 5| Step: 9
Training loss: 0.2703852355480194
Validation loss: 1.735609664711901

Epoch: 5| Step: 10
Training loss: 0.16342861950397491
Validation loss: 1.7359153224575905

Epoch: 429| Step: 0
Training loss: 0.29224690794944763
Validation loss: 1.7026259360774871

Epoch: 5| Step: 1
Training loss: 0.2214958220720291
Validation loss: 1.6745459366870183

Epoch: 5| Step: 2
Training loss: 0.43902796506881714
Validation loss: 1.6785518366803405

Epoch: 5| Step: 3
Training loss: 0.15600642561912537
Validation loss: 1.682232197894845

Epoch: 5| Step: 4
Training loss: 0.16642260551452637
Validation loss: 1.7075944421111897

Epoch: 5| Step: 5
Training loss: 0.36731410026550293
Validation loss: 1.7453740668553177

Epoch: 5| Step: 6
Training loss: 0.26651954650878906
Validation loss: 1.7649884736666115

Epoch: 5| Step: 7
Training loss: 0.24390563368797302
Validation loss: 1.7369224076629968

Epoch: 5| Step: 8
Training loss: 0.3417953848838806
Validation loss: 1.7489696497558265

Epoch: 5| Step: 9
Training loss: 0.30846938490867615
Validation loss: 1.6993031963225333

Epoch: 5| Step: 10
Training loss: 0.21114742755889893
Validation loss: 1.6604454107182

Epoch: 430| Step: 0
Training loss: 0.19898450374603271
Validation loss: 1.6850444527082546

Epoch: 5| Step: 1
Training loss: 0.4764866828918457
Validation loss: 1.6457493971752863

Epoch: 5| Step: 2
Training loss: 0.2854914367198944
Validation loss: 1.6365456260660642

Epoch: 5| Step: 3
Training loss: 0.2008957415819168
Validation loss: 1.6415080024350075

Epoch: 5| Step: 4
Training loss: 0.2578302025794983
Validation loss: 1.6511705062722648

Epoch: 5| Step: 5
Training loss: 0.3183739185333252
Validation loss: 1.644834747878454

Epoch: 5| Step: 6
Training loss: 0.37134140729904175
Validation loss: 1.6547188553758847

Epoch: 5| Step: 7
Training loss: 0.1980648934841156
Validation loss: 1.6744222166717693

Epoch: 5| Step: 8
Training loss: 0.2238474190235138
Validation loss: 1.6668251765671598

Epoch: 5| Step: 9
Training loss: 0.23708339035511017
Validation loss: 1.6819437107732218

Epoch: 5| Step: 10
Training loss: 0.3341483175754547
Validation loss: 1.6839896261051137

Epoch: 431| Step: 0
Training loss: 0.3084321916103363
Validation loss: 1.6464123610527284

Epoch: 5| Step: 1
Training loss: 0.22850079834461212
Validation loss: 1.6768292970554803

Epoch: 5| Step: 2
Training loss: 0.2382483035326004
Validation loss: 1.6946062554595291

Epoch: 5| Step: 3
Training loss: 0.19633764028549194
Validation loss: 1.6994586785634358

Epoch: 5| Step: 4
Training loss: 0.4001133441925049
Validation loss: 1.6786859368765226

Epoch: 5| Step: 5
Training loss: 0.16492271423339844
Validation loss: 1.690143797987251

Epoch: 5| Step: 6
Training loss: 0.19882971048355103
Validation loss: 1.657034109997493

Epoch: 5| Step: 7
Training loss: 0.27565497159957886
Validation loss: 1.6743595536037157

Epoch: 5| Step: 8
Training loss: 0.19595126807689667
Validation loss: 1.689448925756639

Epoch: 5| Step: 9
Training loss: 0.2560265362262726
Validation loss: 1.6406063854053456

Epoch: 5| Step: 10
Training loss: 0.2891218364238739
Validation loss: 1.640387015957986

Epoch: 432| Step: 0
Training loss: 0.16564767062664032
Validation loss: 1.6741430092883367

Epoch: 5| Step: 1
Training loss: 0.21687939763069153
Validation loss: 1.68156054968475

Epoch: 5| Step: 2
Training loss: 0.1844022274017334
Validation loss: 1.6684702519447572

Epoch: 5| Step: 3
Training loss: 0.2681967616081238
Validation loss: 1.661632768569454

Epoch: 5| Step: 4
Training loss: 0.2727082073688507
Validation loss: 1.674145693420082

Epoch: 5| Step: 5
Training loss: 0.18167297542095184
Validation loss: 1.675323409418906

Epoch: 5| Step: 6
Training loss: 0.2587158679962158
Validation loss: 1.698311763425027

Epoch: 5| Step: 7
Training loss: 0.4560151696205139
Validation loss: 1.6998717810517998

Epoch: 5| Step: 8
Training loss: 0.35568130016326904
Validation loss: 1.707273974213549

Epoch: 5| Step: 9
Training loss: 0.24232526123523712
Validation loss: 1.6978629699317358

Epoch: 5| Step: 10
Training loss: 0.21537531912326813
Validation loss: 1.666053045180536

Epoch: 433| Step: 0
Training loss: 0.2780347466468811
Validation loss: 1.6726341734650314

Epoch: 5| Step: 1
Training loss: 0.5398131608963013
Validation loss: 1.667516883983407

Epoch: 5| Step: 2
Training loss: 0.24857644736766815
Validation loss: 1.6418809294700623

Epoch: 5| Step: 3
Training loss: 0.22202594578266144
Validation loss: 1.6259492340908255

Epoch: 5| Step: 4
Training loss: 0.2838682234287262
Validation loss: 1.627311978288876

Epoch: 5| Step: 5
Training loss: 0.31263381242752075
Validation loss: 1.622464362011161

Epoch: 5| Step: 6
Training loss: 0.33448052406311035
Validation loss: 1.6359219576722832

Epoch: 5| Step: 7
Training loss: 0.31540071964263916
Validation loss: 1.6653686877219909

Epoch: 5| Step: 8
Training loss: 0.4149155020713806
Validation loss: 1.6631886189983738

Epoch: 5| Step: 9
Training loss: 0.16817203164100647
Validation loss: 1.6696781227665562

Epoch: 5| Step: 10
Training loss: 0.22667120397090912
Validation loss: 1.6641745791640332

Epoch: 434| Step: 0
Training loss: 0.38942164182662964
Validation loss: 1.6880868340051303

Epoch: 5| Step: 1
Training loss: 0.3575666844844818
Validation loss: 1.694508412832855

Epoch: 5| Step: 2
Training loss: 0.534501850605011
Validation loss: 1.6816406314091017

Epoch: 5| Step: 3
Training loss: 0.24112597107887268
Validation loss: 1.6973874299756941

Epoch: 5| Step: 4
Training loss: 0.37865716218948364
Validation loss: 1.6678222917741345

Epoch: 5| Step: 5
Training loss: 0.19721844792366028
Validation loss: 1.7190433381706156

Epoch: 5| Step: 6
Training loss: 0.16599750518798828
Validation loss: 1.7212593927178332

Epoch: 5| Step: 7
Training loss: 0.13319343328475952
Validation loss: 1.7094706848103514

Epoch: 5| Step: 8
Training loss: 0.34189629554748535
Validation loss: 1.7116574113086989

Epoch: 5| Step: 9
Training loss: 0.2727798521518707
Validation loss: 1.675432664091869

Epoch: 5| Step: 10
Training loss: 0.18933363258838654
Validation loss: 1.6894727253144788

Epoch: 435| Step: 0
Training loss: 0.3900145888328552
Validation loss: 1.6840733443537066

Epoch: 5| Step: 1
Training loss: 0.29200488328933716
Validation loss: 1.7303853316973614

Epoch: 5| Step: 2
Training loss: 0.21450471878051758
Validation loss: 1.7373647497546287

Epoch: 5| Step: 3
Training loss: 0.31988292932510376
Validation loss: 1.729113232704901

Epoch: 5| Step: 4
Training loss: 0.2363167703151703
Validation loss: 1.7290104281517766

Epoch: 5| Step: 5
Training loss: 0.24986529350280762
Validation loss: 1.6956731183554536

Epoch: 5| Step: 6
Training loss: 0.2634419798851013
Validation loss: 1.6796651783809866

Epoch: 5| Step: 7
Training loss: 0.29572850465774536
Validation loss: 1.704911273012879

Epoch: 5| Step: 8
Training loss: 0.2404404580593109
Validation loss: 1.7137961028724589

Epoch: 5| Step: 9
Training loss: 0.26897481083869934
Validation loss: 1.7032350596561228

Epoch: 5| Step: 10
Training loss: 0.21053755283355713
Validation loss: 1.667674796555632

Epoch: 436| Step: 0
Training loss: 0.34535884857177734
Validation loss: 1.660350170186771

Epoch: 5| Step: 1
Training loss: 0.31894558668136597
Validation loss: 1.676395308586859

Epoch: 5| Step: 2
Training loss: 0.1968722939491272
Validation loss: 1.6677771281170588

Epoch: 5| Step: 3
Training loss: 0.45040827989578247
Validation loss: 1.6662953399842786

Epoch: 5| Step: 4
Training loss: 0.2316690981388092
Validation loss: 1.6768059974075646

Epoch: 5| Step: 5
Training loss: 0.27298521995544434
Validation loss: 1.6841884300272951

Epoch: 5| Step: 6
Training loss: 0.17134645581245422
Validation loss: 1.7075066617740098

Epoch: 5| Step: 7
Training loss: 0.1467553824186325
Validation loss: 1.7270237309958345

Epoch: 5| Step: 8
Training loss: 0.38197198510169983
Validation loss: 1.753691897597364

Epoch: 5| Step: 9
Training loss: 0.3237478733062744
Validation loss: 1.704121526851449

Epoch: 5| Step: 10
Training loss: 0.2993532121181488
Validation loss: 1.6609909944636847

Epoch: 437| Step: 0
Training loss: 0.30723801255226135
Validation loss: 1.6639350973149782

Epoch: 5| Step: 1
Training loss: 0.34970277547836304
Validation loss: 1.643816086553758

Epoch: 5| Step: 2
Training loss: 0.4837304651737213
Validation loss: 1.6677301551706047

Epoch: 5| Step: 3
Training loss: 0.26388317346572876
Validation loss: 1.6585793687451271

Epoch: 5| Step: 4
Training loss: 0.2784433960914612
Validation loss: 1.6468994899462628

Epoch: 5| Step: 5
Training loss: 0.23840837180614471
Validation loss: 1.6599048600401929

Epoch: 5| Step: 6
Training loss: 0.4284924864768982
Validation loss: 1.7082865917554466

Epoch: 5| Step: 7
Training loss: 0.3405683636665344
Validation loss: 1.7245747902060067

Epoch: 5| Step: 8
Training loss: 0.3828265368938446
Validation loss: 1.7535773067064182

Epoch: 5| Step: 9
Training loss: 0.243946835398674
Validation loss: 1.7278842426115466

Epoch: 5| Step: 10
Training loss: 0.37829136848449707
Validation loss: 1.6870037990231668

Epoch: 438| Step: 0
Training loss: 0.3189377188682556
Validation loss: 1.650837493199174

Epoch: 5| Step: 1
Training loss: 0.20075087249279022
Validation loss: 1.6496093093707997

Epoch: 5| Step: 2
Training loss: 0.17064985632896423
Validation loss: 1.6199581546168174

Epoch: 5| Step: 3
Training loss: 0.2651183009147644
Validation loss: 1.6263515000702233

Epoch: 5| Step: 4
Training loss: 0.3552624583244324
Validation loss: 1.6466479327089043

Epoch: 5| Step: 5
Training loss: 0.318500280380249
Validation loss: 1.6393772338026313

Epoch: 5| Step: 6
Training loss: 0.5922265648841858
Validation loss: 1.6586839088829615

Epoch: 5| Step: 7
Training loss: 0.18898004293441772
Validation loss: 1.6920875003260951

Epoch: 5| Step: 8
Training loss: 0.2088652104139328
Validation loss: 1.7083817143594064

Epoch: 5| Step: 9
Training loss: 0.31105276942253113
Validation loss: 1.740387644819034

Epoch: 5| Step: 10
Training loss: 0.22093045711517334
Validation loss: 1.7193656788077405

Epoch: 439| Step: 0
Training loss: 0.29504626989364624
Validation loss: 1.7598722827049993

Epoch: 5| Step: 1
Training loss: 0.2915964424610138
Validation loss: 1.775870761563701

Epoch: 5| Step: 2
Training loss: 0.27784276008605957
Validation loss: 1.7411284703080372

Epoch: 5| Step: 3
Training loss: 0.21845760941505432
Validation loss: 1.717285304941157

Epoch: 5| Step: 4
Training loss: 0.281756728887558
Validation loss: 1.6541787885850476

Epoch: 5| Step: 5
Training loss: 0.24602708220481873
Validation loss: 1.6630918133643366

Epoch: 5| Step: 6
Training loss: 0.16407470405101776
Validation loss: 1.6371913007510606

Epoch: 5| Step: 7
Training loss: 0.18145552277565002
Validation loss: 1.672890111964236

Epoch: 5| Step: 8
Training loss: 0.3104480504989624
Validation loss: 1.6571574044483963

Epoch: 5| Step: 9
Training loss: 0.4279860556125641
Validation loss: 1.6326035120153939

Epoch: 5| Step: 10
Training loss: 0.21039988100528717
Validation loss: 1.634728116373862

Epoch: 440| Step: 0
Training loss: 0.30578628182411194
Validation loss: 1.6281150976816814

Epoch: 5| Step: 1
Training loss: 0.13921049237251282
Validation loss: 1.6286258825691797

Epoch: 5| Step: 2
Training loss: 0.34187641739845276
Validation loss: 1.62629061360513

Epoch: 5| Step: 3
Training loss: 0.327772855758667
Validation loss: 1.6435406387493174

Epoch: 5| Step: 4
Training loss: 0.4827938973903656
Validation loss: 1.6489953135931363

Epoch: 5| Step: 5
Training loss: 0.19353380799293518
Validation loss: 1.640426420396374

Epoch: 5| Step: 6
Training loss: 0.22258524596691132
Validation loss: 1.6277139814951087

Epoch: 5| Step: 7
Training loss: 0.3584643304347992
Validation loss: 1.6819130912903817

Epoch: 5| Step: 8
Training loss: 0.2200886756181717
Validation loss: 1.7078217306444723

Epoch: 5| Step: 9
Training loss: 0.23108425736427307
Validation loss: 1.6767117913051317

Epoch: 5| Step: 10
Training loss: 0.22980114817619324
Validation loss: 1.6878385428459413

Epoch: 441| Step: 0
Training loss: 0.2956693768501282
Validation loss: 1.6618561001234158

Epoch: 5| Step: 1
Training loss: 0.14709320664405823
Validation loss: 1.6467158845675889

Epoch: 5| Step: 2
Training loss: 0.18684273958206177
Validation loss: 1.6327700602110995

Epoch: 5| Step: 3
Training loss: 0.28688088059425354
Validation loss: 1.6378644063908567

Epoch: 5| Step: 4
Training loss: 0.27906113862991333
Validation loss: 1.6358295666274203

Epoch: 5| Step: 5
Training loss: 0.23769979178905487
Validation loss: 1.6257020299152662

Epoch: 5| Step: 6
Training loss: 0.3039625883102417
Validation loss: 1.6279430517586329

Epoch: 5| Step: 7
Training loss: 0.30443134903907776
Validation loss: 1.6416341758543445

Epoch: 5| Step: 8
Training loss: 0.3410876989364624
Validation loss: 1.6177136128948582

Epoch: 5| Step: 9
Training loss: 0.39588040113449097
Validation loss: 1.6503480160108177

Epoch: 5| Step: 10
Training loss: 0.23126347362995148
Validation loss: 1.6411848516874417

Epoch: 442| Step: 0
Training loss: 0.24543261528015137
Validation loss: 1.6394116442690614

Epoch: 5| Step: 1
Training loss: 0.2804448902606964
Validation loss: 1.6564768206688665

Epoch: 5| Step: 2
Training loss: 0.5049835443496704
Validation loss: 1.6577752841416227

Epoch: 5| Step: 3
Training loss: 0.21670255064964294
Validation loss: 1.65606415143577

Epoch: 5| Step: 4
Training loss: 0.27752789855003357
Validation loss: 1.6247073783669421

Epoch: 5| Step: 5
Training loss: 0.15894272923469543
Validation loss: 1.6540268826228317

Epoch: 5| Step: 6
Training loss: 0.30277013778686523
Validation loss: 1.6484626903328845

Epoch: 5| Step: 7
Training loss: 0.18126848340034485
Validation loss: 1.676164335140618

Epoch: 5| Step: 8
Training loss: 0.14162495732307434
Validation loss: 1.6574514630020305

Epoch: 5| Step: 9
Training loss: 0.25760382413864136
Validation loss: 1.6886001222877092

Epoch: 5| Step: 10
Training loss: 0.2609785795211792
Validation loss: 1.6713922151955225

Epoch: 443| Step: 0
Training loss: 0.32879048585891724
Validation loss: 1.675524175807994

Epoch: 5| Step: 1
Training loss: 0.18527168035507202
Validation loss: 1.6420164672277306

Epoch: 5| Step: 2
Training loss: 0.2540828585624695
Validation loss: 1.6304402107833533

Epoch: 5| Step: 3
Training loss: 0.3641262650489807
Validation loss: 1.6635705527438913

Epoch: 5| Step: 4
Training loss: 0.29139620065689087
Validation loss: 1.6473102774671329

Epoch: 5| Step: 5
Training loss: 0.26092731952667236
Validation loss: 1.635647814760926

Epoch: 5| Step: 6
Training loss: 0.3829565942287445
Validation loss: 1.641949349834073

Epoch: 5| Step: 7
Training loss: 0.25955963134765625
Validation loss: 1.6529783766756776

Epoch: 5| Step: 8
Training loss: 0.1406833976507187
Validation loss: 1.6516748577035882

Epoch: 5| Step: 9
Training loss: 0.27949440479278564
Validation loss: 1.669662416622203

Epoch: 5| Step: 10
Training loss: 0.16932928562164307
Validation loss: 1.644850637964023

Epoch: 444| Step: 0
Training loss: 0.2048686295747757
Validation loss: 1.6382838218442854

Epoch: 5| Step: 1
Training loss: 0.2072111815214157
Validation loss: 1.6641723238011843

Epoch: 5| Step: 2
Training loss: 0.13464252650737762
Validation loss: 1.665971779054211

Epoch: 5| Step: 3
Training loss: 0.2916804254055023
Validation loss: 1.6570271650950115

Epoch: 5| Step: 4
Training loss: 0.2485508918762207
Validation loss: 1.650566679175182

Epoch: 5| Step: 5
Training loss: 0.2750246226787567
Validation loss: 1.6265848509726986

Epoch: 5| Step: 6
Training loss: 0.31562668085098267
Validation loss: 1.6304508684783854

Epoch: 5| Step: 7
Training loss: 0.2637263536453247
Validation loss: 1.6018336178154073

Epoch: 5| Step: 8
Training loss: 0.3341357111930847
Validation loss: 1.6027135131179646

Epoch: 5| Step: 9
Training loss: 0.22211527824401855
Validation loss: 1.5647914948001984

Epoch: 5| Step: 10
Training loss: 0.20931939780712128
Validation loss: 1.571026135516423

Epoch: 445| Step: 0
Training loss: 0.4566686749458313
Validation loss: 1.6181529016904934

Epoch: 5| Step: 1
Training loss: 0.3296779990196228
Validation loss: 1.630740104183074

Epoch: 5| Step: 2
Training loss: 0.13941673934459686
Validation loss: 1.6080165518227445

Epoch: 5| Step: 3
Training loss: 0.32487064599990845
Validation loss: 1.651059127623035

Epoch: 5| Step: 4
Training loss: 0.23852519690990448
Validation loss: 1.636485671484342

Epoch: 5| Step: 5
Training loss: 0.29293036460876465
Validation loss: 1.6328244709199475

Epoch: 5| Step: 6
Training loss: 0.19344832003116608
Validation loss: 1.6524260146643526

Epoch: 5| Step: 7
Training loss: 0.1735764592885971
Validation loss: 1.6516927185878958

Epoch: 5| Step: 8
Training loss: 0.26815441250801086
Validation loss: 1.6662546921801824

Epoch: 5| Step: 9
Training loss: 0.15809178352355957
Validation loss: 1.6599155254261468

Epoch: 5| Step: 10
Training loss: 0.1689850389957428
Validation loss: 1.6481677332232076

Epoch: 446| Step: 0
Training loss: 0.13685934245586395
Validation loss: 1.6589373965417185

Epoch: 5| Step: 1
Training loss: 0.2152218371629715
Validation loss: 1.6278615305500646

Epoch: 5| Step: 2
Training loss: 0.35708045959472656
Validation loss: 1.6390198943435506

Epoch: 5| Step: 3
Training loss: 0.19948264956474304
Validation loss: 1.6298364362409037

Epoch: 5| Step: 4
Training loss: 0.24690666794776917
Validation loss: 1.6153298244681409

Epoch: 5| Step: 5
Training loss: 0.2604551613330841
Validation loss: 1.6179599915781329

Epoch: 5| Step: 6
Training loss: 0.2862236201763153
Validation loss: 1.6323232445665585

Epoch: 5| Step: 7
Training loss: 0.2804940342903137
Validation loss: 1.6220061356021511

Epoch: 5| Step: 8
Training loss: 0.18816545605659485
Validation loss: 1.6095753844066332

Epoch: 5| Step: 9
Training loss: 0.11487825214862823
Validation loss: 1.627326201367122

Epoch: 5| Step: 10
Training loss: 0.24011977016925812
Validation loss: 1.6068306840876097

Epoch: 447| Step: 0
Training loss: 0.11834193766117096
Validation loss: 1.623245414867196

Epoch: 5| Step: 1
Training loss: 0.14358064532279968
Validation loss: 1.6315306668640466

Epoch: 5| Step: 2
Training loss: 0.2530062794685364
Validation loss: 1.6516885936901133

Epoch: 5| Step: 3
Training loss: 0.20123739540576935
Validation loss: 1.6884131726398264

Epoch: 5| Step: 4
Training loss: 0.28036433458328247
Validation loss: 1.6645078646239413

Epoch: 5| Step: 5
Training loss: 0.26555126905441284
Validation loss: 1.6501392613175094

Epoch: 5| Step: 6
Training loss: 0.28207287192344666
Validation loss: 1.6326644446260186

Epoch: 5| Step: 7
Training loss: 0.23118560016155243
Validation loss: 1.6428742190842986

Epoch: 5| Step: 8
Training loss: 0.15217390656471252
Validation loss: 1.6377704899798158

Epoch: 5| Step: 9
Training loss: 0.26723068952560425
Validation loss: 1.637782750591155

Epoch: 5| Step: 10
Training loss: 0.21152567863464355
Validation loss: 1.6273956016827655

Epoch: 448| Step: 0
Training loss: 0.14328542351722717
Validation loss: 1.64075134646508

Epoch: 5| Step: 1
Training loss: 0.24593155086040497
Validation loss: 1.6244777889661892

Epoch: 5| Step: 2
Training loss: 0.22182142734527588
Validation loss: 1.6511442071648055

Epoch: 5| Step: 3
Training loss: 0.23558056354522705
Validation loss: 1.6241564058488416

Epoch: 5| Step: 4
Training loss: 0.18088211119174957
Validation loss: 1.648467731732194

Epoch: 5| Step: 5
Training loss: 0.3351314663887024
Validation loss: 1.6779545468668784

Epoch: 5| Step: 6
Training loss: 0.21417124569416046
Validation loss: 1.6896243326125606

Epoch: 5| Step: 7
Training loss: 0.2815142869949341
Validation loss: 1.7110316753387451

Epoch: 5| Step: 8
Training loss: 0.40826478600502014
Validation loss: 1.6596844785956926

Epoch: 5| Step: 9
Training loss: 0.3687216639518738
Validation loss: 1.6710076883275022

Epoch: 5| Step: 10
Training loss: 0.19486308097839355
Validation loss: 1.6580119620087326

Epoch: 449| Step: 0
Training loss: 0.33674412965774536
Validation loss: 1.6539280312035674

Epoch: 5| Step: 1
Training loss: 0.21808810532093048
Validation loss: 1.667118186591774

Epoch: 5| Step: 2
Training loss: 0.1809951514005661
Validation loss: 1.6382119860700382

Epoch: 5| Step: 3
Training loss: 0.33220043778419495
Validation loss: 1.6374098049697055

Epoch: 5| Step: 4
Training loss: 0.23437801003456116
Validation loss: 1.6481938349303378

Epoch: 5| Step: 5
Training loss: 0.17548982799053192
Validation loss: 1.690045173450183

Epoch: 5| Step: 6
Training loss: 0.35183292627334595
Validation loss: 1.6731368918572702

Epoch: 5| Step: 7
Training loss: 0.27666106820106506
Validation loss: 1.641439038579182

Epoch: 5| Step: 8
Training loss: 0.19225838780403137
Validation loss: 1.6272600927660543

Epoch: 5| Step: 9
Training loss: 0.32120922207832336
Validation loss: 1.6004163308810162

Epoch: 5| Step: 10
Training loss: 0.24365870654582977
Validation loss: 1.589847263469491

Epoch: 450| Step: 0
Training loss: 0.40320461988449097
Validation loss: 1.635064014824488

Epoch: 5| Step: 1
Training loss: 0.40497273206710815
Validation loss: 1.6153573477140037

Epoch: 5| Step: 2
Training loss: 0.17848701775074005
Validation loss: 1.6110343728014218

Epoch: 5| Step: 3
Training loss: 0.1548866331577301
Validation loss: 1.6055313682043424

Epoch: 5| Step: 4
Training loss: 0.3687560558319092
Validation loss: 1.651360568179879

Epoch: 5| Step: 5
Training loss: 0.3143472671508789
Validation loss: 1.6814548917995986

Epoch: 5| Step: 6
Training loss: 0.34089964628219604
Validation loss: 1.709981277424802

Epoch: 5| Step: 7
Training loss: 0.3504997789859772
Validation loss: 1.6982916644824448

Epoch: 5| Step: 8
Training loss: 0.18736574053764343
Validation loss: 1.6794478918916436

Epoch: 5| Step: 9
Training loss: 0.22645029425621033
Validation loss: 1.6426850006144533

Epoch: 5| Step: 10
Training loss: 0.17719696462154388
Validation loss: 1.6475248054791523

Epoch: 451| Step: 0
Training loss: 0.2642633020877838
Validation loss: 1.6653395070824573

Epoch: 5| Step: 1
Training loss: 0.4277104437351227
Validation loss: 1.649876344588495

Epoch: 5| Step: 2
Training loss: 0.33234986662864685
Validation loss: 1.6681592515719834

Epoch: 5| Step: 3
Training loss: 0.14289143681526184
Validation loss: 1.6611359991053098

Epoch: 5| Step: 4
Training loss: 0.3342197835445404
Validation loss: 1.6374806306695426

Epoch: 5| Step: 5
Training loss: 0.3438080847263336
Validation loss: 1.6545255466174054

Epoch: 5| Step: 6
Training loss: 0.2730571925640106
Validation loss: 1.6747810545788016

Epoch: 5| Step: 7
Training loss: 0.21911239624023438
Validation loss: 1.680217207119029

Epoch: 5| Step: 8
Training loss: 0.22070717811584473
Validation loss: 1.678473714859255

Epoch: 5| Step: 9
Training loss: 0.1573617160320282
Validation loss: 1.7182389766939226

Epoch: 5| Step: 10
Training loss: 0.1794140785932541
Validation loss: 1.68367180901189

Epoch: 452| Step: 0
Training loss: 0.32067593932151794
Validation loss: 1.6481623239414667

Epoch: 5| Step: 1
Training loss: 0.24584050476551056
Validation loss: 1.6497028341857336

Epoch: 5| Step: 2
Training loss: 0.22507676482200623
Validation loss: 1.6348518838164627

Epoch: 5| Step: 3
Training loss: 0.2051486223936081
Validation loss: 1.641272796097622

Epoch: 5| Step: 4
Training loss: 0.375530481338501
Validation loss: 1.6258589477949246

Epoch: 5| Step: 5
Training loss: 0.19177570939064026
Validation loss: 1.6430086166627946

Epoch: 5| Step: 6
Training loss: 0.19544267654418945
Validation loss: 1.6618047632196897

Epoch: 5| Step: 7
Training loss: 0.354024738073349
Validation loss: 1.666982885329954

Epoch: 5| Step: 8
Training loss: 0.1861141473054886
Validation loss: 1.683619232587917

Epoch: 5| Step: 9
Training loss: 0.19203068315982819
Validation loss: 1.6834505802841597

Epoch: 5| Step: 10
Training loss: 0.15101583302021027
Validation loss: 1.690789217590004

Epoch: 453| Step: 0
Training loss: 0.1493547111749649
Validation loss: 1.677709512813117

Epoch: 5| Step: 1
Training loss: 0.2654823660850525
Validation loss: 1.6843370686295212

Epoch: 5| Step: 2
Training loss: 0.32414454221725464
Validation loss: 1.6471209705516856

Epoch: 5| Step: 3
Training loss: 0.20417380332946777
Validation loss: 1.6562481554605628

Epoch: 5| Step: 4
Training loss: 0.14624109864234924
Validation loss: 1.658947035830508

Epoch: 5| Step: 5
Training loss: 0.26287728548049927
Validation loss: 1.6428664076712824

Epoch: 5| Step: 6
Training loss: 0.31204113364219666
Validation loss: 1.6765196759213683

Epoch: 5| Step: 7
Training loss: 0.21518687903881073
Validation loss: 1.6515953028073875

Epoch: 5| Step: 8
Training loss: 0.3713250756263733
Validation loss: 1.6528283216620003

Epoch: 5| Step: 9
Training loss: 0.1170584186911583
Validation loss: 1.645537296930949

Epoch: 5| Step: 10
Training loss: 0.22691375017166138
Validation loss: 1.6197839013991817

Epoch: 454| Step: 0
Training loss: 0.16606706380844116
Validation loss: 1.6247748828703357

Epoch: 5| Step: 1
Training loss: 0.1497151106595993
Validation loss: 1.623641594763725

Epoch: 5| Step: 2
Training loss: 0.19712094962596893
Validation loss: 1.6152357837205291

Epoch: 5| Step: 3
Training loss: 0.2769940197467804
Validation loss: 1.6363850767894457

Epoch: 5| Step: 4
Training loss: 0.18111996352672577
Validation loss: 1.6241729246672763

Epoch: 5| Step: 5
Training loss: 0.42412668466567993
Validation loss: 1.6506424578287269

Epoch: 5| Step: 6
Training loss: 0.3270222246646881
Validation loss: 1.6492511405739734

Epoch: 5| Step: 7
Training loss: 0.10055655241012573
Validation loss: 1.657442985042449

Epoch: 5| Step: 8
Training loss: 0.18402370810508728
Validation loss: 1.6789432853780768

Epoch: 5| Step: 9
Training loss: 0.20539455115795135
Validation loss: 1.669437155287753

Epoch: 5| Step: 10
Training loss: 0.2814564108848572
Validation loss: 1.706277847290039

Epoch: 455| Step: 0
Training loss: 0.09671072661876678
Validation loss: 1.6898580956202682

Epoch: 5| Step: 1
Training loss: 0.17866463959217072
Validation loss: 1.6886473407027542

Epoch: 5| Step: 2
Training loss: 0.1682581752538681
Validation loss: 1.65964735451565

Epoch: 5| Step: 3
Training loss: 0.1902540773153305
Validation loss: 1.6383735428574264

Epoch: 5| Step: 4
Training loss: 0.16194882988929749
Validation loss: 1.6405734926141717

Epoch: 5| Step: 5
Training loss: 0.4223858714103699
Validation loss: 1.6416944611457087

Epoch: 5| Step: 6
Training loss: 0.2978660762310028
Validation loss: 1.6391337328059699

Epoch: 5| Step: 7
Training loss: 0.28889864683151245
Validation loss: 1.6794804526913552

Epoch: 5| Step: 8
Training loss: 0.22462394833564758
Validation loss: 1.653593131290969

Epoch: 5| Step: 9
Training loss: 0.21735629439353943
Validation loss: 1.692288315424355

Epoch: 5| Step: 10
Training loss: 0.2160671204328537
Validation loss: 1.683331387017363

Epoch: 456| Step: 0
Training loss: 0.12137658894062042
Validation loss: 1.6789032400295298

Epoch: 5| Step: 1
Training loss: 0.29085102677345276
Validation loss: 1.693964982545504

Epoch: 5| Step: 2
Training loss: 0.16054251790046692
Validation loss: 1.6602043772256503

Epoch: 5| Step: 3
Training loss: 0.21693959832191467
Validation loss: 1.6187019886509064

Epoch: 5| Step: 4
Training loss: 0.1750292181968689
Validation loss: 1.6100462534094369

Epoch: 5| Step: 5
Training loss: 0.29941415786743164
Validation loss: 1.5735056425935479

Epoch: 5| Step: 6
Training loss: 0.20249104499816895
Validation loss: 1.6198347947930778

Epoch: 5| Step: 7
Training loss: 0.33709007501602173
Validation loss: 1.584045648574829

Epoch: 5| Step: 8
Training loss: 0.3213982582092285
Validation loss: 1.585794416166121

Epoch: 5| Step: 9
Training loss: 0.18657323718070984
Validation loss: 1.5964991572082683

Epoch: 5| Step: 10
Training loss: 0.30594685673713684
Validation loss: 1.6101717923277168

Epoch: 457| Step: 0
Training loss: 0.240240216255188
Validation loss: 1.626245278184132

Epoch: 5| Step: 1
Training loss: 0.1829085648059845
Validation loss: 1.6162094031610796

Epoch: 5| Step: 2
Training loss: 0.3989933133125305
Validation loss: 1.6344258977520851

Epoch: 5| Step: 3
Training loss: 0.2959415912628174
Validation loss: 1.6366789674246183

Epoch: 5| Step: 4
Training loss: 0.2592659890651703
Validation loss: 1.6443966332302298

Epoch: 5| Step: 5
Training loss: 0.2518497109413147
Validation loss: 1.6289846461306337

Epoch: 5| Step: 6
Training loss: 0.14454224705696106
Validation loss: 1.6166478498007661

Epoch: 5| Step: 7
Training loss: 0.2652921676635742
Validation loss: 1.5971609482201197

Epoch: 5| Step: 8
Training loss: 0.281854510307312
Validation loss: 1.6059492634188743

Epoch: 5| Step: 9
Training loss: 0.20262980461120605
Validation loss: 1.598160095112298

Epoch: 5| Step: 10
Training loss: 0.12880434095859528
Validation loss: 1.5722931585004252

Epoch: 458| Step: 0
Training loss: 0.24494871497154236
Validation loss: 1.5809610633439914

Epoch: 5| Step: 1
Training loss: 0.21542850136756897
Validation loss: 1.587858933274464

Epoch: 5| Step: 2
Training loss: 0.11935730278491974
Validation loss: 1.61038242360597

Epoch: 5| Step: 3
Training loss: 0.19319359958171844
Validation loss: 1.6075945156876759

Epoch: 5| Step: 4
Training loss: 0.22491708397865295
Validation loss: 1.6434509984908565

Epoch: 5| Step: 5
Training loss: 0.29462721943855286
Validation loss: 1.6568350099748181

Epoch: 5| Step: 6
Training loss: 0.16335193812847137
Validation loss: 1.6260992442407916

Epoch: 5| Step: 7
Training loss: 0.16133849322795868
Validation loss: 1.5975838886794222

Epoch: 5| Step: 8
Training loss: 0.209486722946167
Validation loss: 1.6162913819795013

Epoch: 5| Step: 9
Training loss: 0.3200724124908447
Validation loss: 1.632780719828862

Epoch: 5| Step: 10
Training loss: 0.23200038075447083
Validation loss: 1.6198766974992649

Epoch: 459| Step: 0
Training loss: 0.20313826203346252
Validation loss: 1.596973640944368

Epoch: 5| Step: 1
Training loss: 0.24372251331806183
Validation loss: 1.6296487739009242

Epoch: 5| Step: 2
Training loss: 0.1531953066587448
Validation loss: 1.6496855840888074

Epoch: 5| Step: 3
Training loss: 0.22949829697608948
Validation loss: 1.6516978497146277

Epoch: 5| Step: 4
Training loss: 0.21443839371204376
Validation loss: 1.6442413932533675

Epoch: 5| Step: 5
Training loss: 0.4315508306026459
Validation loss: 1.656843751989385

Epoch: 5| Step: 6
Training loss: 0.10840004682540894
Validation loss: 1.640387350513089

Epoch: 5| Step: 7
Training loss: 0.11072645336389542
Validation loss: 1.6250419642335625

Epoch: 5| Step: 8
Training loss: 0.2265750616788864
Validation loss: 1.6302892725954774

Epoch: 5| Step: 9
Training loss: 0.3407820463180542
Validation loss: 1.6160899182801605

Epoch: 5| Step: 10
Training loss: 0.1976204365491867
Validation loss: 1.6154914966193579

Epoch: 460| Step: 0
Training loss: 0.29502955079078674
Validation loss: 1.6029488578919442

Epoch: 5| Step: 1
Training loss: 0.15331462025642395
Validation loss: 1.6443786262184061

Epoch: 5| Step: 2
Training loss: 0.26350387930870056
Validation loss: 1.6861120552145026

Epoch: 5| Step: 3
Training loss: 0.22016946971416473
Validation loss: 1.6523204772703108

Epoch: 5| Step: 4
Training loss: 0.23188695311546326
Validation loss: 1.6476466707004014

Epoch: 5| Step: 5
Training loss: 0.20289018750190735
Validation loss: 1.6203426353393062

Epoch: 5| Step: 6
Training loss: 0.21619394421577454
Validation loss: 1.634755560146865

Epoch: 5| Step: 7
Training loss: 0.23055243492126465
Validation loss: 1.606429466637232

Epoch: 5| Step: 8
Training loss: 0.22162191569805145
Validation loss: 1.5907771741190264

Epoch: 5| Step: 9
Training loss: 0.17195332050323486
Validation loss: 1.6018706829317155

Epoch: 5| Step: 10
Training loss: 0.3292192220687866
Validation loss: 1.6120514638962284

Epoch: 461| Step: 0
Training loss: 0.2390632927417755
Validation loss: 1.5890784891702796

Epoch: 5| Step: 1
Training loss: 0.2202204465866089
Validation loss: 1.607285580327434

Epoch: 5| Step: 2
Training loss: 0.3054177761077881
Validation loss: 1.6143869033423803

Epoch: 5| Step: 3
Training loss: 0.27019333839416504
Validation loss: 1.6057583837098972

Epoch: 5| Step: 4
Training loss: 0.19870154559612274
Validation loss: 1.6445476060272546

Epoch: 5| Step: 5
Training loss: 0.35255855321884155
Validation loss: 1.6359264286615516

Epoch: 5| Step: 6
Training loss: 0.11429150402545929
Validation loss: 1.6527568114701139

Epoch: 5| Step: 7
Training loss: 0.1615867018699646
Validation loss: 1.6198838346747941

Epoch: 5| Step: 8
Training loss: 0.15591830015182495
Validation loss: 1.6554331343661073

Epoch: 5| Step: 9
Training loss: 0.26260122656822205
Validation loss: 1.6057821204585414

Epoch: 5| Step: 10
Training loss: 0.18089257180690765
Validation loss: 1.6529283626105196

Epoch: 462| Step: 0
Training loss: 0.16800449788570404
Validation loss: 1.6179063409887335

Epoch: 5| Step: 1
Training loss: 0.18425051867961884
Validation loss: 1.6087702987014607

Epoch: 5| Step: 2
Training loss: 0.14329755306243896
Validation loss: 1.5991217256874166

Epoch: 5| Step: 3
Training loss: 0.24407009780406952
Validation loss: 1.5965855185703566

Epoch: 5| Step: 4
Training loss: 0.21369752287864685
Validation loss: 1.60451393101805

Epoch: 5| Step: 5
Training loss: 0.2576141357421875
Validation loss: 1.615707242360679

Epoch: 5| Step: 6
Training loss: 0.18572480976581573
Validation loss: 1.6190857220721502

Epoch: 5| Step: 7
Training loss: 0.19921667873859406
Validation loss: 1.6184181051869546

Epoch: 5| Step: 8
Training loss: 0.24278545379638672
Validation loss: 1.6555352082816504

Epoch: 5| Step: 9
Training loss: 0.4066133499145508
Validation loss: 1.6455501606387477

Epoch: 5| Step: 10
Training loss: 0.13632622361183167
Validation loss: 1.6290692103806363

Epoch: 463| Step: 0
Training loss: 0.35679781436920166
Validation loss: 1.626837645807574

Epoch: 5| Step: 1
Training loss: 0.18569207191467285
Validation loss: 1.6255829539350284

Epoch: 5| Step: 2
Training loss: 0.10934843868017197
Validation loss: 1.6267262633128832

Epoch: 5| Step: 3
Training loss: 0.15894725918769836
Validation loss: 1.6348584313546457

Epoch: 5| Step: 4
Training loss: 0.2526155114173889
Validation loss: 1.6406931120862243

Epoch: 5| Step: 5
Training loss: 0.27404898405075073
Validation loss: 1.607702462903915

Epoch: 5| Step: 6
Training loss: 0.2029915302991867
Validation loss: 1.626637610056067

Epoch: 5| Step: 7
Training loss: 0.20985989272594452
Validation loss: 1.6396139834516792

Epoch: 5| Step: 8
Training loss: 0.2327476441860199
Validation loss: 1.649577162599051

Epoch: 5| Step: 9
Training loss: 0.16473665833473206
Validation loss: 1.6742016705133582

Epoch: 5| Step: 10
Training loss: 0.16581737995147705
Validation loss: 1.6978625584674139

Epoch: 464| Step: 0
Training loss: 0.3116779029369354
Validation loss: 1.6949218537217827

Epoch: 5| Step: 1
Training loss: 0.23893912136554718
Validation loss: 1.662209467221332

Epoch: 5| Step: 2
Training loss: 0.18959733843803406
Validation loss: 1.6660794263244958

Epoch: 5| Step: 3
Training loss: 0.20398306846618652
Validation loss: 1.6518680716073642

Epoch: 5| Step: 4
Training loss: 0.26526859402656555
Validation loss: 1.6406416995550996

Epoch: 5| Step: 5
Training loss: 0.18843887746334076
Validation loss: 1.6118037867289718

Epoch: 5| Step: 6
Training loss: 0.22037272155284882
Validation loss: 1.628926674524943

Epoch: 5| Step: 7
Training loss: 0.22887074947357178
Validation loss: 1.598626967399351

Epoch: 5| Step: 8
Training loss: 0.21047334372997284
Validation loss: 1.6264723667534449

Epoch: 5| Step: 9
Training loss: 0.17145203053951263
Validation loss: 1.6128327397889988

Epoch: 5| Step: 10
Training loss: 0.1162511333823204
Validation loss: 1.6185122266892464

Epoch: 465| Step: 0
Training loss: 0.1685965359210968
Validation loss: 1.5774787523413216

Epoch: 5| Step: 1
Training loss: 0.3329051733016968
Validation loss: 1.6035607771206928

Epoch: 5| Step: 2
Training loss: 0.08898576349020004
Validation loss: 1.597859836393787

Epoch: 5| Step: 3
Training loss: 0.18318116664886475
Validation loss: 1.6166618024149249

Epoch: 5| Step: 4
Training loss: 0.3003755807876587
Validation loss: 1.6132974759224923

Epoch: 5| Step: 5
Training loss: 0.16232448816299438
Validation loss: 1.6169468869445145

Epoch: 5| Step: 6
Training loss: 0.24098777770996094
Validation loss: 1.6389330663988668

Epoch: 5| Step: 7
Training loss: 0.13809460401535034
Validation loss: 1.6429311793337587

Epoch: 5| Step: 8
Training loss: 0.1519394814968109
Validation loss: 1.6037603629532682

Epoch: 5| Step: 9
Training loss: 0.17923615872859955
Validation loss: 1.60397163385986

Epoch: 5| Step: 10
Training loss: 0.23201251029968262
Validation loss: 1.576041175473121

Epoch: 466| Step: 0
Training loss: 0.23394529521465302
Validation loss: 1.5870015928822179

Epoch: 5| Step: 1
Training loss: 0.08999599516391754
Validation loss: 1.5964006621350524

Epoch: 5| Step: 2
Training loss: 0.16992779076099396
Validation loss: 1.6232788505092743

Epoch: 5| Step: 3
Training loss: 0.11954734474420547
Validation loss: 1.602694821614091

Epoch: 5| Step: 4
Training loss: 0.29046231508255005
Validation loss: 1.6187562724595428

Epoch: 5| Step: 5
Training loss: 0.2918660640716553
Validation loss: 1.6710452777083202

Epoch: 5| Step: 6
Training loss: 0.33718591928482056
Validation loss: 1.664486615888534

Epoch: 5| Step: 7
Training loss: 0.17487536370754242
Validation loss: 1.640403067552915

Epoch: 5| Step: 8
Training loss: 0.16987431049346924
Validation loss: 1.638034603929007

Epoch: 5| Step: 9
Training loss: 0.2861565947532654
Validation loss: 1.6396270875007875

Epoch: 5| Step: 10
Training loss: 0.2314133197069168
Validation loss: 1.6387099271179528

Epoch: 467| Step: 0
Training loss: 0.19633616507053375
Validation loss: 1.6221571865902151

Epoch: 5| Step: 1
Training loss: 0.18411417305469513
Validation loss: 1.5967141005300707

Epoch: 5| Step: 2
Training loss: 0.1982438862323761
Validation loss: 1.6314988802838069

Epoch: 5| Step: 3
Training loss: 0.2217223346233368
Validation loss: 1.6658430432760587

Epoch: 5| Step: 4
Training loss: 0.22944052517414093
Validation loss: 1.6532307991417505

Epoch: 5| Step: 5
Training loss: 0.2368941754102707
Validation loss: 1.6500221375496156

Epoch: 5| Step: 6
Training loss: 0.38142141699790955
Validation loss: 1.6713985448242517

Epoch: 5| Step: 7
Training loss: 0.2445804327726364
Validation loss: 1.6950246877567743

Epoch: 5| Step: 8
Training loss: 0.12827417254447937
Validation loss: 1.6794360171082199

Epoch: 5| Step: 9
Training loss: 0.21870341897010803
Validation loss: 1.678678088290717

Epoch: 5| Step: 10
Training loss: 0.09875185042619705
Validation loss: 1.6434986334975048

Epoch: 468| Step: 0
Training loss: 0.13846316933631897
Validation loss: 1.6111671937409269

Epoch: 5| Step: 1
Training loss: 0.1587381362915039
Validation loss: 1.6216269295702699

Epoch: 5| Step: 2
Training loss: 0.2673170268535614
Validation loss: 1.6091897410731162

Epoch: 5| Step: 3
Training loss: 0.3178115487098694
Validation loss: 1.6091625677642

Epoch: 5| Step: 4
Training loss: 0.19422924518585205
Validation loss: 1.6231743981761317

Epoch: 5| Step: 5
Training loss: 0.09750061482191086
Validation loss: 1.6148263895383446

Epoch: 5| Step: 6
Training loss: 0.0944070965051651
Validation loss: 1.6135654282826248

Epoch: 5| Step: 7
Training loss: 0.2904757857322693
Validation loss: 1.6397397633521789

Epoch: 5| Step: 8
Training loss: 0.3373201787471771
Validation loss: 1.6673717806416173

Epoch: 5| Step: 9
Training loss: 0.1474706083536148
Validation loss: 1.6358185327181252

Epoch: 5| Step: 10
Training loss: 0.28497713804244995
Validation loss: 1.6324546138445537

Epoch: 469| Step: 0
Training loss: 0.20978951454162598
Validation loss: 1.6098582795871201

Epoch: 5| Step: 1
Training loss: 0.18606534600257874
Validation loss: 1.6045292474890267

Epoch: 5| Step: 2
Training loss: 0.11520980298519135
Validation loss: 1.5988344896224238

Epoch: 5| Step: 3
Training loss: 0.31603187322616577
Validation loss: 1.5889282072744062

Epoch: 5| Step: 4
Training loss: 0.20336619019508362
Validation loss: 1.5746339085281535

Epoch: 5| Step: 5
Training loss: 0.202924445271492
Validation loss: 1.6155628824746737

Epoch: 5| Step: 6
Training loss: 0.2046188861131668
Validation loss: 1.5988889266085882

Epoch: 5| Step: 7
Training loss: 0.1895408034324646
Validation loss: 1.598854394369228

Epoch: 5| Step: 8
Training loss: 0.20420363545417786
Validation loss: 1.5708918084380448

Epoch: 5| Step: 9
Training loss: 0.3304710388183594
Validation loss: 1.5812447224893877

Epoch: 5| Step: 10
Training loss: 0.10627550631761551
Validation loss: 1.5938325543557443

Epoch: 470| Step: 0
Training loss: 0.14487262070178986
Validation loss: 1.616565546681804

Epoch: 5| Step: 1
Training loss: 0.2396848201751709
Validation loss: 1.6233207782109578

Epoch: 5| Step: 2
Training loss: 0.29190945625305176
Validation loss: 1.6020687882618239

Epoch: 5| Step: 3
Training loss: 0.22797361016273499
Validation loss: 1.637459308870377

Epoch: 5| Step: 4
Training loss: 0.1940803825855255
Validation loss: 1.6308873891830444

Epoch: 5| Step: 5
Training loss: 0.22965848445892334
Validation loss: 1.6184995046225927

Epoch: 5| Step: 6
Training loss: 0.27131062746047974
Validation loss: 1.6135908865159558

Epoch: 5| Step: 7
Training loss: 0.39377811551094055
Validation loss: 1.6215479912296418

Epoch: 5| Step: 8
Training loss: 0.30214762687683105
Validation loss: 1.6047203476710985

Epoch: 5| Step: 9
Training loss: 0.21996179223060608
Validation loss: 1.5892100180349042

Epoch: 5| Step: 10
Training loss: 0.1186574175953865
Validation loss: 1.5867831117363387

Epoch: 471| Step: 0
Training loss: 0.16758863627910614
Validation loss: 1.5841967854448544

Epoch: 5| Step: 1
Training loss: 0.1397251933813095
Validation loss: 1.6206832162795528

Epoch: 5| Step: 2
Training loss: 0.28344249725341797
Validation loss: 1.6455943943351827

Epoch: 5| Step: 3
Training loss: 0.21611185371875763
Validation loss: 1.6406718736053796

Epoch: 5| Step: 4
Training loss: 0.16472658514976501
Validation loss: 1.6386299992120394

Epoch: 5| Step: 5
Training loss: 0.18406368792057037
Validation loss: 1.6610899445831135

Epoch: 5| Step: 6
Training loss: 0.23613567650318146
Validation loss: 1.6428662269346175

Epoch: 5| Step: 7
Training loss: 0.15520457923412323
Validation loss: 1.6588260973653486

Epoch: 5| Step: 8
Training loss: 0.1923336684703827
Validation loss: 1.6230137053356375

Epoch: 5| Step: 9
Training loss: 0.3296157717704773
Validation loss: 1.6413164215703164

Epoch: 5| Step: 10
Training loss: 0.2001681625843048
Validation loss: 1.6384232095492783

Epoch: 472| Step: 0
Training loss: 0.22098490595817566
Validation loss: 1.6547608734459005

Epoch: 5| Step: 1
Training loss: 0.3566126823425293
Validation loss: 1.6262792682134977

Epoch: 5| Step: 2
Training loss: 0.22262144088745117
Validation loss: 1.6289065012367823

Epoch: 5| Step: 3
Training loss: 0.2429266721010208
Validation loss: 1.6477208252876037

Epoch: 5| Step: 4
Training loss: 0.14016996324062347
Validation loss: 1.658857314817367

Epoch: 5| Step: 5
Training loss: 0.12564966082572937
Validation loss: 1.6464156425127419

Epoch: 5| Step: 6
Training loss: 0.15537574887275696
Validation loss: 1.6346772697664076

Epoch: 5| Step: 7
Training loss: 0.19604353606700897
Validation loss: 1.6204453161967698

Epoch: 5| Step: 8
Training loss: 0.24660786986351013
Validation loss: 1.6301445191906345

Epoch: 5| Step: 9
Training loss: 0.1637570559978485
Validation loss: 1.6241841277768534

Epoch: 5| Step: 10
Training loss: 0.20171386003494263
Validation loss: 1.646549629908736

Epoch: 473| Step: 0
Training loss: 0.168475940823555
Validation loss: 1.6068615323753768

Epoch: 5| Step: 1
Training loss: 0.2740252912044525
Validation loss: 1.6163268576386154

Epoch: 5| Step: 2
Training loss: 0.07502564042806625
Validation loss: 1.6131302791257058

Epoch: 5| Step: 3
Training loss: 0.12969869375228882
Validation loss: 1.6317496838108185

Epoch: 5| Step: 4
Training loss: 0.20815162360668182
Validation loss: 1.611149755857324

Epoch: 5| Step: 5
Training loss: 0.13441571593284607
Validation loss: 1.6371276981087142

Epoch: 5| Step: 6
Training loss: 0.22862562537193298
Validation loss: 1.6448610751859603

Epoch: 5| Step: 7
Training loss: 0.2975422441959381
Validation loss: 1.6244006310739825

Epoch: 5| Step: 8
Training loss: 0.1535816192626953
Validation loss: 1.6265635387871855

Epoch: 5| Step: 9
Training loss: 0.182130366563797
Validation loss: 1.6193224973576044

Epoch: 5| Step: 10
Training loss: 0.23398876190185547
Validation loss: 1.618180879982569

Epoch: 474| Step: 0
Training loss: 0.18804171681404114
Validation loss: 1.630736111312784

Epoch: 5| Step: 1
Training loss: 0.13834592700004578
Validation loss: 1.6234882031717608

Epoch: 5| Step: 2
Training loss: 0.2917376160621643
Validation loss: 1.6264933898884764

Epoch: 5| Step: 3
Training loss: 0.16456995904445648
Validation loss: 1.6536070492959791

Epoch: 5| Step: 4
Training loss: 0.22180774807929993
Validation loss: 1.641062944166122

Epoch: 5| Step: 5
Training loss: 0.16230472922325134
Validation loss: 1.67741806532747

Epoch: 5| Step: 6
Training loss: 0.26946884393692017
Validation loss: 1.6601068537722352

Epoch: 5| Step: 7
Training loss: 0.21133308112621307
Validation loss: 1.6490888723763086

Epoch: 5| Step: 8
Training loss: 0.16934777796268463
Validation loss: 1.671521209901379

Epoch: 5| Step: 9
Training loss: 0.16279208660125732
Validation loss: 1.6738807539786063

Epoch: 5| Step: 10
Training loss: 0.17499631643295288
Validation loss: 1.6672345002492268

Epoch: 475| Step: 0
Training loss: 0.19815167784690857
Validation loss: 1.6570120755062308

Epoch: 5| Step: 1
Training loss: 0.2938230633735657
Validation loss: 1.663047677727156

Epoch: 5| Step: 2
Training loss: 0.2643832266330719
Validation loss: 1.6598901998612188

Epoch: 5| Step: 3
Training loss: 0.13845419883728027
Validation loss: 1.6191369743757351

Epoch: 5| Step: 4
Training loss: 0.14101596176624298
Validation loss: 1.622109192673878

Epoch: 5| Step: 5
Training loss: 0.23059305548667908
Validation loss: 1.6022484930612708

Epoch: 5| Step: 6
Training loss: 0.11630094051361084
Validation loss: 1.6086544913630332

Epoch: 5| Step: 7
Training loss: 0.12040440738201141
Validation loss: 1.6097184765723445

Epoch: 5| Step: 8
Training loss: 0.28471434116363525
Validation loss: 1.589062189543119

Epoch: 5| Step: 9
Training loss: 0.17230968177318573
Validation loss: 1.6036678065535843

Epoch: 5| Step: 10
Training loss: 0.2981920838356018
Validation loss: 1.5754728022442068

Epoch: 476| Step: 0
Training loss: 0.18420931696891785
Validation loss: 1.5984838367790304

Epoch: 5| Step: 1
Training loss: 0.14022484421730042
Validation loss: 1.6170637005118913

Epoch: 5| Step: 2
Training loss: 0.13887634873390198
Validation loss: 1.6155269094692764

Epoch: 5| Step: 3
Training loss: 0.2004474699497223
Validation loss: 1.6469858000355382

Epoch: 5| Step: 4
Training loss: 0.16646583378314972
Validation loss: 1.6354251907717796

Epoch: 5| Step: 5
Training loss: 0.2879839837551117
Validation loss: 1.6281331713481615

Epoch: 5| Step: 6
Training loss: 0.2061534821987152
Validation loss: 1.6441673796664003

Epoch: 5| Step: 7
Training loss: 0.17947451770305634
Validation loss: 1.6114560237494848

Epoch: 5| Step: 8
Training loss: 0.22710156440734863
Validation loss: 1.6009249982013498

Epoch: 5| Step: 9
Training loss: 0.2798604369163513
Validation loss: 1.5849065921639884

Epoch: 5| Step: 10
Training loss: 0.1753559410572052
Validation loss: 1.604020651950631

Epoch: 477| Step: 0
Training loss: 0.1643989235162735
Validation loss: 1.6004340866560578

Epoch: 5| Step: 1
Training loss: 0.2661714255809784
Validation loss: 1.6295486060521935

Epoch: 5| Step: 2
Training loss: 0.15846876800060272
Validation loss: 1.6126791463103345

Epoch: 5| Step: 3
Training loss: 0.22840967774391174
Validation loss: 1.6372695174268497

Epoch: 5| Step: 4
Training loss: 0.22858822345733643
Validation loss: 1.654612248943698

Epoch: 5| Step: 5
Training loss: 0.14461751282215118
Validation loss: 1.630137865261365

Epoch: 5| Step: 6
Training loss: 0.17671461403369904
Validation loss: 1.6014081470427974

Epoch: 5| Step: 7
Training loss: 0.24321162700653076
Validation loss: 1.6096051213561848

Epoch: 5| Step: 8
Training loss: 0.32295551896095276
Validation loss: 1.6263602600302747

Epoch: 5| Step: 9
Training loss: 0.2822292745113373
Validation loss: 1.6292951581298665

Epoch: 5| Step: 10
Training loss: 0.3228124678134918
Validation loss: 1.6007399392384354

Epoch: 478| Step: 0
Training loss: 0.16322928667068481
Validation loss: 1.5885695013948666

Epoch: 5| Step: 1
Training loss: 0.18543294072151184
Validation loss: 1.5848177056158743

Epoch: 5| Step: 2
Training loss: 0.22849345207214355
Validation loss: 1.5913198276232647

Epoch: 5| Step: 3
Training loss: 0.24095480144023895
Validation loss: 1.5880475710797053

Epoch: 5| Step: 4
Training loss: 0.2795173227787018
Validation loss: 1.6220917708130294

Epoch: 5| Step: 5
Training loss: 0.16388460993766785
Validation loss: 1.632870243441674

Epoch: 5| Step: 6
Training loss: 0.2239840030670166
Validation loss: 1.6316890998553204

Epoch: 5| Step: 7
Training loss: 0.1940070539712906
Validation loss: 1.6425933107253043

Epoch: 5| Step: 8
Training loss: 0.16875889897346497
Validation loss: 1.6255594043321506

Epoch: 5| Step: 9
Training loss: 0.28087300062179565
Validation loss: 1.619380468963295

Epoch: 5| Step: 10
Training loss: 0.18074677884578705
Validation loss: 1.6397592354846258

Epoch: 479| Step: 0
Training loss: 0.2247520238161087
Validation loss: 1.605609405425287

Epoch: 5| Step: 1
Training loss: 0.24647626280784607
Validation loss: 1.609715461730957

Epoch: 5| Step: 2
Training loss: 0.1994170844554901
Validation loss: 1.6449494733605334

Epoch: 5| Step: 3
Training loss: 0.146665558218956
Validation loss: 1.6553449797373947

Epoch: 5| Step: 4
Training loss: 0.19901171326637268
Validation loss: 1.6834906531918434

Epoch: 5| Step: 5
Training loss: 0.16461721062660217
Validation loss: 1.6813640158663514

Epoch: 5| Step: 6
Training loss: 0.2922583818435669
Validation loss: 1.6670831082969584

Epoch: 5| Step: 7
Training loss: 0.1614622175693512
Validation loss: 1.6468246124124015

Epoch: 5| Step: 8
Training loss: 0.27055373787879944
Validation loss: 1.6429245189953876

Epoch: 5| Step: 9
Training loss: 0.22990533709526062
Validation loss: 1.657786992288405

Epoch: 5| Step: 10
Training loss: 0.2123095840215683
Validation loss: 1.6220362224886495

Epoch: 480| Step: 0
Training loss: 0.15743227303028107
Validation loss: 1.5916204035923045

Epoch: 5| Step: 1
Training loss: 0.19688889384269714
Validation loss: 1.5982035616392731

Epoch: 5| Step: 2
Training loss: 0.20192542672157288
Validation loss: 1.5830116412972892

Epoch: 5| Step: 3
Training loss: 0.16844776272773743
Validation loss: 1.5891432031508415

Epoch: 5| Step: 4
Training loss: 0.25041982531547546
Validation loss: 1.5959040785348544

Epoch: 5| Step: 5
Training loss: 0.24358467757701874
Validation loss: 1.5903693834940593

Epoch: 5| Step: 6
Training loss: 0.2569113075733185
Validation loss: 1.595357883361078

Epoch: 5| Step: 7
Training loss: 0.1431887000799179
Validation loss: 1.5777085237605597

Epoch: 5| Step: 8
Training loss: 0.2044883519411087
Validation loss: 1.591954642726529

Epoch: 5| Step: 9
Training loss: 0.14001896977424622
Validation loss: 1.6044213835911085

Epoch: 5| Step: 10
Training loss: 0.1694520264863968
Validation loss: 1.5668403089687388

Epoch: 481| Step: 0
Training loss: 0.18222501873970032
Validation loss: 1.5517581034732122

Epoch: 5| Step: 1
Training loss: 0.20989160239696503
Validation loss: 1.5513468442424652

Epoch: 5| Step: 2
Training loss: 0.30931538343429565
Validation loss: 1.5762317462634015

Epoch: 5| Step: 3
Training loss: 0.11958149820566177
Validation loss: 1.6000599168962049

Epoch: 5| Step: 4
Training loss: 0.17910590767860413
Validation loss: 1.6151463536806003

Epoch: 5| Step: 5
Training loss: 0.19649310410022736
Validation loss: 1.658742243243802

Epoch: 5| Step: 6
Training loss: 0.24916784465312958
Validation loss: 1.6547432279074064

Epoch: 5| Step: 7
Training loss: 0.2908669412136078
Validation loss: 1.710634982714089

Epoch: 5| Step: 8
Training loss: 0.2575770616531372
Validation loss: 1.6874997026176863

Epoch: 5| Step: 9
Training loss: 0.1717005968093872
Validation loss: 1.6504429360871673

Epoch: 5| Step: 10
Training loss: 0.2693595290184021
Validation loss: 1.6285249610101022

Epoch: 482| Step: 0
Training loss: 0.22158269584178925
Validation loss: 1.6354494825486214

Epoch: 5| Step: 1
Training loss: 0.26003217697143555
Validation loss: 1.6305322147184802

Epoch: 5| Step: 2
Training loss: 0.3502437174320221
Validation loss: 1.6320570591957337

Epoch: 5| Step: 3
Training loss: 0.2561056613922119
Validation loss: 1.6285975069128058

Epoch: 5| Step: 4
Training loss: 0.182174414396286
Validation loss: 1.6531311581211705

Epoch: 5| Step: 5
Training loss: 0.292563259601593
Validation loss: 1.6607241489553963

Epoch: 5| Step: 6
Training loss: 0.2817937135696411
Validation loss: 1.6813076132087297

Epoch: 5| Step: 7
Training loss: 0.23595654964447021
Validation loss: 1.6571285775912705

Epoch: 5| Step: 8
Training loss: 0.1729639172554016
Validation loss: 1.6362766924724783

Epoch: 5| Step: 9
Training loss: 0.15379711985588074
Validation loss: 1.6241962243151922

Epoch: 5| Step: 10
Training loss: 0.322055846452713
Validation loss: 1.5917627567886024

Epoch: 483| Step: 0
Training loss: 0.20023488998413086
Validation loss: 1.6209120301790134

Epoch: 5| Step: 1
Training loss: 0.11713869869709015
Validation loss: 1.603533169274689

Epoch: 5| Step: 2
Training loss: 0.15138810873031616
Validation loss: 1.599583819348325

Epoch: 5| Step: 3
Training loss: 0.19729335606098175
Validation loss: 1.6039102128756944

Epoch: 5| Step: 4
Training loss: 0.15355077385902405
Validation loss: 1.6412768556225685

Epoch: 5| Step: 5
Training loss: 0.2410031259059906
Validation loss: 1.6258642596583213

Epoch: 5| Step: 6
Training loss: 0.20845694839954376
Validation loss: 1.6335918236804265

Epoch: 5| Step: 7
Training loss: 0.17797383666038513
Validation loss: 1.6237770600985455

Epoch: 5| Step: 8
Training loss: 0.24497444927692413
Validation loss: 1.601054665862873

Epoch: 5| Step: 9
Training loss: 0.24191316962242126
Validation loss: 1.6237753732230074

Epoch: 5| Step: 10
Training loss: 0.21848255395889282
Validation loss: 1.6222487316336682

Epoch: 484| Step: 0
Training loss: 0.16659550368785858
Validation loss: 1.6407989340443765

Epoch: 5| Step: 1
Training loss: 0.15405425429344177
Validation loss: 1.6431682776379328

Epoch: 5| Step: 2
Training loss: 0.16733887791633606
Validation loss: 1.6865141699391026

Epoch: 5| Step: 3
Training loss: 0.130045548081398
Validation loss: 1.6460401447870399

Epoch: 5| Step: 4
Training loss: 0.23792187869548798
Validation loss: 1.6526239110577492

Epoch: 5| Step: 5
Training loss: 0.21007516980171204
Validation loss: 1.6416271232789563

Epoch: 5| Step: 6
Training loss: 0.22037562727928162
Validation loss: 1.6525122324625652

Epoch: 5| Step: 7
Training loss: 0.32209596037864685
Validation loss: 1.6526601314544678

Epoch: 5| Step: 8
Training loss: 0.2005450278520584
Validation loss: 1.62069913905154

Epoch: 5| Step: 9
Training loss: 0.17475271224975586
Validation loss: 1.6110216738075338

Epoch: 5| Step: 10
Training loss: 0.24986031651496887
Validation loss: 1.5972438640491937

Epoch: 485| Step: 0
Training loss: 0.18459005653858185
Validation loss: 1.598452434744886

Epoch: 5| Step: 1
Training loss: 0.2163945734500885
Validation loss: 1.5904841903717286

Epoch: 5| Step: 2
Training loss: 0.1795995831489563
Validation loss: 1.5792398324576757

Epoch: 5| Step: 3
Training loss: 0.13423851132392883
Validation loss: 1.6062125454666794

Epoch: 5| Step: 4
Training loss: 0.2884278893470764
Validation loss: 1.5944136945150231

Epoch: 5| Step: 5
Training loss: 0.11578287929296494
Validation loss: 1.5901271271449264

Epoch: 5| Step: 6
Training loss: 0.1303289234638214
Validation loss: 1.621953587378225

Epoch: 5| Step: 7
Training loss: 0.2213602066040039
Validation loss: 1.6463011900583904

Epoch: 5| Step: 8
Training loss: 0.21961745619773865
Validation loss: 1.651342370176828

Epoch: 5| Step: 9
Training loss: 0.1410401165485382
Validation loss: 1.6448903513211075

Epoch: 5| Step: 10
Training loss: 0.19998487830162048
Validation loss: 1.6620858664153724

Epoch: 486| Step: 0
Training loss: 0.27338144183158875
Validation loss: 1.6584357676967498

Epoch: 5| Step: 1
Training loss: 0.23649081587791443
Validation loss: 1.616877950647826

Epoch: 5| Step: 2
Training loss: 0.2557204067707062
Validation loss: 1.6181928303933912

Epoch: 5| Step: 3
Training loss: 0.18043240904808044
Validation loss: 1.6063683173989738

Epoch: 5| Step: 4
Training loss: 0.2545836567878723
Validation loss: 1.5952931898896412

Epoch: 5| Step: 5
Training loss: 0.19319574534893036
Validation loss: 1.6020828062488186

Epoch: 5| Step: 6
Training loss: 0.3682038187980652
Validation loss: 1.5768981108101465

Epoch: 5| Step: 7
Training loss: 0.20176520943641663
Validation loss: 1.5675581424467024

Epoch: 5| Step: 8
Training loss: 0.23846492171287537
Validation loss: 1.565777648520726

Epoch: 5| Step: 9
Training loss: 0.13091237843036652
Validation loss: 1.5834336293640958

Epoch: 5| Step: 10
Training loss: 0.2441028356552124
Validation loss: 1.5977008701652609

Epoch: 487| Step: 0
Training loss: 0.22959046065807343
Validation loss: 1.614642830305202

Epoch: 5| Step: 1
Training loss: 0.23974378407001495
Validation loss: 1.6257314528188398

Epoch: 5| Step: 2
Training loss: 0.24184902012348175
Validation loss: 1.607203701490997

Epoch: 5| Step: 3
Training loss: 0.16766440868377686
Validation loss: 1.5856251633295448

Epoch: 5| Step: 4
Training loss: 0.21028366684913635
Validation loss: 1.5838506196134834

Epoch: 5| Step: 5
Training loss: 0.21640296280384064
Validation loss: 1.5857230937609108

Epoch: 5| Step: 6
Training loss: 0.22339001297950745
Validation loss: 1.5952785681652766

Epoch: 5| Step: 7
Training loss: 0.24985627830028534
Validation loss: 1.6018769843603975

Epoch: 5| Step: 8
Training loss: 0.3444545269012451
Validation loss: 1.6399645728449668

Epoch: 5| Step: 9
Training loss: 0.2293970137834549
Validation loss: 1.670941537426364

Epoch: 5| Step: 10
Training loss: 0.2183217704296112
Validation loss: 1.6431603252246816

Epoch: 488| Step: 0
Training loss: 0.1415112018585205
Validation loss: 1.6333284634415821

Epoch: 5| Step: 1
Training loss: 0.3066162168979645
Validation loss: 1.5971361847334011

Epoch: 5| Step: 2
Training loss: 0.1642121970653534
Validation loss: 1.5792924140089302

Epoch: 5| Step: 3
Training loss: 0.22973303496837616
Validation loss: 1.5781668027242024

Epoch: 5| Step: 4
Training loss: 0.24150808155536652
Validation loss: 1.5803022653825822

Epoch: 5| Step: 5
Training loss: 0.1563788801431656
Validation loss: 1.5744254037898073

Epoch: 5| Step: 6
Training loss: 0.21932780742645264
Validation loss: 1.5814944133963635

Epoch: 5| Step: 7
Training loss: 0.24017433822155
Validation loss: 1.6371107255258868

Epoch: 5| Step: 8
Training loss: 0.2081119567155838
Validation loss: 1.6018311003203034

Epoch: 5| Step: 9
Training loss: 0.20088747143745422
Validation loss: 1.5809130463548886

Epoch: 5| Step: 10
Training loss: 0.3547573387622833
Validation loss: 1.5962094850437616

Epoch: 489| Step: 0
Training loss: 0.3610239028930664
Validation loss: 1.569982349231679

Epoch: 5| Step: 1
Training loss: 0.24486558139324188
Validation loss: 1.564511340151551

Epoch: 5| Step: 2
Training loss: 0.15608425438404083
Validation loss: 1.5736485065952424

Epoch: 5| Step: 3
Training loss: 0.1733730286359787
Validation loss: 1.5757933496147074

Epoch: 5| Step: 4
Training loss: 0.21874785423278809
Validation loss: 1.5804884626019386

Epoch: 5| Step: 5
Training loss: 0.15000401437282562
Validation loss: 1.5811120335773756

Epoch: 5| Step: 6
Training loss: 0.17964550852775574
Validation loss: 1.6059094872525943

Epoch: 5| Step: 7
Training loss: 0.11739824712276459
Validation loss: 1.6240452822818552

Epoch: 5| Step: 8
Training loss: 0.15479084849357605
Validation loss: 1.6037991264814973

Epoch: 5| Step: 9
Training loss: 0.28155773878097534
Validation loss: 1.6410073170097925

Epoch: 5| Step: 10
Training loss: 0.13000361621379852
Validation loss: 1.6224422249742734

Epoch: 490| Step: 0
Training loss: 0.13573263585567474
Validation loss: 1.611897184002784

Epoch: 5| Step: 1
Training loss: 0.18132832646369934
Validation loss: 1.6179793624467746

Epoch: 5| Step: 2
Training loss: 0.16321170330047607
Validation loss: 1.5855893832381054

Epoch: 5| Step: 3
Training loss: 0.09139042347669601
Validation loss: 1.604010352524378

Epoch: 5| Step: 4
Training loss: 0.08320367336273193
Validation loss: 1.5964495392255886

Epoch: 5| Step: 5
Training loss: 0.18926385045051575
Validation loss: 1.54969193602121

Epoch: 5| Step: 6
Training loss: 0.22948727011680603
Validation loss: 1.578887777943765

Epoch: 5| Step: 7
Training loss: 0.24502094089984894
Validation loss: 1.5618687393844768

Epoch: 5| Step: 8
Training loss: 0.12042198330163956
Validation loss: 1.5564320029750947

Epoch: 5| Step: 9
Training loss: 0.1658840924501419
Validation loss: 1.534368673960368

Epoch: 5| Step: 10
Training loss: 0.14069709181785583
Validation loss: 1.5424526192808663

Epoch: 491| Step: 0
Training loss: 0.1952471137046814
Validation loss: 1.5598478881261681

Epoch: 5| Step: 1
Training loss: 0.14613988995552063
Validation loss: 1.5471426133186585

Epoch: 5| Step: 2
Training loss: 0.132109597325325
Validation loss: 1.5765008695663945

Epoch: 5| Step: 3
Training loss: 0.12302178144454956
Validation loss: 1.5938142653434508

Epoch: 5| Step: 4
Training loss: 0.2295318841934204
Validation loss: 1.6002697021730485

Epoch: 5| Step: 5
Training loss: 0.2026354819536209
Validation loss: 1.597895699162637

Epoch: 5| Step: 6
Training loss: 0.19479027390480042
Validation loss: 1.6312315912656887

Epoch: 5| Step: 7
Training loss: 0.19320018589496613
Validation loss: 1.604499178548013

Epoch: 5| Step: 8
Training loss: 0.1797257959842682
Validation loss: 1.5837519297035791

Epoch: 5| Step: 9
Training loss: 0.22988756000995636
Validation loss: 1.6010594560254006

Epoch: 5| Step: 10
Training loss: 0.10942623764276505
Validation loss: 1.5858816965933769

Epoch: 492| Step: 0
Training loss: 0.22895602881908417
Validation loss: 1.6178386108849638

Epoch: 5| Step: 1
Training loss: 0.20431947708129883
Validation loss: 1.644129753112793

Epoch: 5| Step: 2
Training loss: 0.2448221743106842
Validation loss: 1.659151219552563

Epoch: 5| Step: 3
Training loss: 0.17240796983242035
Validation loss: 1.689640393821142

Epoch: 5| Step: 4
Training loss: 0.24544663727283478
Validation loss: 1.6708729895212318

Epoch: 5| Step: 5
Training loss: 0.21214540302753448
Validation loss: 1.6714788098489084

Epoch: 5| Step: 6
Training loss: 0.19550059735774994
Validation loss: 1.6702852069690663

Epoch: 5| Step: 7
Training loss: 0.2099536657333374
Validation loss: 1.6341780154935774

Epoch: 5| Step: 8
Training loss: 0.18425855040550232
Validation loss: 1.6199845107652808

Epoch: 5| Step: 9
Training loss: 0.17644646763801575
Validation loss: 1.5874851762607534

Epoch: 5| Step: 10
Training loss: 0.08310074359178543
Validation loss: 1.609610334519417

Epoch: 493| Step: 0
Training loss: 0.22218027710914612
Validation loss: 1.6165466539321407

Epoch: 5| Step: 1
Training loss: 0.3210833966732025
Validation loss: 1.607377775253788

Epoch: 5| Step: 2
Training loss: 0.19814297556877136
Validation loss: 1.5881305548452562

Epoch: 5| Step: 3
Training loss: 0.207353875041008
Validation loss: 1.5820106908839235

Epoch: 5| Step: 4
Training loss: 0.15161029994487762
Validation loss: 1.5697057298434678

Epoch: 5| Step: 5
Training loss: 0.16893425583839417
Validation loss: 1.5603441179439586

Epoch: 5| Step: 6
Training loss: 0.19536253809928894
Validation loss: 1.5730668613987584

Epoch: 5| Step: 7
Training loss: 0.20489689707756042
Validation loss: 1.5966137647628784

Epoch: 5| Step: 8
Training loss: 0.23887300491333008
Validation loss: 1.598573798774391

Epoch: 5| Step: 9
Training loss: 0.12589898705482483
Validation loss: 1.5804377627629105

Epoch: 5| Step: 10
Training loss: 0.13276907801628113
Validation loss: 1.594423750395416

Epoch: 494| Step: 0
Training loss: 0.20981410145759583
Validation loss: 1.5828846257220033

Epoch: 5| Step: 1
Training loss: 0.12877053022384644
Validation loss: 1.5932207825363323

Epoch: 5| Step: 2
Training loss: 0.22309765219688416
Validation loss: 1.6079319433499408

Epoch: 5| Step: 3
Training loss: 0.2629387378692627
Validation loss: 1.6339380818028604

Epoch: 5| Step: 4
Training loss: 0.22556892037391663
Validation loss: 1.596664935029963

Epoch: 5| Step: 5
Training loss: 0.16403986513614655
Validation loss: 1.6052586506771784

Epoch: 5| Step: 6
Training loss: 0.14192810654640198
Validation loss: 1.5836423827755837

Epoch: 5| Step: 7
Training loss: 0.18226590752601624
Validation loss: 1.6088542374231483

Epoch: 5| Step: 8
Training loss: 0.19819435477256775
Validation loss: 1.6183079622125114

Epoch: 5| Step: 9
Training loss: 0.2123357057571411
Validation loss: 1.6020394230401644

Epoch: 5| Step: 10
Training loss: 0.2061527669429779
Validation loss: 1.579542931690011

Epoch: 495| Step: 0
Training loss: 0.1278541386127472
Validation loss: 1.5809959250111734

Epoch: 5| Step: 1
Training loss: 0.2262433022260666
Validation loss: 1.5483201075625677

Epoch: 5| Step: 2
Training loss: 0.1492469608783722
Validation loss: 1.5704276984737766

Epoch: 5| Step: 3
Training loss: 0.19205927848815918
Validation loss: 1.570821051956505

Epoch: 5| Step: 4
Training loss: 0.1692052185535431
Validation loss: 1.5739269961592972

Epoch: 5| Step: 5
Training loss: 0.2782805562019348
Validation loss: 1.568031007243741

Epoch: 5| Step: 6
Training loss: 0.20102539658546448
Validation loss: 1.5893961665450886

Epoch: 5| Step: 7
Training loss: 0.11487245559692383
Validation loss: 1.6007940192376413

Epoch: 5| Step: 8
Training loss: 0.16337823867797852
Validation loss: 1.6116074169835737

Epoch: 5| Step: 9
Training loss: 0.2163625955581665
Validation loss: 1.623339053123228

Epoch: 5| Step: 10
Training loss: 0.19570571184158325
Validation loss: 1.6358674738996772

Epoch: 496| Step: 0
Training loss: 0.18011870980262756
Validation loss: 1.6272530030178767

Epoch: 5| Step: 1
Training loss: 0.16774395108222961
Validation loss: 1.6459607821638866

Epoch: 5| Step: 2
Training loss: 0.21284842491149902
Validation loss: 1.643828861175045

Epoch: 5| Step: 3
Training loss: 0.24439552426338196
Validation loss: 1.6312171618143718

Epoch: 5| Step: 4
Training loss: 0.1818147748708725
Validation loss: 1.6554909752261253

Epoch: 5| Step: 5
Training loss: 0.1893918216228485
Validation loss: 1.6547711856903569

Epoch: 5| Step: 6
Training loss: 0.21083927154541016
Validation loss: 1.6166740155989123

Epoch: 5| Step: 7
Training loss: 0.22714939713478088
Validation loss: 1.6368028451037664

Epoch: 5| Step: 8
Training loss: 0.2106940746307373
Validation loss: 1.621439774831136

Epoch: 5| Step: 9
Training loss: 0.1518278867006302
Validation loss: 1.6116770813542027

Epoch: 5| Step: 10
Training loss: 0.14288079738616943
Validation loss: 1.6223493711922758

Epoch: 497| Step: 0
Training loss: 0.1800159513950348
Validation loss: 1.609852622914058

Epoch: 5| Step: 1
Training loss: 0.08562584966421127
Validation loss: 1.6016538848159134

Epoch: 5| Step: 2
Training loss: 0.15720954537391663
Validation loss: 1.5846901709033596

Epoch: 5| Step: 3
Training loss: 0.13706627488136292
Validation loss: 1.5695734280411915

Epoch: 5| Step: 4
Training loss: 0.17848511040210724
Validation loss: 1.5891397050631944

Epoch: 5| Step: 5
Training loss: 0.13847976922988892
Validation loss: 1.5819036755510556

Epoch: 5| Step: 6
Training loss: 0.1487884670495987
Validation loss: 1.5847090931348904

Epoch: 5| Step: 7
Training loss: 0.1722729504108429
Validation loss: 1.6049495512439358

Epoch: 5| Step: 8
Training loss: 0.16384534537792206
Validation loss: 1.5967230707086542

Epoch: 5| Step: 9
Training loss: 0.13029377162456512
Validation loss: 1.6023871116740729

Epoch: 5| Step: 10
Training loss: 0.25168871879577637
Validation loss: 1.597160885410924

Epoch: 498| Step: 0
Training loss: 0.21926434338092804
Validation loss: 1.5993588765462239

Epoch: 5| Step: 1
Training loss: 0.16683058440685272
Validation loss: 1.5874391473749632

Epoch: 5| Step: 2
Training loss: 0.18256567418575287
Validation loss: 1.5748689200288506

Epoch: 5| Step: 3
Training loss: 0.17961105704307556
Validation loss: 1.5645233123533187

Epoch: 5| Step: 4
Training loss: 0.18477533757686615
Validation loss: 1.6009873228688394

Epoch: 5| Step: 5
Training loss: 0.19014421105384827
Validation loss: 1.589041345862932

Epoch: 5| Step: 6
Training loss: 0.15600240230560303
Validation loss: 1.6276320129312494

Epoch: 5| Step: 7
Training loss: 0.1652611494064331
Validation loss: 1.6035826129298056

Epoch: 5| Step: 8
Training loss: 0.14932502806186676
Validation loss: 1.6001139763862855

Epoch: 5| Step: 9
Training loss: 0.14415423572063446
Validation loss: 1.5668882349485993

Epoch: 5| Step: 10
Training loss: 0.1368507444858551
Validation loss: 1.5793090481911936

Epoch: 499| Step: 0
Training loss: 0.13217709958553314
Validation loss: 1.590275537583136

Epoch: 5| Step: 1
Training loss: 0.11396624892950058
Validation loss: 1.590235003861048

Epoch: 5| Step: 2
Training loss: 0.24228966236114502
Validation loss: 1.5813442776280064

Epoch: 5| Step: 3
Training loss: 0.24738498032093048
Validation loss: 1.600321917123692

Epoch: 5| Step: 4
Training loss: 0.2521893084049225
Validation loss: 1.5990657242395545

Epoch: 5| Step: 5
Training loss: 0.1248336210846901
Validation loss: 1.55952702799151

Epoch: 5| Step: 6
Training loss: 0.1473253071308136
Validation loss: 1.565437965495612

Epoch: 5| Step: 7
Training loss: 0.26569274067878723
Validation loss: 1.5686693729892853

Epoch: 5| Step: 8
Training loss: 0.15068641304969788
Validation loss: 1.574077695928594

Epoch: 5| Step: 9
Training loss: 0.11437247693538666
Validation loss: 1.611549098004577

Epoch: 5| Step: 10
Training loss: 0.17417725920677185
Validation loss: 1.58386819465186

Epoch: 500| Step: 0
Training loss: 0.16517819464206696
Validation loss: 1.577914539203849

Epoch: 5| Step: 1
Training loss: 0.16788740456104279
Validation loss: 1.5920482502188733

Epoch: 5| Step: 2
Training loss: 0.15115444362163544
Validation loss: 1.6038200637345672

Epoch: 5| Step: 3
Training loss: 0.1280389130115509
Validation loss: 1.5820331483758905

Epoch: 5| Step: 4
Training loss: 0.18170307576656342
Validation loss: 1.5730862579038065

Epoch: 5| Step: 5
Training loss: 0.17095616459846497
Validation loss: 1.5733973313403387

Epoch: 5| Step: 6
Training loss: 0.14865413308143616
Validation loss: 1.5427718482991701

Epoch: 5| Step: 7
Training loss: 0.22572460770606995
Validation loss: 1.5762909266256517

Epoch: 5| Step: 8
Training loss: 0.13956023752689362
Validation loss: 1.5538491408030193

Epoch: 5| Step: 9
Training loss: 0.15282347798347473
Validation loss: 1.5291589370337866

Epoch: 5| Step: 10
Training loss: 0.14302660524845123
Validation loss: 1.549298115955886

Epoch: 501| Step: 0
Training loss: 0.20073500275611877
Validation loss: 1.5461126565933228

Epoch: 5| Step: 1
Training loss: 0.1178094744682312
Validation loss: 1.5285014990837342

Epoch: 5| Step: 2
Training loss: 0.16784678399562836
Validation loss: 1.5590847653727378

Epoch: 5| Step: 3
Training loss: 0.17989227175712585
Validation loss: 1.556455857010298

Epoch: 5| Step: 4
Training loss: 0.2313728630542755
Validation loss: 1.5476730920935189

Epoch: 5| Step: 5
Training loss: 0.08430840075016022
Validation loss: 1.542778306109931

Epoch: 5| Step: 6
Training loss: 0.12955451011657715
Validation loss: 1.5692499183839368

Epoch: 5| Step: 7
Training loss: 0.18454210460186005
Validation loss: 1.5568346797779042

Epoch: 5| Step: 8
Training loss: 0.11134932190179825
Validation loss: 1.5171928982580862

Epoch: 5| Step: 9
Training loss: 0.1811404675245285
Validation loss: 1.580304882859671

Epoch: 5| Step: 10
Training loss: 0.1577657014131546
Validation loss: 1.5577417406984555

Epoch: 502| Step: 0
Training loss: 0.16400864720344543
Validation loss: 1.5586515908600183

Epoch: 5| Step: 1
Training loss: 0.13804179430007935
Validation loss: 1.5463654213054205

Epoch: 5| Step: 2
Training loss: 0.16114768385887146
Validation loss: 1.5543525013872372

Epoch: 5| Step: 3
Training loss: 0.18906843662261963
Validation loss: 1.5610673671127648

Epoch: 5| Step: 4
Training loss: 0.1322248876094818
Validation loss: 1.5734339606377385

Epoch: 5| Step: 5
Training loss: 0.1771898865699768
Validation loss: 1.5745159656770769

Epoch: 5| Step: 6
Training loss: 0.17554141581058502
Validation loss: 1.5822578527594124

Epoch: 5| Step: 7
Training loss: 0.18136849999427795
Validation loss: 1.5780538435905211

Epoch: 5| Step: 8
Training loss: 0.16294744610786438
Validation loss: 1.605937724472374

Epoch: 5| Step: 9
Training loss: 0.19375109672546387
Validation loss: 1.6251197271449591

Epoch: 5| Step: 10
Training loss: 0.11353545635938644
Validation loss: 1.6143098415866974

Epoch: 503| Step: 0
Training loss: 0.09349002689123154
Validation loss: 1.6071265628260951

Epoch: 5| Step: 1
Training loss: 0.1726965606212616
Validation loss: 1.5834096663741655

Epoch: 5| Step: 2
Training loss: 0.170553520321846
Validation loss: 1.5732820751846477

Epoch: 5| Step: 3
Training loss: 0.14061638712882996
Validation loss: 1.5543544138631513

Epoch: 5| Step: 4
Training loss: 0.11549464613199234
Validation loss: 1.5474166344570857

Epoch: 5| Step: 5
Training loss: 0.15333198010921478
Validation loss: 1.5228515812145766

Epoch: 5| Step: 6
Training loss: 0.17335765063762665
Validation loss: 1.547804287684861

Epoch: 5| Step: 7
Training loss: 0.14413732290267944
Validation loss: 1.5510394060483543

Epoch: 5| Step: 8
Training loss: 0.09958171844482422
Validation loss: 1.5704475705341627

Epoch: 5| Step: 9
Training loss: 0.27553391456604004
Validation loss: 1.5310811432459022

Epoch: 5| Step: 10
Training loss: 0.07699685543775558
Validation loss: 1.5484437955323087

Epoch: 504| Step: 0
Training loss: 0.15573513507843018
Validation loss: 1.5381272838961693

Epoch: 5| Step: 1
Training loss: 0.12171001732349396
Validation loss: 1.544975826817174

Epoch: 5| Step: 2
Training loss: 0.09546768665313721
Validation loss: 1.5357477152219383

Epoch: 5| Step: 3
Training loss: 0.13935013115406036
Validation loss: 1.5708023976254206

Epoch: 5| Step: 4
Training loss: 0.20359523594379425
Validation loss: 1.5456946383240402

Epoch: 5| Step: 5
Training loss: 0.1882287561893463
Validation loss: 1.5728062711736208

Epoch: 5| Step: 6
Training loss: 0.23207934200763702
Validation loss: 1.6044407749688754

Epoch: 5| Step: 7
Training loss: 0.21096298098564148
Validation loss: 1.6449689352384178

Epoch: 5| Step: 8
Training loss: 0.07709699869155884
Validation loss: 1.603590424342822

Epoch: 5| Step: 9
Training loss: 0.10310514271259308
Validation loss: 1.5901342348385883

Epoch: 5| Step: 10
Training loss: 0.19586771726608276
Validation loss: 1.5884163315578173

Epoch: 505| Step: 0
Training loss: 0.10601802170276642
Validation loss: 1.5721022352095573

Epoch: 5| Step: 1
Training loss: 0.11478954553604126
Validation loss: 1.5492591127272575

Epoch: 5| Step: 2
Training loss: 0.10745090246200562
Validation loss: 1.5259312429735739

Epoch: 5| Step: 3
Training loss: 0.21829453110694885
Validation loss: 1.544498961458924

Epoch: 5| Step: 4
Training loss: 0.21527723968029022
Validation loss: 1.5247792274721208

Epoch: 5| Step: 5
Training loss: 0.11933448165655136
Validation loss: 1.5347198273545952

Epoch: 5| Step: 6
Training loss: 0.15438421070575714
Validation loss: 1.5635557879683792

Epoch: 5| Step: 7
Training loss: 0.15952453017234802
Validation loss: 1.5632985009942004

Epoch: 5| Step: 8
Training loss: 0.25134164094924927
Validation loss: 1.5342893497918242

Epoch: 5| Step: 9
Training loss: 0.11784795671701431
Validation loss: 1.5537050026719288

Epoch: 5| Step: 10
Training loss: 0.20870894193649292
Validation loss: 1.5461331029092111

Epoch: 506| Step: 0
Training loss: 0.1822776049375534
Validation loss: 1.5512437000069568

Epoch: 5| Step: 1
Training loss: 0.1442783772945404
Validation loss: 1.53908283223388

Epoch: 5| Step: 2
Training loss: 0.09876056760549545
Validation loss: 1.548276218034888

Epoch: 5| Step: 3
Training loss: 0.10962045192718506
Validation loss: 1.5596850418275403

Epoch: 5| Step: 4
Training loss: 0.22722065448760986
Validation loss: 1.5951796116367463

Epoch: 5| Step: 5
Training loss: 0.1710263043642044
Validation loss: 1.5616607012287262

Epoch: 5| Step: 6
Training loss: 0.159738689661026
Validation loss: 1.607052218529486

Epoch: 5| Step: 7
Training loss: 0.16926802694797516
Validation loss: 1.6050966247435539

Epoch: 5| Step: 8
Training loss: 0.21390457451343536
Validation loss: 1.6054934634957263

Epoch: 5| Step: 9
Training loss: 0.15914718806743622
Validation loss: 1.59929528415844

Epoch: 5| Step: 10
Training loss: 0.14652583003044128
Validation loss: 1.6156573641684748

Epoch: 507| Step: 0
Training loss: 0.1279938519001007
Validation loss: 1.5766208287208312

Epoch: 5| Step: 1
Training loss: 0.13198581337928772
Validation loss: 1.573179506486462

Epoch: 5| Step: 2
Training loss: 0.09781523793935776
Validation loss: 1.5553719112949986

Epoch: 5| Step: 3
Training loss: 0.18035264313220978
Validation loss: 1.575601666204391

Epoch: 5| Step: 4
Training loss: 0.24256937205791473
Validation loss: 1.5639285310622184

Epoch: 5| Step: 5
Training loss: 0.11636857688426971
Validation loss: 1.578829200037064

Epoch: 5| Step: 6
Training loss: 0.1752026230096817
Validation loss: 1.570687711238861

Epoch: 5| Step: 7
Training loss: 0.14340615272521973
Validation loss: 1.5793095545102191

Epoch: 5| Step: 8
Training loss: 0.14388667047023773
Validation loss: 1.5996709972299554

Epoch: 5| Step: 9
Training loss: 0.17927971482276917
Validation loss: 1.5988277113565834

Epoch: 5| Step: 10
Training loss: 0.15500538051128387
Validation loss: 1.6059500312292447

Epoch: 508| Step: 0
Training loss: 0.13469628989696503
Validation loss: 1.6009192018098728

Epoch: 5| Step: 1
Training loss: 0.2309318482875824
Validation loss: 1.6199409384881296

Epoch: 5| Step: 2
Training loss: 0.10578414052724838
Validation loss: 1.588545145527009

Epoch: 5| Step: 3
Training loss: 0.17244289815425873
Validation loss: 1.6117513589961554

Epoch: 5| Step: 4
Training loss: 0.1345071792602539
Validation loss: 1.5978235083241616

Epoch: 5| Step: 5
Training loss: 0.17248864471912384
Validation loss: 1.5368120913864465

Epoch: 5| Step: 6
Training loss: 0.13948802649974823
Validation loss: 1.58125388878648

Epoch: 5| Step: 7
Training loss: 0.19745251536369324
Validation loss: 1.5618925190741015

Epoch: 5| Step: 8
Training loss: 0.10715927183628082
Validation loss: 1.5634804643610472

Epoch: 5| Step: 9
Training loss: 0.19297780096530914
Validation loss: 1.5587814597673313

Epoch: 5| Step: 10
Training loss: 0.12325549125671387
Validation loss: 1.5730986582335604

Epoch: 509| Step: 0
Training loss: 0.2149108350276947
Validation loss: 1.5571516752243042

Epoch: 5| Step: 1
Training loss: 0.1487882435321808
Validation loss: 1.5566475147842078

Epoch: 5| Step: 2
Training loss: 0.0868743434548378
Validation loss: 1.560523360006271

Epoch: 5| Step: 3
Training loss: 0.13996143639087677
Validation loss: 1.554025291114725

Epoch: 5| Step: 4
Training loss: 0.15490587055683136
Validation loss: 1.5846726984106085

Epoch: 5| Step: 5
Training loss: 0.15239812433719635
Validation loss: 1.5876096448590677

Epoch: 5| Step: 6
Training loss: 0.12613722681999207
Validation loss: 1.6096760752380534

Epoch: 5| Step: 7
Training loss: 0.18999016284942627
Validation loss: 1.6232609466839862

Epoch: 5| Step: 8
Training loss: 0.14365363121032715
Validation loss: 1.6000289122263591

Epoch: 5| Step: 9
Training loss: 0.15617460012435913
Validation loss: 1.5857336969785794

Epoch: 5| Step: 10
Training loss: 0.13010503351688385
Validation loss: 1.5904657610001103

Epoch: 510| Step: 0
Training loss: 0.1571430116891861
Validation loss: 1.573945245435161

Epoch: 5| Step: 1
Training loss: 0.3032858371734619
Validation loss: 1.5745581362837104

Epoch: 5| Step: 2
Training loss: 0.1457909345626831
Validation loss: 1.5662326274379608

Epoch: 5| Step: 3
Training loss: 0.07799936085939407
Validation loss: 1.5851750181567283

Epoch: 5| Step: 4
Training loss: 0.20988404750823975
Validation loss: 1.5462112734394688

Epoch: 5| Step: 5
Training loss: 0.07603292912244797
Validation loss: 1.568207678615406

Epoch: 5| Step: 6
Training loss: 0.1234988421201706
Validation loss: 1.605565018551324

Epoch: 5| Step: 7
Training loss: 0.13124628365039825
Validation loss: 1.5734415208139727

Epoch: 5| Step: 8
Training loss: 0.1965283900499344
Validation loss: 1.5646749504150883

Epoch: 5| Step: 9
Training loss: 0.09137307852506638
Validation loss: 1.5868159814547467

Epoch: 5| Step: 10
Training loss: 0.10071057081222534
Validation loss: 1.5538806992192422

Epoch: 511| Step: 0
Training loss: 0.1133364886045456
Validation loss: 1.5597784878105245

Epoch: 5| Step: 1
Training loss: 0.11417889595031738
Validation loss: 1.5528782593306674

Epoch: 5| Step: 2
Training loss: 0.18456587195396423
Validation loss: 1.551661245284542

Epoch: 5| Step: 3
Training loss: 0.2202608585357666
Validation loss: 1.5412090747587142

Epoch: 5| Step: 4
Training loss: 0.10248677432537079
Validation loss: 1.527551411300577

Epoch: 5| Step: 5
Training loss: 0.15819036960601807
Validation loss: 1.5435681509715256

Epoch: 5| Step: 6
Training loss: 0.08777247369289398
Validation loss: 1.5600133749746508

Epoch: 5| Step: 7
Training loss: 0.2197386920452118
Validation loss: 1.551946916887837

Epoch: 5| Step: 8
Training loss: 0.07191921770572662
Validation loss: 1.5518095057497743

Epoch: 5| Step: 9
Training loss: 0.09878943860530853
Validation loss: 1.5671335676664948

Epoch: 5| Step: 10
Training loss: 0.12730613350868225
Validation loss: 1.5675406571357482

Epoch: 512| Step: 0
Training loss: 0.08025183528661728
Validation loss: 1.5764826241359915

Epoch: 5| Step: 1
Training loss: 0.07472680509090424
Validation loss: 1.5695419997297309

Epoch: 5| Step: 2
Training loss: 0.15405979752540588
Validation loss: 1.5810935753647999

Epoch: 5| Step: 3
Training loss: 0.09304243326187134
Validation loss: 1.5898053440996396

Epoch: 5| Step: 4
Training loss: 0.1283312737941742
Validation loss: 1.5978922087659118

Epoch: 5| Step: 5
Training loss: 0.15742866694927216
Validation loss: 1.6046313188409294

Epoch: 5| Step: 6
Training loss: 0.1310567855834961
Validation loss: 1.586554681101153

Epoch: 5| Step: 7
Training loss: 0.15984909236431122
Validation loss: 1.5996039849455639

Epoch: 5| Step: 8
Training loss: 0.1171993762254715
Validation loss: 1.5825025663580945

Epoch: 5| Step: 9
Training loss: 0.25158193707466125
Validation loss: 1.580230898754571

Epoch: 5| Step: 10
Training loss: 0.10568290948867798
Validation loss: 1.5800076069370392

Epoch: 513| Step: 0
Training loss: 0.11218501627445221
Validation loss: 1.567021353911328

Epoch: 5| Step: 1
Training loss: 0.14234447479248047
Validation loss: 1.5809862030449735

Epoch: 5| Step: 2
Training loss: 0.1352616548538208
Validation loss: 1.5732060401670394

Epoch: 5| Step: 3
Training loss: 0.1109437495470047
Validation loss: 1.579438159542699

Epoch: 5| Step: 4
Training loss: 0.1725253015756607
Validation loss: 1.5767741023853261

Epoch: 5| Step: 5
Training loss: 0.22414083778858185
Validation loss: 1.5819772936964547

Epoch: 5| Step: 6
Training loss: 0.16337433457374573
Validation loss: 1.5863384405771892

Epoch: 5| Step: 7
Training loss: 0.2234373539686203
Validation loss: 1.6243342917452577

Epoch: 5| Step: 8
Training loss: 0.1297469586133957
Validation loss: 1.6043962893947479

Epoch: 5| Step: 9
Training loss: 0.16377688944339752
Validation loss: 1.5984722209233109

Epoch: 5| Step: 10
Training loss: 0.16766588389873505
Validation loss: 1.605396052842499

Epoch: 514| Step: 0
Training loss: 0.1590074747800827
Validation loss: 1.602516766517393

Epoch: 5| Step: 1
Training loss: 0.07408925145864487
Validation loss: 1.5821462587643695

Epoch: 5| Step: 2
Training loss: 0.11647675931453705
Validation loss: 1.5938734687784666

Epoch: 5| Step: 3
Training loss: 0.137909397482872
Validation loss: 1.5936728382623324

Epoch: 5| Step: 4
Training loss: 0.12443938106298447
Validation loss: 1.5665286587130638

Epoch: 5| Step: 5
Training loss: 0.1259693056344986
Validation loss: 1.544255345098434

Epoch: 5| Step: 6
Training loss: 0.10337364673614502
Validation loss: 1.5422281885659823

Epoch: 5| Step: 7
Training loss: 0.20679578185081482
Validation loss: 1.5645769808882026

Epoch: 5| Step: 8
Training loss: 0.27155348658561707
Validation loss: 1.5876867463511806

Epoch: 5| Step: 9
Training loss: 0.0941343754529953
Validation loss: 1.5908718980768675

Epoch: 5| Step: 10
Training loss: 0.17875060439109802
Validation loss: 1.5697623299014183

Epoch: 515| Step: 0
Training loss: 0.20366270840168
Validation loss: 1.5716434204450218

Epoch: 5| Step: 1
Training loss: 0.0940924659371376
Validation loss: 1.5559891436689643

Epoch: 5| Step: 2
Training loss: 0.10332024097442627
Validation loss: 1.5714397725238596

Epoch: 5| Step: 3
Training loss: 0.12167684733867645
Validation loss: 1.572869759733959

Epoch: 5| Step: 4
Training loss: 0.11639682203531265
Validation loss: 1.5917692235721055

Epoch: 5| Step: 5
Training loss: 0.1439795196056366
Validation loss: 1.5835443401849398

Epoch: 5| Step: 6
Training loss: 0.1309979408979416
Validation loss: 1.6405597361185218

Epoch: 5| Step: 7
Training loss: 0.1248684898018837
Validation loss: 1.6062440852965079

Epoch: 5| Step: 8
Training loss: 0.13692355155944824
Validation loss: 1.613867445658612

Epoch: 5| Step: 9
Training loss: 0.15798841416835785
Validation loss: 1.6107927753079323

Epoch: 5| Step: 10
Training loss: 0.17202889919281006
Validation loss: 1.5920567333057363

Epoch: 516| Step: 0
Training loss: 0.10633935779333115
Validation loss: 1.5944302876790364

Epoch: 5| Step: 1
Training loss: 0.13445445895195007
Validation loss: 1.5561272687809442

Epoch: 5| Step: 2
Training loss: 0.22317178547382355
Validation loss: 1.5755952699210054

Epoch: 5| Step: 3
Training loss: 0.15970996022224426
Validation loss: 1.5711894394249044

Epoch: 5| Step: 4
Training loss: 0.2839473783969879
Validation loss: 1.5617246063806678

Epoch: 5| Step: 5
Training loss: 0.17672555148601532
Validation loss: 1.5919090817051549

Epoch: 5| Step: 6
Training loss: 0.10365284979343414
Validation loss: 1.596867258830737

Epoch: 5| Step: 7
Training loss: 0.06992573291063309
Validation loss: 1.6265844786038963

Epoch: 5| Step: 8
Training loss: 0.17080149054527283
Validation loss: 1.618473974607324

Epoch: 5| Step: 9
Training loss: 0.11382763087749481
Validation loss: 1.637580689563546

Epoch: 5| Step: 10
Training loss: 0.08933164924383163
Validation loss: 1.6444135763311898

Epoch: 517| Step: 0
Training loss: 0.11640288680791855
Validation loss: 1.6128327577344832

Epoch: 5| Step: 1
Training loss: 0.13650526106357574
Validation loss: 1.6046118140220642

Epoch: 5| Step: 2
Training loss: 0.2007749378681183
Validation loss: 1.6167034051751579

Epoch: 5| Step: 3
Training loss: 0.21813614666461945
Validation loss: 1.6346492293060466

Epoch: 5| Step: 4
Training loss: 0.11850064992904663
Validation loss: 1.6134548725620392

Epoch: 5| Step: 5
Training loss: 0.16439290344715118
Validation loss: 1.5712055852336269

Epoch: 5| Step: 6
Training loss: 0.13701434433460236
Validation loss: 1.59720383151885

Epoch: 5| Step: 7
Training loss: 0.16653671860694885
Validation loss: 1.6009406684547343

Epoch: 5| Step: 8
Training loss: 0.1489226520061493
Validation loss: 1.5773003690986223

Epoch: 5| Step: 9
Training loss: 0.14021944999694824
Validation loss: 1.5886203973524031

Epoch: 5| Step: 10
Training loss: 0.10935185104608536
Validation loss: 1.5976312032309912

Epoch: 518| Step: 0
Training loss: 0.14937624335289001
Validation loss: 1.59781014919281

Epoch: 5| Step: 1
Training loss: 0.08473151922225952
Validation loss: 1.6038940286123624

Epoch: 5| Step: 2
Training loss: 0.17348171770572662
Validation loss: 1.581548180631412

Epoch: 5| Step: 3
Training loss: 0.13583001494407654
Validation loss: 1.5917150974273682

Epoch: 5| Step: 4
Training loss: 0.1838572472333908
Validation loss: 1.5432177128330353

Epoch: 5| Step: 5
Training loss: 0.1689368039369583
Validation loss: 1.5618105716602777

Epoch: 5| Step: 6
Training loss: 0.19160184264183044
Validation loss: 1.563270443229265

Epoch: 5| Step: 7
Training loss: 0.2112528383731842
Validation loss: 1.561959232053449

Epoch: 5| Step: 8
Training loss: 0.0994851142168045
Validation loss: 1.5792455801399805

Epoch: 5| Step: 9
Training loss: 0.19460490345954895
Validation loss: 1.578881299623879

Epoch: 5| Step: 10
Training loss: 0.13858743011951447
Validation loss: 1.613599257443541

Epoch: 519| Step: 0
Training loss: 0.19773142039775848
Validation loss: 1.6086809519798524

Epoch: 5| Step: 1
Training loss: 0.16869965195655823
Validation loss: 1.6017807581091439

Epoch: 5| Step: 2
Training loss: 0.19937925040721893
Validation loss: 1.5525220376189037

Epoch: 5| Step: 3
Training loss: 0.11103196442127228
Validation loss: 1.5420625799445695

Epoch: 5| Step: 4
Training loss: 0.08904515206813812
Validation loss: 1.519624929274282

Epoch: 5| Step: 5
Training loss: 0.09144781529903412
Validation loss: 1.5612572482837144

Epoch: 5| Step: 6
Training loss: 0.09780928492546082
Validation loss: 1.5478631757920789

Epoch: 5| Step: 7
Training loss: 0.12492859363555908
Validation loss: 1.5723459079701414

Epoch: 5| Step: 8
Training loss: 0.14631102979183197
Validation loss: 1.536225644491052

Epoch: 5| Step: 9
Training loss: 0.19609470665454865
Validation loss: 1.558725328855617

Epoch: 5| Step: 10
Training loss: 0.17323561012744904
Validation loss: 1.5665459799510177

Epoch: 520| Step: 0
Training loss: 0.09415832906961441
Validation loss: 1.5714355623850258

Epoch: 5| Step: 1
Training loss: 0.139543816447258
Validation loss: 1.5415073787012408

Epoch: 5| Step: 2
Training loss: 0.12812970578670502
Validation loss: 1.5487971972393733

Epoch: 5| Step: 3
Training loss: 0.14333847165107727
Validation loss: 1.5779585492226385

Epoch: 5| Step: 4
Training loss: 0.15057100355625153
Validation loss: 1.5611025389804636

Epoch: 5| Step: 5
Training loss: 0.1190752238035202
Validation loss: 1.5723297083249657

Epoch: 5| Step: 6
Training loss: 0.2386583834886551
Validation loss: 1.5541656530031593

Epoch: 5| Step: 7
Training loss: 0.18395209312438965
Validation loss: 1.5528403943584812

Epoch: 5| Step: 8
Training loss: 0.11944010108709335
Validation loss: 1.5543544843632688

Epoch: 5| Step: 9
Training loss: 0.10033166408538818
Validation loss: 1.5525646876263361

Epoch: 5| Step: 10
Training loss: 0.12112826108932495
Validation loss: 1.5898347926396195

Epoch: 521| Step: 0
Training loss: 0.1826017200946808
Validation loss: 1.610439879919893

Epoch: 5| Step: 1
Training loss: 0.15998415648937225
Validation loss: 1.619622358711817

Epoch: 5| Step: 2
Training loss: 0.19111566245555878
Validation loss: 1.6018753269667267

Epoch: 5| Step: 3
Training loss: 0.13045471906661987
Validation loss: 1.5856104820005354

Epoch: 5| Step: 4
Training loss: 0.13152332603931427
Validation loss: 1.582143125995513

Epoch: 5| Step: 5
Training loss: 0.11731195449829102
Validation loss: 1.567484212178056

Epoch: 5| Step: 6
Training loss: 0.12134087085723877
Validation loss: 1.5699448739328692

Epoch: 5| Step: 7
Training loss: 0.14886605739593506
Validation loss: 1.5473867577891196

Epoch: 5| Step: 8
Training loss: 0.10294141620397568
Validation loss: 1.553840750007219

Epoch: 5| Step: 9
Training loss: 0.14371664822101593
Validation loss: 1.556951181862944

Epoch: 5| Step: 10
Training loss: 0.15435843169689178
Validation loss: 1.5899361487357848

Epoch: 522| Step: 0
Training loss: 0.1172468438744545
Validation loss: 1.5599627494812012

Epoch: 5| Step: 1
Training loss: 0.09086798131465912
Validation loss: 1.562815345743651

Epoch: 5| Step: 2
Training loss: 0.1323220133781433
Validation loss: 1.5617767623675767

Epoch: 5| Step: 3
Training loss: 0.06849972903728485
Validation loss: 1.5701378083998156

Epoch: 5| Step: 4
Training loss: 0.08568533509969711
Validation loss: 1.5757029902550481

Epoch: 5| Step: 5
Training loss: 0.20702150464057922
Validation loss: 1.5512498886354509

Epoch: 5| Step: 6
Training loss: 0.10703913122415543
Validation loss: 1.540385728241295

Epoch: 5| Step: 7
Training loss: 0.12623628973960876
Validation loss: 1.5664762232893257

Epoch: 5| Step: 8
Training loss: 0.1798548698425293
Validation loss: 1.5642910542026642

Epoch: 5| Step: 9
Training loss: 0.1461189240217209
Validation loss: 1.5687446286601405

Epoch: 5| Step: 10
Training loss: 0.07112178951501846
Validation loss: 1.5463850344381025

Epoch: 523| Step: 0
Training loss: 0.12406916916370392
Validation loss: 1.555772614735429

Epoch: 5| Step: 1
Training loss: 0.08126197755336761
Validation loss: 1.5650846906887588

Epoch: 5| Step: 2
Training loss: 0.073142409324646
Validation loss: 1.568538055625013

Epoch: 5| Step: 3
Training loss: 0.12984251976013184
Validation loss: 1.5383992066947363

Epoch: 5| Step: 4
Training loss: 0.09421112388372421
Validation loss: 1.5522596823271884

Epoch: 5| Step: 5
Training loss: 0.09911997616291046
Validation loss: 1.5496598238586097

Epoch: 5| Step: 6
Training loss: 0.21372108161449432
Validation loss: 1.5255463238685363

Epoch: 5| Step: 7
Training loss: 0.11935676634311676
Validation loss: 1.522032025039837

Epoch: 5| Step: 8
Training loss: 0.18254975974559784
Validation loss: 1.545014678791005

Epoch: 5| Step: 9
Training loss: 0.07172087579965591
Validation loss: 1.5378408880643948

Epoch: 5| Step: 10
Training loss: 0.19015832245349884
Validation loss: 1.5445886094083068

Epoch: 524| Step: 0
Training loss: 0.08864030241966248
Validation loss: 1.565903845653739

Epoch: 5| Step: 1
Training loss: 0.11610953509807587
Validation loss: 1.541452718037431

Epoch: 5| Step: 2
Training loss: 0.08909699320793152
Validation loss: 1.567251233644383

Epoch: 5| Step: 3
Training loss: 0.08894602209329605
Validation loss: 1.5702827079321748

Epoch: 5| Step: 4
Training loss: 0.15143364667892456
Validation loss: 1.5590642190748645

Epoch: 5| Step: 5
Training loss: 0.08022995293140411
Validation loss: 1.5808398249328777

Epoch: 5| Step: 6
Training loss: 0.09437962621450424
Validation loss: 1.5844707604377501

Epoch: 5| Step: 7
Training loss: 0.16754642128944397
Validation loss: 1.5718471234844578

Epoch: 5| Step: 8
Training loss: 0.07686245441436768
Validation loss: 1.5610208267806678

Epoch: 5| Step: 9
Training loss: 0.18484020233154297
Validation loss: 1.5992045325617636

Epoch: 5| Step: 10
Training loss: 0.12771673500537872
Validation loss: 1.577907249491702

Epoch: 525| Step: 0
Training loss: 0.11697746813297272
Validation loss: 1.5565120161220591

Epoch: 5| Step: 1
Training loss: 0.12726335227489471
Validation loss: 1.5854419418560561

Epoch: 5| Step: 2
Training loss: 0.07216884940862656
Validation loss: 1.550148299945298

Epoch: 5| Step: 3
Training loss: 0.19391779601573944
Validation loss: 1.579142939659857

Epoch: 5| Step: 4
Training loss: 0.13645039498806
Validation loss: 1.5759105323463358

Epoch: 5| Step: 5
Training loss: 0.17983639240264893
Validation loss: 1.580514572640901

Epoch: 5| Step: 6
Training loss: 0.15959489345550537
Validation loss: 1.575791253838488

Epoch: 5| Step: 7
Training loss: 0.18830713629722595
Validation loss: 1.602043333873954

Epoch: 5| Step: 8
Training loss: 0.09008431434631348
Validation loss: 1.5512271670884983

Epoch: 5| Step: 9
Training loss: 0.15307773649692535
Validation loss: 1.5813965310332596

Epoch: 5| Step: 10
Training loss: 0.06566089391708374
Validation loss: 1.5693419018099386

Epoch: 526| Step: 0
Training loss: 0.1423548012971878
Validation loss: 1.5867427100417435

Epoch: 5| Step: 1
Training loss: 0.17646381258964539
Validation loss: 1.600725907151417

Epoch: 5| Step: 2
Training loss: 0.1740623414516449
Validation loss: 1.606255458247277

Epoch: 5| Step: 3
Training loss: 0.11887089163064957
Validation loss: 1.5898539891806982

Epoch: 5| Step: 4
Training loss: 0.12086087465286255
Validation loss: 1.6050071152307654

Epoch: 5| Step: 5
Training loss: 0.10954008251428604
Validation loss: 1.5680606935613899

Epoch: 5| Step: 6
Training loss: 0.0895223394036293
Validation loss: 1.5769558914246098

Epoch: 5| Step: 7
Training loss: 0.19538182020187378
Validation loss: 1.582996267144398

Epoch: 5| Step: 8
Training loss: 0.10693156719207764
Validation loss: 1.5560093169571252

Epoch: 5| Step: 9
Training loss: 0.1584084928035736
Validation loss: 1.5695873845008113

Epoch: 5| Step: 10
Training loss: 0.11382660269737244
Validation loss: 1.5605211886026527

Epoch: 527| Step: 0
Training loss: 0.11571985483169556
Validation loss: 1.5381852016654065

Epoch: 5| Step: 1
Training loss: 0.12146731466054916
Validation loss: 1.5572543144226074

Epoch: 5| Step: 2
Training loss: 0.12460241466760635
Validation loss: 1.5412778200641755

Epoch: 5| Step: 3
Training loss: 0.08808012306690216
Validation loss: 1.55575127883624

Epoch: 5| Step: 4
Training loss: 0.11440566927194595
Validation loss: 1.55595745835253

Epoch: 5| Step: 5
Training loss: 0.1112748384475708
Validation loss: 1.5484677335267425

Epoch: 5| Step: 6
Training loss: 0.14847324788570404
Validation loss: 1.5558884451466222

Epoch: 5| Step: 7
Training loss: 0.06762035936117172
Validation loss: 1.5309544763257426

Epoch: 5| Step: 8
Training loss: 0.1331101357936859
Validation loss: 1.5364013243747014

Epoch: 5| Step: 9
Training loss: 0.1597299873828888
Validation loss: 1.5531654998820315

Epoch: 5| Step: 10
Training loss: 0.09543784707784653
Validation loss: 1.5566950498088714

Epoch: 528| Step: 0
Training loss: 0.10850342363119125
Validation loss: 1.526110759345434

Epoch: 5| Step: 1
Training loss: 0.16928263008594513
Validation loss: 1.5694683982479958

Epoch: 5| Step: 2
Training loss: 0.19444426894187927
Validation loss: 1.5973120466355355

Epoch: 5| Step: 3
Training loss: 0.09211588650941849
Validation loss: 1.5766601703500236

Epoch: 5| Step: 4
Training loss: 0.14312592148780823
Validation loss: 1.580633924212507

Epoch: 5| Step: 5
Training loss: 0.12030011415481567
Validation loss: 1.5984295965522848

Epoch: 5| Step: 6
Training loss: 0.10511340200901031
Validation loss: 1.6010182121748566

Epoch: 5| Step: 7
Training loss: 0.15750740468502045
Validation loss: 1.5894506246812883

Epoch: 5| Step: 8
Training loss: 0.11032000929117203
Validation loss: 1.5972632259450934

Epoch: 5| Step: 9
Training loss: 0.1559266746044159
Validation loss: 1.6120829223304667

Epoch: 5| Step: 10
Training loss: 0.14035119116306305
Validation loss: 1.58527377728493

Epoch: 529| Step: 0
Training loss: 0.0962551012635231
Validation loss: 1.5771089740978774

Epoch: 5| Step: 1
Training loss: 0.14006665349006653
Validation loss: 1.572022489322129

Epoch: 5| Step: 2
Training loss: 0.13064920902252197
Validation loss: 1.5869045398568595

Epoch: 5| Step: 3
Training loss: 0.14030751585960388
Validation loss: 1.555528763801821

Epoch: 5| Step: 4
Training loss: 0.09789665788412094
Validation loss: 1.5599464677995252

Epoch: 5| Step: 5
Training loss: 0.06832956522703171
Validation loss: 1.558244059162755

Epoch: 5| Step: 6
Training loss: 0.13924367725849152
Validation loss: 1.5591576663396691

Epoch: 5| Step: 7
Training loss: 0.13244237005710602
Validation loss: 1.5495629002971034

Epoch: 5| Step: 8
Training loss: 0.09398752450942993
Validation loss: 1.539814623453284

Epoch: 5| Step: 9
Training loss: 0.16513606905937195
Validation loss: 1.5417332892776818

Epoch: 5| Step: 10
Training loss: 0.1125061959028244
Validation loss: 1.5386319801371584

Epoch: 530| Step: 0
Training loss: 0.17880648374557495
Validation loss: 1.560172491176154

Epoch: 5| Step: 1
Training loss: 0.11366625130176544
Validation loss: 1.5526477213828795

Epoch: 5| Step: 2
Training loss: 0.10864061117172241
Validation loss: 1.535316700576454

Epoch: 5| Step: 3
Training loss: 0.15679466724395752
Validation loss: 1.5422986040833175

Epoch: 5| Step: 4
Training loss: 0.10188190639019012
Validation loss: 1.5612578661211076

Epoch: 5| Step: 5
Training loss: 0.07972661405801773
Validation loss: 1.5377007402399534

Epoch: 5| Step: 6
Training loss: 0.13425037264823914
Validation loss: 1.5654841251270746

Epoch: 5| Step: 7
Training loss: 0.16713903844356537
Validation loss: 1.5750761070559103

Epoch: 5| Step: 8
Training loss: 0.15044236183166504
Validation loss: 1.5912681984645065

Epoch: 5| Step: 9
Training loss: 0.1308092623949051
Validation loss: 1.595796133882256

Epoch: 5| Step: 10
Training loss: 0.0909363180398941
Validation loss: 1.5630042258129324

Epoch: 531| Step: 0
Training loss: 0.12844876945018768
Validation loss: 1.541968302060199

Epoch: 5| Step: 1
Training loss: 0.11807705461978912
Validation loss: 1.5388615259560205

Epoch: 5| Step: 2
Training loss: 0.10719694197177887
Validation loss: 1.555429430418117

Epoch: 5| Step: 3
Training loss: 0.10156987607479095
Validation loss: 1.529508384325171

Epoch: 5| Step: 4
Training loss: 0.1107003316283226
Validation loss: 1.5452272802270868

Epoch: 5| Step: 5
Training loss: 0.1363098919391632
Validation loss: 1.5636856446983993

Epoch: 5| Step: 6
Training loss: 0.10869824886322021
Validation loss: 1.5225884555488505

Epoch: 5| Step: 7
Training loss: 0.10201995074748993
Validation loss: 1.5718588547040058

Epoch: 5| Step: 8
Training loss: 0.12490050494670868
Validation loss: 1.5573337860004877

Epoch: 5| Step: 9
Training loss: 0.21346299350261688
Validation loss: 1.5645175095527404

Epoch: 5| Step: 10
Training loss: 0.14276616275310516
Validation loss: 1.5823726654052734

Epoch: 532| Step: 0
Training loss: 0.20412829518318176
Validation loss: 1.564122070548355

Epoch: 5| Step: 1
Training loss: 0.10546515136957169
Validation loss: 1.5755429985702678

Epoch: 5| Step: 2
Training loss: 0.1226024404168129
Validation loss: 1.5767581462860107

Epoch: 5| Step: 3
Training loss: 0.07859154790639877
Validation loss: 1.597150464211741

Epoch: 5| Step: 4
Training loss: 0.10663957893848419
Validation loss: 1.590226488728677

Epoch: 5| Step: 5
Training loss: 0.10651125013828278
Validation loss: 1.5979113681342012

Epoch: 5| Step: 6
Training loss: 0.11234147846698761
Validation loss: 1.6028392494365733

Epoch: 5| Step: 7
Training loss: 0.13521412014961243
Validation loss: 1.6064786231645973

Epoch: 5| Step: 8
Training loss: 0.07343089580535889
Validation loss: 1.6110997687103927

Epoch: 5| Step: 9
Training loss: 0.10351911932229996
Validation loss: 1.6036657876865839

Epoch: 5| Step: 10
Training loss: 0.15227194130420685
Validation loss: 1.6212554888058734

Epoch: 533| Step: 0
Training loss: 0.12687334418296814
Validation loss: 1.6007145245869954

Epoch: 5| Step: 1
Training loss: 0.11504985392093658
Validation loss: 1.6015492434142737

Epoch: 5| Step: 2
Training loss: 0.14226101338863373
Validation loss: 1.5710533383072063

Epoch: 5| Step: 3
Training loss: 0.0679466724395752
Validation loss: 1.571428891151182

Epoch: 5| Step: 4
Training loss: 0.06569813191890717
Validation loss: 1.5719051130356327

Epoch: 5| Step: 5
Training loss: 0.059249572455883026
Validation loss: 1.5592444763388684

Epoch: 5| Step: 6
Training loss: 0.15143729746341705
Validation loss: 1.55868197384701

Epoch: 5| Step: 7
Training loss: 0.09349799156188965
Validation loss: 1.576300778696614

Epoch: 5| Step: 8
Training loss: 0.1469520926475525
Validation loss: 1.5726513106335875

Epoch: 5| Step: 9
Training loss: 0.18268391489982605
Validation loss: 1.5770468724671232

Epoch: 5| Step: 10
Training loss: 0.1050812229514122
Validation loss: 1.5994047311044508

Epoch: 534| Step: 0
Training loss: 0.10192473232746124
Validation loss: 1.5712211157685967

Epoch: 5| Step: 1
Training loss: 0.11320239305496216
Validation loss: 1.5903577304655505

Epoch: 5| Step: 2
Training loss: 0.09143807739019394
Validation loss: 1.559042929321207

Epoch: 5| Step: 3
Training loss: 0.13799847662448883
Validation loss: 1.558614230925037

Epoch: 5| Step: 4
Training loss: 0.09667521715164185
Validation loss: 1.5511282695237028

Epoch: 5| Step: 5
Training loss: 0.16717687249183655
Validation loss: 1.528774098683429

Epoch: 5| Step: 6
Training loss: 0.1943904310464859
Validation loss: 1.5304728400322698

Epoch: 5| Step: 7
Training loss: 0.18884658813476562
Validation loss: 1.5297688861047067

Epoch: 5| Step: 8
Training loss: 0.2022777795791626
Validation loss: 1.5543225465282318

Epoch: 5| Step: 9
Training loss: 0.2138301134109497
Validation loss: 1.548845011700866

Epoch: 5| Step: 10
Training loss: 0.15442462265491486
Validation loss: 1.5450295088111714

Epoch: 535| Step: 0
Training loss: 0.12030382454395294
Validation loss: 1.5554034806066943

Epoch: 5| Step: 1
Training loss: 0.13124112784862518
Validation loss: 1.566647683420489

Epoch: 5| Step: 2
Training loss: 0.10172192752361298
Validation loss: 1.5978347152791998

Epoch: 5| Step: 3
Training loss: 0.14192239940166473
Validation loss: 1.5842471738015451

Epoch: 5| Step: 4
Training loss: 0.13366864621639252
Validation loss: 1.5707268061176423

Epoch: 5| Step: 5
Training loss: 0.12915118038654327
Validation loss: 1.5800848930112776

Epoch: 5| Step: 6
Training loss: 0.10202479362487793
Validation loss: 1.5710989916196434

Epoch: 5| Step: 7
Training loss: 0.11575940996408463
Validation loss: 1.5893264252652404

Epoch: 5| Step: 8
Training loss: 0.11585183441638947
Validation loss: 1.5729864976739372

Epoch: 5| Step: 9
Training loss: 0.1027931421995163
Validation loss: 1.5434051123998498

Epoch: 5| Step: 10
Training loss: 0.10385175794363022
Validation loss: 1.5551363960389168

Epoch: 536| Step: 0
Training loss: 0.1137140616774559
Validation loss: 1.5541494443852415

Epoch: 5| Step: 1
Training loss: 0.07415805757045746
Validation loss: 1.5255641924437655

Epoch: 5| Step: 2
Training loss: 0.1427328884601593
Validation loss: 1.554693320746063

Epoch: 5| Step: 3
Training loss: 0.14100009202957153
Validation loss: 1.5451745884392851

Epoch: 5| Step: 4
Training loss: 0.07074540853500366
Validation loss: 1.5424331272802045

Epoch: 5| Step: 5
Training loss: 0.17903783917427063
Validation loss: 1.5572232610435897

Epoch: 5| Step: 6
Training loss: 0.13441573083400726
Validation loss: 1.5694170369896838

Epoch: 5| Step: 7
Training loss: 0.13914652168750763
Validation loss: 1.5661364319503948

Epoch: 5| Step: 8
Training loss: 0.07208257168531418
Validation loss: 1.5624579229662496

Epoch: 5| Step: 9
Training loss: 0.1280873715877533
Validation loss: 1.565259575843811

Epoch: 5| Step: 10
Training loss: 0.14821834862232208
Validation loss: 1.5532544107847317

Epoch: 537| Step: 0
Training loss: 0.10772410780191422
Validation loss: 1.5733808548219743

Epoch: 5| Step: 1
Training loss: 0.08086253702640533
Validation loss: 1.5483268845465876

Epoch: 5| Step: 2
Training loss: 0.10288651287555695
Validation loss: 1.5435204916102911

Epoch: 5| Step: 3
Training loss: 0.12706564366817474
Validation loss: 1.5484579128603781

Epoch: 5| Step: 4
Training loss: 0.08827835321426392
Validation loss: 1.5455281785739365

Epoch: 5| Step: 5
Training loss: 0.10454388707876205
Validation loss: 1.5572759694950555

Epoch: 5| Step: 6
Training loss: 0.13798753917217255
Validation loss: 1.5453471393995388

Epoch: 5| Step: 7
Training loss: 0.12914255261421204
Validation loss: 1.5360692816395913

Epoch: 5| Step: 8
Training loss: 0.19628553092479706
Validation loss: 1.503180052644463

Epoch: 5| Step: 9
Training loss: 0.11715154349803925
Validation loss: 1.515368092444635

Epoch: 5| Step: 10
Training loss: 0.07398613542318344
Validation loss: 1.5366009012345345

Epoch: 538| Step: 0
Training loss: 0.13613556325435638
Validation loss: 1.5178061851891138

Epoch: 5| Step: 1
Training loss: 0.1616014540195465
Validation loss: 1.5257744391759236

Epoch: 5| Step: 2
Training loss: 0.09281802177429199
Validation loss: 1.521337620673641

Epoch: 5| Step: 3
Training loss: 0.11887697130441666
Validation loss: 1.5090769875434138

Epoch: 5| Step: 4
Training loss: 0.10811229050159454
Validation loss: 1.5183859127824024

Epoch: 5| Step: 5
Training loss: 0.1574312150478363
Validation loss: 1.5033654525715818

Epoch: 5| Step: 6
Training loss: 0.09952601790428162
Validation loss: 1.5095146035635343

Epoch: 5| Step: 7
Training loss: 0.08138440549373627
Validation loss: 1.5106882113282398

Epoch: 5| Step: 8
Training loss: 0.15254035592079163
Validation loss: 1.4992016105241672

Epoch: 5| Step: 9
Training loss: 0.09850946813821793
Validation loss: 1.5269320991731459

Epoch: 5| Step: 10
Training loss: 0.09765177965164185
Validation loss: 1.5472193751283871

Epoch: 539| Step: 0
Training loss: 0.2149503231048584
Validation loss: 1.5228428263818063

Epoch: 5| Step: 1
Training loss: 0.11075885593891144
Validation loss: 1.5133971168148903

Epoch: 5| Step: 2
Training loss: 0.0934455618262291
Validation loss: 1.5256678750438075

Epoch: 5| Step: 3
Training loss: 0.11405901610851288
Validation loss: 1.5566983992053616

Epoch: 5| Step: 4
Training loss: 0.11342046409845352
Validation loss: 1.5441023265161822

Epoch: 5| Step: 5
Training loss: 0.10636917501688004
Validation loss: 1.56098271313534

Epoch: 5| Step: 6
Training loss: 0.114974245429039
Validation loss: 1.5825625875944733

Epoch: 5| Step: 7
Training loss: 0.06721995025873184
Validation loss: 1.561635273759083

Epoch: 5| Step: 8
Training loss: 0.07519377768039703
Validation loss: 1.5853551357023177

Epoch: 5| Step: 9
Training loss: 0.0946066677570343
Validation loss: 1.5833761845865557

Epoch: 5| Step: 10
Training loss: 0.19912901520729065
Validation loss: 1.6004540740802724

Epoch: 540| Step: 0
Training loss: 0.11254012584686279
Validation loss: 1.5871936044385355

Epoch: 5| Step: 1
Training loss: 0.13151806592941284
Validation loss: 1.5587684467274656

Epoch: 5| Step: 2
Training loss: 0.10748165845870972
Validation loss: 1.5688532885684763

Epoch: 5| Step: 3
Training loss: 0.1302708387374878
Validation loss: 1.5536619206910491

Epoch: 5| Step: 4
Training loss: 0.16635458171367645
Validation loss: 1.5671085593520955

Epoch: 5| Step: 5
Training loss: 0.10469654947519302
Validation loss: 1.5591160956249441

Epoch: 5| Step: 6
Training loss: 0.13172651827335358
Validation loss: 1.567673598566363

Epoch: 5| Step: 7
Training loss: 0.11538241058588028
Validation loss: 1.5853942645493375

Epoch: 5| Step: 8
Training loss: 0.09119923412799835
Validation loss: 1.5656208735640331

Epoch: 5| Step: 9
Training loss: 0.08120163530111313
Validation loss: 1.5734779283564577

Epoch: 5| Step: 10
Training loss: 0.09362708032131195
Validation loss: 1.625321993263819

Epoch: 541| Step: 0
Training loss: 0.15578770637512207
Validation loss: 1.588988173392511

Epoch: 5| Step: 1
Training loss: 0.1441972255706787
Validation loss: 1.5950483673362321

Epoch: 5| Step: 2
Training loss: 0.07142071425914764
Validation loss: 1.5656591102641115

Epoch: 5| Step: 3
Training loss: 0.08803130686283112
Validation loss: 1.5645664353524484

Epoch: 5| Step: 4
Training loss: 0.187839537858963
Validation loss: 1.5546616809342497

Epoch: 5| Step: 5
Training loss: 0.112589992582798
Validation loss: 1.544607190675633

Epoch: 5| Step: 6
Training loss: 0.133518785238266
Validation loss: 1.5667434046345372

Epoch: 5| Step: 7
Training loss: 0.14159107208251953
Validation loss: 1.5561099001156387

Epoch: 5| Step: 8
Training loss: 0.10930375009775162
Validation loss: 1.571024638350292

Epoch: 5| Step: 9
Training loss: 0.15939894318580627
Validation loss: 1.5614889924244215

Epoch: 5| Step: 10
Training loss: 0.16254790127277374
Validation loss: 1.5597829562361523

Epoch: 542| Step: 0
Training loss: 0.11901547014713287
Validation loss: 1.5106306306777462

Epoch: 5| Step: 1
Training loss: 0.12452296912670135
Validation loss: 1.5463493703514017

Epoch: 5| Step: 2
Training loss: 0.1592976152896881
Validation loss: 1.5463413833290018

Epoch: 5| Step: 3
Training loss: 0.0874171108007431
Validation loss: 1.5576214892889864

Epoch: 5| Step: 4
Training loss: 0.12580454349517822
Validation loss: 1.575097466027865

Epoch: 5| Step: 5
Training loss: 0.09135757386684418
Validation loss: 1.5687478075745285

Epoch: 5| Step: 6
Training loss: 0.13190795481204987
Validation loss: 1.586318991517508

Epoch: 5| Step: 7
Training loss: 0.1369602382183075
Validation loss: 1.5909706059322561

Epoch: 5| Step: 8
Training loss: 0.08284030854701996
Validation loss: 1.5493261839753838

Epoch: 5| Step: 9
Training loss: 0.10484949499368668
Validation loss: 1.5669009800880187

Epoch: 5| Step: 10
Training loss: 0.10009587556123734
Validation loss: 1.5425894978225871

Epoch: 543| Step: 0
Training loss: 0.12481437623500824
Validation loss: 1.5476499116548927

Epoch: 5| Step: 1
Training loss: 0.08286850154399872
Validation loss: 1.5723998123599636

Epoch: 5| Step: 2
Training loss: 0.07716219127178192
Validation loss: 1.5793713292767924

Epoch: 5| Step: 3
Training loss: 0.14586180448532104
Validation loss: 1.5580168654841762

Epoch: 5| Step: 4
Training loss: 0.1406349390745163
Validation loss: 1.5734066091557986

Epoch: 5| Step: 5
Training loss: 0.0973423644900322
Validation loss: 1.5670418162499704

Epoch: 5| Step: 6
Training loss: 0.13118740916252136
Validation loss: 1.56965119864351

Epoch: 5| Step: 7
Training loss: 0.07501854002475739
Validation loss: 1.5592926522736907

Epoch: 5| Step: 8
Training loss: 0.09936092793941498
Validation loss: 1.5581302360821796

Epoch: 5| Step: 9
Training loss: 0.12337370216846466
Validation loss: 1.5524267919601933

Epoch: 5| Step: 10
Training loss: 0.11571823060512543
Validation loss: 1.5544068736414756

Epoch: 544| Step: 0
Training loss: 0.11759563535451889
Validation loss: 1.5527749766585648

Epoch: 5| Step: 1
Training loss: 0.15743987262248993
Validation loss: 1.5562442528304232

Epoch: 5| Step: 2
Training loss: 0.1292973756790161
Validation loss: 1.500428153622535

Epoch: 5| Step: 3
Training loss: 0.09259665012359619
Validation loss: 1.5277470029810423

Epoch: 5| Step: 4
Training loss: 0.08379246294498444
Validation loss: 1.5343711747918078

Epoch: 5| Step: 5
Training loss: 0.21923799812793732
Validation loss: 1.5482952979303175

Epoch: 5| Step: 6
Training loss: 0.12415535748004913
Validation loss: 1.5213455256595407

Epoch: 5| Step: 7
Training loss: 0.0668175220489502
Validation loss: 1.5238787871535107

Epoch: 5| Step: 8
Training loss: 0.0840512067079544
Validation loss: 1.5568615518590456

Epoch: 5| Step: 9
Training loss: 0.11120760440826416
Validation loss: 1.5318881734724967

Epoch: 5| Step: 10
Training loss: 0.12974242866039276
Validation loss: 1.557302632639485

Epoch: 545| Step: 0
Training loss: 0.13071832060813904
Validation loss: 1.5623656216488089

Epoch: 5| Step: 1
Training loss: 0.09027533233165741
Validation loss: 1.54387435349085

Epoch: 5| Step: 2
Training loss: 0.11686551570892334
Validation loss: 1.5598735322234452

Epoch: 5| Step: 3
Training loss: 0.11240200698375702
Validation loss: 1.585503189794479

Epoch: 5| Step: 4
Training loss: 0.09346010535955429
Validation loss: 1.5565812023737098

Epoch: 5| Step: 5
Training loss: 0.15686945617198944
Validation loss: 1.5720629051167478

Epoch: 5| Step: 6
Training loss: 0.1825006753206253
Validation loss: 1.5577062727302633

Epoch: 5| Step: 7
Training loss: 0.11012103408575058
Validation loss: 1.5774624322050361

Epoch: 5| Step: 8
Training loss: 0.12551116943359375
Validation loss: 1.5609221278980214

Epoch: 5| Step: 9
Training loss: 0.09082426130771637
Validation loss: 1.5500581905406008

Epoch: 5| Step: 10
Training loss: 0.09032252430915833
Validation loss: 1.5190733991643435

Epoch: 546| Step: 0
Training loss: 0.1740422546863556
Validation loss: 1.525060231967639

Epoch: 5| Step: 1
Training loss: 0.17764636874198914
Validation loss: 1.5487779084072317

Epoch: 5| Step: 2
Training loss: 0.0513283833861351
Validation loss: 1.5570481643881848

Epoch: 5| Step: 3
Training loss: 0.16691648960113525
Validation loss: 1.5629284817685363

Epoch: 5| Step: 4
Training loss: 0.11512202024459839
Validation loss: 1.586969264091984

Epoch: 5| Step: 5
Training loss: 0.08024182915687561
Validation loss: 1.5791669404634865

Epoch: 5| Step: 6
Training loss: 0.15632419288158417
Validation loss: 1.6084790550252444

Epoch: 5| Step: 7
Training loss: 0.12279639393091202
Validation loss: 1.6060041778831071

Epoch: 5| Step: 8
Training loss: 0.09369935095310211
Validation loss: 1.578272742609824

Epoch: 5| Step: 9
Training loss: 0.08772413432598114
Validation loss: 1.578057599324052

Epoch: 5| Step: 10
Training loss: 0.11201241612434387
Validation loss: 1.5585516575844056

Epoch: 547| Step: 0
Training loss: 0.1270572394132614
Validation loss: 1.575263774523171

Epoch: 5| Step: 1
Training loss: 0.11130032688379288
Validation loss: 1.5493147309108446

Epoch: 5| Step: 2
Training loss: 0.11593179404735565
Validation loss: 1.554529127254281

Epoch: 5| Step: 3
Training loss: 0.12893736362457275
Validation loss: 1.5527195994571974

Epoch: 5| Step: 4
Training loss: 0.14925649762153625
Validation loss: 1.563182411655303

Epoch: 5| Step: 5
Training loss: 0.19196894764900208
Validation loss: 1.5717478080462384

Epoch: 5| Step: 6
Training loss: 0.08844379335641861
Validation loss: 1.5495754191952367

Epoch: 5| Step: 7
Training loss: 0.06436491757631302
Validation loss: 1.5809954545831169

Epoch: 5| Step: 8
Training loss: 0.13080117106437683
Validation loss: 1.5606983130978

Epoch: 5| Step: 9
Training loss: 0.09403687715530396
Validation loss: 1.5872759331939041

Epoch: 5| Step: 10
Training loss: 0.09730634838342667
Validation loss: 1.6080086949051067

Epoch: 548| Step: 0
Training loss: 0.08954577893018723
Validation loss: 1.5670124984556628

Epoch: 5| Step: 1
Training loss: 0.08871423453092575
Validation loss: 1.5647149880727131

Epoch: 5| Step: 2
Training loss: 0.16267983615398407
Validation loss: 1.5823430912469023

Epoch: 5| Step: 3
Training loss: 0.09001021087169647
Validation loss: 1.5662190042516237

Epoch: 5| Step: 4
Training loss: 0.1486789733171463
Validation loss: 1.5775841038714173

Epoch: 5| Step: 5
Training loss: 0.1293855458498001
Validation loss: 1.5602457843801028

Epoch: 5| Step: 6
Training loss: 0.124867282807827
Validation loss: 1.5457184186545752

Epoch: 5| Step: 7
Training loss: 0.14431965351104736
Validation loss: 1.5567581807413409

Epoch: 5| Step: 8
Training loss: 0.13850101828575134
Validation loss: 1.5196316703673332

Epoch: 5| Step: 9
Training loss: 0.09280566871166229
Validation loss: 1.554220849467862

Epoch: 5| Step: 10
Training loss: 0.09077306091785431
Validation loss: 1.5709763367970784

Epoch: 549| Step: 0
Training loss: 0.07957489788532257
Validation loss: 1.576355795706472

Epoch: 5| Step: 1
Training loss: 0.1566314399242401
Validation loss: 1.5688685127483901

Epoch: 5| Step: 2
Training loss: 0.0895441323518753
Validation loss: 1.5862818687192854

Epoch: 5| Step: 3
Training loss: 0.0994536429643631
Validation loss: 1.6106967451751872

Epoch: 5| Step: 4
Training loss: 0.1440332680940628
Validation loss: 1.568958435007321

Epoch: 5| Step: 5
Training loss: 0.10886218398809433
Validation loss: 1.5668299492969309

Epoch: 5| Step: 6
Training loss: 0.1133706122636795
Validation loss: 1.5909778366806686

Epoch: 5| Step: 7
Training loss: 0.09379509091377258
Validation loss: 1.5776962964765486

Epoch: 5| Step: 8
Training loss: 0.0996844694018364
Validation loss: 1.5413287813945482

Epoch: 5| Step: 9
Training loss: 0.08046361058950424
Validation loss: 1.5547593242378646

Epoch: 5| Step: 10
Training loss: 0.18700425326824188
Validation loss: 1.5354751028040403

Epoch: 550| Step: 0
Training loss: 0.06669659912586212
Validation loss: 1.551157046389836

Epoch: 5| Step: 1
Training loss: 0.11649944633245468
Validation loss: 1.5488004530629804

Epoch: 5| Step: 2
Training loss: 0.0909411758184433
Validation loss: 1.518265430645276

Epoch: 5| Step: 3
Training loss: 0.16002026200294495
Validation loss: 1.5528427605987878

Epoch: 5| Step: 4
Training loss: 0.0888628363609314
Validation loss: 1.542398561713516

Epoch: 5| Step: 5
Training loss: 0.09632835537195206
Validation loss: 1.5740532682787987

Epoch: 5| Step: 6
Training loss: 0.11890880763530731
Validation loss: 1.5707800490881807

Epoch: 5| Step: 7
Training loss: 0.14675718545913696
Validation loss: 1.5719981936998264

Epoch: 5| Step: 8
Training loss: 0.10032691806554794
Validation loss: 1.5902145524178781

Epoch: 5| Step: 9
Training loss: 0.12852947413921356
Validation loss: 1.5628568664673836

Epoch: 5| Step: 10
Training loss: 0.10768170654773712
Validation loss: 1.5624984169519076

Epoch: 551| Step: 0
Training loss: 0.11887456476688385
Validation loss: 1.553538316680539

Epoch: 5| Step: 1
Training loss: 0.05921821668744087
Validation loss: 1.5471076170603435

Epoch: 5| Step: 2
Training loss: 0.11284588277339935
Validation loss: 1.520259008612684

Epoch: 5| Step: 3
Training loss: 0.07494131475687027
Validation loss: 1.5457643437129196

Epoch: 5| Step: 4
Training loss: 0.1449817568063736
Validation loss: 1.5633874074105294

Epoch: 5| Step: 5
Training loss: 0.1317526400089264
Validation loss: 1.5407046707727576

Epoch: 5| Step: 6
Training loss: 0.09853101521730423
Validation loss: 1.5215236371563328

Epoch: 5| Step: 7
Training loss: 0.08555404096841812
Validation loss: 1.5697280335169967

Epoch: 5| Step: 8
Training loss: 0.1593974083662033
Validation loss: 1.5740743606321272

Epoch: 5| Step: 9
Training loss: 0.09460148960351944
Validation loss: 1.6167275469790223

Epoch: 5| Step: 10
Training loss: 0.09679096192121506
Validation loss: 1.6000584517755816

Epoch: 552| Step: 0
Training loss: 0.09663907438516617
Validation loss: 1.608366116400688

Epoch: 5| Step: 1
Training loss: 0.11037011444568634
Validation loss: 1.6054205779106385

Epoch: 5| Step: 2
Training loss: 0.10590161383152008
Validation loss: 1.5722690243874826

Epoch: 5| Step: 3
Training loss: 0.07045748084783554
Validation loss: 1.5624748570944673

Epoch: 5| Step: 4
Training loss: 0.07717234641313553
Validation loss: 1.5607333798562326

Epoch: 5| Step: 5
Training loss: 0.10121846199035645
Validation loss: 1.5281262320856894

Epoch: 5| Step: 6
Training loss: 0.11678214371204376
Validation loss: 1.5221733931572206

Epoch: 5| Step: 7
Training loss: 0.13901445269584656
Validation loss: 1.5077446609415033

Epoch: 5| Step: 8
Training loss: 0.09265962988138199
Validation loss: 1.5126561285347067

Epoch: 5| Step: 9
Training loss: 0.12470366060733795
Validation loss: 1.4846888024319884

Epoch: 5| Step: 10
Training loss: 0.16049793362617493
Validation loss: 1.5283510736239854

Epoch: 553| Step: 0
Training loss: 0.1285879909992218
Validation loss: 1.5338397910518031

Epoch: 5| Step: 1
Training loss: 0.062298066914081573
Validation loss: 1.5215914685239074

Epoch: 5| Step: 2
Training loss: 0.09978537261486053
Validation loss: 1.5213826189758957

Epoch: 5| Step: 3
Training loss: 0.14705690741539001
Validation loss: 1.5764824651902722

Epoch: 5| Step: 4
Training loss: 0.12985935807228088
Validation loss: 1.5563101537765995

Epoch: 5| Step: 5
Training loss: 0.11891604959964752
Validation loss: 1.5434624994954755

Epoch: 5| Step: 6
Training loss: 0.09386574476957321
Validation loss: 1.4946902605795092

Epoch: 5| Step: 7
Training loss: 0.1255861073732376
Validation loss: 1.5191718891102781

Epoch: 5| Step: 8
Training loss: 0.15997633337974548
Validation loss: 1.5098834704327326

Epoch: 5| Step: 9
Training loss: 0.17373648285865784
Validation loss: 1.504228594482586

Epoch: 5| Step: 10
Training loss: 0.16319230198860168
Validation loss: 1.511622534003309

Epoch: 554| Step: 0
Training loss: 0.09340052306652069
Validation loss: 1.5119662092578026

Epoch: 5| Step: 1
Training loss: 0.11351598799228668
Validation loss: 1.4845619791297502

Epoch: 5| Step: 2
Training loss: 0.12830159068107605
Validation loss: 1.5218870896165089

Epoch: 5| Step: 3
Training loss: 0.14568309485912323
Validation loss: 1.5194343366930563

Epoch: 5| Step: 4
Training loss: 0.1792513132095337
Validation loss: 1.5400500733365294

Epoch: 5| Step: 5
Training loss: 0.14679934084415436
Validation loss: 1.5093667955808743

Epoch: 5| Step: 6
Training loss: 0.09906435012817383
Validation loss: 1.5132216599679762

Epoch: 5| Step: 7
Training loss: 0.21286292374134064
Validation loss: 1.5405268489673574

Epoch: 5| Step: 8
Training loss: 0.18979600071907043
Validation loss: 1.5308582129016999

Epoch: 5| Step: 9
Training loss: 0.1920052468776703
Validation loss: 1.5190938403529506

Epoch: 5| Step: 10
Training loss: 0.11051350831985474
Validation loss: 1.5572343744257444

Epoch: 555| Step: 0
Training loss: 0.07818756997585297
Validation loss: 1.5506289236007198

Epoch: 5| Step: 1
Training loss: 0.20259535312652588
Validation loss: 1.5818604480835698

Epoch: 5| Step: 2
Training loss: 0.2055937796831131
Validation loss: 1.6256734222494147

Epoch: 5| Step: 3
Training loss: 0.10080323368310928
Validation loss: 1.6148997276060042

Epoch: 5| Step: 4
Training loss: 0.13550493121147156
Validation loss: 1.5775629192270257

Epoch: 5| Step: 5
Training loss: 0.111238993704319
Validation loss: 1.581949617273064

Epoch: 5| Step: 6
Training loss: 0.14468511939048767
Validation loss: 1.5669380137997289

Epoch: 5| Step: 7
Training loss: 0.15961091220378876
Validation loss: 1.5683274031967245

Epoch: 5| Step: 8
Training loss: 0.10706444829702377
Validation loss: 1.5598328857011692

Epoch: 5| Step: 9
Training loss: 0.11236145347356796
Validation loss: 1.5667175144277594

Epoch: 5| Step: 10
Training loss: 0.20084905624389648
Validation loss: 1.5624578857934603

Epoch: 556| Step: 0
Training loss: 0.0740823745727539
Validation loss: 1.5704185014129968

Epoch: 5| Step: 1
Training loss: 0.12692031264305115
Validation loss: 1.5894440207430112

Epoch: 5| Step: 2
Training loss: 0.12702825665473938
Validation loss: 1.582190357228761

Epoch: 5| Step: 3
Training loss: 0.16004280745983124
Validation loss: 1.5619547854187668

Epoch: 5| Step: 4
Training loss: 0.14850738644599915
Validation loss: 1.5356248399262786

Epoch: 5| Step: 5
Training loss: 0.06925982981920242
Validation loss: 1.5266271970605338

Epoch: 5| Step: 6
Training loss: 0.09858987480401993
Validation loss: 1.5162048673117032

Epoch: 5| Step: 7
Training loss: 0.08977265655994415
Validation loss: 1.5077947147430912

Epoch: 5| Step: 8
Training loss: 0.1745816469192505
Validation loss: 1.498617429887095

Epoch: 5| Step: 9
Training loss: 0.11569156497716904
Validation loss: 1.5196369078851515

Epoch: 5| Step: 10
Training loss: 0.05403799191117287
Validation loss: 1.528088895223474

Epoch: 557| Step: 0
Training loss: 0.08660600334405899
Validation loss: 1.5665285894947667

Epoch: 5| Step: 1
Training loss: 0.10645010322332382
Validation loss: 1.5222962338437316

Epoch: 5| Step: 2
Training loss: 0.11225622892379761
Validation loss: 1.5240393736029183

Epoch: 5| Step: 3
Training loss: 0.13714967668056488
Validation loss: 1.5489684715065906

Epoch: 5| Step: 4
Training loss: 0.13458113372325897
Validation loss: 1.545266757729233

Epoch: 5| Step: 5
Training loss: 0.1814936101436615
Validation loss: 1.546616486323777

Epoch: 5| Step: 6
Training loss: 0.09762265533208847
Validation loss: 1.5182952957768594

Epoch: 5| Step: 7
Training loss: 0.1261710822582245
Validation loss: 1.51154927925397

Epoch: 5| Step: 8
Training loss: 0.06688673049211502
Validation loss: 1.5317207940163151

Epoch: 5| Step: 9
Training loss: 0.12561996281147003
Validation loss: 1.5679707706615489

Epoch: 5| Step: 10
Training loss: 0.12691320478916168
Validation loss: 1.5610028082324612

Epoch: 558| Step: 0
Training loss: 0.114392951130867
Validation loss: 1.5479845359761228

Epoch: 5| Step: 1
Training loss: 0.09670066833496094
Validation loss: 1.5849488255798176

Epoch: 5| Step: 2
Training loss: 0.10400480031967163
Validation loss: 1.5769297871538388

Epoch: 5| Step: 3
Training loss: 0.12174031883478165
Validation loss: 1.56352694829305

Epoch: 5| Step: 4
Training loss: 0.09902296960353851
Validation loss: 1.5841450422040877

Epoch: 5| Step: 5
Training loss: 0.08089350163936615
Validation loss: 1.5863675609711678

Epoch: 5| Step: 6
Training loss: 0.12973448634147644
Validation loss: 1.5694821239799581

Epoch: 5| Step: 7
Training loss: 0.12899556756019592
Validation loss: 1.5479333862181632

Epoch: 5| Step: 8
Training loss: 0.08720724284648895
Validation loss: 1.569020745574787

Epoch: 5| Step: 9
Training loss: 0.1785835176706314
Validation loss: 1.5604464007962136

Epoch: 5| Step: 10
Training loss: 0.08708610385656357
Validation loss: 1.5628782177484164

Epoch: 559| Step: 0
Training loss: 0.07171203196048737
Validation loss: 1.5722057255365516

Epoch: 5| Step: 1
Training loss: 0.07611390203237534
Validation loss: 1.5411178322248562

Epoch: 5| Step: 2
Training loss: 0.12591560184955597
Validation loss: 1.5303337330459266

Epoch: 5| Step: 3
Training loss: 0.14676430821418762
Validation loss: 1.53501082235767

Epoch: 5| Step: 4
Training loss: 0.10806373506784439
Validation loss: 1.5504976055955375

Epoch: 5| Step: 5
Training loss: 0.12149055302143097
Validation loss: 1.5585141220400411

Epoch: 5| Step: 6
Training loss: 0.16211174428462982
Validation loss: 1.544716210775478

Epoch: 5| Step: 7
Training loss: 0.14987298846244812
Validation loss: 1.56276491636871

Epoch: 5| Step: 8
Training loss: 0.13257896900177002
Validation loss: 1.5688555855904855

Epoch: 5| Step: 9
Training loss: 0.13320417702198029
Validation loss: 1.5851485677944717

Epoch: 5| Step: 10
Training loss: 0.08477026224136353
Validation loss: 1.5685823296987882

Epoch: 560| Step: 0
Training loss: 0.13733169436454773
Validation loss: 1.5510292976133284

Epoch: 5| Step: 1
Training loss: 0.1769091635942459
Validation loss: 1.5449375465352049

Epoch: 5| Step: 2
Training loss: 0.10353299230337143
Validation loss: 1.5608484552752586

Epoch: 5| Step: 3
Training loss: 0.08829785883426666
Validation loss: 1.5641978633019231

Epoch: 5| Step: 4
Training loss: 0.07443951815366745
Validation loss: 1.5637486403988254

Epoch: 5| Step: 5
Training loss: 0.09033968299627304
Validation loss: 1.5611068638422156

Epoch: 5| Step: 6
Training loss: 0.10696258395910263
Validation loss: 1.5717478939281997

Epoch: 5| Step: 7
Training loss: 0.2014574110507965
Validation loss: 1.5938854114983672

Epoch: 5| Step: 8
Training loss: 0.11845811456441879
Validation loss: 1.574358888851699

Epoch: 5| Step: 9
Training loss: 0.105926513671875
Validation loss: 1.525533212128506

Epoch: 5| Step: 10
Training loss: 0.16427594423294067
Validation loss: 1.5307600677654307

Epoch: 561| Step: 0
Training loss: 0.1719215214252472
Validation loss: 1.5161978942091747

Epoch: 5| Step: 1
Training loss: 0.19984935224056244
Validation loss: 1.5390492549506567

Epoch: 5| Step: 2
Training loss: 0.17231111228466034
Validation loss: 1.5036590099334717

Epoch: 5| Step: 3
Training loss: 0.16359810531139374
Validation loss: 1.5169990242168467

Epoch: 5| Step: 4
Training loss: 0.11011211574077606
Validation loss: 1.535399293386808

Epoch: 5| Step: 5
Training loss: 0.12904633581638336
Validation loss: 1.522781786098275

Epoch: 5| Step: 6
Training loss: 0.09724898636341095
Validation loss: 1.5441794190355527

Epoch: 5| Step: 7
Training loss: 0.132371187210083
Validation loss: 1.5530884810673293

Epoch: 5| Step: 8
Training loss: 0.14878317713737488
Validation loss: 1.5942329155501498

Epoch: 5| Step: 9
Training loss: 0.09399338066577911
Validation loss: 1.5672882321060344

Epoch: 5| Step: 10
Training loss: 0.13061437010765076
Validation loss: 1.539975373334782

Epoch: 562| Step: 0
Training loss: 0.07300789654254913
Validation loss: 1.5469183114267164

Epoch: 5| Step: 1
Training loss: 0.09584159404039383
Validation loss: 1.4929889402081888

Epoch: 5| Step: 2
Training loss: 0.10626997798681259
Validation loss: 1.4956261573299285

Epoch: 5| Step: 3
Training loss: 0.14553122222423553
Validation loss: 1.516038639571077

Epoch: 5| Step: 4
Training loss: 0.09015889465808868
Validation loss: 1.510103351326399

Epoch: 5| Step: 5
Training loss: 0.07877625524997711
Validation loss: 1.5183766670124506

Epoch: 5| Step: 6
Training loss: 0.11498360335826874
Validation loss: 1.4950537950761857

Epoch: 5| Step: 7
Training loss: 0.12462488561868668
Validation loss: 1.511814458395845

Epoch: 5| Step: 8
Training loss: 0.10591983795166016
Validation loss: 1.494180913894407

Epoch: 5| Step: 9
Training loss: 0.06630483269691467
Validation loss: 1.496154756956203

Epoch: 5| Step: 10
Training loss: 0.15572263300418854
Validation loss: 1.5281882503981232

Epoch: 563| Step: 0
Training loss: 0.06594649702310562
Validation loss: 1.5475979184591642

Epoch: 5| Step: 1
Training loss: 0.08817648142576218
Validation loss: 1.5579070891103437

Epoch: 5| Step: 2
Training loss: 0.1949814260005951
Validation loss: 1.565281186052548

Epoch: 5| Step: 3
Training loss: 0.08556383848190308
Validation loss: 1.5563228412341046

Epoch: 5| Step: 4
Training loss: 0.1724080741405487
Validation loss: 1.5006910229241976

Epoch: 5| Step: 5
Training loss: 0.1663488745689392
Validation loss: 1.5020409732736566

Epoch: 5| Step: 6
Training loss: 0.12117595970630646
Validation loss: 1.483379953651018

Epoch: 5| Step: 7
Training loss: 0.16000445187091827
Validation loss: 1.497743953940689

Epoch: 5| Step: 8
Training loss: 0.10290636867284775
Validation loss: 1.4827964011059012

Epoch: 5| Step: 9
Training loss: 0.0795716717839241
Validation loss: 1.485046762292103

Epoch: 5| Step: 10
Training loss: 0.1535469889640808
Validation loss: 1.5070314285575703

Epoch: 564| Step: 0
Training loss: 0.12505678832530975
Validation loss: 1.5313236726227628

Epoch: 5| Step: 1
Training loss: 0.09288851916790009
Validation loss: 1.542625109354655

Epoch: 5| Step: 2
Training loss: 0.1544310599565506
Validation loss: 1.548841695631704

Epoch: 5| Step: 3
Training loss: 0.07088710367679596
Validation loss: 1.5591432125337663

Epoch: 5| Step: 4
Training loss: 0.1330442726612091
Validation loss: 1.5652347354478733

Epoch: 5| Step: 5
Training loss: 0.1056489497423172
Validation loss: 1.5593691256738478

Epoch: 5| Step: 6
Training loss: 0.08342103660106659
Validation loss: 1.5529791911443074

Epoch: 5| Step: 7
Training loss: 0.1335010528564453
Validation loss: 1.5695034175790765

Epoch: 5| Step: 8
Training loss: 0.08046988397836685
Validation loss: 1.574472931123549

Epoch: 5| Step: 9
Training loss: 0.1810118407011032
Validation loss: 1.5921849409739177

Epoch: 5| Step: 10
Training loss: 0.06381041556596756
Validation loss: 1.6019511581749044

Epoch: 565| Step: 0
Training loss: 0.1742815524339676
Validation loss: 1.5978146253093597

Epoch: 5| Step: 1
Training loss: 0.11283447593450546
Validation loss: 1.5849651187978766

Epoch: 5| Step: 2
Training loss: 0.10001388937234879
Validation loss: 1.569454857098159

Epoch: 5| Step: 3
Training loss: 0.15400239825248718
Validation loss: 1.5879214745695873

Epoch: 5| Step: 4
Training loss: 0.06392330676317215
Validation loss: 1.5869234608065697

Epoch: 5| Step: 5
Training loss: 0.10105638206005096
Validation loss: 1.5631190871679654

Epoch: 5| Step: 6
Training loss: 0.14396712183952332
Validation loss: 1.5824056274147444

Epoch: 5| Step: 7
Training loss: 0.1271074265241623
Validation loss: 1.5760757186079537

Epoch: 5| Step: 8
Training loss: 0.15513905882835388
Validation loss: 1.555836428878128

Epoch: 5| Step: 9
Training loss: 0.09408905357122421
Validation loss: 1.5129721510794856

Epoch: 5| Step: 10
Training loss: 0.05747444927692413
Validation loss: 1.5102058918245378

Epoch: 566| Step: 0
Training loss: 0.09134100377559662
Validation loss: 1.497278823647448

Epoch: 5| Step: 1
Training loss: 0.1377268135547638
Validation loss: 1.4950567567220299

Epoch: 5| Step: 2
Training loss: 0.141087144613266
Validation loss: 1.4978450459818686

Epoch: 5| Step: 3
Training loss: 0.1498917192220688
Validation loss: 1.503443996111552

Epoch: 5| Step: 4
Training loss: 0.0923515111207962
Validation loss: 1.5011691752300467

Epoch: 5| Step: 5
Training loss: 0.13277985155582428
Validation loss: 1.5169403719645675

Epoch: 5| Step: 6
Training loss: 0.06496457010507584
Validation loss: 1.5289610175676243

Epoch: 5| Step: 7
Training loss: 0.12869469821453094
Validation loss: 1.5211828190793273

Epoch: 5| Step: 8
Training loss: 0.09894968569278717
Validation loss: 1.527656236002522

Epoch: 5| Step: 9
Training loss: 0.09175947308540344
Validation loss: 1.5069438590798327

Epoch: 5| Step: 10
Training loss: 0.16998256742954254
Validation loss: 1.5088743753330682

Epoch: 567| Step: 0
Training loss: 0.13940685987472534
Validation loss: 1.4905950074554772

Epoch: 5| Step: 1
Training loss: 0.10099691152572632
Validation loss: 1.5143575514516523

Epoch: 5| Step: 2
Training loss: 0.09579510986804962
Validation loss: 1.4937649798649613

Epoch: 5| Step: 3
Training loss: 0.06200529262423515
Validation loss: 1.5105267263227893

Epoch: 5| Step: 4
Training loss: 0.12077128887176514
Validation loss: 1.5153188833626368

Epoch: 5| Step: 5
Training loss: 0.0819951742887497
Validation loss: 1.5317265064485612

Epoch: 5| Step: 6
Training loss: 0.11014249175786972
Validation loss: 1.5505126548069779

Epoch: 5| Step: 7
Training loss: 0.11471536010503769
Validation loss: 1.5269783645547845

Epoch: 5| Step: 8
Training loss: 0.09052150696516037
Validation loss: 1.5156814308576687

Epoch: 5| Step: 9
Training loss: 0.12878963351249695
Validation loss: 1.5297198039229198

Epoch: 5| Step: 10
Training loss: 0.13534054160118103
Validation loss: 1.5590844615813224

Epoch: 568| Step: 0
Training loss: 0.06913365423679352
Validation loss: 1.5739873564371498

Epoch: 5| Step: 1
Training loss: 0.09789250791072845
Validation loss: 1.5519727994036931

Epoch: 5| Step: 2
Training loss: 0.11835982650518417
Validation loss: 1.552784565956362

Epoch: 5| Step: 3
Training loss: 0.14589282870292664
Validation loss: 1.536324554874051

Epoch: 5| Step: 4
Training loss: 0.06258783489465714
Validation loss: 1.555656704851376

Epoch: 5| Step: 5
Training loss: 0.13440492749214172
Validation loss: 1.5417340801608177

Epoch: 5| Step: 6
Training loss: 0.07719980925321579
Validation loss: 1.5374351778338033

Epoch: 5| Step: 7
Training loss: 0.14268596470355988
Validation loss: 1.5371072151327645

Epoch: 5| Step: 8
Training loss: 0.06860534101724625
Validation loss: 1.5169570779287687

Epoch: 5| Step: 9
Training loss: 0.09904234856367111
Validation loss: 1.536730485577737

Epoch: 5| Step: 10
Training loss: 0.1516007035970688
Validation loss: 1.5282715418005501

Epoch: 569| Step: 0
Training loss: 0.08774124085903168
Validation loss: 1.5359430845065782

Epoch: 5| Step: 1
Training loss: 0.11982496827840805
Validation loss: 1.5500221675442112

Epoch: 5| Step: 2
Training loss: 0.07107995450496674
Validation loss: 1.542530636633596

Epoch: 5| Step: 3
Training loss: 0.12705157697200775
Validation loss: 1.5400784220746768

Epoch: 5| Step: 4
Training loss: 0.06425909698009491
Validation loss: 1.5446535387346823

Epoch: 5| Step: 5
Training loss: 0.1007893905043602
Validation loss: 1.5709245935563119

Epoch: 5| Step: 6
Training loss: 0.09079942852258682
Validation loss: 1.5750116186757241

Epoch: 5| Step: 7
Training loss: 0.10262705385684967
Validation loss: 1.555096168671885

Epoch: 5| Step: 8
Training loss: 0.10835957527160645
Validation loss: 1.5701024609227334

Epoch: 5| Step: 9
Training loss: 0.10185153782367706
Validation loss: 1.5650096272909513

Epoch: 5| Step: 10
Training loss: 0.1269611120223999
Validation loss: 1.547159892256542

Epoch: 570| Step: 0
Training loss: 0.09014665335416794
Validation loss: 1.512501915936829

Epoch: 5| Step: 1
Training loss: 0.09533382952213287
Validation loss: 1.5251310204946866

Epoch: 5| Step: 2
Training loss: 0.057301901280879974
Validation loss: 1.5351203692856656

Epoch: 5| Step: 3
Training loss: 0.0750817358493805
Validation loss: 1.5029207006577523

Epoch: 5| Step: 4
Training loss: 0.09969167411327362
Validation loss: 1.5260868636510705

Epoch: 5| Step: 5
Training loss: 0.16592267155647278
Validation loss: 1.516882001712758

Epoch: 5| Step: 6
Training loss: 0.09311380237340927
Validation loss: 1.519739281746649

Epoch: 5| Step: 7
Training loss: 0.0823969691991806
Validation loss: 1.5035366332659157

Epoch: 5| Step: 8
Training loss: 0.07793791592121124
Validation loss: 1.5185115952645578

Epoch: 5| Step: 9
Training loss: 0.08383785933256149
Validation loss: 1.5015865237482133

Epoch: 5| Step: 10
Training loss: 0.14937260746955872
Validation loss: 1.5189790027115935

Epoch: 571| Step: 0
Training loss: 0.1092933863401413
Validation loss: 1.5273168830461399

Epoch: 5| Step: 1
Training loss: 0.08440341800451279
Validation loss: 1.4986467765223594

Epoch: 5| Step: 2
Training loss: 0.1153435930609703
Validation loss: 1.5023610553433817

Epoch: 5| Step: 3
Training loss: 0.1533062756061554
Validation loss: 1.5016315906278548

Epoch: 5| Step: 4
Training loss: 0.10277567058801651
Validation loss: 1.5355832730570147

Epoch: 5| Step: 5
Training loss: 0.10532520711421967
Validation loss: 1.5050792822273829

Epoch: 5| Step: 6
Training loss: 0.08101166784763336
Validation loss: 1.537272737872216

Epoch: 5| Step: 7
Training loss: 0.09002141654491425
Validation loss: 1.5222154586545882

Epoch: 5| Step: 8
Training loss: 0.03520180284976959
Validation loss: 1.5239948880287908

Epoch: 5| Step: 9
Training loss: 0.07538732886314392
Validation loss: 1.526066739072082

Epoch: 5| Step: 10
Training loss: 0.08854318410158157
Validation loss: 1.5122855594081264

Epoch: 572| Step: 0
Training loss: 0.1143004447221756
Validation loss: 1.5325849697154055

Epoch: 5| Step: 1
Training loss: 0.12465775012969971
Validation loss: 1.5541220300941057

Epoch: 5| Step: 2
Training loss: 0.07247374951839447
Validation loss: 1.508503742115472

Epoch: 5| Step: 3
Training loss: 0.1548784077167511
Validation loss: 1.5152162518552554

Epoch: 5| Step: 4
Training loss: 0.08283758163452148
Validation loss: 1.539880032180458

Epoch: 5| Step: 5
Training loss: 0.1099935993552208
Validation loss: 1.5275985092245123

Epoch: 5| Step: 6
Training loss: 0.07264219969511032
Validation loss: 1.5476399493473831

Epoch: 5| Step: 7
Training loss: 0.07682988792657852
Validation loss: 1.529983756362751

Epoch: 5| Step: 8
Training loss: 0.08295059204101562
Validation loss: 1.5470221273360714

Epoch: 5| Step: 9
Training loss: 0.04767284542322159
Validation loss: 1.5312427115696732

Epoch: 5| Step: 10
Training loss: 0.09052372723817825
Validation loss: 1.5049233833948772

Epoch: 573| Step: 0
Training loss: 0.05855631083250046
Validation loss: 1.533180082997968

Epoch: 5| Step: 1
Training loss: 0.09922812879085541
Validation loss: 1.503374881641839

Epoch: 5| Step: 2
Training loss: 0.09400905668735504
Validation loss: 1.5406441009172829

Epoch: 5| Step: 3
Training loss: 0.07204582542181015
Validation loss: 1.5088564003667524

Epoch: 5| Step: 4
Training loss: 0.11230359226465225
Validation loss: 1.5545738602197299

Epoch: 5| Step: 5
Training loss: 0.07376221567392349
Validation loss: 1.543325621594665

Epoch: 5| Step: 6
Training loss: 0.14090827107429504
Validation loss: 1.541738615882012

Epoch: 5| Step: 7
Training loss: 0.07898522913455963
Validation loss: 1.5226328757501417

Epoch: 5| Step: 8
Training loss: 0.08374173939228058
Validation loss: 1.5241884467422322

Epoch: 5| Step: 9
Training loss: 0.06609463691711426
Validation loss: 1.5105634902113227

Epoch: 5| Step: 10
Training loss: 0.0994991660118103
Validation loss: 1.5388977963437316

Epoch: 574| Step: 0
Training loss: 0.15982584655284882
Validation loss: 1.546070739787112

Epoch: 5| Step: 1
Training loss: 0.08558689057826996
Validation loss: 1.550105417928388

Epoch: 5| Step: 2
Training loss: 0.07035855203866959
Validation loss: 1.5434189035046486

Epoch: 5| Step: 3
Training loss: 0.07652311772108078
Validation loss: 1.5229184281441472

Epoch: 5| Step: 4
Training loss: 0.11556863784790039
Validation loss: 1.535170683296778

Epoch: 5| Step: 5
Training loss: 0.08140160888433456
Validation loss: 1.5328943934491885

Epoch: 5| Step: 6
Training loss: 0.11156189441680908
Validation loss: 1.5423992449237454

Epoch: 5| Step: 7
Training loss: 0.08923885971307755
Validation loss: 1.5712174651443318

Epoch: 5| Step: 8
Training loss: 0.08425968140363693
Validation loss: 1.5179150950524114

Epoch: 5| Step: 9
Training loss: 0.08617415279150009
Validation loss: 1.5370905232685868

Epoch: 5| Step: 10
Training loss: 0.0787174254655838
Validation loss: 1.5285934120096185

Epoch: 575| Step: 0
Training loss: 0.10812175273895264
Validation loss: 1.5346885432479203

Epoch: 5| Step: 1
Training loss: 0.1098770871758461
Validation loss: 1.5146449676123999

Epoch: 5| Step: 2
Training loss: 0.09616922587156296
Validation loss: 1.534627737537507

Epoch: 5| Step: 3
Training loss: 0.10006885230541229
Validation loss: 1.520179307588967

Epoch: 5| Step: 4
Training loss: 0.0933009460568428
Validation loss: 1.5333228277903732

Epoch: 5| Step: 5
Training loss: 0.06790966540575027
Validation loss: 1.5211741257739324

Epoch: 5| Step: 6
Training loss: 0.12149493396282196
Validation loss: 1.5562945104414416

Epoch: 5| Step: 7
Training loss: 0.12358476966619492
Validation loss: 1.5352094532341085

Epoch: 5| Step: 8
Training loss: 0.08498334139585495
Validation loss: 1.5521632298346488

Epoch: 5| Step: 9
Training loss: 0.06889347732067108
Validation loss: 1.546263930618122

Epoch: 5| Step: 10
Training loss: 0.10938399285078049
Validation loss: 1.5603298141110329

Epoch: 576| Step: 0
Training loss: 0.10095204412937164
Validation loss: 1.5470356979677755

Epoch: 5| Step: 1
Training loss: 0.09529516100883484
Validation loss: 1.5614768382041686

Epoch: 5| Step: 2
Training loss: 0.07552894204854965
Validation loss: 1.563018956492024

Epoch: 5| Step: 3
Training loss: 0.1344551295042038
Validation loss: 1.5628353652133737

Epoch: 5| Step: 4
Training loss: 0.11991994082927704
Validation loss: 1.5244494343316684

Epoch: 5| Step: 5
Training loss: 0.0869147926568985
Validation loss: 1.5240969606625137

Epoch: 5| Step: 6
Training loss: 0.09283076226711273
Validation loss: 1.506811180422383

Epoch: 5| Step: 7
Training loss: 0.05268874764442444
Validation loss: 1.5180472987954334

Epoch: 5| Step: 8
Training loss: 0.10882089287042618
Validation loss: 1.5227730069109189

Epoch: 5| Step: 9
Training loss: 0.14517360925674438
Validation loss: 1.5216277889026109

Epoch: 5| Step: 10
Training loss: 0.09047337621450424
Validation loss: 1.5139399927149537

Epoch: 577| Step: 0
Training loss: 0.1107134222984314
Validation loss: 1.5108491810419227

Epoch: 5| Step: 1
Training loss: 0.1662578582763672
Validation loss: 1.51088378249958

Epoch: 5| Step: 2
Training loss: 0.09257258474826813
Validation loss: 1.5141547995228921

Epoch: 5| Step: 3
Training loss: 0.0720062106847763
Validation loss: 1.528541785414501

Epoch: 5| Step: 4
Training loss: 0.08402349054813385
Validation loss: 1.5499281191056775

Epoch: 5| Step: 5
Training loss: 0.10738400369882584
Validation loss: 1.547513719527952

Epoch: 5| Step: 6
Training loss: 0.06954991072416306
Validation loss: 1.5528695403888662

Epoch: 5| Step: 7
Training loss: 0.1013251543045044
Validation loss: 1.5985340777263846

Epoch: 5| Step: 8
Training loss: 0.10207313299179077
Validation loss: 1.555613140906057

Epoch: 5| Step: 9
Training loss: 0.0839570015668869
Validation loss: 1.567963465567558

Epoch: 5| Step: 10
Training loss: 0.11393016576766968
Validation loss: 1.5695188596684446

Epoch: 578| Step: 0
Training loss: 0.0790162906050682
Validation loss: 1.5301043122045455

Epoch: 5| Step: 1
Training loss: 0.07616466283798218
Validation loss: 1.5086879102132653

Epoch: 5| Step: 2
Training loss: 0.11910732835531235
Validation loss: 1.5166915411590247

Epoch: 5| Step: 3
Training loss: 0.14099593460559845
Validation loss: 1.5231187590347823

Epoch: 5| Step: 4
Training loss: 0.09259023517370224
Validation loss: 1.5298883722674461

Epoch: 5| Step: 5
Training loss: 0.14140582084655762
Validation loss: 1.53093933802779

Epoch: 5| Step: 6
Training loss: 0.11889217048883438
Validation loss: 1.545513560695033

Epoch: 5| Step: 7
Training loss: 0.08272053301334381
Validation loss: 1.5181639553398214

Epoch: 5| Step: 8
Training loss: 0.09020188450813293
Validation loss: 1.5554421864530092

Epoch: 5| Step: 9
Training loss: 0.12967680394649506
Validation loss: 1.5080326552032142

Epoch: 5| Step: 10
Training loss: 0.08455189317464828
Validation loss: 1.4967772191570652

Epoch: 579| Step: 0
Training loss: 0.10098043829202652
Validation loss: 1.5250159181574339

Epoch: 5| Step: 1
Training loss: 0.0975891575217247
Validation loss: 1.5270292105213288

Epoch: 5| Step: 2
Training loss: 0.12504008412361145
Validation loss: 1.512167461456791

Epoch: 5| Step: 3
Training loss: 0.13070878386497498
Validation loss: 1.5229917713390884

Epoch: 5| Step: 4
Training loss: 0.06399078667163849
Validation loss: 1.5243545821917954

Epoch: 5| Step: 5
Training loss: 0.07912112772464752
Validation loss: 1.553068591702369

Epoch: 5| Step: 6
Training loss: 0.17905905842781067
Validation loss: 1.5722722135564333

Epoch: 5| Step: 7
Training loss: 0.16331663727760315
Validation loss: 1.5859236896678965

Epoch: 5| Step: 8
Training loss: 0.09749516099691391
Validation loss: 1.5932352747968448

Epoch: 5| Step: 9
Training loss: 0.165481835603714
Validation loss: 1.571261675127091

Epoch: 5| Step: 10
Training loss: 0.07507079839706421
Validation loss: 1.5483484409188712

Epoch: 580| Step: 0
Training loss: 0.1016395092010498
Validation loss: 1.5706733260103451

Epoch: 5| Step: 1
Training loss: 0.09040573984384537
Validation loss: 1.5351614426541071

Epoch: 5| Step: 2
Training loss: 0.1472465991973877
Validation loss: 1.5375228261434903

Epoch: 5| Step: 3
Training loss: 0.11419246345758438
Validation loss: 1.5627534363859443

Epoch: 5| Step: 4
Training loss: 0.11724159866571426
Validation loss: 1.5665671569044872

Epoch: 5| Step: 5
Training loss: 0.10669174045324326
Validation loss: 1.555357479280041

Epoch: 5| Step: 6
Training loss: 0.12892842292785645
Validation loss: 1.5835683166339833

Epoch: 5| Step: 7
Training loss: 0.0515584833920002
Validation loss: 1.558275173428238

Epoch: 5| Step: 8
Training loss: 0.15391162037849426
Validation loss: 1.5909851392110188

Epoch: 5| Step: 9
Training loss: 0.12096265703439713
Validation loss: 1.5623466225080593

Epoch: 5| Step: 10
Training loss: 0.14791622757911682
Validation loss: 1.5410231774853123

Epoch: 581| Step: 0
Training loss: 0.10446806252002716
Validation loss: 1.554283470235845

Epoch: 5| Step: 1
Training loss: 0.07779574394226074
Validation loss: 1.551236238530887

Epoch: 5| Step: 2
Training loss: 0.10753600299358368
Validation loss: 1.5331479580171647

Epoch: 5| Step: 3
Training loss: 0.1190575510263443
Validation loss: 1.5145917656601116

Epoch: 5| Step: 4
Training loss: 0.07623416185379028
Validation loss: 1.5301060086937361

Epoch: 5| Step: 5
Training loss: 0.10124242305755615
Validation loss: 1.4952055356835807

Epoch: 5| Step: 6
Training loss: 0.10386071354150772
Validation loss: 1.540469023489183

Epoch: 5| Step: 7
Training loss: 0.12988437712192535
Validation loss: 1.542022006486052

Epoch: 5| Step: 8
Training loss: 0.06312905997037888
Validation loss: 1.5378545894417712

Epoch: 5| Step: 9
Training loss: 0.11087413877248764
Validation loss: 1.5435646810839254

Epoch: 5| Step: 10
Training loss: 0.12349481880664825
Validation loss: 1.5555319247707244

Epoch: 582| Step: 0
Training loss: 0.10208934545516968
Validation loss: 1.5712729846277544

Epoch: 5| Step: 1
Training loss: 0.11694811284542084
Validation loss: 1.558656290013303

Epoch: 5| Step: 2
Training loss: 0.11136671155691147
Validation loss: 1.5455600958998486

Epoch: 5| Step: 3
Training loss: 0.08948151767253876
Validation loss: 1.5389768462027273

Epoch: 5| Step: 4
Training loss: 0.09065882116556168
Validation loss: 1.5315327323893064

Epoch: 5| Step: 5
Training loss: 0.17405559122562408
Validation loss: 1.494077600458617

Epoch: 5| Step: 6
Training loss: 0.08300678431987762
Validation loss: 1.50668014249494

Epoch: 5| Step: 7
Training loss: 0.09695829451084137
Validation loss: 1.5130856703686457

Epoch: 5| Step: 8
Training loss: 0.10715875774621964
Validation loss: 1.5175723542449295

Epoch: 5| Step: 9
Training loss: 0.0831984207034111
Validation loss: 1.5179217476998605

Epoch: 5| Step: 10
Training loss: 0.12733094394207
Validation loss: 1.5182667163110548

Epoch: 583| Step: 0
Training loss: 0.11675029993057251
Validation loss: 1.5276592220029523

Epoch: 5| Step: 1
Training loss: 0.08824565261602402
Validation loss: 1.551722058685877

Epoch: 5| Step: 2
Training loss: 0.11320872604846954
Validation loss: 1.54991780301576

Epoch: 5| Step: 3
Training loss: 0.09291799366474152
Validation loss: 1.5546860733339865

Epoch: 5| Step: 4
Training loss: 0.08993431180715561
Validation loss: 1.5695981229505231

Epoch: 5| Step: 5
Training loss: 0.04641490429639816
Validation loss: 1.5514327979856921

Epoch: 5| Step: 6
Training loss: 0.12282389402389526
Validation loss: 1.5643313187424854

Epoch: 5| Step: 7
Training loss: 0.1583525687456131
Validation loss: 1.5688815552701232

Epoch: 5| Step: 8
Training loss: 0.055858056992292404
Validation loss: 1.5717425974466468

Epoch: 5| Step: 9
Training loss: 0.14448407292366028
Validation loss: 1.5605293166252874

Epoch: 5| Step: 10
Training loss: 0.07023286819458008
Validation loss: 1.5757458568901144

Epoch: 584| Step: 0
Training loss: 0.10416306555271149
Validation loss: 1.6065359961601995

Epoch: 5| Step: 1
Training loss: 0.0767395868897438
Validation loss: 1.5608281217595583

Epoch: 5| Step: 2
Training loss: 0.08822716772556305
Validation loss: 1.5772283936059603

Epoch: 5| Step: 3
Training loss: 0.1011526808142662
Validation loss: 1.5846511292201217

Epoch: 5| Step: 4
Training loss: 0.16099385917186737
Validation loss: 1.557141120715808

Epoch: 5| Step: 5
Training loss: 0.06428054720163345
Validation loss: 1.5393125664803289

Epoch: 5| Step: 6
Training loss: 0.04073423892259598
Validation loss: 1.5306686239857827

Epoch: 5| Step: 7
Training loss: 0.07966164499521255
Validation loss: 1.5248619459008659

Epoch: 5| Step: 8
Training loss: 0.11983253806829453
Validation loss: 1.5036352635711752

Epoch: 5| Step: 9
Training loss: 0.07447995990514755
Validation loss: 1.490671823101659

Epoch: 5| Step: 10
Training loss: 0.15248169004917145
Validation loss: 1.500672560866161

Epoch: 585| Step: 0
Training loss: 0.11024919897317886
Validation loss: 1.509408212477161

Epoch: 5| Step: 1
Training loss: 0.14975664019584656
Validation loss: 1.4931518211159656

Epoch: 5| Step: 2
Training loss: 0.10287592560052872
Validation loss: 1.5051860693962342

Epoch: 5| Step: 3
Training loss: 0.0662832036614418
Validation loss: 1.5096288996358072

Epoch: 5| Step: 4
Training loss: 0.09011299163103104
Validation loss: 1.547723472759288

Epoch: 5| Step: 5
Training loss: 0.09985753893852234
Validation loss: 1.536489576421758

Epoch: 5| Step: 6
Training loss: 0.1094619408249855
Validation loss: 1.5265964602911344

Epoch: 5| Step: 7
Training loss: 0.08211235702037811
Validation loss: 1.5342361670668407

Epoch: 5| Step: 8
Training loss: 0.0783560499548912
Validation loss: 1.5636943905584273

Epoch: 5| Step: 9
Training loss: 0.11047748476266861
Validation loss: 1.5481748606569024

Epoch: 5| Step: 10
Training loss: 0.0745440125465393
Validation loss: 1.5409356189030472

Epoch: 586| Step: 0
Training loss: 0.11996719986200333
Validation loss: 1.5398274852383522

Epoch: 5| Step: 1
Training loss: 0.1256461888551712
Validation loss: 1.5614970012377667

Epoch: 5| Step: 2
Training loss: 0.08076561987400055
Validation loss: 1.5460566987273514

Epoch: 5| Step: 3
Training loss: 0.08168474584817886
Validation loss: 1.5585092626592165

Epoch: 5| Step: 4
Training loss: 0.09983564913272858
Validation loss: 1.534480784528999

Epoch: 5| Step: 5
Training loss: 0.04737343639135361
Validation loss: 1.5160459664560133

Epoch: 5| Step: 6
Training loss: 0.12927672266960144
Validation loss: 1.532127534189532

Epoch: 5| Step: 7
Training loss: 0.06092999130487442
Validation loss: 1.5256271054667812

Epoch: 5| Step: 8
Training loss: 0.04842584952712059
Validation loss: 1.5174735323075326

Epoch: 5| Step: 9
Training loss: 0.07514580339193344
Validation loss: 1.5153001277677474

Epoch: 5| Step: 10
Training loss: 0.12200864404439926
Validation loss: 1.5079845542548804

Epoch: 587| Step: 0
Training loss: 0.07611598819494247
Validation loss: 1.4975943732005295

Epoch: 5| Step: 1
Training loss: 0.0891878679394722
Validation loss: 1.5189980242841987

Epoch: 5| Step: 2
Training loss: 0.145650252699852
Validation loss: 1.5077401758522115

Epoch: 5| Step: 3
Training loss: 0.11548361927270889
Validation loss: 1.5173831889706273

Epoch: 5| Step: 4
Training loss: 0.10388033092021942
Validation loss: 1.5354997316996257

Epoch: 5| Step: 5
Training loss: 0.0634002834558487
Validation loss: 1.5471484814920733

Epoch: 5| Step: 6
Training loss: 0.06298572570085526
Validation loss: 1.532870219599816

Epoch: 5| Step: 7
Training loss: 0.08329720050096512
Validation loss: 1.55886165044641

Epoch: 5| Step: 8
Training loss: 0.13538286089897156
Validation loss: 1.5672694765111452

Epoch: 5| Step: 9
Training loss: 0.10103289783000946
Validation loss: 1.5617655579761793

Epoch: 5| Step: 10
Training loss: 0.0986671894788742
Validation loss: 1.5701031979694162

Epoch: 588| Step: 0
Training loss: 0.07068460434675217
Validation loss: 1.5599019719708351

Epoch: 5| Step: 1
Training loss: 0.10434393584728241
Validation loss: 1.5609402733464395

Epoch: 5| Step: 2
Training loss: 0.06328699737787247
Validation loss: 1.5623581165908484

Epoch: 5| Step: 3
Training loss: 0.0754493847489357
Validation loss: 1.5549107418265393

Epoch: 5| Step: 4
Training loss: 0.06925185024738312
Validation loss: 1.5773013740457513

Epoch: 5| Step: 5
Training loss: 0.10371991246938705
Validation loss: 1.5642315867126628

Epoch: 5| Step: 6
Training loss: 0.08037324249744415
Validation loss: 1.5832726775958974

Epoch: 5| Step: 7
Training loss: 0.14379701018333435
Validation loss: 1.5850017122043076

Epoch: 5| Step: 8
Training loss: 0.1314728558063507
Validation loss: 1.584547431238236

Epoch: 5| Step: 9
Training loss: 0.16751828789710999
Validation loss: 1.6196270937560706

Epoch: 5| Step: 10
Training loss: 0.16834834218025208
Validation loss: 1.562730981457618

Epoch: 589| Step: 0
Training loss: 0.10081355273723602
Validation loss: 1.5422380367914836

Epoch: 5| Step: 1
Training loss: 0.10644696652889252
Validation loss: 1.526895938381072

Epoch: 5| Step: 2
Training loss: 0.11476047337055206
Validation loss: 1.5115330014177548

Epoch: 5| Step: 3
Training loss: 0.14477553963661194
Validation loss: 1.5428094556254726

Epoch: 5| Step: 4
Training loss: 0.1113521084189415
Validation loss: 1.5528195481146536

Epoch: 5| Step: 5
Training loss: 0.10342548042535782
Validation loss: 1.5492128864411385

Epoch: 5| Step: 6
Training loss: 0.08952272683382034
Validation loss: 1.542353255774385

Epoch: 5| Step: 7
Training loss: 0.1736360490322113
Validation loss: 1.614641821512612

Epoch: 5| Step: 8
Training loss: 0.1925952136516571
Validation loss: 1.6350159401534705

Epoch: 5| Step: 9
Training loss: 0.1449730396270752
Validation loss: 1.6137762941339964

Epoch: 5| Step: 10
Training loss: 0.0906810313463211
Validation loss: 1.6111750077175837

Epoch: 590| Step: 0
Training loss: 0.08779691904783249
Validation loss: 1.5648894656089045

Epoch: 5| Step: 1
Training loss: 0.07814553380012512
Validation loss: 1.5513377945910218

Epoch: 5| Step: 2
Training loss: 0.0951230525970459
Validation loss: 1.5343502336932766

Epoch: 5| Step: 3
Training loss: 0.1247464194893837
Validation loss: 1.5546158693170036

Epoch: 5| Step: 4
Training loss: 0.13390663266181946
Validation loss: 1.540709472471668

Epoch: 5| Step: 5
Training loss: 0.061888210475444794
Validation loss: 1.5541432083293956

Epoch: 5| Step: 6
Training loss: 0.11000214517116547
Validation loss: 1.5382031766317223

Epoch: 5| Step: 7
Training loss: 0.14401760697364807
Validation loss: 1.5333759310424968

Epoch: 5| Step: 8
Training loss: 0.07102074474096298
Validation loss: 1.530830285241527

Epoch: 5| Step: 9
Training loss: 0.09170167148113251
Validation loss: 1.510129136423911

Epoch: 5| Step: 10
Training loss: 0.10903287678956985
Validation loss: 1.517691466116136

Epoch: 591| Step: 0
Training loss: 0.12322378158569336
Validation loss: 1.5035442972695956

Epoch: 5| Step: 1
Training loss: 0.09172938764095306
Validation loss: 1.5019504536864579

Epoch: 5| Step: 2
Training loss: 0.05855174735188484
Validation loss: 1.5039487179889475

Epoch: 5| Step: 3
Training loss: 0.10568936914205551
Validation loss: 1.5112378763896164

Epoch: 5| Step: 4
Training loss: 0.09285639226436615
Validation loss: 1.5288573118948168

Epoch: 5| Step: 5
Training loss: 0.10616445541381836
Validation loss: 1.4951504968827771

Epoch: 5| Step: 6
Training loss: 0.07550303637981415
Validation loss: 1.5098076815246253

Epoch: 5| Step: 7
Training loss: 0.066880002617836
Validation loss: 1.490547409621618

Epoch: 5| Step: 8
Training loss: 0.07009299099445343
Validation loss: 1.5213497197756203

Epoch: 5| Step: 9
Training loss: 0.06549596786499023
Validation loss: 1.5033188994212816

Epoch: 5| Step: 10
Training loss: 0.12880781292915344
Validation loss: 1.4959965444380237

Epoch: 592| Step: 0
Training loss: 0.11346845328807831
Validation loss: 1.5218390431455386

Epoch: 5| Step: 1
Training loss: 0.0973382219672203
Validation loss: 1.530964634751761

Epoch: 5| Step: 2
Training loss: 0.1034364104270935
Validation loss: 1.5201574064070178

Epoch: 5| Step: 3
Training loss: 0.1021103635430336
Validation loss: 1.5391830359735796

Epoch: 5| Step: 4
Training loss: 0.08539943397045135
Validation loss: 1.5231112728836715

Epoch: 5| Step: 5
Training loss: 0.11053912341594696
Validation loss: 1.5632735477980746

Epoch: 5| Step: 6
Training loss: 0.07378765195608139
Validation loss: 1.557712548522539

Epoch: 5| Step: 7
Training loss: 0.08112485706806183
Validation loss: 1.5655111382084508

Epoch: 5| Step: 8
Training loss: 0.06718037277460098
Validation loss: 1.5614130663615402

Epoch: 5| Step: 9
Training loss: 0.08435140550136566
Validation loss: 1.5300371223880398

Epoch: 5| Step: 10
Training loss: 0.043855324387550354
Validation loss: 1.5083435466212611

Epoch: 593| Step: 0
Training loss: 0.10472533851861954
Validation loss: 1.493979605295325

Epoch: 5| Step: 1
Training loss: 0.08162697404623032
Validation loss: 1.5160093063949256

Epoch: 5| Step: 2
Training loss: 0.08710131049156189
Validation loss: 1.50615265036142

Epoch: 5| Step: 3
Training loss: 0.07964648306369781
Validation loss: 1.5135853623831144

Epoch: 5| Step: 4
Training loss: 0.0632709339261055
Validation loss: 1.5470256100418747

Epoch: 5| Step: 5
Training loss: 0.05679548904299736
Validation loss: 1.5296853947383102

Epoch: 5| Step: 6
Training loss: 0.12141022831201553
Validation loss: 1.5229504223792785

Epoch: 5| Step: 7
Training loss: 0.06310918182134628
Validation loss: 1.5236125761462795

Epoch: 5| Step: 8
Training loss: 0.09436656534671783
Validation loss: 1.5477903882662456

Epoch: 5| Step: 9
Training loss: 0.08917834609746933
Validation loss: 1.5273092741607337

Epoch: 5| Step: 10
Training loss: 0.0931008905172348
Validation loss: 1.5213523321254279

Epoch: 594| Step: 0
Training loss: 0.1257205307483673
Validation loss: 1.5065133007623817

Epoch: 5| Step: 1
Training loss: 0.06550240516662598
Validation loss: 1.5007088799630441

Epoch: 5| Step: 2
Training loss: 0.07880018651485443
Validation loss: 1.5081962244485014

Epoch: 5| Step: 3
Training loss: 0.11419333517551422
Validation loss: 1.498207196112602

Epoch: 5| Step: 4
Training loss: 0.10407695919275284
Validation loss: 1.5106848452680854

Epoch: 5| Step: 5
Training loss: 0.12155640125274658
Validation loss: 1.5342391107672004

Epoch: 5| Step: 6
Training loss: 0.1630220115184784
Validation loss: 1.542098032530918

Epoch: 5| Step: 7
Training loss: 0.15161851048469543
Validation loss: 1.5160078579379666

Epoch: 5| Step: 8
Training loss: 0.12151162326335907
Validation loss: 1.5866099249932073

Epoch: 5| Step: 9
Training loss: 0.10888490825891495
Validation loss: 1.5764166706351823

Epoch: 5| Step: 10
Training loss: 0.09257709234952927
Validation loss: 1.591667761084854

Epoch: 595| Step: 0
Training loss: 0.08476188778877258
Validation loss: 1.5934520754762875

Epoch: 5| Step: 1
Training loss: 0.12305011600255966
Validation loss: 1.624322997626438

Epoch: 5| Step: 2
Training loss: 0.1004619225859642
Validation loss: 1.5976227406532533

Epoch: 5| Step: 3
Training loss: 0.07156001031398773
Validation loss: 1.6164404769097604

Epoch: 5| Step: 4
Training loss: 0.12990787625312805
Validation loss: 1.620475152487396

Epoch: 5| Step: 5
Training loss: 0.13178804516792297
Validation loss: 1.5744758793102798

Epoch: 5| Step: 6
Training loss: 0.08794546127319336
Validation loss: 1.5904996548929522

Epoch: 5| Step: 7
Training loss: 0.0774647518992424
Validation loss: 1.552733439271168

Epoch: 5| Step: 8
Training loss: 0.12421488761901855
Validation loss: 1.54858233082679

Epoch: 5| Step: 9
Training loss: 0.08383335173130035
Validation loss: 1.5451378027598064

Epoch: 5| Step: 10
Training loss: 0.1331295371055603
Validation loss: 1.5484628831186602

Epoch: 596| Step: 0
Training loss: 0.11448986828327179
Validation loss: 1.5592626884419432

Epoch: 5| Step: 1
Training loss: 0.08495012670755386
Validation loss: 1.5459830927592453

Epoch: 5| Step: 2
Training loss: 0.15761622786521912
Validation loss: 1.545410135740875

Epoch: 5| Step: 3
Training loss: 0.1352030336856842
Validation loss: 1.5181512371186288

Epoch: 5| Step: 4
Training loss: 0.08794562518596649
Validation loss: 1.489460649028901

Epoch: 5| Step: 5
Training loss: 0.08522780239582062
Validation loss: 1.489132926028262

Epoch: 5| Step: 6
Training loss: 0.07912740111351013
Validation loss: 1.5002570991875024

Epoch: 5| Step: 7
Training loss: 0.0800473541021347
Validation loss: 1.512043886287238

Epoch: 5| Step: 8
Training loss: 0.1446504145860672
Validation loss: 1.5086616380240327

Epoch: 5| Step: 9
Training loss: 0.09099187701940536
Validation loss: 1.4842129753481956

Epoch: 5| Step: 10
Training loss: 0.1936415433883667
Validation loss: 1.523875408916063

Epoch: 597| Step: 0
Training loss: 0.06690959632396698
Validation loss: 1.4999231010354974

Epoch: 5| Step: 1
Training loss: 0.10646474361419678
Validation loss: 1.5371533529732817

Epoch: 5| Step: 2
Training loss: 0.12457513809204102
Validation loss: 1.5470287082015828

Epoch: 5| Step: 3
Training loss: 0.15192429721355438
Validation loss: 1.5388202564690703

Epoch: 5| Step: 4
Training loss: 0.13170281052589417
Validation loss: 1.5574376634372178

Epoch: 5| Step: 5
Training loss: 0.07837291806936264
Validation loss: 1.5462613592865646

Epoch: 5| Step: 6
Training loss: 0.10508636385202408
Validation loss: 1.52673811809991

Epoch: 5| Step: 7
Training loss: 0.09235602617263794
Validation loss: 1.5441958519720262

Epoch: 5| Step: 8
Training loss: 0.056692611426115036
Validation loss: 1.5310740304249588

Epoch: 5| Step: 9
Training loss: 0.06239950656890869
Validation loss: 1.524357819429008

Epoch: 5| Step: 10
Training loss: 0.09945397078990936
Validation loss: 1.5443087854693014

Epoch: 598| Step: 0
Training loss: 0.16185112297534943
Validation loss: 1.5506576645758845

Epoch: 5| Step: 1
Training loss: 0.13769009709358215
Validation loss: 1.5625230035474222

Epoch: 5| Step: 2
Training loss: 0.07810167968273163
Validation loss: 1.554554247087048

Epoch: 5| Step: 3
Training loss: 0.10674679279327393
Validation loss: 1.5640114148457844

Epoch: 5| Step: 4
Training loss: 0.08078702539205551
Validation loss: 1.5472776607800556

Epoch: 5| Step: 5
Training loss: 0.07433315366506577
Validation loss: 1.5792263784716207

Epoch: 5| Step: 6
Training loss: 0.11296030133962631
Validation loss: 1.5768828340755996

Epoch: 5| Step: 7
Training loss: 0.15336091816425323
Validation loss: 1.5541021439336962

Epoch: 5| Step: 8
Training loss: 0.08218030631542206
Validation loss: 1.584175625155049

Epoch: 5| Step: 9
Training loss: 0.0724882036447525
Validation loss: 1.5518195488119637

Epoch: 5| Step: 10
Training loss: 0.09226789325475693
Validation loss: 1.5194614907746673

Epoch: 599| Step: 0
Training loss: 0.09484647214412689
Validation loss: 1.52782243041582

Epoch: 5| Step: 1
Training loss: 0.08683397620916367
Validation loss: 1.5307228834398332

Epoch: 5| Step: 2
Training loss: 0.09534543752670288
Validation loss: 1.552762141791723

Epoch: 5| Step: 3
Training loss: 0.09769900143146515
Validation loss: 1.532938229140415

Epoch: 5| Step: 4
Training loss: 0.06889341026544571
Validation loss: 1.5496620157713532

Epoch: 5| Step: 5
Training loss: 0.09627839177846909
Validation loss: 1.5607675237040366

Epoch: 5| Step: 6
Training loss: 0.07573345303535461
Validation loss: 1.5649061908004105

Epoch: 5| Step: 7
Training loss: 0.10206820070743561
Validation loss: 1.5734535160885061

Epoch: 5| Step: 8
Training loss: 0.11997830867767334
Validation loss: 1.5514884648784515

Epoch: 5| Step: 9
Training loss: 0.08000031858682632
Validation loss: 1.560665568997783

Epoch: 5| Step: 10
Training loss: 0.10357799381017685
Validation loss: 1.5545105152232672

Epoch: 600| Step: 0
Training loss: 0.07595397531986237
Validation loss: 1.5401034675618654

Epoch: 5| Step: 1
Training loss: 0.11934218555688858
Validation loss: 1.546219648853425

Epoch: 5| Step: 2
Training loss: 0.052681244909763336
Validation loss: 1.5479697296696324

Epoch: 5| Step: 3
Training loss: 0.06373143196105957
Validation loss: 1.5305974919308898

Epoch: 5| Step: 4
Training loss: 0.10781288146972656
Validation loss: 1.54523334451901

Epoch: 5| Step: 5
Training loss: 0.11703856289386749
Validation loss: 1.5344965355370634

Epoch: 5| Step: 6
Training loss: 0.07889135926961899
Validation loss: 1.532966144623295

Epoch: 5| Step: 7
Training loss: 0.12812557816505432
Validation loss: 1.5239456597194876

Epoch: 5| Step: 8
Training loss: 0.12992508709430695
Validation loss: 1.4985198295244606

Epoch: 5| Step: 9
Training loss: 0.10128025710582733
Validation loss: 1.5176102217807566

Epoch: 5| Step: 10
Training loss: 0.07482098042964935
Validation loss: 1.5127919027882237

Epoch: 601| Step: 0
Training loss: 0.09921872615814209
Validation loss: 1.4960062798633371

Epoch: 5| Step: 1
Training loss: 0.06932001560926437
Validation loss: 1.5398516616513651

Epoch: 5| Step: 2
Training loss: 0.08923625200986862
Validation loss: 1.5545563608087518

Epoch: 5| Step: 3
Training loss: 0.07383944094181061
Validation loss: 1.562847807843198

Epoch: 5| Step: 4
Training loss: 0.13024616241455078
Validation loss: 1.5640310318239274

Epoch: 5| Step: 5
Training loss: 0.05399451404809952
Validation loss: 1.5578414842646608

Epoch: 5| Step: 6
Training loss: 0.10997726768255234
Validation loss: 1.542332709476512

Epoch: 5| Step: 7
Training loss: 0.062335461378097534
Validation loss: 1.5376711468542776

Epoch: 5| Step: 8
Training loss: 0.06560822576284409
Validation loss: 1.5092687799084572

Epoch: 5| Step: 9
Training loss: 0.08297143876552582
Validation loss: 1.5198061440580635

Epoch: 5| Step: 10
Training loss: 0.08281353861093521
Validation loss: 1.5206855920053297

Epoch: 602| Step: 0
Training loss: 0.12017272412776947
Validation loss: 1.4989378503573838

Epoch: 5| Step: 1
Training loss: 0.12189469486474991
Validation loss: 1.5012876641365789

Epoch: 5| Step: 2
Training loss: 0.08279871940612793
Validation loss: 1.5165615748333674

Epoch: 5| Step: 3
Training loss: 0.06608094274997711
Validation loss: 1.5206040092693862

Epoch: 5| Step: 4
Training loss: 0.04837682843208313
Validation loss: 1.5122154387094642

Epoch: 5| Step: 5
Training loss: 0.0712413340806961
Validation loss: 1.5433180050183368

Epoch: 5| Step: 6
Training loss: 0.07350368797779083
Validation loss: 1.5423272630219818

Epoch: 5| Step: 7
Training loss: 0.10583676397800446
Validation loss: 1.5308227180152811

Epoch: 5| Step: 8
Training loss: 0.08959343284368515
Validation loss: 1.519630359065148

Epoch: 5| Step: 9
Training loss: 0.08166743814945221
Validation loss: 1.50632982612938

Epoch: 5| Step: 10
Training loss: 0.10504277795553207
Validation loss: 1.540161399431126

Epoch: 603| Step: 0
Training loss: 0.09241969883441925
Validation loss: 1.5462904912169262

Epoch: 5| Step: 1
Training loss: 0.0849224105477333
Validation loss: 1.533414904789258

Epoch: 5| Step: 2
Training loss: 0.14197146892547607
Validation loss: 1.5301139297023896

Epoch: 5| Step: 3
Training loss: 0.09840534627437592
Validation loss: 1.52999956633455

Epoch: 5| Step: 4
Training loss: 0.06857845187187195
Validation loss: 1.5281020877181843

Epoch: 5| Step: 5
Training loss: 0.11976517736911774
Validation loss: 1.5125467700342978

Epoch: 5| Step: 6
Training loss: 0.09991500526666641
Validation loss: 1.5152842460140106

Epoch: 5| Step: 7
Training loss: 0.10696816444396973
Validation loss: 1.5019518316432994

Epoch: 5| Step: 8
Training loss: 0.0794430822134018
Validation loss: 1.4768534783394105

Epoch: 5| Step: 9
Training loss: 0.13495996594429016
Validation loss: 1.4837824119034635

Epoch: 5| Step: 10
Training loss: 0.08028490096330643
Validation loss: 1.4963589900283403

Epoch: 604| Step: 0
Training loss: 0.12529794871807098
Validation loss: 1.5187017058813443

Epoch: 5| Step: 1
Training loss: 0.09185968339443207
Validation loss: 1.5212170257363269

Epoch: 5| Step: 2
Training loss: 0.14913532137870789
Validation loss: 1.5349399838396298

Epoch: 5| Step: 3
Training loss: 0.10711145401000977
Validation loss: 1.5247102014480098

Epoch: 5| Step: 4
Training loss: 0.06781395524740219
Validation loss: 1.500742962924383

Epoch: 5| Step: 5
Training loss: 0.09637421369552612
Validation loss: 1.5010810513650217

Epoch: 5| Step: 6
Training loss: 0.13882741332054138
Validation loss: 1.491107047885977

Epoch: 5| Step: 7
Training loss: 0.15268288552761078
Validation loss: 1.486476476474475

Epoch: 5| Step: 8
Training loss: 0.08810314536094666
Validation loss: 1.5164603802465624

Epoch: 5| Step: 9
Training loss: 0.08246562629938126
Validation loss: 1.500097579853509

Epoch: 5| Step: 10
Training loss: 0.0843830481171608
Validation loss: 1.5341549522133284

Epoch: 605| Step: 0
Training loss: 0.09183909744024277
Validation loss: 1.5249681729142384

Epoch: 5| Step: 1
Training loss: 0.08955264091491699
Validation loss: 1.5167245903322775

Epoch: 5| Step: 2
Training loss: 0.07890923321247101
Validation loss: 1.494797150293986

Epoch: 5| Step: 3
Training loss: 0.10931999981403351
Validation loss: 1.465986014694296

Epoch: 5| Step: 4
Training loss: 0.1466725915670395
Validation loss: 1.4800860663895965

Epoch: 5| Step: 5
Training loss: 0.10905824601650238
Validation loss: 1.4763353665669758

Epoch: 5| Step: 6
Training loss: 0.12371627986431122
Validation loss: 1.4844748570073036

Epoch: 5| Step: 7
Training loss: 0.08037810027599335
Validation loss: 1.4751836439614654

Epoch: 5| Step: 8
Training loss: 0.08093979954719543
Validation loss: 1.5032251547741633

Epoch: 5| Step: 9
Training loss: 0.09687668830156326
Validation loss: 1.523934639910216

Epoch: 5| Step: 10
Training loss: 0.06048363819718361
Validation loss: 1.5352052501452866

Epoch: 606| Step: 0
Training loss: 0.08587535470724106
Validation loss: 1.5332582086645148

Epoch: 5| Step: 1
Training loss: 0.12158826738595963
Validation loss: 1.5316266411094255

Epoch: 5| Step: 2
Training loss: 0.06938961148262024
Validation loss: 1.5484730300082956

Epoch: 5| Step: 3
Training loss: 0.14089877903461456
Validation loss: 1.5392871633652718

Epoch: 5| Step: 4
Training loss: 0.08508245646953583
Validation loss: 1.5425612721391904

Epoch: 5| Step: 5
Training loss: 0.11204858869314194
Validation loss: 1.521897248042527

Epoch: 5| Step: 6
Training loss: 0.17016200721263885
Validation loss: 1.5149305046245616

Epoch: 5| Step: 7
Training loss: 0.10563685745000839
Validation loss: 1.4967415243066766

Epoch: 5| Step: 8
Training loss: 0.06599602848291397
Validation loss: 1.4883771660507366

Epoch: 5| Step: 9
Training loss: 0.09619173407554626
Validation loss: 1.4866754675424227

Epoch: 5| Step: 10
Training loss: 0.08505895733833313
Validation loss: 1.482204432128578

Epoch: 607| Step: 0
Training loss: 0.10817668586969376
Validation loss: 1.4665158192316692

Epoch: 5| Step: 1
Training loss: 0.07634759694337845
Validation loss: 1.4681677151751775

Epoch: 5| Step: 2
Training loss: 0.09503136575222015
Validation loss: 1.471195190183578

Epoch: 5| Step: 3
Training loss: 0.08294674009084702
Validation loss: 1.491292336294728

Epoch: 5| Step: 4
Training loss: 0.09448449313640594
Validation loss: 1.5120797926379788

Epoch: 5| Step: 5
Training loss: 0.08831189572811127
Validation loss: 1.5218806138602636

Epoch: 5| Step: 6
Training loss: 0.1083851307630539
Validation loss: 1.5133209856607581

Epoch: 5| Step: 7
Training loss: 0.09601239860057831
Validation loss: 1.4856310595748246

Epoch: 5| Step: 8
Training loss: 0.07897467911243439
Validation loss: 1.5109389712733607

Epoch: 5| Step: 9
Training loss: 0.09470558166503906
Validation loss: 1.532055611251503

Epoch: 5| Step: 10
Training loss: 0.11506030708551407
Validation loss: 1.5050832956067977

Epoch: 608| Step: 0
Training loss: 0.0647839680314064
Validation loss: 1.5249435888823641

Epoch: 5| Step: 1
Training loss: 0.08853909373283386
Validation loss: 1.534043430000223

Epoch: 5| Step: 2
Training loss: 0.10210810601711273
Validation loss: 1.5373390797645814

Epoch: 5| Step: 3
Training loss: 0.07834523916244507
Validation loss: 1.5460668417715258

Epoch: 5| Step: 4
Training loss: 0.11262472718954086
Validation loss: 1.5188326694632088

Epoch: 5| Step: 5
Training loss: 0.067022904753685
Validation loss: 1.517552633439341

Epoch: 5| Step: 6
Training loss: 0.07857973873615265
Validation loss: 1.5007240823520127

Epoch: 5| Step: 7
Training loss: 0.12909848988056183
Validation loss: 1.501872533111162

Epoch: 5| Step: 8
Training loss: 0.05350174382328987
Validation loss: 1.488119904712964

Epoch: 5| Step: 9
Training loss: 0.10355351120233536
Validation loss: 1.4986379133757723

Epoch: 5| Step: 10
Training loss: 0.05823347717523575
Validation loss: 1.5096053231147029

Epoch: 609| Step: 0
Training loss: 0.11004461348056793
Validation loss: 1.469519370345659

Epoch: 5| Step: 1
Training loss: 0.08428772538900375
Validation loss: 1.4986345434701571

Epoch: 5| Step: 2
Training loss: 0.10875071585178375
Validation loss: 1.5033690006502214

Epoch: 5| Step: 3
Training loss: 0.06928449124097824
Validation loss: 1.5020926524234075

Epoch: 5| Step: 4
Training loss: 0.08856133371591568
Validation loss: 1.4903562235575851

Epoch: 5| Step: 5
Training loss: 0.08524324744939804
Validation loss: 1.4889687158728158

Epoch: 5| Step: 6
Training loss: 0.09639515727758408
Validation loss: 1.4849617186413016

Epoch: 5| Step: 7
Training loss: 0.12163462489843369
Validation loss: 1.4813630055355769

Epoch: 5| Step: 8
Training loss: 0.10788674652576447
Validation loss: 1.5206054237581068

Epoch: 5| Step: 9
Training loss: 0.10002686828374863
Validation loss: 1.4951543423437303

Epoch: 5| Step: 10
Training loss: 0.08390671014785767
Validation loss: 1.4979499822021813

Epoch: 610| Step: 0
Training loss: 0.0979517325758934
Validation loss: 1.5302490021592827

Epoch: 5| Step: 1
Training loss: 0.09446772187948227
Validation loss: 1.5406403951747443

Epoch: 5| Step: 2
Training loss: 0.14113149046897888
Validation loss: 1.5416641126396835

Epoch: 5| Step: 3
Training loss: 0.17494097352027893
Validation loss: 1.585877892791584

Epoch: 5| Step: 4
Training loss: 0.1275029182434082
Validation loss: 1.5399271852226668

Epoch: 5| Step: 5
Training loss: 0.12110801041126251
Validation loss: 1.534412496833391

Epoch: 5| Step: 6
Training loss: 0.08462121337652206
Validation loss: 1.5329761787127423

Epoch: 5| Step: 7
Training loss: 0.12146411091089249
Validation loss: 1.5037330888932752

Epoch: 5| Step: 8
Training loss: 0.16487398743629456
Validation loss: 1.4969507981372137

Epoch: 5| Step: 9
Training loss: 0.09683146327733994
Validation loss: 1.5169560550361552

Epoch: 5| Step: 10
Training loss: 0.14639975130558014
Validation loss: 1.4918038024697253

Epoch: 611| Step: 0
Training loss: 0.10660803318023682
Validation loss: 1.4977559863880117

Epoch: 5| Step: 1
Training loss: 0.09166570007801056
Validation loss: 1.5329488362035444

Epoch: 5| Step: 2
Training loss: 0.141224667429924
Validation loss: 1.5215918774245887

Epoch: 5| Step: 3
Training loss: 0.1250637322664261
Validation loss: 1.5658583769234278

Epoch: 5| Step: 4
Training loss: 0.07418270409107208
Validation loss: 1.5647519519252162

Epoch: 5| Step: 5
Training loss: 0.06677795946598053
Validation loss: 1.5313759439735002

Epoch: 5| Step: 6
Training loss: 0.10917967557907104
Validation loss: 1.5475253443564139

Epoch: 5| Step: 7
Training loss: 0.08980812877416611
Validation loss: 1.5189619538604573

Epoch: 5| Step: 8
Training loss: 0.06845328956842422
Validation loss: 1.539782125462768

Epoch: 5| Step: 9
Training loss: 0.11758687347173691
Validation loss: 1.5329848591999342

Epoch: 5| Step: 10
Training loss: 0.11234322190284729
Validation loss: 1.55288682189039

Epoch: 612| Step: 0
Training loss: 0.11491759121417999
Validation loss: 1.522067662208311

Epoch: 5| Step: 1
Training loss: 0.06493300199508667
Validation loss: 1.5394474332050612

Epoch: 5| Step: 2
Training loss: 0.07099084556102753
Validation loss: 1.5350816339574835

Epoch: 5| Step: 3
Training loss: 0.11674715578556061
Validation loss: 1.5497517662663614

Epoch: 5| Step: 4
Training loss: 0.10021641105413437
Validation loss: 1.5372791469738047

Epoch: 5| Step: 5
Training loss: 0.06501595675945282
Validation loss: 1.5347536545927807

Epoch: 5| Step: 6
Training loss: 0.10264156013727188
Validation loss: 1.5237251161247172

Epoch: 5| Step: 7
Training loss: 0.11068234592676163
Validation loss: 1.5131192937974007

Epoch: 5| Step: 8
Training loss: 0.09678144752979279
Validation loss: 1.5362650784113074

Epoch: 5| Step: 9
Training loss: 0.05810824781656265
Validation loss: 1.5251933195257699

Epoch: 5| Step: 10
Training loss: 0.08353828638792038
Validation loss: 1.4997418631789505

Epoch: 613| Step: 0
Training loss: 0.07020466029644012
Validation loss: 1.5112094776604765

Epoch: 5| Step: 1
Training loss: 0.09121327102184296
Validation loss: 1.5128839861962102

Epoch: 5| Step: 2
Training loss: 0.08914157003164291
Validation loss: 1.5009534141068817

Epoch: 5| Step: 3
Training loss: 0.09560686349868774
Validation loss: 1.5245383016524776

Epoch: 5| Step: 4
Training loss: 0.08792218565940857
Validation loss: 1.5235965200649795

Epoch: 5| Step: 5
Training loss: 0.11927874386310577
Validation loss: 1.5118943164425511

Epoch: 5| Step: 6
Training loss: 0.07708197087049484
Validation loss: 1.527558870213006

Epoch: 5| Step: 7
Training loss: 0.07863718271255493
Validation loss: 1.5144433321491364

Epoch: 5| Step: 8
Training loss: 0.0707327201962471
Validation loss: 1.5117466039555048

Epoch: 5| Step: 9
Training loss: 0.099239781498909
Validation loss: 1.5078316042500157

Epoch: 5| Step: 10
Training loss: 0.05133988708257675
Validation loss: 1.5180556056320027

Epoch: 614| Step: 0
Training loss: 0.0993831604719162
Validation loss: 1.487094517677061

Epoch: 5| Step: 1
Training loss: 0.10954131186008453
Validation loss: 1.4849455946235246

Epoch: 5| Step: 2
Training loss: 0.08214066177606583
Validation loss: 1.4906935435469433

Epoch: 5| Step: 3
Training loss: 0.10315112769603729
Validation loss: 1.4740402429334578

Epoch: 5| Step: 4
Training loss: 0.08477728813886642
Validation loss: 1.52138961515119

Epoch: 5| Step: 5
Training loss: 0.1229616180062294
Validation loss: 1.523566335760137

Epoch: 5| Step: 6
Training loss: 0.0889839380979538
Validation loss: 1.5320131688989618

Epoch: 5| Step: 7
Training loss: 0.18968352675437927
Validation loss: 1.5529861386104296

Epoch: 5| Step: 8
Training loss: 0.13879169523715973
Validation loss: 1.5236718846905617

Epoch: 5| Step: 9
Training loss: 0.10644717514514923
Validation loss: 1.5553407361430507

Epoch: 5| Step: 10
Training loss: 0.0705915242433548
Validation loss: 1.5361726655754993

Epoch: 615| Step: 0
Training loss: 0.0768236368894577
Validation loss: 1.5340435645913566

Epoch: 5| Step: 1
Training loss: 0.05630604177713394
Validation loss: 1.5250251011181903

Epoch: 5| Step: 2
Training loss: 0.09806394577026367
Validation loss: 1.531031334271995

Epoch: 5| Step: 3
Training loss: 0.09361707419157028
Validation loss: 1.528094030195667

Epoch: 5| Step: 4
Training loss: 0.09695710241794586
Validation loss: 1.5491665396639096

Epoch: 5| Step: 5
Training loss: 0.06213323026895523
Validation loss: 1.5365634143993419

Epoch: 5| Step: 6
Training loss: 0.06472770869731903
Validation loss: 1.5424247185389202

Epoch: 5| Step: 7
Training loss: 0.10402693599462509
Validation loss: 1.5300015916106522

Epoch: 5| Step: 8
Training loss: 0.11749130487442017
Validation loss: 1.5072139065752748

Epoch: 5| Step: 9
Training loss: 0.08276988565921783
Validation loss: 1.4902266956144763

Epoch: 5| Step: 10
Training loss: 0.0656236931681633
Validation loss: 1.4819486961569837

Epoch: 616| Step: 0
Training loss: 0.0821801945567131
Validation loss: 1.4879076134773992

Epoch: 5| Step: 1
Training loss: 0.1112152710556984
Validation loss: 1.4741130067456154

Epoch: 5| Step: 2
Training loss: 0.09772099554538727
Validation loss: 1.5085594384900984

Epoch: 5| Step: 3
Training loss: 0.0993562787771225
Validation loss: 1.5009917174616167

Epoch: 5| Step: 4
Training loss: 0.07841193675994873
Validation loss: 1.5398356030064244

Epoch: 5| Step: 5
Training loss: 0.11437402665615082
Validation loss: 1.53393586989372

Epoch: 5| Step: 6
Training loss: 0.10527074337005615
Validation loss: 1.5403062502543132

Epoch: 5| Step: 7
Training loss: 0.09508510679006577
Validation loss: 1.5527060736892044

Epoch: 5| Step: 8
Training loss: 0.07839629799127579
Validation loss: 1.5512403659923102

Epoch: 5| Step: 9
Training loss: 0.11093726009130478
Validation loss: 1.5483452966136317

Epoch: 5| Step: 10
Training loss: 0.04803534597158432
Validation loss: 1.5377406804792342

Epoch: 617| Step: 0
Training loss: 0.08901612460613251
Validation loss: 1.5211707917592858

Epoch: 5| Step: 1
Training loss: 0.08609159290790558
Validation loss: 1.5097165030817832

Epoch: 5| Step: 2
Training loss: 0.09332195669412613
Validation loss: 1.5007474025090535

Epoch: 5| Step: 3
Training loss: 0.09643752872943878
Validation loss: 1.5451255152302403

Epoch: 5| Step: 4
Training loss: 0.0706908330321312
Validation loss: 1.5027196240681473

Epoch: 5| Step: 5
Training loss: 0.05419773980975151
Validation loss: 1.539270342037242

Epoch: 5| Step: 6
Training loss: 0.08314508199691772
Validation loss: 1.5365231742141068

Epoch: 5| Step: 7
Training loss: 0.06671080738306046
Validation loss: 1.5399650591675953

Epoch: 5| Step: 8
Training loss: 0.10411036014556885
Validation loss: 1.551398241391746

Epoch: 5| Step: 9
Training loss: 0.08360347151756287
Validation loss: 1.5646041888062672

Epoch: 5| Step: 10
Training loss: 0.08356238156557083
Validation loss: 1.5207510327780118

Epoch: 618| Step: 0
Training loss: 0.0816350132226944
Validation loss: 1.5374081442433019

Epoch: 5| Step: 1
Training loss: 0.05133213847875595
Validation loss: 1.5260459152601098

Epoch: 5| Step: 2
Training loss: 0.08394522964954376
Validation loss: 1.4996974083685106

Epoch: 5| Step: 3
Training loss: 0.061997126787900925
Validation loss: 1.5168785305433377

Epoch: 5| Step: 4
Training loss: 0.05376281589269638
Validation loss: 1.527313046557929

Epoch: 5| Step: 5
Training loss: 0.09107111394405365
Validation loss: 1.534030379787568

Epoch: 5| Step: 6
Training loss: 0.06686481088399887
Validation loss: 1.5359870772207938

Epoch: 5| Step: 7
Training loss: 0.06579013913869858
Validation loss: 1.5549034841599003

Epoch: 5| Step: 8
Training loss: 0.06595063209533691
Validation loss: 1.5167657534281414

Epoch: 5| Step: 9
Training loss: 0.061432063579559326
Validation loss: 1.513609714405511

Epoch: 5| Step: 10
Training loss: 0.12396663427352905
Validation loss: 1.5224178196281515

Epoch: 619| Step: 0
Training loss: 0.06252835690975189
Validation loss: 1.5137110461470902

Epoch: 5| Step: 1
Training loss: 0.11346721649169922
Validation loss: 1.5105391202434417

Epoch: 5| Step: 2
Training loss: 0.06710801273584366
Validation loss: 1.5325609868572605

Epoch: 5| Step: 3
Training loss: 0.08705411851406097
Validation loss: 1.5126575757098455

Epoch: 5| Step: 4
Training loss: 0.07538235187530518
Validation loss: 1.5477513587603005

Epoch: 5| Step: 5
Training loss: 0.09374765306711197
Validation loss: 1.5514452854792278

Epoch: 5| Step: 6
Training loss: 0.10517891496419907
Validation loss: 1.5767369052415252

Epoch: 5| Step: 7
Training loss: 0.10391394793987274
Validation loss: 1.5516348615769417

Epoch: 5| Step: 8
Training loss: 0.08530507981777191
Validation loss: 1.572856326257029

Epoch: 5| Step: 9
Training loss: 0.10765161365270615
Validation loss: 1.5588717614450762

Epoch: 5| Step: 10
Training loss: 0.044222746044397354
Validation loss: 1.546083656690454

Epoch: 620| Step: 0
Training loss: 0.09311415255069733
Validation loss: 1.550389459056239

Epoch: 5| Step: 1
Training loss: 0.0679115504026413
Validation loss: 1.5295876764482068

Epoch: 5| Step: 2
Training loss: 0.07867863774299622
Validation loss: 1.5163906056393859

Epoch: 5| Step: 3
Training loss: 0.09920741617679596
Validation loss: 1.5150906603823426

Epoch: 5| Step: 4
Training loss: 0.08696945011615753
Validation loss: 1.5173949092947028

Epoch: 5| Step: 5
Training loss: 0.08289878815412521
Validation loss: 1.521657609170483

Epoch: 5| Step: 6
Training loss: 0.1240464597940445
Validation loss: 1.5235136497405268

Epoch: 5| Step: 7
Training loss: 0.05329092592000961
Validation loss: 1.5440787884496874

Epoch: 5| Step: 8
Training loss: 0.0944380983710289
Validation loss: 1.5268998863876506

Epoch: 5| Step: 9
Training loss: 0.10134254395961761
Validation loss: 1.5474297641426005

Epoch: 5| Step: 10
Training loss: 0.05277397483587265
Validation loss: 1.5432038627645022

Epoch: 621| Step: 0
Training loss: 0.09845265746116638
Validation loss: 1.5528724155118387

Epoch: 5| Step: 1
Training loss: 0.08197807520627975
Validation loss: 1.5618893081142056

Epoch: 5| Step: 2
Training loss: 0.10630278289318085
Validation loss: 1.5486713711933424

Epoch: 5| Step: 3
Training loss: 0.07545650005340576
Validation loss: 1.5601366027708976

Epoch: 5| Step: 4
Training loss: 0.10522512346506119
Validation loss: 1.5421363884402859

Epoch: 5| Step: 5
Training loss: 0.11944665759801865
Validation loss: 1.5282337652739657

Epoch: 5| Step: 6
Training loss: 0.05901549383997917
Validation loss: 1.523599281105944

Epoch: 5| Step: 7
Training loss: 0.045493561774492264
Validation loss: 1.5440898313317248

Epoch: 5| Step: 8
Training loss: 0.11200986057519913
Validation loss: 1.5529957753355785

Epoch: 5| Step: 9
Training loss: 0.06382165104150772
Validation loss: 1.573225667399745

Epoch: 5| Step: 10
Training loss: 0.09806020557880402
Validation loss: 1.563028036907155

Epoch: 622| Step: 0
Training loss: 0.12953440845012665
Validation loss: 1.5745878322150118

Epoch: 5| Step: 1
Training loss: 0.09252142161130905
Validation loss: 1.545021370533974

Epoch: 5| Step: 2
Training loss: 0.11356467008590698
Validation loss: 1.517959419117179

Epoch: 5| Step: 3
Training loss: 0.06987547874450684
Validation loss: 1.5381330059420677

Epoch: 5| Step: 4
Training loss: 0.08134735375642776
Validation loss: 1.5057647023149716

Epoch: 5| Step: 5
Training loss: 0.10967061668634415
Validation loss: 1.5286030577075096

Epoch: 5| Step: 6
Training loss: 0.08519282937049866
Validation loss: 1.5129896222904164

Epoch: 5| Step: 7
Training loss: 0.0729450210928917
Validation loss: 1.5180023600978236

Epoch: 5| Step: 8
Training loss: 0.09274459630250931
Validation loss: 1.564952406831967

Epoch: 5| Step: 9
Training loss: 0.07698427140712738
Validation loss: 1.5353012495143439

Epoch: 5| Step: 10
Training loss: 0.0767354816198349
Validation loss: 1.5377450104682677

Epoch: 623| Step: 0
Training loss: 0.060798704624176025
Validation loss: 1.5467634918869182

Epoch: 5| Step: 1
Training loss: 0.09451071918010712
Validation loss: 1.568689416813594

Epoch: 5| Step: 2
Training loss: 0.10702308267354965
Validation loss: 1.5364647129530549

Epoch: 5| Step: 3
Training loss: 0.114832304418087
Validation loss: 1.576611690623786

Epoch: 5| Step: 4
Training loss: 0.10081502050161362
Validation loss: 1.5557424458124305

Epoch: 5| Step: 5
Training loss: 0.0997835323214531
Validation loss: 1.5502832999793432

Epoch: 5| Step: 6
Training loss: 0.13850107789039612
Validation loss: 1.5245494586165234

Epoch: 5| Step: 7
Training loss: 0.07966960966587067
Validation loss: 1.531225646695783

Epoch: 5| Step: 8
Training loss: 0.08804191648960114
Validation loss: 1.5362238781426543

Epoch: 5| Step: 9
Training loss: 0.08675653487443924
Validation loss: 1.5476067745557396

Epoch: 5| Step: 10
Training loss: 0.09006410092115402
Validation loss: 1.5487837137714509

Epoch: 624| Step: 0
Training loss: 0.07537220418453217
Validation loss: 1.5469761920231644

Epoch: 5| Step: 1
Training loss: 0.06317035853862762
Validation loss: 1.5541649390292425

Epoch: 5| Step: 2
Training loss: 0.11103532463312149
Validation loss: 1.5649379901988532

Epoch: 5| Step: 3
Training loss: 0.12219642102718353
Validation loss: 1.531215234469342

Epoch: 5| Step: 4
Training loss: 0.07115129381418228
Validation loss: 1.5530572783562444

Epoch: 5| Step: 5
Training loss: 0.1164221540093422
Validation loss: 1.548655915003951

Epoch: 5| Step: 6
Training loss: 0.13798275589942932
Validation loss: 1.5370493396635978

Epoch: 5| Step: 7
Training loss: 0.10238821804523468
Validation loss: 1.53502949976152

Epoch: 5| Step: 8
Training loss: 0.0779343917965889
Validation loss: 1.5313953661149549

Epoch: 5| Step: 9
Training loss: 0.10265620052814484
Validation loss: 1.52488753872533

Epoch: 5| Step: 10
Training loss: 0.09379340708255768
Validation loss: 1.5279908616055724

Epoch: 625| Step: 0
Training loss: 0.04884631931781769
Validation loss: 1.5316325900375203

Epoch: 5| Step: 1
Training loss: 0.08991573750972748
Validation loss: 1.5028121061222528

Epoch: 5| Step: 2
Training loss: 0.10187359899282455
Validation loss: 1.5100021593032344

Epoch: 5| Step: 3
Training loss: 0.10678074508905411
Validation loss: 1.5076450442755094

Epoch: 5| Step: 4
Training loss: 0.08667485415935516
Validation loss: 1.4849251688167613

Epoch: 5| Step: 5
Training loss: 0.07600749284029007
Validation loss: 1.4725451994967718

Epoch: 5| Step: 6
Training loss: 0.074330173432827
Validation loss: 1.4712615333577639

Epoch: 5| Step: 7
Training loss: 0.1311987340450287
Validation loss: 1.487760013790541

Epoch: 5| Step: 8
Training loss: 0.10062272846698761
Validation loss: 1.4856984102597801

Epoch: 5| Step: 9
Training loss: 0.07523541897535324
Validation loss: 1.4755880819853915

Epoch: 5| Step: 10
Training loss: 0.13308602571487427
Validation loss: 1.5055016138220345

Epoch: 626| Step: 0
Training loss: 0.08721394836902618
Validation loss: 1.4799027135295253

Epoch: 5| Step: 1
Training loss: 0.09438202530145645
Validation loss: 1.479883078605898

Epoch: 5| Step: 2
Training loss: 0.08315516263246536
Validation loss: 1.5017853552295315

Epoch: 5| Step: 3
Training loss: 0.07717950642108917
Validation loss: 1.4683365104019002

Epoch: 5| Step: 4
Training loss: 0.07879122346639633
Validation loss: 1.4835962890296854

Epoch: 5| Step: 5
Training loss: 0.0837474837899208
Validation loss: 1.4935601975328179

Epoch: 5| Step: 6
Training loss: 0.165260910987854
Validation loss: 1.5239016061188073

Epoch: 5| Step: 7
Training loss: 0.07050912827253342
Validation loss: 1.5359442580130793

Epoch: 5| Step: 8
Training loss: 0.06929955631494522
Validation loss: 1.5386502217221003

Epoch: 5| Step: 9
Training loss: 0.10967830568552017
Validation loss: 1.558304020153579

Epoch: 5| Step: 10
Training loss: 0.09875985980033875
Validation loss: 1.542949035603513

Epoch: 627| Step: 0
Training loss: 0.14636948704719543
Validation loss: 1.5613356777416763

Epoch: 5| Step: 1
Training loss: 0.05856611579656601
Validation loss: 1.5411235209434264

Epoch: 5| Step: 2
Training loss: 0.12360522896051407
Validation loss: 1.542424931321093

Epoch: 5| Step: 3
Training loss: 0.09702616184949875
Validation loss: 1.5305822792873587

Epoch: 5| Step: 4
Training loss: 0.08615019172430038
Validation loss: 1.5343613598936348

Epoch: 5| Step: 5
Training loss: 0.07886193692684174
Validation loss: 1.5061158287909724

Epoch: 5| Step: 6
Training loss: 0.09892983734607697
Validation loss: 1.5126619979899416

Epoch: 5| Step: 7
Training loss: 0.1246316209435463
Validation loss: 1.5204767411754978

Epoch: 5| Step: 8
Training loss: 0.053088437765836716
Validation loss: 1.5333035786946614

Epoch: 5| Step: 9
Training loss: 0.06293468177318573
Validation loss: 1.5171850522359211

Epoch: 5| Step: 10
Training loss: 0.07318620383739471
Validation loss: 1.5405725638071697

Epoch: 628| Step: 0
Training loss: 0.07243096828460693
Validation loss: 1.5320235798435826

Epoch: 5| Step: 1
Training loss: 0.09507471323013306
Validation loss: 1.5531277425827519

Epoch: 5| Step: 2
Training loss: 0.10688774287700653
Validation loss: 1.5394512620023502

Epoch: 5| Step: 3
Training loss: 0.08442581444978714
Validation loss: 1.5382141144044938

Epoch: 5| Step: 4
Training loss: 0.05633597820997238
Validation loss: 1.5438646090927945

Epoch: 5| Step: 5
Training loss: 0.0801904946565628
Validation loss: 1.535004485038019

Epoch: 5| Step: 6
Training loss: 0.0649803876876831
Validation loss: 1.5355167747825704

Epoch: 5| Step: 7
Training loss: 0.062246568500995636
Validation loss: 1.5358575954232165

Epoch: 5| Step: 8
Training loss: 0.1469777524471283
Validation loss: 1.5035919322762439

Epoch: 5| Step: 9
Training loss: 0.05892683193087578
Validation loss: 1.526314071429673

Epoch: 5| Step: 10
Training loss: 0.08908085525035858
Validation loss: 1.4857163929170178

Epoch: 629| Step: 0
Training loss: 0.06255695968866348
Validation loss: 1.5118905549408288

Epoch: 5| Step: 1
Training loss: 0.08228805661201477
Validation loss: 1.5130735763939478

Epoch: 5| Step: 2
Training loss: 0.052188027650117874
Validation loss: 1.509955890717045

Epoch: 5| Step: 3
Training loss: 0.09807614982128143
Validation loss: 1.5186366137637888

Epoch: 5| Step: 4
Training loss: 0.13358204066753387
Validation loss: 1.5390659673239595

Epoch: 5| Step: 5
Training loss: 0.07679031789302826
Validation loss: 1.5371162147932156

Epoch: 5| Step: 6
Training loss: 0.09277920424938202
Validation loss: 1.5267394563203216

Epoch: 5| Step: 7
Training loss: 0.11270205676555634
Validation loss: 1.5109399544295443

Epoch: 5| Step: 8
Training loss: 0.05066915601491928
Validation loss: 1.483950775156739

Epoch: 5| Step: 9
Training loss: 0.06750048696994781
Validation loss: 1.5028636481172295

Epoch: 5| Step: 10
Training loss: 0.06139463558793068
Validation loss: 1.4920553712434665

Epoch: 630| Step: 0
Training loss: 0.07720186561346054
Validation loss: 1.4891891783924514

Epoch: 5| Step: 1
Training loss: 0.10812709480524063
Validation loss: 1.488823736867597

Epoch: 5| Step: 2
Training loss: 0.09322003275156021
Validation loss: 1.5122481456366919

Epoch: 5| Step: 3
Training loss: 0.10675615072250366
Validation loss: 1.5308763814228836

Epoch: 5| Step: 4
Training loss: 0.12767073512077332
Validation loss: 1.5441529225277644

Epoch: 5| Step: 5
Training loss: 0.04982036352157593
Validation loss: 1.5702580610911052

Epoch: 5| Step: 6
Training loss: 0.10787370055913925
Validation loss: 1.5358787672494048

Epoch: 5| Step: 7
Training loss: 0.08730193227529526
Validation loss: 1.5353115027950657

Epoch: 5| Step: 8
Training loss: 0.07734016329050064
Validation loss: 1.5336655788524176

Epoch: 5| Step: 9
Training loss: 0.07474847137928009
Validation loss: 1.525771631989428

Epoch: 5| Step: 10
Training loss: 0.1279505342245102
Validation loss: 1.5177751010464084

Epoch: 631| Step: 0
Training loss: 0.07594750076532364
Validation loss: 1.5171252258362309

Epoch: 5| Step: 1
Training loss: 0.10671162605285645
Validation loss: 1.5358990764105191

Epoch: 5| Step: 2
Training loss: 0.07278067618608475
Validation loss: 1.5111818992963402

Epoch: 5| Step: 3
Training loss: 0.07971826195716858
Validation loss: 1.5302775534250403

Epoch: 5| Step: 4
Training loss: 0.15095575153827667
Validation loss: 1.5345520165658766

Epoch: 5| Step: 5
Training loss: 0.07803808152675629
Validation loss: 1.5408471098510168

Epoch: 5| Step: 6
Training loss: 0.08524639904499054
Validation loss: 1.5312067603552213

Epoch: 5| Step: 7
Training loss: 0.10096331685781479
Validation loss: 1.5060105605791974

Epoch: 5| Step: 8
Training loss: 0.11385814100503922
Validation loss: 1.5094951397629195

Epoch: 5| Step: 9
Training loss: 0.10995914787054062
Validation loss: 1.4904199723274476

Epoch: 5| Step: 10
Training loss: 0.09274192899465561
Validation loss: 1.4987824052892706

Epoch: 632| Step: 0
Training loss: 0.101178839802742
Validation loss: 1.500227137278485

Epoch: 5| Step: 1
Training loss: 0.06818599253892899
Validation loss: 1.4985156687357093

Epoch: 5| Step: 2
Training loss: 0.07685713469982147
Validation loss: 1.5465527824176255

Epoch: 5| Step: 3
Training loss: 0.12453031539916992
Validation loss: 1.5558484959345993

Epoch: 5| Step: 4
Training loss: 0.09473291784524918
Validation loss: 1.539813627478897

Epoch: 5| Step: 5
Training loss: 0.08154165744781494
Validation loss: 1.5240335682386994

Epoch: 5| Step: 6
Training loss: 0.13030891120433807
Validation loss: 1.5153897577716458

Epoch: 5| Step: 7
Training loss: 0.09296822547912598
Validation loss: 1.5209565393386348

Epoch: 5| Step: 8
Training loss: 0.08507251739501953
Validation loss: 1.537584650901056

Epoch: 5| Step: 9
Training loss: 0.07032252848148346
Validation loss: 1.5382498310458275

Epoch: 5| Step: 10
Training loss: 0.09336020797491074
Validation loss: 1.5207726083776003

Epoch: 633| Step: 0
Training loss: 0.0497363917529583
Validation loss: 1.555310647974732

Epoch: 5| Step: 1
Training loss: 0.08199183642864227
Validation loss: 1.547159961474839

Epoch: 5| Step: 2
Training loss: 0.08729967474937439
Validation loss: 1.5446370122253255

Epoch: 5| Step: 3
Training loss: 0.10981247574090958
Validation loss: 1.5091751583160893

Epoch: 5| Step: 4
Training loss: 0.11280621588230133
Validation loss: 1.5016639796636437

Epoch: 5| Step: 5
Training loss: 0.09054733067750931
Validation loss: 1.48840759646508

Epoch: 5| Step: 6
Training loss: 0.08955147862434387
Validation loss: 1.478743310897581

Epoch: 5| Step: 7
Training loss: 0.11268994957208633
Validation loss: 1.5112371918975667

Epoch: 5| Step: 8
Training loss: 0.06197042390704155
Validation loss: 1.503156973469642

Epoch: 5| Step: 9
Training loss: 0.07725019007921219
Validation loss: 1.4991756228990452

Epoch: 5| Step: 10
Training loss: 0.10241840779781342
Validation loss: 1.511602755515806

Epoch: 634| Step: 0
Training loss: 0.04928610101342201
Validation loss: 1.5177546489623286

Epoch: 5| Step: 1
Training loss: 0.062178999185562134
Validation loss: 1.527769124636086

Epoch: 5| Step: 2
Training loss: 0.06577713042497635
Validation loss: 1.5726865030104114

Epoch: 5| Step: 3
Training loss: 0.1229737401008606
Validation loss: 1.5804700697621992

Epoch: 5| Step: 4
Training loss: 0.09225635975599289
Validation loss: 1.55076015123757

Epoch: 5| Step: 5
Training loss: 0.07471472769975662
Validation loss: 1.5403942779828144

Epoch: 5| Step: 6
Training loss: 0.051470886915922165
Validation loss: 1.5380238025419173

Epoch: 5| Step: 7
Training loss: 0.0839051604270935
Validation loss: 1.5308281747243737

Epoch: 5| Step: 8
Training loss: 0.08473507314920425
Validation loss: 1.517994535866604

Epoch: 5| Step: 9
Training loss: 0.09802696853876114
Validation loss: 1.5284382861147645

Epoch: 5| Step: 10
Training loss: 0.12278782576322556
Validation loss: 1.5057133897658317

Epoch: 635| Step: 0
Training loss: 0.08127794414758682
Validation loss: 1.49296909634785

Epoch: 5| Step: 1
Training loss: 0.09451587498188019
Validation loss: 1.5027434588760458

Epoch: 5| Step: 2
Training loss: 0.07031945884227753
Validation loss: 1.4769270919984387

Epoch: 5| Step: 3
Training loss: 0.07409748435020447
Validation loss: 1.4958517730876963

Epoch: 5| Step: 4
Training loss: 0.06787648051977158
Validation loss: 1.483961102783039

Epoch: 5| Step: 5
Training loss: 0.0971510261297226
Validation loss: 1.4941655282051332

Epoch: 5| Step: 6
Training loss: 0.12773889303207397
Validation loss: 1.4916238323334725

Epoch: 5| Step: 7
Training loss: 0.08711391687393188
Validation loss: 1.5002579240388767

Epoch: 5| Step: 8
Training loss: 0.05595528334379196
Validation loss: 1.5109680224490423

Epoch: 5| Step: 9
Training loss: 0.10907129943370819
Validation loss: 1.5029264573127992

Epoch: 5| Step: 10
Training loss: 0.12179702520370483
Validation loss: 1.4892598172669769

Epoch: 636| Step: 0
Training loss: 0.07867638021707535
Validation loss: 1.5138056060319305

Epoch: 5| Step: 1
Training loss: 0.12901920080184937
Validation loss: 1.5004209292832242

Epoch: 5| Step: 2
Training loss: 0.0833115503191948
Validation loss: 1.4896270382788874

Epoch: 5| Step: 3
Training loss: 0.07402999699115753
Validation loss: 1.475492351798601

Epoch: 5| Step: 4
Training loss: 0.15282253921031952
Validation loss: 1.5061075290044148

Epoch: 5| Step: 5
Training loss: 0.1506982147693634
Validation loss: 1.5304717261304137

Epoch: 5| Step: 6
Training loss: 0.14268331229686737
Validation loss: 1.5496019419803415

Epoch: 5| Step: 7
Training loss: 0.14167092740535736
Validation loss: 1.514339062475389

Epoch: 5| Step: 8
Training loss: 0.05601316690444946
Validation loss: 1.5180241241249988

Epoch: 5| Step: 9
Training loss: 0.09208087623119354
Validation loss: 1.5515059207075386

Epoch: 5| Step: 10
Training loss: 0.10044268518686295
Validation loss: 1.5621645912047355

Epoch: 637| Step: 0
Training loss: 0.10602965205907822
Validation loss: 1.5843392520822503

Epoch: 5| Step: 1
Training loss: 0.14014673233032227
Validation loss: 1.558790332527571

Epoch: 5| Step: 2
Training loss: 0.10504021495580673
Validation loss: 1.5247384155950239

Epoch: 5| Step: 3
Training loss: 0.12794342637062073
Validation loss: 1.4979640591529109

Epoch: 5| Step: 4
Training loss: 0.12091183662414551
Validation loss: 1.503798302783761

Epoch: 5| Step: 5
Training loss: 0.10971727222204208
Validation loss: 1.473456205860261

Epoch: 5| Step: 6
Training loss: 0.1337694674730301
Validation loss: 1.4827675127214002

Epoch: 5| Step: 7
Training loss: 0.10515959560871124
Validation loss: 1.476162838679488

Epoch: 5| Step: 8
Training loss: 0.10039599239826202
Validation loss: 1.5090598252511793

Epoch: 5| Step: 9
Training loss: 0.052033353596925735
Validation loss: 1.5118602296357513

Epoch: 5| Step: 10
Training loss: 0.10539308935403824
Validation loss: 1.5190414972202753

Epoch: 638| Step: 0
Training loss: 0.06132681295275688
Validation loss: 1.567904116005026

Epoch: 5| Step: 1
Training loss: 0.07875797152519226
Validation loss: 1.5596189678356212

Epoch: 5| Step: 2
Training loss: 0.1985122710466385
Validation loss: 1.5732764915753437

Epoch: 5| Step: 3
Training loss: 0.06014082580804825
Validation loss: 1.5676616417464388

Epoch: 5| Step: 4
Training loss: 0.08397077023983002
Validation loss: 1.5288383999178488

Epoch: 5| Step: 5
Training loss: 0.1255187690258026
Validation loss: 1.5415289684008526

Epoch: 5| Step: 6
Training loss: 0.09718599915504456
Validation loss: 1.5650129356691915

Epoch: 5| Step: 7
Training loss: 0.11086950451135635
Validation loss: 1.5345255995309481

Epoch: 5| Step: 8
Training loss: 0.11742758750915527
Validation loss: 1.5317315516933319

Epoch: 5| Step: 9
Training loss: 0.060430318117141724
Validation loss: 1.5188514929945751

Epoch: 5| Step: 10
Training loss: 0.0757058709859848
Validation loss: 1.5141884178243659

Epoch: 639| Step: 0
Training loss: 0.10077472031116486
Validation loss: 1.4978722641544957

Epoch: 5| Step: 1
Training loss: 0.1358821839094162
Validation loss: 1.5285569166624418

Epoch: 5| Step: 2
Training loss: 0.12536725401878357
Validation loss: 1.5320943273523802

Epoch: 5| Step: 3
Training loss: 0.11758007854223251
Validation loss: 1.4854779602378927

Epoch: 5| Step: 4
Training loss: 0.08260927349328995
Validation loss: 1.497087566442387

Epoch: 5| Step: 5
Training loss: 0.10454241186380386
Validation loss: 1.4819614009190631

Epoch: 5| Step: 6
Training loss: 0.06644104421138763
Validation loss: 1.4693895322020336

Epoch: 5| Step: 7
Training loss: 0.0853843167424202
Validation loss: 1.4621319642630957

Epoch: 5| Step: 8
Training loss: 0.1410624235868454
Validation loss: 1.4590259393056233

Epoch: 5| Step: 9
Training loss: 0.06728778779506683
Validation loss: 1.4794845593872892

Epoch: 5| Step: 10
Training loss: 0.05368310958147049
Validation loss: 1.4677674622945889

Epoch: 640| Step: 0
Training loss: 0.06338107585906982
Validation loss: 1.484051815925106

Epoch: 5| Step: 1
Training loss: 0.08141519129276276
Validation loss: 1.4939318228793401

Epoch: 5| Step: 2
Training loss: 0.10445225238800049
Validation loss: 1.5110695887637395

Epoch: 5| Step: 3
Training loss: 0.07799897342920303
Validation loss: 1.5178698057769446

Epoch: 5| Step: 4
Training loss: 0.13885776698589325
Validation loss: 1.5347844169985863

Epoch: 5| Step: 5
Training loss: 0.08814863115549088
Validation loss: 1.5243781548674389

Epoch: 5| Step: 6
Training loss: 0.052834708243608475
Validation loss: 1.5095070536418627

Epoch: 5| Step: 7
Training loss: 0.1146644577383995
Validation loss: 1.5087906929754442

Epoch: 5| Step: 8
Training loss: 0.11609236896038055
Validation loss: 1.515594668285821

Epoch: 5| Step: 9
Training loss: 0.08503314852714539
Validation loss: 1.505896847735169

Epoch: 5| Step: 10
Training loss: 0.08837366849184036
Validation loss: 1.479751116486006

Epoch: 641| Step: 0
Training loss: 0.060303300619125366
Validation loss: 1.5188453159024637

Epoch: 5| Step: 1
Training loss: 0.08715999126434326
Validation loss: 1.5278981231874036

Epoch: 5| Step: 2
Training loss: 0.08946701139211655
Validation loss: 1.5517862881383588

Epoch: 5| Step: 3
Training loss: 0.1018039807677269
Validation loss: 1.5342630929844354

Epoch: 5| Step: 4
Training loss: 0.11185286194086075
Validation loss: 1.528251576167281

Epoch: 5| Step: 5
Training loss: 0.07791197299957275
Validation loss: 1.5096622090185843

Epoch: 5| Step: 6
Training loss: 0.07108268141746521
Validation loss: 1.4813955105761045

Epoch: 5| Step: 7
Training loss: 0.07277481257915497
Validation loss: 1.5145756134422876

Epoch: 5| Step: 8
Training loss: 0.13488829135894775
Validation loss: 1.482435300786008

Epoch: 5| Step: 9
Training loss: 0.09242770820856094
Validation loss: 1.4742566052303518

Epoch: 5| Step: 10
Training loss: 0.12691549956798553
Validation loss: 1.4684660806450793

Epoch: 642| Step: 0
Training loss: 0.06455856561660767
Validation loss: 1.4897507083031438

Epoch: 5| Step: 1
Training loss: 0.0689006820321083
Validation loss: 1.505180775478322

Epoch: 5| Step: 2
Training loss: 0.08555080741643906
Validation loss: 1.5086433720845047

Epoch: 5| Step: 3
Training loss: 0.05517222732305527
Validation loss: 1.504302861869976

Epoch: 5| Step: 4
Training loss: 0.06674561649560928
Validation loss: 1.4911821683247883

Epoch: 5| Step: 5
Training loss: 0.07407532632350922
Validation loss: 1.4768347688900527

Epoch: 5| Step: 6
Training loss: 0.09447674453258514
Validation loss: 1.4857643278696204

Epoch: 5| Step: 7
Training loss: 0.1234918087720871
Validation loss: 1.5079724993757022

Epoch: 5| Step: 8
Training loss: 0.06625998020172119
Validation loss: 1.5055514304868636

Epoch: 5| Step: 9
Training loss: 0.08569621294736862
Validation loss: 1.4974141979730258

Epoch: 5| Step: 10
Training loss: 0.08462989330291748
Validation loss: 1.5119803182540401

Epoch: 643| Step: 0
Training loss: 0.06630881130695343
Validation loss: 1.5356404230158816

Epoch: 5| Step: 1
Training loss: 0.1284337192773819
Validation loss: 1.5454282478619648

Epoch: 5| Step: 2
Training loss: 0.048898596316576004
Validation loss: 1.5271287528417443

Epoch: 5| Step: 3
Training loss: 0.06642370671033859
Validation loss: 1.5314111107139177

Epoch: 5| Step: 4
Training loss: 0.10236005485057831
Validation loss: 1.535957601762587

Epoch: 5| Step: 5
Training loss: 0.08135593682527542
Validation loss: 1.504841455208358

Epoch: 5| Step: 6
Training loss: 0.08516985177993774
Validation loss: 1.5034091844353625

Epoch: 5| Step: 7
Training loss: 0.0840069055557251
Validation loss: 1.4738708106420373

Epoch: 5| Step: 8
Training loss: 0.05966224521398544
Validation loss: 1.4526066985181583

Epoch: 5| Step: 9
Training loss: 0.10308919101953506
Validation loss: 1.4713941460014672

Epoch: 5| Step: 10
Training loss: 0.11326315999031067
Validation loss: 1.4654500663921397

Epoch: 644| Step: 0
Training loss: 0.08285597711801529
Validation loss: 1.471857701578448

Epoch: 5| Step: 1
Training loss: 0.08513291925191879
Validation loss: 1.4600315555449455

Epoch: 5| Step: 2
Training loss: 0.0645008534193039
Validation loss: 1.467936748458493

Epoch: 5| Step: 3
Training loss: 0.06710730493068695
Validation loss: 1.4892522045361098

Epoch: 5| Step: 4
Training loss: 0.11483170837163925
Validation loss: 1.5018832004198464

Epoch: 5| Step: 5
Training loss: 0.10369405895471573
Validation loss: 1.5072528623765515

Epoch: 5| Step: 6
Training loss: 0.07244490087032318
Validation loss: 1.5003015584843133

Epoch: 5| Step: 7
Training loss: 0.06179289147257805
Validation loss: 1.5013192417801067

Epoch: 5| Step: 8
Training loss: 0.07566430419683456
Validation loss: 1.4800316479898268

Epoch: 5| Step: 9
Training loss: 0.08349164575338364
Validation loss: 1.4795017908978205

Epoch: 5| Step: 10
Training loss: 0.10252709686756134
Validation loss: 1.488744189021408

Epoch: 645| Step: 0
Training loss: 0.0650111585855484
Validation loss: 1.4993006272982525

Epoch: 5| Step: 1
Training loss: 0.10511362552642822
Validation loss: 1.5151342166367399

Epoch: 5| Step: 2
Training loss: 0.07717575877904892
Validation loss: 1.5338332576136435

Epoch: 5| Step: 3
Training loss: 0.052961595356464386
Validation loss: 1.5311086447008195

Epoch: 5| Step: 4
Training loss: 0.1005750447511673
Validation loss: 1.537251394282105

Epoch: 5| Step: 5
Training loss: 0.12718701362609863
Validation loss: 1.511142760194758

Epoch: 5| Step: 6
Training loss: 0.07055294513702393
Validation loss: 1.5048329099532096

Epoch: 5| Step: 7
Training loss: 0.06276082992553711
Validation loss: 1.5114908602929884

Epoch: 5| Step: 8
Training loss: 0.05883950740098953
Validation loss: 1.4822964822092364

Epoch: 5| Step: 9
Training loss: 0.08293942362070084
Validation loss: 1.4857314017511183

Epoch: 5| Step: 10
Training loss: 0.10964560508728027
Validation loss: 1.507509539204259

Epoch: 646| Step: 0
Training loss: 0.05572804808616638
Validation loss: 1.5089357860626713

Epoch: 5| Step: 1
Training loss: 0.0797279104590416
Validation loss: 1.4932269306593045

Epoch: 5| Step: 2
Training loss: 0.06385379284620285
Validation loss: 1.5080431622843589

Epoch: 5| Step: 3
Training loss: 0.06587077677249908
Validation loss: 1.492017161461615

Epoch: 5| Step: 4
Training loss: 0.08128252625465393
Validation loss: 1.5081850738935574

Epoch: 5| Step: 5
Training loss: 0.07292201370000839
Validation loss: 1.470341246615174

Epoch: 5| Step: 6
Training loss: 0.06176670640707016
Validation loss: 1.4786403473987375

Epoch: 5| Step: 7
Training loss: 0.08753321319818497
Validation loss: 1.4813166356855823

Epoch: 5| Step: 8
Training loss: 0.059814829379320145
Validation loss: 1.4846773339856056

Epoch: 5| Step: 9
Training loss: 0.054588936269283295
Validation loss: 1.466742915491904

Epoch: 5| Step: 10
Training loss: 0.05111216381192207
Validation loss: 1.4787365851863739

Epoch: 647| Step: 0
Training loss: 0.08298581838607788
Validation loss: 1.5069932847894647

Epoch: 5| Step: 1
Training loss: 0.05440492555499077
Validation loss: 1.5145788410658478

Epoch: 5| Step: 2
Training loss: 0.07553006708621979
Validation loss: 1.5390345460625106

Epoch: 5| Step: 3
Training loss: 0.06535391509532928
Validation loss: 1.510643038698422

Epoch: 5| Step: 4
Training loss: 0.05157574266195297
Validation loss: 1.5298076906511862

Epoch: 5| Step: 5
Training loss: 0.07910679280757904
Validation loss: 1.5243106042185137

Epoch: 5| Step: 6
Training loss: 0.1420350819826126
Validation loss: 1.5198492696208339

Epoch: 5| Step: 7
Training loss: 0.12293042987585068
Validation loss: 1.515336198191489

Epoch: 5| Step: 8
Training loss: 0.08716575056314468
Validation loss: 1.5040757361278738

Epoch: 5| Step: 9
Training loss: 0.08469398319721222
Validation loss: 1.4939863579247588

Epoch: 5| Step: 10
Training loss: 0.09168046712875366
Validation loss: 1.486341796895509

Epoch: 648| Step: 0
Training loss: 0.18539290130138397
Validation loss: 1.474779990411574

Epoch: 5| Step: 1
Training loss: 0.12477917969226837
Validation loss: 1.4949763500562279

Epoch: 5| Step: 2
Training loss: 0.0719933807849884
Validation loss: 1.4889419437736593

Epoch: 5| Step: 3
Training loss: 0.10180336236953735
Validation loss: 1.5066689650217693

Epoch: 5| Step: 4
Training loss: 0.08326878398656845
Validation loss: 1.5166261670409993

Epoch: 5| Step: 5
Training loss: 0.10212941467761993
Validation loss: 1.5422817981371315

Epoch: 5| Step: 6
Training loss: 0.07641307264566422
Validation loss: 1.5358991110196678

Epoch: 5| Step: 7
Training loss: 0.0686015635728836
Validation loss: 1.530583909762803

Epoch: 5| Step: 8
Training loss: 0.08365651965141296
Validation loss: 1.537009819220471

Epoch: 5| Step: 9
Training loss: 0.0716080367565155
Validation loss: 1.499699818190708

Epoch: 5| Step: 10
Training loss: 0.06191874295473099
Validation loss: 1.5029566518722042

Epoch: 649| Step: 0
Training loss: 0.06318121403455734
Validation loss: 1.4927433383080266

Epoch: 5| Step: 1
Training loss: 0.08134384453296661
Validation loss: 1.5012912365698046

Epoch: 5| Step: 2
Training loss: 0.0802132785320282
Validation loss: 1.5081905837981933

Epoch: 5| Step: 3
Training loss: 0.15492166578769684
Validation loss: 1.5065274366768457

Epoch: 5| Step: 4
Training loss: 0.06305034458637238
Validation loss: 1.4971169432004292

Epoch: 5| Step: 5
Training loss: 0.07357309758663177
Validation loss: 1.5039825631726174

Epoch: 5| Step: 6
Training loss: 0.07166002690792084
Validation loss: 1.4878990355358328

Epoch: 5| Step: 7
Training loss: 0.07732581347227097
Validation loss: 1.4601936359559335

Epoch: 5| Step: 8
Training loss: 0.07314524799585342
Validation loss: 1.4873333490023048

Epoch: 5| Step: 9
Training loss: 0.11659204959869385
Validation loss: 1.4793563927373579

Epoch: 5| Step: 10
Training loss: 0.08881634473800659
Validation loss: 1.4657162556084253

Epoch: 650| Step: 0
Training loss: 0.07989891618490219
Validation loss: 1.5232047252757575

Epoch: 5| Step: 1
Training loss: 0.08813808858394623
Validation loss: 1.5244604746500652

Epoch: 5| Step: 2
Training loss: 0.16054852306842804
Validation loss: 1.5478870073954265

Epoch: 5| Step: 3
Training loss: 0.11380738019943237
Validation loss: 1.5560300016915927

Epoch: 5| Step: 4
Training loss: 0.13042473793029785
Validation loss: 1.55979561421179

Epoch: 5| Step: 5
Training loss: 0.0644323006272316
Validation loss: 1.551910932346057

Epoch: 5| Step: 6
Training loss: 0.08525034785270691
Validation loss: 1.5501400437406314

Epoch: 5| Step: 7
Training loss: 0.08707091212272644
Validation loss: 1.5081682487200665

Epoch: 5| Step: 8
Training loss: 0.10303273051977158
Validation loss: 1.4905437397700485

Epoch: 5| Step: 9
Training loss: 0.10226644575595856
Validation loss: 1.4761341861499253

Epoch: 5| Step: 10
Training loss: 0.08439570665359497
Validation loss: 1.4786005609778947

Epoch: 651| Step: 0
Training loss: 0.08711835741996765
Validation loss: 1.5302318129488217

Epoch: 5| Step: 1
Training loss: 0.11170663684606552
Validation loss: 1.505260585456766

Epoch: 5| Step: 2
Training loss: 0.0920141190290451
Validation loss: 1.514243132324629

Epoch: 5| Step: 3
Training loss: 0.11867249011993408
Validation loss: 1.5258830760114936

Epoch: 5| Step: 4
Training loss: 0.05510997772216797
Validation loss: 1.5478834746986307

Epoch: 5| Step: 5
Training loss: 0.07074065506458282
Validation loss: 1.5632633983447988

Epoch: 5| Step: 6
Training loss: 0.10994584858417511
Validation loss: 1.5657563555625178

Epoch: 5| Step: 7
Training loss: 0.19551943242549896
Validation loss: 1.5603574129842943

Epoch: 5| Step: 8
Training loss: 0.11817662417888641
Validation loss: 1.5515107826520038

Epoch: 5| Step: 9
Training loss: 0.08556801080703735
Validation loss: 1.5548721724940884

Epoch: 5| Step: 10
Training loss: 0.07880055159330368
Validation loss: 1.561853124249366

Epoch: 652| Step: 0
Training loss: 0.0614192858338356
Validation loss: 1.5686304569244385

Epoch: 5| Step: 1
Training loss: 0.06986985355615616
Validation loss: 1.5218229409187072

Epoch: 5| Step: 2
Training loss: 0.0981641337275505
Validation loss: 1.5348065822355208

Epoch: 5| Step: 3
Training loss: 0.08289209753274918
Validation loss: 1.5400808459968978

Epoch: 5| Step: 4
Training loss: 0.0809309259057045
Validation loss: 1.5447344305694743

Epoch: 5| Step: 5
Training loss: 0.08641137182712555
Validation loss: 1.5234861207264725

Epoch: 5| Step: 6
Training loss: 0.0632842630147934
Validation loss: 1.5271551250129618

Epoch: 5| Step: 7
Training loss: 0.08878029882907867
Validation loss: 1.5391860931150374

Epoch: 5| Step: 8
Training loss: 0.14099594950675964
Validation loss: 1.5131216164558166

Epoch: 5| Step: 9
Training loss: 0.09441979974508286
Validation loss: 1.513590931892395

Epoch: 5| Step: 10
Training loss: 0.07462766021490097
Validation loss: 1.506194717140608

Epoch: 653| Step: 0
Training loss: 0.09456586092710495
Validation loss: 1.5003344333300026

Epoch: 5| Step: 1
Training loss: 0.04162538796663284
Validation loss: 1.4901030217447588

Epoch: 5| Step: 2
Training loss: 0.06040403991937637
Validation loss: 1.5253773458221906

Epoch: 5| Step: 3
Training loss: 0.05095374584197998
Validation loss: 1.4975731142105595

Epoch: 5| Step: 4
Training loss: 0.0836050882935524
Validation loss: 1.498174290503225

Epoch: 5| Step: 5
Training loss: 0.07177416980266571
Validation loss: 1.495845906196102

Epoch: 5| Step: 6
Training loss: 0.06053132563829422
Validation loss: 1.4774737127365605

Epoch: 5| Step: 7
Training loss: 0.0920473113656044
Validation loss: 1.4876811478727607

Epoch: 5| Step: 8
Training loss: 0.12435846030712128
Validation loss: 1.4639631343144242

Epoch: 5| Step: 9
Training loss: 0.05290260165929794
Validation loss: 1.4652064372134466

Epoch: 5| Step: 10
Training loss: 0.09836632758378983
Validation loss: 1.4894346101309663

Epoch: 654| Step: 0
Training loss: 0.05693933367729187
Validation loss: 1.4733472267786663

Epoch: 5| Step: 1
Training loss: 0.07774176448583603
Validation loss: 1.4810117918957946

Epoch: 5| Step: 2
Training loss: 0.08344832062721252
Validation loss: 1.475173145212153

Epoch: 5| Step: 3
Training loss: 0.061683692038059235
Validation loss: 1.4825212647837978

Epoch: 5| Step: 4
Training loss: 0.07884582877159119
Validation loss: 1.4886956266177598

Epoch: 5| Step: 5
Training loss: 0.046184130012989044
Validation loss: 1.4901384961220525

Epoch: 5| Step: 6
Training loss: 0.12086205184459686
Validation loss: 1.5198288845118655

Epoch: 5| Step: 7
Training loss: 0.10699330270290375
Validation loss: 1.5372190398554648

Epoch: 5| Step: 8
Training loss: 0.07773645967245102
Validation loss: 1.5233483775969474

Epoch: 5| Step: 9
Training loss: 0.07276329398155212
Validation loss: 1.5314506023160872

Epoch: 5| Step: 10
Training loss: 0.09857076406478882
Validation loss: 1.5019611876497987

Epoch: 655| Step: 0
Training loss: 0.0987384170293808
Validation loss: 1.5310557914036576

Epoch: 5| Step: 1
Training loss: 0.07563988864421844
Validation loss: 1.5279618514481412

Epoch: 5| Step: 2
Training loss: 0.10958930104970932
Validation loss: 1.5049958716156662

Epoch: 5| Step: 3
Training loss: 0.09195930510759354
Validation loss: 1.4953189729362406

Epoch: 5| Step: 4
Training loss: 0.08546124398708344
Validation loss: 1.48326067514317

Epoch: 5| Step: 5
Training loss: 0.05228537321090698
Validation loss: 1.4772715331405721

Epoch: 5| Step: 6
Training loss: 0.09941728413105011
Validation loss: 1.4847622661180393

Epoch: 5| Step: 7
Training loss: 0.11857477575540543
Validation loss: 1.474821251566692

Epoch: 5| Step: 8
Training loss: 0.06758228689432144
Validation loss: 1.4679392435217415

Epoch: 5| Step: 9
Training loss: 0.07158897817134857
Validation loss: 1.4880071788705804

Epoch: 5| Step: 10
Training loss: 0.05499020591378212
Validation loss: 1.470750625415515

Epoch: 656| Step: 0
Training loss: 0.0932750254869461
Validation loss: 1.476450466340588

Epoch: 5| Step: 1
Training loss: 0.07738756388425827
Validation loss: 1.4580880890610397

Epoch: 5| Step: 2
Training loss: 0.06005784124135971
Validation loss: 1.4552185958431614

Epoch: 5| Step: 3
Training loss: 0.11580339819192886
Validation loss: 1.4742282052193918

Epoch: 5| Step: 4
Training loss: 0.04479436203837395
Validation loss: 1.4664751688639324

Epoch: 5| Step: 5
Training loss: 0.12115757167339325
Validation loss: 1.4676074251051872

Epoch: 5| Step: 6
Training loss: 0.09165849536657333
Validation loss: 1.4629257161130187

Epoch: 5| Step: 7
Training loss: 0.07302416115999222
Validation loss: 1.4624340739301456

Epoch: 5| Step: 8
Training loss: 0.0574212446808815
Validation loss: 1.471250992949291

Epoch: 5| Step: 9
Training loss: 0.06776304543018341
Validation loss: 1.4822119512865621

Epoch: 5| Step: 10
Training loss: 0.044313423335552216
Validation loss: 1.5135876645324051

Epoch: 657| Step: 0
Training loss: 0.05860245227813721
Validation loss: 1.4950139073915378

Epoch: 5| Step: 1
Training loss: 0.08399342000484467
Validation loss: 1.4805773791446482

Epoch: 5| Step: 2
Training loss: 0.07564078271389008
Validation loss: 1.5190493804152294

Epoch: 5| Step: 3
Training loss: 0.07180409878492355
Validation loss: 1.4801418358279812

Epoch: 5| Step: 4
Training loss: 0.09246762841939926
Validation loss: 1.507708659736059

Epoch: 5| Step: 5
Training loss: 0.04994857683777809
Validation loss: 1.4865076977719542

Epoch: 5| Step: 6
Training loss: 0.03781326487660408
Validation loss: 1.5121901701855403

Epoch: 5| Step: 7
Training loss: 0.07362508028745651
Validation loss: 1.491021122983707

Epoch: 5| Step: 8
Training loss: 0.02871030569076538
Validation loss: 1.5104220631302043

Epoch: 5| Step: 9
Training loss: 0.06433729082345963
Validation loss: 1.5088261160799252

Epoch: 5| Step: 10
Training loss: 0.07320469617843628
Validation loss: 1.5159002093858616

Epoch: 658| Step: 0
Training loss: 0.07114793360233307
Validation loss: 1.4970230620394471

Epoch: 5| Step: 1
Training loss: 0.07181566953659058
Validation loss: 1.4888556516298683

Epoch: 5| Step: 2
Training loss: 0.0725930780172348
Validation loss: 1.5106317330432195

Epoch: 5| Step: 3
Training loss: 0.10858528316020966
Validation loss: 1.5075040017404864

Epoch: 5| Step: 4
Training loss: 0.0746404156088829
Validation loss: 1.5075020328644784

Epoch: 5| Step: 5
Training loss: 0.08645179867744446
Validation loss: 1.5427928624614593

Epoch: 5| Step: 6
Training loss: 0.056544870138168335
Validation loss: 1.531284143847804

Epoch: 5| Step: 7
Training loss: 0.0927749052643776
Validation loss: 1.53498960310413

Epoch: 5| Step: 8
Training loss: 0.06746850162744522
Validation loss: 1.543029546737671

Epoch: 5| Step: 9
Training loss: 0.08890453726053238
Validation loss: 1.5150205691655476

Epoch: 5| Step: 10
Training loss: 0.06336144357919693
Validation loss: 1.5359566583428332

Epoch: 659| Step: 0
Training loss: 0.07465521991252899
Validation loss: 1.510536624539283

Epoch: 5| Step: 1
Training loss: 0.05207742005586624
Validation loss: 1.510109318199978

Epoch: 5| Step: 2
Training loss: 0.07267703115940094
Validation loss: 1.5300394335100729

Epoch: 5| Step: 3
Training loss: 0.07228390127420425
Validation loss: 1.487843955716779

Epoch: 5| Step: 4
Training loss: 0.06907684355974197
Validation loss: 1.5013259328821653

Epoch: 5| Step: 5
Training loss: 0.0650787204504013
Validation loss: 1.48257286958797

Epoch: 5| Step: 6
Training loss: 0.07412513345479965
Validation loss: 1.4827716260827997

Epoch: 5| Step: 7
Training loss: 0.10636311769485474
Validation loss: 1.483784584588902

Epoch: 5| Step: 8
Training loss: 0.08567062765359879
Validation loss: 1.5017249174015497

Epoch: 5| Step: 9
Training loss: 0.11122450977563858
Validation loss: 1.5090275092791485

Epoch: 5| Step: 10
Training loss: 0.08343428373336792
Validation loss: 1.5175359402933428

Epoch: 660| Step: 0
Training loss: 0.051501721143722534
Validation loss: 1.4951416728317097

Epoch: 5| Step: 1
Training loss: 0.09341871738433838
Validation loss: 1.5014786886912521

Epoch: 5| Step: 2
Training loss: 0.04166730120778084
Validation loss: 1.4987476897496048

Epoch: 5| Step: 3
Training loss: 0.0884178876876831
Validation loss: 1.511451832709774

Epoch: 5| Step: 4
Training loss: 0.05937919765710831
Validation loss: 1.5304307604348788

Epoch: 5| Step: 5
Training loss: 0.04025476425886154
Validation loss: 1.5124895175298054

Epoch: 5| Step: 6
Training loss: 0.06027766317129135
Validation loss: 1.5238462494265648

Epoch: 5| Step: 7
Training loss: 0.10029717534780502
Validation loss: 1.5397850800586004

Epoch: 5| Step: 8
Training loss: 0.08517330884933472
Validation loss: 1.5226122089611587

Epoch: 5| Step: 9
Training loss: 0.04451177269220352
Validation loss: 1.5148824299535444

Epoch: 5| Step: 10
Training loss: 0.05434509739279747
Validation loss: 1.480241928049313

Epoch: 661| Step: 0
Training loss: 0.047709740698337555
Validation loss: 1.4900280512789243

Epoch: 5| Step: 1
Training loss: 0.05553349852561951
Validation loss: 1.5041246189866015

Epoch: 5| Step: 2
Training loss: 0.05995992571115494
Validation loss: 1.5058495742018505

Epoch: 5| Step: 3
Training loss: 0.0805635005235672
Validation loss: 1.47797982282536

Epoch: 5| Step: 4
Training loss: 0.0712093859910965
Validation loss: 1.45571723932861

Epoch: 5| Step: 5
Training loss: 0.07064029574394226
Validation loss: 1.5083462320348269

Epoch: 5| Step: 6
Training loss: 0.054840315133333206
Validation loss: 1.5212027808671356

Epoch: 5| Step: 7
Training loss: 0.11486025899648666
Validation loss: 1.5106345735570437

Epoch: 5| Step: 8
Training loss: 0.04411919042468071
Validation loss: 1.520479932908089

Epoch: 5| Step: 9
Training loss: 0.13950982689857483
Validation loss: 1.5324681023115754

Epoch: 5| Step: 10
Training loss: 0.09169686585664749
Validation loss: 1.5149891325222549

Epoch: 662| Step: 0
Training loss: 0.10770110785961151
Validation loss: 1.5087529318307036

Epoch: 5| Step: 1
Training loss: 0.07661505043506622
Validation loss: 1.5192724453505648

Epoch: 5| Step: 2
Training loss: 0.140674889087677
Validation loss: 1.5060200434859081

Epoch: 5| Step: 3
Training loss: 0.07587070763111115
Validation loss: 1.5068788413078553

Epoch: 5| Step: 4
Training loss: 0.08370016515254974
Validation loss: 1.4944642019528214

Epoch: 5| Step: 5
Training loss: 0.08954634517431259
Validation loss: 1.496629238128662

Epoch: 5| Step: 6
Training loss: 0.07841457426548004
Validation loss: 1.5259462735986198

Epoch: 5| Step: 7
Training loss: 0.0539216622710228
Validation loss: 1.5177658847583237

Epoch: 5| Step: 8
Training loss: 0.09663309901952744
Validation loss: 1.507326631135838

Epoch: 5| Step: 9
Training loss: 0.051961857825517654
Validation loss: 1.4885336583660496

Epoch: 5| Step: 10
Training loss: 0.058737531304359436
Validation loss: 1.5102322511775519

Epoch: 663| Step: 0
Training loss: 0.10211296379566193
Validation loss: 1.4954440247627996

Epoch: 5| Step: 1
Training loss: 0.0703606978058815
Validation loss: 1.5044211341488747

Epoch: 5| Step: 2
Training loss: 0.0860939472913742
Validation loss: 1.5100734182583389

Epoch: 5| Step: 3
Training loss: 0.06633780151605606
Validation loss: 1.5090911772943312

Epoch: 5| Step: 4
Training loss: 0.05019056797027588
Validation loss: 1.5132996484797487

Epoch: 5| Step: 5
Training loss: 0.04710490629076958
Validation loss: 1.5125012602857364

Epoch: 5| Step: 6
Training loss: 0.1119198203086853
Validation loss: 1.5218563259288829

Epoch: 5| Step: 7
Training loss: 0.049909643828868866
Validation loss: 1.5318865237697479

Epoch: 5| Step: 8
Training loss: 0.0861005038022995
Validation loss: 1.5109145205507997

Epoch: 5| Step: 9
Training loss: 0.04462338984012604
Validation loss: 1.4705579216762255

Epoch: 5| Step: 10
Training loss: 0.0872151181101799
Validation loss: 1.4858744464894778

Epoch: 664| Step: 0
Training loss: 0.06644771993160248
Validation loss: 1.4741388854160105

Epoch: 5| Step: 1
Training loss: 0.09729781001806259
Validation loss: 1.4559025802919943

Epoch: 5| Step: 2
Training loss: 0.08189068734645844
Validation loss: 1.4846406854609007

Epoch: 5| Step: 3
Training loss: 0.07856722921133041
Validation loss: 1.4943526329532746

Epoch: 5| Step: 4
Training loss: 0.06746132671833038
Validation loss: 1.5023727083718905

Epoch: 5| Step: 5
Training loss: 0.08003315329551697
Validation loss: 1.5080325340711942

Epoch: 5| Step: 6
Training loss: 0.07077445089817047
Validation loss: 1.5089299986439366

Epoch: 5| Step: 7
Training loss: 0.05837959051132202
Validation loss: 1.523084004720052

Epoch: 5| Step: 8
Training loss: 0.06455574929714203
Validation loss: 1.5143733652689124

Epoch: 5| Step: 9
Training loss: 0.11194728314876556
Validation loss: 1.5127123735284294

Epoch: 5| Step: 10
Training loss: 0.11951619386672974
Validation loss: 1.5034440012388333

Epoch: 665| Step: 0
Training loss: 0.10329000651836395
Validation loss: 1.4864312769264303

Epoch: 5| Step: 1
Training loss: 0.08304198086261749
Validation loss: 1.4829392997167443

Epoch: 5| Step: 2
Training loss: 0.09675882756710052
Validation loss: 1.4729418370031542

Epoch: 5| Step: 3
Training loss: 0.07407271862030029
Validation loss: 1.4787012505274948

Epoch: 5| Step: 4
Training loss: 0.09839673340320587
Validation loss: 1.4977045777023479

Epoch: 5| Step: 5
Training loss: 0.07038447260856628
Validation loss: 1.4967661032112696

Epoch: 5| Step: 6
Training loss: 0.04913374036550522
Validation loss: 1.5135357251731298

Epoch: 5| Step: 7
Training loss: 0.05983073636889458
Validation loss: 1.5258068243662517

Epoch: 5| Step: 8
Training loss: 0.06984690576791763
Validation loss: 1.5208902666645665

Epoch: 5| Step: 9
Training loss: 0.11415410041809082
Validation loss: 1.5396294792493184

Epoch: 5| Step: 10
Training loss: 0.05441329628229141
Validation loss: 1.4979011358753327

Epoch: 666| Step: 0
Training loss: 0.06184626743197441
Validation loss: 1.5024521273951377

Epoch: 5| Step: 1
Training loss: 0.07454558461904526
Validation loss: 1.49611238766742

Epoch: 5| Step: 2
Training loss: 0.053085844963788986
Validation loss: 1.4736469778963315

Epoch: 5| Step: 3
Training loss: 0.0751674547791481
Validation loss: 1.47145712888369

Epoch: 5| Step: 4
Training loss: 0.08194738626480103
Validation loss: 1.5012240896942795

Epoch: 5| Step: 5
Training loss: 0.08235451579093933
Validation loss: 1.5051157551427041

Epoch: 5| Step: 6
Training loss: 0.07864737510681152
Validation loss: 1.51107745785867

Epoch: 5| Step: 7
Training loss: 0.058465830981731415
Validation loss: 1.4994397906846897

Epoch: 5| Step: 8
Training loss: 0.08034348487854004
Validation loss: 1.4987701946689236

Epoch: 5| Step: 9
Training loss: 0.08153030276298523
Validation loss: 1.5021262681612404

Epoch: 5| Step: 10
Training loss: 0.0747075006365776
Validation loss: 1.507255172216764

Epoch: 667| Step: 0
Training loss: 0.08119827508926392
Validation loss: 1.5005294520367858

Epoch: 5| Step: 1
Training loss: 0.05903834104537964
Validation loss: 1.4859275048778904

Epoch: 5| Step: 2
Training loss: 0.07810353487730026
Validation loss: 1.4897553754109207

Epoch: 5| Step: 3
Training loss: 0.05667078495025635
Validation loss: 1.489626258932134

Epoch: 5| Step: 4
Training loss: 0.07527293264865875
Validation loss: 1.4765631223237643

Epoch: 5| Step: 5
Training loss: 0.05241961404681206
Validation loss: 1.479734141339538

Epoch: 5| Step: 6
Training loss: 0.04467308148741722
Validation loss: 1.4693035617951424

Epoch: 5| Step: 7
Training loss: 0.09116586297750473
Validation loss: 1.4707737545813284

Epoch: 5| Step: 8
Training loss: 0.0799652710556984
Validation loss: 1.450751708399865

Epoch: 5| Step: 9
Training loss: 0.08720024675130844
Validation loss: 1.5050546174408288

Epoch: 5| Step: 10
Training loss: 0.07185535132884979
Validation loss: 1.468089536953998

Epoch: 668| Step: 0
Training loss: 0.046045586466789246
Validation loss: 1.4609679919417187

Epoch: 5| Step: 1
Training loss: 0.038812898099422455
Validation loss: 1.495397893331384

Epoch: 5| Step: 2
Training loss: 0.0852472335100174
Validation loss: 1.4817533095677693

Epoch: 5| Step: 3
Training loss: 0.07318675518035889
Validation loss: 1.4676638963401958

Epoch: 5| Step: 4
Training loss: 0.08810820430517197
Validation loss: 1.4818764220001877

Epoch: 5| Step: 5
Training loss: 0.08414352685213089
Validation loss: 1.5151243696930587

Epoch: 5| Step: 6
Training loss: 0.07829190790653229
Validation loss: 1.5176119996655373

Epoch: 5| Step: 7
Training loss: 0.048730432987213135
Validation loss: 1.4976869180638304

Epoch: 5| Step: 8
Training loss: 0.05644385889172554
Validation loss: 1.5133808915333082

Epoch: 5| Step: 9
Training loss: 0.04995322972536087
Validation loss: 1.4893979321243942

Epoch: 5| Step: 10
Training loss: 0.11207929253578186
Validation loss: 1.5107809753828152

Epoch: 669| Step: 0
Training loss: 0.08725550025701523
Validation loss: 1.5075969683226718

Epoch: 5| Step: 1
Training loss: 0.08407088369131088
Validation loss: 1.5284819884966778

Epoch: 5| Step: 2
Training loss: 0.0677124559879303
Validation loss: 1.5173366787613078

Epoch: 5| Step: 3
Training loss: 0.03649664670228958
Validation loss: 1.4990320051870039

Epoch: 5| Step: 4
Training loss: 0.046457745134830475
Validation loss: 1.4878680962388233

Epoch: 5| Step: 5
Training loss: 0.059715814888477325
Validation loss: 1.5167469811695877

Epoch: 5| Step: 6
Training loss: 0.07506707310676575
Validation loss: 1.5175976266143143

Epoch: 5| Step: 7
Training loss: 0.08201678842306137
Validation loss: 1.524646924388024

Epoch: 5| Step: 8
Training loss: 0.07542680948972702
Validation loss: 1.524065386864447

Epoch: 5| Step: 9
Training loss: 0.06565027683973312
Validation loss: 1.5255552338015648

Epoch: 5| Step: 10
Training loss: 0.06559988856315613
Validation loss: 1.5221120747186805

Epoch: 670| Step: 0
Training loss: 0.0828930139541626
Validation loss: 1.4972119331359863

Epoch: 5| Step: 1
Training loss: 0.05501536279916763
Validation loss: 1.5189265474196403

Epoch: 5| Step: 2
Training loss: 0.08381892740726471
Validation loss: 1.5115553538004558

Epoch: 5| Step: 3
Training loss: 0.043106891214847565
Validation loss: 1.5291833262289725

Epoch: 5| Step: 4
Training loss: 0.06855208426713943
Validation loss: 1.5153035886826054

Epoch: 5| Step: 5
Training loss: 0.047965504229068756
Validation loss: 1.5114405270545714

Epoch: 5| Step: 6
Training loss: 0.06728353351354599
Validation loss: 1.5129055912776659

Epoch: 5| Step: 7
Training loss: 0.11703898012638092
Validation loss: 1.5143696185081237

Epoch: 5| Step: 8
Training loss: 0.05694615840911865
Validation loss: 1.512948255385122

Epoch: 5| Step: 9
Training loss: 0.0884564146399498
Validation loss: 1.4867818355560303

Epoch: 5| Step: 10
Training loss: 0.08650080859661102
Validation loss: 1.4935406074729016

Epoch: 671| Step: 0
Training loss: 0.09295883774757385
Validation loss: 1.5000261452890211

Epoch: 5| Step: 1
Training loss: 0.07163798809051514
Validation loss: 1.519925299511161

Epoch: 5| Step: 2
Training loss: 0.08738285303115845
Validation loss: 1.5058240275229178

Epoch: 5| Step: 3
Training loss: 0.06629149615764618
Validation loss: 1.4726409976200392

Epoch: 5| Step: 4
Training loss: 0.049495719373226166
Validation loss: 1.4890528045674807

Epoch: 5| Step: 5
Training loss: 0.13382987678050995
Validation loss: 1.506785160751753

Epoch: 5| Step: 6
Training loss: 0.07362143695354462
Validation loss: 1.5244655301493983

Epoch: 5| Step: 7
Training loss: 0.06410384923219681
Validation loss: 1.5076139274463858

Epoch: 5| Step: 8
Training loss: 0.041966695338487625
Validation loss: 1.5242657674256193

Epoch: 5| Step: 9
Training loss: 0.08647789061069489
Validation loss: 1.5337085531603905

Epoch: 5| Step: 10
Training loss: 0.06719410419464111
Validation loss: 1.5255962751244987

Epoch: 672| Step: 0
Training loss: 0.101584292948246
Validation loss: 1.5040821561249353

Epoch: 5| Step: 1
Training loss: 0.057445086538791656
Validation loss: 1.5016933359125608

Epoch: 5| Step: 2
Training loss: 0.062378622591495514
Validation loss: 1.5133098133148686

Epoch: 5| Step: 3
Training loss: 0.051500122994184494
Validation loss: 1.5369280871524607

Epoch: 5| Step: 4
Training loss: 0.09512440860271454
Validation loss: 1.5213654630927629

Epoch: 5| Step: 5
Training loss: 0.1243743896484375
Validation loss: 1.5189100516739713

Epoch: 5| Step: 6
Training loss: 0.08249945938587189
Validation loss: 1.5245290802371116

Epoch: 5| Step: 7
Training loss: 0.054391492158174515
Validation loss: 1.5011889139811199

Epoch: 5| Step: 8
Training loss: 0.09886354953050613
Validation loss: 1.515205019263811

Epoch: 5| Step: 9
Training loss: 0.08798162639141083
Validation loss: 1.5301428033459572

Epoch: 5| Step: 10
Training loss: 0.08502732217311859
Validation loss: 1.4624281865294262

Epoch: 673| Step: 0
Training loss: 0.04709702357649803
Validation loss: 1.4856660660877024

Epoch: 5| Step: 1
Training loss: 0.09600679576396942
Validation loss: 1.4748953516765306

Epoch: 5| Step: 2
Training loss: 0.10638757050037384
Validation loss: 1.4702459996746433

Epoch: 5| Step: 3
Training loss: 0.11334986984729767
Validation loss: 1.4850749700300154

Epoch: 5| Step: 4
Training loss: 0.06331650912761688
Validation loss: 1.4989111077400945

Epoch: 5| Step: 5
Training loss: 0.04498719051480293
Validation loss: 1.5154419496495237

Epoch: 5| Step: 6
Training loss: 0.0994463711977005
Validation loss: 1.5440648486537318

Epoch: 5| Step: 7
Training loss: 0.07446114718914032
Validation loss: 1.5330084190573743

Epoch: 5| Step: 8
Training loss: 0.050630491226911545
Validation loss: 1.5197274825906242

Epoch: 5| Step: 9
Training loss: 0.09041371196508408
Validation loss: 1.512165436180689

Epoch: 5| Step: 10
Training loss: 0.10613006353378296
Validation loss: 1.4808019950825682

Epoch: 674| Step: 0
Training loss: 0.10582032054662704
Validation loss: 1.4986766333221107

Epoch: 5| Step: 1
Training loss: 0.10014770925045013
Validation loss: 1.4974122739607287

Epoch: 5| Step: 2
Training loss: 0.06490186601877213
Validation loss: 1.5070095254528908

Epoch: 5| Step: 3
Training loss: 0.0764785185456276
Validation loss: 1.4918408804042365

Epoch: 5| Step: 4
Training loss: 0.11009601503610611
Validation loss: 1.5118706431440128

Epoch: 5| Step: 5
Training loss: 0.10227258503437042
Validation loss: 1.50516257362981

Epoch: 5| Step: 6
Training loss: 0.06514625251293182
Validation loss: 1.5292516357155257

Epoch: 5| Step: 7
Training loss: 0.06284896284341812
Validation loss: 1.5650152955003964

Epoch: 5| Step: 8
Training loss: 0.12033072859048843
Validation loss: 1.557084124575379

Epoch: 5| Step: 9
Training loss: 0.11470474302768707
Validation loss: 1.5067574785601707

Epoch: 5| Step: 10
Training loss: 0.09206309169530869
Validation loss: 1.4948648163067397

Epoch: 675| Step: 0
Training loss: 0.08337970077991486
Validation loss: 1.512426132796913

Epoch: 5| Step: 1
Training loss: 0.14876756072044373
Validation loss: 1.465562379488381

Epoch: 5| Step: 2
Training loss: 0.07385839521884918
Validation loss: 1.4723120415082542

Epoch: 5| Step: 3
Training loss: 0.05620652437210083
Validation loss: 1.4513427326756139

Epoch: 5| Step: 4
Training loss: 0.055029064416885376
Validation loss: 1.461060429132113

Epoch: 5| Step: 5
Training loss: 0.10433647781610489
Validation loss: 1.475958840821379

Epoch: 5| Step: 6
Training loss: 0.13144221901893616
Validation loss: 1.482376770306659

Epoch: 5| Step: 7
Training loss: 0.11060123145580292
Validation loss: 1.4892739865087694

Epoch: 5| Step: 8
Training loss: 0.06844332069158554
Validation loss: 1.5251437720432077

Epoch: 5| Step: 9
Training loss: 0.07742077857255936
Validation loss: 1.4994135761773715

Epoch: 5| Step: 10
Training loss: 0.0943589061498642
Validation loss: 1.496528608824617

Epoch: 676| Step: 0
Training loss: 0.04408618062734604
Validation loss: 1.4991550189192577

Epoch: 5| Step: 1
Training loss: 0.07162873446941376
Validation loss: 1.4885095357894897

Epoch: 5| Step: 2
Training loss: 0.07839756458997726
Validation loss: 1.4807348097524335

Epoch: 5| Step: 3
Training loss: 0.07557089626789093
Validation loss: 1.4853017765988585

Epoch: 5| Step: 4
Training loss: 0.11666172742843628
Validation loss: 1.4736124392478698

Epoch: 5| Step: 5
Training loss: 0.09973235428333282
Validation loss: 1.468305476250187

Epoch: 5| Step: 6
Training loss: 0.045322369784116745
Validation loss: 1.46638536196883

Epoch: 5| Step: 7
Training loss: 0.11549349129199982
Validation loss: 1.495284326614872

Epoch: 5| Step: 8
Training loss: 0.10561765730381012
Validation loss: 1.4830304858505086

Epoch: 5| Step: 9
Training loss: 0.07844527065753937
Validation loss: 1.4865696161024031

Epoch: 5| Step: 10
Training loss: 0.0803840160369873
Validation loss: 1.4920470958114953

Epoch: 677| Step: 0
Training loss: 0.05662884563207626
Validation loss: 1.4850055761234735

Epoch: 5| Step: 1
Training loss: 0.09101768583059311
Validation loss: 1.5133978013069398

Epoch: 5| Step: 2
Training loss: 0.0708603486418724
Validation loss: 1.4868752084752566

Epoch: 5| Step: 3
Training loss: 0.10682548582553864
Validation loss: 1.50642313367577

Epoch: 5| Step: 4
Training loss: 0.07422660291194916
Validation loss: 1.494421608986393

Epoch: 5| Step: 5
Training loss: 0.05272035673260689
Validation loss: 1.4993421935266065

Epoch: 5| Step: 6
Training loss: 0.05519747734069824
Validation loss: 1.4873376841186194

Epoch: 5| Step: 7
Training loss: 0.07068511843681335
Validation loss: 1.4915475473609021

Epoch: 5| Step: 8
Training loss: 0.06117807701230049
Validation loss: 1.5115784957844725

Epoch: 5| Step: 9
Training loss: 0.09474502503871918
Validation loss: 1.5231526346616848

Epoch: 5| Step: 10
Training loss: 0.06862268596887589
Validation loss: 1.5358774335153642

Epoch: 678| Step: 0
Training loss: 0.052406929433345795
Validation loss: 1.525108265620406

Epoch: 5| Step: 1
Training loss: 0.05486971139907837
Validation loss: 1.4856124898438812

Epoch: 5| Step: 2
Training loss: 0.07404118031263351
Validation loss: 1.4632888070998653

Epoch: 5| Step: 3
Training loss: 0.0594278946518898
Validation loss: 1.4547183411095732

Epoch: 5| Step: 4
Training loss: 0.05664539337158203
Validation loss: 1.473327285499983

Epoch: 5| Step: 5
Training loss: 0.06408875435590744
Validation loss: 1.4830055262452813

Epoch: 5| Step: 6
Training loss: 0.06591873615980148
Validation loss: 1.4675028542036652

Epoch: 5| Step: 7
Training loss: 0.07223658263683319
Validation loss: 1.5067401880859046

Epoch: 5| Step: 8
Training loss: 0.09033836424350739
Validation loss: 1.5097771883010864

Epoch: 5| Step: 9
Training loss: 0.057217516005039215
Validation loss: 1.5170710381641184

Epoch: 5| Step: 10
Training loss: 0.06599358469247818
Validation loss: 1.5171005520769345

Epoch: 679| Step: 0
Training loss: 0.10231562703847885
Validation loss: 1.5131733584147629

Epoch: 5| Step: 1
Training loss: 0.06812402606010437
Validation loss: 1.494681449346645

Epoch: 5| Step: 2
Training loss: 0.06865982711315155
Validation loss: 1.4966270821068877

Epoch: 5| Step: 3
Training loss: 0.07987932115793228
Validation loss: 1.4786021042895574

Epoch: 5| Step: 4
Training loss: 0.0674080103635788
Validation loss: 1.466272295162242

Epoch: 5| Step: 5
Training loss: 0.06888259947299957
Validation loss: 1.4875293893198813

Epoch: 5| Step: 6
Training loss: 0.07198868691921234
Validation loss: 1.474297228038952

Epoch: 5| Step: 7
Training loss: 0.04576050490140915
Validation loss: 1.4875506137007026

Epoch: 5| Step: 8
Training loss: 0.096458300948143
Validation loss: 1.480762190716241

Epoch: 5| Step: 9
Training loss: 0.05558618903160095
Validation loss: 1.501853378870154

Epoch: 5| Step: 10
Training loss: 0.08508272469043732
Validation loss: 1.4890683966298257

Epoch: 680| Step: 0
Training loss: 0.04384150728583336
Validation loss: 1.508844308955695

Epoch: 5| Step: 1
Training loss: 0.053162895143032074
Validation loss: 1.5000886737659413

Epoch: 5| Step: 2
Training loss: 0.05457767844200134
Validation loss: 1.484897344343124

Epoch: 5| Step: 3
Training loss: 0.09093500673770905
Validation loss: 1.490111404849637

Epoch: 5| Step: 4
Training loss: 0.05013260245323181
Validation loss: 1.509591620455506

Epoch: 5| Step: 5
Training loss: 0.08677627891302109
Validation loss: 1.493890852697434

Epoch: 5| Step: 6
Training loss: 0.06203047186136246
Validation loss: 1.493019570586502

Epoch: 5| Step: 7
Training loss: 0.08453749120235443
Validation loss: 1.4763171019092682

Epoch: 5| Step: 8
Training loss: 0.10342278331518173
Validation loss: 1.4883462421355709

Epoch: 5| Step: 9
Training loss: 0.06670036166906357
Validation loss: 1.4758886541089704

Epoch: 5| Step: 10
Training loss: 0.06784768402576447
Validation loss: 1.4764473797172628

Epoch: 681| Step: 0
Training loss: 0.05420947074890137
Validation loss: 1.4440591860842962

Epoch: 5| Step: 1
Training loss: 0.07826270908117294
Validation loss: 1.4647164857515724

Epoch: 5| Step: 2
Training loss: 0.08980919420719147
Validation loss: 1.470823126454507

Epoch: 5| Step: 3
Training loss: 0.11593873798847198
Validation loss: 1.5138175256790654

Epoch: 5| Step: 4
Training loss: 0.08143738657236099
Validation loss: 1.5101567365789925

Epoch: 5| Step: 5
Training loss: 0.06220708042383194
Validation loss: 1.5122065621037637

Epoch: 5| Step: 6
Training loss: 0.06386439502239227
Validation loss: 1.5078920061870287

Epoch: 5| Step: 7
Training loss: 0.04010222107172012
Validation loss: 1.5077165467764742

Epoch: 5| Step: 8
Training loss: 0.052353549748659134
Validation loss: 1.4894445096292803

Epoch: 5| Step: 9
Training loss: 0.11656396090984344
Validation loss: 1.491471367497598

Epoch: 5| Step: 10
Training loss: 0.12367922812700272
Validation loss: 1.5285743859506422

Epoch: 682| Step: 0
Training loss: 0.06020989269018173
Validation loss: 1.5078750630860687

Epoch: 5| Step: 1
Training loss: 0.11700411140918732
Validation loss: 1.5131133756329935

Epoch: 5| Step: 2
Training loss: 0.05858153849840164
Validation loss: 1.507593120298078

Epoch: 5| Step: 3
Training loss: 0.06971284002065659
Validation loss: 1.5139077639067045

Epoch: 5| Step: 4
Training loss: 0.043047450482845306
Validation loss: 1.5399548414573874

Epoch: 5| Step: 5
Training loss: 0.05861366540193558
Validation loss: 1.5092853487178843

Epoch: 5| Step: 6
Training loss: 0.10214121639728546
Validation loss: 1.522767238719489

Epoch: 5| Step: 7
Training loss: 0.04873914644122124
Validation loss: 1.4605556700819282

Epoch: 5| Step: 8
Training loss: 0.06687335669994354
Validation loss: 1.475429590030383

Epoch: 5| Step: 9
Training loss: 0.06468331813812256
Validation loss: 1.4777024125540128

Epoch: 5| Step: 10
Training loss: 0.05881809443235397
Validation loss: 1.45238313880018

Epoch: 683| Step: 0
Training loss: 0.06477650254964828
Validation loss: 1.471306126604798

Epoch: 5| Step: 1
Training loss: 0.09036393463611603
Validation loss: 1.4637476487826275

Epoch: 5| Step: 2
Training loss: 0.07548963278532028
Validation loss: 1.4858957772613854

Epoch: 5| Step: 3
Training loss: 0.07040474563837051
Validation loss: 1.5101349161517235

Epoch: 5| Step: 4
Training loss: 0.06121690198779106
Validation loss: 1.4766018057382235

Epoch: 5| Step: 5
Training loss: 0.03655160218477249
Validation loss: 1.4896424329409035

Epoch: 5| Step: 6
Training loss: 0.05850669741630554
Validation loss: 1.4594579973528463

Epoch: 5| Step: 7
Training loss: 0.0560624822974205
Validation loss: 1.4550819602063907

Epoch: 5| Step: 8
Training loss: 0.07405441999435425
Validation loss: 1.4586396627528693

Epoch: 5| Step: 9
Training loss: 0.06151977926492691
Validation loss: 1.4637305044358777

Epoch: 5| Step: 10
Training loss: 0.06684111058712006
Validation loss: 1.4618671299308859

Epoch: 684| Step: 0
Training loss: 0.04902976006269455
Validation loss: 1.457602326587964

Epoch: 5| Step: 1
Training loss: 0.07080577313899994
Validation loss: 1.480958224624716

Epoch: 5| Step: 2
Training loss: 0.10231395065784454
Validation loss: 1.4812371730804443

Epoch: 5| Step: 3
Training loss: 0.04380234330892563
Validation loss: 1.5055018099405433

Epoch: 5| Step: 4
Training loss: 0.07785803079605103
Validation loss: 1.4752295888880247

Epoch: 5| Step: 5
Training loss: 0.06080668047070503
Validation loss: 1.4800992002410274

Epoch: 5| Step: 6
Training loss: 0.06654751300811768
Validation loss: 1.4469123450658654

Epoch: 5| Step: 7
Training loss: 0.06727302819490433
Validation loss: 1.4798690426734187

Epoch: 5| Step: 8
Training loss: 0.04134571552276611
Validation loss: 1.464039005259032

Epoch: 5| Step: 9
Training loss: 0.05196649953722954
Validation loss: 1.4657408627130653

Epoch: 5| Step: 10
Training loss: 0.09785277396440506
Validation loss: 1.476672525046974

Epoch: 685| Step: 0
Training loss: 0.06198698282241821
Validation loss: 1.4774321984219294

Epoch: 5| Step: 1
Training loss: 0.05998122692108154
Validation loss: 1.475363019974001

Epoch: 5| Step: 2
Training loss: 0.06761009991168976
Validation loss: 1.476226306730701

Epoch: 5| Step: 3
Training loss: 0.06870557367801666
Validation loss: 1.500722603131366

Epoch: 5| Step: 4
Training loss: 0.05940437316894531
Validation loss: 1.4784701844697357

Epoch: 5| Step: 5
Training loss: 0.07722531259059906
Validation loss: 1.4746499189766504

Epoch: 5| Step: 6
Training loss: 0.08181379735469818
Validation loss: 1.496220040064986

Epoch: 5| Step: 7
Training loss: 0.049917303025722504
Validation loss: 1.4921308646919906

Epoch: 5| Step: 8
Training loss: 0.05325872823596001
Validation loss: 1.495940549399263

Epoch: 5| Step: 9
Training loss: 0.0989484041929245
Validation loss: 1.4671204090118408

Epoch: 5| Step: 10
Training loss: 0.06539834290742874
Validation loss: 1.4838994920894664

Epoch: 686| Step: 0
Training loss: 0.07280095666646957
Validation loss: 1.4792418069736932

Epoch: 5| Step: 1
Training loss: 0.06535109877586365
Validation loss: 1.4646141554719658

Epoch: 5| Step: 2
Training loss: 0.047553498297929764
Validation loss: 1.4815047863991029

Epoch: 5| Step: 3
Training loss: 0.06654529273509979
Validation loss: 1.4668695426756335

Epoch: 5| Step: 4
Training loss: 0.06466688215732574
Validation loss: 1.49139965029173

Epoch: 5| Step: 5
Training loss: 0.0838504284620285
Validation loss: 1.5038414373192737

Epoch: 5| Step: 6
Training loss: 0.1155441626906395
Validation loss: 1.4933120685238992

Epoch: 5| Step: 7
Training loss: 0.05066446214914322
Validation loss: 1.4979849502604494

Epoch: 5| Step: 8
Training loss: 0.06805533170700073
Validation loss: 1.507712043741698

Epoch: 5| Step: 9
Training loss: 0.09088169783353806
Validation loss: 1.4959150501476821

Epoch: 5| Step: 10
Training loss: 0.1022673100233078
Validation loss: 1.5505674539073822

Epoch: 687| Step: 0
Training loss: 0.0648871660232544
Validation loss: 1.554904621134522

Epoch: 5| Step: 1
Training loss: 0.07399232685565948
Validation loss: 1.518765768697185

Epoch: 5| Step: 2
Training loss: 0.09144983440637589
Validation loss: 1.5128135693970548

Epoch: 5| Step: 3
Training loss: 0.08616455644369125
Validation loss: 1.491407814846244

Epoch: 5| Step: 4
Training loss: 0.058735430240631104
Validation loss: 1.4575448625831193

Epoch: 5| Step: 5
Training loss: 0.07933591306209564
Validation loss: 1.4640493264762304

Epoch: 5| Step: 6
Training loss: 0.056593358516693115
Validation loss: 1.478723402946226

Epoch: 5| Step: 7
Training loss: 0.08765076845884323
Validation loss: 1.5042266358611405

Epoch: 5| Step: 8
Training loss: 0.07086615264415741
Validation loss: 1.476582432305941

Epoch: 5| Step: 9
Training loss: 0.07146646827459335
Validation loss: 1.4843560816139303

Epoch: 5| Step: 10
Training loss: 0.050569236278533936
Validation loss: 1.4831918670285134

Epoch: 688| Step: 0
Training loss: 0.0694693922996521
Validation loss: 1.4939712055267826

Epoch: 5| Step: 1
Training loss: 0.06494839489459991
Validation loss: 1.4979605764471076

Epoch: 5| Step: 2
Training loss: 0.06570392847061157
Validation loss: 1.4886629414814774

Epoch: 5| Step: 3
Training loss: 0.10864891856908798
Validation loss: 1.5143273991923178

Epoch: 5| Step: 4
Training loss: 0.08981280028820038
Validation loss: 1.4837931343304214

Epoch: 5| Step: 5
Training loss: 0.06935827434062958
Validation loss: 1.4982463025277661

Epoch: 5| Step: 6
Training loss: 0.05955858901143074
Validation loss: 1.4804546115218953

Epoch: 5| Step: 7
Training loss: 0.08263406902551651
Validation loss: 1.4833781129570418

Epoch: 5| Step: 8
Training loss: 0.04385678470134735
Validation loss: 1.4863486520705684

Epoch: 5| Step: 9
Training loss: 0.0881219357252121
Validation loss: 1.5114680246640277

Epoch: 5| Step: 10
Training loss: 0.07460425049066544
Validation loss: 1.471176589688947

Epoch: 689| Step: 0
Training loss: 0.057808734476566315
Validation loss: 1.4997966545884327

Epoch: 5| Step: 1
Training loss: 0.0540120005607605
Validation loss: 1.4989060894135506

Epoch: 5| Step: 2
Training loss: 0.06706328690052032
Validation loss: 1.4843161926474622

Epoch: 5| Step: 3
Training loss: 0.04824129492044449
Validation loss: 1.5085658296462028

Epoch: 5| Step: 4
Training loss: 0.04509603977203369
Validation loss: 1.5069071272368073

Epoch: 5| Step: 5
Training loss: 0.04657870531082153
Validation loss: 1.4804157300661969

Epoch: 5| Step: 6
Training loss: 0.0605744794011116
Validation loss: 1.5083469242177985

Epoch: 5| Step: 7
Training loss: 0.05857153981924057
Validation loss: 1.5266098540316346

Epoch: 5| Step: 8
Training loss: 0.10840936005115509
Validation loss: 1.5431689267517419

Epoch: 5| Step: 9
Training loss: 0.07393940538167953
Validation loss: 1.5178586001037269

Epoch: 5| Step: 10
Training loss: 0.11548813432455063
Validation loss: 1.5616508273668186

Epoch: 690| Step: 0
Training loss: 0.08567289263010025
Validation loss: 1.5507529640710482

Epoch: 5| Step: 1
Training loss: 0.08787034451961517
Validation loss: 1.5417222681865896

Epoch: 5| Step: 2
Training loss: 0.104483462870121
Validation loss: 1.5306533837831149

Epoch: 5| Step: 3
Training loss: 0.08326013386249542
Validation loss: 1.499964246185877

Epoch: 5| Step: 4
Training loss: 0.05928920581936836
Validation loss: 1.495207477641362

Epoch: 5| Step: 5
Training loss: 0.08210917562246323
Validation loss: 1.4821992663926975

Epoch: 5| Step: 6
Training loss: 0.10979680716991425
Validation loss: 1.4878758486881052

Epoch: 5| Step: 7
Training loss: 0.0616312101483345
Validation loss: 1.494315375563919

Epoch: 5| Step: 8
Training loss: 0.04230241850018501
Validation loss: 1.4849383042704674

Epoch: 5| Step: 9
Training loss: 0.03669809550046921
Validation loss: 1.496203771201513

Epoch: 5| Step: 10
Training loss: 0.05026894435286522
Validation loss: 1.482953074157879

Epoch: 691| Step: 0
Training loss: 0.0643884539604187
Validation loss: 1.500712671587544

Epoch: 5| Step: 1
Training loss: 0.06290187686681747
Validation loss: 1.5216826187667025

Epoch: 5| Step: 2
Training loss: 0.08937764167785645
Validation loss: 1.5229963102648336

Epoch: 5| Step: 3
Training loss: 0.07061643898487091
Validation loss: 1.5020417372385662

Epoch: 5| Step: 4
Training loss: 0.12677983939647675
Validation loss: 1.4885470713338544

Epoch: 5| Step: 5
Training loss: 0.057896457612514496
Validation loss: 1.494135134963579

Epoch: 5| Step: 6
Training loss: 0.08704645186662674
Validation loss: 1.4946232816224456

Epoch: 5| Step: 7
Training loss: 0.10494424402713776
Validation loss: 1.4799564948645971

Epoch: 5| Step: 8
Training loss: 0.05064547061920166
Validation loss: 1.4925188941340293

Epoch: 5| Step: 9
Training loss: 0.055470772087574005
Validation loss: 1.4948868290070565

Epoch: 5| Step: 10
Training loss: 0.09321226179599762
Validation loss: 1.501626903651863

Epoch: 692| Step: 0
Training loss: 0.10597606003284454
Validation loss: 1.5307622160962833

Epoch: 5| Step: 1
Training loss: 0.06674928963184357
Validation loss: 1.5271172241498066

Epoch: 5| Step: 2
Training loss: 0.09276510775089264
Validation loss: 1.5057073139375257

Epoch: 5| Step: 3
Training loss: 0.04789423197507858
Validation loss: 1.512089765200051

Epoch: 5| Step: 4
Training loss: 0.06023238226771355
Validation loss: 1.5246424354532713

Epoch: 5| Step: 5
Training loss: 0.06984993070363998
Validation loss: 1.4796514126562303

Epoch: 5| Step: 6
Training loss: 0.05084041878581047
Validation loss: 1.4929246812738397

Epoch: 5| Step: 7
Training loss: 0.07185285538434982
Validation loss: 1.4916083223076277

Epoch: 5| Step: 8
Training loss: 0.07585765421390533
Validation loss: 1.4945721075099

Epoch: 5| Step: 9
Training loss: 0.0673394501209259
Validation loss: 1.481521451345054

Epoch: 5| Step: 10
Training loss: 0.052785903215408325
Validation loss: 1.497893883335975

Epoch: 693| Step: 0
Training loss: 0.06564753502607346
Validation loss: 1.5063676757197226

Epoch: 5| Step: 1
Training loss: 0.09197728335857391
Validation loss: 1.4926225792977117

Epoch: 5| Step: 2
Training loss: 0.05040116235613823
Validation loss: 1.4878441915717175

Epoch: 5| Step: 3
Training loss: 0.10226128250360489
Validation loss: 1.474957186688659

Epoch: 5| Step: 4
Training loss: 0.1355288028717041
Validation loss: 1.4885899341234596

Epoch: 5| Step: 5
Training loss: 0.06703974306583405
Validation loss: 1.5205186002997941

Epoch: 5| Step: 6
Training loss: 0.07551644742488861
Validation loss: 1.5000167123733028

Epoch: 5| Step: 7
Training loss: 0.08838102221488953
Validation loss: 1.523922897154285

Epoch: 5| Step: 8
Training loss: 0.07258790731430054
Validation loss: 1.5171318169563048

Epoch: 5| Step: 9
Training loss: 0.0928133949637413
Validation loss: 1.5286375963559715

Epoch: 5| Step: 10
Training loss: 0.10032965242862701
Validation loss: 1.5045065867003573

Epoch: 694| Step: 0
Training loss: 0.06456911563873291
Validation loss: 1.4794889714128228

Epoch: 5| Step: 1
Training loss: 0.08530984073877335
Validation loss: 1.4891356319509528

Epoch: 5| Step: 2
Training loss: 0.08525832742452621
Validation loss: 1.5193227305207202

Epoch: 5| Step: 3
Training loss: 0.07160024344921112
Validation loss: 1.5348269010102877

Epoch: 5| Step: 4
Training loss: 0.0729050263762474
Validation loss: 1.5025142437668257

Epoch: 5| Step: 5
Training loss: 0.05923476070165634
Validation loss: 1.5075477746225172

Epoch: 5| Step: 6
Training loss: 0.0652720034122467
Validation loss: 1.4973234130490212

Epoch: 5| Step: 7
Training loss: 0.059747397899627686
Validation loss: 1.498123921373839

Epoch: 5| Step: 8
Training loss: 0.08870396018028259
Validation loss: 1.4781869329432005

Epoch: 5| Step: 9
Training loss: 0.06771226972341537
Validation loss: 1.4978342325456682

Epoch: 5| Step: 10
Training loss: 0.08490067720413208
Validation loss: 1.498128580790694

Epoch: 695| Step: 0
Training loss: 0.08126549422740936
Validation loss: 1.4824885219656012

Epoch: 5| Step: 1
Training loss: 0.07126758992671967
Validation loss: 1.5062249296454973

Epoch: 5| Step: 2
Training loss: 0.055556319653987885
Validation loss: 1.5043660594571022

Epoch: 5| Step: 3
Training loss: 0.05645189434289932
Validation loss: 1.505538954529711

Epoch: 5| Step: 4
Training loss: 0.08648212999105453
Validation loss: 1.4915301351137058

Epoch: 5| Step: 5
Training loss: 0.1037137359380722
Validation loss: 1.4977949780802573

Epoch: 5| Step: 6
Training loss: 0.07809866219758987
Validation loss: 1.5259898054984309

Epoch: 5| Step: 7
Training loss: 0.08253063261508942
Validation loss: 1.5113498703125985

Epoch: 5| Step: 8
Training loss: 0.04977724701166153
Validation loss: 1.5171662440863989

Epoch: 5| Step: 9
Training loss: 0.11117386817932129
Validation loss: 1.5112616810747372

Epoch: 5| Step: 10
Training loss: 0.07029343396425247
Validation loss: 1.5349451675209949

Epoch: 696| Step: 0
Training loss: 0.08862503618001938
Validation loss: 1.5328525471430954

Epoch: 5| Step: 1
Training loss: 0.057048164308071136
Validation loss: 1.4965122284427765

Epoch: 5| Step: 2
Training loss: 0.06562310457229614
Validation loss: 1.511083443959554

Epoch: 5| Step: 3
Training loss: 0.07014037668704987
Validation loss: 1.4947974105035104

Epoch: 5| Step: 4
Training loss: 0.10821297019720078
Validation loss: 1.49439017106128

Epoch: 5| Step: 5
Training loss: 0.11073005199432373
Validation loss: 1.502360059368995

Epoch: 5| Step: 6
Training loss: 0.10156889259815216
Validation loss: 1.5047765951002798

Epoch: 5| Step: 7
Training loss: 0.08345916867256165
Validation loss: 1.5002377430597942

Epoch: 5| Step: 8
Training loss: 0.05465647578239441
Validation loss: 1.5015491913723689

Epoch: 5| Step: 9
Training loss: 0.0760287344455719
Validation loss: 1.5316435278102916

Epoch: 5| Step: 10
Training loss: 0.07058993726968765
Validation loss: 1.520452069979842

Epoch: 697| Step: 0
Training loss: 0.07540885359048843
Validation loss: 1.5206584302327966

Epoch: 5| Step: 1
Training loss: 0.1375899761915207
Validation loss: 1.545277348128698

Epoch: 5| Step: 2
Training loss: 0.10781921446323395
Validation loss: 1.5441372798335167

Epoch: 5| Step: 3
Training loss: 0.061212360858917236
Validation loss: 1.5323192586180985

Epoch: 5| Step: 4
Training loss: 0.08080168068408966
Validation loss: 1.500631345215664

Epoch: 5| Step: 5
Training loss: 0.10188541561365128
Validation loss: 1.4884520243572932

Epoch: 5| Step: 6
Training loss: 0.09936337172985077
Validation loss: 1.4798281288916064

Epoch: 5| Step: 7
Training loss: 0.06312759220600128
Validation loss: 1.4943962456077657

Epoch: 5| Step: 8
Training loss: 0.05514507368206978
Validation loss: 1.50299725801714

Epoch: 5| Step: 9
Training loss: 0.07019610702991486
Validation loss: 1.5209389066183439

Epoch: 5| Step: 10
Training loss: 0.06222847104072571
Validation loss: 1.4993529319763184

Epoch: 698| Step: 0
Training loss: 0.07051219046115875
Validation loss: 1.5095888337781351

Epoch: 5| Step: 1
Training loss: 0.10744331032037735
Validation loss: 1.5281614321534351

Epoch: 5| Step: 2
Training loss: 0.0660356655716896
Validation loss: 1.4896165658068914

Epoch: 5| Step: 3
Training loss: 0.047217417508363724
Validation loss: 1.5053484106576571

Epoch: 5| Step: 4
Training loss: 0.04598404839634895
Validation loss: 1.5090400916273876

Epoch: 5| Step: 5
Training loss: 0.07456730306148529
Validation loss: 1.4967092954984276

Epoch: 5| Step: 6
Training loss: 0.08332591503858566
Validation loss: 1.4647418516938404

Epoch: 5| Step: 7
Training loss: 0.07073675096035004
Validation loss: 1.4840347818149033

Epoch: 5| Step: 8
Training loss: 0.08772166073322296
Validation loss: 1.4879690434343071

Epoch: 5| Step: 9
Training loss: 0.08495618402957916
Validation loss: 1.4835040678260147

Epoch: 5| Step: 10
Training loss: 0.06136735901236534
Validation loss: 1.5042047321155507

Epoch: 699| Step: 0
Training loss: 0.07685644924640656
Validation loss: 1.5136401089288856

Epoch: 5| Step: 1
Training loss: 0.07354773581027985
Validation loss: 1.5008731965095765

Epoch: 5| Step: 2
Training loss: 0.04504254460334778
Validation loss: 1.499770183717051

Epoch: 5| Step: 3
Training loss: 0.059739697724580765
Validation loss: 1.5084672410001037

Epoch: 5| Step: 4
Training loss: 0.0532783642411232
Validation loss: 1.4965508291798253

Epoch: 5| Step: 5
Training loss: 0.04508218914270401
Validation loss: 1.4897911202523015

Epoch: 5| Step: 6
Training loss: 0.08576716482639313
Validation loss: 1.5134584551216455

Epoch: 5| Step: 7
Training loss: 0.051917046308517456
Validation loss: 1.490894938027987

Epoch: 5| Step: 8
Training loss: 0.029136156663298607
Validation loss: 1.496863180591214

Epoch: 5| Step: 9
Training loss: 0.08025798201560974
Validation loss: 1.5020920435587566

Epoch: 5| Step: 10
Training loss: 0.08027251809835434
Validation loss: 1.5017069353852222

Epoch: 700| Step: 0
Training loss: 0.08184026926755905
Validation loss: 1.5095419947819044

Epoch: 5| Step: 1
Training loss: 0.10256228595972061
Validation loss: 1.4855347025778987

Epoch: 5| Step: 2
Training loss: 0.03582822531461716
Validation loss: 1.5287698968764274

Epoch: 5| Step: 3
Training loss: 0.0812755897641182
Validation loss: 1.4944825864607287

Epoch: 5| Step: 4
Training loss: 0.04409760236740112
Validation loss: 1.5091484028805968

Epoch: 5| Step: 5
Training loss: 0.06120062991976738
Validation loss: 1.511401568689654

Epoch: 5| Step: 6
Training loss: 0.0868978276848793
Validation loss: 1.5158479277805617

Epoch: 5| Step: 7
Training loss: 0.0597197599709034
Validation loss: 1.5144131170806063

Epoch: 5| Step: 8
Training loss: 0.06853683292865753
Validation loss: 1.5182936191558838

Epoch: 5| Step: 9
Training loss: 0.10030288994312286
Validation loss: 1.536265362975418

Epoch: 5| Step: 10
Training loss: 0.04478321969509125
Validation loss: 1.536557525716802

Epoch: 701| Step: 0
Training loss: 0.048972856253385544
Validation loss: 1.506717119165646

Epoch: 5| Step: 1
Training loss: 0.04249237850308418
Validation loss: 1.502662968891923

Epoch: 5| Step: 2
Training loss: 0.04563860967755318
Validation loss: 1.5043029246791717

Epoch: 5| Step: 3
Training loss: 0.07111077010631561
Validation loss: 1.4769591810882732

Epoch: 5| Step: 4
Training loss: 0.10403309017419815
Validation loss: 1.470530689403575

Epoch: 5| Step: 5
Training loss: 0.08016594499349594
Validation loss: 1.4841307933612535

Epoch: 5| Step: 6
Training loss: 0.04611203819513321
Validation loss: 1.4816791472896453

Epoch: 5| Step: 7
Training loss: 0.11912190914154053
Validation loss: 1.5275049491595196

Epoch: 5| Step: 8
Training loss: 0.10982602834701538
Validation loss: 1.5276578344324583

Epoch: 5| Step: 9
Training loss: 0.08252004534006119
Validation loss: 1.5180647168108212

Epoch: 5| Step: 10
Training loss: 0.06343597918748856
Validation loss: 1.5219642321268718

Epoch: 702| Step: 0
Training loss: 0.07661381363868713
Validation loss: 1.4988773638202297

Epoch: 5| Step: 1
Training loss: 0.03721003979444504
Validation loss: 1.4677639866387973

Epoch: 5| Step: 2
Training loss: 0.05179320648312569
Validation loss: 1.4593280335908294

Epoch: 5| Step: 3
Training loss: 0.10595307499170303
Validation loss: 1.4748242273125598

Epoch: 5| Step: 4
Training loss: 0.11605657637119293
Validation loss: 1.4686458386400694

Epoch: 5| Step: 5
Training loss: 0.08220873773097992
Validation loss: 1.4750201253480808

Epoch: 5| Step: 6
Training loss: 0.08471687138080597
Validation loss: 1.476882016786965

Epoch: 5| Step: 7
Training loss: 0.06323017179965973
Validation loss: 1.4666554312552176

Epoch: 5| Step: 8
Training loss: 0.05431468039751053
Validation loss: 1.500475198991837

Epoch: 5| Step: 9
Training loss: 0.07018537074327469
Validation loss: 1.4780855653106526

Epoch: 5| Step: 10
Training loss: 0.0705927386879921
Validation loss: 1.5166099866231282

Epoch: 703| Step: 0
Training loss: 0.06384307891130447
Validation loss: 1.5386336208671652

Epoch: 5| Step: 1
Training loss: 0.09300871193408966
Validation loss: 1.53782965419113

Epoch: 5| Step: 2
Training loss: 0.0683889240026474
Validation loss: 1.5479617285472091

Epoch: 5| Step: 3
Training loss: 0.045949846506118774
Validation loss: 1.4969649686608264

Epoch: 5| Step: 4
Training loss: 0.12129779160022736
Validation loss: 1.5017783782815421

Epoch: 5| Step: 5
Training loss: 0.0886886864900589
Validation loss: 1.4996717296620852

Epoch: 5| Step: 6
Training loss: 0.05409913510084152
Validation loss: 1.4948519955399215

Epoch: 5| Step: 7
Training loss: 0.06676816940307617
Validation loss: 1.5068358554634997

Epoch: 5| Step: 8
Training loss: 0.059382058680057526
Validation loss: 1.5114707267412575

Epoch: 5| Step: 9
Training loss: 0.0637841448187828
Validation loss: 1.5380757098556848

Epoch: 5| Step: 10
Training loss: 0.11522195488214493
Validation loss: 1.532084773945552

Epoch: 704| Step: 0
Training loss: 0.05143899843096733
Validation loss: 1.5412177578095467

Epoch: 5| Step: 1
Training loss: 0.09373383969068527
Validation loss: 1.5383922162876333

Epoch: 5| Step: 2
Training loss: 0.06292493641376495
Validation loss: 1.5084326523606495

Epoch: 5| Step: 3
Training loss: 0.06733636558055878
Validation loss: 1.4960750226051576

Epoch: 5| Step: 4
Training loss: 0.06753283739089966
Validation loss: 1.495837778173467

Epoch: 5| Step: 5
Training loss: 0.11760178953409195
Validation loss: 1.4859749694024362

Epoch: 5| Step: 6
Training loss: 0.11969952285289764
Validation loss: 1.4978717655263922

Epoch: 5| Step: 7
Training loss: 0.08546304702758789
Validation loss: 1.5171726480607064

Epoch: 5| Step: 8
Training loss: 0.0984763354063034
Validation loss: 1.4892558295239684

Epoch: 5| Step: 9
Training loss: 0.06346186995506287
Validation loss: 1.4837022148152834

Epoch: 5| Step: 10
Training loss: 0.05592717230319977
Validation loss: 1.502932002467494

Epoch: 705| Step: 0
Training loss: 0.06182824820280075
Validation loss: 1.525463214484594

Epoch: 5| Step: 1
Training loss: 0.054471004754304886
Validation loss: 1.4985907603335638

Epoch: 5| Step: 2
Training loss: 0.0870627909898758
Validation loss: 1.5268506055237145

Epoch: 5| Step: 3
Training loss: 0.04249940440058708
Validation loss: 1.4766729627886126

Epoch: 5| Step: 4
Training loss: 0.08760705590248108
Validation loss: 1.5100006006097282

Epoch: 5| Step: 5
Training loss: 0.04129708185791969
Validation loss: 1.5044239938900035

Epoch: 5| Step: 6
Training loss: 0.07840792834758759
Validation loss: 1.4685447856944094

Epoch: 5| Step: 7
Training loss: 0.0732119157910347
Validation loss: 1.4611465674574657

Epoch: 5| Step: 8
Training loss: 0.05159192159771919
Validation loss: 1.4617125398369246

Epoch: 5| Step: 9
Training loss: 0.06582728028297424
Validation loss: 1.4674872390685543

Epoch: 5| Step: 10
Training loss: 0.09538214653730392
Validation loss: 1.4394145563084593

Epoch: 706| Step: 0
Training loss: 0.07891184091567993
Validation loss: 1.4513776635610929

Epoch: 5| Step: 1
Training loss: 0.04525812715291977
Validation loss: 1.4601069746478912

Epoch: 5| Step: 2
Training loss: 0.08931337296962738
Validation loss: 1.4827560827296267

Epoch: 5| Step: 3
Training loss: 0.09844502806663513
Validation loss: 1.4649979542660456

Epoch: 5| Step: 4
Training loss: 0.0611540786921978
Validation loss: 1.4767214444375807

Epoch: 5| Step: 5
Training loss: 0.09215151518583298
Validation loss: 1.4841382785509991

Epoch: 5| Step: 6
Training loss: 0.03765792399644852
Validation loss: 1.4920926222237207

Epoch: 5| Step: 7
Training loss: 0.07667922228574753
Validation loss: 1.5121067775193082

Epoch: 5| Step: 8
Training loss: 0.07149486988782883
Validation loss: 1.5403155754971247

Epoch: 5| Step: 9
Training loss: 0.08208805322647095
Validation loss: 1.5269651028417772

Epoch: 5| Step: 10
Training loss: 0.0496726855635643
Validation loss: 1.518687722503498

Epoch: 707| Step: 0
Training loss: 0.05417292192578316
Validation loss: 1.5105604061516382

Epoch: 5| Step: 1
Training loss: 0.06917546689510345
Validation loss: 1.5192693978227594

Epoch: 5| Step: 2
Training loss: 0.05686519294977188
Validation loss: 1.5084802848036571

Epoch: 5| Step: 3
Training loss: 0.09899665415287018
Validation loss: 1.5196681522553968

Epoch: 5| Step: 4
Training loss: 0.10352738946676254
Validation loss: 1.525845927576865

Epoch: 5| Step: 5
Training loss: 0.068919837474823
Validation loss: 1.5165247506992792

Epoch: 5| Step: 6
Training loss: 0.04943881928920746
Validation loss: 1.5165724959424747

Epoch: 5| Step: 7
Training loss: 0.048295844346284866
Validation loss: 1.5128511280141852

Epoch: 5| Step: 8
Training loss: 0.08481808006763458
Validation loss: 1.5180638413275442

Epoch: 5| Step: 9
Training loss: 0.09230585396289825
Validation loss: 1.5039453301378476

Epoch: 5| Step: 10
Training loss: 0.05670570582151413
Validation loss: 1.5253120827418503

Epoch: 708| Step: 0
Training loss: 0.049168918281793594
Validation loss: 1.5133380953983595

Epoch: 5| Step: 1
Training loss: 0.06093712896108627
Validation loss: 1.514610964764831

Epoch: 5| Step: 2
Training loss: 0.07509016990661621
Validation loss: 1.5076988499651673

Epoch: 5| Step: 3
Training loss: 0.08450786769390106
Validation loss: 1.5058411154695737

Epoch: 5| Step: 4
Training loss: 0.031962692737579346
Validation loss: 1.4845308546097047

Epoch: 5| Step: 5
Training loss: 0.08986938744783401
Validation loss: 1.5080158146478797

Epoch: 5| Step: 6
Training loss: 0.07798294723033905
Validation loss: 1.4921917389797907

Epoch: 5| Step: 7
Training loss: 0.08550269901752472
Validation loss: 1.515028863824824

Epoch: 5| Step: 8
Training loss: 0.07640465348958969
Validation loss: 1.5074734508350331

Epoch: 5| Step: 9
Training loss: 0.05723121762275696
Validation loss: 1.5213636249624274

Epoch: 5| Step: 10
Training loss: 0.046899277716875076
Validation loss: 1.5223924216403757

Epoch: 709| Step: 0
Training loss: 0.05389585345983505
Validation loss: 1.50543204815157

Epoch: 5| Step: 1
Training loss: 0.061656080186367035
Validation loss: 1.5370033300051125

Epoch: 5| Step: 2
Training loss: 0.0549362376332283
Validation loss: 1.516895083970921

Epoch: 5| Step: 3
Training loss: 0.06030651926994324
Validation loss: 1.5127568219297676

Epoch: 5| Step: 4
Training loss: 0.07934650033712387
Validation loss: 1.5116988792214343

Epoch: 5| Step: 5
Training loss: 0.08849595487117767
Validation loss: 1.5237331210926015

Epoch: 5| Step: 6
Training loss: 0.07686706632375717
Validation loss: 1.534561425127009

Epoch: 5| Step: 7
Training loss: 0.09596150368452072
Validation loss: 1.539863815871618

Epoch: 5| Step: 8
Training loss: 0.07008230686187744
Validation loss: 1.5134058883113246

Epoch: 5| Step: 9
Training loss: 0.0785161629319191
Validation loss: 1.5143455151588685

Epoch: 5| Step: 10
Training loss: 0.08269423991441727
Validation loss: 1.5149451763399187

Epoch: 710| Step: 0
Training loss: 0.05611886456608772
Validation loss: 1.5133682027939828

Epoch: 5| Step: 1
Training loss: 0.0945385992527008
Validation loss: 1.5283970249596464

Epoch: 5| Step: 2
Training loss: 0.06322909891605377
Validation loss: 1.515049695968628

Epoch: 5| Step: 3
Training loss: 0.10379691421985626
Validation loss: 1.528775058766847

Epoch: 5| Step: 4
Training loss: 0.06348317116498947
Validation loss: 1.513244096950818

Epoch: 5| Step: 5
Training loss: 0.06686224788427353
Validation loss: 1.4940682252248128

Epoch: 5| Step: 6
Training loss: 0.09692816436290741
Validation loss: 1.498779844853186

Epoch: 5| Step: 7
Training loss: 0.09534533321857452
Validation loss: 1.527793038275934

Epoch: 5| Step: 8
Training loss: 0.13617326319217682
Validation loss: 1.5194164322268577

Epoch: 5| Step: 9
Training loss: 0.07205873727798462
Validation loss: 1.5680817942465506

Epoch: 5| Step: 10
Training loss: 0.11734665185213089
Validation loss: 1.5903028775286931

Epoch: 711| Step: 0
Training loss: 0.1411716490983963
Validation loss: 1.5974837900489889

Epoch: 5| Step: 1
Training loss: 0.10968102514743805
Validation loss: 1.605756281524576

Epoch: 5| Step: 2
Training loss: 0.11800803989171982
Validation loss: 1.5338680718534736

Epoch: 5| Step: 3
Training loss: 0.08823122829198837
Validation loss: 1.530908897358884

Epoch: 5| Step: 4
Training loss: 0.05996175482869148
Validation loss: 1.4933673720205984

Epoch: 5| Step: 5
Training loss: 0.08626581728458405
Validation loss: 1.4967039836350309

Epoch: 5| Step: 6
Training loss: 0.07850934565067291
Validation loss: 1.4589874103505125

Epoch: 5| Step: 7
Training loss: 0.06071363762021065
Validation loss: 1.4505522558766026

Epoch: 5| Step: 8
Training loss: 0.08422894775867462
Validation loss: 1.4816301157397609

Epoch: 5| Step: 9
Training loss: 0.13505809009075165
Validation loss: 1.4826760779144943

Epoch: 5| Step: 10
Training loss: 0.08980926126241684
Validation loss: 1.4934420034449587

Epoch: 712| Step: 0
Training loss: 0.10446427017450333
Validation loss: 1.4968855925785598

Epoch: 5| Step: 1
Training loss: 0.07672669738531113
Validation loss: 1.504643254382636

Epoch: 5| Step: 2
Training loss: 0.08420728892087936
Validation loss: 1.4620038899042274

Epoch: 5| Step: 3
Training loss: 0.05172652006149292
Validation loss: 1.4611249924987875

Epoch: 5| Step: 4
Training loss: 0.05283083766698837
Validation loss: 1.4651259568429762

Epoch: 5| Step: 5
Training loss: 0.05434729903936386
Validation loss: 1.4654913294699885

Epoch: 5| Step: 6
Training loss: 0.06348486989736557
Validation loss: 1.4962757992488083

Epoch: 5| Step: 7
Training loss: 0.07096994668245316
Validation loss: 1.509384826947284

Epoch: 5| Step: 8
Training loss: 0.08230707794427872
Validation loss: 1.4655718457314275

Epoch: 5| Step: 9
Training loss: 0.053862351924180984
Validation loss: 1.4533097654260614

Epoch: 5| Step: 10
Training loss: 0.11649134755134583
Validation loss: 1.4911460838010233

Epoch: 713| Step: 0
Training loss: 0.039431266486644745
Validation loss: 1.4895186167891308

Epoch: 5| Step: 1
Training loss: 0.08970347791910172
Validation loss: 1.494812564183307

Epoch: 5| Step: 2
Training loss: 0.0393318310379982
Validation loss: 1.5144869037853774

Epoch: 5| Step: 3
Training loss: 0.06146617978811264
Validation loss: 1.543632516296961

Epoch: 5| Step: 4
Training loss: 0.09525022655725479
Validation loss: 1.527470624575051

Epoch: 5| Step: 5
Training loss: 0.07296537607908249
Validation loss: 1.551529630537956

Epoch: 5| Step: 6
Training loss: 0.09454543888568878
Validation loss: 1.5145127952739756

Epoch: 5| Step: 7
Training loss: 0.0594516284763813
Validation loss: 1.5074136321262648

Epoch: 5| Step: 8
Training loss: 0.06601530313491821
Validation loss: 1.5001928537122664

Epoch: 5| Step: 9
Training loss: 0.08102134615182877
Validation loss: 1.519106957220262

Epoch: 5| Step: 10
Training loss: 0.0724809318780899
Validation loss: 1.5190381978147773

Epoch: 714| Step: 0
Training loss: 0.052048154175281525
Validation loss: 1.4891360805880638

Epoch: 5| Step: 1
Training loss: 0.12038564682006836
Validation loss: 1.5160856246948242

Epoch: 5| Step: 2
Training loss: 0.10145270824432373
Validation loss: 1.5367665431832755

Epoch: 5| Step: 3
Training loss: 0.13498470187187195
Validation loss: 1.5490140620098318

Epoch: 5| Step: 4
Training loss: 0.09333662688732147
Validation loss: 1.5484880042332474

Epoch: 5| Step: 5
Training loss: 0.11093807220458984
Validation loss: 1.5570526699866019

Epoch: 5| Step: 6
Training loss: 0.05694333463907242
Validation loss: 1.5251905661757275

Epoch: 5| Step: 7
Training loss: 0.042450111359357834
Validation loss: 1.5318485793247019

Epoch: 5| Step: 8
Training loss: 0.07158462703227997
Validation loss: 1.5435813229571107

Epoch: 5| Step: 9
Training loss: 0.11195049434900284
Validation loss: 1.5196458485818678

Epoch: 5| Step: 10
Training loss: 0.09039155393838882
Validation loss: 1.5007572571436565

Epoch: 715| Step: 0
Training loss: 0.05179732292890549
Validation loss: 1.4876340948125368

Epoch: 5| Step: 1
Training loss: 0.09513695538043976
Validation loss: 1.4721544968184603

Epoch: 5| Step: 2
Training loss: 0.07673803716897964
Validation loss: 1.4718867655723327

Epoch: 5| Step: 3
Training loss: 0.10419275611639023
Validation loss: 1.471471446175729

Epoch: 5| Step: 4
Training loss: 0.09103914350271225
Validation loss: 1.4799681299476213

Epoch: 5| Step: 5
Training loss: 0.10436353832483292
Validation loss: 1.467126695058679

Epoch: 5| Step: 6
Training loss: 0.09674431383609772
Validation loss: 1.4667741290984615

Epoch: 5| Step: 7
Training loss: 0.08113081753253937
Validation loss: 1.50348917002319

Epoch: 5| Step: 8
Training loss: 0.046457476913928986
Validation loss: 1.5109314021243845

Epoch: 5| Step: 9
Training loss: 0.05822509527206421
Validation loss: 1.533465193163964

Epoch: 5| Step: 10
Training loss: 0.061439260840415955
Validation loss: 1.5501508020585584

Epoch: 716| Step: 0
Training loss: 0.09647758305072784
Validation loss: 1.5472595640408096

Epoch: 5| Step: 1
Training loss: 0.07269640266895294
Validation loss: 1.5320793774820143

Epoch: 5| Step: 2
Training loss: 0.07299305498600006
Validation loss: 1.5502409204359977

Epoch: 5| Step: 3
Training loss: 0.10095758736133575
Validation loss: 1.520885698256954

Epoch: 5| Step: 4
Training loss: 0.11195607483386993
Validation loss: 1.5161220585146258

Epoch: 5| Step: 5
Training loss: 0.1055983453989029
Validation loss: 1.5175092643307102

Epoch: 5| Step: 6
Training loss: 0.07299055904150009
Validation loss: 1.5176802450610745

Epoch: 5| Step: 7
Training loss: 0.05585011839866638
Validation loss: 1.530028873874295

Epoch: 5| Step: 8
Training loss: 0.04702301695942879
Validation loss: 1.5125789879470743

Epoch: 5| Step: 9
Training loss: 0.05678870156407356
Validation loss: 1.5041677272447975

Epoch: 5| Step: 10
Training loss: 0.06268492341041565
Validation loss: 1.467124932555742

Epoch: 717| Step: 0
Training loss: 0.07213384658098221
Validation loss: 1.4655286048048286

Epoch: 5| Step: 1
Training loss: 0.08486735820770264
Validation loss: 1.5082336010471467

Epoch: 5| Step: 2
Training loss: 0.053479861468076706
Validation loss: 1.46686569593286

Epoch: 5| Step: 3
Training loss: 0.08386461436748505
Validation loss: 1.4756680329640706

Epoch: 5| Step: 4
Training loss: 0.08788448572158813
Validation loss: 1.4869216770254157

Epoch: 5| Step: 5
Training loss: 0.06639949977397919
Validation loss: 1.489071249961853

Epoch: 5| Step: 6
Training loss: 0.07271680980920792
Validation loss: 1.4930324080169841

Epoch: 5| Step: 7
Training loss: 0.06192191690206528
Validation loss: 1.4923283874347646

Epoch: 5| Step: 8
Training loss: 0.08510243892669678
Validation loss: 1.497815098813785

Epoch: 5| Step: 9
Training loss: 0.10208368301391602
Validation loss: 1.5277017265237787

Epoch: 5| Step: 10
Training loss: 0.060284893959760666
Validation loss: 1.5473693993783766

Epoch: 718| Step: 0
Training loss: 0.059311170130968094
Validation loss: 1.54472327873271

Epoch: 5| Step: 1
Training loss: 0.10399160534143448
Validation loss: 1.5465868032106789

Epoch: 5| Step: 2
Training loss: 0.05549153685569763
Validation loss: 1.578200614580544

Epoch: 5| Step: 3
Training loss: 0.08138962090015411
Validation loss: 1.5684081713358562

Epoch: 5| Step: 4
Training loss: 0.07115256041288376
Validation loss: 1.5536247120108655

Epoch: 5| Step: 5
Training loss: 0.06276625394821167
Validation loss: 1.566155599009606

Epoch: 5| Step: 6
Training loss: 0.09423334151506424
Validation loss: 1.5533719857533772

Epoch: 5| Step: 7
Training loss: 0.045031290501356125
Validation loss: 1.5327123762458883

Epoch: 5| Step: 8
Training loss: 0.04763355106115341
Validation loss: 1.5285924160352318

Epoch: 5| Step: 9
Training loss: 0.07210860401391983
Validation loss: 1.4886538892663934

Epoch: 5| Step: 10
Training loss: 0.13850902020931244
Validation loss: 1.5007863217784512

Epoch: 719| Step: 0
Training loss: 0.11537656933069229
Validation loss: 1.514264090086824

Epoch: 5| Step: 1
Training loss: 0.07820834964513779
Validation loss: 1.4915328064272482

Epoch: 5| Step: 2
Training loss: 0.08650588244199753
Validation loss: 1.5018493270361295

Epoch: 5| Step: 3
Training loss: 0.11949310451745987
Validation loss: 1.5123167819874261

Epoch: 5| Step: 4
Training loss: 0.0982147604227066
Validation loss: 1.5044499802333053

Epoch: 5| Step: 5
Training loss: 0.0860661044716835
Validation loss: 1.4584755794976347

Epoch: 5| Step: 6
Training loss: 0.08040976524353027
Validation loss: 1.4979461469957907

Epoch: 5| Step: 7
Training loss: 0.06938374787569046
Validation loss: 1.4742777296291885

Epoch: 5| Step: 8
Training loss: 0.06512212008237839
Validation loss: 1.4858723250768517

Epoch: 5| Step: 9
Training loss: 0.07928381860256195
Validation loss: 1.5334093083617508

Epoch: 5| Step: 10
Training loss: 0.0893479511141777
Validation loss: 1.53452544571251

Epoch: 720| Step: 0
Training loss: 0.07975994050502777
Validation loss: 1.5664722458008797

Epoch: 5| Step: 1
Training loss: 0.11943743377923965
Validation loss: 1.5661965698324225

Epoch: 5| Step: 2
Training loss: 0.06482861936092377
Validation loss: 1.5691890562734296

Epoch: 5| Step: 3
Training loss: 0.07157181203365326
Validation loss: 1.592910453837405

Epoch: 5| Step: 4
Training loss: 0.10190153121948242
Validation loss: 1.5715152499496297

Epoch: 5| Step: 5
Training loss: 0.06447415053844452
Validation loss: 1.5824940941667045

Epoch: 5| Step: 6
Training loss: 0.0820372998714447
Validation loss: 1.5484626972547142

Epoch: 5| Step: 7
Training loss: 0.07866773754358292
Validation loss: 1.5048352569662116

Epoch: 5| Step: 8
Training loss: 0.11905839294195175
Validation loss: 1.5250901983630272

Epoch: 5| Step: 9
Training loss: 0.12049110978841782
Validation loss: 1.5204309532719273

Epoch: 5| Step: 10
Training loss: 0.08769387751817703
Validation loss: 1.5433405291649602

Epoch: 721| Step: 0
Training loss: 0.10880470275878906
Validation loss: 1.4912634370147542

Epoch: 5| Step: 1
Training loss: 0.06765929609537125
Validation loss: 1.518996847573147

Epoch: 5| Step: 2
Training loss: 0.08599025756120682
Validation loss: 1.4990070366090344

Epoch: 5| Step: 3
Training loss: 0.06652237474918365
Validation loss: 1.5236078129019788

Epoch: 5| Step: 4
Training loss: 0.08558636158704758
Validation loss: 1.519005456278401

Epoch: 5| Step: 5
Training loss: 0.048325274139642715
Validation loss: 1.5089430680838964

Epoch: 5| Step: 6
Training loss: 0.0985688790678978
Validation loss: 1.4973615715580602

Epoch: 5| Step: 7
Training loss: 0.08092252910137177
Validation loss: 1.5091290012482674

Epoch: 5| Step: 8
Training loss: 0.05648566037416458
Validation loss: 1.526476797237191

Epoch: 5| Step: 9
Training loss: 0.08982983231544495
Validation loss: 1.529998751096828

Epoch: 5| Step: 10
Training loss: 0.07336843758821487
Validation loss: 1.5245884285178235

Epoch: 722| Step: 0
Training loss: 0.0832204595208168
Validation loss: 1.5265985400446

Epoch: 5| Step: 1
Training loss: 0.05280238389968872
Validation loss: 1.4945491962535407

Epoch: 5| Step: 2
Training loss: 0.10512657463550568
Validation loss: 1.5067500798932967

Epoch: 5| Step: 3
Training loss: 0.07621388137340546
Validation loss: 1.4927725151020994

Epoch: 5| Step: 4
Training loss: 0.07799501717090607
Validation loss: 1.5124396636921873

Epoch: 5| Step: 5
Training loss: 0.06799932569265366
Validation loss: 1.5337840792953328

Epoch: 5| Step: 6
Training loss: 0.06675773113965988
Validation loss: 1.529058733294087

Epoch: 5| Step: 7
Training loss: 0.10883419215679169
Validation loss: 1.5370426408706173

Epoch: 5| Step: 8
Training loss: 0.0686507523059845
Validation loss: 1.5163311509675876

Epoch: 5| Step: 9
Training loss: 0.04294575750827789
Validation loss: 1.504291437005484

Epoch: 5| Step: 10
Training loss: 0.07132469862699509
Validation loss: 1.5018074768845753

Epoch: 723| Step: 0
Training loss: 0.11232318729162216
Validation loss: 1.493763921081379

Epoch: 5| Step: 1
Training loss: 0.12459540367126465
Validation loss: 1.4831357143258537

Epoch: 5| Step: 2
Training loss: 0.09278770536184311
Validation loss: 1.5113922114013343

Epoch: 5| Step: 3
Training loss: 0.061677467077970505
Validation loss: 1.501768721047268

Epoch: 5| Step: 4
Training loss: 0.06888067722320557
Validation loss: 1.4727931689190608

Epoch: 5| Step: 5
Training loss: 0.06438013166189194
Validation loss: 1.4989034514273367

Epoch: 5| Step: 6
Training loss: 0.08788828551769257
Validation loss: 1.5056740891548894

Epoch: 5| Step: 7
Training loss: 0.11813654005527496
Validation loss: 1.5049214337461738

Epoch: 5| Step: 8
Training loss: 0.07763538509607315
Validation loss: 1.5276842976129184

Epoch: 5| Step: 9
Training loss: 0.06917152553796768
Validation loss: 1.5311305869010188

Epoch: 5| Step: 10
Training loss: 0.069264255464077
Validation loss: 1.5408127679619739

Epoch: 724| Step: 0
Training loss: 0.05368887260556221
Validation loss: 1.5537878172371977

Epoch: 5| Step: 1
Training loss: 0.049737218767404556
Validation loss: 1.5293680365367601

Epoch: 5| Step: 2
Training loss: 0.07499101012945175
Validation loss: 1.5145711789848983

Epoch: 5| Step: 3
Training loss: 0.06816885620355606
Validation loss: 1.5081218468245638

Epoch: 5| Step: 4
Training loss: 0.075116828083992
Validation loss: 1.5120451219620243

Epoch: 5| Step: 5
Training loss: 0.10809800773859024
Validation loss: 1.5056371688842773

Epoch: 5| Step: 6
Training loss: 0.0969577357172966
Validation loss: 1.488319985328182

Epoch: 5| Step: 7
Training loss: 0.07302585989236832
Validation loss: 1.5320585312381867

Epoch: 5| Step: 8
Training loss: 0.1046961173415184
Validation loss: 1.5299014916983984

Epoch: 5| Step: 9
Training loss: 0.0632578581571579
Validation loss: 1.519376447123866

Epoch: 5| Step: 10
Training loss: 0.06687027215957642
Validation loss: 1.5326896405989123

Epoch: 725| Step: 0
Training loss: 0.04276489466428757
Validation loss: 1.5200862493566287

Epoch: 5| Step: 1
Training loss: 0.08122558891773224
Validation loss: 1.534807938401417

Epoch: 5| Step: 2
Training loss: 0.09950938075780869
Validation loss: 1.5024771331458964

Epoch: 5| Step: 3
Training loss: 0.056553829461336136
Validation loss: 1.5047234053252845

Epoch: 5| Step: 4
Training loss: 0.08499111235141754
Validation loss: 1.5274859448914886

Epoch: 5| Step: 5
Training loss: 0.05914734676480293
Validation loss: 1.519391248303075

Epoch: 5| Step: 6
Training loss: 0.06833727657794952
Validation loss: 1.5174529655005342

Epoch: 5| Step: 7
Training loss: 0.0762469619512558
Validation loss: 1.5214478841391943

Epoch: 5| Step: 8
Training loss: 0.058754563331604004
Validation loss: 1.5225447416305542

Epoch: 5| Step: 9
Training loss: 0.0770518109202385
Validation loss: 1.5243056589557278

Epoch: 5| Step: 10
Training loss: 0.06760161370038986
Validation loss: 1.4974874399041618

Epoch: 726| Step: 0
Training loss: 0.0667269378900528
Validation loss: 1.4437544756038214

Epoch: 5| Step: 1
Training loss: 0.06100128963589668
Validation loss: 1.4755436297385924

Epoch: 5| Step: 2
Training loss: 0.06232422590255737
Validation loss: 1.4654160853355163

Epoch: 5| Step: 3
Training loss: 0.07835153490304947
Validation loss: 1.486922989609421

Epoch: 5| Step: 4
Training loss: 0.114455446600914
Validation loss: 1.4640198817817114

Epoch: 5| Step: 5
Training loss: 0.08922087401151657
Validation loss: 1.4795934231050554

Epoch: 5| Step: 6
Training loss: 0.0735403299331665
Validation loss: 1.495842929809324

Epoch: 5| Step: 7
Training loss: 0.058679062873125076
Validation loss: 1.4833471800691338

Epoch: 5| Step: 8
Training loss: 0.056488245725631714
Validation loss: 1.4775637849684684

Epoch: 5| Step: 9
Training loss: 0.06779821217060089
Validation loss: 1.4788628291058283

Epoch: 5| Step: 10
Training loss: 0.07787419855594635
Validation loss: 1.489065331797446

Epoch: 727| Step: 0
Training loss: 0.06958159804344177
Validation loss: 1.4943896301331059

Epoch: 5| Step: 1
Training loss: 0.05156274884939194
Validation loss: 1.4977947383798578

Epoch: 5| Step: 2
Training loss: 0.057508014142513275
Validation loss: 1.5076907911608297

Epoch: 5| Step: 3
Training loss: 0.0766931027173996
Validation loss: 1.4907157318566435

Epoch: 5| Step: 4
Training loss: 0.09644094854593277
Validation loss: 1.5065927684948008

Epoch: 5| Step: 5
Training loss: 0.08956433832645416
Validation loss: 1.520338842945714

Epoch: 5| Step: 6
Training loss: 0.0807008370757103
Validation loss: 1.5242514046289588

Epoch: 5| Step: 7
Training loss: 0.09301979839801788
Validation loss: 1.5021816915081394

Epoch: 5| Step: 8
Training loss: 0.07278220355510712
Validation loss: 1.5044327666682582

Epoch: 5| Step: 9
Training loss: 0.05322585254907608
Validation loss: 1.4949269730557677

Epoch: 5| Step: 10
Training loss: 0.04274969920516014
Validation loss: 1.5274539263017717

Epoch: 728| Step: 0
Training loss: 0.0907803326845169
Validation loss: 1.523316708944177

Epoch: 5| Step: 1
Training loss: 0.07000161707401276
Validation loss: 1.5136098528421054

Epoch: 5| Step: 2
Training loss: 0.05168613791465759
Validation loss: 1.5031972303185412

Epoch: 5| Step: 3
Training loss: 0.05599943548440933
Validation loss: 1.503457792984542

Epoch: 5| Step: 4
Training loss: 0.06102627515792847
Validation loss: 1.5153549544272884

Epoch: 5| Step: 5
Training loss: 0.060397468507289886
Validation loss: 1.4997403737037414

Epoch: 5| Step: 6
Training loss: 0.06329388916492462
Validation loss: 1.4976333110563216

Epoch: 5| Step: 7
Training loss: 0.08248642832040787
Validation loss: 1.4938859176892105

Epoch: 5| Step: 8
Training loss: 0.04414094239473343
Validation loss: 1.4961213322095974

Epoch: 5| Step: 9
Training loss: 0.05208799988031387
Validation loss: 1.4948063512002268

Epoch: 5| Step: 10
Training loss: 0.08046916127204895
Validation loss: 1.5053286616520216

Epoch: 729| Step: 0
Training loss: 0.07433640956878662
Validation loss: 1.5219606737936697

Epoch: 5| Step: 1
Training loss: 0.0867220014333725
Validation loss: 1.5056108441404117

Epoch: 5| Step: 2
Training loss: 0.07402314245700836
Validation loss: 1.4937425198093537

Epoch: 5| Step: 3
Training loss: 0.03765789791941643
Validation loss: 1.4819339821415562

Epoch: 5| Step: 4
Training loss: 0.07433085143566132
Validation loss: 1.5113648035193001

Epoch: 5| Step: 5
Training loss: 0.06863061338663101
Validation loss: 1.4908970543133315

Epoch: 5| Step: 6
Training loss: 0.07522071152925491
Validation loss: 1.5006509673210882

Epoch: 5| Step: 7
Training loss: 0.05309868976473808
Validation loss: 1.4894707997639973

Epoch: 5| Step: 8
Training loss: 0.058494023978710175
Validation loss: 1.5051324136795536

Epoch: 5| Step: 9
Training loss: 0.03737304359674454
Validation loss: 1.4966043900418025

Epoch: 5| Step: 10
Training loss: 0.07284489274024963
Validation loss: 1.5114781298945028

Epoch: 730| Step: 0
Training loss: 0.06465191394090652
Validation loss: 1.5198140413530412

Epoch: 5| Step: 1
Training loss: 0.046048156917095184
Validation loss: 1.4764542521968964

Epoch: 5| Step: 2
Training loss: 0.06746499240398407
Validation loss: 1.487686175172047

Epoch: 5| Step: 3
Training loss: 0.08814217150211334
Validation loss: 1.490891815513693

Epoch: 5| Step: 4
Training loss: 0.05493909865617752
Validation loss: 1.471238112577828

Epoch: 5| Step: 5
Training loss: 0.04481274634599686
Validation loss: 1.491766006715836

Epoch: 5| Step: 6
Training loss: 0.07131756842136383
Validation loss: 1.487329359977476

Epoch: 5| Step: 7
Training loss: 0.06492885202169418
Validation loss: 1.50031191302884

Epoch: 5| Step: 8
Training loss: 0.05036874860525131
Validation loss: 1.5100066020924559

Epoch: 5| Step: 9
Training loss: 0.07481175661087036
Validation loss: 1.5110999935416765

Epoch: 5| Step: 10
Training loss: 0.08885437250137329
Validation loss: 1.5015136259858326

Epoch: 731| Step: 0
Training loss: 0.06173549219965935
Validation loss: 1.4946589700637325

Epoch: 5| Step: 1
Training loss: 0.06952866166830063
Validation loss: 1.5237843105869908

Epoch: 5| Step: 2
Training loss: 0.06214757636189461
Validation loss: 1.5278648535410564

Epoch: 5| Step: 3
Training loss: 0.1027124673128128
Validation loss: 1.5421497834626066

Epoch: 5| Step: 4
Training loss: 0.051555000245571136
Validation loss: 1.5591411244484685

Epoch: 5| Step: 5
Training loss: 0.08416904509067535
Validation loss: 1.5593534515750023

Epoch: 5| Step: 6
Training loss: 0.0631481260061264
Validation loss: 1.541083005166823

Epoch: 5| Step: 7
Training loss: 0.07413986325263977
Validation loss: 1.532724021583475

Epoch: 5| Step: 8
Training loss: 0.049842990934848785
Validation loss: 1.531184337472403

Epoch: 5| Step: 9
Training loss: 0.060484278947114944
Validation loss: 1.4984384813616354

Epoch: 5| Step: 10
Training loss: 0.05471685156226158
Validation loss: 1.510948411880001

Epoch: 732| Step: 0
Training loss: 0.06912414729595184
Validation loss: 1.506462250986407

Epoch: 5| Step: 1
Training loss: 0.0732487291097641
Validation loss: 1.510953785270773

Epoch: 5| Step: 2
Training loss: 0.06315398216247559
Validation loss: 1.5066310551858717

Epoch: 5| Step: 3
Training loss: 0.11856760084629059
Validation loss: 1.5053016229342389

Epoch: 5| Step: 4
Training loss: 0.054873622953891754
Validation loss: 1.4975543111883185

Epoch: 5| Step: 5
Training loss: 0.04625708982348442
Validation loss: 1.53229453679054

Epoch: 5| Step: 6
Training loss: 0.0697958916425705
Validation loss: 1.498526870563466

Epoch: 5| Step: 7
Training loss: 0.05063823610544205
Validation loss: 1.5132373943123767

Epoch: 5| Step: 8
Training loss: 0.04646696522831917
Validation loss: 1.506131588771779

Epoch: 5| Step: 9
Training loss: 0.06406871229410172
Validation loss: 1.5132536157484977

Epoch: 5| Step: 10
Training loss: 0.08458217233419418
Validation loss: 1.4899247833477554

Epoch: 733| Step: 0
Training loss: 0.05310063809156418
Validation loss: 1.5086696852919876

Epoch: 5| Step: 1
Training loss: 0.07224418222904205
Validation loss: 1.4840409960798038

Epoch: 5| Step: 2
Training loss: 0.06754255294799805
Validation loss: 1.5108949500386433

Epoch: 5| Step: 3
Training loss: 0.06374110281467438
Validation loss: 1.495610669095029

Epoch: 5| Step: 4
Training loss: 0.06988976895809174
Validation loss: 1.5460498268886278

Epoch: 5| Step: 5
Training loss: 0.05866517499089241
Validation loss: 1.528907823306258

Epoch: 5| Step: 6
Training loss: 0.05691087245941162
Validation loss: 1.5097010084377822

Epoch: 5| Step: 7
Training loss: 0.03862379863858223
Validation loss: 1.5178437258607598

Epoch: 5| Step: 8
Training loss: 0.04496266692876816
Validation loss: 1.5141299796360794

Epoch: 5| Step: 9
Training loss: 0.06678204238414764
Validation loss: 1.5195922761835077

Epoch: 5| Step: 10
Training loss: 0.055247146636247635
Validation loss: 1.4797224344745759

Epoch: 734| Step: 0
Training loss: 0.09255582839250565
Validation loss: 1.5308157449127526

Epoch: 5| Step: 1
Training loss: 0.04108994081616402
Validation loss: 1.5084181453592034

Epoch: 5| Step: 2
Training loss: 0.056751709431409836
Validation loss: 1.5210395666860765

Epoch: 5| Step: 3
Training loss: 0.06292641907930374
Validation loss: 1.4870921437458327

Epoch: 5| Step: 4
Training loss: 0.0632864460349083
Validation loss: 1.4965698975388722

Epoch: 5| Step: 5
Training loss: 0.04354477673768997
Validation loss: 1.5068666088965632

Epoch: 5| Step: 6
Training loss: 0.05357516556978226
Validation loss: 1.510872539653573

Epoch: 5| Step: 7
Training loss: 0.05561266094446182
Validation loss: 1.5012992928105016

Epoch: 5| Step: 8
Training loss: 0.0747312679886818
Validation loss: 1.5284629419285765

Epoch: 5| Step: 9
Training loss: 0.06990905106067657
Validation loss: 1.508463616012245

Epoch: 5| Step: 10
Training loss: 0.10059607774019241
Validation loss: 1.4967751361990487

Epoch: 735| Step: 0
Training loss: 0.06406024843454361
Validation loss: 1.4882455583541625

Epoch: 5| Step: 1
Training loss: 0.07323820143938065
Validation loss: 1.4799320825966455

Epoch: 5| Step: 2
Training loss: 0.11033916473388672
Validation loss: 1.4764407693698842

Epoch: 5| Step: 3
Training loss: 0.07113298773765564
Validation loss: 1.5076069421665643

Epoch: 5| Step: 4
Training loss: 0.0510779544711113
Validation loss: 1.5018584279603855

Epoch: 5| Step: 5
Training loss: 0.07498735934495926
Validation loss: 1.5418309332222067

Epoch: 5| Step: 6
Training loss: 0.062434643507003784
Validation loss: 1.557359237824717

Epoch: 5| Step: 7
Training loss: 0.07398860156536102
Validation loss: 1.5354048513597058

Epoch: 5| Step: 8
Training loss: 0.08103765547275543
Validation loss: 1.5602833276153893

Epoch: 5| Step: 9
Training loss: 0.056254804134368896
Validation loss: 1.5327560645277782

Epoch: 5| Step: 10
Training loss: 0.09421543031930923
Validation loss: 1.530135646943123

Epoch: 736| Step: 0
Training loss: 0.07796522229909897
Validation loss: 1.5415582759405977

Epoch: 5| Step: 1
Training loss: 0.05295123904943466
Validation loss: 1.503919328412702

Epoch: 5| Step: 2
Training loss: 0.07949702441692352
Validation loss: 1.5079900436503912

Epoch: 5| Step: 3
Training loss: 0.08895756304264069
Validation loss: 1.4929429657997624

Epoch: 5| Step: 4
Training loss: 0.06770800054073334
Validation loss: 1.5177918377742972

Epoch: 5| Step: 5
Training loss: 0.07881876826286316
Validation loss: 1.5186517418071788

Epoch: 5| Step: 6
Training loss: 0.09991806000471115
Validation loss: 1.5472236679446312

Epoch: 5| Step: 7
Training loss: 0.147866889834404
Validation loss: 1.5391563894928142

Epoch: 5| Step: 8
Training loss: 0.05116511508822441
Validation loss: 1.5208433699864212

Epoch: 5| Step: 9
Training loss: 0.04906652122735977
Validation loss: 1.4877105643672328

Epoch: 5| Step: 10
Training loss: 0.0326177179813385
Validation loss: 1.4851896634665869

Epoch: 737| Step: 0
Training loss: 0.07019880414009094
Validation loss: 1.486156573859594

Epoch: 5| Step: 1
Training loss: 0.08593623340129852
Validation loss: 1.5235331096956808

Epoch: 5| Step: 2
Training loss: 0.0636453628540039
Validation loss: 1.5369705628323298

Epoch: 5| Step: 3
Training loss: 0.08488599956035614
Validation loss: 1.4991226683380783

Epoch: 5| Step: 4
Training loss: 0.07763552665710449
Validation loss: 1.5034630349887315

Epoch: 5| Step: 5
Training loss: 0.06393080949783325
Validation loss: 1.498766028752891

Epoch: 5| Step: 6
Training loss: 0.06469917297363281
Validation loss: 1.4944390968609882

Epoch: 5| Step: 7
Training loss: 0.07716235518455505
Validation loss: 1.5000879572283836

Epoch: 5| Step: 8
Training loss: 0.04511788859963417
Validation loss: 1.5051315881872689

Epoch: 5| Step: 9
Training loss: 0.05558411404490471
Validation loss: 1.492926001548767

Epoch: 5| Step: 10
Training loss: 0.08170610666275024
Validation loss: 1.5017280629886094

Epoch: 738| Step: 0
Training loss: 0.07440190017223358
Validation loss: 1.4979131837044992

Epoch: 5| Step: 1
Training loss: 0.052791595458984375
Validation loss: 1.4848984454267768

Epoch: 5| Step: 2
Training loss: 0.04936734586954117
Validation loss: 1.5099802273575977

Epoch: 5| Step: 3
Training loss: 0.0776606872677803
Validation loss: 1.5177596986934703

Epoch: 5| Step: 4
Training loss: 0.0664256364107132
Validation loss: 1.533617309344712

Epoch: 5| Step: 5
Training loss: 0.06960660219192505
Validation loss: 1.5063360012987608

Epoch: 5| Step: 6
Training loss: 0.08564450591802597
Validation loss: 1.5203721702739756

Epoch: 5| Step: 7
Training loss: 0.07460422068834305
Validation loss: 1.513663027876167

Epoch: 5| Step: 8
Training loss: 0.09249211847782135
Validation loss: 1.5206752502790062

Epoch: 5| Step: 9
Training loss: 0.05382189899682999
Validation loss: 1.5163990630898425

Epoch: 5| Step: 10
Training loss: 0.05820947512984276
Validation loss: 1.529067362508466

Epoch: 739| Step: 0
Training loss: 0.07821522653102875
Validation loss: 1.522614985383967

Epoch: 5| Step: 1
Training loss: 0.04331541806459427
Validation loss: 1.5200237151115172

Epoch: 5| Step: 2
Training loss: 0.049700502306222916
Validation loss: 1.4922146989453224

Epoch: 5| Step: 3
Training loss: 0.06361691653728485
Validation loss: 1.4623781647733463

Epoch: 5| Step: 4
Training loss: 0.06528749316930771
Validation loss: 1.4974711056678527

Epoch: 5| Step: 5
Training loss: 0.060499370098114014
Validation loss: 1.5145990181994695

Epoch: 5| Step: 6
Training loss: 0.09246625751256943
Validation loss: 1.4846535152004612

Epoch: 5| Step: 7
Training loss: 0.07488040626049042
Validation loss: 1.4911354934015582

Epoch: 5| Step: 8
Training loss: 0.07629185169935226
Validation loss: 1.5033106496257167

Epoch: 5| Step: 9
Training loss: 0.07624061405658722
Validation loss: 1.5068233154153312

Epoch: 5| Step: 10
Training loss: 0.08163563907146454
Validation loss: 1.5241352358172018

Epoch: 740| Step: 0
Training loss: 0.07766928523778915
Validation loss: 1.524213807557219

Epoch: 5| Step: 1
Training loss: 0.09909982979297638
Validation loss: 1.5169635267667874

Epoch: 5| Step: 2
Training loss: 0.07612814009189606
Validation loss: 1.548858493886968

Epoch: 5| Step: 3
Training loss: 0.06251221150159836
Validation loss: 1.5201579896352624

Epoch: 5| Step: 4
Training loss: 0.07763884961605072
Validation loss: 1.5014091563481156

Epoch: 5| Step: 5
Training loss: 0.0630110651254654
Validation loss: 1.5132597133677492

Epoch: 5| Step: 6
Training loss: 0.06183455511927605
Validation loss: 1.499294541215384

Epoch: 5| Step: 7
Training loss: 0.05744587257504463
Validation loss: 1.4771854082743328

Epoch: 5| Step: 8
Training loss: 0.074591726064682
Validation loss: 1.4974042472018991

Epoch: 5| Step: 9
Training loss: 0.044197436422109604
Validation loss: 1.5033998540652695

Epoch: 5| Step: 10
Training loss: 0.0811435729265213
Validation loss: 1.5049241396688646

Epoch: 741| Step: 0
Training loss: 0.04046196863055229
Validation loss: 1.5042313273235033

Epoch: 5| Step: 1
Training loss: 0.033811118453741074
Validation loss: 1.504040418132659

Epoch: 5| Step: 2
Training loss: 0.047060444951057434
Validation loss: 1.529769165541536

Epoch: 5| Step: 3
Training loss: 0.10249445587396622
Validation loss: 1.5236806267051286

Epoch: 5| Step: 4
Training loss: 0.04960943013429642
Validation loss: 1.5598470741702664

Epoch: 5| Step: 5
Training loss: 0.07061044126749039
Validation loss: 1.591189281914824

Epoch: 5| Step: 6
Training loss: 0.07629428803920746
Validation loss: 1.5313278821206862

Epoch: 5| Step: 7
Training loss: 0.0460689552128315
Validation loss: 1.5107913876092562

Epoch: 5| Step: 8
Training loss: 0.06711940467357635
Validation loss: 1.5006753090889222

Epoch: 5| Step: 9
Training loss: 0.08834773302078247
Validation loss: 1.5046052612284178

Epoch: 5| Step: 10
Training loss: 0.06859507411718369
Validation loss: 1.5058989787614474

Epoch: 742| Step: 0
Training loss: 0.07266822457313538
Validation loss: 1.4971127292161346

Epoch: 5| Step: 1
Training loss: 0.04930456727743149
Validation loss: 1.4848002554267965

Epoch: 5| Step: 2
Training loss: 0.0686897411942482
Validation loss: 1.4788962198841957

Epoch: 5| Step: 3
Training loss: 0.05572035163640976
Validation loss: 1.4993588693680302

Epoch: 5| Step: 4
Training loss: 0.04938587546348572
Validation loss: 1.4876758911276375

Epoch: 5| Step: 5
Training loss: 0.05800216645002365
Validation loss: 1.4884808255780129

Epoch: 5| Step: 6
Training loss: 0.060623764991760254
Validation loss: 1.481841302687122

Epoch: 5| Step: 7
Training loss: 0.052227266132831573
Validation loss: 1.4850080218366397

Epoch: 5| Step: 8
Training loss: 0.06425882875919342
Validation loss: 1.4874394580882082

Epoch: 5| Step: 9
Training loss: 0.0660751685500145
Validation loss: 1.49991778660846

Epoch: 5| Step: 10
Training loss: 0.03643512725830078
Validation loss: 1.5151121667636338

Epoch: 743| Step: 0
Training loss: 0.05324847623705864
Validation loss: 1.5028114344484063

Epoch: 5| Step: 1
Training loss: 0.06819175183773041
Validation loss: 1.5033212207978772

Epoch: 5| Step: 2
Training loss: 0.039923377335071564
Validation loss: 1.5084200866760746

Epoch: 5| Step: 3
Training loss: 0.04630618542432785
Validation loss: 1.5204712549845378

Epoch: 5| Step: 4
Training loss: 0.05501507967710495
Validation loss: 1.4958231359399774

Epoch: 5| Step: 5
Training loss: 0.05467833951115608
Validation loss: 1.495008808310314

Epoch: 5| Step: 6
Training loss: 0.03914840891957283
Validation loss: 1.505648983422146

Epoch: 5| Step: 7
Training loss: 0.057749319821596146
Validation loss: 1.4995708888576877

Epoch: 5| Step: 8
Training loss: 0.05007444694638252
Validation loss: 1.4902778197360296

Epoch: 5| Step: 9
Training loss: 0.0806884914636612
Validation loss: 1.4993728771004626

Epoch: 5| Step: 10
Training loss: 0.08127499371767044
Validation loss: 1.5159402431980256

Epoch: 744| Step: 0
Training loss: 0.0883164331316948
Validation loss: 1.5104419018632622

Epoch: 5| Step: 1
Training loss: 0.04703880473971367
Validation loss: 1.5131554372849003

Epoch: 5| Step: 2
Training loss: 0.04315130412578583
Validation loss: 1.5026102027585428

Epoch: 5| Step: 3
Training loss: 0.04247034341096878
Validation loss: 1.5039373187608616

Epoch: 5| Step: 4
Training loss: 0.06600330770015717
Validation loss: 1.5172764037245063

Epoch: 5| Step: 5
Training loss: 0.06543203443288803
Validation loss: 1.4872806943872923

Epoch: 5| Step: 6
Training loss: 0.06546465307474136
Validation loss: 1.4979987605925529

Epoch: 5| Step: 7
Training loss: 0.04536702483892441
Validation loss: 1.497048948400764

Epoch: 5| Step: 8
Training loss: 0.03891637548804283
Validation loss: 1.4891992602297055

Epoch: 5| Step: 9
Training loss: 0.12278102338314056
Validation loss: 1.4997897430132794

Epoch: 5| Step: 10
Training loss: 0.07628139108419418
Validation loss: 1.4969382773163498

Epoch: 745| Step: 0
Training loss: 0.041729822754859924
Validation loss: 1.5083432979481195

Epoch: 5| Step: 1
Training loss: 0.04296383261680603
Validation loss: 1.4983832278559286

Epoch: 5| Step: 2
Training loss: 0.032583512365818024
Validation loss: 1.4988096478164836

Epoch: 5| Step: 3
Training loss: 0.06181999295949936
Validation loss: 1.5031529729084303

Epoch: 5| Step: 4
Training loss: 0.06265437602996826
Validation loss: 1.526232534839261

Epoch: 5| Step: 5
Training loss: 0.05372069403529167
Validation loss: 1.5231425313539402

Epoch: 5| Step: 6
Training loss: 0.03989441320300102
Validation loss: 1.4839221303180983

Epoch: 5| Step: 7
Training loss: 0.0478629432618618
Validation loss: 1.5032771953972437

Epoch: 5| Step: 8
Training loss: 0.07997693121433258
Validation loss: 1.491354234756962

Epoch: 5| Step: 9
Training loss: 0.08766498416662216
Validation loss: 1.5070526522974814

Epoch: 5| Step: 10
Training loss: 0.07414994388818741
Validation loss: 1.5254024908106814

Epoch: 746| Step: 0
Training loss: 0.049885887652635574
Validation loss: 1.5239506774051215

Epoch: 5| Step: 1
Training loss: 0.056434620171785355
Validation loss: 1.499966662417176

Epoch: 5| Step: 2
Training loss: 0.09756658226251602
Validation loss: 1.5124960432770431

Epoch: 5| Step: 3
Training loss: 0.1038389652967453
Validation loss: 1.5093798118252908

Epoch: 5| Step: 4
Training loss: 0.03622407466173172
Validation loss: 1.5011325933599984

Epoch: 5| Step: 5
Training loss: 0.0624920129776001
Validation loss: 1.5011754792223695

Epoch: 5| Step: 6
Training loss: 0.0381927490234375
Validation loss: 1.504171996988276

Epoch: 5| Step: 7
Training loss: 0.08878111094236374
Validation loss: 1.477381076864017

Epoch: 5| Step: 8
Training loss: 0.07657063007354736
Validation loss: 1.492048321231719

Epoch: 5| Step: 9
Training loss: 0.0627969279885292
Validation loss: 1.4763225458001579

Epoch: 5| Step: 10
Training loss: 0.04806168004870415
Validation loss: 1.4738660345795334

Epoch: 747| Step: 0
Training loss: 0.06143894046545029
Validation loss: 1.507476609240296

Epoch: 5| Step: 1
Training loss: 0.06972984969615936
Validation loss: 1.4900056649279851

Epoch: 5| Step: 2
Training loss: 0.05742669850587845
Validation loss: 1.488033486950782

Epoch: 5| Step: 3
Training loss: 0.06629673391580582
Validation loss: 1.444705593970514

Epoch: 5| Step: 4
Training loss: 0.06364722549915314
Validation loss: 1.498299280802409

Epoch: 5| Step: 5
Training loss: 0.06920024752616882
Validation loss: 1.5130570588573333

Epoch: 5| Step: 6
Training loss: 0.0570012703537941
Validation loss: 1.5358410330228909

Epoch: 5| Step: 7
Training loss: 0.07572287321090698
Validation loss: 1.5135763998954528

Epoch: 5| Step: 8
Training loss: 0.047480009496212006
Validation loss: 1.4735531358308689

Epoch: 5| Step: 9
Training loss: 0.048391956835985184
Validation loss: 1.4862153376302412

Epoch: 5| Step: 10
Training loss: 0.06102662906050682
Validation loss: 1.479888117441567

Epoch: 748| Step: 0
Training loss: 0.08677150309085846
Validation loss: 1.4770342688406668

Epoch: 5| Step: 1
Training loss: 0.056421756744384766
Validation loss: 1.4910381737575735

Epoch: 5| Step: 2
Training loss: 0.09877140820026398
Validation loss: 1.4744012073803974

Epoch: 5| Step: 3
Training loss: 0.06223311275243759
Validation loss: 1.483884060254661

Epoch: 5| Step: 4
Training loss: 0.07338286936283112
Validation loss: 1.5011322145820947

Epoch: 5| Step: 5
Training loss: 0.07804837822914124
Validation loss: 1.5167419974521925

Epoch: 5| Step: 6
Training loss: 0.09092914313077927
Validation loss: 1.5322550650565856

Epoch: 5| Step: 7
Training loss: 0.061851441860198975
Validation loss: 1.5235248477228227

Epoch: 5| Step: 8
Training loss: 0.047723438590765
Validation loss: 1.4969579109581568

Epoch: 5| Step: 9
Training loss: 0.03348960727453232
Validation loss: 1.4990913739768408

Epoch: 5| Step: 10
Training loss: 0.038542989641427994
Validation loss: 1.4973868503365466

Epoch: 749| Step: 0
Training loss: 0.07958460599184036
Validation loss: 1.5027158029617802

Epoch: 5| Step: 1
Training loss: 0.0697101280093193
Validation loss: 1.4636580168559987

Epoch: 5| Step: 2
Training loss: 0.06882286071777344
Validation loss: 1.486599233201755

Epoch: 5| Step: 3
Training loss: 0.06551895290613174
Validation loss: 1.468182752209325

Epoch: 5| Step: 4
Training loss: 0.09105702489614487
Validation loss: 1.4973529231163762

Epoch: 5| Step: 5
Training loss: 0.048819832503795624
Validation loss: 1.5276199553602485

Epoch: 5| Step: 6
Training loss: 0.03290422260761261
Validation loss: 1.5285105653988418

Epoch: 5| Step: 7
Training loss: 0.0714292898774147
Validation loss: 1.533328910027781

Epoch: 5| Step: 8
Training loss: 0.03368773311376572
Validation loss: 1.5323038485742384

Epoch: 5| Step: 9
Training loss: 0.034870702773332596
Validation loss: 1.5154528656313497

Epoch: 5| Step: 10
Training loss: 0.06585615873336792
Validation loss: 1.5240988757020684

Epoch: 750| Step: 0
Training loss: 0.046502940356731415
Validation loss: 1.4915501904743973

Epoch: 5| Step: 1
Training loss: 0.04603440687060356
Validation loss: 1.501827774509307

Epoch: 5| Step: 2
Training loss: 0.06545364111661911
Validation loss: 1.5195068505502516

Epoch: 5| Step: 3
Training loss: 0.06249270588159561
Validation loss: 1.512667182953127

Epoch: 5| Step: 4
Training loss: 0.059352971613407135
Validation loss: 1.5271480769239447

Epoch: 5| Step: 5
Training loss: 0.04059397056698799
Validation loss: 1.5661759145798222

Epoch: 5| Step: 6
Training loss: 0.0713241919875145
Validation loss: 1.5378513323363436

Epoch: 5| Step: 7
Training loss: 0.05704694986343384
Validation loss: 1.5717784896973641

Epoch: 5| Step: 8
Training loss: 0.031985510140657425
Validation loss: 1.5762340214944655

Epoch: 5| Step: 9
Training loss: 0.04064576327800751
Validation loss: 1.5702728661157752

Epoch: 5| Step: 10
Training loss: 0.07758110761642456
Validation loss: 1.5274531713096045

Epoch: 751| Step: 0
Training loss: 0.027127940207719803
Validation loss: 1.5345038444765153

Epoch: 5| Step: 1
Training loss: 0.06294234097003937
Validation loss: 1.5105639029574651

Epoch: 5| Step: 2
Training loss: 0.03804996237158775
Validation loss: 1.5150736762631325

Epoch: 5| Step: 3
Training loss: 0.07003134489059448
Validation loss: 1.5052188673327047

Epoch: 5| Step: 4
Training loss: 0.05597670003771782
Validation loss: 1.505675414557098

Epoch: 5| Step: 5
Training loss: 0.04031553864479065
Validation loss: 1.5149028762694328

Epoch: 5| Step: 6
Training loss: 0.09193003922700882
Validation loss: 1.51403594786121

Epoch: 5| Step: 7
Training loss: 0.035679884254932404
Validation loss: 1.5206190116943852

Epoch: 5| Step: 8
Training loss: 0.057076625525951385
Validation loss: 1.5419075655680832

Epoch: 5| Step: 9
Training loss: 0.049143679440021515
Validation loss: 1.503359813844004

Epoch: 5| Step: 10
Training loss: 0.04870687425136566
Validation loss: 1.507214884604177

Epoch: 752| Step: 0
Training loss: 0.04832413047552109
Validation loss: 1.4972074954740462

Epoch: 5| Step: 1
Training loss: 0.0975080281496048
Validation loss: 1.5054036417315084

Epoch: 5| Step: 2
Training loss: 0.05314243957400322
Validation loss: 1.5399674920625583

Epoch: 5| Step: 3
Training loss: 0.07472403347492218
Validation loss: 1.4895014993606075

Epoch: 5| Step: 4
Training loss: 0.0824354887008667
Validation loss: 1.5035267209493985

Epoch: 5| Step: 5
Training loss: 0.06362195312976837
Validation loss: 1.504803878004833

Epoch: 5| Step: 6
Training loss: 0.046457093209028244
Validation loss: 1.5143213861732072

Epoch: 5| Step: 7
Training loss: 0.062296587973833084
Validation loss: 1.522788337481919

Epoch: 5| Step: 8
Training loss: 0.06253398209810257
Validation loss: 1.5462421364681695

Epoch: 5| Step: 9
Training loss: 0.056391023099422455
Validation loss: 1.5539896411280478

Epoch: 5| Step: 10
Training loss: 0.06715506315231323
Validation loss: 1.5549992412649176

Epoch: 753| Step: 0
Training loss: 0.06694954633712769
Validation loss: 1.5275924821053781

Epoch: 5| Step: 1
Training loss: 0.06402750313282013
Validation loss: 1.529627268032361

Epoch: 5| Step: 2
Training loss: 0.0640462189912796
Validation loss: 1.4985702499266593

Epoch: 5| Step: 3
Training loss: 0.08079683035612106
Validation loss: 1.5011072242131798

Epoch: 5| Step: 4
Training loss: 0.08993448317050934
Validation loss: 1.510872071789157

Epoch: 5| Step: 5
Training loss: 0.07912337779998779
Validation loss: 1.5000602686277

Epoch: 5| Step: 6
Training loss: 0.10272513329982758
Validation loss: 1.5010389179311774

Epoch: 5| Step: 7
Training loss: 0.06117050722241402
Validation loss: 1.5332292728526618

Epoch: 5| Step: 8
Training loss: 0.06038777157664299
Validation loss: 1.5354973193137877

Epoch: 5| Step: 9
Training loss: 0.04018484801054001
Validation loss: 1.5561294171117968

Epoch: 5| Step: 10
Training loss: 0.1019689217209816
Validation loss: 1.5684755399662962

Epoch: 754| Step: 0
Training loss: 0.06489412486553192
Validation loss: 1.5542247679925734

Epoch: 5| Step: 1
Training loss: 0.04264594241976738
Validation loss: 1.5511122967607232

Epoch: 5| Step: 2
Training loss: 0.05437181144952774
Validation loss: 1.5546301372589604

Epoch: 5| Step: 3
Training loss: 0.10441634804010391
Validation loss: 1.5016661036399104

Epoch: 5| Step: 4
Training loss: 0.05684981495141983
Validation loss: 1.4809115061195948

Epoch: 5| Step: 5
Training loss: 0.07578042149543762
Validation loss: 1.5090403223550448

Epoch: 5| Step: 6
Training loss: 0.09180931746959686
Validation loss: 1.524840748438271

Epoch: 5| Step: 7
Training loss: 0.08578649908304214
Validation loss: 1.5318877581627137

Epoch: 5| Step: 8
Training loss: 0.07831252366304398
Validation loss: 1.5534530993430846

Epoch: 5| Step: 9
Training loss: 0.09437785297632217
Validation loss: 1.5204789670564796

Epoch: 5| Step: 10
Training loss: 0.0617150142788887
Validation loss: 1.5274590317920973

Epoch: 755| Step: 0
Training loss: 0.05005024001002312
Validation loss: 1.528926113600372

Epoch: 5| Step: 1
Training loss: 0.0582776740193367
Validation loss: 1.5195867169287898

Epoch: 5| Step: 2
Training loss: 0.06158757209777832
Validation loss: 1.5135396013977707

Epoch: 5| Step: 3
Training loss: 0.05189526081085205
Validation loss: 1.5038148536477038

Epoch: 5| Step: 4
Training loss: 0.07038149982690811
Validation loss: 1.4802214612242997

Epoch: 5| Step: 5
Training loss: 0.08767379820346832
Validation loss: 1.4781565499562088

Epoch: 5| Step: 6
Training loss: 0.026710033416748047
Validation loss: 1.4732840035551338

Epoch: 5| Step: 7
Training loss: 0.058465201407670975
Validation loss: 1.4890330171072355

Epoch: 5| Step: 8
Training loss: 0.10091666877269745
Validation loss: 1.4925024714521182

Epoch: 5| Step: 9
Training loss: 0.04635530710220337
Validation loss: 1.497204106341126

Epoch: 5| Step: 10
Training loss: 0.048562273383140564
Validation loss: 1.4993700865776307

Epoch: 756| Step: 0
Training loss: 0.07629255950450897
Validation loss: 1.5039210140064199

Epoch: 5| Step: 1
Training loss: 0.09373354911804199
Validation loss: 1.5133128602017638

Epoch: 5| Step: 2
Training loss: 0.06515413522720337
Validation loss: 1.4876939558213758

Epoch: 5| Step: 3
Training loss: 0.061265118420124054
Validation loss: 1.5029188509910338

Epoch: 5| Step: 4
Training loss: 0.04759670048952103
Validation loss: 1.491873578358722

Epoch: 5| Step: 5
Training loss: 0.05040748044848442
Validation loss: 1.524781770603631

Epoch: 5| Step: 6
Training loss: 0.04894579201936722
Validation loss: 1.5339582299673429

Epoch: 5| Step: 7
Training loss: 0.05832792446017265
Validation loss: 1.5369416603478052

Epoch: 5| Step: 8
Training loss: 0.05017732456326485
Validation loss: 1.508025788491772

Epoch: 5| Step: 9
Training loss: 0.08081553876399994
Validation loss: 1.5245237183827225

Epoch: 5| Step: 10
Training loss: 0.06256935000419617
Validation loss: 1.5047212441762288

Epoch: 757| Step: 0
Training loss: 0.0345761775970459
Validation loss: 1.5146576653244674

Epoch: 5| Step: 1
Training loss: 0.05063336342573166
Validation loss: 1.52341515146276

Epoch: 5| Step: 2
Training loss: 0.09326942265033722
Validation loss: 1.5182217961998397

Epoch: 5| Step: 3
Training loss: 0.06471780687570572
Validation loss: 1.5350457276067426

Epoch: 5| Step: 4
Training loss: 0.07208947092294693
Validation loss: 1.5214679420635264

Epoch: 5| Step: 5
Training loss: 0.05431453511118889
Validation loss: 1.513856376371076

Epoch: 5| Step: 6
Training loss: 0.057787250727415085
Validation loss: 1.5032692186294063

Epoch: 5| Step: 7
Training loss: 0.11563573777675629
Validation loss: 1.5314675082442581

Epoch: 5| Step: 8
Training loss: 0.0673503503203392
Validation loss: 1.5160525165578371

Epoch: 5| Step: 9
Training loss: 0.0979236513376236
Validation loss: 1.5242547309526833

Epoch: 5| Step: 10
Training loss: 0.05865061283111572
Validation loss: 1.5098762499388827

Epoch: 758| Step: 0
Training loss: 0.04109618812799454
Validation loss: 1.544286286959084

Epoch: 5| Step: 1
Training loss: 0.06949814409017563
Validation loss: 1.54672255310961

Epoch: 5| Step: 2
Training loss: 0.06587322056293488
Validation loss: 1.5396191702094129

Epoch: 5| Step: 3
Training loss: 0.07464327663183212
Validation loss: 1.5470302322859406

Epoch: 5| Step: 4
Training loss: 0.05838426202535629
Validation loss: 1.565841951677876

Epoch: 5| Step: 5
Training loss: 0.05472750589251518
Validation loss: 1.5159272968128163

Epoch: 5| Step: 6
Training loss: 0.04399273544549942
Validation loss: 1.4943255570627028

Epoch: 5| Step: 7
Training loss: 0.05485953018069267
Validation loss: 1.505507505068215

Epoch: 5| Step: 8
Training loss: 0.06851744651794434
Validation loss: 1.5035956354551419

Epoch: 5| Step: 9
Training loss: 0.078862264752388
Validation loss: 1.5198555255448947

Epoch: 5| Step: 10
Training loss: 0.0597134605050087
Validation loss: 1.5160387856985933

Epoch: 759| Step: 0
Training loss: 0.11551399528980255
Validation loss: 1.5164677648134128

Epoch: 5| Step: 1
Training loss: 0.10635177046060562
Validation loss: 1.5508423595018284

Epoch: 5| Step: 2
Training loss: 0.08211401849985123
Validation loss: 1.546944805370864

Epoch: 5| Step: 3
Training loss: 0.07130510360002518
Validation loss: 1.5454196301839684

Epoch: 5| Step: 4
Training loss: 0.07775996625423431
Validation loss: 1.5302127727898218

Epoch: 5| Step: 5
Training loss: 0.06972222030162811
Validation loss: 1.5051696800416516

Epoch: 5| Step: 6
Training loss: 0.04446597024798393
Validation loss: 1.5204203346724152

Epoch: 5| Step: 7
Training loss: 0.09673532843589783
Validation loss: 1.522493721336447

Epoch: 5| Step: 8
Training loss: 0.08919046819210052
Validation loss: 1.5470369759426321

Epoch: 5| Step: 9
Training loss: 0.03818582370877266
Validation loss: 1.5311281142696258

Epoch: 5| Step: 10
Training loss: 0.05914117395877838
Validation loss: 1.5319157697821175

Epoch: 760| Step: 0
Training loss: 0.051927484571933746
Validation loss: 1.5166679274651311

Epoch: 5| Step: 1
Training loss: 0.05081474035978317
Validation loss: 1.5172952311013335

Epoch: 5| Step: 2
Training loss: 0.06976093351840973
Validation loss: 1.508312632960658

Epoch: 5| Step: 3
Training loss: 0.05478274077177048
Validation loss: 1.5339870113198475

Epoch: 5| Step: 4
Training loss: 0.05435987561941147
Validation loss: 1.5307411198974938

Epoch: 5| Step: 5
Training loss: 0.10074847936630249
Validation loss: 1.5301851585347166

Epoch: 5| Step: 6
Training loss: 0.07227101922035217
Validation loss: 1.5377837727146764

Epoch: 5| Step: 7
Training loss: 0.07452596724033356
Validation loss: 1.533102854605644

Epoch: 5| Step: 8
Training loss: 0.08183558285236359
Validation loss: 1.5310721089763026

Epoch: 5| Step: 9
Training loss: 0.06340150535106659
Validation loss: 1.5487057637142878

Epoch: 5| Step: 10
Training loss: 0.03791303560137749
Validation loss: 1.4986191359899377

Epoch: 761| Step: 0
Training loss: 0.09854034334421158
Validation loss: 1.5255048441630539

Epoch: 5| Step: 1
Training loss: 0.0497828908264637
Validation loss: 1.5247093028919672

Epoch: 5| Step: 2
Training loss: 0.05099371820688248
Validation loss: 1.5238505409609886

Epoch: 5| Step: 3
Training loss: 0.058177076280117035
Validation loss: 1.5071785603800127

Epoch: 5| Step: 4
Training loss: 0.0754646435379982
Validation loss: 1.5030041702332035

Epoch: 5| Step: 5
Training loss: 0.06359691917896271
Validation loss: 1.5000598840816046

Epoch: 5| Step: 6
Training loss: 0.07371848076581955
Validation loss: 1.5054370639144734

Epoch: 5| Step: 7
Training loss: 0.07273945212364197
Validation loss: 1.5120338803978377

Epoch: 5| Step: 8
Training loss: 0.053660888224840164
Validation loss: 1.4987786662194036

Epoch: 5| Step: 9
Training loss: 0.04946614056825638
Validation loss: 1.5067739358512304

Epoch: 5| Step: 10
Training loss: 0.037037428468465805
Validation loss: 1.5001771847407024

Epoch: 762| Step: 0
Training loss: 0.04548956826329231
Validation loss: 1.5000078075675554

Epoch: 5| Step: 1
Training loss: 0.04607832431793213
Validation loss: 1.487517761927779

Epoch: 5| Step: 2
Training loss: 0.08180758357048035
Validation loss: 1.5042280317634664

Epoch: 5| Step: 3
Training loss: 0.03790181875228882
Validation loss: 1.4766582186504076

Epoch: 5| Step: 4
Training loss: 0.046864431351423264
Validation loss: 1.50311424527117

Epoch: 5| Step: 5
Training loss: 0.08257254958152771
Validation loss: 1.4752450771229242

Epoch: 5| Step: 6
Training loss: 0.048523880541324615
Validation loss: 1.479592437385231

Epoch: 5| Step: 7
Training loss: 0.06561235338449478
Validation loss: 1.5016622235698085

Epoch: 5| Step: 8
Training loss: 0.08598443120718002
Validation loss: 1.510029778685621

Epoch: 5| Step: 9
Training loss: 0.05143660306930542
Validation loss: 1.5123271506319764

Epoch: 5| Step: 10
Training loss: 0.06020638346672058
Validation loss: 1.5236373460420998

Epoch: 763| Step: 0
Training loss: 0.08105708658695221
Validation loss: 1.5607056489554785

Epoch: 5| Step: 1
Training loss: 0.09576746821403503
Validation loss: 1.5467497443640104

Epoch: 5| Step: 2
Training loss: 0.09969787299633026
Validation loss: 1.526875119055471

Epoch: 5| Step: 3
Training loss: 0.06429313123226166
Validation loss: 1.5272078783281389

Epoch: 5| Step: 4
Training loss: 0.05125352740287781
Validation loss: 1.5069780477913477

Epoch: 5| Step: 5
Training loss: 0.05341844633221626
Validation loss: 1.4800584213708037

Epoch: 5| Step: 6
Training loss: 0.061774034053087234
Validation loss: 1.4651260863068283

Epoch: 5| Step: 7
Training loss: 0.038600511848926544
Validation loss: 1.4381670977479668

Epoch: 5| Step: 8
Training loss: 0.07967312633991241
Validation loss: 1.4294811179561

Epoch: 5| Step: 9
Training loss: 0.06593002378940582
Validation loss: 1.4409982683838054

Epoch: 5| Step: 10
Training loss: 0.05946655198931694
Validation loss: 1.4730507827574206

Epoch: 764| Step: 0
Training loss: 0.05648808553814888
Validation loss: 1.46563079280238

Epoch: 5| Step: 1
Training loss: 0.1058344841003418
Validation loss: 1.4860459643025552

Epoch: 5| Step: 2
Training loss: 0.07883240282535553
Validation loss: 1.4846560211591824

Epoch: 5| Step: 3
Training loss: 0.056014977395534515
Validation loss: 1.4882007004112325

Epoch: 5| Step: 4
Training loss: 0.059769947081804276
Validation loss: 1.4787230773638653

Epoch: 5| Step: 5
Training loss: 0.05844254046678543
Validation loss: 1.4739322726444533

Epoch: 5| Step: 6
Training loss: 0.06668585538864136
Validation loss: 1.49578405580213

Epoch: 5| Step: 7
Training loss: 0.06882372498512268
Validation loss: 1.4674640804208734

Epoch: 5| Step: 8
Training loss: 0.05334620550274849
Validation loss: 1.5067271019822808

Epoch: 5| Step: 9
Training loss: 0.0446072593331337
Validation loss: 1.470971271555911

Epoch: 5| Step: 10
Training loss: 0.06930384784936905
Validation loss: 1.5016703554379043

Epoch: 765| Step: 0
Training loss: 0.03326864913105965
Validation loss: 1.4912269153902609

Epoch: 5| Step: 1
Training loss: 0.09998247772455215
Validation loss: 1.5206474847691034

Epoch: 5| Step: 2
Training loss: 0.05801752209663391
Validation loss: 1.5242876468166229

Epoch: 5| Step: 3
Training loss: 0.04250698909163475
Validation loss: 1.5146865088452575

Epoch: 5| Step: 4
Training loss: 0.06603562831878662
Validation loss: 1.5350965428095993

Epoch: 5| Step: 5
Training loss: 0.05667673796415329
Validation loss: 1.5430678680378904

Epoch: 5| Step: 6
Training loss: 0.052563201636075974
Validation loss: 1.5267977958084435

Epoch: 5| Step: 7
Training loss: 0.05769937485456467
Validation loss: 1.5261857778795305

Epoch: 5| Step: 8
Training loss: 0.07843838632106781
Validation loss: 1.5115135446671517

Epoch: 5| Step: 9
Training loss: 0.04092614725232124
Validation loss: 1.5070143130517775

Epoch: 5| Step: 10
Training loss: 0.06477946043014526
Validation loss: 1.515525548688827

Epoch: 766| Step: 0
Training loss: 0.06993858516216278
Validation loss: 1.5246347714495916

Epoch: 5| Step: 1
Training loss: 0.08078509569168091
Validation loss: 1.5268746229910082

Epoch: 5| Step: 2
Training loss: 0.06167317181825638
Validation loss: 1.522524009468735

Epoch: 5| Step: 3
Training loss: 0.07985014468431473
Validation loss: 1.5369259490761706

Epoch: 5| Step: 4
Training loss: 0.06355930864810944
Validation loss: 1.539735265957412

Epoch: 5| Step: 5
Training loss: 0.04753991216421127
Validation loss: 1.5384039596844745

Epoch: 5| Step: 6
Training loss: 0.0762198194861412
Validation loss: 1.5318136458755822

Epoch: 5| Step: 7
Training loss: 0.08350545167922974
Validation loss: 1.5146318693314829

Epoch: 5| Step: 8
Training loss: 0.04668582230806351
Validation loss: 1.5210076685874694

Epoch: 5| Step: 9
Training loss: 0.06837259978055954
Validation loss: 1.5570450354647893

Epoch: 5| Step: 10
Training loss: 0.05753165856003761
Validation loss: 1.5585244740209272

Epoch: 767| Step: 0
Training loss: 0.1005132645368576
Validation loss: 1.5550671046780002

Epoch: 5| Step: 1
Training loss: 0.05029924958944321
Validation loss: 1.5769527163556827

Epoch: 5| Step: 2
Training loss: 0.06499264389276505
Validation loss: 1.57510644261555

Epoch: 5| Step: 3
Training loss: 0.07480547577142715
Validation loss: 1.5372049488047117

Epoch: 5| Step: 4
Training loss: 0.053942274302244186
Validation loss: 1.5367165573181645

Epoch: 5| Step: 5
Training loss: 0.04402031749486923
Validation loss: 1.5449189883406445

Epoch: 5| Step: 6
Training loss: 0.06473147869110107
Validation loss: 1.5132117053513885

Epoch: 5| Step: 7
Training loss: 0.06317560374736786
Validation loss: 1.5229905164369972

Epoch: 5| Step: 8
Training loss: 0.08222484588623047
Validation loss: 1.5153065509693597

Epoch: 5| Step: 9
Training loss: 0.07546871900558472
Validation loss: 1.5249945514945573

Epoch: 5| Step: 10
Training loss: 0.05483059957623482
Validation loss: 1.4923300538011777

Epoch: 768| Step: 0
Training loss: 0.041493646800518036
Validation loss: 1.5127663458547285

Epoch: 5| Step: 1
Training loss: 0.046294569969177246
Validation loss: 1.5524537563323975

Epoch: 5| Step: 2
Training loss: 0.08266884088516235
Validation loss: 1.5509308461220033

Epoch: 5| Step: 3
Training loss: 0.06706087291240692
Validation loss: 1.5451592847865114

Epoch: 5| Step: 4
Training loss: 0.07491851598024368
Validation loss: 1.5149990871388426

Epoch: 5| Step: 5
Training loss: 0.043948959559202194
Validation loss: 1.5116936724673036

Epoch: 5| Step: 6
Training loss: 0.0804746150970459
Validation loss: 1.518802890213587

Epoch: 5| Step: 7
Training loss: 0.046027325093746185
Validation loss: 1.5035596278405958

Epoch: 5| Step: 8
Training loss: 0.07457821071147919
Validation loss: 1.526082040161215

Epoch: 5| Step: 9
Training loss: 0.06458678096532822
Validation loss: 1.5171222058675622

Epoch: 5| Step: 10
Training loss: 0.09180811792612076
Validation loss: 1.5185455763211815

Epoch: 769| Step: 0
Training loss: 0.03507230803370476
Validation loss: 1.5151318247600267

Epoch: 5| Step: 1
Training loss: 0.04384692758321762
Validation loss: 1.5082118049744637

Epoch: 5| Step: 2
Training loss: 0.05099118500947952
Validation loss: 1.5206650585256598

Epoch: 5| Step: 3
Training loss: 0.07939288020133972
Validation loss: 1.5385030636223413

Epoch: 5| Step: 4
Training loss: 0.08181224018335342
Validation loss: 1.5305983968960342

Epoch: 5| Step: 5
Training loss: 0.07122427225112915
Validation loss: 1.5172841459192254

Epoch: 5| Step: 6
Training loss: 0.04116407781839371
Validation loss: 1.5168480937198927

Epoch: 5| Step: 7
Training loss: 0.06684718281030655
Validation loss: 1.4832442678431028

Epoch: 5| Step: 8
Training loss: 0.11446400731801987
Validation loss: 1.4896993778085197

Epoch: 5| Step: 9
Training loss: 0.05429568886756897
Validation loss: 1.5166007498259186

Epoch: 5| Step: 10
Training loss: 0.05465776473283768
Validation loss: 1.4844044741763864

Epoch: 770| Step: 0
Training loss: 0.04409962520003319
Validation loss: 1.4830742728325628

Epoch: 5| Step: 1
Training loss: 0.06408326327800751
Validation loss: 1.5134921138004591

Epoch: 5| Step: 2
Training loss: 0.10550723969936371
Validation loss: 1.5241995972971762

Epoch: 5| Step: 3
Training loss: 0.04606635496020317
Validation loss: 1.5394226645910611

Epoch: 5| Step: 4
Training loss: 0.045693088322877884
Validation loss: 1.5306046816610521

Epoch: 5| Step: 5
Training loss: 0.05200592800974846
Validation loss: 1.5221111018170592

Epoch: 5| Step: 6
Training loss: 0.07701214402914047
Validation loss: 1.5334023634592693

Epoch: 5| Step: 7
Training loss: 0.07885737717151642
Validation loss: 1.4805343875321009

Epoch: 5| Step: 8
Training loss: 0.07056988775730133
Validation loss: 1.4917466678927023

Epoch: 5| Step: 9
Training loss: 0.12127487361431122
Validation loss: 1.49578720267101

Epoch: 5| Step: 10
Training loss: 0.07486454397439957
Validation loss: 1.4839089955053022

Epoch: 771| Step: 0
Training loss: 0.0638197660446167
Validation loss: 1.490397693008505

Epoch: 5| Step: 1
Training loss: 0.05008050799369812
Validation loss: 1.4752620984149236

Epoch: 5| Step: 2
Training loss: 0.047868166118860245
Validation loss: 1.4941201171567362

Epoch: 5| Step: 3
Training loss: 0.049080319702625275
Validation loss: 1.4889270195396997

Epoch: 5| Step: 4
Training loss: 0.05766754224896431
Validation loss: 1.5038307482196438

Epoch: 5| Step: 5
Training loss: 0.12804298102855682
Validation loss: 1.522534228140308

Epoch: 5| Step: 6
Training loss: 0.046341706067323685
Validation loss: 1.4904258456281436

Epoch: 5| Step: 7
Training loss: 0.04905077815055847
Validation loss: 1.486418886851239

Epoch: 5| Step: 8
Training loss: 0.027473872527480125
Validation loss: 1.5068597216759958

Epoch: 5| Step: 9
Training loss: 0.04848119989037514
Validation loss: 1.520444905886086

Epoch: 5| Step: 10
Training loss: 0.06360676139593124
Validation loss: 1.505369750402307

Epoch: 772| Step: 0
Training loss: 0.041058652102947235
Validation loss: 1.5050738755092825

Epoch: 5| Step: 1
Training loss: 0.05345800518989563
Validation loss: 1.5011795259291125

Epoch: 5| Step: 2
Training loss: 0.054137684404850006
Validation loss: 1.5143584410349529

Epoch: 5| Step: 3
Training loss: 0.04285602644085884
Validation loss: 1.5199312913802363

Epoch: 5| Step: 4
Training loss: 0.057240504771471024
Validation loss: 1.4942093703054613

Epoch: 5| Step: 5
Training loss: 0.08500044047832489
Validation loss: 1.501419537810869

Epoch: 5| Step: 6
Training loss: 0.07284213602542877
Validation loss: 1.4817285819720196

Epoch: 5| Step: 7
Training loss: 0.040945108979940414
Validation loss: 1.4970096734262281

Epoch: 5| Step: 8
Training loss: 0.03901638090610504
Validation loss: 1.4817390159894062

Epoch: 5| Step: 9
Training loss: 0.03945023566484451
Validation loss: 1.4762480707578762

Epoch: 5| Step: 10
Training loss: 0.07734640687704086
Validation loss: 1.4710214945577806

Epoch: 773| Step: 0
Training loss: 0.03885072469711304
Validation loss: 1.4675087134043376

Epoch: 5| Step: 1
Training loss: 0.06085696071386337
Validation loss: 1.4787809489875712

Epoch: 5| Step: 2
Training loss: 0.04511522874236107
Validation loss: 1.5137078095507879

Epoch: 5| Step: 3
Training loss: 0.07062734663486481
Validation loss: 1.517251483855709

Epoch: 5| Step: 4
Training loss: 0.07964476197957993
Validation loss: 1.519550831087174

Epoch: 5| Step: 5
Training loss: 0.04755937308073044
Validation loss: 1.507358076751873

Epoch: 5| Step: 6
Training loss: 0.060133956372737885
Validation loss: 1.5075390249170282

Epoch: 5| Step: 7
Training loss: 0.07208861410617828
Validation loss: 1.4823851021387244

Epoch: 5| Step: 8
Training loss: 0.08232595026493073
Validation loss: 1.509164906317188

Epoch: 5| Step: 9
Training loss: 0.04328259825706482
Validation loss: 1.4785064510119859

Epoch: 5| Step: 10
Training loss: 0.05007746070623398
Validation loss: 1.5106080975583804

Epoch: 774| Step: 0
Training loss: 0.04436622932553291
Validation loss: 1.5088532573433333

Epoch: 5| Step: 1
Training loss: 0.05286196991801262
Validation loss: 1.5044468961736208

Epoch: 5| Step: 2
Training loss: 0.06776542961597443
Validation loss: 1.5108683666875284

Epoch: 5| Step: 3
Training loss: 0.03883711248636246
Validation loss: 1.5072000859886088

Epoch: 5| Step: 4
Training loss: 0.057717133313417435
Validation loss: 1.492223067950177

Epoch: 5| Step: 5
Training loss: 0.0643421858549118
Validation loss: 1.5168076715161722

Epoch: 5| Step: 6
Training loss: 0.055339265614748
Validation loss: 1.4933416164049538

Epoch: 5| Step: 7
Training loss: 0.07321615517139435
Validation loss: 1.502631696321631

Epoch: 5| Step: 8
Training loss: 0.060060083866119385
Validation loss: 1.4639213315902218

Epoch: 5| Step: 9
Training loss: 0.05574941635131836
Validation loss: 1.4794825353930074

Epoch: 5| Step: 10
Training loss: 0.10212953388690948
Validation loss: 1.4645301334319576

Epoch: 775| Step: 0
Training loss: 0.07091464847326279
Validation loss: 1.4889162932672808

Epoch: 5| Step: 1
Training loss: 0.08157478272914886
Validation loss: 1.46476266589216

Epoch: 5| Step: 2
Training loss: 0.043424174189567566
Validation loss: 1.5085686252963157

Epoch: 5| Step: 3
Training loss: 0.04674307256937027
Validation loss: 1.5188865148892967

Epoch: 5| Step: 4
Training loss: 0.05748479440808296
Validation loss: 1.5270100844803678

Epoch: 5| Step: 5
Training loss: 0.10024698078632355
Validation loss: 1.5189811606560983

Epoch: 5| Step: 6
Training loss: 0.06509454548358917
Validation loss: 1.5194764367995723

Epoch: 5| Step: 7
Training loss: 0.0602724626660347
Validation loss: 1.539716750062922

Epoch: 5| Step: 8
Training loss: 0.05790496990084648
Validation loss: 1.5382050852621756

Epoch: 5| Step: 9
Training loss: 0.0914405956864357
Validation loss: 1.526700271073208

Epoch: 5| Step: 10
Training loss: 0.07151618599891663
Validation loss: 1.4901472663366666

Epoch: 776| Step: 0
Training loss: 0.05749901384115219
Validation loss: 1.5010051445294452

Epoch: 5| Step: 1
Training loss: 0.08210983872413635
Validation loss: 1.4713844900490136

Epoch: 5| Step: 2
Training loss: 0.08345457166433334
Validation loss: 1.4840844677340599

Epoch: 5| Step: 3
Training loss: 0.07385721057653427
Validation loss: 1.4690768205991356

Epoch: 5| Step: 4
Training loss: 0.05801116302609444
Validation loss: 1.489217367223514

Epoch: 5| Step: 5
Training loss: 0.07058805972337723
Validation loss: 1.4811750214586976

Epoch: 5| Step: 6
Training loss: 0.06899786740541458
Validation loss: 1.5274234112872873

Epoch: 5| Step: 7
Training loss: 0.08052335679531097
Validation loss: 1.534996505706541

Epoch: 5| Step: 8
Training loss: 0.03807556629180908
Validation loss: 1.517911120127606

Epoch: 5| Step: 9
Training loss: 0.05066101625561714
Validation loss: 1.5487579517467047

Epoch: 5| Step: 10
Training loss: 0.04706740006804466
Validation loss: 1.5397900894124021

Epoch: 777| Step: 0
Training loss: 0.025291752070188522
Validation loss: 1.5163148359585834

Epoch: 5| Step: 1
Training loss: 0.03553585335612297
Validation loss: 1.5301082582883938

Epoch: 5| Step: 2
Training loss: 0.0644833892583847
Validation loss: 1.5190863884905332

Epoch: 5| Step: 3
Training loss: 0.06224552541971207
Validation loss: 1.5305911020566059

Epoch: 5| Step: 4
Training loss: 0.08011806756258011
Validation loss: 1.5172671797454997

Epoch: 5| Step: 5
Training loss: 0.059013109654188156
Validation loss: 1.4979570181139055

Epoch: 5| Step: 6
Training loss: 0.06180429458618164
Validation loss: 1.513288890802732

Epoch: 5| Step: 7
Training loss: 0.05558272451162338
Validation loss: 1.5211926538457152

Epoch: 5| Step: 8
Training loss: 0.07331443578004837
Validation loss: 1.5418381139796267

Epoch: 5| Step: 9
Training loss: 0.07824428379535675
Validation loss: 1.5467797876686178

Epoch: 5| Step: 10
Training loss: 0.07892467826604843
Validation loss: 1.536837307355737

Epoch: 778| Step: 0
Training loss: 0.08848066627979279
Validation loss: 1.5085959306327246

Epoch: 5| Step: 1
Training loss: 0.04123448580503464
Validation loss: 1.5444462940257082

Epoch: 5| Step: 2
Training loss: 0.05065768212080002
Validation loss: 1.5394250769768991

Epoch: 5| Step: 3
Training loss: 0.0650617927312851
Validation loss: 1.5395206212997437

Epoch: 5| Step: 4
Training loss: 0.12950612604618073
Validation loss: 1.5457680545827395

Epoch: 5| Step: 5
Training loss: 0.07051026821136475
Validation loss: 1.5178236487091228

Epoch: 5| Step: 6
Training loss: 0.07584725320339203
Validation loss: 1.5049530767625379

Epoch: 5| Step: 7
Training loss: 0.08025549352169037
Validation loss: 1.5033607790547032

Epoch: 5| Step: 8
Training loss: 0.12522853910923004
Validation loss: 1.5102467690744708

Epoch: 5| Step: 9
Training loss: 0.0754457414150238
Validation loss: 1.488738718853202

Epoch: 5| Step: 10
Training loss: 0.08717113733291626
Validation loss: 1.4875654187253726

Epoch: 779| Step: 0
Training loss: 0.08696970343589783
Validation loss: 1.5088297244041198

Epoch: 5| Step: 1
Training loss: 0.05224227160215378
Validation loss: 1.51968930357246

Epoch: 5| Step: 2
Training loss: 0.07099657505750656
Validation loss: 1.5168007304591518

Epoch: 5| Step: 3
Training loss: 0.06259183585643768
Validation loss: 1.516616952034735

Epoch: 5| Step: 4
Training loss: 0.07449223846197128
Validation loss: 1.54515669679129

Epoch: 5| Step: 5
Training loss: 0.12623734772205353
Validation loss: 1.5323575812001382

Epoch: 5| Step: 6
Training loss: 0.06774717569351196
Validation loss: 1.5098886464231758

Epoch: 5| Step: 7
Training loss: 0.0401858314871788
Validation loss: 1.4740817623753701

Epoch: 5| Step: 8
Training loss: 0.05354534462094307
Validation loss: 1.4930394272650442

Epoch: 5| Step: 9
Training loss: 0.04824688658118248
Validation loss: 1.5040741710252659

Epoch: 5| Step: 10
Training loss: 0.04752127453684807
Validation loss: 1.5082013837752803

Epoch: 780| Step: 0
Training loss: 0.06281090527772903
Validation loss: 1.4857672517017653

Epoch: 5| Step: 1
Training loss: 0.06146993115544319
Validation loss: 1.4738765954971313

Epoch: 5| Step: 2
Training loss: 0.04019327089190483
Validation loss: 1.4801525762004237

Epoch: 5| Step: 3
Training loss: 0.06828439235687256
Validation loss: 1.492009775612944

Epoch: 5| Step: 4
Training loss: 0.07381712645292282
Validation loss: 1.5165843079167027

Epoch: 5| Step: 5
Training loss: 0.054412841796875
Validation loss: 1.5011590052676458

Epoch: 5| Step: 6
Training loss: 0.07131967693567276
Validation loss: 1.5003325907132958

Epoch: 5| Step: 7
Training loss: 0.05645911768078804
Validation loss: 1.497074491234236

Epoch: 5| Step: 8
Training loss: 0.05933383107185364
Validation loss: 1.4720041444224696

Epoch: 5| Step: 9
Training loss: 0.04822471737861633
Validation loss: 1.4908740148749402

Epoch: 5| Step: 10
Training loss: 0.045297764241695404
Validation loss: 1.5153633010002874

Epoch: 781| Step: 0
Training loss: 0.06028022617101669
Validation loss: 1.4683667023976643

Epoch: 5| Step: 1
Training loss: 0.06771493703126907
Validation loss: 1.4805655402521933

Epoch: 5| Step: 2
Training loss: 0.05631251260638237
Validation loss: 1.4698936836693877

Epoch: 5| Step: 3
Training loss: 0.04685400798916817
Validation loss: 1.5113485423467492

Epoch: 5| Step: 4
Training loss: 0.0737885981798172
Validation loss: 1.50701952749683

Epoch: 5| Step: 5
Training loss: 0.060065269470214844
Validation loss: 1.485168808250017

Epoch: 5| Step: 6
Training loss: 0.04961196333169937
Validation loss: 1.4919765200666202

Epoch: 5| Step: 7
Training loss: 0.034482650458812714
Validation loss: 1.506539733179154

Epoch: 5| Step: 8
Training loss: 0.0583951398730278
Validation loss: 1.4887138746118034

Epoch: 5| Step: 9
Training loss: 0.039126958698034286
Validation loss: 1.5000988488556237

Epoch: 5| Step: 10
Training loss: 0.04491659998893738
Validation loss: 1.5085645119349163

Epoch: 782| Step: 0
Training loss: 0.02964850701391697
Validation loss: 1.505265571737802

Epoch: 5| Step: 1
Training loss: 0.04768359661102295
Validation loss: 1.5170527337699808

Epoch: 5| Step: 2
Training loss: 0.04828738421201706
Validation loss: 1.5012900816496981

Epoch: 5| Step: 3
Training loss: 0.03305527940392494
Validation loss: 1.481564393607519

Epoch: 5| Step: 4
Training loss: 0.05309034138917923
Validation loss: 1.5168050912118727

Epoch: 5| Step: 5
Training loss: 0.05281003564596176
Validation loss: 1.533492644627889

Epoch: 5| Step: 6
Training loss: 0.05036814138293266
Validation loss: 1.518413451410109

Epoch: 5| Step: 7
Training loss: 0.0917859822511673
Validation loss: 1.5234084565152404

Epoch: 5| Step: 8
Training loss: 0.0677785724401474
Validation loss: 1.516033895233626

Epoch: 5| Step: 9
Training loss: 0.047398440539836884
Validation loss: 1.515948462229903

Epoch: 5| Step: 10
Training loss: 0.06370410323143005
Validation loss: 1.52241922514413

Epoch: 783| Step: 0
Training loss: 0.0544220507144928
Validation loss: 1.4991402036400252

Epoch: 5| Step: 1
Training loss: 0.06924915313720703
Validation loss: 1.51218000278678

Epoch: 5| Step: 2
Training loss: 0.03739982843399048
Validation loss: 1.500543603333094

Epoch: 5| Step: 3
Training loss: 0.05877085402607918
Validation loss: 1.5087447345897715

Epoch: 5| Step: 4
Training loss: 0.060270339250564575
Validation loss: 1.503115282263807

Epoch: 5| Step: 5
Training loss: 0.04301636666059494
Validation loss: 1.5132877108871297

Epoch: 5| Step: 6
Training loss: 0.04190586879849434
Validation loss: 1.5414734527628908

Epoch: 5| Step: 7
Training loss: 0.0949167013168335
Validation loss: 1.5521970423319007

Epoch: 5| Step: 8
Training loss: 0.060410451143980026
Validation loss: 1.5144488593583465

Epoch: 5| Step: 9
Training loss: 0.04183516651391983
Validation loss: 1.5291807805338213

Epoch: 5| Step: 10
Training loss: 0.0642072930932045
Validation loss: 1.51276058279058

Epoch: 784| Step: 0
Training loss: 0.0814504623413086
Validation loss: 1.495890430224839

Epoch: 5| Step: 1
Training loss: 0.0553164966404438
Validation loss: 1.5358032411144626

Epoch: 5| Step: 2
Training loss: 0.06944602727890015
Validation loss: 1.5240619759405813

Epoch: 5| Step: 3
Training loss: 0.039739541709423065
Validation loss: 1.537757828671445

Epoch: 5| Step: 4
Training loss: 0.026493486016988754
Validation loss: 1.5612180515002179

Epoch: 5| Step: 5
Training loss: 0.07089032977819443
Validation loss: 1.5636440630882018

Epoch: 5| Step: 6
Training loss: 0.0424562469124794
Validation loss: 1.5565167550117738

Epoch: 5| Step: 7
Training loss: 0.040897782891988754
Validation loss: 1.5589380821874064

Epoch: 5| Step: 8
Training loss: 0.04569320008158684
Validation loss: 1.5389955107883742

Epoch: 5| Step: 9
Training loss: 0.04085731878876686
Validation loss: 1.556600059232404

Epoch: 5| Step: 10
Training loss: 0.05537787079811096
Validation loss: 1.5268893241882324

Epoch: 785| Step: 0
Training loss: 0.03572509065270424
Validation loss: 1.5411610398241269

Epoch: 5| Step: 1
Training loss: 0.05824239179491997
Validation loss: 1.502710360352711

Epoch: 5| Step: 2
Training loss: 0.05540058761835098
Validation loss: 1.4953681038271995

Epoch: 5| Step: 3
Training loss: 0.07754798978567123
Validation loss: 1.4934568873015783

Epoch: 5| Step: 4
Training loss: 0.0928744375705719
Validation loss: 1.521046688479762

Epoch: 5| Step: 5
Training loss: 0.03509514406323433
Validation loss: 1.5024497214184012

Epoch: 5| Step: 6
Training loss: 0.055606819689273834
Validation loss: 1.5043599785015147

Epoch: 5| Step: 7
Training loss: 0.10191874206066132
Validation loss: 1.4986659448633912

Epoch: 5| Step: 8
Training loss: 0.055956512689590454
Validation loss: 1.5113933214577295

Epoch: 5| Step: 9
Training loss: 0.056117940694093704
Validation loss: 1.5119998192274442

Epoch: 5| Step: 10
Training loss: 0.041574619710445404
Validation loss: 1.519060996270949

Epoch: 786| Step: 0
Training loss: 0.04986884444952011
Validation loss: 1.5379460229668567

Epoch: 5| Step: 1
Training loss: 0.09037744253873825
Validation loss: 1.5692839212315057

Epoch: 5| Step: 2
Training loss: 0.05097406357526779
Validation loss: 1.5410901026059223

Epoch: 5| Step: 3
Training loss: 0.06240735203027725
Validation loss: 1.5224592865154307

Epoch: 5| Step: 4
Training loss: 0.058202970772981644
Validation loss: 1.536818427424277

Epoch: 5| Step: 5
Training loss: 0.060836631804704666
Validation loss: 1.5372410615285237

Epoch: 5| Step: 6
Training loss: 0.04067050293087959
Validation loss: 1.535246354277416

Epoch: 5| Step: 7
Training loss: 0.08161226660013199
Validation loss: 1.5439415170300392

Epoch: 5| Step: 8
Training loss: 0.0976279228925705
Validation loss: 1.5082464500140118

Epoch: 5| Step: 9
Training loss: 0.056429408490657806
Validation loss: 1.5351502491581825

Epoch: 5| Step: 10
Training loss: 0.041359901428222656
Validation loss: 1.5681122708064255

Epoch: 787| Step: 0
Training loss: 0.050879962742328644
Validation loss: 1.5353266936476513

Epoch: 5| Step: 1
Training loss: 0.03884575888514519
Validation loss: 1.5420153730659074

Epoch: 5| Step: 2
Training loss: 0.05888885259628296
Validation loss: 1.526350046998711

Epoch: 5| Step: 3
Training loss: 0.06267954409122467
Validation loss: 1.5237369050261795

Epoch: 5| Step: 4
Training loss: 0.05167524889111519
Validation loss: 1.513919263116775

Epoch: 5| Step: 5
Training loss: 0.04985525459051132
Validation loss: 1.5336608527809061

Epoch: 5| Step: 6
Training loss: 0.10958051681518555
Validation loss: 1.5190380504054408

Epoch: 5| Step: 7
Training loss: 0.04702741652727127
Validation loss: 1.5344500362232167

Epoch: 5| Step: 8
Training loss: 0.07415927201509476
Validation loss: 1.523744834366665

Epoch: 5| Step: 9
Training loss: 0.05865807458758354
Validation loss: 1.524954649709886

Epoch: 5| Step: 10
Training loss: 0.030245577916502953
Validation loss: 1.503771290984205

Epoch: 788| Step: 0
Training loss: 0.05998779460787773
Validation loss: 1.4974826715325797

Epoch: 5| Step: 1
Training loss: 0.06052212789654732
Validation loss: 1.5182969275341238

Epoch: 5| Step: 2
Training loss: 0.04722266271710396
Validation loss: 1.5274943279963669

Epoch: 5| Step: 3
Training loss: 0.03549118712544441
Validation loss: 1.538145766463331

Epoch: 5| Step: 4
Training loss: 0.09883296489715576
Validation loss: 1.5426246504629813

Epoch: 5| Step: 5
Training loss: 0.08056951314210892
Validation loss: 1.519776649372552

Epoch: 5| Step: 6
Training loss: 0.058470405638217926
Validation loss: 1.5301476255539925

Epoch: 5| Step: 7
Training loss: 0.06713405251502991
Validation loss: 1.5420716642051615

Epoch: 5| Step: 8
Training loss: 0.03809305280447006
Validation loss: 1.5345267249691872

Epoch: 5| Step: 9
Training loss: 0.06242327764630318
Validation loss: 1.5337984228646884

Epoch: 5| Step: 10
Training loss: 0.09817632287740707
Validation loss: 1.5336259347136303

Epoch: 789| Step: 0
Training loss: 0.07544288784265518
Validation loss: 1.5343696494256296

Epoch: 5| Step: 1
Training loss: 0.048454176634550095
Validation loss: 1.5178546777335546

Epoch: 5| Step: 2
Training loss: 0.07055256515741348
Validation loss: 1.4830484249258553

Epoch: 5| Step: 3
Training loss: 0.03722606226801872
Validation loss: 1.4795981485356566

Epoch: 5| Step: 4
Training loss: 0.04706614464521408
Validation loss: 1.4884768352713635

Epoch: 5| Step: 5
Training loss: 0.06612884253263474
Validation loss: 1.4856548514417423

Epoch: 5| Step: 6
Training loss: 0.06698043644428253
Validation loss: 1.4769168156449513

Epoch: 5| Step: 7
Training loss: 0.06130828708410263
Validation loss: 1.4970620319407473

Epoch: 5| Step: 8
Training loss: 0.0553402304649353
Validation loss: 1.469598316377209

Epoch: 5| Step: 9
Training loss: 0.027188200503587723
Validation loss: 1.5186949724792151

Epoch: 5| Step: 10
Training loss: 0.04900193586945534
Validation loss: 1.5332744852189095

Epoch: 790| Step: 0
Training loss: 0.04589463397860527
Validation loss: 1.5190525477932346

Epoch: 5| Step: 1
Training loss: 0.056418277323246
Validation loss: 1.5468649300195838

Epoch: 5| Step: 2
Training loss: 0.06555412709712982
Validation loss: 1.5399525165557861

Epoch: 5| Step: 3
Training loss: 0.053504932671785355
Validation loss: 1.5158832726940032

Epoch: 5| Step: 4
Training loss: 0.07058843970298767
Validation loss: 1.5444946314698906

Epoch: 5| Step: 5
Training loss: 0.09297285974025726
Validation loss: 1.5239939458908573

Epoch: 5| Step: 6
Training loss: 0.06681524217128754
Validation loss: 1.5148806366869199

Epoch: 5| Step: 7
Training loss: 0.041767433285713196
Validation loss: 1.5117118826476477

Epoch: 5| Step: 8
Training loss: 0.04355962947010994
Validation loss: 1.481365139766406

Epoch: 5| Step: 9
Training loss: 0.0779644325375557
Validation loss: 1.4704973774571573

Epoch: 5| Step: 10
Training loss: 0.04595839977264404
Validation loss: 1.4726591776776057

Epoch: 791| Step: 0
Training loss: 0.08263557404279709
Validation loss: 1.5010162745752642

Epoch: 5| Step: 1
Training loss: 0.061674583703279495
Validation loss: 1.4766217867533367

Epoch: 5| Step: 2
Training loss: 0.03274847939610481
Validation loss: 1.4964286306852936

Epoch: 5| Step: 3
Training loss: 0.05936335399746895
Validation loss: 1.5004914146597668

Epoch: 5| Step: 4
Training loss: 0.04064036160707474
Validation loss: 1.5178746651577693

Epoch: 5| Step: 5
Training loss: 0.05777168273925781
Validation loss: 1.5077052218939668

Epoch: 5| Step: 6
Training loss: 0.05215873569250107
Validation loss: 1.4974340315788024

Epoch: 5| Step: 7
Training loss: 0.08772747963666916
Validation loss: 1.4992573466352237

Epoch: 5| Step: 8
Training loss: 0.057656534016132355
Validation loss: 1.516388044562391

Epoch: 5| Step: 9
Training loss: 0.057943738996982574
Validation loss: 1.526189544508534

Epoch: 5| Step: 10
Training loss: 0.04612744599580765
Validation loss: 1.4926060989338865

Epoch: 792| Step: 0
Training loss: 0.04808061197400093
Validation loss: 1.4920168063973869

Epoch: 5| Step: 1
Training loss: 0.07725600898265839
Validation loss: 1.4850940217253983

Epoch: 5| Step: 2
Training loss: 0.042041849344968796
Validation loss: 1.512278300459667

Epoch: 5| Step: 3
Training loss: 0.049052078276872635
Validation loss: 1.496799220320999

Epoch: 5| Step: 4
Training loss: 0.06629662215709686
Validation loss: 1.5233193751304381

Epoch: 5| Step: 5
Training loss: 0.06977935880422592
Validation loss: 1.500738759194651

Epoch: 5| Step: 6
Training loss: 0.050531577318906784
Validation loss: 1.5013565632604784

Epoch: 5| Step: 7
Training loss: 0.05590193718671799
Validation loss: 1.5176933991011752

Epoch: 5| Step: 8
Training loss: 0.06096569821238518
Validation loss: 1.5284324448595765

Epoch: 5| Step: 9
Training loss: 0.05982928350567818
Validation loss: 1.4989630394084479

Epoch: 5| Step: 10
Training loss: 0.03632168099284172
Validation loss: 1.4844890935446626

Epoch: 793| Step: 0
Training loss: 0.05747295543551445
Validation loss: 1.4763222086814143

Epoch: 5| Step: 1
Training loss: 0.047491420060396194
Validation loss: 1.5133853150952248

Epoch: 5| Step: 2
Training loss: 0.052144575864076614
Validation loss: 1.4900909393064437

Epoch: 5| Step: 3
Training loss: 0.041913021355867386
Validation loss: 1.5123039016159632

Epoch: 5| Step: 4
Training loss: 0.06749944388866425
Validation loss: 1.513996034540156

Epoch: 5| Step: 5
Training loss: 0.06275645643472672
Validation loss: 1.5265158453295309

Epoch: 5| Step: 6
Training loss: 0.06800749152898788
Validation loss: 1.546452650459864

Epoch: 5| Step: 7
Training loss: 0.0563066229224205
Validation loss: 1.5282127870026456

Epoch: 5| Step: 8
Training loss: 0.04266342520713806
Validation loss: 1.5551728458814724

Epoch: 5| Step: 9
Training loss: 0.028380539268255234
Validation loss: 1.532337103479652

Epoch: 5| Step: 10
Training loss: 0.04835131764411926
Validation loss: 1.5258105442088137

Epoch: 794| Step: 0
Training loss: 0.05099660903215408
Validation loss: 1.5117781469898839

Epoch: 5| Step: 1
Training loss: 0.03963986784219742
Validation loss: 1.505228563021588

Epoch: 5| Step: 2
Training loss: 0.05457884073257446
Validation loss: 1.5117741348922893

Epoch: 5| Step: 3
Training loss: 0.06566758453845978
Validation loss: 1.5163797845122635

Epoch: 5| Step: 4
Training loss: 0.03579368069767952
Validation loss: 1.5127400884064295

Epoch: 5| Step: 5
Training loss: 0.0591820664703846
Validation loss: 1.5133916601057975

Epoch: 5| Step: 6
Training loss: 0.03138483688235283
Validation loss: 1.5284977805229925

Epoch: 5| Step: 7
Training loss: 0.06793399155139923
Validation loss: 1.5332295484440301

Epoch: 5| Step: 8
Training loss: 0.06269997358322144
Validation loss: 1.533744712029734

Epoch: 5| Step: 9
Training loss: 0.0604352168738842
Validation loss: 1.537135402361552

Epoch: 5| Step: 10
Training loss: 0.0620155893266201
Validation loss: 1.5312428730790333

Epoch: 795| Step: 0
Training loss: 0.050037872046232224
Validation loss: 1.550954089369825

Epoch: 5| Step: 1
Training loss: 0.05259476229548454
Validation loss: 1.5243008367476925

Epoch: 5| Step: 2
Training loss: 0.03448377549648285
Validation loss: 1.5246722634120653

Epoch: 5| Step: 3
Training loss: 0.051448702812194824
Validation loss: 1.5508775570059334

Epoch: 5| Step: 4
Training loss: 0.0571291446685791
Validation loss: 1.5327477929412678

Epoch: 5| Step: 5
Training loss: 0.0619458332657814
Validation loss: 1.5359927979848718

Epoch: 5| Step: 6
Training loss: 0.037218909710645676
Validation loss: 1.5489371181816183

Epoch: 5| Step: 7
Training loss: 0.0399431474506855
Validation loss: 1.5283556510043401

Epoch: 5| Step: 8
Training loss: 0.06497015804052353
Validation loss: 1.5314417769831996

Epoch: 5| Step: 9
Training loss: 0.05968213826417923
Validation loss: 1.5468701765101442

Epoch: 5| Step: 10
Training loss: 0.03426249697804451
Validation loss: 1.5133476923870783

Epoch: 796| Step: 0
Training loss: 0.06022088974714279
Validation loss: 1.5256298959896128

Epoch: 5| Step: 1
Training loss: 0.053296636790037155
Validation loss: 1.519132009116552

Epoch: 5| Step: 2
Training loss: 0.057472191751003265
Validation loss: 1.5150853190370785

Epoch: 5| Step: 3
Training loss: 0.04139021784067154
Validation loss: 1.5268160579025105

Epoch: 5| Step: 4
Training loss: 0.030680621042847633
Validation loss: 1.5198285425862958

Epoch: 5| Step: 5
Training loss: 0.04944276437163353
Validation loss: 1.4860688191588207

Epoch: 5| Step: 6
Training loss: 0.039880938827991486
Validation loss: 1.4897774406658706

Epoch: 5| Step: 7
Training loss: 0.052834052592515945
Validation loss: 1.4778897928935226

Epoch: 5| Step: 8
Training loss: 0.054014481604099274
Validation loss: 1.493148725519898

Epoch: 5| Step: 9
Training loss: 0.0543806329369545
Validation loss: 1.4884873346615863

Epoch: 5| Step: 10
Training loss: 0.03603712096810341
Validation loss: 1.4513206417842577

Epoch: 797| Step: 0
Training loss: 0.05848957970738411
Validation loss: 1.4703307523522327

Epoch: 5| Step: 1
Training loss: 0.041379936039447784
Validation loss: 1.4754053918264245

Epoch: 5| Step: 2
Training loss: 0.048989035189151764
Validation loss: 1.4810625545440181

Epoch: 5| Step: 3
Training loss: 0.03519609570503235
Validation loss: 1.4865644131937334

Epoch: 5| Step: 4
Training loss: 0.05284641310572624
Validation loss: 1.4852400351596136

Epoch: 5| Step: 5
Training loss: 0.04838965833187103
Validation loss: 1.4549074916429416

Epoch: 5| Step: 6
Training loss: 0.041450969874858856
Validation loss: 1.487462664163241

Epoch: 5| Step: 7
Training loss: 0.027033507823944092
Validation loss: 1.4868498694512151

Epoch: 5| Step: 8
Training loss: 0.031474895775318146
Validation loss: 1.4667578871532152

Epoch: 5| Step: 9
Training loss: 0.04824765771627426
Validation loss: 1.4758471647898357

Epoch: 5| Step: 10
Training loss: 0.07527115941047668
Validation loss: 1.4869731946658062

Epoch: 798| Step: 0
Training loss: 0.03284422680735588
Validation loss: 1.4955970010449808

Epoch: 5| Step: 1
Training loss: 0.0701851025223732
Validation loss: 1.4863002889899797

Epoch: 5| Step: 2
Training loss: 0.04472515732049942
Validation loss: 1.5050843992540914

Epoch: 5| Step: 3
Training loss: 0.061001040041446686
Validation loss: 1.486859119066628

Epoch: 5| Step: 4
Training loss: 0.030233312398195267
Validation loss: 1.4888829031298239

Epoch: 5| Step: 5
Training loss: 0.0733976736664772
Validation loss: 1.4881551316989365

Epoch: 5| Step: 6
Training loss: 0.034570567309856415
Validation loss: 1.505988718360983

Epoch: 5| Step: 7
Training loss: 0.03900104761123657
Validation loss: 1.489303865740376

Epoch: 5| Step: 8
Training loss: 0.057024598121643066
Validation loss: 1.4837990704403128

Epoch: 5| Step: 9
Training loss: 0.06824187934398651
Validation loss: 1.4984679632289435

Epoch: 5| Step: 10
Training loss: 0.056071579456329346
Validation loss: 1.4676429289643482

Epoch: 799| Step: 0
Training loss: 0.04195414111018181
Validation loss: 1.4867172523211407

Epoch: 5| Step: 1
Training loss: 0.06649099290370941
Validation loss: 1.4395711729603429

Epoch: 5| Step: 2
Training loss: 0.05632178857922554
Validation loss: 1.4641308348665956

Epoch: 5| Step: 3
Training loss: 0.08610885590314865
Validation loss: 1.4681295925571072

Epoch: 5| Step: 4
Training loss: 0.038158219307661057
Validation loss: 1.456007767749089

Epoch: 5| Step: 5
Training loss: 0.043853577226400375
Validation loss: 1.4729433034055976

Epoch: 5| Step: 6
Training loss: 0.026346009224653244
Validation loss: 1.460610601209825

Epoch: 5| Step: 7
Training loss: 0.04674415662884712
Validation loss: 1.4502611083369101

Epoch: 5| Step: 8
Training loss: 0.04773282632231712
Validation loss: 1.504196859175159

Epoch: 5| Step: 9
Training loss: 0.04934718459844589
Validation loss: 1.4856377186313752

Epoch: 5| Step: 10
Training loss: 0.06401306390762329
Validation loss: 1.447816014289856

Epoch: 800| Step: 0
Training loss: 0.05606977269053459
Validation loss: 1.4629536956869147

Epoch: 5| Step: 1
Training loss: 0.039774972945451736
Validation loss: 1.468608707510015

Epoch: 5| Step: 2
Training loss: 0.05514784902334213
Validation loss: 1.4887978966518114

Epoch: 5| Step: 3
Training loss: 0.03211435675621033
Validation loss: 1.470467290570659

Epoch: 5| Step: 4
Training loss: 0.06425987184047699
Validation loss: 1.450173395936207

Epoch: 5| Step: 5
Training loss: 0.03920977562665939
Validation loss: 1.4681202468051706

Epoch: 5| Step: 6
Training loss: 0.05454312637448311
Validation loss: 1.4940518743248397

Epoch: 5| Step: 7
Training loss: 0.042241454124450684
Validation loss: 1.519981118940538

Epoch: 5| Step: 8
Training loss: 0.06748664379119873
Validation loss: 1.503145835732901

Epoch: 5| Step: 9
Training loss: 0.04400172829627991
Validation loss: 1.5190268716504496

Epoch: 5| Step: 10
Training loss: 0.04265468567609787
Validation loss: 1.5530089787257615

Testing loss: 2.040464202562968
