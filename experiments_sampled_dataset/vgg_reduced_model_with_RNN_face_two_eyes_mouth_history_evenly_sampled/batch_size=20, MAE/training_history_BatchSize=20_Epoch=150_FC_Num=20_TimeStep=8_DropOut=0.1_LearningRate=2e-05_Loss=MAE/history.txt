Epoch: 1| Step: 0
Training loss: 4.599865913391113
Validation loss: 5.257703796509774

Epoch: 5| Step: 1
Training loss: 4.85518741607666
Validation loss: 5.237684014022991

Epoch: 5| Step: 2
Training loss: 5.271182060241699
Validation loss: 5.217509428660075

Epoch: 5| Step: 3
Training loss: 5.056222438812256
Validation loss: 5.19478210326164

Epoch: 5| Step: 4
Training loss: 5.163482666015625
Validation loss: 5.169892905860819

Epoch: 5| Step: 5
Training loss: 6.213028430938721
Validation loss: 5.140396543728408

Epoch: 5| Step: 6
Training loss: 4.224917888641357
Validation loss: 5.108261539090064

Epoch: 5| Step: 7
Training loss: 4.960719108581543
Validation loss: 5.071173637144027

Epoch: 5| Step: 8
Training loss: 3.88132905960083
Validation loss: 5.029262696543047

Epoch: 5| Step: 9
Training loss: 4.588324546813965
Validation loss: 4.982676511169762

Epoch: 5| Step: 10
Training loss: 5.333132266998291
Validation loss: 4.932949296889767

Epoch: 2| Step: 0
Training loss: 4.346794128417969
Validation loss: 4.878061104846257

Epoch: 5| Step: 1
Training loss: 3.9111487865448
Validation loss: 4.815880437051097

Epoch: 5| Step: 2
Training loss: 3.6528847217559814
Validation loss: 4.751212550747779

Epoch: 5| Step: 3
Training loss: 6.284687519073486
Validation loss: 4.679708080907022

Epoch: 5| Step: 4
Training loss: 3.678974151611328
Validation loss: 4.604015063214046

Epoch: 5| Step: 5
Training loss: 3.9186851978302
Validation loss: 4.522196974805606

Epoch: 5| Step: 6
Training loss: 4.838753700256348
Validation loss: 4.438705703263642

Epoch: 5| Step: 7
Training loss: 4.892403602600098
Validation loss: 4.353437018650834

Epoch: 5| Step: 8
Training loss: 4.778188705444336
Validation loss: 4.266150764239732

Epoch: 5| Step: 9
Training loss: 3.8013412952423096
Validation loss: 4.183590022466516

Epoch: 5| Step: 10
Training loss: 3.0608937740325928
Validation loss: 4.104219698136853

Epoch: 3| Step: 0
Training loss: 3.3158657550811768
Validation loss: 4.0282149417426

Epoch: 5| Step: 1
Training loss: 3.0935704708099365
Validation loss: 3.9515702929548038

Epoch: 5| Step: 2
Training loss: 4.024296760559082
Validation loss: 3.8768067154833066

Epoch: 5| Step: 3
Training loss: 4.286386489868164
Validation loss: 3.8211383537579606

Epoch: 5| Step: 4
Training loss: 2.6841700077056885
Validation loss: 3.774942531380602

Epoch: 5| Step: 5
Training loss: 4.209901332855225
Validation loss: 3.7296980145157024

Epoch: 5| Step: 6
Training loss: 3.3473498821258545
Validation loss: 3.6866003621009087

Epoch: 5| Step: 7
Training loss: 3.9516196250915527
Validation loss: 3.64054811129006

Epoch: 5| Step: 8
Training loss: 4.0376715660095215
Validation loss: 3.595646837706207

Epoch: 5| Step: 9
Training loss: 3.308758497238159
Validation loss: 3.552702514074182

Epoch: 5| Step: 10
Training loss: 3.6857051849365234
Validation loss: 3.5077949980253815

Epoch: 4| Step: 0
Training loss: 2.8497588634490967
Validation loss: 3.4554032920509257

Epoch: 5| Step: 1
Training loss: 3.395949602127075
Validation loss: 3.4152542698767876

Epoch: 5| Step: 2
Training loss: 3.3853161334991455
Validation loss: 3.372562095683108

Epoch: 5| Step: 3
Training loss: 3.6372992992401123
Validation loss: 3.326522442602342

Epoch: 5| Step: 4
Training loss: 2.9526679515838623
Validation loss: 3.2795882301945842

Epoch: 5| Step: 5
Training loss: 2.852735996246338
Validation loss: 3.254342830309304

Epoch: 5| Step: 6
Training loss: 3.4630801677703857
Validation loss: 3.2345268059802312

Epoch: 5| Step: 7
Training loss: 3.1513051986694336
Validation loss: 3.2079329183024745

Epoch: 5| Step: 8
Training loss: 3.516099452972412
Validation loss: 3.181364215830321

Epoch: 5| Step: 9
Training loss: 3.077854871749878
Validation loss: 3.1453325979171263

Epoch: 5| Step: 10
Training loss: 3.445625066757202
Validation loss: 3.1173853720388105

Epoch: 5| Step: 0
Training loss: 3.8864219188690186
Validation loss: 3.1027567412263606

Epoch: 5| Step: 1
Training loss: 3.1908934116363525
Validation loss: 3.085843934807726

Epoch: 5| Step: 2
Training loss: 3.100282907485962
Validation loss: 3.0733328019419024

Epoch: 5| Step: 3
Training loss: 3.1047089099884033
Validation loss: 3.059929117079704

Epoch: 5| Step: 4
Training loss: 3.1231935024261475
Validation loss: 3.0476065835645123

Epoch: 5| Step: 5
Training loss: 2.347092390060425
Validation loss: 3.0362518166983

Epoch: 5| Step: 6
Training loss: 3.295374631881714
Validation loss: 3.0240561936491277

Epoch: 5| Step: 7
Training loss: 3.044381618499756
Validation loss: 3.0178224296980005

Epoch: 5| Step: 8
Training loss: 2.789747714996338
Validation loss: 3.008891869616765

Epoch: 5| Step: 9
Training loss: 2.6490681171417236
Validation loss: 2.998666917124102

Epoch: 5| Step: 10
Training loss: 3.5892415046691895
Validation loss: 2.9906650204812326

Epoch: 6| Step: 0
Training loss: 3.4217429161071777
Validation loss: 2.9764624103423087

Epoch: 5| Step: 1
Training loss: 2.4210751056671143
Validation loss: 2.967368584807201

Epoch: 5| Step: 2
Training loss: 3.0124247074127197
Validation loss: 2.9539141988241546

Epoch: 5| Step: 3
Training loss: 3.2752976417541504
Validation loss: 2.9496119612006733

Epoch: 5| Step: 4
Training loss: 3.052952527999878
Validation loss: 2.936917661338724

Epoch: 5| Step: 5
Training loss: 2.716106414794922
Validation loss: 2.9171791076660156

Epoch: 5| Step: 6
Training loss: 2.9462714195251465
Validation loss: 2.910971769722559

Epoch: 5| Step: 7
Training loss: 2.9915032386779785
Validation loss: 2.9044412028404976

Epoch: 5| Step: 8
Training loss: 3.3432776927948
Validation loss: 2.8967084295006207

Epoch: 5| Step: 9
Training loss: 2.961907148361206
Validation loss: 2.8849513787095264

Epoch: 5| Step: 10
Training loss: 3.0215940475463867
Validation loss: 2.871444304784139

Epoch: 7| Step: 0
Training loss: 2.3182477951049805
Validation loss: 2.859252009340512

Epoch: 5| Step: 1
Training loss: 3.2775650024414062
Validation loss: 2.8745630300173195

Epoch: 5| Step: 2
Training loss: 2.6786091327667236
Validation loss: 2.8470008527078936

Epoch: 5| Step: 3
Training loss: 3.254934310913086
Validation loss: 2.8384593840568297

Epoch: 5| Step: 4
Training loss: 2.993337392807007
Validation loss: 2.8294998163818033

Epoch: 5| Step: 5
Training loss: 2.5874245166778564
Validation loss: 2.819918309488604

Epoch: 5| Step: 6
Training loss: 2.1678128242492676
Validation loss: 2.817762569714618

Epoch: 5| Step: 7
Training loss: 3.644197940826416
Validation loss: 2.819941238690448

Epoch: 5| Step: 8
Training loss: 3.058387279510498
Validation loss: 2.807110155782392

Epoch: 5| Step: 9
Training loss: 2.954066753387451
Validation loss: 2.8016598916822866

Epoch: 5| Step: 10
Training loss: 3.6200408935546875
Validation loss: 2.79690061589723

Epoch: 8| Step: 0
Training loss: 3.2529900074005127
Validation loss: 2.7961847910317044

Epoch: 5| Step: 1
Training loss: 2.9601168632507324
Validation loss: 2.7922710834010953

Epoch: 5| Step: 2
Training loss: 2.348844051361084
Validation loss: 2.7827717258084204

Epoch: 5| Step: 3
Training loss: 3.1891512870788574
Validation loss: 2.766998901162096

Epoch: 5| Step: 4
Training loss: 3.043337345123291
Validation loss: 2.762206995359031

Epoch: 5| Step: 5
Training loss: 3.5789623260498047
Validation loss: 2.756281711721933

Epoch: 5| Step: 6
Training loss: 3.1965043544769287
Validation loss: 2.7523346870176253

Epoch: 5| Step: 7
Training loss: 2.6021206378936768
Validation loss: 2.744759526304019

Epoch: 5| Step: 8
Training loss: 2.5431370735168457
Validation loss: 2.744567245565435

Epoch: 5| Step: 9
Training loss: 2.357445240020752
Validation loss: 2.7383356350724415

Epoch: 5| Step: 10
Training loss: 2.9410767555236816
Validation loss: 2.745550973441011

Epoch: 9| Step: 0
Training loss: 2.3974757194519043
Validation loss: 2.7229345434455463

Epoch: 5| Step: 1
Training loss: 2.7423171997070312
Validation loss: 2.724749179296596

Epoch: 5| Step: 2
Training loss: 2.8722901344299316
Validation loss: 2.723921952709075

Epoch: 5| Step: 3
Training loss: 3.3343842029571533
Validation loss: 2.72093826981001

Epoch: 5| Step: 4
Training loss: 2.874746322631836
Validation loss: 2.718689674972206

Epoch: 5| Step: 5
Training loss: 3.060016393661499
Validation loss: 2.7176481139275337

Epoch: 5| Step: 6
Training loss: 3.1680026054382324
Validation loss: 2.7114603878349386

Epoch: 5| Step: 7
Training loss: 2.9508862495422363
Validation loss: 2.705853972383725

Epoch: 5| Step: 8
Training loss: 2.6751890182495117
Validation loss: 2.7022613171608216

Epoch: 5| Step: 9
Training loss: 2.388167381286621
Validation loss: 2.6974865518590456

Epoch: 5| Step: 10
Training loss: 3.27406907081604
Validation loss: 2.690279761950175

Epoch: 10| Step: 0
Training loss: 3.091984272003174
Validation loss: 2.69297952805796

Epoch: 5| Step: 1
Training loss: 2.3096752166748047
Validation loss: 2.6950617298003166

Epoch: 5| Step: 2
Training loss: 2.5742709636688232
Validation loss: 2.6939183999133367

Epoch: 5| Step: 3
Training loss: 2.747645378112793
Validation loss: 2.68394822202703

Epoch: 5| Step: 4
Training loss: 2.9504342079162598
Validation loss: 2.677892738772977

Epoch: 5| Step: 5
Training loss: 2.880730390548706
Validation loss: 2.6779548506582938

Epoch: 5| Step: 6
Training loss: 2.902703046798706
Validation loss: 2.6810066417981218

Epoch: 5| Step: 7
Training loss: 2.8987343311309814
Validation loss: 2.6774056419249503

Epoch: 5| Step: 8
Training loss: 3.0016589164733887
Validation loss: 2.6744250046309603

Epoch: 5| Step: 9
Training loss: 2.6722195148468018
Validation loss: 2.6645632405434885

Epoch: 5| Step: 10
Training loss: 3.4858334064483643
Validation loss: 2.667035465599388

Epoch: 11| Step: 0
Training loss: 3.369081497192383
Validation loss: 2.6703505874961935

Epoch: 5| Step: 1
Training loss: 2.9344515800476074
Validation loss: 2.6700546664576374

Epoch: 5| Step: 2
Training loss: 2.779433012008667
Validation loss: 2.672366544764529

Epoch: 5| Step: 3
Training loss: 3.3561527729034424
Validation loss: 2.6735408536849485

Epoch: 5| Step: 4
Training loss: 3.2309844493865967
Validation loss: 2.667678794553203

Epoch: 5| Step: 5
Training loss: 2.1790823936462402
Validation loss: 2.660670749602779

Epoch: 5| Step: 6
Training loss: 2.9161503314971924
Validation loss: 2.654981246558569

Epoch: 5| Step: 7
Training loss: 1.7374874353408813
Validation loss: 2.6500830342692714

Epoch: 5| Step: 8
Training loss: 2.604022264480591
Validation loss: 2.656313242450837

Epoch: 5| Step: 9
Training loss: 3.3175292015075684
Validation loss: 2.6538052507626113

Epoch: 5| Step: 10
Training loss: 2.8526997566223145
Validation loss: 2.6678839857860277

Epoch: 12| Step: 0
Training loss: 2.6433053016662598
Validation loss: 2.644337920732396

Epoch: 5| Step: 1
Training loss: 2.888599395751953
Validation loss: 2.645301595810921

Epoch: 5| Step: 2
Training loss: 2.696463108062744
Validation loss: 2.6504756071234263

Epoch: 5| Step: 3
Training loss: 3.1287145614624023
Validation loss: 2.651206818960046

Epoch: 5| Step: 4
Training loss: 2.392699718475342
Validation loss: 2.643255638819869

Epoch: 5| Step: 5
Training loss: 3.1986031532287598
Validation loss: 2.6488544915312078

Epoch: 5| Step: 6
Training loss: 2.6798253059387207
Validation loss: 2.6536476406999814

Epoch: 5| Step: 7
Training loss: 2.7143359184265137
Validation loss: 2.6667799693281933

Epoch: 5| Step: 8
Training loss: 3.2069106101989746
Validation loss: 2.6760525498338925

Epoch: 5| Step: 9
Training loss: 2.8787026405334473
Validation loss: 2.660189010763681

Epoch: 5| Step: 10
Training loss: 2.80776047706604
Validation loss: 2.6453317519157165

Epoch: 13| Step: 0
Training loss: 2.9339632987976074
Validation loss: 2.6397373855754895

Epoch: 5| Step: 1
Training loss: 2.635655164718628
Validation loss: 2.6419104324874056

Epoch: 5| Step: 2
Training loss: 2.751431703567505
Validation loss: 2.657366209132697

Epoch: 5| Step: 3
Training loss: 4.188256740570068
Validation loss: 2.6934221380500385

Epoch: 5| Step: 4
Training loss: 2.7871804237365723
Validation loss: 2.6772690357700473

Epoch: 5| Step: 5
Training loss: 3.0174179077148438
Validation loss: 2.639771138468096

Epoch: 5| Step: 6
Training loss: 2.3287625312805176
Validation loss: 2.627087305950862

Epoch: 5| Step: 7
Training loss: 2.517879009246826
Validation loss: 2.6239864236565045

Epoch: 5| Step: 8
Training loss: 2.8426496982574463
Validation loss: 2.6295821820535967

Epoch: 5| Step: 9
Training loss: 2.357269763946533
Validation loss: 2.661519083925473

Epoch: 5| Step: 10
Training loss: 2.8535146713256836
Validation loss: 2.636264334442795

Epoch: 14| Step: 0
Training loss: 2.8230364322662354
Validation loss: 2.636493585442984

Epoch: 5| Step: 1
Training loss: 3.0218656063079834
Validation loss: 2.6480904317671254

Epoch: 5| Step: 2
Training loss: 3.331261396408081
Validation loss: 2.6596049595904607

Epoch: 5| Step: 3
Training loss: 3.084459066390991
Validation loss: 2.6608970447253157

Epoch: 5| Step: 4
Training loss: 2.327414035797119
Validation loss: 2.629345514441049

Epoch: 5| Step: 5
Training loss: 3.1183738708496094
Validation loss: 2.6161062358528056

Epoch: 5| Step: 6
Training loss: 2.8705077171325684
Validation loss: 2.6326834694031747

Epoch: 5| Step: 7
Training loss: 3.0324108600616455
Validation loss: 2.6735703201704126

Epoch: 5| Step: 8
Training loss: 2.3249497413635254
Validation loss: 2.63262620792594

Epoch: 5| Step: 9
Training loss: 2.8510560989379883
Validation loss: 2.6199927919654438

Epoch: 5| Step: 10
Training loss: 2.3040378093719482
Validation loss: 2.6217912755986696

Epoch: 15| Step: 0
Training loss: 3.368914842605591
Validation loss: 2.6148466525539273

Epoch: 5| Step: 1
Training loss: 3.3108372688293457
Validation loss: 2.627802974434309

Epoch: 5| Step: 2
Training loss: 2.0800628662109375
Validation loss: 2.622073814433108

Epoch: 5| Step: 3
Training loss: 2.6657488346099854
Validation loss: 2.6306601109043246

Epoch: 5| Step: 4
Training loss: 2.7389800548553467
Validation loss: 2.6165527477059314

Epoch: 5| Step: 5
Training loss: 3.6337246894836426
Validation loss: 2.601337073951639

Epoch: 5| Step: 6
Training loss: 2.762828826904297
Validation loss: 2.601607422674856

Epoch: 5| Step: 7
Training loss: 2.4918315410614014
Validation loss: 2.5973534045680875

Epoch: 5| Step: 8
Training loss: 2.8740360736846924
Validation loss: 2.5998695973427064

Epoch: 5| Step: 9
Training loss: 2.8342061042785645
Validation loss: 2.590190790032828

Epoch: 5| Step: 10
Training loss: 2.003164768218994
Validation loss: 2.5881167919405046

Epoch: 16| Step: 0
Training loss: 3.281280994415283
Validation loss: 2.5832226276397705

Epoch: 5| Step: 1
Training loss: 3.12774658203125
Validation loss: 2.5777670747490338

Epoch: 5| Step: 2
Training loss: 2.393265962600708
Validation loss: 2.5751512512083976

Epoch: 5| Step: 3
Training loss: 3.184075117111206
Validation loss: 2.571346200922484

Epoch: 5| Step: 4
Training loss: 2.781759262084961
Validation loss: 2.572510334753221

Epoch: 5| Step: 5
Training loss: 1.8954397439956665
Validation loss: 2.582622371694093

Epoch: 5| Step: 6
Training loss: 2.8643741607666016
Validation loss: 2.596992233748077

Epoch: 5| Step: 7
Training loss: 3.0979135036468506
Validation loss: 2.5965799721338416

Epoch: 5| Step: 8
Training loss: 2.841325044631958
Validation loss: 2.5852664337363294

Epoch: 5| Step: 9
Training loss: 2.385420322418213
Validation loss: 2.5706148711583947

Epoch: 5| Step: 10
Training loss: 2.822809934616089
Validation loss: 2.561901415548017

Epoch: 17| Step: 0
Training loss: 2.130686044692993
Validation loss: 2.5554225521702922

Epoch: 5| Step: 1
Training loss: 2.5431294441223145
Validation loss: 2.556921605140932

Epoch: 5| Step: 2
Training loss: 3.0689122676849365
Validation loss: 2.558724449526879

Epoch: 5| Step: 3
Training loss: 2.3157360553741455
Validation loss: 2.561672915694534

Epoch: 5| Step: 4
Training loss: 3.1304566860198975
Validation loss: 2.554344436173798

Epoch: 5| Step: 5
Training loss: 3.3227241039276123
Validation loss: 2.556797804371003

Epoch: 5| Step: 6
Training loss: 3.7999374866485596
Validation loss: 2.5757321209035893

Epoch: 5| Step: 7
Training loss: 2.2721402645111084
Validation loss: 2.5601798308792936

Epoch: 5| Step: 8
Training loss: 3.084676742553711
Validation loss: 2.5591998074644353

Epoch: 5| Step: 9
Training loss: 2.7952959537506104
Validation loss: 2.543062525410806

Epoch: 5| Step: 10
Training loss: 2.0418643951416016
Validation loss: 2.5420288347428843

Epoch: 18| Step: 0
Training loss: 3.344029664993286
Validation loss: 2.5410997444583523

Epoch: 5| Step: 1
Training loss: 2.770141124725342
Validation loss: 2.540176563365485

Epoch: 5| Step: 2
Training loss: 2.637840747833252
Validation loss: 2.5341829843418573

Epoch: 5| Step: 3
Training loss: 3.257587432861328
Validation loss: 2.5365622171791653

Epoch: 5| Step: 4
Training loss: 3.0965402126312256
Validation loss: 2.5338253872368925

Epoch: 5| Step: 5
Training loss: 2.433053970336914
Validation loss: 2.5359152337556243

Epoch: 5| Step: 6
Training loss: 1.6818978786468506
Validation loss: 2.5315595544794554

Epoch: 5| Step: 7
Training loss: 3.1443164348602295
Validation loss: 2.54043597303411

Epoch: 5| Step: 8
Training loss: 2.391218662261963
Validation loss: 2.547669574778567

Epoch: 5| Step: 9
Training loss: 2.9214515686035156
Validation loss: 2.5405418155013875

Epoch: 5| Step: 10
Training loss: 2.7021172046661377
Validation loss: 2.5359462358618297

Epoch: 19| Step: 0
Training loss: 2.7996373176574707
Validation loss: 2.531631641490485

Epoch: 5| Step: 1
Training loss: 2.5571093559265137
Validation loss: 2.5254540981784945

Epoch: 5| Step: 2
Training loss: 3.23022198677063
Validation loss: 2.5233066158909954

Epoch: 5| Step: 3
Training loss: 1.969792127609253
Validation loss: 2.5260351088739212

Epoch: 5| Step: 4
Training loss: 3.156771421432495
Validation loss: 2.5280655404572845

Epoch: 5| Step: 5
Training loss: 2.5693764686584473
Validation loss: 2.5288778761381745

Epoch: 5| Step: 6
Training loss: 2.3179492950439453
Validation loss: 2.522074245637463

Epoch: 5| Step: 7
Training loss: 3.0715432167053223
Validation loss: 2.5345033907121226

Epoch: 5| Step: 8
Training loss: 2.575913906097412
Validation loss: 2.535487139096824

Epoch: 5| Step: 9
Training loss: 2.807715892791748
Validation loss: 2.559512392167122

Epoch: 5| Step: 10
Training loss: 3.3390908241271973
Validation loss: 2.5265806310920307

Epoch: 20| Step: 0
Training loss: 2.8245644569396973
Validation loss: 2.514480249856108

Epoch: 5| Step: 1
Training loss: 3.3901607990264893
Validation loss: 2.515660262876941

Epoch: 5| Step: 2
Training loss: 3.245487928390503
Validation loss: 2.5137946862046436

Epoch: 5| Step: 3
Training loss: 2.7876083850860596
Validation loss: 2.5118041269240843

Epoch: 5| Step: 4
Training loss: 2.3860771656036377
Validation loss: 2.5099013390079623

Epoch: 5| Step: 5
Training loss: 2.6540415287017822
Validation loss: 2.5124606188907417

Epoch: 5| Step: 6
Training loss: 2.3996188640594482
Validation loss: 2.5193993788893505

Epoch: 5| Step: 7
Training loss: 2.1223015785217285
Validation loss: 2.529836377789897

Epoch: 5| Step: 8
Training loss: 3.4040236473083496
Validation loss: 2.562692601193664

Epoch: 5| Step: 9
Training loss: 2.351256847381592
Validation loss: 2.5911044895008044

Epoch: 5| Step: 10
Training loss: 2.701589345932007
Validation loss: 2.5857972560390348

Epoch: 21| Step: 0
Training loss: 2.5418710708618164
Validation loss: 2.564261551826231

Epoch: 5| Step: 1
Training loss: 2.47448468208313
Validation loss: 2.5120897139272382

Epoch: 5| Step: 2
Training loss: 3.354883909225464
Validation loss: 2.4997198299695085

Epoch: 5| Step: 3
Training loss: 2.9135968685150146
Validation loss: 2.5245802351223525

Epoch: 5| Step: 4
Training loss: 2.561131715774536
Validation loss: 2.5658661498818347

Epoch: 5| Step: 5
Training loss: 2.971484899520874
Validation loss: 2.604630644603442

Epoch: 5| Step: 6
Training loss: 2.8875720500946045
Validation loss: 2.548594021028088

Epoch: 5| Step: 7
Training loss: 2.3622210025787354
Validation loss: 2.542878407304005

Epoch: 5| Step: 8
Training loss: 2.378669023513794
Validation loss: 2.553075426368303

Epoch: 5| Step: 9
Training loss: 2.9066481590270996
Validation loss: 2.5425907527246783

Epoch: 5| Step: 10
Training loss: 3.2550101280212402
Validation loss: 2.5473357426222933

Epoch: 22| Step: 0
Training loss: 2.458160400390625
Validation loss: 2.548623510586318

Epoch: 5| Step: 1
Training loss: 3.084829092025757
Validation loss: 2.529595818570865

Epoch: 5| Step: 2
Training loss: 2.206801414489746
Validation loss: 2.5217480864576114

Epoch: 5| Step: 3
Training loss: 3.0782723426818848
Validation loss: 2.531993099438247

Epoch: 5| Step: 4
Training loss: 2.7556324005126953
Validation loss: 2.5174636046091714

Epoch: 5| Step: 5
Training loss: 3.37565279006958
Validation loss: 2.5060272498797347

Epoch: 5| Step: 6
Training loss: 2.221846103668213
Validation loss: 2.500189865789106

Epoch: 5| Step: 7
Training loss: 3.3596997261047363
Validation loss: 2.496783928204608

Epoch: 5| Step: 8
Training loss: 2.7499003410339355
Validation loss: 2.4970092593982653

Epoch: 5| Step: 9
Training loss: 2.4267258644104004
Validation loss: 2.510082076954585

Epoch: 5| Step: 10
Training loss: 2.477530002593994
Validation loss: 2.503305442871586

Epoch: 23| Step: 0
Training loss: 3.1478724479675293
Validation loss: 2.507378711495348

Epoch: 5| Step: 1
Training loss: 2.9937140941619873
Validation loss: 2.496790116833102

Epoch: 5| Step: 2
Training loss: 2.456861734390259
Validation loss: 2.491082488849599

Epoch: 5| Step: 3
Training loss: 2.8113174438476562
Validation loss: 2.489837372174827

Epoch: 5| Step: 4
Training loss: 1.6043426990509033
Validation loss: 2.4890018611825924

Epoch: 5| Step: 5
Training loss: 2.9207162857055664
Validation loss: 2.490593151379657

Epoch: 5| Step: 6
Training loss: 2.8893465995788574
Validation loss: 2.4928433254200923

Epoch: 5| Step: 7
Training loss: 2.8827929496765137
Validation loss: 2.493068556631765

Epoch: 5| Step: 8
Training loss: 2.400542736053467
Validation loss: 2.497362918751214

Epoch: 5| Step: 9
Training loss: 2.997620105743408
Validation loss: 2.4962391917423536

Epoch: 5| Step: 10
Training loss: 2.9331820011138916
Validation loss: 2.4950302236823627

Epoch: 24| Step: 0
Training loss: 2.49450421333313
Validation loss: 2.4938791439097416

Epoch: 5| Step: 1
Training loss: 2.988778591156006
Validation loss: 2.493962175102644

Epoch: 5| Step: 2
Training loss: 3.4552135467529297
Validation loss: 2.511075432582568

Epoch: 5| Step: 3
Training loss: 3.328307628631592
Validation loss: 2.497293864527056

Epoch: 5| Step: 4
Training loss: 2.357938051223755
Validation loss: 2.4812115212922454

Epoch: 5| Step: 5
Training loss: 2.503584623336792
Validation loss: 2.4771002774597495

Epoch: 5| Step: 6
Training loss: 2.9305403232574463
Validation loss: 2.4945500179003646

Epoch: 5| Step: 7
Training loss: 2.2166085243225098
Validation loss: 2.5182012383655836

Epoch: 5| Step: 8
Training loss: 2.938849925994873
Validation loss: 2.5502365942924254

Epoch: 5| Step: 9
Training loss: 2.139946460723877
Validation loss: 2.529253887873824

Epoch: 5| Step: 10
Training loss: 2.6567792892456055
Validation loss: 2.5219147692444506

Epoch: 25| Step: 0
Training loss: 2.684784412384033
Validation loss: 2.5133285907007035

Epoch: 5| Step: 1
Training loss: 2.588655471801758
Validation loss: 2.50110718511766

Epoch: 5| Step: 2
Training loss: 2.507232666015625
Validation loss: 2.49536161012547

Epoch: 5| Step: 3
Training loss: 2.757875919342041
Validation loss: 2.4790748344954623

Epoch: 5| Step: 4
Training loss: 2.5991740226745605
Validation loss: 2.473865992279463

Epoch: 5| Step: 5
Training loss: 2.4415507316589355
Validation loss: 2.4710195397817962

Epoch: 5| Step: 6
Training loss: 3.189791440963745
Validation loss: 2.4712456708313315

Epoch: 5| Step: 7
Training loss: 2.5607903003692627
Validation loss: 2.480037828927399

Epoch: 5| Step: 8
Training loss: 3.417877674102783
Validation loss: 2.4832816252144436

Epoch: 5| Step: 9
Training loss: 2.6205692291259766
Validation loss: 2.482079134192518

Epoch: 5| Step: 10
Training loss: 2.5172531604766846
Validation loss: 2.470815658569336

Epoch: 26| Step: 0
Training loss: 2.173306941986084
Validation loss: 2.4786011788152877

Epoch: 5| Step: 1
Training loss: 2.7501463890075684
Validation loss: 2.484631815264302

Epoch: 5| Step: 2
Training loss: 2.2500431537628174
Validation loss: 2.5105168665609052

Epoch: 5| Step: 3
Training loss: 2.661259889602661
Validation loss: 2.5446134331405803

Epoch: 5| Step: 4
Training loss: 3.4949569702148438
Validation loss: 2.528863368495818

Epoch: 5| Step: 5
Training loss: 3.178680181503296
Validation loss: 2.484301123567807

Epoch: 5| Step: 6
Training loss: 2.849119186401367
Validation loss: 2.4640383540943103

Epoch: 5| Step: 7
Training loss: 2.540017604827881
Validation loss: 2.45413290813405

Epoch: 5| Step: 8
Training loss: 2.506108522415161
Validation loss: 2.4529558791909167

Epoch: 5| Step: 9
Training loss: 2.5451340675354004
Validation loss: 2.4587137622217976

Epoch: 5| Step: 10
Training loss: 2.852717638015747
Validation loss: 2.458671418569421

Epoch: 27| Step: 0
Training loss: 2.846057415008545
Validation loss: 2.4618810261449506

Epoch: 5| Step: 1
Training loss: 2.786470890045166
Validation loss: 2.458855885331349

Epoch: 5| Step: 2
Training loss: 2.1532416343688965
Validation loss: 2.4597459198326193

Epoch: 5| Step: 3
Training loss: 2.9884276390075684
Validation loss: 2.4617670633459605

Epoch: 5| Step: 4
Training loss: 3.32792329788208
Validation loss: 2.4770127983503443

Epoch: 5| Step: 5
Training loss: 3.3389198780059814
Validation loss: 2.4861426866182716

Epoch: 5| Step: 6
Training loss: 3.316127061843872
Validation loss: 2.491916838512626

Epoch: 5| Step: 7
Training loss: 1.933847427368164
Validation loss: 2.482046809247745

Epoch: 5| Step: 8
Training loss: 2.1064133644104004
Validation loss: 2.486790421188519

Epoch: 5| Step: 9
Training loss: 2.6125240325927734
Validation loss: 2.5061042308807373

Epoch: 5| Step: 10
Training loss: 2.282602310180664
Validation loss: 2.4638608604349117

Epoch: 28| Step: 0
Training loss: 3.1311309337615967
Validation loss: 2.4536083257326515

Epoch: 5| Step: 1
Training loss: 2.651583194732666
Validation loss: 2.455383672509142

Epoch: 5| Step: 2
Training loss: 2.2893669605255127
Validation loss: 2.4631815084847073

Epoch: 5| Step: 3
Training loss: 3.4975180625915527
Validation loss: 2.4773002965475923

Epoch: 5| Step: 4
Training loss: 3.0786633491516113
Validation loss: 2.460132388658421

Epoch: 5| Step: 5
Training loss: 3.0302329063415527
Validation loss: 2.4562983666696856

Epoch: 5| Step: 6
Training loss: 2.363511323928833
Validation loss: 2.468765333134641

Epoch: 5| Step: 7
Training loss: 2.1314733028411865
Validation loss: 2.4914322924870316

Epoch: 5| Step: 8
Training loss: 2.5204763412475586
Validation loss: 2.496591314192741

Epoch: 5| Step: 9
Training loss: 2.4075982570648193
Validation loss: 2.475560995840257

Epoch: 5| Step: 10
Training loss: 2.4935624599456787
Validation loss: 2.4549370709285943

Epoch: 29| Step: 0
Training loss: 3.2096829414367676
Validation loss: 2.4472321976897535

Epoch: 5| Step: 1
Training loss: 3.0155844688415527
Validation loss: 2.434999886379447

Epoch: 5| Step: 2
Training loss: 3.4346909523010254
Validation loss: 2.4321316390909176

Epoch: 5| Step: 3
Training loss: 2.581113815307617
Validation loss: 2.428835368925525

Epoch: 5| Step: 4
Training loss: 1.9754703044891357
Validation loss: 2.426382772384151

Epoch: 5| Step: 5
Training loss: 2.229471445083618
Validation loss: 2.4353534201140046

Epoch: 5| Step: 6
Training loss: 2.564892292022705
Validation loss: 2.4506102044095277

Epoch: 5| Step: 7
Training loss: 2.897488594055176
Validation loss: 2.4797206976080455

Epoch: 5| Step: 8
Training loss: 2.4211535453796387
Validation loss: 2.496378275655931

Epoch: 5| Step: 9
Training loss: 2.6101579666137695
Validation loss: 2.484688307649346

Epoch: 5| Step: 10
Training loss: 2.4717564582824707
Validation loss: 2.48532134743147

Epoch: 30| Step: 0
Training loss: 2.404846668243408
Validation loss: 2.457439499516641

Epoch: 5| Step: 1
Training loss: 2.5101561546325684
Validation loss: 2.4410635527744087

Epoch: 5| Step: 2
Training loss: 2.3986096382141113
Validation loss: 2.4413519469640588

Epoch: 5| Step: 3
Training loss: 3.667757749557495
Validation loss: 2.46787937225834

Epoch: 5| Step: 4
Training loss: 2.827348232269287
Validation loss: 2.4909995563568605

Epoch: 5| Step: 5
Training loss: 2.6516692638397217
Validation loss: 2.5115779164016887

Epoch: 5| Step: 6
Training loss: 2.792501926422119
Validation loss: 2.5011210723589827

Epoch: 5| Step: 7
Training loss: 2.535541534423828
Validation loss: 2.4766308748593895

Epoch: 5| Step: 8
Training loss: 2.798675060272217
Validation loss: 2.439724450470299

Epoch: 5| Step: 9
Training loss: 1.739403486251831
Validation loss: 2.4256913815775225

Epoch: 5| Step: 10
Training loss: 3.2535033226013184
Validation loss: 2.424711335089899

Epoch: 31| Step: 0
Training loss: 2.2980637550354004
Validation loss: 2.4331777659795617

Epoch: 5| Step: 1
Training loss: 3.204998016357422
Validation loss: 2.436451881162582

Epoch: 5| Step: 2
Training loss: 2.606431722640991
Validation loss: 2.4255244449902604

Epoch: 5| Step: 3
Training loss: 2.630110263824463
Validation loss: 2.415905673016784

Epoch: 5| Step: 4
Training loss: 3.089663505554199
Validation loss: 2.415456892341696

Epoch: 5| Step: 5
Training loss: 2.8454062938690186
Validation loss: 2.413597878589425

Epoch: 5| Step: 6
Training loss: 1.7962592840194702
Validation loss: 2.422791750200333

Epoch: 5| Step: 7
Training loss: 3.1340975761413574
Validation loss: 2.453061080748035

Epoch: 5| Step: 8
Training loss: 2.7704567909240723
Validation loss: 2.5108185788636566

Epoch: 5| Step: 9
Training loss: 2.6642651557922363
Validation loss: 2.506634307164018

Epoch: 5| Step: 10
Training loss: 2.2491519451141357
Validation loss: 2.5450663976771857

Epoch: 32| Step: 0
Training loss: 2.257835865020752
Validation loss: 2.5818199085932907

Epoch: 5| Step: 1
Training loss: 2.138397455215454
Validation loss: 2.653529503012216

Epoch: 5| Step: 2
Training loss: 2.991597890853882
Validation loss: 2.6159802893156647

Epoch: 5| Step: 3
Training loss: 2.2140793800354004
Validation loss: 2.554526150867503

Epoch: 5| Step: 4
Training loss: 2.7925021648406982
Validation loss: 2.4594210988731793

Epoch: 5| Step: 5
Training loss: 2.4752049446105957
Validation loss: 2.438644434816094

Epoch: 5| Step: 6
Training loss: 2.911741018295288
Validation loss: 2.4330775840308076

Epoch: 5| Step: 7
Training loss: 3.2942588329315186
Validation loss: 2.428234008050734

Epoch: 5| Step: 8
Training loss: 2.988173007965088
Validation loss: 2.4356905657757997

Epoch: 5| Step: 9
Training loss: 2.90840482711792
Validation loss: 2.449528568534441

Epoch: 5| Step: 10
Training loss: 2.668757915496826
Validation loss: 2.4329624842571955

Epoch: 33| Step: 0
Training loss: 2.077190637588501
Validation loss: 2.4321694220266035

Epoch: 5| Step: 1
Training loss: 3.5982327461242676
Validation loss: 2.4351571298414663

Epoch: 5| Step: 2
Training loss: 2.8679943084716797
Validation loss: 2.435584898917906

Epoch: 5| Step: 3
Training loss: 2.330195426940918
Validation loss: 2.440022696730911

Epoch: 5| Step: 4
Training loss: 2.843254566192627
Validation loss: 2.4539942741394043

Epoch: 5| Step: 5
Training loss: 2.5728583335876465
Validation loss: 2.4735162899058354

Epoch: 5| Step: 6
Training loss: 2.6938624382019043
Validation loss: 2.473550417089975

Epoch: 5| Step: 7
Training loss: 2.6983680725097656
Validation loss: 2.4804164671128794

Epoch: 5| Step: 8
Training loss: 2.526014804840088
Validation loss: 2.476812977944651

Epoch: 5| Step: 9
Training loss: 2.525139331817627
Validation loss: 2.4676643392091155

Epoch: 5| Step: 10
Training loss: 2.6590709686279297
Validation loss: 2.4484063092098443

Epoch: 34| Step: 0
Training loss: 2.618312358856201
Validation loss: 2.436731610246884

Epoch: 5| Step: 1
Training loss: 2.779953718185425
Validation loss: 2.426469672110773

Epoch: 5| Step: 2
Training loss: 2.3179829120635986
Validation loss: 2.4201460089734805

Epoch: 5| Step: 3
Training loss: 2.1658859252929688
Validation loss: 2.4173661483231412

Epoch: 5| Step: 4
Training loss: 2.518580913543701
Validation loss: 2.414400218635477

Epoch: 5| Step: 5
Training loss: 3.198453903198242
Validation loss: 2.417497447741929

Epoch: 5| Step: 6
Training loss: 2.9335880279541016
Validation loss: 2.4435006059626097

Epoch: 5| Step: 7
Training loss: 2.577357053756714
Validation loss: 2.4714684101843063

Epoch: 5| Step: 8
Training loss: 2.4534013271331787
Validation loss: 2.508016840104134

Epoch: 5| Step: 9
Training loss: 2.803471565246582
Validation loss: 2.521289938239641

Epoch: 5| Step: 10
Training loss: 3.030845880508423
Validation loss: 2.4705104520243983

Epoch: 35| Step: 0
Training loss: 3.2795650959014893
Validation loss: 2.41609715389949

Epoch: 5| Step: 1
Training loss: 2.7893142700195312
Validation loss: 2.404155041581841

Epoch: 5| Step: 2
Training loss: 2.6955137252807617
Validation loss: 2.3917586341980965

Epoch: 5| Step: 3
Training loss: 2.3282368183135986
Validation loss: 2.3860380598293838

Epoch: 5| Step: 4
Training loss: 3.0320751667022705
Validation loss: 2.3858182481540147

Epoch: 5| Step: 5
Training loss: 2.7996726036071777
Validation loss: 2.394851379497077

Epoch: 5| Step: 6
Training loss: 2.2709240913391113
Validation loss: 2.40682953147478

Epoch: 5| Step: 7
Training loss: 1.8837902545928955
Validation loss: 2.4211295881579

Epoch: 5| Step: 8
Training loss: 2.669614791870117
Validation loss: 2.4226885252101447

Epoch: 5| Step: 9
Training loss: 2.617638111114502
Validation loss: 2.438352207983694

Epoch: 5| Step: 10
Training loss: 3.0182385444641113
Validation loss: 2.4431005524050806

Epoch: 36| Step: 0
Training loss: 2.795092821121216
Validation loss: 2.430401599535378

Epoch: 5| Step: 1
Training loss: 2.904447555541992
Validation loss: 2.4704447420694495

Epoch: 5| Step: 2
Training loss: 2.0959298610687256
Validation loss: 2.5414274789953746

Epoch: 5| Step: 3
Training loss: 2.4152846336364746
Validation loss: 2.536666359952701

Epoch: 5| Step: 4
Training loss: 2.1935057640075684
Validation loss: 2.539883344404159

Epoch: 5| Step: 5
Training loss: 3.3877601623535156
Validation loss: 2.471220847099058

Epoch: 5| Step: 6
Training loss: 2.295577049255371
Validation loss: 2.418436345233712

Epoch: 5| Step: 7
Training loss: 3.1201183795928955
Validation loss: 2.3904204830046623

Epoch: 5| Step: 8
Training loss: 2.955579996109009
Validation loss: 2.3876606110603578

Epoch: 5| Step: 9
Training loss: 2.5879406929016113
Validation loss: 2.3900767346864105

Epoch: 5| Step: 10
Training loss: 2.4111435413360596
Validation loss: 2.3776911766298356

Epoch: 37| Step: 0
Training loss: 2.4334511756896973
Validation loss: 2.3759832279656523

Epoch: 5| Step: 1
Training loss: 2.814521074295044
Validation loss: 2.3744760841451664

Epoch: 5| Step: 2
Training loss: 2.2874934673309326
Validation loss: 2.3753488473994757

Epoch: 5| Step: 3
Training loss: 2.9656176567077637
Validation loss: 2.380301014069588

Epoch: 5| Step: 4
Training loss: 2.0905535221099854
Validation loss: 2.385012698429887

Epoch: 5| Step: 5
Training loss: 2.9299979209899902
Validation loss: 2.399608435169343

Epoch: 5| Step: 6
Training loss: 2.4217538833618164
Validation loss: 2.427257991606189

Epoch: 5| Step: 7
Training loss: 2.070096015930176
Validation loss: 2.434868981761317

Epoch: 5| Step: 8
Training loss: 2.8049874305725098
Validation loss: 2.433951177904683

Epoch: 5| Step: 9
Training loss: 3.053966999053955
Validation loss: 2.4214939609650643

Epoch: 5| Step: 10
Training loss: 3.2685608863830566
Validation loss: 2.420095638562274

Epoch: 38| Step: 0
Training loss: 2.5262491703033447
Validation loss: 2.4026903490866385

Epoch: 5| Step: 1
Training loss: 2.811558961868286
Validation loss: 2.3899672467221498

Epoch: 5| Step: 2
Training loss: 1.6804485321044922
Validation loss: 2.391402098440355

Epoch: 5| Step: 3
Training loss: 2.5462188720703125
Validation loss: 2.398582035495389

Epoch: 5| Step: 4
Training loss: 2.175171375274658
Validation loss: 2.3950930128815355

Epoch: 5| Step: 5
Training loss: 2.626394748687744
Validation loss: 2.3840401711002475

Epoch: 5| Step: 6
Training loss: 2.367737054824829
Validation loss: 2.374911800507576

Epoch: 5| Step: 7
Training loss: 2.6935007572174072
Validation loss: 2.3680157687074397

Epoch: 5| Step: 8
Training loss: 3.007018566131592
Validation loss: 2.362910250181793

Epoch: 5| Step: 9
Training loss: 2.9394774436950684
Validation loss: 2.3595668218469106

Epoch: 5| Step: 10
Training loss: 3.6038150787353516
Validation loss: 2.365889669746481

Epoch: 39| Step: 0
Training loss: 2.4294955730438232
Validation loss: 2.378366542118852

Epoch: 5| Step: 1
Training loss: 2.3919360637664795
Validation loss: 2.3841925590269026

Epoch: 5| Step: 2
Training loss: 2.851651430130005
Validation loss: 2.3836554327318744

Epoch: 5| Step: 3
Training loss: 2.2497029304504395
Validation loss: 2.382286053831859

Epoch: 5| Step: 4
Training loss: 2.6015474796295166
Validation loss: 2.383827858073737

Epoch: 5| Step: 5
Training loss: 2.7750935554504395
Validation loss: 2.3853527397237797

Epoch: 5| Step: 6
Training loss: 3.3394370079040527
Validation loss: 2.3828591249322377

Epoch: 5| Step: 7
Training loss: 2.757888078689575
Validation loss: 2.37929303543542

Epoch: 5| Step: 8
Training loss: 2.3657498359680176
Validation loss: 2.3710995515187583

Epoch: 5| Step: 9
Training loss: 2.2605977058410645
Validation loss: 2.377209483936269

Epoch: 5| Step: 10
Training loss: 2.850628614425659
Validation loss: 2.3836476161915767

Epoch: 40| Step: 0
Training loss: 2.256007432937622
Validation loss: 2.4018068287962224

Epoch: 5| Step: 1
Training loss: 3.3463134765625
Validation loss: 2.4251790546601817

Epoch: 5| Step: 2
Training loss: 2.1324210166931152
Validation loss: 2.4240160936950357

Epoch: 5| Step: 3
Training loss: 2.7279324531555176
Validation loss: 2.433105445677234

Epoch: 5| Step: 4
Training loss: 1.8274438381195068
Validation loss: 2.42751246113931

Epoch: 5| Step: 5
Training loss: 2.930110216140747
Validation loss: 2.4116222384155437

Epoch: 5| Step: 6
Training loss: 2.1310877799987793
Validation loss: 2.395140893997685

Epoch: 5| Step: 7
Training loss: 2.915050506591797
Validation loss: 2.3845983551394556

Epoch: 5| Step: 8
Training loss: 3.0300650596618652
Validation loss: 2.3676314328306463

Epoch: 5| Step: 9
Training loss: 2.4123618602752686
Validation loss: 2.3589451031018327

Epoch: 5| Step: 10
Training loss: 3.075058698654175
Validation loss: 2.355955334119899

Epoch: 41| Step: 0
Training loss: 2.4045541286468506
Validation loss: 2.3509935922520135

Epoch: 5| Step: 1
Training loss: 2.402599334716797
Validation loss: 2.3483955321773404

Epoch: 5| Step: 2
Training loss: 3.1314685344696045
Validation loss: 2.3532381929377073

Epoch: 5| Step: 3
Training loss: 2.965906858444214
Validation loss: 2.3499305555897374

Epoch: 5| Step: 4
Training loss: 2.5512452125549316
Validation loss: 2.350347136938444

Epoch: 5| Step: 5
Training loss: 2.92570161819458
Validation loss: 2.351224753164476

Epoch: 5| Step: 6
Training loss: 2.680371046066284
Validation loss: 2.3492158305260444

Epoch: 5| Step: 7
Training loss: 2.728745698928833
Validation loss: 2.349398607848793

Epoch: 5| Step: 8
Training loss: 2.5867226123809814
Validation loss: 2.35065060277139

Epoch: 5| Step: 9
Training loss: 2.037884473800659
Validation loss: 2.3582931846700688

Epoch: 5| Step: 10
Training loss: 2.407435655593872
Validation loss: 2.3684687947714202

Epoch: 42| Step: 0
Training loss: 3.006230115890503
Validation loss: 2.382055700466197

Epoch: 5| Step: 1
Training loss: 2.109673023223877
Validation loss: 2.4046888864168556

Epoch: 5| Step: 2
Training loss: 2.876568555831909
Validation loss: 2.4368898612196728

Epoch: 5| Step: 3
Training loss: 2.2957661151885986
Validation loss: 2.478981682049331

Epoch: 5| Step: 4
Training loss: 3.325815200805664
Validation loss: 2.47410406989436

Epoch: 5| Step: 5
Training loss: 2.928210735321045
Validation loss: 2.4591953703152236

Epoch: 5| Step: 6
Training loss: 2.939598560333252
Validation loss: 2.422666408682382

Epoch: 5| Step: 7
Training loss: 2.657524347305298
Validation loss: 2.3908524820881505

Epoch: 5| Step: 8
Training loss: 2.6318039894104004
Validation loss: 2.3630274777771323

Epoch: 5| Step: 9
Training loss: 2.1331539154052734
Validation loss: 2.348415446537797

Epoch: 5| Step: 10
Training loss: 2.008726119995117
Validation loss: 2.3406385247425368

Epoch: 43| Step: 0
Training loss: 2.5070431232452393
Validation loss: 2.3402642203915502

Epoch: 5| Step: 1
Training loss: 2.5676136016845703
Validation loss: 2.338869076903148

Epoch: 5| Step: 2
Training loss: 2.6262574195861816
Validation loss: 2.339828360465265

Epoch: 5| Step: 3
Training loss: 2.5475237369537354
Validation loss: 2.3383879610287246

Epoch: 5| Step: 4
Training loss: 2.3187971115112305
Validation loss: 2.340301868736103

Epoch: 5| Step: 5
Training loss: 2.006959915161133
Validation loss: 2.3523091116259174

Epoch: 5| Step: 6
Training loss: 2.3075737953186035
Validation loss: 2.358231472712691

Epoch: 5| Step: 7
Training loss: 2.940107822418213
Validation loss: 2.3654780695515294

Epoch: 5| Step: 8
Training loss: 3.2232277393341064
Validation loss: 2.3981220760653095

Epoch: 5| Step: 9
Training loss: 2.682732582092285
Validation loss: 2.396257842740705

Epoch: 5| Step: 10
Training loss: 2.9670557975769043
Validation loss: 2.4025130938458186

Epoch: 44| Step: 0
Training loss: 2.5788402557373047
Validation loss: 2.410279071459206

Epoch: 5| Step: 1
Training loss: 2.298130750656128
Validation loss: 2.4184784991766817

Epoch: 5| Step: 2
Training loss: 2.841529130935669
Validation loss: 2.409030657942577

Epoch: 5| Step: 3
Training loss: 2.3397631645202637
Validation loss: 2.407386049147575

Epoch: 5| Step: 4
Training loss: 2.608832597732544
Validation loss: 2.382773366025699

Epoch: 5| Step: 5
Training loss: 2.6859359741210938
Validation loss: 2.3622784922199864

Epoch: 5| Step: 6
Training loss: 2.7972917556762695
Validation loss: 2.343256768359933

Epoch: 5| Step: 7
Training loss: 2.2470905780792236
Validation loss: 2.3313329450545774

Epoch: 5| Step: 8
Training loss: 2.6200015544891357
Validation loss: 2.3296562420424594

Epoch: 5| Step: 9
Training loss: 2.5925657749176025
Validation loss: 2.330715166625156

Epoch: 5| Step: 10
Training loss: 3.107759714126587
Validation loss: 2.3347595237916514

Epoch: 45| Step: 0
Training loss: 2.733351707458496
Validation loss: 2.331181590275098

Epoch: 5| Step: 1
Training loss: 2.6765666007995605
Validation loss: 2.3267735512025896

Epoch: 5| Step: 2
Training loss: 2.4822354316711426
Validation loss: 2.3172385666960027

Epoch: 5| Step: 3
Training loss: 2.313105821609497
Validation loss: 2.320530652999878

Epoch: 5| Step: 4
Training loss: 2.0696024894714355
Validation loss: 2.334786110026862

Epoch: 5| Step: 5
Training loss: 2.761312246322632
Validation loss: 2.363942180910418

Epoch: 5| Step: 6
Training loss: 2.217623472213745
Validation loss: 2.368587137550436

Epoch: 5| Step: 7
Training loss: 2.9607436656951904
Validation loss: 2.3894725179159515

Epoch: 5| Step: 8
Training loss: 3.1508870124816895
Validation loss: 2.3928582027394283

Epoch: 5| Step: 9
Training loss: 2.7487194538116455
Validation loss: 2.3866856405811925

Epoch: 5| Step: 10
Training loss: 2.7113935947418213
Validation loss: 2.3940366083575833

Epoch: 46| Step: 0
Training loss: 3.415339708328247
Validation loss: 2.390690034435641

Epoch: 5| Step: 1
Training loss: 1.7698347568511963
Validation loss: 2.3791339269248386

Epoch: 5| Step: 2
Training loss: 3.1026694774627686
Validation loss: 2.352449140241069

Epoch: 5| Step: 3
Training loss: 3.20881724357605
Validation loss: 2.341522455215454

Epoch: 5| Step: 4
Training loss: 2.5541486740112305
Validation loss: 2.323506527049567

Epoch: 5| Step: 5
Training loss: 3.049330234527588
Validation loss: 2.329462182137274

Epoch: 5| Step: 6
Training loss: 2.3129944801330566
Validation loss: 2.337846394508116

Epoch: 5| Step: 7
Training loss: 2.26789927482605
Validation loss: 2.339490995612196

Epoch: 5| Step: 8
Training loss: 2.306579113006592
Validation loss: 2.335699448021509

Epoch: 5| Step: 9
Training loss: 2.474985361099243
Validation loss: 2.3369925637398996

Epoch: 5| Step: 10
Training loss: 1.990990161895752
Validation loss: 2.3331063691005913

Epoch: 47| Step: 0
Training loss: 2.5240049362182617
Validation loss: 2.3237691899781585

Epoch: 5| Step: 1
Training loss: 2.7147884368896484
Validation loss: 2.324986455261066

Epoch: 5| Step: 2
Training loss: 2.1090128421783447
Validation loss: 2.328957491023566

Epoch: 5| Step: 3
Training loss: 2.1264169216156006
Validation loss: 2.3332889028774795

Epoch: 5| Step: 4
Training loss: 2.746429920196533
Validation loss: 2.337391886659848

Epoch: 5| Step: 5
Training loss: 2.9718785285949707
Validation loss: 2.3634522063757784

Epoch: 5| Step: 6
Training loss: 3.059145927429199
Validation loss: 2.384795832377608

Epoch: 5| Step: 7
Training loss: 2.7095675468444824
Validation loss: 2.4007300305110153

Epoch: 5| Step: 8
Training loss: 2.5420680046081543
Validation loss: 2.4046329118872203

Epoch: 5| Step: 9
Training loss: 2.654611825942993
Validation loss: 2.385211565161264

Epoch: 5| Step: 10
Training loss: 2.4710047245025635
Validation loss: 2.3571377056901173

Epoch: 48| Step: 0
Training loss: 2.6146652698516846
Validation loss: 2.3363320366028817

Epoch: 5| Step: 1
Training loss: 3.214416980743408
Validation loss: 2.31942234757126

Epoch: 5| Step: 2
Training loss: 2.43696928024292
Validation loss: 2.309507372558758

Epoch: 5| Step: 3
Training loss: 2.420335292816162
Validation loss: 2.302803167732813

Epoch: 5| Step: 4
Training loss: 2.450899124145508
Validation loss: 2.3022561727031583

Epoch: 5| Step: 5
Training loss: 2.121583938598633
Validation loss: 2.2978518470641105

Epoch: 5| Step: 6
Training loss: 2.4813294410705566
Validation loss: 2.293773921587134

Epoch: 5| Step: 7
Training loss: 2.893484592437744
Validation loss: 2.2982777011009956

Epoch: 5| Step: 8
Training loss: 2.2867074012756348
Validation loss: 2.3013483067994476

Epoch: 5| Step: 9
Training loss: 2.2240474224090576
Validation loss: 2.30349329979189

Epoch: 5| Step: 10
Training loss: 3.4998836517333984
Validation loss: 2.309421585452172

Epoch: 49| Step: 0
Training loss: 2.3192808628082275
Validation loss: 2.316292555101456

Epoch: 5| Step: 1
Training loss: 2.199227809906006
Validation loss: 2.323728802383587

Epoch: 5| Step: 2
Training loss: 2.2771177291870117
Validation loss: 2.3281169706775295

Epoch: 5| Step: 3
Training loss: 3.1525635719299316
Validation loss: 2.320379175165648

Epoch: 5| Step: 4
Training loss: 2.2764086723327637
Validation loss: 2.3136681164464643

Epoch: 5| Step: 5
Training loss: 2.3857903480529785
Validation loss: 2.299564723045595

Epoch: 5| Step: 6
Training loss: 2.8644299507141113
Validation loss: 2.29640862505923

Epoch: 5| Step: 7
Training loss: 2.1359095573425293
Validation loss: 2.2922437729374057

Epoch: 5| Step: 8
Training loss: 3.1498234272003174
Validation loss: 2.2893445158517487

Epoch: 5| Step: 9
Training loss: 2.9657504558563232
Validation loss: 2.2863624890645347

Epoch: 5| Step: 10
Training loss: 2.6995575428009033
Validation loss: 2.289571846685102

Epoch: 50| Step: 0
Training loss: 2.5029919147491455
Validation loss: 2.293977609244726

Epoch: 5| Step: 1
Training loss: 2.9312591552734375
Validation loss: 2.3091723560005106

Epoch: 5| Step: 2
Training loss: 2.2864725589752197
Validation loss: 2.321565179414647

Epoch: 5| Step: 3
Training loss: 3.2591850757598877
Validation loss: 2.335009123689385

Epoch: 5| Step: 4
Training loss: 2.758317708969116
Validation loss: 2.3343416131952757

Epoch: 5| Step: 5
Training loss: 2.0612761974334717
Validation loss: 2.325454265840592

Epoch: 5| Step: 6
Training loss: 2.434680938720703
Validation loss: 2.32278242675207

Epoch: 5| Step: 7
Training loss: 2.547797679901123
Validation loss: 2.327269151646604

Epoch: 5| Step: 8
Training loss: 2.271864652633667
Validation loss: 2.325606523021575

Epoch: 5| Step: 9
Training loss: 2.9323277473449707
Validation loss: 2.3149252450594338

Epoch: 5| Step: 10
Training loss: 2.340031147003174
Validation loss: 2.3170442940086446

Epoch: 51| Step: 0
Training loss: 2.432644844055176
Validation loss: 2.3109042054863385

Epoch: 5| Step: 1
Training loss: 1.821405053138733
Validation loss: 2.3004279367385374

Epoch: 5| Step: 2
Training loss: 2.5942912101745605
Validation loss: 2.2965632023349887

Epoch: 5| Step: 3
Training loss: 2.3143136501312256
Validation loss: 2.293976996534614

Epoch: 5| Step: 4
Training loss: 2.86220121383667
Validation loss: 2.2983381209834928

Epoch: 5| Step: 5
Training loss: 2.150322437286377
Validation loss: 2.305032899302821

Epoch: 5| Step: 6
Training loss: 2.951472043991089
Validation loss: 2.3127999305725098

Epoch: 5| Step: 7
Training loss: 2.503530979156494
Validation loss: 2.309178553601747

Epoch: 5| Step: 8
Training loss: 3.2548046112060547
Validation loss: 2.312845876139979

Epoch: 5| Step: 9
Training loss: 2.65757417678833
Validation loss: 2.3143595213531167

Epoch: 5| Step: 10
Training loss: 2.661358118057251
Validation loss: 2.3144607672127346

Epoch: 52| Step: 0
Training loss: 2.1732168197631836
Validation loss: 2.317701793486072

Epoch: 5| Step: 1
Training loss: 1.9616206884384155
Validation loss: 2.317353343450895

Epoch: 5| Step: 2
Training loss: 3.0220932960510254
Validation loss: 2.327389806829473

Epoch: 5| Step: 3
Training loss: 2.709120273590088
Validation loss: 2.319714564149098

Epoch: 5| Step: 4
Training loss: 2.921947717666626
Validation loss: 2.3115337382080736

Epoch: 5| Step: 5
Training loss: 2.209442377090454
Validation loss: 2.294841553575249

Epoch: 5| Step: 6
Training loss: 2.6715903282165527
Validation loss: 2.290713302550777

Epoch: 5| Step: 7
Training loss: 2.7631068229675293
Validation loss: 2.2841484969662083

Epoch: 5| Step: 8
Training loss: 2.523517608642578
Validation loss: 2.2781165107603996

Epoch: 5| Step: 9
Training loss: 2.653055429458618
Validation loss: 2.2765011723323534

Epoch: 5| Step: 10
Training loss: 2.663520097732544
Validation loss: 2.279769174514278

Epoch: 53| Step: 0
Training loss: 2.583778142929077
Validation loss: 2.2836946197735366

Epoch: 5| Step: 1
Training loss: 2.3239684104919434
Validation loss: 2.3038661326131513

Epoch: 5| Step: 2
Training loss: 2.3631865978240967
Validation loss: 2.34653579291477

Epoch: 5| Step: 3
Training loss: 3.048013210296631
Validation loss: 2.38855839801091

Epoch: 5| Step: 4
Training loss: 2.8654425144195557
Validation loss: 2.418537183474469

Epoch: 5| Step: 5
Training loss: 2.4623286724090576
Validation loss: 2.4271304671482374

Epoch: 5| Step: 6
Training loss: 2.2367141246795654
Validation loss: 2.357622964407808

Epoch: 5| Step: 7
Training loss: 3.037816047668457
Validation loss: 2.3077987855480564

Epoch: 5| Step: 8
Training loss: 2.020781993865967
Validation loss: 2.2786876924576296

Epoch: 5| Step: 9
Training loss: 2.74119234085083
Validation loss: 2.2704437522478003

Epoch: 5| Step: 10
Training loss: 2.756972312927246
Validation loss: 2.2681300922106673

Epoch: 54| Step: 0
Training loss: 2.749879837036133
Validation loss: 2.265387201821932

Epoch: 5| Step: 1
Training loss: 2.0114033222198486
Validation loss: 2.2659010092417398

Epoch: 5| Step: 2
Training loss: 3.1072630882263184
Validation loss: 2.269554720130018

Epoch: 5| Step: 3
Training loss: 2.7279491424560547
Validation loss: 2.286197631589828

Epoch: 5| Step: 4
Training loss: 2.425611972808838
Validation loss: 2.283935685311594

Epoch: 5| Step: 5
Training loss: 2.144343376159668
Validation loss: 2.2894972216698433

Epoch: 5| Step: 6
Training loss: 2.4581785202026367
Validation loss: 2.2873948466393257

Epoch: 5| Step: 7
Training loss: 3.028263568878174
Validation loss: 2.30025391937584

Epoch: 5| Step: 8
Training loss: 2.4678938388824463
Validation loss: 2.2935808474017727

Epoch: 5| Step: 9
Training loss: 2.6646504402160645
Validation loss: 2.2920614109244397

Epoch: 5| Step: 10
Training loss: 2.2838947772979736
Validation loss: 2.293897823620868

Epoch: 55| Step: 0
Training loss: 2.5219624042510986
Validation loss: 2.280067825830111

Epoch: 5| Step: 1
Training loss: 2.327570676803589
Validation loss: 2.2776451392840316

Epoch: 5| Step: 2
Training loss: 2.7246899604797363
Validation loss: 2.276235657353555

Epoch: 5| Step: 3
Training loss: 2.468564987182617
Validation loss: 2.273987316316174

Epoch: 5| Step: 4
Training loss: 2.169105052947998
Validation loss: 2.2710768176663305

Epoch: 5| Step: 5
Training loss: 2.8609633445739746
Validation loss: 2.281710893877091

Epoch: 5| Step: 6
Training loss: 2.478731632232666
Validation loss: 2.2805803821932886

Epoch: 5| Step: 7
Training loss: 2.5521206855773926
Validation loss: 2.278798214850887

Epoch: 5| Step: 8
Training loss: 2.439969539642334
Validation loss: 2.271888081745435

Epoch: 5| Step: 9
Training loss: 2.3755600452423096
Validation loss: 2.257278803856142

Epoch: 5| Step: 10
Training loss: 3.2199907302856445
Validation loss: 2.257757225344258

Epoch: 56| Step: 0
Training loss: 2.159665584564209
Validation loss: 2.2543738093427432

Epoch: 5| Step: 1
Training loss: 3.0887503623962402
Validation loss: 2.2495514526162097

Epoch: 5| Step: 2
Training loss: 2.0027120113372803
Validation loss: 2.2566386781713015

Epoch: 5| Step: 3
Training loss: 2.914854049682617
Validation loss: 2.2574619272703766

Epoch: 5| Step: 4
Training loss: 2.7949445247650146
Validation loss: 2.261785125219694

Epoch: 5| Step: 5
Training loss: 2.2117838859558105
Validation loss: 2.2568905251000517

Epoch: 5| Step: 6
Training loss: 2.4368720054626465
Validation loss: 2.2718421695052937

Epoch: 5| Step: 7
Training loss: 2.3335437774658203
Validation loss: 2.2734747163711058

Epoch: 5| Step: 8
Training loss: 2.9956796169281006
Validation loss: 2.270299037297567

Epoch: 5| Step: 9
Training loss: 2.0811381340026855
Validation loss: 2.2691669823021017

Epoch: 5| Step: 10
Training loss: 2.9903383255004883
Validation loss: 2.26709758850836

Epoch: 57| Step: 0
Training loss: 2.286858558654785
Validation loss: 2.2706471258594143

Epoch: 5| Step: 1
Training loss: 2.4189791679382324
Validation loss: 2.2860830214715775

Epoch: 5| Step: 2
Training loss: 2.291536808013916
Validation loss: 2.29120607273553

Epoch: 5| Step: 3
Training loss: 2.47031569480896
Validation loss: 2.2907473541075185

Epoch: 5| Step: 4
Training loss: 3.121490955352783
Validation loss: 2.2914600372314453

Epoch: 5| Step: 5
Training loss: 2.2777984142303467
Validation loss: 2.2835630601452244

Epoch: 5| Step: 6
Training loss: 2.530022144317627
Validation loss: 2.281363459043605

Epoch: 5| Step: 7
Training loss: 2.4999401569366455
Validation loss: 2.2473259305441253

Epoch: 5| Step: 8
Training loss: 3.014101028442383
Validation loss: 2.2455857312807472

Epoch: 5| Step: 9
Training loss: 2.106956958770752
Validation loss: 2.2380211558393253

Epoch: 5| Step: 10
Training loss: 2.898970365524292
Validation loss: 2.2320855996942006

Epoch: 58| Step: 0
Training loss: 2.4810690879821777
Validation loss: 2.236520013501567

Epoch: 5| Step: 1
Training loss: 2.377194881439209
Validation loss: 2.235763698495844

Epoch: 5| Step: 2
Training loss: 2.708383798599243
Validation loss: 2.236980847133103

Epoch: 5| Step: 3
Training loss: 2.1293253898620605
Validation loss: 2.236417096148255

Epoch: 5| Step: 4
Training loss: 2.57517147064209
Validation loss: 2.2412191770410024

Epoch: 5| Step: 5
Training loss: 3.0581283569335938
Validation loss: 2.2463449739640757

Epoch: 5| Step: 6
Training loss: 2.8101353645324707
Validation loss: 2.2562564290979856

Epoch: 5| Step: 7
Training loss: 2.4136040210723877
Validation loss: 2.2688571381312546

Epoch: 5| Step: 8
Training loss: 3.0054879188537598
Validation loss: 2.2895179102497716

Epoch: 5| Step: 9
Training loss: 2.4656407833099365
Validation loss: 2.3121692416488484

Epoch: 5| Step: 10
Training loss: 2.0117716789245605
Validation loss: 2.345601643285444

Epoch: 59| Step: 0
Training loss: 2.1479785442352295
Validation loss: 2.2900633286404353

Epoch: 5| Step: 1
Training loss: 2.412374973297119
Validation loss: 2.253034102019443

Epoch: 5| Step: 2
Training loss: 2.6821861267089844
Validation loss: 2.232302664428629

Epoch: 5| Step: 3
Training loss: 2.214207172393799
Validation loss: 2.234251429957728

Epoch: 5| Step: 4
Training loss: 2.9976274967193604
Validation loss: 2.23686126483384

Epoch: 5| Step: 5
Training loss: 2.6666927337646484
Validation loss: 2.2281835515012025

Epoch: 5| Step: 6
Training loss: 2.2208609580993652
Validation loss: 2.2277920117942234

Epoch: 5| Step: 7
Training loss: 2.756132125854492
Validation loss: 2.2230355739593506

Epoch: 5| Step: 8
Training loss: 2.5174193382263184
Validation loss: 2.236357540212652

Epoch: 5| Step: 9
Training loss: 2.948035717010498
Validation loss: 2.245678215898493

Epoch: 5| Step: 10
Training loss: 2.408184289932251
Validation loss: 2.278904668746456

Epoch: 60| Step: 0
Training loss: 3.0840861797332764
Validation loss: 2.2910765704288276

Epoch: 5| Step: 1
Training loss: 2.3290133476257324
Validation loss: 2.271025514089933

Epoch: 5| Step: 2
Training loss: 1.8515249490737915
Validation loss: 2.2367046340819328

Epoch: 5| Step: 3
Training loss: 2.706958770751953
Validation loss: 2.236419067587904

Epoch: 5| Step: 4
Training loss: 2.631716251373291
Validation loss: 2.249196026914863

Epoch: 5| Step: 5
Training loss: 3.151273488998413
Validation loss: 2.250110523675078

Epoch: 5| Step: 6
Training loss: 2.3749735355377197
Validation loss: 2.2610722267499535

Epoch: 5| Step: 7
Training loss: 2.052130699157715
Validation loss: 2.2515065131648893

Epoch: 5| Step: 8
Training loss: 1.9695965051651
Validation loss: 2.2446856511536466

Epoch: 5| Step: 9
Training loss: 2.7685282230377197
Validation loss: 2.2534547441749164

Epoch: 5| Step: 10
Training loss: 2.9627647399902344
Validation loss: 2.2745775766270135

Epoch: 61| Step: 0
Training loss: 1.9585816860198975
Validation loss: 2.272155546372937

Epoch: 5| Step: 1
Training loss: 2.720005750656128
Validation loss: 2.2809511948657293

Epoch: 5| Step: 2
Training loss: 2.530627727508545
Validation loss: 2.2687750939399964

Epoch: 5| Step: 3
Training loss: 2.6382687091827393
Validation loss: 2.279208672943936

Epoch: 5| Step: 4
Training loss: 2.4344465732574463
Validation loss: 2.2913613729579474

Epoch: 5| Step: 5
Training loss: 2.3605823516845703
Validation loss: 2.242245151150611

Epoch: 5| Step: 6
Training loss: 2.5726218223571777
Validation loss: 2.2237973700287523

Epoch: 5| Step: 7
Training loss: 2.535940170288086
Validation loss: 2.216537910123025

Epoch: 5| Step: 8
Training loss: 2.123683214187622
Validation loss: 2.218207727196396

Epoch: 5| Step: 9
Training loss: 3.240617275238037
Validation loss: 2.21672777078485

Epoch: 5| Step: 10
Training loss: 2.8620645999908447
Validation loss: 2.218302680600074

Epoch: 62| Step: 0
Training loss: 2.0411059856414795
Validation loss: 2.2120818438068515

Epoch: 5| Step: 1
Training loss: 3.2218101024627686
Validation loss: 2.2167478569092287

Epoch: 5| Step: 2
Training loss: 2.7509677410125732
Validation loss: 2.2222437217671382

Epoch: 5| Step: 3
Training loss: 2.4086380004882812
Validation loss: 2.254280441550798

Epoch: 5| Step: 4
Training loss: 2.151731491088867
Validation loss: 2.309708172275174

Epoch: 5| Step: 5
Training loss: 2.8061439990997314
Validation loss: 2.34095585730768

Epoch: 5| Step: 6
Training loss: 2.4490058422088623
Validation loss: 2.3443886080095844

Epoch: 5| Step: 7
Training loss: 2.362727642059326
Validation loss: 2.3795587324327037

Epoch: 5| Step: 8
Training loss: 2.5027403831481934
Validation loss: 2.3688181933536323

Epoch: 5| Step: 9
Training loss: 2.4747838973999023
Validation loss: 2.3526048147550194

Epoch: 5| Step: 10
Training loss: 2.7474076747894287
Validation loss: 2.3270046377694733

Epoch: 63| Step: 0
Training loss: 2.96528697013855
Validation loss: 2.293710021562474

Epoch: 5| Step: 1
Training loss: 2.8936517238616943
Validation loss: 2.2855679553042174

Epoch: 5| Step: 2
Training loss: 2.5497612953186035
Validation loss: 2.254536190340596

Epoch: 5| Step: 3
Training loss: 2.166720151901245
Validation loss: 2.2257599292262906

Epoch: 5| Step: 4
Training loss: 2.5753378868103027
Validation loss: 2.2099681977302796

Epoch: 5| Step: 5
Training loss: 2.493075132369995
Validation loss: 2.206561910208835

Epoch: 5| Step: 6
Training loss: 2.4939897060394287
Validation loss: 2.206142594737391

Epoch: 5| Step: 7
Training loss: 2.4748988151550293
Validation loss: 2.193617777157855

Epoch: 5| Step: 8
Training loss: 2.150076150894165
Validation loss: 2.1951649291540987

Epoch: 5| Step: 9
Training loss: 1.8562034368515015
Validation loss: 2.1935920369240547

Epoch: 5| Step: 10
Training loss: 3.4466991424560547
Validation loss: 2.1949940842966877

Epoch: 64| Step: 0
Training loss: 2.851064682006836
Validation loss: 2.1979551853672152

Epoch: 5| Step: 1
Training loss: 2.3955535888671875
Validation loss: 2.2039972889807915

Epoch: 5| Step: 2
Training loss: 2.5835490226745605
Validation loss: 2.2336505433564544

Epoch: 5| Step: 3
Training loss: 2.8152012825012207
Validation loss: 2.2934323946634927

Epoch: 5| Step: 4
Training loss: 2.6250462532043457
Validation loss: 2.2735033983825357

Epoch: 5| Step: 5
Training loss: 2.160612106323242
Validation loss: 2.2277797524647047

Epoch: 5| Step: 6
Training loss: 2.2278828620910645
Validation loss: 2.1989730981088456

Epoch: 5| Step: 7
Training loss: 2.1231188774108887
Validation loss: 2.191249906375844

Epoch: 5| Step: 8
Training loss: 2.3276047706604004
Validation loss: 2.1989455876811856

Epoch: 5| Step: 9
Training loss: 2.651632785797119
Validation loss: 2.278424637292021

Epoch: 5| Step: 10
Training loss: 3.2337534427642822
Validation loss: 2.3647810515537055

Epoch: 65| Step: 0
Training loss: 2.2822718620300293
Validation loss: 2.3916078459831978

Epoch: 5| Step: 1
Training loss: 1.7965869903564453
Validation loss: 2.379300596893475

Epoch: 5| Step: 2
Training loss: 2.975381851196289
Validation loss: 2.300286977521835

Epoch: 5| Step: 3
Training loss: 3.2723755836486816
Validation loss: 2.2225842052890408

Epoch: 5| Step: 4
Training loss: 2.3216304779052734
Validation loss: 2.1941186407560944

Epoch: 5| Step: 5
Training loss: 2.8145384788513184
Validation loss: 2.195639625672371

Epoch: 5| Step: 6
Training loss: 2.6769490242004395
Validation loss: 2.191956612371629

Epoch: 5| Step: 7
Training loss: 2.4610700607299805
Validation loss: 2.186296970613541

Epoch: 5| Step: 8
Training loss: 2.7121455669403076
Validation loss: 2.1811062007822017

Epoch: 5| Step: 9
Training loss: 2.5215232372283936
Validation loss: 2.1773784288796048

Epoch: 5| Step: 10
Training loss: 2.081838607788086
Validation loss: 2.174573279196216

Epoch: 66| Step: 0
Training loss: 3.17333722114563
Validation loss: 2.174987293058826

Epoch: 5| Step: 1
Training loss: 2.2189242839813232
Validation loss: 2.186194996679983

Epoch: 5| Step: 2
Training loss: 2.3377845287323
Validation loss: 2.2094154742456253

Epoch: 5| Step: 3
Training loss: 2.583831787109375
Validation loss: 2.2163416736869404

Epoch: 5| Step: 4
Training loss: 1.5195778608322144
Validation loss: 2.2127163076913483

Epoch: 5| Step: 5
Training loss: 2.426431894302368
Validation loss: 2.22462454406164

Epoch: 5| Step: 6
Training loss: 2.964641809463501
Validation loss: 2.213583097662977

Epoch: 5| Step: 7
Training loss: 3.2544467449188232
Validation loss: 2.2025303840637207

Epoch: 5| Step: 8
Training loss: 2.4469447135925293
Validation loss: 2.189586308694655

Epoch: 5| Step: 9
Training loss: 2.6520190238952637
Validation loss: 2.1875159202083463

Epoch: 5| Step: 10
Training loss: 1.912099003791809
Validation loss: 2.1925731217989357

Epoch: 67| Step: 0
Training loss: 2.3663108348846436
Validation loss: 2.186520940514021

Epoch: 5| Step: 1
Training loss: 2.436483860015869
Validation loss: 2.1874074243730113

Epoch: 5| Step: 2
Training loss: 2.450610637664795
Validation loss: 2.185616165079096

Epoch: 5| Step: 3
Training loss: 2.785914897918701
Validation loss: 2.1865882796625935

Epoch: 5| Step: 4
Training loss: 2.5182740688323975
Validation loss: 2.1955011352416007

Epoch: 5| Step: 5
Training loss: 2.612377643585205
Validation loss: 2.1909803985267557

Epoch: 5| Step: 6
Training loss: 1.6063820123672485
Validation loss: 2.190182388469737

Epoch: 5| Step: 7
Training loss: 3.109708786010742
Validation loss: 2.2024469913974887

Epoch: 5| Step: 8
Training loss: 2.811906337738037
Validation loss: 2.194172546427737

Epoch: 5| Step: 9
Training loss: 2.432163953781128
Validation loss: 2.200783129661314

Epoch: 5| Step: 10
Training loss: 2.2924067974090576
Validation loss: 2.208085754866241

Epoch: 68| Step: 0
Training loss: 2.2934975624084473
Validation loss: 2.2310619995158207

Epoch: 5| Step: 1
Training loss: 2.4279894828796387
Validation loss: 2.2475557891271447

Epoch: 5| Step: 2
Training loss: 1.9740054607391357
Validation loss: 2.2886714781484296

Epoch: 5| Step: 3
Training loss: 2.656447172164917
Validation loss: 2.304325706215315

Epoch: 5| Step: 4
Training loss: 2.7585558891296387
Validation loss: 2.2777341078686457

Epoch: 5| Step: 5
Training loss: 2.935588836669922
Validation loss: 2.2255757239557084

Epoch: 5| Step: 6
Training loss: 1.9853007793426514
Validation loss: 2.201514951644405

Epoch: 5| Step: 7
Training loss: 2.1904966831207275
Validation loss: 2.195905316260553

Epoch: 5| Step: 8
Training loss: 2.9214470386505127
Validation loss: 2.1912948476370944

Epoch: 5| Step: 9
Training loss: 3.2927944660186768
Validation loss: 2.1874763670788018

Epoch: 5| Step: 10
Training loss: 1.8801389932632446
Validation loss: 2.1775367118979014

Epoch: 69| Step: 0
Training loss: 2.1139028072357178
Validation loss: 2.1779961265543455

Epoch: 5| Step: 1
Training loss: 2.3803067207336426
Validation loss: 2.177717479326392

Epoch: 5| Step: 2
Training loss: 2.890727996826172
Validation loss: 2.17214269920062

Epoch: 5| Step: 3
Training loss: 2.935356616973877
Validation loss: 2.1786472541029736

Epoch: 5| Step: 4
Training loss: 1.9925493001937866
Validation loss: 2.172236232347386

Epoch: 5| Step: 5
Training loss: 2.577542781829834
Validation loss: 2.1753856071861843

Epoch: 5| Step: 6
Training loss: 2.703146457672119
Validation loss: 2.1774359646663872

Epoch: 5| Step: 7
Training loss: 2.761009693145752
Validation loss: 2.1874520124927646

Epoch: 5| Step: 8
Training loss: 2.137329578399658
Validation loss: 2.208193471354823

Epoch: 5| Step: 9
Training loss: 2.4716129302978516
Validation loss: 2.2375088276401645

Epoch: 5| Step: 10
Training loss: 2.5387675762176514
Validation loss: 2.2358044911456365

Epoch: 70| Step: 0
Training loss: 2.7446913719177246
Validation loss: 2.2164952024336784

Epoch: 5| Step: 1
Training loss: 1.968369483947754
Validation loss: 2.1787421472610964

Epoch: 5| Step: 2
Training loss: 2.1582183837890625
Validation loss: 2.169563352420766

Epoch: 5| Step: 3
Training loss: 2.243558406829834
Validation loss: 2.1561067796522573

Epoch: 5| Step: 4
Training loss: 2.3733720779418945
Validation loss: 2.163129711663851

Epoch: 5| Step: 5
Training loss: 3.0407514572143555
Validation loss: 2.164994044970441

Epoch: 5| Step: 6
Training loss: 2.8735263347625732
Validation loss: 2.1690988950831915

Epoch: 5| Step: 7
Training loss: 2.1882379055023193
Validation loss: 2.178795419713502

Epoch: 5| Step: 8
Training loss: 1.9491453170776367
Validation loss: 2.186282311716387

Epoch: 5| Step: 9
Training loss: 2.7885451316833496
Validation loss: 2.2016543931858514

Epoch: 5| Step: 10
Training loss: 3.138495922088623
Validation loss: 2.2138160941421345

Epoch: 71| Step: 0
Training loss: 2.926330089569092
Validation loss: 2.229241491645895

Epoch: 5| Step: 1
Training loss: 2.4795660972595215
Validation loss: 2.2529909662021104

Epoch: 5| Step: 2
Training loss: 2.2331504821777344
Validation loss: 2.2289524411642425

Epoch: 5| Step: 3
Training loss: 2.3706624507904053
Validation loss: 2.2066225659462715

Epoch: 5| Step: 4
Training loss: 2.4706196784973145
Validation loss: 2.1919678667540192

Epoch: 5| Step: 5
Training loss: 2.4252829551696777
Validation loss: 2.180927348393266

Epoch: 5| Step: 6
Training loss: 2.3721137046813965
Validation loss: 2.1792591207770893

Epoch: 5| Step: 7
Training loss: 2.4781908988952637
Validation loss: 2.1641585493600495

Epoch: 5| Step: 8
Training loss: 3.0835773944854736
Validation loss: 2.1649651911950882

Epoch: 5| Step: 9
Training loss: 2.4848008155822754
Validation loss: 2.1556779210285475

Epoch: 5| Step: 10
Training loss: 1.9295306205749512
Validation loss: 2.1603546116941716

Epoch: 72| Step: 0
Training loss: 2.5582218170166016
Validation loss: 2.170364237600757

Epoch: 5| Step: 1
Training loss: 2.220968246459961
Validation loss: 2.1897157520376225

Epoch: 5| Step: 2
Training loss: 2.2740426063537598
Validation loss: 2.212288974433817

Epoch: 5| Step: 3
Training loss: 2.5378875732421875
Validation loss: 2.292217554584626

Epoch: 5| Step: 4
Training loss: 1.8506746292114258
Validation loss: 2.371717699112431

Epoch: 5| Step: 5
Training loss: 2.5390689373016357
Validation loss: 2.396378437678019

Epoch: 5| Step: 6
Training loss: 3.0996930599212646
Validation loss: 2.3582727909088135

Epoch: 5| Step: 7
Training loss: 2.3846585750579834
Validation loss: 2.231204645608061

Epoch: 5| Step: 8
Training loss: 2.802982807159424
Validation loss: 2.1713290214538574

Epoch: 5| Step: 9
Training loss: 2.613948345184326
Validation loss: 2.1616783629181566

Epoch: 5| Step: 10
Training loss: 2.9188711643218994
Validation loss: 2.1533970896915724

Epoch: 73| Step: 0
Training loss: 2.756946086883545
Validation loss: 2.1574752920417377

Epoch: 5| Step: 1
Training loss: 2.422438144683838
Validation loss: 2.154357942201758

Epoch: 5| Step: 2
Training loss: 1.952256441116333
Validation loss: 2.153728199261491

Epoch: 5| Step: 3
Training loss: 2.702684164047241
Validation loss: 2.1524531020913074

Epoch: 5| Step: 4
Training loss: 3.275031566619873
Validation loss: 2.155118467987225

Epoch: 5| Step: 5
Training loss: 2.254033088684082
Validation loss: 2.1601606338254866

Epoch: 5| Step: 6
Training loss: 2.4376015663146973
Validation loss: 2.162183610341882

Epoch: 5| Step: 7
Training loss: 2.0929055213928223
Validation loss: 2.173994779586792

Epoch: 5| Step: 8
Training loss: 1.710179090499878
Validation loss: 2.1975221390365274

Epoch: 5| Step: 9
Training loss: 2.7843360900878906
Validation loss: 2.230550119953771

Epoch: 5| Step: 10
Training loss: 3.195310354232788
Validation loss: 2.227657982098159

Epoch: 74| Step: 0
Training loss: 2.0838444232940674
Validation loss: 2.2210192065085135

Epoch: 5| Step: 1
Training loss: 2.041093111038208
Validation loss: 2.219587354249852

Epoch: 5| Step: 2
Training loss: 3.358165740966797
Validation loss: 2.226392638298773

Epoch: 5| Step: 3
Training loss: 2.647761821746826
Validation loss: 2.2127031408330446

Epoch: 5| Step: 4
Training loss: 2.7342324256896973
Validation loss: 2.193912366385101

Epoch: 5| Step: 5
Training loss: 2.869804859161377
Validation loss: 2.1794680895343905

Epoch: 5| Step: 6
Training loss: 2.5716023445129395
Validation loss: 2.1507177839996996

Epoch: 5| Step: 7
Training loss: 2.0945568084716797
Validation loss: 2.1360615966140584

Epoch: 5| Step: 8
Training loss: 1.817987084388733
Validation loss: 2.1350056676454443

Epoch: 5| Step: 9
Training loss: 2.6973769664764404
Validation loss: 2.1315676832711823

Epoch: 5| Step: 10
Training loss: 2.3669562339782715
Validation loss: 2.134578656124812

Epoch: 75| Step: 0
Training loss: 2.4667398929595947
Validation loss: 2.1367620165630052

Epoch: 5| Step: 1
Training loss: 2.4261107444763184
Validation loss: 2.1371013015829106

Epoch: 5| Step: 2
Training loss: 2.5816612243652344
Validation loss: 2.135901701065802

Epoch: 5| Step: 3
Training loss: 2.568655252456665
Validation loss: 2.14655129883879

Epoch: 5| Step: 4
Training loss: 2.698607921600342
Validation loss: 2.148168206214905

Epoch: 5| Step: 5
Training loss: 2.3694136142730713
Validation loss: 2.1448331520121586

Epoch: 5| Step: 6
Training loss: 2.9121527671813965
Validation loss: 2.149896219212522

Epoch: 5| Step: 7
Training loss: 2.326157808303833
Validation loss: 2.146153643567075

Epoch: 5| Step: 8
Training loss: 2.308676242828369
Validation loss: 2.156700021477156

Epoch: 5| Step: 9
Training loss: 2.337718963623047
Validation loss: 2.1592220516615015

Epoch: 5| Step: 10
Training loss: 2.0341596603393555
Validation loss: 2.164390763928813

Epoch: 76| Step: 0
Training loss: 2.427964448928833
Validation loss: 2.184522280129053

Epoch: 5| Step: 1
Training loss: 2.6098358631134033
Validation loss: 2.2386118673509166

Epoch: 5| Step: 2
Training loss: 2.137977361679077
Validation loss: 2.2840817436095207

Epoch: 5| Step: 3
Training loss: 2.6514482498168945
Validation loss: 2.3031310086609214

Epoch: 5| Step: 4
Training loss: 2.8098912239074707
Validation loss: 2.2667291625853507

Epoch: 5| Step: 5
Training loss: 2.903630495071411
Validation loss: 2.231943277902501

Epoch: 5| Step: 6
Training loss: 2.443085193634033
Validation loss: 2.1928282373694965

Epoch: 5| Step: 7
Training loss: 1.9159942865371704
Validation loss: 2.1826904114856513

Epoch: 5| Step: 8
Training loss: 2.5820376873016357
Validation loss: 2.1578916785537556

Epoch: 5| Step: 9
Training loss: 2.477263927459717
Validation loss: 2.1473998856800858

Epoch: 5| Step: 10
Training loss: 2.580720901489258
Validation loss: 2.1479823486779326

Epoch: 77| Step: 0
Training loss: 2.5047800540924072
Validation loss: 2.1370991558156986

Epoch: 5| Step: 1
Training loss: 2.375145435333252
Validation loss: 2.132912337139089

Epoch: 5| Step: 2
Training loss: 2.0222296714782715
Validation loss: 2.1274106887079056

Epoch: 5| Step: 3
Training loss: 2.732468843460083
Validation loss: 2.1436128334332536

Epoch: 5| Step: 4
Training loss: 2.5670454502105713
Validation loss: 2.1651368910266506

Epoch: 5| Step: 5
Training loss: 2.3058295249938965
Validation loss: 2.195309779977286

Epoch: 5| Step: 6
Training loss: 2.4668946266174316
Validation loss: 2.2268743438105427

Epoch: 5| Step: 7
Training loss: 2.915487766265869
Validation loss: 2.233381591817384

Epoch: 5| Step: 8
Training loss: 2.536813259124756
Validation loss: 2.2551276055715417

Epoch: 5| Step: 9
Training loss: 2.2656564712524414
Validation loss: 2.25073137334598

Epoch: 5| Step: 10
Training loss: 2.586981773376465
Validation loss: 2.213479289444544

Epoch: 78| Step: 0
Training loss: 2.017469644546509
Validation loss: 2.209137124399985

Epoch: 5| Step: 1
Training loss: 2.3982226848602295
Validation loss: 2.2258144629898893

Epoch: 5| Step: 2
Training loss: 2.487039089202881
Validation loss: 2.2015306898342666

Epoch: 5| Step: 3
Training loss: 2.698256254196167
Validation loss: 2.177849623464769

Epoch: 5| Step: 4
Training loss: 2.1866750717163086
Validation loss: 2.1824847652066137

Epoch: 5| Step: 5
Training loss: 1.9952075481414795
Validation loss: 2.209090899395686

Epoch: 5| Step: 6
Training loss: 2.2079038619995117
Validation loss: 2.253122427130258

Epoch: 5| Step: 7
Training loss: 3.3588976860046387
Validation loss: 2.266482107100948

Epoch: 5| Step: 8
Training loss: 2.7421011924743652
Validation loss: 2.2498681058165846

Epoch: 5| Step: 9
Training loss: 2.816277027130127
Validation loss: 2.22359723173162

Epoch: 5| Step: 10
Training loss: 2.456331729888916
Validation loss: 2.187608713744789

Epoch: 79| Step: 0
Training loss: 2.777498722076416
Validation loss: 2.182801554279943

Epoch: 5| Step: 1
Training loss: 2.29152512550354
Validation loss: 2.176081967610185

Epoch: 5| Step: 2
Training loss: 2.508784770965576
Validation loss: 2.1681523425604707

Epoch: 5| Step: 3
Training loss: 2.504669427871704
Validation loss: 2.1576981134312128

Epoch: 5| Step: 4
Training loss: 2.32753324508667
Validation loss: 2.1523004424187446

Epoch: 5| Step: 5
Training loss: 2.6844468116760254
Validation loss: 2.1432533187250935

Epoch: 5| Step: 6
Training loss: 2.659015417098999
Validation loss: 2.1310445480449225

Epoch: 5| Step: 7
Training loss: 2.7373147010803223
Validation loss: 2.1196344360228507

Epoch: 5| Step: 8
Training loss: 2.60237193107605
Validation loss: 2.121373766212053

Epoch: 5| Step: 9
Training loss: 1.9010889530181885
Validation loss: 2.1288693566476145

Epoch: 5| Step: 10
Training loss: 2.2790300846099854
Validation loss: 2.132300171800839

Epoch: 80| Step: 0
Training loss: 2.404149293899536
Validation loss: 2.1370898754365983

Epoch: 5| Step: 1
Training loss: 2.326399326324463
Validation loss: 2.1567172619604293

Epoch: 5| Step: 2
Training loss: 2.353102207183838
Validation loss: 2.168815238501436

Epoch: 5| Step: 3
Training loss: 2.0857813358306885
Validation loss: 2.177859401190153

Epoch: 5| Step: 4
Training loss: 2.1874892711639404
Validation loss: 2.1730808032456266

Epoch: 5| Step: 5
Training loss: 2.445425271987915
Validation loss: 2.1777970649862803

Epoch: 5| Step: 6
Training loss: 2.939324140548706
Validation loss: 2.1683208609140046

Epoch: 5| Step: 7
Training loss: 2.5497632026672363
Validation loss: 2.158590341127047

Epoch: 5| Step: 8
Training loss: 2.4044880867004395
Validation loss: 2.147141828331896

Epoch: 5| Step: 9
Training loss: 2.462381362915039
Validation loss: 2.1296396332402385

Epoch: 5| Step: 10
Training loss: 2.8342301845550537
Validation loss: 2.1168183383121284

Epoch: 81| Step: 0
Training loss: 2.056403636932373
Validation loss: 2.1152030370568715

Epoch: 5| Step: 1
Training loss: 2.442016124725342
Validation loss: 2.117459020306987

Epoch: 5| Step: 2
Training loss: 3.1260101795196533
Validation loss: 2.1136691134463073

Epoch: 5| Step: 3
Training loss: 3.1155612468719482
Validation loss: 2.1170927068238616

Epoch: 5| Step: 4
Training loss: 2.490494966506958
Validation loss: 2.116175143949447

Epoch: 5| Step: 5
Training loss: 2.108819007873535
Validation loss: 2.1144048936905397

Epoch: 5| Step: 6
Training loss: 2.51690411567688
Validation loss: 2.1287447611490884

Epoch: 5| Step: 7
Training loss: 2.730684757232666
Validation loss: 2.1574385986533215

Epoch: 5| Step: 8
Training loss: 2.2106029987335205
Validation loss: 2.166436602992396

Epoch: 5| Step: 9
Training loss: 1.8137305974960327
Validation loss: 2.1746600135680167

Epoch: 5| Step: 10
Training loss: 2.3223161697387695
Validation loss: 2.1807432123409805

Epoch: 82| Step: 0
Training loss: 2.3279550075531006
Validation loss: 2.184698094603836

Epoch: 5| Step: 1
Training loss: 2.504011392593384
Validation loss: 2.1941727463917067

Epoch: 5| Step: 2
Training loss: 2.7802977561950684
Validation loss: 2.1801364319298857

Epoch: 5| Step: 3
Training loss: 2.4181885719299316
Validation loss: 2.1757247191603466

Epoch: 5| Step: 4
Training loss: 2.1817924976348877
Validation loss: 2.1761180508521294

Epoch: 5| Step: 5
Training loss: 2.0039069652557373
Validation loss: 2.1732586814511206

Epoch: 5| Step: 6
Training loss: 2.9551842212677
Validation loss: 2.166933162238008

Epoch: 5| Step: 7
Training loss: 2.808581829071045
Validation loss: 2.1616389623252292

Epoch: 5| Step: 8
Training loss: 1.7480064630508423
Validation loss: 2.147165475353118

Epoch: 5| Step: 9
Training loss: 2.613229513168335
Validation loss: 2.131448818791297

Epoch: 5| Step: 10
Training loss: 2.5478663444519043
Validation loss: 2.1289046105518135

Epoch: 83| Step: 0
Training loss: 3.214531660079956
Validation loss: 2.121037240951292

Epoch: 5| Step: 1
Training loss: 2.175554037094116
Validation loss: 2.11020932146298

Epoch: 5| Step: 2
Training loss: 2.7166523933410645
Validation loss: 2.1016452120196436

Epoch: 5| Step: 3
Training loss: 2.6695213317871094
Validation loss: 2.1025866308519916

Epoch: 5| Step: 4
Training loss: 2.10845947265625
Validation loss: 2.1088137049828806

Epoch: 5| Step: 5
Training loss: 2.8618268966674805
Validation loss: 2.1020722799403693

Epoch: 5| Step: 6
Training loss: 2.0084800720214844
Validation loss: 2.0976563371637815

Epoch: 5| Step: 7
Training loss: 2.4054760932922363
Validation loss: 2.110593752194476

Epoch: 5| Step: 8
Training loss: 2.584210157394409
Validation loss: 2.1360118055856354

Epoch: 5| Step: 9
Training loss: 2.5901005268096924
Validation loss: 2.1386888514282885

Epoch: 5| Step: 10
Training loss: 1.4242825508117676
Validation loss: 2.146036712072229

Epoch: 84| Step: 0
Training loss: 2.2624142169952393
Validation loss: 2.1618591021466

Epoch: 5| Step: 1
Training loss: 2.824751615524292
Validation loss: 2.1831592244486653

Epoch: 5| Step: 2
Training loss: 2.048642635345459
Validation loss: 2.192586052802301

Epoch: 5| Step: 3
Training loss: 2.7336559295654297
Validation loss: 2.184800076228316

Epoch: 5| Step: 4
Training loss: 2.1162452697753906
Validation loss: 2.196365746118689

Epoch: 5| Step: 5
Training loss: 2.6460251808166504
Validation loss: 2.1664617574343117

Epoch: 5| Step: 6
Training loss: 2.378896951675415
Validation loss: 2.1202913266356274

Epoch: 5| Step: 7
Training loss: 2.318903923034668
Validation loss: 2.0837883590370097

Epoch: 5| Step: 8
Training loss: 2.764047861099243
Validation loss: 2.0782612395542923

Epoch: 5| Step: 9
Training loss: 2.3859965801239014
Validation loss: 2.0770851873582408

Epoch: 5| Step: 10
Training loss: 2.2976608276367188
Validation loss: 2.079562299995012

Epoch: 85| Step: 0
Training loss: 2.773206949234009
Validation loss: 2.0781674936253536

Epoch: 5| Step: 1
Training loss: 2.292677402496338
Validation loss: 2.081509538876113

Epoch: 5| Step: 2
Training loss: 2.7215542793273926
Validation loss: 2.0929866144734044

Epoch: 5| Step: 3
Training loss: 2.7047386169433594
Validation loss: 2.102779439700547

Epoch: 5| Step: 4
Training loss: 2.13102388381958
Validation loss: 2.115915295898273

Epoch: 5| Step: 5
Training loss: 2.4745335578918457
Validation loss: 2.112698471674355

Epoch: 5| Step: 6
Training loss: 2.66109299659729
Validation loss: 2.1154636849639235

Epoch: 5| Step: 7
Training loss: 2.3503684997558594
Validation loss: 2.1092011031284126

Epoch: 5| Step: 8
Training loss: 2.5536322593688965
Validation loss: 2.1059683651052494

Epoch: 5| Step: 9
Training loss: 1.9961076974868774
Validation loss: 2.1286987322632984

Epoch: 5| Step: 10
Training loss: 2.0775532722473145
Validation loss: 2.141305169751567

Epoch: 86| Step: 0
Training loss: 2.284123182296753
Validation loss: 2.14002021538314

Epoch: 5| Step: 1
Training loss: 1.9421762228012085
Validation loss: 2.134475669553203

Epoch: 5| Step: 2
Training loss: 2.851971387863159
Validation loss: 2.1229930257284515

Epoch: 5| Step: 3
Training loss: 2.679309129714966
Validation loss: 2.0972672611154537

Epoch: 5| Step: 4
Training loss: 2.374701499938965
Validation loss: 2.0871947311585948

Epoch: 5| Step: 5
Training loss: 2.098749876022339
Validation loss: 2.0904154136616695

Epoch: 5| Step: 6
Training loss: 2.265761613845825
Validation loss: 2.0890314835374073

Epoch: 5| Step: 7
Training loss: 2.6380181312561035
Validation loss: 2.0912146222206855

Epoch: 5| Step: 8
Training loss: 3.139294385910034
Validation loss: 2.110566876267874

Epoch: 5| Step: 9
Training loss: 2.148062229156494
Validation loss: 2.134898849712905

Epoch: 5| Step: 10
Training loss: 2.1922595500946045
Validation loss: 2.15185696078885

Epoch: 87| Step: 0
Training loss: 2.778944730758667
Validation loss: 2.1561596624312864

Epoch: 5| Step: 1
Training loss: 2.093303680419922
Validation loss: 2.1324146793734644

Epoch: 5| Step: 2
Training loss: 2.500483989715576
Validation loss: 2.1281826521760676

Epoch: 5| Step: 3
Training loss: 2.8798301219940186
Validation loss: 2.128369931251772

Epoch: 5| Step: 4
Training loss: 2.1693975925445557
Validation loss: 2.1064252443211053

Epoch: 5| Step: 5
Training loss: 1.8349130153656006
Validation loss: 2.108124110006517

Epoch: 5| Step: 6
Training loss: 2.664806842803955
Validation loss: 2.0751748866932367

Epoch: 5| Step: 7
Training loss: 2.2550137042999268
Validation loss: 2.080651101245675

Epoch: 5| Step: 8
Training loss: 2.763371706008911
Validation loss: 2.0779613115454234

Epoch: 5| Step: 9
Training loss: 2.512664318084717
Validation loss: 2.079546651532573

Epoch: 5| Step: 10
Training loss: 2.1324546337127686
Validation loss: 2.079052679000362

Epoch: 88| Step: 0
Training loss: 2.7074596881866455
Validation loss: 2.0895817510543333

Epoch: 5| Step: 1
Training loss: 1.8397926092147827
Validation loss: 2.0937316238239245

Epoch: 5| Step: 2
Training loss: 2.8268656730651855
Validation loss: 2.0923325387380456

Epoch: 5| Step: 3
Training loss: 2.553807020187378
Validation loss: 2.0922410565037883

Epoch: 5| Step: 4
Training loss: 2.280311107635498
Validation loss: 2.077623595473587

Epoch: 5| Step: 5
Training loss: 2.6432106494903564
Validation loss: 2.0752727882836455

Epoch: 5| Step: 6
Training loss: 2.4565412998199463
Validation loss: 2.0782261022957425

Epoch: 5| Step: 7
Training loss: 2.1412341594696045
Validation loss: 2.0759014673130487

Epoch: 5| Step: 8
Training loss: 2.6002891063690186
Validation loss: 2.0841137734792565

Epoch: 5| Step: 9
Training loss: 2.428534746170044
Validation loss: 2.1005402380420315

Epoch: 5| Step: 10
Training loss: 2.0830888748168945
Validation loss: 2.10864774129724

Epoch: 89| Step: 0
Training loss: 1.8241980075836182
Validation loss: 2.1209089166374615

Epoch: 5| Step: 1
Training loss: 1.5618022680282593
Validation loss: 2.122257391611735

Epoch: 5| Step: 2
Training loss: 2.737616777420044
Validation loss: 2.1349285494896675

Epoch: 5| Step: 3
Training loss: 2.6769728660583496
Validation loss: 2.158450062556933

Epoch: 5| Step: 4
Training loss: 2.7057342529296875
Validation loss: 2.149163343573129

Epoch: 5| Step: 5
Training loss: 2.9312872886657715
Validation loss: 2.143693506076772

Epoch: 5| Step: 6
Training loss: 2.2432286739349365
Validation loss: 2.1027074244714554

Epoch: 5| Step: 7
Training loss: 2.2612338066101074
Validation loss: 2.05805217835211

Epoch: 5| Step: 8
Training loss: 2.3675272464752197
Validation loss: 2.048521004697328

Epoch: 5| Step: 9
Training loss: 2.8584697246551514
Validation loss: 2.0514613325877855

Epoch: 5| Step: 10
Training loss: 2.647653818130493
Validation loss: 2.056366797416441

Epoch: 90| Step: 0
Training loss: 2.5101823806762695
Validation loss: 2.0559171438217163

Epoch: 5| Step: 1
Training loss: 2.7774817943573
Validation loss: 2.056356559517563

Epoch: 5| Step: 2
Training loss: 1.78948974609375
Validation loss: 2.0560265023221254

Epoch: 5| Step: 3
Training loss: 2.4418482780456543
Validation loss: 2.0626528122091807

Epoch: 5| Step: 4
Training loss: 3.001753330230713
Validation loss: 2.082696194289833

Epoch: 5| Step: 5
Training loss: 1.935968041419983
Validation loss: 2.1112534256391626

Epoch: 5| Step: 6
Training loss: 2.1025946140289307
Validation loss: 2.1314803554165747

Epoch: 5| Step: 7
Training loss: 2.8342392444610596
Validation loss: 2.184255861466931

Epoch: 5| Step: 8
Training loss: 2.4090046882629395
Validation loss: 2.2187948534565587

Epoch: 5| Step: 9
Training loss: 2.5734004974365234
Validation loss: 2.173222518736316

Epoch: 5| Step: 10
Training loss: 2.3641700744628906
Validation loss: 2.1346471284025457

Epoch: 91| Step: 0
Training loss: 1.9128612279891968
Validation loss: 2.123453296640868

Epoch: 5| Step: 1
Training loss: 2.8622748851776123
Validation loss: 2.0848233866435226

Epoch: 5| Step: 2
Training loss: 2.2114462852478027
Validation loss: 2.0691497248987996

Epoch: 5| Step: 3
Training loss: 2.097642183303833
Validation loss: 2.0600756111965386

Epoch: 5| Step: 4
Training loss: 2.2503342628479004
Validation loss: 2.068129026761619

Epoch: 5| Step: 5
Training loss: 2.405322313308716
Validation loss: 2.07922302779331

Epoch: 5| Step: 6
Training loss: 2.9544928073883057
Validation loss: 2.0823931232575448

Epoch: 5| Step: 7
Training loss: 2.3113436698913574
Validation loss: 2.097074265121132

Epoch: 5| Step: 8
Training loss: 2.5427348613739014
Validation loss: 2.097733809101966

Epoch: 5| Step: 9
Training loss: 3.097932815551758
Validation loss: 2.0764268944340367

Epoch: 5| Step: 10
Training loss: 1.6431022882461548
Validation loss: 2.072468021864532

Epoch: 92| Step: 0
Training loss: 2.5078961849212646
Validation loss: 2.0604689633974465

Epoch: 5| Step: 1
Training loss: 2.405745029449463
Validation loss: 2.0636449013986895

Epoch: 5| Step: 2
Training loss: 1.984159231185913
Validation loss: 2.0528696634436168

Epoch: 5| Step: 3
Training loss: 1.9387798309326172
Validation loss: 2.0679106520068262

Epoch: 5| Step: 4
Training loss: 2.1869406700134277
Validation loss: 2.0487538024943364

Epoch: 5| Step: 5
Training loss: 2.4462547302246094
Validation loss: 2.0687609834055745

Epoch: 5| Step: 6
Training loss: 2.3456389904022217
Validation loss: 2.0622975774990615

Epoch: 5| Step: 7
Training loss: 2.645763874053955
Validation loss: 2.0940782408560477

Epoch: 5| Step: 8
Training loss: 2.7132062911987305
Validation loss: 2.104981956943389

Epoch: 5| Step: 9
Training loss: 3.1087822914123535
Validation loss: 2.159654780100751

Epoch: 5| Step: 10
Training loss: 2.025236129760742
Validation loss: 2.1592163911429783

Epoch: 93| Step: 0
Training loss: 2.374811887741089
Validation loss: 2.1281611560493388

Epoch: 5| Step: 1
Training loss: 2.537827968597412
Validation loss: 2.0871033386517595

Epoch: 5| Step: 2
Training loss: 2.7410778999328613
Validation loss: 2.071037143789312

Epoch: 5| Step: 3
Training loss: 2.7711706161499023
Validation loss: 2.0641343285960536

Epoch: 5| Step: 4
Training loss: 2.2717177867889404
Validation loss: 2.0592369776900097

Epoch: 5| Step: 5
Training loss: 2.388317108154297
Validation loss: 2.055904913974065

Epoch: 5| Step: 6
Training loss: 2.060821056365967
Validation loss: 2.0686215252004643

Epoch: 5| Step: 7
Training loss: 2.0207996368408203
Validation loss: 2.0534110287184357

Epoch: 5| Step: 8
Training loss: 2.232771396636963
Validation loss: 2.068133395205262

Epoch: 5| Step: 9
Training loss: 2.4867770671844482
Validation loss: 2.0757255708017657

Epoch: 5| Step: 10
Training loss: 2.340120553970337
Validation loss: 2.1043729397558395

Epoch: 94| Step: 0
Training loss: 2.182971239089966
Validation loss: 2.113338888332408

Epoch: 5| Step: 1
Training loss: 2.296196460723877
Validation loss: 2.144514406881025

Epoch: 5| Step: 2
Training loss: 2.834696054458618
Validation loss: 2.153707693981868

Epoch: 5| Step: 3
Training loss: 2.1945276260375977
Validation loss: 2.1242377168388775

Epoch: 5| Step: 4
Training loss: 3.028014659881592
Validation loss: 2.0830182016536756

Epoch: 5| Step: 5
Training loss: 2.4318222999572754
Validation loss: 2.0786549916831394

Epoch: 5| Step: 6
Training loss: 2.6788196563720703
Validation loss: 2.0645726085990987

Epoch: 5| Step: 7
Training loss: 1.4546668529510498
Validation loss: 2.0508272827312513

Epoch: 5| Step: 8
Training loss: 2.06384015083313
Validation loss: 2.053660765770943

Epoch: 5| Step: 9
Training loss: 2.5142979621887207
Validation loss: 2.057376329616834

Epoch: 5| Step: 10
Training loss: 2.642521381378174
Validation loss: 2.0634146005876604

Epoch: 95| Step: 0
Training loss: 2.7213187217712402
Validation loss: 2.065459333440309

Epoch: 5| Step: 1
Training loss: 2.0573370456695557
Validation loss: 2.059260610611208

Epoch: 5| Step: 2
Training loss: 2.2829484939575195
Validation loss: 2.0731102317892094

Epoch: 5| Step: 3
Training loss: 2.7864441871643066
Validation loss: 2.0659784745144587

Epoch: 5| Step: 4
Training loss: 1.985521912574768
Validation loss: 2.0663200040017404

Epoch: 5| Step: 5
Training loss: 2.5141475200653076
Validation loss: 2.052162613919986

Epoch: 5| Step: 6
Training loss: 2.7563693523406982
Validation loss: 2.0516236776946695

Epoch: 5| Step: 7
Training loss: 2.5194010734558105
Validation loss: 2.051451903517528

Epoch: 5| Step: 8
Training loss: 1.9354299306869507
Validation loss: 2.0488090976592033

Epoch: 5| Step: 9
Training loss: 1.9220516681671143
Validation loss: 2.057460646475515

Epoch: 5| Step: 10
Training loss: 2.601025104522705
Validation loss: 2.0749549583722184

Epoch: 96| Step: 0
Training loss: 2.2096099853515625
Validation loss: 2.082530883050734

Epoch: 5| Step: 1
Training loss: 2.9870786666870117
Validation loss: 2.0903376610048356

Epoch: 5| Step: 2
Training loss: 2.068866491317749
Validation loss: 2.1060851543180403

Epoch: 5| Step: 3
Training loss: 2.2045583724975586
Validation loss: 2.115778370570111

Epoch: 5| Step: 4
Training loss: 2.795708179473877
Validation loss: 2.151271907232141

Epoch: 5| Step: 5
Training loss: 2.627578020095825
Validation loss: 2.1397072551071004

Epoch: 5| Step: 6
Training loss: 2.33343505859375
Validation loss: 2.1354461587885374

Epoch: 5| Step: 7
Training loss: 2.514401912689209
Validation loss: 2.0884887479966685

Epoch: 5| Step: 8
Training loss: 2.160266160964966
Validation loss: 2.052938372858109

Epoch: 5| Step: 9
Training loss: 1.9911638498306274
Validation loss: 2.0401332686024327

Epoch: 5| Step: 10
Training loss: 2.210752248764038
Validation loss: 2.0427154699961343

Epoch: 97| Step: 0
Training loss: 2.575468063354492
Validation loss: 2.036831545573409

Epoch: 5| Step: 1
Training loss: 2.116364002227783
Validation loss: 2.0365212655836538

Epoch: 5| Step: 2
Training loss: 2.584632158279419
Validation loss: 2.0407588340902842

Epoch: 5| Step: 3
Training loss: 2.409332752227783
Validation loss: 2.0390068536163657

Epoch: 5| Step: 4
Training loss: 2.571782350540161
Validation loss: 2.03898960544217

Epoch: 5| Step: 5
Training loss: 2.996350049972534
Validation loss: 2.0299791392459663

Epoch: 5| Step: 6
Training loss: 2.388673782348633
Validation loss: 2.035222586765084

Epoch: 5| Step: 7
Training loss: 2.6657631397247314
Validation loss: 2.0353576803720124

Epoch: 5| Step: 8
Training loss: 1.7508900165557861
Validation loss: 2.023401801304151

Epoch: 5| Step: 9
Training loss: 1.9002033472061157
Validation loss: 2.0417058416592178

Epoch: 5| Step: 10
Training loss: 2.247593402862549
Validation loss: 2.049210266400409

Epoch: 98| Step: 0
Training loss: 2.173161268234253
Validation loss: 2.056315747640466

Epoch: 5| Step: 1
Training loss: 2.4379286766052246
Validation loss: 2.071018047230218

Epoch: 5| Step: 2
Training loss: 2.5922865867614746
Validation loss: 2.067917399508979

Epoch: 5| Step: 3
Training loss: 3.325373411178589
Validation loss: 2.0777012737848426

Epoch: 5| Step: 4
Training loss: 1.8917837142944336
Validation loss: 2.0746176140282744

Epoch: 5| Step: 5
Training loss: 2.351062774658203
Validation loss: 2.0729503221409296

Epoch: 5| Step: 6
Training loss: 1.9680131673812866
Validation loss: 2.067370068642401

Epoch: 5| Step: 7
Training loss: 1.6414289474487305
Validation loss: 2.043034117708924

Epoch: 5| Step: 8
Training loss: 2.811875581741333
Validation loss: 2.028399286731597

Epoch: 5| Step: 9
Training loss: 2.368417263031006
Validation loss: 2.0110287999594085

Epoch: 5| Step: 10
Training loss: 2.3496503829956055
Validation loss: 2.0061582801162556

Epoch: 99| Step: 0
Training loss: 2.6119399070739746
Validation loss: 2.0071662831050094

Epoch: 5| Step: 1
Training loss: 2.667839527130127
Validation loss: 2.006114113715387

Epoch: 5| Step: 2
Training loss: 2.2018332481384277
Validation loss: 2.010440787961406

Epoch: 5| Step: 3
Training loss: 2.4922947883605957
Validation loss: 2.015046901600335

Epoch: 5| Step: 4
Training loss: 2.475832462310791
Validation loss: 2.014436300082873

Epoch: 5| Step: 5
Training loss: 2.1801342964172363
Validation loss: 2.015211734720456

Epoch: 5| Step: 6
Training loss: 2.3897712230682373
Validation loss: 2.015303252845682

Epoch: 5| Step: 7
Training loss: 2.400381565093994
Validation loss: 2.0339216032335834

Epoch: 5| Step: 8
Training loss: 2.0344865322113037
Validation loss: 2.0707823832829795

Epoch: 5| Step: 9
Training loss: 2.310014486312866
Validation loss: 2.134115260134461

Epoch: 5| Step: 10
Training loss: 1.756502628326416
Validation loss: 2.1501355299385647

Epoch: 100| Step: 0
Training loss: 2.2163174152374268
Validation loss: 2.216908008821549

Epoch: 5| Step: 1
Training loss: 2.0863289833068848
Validation loss: 2.2965689551445747

Epoch: 5| Step: 2
Training loss: 3.0672316551208496
Validation loss: 2.3704711083442933

Epoch: 5| Step: 3
Training loss: 2.5743556022644043
Validation loss: 2.2752024255773073

Epoch: 5| Step: 4
Training loss: 2.303162097930908
Validation loss: 2.166678508122762

Epoch: 5| Step: 5
Training loss: 2.301877021789551
Validation loss: 2.0605724960245113

Epoch: 5| Step: 6
Training loss: 2.2613515853881836
Validation loss: 2.0134736632788055

Epoch: 5| Step: 7
Training loss: 2.130531072616577
Validation loss: 2.0158973573356547

Epoch: 5| Step: 8
Training loss: 2.2354941368103027
Validation loss: 2.0279269923445997

Epoch: 5| Step: 9
Training loss: 2.8179287910461426
Validation loss: 2.0348105994603967

Epoch: 5| Step: 10
Training loss: 2.4915542602539062
Validation loss: 2.042961710242815

Epoch: 101| Step: 0
Training loss: 2.176919460296631
Validation loss: 2.0310220385110505

Epoch: 5| Step: 1
Training loss: 3.0134103298187256
Validation loss: 2.0242060897170857

Epoch: 5| Step: 2
Training loss: 2.4069628715515137
Validation loss: 2.0162472545459704

Epoch: 5| Step: 3
Training loss: 2.4621152877807617
Validation loss: 2.015447275612944

Epoch: 5| Step: 4
Training loss: 2.322404146194458
Validation loss: 2.023915711269584

Epoch: 5| Step: 5
Training loss: 2.3458125591278076
Validation loss: 2.033893317304632

Epoch: 5| Step: 6
Training loss: 2.2113146781921387
Validation loss: 2.0427690911036667

Epoch: 5| Step: 7
Training loss: 1.8378162384033203
Validation loss: 2.0619218503275225

Epoch: 5| Step: 8
Training loss: 2.39528489112854
Validation loss: 2.1048552554140807

Epoch: 5| Step: 9
Training loss: 2.5278754234313965
Validation loss: 2.082321914293433

Epoch: 5| Step: 10
Training loss: 2.2576749324798584
Validation loss: 2.0599546381222305

Epoch: 102| Step: 0
Training loss: 1.94094979763031
Validation loss: 2.048346628424942

Epoch: 5| Step: 1
Training loss: 2.2860701084136963
Validation loss: 2.031181517467704

Epoch: 5| Step: 2
Training loss: 2.2012088298797607
Validation loss: 2.016027694107384

Epoch: 5| Step: 3
Training loss: 2.8320069313049316
Validation loss: 2.0124735140031382

Epoch: 5| Step: 4
Training loss: 2.129417896270752
Validation loss: 2.014248222433111

Epoch: 5| Step: 5
Training loss: 2.0737690925598145
Validation loss: 2.017144610804896

Epoch: 5| Step: 6
Training loss: 2.297481060028076
Validation loss: 2.0211617100623345

Epoch: 5| Step: 7
Training loss: 2.3819334506988525
Validation loss: 2.0147366754470335

Epoch: 5| Step: 8
Training loss: 2.8039700984954834
Validation loss: 2.0238979619036437

Epoch: 5| Step: 9
Training loss: 2.7696197032928467
Validation loss: 2.0473508193928707

Epoch: 5| Step: 10
Training loss: 1.975201964378357
Validation loss: 2.06204193381853

Epoch: 103| Step: 0
Training loss: 2.5951695442199707
Validation loss: 2.066799804728518

Epoch: 5| Step: 1
Training loss: 2.35042405128479
Validation loss: 2.0650493791026454

Epoch: 5| Step: 2
Training loss: 2.3884708881378174
Validation loss: 2.061696534515709

Epoch: 5| Step: 3
Training loss: 2.3622868061065674
Validation loss: 2.0250396318333124

Epoch: 5| Step: 4
Training loss: 2.582836866378784
Validation loss: 2.0154291532372914

Epoch: 5| Step: 5
Training loss: 2.246081590652466
Validation loss: 2.0136431737612654

Epoch: 5| Step: 6
Training loss: 2.145935297012329
Validation loss: 1.9850823968969367

Epoch: 5| Step: 7
Training loss: 2.0411057472229004
Validation loss: 1.9836457314029816

Epoch: 5| Step: 8
Training loss: 2.657119035720825
Validation loss: 1.9879298620326544

Epoch: 5| Step: 9
Training loss: 2.085815906524658
Validation loss: 2.000585566284836

Epoch: 5| Step: 10
Training loss: 2.3040695190429688
Validation loss: 2.022092560286163

Epoch: 104| Step: 0
Training loss: 2.2503702640533447
Validation loss: 2.0553552309672036

Epoch: 5| Step: 1
Training loss: 2.717421054840088
Validation loss: 2.0981316066557363

Epoch: 5| Step: 2
Training loss: 2.1944007873535156
Validation loss: 2.108002242221627

Epoch: 5| Step: 3
Training loss: 2.1891934871673584
Validation loss: 2.0928920520249235

Epoch: 5| Step: 4
Training loss: 2.824394464492798
Validation loss: 2.081260255587998

Epoch: 5| Step: 5
Training loss: 2.60011625289917
Validation loss: 2.07812161086708

Epoch: 5| Step: 6
Training loss: 2.2492854595184326
Validation loss: 2.0684494997865412

Epoch: 5| Step: 7
Training loss: 2.4663875102996826
Validation loss: 2.062527584773238

Epoch: 5| Step: 8
Training loss: 1.7945197820663452
Validation loss: 2.0557016582899195

Epoch: 5| Step: 9
Training loss: 2.489819049835205
Validation loss: 2.0483300788428194

Epoch: 5| Step: 10
Training loss: 1.8274785280227661
Validation loss: 2.0312671225558043

Epoch: 105| Step: 0
Training loss: 2.1547698974609375
Validation loss: 2.0269050585326327

Epoch: 5| Step: 1
Training loss: 1.6940666437149048
Validation loss: 2.0377338240223546

Epoch: 5| Step: 2
Training loss: 3.3923964500427246
Validation loss: 2.0565793180978424

Epoch: 5| Step: 3
Training loss: 1.7700061798095703
Validation loss: 2.0307797334527455

Epoch: 5| Step: 4
Training loss: 2.4164071083068848
Validation loss: 2.005677644924451

Epoch: 5| Step: 5
Training loss: 2.402132749557495
Validation loss: 1.9981452752185125

Epoch: 5| Step: 6
Training loss: 2.4132251739501953
Validation loss: 2.000221876687901

Epoch: 5| Step: 7
Training loss: 2.100494861602783
Validation loss: 1.9867899571695635

Epoch: 5| Step: 8
Training loss: 2.535141944885254
Validation loss: 1.9985826015472412

Epoch: 5| Step: 9
Training loss: 2.2606804370880127
Validation loss: 1.9951156249610327

Epoch: 5| Step: 10
Training loss: 2.3364737033843994
Validation loss: 2.015128307445075

Epoch: 106| Step: 0
Training loss: 2.734978199005127
Validation loss: 2.028309918219043

Epoch: 5| Step: 1
Training loss: 2.223341703414917
Validation loss: 2.0174067507507982

Epoch: 5| Step: 2
Training loss: 2.06361722946167
Validation loss: 2.0388084791039907

Epoch: 5| Step: 3
Training loss: 2.132660388946533
Validation loss: 2.062215571762413

Epoch: 5| Step: 4
Training loss: 2.346381425857544
Validation loss: 2.0823543148656047

Epoch: 5| Step: 5
Training loss: 2.5405797958374023
Validation loss: 2.072696901136829

Epoch: 5| Step: 6
Training loss: 1.8041503429412842
Validation loss: 2.0467689268050657

Epoch: 5| Step: 7
Training loss: 2.575363874435425
Validation loss: 2.028148953632642

Epoch: 5| Step: 8
Training loss: 2.1959118843078613
Validation loss: 2.033055243953582

Epoch: 5| Step: 9
Training loss: 2.5499792098999023
Validation loss: 2.025540308285785

Epoch: 5| Step: 10
Training loss: 2.100714921951294
Validation loss: 2.0234000554648777

Epoch: 107| Step: 0
Training loss: 2.719202756881714
Validation loss: 2.013759228491014

Epoch: 5| Step: 1
Training loss: 2.288700580596924
Validation loss: 2.008520418597806

Epoch: 5| Step: 2
Training loss: 1.9007682800292969
Validation loss: 2.0072914285044514

Epoch: 5| Step: 3
Training loss: 2.2730190753936768
Validation loss: 2.0175884615990425

Epoch: 5| Step: 4
Training loss: 2.308342933654785
Validation loss: 2.0399837224714217

Epoch: 5| Step: 5
Training loss: 2.628997325897217
Validation loss: 2.0661144692410707

Epoch: 5| Step: 6
Training loss: 2.210174560546875
Validation loss: 2.066208388215752

Epoch: 5| Step: 7
Training loss: 2.4266955852508545
Validation loss: 2.0738992434675976

Epoch: 5| Step: 8
Training loss: 1.9336795806884766
Validation loss: 2.091140765015797

Epoch: 5| Step: 9
Training loss: 2.2125353813171387
Validation loss: 2.116029615043312

Epoch: 5| Step: 10
Training loss: 2.480246067047119
Validation loss: 2.1171542547082387

Epoch: 108| Step: 0
Training loss: 1.874606728553772
Validation loss: 2.0907503481834167

Epoch: 5| Step: 1
Training loss: 2.4015719890594482
Validation loss: 2.0482151200694423

Epoch: 5| Step: 2
Training loss: 2.622323989868164
Validation loss: 2.022554543710524

Epoch: 5| Step: 3
Training loss: 2.4440460205078125
Validation loss: 2.0045774239365772

Epoch: 5| Step: 4
Training loss: 2.401822328567505
Validation loss: 2.001436210447742

Epoch: 5| Step: 5
Training loss: 2.028007745742798
Validation loss: 2.014640618396062

Epoch: 5| Step: 6
Training loss: 1.7322978973388672
Validation loss: 2.0583437950380388

Epoch: 5| Step: 7
Training loss: 2.817124128341675
Validation loss: 2.127483962684549

Epoch: 5| Step: 8
Training loss: 2.411388635635376
Validation loss: 2.185370893888576

Epoch: 5| Step: 9
Training loss: 2.1049277782440186
Validation loss: 2.181779779413695

Epoch: 5| Step: 10
Training loss: 2.480571985244751
Validation loss: 2.1498758126330633

Epoch: 109| Step: 0
Training loss: 2.3861289024353027
Validation loss: 2.1098255290780017

Epoch: 5| Step: 1
Training loss: 2.0273537635803223
Validation loss: 2.049410581588745

Epoch: 5| Step: 2
Training loss: 1.9499025344848633
Validation loss: 2.0338159556029947

Epoch: 5| Step: 3
Training loss: 2.2081775665283203
Validation loss: 2.0209657184539305

Epoch: 5| Step: 4
Training loss: 2.002242088317871
Validation loss: 2.0316004368566696

Epoch: 5| Step: 5
Training loss: 2.5021419525146484
Validation loss: 2.0510916274080992

Epoch: 5| Step: 6
Training loss: 2.3774304389953613
Validation loss: 2.060590651727492

Epoch: 5| Step: 7
Training loss: 1.9078058004379272
Validation loss: 2.0497146485954203

Epoch: 5| Step: 8
Training loss: 2.656446933746338
Validation loss: 2.0494561233828144

Epoch: 5| Step: 9
Training loss: 2.8014724254608154
Validation loss: 2.061984669777655

Epoch: 5| Step: 10
Training loss: 2.1614739894866943
Validation loss: 2.097836027863205

Epoch: 110| Step: 0
Training loss: 1.9228893518447876
Validation loss: 2.0810221625912573

Epoch: 5| Step: 1
Training loss: 2.7065837383270264
Validation loss: 2.053495667314017

Epoch: 5| Step: 2
Training loss: 2.5421841144561768
Validation loss: 2.0851225545329433

Epoch: 5| Step: 3
Training loss: 2.039473295211792
Validation loss: 2.095625904298598

Epoch: 5| Step: 4
Training loss: 2.0972342491149902
Validation loss: 2.0931590013606574

Epoch: 5| Step: 5
Training loss: 2.7286462783813477
Validation loss: 2.0541792531167307

Epoch: 5| Step: 6
Training loss: 1.4458105564117432
Validation loss: 2.0446205767252112

Epoch: 5| Step: 7
Training loss: 2.1015572547912598
Validation loss: 2.0322231195306264

Epoch: 5| Step: 8
Training loss: 2.389726161956787
Validation loss: 2.0094545477180072

Epoch: 5| Step: 9
Training loss: 1.9098548889160156
Validation loss: 2.004955417366438

Epoch: 5| Step: 10
Training loss: 3.0073041915893555
Validation loss: 1.9727037491336945

Epoch: 111| Step: 0
Training loss: 1.9554523229599
Validation loss: 1.9628317022836337

Epoch: 5| Step: 1
Training loss: 2.492995262145996
Validation loss: 1.955452835688027

Epoch: 5| Step: 2
Training loss: 2.258300304412842
Validation loss: 1.953846013674172

Epoch: 5| Step: 3
Training loss: 2.6571788787841797
Validation loss: 1.9615594751091414

Epoch: 5| Step: 4
Training loss: 2.0164542198181152
Validation loss: 1.9742317148434219

Epoch: 5| Step: 5
Training loss: 2.034569263458252
Validation loss: 2.0319724147037794

Epoch: 5| Step: 6
Training loss: 2.142490863800049
Validation loss: 2.114059853297408

Epoch: 5| Step: 7
Training loss: 2.637467861175537
Validation loss: 2.1144182771764775

Epoch: 5| Step: 8
Training loss: 2.338466167449951
Validation loss: 2.104321010651127

Epoch: 5| Step: 9
Training loss: 2.6518185138702393
Validation loss: 2.046425629687566

Epoch: 5| Step: 10
Training loss: 1.7575465440750122
Validation loss: 1.9854766476538874

Epoch: 112| Step: 0
Training loss: 2.8722777366638184
Validation loss: 1.9598784523625528

Epoch: 5| Step: 1
Training loss: 2.208425760269165
Validation loss: 1.9519309766830937

Epoch: 5| Step: 2
Training loss: 2.1455225944519043
Validation loss: 1.964922389676494

Epoch: 5| Step: 3
Training loss: 2.0721096992492676
Validation loss: 1.9657910241875598

Epoch: 5| Step: 4
Training loss: 2.3492164611816406
Validation loss: 1.9786223852506248

Epoch: 5| Step: 5
Training loss: 2.726222276687622
Validation loss: 2.0097399693663403

Epoch: 5| Step: 6
Training loss: 1.7632020711898804
Validation loss: 2.0111260491032756

Epoch: 5| Step: 7
Training loss: 2.2539725303649902
Validation loss: 2.0189211881288918

Epoch: 5| Step: 8
Training loss: 2.793684720993042
Validation loss: 2.0681451161702475

Epoch: 5| Step: 9
Training loss: 2.0258095264434814
Validation loss: 2.0848724816435125

Epoch: 5| Step: 10
Training loss: 1.4380970001220703
Validation loss: 2.104779433178645

Epoch: 113| Step: 0
Training loss: 2.408820867538452
Validation loss: 2.1353926299720682

Epoch: 5| Step: 1
Training loss: 2.320568323135376
Validation loss: 2.1422844894470705

Epoch: 5| Step: 2
Training loss: 2.1660807132720947
Validation loss: 2.0861056235528763

Epoch: 5| Step: 3
Training loss: 2.1907098293304443
Validation loss: 2.0396496211328814

Epoch: 5| Step: 4
Training loss: 2.4920639991760254
Validation loss: 1.9931839871150192

Epoch: 5| Step: 5
Training loss: 2.1408839225769043
Validation loss: 1.9622978113030876

Epoch: 5| Step: 6
Training loss: 2.459451675415039
Validation loss: 1.940666183348625

Epoch: 5| Step: 7
Training loss: 1.832542061805725
Validation loss: 1.9272407921411658

Epoch: 5| Step: 8
Training loss: 2.293591022491455
Validation loss: 1.9302985950182843

Epoch: 5| Step: 9
Training loss: 2.453089475631714
Validation loss: 1.9398697153214486

Epoch: 5| Step: 10
Training loss: 2.038123369216919
Validation loss: 1.936263435630388

Epoch: 114| Step: 0
Training loss: 1.8176828622817993
Validation loss: 1.9522985450683101

Epoch: 5| Step: 1
Training loss: 1.7772334814071655
Validation loss: 1.970125352182696

Epoch: 5| Step: 2
Training loss: 2.547114610671997
Validation loss: 1.9975067005362561

Epoch: 5| Step: 3
Training loss: 2.652947425842285
Validation loss: 2.047207099135204

Epoch: 5| Step: 4
Training loss: 2.350203275680542
Validation loss: 2.0593016993614937

Epoch: 5| Step: 5
Training loss: 2.2628955841064453
Validation loss: 2.0434310128611903

Epoch: 5| Step: 6
Training loss: 2.156144618988037
Validation loss: 2.053088018971105

Epoch: 5| Step: 7
Training loss: 2.2719922065734863
Validation loss: 2.065768257264168

Epoch: 5| Step: 8
Training loss: 2.7140650749206543
Validation loss: 2.0882439562069472

Epoch: 5| Step: 9
Training loss: 2.2021946907043457
Validation loss: 2.0539983523789274

Epoch: 5| Step: 10
Training loss: 1.8527171611785889
Validation loss: 1.9944589343122257

Epoch: 115| Step: 0
Training loss: 1.7703351974487305
Validation loss: 1.9623233195274108

Epoch: 5| Step: 1
Training loss: 2.3822834491729736
Validation loss: 1.9618210202904158

Epoch: 5| Step: 2
Training loss: 2.1341006755828857
Validation loss: 1.9614680146658292

Epoch: 5| Step: 3
Training loss: 2.048830509185791
Validation loss: 1.956299481853362

Epoch: 5| Step: 4
Training loss: 2.0761561393737793
Validation loss: 1.9562389722434423

Epoch: 5| Step: 5
Training loss: 2.2532360553741455
Validation loss: 1.968974623628842

Epoch: 5| Step: 6
Training loss: 2.2013487815856934
Validation loss: 1.9847113599059403

Epoch: 5| Step: 7
Training loss: 2.348193645477295
Validation loss: 2.007574604403588

Epoch: 5| Step: 8
Training loss: 2.4753670692443848
Validation loss: 2.0271291245696363

Epoch: 5| Step: 9
Training loss: 2.3636741638183594
Validation loss: 2.040622957291142

Epoch: 5| Step: 10
Training loss: 2.0063726902008057
Validation loss: 2.1185938683889245

Epoch: 116| Step: 0
Training loss: 2.0560030937194824
Validation loss: 2.1425891153274046

Epoch: 5| Step: 1
Training loss: 2.123807907104492
Validation loss: 2.1272860086092384

Epoch: 5| Step: 2
Training loss: 2.2873687744140625
Validation loss: 2.0872612922422347

Epoch: 5| Step: 3
Training loss: 1.8135982751846313
Validation loss: 2.009496363260413

Epoch: 5| Step: 4
Training loss: 2.2060465812683105
Validation loss: 1.968856132158669

Epoch: 5| Step: 5
Training loss: 2.062035322189331
Validation loss: 1.964749320860832

Epoch: 5| Step: 6
Training loss: 2.574605941772461
Validation loss: 1.9627912839253743

Epoch: 5| Step: 7
Training loss: 2.5931270122528076
Validation loss: 1.9738462355829054

Epoch: 5| Step: 8
Training loss: 2.0828280448913574
Validation loss: 2.004192352294922

Epoch: 5| Step: 9
Training loss: 2.2938008308410645
Validation loss: 2.0066223721350394

Epoch: 5| Step: 10
Training loss: 2.341315984725952
Validation loss: 2.020543961114781

Epoch: 117| Step: 0
Training loss: 1.9497458934783936
Validation loss: 2.0209789917033207

Epoch: 5| Step: 1
Training loss: 1.6644287109375
Validation loss: 2.028141621620424

Epoch: 5| Step: 2
Training loss: 2.1297266483306885
Validation loss: 2.071885501184771

Epoch: 5| Step: 3
Training loss: 2.393014669418335
Validation loss: 2.089777649089854

Epoch: 5| Step: 4
Training loss: 2.392332077026367
Validation loss: 2.0777807004990114

Epoch: 5| Step: 5
Training loss: 2.6656644344329834
Validation loss: 2.052040671789518

Epoch: 5| Step: 6
Training loss: 2.5999722480773926
Validation loss: 2.052233657529277

Epoch: 5| Step: 7
Training loss: 1.8658939599990845
Validation loss: 2.0192910445633756

Epoch: 5| Step: 8
Training loss: 1.9711542129516602
Validation loss: 1.9969169196262155

Epoch: 5| Step: 9
Training loss: 2.036949634552002
Validation loss: 1.9898643980744064

Epoch: 5| Step: 10
Training loss: 2.5934529304504395
Validation loss: 1.9775847670852498

Epoch: 118| Step: 0
Training loss: 1.9886605739593506
Validation loss: 1.9782654982741161

Epoch: 5| Step: 1
Training loss: 2.3866372108459473
Validation loss: 1.9773465279609925

Epoch: 5| Step: 2
Training loss: 2.5223186016082764
Validation loss: 1.9902353581561838

Epoch: 5| Step: 3
Training loss: 2.1678719520568848
Validation loss: 2.039721155679354

Epoch: 5| Step: 4
Training loss: 2.0345070362091064
Validation loss: 2.052191501022667

Epoch: 5| Step: 5
Training loss: 2.3515381813049316
Validation loss: 2.1095690957961546

Epoch: 5| Step: 6
Training loss: 2.0097062587738037
Validation loss: 2.1586627703841015

Epoch: 5| Step: 7
Training loss: 2.3795132637023926
Validation loss: 2.1843585993653987

Epoch: 5| Step: 8
Training loss: 2.0274574756622314
Validation loss: 2.176482385204684

Epoch: 5| Step: 9
Training loss: 2.1378865242004395
Validation loss: 2.1269463210977535

Epoch: 5| Step: 10
Training loss: 2.7725751399993896
Validation loss: 2.077053872487878

Epoch: 119| Step: 0
Training loss: 2.2656009197235107
Validation loss: 2.0223006791965936

Epoch: 5| Step: 1
Training loss: 2.171557664871216
Validation loss: 1.9831059876308645

Epoch: 5| Step: 2
Training loss: 2.5196564197540283
Validation loss: 1.9835190298736736

Epoch: 5| Step: 3
Training loss: 2.4840774536132812
Validation loss: 1.9786645391935944

Epoch: 5| Step: 4
Training loss: 2.029474973678589
Validation loss: 1.9782971002722298

Epoch: 5| Step: 5
Training loss: 2.016054630279541
Validation loss: 1.9878286430912633

Epoch: 5| Step: 6
Training loss: 2.557774543762207
Validation loss: 2.000530283938172

Epoch: 5| Step: 7
Training loss: 1.7656742334365845
Validation loss: 2.021967226459134

Epoch: 5| Step: 8
Training loss: 2.313175916671753
Validation loss: 2.0581535767483454

Epoch: 5| Step: 9
Training loss: 1.8422645330429077
Validation loss: 2.150074715255409

Epoch: 5| Step: 10
Training loss: 2.2550578117370605
Validation loss: 2.1967938125774427

Epoch: 120| Step: 0
Training loss: 2.4607691764831543
Validation loss: 2.1875357589414044

Epoch: 5| Step: 1
Training loss: 2.466463804244995
Validation loss: 2.128512079997729

Epoch: 5| Step: 2
Training loss: 2.029940366744995
Validation loss: 2.0303089157227547

Epoch: 5| Step: 3
Training loss: 2.4801595211029053
Validation loss: 1.961602549399099

Epoch: 5| Step: 4
Training loss: 2.375577449798584
Validation loss: 1.9396010034827775

Epoch: 5| Step: 5
Training loss: 2.052476406097412
Validation loss: 1.9344126870555263

Epoch: 5| Step: 6
Training loss: 1.5220787525177002
Validation loss: 1.9403962242987849

Epoch: 5| Step: 7
Training loss: 2.5584092140197754
Validation loss: 1.9616025699082242

Epoch: 5| Step: 8
Training loss: 2.0646140575408936
Validation loss: 1.9564242696249357

Epoch: 5| Step: 9
Training loss: 2.016885757446289
Validation loss: 1.9549710314760926

Epoch: 5| Step: 10
Training loss: 3.0581276416778564
Validation loss: 1.959957125366375

Epoch: 121| Step: 0
Training loss: 2.9069876670837402
Validation loss: 1.9611849631032636

Epoch: 5| Step: 1
Training loss: 1.9202651977539062
Validation loss: 1.9763692386688725

Epoch: 5| Step: 2
Training loss: 2.0231056213378906
Validation loss: 1.9999100597955848

Epoch: 5| Step: 3
Training loss: 1.6921535730361938
Validation loss: 2.02792743585443

Epoch: 5| Step: 4
Training loss: 2.1138062477111816
Validation loss: 2.025416910007436

Epoch: 5| Step: 5
Training loss: 2.0663695335388184
Validation loss: 2.038375393036873

Epoch: 5| Step: 6
Training loss: 2.224976062774658
Validation loss: 2.041218211573939

Epoch: 5| Step: 7
Training loss: 2.0444912910461426
Validation loss: 2.0193663886798325

Epoch: 5| Step: 8
Training loss: 2.2423181533813477
Validation loss: 2.011958743936272

Epoch: 5| Step: 9
Training loss: 2.661937713623047
Validation loss: 2.018808898105416

Epoch: 5| Step: 10
Training loss: 2.1322689056396484
Validation loss: 2.002067396717687

Epoch: 122| Step: 0
Training loss: 1.6108980178833008
Validation loss: 1.9537162011669529

Epoch: 5| Step: 1
Training loss: 2.4866809844970703
Validation loss: 1.9255821320318407

Epoch: 5| Step: 2
Training loss: 2.104172706604004
Validation loss: 1.9100837797246955

Epoch: 5| Step: 3
Training loss: 2.4529051780700684
Validation loss: 1.910557827641887

Epoch: 5| Step: 4
Training loss: 2.716076135635376
Validation loss: 1.9151540366552209

Epoch: 5| Step: 5
Training loss: 2.5281074047088623
Validation loss: 1.9220166206359863

Epoch: 5| Step: 6
Training loss: 1.9252846240997314
Validation loss: 1.9221308359535791

Epoch: 5| Step: 7
Training loss: 2.0473556518554688
Validation loss: 1.9380562407996065

Epoch: 5| Step: 8
Training loss: 2.076747417449951
Validation loss: 1.9678303272493425

Epoch: 5| Step: 9
Training loss: 2.1775736808776855
Validation loss: 2.04109557982414

Epoch: 5| Step: 10
Training loss: 1.9446909427642822
Validation loss: 2.1001444055188085

Epoch: 123| Step: 0
Training loss: 2.425493001937866
Validation loss: 2.132821152287145

Epoch: 5| Step: 1
Training loss: 1.5220428705215454
Validation loss: 2.1062881767108874

Epoch: 5| Step: 2
Training loss: 1.953656792640686
Validation loss: 2.0513892763404438

Epoch: 5| Step: 3
Training loss: 2.662531852722168
Validation loss: 2.0028920442827287

Epoch: 5| Step: 4
Training loss: 1.8307344913482666
Validation loss: 1.9587684831311625

Epoch: 5| Step: 5
Training loss: 2.0517683029174805
Validation loss: 1.9252316298023346

Epoch: 5| Step: 6
Training loss: 1.5878422260284424
Validation loss: 1.9191903965447539

Epoch: 5| Step: 7
Training loss: 2.466705322265625
Validation loss: 1.9370496324313584

Epoch: 5| Step: 8
Training loss: 2.4365525245666504
Validation loss: 1.9499147989416634

Epoch: 5| Step: 9
Training loss: 2.5483949184417725
Validation loss: 1.979471932175339

Epoch: 5| Step: 10
Training loss: 2.567345142364502
Validation loss: 2.0382853349049888

Epoch: 124| Step: 0
Training loss: 2.290482521057129
Validation loss: 2.0762884129760084

Epoch: 5| Step: 1
Training loss: 2.012291669845581
Validation loss: 2.107204791038267

Epoch: 5| Step: 2
Training loss: 2.3407680988311768
Validation loss: 2.100058945276404

Epoch: 5| Step: 3
Training loss: 2.4079549312591553
Validation loss: 2.0670304452219317

Epoch: 5| Step: 4
Training loss: 2.293865203857422
Validation loss: 2.002863294334822

Epoch: 5| Step: 5
Training loss: 2.1631205081939697
Validation loss: 1.9599426895059564

Epoch: 5| Step: 6
Training loss: 2.0450356006622314
Validation loss: 1.9466118440833142

Epoch: 5| Step: 7
Training loss: 2.4219818115234375
Validation loss: 1.9431781256070702

Epoch: 5| Step: 8
Training loss: 2.0851101875305176
Validation loss: 1.9549750461373279

Epoch: 5| Step: 9
Training loss: 2.4947762489318848
Validation loss: 1.9556868294233918

Epoch: 5| Step: 10
Training loss: 1.8496520519256592
Validation loss: 1.9711840498831965

Epoch: 125| Step: 0
Training loss: 2.298675060272217
Validation loss: 1.9845416135685419

Epoch: 5| Step: 1
Training loss: 1.8940738439559937
Validation loss: 2.0069729102555143

Epoch: 5| Step: 2
Training loss: 2.5455265045166016
Validation loss: 2.0091068513931765

Epoch: 5| Step: 3
Training loss: 2.0680487155914307
Validation loss: 2.01516019657094

Epoch: 5| Step: 4
Training loss: 1.7196401357650757
Validation loss: 2.024274464576475

Epoch: 5| Step: 5
Training loss: 1.8701574802398682
Validation loss: 2.0162197569365143

Epoch: 5| Step: 6
Training loss: 2.3597731590270996
Validation loss: 2.0204803635997157

Epoch: 5| Step: 7
Training loss: 1.7918685674667358
Validation loss: 2.0188496266641924

Epoch: 5| Step: 8
Training loss: 2.408905506134033
Validation loss: 2.009558831491778

Epoch: 5| Step: 9
Training loss: 2.3771681785583496
Validation loss: 1.9802876980073991

Epoch: 5| Step: 10
Training loss: 1.81356680393219
Validation loss: 1.9704577974093858

Epoch: 126| Step: 0
Training loss: 1.7767372131347656
Validation loss: 1.9482017229962092

Epoch: 5| Step: 1
Training loss: 1.9436674118041992
Validation loss: 1.9704818687131327

Epoch: 5| Step: 2
Training loss: 1.930997610092163
Validation loss: 1.9784961297947874

Epoch: 5| Step: 3
Training loss: 2.8534343242645264
Validation loss: 1.9920154489496702

Epoch: 5| Step: 4
Training loss: 2.321420431137085
Validation loss: 1.9928623245608421

Epoch: 5| Step: 5
Training loss: 1.8015491962432861
Validation loss: 1.9919746627089798

Epoch: 5| Step: 6
Training loss: 2.1558711528778076
Validation loss: 1.9835869753232567

Epoch: 5| Step: 7
Training loss: 1.8669592142105103
Validation loss: 1.9953715775602607

Epoch: 5| Step: 8
Training loss: 2.4253973960876465
Validation loss: 2.0414750576019287

Epoch: 5| Step: 9
Training loss: 2.399338483810425
Validation loss: 2.043571170940194

Epoch: 5| Step: 10
Training loss: 1.5415315628051758
Validation loss: 2.078824794420632

Epoch: 127| Step: 0
Training loss: 1.8082664012908936
Validation loss: 2.056181179579868

Epoch: 5| Step: 1
Training loss: 1.8438717126846313
Validation loss: 2.0469462666460263

Epoch: 5| Step: 2
Training loss: 1.998045563697815
Validation loss: 1.981618663316132

Epoch: 5| Step: 3
Training loss: 1.9443213939666748
Validation loss: 1.9595883251518331

Epoch: 5| Step: 4
Training loss: 1.9200023412704468
Validation loss: 1.945005855252666

Epoch: 5| Step: 5
Training loss: 2.7679648399353027
Validation loss: 1.93216884264382

Epoch: 5| Step: 6
Training loss: 1.8354114294052124
Validation loss: 1.939618000420191

Epoch: 5| Step: 7
Training loss: 2.5074167251586914
Validation loss: 1.95176830855749

Epoch: 5| Step: 8
Training loss: 2.0136780738830566
Validation loss: 1.9593307497680827

Epoch: 5| Step: 9
Training loss: 2.610767126083374
Validation loss: 1.999567857352636

Epoch: 5| Step: 10
Training loss: 1.9730921983718872
Validation loss: 2.018316363775602

Epoch: 128| Step: 0
Training loss: 1.8229490518569946
Validation loss: 2.057956405865249

Epoch: 5| Step: 1
Training loss: 1.874434232711792
Validation loss: 2.049905615468179

Epoch: 5| Step: 2
Training loss: 1.8727601766586304
Validation loss: 2.00737601582722

Epoch: 5| Step: 3
Training loss: 1.9089235067367554
Validation loss: 1.9558132694613548

Epoch: 5| Step: 4
Training loss: 2.6218149662017822
Validation loss: 1.9407901328097108

Epoch: 5| Step: 5
Training loss: 2.1964352130889893
Validation loss: 1.9546394578872188

Epoch: 5| Step: 6
Training loss: 2.0400009155273438
Validation loss: 1.958726344570037

Epoch: 5| Step: 7
Training loss: 2.0513274669647217
Validation loss: 1.9688767310111754

Epoch: 5| Step: 8
Training loss: 1.827410101890564
Validation loss: 1.9962213936672415

Epoch: 5| Step: 9
Training loss: 2.403902769088745
Validation loss: 2.02923576037089

Epoch: 5| Step: 10
Training loss: 2.5207860469818115
Validation loss: 2.0420871280854747

Epoch: 129| Step: 0
Training loss: 2.302055835723877
Validation loss: 1.9963558796913392

Epoch: 5| Step: 1
Training loss: 1.9978358745574951
Validation loss: 1.9349037319101312

Epoch: 5| Step: 2
Training loss: 1.881387710571289
Validation loss: 1.92465760630946

Epoch: 5| Step: 3
Training loss: 1.8440876007080078
Validation loss: 1.948951191799615

Epoch: 5| Step: 4
Training loss: 1.5734111070632935
Validation loss: 1.9637715662679365

Epoch: 5| Step: 5
Training loss: 2.0781502723693848
Validation loss: 1.9695070815342728

Epoch: 5| Step: 6
Training loss: 2.4060301780700684
Validation loss: 1.993532580714072

Epoch: 5| Step: 7
Training loss: 1.7908518314361572
Validation loss: 2.0083038242914344

Epoch: 5| Step: 8
Training loss: 2.4926259517669678
Validation loss: 1.991701582426666

Epoch: 5| Step: 9
Training loss: 2.4586687088012695
Validation loss: 1.9719350325163973

Epoch: 5| Step: 10
Training loss: 1.9717432260513306
Validation loss: 1.9636444212287985

Epoch: 130| Step: 0
Training loss: 1.8040459156036377
Validation loss: 1.952108031959944

Epoch: 5| Step: 1
Training loss: 3.0468153953552246
Validation loss: 1.9513857685109621

Epoch: 5| Step: 2
Training loss: 2.7463455200195312
Validation loss: 1.966522337287985

Epoch: 5| Step: 3
Training loss: 1.509497046470642
Validation loss: 1.983058253924052

Epoch: 5| Step: 4
Training loss: 1.323678970336914
Validation loss: 1.9965117490419777

Epoch: 5| Step: 5
Training loss: 2.0918431282043457
Validation loss: 2.0062085531091176

Epoch: 5| Step: 6
Training loss: 1.494287133216858
Validation loss: 2.019934505544683

Epoch: 5| Step: 7
Training loss: 2.2751574516296387
Validation loss: 2.0274525919268207

Epoch: 5| Step: 8
Training loss: 1.9880796670913696
Validation loss: 2.037673170848559

Epoch: 5| Step: 9
Training loss: 1.7588882446289062
Validation loss: 2.0242414320668867

Epoch: 5| Step: 10
Training loss: 2.5743956565856934
Validation loss: 2.0078045347685456

Epoch: 131| Step: 0
Training loss: 1.5255777835845947
Validation loss: 1.98781959343982

Epoch: 5| Step: 1
Training loss: 2.3788466453552246
Validation loss: 1.9607975367576844

Epoch: 5| Step: 2
Training loss: 1.939565658569336
Validation loss: 1.9380909255755845

Epoch: 5| Step: 3
Training loss: 2.2950806617736816
Validation loss: 1.9490463297854188

Epoch: 5| Step: 4
Training loss: 1.9018653631210327
Validation loss: 1.9564283394044446

Epoch: 5| Step: 5
Training loss: 1.8958107233047485
Validation loss: 1.9684972455424647

Epoch: 5| Step: 6
Training loss: 2.004995107650757
Validation loss: 2.0016417862266622

Epoch: 5| Step: 7
Training loss: 2.5785446166992188
Validation loss: 2.04484079089216

Epoch: 5| Step: 8
Training loss: 2.1860439777374268
Validation loss: 2.0568907350622196

Epoch: 5| Step: 9
Training loss: 1.6065292358398438
Validation loss: 2.025871597310548

Epoch: 5| Step: 10
Training loss: 2.2332558631896973
Validation loss: 1.988767885392712

Epoch: 132| Step: 0
Training loss: 2.382176160812378
Validation loss: 1.962818976371519

Epoch: 5| Step: 1
Training loss: 2.1578452587127686
Validation loss: 1.9432345231374104

Epoch: 5| Step: 2
Training loss: 1.9855711460113525
Validation loss: 1.9358270847669212

Epoch: 5| Step: 3
Training loss: 2.509617328643799
Validation loss: 1.9381933135371054

Epoch: 5| Step: 4
Training loss: 2.579977035522461
Validation loss: 1.9397433970564155

Epoch: 5| Step: 5
Training loss: 2.086066484451294
Validation loss: 1.951787055179637

Epoch: 5| Step: 6
Training loss: 2.5546607971191406
Validation loss: 1.9650082331831737

Epoch: 5| Step: 7
Training loss: 1.818537950515747
Validation loss: 2.0042659441630044

Epoch: 5| Step: 8
Training loss: 1.2238988876342773
Validation loss: 2.028032748929916

Epoch: 5| Step: 9
Training loss: 1.875380516052246
Validation loss: 2.0493769978964202

Epoch: 5| Step: 10
Training loss: 1.1312918663024902
Validation loss: 2.0410172272753972

Epoch: 133| Step: 0
Training loss: 2.544652223587036
Validation loss: 2.025080639828918

Epoch: 5| Step: 1
Training loss: 2.083522319793701
Validation loss: 2.0094730213124263

Epoch: 5| Step: 2
Training loss: 2.417632579803467
Validation loss: 1.9943777361223776

Epoch: 5| Step: 3
Training loss: 2.1372554302215576
Validation loss: 1.974054483957188

Epoch: 5| Step: 4
Training loss: 1.4890015125274658
Validation loss: 1.9697817807556481

Epoch: 5| Step: 5
Training loss: 2.2527294158935547
Validation loss: 1.969718139658692

Epoch: 5| Step: 6
Training loss: 1.6690905094146729
Validation loss: 1.9801820683222946

Epoch: 5| Step: 7
Training loss: 1.5891319513320923
Validation loss: 2.0197885754287883

Epoch: 5| Step: 8
Training loss: 2.1990771293640137
Validation loss: 2.050545302770471

Epoch: 5| Step: 9
Training loss: 1.8037452697753906
Validation loss: 2.053731367152224

Epoch: 5| Step: 10
Training loss: 2.066584348678589
Validation loss: 2.0651437569690008

Epoch: 134| Step: 0
Training loss: 1.797370195388794
Validation loss: 2.0213719491035707

Epoch: 5| Step: 1
Training loss: 1.9921939373016357
Validation loss: 1.9826959179293724

Epoch: 5| Step: 2
Training loss: 2.118516206741333
Validation loss: 1.977052406598163

Epoch: 5| Step: 3
Training loss: 2.033163547515869
Validation loss: 1.9632597995060745

Epoch: 5| Step: 4
Training loss: 1.7707061767578125
Validation loss: 1.9557160536448162

Epoch: 5| Step: 5
Training loss: 2.2706665992736816
Validation loss: 1.9580027364915418

Epoch: 5| Step: 6
Training loss: 2.239436388015747
Validation loss: 1.9677086850648284

Epoch: 5| Step: 7
Training loss: 1.4945582151412964
Validation loss: 1.9874338385879353

Epoch: 5| Step: 8
Training loss: 1.9906418323516846
Validation loss: 2.025537863854439

Epoch: 5| Step: 9
Training loss: 2.506621837615967
Validation loss: 2.0528098370439265

Epoch: 5| Step: 10
Training loss: 1.8613252639770508
Validation loss: 2.0507522424062095

Epoch: 135| Step: 0
Training loss: 2.3156840801239014
Validation loss: 2.009835353461645

Epoch: 5| Step: 1
Training loss: 1.0378888845443726
Validation loss: 1.959212754362373

Epoch: 5| Step: 2
Training loss: 1.900958776473999
Validation loss: 1.9454197076059156

Epoch: 5| Step: 3
Training loss: 1.6011266708374023
Validation loss: 1.9408544955715057

Epoch: 5| Step: 4
Training loss: 2.4572434425354004
Validation loss: 1.9450528262763895

Epoch: 5| Step: 5
Training loss: 2.005815267562866
Validation loss: 1.9536842889683221

Epoch: 5| Step: 6
Training loss: 2.15055513381958
Validation loss: 1.961710044132766

Epoch: 5| Step: 7
Training loss: 2.0441975593566895
Validation loss: 1.9561693668365479

Epoch: 5| Step: 8
Training loss: 1.9063371419906616
Validation loss: 1.9796258993046258

Epoch: 5| Step: 9
Training loss: 2.7650535106658936
Validation loss: 2.003391501724079

Epoch: 5| Step: 10
Training loss: 1.6354169845581055
Validation loss: 2.0033548544811945

Epoch: 136| Step: 0
Training loss: 1.5044692754745483
Validation loss: 2.002548897138206

Epoch: 5| Step: 1
Training loss: 2.3356099128723145
Validation loss: 1.9807272213761524

Epoch: 5| Step: 2
Training loss: 1.749776840209961
Validation loss: 1.9798883981602167

Epoch: 5| Step: 3
Training loss: 1.6548417806625366
Validation loss: 1.9700932156655095

Epoch: 5| Step: 4
Training loss: 2.4184701442718506
Validation loss: 1.9802941353090349

Epoch: 5| Step: 5
Training loss: 1.5213971138000488
Validation loss: 1.993259213304007

Epoch: 5| Step: 6
Training loss: 2.033425807952881
Validation loss: 1.9904844760894775

Epoch: 5| Step: 7
Training loss: 1.7395477294921875
Validation loss: 1.9827776032109414

Epoch: 5| Step: 8
Training loss: 2.3717727661132812
Validation loss: 1.986425971472135

Epoch: 5| Step: 9
Training loss: 2.241727113723755
Validation loss: 1.9785427149905954

Epoch: 5| Step: 10
Training loss: 2.078824043273926
Validation loss: 1.9743372407010806

Epoch: 137| Step: 0
Training loss: 1.7770153284072876
Validation loss: 1.9818233495117517

Epoch: 5| Step: 1
Training loss: 2.0924134254455566
Validation loss: 2.0172616102362193

Epoch: 5| Step: 2
Training loss: 1.9692509174346924
Validation loss: 2.03575647518199

Epoch: 5| Step: 3
Training loss: 1.9708871841430664
Validation loss: 2.0682188951840965

Epoch: 5| Step: 4
Training loss: 1.3346822261810303
Validation loss: 2.0643337183101202

Epoch: 5| Step: 5
Training loss: 3.0647542476654053
Validation loss: 2.036914090956411

Epoch: 5| Step: 6
Training loss: 2.100938558578491
Validation loss: 2.012714206531484

Epoch: 5| Step: 7
Training loss: 2.0756607055664062
Validation loss: 1.9916015953146002

Epoch: 5| Step: 8
Training loss: 1.9339412450790405
Validation loss: 1.9601624524721535

Epoch: 5| Step: 9
Training loss: 1.7306007146835327
Validation loss: 1.9497779684682046

Epoch: 5| Step: 10
Training loss: 1.4991118907928467
Validation loss: 1.9555333481040051

Epoch: 138| Step: 0
Training loss: 1.7793712615966797
Validation loss: 1.9495346494900283

Epoch: 5| Step: 1
Training loss: 2.010974407196045
Validation loss: 1.9527740914334533

Epoch: 5| Step: 2
Training loss: 1.6679598093032837
Validation loss: 1.9683909634108185

Epoch: 5| Step: 3
Training loss: 2.156043529510498
Validation loss: 2.0325924452914985

Epoch: 5| Step: 4
Training loss: 2.262439012527466
Validation loss: 2.037102917189239

Epoch: 5| Step: 5
Training loss: 1.895160436630249
Validation loss: 2.052230264550896

Epoch: 5| Step: 6
Training loss: 1.6824884414672852
Validation loss: 1.98605865047824

Epoch: 5| Step: 7
Training loss: 1.8894933462142944
Validation loss: 1.9701942525884157

Epoch: 5| Step: 8
Training loss: 1.6970593929290771
Validation loss: 1.9572360912958782

Epoch: 5| Step: 9
Training loss: 2.6960253715515137
Validation loss: 1.9465672149453113

Epoch: 5| Step: 10
Training loss: 1.9600852727890015
Validation loss: 1.951197604979238

Epoch: 139| Step: 0
Training loss: 2.0157980918884277
Validation loss: 1.9514836854832147

Epoch: 5| Step: 1
Training loss: 2.605069398880005
Validation loss: 1.9647935833982242

Epoch: 5| Step: 2
Training loss: 1.6759679317474365
Validation loss: 1.9724772668653918

Epoch: 5| Step: 3
Training loss: 2.2355570793151855
Validation loss: 1.9740868870930006

Epoch: 5| Step: 4
Training loss: 1.5056161880493164
Validation loss: 2.00456589780828

Epoch: 5| Step: 5
Training loss: 1.7529592514038086
Validation loss: 2.0177265674837175

Epoch: 5| Step: 6
Training loss: 2.0923562049865723
Validation loss: 2.0447626857347387

Epoch: 5| Step: 7
Training loss: 2.6842269897460938
Validation loss: 2.054082452609975

Epoch: 5| Step: 8
Training loss: 1.6779956817626953
Validation loss: 2.0037915040087957

Epoch: 5| Step: 9
Training loss: 1.4552319049835205
Validation loss: 1.9711565253555134

Epoch: 5| Step: 10
Training loss: 1.8177796602249146
Validation loss: 1.9426744317495694

Epoch: 140| Step: 0
Training loss: 2.133932590484619
Validation loss: 1.9305950467304518

Epoch: 5| Step: 1
Training loss: 1.6243091821670532
Validation loss: 1.9395512765453709

Epoch: 5| Step: 2
Training loss: 2.4177193641662598
Validation loss: 1.967649208602085

Epoch: 5| Step: 3
Training loss: 1.7064129114151
Validation loss: 1.9880231759881462

Epoch: 5| Step: 4
Training loss: 2.32017183303833
Validation loss: 2.0260217702516945

Epoch: 5| Step: 5
Training loss: 1.481684684753418
Validation loss: 2.0591766116439656

Epoch: 5| Step: 6
Training loss: 1.2421026229858398
Validation loss: 2.079144654735442

Epoch: 5| Step: 7
Training loss: 2.3805103302001953
Validation loss: 2.0547419260906916

Epoch: 5| Step: 8
Training loss: 2.18583083152771
Validation loss: 2.001356338941923

Epoch: 5| Step: 9
Training loss: 1.9477922916412354
Validation loss: 1.963037726699665

Epoch: 5| Step: 10
Training loss: 2.062396287918091
Validation loss: 1.9476589477190407

Epoch: 141| Step: 0
Training loss: 1.7012007236480713
Validation loss: 1.9537831224421018

Epoch: 5| Step: 1
Training loss: 1.9209449291229248
Validation loss: 1.9550257703309417

Epoch: 5| Step: 2
Training loss: 2.142747640609741
Validation loss: 1.9578418334325154

Epoch: 5| Step: 3
Training loss: 2.3998427391052246
Validation loss: 1.9632690042577765

Epoch: 5| Step: 4
Training loss: 1.954504370689392
Validation loss: 2.018310546875

Epoch: 5| Step: 5
Training loss: 2.758871078491211
Validation loss: 2.083872773314035

Epoch: 5| Step: 6
Training loss: 2.0168967247009277
Validation loss: 2.1289173146729827

Epoch: 5| Step: 7
Training loss: 1.520532250404358
Validation loss: 2.1310634766855547

Epoch: 5| Step: 8
Training loss: 1.6649805307388306
Validation loss: 2.136683879360076

Epoch: 5| Step: 9
Training loss: 1.8515602350234985
Validation loss: 2.0948771481872885

Epoch: 5| Step: 10
Training loss: 1.804297685623169
Validation loss: 2.0490007438967304

Epoch: 142| Step: 0
Training loss: 2.2704567909240723
Validation loss: 2.0024762307443926

Epoch: 5| Step: 1
Training loss: 1.5493974685668945
Validation loss: 1.9657606886279198

Epoch: 5| Step: 2
Training loss: 2.0598232746124268
Validation loss: 1.93772126782325

Epoch: 5| Step: 3
Training loss: 1.801696538925171
Validation loss: 1.9141148418508551

Epoch: 5| Step: 4
Training loss: 1.9559255838394165
Validation loss: 1.9312519655432752

Epoch: 5| Step: 5
Training loss: 1.8899726867675781
Validation loss: 1.9231886620162635

Epoch: 5| Step: 6
Training loss: 2.0874855518341064
Validation loss: 1.9311675512662498

Epoch: 5| Step: 7
Training loss: 2.3258652687072754
Validation loss: 1.9388940218956239

Epoch: 5| Step: 8
Training loss: 2.1814656257629395
Validation loss: 1.9750498520430697

Epoch: 5| Step: 9
Training loss: 1.5434879064559937
Validation loss: 2.0009347149120864

Epoch: 5| Step: 10
Training loss: 1.6735775470733643
Validation loss: 2.0632074315060853

Epoch: 143| Step: 0
Training loss: 1.690317153930664
Validation loss: 2.1240972626593804

Epoch: 5| Step: 1
Training loss: 2.1558518409729004
Validation loss: 2.1324927114671275

Epoch: 5| Step: 2
Training loss: 1.6981254816055298
Validation loss: 2.1253257566882717

Epoch: 5| Step: 3
Training loss: 1.38741135597229
Validation loss: 2.0949293503197293

Epoch: 5| Step: 4
Training loss: 2.130600690841675
Validation loss: 2.024108789300406

Epoch: 5| Step: 5
Training loss: 2.239710807800293
Validation loss: 1.9829883472893828

Epoch: 5| Step: 6
Training loss: 2.5100936889648438
Validation loss: 1.9578196912683465

Epoch: 5| Step: 7
Training loss: 2.191971778869629
Validation loss: 1.954746897502612

Epoch: 5| Step: 8
Training loss: 1.9743601083755493
Validation loss: 1.9373944549150364

Epoch: 5| Step: 9
Training loss: 1.4275243282318115
Validation loss: 1.9467993244048087

Epoch: 5| Step: 10
Training loss: 1.828245997428894
Validation loss: 1.9280443165891914

Epoch: 144| Step: 0
Training loss: 1.9733402729034424
Validation loss: 1.9293598513449393

Epoch: 5| Step: 1
Training loss: 1.20128333568573
Validation loss: 1.938711284309305

Epoch: 5| Step: 2
Training loss: 1.5347257852554321
Validation loss: 1.930651080223822

Epoch: 5| Step: 3
Training loss: 1.6357892751693726
Validation loss: 1.9526636190311883

Epoch: 5| Step: 4
Training loss: 2.31315016746521
Validation loss: 1.9677984496598602

Epoch: 5| Step: 5
Training loss: 2.3537161350250244
Validation loss: 1.9669172199823524

Epoch: 5| Step: 6
Training loss: 1.6264301538467407
Validation loss: 1.9636940084477907

Epoch: 5| Step: 7
Training loss: 2.1993777751922607
Validation loss: 1.9535826303625619

Epoch: 5| Step: 8
Training loss: 2.5416884422302246
Validation loss: 1.9828196712719497

Epoch: 5| Step: 9
Training loss: 2.0279746055603027
Validation loss: 1.985034183789325

Epoch: 5| Step: 10
Training loss: 1.794159173965454
Validation loss: 1.980712841915828

Epoch: 145| Step: 0
Training loss: 1.6825405359268188
Validation loss: 1.9942712424903788

Epoch: 5| Step: 1
Training loss: 1.9916093349456787
Validation loss: 2.007512838609757

Epoch: 5| Step: 2
Training loss: 1.398587703704834
Validation loss: 1.991672199259522

Epoch: 5| Step: 3
Training loss: 1.8539974689483643
Validation loss: 1.9883982635313464

Epoch: 5| Step: 4
Training loss: 1.6406266689300537
Validation loss: 2.0045986303719143

Epoch: 5| Step: 5
Training loss: 1.953963041305542
Validation loss: 2.017243118696315

Epoch: 5| Step: 6
Training loss: 2.225764513015747
Validation loss: 2.0209327205534904

Epoch: 5| Step: 7
Training loss: 2.419395923614502
Validation loss: 2.0010487571839364

Epoch: 5| Step: 8
Training loss: 2.0272395610809326
Validation loss: 1.9877027132177865

Epoch: 5| Step: 9
Training loss: 1.4763139486312866
Validation loss: 1.9791114804565266

Epoch: 5| Step: 10
Training loss: 2.429058790206909
Validation loss: 1.9753273097417687

Epoch: 146| Step: 0
Training loss: 2.19227933883667
Validation loss: 1.984781765168713

Epoch: 5| Step: 1
Training loss: 1.6846916675567627
Validation loss: 1.989693815990161

Epoch: 5| Step: 2
Training loss: 1.191014051437378
Validation loss: 1.9984944635821926

Epoch: 5| Step: 3
Training loss: 1.7724891901016235
Validation loss: 1.9820076804007254

Epoch: 5| Step: 4
Training loss: 1.335532546043396
Validation loss: 1.9626501785811556

Epoch: 5| Step: 5
Training loss: 2.2461094856262207
Validation loss: 1.9694473640893095

Epoch: 5| Step: 6
Training loss: 1.8856937885284424
Validation loss: 1.9593495707358084

Epoch: 5| Step: 7
Training loss: 2.2206180095672607
Validation loss: 1.9718236038761754

Epoch: 5| Step: 8
Training loss: 1.5707324743270874
Validation loss: 1.984331420672837

Epoch: 5| Step: 9
Training loss: 2.344691514968872
Validation loss: 2.0196770698793474

Epoch: 5| Step: 10
Training loss: 2.3687241077423096
Validation loss: 2.0289296809063164

Epoch: 147| Step: 0
Training loss: 2.0367281436920166
Validation loss: 2.044735831599082

Epoch: 5| Step: 1
Training loss: 1.6962969303131104
Validation loss: 2.0367877432095107

Epoch: 5| Step: 2
Training loss: 2.476097583770752
Validation loss: 2.0143341710490565

Epoch: 5| Step: 3
Training loss: 1.9544849395751953
Validation loss: 1.971678554370839

Epoch: 5| Step: 4
Training loss: 1.4453749656677246
Validation loss: 1.94690078561024

Epoch: 5| Step: 5
Training loss: 2.274329423904419
Validation loss: 1.95450129560245

Epoch: 5| Step: 6
Training loss: 2.3039133548736572
Validation loss: 1.9627053955549836

Epoch: 5| Step: 7
Training loss: 1.6999202966690063
Validation loss: 1.9789953898358088

Epoch: 5| Step: 8
Training loss: 1.7704360485076904
Validation loss: 2.011025974827428

Epoch: 5| Step: 9
Training loss: 1.669816017150879
Validation loss: 2.0307373385275564

Epoch: 5| Step: 10
Training loss: 1.5779026746749878
Validation loss: 2.0785815151788856

Epoch: 148| Step: 0
Training loss: 1.5603067874908447
Validation loss: 2.106488547017497

Epoch: 5| Step: 1
Training loss: 1.4914549589157104
Validation loss: 2.1441463347404235

Epoch: 5| Step: 2
Training loss: 2.3544321060180664
Validation loss: 2.1275197690533054

Epoch: 5| Step: 3
Training loss: 2.1351888179779053
Validation loss: 2.078328868394257

Epoch: 5| Step: 4
Training loss: 1.9789196252822876
Validation loss: 2.01614277080823

Epoch: 5| Step: 5
Training loss: 1.7831770181655884
Validation loss: 1.9599964849410518

Epoch: 5| Step: 6
Training loss: 1.7080650329589844
Validation loss: 1.9636896823042183

Epoch: 5| Step: 7
Training loss: 1.9467636346817017
Validation loss: 1.9324417101439608

Epoch: 5| Step: 8
Training loss: 2.207077741622925
Validation loss: 1.9314001811447965

Epoch: 5| Step: 9
Training loss: 1.7921870946884155
Validation loss: 1.943604064244096

Epoch: 5| Step: 10
Training loss: 1.9701929092407227
Validation loss: 1.968001381043465

Epoch: 149| Step: 0
Training loss: 1.3595407009124756
Validation loss: 2.0044682307909896

Epoch: 5| Step: 1
Training loss: 1.6938269138336182
Validation loss: 2.043019829257842

Epoch: 5| Step: 2
Training loss: 2.564210891723633
Validation loss: 2.048659670737482

Epoch: 5| Step: 3
Training loss: 2.022304058074951
Validation loss: 2.054504020239717

Epoch: 5| Step: 4
Training loss: 1.8356311321258545
Validation loss: 2.046462970395242

Epoch: 5| Step: 5
Training loss: 1.763647437095642
Validation loss: 2.0324550726080455

Epoch: 5| Step: 6
Training loss: 2.192875385284424
Validation loss: 2.0162653666670605

Epoch: 5| Step: 7
Training loss: 1.5073344707489014
Validation loss: 2.0006997277659755

Epoch: 5| Step: 8
Training loss: 1.9468889236450195
Validation loss: 1.98228931555184

Epoch: 5| Step: 9
Training loss: 2.333609104156494
Validation loss: 1.973170647057154

Epoch: 5| Step: 10
Training loss: 1.3360050916671753
Validation loss: 1.9756494581058461

Epoch: 150| Step: 0
Training loss: 1.7359943389892578
Validation loss: 1.984860348445113

Epoch: 5| Step: 1
Training loss: 1.3505170345306396
Validation loss: 1.9919263380830006

Epoch: 5| Step: 2
Training loss: 1.9145931005477905
Validation loss: 2.0082671360302995

Epoch: 5| Step: 3
Training loss: 1.3149566650390625
Validation loss: 2.0117018094626804

Epoch: 5| Step: 4
Training loss: 1.7884231805801392
Validation loss: 2.0298590942095687

Epoch: 5| Step: 5
Training loss: 2.850308656692505
Validation loss: 2.041880293559003

Epoch: 5| Step: 6
Training loss: 2.0720152854919434
Validation loss: 2.0475287642530215

Epoch: 5| Step: 7
Training loss: 2.2184581756591797
Validation loss: 2.044734688215358

Epoch: 5| Step: 8
Training loss: 2.2239420413970947
Validation loss: 2.037465041683566

Epoch: 5| Step: 9
Training loss: 1.7964270114898682
Validation loss: 2.0394687178314372

Epoch: 5| Step: 10
Training loss: 0.9921389222145081
Validation loss: 2.0305447501520955

Testing loss: 2.209004521369934
