Epoch: 1| Step: 0
Training loss: 5.262748718261719
Validation loss: 5.159677500365882

Epoch: 5| Step: 1
Training loss: 5.159417152404785
Validation loss: 5.134003700748567

Epoch: 5| Step: 2
Training loss: 4.895046234130859
Validation loss: 5.108933761555662

Epoch: 5| Step: 3
Training loss: 5.333951950073242
Validation loss: 5.083879347770445

Epoch: 5| Step: 4
Training loss: 5.287934303283691
Validation loss: 5.0568401480233796

Epoch: 5| Step: 5
Training loss: 4.549712657928467
Validation loss: 5.026437872199602

Epoch: 5| Step: 6
Training loss: 4.904193878173828
Validation loss: 4.992624411018946

Epoch: 5| Step: 7
Training loss: 4.193063259124756
Validation loss: 4.954248230944398

Epoch: 5| Step: 8
Training loss: 4.789736747741699
Validation loss: 4.911385679757723

Epoch: 5| Step: 9
Training loss: 3.809300184249878
Validation loss: 4.863496754759101

Epoch: 5| Step: 10
Training loss: 4.669201850891113
Validation loss: 4.809116722435079

Epoch: 2| Step: 0
Training loss: 4.618908882141113
Validation loss: 4.74866553788544

Epoch: 5| Step: 1
Training loss: 4.091894626617432
Validation loss: 4.683451098780478

Epoch: 5| Step: 2
Training loss: 4.6337971687316895
Validation loss: 4.614197884836504

Epoch: 5| Step: 3
Training loss: 4.409605979919434
Validation loss: 4.542023510061284

Epoch: 5| Step: 4
Training loss: 3.620745897293091
Validation loss: 4.467391065371934

Epoch: 5| Step: 5
Training loss: 4.059565544128418
Validation loss: 4.392231546422487

Epoch: 5| Step: 6
Training loss: 3.6812329292297363
Validation loss: 4.323617007142754

Epoch: 5| Step: 7
Training loss: 4.074923038482666
Validation loss: 4.257945173530168

Epoch: 5| Step: 8
Training loss: 4.06403112411499
Validation loss: 4.197294324956914

Epoch: 5| Step: 9
Training loss: 4.8717827796936035
Validation loss: 4.140406454763105

Epoch: 5| Step: 10
Training loss: 4.083903789520264
Validation loss: 4.08421117003246

Epoch: 3| Step: 0
Training loss: 3.8404667377471924
Validation loss: 4.030041122949251

Epoch: 5| Step: 1
Training loss: 3.7839789390563965
Validation loss: 3.976571916252054

Epoch: 5| Step: 2
Training loss: 3.702777862548828
Validation loss: 3.930960516775808

Epoch: 5| Step: 3
Training loss: 3.725451707839966
Validation loss: 3.8932907658238567

Epoch: 5| Step: 4
Training loss: 3.208695650100708
Validation loss: 3.8651387947861866

Epoch: 5| Step: 5
Training loss: 3.071181535720825
Validation loss: 3.839880645916026

Epoch: 5| Step: 6
Training loss: 3.6269309520721436
Validation loss: 3.8101906904610257

Epoch: 5| Step: 7
Training loss: 4.329662322998047
Validation loss: 3.7825378884551344

Epoch: 5| Step: 8
Training loss: 4.205630302429199
Validation loss: 3.7533439795176187

Epoch: 5| Step: 9
Training loss: 3.5075392723083496
Validation loss: 3.72463971055964

Epoch: 5| Step: 10
Training loss: 3.9969778060913086
Validation loss: 3.6961035472090527

Epoch: 4| Step: 0
Training loss: 3.4507575035095215
Validation loss: 3.6666789977781233

Epoch: 5| Step: 1
Training loss: 4.104544639587402
Validation loss: 3.644354510050948

Epoch: 5| Step: 2
Training loss: 2.598707675933838
Validation loss: 3.6255879632888304

Epoch: 5| Step: 3
Training loss: 3.830961227416992
Validation loss: 3.6106343269348145

Epoch: 5| Step: 4
Training loss: 2.8253190517425537
Validation loss: 3.594089941311908

Epoch: 5| Step: 5
Training loss: 3.0821995735168457
Validation loss: 3.575812498728434

Epoch: 5| Step: 6
Training loss: 3.8310210704803467
Validation loss: 3.558370308209491

Epoch: 5| Step: 7
Training loss: 4.821787357330322
Validation loss: 3.547415953810497

Epoch: 5| Step: 8
Training loss: 3.1997244358062744
Validation loss: 3.532688046014437

Epoch: 5| Step: 9
Training loss: 3.25483775138855
Validation loss: 3.521477976152974

Epoch: 5| Step: 10
Training loss: 3.5773112773895264
Validation loss: 3.509179645969022

Epoch: 5| Step: 0
Training loss: 4.006394863128662
Validation loss: 3.496803258055

Epoch: 5| Step: 1
Training loss: 3.8202273845672607
Validation loss: 3.478524079886816

Epoch: 5| Step: 2
Training loss: 4.031319618225098
Validation loss: 3.4600502137214906

Epoch: 5| Step: 3
Training loss: 2.1030707359313965
Validation loss: 3.446981235217023

Epoch: 5| Step: 4
Training loss: 4.128432273864746
Validation loss: 3.4384468627232376

Epoch: 5| Step: 5
Training loss: 3.1657466888427734
Validation loss: 3.4259804243682535

Epoch: 5| Step: 6
Training loss: 2.942021131515503
Validation loss: 3.4130102742102837

Epoch: 5| Step: 7
Training loss: 2.723515510559082
Validation loss: 3.4017401664487776

Epoch: 5| Step: 8
Training loss: 3.5226359367370605
Validation loss: 3.388162113005115

Epoch: 5| Step: 9
Training loss: 3.5342087745666504
Validation loss: 3.374520383855348

Epoch: 5| Step: 10
Training loss: 3.0978810787200928
Validation loss: 3.3596497299850627

Epoch: 6| Step: 0
Training loss: 4.008133888244629
Validation loss: 3.3519332588359876

Epoch: 5| Step: 1
Training loss: 3.306489944458008
Validation loss: 3.3365430985727618

Epoch: 5| Step: 2
Training loss: 3.633671522140503
Validation loss: 3.327419514297157

Epoch: 5| Step: 3
Training loss: 3.588181972503662
Validation loss: 3.3201549232646985

Epoch: 5| Step: 4
Training loss: 5.001309871673584
Validation loss: 3.3081968292113273

Epoch: 5| Step: 5
Training loss: 2.7951653003692627
Validation loss: 3.2914369721566477

Epoch: 5| Step: 6
Training loss: 2.627248764038086
Validation loss: 3.277304267370573

Epoch: 5| Step: 7
Training loss: 1.739745855331421
Validation loss: 3.2675471818575295

Epoch: 5| Step: 8
Training loss: 3.9769606590270996
Validation loss: 3.2604272929571008

Epoch: 5| Step: 9
Training loss: 2.5162980556488037
Validation loss: 3.2501847538896786

Epoch: 5| Step: 10
Training loss: 2.733133316040039
Validation loss: 3.248111573598718

Epoch: 7| Step: 0
Training loss: 3.5288262367248535
Validation loss: 3.231548391362672

Epoch: 5| Step: 1
Training loss: 2.8062005043029785
Validation loss: 3.220371389901766

Epoch: 5| Step: 2
Training loss: 3.346287965774536
Validation loss: 3.2107334393326954

Epoch: 5| Step: 3
Training loss: 2.4978556632995605
Validation loss: 3.2046455721701346

Epoch: 5| Step: 4
Training loss: 3.294482707977295
Validation loss: 3.2004123554434827

Epoch: 5| Step: 5
Training loss: 4.040399551391602
Validation loss: 3.190034863769367

Epoch: 5| Step: 6
Training loss: 3.5134825706481934
Validation loss: 3.1834636657468733

Epoch: 5| Step: 7
Training loss: 3.2939674854278564
Validation loss: 3.178751091803274

Epoch: 5| Step: 8
Training loss: 2.453176498413086
Validation loss: 3.1719630969467985

Epoch: 5| Step: 9
Training loss: 3.04215669631958
Validation loss: 3.1636202540448917

Epoch: 5| Step: 10
Training loss: 3.35783052444458
Validation loss: 3.1532117474463677

Epoch: 8| Step: 0
Training loss: 3.6172378063201904
Validation loss: 3.1590092259068645

Epoch: 5| Step: 1
Training loss: 3.3255786895751953
Validation loss: 3.1325487885423886

Epoch: 5| Step: 2
Training loss: 2.9185681343078613
Validation loss: 3.145259359831451

Epoch: 5| Step: 3
Training loss: 2.545653820037842
Validation loss: 3.1273432034318165

Epoch: 5| Step: 4
Training loss: 3.418334484100342
Validation loss: 3.11303803741291

Epoch: 5| Step: 5
Training loss: 3.089588165283203
Validation loss: 3.1115280094967095

Epoch: 5| Step: 6
Training loss: 3.352919816970825
Validation loss: 3.109851021920481

Epoch: 5| Step: 7
Training loss: 3.181002140045166
Validation loss: 3.1023117752485376

Epoch: 5| Step: 8
Training loss: 3.489053249359131
Validation loss: 3.093738373889718

Epoch: 5| Step: 9
Training loss: 3.0986838340759277
Validation loss: 3.078102106689125

Epoch: 5| Step: 10
Training loss: 2.4067814350128174
Validation loss: 3.0727499992616716

Epoch: 9| Step: 0
Training loss: 3.739919662475586
Validation loss: 3.071143663057717

Epoch: 5| Step: 1
Training loss: 2.159294843673706
Validation loss: 3.0617471074545257

Epoch: 5| Step: 2
Training loss: 2.258183717727661
Validation loss: 3.062332127683906

Epoch: 5| Step: 3
Training loss: 3.1498610973358154
Validation loss: 3.0568149346177296

Epoch: 5| Step: 4
Training loss: 3.795445680618286
Validation loss: 3.055549242163217

Epoch: 5| Step: 5
Training loss: 2.821197748184204
Validation loss: 3.0401649552006877

Epoch: 5| Step: 6
Training loss: 2.8253941535949707
Validation loss: 3.028805261017174

Epoch: 5| Step: 7
Training loss: 3.472344160079956
Validation loss: 3.022044494587888

Epoch: 5| Step: 8
Training loss: 3.068437337875366
Validation loss: 3.0187606478250153

Epoch: 5| Step: 9
Training loss: 3.606513261795044
Validation loss: 3.0110946880873812

Epoch: 5| Step: 10
Training loss: 3.115861177444458
Validation loss: 3.001202949913599

Epoch: 10| Step: 0
Training loss: 3.1697144508361816
Validation loss: 3.0016730216241654

Epoch: 5| Step: 1
Training loss: 3.457273006439209
Validation loss: 3.002573203015071

Epoch: 5| Step: 2
Training loss: 3.362700939178467
Validation loss: 2.9857823694905927

Epoch: 5| Step: 3
Training loss: 3.2794456481933594
Validation loss: 2.9818675236035417

Epoch: 5| Step: 4
Training loss: 2.605379581451416
Validation loss: 2.9930924189988004

Epoch: 5| Step: 5
Training loss: 3.2654929161071777
Validation loss: 2.96900834063048

Epoch: 5| Step: 6
Training loss: 3.494279384613037
Validation loss: 2.972171380955686

Epoch: 5| Step: 7
Training loss: 2.093247652053833
Validation loss: 2.9617108888523553

Epoch: 5| Step: 8
Training loss: 3.079519748687744
Validation loss: 2.95608361049365

Epoch: 5| Step: 9
Training loss: 2.7859997749328613
Validation loss: 2.9554417466604583

Epoch: 5| Step: 10
Training loss: 2.942570686340332
Validation loss: 2.9416591300759265

Epoch: 11| Step: 0
Training loss: 2.2162983417510986
Validation loss: 2.93398743291055

Epoch: 5| Step: 1
Training loss: 2.894552707672119
Validation loss: 2.9356028905478855

Epoch: 5| Step: 2
Training loss: 3.285114288330078
Validation loss: 2.9354052056548414

Epoch: 5| Step: 3
Training loss: 3.8620076179504395
Validation loss: 2.941067090598486

Epoch: 5| Step: 4
Training loss: 3.428335189819336
Validation loss: 2.9241614521190686

Epoch: 5| Step: 5
Training loss: 3.0721747875213623
Validation loss: 2.91646751793482

Epoch: 5| Step: 6
Training loss: 3.1757102012634277
Validation loss: 2.9090673820946806

Epoch: 5| Step: 7
Training loss: 2.4942867755889893
Validation loss: 2.9039597485655095

Epoch: 5| Step: 8
Training loss: 2.9890196323394775
Validation loss: 2.9117496372551046

Epoch: 5| Step: 9
Training loss: 2.9980485439300537
Validation loss: 2.893289601931008

Epoch: 5| Step: 10
Training loss: 2.6303014755249023
Validation loss: 2.8926809346804054

Epoch: 12| Step: 0
Training loss: 2.970745086669922
Validation loss: 2.8926449744932112

Epoch: 5| Step: 1
Training loss: 1.9168834686279297
Validation loss: 2.8861578203016713

Epoch: 5| Step: 2
Training loss: 2.6736738681793213
Validation loss: 2.8893504527307328

Epoch: 5| Step: 3
Training loss: 2.5821616649627686
Validation loss: 2.8936666186137865

Epoch: 5| Step: 4
Training loss: 2.949427843093872
Validation loss: 2.9502838375747844

Epoch: 5| Step: 5
Training loss: 3.7377448081970215
Validation loss: 2.8829361341332875

Epoch: 5| Step: 6
Training loss: 2.8473401069641113
Validation loss: 2.8746672522637153

Epoch: 5| Step: 7
Training loss: 2.8320136070251465
Validation loss: 2.8742178691330778

Epoch: 5| Step: 8
Training loss: 3.7867026329040527
Validation loss: 2.8814780225035963

Epoch: 5| Step: 9
Training loss: 2.9603660106658936
Validation loss: 2.872756322224935

Epoch: 5| Step: 10
Training loss: 3.7462000846862793
Validation loss: 2.862993489029587

Epoch: 13| Step: 0
Training loss: 2.3118882179260254
Validation loss: 2.859453708894791

Epoch: 5| Step: 1
Training loss: 2.6063923835754395
Validation loss: 2.8590222686849613

Epoch: 5| Step: 2
Training loss: 2.874208450317383
Validation loss: 2.865835323128649

Epoch: 5| Step: 3
Training loss: 3.486679792404175
Validation loss: 2.85903194386472

Epoch: 5| Step: 4
Training loss: 3.100511074066162
Validation loss: 2.84324707523469

Epoch: 5| Step: 5
Training loss: 3.4722118377685547
Validation loss: 2.8321372309038715

Epoch: 5| Step: 6
Training loss: 3.5880279541015625
Validation loss: 2.834712915523078

Epoch: 5| Step: 7
Training loss: 2.5232338905334473
Validation loss: 2.8386313325615338

Epoch: 5| Step: 8
Training loss: 2.4669861793518066
Validation loss: 2.844733912457702

Epoch: 5| Step: 9
Training loss: 3.686995029449463
Validation loss: 2.826397988104051

Epoch: 5| Step: 10
Training loss: 2.392019271850586
Validation loss: 2.812001215514316

Epoch: 14| Step: 0
Training loss: 2.8534128665924072
Validation loss: 2.8039763691604778

Epoch: 5| Step: 1
Training loss: 2.52473521232605
Validation loss: 2.796154168344313

Epoch: 5| Step: 2
Training loss: 3.5175392627716064
Validation loss: 2.7915322062789754

Epoch: 5| Step: 3
Training loss: 2.3096187114715576
Validation loss: 2.7908435047313733

Epoch: 5| Step: 4
Training loss: 2.903743028640747
Validation loss: 2.788482019978185

Epoch: 5| Step: 5
Training loss: 2.734780788421631
Validation loss: 2.783672296872703

Epoch: 5| Step: 6
Training loss: 2.9528286457061768
Validation loss: 2.780604129196495

Epoch: 5| Step: 7
Training loss: 2.7202136516571045
Validation loss: 2.775528061774469

Epoch: 5| Step: 8
Training loss: 2.5341832637786865
Validation loss: 2.773929426746984

Epoch: 5| Step: 9
Training loss: 3.4963066577911377
Validation loss: 2.771641767153176

Epoch: 5| Step: 10
Training loss: 3.659423828125
Validation loss: 2.763879901619368

Epoch: 15| Step: 0
Training loss: 3.331416606903076
Validation loss: 2.765806236574727

Epoch: 5| Step: 1
Training loss: 2.699260950088501
Validation loss: 2.757336821607364

Epoch: 5| Step: 2
Training loss: 3.036761999130249
Validation loss: 2.754472053179177

Epoch: 5| Step: 3
Training loss: 2.2429370880126953
Validation loss: 2.7610104058378484

Epoch: 5| Step: 4
Training loss: 2.7165300846099854
Validation loss: 2.7672605617071993

Epoch: 5| Step: 5
Training loss: 2.144233226776123
Validation loss: 2.75747710915022

Epoch: 5| Step: 6
Training loss: 3.2223868370056152
Validation loss: 2.752720868715676

Epoch: 5| Step: 7
Training loss: 3.7541706562042236
Validation loss: 2.7537833747043403

Epoch: 5| Step: 8
Training loss: 2.9023303985595703
Validation loss: 2.747587591089228

Epoch: 5| Step: 9
Training loss: 2.4697015285491943
Validation loss: 2.7418046587256977

Epoch: 5| Step: 10
Training loss: 3.5214810371398926
Validation loss: 2.7402474649490847

Epoch: 16| Step: 0
Training loss: 3.1125810146331787
Validation loss: 2.7372018906377975

Epoch: 5| Step: 1
Training loss: 1.9075618982315063
Validation loss: 2.7400137685960337

Epoch: 5| Step: 2
Training loss: 3.4539284706115723
Validation loss: 2.744625911917738

Epoch: 5| Step: 3
Training loss: 2.9837121963500977
Validation loss: 2.739428581730012

Epoch: 5| Step: 4
Training loss: 3.1282944679260254
Validation loss: 2.736572434825282

Epoch: 5| Step: 5
Training loss: 2.9027199745178223
Validation loss: 2.7283284946154525

Epoch: 5| Step: 6
Training loss: 3.681520938873291
Validation loss: 2.7234677371158393

Epoch: 5| Step: 7
Training loss: 3.0493412017822266
Validation loss: 2.718772436982842

Epoch: 5| Step: 8
Training loss: 2.371328353881836
Validation loss: 2.7164755123917774

Epoch: 5| Step: 9
Training loss: 2.6406898498535156
Validation loss: 2.716423911433066

Epoch: 5| Step: 10
Training loss: 2.4009954929351807
Validation loss: 2.7134211755567983

Epoch: 17| Step: 0
Training loss: 2.652320146560669
Validation loss: 2.713442205100931

Epoch: 5| Step: 1
Training loss: 2.1998066902160645
Validation loss: 2.709653672351632

Epoch: 5| Step: 2
Training loss: 3.4416847229003906
Validation loss: 2.7122520733905096

Epoch: 5| Step: 3
Training loss: 3.2067952156066895
Validation loss: 2.719118610505135

Epoch: 5| Step: 4
Training loss: 3.8508808612823486
Validation loss: 2.734940949306693

Epoch: 5| Step: 5
Training loss: 3.348442554473877
Validation loss: 2.704518938577303

Epoch: 5| Step: 6
Training loss: 2.8379933834075928
Validation loss: 2.6967314340734996

Epoch: 5| Step: 7
Training loss: 2.396440029144287
Validation loss: 2.695249103730725

Epoch: 5| Step: 8
Training loss: 3.214686632156372
Validation loss: 2.6943512321800314

Epoch: 5| Step: 9
Training loss: 2.2124290466308594
Validation loss: 2.6945567310497327

Epoch: 5| Step: 10
Training loss: 2.1113216876983643
Validation loss: 2.697330523562688

Epoch: 18| Step: 0
Training loss: 2.9179575443267822
Validation loss: 2.696342375970656

Epoch: 5| Step: 1
Training loss: 2.790148973464966
Validation loss: 2.691498743590488

Epoch: 5| Step: 2
Training loss: 3.2513251304626465
Validation loss: 2.6849864631570797

Epoch: 5| Step: 3
Training loss: 2.885948657989502
Validation loss: 2.683454321276757

Epoch: 5| Step: 4
Training loss: 2.0885252952575684
Validation loss: 2.680890675513975

Epoch: 5| Step: 5
Training loss: 3.209160327911377
Validation loss: 2.699011738582324

Epoch: 5| Step: 6
Training loss: 3.5314133167266846
Validation loss: 2.692355284126856

Epoch: 5| Step: 7
Training loss: 2.4358468055725098
Validation loss: 2.6857114120196273

Epoch: 5| Step: 8
Training loss: 2.5713143348693848
Validation loss: 2.678785898352182

Epoch: 5| Step: 9
Training loss: 2.7968225479125977
Validation loss: 2.675102713287518

Epoch: 5| Step: 10
Training loss: 2.90877103805542
Validation loss: 2.6748022725505214

Epoch: 19| Step: 0
Training loss: 3.106316089630127
Validation loss: 2.672107465805546

Epoch: 5| Step: 1
Training loss: 3.1934967041015625
Validation loss: 2.6715717213128203

Epoch: 5| Step: 2
Training loss: 2.9082796573638916
Validation loss: 2.6665509439283803

Epoch: 5| Step: 3
Training loss: 2.7010812759399414
Validation loss: 2.6657978847462642

Epoch: 5| Step: 4
Training loss: 2.4650540351867676
Validation loss: 2.66233370893745

Epoch: 5| Step: 5
Training loss: 3.2114784717559814
Validation loss: 2.661062696928619

Epoch: 5| Step: 6
Training loss: 2.7456462383270264
Validation loss: 2.6555766674780075

Epoch: 5| Step: 7
Training loss: 2.9364800453186035
Validation loss: 2.6561055747411584

Epoch: 5| Step: 8
Training loss: 2.847898006439209
Validation loss: 2.6532604335456766

Epoch: 5| Step: 9
Training loss: 2.7815208435058594
Validation loss: 2.6552047601310154

Epoch: 5| Step: 10
Training loss: 2.148268938064575
Validation loss: 2.6565902104941745

Epoch: 20| Step: 0
Training loss: 2.701545238494873
Validation loss: 2.656454170903852

Epoch: 5| Step: 1
Training loss: 3.3038947582244873
Validation loss: 2.654200969203826

Epoch: 5| Step: 2
Training loss: 2.878039598464966
Validation loss: 2.643724315909929

Epoch: 5| Step: 3
Training loss: 2.554478168487549
Validation loss: 2.633416780861475

Epoch: 5| Step: 4
Training loss: 2.811662197113037
Validation loss: 2.632940359013055

Epoch: 5| Step: 5
Training loss: 2.314702272415161
Validation loss: 2.6397810418118715

Epoch: 5| Step: 6
Training loss: 3.0790140628814697
Validation loss: 2.6769646931720037

Epoch: 5| Step: 7
Training loss: 2.575399875640869
Validation loss: 2.670414327293314

Epoch: 5| Step: 8
Training loss: 2.0398733615875244
Validation loss: 2.636717806580246

Epoch: 5| Step: 9
Training loss: 2.8355460166931152
Validation loss: 2.633597863617764

Epoch: 5| Step: 10
Training loss: 4.1787614822387695
Validation loss: 2.6319121135178434

Epoch: 21| Step: 0
Training loss: 3.799708127975464
Validation loss: 2.6260843430795977

Epoch: 5| Step: 1
Training loss: 3.7461953163146973
Validation loss: 2.609705825005808

Epoch: 5| Step: 2
Training loss: 2.6578521728515625
Validation loss: 2.6081723115777455

Epoch: 5| Step: 3
Training loss: 2.1665608882904053
Validation loss: 2.6102874484113467

Epoch: 5| Step: 4
Training loss: 2.2845635414123535
Validation loss: 2.635382031881681

Epoch: 5| Step: 5
Training loss: 3.1907410621643066
Validation loss: 2.619909437753821

Epoch: 5| Step: 6
Training loss: 3.028181552886963
Validation loss: 2.6327449531965357

Epoch: 5| Step: 7
Training loss: 2.6739821434020996
Validation loss: 2.61629972662977

Epoch: 5| Step: 8
Training loss: 2.7387375831604004
Validation loss: 2.604420349162112

Epoch: 5| Step: 9
Training loss: 1.9806076288223267
Validation loss: 2.596820585189327

Epoch: 5| Step: 10
Training loss: 2.463496446609497
Validation loss: 2.597773536559074

Epoch: 22| Step: 0
Training loss: 2.357750415802002
Validation loss: 2.601452899235551

Epoch: 5| Step: 1
Training loss: 3.8139901161193848
Validation loss: 2.6066915809467273

Epoch: 5| Step: 2
Training loss: 2.7647218704223633
Validation loss: 2.605307432913011

Epoch: 5| Step: 3
Training loss: 3.1386256217956543
Validation loss: 2.590534225586922

Epoch: 5| Step: 4
Training loss: 2.165170192718506
Validation loss: 2.602893703727312

Epoch: 5| Step: 5
Training loss: 3.4837539196014404
Validation loss: 2.5972070411969255

Epoch: 5| Step: 6
Training loss: 2.7446539402008057
Validation loss: 2.6004349929030224

Epoch: 5| Step: 7
Training loss: 2.6769144535064697
Validation loss: 2.5962941364575456

Epoch: 5| Step: 8
Training loss: 2.0969951152801514
Validation loss: 2.6063691005911878

Epoch: 5| Step: 9
Training loss: 2.970073699951172
Validation loss: 2.633969704310099

Epoch: 5| Step: 10
Training loss: 2.426473617553711
Validation loss: 2.6471472196681525

Epoch: 23| Step: 0
Training loss: 3.299847364425659
Validation loss: 2.6425133161647345

Epoch: 5| Step: 1
Training loss: 2.711284637451172
Validation loss: 2.6465981621896066

Epoch: 5| Step: 2
Training loss: 2.845050811767578
Validation loss: 2.6521420017365487

Epoch: 5| Step: 3
Training loss: 2.4589223861694336
Validation loss: 2.6351671475236134

Epoch: 5| Step: 4
Training loss: 2.5401852130889893
Validation loss: 2.6245645066743255

Epoch: 5| Step: 5
Training loss: 2.474785327911377
Validation loss: 2.6163014519599175

Epoch: 5| Step: 6
Training loss: 2.6976053714752197
Validation loss: 2.609793593806605

Epoch: 5| Step: 7
Training loss: 3.043806791305542
Validation loss: 2.596354123084776

Epoch: 5| Step: 8
Training loss: 2.8207874298095703
Validation loss: 2.5894368002491612

Epoch: 5| Step: 9
Training loss: 3.1637892723083496
Validation loss: 2.5745046010581394

Epoch: 5| Step: 10
Training loss: 2.59979510307312
Validation loss: 2.569709475322436

Epoch: 24| Step: 0
Training loss: 2.3545889854431152
Validation loss: 2.5638976148379746

Epoch: 5| Step: 1
Training loss: 3.234846591949463
Validation loss: 2.57576685567056

Epoch: 5| Step: 2
Training loss: 2.6799070835113525
Validation loss: 2.585271748163367

Epoch: 5| Step: 3
Training loss: 2.990100622177124
Validation loss: 2.6300817125587055

Epoch: 5| Step: 4
Training loss: 2.4800686836242676
Validation loss: 2.658166762321226

Epoch: 5| Step: 5
Training loss: 2.960081100463867
Validation loss: 2.651251636525636

Epoch: 5| Step: 6
Training loss: 2.7267792224884033
Validation loss: 2.6589526745580856

Epoch: 5| Step: 7
Training loss: 2.525641679763794
Validation loss: 2.6328471142758607

Epoch: 5| Step: 8
Training loss: 3.1295228004455566
Validation loss: 2.609988915022983

Epoch: 5| Step: 9
Training loss: 2.731724500656128
Validation loss: 2.6043739190665622

Epoch: 5| Step: 10
Training loss: 3.094716787338257
Validation loss: 2.6010248994314544

Epoch: 25| Step: 0
Training loss: 2.764932155609131
Validation loss: 2.604395071665446

Epoch: 5| Step: 1
Training loss: 2.8133597373962402
Validation loss: 2.60915231961076

Epoch: 5| Step: 2
Training loss: 3.4208216667175293
Validation loss: 2.6375710579656784

Epoch: 5| Step: 3
Training loss: 3.3249289989471436
Validation loss: 2.6569862570813907

Epoch: 5| Step: 4
Training loss: 2.0437686443328857
Validation loss: 2.6223464165964434

Epoch: 5| Step: 5
Training loss: 2.766590118408203
Validation loss: 2.597051512810492

Epoch: 5| Step: 6
Training loss: 2.4642891883850098
Validation loss: 2.564911621873097

Epoch: 5| Step: 7
Training loss: 2.7746176719665527
Validation loss: 2.5472696288939445

Epoch: 5| Step: 8
Training loss: 3.2930679321289062
Validation loss: 2.549073701263756

Epoch: 5| Step: 9
Training loss: 2.482597827911377
Validation loss: 2.557184506488103

Epoch: 5| Step: 10
Training loss: 2.3225302696228027
Validation loss: 2.565352791099138

Epoch: 26| Step: 0
Training loss: 3.420581102371216
Validation loss: 2.5611934379864763

Epoch: 5| Step: 1
Training loss: 2.8107426166534424
Validation loss: 2.5514891506523214

Epoch: 5| Step: 2
Training loss: 2.922881603240967
Validation loss: 2.538187167977774

Epoch: 5| Step: 3
Training loss: 3.0110225677490234
Validation loss: 2.5279952505583405

Epoch: 5| Step: 4
Training loss: 3.1068975925445557
Validation loss: 2.52149974402561

Epoch: 5| Step: 5
Training loss: 2.1040666103363037
Validation loss: 2.5211843572637087

Epoch: 5| Step: 6
Training loss: 2.2076268196105957
Validation loss: 2.5210151723636094

Epoch: 5| Step: 7
Training loss: 2.8887035846710205
Validation loss: 2.5140973649999148

Epoch: 5| Step: 8
Training loss: 2.3356986045837402
Validation loss: 2.5172454567365747

Epoch: 5| Step: 9
Training loss: 2.4982142448425293
Validation loss: 2.524452009508687

Epoch: 5| Step: 10
Training loss: 2.8491921424865723
Validation loss: 2.522874209188646

Epoch: 27| Step: 0
Training loss: 3.1382648944854736
Validation loss: 2.5215407648394184

Epoch: 5| Step: 1
Training loss: 2.6756699085235596
Validation loss: 2.517256300936463

Epoch: 5| Step: 2
Training loss: 2.508410930633545
Validation loss: 2.517646135822419

Epoch: 5| Step: 3
Training loss: 2.593722105026245
Validation loss: 2.517682777938022

Epoch: 5| Step: 4
Training loss: 2.4116783142089844
Validation loss: 2.523833090259183

Epoch: 5| Step: 5
Training loss: 2.249159097671509
Validation loss: 2.5198703504377797

Epoch: 5| Step: 6
Training loss: 3.0929737091064453
Validation loss: 2.5279970245976604

Epoch: 5| Step: 7
Training loss: 2.703136444091797
Validation loss: 2.5340093848525838

Epoch: 5| Step: 8
Training loss: 3.4106125831604004
Validation loss: 2.521024114342146

Epoch: 5| Step: 9
Training loss: 2.636085271835327
Validation loss: 2.5070857386435232

Epoch: 5| Step: 10
Training loss: 2.494272470474243
Validation loss: 2.5025353482974473

Epoch: 28| Step: 0
Training loss: 2.8236961364746094
Validation loss: 2.5090765389063026

Epoch: 5| Step: 1
Training loss: 3.2055282592773438
Validation loss: 2.514352762570945

Epoch: 5| Step: 2
Training loss: 2.3529186248779297
Validation loss: 2.514164319602392

Epoch: 5| Step: 3
Training loss: 2.767023801803589
Validation loss: 2.5122351466968493

Epoch: 5| Step: 4
Training loss: 2.8425395488739014
Validation loss: 2.509510906793738

Epoch: 5| Step: 5
Training loss: 2.9504640102386475
Validation loss: 2.508274652624643

Epoch: 5| Step: 6
Training loss: 2.1409010887145996
Validation loss: 2.5056133372809297

Epoch: 5| Step: 7
Training loss: 2.6171369552612305
Validation loss: 2.5143095985535653

Epoch: 5| Step: 8
Training loss: 2.3031868934631348
Validation loss: 2.513990884186119

Epoch: 5| Step: 9
Training loss: 3.0280985832214355
Validation loss: 2.506435490423633

Epoch: 5| Step: 10
Training loss: 2.9456186294555664
Validation loss: 2.51007584346238

Epoch: 29| Step: 0
Training loss: 3.2215588092803955
Validation loss: 2.512854887593177

Epoch: 5| Step: 1
Training loss: 2.4189727306365967
Validation loss: 2.526495343895369

Epoch: 5| Step: 2
Training loss: 3.254197359085083
Validation loss: 2.5059449826517413

Epoch: 5| Step: 3
Training loss: 1.9751403331756592
Validation loss: 2.4974709762040006

Epoch: 5| Step: 4
Training loss: 3.0558648109436035
Validation loss: 2.4925153447735693

Epoch: 5| Step: 5
Training loss: 2.386502981185913
Validation loss: 2.491833363809893

Epoch: 5| Step: 6
Training loss: 3.41505765914917
Validation loss: 2.4897898781684136

Epoch: 5| Step: 7
Training loss: 2.0535035133361816
Validation loss: 2.4882918403994654

Epoch: 5| Step: 8
Training loss: 2.9848198890686035
Validation loss: 2.4898639981464674

Epoch: 5| Step: 9
Training loss: 2.753246307373047
Validation loss: 2.4905247803657287

Epoch: 5| Step: 10
Training loss: 2.269709348678589
Validation loss: 2.49151881535848

Epoch: 30| Step: 0
Training loss: 2.730746030807495
Validation loss: 2.5121061468637116

Epoch: 5| Step: 1
Training loss: 3.4734344482421875
Validation loss: 2.58434110559443

Epoch: 5| Step: 2
Training loss: 2.44734787940979
Validation loss: 2.549024312726913

Epoch: 5| Step: 3
Training loss: 2.242988109588623
Validation loss: 2.498394919979957

Epoch: 5| Step: 4
Training loss: 2.2311794757843018
Validation loss: 2.4929829951255553

Epoch: 5| Step: 5
Training loss: 2.37947416305542
Validation loss: 2.4909905515691286

Epoch: 5| Step: 6
Training loss: 2.7958216667175293
Validation loss: 2.484331477072931

Epoch: 5| Step: 7
Training loss: 3.0381462574005127
Validation loss: 2.4820840538188977

Epoch: 5| Step: 8
Training loss: 3.054450273513794
Validation loss: 2.483939032400808

Epoch: 5| Step: 9
Training loss: 2.5909924507141113
Validation loss: 2.517644871947586

Epoch: 5| Step: 10
Training loss: 2.894824743270874
Validation loss: 2.558218474029213

Epoch: 31| Step: 0
Training loss: 2.6324639320373535
Validation loss: 2.5935784104049846

Epoch: 5| Step: 1
Training loss: 2.2492759227752686
Validation loss: 2.6421892463520007

Epoch: 5| Step: 2
Training loss: 2.618622064590454
Validation loss: 2.681271381275628

Epoch: 5| Step: 3
Training loss: 3.9762001037597656
Validation loss: 2.6566634255070842

Epoch: 5| Step: 4
Training loss: 2.815472364425659
Validation loss: 2.5865860651898127

Epoch: 5| Step: 5
Training loss: 1.720948576927185
Validation loss: 2.5486342291678152

Epoch: 5| Step: 6
Training loss: 2.629549026489258
Validation loss: 2.5518142433576685

Epoch: 5| Step: 7
Training loss: 2.2813315391540527
Validation loss: 2.569469395504203

Epoch: 5| Step: 8
Training loss: 2.99816632270813
Validation loss: 2.5777180605037238

Epoch: 5| Step: 9
Training loss: 3.237788438796997
Validation loss: 2.586651115007298

Epoch: 5| Step: 10
Training loss: 3.413113594055176
Validation loss: 2.541275367941908

Epoch: 32| Step: 0
Training loss: 3.3692169189453125
Validation loss: 2.506024017128893

Epoch: 5| Step: 1
Training loss: 2.9045252799987793
Validation loss: 2.4855818440837245

Epoch: 5| Step: 2
Training loss: 2.663910388946533
Validation loss: 2.5000870919996694

Epoch: 5| Step: 3
Training loss: 2.74188494682312
Validation loss: 2.5259903451447845

Epoch: 5| Step: 4
Training loss: 2.7523720264434814
Validation loss: 2.554663453050839

Epoch: 5| Step: 5
Training loss: 2.529033899307251
Validation loss: 2.61981285772016

Epoch: 5| Step: 6
Training loss: 3.2633185386657715
Validation loss: 2.6670725832703295

Epoch: 5| Step: 7
Training loss: 1.9590976238250732
Validation loss: 2.646525054849604

Epoch: 5| Step: 8
Training loss: 2.9238734245300293
Validation loss: 2.632563198766401

Epoch: 5| Step: 9
Training loss: 2.4703707695007324
Validation loss: 2.5717700860833608

Epoch: 5| Step: 10
Training loss: 2.8435041904449463
Validation loss: 2.537717652577226

Epoch: 33| Step: 0
Training loss: 3.5469322204589844
Validation loss: 2.562785545984904

Epoch: 5| Step: 1
Training loss: 1.9428412914276123
Validation loss: 2.5736958390922955

Epoch: 5| Step: 2
Training loss: 2.499570846557617
Validation loss: 2.5951760456126225

Epoch: 5| Step: 3
Training loss: 3.3989810943603516
Validation loss: 2.6110226287636706

Epoch: 5| Step: 4
Training loss: 2.779770612716675
Validation loss: 2.584420883527366

Epoch: 5| Step: 5
Training loss: 2.1160407066345215
Validation loss: 2.5349881495198896

Epoch: 5| Step: 6
Training loss: 2.337705373764038
Validation loss: 2.5275770336069088

Epoch: 5| Step: 7
Training loss: 2.651395082473755
Validation loss: 2.501837220243228

Epoch: 5| Step: 8
Training loss: 2.663731575012207
Validation loss: 2.482366318343788

Epoch: 5| Step: 9
Training loss: 3.172555446624756
Validation loss: 2.4835568128093595

Epoch: 5| Step: 10
Training loss: 3.023707866668701
Validation loss: 2.4739477839521182

Epoch: 34| Step: 0
Training loss: 2.809217929840088
Validation loss: 2.4674648033675326

Epoch: 5| Step: 1
Training loss: 3.015326499938965
Validation loss: 2.46448020012148

Epoch: 5| Step: 2
Training loss: 2.802004337310791
Validation loss: 2.4622685011997016

Epoch: 5| Step: 3
Training loss: 2.8619868755340576
Validation loss: 2.4610505180974163

Epoch: 5| Step: 4
Training loss: 2.6623291969299316
Validation loss: 2.457418580209055

Epoch: 5| Step: 5
Training loss: 2.102041721343994
Validation loss: 2.4528572431174656

Epoch: 5| Step: 6
Training loss: 2.9147000312805176
Validation loss: 2.454360197949153

Epoch: 5| Step: 7
Training loss: 2.1712839603424072
Validation loss: 2.4499046084701375

Epoch: 5| Step: 8
Training loss: 3.0980918407440186
Validation loss: 2.4526350318744616

Epoch: 5| Step: 9
Training loss: 2.6655685901641846
Validation loss: 2.457273160257647

Epoch: 5| Step: 10
Training loss: 2.4053728580474854
Validation loss: 2.4785863686633367

Epoch: 35| Step: 0
Training loss: 2.2264609336853027
Validation loss: 2.4885894867681686

Epoch: 5| Step: 1
Training loss: 3.284956455230713
Validation loss: 2.4835570909643687

Epoch: 5| Step: 2
Training loss: 2.5005176067352295
Validation loss: 2.4945823043905277

Epoch: 5| Step: 3
Training loss: 2.879429340362549
Validation loss: 2.487371849757369

Epoch: 5| Step: 4
Training loss: 2.0620574951171875
Validation loss: 2.456376214181223

Epoch: 5| Step: 5
Training loss: 2.2700533866882324
Validation loss: 2.447371147012198

Epoch: 5| Step: 6
Training loss: 3.2185873985290527
Validation loss: 2.4404306181015505

Epoch: 5| Step: 7
Training loss: 3.1441030502319336
Validation loss: 2.444671628295734

Epoch: 5| Step: 8
Training loss: 2.9098033905029297
Validation loss: 2.454610880985055

Epoch: 5| Step: 9
Training loss: 2.262906312942505
Validation loss: 2.464091744474185

Epoch: 5| Step: 10
Training loss: 2.813154697418213
Validation loss: 2.472595768590127

Epoch: 36| Step: 0
Training loss: 2.761080503463745
Validation loss: 2.47806925799257

Epoch: 5| Step: 1
Training loss: 2.320751667022705
Validation loss: 2.4837567678061863

Epoch: 5| Step: 2
Training loss: 3.286832332611084
Validation loss: 2.488894954804451

Epoch: 5| Step: 3
Training loss: 2.799651861190796
Validation loss: 2.480632625600343

Epoch: 5| Step: 4
Training loss: 3.15407133102417
Validation loss: 2.466474022916568

Epoch: 5| Step: 5
Training loss: 2.8242886066436768
Validation loss: 2.4531198265731975

Epoch: 5| Step: 6
Training loss: 2.4420008659362793
Validation loss: 2.444334158333399

Epoch: 5| Step: 7
Training loss: 2.525163173675537
Validation loss: 2.435008866812593

Epoch: 5| Step: 8
Training loss: 2.56927227973938
Validation loss: 2.43384446636323

Epoch: 5| Step: 9
Training loss: 2.5777151584625244
Validation loss: 2.445258491782732

Epoch: 5| Step: 10
Training loss: 2.154478073120117
Validation loss: 2.469625262803929

Epoch: 37| Step: 0
Training loss: 2.597505569458008
Validation loss: 2.4807497198863695

Epoch: 5| Step: 1
Training loss: 2.5264101028442383
Validation loss: 2.4733599026997886

Epoch: 5| Step: 2
Training loss: 3.2822201251983643
Validation loss: 2.4708108722522693

Epoch: 5| Step: 3
Training loss: 2.6243252754211426
Validation loss: 2.46888300423981

Epoch: 5| Step: 4
Training loss: 2.5558223724365234
Validation loss: 2.4763590981883388

Epoch: 5| Step: 5
Training loss: 2.814643144607544
Validation loss: 2.4646642361917803

Epoch: 5| Step: 6
Training loss: 2.4608051776885986
Validation loss: 2.452958336440466

Epoch: 5| Step: 7
Training loss: 2.9137935638427734
Validation loss: 2.4518028715605378

Epoch: 5| Step: 8
Training loss: 2.938755750656128
Validation loss: 2.4361663377413185

Epoch: 5| Step: 9
Training loss: 2.297940731048584
Validation loss: 2.4352035240460466

Epoch: 5| Step: 10
Training loss: 2.256484270095825
Validation loss: 2.432433892321843

Epoch: 38| Step: 0
Training loss: 3.0508742332458496
Validation loss: 2.4217446978374193

Epoch: 5| Step: 1
Training loss: 2.8596808910369873
Validation loss: 2.424601306197464

Epoch: 5| Step: 2
Training loss: 2.1537082195281982
Validation loss: 2.4250061909357705

Epoch: 5| Step: 3
Training loss: 2.479687213897705
Validation loss: 2.4270132305801555

Epoch: 5| Step: 4
Training loss: 3.0540385246276855
Validation loss: 2.4320451213467504

Epoch: 5| Step: 5
Training loss: 3.045203685760498
Validation loss: 2.4302139628318047

Epoch: 5| Step: 6
Training loss: 1.9329372644424438
Validation loss: 2.4293719953106296

Epoch: 5| Step: 7
Training loss: 2.858827829360962
Validation loss: 2.4237102385490172

Epoch: 5| Step: 8
Training loss: 2.7671854496002197
Validation loss: 2.417875246335101

Epoch: 5| Step: 9
Training loss: 2.8482844829559326
Validation loss: 2.4168333494535057

Epoch: 5| Step: 10
Training loss: 2.2400240898132324
Validation loss: 2.413690003015662

Epoch: 39| Step: 0
Training loss: 2.9435181617736816
Validation loss: 2.4229186939936813

Epoch: 5| Step: 1
Training loss: 2.723250389099121
Validation loss: 2.4276402586249897

Epoch: 5| Step: 2
Training loss: 2.1469578742980957
Validation loss: 2.4437546550586657

Epoch: 5| Step: 3
Training loss: 2.8437161445617676
Validation loss: 2.479507069433889

Epoch: 5| Step: 4
Training loss: 2.8926033973693848
Validation loss: 2.5154783289919616

Epoch: 5| Step: 5
Training loss: 2.4089462757110596
Validation loss: 2.559479295566518

Epoch: 5| Step: 6
Training loss: 2.42038631439209
Validation loss: 2.561775417738063

Epoch: 5| Step: 7
Training loss: 3.5258126258850098
Validation loss: 2.5599801899284444

Epoch: 5| Step: 8
Training loss: 2.021892547607422
Validation loss: 2.574232852587136

Epoch: 5| Step: 9
Training loss: 3.2714850902557373
Validation loss: 2.514420285019823

Epoch: 5| Step: 10
Training loss: 2.450847864151001
Validation loss: 2.458031718448926

Epoch: 40| Step: 0
Training loss: 3.074143886566162
Validation loss: 2.4385818691663843

Epoch: 5| Step: 1
Training loss: 2.721527338027954
Validation loss: 2.4191922628751366

Epoch: 5| Step: 2
Training loss: 2.494799852371216
Validation loss: 2.433429733399422

Epoch: 5| Step: 3
Training loss: 2.8472018241882324
Validation loss: 2.4417965104503017

Epoch: 5| Step: 4
Training loss: 2.9082798957824707
Validation loss: 2.467221442089286

Epoch: 5| Step: 5
Training loss: 2.968278169631958
Validation loss: 2.478989683171754

Epoch: 5| Step: 6
Training loss: 2.3419876098632812
Validation loss: 2.4819771833317255

Epoch: 5| Step: 7
Training loss: 2.527104139328003
Validation loss: 2.4428436576679187

Epoch: 5| Step: 8
Training loss: 2.8598759174346924
Validation loss: 2.4274545228609474

Epoch: 5| Step: 9
Training loss: 2.167539358139038
Validation loss: 2.4153205861327467

Epoch: 5| Step: 10
Training loss: 2.6432104110717773
Validation loss: 2.407973035689323

Epoch: 41| Step: 0
Training loss: 2.4457790851593018
Validation loss: 2.410985639018397

Epoch: 5| Step: 1
Training loss: 2.8002429008483887
Validation loss: 2.409111522859143

Epoch: 5| Step: 2
Training loss: 2.207859992980957
Validation loss: 2.4203040317822526

Epoch: 5| Step: 3
Training loss: 2.7782721519470215
Validation loss: 2.421594842787712

Epoch: 5| Step: 4
Training loss: 2.2580502033233643
Validation loss: 2.4166944360220306

Epoch: 5| Step: 5
Training loss: 3.4030921459198
Validation loss: 2.416262242101854

Epoch: 5| Step: 6
Training loss: 2.3085741996765137
Validation loss: 2.4171218410615

Epoch: 5| Step: 7
Training loss: 2.879364013671875
Validation loss: 2.4145608717395413

Epoch: 5| Step: 8
Training loss: 2.786316156387329
Validation loss: 2.4203306474993305

Epoch: 5| Step: 9
Training loss: 2.252962350845337
Validation loss: 2.419316666100615

Epoch: 5| Step: 10
Training loss: 3.0952584743499756
Validation loss: 2.430944178694038

Epoch: 42| Step: 0
Training loss: 3.0964884757995605
Validation loss: 2.4793509770465154

Epoch: 5| Step: 1
Training loss: 2.4531426429748535
Validation loss: 2.5237413631972445

Epoch: 5| Step: 2
Training loss: 3.0890700817108154
Validation loss: 2.5549160588172173

Epoch: 5| Step: 3
Training loss: 2.189058303833008
Validation loss: 2.565595926777009

Epoch: 5| Step: 4
Training loss: 2.711913585662842
Validation loss: 2.566628761188958

Epoch: 5| Step: 5
Training loss: 2.457068920135498
Validation loss: 2.5273815842084986

Epoch: 5| Step: 6
Training loss: 3.00103497505188
Validation loss: 2.454270093671737

Epoch: 5| Step: 7
Training loss: 2.4991118907928467
Validation loss: 2.4356653100700787

Epoch: 5| Step: 8
Training loss: 2.6549363136291504
Validation loss: 2.434089811899329

Epoch: 5| Step: 9
Training loss: 2.6070141792297363
Validation loss: 2.4340773449149182

Epoch: 5| Step: 10
Training loss: 2.9187872409820557
Validation loss: 2.4500657076476724

Epoch: 43| Step: 0
Training loss: 2.7966549396514893
Validation loss: 2.4702353503114436

Epoch: 5| Step: 1
Training loss: 2.583493709564209
Validation loss: 2.4605299657390964

Epoch: 5| Step: 2
Training loss: 2.586977243423462
Validation loss: 2.4465318213226976

Epoch: 5| Step: 3
Training loss: 1.9569679498672485
Validation loss: 2.4204398534631215

Epoch: 5| Step: 4
Training loss: 2.9809558391571045
Validation loss: 2.4180048652874526

Epoch: 5| Step: 5
Training loss: 2.9198226928710938
Validation loss: 2.414287713266188

Epoch: 5| Step: 6
Training loss: 3.127997875213623
Validation loss: 2.416793497659827

Epoch: 5| Step: 7
Training loss: 2.7290656566619873
Validation loss: 2.4004212041055

Epoch: 5| Step: 8
Training loss: 2.95176362991333
Validation loss: 2.407259330954603

Epoch: 5| Step: 9
Training loss: 2.2976484298706055
Validation loss: 2.408045038100212

Epoch: 5| Step: 10
Training loss: 2.2692251205444336
Validation loss: 2.413900352293445

Epoch: 44| Step: 0
Training loss: 2.240635633468628
Validation loss: 2.426299120790215

Epoch: 5| Step: 1
Training loss: 3.138174533843994
Validation loss: 2.445172602130521

Epoch: 5| Step: 2
Training loss: 1.929979681968689
Validation loss: 2.445048919288061

Epoch: 5| Step: 3
Training loss: 3.1183314323425293
Validation loss: 2.436233987090408

Epoch: 5| Step: 4
Training loss: 2.3574492931365967
Validation loss: 2.4261470558822795

Epoch: 5| Step: 5
Training loss: 3.0680434703826904
Validation loss: 2.427124179819579

Epoch: 5| Step: 6
Training loss: 2.619155168533325
Validation loss: 2.4159701511424077

Epoch: 5| Step: 7
Training loss: 2.804516315460205
Validation loss: 2.415597420866771

Epoch: 5| Step: 8
Training loss: 2.8889756202697754
Validation loss: 2.4089791364567255

Epoch: 5| Step: 9
Training loss: 3.129284381866455
Validation loss: 2.4057699390636977

Epoch: 5| Step: 10
Training loss: 1.6903877258300781
Validation loss: 2.400761778636645

Epoch: 45| Step: 0
Training loss: 2.5797038078308105
Validation loss: 2.39598407283906

Epoch: 5| Step: 1
Training loss: 2.3703274726867676
Validation loss: 2.3861014663532214

Epoch: 5| Step: 2
Training loss: 2.499887466430664
Validation loss: 2.382044728084277

Epoch: 5| Step: 3
Training loss: 2.8831980228424072
Validation loss: 2.376368007352275

Epoch: 5| Step: 4
Training loss: 3.2137038707733154
Validation loss: 2.3787333324391353

Epoch: 5| Step: 5
Training loss: 2.6203837394714355
Validation loss: 2.380511504347606

Epoch: 5| Step: 6
Training loss: 2.413621425628662
Validation loss: 2.381010163214899

Epoch: 5| Step: 7
Training loss: 2.581512212753296
Validation loss: 2.3775906742260022

Epoch: 5| Step: 8
Training loss: 2.5121476650238037
Validation loss: 2.3753218471363025

Epoch: 5| Step: 9
Training loss: 2.934004783630371
Validation loss: 2.375268469574631

Epoch: 5| Step: 10
Training loss: 2.4982192516326904
Validation loss: 2.3708951832145773

Epoch: 46| Step: 0
Training loss: 2.384573459625244
Validation loss: 2.37152607979313

Epoch: 5| Step: 1
Training loss: 2.1676464080810547
Validation loss: 2.370803274134154

Epoch: 5| Step: 2
Training loss: 2.3874876499176025
Validation loss: 2.3696794868797384

Epoch: 5| Step: 3
Training loss: 3.3164939880371094
Validation loss: 2.3699079867332213

Epoch: 5| Step: 4
Training loss: 2.2687814235687256
Validation loss: 2.3674204900700557

Epoch: 5| Step: 5
Training loss: 2.483093500137329
Validation loss: 2.3657248148354153

Epoch: 5| Step: 6
Training loss: 3.01051664352417
Validation loss: 2.3651025628530853

Epoch: 5| Step: 7
Training loss: 2.862062454223633
Validation loss: 2.3613502902369343

Epoch: 5| Step: 8
Training loss: 2.3929524421691895
Validation loss: 2.3621527994832685

Epoch: 5| Step: 9
Training loss: 2.9147350788116455
Validation loss: 2.365986306180236

Epoch: 5| Step: 10
Training loss: 2.935086488723755
Validation loss: 2.3700121474522415

Epoch: 47| Step: 0
Training loss: 3.422860622406006
Validation loss: 2.387158283623316

Epoch: 5| Step: 1
Training loss: 2.9304778575897217
Validation loss: 2.3890419160166094

Epoch: 5| Step: 2
Training loss: 2.6792798042297363
Validation loss: 2.378486330791186

Epoch: 5| Step: 3
Training loss: 2.460848569869995
Validation loss: 2.381511047322263

Epoch: 5| Step: 4
Training loss: 1.7234318256378174
Validation loss: 2.395410842792962

Epoch: 5| Step: 5
Training loss: 2.1170787811279297
Validation loss: 2.4105416420967347

Epoch: 5| Step: 6
Training loss: 3.192101240158081
Validation loss: 2.40680262350267

Epoch: 5| Step: 7
Training loss: 2.9854679107666016
Validation loss: 2.4354159473091044

Epoch: 5| Step: 8
Training loss: 2.618196964263916
Validation loss: 2.4483835594628447

Epoch: 5| Step: 9
Training loss: 2.193408250808716
Validation loss: 2.43563013692056

Epoch: 5| Step: 10
Training loss: 2.8057591915130615
Validation loss: 2.4208912746880644

Epoch: 48| Step: 0
Training loss: 2.6624724864959717
Validation loss: 2.390638074567241

Epoch: 5| Step: 1
Training loss: 2.3002734184265137
Validation loss: 2.370203125861383

Epoch: 5| Step: 2
Training loss: 3.1476848125457764
Validation loss: 2.368153659246301

Epoch: 5| Step: 3
Training loss: 2.797882556915283
Validation loss: 2.3585511715181413

Epoch: 5| Step: 4
Training loss: 2.45013427734375
Validation loss: 2.3556446849658923

Epoch: 5| Step: 5
Training loss: 2.9002163410186768
Validation loss: 2.361657340039489

Epoch: 5| Step: 6
Training loss: 2.864182233810425
Validation loss: 2.368602111775388

Epoch: 5| Step: 7
Training loss: 2.3987104892730713
Validation loss: 2.3640191042295067

Epoch: 5| Step: 8
Training loss: 2.5877747535705566
Validation loss: 2.3597077426090034

Epoch: 5| Step: 9
Training loss: 2.400897741317749
Validation loss: 2.357684381546513

Epoch: 5| Step: 10
Training loss: 2.5599570274353027
Validation loss: 2.3519676885297223

Epoch: 49| Step: 0
Training loss: 3.0877556800842285
Validation loss: 2.3476188721195346

Epoch: 5| Step: 1
Training loss: 2.5816588401794434
Validation loss: 2.3510653946989324

Epoch: 5| Step: 2
Training loss: 2.6539597511291504
Validation loss: 2.353796571813604

Epoch: 5| Step: 3
Training loss: 2.68458890914917
Validation loss: 2.360185594968898

Epoch: 5| Step: 4
Training loss: 2.329178810119629
Validation loss: 2.3602128041687833

Epoch: 5| Step: 5
Training loss: 2.486213207244873
Validation loss: 2.3662744850240727

Epoch: 5| Step: 6
Training loss: 2.4354307651519775
Validation loss: 2.3594246218281407

Epoch: 5| Step: 7
Training loss: 2.110752582550049
Validation loss: 2.3558504017450477

Epoch: 5| Step: 8
Training loss: 2.6890158653259277
Validation loss: 2.350640117481191

Epoch: 5| Step: 9
Training loss: 2.883296012878418
Validation loss: 2.352412657071185

Epoch: 5| Step: 10
Training loss: 2.9126029014587402
Validation loss: 2.349512089965164

Epoch: 50| Step: 0
Training loss: 2.8998756408691406
Validation loss: 2.3470298654289654

Epoch: 5| Step: 1
Training loss: 2.531858444213867
Validation loss: 2.351133261957476

Epoch: 5| Step: 2
Training loss: 2.6330978870391846
Validation loss: 2.342563857314407

Epoch: 5| Step: 3
Training loss: 3.128209114074707
Validation loss: 2.3402053848389657

Epoch: 5| Step: 4
Training loss: 1.9395288228988647
Validation loss: 2.3390345919516777

Epoch: 5| Step: 5
Training loss: 3.0646345615386963
Validation loss: 2.3414244497975996

Epoch: 5| Step: 6
Training loss: 2.787567377090454
Validation loss: 2.337593214486235

Epoch: 5| Step: 7
Training loss: 2.1667256355285645
Validation loss: 2.3369922766121487

Epoch: 5| Step: 8
Training loss: 2.695744037628174
Validation loss: 2.339609028190695

Epoch: 5| Step: 9
Training loss: 2.858309268951416
Validation loss: 2.335353784663703

Epoch: 5| Step: 10
Training loss: 2.007112741470337
Validation loss: 2.3372191126628588

Epoch: 51| Step: 0
Training loss: 1.6742407083511353
Validation loss: 2.342111067105365

Epoch: 5| Step: 1
Training loss: 2.6907293796539307
Validation loss: 2.3490625824979556

Epoch: 5| Step: 2
Training loss: 2.4528732299804688
Validation loss: 2.360143497426023

Epoch: 5| Step: 3
Training loss: 3.2267158031463623
Validation loss: 2.368205237132247

Epoch: 5| Step: 4
Training loss: 2.5257701873779297
Validation loss: 2.3762527511965845

Epoch: 5| Step: 5
Training loss: 3.1003079414367676
Validation loss: 2.379002614687848

Epoch: 5| Step: 6
Training loss: 2.9594550132751465
Validation loss: 2.3654652526301723

Epoch: 5| Step: 7
Training loss: 2.434394359588623
Validation loss: 2.3448899022994505

Epoch: 5| Step: 8
Training loss: 2.3012630939483643
Validation loss: 2.3407603925274265

Epoch: 5| Step: 9
Training loss: 2.2097339630126953
Validation loss: 2.3328444880823933

Epoch: 5| Step: 10
Training loss: 3.2950427532196045
Validation loss: 2.333793588863906

Epoch: 52| Step: 0
Training loss: 2.533869743347168
Validation loss: 2.330184144358481

Epoch: 5| Step: 1
Training loss: 2.936819553375244
Validation loss: 2.3339075939629668

Epoch: 5| Step: 2
Training loss: 2.28181529045105
Validation loss: 2.341076215108236

Epoch: 5| Step: 3
Training loss: 1.7837461233139038
Validation loss: 2.3437904439946657

Epoch: 5| Step: 4
Training loss: 2.622948169708252
Validation loss: 2.345163999065276

Epoch: 5| Step: 5
Training loss: 3.0451416969299316
Validation loss: 2.3690362130441973

Epoch: 5| Step: 6
Training loss: 2.766603469848633
Validation loss: 2.388574589965164

Epoch: 5| Step: 7
Training loss: 2.6527962684631348
Validation loss: 2.3748418438819145

Epoch: 5| Step: 8
Training loss: 2.7242159843444824
Validation loss: 2.3529351116508566

Epoch: 5| Step: 9
Training loss: 3.045738697052002
Validation loss: 2.338110295675134

Epoch: 5| Step: 10
Training loss: 2.312389373779297
Validation loss: 2.3322912057240806

Epoch: 53| Step: 0
Training loss: 2.714211940765381
Validation loss: 2.3251965199747393

Epoch: 5| Step: 1
Training loss: 3.055764675140381
Validation loss: 2.3286898930867515

Epoch: 5| Step: 2
Training loss: 2.626988172531128
Validation loss: 2.3248804077025382

Epoch: 5| Step: 3
Training loss: 2.401740312576294
Validation loss: 2.3248664512429187

Epoch: 5| Step: 4
Training loss: 2.105445384979248
Validation loss: 2.3259861597450833

Epoch: 5| Step: 5
Training loss: 2.821895122528076
Validation loss: 2.326938654786797

Epoch: 5| Step: 6
Training loss: 2.8974616527557373
Validation loss: 2.32971538266828

Epoch: 5| Step: 7
Training loss: 2.548654079437256
Validation loss: 2.3461870557518414

Epoch: 5| Step: 8
Training loss: 2.667830228805542
Validation loss: 2.353314315119097

Epoch: 5| Step: 9
Training loss: 2.2509732246398926
Validation loss: 2.366394594151487

Epoch: 5| Step: 10
Training loss: 2.567697048187256
Validation loss: 2.375660527137018

Epoch: 54| Step: 0
Training loss: 2.9031665325164795
Validation loss: 2.3827671158698296

Epoch: 5| Step: 1
Training loss: 2.8061554431915283
Validation loss: 2.391550817797261

Epoch: 5| Step: 2
Training loss: 3.2853050231933594
Validation loss: 2.402212830000026

Epoch: 5| Step: 3
Training loss: 2.2247226238250732
Validation loss: 2.3946893779180383

Epoch: 5| Step: 4
Training loss: 2.014615535736084
Validation loss: 2.3574672950211393

Epoch: 5| Step: 5
Training loss: 2.6769917011260986
Validation loss: 2.3266719848878923

Epoch: 5| Step: 6
Training loss: 2.4896788597106934
Validation loss: 2.3201379314545663

Epoch: 5| Step: 7
Training loss: 2.1099047660827637
Validation loss: 2.3172006837783323

Epoch: 5| Step: 8
Training loss: 2.7177176475524902
Validation loss: 2.3144343924778763

Epoch: 5| Step: 9
Training loss: 2.8411335945129395
Validation loss: 2.3142692837663876

Epoch: 5| Step: 10
Training loss: 2.585278272628784
Validation loss: 2.326527294292245

Epoch: 55| Step: 0
Training loss: 2.3530468940734863
Validation loss: 2.324287273550546

Epoch: 5| Step: 1
Training loss: 2.6500585079193115
Validation loss: 2.3253733265784478

Epoch: 5| Step: 2
Training loss: 2.1275925636291504
Validation loss: 2.3249974173884236

Epoch: 5| Step: 3
Training loss: 2.7608296871185303
Validation loss: 2.3346405798389065

Epoch: 5| Step: 4
Training loss: 2.9784579277038574
Validation loss: 2.350700168199437

Epoch: 5| Step: 5
Training loss: 3.008284330368042
Validation loss: 2.3596197405169086

Epoch: 5| Step: 6
Training loss: 2.9178249835968018
Validation loss: 2.3621564372893302

Epoch: 5| Step: 7
Training loss: 2.2155168056488037
Validation loss: 2.3682437699328185

Epoch: 5| Step: 8
Training loss: 1.7943347692489624
Validation loss: 2.359873423012354

Epoch: 5| Step: 9
Training loss: 2.541555881500244
Validation loss: 2.347150359102475

Epoch: 5| Step: 10
Training loss: 3.388723611831665
Validation loss: 2.3438439881929787

Epoch: 56| Step: 0
Training loss: 2.01540470123291
Validation loss: 2.3328024341214086

Epoch: 5| Step: 1
Training loss: 3.299365997314453
Validation loss: 2.326976107012841

Epoch: 5| Step: 2
Training loss: 2.1405625343322754
Validation loss: 2.3154639710662184

Epoch: 5| Step: 3
Training loss: 2.630018472671509
Validation loss: 2.318173352108207

Epoch: 5| Step: 4
Training loss: 3.235212802886963
Validation loss: 2.321597622286889

Epoch: 5| Step: 5
Training loss: 1.961927056312561
Validation loss: 2.3159674726506716

Epoch: 5| Step: 6
Training loss: 2.5490455627441406
Validation loss: 2.3117709416215138

Epoch: 5| Step: 7
Training loss: 2.85086727142334
Validation loss: 2.3093926675858034

Epoch: 5| Step: 8
Training loss: 2.8474464416503906
Validation loss: 2.310667767319628

Epoch: 5| Step: 9
Training loss: 2.621419906616211
Validation loss: 2.3107284294661654

Epoch: 5| Step: 10
Training loss: 2.346944808959961
Validation loss: 2.3078499301787345

Epoch: 57| Step: 0
Training loss: 2.8813982009887695
Validation loss: 2.305779551946989

Epoch: 5| Step: 1
Training loss: 2.6849286556243896
Validation loss: 2.3065222924755466

Epoch: 5| Step: 2
Training loss: 2.7727293968200684
Validation loss: 2.304841992675617

Epoch: 5| Step: 3
Training loss: 2.7932822704315186
Validation loss: 2.304825036756454

Epoch: 5| Step: 4
Training loss: 2.2313790321350098
Validation loss: 2.308968884970552

Epoch: 5| Step: 5
Training loss: 2.396639585494995
Validation loss: 2.3155632083133986

Epoch: 5| Step: 6
Training loss: 3.071622133255005
Validation loss: 2.330709557379446

Epoch: 5| Step: 7
Training loss: 2.1841750144958496
Validation loss: 2.334142302954069

Epoch: 5| Step: 8
Training loss: 2.180243730545044
Validation loss: 2.3417160869926534

Epoch: 5| Step: 9
Training loss: 2.1870973110198975
Validation loss: 2.329151863692909

Epoch: 5| Step: 10
Training loss: 3.1497139930725098
Validation loss: 2.3158494323812504

Epoch: 58| Step: 0
Training loss: 2.0702779293060303
Validation loss: 2.3022779623667398

Epoch: 5| Step: 1
Training loss: 2.6107566356658936
Validation loss: 2.299472952401766

Epoch: 5| Step: 2
Training loss: 2.973289966583252
Validation loss: 2.300228177860219

Epoch: 5| Step: 3
Training loss: 2.1282057762145996
Validation loss: 2.3002395117154686

Epoch: 5| Step: 4
Training loss: 1.9780991077423096
Validation loss: 2.2958682249951106

Epoch: 5| Step: 5
Training loss: 2.7067160606384277
Validation loss: 2.299435387375534

Epoch: 5| Step: 6
Training loss: 3.2861104011535645
Validation loss: 2.2961816544173868

Epoch: 5| Step: 7
Training loss: 2.7883646488189697
Validation loss: 2.295592677208685

Epoch: 5| Step: 8
Training loss: 2.4504590034484863
Validation loss: 2.2972032293196647

Epoch: 5| Step: 9
Training loss: 3.316838026046753
Validation loss: 2.2964830347286758

Epoch: 5| Step: 10
Training loss: 2.0393550395965576
Validation loss: 2.300942585032473

Epoch: 59| Step: 0
Training loss: 2.11570405960083
Validation loss: 2.307798893220963

Epoch: 5| Step: 1
Training loss: 2.87663197517395
Validation loss: 2.307330749368155

Epoch: 5| Step: 2
Training loss: 2.1810595989227295
Validation loss: 2.3153047869282384

Epoch: 5| Step: 3
Training loss: 2.6131675243377686
Validation loss: 2.306881886656566

Epoch: 5| Step: 4
Training loss: 2.8871426582336426
Validation loss: 2.298806231508973

Epoch: 5| Step: 5
Training loss: 2.503302574157715
Validation loss: 2.298931793500018

Epoch: 5| Step: 6
Training loss: 2.94606876373291
Validation loss: 2.296415267452117

Epoch: 5| Step: 7
Training loss: 2.099402666091919
Validation loss: 2.300139170820995

Epoch: 5| Step: 8
Training loss: 2.5768985748291016
Validation loss: 2.29886063965418

Epoch: 5| Step: 9
Training loss: 2.7819926738739014
Validation loss: 2.298592450798199

Epoch: 5| Step: 10
Training loss: 2.740316152572632
Validation loss: 2.301508326684275

Epoch: 60| Step: 0
Training loss: 2.6263372898101807
Validation loss: 2.30087540482962

Epoch: 5| Step: 1
Training loss: 2.278322219848633
Validation loss: 2.293874407327303

Epoch: 5| Step: 2
Training loss: 2.247150421142578
Validation loss: 2.293192789118777

Epoch: 5| Step: 3
Training loss: 2.663094997406006
Validation loss: 2.293479565651186

Epoch: 5| Step: 4
Training loss: 2.4800708293914795
Validation loss: 2.2897935169999317

Epoch: 5| Step: 5
Training loss: 3.0796585083007812
Validation loss: 2.2937513218131116

Epoch: 5| Step: 6
Training loss: 2.5971620082855225
Validation loss: 2.2948818078605075

Epoch: 5| Step: 7
Training loss: 2.191530466079712
Validation loss: 2.2900694570233746

Epoch: 5| Step: 8
Training loss: 2.154655933380127
Validation loss: 2.2965332692669285

Epoch: 5| Step: 9
Training loss: 3.0356905460357666
Validation loss: 2.3025132584315475

Epoch: 5| Step: 10
Training loss: 2.847486734390259
Validation loss: 2.299262781297007

Epoch: 61| Step: 0
Training loss: 3.6727466583251953
Validation loss: 2.332971724130774

Epoch: 5| Step: 1
Training loss: 2.7546353340148926
Validation loss: 2.3477493665551625

Epoch: 5| Step: 2
Training loss: 2.508697986602783
Validation loss: 2.3432466342885006

Epoch: 5| Step: 3
Training loss: 3.179234743118286
Validation loss: 2.3251639207204184

Epoch: 5| Step: 4
Training loss: 2.634864330291748
Validation loss: 2.3049775990106727

Epoch: 5| Step: 5
Training loss: 2.329876661300659
Validation loss: 2.2874244336158998

Epoch: 5| Step: 6
Training loss: 2.1887505054473877
Validation loss: 2.28243915752698

Epoch: 5| Step: 7
Training loss: 2.125002861022949
Validation loss: 2.289530095233712

Epoch: 5| Step: 8
Training loss: 2.6711370944976807
Validation loss: 2.2906499729361585

Epoch: 5| Step: 9
Training loss: 2.0263848304748535
Validation loss: 2.288254327671502

Epoch: 5| Step: 10
Training loss: 2.1187357902526855
Validation loss: 2.291533770099763

Epoch: 62| Step: 0
Training loss: 2.4046790599823
Validation loss: 2.29732096323403

Epoch: 5| Step: 1
Training loss: 2.2815730571746826
Validation loss: 2.325446682591592

Epoch: 5| Step: 2
Training loss: 2.6127657890319824
Validation loss: 2.359962030123639

Epoch: 5| Step: 3
Training loss: 2.800321102142334
Validation loss: 2.3696590341547483

Epoch: 5| Step: 4
Training loss: 3.1580920219421387
Validation loss: 2.358307905094598

Epoch: 5| Step: 5
Training loss: 2.6440913677215576
Validation loss: 2.3347517623696277

Epoch: 5| Step: 6
Training loss: 2.413296699523926
Validation loss: 2.310318044436875

Epoch: 5| Step: 7
Training loss: 2.129889726638794
Validation loss: 2.3087776348155034

Epoch: 5| Step: 8
Training loss: 2.308405637741089
Validation loss: 2.3199624323075816

Epoch: 5| Step: 9
Training loss: 3.018069267272949
Validation loss: 2.3213217296907978

Epoch: 5| Step: 10
Training loss: 2.6197257041931152
Validation loss: 2.312885526687868

Epoch: 63| Step: 0
Training loss: 2.381331205368042
Validation loss: 2.2848281321987027

Epoch: 5| Step: 1
Training loss: 3.046717405319214
Validation loss: 2.2739030366302817

Epoch: 5| Step: 2
Training loss: 2.106912136077881
Validation loss: 2.268147789021974

Epoch: 5| Step: 3
Training loss: 2.3914718627929688
Validation loss: 2.2707500098853983

Epoch: 5| Step: 4
Training loss: 2.656595230102539
Validation loss: 2.2785861953612296

Epoch: 5| Step: 5
Training loss: 2.6433117389678955
Validation loss: 2.2893325974864345

Epoch: 5| Step: 6
Training loss: 2.4939539432525635
Validation loss: 2.284587219197263

Epoch: 5| Step: 7
Training loss: 2.4452576637268066
Validation loss: 2.2898174819125923

Epoch: 5| Step: 8
Training loss: 2.9794363975524902
Validation loss: 2.291290972822456

Epoch: 5| Step: 9
Training loss: 2.429729461669922
Validation loss: 2.284173619362616

Epoch: 5| Step: 10
Training loss: 2.6847784519195557
Validation loss: 2.279201284531624

Epoch: 64| Step: 0
Training loss: 2.0871376991271973
Validation loss: 2.2778915205309467

Epoch: 5| Step: 1
Training loss: 2.5740795135498047
Validation loss: 2.27113744776736

Epoch: 5| Step: 2
Training loss: 2.6035261154174805
Validation loss: 2.2726252130282822

Epoch: 5| Step: 3
Training loss: 2.6416354179382324
Validation loss: 2.2680546417031238

Epoch: 5| Step: 4
Training loss: 2.1783623695373535
Validation loss: 2.2643161819827173

Epoch: 5| Step: 5
Training loss: 2.8260035514831543
Validation loss: 2.266805220675725

Epoch: 5| Step: 6
Training loss: 2.3862595558166504
Validation loss: 2.272727422816779

Epoch: 5| Step: 7
Training loss: 2.852663278579712
Validation loss: 2.2846653333274265

Epoch: 5| Step: 8
Training loss: 2.4784533977508545
Validation loss: 2.2828406428778045

Epoch: 5| Step: 9
Training loss: 2.8347103595733643
Validation loss: 2.2710682679248113

Epoch: 5| Step: 10
Training loss: 2.606285333633423
Validation loss: 2.2558195462790867

Epoch: 65| Step: 0
Training loss: 2.4207377433776855
Validation loss: 2.259731108142484

Epoch: 5| Step: 1
Training loss: 3.3111796379089355
Validation loss: 2.250790565244613

Epoch: 5| Step: 2
Training loss: 2.7558252811431885
Validation loss: 2.2580567303524224

Epoch: 5| Step: 3
Training loss: 2.219209671020508
Validation loss: 2.2533288719833537

Epoch: 5| Step: 4
Training loss: 2.757143020629883
Validation loss: 2.262145807666163

Epoch: 5| Step: 5
Training loss: 2.3935208320617676
Validation loss: 2.2738816071582097

Epoch: 5| Step: 6
Training loss: 1.0620777606964111
Validation loss: 2.2765208290469263

Epoch: 5| Step: 7
Training loss: 2.6135172843933105
Validation loss: 2.3129981102481967

Epoch: 5| Step: 8
Training loss: 3.258437395095825
Validation loss: 2.3179578268399803

Epoch: 5| Step: 9
Training loss: 2.696218967437744
Validation loss: 2.289964827158118

Epoch: 5| Step: 10
Training loss: 2.5526230335235596
Validation loss: 2.2539131333751063

Epoch: 66| Step: 0
Training loss: 2.2704367637634277
Validation loss: 2.249602779265373

Epoch: 5| Step: 1
Training loss: 2.419780731201172
Validation loss: 2.248287109918492

Epoch: 5| Step: 2
Training loss: 2.2257606983184814
Validation loss: 2.248225114678824

Epoch: 5| Step: 3
Training loss: 2.4364113807678223
Validation loss: 2.256249057349338

Epoch: 5| Step: 4
Training loss: 2.849909543991089
Validation loss: 2.266496942889306

Epoch: 5| Step: 5
Training loss: 2.959200143814087
Validation loss: 2.2782313516063075

Epoch: 5| Step: 6
Training loss: 2.464961528778076
Validation loss: 2.279947398811258

Epoch: 5| Step: 7
Training loss: 2.9251315593719482
Validation loss: 2.294340507958525

Epoch: 5| Step: 8
Training loss: 2.944906711578369
Validation loss: 2.3003076635381228

Epoch: 5| Step: 9
Training loss: 2.404407024383545
Validation loss: 2.2858744744331605

Epoch: 5| Step: 10
Training loss: 2.266690969467163
Validation loss: 2.267535049428222

Epoch: 67| Step: 0
Training loss: 2.9776172637939453
Validation loss: 2.2536264337519163

Epoch: 5| Step: 1
Training loss: 3.106374502182007
Validation loss: 2.244870190979332

Epoch: 5| Step: 2
Training loss: 2.0521042346954346
Validation loss: 2.2436609293824885

Epoch: 5| Step: 3
Training loss: 2.2053630352020264
Validation loss: 2.2467035144887944

Epoch: 5| Step: 4
Training loss: 2.475983142852783
Validation loss: 2.2488666478023736

Epoch: 5| Step: 5
Training loss: 2.785128116607666
Validation loss: 2.254806063508475

Epoch: 5| Step: 6
Training loss: 2.896296739578247
Validation loss: 2.267980706307196

Epoch: 5| Step: 7
Training loss: 2.423410177230835
Validation loss: 2.2704877084301365

Epoch: 5| Step: 8
Training loss: 2.288571834564209
Validation loss: 2.2695382154116066

Epoch: 5| Step: 9
Training loss: 2.489227771759033
Validation loss: 2.2653761832944808

Epoch: 5| Step: 10
Training loss: 2.1238598823547363
Validation loss: 2.2492127649245726

Epoch: 68| Step: 0
Training loss: 2.307317018508911
Validation loss: 2.2379688191157516

Epoch: 5| Step: 1
Training loss: 2.7927322387695312
Validation loss: 2.234947766027143

Epoch: 5| Step: 2
Training loss: 1.6456750631332397
Validation loss: 2.236123546477287

Epoch: 5| Step: 3
Training loss: 1.8370082378387451
Validation loss: 2.233728842068744

Epoch: 5| Step: 4
Training loss: 3.2399742603302
Validation loss: 2.230180328892123

Epoch: 5| Step: 5
Training loss: 3.18076753616333
Validation loss: 2.239417229929278

Epoch: 5| Step: 6
Training loss: 2.774313449859619
Validation loss: 2.239149280773696

Epoch: 5| Step: 7
Training loss: 2.7229931354522705
Validation loss: 2.239176522019089

Epoch: 5| Step: 8
Training loss: 2.2971012592315674
Validation loss: 2.2451634586498304

Epoch: 5| Step: 9
Training loss: 1.9550869464874268
Validation loss: 2.2532932296875985

Epoch: 5| Step: 10
Training loss: 3.217649221420288
Validation loss: 2.2669705947240195

Epoch: 69| Step: 0
Training loss: 2.2180874347686768
Validation loss: 2.239722603110857

Epoch: 5| Step: 1
Training loss: 2.037264347076416
Validation loss: 2.2291022128956293

Epoch: 5| Step: 2
Training loss: 2.9260597229003906
Validation loss: 2.222361692818262

Epoch: 5| Step: 3
Training loss: 2.4137253761291504
Validation loss: 2.2201228974967875

Epoch: 5| Step: 4
Training loss: 2.502624034881592
Validation loss: 2.221623315606066

Epoch: 5| Step: 5
Training loss: 2.7049074172973633
Validation loss: 2.2252750166000856

Epoch: 5| Step: 6
Training loss: 3.236910343170166
Validation loss: 2.2219042572923886

Epoch: 5| Step: 7
Training loss: 2.5635225772857666
Validation loss: 2.2251334267277874

Epoch: 5| Step: 8
Training loss: 1.978681206703186
Validation loss: 2.222230924073086

Epoch: 5| Step: 9
Training loss: 3.3759989738464355
Validation loss: 2.224425285093246

Epoch: 5| Step: 10
Training loss: 1.866888165473938
Validation loss: 2.2220488709788166

Epoch: 70| Step: 0
Training loss: 2.403416156768799
Validation loss: 2.2253495313787974

Epoch: 5| Step: 1
Training loss: 2.438009738922119
Validation loss: 2.2227995613569855

Epoch: 5| Step: 2
Training loss: 2.14788556098938
Validation loss: 2.2288397845401557

Epoch: 5| Step: 3
Training loss: 2.74619722366333
Validation loss: 2.237385512680136

Epoch: 5| Step: 4
Training loss: 2.4942467212677
Validation loss: 2.2411354741742535

Epoch: 5| Step: 5
Training loss: 2.376410722732544
Validation loss: 2.2444479209120556

Epoch: 5| Step: 6
Training loss: 2.9015116691589355
Validation loss: 2.2358504469676683

Epoch: 5| Step: 7
Training loss: 2.6015422344207764
Validation loss: 2.2224177391298356

Epoch: 5| Step: 8
Training loss: 3.1484508514404297
Validation loss: 2.2230838973035096

Epoch: 5| Step: 9
Training loss: 2.2239203453063965
Validation loss: 2.2155847575074885

Epoch: 5| Step: 10
Training loss: 2.2219996452331543
Validation loss: 2.2154444392009447

Epoch: 71| Step: 0
Training loss: 2.6237337589263916
Validation loss: 2.228656256070701

Epoch: 5| Step: 1
Training loss: 2.407271146774292
Validation loss: 2.260203940894014

Epoch: 5| Step: 2
Training loss: 2.69696307182312
Validation loss: 2.288676187556277

Epoch: 5| Step: 3
Training loss: 2.6752676963806152
Validation loss: 2.333020205138832

Epoch: 5| Step: 4
Training loss: 2.082720994949341
Validation loss: 2.3548111018314155

Epoch: 5| Step: 5
Training loss: 2.436941146850586
Validation loss: 2.352941269515663

Epoch: 5| Step: 6
Training loss: 2.6641461849212646
Validation loss: 2.3245091361384236

Epoch: 5| Step: 7
Training loss: 2.3577182292938232
Validation loss: 2.251472544926469

Epoch: 5| Step: 8
Training loss: 2.3899195194244385
Validation loss: 2.218803134015811

Epoch: 5| Step: 9
Training loss: 2.939995765686035
Validation loss: 2.2130439102008777

Epoch: 5| Step: 10
Training loss: 2.612105369567871
Validation loss: 2.2256156936768563

Epoch: 72| Step: 0
Training loss: 2.3202738761901855
Validation loss: 2.2461799985619

Epoch: 5| Step: 1
Training loss: 2.4461464881896973
Validation loss: 2.2699071361172583

Epoch: 5| Step: 2
Training loss: 3.0106701850891113
Validation loss: 2.277592833324145

Epoch: 5| Step: 3
Training loss: 2.5847058296203613
Validation loss: 2.267269085812312

Epoch: 5| Step: 4
Training loss: 2.720452070236206
Validation loss: 2.2517486900411625

Epoch: 5| Step: 5
Training loss: 2.4066295623779297
Validation loss: 2.238470754315776

Epoch: 5| Step: 6
Training loss: 2.771968126296997
Validation loss: 2.2282895426596365

Epoch: 5| Step: 7
Training loss: 2.3384592533111572
Validation loss: 2.2225570063437186

Epoch: 5| Step: 8
Training loss: 2.915153980255127
Validation loss: 2.226817164369809

Epoch: 5| Step: 9
Training loss: 2.393221616744995
Validation loss: 2.2289643133840253

Epoch: 5| Step: 10
Training loss: 2.2329695224761963
Validation loss: 2.2315158177447576

Epoch: 73| Step: 0
Training loss: 2.2786788940429688
Validation loss: 2.2558740851699666

Epoch: 5| Step: 1
Training loss: 2.961697816848755
Validation loss: 2.2801134047969693

Epoch: 5| Step: 2
Training loss: 2.4667670726776123
Validation loss: 2.284952057305203

Epoch: 5| Step: 3
Training loss: 2.4541187286376953
Validation loss: 2.2872035170114167

Epoch: 5| Step: 4
Training loss: 2.177924633026123
Validation loss: 2.2707022800240466

Epoch: 5| Step: 5
Training loss: 2.5265767574310303
Validation loss: 2.2687941674263246

Epoch: 5| Step: 6
Training loss: 3.0496346950531006
Validation loss: 2.2621297041575112

Epoch: 5| Step: 7
Training loss: 2.7749314308166504
Validation loss: 2.260472515577911

Epoch: 5| Step: 8
Training loss: 2.0672154426574707
Validation loss: 2.244931682463615

Epoch: 5| Step: 9
Training loss: 2.6357364654541016
Validation loss: 2.230517646317841

Epoch: 5| Step: 10
Training loss: 2.188016653060913
Validation loss: 2.232175447607553

Epoch: 74| Step: 0
Training loss: 2.497077226638794
Validation loss: 2.218647982484551

Epoch: 5| Step: 1
Training loss: 2.8352298736572266
Validation loss: 2.2106934670479066

Epoch: 5| Step: 2
Training loss: 2.693962812423706
Validation loss: 2.2129279080257622

Epoch: 5| Step: 3
Training loss: 2.090693950653076
Validation loss: 2.2083562625351774

Epoch: 5| Step: 4
Training loss: 2.702089786529541
Validation loss: 2.2051315307617188

Epoch: 5| Step: 5
Training loss: 1.789904236793518
Validation loss: 2.2054796475236134

Epoch: 5| Step: 6
Training loss: 2.2736449241638184
Validation loss: 2.1989793726193008

Epoch: 5| Step: 7
Training loss: 3.003079891204834
Validation loss: 2.2075285168104273

Epoch: 5| Step: 8
Training loss: 2.042513132095337
Validation loss: 2.202370610288394

Epoch: 5| Step: 9
Training loss: 2.997084379196167
Validation loss: 2.2078421397875716

Epoch: 5| Step: 10
Training loss: 2.59513521194458
Validation loss: 2.2064433533658265

Epoch: 75| Step: 0
Training loss: 2.877281904220581
Validation loss: 2.2066649724078435

Epoch: 5| Step: 1
Training loss: 2.4727094173431396
Validation loss: 2.1967624438706266

Epoch: 5| Step: 2
Training loss: 2.104647159576416
Validation loss: 2.194539982785461

Epoch: 5| Step: 3
Training loss: 2.217820167541504
Validation loss: 2.1896115400457896

Epoch: 5| Step: 4
Training loss: 2.5260748863220215
Validation loss: 2.1892006243428876

Epoch: 5| Step: 5
Training loss: 2.391878604888916
Validation loss: 2.1832456447744883

Epoch: 5| Step: 6
Training loss: 2.953226327896118
Validation loss: 2.180521639444495

Epoch: 5| Step: 7
Training loss: 1.975107192993164
Validation loss: 2.1873214257660734

Epoch: 5| Step: 8
Training loss: 2.859387159347534
Validation loss: 2.17768923441569

Epoch: 5| Step: 9
Training loss: 2.853111505508423
Validation loss: 2.1786811787595033

Epoch: 5| Step: 10
Training loss: 2.2091856002807617
Validation loss: 2.1791361249903196

Epoch: 76| Step: 0
Training loss: 2.3454558849334717
Validation loss: 2.1943099767931047

Epoch: 5| Step: 1
Training loss: 2.6121222972869873
Validation loss: 2.1976940990776144

Epoch: 5| Step: 2
Training loss: 2.2229485511779785
Validation loss: 2.200904994882563

Epoch: 5| Step: 3
Training loss: 2.2323269844055176
Validation loss: 2.2152649356472875

Epoch: 5| Step: 4
Training loss: 2.876024007797241
Validation loss: 2.2335333619066464

Epoch: 5| Step: 5
Training loss: 3.034125566482544
Validation loss: 2.253871363978232

Epoch: 5| Step: 6
Training loss: 2.4694950580596924
Validation loss: 2.270661977029616

Epoch: 5| Step: 7
Training loss: 2.8666188716888428
Validation loss: 2.2364536869910454

Epoch: 5| Step: 8
Training loss: 2.386108875274658
Validation loss: 2.204379258617278

Epoch: 5| Step: 9
Training loss: 2.098667621612549
Validation loss: 2.1938393885089504

Epoch: 5| Step: 10
Training loss: 2.3672337532043457
Validation loss: 2.170906397604173

Epoch: 77| Step: 0
Training loss: 2.3920626640319824
Validation loss: 2.1776430222295944

Epoch: 5| Step: 1
Training loss: 2.326941967010498
Validation loss: 2.187357098825516

Epoch: 5| Step: 2
Training loss: 2.574272632598877
Validation loss: 2.199380087596114

Epoch: 5| Step: 3
Training loss: 2.835524320602417
Validation loss: 2.2146054724211335

Epoch: 5| Step: 4
Training loss: 2.669731616973877
Validation loss: 2.220499610388151

Epoch: 5| Step: 5
Training loss: 2.314584493637085
Validation loss: 2.22029294249832

Epoch: 5| Step: 6
Training loss: 2.824509382247925
Validation loss: 2.22148819123545

Epoch: 5| Step: 7
Training loss: 2.391000747680664
Validation loss: 2.2233302439412763

Epoch: 5| Step: 8
Training loss: 2.86027455329895
Validation loss: 2.2215498698654996

Epoch: 5| Step: 9
Training loss: 2.5086777210235596
Validation loss: 2.2042854293700187

Epoch: 5| Step: 10
Training loss: 2.5428502559661865
Validation loss: 2.1998020628447175

Epoch: 78| Step: 0
Training loss: 1.9290443658828735
Validation loss: 2.1905039305328042

Epoch: 5| Step: 1
Training loss: 2.0052096843719482
Validation loss: 2.18001526658253

Epoch: 5| Step: 2
Training loss: 2.7688615322113037
Validation loss: 2.176668285041727

Epoch: 5| Step: 3
Training loss: 2.282701015472412
Validation loss: 2.169357357486602

Epoch: 5| Step: 4
Training loss: 3.259873628616333
Validation loss: 2.169850604508513

Epoch: 5| Step: 5
Training loss: 2.664656162261963
Validation loss: 2.1782519419988

Epoch: 5| Step: 6
Training loss: 2.842510461807251
Validation loss: 2.1786247479018344

Epoch: 5| Step: 7
Training loss: 2.583780527114868
Validation loss: 2.204287523864418

Epoch: 5| Step: 8
Training loss: 2.1774191856384277
Validation loss: 2.2192801685743433

Epoch: 5| Step: 9
Training loss: 2.5458004474639893
Validation loss: 2.2515686301774878

Epoch: 5| Step: 10
Training loss: 2.331925868988037
Validation loss: 2.253688919928766

Epoch: 79| Step: 0
Training loss: 2.249746322631836
Validation loss: 2.2549826457936275

Epoch: 5| Step: 1
Training loss: 2.4793307781219482
Validation loss: 2.2238717514981508

Epoch: 5| Step: 2
Training loss: 3.3207640647888184
Validation loss: 2.1992075968814153

Epoch: 5| Step: 3
Training loss: 1.9510562419891357
Validation loss: 2.1847480343234156

Epoch: 5| Step: 4
Training loss: 2.2985332012176514
Validation loss: 2.18091824746901

Epoch: 5| Step: 5
Training loss: 2.648899555206299
Validation loss: 2.1802671212022022

Epoch: 5| Step: 6
Training loss: 2.3595452308654785
Validation loss: 2.184099672943033

Epoch: 5| Step: 7
Training loss: 2.38447904586792
Validation loss: 2.181755356891181

Epoch: 5| Step: 8
Training loss: 2.6039323806762695
Validation loss: 2.1827317771091255

Epoch: 5| Step: 9
Training loss: 2.521502733230591
Validation loss: 2.179823736990652

Epoch: 5| Step: 10
Training loss: 2.5723328590393066
Validation loss: 2.1705752995706376

Epoch: 80| Step: 0
Training loss: 2.961148500442505
Validation loss: 2.175347546095489

Epoch: 5| Step: 1
Training loss: 2.765636444091797
Validation loss: 2.1751582212345575

Epoch: 5| Step: 2
Training loss: 2.3858346939086914
Validation loss: 2.167961942252292

Epoch: 5| Step: 3
Training loss: 2.0228211879730225
Validation loss: 2.165585933193084

Epoch: 5| Step: 4
Training loss: 2.244374990463257
Validation loss: 2.161761942730155

Epoch: 5| Step: 5
Training loss: 2.5421245098114014
Validation loss: 2.1783552990164807

Epoch: 5| Step: 6
Training loss: 2.0741114616394043
Validation loss: 2.1683411239295878

Epoch: 5| Step: 7
Training loss: 2.499298572540283
Validation loss: 2.16719453565536

Epoch: 5| Step: 8
Training loss: 2.6239891052246094
Validation loss: 2.16713886619896

Epoch: 5| Step: 9
Training loss: 2.422797203063965
Validation loss: 2.1692472298940024

Epoch: 5| Step: 10
Training loss: 2.573214054107666
Validation loss: 2.1698424431585495

Epoch: 81| Step: 0
Training loss: 2.526921510696411
Validation loss: 2.1646269188132337

Epoch: 5| Step: 1
Training loss: 2.6166634559631348
Validation loss: 2.155324835931101

Epoch: 5| Step: 2
Training loss: 2.7250137329101562
Validation loss: 2.1544051875350294

Epoch: 5| Step: 3
Training loss: 2.5095603466033936
Validation loss: 2.1532072354388494

Epoch: 5| Step: 4
Training loss: 2.4177937507629395
Validation loss: 2.1585196102819135

Epoch: 5| Step: 5
Training loss: 2.6724462509155273
Validation loss: 2.1621281434130926

Epoch: 5| Step: 6
Training loss: 2.8844547271728516
Validation loss: 2.153070378047164

Epoch: 5| Step: 7
Training loss: 2.1301400661468506
Validation loss: 2.1587595042362007

Epoch: 5| Step: 8
Training loss: 2.0617287158966064
Validation loss: 2.1596291116488877

Epoch: 5| Step: 9
Training loss: 2.3083884716033936
Validation loss: 2.1745489156374367

Epoch: 5| Step: 10
Training loss: 2.062643051147461
Validation loss: 2.1932439906622774

Epoch: 82| Step: 0
Training loss: 2.508960485458374
Validation loss: 2.177889036875899

Epoch: 5| Step: 1
Training loss: 2.1207594871520996
Validation loss: 2.157193463335755

Epoch: 5| Step: 2
Training loss: 2.4333672523498535
Validation loss: 2.143286176907119

Epoch: 5| Step: 3
Training loss: 1.9221922159194946
Validation loss: 2.138561466688751

Epoch: 5| Step: 4
Training loss: 2.5805156230926514
Validation loss: 2.138828462170016

Epoch: 5| Step: 5
Training loss: 2.234198570251465
Validation loss: 2.1375557171401156

Epoch: 5| Step: 6
Training loss: 2.617488145828247
Validation loss: 2.1427013912508563

Epoch: 5| Step: 7
Training loss: 2.4984970092773438
Validation loss: 2.1413297935198714

Epoch: 5| Step: 8
Training loss: 2.643780469894409
Validation loss: 2.149239686227614

Epoch: 5| Step: 9
Training loss: 2.83196759223938
Validation loss: 2.154868710425592

Epoch: 5| Step: 10
Training loss: 2.663760185241699
Validation loss: 2.1614974596167125

Epoch: 83| Step: 0
Training loss: 2.6882636547088623
Validation loss: 2.172679844722953

Epoch: 5| Step: 1
Training loss: 2.770209550857544
Validation loss: 2.1770996919242283

Epoch: 5| Step: 2
Training loss: 1.8501449823379517
Validation loss: 2.1684311384795816

Epoch: 5| Step: 3
Training loss: 2.173490047454834
Validation loss: 2.1618784627606793

Epoch: 5| Step: 4
Training loss: 2.659787654876709
Validation loss: 2.1531143521749847

Epoch: 5| Step: 5
Training loss: 2.2578892707824707
Validation loss: 2.1499075094858804

Epoch: 5| Step: 6
Training loss: 2.361017942428589
Validation loss: 2.141921184396231

Epoch: 5| Step: 7
Training loss: 3.055271863937378
Validation loss: 2.1395324814704155

Epoch: 5| Step: 8
Training loss: 2.3455843925476074
Validation loss: 2.14110557750989

Epoch: 5| Step: 9
Training loss: 2.404435157775879
Validation loss: 2.14073775147879

Epoch: 5| Step: 10
Training loss: 2.272463083267212
Validation loss: 2.147264563909141

Epoch: 84| Step: 0
Training loss: 1.429041862487793
Validation loss: 2.1479513132443993

Epoch: 5| Step: 1
Training loss: 2.613431930541992
Validation loss: 2.158513133243848

Epoch: 5| Step: 2
Training loss: 3.0490221977233887
Validation loss: 2.1891237381965882

Epoch: 5| Step: 3
Training loss: 2.6087212562561035
Validation loss: 2.17262274988236

Epoch: 5| Step: 4
Training loss: 2.925894260406494
Validation loss: 2.1425997287996355

Epoch: 5| Step: 5
Training loss: 2.1028807163238525
Validation loss: 2.1344549886641966

Epoch: 5| Step: 6
Training loss: 2.438203811645508
Validation loss: 2.128239167633877

Epoch: 5| Step: 7
Training loss: 2.381887674331665
Validation loss: 2.128490876126033

Epoch: 5| Step: 8
Training loss: 2.5791773796081543
Validation loss: 2.1271566370482087

Epoch: 5| Step: 9
Training loss: 2.7616355419158936
Validation loss: 2.1337411480565227

Epoch: 5| Step: 10
Training loss: 2.1287736892700195
Validation loss: 2.133225187178581

Epoch: 85| Step: 0
Training loss: 2.477149248123169
Validation loss: 2.128931153205133

Epoch: 5| Step: 1
Training loss: 2.229279041290283
Validation loss: 2.1261241179640575

Epoch: 5| Step: 2
Training loss: 2.6132194995880127
Validation loss: 2.124182698547199

Epoch: 5| Step: 3
Training loss: 2.3856711387634277
Validation loss: 2.124721828327384

Epoch: 5| Step: 4
Training loss: 2.401721954345703
Validation loss: 2.1382491844956593

Epoch: 5| Step: 5
Training loss: 2.8504669666290283
Validation loss: 2.1558850734464583

Epoch: 5| Step: 6
Training loss: 2.695817470550537
Validation loss: 2.177275534599058

Epoch: 5| Step: 7
Training loss: 2.8544135093688965
Validation loss: 2.2148924463538715

Epoch: 5| Step: 8
Training loss: 2.180891752243042
Validation loss: 2.2138764371154127

Epoch: 5| Step: 9
Training loss: 2.4809422492980957
Validation loss: 2.1887505285201536

Epoch: 5| Step: 10
Training loss: 1.7599540948867798
Validation loss: 2.1739933695844424

Epoch: 86| Step: 0
Training loss: 2.2406859397888184
Validation loss: 2.160358662246376

Epoch: 5| Step: 1
Training loss: 2.4907681941986084
Validation loss: 2.1547385364450435

Epoch: 5| Step: 2
Training loss: 2.474364757537842
Validation loss: 2.147186307496922

Epoch: 5| Step: 3
Training loss: 2.1020960807800293
Validation loss: 2.1424054535486365

Epoch: 5| Step: 4
Training loss: 2.791226863861084
Validation loss: 2.1578853514886673

Epoch: 5| Step: 5
Training loss: 2.407104969024658
Validation loss: 2.1590898190775225

Epoch: 5| Step: 6
Training loss: 3.062598705291748
Validation loss: 2.1623603349090903

Epoch: 5| Step: 7
Training loss: 2.5523529052734375
Validation loss: 2.1548323913287093

Epoch: 5| Step: 8
Training loss: 2.205028772354126
Validation loss: 2.1354475790454495

Epoch: 5| Step: 9
Training loss: 2.251873731613159
Validation loss: 2.1235881825929046

Epoch: 5| Step: 10
Training loss: 2.451650619506836
Validation loss: 2.1178335758947555

Epoch: 87| Step: 0
Training loss: 2.480372190475464
Validation loss: 2.1269875252118675

Epoch: 5| Step: 1
Training loss: 3.2730064392089844
Validation loss: 2.1514933698920795

Epoch: 5| Step: 2
Training loss: 2.309875011444092
Validation loss: 2.1723805909515708

Epoch: 5| Step: 3
Training loss: 2.3003201484680176
Validation loss: 2.1854698093988563

Epoch: 5| Step: 4
Training loss: 2.7572243213653564
Validation loss: 2.1583233943549534

Epoch: 5| Step: 5
Training loss: 2.2861063480377197
Validation loss: 2.1364066139344247

Epoch: 5| Step: 6
Training loss: 2.8240113258361816
Validation loss: 2.118668204994612

Epoch: 5| Step: 7
Training loss: 2.2499659061431885
Validation loss: 2.1060256329915856

Epoch: 5| Step: 8
Training loss: 2.2621307373046875
Validation loss: 2.107923159035303

Epoch: 5| Step: 9
Training loss: 2.34920072555542
Validation loss: 2.1016519249126477

Epoch: 5| Step: 10
Training loss: 1.7280335426330566
Validation loss: 2.103019304172967

Epoch: 88| Step: 0
Training loss: 1.9308137893676758
Validation loss: 2.1107649457070137

Epoch: 5| Step: 1
Training loss: 3.0200862884521484
Validation loss: 2.1044308562432565

Epoch: 5| Step: 2
Training loss: 1.8908792734146118
Validation loss: 2.1051335539869083

Epoch: 5| Step: 3
Training loss: 2.5517239570617676
Validation loss: 2.1089666581922963

Epoch: 5| Step: 4
Training loss: 2.9257943630218506
Validation loss: 2.115225807312996

Epoch: 5| Step: 5
Training loss: 2.4830985069274902
Validation loss: 2.1211807855995755

Epoch: 5| Step: 6
Training loss: 3.0276503562927246
Validation loss: 2.1115943116526448

Epoch: 5| Step: 7
Training loss: 2.137187957763672
Validation loss: 2.108359479135083

Epoch: 5| Step: 8
Training loss: 1.9941539764404297
Validation loss: 2.118418865306403

Epoch: 5| Step: 9
Training loss: 2.4662787914276123
Validation loss: 2.1137001591344036

Epoch: 5| Step: 10
Training loss: 2.062509059906006
Validation loss: 2.1147879567197574

Epoch: 89| Step: 0
Training loss: 1.7182466983795166
Validation loss: 2.1078496620219243

Epoch: 5| Step: 1
Training loss: 2.511754274368286
Validation loss: 2.107832552284323

Epoch: 5| Step: 2
Training loss: 2.030101776123047
Validation loss: 2.0992711397909347

Epoch: 5| Step: 3
Training loss: 2.7957804203033447
Validation loss: 2.100053289885162

Epoch: 5| Step: 4
Training loss: 2.5275673866271973
Validation loss: 2.1002407702066566

Epoch: 5| Step: 5
Training loss: 2.0339574813842773
Validation loss: 2.09209603904396

Epoch: 5| Step: 6
Training loss: 2.2339675426483154
Validation loss: 2.090939211589034

Epoch: 5| Step: 7
Training loss: 2.53157639503479
Validation loss: 2.092771404532976

Epoch: 5| Step: 8
Training loss: 3.1371378898620605
Validation loss: 2.10333110824708

Epoch: 5| Step: 9
Training loss: 2.3046841621398926
Validation loss: 2.105191174373832

Epoch: 5| Step: 10
Training loss: 2.70560622215271
Validation loss: 2.1019944426833943

Epoch: 90| Step: 0
Training loss: 2.372069835662842
Validation loss: 2.0990866204743743

Epoch: 5| Step: 1
Training loss: 2.396355152130127
Validation loss: 2.097258698555731

Epoch: 5| Step: 2
Training loss: 2.4169037342071533
Validation loss: 2.0926932980937343

Epoch: 5| Step: 3
Training loss: 2.4202704429626465
Validation loss: 2.094059569861299

Epoch: 5| Step: 4
Training loss: 1.9012229442596436
Validation loss: 2.092160863261069

Epoch: 5| Step: 5
Training loss: 1.8493778705596924
Validation loss: 2.09504024956816

Epoch: 5| Step: 6
Training loss: 2.4365897178649902
Validation loss: 2.103028764006912

Epoch: 5| Step: 7
Training loss: 2.675344944000244
Validation loss: 2.104475854545511

Epoch: 5| Step: 8
Training loss: 2.6346330642700195
Validation loss: 2.114599673978744

Epoch: 5| Step: 9
Training loss: 2.383485794067383
Validation loss: 2.1117229538579143

Epoch: 5| Step: 10
Training loss: 3.0539417266845703
Validation loss: 2.112746693754709

Epoch: 91| Step: 0
Training loss: 2.7083797454833984
Validation loss: 2.1049612722089215

Epoch: 5| Step: 1
Training loss: 1.9441406726837158
Validation loss: 2.099514748460503

Epoch: 5| Step: 2
Training loss: 2.2323763370513916
Validation loss: 2.0941423498174196

Epoch: 5| Step: 3
Training loss: 1.8580939769744873
Validation loss: 2.0899901364439275

Epoch: 5| Step: 4
Training loss: 2.5933938026428223
Validation loss: 2.0797593234687723

Epoch: 5| Step: 5
Training loss: 2.3284826278686523
Validation loss: 2.082890227276792

Epoch: 5| Step: 6
Training loss: 1.664025902748108
Validation loss: 2.093880808481606

Epoch: 5| Step: 7
Training loss: 2.7455174922943115
Validation loss: 2.0917510486418203

Epoch: 5| Step: 8
Training loss: 3.1330370903015137
Validation loss: 2.087546112716839

Epoch: 5| Step: 9
Training loss: 2.285100221633911
Validation loss: 2.0928133405664915

Epoch: 5| Step: 10
Training loss: 2.939936399459839
Validation loss: 2.096359993821831

Epoch: 92| Step: 0
Training loss: 2.4880573749542236
Validation loss: 2.1202660863117506

Epoch: 5| Step: 1
Training loss: 2.488678455352783
Validation loss: 2.1169608126404467

Epoch: 5| Step: 2
Training loss: 2.2754788398742676
Validation loss: 2.1046945664190475

Epoch: 5| Step: 3
Training loss: 2.528757095336914
Validation loss: 2.0976989679439093

Epoch: 5| Step: 4
Training loss: 3.0030791759490967
Validation loss: 2.090464574034496

Epoch: 5| Step: 5
Training loss: 1.6742233037948608
Validation loss: 2.0839930542053713

Epoch: 5| Step: 6
Training loss: 2.6558518409729004
Validation loss: 2.090953178303216

Epoch: 5| Step: 7
Training loss: 2.8700244426727295
Validation loss: 2.0767698313600276

Epoch: 5| Step: 8
Training loss: 2.0411362648010254
Validation loss: 2.0782440913620817

Epoch: 5| Step: 9
Training loss: 1.756376028060913
Validation loss: 2.0801191765774965

Epoch: 5| Step: 10
Training loss: 2.582484245300293
Validation loss: 2.0711212106930312

Epoch: 93| Step: 0
Training loss: 2.073556423187256
Validation loss: 2.0795200691428235

Epoch: 5| Step: 1
Training loss: 2.1300532817840576
Validation loss: 2.0803737768562893

Epoch: 5| Step: 2
Training loss: 2.2395577430725098
Validation loss: 2.0832340153314735

Epoch: 5| Step: 3
Training loss: 2.2717976570129395
Validation loss: 2.0920677236331406

Epoch: 5| Step: 4
Training loss: 2.257354259490967
Validation loss: 2.0924200037474274

Epoch: 5| Step: 5
Training loss: 2.437180519104004
Validation loss: 2.0966840456890803

Epoch: 5| Step: 6
Training loss: 2.3758420944213867
Validation loss: 2.1044229640755603

Epoch: 5| Step: 7
Training loss: 2.554198980331421
Validation loss: 2.0918538980586554

Epoch: 5| Step: 8
Training loss: 2.4021480083465576
Validation loss: 2.0989084859048166

Epoch: 5| Step: 9
Training loss: 3.1046457290649414
Validation loss: 2.089245514203143

Epoch: 5| Step: 10
Training loss: 2.288515090942383
Validation loss: 2.089885829597391

Epoch: 94| Step: 0
Training loss: 2.4186489582061768
Validation loss: 2.0798740040871406

Epoch: 5| Step: 1
Training loss: 1.9739320278167725
Validation loss: 2.0782446553630214

Epoch: 5| Step: 2
Training loss: 1.9538494348526
Validation loss: 2.0700690002851587

Epoch: 5| Step: 3
Training loss: 2.246910810470581
Validation loss: 2.07215053291731

Epoch: 5| Step: 4
Training loss: 2.28523588180542
Validation loss: 2.068846087301931

Epoch: 5| Step: 5
Training loss: 2.304386615753174
Validation loss: 2.067920284886514

Epoch: 5| Step: 6
Training loss: 2.587855815887451
Validation loss: 2.07133452610303

Epoch: 5| Step: 7
Training loss: 2.388685703277588
Validation loss: 2.0753257633537374

Epoch: 5| Step: 8
Training loss: 3.1775050163269043
Validation loss: 2.077012114627387

Epoch: 5| Step: 9
Training loss: 2.2358968257904053
Validation loss: 2.084633914373254

Epoch: 5| Step: 10
Training loss: 2.5092179775238037
Validation loss: 2.0870226121717885

Epoch: 95| Step: 0
Training loss: 1.9899165630340576
Validation loss: 2.094175778409486

Epoch: 5| Step: 1
Training loss: 2.168238401412964
Validation loss: 2.0982653812695573

Epoch: 5| Step: 2
Training loss: 2.0799028873443604
Validation loss: 2.089637311556006

Epoch: 5| Step: 3
Training loss: 3.1691441535949707
Validation loss: 2.0979252130754533

Epoch: 5| Step: 4
Training loss: 2.4822068214416504
Validation loss: 2.091156680096862

Epoch: 5| Step: 5
Training loss: 2.3339245319366455
Validation loss: 2.091788850804811

Epoch: 5| Step: 6
Training loss: 2.4803643226623535
Validation loss: 2.0891149659310617

Epoch: 5| Step: 7
Training loss: 2.198136806488037
Validation loss: 2.0814109451027325

Epoch: 5| Step: 8
Training loss: 2.486342668533325
Validation loss: 2.075833643636396

Epoch: 5| Step: 9
Training loss: 1.8870102167129517
Validation loss: 2.076228021293558

Epoch: 5| Step: 10
Training loss: 2.739645004272461
Validation loss: 2.0683603812289495

Epoch: 96| Step: 0
Training loss: 2.519272565841675
Validation loss: 2.0758073804199055

Epoch: 5| Step: 1
Training loss: 2.488041877746582
Validation loss: 2.0667930956809752

Epoch: 5| Step: 2
Training loss: 2.182051181793213
Validation loss: 2.0587377804581837

Epoch: 5| Step: 3
Training loss: 2.633098840713501
Validation loss: 2.0680173058663645

Epoch: 5| Step: 4
Training loss: 2.0560731887817383
Validation loss: 2.06275357994982

Epoch: 5| Step: 5
Training loss: 2.2035865783691406
Validation loss: 2.0664685362128803

Epoch: 5| Step: 6
Training loss: 2.732445240020752
Validation loss: 2.0749686200131654

Epoch: 5| Step: 7
Training loss: 2.250422954559326
Validation loss: 2.0706521247022893

Epoch: 5| Step: 8
Training loss: 2.38814115524292
Validation loss: 2.0807217961998394

Epoch: 5| Step: 9
Training loss: 2.1073403358459473
Validation loss: 2.079550522629933

Epoch: 5| Step: 10
Training loss: 2.4650440216064453
Validation loss: 2.0918428897857666

Epoch: 97| Step: 0
Training loss: 2.290750741958618
Validation loss: 2.104889485143846

Epoch: 5| Step: 1
Training loss: 2.5661208629608154
Validation loss: 2.0929348661053564

Epoch: 5| Step: 2
Training loss: 2.0880253314971924
Validation loss: 2.078811830089938

Epoch: 5| Step: 3
Training loss: 2.4684994220733643
Validation loss: 2.0784845608536915

Epoch: 5| Step: 4
Training loss: 2.237957000732422
Validation loss: 2.06912895171873

Epoch: 5| Step: 5
Training loss: 2.4826598167419434
Validation loss: 2.066848806155625

Epoch: 5| Step: 6
Training loss: 2.2884554862976074
Validation loss: 2.0565925285380375

Epoch: 5| Step: 7
Training loss: 3.016913890838623
Validation loss: 2.0563703339586974

Epoch: 5| Step: 8
Training loss: 1.9665610790252686
Validation loss: 2.0529798974273024

Epoch: 5| Step: 9
Training loss: 2.6071808338165283
Validation loss: 2.057621358543314

Epoch: 5| Step: 10
Training loss: 1.8636441230773926
Validation loss: 2.063799160783009

Epoch: 98| Step: 0
Training loss: 2.5175633430480957
Validation loss: 2.0676717001904725

Epoch: 5| Step: 1
Training loss: 1.5568851232528687
Validation loss: 2.062446335310577

Epoch: 5| Step: 2
Training loss: 1.5316523313522339
Validation loss: 2.064029230866381

Epoch: 5| Step: 3
Training loss: 2.6128182411193848
Validation loss: 2.065741936365763

Epoch: 5| Step: 4
Training loss: 2.201083183288574
Validation loss: 2.066955384387765

Epoch: 5| Step: 5
Training loss: 2.4978652000427246
Validation loss: 2.0697994385996172

Epoch: 5| Step: 6
Training loss: 2.3542466163635254
Validation loss: 2.0726070839871644

Epoch: 5| Step: 7
Training loss: 2.4212052822113037
Validation loss: 2.072781648687137

Epoch: 5| Step: 8
Training loss: 2.766334056854248
Validation loss: 2.067635682321364

Epoch: 5| Step: 9
Training loss: 2.905550956726074
Validation loss: 2.0558274920268724

Epoch: 5| Step: 10
Training loss: 2.419752597808838
Validation loss: 2.050192068981868

Epoch: 99| Step: 0
Training loss: 2.6241092681884766
Validation loss: 2.0451055213969243

Epoch: 5| Step: 1
Training loss: 1.946189284324646
Validation loss: 2.048188594079787

Epoch: 5| Step: 2
Training loss: 2.6865365505218506
Validation loss: 2.0541739797079437

Epoch: 5| Step: 3
Training loss: 2.467589855194092
Validation loss: 2.054110755202591

Epoch: 5| Step: 4
Training loss: 1.8847949504852295
Validation loss: 2.057141298888832

Epoch: 5| Step: 5
Training loss: 2.7783138751983643
Validation loss: 2.0695491221643265

Epoch: 5| Step: 6
Training loss: 2.6157994270324707
Validation loss: 2.074457476215978

Epoch: 5| Step: 7
Training loss: 2.3689541816711426
Validation loss: 2.09298635298206

Epoch: 5| Step: 8
Training loss: 2.7048048973083496
Validation loss: 2.0921121105071037

Epoch: 5| Step: 9
Training loss: 2.202099323272705
Validation loss: 2.0990403749609507

Epoch: 5| Step: 10
Training loss: 1.571832537651062
Validation loss: 2.07095685825553

Epoch: 100| Step: 0
Training loss: 1.678687334060669
Validation loss: 2.060189167658488

Epoch: 5| Step: 1
Training loss: 2.473994493484497
Validation loss: 2.053198678519136

Epoch: 5| Step: 2
Training loss: 2.570120334625244
Validation loss: 2.0613710752097507

Epoch: 5| Step: 3
Training loss: 2.9248201847076416
Validation loss: 2.083191587078956

Epoch: 5| Step: 4
Training loss: 2.270456314086914
Validation loss: 2.0842817009136243

Epoch: 5| Step: 5
Training loss: 1.9965007305145264
Validation loss: 2.0868702370633363

Epoch: 5| Step: 6
Training loss: 2.261080741882324
Validation loss: 2.069994749561433

Epoch: 5| Step: 7
Training loss: 2.615692615509033
Validation loss: 2.0700504151723718

Epoch: 5| Step: 8
Training loss: 2.5995919704437256
Validation loss: 2.0575523376464844

Epoch: 5| Step: 9
Training loss: 2.493013620376587
Validation loss: 2.052131983541673

Epoch: 5| Step: 10
Training loss: 2.019541025161743
Validation loss: 2.0527928413883334

Epoch: 101| Step: 0
Training loss: 2.2161834239959717
Validation loss: 2.0571044081000873

Epoch: 5| Step: 1
Training loss: 2.543412923812866
Validation loss: 2.077373440547656

Epoch: 5| Step: 2
Training loss: 2.6348319053649902
Validation loss: 2.096950028532295

Epoch: 5| Step: 3
Training loss: 2.181529998779297
Validation loss: 2.0861830429364274

Epoch: 5| Step: 4
Training loss: 2.345832347869873
Validation loss: 2.06581679467232

Epoch: 5| Step: 5
Training loss: 2.2986679077148438
Validation loss: 2.0680421731805287

Epoch: 5| Step: 6
Training loss: 1.981204628944397
Validation loss: 2.056200394066431

Epoch: 5| Step: 7
Training loss: 3.009171962738037
Validation loss: 2.047449142702164

Epoch: 5| Step: 8
Training loss: 1.2833563089370728
Validation loss: 2.0457207233675065

Epoch: 5| Step: 9
Training loss: 2.265530586242676
Validation loss: 2.045765774224394

Epoch: 5| Step: 10
Training loss: 2.9981980323791504
Validation loss: 2.0416385678834814

Epoch: 102| Step: 0
Training loss: 1.85454523563385
Validation loss: 2.0497976451791744

Epoch: 5| Step: 1
Training loss: 2.055474042892456
Validation loss: 2.0566190776004585

Epoch: 5| Step: 2
Training loss: 1.7858545780181885
Validation loss: 2.064928476528455

Epoch: 5| Step: 3
Training loss: 2.642508029937744
Validation loss: 2.052841007068593

Epoch: 5| Step: 4
Training loss: 2.1480472087860107
Validation loss: 2.057506863788892

Epoch: 5| Step: 5
Training loss: 2.428859233856201
Validation loss: 2.0608380712488645

Epoch: 5| Step: 6
Training loss: 2.53987455368042
Validation loss: 2.077334967992639

Epoch: 5| Step: 7
Training loss: 2.706317901611328
Validation loss: 2.0899587908098773

Epoch: 5| Step: 8
Training loss: 2.695812940597534
Validation loss: 2.1108134754242434

Epoch: 5| Step: 9
Training loss: 2.709521770477295
Validation loss: 2.109097869165482

Epoch: 5| Step: 10
Training loss: 2.444058895111084
Validation loss: 2.0962509134764313

Epoch: 103| Step: 0
Training loss: 2.7515974044799805
Validation loss: 2.092999904386459

Epoch: 5| Step: 1
Training loss: 2.201397657394409
Validation loss: 2.0888893219732467

Epoch: 5| Step: 2
Training loss: 2.0479044914245605
Validation loss: 2.074372645347349

Epoch: 5| Step: 3
Training loss: 2.988137722015381
Validation loss: 2.0570493910902288

Epoch: 5| Step: 4
Training loss: 2.5845396518707275
Validation loss: 2.0558461014942457

Epoch: 5| Step: 5
Training loss: 2.4191322326660156
Validation loss: 2.058517207381546

Epoch: 5| Step: 6
Training loss: 2.0528712272644043
Validation loss: 2.0622385753098356

Epoch: 5| Step: 7
Training loss: 1.9140866994857788
Validation loss: 2.059728435290757

Epoch: 5| Step: 8
Training loss: 2.58207368850708
Validation loss: 2.0509324330155567

Epoch: 5| Step: 9
Training loss: 1.7945706844329834
Validation loss: 2.051891826814221

Epoch: 5| Step: 10
Training loss: 2.4292991161346436
Validation loss: 2.0739484499859553

Epoch: 104| Step: 0
Training loss: 2.7187228202819824
Validation loss: 2.064962684467275

Epoch: 5| Step: 1
Training loss: 2.113114595413208
Validation loss: 2.0578675834081506

Epoch: 5| Step: 2
Training loss: 2.917445659637451
Validation loss: 2.050539042360039

Epoch: 5| Step: 3
Training loss: 2.5605416297912598
Validation loss: 2.0504397910128356

Epoch: 5| Step: 4
Training loss: 2.4775309562683105
Validation loss: 2.0571500383397585

Epoch: 5| Step: 5
Training loss: 2.64988112449646
Validation loss: 2.061857229919844

Epoch: 5| Step: 6
Training loss: 1.8558508157730103
Validation loss: 2.0583888061584963

Epoch: 5| Step: 7
Training loss: 1.9724143743515015
Validation loss: 2.064389451857536

Epoch: 5| Step: 8
Training loss: 2.6003589630126953
Validation loss: 2.067270722440494

Epoch: 5| Step: 9
Training loss: 1.4833749532699585
Validation loss: 2.066528898413463

Epoch: 5| Step: 10
Training loss: 2.0892138481140137
Validation loss: 2.071160833040873

Epoch: 105| Step: 0
Training loss: 2.3009393215179443
Validation loss: 2.0581732552538634

Epoch: 5| Step: 1
Training loss: 2.4444711208343506
Validation loss: 2.0472896893819175

Epoch: 5| Step: 2
Training loss: 2.283000946044922
Validation loss: 2.038422840897755

Epoch: 5| Step: 3
Training loss: 2.1238999366760254
Validation loss: 2.04772356248671

Epoch: 5| Step: 4
Training loss: 2.230353593826294
Validation loss: 2.0466848111921743

Epoch: 5| Step: 5
Training loss: 3.303112506866455
Validation loss: 2.040707529232066

Epoch: 5| Step: 6
Training loss: 2.3174757957458496
Validation loss: 2.0466255603298062

Epoch: 5| Step: 7
Training loss: 2.468353748321533
Validation loss: 2.0387015675985687

Epoch: 5| Step: 8
Training loss: 2.042562246322632
Validation loss: 2.0340233733577113

Epoch: 5| Step: 9
Training loss: 2.0425925254821777
Validation loss: 2.0413818231192966

Epoch: 5| Step: 10
Training loss: 1.8974299430847168
Validation loss: 2.043509711501419

Epoch: 106| Step: 0
Training loss: 1.928082823753357
Validation loss: 2.040262855509276

Epoch: 5| Step: 1
Training loss: 2.59399151802063
Validation loss: 2.0549613109198948

Epoch: 5| Step: 2
Training loss: 2.7421298027038574
Validation loss: 2.058305707029117

Epoch: 5| Step: 3
Training loss: 2.378086566925049
Validation loss: 2.0594773266905095

Epoch: 5| Step: 4
Training loss: 2.2552125453948975
Validation loss: 2.0620695519190964

Epoch: 5| Step: 5
Training loss: 2.3845055103302
Validation loss: 2.06363498010943

Epoch: 5| Step: 6
Training loss: 2.1989493370056152
Validation loss: 2.0730761917688514

Epoch: 5| Step: 7
Training loss: 2.159003734588623
Validation loss: 2.0684180285341

Epoch: 5| Step: 8
Training loss: 2.3404476642608643
Validation loss: 2.0763043306207143

Epoch: 5| Step: 9
Training loss: 2.1689581871032715
Validation loss: 2.076264913364123

Epoch: 5| Step: 10
Training loss: 2.2657291889190674
Validation loss: 2.075923599222655

Epoch: 107| Step: 0
Training loss: 2.546184539794922
Validation loss: 2.0585279797994964

Epoch: 5| Step: 1
Training loss: 1.9901316165924072
Validation loss: 2.0693622340438185

Epoch: 5| Step: 2
Training loss: 2.4937245845794678
Validation loss: 2.075948997210431

Epoch: 5| Step: 3
Training loss: 2.017024040222168
Validation loss: 2.0873363940946517

Epoch: 5| Step: 4
Training loss: 2.1191279888153076
Validation loss: 2.0863710808497604

Epoch: 5| Step: 5
Training loss: 2.705357789993286
Validation loss: 2.0874244602777625

Epoch: 5| Step: 6
Training loss: 2.2972922325134277
Validation loss: 2.051041708197645

Epoch: 5| Step: 7
Training loss: 2.561237096786499
Validation loss: 2.02656876912681

Epoch: 5| Step: 8
Training loss: 2.0598301887512207
Validation loss: 2.019621149186165

Epoch: 5| Step: 9
Training loss: 2.790853977203369
Validation loss: 2.03140317240069

Epoch: 5| Step: 10
Training loss: 2.1772854328155518
Validation loss: 2.0426797136183708

Epoch: 108| Step: 0
Training loss: 3.1058900356292725
Validation loss: 2.041449685250559

Epoch: 5| Step: 1
Training loss: 2.082362413406372
Validation loss: 2.0362572490528064

Epoch: 5| Step: 2
Training loss: 2.1466498374938965
Validation loss: 2.0433928312793856

Epoch: 5| Step: 3
Training loss: 2.027359962463379
Validation loss: 2.033303295412371

Epoch: 5| Step: 4
Training loss: 2.544264793395996
Validation loss: 2.0217863411031742

Epoch: 5| Step: 5
Training loss: 2.1641430854797363
Validation loss: 2.0315071562285065

Epoch: 5| Step: 6
Training loss: 2.267225980758667
Validation loss: 2.033294198333576

Epoch: 5| Step: 7
Training loss: 2.5454611778259277
Validation loss: 2.0375495777335217

Epoch: 5| Step: 8
Training loss: 1.9411087036132812
Validation loss: 2.040556275716392

Epoch: 5| Step: 9
Training loss: 2.697023630142212
Validation loss: 2.0477964185899302

Epoch: 5| Step: 10
Training loss: 1.7856656312942505
Validation loss: 2.0428620000039377

Epoch: 109| Step: 0
Training loss: 2.4729275703430176
Validation loss: 2.0476000847355014

Epoch: 5| Step: 1
Training loss: 2.177257537841797
Validation loss: 2.0448386938341203

Epoch: 5| Step: 2
Training loss: 2.070756673812866
Validation loss: 2.0393716468605945

Epoch: 5| Step: 3
Training loss: 1.9342105388641357
Validation loss: 2.034543296342255

Epoch: 5| Step: 4
Training loss: 2.31738543510437
Validation loss: 2.045287532191123

Epoch: 5| Step: 5
Training loss: 2.3875460624694824
Validation loss: 2.0376071455658122

Epoch: 5| Step: 6
Training loss: 3.1202473640441895
Validation loss: 2.0306143863226778

Epoch: 5| Step: 7
Training loss: 2.1997599601745605
Validation loss: 2.035792750696982

Epoch: 5| Step: 8
Training loss: 2.339350938796997
Validation loss: 2.0335249029180056

Epoch: 5| Step: 9
Training loss: 2.1274147033691406
Validation loss: 2.036866100885535

Epoch: 5| Step: 10
Training loss: 2.105581760406494
Validation loss: 2.0453932721127748

Epoch: 110| Step: 0
Training loss: 2.981826066970825
Validation loss: 2.0442927601516887

Epoch: 5| Step: 1
Training loss: 2.0030345916748047
Validation loss: 2.0527530459947485

Epoch: 5| Step: 2
Training loss: 2.2055914402008057
Validation loss: 2.0516036197703373

Epoch: 5| Step: 3
Training loss: 1.7835413217544556
Validation loss: 2.051131874002436

Epoch: 5| Step: 4
Training loss: 2.3351194858551025
Validation loss: 2.0514588279108845

Epoch: 5| Step: 5
Training loss: 2.2243313789367676
Validation loss: 2.05669819155047

Epoch: 5| Step: 6
Training loss: 1.9203598499298096
Validation loss: 2.042516016191052

Epoch: 5| Step: 7
Training loss: 2.660147190093994
Validation loss: 2.0476502218554096

Epoch: 5| Step: 8
Training loss: 1.7348558902740479
Validation loss: 2.048779212018495

Epoch: 5| Step: 9
Training loss: 2.516146183013916
Validation loss: 2.042592945919242

Epoch: 5| Step: 10
Training loss: 2.6959667205810547
Validation loss: 2.0345759904512795

Epoch: 111| Step: 0
Training loss: 2.852848768234253
Validation loss: 2.0335334629140873

Epoch: 5| Step: 1
Training loss: 2.249019145965576
Validation loss: 2.0297318120156564

Epoch: 5| Step: 2
Training loss: 2.051515579223633
Validation loss: 2.0346692941522084

Epoch: 5| Step: 3
Training loss: 2.9176831245422363
Validation loss: 2.041149099667867

Epoch: 5| Step: 4
Training loss: 2.305504083633423
Validation loss: 2.046974241092641

Epoch: 5| Step: 5
Training loss: 1.9965941905975342
Validation loss: 2.0631550063369093

Epoch: 5| Step: 6
Training loss: 1.8246101140975952
Validation loss: 2.061792483893774

Epoch: 5| Step: 7
Training loss: 1.9945071935653687
Validation loss: 2.089492113359513

Epoch: 5| Step: 8
Training loss: 2.5885369777679443
Validation loss: 2.079846594923286

Epoch: 5| Step: 9
Training loss: 2.1325924396514893
Validation loss: 2.04968104311215

Epoch: 5| Step: 10
Training loss: 2.4258556365966797
Validation loss: 2.051091637662662

Epoch: 112| Step: 0
Training loss: 2.110673189163208
Validation loss: 2.061689228139898

Epoch: 5| Step: 1
Training loss: 2.320011854171753
Validation loss: 2.0723759871657177

Epoch: 5| Step: 2
Training loss: 1.7419288158416748
Validation loss: 2.0924769242604575

Epoch: 5| Step: 3
Training loss: 2.510084390640259
Validation loss: 2.1045540353303314

Epoch: 5| Step: 4
Training loss: 2.8908298015594482
Validation loss: 2.0922973463612218

Epoch: 5| Step: 5
Training loss: 2.564606189727783
Validation loss: 2.059160785008502

Epoch: 5| Step: 6
Training loss: 2.376394748687744
Validation loss: 2.0426360791729343

Epoch: 5| Step: 7
Training loss: 2.413276195526123
Validation loss: 2.051370405381726

Epoch: 5| Step: 8
Training loss: 2.4892051219940186
Validation loss: 2.0558975153071906

Epoch: 5| Step: 9
Training loss: 2.147519588470459
Validation loss: 2.0747977354193248

Epoch: 5| Step: 10
Training loss: 1.9994308948516846
Validation loss: 2.0624529623216197

Epoch: 113| Step: 0
Training loss: 2.4532439708709717
Validation loss: 2.0323676101623045

Epoch: 5| Step: 1
Training loss: 2.041430711746216
Validation loss: 2.0316165570289857

Epoch: 5| Step: 2
Training loss: 2.6490283012390137
Validation loss: 2.027517663535251

Epoch: 5| Step: 3
Training loss: 1.930749535560608
Validation loss: 2.0214822779419603

Epoch: 5| Step: 4
Training loss: 2.8478641510009766
Validation loss: 2.017415790147679

Epoch: 5| Step: 5
Training loss: 2.375991106033325
Validation loss: 2.022286066444971

Epoch: 5| Step: 6
Training loss: 2.7909328937530518
Validation loss: 2.0373943851840113

Epoch: 5| Step: 7
Training loss: 1.595795750617981
Validation loss: 2.030779097669868

Epoch: 5| Step: 8
Training loss: 1.68131422996521
Validation loss: 2.028462093363526

Epoch: 5| Step: 9
Training loss: 2.4346506595611572
Validation loss: 2.0376271381173083

Epoch: 5| Step: 10
Training loss: 2.339430093765259
Validation loss: 2.0598971741173857

Epoch: 114| Step: 0
Training loss: 2.443488359451294
Validation loss: 2.0713167421279417

Epoch: 5| Step: 1
Training loss: 1.7309223413467407
Validation loss: 2.0730594024863294

Epoch: 5| Step: 2
Training loss: 2.250673770904541
Validation loss: 2.0575700882942445

Epoch: 5| Step: 3
Training loss: 2.7104897499084473
Validation loss: 2.0396985879508396

Epoch: 5| Step: 4
Training loss: 1.6881921291351318
Validation loss: 2.0352371020983626

Epoch: 5| Step: 5
Training loss: 2.7688519954681396
Validation loss: 2.036704877371429

Epoch: 5| Step: 6
Training loss: 2.4381401538848877
Validation loss: 2.0408283920698267

Epoch: 5| Step: 7
Training loss: 1.6849168539047241
Validation loss: 2.027868342655961

Epoch: 5| Step: 8
Training loss: 2.1422433853149414
Validation loss: 2.0310360603435065

Epoch: 5| Step: 9
Training loss: 2.231234312057495
Validation loss: 2.020889428354079

Epoch: 5| Step: 10
Training loss: 2.897726058959961
Validation loss: 2.0164810201173187

Epoch: 115| Step: 0
Training loss: 2.0936388969421387
Validation loss: 2.024739424387614

Epoch: 5| Step: 1
Training loss: 1.9232442378997803
Validation loss: 2.0425356075327885

Epoch: 5| Step: 2
Training loss: 2.5789079666137695
Validation loss: 2.0467674373298563

Epoch: 5| Step: 3
Training loss: 1.9755901098251343
Validation loss: 2.0575715700785318

Epoch: 5| Step: 4
Training loss: 1.5224558115005493
Validation loss: 2.077522631614439

Epoch: 5| Step: 5
Training loss: 2.7516980171203613
Validation loss: 2.0595597926006524

Epoch: 5| Step: 6
Training loss: 2.0703768730163574
Validation loss: 2.059021749804097

Epoch: 5| Step: 7
Training loss: 2.1902382373809814
Validation loss: 2.067664664278748

Epoch: 5| Step: 8
Training loss: 2.5033836364746094
Validation loss: 2.0681292113437446

Epoch: 5| Step: 9
Training loss: 2.7348034381866455
Validation loss: 2.0600623469198904

Epoch: 5| Step: 10
Training loss: 2.2962775230407715
Validation loss: 2.044045861049365

Epoch: 116| Step: 0
Training loss: 2.150791645050049
Validation loss: 2.0187374930227957

Epoch: 5| Step: 1
Training loss: 2.323075771331787
Validation loss: 2.006798440410245

Epoch: 5| Step: 2
Training loss: 1.844430923461914
Validation loss: 2.0174284314596527

Epoch: 5| Step: 3
Training loss: 2.3037495613098145
Validation loss: 2.0126912350295694

Epoch: 5| Step: 4
Training loss: 2.4767661094665527
Validation loss: 2.0144593561849287

Epoch: 5| Step: 5
Training loss: 1.2263157367706299
Validation loss: 2.012665589650472

Epoch: 5| Step: 6
Training loss: 2.2472691535949707
Validation loss: 2.0119342073317497

Epoch: 5| Step: 7
Training loss: 2.2956106662750244
Validation loss: 2.0076444507927023

Epoch: 5| Step: 8
Training loss: 1.8028640747070312
Validation loss: 2.015157198393217

Epoch: 5| Step: 9
Training loss: 2.957939863204956
Validation loss: 2.0205043695306264

Epoch: 5| Step: 10
Training loss: 2.9576609134674072
Validation loss: 2.0033052018893662

Epoch: 117| Step: 0
Training loss: 2.3672444820404053
Validation loss: 2.0112971080246793

Epoch: 5| Step: 1
Training loss: 2.4334559440612793
Validation loss: 2.012732172525057

Epoch: 5| Step: 2
Training loss: 2.16111421585083
Validation loss: 2.028071426576184

Epoch: 5| Step: 3
Training loss: 2.7422778606414795
Validation loss: 2.024389651513869

Epoch: 5| Step: 4
Training loss: 1.4273041486740112
Validation loss: 2.020950432746641

Epoch: 5| Step: 5
Training loss: 1.9509813785552979
Validation loss: 2.0310709835380636

Epoch: 5| Step: 6
Training loss: 2.214420795440674
Validation loss: 2.028615436246318

Epoch: 5| Step: 7
Training loss: 2.7251715660095215
Validation loss: 2.02908654110406

Epoch: 5| Step: 8
Training loss: 1.827751874923706
Validation loss: 2.031413103944512

Epoch: 5| Step: 9
Training loss: 2.0211448669433594
Validation loss: 2.0420747546739477

Epoch: 5| Step: 10
Training loss: 2.5671603679656982
Validation loss: 2.0407285639034805

Epoch: 118| Step: 0
Training loss: 2.615161657333374
Validation loss: 2.0301709905747445

Epoch: 5| Step: 1
Training loss: 2.4506821632385254
Validation loss: 2.029685248610794

Epoch: 5| Step: 2
Training loss: 1.8855266571044922
Validation loss: 2.02545787185751

Epoch: 5| Step: 3
Training loss: 1.8053258657455444
Validation loss: 2.0249696982804166

Epoch: 5| Step: 4
Training loss: 1.741628646850586
Validation loss: 2.015476844644034

Epoch: 5| Step: 5
Training loss: 2.000697374343872
Validation loss: 2.0132352062450942

Epoch: 5| Step: 6
Training loss: 2.780733585357666
Validation loss: 2.0214922351221882

Epoch: 5| Step: 7
Training loss: 2.5610952377319336
Validation loss: 2.046006682098553

Epoch: 5| Step: 8
Training loss: 2.226457118988037
Validation loss: 2.0968764494824153

Epoch: 5| Step: 9
Training loss: 1.8941243886947632
Validation loss: 2.0982780635997815

Epoch: 5| Step: 10
Training loss: 2.958548069000244
Validation loss: 2.11756375528151

Epoch: 119| Step: 0
Training loss: 2.234729051589966
Validation loss: 2.0185302406229

Epoch: 5| Step: 1
Training loss: 2.2002978324890137
Validation loss: 2.0006937365378104

Epoch: 5| Step: 2
Training loss: 2.9318182468414307
Validation loss: 1.9936785582573182

Epoch: 5| Step: 3
Training loss: 2.417928695678711
Validation loss: 2.0060705561791696

Epoch: 5| Step: 4
Training loss: 2.3078339099884033
Validation loss: 2.0126529278293734

Epoch: 5| Step: 5
Training loss: 2.125070095062256
Validation loss: 2.0192599219660603

Epoch: 5| Step: 6
Training loss: 1.8034236431121826
Validation loss: 2.024730287572389

Epoch: 5| Step: 7
Training loss: 2.087818145751953
Validation loss: 2.0084870758877007

Epoch: 5| Step: 8
Training loss: 1.7949491739273071
Validation loss: 2.0173793685051704

Epoch: 5| Step: 9
Training loss: 2.3990390300750732
Validation loss: 2.0265184217883694

Epoch: 5| Step: 10
Training loss: 2.550931930541992
Validation loss: 2.034552510066699

Epoch: 120| Step: 0
Training loss: 1.5944486856460571
Validation loss: 2.0469830574527865

Epoch: 5| Step: 1
Training loss: 2.6308417320251465
Validation loss: 2.0590870662402083

Epoch: 5| Step: 2
Training loss: 2.541594982147217
Validation loss: 2.0528940129023727

Epoch: 5| Step: 3
Training loss: 2.291378974914551
Validation loss: 2.032686815466932

Epoch: 5| Step: 4
Training loss: 2.779752492904663
Validation loss: 2.0184470940661687

Epoch: 5| Step: 5
Training loss: 2.7310025691986084
Validation loss: 2.0012508861480223

Epoch: 5| Step: 6
Training loss: 1.674329400062561
Validation loss: 2.0033246265944613

Epoch: 5| Step: 7
Training loss: 2.1024529933929443
Validation loss: 2.0133160160433863

Epoch: 5| Step: 8
Training loss: 2.0914828777313232
Validation loss: 2.022879203160604

Epoch: 5| Step: 9
Training loss: 2.680058240890503
Validation loss: 2.013349581790227

Epoch: 5| Step: 10
Training loss: 2.007258892059326
Validation loss: 2.002877154657918

Epoch: 121| Step: 0
Training loss: 1.9290597438812256
Validation loss: 2.0162878690227384

Epoch: 5| Step: 1
Training loss: 2.5326826572418213
Validation loss: 2.0249379552820677

Epoch: 5| Step: 2
Training loss: 2.968733549118042
Validation loss: 2.0708576915084675

Epoch: 5| Step: 3
Training loss: 1.9832429885864258
Validation loss: 2.0778841318622714

Epoch: 5| Step: 4
Training loss: 2.137406587600708
Validation loss: 2.137274742126465

Epoch: 5| Step: 5
Training loss: 2.0976181030273438
Validation loss: 2.2106676050411758

Epoch: 5| Step: 6
Training loss: 2.268556594848633
Validation loss: 2.1689885431720364

Epoch: 5| Step: 7
Training loss: 1.9330847263336182
Validation loss: 2.0987364527999715

Epoch: 5| Step: 8
Training loss: 2.441551685333252
Validation loss: 2.0761826358815676

Epoch: 5| Step: 9
Training loss: 2.448279619216919
Validation loss: 2.0634472447056926

Epoch: 5| Step: 10
Training loss: 2.2570652961730957
Validation loss: 2.0682337437906573

Epoch: 122| Step: 0
Training loss: 2.318542242050171
Validation loss: 2.0560350546272854

Epoch: 5| Step: 1
Training loss: 2.151305913925171
Validation loss: 2.0547520960530927

Epoch: 5| Step: 2
Training loss: 2.1601288318634033
Validation loss: 2.0317606438872633

Epoch: 5| Step: 3
Training loss: 2.5126185417175293
Validation loss: 2.031842218932285

Epoch: 5| Step: 4
Training loss: 1.9428590536117554
Validation loss: 2.0269935156709407

Epoch: 5| Step: 5
Training loss: 2.5083506107330322
Validation loss: 2.049486837079448

Epoch: 5| Step: 6
Training loss: 1.6096261739730835
Validation loss: 2.06343577754113

Epoch: 5| Step: 7
Training loss: 2.0573883056640625
Validation loss: 2.08852199328843

Epoch: 5| Step: 8
Training loss: 2.4654507637023926
Validation loss: 2.0650385208027338

Epoch: 5| Step: 9
Training loss: 2.3730130195617676
Validation loss: 2.0573033081587924

Epoch: 5| Step: 10
Training loss: 2.759274959564209
Validation loss: 2.042589815714026

Epoch: 123| Step: 0
Training loss: 2.6234781742095947
Validation loss: 2.040561883680282

Epoch: 5| Step: 1
Training loss: 2.353666305541992
Validation loss: 2.0304852916348364

Epoch: 5| Step: 2
Training loss: 1.9962186813354492
Validation loss: 2.0394684281400455

Epoch: 5| Step: 3
Training loss: 1.830940842628479
Validation loss: 2.042882142528411

Epoch: 5| Step: 4
Training loss: 2.057015895843506
Validation loss: 2.0346106572817733

Epoch: 5| Step: 5
Training loss: 2.9250309467315674
Validation loss: 2.0425874699828444

Epoch: 5| Step: 6
Training loss: 2.3485655784606934
Validation loss: 2.03993809094993

Epoch: 5| Step: 7
Training loss: 1.9731334447860718
Validation loss: 2.0226054986317954

Epoch: 5| Step: 8
Training loss: 1.9645805358886719
Validation loss: 2.033783451203377

Epoch: 5| Step: 9
Training loss: 1.5212504863739014
Validation loss: 2.0524639057856735

Epoch: 5| Step: 10
Training loss: 2.728135108947754
Validation loss: 2.0595798800068517

Epoch: 124| Step: 0
Training loss: 2.0996181964874268
Validation loss: 2.0663247608369395

Epoch: 5| Step: 1
Training loss: 2.0172791481018066
Validation loss: 2.0413716762296614

Epoch: 5| Step: 2
Training loss: 1.9124568700790405
Validation loss: 2.0578155607305546

Epoch: 5| Step: 3
Training loss: 2.6575815677642822
Validation loss: 2.055194911136422

Epoch: 5| Step: 4
Training loss: 1.8131519556045532
Validation loss: 2.071669299115417

Epoch: 5| Step: 5
Training loss: 1.9639323949813843
Validation loss: 2.05758503688279

Epoch: 5| Step: 6
Training loss: 1.9765666723251343
Validation loss: 2.0397527679320304

Epoch: 5| Step: 7
Training loss: 2.4282889366149902
Validation loss: 2.030749579911591

Epoch: 5| Step: 8
Training loss: 2.432440996170044
Validation loss: 2.0235831596518077

Epoch: 5| Step: 9
Training loss: 2.532700538635254
Validation loss: 2.0231209172997424

Epoch: 5| Step: 10
Training loss: 2.276735305786133
Validation loss: 2.0087989491801106

Epoch: 125| Step: 0
Training loss: 2.272545337677002
Validation loss: 2.0015272683994745

Epoch: 5| Step: 1
Training loss: 2.20877742767334
Validation loss: 2.008161635809047

Epoch: 5| Step: 2
Training loss: 1.5203737020492554
Validation loss: 2.0129525379468034

Epoch: 5| Step: 3
Training loss: 2.7652587890625
Validation loss: 2.0251115829713884

Epoch: 5| Step: 4
Training loss: 2.452829360961914
Validation loss: 2.0555556205011185

Epoch: 5| Step: 5
Training loss: 2.2925186157226562
Validation loss: 2.0724642597218996

Epoch: 5| Step: 6
Training loss: 2.2167720794677734
Validation loss: 2.059418239901143

Epoch: 5| Step: 7
Training loss: 2.3572309017181396
Validation loss: 2.0467431173529675

Epoch: 5| Step: 8
Training loss: 2.126357078552246
Validation loss: 2.0187295867550756

Epoch: 5| Step: 9
Training loss: 1.9978187084197998
Validation loss: 1.9984780152638753

Epoch: 5| Step: 10
Training loss: 2.169048309326172
Validation loss: 2.001762056863436

Epoch: 126| Step: 0
Training loss: 2.3594295978546143
Validation loss: 2.0097782868210987

Epoch: 5| Step: 1
Training loss: 2.518023729324341
Validation loss: 2.0146743917977936

Epoch: 5| Step: 2
Training loss: 2.5390255451202393
Validation loss: 2.020552950520669

Epoch: 5| Step: 3
Training loss: 1.7015113830566406
Validation loss: 2.0314795509461434

Epoch: 5| Step: 4
Training loss: 2.9168426990509033
Validation loss: 2.0253838595523628

Epoch: 5| Step: 5
Training loss: 1.8882306814193726
Validation loss: 2.0372338077073455

Epoch: 5| Step: 6
Training loss: 1.870197057723999
Validation loss: 2.046619351192187

Epoch: 5| Step: 7
Training loss: 2.254791259765625
Validation loss: 2.0372649610683484

Epoch: 5| Step: 8
Training loss: 2.30603289604187
Validation loss: 2.044166559814125

Epoch: 5| Step: 9
Training loss: 2.090609312057495
Validation loss: 2.0463371084582422

Epoch: 5| Step: 10
Training loss: 1.5210306644439697
Validation loss: 2.066394329071045

Epoch: 127| Step: 0
Training loss: 1.8257259130477905
Validation loss: 2.0639709400874313

Epoch: 5| Step: 1
Training loss: 1.1755465269088745
Validation loss: 2.057313178175239

Epoch: 5| Step: 2
Training loss: 1.7972885370254517
Validation loss: 2.065825170086276

Epoch: 5| Step: 3
Training loss: 2.132539987564087
Validation loss: 2.097477851375457

Epoch: 5| Step: 4
Training loss: 2.8540358543395996
Validation loss: 2.1428911378306728

Epoch: 5| Step: 5
Training loss: 2.6501588821411133
Validation loss: 2.1325773667263728

Epoch: 5| Step: 6
Training loss: 2.304874897003174
Validation loss: 2.069677592605673

Epoch: 5| Step: 7
Training loss: 2.421954393386841
Validation loss: 2.0390399912352204

Epoch: 5| Step: 8
Training loss: 2.5591189861297607
Validation loss: 2.0206396746379074

Epoch: 5| Step: 9
Training loss: 2.470304250717163
Validation loss: 2.032681154948409

Epoch: 5| Step: 10
Training loss: 1.6061650514602661
Validation loss: 2.0194252652506672

Epoch: 128| Step: 0
Training loss: 2.149313449859619
Validation loss: 2.0178868411689677

Epoch: 5| Step: 1
Training loss: 1.5019320249557495
Validation loss: 2.0051235024647047

Epoch: 5| Step: 2
Training loss: 1.9866111278533936
Validation loss: 2.007116792022541

Epoch: 5| Step: 3
Training loss: 2.0926525592803955
Validation loss: 1.9983314096286733

Epoch: 5| Step: 4
Training loss: 1.8425066471099854
Validation loss: 1.9977504668697235

Epoch: 5| Step: 5
Training loss: 2.8546531200408936
Validation loss: 2.0294781474656958

Epoch: 5| Step: 6
Training loss: 2.400214910507202
Validation loss: 2.0464839499483825

Epoch: 5| Step: 7
Training loss: 2.109057903289795
Validation loss: 2.0476761735895628

Epoch: 5| Step: 8
Training loss: 2.6678860187530518
Validation loss: 2.054787581966769

Epoch: 5| Step: 9
Training loss: 2.1186575889587402
Validation loss: 2.031855878009591

Epoch: 5| Step: 10
Training loss: 2.392993211746216
Validation loss: 2.0261401771217264

Epoch: 129| Step: 0
Training loss: 2.0575344562530518
Validation loss: 2.0141948551260014

Epoch: 5| Step: 1
Training loss: 2.0435726642608643
Validation loss: 2.0071579333274596

Epoch: 5| Step: 2
Training loss: 1.8577511310577393
Validation loss: 1.9971145147918372

Epoch: 5| Step: 3
Training loss: 1.910698652267456
Validation loss: 2.0057984949440084

Epoch: 5| Step: 4
Training loss: 2.0618739128112793
Validation loss: 1.9995518525441487

Epoch: 5| Step: 5
Training loss: 2.0594286918640137
Validation loss: 1.9884750753320672

Epoch: 5| Step: 6
Training loss: 2.375302791595459
Validation loss: 2.012307108089488

Epoch: 5| Step: 7
Training loss: 2.4950485229492188
Validation loss: 2.040404373599637

Epoch: 5| Step: 8
Training loss: 2.3232388496398926
Validation loss: 2.0683692988529

Epoch: 5| Step: 9
Training loss: 2.7040863037109375
Validation loss: 2.110176101807625

Epoch: 5| Step: 10
Training loss: 1.7855806350708008
Validation loss: 2.0768041867081837

Epoch: 130| Step: 0
Training loss: 2.0956532955169678
Validation loss: 2.03535323245551

Epoch: 5| Step: 1
Training loss: 1.7932682037353516
Validation loss: 2.0291305703501545

Epoch: 5| Step: 2
Training loss: 2.3154690265655518
Validation loss: 2.012629252608104

Epoch: 5| Step: 3
Training loss: 2.7716617584228516
Validation loss: 2.0166830696085447

Epoch: 5| Step: 4
Training loss: 2.3711495399475098
Validation loss: 2.0215706415073846

Epoch: 5| Step: 5
Training loss: 2.000727653503418
Validation loss: 2.0247330152860252

Epoch: 5| Step: 6
Training loss: 2.3248608112335205
Validation loss: 2.041725944447261

Epoch: 5| Step: 7
Training loss: 2.13389253616333
Validation loss: 2.0735357269164054

Epoch: 5| Step: 8
Training loss: 1.5327527523040771
Validation loss: 2.112911119255968

Epoch: 5| Step: 9
Training loss: 2.3326897621154785
Validation loss: 2.08106860422319

Epoch: 5| Step: 10
Training loss: 1.858042597770691
Validation loss: 2.078876810689126

Epoch: 131| Step: 0
Training loss: 2.3789515495300293
Validation loss: 2.076715966706635

Epoch: 5| Step: 1
Training loss: 2.0482306480407715
Validation loss: 2.064781424819782

Epoch: 5| Step: 2
Training loss: 2.321133852005005
Validation loss: 2.066593352184501

Epoch: 5| Step: 3
Training loss: 2.1820859909057617
Validation loss: 2.0593078303080734

Epoch: 5| Step: 4
Training loss: 1.7792384624481201
Validation loss: 2.045979040925221

Epoch: 5| Step: 5
Training loss: 1.7231881618499756
Validation loss: 2.0232439002683087

Epoch: 5| Step: 6
Training loss: 2.0983073711395264
Validation loss: 2.05059640894654

Epoch: 5| Step: 7
Training loss: 1.9984089136123657
Validation loss: 2.0452359158505677

Epoch: 5| Step: 8
Training loss: 2.563511371612549
Validation loss: 2.0332420923376597

Epoch: 5| Step: 9
Training loss: 1.6938190460205078
Validation loss: 2.016439022556428

Epoch: 5| Step: 10
Training loss: 2.5083425045013428
Validation loss: 2.001406054342947

Epoch: 132| Step: 0
Training loss: 2.714103937149048
Validation loss: 2.0009356955046296

Epoch: 5| Step: 1
Training loss: 2.4673619270324707
Validation loss: 2.023156778786772

Epoch: 5| Step: 2
Training loss: 2.1432816982269287
Validation loss: 2.0031800193171345

Epoch: 5| Step: 3
Training loss: 1.7103840112686157
Validation loss: 1.9943435397199405

Epoch: 5| Step: 4
Training loss: 1.7412601709365845
Validation loss: 2.0518953825837825

Epoch: 5| Step: 5
Training loss: 1.965437650680542
Validation loss: 2.0867528838496052

Epoch: 5| Step: 6
Training loss: 2.0559306144714355
Validation loss: 2.1324093675100677

Epoch: 5| Step: 7
Training loss: 2.0672004222869873
Validation loss: 2.1781639463158062

Epoch: 5| Step: 8
Training loss: 1.9526081085205078
Validation loss: 2.1263903417894916

Epoch: 5| Step: 9
Training loss: 2.8411450386047363
Validation loss: 2.076750978346794

Epoch: 5| Step: 10
Training loss: 1.5663241147994995
Validation loss: 2.033680787650488

Epoch: 133| Step: 0
Training loss: 2.211620330810547
Validation loss: 2.015179746894426

Epoch: 5| Step: 1
Training loss: 2.3966193199157715
Validation loss: 2.000186986820672

Epoch: 5| Step: 2
Training loss: 2.623051404953003
Validation loss: 2.016902205764606

Epoch: 5| Step: 3
Training loss: 1.7221254110336304
Validation loss: 2.0089003962855183

Epoch: 5| Step: 4
Training loss: 2.165224552154541
Validation loss: 2.0236922130789807

Epoch: 5| Step: 5
Training loss: 1.9998184442520142
Validation loss: 2.025533912002399

Epoch: 5| Step: 6
Training loss: 1.9983543157577515
Validation loss: 2.0543867080442366

Epoch: 5| Step: 7
Training loss: 2.0600647926330566
Validation loss: 2.087086190459549

Epoch: 5| Step: 8
Training loss: 2.084794521331787
Validation loss: 2.1267954405917915

Epoch: 5| Step: 9
Training loss: 2.047553300857544
Validation loss: 2.13057711303875

Epoch: 5| Step: 10
Training loss: 1.7856411933898926
Validation loss: 2.0653179986502535

Epoch: 134| Step: 0
Training loss: 2.0464084148406982
Validation loss: 2.0124294322024108

Epoch: 5| Step: 1
Training loss: 2.231210947036743
Validation loss: 1.9858525927348802

Epoch: 5| Step: 2
Training loss: 1.7221543788909912
Validation loss: 1.9643755189834102

Epoch: 5| Step: 3
Training loss: 2.0207791328430176
Validation loss: 1.9728037682912682

Epoch: 5| Step: 4
Training loss: 2.4204185009002686
Validation loss: 1.9760332479271838

Epoch: 5| Step: 5
Training loss: 1.8884096145629883
Validation loss: 1.9930241441213956

Epoch: 5| Step: 6
Training loss: 2.2834339141845703
Validation loss: 2.0236482069056523

Epoch: 5| Step: 7
Training loss: 2.3069427013397217
Validation loss: 2.0695591280537267

Epoch: 5| Step: 8
Training loss: 2.2611727714538574
Validation loss: 2.0434095526254303

Epoch: 5| Step: 9
Training loss: 2.1957690715789795
Validation loss: 2.025739259617303

Epoch: 5| Step: 10
Training loss: 1.6205224990844727
Validation loss: 2.011518091283819

Epoch: 135| Step: 0
Training loss: 1.7299972772598267
Validation loss: 2.01332837535489

Epoch: 5| Step: 1
Training loss: 2.0657801628112793
Validation loss: 2.0261955440685315

Epoch: 5| Step: 2
Training loss: 1.9289124011993408
Validation loss: 2.0325410058421474

Epoch: 5| Step: 3
Training loss: 2.74906325340271
Validation loss: 2.042450499790971

Epoch: 5| Step: 4
Training loss: 1.8586320877075195
Validation loss: 2.0540697036250943

Epoch: 5| Step: 5
Training loss: 1.572303295135498
Validation loss: 2.052485922331451

Epoch: 5| Step: 6
Training loss: 1.9231475591659546
Validation loss: 2.0640750520972797

Epoch: 5| Step: 7
Training loss: 2.6555850505828857
Validation loss: 2.056721228425221

Epoch: 5| Step: 8
Training loss: 1.7509262561798096
Validation loss: 2.034291221249488

Epoch: 5| Step: 9
Training loss: 2.091686487197876
Validation loss: 2.0328673008949525

Epoch: 5| Step: 10
Training loss: 2.117095947265625
Validation loss: 2.0269643260586645

Epoch: 136| Step: 0
Training loss: 1.7778193950653076
Validation loss: 1.9995416261816537

Epoch: 5| Step: 1
Training loss: 1.720603585243225
Validation loss: 1.980004297789707

Epoch: 5| Step: 2
Training loss: 2.9949569702148438
Validation loss: 1.9768770471695931

Epoch: 5| Step: 3
Training loss: 2.085949182510376
Validation loss: 1.9828592731106667

Epoch: 5| Step: 4
Training loss: 2.4906749725341797
Validation loss: 1.985318858136413

Epoch: 5| Step: 5
Training loss: 1.9320869445800781
Validation loss: 1.9997979158996253

Epoch: 5| Step: 6
Training loss: 2.259464740753174
Validation loss: 2.0495681249967186

Epoch: 5| Step: 7
Training loss: 1.7190412282943726
Validation loss: 2.057887419577568

Epoch: 5| Step: 8
Training loss: 1.7272052764892578
Validation loss: 2.104407628377279

Epoch: 5| Step: 9
Training loss: 1.8275854587554932
Validation loss: 2.112608540442682

Epoch: 5| Step: 10
Training loss: 2.193425416946411
Validation loss: 2.0728310346603394

Epoch: 137| Step: 0
Training loss: 2.0337867736816406
Validation loss: 2.0499357472183886

Epoch: 5| Step: 1
Training loss: 2.200411558151245
Validation loss: 2.0352135166045158

Epoch: 5| Step: 2
Training loss: 1.773535132408142
Validation loss: 2.0309024010935137

Epoch: 5| Step: 3
Training loss: 2.1177539825439453
Validation loss: 2.0553628539526336

Epoch: 5| Step: 4
Training loss: 2.102181911468506
Validation loss: 2.079310417175293

Epoch: 5| Step: 5
Training loss: 2.3630173206329346
Validation loss: 2.0506144313402075

Epoch: 5| Step: 6
Training loss: 1.8285160064697266
Validation loss: 2.0375124344261746

Epoch: 5| Step: 7
Training loss: 2.228088855743408
Validation loss: 2.010383705939016

Epoch: 5| Step: 8
Training loss: 1.9235193729400635
Validation loss: 1.9972611037633752

Epoch: 5| Step: 9
Training loss: 1.7510960102081299
Validation loss: 1.9896914497498543

Epoch: 5| Step: 10
Training loss: 1.9740591049194336
Validation loss: 1.9917539858048963

Epoch: 138| Step: 0
Training loss: 1.8635305166244507
Validation loss: 1.9647769966433126

Epoch: 5| Step: 1
Training loss: 1.9876439571380615
Validation loss: 1.9785477422898816

Epoch: 5| Step: 2
Training loss: 1.6443036794662476
Validation loss: 1.9875092224408222

Epoch: 5| Step: 3
Training loss: 2.0768883228302
Validation loss: 1.985785775287177

Epoch: 5| Step: 4
Training loss: 2.0355796813964844
Validation loss: 1.9989937197777532

Epoch: 5| Step: 5
Training loss: 1.8967607021331787
Validation loss: 2.0069644989505893

Epoch: 5| Step: 6
Training loss: 1.7284637689590454
Validation loss: 2.066696656647549

Epoch: 5| Step: 7
Training loss: 2.3987984657287598
Validation loss: 2.0647451441775084

Epoch: 5| Step: 8
Training loss: 2.3249969482421875
Validation loss: 2.0608494589405675

Epoch: 5| Step: 9
Training loss: 2.4155311584472656
Validation loss: 2.0088454779758247

Epoch: 5| Step: 10
Training loss: 1.7308293581008911
Validation loss: 1.9959069426341722

Epoch: 139| Step: 0
Training loss: 1.7452768087387085
Validation loss: 2.0451095386218

Epoch: 5| Step: 1
Training loss: 1.8897755146026611
Validation loss: 2.0292448920588337

Epoch: 5| Step: 2
Training loss: 2.017179489135742
Validation loss: 2.0304458615600423

Epoch: 5| Step: 3
Training loss: 1.5185405015945435
Validation loss: 2.051108287226769

Epoch: 5| Step: 4
Training loss: 2.3850131034851074
Validation loss: 2.0281487946869223

Epoch: 5| Step: 5
Training loss: 1.9837672710418701
Validation loss: 2.0076928882188696

Epoch: 5| Step: 6
Training loss: 2.0945885181427
Validation loss: 2.006147947362674

Epoch: 5| Step: 7
Training loss: 2.416259288787842
Validation loss: 2.0300661671546196

Epoch: 5| Step: 8
Training loss: 1.6742088794708252
Validation loss: 2.0033338326279835

Epoch: 5| Step: 9
Training loss: 1.9173831939697266
Validation loss: 1.9854810237884521

Epoch: 5| Step: 10
Training loss: 2.295198917388916
Validation loss: 1.9852499013305993

Epoch: 140| Step: 0
Training loss: 2.0759613513946533
Validation loss: 1.9675813028889317

Epoch: 5| Step: 1
Training loss: 2.0404086112976074
Validation loss: 1.9641591284864692

Epoch: 5| Step: 2
Training loss: 1.5285067558288574
Validation loss: 1.9645607138192782

Epoch: 5| Step: 3
Training loss: 2.3605518341064453
Validation loss: 1.962389781910886

Epoch: 5| Step: 4
Training loss: 1.6967670917510986
Validation loss: 1.9762243314455914

Epoch: 5| Step: 5
Training loss: 1.9752171039581299
Validation loss: 2.0122784235144175

Epoch: 5| Step: 6
Training loss: 2.0057930946350098
Validation loss: 2.0598855864617134

Epoch: 5| Step: 7
Training loss: 2.576866626739502
Validation loss: 2.1328254425397484

Epoch: 5| Step: 8
Training loss: 2.0921213626861572
Validation loss: 2.1361295100181334

Epoch: 5| Step: 9
Training loss: 1.7581243515014648
Validation loss: 2.0847799495984147

Epoch: 5| Step: 10
Training loss: 1.733365774154663
Validation loss: 2.0831266039161274

Epoch: 141| Step: 0
Training loss: 1.8475145101547241
Validation loss: 2.058090002306046

Epoch: 5| Step: 1
Training loss: 2.5338706970214844
Validation loss: 2.0537658301732873

Epoch: 5| Step: 2
Training loss: 1.996023178100586
Validation loss: 2.0160925644700245

Epoch: 5| Step: 3
Training loss: 2.3524632453918457
Validation loss: 1.9845139031769128

Epoch: 5| Step: 4
Training loss: 1.7268779277801514
Validation loss: 1.9778157587974303

Epoch: 5| Step: 5
Training loss: 2.465014696121216
Validation loss: 1.9972348315741426

Epoch: 5| Step: 6
Training loss: 1.3817451000213623
Validation loss: 1.9883679728354178

Epoch: 5| Step: 7
Training loss: 2.0105910301208496
Validation loss: 1.9825253640451739

Epoch: 5| Step: 8
Training loss: 1.859497308731079
Validation loss: 1.9732962058436485

Epoch: 5| Step: 9
Training loss: 1.5165950059890747
Validation loss: 1.9732677141825359

Epoch: 5| Step: 10
Training loss: 1.9305419921875
Validation loss: 1.978473259556678

Epoch: 142| Step: 0
Training loss: 1.662348747253418
Validation loss: 1.9953678038812452

Epoch: 5| Step: 1
Training loss: 2.0860085487365723
Validation loss: 1.9906836735304965

Epoch: 5| Step: 2
Training loss: 2.19218373298645
Validation loss: 1.9803560677395071

Epoch: 5| Step: 3
Training loss: 2.0535824298858643
Validation loss: 1.9689656073047268

Epoch: 5| Step: 4
Training loss: 2.032853603363037
Validation loss: 1.9683539918673936

Epoch: 5| Step: 5
Training loss: 2.2479186058044434
Validation loss: 1.986439690794996

Epoch: 5| Step: 6
Training loss: 2.204202651977539
Validation loss: 2.0108928526601484

Epoch: 5| Step: 7
Training loss: 1.5339648723602295
Validation loss: 2.0332426768477245

Epoch: 5| Step: 8
Training loss: 1.8982053995132446
Validation loss: 2.078278044218658

Epoch: 5| Step: 9
Training loss: 2.374547004699707
Validation loss: 2.156401515007019

Epoch: 5| Step: 10
Training loss: 1.185727834701538
Validation loss: 2.220109978029805

Epoch: 143| Step: 0
Training loss: 2.321643114089966
Validation loss: 2.2710494713116716

Epoch: 5| Step: 1
Training loss: 2.559781312942505
Validation loss: 2.211146039347495

Epoch: 5| Step: 2
Training loss: 2.5404934883117676
Validation loss: 2.1646529654020905

Epoch: 5| Step: 3
Training loss: 1.9037052392959595
Validation loss: 2.1158056336064495

Epoch: 5| Step: 4
Training loss: 2.0417447090148926
Validation loss: 2.0820307065081853

Epoch: 5| Step: 5
Training loss: 1.8019005060195923
Validation loss: 2.0554868610956336

Epoch: 5| Step: 6
Training loss: 1.9856183528900146
Validation loss: 2.0641147103360904

Epoch: 5| Step: 7
Training loss: 1.4896446466445923
Validation loss: 2.078811078943232

Epoch: 5| Step: 8
Training loss: 1.615096092224121
Validation loss: 2.0861650615610103

Epoch: 5| Step: 9
Training loss: 2.2186264991760254
Validation loss: 2.05796585031735

Epoch: 5| Step: 10
Training loss: 1.282029628753662
Validation loss: 2.0177700942562473

Epoch: 144| Step: 0
Training loss: 1.6087173223495483
Validation loss: 1.9728839448703233

Epoch: 5| Step: 1
Training loss: 2.3524181842803955
Validation loss: 1.9552851389813166

Epoch: 5| Step: 2
Training loss: 2.5126261711120605
Validation loss: 1.9257324408459406

Epoch: 5| Step: 3
Training loss: 1.9854259490966797
Validation loss: 1.9311560494925386

Epoch: 5| Step: 4
Training loss: 2.487645387649536
Validation loss: 1.9397831578408518

Epoch: 5| Step: 5
Training loss: 1.9985687732696533
Validation loss: 1.9849110341841174

Epoch: 5| Step: 6
Training loss: 1.7020460367202759
Validation loss: 2.02704055078568

Epoch: 5| Step: 7
Training loss: 1.6475133895874023
Validation loss: 2.0523958001085507

Epoch: 5| Step: 8
Training loss: 2.278006076812744
Validation loss: 2.055046914726175

Epoch: 5| Step: 9
Training loss: 1.7650066614151
Validation loss: 2.035628095749886

Epoch: 5| Step: 10
Training loss: 1.4179710149765015
Validation loss: 2.003227377450594

Epoch: 145| Step: 0
Training loss: 2.1915931701660156
Validation loss: 1.9872943252645514

Epoch: 5| Step: 1
Training loss: 1.4888046979904175
Validation loss: 1.9873848781790784

Epoch: 5| Step: 2
Training loss: 1.9338477849960327
Validation loss: 1.989539138732418

Epoch: 5| Step: 3
Training loss: 1.9531946182250977
Validation loss: 2.015862182904315

Epoch: 5| Step: 4
Training loss: 1.419609785079956
Validation loss: 2.052238554082891

Epoch: 5| Step: 5
Training loss: 1.8229280710220337
Validation loss: 2.1085324095141504

Epoch: 5| Step: 6
Training loss: 2.1843602657318115
Validation loss: 2.1460612973859234

Epoch: 5| Step: 7
Training loss: 2.1868953704833984
Validation loss: 2.1728702616947952

Epoch: 5| Step: 8
Training loss: 1.6991727352142334
Validation loss: 2.0949317434782624

Epoch: 5| Step: 9
Training loss: 2.410177707672119
Validation loss: 2.03857324969384

Epoch: 5| Step: 10
Training loss: 2.074263095855713
Validation loss: 1.9956534088298838

Epoch: 146| Step: 0
Training loss: 1.786921739578247
Validation loss: 1.9481579590869207

Epoch: 5| Step: 1
Training loss: 1.7372554540634155
Validation loss: 1.9419076006899598

Epoch: 5| Step: 2
Training loss: 2.279409170150757
Validation loss: 1.927761306044876

Epoch: 5| Step: 3
Training loss: 2.0495028495788574
Validation loss: 1.9203582297089279

Epoch: 5| Step: 4
Training loss: 2.3787970542907715
Validation loss: 1.9364580339001072

Epoch: 5| Step: 5
Training loss: 2.174656391143799
Validation loss: 1.9653706601870957

Epoch: 5| Step: 6
Training loss: 1.69723379611969
Validation loss: 2.0115579533320602

Epoch: 5| Step: 7
Training loss: 1.7710891962051392
Validation loss: 2.02512554712193

Epoch: 5| Step: 8
Training loss: 2.153428316116333
Validation loss: 2.0246687550698557

Epoch: 5| Step: 9
Training loss: 2.241668462753296
Validation loss: 2.0144389957510014

Epoch: 5| Step: 10
Training loss: 1.766047716140747
Validation loss: 2.0324866951152845

Epoch: 147| Step: 0
Training loss: 1.2770030498504639
Validation loss: 2.0220639692839755

Epoch: 5| Step: 1
Training loss: 1.5366896390914917
Validation loss: 2.0275579934479087

Epoch: 5| Step: 2
Training loss: 1.8130191564559937
Validation loss: 2.0231674589136595

Epoch: 5| Step: 3
Training loss: 2.0751683712005615
Validation loss: 2.00950538727545

Epoch: 5| Step: 4
Training loss: 1.9820773601531982
Validation loss: 1.9973270662369267

Epoch: 5| Step: 5
Training loss: 2.0168099403381348
Validation loss: 2.0348138052930116

Epoch: 5| Step: 6
Training loss: 1.7593482732772827
Validation loss: 2.0314198206829768

Epoch: 5| Step: 7
Training loss: 1.7261426448822021
Validation loss: 2.0501239107501124

Epoch: 5| Step: 8
Training loss: 2.5293262004852295
Validation loss: 2.0640356207406647

Epoch: 5| Step: 9
Training loss: 1.9338674545288086
Validation loss: 2.054353303806756

Epoch: 5| Step: 10
Training loss: 2.5114781856536865
Validation loss: 2.0457307087477816

Epoch: 148| Step: 0
Training loss: 1.6822712421417236
Validation loss: 2.0023975833769767

Epoch: 5| Step: 1
Training loss: 1.6851234436035156
Validation loss: 1.9844510824449602

Epoch: 5| Step: 2
Training loss: 2.199040651321411
Validation loss: 1.9968060806233396

Epoch: 5| Step: 3
Training loss: 1.790824294090271
Validation loss: 2.0088888573390182

Epoch: 5| Step: 4
Training loss: 2.300767183303833
Validation loss: 2.0283788942521617

Epoch: 5| Step: 5
Training loss: 1.7466195821762085
Validation loss: 2.036978958755411

Epoch: 5| Step: 6
Training loss: 1.9000803232192993
Validation loss: 2.061020694753175

Epoch: 5| Step: 7
Training loss: 2.3841350078582764
Validation loss: 2.0656998529229114

Epoch: 5| Step: 8
Training loss: 1.94429612159729
Validation loss: 2.1014789124970794

Epoch: 5| Step: 9
Training loss: 2.047325611114502
Validation loss: 2.109914505353538

Epoch: 5| Step: 10
Training loss: 1.311835765838623
Validation loss: 2.1072338781049176

Epoch: 149| Step: 0
Training loss: 1.5215699672698975
Validation loss: 2.096518248640081

Epoch: 5| Step: 1
Training loss: 1.633205771446228
Validation loss: 2.1188315217212965

Epoch: 5| Step: 2
Training loss: 2.0210325717926025
Validation loss: 2.1072110001758864

Epoch: 5| Step: 3
Training loss: 2.259108066558838
Validation loss: 2.0955415989762995

Epoch: 5| Step: 4
Training loss: 1.707531213760376
Validation loss: 2.076352337355255

Epoch: 5| Step: 5
Training loss: 1.8799912929534912
Validation loss: 2.0283847560164747

Epoch: 5| Step: 6
Training loss: 1.3054485321044922
Validation loss: 2.004103551628769

Epoch: 5| Step: 7
Training loss: 1.9915533065795898
Validation loss: 1.9916721210684827

Epoch: 5| Step: 8
Training loss: 2.7486448287963867
Validation loss: 1.9867222539840206

Epoch: 5| Step: 9
Training loss: 1.924708604812622
Validation loss: 1.9721425592258413

Epoch: 5| Step: 10
Training loss: 1.829767107963562
Validation loss: 2.0055523764702583

Epoch: 150| Step: 0
Training loss: 2.0432212352752686
Validation loss: 1.987294502155755

Epoch: 5| Step: 1
Training loss: 1.690526008605957
Validation loss: 2.008946445680434

Epoch: 5| Step: 2
Training loss: 1.471383810043335
Validation loss: 2.0000845078499085

Epoch: 5| Step: 3
Training loss: 2.0965445041656494
Validation loss: 1.995745183319174

Epoch: 5| Step: 4
Training loss: 1.7238807678222656
Validation loss: 2.0292171957672283

Epoch: 5| Step: 5
Training loss: 2.0549216270446777
Validation loss: 2.0267403318035986

Epoch: 5| Step: 6
Training loss: 1.6810314655303955
Validation loss: 2.0653728772235174

Epoch: 5| Step: 7
Training loss: 2.067352294921875
Validation loss: 2.108305432463205

Epoch: 5| Step: 8
Training loss: 1.8982521295547485
Validation loss: 2.0753219114836825

Epoch: 5| Step: 9
Training loss: 1.8367316722869873
Validation loss: 2.0108240112181632

Epoch: 5| Step: 10
Training loss: 2.2381632328033447
Validation loss: 1.950086914083009

Epoch: 151| Step: 0
Training loss: 1.597116470336914
Validation loss: 1.9214113194455382

Epoch: 5| Step: 1
Training loss: 1.6386245489120483
Validation loss: 1.9311667642285746

Epoch: 5| Step: 2
Training loss: 2.9219837188720703
Validation loss: 1.910803505169448

Epoch: 5| Step: 3
Training loss: 1.7133022546768188
Validation loss: 1.925755064974549

Epoch: 5| Step: 4
Training loss: 1.9218370914459229
Validation loss: 1.9494873016111312

Epoch: 5| Step: 5
Training loss: 1.3481566905975342
Validation loss: 1.9857068997557445

Epoch: 5| Step: 6
Training loss: 1.7886966466903687
Validation loss: 2.021809370287003

Epoch: 5| Step: 7
Training loss: 2.640775442123413
Validation loss: 2.082474822639137

Epoch: 5| Step: 8
Training loss: 2.343935489654541
Validation loss: 2.1219281701631445

Epoch: 5| Step: 9
Training loss: 1.8425594568252563
Validation loss: 2.1412011167054534

Epoch: 5| Step: 10
Training loss: 1.3185510635375977
Validation loss: 2.1146921932056384

Epoch: 152| Step: 0
Training loss: 1.7005687952041626
Validation loss: 2.0896245741075083

Epoch: 5| Step: 1
Training loss: 1.55253005027771
Validation loss: 2.023617776491309

Epoch: 5| Step: 2
Training loss: 2.3077621459960938
Validation loss: 1.9855614349406252

Epoch: 5| Step: 3
Training loss: 2.0938267707824707
Validation loss: 1.9819391414683352

Epoch: 5| Step: 4
Training loss: 2.3586859703063965
Validation loss: 2.0013455831876366

Epoch: 5| Step: 5
Training loss: 1.7867987155914307
Validation loss: 2.0382417709596696

Epoch: 5| Step: 6
Training loss: 1.6538960933685303
Validation loss: 2.0590153535207114

Epoch: 5| Step: 7
Training loss: 1.6729522943496704
Validation loss: 2.1119763312801236

Epoch: 5| Step: 8
Training loss: 1.3340413570404053
Validation loss: 2.1217386517473447

Epoch: 5| Step: 9
Training loss: 2.5475001335144043
Validation loss: 2.1067250620934272

Epoch: 5| Step: 10
Training loss: 1.4064899682998657
Validation loss: 2.0814382107027116

Epoch: 153| Step: 0
Training loss: 1.780082106590271
Validation loss: 2.0864553656629337

Epoch: 5| Step: 1
Training loss: 1.8748592138290405
Validation loss: 2.0580815576737925

Epoch: 5| Step: 2
Training loss: 2.264075517654419
Validation loss: 2.019180800325127

Epoch: 5| Step: 3
Training loss: 1.932535171508789
Validation loss: 1.9911692847487747

Epoch: 5| Step: 4
Training loss: 1.595000147819519
Validation loss: 1.9941006078515002

Epoch: 5| Step: 5
Training loss: 2.1576123237609863
Validation loss: 1.9822818386939265

Epoch: 5| Step: 6
Training loss: 1.8502705097198486
Validation loss: 2.0250025756897463

Epoch: 5| Step: 7
Training loss: 1.6942371129989624
Validation loss: 2.0927500301791775

Epoch: 5| Step: 8
Training loss: 2.0633373260498047
Validation loss: 2.1252710332152662

Epoch: 5| Step: 9
Training loss: 2.1752281188964844
Validation loss: 2.093635610354844

Epoch: 5| Step: 10
Training loss: 0.966668426990509
Validation loss: 2.069928046195738

Epoch: 154| Step: 0
Training loss: 1.9995132684707642
Validation loss: 2.037768430607293

Epoch: 5| Step: 1
Training loss: 2.489846706390381
Validation loss: 2.0159431311392013

Epoch: 5| Step: 2
Training loss: 1.4314956665039062
Validation loss: 1.9707720882149153

Epoch: 5| Step: 3
Training loss: 1.4202520847320557
Validation loss: 1.949059481261879

Epoch: 5| Step: 4
Training loss: 1.6655762195587158
Validation loss: 1.9399637893963886

Epoch: 5| Step: 5
Training loss: 2.0965418815612793
Validation loss: 1.932492438183036

Epoch: 5| Step: 6
Training loss: 1.6207681894302368
Validation loss: 1.9581764987719956

Epoch: 5| Step: 7
Training loss: 2.0649025440216064
Validation loss: 1.9700393817758048

Epoch: 5| Step: 8
Training loss: 1.8722851276397705
Validation loss: 2.0294389135094097

Epoch: 5| Step: 9
Training loss: 2.062828779220581
Validation loss: 2.076439239645517

Epoch: 5| Step: 10
Training loss: 1.7534911632537842
Validation loss: 2.0888185270370974

Epoch: 155| Step: 0
Training loss: 2.2638258934020996
Validation loss: 2.1140537800327426

Epoch: 5| Step: 1
Training loss: 1.556615948677063
Validation loss: 2.0899608045495968

Epoch: 5| Step: 2
Training loss: 1.7814403772354126
Validation loss: 2.0738064114765455

Epoch: 5| Step: 3
Training loss: 1.7767280340194702
Validation loss: 2.0895830764565417

Epoch: 5| Step: 4
Training loss: 1.7571640014648438
Validation loss: 2.0405373393848376

Epoch: 5| Step: 5
Training loss: 1.6896045207977295
Validation loss: 2.022387845541841

Epoch: 5| Step: 6
Training loss: 2.0075571537017822
Validation loss: 2.0033500707277687

Epoch: 5| Step: 7
Training loss: 1.9817670583724976
Validation loss: 1.9826086003293273

Epoch: 5| Step: 8
Training loss: 2.1065433025360107
Validation loss: 1.9602253283223798

Epoch: 5| Step: 9
Training loss: 2.224616527557373
Validation loss: 2.012531074144507

Epoch: 5| Step: 10
Training loss: 1.0422313213348389
Validation loss: 2.057408253351847

Epoch: 156| Step: 0
Training loss: 1.7382723093032837
Validation loss: 2.0865682248146302

Epoch: 5| Step: 1
Training loss: 1.5364543199539185
Validation loss: 2.099276263226745

Epoch: 5| Step: 2
Training loss: 1.445204734802246
Validation loss: 2.1475613219763643

Epoch: 5| Step: 3
Training loss: 2.492379665374756
Validation loss: 2.1609386064672984

Epoch: 5| Step: 4
Training loss: 1.5428135395050049
Validation loss: 2.128263004364506

Epoch: 5| Step: 5
Training loss: 1.9332282543182373
Validation loss: 2.079404346404537

Epoch: 5| Step: 6
Training loss: 1.8602575063705444
Validation loss: 2.0853439043926936

Epoch: 5| Step: 7
Training loss: 2.2259063720703125
Validation loss: 2.017078552194821

Epoch: 5| Step: 8
Training loss: 1.687879204750061
Validation loss: 1.9894741094240578

Epoch: 5| Step: 9
Training loss: 1.9901984930038452
Validation loss: 1.9447652985972743

Epoch: 5| Step: 10
Training loss: 1.797589898109436
Validation loss: 1.9408741035769064

Epoch: 157| Step: 0
Training loss: 1.7747596502304077
Validation loss: 1.9770147403081257

Epoch: 5| Step: 1
Training loss: 2.100247859954834
Validation loss: 1.9927509497570735

Epoch: 5| Step: 2
Training loss: 1.817063331604004
Validation loss: 2.0202407798459454

Epoch: 5| Step: 3
Training loss: 1.9085090160369873
Validation loss: 2.0661510062474076

Epoch: 5| Step: 4
Training loss: 1.5064610242843628
Validation loss: 2.0958007509990404

Epoch: 5| Step: 5
Training loss: 1.646834373474121
Validation loss: 2.119061052158315

Epoch: 5| Step: 6
Training loss: 1.7709887027740479
Validation loss: 2.074381637316878

Epoch: 5| Step: 7
Training loss: 2.169581651687622
Validation loss: 2.030578350508085

Epoch: 5| Step: 8
Training loss: 2.4103751182556152
Validation loss: 1.9919090604269376

Epoch: 5| Step: 9
Training loss: 2.0116617679595947
Validation loss: 1.9631483939386183

Epoch: 5| Step: 10
Training loss: 1.2736190557479858
Validation loss: 1.9671151689303819

Epoch: 158| Step: 0
Training loss: 1.8763229846954346
Validation loss: 1.9764628858976467

Epoch: 5| Step: 1
Training loss: 2.3850739002227783
Validation loss: 2.0160188598017537

Epoch: 5| Step: 2
Training loss: 1.9782726764678955
Validation loss: 2.0537060024917766

Epoch: 5| Step: 3
Training loss: 1.8675518035888672
Validation loss: 2.0796198768000447

Epoch: 5| Step: 4
Training loss: 2.02337384223938
Validation loss: 2.0856166347380607

Epoch: 5| Step: 5
Training loss: 1.815725326538086
Validation loss: 2.068050402466969

Epoch: 5| Step: 6
Training loss: 1.2327994108200073
Validation loss: 2.045944201048984

Epoch: 5| Step: 7
Training loss: 1.7759109735488892
Validation loss: 2.0452262009343793

Epoch: 5| Step: 8
Training loss: 1.8383533954620361
Validation loss: 2.03085490452346

Epoch: 5| Step: 9
Training loss: 1.4949876070022583
Validation loss: 2.0304903740523965

Epoch: 5| Step: 10
Training loss: 1.6212217807769775
Validation loss: 2.050809887147719

Epoch: 159| Step: 0
Training loss: 1.3084018230438232
Validation loss: 2.088959656735902

Epoch: 5| Step: 1
Training loss: 2.088042736053467
Validation loss: 2.138018336347354

Epoch: 5| Step: 2
Training loss: 1.7470417022705078
Validation loss: 2.108581878805673

Epoch: 5| Step: 3
Training loss: 2.02087664604187
Validation loss: 2.056303726729526

Epoch: 5| Step: 4
Training loss: 1.7351760864257812
Validation loss: 2.0007096182915474

Epoch: 5| Step: 5
Training loss: 2.1146867275238037
Validation loss: 1.9543494844949374

Epoch: 5| Step: 6
Training loss: 2.5214648246765137
Validation loss: 1.9464842888616747

Epoch: 5| Step: 7
Training loss: 1.7994416952133179
Validation loss: 1.960951805114746

Epoch: 5| Step: 8
Training loss: 2.1171486377716064
Validation loss: 1.9744686029290641

Epoch: 5| Step: 9
Training loss: 1.2440619468688965
Validation loss: 2.0333147125859417

Epoch: 5| Step: 10
Training loss: 1.3497251272201538
Validation loss: 2.090943587723599

Epoch: 160| Step: 0
Training loss: 1.3716020584106445
Validation loss: 2.1211565540682886

Epoch: 5| Step: 1
Training loss: 1.848870873451233
Validation loss: 2.131406767393953

Epoch: 5| Step: 2
Training loss: 1.485111117362976
Validation loss: 2.1045130657893356

Epoch: 5| Step: 3
Training loss: 2.136685848236084
Validation loss: 2.102013644351754

Epoch: 5| Step: 4
Training loss: 1.4859528541564941
Validation loss: 2.0712788258829424

Epoch: 5| Step: 5
Training loss: 2.023789882659912
Validation loss: 2.0152501906118085

Epoch: 5| Step: 6
Training loss: 1.7352492809295654
Validation loss: 2.0062726889887164

Epoch: 5| Step: 7
Training loss: 1.9936268329620361
Validation loss: 1.9908659355614775

Epoch: 5| Step: 8
Training loss: 1.9736945629119873
Validation loss: 1.957146236973424

Epoch: 5| Step: 9
Training loss: 1.758408784866333
Validation loss: 1.9445361603972733

Epoch: 5| Step: 10
Training loss: 1.8228479623794556
Validation loss: 1.9940302423251572

Epoch: 161| Step: 0
Training loss: 1.840179204940796
Validation loss: 2.0268123380599485

Epoch: 5| Step: 1
Training loss: 1.758737564086914
Validation loss: 2.0620301718352945

Epoch: 5| Step: 2
Training loss: 1.4367682933807373
Validation loss: 2.0933979429224485

Epoch: 5| Step: 3
Training loss: 1.2094674110412598
Validation loss: 2.0998371237067768

Epoch: 5| Step: 4
Training loss: 1.900333046913147
Validation loss: 2.1096835751687326

Epoch: 5| Step: 5
Training loss: 2.470288038253784
Validation loss: 2.0915173663887927

Epoch: 5| Step: 6
Training loss: 1.8029810190200806
Validation loss: 2.0722777946020967

Epoch: 5| Step: 7
Training loss: 1.536150336265564
Validation loss: 2.0431314206892446

Epoch: 5| Step: 8
Training loss: 1.7693771123886108
Validation loss: 2.0390145547928347

Epoch: 5| Step: 9
Training loss: 2.1296887397766113
Validation loss: 2.0233895368473505

Epoch: 5| Step: 10
Training loss: 1.6717509031295776
Validation loss: 1.9732479305677517

Epoch: 162| Step: 0
Training loss: 1.5331931114196777
Validation loss: 1.9499210529429938

Epoch: 5| Step: 1
Training loss: 1.6108856201171875
Validation loss: 1.926557566529961

Epoch: 5| Step: 2
Training loss: 1.5125925540924072
Validation loss: 1.9438653786977131

Epoch: 5| Step: 3
Training loss: 2.5324816703796387
Validation loss: 1.9551844519953574

Epoch: 5| Step: 4
Training loss: 1.4651111364364624
Validation loss: 1.9934377208832772

Epoch: 5| Step: 5
Training loss: 1.9669281244277954
Validation loss: 2.024357970042895

Epoch: 5| Step: 6
Training loss: 2.0241360664367676
Validation loss: 2.019111015463388

Epoch: 5| Step: 7
Training loss: 1.9490888118743896
Validation loss: 2.0136045409787084

Epoch: 5| Step: 8
Training loss: 1.688594102859497
Validation loss: 1.9940816651108444

Epoch: 5| Step: 9
Training loss: 1.909364104270935
Validation loss: 2.0005587608583513

Epoch: 5| Step: 10
Training loss: 1.460886001586914
Validation loss: 1.990746126380018

Epoch: 163| Step: 0
Training loss: 1.514782428741455
Validation loss: 2.008200999229185

Epoch: 5| Step: 1
Training loss: 1.4731050729751587
Validation loss: 1.9906153089256697

Epoch: 5| Step: 2
Training loss: 1.7420860528945923
Validation loss: 1.9858369135087537

Epoch: 5| Step: 3
Training loss: 2.11627459526062
Validation loss: 1.9536508385853102

Epoch: 5| Step: 4
Training loss: 1.6540536880493164
Validation loss: 1.937964459901215

Epoch: 5| Step: 5
Training loss: 1.9187170267105103
Validation loss: 1.9528469039547829

Epoch: 5| Step: 6
Training loss: 1.6278880834579468
Validation loss: 1.9706698617627543

Epoch: 5| Step: 7
Training loss: 1.5457971096038818
Validation loss: 1.986872475634339

Epoch: 5| Step: 8
Training loss: 1.491957426071167
Validation loss: 2.0604887995668637

Epoch: 5| Step: 9
Training loss: 2.323319673538208
Validation loss: 2.0677513050776657

Epoch: 5| Step: 10
Training loss: 1.9859377145767212
Validation loss: 2.074717364003581

Epoch: 164| Step: 0
Training loss: 1.7910032272338867
Validation loss: 2.0305314012753066

Epoch: 5| Step: 1
Training loss: 1.7986196279525757
Validation loss: 2.00002146023576

Epoch: 5| Step: 2
Training loss: 1.5583384037017822
Validation loss: 1.9661919442556237

Epoch: 5| Step: 3
Training loss: 1.4373620748519897
Validation loss: 1.9299170432552215

Epoch: 5| Step: 4
Training loss: 2.0541839599609375
Validation loss: 1.9183184177644792

Epoch: 5| Step: 5
Training loss: 2.013576030731201
Validation loss: 1.9154788935056297

Epoch: 5| Step: 6
Training loss: 2.2946064472198486
Validation loss: 1.9200659131491056

Epoch: 5| Step: 7
Training loss: 1.7255890369415283
Validation loss: 1.9418148417626657

Epoch: 5| Step: 8
Training loss: 1.4199422597885132
Validation loss: 1.9619785329347015

Epoch: 5| Step: 9
Training loss: 1.5591315031051636
Validation loss: 2.0399434694679837

Epoch: 5| Step: 10
Training loss: 2.037747859954834
Validation loss: 2.0621061466073476

Epoch: 165| Step: 0
Training loss: 1.5544757843017578
Validation loss: 2.0524821319887714

Epoch: 5| Step: 1
Training loss: 1.8148177862167358
Validation loss: 2.041705077694308

Epoch: 5| Step: 2
Training loss: 1.8124122619628906
Validation loss: 2.01664932568868

Epoch: 5| Step: 3
Training loss: 1.4339158535003662
Validation loss: 2.0077714945680354

Epoch: 5| Step: 4
Training loss: 2.377659320831299
Validation loss: 2.0231711428652526

Epoch: 5| Step: 5
Training loss: 1.8843826055526733
Validation loss: 2.0484719289246427

Epoch: 5| Step: 6
Training loss: 2.584057569503784
Validation loss: 2.020862510127406

Epoch: 5| Step: 7
Training loss: 1.619971513748169
Validation loss: 2.040814748374365

Epoch: 5| Step: 8
Training loss: 1.2329270839691162
Validation loss: 2.040936632822919

Epoch: 5| Step: 9
Training loss: 1.4257285594940186
Validation loss: 2.0498522635429137

Epoch: 5| Step: 10
Training loss: 1.5158976316452026
Validation loss: 2.057363881859728

Epoch: 166| Step: 0
Training loss: 1.9303029775619507
Validation loss: 2.0349381585274973

Epoch: 5| Step: 1
Training loss: 1.927593469619751
Validation loss: 1.9883681727993874

Epoch: 5| Step: 2
Training loss: 2.1023812294006348
Validation loss: 1.9736286799112956

Epoch: 5| Step: 3
Training loss: 1.980736494064331
Validation loss: 1.984749468423987

Epoch: 5| Step: 4
Training loss: 1.6103379726409912
Validation loss: 2.036919229774065

Epoch: 5| Step: 5
Training loss: 1.7371273040771484
Validation loss: 2.0890262280741045

Epoch: 5| Step: 6
Training loss: 1.9664417505264282
Validation loss: 2.0827034724655973

Epoch: 5| Step: 7
Training loss: 1.5844240188598633
Validation loss: 2.0971867217812488

Epoch: 5| Step: 8
Training loss: 1.5837360620498657
Validation loss: 2.074556363526211

Epoch: 5| Step: 9
Training loss: 1.2984044551849365
Validation loss: 2.028648148300827

Epoch: 5| Step: 10
Training loss: 1.4982925653457642
Validation loss: 1.9695102296849734

Epoch: 167| Step: 0
Training loss: 1.559407114982605
Validation loss: 1.9561471426358787

Epoch: 5| Step: 1
Training loss: 2.2819337844848633
Validation loss: 1.9713221647406136

Epoch: 5| Step: 2
Training loss: 1.4832565784454346
Validation loss: 1.9627809537354337

Epoch: 5| Step: 3
Training loss: 1.8517637252807617
Validation loss: 2.0050205158930954

Epoch: 5| Step: 4
Training loss: 2.2788264751434326
Validation loss: 2.04429958199942

Epoch: 5| Step: 5
Training loss: 1.8755967617034912
Validation loss: 2.0629258566005255

Epoch: 5| Step: 6
Training loss: 2.2505064010620117
Validation loss: 2.078447905919885

Epoch: 5| Step: 7
Training loss: 1.280606985092163
Validation loss: 2.0778860571563884

Epoch: 5| Step: 8
Training loss: 1.5671586990356445
Validation loss: 2.0468567353422924

Epoch: 5| Step: 9
Training loss: 1.2396329641342163
Validation loss: 2.0401190955151796

Epoch: 5| Step: 10
Training loss: 1.2091773748397827
Validation loss: 2.0396379270861225

Epoch: 168| Step: 0
Training loss: 1.9790198802947998
Validation loss: 2.008259037489532

Epoch: 5| Step: 1
Training loss: 1.9348281621932983
Validation loss: 2.006041003811744

Epoch: 5| Step: 2
Training loss: 1.9277366399765015
Validation loss: 1.9901178344603507

Epoch: 5| Step: 3
Training loss: 1.6280715465545654
Validation loss: 1.9811610278262888

Epoch: 5| Step: 4
Training loss: 1.5391589403152466
Validation loss: 1.9617090827675276

Epoch: 5| Step: 5
Training loss: 1.8051906824111938
Validation loss: 1.984221286671136

Epoch: 5| Step: 6
Training loss: 0.955380916595459
Validation loss: 1.9905842747739566

Epoch: 5| Step: 7
Training loss: 2.3044931888580322
Validation loss: 1.999177058537801

Epoch: 5| Step: 8
Training loss: 1.257409930229187
Validation loss: 2.0329657934045278

Epoch: 5| Step: 9
Training loss: 1.3822901248931885
Validation loss: 2.086187343443594

Epoch: 5| Step: 10
Training loss: 1.8338688611984253
Validation loss: 2.0984725093328827

Epoch: 169| Step: 0
Training loss: 1.2279253005981445
Validation loss: 2.111519093154579

Epoch: 5| Step: 1
Training loss: 1.4583799839019775
Validation loss: 2.0935633259434856

Epoch: 5| Step: 2
Training loss: 1.9664156436920166
Validation loss: 2.0569513049176944

Epoch: 5| Step: 3
Training loss: 1.8638423681259155
Validation loss: 1.997626704554404

Epoch: 5| Step: 4
Training loss: 1.8258850574493408
Validation loss: 1.9468931639066307

Epoch: 5| Step: 5
Training loss: 2.2766921520233154
Validation loss: 1.9360326323457944

Epoch: 5| Step: 6
Training loss: 1.3808059692382812
Validation loss: 1.938628601771529

Epoch: 5| Step: 7
Training loss: 1.8005222082138062
Validation loss: 1.9632188133014146

Epoch: 5| Step: 8
Training loss: 1.6440722942352295
Validation loss: 2.0296514405999133

Epoch: 5| Step: 9
Training loss: 1.7199691534042358
Validation loss: 2.0753858371447493

Epoch: 5| Step: 10
Training loss: 2.016583204269409
Validation loss: 2.1205856646260908

Epoch: 170| Step: 0
Training loss: 1.3358074426651
Validation loss: 2.1159828991018315

Epoch: 5| Step: 1
Training loss: 1.3401423692703247
Validation loss: 2.0880659549467024

Epoch: 5| Step: 2
Training loss: 1.5430123805999756
Validation loss: 2.014932442736882

Epoch: 5| Step: 3
Training loss: 1.5881620645523071
Validation loss: 1.975517338322055

Epoch: 5| Step: 4
Training loss: 1.771885633468628
Validation loss: 1.9472186757672219

Epoch: 5| Step: 5
Training loss: 2.0424208641052246
Validation loss: 1.9579380789110739

Epoch: 5| Step: 6
Training loss: 2.224931001663208
Validation loss: 1.9815161330725557

Epoch: 5| Step: 7
Training loss: 1.8138840198516846
Validation loss: 2.035736899222097

Epoch: 5| Step: 8
Training loss: 1.967254638671875
Validation loss: 2.0975990859411096

Epoch: 5| Step: 9
Training loss: 2.2556257247924805
Validation loss: 2.2000667933494813

Epoch: 5| Step: 10
Training loss: 1.6388216018676758
Validation loss: 2.1780334416256157

Epoch: 171| Step: 0
Training loss: 1.74270761013031
Validation loss: 2.1206967753748738

Epoch: 5| Step: 1
Training loss: 2.2374281883239746
Validation loss: 2.068815997851792

Epoch: 5| Step: 2
Training loss: 1.89453125
Validation loss: 2.0071062439231464

Epoch: 5| Step: 3
Training loss: 1.5253335237503052
Validation loss: 1.9689650804765764

Epoch: 5| Step: 4
Training loss: 1.8886200189590454
Validation loss: 1.9297318971285256

Epoch: 5| Step: 5
Training loss: 1.3315227031707764
Validation loss: 1.923604497345545

Epoch: 5| Step: 6
Training loss: 1.9035367965698242
Validation loss: 1.9236953578969485

Epoch: 5| Step: 7
Training loss: 1.9797484874725342
Validation loss: 1.9524380891553816

Epoch: 5| Step: 8
Training loss: 1.2299093008041382
Validation loss: 1.9817796881480882

Epoch: 5| Step: 9
Training loss: 1.8408724069595337
Validation loss: 2.0144916042204826

Epoch: 5| Step: 10
Training loss: 1.4018776416778564
Validation loss: 2.0432812219024985

Epoch: 172| Step: 0
Training loss: 1.7809078693389893
Validation loss: 2.079834968813004

Epoch: 5| Step: 1
Training loss: 1.9725135564804077
Validation loss: 2.072173051936652

Epoch: 5| Step: 2
Training loss: 1.7712385654449463
Validation loss: 2.135684335103599

Epoch: 5| Step: 3
Training loss: 1.4041337966918945
Validation loss: 2.1328860752044188

Epoch: 5| Step: 4
Training loss: 1.7582311630249023
Validation loss: 2.0798465359595513

Epoch: 5| Step: 5
Training loss: 1.6998622417449951
Validation loss: 2.0626699514286493

Epoch: 5| Step: 6
Training loss: 1.3427077531814575
Validation loss: 2.0088614545842653

Epoch: 5| Step: 7
Training loss: 1.5382740497589111
Validation loss: 1.9328699829757854

Epoch: 5| Step: 8
Training loss: 1.819668173789978
Validation loss: 1.917139869864269

Epoch: 5| Step: 9
Training loss: 1.4950337409973145
Validation loss: 1.9345326244190175

Epoch: 5| Step: 10
Training loss: 2.1976821422576904
Validation loss: 1.934921000593452

Epoch: 173| Step: 0
Training loss: 1.701521635055542
Validation loss: 1.9462702851141653

Epoch: 5| Step: 1
Training loss: 2.299403429031372
Validation loss: 1.93141540404289

Epoch: 5| Step: 2
Training loss: 2.1056623458862305
Validation loss: 1.9353534790777391

Epoch: 5| Step: 3
Training loss: 1.4601306915283203
Validation loss: 1.9430410810696181

Epoch: 5| Step: 4
Training loss: 1.9644403457641602
Validation loss: 1.96418014905786

Epoch: 5| Step: 5
Training loss: 1.0437251329421997
Validation loss: 2.011829013465553

Epoch: 5| Step: 6
Training loss: 1.9870541095733643
Validation loss: 2.035008866299865

Epoch: 5| Step: 7
Training loss: 1.1881648302078247
Validation loss: 2.01926351106295

Epoch: 5| Step: 8
Training loss: 1.624419927597046
Validation loss: 2.041673247532178

Epoch: 5| Step: 9
Training loss: 2.0568900108337402
Validation loss: 2.017263072793202

Epoch: 5| Step: 10
Training loss: 1.1127029657363892
Validation loss: 1.9999293742641326

Epoch: 174| Step: 0
Training loss: 1.5308921337127686
Validation loss: 2.0083830228415867

Epoch: 5| Step: 1
Training loss: 1.943524718284607
Validation loss: 2.0371265411376953

Epoch: 5| Step: 2
Training loss: 1.8692073822021484
Validation loss: 2.0490261918754986

Epoch: 5| Step: 3
Training loss: 1.6336969137191772
Validation loss: 2.057984621294083

Epoch: 5| Step: 4
Training loss: 1.2060611248016357
Validation loss: 2.0475355655916276

Epoch: 5| Step: 5
Training loss: 1.081688404083252
Validation loss: 2.0369607222977506

Epoch: 5| Step: 6
Training loss: 1.5831810235977173
Validation loss: 2.0168613900420485

Epoch: 5| Step: 7
Training loss: 1.9327949285507202
Validation loss: 2.027173449916224

Epoch: 5| Step: 8
Training loss: 2.257539749145508
Validation loss: 2.0202404222180768

Epoch: 5| Step: 9
Training loss: 1.5738375186920166
Validation loss: 2.0217077219358055

Epoch: 5| Step: 10
Training loss: 1.644416093826294
Validation loss: 2.0021631358772196

Epoch: 175| Step: 0
Training loss: 1.1172540187835693
Validation loss: 2.011368774598645

Epoch: 5| Step: 1
Training loss: 1.7750723361968994
Validation loss: 2.0232010015877346

Epoch: 5| Step: 2
Training loss: 2.0195541381835938
Validation loss: 2.076972652507085

Epoch: 5| Step: 3
Training loss: 1.1672788858413696
Validation loss: 2.0982249834204234

Epoch: 5| Step: 4
Training loss: 1.650726079940796
Validation loss: 2.1074102309442337

Epoch: 5| Step: 5
Training loss: 1.4809226989746094
Validation loss: 2.1093229939860683

Epoch: 5| Step: 6
Training loss: 1.7396690845489502
Validation loss: 2.0562727887143373

Epoch: 5| Step: 7
Training loss: 1.9567651748657227
Validation loss: 2.0157766572890745

Epoch: 5| Step: 8
Training loss: 1.2995481491088867
Validation loss: 2.02310436771762

Epoch: 5| Step: 9
Training loss: 1.6446170806884766
Validation loss: 2.006420853317425

Epoch: 5| Step: 10
Training loss: 2.6756105422973633
Validation loss: 1.9923328609876736

Epoch: 176| Step: 0
Training loss: 1.4326817989349365
Validation loss: 2.0149331105652677

Epoch: 5| Step: 1
Training loss: 1.9471204280853271
Validation loss: 2.049530993225754

Epoch: 5| Step: 2
Training loss: 1.767049789428711
Validation loss: 2.107995281937302

Epoch: 5| Step: 3
Training loss: 1.4925081729888916
Validation loss: 2.079436530349075

Epoch: 5| Step: 4
Training loss: 1.883639931678772
Validation loss: 2.0754523508010374

Epoch: 5| Step: 5
Training loss: 1.734337568283081
Validation loss: 2.0617007183772262

Epoch: 5| Step: 6
Training loss: 2.524722099304199
Validation loss: 2.0419890175583544

Epoch: 5| Step: 7
Training loss: 1.0826441049575806
Validation loss: 1.9859222853055565

Epoch: 5| Step: 8
Training loss: 1.7266790866851807
Validation loss: 1.9341325516341834

Epoch: 5| Step: 9
Training loss: 1.3923979997634888
Validation loss: 1.9286671376997424

Epoch: 5| Step: 10
Training loss: 1.5328508615493774
Validation loss: 1.9288508328058387

Epoch: 177| Step: 0
Training loss: 1.301727533340454
Validation loss: 1.9774263546031008

Epoch: 5| Step: 1
Training loss: 1.4848413467407227
Validation loss: 2.028668843289857

Epoch: 5| Step: 2
Training loss: 2.151576280593872
Validation loss: 2.074230403028509

Epoch: 5| Step: 3
Training loss: 1.2526452541351318
Validation loss: 2.116556921312886

Epoch: 5| Step: 4
Training loss: 1.845767617225647
Validation loss: 2.1352407329825946

Epoch: 5| Step: 5
Training loss: 1.6997909545898438
Validation loss: 2.0532903055990896

Epoch: 5| Step: 6
Training loss: 1.1434897184371948
Validation loss: 1.9918696726522138

Epoch: 5| Step: 7
Training loss: 1.4250978231430054
Validation loss: 1.9349981546401978

Epoch: 5| Step: 8
Training loss: 1.932354211807251
Validation loss: 1.9336349989778252

Epoch: 5| Step: 9
Training loss: 1.8444797992706299
Validation loss: 1.927711365043476

Epoch: 5| Step: 10
Training loss: 2.426515579223633
Validation loss: 1.9393856294693486

Epoch: 178| Step: 0
Training loss: 1.8010867834091187
Validation loss: 2.0148088496218444

Epoch: 5| Step: 1
Training loss: 1.9590650796890259
Validation loss: 2.105506755972421

Epoch: 5| Step: 2
Training loss: 1.6483142375946045
Validation loss: 2.1490934420657415

Epoch: 5| Step: 3
Training loss: 1.3509166240692139
Validation loss: 2.155410946056407

Epoch: 5| Step: 4
Training loss: 2.5116171836853027
Validation loss: 2.162522631306802

Epoch: 5| Step: 5
Training loss: 1.4024549722671509
Validation loss: 2.1334404894100722

Epoch: 5| Step: 6
Training loss: 1.6362460851669312
Validation loss: 2.0616334587015133

Epoch: 5| Step: 7
Training loss: 1.7412078380584717
Validation loss: 2.0344976661025838

Epoch: 5| Step: 8
Training loss: 1.1294019222259521
Validation loss: 1.9899315731499785

Epoch: 5| Step: 9
Training loss: 2.1399593353271484
Validation loss: 1.9767223699118501

Epoch: 5| Step: 10
Training loss: 1.2875800132751465
Validation loss: 1.9502405940845449

Epoch: 179| Step: 0
Training loss: 1.0927050113677979
Validation loss: 1.964947481309214

Epoch: 5| Step: 1
Training loss: 2.0279674530029297
Validation loss: 2.0009081145768524

Epoch: 5| Step: 2
Training loss: 1.1404263973236084
Validation loss: 2.0521455669915802

Epoch: 5| Step: 3
Training loss: 1.5890309810638428
Validation loss: 2.058714428255635

Epoch: 5| Step: 4
Training loss: 1.7531187534332275
Validation loss: 2.118622890082739

Epoch: 5| Step: 5
Training loss: 2.2492425441741943
Validation loss: 2.1930740366699877

Epoch: 5| Step: 6
Training loss: 1.9588024616241455
Validation loss: 2.164636758065993

Epoch: 5| Step: 7
Training loss: 1.7503364086151123
Validation loss: 2.140742563432263

Epoch: 5| Step: 8
Training loss: 1.4599528312683105
Validation loss: 2.0663847500278103

Epoch: 5| Step: 9
Training loss: 1.8976895809173584
Validation loss: 1.9939161833896433

Epoch: 5| Step: 10
Training loss: 1.416696548461914
Validation loss: 1.9671932010240452

Epoch: 180| Step: 0
Training loss: 1.55857253074646
Validation loss: 1.9375236213848155

Epoch: 5| Step: 1
Training loss: 1.8362849950790405
Validation loss: 1.9305943801838865

Epoch: 5| Step: 2
Training loss: 1.4206535816192627
Validation loss: 1.9446083191902406

Epoch: 5| Step: 3
Training loss: 1.6506545543670654
Validation loss: 1.9605672436375772

Epoch: 5| Step: 4
Training loss: 1.6284666061401367
Validation loss: 2.0047380488405944

Epoch: 5| Step: 5
Training loss: 1.706006646156311
Validation loss: 2.0176301669049006

Epoch: 5| Step: 6
Training loss: 1.0183722972869873
Validation loss: 2.0404207796178837

Epoch: 5| Step: 7
Training loss: 1.6053979396820068
Validation loss: 2.0545489736782607

Epoch: 5| Step: 8
Training loss: 2.273951768875122
Validation loss: 2.08127046785047

Epoch: 5| Step: 9
Training loss: 1.5620596408843994
Validation loss: 2.0779264767964682

Epoch: 5| Step: 10
Training loss: 1.6689507961273193
Validation loss: 2.0710604306190246

Epoch: 181| Step: 0
Training loss: 1.6796576976776123
Validation loss: 2.0368765707938903

Epoch: 5| Step: 1
Training loss: 1.3190611600875854
Validation loss: 2.0212798041682087

Epoch: 5| Step: 2
Training loss: 1.6472619771957397
Validation loss: 2.019771332381874

Epoch: 5| Step: 3
Training loss: 1.5890685319900513
Validation loss: 1.9900344392304778

Epoch: 5| Step: 4
Training loss: 1.6678588390350342
Validation loss: 1.9793366719317693

Epoch: 5| Step: 5
Training loss: 1.3141134977340698
Validation loss: 1.9629089922033331

Epoch: 5| Step: 6
Training loss: 1.6216955184936523
Validation loss: 1.9636415730240524

Epoch: 5| Step: 7
Training loss: 2.1444709300994873
Validation loss: 1.9614571038112845

Epoch: 5| Step: 8
Training loss: 0.8988353610038757
Validation loss: 1.9498158885586647

Epoch: 5| Step: 9
Training loss: 1.4295042753219604
Validation loss: 1.9558591945196993

Epoch: 5| Step: 10
Training loss: 2.1220481395721436
Validation loss: 1.956768330707345

Epoch: 182| Step: 0
Training loss: 1.8793249130249023
Validation loss: 1.9520895493927823

Epoch: 5| Step: 1
Training loss: 1.3429282903671265
Validation loss: 1.987883270427745

Epoch: 5| Step: 2
Training loss: 1.7477458715438843
Validation loss: 2.0231612100396106

Epoch: 5| Step: 3
Training loss: 1.5467700958251953
Validation loss: 2.0423379969853226

Epoch: 5| Step: 4
Training loss: 1.478179693222046
Validation loss: 2.013915784897343

Epoch: 5| Step: 5
Training loss: 1.5728352069854736
Validation loss: 1.9978642232956425

Epoch: 5| Step: 6
Training loss: 1.2769982814788818
Validation loss: 1.9891897170774397

Epoch: 5| Step: 7
Training loss: 1.554224967956543
Validation loss: 1.975525394562752

Epoch: 5| Step: 8
Training loss: 2.1944565773010254
Validation loss: 1.9927992359284432

Epoch: 5| Step: 9
Training loss: 1.4564439058303833
Validation loss: 1.9596201655685261

Epoch: 5| Step: 10
Training loss: 1.2802119255065918
Validation loss: 1.9444426118686635

Epoch: 183| Step: 0
Training loss: 1.7503162622451782
Validation loss: 1.9722770952409314

Epoch: 5| Step: 1
Training loss: 1.3024709224700928
Validation loss: 1.9661346763692877

Epoch: 5| Step: 2
Training loss: 1.4771430492401123
Validation loss: 1.9974880244142266

Epoch: 5| Step: 3
Training loss: 1.7793020009994507
Validation loss: 2.052558437470467

Epoch: 5| Step: 4
Training loss: 1.5990347862243652
Validation loss: 2.07610244904795

Epoch: 5| Step: 5
Training loss: 1.7692039012908936
Validation loss: 2.074031270960326

Epoch: 5| Step: 6
Training loss: 1.389817714691162
Validation loss: 2.0262254335547007

Epoch: 5| Step: 7
Training loss: 1.3657283782958984
Validation loss: 2.003317125381962

Epoch: 5| Step: 8
Training loss: 1.8734924793243408
Validation loss: 1.9849896366878221

Epoch: 5| Step: 9
Training loss: 1.7796821594238281
Validation loss: 1.9369301411413378

Epoch: 5| Step: 10
Training loss: 1.6488940715789795
Validation loss: 1.8937861868130264

Epoch: 184| Step: 0
Training loss: 1.5801074504852295
Validation loss: 1.8873780619713567

Epoch: 5| Step: 1
Training loss: 1.3813526630401611
Validation loss: 1.935796206997287

Epoch: 5| Step: 2
Training loss: 1.7626125812530518
Validation loss: 2.002040506691061

Epoch: 5| Step: 3
Training loss: 1.8564965724945068
Validation loss: 2.0891995506901897

Epoch: 5| Step: 4
Training loss: 1.3014657497406006
Validation loss: 2.1147207829260055

Epoch: 5| Step: 5
Training loss: 1.8064085245132446
Validation loss: 2.1481122316852694

Epoch: 5| Step: 6
Training loss: 2.1536600589752197
Validation loss: 2.1302590421451035

Epoch: 5| Step: 7
Training loss: 1.3325955867767334
Validation loss: 2.0979458285916235

Epoch: 5| Step: 8
Training loss: 1.222553014755249
Validation loss: 2.040911397626323

Epoch: 5| Step: 9
Training loss: 1.5232104063034058
Validation loss: 1.9988070841758483

Epoch: 5| Step: 10
Training loss: 1.8446177244186401
Validation loss: 1.9867957843247281

Epoch: 185| Step: 0
Training loss: 1.4509387016296387
Validation loss: 1.9956710723138624

Epoch: 5| Step: 1
Training loss: 0.7687318325042725
Validation loss: 1.9889979490669825

Epoch: 5| Step: 2
Training loss: 1.5651580095291138
Validation loss: 2.0558232363834175

Epoch: 5| Step: 3
Training loss: 2.2531771659851074
Validation loss: 2.079791348467591

Epoch: 5| Step: 4
Training loss: 1.7776635885238647
Validation loss: 2.0731416863779866

Epoch: 5| Step: 5
Training loss: 2.1125216484069824
Validation loss: 2.066913039453568

Epoch: 5| Step: 6
Training loss: 1.3378424644470215
Validation loss: 1.9869606443630752

Epoch: 5| Step: 7
Training loss: 1.6011021137237549
Validation loss: 1.9099267016174972

Epoch: 5| Step: 8
Training loss: 1.6888980865478516
Validation loss: 1.8778992006855626

Epoch: 5| Step: 9
Training loss: 1.7923511266708374
Validation loss: 1.8588860637398177

Epoch: 5| Step: 10
Training loss: 1.4479591846466064
Validation loss: 1.8714968209625573

Epoch: 186| Step: 0
Training loss: 1.9012863636016846
Validation loss: 1.895775423255018

Epoch: 5| Step: 1
Training loss: 1.5146328210830688
Validation loss: 1.906316352146928

Epoch: 5| Step: 2
Training loss: 1.7693536281585693
Validation loss: 1.9463194070323822

Epoch: 5| Step: 3
Training loss: 1.4373431205749512
Validation loss: 1.9805057279525264

Epoch: 5| Step: 4
Training loss: 1.803300142288208
Validation loss: 2.0509267801879556

Epoch: 5| Step: 5
Training loss: 1.5782978534698486
Validation loss: 2.1016735466577674

Epoch: 5| Step: 6
Training loss: 1.5152361392974854
Validation loss: 2.0950758764820714

Epoch: 5| Step: 7
Training loss: 1.542136788368225
Validation loss: 2.066265530483697

Epoch: 5| Step: 8
Training loss: 0.9542690515518188
Validation loss: 2.0096336205800376

Epoch: 5| Step: 9
Training loss: 1.4884105920791626
Validation loss: 1.9770463666608256

Epoch: 5| Step: 10
Training loss: 1.5943061113357544
Validation loss: 1.9502131490297214

Epoch: 187| Step: 0
Training loss: 2.0460002422332764
Validation loss: 1.9632633655301985

Epoch: 5| Step: 1
Training loss: 1.609798789024353
Validation loss: 1.961140348065284

Epoch: 5| Step: 2
Training loss: 1.2442184686660767
Validation loss: 1.9798772924689836

Epoch: 5| Step: 3
Training loss: 1.3169691562652588
Validation loss: 2.015976195694298

Epoch: 5| Step: 4
Training loss: 1.7700698375701904
Validation loss: 2.0641187442246305

Epoch: 5| Step: 5
Training loss: 1.0614099502563477
Validation loss: 2.111515529694096

Epoch: 5| Step: 6
Training loss: 2.1711833477020264
Validation loss: 2.1265301499315488

Epoch: 5| Step: 7
Training loss: 1.4875009059906006
Validation loss: 2.0861415324672574

Epoch: 5| Step: 8
Training loss: 1.3928964138031006
Validation loss: 2.0195708697842014

Epoch: 5| Step: 9
Training loss: 1.479452133178711
Validation loss: 1.9725838963703444

Epoch: 5| Step: 10
Training loss: 1.8773292303085327
Validation loss: 1.9238878911541355

Epoch: 188| Step: 0
Training loss: 1.7726147174835205
Validation loss: 1.881765406618836

Epoch: 5| Step: 1
Training loss: 1.5691719055175781
Validation loss: 1.8864222675241449

Epoch: 5| Step: 2
Training loss: 1.68979012966156
Validation loss: 1.8687571812701482

Epoch: 5| Step: 3
Training loss: 1.2420564889907837
Validation loss: 1.8631833830187399

Epoch: 5| Step: 4
Training loss: 1.3154749870300293
Validation loss: 1.874642478522434

Epoch: 5| Step: 5
Training loss: 1.5523258447647095
Validation loss: 1.8930941320234729

Epoch: 5| Step: 6
Training loss: 1.224045991897583
Validation loss: 1.909396489461263

Epoch: 5| Step: 7
Training loss: 1.8882286548614502
Validation loss: 1.933213307011512

Epoch: 5| Step: 8
Training loss: 1.1033899784088135
Validation loss: 1.9821819259274391

Epoch: 5| Step: 9
Training loss: 2.162398338317871
Validation loss: 1.9978225820808

Epoch: 5| Step: 10
Training loss: 1.7808321714401245
Validation loss: 2.0486867940554054

Epoch: 189| Step: 0
Training loss: 1.4763051271438599
Validation loss: 2.0453109049027964

Epoch: 5| Step: 1
Training loss: 1.6764246225357056
Validation loss: 2.066733870455014

Epoch: 5| Step: 2
Training loss: 1.452300786972046
Validation loss: 2.057255715452215

Epoch: 5| Step: 3
Training loss: 1.4546855688095093
Validation loss: 2.0586393943396946

Epoch: 5| Step: 4
Training loss: 1.380361557006836
Validation loss: 2.047668828759142

Epoch: 5| Step: 5
Training loss: 1.1358850002288818
Validation loss: 2.0167872149457216

Epoch: 5| Step: 6
Training loss: 1.719138503074646
Validation loss: 1.974418350445327

Epoch: 5| Step: 7
Training loss: 1.6361188888549805
Validation loss: 1.9357664431295087

Epoch: 5| Step: 8
Training loss: 1.6131317615509033
Validation loss: 1.8947849376227266

Epoch: 5| Step: 9
Training loss: 1.752812147140503
Validation loss: 1.9060837696957331

Epoch: 5| Step: 10
Training loss: 1.6478863954544067
Validation loss: 1.9068675938472952

Epoch: 190| Step: 0
Training loss: 1.638183355331421
Validation loss: 1.9555593575200727

Epoch: 5| Step: 1
Training loss: 1.9128656387329102
Validation loss: 1.974165734424386

Epoch: 5| Step: 2
Training loss: 1.6718155145645142
Validation loss: 2.027183109714139

Epoch: 5| Step: 3
Training loss: 1.7026441097259521
Validation loss: 2.0026295467089583

Epoch: 5| Step: 4
Training loss: 1.3240599632263184
Validation loss: 1.98826386338921

Epoch: 5| Step: 5
Training loss: 1.163048505783081
Validation loss: 1.9765484179219892

Epoch: 5| Step: 6
Training loss: 1.7557512521743774
Validation loss: 1.97302806761957

Epoch: 5| Step: 7
Training loss: 0.9048290252685547
Validation loss: 1.9453577867118261

Epoch: 5| Step: 8
Training loss: 1.7022145986557007
Validation loss: 1.9734223376038253

Epoch: 5| Step: 9
Training loss: 1.0940325260162354
Validation loss: 2.002966534706854

Epoch: 5| Step: 10
Training loss: 1.5858596563339233
Validation loss: 2.0309432219433528

Epoch: 191| Step: 0
Training loss: 1.278032898902893
Validation loss: 2.041134577925487

Epoch: 5| Step: 1
Training loss: 1.4420421123504639
Validation loss: 2.0493822405415196

Epoch: 5| Step: 2
Training loss: 1.2574284076690674
Validation loss: 2.0434869489362164

Epoch: 5| Step: 3
Training loss: 0.9413242340087891
Validation loss: 1.9957198071223434

Epoch: 5| Step: 4
Training loss: 1.863154649734497
Validation loss: 1.9822048397474392

Epoch: 5| Step: 5
Training loss: 1.646425485610962
Validation loss: 1.9764068306133311

Epoch: 5| Step: 6
Training loss: 1.7642583847045898
Validation loss: 1.9377340424445368

Epoch: 5| Step: 7
Training loss: 1.7550203800201416
Validation loss: 1.9556739791747062

Epoch: 5| Step: 8
Training loss: 1.0698778629302979
Validation loss: 1.998854173127041

Epoch: 5| Step: 9
Training loss: 1.875848412513733
Validation loss: 2.010570720959735

Epoch: 5| Step: 10
Training loss: 1.6933130025863647
Validation loss: 2.0178548982066493

Epoch: 192| Step: 0
Training loss: 1.456835389137268
Validation loss: 2.012804727400503

Epoch: 5| Step: 1
Training loss: 1.6795622110366821
Validation loss: 1.998333651532409

Epoch: 5| Step: 2
Training loss: 1.735695242881775
Validation loss: 1.9607142991917108

Epoch: 5| Step: 3
Training loss: 1.8523693084716797
Validation loss: 1.9424790746422225

Epoch: 5| Step: 4
Training loss: 1.2813552618026733
Validation loss: 1.9530758062998455

Epoch: 5| Step: 5
Training loss: 1.6581910848617554
Validation loss: 1.9831221847123996

Epoch: 5| Step: 6
Training loss: 1.0235507488250732
Validation loss: 2.0178955498562066

Epoch: 5| Step: 7
Training loss: 1.4908689260482788
Validation loss: 2.0214680638364566

Epoch: 5| Step: 8
Training loss: 1.4579851627349854
Validation loss: 1.9888568808955531

Epoch: 5| Step: 9
Training loss: 1.5506541728973389
Validation loss: 1.9417507545922392

Epoch: 5| Step: 10
Training loss: 1.049161434173584
Validation loss: 1.9103531350371659

Epoch: 193| Step: 0
Training loss: 1.9179494380950928
Validation loss: 1.9081793254421604

Epoch: 5| Step: 1
Training loss: 1.2363450527191162
Validation loss: 1.941472949520234

Epoch: 5| Step: 2
Training loss: 0.9974905848503113
Validation loss: 1.994621979293003

Epoch: 5| Step: 3
Training loss: 1.5414211750030518
Validation loss: 2.039024035135905

Epoch: 5| Step: 4
Training loss: 1.399505853652954
Validation loss: 2.0534327184000323

Epoch: 5| Step: 5
Training loss: 1.041751742362976
Validation loss: 2.0715705322962936

Epoch: 5| Step: 6
Training loss: 1.5001757144927979
Validation loss: 2.056545288332047

Epoch: 5| Step: 7
Training loss: 1.7623800039291382
Validation loss: 2.053008352556536

Epoch: 5| Step: 8
Training loss: 1.8672170639038086
Validation loss: 2.0477899095063568

Epoch: 5| Step: 9
Training loss: 1.4153506755828857
Validation loss: 1.9871774565789007

Epoch: 5| Step: 10
Training loss: 1.7526819705963135
Validation loss: 1.9703488452460176

Epoch: 194| Step: 0
Training loss: 1.8215086460113525
Validation loss: 1.938261579441768

Epoch: 5| Step: 1
Training loss: 1.4500631093978882
Validation loss: 1.933267178074006

Epoch: 5| Step: 2
Training loss: 1.3416723012924194
Validation loss: 1.9407032100103234

Epoch: 5| Step: 3
Training loss: 1.476529836654663
Validation loss: 1.947460946216378

Epoch: 5| Step: 4
Training loss: 0.9730734825134277
Validation loss: 1.9974877526683192

Epoch: 5| Step: 5
Training loss: 1.8034645318984985
Validation loss: 2.0434996133209555

Epoch: 5| Step: 6
Training loss: 1.6378514766693115
Validation loss: 2.082438982943053

Epoch: 5| Step: 7
Training loss: 1.3571330308914185
Validation loss: 2.066785520122897

Epoch: 5| Step: 8
Training loss: 1.725189447402954
Validation loss: 2.0222531903174614

Epoch: 5| Step: 9
Training loss: 1.7603881359100342
Validation loss: 1.9284754068620744

Epoch: 5| Step: 10
Training loss: 1.128760814666748
Validation loss: 1.8823268349452684

Epoch: 195| Step: 0
Training loss: 1.547654628753662
Validation loss: 1.876350587414157

Epoch: 5| Step: 1
Training loss: 1.530164122581482
Validation loss: 1.9065200936409734

Epoch: 5| Step: 2
Training loss: 1.417771577835083
Validation loss: 1.9130134710701563

Epoch: 5| Step: 3
Training loss: 1.53464937210083
Validation loss: 1.9241228257456133

Epoch: 5| Step: 4
Training loss: 1.4885355234146118
Validation loss: 1.9697717774298884

Epoch: 5| Step: 5
Training loss: 1.338865876197815
Validation loss: 2.017591171367194

Epoch: 5| Step: 6
Training loss: 1.7231508493423462
Validation loss: 2.037358007123393

Epoch: 5| Step: 7
Training loss: 1.2372277975082397
Validation loss: 2.0583655295833463

Epoch: 5| Step: 8
Training loss: 1.8113981485366821
Validation loss: 2.06608275957005

Epoch: 5| Step: 9
Training loss: 1.4241702556610107
Validation loss: 2.0564258303693546

Epoch: 5| Step: 10
Training loss: 1.6422420740127563
Validation loss: 2.032980703538464

Epoch: 196| Step: 0
Training loss: 1.6385911703109741
Validation loss: 2.019183733130014

Epoch: 5| Step: 1
Training loss: 1.7676410675048828
Validation loss: 1.9402169566000662

Epoch: 5| Step: 2
Training loss: 1.3081238269805908
Validation loss: 1.9068597157796223

Epoch: 5| Step: 3
Training loss: 1.367374062538147
Validation loss: 1.9159169068900488

Epoch: 5| Step: 4
Training loss: 1.4270899295806885
Validation loss: 1.9153170841996388

Epoch: 5| Step: 5
Training loss: 1.2840453386306763
Validation loss: 1.944306158250378

Epoch: 5| Step: 6
Training loss: 1.5610854625701904
Validation loss: 1.9914747591941588

Epoch: 5| Step: 7
Training loss: 1.9716498851776123
Validation loss: 2.0077488550575833

Epoch: 5| Step: 8
Training loss: 1.4313687086105347
Validation loss: 2.0318002303441367

Epoch: 5| Step: 9
Training loss: 1.1175330877304077
Validation loss: 2.0080086095358736

Epoch: 5| Step: 10
Training loss: 1.2913377285003662
Validation loss: 1.995045925981255

Epoch: 197| Step: 0
Training loss: 1.223858118057251
Validation loss: 1.9790772340630973

Epoch: 5| Step: 1
Training loss: 1.605049729347229
Validation loss: 1.951697677694341

Epoch: 5| Step: 2
Training loss: 1.3953393697738647
Validation loss: 1.949158505726886

Epoch: 5| Step: 3
Training loss: 1.3594486713409424
Validation loss: 1.9296939180743309

Epoch: 5| Step: 4
Training loss: 1.852094292640686
Validation loss: 1.9088519926994079

Epoch: 5| Step: 5
Training loss: 1.4636257886886597
Validation loss: 1.9229126335472189

Epoch: 5| Step: 6
Training loss: 1.6248060464859009
Validation loss: 1.9153321212337864

Epoch: 5| Step: 7
Training loss: 1.2876824140548706
Validation loss: 1.9537214040756226

Epoch: 5| Step: 8
Training loss: 1.1386301517486572
Validation loss: 1.9835208000675324

Epoch: 5| Step: 9
Training loss: 1.4730041027069092
Validation loss: 2.001096902355071

Epoch: 5| Step: 10
Training loss: 1.5113292932510376
Validation loss: 1.9894593338812552

Epoch: 198| Step: 0
Training loss: 1.5486892461776733
Validation loss: 1.9625017425065399

Epoch: 5| Step: 1
Training loss: 1.3942934274673462
Validation loss: 1.9493295454209851

Epoch: 5| Step: 2
Training loss: 1.3000050783157349
Validation loss: 1.9401159491590274

Epoch: 5| Step: 3
Training loss: 1.739630103111267
Validation loss: 1.9346244873539094

Epoch: 5| Step: 4
Training loss: 1.4559004306793213
Validation loss: 1.948864899655824

Epoch: 5| Step: 5
Training loss: 1.217206358909607
Validation loss: 1.9695860980659403

Epoch: 5| Step: 6
Training loss: 1.4054425954818726
Validation loss: 1.9954742795677596

Epoch: 5| Step: 7
Training loss: 1.4485270977020264
Validation loss: 2.0152091851798435

Epoch: 5| Step: 8
Training loss: 1.1690715551376343
Validation loss: 1.9979594343452043

Epoch: 5| Step: 9
Training loss: 1.736807107925415
Validation loss: 1.9941727551080848

Epoch: 5| Step: 10
Training loss: 1.3051060438156128
Validation loss: 1.9508175183367986

Epoch: 199| Step: 0
Training loss: 1.896905541419983
Validation loss: 1.9363297172771987

Epoch: 5| Step: 1
Training loss: 1.387479305267334
Validation loss: 1.91502809011808

Epoch: 5| Step: 2
Training loss: 0.9947919845581055
Validation loss: 1.9337177135611092

Epoch: 5| Step: 3
Training loss: 1.38888418674469
Validation loss: 1.9541253056577457

Epoch: 5| Step: 4
Training loss: 1.1568342447280884
Validation loss: 1.9549696881283996

Epoch: 5| Step: 5
Training loss: 1.194946527481079
Validation loss: 1.9779769528296687

Epoch: 5| Step: 6
Training loss: 1.2998870611190796
Validation loss: 1.9974923620941818

Epoch: 5| Step: 7
Training loss: 1.5036157369613647
Validation loss: 2.0099836177723382

Epoch: 5| Step: 8
Training loss: 1.6627038717269897
Validation loss: 2.022990988146874

Epoch: 5| Step: 9
Training loss: 1.851615309715271
Validation loss: 2.0216845491881013

Epoch: 5| Step: 10
Training loss: 1.3400487899780273
Validation loss: 1.971318252625004

Epoch: 200| Step: 0
Training loss: 1.5982494354248047
Validation loss: 1.9200949361247401

Epoch: 5| Step: 1
Training loss: 1.601897954940796
Validation loss: 1.8892902558849705

Epoch: 5| Step: 2
Training loss: 1.537896752357483
Validation loss: 1.86793396037112

Epoch: 5| Step: 3
Training loss: 1.395855188369751
Validation loss: 1.866517892447851

Epoch: 5| Step: 4
Training loss: 1.2399449348449707
Validation loss: 1.8980307989223029

Epoch: 5| Step: 5
Training loss: 1.5525928735733032
Validation loss: 1.8916920872144802

Epoch: 5| Step: 6
Training loss: 1.7138464450836182
Validation loss: 1.9248264630635579

Epoch: 5| Step: 7
Training loss: 1.4739253520965576
Validation loss: 1.9429969377415155

Epoch: 5| Step: 8
Training loss: 1.0545539855957031
Validation loss: 1.9903550045464629

Epoch: 5| Step: 9
Training loss: 1.2149730920791626
Validation loss: 2.0002505779266357

Epoch: 5| Step: 10
Training loss: 1.1697618961334229
Validation loss: 2.022578666287084

Epoch: 201| Step: 0
Training loss: 0.9338701367378235
Validation loss: 2.0407254285709833

Epoch: 5| Step: 1
Training loss: 1.3532224893569946
Validation loss: 2.030088145245788

Epoch: 5| Step: 2
Training loss: 1.8323030471801758
Validation loss: 2.0279749875427573

Epoch: 5| Step: 3
Training loss: 1.2249300479888916
Validation loss: 1.9669425333699873

Epoch: 5| Step: 4
Training loss: 1.4095675945281982
Validation loss: 1.9687020547928349

Epoch: 5| Step: 5
Training loss: 0.9925824403762817
Validation loss: 1.9285389710498113

Epoch: 5| Step: 6
Training loss: 1.4902498722076416
Validation loss: 1.9258968137925672

Epoch: 5| Step: 7
Training loss: 1.7644144296646118
Validation loss: 1.9131414480106805

Epoch: 5| Step: 8
Training loss: 1.7447330951690674
Validation loss: 1.902663702605873

Epoch: 5| Step: 9
Training loss: 1.2797069549560547
Validation loss: 1.8950643193337224

Epoch: 5| Step: 10
Training loss: 1.1676275730133057
Validation loss: 1.892807073490594

Epoch: 202| Step: 0
Training loss: 1.1546313762664795
Validation loss: 1.8998330177799347

Epoch: 5| Step: 1
Training loss: 0.9374710321426392
Validation loss: 1.8860526469445997

Epoch: 5| Step: 2
Training loss: 1.0409486293792725
Validation loss: 1.894274639826949

Epoch: 5| Step: 3
Training loss: 1.80552077293396
Validation loss: 1.923301750613797

Epoch: 5| Step: 4
Training loss: 1.9533469676971436
Validation loss: 1.9797656023374168

Epoch: 5| Step: 5
Training loss: 1.414768099784851
Validation loss: 2.0093248621109994

Epoch: 5| Step: 6
Training loss: 1.517876386642456
Validation loss: 2.0197297706398913

Epoch: 5| Step: 7
Training loss: 1.2431080341339111
Validation loss: 2.000792564884309

Epoch: 5| Step: 8
Training loss: 1.4863039255142212
Validation loss: 2.003427795184556

Epoch: 5| Step: 9
Training loss: 1.1820142269134521
Validation loss: 1.973516938506916

Epoch: 5| Step: 10
Training loss: 1.6190482378005981
Validation loss: 1.9542294548403831

Epoch: 203| Step: 0
Training loss: 1.4962146282196045
Validation loss: 1.918583603315456

Epoch: 5| Step: 1
Training loss: 0.9997334480285645
Validation loss: 1.9170735536083099

Epoch: 5| Step: 2
Training loss: 0.9284149408340454
Validation loss: 1.9148098909726707

Epoch: 5| Step: 3
Training loss: 1.3392550945281982
Validation loss: 1.8936900438800934

Epoch: 5| Step: 4
Training loss: 1.4908391237258911
Validation loss: 1.8890683599697646

Epoch: 5| Step: 5
Training loss: 1.8017898797988892
Validation loss: 1.8996658299558906

Epoch: 5| Step: 6
Training loss: 1.5858054161071777
Validation loss: 1.9014351239768408

Epoch: 5| Step: 7
Training loss: 1.3511165380477905
Validation loss: 1.9162161888614777

Epoch: 5| Step: 8
Training loss: 1.0842722654342651
Validation loss: 1.9499418671413133

Epoch: 5| Step: 9
Training loss: 1.7219854593276978
Validation loss: 1.926992211290585

Epoch: 5| Step: 10
Training loss: 1.3125571012496948
Validation loss: 1.8947723911654564

Epoch: 204| Step: 0
Training loss: 0.9194242358207703
Validation loss: 1.9311589361518942

Epoch: 5| Step: 1
Training loss: 1.325528860092163
Validation loss: 1.9412018035047798

Epoch: 5| Step: 2
Training loss: 2.0025224685668945
Validation loss: 1.9601791097271828

Epoch: 5| Step: 3
Training loss: 1.2618634700775146
Validation loss: 1.9933721121921335

Epoch: 5| Step: 4
Training loss: 1.777683973312378
Validation loss: 1.9729248298111783

Epoch: 5| Step: 5
Training loss: 1.359088659286499
Validation loss: 1.9488325606110275

Epoch: 5| Step: 6
Training loss: 1.3180763721466064
Validation loss: 1.9358630103449668

Epoch: 5| Step: 7
Training loss: 1.088020920753479
Validation loss: 1.9438220095890824

Epoch: 5| Step: 8
Training loss: 0.7607585191726685
Validation loss: 1.9554274428275324

Epoch: 5| Step: 9
Training loss: 1.3109875917434692
Validation loss: 1.9633138551506946

Epoch: 5| Step: 10
Training loss: 1.8529936075210571
Validation loss: 1.9613104046031993

Epoch: 205| Step: 0
Training loss: 1.237009882926941
Validation loss: 1.9627573054323915

Epoch: 5| Step: 1
Training loss: 1.2802515029907227
Validation loss: 1.933596016258322

Epoch: 5| Step: 2
Training loss: 1.2748816013336182
Validation loss: 1.9186472918397637

Epoch: 5| Step: 3
Training loss: 1.6441348791122437
Validation loss: 1.913227463281283

Epoch: 5| Step: 4
Training loss: 1.4634487628936768
Validation loss: 1.9101310199306858

Epoch: 5| Step: 5
Training loss: 2.0396671295166016
Validation loss: 1.918585149190759

Epoch: 5| Step: 6
Training loss: 1.5058223009109497
Validation loss: 1.9261446511873634

Epoch: 5| Step: 7
Training loss: 1.232406735420227
Validation loss: 1.9385580119266306

Epoch: 5| Step: 8
Training loss: 1.0562818050384521
Validation loss: 1.9365727363094207

Epoch: 5| Step: 9
Training loss: 0.9821798205375671
Validation loss: 1.9591582321351575

Epoch: 5| Step: 10
Training loss: 0.9250084161758423
Validation loss: 1.9792189354537635

Epoch: 206| Step: 0
Training loss: 1.408563256263733
Validation loss: 2.0020168455698157

Epoch: 5| Step: 1
Training loss: 0.8744010925292969
Validation loss: 1.9980925231851556

Epoch: 5| Step: 2
Training loss: 1.41110360622406
Validation loss: 2.0033290796382452

Epoch: 5| Step: 3
Training loss: 1.3719545602798462
Validation loss: 1.9744216267780592

Epoch: 5| Step: 4
Training loss: 1.3521931171417236
Validation loss: 1.9623523155848186

Epoch: 5| Step: 5
Training loss: 1.6631466150283813
Validation loss: 1.9350512668650637

Epoch: 5| Step: 6
Training loss: 0.7067261934280396
Validation loss: 1.9355256403646162

Epoch: 5| Step: 7
Training loss: 1.8844712972640991
Validation loss: 1.922490781353366

Epoch: 5| Step: 8
Training loss: 1.0366621017456055
Validation loss: 1.9071619305559384

Epoch: 5| Step: 9
Training loss: 1.561953067779541
Validation loss: 1.9163276533926688

Epoch: 5| Step: 10
Training loss: 1.2543749809265137
Validation loss: 1.906426150311706

Epoch: 207| Step: 0
Training loss: 1.138264775276184
Validation loss: 1.9392163561236473

Epoch: 5| Step: 1
Training loss: 1.1301168203353882
Validation loss: 1.9617572317841232

Epoch: 5| Step: 2
Training loss: 1.347898244857788
Validation loss: 1.9841551267972557

Epoch: 5| Step: 3
Training loss: 1.7527697086334229
Validation loss: 1.9829955562468498

Epoch: 5| Step: 4
Training loss: 1.4611271619796753
Validation loss: 1.9911440918522496

Epoch: 5| Step: 5
Training loss: 1.021226167678833
Validation loss: 1.9471721764533751

Epoch: 5| Step: 6
Training loss: 1.5012062788009644
Validation loss: 1.9139079073423981

Epoch: 5| Step: 7
Training loss: 1.4777673482894897
Validation loss: 1.887350005488242

Epoch: 5| Step: 8
Training loss: 1.4679248332977295
Validation loss: 1.868858374575133

Epoch: 5| Step: 9
Training loss: 1.3098734617233276
Validation loss: 1.8835321805810417

Epoch: 5| Step: 10
Training loss: 0.8251029253005981
Validation loss: 1.8912402916980047

Epoch: 208| Step: 0
Training loss: 1.2632720470428467
Validation loss: 1.9329224773632583

Epoch: 5| Step: 1
Training loss: 1.1795744895935059
Validation loss: 1.9531886141787294

Epoch: 5| Step: 2
Training loss: 1.3158574104309082
Validation loss: 1.9397238351965462

Epoch: 5| Step: 3
Training loss: 1.3041986227035522
Validation loss: 1.9548964987518966

Epoch: 5| Step: 4
Training loss: 1.275646448135376
Validation loss: 1.9395341398895427

Epoch: 5| Step: 5
Training loss: 0.9083725214004517
Validation loss: 1.9282786461614794

Epoch: 5| Step: 6
Training loss: 1.5206491947174072
Validation loss: 1.8989603711712746

Epoch: 5| Step: 7
Training loss: 1.7183091640472412
Validation loss: 1.8944453539386872

Epoch: 5| Step: 8
Training loss: 1.4206650257110596
Validation loss: 1.8774161672079435

Epoch: 5| Step: 9
Training loss: 1.0946996212005615
Validation loss: 1.9376425127829275

Epoch: 5| Step: 10
Training loss: 1.209293246269226
Validation loss: 1.9756056647146902

Epoch: 209| Step: 0
Training loss: 1.6676175594329834
Validation loss: 1.9934296992517286

Epoch: 5| Step: 1
Training loss: 1.125918984413147
Validation loss: 1.9589435387683172

Epoch: 5| Step: 2
Training loss: 0.8478800058364868
Validation loss: 1.9294438541576426

Epoch: 5| Step: 3
Training loss: 1.12813401222229
Validation loss: 1.9176677273165794

Epoch: 5| Step: 4
Training loss: 1.327335000038147
Validation loss: 1.9116430974775744

Epoch: 5| Step: 5
Training loss: 1.720312476158142
Validation loss: 1.8954744287716445

Epoch: 5| Step: 6
Training loss: 0.6675251126289368
Validation loss: 1.883858734561551

Epoch: 5| Step: 7
Training loss: 1.5329569578170776
Validation loss: 1.8704775469277495

Epoch: 5| Step: 8
Training loss: 1.3312757015228271
Validation loss: 1.8745080322347663

Epoch: 5| Step: 9
Training loss: 1.3796244859695435
Validation loss: 1.8719125537462131

Epoch: 5| Step: 10
Training loss: 1.164886713027954
Validation loss: 1.8776223556969756

Epoch: 210| Step: 0
Training loss: 1.4709705114364624
Validation loss: 1.8976829474972141

Epoch: 5| Step: 1
Training loss: 1.4356023073196411
Validation loss: 1.893137590859526

Epoch: 5| Step: 2
Training loss: 0.9630037546157837
Validation loss: 1.8884578981707174

Epoch: 5| Step: 3
Training loss: 0.8523635864257812
Validation loss: 1.8770844013460222

Epoch: 5| Step: 4
Training loss: 1.3946088552474976
Validation loss: 1.8574833485387987

Epoch: 5| Step: 5
Training loss: 1.3756722211837769
Validation loss: 1.8621137988182805

Epoch: 5| Step: 6
Training loss: 1.1916329860687256
Validation loss: 1.8693451599408222

Epoch: 5| Step: 7
Training loss: 1.2864971160888672
Validation loss: 1.87447750952936

Epoch: 5| Step: 8
Training loss: 1.2634559869766235
Validation loss: 1.9136280872488534

Epoch: 5| Step: 9
Training loss: 1.531101107597351
Validation loss: 1.9448538826357933

Epoch: 5| Step: 10
Training loss: 1.209704875946045
Validation loss: 1.9687353667392526

Epoch: 211| Step: 0
Training loss: 1.0576741695404053
Validation loss: 1.954221672909234

Epoch: 5| Step: 1
Training loss: 1.6635494232177734
Validation loss: 1.9162864492785545

Epoch: 5| Step: 2
Training loss: 1.4928531646728516
Validation loss: 1.9032779867931078

Epoch: 5| Step: 3
Training loss: 1.1765429973602295
Validation loss: 1.892745025696293

Epoch: 5| Step: 4
Training loss: 1.1479301452636719
Validation loss: 1.884603306811343

Epoch: 5| Step: 5
Training loss: 1.0138750076293945
Validation loss: 1.8855475097574212

Epoch: 5| Step: 6
Training loss: 1.5513828992843628
Validation loss: 1.9492071572170462

Epoch: 5| Step: 7
Training loss: 1.0354000329971313
Validation loss: 1.9595929294504144

Epoch: 5| Step: 8
Training loss: 0.9288430213928223
Validation loss: 1.9679200239078973

Epoch: 5| Step: 9
Training loss: 1.2862807512283325
Validation loss: 1.9597938906761907

Epoch: 5| Step: 10
Training loss: 1.367109775543213
Validation loss: 1.891243411648658

Epoch: 212| Step: 0
Training loss: 1.1845104694366455
Validation loss: 1.8884701780093613

Epoch: 5| Step: 1
Training loss: 1.4557307958602905
Validation loss: 1.8870240565269225

Epoch: 5| Step: 2
Training loss: 1.3185961246490479
Validation loss: 1.9118364408452024

Epoch: 5| Step: 3
Training loss: 1.1915985345840454
Validation loss: 1.9472364328240837

Epoch: 5| Step: 4
Training loss: 0.9866073727607727
Validation loss: 1.9543098352288688

Epoch: 5| Step: 5
Training loss: 0.9313364028930664
Validation loss: 1.9322148446113832

Epoch: 5| Step: 6
Training loss: 0.9938417673110962
Validation loss: 1.9565693691212644

Epoch: 5| Step: 7
Training loss: 1.0261290073394775
Validation loss: 1.8995417510309527

Epoch: 5| Step: 8
Training loss: 1.4847431182861328
Validation loss: 1.8781418185080252

Epoch: 5| Step: 9
Training loss: 1.543820858001709
Validation loss: 1.8449243653205134

Epoch: 5| Step: 10
Training loss: 1.635481595993042
Validation loss: 1.8318624509278165

Epoch: 213| Step: 0
Training loss: 1.3827794790267944
Validation loss: 1.8406258808669222

Epoch: 5| Step: 1
Training loss: 1.5317978858947754
Validation loss: 1.8210488006632815

Epoch: 5| Step: 2
Training loss: 1.2000141143798828
Validation loss: 1.8236937804888653

Epoch: 5| Step: 3
Training loss: 1.4635868072509766
Validation loss: 1.819105012442476

Epoch: 5| Step: 4
Training loss: 1.0702121257781982
Validation loss: 1.8220282985318093

Epoch: 5| Step: 5
Training loss: 1.2675644159317017
Validation loss: 1.8561242780377787

Epoch: 5| Step: 6
Training loss: 1.0702577829360962
Validation loss: 1.8995094337771017

Epoch: 5| Step: 7
Training loss: 1.2787566184997559
Validation loss: 1.9585368005178307

Epoch: 5| Step: 8
Training loss: 1.9182935953140259
Validation loss: 1.9430469518066735

Epoch: 5| Step: 9
Training loss: 0.9550769925117493
Validation loss: 1.9619852240367601

Epoch: 5| Step: 10
Training loss: 1.0243542194366455
Validation loss: 1.929586962987018

Epoch: 214| Step: 0
Training loss: 1.0931161642074585
Validation loss: 1.876586797416851

Epoch: 5| Step: 1
Training loss: 0.7108073234558105
Validation loss: 1.8781579540621849

Epoch: 5| Step: 2
Training loss: 1.107349157333374
Validation loss: 1.8686956872222245

Epoch: 5| Step: 3
Training loss: 1.515434980392456
Validation loss: 1.8803418541467318

Epoch: 5| Step: 4
Training loss: 1.2366721630096436
Validation loss: 1.874614736085297

Epoch: 5| Step: 5
Training loss: 1.5338809490203857
Validation loss: 1.8504411738405946

Epoch: 5| Step: 6
Training loss: 1.267137885093689
Validation loss: 1.8963067044493973

Epoch: 5| Step: 7
Training loss: 1.2455170154571533
Validation loss: 1.9277097050861647

Epoch: 5| Step: 8
Training loss: 1.1029512882232666
Validation loss: 1.9372631836962957

Epoch: 5| Step: 9
Training loss: 1.5554852485656738
Validation loss: 1.912414522581203

Epoch: 5| Step: 10
Training loss: 1.0931280851364136
Validation loss: 1.8612394153430898

Epoch: 215| Step: 0
Training loss: 1.2661781311035156
Validation loss: 1.8459010547207249

Epoch: 5| Step: 1
Training loss: 1.4801816940307617
Validation loss: 1.8344388828482678

Epoch: 5| Step: 2
Training loss: 0.8893339037895203
Validation loss: 1.837931622741043

Epoch: 5| Step: 3
Training loss: 0.7925239205360413
Validation loss: 1.8410660195094284

Epoch: 5| Step: 4
Training loss: 1.1467359066009521
Validation loss: 1.8812939261877408

Epoch: 5| Step: 5
Training loss: 0.9123225212097168
Validation loss: 1.8809960196095128

Epoch: 5| Step: 6
Training loss: 1.3161697387695312
Validation loss: 1.932914177576701

Epoch: 5| Step: 7
Training loss: 1.2582077980041504
Validation loss: 1.9378753144253966

Epoch: 5| Step: 8
Training loss: 1.6051088571548462
Validation loss: 1.925186498190767

Epoch: 5| Step: 9
Training loss: 1.3671000003814697
Validation loss: 1.8793198998256395

Epoch: 5| Step: 10
Training loss: 1.2712063789367676
Validation loss: 1.8691311869570004

Epoch: 216| Step: 0
Training loss: 0.8837030529975891
Validation loss: 1.8555934736805577

Epoch: 5| Step: 1
Training loss: 1.3888423442840576
Validation loss: 1.89812514346133

Epoch: 5| Step: 2
Training loss: 1.3213729858398438
Validation loss: 1.9555555979410808

Epoch: 5| Step: 3
Training loss: 1.1808732748031616
Validation loss: 1.9706744545249528

Epoch: 5| Step: 4
Training loss: 1.233780860900879
Validation loss: 1.9695946016619283

Epoch: 5| Step: 5
Training loss: 1.005871057510376
Validation loss: 1.9462839211187055

Epoch: 5| Step: 6
Training loss: 1.4882522821426392
Validation loss: 1.9177032260484592

Epoch: 5| Step: 7
Training loss: 1.33154296875
Validation loss: 1.9002936681111653

Epoch: 5| Step: 8
Training loss: 1.4912078380584717
Validation loss: 1.8840668816720285

Epoch: 5| Step: 9
Training loss: 0.8287860155105591
Validation loss: 1.885185008407921

Epoch: 5| Step: 10
Training loss: 0.9919990301132202
Validation loss: 1.8749965172941967

Epoch: 217| Step: 0
Training loss: 1.1222141981124878
Validation loss: 1.8657095701463762

Epoch: 5| Step: 1
Training loss: 1.4273548126220703
Validation loss: 1.8561622647828953

Epoch: 5| Step: 2
Training loss: 0.7385545969009399
Validation loss: 1.8617770389844013

Epoch: 5| Step: 3
Training loss: 1.486802101135254
Validation loss: 1.8518566880174863

Epoch: 5| Step: 4
Training loss: 1.1440203189849854
Validation loss: 1.8712761440584738

Epoch: 5| Step: 5
Training loss: 1.2172688245773315
Validation loss: 1.9304572510462936

Epoch: 5| Step: 6
Training loss: 0.8146487474441528
Validation loss: 1.9682247433611142

Epoch: 5| Step: 7
Training loss: 1.4089866876602173
Validation loss: 2.000023539348315

Epoch: 5| Step: 8
Training loss: 1.8321685791015625
Validation loss: 1.9304369470124603

Epoch: 5| Step: 9
Training loss: 0.7058881521224976
Validation loss: 1.8768597623353362

Epoch: 5| Step: 10
Training loss: 1.0269943475723267
Validation loss: 1.8448879052233953

Epoch: 218| Step: 0
Training loss: 1.4683506488800049
Validation loss: 1.8243487637530091

Epoch: 5| Step: 1
Training loss: 0.9386979937553406
Validation loss: 1.83356184856866

Epoch: 5| Step: 2
Training loss: 1.052543044090271
Validation loss: 1.8480807478709886

Epoch: 5| Step: 3
Training loss: 1.1136224269866943
Validation loss: 1.899363047333174

Epoch: 5| Step: 4
Training loss: 1.0568565130233765
Validation loss: 1.9498339878615512

Epoch: 5| Step: 5
Training loss: 1.1558902263641357
Validation loss: 1.9540792876674282

Epoch: 5| Step: 6
Training loss: 1.0445055961608887
Validation loss: 1.9612074859680668

Epoch: 5| Step: 7
Training loss: 1.348796010017395
Validation loss: 1.9359319838144446

Epoch: 5| Step: 8
Training loss: 0.8190990686416626
Validation loss: 1.9172027636599798

Epoch: 5| Step: 9
Training loss: 1.2075618505477905
Validation loss: 1.9079727062615015

Epoch: 5| Step: 10
Training loss: 1.6828864812850952
Validation loss: 1.8660866137473815

Epoch: 219| Step: 0
Training loss: 0.9570578336715698
Validation loss: 1.839873944559405

Epoch: 5| Step: 1
Training loss: 1.5187718868255615
Validation loss: 1.831612426747558

Epoch: 5| Step: 2
Training loss: 1.5173616409301758
Validation loss: 1.8086649397368073

Epoch: 5| Step: 3
Training loss: 1.161738395690918
Validation loss: 1.8390434095936437

Epoch: 5| Step: 4
Training loss: 0.8919774293899536
Validation loss: 1.8842499743225753

Epoch: 5| Step: 5
Training loss: 1.3924469947814941
Validation loss: 1.919282538916475

Epoch: 5| Step: 6
Training loss: 1.1425354480743408
Validation loss: 1.939324910922717

Epoch: 5| Step: 7
Training loss: 1.0678236484527588
Validation loss: 1.8907813577241794

Epoch: 5| Step: 8
Training loss: 1.2334996461868286
Validation loss: 1.8955453826535134

Epoch: 5| Step: 9
Training loss: 0.835180938243866
Validation loss: 1.8647794967056603

Epoch: 5| Step: 10
Training loss: 1.0096160173416138
Validation loss: 1.8669462985889886

Epoch: 220| Step: 0
Training loss: 1.2753207683563232
Validation loss: 1.9096239843676168

Epoch: 5| Step: 1
Training loss: 0.902948260307312
Validation loss: 1.9341656597711707

Epoch: 5| Step: 2
Training loss: 1.1867517232894897
Validation loss: 1.9051461194151191

Epoch: 5| Step: 3
Training loss: 0.982801079750061
Validation loss: 1.8930809344014814

Epoch: 5| Step: 4
Training loss: 1.0295219421386719
Validation loss: 1.8791559114251086

Epoch: 5| Step: 5
Training loss: 1.1798546314239502
Validation loss: 1.8423204063087382

Epoch: 5| Step: 6
Training loss: 1.0204046964645386
Validation loss: 1.8404496421096146

Epoch: 5| Step: 7
Training loss: 0.9465219378471375
Validation loss: 1.865793474258915

Epoch: 5| Step: 8
Training loss: 1.4196364879608154
Validation loss: 1.9152493835777364

Epoch: 5| Step: 9
Training loss: 1.375361680984497
Validation loss: 1.9244600060165569

Epoch: 5| Step: 10
Training loss: 1.2177714109420776
Validation loss: 1.9199202060699463

Epoch: 221| Step: 0
Training loss: 1.3577382564544678
Validation loss: 1.8913652576426023

Epoch: 5| Step: 1
Training loss: 0.5817776322364807
Validation loss: 1.864449603583223

Epoch: 5| Step: 2
Training loss: 1.01947021484375
Validation loss: 1.8594797708654915

Epoch: 5| Step: 3
Training loss: 1.24881911277771
Validation loss: 1.8050801446360927

Epoch: 5| Step: 4
Training loss: 1.4931554794311523
Validation loss: 1.8138258777638918

Epoch: 5| Step: 5
Training loss: 1.1195690631866455
Validation loss: 1.8294362752668318

Epoch: 5| Step: 6
Training loss: 1.4438347816467285
Validation loss: 1.8558494301252468

Epoch: 5| Step: 7
Training loss: 1.3884766101837158
Validation loss: 1.9026832708748438

Epoch: 5| Step: 8
Training loss: 1.0535634756088257
Validation loss: 1.8905223197834466

Epoch: 5| Step: 9
Training loss: 0.7794798612594604
Validation loss: 1.882531923632468

Epoch: 5| Step: 10
Training loss: 0.9821641445159912
Validation loss: 1.8151001840509393

Epoch: 222| Step: 0
Training loss: 1.705377221107483
Validation loss: 1.8025068595845213

Epoch: 5| Step: 1
Training loss: 1.7648849487304688
Validation loss: 1.8063547585600166

Epoch: 5| Step: 2
Training loss: 0.989476203918457
Validation loss: 1.786693713998282

Epoch: 5| Step: 3
Training loss: 1.1819517612457275
Validation loss: 1.7887306251833517

Epoch: 5| Step: 4
Training loss: 0.8340343236923218
Validation loss: 1.7904048991459671

Epoch: 5| Step: 5
Training loss: 0.5015621185302734
Validation loss: 1.8114055254126107

Epoch: 5| Step: 6
Training loss: 0.9279511570930481
Validation loss: 1.903198302433055

Epoch: 5| Step: 7
Training loss: 1.6822049617767334
Validation loss: 1.9123246285223192

Epoch: 5| Step: 8
Training loss: 0.9972874522209167
Validation loss: 1.8696739090386258

Epoch: 5| Step: 9
Training loss: 1.2511394023895264
Validation loss: 1.8421062243882047

Epoch: 5| Step: 10
Training loss: 0.6595765352249146
Validation loss: 1.822800350445573

Epoch: 223| Step: 0
Training loss: 0.685960590839386
Validation loss: 1.806322436178884

Epoch: 5| Step: 1
Training loss: 1.5574201345443726
Validation loss: 1.805607085586876

Epoch: 5| Step: 2
Training loss: 1.4762612581253052
Validation loss: 1.8355862812329364

Epoch: 5| Step: 3
Training loss: 1.1919194459915161
Validation loss: 1.8265493467289915

Epoch: 5| Step: 4
Training loss: 0.6685771346092224
Validation loss: 1.8794305401463662

Epoch: 5| Step: 5
Training loss: 0.8815590143203735
Validation loss: 1.8925207712317025

Epoch: 5| Step: 6
Training loss: 0.8049929738044739
Validation loss: 1.9203779992236887

Epoch: 5| Step: 7
Training loss: 0.7862719297409058
Validation loss: 1.8923794043961393

Epoch: 5| Step: 8
Training loss: 1.339066743850708
Validation loss: 1.8762624097126785

Epoch: 5| Step: 9
Training loss: 1.3439080715179443
Validation loss: 1.843962933427544

Epoch: 5| Step: 10
Training loss: 1.6333616971969604
Validation loss: 1.8230646348768664

Epoch: 224| Step: 0
Training loss: 1.3592569828033447
Validation loss: 1.806207033895677

Epoch: 5| Step: 1
Training loss: 1.4102548360824585
Validation loss: 1.8196195146088958

Epoch: 5| Step: 2
Training loss: 0.9311046600341797
Validation loss: 1.807768582015909

Epoch: 5| Step: 3
Training loss: 0.9722404479980469
Validation loss: 1.8188195664395568

Epoch: 5| Step: 4
Training loss: 1.0117475986480713
Validation loss: 1.8766891417964813

Epoch: 5| Step: 5
Training loss: 0.7422428131103516
Validation loss: 1.922490225043348

Epoch: 5| Step: 6
Training loss: 1.2461373805999756
Validation loss: 1.936276174360706

Epoch: 5| Step: 7
Training loss: 1.10958993434906
Validation loss: 1.9197994560323737

Epoch: 5| Step: 8
Training loss: 1.0325088500976562
Validation loss: 1.888212061697437

Epoch: 5| Step: 9
Training loss: 0.7812925577163696
Validation loss: 1.841947672187641

Epoch: 5| Step: 10
Training loss: 1.6544963121414185
Validation loss: 1.8049815431717904

Epoch: 225| Step: 0
Training loss: 0.7977378368377686
Validation loss: 1.8092589737266622

Epoch: 5| Step: 1
Training loss: 1.1563341617584229
Validation loss: 1.8085089498950588

Epoch: 5| Step: 2
Training loss: 1.1419708728790283
Validation loss: 1.8183244171962942

Epoch: 5| Step: 3
Training loss: 1.0904309749603271
Validation loss: 1.8631700905420447

Epoch: 5| Step: 4
Training loss: 1.1421376466751099
Validation loss: 1.904566361058143

Epoch: 5| Step: 5
Training loss: 1.2340493202209473
Validation loss: 1.9038614752472087

Epoch: 5| Step: 6
Training loss: 0.9007803201675415
Validation loss: 1.855976745646487

Epoch: 5| Step: 7
Training loss: 0.969343364238739
Validation loss: 1.833158585333055

Epoch: 5| Step: 8
Training loss: 1.308944821357727
Validation loss: 1.8618356399638678

Epoch: 5| Step: 9
Training loss: 1.1440622806549072
Validation loss: 1.8763460061883415

Epoch: 5| Step: 10
Training loss: 1.1731163263320923
Validation loss: 1.871010257351783

Epoch: 226| Step: 0
Training loss: 1.2772343158721924
Validation loss: 1.8622321262154529

Epoch: 5| Step: 1
Training loss: 1.3454444408416748
Validation loss: 1.8441759437643073

Epoch: 5| Step: 2
Training loss: 1.1164000034332275
Validation loss: 1.839208690069055

Epoch: 5| Step: 3
Training loss: 0.7837570905685425
Validation loss: 1.836059977931361

Epoch: 5| Step: 4
Training loss: 1.6290099620819092
Validation loss: 1.8515437085141417

Epoch: 5| Step: 5
Training loss: 1.1660821437835693
Validation loss: 1.8940147763939315

Epoch: 5| Step: 6
Training loss: 0.7759616374969482
Validation loss: 1.9057555211487638

Epoch: 5| Step: 7
Training loss: 0.6904773712158203
Validation loss: 1.9079291666707685

Epoch: 5| Step: 8
Training loss: 1.0110195875167847
Validation loss: 1.888134491059088

Epoch: 5| Step: 9
Training loss: 1.2211343050003052
Validation loss: 1.888250857271174

Epoch: 5| Step: 10
Training loss: 1.0403757095336914
Validation loss: 1.8797507914163734

Epoch: 227| Step: 0
Training loss: 0.9108113050460815
Validation loss: 1.9107586055673578

Epoch: 5| Step: 1
Training loss: 0.7480422854423523
Validation loss: 1.888158079116575

Epoch: 5| Step: 2
Training loss: 0.8861549496650696
Validation loss: 1.9150331251082882

Epoch: 5| Step: 3
Training loss: 1.4963209629058838
Validation loss: 1.907278831287097

Epoch: 5| Step: 4
Training loss: 1.2923495769500732
Validation loss: 1.8835570722497919

Epoch: 5| Step: 5
Training loss: 0.9098504781723022
Validation loss: 1.8523627352970902

Epoch: 5| Step: 6
Training loss: 0.8883622884750366
Validation loss: 1.8633290965070006

Epoch: 5| Step: 7
Training loss: 1.120380163192749
Validation loss: 1.8771808339703469

Epoch: 5| Step: 8
Training loss: 1.1965434551239014
Validation loss: 1.8809418921829553

Epoch: 5| Step: 9
Training loss: 1.0160605907440186
Validation loss: 1.8888932146051878

Epoch: 5| Step: 10
Training loss: 1.4109883308410645
Validation loss: 1.8797658002504738

Epoch: 228| Step: 0
Training loss: 1.3323956727981567
Validation loss: 1.8369631395545056

Epoch: 5| Step: 1
Training loss: 0.6784342527389526
Validation loss: 1.8249295808935677

Epoch: 5| Step: 2
Training loss: 0.8563247919082642
Validation loss: 1.8279884412724485

Epoch: 5| Step: 3
Training loss: 0.8833447694778442
Validation loss: 1.8431083694581063

Epoch: 5| Step: 4
Training loss: 0.7066844701766968
Validation loss: 1.866537105652594

Epoch: 5| Step: 5
Training loss: 0.8050797581672668
Validation loss: 1.9065515225933445

Epoch: 5| Step: 6
Training loss: 1.4170255661010742
Validation loss: 1.9030339666592178

Epoch: 5| Step: 7
Training loss: 1.2728391885757446
Validation loss: 1.8838195787963046

Epoch: 5| Step: 8
Training loss: 1.073664903640747
Validation loss: 1.8503622508818103

Epoch: 5| Step: 9
Training loss: 1.3551666736602783
Validation loss: 1.8207035115970078

Epoch: 5| Step: 10
Training loss: 1.3857769966125488
Validation loss: 1.8100115586352605

Epoch: 229| Step: 0
Training loss: 0.9735867381095886
Validation loss: 1.8177681789603284

Epoch: 5| Step: 1
Training loss: 0.7096675038337708
Validation loss: 1.8233086011743034

Epoch: 5| Step: 2
Training loss: 1.1234080791473389
Validation loss: 1.848473423270769

Epoch: 5| Step: 3
Training loss: 1.020490050315857
Validation loss: 1.8586731533850394

Epoch: 5| Step: 4
Training loss: 0.7036985158920288
Validation loss: 1.8616749753234207

Epoch: 5| Step: 5
Training loss: 1.2836631536483765
Validation loss: 1.8671757072530768

Epoch: 5| Step: 6
Training loss: 1.4416695833206177
Validation loss: 1.8287515133939765

Epoch: 5| Step: 7
Training loss: 1.235364556312561
Validation loss: 1.816536525244354

Epoch: 5| Step: 8
Training loss: 1.0370433330535889
Validation loss: 1.82886089048078

Epoch: 5| Step: 9
Training loss: 1.223587155342102
Validation loss: 1.8383223138829714

Epoch: 5| Step: 10
Training loss: 0.796696126461029
Validation loss: 1.8923653223181283

Epoch: 230| Step: 0
Training loss: 1.13030207157135
Validation loss: 1.8942035410993843

Epoch: 5| Step: 1
Training loss: 0.6997459530830383
Validation loss: 1.9215578084350915

Epoch: 5| Step: 2
Training loss: 1.0437850952148438
Validation loss: 1.9040850567561325

Epoch: 5| Step: 3
Training loss: 0.9190584421157837
Validation loss: 1.8942807348825599

Epoch: 5| Step: 4
Training loss: 1.298769235610962
Validation loss: 1.8839129542791715

Epoch: 5| Step: 5
Training loss: 1.119490385055542
Validation loss: 1.8740981009698683

Epoch: 5| Step: 6
Training loss: 1.4288933277130127
Validation loss: 1.8376178677364061

Epoch: 5| Step: 7
Training loss: 0.7493915557861328
Validation loss: 1.80982554599803

Epoch: 5| Step: 8
Training loss: 0.9651710391044617
Validation loss: 1.799994425107074

Epoch: 5| Step: 9
Training loss: 0.8010218739509583
Validation loss: 1.7939408581743959

Epoch: 5| Step: 10
Training loss: 1.176938772201538
Validation loss: 1.7874251873262468

Epoch: 231| Step: 0
Training loss: 1.4274909496307373
Validation loss: 1.7805177985980947

Epoch: 5| Step: 1
Training loss: 0.8100219964981079
Validation loss: 1.7961118195646553

Epoch: 5| Step: 2
Training loss: 1.1826568841934204
Validation loss: 1.8396689827724169

Epoch: 5| Step: 3
Training loss: 1.2654510736465454
Validation loss: 1.8881482808820662

Epoch: 5| Step: 4
Training loss: 0.6333931088447571
Validation loss: 1.907193620999654

Epoch: 5| Step: 5
Training loss: 1.0109729766845703
Validation loss: 1.908573345471454

Epoch: 5| Step: 6
Training loss: 1.0779390335083008
Validation loss: 1.911284524907348

Epoch: 5| Step: 7
Training loss: 1.0217012166976929
Validation loss: 1.8764654551782916

Epoch: 5| Step: 8
Training loss: 1.1789090633392334
Validation loss: 1.8516803377418107

Epoch: 5| Step: 9
Training loss: 1.0904310941696167
Validation loss: 1.8451557223514845

Epoch: 5| Step: 10
Training loss: 0.9491784572601318
Validation loss: 1.8420797483895415

Epoch: 232| Step: 0
Training loss: 0.9950014352798462
Validation loss: 1.8395502144290554

Epoch: 5| Step: 1
Training loss: 0.7596470713615417
Validation loss: 1.8629772534934423

Epoch: 5| Step: 2
Training loss: 0.7385789752006531
Validation loss: 1.894889893070344

Epoch: 5| Step: 3
Training loss: 0.9683879017829895
Validation loss: 1.9207298858191377

Epoch: 5| Step: 4
Training loss: 1.1955111026763916
Validation loss: 1.8868718172914238

Epoch: 5| Step: 5
Training loss: 1.384023666381836
Validation loss: 1.8641941342302548

Epoch: 5| Step: 6
Training loss: 1.004563808441162
Validation loss: 1.8256294496597782

Epoch: 5| Step: 7
Training loss: 1.6247756481170654
Validation loss: 1.83756753834345

Epoch: 5| Step: 8
Training loss: 0.7961990237236023
Validation loss: 1.83122605405828

Epoch: 5| Step: 9
Training loss: 0.8834794759750366
Validation loss: 1.845725101809348

Epoch: 5| Step: 10
Training loss: 0.9595435857772827
Validation loss: 1.8583637014512093

Epoch: 233| Step: 0
Training loss: 0.7784165143966675
Validation loss: 1.8965361054225633

Epoch: 5| Step: 1
Training loss: 0.7224897742271423
Validation loss: 1.8988932101957259

Epoch: 5| Step: 2
Training loss: 0.8096210360527039
Validation loss: 1.9095142656756985

Epoch: 5| Step: 3
Training loss: 1.0081558227539062
Validation loss: 1.8955281216611144

Epoch: 5| Step: 4
Training loss: 0.9375839233398438
Validation loss: 1.8627747194741362

Epoch: 5| Step: 5
Training loss: 1.224252462387085
Validation loss: 1.8579224553159488

Epoch: 5| Step: 6
Training loss: 1.094975233078003
Validation loss: 1.8507682302946686

Epoch: 5| Step: 7
Training loss: 1.0049455165863037
Validation loss: 1.8523753458453762

Epoch: 5| Step: 8
Training loss: 0.8367854356765747
Validation loss: 1.837396716558805

Epoch: 5| Step: 9
Training loss: 1.0929855108261108
Validation loss: 1.8397191134832238

Epoch: 5| Step: 10
Training loss: 1.5956735610961914
Validation loss: 1.8325923847895798

Epoch: 234| Step: 0
Training loss: 0.7564045786857605
Validation loss: 1.8206942594179543

Epoch: 5| Step: 1
Training loss: 1.0289790630340576
Validation loss: 1.856965418784849

Epoch: 5| Step: 2
Training loss: 0.9266229867935181
Validation loss: 1.8765856001966743

Epoch: 5| Step: 3
Training loss: 0.8597504496574402
Validation loss: 1.8521545266592374

Epoch: 5| Step: 4
Training loss: 0.8155766725540161
Validation loss: 1.859929548796787

Epoch: 5| Step: 5
Training loss: 1.1704118251800537
Validation loss: 1.8444774381576046

Epoch: 5| Step: 6
Training loss: 1.3263968229293823
Validation loss: 1.832422992234589

Epoch: 5| Step: 7
Training loss: 1.1005957126617432
Validation loss: 1.817299118605993

Epoch: 5| Step: 8
Training loss: 1.7536327838897705
Validation loss: 1.8242651031863304

Epoch: 5| Step: 9
Training loss: 0.7082878351211548
Validation loss: 1.8212350440281693

Epoch: 5| Step: 10
Training loss: 0.5896852016448975
Validation loss: 1.8434705785525742

Epoch: 235| Step: 0
Training loss: 1.1069204807281494
Validation loss: 1.8790472476713118

Epoch: 5| Step: 1
Training loss: 0.7116585969924927
Validation loss: 1.9134842093272875

Epoch: 5| Step: 2
Training loss: 0.9723832011222839
Validation loss: 1.8959668323557863

Epoch: 5| Step: 3
Training loss: 1.2632455825805664
Validation loss: 1.8860556681950886

Epoch: 5| Step: 4
Training loss: 0.7338525056838989
Validation loss: 1.8550243249503515

Epoch: 5| Step: 5
Training loss: 0.9355071187019348
Validation loss: 1.8449526525312854

Epoch: 5| Step: 6
Training loss: 0.9681046605110168
Validation loss: 1.8346870150617374

Epoch: 5| Step: 7
Training loss: 1.2680448293685913
Validation loss: 1.8654411659445813

Epoch: 5| Step: 8
Training loss: 0.9272748827934265
Validation loss: 1.889156146716046

Epoch: 5| Step: 9
Training loss: 0.9951568841934204
Validation loss: 1.9421455206409577

Epoch: 5| Step: 10
Training loss: 1.1195306777954102
Validation loss: 1.8930999361058718

Epoch: 236| Step: 0
Training loss: 0.641982913017273
Validation loss: 1.8832088490968109

Epoch: 5| Step: 1
Training loss: 1.341129183769226
Validation loss: 1.8529121888581144

Epoch: 5| Step: 2
Training loss: 1.0319881439208984
Validation loss: 1.858948431989198

Epoch: 5| Step: 3
Training loss: 0.6815200448036194
Validation loss: 1.8475979489664878

Epoch: 5| Step: 4
Training loss: 0.9682548642158508
Validation loss: 1.838665699446073

Epoch: 5| Step: 5
Training loss: 1.2076542377471924
Validation loss: 1.8366454019341418

Epoch: 5| Step: 6
Training loss: 0.8835364580154419
Validation loss: 1.8447035897162654

Epoch: 5| Step: 7
Training loss: 1.0072052478790283
Validation loss: 1.8620502295032624

Epoch: 5| Step: 8
Training loss: 0.9460180401802063
Validation loss: 1.8558012054812523

Epoch: 5| Step: 9
Training loss: 0.8624471426010132
Validation loss: 1.8654237729246899

Epoch: 5| Step: 10
Training loss: 1.1121512651443481
Validation loss: 1.862101311324745

Epoch: 237| Step: 0
Training loss: 0.7546421885490417
Validation loss: 1.8673983286785822

Epoch: 5| Step: 1
Training loss: 0.48143497109413147
Validation loss: 1.8725756086328977

Epoch: 5| Step: 2
Training loss: 0.8387773633003235
Validation loss: 1.8465262215624574

Epoch: 5| Step: 3
Training loss: 0.9630025029182434
Validation loss: 1.8478324567117999

Epoch: 5| Step: 4
Training loss: 1.0295908451080322
Validation loss: 1.8301157079717165

Epoch: 5| Step: 5
Training loss: 1.106706976890564
Validation loss: 1.807835005944775

Epoch: 5| Step: 6
Training loss: 1.1816797256469727
Validation loss: 1.819990005544437

Epoch: 5| Step: 7
Training loss: 1.1348495483398438
Validation loss: 1.8300511631914365

Epoch: 5| Step: 8
Training loss: 0.8160582780838013
Validation loss: 1.8410917059067757

Epoch: 5| Step: 9
Training loss: 1.0938615798950195
Validation loss: 1.8563249495721632

Epoch: 5| Step: 10
Training loss: 1.2909841537475586
Validation loss: 1.8739417624729935

Epoch: 238| Step: 0
Training loss: 1.1306451559066772
Validation loss: 1.8654120199141964

Epoch: 5| Step: 1
Training loss: 1.2538963556289673
Validation loss: 1.8628174502362487

Epoch: 5| Step: 2
Training loss: 0.714996337890625
Validation loss: 1.834470901437985

Epoch: 5| Step: 3
Training loss: 0.7323524355888367
Validation loss: 1.842987592502307

Epoch: 5| Step: 4
Training loss: 1.0650241374969482
Validation loss: 1.8099909623463948

Epoch: 5| Step: 5
Training loss: 0.9421176910400391
Validation loss: 1.8227494480789348

Epoch: 5| Step: 6
Training loss: 1.119037389755249
Validation loss: 1.8367882672176565

Epoch: 5| Step: 7
Training loss: 0.5645885467529297
Validation loss: 1.8544877434289584

Epoch: 5| Step: 8
Training loss: 0.7303444743156433
Validation loss: 1.8455501038541076

Epoch: 5| Step: 9
Training loss: 0.9237504005432129
Validation loss: 1.8403843987372615

Epoch: 5| Step: 10
Training loss: 1.048004388809204
Validation loss: 1.8609438365505588

Epoch: 239| Step: 0
Training loss: 0.5870809555053711
Validation loss: 1.8431789105938328

Epoch: 5| Step: 1
Training loss: 1.1727268695831299
Validation loss: 1.8320309564631472

Epoch: 5| Step: 2
Training loss: 1.2170002460479736
Validation loss: 1.799447697977866

Epoch: 5| Step: 3
Training loss: 0.6731806993484497
Validation loss: 1.8051516881553076

Epoch: 5| Step: 4
Training loss: 1.3483600616455078
Validation loss: 1.8139621878183017

Epoch: 5| Step: 5
Training loss: 1.0937175750732422
Validation loss: 1.8001787816324542

Epoch: 5| Step: 6
Training loss: 0.625298023223877
Validation loss: 1.8426910831082253

Epoch: 5| Step: 7
Training loss: 1.100531816482544
Validation loss: 1.831563062565301

Epoch: 5| Step: 8
Training loss: 0.8749459385871887
Validation loss: 1.8382722203449537

Epoch: 5| Step: 9
Training loss: 0.9440954923629761
Validation loss: 1.8232492849390993

Epoch: 5| Step: 10
Training loss: 0.7177148461341858
Validation loss: 1.8390985509400726

Epoch: 240| Step: 0
Training loss: 0.6419782638549805
Validation loss: 1.8274886031304636

Epoch: 5| Step: 1
Training loss: 0.8877733945846558
Validation loss: 1.8373936619809879

Epoch: 5| Step: 2
Training loss: 1.0028892755508423
Validation loss: 1.8732493487737512

Epoch: 5| Step: 3
Training loss: 0.8971863985061646
Validation loss: 1.8738141828967678

Epoch: 5| Step: 4
Training loss: 0.8213037252426147
Validation loss: 1.8752481347771102

Epoch: 5| Step: 5
Training loss: 0.9368098974227905
Validation loss: 1.8623223458566973

Epoch: 5| Step: 6
Training loss: 1.1701329946517944
Validation loss: 1.8687782133779218

Epoch: 5| Step: 7
Training loss: 1.0815985202789307
Validation loss: 1.8731597687608452

Epoch: 5| Step: 8
Training loss: 0.9352798461914062
Validation loss: 1.8776689678110101

Epoch: 5| Step: 9
Training loss: 0.8997330665588379
Validation loss: 1.8673667202713669

Epoch: 5| Step: 10
Training loss: 1.063547968864441
Validation loss: 1.8462676873771093

Epoch: 241| Step: 0
Training loss: 0.6235839128494263
Validation loss: 1.8359172344207764

Epoch: 5| Step: 1
Training loss: 0.9248998761177063
Validation loss: 1.8283056033554899

Epoch: 5| Step: 2
Training loss: 1.008978247642517
Validation loss: 1.8081348262807375

Epoch: 5| Step: 3
Training loss: 0.5881835222244263
Validation loss: 1.8511129476690804

Epoch: 5| Step: 4
Training loss: 0.8437877893447876
Validation loss: 1.8121080321650351

Epoch: 5| Step: 5
Training loss: 1.469076156616211
Validation loss: 1.7975453202442457

Epoch: 5| Step: 6
Training loss: 0.991511344909668
Validation loss: 1.7825546226193827

Epoch: 5| Step: 7
Training loss: 1.1696484088897705
Validation loss: 1.7913173808846423

Epoch: 5| Step: 8
Training loss: 0.9325754046440125
Validation loss: 1.7956171215221446

Epoch: 5| Step: 9
Training loss: 0.7222281694412231
Validation loss: 1.7961424589157104

Epoch: 5| Step: 10
Training loss: 0.8811637759208679
Validation loss: 1.8196185455527356

Epoch: 242| Step: 0
Training loss: 1.1161754131317139
Validation loss: 1.8549895337832871

Epoch: 5| Step: 1
Training loss: 0.702447772026062
Validation loss: 1.8933080793708883

Epoch: 5| Step: 2
Training loss: 1.2093919515609741
Validation loss: 1.9024861128099504

Epoch: 5| Step: 3
Training loss: 0.573327898979187
Validation loss: 1.8546418977040116

Epoch: 5| Step: 4
Training loss: 0.9226096272468567
Validation loss: 1.850322095296716

Epoch: 5| Step: 5
Training loss: 0.6331032514572144
Validation loss: 1.8273094956592848

Epoch: 5| Step: 6
Training loss: 0.8452073335647583
Validation loss: 1.7758060501467796

Epoch: 5| Step: 7
Training loss: 1.343523621559143
Validation loss: 1.7718805395146853

Epoch: 5| Step: 8
Training loss: 0.8930416107177734
Validation loss: 1.7715760879619147

Epoch: 5| Step: 9
Training loss: 1.1876963376998901
Validation loss: 1.768038058793673

Epoch: 5| Step: 10
Training loss: 1.0204488039016724
Validation loss: 1.7646109506648073

Epoch: 243| Step: 0
Training loss: 0.9229921102523804
Validation loss: 1.785000208885439

Epoch: 5| Step: 1
Training loss: 0.9776712656021118
Validation loss: 1.807553760467037

Epoch: 5| Step: 2
Training loss: 1.008974313735962
Validation loss: 1.7993398148526427

Epoch: 5| Step: 3
Training loss: 0.7823166251182556
Validation loss: 1.7756832440694172

Epoch: 5| Step: 4
Training loss: 0.9901235699653625
Validation loss: 1.7809851541314075

Epoch: 5| Step: 5
Training loss: 1.0167256593704224
Validation loss: 1.7777185106790194

Epoch: 5| Step: 6
Training loss: 0.8143211603164673
Validation loss: 1.8071924332649476

Epoch: 5| Step: 7
Training loss: 0.9690325856208801
Validation loss: 1.8107986629650157

Epoch: 5| Step: 8
Training loss: 0.6720609664916992
Validation loss: 1.8276376698606758

Epoch: 5| Step: 9
Training loss: 1.0944067239761353
Validation loss: 1.8478488563209452

Epoch: 5| Step: 10
Training loss: 0.8813843727111816
Validation loss: 1.868678149356637

Epoch: 244| Step: 0
Training loss: 1.0264503955841064
Validation loss: 1.8098239309044295

Epoch: 5| Step: 1
Training loss: 0.9276899099349976
Validation loss: 1.7899774069427161

Epoch: 5| Step: 2
Training loss: 0.7820574641227722
Validation loss: 1.7787417045203588

Epoch: 5| Step: 3
Training loss: 1.1460230350494385
Validation loss: 1.79811994747449

Epoch: 5| Step: 4
Training loss: 1.1397603750228882
Validation loss: 1.7954704184685983

Epoch: 5| Step: 5
Training loss: 0.740824818611145
Validation loss: 1.8134118049375472

Epoch: 5| Step: 6
Training loss: 0.6027984619140625
Validation loss: 1.8233039097119403

Epoch: 5| Step: 7
Training loss: 1.050410509109497
Validation loss: 1.8278506058518604

Epoch: 5| Step: 8
Training loss: 0.6668380498886108
Validation loss: 1.827899448333248

Epoch: 5| Step: 9
Training loss: 1.1234534978866577
Validation loss: 1.8050781347418343

Epoch: 5| Step: 10
Training loss: 0.8663010001182556
Validation loss: 1.7842327010247014

Epoch: 245| Step: 0
Training loss: 0.8880073428153992
Validation loss: 1.7524912613694386

Epoch: 5| Step: 1
Training loss: 0.9361030459403992
Validation loss: 1.752001541917042

Epoch: 5| Step: 2
Training loss: 0.6778558492660522
Validation loss: 1.7688895451125277

Epoch: 5| Step: 3
Training loss: 0.885802149772644
Validation loss: 1.7483885236965713

Epoch: 5| Step: 4
Training loss: 0.8584901690483093
Validation loss: 1.768380267645723

Epoch: 5| Step: 5
Training loss: 0.6002827882766724
Validation loss: 1.801409621392527

Epoch: 5| Step: 6
Training loss: 0.9836910367012024
Validation loss: 1.8662504637113182

Epoch: 5| Step: 7
Training loss: 0.7983937859535217
Validation loss: 1.8617470238798408

Epoch: 5| Step: 8
Training loss: 1.1473091840744019
Validation loss: 1.8432108202288229

Epoch: 5| Step: 9
Training loss: 0.8724864721298218
Validation loss: 1.832356681105911

Epoch: 5| Step: 10
Training loss: 1.220595359802246
Validation loss: 1.7950803720822899

Epoch: 246| Step: 0
Training loss: 0.669248640537262
Validation loss: 1.7931805169710548

Epoch: 5| Step: 1
Training loss: 1.0222944021224976
Validation loss: 1.78791457094172

Epoch: 5| Step: 2
Training loss: 1.1570913791656494
Validation loss: 1.7980266655645063

Epoch: 5| Step: 3
Training loss: 1.1652557849884033
Validation loss: 1.8034297291950514

Epoch: 5| Step: 4
Training loss: 0.815686047077179
Validation loss: 1.8221917498496272

Epoch: 5| Step: 5
Training loss: 0.4156881272792816
Validation loss: 1.838033615901906

Epoch: 5| Step: 6
Training loss: 1.2580947875976562
Validation loss: 1.8379034714032245

Epoch: 5| Step: 7
Training loss: 0.7978507280349731
Validation loss: 1.8112109822611655

Epoch: 5| Step: 8
Training loss: 1.0595502853393555
Validation loss: 1.7972881524793562

Epoch: 5| Step: 9
Training loss: 0.7402430772781372
Validation loss: 1.7951415226023684

Epoch: 5| Step: 10
Training loss: 0.43267765641212463
Validation loss: 1.7941903580901444

Epoch: 247| Step: 0
Training loss: 0.40630435943603516
Validation loss: 1.8068970044453938

Epoch: 5| Step: 1
Training loss: 1.1443148851394653
Validation loss: 1.8095836588131484

Epoch: 5| Step: 2
Training loss: 1.1444463729858398
Validation loss: 1.8135116933494486

Epoch: 5| Step: 3
Training loss: 0.8975958824157715
Validation loss: 1.8447070621675061

Epoch: 5| Step: 4
Training loss: 0.7203126549720764
Validation loss: 1.8156710517021917

Epoch: 5| Step: 5
Training loss: 0.7467243075370789
Validation loss: 1.8337778019648727

Epoch: 5| Step: 6
Training loss: 0.6418553590774536
Validation loss: 1.8038387375493203

Epoch: 5| Step: 7
Training loss: 0.9761447906494141
Validation loss: 1.7959818442662556

Epoch: 5| Step: 8
Training loss: 1.1428295373916626
Validation loss: 1.8007091860617361

Epoch: 5| Step: 9
Training loss: 0.8612947463989258
Validation loss: 1.799554301846412

Epoch: 5| Step: 10
Training loss: 0.7227916717529297
Validation loss: 1.7983236646139493

Epoch: 248| Step: 0
Training loss: 0.825431227684021
Validation loss: 1.8222313542519846

Epoch: 5| Step: 1
Training loss: 1.0081695318222046
Validation loss: 1.8113985459009807

Epoch: 5| Step: 2
Training loss: 0.5854765176773071
Validation loss: 1.7815906565676454

Epoch: 5| Step: 3
Training loss: 1.0805511474609375
Validation loss: 1.7632175837793658

Epoch: 5| Step: 4
Training loss: 0.7274162769317627
Validation loss: 1.7797955325854722

Epoch: 5| Step: 5
Training loss: 0.9372251629829407
Validation loss: 1.8391108166786931

Epoch: 5| Step: 6
Training loss: 0.5305908918380737
Validation loss: 1.8244884924222065

Epoch: 5| Step: 7
Training loss: 1.2035014629364014
Validation loss: 1.813393195470174

Epoch: 5| Step: 8
Training loss: 0.6846402883529663
Validation loss: 1.7767853544604393

Epoch: 5| Step: 9
Training loss: 0.9094780087471008
Validation loss: 1.7675670962179861

Epoch: 5| Step: 10
Training loss: 0.9453058838844299
Validation loss: 1.7647559668428154

Epoch: 249| Step: 0
Training loss: 0.6857924461364746
Validation loss: 1.7880804641272432

Epoch: 5| Step: 1
Training loss: 0.7456777691841125
Validation loss: 1.7678004080249416

Epoch: 5| Step: 2
Training loss: 0.8246100544929504
Validation loss: 1.7902986798235165

Epoch: 5| Step: 3
Training loss: 0.6410494446754456
Validation loss: 1.7997379302978516

Epoch: 5| Step: 4
Training loss: 1.0950950384140015
Validation loss: 1.793468685560329

Epoch: 5| Step: 5
Training loss: 1.012156367301941
Validation loss: 1.819630774118567

Epoch: 5| Step: 6
Training loss: 1.0152537822723389
Validation loss: 1.8313770794099378

Epoch: 5| Step: 7
Training loss: 0.9420837163925171
Validation loss: 1.8311896580521778

Epoch: 5| Step: 8
Training loss: 0.7800765037536621
Validation loss: 1.790132514892086

Epoch: 5| Step: 9
Training loss: 0.6601553559303284
Validation loss: 1.7492307360454271

Epoch: 5| Step: 10
Training loss: 0.8947062492370605
Validation loss: 1.730997367571759

Epoch: 250| Step: 0
Training loss: 1.0095939636230469
Validation loss: 1.725156992994329

Epoch: 5| Step: 1
Training loss: 0.9022541046142578
Validation loss: 1.7304791878628474

Epoch: 5| Step: 2
Training loss: 0.6150029301643372
Validation loss: 1.7452963577803744

Epoch: 5| Step: 3
Training loss: 1.3201618194580078
Validation loss: 1.754692433982767

Epoch: 5| Step: 4
Training loss: 1.052196741104126
Validation loss: 1.8001511814773723

Epoch: 5| Step: 5
Training loss: 0.8584667444229126
Validation loss: 1.8418562809626262

Epoch: 5| Step: 6
Training loss: 0.7509510517120361
Validation loss: 1.8604907476773827

Epoch: 5| Step: 7
Training loss: 0.7310099005699158
Validation loss: 1.8287207311199558

Epoch: 5| Step: 8
Training loss: 1.116990566253662
Validation loss: 1.8198234342759656

Epoch: 5| Step: 9
Training loss: 0.3529461920261383
Validation loss: 1.797626426143031

Epoch: 5| Step: 10
Training loss: 0.9304050207138062
Validation loss: 1.7844672741428498

Epoch: 251| Step: 0
Training loss: 0.6684364080429077
Validation loss: 1.7763415331481605

Epoch: 5| Step: 1
Training loss: 0.6438098549842834
Validation loss: 1.8029685379356466

Epoch: 5| Step: 2
Training loss: 0.8163502812385559
Validation loss: 1.8229540137834446

Epoch: 5| Step: 3
Training loss: 0.9104108810424805
Validation loss: 1.850229883706698

Epoch: 5| Step: 4
Training loss: 1.0048744678497314
Validation loss: 1.8585469902202647

Epoch: 5| Step: 5
Training loss: 1.1431710720062256
Validation loss: 1.9004843388834307

Epoch: 5| Step: 6
Training loss: 0.7965970039367676
Validation loss: 1.8435682968426776

Epoch: 5| Step: 7
Training loss: 0.7572606801986694
Validation loss: 1.7897915032602125

Epoch: 5| Step: 8
Training loss: 1.0797889232635498
Validation loss: 1.7694708121720182

Epoch: 5| Step: 9
Training loss: 0.9840976595878601
Validation loss: 1.7754961457303775

Epoch: 5| Step: 10
Training loss: 0.5661966800689697
Validation loss: 1.7648132193473078

Epoch: 252| Step: 0
Training loss: 0.4413222372531891
Validation loss: 1.764861955437609

Epoch: 5| Step: 1
Training loss: 0.6164513230323792
Validation loss: 1.7702779872443086

Epoch: 5| Step: 2
Training loss: 1.014159917831421
Validation loss: 1.7922333261018157

Epoch: 5| Step: 3
Training loss: 0.8592931032180786
Validation loss: 1.7968470973353232

Epoch: 5| Step: 4
Training loss: 0.919204831123352
Validation loss: 1.840691581849129

Epoch: 5| Step: 5
Training loss: 0.6022224426269531
Validation loss: 1.8303027947743733

Epoch: 5| Step: 6
Training loss: 1.354952335357666
Validation loss: 1.7958947779029928

Epoch: 5| Step: 7
Training loss: 0.7637107968330383
Validation loss: 1.7805251485557967

Epoch: 5| Step: 8
Training loss: 1.0048202276229858
Validation loss: 1.7630006485087897

Epoch: 5| Step: 9
Training loss: 1.1527537107467651
Validation loss: 1.7663931641527402

Epoch: 5| Step: 10
Training loss: 1.0573723316192627
Validation loss: 1.7559293623893493

Epoch: 253| Step: 0
Training loss: 0.7602185010910034
Validation loss: 1.7501321723384242

Epoch: 5| Step: 1
Training loss: 0.7383486032485962
Validation loss: 1.7734683354695637

Epoch: 5| Step: 2
Training loss: 0.9484577178955078
Validation loss: 1.7777220997759091

Epoch: 5| Step: 3
Training loss: 0.7915191650390625
Validation loss: 1.813667143544843

Epoch: 5| Step: 4
Training loss: 0.8216351270675659
Validation loss: 1.8635187149047852

Epoch: 5| Step: 5
Training loss: 0.8252614140510559
Validation loss: 1.8821553748141053

Epoch: 5| Step: 6
Training loss: 0.6737051010131836
Validation loss: 1.832972406059183

Epoch: 5| Step: 7
Training loss: 0.9830312728881836
Validation loss: 1.7999162584222772

Epoch: 5| Step: 8
Training loss: 1.1720000505447388
Validation loss: 1.781250851128691

Epoch: 5| Step: 9
Training loss: 0.8917359113693237
Validation loss: 1.7673152313437512

Epoch: 5| Step: 10
Training loss: 0.6946574449539185
Validation loss: 1.775851047167214

Epoch: 254| Step: 0
Training loss: 0.8847088813781738
Validation loss: 1.7949485932627032

Epoch: 5| Step: 1
Training loss: 0.976513683795929
Validation loss: 1.8091671120735906

Epoch: 5| Step: 2
Training loss: 1.136313557624817
Validation loss: 1.852830812495242

Epoch: 5| Step: 3
Training loss: 0.8059242963790894
Validation loss: 1.8638208168809132

Epoch: 5| Step: 4
Training loss: 0.7254567742347717
Validation loss: 1.8026665897779568

Epoch: 5| Step: 5
Training loss: 1.0596306324005127
Validation loss: 1.7869263323404456

Epoch: 5| Step: 6
Training loss: 0.725662350654602
Validation loss: 1.792516758365016

Epoch: 5| Step: 7
Training loss: 1.0639584064483643
Validation loss: 1.7907779575676046

Epoch: 5| Step: 8
Training loss: 0.9028372764587402
Validation loss: 1.7932158593208558

Epoch: 5| Step: 9
Training loss: 0.5127006769180298
Validation loss: 1.814998520317898

Epoch: 5| Step: 10
Training loss: 0.8502090573310852
Validation loss: 1.8593955950070453

Epoch: 255| Step: 0
Training loss: 1.0293934345245361
Validation loss: 1.9560929011273127

Epoch: 5| Step: 1
Training loss: 0.9707286953926086
Validation loss: 1.9447684749480216

Epoch: 5| Step: 2
Training loss: 0.7427991032600403
Validation loss: 1.9046639806480818

Epoch: 5| Step: 3
Training loss: 0.8949518203735352
Validation loss: 1.8343942216647569

Epoch: 5| Step: 4
Training loss: 0.5644032955169678
Validation loss: 1.784748073547117

Epoch: 5| Step: 5
Training loss: 0.9859079122543335
Validation loss: 1.760787057620223

Epoch: 5| Step: 6
Training loss: 0.9305631518363953
Validation loss: 1.7689412575896069

Epoch: 5| Step: 7
Training loss: 0.5671417117118835
Validation loss: 1.7682237753304102

Epoch: 5| Step: 8
Training loss: 0.9340264201164246
Validation loss: 1.7523169748244747

Epoch: 5| Step: 9
Training loss: 0.8824261426925659
Validation loss: 1.820544961960085

Epoch: 5| Step: 10
Training loss: 1.1941757202148438
Validation loss: 1.8779270251592

Epoch: 256| Step: 0
Training loss: 1.1241273880004883
Validation loss: 1.8513951660484396

Epoch: 5| Step: 1
Training loss: 1.1421678066253662
Validation loss: 1.8534409692210536

Epoch: 5| Step: 2
Training loss: 0.9751955270767212
Validation loss: 1.8146359420591784

Epoch: 5| Step: 3
Training loss: 0.45547810196876526
Validation loss: 1.7886897633152623

Epoch: 5| Step: 4
Training loss: 0.5831436514854431
Validation loss: 1.760181701311501

Epoch: 5| Step: 5
Training loss: 0.8028815984725952
Validation loss: 1.7689373916195286

Epoch: 5| Step: 6
Training loss: 1.1162467002868652
Validation loss: 1.7812379970345447

Epoch: 5| Step: 7
Training loss: 1.083307147026062
Validation loss: 1.7847722185555326

Epoch: 5| Step: 8
Training loss: 0.6292949914932251
Validation loss: 1.7605514757094844

Epoch: 5| Step: 9
Training loss: 0.6138025522232056
Validation loss: 1.7645540147699335

Epoch: 5| Step: 10
Training loss: 1.1086130142211914
Validation loss: 1.7626438576688048

Epoch: 257| Step: 0
Training loss: 0.49825921654701233
Validation loss: 1.7592543466116792

Epoch: 5| Step: 1
Training loss: 1.0884466171264648
Validation loss: 1.7845754418321835

Epoch: 5| Step: 2
Training loss: 0.6110193729400635
Validation loss: 1.7973473853962396

Epoch: 5| Step: 3
Training loss: 1.021325707435608
Validation loss: 1.8240920305252075

Epoch: 5| Step: 4
Training loss: 1.139958381652832
Validation loss: 1.8360000989770378

Epoch: 5| Step: 5
Training loss: 1.0454723834991455
Validation loss: 1.8498592863800705

Epoch: 5| Step: 6
Training loss: 0.6808211803436279
Validation loss: 1.7963583841118762

Epoch: 5| Step: 7
Training loss: 0.6058340668678284
Validation loss: 1.7875553946341238

Epoch: 5| Step: 8
Training loss: 0.5152985453605652
Validation loss: 1.767117408014113

Epoch: 5| Step: 9
Training loss: 0.8461624979972839
Validation loss: 1.7448096941876154

Epoch: 5| Step: 10
Training loss: 0.9069076180458069
Validation loss: 1.7326651862872544

Epoch: 258| Step: 0
Training loss: 0.9855273962020874
Validation loss: 1.7076011332132484

Epoch: 5| Step: 1
Training loss: 0.6542396545410156
Validation loss: 1.7284127089285082

Epoch: 5| Step: 2
Training loss: 1.1919279098510742
Validation loss: 1.7691797043687554

Epoch: 5| Step: 3
Training loss: 1.0187777280807495
Validation loss: 1.777150861678585

Epoch: 5| Step: 4
Training loss: 0.6942154765129089
Validation loss: 1.7755127581216956

Epoch: 5| Step: 5
Training loss: 0.901135265827179
Validation loss: 1.793302991056955

Epoch: 5| Step: 6
Training loss: 0.6613596677780151
Validation loss: 1.7807521999523204

Epoch: 5| Step: 7
Training loss: 0.7892733812332153
Validation loss: 1.7360455502745926

Epoch: 5| Step: 8
Training loss: 0.7581602334976196
Validation loss: 1.7586091154365129

Epoch: 5| Step: 9
Training loss: 0.8160402178764343
Validation loss: 1.7610759696652811

Epoch: 5| Step: 10
Training loss: 0.5922343134880066
Validation loss: 1.7478709528523106

Epoch: 259| Step: 0
Training loss: 0.6551104784011841
Validation loss: 1.787516842606247

Epoch: 5| Step: 1
Training loss: 0.8930639028549194
Validation loss: 1.796987623296758

Epoch: 5| Step: 2
Training loss: 0.6433483362197876
Validation loss: 1.809700696699081

Epoch: 5| Step: 3
Training loss: 0.9886674880981445
Validation loss: 1.813810610002087

Epoch: 5| Step: 4
Training loss: 0.8319206237792969
Validation loss: 1.798334947196386

Epoch: 5| Step: 5
Training loss: 0.878792405128479
Validation loss: 1.766487233100399

Epoch: 5| Step: 6
Training loss: 0.8209006190299988
Validation loss: 1.7630386531993907

Epoch: 5| Step: 7
Training loss: 0.7349215745925903
Validation loss: 1.7380270137581775

Epoch: 5| Step: 8
Training loss: 0.9095790982246399
Validation loss: 1.7502941572537987

Epoch: 5| Step: 9
Training loss: 0.7929531335830688
Validation loss: 1.7540839487506497

Epoch: 5| Step: 10
Training loss: 0.6686151027679443
Validation loss: 1.7790871538141722

Epoch: 260| Step: 0
Training loss: 0.8534873127937317
Validation loss: 1.7888303905405023

Epoch: 5| Step: 1
Training loss: 0.49101656675338745
Validation loss: 1.802512320139075

Epoch: 5| Step: 2
Training loss: 0.9889658689498901
Validation loss: 1.830525513618223

Epoch: 5| Step: 3
Training loss: 1.0687144994735718
Validation loss: 1.7896523065464471

Epoch: 5| Step: 4
Training loss: 0.3641242980957031
Validation loss: 1.7486653776579006

Epoch: 5| Step: 5
Training loss: 0.8251577615737915
Validation loss: 1.7495216554211033

Epoch: 5| Step: 6
Training loss: 1.1561754941940308
Validation loss: 1.7442742701499694

Epoch: 5| Step: 7
Training loss: 0.6586147546768188
Validation loss: 1.7345285184921757

Epoch: 5| Step: 8
Training loss: 1.0206868648529053
Validation loss: 1.7708652198955577

Epoch: 5| Step: 9
Training loss: 0.6641983985900879
Validation loss: 1.805477075679328

Epoch: 5| Step: 10
Training loss: 0.6710145473480225
Validation loss: 1.8558705391422394

Epoch: 261| Step: 0
Training loss: 0.9467977285385132
Validation loss: 1.8221080264737528

Epoch: 5| Step: 1
Training loss: 0.5940345525741577
Validation loss: 1.7650532722473145

Epoch: 5| Step: 2
Training loss: 0.745587170124054
Validation loss: 1.7247994369076145

Epoch: 5| Step: 3
Training loss: 0.39549288153648376
Validation loss: 1.7186759928221345

Epoch: 5| Step: 4
Training loss: 0.531001627445221
Validation loss: 1.7327634801146805

Epoch: 5| Step: 5
Training loss: 1.0580072402954102
Validation loss: 1.7481392621994019

Epoch: 5| Step: 6
Training loss: 1.022274374961853
Validation loss: 1.7631519571427376

Epoch: 5| Step: 7
Training loss: 0.518563449382782
Validation loss: 1.7631301367154686

Epoch: 5| Step: 8
Training loss: 1.2810533046722412
Validation loss: 1.7620331971876082

Epoch: 5| Step: 9
Training loss: 0.7188652753829956
Validation loss: 1.7664107058637886

Epoch: 5| Step: 10
Training loss: 0.5389953851699829
Validation loss: 1.763647561432213

Epoch: 262| Step: 0
Training loss: 1.091486930847168
Validation loss: 1.7504546796121905

Epoch: 5| Step: 1
Training loss: 1.0026166439056396
Validation loss: 1.7424602290635467

Epoch: 5| Step: 2
Training loss: 0.9008057713508606
Validation loss: 1.7451770331269951

Epoch: 5| Step: 3
Training loss: 0.5337855219841003
Validation loss: 1.724200866555655

Epoch: 5| Step: 4
Training loss: 0.725492000579834
Validation loss: 1.7335343912083616

Epoch: 5| Step: 5
Training loss: 0.6441570520401001
Validation loss: 1.7709784546206075

Epoch: 5| Step: 6
Training loss: 0.6304918527603149
Validation loss: 1.7970866182798981

Epoch: 5| Step: 7
Training loss: 0.766130268573761
Validation loss: 1.8062439964663597

Epoch: 5| Step: 8
Training loss: 0.7587933540344238
Validation loss: 1.8007816806916268

Epoch: 5| Step: 9
Training loss: 0.5530866384506226
Validation loss: 1.7788565620299308

Epoch: 5| Step: 10
Training loss: 0.6117842793464661
Validation loss: 1.7959680429068945

Epoch: 263| Step: 0
Training loss: 0.6797994375228882
Validation loss: 1.7359998200529365

Epoch: 5| Step: 1
Training loss: 0.9753557443618774
Validation loss: 1.7209700166538198

Epoch: 5| Step: 2
Training loss: 0.7069016695022583
Validation loss: 1.7462170495781848

Epoch: 5| Step: 3
Training loss: 0.7364776730537415
Validation loss: 1.7661739062237483

Epoch: 5| Step: 4
Training loss: 0.6813502311706543
Validation loss: 1.7572437140249437

Epoch: 5| Step: 5
Training loss: 1.1208447217941284
Validation loss: 1.8013103777362454

Epoch: 5| Step: 6
Training loss: 0.5785002112388611
Validation loss: 1.807914815923219

Epoch: 5| Step: 7
Training loss: 0.8973339200019836
Validation loss: 1.7940741495419574

Epoch: 5| Step: 8
Training loss: 0.6506334543228149
Validation loss: 1.7784130342545048

Epoch: 5| Step: 9
Training loss: 0.5005143880844116
Validation loss: 1.780882716178894

Epoch: 5| Step: 10
Training loss: 0.6642166376113892
Validation loss: 1.7538606030966646

Epoch: 264| Step: 0
Training loss: 0.9171384572982788
Validation loss: 1.7321568201946955

Epoch: 5| Step: 1
Training loss: 0.7043387293815613
Validation loss: 1.7532950870452388

Epoch: 5| Step: 2
Training loss: 0.6722534894943237
Validation loss: 1.776240453925184

Epoch: 5| Step: 3
Training loss: 0.744387149810791
Validation loss: 1.774198027067287

Epoch: 5| Step: 4
Training loss: 1.06409752368927
Validation loss: 1.7681474044758787

Epoch: 5| Step: 5
Training loss: 0.6581301093101501
Validation loss: 1.7664061259197932

Epoch: 5| Step: 6
Training loss: 0.7239964008331299
Validation loss: 1.7737721473939958

Epoch: 5| Step: 7
Training loss: 0.4948693811893463
Validation loss: 1.800896639465004

Epoch: 5| Step: 8
Training loss: 0.8982182741165161
Validation loss: 1.799705777117001

Epoch: 5| Step: 9
Training loss: 0.6818327307701111
Validation loss: 1.7898750010357107

Epoch: 5| Step: 10
Training loss: 0.758512556552887
Validation loss: 1.767366010655639

Epoch: 265| Step: 0
Training loss: 0.6014499664306641
Validation loss: 1.7403332994830223

Epoch: 5| Step: 1
Training loss: 0.6174765825271606
Validation loss: 1.7418059905370076

Epoch: 5| Step: 2
Training loss: 0.7249239683151245
Validation loss: 1.742251383360996

Epoch: 5| Step: 3
Training loss: 1.1726040840148926
Validation loss: 1.7302830642269504

Epoch: 5| Step: 4
Training loss: 0.5324031710624695
Validation loss: 1.7694207801613757

Epoch: 5| Step: 5
Training loss: 0.6682942509651184
Validation loss: 1.7742462811931488

Epoch: 5| Step: 6
Training loss: 0.8395929336547852
Validation loss: 1.8296745938639487

Epoch: 5| Step: 7
Training loss: 0.9369815587997437
Validation loss: 1.8574471313466308

Epoch: 5| Step: 8
Training loss: 0.5539334416389465
Validation loss: 1.840192671745054

Epoch: 5| Step: 9
Training loss: 0.4700987935066223
Validation loss: 1.7982057166355911

Epoch: 5| Step: 10
Training loss: 1.2517385482788086
Validation loss: 1.7692715685854676

Epoch: 266| Step: 0
Training loss: 1.0998437404632568
Validation loss: 1.7422593062923801

Epoch: 5| Step: 1
Training loss: 0.7332464456558228
Validation loss: 1.7165203145755235

Epoch: 5| Step: 2
Training loss: 1.1628522872924805
Validation loss: 1.7150445433073147

Epoch: 5| Step: 3
Training loss: 0.6191205978393555
Validation loss: 1.7298493167405486

Epoch: 5| Step: 4
Training loss: 0.44002360105514526
Validation loss: 1.7070684855984104

Epoch: 5| Step: 5
Training loss: 0.8698404431343079
Validation loss: 1.746806275460028

Epoch: 5| Step: 6
Training loss: 0.9476543664932251
Validation loss: 1.7771954767165645

Epoch: 5| Step: 7
Training loss: 0.7933024168014526
Validation loss: 1.804755646695373

Epoch: 5| Step: 8
Training loss: 0.7481030821800232
Validation loss: 1.7995639949716546

Epoch: 5| Step: 9
Training loss: 0.5692495703697205
Validation loss: 1.7992857809989684

Epoch: 5| Step: 10
Training loss: 0.5407271385192871
Validation loss: 1.7647159740489016

Epoch: 267| Step: 0
Training loss: 0.5396192669868469
Validation loss: 1.7248968514063026

Epoch: 5| Step: 1
Training loss: 0.7256802916526794
Validation loss: 1.7255624212244505

Epoch: 5| Step: 2
Training loss: 0.669875979423523
Validation loss: 1.723592032668411

Epoch: 5| Step: 3
Training loss: 0.9032474756240845
Validation loss: 1.7221370294529905

Epoch: 5| Step: 4
Training loss: 0.566066563129425
Validation loss: 1.734904158499933

Epoch: 5| Step: 5
Training loss: 0.729053795337677
Validation loss: 1.7573562283669748

Epoch: 5| Step: 6
Training loss: 0.9426703453063965
Validation loss: 1.7862840749884163

Epoch: 5| Step: 7
Training loss: 0.9004867672920227
Validation loss: 1.7823822549594346

Epoch: 5| Step: 8
Training loss: 0.5781484842300415
Validation loss: 1.7846698773804532

Epoch: 5| Step: 9
Training loss: 0.5985390543937683
Validation loss: 1.7504733685524232

Epoch: 5| Step: 10
Training loss: 0.9063043594360352
Validation loss: 1.731337506283996

Epoch: 268| Step: 0
Training loss: 0.5881673097610474
Validation loss: 1.6868985378614036

Epoch: 5| Step: 1
Training loss: 0.9943881034851074
Validation loss: 1.7102669580008394

Epoch: 5| Step: 2
Training loss: 0.7054492235183716
Validation loss: 1.6904354351823048

Epoch: 5| Step: 3
Training loss: 0.660692036151886
Validation loss: 1.6890274299088346

Epoch: 5| Step: 4
Training loss: 0.8142545819282532
Validation loss: 1.6987297599033644

Epoch: 5| Step: 5
Training loss: 0.8671250343322754
Validation loss: 1.7160721504560081

Epoch: 5| Step: 6
Training loss: 0.534797191619873
Validation loss: 1.7264476027539981

Epoch: 5| Step: 7
Training loss: 0.911059558391571
Validation loss: 1.7322105335932907

Epoch: 5| Step: 8
Training loss: 0.419318288564682
Validation loss: 1.738911667177754

Epoch: 5| Step: 9
Training loss: 0.5245543718338013
Validation loss: 1.7314303921115013

Epoch: 5| Step: 10
Training loss: 0.6972655057907104
Validation loss: 1.721451800356629

Epoch: 269| Step: 0
Training loss: 0.9198554754257202
Validation loss: 1.7229776561901133

Epoch: 5| Step: 1
Training loss: 0.7365262508392334
Validation loss: 1.7276606303389355

Epoch: 5| Step: 2
Training loss: 0.44484061002731323
Validation loss: 1.7469952132112236

Epoch: 5| Step: 3
Training loss: 0.6022742390632629
Validation loss: 1.7613512213512132

Epoch: 5| Step: 4
Training loss: 0.4243626594543457
Validation loss: 1.793443460618296

Epoch: 5| Step: 5
Training loss: 0.7168498635292053
Validation loss: 1.8128441738825973

Epoch: 5| Step: 6
Training loss: 0.7598403692245483
Validation loss: 1.8127828695440804

Epoch: 5| Step: 7
Training loss: 0.6387157440185547
Validation loss: 1.8024352942743609

Epoch: 5| Step: 8
Training loss: 0.8237488865852356
Validation loss: 1.7811709539864653

Epoch: 5| Step: 9
Training loss: 0.9425738453865051
Validation loss: 1.7488391040473856

Epoch: 5| Step: 10
Training loss: 0.495185524225235
Validation loss: 1.7501264374743226

Epoch: 270| Step: 0
Training loss: 0.9154385328292847
Validation loss: 1.736772197549061

Epoch: 5| Step: 1
Training loss: 0.6923332214355469
Validation loss: 1.7239613584292832

Epoch: 5| Step: 2
Training loss: 0.49856728315353394
Validation loss: 1.7326269995781682

Epoch: 5| Step: 3
Training loss: 0.36379748582839966
Validation loss: 1.7365633556919713

Epoch: 5| Step: 4
Training loss: 0.8499671816825867
Validation loss: 1.7277402595807148

Epoch: 5| Step: 5
Training loss: 0.657092809677124
Validation loss: 1.7430372955978557

Epoch: 5| Step: 6
Training loss: 0.3824493885040283
Validation loss: 1.7261865280007804

Epoch: 5| Step: 7
Training loss: 0.8374018669128418
Validation loss: 1.7055461675890031

Epoch: 5| Step: 8
Training loss: 0.6501332521438599
Validation loss: 1.7061820453213108

Epoch: 5| Step: 9
Training loss: 0.8789024353027344
Validation loss: 1.6928638822288924

Epoch: 5| Step: 10
Training loss: 0.6579676270484924
Validation loss: 1.6818586562269477

Epoch: 271| Step: 0
Training loss: 0.7449685335159302
Validation loss: 1.6868907431120514

Epoch: 5| Step: 1
Training loss: 0.7808270454406738
Validation loss: 1.688948513359152

Epoch: 5| Step: 2
Training loss: 0.42809373140335083
Validation loss: 1.7082285201677712

Epoch: 5| Step: 3
Training loss: 0.7488225698471069
Validation loss: 1.7102602784351637

Epoch: 5| Step: 4
Training loss: 0.44417232275009155
Validation loss: 1.7147033099205262

Epoch: 5| Step: 5
Training loss: 0.7557685971260071
Validation loss: 1.7248424817157049

Epoch: 5| Step: 6
Training loss: 0.5742641091346741
Validation loss: 1.7091293437506563

Epoch: 5| Step: 7
Training loss: 0.8157738447189331
Validation loss: 1.728919139472387

Epoch: 5| Step: 8
Training loss: 0.9032405018806458
Validation loss: 1.7563046678420036

Epoch: 5| Step: 9
Training loss: 0.6847074627876282
Validation loss: 1.7530155028066328

Epoch: 5| Step: 10
Training loss: 0.46946313977241516
Validation loss: 1.7371355179817445

Epoch: 272| Step: 0
Training loss: 0.7254303097724915
Validation loss: 1.743166095467024

Epoch: 5| Step: 1
Training loss: 0.789696991443634
Validation loss: 1.7305169989985805

Epoch: 5| Step: 2
Training loss: 0.5471757054328918
Validation loss: 1.7481485720603698

Epoch: 5| Step: 3
Training loss: 0.567198634147644
Validation loss: 1.7150484567047448

Epoch: 5| Step: 4
Training loss: 0.3701196312904358
Validation loss: 1.7321748169519569

Epoch: 5| Step: 5
Training loss: 1.0538464784622192
Validation loss: 1.711229988323745

Epoch: 5| Step: 6
Training loss: 0.7437053918838501
Validation loss: 1.7234491167529937

Epoch: 5| Step: 7
Training loss: 0.5554447174072266
Validation loss: 1.735673048162973

Epoch: 5| Step: 8
Training loss: 0.5548834800720215
Validation loss: 1.739469692271243

Epoch: 5| Step: 9
Training loss: 0.8555921316146851
Validation loss: 1.7599800889210035

Epoch: 5| Step: 10
Training loss: 0.47938504815101624
Validation loss: 1.7444757671766384

Epoch: 273| Step: 0
Training loss: 0.4366587698459625
Validation loss: 1.7537367164447744

Epoch: 5| Step: 1
Training loss: 0.5556139945983887
Validation loss: 1.7603110497997654

Epoch: 5| Step: 2
Training loss: 0.8297806978225708
Validation loss: 1.7126047598418368

Epoch: 5| Step: 3
Training loss: 0.597267746925354
Validation loss: 1.695488622111659

Epoch: 5| Step: 4
Training loss: 0.7225089073181152
Validation loss: 1.6908951754211097

Epoch: 5| Step: 5
Training loss: 0.9427193403244019
Validation loss: 1.6987938240010252

Epoch: 5| Step: 6
Training loss: 0.44361552596092224
Validation loss: 1.7384218156978648

Epoch: 5| Step: 7
Training loss: 0.5366080403327942
Validation loss: 1.760667036938411

Epoch: 5| Step: 8
Training loss: 0.4991688132286072
Validation loss: 1.7650142638914046

Epoch: 5| Step: 9
Training loss: 0.8745541572570801
Validation loss: 1.7641140850641395

Epoch: 5| Step: 10
Training loss: 0.6757495999336243
Validation loss: 1.76047682762146

Epoch: 274| Step: 0
Training loss: 0.6422477960586548
Validation loss: 1.7588675150307276

Epoch: 5| Step: 1
Training loss: 0.612994372844696
Validation loss: 1.7147698056313299

Epoch: 5| Step: 2
Training loss: 0.6556111574172974
Validation loss: 1.700302162478047

Epoch: 5| Step: 3
Training loss: 0.5587218999862671
Validation loss: 1.7132960519483011

Epoch: 5| Step: 4
Training loss: 0.9354947805404663
Validation loss: 1.6945275683556833

Epoch: 5| Step: 5
Training loss: 0.7047983407974243
Validation loss: 1.694142646687005

Epoch: 5| Step: 6
Training loss: 0.4891543984413147
Validation loss: 1.6958923878208283

Epoch: 5| Step: 7
Training loss: 0.47713273763656616
Validation loss: 1.699392968608487

Epoch: 5| Step: 8
Training loss: 0.8836857676506042
Validation loss: 1.7217227566626765

Epoch: 5| Step: 9
Training loss: 0.4486311078071594
Validation loss: 1.730143343248675

Epoch: 5| Step: 10
Training loss: 0.6705222725868225
Validation loss: 1.7317723843359178

Epoch: 275| Step: 0
Training loss: 0.781427264213562
Validation loss: 1.723604876507995

Epoch: 5| Step: 1
Training loss: 0.3239056468009949
Validation loss: 1.7044785432918097

Epoch: 5| Step: 2
Training loss: 0.7317662239074707
Validation loss: 1.6768011598176853

Epoch: 5| Step: 3
Training loss: 0.5037810206413269
Validation loss: 1.7064868839838172

Epoch: 5| Step: 4
Training loss: 0.6196379065513611
Validation loss: 1.688829465578961

Epoch: 5| Step: 5
Training loss: 0.9205416440963745
Validation loss: 1.6973499457041423

Epoch: 5| Step: 6
Training loss: 0.423729807138443
Validation loss: 1.7280285627611223

Epoch: 5| Step: 7
Training loss: 0.42181387543678284
Validation loss: 1.7334260812369726

Epoch: 5| Step: 8
Training loss: 0.8873294591903687
Validation loss: 1.7646114928748018

Epoch: 5| Step: 9
Training loss: 0.6754578351974487
Validation loss: 1.766612228526864

Epoch: 5| Step: 10
Training loss: 0.777633786201477
Validation loss: 1.733214464238895

Epoch: 276| Step: 0
Training loss: 0.17970183491706848
Validation loss: 1.700163987375075

Epoch: 5| Step: 1
Training loss: 0.6184471249580383
Validation loss: 1.7037762749579646

Epoch: 5| Step: 2
Training loss: 0.8643087148666382
Validation loss: 1.700322760048733

Epoch: 5| Step: 3
Training loss: 1.1586066484451294
Validation loss: 1.7059647331955612

Epoch: 5| Step: 4
Training loss: 0.6448235511779785
Validation loss: 1.706210018486105

Epoch: 5| Step: 5
Training loss: 0.8113042712211609
Validation loss: 1.6995016644077916

Epoch: 5| Step: 6
Training loss: 0.7199339866638184
Validation loss: 1.7241531213124592

Epoch: 5| Step: 7
Training loss: 0.935832679271698
Validation loss: 1.788097587323958

Epoch: 5| Step: 8
Training loss: 0.45233529806137085
Validation loss: 1.7879357312315254

Epoch: 5| Step: 9
Training loss: 0.3766653537750244
Validation loss: 1.7615406372213875

Epoch: 5| Step: 10
Training loss: 0.5153118371963501
Validation loss: 1.7322676194611417

Epoch: 277| Step: 0
Training loss: 0.5741134881973267
Validation loss: 1.7175523696407196

Epoch: 5| Step: 1
Training loss: 0.8262999653816223
Validation loss: 1.6925039906655588

Epoch: 5| Step: 2
Training loss: 0.8177550435066223
Validation loss: 1.6978979584991292

Epoch: 5| Step: 3
Training loss: 0.6726654171943665
Validation loss: 1.7196608448541293

Epoch: 5| Step: 4
Training loss: 0.6516562700271606
Validation loss: 1.7177639058841172

Epoch: 5| Step: 5
Training loss: 0.5066630840301514
Validation loss: 1.7366820663534186

Epoch: 5| Step: 6
Training loss: 0.58562171459198
Validation loss: 1.7280343091616066

Epoch: 5| Step: 7
Training loss: 0.4680202603340149
Validation loss: 1.7174209138398528

Epoch: 5| Step: 8
Training loss: 0.545409083366394
Validation loss: 1.7012698342723231

Epoch: 5| Step: 9
Training loss: 0.5290448069572449
Validation loss: 1.676099669548773

Epoch: 5| Step: 10
Training loss: 0.9331039190292358
Validation loss: 1.6887500843694132

Epoch: 278| Step: 0
Training loss: 0.5974087715148926
Validation loss: 1.7019289257705852

Epoch: 5| Step: 1
Training loss: 1.0811126232147217
Validation loss: 1.6880891681999288

Epoch: 5| Step: 2
Training loss: 0.46975135803222656
Validation loss: 1.7373260708265408

Epoch: 5| Step: 3
Training loss: 0.42864084243774414
Validation loss: 1.7576882685384443

Epoch: 5| Step: 4
Training loss: 0.610374927520752
Validation loss: 1.7461357667881956

Epoch: 5| Step: 5
Training loss: 0.6533541083335876
Validation loss: 1.761707510999454

Epoch: 5| Step: 6
Training loss: 0.6627050638198853
Validation loss: 1.7482559014392156

Epoch: 5| Step: 7
Training loss: 0.948863685131073
Validation loss: 1.709192305482844

Epoch: 5| Step: 8
Training loss: 0.42456865310668945
Validation loss: 1.7118843806687223

Epoch: 5| Step: 9
Training loss: 0.3888060748577118
Validation loss: 1.703610949618842

Epoch: 5| Step: 10
Training loss: 0.6943569779396057
Validation loss: 1.70094677581582

Epoch: 279| Step: 0
Training loss: 0.49837055802345276
Validation loss: 1.7294093588347077

Epoch: 5| Step: 1
Training loss: 0.6003459095954895
Validation loss: 1.7101823719598914

Epoch: 5| Step: 2
Training loss: 0.39106476306915283
Validation loss: 1.7263216433986541

Epoch: 5| Step: 3
Training loss: 0.4451964497566223
Validation loss: 1.7388249879242272

Epoch: 5| Step: 4
Training loss: 0.5419133901596069
Validation loss: 1.704788141353156

Epoch: 5| Step: 5
Training loss: 0.8563622236251831
Validation loss: 1.7078700462977092

Epoch: 5| Step: 6
Training loss: 0.6826598048210144
Validation loss: 1.7047014582541682

Epoch: 5| Step: 7
Training loss: 0.9209026098251343
Validation loss: 1.7156342921718475

Epoch: 5| Step: 8
Training loss: 0.7575719356536865
Validation loss: 1.7024634858613372

Epoch: 5| Step: 9
Training loss: 0.5265019536018372
Validation loss: 1.6793812090350735

Epoch: 5| Step: 10
Training loss: 0.6078376173973083
Validation loss: 1.6702964510968936

Epoch: 280| Step: 0
Training loss: 0.5560390949249268
Validation loss: 1.6567642022204656

Epoch: 5| Step: 1
Training loss: 0.4054810106754303
Validation loss: 1.669318135066699

Epoch: 5| Step: 2
Training loss: 0.6865726709365845
Validation loss: 1.653977991432272

Epoch: 5| Step: 3
Training loss: 0.9282299280166626
Validation loss: 1.6685702800750732

Epoch: 5| Step: 4
Training loss: 0.6681441068649292
Validation loss: 1.710977340257296

Epoch: 5| Step: 5
Training loss: 0.753445029258728
Validation loss: 1.6893174366284442

Epoch: 5| Step: 6
Training loss: 0.64261794090271
Validation loss: 1.7183966867385372

Epoch: 5| Step: 7
Training loss: 0.6111801862716675
Validation loss: 1.6684021898495254

Epoch: 5| Step: 8
Training loss: 0.47811374068260193
Validation loss: 1.6354301283436437

Epoch: 5| Step: 9
Training loss: 0.3609498143196106
Validation loss: 1.6414696990802724

Epoch: 5| Step: 10
Training loss: 0.6166785359382629
Validation loss: 1.6430849887991463

Epoch: 281| Step: 0
Training loss: 0.5390163064002991
Validation loss: 1.6537546034782165

Epoch: 5| Step: 1
Training loss: 0.648234486579895
Validation loss: 1.653295208689987

Epoch: 5| Step: 2
Training loss: 0.7876124382019043
Validation loss: 1.7107559480974752

Epoch: 5| Step: 3
Training loss: 0.9796651005744934
Validation loss: 1.7896735078545027

Epoch: 5| Step: 4
Training loss: 0.37009677290916443
Validation loss: 1.7875300991919734

Epoch: 5| Step: 5
Training loss: 0.5622998476028442
Validation loss: 1.760733667240348

Epoch: 5| Step: 6
Training loss: 0.5472065210342407
Validation loss: 1.7548860580690446

Epoch: 5| Step: 7
Training loss: 1.0819305181503296
Validation loss: 1.7006522737523562

Epoch: 5| Step: 8
Training loss: 0.5134384036064148
Validation loss: 1.6810102232040898

Epoch: 5| Step: 9
Training loss: 0.8126174211502075
Validation loss: 1.7014099423603346

Epoch: 5| Step: 10
Training loss: 0.6096205115318298
Validation loss: 1.690716734496496

Epoch: 282| Step: 0
Training loss: 0.9856534004211426
Validation loss: 1.6981204632789857

Epoch: 5| Step: 1
Training loss: 0.8032979965209961
Validation loss: 1.7309594538904005

Epoch: 5| Step: 2
Training loss: 0.8569936752319336
Validation loss: 1.8457676236347487

Epoch: 5| Step: 3
Training loss: 0.6966818571090698
Validation loss: 1.8955364150385703

Epoch: 5| Step: 4
Training loss: 0.7392939925193787
Validation loss: 1.8608136561609083

Epoch: 5| Step: 5
Training loss: 0.5026551485061646
Validation loss: 1.7489387771134735

Epoch: 5| Step: 6
Training loss: 0.5509989857673645
Validation loss: 1.704995209170926

Epoch: 5| Step: 7
Training loss: 0.47815924882888794
Validation loss: 1.6661035565919773

Epoch: 5| Step: 8
Training loss: 0.7257277369499207
Validation loss: 1.6624281675584855

Epoch: 5| Step: 9
Training loss: 0.6395236849784851
Validation loss: 1.650278168339883

Epoch: 5| Step: 10
Training loss: 0.47445061802864075
Validation loss: 1.6647607164998208

Epoch: 283| Step: 0
Training loss: 0.76513671875
Validation loss: 1.6580030828393915

Epoch: 5| Step: 1
Training loss: 0.5785152912139893
Validation loss: 1.683971151228874

Epoch: 5| Step: 2
Training loss: 0.4693726897239685
Validation loss: 1.6837304779278335

Epoch: 5| Step: 3
Training loss: 0.7402427792549133
Validation loss: 1.7238648809412473

Epoch: 5| Step: 4
Training loss: 0.6794365644454956
Validation loss: 1.7508874657333537

Epoch: 5| Step: 5
Training loss: 0.6478413343429565
Validation loss: 1.738964121828797

Epoch: 5| Step: 6
Training loss: 0.46561622619628906
Validation loss: 1.7298733072896157

Epoch: 5| Step: 7
Training loss: 0.45293086767196655
Validation loss: 1.7136130973856936

Epoch: 5| Step: 8
Training loss: 0.6880905628204346
Validation loss: 1.7129972391231085

Epoch: 5| Step: 9
Training loss: 0.651611328125
Validation loss: 1.7318178479389479

Epoch: 5| Step: 10
Training loss: 0.6401606202125549
Validation loss: 1.7207424999565206

Epoch: 284| Step: 0
Training loss: 0.47477784752845764
Validation loss: 1.7082869596378778

Epoch: 5| Step: 1
Training loss: 0.7064813375473022
Validation loss: 1.704490771857641

Epoch: 5| Step: 2
Training loss: 0.36801615357398987
Validation loss: 1.676075147044274

Epoch: 5| Step: 3
Training loss: 0.6187543272972107
Validation loss: 1.6703898637525496

Epoch: 5| Step: 4
Training loss: 0.4827847480773926
Validation loss: 1.714791746549709

Epoch: 5| Step: 5
Training loss: 0.5747044086456299
Validation loss: 1.7217988890986289

Epoch: 5| Step: 6
Training loss: 0.8745201230049133
Validation loss: 1.7309371835442

Epoch: 5| Step: 7
Training loss: 0.5146800875663757
Validation loss: 1.7210679900261663

Epoch: 5| Step: 8
Training loss: 0.6228078007698059
Validation loss: 1.7105993211910289

Epoch: 5| Step: 9
Training loss: 0.588985025882721
Validation loss: 1.7097384416928856

Epoch: 5| Step: 10
Training loss: 0.5207338333129883
Validation loss: 1.7148117429466658

Epoch: 285| Step: 0
Training loss: 0.506020188331604
Validation loss: 1.7008210036062426

Epoch: 5| Step: 1
Training loss: 0.5278233289718628
Validation loss: 1.6771257410767257

Epoch: 5| Step: 2
Training loss: 0.6147605180740356
Validation loss: 1.6649075797809068

Epoch: 5| Step: 3
Training loss: 0.5775840282440186
Validation loss: 1.665011611036075

Epoch: 5| Step: 4
Training loss: 0.6932903528213501
Validation loss: 1.6795271622237338

Epoch: 5| Step: 5
Training loss: 0.7374664545059204
Validation loss: 1.6820356128036336

Epoch: 5| Step: 6
Training loss: 0.8188763856887817
Validation loss: 1.6622397630445418

Epoch: 5| Step: 7
Training loss: 0.4719052314758301
Validation loss: 1.708263881744877

Epoch: 5| Step: 8
Training loss: 0.3797532021999359
Validation loss: 1.7421002362364082

Epoch: 5| Step: 9
Training loss: 0.679556131362915
Validation loss: 1.7310863079563263

Epoch: 5| Step: 10
Training loss: 0.6792888641357422
Validation loss: 1.688974859893963

Epoch: 286| Step: 0
Training loss: 0.4980900287628174
Validation loss: 1.6684617688578944

Epoch: 5| Step: 1
Training loss: 0.6408002972602844
Validation loss: 1.6631282721796343

Epoch: 5| Step: 2
Training loss: 0.4487680494785309
Validation loss: 1.6457055807113647

Epoch: 5| Step: 3
Training loss: 0.7485127449035645
Validation loss: 1.673645233595243

Epoch: 5| Step: 4
Training loss: 0.5613994598388672
Validation loss: 1.6886988250158166

Epoch: 5| Step: 5
Training loss: 0.6838070750236511
Validation loss: 1.6772178552484

Epoch: 5| Step: 6
Training loss: 0.37001460790634155
Validation loss: 1.673158541802437

Epoch: 5| Step: 7
Training loss: 0.4984745979309082
Validation loss: 1.702713237013868

Epoch: 5| Step: 8
Training loss: 0.6986758708953857
Validation loss: 1.7300858061800721

Epoch: 5| Step: 9
Training loss: 0.5443325042724609
Validation loss: 1.7095707872862458

Epoch: 5| Step: 10
Training loss: 0.4599931240081787
Validation loss: 1.694120232776929

Epoch: 287| Step: 0
Training loss: 0.5327216386795044
Validation loss: 1.6653564155742686

Epoch: 5| Step: 1
Training loss: 0.652077317237854
Validation loss: 1.6514877747463923

Epoch: 5| Step: 2
Training loss: 0.22064490616321564
Validation loss: 1.6540529369026102

Epoch: 5| Step: 3
Training loss: 0.5266560316085815
Validation loss: 1.6514190653319

Epoch: 5| Step: 4
Training loss: 0.6696603298187256
Validation loss: 1.6573205929930492

Epoch: 5| Step: 5
Training loss: 0.5085011720657349
Validation loss: 1.66969499985377

Epoch: 5| Step: 6
Training loss: 0.8430362939834595
Validation loss: 1.6980590922858125

Epoch: 5| Step: 7
Training loss: 0.46688738465309143
Validation loss: 1.721161106581329

Epoch: 5| Step: 8
Training loss: 0.5119094252586365
Validation loss: 1.7481610723721084

Epoch: 5| Step: 9
Training loss: 0.7637457847595215
Validation loss: 1.751744879189358

Epoch: 5| Step: 10
Training loss: 0.5453181862831116
Validation loss: 1.7302582994584115

Epoch: 288| Step: 0
Training loss: 0.5200722813606262
Validation loss: 1.7107417301465107

Epoch: 5| Step: 1
Training loss: 0.6866547465324402
Validation loss: 1.68534174401273

Epoch: 5| Step: 2
Training loss: 0.5824394226074219
Validation loss: 1.6674130373103644

Epoch: 5| Step: 3
Training loss: 0.40609583258628845
Validation loss: 1.670033061376182

Epoch: 5| Step: 4
Training loss: 0.45154738426208496
Validation loss: 1.6705800294876099

Epoch: 5| Step: 5
Training loss: 0.5263787508010864
Validation loss: 1.6893740546318792

Epoch: 5| Step: 6
Training loss: 0.5699899196624756
Validation loss: 1.696469714564662

Epoch: 5| Step: 7
Training loss: 0.5979651212692261
Validation loss: 1.7087657246538388

Epoch: 5| Step: 8
Training loss: 0.6282200813293457
Validation loss: 1.7166872383445821

Epoch: 5| Step: 9
Training loss: 0.5220664739608765
Validation loss: 1.686769438046281

Epoch: 5| Step: 10
Training loss: 0.3918922543525696
Validation loss: 1.6643918227123957

Epoch: 289| Step: 0
Training loss: 0.6529539227485657
Validation loss: 1.6675717241020613

Epoch: 5| Step: 1
Training loss: 0.5121249556541443
Validation loss: 1.6551833665499123

Epoch: 5| Step: 2
Training loss: 0.435944139957428
Validation loss: 1.6268511023572696

Epoch: 5| Step: 3
Training loss: 0.65223228931427
Validation loss: 1.635994416411205

Epoch: 5| Step: 4
Training loss: 0.33108606934547424
Validation loss: 1.6161635280937277

Epoch: 5| Step: 5
Training loss: 0.7221741676330566
Validation loss: 1.6503150975832375

Epoch: 5| Step: 6
Training loss: 0.3259742856025696
Validation loss: 1.6767171352140364

Epoch: 5| Step: 7
Training loss: 0.36809176206588745
Validation loss: 1.7125185497345463

Epoch: 5| Step: 8
Training loss: 1.0237518548965454
Validation loss: 1.7076754659734747

Epoch: 5| Step: 9
Training loss: 0.4274512231349945
Validation loss: 1.6917363430864067

Epoch: 5| Step: 10
Training loss: 0.4525688886642456
Validation loss: 1.6818480466001777

Epoch: 290| Step: 0
Training loss: 0.5874643325805664
Validation loss: 1.7070845070705618

Epoch: 5| Step: 1
Training loss: 0.7540073394775391
Validation loss: 1.6891233549323132

Epoch: 5| Step: 2
Training loss: 0.4808560013771057
Validation loss: 1.6692051708057363

Epoch: 5| Step: 3
Training loss: 0.3113192617893219
Validation loss: 1.6946997770699121

Epoch: 5| Step: 4
Training loss: 0.6653461456298828
Validation loss: 1.6975608474464827

Epoch: 5| Step: 5
Training loss: 0.3653992712497711
Validation loss: 1.7033553777202484

Epoch: 5| Step: 6
Training loss: 0.7300098538398743
Validation loss: 1.728874647489158

Epoch: 5| Step: 7
Training loss: 0.6505331993103027
Validation loss: 1.7151950085034935

Epoch: 5| Step: 8
Training loss: 0.4449232220649719
Validation loss: 1.7228188501891268

Epoch: 5| Step: 9
Training loss: 0.6783364415168762
Validation loss: 1.693184071971524

Epoch: 5| Step: 10
Training loss: 0.31423890590667725
Validation loss: 1.7032761932701193

Epoch: 291| Step: 0
Training loss: 0.6997772455215454
Validation loss: 1.6797212900653962

Epoch: 5| Step: 1
Training loss: 0.5952195525169373
Validation loss: 1.6763949797999473

Epoch: 5| Step: 2
Training loss: 0.6433712840080261
Validation loss: 1.686001241848033

Epoch: 5| Step: 3
Training loss: 0.7339868545532227
Validation loss: 1.697494585026977

Epoch: 5| Step: 4
Training loss: 0.47699394822120667
Validation loss: 1.6887492531089372

Epoch: 5| Step: 5
Training loss: 0.25612014532089233
Validation loss: 1.6960640645796252

Epoch: 5| Step: 6
Training loss: 0.401423841714859
Validation loss: 1.6826439313991095

Epoch: 5| Step: 7
Training loss: 0.45237693190574646
Validation loss: 1.668619507102556

Epoch: 5| Step: 8
Training loss: 0.37029820680618286
Validation loss: 1.6714913434879755

Epoch: 5| Step: 9
Training loss: 0.728001058101654
Validation loss: 1.6737192266730851

Epoch: 5| Step: 10
Training loss: 0.4977899491786957
Validation loss: 1.6610267469959874

Epoch: 292| Step: 0
Training loss: 0.4488571286201477
Validation loss: 1.6719956590283302

Epoch: 5| Step: 1
Training loss: 0.7197429537773132
Validation loss: 1.685400305255767

Epoch: 5| Step: 2
Training loss: 0.5108726024627686
Validation loss: 1.657888945712838

Epoch: 5| Step: 3
Training loss: 0.8066533207893372
Validation loss: 1.6502103651723554

Epoch: 5| Step: 4
Training loss: 0.2560540437698364
Validation loss: 1.6727282475399714

Epoch: 5| Step: 5
Training loss: 0.3221372663974762
Validation loss: 1.6718753742915329

Epoch: 5| Step: 6
Training loss: 0.5190003514289856
Validation loss: 1.6789725057540401

Epoch: 5| Step: 7
Training loss: 0.42662912607192993
Validation loss: 1.6780058530069166

Epoch: 5| Step: 8
Training loss: 0.7004966139793396
Validation loss: 1.692732375155213

Epoch: 5| Step: 9
Training loss: 0.504086434841156
Validation loss: 1.677899706107314

Epoch: 5| Step: 10
Training loss: 0.5475009083747864
Validation loss: 1.6822105325678343

Epoch: 293| Step: 0
Training loss: 0.4049608111381531
Validation loss: 1.7025611990241594

Epoch: 5| Step: 1
Training loss: 0.5374987721443176
Validation loss: 1.6654298561875538

Epoch: 5| Step: 2
Training loss: 0.6576975584030151
Validation loss: 1.665476966929692

Epoch: 5| Step: 3
Training loss: 0.2651073634624481
Validation loss: 1.640614478818832

Epoch: 5| Step: 4
Training loss: 0.3559334874153137
Validation loss: 1.6556860528966433

Epoch: 5| Step: 5
Training loss: 0.5788533091545105
Validation loss: 1.643701550781086

Epoch: 5| Step: 6
Training loss: 0.576805591583252
Validation loss: 1.6557214849738664

Epoch: 5| Step: 7
Training loss: 0.8691293597221375
Validation loss: 1.6658418332376788

Epoch: 5| Step: 8
Training loss: 0.2913473844528198
Validation loss: 1.7017138055575791

Epoch: 5| Step: 9
Training loss: 0.4114592969417572
Validation loss: 1.7166661511185348

Epoch: 5| Step: 10
Training loss: 0.6454628109931946
Validation loss: 1.7101497406600623

Epoch: 294| Step: 0
Training loss: 0.31596189737319946
Validation loss: 1.703211163961759

Epoch: 5| Step: 1
Training loss: 0.6166862845420837
Validation loss: 1.7194396936765282

Epoch: 5| Step: 2
Training loss: 0.847358226776123
Validation loss: 1.6960033152693061

Epoch: 5| Step: 3
Training loss: 0.4337785243988037
Validation loss: 1.678630308438373

Epoch: 5| Step: 4
Training loss: 0.6029024124145508
Validation loss: 1.6290545104652323

Epoch: 5| Step: 5
Training loss: 0.2956477403640747
Validation loss: 1.6310310389405938

Epoch: 5| Step: 6
Training loss: 0.5123273730278015
Validation loss: 1.587484391786719

Epoch: 5| Step: 7
Training loss: 0.6925910711288452
Validation loss: 1.5994821645880257

Epoch: 5| Step: 8
Training loss: 0.5270306468009949
Validation loss: 1.6315542254396664

Epoch: 5| Step: 9
Training loss: 0.440896213054657
Validation loss: 1.6120605596932032

Epoch: 5| Step: 10
Training loss: 0.5831162929534912
Validation loss: 1.6282619314809

Epoch: 295| Step: 0
Training loss: 0.4182218909263611
Validation loss: 1.6629544560627272

Epoch: 5| Step: 1
Training loss: 0.4108700752258301
Validation loss: 1.6667998913795716

Epoch: 5| Step: 2
Training loss: 0.6023991703987122
Validation loss: 1.6917672759743148

Epoch: 5| Step: 3
Training loss: 0.43047088384628296
Validation loss: 1.6740980443134104

Epoch: 5| Step: 4
Training loss: 0.4258298873901367
Validation loss: 1.6609730899974864

Epoch: 5| Step: 5
Training loss: 0.7011541128158569
Validation loss: 1.6786803648036013

Epoch: 5| Step: 6
Training loss: 0.5750316977500916
Validation loss: 1.6475777177400486

Epoch: 5| Step: 7
Training loss: 0.3583570718765259
Validation loss: 1.6284471032440022

Epoch: 5| Step: 8
Training loss: 0.44277676939964294
Validation loss: 1.6321055017491823

Epoch: 5| Step: 9
Training loss: 0.678504467010498
Validation loss: 1.6446324574050082

Epoch: 5| Step: 10
Training loss: 0.5878227949142456
Validation loss: 1.644947826221425

Epoch: 296| Step: 0
Training loss: 0.5137572884559631
Validation loss: 1.6276068687438965

Epoch: 5| Step: 1
Training loss: 0.38766416907310486
Validation loss: 1.6406800541826474

Epoch: 5| Step: 2
Training loss: 0.7367438077926636
Validation loss: 1.6749891850256151

Epoch: 5| Step: 3
Training loss: 0.599254310131073
Validation loss: 1.7007743350921138

Epoch: 5| Step: 4
Training loss: 0.6689872741699219
Validation loss: 1.7073692429450251

Epoch: 5| Step: 5
Training loss: 0.3900919258594513
Validation loss: 1.7419952423341813

Epoch: 5| Step: 6
Training loss: 0.5707722306251526
Validation loss: 1.6909183404778922

Epoch: 5| Step: 7
Training loss: 0.46363043785095215
Validation loss: 1.6438607003099175

Epoch: 5| Step: 8
Training loss: 0.29091745615005493
Validation loss: 1.6154223962496685

Epoch: 5| Step: 9
Training loss: 0.6009119749069214
Validation loss: 1.595613116859108

Epoch: 5| Step: 10
Training loss: 0.422988623380661
Validation loss: 1.6065349924948908

Epoch: 297| Step: 0
Training loss: 0.32324400544166565
Validation loss: 1.6286007729909753

Epoch: 5| Step: 1
Training loss: 0.4895353317260742
Validation loss: 1.6435813839717577

Epoch: 5| Step: 2
Training loss: 0.32319575548171997
Validation loss: 1.668596516373337

Epoch: 5| Step: 3
Training loss: 0.8066425323486328
Validation loss: 1.702441248842465

Epoch: 5| Step: 4
Training loss: 0.8521732091903687
Validation loss: 1.6992578814106603

Epoch: 5| Step: 5
Training loss: 0.33622828125953674
Validation loss: 1.6747816301161242

Epoch: 5| Step: 6
Training loss: 0.5494003891944885
Validation loss: 1.6549507148804203

Epoch: 5| Step: 7
Training loss: 0.4061281681060791
Validation loss: 1.6572582875528643

Epoch: 5| Step: 8
Training loss: 0.5242200493812561
Validation loss: 1.6334380449787262

Epoch: 5| Step: 9
Training loss: 0.3942157030105591
Validation loss: 1.62881677509636

Epoch: 5| Step: 10
Training loss: 0.5681210160255432
Validation loss: 1.6443949207182853

Epoch: 298| Step: 0
Training loss: 0.408669650554657
Validation loss: 1.7155976962017756

Epoch: 5| Step: 1
Training loss: 0.5380250215530396
Validation loss: 1.7399356711295344

Epoch: 5| Step: 2
Training loss: 0.7545489072799683
Validation loss: 1.7794739584768973

Epoch: 5| Step: 3
Training loss: 0.8915027379989624
Validation loss: 1.705000582561698

Epoch: 5| Step: 4
Training loss: 0.4629708230495453
Validation loss: 1.6597554696503507

Epoch: 5| Step: 5
Training loss: 0.43966540694236755
Validation loss: 1.6289305686950684

Epoch: 5| Step: 6
Training loss: 0.43933477997779846
Validation loss: 1.6185146685569518

Epoch: 5| Step: 7
Training loss: 0.617592990398407
Validation loss: 1.6153291194669661

Epoch: 5| Step: 8
Training loss: 0.4925619661808014
Validation loss: 1.618913524894304

Epoch: 5| Step: 9
Training loss: 0.43711644411087036
Validation loss: 1.608363966788015

Epoch: 5| Step: 10
Training loss: 0.5685425996780396
Validation loss: 1.6531309408526267

Epoch: 299| Step: 0
Training loss: 0.39652562141418457
Validation loss: 1.6928101316575082

Epoch: 5| Step: 1
Training loss: 0.6805791854858398
Validation loss: 1.7578506931181876

Epoch: 5| Step: 2
Training loss: 0.5612000823020935
Validation loss: 1.777015560416765

Epoch: 5| Step: 3
Training loss: 0.6315024495124817
Validation loss: 1.7717529150747484

Epoch: 5| Step: 4
Training loss: 0.8296126127243042
Validation loss: 1.7244240840276082

Epoch: 5| Step: 5
Training loss: 0.5997630953788757
Validation loss: 1.6476113950052569

Epoch: 5| Step: 6
Training loss: 0.48917239904403687
Validation loss: 1.6132650477911836

Epoch: 5| Step: 7
Training loss: 0.5282300710678101
Validation loss: 1.6295353693346823

Epoch: 5| Step: 8
Training loss: 0.3891668915748596
Validation loss: 1.6379879136239328

Epoch: 5| Step: 9
Training loss: 0.5444191694259644
Validation loss: 1.6251616939421623

Epoch: 5| Step: 10
Training loss: 0.5595313906669617
Validation loss: 1.6682833266514603

Epoch: 300| Step: 0
Training loss: 0.45607852935791016
Validation loss: 1.7103823372112807

Epoch: 5| Step: 1
Training loss: 0.5540246963500977
Validation loss: 1.730757897899997

Epoch: 5| Step: 2
Training loss: 0.5546983480453491
Validation loss: 1.742997259222051

Epoch: 5| Step: 3
Training loss: 0.3820720613002777
Validation loss: 1.692690686513019

Epoch: 5| Step: 4
Training loss: 0.3714604377746582
Validation loss: 1.6581548003740207

Epoch: 5| Step: 5
Training loss: 0.7935683727264404
Validation loss: 1.6085495512972596

Epoch: 5| Step: 6
Training loss: 0.43316611647605896
Validation loss: 1.6069056039215417

Epoch: 5| Step: 7
Training loss: 0.4710177779197693
Validation loss: 1.6031632590037521

Epoch: 5| Step: 8
Training loss: 0.5636491775512695
Validation loss: 1.5978954094712452

Epoch: 5| Step: 9
Training loss: 0.7465283274650574
Validation loss: 1.6075699778013333

Epoch: 5| Step: 10
Training loss: 0.48130327463150024
Validation loss: 1.6072222994219871

Epoch: 301| Step: 0
Training loss: 0.4350205361843109
Validation loss: 1.639391835017871

Epoch: 5| Step: 1
Training loss: 0.5807878375053406
Validation loss: 1.6339518588076356

Epoch: 5| Step: 2
Training loss: 0.7467390894889832
Validation loss: 1.630322855005982

Epoch: 5| Step: 3
Training loss: 0.5152074098587036
Validation loss: 1.6384803492535827

Epoch: 5| Step: 4
Training loss: 0.46039000153541565
Validation loss: 1.6308124693491126

Epoch: 5| Step: 5
Training loss: 0.7734065055847168
Validation loss: 1.613869567071238

Epoch: 5| Step: 6
Training loss: 0.27900952100753784
Validation loss: 1.617011688088858

Epoch: 5| Step: 7
Training loss: 0.23891505599021912
Validation loss: 1.6046974902511926

Epoch: 5| Step: 8
Training loss: 0.45223531126976013
Validation loss: 1.6099026510792394

Epoch: 5| Step: 9
Training loss: 0.40501803159713745
Validation loss: 1.6180590685977732

Epoch: 5| Step: 10
Training loss: 0.5732999444007874
Validation loss: 1.6286364293867541

Epoch: 302| Step: 0
Training loss: 0.43081340193748474
Validation loss: 1.6543897018637708

Epoch: 5| Step: 1
Training loss: 0.4008735120296478
Validation loss: 1.6519932285431893

Epoch: 5| Step: 2
Training loss: 0.6603331565856934
Validation loss: 1.6359779527110438

Epoch: 5| Step: 3
Training loss: 0.7040159106254578
Validation loss: 1.6031528121681624

Epoch: 5| Step: 4
Training loss: 0.4058956205844879
Validation loss: 1.6213128284741474

Epoch: 5| Step: 5
Training loss: 0.3220725953578949
Validation loss: 1.6114640498674044

Epoch: 5| Step: 6
Training loss: 0.6310296058654785
Validation loss: 1.612109245792512

Epoch: 5| Step: 7
Training loss: 0.6523884534835815
Validation loss: 1.6140866779511975

Epoch: 5| Step: 8
Training loss: 0.5763438940048218
Validation loss: 1.5945987239960702

Epoch: 5| Step: 9
Training loss: 0.25760093331336975
Validation loss: 1.6441080480493524

Epoch: 5| Step: 10
Training loss: 0.5448260307312012
Validation loss: 1.6670383458496423

Epoch: 303| Step: 0
Training loss: 0.4447394013404846
Validation loss: 1.7066470448688795

Epoch: 5| Step: 1
Training loss: 0.693988561630249
Validation loss: 1.7005447123640327

Epoch: 5| Step: 2
Training loss: 0.45249947905540466
Validation loss: 1.6844773779633224

Epoch: 5| Step: 3
Training loss: 0.6492277979850769
Validation loss: 1.6704548802427066

Epoch: 5| Step: 4
Training loss: 0.38700875639915466
Validation loss: 1.6326054091094642

Epoch: 5| Step: 5
Training loss: 0.6963518857955933
Validation loss: 1.618037930098913

Epoch: 5| Step: 6
Training loss: 0.5974587202072144
Validation loss: 1.6395761787250478

Epoch: 5| Step: 7
Training loss: 0.6975898742675781
Validation loss: 1.6359987258911133

Epoch: 5| Step: 8
Training loss: 0.26007920503616333
Validation loss: 1.6500130725163284

Epoch: 5| Step: 9
Training loss: 0.3213861286640167
Validation loss: 1.6376374908672866

Epoch: 5| Step: 10
Training loss: 0.5753265619277954
Validation loss: 1.6365402680571361

Epoch: 304| Step: 0
Training loss: 0.6572392582893372
Validation loss: 1.6111705521101594

Epoch: 5| Step: 1
Training loss: 0.44292593002319336
Validation loss: 1.609746330527849

Epoch: 5| Step: 2
Training loss: 0.3317334055900574
Validation loss: 1.6538685367953392

Epoch: 5| Step: 3
Training loss: 0.5513079166412354
Validation loss: 1.64659514991186

Epoch: 5| Step: 4
Training loss: 0.396616131067276
Validation loss: 1.6698180616542857

Epoch: 5| Step: 5
Training loss: 0.3546716570854187
Validation loss: 1.6417002549735449

Epoch: 5| Step: 6
Training loss: 0.4714762568473816
Validation loss: 1.6559572886395197

Epoch: 5| Step: 7
Training loss: 0.44188252091407776
Validation loss: 1.6460787942332606

Epoch: 5| Step: 8
Training loss: 0.44305428862571716
Validation loss: 1.6454000357658631

Epoch: 5| Step: 9
Training loss: 0.5987876057624817
Validation loss: 1.6566624987509944

Epoch: 5| Step: 10
Training loss: 0.46499550342559814
Validation loss: 1.6493289880855109

Epoch: 305| Step: 0
Training loss: 0.30522432923316956
Validation loss: 1.6227772415325206

Epoch: 5| Step: 1
Training loss: 0.5685534477233887
Validation loss: 1.6283406429393317

Epoch: 5| Step: 2
Training loss: 0.5227102637290955
Validation loss: 1.646086194181955

Epoch: 5| Step: 3
Training loss: 0.49314913153648376
Validation loss: 1.6308363573525542

Epoch: 5| Step: 4
Training loss: 0.5848454236984253
Validation loss: 1.6504921477328065

Epoch: 5| Step: 5
Training loss: 0.526106059551239
Validation loss: 1.6497705495485695

Epoch: 5| Step: 6
Training loss: 0.43576231598854065
Validation loss: 1.6507080472925657

Epoch: 5| Step: 7
Training loss: 0.33755427598953247
Validation loss: 1.6204415245722699

Epoch: 5| Step: 8
Training loss: 0.5393683910369873
Validation loss: 1.6190420043083928

Epoch: 5| Step: 9
Training loss: 0.19622020423412323
Validation loss: 1.624170616108884

Epoch: 5| Step: 10
Training loss: 0.5613044500350952
Validation loss: 1.6240547292975969

Epoch: 306| Step: 0
Training loss: 0.33175888657569885
Validation loss: 1.6232564346764677

Epoch: 5| Step: 1
Training loss: 0.6393186450004578
Validation loss: 1.623840792204744

Epoch: 5| Step: 2
Training loss: 0.4031088352203369
Validation loss: 1.6134849786758423

Epoch: 5| Step: 3
Training loss: 0.343572199344635
Validation loss: 1.630917388905761

Epoch: 5| Step: 4
Training loss: 0.5684722065925598
Validation loss: 1.6273735095095891

Epoch: 5| Step: 5
Training loss: 0.643397867679596
Validation loss: 1.6337646502320484

Epoch: 5| Step: 6
Training loss: 0.23062483966350555
Validation loss: 1.6398928575618292

Epoch: 5| Step: 7
Training loss: 0.5052580833435059
Validation loss: 1.644074091347315

Epoch: 5| Step: 8
Training loss: 0.42881378531455994
Validation loss: 1.6485612943608274

Epoch: 5| Step: 9
Training loss: 0.4406425952911377
Validation loss: 1.665074045940112

Epoch: 5| Step: 10
Training loss: 0.35567498207092285
Validation loss: 1.6760768095652263

Epoch: 307| Step: 0
Training loss: 0.5194080471992493
Validation loss: 1.696311709701374

Epoch: 5| Step: 1
Training loss: 0.5936471819877625
Validation loss: 1.6907854881337894

Epoch: 5| Step: 2
Training loss: 0.6213441491127014
Validation loss: 1.6950594173964633

Epoch: 5| Step: 3
Training loss: 0.235438272356987
Validation loss: 1.7070793015982515

Epoch: 5| Step: 4
Training loss: 0.6753703355789185
Validation loss: 1.7083203126025457

Epoch: 5| Step: 5
Training loss: 0.5023277997970581
Validation loss: 1.6675731392316921

Epoch: 5| Step: 6
Training loss: 0.3393717408180237
Validation loss: 1.660830488768957

Epoch: 5| Step: 7
Training loss: 0.41532835364341736
Validation loss: 1.6575042970718876

Epoch: 5| Step: 8
Training loss: 0.336770623922348
Validation loss: 1.6647559135190901

Epoch: 5| Step: 9
Training loss: 0.45326194167137146
Validation loss: 1.6351360441536031

Epoch: 5| Step: 10
Training loss: 0.4180886745452881
Validation loss: 1.6481005671203777

Epoch: 308| Step: 0
Training loss: 0.5844215750694275
Validation loss: 1.6872198088194734

Epoch: 5| Step: 1
Training loss: 0.5303042531013489
Validation loss: 1.6973557062046503

Epoch: 5| Step: 2
Training loss: 0.2707282304763794
Validation loss: 1.721501006874987

Epoch: 5| Step: 3
Training loss: 0.385741651058197
Validation loss: 1.6697807453011955

Epoch: 5| Step: 4
Training loss: 0.5569442510604858
Validation loss: 1.6577666433908607

Epoch: 5| Step: 5
Training loss: 0.35576334595680237
Validation loss: 1.6382160699495705

Epoch: 5| Step: 6
Training loss: 0.4507075250148773
Validation loss: 1.6360953866794545

Epoch: 5| Step: 7
Training loss: 0.40498724579811096
Validation loss: 1.6382145010015017

Epoch: 5| Step: 8
Training loss: 0.5870620012283325
Validation loss: 1.6671928667253064

Epoch: 5| Step: 9
Training loss: 0.580886960029602
Validation loss: 1.698986477749322

Epoch: 5| Step: 10
Training loss: 0.5092312693595886
Validation loss: 1.6281701621188913

Epoch: 309| Step: 0
Training loss: 0.40638357400894165
Validation loss: 1.651807209496857

Epoch: 5| Step: 1
Training loss: 0.47285228967666626
Validation loss: 1.637733777364095

Epoch: 5| Step: 2
Training loss: 0.4243294596672058
Validation loss: 1.6173237113542454

Epoch: 5| Step: 3
Training loss: 0.4108528196811676
Validation loss: 1.6262456922120945

Epoch: 5| Step: 4
Training loss: 0.3947204053401947
Validation loss: 1.636343030519383

Epoch: 5| Step: 5
Training loss: 0.4226049482822418
Validation loss: 1.6336850158629879

Epoch: 5| Step: 6
Training loss: 0.46472373604774475
Validation loss: 1.6494534246383175

Epoch: 5| Step: 7
Training loss: 0.701123833656311
Validation loss: 1.6529536477981075

Epoch: 5| Step: 8
Training loss: 0.2136579006910324
Validation loss: 1.634702185148834

Epoch: 5| Step: 9
Training loss: 0.6118236780166626
Validation loss: 1.6665121791183308

Epoch: 5| Step: 10
Training loss: 0.6363568305969238
Validation loss: 1.6398064295450847

Epoch: 310| Step: 0
Training loss: 0.5401178598403931
Validation loss: 1.6532960361050022

Epoch: 5| Step: 1
Training loss: 0.6136122941970825
Validation loss: 1.6428190098013928

Epoch: 5| Step: 2
Training loss: 0.5904203057289124
Validation loss: 1.6439822412306262

Epoch: 5| Step: 3
Training loss: 0.5756250619888306
Validation loss: 1.6559803408961142

Epoch: 5| Step: 4
Training loss: 0.4199341833591461
Validation loss: 1.6535039691514866

Epoch: 5| Step: 5
Training loss: 0.37964293360710144
Validation loss: 1.6626742245048605

Epoch: 5| Step: 6
Training loss: 0.5114454030990601
Validation loss: 1.6473340001157535

Epoch: 5| Step: 7
Training loss: 0.5438323020935059
Validation loss: 1.6387201163076586

Epoch: 5| Step: 8
Training loss: 0.48585277795791626
Validation loss: 1.6214157971002723

Epoch: 5| Step: 9
Training loss: 0.1960878223180771
Validation loss: 1.608244913880543

Epoch: 5| Step: 10
Training loss: 0.3853459060192108
Validation loss: 1.6291598658407889

Epoch: 311| Step: 0
Training loss: 0.3658238351345062
Validation loss: 1.654808525116213

Epoch: 5| Step: 1
Training loss: 0.5251786112785339
Validation loss: 1.650356770843588

Epoch: 5| Step: 2
Training loss: 0.509177565574646
Validation loss: 1.64819719201775

Epoch: 5| Step: 3
Training loss: 0.3665865957736969
Validation loss: 1.6523291257119948

Epoch: 5| Step: 4
Training loss: 0.22668810188770294
Validation loss: 1.635706046576141

Epoch: 5| Step: 5
Training loss: 0.6715680956840515
Validation loss: 1.6629485750711093

Epoch: 5| Step: 6
Training loss: 0.50794917345047
Validation loss: 1.6672315212988085

Epoch: 5| Step: 7
Training loss: 0.27141880989074707
Validation loss: 1.6896481847250333

Epoch: 5| Step: 8
Training loss: 0.39194363355636597
Validation loss: 1.6772452413394887

Epoch: 5| Step: 9
Training loss: 0.44648808240890503
Validation loss: 1.675977200590154

Epoch: 5| Step: 10
Training loss: 0.4506359398365021
Validation loss: 1.6340612262807868

Epoch: 312| Step: 0
Training loss: 0.4126532971858978
Validation loss: 1.6427167538673646

Epoch: 5| Step: 1
Training loss: 0.4195646345615387
Validation loss: 1.6424478753920524

Epoch: 5| Step: 2
Training loss: 0.43801459670066833
Validation loss: 1.6369527988536383

Epoch: 5| Step: 3
Training loss: 0.5349023342132568
Validation loss: 1.6430488876117173

Epoch: 5| Step: 4
Training loss: 0.4884958863258362
Validation loss: 1.6529734352583527

Epoch: 5| Step: 5
Training loss: 0.4049784243106842
Validation loss: 1.6521123224689114

Epoch: 5| Step: 6
Training loss: 0.5506981611251831
Validation loss: 1.6330407716894662

Epoch: 5| Step: 7
Training loss: 0.2872393727302551
Validation loss: 1.6263187841702533

Epoch: 5| Step: 8
Training loss: 0.5294286608695984
Validation loss: 1.6274149622968448

Epoch: 5| Step: 9
Training loss: 0.37926042079925537
Validation loss: 1.6436855536635204

Epoch: 5| Step: 10
Training loss: 0.40984371304512024
Validation loss: 1.6321467943088983

Epoch: 313| Step: 0
Training loss: 0.6518988609313965
Validation loss: 1.6360324992928454

Epoch: 5| Step: 1
Training loss: 0.41177549958229065
Validation loss: 1.6208450896765596

Epoch: 5| Step: 2
Training loss: 0.40490278601646423
Validation loss: 1.640257304714572

Epoch: 5| Step: 3
Training loss: 0.31733235716819763
Validation loss: 1.622011394910915

Epoch: 5| Step: 4
Training loss: 0.570904016494751
Validation loss: 1.6417473746884255

Epoch: 5| Step: 5
Training loss: 0.4614082872867584
Validation loss: 1.671192817790534

Epoch: 5| Step: 6
Training loss: 0.4146595895290375
Validation loss: 1.6807208099672872

Epoch: 5| Step: 7
Training loss: 0.4695664346218109
Validation loss: 1.6858981296580324

Epoch: 5| Step: 8
Training loss: 0.3619574010372162
Validation loss: 1.6861421664555867

Epoch: 5| Step: 9
Training loss: 0.31398358941078186
Validation loss: 1.6657103941004763

Epoch: 5| Step: 10
Training loss: 0.30114272236824036
Validation loss: 1.6620191233132475

Epoch: 314| Step: 0
Training loss: 0.4440995752811432
Validation loss: 1.6722705710318782

Epoch: 5| Step: 1
Training loss: 0.7663735151290894
Validation loss: 1.6478254000345867

Epoch: 5| Step: 2
Training loss: 0.387291818857193
Validation loss: 1.6557395265948387

Epoch: 5| Step: 3
Training loss: 0.4667823314666748
Validation loss: 1.629381069573023

Epoch: 5| Step: 4
Training loss: 0.4711264669895172
Validation loss: 1.6572305861339773

Epoch: 5| Step: 5
Training loss: 0.5475842952728271
Validation loss: 1.6708369408884356

Epoch: 5| Step: 6
Training loss: 0.44361478090286255
Validation loss: 1.6839979412735149

Epoch: 5| Step: 7
Training loss: 0.28357845544815063
Validation loss: 1.6827143084618352

Epoch: 5| Step: 8
Training loss: 0.4199531078338623
Validation loss: 1.6646115895240539

Epoch: 5| Step: 9
Training loss: 0.3232721984386444
Validation loss: 1.6056192331416632

Epoch: 5| Step: 10
Training loss: 0.26943182945251465
Validation loss: 1.6269091226721322

Epoch: 315| Step: 0
Training loss: 0.3420473635196686
Validation loss: 1.599929791624828

Epoch: 5| Step: 1
Training loss: 0.26489585638046265
Validation loss: 1.611586824540169

Epoch: 5| Step: 2
Training loss: 0.4078454077243805
Validation loss: 1.595162486517301

Epoch: 5| Step: 3
Training loss: 0.5329734086990356
Validation loss: 1.6014774909583471

Epoch: 5| Step: 4
Training loss: 0.3919890820980072
Validation loss: 1.6064605257844413

Epoch: 5| Step: 5
Training loss: 0.47648659348487854
Validation loss: 1.6319068952273297

Epoch: 5| Step: 6
Training loss: 0.4739413261413574
Validation loss: 1.6403166324861589

Epoch: 5| Step: 7
Training loss: 0.45655637979507446
Validation loss: 1.6703281992225236

Epoch: 5| Step: 8
Training loss: 0.7299031019210815
Validation loss: 1.6708890084297425

Epoch: 5| Step: 9
Training loss: 0.42237386107444763
Validation loss: 1.6761256905012234

Epoch: 5| Step: 10
Training loss: 0.30859869718551636
Validation loss: 1.6429433348358318

Epoch: 316| Step: 0
Training loss: 0.17358767986297607
Validation loss: 1.6335964638699767

Epoch: 5| Step: 1
Training loss: 0.5861478447914124
Validation loss: 1.6297804745294715

Epoch: 5| Step: 2
Training loss: 0.3439677357673645
Validation loss: 1.6149465422476492

Epoch: 5| Step: 3
Training loss: 0.5769109129905701
Validation loss: 1.6199804659812682

Epoch: 5| Step: 4
Training loss: 0.25193560123443604
Validation loss: 1.6260702840743526

Epoch: 5| Step: 5
Training loss: 0.5013165473937988
Validation loss: 1.6273085301922214

Epoch: 5| Step: 6
Training loss: 0.5578064322471619
Validation loss: 1.6081713630307106

Epoch: 5| Step: 7
Training loss: 0.4468197226524353
Validation loss: 1.6430460688888386

Epoch: 5| Step: 8
Training loss: 0.4613613188266754
Validation loss: 1.6438327873906782

Epoch: 5| Step: 9
Training loss: 0.4403524398803711
Validation loss: 1.6383695820326447

Epoch: 5| Step: 10
Training loss: 0.3531733751296997
Validation loss: 1.6621548193757252

Epoch: 317| Step: 0
Training loss: 0.43877774477005005
Validation loss: 1.6718249846530218

Epoch: 5| Step: 1
Training loss: 0.33373403549194336
Validation loss: 1.6238300864414503

Epoch: 5| Step: 2
Training loss: 0.6029168367385864
Validation loss: 1.603991323901761

Epoch: 5| Step: 3
Training loss: 0.49868154525756836
Validation loss: 1.5743930916632376

Epoch: 5| Step: 4
Training loss: 0.5099037885665894
Validation loss: 1.5820967253818308

Epoch: 5| Step: 5
Training loss: 0.5265319347381592
Validation loss: 1.604244202695867

Epoch: 5| Step: 6
Training loss: 0.1708245873451233
Validation loss: 1.627258159781015

Epoch: 5| Step: 7
Training loss: 0.48782816529273987
Validation loss: 1.6419858753040273

Epoch: 5| Step: 8
Training loss: 0.36712437868118286
Validation loss: 1.6557650925010763

Epoch: 5| Step: 9
Training loss: 0.4397517740726471
Validation loss: 1.6555620470354635

Epoch: 5| Step: 10
Training loss: 0.401264488697052
Validation loss: 1.6464383858506397

Epoch: 318| Step: 0
Training loss: 0.3667635917663574
Validation loss: 1.6596204837163289

Epoch: 5| Step: 1
Training loss: 0.3731686770915985
Validation loss: 1.625119391308036

Epoch: 5| Step: 2
Training loss: 0.6412382125854492
Validation loss: 1.6240688241938108

Epoch: 5| Step: 3
Training loss: 0.615949273109436
Validation loss: 1.6065142590512511

Epoch: 5| Step: 4
Training loss: 0.5139099955558777
Validation loss: 1.6036714174414193

Epoch: 5| Step: 5
Training loss: 0.42757463455200195
Validation loss: 1.6119559708461966

Epoch: 5| Step: 6
Training loss: 0.5570880770683289
Validation loss: 1.6271160212896203

Epoch: 5| Step: 7
Training loss: 0.2973599433898926
Validation loss: 1.6271762142899215

Epoch: 5| Step: 8
Training loss: 0.2639966309070587
Validation loss: 1.6338024754678049

Epoch: 5| Step: 9
Training loss: 0.3002428412437439
Validation loss: 1.6239192101263231

Epoch: 5| Step: 10
Training loss: 0.29398924112319946
Validation loss: 1.6365236864295056

Epoch: 319| Step: 0
Training loss: 0.2872651517391205
Validation loss: 1.622423046378679

Epoch: 5| Step: 1
Training loss: 0.3502825200557709
Validation loss: 1.6146767139434814

Epoch: 5| Step: 2
Training loss: 0.4869334101676941
Validation loss: 1.6162472104513517

Epoch: 5| Step: 3
Training loss: 0.4224274754524231
Validation loss: 1.6127574097725652

Epoch: 5| Step: 4
Training loss: 0.19009625911712646
Validation loss: 1.62993840120172

Epoch: 5| Step: 5
Training loss: 0.8827382326126099
Validation loss: 1.6255130485821796

Epoch: 5| Step: 6
Training loss: 0.27218830585479736
Validation loss: 1.6148623093481986

Epoch: 5| Step: 7
Training loss: 0.1710912436246872
Validation loss: 1.6240479100135066

Epoch: 5| Step: 8
Training loss: 0.3205278813838959
Validation loss: 1.6373411224734398

Epoch: 5| Step: 9
Training loss: 0.41832274198532104
Validation loss: 1.6409004465226205

Epoch: 5| Step: 10
Training loss: 0.4301703870296478
Validation loss: 1.6534602872786983

Epoch: 320| Step: 0
Training loss: 0.3968808352947235
Validation loss: 1.6533003154621329

Epoch: 5| Step: 1
Training loss: 0.33194518089294434
Validation loss: 1.6231630322753743

Epoch: 5| Step: 2
Training loss: 0.4157274663448334
Validation loss: 1.6011835311048774

Epoch: 5| Step: 3
Training loss: 0.5056118965148926
Validation loss: 1.6177307739052722

Epoch: 5| Step: 4
Training loss: 0.2258157730102539
Validation loss: 1.6349595554413334

Epoch: 5| Step: 5
Training loss: 0.4393842816352844
Validation loss: 1.6368618242202266

Epoch: 5| Step: 6
Training loss: 0.35011425614356995
Validation loss: 1.6470592765397922

Epoch: 5| Step: 7
Training loss: 0.5198349356651306
Validation loss: 1.6430765262214087

Epoch: 5| Step: 8
Training loss: 0.33688122034072876
Validation loss: 1.6411778119302565

Epoch: 5| Step: 9
Training loss: 0.45457911491394043
Validation loss: 1.6268241655442022

Epoch: 5| Step: 10
Training loss: 0.2670047879219055
Validation loss: 1.6180937661919543

Epoch: 321| Step: 0
Training loss: 0.48148566484451294
Validation loss: 1.614757276350452

Epoch: 5| Step: 1
Training loss: 0.2528509497642517
Validation loss: 1.6329963604609172

Epoch: 5| Step: 2
Training loss: 0.3354648947715759
Validation loss: 1.6144366969344437

Epoch: 5| Step: 3
Training loss: 0.22971415519714355
Validation loss: 1.6631177163893176

Epoch: 5| Step: 4
Training loss: 0.23958858847618103
Validation loss: 1.663151111654056

Epoch: 5| Step: 5
Training loss: 0.4986216425895691
Validation loss: 1.6958457987795594

Epoch: 5| Step: 6
Training loss: 0.6751477122306824
Validation loss: 1.6899300762402114

Epoch: 5| Step: 7
Training loss: 0.2685163915157318
Validation loss: 1.6749697603205198

Epoch: 5| Step: 8
Training loss: 0.5579619407653809
Validation loss: 1.6865656042611727

Epoch: 5| Step: 9
Training loss: 0.5272439122200012
Validation loss: 1.625855072852104

Epoch: 5| Step: 10
Training loss: 0.43822726607322693
Validation loss: 1.634988405371225

Epoch: 322| Step: 0
Training loss: 0.3272533416748047
Validation loss: 1.6217671312311643

Epoch: 5| Step: 1
Training loss: 0.46263861656188965
Validation loss: 1.6024863745576592

Epoch: 5| Step: 2
Training loss: 0.4589416980743408
Validation loss: 1.629615229945029

Epoch: 5| Step: 3
Training loss: 0.32744771242141724
Validation loss: 1.6206886627340829

Epoch: 5| Step: 4
Training loss: 0.33536258339881897
Validation loss: 1.6553368670966035

Epoch: 5| Step: 5
Training loss: 0.3357483744621277
Validation loss: 1.6779431989116054

Epoch: 5| Step: 6
Training loss: 0.25740689039230347
Validation loss: 1.6858783050249981

Epoch: 5| Step: 7
Training loss: 0.2954704165458679
Validation loss: 1.654580605927334

Epoch: 5| Step: 8
Training loss: 0.2799566388130188
Validation loss: 1.6483351017839165

Epoch: 5| Step: 9
Training loss: 0.7612854242324829
Validation loss: 1.6261878808339436

Epoch: 5| Step: 10
Training loss: 0.5026891231536865
Validation loss: 1.6095701212524085

Epoch: 323| Step: 0
Training loss: 0.22758027911186218
Validation loss: 1.6272345576235043

Epoch: 5| Step: 1
Training loss: 0.33646678924560547
Validation loss: 1.6107782458746305

Epoch: 5| Step: 2
Training loss: 0.345210999250412
Validation loss: 1.6166837305151007

Epoch: 5| Step: 3
Training loss: 0.4393269419670105
Validation loss: 1.6424016414150115

Epoch: 5| Step: 4
Training loss: 0.24017873406410217
Validation loss: 1.6509100032109085

Epoch: 5| Step: 5
Training loss: 0.44612932205200195
Validation loss: 1.644797949380772

Epoch: 5| Step: 6
Training loss: 0.3859172463417053
Validation loss: 1.6347973141618954

Epoch: 5| Step: 7
Training loss: 0.38337886333465576
Validation loss: 1.6325812339782715

Epoch: 5| Step: 8
Training loss: 0.3785884380340576
Validation loss: 1.631049790690022

Epoch: 5| Step: 9
Training loss: 0.5987383723258972
Validation loss: 1.6251749454006073

Epoch: 5| Step: 10
Training loss: 0.31198909878730774
Validation loss: 1.6492585341135662

Epoch: 324| Step: 0
Training loss: 0.4430397152900696
Validation loss: 1.6269425704915037

Epoch: 5| Step: 1
Training loss: 0.40443867444992065
Validation loss: 1.6336672088151336

Epoch: 5| Step: 2
Training loss: 0.449200302362442
Validation loss: 1.6414219679371003

Epoch: 5| Step: 3
Training loss: 0.5664044618606567
Validation loss: 1.642931402370494

Epoch: 5| Step: 4
Training loss: 0.22252967953681946
Validation loss: 1.626146666465267

Epoch: 5| Step: 5
Training loss: 0.3014199733734131
Validation loss: 1.6287835849228727

Epoch: 5| Step: 6
Training loss: 0.22486059367656708
Validation loss: 1.6110253718591505

Epoch: 5| Step: 7
Training loss: 0.30440554022789
Validation loss: 1.6070412551203082

Epoch: 5| Step: 8
Training loss: 0.3683027923107147
Validation loss: 1.6301074476652249

Epoch: 5| Step: 9
Training loss: 0.45539626479148865
Validation loss: 1.6239350803436772

Epoch: 5| Step: 10
Training loss: 0.34534886479377747
Validation loss: 1.6421322745661582

Epoch: 325| Step: 0
Training loss: 0.6346611976623535
Validation loss: 1.6524235087056314

Epoch: 5| Step: 1
Training loss: 0.27418234944343567
Validation loss: 1.6666686419517762

Epoch: 5| Step: 2
Training loss: 0.4818239212036133
Validation loss: 1.6904535831943635

Epoch: 5| Step: 3
Training loss: 0.42928165197372437
Validation loss: 1.6967871932573215

Epoch: 5| Step: 4
Training loss: 0.33269476890563965
Validation loss: 1.681124770513145

Epoch: 5| Step: 5
Training loss: 0.15848854184150696
Validation loss: 1.6680186845922982

Epoch: 5| Step: 6
Training loss: 0.35457420349121094
Validation loss: 1.6325673275096442

Epoch: 5| Step: 7
Training loss: 0.3749929666519165
Validation loss: 1.60032090064018

Epoch: 5| Step: 8
Training loss: 0.6806700229644775
Validation loss: 1.6165098592799196

Epoch: 5| Step: 9
Training loss: 0.4126926362514496
Validation loss: 1.6318058736862675

Epoch: 5| Step: 10
Training loss: 0.3974330425262451
Validation loss: 1.6180559806926276

Epoch: 326| Step: 0
Training loss: 0.4806098937988281
Validation loss: 1.6464330932145477

Epoch: 5| Step: 1
Training loss: 0.4102703630924225
Validation loss: 1.703745251060814

Epoch: 5| Step: 2
Training loss: 0.4232110381126404
Validation loss: 1.707526417188747

Epoch: 5| Step: 3
Training loss: 0.5182135701179504
Validation loss: 1.7092030509825675

Epoch: 5| Step: 4
Training loss: 0.2126823216676712
Validation loss: 1.67095745507107

Epoch: 5| Step: 5
Training loss: 0.3643014430999756
Validation loss: 1.649068352996662

Epoch: 5| Step: 6
Training loss: 0.26293855905532837
Validation loss: 1.670353042182102

Epoch: 5| Step: 7
Training loss: 0.4157073497772217
Validation loss: 1.6741684995671755

Epoch: 5| Step: 8
Training loss: 0.3473164439201355
Validation loss: 1.6793189241040138

Epoch: 5| Step: 9
Training loss: 0.27668458223342896
Validation loss: 1.6379469504920385

Epoch: 5| Step: 10
Training loss: 0.47551995515823364
Validation loss: 1.6230887379697574

Epoch: 327| Step: 0
Training loss: 0.5706230401992798
Validation loss: 1.5879020870372813

Epoch: 5| Step: 1
Training loss: 0.29557400941848755
Validation loss: 1.6014003010206326

Epoch: 5| Step: 2
Training loss: 0.3596321940422058
Validation loss: 1.6114748934263825

Epoch: 5| Step: 3
Training loss: 0.2748229205608368
Validation loss: 1.594851763017716

Epoch: 5| Step: 4
Training loss: 0.46387702226638794
Validation loss: 1.581453433600805

Epoch: 5| Step: 5
Training loss: 0.42594194412231445
Validation loss: 1.6129064393299881

Epoch: 5| Step: 6
Training loss: 0.33982419967651367
Validation loss: 1.6172866667470625

Epoch: 5| Step: 7
Training loss: 0.25610700249671936
Validation loss: 1.5948032448368687

Epoch: 5| Step: 8
Training loss: 0.3827260136604309
Validation loss: 1.6116791053484845

Epoch: 5| Step: 9
Training loss: 0.3023427724838257
Validation loss: 1.5956652151641024

Epoch: 5| Step: 10
Training loss: 0.5466238260269165
Validation loss: 1.590733471737113

Epoch: 328| Step: 0
Training loss: 0.31577810645103455
Validation loss: 1.5847965709624752

Epoch: 5| Step: 1
Training loss: 0.18249252438545227
Validation loss: 1.5913534702793244

Epoch: 5| Step: 2
Training loss: 0.3481527268886566
Validation loss: 1.600815785828457

Epoch: 5| Step: 3
Training loss: 0.4685356020927429
Validation loss: 1.6156020523399435

Epoch: 5| Step: 4
Training loss: 0.47796526551246643
Validation loss: 1.6284715680665867

Epoch: 5| Step: 5
Training loss: 0.3909314274787903
Validation loss: 1.6295577454310592

Epoch: 5| Step: 6
Training loss: 0.27968719601631165
Validation loss: 1.637381879232263

Epoch: 5| Step: 7
Training loss: 0.4488982558250427
Validation loss: 1.6251049669840003

Epoch: 5| Step: 8
Training loss: 0.31834107637405396
Validation loss: 1.6470200836017568

Epoch: 5| Step: 9
Training loss: 0.5216173529624939
Validation loss: 1.6133257881287606

Epoch: 5| Step: 10
Training loss: 0.19980792701244354
Validation loss: 1.611715885900682

Epoch: 329| Step: 0
Training loss: 0.41199955344200134
Validation loss: 1.6139680095898208

Epoch: 5| Step: 1
Training loss: 0.33660101890563965
Validation loss: 1.5836444811154438

Epoch: 5| Step: 2
Training loss: 0.30084502696990967
Validation loss: 1.582130838465947

Epoch: 5| Step: 3
Training loss: 0.38484054803848267
Validation loss: 1.5947736206875052

Epoch: 5| Step: 4
Training loss: 0.6467872858047485
Validation loss: 1.5998521953500726

Epoch: 5| Step: 5
Training loss: 0.2861435115337372
Validation loss: 1.6163740978446057

Epoch: 5| Step: 6
Training loss: 0.2439061403274536
Validation loss: 1.607241863845497

Epoch: 5| Step: 7
Training loss: 0.22519469261169434
Validation loss: 1.6206171563876572

Epoch: 5| Step: 8
Training loss: 0.273121178150177
Validation loss: 1.6517264099531277

Epoch: 5| Step: 9
Training loss: 0.47755560278892517
Validation loss: 1.6439112514577887

Epoch: 5| Step: 10
Training loss: 0.3479953408241272
Validation loss: 1.633783326354078

Epoch: 330| Step: 0
Training loss: 0.53818678855896
Validation loss: 1.6150206506893199

Epoch: 5| Step: 1
Training loss: 0.4542158246040344
Validation loss: 1.6001806271973478

Epoch: 5| Step: 2
Training loss: 0.2338641881942749
Validation loss: 1.6311491151009836

Epoch: 5| Step: 3
Training loss: 0.23226948082447052
Validation loss: 1.6077231284110778

Epoch: 5| Step: 4
Training loss: 0.42292651534080505
Validation loss: 1.6062452100938367

Epoch: 5| Step: 5
Training loss: 0.5329299569129944
Validation loss: 1.6022982866533342

Epoch: 5| Step: 6
Training loss: 0.20081225037574768
Validation loss: 1.6449285245710803

Epoch: 5| Step: 7
Training loss: 0.41436830163002014
Validation loss: 1.649961543339555

Epoch: 5| Step: 8
Training loss: 0.40159663558006287
Validation loss: 1.624811710849885

Epoch: 5| Step: 9
Training loss: 0.17766110599040985
Validation loss: 1.6248371639559347

Epoch: 5| Step: 10
Training loss: 0.22517120838165283
Validation loss: 1.6237005777256464

Epoch: 331| Step: 0
Training loss: 0.44961175322532654
Validation loss: 1.6169601268665765

Epoch: 5| Step: 1
Training loss: 0.18761612474918365
Validation loss: 1.6199593492733535

Epoch: 5| Step: 2
Training loss: 0.2646852135658264
Validation loss: 1.617443291089868

Epoch: 5| Step: 3
Training loss: 0.30406874418258667
Validation loss: 1.6259282122376144

Epoch: 5| Step: 4
Training loss: 0.20640043914318085
Validation loss: 1.6309145624919603

Epoch: 5| Step: 5
Training loss: 0.313944935798645
Validation loss: 1.5949002235166487

Epoch: 5| Step: 6
Training loss: 0.6822859644889832
Validation loss: 1.5897824020795925

Epoch: 5| Step: 7
Training loss: 0.36490777134895325
Validation loss: 1.590868994753848

Epoch: 5| Step: 8
Training loss: 0.12503650784492493
Validation loss: 1.605542420059122

Epoch: 5| Step: 9
Training loss: 0.3890076279640198
Validation loss: 1.6218367424062503

Epoch: 5| Step: 10
Training loss: 0.364801824092865
Validation loss: 1.5941892182955177

Epoch: 332| Step: 0
Training loss: 0.5587659478187561
Validation loss: 1.5930554866790771

Epoch: 5| Step: 1
Training loss: 0.13472576439380646
Validation loss: 1.6057313719103414

Epoch: 5| Step: 2
Training loss: 0.4192928373813629
Validation loss: 1.582105875656169

Epoch: 5| Step: 3
Training loss: 0.23168949782848358
Validation loss: 1.5698294921587872

Epoch: 5| Step: 4
Training loss: 0.3458457589149475
Validation loss: 1.5553070588778424

Epoch: 5| Step: 5
Training loss: 0.2201797068119049
Validation loss: 1.5604147052252164

Epoch: 5| Step: 6
Training loss: 0.24315543472766876
Validation loss: 1.5744487880378641

Epoch: 5| Step: 7
Training loss: 0.49644508957862854
Validation loss: 1.5985763342149797

Epoch: 5| Step: 8
Training loss: 0.43099117279052734
Validation loss: 1.586147379490637

Epoch: 5| Step: 9
Training loss: 0.27688050270080566
Validation loss: 1.6246798910120481

Epoch: 5| Step: 10
Training loss: 0.3356176018714905
Validation loss: 1.6298109228892992

Epoch: 333| Step: 0
Training loss: 0.2686687707901001
Validation loss: 1.6409690521096671

Epoch: 5| Step: 1
Training loss: 0.32554346323013306
Validation loss: 1.6199967502265848

Epoch: 5| Step: 2
Training loss: 0.31065845489501953
Validation loss: 1.5826400377417122

Epoch: 5| Step: 3
Training loss: 0.33154481649398804
Validation loss: 1.5810940624565206

Epoch: 5| Step: 4
Training loss: 0.26053178310394287
Validation loss: 1.613494905092383

Epoch: 5| Step: 5
Training loss: 0.5698646903038025
Validation loss: 1.5957567461075322

Epoch: 5| Step: 6
Training loss: 0.45407742261886597
Validation loss: 1.6065710616368118

Epoch: 5| Step: 7
Training loss: 0.30178302526474
Validation loss: 1.6186321114981046

Epoch: 5| Step: 8
Training loss: 0.273014098405838
Validation loss: 1.6339344068240094

Epoch: 5| Step: 9
Training loss: 0.49249306321144104
Validation loss: 1.6479137033544562

Epoch: 5| Step: 10
Training loss: 0.3245857357978821
Validation loss: 1.6487431141637987

Epoch: 334| Step: 0
Training loss: 0.4324437081813812
Validation loss: 1.6668097908778856

Epoch: 5| Step: 1
Training loss: 0.2796455919742584
Validation loss: 1.6404185320741387

Epoch: 5| Step: 2
Training loss: 0.4653170704841614
Validation loss: 1.6209236960257254

Epoch: 5| Step: 3
Training loss: 0.3729589581489563
Validation loss: 1.6213029866577477

Epoch: 5| Step: 4
Training loss: 0.24838528037071228
Validation loss: 1.6012117221791258

Epoch: 5| Step: 5
Training loss: 0.5625858306884766
Validation loss: 1.6040996748914

Epoch: 5| Step: 6
Training loss: 0.14110711216926575
Validation loss: 1.6259568109307239

Epoch: 5| Step: 7
Training loss: 0.47325438261032104
Validation loss: 1.612827600330435

Epoch: 5| Step: 8
Training loss: 0.30488672852516174
Validation loss: 1.6207371988604147

Epoch: 5| Step: 9
Training loss: 0.1144869327545166
Validation loss: 1.6396610288209812

Epoch: 5| Step: 10
Training loss: 0.2636503279209137
Validation loss: 1.649005461764592

Epoch: 335| Step: 0
Training loss: 0.14574871957302094
Validation loss: 1.6503554262140745

Epoch: 5| Step: 1
Training loss: 0.3320257067680359
Validation loss: 1.6265110264542282

Epoch: 5| Step: 2
Training loss: 0.3074352443218231
Validation loss: 1.6000554305250927

Epoch: 5| Step: 3
Training loss: 0.5680827498435974
Validation loss: 1.6040773084086757

Epoch: 5| Step: 4
Training loss: 0.2737411856651306
Validation loss: 1.6037438018347627

Epoch: 5| Step: 5
Training loss: 0.2777222692966461
Validation loss: 1.5933532279024842

Epoch: 5| Step: 6
Training loss: 0.3741711676120758
Validation loss: 1.613514268270103

Epoch: 5| Step: 7
Training loss: 0.3512949049472809
Validation loss: 1.6173645322040846

Epoch: 5| Step: 8
Training loss: 0.4922715127468109
Validation loss: 1.6110013402918333

Epoch: 5| Step: 9
Training loss: 0.33623605966567993
Validation loss: 1.6284270799288185

Epoch: 5| Step: 10
Training loss: 0.23936975002288818
Validation loss: 1.6613478775947326

Epoch: 336| Step: 0
Training loss: 0.5246832370758057
Validation loss: 1.6597473980278097

Epoch: 5| Step: 1
Training loss: 0.26946085691452026
Validation loss: 1.645605670508518

Epoch: 5| Step: 2
Training loss: 0.29774612188339233
Validation loss: 1.6040782941285001

Epoch: 5| Step: 3
Training loss: 0.25855499505996704
Validation loss: 1.6097698121942499

Epoch: 5| Step: 4
Training loss: 0.4359259605407715
Validation loss: 1.593667491789787

Epoch: 5| Step: 5
Training loss: 0.2771916687488556
Validation loss: 1.5998759391487285

Epoch: 5| Step: 6
Training loss: 0.215193510055542
Validation loss: 1.5843761544073782

Epoch: 5| Step: 7
Training loss: 0.5398293733596802
Validation loss: 1.595002999869726

Epoch: 5| Step: 8
Training loss: 0.29038485884666443
Validation loss: 1.6038016273129372

Epoch: 5| Step: 9
Training loss: 0.22096633911132812
Validation loss: 1.6322058259799916

Epoch: 5| Step: 10
Training loss: 0.2925022840499878
Validation loss: 1.647001952253362

Epoch: 337| Step: 0
Training loss: 0.14957252144813538
Validation loss: 1.634262643834596

Epoch: 5| Step: 1
Training loss: 0.22660419344902039
Validation loss: 1.6162647547260407

Epoch: 5| Step: 2
Training loss: 0.30418434739112854
Validation loss: 1.600664904040675

Epoch: 5| Step: 3
Training loss: 0.43774908781051636
Validation loss: 1.612466207114599

Epoch: 5| Step: 4
Training loss: 0.2903010845184326
Validation loss: 1.5966455013521257

Epoch: 5| Step: 5
Training loss: 0.31318527460098267
Validation loss: 1.5892639826702815

Epoch: 5| Step: 6
Training loss: 0.43972253799438477
Validation loss: 1.5979198422483218

Epoch: 5| Step: 7
Training loss: 0.26462921500205994
Validation loss: 1.5911318371372838

Epoch: 5| Step: 8
Training loss: 0.3651682436466217
Validation loss: 1.6092666964377127

Epoch: 5| Step: 9
Training loss: 0.35278746485710144
Validation loss: 1.6364073945629982

Epoch: 5| Step: 10
Training loss: 0.5893335938453674
Validation loss: 1.6457837755962084

Epoch: 338| Step: 0
Training loss: 0.43932056427001953
Validation loss: 1.6372558942405127

Epoch: 5| Step: 1
Training loss: 0.2990657687187195
Validation loss: 1.6330455400610482

Epoch: 5| Step: 2
Training loss: 0.25319987535476685
Validation loss: 1.6173347170634935

Epoch: 5| Step: 3
Training loss: 0.3345669209957123
Validation loss: 1.6029019227591894

Epoch: 5| Step: 4
Training loss: 0.26027268171310425
Validation loss: 1.5962295621953986

Epoch: 5| Step: 5
Training loss: 0.20761795341968536
Validation loss: 1.640038642832028

Epoch: 5| Step: 6
Training loss: 0.3756837248802185
Validation loss: 1.6255507225631385

Epoch: 5| Step: 7
Training loss: 0.3658861517906189
Validation loss: 1.6295523246129353

Epoch: 5| Step: 8
Training loss: 0.4168025851249695
Validation loss: 1.6507955360156235

Epoch: 5| Step: 9
Training loss: 0.34081417322158813
Validation loss: 1.634626038612858

Epoch: 5| Step: 10
Training loss: 0.2362217903137207
Validation loss: 1.646648617200954

Epoch: 339| Step: 0
Training loss: 0.2313571721315384
Validation loss: 1.6473694668021253

Epoch: 5| Step: 1
Training loss: 0.2871597707271576
Validation loss: 1.6487062387568976

Epoch: 5| Step: 2
Training loss: 0.4651030898094177
Validation loss: 1.666375925464015

Epoch: 5| Step: 3
Training loss: 0.35313472151756287
Validation loss: 1.6558880472695956

Epoch: 5| Step: 4
Training loss: 0.18987050652503967
Validation loss: 1.6459878657453804

Epoch: 5| Step: 5
Training loss: 0.44066277146339417
Validation loss: 1.6273033875291065

Epoch: 5| Step: 6
Training loss: 0.2091822624206543
Validation loss: 1.5997880210158646

Epoch: 5| Step: 7
Training loss: 0.4811045527458191
Validation loss: 1.5863211603574856

Epoch: 5| Step: 8
Training loss: 0.3083469271659851
Validation loss: 1.6062241895224458

Epoch: 5| Step: 9
Training loss: 0.2387615144252777
Validation loss: 1.6179752221671484

Epoch: 5| Step: 10
Training loss: 0.3085314631462097
Validation loss: 1.5874312411072433

Epoch: 340| Step: 0
Training loss: 0.45610079169273376
Validation loss: 1.6023107574832054

Epoch: 5| Step: 1
Training loss: 0.21130752563476562
Validation loss: 1.596107812337978

Epoch: 5| Step: 2
Training loss: 0.16084055602550507
Validation loss: 1.612212364391614

Epoch: 5| Step: 3
Training loss: 0.32532191276550293
Validation loss: 1.6412277529316563

Epoch: 5| Step: 4
Training loss: 0.15971526503562927
Validation loss: 1.6139462083898566

Epoch: 5| Step: 5
Training loss: 0.4031994342803955
Validation loss: 1.6345046233105403

Epoch: 5| Step: 6
Training loss: 0.1273680031299591
Validation loss: 1.6229538238176735

Epoch: 5| Step: 7
Training loss: 0.3482958674430847
Validation loss: 1.6315870438852618

Epoch: 5| Step: 8
Training loss: 0.22226658463478088
Validation loss: 1.6023458729508102

Epoch: 5| Step: 9
Training loss: 0.32385990023612976
Validation loss: 1.6343064974713069

Epoch: 5| Step: 10
Training loss: 0.7105585336685181
Validation loss: 1.6307940854821155

Epoch: 341| Step: 0
Training loss: 0.22221913933753967
Validation loss: 1.6250633578146658

Epoch: 5| Step: 1
Training loss: 0.24161019921302795
Validation loss: 1.623876867755767

Epoch: 5| Step: 2
Training loss: 0.2453954964876175
Validation loss: 1.6214777577307917

Epoch: 5| Step: 3
Training loss: 0.24291947484016418
Validation loss: 1.6130409650905158

Epoch: 5| Step: 4
Training loss: 0.4077731966972351
Validation loss: 1.5865963607706048

Epoch: 5| Step: 5
Training loss: 0.16955585777759552
Validation loss: 1.5956991090569446

Epoch: 5| Step: 6
Training loss: 0.6489564180374146
Validation loss: 1.6121865639122583

Epoch: 5| Step: 7
Training loss: 0.26880717277526855
Validation loss: 1.6209403853262625

Epoch: 5| Step: 8
Training loss: 0.3440248370170593
Validation loss: 1.6290874622201408

Epoch: 5| Step: 9
Training loss: 0.4552682042121887
Validation loss: 1.6318808781203402

Epoch: 5| Step: 10
Training loss: 0.29363715648651123
Validation loss: 1.647829342913884

Epoch: 342| Step: 0
Training loss: 0.3146660625934601
Validation loss: 1.6602728636034074

Epoch: 5| Step: 1
Training loss: 0.25079137086868286
Validation loss: 1.6571511914653163

Epoch: 5| Step: 2
Training loss: 0.4945918023586273
Validation loss: 1.6435505715749597

Epoch: 5| Step: 3
Training loss: 0.17295068502426147
Validation loss: 1.637576259592528

Epoch: 5| Step: 4
Training loss: 0.3073274493217468
Validation loss: 1.5968398310804879

Epoch: 5| Step: 5
Training loss: 0.293264776468277
Validation loss: 1.598862938983466

Epoch: 5| Step: 6
Training loss: 0.37042659521102905
Validation loss: 1.576775215005362

Epoch: 5| Step: 7
Training loss: 0.256736695766449
Validation loss: 1.6063473083639657

Epoch: 5| Step: 8
Training loss: 0.5875011682510376
Validation loss: 1.6287300445700204

Epoch: 5| Step: 9
Training loss: 0.3371036946773529
Validation loss: 1.6362534235882502

Epoch: 5| Step: 10
Training loss: 0.21629174053668976
Validation loss: 1.6364627833007483

Epoch: 343| Step: 0
Training loss: 0.2569860816001892
Validation loss: 1.610962571636323

Epoch: 5| Step: 1
Training loss: 0.32864832878112793
Validation loss: 1.5971752520530456

Epoch: 5| Step: 2
Training loss: 0.27314749360084534
Validation loss: 1.5705255129004037

Epoch: 5| Step: 3
Training loss: 0.3366517424583435
Validation loss: 1.5811468760172527

Epoch: 5| Step: 4
Training loss: 0.28236132860183716
Validation loss: 1.551859216023517

Epoch: 5| Step: 5
Training loss: 0.5071448087692261
Validation loss: 1.5686780579628483

Epoch: 5| Step: 6
Training loss: 0.3566846251487732
Validation loss: 1.5705274766491306

Epoch: 5| Step: 7
Training loss: 0.36637526750564575
Validation loss: 1.5854589375116492

Epoch: 5| Step: 8
Training loss: 0.2327221930027008
Validation loss: 1.5578936658879763

Epoch: 5| Step: 9
Training loss: 0.14728200435638428
Validation loss: 1.5840090051774056

Epoch: 5| Step: 10
Training loss: 0.3108972907066345
Validation loss: 1.5867804417046167

Epoch: 344| Step: 0
Training loss: 0.2891220152378082
Validation loss: 1.5921971567215458

Epoch: 5| Step: 1
Training loss: 0.36428967118263245
Validation loss: 1.5567258070873957

Epoch: 5| Step: 2
Training loss: 0.17801347374916077
Validation loss: 1.573824566538616

Epoch: 5| Step: 3
Training loss: 0.26627200841903687
Validation loss: 1.584163502980304

Epoch: 5| Step: 4
Training loss: 0.3173331320285797
Validation loss: 1.5600917390597764

Epoch: 5| Step: 5
Training loss: 0.24549441039562225
Validation loss: 1.5689550817653697

Epoch: 5| Step: 6
Training loss: 0.29471641778945923
Validation loss: 1.5589579343795776

Epoch: 5| Step: 7
Training loss: 0.3202884793281555
Validation loss: 1.5744765227840793

Epoch: 5| Step: 8
Training loss: 0.5146335363388062
Validation loss: 1.5927991597883162

Epoch: 5| Step: 9
Training loss: 0.2874360680580139
Validation loss: 1.587388216808278

Epoch: 5| Step: 10
Training loss: 0.40816664695739746
Validation loss: 1.6152704063282217

Epoch: 345| Step: 0
Training loss: 0.32057318091392517
Validation loss: 1.6288067961251864

Epoch: 5| Step: 1
Training loss: 0.2754783630371094
Validation loss: 1.6037330870987268

Epoch: 5| Step: 2
Training loss: 0.4117890000343323
Validation loss: 1.584546676886979

Epoch: 5| Step: 3
Training loss: 0.35739484429359436
Validation loss: 1.6019733528937063

Epoch: 5| Step: 4
Training loss: 0.33298730850219727
Validation loss: 1.5656669396226124

Epoch: 5| Step: 5
Training loss: 0.3819408416748047
Validation loss: 1.5678833274431125

Epoch: 5| Step: 6
Training loss: 0.39686959981918335
Validation loss: 1.5734762235354351

Epoch: 5| Step: 7
Training loss: 0.2911824584007263
Validation loss: 1.592068684998379

Epoch: 5| Step: 8
Training loss: 0.21900621056556702
Validation loss: 1.6074306503418954

Epoch: 5| Step: 9
Training loss: 0.2219429463148117
Validation loss: 1.6164336076346777

Epoch: 5| Step: 10
Training loss: 0.36036550998687744
Validation loss: 1.6255548769427883

Epoch: 346| Step: 0
Training loss: 0.32281044125556946
Validation loss: 1.6217183759135585

Epoch: 5| Step: 1
Training loss: 0.14941546320915222
Validation loss: 1.593290364870461

Epoch: 5| Step: 2
Training loss: 0.18296274542808533
Validation loss: 1.6041051559550787

Epoch: 5| Step: 3
Training loss: 0.19179858267307281
Validation loss: 1.6010522483497538

Epoch: 5| Step: 4
Training loss: 0.22017650306224823
Validation loss: 1.6021973368942097

Epoch: 5| Step: 5
Training loss: 0.2719995975494385
Validation loss: 1.611306090508738

Epoch: 5| Step: 6
Training loss: 0.4296465516090393
Validation loss: 1.6244147041792512

Epoch: 5| Step: 7
Training loss: 0.5152208805084229
Validation loss: 1.62094557926219

Epoch: 5| Step: 8
Training loss: 0.3726564049720764
Validation loss: 1.6165867197898127

Epoch: 5| Step: 9
Training loss: 0.24236218631267548
Validation loss: 1.619777012896794

Epoch: 5| Step: 10
Training loss: 0.4849925935268402
Validation loss: 1.5999629343709638

Epoch: 347| Step: 0
Training loss: 0.23133797943592072
Validation loss: 1.5965977689271331

Epoch: 5| Step: 1
Training loss: 0.3968358337879181
Validation loss: 1.572734325162826

Epoch: 5| Step: 2
Training loss: 0.25408321619033813
Validation loss: 1.590138776327974

Epoch: 5| Step: 3
Training loss: 0.25454938411712646
Validation loss: 1.5935005129024546

Epoch: 5| Step: 4
Training loss: 0.2336786538362503
Validation loss: 1.5881063867640752

Epoch: 5| Step: 5
Training loss: 0.22533681988716125
Validation loss: 1.5772573794088056

Epoch: 5| Step: 6
Training loss: 0.4098414480686188
Validation loss: 1.6114759881009337

Epoch: 5| Step: 7
Training loss: 0.326643168926239
Validation loss: 1.5866213953623207

Epoch: 5| Step: 8
Training loss: 0.20718280971050262
Validation loss: 1.6294604732144264

Epoch: 5| Step: 9
Training loss: 0.5313891172409058
Validation loss: 1.6176379521687825

Epoch: 5| Step: 10
Training loss: 0.28257954120635986
Validation loss: 1.6402159711366058

Epoch: 348| Step: 0
Training loss: 0.28836408257484436
Validation loss: 1.6124736416724421

Epoch: 5| Step: 1
Training loss: 0.39550521969795227
Validation loss: 1.6061057813705937

Epoch: 5| Step: 2
Training loss: 0.32090210914611816
Validation loss: 1.5763905618780403

Epoch: 5| Step: 3
Training loss: 0.3060676157474518
Validation loss: 1.6031135051481185

Epoch: 5| Step: 4
Training loss: 0.22587370872497559
Validation loss: 1.5865053105097946

Epoch: 5| Step: 5
Training loss: 0.24908247590065002
Validation loss: 1.5818737809376051

Epoch: 5| Step: 6
Training loss: 0.3025159239768982
Validation loss: 1.5951598421219857

Epoch: 5| Step: 7
Training loss: 0.26275062561035156
Validation loss: 1.5951772248873146

Epoch: 5| Step: 8
Training loss: 0.30024203658103943
Validation loss: 1.6217211625909294

Epoch: 5| Step: 9
Training loss: 0.22065481543540955
Validation loss: 1.634951263345698

Epoch: 5| Step: 10
Training loss: 0.37230879068374634
Validation loss: 1.6250857178882887

Epoch: 349| Step: 0
Training loss: 0.19473329186439514
Validation loss: 1.6040903970759401

Epoch: 5| Step: 1
Training loss: 0.31559011340141296
Validation loss: 1.6018031079282042

Epoch: 5| Step: 2
Training loss: 0.11345729976892471
Validation loss: 1.582099445404545

Epoch: 5| Step: 3
Training loss: 0.34186553955078125
Validation loss: 1.6023432644464637

Epoch: 5| Step: 4
Training loss: 0.1851554661989212
Validation loss: 1.6153875371461273

Epoch: 5| Step: 5
Training loss: 0.4474894404411316
Validation loss: 1.560997780933175

Epoch: 5| Step: 6
Training loss: 0.07892916351556778
Validation loss: 1.5845150857843378

Epoch: 5| Step: 7
Training loss: 0.19398033618927002
Validation loss: 1.5672039216564548

Epoch: 5| Step: 8
Training loss: 0.3848639726638794
Validation loss: 1.5658578590680194

Epoch: 5| Step: 9
Training loss: 0.43755030632019043
Validation loss: 1.5911206506913709

Epoch: 5| Step: 10
Training loss: 0.38034987449645996
Validation loss: 1.5994603864608272

Epoch: 350| Step: 0
Training loss: 0.3400292992591858
Validation loss: 1.6077753113162132

Epoch: 5| Step: 1
Training loss: 0.2640969157218933
Validation loss: 1.625173459770859

Epoch: 5| Step: 2
Training loss: 0.3124322295188904
Validation loss: 1.5807576525595881

Epoch: 5| Step: 3
Training loss: 0.5035379528999329
Validation loss: 1.6029778372856878

Epoch: 5| Step: 4
Training loss: 0.4262414574623108
Validation loss: 1.578857598766204

Epoch: 5| Step: 5
Training loss: 0.14443111419677734
Validation loss: 1.5687550203774565

Epoch: 5| Step: 6
Training loss: 0.28301239013671875
Validation loss: 1.561757806808718

Epoch: 5| Step: 7
Training loss: 0.269889771938324
Validation loss: 1.5322038512076102

Epoch: 5| Step: 8
Training loss: 0.14455854892730713
Validation loss: 1.5833674368037973

Epoch: 5| Step: 9
Training loss: 0.3245879113674164
Validation loss: 1.5756592660821893

Epoch: 5| Step: 10
Training loss: 0.33303582668304443
Validation loss: 1.5789037481431039

Epoch: 351| Step: 0
Training loss: 0.43092793226242065
Validation loss: 1.5976697450043054

Epoch: 5| Step: 1
Training loss: 0.18589606881141663
Validation loss: 1.5689296933912462

Epoch: 5| Step: 2
Training loss: 0.21592457592487335
Validation loss: 1.564132462265671

Epoch: 5| Step: 3
Training loss: 0.16506549715995789
Validation loss: 1.570757927433137

Epoch: 5| Step: 4
Training loss: 0.24434876441955566
Validation loss: 1.5508711030406337

Epoch: 5| Step: 5
Training loss: 0.3478941321372986
Validation loss: 1.5721895963914934

Epoch: 5| Step: 6
Training loss: 0.35264480113983154
Validation loss: 1.578720110718922

Epoch: 5| Step: 7
Training loss: 0.30492377281188965
Validation loss: 1.5645007292429607

Epoch: 5| Step: 8
Training loss: 0.2153799831867218
Validation loss: 1.5673872963074715

Epoch: 5| Step: 9
Training loss: 0.22041459381580353
Validation loss: 1.5861845990662933

Epoch: 5| Step: 10
Training loss: 0.41786640882492065
Validation loss: 1.592980231008222

Epoch: 352| Step: 0
Training loss: 0.19480697810649872
Validation loss: 1.5836930031417518

Epoch: 5| Step: 1
Training loss: 0.2796900272369385
Validation loss: 1.5973279360801942

Epoch: 5| Step: 2
Training loss: 0.40092381834983826
Validation loss: 1.6097449153982184

Epoch: 5| Step: 3
Training loss: 0.298214852809906
Validation loss: 1.5913664192281745

Epoch: 5| Step: 4
Training loss: 0.23475055396556854
Validation loss: 1.5708402677248883

Epoch: 5| Step: 5
Training loss: 0.1472872793674469
Validation loss: 1.573326369767548

Epoch: 5| Step: 6
Training loss: 0.40583938360214233
Validation loss: 1.5881638116734003

Epoch: 5| Step: 7
Training loss: 0.1992959827184677
Validation loss: 1.5936746148652927

Epoch: 5| Step: 8
Training loss: 0.2505393922328949
Validation loss: 1.5951423811656174

Epoch: 5| Step: 9
Training loss: 0.28470689058303833
Validation loss: 1.5950988467021654

Epoch: 5| Step: 10
Training loss: 0.4758542478084564
Validation loss: 1.5867894272650442

Epoch: 353| Step: 0
Training loss: 0.22199711203575134
Validation loss: 1.5991253801571426

Epoch: 5| Step: 1
Training loss: 0.19324040412902832
Validation loss: 1.6103421244570004

Epoch: 5| Step: 2
Training loss: 0.22263236343860626
Validation loss: 1.605505347251892

Epoch: 5| Step: 3
Training loss: 0.20747992396354675
Validation loss: 1.5936124888799523

Epoch: 5| Step: 4
Training loss: 0.33416229486465454
Validation loss: 1.5667671490741033

Epoch: 5| Step: 5
Training loss: 0.18617704510688782
Validation loss: 1.5893468933720742

Epoch: 5| Step: 6
Training loss: 0.309565007686615
Validation loss: 1.553249446294641

Epoch: 5| Step: 7
Training loss: 0.41181308031082153
Validation loss: 1.5559067597953222

Epoch: 5| Step: 8
Training loss: 0.3610847592353821
Validation loss: 1.560772071602524

Epoch: 5| Step: 9
Training loss: 0.39130887389183044
Validation loss: 1.5508592795300227

Epoch: 5| Step: 10
Training loss: 0.2485743761062622
Validation loss: 1.5621001105154715

Epoch: 354| Step: 0
Training loss: 0.3169722557067871
Validation loss: 1.5635906496355612

Epoch: 5| Step: 1
Training loss: 0.3002660274505615
Validation loss: 1.5804796834145822

Epoch: 5| Step: 2
Training loss: 0.23140600323677063
Validation loss: 1.5771044005629837

Epoch: 5| Step: 3
Training loss: 0.15874968469142914
Validation loss: 1.5964240143376012

Epoch: 5| Step: 4
Training loss: 0.32231277227401733
Validation loss: 1.5992091701876732

Epoch: 5| Step: 5
Training loss: 0.2208237648010254
Validation loss: 1.6155377100872736

Epoch: 5| Step: 6
Training loss: 0.33497247099876404
Validation loss: 1.626841527159496

Epoch: 5| Step: 7
Training loss: 0.20472589135169983
Validation loss: 1.6111140122977636

Epoch: 5| Step: 8
Training loss: 0.3058280646800995
Validation loss: 1.614519150026383

Epoch: 5| Step: 9
Training loss: 0.19782590866088867
Validation loss: 1.5959247055874075

Epoch: 5| Step: 10
Training loss: 0.43035563826560974
Validation loss: 1.613093336423238

Epoch: 355| Step: 0
Training loss: 0.43269675970077515
Validation loss: 1.5830480744761806

Epoch: 5| Step: 1
Training loss: 0.28535500168800354
Validation loss: 1.5831367943876533

Epoch: 5| Step: 2
Training loss: 0.14560599625110626
Validation loss: 1.5573619347746654

Epoch: 5| Step: 3
Training loss: 0.20720016956329346
Validation loss: 1.558367403604651

Epoch: 5| Step: 4
Training loss: 0.3178155720233917
Validation loss: 1.5711806205011183

Epoch: 5| Step: 5
Training loss: 0.2586916387081146
Validation loss: 1.571474362445134

Epoch: 5| Step: 6
Training loss: 0.2065715342760086
Validation loss: 1.5945960039733558

Epoch: 5| Step: 7
Training loss: 0.19867584109306335
Validation loss: 1.5741745733445691

Epoch: 5| Step: 8
Training loss: 0.20659908652305603
Validation loss: 1.5848562166255007

Epoch: 5| Step: 9
Training loss: 0.45390334725379944
Validation loss: 1.6017479922181816

Epoch: 5| Step: 10
Training loss: 0.2800663709640503
Validation loss: 1.5940814043885918

Epoch: 356| Step: 0
Training loss: 0.24255681037902832
Validation loss: 1.6007347747843752

Epoch: 5| Step: 1
Training loss: 0.23905077576637268
Validation loss: 1.5509935245719007

Epoch: 5| Step: 2
Training loss: 0.29852747917175293
Validation loss: 1.5461246864770049

Epoch: 5| Step: 3
Training loss: 0.21558921039104462
Validation loss: 1.5833054011867893

Epoch: 5| Step: 4
Training loss: 0.3041714131832123
Validation loss: 1.5568270644833964

Epoch: 5| Step: 5
Training loss: 0.19312766194343567
Validation loss: 1.5687655941132577

Epoch: 5| Step: 6
Training loss: 0.2577942907810211
Validation loss: 1.5710115983921995

Epoch: 5| Step: 7
Training loss: 0.39910346269607544
Validation loss: 1.5964468409938197

Epoch: 5| Step: 8
Training loss: 0.19121520221233368
Validation loss: 1.6217693269893687

Epoch: 5| Step: 9
Training loss: 0.2377852201461792
Validation loss: 1.6024756136760916

Epoch: 5| Step: 10
Training loss: 0.37150728702545166
Validation loss: 1.6207713119445308

Epoch: 357| Step: 0
Training loss: 0.4235864281654358
Validation loss: 1.590182614582841

Epoch: 5| Step: 1
Training loss: 0.2089323103427887
Validation loss: 1.6094555931706582

Epoch: 5| Step: 2
Training loss: 0.2825395166873932
Validation loss: 1.5997467041015625

Epoch: 5| Step: 3
Training loss: 0.22212564945220947
Validation loss: 1.5483395822586552

Epoch: 5| Step: 4
Training loss: 0.20714989304542542
Validation loss: 1.5531046339260635

Epoch: 5| Step: 5
Training loss: 0.26500192284584045
Validation loss: 1.5541323564385856

Epoch: 5| Step: 6
Training loss: 0.35872983932495117
Validation loss: 1.5564864950795327

Epoch: 5| Step: 7
Training loss: 0.27663832902908325
Validation loss: 1.5334406950140511

Epoch: 5| Step: 8
Training loss: 0.3642590641975403
Validation loss: 1.5498799688072615

Epoch: 5| Step: 9
Training loss: 0.23195604979991913
Validation loss: 1.5698997102757937

Epoch: 5| Step: 10
Training loss: 0.19888506829738617
Validation loss: 1.546400785446167

Epoch: 358| Step: 0
Training loss: 0.2572695016860962
Validation loss: 1.5632040116094774

Epoch: 5| Step: 1
Training loss: 0.4077209532260895
Validation loss: 1.5719773250241433

Epoch: 5| Step: 2
Training loss: 0.2815304398536682
Validation loss: 1.5733004923789733

Epoch: 5| Step: 3
Training loss: 0.19417531788349152
Validation loss: 1.570203906746321

Epoch: 5| Step: 4
Training loss: 0.1988532543182373
Validation loss: 1.5806988913525817

Epoch: 5| Step: 5
Training loss: 0.12927106022834778
Validation loss: 1.5559585427725187

Epoch: 5| Step: 6
Training loss: 0.23625226318836212
Validation loss: 1.5553328734572216

Epoch: 5| Step: 7
Training loss: 0.338767945766449
Validation loss: 1.5667804774417673

Epoch: 5| Step: 8
Training loss: 0.24717548489570618
Validation loss: 1.552516834710234

Epoch: 5| Step: 9
Training loss: 0.3194657862186432
Validation loss: 1.5942168620324904

Epoch: 5| Step: 10
Training loss: 0.31967470049858093
Validation loss: 1.588634753739962

Epoch: 359| Step: 0
Training loss: 0.3062043786048889
Validation loss: 1.6021587669208486

Epoch: 5| Step: 1
Training loss: 0.35146570205688477
Validation loss: 1.587875570020368

Epoch: 5| Step: 2
Training loss: 0.11821386963129044
Validation loss: 1.5646444289915022

Epoch: 5| Step: 3
Training loss: 0.20027808845043182
Validation loss: 1.5721775075440765

Epoch: 5| Step: 4
Training loss: 0.3051661252975464
Validation loss: 1.5488994941916516

Epoch: 5| Step: 5
Training loss: 0.3799951672554016
Validation loss: 1.552600581158874

Epoch: 5| Step: 6
Training loss: 0.38489899039268494
Validation loss: 1.555986818446908

Epoch: 5| Step: 7
Training loss: 0.2624615430831909
Validation loss: 1.5538031183263308

Epoch: 5| Step: 8
Training loss: 0.40090838074684143
Validation loss: 1.5915379754958614

Epoch: 5| Step: 9
Training loss: 0.3878568708896637
Validation loss: 1.583173204493779

Epoch: 5| Step: 10
Training loss: 0.13215601444244385
Validation loss: 1.5794782933368479

Epoch: 360| Step: 0
Training loss: 0.337735652923584
Validation loss: 1.5690157413482666

Epoch: 5| Step: 1
Training loss: 0.16751226782798767
Validation loss: 1.5787645027201662

Epoch: 5| Step: 2
Training loss: 0.2801087498664856
Validation loss: 1.5556227872448583

Epoch: 5| Step: 3
Training loss: 0.23525314033031464
Validation loss: 1.5742483626129806

Epoch: 5| Step: 4
Training loss: 0.2445523738861084
Validation loss: 1.5617193387400718

Epoch: 5| Step: 5
Training loss: 0.10789342224597931
Validation loss: 1.5667749361325336

Epoch: 5| Step: 6
Training loss: 0.3358435034751892
Validation loss: 1.5699458442708498

Epoch: 5| Step: 7
Training loss: 0.25893697142601013
Validation loss: 1.5865355294237855

Epoch: 5| Step: 8
Training loss: 0.3656516373157501
Validation loss: 1.571446249561925

Epoch: 5| Step: 9
Training loss: 0.1443549394607544
Validation loss: 1.577300711344647

Epoch: 5| Step: 10
Training loss: 0.406081885099411
Validation loss: 1.5798200484245055

Epoch: 361| Step: 0
Training loss: 0.33510273694992065
Validation loss: 1.580029813192224

Epoch: 5| Step: 1
Training loss: 0.2133980691432953
Validation loss: 1.5882959032571444

Epoch: 5| Step: 2
Training loss: 0.3299538791179657
Validation loss: 1.6160861061465355

Epoch: 5| Step: 3
Training loss: 0.2716762125492096
Validation loss: 1.5914288759231567

Epoch: 5| Step: 4
Training loss: 0.25823965668678284
Validation loss: 1.5684059473776049

Epoch: 5| Step: 5
Training loss: 0.25825321674346924
Validation loss: 1.5606702220055364

Epoch: 5| Step: 6
Training loss: 0.20486506819725037
Validation loss: 1.53662940315021

Epoch: 5| Step: 7
Training loss: 0.18607136607170105
Validation loss: 1.553222410140499

Epoch: 5| Step: 8
Training loss: 0.3601543605327606
Validation loss: 1.5655048893344017

Epoch: 5| Step: 9
Training loss: 0.34630072116851807
Validation loss: 1.5604827814204718

Epoch: 5| Step: 10
Training loss: 0.12882697582244873
Validation loss: 1.5795219213731828

Epoch: 362| Step: 0
Training loss: 0.12110073864459991
Validation loss: 1.580721430881049

Epoch: 5| Step: 1
Training loss: 0.25373581051826477
Validation loss: 1.5849219675986999

Epoch: 5| Step: 2
Training loss: 0.3779720067977905
Validation loss: 1.5808382521393478

Epoch: 5| Step: 3
Training loss: 0.1871868073940277
Validation loss: 1.5859263404723136

Epoch: 5| Step: 4
Training loss: 0.27260881662368774
Validation loss: 1.5966744493412715

Epoch: 5| Step: 5
Training loss: 0.20706024765968323
Validation loss: 1.579904358874085

Epoch: 5| Step: 6
Training loss: 0.3088875412940979
Validation loss: 1.5657779856394696

Epoch: 5| Step: 7
Training loss: 0.17816171050071716
Validation loss: 1.5580464729698755

Epoch: 5| Step: 8
Training loss: 0.25503021478652954
Validation loss: 1.5422481541992517

Epoch: 5| Step: 9
Training loss: 0.3255797028541565
Validation loss: 1.5702577508905882

Epoch: 5| Step: 10
Training loss: 0.3195597231388092
Validation loss: 1.563505749548635

Epoch: 363| Step: 0
Training loss: 0.33945733308792114
Validation loss: 1.6007690891142814

Epoch: 5| Step: 1
Training loss: 0.3394830822944641
Validation loss: 1.5698090996793521

Epoch: 5| Step: 2
Training loss: 0.1279708445072174
Validation loss: 1.5613691524792743

Epoch: 5| Step: 3
Training loss: 0.1302212029695511
Validation loss: 1.553140204439881

Epoch: 5| Step: 4
Training loss: 0.4827340245246887
Validation loss: 1.5520469219453874

Epoch: 5| Step: 5
Training loss: 0.22029709815979004
Validation loss: 1.5541359468172955

Epoch: 5| Step: 6
Training loss: 0.24894115328788757
Validation loss: 1.5600769955624816

Epoch: 5| Step: 7
Training loss: 0.37023279070854187
Validation loss: 1.5994234046628397

Epoch: 5| Step: 8
Training loss: 0.17755256593227386
Validation loss: 1.5632508031783565

Epoch: 5| Step: 9
Training loss: 0.2076132744550705
Validation loss: 1.5805388958223405

Epoch: 5| Step: 10
Training loss: 0.25819316506385803
Validation loss: 1.6015880005334013

Epoch: 364| Step: 0
Training loss: 0.32863718271255493
Validation loss: 1.599319705399134

Epoch: 5| Step: 1
Training loss: 0.3253360986709595
Validation loss: 1.580354235505545

Epoch: 5| Step: 2
Training loss: 0.165825754404068
Validation loss: 1.5538786739431403

Epoch: 5| Step: 3
Training loss: 0.23122723400592804
Validation loss: 1.549251123141217

Epoch: 5| Step: 4
Training loss: 0.24233348667621613
Validation loss: 1.5429938480418215

Epoch: 5| Step: 5
Training loss: 0.19112727046012878
Validation loss: 1.5499752490751204

Epoch: 5| Step: 6
Training loss: 0.3524767756462097
Validation loss: 1.553692388278182

Epoch: 5| Step: 7
Training loss: 0.3970920443534851
Validation loss: 1.5369404541548861

Epoch: 5| Step: 8
Training loss: 0.37041568756103516
Validation loss: 1.52679612816021

Epoch: 5| Step: 9
Training loss: 0.41147464513778687
Validation loss: 1.5786540956907376

Epoch: 5| Step: 10
Training loss: 0.42045193910598755
Validation loss: 1.6216595903519662

Epoch: 365| Step: 0
Training loss: 0.413076251745224
Validation loss: 1.623171171834392

Epoch: 5| Step: 1
Training loss: 0.1864946484565735
Validation loss: 1.5899611134682932

Epoch: 5| Step: 2
Training loss: 0.42859190702438354
Validation loss: 1.6007210964797645

Epoch: 5| Step: 3
Training loss: 0.2573074698448181
Validation loss: 1.597762087339996

Epoch: 5| Step: 4
Training loss: 0.36376047134399414
Validation loss: 1.57379295620867

Epoch: 5| Step: 5
Training loss: 0.38782158493995667
Validation loss: 1.605063089760401

Epoch: 5| Step: 6
Training loss: 0.24872756004333496
Validation loss: 1.5867375096967142

Epoch: 5| Step: 7
Training loss: 0.17772872745990753
Validation loss: 1.5995076849896421

Epoch: 5| Step: 8
Training loss: 0.2696476876735687
Validation loss: 1.6035327680649296

Epoch: 5| Step: 9
Training loss: 0.32129859924316406
Validation loss: 1.6168995999520825

Epoch: 5| Step: 10
Training loss: 0.11744718253612518
Validation loss: 1.5807280489193496

Epoch: 366| Step: 0
Training loss: 0.2450413703918457
Validation loss: 1.5911127303236274

Epoch: 5| Step: 1
Training loss: 0.2787177264690399
Validation loss: 1.5746406432121032

Epoch: 5| Step: 2
Training loss: 0.1234336644411087
Validation loss: 1.5805405942342614

Epoch: 5| Step: 3
Training loss: 0.14827951788902283
Validation loss: 1.57661703196905

Epoch: 5| Step: 4
Training loss: 0.3010145425796509
Validation loss: 1.5910868106349823

Epoch: 5| Step: 5
Training loss: 0.2835726737976074
Validation loss: 1.5819877168183685

Epoch: 5| Step: 6
Training loss: 0.31645044684410095
Validation loss: 1.5813795417867682

Epoch: 5| Step: 7
Training loss: 0.214970201253891
Validation loss: 1.5951093601924118

Epoch: 5| Step: 8
Training loss: 0.35378727316856384
Validation loss: 1.589448921142086

Epoch: 5| Step: 9
Training loss: 0.3425935208797455
Validation loss: 1.6004735333945161

Epoch: 5| Step: 10
Training loss: 0.34506332874298096
Validation loss: 1.5980657851824196

Epoch: 367| Step: 0
Training loss: 0.17388299107551575
Validation loss: 1.5779156441329627

Epoch: 5| Step: 1
Training loss: 0.16566285490989685
Validation loss: 1.5877996901030182

Epoch: 5| Step: 2
Training loss: 0.28637242317199707
Validation loss: 1.5669809022257406

Epoch: 5| Step: 3
Training loss: 0.4904213845729828
Validation loss: 1.5612279484348912

Epoch: 5| Step: 4
Training loss: 0.30030471086502075
Validation loss: 1.5374256910816315

Epoch: 5| Step: 5
Training loss: 0.2973097562789917
Validation loss: 1.5540081557407175

Epoch: 5| Step: 6
Training loss: 0.23427096009254456
Validation loss: 1.5633957091198172

Epoch: 5| Step: 7
Training loss: 0.18903112411499023
Validation loss: 1.5484123704253987

Epoch: 5| Step: 8
Training loss: 0.07390347868204117
Validation loss: 1.5656412942435152

Epoch: 5| Step: 9
Training loss: 0.3579750657081604
Validation loss: 1.586049905387304

Epoch: 5| Step: 10
Training loss: 0.36330488324165344
Validation loss: 1.6301342441189675

Epoch: 368| Step: 0
Training loss: 0.25546401739120483
Validation loss: 1.6493650110819007

Epoch: 5| Step: 1
Training loss: 0.32438233494758606
Validation loss: 1.620376903523681

Epoch: 5| Step: 2
Training loss: 0.3423600196838379
Validation loss: 1.5513367652893066

Epoch: 5| Step: 3
Training loss: 0.21387676894664764
Validation loss: 1.5443999805758077

Epoch: 5| Step: 4
Training loss: 0.20516078174114227
Validation loss: 1.5486835875818807

Epoch: 5| Step: 5
Training loss: 0.2669636011123657
Validation loss: 1.5339449913271013

Epoch: 5| Step: 6
Training loss: 0.20104102790355682
Validation loss: 1.5369208012857745

Epoch: 5| Step: 7
Training loss: 0.5761107802391052
Validation loss: 1.549266589585171

Epoch: 5| Step: 8
Training loss: 0.3021549582481384
Validation loss: 1.5453515796251194

Epoch: 5| Step: 9
Training loss: 0.24056482315063477
Validation loss: 1.6036685384729856

Epoch: 5| Step: 10
Training loss: 0.2256387621164322
Validation loss: 1.5787252303092711

Epoch: 369| Step: 0
Training loss: 0.2642557919025421
Validation loss: 1.5581168333689372

Epoch: 5| Step: 1
Training loss: 0.3166334629058838
Validation loss: 1.5814444454767371

Epoch: 5| Step: 2
Training loss: 0.29083451628685
Validation loss: 1.577923100481751

Epoch: 5| Step: 3
Training loss: 0.20496349036693573
Validation loss: 1.5557348753816338

Epoch: 5| Step: 4
Training loss: 0.340492308139801
Validation loss: 1.5560505390167236

Epoch: 5| Step: 5
Training loss: 0.3358733355998993
Validation loss: 1.5829737160795478

Epoch: 5| Step: 6
Training loss: 0.27750277519226074
Validation loss: 1.575431571211866

Epoch: 5| Step: 7
Training loss: 0.18491221964359283
Validation loss: 1.588371693447072

Epoch: 5| Step: 8
Training loss: 0.23193660378456116
Validation loss: 1.5871491611644786

Epoch: 5| Step: 9
Training loss: 0.27114489674568176
Validation loss: 1.5936509742531726

Epoch: 5| Step: 10
Training loss: 0.1399930715560913
Validation loss: 1.6085093598211966

Epoch: 370| Step: 0
Training loss: 0.3388186991214752
Validation loss: 1.5769167074593164

Epoch: 5| Step: 1
Training loss: 0.16144199669361115
Validation loss: 1.555359709647394

Epoch: 5| Step: 2
Training loss: 0.34402650594711304
Validation loss: 1.551083577576504

Epoch: 5| Step: 3
Training loss: 0.20198392868041992
Validation loss: 1.5560161285502936

Epoch: 5| Step: 4
Training loss: 0.2567494809627533
Validation loss: 1.5275811379955662

Epoch: 5| Step: 5
Training loss: 0.11515860259532928
Validation loss: 1.5215390850138921

Epoch: 5| Step: 6
Training loss: 0.38972529768943787
Validation loss: 1.5148968927321895

Epoch: 5| Step: 7
Training loss: 0.19774754345417023
Validation loss: 1.5384798613927697

Epoch: 5| Step: 8
Training loss: 0.20117191970348358
Validation loss: 1.566176845181373

Epoch: 5| Step: 9
Training loss: 0.23567838966846466
Validation loss: 1.5687883054056475

Epoch: 5| Step: 10
Training loss: 0.177864208817482
Validation loss: 1.5547065273407967

Epoch: 371| Step: 0
Training loss: 0.26992470026016235
Validation loss: 1.5832988959486767

Epoch: 5| Step: 1
Training loss: 0.2838493883609772
Validation loss: 1.5484632843284196

Epoch: 5| Step: 2
Training loss: 0.2036246359348297
Validation loss: 1.5334447096752863

Epoch: 5| Step: 3
Training loss: 0.47654399275779724
Validation loss: 1.5601452524944017

Epoch: 5| Step: 4
Training loss: 0.19726040959358215
Validation loss: 1.5527063531260337

Epoch: 5| Step: 5
Training loss: 0.23661932349205017
Validation loss: 1.5611147021734586

Epoch: 5| Step: 6
Training loss: 0.22518160939216614
Validation loss: 1.557013923762947

Epoch: 5| Step: 7
Training loss: 0.26807528734207153
Validation loss: 1.577877817615386

Epoch: 5| Step: 8
Training loss: 0.12476138025522232
Validation loss: 1.5535660616813167

Epoch: 5| Step: 9
Training loss: 0.1295047253370285
Validation loss: 1.5631406294402255

Epoch: 5| Step: 10
Training loss: 0.21788719296455383
Validation loss: 1.5410336345754645

Epoch: 372| Step: 0
Training loss: 0.23414039611816406
Validation loss: 1.522597833346295

Epoch: 5| Step: 1
Training loss: 0.20654693245887756
Validation loss: 1.5535250517629808

Epoch: 5| Step: 2
Training loss: 0.22468814253807068
Validation loss: 1.5164448612479753

Epoch: 5| Step: 3
Training loss: 0.20701685547828674
Validation loss: 1.5306429350247948

Epoch: 5| Step: 4
Training loss: 0.16167950630187988
Validation loss: 1.5340545972188313

Epoch: 5| Step: 5
Training loss: 0.4097653329372406
Validation loss: 1.5494153499603271

Epoch: 5| Step: 6
Training loss: 0.2997523248195648
Validation loss: 1.580640826174008

Epoch: 5| Step: 7
Training loss: 0.15057459473609924
Validation loss: 1.5724847771788155

Epoch: 5| Step: 8
Training loss: 0.20743727684020996
Validation loss: 1.546771219981614

Epoch: 5| Step: 9
Training loss: 0.2386365681886673
Validation loss: 1.539303469401534

Epoch: 5| Step: 10
Training loss: 0.2767230272293091
Validation loss: 1.564047404514846

Epoch: 373| Step: 0
Training loss: 0.2827351987361908
Validation loss: 1.5414186754534323

Epoch: 5| Step: 1
Training loss: 0.33456698060035706
Validation loss: 1.5430276086253505

Epoch: 5| Step: 2
Training loss: 0.17862731218338013
Validation loss: 1.524220960114592

Epoch: 5| Step: 3
Training loss: 0.2146306037902832
Validation loss: 1.526911404825026

Epoch: 5| Step: 4
Training loss: 0.3814220428466797
Validation loss: 1.541267459110547

Epoch: 5| Step: 5
Training loss: 0.2302629053592682
Validation loss: 1.5269766981883715

Epoch: 5| Step: 6
Training loss: 0.16761015355587006
Validation loss: 1.5489898855968187

Epoch: 5| Step: 7
Training loss: 0.2797277271747589
Validation loss: 1.6011516733836102

Epoch: 5| Step: 8
Training loss: 0.22478938102722168
Validation loss: 1.59214747400694

Epoch: 5| Step: 9
Training loss: 0.20250467956066132
Validation loss: 1.5731932514457292

Epoch: 5| Step: 10
Training loss: 0.0844748467206955
Validation loss: 1.5483135472061813

Epoch: 374| Step: 0
Training loss: 0.40795183181762695
Validation loss: 1.5241506779065697

Epoch: 5| Step: 1
Training loss: 0.2604662775993347
Validation loss: 1.5129146729746172

Epoch: 5| Step: 2
Training loss: 0.30046916007995605
Validation loss: 1.533387235415879

Epoch: 5| Step: 3
Training loss: 0.21418726444244385
Validation loss: 1.551273335692703

Epoch: 5| Step: 4
Training loss: 0.18560341000556946
Validation loss: 1.5441734028118912

Epoch: 5| Step: 5
Training loss: 0.4060226380825043
Validation loss: 1.5777862994901595

Epoch: 5| Step: 6
Training loss: 0.12982791662216187
Validation loss: 1.5511791949631066

Epoch: 5| Step: 7
Training loss: 0.2275783270597458
Validation loss: 1.569813834723606

Epoch: 5| Step: 8
Training loss: 0.1736007034778595
Validation loss: 1.5813142202233756

Epoch: 5| Step: 9
Training loss: 0.17342892289161682
Validation loss: 1.5839026512638215

Epoch: 5| Step: 10
Training loss: 0.111111119389534
Validation loss: 1.5567242996667021

Epoch: 375| Step: 0
Training loss: 0.2915971875190735
Validation loss: 1.5920994640678487

Epoch: 5| Step: 1
Training loss: 0.1477474421262741
Validation loss: 1.5730300257282872

Epoch: 5| Step: 2
Training loss: 0.2408992350101471
Validation loss: 1.5685031721668858

Epoch: 5| Step: 3
Training loss: 0.2812451124191284
Validation loss: 1.5418971917962516

Epoch: 5| Step: 4
Training loss: 0.13906440138816833
Validation loss: 1.5406141896401682

Epoch: 5| Step: 5
Training loss: 0.16046246886253357
Validation loss: 1.512295243560627

Epoch: 5| Step: 6
Training loss: 0.34748131036758423
Validation loss: 1.5445326707696403

Epoch: 5| Step: 7
Training loss: 0.22069425880908966
Validation loss: 1.5311362281922372

Epoch: 5| Step: 8
Training loss: 0.2646980881690979
Validation loss: 1.5225558460399669

Epoch: 5| Step: 9
Training loss: 0.1681930422782898
Validation loss: 1.5532993360232281

Epoch: 5| Step: 10
Training loss: 0.264200359582901
Validation loss: 1.5369997729537308

Epoch: 376| Step: 0
Training loss: 0.2944231629371643
Validation loss: 1.5524193638114518

Epoch: 5| Step: 1
Training loss: 0.15850010514259338
Validation loss: 1.5370350858216644

Epoch: 5| Step: 2
Training loss: 0.1641441136598587
Validation loss: 1.5436631530843756

Epoch: 5| Step: 3
Training loss: 0.15611881017684937
Validation loss: 1.5392248938160558

Epoch: 5| Step: 4
Training loss: 0.22305603325366974
Validation loss: 1.5425034005154845

Epoch: 5| Step: 5
Training loss: 0.34071364998817444
Validation loss: 1.5325448577122023

Epoch: 5| Step: 6
Training loss: 0.20574799180030823
Validation loss: 1.5311187018630326

Epoch: 5| Step: 7
Training loss: 0.36245283484458923
Validation loss: 1.5514159100030058

Epoch: 5| Step: 8
Training loss: 0.24492177367210388
Validation loss: 1.5593277074957406

Epoch: 5| Step: 9
Training loss: 0.19472305476665497
Validation loss: 1.585714614519509

Epoch: 5| Step: 10
Training loss: 0.17382806539535522
Validation loss: 1.5723957400168143

Epoch: 377| Step: 0
Training loss: 0.21002373099327087
Validation loss: 1.5813506822432242

Epoch: 5| Step: 1
Training loss: 0.2173704206943512
Validation loss: 1.5424964017765497

Epoch: 5| Step: 2
Training loss: 0.2467643767595291
Validation loss: 1.5792623976225495

Epoch: 5| Step: 3
Training loss: 0.14963693916797638
Validation loss: 1.5394691228866577

Epoch: 5| Step: 4
Training loss: 0.1708509773015976
Validation loss: 1.5587874433045745

Epoch: 5| Step: 5
Training loss: 0.13968384265899658
Validation loss: 1.541441366236697

Epoch: 5| Step: 6
Training loss: 0.19472463428974152
Validation loss: 1.5457778540990685

Epoch: 5| Step: 7
Training loss: 0.38882285356521606
Validation loss: 1.5388171429275184

Epoch: 5| Step: 8
Training loss: 0.1983165740966797
Validation loss: 1.5363976609322332

Epoch: 5| Step: 9
Training loss: 0.3026687204837799
Validation loss: 1.5226438955594135

Epoch: 5| Step: 10
Training loss: 0.2618357241153717
Validation loss: 1.511536221350393

Epoch: 378| Step: 0
Training loss: 0.3248220384120941
Validation loss: 1.5317655750500259

Epoch: 5| Step: 1
Training loss: 0.2706086039543152
Validation loss: 1.5292462161792222

Epoch: 5| Step: 2
Training loss: 0.23119929432868958
Validation loss: 1.5556047180647492

Epoch: 5| Step: 3
Training loss: 0.23160243034362793
Validation loss: 1.5510065632481729

Epoch: 5| Step: 4
Training loss: 0.35205283761024475
Validation loss: 1.5697372292959562

Epoch: 5| Step: 5
Training loss: 0.12399441003799438
Validation loss: 1.576339170496951

Epoch: 5| Step: 6
Training loss: 0.14099574089050293
Validation loss: 1.569855341347315

Epoch: 5| Step: 7
Training loss: 0.14813292026519775
Validation loss: 1.5512349605560303

Epoch: 5| Step: 8
Training loss: 0.13222679495811462
Validation loss: 1.5358924211994294

Epoch: 5| Step: 9
Training loss: 0.22111065685749054
Validation loss: 1.5599879282777027

Epoch: 5| Step: 10
Training loss: 0.26500770449638367
Validation loss: 1.5332370470928889

Epoch: 379| Step: 0
Training loss: 0.3760078549385071
Validation loss: 1.51042357888273

Epoch: 5| Step: 1
Training loss: 0.42310038208961487
Validation loss: 1.507925230969665

Epoch: 5| Step: 2
Training loss: 0.10698065906763077
Validation loss: 1.5213835534229074

Epoch: 5| Step: 3
Training loss: 0.16792932152748108
Validation loss: 1.5169470156392744

Epoch: 5| Step: 4
Training loss: 0.15279848873615265
Validation loss: 1.5557343447080223

Epoch: 5| Step: 5
Training loss: 0.27265653014183044
Validation loss: 1.573977308888589

Epoch: 5| Step: 6
Training loss: 0.1829138696193695
Validation loss: 1.5961068304636146

Epoch: 5| Step: 7
Training loss: 0.30147820711135864
Validation loss: 1.578713716999177

Epoch: 5| Step: 8
Training loss: 0.24172420799732208
Validation loss: 1.5406124284190517

Epoch: 5| Step: 9
Training loss: 0.15661782026290894
Validation loss: 1.552496507603635

Epoch: 5| Step: 10
Training loss: 0.15858151018619537
Validation loss: 1.5266044293680499

Epoch: 380| Step: 0
Training loss: 0.2892691195011139
Validation loss: 1.5220622862538984

Epoch: 5| Step: 1
Training loss: 0.5225699543952942
Validation loss: 1.5151616104187504

Epoch: 5| Step: 2
Training loss: 0.3045937120914459
Validation loss: 1.5417007528325564

Epoch: 5| Step: 3
Training loss: 0.149448961019516
Validation loss: 1.544497356619886

Epoch: 5| Step: 4
Training loss: 0.17313137650489807
Validation loss: 1.5430236542096702

Epoch: 5| Step: 5
Training loss: 0.130869060754776
Validation loss: 1.5594569765111452

Epoch: 5| Step: 6
Training loss: 0.10499560832977295
Validation loss: 1.5594324232429586

Epoch: 5| Step: 7
Training loss: 0.34983766078948975
Validation loss: 1.5734294627302436

Epoch: 5| Step: 8
Training loss: 0.10258544981479645
Validation loss: 1.57728821744201

Epoch: 5| Step: 9
Training loss: 0.2773270905017853
Validation loss: 1.554584127600475

Epoch: 5| Step: 10
Training loss: 0.11914143711328506
Validation loss: 1.5379218414265623

Epoch: 381| Step: 0
Training loss: 0.16802296042442322
Validation loss: 1.5443794317142938

Epoch: 5| Step: 1
Training loss: 0.35059303045272827
Validation loss: 1.5411449222154514

Epoch: 5| Step: 2
Training loss: 0.23253831267356873
Validation loss: 1.5392619166322934

Epoch: 5| Step: 3
Training loss: 0.16774240136146545
Validation loss: 1.5427124487456454

Epoch: 5| Step: 4
Training loss: 0.28595083951950073
Validation loss: 1.5675015987888459

Epoch: 5| Step: 5
Training loss: 0.18165311217308044
Validation loss: 1.5641530322772201

Epoch: 5| Step: 6
Training loss: 0.3137640357017517
Validation loss: 1.5440132310313563

Epoch: 5| Step: 7
Training loss: 0.11740671098232269
Validation loss: 1.5341020181614866

Epoch: 5| Step: 8
Training loss: 0.16484889388084412
Validation loss: 1.5257858883950017

Epoch: 5| Step: 9
Training loss: 0.20664215087890625
Validation loss: 1.5279759130170267

Epoch: 5| Step: 10
Training loss: 0.18703331053256989
Validation loss: 1.5459154767374839

Epoch: 382| Step: 0
Training loss: 0.20117183029651642
Validation loss: 1.5397100320426367

Epoch: 5| Step: 1
Training loss: 0.13025042414665222
Validation loss: 1.5534020008579377

Epoch: 5| Step: 2
Training loss: 0.11835084110498428
Validation loss: 1.5252795501421856

Epoch: 5| Step: 3
Training loss: 0.13480524718761444
Validation loss: 1.5270867514353927

Epoch: 5| Step: 4
Training loss: 0.20938023924827576
Validation loss: 1.5504122280305432

Epoch: 5| Step: 5
Training loss: 0.3005285859107971
Validation loss: 1.5300326379396583

Epoch: 5| Step: 6
Training loss: 0.29681092500686646
Validation loss: 1.5308738934096469

Epoch: 5| Step: 7
Training loss: 0.2272920161485672
Validation loss: 1.5278827977436844

Epoch: 5| Step: 8
Training loss: 0.34434977173805237
Validation loss: 1.518315484446864

Epoch: 5| Step: 9
Training loss: 0.23921003937721252
Validation loss: 1.5193383975695538

Epoch: 5| Step: 10
Training loss: 0.22406861186027527
Validation loss: 1.515966207750382

Epoch: 383| Step: 0
Training loss: 0.08208668231964111
Validation loss: 1.5097297635129703

Epoch: 5| Step: 1
Training loss: 0.26860305666923523
Validation loss: 1.4991308566062682

Epoch: 5| Step: 2
Training loss: 0.18269707262516022
Validation loss: 1.5460745929389872

Epoch: 5| Step: 3
Training loss: 0.34083789587020874
Validation loss: 1.5411340549427976

Epoch: 5| Step: 4
Training loss: 0.20575638115406036
Validation loss: 1.5114199987021826

Epoch: 5| Step: 5
Training loss: 0.13001540303230286
Validation loss: 1.5676333365901824

Epoch: 5| Step: 6
Training loss: 0.2938002049922943
Validation loss: 1.5487760125949819

Epoch: 5| Step: 7
Training loss: 0.19126854836940765
Validation loss: 1.5384933461425125

Epoch: 5| Step: 8
Training loss: 0.18729963898658752
Validation loss: 1.5348571885016657

Epoch: 5| Step: 9
Training loss: 0.24324221909046173
Validation loss: 1.5490387864010309

Epoch: 5| Step: 10
Training loss: 0.29236286878585815
Validation loss: 1.5142874615166777

Epoch: 384| Step: 0
Training loss: 0.2092568576335907
Validation loss: 1.5360119535077004

Epoch: 5| Step: 1
Training loss: 0.08802977949380875
Validation loss: 1.5474986209664294

Epoch: 5| Step: 2
Training loss: 0.20732364058494568
Validation loss: 1.537520634230747

Epoch: 5| Step: 3
Training loss: 0.28691110014915466
Validation loss: 1.5706430596690024

Epoch: 5| Step: 4
Training loss: 0.25169986486434937
Validation loss: 1.5670160349979196

Epoch: 5| Step: 5
Training loss: 0.14055564999580383
Validation loss: 1.5812461619736047

Epoch: 5| Step: 6
Training loss: 0.3769915997982025
Validation loss: 1.5325950896868141

Epoch: 5| Step: 7
Training loss: 0.15306636691093445
Validation loss: 1.5191608308463969

Epoch: 5| Step: 8
Training loss: 0.23233520984649658
Validation loss: 1.5259272513851043

Epoch: 5| Step: 9
Training loss: 0.19788077473640442
Validation loss: 1.4951665247640302

Epoch: 5| Step: 10
Training loss: 0.1604439616203308
Validation loss: 1.5176657784369685

Epoch: 385| Step: 0
Training loss: 0.17402046918869019
Validation loss: 1.4905999629728255

Epoch: 5| Step: 1
Training loss: 0.1797860562801361
Validation loss: 1.5195473586359332

Epoch: 5| Step: 2
Training loss: 0.276233047246933
Validation loss: 1.5299612604161745

Epoch: 5| Step: 3
Training loss: 0.22788052260875702
Validation loss: 1.5371227174676874

Epoch: 5| Step: 4
Training loss: 0.18188384175300598
Validation loss: 1.5364888893660678

Epoch: 5| Step: 5
Training loss: 0.17375290393829346
Validation loss: 1.552464190349784

Epoch: 5| Step: 6
Training loss: 0.22446808218955994
Validation loss: 1.5336518428658927

Epoch: 5| Step: 7
Training loss: 0.31980273127555847
Validation loss: 1.519963704129701

Epoch: 5| Step: 8
Training loss: 0.23353955149650574
Validation loss: 1.4830486518080517

Epoch: 5| Step: 9
Training loss: 0.2005663365125656
Validation loss: 1.4790761445158271

Epoch: 5| Step: 10
Training loss: 0.2181844264268875
Validation loss: 1.4904178047692904

Epoch: 386| Step: 0
Training loss: 0.34374508261680603
Validation loss: 1.4888078615229616

Epoch: 5| Step: 1
Training loss: 0.14678601920604706
Validation loss: 1.484727813351539

Epoch: 5| Step: 2
Training loss: 0.21041841804981232
Validation loss: 1.4954956513579174

Epoch: 5| Step: 3
Training loss: 0.3009736239910126
Validation loss: 1.5045923667569314

Epoch: 5| Step: 4
Training loss: 0.1334337592124939
Validation loss: 1.5173208034166725

Epoch: 5| Step: 5
Training loss: 0.3610071539878845
Validation loss: 1.5277771385767127

Epoch: 5| Step: 6
Training loss: 0.1807257980108261
Validation loss: 1.5145034969493907

Epoch: 5| Step: 7
Training loss: 0.12971192598342896
Validation loss: 1.505660609532428

Epoch: 5| Step: 8
Training loss: 0.3627435564994812
Validation loss: 1.488564310535308

Epoch: 5| Step: 9
Training loss: 0.13270168006420135
Validation loss: 1.5083135879167946

Epoch: 5| Step: 10
Training loss: 0.11884517967700958
Validation loss: 1.4899635596941876

Epoch: 387| Step: 0
Training loss: 0.29276901483535767
Validation loss: 1.5134526388619536

Epoch: 5| Step: 1
Training loss: 0.13986533880233765
Validation loss: 1.5228288391584992

Epoch: 5| Step: 2
Training loss: 0.18578672409057617
Validation loss: 1.554330724541859

Epoch: 5| Step: 3
Training loss: 0.2682218551635742
Validation loss: 1.573384154227472

Epoch: 5| Step: 4
Training loss: 0.11798135936260223
Validation loss: 1.5690391537963704

Epoch: 5| Step: 5
Training loss: 0.2685410678386688
Validation loss: 1.5877038778797272

Epoch: 5| Step: 6
Training loss: 0.19923794269561768
Validation loss: 1.5357284366443593

Epoch: 5| Step: 7
Training loss: 0.1845112144947052
Validation loss: 1.5430299851202196

Epoch: 5| Step: 8
Training loss: 0.2641077935695648
Validation loss: 1.5334751388078094

Epoch: 5| Step: 9
Training loss: 0.16181883215904236
Validation loss: 1.518799263943908

Epoch: 5| Step: 10
Training loss: 0.17608210444450378
Validation loss: 1.5204045323915378

Epoch: 388| Step: 0
Training loss: 0.16920106112957
Validation loss: 1.5428006315744052

Epoch: 5| Step: 1
Training loss: 0.16375377774238586
Validation loss: 1.5537691026605585

Epoch: 5| Step: 2
Training loss: 0.31314653158187866
Validation loss: 1.5216327700563657

Epoch: 5| Step: 3
Training loss: 0.1236042007803917
Validation loss: 1.5542307451207151

Epoch: 5| Step: 4
Training loss: 0.218821719288826
Validation loss: 1.5289808704007057

Epoch: 5| Step: 5
Training loss: 0.2669912874698639
Validation loss: 1.5491317869514547

Epoch: 5| Step: 6
Training loss: 0.2103554755449295
Validation loss: 1.528215177597538

Epoch: 5| Step: 7
Training loss: 0.2684505581855774
Validation loss: 1.5141682470998457

Epoch: 5| Step: 8
Training loss: 0.25919321179389954
Validation loss: 1.5325803769532071

Epoch: 5| Step: 9
Training loss: 0.1945010870695114
Validation loss: 1.550393242989817

Epoch: 5| Step: 10
Training loss: 0.15350191295146942
Validation loss: 1.5304278058390464

Epoch: 389| Step: 0
Training loss: 0.16352148354053497
Validation loss: 1.523106199438854

Epoch: 5| Step: 1
Training loss: 0.1953662633895874
Validation loss: 1.5311796498555008

Epoch: 5| Step: 2
Training loss: 0.3089246153831482
Validation loss: 1.550356763665394

Epoch: 5| Step: 3
Training loss: 0.1425226330757141
Validation loss: 1.5593023332216407

Epoch: 5| Step: 4
Training loss: 0.19526407122612
Validation loss: 1.5402425181481145

Epoch: 5| Step: 5
Training loss: 0.22172629833221436
Validation loss: 1.5486993558945195

Epoch: 5| Step: 6
Training loss: 0.3223152160644531
Validation loss: 1.5727527718390188

Epoch: 5| Step: 7
Training loss: 0.18297572433948517
Validation loss: 1.561687441282375

Epoch: 5| Step: 8
Training loss: 0.25017568469047546
Validation loss: 1.5091583158380242

Epoch: 5| Step: 9
Training loss: 0.3786936402320862
Validation loss: 1.5023575675102971

Epoch: 5| Step: 10
Training loss: 0.17369228601455688
Validation loss: 1.511780467084659

Epoch: 390| Step: 0
Training loss: 0.1707717627286911
Validation loss: 1.5408896464173512

Epoch: 5| Step: 1
Training loss: 0.1200547069311142
Validation loss: 1.559593758275432

Epoch: 5| Step: 2
Training loss: 0.33391115069389343
Validation loss: 1.5584193993640203

Epoch: 5| Step: 3
Training loss: 0.2232309877872467
Validation loss: 1.5546609496557584

Epoch: 5| Step: 4
Training loss: 0.11930842697620392
Validation loss: 1.5468742001441218

Epoch: 5| Step: 5
Training loss: 0.20626115798950195
Validation loss: 1.5144399878799275

Epoch: 5| Step: 6
Training loss: 0.20061974227428436
Validation loss: 1.5275073474453342

Epoch: 5| Step: 7
Training loss: 0.14447519183158875
Validation loss: 1.5316761552646596

Epoch: 5| Step: 8
Training loss: 0.36118683218955994
Validation loss: 1.4959433155675088

Epoch: 5| Step: 9
Training loss: 0.2025725394487381
Validation loss: 1.5278653867783085

Epoch: 5| Step: 10
Training loss: 0.18912817537784576
Validation loss: 1.528726698249899

Epoch: 391| Step: 0
Training loss: 0.0751321017742157
Validation loss: 1.520222266515096

Epoch: 5| Step: 1
Training loss: 0.3052387237548828
Validation loss: 1.5296448353798158

Epoch: 5| Step: 2
Training loss: 0.14213505387306213
Validation loss: 1.5294896518030474

Epoch: 5| Step: 3
Training loss: 0.17508240044116974
Validation loss: 1.5619746369700278

Epoch: 5| Step: 4
Training loss: 0.11657895892858505
Validation loss: 1.5279285600108485

Epoch: 5| Step: 5
Training loss: 0.17858095467090607
Validation loss: 1.5465854444811422

Epoch: 5| Step: 6
Training loss: 0.28111499547958374
Validation loss: 1.5499022635080482

Epoch: 5| Step: 7
Training loss: 0.3299766480922699
Validation loss: 1.5551176481349493

Epoch: 5| Step: 8
Training loss: 0.18267640471458435
Validation loss: 1.5452146562196876

Epoch: 5| Step: 9
Training loss: 0.2618013322353363
Validation loss: 1.5478115357378477

Epoch: 5| Step: 10
Training loss: 0.24241173267364502
Validation loss: 1.53614552046663

Epoch: 392| Step: 0
Training loss: 0.3465767204761505
Validation loss: 1.5394356237944735

Epoch: 5| Step: 1
Training loss: 0.1363503634929657
Validation loss: 1.5255970570348925

Epoch: 5| Step: 2
Training loss: 0.13006660342216492
Validation loss: 1.5397045343152937

Epoch: 5| Step: 3
Training loss: 0.06354956328868866
Validation loss: 1.5117907742018342

Epoch: 5| Step: 4
Training loss: 0.16791856288909912
Validation loss: 1.5339565533463673

Epoch: 5| Step: 5
Training loss: 0.2864350378513336
Validation loss: 1.5027235297746555

Epoch: 5| Step: 6
Training loss: 0.3306209444999695
Validation loss: 1.4998456098700081

Epoch: 5| Step: 7
Training loss: 0.1836359202861786
Validation loss: 1.5158249972968973

Epoch: 5| Step: 8
Training loss: 0.2230280190706253
Validation loss: 1.4953203931931527

Epoch: 5| Step: 9
Training loss: 0.1674659550189972
Validation loss: 1.5059173030237998

Epoch: 5| Step: 10
Training loss: 0.3429686725139618
Validation loss: 1.5460267861684163

Epoch: 393| Step: 0
Training loss: 0.2837141156196594
Validation loss: 1.534569489058628

Epoch: 5| Step: 1
Training loss: 0.16093917191028595
Validation loss: 1.5600918980054959

Epoch: 5| Step: 2
Training loss: 0.143498495221138
Validation loss: 1.5357209482500631

Epoch: 5| Step: 3
Training loss: 0.14885826408863068
Validation loss: 1.52512115047824

Epoch: 5| Step: 4
Training loss: 0.282641738653183
Validation loss: 1.529194378083752

Epoch: 5| Step: 5
Training loss: 0.2620337903499603
Validation loss: 1.5057844846479354

Epoch: 5| Step: 6
Training loss: 0.10999476909637451
Validation loss: 1.5305583592384093

Epoch: 5| Step: 7
Training loss: 0.17746861279010773
Validation loss: 1.5413242719506706

Epoch: 5| Step: 8
Training loss: 0.2514628767967224
Validation loss: 1.5390677298268964

Epoch: 5| Step: 9
Training loss: 0.26601094007492065
Validation loss: 1.5603575174526503

Epoch: 5| Step: 10
Training loss: 0.2261684685945511
Validation loss: 1.5532038102867782

Epoch: 394| Step: 0
Training loss: 0.133746936917305
Validation loss: 1.5458211232257146

Epoch: 5| Step: 1
Training loss: 0.11011886596679688
Validation loss: 1.5261856907157487

Epoch: 5| Step: 2
Training loss: 0.12734317779541016
Validation loss: 1.5113596864925918

Epoch: 5| Step: 3
Training loss: 0.07415549457073212
Validation loss: 1.4927770091641335

Epoch: 5| Step: 4
Training loss: 0.25023549795150757
Validation loss: 1.5237589036264727

Epoch: 5| Step: 5
Training loss: 0.3789873719215393
Validation loss: 1.5347822545677103

Epoch: 5| Step: 6
Training loss: 0.3345949351787567
Validation loss: 1.5426632165908813

Epoch: 5| Step: 7
Training loss: 0.19130146503448486
Validation loss: 1.561764895275075

Epoch: 5| Step: 8
Training loss: 0.23566801846027374
Validation loss: 1.5467267305620256

Epoch: 5| Step: 9
Training loss: 0.14600519835948944
Validation loss: 1.5531406171860234

Epoch: 5| Step: 10
Training loss: 0.18794873356819153
Validation loss: 1.5404122074445088

Epoch: 395| Step: 0
Training loss: 0.1455840766429901
Validation loss: 1.523506567042361

Epoch: 5| Step: 1
Training loss: 0.14985673129558563
Validation loss: 1.5059414576458674

Epoch: 5| Step: 2
Training loss: 0.4607314467430115
Validation loss: 1.5193928967240036

Epoch: 5| Step: 3
Training loss: 0.18530920147895813
Validation loss: 1.5122429709280691

Epoch: 5| Step: 4
Training loss: 0.1346263587474823
Validation loss: 1.5362996824326054

Epoch: 5| Step: 5
Training loss: 0.1378793716430664
Validation loss: 1.5332441047955585

Epoch: 5| Step: 6
Training loss: 0.3058318495750427
Validation loss: 1.5407001715834423

Epoch: 5| Step: 7
Training loss: 0.1799006313085556
Validation loss: 1.5302533590665428

Epoch: 5| Step: 8
Training loss: 0.10159637778997421
Validation loss: 1.5492290707044705

Epoch: 5| Step: 9
Training loss: 0.19375887513160706
Validation loss: 1.5373973948981172

Epoch: 5| Step: 10
Training loss: 0.21667775511741638
Validation loss: 1.5393710687596311

Epoch: 396| Step: 0
Training loss: 0.2859906852245331
Validation loss: 1.520778291968889

Epoch: 5| Step: 1
Training loss: 0.09470675885677338
Validation loss: 1.5085574273140199

Epoch: 5| Step: 2
Training loss: 0.18022456765174866
Validation loss: 1.5254545493792462

Epoch: 5| Step: 3
Training loss: 0.33368223905563354
Validation loss: 1.497217405867833

Epoch: 5| Step: 4
Training loss: 0.1600259244441986
Validation loss: 1.5040421267991424

Epoch: 5| Step: 5
Training loss: 0.2399284392595291
Validation loss: 1.5153437006858088

Epoch: 5| Step: 6
Training loss: 0.3395281434059143
Validation loss: 1.5361486147808772

Epoch: 5| Step: 7
Training loss: 0.22673742473125458
Validation loss: 1.5721144586481073

Epoch: 5| Step: 8
Training loss: 0.16173945367336273
Validation loss: 1.5493818694545376

Epoch: 5| Step: 9
Training loss: 0.16665709018707275
Validation loss: 1.5331917334628362

Epoch: 5| Step: 10
Training loss: 0.19729480147361755
Validation loss: 1.54839627973495

Epoch: 397| Step: 0
Training loss: 0.3438928425312042
Validation loss: 1.5370938726650771

Epoch: 5| Step: 1
Training loss: 0.28832951188087463
Validation loss: 1.5421836401826592

Epoch: 5| Step: 2
Training loss: 0.35711637139320374
Validation loss: 1.5401982479198004

Epoch: 5| Step: 3
Training loss: 0.15079379081726074
Validation loss: 1.5337501411796899

Epoch: 5| Step: 4
Training loss: 0.2298467606306076
Validation loss: 1.541836695004535

Epoch: 5| Step: 5
Training loss: 0.0838003158569336
Validation loss: 1.5395368863177556

Epoch: 5| Step: 6
Training loss: 0.16024582087993622
Validation loss: 1.5377579132715862

Epoch: 5| Step: 7
Training loss: 0.10115699470043182
Validation loss: 1.5557478409941479

Epoch: 5| Step: 8
Training loss: 0.09790187329053879
Validation loss: 1.559140295110723

Epoch: 5| Step: 9
Training loss: 0.22398774325847626
Validation loss: 1.5454449474170644

Epoch: 5| Step: 10
Training loss: 0.1380978524684906
Validation loss: 1.542825186124412

Epoch: 398| Step: 0
Training loss: 0.1785205900669098
Validation loss: 1.5172244387288247

Epoch: 5| Step: 1
Training loss: 0.1459532082080841
Validation loss: 1.5165173084505144

Epoch: 5| Step: 2
Training loss: 0.4166600704193115
Validation loss: 1.5114555140977264

Epoch: 5| Step: 3
Training loss: 0.1953747719526291
Validation loss: 1.5411967385199763

Epoch: 5| Step: 4
Training loss: 0.15953458845615387
Validation loss: 1.5355655442001999

Epoch: 5| Step: 5
Training loss: 0.21944764256477356
Validation loss: 1.5640019191208707

Epoch: 5| Step: 6
Training loss: 0.25487709045410156
Validation loss: 1.5369485155228646

Epoch: 5| Step: 7
Training loss: 0.1462523192167282
Validation loss: 1.5464092070056545

Epoch: 5| Step: 8
Training loss: 0.1454775631427765
Validation loss: 1.543475697117467

Epoch: 5| Step: 9
Training loss: 0.14951367676258087
Validation loss: 1.5492702735367643

Epoch: 5| Step: 10
Training loss: 0.24041102826595306
Validation loss: 1.546129595848822

Epoch: 399| Step: 0
Training loss: 0.18105831742286682
Validation loss: 1.5172020555824361

Epoch: 5| Step: 1
Training loss: 0.16977059841156006
Validation loss: 1.5297068357467651

Epoch: 5| Step: 2
Training loss: 0.23310010135173798
Validation loss: 1.5421368511774207

Epoch: 5| Step: 3
Training loss: 0.12992136180400848
Validation loss: 1.5365973557195356

Epoch: 5| Step: 4
Training loss: 0.22191277146339417
Validation loss: 1.5517414539091048

Epoch: 5| Step: 5
Training loss: 0.21651630103588104
Validation loss: 1.5486061367937314

Epoch: 5| Step: 6
Training loss: 0.22610309720039368
Validation loss: 1.5519223059377363

Epoch: 5| Step: 7
Training loss: 0.14912669360637665
Validation loss: 1.5498102044546476

Epoch: 5| Step: 8
Training loss: 0.2751152813434601
Validation loss: 1.526367473345931

Epoch: 5| Step: 9
Training loss: 0.15752184391021729
Validation loss: 1.5189078892430952

Epoch: 5| Step: 10
Training loss: 0.1518532782793045
Validation loss: 1.4948209998428181

Epoch: 400| Step: 0
Training loss: 0.14787010848522186
Validation loss: 1.5082487636996853

Epoch: 5| Step: 1
Training loss: 0.08163319528102875
Validation loss: 1.5038088688286402

Epoch: 5| Step: 2
Training loss: 0.13040199875831604
Validation loss: 1.5071232447060205

Epoch: 5| Step: 3
Training loss: 0.3853558897972107
Validation loss: 1.4929525954748994

Epoch: 5| Step: 4
Training loss: 0.10391321033239365
Validation loss: 1.5106984979362899

Epoch: 5| Step: 5
Training loss: 0.1793861836194992
Validation loss: 1.5295670840048021

Epoch: 5| Step: 6
Training loss: 0.24806490540504456
Validation loss: 1.5274992194226993

Epoch: 5| Step: 7
Training loss: 0.23847930133342743
Validation loss: 1.5137992699940999

Epoch: 5| Step: 8
Training loss: 0.2136273831129074
Validation loss: 1.503001033618886

Epoch: 5| Step: 9
Training loss: 0.3161078989505768
Validation loss: 1.5110433716927805

Epoch: 5| Step: 10
Training loss: 0.1838071048259735
Validation loss: 1.522861337149015

Epoch: 401| Step: 0
Training loss: 0.18733251094818115
Validation loss: 1.5188345268208494

Epoch: 5| Step: 1
Training loss: 0.22707700729370117
Validation loss: 1.4984507124911073

Epoch: 5| Step: 2
Training loss: 0.10131508111953735
Validation loss: 1.5125987273390575

Epoch: 5| Step: 3
Training loss: 0.2502066493034363
Validation loss: 1.530586297794055

Epoch: 5| Step: 4
Training loss: 0.1062462106347084
Validation loss: 1.5335571599263016

Epoch: 5| Step: 5
Training loss: 0.35577505826950073
Validation loss: 1.5271645028104064

Epoch: 5| Step: 6
Training loss: 0.10328616946935654
Validation loss: 1.5223987153781358

Epoch: 5| Step: 7
Training loss: 0.3256368041038513
Validation loss: 1.5200881150461012

Epoch: 5| Step: 8
Training loss: 0.21110686659812927
Validation loss: 1.5190272215873963

Epoch: 5| Step: 9
Training loss: 0.15729475021362305
Validation loss: 1.5353606695769935

Epoch: 5| Step: 10
Training loss: 0.1695682257413864
Validation loss: 1.5349327197638891

Epoch: 402| Step: 0
Training loss: 0.2845093309879303
Validation loss: 1.5433070928819719

Epoch: 5| Step: 1
Training loss: 0.2055574655532837
Validation loss: 1.5204461325881302

Epoch: 5| Step: 2
Training loss: 0.2031814306974411
Validation loss: 1.517855086634236

Epoch: 5| Step: 3
Training loss: 0.17421817779541016
Validation loss: 1.4896635278578727

Epoch: 5| Step: 4
Training loss: 0.18502500653266907
Validation loss: 1.514037839827999

Epoch: 5| Step: 5
Training loss: 0.1688653528690338
Validation loss: 1.5153104989759383

Epoch: 5| Step: 6
Training loss: 0.11959347873926163
Validation loss: 1.522473830048756

Epoch: 5| Step: 7
Training loss: 0.2202008217573166
Validation loss: 1.5287507387899584

Epoch: 5| Step: 8
Training loss: 0.15353313088417053
Validation loss: 1.5249925941549323

Epoch: 5| Step: 9
Training loss: 0.27322059869766235
Validation loss: 1.5218450382191648

Epoch: 5| Step: 10
Training loss: 0.18853367865085602
Validation loss: 1.5288835366566975

Epoch: 403| Step: 0
Training loss: 0.23746061325073242
Validation loss: 1.5633884322258733

Epoch: 5| Step: 1
Training loss: 0.2659173011779785
Validation loss: 1.5767115803175076

Epoch: 5| Step: 2
Training loss: 0.16409000754356384
Validation loss: 1.5907335025008007

Epoch: 5| Step: 3
Training loss: 0.14536693692207336
Validation loss: 1.582515473006874

Epoch: 5| Step: 4
Training loss: 0.17045636475086212
Validation loss: 1.564510626177634

Epoch: 5| Step: 5
Training loss: 0.14446356892585754
Validation loss: 1.5509048431150374

Epoch: 5| Step: 6
Training loss: 0.40104690194129944
Validation loss: 1.513563230473508

Epoch: 5| Step: 7
Training loss: 0.11358337104320526
Validation loss: 1.5013093217726676

Epoch: 5| Step: 8
Training loss: 0.16913707554340363
Validation loss: 1.5070514537954842

Epoch: 5| Step: 9
Training loss: 0.15339341759681702
Validation loss: 1.520662389775758

Epoch: 5| Step: 10
Training loss: 0.17884540557861328
Validation loss: 1.5384451522622058

Epoch: 404| Step: 0
Training loss: 0.14597955346107483
Validation loss: 1.5592632524428829

Epoch: 5| Step: 1
Training loss: 0.11826562881469727
Validation loss: 1.5315268424249464

Epoch: 5| Step: 2
Training loss: 0.32270511984825134
Validation loss: 1.533554600131127

Epoch: 5| Step: 3
Training loss: 0.22767610847949982
Validation loss: 1.5574372007000832

Epoch: 5| Step: 4
Training loss: 0.23029978573322296
Validation loss: 1.5590327849952124

Epoch: 5| Step: 5
Training loss: 0.1643313467502594
Validation loss: 1.5499752260023547

Epoch: 5| Step: 6
Training loss: 0.11998434364795685
Validation loss: 1.5433302002568399

Epoch: 5| Step: 7
Training loss: 0.22517314553260803
Validation loss: 1.5336154737780172

Epoch: 5| Step: 8
Training loss: 0.3019620180130005
Validation loss: 1.5226000342317807

Epoch: 5| Step: 9
Training loss: 0.20172157883644104
Validation loss: 1.539568220415423

Epoch: 5| Step: 10
Training loss: 0.14638368785381317
Validation loss: 1.5511287373881186

Epoch: 405| Step: 0
Training loss: 0.16194069385528564
Validation loss: 1.5331043043444235

Epoch: 5| Step: 1
Training loss: 0.10303530842065811
Validation loss: 1.535196783722088

Epoch: 5| Step: 2
Training loss: 0.19690458476543427
Validation loss: 1.5394099899517593

Epoch: 5| Step: 3
Training loss: 0.16811016201972961
Validation loss: 1.54520833364097

Epoch: 5| Step: 4
Training loss: 0.3493770658969879
Validation loss: 1.5385852359956311

Epoch: 5| Step: 5
Training loss: 0.27406078577041626
Validation loss: 1.527608520882104

Epoch: 5| Step: 6
Training loss: 0.138797327876091
Validation loss: 1.5435135569623721

Epoch: 5| Step: 7
Training loss: 0.22666744887828827
Validation loss: 1.5255920925448019

Epoch: 5| Step: 8
Training loss: 0.12181806564331055
Validation loss: 1.5381717528066328

Epoch: 5| Step: 9
Training loss: 0.10590382665395737
Validation loss: 1.5260499190258723

Epoch: 5| Step: 10
Training loss: 0.15182572603225708
Validation loss: 1.5289716348853162

Epoch: 406| Step: 0
Training loss: 0.11836888641119003
Validation loss: 1.501881916035888

Epoch: 5| Step: 1
Training loss: 0.15218785405158997
Validation loss: 1.5010838944424865

Epoch: 5| Step: 2
Training loss: 0.17225126922130585
Validation loss: 1.5025599374566028

Epoch: 5| Step: 3
Training loss: 0.14296042919158936
Validation loss: 1.5145581242858723

Epoch: 5| Step: 4
Training loss: 0.23675045371055603
Validation loss: 1.5410377261459187

Epoch: 5| Step: 5
Training loss: 0.20281465351581573
Validation loss: 1.495583809832091

Epoch: 5| Step: 6
Training loss: 0.15443143248558044
Validation loss: 1.5370116797826623

Epoch: 5| Step: 7
Training loss: 0.13763578236103058
Validation loss: 1.499150009565456

Epoch: 5| Step: 8
Training loss: 0.35360655188560486
Validation loss: 1.5078226802169636

Epoch: 5| Step: 9
Training loss: 0.22899813950061798
Validation loss: 1.4957584027321107

Epoch: 5| Step: 10
Training loss: 0.11354824900627136
Validation loss: 1.522608325045596

Epoch: 407| Step: 0
Training loss: 0.14008699357509613
Validation loss: 1.4928894465969456

Epoch: 5| Step: 1
Training loss: 0.11960829794406891
Validation loss: 1.5094843244039884

Epoch: 5| Step: 2
Training loss: 0.17720310389995575
Validation loss: 1.5191179475476664

Epoch: 5| Step: 3
Training loss: 0.15238964557647705
Validation loss: 1.5222080907514017

Epoch: 5| Step: 4
Training loss: 0.16194723546504974
Validation loss: 1.5089424899829331

Epoch: 5| Step: 5
Training loss: 0.09737016260623932
Validation loss: 1.523475673890883

Epoch: 5| Step: 6
Training loss: 0.17136256396770477
Validation loss: 1.5369305995202833

Epoch: 5| Step: 7
Training loss: 0.19857218861579895
Validation loss: 1.532520399298719

Epoch: 5| Step: 8
Training loss: 0.46586328744888306
Validation loss: 1.5343528306612404

Epoch: 5| Step: 9
Training loss: 0.10506479442119598
Validation loss: 1.52573856230705

Epoch: 5| Step: 10
Training loss: 0.26918426156044006
Validation loss: 1.5111668263712237

Epoch: 408| Step: 0
Training loss: 0.22031912207603455
Validation loss: 1.5022941174045685

Epoch: 5| Step: 1
Training loss: 0.10157251358032227
Validation loss: 1.5252953819049302

Epoch: 5| Step: 2
Training loss: 0.16093340516090393
Validation loss: 1.4953534731300928

Epoch: 5| Step: 3
Training loss: 0.18394842743873596
Validation loss: 1.511321650397393

Epoch: 5| Step: 4
Training loss: 0.18628890812397003
Validation loss: 1.507305432391423

Epoch: 5| Step: 5
Training loss: 0.15488465130329132
Validation loss: 1.515120711377872

Epoch: 5| Step: 6
Training loss: 0.17548033595085144
Validation loss: 1.526679688884366

Epoch: 5| Step: 7
Training loss: 0.21967172622680664
Validation loss: 1.5239675814105618

Epoch: 5| Step: 8
Training loss: 0.3551742434501648
Validation loss: 1.549392229767256

Epoch: 5| Step: 9
Training loss: 0.2465856820344925
Validation loss: 1.528589751130791

Epoch: 5| Step: 10
Training loss: 0.07625065743923187
Validation loss: 1.5166590944413216

Epoch: 409| Step: 0
Training loss: 0.14265744388103485
Validation loss: 1.5237719948573778

Epoch: 5| Step: 1
Training loss: 0.16305580735206604
Validation loss: 1.5334116207656039

Epoch: 5| Step: 2
Training loss: 0.1496981680393219
Validation loss: 1.5182934217555548

Epoch: 5| Step: 3
Training loss: 0.27507519721984863
Validation loss: 1.5315357010851625

Epoch: 5| Step: 4
Training loss: 0.12142584472894669
Validation loss: 1.5372003778334586

Epoch: 5| Step: 5
Training loss: 0.1553836613893509
Validation loss: 1.5416352313051942

Epoch: 5| Step: 6
Training loss: 0.19241651892662048
Validation loss: 1.5708221991856892

Epoch: 5| Step: 7
Training loss: 0.24309952557086945
Validation loss: 1.5729528024632444

Epoch: 5| Step: 8
Training loss: 0.23601463437080383
Validation loss: 1.5765326164102043

Epoch: 5| Step: 9
Training loss: 0.2354995310306549
Validation loss: 1.596564253171285

Epoch: 5| Step: 10
Training loss: 0.18624399602413177
Validation loss: 1.5627475015578731

Epoch: 410| Step: 0
Training loss: 0.09075169265270233
Validation loss: 1.5567848323493876

Epoch: 5| Step: 1
Training loss: 0.10141142457723618
Validation loss: 1.5164704489451584

Epoch: 5| Step: 2
Training loss: 0.20086602866649628
Validation loss: 1.5388737750309769

Epoch: 5| Step: 3
Training loss: 0.12929369509220123
Validation loss: 1.5225505341765702

Epoch: 5| Step: 4
Training loss: 0.18921718001365662
Validation loss: 1.5146883264664681

Epoch: 5| Step: 5
Training loss: 0.17307181656360626
Validation loss: 1.5213579567529822

Epoch: 5| Step: 6
Training loss: 0.15805697441101074
Validation loss: 1.5124891778474212

Epoch: 5| Step: 7
Training loss: 0.23582473397254944
Validation loss: 1.5478783269082346

Epoch: 5| Step: 8
Training loss: 0.23074059188365936
Validation loss: 1.5351316634044851

Epoch: 5| Step: 9
Training loss: 0.20553264021873474
Validation loss: 1.516510223829618

Epoch: 5| Step: 10
Training loss: 0.3354233205318451
Validation loss: 1.5049331624020812

Epoch: 411| Step: 0
Training loss: 0.09633871167898178
Validation loss: 1.4878958553396247

Epoch: 5| Step: 1
Training loss: 0.1927613466978073
Validation loss: 1.511816059389422

Epoch: 5| Step: 2
Training loss: 0.28906744718551636
Validation loss: 1.4826092598258809

Epoch: 5| Step: 3
Training loss: 0.19834864139556885
Validation loss: 1.4927062796008201

Epoch: 5| Step: 4
Training loss: 0.15861766040325165
Validation loss: 1.493842795330991

Epoch: 5| Step: 5
Training loss: 0.13617923855781555
Validation loss: 1.4454468245147376

Epoch: 5| Step: 6
Training loss: 0.3422934412956238
Validation loss: 1.4795807177020657

Epoch: 5| Step: 7
Training loss: 0.16210675239562988
Validation loss: 1.5001719843956731

Epoch: 5| Step: 8
Training loss: 0.16972298920154572
Validation loss: 1.511296993942671

Epoch: 5| Step: 9
Training loss: 0.21739737689495087
Validation loss: 1.4890233419274772

Epoch: 5| Step: 10
Training loss: 0.09401824325323105
Validation loss: 1.4751518887858237

Epoch: 412| Step: 0
Training loss: 0.1600809395313263
Validation loss: 1.437131151076286

Epoch: 5| Step: 1
Training loss: 0.11627157032489777
Validation loss: 1.4746788445339407

Epoch: 5| Step: 2
Training loss: 0.1773853600025177
Validation loss: 1.4652776090047692

Epoch: 5| Step: 3
Training loss: 0.1555999219417572
Validation loss: 1.5000861370435326

Epoch: 5| Step: 4
Training loss: 0.2817491888999939
Validation loss: 1.5297865893251152

Epoch: 5| Step: 5
Training loss: 0.16795071959495544
Validation loss: 1.5185853319783365

Epoch: 5| Step: 6
Training loss: 0.2863335907459259
Validation loss: 1.494765394477434

Epoch: 5| Step: 7
Training loss: 0.12609031796455383
Validation loss: 1.5204686246892458

Epoch: 5| Step: 8
Training loss: 0.18740350008010864
Validation loss: 1.5368932408671225

Epoch: 5| Step: 9
Training loss: 0.2525790333747864
Validation loss: 1.53467131686467

Epoch: 5| Step: 10
Training loss: 0.1810920536518097
Validation loss: 1.5252702966813119

Epoch: 413| Step: 0
Training loss: 0.15026193857192993
Validation loss: 1.5125988548801792

Epoch: 5| Step: 1
Training loss: 0.22460579872131348
Validation loss: 1.5018622272758073

Epoch: 5| Step: 2
Training loss: 0.19050171971321106
Validation loss: 1.5075145152307325

Epoch: 5| Step: 3
Training loss: 0.19345800578594208
Validation loss: 1.4930055372176632

Epoch: 5| Step: 4
Training loss: 0.15489892661571503
Validation loss: 1.529686229203337

Epoch: 5| Step: 5
Training loss: 0.2709982991218567
Validation loss: 1.500352668505843

Epoch: 5| Step: 6
Training loss: 0.22779850661754608
Validation loss: 1.5456456535605974

Epoch: 5| Step: 7
Training loss: 0.15421147644519806
Validation loss: 1.5522691485702351

Epoch: 5| Step: 8
Training loss: 0.17563459277153015
Validation loss: 1.5600160078335834

Epoch: 5| Step: 9
Training loss: 0.18635988235473633
Validation loss: 1.5196445436887844

Epoch: 5| Step: 10
Training loss: 0.13520675897598267
Validation loss: 1.5065144608097691

Epoch: 414| Step: 0
Training loss: 0.237168550491333
Validation loss: 1.4900424083073933

Epoch: 5| Step: 1
Training loss: 0.15080538392066956
Validation loss: 1.4804172426141717

Epoch: 5| Step: 2
Training loss: 0.18995440006256104
Validation loss: 1.4840572886569525

Epoch: 5| Step: 3
Training loss: 0.1956387460231781
Validation loss: 1.4827224746827157

Epoch: 5| Step: 4
Training loss: 0.17133642733097076
Validation loss: 1.4720274402249245

Epoch: 5| Step: 5
Training loss: 0.130163311958313
Validation loss: 1.5072984195524646

Epoch: 5| Step: 6
Training loss: 0.3516853451728821
Validation loss: 1.4774181522348875

Epoch: 5| Step: 7
Training loss: 0.1415438950061798
Validation loss: 1.483687687304712

Epoch: 5| Step: 8
Training loss: 0.18572098016738892
Validation loss: 1.4962488284675024

Epoch: 5| Step: 9
Training loss: 0.17108598351478577
Validation loss: 1.5126864487125027

Epoch: 5| Step: 10
Training loss: 0.12564527988433838
Validation loss: 1.4952827307485765

Epoch: 415| Step: 0
Training loss: 0.11704349517822266
Validation loss: 1.5196488557323333

Epoch: 5| Step: 1
Training loss: 0.335273414850235
Validation loss: 1.5441369843739334

Epoch: 5| Step: 2
Training loss: 0.20181116461753845
Validation loss: 1.5075219754249818

Epoch: 5| Step: 3
Training loss: 0.19271263480186462
Validation loss: 1.506688384599583

Epoch: 5| Step: 4
Training loss: 0.18861034512519836
Validation loss: 1.4915894340443354

Epoch: 5| Step: 5
Training loss: 0.225542813539505
Validation loss: 1.4717732475649925

Epoch: 5| Step: 6
Training loss: 0.12176583707332611
Validation loss: 1.482619588093091

Epoch: 5| Step: 7
Training loss: 0.20945163071155548
Validation loss: 1.4761632565529115

Epoch: 5| Step: 8
Training loss: 0.10388300567865372
Validation loss: 1.4732448439444266

Epoch: 5| Step: 9
Training loss: 0.1580110490322113
Validation loss: 1.4743526122903312

Epoch: 5| Step: 10
Training loss: 0.1863146722316742
Validation loss: 1.4955321588823873

Epoch: 416| Step: 0
Training loss: 0.0998746007680893
Validation loss: 1.4878712020894533

Epoch: 5| Step: 1
Training loss: 0.1768053025007248
Validation loss: 1.4994969009071268

Epoch: 5| Step: 2
Training loss: 0.12706544995307922
Validation loss: 1.5218977107796618

Epoch: 5| Step: 3
Training loss: 0.2143649309873581
Validation loss: 1.5091340811021867

Epoch: 5| Step: 4
Training loss: 0.3979124426841736
Validation loss: 1.5027286955105361

Epoch: 5| Step: 5
Training loss: 0.1444619596004486
Validation loss: 1.4938865150174787

Epoch: 5| Step: 6
Training loss: 0.1410350352525711
Validation loss: 1.5055135411600913

Epoch: 5| Step: 7
Training loss: 0.12199096381664276
Validation loss: 1.512932082658173

Epoch: 5| Step: 8
Training loss: 0.17967776954174042
Validation loss: 1.502961730444303

Epoch: 5| Step: 9
Training loss: 0.17078125476837158
Validation loss: 1.5068417492733206

Epoch: 5| Step: 10
Training loss: 0.15496379137039185
Validation loss: 1.5138747551107918

Epoch: 417| Step: 0
Training loss: 0.15337510406970978
Validation loss: 1.5359628110803583

Epoch: 5| Step: 1
Training loss: 0.14475326240062714
Validation loss: 1.5312744250861547

Epoch: 5| Step: 2
Training loss: 0.15333077311515808
Validation loss: 1.5132121552703202

Epoch: 5| Step: 3
Training loss: 0.09851618856191635
Validation loss: 1.5025073712871921

Epoch: 5| Step: 4
Training loss: 0.19885140657424927
Validation loss: 1.5226881196421962

Epoch: 5| Step: 5
Training loss: 0.24182374775409698
Validation loss: 1.5292717077398812

Epoch: 5| Step: 6
Training loss: 0.28647810220718384
Validation loss: 1.4955062199664373

Epoch: 5| Step: 7
Training loss: 0.2418803721666336
Validation loss: 1.5335758219483078

Epoch: 5| Step: 8
Training loss: 0.14823614060878754
Validation loss: 1.5262533798012683

Epoch: 5| Step: 9
Training loss: 0.14995869994163513
Validation loss: 1.5354550192433019

Epoch: 5| Step: 10
Training loss: 0.18995434045791626
Validation loss: 1.538974541489796

Epoch: 418| Step: 0
Training loss: 0.2134932577610016
Validation loss: 1.5024695665605607

Epoch: 5| Step: 1
Training loss: 0.23429334163665771
Validation loss: 1.50367489681449

Epoch: 5| Step: 2
Training loss: 0.1910594254732132
Validation loss: 1.4884267045605568

Epoch: 5| Step: 3
Training loss: 0.20386581122875214
Validation loss: 1.4919160783931773

Epoch: 5| Step: 4
Training loss: 0.1877981573343277
Validation loss: 1.494390663280282

Epoch: 5| Step: 5
Training loss: 0.10732938349246979
Validation loss: 1.5010280391221404

Epoch: 5| Step: 6
Training loss: 0.13975897431373596
Validation loss: 1.51741333417995

Epoch: 5| Step: 7
Training loss: 0.21777069568634033
Validation loss: 1.527428255286268

Epoch: 5| Step: 8
Training loss: 0.19778385758399963
Validation loss: 1.5356090261090187

Epoch: 5| Step: 9
Training loss: 0.22382065653800964
Validation loss: 1.545947305617794

Epoch: 5| Step: 10
Training loss: 0.2923978567123413
Validation loss: 1.5374795929078133

Epoch: 419| Step: 0
Training loss: 0.25165194272994995
Validation loss: 1.504047034889139

Epoch: 5| Step: 1
Training loss: 0.24574081599712372
Validation loss: 1.5329975992120721

Epoch: 5| Step: 2
Training loss: 0.1634700745344162
Validation loss: 1.5219341939495457

Epoch: 5| Step: 3
Training loss: 0.24506521224975586
Validation loss: 1.4967950319731107

Epoch: 5| Step: 4
Training loss: 0.1814465969800949
Validation loss: 1.498492052478175

Epoch: 5| Step: 5
Training loss: 0.1439214050769806
Validation loss: 1.4795161242126136

Epoch: 5| Step: 6
Training loss: 0.18130572140216827
Validation loss: 1.4945070384651102

Epoch: 5| Step: 7
Training loss: 0.30364710092544556
Validation loss: 1.5187680875101397

Epoch: 5| Step: 8
Training loss: 0.11680762469768524
Validation loss: 1.5201608455309303

Epoch: 5| Step: 9
Training loss: 0.28148266673088074
Validation loss: 1.560450102693291

Epoch: 5| Step: 10
Training loss: 0.21349038183689117
Validation loss: 1.5861325520341114

Epoch: 420| Step: 0
Training loss: 0.2538453936576843
Validation loss: 1.5809262619223645

Epoch: 5| Step: 1
Training loss: 0.3258868157863617
Validation loss: 1.5718076588005148

Epoch: 5| Step: 2
Training loss: 0.2112470120191574
Validation loss: 1.5445386914796726

Epoch: 5| Step: 3
Training loss: 0.10987713187932968
Validation loss: 1.5188774601105721

Epoch: 5| Step: 4
Training loss: 0.09706737101078033
Validation loss: 1.4897267190358972

Epoch: 5| Step: 5
Training loss: 0.20883306860923767
Validation loss: 1.4982825850927701

Epoch: 5| Step: 6
Training loss: 0.30496612191200256
Validation loss: 1.4963434870525072

Epoch: 5| Step: 7
Training loss: 0.11197642982006073
Validation loss: 1.483107223305651

Epoch: 5| Step: 8
Training loss: 0.12790527939796448
Validation loss: 1.4930792655996097

Epoch: 5| Step: 9
Training loss: 0.20463986694812775
Validation loss: 1.5055505678217898

Epoch: 5| Step: 10
Training loss: 0.15139277279376984
Validation loss: 1.5299323912589782

Epoch: 421| Step: 0
Training loss: 0.15967176854610443
Validation loss: 1.5473545610263784

Epoch: 5| Step: 1
Training loss: 0.1944415122270584
Validation loss: 1.5463818503964333

Epoch: 5| Step: 2
Training loss: 0.18470852077007294
Validation loss: 1.5411127151981476

Epoch: 5| Step: 3
Training loss: 0.1832408607006073
Validation loss: 1.5219762043286396

Epoch: 5| Step: 4
Training loss: 0.11091633886098862
Validation loss: 1.5232184356258762

Epoch: 5| Step: 5
Training loss: 0.13719889521598816
Validation loss: 1.5166360255210631

Epoch: 5| Step: 6
Training loss: 0.12701454758644104
Validation loss: 1.5038144703834289

Epoch: 5| Step: 7
Training loss: 0.08245697617530823
Validation loss: 1.510020048387589

Epoch: 5| Step: 8
Training loss: 0.2739410996437073
Validation loss: 1.5399350273993708

Epoch: 5| Step: 9
Training loss: 0.13328036665916443
Validation loss: 1.5237262095174482

Epoch: 5| Step: 10
Training loss: 0.24508877098560333
Validation loss: 1.51759583462951

Epoch: 422| Step: 0
Training loss: 0.18326887488365173
Validation loss: 1.5156564020341443

Epoch: 5| Step: 1
Training loss: 0.08587722480297089
Validation loss: 1.5021316505247546

Epoch: 5| Step: 2
Training loss: 0.12098715454339981
Validation loss: 1.4817103967871716

Epoch: 5| Step: 3
Training loss: 0.1374765932559967
Validation loss: 1.473684242976609

Epoch: 5| Step: 4
Training loss: 0.16660630702972412
Validation loss: 1.4968722430608605

Epoch: 5| Step: 5
Training loss: 0.1943378448486328
Validation loss: 1.5128321237461542

Epoch: 5| Step: 6
Training loss: 0.1293376386165619
Validation loss: 1.483563724384513

Epoch: 5| Step: 7
Training loss: 0.0963481068611145
Validation loss: 1.492947014429236

Epoch: 5| Step: 8
Training loss: 0.1487119495868683
Validation loss: 1.483569533594193

Epoch: 5| Step: 9
Training loss: 0.2319118082523346
Validation loss: 1.4673522781300288

Epoch: 5| Step: 10
Training loss: 0.13196207582950592
Validation loss: 1.4546064753686228

Epoch: 423| Step: 0
Training loss: 0.15390925109386444
Validation loss: 1.477993574193729

Epoch: 5| Step: 1
Training loss: 0.16565436124801636
Validation loss: 1.4914084506291214

Epoch: 5| Step: 2
Training loss: 0.1620822250843048
Validation loss: 1.4788013536442992

Epoch: 5| Step: 3
Training loss: 0.176079660654068
Validation loss: 1.5051310075226652

Epoch: 5| Step: 4
Training loss: 0.35211628675460815
Validation loss: 1.5174086529721496

Epoch: 5| Step: 5
Training loss: 0.1426389366388321
Validation loss: 1.4905695505039667

Epoch: 5| Step: 6
Training loss: 0.1935614049434662
Validation loss: 1.468103862577869

Epoch: 5| Step: 7
Training loss: 0.15719184279441833
Validation loss: 1.475342454448823

Epoch: 5| Step: 8
Training loss: 0.14015038311481476
Validation loss: 1.4731620780883297

Epoch: 5| Step: 9
Training loss: 0.14881817996501923
Validation loss: 1.482588195031689

Epoch: 5| Step: 10
Training loss: 0.16252365708351135
Validation loss: 1.496797416799812

Epoch: 424| Step: 0
Training loss: 0.15063151717185974
Validation loss: 1.5230672333830146

Epoch: 5| Step: 1
Training loss: 0.2215791940689087
Validation loss: 1.5238739546909128

Epoch: 5| Step: 2
Training loss: 0.17709524929523468
Validation loss: 1.5571876918115923

Epoch: 5| Step: 3
Training loss: 0.145684152841568
Validation loss: 1.5505038948469265

Epoch: 5| Step: 4
Training loss: 0.09735383093357086
Validation loss: 1.518501579120595

Epoch: 5| Step: 5
Training loss: 0.13083615899085999
Validation loss: 1.5088257712702597

Epoch: 5| Step: 6
Training loss: 0.14160092175006866
Validation loss: 1.4987488305696877

Epoch: 5| Step: 7
Training loss: 0.25274890661239624
Validation loss: 1.5020805071758967

Epoch: 5| Step: 8
Training loss: 0.13138200342655182
Validation loss: 1.512953972303739

Epoch: 5| Step: 9
Training loss: 0.25521960854530334
Validation loss: 1.4826647498274361

Epoch: 5| Step: 10
Training loss: 0.22716167569160461
Validation loss: 1.5122597127832391

Epoch: 425| Step: 0
Training loss: 0.2719908356666565
Validation loss: 1.52506628728682

Epoch: 5| Step: 1
Training loss: 0.16405627131462097
Validation loss: 1.551577910300224

Epoch: 5| Step: 2
Training loss: 0.1434026062488556
Validation loss: 1.5221433075525428

Epoch: 5| Step: 3
Training loss: 0.15571817755699158
Validation loss: 1.5420493438679685

Epoch: 5| Step: 4
Training loss: 0.15714052319526672
Validation loss: 1.5752057221628004

Epoch: 5| Step: 5
Training loss: 0.28230538964271545
Validation loss: 1.5826714628486223

Epoch: 5| Step: 6
Training loss: 0.19824929535388947
Validation loss: 1.5639131581911476

Epoch: 5| Step: 7
Training loss: 0.123041532933712
Validation loss: 1.5434949782586866

Epoch: 5| Step: 8
Training loss: 0.2178960144519806
Validation loss: 1.5390307967380812

Epoch: 5| Step: 9
Training loss: 0.22925157845020294
Validation loss: 1.504251912075986

Epoch: 5| Step: 10
Training loss: 0.11139947921037674
Validation loss: 1.503509641975485

Epoch: 426| Step: 0
Training loss: 0.13682036101818085
Validation loss: 1.5226956952002741

Epoch: 5| Step: 1
Training loss: 0.274156779050827
Validation loss: 1.5077036042367258

Epoch: 5| Step: 2
Training loss: 0.14654307067394257
Validation loss: 1.5265211777020526

Epoch: 5| Step: 3
Training loss: 0.1672588288784027
Validation loss: 1.503809461029627

Epoch: 5| Step: 4
Training loss: 0.13181963562965393
Validation loss: 1.5116871095472766

Epoch: 5| Step: 5
Training loss: 0.16078618168830872
Validation loss: 1.4899486085420013

Epoch: 5| Step: 6
Training loss: 0.09146939218044281
Validation loss: 1.5111984334966189

Epoch: 5| Step: 7
Training loss: 0.10538287460803986
Validation loss: 1.504675870300621

Epoch: 5| Step: 8
Training loss: 0.2075222283601761
Validation loss: 1.5028092181810768

Epoch: 5| Step: 9
Training loss: 0.21036270260810852
Validation loss: 1.5003884851291616

Epoch: 5| Step: 10
Training loss: 0.14884217083454132
Validation loss: 1.5153846144676208

Epoch: 427| Step: 0
Training loss: 0.2233504354953766
Validation loss: 1.514127472395538

Epoch: 5| Step: 1
Training loss: 0.2346835881471634
Validation loss: 1.4986301442628265

Epoch: 5| Step: 2
Training loss: 0.10185275226831436
Validation loss: 1.4992000274760748

Epoch: 5| Step: 3
Training loss: 0.13334520161151886
Validation loss: 1.495846648370066

Epoch: 5| Step: 4
Training loss: 0.10272283852100372
Validation loss: 1.487335862651948

Epoch: 5| Step: 5
Training loss: 0.17505520582199097
Validation loss: 1.4602628234894044

Epoch: 5| Step: 6
Training loss: 0.12699449062347412
Validation loss: 1.459908659740161

Epoch: 5| Step: 7
Training loss: 0.1423531323671341
Validation loss: 1.4676606526938818

Epoch: 5| Step: 8
Training loss: 0.16999545693397522
Validation loss: 1.4717340507814962

Epoch: 5| Step: 9
Training loss: 0.2267897129058838
Validation loss: 1.4762010907614103

Epoch: 5| Step: 10
Training loss: 0.28195399045944214
Validation loss: 1.4796905466305312

Epoch: 428| Step: 0
Training loss: 0.12762179970741272
Validation loss: 1.5111425608716986

Epoch: 5| Step: 1
Training loss: 0.20362699031829834
Validation loss: 1.4883473650101693

Epoch: 5| Step: 2
Training loss: 0.12298820167779922
Validation loss: 1.4864715953027048

Epoch: 5| Step: 3
Training loss: 0.13750603795051575
Validation loss: 1.4938423531029814

Epoch: 5| Step: 4
Training loss: 0.17329318821430206
Validation loss: 1.4870310111712384

Epoch: 5| Step: 5
Training loss: 0.19441497325897217
Validation loss: 1.4740697222371255

Epoch: 5| Step: 6
Training loss: 0.21077480912208557
Validation loss: 1.4892427421385241

Epoch: 5| Step: 7
Training loss: 0.15645131468772888
Validation loss: 1.5010370028916227

Epoch: 5| Step: 8
Training loss: 0.13324308395385742
Validation loss: 1.4841244066915205

Epoch: 5| Step: 9
Training loss: 0.225101038813591
Validation loss: 1.503673602175969

Epoch: 5| Step: 10
Training loss: 0.16405004262924194
Validation loss: 1.5161778362848426

Epoch: 429| Step: 0
Training loss: 0.18590876460075378
Validation loss: 1.5205194257920789

Epoch: 5| Step: 1
Training loss: 0.13549312949180603
Validation loss: 1.519311785697937

Epoch: 5| Step: 2
Training loss: 0.12931528687477112
Validation loss: 1.5077039990373837

Epoch: 5| Step: 3
Training loss: 0.11253126710653305
Validation loss: 1.5081392565081198

Epoch: 5| Step: 4
Training loss: 0.11860879510641098
Validation loss: 1.510470462101762

Epoch: 5| Step: 5
Training loss: 0.13475891947746277
Validation loss: 1.4985392606386574

Epoch: 5| Step: 6
Training loss: 0.15184159576892853
Validation loss: 1.504460847505959

Epoch: 5| Step: 7
Training loss: 0.09330718219280243
Validation loss: 1.5104920415468113

Epoch: 5| Step: 8
Training loss: 0.11504051834344864
Validation loss: 1.5056430460304342

Epoch: 5| Step: 9
Training loss: 0.267019122838974
Validation loss: 1.5073439382737683

Epoch: 5| Step: 10
Training loss: 0.19803597033023834
Validation loss: 1.4874386082413376

Epoch: 430| Step: 0
Training loss: 0.20551927387714386
Validation loss: 1.463466562891519

Epoch: 5| Step: 1
Training loss: 0.1438138782978058
Validation loss: 1.4893421793496737

Epoch: 5| Step: 2
Training loss: 0.19728054106235504
Validation loss: 1.4733508145937355

Epoch: 5| Step: 3
Training loss: 0.19718720018863678
Validation loss: 1.4774230974976734

Epoch: 5| Step: 4
Training loss: 0.2570950984954834
Validation loss: 1.476132987647928

Epoch: 5| Step: 5
Training loss: 0.19288280606269836
Validation loss: 1.4804345100156722

Epoch: 5| Step: 6
Training loss: 0.08028601109981537
Validation loss: 1.5116509916961833

Epoch: 5| Step: 7
Training loss: 0.19249168038368225
Validation loss: 1.5364967059063654

Epoch: 5| Step: 8
Training loss: 0.10507750511169434
Validation loss: 1.5289651924563992

Epoch: 5| Step: 9
Training loss: 0.10808960348367691
Validation loss: 1.5568255967991327

Epoch: 5| Step: 10
Training loss: 0.1261008232831955
Validation loss: 1.546069937367593

Epoch: 431| Step: 0
Training loss: 0.20348837971687317
Validation loss: 1.5631733530311174

Epoch: 5| Step: 1
Training loss: 0.20524191856384277
Validation loss: 1.527139998251392

Epoch: 5| Step: 2
Training loss: 0.08583617210388184
Validation loss: 1.5107417542447326

Epoch: 5| Step: 3
Training loss: 0.1476334035396576
Validation loss: 1.4990693907583914

Epoch: 5| Step: 4
Training loss: 0.19729773700237274
Validation loss: 1.4914722160626483

Epoch: 5| Step: 5
Training loss: 0.14610165357589722
Validation loss: 1.5038586816480082

Epoch: 5| Step: 6
Training loss: 0.1866997480392456
Validation loss: 1.519435146803497

Epoch: 5| Step: 7
Training loss: 0.21162860095500946
Validation loss: 1.499441997979277

Epoch: 5| Step: 8
Training loss: 0.1557272970676422
Validation loss: 1.517977096701181

Epoch: 5| Step: 9
Training loss: 0.1888640820980072
Validation loss: 1.5191684333227014

Epoch: 5| Step: 10
Training loss: 0.21326479315757751
Validation loss: 1.568470751085589

Epoch: 432| Step: 0
Training loss: 0.25790899991989136
Validation loss: 1.549525821721682

Epoch: 5| Step: 1
Training loss: 0.11717426776885986
Validation loss: 1.5226322233036

Epoch: 5| Step: 2
Training loss: 0.16143544018268585
Validation loss: 1.5015412556227816

Epoch: 5| Step: 3
Training loss: 0.2371596395969391
Validation loss: 1.498258513148113

Epoch: 5| Step: 4
Training loss: 0.16593065857887268
Validation loss: 1.4603546101559874

Epoch: 5| Step: 5
Training loss: 0.22760574519634247
Validation loss: 1.469957688803314

Epoch: 5| Step: 6
Training loss: 0.12877734005451202
Validation loss: 1.4830231339700761

Epoch: 5| Step: 7
Training loss: 0.16238202154636383
Validation loss: 1.491832257598959

Epoch: 5| Step: 8
Training loss: 0.16727593541145325
Validation loss: 1.4971083966634606

Epoch: 5| Step: 9
Training loss: 0.16512411832809448
Validation loss: 1.480003708793271

Epoch: 5| Step: 10
Training loss: 0.19879983365535736
Validation loss: 1.4738387382158669

Epoch: 433| Step: 0
Training loss: 0.13301318883895874
Validation loss: 1.4896865775508266

Epoch: 5| Step: 1
Training loss: 0.26182547211647034
Validation loss: 1.4916153313011251

Epoch: 5| Step: 2
Training loss: 0.29639020562171936
Validation loss: 1.4726860074586765

Epoch: 5| Step: 3
Training loss: 0.14165763556957245
Validation loss: 1.4987611424538396

Epoch: 5| Step: 4
Training loss: 0.15555135905742645
Validation loss: 1.5006947773759083

Epoch: 5| Step: 5
Training loss: 0.1613544076681137
Validation loss: 1.4907951829253987

Epoch: 5| Step: 6
Training loss: 0.10497359931468964
Validation loss: 1.4734130956793343

Epoch: 5| Step: 7
Training loss: 0.13931593298912048
Validation loss: 1.5178314011584046

Epoch: 5| Step: 8
Training loss: 0.1358300745487213
Validation loss: 1.4968778010337584

Epoch: 5| Step: 9
Training loss: 0.11221106350421906
Validation loss: 1.5261068600480274

Epoch: 5| Step: 10
Training loss: 0.1584048569202423
Validation loss: 1.4912452454208045

Epoch: 434| Step: 0
Training loss: 0.13669708371162415
Validation loss: 1.4882866631272018

Epoch: 5| Step: 1
Training loss: 0.10888407379388809
Validation loss: 1.4702348734742852

Epoch: 5| Step: 2
Training loss: 0.14964590966701508
Validation loss: 1.483561751663044

Epoch: 5| Step: 3
Training loss: 0.20746822655200958
Validation loss: 1.4449311635827506

Epoch: 5| Step: 4
Training loss: 0.18252965807914734
Validation loss: 1.4700886434124363

Epoch: 5| Step: 5
Training loss: 0.21530158817768097
Validation loss: 1.4942665548734768

Epoch: 5| Step: 6
Training loss: 0.13343434035778046
Validation loss: 1.4910829272321475

Epoch: 5| Step: 7
Training loss: 0.1905081421136856
Validation loss: 1.4875691321588331

Epoch: 5| Step: 8
Training loss: 0.13015063107013702
Validation loss: 1.506801373215132

Epoch: 5| Step: 9
Training loss: 0.14270050823688507
Validation loss: 1.507373700859726

Epoch: 5| Step: 10
Training loss: 0.13788197934627533
Validation loss: 1.5263985356976908

Epoch: 435| Step: 0
Training loss: 0.10281304270029068
Validation loss: 1.4997006988012662

Epoch: 5| Step: 1
Training loss: 0.20757997035980225
Validation loss: 1.513684166375027

Epoch: 5| Step: 2
Training loss: 0.1521872729063034
Validation loss: 1.5015424586111499

Epoch: 5| Step: 3
Training loss: 0.13085058331489563
Validation loss: 1.4964029378788446

Epoch: 5| Step: 4
Training loss: 0.19944192469120026
Validation loss: 1.4912062486012776

Epoch: 5| Step: 5
Training loss: 0.1488959938287735
Validation loss: 1.4891790254141695

Epoch: 5| Step: 6
Training loss: 0.1283772736787796
Validation loss: 1.4879701304179367

Epoch: 5| Step: 7
Training loss: 0.11390237510204315
Validation loss: 1.4983701500841367

Epoch: 5| Step: 8
Training loss: 0.15582218766212463
Validation loss: 1.4699041317867976

Epoch: 5| Step: 9
Training loss: 0.2106265276670456
Validation loss: 1.5058404732775945

Epoch: 5| Step: 10
Training loss: 0.1348274201154709
Validation loss: 1.4843735259066346

Epoch: 436| Step: 0
Training loss: 0.1005803793668747
Validation loss: 1.5087651821874803

Epoch: 5| Step: 1
Training loss: 0.13703766465187073
Validation loss: 1.5083902676900227

Epoch: 5| Step: 2
Training loss: 0.12807579338550568
Validation loss: 1.5057569306383851

Epoch: 5| Step: 3
Training loss: 0.15486088395118713
Validation loss: 1.496614501040469

Epoch: 5| Step: 4
Training loss: 0.11848872900009155
Validation loss: 1.5044376888582784

Epoch: 5| Step: 5
Training loss: 0.11760751903057098
Validation loss: 1.4808622098738147

Epoch: 5| Step: 6
Training loss: 0.2958056628704071
Validation loss: 1.4676260140634352

Epoch: 5| Step: 7
Training loss: 0.19003741443157196
Validation loss: 1.4646516141071115

Epoch: 5| Step: 8
Training loss: 0.21303603053092957
Validation loss: 1.4700439091651671

Epoch: 5| Step: 9
Training loss: 0.17384564876556396
Validation loss: 1.502302126217914

Epoch: 5| Step: 10
Training loss: 0.10672320425510406
Validation loss: 1.4705615966550765

Epoch: 437| Step: 0
Training loss: 0.09212468564510345
Validation loss: 1.482460912837777

Epoch: 5| Step: 1
Training loss: 0.1090749055147171
Validation loss: 1.488300177999722

Epoch: 5| Step: 2
Training loss: 0.0763503760099411
Validation loss: 1.4902760239057644

Epoch: 5| Step: 3
Training loss: 0.2747958302497864
Validation loss: 1.4710342230335358

Epoch: 5| Step: 4
Training loss: 0.12659287452697754
Validation loss: 1.4962586664384412

Epoch: 5| Step: 5
Training loss: 0.22660048305988312
Validation loss: 1.5052090690981956

Epoch: 5| Step: 6
Training loss: 0.10009225457906723
Validation loss: 1.4888665445389286

Epoch: 5| Step: 7
Training loss: 0.12100641429424286
Validation loss: 1.479342596505278

Epoch: 5| Step: 8
Training loss: 0.13677655160427094
Validation loss: 1.4854709486807547

Epoch: 5| Step: 9
Training loss: 0.23369252681732178
Validation loss: 1.470597759369881

Epoch: 5| Step: 10
Training loss: 0.16694049537181854
Validation loss: 1.478153278750758

Epoch: 438| Step: 0
Training loss: 0.08983834832906723
Validation loss: 1.4886924746215984

Epoch: 5| Step: 1
Training loss: 0.12344131618738174
Validation loss: 1.4941579564925163

Epoch: 5| Step: 2
Training loss: 0.19642172753810883
Validation loss: 1.46948802855707

Epoch: 5| Step: 3
Training loss: 0.1708846092224121
Validation loss: 1.461716749334848

Epoch: 5| Step: 4
Training loss: 0.12952491641044617
Validation loss: 1.480432939785783

Epoch: 5| Step: 5
Training loss: 0.2138291895389557
Validation loss: 1.476346408808103

Epoch: 5| Step: 6
Training loss: 0.08245114237070084
Validation loss: 1.4809463972686439

Epoch: 5| Step: 7
Training loss: 0.14069890975952148
Validation loss: 1.4835098917766283

Epoch: 5| Step: 8
Training loss: 0.11066589504480362
Validation loss: 1.482272723669647

Epoch: 5| Step: 9
Training loss: 0.12972494959831238
Validation loss: 1.497917567529986

Epoch: 5| Step: 10
Training loss: 0.10385280847549438
Validation loss: 1.489228497269333

Epoch: 439| Step: 0
Training loss: 0.09040560573339462
Validation loss: 1.488355258459686

Epoch: 5| Step: 1
Training loss: 0.1789056807756424
Validation loss: 1.5085699558258057

Epoch: 5| Step: 2
Training loss: 0.12762638926506042
Validation loss: 1.4681715683270526

Epoch: 5| Step: 3
Training loss: 0.16415779292583466
Validation loss: 1.4825554483680314

Epoch: 5| Step: 4
Training loss: 0.1295836716890335
Validation loss: 1.4663725309474493

Epoch: 5| Step: 5
Training loss: 0.09802532196044922
Validation loss: 1.4671117618519773

Epoch: 5| Step: 6
Training loss: 0.13448107242584229
Validation loss: 1.470238552298597

Epoch: 5| Step: 7
Training loss: 0.14833278954029083
Validation loss: 1.4281931846372542

Epoch: 5| Step: 8
Training loss: 0.13125208020210266
Validation loss: 1.4445155602629467

Epoch: 5| Step: 9
Training loss: 0.14954844117164612
Validation loss: 1.4446562220973354

Epoch: 5| Step: 10
Training loss: 0.09585488587617874
Validation loss: 1.4683399841349611

Epoch: 440| Step: 0
Training loss: 0.08335348963737488
Validation loss: 1.4550927108333958

Epoch: 5| Step: 1
Training loss: 0.23937925696372986
Validation loss: 1.4788168886656403

Epoch: 5| Step: 2
Training loss: 0.20881767570972443
Validation loss: 1.4798213038393246

Epoch: 5| Step: 3
Training loss: 0.10186950862407684
Validation loss: 1.490797314592587

Epoch: 5| Step: 4
Training loss: 0.0958465188741684
Validation loss: 1.4954333741177794

Epoch: 5| Step: 5
Training loss: 0.19048254191875458
Validation loss: 1.5186299925209374

Epoch: 5| Step: 6
Training loss: 0.14719344675540924
Validation loss: 1.5096116258252052

Epoch: 5| Step: 7
Training loss: 0.23586425185203552
Validation loss: 1.4996647719414002

Epoch: 5| Step: 8
Training loss: 0.14136192202568054
Validation loss: 1.5060379005247546

Epoch: 5| Step: 9
Training loss: 0.1622922718524933
Validation loss: 1.4961921656003563

Epoch: 5| Step: 10
Training loss: 0.09230183809995651
Validation loss: 1.4779500038393083

Epoch: 441| Step: 0
Training loss: 0.12206520140171051
Validation loss: 1.505206233711653

Epoch: 5| Step: 1
Training loss: 0.14923983812332153
Validation loss: 1.4805678154832573

Epoch: 5| Step: 2
Training loss: 0.12236504256725311
Validation loss: 1.4933311439329577

Epoch: 5| Step: 3
Training loss: 0.16150407493114471
Validation loss: 1.4830085705685359

Epoch: 5| Step: 4
Training loss: 0.1695564091205597
Validation loss: 1.467369674354471

Epoch: 5| Step: 5
Training loss: 0.13736936450004578
Validation loss: 1.4705084511028823

Epoch: 5| Step: 6
Training loss: 0.12313921749591827
Validation loss: 1.4538865371416974

Epoch: 5| Step: 7
Training loss: 0.15163719654083252
Validation loss: 1.475329755454935

Epoch: 5| Step: 8
Training loss: 0.13335272669792175
Validation loss: 1.4595096354843469

Epoch: 5| Step: 9
Training loss: 0.15946117043495178
Validation loss: 1.4624445246111961

Epoch: 5| Step: 10
Training loss: 0.18445643782615662
Validation loss: 1.4867008770665815

Epoch: 442| Step: 0
Training loss: 0.15915855765342712
Validation loss: 1.4889460186804495

Epoch: 5| Step: 1
Training loss: 0.08258189260959625
Validation loss: 1.4568913591805326

Epoch: 5| Step: 2
Training loss: 0.05857127159833908
Validation loss: 1.4735873104423605

Epoch: 5| Step: 3
Training loss: 0.09729409217834473
Validation loss: 1.4991945118032477

Epoch: 5| Step: 4
Training loss: 0.14137884974479675
Validation loss: 1.4780202706654866

Epoch: 5| Step: 5
Training loss: 0.14257267117500305
Validation loss: 1.4775822829174738

Epoch: 5| Step: 6
Training loss: 0.11514107882976532
Validation loss: 1.4862355211729645

Epoch: 5| Step: 7
Training loss: 0.19088003039360046
Validation loss: 1.4849164639749834

Epoch: 5| Step: 8
Training loss: 0.15149232745170593
Validation loss: 1.4926494283060874

Epoch: 5| Step: 9
Training loss: 0.1857098489999771
Validation loss: 1.4938157450768255

Epoch: 5| Step: 10
Training loss: 0.12891648709774017
Validation loss: 1.497445491052443

Epoch: 443| Step: 0
Training loss: 0.09978790581226349
Validation loss: 1.5097908166147047

Epoch: 5| Step: 1
Training loss: 0.105415940284729
Validation loss: 1.5032785464358587

Epoch: 5| Step: 2
Training loss: 0.11755596101284027
Validation loss: 1.5012504753246103

Epoch: 5| Step: 3
Training loss: 0.1265852302312851
Validation loss: 1.521515621933886

Epoch: 5| Step: 4
Training loss: 0.11784744262695312
Validation loss: 1.52324047652624

Epoch: 5| Step: 5
Training loss: 0.19122017920017242
Validation loss: 1.5177480501513327

Epoch: 5| Step: 6
Training loss: 0.14431194961071014
Validation loss: 1.5047666411246023

Epoch: 5| Step: 7
Training loss: 0.15711204707622528
Validation loss: 1.4876376044365667

Epoch: 5| Step: 8
Training loss: 0.1532614678144455
Validation loss: 1.507027792674239

Epoch: 5| Step: 9
Training loss: 0.08753130584955215
Validation loss: 1.513153087708258

Epoch: 5| Step: 10
Training loss: 0.1739630252122879
Validation loss: 1.5190770376113154

Epoch: 444| Step: 0
Training loss: 0.1343478113412857
Validation loss: 1.5175138404292445

Epoch: 5| Step: 1
Training loss: 0.2218867838382721
Validation loss: 1.4957830124003912

Epoch: 5| Step: 2
Training loss: 0.14736606180667877
Validation loss: 1.4981222377028516

Epoch: 5| Step: 3
Training loss: 0.12172768265008926
Validation loss: 1.4761578152256627

Epoch: 5| Step: 4
Training loss: 0.1544756442308426
Validation loss: 1.48596772327218

Epoch: 5| Step: 5
Training loss: 0.18679124116897583
Validation loss: 1.4747886093713904

Epoch: 5| Step: 6
Training loss: 0.15246884524822235
Validation loss: 1.4735192432198474

Epoch: 5| Step: 7
Training loss: 0.13423840701580048
Validation loss: 1.4751883604193246

Epoch: 5| Step: 8
Training loss: 0.05972438305616379
Validation loss: 1.455756833476405

Epoch: 5| Step: 9
Training loss: 0.15197841823101044
Validation loss: 1.4986826796685495

Epoch: 5| Step: 10
Training loss: 0.16034987568855286
Validation loss: 1.4972358788213422

Epoch: 445| Step: 0
Training loss: 0.15842938423156738
Validation loss: 1.532531640862906

Epoch: 5| Step: 1
Training loss: 0.13029807806015015
Validation loss: 1.5609931381799842

Epoch: 5| Step: 2
Training loss: 0.1950671374797821
Validation loss: 1.5593470629825388

Epoch: 5| Step: 3
Training loss: 0.13839055597782135
Validation loss: 1.5064515554776756

Epoch: 5| Step: 4
Training loss: 0.13686956465244293
Validation loss: 1.49801202102374

Epoch: 5| Step: 5
Training loss: 0.11687321960926056
Validation loss: 1.4817134782832155

Epoch: 5| Step: 6
Training loss: 0.12494499981403351
Validation loss: 1.479373397365693

Epoch: 5| Step: 7
Training loss: 0.18714596331119537
Validation loss: 1.480304177730314

Epoch: 5| Step: 8
Training loss: 0.20706625282764435
Validation loss: 1.4786245463996806

Epoch: 5| Step: 9
Training loss: 0.16153284907341003
Validation loss: 1.4854462313395675

Epoch: 5| Step: 10
Training loss: 0.2321174591779709
Validation loss: 1.5057331682533346

Epoch: 446| Step: 0
Training loss: 0.061956774443387985
Validation loss: 1.5123975533311085

Epoch: 5| Step: 1
Training loss: 0.12874194979667664
Validation loss: 1.4943106353923838

Epoch: 5| Step: 2
Training loss: 0.19137337803840637
Validation loss: 1.4878558138365388

Epoch: 5| Step: 3
Training loss: 0.20649194717407227
Validation loss: 1.4582732198058919

Epoch: 5| Step: 4
Training loss: 0.24516446888446808
Validation loss: 1.4335751789872364

Epoch: 5| Step: 5
Training loss: 0.12472094595432281
Validation loss: 1.4378798277147355

Epoch: 5| Step: 6
Training loss: 0.1071891039609909
Validation loss: 1.4570661129490021

Epoch: 5| Step: 7
Training loss: 0.15258076786994934
Validation loss: 1.4378252952329573

Epoch: 5| Step: 8
Training loss: 0.1766314059495926
Validation loss: 1.4592020857718684

Epoch: 5| Step: 9
Training loss: 0.1219409853219986
Validation loss: 1.4706235713856195

Epoch: 5| Step: 10
Training loss: 0.19764086604118347
Validation loss: 1.469304903861015

Epoch: 447| Step: 0
Training loss: 0.13175514340400696
Validation loss: 1.4689604595143309

Epoch: 5| Step: 1
Training loss: 0.14418433606624603
Validation loss: 1.5050933386689873

Epoch: 5| Step: 2
Training loss: 0.1975908726453781
Validation loss: 1.5158797053880588

Epoch: 5| Step: 3
Training loss: 0.2833704650402069
Validation loss: 1.4845618355658747

Epoch: 5| Step: 4
Training loss: 0.21456173062324524
Validation loss: 1.4938566011767234

Epoch: 5| Step: 5
Training loss: 0.10543127357959747
Validation loss: 1.4598217023316251

Epoch: 5| Step: 6
Training loss: 0.14495928585529327
Validation loss: 1.4536434347911547

Epoch: 5| Step: 7
Training loss: 0.11044035106897354
Validation loss: 1.4640310887367494

Epoch: 5| Step: 8
Training loss: 0.1263241469860077
Validation loss: 1.4557931628278507

Epoch: 5| Step: 9
Training loss: 0.18491576611995697
Validation loss: 1.4468566153639106

Epoch: 5| Step: 10
Training loss: 0.12665005028247833
Validation loss: 1.4557450830295522

Epoch: 448| Step: 0
Training loss: 0.22270970046520233
Validation loss: 1.4652241340247534

Epoch: 5| Step: 1
Training loss: 0.1387355923652649
Validation loss: 1.4774647348670549

Epoch: 5| Step: 2
Training loss: 0.12345006316900253
Validation loss: 1.4632824428619877

Epoch: 5| Step: 3
Training loss: 0.17047710716724396
Validation loss: 1.5172620742551741

Epoch: 5| Step: 4
Training loss: 0.19272348284721375
Validation loss: 1.5019717145991582

Epoch: 5| Step: 5
Training loss: 0.23881101608276367
Validation loss: 1.54590807935243

Epoch: 5| Step: 6
Training loss: 0.12012825161218643
Validation loss: 1.5147742622642106

Epoch: 5| Step: 7
Training loss: 0.1014995127916336
Validation loss: 1.5189411793985674

Epoch: 5| Step: 8
Training loss: 0.10663662105798721
Validation loss: 1.4857582091003336

Epoch: 5| Step: 9
Training loss: 0.09997142851352692
Validation loss: 1.4888904184423468

Epoch: 5| Step: 10
Training loss: 0.1351584643125534
Validation loss: 1.5262776895235943

Epoch: 449| Step: 0
Training loss: 0.1194629818201065
Validation loss: 1.5274569706250263

Epoch: 5| Step: 1
Training loss: 0.10911792516708374
Validation loss: 1.5066283684904858

Epoch: 5| Step: 2
Training loss: 0.18604445457458496
Validation loss: 1.507372643357964

Epoch: 5| Step: 3
Training loss: 0.17855605483055115
Validation loss: 1.5025563316960489

Epoch: 5| Step: 4
Training loss: 0.09785390645265579
Validation loss: 1.5259474862006404

Epoch: 5| Step: 5
Training loss: 0.19458246231079102
Validation loss: 1.4978139323572959

Epoch: 5| Step: 6
Training loss: 0.18470998108386993
Validation loss: 1.4763225534910798

Epoch: 5| Step: 7
Training loss: 0.1371464729309082
Validation loss: 1.5016149538819508

Epoch: 5| Step: 8
Training loss: 0.1258036345243454
Validation loss: 1.5004914627280286

Epoch: 5| Step: 9
Training loss: 0.16503770649433136
Validation loss: 1.4821505943934123

Epoch: 5| Step: 10
Training loss: 0.14797376096248627
Validation loss: 1.4983076164799352

Epoch: 450| Step: 0
Training loss: 0.1167086586356163
Validation loss: 1.5107804652183288

Epoch: 5| Step: 1
Training loss: 0.1766301393508911
Validation loss: 1.4948946763110418

Epoch: 5| Step: 2
Training loss: 0.19354093074798584
Validation loss: 1.4791692790164743

Epoch: 5| Step: 3
Training loss: 0.09300243109464645
Validation loss: 1.4785748130531722

Epoch: 5| Step: 4
Training loss: 0.14398786425590515
Validation loss: 1.4747067497622581

Epoch: 5| Step: 5
Training loss: 0.11273584514856339
Validation loss: 1.4705064322358818

Epoch: 5| Step: 6
Training loss: 0.1206594705581665
Validation loss: 1.4653168262973908

Epoch: 5| Step: 7
Training loss: 0.13702134788036346
Validation loss: 1.4512959436703754

Epoch: 5| Step: 8
Training loss: 0.14547494053840637
Validation loss: 1.467554929435894

Epoch: 5| Step: 9
Training loss: 0.06674625724554062
Validation loss: 1.4749978505155092

Epoch: 5| Step: 10
Training loss: 0.1222061961889267
Validation loss: 1.4560045631982947

Epoch: 451| Step: 0
Training loss: 0.22689136862754822
Validation loss: 1.4738521165745233

Epoch: 5| Step: 1
Training loss: 0.15083719789981842
Validation loss: 1.4557436358544134

Epoch: 5| Step: 2
Training loss: 0.15654343366622925
Validation loss: 1.4901236769973591

Epoch: 5| Step: 3
Training loss: 0.11563054472208023
Validation loss: 1.4911398015996462

Epoch: 5| Step: 4
Training loss: 0.10450240224599838
Validation loss: 1.481999256277597

Epoch: 5| Step: 5
Training loss: 0.08834626525640488
Validation loss: 1.4908126746454546

Epoch: 5| Step: 6
Training loss: 0.11882191896438599
Validation loss: 1.5012221003091464

Epoch: 5| Step: 7
Training loss: 0.12727731466293335
Validation loss: 1.45941900373787

Epoch: 5| Step: 8
Training loss: 0.16033104062080383
Validation loss: 1.4645590897529357

Epoch: 5| Step: 9
Training loss: 0.11938194930553436
Validation loss: 1.4481976006620674

Epoch: 5| Step: 10
Training loss: 0.14104928076267242
Validation loss: 1.4399719404917892

Epoch: 452| Step: 0
Training loss: 0.1794680505990982
Validation loss: 1.4412023034147037

Epoch: 5| Step: 1
Training loss: 0.09820116311311722
Validation loss: 1.4894776075117049

Epoch: 5| Step: 2
Training loss: 0.11200942099094391
Validation loss: 1.5166116491440804

Epoch: 5| Step: 3
Training loss: 0.1656874567270279
Validation loss: 1.4938152092759327

Epoch: 5| Step: 4
Training loss: 0.2544938921928406
Validation loss: 1.5325890535949378

Epoch: 5| Step: 5
Training loss: 0.13950921595096588
Validation loss: 1.5050901123272475

Epoch: 5| Step: 6
Training loss: 0.1270674616098404
Validation loss: 1.4732649300688057

Epoch: 5| Step: 7
Training loss: 0.08697881549596786
Validation loss: 1.4871666617290948

Epoch: 5| Step: 8
Training loss: 0.13258984684944153
Validation loss: 1.4638728621185466

Epoch: 5| Step: 9
Training loss: 0.15547196567058563
Validation loss: 1.483144199976357

Epoch: 5| Step: 10
Training loss: 0.46083444356918335
Validation loss: 1.5093442816888132

Epoch: 453| Step: 0
Training loss: 0.1876533478498459
Validation loss: 1.4764160904833066

Epoch: 5| Step: 1
Training loss: 0.21724167466163635
Validation loss: 1.501782064796776

Epoch: 5| Step: 2
Training loss: 0.09465325623750687
Validation loss: 1.5521048166418587

Epoch: 5| Step: 3
Training loss: 0.15385647118091583
Validation loss: 1.5622516780771234

Epoch: 5| Step: 4
Training loss: 0.19718101620674133
Validation loss: 1.5719301354500554

Epoch: 5| Step: 5
Training loss: 0.20282991230487823
Validation loss: 1.5537587320932778

Epoch: 5| Step: 6
Training loss: 0.12369676679372787
Validation loss: 1.5299521582100981

Epoch: 5| Step: 7
Training loss: 0.12826207280158997
Validation loss: 1.4837315185095674

Epoch: 5| Step: 8
Training loss: 0.13089442253112793
Validation loss: 1.4723958661479335

Epoch: 5| Step: 9
Training loss: 0.25073522329330444
Validation loss: 1.4629950472103652

Epoch: 5| Step: 10
Training loss: 0.12684065103530884
Validation loss: 1.482326017912998

Epoch: 454| Step: 0
Training loss: 0.1994999647140503
Validation loss: 1.4847412468284689

Epoch: 5| Step: 1
Training loss: 0.13580717146396637
Validation loss: 1.4547745002213346

Epoch: 5| Step: 2
Training loss: 0.10523390769958496
Validation loss: 1.443653565581127

Epoch: 5| Step: 3
Training loss: 0.07073663920164108
Validation loss: 1.4738409999878175

Epoch: 5| Step: 4
Training loss: 0.0887710303068161
Validation loss: 1.4706779795308267

Epoch: 5| Step: 5
Training loss: 0.14403009414672852
Validation loss: 1.472913356237514

Epoch: 5| Step: 6
Training loss: 0.3301387429237366
Validation loss: 1.509646870756662

Epoch: 5| Step: 7
Training loss: 0.30536073446273804
Validation loss: 1.5135871569315593

Epoch: 5| Step: 8
Training loss: 0.10834457725286484
Validation loss: 1.4408530599327498

Epoch: 5| Step: 9
Training loss: 0.19846001267433167
Validation loss: 1.445819697072429

Epoch: 5| Step: 10
Training loss: 0.19806182384490967
Validation loss: 1.4305640330878637

Epoch: 455| Step: 0
Training loss: 0.21263828873634338
Validation loss: 1.4596251339040778

Epoch: 5| Step: 1
Training loss: 0.2768319547176361
Validation loss: 1.452495398059968

Epoch: 5| Step: 2
Training loss: 0.1348104327917099
Validation loss: 1.4492316963852092

Epoch: 5| Step: 3
Training loss: 0.10705975443124771
Validation loss: 1.4836070819567608

Epoch: 5| Step: 4
Training loss: 0.11184831708669662
Validation loss: 1.4745042311247958

Epoch: 5| Step: 5
Training loss: 0.21796099841594696
Validation loss: 1.514814374267414

Epoch: 5| Step: 6
Training loss: 0.2568114697933197
Validation loss: 1.536574698263599

Epoch: 5| Step: 7
Training loss: 0.20054969191551208
Validation loss: 1.5481607926789152

Epoch: 5| Step: 8
Training loss: 0.1994849592447281
Validation loss: 1.5207579622986496

Epoch: 5| Step: 9
Training loss: 0.17477385699748993
Validation loss: 1.5022893721057522

Epoch: 5| Step: 10
Training loss: 0.085883229970932
Validation loss: 1.498914723755211

Epoch: 456| Step: 0
Training loss: 0.19000506401062012
Validation loss: 1.4581295431301158

Epoch: 5| Step: 1
Training loss: 0.3041953444480896
Validation loss: 1.4490676656846078

Epoch: 5| Step: 2
Training loss: 0.1484205424785614
Validation loss: 1.451388451360887

Epoch: 5| Step: 3
Training loss: 0.18743789196014404
Validation loss: 1.466634609365976

Epoch: 5| Step: 4
Training loss: 0.07598365843296051
Validation loss: 1.4541439266615017

Epoch: 5| Step: 5
Training loss: 0.11714495718479156
Validation loss: 1.454410913170025

Epoch: 5| Step: 6
Training loss: 0.08338390290737152
Validation loss: 1.4733997019388343

Epoch: 5| Step: 7
Training loss: 0.1361645758152008
Validation loss: 1.4909543087405543

Epoch: 5| Step: 8
Training loss: 0.19215638935565948
Validation loss: 1.4975097781868392

Epoch: 5| Step: 9
Training loss: 0.14791133999824524
Validation loss: 1.4986206049560218

Epoch: 5| Step: 10
Training loss: 0.19799180328845978
Validation loss: 1.4988777509299658

Epoch: 457| Step: 0
Training loss: 0.15155145525932312
Validation loss: 1.4773129852869178

Epoch: 5| Step: 1
Training loss: 0.21782942116260529
Validation loss: 1.4753427428583945

Epoch: 5| Step: 2
Training loss: 0.13781163096427917
Validation loss: 1.4829691148573352

Epoch: 5| Step: 3
Training loss: 0.13928356766700745
Validation loss: 1.468388113924252

Epoch: 5| Step: 4
Training loss: 0.15435904264450073
Validation loss: 1.5015488029808126

Epoch: 5| Step: 5
Training loss: 0.22257938981056213
Validation loss: 1.482230160825996

Epoch: 5| Step: 6
Training loss: 0.13311399519443512
Validation loss: 1.4874561717433314

Epoch: 5| Step: 7
Training loss: 0.10713718086481094
Validation loss: 1.4779581075073571

Epoch: 5| Step: 8
Training loss: 0.21719691157341003
Validation loss: 1.5339637238492247

Epoch: 5| Step: 9
Training loss: 0.12690021097660065
Validation loss: 1.5382664203643799

Epoch: 5| Step: 10
Training loss: 0.15578530728816986
Validation loss: 1.572486928714219

Epoch: 458| Step: 0
Training loss: 0.23539555072784424
Validation loss: 1.5417072875525362

Epoch: 5| Step: 1
Training loss: 0.21723756194114685
Validation loss: 1.5168932253314602

Epoch: 5| Step: 2
Training loss: 0.11819948256015778
Validation loss: 1.4964535415813487

Epoch: 5| Step: 3
Training loss: 0.08025553822517395
Validation loss: 1.4860145840593564

Epoch: 5| Step: 4
Training loss: 0.1378268301486969
Validation loss: 1.4944584574750674

Epoch: 5| Step: 5
Training loss: 0.10942509025335312
Validation loss: 1.4868909197468911

Epoch: 5| Step: 6
Training loss: 0.15120454132556915
Validation loss: 1.5027025233032882

Epoch: 5| Step: 7
Training loss: 0.15850119292736053
Validation loss: 1.4944616722804245

Epoch: 5| Step: 8
Training loss: 0.15533031523227692
Validation loss: 1.4808778903817619

Epoch: 5| Step: 9
Training loss: 0.15433964133262634
Validation loss: 1.4999067296263993

Epoch: 5| Step: 10
Training loss: 0.12548968195915222
Validation loss: 1.4860028810398553

Epoch: 459| Step: 0
Training loss: 0.18421661853790283
Validation loss: 1.5154031079302552

Epoch: 5| Step: 1
Training loss: 0.09275723993778229
Validation loss: 1.5002155098863827

Epoch: 5| Step: 2
Training loss: 0.20722678303718567
Validation loss: 1.5393099195213729

Epoch: 5| Step: 3
Training loss: 0.09200967848300934
Validation loss: 1.509382773471135

Epoch: 5| Step: 4
Training loss: 0.12021210044622421
Validation loss: 1.495963433737396

Epoch: 5| Step: 5
Training loss: 0.11197318881750107
Validation loss: 1.5017761889324392

Epoch: 5| Step: 6
Training loss: 0.09886620938777924
Validation loss: 1.4736023461946877

Epoch: 5| Step: 7
Training loss: 0.12139354646205902
Validation loss: 1.4929998254263273

Epoch: 5| Step: 8
Training loss: 0.20915618538856506
Validation loss: 1.4952980235058775

Epoch: 5| Step: 9
Training loss: 0.16664206981658936
Validation loss: 1.5137622907597532

Epoch: 5| Step: 10
Training loss: 0.07463689148426056
Validation loss: 1.4953262773893212

Epoch: 460| Step: 0
Training loss: 0.1270616352558136
Validation loss: 1.5060200319495252

Epoch: 5| Step: 1
Training loss: 0.1161242127418518
Validation loss: 1.5166254325579571

Epoch: 5| Step: 2
Training loss: 0.07184134423732758
Validation loss: 1.503670573555013

Epoch: 5| Step: 3
Training loss: 0.15184353291988373
Validation loss: 1.501107608118365

Epoch: 5| Step: 4
Training loss: 0.17782138288021088
Validation loss: 1.505073590945172

Epoch: 5| Step: 5
Training loss: 0.11050379276275635
Validation loss: 1.494152101778215

Epoch: 5| Step: 6
Training loss: 0.11216308921575546
Validation loss: 1.4884456767830798

Epoch: 5| Step: 7
Training loss: 0.17959189414978027
Validation loss: 1.4833329826272943

Epoch: 5| Step: 8
Training loss: 0.08503719419240952
Validation loss: 1.480642149525304

Epoch: 5| Step: 9
Training loss: 0.15146522223949432
Validation loss: 1.4851545005716302

Epoch: 5| Step: 10
Training loss: 0.1091887354850769
Validation loss: 1.4796012550271966

Epoch: 461| Step: 0
Training loss: 0.09630545973777771
Validation loss: 1.4749244028522122

Epoch: 5| Step: 1
Training loss: 0.21418924629688263
Validation loss: 1.4955565570503153

Epoch: 5| Step: 2
Training loss: 0.10093832015991211
Validation loss: 1.464265150408591

Epoch: 5| Step: 3
Training loss: 0.13120214641094208
Validation loss: 1.4856604119782806

Epoch: 5| Step: 4
Training loss: 0.06013047695159912
Validation loss: 1.4813132850072717

Epoch: 5| Step: 5
Training loss: 0.089771568775177
Validation loss: 1.4755915749457575

Epoch: 5| Step: 6
Training loss: 0.3066306710243225
Validation loss: 1.5029267636678552

Epoch: 5| Step: 7
Training loss: 0.15103362500667572
Validation loss: 1.5063366492589314

Epoch: 5| Step: 8
Training loss: 0.15329019725322723
Validation loss: 1.4892758630937146

Epoch: 5| Step: 9
Training loss: 0.16267172992229462
Validation loss: 1.462202936090449

Epoch: 5| Step: 10
Training loss: 0.09152484685182571
Validation loss: 1.4549227683774886

Epoch: 462| Step: 0
Training loss: 0.18813219666481018
Validation loss: 1.4479699468099942

Epoch: 5| Step: 1
Training loss: 0.11880340427160263
Validation loss: 1.4551736398409771

Epoch: 5| Step: 2
Training loss: 0.18390128016471863
Validation loss: 1.4264330851134432

Epoch: 5| Step: 3
Training loss: 0.18550989031791687
Validation loss: 1.4477398177628875

Epoch: 5| Step: 4
Training loss: 0.1871384084224701
Validation loss: 1.4636840307584373

Epoch: 5| Step: 5
Training loss: 0.08688077330589294
Validation loss: 1.4651772040192799

Epoch: 5| Step: 6
Training loss: 0.13603682816028595
Validation loss: 1.4834297075066516

Epoch: 5| Step: 7
Training loss: 0.18982776999473572
Validation loss: 1.5048753510239303

Epoch: 5| Step: 8
Training loss: 0.08999479562044144
Validation loss: 1.4928627911434378

Epoch: 5| Step: 9
Training loss: 0.10526517778635025
Validation loss: 1.5318418382316508

Epoch: 5| Step: 10
Training loss: 0.15231244266033173
Validation loss: 1.476990178067197

Epoch: 463| Step: 0
Training loss: 0.1036740094423294
Validation loss: 1.4834690247812579

Epoch: 5| Step: 1
Training loss: 0.0884174108505249
Validation loss: 1.45244203588014

Epoch: 5| Step: 2
Training loss: 0.14527928829193115
Validation loss: 1.4518191442694715

Epoch: 5| Step: 3
Training loss: 0.17754460871219635
Validation loss: 1.4500268326010755

Epoch: 5| Step: 4
Training loss: 0.1240202784538269
Validation loss: 1.4643682420894664

Epoch: 5| Step: 5
Training loss: 0.1497279703617096
Validation loss: 1.4713652672306183

Epoch: 5| Step: 6
Training loss: 0.10982821136713028
Validation loss: 1.468299868927207

Epoch: 5| Step: 7
Training loss: 0.11110243946313858
Validation loss: 1.4657703740622408

Epoch: 5| Step: 8
Training loss: 0.17586749792099
Validation loss: 1.461060675241614

Epoch: 5| Step: 9
Training loss: 0.14407916367053986
Validation loss: 1.4884798526763916

Epoch: 5| Step: 10
Training loss: 0.23777993023395538
Validation loss: 1.5117320514494372

Epoch: 464| Step: 0
Training loss: 0.21343092620372772
Validation loss: 1.496420753899441

Epoch: 5| Step: 1
Training loss: 0.09115512669086456
Validation loss: 1.4833407491765997

Epoch: 5| Step: 2
Training loss: 0.13332124054431915
Validation loss: 1.4699555558543052

Epoch: 5| Step: 3
Training loss: 0.08507012575864792
Validation loss: 1.4740462738980529

Epoch: 5| Step: 4
Training loss: 0.17330476641654968
Validation loss: 1.45299570919365

Epoch: 5| Step: 5
Training loss: 0.12418095022439957
Validation loss: 1.4460045176167642

Epoch: 5| Step: 6
Training loss: 0.10814480483531952
Validation loss: 1.4704278919004625

Epoch: 5| Step: 7
Training loss: 0.09588014334440231
Validation loss: 1.4640619536881805

Epoch: 5| Step: 8
Training loss: 0.13036133348941803
Validation loss: 1.4822301146804646

Epoch: 5| Step: 9
Training loss: 0.1388911008834839
Validation loss: 1.4895955298536567

Epoch: 5| Step: 10
Training loss: 0.1069025844335556
Validation loss: 1.4820192949746245

Epoch: 465| Step: 0
Training loss: 0.14485231041908264
Validation loss: 1.481661315887205

Epoch: 5| Step: 1
Training loss: 0.1405515968799591
Validation loss: 1.5015062875645135

Epoch: 5| Step: 2
Training loss: 0.14653527736663818
Validation loss: 1.5165250557725147

Epoch: 5| Step: 3
Training loss: 0.0875680223107338
Validation loss: 1.4839106259807464

Epoch: 5| Step: 4
Training loss: 0.07889626175165176
Validation loss: 1.4906395173841906

Epoch: 5| Step: 5
Training loss: 0.08875180780887604
Validation loss: 1.4593559984237916

Epoch: 5| Step: 6
Training loss: 0.19421352446079254
Validation loss: 1.4658983958664762

Epoch: 5| Step: 7
Training loss: 0.08891954272985458
Validation loss: 1.4697499441844162

Epoch: 5| Step: 8
Training loss: 0.1257919818162918
Validation loss: 1.4722767401767034

Epoch: 5| Step: 9
Training loss: 0.13081499934196472
Validation loss: 1.4608174479135903

Epoch: 5| Step: 10
Training loss: 0.1048007681965828
Validation loss: 1.4798865536207795

Epoch: 466| Step: 0
Training loss: 0.12320319563150406
Validation loss: 1.467653593709392

Epoch: 5| Step: 1
Training loss: 0.06881735473871231
Validation loss: 1.4839365559239541

Epoch: 5| Step: 2
Training loss: 0.146929070353508
Validation loss: 1.4913052346116753

Epoch: 5| Step: 3
Training loss: 0.12042906135320663
Validation loss: 1.459988627382504

Epoch: 5| Step: 4
Training loss: 0.11730065196752548
Validation loss: 1.4897759665725052

Epoch: 5| Step: 5
Training loss: 0.13990959525108337
Validation loss: 1.445543578875962

Epoch: 5| Step: 6
Training loss: 0.1515219509601593
Validation loss: 1.4639217635636688

Epoch: 5| Step: 7
Training loss: 0.06965522468090057
Validation loss: 1.45752937434822

Epoch: 5| Step: 8
Training loss: 0.1472289264202118
Validation loss: 1.4626750676862654

Epoch: 5| Step: 9
Training loss: 0.15952342748641968
Validation loss: 1.4523170276354718

Epoch: 5| Step: 10
Training loss: 0.10010834038257599
Validation loss: 1.4621163132370159

Epoch: 467| Step: 0
Training loss: 0.11220190674066544
Validation loss: 1.487137190116349

Epoch: 5| Step: 1
Training loss: 0.054582107812166214
Validation loss: 1.470594588787325

Epoch: 5| Step: 2
Training loss: 0.26319950819015503
Validation loss: 1.4920039740941857

Epoch: 5| Step: 3
Training loss: 0.14863142371177673
Validation loss: 1.4943049684647591

Epoch: 5| Step: 4
Training loss: 0.1127215251326561
Validation loss: 1.476711170647734

Epoch: 5| Step: 5
Training loss: 0.12813812494277954
Validation loss: 1.4755695737818235

Epoch: 5| Step: 6
Training loss: 0.13964591920375824
Validation loss: 1.4808540972330237

Epoch: 5| Step: 7
Training loss: 0.14411847293376923
Validation loss: 1.4781362523314774

Epoch: 5| Step: 8
Training loss: 0.18185923993587494
Validation loss: 1.506807755398494

Epoch: 5| Step: 9
Training loss: 0.11155764013528824
Validation loss: 1.4902581578941756

Epoch: 5| Step: 10
Training loss: 0.13895340263843536
Validation loss: 1.4984176466541905

Epoch: 468| Step: 0
Training loss: 0.13482467830181122
Validation loss: 1.5091700925621936

Epoch: 5| Step: 1
Training loss: 0.059983156621456146
Validation loss: 1.519077976544698

Epoch: 5| Step: 2
Training loss: 0.12522757053375244
Validation loss: 1.50665146048351

Epoch: 5| Step: 3
Training loss: 0.07393871247768402
Validation loss: 1.4955401548775293

Epoch: 5| Step: 4
Training loss: 0.11317068338394165
Validation loss: 1.5174045934472034

Epoch: 5| Step: 5
Training loss: 0.10254756361246109
Validation loss: 1.5138798311192503

Epoch: 5| Step: 6
Training loss: 0.10493604838848114
Validation loss: 1.5094083829592633

Epoch: 5| Step: 7
Training loss: 0.16861678659915924
Validation loss: 1.4898509735702186

Epoch: 5| Step: 8
Training loss: 0.21193107962608337
Validation loss: 1.5110501499586209

Epoch: 5| Step: 9
Training loss: 0.13744893670082092
Validation loss: 1.4912662852195002

Epoch: 5| Step: 10
Training loss: 0.21944469213485718
Validation loss: 1.4922650103927941

Epoch: 469| Step: 0
Training loss: 0.12029357254505157
Validation loss: 1.4804550672090182

Epoch: 5| Step: 1
Training loss: 0.11161386966705322
Validation loss: 1.4888340593666158

Epoch: 5| Step: 2
Training loss: 0.1471451222896576
Validation loss: 1.4916435621118034

Epoch: 5| Step: 3
Training loss: 0.19816549122333527
Validation loss: 1.4772904124311221

Epoch: 5| Step: 4
Training loss: 0.16468445956707
Validation loss: 1.474292193689654

Epoch: 5| Step: 5
Training loss: 0.1336871087551117
Validation loss: 1.4812922272630917

Epoch: 5| Step: 6
Training loss: 0.07084633409976959
Validation loss: 1.4606549964156201

Epoch: 5| Step: 7
Training loss: 0.09028550237417221
Validation loss: 1.4985675516948904

Epoch: 5| Step: 8
Training loss: 0.09193055331707001
Validation loss: 1.4712543103002733

Epoch: 5| Step: 9
Training loss: 0.07372762262821198
Validation loss: 1.477472669334822

Epoch: 5| Step: 10
Training loss: 0.10050689429044724
Validation loss: 1.4855811788189797

Epoch: 470| Step: 0
Training loss: 0.06805983185768127
Validation loss: 1.4876366392258675

Epoch: 5| Step: 1
Training loss: 0.09082569181919098
Validation loss: 1.492122979574306

Epoch: 5| Step: 2
Training loss: 0.11065705120563507
Validation loss: 1.4781306911540288

Epoch: 5| Step: 3
Training loss: 0.07690911740064621
Validation loss: 1.4995477250827256

Epoch: 5| Step: 4
Training loss: 0.11951678991317749
Validation loss: 1.4964281679481588

Epoch: 5| Step: 5
Training loss: 0.19271264970302582
Validation loss: 1.5024911267783052

Epoch: 5| Step: 6
Training loss: 0.14844925701618195
Validation loss: 1.4931454261144002

Epoch: 5| Step: 7
Training loss: 0.14296405017375946
Validation loss: 1.5017351553004274

Epoch: 5| Step: 8
Training loss: 0.12353916466236115
Validation loss: 1.5054298620070181

Epoch: 5| Step: 9
Training loss: 0.10306596755981445
Validation loss: 1.499883267187303

Epoch: 5| Step: 10
Training loss: 0.11342970281839371
Validation loss: 1.4853667764253513

Epoch: 471| Step: 0
Training loss: 0.09697523713111877
Validation loss: 1.49372039815431

Epoch: 5| Step: 1
Training loss: 0.10506904125213623
Validation loss: 1.5017460917913785

Epoch: 5| Step: 2
Training loss: 0.09206526726484299
Validation loss: 1.487205518189297

Epoch: 5| Step: 3
Training loss: 0.06801506876945496
Validation loss: 1.4841917073854836

Epoch: 5| Step: 4
Training loss: 0.09751955419778824
Validation loss: 1.4786947683621479

Epoch: 5| Step: 5
Training loss: 0.13354209065437317
Validation loss: 1.466703866117744

Epoch: 5| Step: 6
Training loss: 0.09010905027389526
Validation loss: 1.4755719259221067

Epoch: 5| Step: 7
Training loss: 0.1226658821105957
Validation loss: 1.4978961111396871

Epoch: 5| Step: 8
Training loss: 0.1850096881389618
Validation loss: 1.4724898363954277

Epoch: 5| Step: 9
Training loss: 0.07525160163640976
Validation loss: 1.4674808306078757

Epoch: 5| Step: 10
Training loss: 0.2423640489578247
Validation loss: 1.4570618752510316

Epoch: 472| Step: 0
Training loss: 0.1083746924996376
Validation loss: 1.4760329402903074

Epoch: 5| Step: 1
Training loss: 0.05980765074491501
Validation loss: 1.4833292384301462

Epoch: 5| Step: 2
Training loss: 0.14071610569953918
Validation loss: 1.4711187347289054

Epoch: 5| Step: 3
Training loss: 0.192649245262146
Validation loss: 1.4711911729587022

Epoch: 5| Step: 4
Training loss: 0.1734468638896942
Validation loss: 1.4329108371529529

Epoch: 5| Step: 5
Training loss: 0.12545597553253174
Validation loss: 1.452579846946142

Epoch: 5| Step: 6
Training loss: 0.16172680258750916
Validation loss: 1.4472865263621013

Epoch: 5| Step: 7
Training loss: 0.07039870321750641
Validation loss: 1.4432477925413398

Epoch: 5| Step: 8
Training loss: 0.06195307895541191
Validation loss: 1.4595503037975681

Epoch: 5| Step: 9
Training loss: 0.09355664253234863
Validation loss: 1.4614952443748392

Epoch: 5| Step: 10
Training loss: 0.11769314110279083
Validation loss: 1.465313446137213

Epoch: 473| Step: 0
Training loss: 0.2068709433078766
Validation loss: 1.463379236959642

Epoch: 5| Step: 1
Training loss: 0.1613602191209793
Validation loss: 1.4785585441896993

Epoch: 5| Step: 2
Training loss: 0.11202926933765411
Validation loss: 1.467030208597901

Epoch: 5| Step: 3
Training loss: 0.0944075956940651
Validation loss: 1.4674587031846404

Epoch: 5| Step: 4
Training loss: 0.1104288324713707
Validation loss: 1.4607787696264123

Epoch: 5| Step: 5
Training loss: 0.05758511275053024
Validation loss: 1.4575365743329447

Epoch: 5| Step: 6
Training loss: 0.10633178800344467
Validation loss: 1.4582241645423315

Epoch: 5| Step: 7
Training loss: 0.1099439412355423
Validation loss: 1.4790695905685425

Epoch: 5| Step: 8
Training loss: 0.09936419874429703
Validation loss: 1.4697653144918463

Epoch: 5| Step: 9
Training loss: 0.10354164987802505
Validation loss: 1.4927787062942341

Epoch: 5| Step: 10
Training loss: 0.13563767075538635
Validation loss: 1.4585097310363606

Epoch: 474| Step: 0
Training loss: 0.13129988312721252
Validation loss: 1.4862474497928415

Epoch: 5| Step: 1
Training loss: 0.09626023471355438
Validation loss: 1.4658527720359065

Epoch: 5| Step: 2
Training loss: 0.06977011263370514
Validation loss: 1.4747724122898553

Epoch: 5| Step: 3
Training loss: 0.0937628298997879
Validation loss: 1.455088864090622

Epoch: 5| Step: 4
Training loss: 0.08576984703540802
Validation loss: 1.453942947490241

Epoch: 5| Step: 5
Training loss: 0.170912504196167
Validation loss: 1.4496646324793498

Epoch: 5| Step: 6
Training loss: 0.13745923340320587
Validation loss: 1.4646344889876663

Epoch: 5| Step: 7
Training loss: 0.06442336738109589
Validation loss: 1.467498746610457

Epoch: 5| Step: 8
Training loss: 0.10707615315914154
Validation loss: 1.444799026494385

Epoch: 5| Step: 9
Training loss: 0.1701919287443161
Validation loss: 1.4475854609602241

Epoch: 5| Step: 10
Training loss: 0.08165457844734192
Validation loss: 1.45288565979209

Epoch: 475| Step: 0
Training loss: 0.15799856185913086
Validation loss: 1.4282210366700285

Epoch: 5| Step: 1
Training loss: 0.14959660172462463
Validation loss: 1.4434265052118609

Epoch: 5| Step: 2
Training loss: 0.08697780221700668
Validation loss: 1.4696006057082966

Epoch: 5| Step: 3
Training loss: 0.15125475823879242
Validation loss: 1.440668511134322

Epoch: 5| Step: 4
Training loss: 0.16756519675254822
Validation loss: 1.4455962783546858

Epoch: 5| Step: 5
Training loss: 0.08879611641168594
Validation loss: 1.444209865344468

Epoch: 5| Step: 6
Training loss: 0.13531973958015442
Validation loss: 1.4490189821489396

Epoch: 5| Step: 7
Training loss: 0.07358719408512115
Validation loss: 1.4502826147182013

Epoch: 5| Step: 8
Training loss: 0.21499848365783691
Validation loss: 1.4783174043060632

Epoch: 5| Step: 9
Training loss: 0.15993687510490417
Validation loss: 1.4392092497118059

Epoch: 5| Step: 10
Training loss: 0.12285558134317398
Validation loss: 1.446308410295876

Epoch: 476| Step: 0
Training loss: 0.12873975932598114
Validation loss: 1.480027889692655

Epoch: 5| Step: 1
Training loss: 0.1134975329041481
Validation loss: 1.467482324569456

Epoch: 5| Step: 2
Training loss: 0.09800194948911667
Validation loss: 1.4764294560237596

Epoch: 5| Step: 3
Training loss: 0.10097756236791611
Validation loss: 1.4927767284454838

Epoch: 5| Step: 4
Training loss: 0.08484924584627151
Validation loss: 1.4675731658935547

Epoch: 5| Step: 5
Training loss: 0.15458673238754272
Validation loss: 1.468159342324862

Epoch: 5| Step: 6
Training loss: 0.1263391375541687
Validation loss: 1.4756783298266831

Epoch: 5| Step: 7
Training loss: 0.11805667728185654
Validation loss: 1.4752393973770963

Epoch: 5| Step: 8
Training loss: 0.1418224573135376
Validation loss: 1.4853015958621938

Epoch: 5| Step: 9
Training loss: 0.11352670192718506
Validation loss: 1.4706186889320292

Epoch: 5| Step: 10
Training loss: 0.08326607942581177
Validation loss: 1.4642757920808689

Epoch: 477| Step: 0
Training loss: 0.07977165281772614
Validation loss: 1.4754858055422384

Epoch: 5| Step: 1
Training loss: 0.13346759974956512
Validation loss: 1.4801568344075193

Epoch: 5| Step: 2
Training loss: 0.06901028752326965
Validation loss: 1.4736663385104107

Epoch: 5| Step: 3
Training loss: 0.058626651763916016
Validation loss: 1.457861590129073

Epoch: 5| Step: 4
Training loss: 0.1956142634153366
Validation loss: 1.470038898529545

Epoch: 5| Step: 5
Training loss: 0.11003135144710541
Validation loss: 1.464976022320409

Epoch: 5| Step: 6
Training loss: 0.1277659833431244
Validation loss: 1.4699813672291335

Epoch: 5| Step: 7
Training loss: 0.18345531821250916
Validation loss: 1.468979848328457

Epoch: 5| Step: 8
Training loss: 0.12978003919124603
Validation loss: 1.4808553380350913

Epoch: 5| Step: 9
Training loss: 0.0732044130563736
Validation loss: 1.4960537918152348

Epoch: 5| Step: 10
Training loss: 0.07565898448228836
Validation loss: 1.4618449864848968

Epoch: 478| Step: 0
Training loss: 0.06968796253204346
Validation loss: 1.473125273181546

Epoch: 5| Step: 1
Training loss: 0.07203086465597153
Validation loss: 1.4552414308312118

Epoch: 5| Step: 2
Training loss: 0.09930846840143204
Validation loss: 1.4476611139953777

Epoch: 5| Step: 3
Training loss: 0.07872150838375092
Validation loss: 1.4858023658875497

Epoch: 5| Step: 4
Training loss: 0.1825547218322754
Validation loss: 1.5021892209206857

Epoch: 5| Step: 5
Training loss: 0.11587353050708771
Validation loss: 1.473181983476044

Epoch: 5| Step: 6
Training loss: 0.16119350492954254
Validation loss: 1.4759584396116194

Epoch: 5| Step: 7
Training loss: 0.09407006204128265
Validation loss: 1.5082053606228163

Epoch: 5| Step: 8
Training loss: 0.09801659733057022
Validation loss: 1.506235844345503

Epoch: 5| Step: 9
Training loss: 0.09700209647417068
Validation loss: 1.4891816916004303

Epoch: 5| Step: 10
Training loss: 0.14586712419986725
Validation loss: 1.4773368514994139

Epoch: 479| Step: 0
Training loss: 0.12224849313497543
Validation loss: 1.441010852013865

Epoch: 5| Step: 1
Training loss: 0.10612782090902328
Validation loss: 1.447460521933853

Epoch: 5| Step: 2
Training loss: 0.1382218897342682
Validation loss: 1.4231291432534494

Epoch: 5| Step: 3
Training loss: 0.20259277522563934
Validation loss: 1.427060681004678

Epoch: 5| Step: 4
Training loss: 0.12367270141839981
Validation loss: 1.4379842691524054

Epoch: 5| Step: 5
Training loss: 0.1514192819595337
Validation loss: 1.423306227371257

Epoch: 5| Step: 6
Training loss: 0.07448671758174896
Validation loss: 1.447033078439774

Epoch: 5| Step: 7
Training loss: 0.08030620962381363
Validation loss: 1.4395518443917716

Epoch: 5| Step: 8
Training loss: 0.14379222691059113
Validation loss: 1.451510593455325

Epoch: 5| Step: 9
Training loss: 0.06620822846889496
Validation loss: 1.4575041237697806

Epoch: 5| Step: 10
Training loss: 0.07731730490922928
Validation loss: 1.4465050569144629

Epoch: 480| Step: 0
Training loss: 0.1412748098373413
Validation loss: 1.4714109038793912

Epoch: 5| Step: 1
Training loss: 0.07080257683992386
Validation loss: 1.473170075365292

Epoch: 5| Step: 2
Training loss: 0.1097743883728981
Validation loss: 1.4738146169211275

Epoch: 5| Step: 3
Training loss: 0.09702004492282867
Validation loss: 1.4825572762438046

Epoch: 5| Step: 4
Training loss: 0.14407172799110413
Validation loss: 1.4666213027892574

Epoch: 5| Step: 5
Training loss: 0.09530550986528397
Validation loss: 1.4772515655845724

Epoch: 5| Step: 6
Training loss: 0.07431217283010483
Validation loss: 1.4326385509583257

Epoch: 5| Step: 7
Training loss: 0.06242680549621582
Validation loss: 1.4572316882430867

Epoch: 5| Step: 8
Training loss: 0.08579651266336441
Validation loss: 1.450795961964515

Epoch: 5| Step: 9
Training loss: 0.22465696930885315
Validation loss: 1.4790363773222892

Epoch: 5| Step: 10
Training loss: 0.11508724838495255
Validation loss: 1.467397077109224

Epoch: 481| Step: 0
Training loss: 0.06460399925708771
Validation loss: 1.444305366726332

Epoch: 5| Step: 1
Training loss: 0.1147865429520607
Validation loss: 1.4314343224289596

Epoch: 5| Step: 2
Training loss: 0.06344811618328094
Validation loss: 1.45220467223916

Epoch: 5| Step: 3
Training loss: 0.08103606849908829
Validation loss: 1.4547224506255119

Epoch: 5| Step: 4
Training loss: 0.09107870608568192
Validation loss: 1.4684851297768213

Epoch: 5| Step: 5
Training loss: 0.05559806898236275
Validation loss: 1.4395744582658172

Epoch: 5| Step: 6
Training loss: 0.11502553522586823
Validation loss: 1.4472429880531885

Epoch: 5| Step: 7
Training loss: 0.26084378361701965
Validation loss: 1.4436297262868574

Epoch: 5| Step: 8
Training loss: 0.09182123094797134
Validation loss: 1.4270999662337764

Epoch: 5| Step: 9
Training loss: 0.08393619954586029
Validation loss: 1.427578397976455

Epoch: 5| Step: 10
Training loss: 0.08716046065092087
Validation loss: 1.4337343759434198

Epoch: 482| Step: 0
Training loss: 0.11837494373321533
Validation loss: 1.4130435207838654

Epoch: 5| Step: 1
Training loss: 0.11052630096673965
Validation loss: 1.4285083060623498

Epoch: 5| Step: 2
Training loss: 0.1306847631931305
Validation loss: 1.4246243110267065

Epoch: 5| Step: 3
Training loss: 0.061922259628772736
Validation loss: 1.4399523837592012

Epoch: 5| Step: 4
Training loss: 0.056451499462127686
Validation loss: 1.4429335863359514

Epoch: 5| Step: 5
Training loss: 0.09877026826143265
Validation loss: 1.4638153917046004

Epoch: 5| Step: 6
Training loss: 0.16790737211704254
Validation loss: 1.4574407441641695

Epoch: 5| Step: 7
Training loss: 0.09098514169454575
Validation loss: 1.4449053284942464

Epoch: 5| Step: 8
Training loss: 0.15761205554008484
Validation loss: 1.4429035186767578

Epoch: 5| Step: 9
Training loss: 0.09977532923221588
Validation loss: 1.4508438110351562

Epoch: 5| Step: 10
Training loss: 0.1073470190167427
Validation loss: 1.4483835825356104

Epoch: 483| Step: 0
Training loss: 0.10485521703958511
Validation loss: 1.431947636347945

Epoch: 5| Step: 1
Training loss: 0.14402209222316742
Validation loss: 1.4325221264234154

Epoch: 5| Step: 2
Training loss: 0.11924906075000763
Validation loss: 1.4105002976232959

Epoch: 5| Step: 3
Training loss: 0.13327863812446594
Validation loss: 1.4501574744460404

Epoch: 5| Step: 4
Training loss: 0.08681827783584595
Validation loss: 1.4427283912576654

Epoch: 5| Step: 5
Training loss: 0.08281783759593964
Validation loss: 1.436225833431367

Epoch: 5| Step: 6
Training loss: 0.0563645139336586
Validation loss: 1.4496608165002638

Epoch: 5| Step: 7
Training loss: 0.10565590858459473
Validation loss: 1.472761170838469

Epoch: 5| Step: 8
Training loss: 0.09596209228038788
Validation loss: 1.4671587431302635

Epoch: 5| Step: 9
Training loss: 0.1427588015794754
Validation loss: 1.4853408144366356

Epoch: 5| Step: 10
Training loss: 0.10021618008613586
Validation loss: 1.4612119018390615

Epoch: 484| Step: 0
Training loss: 0.06894006580114365
Validation loss: 1.4645111503139618

Epoch: 5| Step: 1
Training loss: 0.06025887653231621
Validation loss: 1.4596813494159329

Epoch: 5| Step: 2
Training loss: 0.2153262197971344
Validation loss: 1.443790380672742

Epoch: 5| Step: 3
Training loss: 0.18738776445388794
Validation loss: 1.4731137688441942

Epoch: 5| Step: 4
Training loss: 0.17609558999538422
Validation loss: 1.4560067884383663

Epoch: 5| Step: 5
Training loss: 0.14730902016162872
Validation loss: 1.446286334786364

Epoch: 5| Step: 6
Training loss: 0.06717081367969513
Validation loss: 1.481180444840462

Epoch: 5| Step: 7
Training loss: 0.07680317759513855
Validation loss: 1.4667677494787401

Epoch: 5| Step: 8
Training loss: 0.08880393207073212
Validation loss: 1.4699427197056432

Epoch: 5| Step: 9
Training loss: 0.1908486783504486
Validation loss: 1.4932450363712926

Epoch: 5| Step: 10
Training loss: 0.11698617786169052
Validation loss: 1.495079823719558

Epoch: 485| Step: 0
Training loss: 0.10058838129043579
Validation loss: 1.4951429315792617

Epoch: 5| Step: 1
Training loss: 0.09413523972034454
Validation loss: 1.4943752673364454

Epoch: 5| Step: 2
Training loss: 0.12502416968345642
Validation loss: 1.446659008661906

Epoch: 5| Step: 3
Training loss: 0.1102481484413147
Validation loss: 1.4539413964876564

Epoch: 5| Step: 4
Training loss: 0.22258663177490234
Validation loss: 1.4661124598595403

Epoch: 5| Step: 5
Training loss: 0.0891159251332283
Validation loss: 1.4818819594639603

Epoch: 5| Step: 6
Training loss: 0.1561187505722046
Validation loss: 1.4774946307623258

Epoch: 5| Step: 7
Training loss: 0.09982285648584366
Validation loss: 1.4842220211541781

Epoch: 5| Step: 8
Training loss: 0.09178151935338974
Validation loss: 1.488306914606402

Epoch: 5| Step: 9
Training loss: 0.13158836960792542
Validation loss: 1.485663346064988

Epoch: 5| Step: 10
Training loss: 0.06902431696653366
Validation loss: 1.5009948797123407

Epoch: 486| Step: 0
Training loss: 0.10193351656198502
Validation loss: 1.4598146715471823

Epoch: 5| Step: 1
Training loss: 0.13260097801685333
Validation loss: 1.4785198626979705

Epoch: 5| Step: 2
Training loss: 0.13649728894233704
Validation loss: 1.488898605428716

Epoch: 5| Step: 3
Training loss: 0.06395424157381058
Validation loss: 1.4625390960324196

Epoch: 5| Step: 4
Training loss: 0.10743026435375214
Validation loss: 1.4615388378020255

Epoch: 5| Step: 5
Training loss: 0.13929559290409088
Validation loss: 1.460621811369414

Epoch: 5| Step: 6
Training loss: 0.1340668648481369
Validation loss: 1.4535854683127454

Epoch: 5| Step: 7
Training loss: 0.1060241237282753
Validation loss: 1.4555647706472745

Epoch: 5| Step: 8
Training loss: 0.08710688352584839
Validation loss: 1.457072260559246

Epoch: 5| Step: 9
Training loss: 0.09210159629583359
Validation loss: 1.4631676609798143

Epoch: 5| Step: 10
Training loss: 0.05115869641304016
Validation loss: 1.458912209797931

Epoch: 487| Step: 0
Training loss: 0.1544235199689865
Validation loss: 1.475643257940969

Epoch: 5| Step: 1
Training loss: 0.07041139900684357
Validation loss: 1.438762157194076

Epoch: 5| Step: 2
Training loss: 0.04453097656369209
Validation loss: 1.4516471899965757

Epoch: 5| Step: 3
Training loss: 0.08712074905633926
Validation loss: 1.4468497037887573

Epoch: 5| Step: 4
Training loss: 0.11068107187747955
Validation loss: 1.4491109367339843

Epoch: 5| Step: 5
Training loss: 0.12808595597743988
Validation loss: 1.4477040690760459

Epoch: 5| Step: 6
Training loss: 0.10212733596563339
Validation loss: 1.459853022329269

Epoch: 5| Step: 7
Training loss: 0.1277078092098236
Validation loss: 1.452365795771281

Epoch: 5| Step: 8
Training loss: 0.08848880976438522
Validation loss: 1.4817897427466609

Epoch: 5| Step: 9
Training loss: 0.12445278465747833
Validation loss: 1.4838200833207817

Epoch: 5| Step: 10
Training loss: 0.1358094960451126
Validation loss: 1.4958029344517698

Epoch: 488| Step: 0
Training loss: 0.08269613981246948
Validation loss: 1.4956703865399925

Epoch: 5| Step: 1
Training loss: 0.07511535286903381
Validation loss: 1.4814196389208558

Epoch: 5| Step: 2
Training loss: 0.1049460917711258
Validation loss: 1.4505347551838044

Epoch: 5| Step: 3
Training loss: 0.10571552813053131
Validation loss: 1.4732627791743125

Epoch: 5| Step: 4
Training loss: 0.10398000478744507
Validation loss: 1.4766342691195908

Epoch: 5| Step: 5
Training loss: 0.14370553195476532
Validation loss: 1.4889339234239312

Epoch: 5| Step: 6
Training loss: 0.05073963478207588
Validation loss: 1.474237815026314

Epoch: 5| Step: 7
Training loss: 0.1789577603340149
Validation loss: 1.46166996161143

Epoch: 5| Step: 8
Training loss: 0.125330850481987
Validation loss: 1.4710611527965916

Epoch: 5| Step: 9
Training loss: 0.10826928913593292
Validation loss: 1.4669921321253623

Epoch: 5| Step: 10
Training loss: 0.15851758420467377
Validation loss: 1.437253684766831

Epoch: 489| Step: 0
Training loss: 0.10625261068344116
Validation loss: 1.4254596489731983

Epoch: 5| Step: 1
Training loss: 0.1476740688085556
Validation loss: 1.4427498553388862

Epoch: 5| Step: 2
Training loss: 0.10742151737213135
Validation loss: 1.4382529335637246

Epoch: 5| Step: 3
Training loss: 0.16341514885425568
Validation loss: 1.452905898453087

Epoch: 5| Step: 4
Training loss: 0.1277739405632019
Validation loss: 1.4737016565056258

Epoch: 5| Step: 5
Training loss: 0.08197423070669174
Validation loss: 1.481608158798628

Epoch: 5| Step: 6
Training loss: 0.11553005874156952
Validation loss: 1.46072353342528

Epoch: 5| Step: 7
Training loss: 0.10133419930934906
Validation loss: 1.4657307696598831

Epoch: 5| Step: 8
Training loss: 0.1928386390209198
Validation loss: 1.4883227732873732

Epoch: 5| Step: 9
Training loss: 0.07985869795084
Validation loss: 1.4596040723144368

Epoch: 5| Step: 10
Training loss: 0.11190734058618546
Validation loss: 1.467151777718657

Epoch: 490| Step: 0
Training loss: 0.09984682500362396
Validation loss: 1.4564803287547121

Epoch: 5| Step: 1
Training loss: 0.06903193891048431
Validation loss: 1.4757787822395243

Epoch: 5| Step: 2
Training loss: 0.09920104593038559
Validation loss: 1.4744618259450442

Epoch: 5| Step: 3
Training loss: 0.12064210325479507
Validation loss: 1.4586922096949753

Epoch: 5| Step: 4
Training loss: 0.12648367881774902
Validation loss: 1.4636633556376222

Epoch: 5| Step: 5
Training loss: 0.09031672030687332
Validation loss: 1.4644288145085818

Epoch: 5| Step: 6
Training loss: 0.04731704667210579
Validation loss: 1.4630955893506286

Epoch: 5| Step: 7
Training loss: 0.17025795578956604
Validation loss: 1.464049412999102

Epoch: 5| Step: 8
Training loss: 0.05740007013082504
Validation loss: 1.4654196975051716

Epoch: 5| Step: 9
Training loss: 0.05525108426809311
Validation loss: 1.443918094840101

Epoch: 5| Step: 10
Training loss: 0.09399240463972092
Validation loss: 1.4652476785003499

Epoch: 491| Step: 0
Training loss: 0.1474199742078781
Validation loss: 1.4519671009432884

Epoch: 5| Step: 1
Training loss: 0.07128974050283432
Validation loss: 1.4558385546489427

Epoch: 5| Step: 2
Training loss: 0.11416181176900864
Validation loss: 1.4385997787598641

Epoch: 5| Step: 3
Training loss: 0.13043175637722015
Validation loss: 1.447423097907856

Epoch: 5| Step: 4
Training loss: 0.06813518702983856
Validation loss: 1.4305700525160758

Epoch: 5| Step: 5
Training loss: 0.11399145424365997
Validation loss: 1.4488288612775906

Epoch: 5| Step: 6
Training loss: 0.10872642695903778
Validation loss: 1.4374743860255006

Epoch: 5| Step: 7
Training loss: 0.09621479362249374
Validation loss: 1.441474901732578

Epoch: 5| Step: 8
Training loss: 0.08444570004940033
Validation loss: 1.4329969857328682

Epoch: 5| Step: 9
Training loss: 0.10218994319438934
Validation loss: 1.4281676385992317

Epoch: 5| Step: 10
Training loss: 0.0748995766043663
Validation loss: 1.4411350398935296

Epoch: 492| Step: 0
Training loss: 0.06076637655496597
Validation loss: 1.4442511104768323

Epoch: 5| Step: 1
Training loss: 0.17903831601142883
Validation loss: 1.4639346202214558

Epoch: 5| Step: 2
Training loss: 0.15059030055999756
Validation loss: 1.4356740738755913

Epoch: 5| Step: 3
Training loss: 0.08783866465091705
Validation loss: 1.4610692378013366

Epoch: 5| Step: 4
Training loss: 0.10632503032684326
Validation loss: 1.4605739373032764

Epoch: 5| Step: 5
Training loss: 0.08335672318935394
Validation loss: 1.469240261662391

Epoch: 5| Step: 6
Training loss: 0.08069731295108795
Validation loss: 1.4802557178722915

Epoch: 5| Step: 7
Training loss: 0.08324108272790909
Validation loss: 1.4623033974760322

Epoch: 5| Step: 8
Training loss: 0.09288619458675385
Validation loss: 1.4930222149818175

Epoch: 5| Step: 9
Training loss: 0.11228706687688828
Validation loss: 1.454237876399871

Epoch: 5| Step: 10
Training loss: 0.10864561796188354
Validation loss: 1.4588705403830415

Epoch: 493| Step: 0
Training loss: 0.15180036425590515
Validation loss: 1.4516599127041396

Epoch: 5| Step: 1
Training loss: 0.0888422280550003
Validation loss: 1.4407770300424227

Epoch: 5| Step: 2
Training loss: 0.10899615287780762
Validation loss: 1.4398144880930583

Epoch: 5| Step: 3
Training loss: 0.08388233929872513
Validation loss: 1.448765141989595

Epoch: 5| Step: 4
Training loss: 0.09014985710382462
Validation loss: 1.4696389372630785

Epoch: 5| Step: 5
Training loss: 0.08636830747127533
Validation loss: 1.443887323461553

Epoch: 5| Step: 6
Training loss: 0.13929612934589386
Validation loss: 1.4626487288423764

Epoch: 5| Step: 7
Training loss: 0.10907350480556488
Validation loss: 1.446273487101319

Epoch: 5| Step: 8
Training loss: 0.11675716936588287
Validation loss: 1.4606699482087167

Epoch: 5| Step: 9
Training loss: 0.060186922550201416
Validation loss: 1.4543243454348656

Epoch: 5| Step: 10
Training loss: 0.153783917427063
Validation loss: 1.4567117114220896

Epoch: 494| Step: 0
Training loss: 0.09077659994363785
Validation loss: 1.4270792231764844

Epoch: 5| Step: 1
Training loss: 0.07010652124881744
Validation loss: 1.4606408508875037

Epoch: 5| Step: 2
Training loss: 0.18671268224716187
Validation loss: 1.4489281792794504

Epoch: 5| Step: 3
Training loss: 0.061204470694065094
Validation loss: 1.4486522264378046

Epoch: 5| Step: 4
Training loss: 0.14031513035297394
Validation loss: 1.4539284360024236

Epoch: 5| Step: 5
Training loss: 0.05849176645278931
Validation loss: 1.463005563264252

Epoch: 5| Step: 6
Training loss: 0.07437034696340561
Validation loss: 1.472385589794446

Epoch: 5| Step: 7
Training loss: 0.0873829573392868
Validation loss: 1.4720825687531502

Epoch: 5| Step: 8
Training loss: 0.11957023292779922
Validation loss: 1.4546941339328725

Epoch: 5| Step: 9
Training loss: 0.08677615970373154
Validation loss: 1.4453578700301468

Epoch: 5| Step: 10
Training loss: 0.11923645436763763
Validation loss: 1.4556011057669116

Epoch: 495| Step: 0
Training loss: 0.09470032900571823
Validation loss: 1.4336293653775287

Epoch: 5| Step: 1
Training loss: 0.06144694238901138
Validation loss: 1.4556860180311306

Epoch: 5| Step: 2
Training loss: 0.09526392817497253
Validation loss: 1.44114427925438

Epoch: 5| Step: 3
Training loss: 0.07322213053703308
Validation loss: 1.4600742363160657

Epoch: 5| Step: 4
Training loss: 0.20161619782447815
Validation loss: 1.4514500530817176

Epoch: 5| Step: 5
Training loss: 0.08700283616781235
Validation loss: 1.4393860479836822

Epoch: 5| Step: 6
Training loss: 0.07282226532697678
Validation loss: 1.463843987834069

Epoch: 5| Step: 7
Training loss: 0.09365876019001007
Validation loss: 1.4624106653275029

Epoch: 5| Step: 8
Training loss: 0.07541894167661667
Validation loss: 1.4540101905022897

Epoch: 5| Step: 9
Training loss: 0.09782575070858002
Validation loss: 1.4555933360130555

Epoch: 5| Step: 10
Training loss: 0.08941466361284256
Validation loss: 1.4821946864487023

Epoch: 496| Step: 0
Training loss: 0.1435740888118744
Validation loss: 1.4582311030357116

Epoch: 5| Step: 1
Training loss: 0.0789727121591568
Validation loss: 1.4600841665780673

Epoch: 5| Step: 2
Training loss: 0.07121440023183823
Validation loss: 1.4678617433835102

Epoch: 5| Step: 3
Training loss: 0.12814243137836456
Validation loss: 1.4706576575515091

Epoch: 5| Step: 4
Training loss: 0.06969600915908813
Validation loss: 1.457520713088333

Epoch: 5| Step: 5
Training loss: 0.07006001472473145
Validation loss: 1.4695141289823799

Epoch: 5| Step: 6
Training loss: 0.09502257406711578
Validation loss: 1.481659773857363

Epoch: 5| Step: 7
Training loss: 0.11899328231811523
Validation loss: 1.4687533916965607

Epoch: 5| Step: 8
Training loss: 0.12568692862987518
Validation loss: 1.4707135077445739

Epoch: 5| Step: 9
Training loss: 0.047424979507923126
Validation loss: 1.4706285397211711

Epoch: 5| Step: 10
Training loss: 0.13805708289146423
Validation loss: 1.4689674082622732

Epoch: 497| Step: 0
Training loss: 0.10513138771057129
Validation loss: 1.4877833448430544

Epoch: 5| Step: 1
Training loss: 0.06849709153175354
Validation loss: 1.4720366513857277

Epoch: 5| Step: 2
Training loss: 0.07585412263870239
Validation loss: 1.473226595950383

Epoch: 5| Step: 3
Training loss: 0.15003123879432678
Validation loss: 1.4499348325114096

Epoch: 5| Step: 4
Training loss: 0.1268046349287033
Validation loss: 1.449145891333139

Epoch: 5| Step: 5
Training loss: 0.08196709305047989
Validation loss: 1.467791118929463

Epoch: 5| Step: 6
Training loss: 0.08587674796581268
Validation loss: 1.474807313693467

Epoch: 5| Step: 7
Training loss: 0.10357715934515
Validation loss: 1.4598957056640296

Epoch: 5| Step: 8
Training loss: 0.15928497910499573
Validation loss: 1.4869263877150833

Epoch: 5| Step: 9
Training loss: 0.10118870437145233
Validation loss: 1.457819143931071

Epoch: 5| Step: 10
Training loss: 0.10243736952543259
Validation loss: 1.4677602526962117

Epoch: 498| Step: 0
Training loss: 0.0823526531457901
Validation loss: 1.4640087119994625

Epoch: 5| Step: 1
Training loss: 0.0939531996846199
Validation loss: 1.4505649176977014

Epoch: 5| Step: 2
Training loss: 0.07641635835170746
Validation loss: 1.4270849202268867

Epoch: 5| Step: 3
Training loss: 0.07747037708759308
Validation loss: 1.4253655184981644

Epoch: 5| Step: 4
Training loss: 0.07660768926143646
Validation loss: 1.4350845249750281

Epoch: 5| Step: 5
Training loss: 0.130406454205513
Validation loss: 1.459421661592299

Epoch: 5| Step: 6
Training loss: 0.133053258061409
Validation loss: 1.4317725730198685

Epoch: 5| Step: 7
Training loss: 0.10718349367380142
Validation loss: 1.4404136096277544

Epoch: 5| Step: 8
Training loss: 0.1313381940126419
Validation loss: 1.4277663439191797

Epoch: 5| Step: 9
Training loss: 0.11211024224758148
Validation loss: 1.4425126301345004

Epoch: 5| Step: 10
Training loss: 0.052037857472896576
Validation loss: 1.4379030568625337

Epoch: 499| Step: 0
Training loss: 0.06465619057416916
Validation loss: 1.457870207807069

Epoch: 5| Step: 1
Training loss: 0.06870101392269135
Validation loss: 1.4572707901718795

Epoch: 5| Step: 2
Training loss: 0.06124497205018997
Validation loss: 1.4304516110368954

Epoch: 5| Step: 3
Training loss: 0.09809335321187973
Validation loss: 1.4503644640727709

Epoch: 5| Step: 4
Training loss: 0.0995795875787735
Validation loss: 1.4305284427058311

Epoch: 5| Step: 5
Training loss: 0.1189001202583313
Validation loss: 1.430606847168297

Epoch: 5| Step: 6
Training loss: 0.07899560034275055
Validation loss: 1.4418151891359718

Epoch: 5| Step: 7
Training loss: 0.2166016548871994
Validation loss: 1.4495349930178734

Epoch: 5| Step: 8
Training loss: 0.05925871804356575
Validation loss: 1.4486081292552333

Epoch: 5| Step: 9
Training loss: 0.08213551342487335
Validation loss: 1.4453293937508778

Epoch: 5| Step: 10
Training loss: 0.12006840854883194
Validation loss: 1.4568985828789331

Epoch: 500| Step: 0
Training loss: 0.06901291012763977
Validation loss: 1.4652692258998912

Epoch: 5| Step: 1
Training loss: 0.12256269156932831
Validation loss: 1.47694779211475

Epoch: 5| Step: 2
Training loss: 0.09941430389881134
Validation loss: 1.464192190477925

Epoch: 5| Step: 3
Training loss: 0.1230984777212143
Validation loss: 1.4517754380420973

Epoch: 5| Step: 4
Training loss: 0.18209773302078247
Validation loss: 1.4438532680593512

Epoch: 5| Step: 5
Training loss: 0.1440603882074356
Validation loss: 1.4439590810447611

Epoch: 5| Step: 6
Training loss: 0.08330394327640533
Validation loss: 1.4414403515477334

Epoch: 5| Step: 7
Training loss: 0.12217231839895248
Validation loss: 1.4496115317908667

Epoch: 5| Step: 8
Training loss: 0.08659979701042175
Validation loss: 1.45685943993189

Epoch: 5| Step: 9
Training loss: 0.081209696829319
Validation loss: 1.453649078646014

Epoch: 5| Step: 10
Training loss: 0.11326054483652115
Validation loss: 1.443870077850998

Epoch: 501| Step: 0
Training loss: 0.07975395768880844
Validation loss: 1.4531877476681945

Epoch: 5| Step: 1
Training loss: 0.1955711394548416
Validation loss: 1.4538701054870442

Epoch: 5| Step: 2
Training loss: 0.08182688057422638
Validation loss: 1.4519889444433234

Epoch: 5| Step: 3
Training loss: 0.0913081020116806
Validation loss: 1.460784387844865

Epoch: 5| Step: 4
Training loss: 0.10100345313549042
Validation loss: 1.4741685928836945

Epoch: 5| Step: 5
Training loss: 0.09096066653728485
Validation loss: 1.4778792230031823

Epoch: 5| Step: 6
Training loss: 0.08921068161725998
Validation loss: 1.47354079574667

Epoch: 5| Step: 7
Training loss: 0.09167361259460449
Validation loss: 1.4618126833310692

Epoch: 5| Step: 8
Training loss: 0.09580084681510925
Validation loss: 1.4670882724946546

Epoch: 5| Step: 9
Training loss: 0.10121957957744598
Validation loss: 1.4811231666995632

Epoch: 5| Step: 10
Training loss: 0.10393312573432922
Validation loss: 1.4742635744874195

Epoch: 502| Step: 0
Training loss: 0.16338388621807098
Validation loss: 1.4918988199644192

Epoch: 5| Step: 1
Training loss: 0.14583437144756317
Validation loss: 1.4953831998250817

Epoch: 5| Step: 2
Training loss: 0.11183509975671768
Validation loss: 1.4673665544038177

Epoch: 5| Step: 3
Training loss: 0.10322873294353485
Validation loss: 1.486058920942327

Epoch: 5| Step: 4
Training loss: 0.12414328753948212
Validation loss: 1.4786931776231336

Epoch: 5| Step: 5
Training loss: 0.12505514919757843
Validation loss: 1.4645059531734836

Epoch: 5| Step: 6
Training loss: 0.09055902063846588
Validation loss: 1.4684937372002551

Epoch: 5| Step: 7
Training loss: 0.10271777957677841
Validation loss: 1.4601630613368044

Epoch: 5| Step: 8
Training loss: 0.07644295692443848
Validation loss: 1.4400452644594255

Epoch: 5| Step: 9
Training loss: 0.10801134258508682
Validation loss: 1.4198886681628484

Epoch: 5| Step: 10
Training loss: 0.0941619873046875
Validation loss: 1.4292718646346882

Epoch: 503| Step: 0
Training loss: 0.10905832052230835
Validation loss: 1.4166808660312364

Epoch: 5| Step: 1
Training loss: 0.10408779233694077
Validation loss: 1.4381529259425339

Epoch: 5| Step: 2
Training loss: 0.1560923159122467
Validation loss: 1.4484400762024747

Epoch: 5| Step: 3
Training loss: 0.21156540513038635
Validation loss: 1.4607675434440694

Epoch: 5| Step: 4
Training loss: 0.06116436794400215
Validation loss: 1.4364265645703962

Epoch: 5| Step: 5
Training loss: 0.12544329464435577
Validation loss: 1.4153888046100576

Epoch: 5| Step: 6
Training loss: 0.08642818033695221
Validation loss: 1.4222029562919372

Epoch: 5| Step: 7
Training loss: 0.07839169353246689
Validation loss: 1.401219988381991

Epoch: 5| Step: 8
Training loss: 0.060945648699998856
Validation loss: 1.4149882325562098

Epoch: 5| Step: 9
Training loss: 0.13814617693424225
Validation loss: 1.4098492873612272

Epoch: 5| Step: 10
Training loss: 0.10819095373153687
Validation loss: 1.4002942506984999

Epoch: 504| Step: 0
Training loss: 0.1181572899222374
Validation loss: 1.4274945566731114

Epoch: 5| Step: 1
Training loss: 0.09703115373849869
Validation loss: 1.402513998810963

Epoch: 5| Step: 2
Training loss: 0.22295033931732178
Validation loss: 1.43247514899059

Epoch: 5| Step: 3
Training loss: 0.1350134164094925
Validation loss: 1.4521303279425508

Epoch: 5| Step: 4
Training loss: 0.14065265655517578
Validation loss: 1.4599811979519424

Epoch: 5| Step: 5
Training loss: 0.10675831139087677
Validation loss: 1.4684791068236034

Epoch: 5| Step: 6
Training loss: 0.10262063890695572
Validation loss: 1.4816260837739514

Epoch: 5| Step: 7
Training loss: 0.06384499371051788
Validation loss: 1.4452028312990743

Epoch: 5| Step: 8
Training loss: 0.07312992960214615
Validation loss: 1.4387733462036296

Epoch: 5| Step: 9
Training loss: 0.05506007745862007
Validation loss: 1.4430267528821064

Epoch: 5| Step: 10
Training loss: 0.037105742841959
Validation loss: 1.4479500286040767

Epoch: 505| Step: 0
Training loss: 0.06512881815433502
Validation loss: 1.4274120920447892

Epoch: 5| Step: 1
Training loss: 0.08889243751764297
Validation loss: 1.446464810320126

Epoch: 5| Step: 2
Training loss: 0.09237222373485565
Validation loss: 1.419681788131755

Epoch: 5| Step: 3
Training loss: 0.16876399517059326
Validation loss: 1.426036234824888

Epoch: 5| Step: 4
Training loss: 0.10825165361166
Validation loss: 1.4455945594336397

Epoch: 5| Step: 5
Training loss: 0.121243916451931
Validation loss: 1.4619958913454445

Epoch: 5| Step: 6
Training loss: 0.08527229726314545
Validation loss: 1.417590642488131

Epoch: 5| Step: 7
Training loss: 0.06627071648836136
Validation loss: 1.4342708638919297

Epoch: 5| Step: 8
Training loss: 0.08824088424444199
Validation loss: 1.4405877628634054

Epoch: 5| Step: 9
Training loss: 0.09519912302494049
Validation loss: 1.4182809834839196

Epoch: 5| Step: 10
Training loss: 0.06722734123468399
Validation loss: 1.4239646004092308

Epoch: 506| Step: 0
Training loss: 0.07616331428289413
Validation loss: 1.435495553478118

Epoch: 5| Step: 1
Training loss: 0.11768849939107895
Validation loss: 1.4349274366132674

Epoch: 5| Step: 2
Training loss: 0.09394010156393051
Validation loss: 1.432475968073773

Epoch: 5| Step: 3
Training loss: 0.09650025516748428
Validation loss: 1.434173268656577

Epoch: 5| Step: 4
Training loss: 0.05712514370679855
Validation loss: 1.4508711073988227

Epoch: 5| Step: 5
Training loss: 0.09851257503032684
Validation loss: 1.4274798849577546

Epoch: 5| Step: 6
Training loss: 0.09523172676563263
Validation loss: 1.4392191607465026

Epoch: 5| Step: 7
Training loss: 0.06126786395907402
Validation loss: 1.4079930525954052

Epoch: 5| Step: 8
Training loss: 0.0811150074005127
Validation loss: 1.4271015480000486

Epoch: 5| Step: 9
Training loss: 0.18056008219718933
Validation loss: 1.456354918018464

Epoch: 5| Step: 10
Training loss: 0.15786051750183105
Validation loss: 1.4216224032063638

Epoch: 507| Step: 0
Training loss: 0.09892930090427399
Validation loss: 1.4284130091308265

Epoch: 5| Step: 1
Training loss: 0.08849387615919113
Validation loss: 1.425451922801233

Epoch: 5| Step: 2
Training loss: 0.14579470455646515
Validation loss: 1.40224584328231

Epoch: 5| Step: 3
Training loss: 0.15003368258476257
Validation loss: 1.41661702176576

Epoch: 5| Step: 4
Training loss: 0.1033291220664978
Validation loss: 1.42310086693815

Epoch: 5| Step: 5
Training loss: 0.08258043229579926
Validation loss: 1.4112900783938747

Epoch: 5| Step: 6
Training loss: 0.09040264040231705
Validation loss: 1.4088816078760291

Epoch: 5| Step: 7
Training loss: 0.10421742498874664
Validation loss: 1.4119154573768697

Epoch: 5| Step: 8
Training loss: 0.12449412047863007
Validation loss: 1.4109119458865094

Epoch: 5| Step: 9
Training loss: 0.07288555800914764
Validation loss: 1.415648623179364

Epoch: 5| Step: 10
Training loss: 0.058384306728839874
Validation loss: 1.4366285698388213

Epoch: 508| Step: 0
Training loss: 0.12741920351982117
Validation loss: 1.4321937432853125

Epoch: 5| Step: 1
Training loss: 0.05433940887451172
Validation loss: 1.4421861633177726

Epoch: 5| Step: 2
Training loss: 0.11245624721050262
Validation loss: 1.440252629659509

Epoch: 5| Step: 3
Training loss: 0.11044609546661377
Validation loss: 1.4647313343581332

Epoch: 5| Step: 4
Training loss: 0.14404188096523285
Validation loss: 1.463466457141343

Epoch: 5| Step: 5
Training loss: 0.07821148633956909
Validation loss: 1.4632826082168087

Epoch: 5| Step: 6
Training loss: 0.08703948557376862
Validation loss: 1.469514900638211

Epoch: 5| Step: 7
Training loss: 0.08002138137817383
Validation loss: 1.4561557987684846

Epoch: 5| Step: 8
Training loss: 0.103368379175663
Validation loss: 1.4938886088709677

Epoch: 5| Step: 9
Training loss: 0.12161880731582642
Validation loss: 1.467408319955231

Epoch: 5| Step: 10
Training loss: 0.0705258846282959
Validation loss: 1.4713200587098316

Epoch: 509| Step: 0
Training loss: 0.10747220367193222
Validation loss: 1.4866537381243963

Epoch: 5| Step: 1
Training loss: 0.14772364497184753
Validation loss: 1.4893939956541984

Epoch: 5| Step: 2
Training loss: 0.08586473762989044
Validation loss: 1.4905389470438803

Epoch: 5| Step: 3
Training loss: 0.09132377803325653
Validation loss: 1.4847344429262224

Epoch: 5| Step: 4
Training loss: 0.08456440269947052
Validation loss: 1.4764117412669684

Epoch: 5| Step: 5
Training loss: 0.05356220155954361
Validation loss: 1.4538676597738778

Epoch: 5| Step: 6
Training loss: 0.10229308903217316
Validation loss: 1.4611412325213033

Epoch: 5| Step: 7
Training loss: 0.16157124936580658
Validation loss: 1.4470303045806063

Epoch: 5| Step: 8
Training loss: 0.12489812076091766
Validation loss: 1.432362743603286

Epoch: 5| Step: 9
Training loss: 0.04977291822433472
Validation loss: 1.4517047559061358

Epoch: 5| Step: 10
Training loss: 0.14076077938079834
Validation loss: 1.4677778751619401

Epoch: 510| Step: 0
Training loss: 0.09666109830141068
Validation loss: 1.4718761226182342

Epoch: 5| Step: 1
Training loss: 0.09778209775686264
Validation loss: 1.4628303871359876

Epoch: 5| Step: 2
Training loss: 0.12015297263860703
Validation loss: 1.4643941207598614

Epoch: 5| Step: 3
Training loss: 0.09050541371107101
Validation loss: 1.4445126364308019

Epoch: 5| Step: 4
Training loss: 0.08020869642496109
Validation loss: 1.4779684300063758

Epoch: 5| Step: 5
Training loss: 0.08124709129333496
Validation loss: 1.4868933449509323

Epoch: 5| Step: 6
Training loss: 0.138466939330101
Validation loss: 1.484502104020888

Epoch: 5| Step: 7
Training loss: 0.14145393669605255
Validation loss: 1.4925509242601291

Epoch: 5| Step: 8
Training loss: 0.13838806748390198
Validation loss: 1.4741578294384865

Epoch: 5| Step: 9
Training loss: 0.11637085676193237
Validation loss: 1.4624132828045917

Epoch: 5| Step: 10
Training loss: 0.10352880507707596
Validation loss: 1.4657500482374621

Epoch: 511| Step: 0
Training loss: 0.10227739810943604
Validation loss: 1.5069385215800295

Epoch: 5| Step: 1
Training loss: 0.19667449593544006
Validation loss: 1.5033815868439213

Epoch: 5| Step: 2
Training loss: 0.14690248668193817
Validation loss: 1.4794415889247772

Epoch: 5| Step: 3
Training loss: 0.14018850028514862
Validation loss: 1.4646871859027493

Epoch: 5| Step: 4
Training loss: 0.09819846600294113
Validation loss: 1.4744364330845494

Epoch: 5| Step: 5
Training loss: 0.09460274130105972
Validation loss: 1.4715913559800835

Epoch: 5| Step: 6
Training loss: 0.07579644024372101
Validation loss: 1.4661618176326956

Epoch: 5| Step: 7
Training loss: 0.1643352508544922
Validation loss: 1.457075244636946

Epoch: 5| Step: 8
Training loss: 0.10998886823654175
Validation loss: 1.4607667333336287

Epoch: 5| Step: 9
Training loss: 0.06955721229314804
Validation loss: 1.4346598495719254

Epoch: 5| Step: 10
Training loss: 0.07146061211824417
Validation loss: 1.4475792056770735

Epoch: 512| Step: 0
Training loss: 0.07591620832681656
Validation loss: 1.4945614196920907

Epoch: 5| Step: 1
Training loss: 0.11845020949840546
Validation loss: 1.498740747410764

Epoch: 5| Step: 2
Training loss: 0.1353231966495514
Validation loss: 1.4964093969714256

Epoch: 5| Step: 3
Training loss: 0.09054785221815109
Validation loss: 1.511732591095791

Epoch: 5| Step: 4
Training loss: 0.14084689319133759
Validation loss: 1.5230036999589653

Epoch: 5| Step: 5
Training loss: 0.1668970137834549
Validation loss: 1.4860686217584917

Epoch: 5| Step: 6
Training loss: 0.08990723639726639
Validation loss: 1.4796104302970312

Epoch: 5| Step: 7
Training loss: 0.0550808310508728
Validation loss: 1.4693387464810443

Epoch: 5| Step: 8
Training loss: 0.09791195392608643
Validation loss: 1.4822644110648864

Epoch: 5| Step: 9
Training loss: 0.09650139510631561
Validation loss: 1.4695644763208204

Epoch: 5| Step: 10
Training loss: 0.11789709329605103
Validation loss: 1.4624180204124861

Epoch: 513| Step: 0
Training loss: 0.1627245843410492
Validation loss: 1.4369278236102032

Epoch: 5| Step: 1
Training loss: 0.09612849354743958
Validation loss: 1.4424616200949556

Epoch: 5| Step: 2
Training loss: 0.04705233499407768
Validation loss: 1.444522233419521

Epoch: 5| Step: 3
Training loss: 0.10866741836071014
Validation loss: 1.4299171387508351

Epoch: 5| Step: 4
Training loss: 0.09390457719564438
Validation loss: 1.4405621142797573

Epoch: 5| Step: 5
Training loss: 0.07959501445293427
Validation loss: 1.4421573544061312

Epoch: 5| Step: 6
Training loss: 0.1113479733467102
Validation loss: 1.4210091637026878

Epoch: 5| Step: 7
Training loss: 0.06930200010538101
Validation loss: 1.4351192494874359

Epoch: 5| Step: 8
Training loss: 0.17055058479309082
Validation loss: 1.4376295830613823

Epoch: 5| Step: 9
Training loss: 0.09399980306625366
Validation loss: 1.4292021874458558

Epoch: 5| Step: 10
Training loss: 0.08246587216854095
Validation loss: 1.4301522701017317

Epoch: 514| Step: 0
Training loss: 0.05542222410440445
Validation loss: 1.4337000487953104

Epoch: 5| Step: 1
Training loss: 0.07066025584936142
Validation loss: 1.4379742888994114

Epoch: 5| Step: 2
Training loss: 0.08548425137996674
Validation loss: 1.4295163846785022

Epoch: 5| Step: 3
Training loss: 0.0644482746720314
Validation loss: 1.4343240004713818

Epoch: 5| Step: 4
Training loss: 0.1470828354358673
Validation loss: 1.4230285959859048

Epoch: 5| Step: 5
Training loss: 0.16967110335826874
Validation loss: 1.454336799601073

Epoch: 5| Step: 6
Training loss: 0.09261413663625717
Validation loss: 1.4468342565721082

Epoch: 5| Step: 7
Training loss: 0.1024584025144577
Validation loss: 1.4505406964209773

Epoch: 5| Step: 8
Training loss: 0.05379553511738777
Validation loss: 1.4158107221767466

Epoch: 5| Step: 9
Training loss: 0.0563875250518322
Validation loss: 1.4214477718517344

Epoch: 5| Step: 10
Training loss: 0.09020134806632996
Validation loss: 1.4536859937893447

Epoch: 515| Step: 0
Training loss: 0.0713673084974289
Validation loss: 1.4341237903923116

Epoch: 5| Step: 1
Training loss: 0.07135824859142303
Validation loss: 1.4463263115575236

Epoch: 5| Step: 2
Training loss: 0.08144441246986389
Validation loss: 1.4525320888847433

Epoch: 5| Step: 3
Training loss: 0.10560519993305206
Validation loss: 1.455047401048804

Epoch: 5| Step: 4
Training loss: 0.08521158993244171
Validation loss: 1.4393881546553744

Epoch: 5| Step: 5
Training loss: 0.10303699970245361
Validation loss: 1.4370588551285446

Epoch: 5| Step: 6
Training loss: 0.08153034001588821
Validation loss: 1.4182129970160864

Epoch: 5| Step: 7
Training loss: 0.0862421989440918
Validation loss: 1.4359020276736187

Epoch: 5| Step: 8
Training loss: 0.08522801101207733
Validation loss: 1.4008653702274445

Epoch: 5| Step: 9
Training loss: 0.10373334586620331
Validation loss: 1.4175596391001055

Epoch: 5| Step: 10
Training loss: 0.22646445035934448
Validation loss: 1.4114340300201087

Epoch: 516| Step: 0
Training loss: 0.08128686249256134
Validation loss: 1.4236630406430972

Epoch: 5| Step: 1
Training loss: 0.10496550798416138
Validation loss: 1.4385811821106942

Epoch: 5| Step: 2
Training loss: 0.15977495908737183
Validation loss: 1.407329377948597

Epoch: 5| Step: 3
Training loss: 0.08578939735889435
Validation loss: 1.4420627368393766

Epoch: 5| Step: 4
Training loss: 0.09149497747421265
Validation loss: 1.4577106596321188

Epoch: 5| Step: 5
Training loss: 0.08705385774374008
Validation loss: 1.447923755773934

Epoch: 5| Step: 6
Training loss: 0.09932556003332138
Validation loss: 1.455961682463205

Epoch: 5| Step: 7
Training loss: 0.05408738926053047
Validation loss: 1.4546324617119246

Epoch: 5| Step: 8
Training loss: 0.09932095557451248
Validation loss: 1.4780744045011458

Epoch: 5| Step: 9
Training loss: 0.13053758442401886
Validation loss: 1.4171708604340911

Epoch: 5| Step: 10
Training loss: 0.06036940589547157
Validation loss: 1.4671256119205105

Epoch: 517| Step: 0
Training loss: 0.09429506957530975
Validation loss: 1.4577320519314017

Epoch: 5| Step: 1
Training loss: 0.06574825197458267
Validation loss: 1.434777408517817

Epoch: 5| Step: 2
Training loss: 0.06423910707235336
Validation loss: 1.4229330234630133

Epoch: 5| Step: 3
Training loss: 0.07731862366199493
Validation loss: 1.4408373384065525

Epoch: 5| Step: 4
Training loss: 0.07896836847066879
Validation loss: 1.4108776341202438

Epoch: 5| Step: 5
Training loss: 0.12341513484716415
Validation loss: 1.4475827447829708

Epoch: 5| Step: 6
Training loss: 0.07985074818134308
Validation loss: 1.4093121226115892

Epoch: 5| Step: 7
Training loss: 0.1740657240152359
Validation loss: 1.401879111925761

Epoch: 5| Step: 8
Training loss: 0.09023156762123108
Validation loss: 1.404427869345552

Epoch: 5| Step: 9
Training loss: 0.08823274075984955
Validation loss: 1.4417303275036555

Epoch: 5| Step: 10
Training loss: 0.09664783626794815
Validation loss: 1.4276675934432654

Epoch: 518| Step: 0
Training loss: 0.13429085910320282
Validation loss: 1.4229561507060964

Epoch: 5| Step: 1
Training loss: 0.13306130468845367
Validation loss: 1.4151714771024642

Epoch: 5| Step: 2
Training loss: 0.07674884051084518
Validation loss: 1.4388453306690339

Epoch: 5| Step: 3
Training loss: 0.06683826446533203
Validation loss: 1.444210494718244

Epoch: 5| Step: 4
Training loss: 0.07322610914707184
Validation loss: 1.4345411267331851

Epoch: 5| Step: 5
Training loss: 0.10429036617279053
Validation loss: 1.4297478634824035

Epoch: 5| Step: 6
Training loss: 0.09430664777755737
Validation loss: 1.4438676359832927

Epoch: 5| Step: 7
Training loss: 0.14481228590011597
Validation loss: 1.4446130273162678

Epoch: 5| Step: 8
Training loss: 0.06897696852684021
Validation loss: 1.4260070259853075

Epoch: 5| Step: 9
Training loss: 0.05991321802139282
Validation loss: 1.426964036880001

Epoch: 5| Step: 10
Training loss: 0.11958955228328705
Validation loss: 1.457692156555832

Epoch: 519| Step: 0
Training loss: 0.07661200314760208
Validation loss: 1.4257088297156877

Epoch: 5| Step: 1
Training loss: 0.05116691067814827
Validation loss: 1.4340674479802449

Epoch: 5| Step: 2
Training loss: 0.056935738772153854
Validation loss: 1.4249806679705137

Epoch: 5| Step: 3
Training loss: 0.03446675464510918
Validation loss: 1.4429101585060038

Epoch: 5| Step: 4
Training loss: 0.038971368223428726
Validation loss: 1.4352571912991103

Epoch: 5| Step: 5
Training loss: 0.07187069952487946
Validation loss: 1.4331691931652766

Epoch: 5| Step: 6
Training loss: 0.10919898748397827
Validation loss: 1.4529768061894242

Epoch: 5| Step: 7
Training loss: 0.055389631539583206
Validation loss: 1.4513053073677966

Epoch: 5| Step: 8
Training loss: 0.17900089919567108
Validation loss: 1.4299077013487458

Epoch: 5| Step: 9
Training loss: 0.10218966007232666
Validation loss: 1.4382570764069915

Epoch: 5| Step: 10
Training loss: 0.08542585372924805
Validation loss: 1.4453998746410492

Epoch: 520| Step: 0
Training loss: 0.08976784348487854
Validation loss: 1.434629399289367

Epoch: 5| Step: 1
Training loss: 0.08014503121376038
Validation loss: 1.4567101014557706

Epoch: 5| Step: 2
Training loss: 0.072332963347435
Validation loss: 1.4380783240000408

Epoch: 5| Step: 3
Training loss: 0.07242918014526367
Validation loss: 1.460429415907911

Epoch: 5| Step: 4
Training loss: 0.0974806696176529
Validation loss: 1.4286400034863462

Epoch: 5| Step: 5
Training loss: 0.10713376104831696
Validation loss: 1.4417380107346403

Epoch: 5| Step: 6
Training loss: 0.11073758453130722
Validation loss: 1.4691546014560166

Epoch: 5| Step: 7
Training loss: 0.1391638219356537
Validation loss: 1.4492061484244563

Epoch: 5| Step: 8
Training loss: 0.10982169955968857
Validation loss: 1.4226248719358956

Epoch: 5| Step: 9
Training loss: 0.07118085026741028
Validation loss: 1.4205420901698451

Epoch: 5| Step: 10
Training loss: 0.07706529647111893
Validation loss: 1.4128816666141633

Epoch: 521| Step: 0
Training loss: 0.09899468719959259
Validation loss: 1.448797563070892

Epoch: 5| Step: 1
Training loss: 0.08403453230857849
Validation loss: 1.4452141202906126

Epoch: 5| Step: 2
Training loss: 0.09448639303445816
Validation loss: 1.4305773024917932

Epoch: 5| Step: 3
Training loss: 0.08240810036659241
Validation loss: 1.4532667667635026

Epoch: 5| Step: 4
Training loss: 0.11368004977703094
Validation loss: 1.4565761156620518

Epoch: 5| Step: 5
Training loss: 0.15284059941768646
Validation loss: 1.4182291428248088

Epoch: 5| Step: 6
Training loss: 0.09228567779064178
Validation loss: 1.4265903554936892

Epoch: 5| Step: 7
Training loss: 0.0862804427742958
Validation loss: 1.4334761916950185

Epoch: 5| Step: 8
Training loss: 0.07611946761608124
Validation loss: 1.4465366358398108

Epoch: 5| Step: 9
Training loss: 0.05853114277124405
Validation loss: 1.4339074921864334

Epoch: 5| Step: 10
Training loss: 0.0626087635755539
Validation loss: 1.4329241168114446

Epoch: 522| Step: 0
Training loss: 0.12124444544315338
Validation loss: 1.4342419723028779

Epoch: 5| Step: 1
Training loss: 0.05837825685739517
Validation loss: 1.4538252738214308

Epoch: 5| Step: 2
Training loss: 0.08097677677869797
Validation loss: 1.4737939732049101

Epoch: 5| Step: 3
Training loss: 0.08062027394771576
Validation loss: 1.4597166776657104

Epoch: 5| Step: 4
Training loss: 0.10695414245128632
Validation loss: 1.4817044581136396

Epoch: 5| Step: 5
Training loss: 0.20839659869670868
Validation loss: 1.480259640883374

Epoch: 5| Step: 6
Training loss: 0.094284288585186
Validation loss: 1.4729858803492721

Epoch: 5| Step: 7
Training loss: 0.054311685264110565
Validation loss: 1.4529609180265857

Epoch: 5| Step: 8
Training loss: 0.07548090070486069
Validation loss: 1.4367811936204151

Epoch: 5| Step: 9
Training loss: 0.10407000780105591
Validation loss: 1.4662208255901132

Epoch: 5| Step: 10
Training loss: 0.11948787420988083
Validation loss: 1.4599886261006838

Epoch: 523| Step: 0
Training loss: 0.15201899409294128
Validation loss: 1.4432097070960588

Epoch: 5| Step: 1
Training loss: 0.12236706912517548
Validation loss: 1.4371727807547456

Epoch: 5| Step: 2
Training loss: 0.0928613692522049
Validation loss: 1.4497816229379306

Epoch: 5| Step: 3
Training loss: 0.10835671424865723
Validation loss: 1.4516815062492125

Epoch: 5| Step: 4
Training loss: 0.18722698092460632
Validation loss: 1.4602223378355785

Epoch: 5| Step: 5
Training loss: 0.15330031514167786
Validation loss: 1.4554483147077664

Epoch: 5| Step: 6
Training loss: 0.08196218311786652
Validation loss: 1.447953680510162

Epoch: 5| Step: 7
Training loss: 0.1294168382883072
Validation loss: 1.4417023146024315

Epoch: 5| Step: 8
Training loss: 0.15047922730445862
Validation loss: 1.442805951641452

Epoch: 5| Step: 9
Training loss: 0.11847631633281708
Validation loss: 1.4291398320146786

Epoch: 5| Step: 10
Training loss: 0.13316436111927032
Validation loss: 1.4142082891156595

Epoch: 524| Step: 0
Training loss: 0.1381811648607254
Validation loss: 1.423745374525747

Epoch: 5| Step: 1
Training loss: 0.08018113672733307
Validation loss: 1.455508045611843

Epoch: 5| Step: 2
Training loss: 0.1240137591958046
Validation loss: 1.4521476850714734

Epoch: 5| Step: 3
Training loss: 0.0821092277765274
Validation loss: 1.4436544397825837

Epoch: 5| Step: 4
Training loss: 0.12851504981517792
Validation loss: 1.4734869721115276

Epoch: 5| Step: 5
Training loss: 0.1194329485297203
Validation loss: 1.4574158486499582

Epoch: 5| Step: 6
Training loss: 0.11003357172012329
Validation loss: 1.4440715184775732

Epoch: 5| Step: 7
Training loss: 0.0953478068113327
Validation loss: 1.4296951627218595

Epoch: 5| Step: 8
Training loss: 0.13585612177848816
Validation loss: 1.4420799657862673

Epoch: 5| Step: 9
Training loss: 0.09136303514242172
Validation loss: 1.4214413781319895

Epoch: 5| Step: 10
Training loss: 0.05352829396724701
Validation loss: 1.4168090576766639

Epoch: 525| Step: 0
Training loss: 0.057969529181718826
Validation loss: 1.4526219252617127

Epoch: 5| Step: 1
Training loss: 0.10629017651081085
Validation loss: 1.4308533027607908

Epoch: 5| Step: 2
Training loss: 0.0684882327914238
Validation loss: 1.4588953243788851

Epoch: 5| Step: 3
Training loss: 0.07570286095142365
Validation loss: 1.4339853858435025

Epoch: 5| Step: 4
Training loss: 0.06879736483097076
Validation loss: 1.4511660350266324

Epoch: 5| Step: 5
Training loss: 0.08971744030714035
Validation loss: 1.434845623790577

Epoch: 5| Step: 6
Training loss: 0.13931426405906677
Validation loss: 1.4403625701063423

Epoch: 5| Step: 7
Training loss: 0.09945942461490631
Validation loss: 1.4146420263474988

Epoch: 5| Step: 8
Training loss: 0.11166882514953613
Validation loss: 1.436170826035161

Epoch: 5| Step: 9
Training loss: 0.15395276248455048
Validation loss: 1.4113940974717498

Epoch: 5| Step: 10
Training loss: 0.18895766139030457
Validation loss: 1.412211359188121

Epoch: 526| Step: 0
Training loss: 0.08222832530736923
Validation loss: 1.4176945378703456

Epoch: 5| Step: 1
Training loss: 0.19320513308048248
Validation loss: 1.4183479637228034

Epoch: 5| Step: 2
Training loss: 0.13078783452510834
Validation loss: 1.403732192131781

Epoch: 5| Step: 3
Training loss: 0.08945918828248978
Validation loss: 1.4323476552963257

Epoch: 5| Step: 4
Training loss: 0.12114057689905167
Validation loss: 1.4077159012517622

Epoch: 5| Step: 5
Training loss: 0.08790861070156097
Validation loss: 1.426123643434176

Epoch: 5| Step: 6
Training loss: 0.10388953983783722
Validation loss: 1.4239633852435696

Epoch: 5| Step: 7
Training loss: 0.10075680911540985
Validation loss: 1.424006413387996

Epoch: 5| Step: 8
Training loss: 0.10118122398853302
Validation loss: 1.4284259106523247

Epoch: 5| Step: 9
Training loss: 0.08936194330453873
Validation loss: 1.4160112975746073

Epoch: 5| Step: 10
Training loss: 0.1893135905265808
Validation loss: 1.4101260676178882

Epoch: 527| Step: 0
Training loss: 0.16490797698497772
Validation loss: 1.4142731287146126

Epoch: 5| Step: 1
Training loss: 0.08963768184185028
Validation loss: 1.407431879351216

Epoch: 5| Step: 2
Training loss: 0.08985493332147598
Validation loss: 1.4095013654360207

Epoch: 5| Step: 3
Training loss: 0.06742216646671295
Validation loss: 1.4267329938950077

Epoch: 5| Step: 4
Training loss: 0.09232340008020401
Validation loss: 1.4283303945295271

Epoch: 5| Step: 5
Training loss: 0.05431561544537544
Validation loss: 1.4437229844831652

Epoch: 5| Step: 6
Training loss: 0.08877117931842804
Validation loss: 1.4497409341155842

Epoch: 5| Step: 7
Training loss: 0.07101260125637054
Validation loss: 1.422526406344547

Epoch: 5| Step: 8
Training loss: 0.07012423872947693
Validation loss: 1.4422309731924405

Epoch: 5| Step: 9
Training loss: 0.10911132395267487
Validation loss: 1.440870012006452

Epoch: 5| Step: 10
Training loss: 0.103712297976017
Validation loss: 1.436557069260587

Epoch: 528| Step: 0
Training loss: 0.10510209947824478
Validation loss: 1.455892030910779

Epoch: 5| Step: 1
Training loss: 0.13458681106567383
Validation loss: 1.4623799759854552

Epoch: 5| Step: 2
Training loss: 0.10469178855419159
Validation loss: 1.4527658506106305

Epoch: 5| Step: 3
Training loss: 0.08580247312784195
Validation loss: 1.4500324239013016

Epoch: 5| Step: 4
Training loss: 0.09395238757133484
Validation loss: 1.4569168103638517

Epoch: 5| Step: 5
Training loss: 0.11843913793563843
Validation loss: 1.4388602113211026

Epoch: 5| Step: 6
Training loss: 0.08053134381771088
Validation loss: 1.4209428961559007

Epoch: 5| Step: 7
Training loss: 0.0967743769288063
Validation loss: 1.4193639255339099

Epoch: 5| Step: 8
Training loss: 0.09968601912260056
Validation loss: 1.4140182579717329

Epoch: 5| Step: 9
Training loss: 0.13763384521007538
Validation loss: 1.403256957889885

Epoch: 5| Step: 10
Training loss: 0.07000182569026947
Validation loss: 1.418682348343634

Epoch: 529| Step: 0
Training loss: 0.12507613003253937
Validation loss: 1.4190512370037776

Epoch: 5| Step: 1
Training loss: 0.0670362114906311
Validation loss: 1.4198886630355672

Epoch: 5| Step: 2
Training loss: 0.09193899482488632
Validation loss: 1.4329204123507264

Epoch: 5| Step: 3
Training loss: 0.09753575176000595
Validation loss: 1.4395342924261605

Epoch: 5| Step: 4
Training loss: 0.11785038560628891
Validation loss: 1.4598838308806061

Epoch: 5| Step: 5
Training loss: 0.09941408783197403
Validation loss: 1.4296370193522463

Epoch: 5| Step: 6
Training loss: 0.08718384057283401
Validation loss: 1.4628651116483955

Epoch: 5| Step: 7
Training loss: 0.08805237710475922
Validation loss: 1.457869145818936

Epoch: 5| Step: 8
Training loss: 0.06806591898202896
Validation loss: 1.450860354208177

Epoch: 5| Step: 9
Training loss: 0.10269055515527725
Validation loss: 1.4464471096633582

Epoch: 5| Step: 10
Training loss: 0.051414161920547485
Validation loss: 1.467619921571465

Epoch: 530| Step: 0
Training loss: 0.0767592266201973
Validation loss: 1.4475472845057005

Epoch: 5| Step: 1
Training loss: 0.11166094243526459
Validation loss: 1.4541755889051704

Epoch: 5| Step: 2
Training loss: 0.09158501029014587
Validation loss: 1.435608934330684

Epoch: 5| Step: 3
Training loss: 0.07085663080215454
Validation loss: 1.4543849896359187

Epoch: 5| Step: 4
Training loss: 0.16523706912994385
Validation loss: 1.456783575396384

Epoch: 5| Step: 5
Training loss: 0.0872993916273117
Validation loss: 1.4379751047780436

Epoch: 5| Step: 6
Training loss: 0.06827598810195923
Validation loss: 1.4500204683631979

Epoch: 5| Step: 7
Training loss: 0.12944109737873077
Validation loss: 1.4742269836446291

Epoch: 5| Step: 8
Training loss: 0.053020112216472626
Validation loss: 1.4236201996444373

Epoch: 5| Step: 9
Training loss: 0.10152687877416611
Validation loss: 1.429840410268435

Epoch: 5| Step: 10
Training loss: 0.06635566800832748
Validation loss: 1.451003674537905

Epoch: 531| Step: 0
Training loss: 0.08247944712638855
Validation loss: 1.4546886156964045

Epoch: 5| Step: 1
Training loss: 0.08468485623598099
Validation loss: 1.4396147753602715

Epoch: 5| Step: 2
Training loss: 0.10824833065271378
Validation loss: 1.4208502051650838

Epoch: 5| Step: 3
Training loss: 0.09546852111816406
Validation loss: 1.4361449903057468

Epoch: 5| Step: 4
Training loss: 0.12864963710308075
Validation loss: 1.4073940829564167

Epoch: 5| Step: 5
Training loss: 0.09002406895160675
Validation loss: 1.4392402172088623

Epoch: 5| Step: 6
Training loss: 0.07273231446743011
Validation loss: 1.453897532596383

Epoch: 5| Step: 7
Training loss: 0.06919930130243301
Validation loss: 1.4603573442787252

Epoch: 5| Step: 8
Training loss: 0.09883667528629303
Validation loss: 1.4563737223225255

Epoch: 5| Step: 9
Training loss: 0.06178247928619385
Validation loss: 1.4695211943759714

Epoch: 5| Step: 10
Training loss: 0.12548519670963287
Validation loss: 1.43279565406102

Epoch: 532| Step: 0
Training loss: 0.11582468450069427
Validation loss: 1.4548096733708535

Epoch: 5| Step: 1
Training loss: 0.1035546287894249
Validation loss: 1.4277831508267311

Epoch: 5| Step: 2
Training loss: 0.11566851288080215
Validation loss: 1.414521840310866

Epoch: 5| Step: 3
Training loss: 0.06926941126585007
Validation loss: 1.4234567816539476

Epoch: 5| Step: 4
Training loss: 0.055571358650922775
Validation loss: 1.406810995071165

Epoch: 5| Step: 5
Training loss: 0.07511628419160843
Validation loss: 1.399453309274489

Epoch: 5| Step: 6
Training loss: 0.08398417383432388
Validation loss: 1.4063775693216631

Epoch: 5| Step: 7
Training loss: 0.12420125305652618
Validation loss: 1.4189302382930633

Epoch: 5| Step: 8
Training loss: 0.08207184076309204
Validation loss: 1.4284420987611175

Epoch: 5| Step: 9
Training loss: 0.07122062146663666
Validation loss: 1.4124343587506203

Epoch: 5| Step: 10
Training loss: 0.0754145011305809
Validation loss: 1.4191759658116165

Epoch: 533| Step: 0
Training loss: 0.07062332332134247
Validation loss: 1.428943544305781

Epoch: 5| Step: 1
Training loss: 0.04941119626164436
Validation loss: 1.4401274611873012

Epoch: 5| Step: 2
Training loss: 0.08491338789463043
Validation loss: 1.4614500102176462

Epoch: 5| Step: 3
Training loss: 0.11099867522716522
Validation loss: 1.4406166153569375

Epoch: 5| Step: 4
Training loss: 0.1015462875366211
Validation loss: 1.4331425505299722

Epoch: 5| Step: 5
Training loss: 0.1517731249332428
Validation loss: 1.4690553308815084

Epoch: 5| Step: 6
Training loss: 0.0691041424870491
Validation loss: 1.4338497602811424

Epoch: 5| Step: 7
Training loss: 0.15896345674991608
Validation loss: 1.447224311931159

Epoch: 5| Step: 8
Training loss: 0.09724245965480804
Validation loss: 1.4279651923846173

Epoch: 5| Step: 9
Training loss: 0.06543654948472977
Validation loss: 1.4369248869598552

Epoch: 5| Step: 10
Training loss: 0.08509043604135513
Validation loss: 1.4513505761341383

Epoch: 534| Step: 0
Training loss: 0.12243644893169403
Validation loss: 1.4197783700881466

Epoch: 5| Step: 1
Training loss: 0.07758774608373642
Validation loss: 1.4348972715357298

Epoch: 5| Step: 2
Training loss: 0.08001289516687393
Validation loss: 1.426613861514676

Epoch: 5| Step: 3
Training loss: 0.03986850008368492
Validation loss: 1.4152298332542501

Epoch: 5| Step: 4
Training loss: 0.0625072494149208
Validation loss: 1.4198682974743586

Epoch: 5| Step: 5
Training loss: 0.0780784860253334
Validation loss: 1.405429768305953

Epoch: 5| Step: 6
Training loss: 0.06348022073507309
Validation loss: 1.4032512557122014

Epoch: 5| Step: 7
Training loss: 0.13616211712360382
Validation loss: 1.4217979690080047

Epoch: 5| Step: 8
Training loss: 0.09831923246383667
Validation loss: 1.405553546003116

Epoch: 5| Step: 9
Training loss: 0.062213219702243805
Validation loss: 1.3982723880839605

Epoch: 5| Step: 10
Training loss: 0.07396382093429565
Validation loss: 1.4177664274810462

Epoch: 535| Step: 0
Training loss: 0.0827607735991478
Validation loss: 1.4076373987300421

Epoch: 5| Step: 1
Training loss: 0.1366538107395172
Validation loss: 1.4273701303748674

Epoch: 5| Step: 2
Training loss: 0.07369288057088852
Validation loss: 1.4093867719814341

Epoch: 5| Step: 3
Training loss: 0.0937318503856659
Validation loss: 1.4287105978176158

Epoch: 5| Step: 4
Training loss: 0.09218204766511917
Validation loss: 1.4442260508896203

Epoch: 5| Step: 5
Training loss: 0.10362765938043594
Validation loss: 1.4336070719585623

Epoch: 5| Step: 6
Training loss: 0.09923715889453888
Validation loss: 1.4301869548777097

Epoch: 5| Step: 7
Training loss: 0.13618792593479156
Validation loss: 1.4072932825293591

Epoch: 5| Step: 8
Training loss: 0.12808553874492645
Validation loss: 1.4408843696758311

Epoch: 5| Step: 9
Training loss: 0.13252946734428406
Validation loss: 1.439948836962382

Epoch: 5| Step: 10
Training loss: 0.09094911813735962
Validation loss: 1.450384445087884

Epoch: 536| Step: 0
Training loss: 0.10452379286289215
Validation loss: 1.4043191453462005

Epoch: 5| Step: 1
Training loss: 0.07932521402835846
Validation loss: 1.4026990026556037

Epoch: 5| Step: 2
Training loss: 0.10751795768737793
Validation loss: 1.435406687439129

Epoch: 5| Step: 3
Training loss: 0.14705044031143188
Validation loss: 1.457145921645626

Epoch: 5| Step: 4
Training loss: 0.19519999623298645
Validation loss: 1.445900991398801

Epoch: 5| Step: 5
Training loss: 0.07059023529291153
Validation loss: 1.4513522425005514

Epoch: 5| Step: 6
Training loss: 0.08690331131219864
Validation loss: 1.410065379194034

Epoch: 5| Step: 7
Training loss: 0.09534257650375366
Validation loss: 1.4343142612006075

Epoch: 5| Step: 8
Training loss: 0.10521867126226425
Validation loss: 1.41941661091261

Epoch: 5| Step: 9
Training loss: 0.1456325799226761
Validation loss: 1.4308819386266893

Epoch: 5| Step: 10
Training loss: 0.06955458223819733
Validation loss: 1.4464413401901082

Epoch: 537| Step: 0
Training loss: 0.05686420202255249
Validation loss: 1.421492507380824

Epoch: 5| Step: 1
Training loss: 0.06827177852392197
Validation loss: 1.416727900505066

Epoch: 5| Step: 2
Training loss: 0.0849599540233612
Validation loss: 1.4050120628008278

Epoch: 5| Step: 3
Training loss: 0.06213965266942978
Validation loss: 1.4346164887951267

Epoch: 5| Step: 4
Training loss: 0.07085217535495758
Validation loss: 1.4253857943319506

Epoch: 5| Step: 5
Training loss: 0.16733069717884064
Validation loss: 1.4387152553886495

Epoch: 5| Step: 6
Training loss: 0.11749615520238876
Validation loss: 1.4268101594781364

Epoch: 5| Step: 7
Training loss: 0.07539679110050201
Validation loss: 1.4146926813228156

Epoch: 5| Step: 8
Training loss: 0.12318447977304459
Validation loss: 1.434771071198166

Epoch: 5| Step: 9
Training loss: 0.12725895643234253
Validation loss: 1.3972103185551141

Epoch: 5| Step: 10
Training loss: 0.10146650671958923
Validation loss: 1.3998587823683215

Epoch: 538| Step: 0
Training loss: 0.051277972757816315
Validation loss: 1.4187435796183925

Epoch: 5| Step: 1
Training loss: 0.08490829169750214
Validation loss: 1.4135361897048129

Epoch: 5| Step: 2
Training loss: 0.07550279796123505
Validation loss: 1.3962294414479246

Epoch: 5| Step: 3
Training loss: 0.0948755294084549
Validation loss: 1.4009723945330548

Epoch: 5| Step: 4
Training loss: 0.05294938012957573
Validation loss: 1.4134923129953363

Epoch: 5| Step: 5
Training loss: 0.06968002021312714
Validation loss: 1.4166903816243654

Epoch: 5| Step: 6
Training loss: 0.13794706761837006
Validation loss: 1.4128860119850404

Epoch: 5| Step: 7
Training loss: 0.05043160915374756
Validation loss: 1.4046216908321585

Epoch: 5| Step: 8
Training loss: 0.1126069575548172
Validation loss: 1.4194834616876417

Epoch: 5| Step: 9
Training loss: 0.09329213201999664
Validation loss: 1.4331991441788212

Epoch: 5| Step: 10
Training loss: 0.16387715935707092
Validation loss: 1.4463381177635604

Epoch: 539| Step: 0
Training loss: 0.06612732261419296
Validation loss: 1.4285354101529686

Epoch: 5| Step: 1
Training loss: 0.10543026030063629
Validation loss: 1.4367286300146451

Epoch: 5| Step: 2
Training loss: 0.13394176959991455
Validation loss: 1.4247226843269922

Epoch: 5| Step: 3
Training loss: 0.07362814247608185
Validation loss: 1.428789867508796

Epoch: 5| Step: 4
Training loss: 0.11955906450748444
Validation loss: 1.4321115330983234

Epoch: 5| Step: 5
Training loss: 0.08661214262247086
Validation loss: 1.435922573971492

Epoch: 5| Step: 6
Training loss: 0.0722564235329628
Validation loss: 1.4309289634868663

Epoch: 5| Step: 7
Training loss: 0.1344173699617386
Validation loss: 1.4060498245300785

Epoch: 5| Step: 8
Training loss: 0.06692914664745331
Validation loss: 1.419823049217142

Epoch: 5| Step: 9
Training loss: 0.07135407626628876
Validation loss: 1.4141524709681028

Epoch: 5| Step: 10
Training loss: 0.10280527919530869
Validation loss: 1.39502731702661

Epoch: 540| Step: 0
Training loss: 0.1359034776687622
Validation loss: 1.4196232236841673

Epoch: 5| Step: 1
Training loss: 0.07461155205965042
Validation loss: 1.4069985253836519

Epoch: 5| Step: 2
Training loss: 0.08817919343709946
Validation loss: 1.3829737260777464

Epoch: 5| Step: 3
Training loss: 0.08761882781982422
Validation loss: 1.4088432750394266

Epoch: 5| Step: 4
Training loss: 0.057623039931058884
Validation loss: 1.3876399570895779

Epoch: 5| Step: 5
Training loss: 0.0680728405714035
Validation loss: 1.406763192146055

Epoch: 5| Step: 6
Training loss: 0.1582605540752411
Validation loss: 1.425754847065095

Epoch: 5| Step: 7
Training loss: 0.09859336912631989
Validation loss: 1.4054024052876297

Epoch: 5| Step: 8
Training loss: 0.059532441198825836
Validation loss: 1.4050419304960517

Epoch: 5| Step: 9
Training loss: 0.04983022063970566
Validation loss: 1.4081196208154

Epoch: 5| Step: 10
Training loss: 0.06099291518330574
Validation loss: 1.4077356118027882

Epoch: 541| Step: 0
Training loss: 0.09912744164466858
Validation loss: 1.4149491081955612

Epoch: 5| Step: 1
Training loss: 0.07187625765800476
Validation loss: 1.4157619232772498

Epoch: 5| Step: 2
Training loss: 0.13671915233135223
Validation loss: 1.417606253777781

Epoch: 5| Step: 3
Training loss: 0.05677265673875809
Validation loss: 1.420862001757468

Epoch: 5| Step: 4
Training loss: 0.08380763232707977
Validation loss: 1.4211170596461142

Epoch: 5| Step: 5
Training loss: 0.1057126522064209
Validation loss: 1.4393752300611107

Epoch: 5| Step: 6
Training loss: 0.12631218135356903
Validation loss: 1.4355818046036588

Epoch: 5| Step: 7
Training loss: 0.060828231275081635
Validation loss: 1.4249778101521153

Epoch: 5| Step: 8
Training loss: 0.0920848399400711
Validation loss: 1.4028949955458283

Epoch: 5| Step: 9
Training loss: 0.07257404178380966
Validation loss: 1.4058436373228669

Epoch: 5| Step: 10
Training loss: 0.08894425630569458
Validation loss: 1.4301623375185075

Epoch: 542| Step: 0
Training loss: 0.09354527294635773
Validation loss: 1.4233924932377313

Epoch: 5| Step: 1
Training loss: 0.06233394145965576
Validation loss: 1.391325973054414

Epoch: 5| Step: 2
Training loss: 0.062132179737091064
Validation loss: 1.3892624198749501

Epoch: 5| Step: 3
Training loss: 0.05356329679489136
Validation loss: 1.4219599500779183

Epoch: 5| Step: 4
Training loss: 0.09854444116353989
Validation loss: 1.4138768424269974

Epoch: 5| Step: 5
Training loss: 0.056637585163116455
Validation loss: 1.4294169961765248

Epoch: 5| Step: 6
Training loss: 0.0729968324303627
Validation loss: 1.4361716252501293

Epoch: 5| Step: 7
Training loss: 0.1207457035779953
Validation loss: 1.4306286586228238

Epoch: 5| Step: 8
Training loss: 0.13182008266448975
Validation loss: 1.4403447810039725

Epoch: 5| Step: 9
Training loss: 0.14531154930591583
Validation loss: 1.4215932341032131

Epoch: 5| Step: 10
Training loss: 0.047042056918144226
Validation loss: 1.424077909479859

Epoch: 543| Step: 0
Training loss: 0.09730107337236404
Validation loss: 1.4357694272072083

Epoch: 5| Step: 1
Training loss: 0.03150833770632744
Validation loss: 1.4510448645519953

Epoch: 5| Step: 2
Training loss: 0.06288047134876251
Validation loss: 1.44215997188322

Epoch: 5| Step: 3
Training loss: 0.11256172508001328
Validation loss: 1.441300078104901

Epoch: 5| Step: 4
Training loss: 0.06716710329055786
Validation loss: 1.426226008322931

Epoch: 5| Step: 5
Training loss: 0.055269788950681686
Validation loss: 1.4398569842820526

Epoch: 5| Step: 6
Training loss: 0.11046317964792252
Validation loss: 1.4312822190664147

Epoch: 5| Step: 7
Training loss: 0.10349774360656738
Validation loss: 1.4411526687683598

Epoch: 5| Step: 8
Training loss: 0.08545489609241486
Validation loss: 1.4248185516685568

Epoch: 5| Step: 9
Training loss: 0.11764457076787949
Validation loss: 1.4295614432263117

Epoch: 5| Step: 10
Training loss: 0.10804761946201324
Validation loss: 1.4276840577843368

Epoch: 544| Step: 0
Training loss: 0.10987155139446259
Validation loss: 1.4346132848852424

Epoch: 5| Step: 1
Training loss: 0.05718313530087471
Validation loss: 1.4168804749365775

Epoch: 5| Step: 2
Training loss: 0.12465057522058487
Validation loss: 1.4259111567210125

Epoch: 5| Step: 3
Training loss: 0.10265891253948212
Validation loss: 1.400220532571116

Epoch: 5| Step: 4
Training loss: 0.08010460436344147
Validation loss: 1.4030145220859076

Epoch: 5| Step: 5
Training loss: 0.05333005264401436
Validation loss: 1.4082782499251827

Epoch: 5| Step: 6
Training loss: 0.11480124294757843
Validation loss: 1.415533778487995

Epoch: 5| Step: 7
Training loss: 0.0517406091094017
Validation loss: 1.4206094049638318

Epoch: 5| Step: 8
Training loss: 0.09213028848171234
Validation loss: 1.4236222223568988

Epoch: 5| Step: 9
Training loss: 0.16885855793952942
Validation loss: 1.455679726857011

Epoch: 5| Step: 10
Training loss: 0.1000564694404602
Validation loss: 1.4475584722334338

Epoch: 545| Step: 0
Training loss: 0.08983056247234344
Validation loss: 1.4398859905940231

Epoch: 5| Step: 1
Training loss: 0.0718735083937645
Validation loss: 1.4210478964672293

Epoch: 5| Step: 2
Training loss: 0.07102285325527191
Validation loss: 1.4258780684522403

Epoch: 5| Step: 3
Training loss: 0.05456243082880974
Validation loss: 1.4352386061863234

Epoch: 5| Step: 4
Training loss: 0.098027803003788
Validation loss: 1.4443115521502752

Epoch: 5| Step: 5
Training loss: 0.08858112245798111
Validation loss: 1.414926004666154

Epoch: 5| Step: 6
Training loss: 0.08807427436113358
Validation loss: 1.429414378699436

Epoch: 5| Step: 7
Training loss: 0.05564749240875244
Validation loss: 1.4149321817582654

Epoch: 5| Step: 8
Training loss: 0.13987760245800018
Validation loss: 1.4251130191228722

Epoch: 5| Step: 9
Training loss: 0.04807102307677269
Validation loss: 1.4153496341038776

Epoch: 5| Step: 10
Training loss: 0.1380247175693512
Validation loss: 1.4407558876981017

Epoch: 546| Step: 0
Training loss: 0.0701141208410263
Validation loss: 1.444035214762534

Epoch: 5| Step: 1
Training loss: 0.06962743401527405
Validation loss: 1.4589309025836248

Epoch: 5| Step: 2
Training loss: 0.16096647083759308
Validation loss: 1.451250732585948

Epoch: 5| Step: 3
Training loss: 0.07320238649845123
Validation loss: 1.4579127796234623

Epoch: 5| Step: 4
Training loss: 0.1067635789513588
Validation loss: 1.4730416972150084

Epoch: 5| Step: 5
Training loss: 0.0534672848880291
Validation loss: 1.4562439533971971

Epoch: 5| Step: 6
Training loss: 0.09391436725854874
Validation loss: 1.4368840443190707

Epoch: 5| Step: 7
Training loss: 0.08750998228788376
Validation loss: 1.4382040596777392

Epoch: 5| Step: 8
Training loss: 0.07389192283153534
Validation loss: 1.421015324131135

Epoch: 5| Step: 9
Training loss: 0.1262393742799759
Validation loss: 1.4254927968466153

Epoch: 5| Step: 10
Training loss: 0.06879337877035141
Validation loss: 1.4232673388655468

Epoch: 547| Step: 0
Training loss: 0.0974697396159172
Validation loss: 1.4348327011190436

Epoch: 5| Step: 1
Training loss: 0.125913605093956
Validation loss: 1.4350078477654407

Epoch: 5| Step: 2
Training loss: 0.047327686101198196
Validation loss: 1.4190917989259124

Epoch: 5| Step: 3
Training loss: 0.09952958673238754
Validation loss: 1.4258191354813115

Epoch: 5| Step: 4
Training loss: 0.11644972860813141
Validation loss: 1.4253208829510597

Epoch: 5| Step: 5
Training loss: 0.10029421001672745
Validation loss: 1.4045435959292996

Epoch: 5| Step: 6
Training loss: 0.14852198958396912
Validation loss: 1.4163894384138045

Epoch: 5| Step: 7
Training loss: 0.09416360408067703
Validation loss: 1.4174146395857616

Epoch: 5| Step: 8
Training loss: 0.06155272200703621
Validation loss: 1.4032472551509898

Epoch: 5| Step: 9
Training loss: 0.05862254649400711
Validation loss: 1.4302416078505977

Epoch: 5| Step: 10
Training loss: 0.10968735814094543
Validation loss: 1.4174288267730384

Epoch: 548| Step: 0
Training loss: 0.1376514583826065
Validation loss: 1.4164964050375006

Epoch: 5| Step: 1
Training loss: 0.09960087388753891
Validation loss: 1.4308329987269577

Epoch: 5| Step: 2
Training loss: 0.11071212589740753
Validation loss: 1.4388230667319348

Epoch: 5| Step: 3
Training loss: 0.06721122562885284
Validation loss: 1.4078937166480607

Epoch: 5| Step: 4
Training loss: 0.05403183773159981
Validation loss: 1.4143305606739496

Epoch: 5| Step: 5
Training loss: 0.07283918559551239
Validation loss: 1.4186959305117208

Epoch: 5| Step: 6
Training loss: 0.13797762989997864
Validation loss: 1.4317134509804428

Epoch: 5| Step: 7
Training loss: 0.14757126569747925
Validation loss: 1.4206812388153487

Epoch: 5| Step: 8
Training loss: 0.07408281415700912
Validation loss: 1.4223265288978495

Epoch: 5| Step: 9
Training loss: 0.11985766887664795
Validation loss: 1.4216806939853135

Epoch: 5| Step: 10
Training loss: 0.067710280418396
Validation loss: 1.442032257715861

Epoch: 549| Step: 0
Training loss: 0.06457047164440155
Validation loss: 1.4397660378486878

Epoch: 5| Step: 1
Training loss: 0.10531498491764069
Validation loss: 1.4353002886618338

Epoch: 5| Step: 2
Training loss: 0.1309725046157837
Validation loss: 1.445328486863003

Epoch: 5| Step: 3
Training loss: 0.06195557117462158
Validation loss: 1.422565362786734

Epoch: 5| Step: 4
Training loss: 0.10992395877838135
Validation loss: 1.4478350685488792

Epoch: 5| Step: 5
Training loss: 0.07128927111625671
Validation loss: 1.4371305191388695

Epoch: 5| Step: 6
Training loss: 0.04895887151360512
Validation loss: 1.424463616904392

Epoch: 5| Step: 7
Training loss: 0.07156067341566086
Validation loss: 1.4468344949906873

Epoch: 5| Step: 8
Training loss: 0.14753183722496033
Validation loss: 1.40985647965503

Epoch: 5| Step: 9
Training loss: 0.07465825229883194
Validation loss: 1.4261445486417381

Epoch: 5| Step: 10
Training loss: 0.10385175794363022
Validation loss: 1.430009586836702

Epoch: 550| Step: 0
Training loss: 0.15083163976669312
Validation loss: 1.4451076074313092

Epoch: 5| Step: 1
Training loss: 0.07150068134069443
Validation loss: 1.440213486712466

Epoch: 5| Step: 2
Training loss: 0.06794466078281403
Validation loss: 1.430963299607718

Epoch: 5| Step: 3
Training loss: 0.06787868589162827
Validation loss: 1.3867366519025577

Epoch: 5| Step: 4
Training loss: 0.10539872944355011
Validation loss: 1.3996506416669456

Epoch: 5| Step: 5
Training loss: 0.044682830572128296
Validation loss: 1.3972253914802306

Epoch: 5| Step: 6
Training loss: 0.08782458305358887
Validation loss: 1.3993731749955045

Epoch: 5| Step: 7
Training loss: 0.07180601358413696
Validation loss: 1.4084981615825365

Epoch: 5| Step: 8
Training loss: 0.12273021787405014
Validation loss: 1.4033080044613089

Epoch: 5| Step: 9
Training loss: 0.09202918410301208
Validation loss: 1.3959360968682073

Epoch: 5| Step: 10
Training loss: 0.12747573852539062
Validation loss: 1.3925405900965455

Testing loss: 2.177513347731696
